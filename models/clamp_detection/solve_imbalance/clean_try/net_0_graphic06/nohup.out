Initialized data layer 'data', producing 196608 outputs
Initialized data layer 'labels', producing 1 outputs
Initialized convolutional layer 'conv1', producing 63x63 48-channel output
Initialized max-pooling layer 'pool1', producing 31x31 48-channel output
Initialized cross-map response-normalization layer 'rnorm1', producing 31x31 48-channel output
Initialized convolutional layer 'conv2', producing 31x31 128-channel output
Initialized max-pooling layer 'pool2', producing 15x15 128-channel output
Initialized cross-map response-normalization layer 'rnorm2', producing 15x15 128-channel output
Initialized convolutional layer 'conv3', producing 15x15 192-channel output
Initialized convolutional layer 'conv4', producing 15x15 192-channel output
Initialized convolutional layer 'conv5', producing 15x15 128-channel output
Initialized max-pooling layer 'pool5', producing 7x7 128-channel output
Initialized fully-connected layer 'fc6', producing 4096 outputs
Initialized fully-connected layer 'fc7', producing 4096 outputs
Initialized fully-connected layer 'fc8', producing 2 outputs
Initialized softmax layer 'probs', producing 2 outputs
Initialized logistic regression cost 'logprob'
Initialized neuron layer 'conv1_neuron', producing 190512 outputs
Initialized neuron layer 'conv2_neuron', producing 123008 outputs
Initialized neuron layer 'conv3_neuron', producing 43200 outputs
Initialized neuron layer 'conv4_neuron', producing 43200 outputs
Initialized neuron layer 'conv5_neuron', producing 28800 outputs
Initialized neuron layer 'fc6_neuron', producing 4096 outputs
Initialized neuron layer 'fc7_neuron', producing 4096 outputs
=========================
Importing _ConvNet C++ module
=========================
Training ConvNet
Always write savepoints, regardless of test err improvement: 0     [DEFAULT]
Check gradients and quit?                                  : 0     [DEFAULT]
Compress checkpoints?                                      : 0     [DEFAULT]
Conserve GPU memory (slower)?                              : 0     [DEFAULT]
Convert given conv layers to unshared local                :       
Cropped DP: crop border size                               : 4     [DEFAULT]
Cropped DP: logreg layer name (for --multiview-test)       :       [DEFAULT]
Cropped DP: test on multiple patches?                      : 0     [DEFAULT]
Cropped Step: crop border step                             : 1     [DEFAULT]
Data batch range: testing                                  : 46-51 
Data batch range: training                                 : 1-45  
Data path                                                  : /data/ad6813/pipe-data/Bluebox/batches/clamp_detection 
Data provider                                              : basic-leaf256 
GPU override                                               : -1    [DEFAULT]
Layer definition file                                      : /homes/ad6813/Git/pipe-classification/models/clamp_detection/solve_imbalance/clean_try/net_0_graphic06/layers.cfg 
Layer parameter file                                       : /homes/ad6813/Git/pipe-classification/models/clamp_detection/solve_imbalance/clean_try/net_0_graphic06/params.cfg 
Load file                                                  :       [DEFAULT]
Maximum save file size (MB)                                : 0     [DEFAULT]
Minibatch size                                             : 128   [DEFAULT]
Number of GPUs                                             : 1     [DEFAULT]
Number of epochs                                           : 50000 [DEFAULT]
Save path                                                  : /data/ad6813/my-nets/saves 
Test and quit?                                             : 0     [DEFAULT]
Test on more than one batch at a time?                     : -1    
Test on one batch at a time?                               : 0     
Testing frequency                                          : 17    
Unshare weight matrices in given layers                    :       
=========================
Running on CUDA device(s) -2
Current time: Fri Jun 27 05:12:20 2014
Saving checkpoints to /data/ad6813/my-nets/saves/ConvNet__2014-06-27_05.12.17
=========================
1.1... logprob:  0.708715, 0.625000 (0.582 sec)
1.2... logprob:  0.762866, 0.320312 (0.580 sec)
1.3... logprob:  0.891282, 0.679688 (0.580 sec)
1.4... logprob:  1.398519, 0.335938 (0.580 sec)
1.5... logprob:  0.748735, 0.695312 (0.580 sec)
1.6... logprob:  1.177929, 0.351562 (0.580 sec)
1.7... logprob:  1.019436, 0.695312 (0.580 sec)
1.8... logprob:  1.439999, 0.296875 (0.580 sec)
1.9... logprob:  0.679257, 0.375000 (0.580 sec)
1.10... logprob:  0.749546, 0.671875 (0.580 sec)
1.11... logprob:  1.046964, 0.335938 (0.580 sec)
1.12... logprob:  0.928010, 0.648438 (0.580 sec)
1.13... logprob:  1.194717, 0.296875 (0.580 sec)
1.14... logprob:  0.668946, 0.359375 (0.580 sec)
1.15... logprob:  0.700588, 0.343750 (0.580 sec)
1.16... logprob:  0.856322, 0.726562 (0.580 sec)
1.17... logprob:  1.290977, 0.296875 (0.580 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.723368, 0.500000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979723e-03 [2.745254e-09] 
Layer 'conv1' biases: 4.817459e-10 [6.963362e-11] 
Layer 'conv2' weights[0]: 7.966638e-03 [2.869389e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.396619e-10] 
Layer 'conv3' weights[0]: 7.965014e-03 [2.769723e-09] 
Layer 'conv3' biases: 1.247520e-08 [1.712034e-09] 
Layer 'conv4' weights[0]: 7.997502e-03 [3.531482e-09] 
Layer 'conv4' biases: 1.000000e+00 [1.953011e-08] 
Layer 'conv5' weights[0]: 7.996422e-03 [1.256794e-07] 
Layer 'conv5' biases: 9.999997e-01 [1.350358e-07] 
Layer 'fc6' weights[0]: 7.593267e-03 [1.561543e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.578704e-08] 
Layer 'fc7' weights[0]: 7.854268e-03 [2.487442e-07] 
Layer 'fc7' biases: 9.999999e-01 [2.430859e-07] 
Layer 'fc8' weights[0]: 4.769299e-04 [2.938393e-04] 
Layer 'fc8' biases: 4.459734e-05 [2.835324e-04] 
Train error last 45 batches: 0.956636
-------------------------------------------------------
Saved checkpoint to /data/ad6813/my-nets/saves/ConvNet__2014-06-27_05.12.17
======================================================= (4.632 sec)
1.18... logprob:  0.669311, 0.390625 (0.584 sec)
1.19... logprob:  0.649325, 0.328125 (0.583 sec)
1.20... logprob:  0.898654, 0.460938 (0.583 sec)
1.21... logprob:  1.753214, 0.734375 (0.583 sec)
1.22... logprob:  1.919593, 0.304688 (0.583 sec)
1.23... logprob:  0.697613, 0.265625 (0.583 sec)
1.24... logprob:  0.694745, 0.625000 (0.583 sec)
1.25... logprob:  0.684163, 0.304688 (0.583 sec)
1.26... logprob:  0.739266, 0.625000 (0.586 sec)
1.27... logprob:  0.963014, 0.375000 (0.586 sec)
1.28... logprob:  1.044433, 0.570312 (0.586 sec)
1.29... logprob:  1.153575, 0.312500 (0.586 sec)
1.30... logprob:  0.722495, 0.640625 (0.586 sec)
1.31... logprob:  0.807574, 0.312500 (0.586 sec)
1.32... logprob:  0.851693, 0.679688 (0.586 sec)
1.33... logprob:  1.160143, 0.304688 (0.587 sec)
1.34... logprob:  0.688781, 0.296875 (0.586 sec)
=========================
Testing all batches

======================Test output======================
logprob:  1.381236, 0.500000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979716e-03 [7.490831e-10] 
Layer 'conv1' biases: 9.430044e-10 [2.521181e-11] 
Layer 'conv2' weights[0]: 7.966634e-03 [9.274788e-10] 
Layer 'conv2' biases: 1.000000e+00 [1.457257e-10] 
Layer 'conv3' weights[0]: 7.965009e-03 [1.052973e-09] 
Layer 'conv3' biases: 2.425706e-08 [5.373398e-10] 
Layer 'conv4' weights[0]: 7.997493e-03 [1.313786e-09] 
Layer 'conv4' biases: 1.000000e+00 [5.733227e-09] 
Layer 'conv5' weights[0]: 7.996426e-03 [3.310679e-08] 
Layer 'conv5' biases: 9.999990e-01 [3.426531e-08] 
Layer 'fc6' weights[0]: 7.593266e-03 [6.705438e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.825640e-09] 
Layer 'fc7' weights[0]: 7.854215e-03 [1.177278e-07] 
Layer 'fc7' biases: 9.999999e-01 [1.149133e-07] 
Layer 'fc8' weights[0]: 5.153578e-04 [2.027592e-04] 
Layer 'fc8' biases: 2.058567e-04 [1.976804e-04] 
Train error last 45 batches: 0.951776
-------------------------------------------------------
Not saving because 1.381236 > 0.723368 (1.17: -0.00%)
======================================================= (4.272 sec)
1.35... logprob:  1.053475, 0.375000 (0.586 sec)
1.36... logprob:  1.169949, 0.671875 (0.586 sec)
1.37... logprob:  1.558738, 0.320312 (0.585 sec)
1.38... logprob:  0.632919, 0.328125 (0.588 sec)
1.39... logprob:  0.607057, 0.289062 (0.587 sec)
1.40... logprob:  0.597797, 0.273438 (0.587 sec)
1.41... logprob:  0.634258, 0.320312 (0.587 sec)
1.42... logprob:  0.661969, 0.328125 (0.586 sec)
1.43... logprob:  0.716874, 0.671875 (0.587 sec)
1.44...