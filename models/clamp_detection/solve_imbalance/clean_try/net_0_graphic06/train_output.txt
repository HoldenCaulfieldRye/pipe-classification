nohup: ignoring input
Initialized data layer 'data', producing 196608 outputs
Initialized data layer 'labels', producing 1 outputs
Initialized convolutional layer 'conv1', producing 63x63 48-channel output
Initialized max-pooling layer 'pool1', producing 31x31 48-channel output
Initialized cross-map response-normalization layer 'rnorm1', producing 31x31 48-channel output
Initialized convolutional layer 'conv2', producing 31x31 128-channel output
Initialized max-pooling layer 'pool2', producing 15x15 128-channel output
Initialized cross-map response-normalization layer 'rnorm2', producing 15x15 128-channel output
Initialized convolutional layer 'conv3', producing 15x15 192-channel output
Initialized convolutional layer 'conv4', producing 15x15 192-channel output
Initialized convolutional layer 'conv5', producing 15x15 128-channel output
Initialized max-pooling layer 'pool5', producing 7x7 128-channel output
Initialized fully-connected layer 'fc6', producing 4096 outputs
Initialized fully-connected layer 'fc7', producing 4096 outputs
Initialized fully-connected layer 'fc8', producing 2 outputs
Initialized softmax layer 'probs', producing 2 outputs
Initialized logistic regression cost 'logprob'
Initialized neuron layer 'conv1_neuron', producing 190512 outputs
Initialized neuron layer 'conv2_neuron', producing 123008 outputs
Initialized neuron layer 'conv3_neuron', producing 43200 outputs
Initialized neuron layer 'conv4_neuron', producing 43200 outputs
Initialized neuron layer 'conv5_neuron', producing 28800 outputs
Initialized neuron layer 'fc6_neuron', producing 4096 outputs
Initialized neuron layer 'fc7_neuron', producing 4096 outputs
=========================
Importing _ConvNet C++ module
=========================
Training ConvNet
Always write savepoints, regardless of test err improvement: 0     [DEFAULT]
Check gradients and quit?                                  : 0     [DEFAULT]
Compress checkpoints?                                      : 0     [DEFAULT]
Conserve GPU memory (slower)?                              : 0     [DEFAULT]
Convert given conv layers to unshared local                :       
Cropped DP: crop border size                               : 4     [DEFAULT]
Cropped DP: logreg layer name (for --multiview-test)       :       [DEFAULT]
Cropped DP: test on multiple patches?                      : 0     [DEFAULT]
Cropped Step: crop border step                             : 1     [DEFAULT]
Data batch range: testing                                  : 46-51 
Data batch range: training                                 : 1-45  
Data path                                                  : /data/ad6813/pipe-data/Bluebox/batches/clamp_detection 
Data provider                                              : basic-leaf256 
GPU override                                               : -1    [DEFAULT]
Layer definition file                                      : /homes/ad6813/Git/pipe-classification/models/clamp_detection/solve_imbalance/clean_try/net_0_graphic06/layers.cfg 
Layer parameter file                                       : /homes/ad6813/Git/pipe-classification/models/clamp_detection/solve_imbalance/clean_try/net_0_graphic06/params.cfg 
Load file                                                  :       [DEFAULT]
Maximum save file size (MB)                                : 0     [DEFAULT]
Minibatch size                                             : 128   [DEFAULT]
Number of GPUs                                             : 1     [DEFAULT]
Number of epochs                                           : 50000 [DEFAULT]
Save path                                                  : /data/ad6813/my-nets/saves 
Test and quit?                                             : 0     [DEFAULT]
Test on more than one batch at a time?                     : -1    
Test on one batch at a time?                               : 0     
Testing frequency                                          : 17    
Unshare weight matrices in given layers                    :       
=========================
Running on CUDA device(s) -2
Current time: Fri Jun 27 20:55:36 2014
Saving checkpoints to /data/ad6813/my-nets/saves/ConvNet__2014-06-27_20.55.32
=========================
1.1... logprob:  0.708712, 0.625000 (0.655 sec)
1.2... logprob:  0.762866, 0.320312 (0.653 sec)
1.3... logprob:  0.891294, 0.679688 (0.652 sec)
1.4... logprob:  1.398528, 0.335938 (0.650 sec)
1.5... logprob:  0.748731, 0.695312 (0.649 sec)
1.6... logprob:  1.177933, 0.351562 (0.655 sec)
1.7... logprob:  1.019430, 0.695312 (0.651 sec)
1.8... logprob:  1.439982, 0.296875 (0.652 sec)
1.9... logprob:  0.679255, 0.375000 (0.652 sec)
1.10... logprob:  0.749524, 0.671875 (0.652 sec)
1.11... logprob:  1.046921, 0.335938 (0.652 sec)
1.12... logprob:  0.928022, 0.648438 (0.652 sec)
1.13... logprob:  1.194739, 0.296875 (0.652 sec)
1.14... logprob:  0.668935, 0.359375 (0.654 sec)
1.15... logprob:  0.700569, 0.343750 (0.654 sec)
1.16... logprob:  0.856264, 0.726562 (0.652 sec)
1.17... logprob:  1.290901, 0.296875 (0.651 sec)
Traceback (most recent call last):
  File "/homes/ad6813/.local/bin/ccn-train", line 9, in <module>
    load_entry_point('noccn==0.1-dev', 'console_scripts', 'ccn-train')()
  File "/homes/ad6813/.local/lib/python2.7/site-packages/noccn-0.1_dev-py2.7.egg/noccn/train.py", line 81, in console
    run_model(ConvNet, 'train')
  File "/homes/ad6813/.local/lib/python2.7/site-packages/noccn-0.1_dev-py2.7.egg/noccn/script.py", line 111, in run_model
    model.start()
  File "/homes/ad6813/.local/lib/python2.7/site-packages/noccn-0.1_dev-py2.7.egg/noccn/train.py", line 62, in start
    self.train()
  File "/homes/ad6813/Git/pipe-classification/cuda_convnet/gpumodel.py", line 157, in train
    self.test_outputs += [self.get_test_error()]
  File "/homes/ad6813/Git/pipe-classification/cuda_convnet/gpumodel.py", line 226, in get_test_error
    next_data = self.get_next_batch(train=False)
  File "/homes/ad6813/Git/pipe-classification/cuda_convnet/gpumodel.py", line 181, in get_next_batch
    return self.parse_batch_data(dp.get_next_batch(), train=train)
  File "/homes/ad6813/Git/pipe-classification/cuda_convnet/convdata.py", line 192, in get_next_batch
    self.data_dic = self.get_batch(self.curr_batchnum)
  File "/homes/ad6813/Git/pipe-classification/cuda_convnet/data.py", line 85, in get_batch
    dic = unpickle(self.get_data_file_name(batch_num))
  File "/homes/ad6813/Git/pipe-classification/cuda_convnet/util.py", line 71, in unpickle
    raise UnpickleError("Path '%s' does not exist." % filename)
util.UnpickleError: Path '/data/ad6813/pipe-data/Bluebox/batches/clamp_detection/data_batch_46' does not exist.
nohup: ignoring input
Initialized data layer 'data', producing 196608 outputs
Initialized data layer 'labels', producing 1 outputs
Initialized convolutional layer 'conv1', producing 63x63 48-channel output
Initialized max-pooling layer 'pool1', producing 31x31 48-channel output
Initialized cross-map response-normalization layer 'rnorm1', producing 31x31 48-channel output
Initialized convolutional layer 'conv2', producing 31x31 128-channel output
Initialized max-pooling layer 'pool2', producing 15x15 128-channel output
Initialized cross-map response-normalization layer 'rnorm2', producing 15x15 128-channel output
Initialized convolutional layer 'conv3', producing 15x15 192-channel output
Initialized convolutional layer 'conv4', producing 15x15 192-channel output
Initialized convolutional layer 'conv5', producing 15x15 128-channel output
Initialized max-pooling layer 'pool5', producing 7x7 128-channel output
Initialized fully-connected layer 'fc6', producing 4096 outputs
Initialized fully-connected layer 'fc7', producing 4096 outputs
Initialized fully-connected layer 'fc8', producing 2 outputs
Initialized softmax layer 'probs', producing 2 outputs
Initialized logistic regression cost 'logprob'
Initialized neuron layer 'conv1_neuron', producing 190512 outputs
Initialized neuron layer 'conv2_neuron', producing 123008 outputs
Initialized neuron layer 'conv3_neuron', producing 43200 outputs
Initialized neuron layer 'conv4_neuron', producing 43200 outputs
Initialized neuron layer 'conv5_neuron', producing 28800 outputs
Initialized neuron layer 'fc6_neuron', producing 4096 outputs
Initialized neuron layer 'fc7_neuron', producing 4096 outputs
=========================
Importing _ConvNet C++ module
=========================
Training ConvNet
Always write savepoints, regardless of test err improvement: 0     [DEFAULT]
Check gradients and quit?                                  : 0     [DEFAULT]
Compress checkpoints?                                      : 0     [DEFAULT]
Conserve GPU memory (slower)?                              : 0     [DEFAULT]
Convert given conv layers to unshared local                :       
Cropped DP: crop border size                               : 4     [DEFAULT]
Cropped DP: logreg layer name (for --multiview-test)       :       [DEFAULT]
Cropped DP: test on multiple patches?                      : 0     [DEFAULT]
Cropped Step: crop border step                             : 1     [DEFAULT]
Data batch range: testing                                  : 39-44 
Data batch range: training                                 : 1-38  
Data path                                                  : /data/ad6813/pipe-data/Bluebox/batches/clamp_detection/net_0 
Data provider                                              : basic-leaf256 
GPU override                                               : -1    [DEFAULT]
Layer definition file                                      : /homes/ad6813/Git/pipe-classification/models/clamp_detection/solve_imbalance/clean_try/net_0_graphic06/layers.cfg 
Layer parameter file                                       : /homes/ad6813/Git/pipe-classification/models/clamp_detection/solve_imbalance/clean_try/net_0_graphic06/params.cfg 
Load file                                                  :       [DEFAULT]
Maximum save file size (MB)                                : 0     [DEFAULT]
Minibatch size                                             : 128   [DEFAULT]
Number of GPUs                                             : 1     [DEFAULT]
Number of epochs                                           : 50000 [DEFAULT]
Save path                                                  : /data/ad6813/my-nets/saves 
Test and quit?                                             : 0     [DEFAULT]
Test on more than one batch at a time?                     : -1    
Test on one batch at a time?                               : 0     
Testing frequency                                          : 17    
Unshare weight matrices in given layers                    :       
=========================
Running on CUDA device(s) -2
Current time: Fri Jun 27 21:30:09 2014
Saving checkpoints to /data/ad6813/my-nets/saves/ConvNet__2014-06-27_21.30.06
=========================
1.1... logprob:  0.708712, 0.625000 (0.605 sec)
1.2... logprob:  0.762866, 0.320312 (0.601 sec)
1.3... logprob:  0.891294, 0.679688 (0.601 sec)
1.4... logprob:  1.398528, 0.335938 (0.601 sec)
1.5... logprob:  0.748731, 0.695312 (0.601 sec)
1.6... logprob:  1.177933, 0.351562 (0.601 sec)
1.7... logprob:  1.019430, 0.695312 (0.605 sec)
1.8... logprob:  1.439982, 0.296875 (0.598 sec)
1.9... logprob:  0.679255, 0.375000 (0.600 sec)
1.10... logprob:  0.749524, 0.671875 (0.598 sec)
1.11... logprob:  1.046921, 0.335938 (0.598 sec)
1.12... logprob:  0.928022, 0.648438 (0.599 sec)
1.13... logprob:  1.194739, 0.296875 (0.599 sec)
1.14... logprob:  0.668935, 0.359375 (0.601 sec)
1.15... logprob:  0.700569, 0.343750 (0.602 sec)
1.16... logprob:  0.856264, 0.726562 (0.599 sec)
1.17... logprob:  1.290901, 0.296875 (0.599 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.630720, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979723e-03 [2.743849e-09] 
Layer 'conv1' biases: 4.836119e-10 [6.923986e-11] 
Layer 'conv2' weights[0]: 7.966638e-03 [2.873931e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.411654e-10] 
Layer 'conv3' weights[0]: 7.965014e-03 [2.770811e-09] 
Layer 'conv3' biases: 1.247666e-08 [1.714542e-09] 
Layer 'conv4' weights[0]: 7.997502e-03 [3.532449e-09] 
Layer 'conv4' biases: 1.000000e+00 [1.953022e-08] 
Layer 'conv5' weights[0]: 7.996424e-03 [1.256687e-07] 
Layer 'conv5' biases: 9.999997e-01 [1.350183e-07] 
Layer 'fc6' weights[0]: 7.593267e-03 [1.561405e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.578661e-08] 
Layer 'fc7' weights[0]: 7.854269e-03 [2.487216e-07] 
Layer 'fc7' biases: 9.999999e-01 [2.430661e-07] 
Layer 'fc8' weights[0]: 4.769288e-04 [2.938361e-04] 
Layer 'fc8' biases: 4.456815e-05 [2.835289e-04] 
Train error last 38 batches: 0.956624
-------------------------------------------------------
Saved checkpoint to /data/ad6813/my-nets/saves/ConvNet__2014-06-27_21.30.06
======================================================= (4.750 sec)
1.18... logprob:  0.669307, 0.390625 (0.594 sec)
1.19... logprob:  0.649288, 0.328125 (0.599 sec)
1.20... logprob:  0.898373, 0.460938 (0.594 sec)
1.21... logprob:  1.752591, 0.734375 (0.595 sec)
1.22... logprob:  1.919558, 0.304688 (0.595 sec)
1.23... logprob:  0.697589, 0.265625 (0.593 sec)
1.24... logprob:  0.694745, 0.625000 (0.593 sec)
1.25... logprob:  0.684173, 0.304688 (0.593 sec)
1.26... logprob:  0.739283, 0.625000 (0.593 sec)
1.27... logprob:  0.963065, 0.375000 (0.594 sec)
1.28... logprob:  1.044430, 0.570312 (0.593 sec)
1.29... logprob:  1.153560, 0.312500 (0.594 sec)
1.30... logprob:  0.722515, 0.640625 (0.593 sec)
1.31... logprob:  0.807624, 0.312500 (0.593 sec)
1.32... logprob:  0.851717, 0.679688 (0.594 sec)
1.33... logprob:  1.160180, 0.304688 (0.593 sec)
1.34... logprob:  0.688766, 0.296875 (0.592 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.889533, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979717e-03 [7.737703e-10] 
Layer 'conv1' biases: 9.501309e-10 [2.291346e-11] 
Layer 'conv2' weights[0]: 7.966634e-03 [9.394400e-10] 
Layer 'conv2' biases: 1.000000e+00 [1.472328e-10] 
Layer 'conv3' weights[0]: 7.965009e-03 [1.050746e-09] 
Layer 'conv3' biases: 2.426667e-08 [5.353438e-10] 
Layer 'conv4' weights[0]: 7.997493e-03 [1.321679e-09] 
Layer 'conv4' biases: 1.000000e+00 [5.737412e-09] 
Layer 'conv5' weights[0]: 7.996426e-03 [3.314261e-08] 
Layer 'conv5' biases: 9.999990e-01 [3.428494e-08] 
Layer 'fc6' weights[0]: 7.593266e-03 [6.705589e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.826059e-09] 
Layer 'fc7' weights[0]: 7.854215e-03 [1.177228e-07] 
Layer 'fc7' biases: 9.999999e-01 [1.149081e-07] 
Layer 'fc8' weights[0]: 5.153528e-04 [2.027398e-04] 
Layer 'fc8' biases: 2.058304e-04 [1.976613e-04] 
Train error last 38 batches: 0.951746
-------------------------------------------------------
Not saving because 0.889533 > 0.630720 (1.17: -0.00%)
======================================================= (4.310 sec)
1.35... logprob:  1.053424, 0.375000 (0.593 sec)
1.36... logprob:  1.169971, 0.671875 (0.594 sec)
1.37... logprob:  1.558760, 0.320312 (0.593 sec)
1.38... logprob:  0.632916, 0.328125 (0.592 sec)
2.1... logprob:  0.664377, 0.375000 (0.593 sec)
2.2... logprob:  0.662335, 0.320312 (0.592 sec)
2.3... logprob:  0.747883, 0.320312 (0.592 sec)
2.4... logprob:  0.831411, 0.664062 (0.592 sec)
2.5... logprob:  1.072779, 0.304688 (0.592 sec)
2.6... logprob:  0.717602, 0.648438 (0.592 sec)
2.7... logprob:  0.788653, 0.304688 (0.592 sec)
2.8... logprob:  0.818611, 0.703125 (0.591 sec)
2.9... logprob:  1.408815, 0.375000 (0.592 sec)
2.10... logprob:  0.934105, 0.671875 (0.591 sec)
2.11... logprob:  1.365791, 0.335938 (0.592 sec)
2.12... logprob:  0.711242, 0.648438 (0.592 sec)
2.13... logprob:  0.751742, 0.296875 (0.592 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.771763, 0.687500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979707e-03 [1.148287e-09] 
Layer 'conv1' biases: 1.390580e-09 [2.482382e-11] 
Layer 'conv2' weights[0]: 7.966623e-03 [1.225123e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.127344e-10] 
Layer 'conv3' weights[0]: 7.965004e-03 [1.249284e-09] 
Layer 'conv3' biases: 3.568971e-08 [7.101334e-10] 
Layer 'conv4' weights[0]: 7.997487e-03 [1.601328e-09] 
Layer 'conv4' biases: 1.000000e+00 [8.127937e-09] 
Layer 'conv5' weights[0]: 7.996391e-03 [4.913615e-08] 
Layer 'conv5' biases: 9.999979e-01 [5.174083e-08] 
Layer 'fc6' weights[0]: 7.593259e-03 [7.769060e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.885861e-09] 
Layer 'fc7' weights[0]: 7.854120e-03 [1.300200e-07] 
Layer 'fc7' biases: 9.999998e-01 [1.273043e-07] 
Layer 'fc8' weights[0]: 4.724700e-04 [1.973755e-04] 
Layer 'fc8' biases: 2.035774e-05 [1.941198e-04] 
Train error last 38 batches: 0.934312
-------------------------------------------------------
Not saving because 0.771763 > 0.630720 (1.17: -0.00%)
======================================================= (4.298 sec)
2.14... logprob:  0.755746, 0.640625 (0.592 sec)
2.15... logprob:  0.956262, 0.343750 (0.592 sec)
2.16... logprob:  1.017121, 0.726562 (0.592 sec)
2.17... logprob:  1.438487, 0.296875 (0.592 sec)
2.18... logprob:  0.716537, 0.390625 (0.592 sec)
2.19... logprob:  0.874798, 0.671875 (0.592 sec)
2.20... logprob:  1.717016, 0.460938 (0.592 sec)
2.21... logprob:  1.546883, 0.734375 (0.591 sec)
2.22... logprob:  1.777627, 0.304688 (0.591 sec)
2.23... logprob:  0.654436, 0.265625 (0.591 sec)
2.24... logprob:  0.677232, 0.375000 (0.591 sec)
2.25... logprob:  0.633807, 0.304688 (0.591 sec)
2.26... logprob:  0.673533, 0.375000 (0.591 sec)
2.27... logprob:  0.708351, 0.375000 (0.592 sec)
2.28... logprob:  0.774570, 0.570312 (0.591 sec)
2.29... logprob:  0.770384, 0.312500 (0.591 sec)
2.30... logprob:  0.788486, 0.640625 (0.591 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.930808, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979702e-03 [7.787716e-10] 
Layer 'conv1' biases: 1.852359e-09 [3.277141e-11] 
Layer 'conv2' weights[0]: 7.966619e-03 [1.156874e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.987289e-10] 
Layer 'conv3' weights[0]: 7.964996e-03 [1.296066e-09] 
Layer 'conv3' biases: 4.748888e-08 [7.171776e-10] 
Layer 'conv4' weights[0]: 7.997474e-03 [1.617886e-09] 
Layer 'conv4' biases: 1.000000e+00 [7.505757e-09] 
Layer 'conv5' weights[0]: 7.996380e-03 [4.364107e-08] 
Layer 'conv5' biases: 9.999964e-01 [4.570457e-08] 
Layer 'fc6' weights[0]: 7.593246e-03 [8.779056e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.840041e-09] 
Layer 'fc7' weights[0]: 7.854018e-03 [1.512921e-07] 
Layer 'fc7' biases: 9.999997e-01 [1.484390e-07] 
Layer 'fc8' weights[0]: 5.190480e-04 [2.594758e-04] 
Layer 'fc8' biases: 2.251342e-04 [2.577447e-04] 
Train error last 38 batches: 0.944210
-------------------------------------------------------
Not saving because 0.930808 > 0.630720 (1.17: -0.00%)
======================================================= (4.301 sec)
2.31... logprob:  0.930795, 0.312500 (0.591 sec)
2.32... logprob:  0.794830, 0.679688 (0.592 sec)
2.33... logprob:  1.012476, 0.304688 (0.592 sec)
2.34... logprob:  0.729068, 0.703125 (0.592 sec)
2.35... logprob:  1.143727, 0.375000 (0.591 sec)
2.36... logprob:  1.055752, 0.671875 (0.592 sec)
2.37... logprob:  1.391430, 0.320312 (0.595 sec)
2.38... logprob:  0.641413, 0.328125 (0.592 sec)
3.1... logprob:  0.718276, 0.375000 (0.597 sec)
3.2... logprob:  0.858642, 0.679688 (0.596 sec)
3.3... logprob:  1.165797, 0.320312 (0.597 sec)
3.4... logprob:  0.712996, 0.664062 (0.596 sec)
3.5... logprob:  0.793511, 0.304688 (0.596 sec)
3.6... logprob:  0.764570, 0.648438 (0.595 sec)
3.7... logprob:  0.868525, 0.304688 (0.596 sec)
3.8... logprob:  0.775222, 0.703125 (0.595 sec)
3.9... logprob:  1.250205, 0.375000 (0.596 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.986879, 0.687500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979691e-03 [2.141903e-09] 
Layer 'conv1' biases: 2.276930e-09 [5.949007e-11] 
Layer 'conv2' weights[0]: 7.966612e-03 [2.644448e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.856267e-10] 
Layer 'conv3' weights[0]: 7.964990e-03 [2.581782e-09] 
Layer 'conv3' biases: 5.839265e-08 [1.579201e-09] 
Layer 'conv4' weights[0]: 7.997469e-03 [3.335741e-09] 
Layer 'conv4' biases: 1.000000e+00 [1.786081e-08] 
Layer 'conv5' weights[0]: 7.996369e-03 [1.111554e-07] 
Layer 'conv5' biases: 9.999955e-01 [1.187329e-07] 
Layer 'fc6' weights[0]: 7.593245e-03 [1.564975e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.585033e-08] 
Layer 'fc7' weights[0]: 7.853958e-03 [2.559369e-07] 
Layer 'fc7' biases: 9.999995e-01 [2.506960e-07] 
Layer 'fc8' weights[0]: 4.739863e-04 [3.364446e-04] 
Layer 'fc8' biases: 7.292928e-05 [3.369659e-04] 
Train error last 38 batches: 0.943458
-------------------------------------------------------
Not saving because 0.986879 > 0.630720 (1.17: -0.00%)
======================================================= (4.341 sec)
3.10... logprob:  0.971772, 0.671875 (0.595 sec)
3.11... logprob:  1.348262, 0.335938 (0.595 sec)
3.12... logprob:  0.690402, 0.351562 (0.596 sec)
3.13... logprob:  0.687137, 0.296875 (0.596 sec)
3.14... logprob:  0.711596, 0.640625 (0.596 sec)
3.15... logprob:  0.811740, 0.343750 (0.596 sec)
3.16... logprob:  0.941687, 0.726562 (0.595 sec)
3.17... logprob:  1.291252, 0.296875 (0.595 sec)
3.18... logprob:  0.683674, 0.390625 (0.596 sec)
3.19... logprob:  0.731261, 0.671875 (0.596 sec)
3.20... logprob:  1.238385, 0.460938 (0.595 sec)
3.21... logprob:  1.743899, 0.734375 (0.596 sec)
3.22... logprob:  1.707119, 0.304688 (0.595 sec)
3.23... logprob:  0.644306, 0.265625 (0.596 sec)
3.24... logprob:  0.669907, 0.375000 (0.596 sec)
3.25... logprob:  0.618829, 0.304688 (0.595 sec)
3.26... logprob:  0.661613, 0.375000 (0.595 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.632248, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979687e-03 [5.799087e-10] 
Layer 'conv1' biases: 2.704250e-09 [5.846227e-12] 
Layer 'conv2' weights[0]: 7.966607e-03 [4.793014e-10] 
Layer 'conv2' biases: 1.000000e+00 [2.070814e-11] 
Layer 'conv3' weights[0]: 7.964984e-03 [4.355807e-10] 
Layer 'conv3' biases: 6.939963e-08 [5.686286e-11] 
Layer 'conv4' weights[0]: 7.997459e-03 [4.408591e-10] 
Layer 'conv4' biases: 1.000000e+00 [1.693339e-10] 
Layer 'conv5' weights[0]: 7.996348e-03 [9.994482e-10] 
Layer 'conv5' biases: 9.999949e-01 [8.830902e-10] 
Layer 'fc6' weights[0]: 7.593237e-03 [4.187894e-10] 
Layer 'fc6' biases: 1.000000e+00 [1.711934e-10] 
Layer 'fc7' weights[0]: 7.853858e-03 [5.201558e-09] 
Layer 'fc7' biases: 9.999993e-01 [2.807265e-09] 
Layer 'fc8' weights[0]: 4.676961e-04 [4.881331e-06] 
Layer 'fc8' biases: 4.226580e-05 [4.945977e-06] 
Train error last 38 batches: 0.915839
-------------------------------------------------------
Not saving because 0.632248 > 0.630720 (1.17: -0.00%)
======================================================= (4.443 sec)
3.27... logprob:  0.661739, 0.375000 (0.595 sec)
3.28... logprob:  0.694106, 0.429688 (0.595 sec)
3.29... logprob:  0.757811, 0.687500 (0.595 sec)
3.30... logprob:  1.086921, 0.359375 (0.595 sec)
3.31... logprob:  0.941881, 0.687500 (0.596 sec)
3.32... logprob:  1.261579, 0.320312 (0.596 sec)
3.33... logprob:  0.654951, 0.304688 (0.596 sec)
3.34... logprob:  0.704322, 0.296875 (0.595 sec)
3.35... logprob:  0.710408, 0.625000 (0.597 sec)
3.36... logprob:  0.736740, 0.328125 (0.595 sec)
3.37... logprob:  0.795387, 0.679688 (0.595 sec)
3.38... logprob:  1.043820, 0.328125 (0.598 sec)
4.1... logprob:  0.758021, 0.625000 (0.597 sec)
4.2... logprob:  0.822542, 0.320312 (0.596 sec)
4.3... logprob:  0.803609, 0.679688 (0.596 sec)
4.4... logprob:  1.079137, 0.335938 (0.596 sec)
4.5... logprob:  0.802934, 0.695312 (0.596 sec)
=========================
Testing all batches

======================Test output======================
logprob:  1.042561, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979678e-03 [8.808121e-10] 
Layer 'conv1' biases: 2.997083e-09 [3.678594e-11] 
Layer 'conv2' weights[0]: 7.966600e-03 [1.406305e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.396189e-10] 
Layer 'conv3' weights[0]: 7.964974e-03 [1.487300e-09] 
Layer 'conv3' biases: 7.699661e-08 [8.263805e-10] 
Layer 'conv4' weights[0]: 7.997450e-03 [1.866557e-09] 
Layer 'conv4' biases: 1.000000e+00 [8.604340e-09] 
Layer 'conv5' weights[0]: 7.996369e-03 [4.998864e-08] 
Layer 'conv5' biases: 9.999943e-01 [5.231815e-08] 
Layer 'fc6' weights[0]: 7.593230e-03 [1.001696e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.012898e-08] 
Layer 'fc7' weights[0]: 7.853785e-03 [1.734070e-07] 
Layer 'fc7' biases: 9.999991e-01 [1.702950e-07] 
Layer 'fc8' weights[0]: 5.332163e-04 [2.977253e-04] 
Layer 'fc8' biases: 2.703345e-04 [3.034471e-04] 
Train error last 38 batches: 0.898086
-------------------------------------------------------
Not saving because 1.042561 > 0.630720 (1.17: -0.00%)
======================================================= (4.332 sec)
4.6... logprob:  1.167950, 0.351562 (0.595 sec)
4.7... logprob:  0.837920, 0.695312 (0.596 sec)
4.8... logprob:  1.042409, 0.296875 (0.595 sec)
4.9... logprob:  0.671107, 0.375000 (0.596 sec)
4.10... logprob:  0.644163, 0.328125 (0.596 sec)
4.11... logprob:  0.661625, 0.335938 (0.596 sec)
4.12... logprob:  0.728892, 0.351562 (0.596 sec)
4.13... logprob:  0.833476, 0.703125 (0.596 sec)
4.14... logprob:  1.266129, 0.359375 (0.596 sec)
4.15... logprob:  0.798331, 0.656250 (0.595 sec)
4.16... logprob:  0.823852, 0.273438 (0.595 sec)
4.17... logprob:  0.653975, 0.296875 (0.596 sec)
4.18... logprob:  0.902295, 0.390625 (0.596 sec)
4.19... logprob:  1.079733, 0.671875 (0.596 sec)
4.20... logprob:  1.886861, 0.460938 (0.595 sec)
4.21... logprob:  1.149350, 0.734375 (0.596 sec)
4.22... logprob:  1.455795, 0.304688 (0.595 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.642891, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979674e-03 [2.678094e-09] 
Layer 'conv1' biases: 3.451981e-09 [6.911432e-11] 
Layer 'conv2' weights[0]: 7.966595e-03 [2.948079e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.678265e-10] 
Layer 'conv3' weights[0]: 7.964967e-03 [2.893055e-09] 
Layer 'conv3' biases: 8.877237e-08 [1.846779e-09] 
Layer 'conv4' weights[0]: 7.997442e-03 [3.627654e-09] 
Layer 'conv4' biases: 9.999999e-01 [2.054203e-08] 
Layer 'conv5' weights[0]: 7.996394e-03 [1.310003e-07] 
Layer 'conv5' biases: 9.999931e-01 [1.409693e-07] 
Layer 'fc6' weights[0]: 7.593212e-03 [1.721762e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.739260e-08] 
Layer 'fc7' weights[0]: 7.853712e-03 [2.786917e-07] 
Layer 'fc7' biases: 9.999987e-01 [2.738205e-07] 
Layer 'fc8' weights[0]: 4.740162e-04 [2.877942e-04] 
Layer 'fc8' biases: 1.094617e-04 [2.961091e-04] 
Train error last 38 batches: 0.881959
-------------------------------------------------------
Not saving because 0.642891 > 0.630720 (1.17: -0.00%)
======================================================= (4.326 sec)
4.23... logprob:  0.584114, 0.265625 (0.596 sec)
4.24... logprob:  0.667635, 0.375000 (0.595 sec)
4.25... logprob:  0.670396, 0.304688 (0.595 sec)
4.26... logprob:  0.890126, 0.375000 (0.595 sec)
4.27... logprob:  0.944576, 0.625000 (0.596 sec)
4.28... logprob:  1.415996, 0.429688 (0.595 sec)
4.29... logprob:  1.172231, 0.687500 (0.595 sec)
4.30... logprob:  1.560651, 0.359375 (0.595 sec)
4.31... logprob:  0.652376, 0.312500 (0.595 sec)
4.32... logprob:  0.709532, 0.320312 (0.595 sec)
4.33... logprob:  0.742378, 0.695312 (0.595 sec)
4.34... logprob:  0.864242, 0.296875 (0.595 sec)
4.35... logprob:  0.696048, 0.625000 (0.595 sec)
4.36... logprob:  0.692789, 0.328125 (0.596 sec)
4.37... logprob:  0.731183, 0.679688 (0.596 sec)
4.38... logprob:  0.884046, 0.328125 (0.596 sec)
5.1... logprob:  0.771341, 0.625000 (0.596 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.804614, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979663e-03 [7.696521e-10] 
Layer 'conv1' biases: 3.758144e-09 [2.909755e-11] 
Layer 'conv2' weights[0]: 7.966589e-03 [1.105773e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.876467e-10] 
Layer 'conv3' weights[0]: 7.964962e-03 [1.189828e-09] 
Layer 'conv3' biases: 9.665309e-08 [6.289296e-10] 
Layer 'conv4' weights[0]: 7.997436e-03 [1.457911e-09] 
Layer 'conv4' biases: 9.999999e-01 [6.510347e-09] 
Layer 'conv5' weights[0]: 7.996390e-03 [3.770269e-08] 
Layer 'conv5' biases: 9.999927e-01 [3.943832e-08] 
Layer 'fc6' weights[0]: 7.593208e-03 [7.500511e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.621709e-09] 
Layer 'fc7' weights[0]: 7.853630e-03 [1.305878e-07] 
Layer 'fc7' biases: 9.999985e-01 [1.281250e-07] 
Layer 'fc8' weights[0]: 4.979288e-04 [2.238532e-04] 
Layer 'fc8' biases: 1.973229e-04 [2.324231e-04] 
Train error last 38 batches: 0.914783
-------------------------------------------------------
Not saving because 0.804614 > 0.630720 (1.17: -0.00%)
======================================================= (4.341 sec)
5.2... logprob:  0.822235, 0.320312 (0.596 sec)
5.3... logprob:  0.772685, 0.679688 (0.596 sec)
5.4... logprob:  0.982968, 0.335938 (0.596 sec)
5.5... logprob:  0.804089, 0.695312 (0.596 sec)
5.6... logprob:  1.124572, 0.351562 (0.595 sec)
5.7... logprob:  0.813769, 0.695312 (0.596 sec)
5.8... logprob:  0.968084, 0.296875 (0.596 sec)
5.9... logprob:  0.674128, 0.375000 (0.596 sec)
5.10... logprob:  0.647281, 0.328125 (0.596 sec)
5.11... logprob:  0.663714, 0.335938 (0.596 sec)
5.12... logprob:  0.726340, 0.351562 (0.596 sec)
5.13... logprob:  0.804089, 0.703125 (0.595 sec)
5.14... logprob:  1.164471, 0.359375 (0.596 sec)
5.15... logprob:  0.807164, 0.656250 (0.595 sec)
5.16... logprob:  0.807464, 0.273438 (0.595 sec)
5.17... logprob:  0.643667, 0.296875 (0.596 sec)
5.18... logprob:  0.849657, 0.390625 (0.596 sec)
=========================
Testing all batches

======================Test output======================
logprob:  1.014104, 0.687500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979657e-03 [1.196840e-09] 
Layer 'conv1' biases: 4.038689e-09 [2.921627e-11] 
Layer 'conv2' weights[0]: 7.966582e-03 [1.286331e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.325092e-10] 
Layer 'conv3' weights[0]: 7.964953e-03 [1.334986e-09] 
Layer 'conv3' biases: 1.039710e-07 [7.906606e-10] 
Layer 'conv4' weights[0]: 7.997424e-03 [1.698857e-09] 
Layer 'conv4' biases: 9.999999e-01 [8.912203e-09] 
Layer 'conv5' weights[0]: 7.996390e-03 [5.216712e-08] 
Layer 'conv5' biases: 9.999923e-01 [5.436910e-08] 
Layer 'fc6' weights[0]: 7.593201e-03 [8.960737e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.081127e-09] 
Layer 'fc7' weights[0]: 7.853530e-03 [1.514863e-07] 
Layer 'fc7' biases: 9.999983e-01 [1.490766e-07] 
Layer 'fc8' weights[0]: 4.677471e-04 [2.349180e-04] 
Layer 'fc8' biases: 8.790306e-05 [2.455822e-04] 
Train error last 38 batches: 0.902573
-------------------------------------------------------
Not saving because 1.014104 > 0.630720 (1.17: -0.00%)
======================================================= (4.336 sec)
5.19... logprob:  0.997981, 0.671875 (0.595 sec)
5.20... logprob:  1.702152, 0.460938 (0.595 sec)
5.21... logprob:  1.208380, 0.734375 (0.597 sec)
5.22... logprob:  1.419332, 0.304688 (0.595 sec)
5.23... logprob:  0.585294, 0.265625 (0.596 sec)
5.24... logprob:  0.667418, 0.375000 (0.598 sec)
5.25... logprob:  0.665573, 0.304688 (0.595 sec)
5.26... logprob:  0.857099, 0.375000 (0.595 sec)
5.27... logprob:  0.894279, 0.625000 (0.596 sec)
5.28... logprob:  1.281789, 0.429688 (0.595 sec)
5.29... logprob:  1.171085, 0.687500 (0.595 sec)
5.30... logprob:  1.484507, 0.359375 (0.595 sec)
5.31... logprob:  0.655966, 0.312500 (0.595 sec)
5.32... logprob:  0.708800, 0.320312 (0.595 sec)
5.33... logprob:  0.724193, 0.695312 (0.595 sec)
5.34... logprob:  0.808840, 0.296875 (0.595 sec)
5.35... logprob:  0.690924, 0.375000 (0.595 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.653816, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979648e-03 [5.743613e-10] 
Layer 'conv1' biases: 4.459126e-09 [1.443870e-11] 
Layer 'conv2' weights[0]: 7.966574e-03 [6.776514e-10] 
Layer 'conv2' biases: 1.000000e+00 [9.048033e-11] 
Layer 'conv3' weights[0]: 7.964941e-03 [7.299835e-10] 
Layer 'conv3' biases: 1.148630e-07 [3.233910e-10] 
Layer 'conv4' weights[0]: 7.997423e-03 [8.719863e-10] 
Layer 'conv4' biases: 9.999998e-01 [3.310958e-09] 
Layer 'conv5' weights[0]: 7.996414e-03 [1.883335e-08] 
Layer 'conv5' biases: 9.999915e-01 [1.941292e-08] 
Layer 'fc6' weights[0]: 7.593198e-03 [3.790573e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.832583e-09] 
Layer 'fc7' weights[0]: 7.853434e-03 [6.604535e-08] 
Layer 'fc7' biases: 9.999979e-01 [6.466878e-08] 
Layer 'fc8' weights[0]: 4.723386e-04 [1.139457e-04] 
Layer 'fc8' biases: 1.238239e-04 [1.204993e-04] 
Train error last 38 batches: 0.886299
-------------------------------------------------------
Not saving because 0.653816 > 0.630720 (1.17: -0.00%)
======================================================= (4.337 sec)
5.36... logprob:  0.675111, 0.328125 (0.595 sec)
5.37... logprob:  0.697863, 0.679688 (0.595 sec)
5.38... logprob:  0.794096, 0.328125 (0.596 sec)
6.1... logprob:  0.749832, 0.625000 (0.597 sec)
6.2... logprob:  0.765588, 0.320312 (0.596 sec)
6.3... logprob:  0.743372, 0.679688 (0.596 sec)
6.4... logprob:  0.899373, 0.335938 (0.597 sec)
6.5... logprob:  0.793987, 0.695312 (0.596 sec)
6.6... logprob:  1.068206, 0.351562 (0.595 sec)
6.7... logprob:  0.801230, 0.695312 (0.596 sec)
6.8... logprob:  0.918238, 0.296875 (0.596 sec)
6.9... logprob:  0.673556, 0.375000 (0.597 sec)
6.10... logprob:  0.643986, 0.328125 (0.596 sec)
6.11... logprob:  0.655359, 0.335938 (0.596 sec)
6.12... logprob:  0.697458, 0.351562 (0.597 sec)
6.13... logprob:  0.742940, 0.703125 (0.597 sec)
6.14... logprob:  1.013435, 0.359375 (0.596 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.850246, 0.687500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979640e-03 [1.623874e-09] 
Layer 'conv1' biases: 4.669505e-09 [4.141637e-11] 
Layer 'conv2' weights[0]: 7.966568e-03 [1.886395e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.474782e-10] 
Layer 'conv3' weights[0]: 7.964930e-03 [1.914345e-09] 
Layer 'conv3' biases: 1.204539e-07 [1.141740e-09] 
Layer 'conv4' weights[0]: 7.997415e-03 [2.420720e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.268642e-08] 
Layer 'conv5' weights[0]: 7.996411e-03 [7.644695e-08] 
Layer 'conv5' biases: 9.999912e-01 [8.093258e-08] 
Layer 'fc6' weights[0]: 7.593197e-03 [1.195845e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.219994e-08] 
Layer 'fc7' weights[0]: 7.853356e-03 [2.012336e-07] 
Layer 'fc7' biases: 9.999976e-01 [1.974763e-07] 
Layer 'fc8' weights[0]: 4.597064e-04 [2.746571e-04] 
Layer 'fc8' biases: 5.278405e-05 [2.918621e-04] 
Train error last 38 batches: 0.867505
-------------------------------------------------------
Not saving because 0.850246 > 0.630720 (1.17: -0.00%)
======================================================= (4.337 sec)
6.15... logprob:  0.831467, 0.656250 (0.595 sec)
6.16... logprob:  0.810103, 0.273438 (0.595 sec)
6.17... logprob:  0.632832, 0.296875 (0.596 sec)
6.18... logprob:  0.801626, 0.390625 (0.596 sec)
6.19... logprob:  0.920848, 0.671875 (0.596 sec)
6.20... logprob:  1.525801, 0.460938 (0.595 sec)
6.21... logprob:  1.259382, 0.734375 (0.595 sec)
6.22... logprob:  1.379073, 0.304688 (0.595 sec)
6.23... logprob:  0.585164, 0.265625 (0.595 sec)
6.24... logprob:  0.668573, 0.375000 (0.595 sec)
6.25... logprob:  0.666999, 0.304688 (0.595 sec)
6.26... logprob:  0.845561, 0.375000 (0.596 sec)
6.27... logprob:  0.859163, 0.625000 (0.598 sec)
6.28... logprob:  1.180111, 0.429688 (0.595 sec)
6.29... logprob:  1.147716, 0.687500 (0.601 sec)
6.30... logprob:  1.406443, 0.359375 (0.600 sec)
6.31... logprob:  0.662543, 0.312500 (0.601 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.700532, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979634e-03 [5.878850e-10] 
Layer 'conv1' biases: 5.059599e-09 [1.799969e-11] 
Layer 'conv2' weights[0]: 7.966561e-03 [7.638179e-10] 
Layer 'conv2' biases: 1.000000e+00 [1.081928e-10] 
Layer 'conv3' weights[0]: 7.964924e-03 [8.186083e-10] 
Layer 'conv3' biases: 1.306058e-07 [3.692165e-10] 
Layer 'conv4' weights[0]: 7.997411e-03 [9.999096e-10] 
Layer 'conv4' biases: 9.999998e-01 [3.872752e-09] 
Layer 'conv5' weights[0]: 7.996382e-03 [2.201539e-08] 
Layer 'conv5' biases: 9.999902e-01 [2.262718e-08] 
Layer 'fc6' weights[0]: 7.593182e-03 [4.385317e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.419328e-09] 
Layer 'fc7' weights[0]: 7.853303e-03 [7.590132e-08] 
Layer 'fc7' biases: 9.999971e-01 [7.456681e-08] 
Layer 'fc8' weights[0]: 4.784453e-04 [1.312040e-04] 
Layer 'fc8' biases: 1.591938e-04 [1.410813e-04] 
Train error last 38 batches: 0.853942
-------------------------------------------------------
Not saving because 0.700532 > 0.630720 (1.17: -0.00%)
======================================================= (4.385 sec)
6.32... logprob:  0.713888, 0.320312 (0.601 sec)
6.33... logprob:  0.712713, 0.695312 (0.600 sec)
6.34... logprob:  0.771713, 0.296875 (0.600 sec)
6.35... logprob:  0.684241, 0.375000 (0.601 sec)
6.36... logprob:  0.658637, 0.328125 (0.601 sec)
6.37... logprob:  0.669917, 0.320312 (0.600 sec)
6.38... logprob:  0.724453, 0.328125 (0.601 sec)
7.1... logprob:  0.717684, 0.625000 (0.602 sec)
7.2... logprob:  0.700837, 0.320312 (0.601 sec)
7.3... logprob:  0.703176, 0.679688 (0.601 sec)
7.4... logprob:  0.803962, 0.335938 (0.602 sec)
7.5... logprob:  0.772244, 0.695312 (0.601 sec)
7.6... logprob:  1.000768, 0.351562 (0.601 sec)
7.7... logprob:  0.795896, 0.695312 (0.601 sec)
7.8... logprob:  0.884666, 0.296875 (0.601 sec)
7.9... logprob:  0.671470, 0.375000 (0.601 sec)
7.10... logprob:  0.639492, 0.328125 (0.601 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.637612, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979628e-03 [5.589315e-10] 
Layer 'conv1' biases: 5.214626e-09 [5.401498e-12] 
Layer 'conv2' weights[0]: 7.966553e-03 [5.140230e-10] 
Layer 'conv2' biases: 1.000000e+00 [4.922411e-11] 
Layer 'conv3' weights[0]: 7.964917e-03 [4.975038e-10] 
Layer 'conv3' biases: 1.348184e-07 [1.638816e-10] 
Layer 'conv4' weights[0]: 7.997402e-03 [5.371632e-10] 
Layer 'conv4' biases: 9.999998e-01 [1.574397e-09] 
Layer 'conv5' weights[0]: 7.996373e-03 [8.948752e-09] 
Layer 'conv5' biases: 9.999899e-01 [9.257810e-09] 
Layer 'fc6' weights[0]: 7.593180e-03 [1.734129e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.715317e-09] 
Layer 'fc7' weights[0]: 7.853229e-03 [2.988106e-08] 
Layer 'fc7' biases: 9.999968e-01 [2.868248e-08] 
Layer 'fc8' weights[0]: 4.556830e-04 [4.862910e-05] 
Layer 'fc8' biases: 3.858789e-05 [5.252301e-05] 
Train error last 38 batches: 0.839957
-------------------------------------------------------
Not saving because 0.637612 > 0.630720 (1.17: -0.00%)
======================================================= (4.387 sec)
7.11... logprob:  0.647090, 0.335938 (0.601 sec)
7.12... logprob:  0.673268, 0.351562 (0.601 sec)
7.13... logprob:  0.689451, 0.296875 (0.601 sec)
7.14... logprob:  0.880708, 0.359375 (0.601 sec)
7.15... logprob:  0.824400, 0.656250 (0.601 sec)
7.16... logprob:  0.780652, 0.273438 (0.600 sec)
7.17... logprob:  0.630123, 0.296875 (0.601 sec)
7.18... logprob:  0.784962, 0.390625 (0.601 sec)
7.19... logprob:  0.877742, 0.671875 (0.601 sec)
7.20... logprob:  1.406008, 0.460938 (0.600 sec)
7.21... logprob:  1.265167, 0.734375 (0.601 sec)
7.22... logprob:  1.326476, 0.304688 (0.600 sec)
7.23... logprob:  0.582803, 0.265625 (0.600 sec)
7.24... logprob:  0.672463, 0.375000 (0.600 sec)
7.25... logprob:  0.676822, 0.304688 (0.600 sec)
7.26... logprob:  0.855794, 0.375000 (0.601 sec)
7.27... logprob:  0.836756, 0.625000 (0.601 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.830242, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979621e-03 [8.116856e-10] 
Layer 'conv1' biases: 5.480945e-09 [3.889450e-11] 
Layer 'conv2' weights[0]: 7.966545e-03 [1.441422e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.500598e-10] 
Layer 'conv3' weights[0]: 7.964907e-03 [1.457081e-09] 
Layer 'conv3' biases: 1.417106e-07 [7.994105e-10] 
Layer 'conv4' weights[0]: 7.997399e-03 [1.770746e-09] 
Layer 'conv4' biases: 9.999998e-01 [8.152279e-09] 
Layer 'conv5' weights[0]: 7.996352e-03 [4.676698e-08] 
Layer 'conv5' biases: 9.999895e-01 [4.876848e-08] 
Layer 'fc6' weights[0]: 7.593179e-03 [9.180067e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.266188e-09] 
Layer 'fc7' weights[0]: 7.853127e-03 [1.576104e-07] 
Layer 'fc7' biases: 9.999964e-01 [1.551689e-07] 
Layer 'fc8' weights[0]: 4.980009e-04 [2.666661e-04] 
Layer 'fc8' biases: 2.253258e-04 [2.901995e-04] 
Train error last 38 batches: 0.827191
-------------------------------------------------------
Not saving because 0.830242 > 0.630720 (1.17: -0.00%)
======================================================= (4.365 sec)
7.28... logprob:  1.108113, 0.429688 (0.600 sec)
7.29... logprob:  1.113082, 0.687500 (0.601 sec)
7.30... logprob:  1.332511, 0.359375 (0.601 sec)
7.31... logprob:  0.670305, 0.312500 (0.601 sec)
7.32... logprob:  0.720070, 0.320312 (0.601 sec)
7.33... logprob:  0.703336, 0.695312 (0.600 sec)
7.34... logprob:  0.743286, 0.296875 (0.600 sec)
7.35... logprob:  0.678332, 0.375000 (0.600 sec)
7.36... logprob:  0.647074, 0.328125 (0.601 sec)
7.37... logprob:  0.650811, 0.320312 (0.600 sec)
7.38... logprob:  0.680331, 0.328125 (0.601 sec)
8.1... logprob:  0.688694, 0.375000 (0.602 sec)
8.2... logprob:  0.651804, 0.320312 (0.601 sec)
8.3... logprob:  0.657727, 0.320312 (0.601 sec)
8.4... logprob:  0.705045, 0.335938 (0.601 sec)
8.5... logprob:  0.714001, 0.695312 (0.601 sec)
8.6... logprob:  0.877781, 0.351562 (0.601 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.795196, 0.687500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979612e-03 [1.237602e-09] 
Layer 'conv1' biases: 5.672813e-09 [3.091958e-11] 
Layer 'conv2' weights[0]: 7.966540e-03 [1.449760e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.696441e-10] 
Layer 'conv3' weights[0]: 7.964897e-03 [1.495269e-09] 
Layer 'conv3' biases: 1.467931e-07 [8.770575e-10] 
Layer 'conv4' weights[0]: 7.997388e-03 [1.873464e-09] 
Layer 'conv4' biases: 9.999998e-01 [9.720490e-09] 
Layer 'conv5' weights[0]: 7.996331e-03 [5.703059e-08] 
Layer 'conv5' biases: 9.999890e-01 [5.971199e-08] 
Layer 'fc6' weights[0]: 7.593172e-03 [9.584173e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.671666e-09] 
Layer 'fc7' weights[0]: 7.853056e-03 [1.610536e-07] 
Layer 'fc7' biases: 9.999962e-01 [1.584184e-07] 
Layer 'fc8' weights[0]: 4.534987e-04 [2.299088e-04] 
Layer 'fc8' biases: 4.078159e-05 [2.515534e-04] 
Train error last 38 batches: 0.809066
-------------------------------------------------------
Not saving because 0.795196 > 0.630720 (1.17: -0.00%)
======================================================= (4.381 sec)
8.7... logprob:  0.798515, 0.695312 (0.604 sec)
8.8... logprob:  0.865850, 0.296875 (0.603 sec)
8.9... logprob:  0.668775, 0.375000 (0.609 sec)
8.10... logprob:  0.635691, 0.328125 (0.602 sec)
8.11... logprob:  0.641340, 0.335938 (0.603 sec)
8.12... logprob:  0.657986, 0.351562 (0.603 sec)
8.13... logprob:  0.651191, 0.296875 (0.602 sec)
8.14... logprob:  0.783965, 0.359375 (0.602 sec)
8.15... logprob:  0.785076, 0.656250 (0.602 sec)
8.16... logprob:  0.724426, 0.273438 (0.602 sec)
8.17... logprob:  0.630878, 0.296875 (0.601 sec)
8.18... logprob:  0.781079, 0.390625 (0.601 sec)
8.19... logprob:  0.853561, 0.671875 (0.601 sec)
8.20... logprob:  1.326176, 0.460938 (0.600 sec)
8.21... logprob:  1.248344, 0.734375 (0.601 sec)
8.22... logprob:  1.274760, 0.304688 (0.600 sec)
8.23... logprob:  0.580669, 0.265625 (0.600 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.622110, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979607e-03 [5.126193e-10] 
Layer 'conv1' biases: 5.904010e-09 [5.024321e-12] 
Layer 'conv2' weights[0]: 7.966534e-03 [4.564678e-10] 
Layer 'conv2' biases: 1.000000e+00 [2.746211e-11] 
Layer 'conv3' weights[0]: 7.964891e-03 [4.329265e-10] 
Layer 'conv3' biases: 1.528171e-07 [8.931609e-11] 
Layer 'conv4' weights[0]: 7.997383e-03 [4.486490e-10] 
Layer 'conv4' biases: 9.999998e-01 [8.182853e-10] 
Layer 'conv5' weights[0]: 7.996311e-03 [4.624235e-09] 
Layer 'conv5' biases: 9.999887e-01 [4.767760e-09] 
Layer 'fc6' weights[0]: 7.593165e-03 [9.406397e-10] 
Layer 'fc6' biases: 1.000000e+00 [8.571224e-10] 
Layer 'fc7' weights[0]: 7.852997e-03 [1.567462e-08] 
Layer 'fc7' biases: 9.999958e-01 [1.428346e-08] 
Layer 'fc8' weights[0]: 4.575902e-04 [2.367640e-05] 
Layer 'fc8' biases: 8.592011e-05 [2.610816e-05] 
Train error last 38 batches: 0.797169
-------------------------------------------------------
Saved checkpoint to /data/ad6813/my-nets/saves/ConvNet__2014-06-27_21.30.06
======================================================= (4.863 sec)
8.24... logprob:  0.677557, 0.375000 (0.599 sec)
8.25... logprob:  0.687005, 0.304688 (0.599 sec)
8.26... logprob:  0.865206, 0.375000 (0.599 sec)
8.27... logprob:  0.817844, 0.625000 (0.599 sec)
8.28... logprob:  1.050105, 0.429688 (0.599 sec)
8.29... logprob:  1.078310, 0.687500 (0.599 sec)
8.30... logprob:  1.268015, 0.359375 (0.599 sec)
8.31... logprob:  0.677374, 0.312500 (0.598 sec)
8.32... logprob:  0.724249, 0.320312 (0.599 sec)
8.33... logprob:  0.694773, 0.695312 (0.599 sec)
8.34... logprob:  0.720422, 0.296875 (0.598 sec)
8.35... logprob:  0.673603, 0.375000 (0.599 sec)
8.36... logprob:  0.639842, 0.328125 (0.599 sec)
8.37... logprob:  0.639089, 0.320312 (0.599 sec)
8.38... logprob:  0.655615, 0.328125 (0.599 sec)
9.1... logprob:  0.670964, 0.375000 (0.600 sec)
9.2... logprob:  0.629991, 0.320312 (0.599 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.626647, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979600e-03 [5.446757e-10] 
Layer 'conv1' biases: 6.072896e-09 [4.795300e-12] 
Layer 'conv2' weights[0]: 7.966527e-03 [5.125938e-10] 
Layer 'conv2' biases: 1.000000e+00 [3.973686e-11] 
Layer 'conv3' weights[0]: 7.964884e-03 [4.702340e-10] 
Layer 'conv3' biases: 1.572462e-07 [1.201241e-10] 
Layer 'conv4' weights[0]: 7.997369e-03 [4.923178e-10] 
Layer 'conv4' biases: 9.999998e-01 [1.039592e-09] 
Layer 'conv5' weights[0]: 7.996298e-03 [5.789787e-09] 
Layer 'conv5' biases: 9.999887e-01 [5.965563e-09] 
Layer 'fc6' weights[0]: 7.593157e-03 [1.181465e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.110566e-09] 
Layer 'fc7' weights[0]: 7.852952e-03 [1.973959e-08] 
Layer 'fc7' biases: 9.999956e-01 [1.856394e-08] 
Layer 'fc8' weights[0]: 4.527337e-04 [3.144276e-05] 
Layer 'fc8' biases: 5.476137e-05 [3.485256e-05] 
Train error last 38 batches: 0.790337
-------------------------------------------------------
Not saving because 0.626647 > 0.622110 (8.23: -1.37%)
======================================================= (4.390 sec)
9.3... logprob:  0.631055, 0.320312 (0.599 sec)
9.4... logprob:  0.648783, 0.335938 (0.599 sec)
9.5... logprob:  0.642727, 0.304688 (0.599 sec)
9.6... logprob:  0.726929, 0.351562 (0.599 sec)
9.7... logprob:  0.740042, 0.695312 (0.599 sec)
9.8... logprob:  0.779256, 0.296875 (0.599 sec)
9.9... logprob:  0.672141, 0.375000 (0.599 sec)
9.10... logprob:  0.638235, 0.328125 (0.599 sec)
9.11... logprob:  0.643876, 0.335938 (0.599 sec)
9.12... logprob:  0.662952, 0.351562 (0.599 sec)
9.13... logprob:  0.659667, 0.296875 (0.599 sec)
9.14... logprob:  0.794181, 0.359375 (0.599 sec)
9.15... logprob:  0.774677, 0.656250 (0.599 sec)
9.16... logprob:  0.702283, 0.273438 (0.599 sec)
9.17... logprob:  0.627705, 0.296875 (0.599 sec)
9.18... logprob:  0.766851, 0.390625 (0.599 sec)
9.19... logprob:  0.824121, 0.671875 (0.599 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.868673, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979594e-03 [9.240636e-10] 
Layer 'conv1' biases: 6.161225e-09 [4.009416e-11] 
Layer 'conv2' weights[0]: 7.966518e-03 [1.513721e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.659457e-10] 
Layer 'conv3' weights[0]: 7.964876e-03 [1.488564e-09] 
Layer 'conv3' biases: 1.596424e-07 [8.299739e-10] 
Layer 'conv4' weights[0]: 7.997362e-03 [1.808733e-09] 
Layer 'conv4' biases: 9.999998e-01 [8.466129e-09] 
Layer 'conv5' weights[0]: 7.996307e-03 [4.803306e-08] 
Layer 'conv5' biases: 9.999885e-01 [4.985090e-08] 
Layer 'fc6' weights[0]: 7.593148e-03 [9.378841e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.473087e-09] 
Layer 'fc7' weights[0]: 7.852868e-03 [1.612956e-07] 
Layer 'fc7' biases: 9.999956e-01 [1.588806e-07] 
Layer 'fc8' weights[0]: 5.031671e-04 [2.747003e-04] 
Layer 'fc8' biases: 2.503588e-04 [3.053336e-04] 
Train error last 38 batches: 0.777247
-------------------------------------------------------
Not saving because 0.868673 > 0.622110 (8.23: -1.37%)
======================================================= (4.360 sec)
9.20... logprob:  1.245100, 0.460938 (0.599 sec)
9.21... logprob:  1.234845, 0.734375 (0.599 sec)
9.22... logprob:  1.231644, 0.304688 (0.599 sec)
9.23... logprob:  0.579555, 0.265625 (0.599 sec)
9.24... logprob:  0.682058, 0.375000 (0.599 sec)
9.25... logprob:  0.693224, 0.695312 (0.599 sec)
9.26... logprob:  0.865756, 0.375000 (0.599 sec)
9.27... logprob:  0.801157, 0.625000 (0.599 sec)
9.28... logprob:  1.001977, 0.429688 (0.598 sec)
9.29... logprob:  1.045014, 0.687500 (0.599 sec)
9.30... logprob:  1.211650, 0.359375 (0.601 sec)
9.31... logprob:  0.683546, 0.312500 (0.596 sec)
9.32... logprob:  0.726661, 0.320312 (0.597 sec)
9.33... logprob:  0.687212, 0.304688 (0.596 sec)
9.34... logprob:  0.702196, 0.296875 (0.596 sec)
9.35... logprob:  0.669934, 0.375000 (0.596 sec)
9.36... logprob:  0.635665, 0.328125 (0.596 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.628201, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979587e-03 [5.018488e-10] 
Layer 'conv1' biases: 6.434617e-09 [5.182611e-12] 
Layer 'conv2' weights[0]: 7.966514e-03 [4.796020e-10] 
Layer 'conv2' biases: 1.000000e+00 [3.582587e-11] 
Layer 'conv3' weights[0]: 7.964869e-03 [4.502401e-10] 
Layer 'conv3' biases: 1.669046e-07 [1.149033e-10] 
Layer 'conv4' weights[0]: 7.997358e-03 [4.638157e-10] 
Layer 'conv4' biases: 9.999998e-01 [1.029577e-09] 
Layer 'conv5' weights[0]: 7.996292e-03 [5.755680e-09] 
Layer 'conv5' biases: 9.999879e-01 [5.918507e-09] 
Layer 'fc6' weights[0]: 7.593128e-03 [1.162016e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.091913e-09] 
Layer 'fc7' weights[0]: 7.852763e-03 [1.944483e-08] 
Layer 'fc7' biases: 9.999951e-01 [1.827036e-08] 
Layer 'fc8' weights[0]: 4.506251e-04 [3.096471e-05] 
Layer 'fc8' biases: 5.247389e-05 [3.473052e-05] 
Train error last 38 batches: 0.769167
-------------------------------------------------------
Not saving because 0.628201 > 0.622110 (8.23: -1.37%)
======================================================= (4.410 sec)
9.37... logprob:  0.632369, 0.320312 (0.598 sec)
9.38... logprob:  0.642701, 0.328125 (0.599 sec)
10.1... logprob:  0.663201, 0.375000 (0.602 sec)
10.2... logprob:  0.627805, 0.320312 (0.599 sec)
10.3... logprob:  0.628101, 0.320312 (0.599 sec)
10.4... logprob:  0.638439, 0.335938 (0.599 sec)
10.5... logprob:  0.615793, 0.304688 (0.599 sec)
10.6... logprob:  0.659952, 0.351562 (0.599 sec)
10.7... logprob:  0.653028, 0.304688 (0.599 sec)
10.8... logprob:  0.656295, 0.296875 (0.599 sec)
10.9... logprob:  0.665430, 0.375000 (0.599 sec)
10.10... logprob:  0.633011, 0.328125 (0.599 sec)
10.11... logprob:  0.638307, 0.335938 (0.599 sec)
10.12... logprob:  0.649209, 0.351562 (0.599 sec)
10.13... logprob:  0.621934, 0.296875 (0.599 sec)
10.14... logprob:  0.706719, 0.359375 (0.599 sec)
10.15... logprob:  0.715929, 0.656250 (0.607 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.705724, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979579e-03 [6.974587e-10] 
Layer 'conv1' biases: 6.447892e-09 [2.672805e-11] 
Layer 'conv2' weights[0]: 7.966506e-03 [1.015300e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.614393e-10] 
Layer 'conv3' weights[0]: 7.964862e-03 [1.022975e-09] 
Layer 'conv3' biases: 1.674148e-07 [5.132993e-10] 
Layer 'conv4' weights[0]: 7.997351e-03 [1.213670e-09] 
Layer 'conv4' biases: 9.999998e-01 [5.199684e-09] 
Layer 'conv5' weights[0]: 7.996289e-03 [2.914845e-08] 
Layer 'conv5' biases: 9.999879e-01 [3.011158e-08] 
Layer 'fc6' weights[0]: 7.593120e-03 [5.570834e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.705269e-09] 
Layer 'fc7' weights[0]: 7.852701e-03 [9.775666e-08] 
Layer 'fc7' biases: 9.999951e-01 [9.610519e-08] 
Layer 'fc8' weights[0]: 4.749346e-04 [1.685701e-04] 
Layer 'fc8' biases: 1.743957e-04 [1.891977e-04] 
Train error last 38 batches: 0.754378
-------------------------------------------------------
Not saving because 0.705724 > 0.622110 (8.23: -1.37%)
======================================================= (4.415 sec)
10.16... logprob:  0.637698, 0.273438 (0.608 sec)
10.17... logprob:  0.621692, 0.296875 (0.606 sec)
10.18... logprob:  0.746158, 0.390625 (0.606 sec)
10.19... logprob:  0.791725, 0.671875 (0.606 sec)
10.20... logprob:  1.165159, 0.460938 (0.606 sec)
10.21... logprob:  1.222085, 0.734375 (0.606 sec)
10.22... logprob:  1.196763, 0.304688 (0.606 sec)
10.23... logprob:  0.579035, 0.265625 (0.606 sec)
10.24... logprob:  0.685827, 0.375000 (0.612 sec)
10.25... logprob:  0.696887, 0.695312 (0.607 sec)
10.26... logprob:  0.862652, 0.375000 (0.607 sec)
10.27... logprob:  0.788069, 0.625000 (0.608 sec)
10.28... logprob:  0.965371, 0.429688 (0.607 sec)
10.29... logprob:  1.015924, 0.687500 (0.607 sec)
10.30... logprob:  1.165334, 0.359375 (0.607 sec)
10.31... logprob:  0.688433, 0.312500 (0.607 sec)
10.32... logprob:  0.727600, 0.320312 (0.607 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.681577, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979568e-03 [8.841063e-10] 
Layer 'conv1' biases: 6.709432e-09 [2.025280e-11] 
Layer 'conv2' weights[0]: 7.966495e-03 [1.039352e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.757813e-10] 
Layer 'conv3' weights[0]: 7.964854e-03 [1.071817e-09] 
Layer 'conv3' biases: 1.744177e-07 [5.819227e-10] 
Layer 'conv4' weights[0]: 7.997346e-03 [1.308624e-09] 
Layer 'conv4' biases: 9.999998e-01 [6.244030e-09] 
Layer 'conv5' weights[0]: 7.996263e-03 [3.541270e-08] 
Layer 'conv5' biases: 9.999875e-01 [3.685176e-08] 
Layer 'fc6' weights[0]: 7.593111e-03 [6.151432e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.265071e-09] 
Layer 'fc7' weights[0]: 7.852633e-03 [1.056167e-07] 
Layer 'fc7' biases: 9.999944e-01 [1.036303e-07] 
Layer 'fc8' weights[0]: 4.467141e-04 [1.565022e-04] 
Layer 'fc8' biases: 4.541427e-06 [1.771392e-04] 
Train error last 38 batches: 0.744727
-------------------------------------------------------
Not saving because 0.681577 > 0.622110 (8.23: -1.37%)
======================================================= (4.417 sec)
10.33... logprob:  0.681067, 0.304688 (0.607 sec)
10.34... logprob:  0.688568, 0.296875 (0.607 sec)
10.35... logprob:  0.667336, 0.375000 (0.607 sec)
10.36... logprob:  0.633664, 0.328125 (0.607 sec)
10.37... logprob:  0.629047, 0.320312 (0.607 sec)
10.38... logprob:  0.636757, 0.328125 (0.607 sec)
11.1... logprob:  0.661549, 0.375000 (0.608 sec)
11.2... logprob:  0.633706, 0.320312 (0.607 sec)
11.3... logprob:  0.636069, 0.320312 (0.608 sec)
11.4... logprob:  0.643849, 0.335938 (0.607 sec)
11.5... logprob:  0.616541, 0.304688 (0.607 sec)
11.6... logprob:  0.649146, 0.351562 (0.607 sec)
11.7... logprob:  0.625336, 0.304688 (0.607 sec)
11.8... logprob:  0.618782, 0.296875 (0.607 sec)
11.9... logprob:  0.661995, 0.375000 (0.608 sec)
11.10... logprob:  0.641955, 0.328125 (0.607 sec)
11.11... logprob:  0.654136, 0.335938 (0.607 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.649278, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979562e-03 [6.338573e-10] 
Layer 'conv1' biases: 6.721422e-09 [1.100310e-11] 
Layer 'conv2' weights[0]: 7.966489e-03 [5.971675e-10] 
Layer 'conv2' biases: 1.000000e+00 [7.605729e-11] 
Layer 'conv3' weights[0]: 7.964848e-03 [5.997395e-10] 
Layer 'conv3' biases: 1.749197e-07 [2.497053e-10] 
Layer 'conv4' weights[0]: 7.997336e-03 [6.801677e-10] 
Layer 'conv4' biases: 9.999998e-01 [2.484640e-09] 
Layer 'conv5' weights[0]: 7.996253e-03 [1.380194e-08] 
Layer 'conv5' biases: 9.999875e-01 [1.431970e-08] 
Layer 'fc6' weights[0]: 7.593107e-03 [2.537920e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.548378e-09] 
Layer 'fc7' weights[0]: 7.852570e-03 [4.360033e-08] 
Layer 'fc7' biases: 9.999943e-01 [4.255159e-08] 
Layer 'fc8' weights[0]: 4.473052e-04 [7.064198e-05] 
Layer 'fc8' biases: 2.768263e-05 [8.003483e-05] 
Train error last 38 batches: 0.742887
-------------------------------------------------------
Not saving because 0.649278 > 0.622110 (8.23: -1.37%)
======================================================= (4.424 sec)
11.12... logprob:  0.660581, 0.351562 (0.606 sec)
11.13... logprob:  0.611160, 0.296875 (0.606 sec)
11.14... logprob:  0.654704, 0.359375 (0.606 sec)
11.15... logprob:  0.648696, 0.343750 (0.606 sec)
11.16... logprob:  0.587029, 0.273438 (0.606 sec)
11.17... logprob:  0.611293, 0.296875 (0.606 sec)
11.18... logprob:  0.676322, 0.390625 (0.606 sec)
11.19... logprob:  0.672325, 0.328125 (0.606 sec)
11.20... logprob:  0.886819, 0.460938 (0.606 sec)
11.21... logprob:  1.141908, 0.734375 (0.606 sec)
11.22... logprob:  1.143986, 0.304688 (0.606 sec)
11.23... logprob:  0.579157, 0.265625 (0.606 sec)
11.24... logprob:  0.695972, 0.375000 (0.606 sec)
11.25... logprob:  0.710387, 0.695312 (0.606 sec)
11.26... logprob:  0.877870, 0.375000 (0.606 sec)
11.27... logprob:  0.778972, 0.625000 (0.607 sec)
11.28... logprob:  0.939550, 0.429688 (0.606 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.992276, 0.687500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979555e-03 [1.300025e-09] 
Layer 'conv1' biases: 6.858903e-09 [3.798461e-11] 
Layer 'conv2' weights[0]: 7.966483e-03 [1.691020e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.048987e-10] 
Layer 'conv3' weights[0]: 7.964840e-03 [1.658491e-09] 
Layer 'conv3' biases: 1.786891e-07 [9.839512e-10] 
Layer 'conv4' weights[0]: 7.997331e-03 [2.035057e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.050411e-08] 
Layer 'conv5' weights[0]: 7.996241e-03 [5.951162e-08] 
Layer 'conv5' biases: 9.999873e-01 [6.202974e-08] 
Layer 'fc6' weights[0]: 7.593100e-03 [1.027804e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.045088e-08] 
Layer 'fc7' weights[0]: 7.852510e-03 [1.754874e-07] 
Layer 'fc7' biases: 9.999940e-01 [1.727271e-07] 
Layer 'fc8' weights[0]: 4.543412e-04 [2.577532e-04] 
Layer 'fc8' biases: 1.043212e-04 [2.932580e-04] 
Train error last 38 batches: 0.722461
-------------------------------------------------------
Not saving because 0.992276 > 0.622110 (8.23: -1.37%)
======================================================= (4.421 sec)
11.29... logprob:  0.992269, 0.687500 (0.606 sec)
11.30... logprob:  1.128780, 0.359375 (0.606 sec)
11.31... logprob:  0.691970, 0.312500 (0.606 sec)
11.32... logprob:  0.727427, 0.320312 (0.606 sec)
11.33... logprob:  0.676244, 0.304688 (0.606 sec)
11.34... logprob:  0.678585, 0.296875 (0.605 sec)
11.35... logprob:  0.665577, 0.375000 (0.606 sec)
11.36... logprob:  0.632925, 0.328125 (0.606 sec)
11.37... logprob:  0.627621, 0.320312 (0.606 sec)
11.38... logprob:  0.634227, 0.328125 (0.606 sec)
12.1... logprob:  0.662380, 0.375000 (0.607 sec)
12.2... logprob:  0.640480, 0.320312 (0.606 sec)
12.3... logprob:  0.644629, 0.320312 (0.607 sec)
12.4... logprob:  0.649061, 0.335938 (0.606 sec)
12.5... logprob:  0.620321, 0.304688 (0.606 sec)
12.6... logprob:  0.648391, 0.351562 (0.606 sec)
12.7... logprob:  0.619503, 0.304688 (0.606 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.628464, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979548e-03 [5.344195e-10] 
Layer 'conv1' biases: 6.937197e-09 [8.991826e-12] 
Layer 'conv2' weights[0]: 7.966479e-03 [5.182054e-10] 
Layer 'conv2' biases: 1.000000e+00 [4.565993e-11] 
Layer 'conv3' weights[0]: 7.964832e-03 [5.189984e-10] 
Layer 'conv3' biases: 1.808850e-07 [1.453323e-10] 
Layer 'conv4' weights[0]: 7.997323e-03 [5.653973e-10] 
Layer 'conv4' biases: 9.999998e-01 [1.323425e-09] 
Layer 'conv5' weights[0]: 7.996225e-03 [7.442560e-09] 
Layer 'conv5' biases: 9.999871e-01 [7.676796e-09] 
Layer 'fc6' weights[0]: 7.593098e-03 [1.421564e-09] 
Layer 'fc6' biases: 9.999999e-01 [1.391928e-09] 
Layer 'fc7' weights[0]: 7.852453e-03 [2.443426e-08] 
Layer 'fc7' biases: 9.999938e-01 [2.333832e-08] 
Layer 'fc8' weights[0]: 4.558687e-04 [4.020917e-05] 
Layer 'fc8' biases: 1.076409e-04 [4.591798e-05] 
Train error last 38 batches: 0.720894
-------------------------------------------------------
Not saving because 0.628464 > 0.622110 (8.23: -1.37%)
======================================================= (4.425 sec)
12.8... logprob:  0.611962, 0.296875 (0.606 sec)
12.9... logprob:  0.665057, 0.375000 (0.607 sec)
12.10... logprob:  0.652421, 0.328125 (0.609 sec)
12.11... logprob:  0.669279, 0.335938 (0.607 sec)
12.12... logprob:  0.670213, 0.351562 (0.606 sec)
12.13... logprob:  0.617458, 0.296875 (0.606 sec)
12.14... logprob:  0.653092, 0.359375 (0.606 sec)
12.15... logprob:  0.644448, 0.343750 (0.606 sec)
12.16... logprob:  0.591629, 0.273438 (0.606 sec)
12.17... logprob:  0.619246, 0.296875 (0.606 sec)
12.18... logprob:  0.671076, 0.390625 (0.606 sec)
12.19... logprob:  0.654767, 0.328125 (0.606 sec)
12.20... logprob:  0.829981, 0.460938 (0.606 sec)
12.21... logprob:  1.062553, 0.734375 (0.606 sec)
12.22... logprob:  1.087837, 0.304688 (0.606 sec)
12.23... logprob:  0.581591, 0.265625 (0.606 sec)
12.24... logprob:  0.709099, 0.375000 (0.606 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.722760, 0.687500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979542e-03 [7.494939e-10] 
Layer 'conv1' biases: 7.015821e-09 [1.369618e-11] 
Layer 'conv2' weights[0]: 7.966475e-03 [8.402418e-10] 
Layer 'conv2' biases: 1.000000e+00 [1.285783e-10] 
Layer 'conv3' weights[0]: 7.964826e-03 [8.178746e-10] 
Layer 'conv3' biases: 1.832054e-07 [4.215969e-10] 
Layer 'conv4' weights[0]: 7.997316e-03 [9.771932e-10] 
Layer 'conv4' biases: 9.999998e-01 [4.372394e-09] 
Layer 'conv5' weights[0]: 7.996220e-03 [2.426468e-08] 
Layer 'conv5' biases: 9.999869e-01 [2.511507e-08] 
Layer 'fc6' weights[0]: 7.593087e-03 [4.396039e-09] 
Layer 'fc6' biases: 9.999999e-01 [4.425635e-09] 
Layer 'fc7' weights[0]: 7.852389e-03 [7.512126e-08] 
Layer 'fc7' biases: 9.999934e-01 [7.385888e-08] 
Layer 'fc8' weights[0]: 4.451596e-04 [1.207266e-04] 
Layer 'fc8' biases: 1.825440e-05 [1.382491e-04] 
Train error last 38 batches: 0.716813
-------------------------------------------------------
Not saving because 0.722760 > 0.622110 (8.23: -1.37%)
======================================================= (4.415 sec)
12.25... logprob:  0.723888, 0.695312 (0.606 sec)
12.26... logprob:  0.890961, 0.375000 (0.606 sec)
12.27... logprob:  0.769754, 0.625000 (0.606 sec)
12.28... logprob:  0.915094, 0.429688 (0.606 sec)
12.29... logprob:  0.969218, 0.687500 (0.606 sec)
12.30... logprob:  1.094168, 0.359375 (0.606 sec)
12.31... logprob:  0.695000, 0.687500 (0.606 sec)
12.32... logprob:  0.726540, 0.320312 (0.606 sec)
12.33... logprob:  0.671772, 0.304688 (0.606 sec)
12.34... logprob:  0.669852, 0.296875 (0.606 sec)
12.35... logprob:  0.664187, 0.375000 (0.606 sec)
12.36... logprob:  0.632856, 0.328125 (0.608 sec)
12.37... logprob:  0.627098, 0.320312 (0.605 sec)
12.38... logprob:  0.633104, 0.328125 (0.607 sec)
13.1... logprob:  0.664215, 0.375000 (0.612 sec)
13.2... logprob:  0.646973, 0.320312 (0.607 sec)
13.3... logprob:  0.652071, 0.320312 (0.607 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644638, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979535e-03 [6.222213e-10] 
Layer 'conv1' biases: 7.139424e-09 [1.113119e-11] 
Layer 'conv2' weights[0]: 7.966467e-03 [6.894186e-10] 
Layer 'conv2' biases: 1.000000e+00 [9.622160e-11] 
Layer 'conv3' weights[0]: 7.964820e-03 [6.934864e-10] 
Layer 'conv3' biases: 1.865576e-07 [3.070685e-10] 
Layer 'conv4' weights[0]: 7.997309e-03 [8.003632e-10] 
Layer 'conv4' biases: 9.999998e-01 [3.114680e-09] 
Layer 'conv5' weights[0]: 7.996221e-03 [1.731625e-08] 
Layer 'conv5' biases: 9.999866e-01 [1.796199e-08] 
Layer 'fc6' weights[0]: 7.593083e-03 [3.103776e-09] 
Layer 'fc6' biases: 9.999999e-01 [3.137020e-09] 
Layer 'fc7' weights[0]: 7.852321e-03 [5.352000e-08] 
Layer 'fc7' biases: 9.999931e-01 [5.228122e-08] 
Layer 'fc8' weights[0]: 4.452885e-04 [8.448720e-05] 
Layer 'fc8' biases: 3.196817e-05 [9.719246e-05] 
Train error last 38 batches: 0.715151
-------------------------------------------------------
Not saving because 0.644638 > 0.622110 (8.23: -1.37%)
======================================================= (4.418 sec)
13.4... logprob:  0.652405, 0.335938 (0.606 sec)
13.5... logprob:  0.622663, 0.304688 (0.607 sec)
13.6... logprob:  0.648508, 0.351562 (0.606 sec)
13.7... logprob:  0.618093, 0.304688 (0.607 sec)
13.8... logprob:  0.610426, 0.296875 (0.606 sec)
13.9... logprob:  0.666944, 0.375000 (0.607 sec)
13.10... logprob:  0.656488, 0.328125 (0.607 sec)
13.11... logprob:  0.673606, 0.335938 (0.607 sec)
13.12... logprob:  0.671097, 0.351562 (0.607 sec)
13.13... logprob:  0.617243, 0.296875 (0.606 sec)
13.14... logprob:  0.653157, 0.359375 (0.607 sec)
13.15... logprob:  0.644723, 0.343750 (0.606 sec)
13.16... logprob:  0.591118, 0.273438 (0.606 sec)
13.17... logprob:  0.618075, 0.296875 (0.606 sec)
13.18... logprob:  0.671820, 0.390625 (0.607 sec)
13.19... logprob:  0.656989, 0.328125 (0.606 sec)
13.20... logprob:  0.833084, 0.460938 (0.606 sec)
=========================
Testing all batches

======================Test output======================
logprob:  1.002821, 0.687500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979529e-03 [9.309274e-10] 
Layer 'conv1' biases: 7.153983e-09 [2.922337e-11] 
Layer 'conv2' weights[0]: 7.966460e-03 [1.370193e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.450853e-10] 
Layer 'conv3' weights[0]: 7.964814e-03 [1.324612e-09] 
Layer 'conv3' biases: 1.871742e-07 [7.523413e-10] 
Layer 'conv4' weights[0]: 7.997303e-03 [1.592888e-09] 
Layer 'conv4' biases: 9.999998e-01 [7.855402e-09] 
Layer 'conv5' weights[0]: 7.996219e-03 [4.356183e-08] 
Layer 'conv5' biases: 9.999866e-01 [4.511107e-08] 
Layer 'fc6' weights[0]: 7.593077e-03 [7.715073e-09] 
Layer 'fc6' biases: 9.999999e-01 [7.830348e-09] 
Layer 'fc7' weights[0]: 7.852251e-03 [1.326905e-07] 
Layer 'fc7' biases: 9.999930e-01 [1.304743e-07] 
Layer 'fc8' weights[0]: 4.534140e-04 [2.100923e-04] 
Layer 'fc8' biases: 1.100734e-04 [2.418256e-04] 
Train error last 38 batches: 0.715639
-------------------------------------------------------
Not saving because 1.002821 > 0.622110 (8.23: -1.37%)
======================================================= (4.421 sec)
13.21... logprob:  1.049932, 0.734375 (0.606 sec)
13.22... logprob:  1.062988, 0.304688 (0.606 sec)
13.23... logprob:  0.582495, 0.265625 (0.606 sec)
13.24... logprob:  0.711826, 0.375000 (0.606 sec)
13.25... logprob:  0.722369, 0.695312 (0.606 sec)
13.26... logprob:  0.880046, 0.375000 (0.606 sec)
13.27... logprob:  0.761625, 0.625000 (0.607 sec)
13.28... logprob:  0.893517, 0.429688 (0.606 sec)
13.29... logprob:  0.946898, 0.687500 (0.606 sec)
13.30... logprob:  1.061044, 0.359375 (0.606 sec)
13.31... logprob:  0.697407, 0.687500 (0.606 sec)
13.32... logprob:  0.724795, 0.320312 (0.607 sec)
13.33... logprob:  0.667518, 0.304688 (0.606 sec)
13.34... logprob:  0.662023, 0.296875 (0.606 sec)
13.35... logprob:  0.663111, 0.375000 (0.606 sec)
13.36... logprob:  0.633308, 0.328125 (0.606 sec)
13.37... logprob:  0.627213, 0.320312 (0.606 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.621631, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979525e-03 [5.569209e-10] 
Layer 'conv1' biases: 7.323931e-09 [4.620702e-12] 
Layer 'conv2' weights[0]: 7.966454e-03 [4.811172e-10] 
Layer 'conv2' biases: 1.000000e+00 [2.459624e-11] 
Layer 'conv3' weights[0]: 7.964801e-03 [4.368733e-10] 
Layer 'conv3' biases: 1.918390e-07 [6.300613e-11] 
Layer 'conv4' weights[0]: 7.997294e-03 [4.416000e-10] 
Layer 'conv4' biases: 9.999998e-01 [2.403406e-10] 
Layer 'conv5' weights[0]: 7.996200e-03 [1.370397e-09] 
Layer 'conv5' biases: 9.999863e-01 [1.344503e-09] 
Layer 'fc6' weights[0]: 7.593077e-03 [4.537570e-10] 
Layer 'fc6' biases: 9.999999e-01 [2.380040e-10] 
Layer 'fc7' weights[0]: 7.852196e-03 [6.114414e-09] 
Layer 'fc7' biases: 9.999925e-01 [3.959141e-09] 
Layer 'fc8' weights[0]: 4.481518e-04 [6.698425e-06] 
Layer 'fc8' biases: 7.342293e-05 [7.759470e-06] 
Train error last 38 batches: 0.711866
-------------------------------------------------------
Saved checkpoint to /data/ad6813/my-nets/saves/ConvNet__2014-06-27_21.30.06
======================================================= (4.966 sec)
13.38... logprob:  0.632819, 0.328125 (0.602 sec)
14.1... logprob:  0.666444, 0.375000 (0.602 sec)
14.2... logprob:  0.652468, 0.320312 (0.602 sec)
14.3... logprob:  0.657551, 0.320312 (0.602 sec)
14.4... logprob:  0.653915, 0.335938 (0.601 sec)
14.5... logprob:  0.623296, 0.304688 (0.601 sec)
14.6... logprob:  0.648510, 0.351562 (0.601 sec)
14.7... logprob:  0.618113, 0.304688 (0.601 sec)
14.8... logprob:  0.610283, 0.296875 (0.601 sec)
14.9... logprob:  0.667349, 0.375000 (0.602 sec)
14.10... logprob:  0.656646, 0.328125 (0.601 sec)
14.11... logprob:  0.672115, 0.335938 (0.602 sec)
14.12... logprob:  0.668646, 0.351562 (0.602 sec)
14.13... logprob:  0.614738, 0.296875 (0.601 sec)
14.14... logprob:  0.653632, 0.359375 (0.601 sec)
14.15... logprob:  0.645991, 0.343750 (0.601 sec)
14.16... logprob:  0.589291, 0.273438 (0.601 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.632630, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979515e-03 [4.947078e-10] 
Layer 'conv1' biases: 7.332098e-09 [8.192171e-12] 
Layer 'conv2' weights[0]: 7.966445e-03 [4.879514e-10] 
Layer 'conv2' biases: 1.000000e+00 [3.653428e-11] 
Layer 'conv3' weights[0]: 7.964795e-03 [4.805199e-10] 
Layer 'conv3' biases: 1.921928e-07 [1.167652e-10] 
Layer 'conv4' weights[0]: 7.997282e-03 [5.118147e-10] 
Layer 'conv4' biases: 9.999998e-01 [1.019312e-09] 
Layer 'conv5' weights[0]: 7.996190e-03 [5.620608e-09] 
Layer 'conv5' biases: 9.999863e-01 [5.790882e-09] 
Layer 'fc6' weights[0]: 7.593072e-03 [1.090793e-09] 
Layer 'fc6' biases: 9.999999e-01 [1.015083e-09] 
Layer 'fc7' weights[0]: 7.852127e-03 [1.817442e-08] 
Layer 'fc7' biases: 9.999925e-01 [1.697208e-08] 
Layer 'fc8' weights[0]: 4.555057e-04 [2.868537e-05] 
Layer 'fc8' biases: 1.174551e-04 [3.326521e-05] 
Train error last 38 batches: 0.712102
-------------------------------------------------------
Not saving because 0.632630 > 0.621631 (13.37: -0.08%)
======================================================= (4.416 sec)
14.17... logprob:  0.615068, 0.296875 (0.602 sec)
14.18... logprob:  0.673700, 0.390625 (0.602 sec)
14.19... logprob:  0.662112, 0.328125 (0.602 sec)
14.20... logprob:  0.843705, 0.460938 (0.602 sec)
14.21... logprob:  1.045633, 0.734375 (0.602 sec)
14.22... logprob:  1.043269, 0.304688 (0.602 sec)
14.23... logprob:  0.583000, 0.265625 (0.602 sec)
14.24... logprob:  0.712772, 0.375000 (0.602 sec)
14.25... logprob:  0.718861, 0.695312 (0.602 sec)
14.26... logprob:  0.866842, 0.375000 (0.602 sec)
14.27... logprob:  0.754083, 0.625000 (0.602 sec)
14.28... logprob:  0.873951, 0.429688 (0.601 sec)
14.29... logprob:  0.925420, 0.687500 (0.602 sec)
14.30... logprob:  1.029520, 0.359375 (0.602 sec)
14.31... logprob:  0.699150, 0.687500 (0.606 sec)
14.32... logprob:  0.722274, 0.320312 (0.603 sec)
14.33... logprob:  0.663508, 0.304688 (0.603 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.679588, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979506e-03 [6.291478e-10] 
Layer 'conv1' biases: 7.500857e-09 [2.263338e-11] 
Layer 'conv2' weights[0]: 7.966441e-03 [9.750572e-10] 
Layer 'conv2' biases: 1.000000e+00 [1.487450e-10] 
Layer 'conv3' weights[0]: 7.964788e-03 [9.332258e-10] 
Layer 'conv3' biases: 1.968024e-07 [4.315324e-10] 
Layer 'conv4' weights[0]: 7.997274e-03 [1.097687e-09] 
Layer 'conv4' biases: 9.999998e-01 [4.403053e-09] 
Layer 'conv5' weights[0]: 7.996197e-03 [2.419712e-08] 
Layer 'conv5' biases: 9.999861e-01 [2.497410e-08] 
Layer 'fc6' weights[0]: 7.593063e-03 [4.417703e-09] 
Layer 'fc6' biases: 9.999999e-01 [4.463091e-09] 
Layer 'fc7' weights[0]: 7.852055e-03 [7.616629e-08] 
Layer 'fc7' biases: 9.999921e-01 [7.493849e-08] 
Layer 'fc8' weights[0]: 4.663922e-04 [1.310022e-04] 
Layer 'fc8' biases: 1.673072e-04 [1.528956e-04] 
Train error last 38 batches: 0.709219
-------------------------------------------------------
Not saving because 0.679588 > 0.621631 (13.37: -0.08%)
======================================================= (4.403 sec)
14.34... logprob:  0.655062, 0.296875 (0.603 sec)
14.35... logprob:  0.662334, 0.375000 (0.603 sec)
14.36... logprob:  0.634159, 0.328125 (0.603 sec)
14.37... logprob:  0.627767, 0.320312 (0.606 sec)
14.38... logprob:  0.633010, 0.328125 (0.603 sec)
15.1... logprob:  0.668635, 0.375000 (0.604 sec)
15.2... logprob:  0.656610, 0.320312 (0.603 sec)
15.3... logprob:  0.660870, 0.320312 (0.604 sec)
15.4... logprob:  0.654062, 0.335938 (0.603 sec)
15.5... logprob:  0.622756, 0.304688 (0.604 sec)
15.6... logprob:  0.648423, 0.351562 (0.603 sec)
15.7... logprob:  0.618796, 0.304688 (0.604 sec)
15.8... logprob:  0.610674, 0.296875 (0.603 sec)
15.9... logprob:  0.667034, 0.375000 (0.604 sec)
15.10... logprob:  0.655264, 0.328125 (0.603 sec)
15.11... logprob:  0.668704, 0.335938 (0.604 sec)
15.12... logprob:  0.665455, 0.351562 (0.603 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.628812, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979502e-03 [6.111722e-10] 
Layer 'conv1' biases: 7.513162e-09 [1.585892e-11] 
Layer 'conv2' weights[0]: 7.966435e-03 [7.264847e-10] 
Layer 'conv2' biases: 1.000000e+00 [9.130655e-11] 
Layer 'conv3' weights[0]: 7.964776e-03 [7.211082e-10] 
Layer 'conv3' biases: 1.973282e-07 [2.757053e-10] 
Layer 'conv4' weights[0]: 7.997268e-03 [8.120893e-10] 
Layer 'conv4' biases: 9.999998e-01 [2.662284e-09] 
Layer 'conv5' weights[0]: 7.996190e-03 [1.457276e-08] 
Layer 'conv5' biases: 9.999860e-01 [1.502817e-08] 
Layer 'fc6' weights[0]: 7.593059e-03 [2.626675e-09] 
Layer 'fc6' biases: 9.999999e-01 [2.658113e-09] 
Layer 'fc7' weights[0]: 7.851991e-03 [4.561172e-08] 
Layer 'fc7' biases: 9.999920e-01 [4.459335e-08] 
Layer 'fc8' weights[0]: 4.533616e-04 [7.780509e-05] 
Layer 'fc8' biases: 1.119679e-04 [9.087696e-05] 
Train error last 38 batches: 0.709109
-------------------------------------------------------
Not saving because 0.628812 > 0.621631 (13.37: -0.08%)
======================================================= (4.401 sec)
15.13... logprob:  0.612224, 0.296875 (0.603 sec)
15.14... logprob:  0.654645, 0.359375 (0.603 sec)
15.15... logprob:  0.647848, 0.343750 (0.603 sec)
15.16... logprob:  0.587898, 0.273438 (0.603 sec)
15.17... logprob:  0.612700, 0.296875 (0.603 sec)
15.18... logprob:  0.675904, 0.390625 (0.603 sec)
15.19... logprob:  0.666900, 0.328125 (0.603 sec)
15.20... logprob:  0.852035, 0.460938 (0.603 sec)
15.21... logprob:  1.037970, 0.734375 (0.603 sec)
15.22... logprob:  1.022954, 0.304688 (0.603 sec)
15.23... logprob:  0.583653, 0.265625 (0.603 sec)
15.24... logprob:  0.714023, 0.375000 (0.603 sec)
15.25... logprob:  0.715792, 0.695312 (0.603 sec)
15.26... logprob:  0.855026, 0.375000 (0.603 sec)
15.27... logprob:  0.747037, 0.625000 (0.604 sec)
15.28... logprob:  0.856188, 0.429688 (0.603 sec)
15.29... logprob:  0.904969, 0.687500 (0.603 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.878901, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979495e-03 [1.296410e-09] 
Layer 'conv1' biases: 7.637073e-09 [5.937544e-11] 
Layer 'conv2' weights[0]: 7.966429e-03 [2.194970e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.906051e-10] 
Layer 'conv3' weights[0]: 7.964771e-03 [1.979512e-09] 
Layer 'conv3' biases: 2.006436e-07 [1.132634e-09] 
Layer 'conv4' weights[0]: 7.997262e-03 [2.292608e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.111608e-08] 
Layer 'conv5' weights[0]: 7.996179e-03 [6.006476e-08] 
Layer 'conv5' biases: 9.999859e-01 [6.170524e-08] 
Layer 'fc6' weights[0]: 7.593055e-03 [1.081492e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.119099e-08] 
Layer 'fc7' weights[0]: 7.851926e-03 [1.889628e-07] 
Layer 'fc7' biases: 9.999916e-01 [1.861492e-07] 
Layer 'fc8' weights[0]: 5.041355e-04 [3.138601e-04] 
Layer 'fc8' biases: 2.801571e-04 [3.681523e-04] 
Train error last 38 batches: 0.707154
-------------------------------------------------------
Not saving because 0.878901 > 0.621631 (13.37: -0.08%)
======================================================= (4.381 sec)
15.30... logprob:  0.999789, 0.359375 (0.603 sec)
15.31... logprob:  0.700194, 0.687500 (0.603 sec)
15.32... logprob:  0.719073, 0.320312 (0.603 sec)
15.33... logprob:  0.659756, 0.304688 (0.603 sec)
15.34... logprob:  0.648921, 0.296875 (0.603 sec)
15.35... logprob:  0.661835, 0.375000 (0.603 sec)
15.36... logprob:  0.635292, 0.328125 (0.603 sec)
15.37... logprob:  0.628585, 0.320312 (0.603 sec)
15.38... logprob:  0.633421, 0.328125 (0.603 sec)
16.1... logprob:  0.670535, 0.375000 (0.604 sec)
16.2... logprob:  0.659396, 0.320312 (0.603 sec)
16.3... logprob:  0.662302, 0.320312 (0.612 sec)
16.4... logprob:  0.653358, 0.335938 (0.602 sec)
16.5... logprob:  0.621621, 0.304688 (0.604 sec)
16.6... logprob:  0.648384, 0.351562 (0.602 sec)
16.7... logprob:  0.619859, 0.304688 (0.605 sec)
16.8... logprob:  0.611323, 0.296875 (0.605 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.621584, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979485e-03 [5.636704e-10] 
Layer 'conv1' biases: 7.679955e-09 [5.926246e-12] 
Layer 'conv2' weights[0]: 7.966422e-03 [4.916981e-10] 
Layer 'conv2' biases: 1.000000e+00 [4.228859e-11] 
Layer 'conv3' weights[0]: 7.964762e-03 [4.652502e-10] 
Layer 'conv3' biases: 2.021368e-07 [1.296726e-10] 
Layer 'conv4' weights[0]: 7.997256e-03 [4.786452e-10] 
Layer 'conv4' biases: 9.999998e-01 [1.141262e-09] 
Layer 'conv5' weights[0]: 7.996176e-03 [6.224433e-09] 
Layer 'conv5' biases: 9.999858e-01 [6.414787e-09] 
Layer 'fc6' weights[0]: 7.593053e-03 [1.171359e-09] 
Layer 'fc6' biases: 9.999999e-01 [1.102441e-09] 
Layer 'fc7' weights[0]: 7.851835e-03 [1.951004e-08] 
Layer 'fc7' biases: 9.999915e-01 [1.835341e-08] 
Layer 'fc8' weights[0]: 4.464044e-04 [3.014330e-05] 
Layer 'fc8' biases: 7.509218e-05 [3.544337e-05] 
Train error last 38 batches: 0.706260
-------------------------------------------------------
Saved checkpoint to /data/ad6813/my-nets/saves/ConvNet__2014-06-27_21.30.06
======================================================= (4.896 sec)
16.9... logprob:  0.666526, 0.375000 (0.609 sec)
16.10... logprob:  0.653570, 0.328125 (0.608 sec)
16.11... logprob:  0.665171, 0.335938 (0.609 sec)
16.12... logprob:  0.662500, 0.351562 (0.608 sec)
16.13... logprob:  0.610370, 0.296875 (0.609 sec)
16.14... logprob:  0.656063, 0.359375 (0.608 sec)
16.15... logprob:  0.649880, 0.343750 (0.608 sec)
16.16... logprob:  0.587138, 0.273438 (0.608 sec)
16.17... logprob:  0.611225, 0.296875 (0.609 sec)
16.18... logprob:  0.677889, 0.390625 (0.608 sec)
16.19... logprob:  0.670294, 0.328125 (0.608 sec)
16.20... logprob:  0.855987, 0.460938 (0.608 sec)
16.21... logprob:  1.026257, 0.734375 (0.608 sec)
16.22... logprob:  1.001820, 0.304688 (0.608 sec)
16.23... logprob:  0.584502, 0.265625 (0.608 sec)
16.24... logprob:  0.715642, 0.375000 (0.608 sec)
16.25... logprob:  0.713162, 0.695312 (0.609 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.727667, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979477e-03 [8.050338e-10] 
Layer 'conv1' biases: 7.751011e-09 [3.483888e-11] 
Layer 'conv2' weights[0]: 7.966414e-03 [1.323547e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.266964e-10] 
Layer 'conv3' weights[0]: 7.964753e-03 [1.250237e-09] 
Layer 'conv3' biases: 2.042213e-07 [6.584790e-10] 
Layer 'conv4' weights[0]: 7.997247e-03 [1.430069e-09] 
Layer 'conv4' biases: 9.999998e-01 [6.478166e-09] 
Layer 'conv5' weights[0]: 7.996166e-03 [3.535701e-08] 
Layer 'conv5' biases: 9.999856e-01 [3.646252e-08] 
Layer 'fc6' weights[0]: 7.593048e-03 [6.202810e-09] 
Layer 'fc6' biases: 9.999999e-01 [6.368889e-09] 
Layer 'fc7' weights[0]: 7.851772e-03 [1.085966e-07] 
Layer 'fc7' biases: 9.999912e-01 [1.067463e-07] 
Layer 'fc8' weights[0]: 4.753193e-04 [1.860401e-04] 
Layer 'fc8' biases: 2.037024e-04 [2.194447e-04] 
Train error last 38 batches: 0.705391
-------------------------------------------------------
Not saving because 0.727667 > 0.621584 (16.8: -0.01%)
======================================================= (4.415 sec)
16.26... logprob:  0.844521, 0.375000 (0.607 sec)
16.27... logprob:  0.740523, 0.625000 (0.607 sec)
16.28... logprob:  0.840198, 0.429688 (0.607 sec)
16.29... logprob:  0.885739, 0.687500 (0.607 sec)
16.30... logprob:  0.972031, 0.359375 (0.607 sec)
16.31... logprob:  0.700534, 0.687500 (0.607 sec)
16.32... logprob:  0.715300, 0.320312 (0.607 sec)
16.33... logprob:  0.656263, 0.304688 (0.607 sec)
16.34... logprob:  0.643536, 0.296875 (0.606 sec)
16.35... logprob:  0.661581, 0.375000 (0.607 sec)
16.36... logprob:  0.636600, 0.328125 (0.607 sec)
16.37... logprob:  0.629527, 0.320312 (0.607 sec)
16.38... logprob:  0.633890, 0.328125 (0.608 sec)
17.1... logprob:  0.672032, 0.375000 (0.608 sec)
17.2... logprob:  0.661008, 0.320312 (0.607 sec)
17.3... logprob:  0.662301, 0.320312 (0.608 sec)
17.4... logprob:  0.652194, 0.335938 (0.606 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.628550, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979471e-03 [6.057896e-10] 
Layer 'conv1' biases: 7.839930e-09 [1.742924e-11] 
Layer 'conv2' weights[0]: 7.966410e-03 [6.846000e-10] 
Layer 'conv2' biases: 1.000000e+00 [8.880319e-11] 
Layer 'conv3' weights[0]: 7.964750e-03 [6.838802e-10] 
Layer 'conv3' biases: 2.067300e-07 [2.560029e-10] 
Layer 'conv4' weights[0]: 7.997243e-03 [7.440749e-10] 
Layer 'conv4' biases: 9.999998e-01 [2.458222e-09] 
Layer 'conv5' weights[0]: 7.996165e-03 [1.332803e-08] 
Layer 'conv5' biases: 9.999853e-01 [1.377835e-08] 
Layer 'fc6' weights[0]: 7.593039e-03 [2.380998e-09] 
Layer 'fc6' biases: 9.999999e-01 [2.366156e-09] 
Layer 'fc7' weights[0]: 7.851721e-03 [4.054369e-08] 
Layer 'fc7' biases: 9.999910e-01 [3.959017e-08] 
Layer 'fc8' weights[0]: 4.517860e-04 [6.867344e-05] 
Layer 'fc8' biases: 1.138118e-04 [8.131163e-05] 
Train error last 38 batches: 0.703078
-------------------------------------------------------
Not saving because 0.628550 > 0.621584 (16.8: -0.01%)
======================================================= (4.423 sec)
17.5... logprob:  0.620298, 0.304688 (0.608 sec)
17.6... logprob:  0.648472, 0.351562 (0.607 sec)
17.7... logprob:  0.621134, 0.304688 (0.608 sec)
17.8... logprob:  0.612081, 0.296875 (0.650 sec)
17.9... logprob:  0.666060, 0.375000 (0.608 sec)
17.10... logprob:  0.652056, 0.328125 (0.607 sec)
17.11... logprob:  0.662136, 0.335938 (0.610 sec)
17.12... logprob:  0.660056, 0.351562 (0.644 sec)
17.13... logprob:  0.609198, 0.296875 (0.608 sec)
17.14... logprob:  0.657666, 0.359375 (0.611 sec)
17.15... logprob:  0.651753, 0.343750 (0.607 sec)
17.16... logprob:  0.586802, 0.273438 (0.607 sec)
17.17... logprob:  0.610393, 0.296875 (0.607 sec)
17.18... logprob:  0.679409, 0.390625 (0.607 sec)
17.19... logprob:  0.672209, 0.328125 (0.607 sec)
17.20... logprob:  0.856094, 0.460938 (0.607 sec)
17.21... logprob:  1.012005, 0.734375 (0.607 sec)
=========================
Testing all batches

======================Test output======================
logprob:  1.004601, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979463e-03 [1.658638e-09] 
Layer 'conv1' biases: 7.874759e-09 [7.749440e-11] 
Layer 'conv2' weights[0]: 7.966402e-03 [2.811801e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.119306e-10] 
Layer 'conv3' weights[0]: 7.964741e-03 [2.516300e-09] 
Layer 'conv3' biases: 2.077826e-07 [1.465247e-09] 
Layer 'conv4' weights[0]: 7.997235e-03 [2.869969e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.420371e-08] 
Layer 'conv5' weights[0]: 7.996154e-03 [7.597101e-08] 
Layer 'conv5' biases: 9.999852e-01 [7.793282e-08] 
Layer 'fc6' weights[0]: 7.593030e-03 [1.347613e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.388214e-08] 
Layer 'fc7' weights[0]: 7.851649e-03 [2.341567e-07] 
Layer 'fc7' biases: 9.999909e-01 [2.300908e-07] 
Layer 'fc8' weights[0]: 5.290422e-04 [3.796101e-04] 
Layer 'fc8' biases: 3.409537e-04 [4.498649e-04] 
Train error last 38 batches: 0.702651
-------------------------------------------------------
Not saving because 1.004601 > 0.621584 (16.8: -0.01%)
======================================================= (4.459 sec)
17.22... logprob:  0.980590, 0.304688 (0.608 sec)
17.23... logprob:  0.585482, 0.265625 (0.607 sec)
17.24... logprob:  0.717367, 0.375000 (0.608 sec)
17.25... logprob:  0.710697, 0.695312 (0.607 sec)
17.26... logprob:  0.834881, 0.375000 (0.608 sec)
17.27... logprob:  0.734532, 0.625000 (0.608 sec)
17.28... logprob:  0.825875, 0.429688 (0.608 sec)
17.29... logprob:  0.867836, 0.687500 (0.608 sec)
17.30... logprob:  0.946343, 0.359375 (0.608 sec)
17.31... logprob:  0.700204, 0.687500 (0.607 sec)
17.32... logprob:  0.711087, 0.320312 (0.608 sec)
17.33... logprob:  0.653022, 0.304688 (0.607 sec)
17.34... logprob:  0.638833, 0.296875 (0.608 sec)
17.35... logprob:  0.661540, 0.375000 (0.607 sec)
17.36... logprob:  0.637993, 0.328125 (0.608 sec)
17.37... logprob:  0.630488, 0.320312 (0.607 sec)
17.38... logprob:  0.634323, 0.328125 (0.608 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.621241, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979460e-03 [5.357479e-10] 
Layer 'conv1' biases: 7.979370e-09 [8.548701e-12] 
Layer 'conv2' weights[0]: 7.966396e-03 [5.079768e-10] 
Layer 'conv2' biases: 1.000000e+00 [3.796803e-11] 
Layer 'conv3' weights[0]: 7.964729e-03 [4.883856e-10] 
Layer 'conv3' biases: 2.109828e-07 [1.098982e-10] 
Layer 'conv4' weights[0]: 7.997228e-03 [5.056220e-10] 
Layer 'conv4' biases: 9.999998e-01 [8.174898e-10] 
Layer 'conv5' weights[0]: 7.996154e-03 [4.414625e-09] 
Layer 'conv5' biases: 9.999849e-01 [4.554813e-09] 
Layer 'fc6' weights[0]: 7.593025e-03 [8.616834e-10] 
Layer 'fc6' biases: 9.999999e-01 [7.710845e-10] 
Layer 'fc7' weights[0]: 7.851577e-03 [1.429693e-08] 
Layer 'fc7' biases: 9.999904e-01 [1.285631e-08] 
Layer 'fc8' weights[0]: 4.467113e-04 [2.193358e-05] 
Layer 'fc8' biases: 8.905558e-05 [2.613707e-05] 
Train error last 38 batches: 0.699906
-------------------------------------------------------
Saved checkpoint to /data/ad6813/my-nets/saves/ConvNet__2014-06-27_21.30.06
======================================================= (4.927 sec)
18.1... logprob:  0.673112, 0.375000 (0.604 sec)
18.2... logprob:  0.661697, 0.320312 (0.604 sec)
18.3... logprob:  0.661316, 0.320312 (0.604 sec)
18.4... logprob:  0.650828, 0.335938 (0.604 sec)
18.5... logprob:  0.619016, 0.304688 (0.603 sec)
18.6... logprob:  0.648709, 0.351562 (0.604 sec)
18.7... logprob:  0.622495, 0.304688 (0.604 sec)
18.8... logprob:  0.612840, 0.296875 (0.603 sec)
18.9... logprob:  0.665713, 0.375000 (0.603 sec)
18.10... logprob:  0.650863, 0.328125 (0.603 sec)
18.11... logprob:  0.659707, 0.335938 (0.603 sec)
18.12... logprob:  0.658123, 0.351562 (0.604 sec)
18.13... logprob:  0.608547, 0.296875 (0.603 sec)
18.14... logprob:  0.659266, 0.359375 (0.604 sec)
18.15... logprob:  0.653297, 0.343750 (0.603 sec)
18.16... logprob:  0.586679, 0.273438 (0.603 sec)
18.17... logprob:  0.609948, 0.296875 (0.602 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.621149, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979452e-03 [5.708422e-10] 
Layer 'conv1' biases: 7.986404e-09 [5.440108e-12] 
Layer 'conv2' weights[0]: 7.966386e-03 [4.865259e-10] 
Layer 'conv2' biases: 1.000000e+00 [3.716615e-11] 
Layer 'conv3' weights[0]: 7.964724e-03 [4.490876e-10] 
Layer 'conv3' biases: 2.113594e-07 [1.133841e-10] 
Layer 'conv4' weights[0]: 7.997219e-03 [4.549346e-10] 
Layer 'conv4' biases: 9.999998e-01 [8.793110e-10] 
Layer 'conv5' weights[0]: 7.996145e-03 [4.764713e-09] 
Layer 'conv5' biases: 9.999849e-01 [4.889275e-09] 
Layer 'fc6' weights[0]: 7.593016e-03 [9.070876e-10] 
Layer 'fc6' biases: 9.999999e-01 [8.221254e-10] 
Layer 'fc7' weights[0]: 7.851507e-03 [1.510567e-08] 
Layer 'fc7' biases: 9.999903e-01 [1.369244e-08] 
Layer 'fc8' weights[0]: 4.455122e-04 [2.246394e-05] 
Layer 'fc8' biases: 8.107233e-05 [2.677805e-05] 
Train error last 38 batches: 0.699815
-------------------------------------------------------
Saved checkpoint to /data/ad6813/my-nets/saves/ConvNet__2014-06-27_21.30.06
======================================================= (4.893 sec)
18.18... logprob:  0.680446, 0.390625 (0.608 sec)
18.19... logprob:  0.672963, 0.328125 (0.607 sec)
18.20... logprob:  0.853582, 0.460938 (0.608 sec)
18.21... logprob:  0.996669, 0.734375 (0.607 sec)
18.22... logprob:  0.959908, 0.304688 (0.608 sec)
18.23... logprob:  0.586512, 0.265625 (0.607 sec)
18.24... logprob:  0.718981, 0.375000 (0.608 sec)
18.25... logprob:  0.708219, 0.695312 (0.607 sec)
18.26... logprob:  0.825823, 0.375000 (0.608 sec)
18.27... logprob:  0.729033, 0.625000 (0.608 sec)
18.28... logprob:  0.813071, 0.429688 (0.608 sec)
18.29... logprob:  0.851291, 0.687500 (0.607 sec)
18.30... logprob:  0.922733, 0.359375 (0.608 sec)
18.31... logprob:  0.699278, 0.687500 (0.607 sec)
18.32... logprob:  0.706576, 0.320312 (0.608 sec)
18.33... logprob:  0.650021, 0.304688 (0.607 sec)
18.34... logprob:  0.634736, 0.296875 (0.607 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.627568, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979442e-03 [5.948080e-10] 
Layer 'conv1' biases: 8.118557e-09 [1.295459e-11] 
Layer 'conv2' weights[0]: 7.966380e-03 [7.213031e-10] 
Layer 'conv2' biases: 1.000000e+00 [1.101867e-10] 
Layer 'conv3' weights[0]: 7.964716e-03 [7.168098e-10] 
Layer 'conv3' biases: 2.151438e-07 [3.390566e-10] 
Layer 'conv4' weights[0]: 7.997214e-03 [8.069615e-10] 
Layer 'conv4' biases: 9.999998e-01 [3.347548e-09] 
Layer 'conv5' weights[0]: 7.996135e-03 [1.816892e-08] 
Layer 'conv5' biases: 9.999848e-01 [1.874682e-08] 
Layer 'fc6' weights[0]: 7.593010e-03 [3.098618e-09] 
Layer 'fc6' biases: 9.999999e-01 [3.135319e-09] 
Layer 'fc7' weights[0]: 7.851426e-03 [5.331426e-08] 
Layer 'fc7' biases: 9.999899e-01 [5.212284e-08] 
Layer 'fc8' weights[0]: 4.417598e-04 [8.089339e-05] 
Layer 'fc8' biases: 5.712577e-05 [9.698285e-05] 
Train error last 38 batches: 0.696746
-------------------------------------------------------
Not saving because 0.627568 > 0.621149 (18.17: -0.01%)
======================================================= (4.420 sec)
18.35... logprob:  0.661673, 0.375000 (0.607 sec)
18.36... logprob:  0.639401, 0.328125 (0.608 sec)
18.37... logprob:  0.631397, 0.320312 (0.607 sec)
18.38... logprob:  0.634676, 0.328125 (0.608 sec)
19.1... logprob:  0.673815, 0.375000 (0.608 sec)
19.2... logprob:  0.661706, 0.320312 (0.609 sec)
19.3... logprob:  0.659724, 0.320312 (0.608 sec)
19.4... logprob:  0.649419, 0.335938 (0.608 sec)
19.5... logprob:  0.617892, 0.304688 (0.608 sec)
19.6... logprob:  0.649080, 0.351562 (0.611 sec)
19.7... logprob:  0.623843, 0.304688 (0.608 sec)
19.8... logprob:  0.613527, 0.296875 (0.609 sec)
19.9... logprob:  0.665494, 0.375000 (0.609 sec)
19.10... logprob:  0.649989, 0.328125 (0.609 sec)
19.11... logprob:  0.657816, 0.335938 (0.610 sec)
19.12... logprob:  0.656614, 0.351562 (0.608 sec)
19.13... logprob:  0.608246, 0.296875 (0.607 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.621345, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979437e-03 [5.348879e-10] 
Layer 'conv1' biases: 8.119506e-09 [5.564324e-12] 
Layer 'conv2' weights[0]: 7.966370e-03 [4.603796e-10] 
Layer 'conv2' biases: 1.000000e+00 [2.153145e-11] 
Layer 'conv3' weights[0]: 7.964704e-03 [4.278610e-10] 
Layer 'conv3' biases: 2.154624e-07 [6.180512e-11] 
Layer 'conv4' weights[0]: 7.997209e-03 [4.262048e-10] 
Layer 'conv4' biases: 9.999998e-01 [2.005911e-10] 
Layer 'conv5' weights[0]: 7.996123e-03 [1.145255e-09] 
Layer 'conv5' biases: 9.999847e-01 [1.073384e-09] 
Layer 'fc6' weights[0]: 7.593004e-03 [4.220270e-10] 
Layer 'fc6' biases: 9.999999e-01 [1.781450e-10] 
Layer 'fc7' weights[0]: 7.851363e-03 [5.237757e-09] 
Layer 'fc7' biases: 9.999898e-01 [2.860424e-09] 
Layer 'fc8' weights[0]: 4.462216e-04 [4.712017e-06] 
Layer 'fc8' biases: 9.119717e-05 [5.649523e-06] 
Train error last 38 batches: 0.696667
-------------------------------------------------------
Not saving because 0.621345 > 0.621149 (18.17: -0.01%)
======================================================= (4.518 sec)
19.14... logprob:  0.660754, 0.359375 (0.607 sec)
19.15... logprob:  0.654470, 0.343750 (0.607 sec)
19.16... logprob:  0.586641, 0.273438 (0.608 sec)
19.17... logprob:  0.609729, 0.296875 (0.607 sec)
19.18... logprob:  0.681096, 0.390625 (0.608 sec)
19.19... logprob:  0.672939, 0.328125 (0.607 sec)
19.20... logprob:  0.849566, 0.460938 (0.608 sec)
19.21... logprob:  0.981227, 0.734375 (0.607 sec)
19.22... logprob:  0.940178, 0.304688 (0.608 sec)
19.23... logprob:  0.587527, 0.265625 (0.607 sec)
19.24... logprob:  0.720353, 0.375000 (0.608 sec)
19.25... logprob:  0.705665, 0.695312 (0.607 sec)
19.26... logprob:  0.817237, 0.375000 (0.608 sec)
19.27... logprob:  0.723985, 0.625000 (0.608 sec)
19.28... logprob:  0.801633, 0.429688 (0.608 sec)
19.29... logprob:  0.836085, 0.687500 (0.607 sec)
19.30... logprob:  0.901158, 0.359375 (0.608 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.697854, 0.687500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979432e-03 [1.208697e-09] 
Layer 'conv1' biases: 8.231068e-09 [3.894707e-11] 
Layer 'conv2' weights[0]: 7.966364e-03 [1.854461e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.307789e-10] 
Layer 'conv3' weights[0]: 7.964694e-03 [1.770118e-09] 
Layer 'conv3' biases: 2.187262e-07 [1.007442e-09] 
Layer 'conv4' weights[0]: 7.997205e-03 [2.110864e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.046568e-08] 
Layer 'conv5' weights[0]: 7.996101e-03 [5.811872e-08] 
Layer 'conv5' biases: 9.999846e-01 [6.045499e-08] 
Layer 'fc6' weights[0]: 7.592994e-03 [9.710182e-09] 
Layer 'fc6' biases: 9.999999e-01 [9.818321e-09] 
Layer 'fc7' weights[0]: 7.851300e-03 [1.650387e-07] 
Layer 'fc7' biases: 9.999894e-01 [1.626814e-07] 
Layer 'fc8' weights[0]: 4.379397e-04 [2.170468e-04] 
Layer 'fc8' biases: 9.054405e-06 [2.614917e-04] 
Train error last 38 batches: 0.694083
-------------------------------------------------------
Not saving because 0.697854 > 0.621149 (18.17: -0.01%)
======================================================= (4.413 sec)
19.31... logprob:  0.697843, 0.687500 (0.607 sec)
19.32... logprob:  0.701901, 0.320312 (0.608 sec)
19.33... logprob:  0.647246, 0.304688 (0.607 sec)
19.34... logprob:  0.631175, 0.296875 (0.607 sec)
19.35... logprob:  0.661946, 0.375000 (0.607 sec)
19.36... logprob:  0.640773, 0.328125 (0.608 sec)
19.37... logprob:  0.632211, 0.320312 (0.607 sec)
19.38... logprob:  0.634934, 0.328125 (0.608 sec)
20.1... logprob:  0.674204, 0.375000 (0.609 sec)
20.2... logprob:  0.661244, 0.320312 (0.608 sec)
20.3... logprob:  0.657802, 0.320312 (0.608 sec)
20.4... logprob:  0.648060, 0.335938 (0.608 sec)
20.5... logprob:  0.616964, 0.304688 (0.607 sec)
20.6... logprob:  0.649554, 0.351562 (0.608 sec)
20.7... logprob:  0.625109, 0.304688 (0.608 sec)
20.8... logprob:  0.614099, 0.296875 (0.608 sec)
20.9... logprob:  0.665387, 0.375000 (0.608 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644133, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979425e-03 [5.390318e-10] 
Layer 'conv1' biases: 8.244999e-09 [6.005951e-12] 
Layer 'conv2' weights[0]: 7.966355e-03 [5.287281e-10] 
Layer 'conv2' biases: 1.000000e+00 [5.069070e-11] 
Layer 'conv3' weights[0]: 7.964687e-03 [4.953826e-10] 
Layer 'conv3' biases: 2.193538e-07 [1.493539e-10] 
Layer 'conv4' weights[0]: 7.997197e-03 [5.325923e-10] 
Layer 'conv4' biases: 9.999998e-01 [1.373221e-09] 
Layer 'conv5' weights[0]: 7.996088e-03 [7.327362e-09] 
Layer 'conv5' biases: 9.999846e-01 [7.531012e-09] 
Layer 'fc6' weights[0]: 7.592988e-03 [1.282872e-09] 
Layer 'fc6' biases: 9.999999e-01 [1.235457e-09] 
Layer 'fc7' weights[0]: 7.851235e-03 [2.161958e-08] 
Layer 'fc7' biases: 9.999893e-01 [2.051821e-08] 
Layer 'fc8' weights[0]: 4.390489e-04 [3.458824e-05] 
Layer 'fc8' biases: 3.310216e-05 [4.174761e-05] 
Train error last 38 batches: 0.693773
-------------------------------------------------------
Not saving because 0.644133 > 0.621149 (18.17: -0.01%)
======================================================= (4.436 sec)
20.10... logprob:  0.649382, 0.328125 (0.608 sec)
20.11... logprob:  0.656347, 0.335938 (0.608 sec)
20.12... logprob:  0.655432, 0.351562 (0.608 sec)
20.13... logprob:  0.608168, 0.296875 (0.607 sec)
20.14... logprob:  0.662081, 0.359375 (0.608 sec)
20.15... logprob:  0.655306, 0.343750 (0.607 sec)
20.16... logprob:  0.586631, 0.273438 (0.608 sec)
20.17... logprob:  0.609642, 0.296875 (0.608 sec)
20.18... logprob:  0.681471, 0.390625 (0.608 sec)
20.19... logprob:  0.672448, 0.328125 (0.607 sec)
20.20... logprob:  0.844838, 0.460938 (0.608 sec)
20.21... logprob:  0.966245, 0.734375 (0.607 sec)
20.22... logprob:  0.921610, 0.304688 (0.608 sec)
20.23... logprob:  0.588480, 0.265625 (0.608 sec)
20.24... logprob:  0.721427, 0.375000 (0.608 sec)
20.25... logprob:  0.703038, 0.695312 (0.607 sec)
20.26... logprob:  0.809091, 0.375000 (0.608 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.730481, 0.687500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979419e-03 [1.168873e-09] 
Layer 'conv1' biases: 8.316411e-09 [3.578590e-11] 
Layer 'conv2' weights[0]: 7.966350e-03 [1.490023e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.739429e-10] 
Layer 'conv3' weights[0]: 7.964683e-03 [1.412780e-09] 
Layer 'conv3' biases: 2.214976e-07 [8.179594e-10] 
Layer 'conv4' weights[0]: 7.997189e-03 [1.658176e-09] 
Layer 'conv4' biases: 9.999998e-01 [8.355795e-09] 
Layer 'conv5' weights[0]: 7.996088e-03 [4.541854e-08] 
Layer 'conv5' biases: 9.999844e-01 [4.699055e-08] 
Layer 'fc6' weights[0]: 7.592979e-03 [7.470867e-09] 
Layer 'fc6' biases: 9.999999e-01 [7.618439e-09] 
Layer 'fc7' weights[0]: 7.851171e-03 [1.284119e-07] 
Layer 'fc7' biases: 9.999891e-01 [1.263327e-07] 
Layer 'fc8' weights[0]: 4.377680e-04 [1.840681e-04] 
Layer 'fc8' biases: 2.740228e-05 [2.227865e-04] 
Train error last 38 batches: 0.692499
-------------------------------------------------------
Not saving because 0.730481 > 0.621149 (18.17: -0.01%)
======================================================= (4.425 sec)
20.27... logprob:  0.719355, 0.625000 (0.611 sec)
20.28... logprob:  0.791418, 0.429688 (0.608 sec)
20.29... logprob:  0.822169, 0.687500 (0.608 sec)
20.30... logprob:  0.881531, 0.359375 (0.608 sec)
20.31... logprob:  0.695997, 0.687500 (0.607 sec)
20.32... logprob:  0.697179, 0.320312 (0.608 sec)
20.33... logprob:  0.644683, 0.304688 (0.607 sec)
20.34... logprob:  0.628082, 0.296875 (0.607 sec)
20.35... logprob:  0.662330, 0.375000 (0.607 sec)
20.36... logprob:  0.642074, 0.328125 (0.608 sec)
20.37... logprob:  0.632908, 0.320312 (0.607 sec)
20.38... logprob:  0.635102, 0.328125 (0.608 sec)
21.1... logprob:  0.674346, 0.375000 (0.608 sec)
21.2... logprob:  0.660473, 0.320312 (0.608 sec)
21.3... logprob:  0.655743, 0.320312 (0.608 sec)
21.4... logprob:  0.646799, 0.335938 (0.608 sec)
21.5... logprob:  0.616236, 0.304688 (0.608 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.621351, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979413e-03 [4.776392e-10] 
Layer 'conv1' biases: 8.371450e-09 [4.883090e-12] 
Layer 'conv2' weights[0]: 7.966344e-03 [4.432669e-10] 
Layer 'conv2' biases: 1.000000e+00 [2.858148e-11] 
Layer 'conv3' weights[0]: 7.964674e-03 [4.251978e-10] 
Layer 'conv3' biases: 2.230269e-07 [8.641521e-11] 
Layer 'conv4' weights[0]: 7.997182e-03 [4.411560e-10] 
Layer 'conv4' biases: 9.999998e-01 [8.401633e-10] 
Layer 'conv5' weights[0]: 7.996087e-03 [4.472975e-09] 
Layer 'conv5' biases: 9.999843e-01 [4.598328e-09] 
Layer 'fc6' weights[0]: 7.592971e-03 [8.367878e-10] 
Layer 'fc6' biases: 9.999999e-01 [7.456981e-10] 
Layer 'fc7' weights[0]: 7.851123e-03 [1.381035e-08] 
Layer 'fc7' biases: 9.999889e-01 [1.237048e-08] 
Layer 'fc8' weights[0]: 4.431974e-04 [2.026593e-05] 
Layer 'fc8' biases: 8.050248e-05 [2.460097e-05] 
Train error last 38 batches: 0.690848
-------------------------------------------------------
Not saving because 0.621351 > 0.621149 (18.17: -0.01%)
======================================================= (4.441 sec)
21.6... logprob:  0.650099, 0.351562 (0.603 sec)
21.7... logprob:  0.626251, 0.304688 (0.604 sec)
21.8... logprob:  0.614538, 0.296875 (0.604 sec)
21.9... logprob:  0.665371, 0.375000 (0.604 sec)
21.10... logprob:  0.648982, 0.328125 (0.603 sec)
21.11... logprob:  0.655196, 0.335938 (0.604 sec)
21.12... logprob:  0.654492, 0.351562 (0.604 sec)
21.13... logprob:  0.608226, 0.296875 (0.604 sec)
21.14... logprob:  0.663241, 0.359375 (0.604 sec)
21.15... logprob:  0.655863, 0.343750 (0.604 sec)
21.16... logprob:  0.586630, 0.273438 (0.604 sec)
21.17... logprob:  0.609634, 0.296875 (0.604 sec)
21.18... logprob:  0.681668, 0.390625 (0.604 sec)
21.19... logprob:  0.671705, 0.328125 (0.606 sec)
21.20... logprob:  0.839887, 0.460938 (0.604 sec)
21.21... logprob:  0.952018, 0.734375 (0.604 sec)
21.22... logprob:  0.904281, 0.304688 (0.603 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.621976, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979409e-03 [1.233561e-09] 
Layer 'conv1' biases: 8.422404e-09 [3.757077e-11] 
Layer 'conv2' weights[0]: 7.966338e-03 [1.812646e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.407549e-10] 
Layer 'conv3' weights[0]: 7.964670e-03 [1.733039e-09] 
Layer 'conv3' biases: 2.246038e-07 [1.051309e-09] 
Layer 'conv4' weights[0]: 7.997173e-03 [2.065190e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.095781e-08] 
Layer 'conv5' weights[0]: 7.996080e-03 [6.155155e-08] 
Layer 'conv5' biases: 9.999843e-01 [6.437559e-08] 
Layer 'fc6' weights[0]: 7.592965e-03 [1.010032e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.026904e-08] 
Layer 'fc7' weights[0]: 7.851047e-03 [1.728110e-07] 
Layer 'fc7' biases: 9.999886e-01 [1.704207e-07] 
Layer 'fc8' weights[0]: 4.423028e-04 [2.020342e-04] 
Layer 'fc8' biases: 7.598223e-05 [2.456249e-04] 
Train error last 38 batches: 0.689909
-------------------------------------------------------
Not saving because 0.621976 > 0.621149 (18.17: -0.01%)
======================================================= (4.385 sec)
21.23... logprob:  0.589342, 0.265625 (0.604 sec)
21.24... logprob:  0.722193, 0.375000 (0.603 sec)
21.25... logprob:  0.700364, 0.695312 (0.603 sec)
21.26... logprob:  0.801388, 0.375000 (0.604 sec)
21.27... logprob:  0.715104, 0.625000 (0.604 sec)
21.28... logprob:  0.782291, 0.429688 (0.603 sec)
21.29... logprob:  0.809466, 0.687500 (0.604 sec)
21.30... logprob:  0.863727, 0.359375 (0.604 sec)
21.31... logprob:  0.693838, 0.687500 (0.603 sec)
21.32... logprob:  0.692507, 0.320312 (0.604 sec)
21.33... logprob:  0.642317, 0.304688 (0.603 sec)
21.34... logprob:  0.625398, 0.296875 (0.603 sec)
21.35... logprob:  0.662798, 0.375000 (0.603 sec)
21.36... logprob:  0.643281, 0.328125 (0.603 sec)
21.37... logprob:  0.633482, 0.320312 (0.603 sec)
21.38... logprob:  0.635191, 0.328125 (0.604 sec)
22.1... logprob:  0.674304, 0.375000 (0.605 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.657804, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979400e-03 [7.253671e-10] 
Layer 'conv1' biases: 8.484577e-09 [9.659471e-12] 
Layer 'conv2' weights[0]: 7.966329e-03 [6.235439e-10] 
Layer 'conv2' biases: 1.000000e+00 [8.426607e-11] 
Layer 'conv3' weights[0]: 7.964663e-03 [5.865603e-10] 
Layer 'conv3' biases: 2.264962e-07 [2.548864e-10] 
Layer 'conv4' weights[0]: 7.997171e-03 [6.720394e-10] 
Layer 'conv4' biases: 9.999998e-01 [2.543107e-09] 
Layer 'conv5' weights[0]: 7.996073e-03 [1.349925e-08] 
Layer 'conv5' biases: 9.999842e-01 [1.387621e-08] 
Layer 'fc6' weights[0]: 7.592954e-03 [2.248175e-09] 
Layer 'fc6' biases: 9.999999e-01 [2.235040e-09] 
Layer 'fc7' weights[0]: 7.850986e-03 [3.801142e-08] 
Layer 'fc7' biases: 9.999882e-01 [3.705270e-08] 
Layer 'fc8' weights[0]: 4.370125e-04 [6.126679e-05] 
Layer 'fc8' biases: 1.956343e-05 [7.478746e-05] 
Train error last 38 batches: 0.688272
-------------------------------------------------------
Not saving because 0.657804 > 0.621149 (18.17: -0.01%)
======================================================= (4.402 sec)
22.2... logprob:  0.659513, 0.320312 (0.604 sec)
22.3... logprob:  0.653674, 0.320312 (0.604 sec)
22.4... logprob:  0.645657, 0.335938 (0.604 sec)
22.5... logprob:  0.615687, 0.304688 (0.604 sec)
22.6... logprob:  0.650682, 0.351562 (0.603 sec)
22.7... logprob:  0.627249, 0.304688 (0.604 sec)
22.8... logprob:  0.614844, 0.296875 (0.603 sec)
22.9... logprob:  0.665429, 0.375000 (0.604 sec)
22.10... logprob:  0.648737, 0.328125 (0.604 sec)
22.11... logprob:  0.654275, 0.335938 (0.604 sec)
22.12... logprob:  0.653731, 0.351562 (0.605 sec)
22.13... logprob:  0.608365, 0.296875 (0.603 sec)
22.14... logprob:  0.664245, 0.359375 (0.603 sec)
22.15... logprob:  0.656202, 0.343750 (0.603 sec)
22.16... logprob:  0.586634, 0.273438 (0.603 sec)
22.17... logprob:  0.609676, 0.296875 (0.603 sec)
22.18... logprob:  0.681756, 0.390625 (0.603 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.668577, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979392e-03 [7.017471e-10] 
Layer 'conv1' biases: 8.495540e-09 [1.094320e-11] 
Layer 'conv2' weights[0]: 7.966324e-03 [6.508837e-10] 
Layer 'conv2' biases: 1.000000e+00 [9.193579e-11] 
Layer 'conv3' weights[0]: 7.964658e-03 [6.028702e-10] 
Layer 'conv3' biases: 2.268662e-07 [2.735624e-10] 
Layer 'conv4' weights[0]: 7.997162e-03 [6.592981e-10] 
Layer 'conv4' biases: 9.999998e-01 [2.594570e-09] 
Layer 'conv5' weights[0]: 7.996069e-03 [1.366929e-08] 
Layer 'conv5' biases: 9.999842e-01 [1.405115e-08] 
Layer 'fc6' weights[0]: 7.592946e-03 [2.259830e-09] 
Layer 'fc6' biases: 9.999999e-01 [2.245756e-09] 
Layer 'fc7' weights[0]: 7.850919e-03 [3.815847e-08] 
Layer 'fc7' biases: 9.999881e-01 [3.721393e-08] 
Layer 'fc8' weights[0]: 4.367229e-04 [6.195671e-05] 
Layer 'fc8' biases: 1.048291e-05 [7.566571e-05] 
Train error last 38 batches: 0.688190
-------------------------------------------------------
Not saving because 0.668577 > 0.621149 (18.17: -0.01%)
======================================================= (4.410 sec)
22.19... logprob:  0.670845, 0.328125 (0.608 sec)
22.20... logprob:  0.834994, 0.460938 (0.603 sec)
22.21... logprob:  0.938673, 0.734375 (0.604 sec)
22.22... logprob:  0.888192, 0.304688 (0.603 sec)
22.23... logprob:  0.590096, 0.265625 (0.604 sec)
22.24... logprob:  0.722667, 0.375000 (0.603 sec)
22.25... logprob:  0.697681, 0.695312 (0.604 sec)
22.26... logprob:  0.794134, 0.375000 (0.604 sec)
22.27... logprob:  0.711205, 0.625000 (0.605 sec)
22.28... logprob:  0.774131, 0.429688 (0.604 sec)
22.29... logprob:  0.797894, 0.687500 (0.604 sec)
22.30... logprob:  0.847619, 0.359375 (0.603 sec)
22.31... logprob:  0.691453, 0.312500 (0.603 sec)
22.32... logprob:  0.687963, 0.320312 (0.604 sec)
22.33... logprob:  0.640135, 0.304688 (0.603 sec)
22.34... logprob:  0.623072, 0.296875 (0.603 sec)
22.35... logprob:  0.663325, 0.375000 (0.603 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.638179, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979388e-03 [6.430149e-10] 
Layer 'conv1' biases: 8.597413e-09 [5.476745e-12] 
Layer 'conv2' weights[0]: 7.966318e-03 [5.370193e-10] 
Layer 'conv2' biases: 1.000000e+00 [4.515774e-11] 
Layer 'conv3' weights[0]: 7.964650e-03 [4.799008e-10] 
Layer 'conv3' biases: 2.297915e-07 [1.353736e-10] 
Layer 'conv4' weights[0]: 7.997160e-03 [4.837398e-10] 
Layer 'conv4' biases: 9.999998e-01 [9.930280e-10] 
Layer 'conv5' weights[0]: 7.996064e-03 [5.170601e-09] 
Layer 'conv5' biases: 9.999840e-01 [5.294121e-09] 
Layer 'fc6' weights[0]: 7.592934e-03 [9.247391e-10] 
Layer 'fc6' biases: 9.999999e-01 [8.411536e-10] 
Layer 'fc7' weights[0]: 7.850846e-03 [1.529479e-08] 
Layer 'fc7' biases: 9.999878e-01 [1.390590e-08] 
Layer 'fc8' weights[0]: 4.376460e-04 [2.341280e-05] 
Layer 'fc8' biases: 4.096490e-05 [2.873276e-05] 
Train error last 38 batches: 0.685702
-------------------------------------------------------
Not saving because 0.638179 > 0.621149 (18.17: -0.01%)
======================================================= (4.433 sec)
22.36... logprob:  0.644382, 0.328125 (0.603 sec)
22.37... logprob:  0.633933, 0.320312 (0.604 sec)
22.38... logprob:  0.635214, 0.328125 (0.604 sec)
23.1... logprob:  0.674129, 0.375000 (0.605 sec)
23.2... logprob:  0.658449, 0.320312 (0.604 sec)
23.3... logprob:  0.651672, 0.320312 (0.604 sec)
23.4... logprob:  0.644641, 0.335938 (0.604 sec)
23.5... logprob:  0.615293, 0.304688 (0.604 sec)
23.6... logprob:  0.651276, 0.351562 (0.604 sec)
23.7... logprob:  0.628095, 0.304688 (0.604 sec)
23.8... logprob:  0.615025, 0.296875 (0.604 sec)
23.9... logprob:  0.665544, 0.375000 (0.604 sec)
23.10... logprob:  0.648601, 0.328125 (0.603 sec)
23.11... logprob:  0.653519, 0.335938 (0.604 sec)
23.12... logprob:  0.653102, 0.351562 (0.604 sec)
23.13... logprob:  0.608554, 0.296875 (0.604 sec)
23.14... logprob:  0.665112, 0.359375 (0.604 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.646586, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979384e-03 [6.742773e-10] 
Layer 'conv1' biases: 8.605078e-09 [1.116849e-11] 
Layer 'conv2' weights[0]: 7.966313e-03 [6.491431e-10] 
Layer 'conv2' biases: 1.000000e+00 [8.749730e-11] 
Layer 'conv3' weights[0]: 7.964644e-03 [6.227831e-10] 
Layer 'conv3' biases: 2.301690e-07 [2.660313e-10] 
Layer 'conv4' weights[0]: 7.997154e-03 [6.932795e-10] 
Layer 'conv4' biases: 9.999998e-01 [2.538981e-09] 
Layer 'conv5' weights[0]: 7.996051e-03 [1.325929e-08] 
Layer 'conv5' biases: 9.999840e-01 [1.361791e-08] 
Layer 'fc6' weights[0]: 7.592927e-03 [2.176334e-09] 
Layer 'fc6' biases: 9.999999e-01 [2.160403e-09] 
Layer 'fc7' weights[0]: 7.850783e-03 [3.674615e-08] 
Layer 'fc7' biases: 9.999878e-01 [3.578744e-08] 
Layer 'fc8' weights[0]: 4.369676e-04 [5.855777e-05] 
Layer 'fc8' biases: 3.077168e-05 [7.190172e-05] 
Train error last 38 batches: 0.685655
-------------------------------------------------------
Not saving because 0.646586 > 0.621149 (18.17: -0.01%)
======================================================= (4.406 sec)
23.15... logprob:  0.656376, 0.343750 (0.604 sec)
23.16... logprob:  0.586645, 0.273438 (0.603 sec)
23.17... logprob:  0.609749, 0.296875 (0.604 sec)
23.18... logprob:  0.681781, 0.390625 (0.604 sec)
23.19... logprob:  0.669948, 0.328125 (0.604 sec)
23.20... logprob:  0.830306, 0.460938 (0.603 sec)
23.21... logprob:  0.926239, 0.734375 (0.604 sec)
23.22... logprob:  0.873296, 0.304688 (0.603 sec)
23.23... logprob:  0.590739, 0.265625 (0.603 sec)
23.24... logprob:  0.722880, 0.375000 (0.603 sec)
23.25... logprob:  0.695024, 0.695312 (0.603 sec)
23.26... logprob:  0.787330, 0.375000 (0.604 sec)
23.27... logprob:  0.707628, 0.625000 (0.604 sec)
23.28... logprob:  0.766830, 0.429688 (0.603 sec)
23.29... logprob:  0.787366, 0.687500 (0.604 sec)
23.30... logprob:  0.833069, 0.359375 (0.603 sec)
23.31... logprob:  0.688923, 0.312500 (0.604 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.671783, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979377e-03 [8.812324e-10] 
Layer 'conv1' biases: 8.697111e-09 [3.551589e-11] 
Layer 'conv2' weights[0]: 7.966303e-03 [1.422272e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.289798e-10] 
Layer 'conv3' weights[0]: 7.964636e-03 [1.251747e-09] 
Layer 'conv3' biases: 2.327355e-07 [6.255752e-10] 
Layer 'conv4' weights[0]: 7.997149e-03 [1.420038e-09] 
Layer 'conv4' biases: 9.999998e-01 [6.093998e-09] 
Layer 'conv5' weights[0]: 7.996048e-03 [3.175491e-08] 
Layer 'conv5' biases: 9.999839e-01 [3.259943e-08] 
Layer 'fc6' weights[0]: 7.592921e-03 [5.069995e-09] 
Layer 'fc6' biases: 9.999999e-01 [5.154170e-09] 
Layer 'fc7' weights[0]: 7.850714e-03 [8.676336e-08] 
Layer 'fc7' biases: 9.999875e-01 [8.546098e-08] 
Layer 'fc8' weights[0]: 4.608823e-04 [1.474429e-04] 
Layer 'fc8' biases: 1.772420e-04 [1.818513e-04] 
Train error last 38 batches: 0.683557
-------------------------------------------------------
Not saving because 0.671783 > 0.621149 (18.17: -0.01%)
======================================================= (4.405 sec)
23.32... logprob:  0.683603, 0.320312 (0.604 sec)
23.33... logprob:  0.638125, 0.304688 (0.603 sec)
23.34... logprob:  0.621056, 0.296875 (0.604 sec)
23.35... logprob:  0.663893, 0.375000 (0.603 sec)
23.36... logprob:  0.645372, 0.328125 (0.604 sec)
23.37... logprob:  0.634271, 0.320312 (0.608 sec)
23.38... logprob:  0.635186, 0.328125 (0.606 sec)
24.1... logprob:  0.673862, 0.375000 (0.606 sec)
24.2... logprob:  0.657344, 0.320312 (0.606 sec)
24.3... logprob:  0.649781, 0.320312 (0.606 sec)
24.4... logprob:  0.643747, 0.335938 (0.605 sec)
24.5... logprob:  0.615027, 0.304688 (0.606 sec)
24.6... logprob:  0.651861, 0.351562 (0.605 sec)
24.7... logprob:  0.628795, 0.304688 (0.606 sec)
24.8... logprob:  0.615099, 0.296875 (0.605 sec)
24.9... logprob:  0.665703, 0.375000 (0.606 sec)
24.10... logprob:  0.648542, 0.328125 (0.605 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.628231, 0.312500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979372e-03 [6.030656e-10] 
Layer 'conv1' biases: 8.708534e-09 [2.027686e-11] 
Layer 'conv2' weights[0]: 7.966296e-03 [8.089237e-10] 
Layer 'conv2' biases: 1.000000e+00 [1.146113e-10] 
Layer 'conv3' weights[0]: 7.964630e-03 [7.643982e-10] 
Layer 'conv3' biases: 2.332990e-07 [3.108526e-10] 
Layer 'conv4' weights[0]: 7.997140e-03 [8.445678e-10] 
Layer 'conv4' biases: 9.999998e-01 [2.966895e-09] 
Layer 'conv5' weights[0]: 7.996045e-03 [1.538410e-08] 
Layer 'conv5' biases: 9.999839e-01 [1.582999e-08] 
Layer 'fc6' weights[0]: 7.592915e-03 [2.471281e-09] 
Layer 'fc6' biases: 9.999999e-01 [2.466985e-09] 
Layer 'fc7' weights[0]: 7.850647e-03 [4.176936e-08] 
Layer 'fc7' biases: 9.999875e-01 [4.082293e-08] 
Layer 'fc8' weights[0]: 4.479918e-04 [6.989305e-05] 
Layer 'fc8' biases: 1.211444e-04 [8.627819e-05] 
Train error last 38 batches: 0.683307
-------------------------------------------------------
Not saving because 0.628231 > 0.621149 (18.17: -0.01%)
======================================================= (4.412 sec)
24.11... logprob:  0.652881, 0.335938 (0.604 sec)
24.12... logprob:  0.652572, 0.351562 (0.604 sec)
24.13... logprob:  0.608772, 0.296875 (0.604 sec)
24.14... logprob:  0.665862, 0.359375 (0.604 sec)
24.15... logprob:  0.656426, 0.343750 (0.604 sec)
24.16... logprob:  0.586666, 0.273438 (0.604 sec)
24.17... logprob:  0.609843, 0.296875 (0.604 sec)
24.18... logprob:  0.681773, 0.390625 (0.604 sec)
24.19... logprob:  0.669060, 0.328125 (0.604 sec)
24.20... logprob:  0.825889, 0.460938 (0.604 sec)
24.21... logprob:  0.914694, 0.734375 (0.604 sec)
24.22... logprob:  0.859522, 0.304688 (0.604 sec)
24.23... logprob:  0.591272, 0.265625 (0.604 sec)
24.24... logprob:  0.722869, 0.375000 (0.604 sec)
24.25... logprob:  0.692418, 0.304688 (0.603 sec)
24.26... logprob:  0.780972, 0.375000 (0.604 sec)
24.27... logprob:  0.704345, 0.625000 (0.604 sec)
=========================
Testing all batches
