nohup: ignoring input
Initialized data layer 'data', producing 196608 outputs
Initialized data layer 'labels', producing 1 outputs
Initialized convolutional layer 'conv1', producing 63x63 48-channel output
Initialized max-pooling layer 'pool1', producing 31x31 48-channel output
Initialized cross-map response-normalization layer 'rnorm1', producing 31x31 48-channel output
Initialized convolutional layer 'conv2', producing 31x31 128-channel output
Initialized max-pooling layer 'pool2', producing 15x15 128-channel output
Initialized cross-map response-normalization layer 'rnorm2', producing 15x15 128-channel output
Initialized convolutional layer 'conv3', producing 15x15 192-channel output
Initialized convolutional layer 'conv4', producing 15x15 192-channel output
Initialized convolutional layer 'conv5', producing 15x15 128-channel output
Initialized max-pooling layer 'pool5', producing 7x7 128-channel output
Initialized fully-connected layer 'fc6', producing 4096 outputs
Initialized fully-connected layer 'fc7', producing 4096 outputs
Initialized fully-connected layer 'fc8', producing 2 outputs
Initialized softmax layer 'probs', producing 2 outputs
Initialized logistic regression cost 'logprob'
Initialized neuron layer 'conv1_neuron', producing 190512 outputs
Initialized neuron layer 'conv2_neuron', producing 123008 outputs
Initialized neuron layer 'conv3_neuron', producing 43200 outputs
Initialized neuron layer 'conv4_neuron', producing 43200 outputs
Initialized neuron layer 'conv5_neuron', producing 28800 outputs
Initialized neuron layer 'fc6_neuron', producing 4096 outputs
Initialized neuron layer 'fc7_neuron', producing 4096 outputs
=========================
Importing _ConvNet C++ module
=========================
Training ConvNet
Always write savepoints, regardless of test err improvement: 0     [DEFAULT]
Check gradients and quit?                                  : 0     [DEFAULT]
Compress checkpoints?                                      : 0     [DEFAULT]
Conserve GPU memory (slower)?                              : 0     [DEFAULT]
Convert given conv layers to unshared local                :       
Cropped DP: crop border size                               : 4     [DEFAULT]
Cropped DP: logreg layer name (for --multiview-test)       :       [DEFAULT]
Cropped DP: test on multiple patches?                      : 0     [DEFAULT]
Cropped Step: crop border step                             : 1     [DEFAULT]
Data batch range: testing                                  : 28-33 
Data batch range: training                                 : 1-27  
Data path                                                  : /data/ad6813/pipe-data/Bluebox/batches/scraping_peeling/net_0 
Data provider                                              : basic-leaf256 
GPU override                                               : -1    [DEFAULT]
Layer definition file                                      : /homes/ad6813/Git/pipe-classification/models/scraping_peeling/net_0/layers.cfg 
Layer parameter file                                       : /homes/ad6813/Git/pipe-classification/models/scraping_peeling/net_0/params.cfg 
Load file                                                  :       [DEFAULT]
Maximum save file size (MB)                                : 0     [DEFAULT]
Minibatch size                                             : 128   [DEFAULT]
Number of GPUs                                             : 1     [DEFAULT]
Number of epochs                                           : 50000 [DEFAULT]
Save path                                                  : /homes/ad6813/Git/pipe-classification/models/scraping_peeling/net_0/saves 
Test and quit?                                             : 0     [DEFAULT]
Test on more than one batch at a time?                     : -1    [DEFAULT]
Test on one batch at a time?                               : 1     [DEFAULT]
Testing frequency                                          : 50    
Unshare weight matrices in given layers                    :       
=========================
Running on CUDA device(s) -2
Current time: Tue Jul  8 14:54:09 2014
Saving checkpoints to /homes/ad6813/Git/pipe-classification/models/scraping_peeling/net_0/saves/ConvNet__2014-07-08_14.54.04
=========================
1.1... logprob:  0.683337, 0.398438 (0.763 sec)
1.2... logprob:  0.588542, 0.273438 (0.671 sec)
1.3... logprob:  0.769547, 0.359375 (1.602 sec)
1.4... logprob:  0.864836, 0.726562 (1.642 sec)
1.5... logprob:  0.727980, 0.265625 (1.587 sec)
1.6... logprob:  0.845116, 0.296875 (1.686 sec)
1.7... logprob:  0.757254, 0.656250 (1.588 sec)
1.8... logprob:  0.647961, 0.289062 (1.665 sec)
1.9... logprob:  0.992297, 0.335938 (1.591 sec)
1.10... logprob:  0.606802, 0.281250 (1.669 sec)
1.11... logprob:  0.947061, 0.664062 (1.589 sec)
1.12... logprob:  1.052126, 0.437500 (1.688 sec)
1.13... logprob:  0.654350, 0.359375 (1.595 sec)
1.14... logprob:  0.848376, 0.632812 (2.346 sec)
1.15... logprob:  0.987970, 0.398438 (1.613 sec)
1.16... logprob:  0.629558, 0.320312 (1.678 sec)
1.17... logprob:  0.865720, 0.664062 (1.619 sec)
1.18... logprob:  0.835687, 0.335938 (1.648 sec)
1.19... logprob:  0.728674, 0.328125 (1.626 sec)
1.20... logprob:  0.938259, 0.648438 (1.638 sec)
1.21... logprob:  0.696372, 0.343750 (1.618 sec)
1.22... logprob:  0.703825, 0.320312 (1.602 sec)
1.23... logprob:  0.712744, 0.687500 (1.640 sec)
1.24... logprob:  0.555634, 0.242188 (1.685 sec)
1.25... logprob:  0.836928, 0.320312 (1.649 sec)
1.26... logprob:  0.673832, 0.390625 (1.603 sec)
1.27... logprob:  1.186495, 0.679688 (0.674 sec)
2.1... logprob:  1.131949, 0.398438 (0.679 sec)
2.2... logprob:  0.720103, 0.273438 (0.676 sec)
2.3... logprob:  0.737491, 0.640625 (0.681 sec)
2.4... logprob:  0.709435, 0.726562 (0.684 sec)
2.5... logprob:  0.845456, 0.265625 (0.682 sec)
2.6... logprob:  0.980339, 0.296875 (0.684 sec)
2.7... logprob:  0.657353, 0.343750 (0.687 sec)
2.8... logprob:  1.168093, 0.710938 (0.692 sec)
2.9... logprob:  1.055611, 0.335938 (0.680 sec)
2.10... logprob:  1.023693, 0.281250 (0.683 sec)
2.11... logprob:  0.662069, 0.335938 (0.684 sec)
2.12... logprob:  1.271416, 0.562500 (0.680 sec)
2.13... logprob:  0.685279, 0.359375 (0.686 sec)
2.14... logprob:  1.249885, 0.367188 (0.682 sec)
2.15... logprob:  1.109269, 0.398438 (0.704 sec)
2.16... logprob:  1.238415, 0.679688 (0.701 sec)
2.17... logprob:  0.681553, 0.335938 (0.689 sec)
2.18... logprob:  1.059733, 0.335938 (0.687 sec)
2.19... logprob:  0.939835, 0.328125 (0.688 sec)
2.20... logprob:  0.750545, 0.648438 (0.689 sec)
2.21... logprob:  0.863933, 0.656250 (0.690 sec)
2.22... logprob:  0.795968, 0.320312 (0.687 sec)
2.23... logprob:  0.879014, 0.312500 (0.688 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.653745, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979557e-03 [7.911528e-09] 
Layer 'conv1' biases: 7.752240e-09 [2.388689e-10] 
Layer 'conv2' weights[0]: 7.966485e-03 [1.063819e-08] 
Layer 'conv2' biases: 1.000000e+00 [1.795956e-09] 
Layer 'conv3' weights[0]: 7.964848e-03 [1.104741e-08] 
Layer 'conv3' biases: 1.949131e-07 [5.941230e-09] 
Layer 'conv4' weights[0]: 7.997336e-03 [1.328408e-08] 
Layer 'conv4' biases: 9.999999e-01 [6.268340e-08] 
Layer 'conv5' weights[0]: 7.996237e-03 [4.007834e-07] 
Layer 'conv5' biases: 9.999858e-01 [4.355980e-07] 
Layer 'fc6' weights[0]: 7.593097e-03 [5.058171e-08] 
Layer 'fc6' biases: 9.999999e-01 [5.164728e-08] 
Layer 'fc7' weights[0]: 7.852500e-03 [8.717132e-07] 
Layer 'fc7' biases: 9.999935e-01 [8.512318e-07] 
Layer 'fc8' weights[0]: 4.485211e-04 [1.751167e-04] 
Layer 'fc8' biases: 4.949767e-05 [1.999668e-04] 
Train error last 27 batches: 0.906271
-------------------------------------------------------
Saved checkpoint to /homes/ad6813/Git/pipe-classification/models/scraping_peeling/net_0/saves/ConvNet__2014-07-08_14.54.04
======================================================= (6.752 sec)
2.24... logprob:  0.576867, 0.242188 (1.620 sec)
2.25... logprob:  0.715244, 0.679688 (1.784 sec)
2.26... logprob:  0.723173, 0.390625 (1.616 sec)
2.27... logprob:  0.629082, 0.320312 (0.678 sec)
3.1... logprob:  0.672388, 0.398438 (0.680 sec)
3.2... logprob:  0.695139, 0.726562 (0.683 sec)
3.3... logprob:  0.775035, 0.359375 (0.681 sec)
3.4... logprob:  0.602223, 0.273438 (0.683 sec)
3.5... logprob:  0.609966, 0.265625 (0.687 sec)
3.6... logprob:  0.611194, 0.296875 (0.686 sec)
3.7... logprob:  0.676638, 0.343750 (0.687 sec)
3.8... logprob:  0.606343, 0.289062 (0.677 sec)
3.9... logprob:  0.638802, 0.335938 (0.678 sec)
3.10... logprob:  0.600914, 0.281250 (0.677 sec)
3.11... logprob:  0.667283, 0.335938 (0.677 sec)
3.12... logprob:  0.718270, 0.437500 (0.686 sec)
3.13... logprob:  0.835742, 0.640625 (0.678 sec)
3.14... logprob:  0.657596, 0.367188 (0.678 sec)
3.15... logprob:  0.823925, 0.398438 (0.680 sec)
3.16... logprob:  0.629944, 0.320312 (0.680 sec)
3.17... logprob:  0.696874, 0.664062 (0.676 sec)
3.18... logprob:  0.640850, 0.335938 (0.677 sec)
3.19... logprob:  0.670820, 0.328125 (0.677 sec)
3.20... logprob:  0.652087, 0.351562 (0.679 sec)
3.21... logprob:  0.695556, 0.656250 (0.678 sec)
3.22... logprob:  0.630871, 0.320312 (0.678 sec)
3.23... logprob:  0.661303, 0.312500 (0.677 sec)
3.24... logprob:  0.554323, 0.242188 (0.682 sec)
3.25... logprob:  0.630176, 0.320312 (0.683 sec)
3.26... logprob:  0.669973, 0.390625 (0.685 sec)
3.27... logprob:  0.689684, 0.320312 (0.683 sec)
4.1... logprob:  0.729381, 0.398438 (0.676 sec)
4.2... logprob:  0.587481, 0.273438 (0.679 sec)
4.3... logprob:  0.659604, 0.359375 (0.678 sec)
4.4... logprob:  0.631621, 0.273438 (0.674 sec)
4.5... logprob:  0.578933, 0.265625 (0.677 sec)
4.6... logprob:  0.664485, 0.296875 (0.678 sec)
4.7... logprob:  0.666100, 0.343750 (0.676 sec)
4.8... logprob:  0.722707, 0.710938 (0.678 sec)
4.9... logprob:  0.638301, 0.335938 (0.681 sec)
4.10... logprob:  0.615085, 0.281250 (0.681 sec)
4.11... logprob:  0.689465, 0.335938 (0.677 sec)
4.12... logprob:  0.685576, 0.437500 (0.678 sec)
4.13... logprob:  0.874705, 0.640625 (0.679 sec)
4.14... logprob:  0.665177, 0.367188 (0.677 sec)
4.15... logprob:  0.861738, 0.398438 (0.677 sec)
4.16... logprob:  0.627920, 0.320312 (0.676 sec)
4.17... logprob:  0.725321, 0.664062 (0.677 sec)
4.18... logprob:  0.638310, 0.335938 (0.677 sec)
4.19... logprob:  0.685997, 0.328125 (0.680 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.638794, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979344e-03 [4.217204e-09] 
Layer 'conv1' biases: 1.076522e-08 [4.796058e-11] 
Layer 'conv2' weights[0]: 7.966292e-03 [4.421626e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.237194e-10] 
Layer 'conv3' weights[0]: 7.964644e-03 [4.566884e-09] 
Layer 'conv3' biases: 2.733445e-07 [1.082575e-09] 
Layer 'conv4' weights[0]: 7.997132e-03 [4.853734e-09] 
Layer 'conv4' biases: 9.999997e-01 [1.057200e-08] 
Layer 'conv5' weights[0]: 7.996026e-03 [6.578467e-08] 
Layer 'conv5' biases: 9.999807e-01 [7.107130e-08] 
Layer 'fc6' weights[0]: 7.592898e-03 [1.199689e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.154615e-08] 
Layer 'fc7' weights[0]: 7.850464e-03 [2.145397e-07] 
Layer 'fc7' biases: 9.999846e-01 [2.034080e-07] 
Layer 'fc8' weights[0]: 4.429255e-04 [3.654881e-05] 
Layer 'fc8' biases: 1.209475e-04 [4.664856e-05] 
Train error last 27 batches: 0.671551
-------------------------------------------------------
Saved checkpoint to /homes/ad6813/Git/pipe-classification/models/scraping_peeling/net_0/saves/ConvNet__2014-07-08_14.54.04
======================================================= (6.541 sec)
4.20... logprob:  0.672767, 0.351562 (0.698 sec)
4.21... logprob:  0.692135, 0.343750 (0.690 sec)
4.22... logprob:  0.660569, 0.320312 (0.694 sec)
4.23... logprob:  0.653259, 0.312500 (0.688 sec)
4.24... logprob:  0.569215, 0.242188 (0.688 sec)
4.25... logprob:  0.650624, 0.320312 (0.688 sec)
4.26... logprob:  0.675133, 0.390625 (0.684 sec)
4.27... logprob:  0.753145, 0.679688 (0.686 sec)
5.1... logprob:  0.730447, 0.398438 (0.688 sec)
5.2... logprob:  0.593596, 0.273438 (0.702 sec)
5.3... logprob:  0.670687, 0.359375 (0.697 sec)
5.4... logprob:  0.671820, 0.273438 (0.695 sec)
5.5... logprob:  0.583684, 0.265625 (0.696 sec)
5.6... logprob:  0.680436, 0.296875 (0.693 sec)
5.7... logprob:  0.719785, 0.343750 (0.702 sec)
5.8... logprob:  0.672186, 0.289062 (0.690 sec)
5.9... logprob:  0.667223, 0.335938 (0.692 sec)
5.10... logprob:  0.597092, 0.281250 (0.689 sec)
5.11... logprob:  0.738991, 0.335938 (0.694 sec)
5.12... logprob:  0.737636, 0.437500 (0.691 sec)
5.13... logprob:  0.909770, 0.640625 (0.696 sec)
5.14... logprob:  0.693600, 0.632812 (0.698 sec)
5.15... logprob:  0.852963, 0.398438 (0.696 sec)
5.16... logprob:  0.685470, 0.320312 (0.692 sec)
5.17... logprob:  0.651632, 0.335938 (0.694 sec)
5.18... logprob:  0.722777, 0.664062 (0.694 sec)
5.19... logprob:  0.633867, 0.328125 (0.694 sec)
5.20... logprob:  0.735812, 0.351562 (0.692 sec)
5.21... logprob:  0.655557, 0.343750 (0.695 sec)
5.22... logprob:  0.694979, 0.679688 (0.693 sec)
5.23... logprob:  0.642673, 0.312500 (0.694 sec)
5.24... logprob:  0.557872, 0.242188 (0.700 sec)
5.25... logprob:  0.769128, 0.320312 (0.701 sec)
5.26... logprob:  0.735071, 0.390625 (0.692 sec)
5.27... logprob:  0.839548, 0.679688 (0.691 sec)
6.1... logprob:  0.697694, 0.601562 (0.692 sec)
6.2... logprob:  0.590916, 0.273438 (0.695 sec)
6.3... logprob:  0.851997, 0.359375 (0.692 sec)
6.4... logprob:  0.590307, 0.273438 (0.683 sec)
6.5... logprob:  0.657709, 0.265625 (0.685 sec)
6.6... logprob:  0.620701, 0.296875 (0.686 sec)
6.7... logprob:  0.692032, 0.343750 (0.689 sec)
6.8... logprob:  0.609267, 0.289062 (0.705 sec)
6.9... logprob:  0.638338, 0.335938 (0.700 sec)
6.10... logprob:  0.647865, 0.281250 (0.693 sec)
6.11... logprob:  0.641087, 0.335938 (0.695 sec)
6.12... logprob:  0.780248, 0.437500 (0.693 sec)
6.13... logprob:  0.671191, 0.359375 (0.695 sec)
6.14... logprob:  0.706554, 0.632812 (0.696 sec)
6.15... logprob:  0.678286, 0.398438 (0.695 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.639304, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979153e-03 [4.159335e-09] 
Layer 'conv1' biases: 1.279228e-08 [3.324348e-11] 
Layer 'conv2' weights[0]: 7.966096e-03 [4.173766e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.108374e-10] 
Layer 'conv3' weights[0]: 7.964434e-03 [4.260700e-09] 
Layer 'conv3' biases: 3.191319e-07 [6.991943e-10] 
Layer 'conv4' weights[0]: 7.996931e-03 [4.404582e-09] 
Layer 'conv4' biases: 9.999996e-01 [6.825269e-09] 
Layer 'conv5' weights[0]: 7.995827e-03 [4.193634e-08] 
Layer 'conv5' biases: 9.999788e-01 [4.458098e-08] 
Layer 'fc6' weights[0]: 7.592689e-03 [9.773983e-09] 
Layer 'fc6' biases: 9.999999e-01 [8.904734e-09] 
Layer 'fc7' weights[0]: 7.848599e-03 [1.715814e-07] 
Layer 'fc7' biases: 9.999743e-01 [1.603588e-07] 
Layer 'fc8' weights[0]: 4.306591e-04 [3.710284e-05] 
Layer 'fc8' biases: 1.281565e-04 [5.241754e-05] 
Train error last 27 batches: 0.681429
-------------------------------------------------------
Not saving because 0.639304 > 0.638794 (4.19: -2.29%)
======================================================= (2.782 sec)
6.16... logprob:  0.631783, 0.320312 (0.692 sec)
6.17... logprob:  0.647952, 0.335938 (0.686 sec)
6.18... logprob:  0.638977, 0.335938 (0.688 sec)
6.19... logprob:  0.646219, 0.328125 (0.687 sec)
6.20... logprob:  0.648660, 0.351562 (0.687 sec)
6.21... logprob:  0.648035, 0.343750 (0.689 sec)
6.22... logprob:  0.627103, 0.320312 (0.690 sec)
6.23... logprob:  0.622830, 0.312500 (0.689 sec)
6.24... logprob:  0.568011, 0.242188 (0.688 sec)
6.25... logprob:  0.659062, 0.320312 (0.692 sec)
6.26... logprob:  0.724445, 0.390625 (0.693 sec)
6.27... logprob:  0.679011, 0.320312 (0.688 sec)
7.1... logprob:  0.684684, 0.398438 (0.687 sec)
7.2... logprob:  0.603275, 0.273438 (0.690 sec)
7.3... logprob:  0.746991, 0.359375 (0.688 sec)
7.4... logprob:  0.595788, 0.273438 (0.693 sec)
7.5... logprob:  0.587929, 0.265625 (0.680 sec)
7.6... logprob:  0.616672, 0.296875 (0.680 sec)
7.7... logprob:  0.647243, 0.343750 (0.694 sec)
7.8... logprob:  0.602112, 0.289062 (0.692 sec)
7.9... logprob:  0.643754, 0.335938 (0.695 sec)
7.10... logprob:  0.599984, 0.281250 (0.688 sec)
7.11... logprob:  0.640376, 0.335938 (0.689 sec)
7.12... logprob:  0.714449, 0.437500 (0.691 sec)
7.13... logprob:  0.694911, 0.640625 (0.691 sec)
7.14... logprob:  0.674682, 0.367188 (0.691 sec)
7.15... logprob:  0.696606, 0.398438 (0.688 sec)
7.16... logprob:  0.629135, 0.320312 (0.691 sec)
7.17... logprob:  0.638609, 0.335938 (0.694 sec)
7.18... logprob:  0.641085, 0.335938 (0.693 sec)
7.19... logprob:  0.635987, 0.328125 (0.683 sec)
7.20... logprob:  0.652172, 0.351562 (0.683 sec)
7.21... logprob:  0.645382, 0.343750 (0.683 sec)
7.22... logprob:  0.630024, 0.320312 (0.686 sec)
7.23... logprob:  0.623620, 0.312500 (0.681 sec)
7.24... logprob:  0.560289, 0.242188 (0.682 sec)
7.25... logprob:  0.668561, 0.320312 (0.687 sec)
7.26... logprob:  0.723692, 0.390625 (0.685 sec)
7.27... logprob:  0.686185, 0.320312 (0.692 sec)
8.1... logprob:  0.688956, 0.398438 (0.692 sec)
8.2... logprob:  0.603285, 0.273438 (0.696 sec)
8.3... logprob:  0.751904, 0.359375 (0.691 sec)
8.4... logprob:  0.600089, 0.273438 (0.684 sec)
8.5... logprob:  0.585007, 0.265625 (0.680 sec)
8.6... logprob:  0.619488, 0.296875 (0.680 sec)
8.7... logprob:  0.644628, 0.343750 (0.680 sec)
8.8... logprob:  0.602255, 0.289062 (0.679 sec)
8.9... logprob:  0.647361, 0.335938 (0.697 sec)
8.10... logprob:  0.597183, 0.281250 (0.689 sec)
8.11... logprob:  0.639598, 0.335938 (0.695 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.685699, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.978969e-03 [4.099191e-09] 
Layer 'conv1' biases: 1.354509e-08 [1.986269e-11] 
Layer 'conv2' weights[0]: 7.965899e-03 [4.036188e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.013069e-10] 
Layer 'conv3' weights[0]: 7.964237e-03 [4.038626e-09] 
Layer 'conv3' biases: 3.337953e-07 [3.330252e-10] 
Layer 'conv4' weights[0]: 7.996744e-03 [4.071195e-09] 
Layer 'conv4' biases: 9.999996e-01 [2.635932e-09] 
Layer 'conv5' weights[0]: 7.995655e-03 [1.566467e-08] 
Layer 'conv5' biases: 9.999784e-01 [1.615464e-08] 
Layer 'fc6' weights[0]: 7.592502e-03 [5.123431e-09] 
Layer 'fc6' biases: 9.999999e-01 [3.292944e-09] 
Layer 'fc7' weights[0]: 7.846750e-03 [7.644737e-08] 
Layer 'fc7' biases: 9.999703e-01 [5.931440e-08] 
Layer 'fc8' weights[0]: 4.205975e-04 [1.366265e-05] 
Layer 'fc8' biases: 9.006920e-05 [1.997023e-05] 
Train error last 27 batches: 0.647968
-------------------------------------------------------
Not saving because 0.685699 > 0.638794 (4.19: -2.29%)
======================================================= (2.725 sec)
8.12... logprob:  0.706763, 0.437500 (0.676 sec)
8.13... logprob:  0.694061, 0.640625 (0.677 sec)
8.14... logprob:  0.671504, 0.367188 (0.677 sec)
8.15... logprob:  0.695844, 0.398438 (0.680 sec)
8.16... logprob:  0.628687, 0.320312 (0.678 sec)
8.17... logprob:  0.638624, 0.335938 (0.683 sec)
8.18... logprob:  0.640483, 0.335938 (0.682 sec)
8.19... logprob:  0.635928, 0.328125 (0.678 sec)
8.20... logprob:  0.651294, 0.351562 (0.676 sec)
8.21... logprob:  0.645147, 0.343750 (0.678 sec)
8.22... logprob:  0.629309, 0.320312 (0.681 sec)
8.23... logprob:  0.623215, 0.312500 (0.678 sec)
8.24... logprob:  0.561260, 0.242188 (0.678 sec)
8.25... logprob:  0.664408, 0.320312 (0.679 sec)
8.26... logprob:  0.724737, 0.390625 (0.678 sec)
8.27... logprob:  0.675279, 0.320312 (0.678 sec)
9.1... logprob:  0.689701, 0.398438 (0.686 sec)
9.2... logprob:  0.611197, 0.273438 (0.684 sec)
9.3... logprob:  0.741320, 0.359375 (0.677 sec)
9.4... logprob:  0.603691, 0.273438 (0.677 sec)
9.5... logprob:  0.580571, 0.265625 (0.679 sec)
9.6... logprob:  0.617660, 0.296875 (0.680 sec)
9.7... logprob:  0.643489, 0.343750 (0.678 sec)
9.8... logprob:  0.604777, 0.289062 (0.676 sec)
9.9... logprob:  0.649189, 0.335938 (0.679 sec)
9.10... logprob:  0.594491, 0.281250 (0.680 sec)
9.11... logprob:  0.640965, 0.335938 (0.682 sec)
9.12... logprob:  0.700977, 0.437500 (0.683 sec)
9.13... logprob:  0.703487, 0.640625 (0.679 sec)
9.14... logprob:  0.671833, 0.367188 (0.678 sec)
9.15... logprob:  0.699868, 0.398438 (0.678 sec)
9.16... logprob:  0.630315, 0.320312 (0.680 sec)
9.17... logprob:  0.638760, 0.335938 (0.678 sec)
9.18... logprob:  0.641822, 0.335938 (0.678 sec)
9.19... logprob:  0.637540, 0.328125 (0.678 sec)
9.20... logprob:  0.651382, 0.351562 (0.679 sec)
9.21... logprob:  0.646520, 0.343750 (0.683 sec)
9.22... logprob:  0.628363, 0.320312 (0.683 sec)
9.23... logprob:  0.623981, 0.312500 (0.684 sec)
9.24... logprob:  0.564433, 0.242188 (0.677 sec)
9.25... logprob:  0.661104, 0.320312 (0.678 sec)
9.26... logprob:  0.731110, 0.390625 (0.680 sec)
9.27... logprob:  0.662030, 0.320312 (0.679 sec)
10.1... logprob:  0.691339, 0.398438 (0.676 sec)
10.2... logprob:  0.624479, 0.273438 (0.686 sec)
10.3... logprob:  0.728771, 0.359375 (0.680 sec)
10.4... logprob:  0.608468, 0.273438 (0.675 sec)
10.5... logprob:  0.578858, 0.265625 (0.681 sec)
10.6... logprob:  0.614289, 0.296875 (0.681 sec)
10.7... logprob:  0.644723, 0.343750 (0.677 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.634406, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.978782e-03 [4.120037e-09] 
Layer 'conv1' biases: 1.413171e-08 [2.126527e-11] 
Layer 'conv2' weights[0]: 7.965695e-03 [4.054710e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.155508e-10] 
Layer 'conv3' weights[0]: 7.964045e-03 [4.068173e-09] 
Layer 'conv3' biases: 3.445716e-07 [3.922455e-10] 
Layer 'conv4' weights[0]: 7.996539e-03 [4.104248e-09] 
Layer 'conv4' biases: 9.999996e-01 [3.220230e-09] 
Layer 'conv5' weights[0]: 7.995455e-03 [1.938284e-08] 
Layer 'conv5' biases: 9.999781e-01 [2.000188e-08] 
Layer 'fc6' weights[0]: 7.592312e-03 [5.805339e-09] 
Layer 'fc6' biases: 9.999999e-01 [4.332962e-09] 
Layer 'fc7' weights[0]: 7.844881e-03 [9.436952e-08] 
Layer 'fc7' biases: 9.999664e-01 [7.909469e-08] 
Layer 'fc8' weights[0]: 4.167807e-04 [6.843781e-06] 
Layer 'fc8' biases: 8.357251e-05 [1.054517e-05] 
Train error last 27 batches: 0.647181
-------------------------------------------------------
Saved checkpoint to /homes/ad6813/Git/pipe-classification/models/scraping_peeling/net_0/saves/ConvNet__2014-07-08_14.54.04
======================================================= (6.610 sec)
10.8... logprob:  0.611032, 0.289062 (0.681 sec)
10.9... logprob:  0.649376, 0.335938 (0.679 sec)
10.10... logprob:  0.594534, 0.281250 (0.695 sec)
10.11... logprob:  0.645151, 0.335938 (0.688 sec)
10.12... logprob:  0.698573, 0.437500 (0.687 sec)
10.13... logprob:  0.718298, 0.640625 (0.684 sec)
10.14... logprob:  0.676878, 0.367188 (0.685 sec)
10.15... logprob:  0.703203, 0.398438 (0.686 sec)
10.16... logprob:  0.634782, 0.320312 (0.693 sec)
10.17... logprob:  0.640053, 0.335938 (0.690 sec)
10.18... logprob:  0.643487, 0.335938 (0.684 sec)
10.19... logprob:  0.642567, 0.328125 (0.687 sec)
10.20... logprob:  0.650294, 0.351562 (0.689 sec)
10.21... logprob:  0.649185, 0.343750 (0.687 sec)
10.22... logprob:  0.627143, 0.320312 (0.685 sec)
10.23... logprob:  0.623922, 0.312500 (0.687 sec)
10.24... logprob:  0.570840, 0.242188 (0.692 sec)
10.25... logprob:  0.652667, 0.320312 (0.689 sec)
10.26... logprob:  0.734299, 0.390625 (0.693 sec)
10.27... logprob:  0.647615, 0.320312 (0.693 sec)
11.1... logprob:  0.688505, 0.398438 (0.689 sec)
11.2... logprob:  0.641617, 0.273438 (0.690 sec)
11.3... logprob:  0.708467, 0.359375 (0.687 sec)
11.4... logprob:  0.608979, 0.273438 (0.688 sec)
11.5... logprob:  0.581085, 0.265625 (0.686 sec)
11.6... logprob:  0.609509, 0.296875 (0.687 sec)
11.7... logprob:  0.646048, 0.343750 (0.688 sec)
11.8... logprob:  0.623488, 0.289062 (0.692 sec)
11.9... logprob:  0.644753, 0.335938 (0.689 sec)
11.10... logprob:  0.596255, 0.281250 (0.693 sec)
11.11... logprob:  0.655192, 0.335938 (0.693 sec)
11.12... logprob:  0.704503, 0.437500 (0.685 sec)
11.13... logprob:  0.730467, 0.640625 (0.687 sec)
11.14... logprob:  0.693256, 0.632812 (0.687 sec)
11.15... logprob:  0.697446, 0.398438 (0.681 sec)
11.16... logprob:  0.642032, 0.320312 (0.680 sec)
11.17... logprob:  0.647222, 0.335938 (0.681 sec)
11.18... logprob:  0.641510, 0.335938 (0.681 sec)
11.19... logprob:  0.652855, 0.328125 (0.685 sec)
11.20... logprob:  0.648410, 0.351562 (0.685 sec)
11.21... logprob:  0.649750, 0.343750 (0.686 sec)
11.22... logprob:  0.628829, 0.320312 (0.683 sec)
11.23... logprob:  0.621360, 0.312500 (0.684 sec)
11.24... logprob:  0.575905, 0.242188 (0.678 sec)
11.25... logprob:  0.638972, 0.320312 (0.681 sec)
11.26... logprob:  0.720765, 0.390625 (0.688 sec)
11.27... logprob:  0.638988, 0.320312 (0.686 sec)
12.1... logprob:  0.679343, 0.398438 (0.680 sec)
12.2... logprob:  0.646688, 0.273438 (0.682 sec)
12.3... logprob:  0.686072, 0.359375 (0.687 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.664077, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.978600e-03 [4.162798e-09] 
Layer 'conv1' biases: 1.477358e-08 [1.898747e-11] 
Layer 'conv2' weights[0]: 7.965492e-03 [4.052450e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.094365e-10] 
Layer 'conv3' weights[0]: 7.963851e-03 [4.062527e-09] 
Layer 'conv3' biases: 3.561994e-07 [3.662594e-10] 
Layer 'conv4' weights[0]: 7.996339e-03 [4.098557e-09] 
Layer 'conv4' biases: 9.999996e-01 [3.195944e-09] 
Layer 'conv5' weights[0]: 7.995267e-03 [1.950674e-08] 
Layer 'conv5' biases: 9.999781e-01 [1.978954e-08] 
Layer 'fc6' weights[0]: 7.592117e-03 [5.813354e-09] 
Layer 'fc6' biases: 9.999999e-01 [4.347366e-09] 
Layer 'fc7' weights[0]: 7.843130e-03 [9.399107e-08] 
Layer 'fc7' biases: 9.999614e-01 [7.838197e-08] 
Layer 'fc8' weights[0]: 4.420743e-04 [2.926402e-05] 
Layer 'fc8' biases: 2.446299e-04 [4.626268e-05] 
Train error last 27 batches: 0.648507
-------------------------------------------------------
Not saving because 0.664077 > 0.634406 (10.7: -0.69%)
======================================================= (2.697 sec)
12.4... logprob:  0.600314, 0.273438 (0.686 sec)
12.5... logprob:  0.582795, 0.265625 (0.680 sec)
12.6... logprob:  0.608405, 0.296875 (0.680 sec)
12.7... logprob:  0.643992, 0.343750 (0.680 sec)
12.8... logprob:  0.633331, 0.289062 (0.680 sec)
12.9... logprob:  0.639049, 0.335938 (0.686 sec)
12.10... logprob:  0.595108, 0.281250 (0.685 sec)
12.11... logprob:  0.665035, 0.335938 (0.683 sec)
12.12... logprob:  0.723456, 0.437500 (0.677 sec)
12.13... logprob:  0.718432, 0.640625 (0.684 sec)
12.14... logprob:  0.716354, 0.632812 (0.686 sec)
12.15... logprob:  0.681224, 0.398438 (0.682 sec)
12.16... logprob:  0.641902, 0.320312 (0.681 sec)
12.17... logprob:  0.662119, 0.335938 (0.680 sec)
12.18... logprob:  0.638389, 0.335938 (0.688 sec)
12.19... logprob:  0.654867, 0.328125 (0.692 sec)
12.20... logprob:  0.654351, 0.351562 (0.692 sec)
12.21... logprob:  0.644412, 0.343750 (0.695 sec)
12.22... logprob:  0.631521, 0.320312 (0.690 sec)
12.23... logprob:  0.623745, 0.312500 (0.689 sec)
12.24... logprob:  0.566197, 0.242188 (0.690 sec)
12.25... logprob:  0.632353, 0.320312 (0.688 sec)
12.26... logprob:  0.695612, 0.390625 (0.687 sec)
12.27... logprob:  0.643391, 0.320312 (0.690 sec)
13.1... logprob:  0.674109, 0.398438 (0.700 sec)
13.2... logprob:  0.628102, 0.273438 (0.685 sec)
13.3... logprob:  0.679750, 0.359375 (0.687 sec)
13.4... logprob:  0.592272, 0.273438 (0.685 sec)
13.5... logprob:  0.580206, 0.265625 (0.683 sec)
13.6... logprob:  0.609045, 0.296875 (0.680 sec)
13.7... logprob:  0.643822, 0.343750 (0.682 sec)
13.8... logprob:  0.626805, 0.289062 (0.697 sec)
13.9... logprob:  0.638308, 0.335938 (0.701 sec)
13.10... logprob:  0.594199, 0.281250 (0.682 sec)
13.11... logprob:  0.661650, 0.335938 (0.684 sec)
13.12... logprob:  0.737749, 0.437500 (0.682 sec)
13.13... logprob:  0.693969, 0.640625 (0.682 sec)
13.14... logprob:  0.719570, 0.632812 (0.687 sec)
13.15... logprob:  0.673283, 0.398438 (0.687 sec)
13.16... logprob:  0.633873, 0.320312 (0.681 sec)
13.17... logprob:  0.668046, 0.335938 (0.680 sec)
13.18... logprob:  0.643728, 0.335938 (0.681 sec)
13.19... logprob:  0.643929, 0.328125 (0.682 sec)
13.20... logprob:  0.660704, 0.351562 (0.682 sec)
13.21... logprob:  0.644805, 0.343750 (0.683 sec)
13.22... logprob:  0.628784, 0.320312 (0.682 sec)
13.23... logprob:  0.628709, 0.312500 (0.682 sec)
13.24... logprob:  0.556336, 0.242188 (0.687 sec)
13.25... logprob:  0.635719, 0.320312 (0.688 sec)
13.26... logprob:  0.686175, 0.390625 (0.682 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.666150, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.978396e-03 [4.203132e-09] 
Layer 'conv1' biases: 1.541680e-08 [3.779263e-11] 
Layer 'conv2' weights[0]: 7.965287e-03 [4.178598e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.015517e-10] 
Layer 'conv3' weights[0]: 7.963653e-03 [4.181067e-09] 
Layer 'conv3' biases: 3.680772e-07 [6.161559e-10] 
Layer 'conv4' weights[0]: 7.996146e-03 [4.239791e-09] 
Layer 'conv4' biases: 9.999996e-01 [5.159419e-09] 
Layer 'conv5' weights[0]: 7.995076e-03 [2.741909e-08] 
Layer 'conv5' biases: 9.999782e-01 [2.872554e-08] 
Layer 'fc6' weights[0]: 7.591898e-03 [6.539575e-09] 
Layer 'fc6' biases: 9.999999e-01 [5.266749e-09] 
Layer 'fc7' weights[0]: 7.841363e-03 [1.056323e-07] 
Layer 'fc7' biases: 9.999560e-01 [8.993923e-08] 
Layer 'fc8' weights[0]: 4.057023e-04 [7.761538e-05] 
Layer 'fc8' biases: 2.257239e-05 [1.279064e-04] 
Train error last 27 batches: 0.645446
-------------------------------------------------------
Not saving because 0.666150 > 0.634406 (10.7: -0.69%)
======================================================= (2.890 sec)
13.27... logprob:  0.656577, 0.320312 (0.681 sec)
14.1... logprob:  0.675121, 0.398438 (0.679 sec)
14.2... logprob:  0.617189, 0.273438 (0.681 sec)
14.3... logprob:  0.687391, 0.359375 (0.678 sec)
14.4... logprob:  0.593032, 0.273438 (0.680 sec)
14.5... logprob:  0.579528, 0.265625 (0.691 sec)
14.6... logprob:  0.608386, 0.296875 (0.681 sec)
14.7... logprob:  0.643703, 0.343750 (0.680 sec)
14.8... logprob:  0.623169, 0.289062 (0.670 sec)
14.9... logprob:  0.638300, 0.335938 (0.672 sec)
14.10... logprob:  0.594321, 0.281250 (0.672 sec)
14.11... logprob:  0.658615, 0.335938 (0.672 sec)
14.12... logprob:  0.737608, 0.437500 (0.671 sec)
14.13... logprob:  0.686081, 0.359375 (0.675 sec)
14.14... logprob:  0.716398, 0.632812 (0.674 sec)
14.15... logprob:  0.672385, 0.398438 (0.680 sec)
14.16... logprob:  0.630554, 0.320312 (0.669 sec)
14.17... logprob:  0.668229, 0.335938 (0.670 sec)
14.18... logprob:  0.648768, 0.335938 (0.672 sec)
14.19... logprob:  0.638070, 0.328125 (0.684 sec)
14.20... logprob:  0.661626, 0.351562 (0.670 sec)
14.21... logprob:  0.649004, 0.343750 (0.674 sec)
14.22... logprob:  0.627236, 0.320312 (0.671 sec)
14.23... logprob:  0.629765, 0.312500 (0.671 sec)
14.24... logprob:  0.553912, 0.242188 (0.672 sec)
14.25... logprob:  0.641990, 0.320312 (0.675 sec)
14.26... logprob:  0.687127, 0.390625 (0.671 sec)
14.27... logprob:  0.663589, 0.320312 (0.671 sec)
15.1... logprob:  0.678745, 0.398438 (0.690 sec)
15.2... logprob:  0.619718, 0.273438 (0.681 sec)
15.3... logprob:  0.690907, 0.359375 (0.684 sec)
15.4... logprob:  0.597078, 0.273438 (0.677 sec)
15.5... logprob:  0.581066, 0.265625 (0.681 sec)
15.6... logprob:  0.608511, 0.296875 (0.678 sec)
15.7... logprob:  0.643490, 0.343750 (0.682 sec)
15.8... logprob:  0.628787, 0.289062 (0.686 sec)
15.9... logprob:  0.638327, 0.335938 (0.680 sec)
15.10... logprob:  0.594155, 0.281250 (0.680 sec)
15.11... logprob:  0.662893, 0.335938 (0.684 sec)
15.12... logprob:  0.744728, 0.437500 (0.672 sec)
15.13... logprob:  0.681505, 0.359375 (0.672 sec)
15.14... logprob:  0.722690, 0.632812 (0.672 sec)
15.15... logprob:  0.673198, 0.398438 (0.674 sec)
15.16... logprob:  0.628821, 0.320312 (0.673 sec)
15.17... logprob:  0.672896, 0.335938 (0.675 sec)
15.18... logprob:  0.657966, 0.335938 (0.679 sec)
15.19... logprob:  0.634173, 0.328125 (0.677 sec)
15.20... logprob:  0.663272, 0.351562 (0.674 sec)
15.21... logprob:  0.657589, 0.343750 (0.676 sec)
15.22... logprob:  0.627648, 0.320312 (0.673 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.639049, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.978204e-03 [4.159778e-09] 
Layer 'conv1' biases: 1.604004e-08 [1.919615e-11] 
Layer 'conv2' weights[0]: 7.965083e-03 [4.054233e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.165532e-10] 
Layer 'conv3' weights[0]: 7.963464e-03 [4.070514e-09] 
Layer 'conv3' biases: 3.784410e-07 [3.968270e-10] 
Layer 'conv4' weights[0]: 7.995961e-03 [4.112762e-09] 
Layer 'conv4' biases: 9.999996e-01 [3.563226e-09] 
Layer 'conv5' weights[0]: 7.994890e-03 [2.184456e-08] 
Layer 'conv5' biases: 9.999783e-01 [2.223414e-08] 
Layer 'fc6' weights[0]: 7.591727e-03 [5.723009e-09] 
Layer 'fc6' biases: 9.999999e-01 [4.224712e-09] 
Layer 'fc7' weights[0]: 7.839596e-03 [8.971917e-08] 
Layer 'fc7' biases: 9.999512e-01 [7.317632e-08] 
Layer 'fc8' weights[0]: 4.288757e-04 [5.682259e-05] 
Layer 'fc8' biases: 2.276906e-04 [9.797906e-05] 
Train error last 27 batches: 0.647576
-------------------------------------------------------
Not saving because 0.639049 > 0.634406 (10.7: -0.69%)
======================================================= (1.816 sec)
15.23... logprob:  0.630524, 0.312500 (0.683 sec)
15.24... logprob:  0.553928, 0.242188 (0.683 sec)
15.25... logprob:  0.652980, 0.320312 (0.684 sec)
15.26... logprob:  0.691946, 0.390625 (0.685 sec)
15.27... logprob:  0.669065, 0.320312 (0.678 sec)
16.1... logprob:  0.686399, 0.398438 (0.679 sec)
16.2... logprob:  0.629231, 0.273438 (0.679 sec)
16.3... logprob:  0.691507, 0.359375 (0.677 sec)
16.4... logprob:  0.603900, 0.273438 (0.679 sec)
16.5... logprob:  0.586346, 0.265625 (0.680 sec)
16.6... logprob:  0.609903, 0.296875 (0.679 sec)
16.7... logprob:  0.643666, 0.343750 (0.678 sec)
16.8... logprob:  0.641316, 0.289062 (0.689 sec)
16.9... logprob:  0.639508, 0.335938 (0.687 sec)
16.10... logprob:  0.594140, 0.281250 (0.705 sec)
16.11... logprob:  0.671520, 0.335938 (0.688 sec)
16.12... logprob:  0.764974, 0.437500 (0.672 sec)
16.13... logprob:  0.671108, 0.359375 (0.680 sec)
16.14... logprob:  0.731388, 0.632812 (0.673 sec)
16.15... logprob:  0.680637, 0.398438 (0.675 sec)
16.16... logprob:  0.627097, 0.320312 (0.673 sec)
16.17... logprob:  0.676911, 0.335938 (0.672 sec)
16.18... logprob:  0.677416, 0.335938 (0.677 sec)
16.19... logprob:  0.633981, 0.328125 (0.678 sec)
16.20... logprob:  0.659529, 0.351562 (0.677 sec)
16.21... logprob:  0.675194, 0.343750 (0.682 sec)
16.22... logprob:  0.636893, 0.320312 (0.673 sec)
16.23... logprob:  0.626483, 0.312500 (0.672 sec)
16.24... logprob:  0.556941, 0.242188 (0.674 sec)
16.25... logprob:  0.680523, 0.320312 (0.672 sec)
16.26... logprob:  0.716821, 0.390625 (0.670 sec)
16.27... logprob:  0.661655, 0.320312 (0.672 sec)
17.1... logprob:  0.704817, 0.601562 (0.674 sec)
17.2... logprob:  0.669705, 0.273438 (0.677 sec)
17.3... logprob:  0.678491, 0.359375 (0.678 sec)
17.4... logprob:  0.613798, 0.273438 (0.682 sec)
17.5... logprob:  0.606960, 0.265625 (0.678 sec)
17.6... logprob:  0.624617, 0.296875 (0.673 sec)
17.7... logprob:  0.643830, 0.343750 (0.677 sec)
17.8... logprob:  0.665045, 0.289062 (0.675 sec)
17.9... logprob:  0.655387, 0.335938 (0.679 sec)
17.10... logprob:  0.597132, 0.281250 (0.683 sec)
17.11... logprob:  0.680434, 0.335938 (0.675 sec)
17.12... logprob:  0.822578, 0.437500 (0.680 sec)
17.13... logprob:  0.653294, 0.359375 (0.697 sec)
17.14... logprob:  0.718647, 0.632812 (0.687 sec)
17.15... logprob:  0.712570, 0.601562 (0.682 sec)
17.16... logprob:  0.644907, 0.320312 (0.683 sec)
17.17... logprob:  0.661206, 0.335938 (0.682 sec)
17.18... logprob:  0.707885, 0.335938 (0.682 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.666450, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.977998e-03 [4.413379e-09] 
Layer 'conv1' biases: 1.710138e-08 [6.895894e-11] 
Layer 'conv2' weights[0]: 7.964884e-03 [4.591458e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.908936e-10] 
Layer 'conv3' weights[0]: 7.963262e-03 [4.711381e-09] 
Layer 'conv3' biases: 3.940554e-07 [1.267712e-09] 
Layer 'conv4' weights[0]: 7.995761e-03 [4.835836e-09] 
Layer 'conv4' biases: 9.999996e-01 [1.114534e-08] 
Layer 'conv5' weights[0]: 7.994714e-03 [6.629728e-08] 
Layer 'conv5' biases: 9.999793e-01 [6.936190e-08] 
Layer 'fc6' weights[0]: 7.591539e-03 [1.286197e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.249991e-08] 
Layer 'fc7' weights[0]: 7.837793e-03 [2.354135e-07] 
Layer 'fc7' biases: 9.999420e-01 [2.245638e-07] 
Layer 'fc8' weights[0]: 4.412931e-04 [3.341611e-05] 
Layer 'fc8' biases: 3.268295e-04 [6.251996e-05] 
Train error last 27 batches: 0.663308
-------------------------------------------------------
Not saving because 0.666450 > 0.634406 (10.7: -0.69%)
======================================================= (1.728 sec)
17.19... logprob:  0.666426, 0.328125 (0.676 sec)
17.20... logprob:  0.649068, 0.351562 (0.679 sec)
17.21... logprob:  0.679987, 0.343750 (0.679 sec)
17.22... logprob:  0.689214, 0.320312 (0.678 sec)
17.23... logprob:  0.626485, 0.312500 (0.676 sec)
17.24... logprob:  0.554242, 0.242188 (0.679 sec)
17.25... logprob:  0.723301, 0.320312 (0.677 sec)
17.26... logprob:  0.819275, 0.390625 (0.677 sec)
17.27... logprob:  0.627099, 0.320312 (0.676 sec)
18.1... logprob:  0.697536, 0.601562 (0.676 sec)
18.2... logprob:  0.796465, 0.726562 (0.677 sec)
18.3... logprob:  0.657207, 0.359375 (0.675 sec)
18.4... logprob:  0.592393, 0.273438 (0.676 sec)
18.5... logprob:  0.633119, 0.265625 (0.677 sec)
18.6... logprob:  0.709090, 0.296875 (0.679 sec)
18.7... logprob:  0.714179, 0.343750 (0.690 sec)
18.8... logprob:  0.613058, 0.289062 (0.674 sec)
18.9... logprob:  0.695544, 0.664062 (0.677 sec)
18.10... logprob:  0.694540, 0.718750 (0.675 sec)
18.11... logprob:  0.638293, 0.335938 (0.684 sec)
18.12... logprob:  0.811094, 0.437500 (0.679 sec)
18.13... logprob:  0.689998, 0.359375 (0.676 sec)
18.14... logprob:  0.659110, 0.367188 (0.674 sec)
18.15... logprob:  0.681537, 0.398438 (0.680 sec)
18.16... logprob:  0.719102, 0.679688 (0.681 sec)
18.17... logprob:  0.658898, 0.335938 (0.684 sec)
18.18... logprob:  0.643722, 0.335938 (0.676 sec)
18.19... logprob:  0.672337, 0.328125 (0.678 sec)
18.20... logprob:  0.709060, 0.351562 (0.677 sec)
18.21... logprob:  0.655014, 0.343750 (0.679 sec)
18.22... logprob:  0.640183, 0.320312 (0.677 sec)
18.23... logprob:  0.670228, 0.312500 (0.677 sec)
18.24... logprob:  0.622950, 0.242188 (0.676 sec)
18.25... logprob:  0.633172, 0.320312 (0.682 sec)
18.26... logprob:  0.777538, 0.390625 (0.681 sec)
18.27... logprob:  0.657543, 0.320312 (0.681 sec)
19.1... logprob:  0.696674, 0.398438 (0.677 sec)
19.2... logprob:  0.652217, 0.273438 (0.678 sec)
19.3... logprob:  0.682011, 0.359375 (0.677 sec)
19.4... logprob:  0.635938, 0.273438 (0.676 sec)
19.5... logprob:  0.580095, 0.265625 (0.674 sec)
19.6... logprob:  0.647125, 0.296875 (0.677 sec)
19.7... logprob:  0.758413, 0.343750 (0.678 sec)
19.8... logprob:  0.627210, 0.289062 (0.678 sec)
19.9... logprob:  0.643350, 0.335938 (0.679 sec)
19.10... logprob:  0.637620, 0.281250 (0.681 sec)
19.11... logprob:  0.671530, 0.335938 (0.679 sec)
19.12... logprob:  0.686067, 0.437500 (0.677 sec)
19.13... logprob:  0.655137, 0.359375 (0.677 sec)
19.14... logprob:  0.658179, 0.367188 (0.677 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.690728, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.977797e-03 [4.326291e-09] 
Layer 'conv1' biases: 1.908068e-08 [5.152917e-11] 
Layer 'conv2' weights[0]: 7.964698e-03 [4.379792e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.127743e-10] 
Layer 'conv3' weights[0]: 7.963059e-03 [4.471529e-09] 
Layer 'conv3' biases: 4.193529e-07 [1.010163e-09] 
Layer 'conv4' weights[0]: 7.995555e-03 [4.599645e-09] 
Layer 'conv4' biases: 9.999995e-01 [9.183503e-09] 
Layer 'conv5' weights[0]: 7.994544e-03 [5.853614e-08] 
Layer 'conv5' biases: 9.999827e-01 [6.158617e-08] 
Layer 'fc6' weights[0]: 7.591341e-03 [9.880225e-09] 
Layer 'fc6' biases: 9.999999e-01 [9.044749e-09] 
Layer 'fc7' weights[0]: 7.835969e-03 [1.712398e-07] 
Layer 'fc7' biases: 9.999241e-01 [1.600708e-07] 
Layer 'fc8' weights[0]: 4.076601e-04 [2.086769e-05] 
Layer 'fc8' biases: 2.541975e-04 [4.736622e-05] 
Train error last 27 batches: 0.665661
-------------------------------------------------------
Not saving because 0.690728 > 0.634406 (10.7: -0.69%)
======================================================= (1.745 sec)
19.15... logprob:  0.684945, 0.398438 (0.676 sec)
19.16... logprob:  0.628151, 0.320312 (0.678 sec)
19.17... logprob:  0.638587, 0.335938 (0.678 sec)
19.18... logprob:  0.638489, 0.335938 (0.683 sec)
19.19... logprob:  0.633067, 0.328125 (0.676 sec)
19.20... logprob:  0.649762, 0.351562 (0.679 sec)
19.21... logprob:  0.643916, 0.343750 (0.677 sec)
19.22... logprob:  0.627960, 0.320312 (0.676 sec)
19.23... logprob:  0.622602, 0.312500 (0.676 sec)
19.24... logprob:  0.569321, 0.242188 (0.677 sec)
19.25... logprob:  0.633501, 0.320312 (0.676 sec)
19.26... logprob:  0.718028, 0.390625 (0.676 sec)
19.27... logprob:  0.628324, 0.320312 (0.682 sec)
20.1... logprob:  0.675739, 0.398438 (0.678 sec)
20.2... logprob:  0.646597, 0.273438 (0.684 sec)
20.3... logprob:  0.660322, 0.359375 (0.675 sec)
20.4... logprob:  0.605445, 0.273438 (0.674 sec)
20.5... logprob:  0.579004, 0.265625 (0.680 sec)
20.6... logprob:  0.633500, 0.296875 (0.675 sec)
20.7... logprob:  0.717727, 0.343750 (0.679 sec)
20.8... logprob:  0.612185, 0.289062 (0.675 sec)
20.9... logprob:  0.641072, 0.335938 (0.676 sec)
20.10... logprob:  0.624652, 0.281250 (0.675 sec)
20.11... logprob:  0.655451, 0.335938 (0.686 sec)
20.12... logprob:  0.688300, 0.437500 (0.687 sec)
20.13... logprob:  0.655980, 0.359375 (0.693 sec)
20.14... logprob:  0.657512, 0.367188 (0.685 sec)
20.15... logprob:  0.677377, 0.398438 (0.684 sec)
20.16... logprob:  0.629729, 0.320312 (0.683 sec)
20.17... logprob:  0.638361, 0.335938 (0.685 sec)
20.18... logprob:  0.638503, 0.335938 (0.686 sec)
20.19... logprob:  0.633048, 0.328125 (0.684 sec)
20.20... logprob:  0.651298, 0.351562 (0.684 sec)
20.21... logprob:  0.643796, 0.343750 (0.688 sec)
20.22... logprob:  0.629417, 0.320312 (0.687 sec)
20.23... logprob:  0.625076, 0.312500 (0.690 sec)
20.24... logprob:  0.574010, 0.242188 (0.684 sec)
20.25... logprob:  0.632392, 0.320312 (0.684 sec)
20.26... logprob:  0.721465, 0.390625 (0.683 sec)
20.27... logprob:  0.630689, 0.320312 (0.684 sec)
21.1... logprob:  0.680364, 0.398438 (0.683 sec)
21.2... logprob:  0.636342, 0.273438 (0.680 sec)
21.3... logprob:  0.661630, 0.359375 (0.682 sec)
21.4... logprob:  0.615173, 0.273438 (0.675 sec)
21.5... logprob:  0.581583, 0.265625 (0.681 sec)
21.6... logprob:  0.625226, 0.296875 (0.680 sec)
21.7... logprob:  0.714682, 0.343750 (0.678 sec)
21.8... logprob:  0.617714, 0.289062 (0.677 sec)
21.9... logprob:  0.648235, 0.335938 (0.675 sec)
21.10... logprob:  0.610143, 0.281250 (0.676 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.648471, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.977586e-03 [4.343227e-09] 
Layer 'conv1' biases: 2.018981e-08 [5.906741e-11] 
Layer 'conv2' weights[0]: 7.964513e-03 [4.426666e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.184495e-10] 
Layer 'conv3' weights[0]: 7.962851e-03 [4.455333e-09] 
Layer 'conv3' biases: 4.303039e-07 [1.006548e-09] 
Layer 'conv4' weights[0]: 7.995362e-03 [4.545812e-09] 
Layer 'conv4' biases: 9.999995e-01 [8.637849e-09] 
Layer 'conv5' weights[0]: 7.994417e-03 [5.456066e-08] 
Layer 'conv5' biases: 9.999838e-01 [5.838467e-08] 
Layer 'fc6' weights[0]: 7.591157e-03 [8.776321e-09] 
Layer 'fc6' biases: 9.999999e-01 [7.808842e-09] 
Layer 'fc7' weights[0]: 7.834113e-03 [1.454992e-07] 
Layer 'fc7' biases: 9.999180e-01 [1.330974e-07] 
Layer 'fc8' weights[0]: 3.892056e-04 [3.857847e-05] 
Layer 'fc8' biases: 1.193616e-04 [9.070532e-05] 
Train error last 27 batches: 0.643463
-------------------------------------------------------
Not saving because 0.648471 > 0.634406 (10.7: -0.69%)
======================================================= (1.751 sec)
21.11... logprob:  0.651167, 0.335938 (0.678 sec)
21.12... logprob:  0.686179, 0.437500 (0.677 sec)
21.13... logprob:  0.663448, 0.359375 (0.679 sec)
21.14... logprob:  0.660367, 0.367188 (0.683 sec)
21.15... logprob:  0.675010, 0.398438 (0.678 sec)
21.16... logprob:  0.628420, 0.320312 (0.677 sec)
21.17... logprob:  0.639139, 0.335938 (0.680 sec)
21.18... logprob:  0.641025, 0.335938 (0.677 sec)
21.19... logprob:  0.634200, 0.328125 (0.677 sec)
21.20... logprob:  0.651123, 0.351562 (0.677 sec)
21.21... logprob:  0.643481, 0.343750 (0.678 sec)
21.22... logprob:  0.632832, 0.320312 (0.678 sec)
21.23... logprob:  0.628238, 0.312500 (0.697 sec)
21.24... logprob:  0.576096, 0.242188 (0.687 sec)
21.25... logprob:  0.633018, 0.320312 (0.687 sec)
21.26... logprob:  0.728330, 0.390625 (0.681 sec)
21.27... logprob:  0.634277, 0.320312 (0.678 sec)
22.1... logprob:  0.685826, 0.398438 (0.682 sec)
22.2... logprob:  0.628779, 0.273438 (0.678 sec)
22.3... logprob:  0.662998, 0.359375 (0.677 sec)
22.4... logprob:  0.625599, 0.273438 (0.676 sec)
22.5... logprob:  0.586904, 0.265625 (0.683 sec)
22.6... logprob:  0.618346, 0.296875 (0.678 sec)
22.7... logprob:  0.709517, 0.343750 (0.682 sec)
22.8... logprob:  0.622504, 0.289062 (0.680 sec)
22.9... logprob:  0.658349, 0.335938 (0.680 sec)
22.10... logprob:  0.599838, 0.281250 (0.675 sec)
22.11... logprob:  0.645110, 0.335938 (0.676 sec)
22.12... logprob:  0.685765, 0.437500 (0.676 sec)
22.13... logprob:  0.672694, 0.359375 (0.676 sec)
22.14... logprob:  0.668223, 0.367188 (0.676 sec)
22.15... logprob:  0.672557, 0.398438 (0.676 sec)
22.16... logprob:  0.628966, 0.320312 (0.677 sec)
22.17... logprob:  0.640800, 0.335938 (0.676 sec)
22.18... logprob:  0.646360, 0.335938 (0.677 sec)
22.19... logprob:  0.638567, 0.328125 (0.681 sec)
22.20... logprob:  0.654408, 0.351562 (0.676 sec)
22.21... logprob:  0.643474, 0.343750 (0.680 sec)
22.22... logprob:  0.635817, 0.320312 (0.690 sec)
22.23... logprob:  0.634569, 0.312500 (0.679 sec)
22.24... logprob:  0.586512, 0.242188 (0.676 sec)
22.25... logprob:  0.630009, 0.320312 (0.677 sec)
22.26... logprob:  0.726317, 0.390625 (0.678 sec)
22.27... logprob:  0.638487, 0.320312 (0.677 sec)
23.1... logprob:  0.697355, 0.398438 (0.679 sec)
23.2... logprob:  0.611890, 0.273438 (0.684 sec)
23.3... logprob:  0.659236, 0.359375 (0.681 sec)
23.4... logprob:  0.632318, 0.273438 (0.676 sec)
23.5... logprob:  0.597836, 0.265625 (0.677 sec)
23.6... logprob:  0.610121, 0.296875 (0.676 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.659126, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.977375e-03 [4.333682e-09] 
Layer 'conv1' biases: 2.123247e-08 [2.696149e-11] 
Layer 'conv2' weights[0]: 7.964303e-03 [4.132058e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.875728e-10] 
Layer 'conv3' weights[0]: 7.962654e-03 [4.151990e-09] 
Layer 'conv3' biases: 4.413846e-07 [5.482466e-10] 
Layer 'conv4' weights[0]: 7.995159e-03 [4.211832e-09] 
Layer 'conv4' biases: 9.999995e-01 [4.864903e-09] 
Layer 'conv5' weights[0]: 7.994279e-03 [2.859359e-08] 
Layer 'conv5' biases: 9.999858e-01 [2.977707e-08] 
Layer 'fc6' weights[0]: 7.590960e-03 [5.332570e-09] 
Layer 'fc6' biases: 9.999999e-01 [3.634027e-09] 
Layer 'fc7' weights[0]: 7.832389e-03 [7.564510e-08] 
Layer 'fc7' biases: 9.999121e-01 [5.713096e-08] 
Layer 'fc8' weights[0]: 4.685333e-04 [6.453748e-05] 
Layer 'fc8' biases: 6.537295e-04 [1.648764e-04] 
Train error last 27 batches: 0.646207
-------------------------------------------------------
Not saving because 0.659126 > 0.634406 (10.7: -0.69%)
======================================================= (1.794 sec)
23.7... logprob:  0.689960, 0.343750 (0.676 sec)
23.8... logprob:  0.620209, 0.289062 (0.675 sec)
23.9... logprob:  0.667530, 0.335938 (0.681 sec)
23.10... logprob:  0.594372, 0.281250 (0.681 sec)
23.11... logprob:  0.638717, 0.335938 (0.678 sec)
23.12... logprob:  0.688172, 0.437500 (0.677 sec)
23.13... logprob:  0.675603, 0.359375 (0.679 sec)
23.14... logprob:  0.680724, 0.367188 (0.678 sec)
23.15... logprob:  0.674917, 0.398438 (0.676 sec)
23.16... logprob:  0.635547, 0.320312 (0.692 sec)
23.17... logprob:  0.639443, 0.335938 (0.688 sec)
23.18... logprob:  0.650262, 0.335938 (0.684 sec)
23.19... logprob:  0.647910, 0.328125 (0.687 sec)
23.20... logprob:  0.666944, 0.351562 (0.689 sec)
23.21... logprob:  0.646141, 0.343750 (0.686 sec)
23.22... logprob:  0.632121, 0.320312 (0.683 sec)
23.23... logprob:  0.638748, 0.312500 (0.684 sec)
23.24... logprob:  0.606439, 0.242188 (0.684 sec)
23.25... logprob:  0.627175, 0.320312 (0.685 sec)
23.26... logprob:  0.704767, 0.390625 (0.686 sec)
23.27... logprob:  0.635831, 0.320312 (0.688 sec)
24.1... logprob:  0.707248, 0.398438 (0.676 sec)
24.2... logprob:  0.595822, 0.273438 (0.678 sec)
24.3... logprob:  0.653262, 0.359375 (0.678 sec)
24.4... logprob:  0.619545, 0.273438 (0.675 sec)
24.5... logprob:  0.602990, 0.265625 (0.672 sec)
24.6... logprob:  0.608372, 0.296875 (0.671 sec)
24.7... logprob:  0.664403, 0.343750 (0.674 sec)
24.8... logprob:  0.608528, 0.289062 (0.671 sec)
24.9... logprob:  0.661701, 0.335938 (0.674 sec)
24.10... logprob:  0.594224, 0.281250 (0.678 sec)
24.11... logprob:  0.639731, 0.335938 (0.676 sec)
24.12... logprob:  0.699682, 0.437500 (0.672 sec)
24.13... logprob:  0.663719, 0.359375 (0.677 sec)
24.14... logprob:  0.679706, 0.367188 (0.675 sec)
24.15... logprob:  0.681213, 0.398438 (0.675 sec)
24.16... logprob:  0.652652, 0.320312 (0.671 sec)
24.17... logprob:  0.639294, 0.335938 (0.669 sec)
24.18... logprob:  0.643502, 0.335938 (0.669 sec)
24.19... logprob:  0.648432, 0.328125 (0.673 sec)
24.20... logprob:  0.679526, 0.351562 (0.673 sec)
24.21... logprob:  0.657683, 0.343750 (0.672 sec)
24.22... logprob:  0.627090, 0.320312 (0.672 sec)
24.23... logprob:  0.628702, 0.312500 (0.673 sec)
24.24... logprob:  0.607068, 0.242188 (0.676 sec)
24.25... logprob:  0.630666, 0.320312 (0.680 sec)
24.26... logprob:  0.681819, 0.390625 (0.685 sec)
24.27... logprob:  0.627895, 0.320312 (0.678 sec)
25.1... logprob:  0.695790, 0.398438 (0.679 sec)
25.2... logprob:  0.593418, 0.273438 (0.679 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.654216, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.977184e-03 [4.433613e-09] 
Layer 'conv1' biases: 2.266294e-08 [3.851003e-11] 
Layer 'conv2' weights[0]: 7.964102e-03 [4.245018e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.212143e-10] 
Layer 'conv3' weights[0]: 7.962461e-03 [4.220583e-09] 
Layer 'conv3' biases: 4.586048e-07 [6.774112e-10] 
Layer 'conv4' weights[0]: 7.994965e-03 [4.274957e-09] 
Layer 'conv4' biases: 9.999995e-01 [5.874156e-09] 
Layer 'conv5' weights[0]: 7.994097e-03 [3.840774e-08] 
Layer 'conv5' biases: 9.999881e-01 [4.105577e-08] 
Layer 'fc6' weights[0]: 7.590752e-03 [6.105203e-09] 
Layer 'fc6' biases: 9.999999e-01 [4.735041e-09] 
Layer 'fc7' weights[0]: 7.830603e-03 [9.485260e-08] 
Layer 'fc7' biases: 9.999056e-01 [7.934792e-08] 
Layer 'fc8' weights[0]: 4.082422e-04 [8.917106e-06] 
Layer 'fc8' biases: 3.913734e-04 [2.430815e-05] 
Train error last 27 batches: 0.644097
-------------------------------------------------------
Not saving because 0.654216 > 0.634406 (10.7: -0.69%)
======================================================= (1.754 sec)
25.3... logprob:  0.654218, 0.359375 (0.676 sec)
25.4... logprob:  0.601056, 0.273438 (0.674 sec)
25.5... logprob:  0.591418, 0.265625 (0.676 sec)
25.6... logprob:  0.608227, 0.296875 (0.673 sec)
25.7... logprob:  0.657140, 0.343750 (0.674 sec)
25.8... logprob:  0.602944, 0.289062 (0.668 sec)
25.9... logprob:  0.649914, 0.335938 (0.668 sec)
25.10... logprob:  0.594405, 0.281250 (0.669 sec)
25.11... logprob:  0.639583, 0.335938 (0.668 sec)
25.12... logprob:  0.706046, 0.437500 (0.672 sec)
25.13... logprob:  0.656670, 0.359375 (0.673 sec)
25.14... logprob:  0.669215, 0.367188 (0.672 sec)
25.15... logprob:  0.678212, 0.398438 (0.676 sec)
25.16... logprob:  0.656931, 0.320312 (0.676 sec)
25.17... logprob:  0.643291, 0.335938 (0.675 sec)
25.18... logprob:  0.638863, 0.335938 (0.672 sec)
25.19... logprob:  0.640338, 0.328125 (0.676 sec)
25.20... logprob:  0.674156, 0.351562 (0.675 sec)
25.21... logprob:  0.660905, 0.343750 (0.676 sec)
25.22... logprob:  0.628631, 0.320312 (0.674 sec)
25.23... logprob:  0.622493, 0.312500 (0.672 sec)
25.24... logprob:  0.590472, 0.242188 (0.678 sec)
25.25... logprob:  0.629532, 0.320312 (0.675 sec)
25.26... logprob:  0.677517, 0.390625 (0.675 sec)
25.27... logprob:  0.627206, 0.320312 (0.682 sec)
26.1... logprob:  0.684667, 0.398438 (0.674 sec)
26.2... logprob:  0.598611, 0.273438 (0.678 sec)
26.3... logprob:  0.653774, 0.359375 (0.678 sec)
26.4... logprob:  0.597860, 0.273438 (0.676 sec)
26.5... logprob:  0.586350, 0.265625 (0.677 sec)
26.6... logprob:  0.608468, 0.296875 (0.679 sec)
26.7... logprob:  0.661270, 0.343750 (0.677 sec)
26.8... logprob:  0.603517, 0.289062 (0.675 sec)
26.9... logprob:  0.649209, 0.335938 (0.681 sec)
26.10... logprob:  0.594802, 0.281250 (0.676 sec)
26.11... logprob:  0.638844, 0.335938 (0.673 sec)
26.12... logprob:  0.703110, 0.437500 (0.674 sec)
26.13... logprob:  0.656908, 0.359375 (0.674 sec)
26.14... logprob:  0.668098, 0.367188 (0.675 sec)
26.15... logprob:  0.677125, 0.398438 (0.674 sec)
26.16... logprob:  0.655258, 0.320312 (0.677 sec)
26.17... logprob:  0.643692, 0.335938 (0.678 sec)
26.18... logprob:  0.638483, 0.335938 (0.678 sec)
26.19... logprob:  0.638357, 0.328125 (0.679 sec)
26.20... logprob:  0.671234, 0.351562 (0.677 sec)
26.21... logprob:  0.660535, 0.343750 (0.676 sec)
26.22... logprob:  0.629383, 0.320312 (0.677 sec)
26.23... logprob:  0.621544, 0.312500 (0.679 sec)
26.24... logprob:  0.584337, 0.242188 (0.676 sec)
26.25... logprob:  0.628779, 0.320312 (0.681 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627340, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.976979e-03 [4.291124e-09] 
Layer 'conv1' biases: 2.370907e-08 [2.674518e-11] 
Layer 'conv2' weights[0]: 7.963916e-03 [4.101458e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.457216e-10] 
Layer 'conv3' weights[0]: 7.962258e-03 [4.090807e-09] 
Layer 'conv3' biases: 4.693452e-07 [4.418583e-10] 
Layer 'conv4' weights[0]: 7.994759e-03 [4.114118e-09] 
Layer 'conv4' biases: 9.999995e-01 [3.727382e-09] 
Layer 'conv5' weights[0]: 7.993928e-03 [2.420537e-08] 
Layer 'conv5' biases: 9.999894e-01 [2.566876e-08] 
Layer 'fc6' weights[0]: 7.590551e-03 [4.762205e-09] 
Layer 'fc6' biases: 9.999999e-01 [2.664270e-09] 
Layer 'fc7' weights[0]: 7.828770e-03 [6.335105e-08] 
Layer 'fc7' biases: 9.999019e-01 [4.345490e-08] 
Layer 'fc8' weights[0]: 4.136609e-04 [1.842862e-05] 
Layer 'fc8' biases: 4.593366e-04 [5.525293e-05] 
Train error last 27 batches: 0.639220
-------------------------------------------------------
Saved checkpoint to /homes/ad6813/Git/pipe-classification/models/scraping_peeling/net_0/saves/ConvNet__2014-07-08_14.54.04
======================================================= (5.656 sec)
26.26... logprob:  0.676948, 0.390625 (0.677 sec)
26.27... logprob:  0.627532, 0.320312 (0.672 sec)
27.1... logprob:  0.681698, 0.398438 (0.675 sec)
27.2... logprob:  0.601062, 0.273438 (0.677 sec)
27.3... logprob:  0.653469, 0.359375 (0.676 sec)
27.4... logprob:  0.597818, 0.273438 (0.679 sec)
27.5... logprob:  0.585678, 0.265625 (0.674 sec)
27.6... logprob:  0.608645, 0.296875 (0.678 sec)
27.7... logprob:  0.662391, 0.343750 (0.678 sec)
27.8... logprob:  0.603988, 0.289062 (0.679 sec)
27.9... logprob:  0.650269, 0.335938 (0.728 sec)
27.10... logprob:  0.594548, 0.281250 (0.690 sec)
27.11... logprob:  0.639044, 0.335938 (0.695 sec)
27.12... logprob:  0.703568, 0.437500 (0.684 sec)
27.13... logprob:  0.656704, 0.359375 (0.683 sec)
27.14... logprob:  0.668124, 0.367188 (0.675 sec)
27.15... logprob:  0.677663, 0.398438 (0.682 sec)
27.16... logprob:  0.657688, 0.320312 (0.674 sec)
27.17... logprob:  0.645409, 0.335938 (0.676 sec)
27.18... logprob:  0.638285, 0.335938 (0.674 sec)
27.19... logprob:  0.637102, 0.328125 (0.675 sec)
27.20... logprob:  0.670411, 0.351562 (0.679 sec)
27.21... logprob:  0.662133, 0.343750 (0.677 sec)
27.22... logprob:  0.630989, 0.320312 (0.680 sec)
27.23... logprob:  0.621089, 0.312500 (0.713 sec)
27.24... logprob:  0.578604, 0.242188 (0.680 sec)
27.25... logprob:  0.628245, 0.320312 (0.681 sec)
27.26... logprob:  0.676041, 0.390625 (0.678 sec)
27.27... logprob:  0.628237, 0.320312 (0.677 sec)
28.1... logprob:  0.678743, 0.398438 (0.705 sec)
28.2... logprob:  0.604290, 0.273438 (0.685 sec)
28.3... logprob:  0.653204, 0.359375 (0.684 sec)
28.4... logprob:  0.597951, 0.273438 (0.681 sec)
28.5... logprob:  0.585031, 0.265625 (0.684 sec)
28.6... logprob:  0.608915, 0.296875 (0.683 sec)
28.7... logprob:  0.664006, 0.343750 (0.689 sec)
28.8... logprob:  0.604727, 0.289062 (0.687 sec)
28.9... logprob:  0.651835, 0.335938 (0.694 sec)
28.10... logprob:  0.594304, 0.281250 (0.687 sec)
28.11... logprob:  0.639349, 0.335938 (0.684 sec)
28.12... logprob:  0.704176, 0.437500 (0.685 sec)
28.13... logprob:  0.656517, 0.359375 (0.685 sec)
28.14... logprob:  0.668273, 0.367188 (0.687 sec)
28.15... logprob:  0.678371, 0.398438 (0.688 sec)
28.16... logprob:  0.660627, 0.320312 (0.684 sec)
28.17... logprob:  0.647631, 0.335938 (0.687 sec)
28.18... logprob:  0.638407, 0.335938 (0.686 sec)
28.19... logprob:  0.635803, 0.328125 (0.691 sec)
28.20... logprob:  0.669104, 0.351562 (0.683 sec)
28.21... logprob:  0.663457, 0.343750 (0.684 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.640721, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.976783e-03 [4.509191e-09] 
Layer 'conv1' biases: 2.473579e-08 [6.157317e-11] 
Layer 'conv2' weights[0]: 7.963737e-03 [4.527277e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.435824e-10] 
Layer 'conv3' weights[0]: 7.962062e-03 [4.520303e-09] 
Layer 'conv3' biases: 4.802583e-07 [1.049976e-09] 
Layer 'conv4' weights[0]: 7.994552e-03 [4.625434e-09] 
Layer 'conv4' biases: 9.999995e-01 [9.346572e-09] 
Layer 'conv5' weights[0]: 7.993743e-03 [6.124170e-08] 
Layer 'conv5' biases: 9.999905e-01 [6.591379e-08] 
Layer 'fc6' weights[0]: 7.590360e-03 [8.129303e-09] 
Layer 'fc6' biases: 9.999999e-01 [7.084971e-09] 
Layer 'fc7' weights[0]: 7.826998e-03 [1.289557e-07] 
Layer 'fc7' biases: 9.998992e-01 [1.150698e-07] 
Layer 'fc8' weights[0]: 4.531618e-04 [2.176344e-05] 
Layer 'fc8' biases: 7.385637e-04 [6.779050e-05] 
Train error last 27 batches: 0.639553
-------------------------------------------------------
Not saving because 0.640721 > 0.627340 (26.25: -1.11%)
======================================================= (1.729 sec)
28.22... logprob:  0.632984, 0.320312 (0.685 sec)
28.23... logprob:  0.621430, 0.312500 (0.683 sec)
28.24... logprob:  0.572561, 0.242188 (0.685 sec)
28.25... logprob:  0.627578, 0.320312 (0.686 sec)
28.26... logprob:  0.676005, 0.390625 (0.688 sec)
28.27... logprob:  0.628959, 0.320312 (0.691 sec)
29.1... logprob:  0.676450, 0.398438 (0.688 sec)
29.2... logprob:  0.608538, 0.273438 (0.684 sec)
29.3... logprob:  0.653043, 0.359375 (0.682 sec)
29.4... logprob:  0.599495, 0.273438 (0.685 sec)
29.5... logprob:  0.585324, 0.265625 (0.683 sec)
29.6... logprob:  0.609010, 0.296875 (0.691 sec)
29.7... logprob:  0.665443, 0.343750 (0.687 sec)
29.8... logprob:  0.605865, 0.289062 (0.682 sec)
29.9... logprob:  0.654755, 0.335938 (0.688 sec)
29.10... logprob:  0.594117, 0.281250 (0.689 sec)
29.11... logprob:  0.640264, 0.335938 (0.690 sec)
29.12... logprob:  0.706347, 0.437500 (0.685 sec)
29.13... logprob:  0.656013, 0.359375 (0.687 sec)
29.14... logprob:  0.668484, 0.367188 (0.688 sec)
29.15... logprob:  0.679680, 0.398438 (0.685 sec)
29.16... logprob:  0.665776, 0.320312 (0.682 sec)
29.17... logprob:  0.651569, 0.335938 (0.684 sec)
29.18... logprob:  0.639238, 0.335938 (0.684 sec)
29.19... logprob:  0.634352, 0.328125 (0.684 sec)
29.20... logprob:  0.667128, 0.351562 (0.686 sec)
29.21... logprob:  0.664791, 0.343750 (0.688 sec)
29.22... logprob:  0.635837, 0.320312 (0.686 sec)
29.23... logprob:  0.623034, 0.312500 (0.686 sec)
29.24... logprob:  0.565792, 0.242188 (0.682 sec)
29.25... logprob:  0.627095, 0.320312 (0.676 sec)
29.26... logprob:  0.677216, 0.390625 (0.676 sec)
29.27... logprob:  0.629391, 0.320312 (0.675 sec)
30.1... logprob:  0.674735, 0.398438 (0.675 sec)
30.2... logprob:  0.614376, 0.273438 (0.680 sec)
30.3... logprob:  0.653485, 0.359375 (0.675 sec)
30.4... logprob:  0.603435, 0.273438 (0.675 sec)
30.5... logprob:  0.587200, 0.265625 (0.676 sec)
30.6... logprob:  0.608727, 0.296875 (0.675 sec)
30.7... logprob:  0.665837, 0.343750 (0.676 sec)
30.8... logprob:  0.607283, 0.289062 (0.677 sec)
30.9... logprob:  0.659399, 0.335938 (0.676 sec)
30.10... logprob:  0.594608, 0.281250 (0.676 sec)
30.11... logprob:  0.642795, 0.335938 (0.676 sec)
30.12... logprob:  0.712151, 0.437500 (0.676 sec)
30.13... logprob:  0.654720, 0.359375 (0.679 sec)
30.14... logprob:  0.667647, 0.367188 (0.678 sec)
30.15... logprob:  0.681207, 0.398438 (0.679 sec)
30.16... logprob:  0.673859, 0.320312 (0.682 sec)
30.17... logprob:  0.659211, 0.335938 (0.676 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.676940, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.976578e-03 [4.369395e-09] 
Layer 'conv1' biases: 2.622568e-08 [4.133430e-11] 
Layer 'conv2' weights[0]: 7.963534e-03 [4.286765e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.874339e-10] 
Layer 'conv3' weights[0]: 7.961861e-03 [4.340498e-09] 
Layer 'conv3' biases: 4.982261e-07 [8.293561e-10] 
Layer 'conv4' weights[0]: 7.994357e-03 [4.455047e-09] 
Layer 'conv4' biases: 9.999995e-01 [7.802723e-09] 
Layer 'conv5' weights[0]: 7.993566e-03 [4.526933e-08] 
Layer 'conv5' biases: 9.999929e-01 [4.760824e-08] 
Layer 'fc6' weights[0]: 7.590167e-03 [6.219304e-09] 
Layer 'fc6' biases: 9.999999e-01 [4.862589e-09] 
Layer 'fc7' weights[0]: 7.825235e-03 [8.931349e-08] 
Layer 'fc7' biases: 9.998956e-01 [7.209722e-08] 
Layer 'fc8' weights[0]: 3.993339e-04 [6.368565e-05] 
Layer 'fc8' biases: 4.176436e-04 [2.187539e-04] 
Train error last 27 batches: 0.641650
-------------------------------------------------------
Not saving because 0.676940 > 0.627340 (26.25: -1.11%)
======================================================= (1.754 sec)
30.18... logprob:  0.642386, 0.335938 (0.685 sec)
30.19... logprob:  0.632919, 0.328125 (0.685 sec)
30.20... logprob:  0.662636, 0.351562 (0.685 sec)
30.21... logprob:  0.664472, 0.343750 (0.686 sec)
30.22... logprob:  0.639274, 0.320312 (0.687 sec)
30.23... logprob:  0.626867, 0.312500 (0.688 sec)
30.24... logprob:  0.558673, 0.242188 (0.686 sec)
30.25... logprob:  0.628215, 0.320312 (0.684 sec)
30.26... logprob:  0.682191, 0.390625 (0.693 sec)
30.27... logprob:  0.628543, 0.320312 (0.687 sec)
31.1... logprob:  0.674141, 0.398438 (0.705 sec)
31.2... logprob:  0.620736, 0.273438 (0.678 sec)
31.3... logprob:  0.655576, 0.359375 (0.674 sec)
31.4... logprob:  0.612717, 0.273438 (0.674 sec)
31.5... logprob:  0.593677, 0.265625 (0.677 sec)
31.6... logprob:  0.608166, 0.296875 (0.679 sec)
31.7... logprob:  0.661785, 0.343750 (0.677 sec)
31.8... logprob:  0.607516, 0.289062 (0.675 sec)
31.9... logprob:  0.664647, 0.335938 (0.677 sec)
31.10... logprob:  0.596962, 0.281250 (0.677 sec)
31.11... logprob:  0.649723, 0.335938 (0.676 sec)
31.12... logprob:  0.727692, 0.437500 (0.676 sec)
31.13... logprob:  0.653060, 0.359375 (0.677 sec)
31.14... logprob:  0.663015, 0.367188 (0.679 sec)
31.15... logprob:  0.680240, 0.398438 (0.685 sec)
31.16... logprob:  0.681947, 0.320312 (0.678 sec)
31.17... logprob:  0.672992, 0.335938 (0.680 sec)
31.18... logprob:  0.653063, 0.335938 (0.681 sec)
31.19... logprob:  0.635245, 0.328125 (0.676 sec)
31.20... logprob:  0.653244, 0.351562 (0.676 sec)
31.21... logprob:  0.657210, 0.343750 (0.677 sec)
31.22... logprob:  0.639337, 0.320312 (0.676 sec)
31.23... logprob:  0.631917, 0.312500 (0.677 sec)
31.24... logprob:  0.554072, 0.242188 (0.676 sec)
31.25... logprob:  0.635783, 0.320312 (0.679 sec)
31.26... logprob:  0.699307, 0.390625 (0.681 sec)
31.27... logprob:  0.627246, 0.320312 (0.678 sec)
32.1... logprob:  0.677818, 0.398438 (0.679 sec)
32.2... logprob:  0.617441, 0.273438 (0.682 sec)
32.3... logprob:  0.657874, 0.359375 (0.676 sec)
32.4... logprob:  0.627963, 0.273438 (0.676 sec)
32.5... logprob:  0.611529, 0.265625 (0.677 sec)
32.6... logprob:  0.612782, 0.296875 (0.678 sec)
32.7... logprob:  0.648900, 0.343750 (0.676 sec)
32.8... logprob:  0.602718, 0.289062 (0.676 sec)
32.9... logprob:  0.659856, 0.335938 (0.676 sec)
32.10... logprob:  0.598788, 0.281250 (0.677 sec)
32.11... logprob:  0.660615, 0.335938 (0.678 sec)
32.12... logprob:  0.759182, 0.437500 (0.678 sec)
32.13... logprob:  0.659496, 0.359375 (0.676 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.635272, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.976395e-03 [5.802869e-09] 
Layer 'conv1' biases: 2.844866e-08 [1.527730e-10] 
Layer 'conv2' weights[0]: 7.963342e-03 [6.638255e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.190474e-10] 
Layer 'conv3' weights[0]: 7.961651e-03 [6.497374e-09] 
Layer 'conv3' biases: 5.269908e-07 [2.788316e-09] 
Layer 'conv4' weights[0]: 7.994160e-03 [6.904801e-09] 
Layer 'conv4' biases: 9.999997e-01 [2.605318e-08] 
Layer 'conv5' weights[0]: 7.993433e-03 [1.709682e-07] 
Layer 'conv5' biases: 9.999967e-01 [1.852949e-07] 
Layer 'fc6' weights[0]: 7.589985e-03 [1.867637e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.825177e-08] 
Layer 'fc7' weights[0]: 7.823453e-03 [2.926593e-07] 
Layer 'fc7' biases: 9.998889e-01 [2.816400e-07] 
Layer 'fc8' weights[0]: 4.143898e-04 [7.627460e-05] 
Layer 'fc8' biases: 6.323439e-04 [2.983345e-04] 
Train error last 27 batches: 0.647392
-------------------------------------------------------
Not saving because 0.635272 > 0.627340 (26.25: -1.11%)
======================================================= (1.696 sec)
32.14... logprob:  0.657493, 0.367188 (0.675 sec)
32.15... logprob:  0.672896, 0.398438 (0.676 sec)
32.16... logprob:  0.667879, 0.320312 (0.677 sec)
32.17... logprob:  0.678024, 0.335938 (0.676 sec)
32.18... logprob:  0.670793, 0.335938 (0.675 sec)
32.19... logprob:  0.652976, 0.328125 (0.679 sec)
32.20... logprob:  0.649854, 0.351562 (0.679 sec)
32.21... logprob:  0.643794, 0.343750 (0.682 sec)
32.22... logprob:  0.628589, 0.320312 (0.677 sec)
32.23... logprob:  0.625968, 0.312500 (0.677 sec)
32.24... logprob:  0.553815, 0.242188 (0.677 sec)
32.25... logprob:  0.645456, 0.320312 (0.676 sec)
32.26... logprob:  0.729841, 0.390625 (0.675 sec)
32.27... logprob:  0.638278, 0.320312 (0.675 sec)
33.1... logprob:  0.703801, 0.398438 (0.674 sec)
33.2... logprob:  0.593127, 0.273438 (0.673 sec)
33.3... logprob:  0.653047, 0.359375 (0.681 sec)
33.4... logprob:  0.616911, 0.273438 (0.686 sec)
33.5... logprob:  0.618528, 0.265625 (0.685 sec)
33.6... logprob:  0.625991, 0.296875 (0.680 sec)
33.7... logprob:  0.644232, 0.343750 (0.674 sec)
33.8... logprob:  0.606664, 0.289062 (0.675 sec)
33.9... logprob:  0.639951, 0.335938 (0.675 sec)
33.10... logprob:  0.594254, 0.281250 (0.673 sec)
33.11... logprob:  0.648840, 0.335938 (0.680 sec)
33.12... logprob:  0.756651, 0.437500 (0.679 sec)
33.13... logprob:  0.668678, 0.359375 (0.676 sec)
33.14... logprob:  0.666630, 0.367188 (0.675 sec)
33.15... logprob:  0.680755, 0.398438 (0.715 sec)
33.16... logprob:  0.633779, 0.320312 (0.678 sec)
33.17... logprob:  0.648118, 0.335938 (0.683 sec)
33.18... logprob:  0.653025, 0.335938 (0.685 sec)
33.19... logprob:  0.651294, 0.328125 (0.676 sec)
33.20... logprob:  0.655687, 0.351562 (0.683 sec)
33.21... logprob:  0.648467, 0.343750 (0.684 sec)
33.22... logprob:  0.632376, 0.320312 (0.683 sec)
33.23... logprob:  0.623194, 0.312500 (0.680 sec)
33.24... logprob:  0.566906, 0.242188 (0.677 sec)
33.25... logprob:  0.630231, 0.320312 (0.680 sec)
33.26... logprob:  0.708918, 0.390625 (0.677 sec)
33.27... logprob:  0.637448, 0.320312 (0.678 sec)
34.1... logprob:  0.718675, 0.398438 (0.682 sec)
34.2... logprob:  0.586671, 0.273438 (0.677 sec)
34.3... logprob:  0.662833, 0.359375 (0.677 sec)
34.4... logprob:  0.591282, 0.273438 (0.680 sec)
34.5... logprob:  0.589691, 0.265625 (0.687 sec)
34.6... logprob:  0.612409, 0.296875 (0.680 sec)
34.7... logprob:  0.643532, 0.343750 (0.684 sec)
34.8... logprob:  0.607500, 0.289062 (0.696 sec)
34.9... logprob:  0.638307, 0.335938 (0.684 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627369, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.976210e-03 [4.516095e-09] 
Layer 'conv1' biases: 3.096032e-08 [3.706837e-11] 
Layer 'conv2' weights[0]: 7.963161e-03 [4.207172e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.849953e-10] 
Layer 'conv3' weights[0]: 7.961458e-03 [4.139593e-09] 
Layer 'conv3' biases: 5.626852e-07 [5.520745e-10] 
Layer 'conv4' weights[0]: 7.993972e-03 [4.178106e-09] 
Layer 'conv4' biases: 9.999998e-01 [4.605890e-09] 
Layer 'conv5' weights[0]: 7.993290e-03 [3.096055e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.349570e-08] 
Layer 'fc6' weights[0]: 7.589812e-03 [4.870126e-09] 
Layer 'fc6' biases: 9.999999e-01 [2.833886e-09] 
Layer 'fc7' weights[0]: 7.821720e-03 [6.346787e-08] 
Layer 'fc7' biases: 9.998812e-01 [4.379516e-08] 
Layer 'fc8' weights[0]: 4.620587e-04 [8.987885e-06] 
Layer 'fc8' biases: 1.242556e-03 [4.770073e-05] 
Train error last 27 batches: 0.642820
-------------------------------------------------------
Not saving because 0.627369 > 0.627340 (26.25: -1.11%)
======================================================= (1.796 sec)
34.10... logprob:  0.599792, 0.281250 (0.677 sec)
34.11... logprob:  0.638834, 0.335938 (0.674 sec)
34.12... logprob:  0.719168, 0.437500 (0.681 sec)
34.13... logprob:  0.656336, 0.359375 (0.682 sec)
34.14... logprob:  0.660038, 0.367188 (0.706 sec)
34.15... logprob:  0.677968, 0.398438 (0.679 sec)
34.16... logprob:  0.631856, 0.320312 (0.684 sec)
34.17... logprob:  0.642315, 0.335938 (0.677 sec)
34.18... logprob:  0.643415, 0.335938 (0.677 sec)
34.19... logprob:  0.639593, 0.328125 (0.673 sec)
34.20... logprob:  0.649798, 0.351562 (0.676 sec)
34.21... logprob:  0.644710, 0.343750 (0.671 sec)
34.22... logprob:  0.629987, 0.320312 (0.675 sec)
34.23... logprob:  0.623116, 0.312500 (0.679 sec)
34.24... logprob:  0.570695, 0.242188 (0.683 sec)
34.25... logprob:  0.627758, 0.320312 (0.684 sec)
34.26... logprob:  0.694683, 0.390625 (0.686 sec)
34.27... logprob:  0.630995, 0.320312 (0.685 sec)
35.1... logprob:  0.704734, 0.398438 (0.675 sec)
35.2... logprob:  0.587531, 0.273438 (0.675 sec)
35.3... logprob:  0.660613, 0.359375 (0.672 sec)
35.4... logprob:  0.591091, 0.273438 (0.672 sec)
35.5... logprob:  0.587296, 0.265625 (0.672 sec)
35.6... logprob:  0.610241, 0.296875 (0.671 sec)
35.7... logprob:  0.644323, 0.343750 (0.673 sec)
35.8... logprob:  0.604300, 0.289062 (0.673 sec)
35.9... logprob:  0.638797, 0.335938 (0.675 sec)
35.10... logprob:  0.597570, 0.281250 (0.678 sec)
35.11... logprob:  0.639407, 0.335938 (0.675 sec)
35.12... logprob:  0.720397, 0.437500 (0.677 sec)
35.13... logprob:  0.656150, 0.359375 (0.673 sec)
35.14... logprob:  0.659513, 0.367188 (0.671 sec)
35.15... logprob:  0.676858, 0.398438 (0.672 sec)
35.16... logprob:  0.633070, 0.320312 (0.672 sec)
35.17... logprob:  0.643473, 0.335938 (0.672 sec)
35.18... logprob:  0.644690, 0.335938 (0.675 sec)
35.19... logprob:  0.640968, 0.328125 (0.673 sec)
35.20... logprob:  0.650410, 0.351562 (0.674 sec)
35.21... logprob:  0.645205, 0.343750 (0.674 sec)
35.22... logprob:  0.630564, 0.320312 (0.672 sec)
35.23... logprob:  0.623474, 0.312500 (0.672 sec)
35.24... logprob:  0.571367, 0.242188 (0.672 sec)
35.25... logprob:  0.627651, 0.320312 (0.688 sec)
35.26... logprob:  0.694240, 0.390625 (0.694 sec)
35.27... logprob:  0.631078, 0.320312 (0.679 sec)
36.1... logprob:  0.705783, 0.398438 (0.672 sec)
36.2... logprob:  0.587222, 0.273438 (0.690 sec)
36.3... logprob:  0.662015, 0.359375 (0.689 sec)
36.4... logprob:  0.589965, 0.273438 (0.683 sec)
36.5... logprob:  0.585715, 0.265625 (0.685 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.656216, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.976009e-03 [4.786537e-09] 
Layer 'conv1' biases: 3.224290e-08 [4.850467e-11] 
Layer 'conv2' weights[0]: 7.962957e-03 [4.419654e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.424860e-10] 
Layer 'conv3' weights[0]: 7.961263e-03 [4.276037e-09] 
Layer 'conv3' biases: 5.790555e-07 [7.270394e-10] 
Layer 'conv4' weights[0]: 7.993770e-03 [4.342966e-09] 
Layer 'conv4' biases: 9.999998e-01 [6.025642e-09] 
Layer 'conv5' weights[0]: 7.993146e-03 [4.159217e-08] 
Layer 'conv5' biases: 1.000003e+00 [4.534209e-08] 
Layer 'fc6' weights[0]: 7.589611e-03 [5.432839e-09] 
Layer 'fc6' biases: 9.999999e-01 [3.789353e-09] 
Layer 'fc7' weights[0]: 7.819904e-03 [7.485929e-08] 
Layer 'fc7' biases: 9.998790e-01 [5.725956e-08] 
Layer 'fc8' weights[0]: 4.867406e-04 [3.888679e-06] 
Layer 'fc8' biases: 1.560935e-03 [1.779234e-05] 
Train error last 27 batches: 0.637572
-------------------------------------------------------
Not saving because 0.656216 > 0.627340 (26.25: -1.11%)
======================================================= (1.787 sec)
36.6... logprob:  0.609610, 0.296875 (0.681 sec)
36.7... logprob:  0.644640, 0.343750 (0.681 sec)
36.8... logprob:  0.604037, 0.289062 (0.682 sec)
36.9... logprob:  0.638777, 0.335938 (0.684 sec)
36.10... logprob:  0.597919, 0.281250 (0.682 sec)
36.11... logprob:  0.639081, 0.335938 (0.683 sec)
36.12... logprob:  0.717907, 0.437500 (0.672 sec)
36.13... logprob:  0.655545, 0.359375 (0.675 sec)
36.14... logprob:  0.659171, 0.367188 (0.672 sec)
36.15... logprob:  0.676662, 0.398438 (0.672 sec)
36.16... logprob:  0.632852, 0.320312 (0.671 sec)
36.17... logprob:  0.643015, 0.335938 (0.672 sec)
36.18... logprob:  0.644064, 0.335938 (0.674 sec)
36.19... logprob:  0.640328, 0.328125 (0.672 sec)
36.20... logprob:  0.650220, 0.351562 (0.673 sec)
36.21... logprob:  0.645179, 0.343750 (0.673 sec)
36.22... logprob:  0.630770, 0.320312 (0.672 sec)
36.23... logprob:  0.623859, 0.312500 (0.672 sec)
36.24... logprob:  0.572861, 0.242188 (0.672 sec)
36.25... logprob:  0.627350, 0.320312 (0.672 sec)
36.26... logprob:  0.691574, 0.390625 (0.671 sec)
36.27... logprob:  0.630213, 0.320312 (0.683 sec)
37.1... logprob:  0.703879, 0.398438 (0.686 sec)
37.2... logprob:  0.587299, 0.273438 (0.721 sec)
37.3... logprob:  0.662340, 0.359375 (0.693 sec)
37.4... logprob:  0.589413, 0.273438 (0.695 sec)
37.5... logprob:  0.584578, 0.265625 (0.675 sec)
37.6... logprob:  0.609066, 0.296875 (0.677 sec)
37.7... logprob:  0.645221, 0.343750 (0.675 sec)
37.8... logprob:  0.603368, 0.289062 (0.676 sec)
37.9... logprob:  0.639030, 0.335938 (0.677 sec)
37.10... logprob:  0.597526, 0.281250 (0.677 sec)
37.11... logprob:  0.639135, 0.335938 (0.675 sec)
37.12... logprob:  0.717491, 0.437500 (0.684 sec)
37.13... logprob:  0.655383, 0.359375 (0.675 sec)
37.14... logprob:  0.659037, 0.367188 (0.675 sec)
37.15... logprob:  0.676514, 0.398438 (0.674 sec)
37.16... logprob:  0.632865, 0.320312 (0.697 sec)
37.17... logprob:  0.642971, 0.335938 (0.700 sec)
37.18... logprob:  0.644037, 0.335938 (0.690 sec)
37.19... logprob:  0.640421, 0.328125 (0.677 sec)
37.20... logprob:  0.650374, 0.351562 (0.689 sec)
37.21... logprob:  0.645437, 0.343750 (0.682 sec)
37.22... logprob:  0.631285, 0.320312 (0.678 sec)
37.23... logprob:  0.624427, 0.312500 (0.678 sec)
37.24... logprob:  0.574510, 0.242188 (0.682 sec)
37.25... logprob:  0.627176, 0.320312 (0.685 sec)
37.26... logprob:  0.689426, 0.390625 (0.682 sec)
37.27... logprob:  0.629609, 0.320312 (0.680 sec)
38.1... logprob:  0.702591, 0.398438 (0.681 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.629313, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.975802e-03 [5.123430e-09] 
Layer 'conv1' biases: 3.332970e-08 [7.064481e-11] 
Layer 'conv2' weights[0]: 7.962779e-03 [4.804199e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.150405e-10] 
Layer 'conv3' weights[0]: 7.961055e-03 [4.635466e-09] 
Layer 'conv3' biases: 5.940090e-07 [1.206099e-09] 
Layer 'conv4' weights[0]: 7.993567e-03 [4.852346e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.152168e-08] 
Layer 'conv5' weights[0]: 7.992933e-03 [7.916038e-08] 
Layer 'conv5' biases: 1.000004e+00 [8.637576e-08] 
Layer 'fc6' weights[0]: 7.589410e-03 [8.251932e-09] 
Layer 'fc6' biases: 9.999999e-01 [7.193345e-09] 
Layer 'fc7' weights[0]: 7.818133e-03 [1.219647e-07] 
Layer 'fc7' biases: 9.998772e-01 [1.067365e-07] 
Layer 'fc8' weights[0]: 5.481933e-04 [1.190204e-05] 
Layer 'fc8' biases: 2.172538e-03 [6.425446e-05] 
Train error last 27 batches: 0.637057
-------------------------------------------------------
Not saving because 0.629313 > 0.627340 (26.25: -1.11%)
======================================================= (1.756 sec)
38.2... logprob:  0.587312, 0.273438 (0.693 sec)
38.3... logprob:  0.662852, 0.359375 (0.685 sec)
38.4... logprob:  0.588870, 0.273438 (0.684 sec)
38.5... logprob:  0.583533, 0.265625 (0.685 sec)
38.6... logprob:  0.608654, 0.296875 (0.681 sec)
38.7... logprob:  0.645907, 0.343750 (0.683 sec)
38.8... logprob:  0.602801, 0.289062 (0.677 sec)
38.9... logprob:  0.639342, 0.335938 (0.682 sec)
38.10... logprob:  0.597126, 0.281250 (0.681 sec)
38.11... logprob:  0.639218, 0.335938 (0.684 sec)
38.12... logprob:  0.717311, 0.437500 (0.681 sec)
38.13... logprob:  0.655286, 0.359375 (0.694 sec)
38.14... logprob:  0.658953, 0.367188 (0.704 sec)
38.15... logprob:  0.676421, 0.398438 (0.691 sec)
38.16... logprob:  0.632847, 0.320312 (0.693 sec)
38.17... logprob:  0.642923, 0.335938 (0.697 sec)
38.18... logprob:  0.644028, 0.335938 (0.694 sec)
38.19... logprob:  0.640550, 0.328125 (0.688 sec)
38.20... logprob:  0.650558, 0.351562 (0.693 sec)
38.21... logprob:  0.645740, 0.343750 (0.689 sec)
38.22... logprob:  0.631882, 0.320312 (0.690 sec)
38.23... logprob:  0.625098, 0.312500 (0.684 sec)
38.24... logprob:  0.576371, 0.242188 (0.685 sec)
38.25... logprob:  0.627099, 0.320312 (0.686 sec)
38.26... logprob:  0.687195, 0.390625 (0.684 sec)
38.27... logprob:  0.628996, 0.320312 (0.681 sec)
39.1... logprob:  0.700991, 0.398438 (0.684 sec)
39.2... logprob:  0.587383, 0.273438 (0.685 sec)
39.3... logprob:  0.663154, 0.359375 (0.684 sec)
39.4... logprob:  0.588470, 0.273438 (0.686 sec)
39.5... logprob:  0.582687, 0.265625 (0.688 sec)
39.6... logprob:  0.608376, 0.296875 (0.691 sec)
39.7... logprob:  0.646716, 0.343750 (0.684 sec)
39.8... logprob:  0.602290, 0.289062 (0.682 sec)
39.9... logprob:  0.639790, 0.335938 (0.684 sec)
39.10... logprob:  0.596605, 0.281250 (0.687 sec)
39.11... logprob:  0.639423, 0.335938 (0.686 sec)
39.12... logprob:  0.717837, 0.437500 (0.685 sec)
39.13... logprob:  0.655367, 0.359375 (0.686 sec)
39.14... logprob:  0.658997, 0.367188 (0.686 sec)
39.15... logprob:  0.676489, 0.398438 (0.686 sec)
39.16... logprob:  0.632709, 0.320312 (0.686 sec)
39.17... logprob:  0.642828, 0.335938 (0.686 sec)
39.18... logprob:  0.644026, 0.335938 (0.686 sec)
39.19... logprob:  0.640751, 0.328125 (0.696 sec)
39.20... logprob:  0.650816, 0.351562 (0.684 sec)
39.21... logprob:  0.646159, 0.343750 (0.685 sec)
39.22... logprob:  0.632680, 0.320312 (0.686 sec)
39.23... logprob:  0.626002, 0.312500 (0.682 sec)
39.24... logprob:  0.578724, 0.242188 (0.684 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.632854, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.975602e-03 [5.118605e-09] 
Layer 'conv1' biases: 3.475437e-08 [7.956622e-11] 
Layer 'conv2' weights[0]: 7.962592e-03 [4.973120e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.956040e-10] 
Layer 'conv3' weights[0]: 7.960853e-03 [5.043550e-09] 
Layer 'conv3' biases: 6.151557e-07 [1.520321e-09] 
Layer 'conv4' weights[0]: 7.993372e-03 [5.361349e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.447685e-08] 
Layer 'conv5' weights[0]: 7.992750e-03 [9.322398e-08] 
Layer 'conv5' biases: 1.000006e+00 [1.011487e-07] 
Layer 'fc6' weights[0]: 7.589200e-03 [1.008861e-08] 
Layer 'fc6' biases: 9.999999e-01 [9.200064e-09] 
Layer 'fc7' weights[0]: 7.816374e-03 [1.445258e-07] 
Layer 'fc7' biases: 9.998752e-01 [1.298572e-07] 
Layer 'fc8' weights[0]: 5.145018e-04 [4.224069e-05] 
Layer 'fc8' biases: 2.080452e-03 [2.660004e-04] 
Train error last 27 batches: 0.637132
-------------------------------------------------------
Not saving because 0.632854 > 0.627340 (26.25: -1.11%)
======================================================= (1.741 sec)
39.25... logprob:  0.627157, 0.320312 (0.682 sec)
39.26... logprob:  0.684716, 0.390625 (0.682 sec)
39.27... logprob:  0.628364, 0.320312 (0.678 sec)
40.1... logprob:  0.698952, 0.398438 (0.678 sec)
40.2... logprob:  0.587536, 0.273438 (0.680 sec)
40.3... logprob:  0.663218, 0.359375 (0.677 sec)
40.4... logprob:  0.588182, 0.273438 (0.680 sec)
40.5... logprob:  0.581991, 0.265625 (0.684 sec)
40.6... logprob:  0.608213, 0.296875 (0.677 sec)
40.7... logprob:  0.647686, 0.343750 (0.674 sec)
40.8... logprob:  0.601845, 0.289062 (0.675 sec)
40.9... logprob:  0.640436, 0.335938 (0.674 sec)
40.10... logprob:  0.595987, 0.281250 (0.678 sec)
40.11... logprob:  0.639798, 0.335938 (0.676 sec)
40.12... logprob:  0.719162, 0.437500 (0.679 sec)
40.13... logprob:  0.655657, 0.359375 (0.678 sec)
40.14... logprob:  0.659197, 0.367188 (0.676 sec)
40.15... logprob:  0.676768, 0.398438 (0.678 sec)
40.16... logprob:  0.632398, 0.320312 (0.680 sec)
40.17... logprob:  0.642628, 0.335938 (0.679 sec)
40.18... logprob:  0.643964, 0.335938 (0.676 sec)
40.19... logprob:  0.640951, 0.328125 (0.679 sec)
40.20... logprob:  0.651126, 0.351562 (0.676 sec)
40.21... logprob:  0.646692, 0.343750 (0.674 sec)
40.22... logprob:  0.633706, 0.320312 (0.677 sec)
40.23... logprob:  0.627205, 0.312500 (0.677 sec)
40.24... logprob:  0.581729, 0.242188 (0.675 sec)
40.25... logprob:  0.627446, 0.320312 (0.678 sec)
40.26... logprob:  0.681917, 0.390625 (0.677 sec)
40.27... logprob:  0.627743, 0.320312 (0.678 sec)
41.1... logprob:  0.696255, 0.398438 (0.678 sec)
41.2... logprob:  0.587852, 0.273438 (0.675 sec)
41.3... logprob:  0.662880, 0.359375 (0.676 sec)
41.4... logprob:  0.588037, 0.273438 (0.687 sec)
41.5... logprob:  0.581482, 0.265625 (0.682 sec)
41.6... logprob:  0.608156, 0.296875 (0.683 sec)
41.7... logprob:  0.648786, 0.343750 (0.685 sec)
41.8... logprob:  0.601512, 0.289062 (0.683 sec)
41.9... logprob:  0.641338, 0.335938 (0.681 sec)
41.10... logprob:  0.595330, 0.281250 (0.766 sec)
41.11... logprob:  0.640431, 0.335938 (0.680 sec)
41.12... logprob:  0.721503, 0.437500 (0.683 sec)
41.13... logprob:  0.656257, 0.359375 (0.686 sec)
41.14... logprob:  0.659647, 0.367188 (0.687 sec)
41.15... logprob:  0.677391, 0.398438 (0.692 sec)
41.16... logprob:  0.631807, 0.320312 (0.693 sec)
41.17... logprob:  0.642216, 0.335938 (0.683 sec)
41.18... logprob:  0.643708, 0.335938 (0.682 sec)
41.19... logprob:  0.640996, 0.328125 (0.681 sec)
41.20... logprob:  0.651411, 0.351562 (0.684 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.676306, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.975398e-03 [4.611053e-09] 
Layer 'conv1' biases: 3.651648e-08 [3.287571e-11] 
Layer 'conv2' weights[0]: 7.962401e-03 [4.174426e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.424875e-10] 
Layer 'conv3' weights[0]: 7.960656e-03 [4.090306e-09] 
Layer 'conv3' biases: 6.420131e-07 [3.929136e-10] 
Layer 'conv4' weights[0]: 7.993157e-03 [4.085393e-09] 
Layer 'conv4' biases: 9.999998e-01 [2.347761e-09] 
Layer 'conv5' weights[0]: 7.992569e-03 [1.478319e-08] 
Layer 'conv5' biases: 1.000008e+00 [1.536949e-08] 
Layer 'fc6' weights[0]: 7.589015e-03 [4.055548e-09] 
Layer 'fc6' biases: 9.999999e-01 [1.297189e-09] 
Layer 'fc7' weights[0]: 7.814591e-03 [4.498147e-08] 
Layer 'fc7' biases: 9.998720e-01 [1.841673e-08] 
Layer 'fc8' weights[0]: 4.487356e-04 [7.313605e-06] 
Layer 'fc8' biases: 1.610275e-03 [5.757796e-05] 
Train error last 27 batches: 0.637164
-------------------------------------------------------
Not saving because 0.676306 > 0.627340 (26.25: -1.11%)
======================================================= (1.862 sec)
41.21... logprob:  0.647287, 0.343750 (0.683 sec)
41.22... logprob:  0.634931, 0.320312 (0.681 sec)
41.23... logprob:  0.628749, 0.312500 (0.680 sec)
41.24... logprob:  0.585520, 0.242188 (0.683 sec)
41.25... logprob:  0.628120, 0.320312 (0.684 sec)
41.26... logprob:  0.678805, 0.390625 (0.684 sec)
41.27... logprob:  0.627253, 0.320312 (0.682 sec)
42.1... logprob:  0.692678, 0.398438 (0.684 sec)
42.2... logprob:  0.588500, 0.273438 (0.686 sec)
42.3... logprob:  0.661904, 0.359375 (0.688 sec)
42.4... logprob:  0.588117, 0.273438 (0.680 sec)
42.5... logprob:  0.581246, 0.265625 (0.684 sec)
42.6... logprob:  0.608171, 0.296875 (0.684 sec)
42.7... logprob:  0.649867, 0.343750 (0.681 sec)
42.8... logprob:  0.601333, 0.289062 (0.683 sec)
42.9... logprob:  0.642505, 0.335938 (0.685 sec)
42.10... logprob:  0.594734, 0.281250 (0.688 sec)
42.11... logprob:  0.641433, 0.335938 (0.686 sec)
42.12... logprob:  0.725097, 0.437500 (0.684 sec)
42.13... logprob:  0.657332, 0.359375 (0.682 sec)
42.14... logprob:  0.660511, 0.367188 (0.683 sec)
42.15... logprob:  0.678573, 0.398438 (0.682 sec)
42.16... logprob:  0.630857, 0.320312 (0.683 sec)
42.17... logprob:  0.641490, 0.335938 (0.682 sec)
42.18... logprob:  0.643093, 0.335938 (0.688 sec)
42.19... logprob:  0.640650, 0.328125 (0.685 sec)
42.20... logprob:  0.651516, 0.351562 (0.687 sec)
42.21... logprob:  0.647780, 0.343750 (0.674 sec)
42.22... logprob:  0.636167, 0.320312 (0.683 sec)
42.23... logprob:  0.630516, 0.312500 (0.675 sec)
42.24... logprob:  0.589963, 0.242188 (0.674 sec)
42.25... logprob:  0.629334, 0.320312 (0.683 sec)
42.26... logprob:  0.675627, 0.390625 (0.672 sec)
42.27... logprob:  0.627164, 0.320312 (0.672 sec)
43.1... logprob:  0.688238, 0.398438 (0.671 sec)
43.2... logprob:  0.589797, 0.273438 (0.673 sec)
43.3... logprob:  0.660110, 0.359375 (0.671 sec)
43.4... logprob:  0.588598, 0.273438 (0.671 sec)
43.5... logprob:  0.581450, 0.265625 (0.676 sec)
43.6... logprob:  0.608181, 0.296875 (0.688 sec)
43.7... logprob:  0.650550, 0.343750 (0.691 sec)
43.8... logprob:  0.601299, 0.289062 (0.689 sec)
43.9... logprob:  0.643750, 0.335938 (0.698 sec)
43.10... logprob:  0.594328, 0.281250 (0.694 sec)
43.11... logprob:  0.642821, 0.335938 (0.689 sec)
43.12... logprob:  0.729910, 0.437500 (0.687 sec)
43.13... logprob:  0.659036, 0.359375 (0.692 sec)
43.14... logprob:  0.661993, 0.367188 (0.692 sec)
43.15... logprob:  0.680579, 0.398438 (0.693 sec)
43.16... logprob:  0.629599, 0.320312 (0.687 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.636196, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.975202e-03 [5.958672e-09] 
Layer 'conv1' biases: 3.805907e-08 [1.589177e-10] 
Layer 'conv2' weights[0]: 7.962194e-03 [6.789577e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.373528e-10] 
Layer 'conv3' weights[0]: 7.960449e-03 [6.512912e-09] 
Layer 'conv3' biases: 6.665806e-07 [2.784516e-09] 
Layer 'conv4' weights[0]: 7.992963e-03 [7.068340e-09] 
Layer 'conv4' biases: 9.999998e-01 [2.722465e-08] 
Layer 'conv5' weights[0]: 7.992422e-03 [1.863384e-07] 
Layer 'conv5' biases: 1.000010e+00 [2.034428e-07] 
Layer 'fc6' weights[0]: 7.588810e-03 [1.689954e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.641398e-08] 
Layer 'fc7' weights[0]: 7.812818e-03 [2.480268e-07] 
Layer 'fc7' biases: 9.998701e-01 [2.348953e-07] 
Layer 'fc8' weights[0]: 5.001261e-04 [3.039934e-05] 
Layer 'fc8' biases: 2.448288e-03 [2.237098e-04] 
Train error last 27 batches: 0.637909
-------------------------------------------------------
Not saving because 0.636196 > 0.627340 (26.25: -1.11%)
======================================================= (1.712 sec)
43.17... logprob:  0.640451, 0.335938 (0.680 sec)
43.18... logprob:  0.642015, 0.335938 (0.685 sec)
43.19... logprob:  0.639660, 0.328125 (0.680 sec)
43.20... logprob:  0.651226, 0.351562 (0.679 sec)
43.21... logprob:  0.647863, 0.343750 (0.678 sec)
43.22... logprob:  0.636950, 0.320312 (0.683 sec)
43.23... logprob:  0.632051, 0.312500 (0.680 sec)
43.24... logprob:  0.594271, 0.242188 (0.679 sec)
43.25... logprob:  0.631019, 0.320312 (0.680 sec)
43.26... logprob:  0.672915, 0.390625 (0.679 sec)
43.27... logprob:  0.627803, 0.320312 (0.679 sec)
44.1... logprob:  0.683521, 0.398438 (0.683 sec)
44.2... logprob:  0.592122, 0.273438 (0.687 sec)
44.3... logprob:  0.657693, 0.359375 (0.685 sec)
44.4... logprob:  0.589810, 0.273438 (0.675 sec)
44.5... logprob:  0.582390, 0.265625 (0.680 sec)
44.6... logprob:  0.608152, 0.296875 (0.677 sec)
44.7... logprob:  0.650267, 0.343750 (0.683 sec)
44.8... logprob:  0.601306, 0.289062 (0.675 sec)
44.9... logprob:  0.644530, 0.335938 (0.674 sec)
44.10... logprob:  0.594164, 0.281250 (0.688 sec)
44.11... logprob:  0.644278, 0.335938 (0.687 sec)
44.12... logprob:  0.735081, 0.437500 (0.698 sec)
44.13... logprob:  0.661262, 0.359375 (0.688 sec)
44.14... logprob:  0.664130, 0.367188 (0.679 sec)
44.15... logprob:  0.683496, 0.398438 (0.679 sec)
44.16... logprob:  0.628336, 0.320312 (0.685 sec)
44.17... logprob:  0.639346, 0.335938 (0.681 sec)
44.18... logprob:  0.640628, 0.335938 (0.684 sec)
44.19... logprob:  0.638025, 0.328125 (0.682 sec)
44.20... logprob:  0.650464, 0.351562 (0.680 sec)
44.21... logprob:  0.647269, 0.343750 (0.684 sec)
44.22... logprob:  0.636711, 0.320312 (0.690 sec)
44.23... logprob:  0.632596, 0.312500 (0.690 sec)
44.24... logprob:  0.596919, 0.242188 (0.687 sec)
44.25... logprob:  0.632568, 0.320312 (0.682 sec)
44.26... logprob:  0.671195, 0.390625 (0.706 sec)
44.27... logprob:  0.629079, 0.320312 (0.695 sec)
45.1... logprob:  0.679660, 0.398438 (0.679 sec)
45.2... logprob:  0.595376, 0.273438 (0.687 sec)
45.3... logprob:  0.655448, 0.359375 (0.684 sec)
45.4... logprob:  0.591987, 0.273438 (0.682 sec)
45.5... logprob:  0.584332, 0.265625 (0.688 sec)
45.6... logprob:  0.608293, 0.296875 (0.681 sec)
45.7... logprob:  0.648830, 0.343750 (0.682 sec)
45.8... logprob:  0.601308, 0.289062 (0.684 sec)
45.9... logprob:  0.644206, 0.335938 (0.683 sec)
45.10... logprob:  0.594147, 0.281250 (0.680 sec)
45.11... logprob:  0.645037, 0.335938 (0.681 sec)
45.12... logprob:  0.738623, 0.437500 (0.684 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.628925, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.974992e-03 [6.515702e-09] 
Layer 'conv1' biases: 3.895594e-08 [1.583100e-10] 
Layer 'conv2' weights[0]: 7.961996e-03 [6.811121e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.393868e-10] 
Layer 'conv3' weights[0]: 7.960251e-03 [6.526151e-09] 
Layer 'conv3' biases: 6.810934e-07 [2.858181e-09] 
Layer 'conv4' weights[0]: 7.992758e-03 [7.094370e-09] 
Layer 'conv4' biases: 9.999998e-01 [2.788712e-08] 
Layer 'conv5' weights[0]: 7.992236e-03 [1.921703e-07] 
Layer 'conv5' biases: 1.000010e+00 [2.099453e-07] 
Layer 'fc6' weights[0]: 7.588619e-03 [1.684600e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.636386e-08] 
Layer 'fc7' weights[0]: 7.810907e-03 [2.470047e-07] 
Layer 'fc7' biases: 9.998689e-01 [2.336633e-07] 
Layer 'fc8' weights[0]: 6.898926e-04 [2.015141e-05] 
Layer 'fc8' biases: 5.080280e-03 [1.591066e-04] 
Train error last 27 batches: 0.638492
-------------------------------------------------------
Not saving because 0.628925 > 0.627340 (26.25: -1.11%)
======================================================= (1.713 sec)
45.13... logprob:  0.663274, 0.359375 (0.680 sec)
45.14... logprob:  0.666384, 0.367188 (0.682 sec)
45.15... logprob:  0.686760, 0.398438 (0.684 sec)
45.16... logprob:  0.627487, 0.320312 (0.682 sec)
45.17... logprob:  0.638589, 0.335938 (0.684 sec)
45.18... logprob:  0.639399, 0.335938 (0.684 sec)
45.19... logprob:  0.636219, 0.328125 (0.685 sec)
45.20... logprob:  0.649526, 0.351562 (0.683 sec)
45.21... logprob:  0.646167, 0.343750 (0.685 sec)
45.22... logprob:  0.635383, 0.320312 (0.680 sec)
45.23... logprob:  0.631782, 0.312500 (0.679 sec)
45.24... logprob:  0.596762, 0.242188 (0.685 sec)
45.25... logprob:  0.633155, 0.320312 (0.686 sec)
45.26... logprob:  0.670509, 0.390625 (0.681 sec)
45.27... logprob:  0.630187, 0.320312 (0.682 sec)
46.1... logprob:  0.677470, 0.398438 (0.679 sec)
46.2... logprob:  0.598372, 0.273438 (0.682 sec)
46.3... logprob:  0.654128, 0.359375 (0.684 sec)
46.4... logprob:  0.594547, 0.273438 (0.682 sec)
46.5... logprob:  0.586848, 0.265625 (0.689 sec)
46.6... logprob:  0.608862, 0.296875 (0.687 sec)
46.7... logprob:  0.647041, 0.343750 (0.682 sec)
46.8... logprob:  0.601497, 0.289062 (0.680 sec)
46.9... logprob:  0.642956, 0.335938 (0.685 sec)
46.10... logprob:  0.594232, 0.281250 (0.698 sec)
46.11... logprob:  0.644639, 0.335938 (0.685 sec)
46.12... logprob:  0.738938, 0.437500 (0.686 sec)
46.13... logprob:  0.664105, 0.359375 (0.684 sec)
46.14... logprob:  0.667765, 0.367188 (0.680 sec)
46.15... logprob:  0.689153, 0.398438 (0.683 sec)
46.16... logprob:  0.627159, 0.320312 (0.681 sec)
46.17... logprob:  0.638333, 0.335938 (0.683 sec)
46.18... logprob:  0.638698, 0.335938 (0.682 sec)
46.19... logprob:  0.634869, 0.328125 (0.702 sec)
46.20... logprob:  0.648862, 0.351562 (0.679 sec)
46.21... logprob:  0.645124, 0.343750 (0.681 sec)
46.22... logprob:  0.633703, 0.320312 (0.683 sec)
46.23... logprob:  0.630230, 0.312500 (0.686 sec)
46.24... logprob:  0.594533, 0.242188 (0.690 sec)
46.25... logprob:  0.632744, 0.320312 (0.711 sec)
46.26... logprob:  0.670495, 0.390625 (0.686 sec)
46.27... logprob:  0.630506, 0.320312 (0.679 sec)
47.1... logprob:  0.676748, 0.398438 (0.678 sec)
47.2... logprob:  0.599893, 0.273438 (0.682 sec)
47.3... logprob:  0.653641, 0.359375 (0.680 sec)
47.4... logprob:  0.596321, 0.273438 (0.680 sec)
47.5... logprob:  0.588796, 0.265625 (0.678 sec)
47.6... logprob:  0.609570, 0.296875 (0.684 sec)
47.7... logprob:  0.645831, 0.343750 (0.683 sec)
47.8... logprob:  0.601904, 0.289062 (0.683 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.661821, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.974775e-03 [6.355040e-09] 
Layer 'conv1' biases: 4.061024e-08 [9.398478e-11] 
Layer 'conv2' weights[0]: 7.961806e-03 [5.615079e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.467789e-10] 
Layer 'conv3' weights[0]: 7.960046e-03 [5.779975e-09] 
Layer 'conv3' biases: 7.021642e-07 [2.035882e-09] 
Layer 'conv4' weights[0]: 7.992572e-03 [6.302271e-09] 
Layer 'conv4' biases: 1.000000e+00 [2.045137e-08] 
Layer 'conv5' weights[0]: 7.992036e-03 [1.403767e-07] 
Layer 'conv5' biases: 1.000012e+00 [1.533359e-07] 
Layer 'fc6' weights[0]: 7.588429e-03 [1.238945e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.177179e-08] 
Layer 'fc7' weights[0]: 7.809007e-03 [1.777765e-07] 
Layer 'fc7' biases: 9.998672e-01 [1.632498e-07] 
Layer 'fc8' weights[0]: 7.288035e-04 [1.772335e-05] 
Layer 'fc8' biases: 6.683257e-03 [1.885846e-04] 
Train error last 27 batches: 0.638509
-------------------------------------------------------
Not saving because 0.661821 > 0.627340 (26.25: -1.11%)
======================================================= (1.733 sec)
47.9... logprob:  0.641734, 0.335938 (0.679 sec)
47.10... logprob:  0.594461, 0.281250 (0.684 sec)
47.11... logprob:  0.643682, 0.335938 (0.680 sec)
47.12... logprob:  0.737004, 0.437500 (0.683 sec)
47.13... logprob:  0.663790, 0.359375 (0.683 sec)
47.14... logprob:  0.667982, 0.367188 (0.681 sec)
47.15... logprob:  0.690059, 0.398438 (0.682 sec)
47.16... logprob:  0.627092, 0.320312 (0.674 sec)
47.17... logprob:  0.638328, 0.335938 (0.676 sec)
47.18... logprob:  0.638438, 0.335938 (0.687 sec)
47.19... logprob:  0.634157, 0.328125 (0.684 sec)
47.20... logprob:  0.648575, 0.351562 (0.683 sec)
47.21... logprob:  0.644492, 0.343750 (0.682 sec)
47.22... logprob:  0.632439, 0.320312 (0.682 sec)
47.23... logprob:  0.628883, 0.312500 (0.681 sec)
47.24... logprob:  0.592092, 0.242188 (0.686 sec)
47.25... logprob:  0.632049, 0.320312 (0.685 sec)
47.26... logprob:  0.670755, 0.390625 (0.683 sec)
47.27... logprob:  0.630320, 0.320312 (0.681 sec)
48.1... logprob:  0.676764, 0.398438 (0.682 sec)
48.2... logprob:  0.600162, 0.273438 (0.682 sec)
48.3... logprob:  0.653527, 0.359375 (0.683 sec)
48.4... logprob:  0.597031, 0.273438 (0.679 sec)
48.5... logprob:  0.589725, 0.265625 (0.683 sec)
48.6... logprob:  0.610016, 0.296875 (0.681 sec)
48.7... logprob:  0.645268, 0.343750 (0.681 sec)
48.8... logprob:  0.602264, 0.289062 (0.680 sec)
48.9... logprob:  0.641014, 0.335938 (0.675 sec)
48.10... logprob:  0.594718, 0.281250 (0.677 sec)
48.11... logprob:  0.642913, 0.335938 (0.675 sec)
48.12... logprob:  0.734940, 0.437500 (0.676 sec)
48.13... logprob:  0.663168, 0.359375 (0.676 sec)
48.14... logprob:  0.667677, 0.367188 (0.671 sec)
48.15... logprob:  0.690076, 0.398438 (0.674 sec)
48.16... logprob:  0.627084, 0.320312 (0.671 sec)
48.17... logprob:  0.638353, 0.335938 (0.676 sec)
48.18... logprob:  0.638363, 0.335938 (0.681 sec)
48.19... logprob:  0.633855, 0.328125 (0.680 sec)
48.20... logprob:  0.648486, 0.351562 (0.674 sec)
48.21... logprob:  0.644198, 0.343750 (0.679 sec)
48.22... logprob:  0.631737, 0.320312 (0.680 sec)
48.23... logprob:  0.628075, 0.312500 (0.674 sec)
48.24... logprob:  0.590457, 0.242188 (0.673 sec)
48.25... logprob:  0.631549, 0.320312 (0.676 sec)
48.26... logprob:  0.671009, 0.390625 (0.675 sec)
48.27... logprob:  0.630087, 0.320312 (0.675 sec)
49.1... logprob:  0.676943, 0.398438 (0.672 sec)
49.2... logprob:  0.600029, 0.273438 (0.678 sec)
49.3... logprob:  0.653519, 0.359375 (0.672 sec)
49.4... logprob:  0.597214, 0.273438 (0.678 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627663, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.974585e-03 [6.531768e-09] 
Layer 'conv1' biases: 4.264246e-08 [1.035250e-10] 
Layer 'conv2' weights[0]: 7.961607e-03 [5.815449e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.747982e-10] 
Layer 'conv3' weights[0]: 7.959856e-03 [5.996050e-09] 
Layer 'conv3' biases: 7.267204e-07 [2.149884e-09] 
Layer 'conv4' weights[0]: 7.992387e-03 [6.485152e-09] 
Layer 'conv4' biases: 1.000000e+00 [2.114407e-08] 
Layer 'conv5' weights[0]: 7.991874e-03 [1.454757e-07] 
Layer 'conv5' biases: 1.000013e+00 [1.590259e-07] 
Layer 'fc6' weights[0]: 7.588226e-03 [1.262611e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.201019e-08] 
Layer 'fc7' weights[0]: 7.806977e-03 [1.803423e-07] 
Layer 'fc7' biases: 9.998651e-01 [1.656971e-07] 
Layer 'fc8' weights[0]: 6.822869e-04 [1.512144e-05] 
Layer 'fc8' biases: 7.344577e-03 [1.833367e-04] 
Train error last 27 batches: 0.637879
-------------------------------------------------------
Not saving because 0.627663 > 0.627340 (26.25: -1.11%)
======================================================= (1.719 sec)
49.5... logprob:  0.590057, 0.265625 (0.676 sec)
49.6... logprob:  0.610220, 0.296875 (0.677 sec)
49.7... logprob:  0.645036, 0.343750 (0.676 sec)
49.8... logprob:  0.602475, 0.289062 (0.674 sec)
49.9... logprob:  0.640664, 0.335938 (0.673 sec)
49.10... logprob:  0.594896, 0.281250 (0.676 sec)
49.11... logprob:  0.642472, 0.335938 (0.673 sec)
49.12... logprob:  0.733596, 0.437500 (0.674 sec)
49.13... logprob:  0.662714, 0.359375 (0.678 sec)
49.14... logprob:  0.667379, 0.367188 (0.677 sec)
49.15... logprob:  0.689909, 0.398438 (0.674 sec)
49.16... logprob:  0.627082, 0.320312 (0.678 sec)
49.17... logprob:  0.638366, 0.335938 (0.675 sec)
49.18... logprob:  0.638338, 0.335938 (0.676 sec)
49.19... logprob:  0.633725, 0.328125 (0.677 sec)
49.20... logprob:  0.648459, 0.351562 (0.675 sec)
49.21... logprob:  0.644064, 0.343750 (0.676 sec)
49.22... logprob:  0.631381, 0.320312 (0.680 sec)
49.23... logprob:  0.627649, 0.312500 (0.681 sec)
49.24... logprob:  0.589547, 0.242188 (0.682 sec)
49.25... logprob:  0.631271, 0.320312 (0.676 sec)
49.26... logprob:  0.671171, 0.390625 (0.679 sec)
49.27... logprob:  0.629944, 0.320312 (0.680 sec)
50.1... logprob:  0.677071, 0.398438 (0.684 sec)
50.2... logprob:  0.599907, 0.273438 (0.676 sec)
50.3... logprob:  0.653524, 0.359375 (0.675 sec)
50.4... logprob:  0.597273, 0.273438 (0.677 sec)
50.5... logprob:  0.590203, 0.265625 (0.675 sec)
50.6... logprob:  0.610320, 0.296875 (0.675 sec)
50.7... logprob:  0.644924, 0.343750 (0.679 sec)
50.8... logprob:  0.602595, 0.289062 (0.672 sec)
50.9... logprob:  0.640484, 0.335938 (0.678 sec)
50.10... logprob:  0.595006, 0.281250 (0.676 sec)
50.11... logprob:  0.642229, 0.335938 (0.680 sec)
50.12... logprob:  0.732814, 0.437500 (0.679 sec)
50.13... logprob:  0.662445, 0.359375 (0.679 sec)
50.14... logprob:  0.667194, 0.367188 (0.677 sec)
50.15... logprob:  0.689794, 0.398438 (0.678 sec)
50.16... logprob:  0.627081, 0.320312 (0.679 sec)
50.17... logprob:  0.638373, 0.335938 (0.680 sec)
50.18... logprob:  0.638326, 0.335938 (0.685 sec)
50.19... logprob:  0.633655, 0.328125 (0.689 sec)
50.20... logprob:  0.648449, 0.351562 (0.689 sec)
50.21... logprob:  0.643993, 0.343750 (0.688 sec)
50.22... logprob:  0.631178, 0.320312 (0.689 sec)
50.23... logprob:  0.627405, 0.312500 (0.690 sec)
50.24... logprob:  0.589017, 0.242188 (0.685 sec)
50.25... logprob:  0.631113, 0.320312 (0.686 sec)
50.26... logprob:  0.671266, 0.390625 (0.688 sec)
50.27... logprob:  0.629864, 0.320312 (0.689 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.634043, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.974393e-03 [6.314807e-09] 
Layer 'conv1' biases: 4.450534e-08 [7.607955e-11] 
Layer 'conv2' weights[0]: 7.961411e-03 [5.116282e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.672063e-10] 
Layer 'conv3' weights[0]: 7.959645e-03 [5.282344e-09] 
Layer 'conv3' biases: 7.444640e-07 [1.593833e-09] 
Layer 'conv4' weights[0]: 7.992191e-03 [5.661495e-09] 
Layer 'conv4' biases: 1.000000e+00 [1.528154e-08] 
Layer 'conv5' weights[0]: 7.991683e-03 [1.049125e-07] 
Layer 'conv5' biases: 1.000014e+00 [1.146673e-07] 
Layer 'fc6' weights[0]: 7.588025e-03 [9.607836e-09] 
Layer 'fc6' biases: 9.999999e-01 [8.551225e-09] 
Layer 'fc7' weights[0]: 7.804975e-03 [1.327730e-07] 
Layer 'fc7' biases: 9.998640e-01 [1.167276e-07] 
Layer 'fc8' weights[0]: 6.682535e-04 [9.982078e-06] 
Layer 'fc8' biases: 8.307336e-03 [1.406707e-04] 
Train error last 27 batches: 0.637611
-------------------------------------------------------
Not saving because 0.634043 > 0.627340 (26.25: -1.11%)
======================================================= (1.733 sec)
51.1... logprob:  0.677142, 0.398438 (0.686 sec)
51.2... logprob:  0.599843, 0.273438 (0.684 sec)
51.3... logprob:  0.653525, 0.359375 (0.680 sec)
51.4... logprob:  0.597315, 0.273438 (0.678 sec)
51.5... logprob:  0.590298, 0.265625 (0.676 sec)
51.6... logprob:  0.610386, 0.296875 (0.677 sec)
51.7... logprob:  0.644855, 0.343750 (0.680 sec)
51.8... logprob:  0.602674, 0.289062 (0.679 sec)
51.9... logprob:  0.640373, 0.335938 (0.679 sec)
51.10... logprob:  0.595080, 0.281250 (0.682 sec)
51.11... logprob:  0.642079, 0.335938 (0.680 sec)
51.12... logprob:  0.732321, 0.437500 (0.683 sec)
51.13... logprob:  0.662278, 0.359375 (0.678 sec)
51.14... logprob:  0.667081, 0.367188 (0.678 sec)
51.15... logprob:  0.689727, 0.398438 (0.677 sec)
51.16... logprob:  0.627081, 0.320312 (0.677 sec)
51.17... logprob:  0.638379, 0.335938 (0.676 sec)
51.18... logprob:  0.638319, 0.335938 (0.678 sec)
51.19... logprob:  0.633607, 0.328125 (0.678 sec)
51.20... logprob:  0.648445, 0.351562 (0.678 sec)
51.21... logprob:  0.643947, 0.343750 (0.682 sec)
51.22... logprob:  0.631045, 0.320312 (0.679 sec)
51.23... logprob:  0.627244, 0.312500 (0.679 sec)
51.24... logprob:  0.588665, 0.242188 (0.673 sec)
51.25... logprob:  0.631010, 0.320312 (0.673 sec)
51.26... logprob:  0.671329, 0.390625 (0.673 sec)
51.27... logprob:  0.629813, 0.320312 (0.674 sec)
52.1... logprob:  0.677186, 0.398438 (0.673 sec)
52.2... logprob:  0.599807, 0.273438 (0.674 sec)
52.3... logprob:  0.653524, 0.359375 (0.673 sec)
52.4... logprob:  0.597351, 0.273438 (0.678 sec)
52.5... logprob:  0.590371, 0.265625 (0.680 sec)
52.6... logprob:  0.610436, 0.296875 (0.676 sec)
52.7... logprob:  0.644805, 0.343750 (0.673 sec)
52.8... logprob:  0.602732, 0.289062 (0.677 sec)
52.9... logprob:  0.640295, 0.335938 (0.678 sec)
52.10... logprob:  0.595134, 0.281250 (0.677 sec)
52.11... logprob:  0.641973, 0.335938 (0.679 sec)
52.12... logprob:  0.731970, 0.437500 (0.678 sec)
52.13... logprob:  0.662160, 0.359375 (0.679 sec)
52.14... logprob:  0.667002, 0.367188 (0.685 sec)
52.15... logprob:  0.689683, 0.398438 (0.689 sec)
52.16... logprob:  0.627080, 0.320312 (0.687 sec)
52.17... logprob:  0.638384, 0.335938 (0.677 sec)
52.18... logprob:  0.638314, 0.335938 (0.679 sec)
52.19... logprob:  0.633573, 0.328125 (0.683 sec)
52.20... logprob:  0.648442, 0.351562 (0.684 sec)
52.21... logprob:  0.643914, 0.343750 (0.678 sec)
52.22... logprob:  0.630947, 0.320312 (0.679 sec)
52.23... logprob:  0.627126, 0.312500 (0.679 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.679013, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.974197e-03 [5.533852e-09] 
Layer 'conv1' biases: 4.628969e-08 [6.265232e-11] 
Layer 'conv2' weights[0]: 7.961207e-03 [4.554907e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.186464e-10] 
Layer 'conv3' weights[0]: 7.959439e-03 [4.269758e-09] 
Layer 'conv3' biases: 7.607491e-07 [5.461011e-10] 
Layer 'conv4' weights[0]: 7.991989e-03 [4.240392e-09] 
Layer 'conv4' biases: 1.000000e+00 [2.812622e-09] 
Layer 'conv5' weights[0]: 7.991510e-03 [2.001057e-08] 
Layer 'conv5' biases: 1.000015e+00 [2.170734e-08] 
Layer 'fc6' weights[0]: 7.587831e-03 [4.253781e-09] 
Layer 'fc6' biases: 9.999999e-01 [1.775744e-09] 
Layer 'fc7' weights[0]: 7.803040e-03 [5.025196e-08] 
Layer 'fc7' biases: 9.998634e-01 [2.707022e-08] 
Layer 'fc8' weights[0]: 6.525556e-04 [1.219375e-06] 
Layer 'fc8' biases: 9.224179e-03 [1.114005e-05] 
Train error last 27 batches: 0.637520
-------------------------------------------------------
Not saving because 0.679013 > 0.627340 (26.25: -1.11%)
======================================================= (1.829 sec)
52.24... logprob:  0.588407, 0.242188 (0.681 sec)
52.25... logprob:  0.630935, 0.320312 (0.680 sec)
52.26... logprob:  0.671376, 0.390625 (0.681 sec)
52.27... logprob:  0.629777, 0.320312 (0.680 sec)
53.1... logprob:  0.677217, 0.398438 (0.681 sec)
53.2... logprob:  0.599781, 0.273438 (0.679 sec)
53.3... logprob:  0.653523, 0.359375 (0.678 sec)
53.4... logprob:  0.597377, 0.273438 (0.682 sec)
53.5... logprob:  0.590425, 0.265625 (0.681 sec)
53.6... logprob:  0.610472, 0.296875 (0.691 sec)
53.7... logprob:  0.644769, 0.343750 (0.682 sec)
53.8... logprob:  0.602777, 0.289062 (0.682 sec)
53.9... logprob:  0.640238, 0.335938 (0.682 sec)
53.10... logprob:  0.595175, 0.281250 (0.676 sec)
53.11... logprob:  0.641894, 0.335938 (0.676 sec)
53.12... logprob:  0.731707, 0.437500 (0.676 sec)
53.13... logprob:  0.662072, 0.359375 (0.677 sec)
53.14... logprob:  0.666942, 0.367188 (0.677 sec)
53.15... logprob:  0.689651, 0.398438 (0.684 sec)
53.16... logprob:  0.627079, 0.320312 (0.686 sec)
53.17... logprob:  0.638388, 0.335938 (0.684 sec)
53.18... logprob:  0.638310, 0.335938 (0.679 sec)
53.19... logprob:  0.633546, 0.328125 (0.681 sec)
53.20... logprob:  0.648441, 0.351562 (0.678 sec)
53.21... logprob:  0.643889, 0.343750 (0.677 sec)
53.22... logprob:  0.630873, 0.320312 (0.685 sec)
53.23... logprob:  0.627036, 0.312500 (0.686 sec)
53.24... logprob:  0.588209, 0.242188 (0.685 sec)
53.25... logprob:  0.630877, 0.320312 (0.691 sec)
53.26... logprob:  0.671411, 0.390625 (0.680 sec)
53.27... logprob:  0.629749, 0.320312 (0.687 sec)
54.1... logprob:  0.677241, 0.398438 (0.686 sec)
54.2... logprob:  0.599760, 0.273438 (0.683 sec)
54.3... logprob:  0.653522, 0.359375 (0.679 sec)
54.4... logprob:  0.597398, 0.273438 (0.681 sec)
54.5... logprob:  0.590467, 0.265625 (0.682 sec)
54.6... logprob:  0.610501, 0.296875 (0.689 sec)
54.7... logprob:  0.644741, 0.343750 (0.684 sec)
54.8... logprob:  0.602812, 0.289062 (0.730 sec)
54.9... logprob:  0.640194, 0.335938 (0.684 sec)
54.10... logprob:  0.595209, 0.281250 (0.692 sec)
54.11... logprob:  0.641832, 0.335938 (0.681 sec)
54.12... logprob:  0.731499, 0.437500 (0.681 sec)
54.13... logprob:  0.662002, 0.359375 (0.684 sec)
54.14... logprob:  0.666896, 0.367188 (0.693 sec)
54.15... logprob:  0.689626, 0.398438 (0.700 sec)
54.16... logprob:  0.627079, 0.320312 (0.688 sec)
54.17... logprob:  0.638391, 0.335938 (0.695 sec)
54.18... logprob:  0.638307, 0.335938 (0.686 sec)
54.19... logprob:  0.633526, 0.328125 (0.685 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.634123, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.973991e-03 [6.393941e-09] 
Layer 'conv1' biases: 4.775283e-08 [1.582908e-10] 
Layer 'conv2' weights[0]: 7.961017e-03 [6.745582e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.794546e-10] 
Layer 'conv3' weights[0]: 7.959248e-03 [6.282319e-09] 
Layer 'conv3' biases: 7.693371e-07 [2.621795e-09] 
Layer 'conv4' weights[0]: 7.991790e-03 [6.802052e-09] 
Layer 'conv4' biases: 1.000000e+00 [2.542004e-08] 
Layer 'conv5' weights[0]: 7.991292e-03 [1.761935e-07] 
Layer 'conv5' biases: 1.000015e+00 [1.927923e-07] 
Layer 'fc6' weights[0]: 7.587628e-03 [1.518050e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.469695e-08] 
Layer 'fc7' weights[0]: 7.801031e-03 [2.209997e-07] 
Layer 'fc7' biases: 9.998635e-01 [2.073340e-07] 
Layer 'fc8' weights[0]: 6.900523e-04 [1.367969e-05] 
Layer 'fc8' biases: 1.092856e-02 [1.384829e-04] 
Train error last 27 batches: 0.637462
-------------------------------------------------------
Not saving because 0.634123 > 0.627340 (26.25: -1.11%)
======================================================= (1.710 sec)
54.20... logprob:  0.648440, 0.351562 (0.687 sec)
54.21... logprob:  0.643870, 0.343750 (0.674 sec)
54.22... logprob:  0.630814, 0.320312 (0.677 sec)
54.23... logprob:  0.626965, 0.312500 (0.674 sec)
54.24... logprob:  0.588052, 0.242188 (0.672 sec)
54.25... logprob:  0.630832, 0.320312 (0.672 sec)
54.26... logprob:  0.671440, 0.390625 (0.682 sec)
54.27... logprob:  0.629727, 0.320312 (0.682 sec)
55.1... logprob:  0.677261, 0.398438 (0.684 sec)
55.2... logprob:  0.599743, 0.273438 (0.677 sec)
55.3... logprob:  0.653522, 0.359375 (0.678 sec)
55.4... logprob:  0.597414, 0.273438 (0.674 sec)
55.5... logprob:  0.590500, 0.265625 (0.672 sec)
55.6... logprob:  0.610524, 0.296875 (0.671 sec)
55.7... logprob:  0.644719, 0.343750 (0.675 sec)
55.8... logprob:  0.602840, 0.289062 (0.676 sec)
55.9... logprob:  0.640158, 0.335938 (0.676 sec)
55.10... logprob:  0.595236, 0.281250 (0.684 sec)
55.11... logprob:  0.641782, 0.335938 (0.681 sec)
55.12... logprob:  0.731329, 0.437500 (0.687 sec)
55.13... logprob:  0.661946, 0.359375 (0.683 sec)
55.14... logprob:  0.666857, 0.367188 (0.677 sec)
55.15... logprob:  0.689605, 0.398438 (0.674 sec)
55.16... logprob:  0.627078, 0.320312 (0.679 sec)
55.17... logprob:  0.638394, 0.335938 (0.681 sec)
55.18... logprob:  0.638304, 0.335938 (0.682 sec)
55.19... logprob:  0.633508, 0.328125 (0.679 sec)
55.20... logprob:  0.648439, 0.351562 (0.690 sec)
55.21... logprob:  0.643854, 0.343750 (0.696 sec)
55.22... logprob:  0.630766, 0.320312 (0.711 sec)
55.23... logprob:  0.626906, 0.312500 (0.721 sec)
55.24... logprob:  0.587921, 0.242188 (0.711 sec)
55.25... logprob:  0.630794, 0.320312 (0.708 sec)
55.26... logprob:  0.671464, 0.390625 (0.689 sec)
55.27... logprob:  0.629708, 0.320312 (0.706 sec)
56.1... logprob:  0.677277, 0.398438 (0.705 sec)
56.2... logprob:  0.599729, 0.273438 (0.701 sec)
56.3... logprob:  0.653521, 0.359375 (0.687 sec)
56.4... logprob:  0.597427, 0.273438 (0.696 sec)
56.5... logprob:  0.590528, 0.265625 (0.695 sec)
56.6... logprob:  0.610543, 0.296875 (0.682 sec)
56.7... logprob:  0.644701, 0.343750 (0.687 sec)
56.8... logprob:  0.602864, 0.289062 (0.681 sec)
56.9... logprob:  0.640128, 0.335938 (0.674 sec)
56.10... logprob:  0.595259, 0.281250 (0.676 sec)
56.11... logprob:  0.641739, 0.335938 (0.673 sec)
56.12... logprob:  0.731184, 0.437500 (0.673 sec)
56.13... logprob:  0.661897, 0.359375 (0.676 sec)
56.14... logprob:  0.666825, 0.367188 (0.680 sec)
56.15... logprob:  0.689588, 0.398438 (0.677 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627176, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.973784e-03 [7.776693e-09] 
Layer 'conv1' biases: 4.902127e-08 [2.405311e-10] 
Layer 'conv2' weights[0]: 7.960812e-03 [9.102485e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.415299e-09] 
Layer 'conv3' weights[0]: 7.959042e-03 [8.386683e-09] 
Layer 'conv3' biases: 7.733614e-07 [4.198469e-09] 
Layer 'conv4' weights[0]: 7.991587e-03 [9.389704e-09] 
Layer 'conv4' biases: 1.000000e+00 [4.230960e-08] 
Layer 'conv5' weights[0]: 7.991079e-03 [2.928562e-07] 
Layer 'conv5' biases: 1.000013e+00 [3.205444e-07] 
Layer 'fc6' weights[0]: 7.587432e-03 [2.446386e-08] 
Layer 'fc6' biases: 9.999999e-01 [2.444845e-08] 
Layer 'fc7' weights[0]: 7.799042e-03 [3.583531e-07] 
Layer 'fc7' biases: 9.998643e-01 [3.443608e-07] 
Layer 'fc8' weights[0]: 7.591122e-04 [2.234283e-05] 
Layer 'fc8' biases: 1.307163e-02 [2.344150e-04] 
Train error last 27 batches: 0.637420
-------------------------------------------------------
Saved checkpoint to /homes/ad6813/Git/pipe-classification/models/scraping_peeling/net_0/saves/ConvNet__2014-07-08_14.54.04
======================================================= (5.558 sec)
56.16... logprob:  0.627078, 0.320312 (0.679 sec)
56.17... logprob:  0.638397, 0.335938 (0.680 sec)
56.18... logprob:  0.638302, 0.335938 (0.690 sec)
56.19... logprob:  0.633493, 0.328125 (0.686 sec)
56.20... logprob:  0.648439, 0.351562 (0.682 sec)
56.21... logprob:  0.643840, 0.343750 (0.687 sec)
56.22... logprob:  0.630724, 0.320312 (0.682 sec)
56.23... logprob:  0.626856, 0.312500 (0.683 sec)
56.24... logprob:  0.587808, 0.242188 (0.683 sec)
56.25... logprob:  0.630762, 0.320312 (0.678 sec)
56.26... logprob:  0.671484, 0.390625 (0.679 sec)
56.27... logprob:  0.629692, 0.320312 (0.679 sec)
57.1... logprob:  0.677290, 0.398438 (0.680 sec)
57.2... logprob:  0.599717, 0.273438 (0.681 sec)
57.3... logprob:  0.653521, 0.359375 (0.685 sec)
57.4... logprob:  0.597438, 0.273438 (0.685 sec)
57.5... logprob:  0.590551, 0.265625 (0.686 sec)
57.6... logprob:  0.610560, 0.296875 (0.678 sec)
57.7... logprob:  0.644684, 0.343750 (0.680 sec)
57.8... logprob:  0.602885, 0.289062 (0.678 sec)
57.9... logprob:  0.640102, 0.335938 (0.681 sec)
57.10... logprob:  0.595279, 0.281250 (0.686 sec)
57.11... logprob:  0.641702, 0.335938 (0.686 sec)
57.12... logprob:  0.731058, 0.437500 (0.688 sec)
57.13... logprob:  0.661856, 0.359375 (0.695 sec)
57.14... logprob:  0.666797, 0.367188 (0.694 sec)
57.15... logprob:  0.689573, 0.398438 (0.697 sec)
57.16... logprob:  0.627077, 0.320312 (0.683 sec)
57.17... logprob:  0.638399, 0.335938 (0.687 sec)
57.18... logprob:  0.638300, 0.335938 (0.686 sec)
57.19... logprob:  0.633480, 0.328125 (0.680 sec)
57.20... logprob:  0.648439, 0.351562 (0.679 sec)
57.21... logprob:  0.643829, 0.343750 (0.679 sec)
57.22... logprob:  0.630688, 0.320312 (0.679 sec)
57.23... logprob:  0.626812, 0.312500 (0.678 sec)
57.24... logprob:  0.587709, 0.242188 (0.677 sec)
57.25... logprob:  0.630733, 0.320312 (0.678 sec)
57.26... logprob:  0.671502, 0.390625 (0.686 sec)
57.27... logprob:  0.629678, 0.320312 (0.682 sec)
58.1... logprob:  0.677302, 0.398438 (0.685 sec)
58.2... logprob:  0.599706, 0.273438 (0.679 sec)
58.3... logprob:  0.653519, 0.359375 (0.678 sec)
58.4... logprob:  0.597448, 0.273438 (0.675 sec)
58.5... logprob:  0.590572, 0.265625 (0.680 sec)
58.6... logprob:  0.610575, 0.296875 (0.676 sec)
58.7... logprob:  0.644670, 0.343750 (0.682 sec)
58.8... logprob:  0.602904, 0.289062 (0.681 sec)
58.9... logprob:  0.640079, 0.335938 (0.686 sec)
58.10... logprob:  0.595298, 0.281250 (0.683 sec)
58.11... logprob:  0.641669, 0.335938 (0.689 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.662765, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.973593e-03 [6.396653e-09] 
Layer 'conv1' biases: 5.040135e-08 [7.981023e-11] 
Layer 'conv2' weights[0]: 7.960622e-03 [5.126315e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.432474e-10] 
Layer 'conv3' weights[0]: 7.958855e-03 [5.130429e-09] 
Layer 'conv3' biases: 7.796122e-07 [1.422208e-09] 
Layer 'conv4' weights[0]: 7.991395e-03 [5.465671e-09] 
Layer 'conv4' biases: 1.000000e+00 [1.364181e-08] 
Layer 'conv5' weights[0]: 7.990867e-03 [9.395650e-08] 
Layer 'conv5' biases: 1.000012e+00 [1.027718e-07] 
Layer 'fc6' weights[0]: 7.587246e-03 [8.770401e-09] 
Layer 'fc6' biases: 9.999999e-01 [7.676621e-09] 
Layer 'fc7' weights[0]: 7.797076e-03 [1.225510e-07] 
Layer 'fc7' biases: 9.998648e-01 [1.053892e-07] 
Layer 'fc8' weights[0]: 8.144673e-04 [7.041521e-06] 
Layer 'fc8' biases: 1.503445e-02 [1.009221e-04] 
Train error last 27 batches: 0.637395
-------------------------------------------------------
Not saving because 0.662765 > 0.627176 (56.15: -0.03%)
======================================================= (1.740 sec)
58.12... logprob:  0.730945, 0.437500 (0.684 sec)
58.13... logprob:  0.661818, 0.359375 (0.683 sec)
58.14... logprob:  0.666771, 0.367188 (0.681 sec)
58.15... logprob:  0.689560, 0.398438 (0.684 sec)
58.16... logprob:  0.627077, 0.320312 (0.682 sec)
58.17... logprob:  0.638401, 0.335938 (0.681 sec)
58.18... logprob:  0.638298, 0.335938 (0.682 sec)
58.19... logprob:  0.633467, 0.328125 (0.683 sec)
58.20... logprob:  0.648439, 0.351562 (0.682 sec)
58.21... logprob:  0.643818, 0.343750 (0.679 sec)
58.22... logprob:  0.630655, 0.320312 (0.681 sec)
58.23... logprob:  0.626771, 0.312500 (0.678 sec)
58.24... logprob:  0.587619, 0.242188 (0.680 sec)
58.25... logprob:  0.630707, 0.320312 (0.680 sec)
58.26... logprob:  0.671518, 0.390625 (0.678 sec)
58.27... logprob:  0.629665, 0.320312 (0.677 sec)
59.1... logprob:  0.677313, 0.398438 (0.680 sec)
59.2... logprob:  0.599696, 0.273438 (0.678 sec)
59.3... logprob:  0.653519, 0.359375 (0.680 sec)
59.4... logprob:  0.597457, 0.273438 (0.679 sec)
59.5... logprob:  0.590591, 0.265625 (0.678 sec)
59.6... logprob:  0.610588, 0.296875 (0.678 sec)
59.7... logprob:  0.644657, 0.343750 (0.681 sec)
59.8... logprob:  0.602921, 0.289062 (0.678 sec)
59.9... logprob:  0.640058, 0.335938 (0.681 sec)
59.10... logprob:  0.595314, 0.281250 (0.687 sec)
59.11... logprob:  0.641639, 0.335938 (0.684 sec)
59.12... logprob:  0.730841, 0.437500 (0.680 sec)
59.13... logprob:  0.661784, 0.359375 (0.682 sec)
59.14... logprob:  0.666748, 0.367188 (0.680 sec)
59.15... logprob:  0.689548, 0.398438 (0.679 sec)
59.16... logprob:  0.627077, 0.320312 (0.681 sec)
59.17... logprob:  0.638403, 0.335938 (0.679 sec)
59.18... logprob:  0.638296, 0.335938 (0.684 sec)
59.19... logprob:  0.633456, 0.328125 (0.684 sec)
59.20... logprob:  0.648439, 0.351562 (0.683 sec)
59.21... logprob:  0.643808, 0.343750 (0.681 sec)
59.22... logprob:  0.630624, 0.320312 (0.680 sec)
59.23... logprob:  0.626734, 0.312500 (0.678 sec)
59.24... logprob:  0.587534, 0.242188 (0.676 sec)
59.25... logprob:  0.630683, 0.320312 (0.678 sec)
59.26... logprob:  0.671533, 0.390625 (0.680 sec)
59.27... logprob:  0.629653, 0.320312 (0.679 sec)
60.1... logprob:  0.677323, 0.398438 (0.680 sec)
60.2... logprob:  0.599687, 0.273438 (0.680 sec)
60.3... logprob:  0.653518, 0.359375 (0.677 sec)
60.4... logprob:  0.597465, 0.273438 (0.679 sec)
60.5... logprob:  0.590610, 0.265625 (0.679 sec)
60.6... logprob:  0.610601, 0.296875 (0.679 sec)
60.7... logprob:  0.644645, 0.343750 (0.679 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627238, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.973394e-03 [7.292388e-09] 
Layer 'conv1' biases: 5.279612e-08 [1.260084e-10] 
Layer 'conv2' weights[0]: 7.960431e-03 [6.371156e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.393934e-10] 
Layer 'conv3' weights[0]: 7.958670e-03 [6.533270e-09] 
Layer 'conv3' biases: 7.988350e-07 [2.602511e-09] 
Layer 'conv4' weights[0]: 7.991205e-03 [7.216325e-09] 
Layer 'conv4' biases: 1.000000e+00 [2.654859e-08] 
Layer 'conv5' weights[0]: 7.990659e-03 [1.829676e-07] 
Layer 'conv5' biases: 1.000013e+00 [2.002816e-07] 
Layer 'fc6' weights[0]: 7.587052e-03 [1.561405e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.506535e-08] 
Layer 'fc7' weights[0]: 7.795106e-03 [2.233482e-07] 
Layer 'fc7' biases: 9.998642e-01 [2.083287e-07] 
Layer 'fc8' weights[0]: 7.758373e-04 [1.353816e-05] 
Layer 'fc8' biases: 1.582786e-02 [1.859795e-04] 
Train error last 27 batches: 0.637368
-------------------------------------------------------
Not saving because 0.627238 > 0.627176 (56.15: -0.03%)
======================================================= (1.717 sec)
60.8... logprob:  0.602938, 0.289062 (0.685 sec)
60.9... logprob:  0.640038, 0.335938 (0.684 sec)
60.10... logprob:  0.595330, 0.281250 (0.682 sec)
60.11... logprob:  0.641610, 0.335938 (0.681 sec)
60.12... logprob:  0.730742, 0.437500 (0.682 sec)
60.13... logprob:  0.661751, 0.359375 (0.687 sec)
60.14... logprob:  0.666725, 0.367188 (0.681 sec)
60.15... logprob:  0.689537, 0.398438 (0.685 sec)
60.16... logprob:  0.627076, 0.320312 (0.682 sec)
60.17... logprob:  0.638405, 0.335938 (0.678 sec)
60.18... logprob:  0.638294, 0.335938 (0.681 sec)
60.19... logprob:  0.633446, 0.328125 (0.680 sec)
60.20... logprob:  0.648438, 0.351562 (0.681 sec)
60.21... logprob:  0.643799, 0.343750 (0.684 sec)
60.22... logprob:  0.630595, 0.320312 (0.681 sec)
60.23... logprob:  0.626698, 0.312500 (0.678 sec)
60.24... logprob:  0.587454, 0.242188 (0.678 sec)
60.25... logprob:  0.630660, 0.320312 (0.678 sec)
60.26... logprob:  0.671547, 0.390625 (0.680 sec)
60.27... logprob:  0.629641, 0.320312 (0.680 sec)
61.1... logprob:  0.677332, 0.398438 (0.680 sec)
61.2... logprob:  0.599677, 0.273438 (0.682 sec)
61.3... logprob:  0.653518, 0.359375 (0.678 sec)
61.4... logprob:  0.597473, 0.273438 (0.679 sec)
61.5... logprob:  0.590627, 0.265625 (0.681 sec)
61.6... logprob:  0.610613, 0.296875 (0.680 sec)
61.7... logprob:  0.644633, 0.343750 (0.681 sec)
61.8... logprob:  0.602953, 0.289062 (0.680 sec)
61.9... logprob:  0.640019, 0.335938 (0.684 sec)
61.10... logprob:  0.595346, 0.281250 (0.684 sec)
61.11... logprob:  0.641583, 0.335938 (0.685 sec)
61.12... logprob:  0.730647, 0.437500 (0.680 sec)
61.13... logprob:  0.661720, 0.359375 (0.684 sec)
61.14... logprob:  0.666704, 0.367188 (0.682 sec)
61.15... logprob:  0.689525, 0.398438 (0.682 sec)
61.16... logprob:  0.627076, 0.320312 (0.686 sec)
61.17... logprob:  0.638407, 0.335938 (0.681 sec)
61.18... logprob:  0.638292, 0.335938 (0.679 sec)
61.19... logprob:  0.633435, 0.328125 (0.681 sec)
61.20... logprob:  0.648438, 0.351562 (0.677 sec)
61.21... logprob:  0.643790, 0.343750 (0.679 sec)
61.22... logprob:  0.630567, 0.320312 (0.678 sec)
61.23... logprob:  0.626665, 0.312500 (0.680 sec)
61.24... logprob:  0.587378, 0.242188 (0.680 sec)
61.25... logprob:  0.630638, 0.320312 (0.675 sec)
61.26... logprob:  0.671560, 0.390625 (0.680 sec)
61.27... logprob:  0.629629, 0.320312 (0.676 sec)
62.1... logprob:  0.677341, 0.398438 (0.700 sec)
62.2... logprob:  0.599668, 0.273438 (0.692 sec)
62.3... logprob:  0.653517, 0.359375 (0.700 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633274, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.973189e-03 [6.585459e-09] 
Layer 'conv1' biases: 5.538623e-08 [8.541529e-11] 
Layer 'conv2' weights[0]: 7.960229e-03 [5.141427e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.448333e-10] 
Layer 'conv3' weights[0]: 7.958475e-03 [5.204461e-09] 
Layer 'conv3' biases: 8.199496e-07 [1.479514e-09] 
Layer 'conv4' weights[0]: 7.991018e-03 [5.437627e-09] 
Layer 'conv4' biases: 1.000000e+00 [1.350113e-08] 
Layer 'conv5' weights[0]: 7.990501e-03 [9.303000e-08] 
Layer 'conv5' biases: 1.000014e+00 [1.017746e-07] 
Layer 'fc6' weights[0]: 7.586869e-03 [8.701741e-09] 
Layer 'fc6' biases: 9.999999e-01 [7.600091e-09] 
Layer 'fc7' weights[0]: 7.793126e-03 [1.213533e-07] 
Layer 'fc7' biases: 9.998631e-01 [1.039665e-07] 
Layer 'fc8' weights[0]: 7.244440e-04 [6.739842e-06] 
Layer 'fc8' biases: 1.640601e-02 [1.069778e-04] 
Train error last 27 batches: 0.637342
-------------------------------------------------------
Not saving because 0.633274 > 0.627176 (56.15: -0.03%)
======================================================= (1.749 sec)
62.4... logprob:  0.597480, 0.273438 (0.679 sec)
62.5... logprob:  0.590643, 0.265625 (0.685 sec)
62.6... logprob:  0.610624, 0.296875 (0.685 sec)
62.7... logprob:  0.644622, 0.343750 (0.683 sec)
62.8... logprob:  0.602968, 0.289062 (0.675 sec)
62.9... logprob:  0.640002, 0.335938 (0.677 sec)
62.10... logprob:  0.595361, 0.281250 (0.679 sec)
62.11... logprob:  0.641557, 0.335938 (0.679 sec)
62.12... logprob:  0.730556, 0.437500 (0.682 sec)
62.13... logprob:  0.661690, 0.359375 (0.684 sec)
62.14... logprob:  0.666683, 0.367188 (0.683 sec)
62.15... logprob:  0.689514, 0.398438 (0.681 sec)
62.16... logprob:  0.627075, 0.320312 (0.676 sec)
62.17... logprob:  0.638409, 0.335938 (0.679 sec)
62.18... logprob:  0.638291, 0.335938 (0.677 sec)
62.19... logprob:  0.633426, 0.328125 (0.682 sec)
62.20... logprob:  0.648439, 0.351562 (0.679 sec)
62.21... logprob:  0.643782, 0.343750 (0.689 sec)
62.22... logprob:  0.630541, 0.320312 (0.685 sec)
62.23... logprob:  0.626632, 0.312500 (0.696 sec)
62.24... logprob:  0.587304, 0.242188 (0.695 sec)
62.25... logprob:  0.630617, 0.320312 (0.698 sec)
62.26... logprob:  0.671574, 0.390625 (0.694 sec)
62.27... logprob:  0.629618, 0.320312 (0.684 sec)
63.1... logprob:  0.677350, 0.398438 (0.681 sec)
63.2... logprob:  0.599659, 0.273438 (0.695 sec)
63.3... logprob:  0.653516, 0.359375 (0.682 sec)
63.4... logprob:  0.597486, 0.273438 (0.679 sec)
63.5... logprob:  0.590658, 0.265625 (0.700 sec)
63.6... logprob:  0.610635, 0.296875 (0.679 sec)
63.7... logprob:  0.644612, 0.343750 (0.676 sec)
63.8... logprob:  0.602982, 0.289062 (0.675 sec)
63.9... logprob:  0.639984, 0.335938 (0.677 sec)
63.10... logprob:  0.595375, 0.281250 (0.679 sec)
63.11... logprob:  0.641532, 0.335938 (0.684 sec)
63.12... logprob:  0.730468, 0.437500 (0.679 sec)
63.13... logprob:  0.661660, 0.359375 (0.679 sec)
63.14... logprob:  0.666663, 0.367188 (0.680 sec)
63.15... logprob:  0.689504, 0.398438 (0.676 sec)
63.16... logprob:  0.627075, 0.320312 (0.679 sec)
63.17... logprob:  0.638410, 0.335938 (0.683 sec)
63.18... logprob:  0.638289, 0.335938 (0.679 sec)
63.19... logprob:  0.633416, 0.328125 (0.689 sec)
63.20... logprob:  0.648438, 0.351562 (0.678 sec)
63.21... logprob:  0.643774, 0.343750 (0.678 sec)
63.22... logprob:  0.630515, 0.320312 (0.681 sec)
63.23... logprob:  0.626600, 0.312500 (0.681 sec)
63.24... logprob:  0.587233, 0.242188 (0.678 sec)
63.25... logprob:  0.630597, 0.320312 (0.677 sec)
63.26... logprob:  0.671587, 0.390625 (0.680 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.681379, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.972969e-03 [6.218253e-09] 
Layer 'conv1' biases: 5.777880e-08 [7.001474e-11] 
Layer 'conv2' weights[0]: 7.960027e-03 [4.879071e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.637318e-10] 
Layer 'conv3' weights[0]: 7.958286e-03 [4.884492e-09] 
Layer 'conv3' biases: 8.373783e-07 [1.255677e-09] 
Layer 'conv4' weights[0]: 7.990821e-03 [5.138656e-09] 
Layer 'conv4' biases: 1.000000e+00 [1.164456e-08] 
Layer 'conv5' weights[0]: 7.990309e-03 [8.003206e-08] 
Layer 'conv5' biases: 1.000014e+00 [8.764859e-08] 
Layer 'fc6' weights[0]: 7.586668e-03 [7.693858e-09] 
Layer 'fc6' biases: 9.999999e-01 [6.514199e-09] 
Layer 'fc7' weights[0]: 7.791155e-03 [1.061862e-07] 
Layer 'fc7' biases: 9.998627e-01 [8.830039e-08] 
Layer 'fc8' weights[0]: 7.017147e-04 [5.717899e-06] 
Layer 'fc8' biases: 1.734821e-02 [1.021834e-04] 
Train error last 27 batches: 0.637320
-------------------------------------------------------
Not saving because 0.681379 > 0.627176 (56.15: -0.03%)
======================================================= (1.751 sec)
63.27... logprob:  0.629607, 0.320312 (0.678 sec)
64.1... logprob:  0.677359, 0.398438 (0.681 sec)
64.2... logprob:  0.599650, 0.273438 (0.683 sec)
64.3... logprob:  0.653516, 0.359375 (0.681 sec)
64.4... logprob:  0.597492, 0.273438 (0.678 sec)
64.5... logprob:  0.590673, 0.265625 (0.679 sec)
64.6... logprob:  0.610646, 0.296875 (0.680 sec)
64.7... logprob:  0.644601, 0.343750 (0.679 sec)
64.8... logprob:  0.602996, 0.289062 (0.681 sec)
64.9... logprob:  0.639968, 0.335938 (0.677 sec)
64.10... logprob:  0.595389, 0.281250 (0.674 sec)
64.11... logprob:  0.641507, 0.335938 (0.677 sec)
64.12... logprob:  0.730383, 0.437500 (0.680 sec)
64.13... logprob:  0.661632, 0.359375 (0.684 sec)
64.14... logprob:  0.666643, 0.367188 (0.682 sec)
64.15... logprob:  0.689493, 0.398438 (0.697 sec)
64.16... logprob:  0.627075, 0.320312 (0.682 sec)
64.17... logprob:  0.638412, 0.335938 (0.683 sec)
64.18... logprob:  0.638288, 0.335938 (0.690 sec)
64.19... logprob:  0.633407, 0.328125 (0.690 sec)
64.20... logprob:  0.648439, 0.351562 (0.710 sec)
64.21... logprob:  0.643766, 0.343750 (0.698 sec)
64.22... logprob:  0.630490, 0.320312 (0.696 sec)
64.23... logprob:  0.626570, 0.312500 (0.703 sec)
64.24... logprob:  0.587163, 0.242188 (0.696 sec)
64.25... logprob:  0.630577, 0.320312 (0.693 sec)
64.26... logprob:  0.671598, 0.390625 (0.683 sec)
64.27... logprob:  0.629597, 0.320312 (0.681 sec)
65.1... logprob:  0.677367, 0.398438 (0.687 sec)
65.2... logprob:  0.599642, 0.273438 (0.690 sec)
65.3... logprob:  0.653515, 0.359375 (0.678 sec)
65.4... logprob:  0.597498, 0.273438 (0.679 sec)
65.5... logprob:  0.590687, 0.265625 (0.675 sec)
65.6... logprob:  0.610656, 0.296875 (0.679 sec)
65.7... logprob:  0.644591, 0.343750 (0.685 sec)
65.8... logprob:  0.603010, 0.289062 (0.682 sec)
65.9... logprob:  0.639952, 0.335938 (0.679 sec)
65.10... logprob:  0.595403, 0.281250 (0.681 sec)
65.11... logprob:  0.641483, 0.335938 (0.683 sec)
65.12... logprob:  0.730298, 0.437500 (0.681 sec)
65.13... logprob:  0.661604, 0.359375 (0.684 sec)
65.14... logprob:  0.666624, 0.367188 (0.688 sec)
65.15... logprob:  0.689483, 0.398438 (0.681 sec)
65.16... logprob:  0.627075, 0.320312 (0.675 sec)
65.17... logprob:  0.638414, 0.335938 (0.679 sec)
65.18... logprob:  0.638286, 0.335938 (0.681 sec)
65.19... logprob:  0.633398, 0.328125 (0.690 sec)
65.20... logprob:  0.648439, 0.351562 (0.694 sec)
65.21... logprob:  0.643758, 0.343750 (0.690 sec)
65.22... logprob:  0.630465, 0.320312 (0.706 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.635385, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.972770e-03 [5.895492e-09] 
Layer 'conv1' biases: 6.018045e-08 [1.040966e-10] 
Layer 'conv2' weights[0]: 7.959822e-03 [5.257551e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.702616e-10] 
Layer 'conv3' weights[0]: 7.958087e-03 [4.865361e-09] 
Layer 'conv3' biases: 8.543177e-07 [1.318858e-09] 
Layer 'conv4' weights[0]: 7.990601e-03 [4.981146e-09] 
Layer 'conv4' biases: 1.000000e+00 [1.125222e-08] 
Layer 'conv5' weights[0]: 7.990115e-03 [7.811301e-08] 
Layer 'conv5' biases: 1.000014e+00 [8.556768e-08] 
Layer 'fc6' weights[0]: 7.586468e-03 [7.775928e-09] 
Layer 'fc6' biases: 9.999999e-01 [6.668979e-09] 
Layer 'fc7' weights[0]: 7.789208e-03 [1.115054e-07] 
Layer 'fc7' biases: 9.998623e-01 [9.521076e-08] 
Layer 'fc8' weights[0]: 6.845600e-04 [5.881777e-06] 
Layer 'fc8' biases: 1.833621e-02 [5.144857e-05] 
Train error last 27 batches: 0.637302
-------------------------------------------------------
Not saving because 0.635385 > 0.627176 (56.15: -0.03%)
======================================================= (1.785 sec)
65.23... logprob:  0.626539, 0.312500 (0.697 sec)
65.24... logprob:  0.587094, 0.242188 (0.688 sec)
65.25... logprob:  0.630557, 0.320312 (0.713 sec)
65.26... logprob:  0.671611, 0.390625 (0.695 sec)
65.27... logprob:  0.629586, 0.320312 (0.709 sec)
66.1... logprob:  0.677376, 0.398438 (0.705 sec)
66.2... logprob:  0.599633, 0.273438 (0.699 sec)
66.3... logprob:  0.653514, 0.359375 (0.683 sec)
66.4... logprob:  0.597505, 0.273438 (0.681 sec)
66.5... logprob:  0.590701, 0.265625 (0.688 sec)
66.6... logprob:  0.610667, 0.296875 (0.681 sec)
66.7... logprob:  0.644581, 0.343750 (0.677 sec)
66.8... logprob:  0.603023, 0.289062 (0.681 sec)
66.9... logprob:  0.639936, 0.335938 (0.684 sec)
66.10... logprob:  0.595416, 0.281250 (0.684 sec)
66.11... logprob:  0.641460, 0.335938 (0.692 sec)
66.12... logprob:  0.730214, 0.437500 (0.680 sec)
66.13... logprob:  0.661576, 0.359375 (0.682 sec)
66.14... logprob:  0.666605, 0.367188 (0.681 sec)
66.15... logprob:  0.689472, 0.398438 (0.683 sec)
66.16... logprob:  0.627074, 0.320312 (0.681 sec)
66.17... logprob:  0.638415, 0.335938 (0.679 sec)
66.18... logprob:  0.638285, 0.335938 (0.678 sec)
66.19... logprob:  0.633389, 0.328125 (0.682 sec)
66.20... logprob:  0.648439, 0.351562 (0.684 sec)
66.21... logprob:  0.643751, 0.343750 (0.685 sec)
66.22... logprob:  0.630441, 0.320312 (0.688 sec)
66.23... logprob:  0.626510, 0.312500 (0.679 sec)
66.24... logprob:  0.587026, 0.242188 (0.678 sec)
66.25... logprob:  0.630537, 0.320312 (0.679 sec)
66.26... logprob:  0.671623, 0.390625 (0.682 sec)
66.27... logprob:  0.629576, 0.320312 (0.682 sec)
67.1... logprob:  0.677384, 0.398438 (0.677 sec)
67.2... logprob:  0.599624, 0.273438 (0.677 sec)
67.3... logprob:  0.653514, 0.359375 (0.683 sec)
67.4... logprob:  0.597510, 0.273438 (0.677 sec)
67.5... logprob:  0.590715, 0.265625 (0.677 sec)
67.6... logprob:  0.610677, 0.296875 (0.676 sec)
67.7... logprob:  0.644572, 0.343750 (0.676 sec)
67.8... logprob:  0.603037, 0.289062 (0.679 sec)
67.9... logprob:  0.639920, 0.335938 (0.684 sec)
67.10... logprob:  0.595430, 0.281250 (0.681 sec)
67.11... logprob:  0.641436, 0.335938 (0.681 sec)
67.12... logprob:  0.730132, 0.437500 (0.681 sec)
67.13... logprob:  0.661548, 0.359375 (0.676 sec)
67.14... logprob:  0.666586, 0.367188 (0.675 sec)
67.15... logprob:  0.689462, 0.398438 (0.678 sec)
67.16... logprob:  0.627074, 0.320312 (0.681 sec)
67.17... logprob:  0.638417, 0.335938 (0.679 sec)
67.18... logprob:  0.638283, 0.335938 (0.678 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.628465, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.972575e-03 [6.585490e-09] 
Layer 'conv1' biases: 6.225632e-08 [1.856692e-10] 
Layer 'conv2' weights[0]: 7.959621e-03 [7.417737e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.046627e-09] 
Layer 'conv3' weights[0]: 7.957882e-03 [6.900739e-09] 
Layer 'conv3' biases: 8.634615e-07 [3.080002e-09] 
Layer 'conv4' weights[0]: 7.990407e-03 [7.524613e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.027164e-08] 
Layer 'conv5' weights[0]: 7.989875e-03 [2.095363e-07] 
Layer 'conv5' biases: 1.000013e+00 [2.293730e-07] 
Layer 'fc6' weights[0]: 7.586272e-03 [1.821183e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.771593e-08] 
Layer 'fc7' weights[0]: 7.787205e-03 [2.628167e-07] 
Layer 'fc7' biases: 9.998628e-01 [2.498730e-07] 
Layer 'fc8' weights[0]: 7.200781e-04 [1.553092e-05] 
Layer 'fc8' biases: 2.011300e-02 [1.705267e-04] 
Train error last 27 batches: 0.637282
-------------------------------------------------------
Not saving because 0.628465 > 0.627176 (56.15: -0.03%)
======================================================= (1.707 sec)
67.19... logprob:  0.633380, 0.328125 (0.679 sec)
67.20... logprob:  0.648439, 0.351562 (0.680 sec)
67.21... logprob:  0.643744, 0.343750 (0.680 sec)
67.22... logprob:  0.630417, 0.320312 (0.684 sec)
67.23... logprob:  0.626481, 0.312500 (0.684 sec)
67.24... logprob:  0.586959, 0.242188 (0.681 sec)
67.25... logprob:  0.630518, 0.320312 (0.679 sec)
67.26... logprob:  0.671635, 0.390625 (0.681 sec)
67.27... logprob:  0.629566, 0.320312 (0.677 sec)
68.1... logprob:  0.677393, 0.398438 (0.677 sec)
68.2... logprob:  0.599616, 0.273438 (0.680 sec)
68.3... logprob:  0.653513, 0.359375 (0.680 sec)
68.4... logprob:  0.597515, 0.273438 (0.677 sec)
68.5... logprob:  0.590728, 0.265625 (0.679 sec)
68.6... logprob:  0.610687, 0.296875 (0.677 sec)
68.7... logprob:  0.644562, 0.343750 (0.675 sec)
68.8... logprob:  0.603050, 0.289062 (0.683 sec)
68.9... logprob:  0.639905, 0.335938 (0.677 sec)
68.10... logprob:  0.595444, 0.281250 (0.676 sec)
68.11... logprob:  0.641413, 0.335938 (0.679 sec)
68.12... logprob:  0.730050, 0.437500 (0.678 sec)
68.13... logprob:  0.661521, 0.359375 (0.679 sec)
68.14... logprob:  0.666566, 0.367188 (0.679 sec)
68.15... logprob:  0.689451, 0.398438 (0.677 sec)
68.16... logprob:  0.627074, 0.320312 (0.680 sec)
68.17... logprob:  0.638418, 0.335938 (0.679 sec)
68.18... logprob:  0.638282, 0.335938 (0.678 sec)
68.19... logprob:  0.633372, 0.328125 (0.684 sec)
68.20... logprob:  0.648439, 0.351562 (0.679 sec)
68.21... logprob:  0.643736, 0.343750 (0.680 sec)
68.22... logprob:  0.630394, 0.320312 (0.684 sec)
68.23... logprob:  0.626451, 0.312500 (0.685 sec)
68.24... logprob:  0.586893, 0.242188 (0.679 sec)
68.25... logprob:  0.630499, 0.320312 (0.678 sec)
68.26... logprob:  0.671647, 0.390625 (0.681 sec)
68.27... logprob:  0.629555, 0.320312 (0.676 sec)
69.1... logprob:  0.677401, 0.398438 (0.675 sec)
69.2... logprob:  0.599606, 0.273438 (0.681 sec)
69.3... logprob:  0.653513, 0.359375 (0.678 sec)
69.4... logprob:  0.597520, 0.273438 (0.681 sec)
69.5... logprob:  0.590741, 0.265625 (0.681 sec)
69.6... logprob:  0.610696, 0.296875 (0.684 sec)
69.7... logprob:  0.644553, 0.343750 (0.692 sec)
69.8... logprob:  0.603063, 0.289062 (0.679 sec)
69.9... logprob:  0.639889, 0.335938 (0.676 sec)
69.10... logprob:  0.595457, 0.281250 (0.682 sec)
69.11... logprob:  0.641390, 0.335938 (0.680 sec)
69.12... logprob:  0.729969, 0.437500 (0.679 sec)
69.13... logprob:  0.661494, 0.359375 (0.679 sec)
69.14... logprob:  0.666547, 0.367188 (0.683 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.658373, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.972381e-03 [7.031467e-09] 
Layer 'conv1' biases: 6.422060e-08 [1.871768e-10] 
Layer 'conv2' weights[0]: 7.959424e-03 [7.367896e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.024749e-09] 
Layer 'conv3' weights[0]: 7.957688e-03 [6.766334e-09] 
Layer 'conv3' biases: 8.697335e-07 [2.982828e-09] 
Layer 'conv4' weights[0]: 7.990203e-03 [7.345196e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.883071e-08] 
Layer 'conv5' weights[0]: 7.989639e-03 [1.995469e-07] 
Layer 'conv5' biases: 1.000012e+00 [2.185017e-07] 
Layer 'fc6' weights[0]: 7.586068e-03 [1.748255e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.698773e-08] 
Layer 'fc7' weights[0]: 7.785222e-03 [2.535082e-07] 
Layer 'fc7' biases: 9.998637e-01 [2.404434e-07] 
Layer 'fc8' weights[0]: 7.847251e-04 [1.487510e-05] 
Layer 'fc8' biases: 2.225807e-02 [1.555632e-04] 
Train error last 27 batches: 0.637261
-------------------------------------------------------
Not saving because 0.658373 > 0.627176 (56.15: -0.03%)
======================================================= (1.717 sec)
69.15... logprob:  0.689440, 0.398438 (0.683 sec)
69.16... logprob:  0.627074, 0.320312 (0.679 sec)
69.17... logprob:  0.638420, 0.335938 (0.681 sec)
69.18... logprob:  0.638281, 0.335938 (0.679 sec)
69.19... logprob:  0.633364, 0.328125 (0.681 sec)
69.20... logprob:  0.648440, 0.351562 (0.680 sec)
69.21... logprob:  0.643729, 0.343750 (0.681 sec)
69.22... logprob:  0.630371, 0.320312 (0.683 sec)
69.23... logprob:  0.626423, 0.312500 (0.679 sec)
69.24... logprob:  0.586827, 0.242188 (0.680 sec)
69.25... logprob:  0.630480, 0.320312 (0.684 sec)
69.26... logprob:  0.671659, 0.390625 (0.681 sec)
69.27... logprob:  0.629545, 0.320312 (0.680 sec)
70.1... logprob:  0.677410, 0.398438 (0.677 sec)
70.2... logprob:  0.599597, 0.273438 (0.683 sec)
70.3... logprob:  0.653512, 0.359375 (0.679 sec)
70.4... logprob:  0.597525, 0.273438 (0.678 sec)
70.5... logprob:  0.590754, 0.265625 (0.682 sec)
70.6... logprob:  0.610706, 0.296875 (0.679 sec)
70.7... logprob:  0.644544, 0.343750 (0.684 sec)
70.8... logprob:  0.603076, 0.289062 (0.677 sec)
70.9... logprob:  0.639874, 0.335938 (0.679 sec)
70.10... logprob:  0.595471, 0.281250 (0.677 sec)
70.11... logprob:  0.641368, 0.335938 (0.678 sec)
70.12... logprob:  0.729889, 0.437500 (0.681 sec)
70.13... logprob:  0.661467, 0.359375 (0.681 sec)
70.14... logprob:  0.666528, 0.367188 (0.679 sec)
70.15... logprob:  0.689430, 0.398438 (0.680 sec)
70.16... logprob:  0.627073, 0.320312 (0.680 sec)
70.17... logprob:  0.638422, 0.335938 (0.680 sec)
70.18... logprob:  0.638279, 0.335938 (0.683 sec)
70.19... logprob:  0.633355, 0.328125 (0.693 sec)
70.20... logprob:  0.648440, 0.351562 (0.685 sec)
70.21... logprob:  0.643723, 0.343750 (0.681 sec)
70.22... logprob:  0.630348, 0.320312 (0.682 sec)
70.23... logprob:  0.626394, 0.312500 (0.679 sec)
70.24... logprob:  0.586761, 0.242188 (0.680 sec)
70.25... logprob:  0.630461, 0.320312 (0.682 sec)
70.26... logprob:  0.671671, 0.390625 (0.679 sec)
70.27... logprob:  0.629535, 0.320312 (0.675 sec)
71.1... logprob:  0.677418, 0.398438 (0.678 sec)
71.2... logprob:  0.599589, 0.273438 (0.681 sec)
71.3... logprob:  0.653512, 0.359375 (0.685 sec)
71.4... logprob:  0.597530, 0.273438 (0.682 sec)
71.5... logprob:  0.590767, 0.265625 (0.699 sec)
71.6... logprob:  0.610716, 0.296875 (0.681 sec)
71.7... logprob:  0.644535, 0.343750 (0.681 sec)
71.8... logprob:  0.603090, 0.289062 (0.681 sec)
71.9... logprob:  0.639859, 0.335938 (0.678 sec)
71.10... logprob:  0.595484, 0.281250 (0.680 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.628178, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.972173e-03 [6.961479e-09] 
Layer 'conv1' biases: 6.651844e-08 [1.084128e-10] 
Layer 'conv2' weights[0]: 7.959229e-03 [5.907762e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.102802e-10] 
Layer 'conv3' weights[0]: 7.957502e-03 [6.079484e-09] 
Layer 'conv3' biases: 8.826531e-07 [2.245107e-09] 
Layer 'conv4' weights[0]: 7.990012e-03 [6.690058e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.275551e-08] 
Layer 'conv5' weights[0]: 7.989414e-03 [1.569678e-07] 
Layer 'conv5' biases: 1.000011e+00 [1.719194e-07] 
Layer 'fc6' weights[0]: 7.585870e-03 [1.368819e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.313372e-08] 
Layer 'fc7' weights[0]: 7.783202e-03 [1.964674e-07] 
Layer 'fc7' biases: 9.998639e-01 [1.819167e-07] 
Layer 'fc8' weights[0]: 8.054422e-04 [1.134718e-05] 
Layer 'fc8' biases: 2.379531e-02 [1.577725e-04] 
Train error last 27 batches: 0.637246
-------------------------------------------------------
Not saving because 0.628178 > 0.627176 (56.15: -0.03%)
======================================================= (1.725 sec)
71.11... logprob:  0.641346, 0.335938 (0.679 sec)
71.12... logprob:  0.729808, 0.437500 (0.681 sec)
71.13... logprob:  0.661441, 0.359375 (0.680 sec)
71.14... logprob:  0.666509, 0.367188 (0.680 sec)
71.15... logprob:  0.689418, 0.398438 (0.677 sec)
71.16... logprob:  0.627073, 0.320312 (0.680 sec)
71.17... logprob:  0.638423, 0.335938 (0.677 sec)
71.18... logprob:  0.638278, 0.335938 (0.679 sec)
71.19... logprob:  0.633347, 0.328125 (0.680 sec)
71.20... logprob:  0.648440, 0.351562 (0.682 sec)
71.21... logprob:  0.643716, 0.343750 (0.690 sec)
71.22... logprob:  0.630326, 0.320312 (0.702 sec)
71.23... logprob:  0.626367, 0.312500 (0.686 sec)
71.24... logprob:  0.586697, 0.242188 (0.680 sec)
71.25... logprob:  0.630443, 0.320312 (0.680 sec)
71.26... logprob:  0.671683, 0.390625 (0.681 sec)
71.27... logprob:  0.629525, 0.320312 (0.678 sec)
72.1... logprob:  0.677426, 0.398438 (0.678 sec)
72.2... logprob:  0.599579, 0.273438 (0.679 sec)
72.3... logprob:  0.653512, 0.359375 (0.678 sec)
72.4... logprob:  0.597534, 0.273438 (0.674 sec)
72.5... logprob:  0.590779, 0.265625 (0.681 sec)
72.6... logprob:  0.610725, 0.296875 (0.683 sec)
72.7... logprob:  0.644526, 0.343750 (0.705 sec)
72.8... logprob:  0.603102, 0.289062 (0.699 sec)
72.9... logprob:  0.639845, 0.335938 (0.697 sec)
72.10... logprob:  0.595497, 0.281250 (0.701 sec)
72.11... logprob:  0.641324, 0.335938 (0.694 sec)
72.12... logprob:  0.729730, 0.437500 (0.695 sec)
72.13... logprob:  0.661414, 0.359375 (0.694 sec)
72.14... logprob:  0.666491, 0.367188 (0.694 sec)
72.15... logprob:  0.689407, 0.398438 (0.684 sec)
72.16... logprob:  0.627073, 0.320312 (0.681 sec)
72.17... logprob:  0.638425, 0.335938 (0.682 sec)
72.18... logprob:  0.638277, 0.335938 (0.683 sec)
72.19... logprob:  0.633340, 0.328125 (0.679 sec)
72.20... logprob:  0.648441, 0.351562 (0.678 sec)
72.21... logprob:  0.643710, 0.343750 (0.680 sec)
72.22... logprob:  0.630304, 0.320312 (0.679 sec)
72.23... logprob:  0.626339, 0.312500 (0.684 sec)
72.24... logprob:  0.586634, 0.242188 (0.681 sec)
72.25... logprob:  0.630425, 0.320312 (0.681 sec)
72.26... logprob:  0.671694, 0.390625 (0.683 sec)
72.27... logprob:  0.629515, 0.320312 (0.698 sec)
73.1... logprob:  0.677434, 0.398438 (0.690 sec)
73.2... logprob:  0.599571, 0.273438 (0.694 sec)
73.3... logprob:  0.653511, 0.359375 (0.681 sec)
73.4... logprob:  0.597538, 0.273438 (0.697 sec)
73.5... logprob:  0.590791, 0.265625 (0.687 sec)
73.6... logprob:  0.610734, 0.296875 (0.681 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.632894, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.971976e-03 [7.637543e-09] 
Layer 'conv1' biases: 6.926246e-08 [1.622292e-10] 
Layer 'conv2' weights[0]: 7.959026e-03 [6.969080e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.032324e-09] 
Layer 'conv3' weights[0]: 7.957296e-03 [7.216186e-09] 
Layer 'conv3' biases: 9.051351e-07 [3.164158e-09] 
Layer 'conv4' weights[0]: 7.989812e-03 [7.980600e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.227142e-08] 
Layer 'conv5' weights[0]: 7.989228e-03 [2.223706e-07] 
Layer 'conv5' biases: 1.000012e+00 [2.435775e-07] 
Layer 'fc6' weights[0]: 7.585675e-03 [1.928205e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.869781e-08] 
Layer 'fc7' weights[0]: 7.781276e-03 [2.731148e-07] 
Layer 'fc7' biases: 9.998633e-01 [2.592894e-07] 
Layer 'fc8' weights[0]: 7.595844e-04 [1.614711e-05] 
Layer 'fc8' biases: 2.443839e-02 [2.279699e-04] 
Train error last 27 batches: 0.637226
-------------------------------------------------------
Not saving because 0.632894 > 0.627176 (56.15: -0.03%)
======================================================= (1.721 sec)
73.7... logprob:  0.644517, 0.343750 (0.688 sec)
73.8... logprob:  0.603115, 0.289062 (0.688 sec)
73.9... logprob:  0.639831, 0.335938 (0.689 sec)
73.10... logprob:  0.595511, 0.281250 (0.689 sec)
73.11... logprob:  0.641302, 0.335938 (0.684 sec)
73.12... logprob:  0.729652, 0.437500 (0.682 sec)
73.13... logprob:  0.661388, 0.359375 (0.679 sec)
73.14... logprob:  0.666472, 0.367188 (0.680 sec)
73.15... logprob:  0.689396, 0.398438 (0.688 sec)
73.16... logprob:  0.627072, 0.320312 (0.691 sec)
73.17... logprob:  0.638427, 0.335938 (0.690 sec)
73.18... logprob:  0.638275, 0.335938 (0.682 sec)
73.19... logprob:  0.633332, 0.328125 (0.682 sec)
73.20... logprob:  0.648442, 0.351562 (0.679 sec)
73.21... logprob:  0.643703, 0.343750 (0.684 sec)
73.22... logprob:  0.630282, 0.320312 (0.682 sec)
73.23... logprob:  0.626312, 0.312500 (0.680 sec)
73.24... logprob:  0.586570, 0.242188 (0.687 sec)
73.25... logprob:  0.630407, 0.320312 (0.687 sec)
73.26... logprob:  0.671706, 0.390625 (0.685 sec)
73.27... logprob:  0.629505, 0.320312 (0.682 sec)
74.1... logprob:  0.677443, 0.398438 (0.687 sec)
74.2... logprob:  0.599561, 0.273438 (0.691 sec)
74.3... logprob:  0.653510, 0.359375 (0.688 sec)
74.4... logprob:  0.597543, 0.273438 (0.688 sec)
74.5... logprob:  0.590803, 0.265625 (0.697 sec)
74.6... logprob:  0.610743, 0.296875 (0.681 sec)
74.7... logprob:  0.644509, 0.343750 (0.679 sec)
74.8... logprob:  0.603128, 0.289062 (0.685 sec)
74.9... logprob:  0.639817, 0.335938 (0.687 sec)
74.10... logprob:  0.595524, 0.281250 (0.684 sec)
74.11... logprob:  0.641281, 0.335938 (0.680 sec)
74.12... logprob:  0.729573, 0.437500 (0.686 sec)
74.13... logprob:  0.661362, 0.359375 (0.689 sec)
74.14... logprob:  0.666453, 0.367188 (0.680 sec)
74.15... logprob:  0.689385, 0.398438 (0.680 sec)
74.16... logprob:  0.627072, 0.320312 (0.683 sec)
74.17... logprob:  0.638428, 0.335938 (0.683 sec)
74.18... logprob:  0.638274, 0.335938 (0.698 sec)
74.19... logprob:  0.633324, 0.328125 (0.704 sec)
74.20... logprob:  0.648442, 0.351562 (0.686 sec)
74.21... logprob:  0.643697, 0.343750 (0.682 sec)
74.22... logprob:  0.630260, 0.320312 (0.683 sec)
74.23... logprob:  0.626285, 0.312500 (0.686 sec)
74.24... logprob:  0.586507, 0.242188 (0.685 sec)
74.25... logprob:  0.630389, 0.320312 (0.680 sec)
74.26... logprob:  0.671718, 0.390625 (0.678 sec)
74.27... logprob:  0.629496, 0.320312 (0.679 sec)
75.1... logprob:  0.677451, 0.398438 (0.677 sec)
75.2... logprob:  0.599552, 0.273438 (0.680 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.683524, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.971778e-03 [6.627852e-09] 
Layer 'conv1' biases: 7.203910e-08 [9.254266e-11] 
Layer 'conv2' weights[0]: 7.958825e-03 [5.281757e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.217931e-10] 
Layer 'conv3' weights[0]: 7.957101e-03 [5.414923e-09] 
Layer 'conv3' biases: 9.275619e-07 [1.694648e-09] 
Layer 'conv4' weights[0]: 7.989623e-03 [5.735955e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.606558e-08] 
Layer 'conv5' weights[0]: 7.989054e-03 [1.104664e-07] 
Layer 'conv5' biases: 1.000012e+00 [1.209838e-07] 
Layer 'fc6' weights[0]: 7.585490e-03 [1.015235e-08] 
Layer 'fc6' biases: 9.999999e-01 [9.240600e-09] 
Layer 'fc7' weights[0]: 7.779323e-03 [1.424152e-07] 
Layer 'fc7' biases: 9.998627e-01 [1.269552e-07] 
Layer 'fc8' weights[0]: 7.151716e-04 [7.908245e-06] 
Layer 'fc8' biases: 2.505486e-02 [1.277050e-04] 
Train error last 27 batches: 0.637205
-------------------------------------------------------
Not saving because 0.683524 > 0.627176 (56.15: -0.03%)
======================================================= (1.732 sec)
75.3... logprob:  0.653510, 0.359375 (0.678 sec)
75.4... logprob:  0.597546, 0.273438 (0.684 sec)
75.5... logprob:  0.590814, 0.265625 (0.682 sec)
75.6... logprob:  0.610752, 0.296875 (0.689 sec)
75.7... logprob:  0.644500, 0.343750 (0.676 sec)
75.8... logprob:  0.603140, 0.289062 (0.683 sec)
75.9... logprob:  0.639803, 0.335938 (0.679 sec)
75.10... logprob:  0.595537, 0.281250 (0.679 sec)
75.11... logprob:  0.641260, 0.335938 (0.679 sec)
75.12... logprob:  0.729496, 0.437500 (0.680 sec)
75.13... logprob:  0.661336, 0.359375 (0.677 sec)
75.14... logprob:  0.666435, 0.367188 (0.680 sec)
75.15... logprob:  0.689374, 0.398438 (0.677 sec)
75.16... logprob:  0.627072, 0.320312 (0.677 sec)
75.17... logprob:  0.638429, 0.335938 (0.678 sec)
75.18... logprob:  0.638273, 0.335938 (0.677 sec)
75.19... logprob:  0.633317, 0.328125 (0.680 sec)
75.20... logprob:  0.648443, 0.351562 (0.678 sec)
75.21... logprob:  0.643691, 0.343750 (0.678 sec)
75.22... logprob:  0.630239, 0.320312 (0.678 sec)
75.23... logprob:  0.626258, 0.312500 (0.677 sec)
75.24... logprob:  0.586445, 0.242188 (0.678 sec)
75.25... logprob:  0.630371, 0.320312 (0.677 sec)
75.26... logprob:  0.671730, 0.390625 (0.679 sec)
75.27... logprob:  0.629486, 0.320312 (0.675 sec)
76.1... logprob:  0.677460, 0.398438 (0.677 sec)
76.2... logprob:  0.599543, 0.273438 (0.677 sec)
76.3... logprob:  0.653510, 0.359375 (0.677 sec)
76.4... logprob:  0.597551, 0.273438 (0.676 sec)
76.5... logprob:  0.590826, 0.265625 (0.677 sec)
76.6... logprob:  0.610761, 0.296875 (0.677 sec)
76.7... logprob:  0.644492, 0.343750 (0.675 sec)
76.8... logprob:  0.603153, 0.289062 (0.678 sec)
76.9... logprob:  0.639789, 0.335938 (0.676 sec)
76.10... logprob:  0.595550, 0.281250 (0.676 sec)
76.11... logprob:  0.641238, 0.335938 (0.673 sec)
76.12... logprob:  0.729419, 0.437500 (0.671 sec)
76.13... logprob:  0.661310, 0.359375 (0.675 sec)
76.14... logprob:  0.666416, 0.367188 (0.674 sec)
76.15... logprob:  0.689362, 0.398438 (0.676 sec)
76.16... logprob:  0.627072, 0.320312 (0.678 sec)
76.17... logprob:  0.638431, 0.335938 (0.674 sec)
76.18... logprob:  0.638272, 0.335938 (0.675 sec)
76.19... logprob:  0.633309, 0.328125 (0.676 sec)
76.20... logprob:  0.648443, 0.351562 (0.675 sec)
76.21... logprob:  0.643684, 0.343750 (0.674 sec)
76.22... logprob:  0.630218, 0.320312 (0.674 sec)
76.23... logprob:  0.626231, 0.312500 (0.673 sec)
76.24... logprob:  0.586382, 0.242188 (0.674 sec)
76.25... logprob:  0.630354, 0.320312 (0.675 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.634451, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.971576e-03 [6.339921e-09] 
Layer 'conv1' biases: 7.467420e-08 [8.275120e-11] 
Layer 'conv2' weights[0]: 7.958626e-03 [5.238869e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.302583e-10] 
Layer 'conv3' weights[0]: 7.956922e-03 [5.351988e-09] 
Layer 'conv3' biases: 9.471351e-07 [1.740843e-09] 
Layer 'conv4' weights[0]: 7.989424e-03 [5.781949e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.713705e-08] 
Layer 'conv5' weights[0]: 7.988860e-03 [1.174450e-07] 
Layer 'conv5' biases: 1.000013e+00 [1.286084e-07] 
Layer 'fc6' weights[0]: 7.585286e-03 [1.063907e-08] 
Layer 'fc6' biases: 9.999999e-01 [9.836897e-09] 
Layer 'fc7' weights[0]: 7.777318e-03 [1.499129e-07] 
Layer 'fc7' biases: 9.998623e-01 [1.347956e-07] 
Layer 'fc8' weights[0]: 6.940456e-04 [8.410263e-06] 
Layer 'fc8' biases: 2.597172e-02 [1.448934e-04] 
Train error last 27 batches: 0.637185
-------------------------------------------------------
Not saving because 0.634451 > 0.627176 (56.15: -0.03%)
======================================================= (1.729 sec)
76.26... logprob:  0.671742, 0.390625 (0.676 sec)
76.27... logprob:  0.629476, 0.320312 (0.675 sec)
77.1... logprob:  0.677468, 0.398438 (0.674 sec)
77.2... logprob:  0.599533, 0.273438 (0.679 sec)
77.3... logprob:  0.653510, 0.359375 (0.677 sec)
77.4... logprob:  0.597554, 0.273438 (0.676 sec)
77.5... logprob:  0.590837, 0.265625 (0.681 sec)
77.6... logprob:  0.610770, 0.296875 (0.684 sec)
77.7... logprob:  0.644484, 0.343750 (0.682 sec)
77.8... logprob:  0.603165, 0.289062 (0.700 sec)
77.9... logprob:  0.639776, 0.335938 (0.692 sec)
77.10... logprob:  0.595564, 0.281250 (0.677 sec)
77.11... logprob:  0.641217, 0.335938 (0.675 sec)
77.12... logprob:  0.729342, 0.437500 (0.674 sec)
77.13... logprob:  0.661284, 0.359375 (0.675 sec)
77.14... logprob:  0.666397, 0.367188 (0.675 sec)
77.15... logprob:  0.689350, 0.398438 (0.673 sec)
77.16... logprob:  0.627071, 0.320312 (0.672 sec)
77.17... logprob:  0.638432, 0.335938 (0.673 sec)
77.18... logprob:  0.638271, 0.335938 (0.679 sec)
77.19... logprob:  0.633302, 0.328125 (0.678 sec)
77.20... logprob:  0.648444, 0.351562 (0.679 sec)
77.21... logprob:  0.643678, 0.343750 (0.675 sec)
77.22... logprob:  0.630197, 0.320312 (0.675 sec)
77.23... logprob:  0.626205, 0.312500 (0.676 sec)
77.24... logprob:  0.586321, 0.242188 (0.674 sec)
77.25... logprob:  0.630336, 0.320312 (0.674 sec)
77.26... logprob:  0.671753, 0.390625 (0.676 sec)
77.27... logprob:  0.629466, 0.320312 (0.677 sec)
78.1... logprob:  0.677477, 0.398438 (0.682 sec)
78.2... logprob:  0.599524, 0.273438 (0.679 sec)
78.3... logprob:  0.653509, 0.359375 (0.682 sec)
78.4... logprob:  0.597557, 0.273438 (0.684 sec)
78.5... logprob:  0.590847, 0.265625 (0.677 sec)
78.6... logprob:  0.610778, 0.296875 (0.681 sec)
78.7... logprob:  0.644476, 0.343750 (0.675 sec)
78.8... logprob:  0.603177, 0.289062 (0.678 sec)
78.9... logprob:  0.639762, 0.335938 (0.680 sec)
78.10... logprob:  0.595577, 0.281250 (0.678 sec)
78.11... logprob:  0.641197, 0.335938 (0.680 sec)
78.12... logprob:  0.729266, 0.437500 (0.681 sec)
78.13... logprob:  0.661258, 0.359375 (0.679 sec)
78.14... logprob:  0.666379, 0.367188 (0.680 sec)
78.15... logprob:  0.689338, 0.398438 (0.688 sec)
78.16... logprob:  0.627071, 0.320312 (0.679 sec)
78.17... logprob:  0.638434, 0.335938 (0.681 sec)
78.18... logprob:  0.638270, 0.335938 (0.681 sec)
78.19... logprob:  0.633295, 0.328125 (0.686 sec)
78.20... logprob:  0.648445, 0.351562 (0.680 sec)
78.21... logprob:  0.643673, 0.343750 (0.677 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.630278, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.971377e-03 [6.160296e-09] 
Layer 'conv1' biases: 7.718851e-08 [1.362378e-10] 
Layer 'conv2' weights[0]: 7.958426e-03 [5.970122e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.837041e-10] 
Layer 'conv3' weights[0]: 7.956710e-03 [5.536453e-09] 
Layer 'conv3' biases: 9.651020e-07 [1.992818e-09] 
Layer 'conv4' weights[0]: 7.989229e-03 [5.808644e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.819698e-08] 
Layer 'conv5' weights[0]: 7.988670e-03 [1.257951e-07] 
Layer 'conv5' biases: 1.000013e+00 [1.378646e-07] 
Layer 'fc6' weights[0]: 7.585078e-03 [1.148662e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.086921e-08] 
Layer 'fc7' weights[0]: 7.775375e-03 [1.672656e-07] 
Layer 'fc7' biases: 9.998620e-01 [1.539166e-07] 
Layer 'fc8' weights[0]: 6.871628e-04 [9.465522e-06] 
Layer 'fc8' biases: 2.707616e-02 [1.029614e-04] 
Train error last 27 batches: 0.637170
-------------------------------------------------------
Not saving because 0.630278 > 0.627176 (56.15: -0.03%)
======================================================= (1.719 sec)
78.22... logprob:  0.630177, 0.320312 (0.675 sec)
78.23... logprob:  0.626179, 0.312500 (0.676 sec)
78.24... logprob:  0.586261, 0.242188 (0.676 sec)
78.25... logprob:  0.630319, 0.320312 (0.683 sec)
78.26... logprob:  0.671765, 0.390625 (0.676 sec)
78.27... logprob:  0.629456, 0.320312 (0.677 sec)
79.1... logprob:  0.677485, 0.398438 (0.678 sec)
79.2... logprob:  0.599515, 0.273438 (0.676 sec)
79.3... logprob:  0.653509, 0.359375 (0.677 sec)
79.4... logprob:  0.597560, 0.273438 (0.682 sec)
79.5... logprob:  0.590858, 0.265625 (0.681 sec)
79.6... logprob:  0.610787, 0.296875 (0.683 sec)
79.7... logprob:  0.644468, 0.343750 (0.676 sec)
79.8... logprob:  0.603189, 0.289062 (0.675 sec)
79.9... logprob:  0.639749, 0.335938 (0.679 sec)
79.10... logprob:  0.595589, 0.281250 (0.676 sec)
79.11... logprob:  0.641176, 0.335938 (0.676 sec)
79.12... logprob:  0.729191, 0.437500 (0.676 sec)
79.13... logprob:  0.661233, 0.359375 (0.676 sec)
79.14... logprob:  0.666360, 0.367188 (0.675 sec)
79.15... logprob:  0.689327, 0.398438 (0.676 sec)
79.16... logprob:  0.627071, 0.320312 (0.678 sec)
79.17... logprob:  0.638435, 0.335938 (0.678 sec)
79.18... logprob:  0.638269, 0.335938 (0.678 sec)
79.19... logprob:  0.633288, 0.328125 (0.678 sec)
79.20... logprob:  0.648446, 0.351562 (0.681 sec)
79.21... logprob:  0.643667, 0.343750 (0.678 sec)
79.22... logprob:  0.630156, 0.320312 (0.679 sec)
79.23... logprob:  0.626154, 0.312500 (0.677 sec)
79.24... logprob:  0.586200, 0.242188 (0.679 sec)
79.25... logprob:  0.630302, 0.320312 (0.682 sec)
79.26... logprob:  0.671776, 0.390625 (0.687 sec)
79.27... logprob:  0.629447, 0.320312 (0.675 sec)
80.1... logprob:  0.677494, 0.398438 (0.674 sec)
80.2... logprob:  0.599505, 0.273438 (0.676 sec)
80.3... logprob:  0.653509, 0.359375 (0.675 sec)
80.4... logprob:  0.597564, 0.273438 (0.676 sec)
80.5... logprob:  0.590869, 0.265625 (0.679 sec)
80.6... logprob:  0.610796, 0.296875 (0.679 sec)
80.7... logprob:  0.644460, 0.343750 (0.672 sec)
80.8... logprob:  0.603202, 0.289062 (0.675 sec)
80.9... logprob:  0.639736, 0.335938 (0.676 sec)
80.10... logprob:  0.595603, 0.281250 (0.675 sec)
80.11... logprob:  0.641156, 0.335938 (0.677 sec)
80.12... logprob:  0.729115, 0.437500 (0.675 sec)
80.13... logprob:  0.661207, 0.359375 (0.677 sec)
80.14... logprob:  0.666341, 0.367188 (0.689 sec)
80.15... logprob:  0.689315, 0.398438 (0.678 sec)
80.16... logprob:  0.627071, 0.320312 (0.677 sec)
80.17... logprob:  0.638437, 0.335938 (0.681 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.654218, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.971165e-03 [6.766928e-09] 
Layer 'conv1' biases: 7.935055e-08 [1.899975e-10] 
Layer 'conv2' weights[0]: 7.958211e-03 [7.752938e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.116013e-09] 
Layer 'conv3' weights[0]: 7.956509e-03 [7.158937e-09] 
Layer 'conv3' biases: 9.763372e-07 [3.255772e-09] 
Layer 'conv4' weights[0]: 7.989019e-03 [7.853586e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.197930e-08] 
Layer 'conv5' weights[0]: 7.988445e-03 [2.201554e-07] 
Layer 'conv5' biases: 1.000012e+00 [2.410923e-07] 
Layer 'fc6' weights[0]: 7.584887e-03 [1.953107e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.903099e-08] 
Layer 'fc7' weights[0]: 7.773340e-03 [2.807648e-07] 
Layer 'fc7' biases: 9.998627e-01 [2.684984e-07] 
Layer 'fc8' weights[0]: 7.287051e-04 [1.651226e-05] 
Layer 'fc8' biases: 2.891270e-02 [1.871349e-04] 
Train error last 27 batches: 0.637151
-------------------------------------------------------
Not saving because 0.654218 > 0.627176 (56.15: -0.03%)
======================================================= (1.707 sec)
80.18... logprob:  0.638268, 0.335938 (0.673 sec)
80.19... logprob:  0.633280, 0.328125 (0.675 sec)
80.20... logprob:  0.648446, 0.351562 (0.675 sec)
80.21... logprob:  0.643661, 0.343750 (0.672 sec)
80.22... logprob:  0.630136, 0.320312 (0.673 sec)
80.23... logprob:  0.626128, 0.312500 (0.678 sec)
80.24... logprob:  0.586139, 0.242188 (0.678 sec)
80.25... logprob:  0.630285, 0.320312 (0.675 sec)
80.26... logprob:  0.671788, 0.390625 (0.679 sec)
80.27... logprob:  0.629437, 0.320312 (0.679 sec)
81.1... logprob:  0.677502, 0.398438 (0.676 sec)
81.2... logprob:  0.599495, 0.273438 (0.683 sec)
81.3... logprob:  0.653509, 0.359375 (0.675 sec)
81.4... logprob:  0.597567, 0.273438 (0.676 sec)
81.5... logprob:  0.590880, 0.265625 (0.675 sec)
81.6... logprob:  0.610804, 0.296875 (0.675 sec)
81.7... logprob:  0.644452, 0.343750 (0.677 sec)
81.8... logprob:  0.603214, 0.289062 (0.681 sec)
81.9... logprob:  0.639723, 0.335938 (0.679 sec)
81.10... logprob:  0.595616, 0.281250 (0.688 sec)
81.11... logprob:  0.641136, 0.335938 (0.672 sec)
81.12... logprob:  0.729040, 0.437500 (0.676 sec)
81.13... logprob:  0.661182, 0.359375 (0.675 sec)
81.14... logprob:  0.666323, 0.367188 (0.679 sec)
81.15... logprob:  0.689303, 0.398438 (0.679 sec)
81.16... logprob:  0.627071, 0.320312 (0.677 sec)
81.17... logprob:  0.638438, 0.335938 (0.678 sec)
81.18... logprob:  0.638267, 0.335938 (0.680 sec)
81.19... logprob:  0.633273, 0.328125 (0.675 sec)
81.20... logprob:  0.648447, 0.351562 (0.678 sec)
81.21... logprob:  0.643656, 0.343750 (0.684 sec)
81.22... logprob:  0.630115, 0.320312 (0.678 sec)
81.23... logprob:  0.626102, 0.312500 (0.676 sec)
81.24... logprob:  0.586079, 0.242188 (0.672 sec)
81.25... logprob:  0.630268, 0.320312 (0.675 sec)
81.26... logprob:  0.671800, 0.390625 (0.675 sec)
81.27... logprob:  0.629428, 0.320312 (0.676 sec)
82.1... logprob:  0.677511, 0.398438 (0.678 sec)
82.2... logprob:  0.599486, 0.273438 (0.680 sec)
82.3... logprob:  0.653509, 0.359375 (0.681 sec)
82.4... logprob:  0.597570, 0.273438 (0.679 sec)
82.5... logprob:  0.590890, 0.265625 (0.679 sec)
82.6... logprob:  0.610813, 0.296875 (0.679 sec)
82.7... logprob:  0.644444, 0.343750 (0.676 sec)
82.8... logprob:  0.603226, 0.289062 (0.678 sec)
82.9... logprob:  0.639710, 0.335938 (0.676 sec)
82.10... logprob:  0.595629, 0.281250 (0.677 sec)
82.11... logprob:  0.641116, 0.335938 (0.675 sec)
82.12... logprob:  0.728964, 0.437500 (0.676 sec)
82.13... logprob:  0.661156, 0.359375 (0.678 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627742, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.970965e-03 [6.627170e-09] 
Layer 'conv1' biases: 8.138404e-08 [1.304143e-10] 
Layer 'conv2' weights[0]: 7.958021e-03 [6.110092e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.109757e-10] 
Layer 'conv3' weights[0]: 7.956307e-03 [5.563395e-09] 
Layer 'conv3' biases: 9.860833e-07 [2.060602e-09] 
Layer 'conv4' weights[0]: 7.988820e-03 [5.852638e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.856420e-08] 
Layer 'conv5' weights[0]: 7.988227e-03 [1.278018e-07] 
Layer 'conv5' biases: 1.000011e+00 [1.400267e-07] 
Layer 'fc6' weights[0]: 7.584673e-03 [1.175967e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.117144e-08] 
Layer 'fc7' weights[0]: 7.771384e-03 [1.720883e-07] 
Layer 'fc7' biases: 9.998633e-01 [1.588355e-07] 
Layer 'fc8' weights[0]: 7.886933e-04 [9.731241e-06] 
Layer 'fc8' biases: 3.096464e-02 [9.680753e-05] 
Train error last 27 batches: 0.637133
-------------------------------------------------------
Not saving because 0.627742 > 0.627176 (56.15: -0.03%)
======================================================= (1.712 sec)
82.14... logprob:  0.666304, 0.367188 (0.676 sec)
82.15... logprob:  0.689291, 0.398438 (0.675 sec)
82.16... logprob:  0.627071, 0.320312 (0.677 sec)
82.17... logprob:  0.638439, 0.335938 (0.675 sec)
82.18... logprob:  0.638266, 0.335938 (0.677 sec)
82.19... logprob:  0.633267, 0.328125 (0.682 sec)
82.20... logprob:  0.648448, 0.351562 (0.683 sec)
82.21... logprob:  0.643650, 0.343750 (0.682 sec)
82.22... logprob:  0.630096, 0.320312 (0.677 sec)
82.23... logprob:  0.626077, 0.312500 (0.678 sec)
82.24... logprob:  0.586019, 0.242188 (0.674 sec)
82.25... logprob:  0.630251, 0.320312 (0.675 sec)
82.26... logprob:  0.671811, 0.390625 (0.677 sec)
82.27... logprob:  0.629418, 0.320312 (0.674 sec)
83.1... logprob:  0.677520, 0.398438 (0.676 sec)
83.2... logprob:  0.599476, 0.273438 (0.678 sec)
83.3... logprob:  0.653508, 0.359375 (0.674 sec)
83.4... logprob:  0.597572, 0.273438 (0.676 sec)
83.5... logprob:  0.590900, 0.265625 (0.676 sec)
83.6... logprob:  0.610821, 0.296875 (0.675 sec)
83.7... logprob:  0.644437, 0.343750 (0.677 sec)
83.8... logprob:  0.603238, 0.289062 (0.679 sec)
83.9... logprob:  0.639697, 0.335938 (0.676 sec)
83.10... logprob:  0.595641, 0.281250 (0.677 sec)
83.11... logprob:  0.641096, 0.335938 (0.679 sec)
83.12... logprob:  0.728891, 0.437500 (0.681 sec)
83.13... logprob:  0.661132, 0.359375 (0.682 sec)
83.14... logprob:  0.666286, 0.367188 (0.682 sec)
83.15... logprob:  0.689279, 0.398438 (0.674 sec)
83.16... logprob:  0.627070, 0.320312 (0.676 sec)
83.17... logprob:  0.638441, 0.335938 (0.675 sec)
83.18... logprob:  0.638265, 0.335938 (0.678 sec)
83.19... logprob:  0.633260, 0.328125 (0.677 sec)
83.20... logprob:  0.648449, 0.351562 (0.677 sec)
83.21... logprob:  0.643645, 0.343750 (0.677 sec)
83.22... logprob:  0.630077, 0.320312 (0.676 sec)
83.23... logprob:  0.626053, 0.312500 (0.677 sec)
83.24... logprob:  0.585961, 0.242188 (0.678 sec)
83.25... logprob:  0.630234, 0.320312 (0.676 sec)
83.26... logprob:  0.671823, 0.390625 (0.677 sec)
83.27... logprob:  0.629409, 0.320312 (0.674 sec)
84.1... logprob:  0.677528, 0.398438 (0.676 sec)
84.2... logprob:  0.599466, 0.273438 (0.676 sec)
84.3... logprob:  0.653508, 0.359375 (0.675 sec)
84.4... logprob:  0.597575, 0.273438 (0.677 sec)
84.5... logprob:  0.590909, 0.265625 (0.679 sec)
84.6... logprob:  0.610829, 0.296875 (0.683 sec)
84.7... logprob:  0.644430, 0.343750 (0.682 sec)
84.8... logprob:  0.603250, 0.289062 (0.676 sec)
84.9... logprob:  0.639685, 0.335938 (0.677 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633894, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.970754e-03 [6.708206e-09] 
Layer 'conv1' biases: 8.391279e-08 [1.004420e-10] 
Layer 'conv2' weights[0]: 7.957829e-03 [5.666984e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.395321e-10] 
Layer 'conv3' weights[0]: 7.956096e-03 [5.819856e-09] 
Layer 'conv3' biases: 1.005049e-06 [2.015635e-09] 
Layer 'conv4' weights[0]: 7.988621e-03 [6.360728e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.038609e-08] 
Layer 'conv5' weights[0]: 7.988032e-03 [1.399592e-07] 
Layer 'conv5' biases: 1.000011e+00 [1.534318e-07] 
Layer 'fc6' weights[0]: 7.584470e-03 [1.256591e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.195643e-08] 
Layer 'fc7' weights[0]: 7.769370e-03 [1.797811e-07] 
Layer 'fc7' biases: 9.998632e-01 [1.653033e-07] 
Layer 'fc8' weights[0]: 7.836235e-04 [1.021077e-05] 
Layer 'fc8' biases: 3.211481e-02 [1.499616e-04] 
Train error last 27 batches: 0.637118
-------------------------------------------------------
Not saving because 0.633894 > 0.627176 (56.15: -0.03%)
======================================================= (1.718 sec)
84.10... logprob:  0.595654, 0.281250 (0.675 sec)
84.11... logprob:  0.641077, 0.335938 (0.679 sec)
84.12... logprob:  0.728818, 0.437500 (0.680 sec)
84.13... logprob:  0.661107, 0.359375 (0.677 sec)
84.14... logprob:  0.666267, 0.367188 (0.679 sec)
84.15... logprob:  0.689267, 0.398438 (0.677 sec)
84.16... logprob:  0.627070, 0.320312 (0.676 sec)
84.17... logprob:  0.638442, 0.335938 (0.677 sec)
84.18... logprob:  0.638264, 0.335938 (0.677 sec)
84.19... logprob:  0.633253, 0.328125 (0.677 sec)
84.20... logprob:  0.648450, 0.351562 (0.677 sec)
84.21... logprob:  0.643640, 0.343750 (0.678 sec)
84.22... logprob:  0.630057, 0.320312 (0.680 sec)
84.23... logprob:  0.626028, 0.312500 (0.680 sec)
84.24... logprob:  0.585903, 0.242188 (0.681 sec)
84.25... logprob:  0.630218, 0.320312 (0.677 sec)
84.26... logprob:  0.671834, 0.390625 (0.675 sec)
84.27... logprob:  0.629399, 0.320312 (0.676 sec)
85.1... logprob:  0.677536, 0.398438 (0.674 sec)
85.2... logprob:  0.599457, 0.273438 (0.678 sec)
85.3... logprob:  0.653508, 0.359375 (0.675 sec)
85.4... logprob:  0.597577, 0.273438 (0.674 sec)
85.5... logprob:  0.590919, 0.265625 (0.675 sec)
85.6... logprob:  0.610837, 0.296875 (0.677 sec)
85.7... logprob:  0.644422, 0.343750 (0.675 sec)
85.8... logprob:  0.603261, 0.289062 (0.677 sec)
85.9... logprob:  0.639673, 0.335938 (0.675 sec)
85.10... logprob:  0.595667, 0.281250 (0.678 sec)
85.11... logprob:  0.641057, 0.335938 (0.677 sec)
85.12... logprob:  0.728744, 0.437500 (0.675 sec)
85.13... logprob:  0.661082, 0.359375 (0.676 sec)
85.14... logprob:  0.666249, 0.367188 (0.678 sec)
85.15... logprob:  0.689255, 0.398438 (0.676 sec)
85.16... logprob:  0.627070, 0.320312 (0.680 sec)
85.17... logprob:  0.638443, 0.335938 (0.682 sec)
85.18... logprob:  0.638264, 0.335938 (0.685 sec)
85.19... logprob:  0.633247, 0.328125 (0.673 sec)
85.20... logprob:  0.648451, 0.351562 (0.679 sec)
85.21... logprob:  0.643635, 0.343750 (0.675 sec)
85.22... logprob:  0.630038, 0.320312 (0.677 sec)
85.23... logprob:  0.626003, 0.312500 (0.676 sec)
85.24... logprob:  0.585844, 0.242188 (0.675 sec)
85.25... logprob:  0.630201, 0.320312 (0.675 sec)
85.26... logprob:  0.671846, 0.390625 (0.677 sec)
85.27... logprob:  0.629390, 0.320312 (0.675 sec)
86.1... logprob:  0.677545, 0.398438 (0.675 sec)
86.2... logprob:  0.599447, 0.273438 (0.677 sec)
86.3... logprob:  0.653508, 0.359375 (0.675 sec)
86.4... logprob:  0.597580, 0.273438 (0.675 sec)
86.5... logprob:  0.590928, 0.265625 (0.677 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.687707, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.970559e-03 [7.556688e-09] 
Layer 'conv1' biases: 8.675313e-08 [1.454712e-10] 
Layer 'conv2' weights[0]: 7.957627e-03 [6.664943e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.193359e-10] 
Layer 'conv3' weights[0]: 7.955886e-03 [6.832989e-09] 
Layer 'conv3' biases: 1.029877e-06 [2.843136e-09] 
Layer 'conv4' weights[0]: 7.988410e-03 [7.487409e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.851147e-08] 
Layer 'conv5' weights[0]: 7.987828e-03 [1.955762e-07] 
Layer 'conv5' biases: 1.000011e+00 [2.143836e-07] 
Layer 'fc6' weights[0]: 7.584273e-03 [1.733098e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.679125e-08] 
Layer 'fc7' weights[0]: 7.767381e-03 [2.470574e-07] 
Layer 'fc7' biases: 9.998624e-01 [2.326105e-07] 
Layer 'fc8' weights[0]: 7.349423e-04 [1.435312e-05] 
Layer 'fc8' biases: 3.263592e-02 [2.117472e-04] 
Train error last 27 batches: 0.637100
-------------------------------------------------------
Not saving because 0.687707 > 0.627176 (56.15: -0.03%)
======================================================= (1.707 sec)
86.6... logprob:  0.610845, 0.296875 (0.681 sec)
86.7... logprob:  0.644415, 0.343750 (0.681 sec)
86.8... logprob:  0.603274, 0.289062 (0.683 sec)
86.9... logprob:  0.639661, 0.335938 (0.683 sec)
86.10... logprob:  0.595680, 0.281250 (0.678 sec)
86.11... logprob:  0.641038, 0.335938 (0.675 sec)
86.12... logprob:  0.728671, 0.437500 (0.676 sec)
86.13... logprob:  0.661057, 0.359375 (0.676 sec)
86.14... logprob:  0.666231, 0.367188 (0.675 sec)
86.15... logprob:  0.689243, 0.398438 (0.678 sec)
86.16... logprob:  0.627070, 0.320312 (0.679 sec)
86.17... logprob:  0.638445, 0.335938 (0.678 sec)
86.18... logprob:  0.638263, 0.335938 (0.675 sec)
86.19... logprob:  0.633241, 0.328125 (0.678 sec)
86.20... logprob:  0.648452, 0.351562 (0.682 sec)
86.21... logprob:  0.643630, 0.343750 (0.676 sec)
86.22... logprob:  0.630018, 0.320312 (0.677 sec)
86.23... logprob:  0.625979, 0.312500 (0.677 sec)
86.24... logprob:  0.585785, 0.242188 (0.680 sec)
86.25... logprob:  0.630185, 0.320312 (0.681 sec)
86.26... logprob:  0.671857, 0.390625 (0.679 sec)
86.27... logprob:  0.629381, 0.320312 (0.681 sec)
87.1... logprob:  0.677554, 0.398438 (0.679 sec)
87.2... logprob:  0.599437, 0.273438 (0.684 sec)
87.3... logprob:  0.653508, 0.359375 (0.676 sec)
87.4... logprob:  0.597583, 0.273438 (0.673 sec)
87.5... logprob:  0.590938, 0.265625 (0.675 sec)
87.6... logprob:  0.610853, 0.296875 (0.675 sec)
87.7... logprob:  0.644408, 0.343750 (0.676 sec)
87.8... logprob:  0.603285, 0.289062 (0.676 sec)
87.9... logprob:  0.639648, 0.335938 (0.677 sec)
87.10... logprob:  0.595693, 0.281250 (0.675 sec)
87.11... logprob:  0.641019, 0.335938 (0.674 sec)
87.12... logprob:  0.728597, 0.437500 (0.677 sec)
87.13... logprob:  0.661032, 0.359375 (0.676 sec)
87.14... logprob:  0.666212, 0.367188 (0.676 sec)
87.15... logprob:  0.689229, 0.398438 (0.676 sec)
87.16... logprob:  0.627070, 0.320312 (0.675 sec)
87.17... logprob:  0.638446, 0.335938 (0.675 sec)
87.18... logprob:  0.638262, 0.335938 (0.677 sec)
87.19... logprob:  0.633234, 0.328125 (0.676 sec)
87.20... logprob:  0.648453, 0.351562 (0.677 sec)
87.21... logprob:  0.643625, 0.343750 (0.682 sec)
87.22... logprob:  0.629999, 0.320312 (0.683 sec)
87.23... logprob:  0.625955, 0.312500 (0.681 sec)
87.24... logprob:  0.585728, 0.242188 (0.672 sec)
87.25... logprob:  0.630169, 0.320312 (0.676 sec)
87.26... logprob:  0.671869, 0.390625 (0.678 sec)
87.27... logprob:  0.629371, 0.320312 (0.681 sec)
88.1... logprob:  0.677563, 0.398438 (0.676 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633750, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.970345e-03 [6.232893e-09] 
Layer 'conv1' biases: 8.952963e-08 [5.788688e-11] 
Layer 'conv2' weights[0]: 7.957443e-03 [4.604760e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.127898e-10] 
Layer 'conv3' weights[0]: 7.955698e-03 [4.423096e-09] 
Layer 'conv3' biases: 1.053328e-06 [7.113074e-10] 
Layer 'conv4' weights[0]: 7.988217e-03 [4.465417e-09] 
Layer 'conv4' biases: 1.000001e+00 [4.817999e-09] 
Layer 'conv5' weights[0]: 7.987644e-03 [3.283327e-08] 
Layer 'conv5' biases: 1.000012e+00 [3.589751e-08] 
Layer 'fc6' weights[0]: 7.584080e-03 [4.832666e-09] 
Layer 'fc6' biases: 9.999999e-01 [2.734994e-09] 
Layer 'fc7' weights[0]: 7.765416e-03 [5.932940e-08] 
Layer 'fc7' biases: 9.998619e-01 [3.640699e-08] 
Layer 'fc8' weights[0]: 7.002547e-04 [2.261236e-06] 
Layer 'fc8' biases: 3.331975e-02 [5.162082e-05] 
Train error last 27 batches: 0.637081
-------------------------------------------------------
Not saving because 0.633750 > 0.627176 (56.15: -0.03%)
======================================================= (1.799 sec)
88.2... logprob:  0.599427, 0.273438 (0.677 sec)
88.3... logprob:  0.653508, 0.359375 (0.676 sec)
88.4... logprob:  0.597584, 0.273438 (0.675 sec)
88.5... logprob:  0.590946, 0.265625 (0.677 sec)
88.6... logprob:  0.610860, 0.296875 (0.677 sec)
88.7... logprob:  0.644401, 0.343750 (0.676 sec)
88.8... logprob:  0.603297, 0.289062 (0.677 sec)
88.9... logprob:  0.639637, 0.335938 (0.678 sec)
88.10... logprob:  0.595706, 0.281250 (0.678 sec)
88.11... logprob:  0.641000, 0.335938 (0.681 sec)
88.12... logprob:  0.728526, 0.437500 (0.682 sec)
88.13... logprob:  0.661008, 0.359375 (0.684 sec)
88.14... logprob:  0.666194, 0.367188 (0.677 sec)
88.15... logprob:  0.689217, 0.398438 (0.677 sec)
88.16... logprob:  0.627069, 0.320312 (0.677 sec)
88.17... logprob:  0.638447, 0.335938 (0.677 sec)
88.18... logprob:  0.638261, 0.335938 (0.677 sec)
88.19... logprob:  0.633228, 0.328125 (0.677 sec)
88.20... logprob:  0.648454, 0.351562 (0.677 sec)
88.21... logprob:  0.643620, 0.343750 (0.675 sec)
88.22... logprob:  0.629981, 0.320312 (0.675 sec)
88.23... logprob:  0.625931, 0.312500 (0.676 sec)
88.24... logprob:  0.585671, 0.242188 (0.676 sec)
88.25... logprob:  0.630153, 0.320312 (0.675 sec)
88.26... logprob:  0.671880, 0.390625 (0.676 sec)
88.27... logprob:  0.629362, 0.320312 (0.676 sec)
89.1... logprob:  0.677571, 0.398438 (0.675 sec)
89.2... logprob:  0.599417, 0.273438 (0.679 sec)
89.3... logprob:  0.653508, 0.359375 (0.697 sec)
89.4... logprob:  0.597586, 0.273438 (0.697 sec)
89.5... logprob:  0.590956, 0.265625 (0.686 sec)
89.6... logprob:  0.610868, 0.296875 (0.687 sec)
89.7... logprob:  0.644394, 0.343750 (0.681 sec)
89.8... logprob:  0.603308, 0.289062 (0.679 sec)
89.9... logprob:  0.639625, 0.335938 (0.677 sec)
89.10... logprob:  0.595719, 0.281250 (0.685 sec)
89.11... logprob:  0.640981, 0.335938 (0.689 sec)
89.12... logprob:  0.728454, 0.437500 (0.680 sec)
89.13... logprob:  0.660983, 0.359375 (0.677 sec)
89.14... logprob:  0.666175, 0.367188 (0.675 sec)
89.15... logprob:  0.689205, 0.398438 (0.676 sec)
89.16... logprob:  0.627069, 0.320312 (0.676 sec)
89.17... logprob:  0.638448, 0.335938 (0.676 sec)
89.18... logprob:  0.638260, 0.335938 (0.677 sec)
89.19... logprob:  0.633221, 0.328125 (0.678 sec)
89.20... logprob:  0.648455, 0.351562 (0.676 sec)
89.21... logprob:  0.643615, 0.343750 (0.675 sec)
89.22... logprob:  0.629962, 0.320312 (0.675 sec)
89.23... logprob:  0.625907, 0.312500 (0.677 sec)
89.24... logprob:  0.585614, 0.242188 (0.681 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.630204, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.970140e-03 [6.091325e-09] 
Layer 'conv1' biases: 9.218130e-08 [6.480595e-11] 
Layer 'conv2' weights[0]: 7.957249e-03 [4.832180e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.888927e-10] 
Layer 'conv3' weights[0]: 7.955502e-03 [4.822814e-09] 
Layer 'conv3' biases: 1.075234e-06 [1.262550e-09] 
Layer 'conv4' weights[0]: 7.988015e-03 [5.094141e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.208332e-08] 
Layer 'conv5' weights[0]: 7.987458e-03 [8.229983e-08] 
Layer 'conv5' biases: 1.000012e+00 [9.012192e-08] 
Layer 'fc6' weights[0]: 7.583877e-03 [8.157524e-09] 
Layer 'fc6' biases: 9.999999e-01 [7.022439e-09] 
Layer 'fc7' weights[0]: 7.763419e-03 [1.134059e-07] 
Layer 'fc7' biases: 9.998617e-01 [9.562374e-08] 
Layer 'fc8' weights[0]: 6.805951e-04 [5.924640e-06] 
Layer 'fc8' biases: 3.419155e-02 [1.128972e-04] 
Train error last 27 batches: 0.637063
-------------------------------------------------------
Not saving because 0.630204 > 0.627176 (56.15: -0.03%)
======================================================= (1.756 sec)
89.25... logprob:  0.630137, 0.320312 (0.679 sec)
89.26... logprob:  0.671892, 0.390625 (0.676 sec)
89.27... logprob:  0.629353, 0.320312 (0.675 sec)
90.1... logprob:  0.677580, 0.398438 (0.676 sec)
90.2... logprob:  0.599407, 0.273438 (0.677 sec)
90.3... logprob:  0.653508, 0.359375 (0.676 sec)
90.4... logprob:  0.597588, 0.273438 (0.673 sec)
90.5... logprob:  0.590964, 0.265625 (0.676 sec)
90.6... logprob:  0.610875, 0.296875 (0.679 sec)
90.7... logprob:  0.644388, 0.343750 (0.677 sec)
90.8... logprob:  0.603320, 0.289062 (0.678 sec)
90.9... logprob:  0.639614, 0.335938 (0.680 sec)
90.10... logprob:  0.595731, 0.281250 (0.677 sec)
90.11... logprob:  0.640963, 0.335938 (0.674 sec)
90.12... logprob:  0.728383, 0.437500 (0.676 sec)
90.13... logprob:  0.660959, 0.359375 (0.677 sec)
90.14... logprob:  0.666157, 0.367188 (0.678 sec)
90.15... logprob:  0.689192, 0.398438 (0.682 sec)
90.16... logprob:  0.627069, 0.320312 (0.682 sec)
90.17... logprob:  0.638450, 0.335938 (0.686 sec)
90.18... logprob:  0.638260, 0.335938 (0.676 sec)
90.19... logprob:  0.633216, 0.328125 (0.681 sec)
90.20... logprob:  0.648457, 0.351562 (0.676 sec)
90.21... logprob:  0.643611, 0.343750 (0.678 sec)
90.22... logprob:  0.629944, 0.320312 (0.680 sec)
90.23... logprob:  0.625884, 0.312500 (0.678 sec)
90.24... logprob:  0.585558, 0.242188 (0.678 sec)
90.25... logprob:  0.630121, 0.320312 (0.679 sec)
90.26... logprob:  0.671903, 0.390625 (0.680 sec)
90.27... logprob:  0.629344, 0.320312 (0.678 sec)
91.1... logprob:  0.677588, 0.398438 (0.675 sec)
91.2... logprob:  0.599397, 0.273438 (0.676 sec)
91.3... logprob:  0.653508, 0.359375 (0.675 sec)
91.4... logprob:  0.597589, 0.273438 (0.674 sec)
91.5... logprob:  0.590973, 0.265625 (0.677 sec)
91.6... logprob:  0.610883, 0.296875 (0.676 sec)
91.7... logprob:  0.644381, 0.343750 (0.679 sec)
91.8... logprob:  0.603332, 0.289062 (0.680 sec)
91.9... logprob:  0.639602, 0.335938 (0.682 sec)
91.10... logprob:  0.595744, 0.281250 (0.687 sec)
91.11... logprob:  0.640944, 0.335938 (0.679 sec)
91.12... logprob:  0.728311, 0.437500 (0.680 sec)
91.13... logprob:  0.660935, 0.359375 (0.677 sec)
91.14... logprob:  0.666139, 0.367188 (0.677 sec)
91.15... logprob:  0.689179, 0.398438 (0.678 sec)
91.16... logprob:  0.627069, 0.320312 (0.672 sec)
91.17... logprob:  0.638451, 0.335938 (0.680 sec)
91.18... logprob:  0.638259, 0.335938 (0.678 sec)
91.19... logprob:  0.633210, 0.328125 (0.676 sec)
91.20... logprob:  0.648458, 0.351562 (0.679 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.653154, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.969926e-03 [6.380900e-09] 
Layer 'conv1' biases: 9.459627e-08 [1.489080e-10] 
Layer 'conv2' weights[0]: 7.957054e-03 [6.334211e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.849684e-10] 
Layer 'conv3' weights[0]: 7.955300e-03 [5.858049e-09] 
Layer 'conv3' biases: 1.093416e-06 [2.284344e-09] 
Layer 'conv4' weights[0]: 7.987807e-03 [6.168553e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.101923e-08] 
Layer 'conv5' weights[0]: 7.987258e-03 [1.438230e-07] 
Layer 'conv5' biases: 1.000012e+00 [1.576078e-07] 
Layer 'fc6' weights[0]: 7.583671e-03 [1.320096e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.269516e-08] 
Layer 'fc7' weights[0]: 7.761482e-03 [1.923777e-07] 
Layer 'fc7' biases: 9.998617e-01 [1.792477e-07] 
Layer 'fc8' weights[0]: 6.897188e-04 [1.096433e-05] 
Layer 'fc8' biases: 3.550455e-02 [1.257921e-04] 
Train error last 27 batches: 0.637049
-------------------------------------------------------
Not saving because 0.653154 > 0.627176 (56.15: -0.03%)
======================================================= (1.714 sec)
91.21... logprob:  0.643606, 0.343750 (0.677 sec)
91.22... logprob:  0.629926, 0.320312 (0.676 sec)
91.23... logprob:  0.625860, 0.312500 (0.677 sec)
91.24... logprob:  0.585501, 0.242188 (0.676 sec)
91.25... logprob:  0.630105, 0.320312 (0.678 sec)
91.26... logprob:  0.671915, 0.390625 (0.682 sec)
91.27... logprob:  0.629334, 0.320312 (0.679 sec)
92.1... logprob:  0.677597, 0.398438 (0.684 sec)
92.2... logprob:  0.599387, 0.273438 (0.677 sec)
92.3... logprob:  0.653508, 0.359375 (0.677 sec)
92.4... logprob:  0.597591, 0.273438 (0.675 sec)
92.5... logprob:  0.590982, 0.265625 (0.674 sec)
92.6... logprob:  0.610891, 0.296875 (0.677 sec)
92.7... logprob:  0.644374, 0.343750 (0.676 sec)
92.8... logprob:  0.603343, 0.289062 (0.676 sec)
92.9... logprob:  0.639591, 0.335938 (0.677 sec)
92.10... logprob:  0.595757, 0.281250 (0.677 sec)
92.11... logprob:  0.640926, 0.335938 (0.676 sec)
92.12... logprob:  0.728240, 0.437500 (0.677 sec)
92.13... logprob:  0.660910, 0.359375 (0.678 sec)
92.14... logprob:  0.666120, 0.367188 (0.675 sec)
92.15... logprob:  0.689166, 0.398438 (0.684 sec)
92.16... logprob:  0.627069, 0.320312 (0.677 sec)
92.17... logprob:  0.638452, 0.335938 (0.679 sec)
92.18... logprob:  0.638258, 0.335938 (0.683 sec)
92.19... logprob:  0.633204, 0.328125 (0.685 sec)
92.20... logprob:  0.648459, 0.351562 (0.708 sec)
92.21... logprob:  0.643601, 0.343750 (0.687 sec)
92.22... logprob:  0.629908, 0.320312 (0.679 sec)
92.23... logprob:  0.625837, 0.312500 (0.678 sec)
92.24... logprob:  0.585446, 0.242188 (0.675 sec)
92.25... logprob:  0.630089, 0.320312 (0.676 sec)
92.26... logprob:  0.671926, 0.390625 (0.676 sec)
92.27... logprob:  0.629325, 0.320312 (0.677 sec)
93.1... logprob:  0.677606, 0.398438 (0.674 sec)
93.2... logprob:  0.599376, 0.273438 (0.676 sec)
93.3... logprob:  0.653508, 0.359375 (0.673 sec)
93.4... logprob:  0.597592, 0.273438 (0.676 sec)
93.5... logprob:  0.590989, 0.265625 (0.675 sec)
93.6... logprob:  0.610897, 0.296875 (0.675 sec)
93.7... logprob:  0.644368, 0.343750 (0.674 sec)
93.8... logprob:  0.603354, 0.289062 (0.674 sec)
93.9... logprob:  0.639580, 0.335938 (0.674 sec)
93.10... logprob:  0.595769, 0.281250 (0.679 sec)
93.11... logprob:  0.640908, 0.335938 (0.677 sec)
93.12... logprob:  0.728171, 0.437500 (0.681 sec)
93.13... logprob:  0.660887, 0.359375 (0.682 sec)
93.14... logprob:  0.666103, 0.367188 (0.697 sec)
93.15... logprob:  0.689154, 0.398438 (0.679 sec)
93.16... logprob:  0.627069, 0.320312 (0.678 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627306, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.969726e-03 [7.087068e-09] 
Layer 'conv1' biases: 9.679246e-08 [2.061328e-10] 
Layer 'conv2' weights[0]: 7.956856e-03 [8.005585e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.170919e-09] 
Layer 'conv3' weights[0]: 7.955115e-03 [7.335421e-09] 
Layer 'conv3' biases: 1.107466e-06 [3.405677e-09] 
Layer 'conv4' weights[0]: 7.987609e-03 [7.969366e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.242954e-08] 
Layer 'conv5' weights[0]: 7.987069e-03 [2.214816e-07] 
Layer 'conv5' biases: 1.000011e+00 [2.425697e-07] 
Layer 'fc6' weights[0]: 7.583475e-03 [1.996502e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.957127e-08] 
Layer 'fc7' weights[0]: 7.759436e-03 [2.877019e-07] 
Layer 'fc7' biases: 9.998621e-01 [2.755835e-07] 
Layer 'fc8' weights[0]: 7.356183e-04 [1.684837e-05] 
Layer 'fc8' biases: 3.736447e-02 [1.953272e-04] 
Train error last 27 batches: 0.637031
-------------------------------------------------------
Not saving because 0.627306 > 0.627176 (56.15: -0.03%)
======================================================= (1.707 sec)
93.17... logprob:  0.638453, 0.335938 (0.673 sec)
93.18... logprob:  0.638258, 0.335938 (0.674 sec)
93.19... logprob:  0.633198, 0.328125 (0.674 sec)
93.20... logprob:  0.648460, 0.351562 (0.680 sec)
93.21... logprob:  0.643597, 0.343750 (0.680 sec)
93.22... logprob:  0.629891, 0.320312 (0.684 sec)
93.23... logprob:  0.625815, 0.312500 (0.681 sec)
93.24... logprob:  0.585391, 0.242188 (0.674 sec)
93.25... logprob:  0.630074, 0.320312 (0.676 sec)
93.26... logprob:  0.671937, 0.390625 (0.678 sec)
93.27... logprob:  0.629316, 0.320312 (0.675 sec)
94.1... logprob:  0.677614, 0.398438 (0.675 sec)
94.2... logprob:  0.599367, 0.273438 (0.679 sec)
94.3... logprob:  0.653508, 0.359375 (0.680 sec)
94.4... logprob:  0.597594, 0.273438 (0.677 sec)
94.5... logprob:  0.590998, 0.265625 (0.680 sec)
94.6... logprob:  0.610905, 0.296875 (0.679 sec)
94.7... logprob:  0.644361, 0.343750 (0.678 sec)
94.8... logprob:  0.603365, 0.289062 (0.681 sec)
94.9... logprob:  0.639568, 0.335938 (0.681 sec)
94.10... logprob:  0.595782, 0.281250 (0.684 sec)
94.11... logprob:  0.640890, 0.335938 (0.686 sec)
94.12... logprob:  0.728101, 0.437500 (0.676 sec)
94.13... logprob:  0.660863, 0.359375 (0.676 sec)
94.14... logprob:  0.666084, 0.367188 (0.680 sec)
94.15... logprob:  0.689140, 0.398438 (0.681 sec)
94.16... logprob:  0.627068, 0.320312 (0.683 sec)
94.17... logprob:  0.638455, 0.335938 (0.690 sec)
94.18... logprob:  0.638257, 0.335938 (0.691 sec)
94.19... logprob:  0.633192, 0.328125 (0.696 sec)
94.20... logprob:  0.648461, 0.351562 (0.694 sec)
94.21... logprob:  0.643593, 0.343750 (0.694 sec)
94.22... logprob:  0.629873, 0.320312 (0.685 sec)
94.23... logprob:  0.625792, 0.312500 (0.686 sec)
94.24... logprob:  0.585336, 0.242188 (0.676 sec)
94.25... logprob:  0.630059, 0.320312 (0.683 sec)
94.26... logprob:  0.671948, 0.390625 (0.685 sec)
94.27... logprob:  0.629307, 0.320312 (0.682 sec)
95.1... logprob:  0.677623, 0.398438 (0.680 sec)
95.2... logprob:  0.599357, 0.273438 (0.677 sec)
95.3... logprob:  0.653509, 0.359375 (0.677 sec)
95.4... logprob:  0.597595, 0.273438 (0.675 sec)
95.5... logprob:  0.591006, 0.265625 (0.680 sec)
95.6... logprob:  0.610912, 0.296875 (0.678 sec)
95.7... logprob:  0.644354, 0.343750 (0.681 sec)
95.8... logprob:  0.603376, 0.289062 (0.677 sec)
95.9... logprob:  0.639557, 0.335938 (0.678 sec)
95.10... logprob:  0.595795, 0.281250 (0.683 sec)
95.11... logprob:  0.640872, 0.335938 (0.684 sec)
95.12... logprob:  0.728031, 0.437500 (0.678 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.634518, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.969530e-03 [6.387447e-09] 
Layer 'conv1' biases: 9.892983e-08 [8.912840e-11] 
Layer 'conv2' weights[0]: 7.956670e-03 [5.188850e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.257748e-10] 
Layer 'conv3' weights[0]: 7.954931e-03 [4.705525e-09] 
Layer 'conv3' biases: 1.121018e-06 [1.214718e-09] 
Layer 'conv4' weights[0]: 7.987412e-03 [4.742598e-09] 
Layer 'conv4' biases: 1.000001e+00 [8.803915e-09] 
Layer 'conv5' weights[0]: 7.986836e-03 [6.017188e-08] 
Layer 'conv5' biases: 1.000010e+00 [6.567546e-08] 
Layer 'fc6' weights[0]: 7.583284e-03 [6.678315e-09] 
Layer 'fc6' biases: 9.999999e-01 [5.431548e-09] 
Layer 'fc7' weights[0]: 7.757463e-03 [9.522728e-08] 
Layer 'fc7' biases: 9.998631e-01 [7.829550e-08] 
Layer 'fc8' weights[0]: 7.863676e-04 [4.742078e-06] 
Layer 'fc8' biases: 3.925271e-02 [3.718635e-05] 
Train error last 27 batches: 0.637015
-------------------------------------------------------
Not saving because 0.634518 > 0.627176 (56.15: -0.03%)
======================================================= (1.754 sec)
95.13... logprob:  0.660839, 0.359375 (0.682 sec)
95.14... logprob:  0.666066, 0.367188 (0.677 sec)
95.15... logprob:  0.689128, 0.398438 (0.679 sec)
95.16... logprob:  0.627068, 0.320312 (0.680 sec)
95.17... logprob:  0.638456, 0.335938 (0.680 sec)
95.18... logprob:  0.638256, 0.335938 (0.681 sec)
95.19... logprob:  0.633186, 0.328125 (0.680 sec)
95.20... logprob:  0.648462, 0.351562 (0.684 sec)
95.21... logprob:  0.643588, 0.343750 (0.687 sec)
95.22... logprob:  0.629855, 0.320312 (0.676 sec)
95.23... logprob:  0.625770, 0.312500 (0.678 sec)
95.24... logprob:  0.585281, 0.242188 (0.674 sec)
95.25... logprob:  0.630043, 0.320312 (0.677 sec)
95.26... logprob:  0.671960, 0.390625 (0.679 sec)
95.27... logprob:  0.629298, 0.320312 (0.677 sec)
96.1... logprob:  0.677632, 0.398438 (0.676 sec)
96.2... logprob:  0.599346, 0.273438 (0.678 sec)
96.3... logprob:  0.653509, 0.359375 (0.676 sec)
96.4... logprob:  0.597596, 0.273438 (0.678 sec)
96.5... logprob:  0.591013, 0.265625 (0.680 sec)
96.6... logprob:  0.610919, 0.296875 (0.678 sec)
96.7... logprob:  0.644348, 0.343750 (0.676 sec)
96.8... logprob:  0.603387, 0.289062 (0.680 sec)
96.9... logprob:  0.639546, 0.335938 (0.675 sec)
96.10... logprob:  0.595807, 0.281250 (0.689 sec)
96.11... logprob:  0.640855, 0.335938 (0.688 sec)
96.12... logprob:  0.727961, 0.437500 (0.691 sec)
96.13... logprob:  0.660815, 0.359375 (0.689 sec)
96.14... logprob:  0.666048, 0.367188 (0.689 sec)
96.15... logprob:  0.689115, 0.398438 (0.683 sec)
96.16... logprob:  0.627068, 0.320312 (0.686 sec)
96.17... logprob:  0.638457, 0.335938 (0.695 sec)
96.18... logprob:  0.638256, 0.335938 (0.684 sec)
96.19... logprob:  0.633181, 0.328125 (0.685 sec)
96.20... logprob:  0.648464, 0.351562 (0.678 sec)
96.21... logprob:  0.643584, 0.343750 (0.685 sec)
96.22... logprob:  0.629838, 0.320312 (0.678 sec)
96.23... logprob:  0.625747, 0.312500 (0.679 sec)
96.24... logprob:  0.585227, 0.242188 (0.680 sec)
96.25... logprob:  0.630028, 0.320312 (0.681 sec)
96.26... logprob:  0.671971, 0.390625 (0.685 sec)
96.27... logprob:  0.629289, 0.320312 (0.674 sec)
97.1... logprob:  0.677641, 0.398438 (0.676 sec)
97.2... logprob:  0.599336, 0.273438 (0.682 sec)
97.3... logprob:  0.653509, 0.359375 (0.674 sec)
97.4... logprob:  0.597597, 0.273438 (0.675 sec)
97.5... logprob:  0.591021, 0.265625 (0.676 sec)
97.6... logprob:  0.610926, 0.296875 (0.682 sec)
97.7... logprob:  0.644342, 0.343750 (0.676 sec)
97.8... logprob:  0.603398, 0.289062 (0.680 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.694780, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.969331e-03 [7.214863e-09] 
Layer 'conv1' biases: 1.016309e-07 [1.304047e-10] 
Layer 'conv2' weights[0]: 7.956479e-03 [6.307201e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.333609e-10] 
Layer 'conv3' weights[0]: 7.954744e-03 [6.464908e-09] 
Layer 'conv3' biases: 1.143130e-06 [2.593684e-09] 
Layer 'conv4' weights[0]: 7.987223e-03 [7.112788e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.602436e-08] 
Layer 'conv5' weights[0]: 7.986659e-03 [1.776966e-07] 
Layer 'conv5' biases: 1.000010e+00 [1.947364e-07] 
Layer 'fc6' weights[0]: 7.583081e-03 [1.604123e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.552973e-08] 
Layer 'fc7' weights[0]: 7.755485e-03 [2.290118e-07] 
Layer 'fc7' biases: 9.998627e-01 [2.144283e-07] 
Layer 'fc8' weights[0]: 7.628118e-04 [1.317192e-05] 
Layer 'fc8' biases: 4.009321e-02 [1.932247e-04] 
Train error last 27 batches: 0.637001
-------------------------------------------------------
Not saving because 0.694780 > 0.627176 (56.15: -0.03%)
======================================================= (1.719 sec)
97.9... logprob:  0.639536, 0.335938 (0.675 sec)
97.10... logprob:  0.595820, 0.281250 (0.677 sec)
97.11... logprob:  0.640838, 0.335938 (0.676 sec)
97.12... logprob:  0.727892, 0.437500 (0.680 sec)
97.13... logprob:  0.660792, 0.359375 (0.680 sec)
97.14... logprob:  0.666030, 0.367188 (0.678 sec)
97.15... logprob:  0.689101, 0.398438 (0.679 sec)
97.16... logprob:  0.627068, 0.320312 (0.678 sec)
97.17... logprob:  0.638458, 0.335938 (0.678 sec)
97.18... logprob:  0.638255, 0.335938 (0.677 sec)
97.19... logprob:  0.633175, 0.328125 (0.683 sec)
97.20... logprob:  0.648465, 0.351562 (0.675 sec)
97.21... logprob:  0.643580, 0.343750 (0.678 sec)
97.22... logprob:  0.629821, 0.320312 (0.684 sec)
97.23... logprob:  0.625726, 0.312500 (0.675 sec)
97.24... logprob:  0.585174, 0.242188 (0.696 sec)
97.25... logprob:  0.630013, 0.320312 (0.676 sec)
97.26... logprob:  0.671982, 0.390625 (0.681 sec)
97.27... logprob:  0.629281, 0.320312 (0.679 sec)
98.1... logprob:  0.677649, 0.398438 (0.684 sec)
98.2... logprob:  0.599326, 0.273438 (0.678 sec)
98.3... logprob:  0.653509, 0.359375 (0.677 sec)
98.4... logprob:  0.597597, 0.273438 (0.677 sec)
98.5... logprob:  0.591028, 0.265625 (0.677 sec)
98.6... logprob:  0.610932, 0.296875 (0.678 sec)
98.7... logprob:  0.644336, 0.343750 (0.678 sec)
98.8... logprob:  0.603409, 0.289062 (0.677 sec)
98.9... logprob:  0.639526, 0.335938 (0.679 sec)
98.10... logprob:  0.595832, 0.281250 (0.682 sec)
98.11... logprob:  0.640821, 0.335938 (0.681 sec)
98.12... logprob:  0.727826, 0.437500 (0.685 sec)
98.13... logprob:  0.660769, 0.359375 (0.677 sec)
98.14... logprob:  0.666013, 0.367188 (0.677 sec)
98.15... logprob:  0.689089, 0.398438 (0.678 sec)
98.16... logprob:  0.627067, 0.320312 (0.677 sec)
98.17... logprob:  0.638459, 0.335938 (0.679 sec)
98.18... logprob:  0.638254, 0.335938 (0.683 sec)
98.19... logprob:  0.633170, 0.328125 (0.683 sec)
98.20... logprob:  0.648467, 0.351562 (0.682 sec)
98.21... logprob:  0.643576, 0.343750 (0.687 sec)
98.22... logprob:  0.629804, 0.320312 (0.683 sec)
98.23... logprob:  0.625704, 0.312500 (0.682 sec)
98.24... logprob:  0.585120, 0.242188 (0.683 sec)
98.25... logprob:  0.629998, 0.320312 (0.682 sec)
98.26... logprob:  0.671993, 0.390625 (0.681 sec)
98.27... logprob:  0.629272, 0.320312 (0.680 sec)
99.1... logprob:  0.677658, 0.398438 (0.684 sec)
99.2... logprob:  0.599316, 0.273438 (0.683 sec)
99.3... logprob:  0.653509, 0.359375 (0.682 sec)
99.4... logprob:  0.597599, 0.273438 (0.685 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633077, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.969135e-03 [6.710927e-09] 
Layer 'conv1' biases: 1.045535e-07 [1.080929e-10] 
Layer 'conv2' weights[0]: 7.956267e-03 [5.610207e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.218438e-10] 
Layer 'conv3' weights[0]: 7.954550e-03 [5.723589e-09] 
Layer 'conv3' biases: 1.168419e-06 [1.956194e-09] 
Layer 'conv4' weights[0]: 7.987036e-03 [6.125411e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.884773e-08] 
Layer 'conv5' weights[0]: 7.986472e-03 [1.284122e-07] 
Layer 'conv5' biases: 1.000011e+00 [1.406722e-07] 
Layer 'fc6' weights[0]: 7.582887e-03 [1.188298e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.122688e-08] 
Layer 'fc7' weights[0]: 7.753547e-03 [1.690030e-07] 
Layer 'fc7' biases: 9.998618e-01 [1.545006e-07] 
Layer 'fc8' weights[0]: 7.126204e-04 [9.477081e-06] 
Layer 'fc8' biases: 4.051099e-02 [1.501195e-04] 
Train error last 27 batches: 0.636983
-------------------------------------------------------
Not saving because 0.633077 > 0.627176 (56.15: -0.03%)
======================================================= (1.734 sec)
99.5... logprob:  0.591036, 0.265625 (0.681 sec)
99.6... logprob:  0.610940, 0.296875 (0.683 sec)
99.7... logprob:  0.644330, 0.343750 (0.684 sec)
99.8... logprob:  0.603420, 0.289062 (0.682 sec)
99.9... logprob:  0.639515, 0.335938 (0.687 sec)
99.10... logprob:  0.595845, 0.281250 (0.685 sec)
99.11... logprob:  0.640803, 0.335938 (0.691 sec)
99.12... logprob:  0.727756, 0.437500 (0.692 sec)
99.13... logprob:  0.660745, 0.359375 (0.694 sec)
99.14... logprob:  0.665994, 0.367188 (0.693 sec)
99.15... logprob:  0.689075, 0.398438 (0.689 sec)
99.16... logprob:  0.627067, 0.320312 (0.682 sec)
99.17... logprob:  0.638460, 0.335938 (0.684 sec)
99.18... logprob:  0.638254, 0.335938 (0.690 sec)
99.19... logprob:  0.633165, 0.328125 (0.688 sec)
99.20... logprob:  0.648468, 0.351562 (0.688 sec)
99.21... logprob:  0.643572, 0.343750 (0.682 sec)
99.22... logprob:  0.629788, 0.320312 (0.680 sec)
99.23... logprob:  0.625682, 0.312500 (0.682 sec)
99.24... logprob:  0.585067, 0.242188 (0.682 sec)
99.25... logprob:  0.629984, 0.320312 (0.686 sec)
99.26... logprob:  0.672005, 0.390625 (0.682 sec)
99.27... logprob:  0.629263, 0.320312 (0.682 sec)
100.1... logprob:  0.677667, 0.398438 (0.684 sec)
100.2... logprob:  0.599305, 0.273438 (0.683 sec)
100.3... logprob:  0.653509, 0.359375 (0.685 sec)
100.4... logprob:  0.597599, 0.273438 (0.683 sec)
100.5... logprob:  0.591043, 0.265625 (0.690 sec)
100.6... logprob:  0.610946, 0.296875 (0.691 sec)
100.7... logprob:  0.644324, 0.343750 (0.687 sec)
100.8... logprob:  0.603431, 0.289062 (0.681 sec)
100.9... logprob:  0.639505, 0.335938 (0.683 sec)
100.10... logprob:  0.595857, 0.281250 (0.683 sec)
100.11... logprob:  0.640786, 0.335938 (0.685 sec)
100.12... logprob:  0.727690, 0.437500 (0.689 sec)
100.13... logprob:  0.660722, 0.359375 (0.688 sec)
100.14... logprob:  0.665977, 0.367188 (0.686 sec)
100.15... logprob:  0.689062, 0.398438 (0.693 sec)
100.16... logprob:  0.627067, 0.320312 (0.683 sec)
100.17... logprob:  0.638461, 0.335938 (0.683 sec)
100.18... logprob:  0.638253, 0.335938 (0.685 sec)
100.19... logprob:  0.633159, 0.328125 (0.682 sec)
100.20... logprob:  0.648469, 0.351562 (0.683 sec)
100.21... logprob:  0.643568, 0.343750 (0.683 sec)
100.22... logprob:  0.629771, 0.320312 (0.686 sec)
100.23... logprob:  0.625661, 0.312500 (0.682 sec)
100.24... logprob:  0.585014, 0.242188 (0.689 sec)
100.25... logprob:  0.629969, 0.320312 (0.685 sec)
100.26... logprob:  0.672015, 0.390625 (0.686 sec)
100.27... logprob:  0.629255, 0.320312 (0.679 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.628956, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.968922e-03 [6.368992e-09] 
Layer 'conv1' biases: 1.073121e-07 [7.150584e-11] 
Layer 'conv2' weights[0]: 7.956089e-03 [4.873008e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.839784e-10] 
Layer 'conv3' weights[0]: 7.954338e-03 [4.920405e-09] 
Layer 'conv3' biases: 1.190634e-06 [1.294168e-09] 
Layer 'conv4' weights[0]: 7.986833e-03 [5.167272e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.177210e-08] 
Layer 'conv5' weights[0]: 7.986281e-03 [7.961965e-08] 
Layer 'conv5' biases: 1.000011e+00 [8.718000e-08] 
Layer 'fc6' weights[0]: 7.582703e-03 [8.084322e-09] 
Layer 'fc6' biases: 9.999999e-01 [6.944105e-09] 
Layer 'fc7' weights[0]: 7.751566e-03 [1.126820e-07] 
Layer 'fc7' biases: 9.998616e-01 [9.487339e-08] 
Layer 'fc8' weights[0]: 6.906505e-04 [5.819454e-06] 
Layer 'fc8' biases: 4.132718e-02 [1.057261e-04] 
Train error last 27 batches: 0.636966
-------------------------------------------------------
Not saving because 0.628956 > 0.627176 (56.15: -0.03%)
======================================================= (1.763 sec)
101.1... logprob:  0.677675, 0.398438 (0.680 sec)
101.2... logprob:  0.599295, 0.273438 (0.683 sec)
101.3... logprob:  0.653510, 0.359375 (0.682 sec)
101.4... logprob:  0.597600, 0.273438 (0.683 sec)
101.5... logprob:  0.591050, 0.265625 (0.684 sec)
101.6... logprob:  0.610953, 0.296875 (0.683 sec)
101.7... logprob:  0.644318, 0.343750 (0.685 sec)
101.8... logprob:  0.603441, 0.289062 (0.683 sec)
101.9... logprob:  0.639494, 0.335938 (0.685 sec)
101.10... logprob:  0.595869, 0.281250 (0.681 sec)
101.11... logprob:  0.640769, 0.335938 (0.682 sec)
101.12... logprob:  0.727621, 0.437500 (0.682 sec)
101.13... logprob:  0.660699, 0.359375 (0.685 sec)
101.14... logprob:  0.665958, 0.367188 (0.682 sec)
101.15... logprob:  0.689049, 0.398438 (0.683 sec)
101.16... logprob:  0.627067, 0.320312 (0.683 sec)
101.17... logprob:  0.638462, 0.335938 (0.684 sec)
101.18... logprob:  0.638253, 0.335938 (0.682 sec)
101.19... logprob:  0.633154, 0.328125 (0.683 sec)
101.20... logprob:  0.648471, 0.351562 (0.685 sec)
101.21... logprob:  0.643564, 0.343750 (0.683 sec)
101.22... logprob:  0.629755, 0.320312 (0.681 sec)
101.23... logprob:  0.625639, 0.312500 (0.677 sec)
101.24... logprob:  0.584961, 0.242188 (0.681 sec)
101.25... logprob:  0.629955, 0.320312 (0.681 sec)
101.26... logprob:  0.672027, 0.390625 (0.682 sec)
101.27... logprob:  0.629246, 0.320312 (0.678 sec)
102.1... logprob:  0.677684, 0.398438 (0.676 sec)
102.2... logprob:  0.599285, 0.273438 (0.681 sec)
102.3... logprob:  0.653510, 0.359375 (0.678 sec)
102.4... logprob:  0.597601, 0.273438 (0.674 sec)
102.5... logprob:  0.591057, 0.265625 (0.679 sec)
102.6... logprob:  0.610960, 0.296875 (0.681 sec)
102.7... logprob:  0.644312, 0.343750 (0.678 sec)
102.8... logprob:  0.603453, 0.289062 (0.677 sec)
102.9... logprob:  0.639484, 0.335938 (0.677 sec)
102.10... logprob:  0.595882, 0.281250 (0.678 sec)
102.11... logprob:  0.640752, 0.335938 (0.683 sec)
102.12... logprob:  0.727554, 0.437500 (0.677 sec)
102.13... logprob:  0.660676, 0.359375 (0.676 sec)
102.14... logprob:  0.665941, 0.367188 (0.676 sec)
102.15... logprob:  0.689036, 0.398438 (0.677 sec)
102.16... logprob:  0.627067, 0.320312 (0.680 sec)
102.17... logprob:  0.638464, 0.335938 (0.679 sec)
102.18... logprob:  0.638253, 0.335938 (0.678 sec)
102.19... logprob:  0.633149, 0.328125 (0.675 sec)
102.20... logprob:  0.648473, 0.351562 (0.676 sec)
102.21... logprob:  0.643560, 0.343750 (0.677 sec)
102.22... logprob:  0.629738, 0.320312 (0.678 sec)
102.23... logprob:  0.625618, 0.312500 (0.678 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.653039, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.968714e-03 [5.769926e-09] 
Layer 'conv1' biases: 1.100576e-07 [7.630695e-11] 
Layer 'conv2' weights[0]: 7.955884e-03 [4.735454e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.812525e-10] 
Layer 'conv3' weights[0]: 7.954134e-03 [4.396353e-09] 
Layer 'conv3' biases: 1.213000e-06 [7.165846e-10] 
Layer 'conv4' weights[0]: 7.986634e-03 [4.348463e-09] 
Layer 'conv4' biases: 1.000001e+00 [4.178340e-09] 
Layer 'conv5' weights[0]: 7.986091e-03 [2.871231e-08] 
Layer 'conv5' biases: 1.000011e+00 [3.122068e-08] 
Layer 'fc6' weights[0]: 7.582495e-03 [4.743417e-09] 
Layer 'fc6' biases: 9.999999e-01 [2.655801e-09] 
Layer 'fc7' weights[0]: 7.749589e-03 [6.025163e-08] 
Layer 'fc7' biases: 9.998612e-01 [3.901630e-08] 
Layer 'fc8' weights[0]: 6.695200e-04 [2.332618e-06] 
Layer 'fc8' biases: 4.211052e-02 [9.290015e-06] 
Train error last 27 batches: 0.636952
-------------------------------------------------------
Not saving because 0.653039 > 0.627176 (56.15: -0.03%)
======================================================= (1.799 sec)
102.24... logprob:  0.584909, 0.242188 (0.682 sec)
102.25... logprob:  0.629939, 0.320312 (0.679 sec)
102.26... logprob:  0.672038, 0.390625 (0.692 sec)
102.27... logprob:  0.629237, 0.320312 (0.684 sec)
103.1... logprob:  0.677693, 0.398438 (0.692 sec)
103.2... logprob:  0.599274, 0.273438 (0.688 sec)
103.3... logprob:  0.653510, 0.359375 (0.683 sec)
103.4... logprob:  0.597601, 0.273438 (0.684 sec)
103.5... logprob:  0.591064, 0.265625 (0.684 sec)
103.6... logprob:  0.610966, 0.296875 (0.684 sec)
103.7... logprob:  0.644307, 0.343750 (0.691 sec)
103.8... logprob:  0.603463, 0.289062 (0.693 sec)
103.9... logprob:  0.639474, 0.335938 (0.694 sec)
103.10... logprob:  0.595894, 0.281250 (0.691 sec)
103.11... logprob:  0.640736, 0.335938 (0.692 sec)
103.12... logprob:  0.727488, 0.437500 (0.696 sec)
103.13... logprob:  0.660653, 0.359375 (0.690 sec)
103.14... logprob:  0.665923, 0.367188 (0.691 sec)
103.15... logprob:  0.689022, 0.398438 (0.698 sec)
103.16... logprob:  0.627067, 0.320312 (0.697 sec)
103.17... logprob:  0.638465, 0.335938 (0.697 sec)
103.18... logprob:  0.638252, 0.335938 (0.698 sec)
103.19... logprob:  0.633144, 0.328125 (0.685 sec)
103.20... logprob:  0.648474, 0.351562 (0.685 sec)
103.21... logprob:  0.643556, 0.343750 (0.685 sec)
103.22... logprob:  0.629722, 0.320312 (0.684 sec)
103.23... logprob:  0.625597, 0.312500 (0.676 sec)
103.24... logprob:  0.584857, 0.242188 (0.681 sec)
103.25... logprob:  0.629925, 0.320312 (0.683 sec)
103.26... logprob:  0.672049, 0.390625 (0.673 sec)
103.27... logprob:  0.629228, 0.320312 (0.683 sec)
104.1... logprob:  0.677702, 0.398438 (0.679 sec)
104.2... logprob:  0.599263, 0.273438 (0.682 sec)
104.3... logprob:  0.653510, 0.359375 (0.683 sec)
104.4... logprob:  0.597601, 0.273438 (0.676 sec)
104.5... logprob:  0.591070, 0.265625 (0.680 sec)
104.6... logprob:  0.610973, 0.296875 (0.676 sec)
104.7... logprob:  0.644301, 0.343750 (0.681 sec)
104.8... logprob:  0.603474, 0.289062 (0.675 sec)
104.9... logprob:  0.639464, 0.335938 (0.673 sec)
104.10... logprob:  0.595906, 0.281250 (0.677 sec)
104.11... logprob:  0.640719, 0.335938 (0.675 sec)
104.12... logprob:  0.727421, 0.437500 (0.674 sec)
104.13... logprob:  0.660630, 0.359375 (0.678 sec)
104.14... logprob:  0.665905, 0.367188 (0.678 sec)
104.15... logprob:  0.689009, 0.398438 (0.678 sec)
104.16... logprob:  0.627066, 0.320312 (0.675 sec)
104.17... logprob:  0.638466, 0.335938 (0.677 sec)
104.18... logprob:  0.638252, 0.335938 (0.680 sec)
104.19... logprob:  0.633139, 0.328125 (0.680 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.628650, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.968501e-03 [6.512636e-09] 
Layer 'conv1' biases: 1.124395e-07 [1.590779e-10] 
Layer 'conv2' weights[0]: 7.955686e-03 [6.648678e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.346416e-10] 
Layer 'conv3' weights[0]: 7.953935e-03 [6.062959e-09] 
Layer 'conv3' biases: 1.230017e-06 [2.412178e-09] 
Layer 'conv4' weights[0]: 7.986440e-03 [6.390513e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.179816e-08] 
Layer 'conv5' weights[0]: 7.985881e-03 [1.478633e-07] 
Layer 'conv5' biases: 1.000010e+00 [1.617748e-07] 
Layer 'fc6' weights[0]: 7.582295e-03 [1.379859e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.332314e-08] 
Layer 'fc7' weights[0]: 7.747620e-03 [2.004240e-07] 
Layer 'fc7' biases: 9.998615e-01 [1.874262e-07] 
Layer 'fc8' weights[0]: 6.931770e-04 [1.139183e-05] 
Layer 'fc8' biases: 4.362042e-02 [1.338880e-04] 
Train error last 27 batches: 0.636936
-------------------------------------------------------
Not saving because 0.628650 > 0.627176 (56.15: -0.03%)
======================================================= (1.714 sec)
104.20... logprob:  0.648475, 0.351562 (0.681 sec)
104.21... logprob:  0.643553, 0.343750 (0.682 sec)
104.22... logprob:  0.629706, 0.320312 (0.676 sec)
104.23... logprob:  0.625576, 0.312500 (0.682 sec)
104.24... logprob:  0.584805, 0.242188 (0.681 sec)
104.25... logprob:  0.629911, 0.320312 (0.691 sec)
104.26... logprob:  0.672061, 0.390625 (0.679 sec)
104.27... logprob:  0.629220, 0.320312 (0.678 sec)
105.1... logprob:  0.677710, 0.398438 (0.681 sec)
105.2... logprob:  0.599253, 0.273438 (0.679 sec)
105.3... logprob:  0.653511, 0.359375 (0.677 sec)
105.4... logprob:  0.597602, 0.273438 (0.678 sec)
105.5... logprob:  0.591077, 0.265625 (0.680 sec)
105.6... logprob:  0.610979, 0.296875 (0.678 sec)
105.7... logprob:  0.644295, 0.343750 (0.673 sec)
105.8... logprob:  0.603484, 0.289062 (0.679 sec)
105.9... logprob:  0.639454, 0.335938 (0.677 sec)
105.10... logprob:  0.595919, 0.281250 (0.678 sec)
105.11... logprob:  0.640703, 0.335938 (0.688 sec)
105.12... logprob:  0.727354, 0.437500 (0.681 sec)
105.13... logprob:  0.660607, 0.359375 (0.680 sec)
105.14... logprob:  0.665887, 0.367188 (0.680 sec)
105.15... logprob:  0.688994, 0.398438 (0.680 sec)
105.16... logprob:  0.627066, 0.320312 (0.677 sec)
105.17... logprob:  0.638467, 0.335938 (0.684 sec)
105.18... logprob:  0.638251, 0.335938 (0.681 sec)
105.19... logprob:  0.633134, 0.328125 (0.687 sec)
105.20... logprob:  0.648477, 0.351562 (0.704 sec)
105.21... logprob:  0.643550, 0.343750 (0.696 sec)
105.22... logprob:  0.629690, 0.320312 (0.700 sec)
105.23... logprob:  0.625556, 0.312500 (0.690 sec)
105.24... logprob:  0.584755, 0.242188 (0.689 sec)
105.25... logprob:  0.629897, 0.320312 (0.699 sec)
105.26... logprob:  0.672071, 0.390625 (0.683 sec)
105.27... logprob:  0.629211, 0.320312 (0.688 sec)
106.1... logprob:  0.677719, 0.398438 (0.680 sec)
106.2... logprob:  0.599242, 0.273438 (0.690 sec)
106.3... logprob:  0.653511, 0.359375 (0.682 sec)
106.4... logprob:  0.597600, 0.273438 (0.683 sec)
106.5... logprob:  0.591082, 0.265625 (0.696 sec)
106.6... logprob:  0.610985, 0.296875 (0.694 sec)
106.7... logprob:  0.644290, 0.343750 (0.700 sec)
106.8... logprob:  0.603494, 0.289062 (0.693 sec)
106.9... logprob:  0.639445, 0.335938 (0.695 sec)
106.10... logprob:  0.595930, 0.281250 (0.683 sec)
106.11... logprob:  0.640688, 0.335938 (0.682 sec)
106.12... logprob:  0.727291, 0.437500 (0.683 sec)
106.13... logprob:  0.660586, 0.359375 (0.681 sec)
106.14... logprob:  0.665870, 0.367188 (0.684 sec)
106.15... logprob:  0.688982, 0.398438 (0.677 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.632952, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.968303e-03 [7.515458e-09] 
Layer 'conv1' biases: 1.146498e-07 [2.265172e-10] 
Layer 'conv2' weights[0]: 7.955499e-03 [8.407929e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.255557e-09] 
Layer 'conv3' weights[0]: 7.953728e-03 [7.603695e-09] 
Layer 'conv3' biases: 1.244278e-06 [3.647186e-09] 
Layer 'conv4' weights[0]: 7.986237e-03 [8.248860e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.418317e-08] 
Layer 'conv5' weights[0]: 7.985693e-03 [2.316104e-07] 
Layer 'conv5' biases: 1.000009e+00 [2.534671e-07] 
Layer 'fc6' weights[0]: 7.582086e-03 [2.108071e-08] 
Layer 'fc6' biases: 9.999999e-01 [2.088872e-08] 
Layer 'fc7' weights[0]: 7.745592e-03 [3.047852e-07] 
Layer 'fc7' biases: 9.998618e-01 [2.929363e-07] 
Layer 'fc8' weights[0]: 7.422302e-04 [1.781675e-05] 
Layer 'fc8' biases: 4.548868e-02 [2.122806e-04] 
Train error last 27 batches: 0.636920
-------------------------------------------------------
Not saving because 0.632952 > 0.627176 (56.15: -0.03%)
======================================================= (1.690 sec)
106.16... logprob:  0.627066, 0.320312 (0.682 sec)
106.17... logprob:  0.638468, 0.335938 (0.678 sec)
106.18... logprob:  0.638251, 0.335938 (0.681 sec)
106.19... logprob:  0.633129, 0.328125 (0.681 sec)
106.20... logprob:  0.648478, 0.351562 (0.683 sec)
106.21... logprob:  0.643546, 0.343750 (0.685 sec)
106.22... logprob:  0.629675, 0.320312 (0.686 sec)
106.23... logprob:  0.625535, 0.312500 (0.688 sec)
106.24... logprob:  0.584704, 0.242188 (0.689 sec)
106.25... logprob:  0.629883, 0.320312 (0.689 sec)
106.26... logprob:  0.672083, 0.390625 (0.684 sec)
106.27... logprob:  0.629203, 0.320312 (0.681 sec)
107.1... logprob:  0.677727, 0.398438 (0.683 sec)
107.2... logprob:  0.599233, 0.273438 (0.685 sec)
107.3... logprob:  0.653511, 0.359375 (0.688 sec)
107.4... logprob:  0.597602, 0.273438 (0.685 sec)
107.5... logprob:  0.591090, 0.265625 (0.692 sec)
107.6... logprob:  0.610992, 0.296875 (0.689 sec)
107.7... logprob:  0.644284, 0.343750 (0.696 sec)
107.8... logprob:  0.603505, 0.289062 (0.687 sec)
107.9... logprob:  0.639435, 0.335938 (0.696 sec)
107.10... logprob:  0.595943, 0.281250 (0.688 sec)
107.11... logprob:  0.640671, 0.335938 (0.694 sec)
107.12... logprob:  0.727224, 0.437500 (0.690 sec)
107.13... logprob:  0.660563, 0.359375 (0.682 sec)
107.14... logprob:  0.665852, 0.367188 (0.689 sec)
107.15... logprob:  0.688968, 0.398438 (0.690 sec)
107.16... logprob:  0.627066, 0.320312 (0.678 sec)
107.17... logprob:  0.638469, 0.335938 (0.686 sec)
107.18... logprob:  0.638250, 0.335938 (0.689 sec)
107.19... logprob:  0.633125, 0.328125 (0.682 sec)
107.20... logprob:  0.648480, 0.351562 (0.687 sec)
107.21... logprob:  0.643543, 0.343750 (0.679 sec)
107.22... logprob:  0.629659, 0.320312 (0.686 sec)
107.23... logprob:  0.625515, 0.312500 (0.686 sec)
107.24... logprob:  0.584653, 0.242188 (0.690 sec)
107.25... logprob:  0.629869, 0.320312 (0.689 sec)
107.26... logprob:  0.672094, 0.390625 (0.688 sec)
107.27... logprob:  0.629194, 0.320312 (0.683 sec)
108.1... logprob:  0.677737, 0.398438 (0.682 sec)
108.2... logprob:  0.599222, 0.273438 (0.687 sec)
108.3... logprob:  0.653512, 0.359375 (0.697 sec)
108.4... logprob:  0.597601, 0.273438 (0.690 sec)
108.5... logprob:  0.591095, 0.265625 (0.678 sec)
108.6... logprob:  0.610997, 0.296875 (0.680 sec)
108.7... logprob:  0.644279, 0.343750 (0.678 sec)
108.8... logprob:  0.603515, 0.289062 (0.682 sec)
108.9... logprob:  0.639426, 0.335938 (0.688 sec)
108.10... logprob:  0.595955, 0.281250 (0.688 sec)
108.11... logprob:  0.640655, 0.335938 (0.682 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.700720, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.968118e-03 [6.469487e-09] 
Layer 'conv1' biases: 1.169872e-07 [8.440451e-11] 
Layer 'conv2' weights[0]: 7.955295e-03 [5.160199e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.913119e-10] 
Layer 'conv3' weights[0]: 7.953532e-03 [5.198447e-09] 
Layer 'conv3' biases: 1.260020e-06 [1.519514e-09] 
Layer 'conv4' weights[0]: 7.986040e-03 [5.540490e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.474019e-08] 
Layer 'conv5' weights[0]: 7.985471e-03 [9.996143e-08] 
Layer 'conv5' biases: 1.000009e+00 [1.095030e-07] 
Layer 'fc6' weights[0]: 7.581885e-03 [9.848992e-09] 
Layer 'fc6' biases: 9.999999e-01 [8.862467e-09] 
Layer 'fc7' weights[0]: 7.743604e-03 [1.370597e-07] 
Layer 'fc7' biases: 9.998623e-01 [1.212885e-07] 
Layer 'fc8' weights[0]: 7.794913e-04 [7.431070e-06] 
Layer 'fc8' biases: 4.715166e-02 [1.156652e-04] 
Train error last 27 batches: 0.636908
-------------------------------------------------------
Not saving because 0.700720 > 0.627176 (56.15: -0.03%)
======================================================= (1.748 sec)
108.12... logprob:  0.727160, 0.437500 (0.680 sec)
108.13... logprob:  0.660541, 0.359375 (0.684 sec)
108.14... logprob:  0.665835, 0.367188 (0.690 sec)
108.15... logprob:  0.688954, 0.398438 (0.691 sec)
108.16... logprob:  0.627065, 0.320312 (0.688 sec)
108.17... logprob:  0.638470, 0.335938 (0.690 sec)
108.18... logprob:  0.638249, 0.335938 (0.697 sec)
108.19... logprob:  0.633120, 0.328125 (0.689 sec)
108.20... logprob:  0.648481, 0.351562 (0.685 sec)
108.21... logprob:  0.643539, 0.343750 (0.684 sec)
108.22... logprob:  0.629644, 0.320312 (0.683 sec)
108.23... logprob:  0.625495, 0.312500 (0.684 sec)
108.24... logprob:  0.584604, 0.242188 (0.687 sec)
108.25... logprob:  0.629855, 0.320312 (0.689 sec)
108.26... logprob:  0.672104, 0.390625 (0.722 sec)
108.27... logprob:  0.629186, 0.320312 (0.689 sec)
109.1... logprob:  0.677745, 0.398438 (0.690 sec)
109.2... logprob:  0.599212, 0.273438 (0.690 sec)
109.3... logprob:  0.653512, 0.359375 (0.688 sec)
109.4... logprob:  0.597601, 0.273438 (0.689 sec)
109.5... logprob:  0.591101, 0.265625 (0.685 sec)
109.6... logprob:  0.611003, 0.296875 (0.689 sec)
109.7... logprob:  0.644274, 0.343750 (0.682 sec)
109.8... logprob:  0.603525, 0.289062 (0.686 sec)
109.9... logprob:  0.639417, 0.335938 (0.681 sec)
109.10... logprob:  0.595967, 0.281250 (0.681 sec)
109.11... logprob:  0.640640, 0.335938 (0.684 sec)
109.12... logprob:  0.727096, 0.437500 (0.678 sec)
109.13... logprob:  0.660519, 0.359375 (0.686 sec)
109.14... logprob:  0.665818, 0.367188 (0.674 sec)
109.15... logprob:  0.688942, 0.398438 (0.674 sec)
109.16... logprob:  0.627066, 0.320312 (0.676 sec)
109.17... logprob:  0.638471, 0.335938 (0.677 sec)
109.18... logprob:  0.638249, 0.335938 (0.675 sec)
109.19... logprob:  0.633115, 0.328125 (0.677 sec)
109.20... logprob:  0.648483, 0.351562 (0.675 sec)
109.21... logprob:  0.643536, 0.343750 (0.676 sec)
109.22... logprob:  0.629629, 0.320312 (0.679 sec)
109.23... logprob:  0.625475, 0.312500 (0.678 sec)
109.24... logprob:  0.584553, 0.242188 (0.678 sec)
109.25... logprob:  0.629841, 0.320312 (0.679 sec)
109.26... logprob:  0.672115, 0.390625 (0.688 sec)
109.27... logprob:  0.629178, 0.320312 (0.679 sec)
110.1... logprob:  0.677754, 0.398438 (0.675 sec)
110.2... logprob:  0.599201, 0.273438 (0.678 sec)
110.3... logprob:  0.653513, 0.359375 (0.676 sec)
110.4... logprob:  0.597601, 0.273438 (0.676 sec)
110.5... logprob:  0.591107, 0.265625 (0.675 sec)
110.6... logprob:  0.611009, 0.296875 (0.673 sec)
110.7... logprob:  0.644268, 0.343750 (0.673 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.632989, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.967928e-03 [6.863610e-09] 
Layer 'conv1' biases: 1.198988e-07 [1.270896e-10] 
Layer 'conv2' weights[0]: 7.955089e-03 [5.969193e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.560093e-10] 
Layer 'conv3' weights[0]: 7.953315e-03 [6.080515e-09] 
Layer 'conv3' biases: 1.284281e-06 [2.312789e-09] 
Layer 'conv4' weights[0]: 7.985825e-03 [6.627827e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.299550e-08] 
Layer 'conv5' weights[0]: 7.985279e-03 [1.554996e-07] 
Layer 'conv5' biases: 1.000009e+00 [1.703208e-07] 
Layer 'fc6' weights[0]: 7.581679e-03 [1.442034e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.387872e-08] 
Layer 'fc7' weights[0]: 7.741654e-03 [2.050604e-07] 
Layer 'fc7' biases: 9.998617e-01 [1.909194e-07] 
Layer 'fc8' weights[0]: 7.404032e-04 [1.165681e-05] 
Layer 'fc8' biases: 4.770928e-02 [1.793876e-04] 
Train error last 27 batches: 0.636892
-------------------------------------------------------
Not saving because 0.632989 > 0.627176 (56.15: -0.03%)
======================================================= (1.711 sec)
110.8... logprob:  0.603536, 0.289062 (0.679 sec)
110.9... logprob:  0.639407, 0.335938 (0.678 sec)
110.10... logprob:  0.595979, 0.281250 (0.674 sec)
110.11... logprob:  0.640624, 0.335938 (0.678 sec)
110.12... logprob:  0.727030, 0.437500 (0.678 sec)
110.13... logprob:  0.660496, 0.359375 (0.679 sec)
110.14... logprob:  0.665800, 0.367188 (0.678 sec)
110.15... logprob:  0.688927, 0.398438 (0.681 sec)
110.16... logprob:  0.627065, 0.320312 (0.680 sec)
110.17... logprob:  0.638472, 0.335938 (0.682 sec)
110.18... logprob:  0.638249, 0.335938 (0.693 sec)
110.19... logprob:  0.633110, 0.328125 (0.683 sec)
110.20... logprob:  0.648485, 0.351562 (0.681 sec)
110.21... logprob:  0.643533, 0.343750 (0.680 sec)
110.22... logprob:  0.629613, 0.320312 (0.678 sec)
110.23... logprob:  0.625455, 0.312500 (0.674 sec)
110.24... logprob:  0.584503, 0.242188 (0.675 sec)
110.25... logprob:  0.629827, 0.320312 (0.675 sec)
110.26... logprob:  0.672127, 0.390625 (0.679 sec)
110.27... logprob:  0.629169, 0.320312 (0.672 sec)
111.1... logprob:  0.677763, 0.398438 (0.680 sec)
111.2... logprob:  0.599191, 0.273438 (0.680 sec)
111.3... logprob:  0.653513, 0.359375 (0.682 sec)
111.4... logprob:  0.597600, 0.273438 (0.680 sec)
111.5... logprob:  0.591113, 0.265625 (0.685 sec)
111.6... logprob:  0.611015, 0.296875 (0.683 sec)
111.7... logprob:  0.644263, 0.343750 (0.679 sec)
111.8... logprob:  0.603546, 0.289062 (0.688 sec)
111.9... logprob:  0.639399, 0.335938 (0.683 sec)
111.10... logprob:  0.595991, 0.281250 (0.691 sec)
111.11... logprob:  0.640608, 0.335938 (0.686 sec)
111.12... logprob:  0.726967, 0.437500 (0.687 sec)
111.13... logprob:  0.660474, 0.359375 (0.682 sec)
111.14... logprob:  0.665782, 0.367188 (0.678 sec)
111.15... logprob:  0.688914, 0.398438 (0.678 sec)
111.16... logprob:  0.627065, 0.320312 (0.676 sec)
111.17... logprob:  0.638473, 0.335938 (0.678 sec)
111.18... logprob:  0.638249, 0.335938 (0.676 sec)
111.19... logprob:  0.633106, 0.328125 (0.674 sec)
111.20... logprob:  0.648486, 0.351562 (0.676 sec)
111.21... logprob:  0.643530, 0.343750 (0.678 sec)
111.22... logprob:  0.629598, 0.320312 (0.677 sec)
111.23... logprob:  0.625436, 0.312500 (0.677 sec)
111.24... logprob:  0.584454, 0.242188 (0.679 sec)
111.25... logprob:  0.629814, 0.320312 (0.681 sec)
111.26... logprob:  0.672137, 0.390625 (0.690 sec)
111.27... logprob:  0.629161, 0.320312 (0.686 sec)
112.1... logprob:  0.677771, 0.398438 (0.695 sec)
112.2... logprob:  0.599180, 0.273438 (0.687 sec)
112.3... logprob:  0.653513, 0.359375 (0.685 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.628267, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.967724e-03 [6.436513e-09] 
Layer 'conv1' biases: 1.229125e-07 [7.205507e-11] 
Layer 'conv2' weights[0]: 7.954892e-03 [4.831098e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.455262e-10] 
Layer 'conv3' weights[0]: 7.953117e-03 [4.776540e-09] 
Layer 'conv3' biases: 1.309135e-06 [1.101709e-09] 
Layer 'conv4' weights[0]: 7.985610e-03 [4.885604e-09] 
Layer 'conv4' biases: 1.000001e+00 [9.448595e-09] 
Layer 'conv5' weights[0]: 7.985091e-03 [6.378192e-08] 
Layer 'conv5' biases: 1.000010e+00 [6.973587e-08] 
Layer 'fc6' weights[0]: 7.581478e-03 [6.932869e-09] 
Layer 'fc6' biases: 9.999999e-01 [5.661679e-09] 
Layer 'fc7' weights[0]: 7.739692e-03 [9.546773e-08] 
Layer 'fc7' biases: 9.998611e-01 [7.708417e-08] 
Layer 'fc8' weights[0]: 6.957286e-04 [4.700298e-06] 
Layer 'fc8' biases: 4.813679e-02 [8.484231e-05] 
Train error last 27 batches: 0.636876
-------------------------------------------------------
Not saving because 0.628267 > 0.627176 (56.15: -0.03%)
======================================================= (1.770 sec)
112.4... logprob:  0.597600, 0.273438 (0.681 sec)
112.5... logprob:  0.591118, 0.265625 (0.685 sec)
112.6... logprob:  0.611021, 0.296875 (0.682 sec)
112.7... logprob:  0.644258, 0.343750 (0.681 sec)
112.8... logprob:  0.603556, 0.289062 (0.683 sec)
112.9... logprob:  0.639390, 0.335938 (0.697 sec)
112.10... logprob:  0.596003, 0.281250 (0.692 sec)
112.11... logprob:  0.640593, 0.335938 (0.691 sec)
112.12... logprob:  0.726903, 0.437500 (0.684 sec)
112.13... logprob:  0.660452, 0.359375 (0.688 sec)
112.14... logprob:  0.665765, 0.367188 (0.682 sec)
112.15... logprob:  0.688900, 0.398438 (0.681 sec)
112.16... logprob:  0.627065, 0.320312 (0.684 sec)
112.17... logprob:  0.638474, 0.335938 (0.683 sec)
112.18... logprob:  0.638248, 0.335938 (0.682 sec)
112.19... logprob:  0.633101, 0.328125 (0.683 sec)
112.20... logprob:  0.648488, 0.351562 (0.686 sec)
112.21... logprob:  0.643527, 0.343750 (0.687 sec)
112.22... logprob:  0.629584, 0.320312 (0.690 sec)
112.23... logprob:  0.625416, 0.312500 (0.695 sec)
112.24... logprob:  0.584405, 0.242188 (0.681 sec)
112.25... logprob:  0.629801, 0.320312 (0.683 sec)
112.26... logprob:  0.672148, 0.390625 (0.682 sec)
112.27... logprob:  0.629153, 0.320312 (0.683 sec)
113.1... logprob:  0.677780, 0.398438 (0.680 sec)
113.2... logprob:  0.599170, 0.273438 (0.683 sec)
113.3... logprob:  0.653514, 0.359375 (0.682 sec)
113.4... logprob:  0.597600, 0.273438 (0.679 sec)
113.5... logprob:  0.591124, 0.265625 (0.682 sec)
113.6... logprob:  0.611027, 0.296875 (0.682 sec)
113.7... logprob:  0.644253, 0.343750 (0.681 sec)
113.8... logprob:  0.603566, 0.289062 (0.684 sec)
113.9... logprob:  0.639380, 0.335938 (0.683 sec)
113.10... logprob:  0.596015, 0.281250 (0.681 sec)
113.11... logprob:  0.640577, 0.335938 (0.682 sec)
113.12... logprob:  0.726840, 0.437500 (0.682 sec)
113.13... logprob:  0.660431, 0.359375 (0.682 sec)
113.14... logprob:  0.665747, 0.367188 (0.689 sec)
113.15... logprob:  0.688886, 0.398438 (0.688 sec)
113.16... logprob:  0.627065, 0.320312 (0.689 sec)
113.17... logprob:  0.638474, 0.335938 (0.690 sec)
113.18... logprob:  0.638248, 0.335938 (0.683 sec)
113.19... logprob:  0.633097, 0.328125 (0.682 sec)
113.20... logprob:  0.648490, 0.351562 (0.681 sec)
113.21... logprob:  0.643524, 0.343750 (0.681 sec)
113.22... logprob:  0.629569, 0.320312 (0.684 sec)
113.23... logprob:  0.625397, 0.312500 (0.685 sec)
113.24... logprob:  0.584356, 0.242188 (0.685 sec)
113.25... logprob:  0.629787, 0.320312 (0.681 sec)
113.26... logprob:  0.672159, 0.390625 (0.682 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.653205, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.967515e-03 [6.083577e-09] 
Layer 'conv1' biases: 1.257594e-07 [6.119615e-11] 
Layer 'conv2' weights[0]: 7.954709e-03 [4.671136e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.775601e-10] 
Layer 'conv3' weights[0]: 7.952919e-03 [4.548704e-09] 
Layer 'conv3' biases: 1.331304e-06 [9.287114e-10] 
Layer 'conv4' weights[0]: 7.985397e-03 [4.642798e-09] 
Layer 'conv4' biases: 1.000001e+00 [7.623176e-09] 
Layer 'conv5' weights[0]: 7.984904e-03 [5.108575e-08] 
Layer 'conv5' biases: 1.000010e+00 [5.587902e-08] 
Layer 'fc6' weights[0]: 7.581291e-03 [6.008855e-09] 
Layer 'fc6' biases: 9.999999e-01 [4.531819e-09] 
Layer 'fc7' weights[0]: 7.737748e-03 [8.045809e-08] 
Layer 'fc7' biases: 9.998608e-01 [6.115039e-08] 
Layer 'fc8' weights[0]: 6.786983e-04 [3.735589e-06] 
Layer 'fc8' biases: 4.897306e-02 [7.751375e-05] 
Train error last 27 batches: 0.636860
-------------------------------------------------------
Not saving because 0.653205 > 0.627176 (56.15: -0.03%)
======================================================= (1.784 sec)
113.27... logprob:  0.629145, 0.320312 (0.679 sec)
114.1... logprob:  0.677789, 0.398438 (0.683 sec)
114.2... logprob:  0.599159, 0.273438 (0.683 sec)
114.3... logprob:  0.653514, 0.359375 (0.680 sec)
114.4... logprob:  0.597599, 0.273438 (0.686 sec)
114.5... logprob:  0.591129, 0.265625 (0.687 sec)
114.6... logprob:  0.611032, 0.296875 (0.685 sec)
114.7... logprob:  0.644248, 0.343750 (0.684 sec)
114.8... logprob:  0.603576, 0.289062 (0.681 sec)
114.9... logprob:  0.639372, 0.335938 (0.692 sec)
114.10... logprob:  0.596027, 0.281250 (0.683 sec)
114.11... logprob:  0.640563, 0.335938 (0.685 sec)
114.12... logprob:  0.726778, 0.437500 (0.680 sec)
114.13... logprob:  0.660409, 0.359375 (0.685 sec)
114.14... logprob:  0.665730, 0.367188 (0.680 sec)
114.15... logprob:  0.688872, 0.398438 (0.680 sec)
114.16... logprob:  0.627064, 0.320312 (0.689 sec)
114.17... logprob:  0.638476, 0.335938 (0.680 sec)
114.18... logprob:  0.638247, 0.335938 (0.676 sec)
114.19... logprob:  0.633093, 0.328125 (0.676 sec)
114.20... logprob:  0.648491, 0.351562 (0.676 sec)
114.21... logprob:  0.643521, 0.343750 (0.678 sec)
114.22... logprob:  0.629555, 0.320312 (0.679 sec)
114.23... logprob:  0.625378, 0.312500 (0.676 sec)
114.24... logprob:  0.584308, 0.242188 (0.672 sec)
114.25... logprob:  0.629774, 0.320312 (0.676 sec)
114.26... logprob:  0.672170, 0.390625 (0.677 sec)
114.27... logprob:  0.629137, 0.320312 (0.680 sec)
115.1... logprob:  0.677798, 0.398438 (0.677 sec)
115.2... logprob:  0.599149, 0.273438 (0.681 sec)
115.3... logprob:  0.653515, 0.359375 (0.685 sec)
115.4... logprob:  0.597599, 0.273438 (0.678 sec)
115.5... logprob:  0.591135, 0.265625 (0.678 sec)
115.6... logprob:  0.611038, 0.296875 (0.676 sec)
115.7... logprob:  0.644243, 0.343750 (0.671 sec)
115.8... logprob:  0.603586, 0.289062 (0.685 sec)
115.9... logprob:  0.639363, 0.335938 (0.682 sec)
115.10... logprob:  0.596039, 0.281250 (0.682 sec)
115.11... logprob:  0.640548, 0.335938 (0.686 sec)
115.12... logprob:  0.726714, 0.437500 (0.681 sec)
115.13... logprob:  0.660387, 0.359375 (0.682 sec)
115.14... logprob:  0.665713, 0.367188 (0.679 sec)
115.15... logprob:  0.688859, 0.398438 (0.676 sec)
115.16... logprob:  0.627065, 0.320312 (0.675 sec)
115.17... logprob:  0.638477, 0.335938 (0.673 sec)
115.18... logprob:  0.638247, 0.335938 (0.673 sec)
115.19... logprob:  0.633088, 0.328125 (0.674 sec)
115.20... logprob:  0.648493, 0.351562 (0.675 sec)
115.21... logprob:  0.643518, 0.343750 (0.682 sec)
115.22... logprob:  0.629540, 0.320312 (0.679 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.630007, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.967324e-03 [6.132253e-09] 
Layer 'conv1' biases: 1.286511e-07 [1.146432e-10] 
Layer 'conv2' weights[0]: 7.954507e-03 [5.440122e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.018861e-10] 
Layer 'conv3' weights[0]: 7.952718e-03 [4.970111e-09] 
Layer 'conv3' biases: 1.353040e-06 [1.393409e-09] 
Layer 'conv4' weights[0]: 7.985196e-03 [5.026161e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.102313e-08] 
Layer 'conv5' weights[0]: 7.984703e-03 [7.425029e-08] 
Layer 'conv5' biases: 1.000010e+00 [8.111265e-08] 
Layer 'fc6' weights[0]: 7.581084e-03 [7.930959e-09] 
Layer 'fc6' biases: 9.999999e-01 [6.845323e-09] 
Layer 'fc7' weights[0]: 7.735776e-03 [1.133992e-07] 
Layer 'fc7' biases: 9.998605e-01 [9.679529e-08] 
Layer 'fc8' weights[0]: 6.659286e-04 [5.829526e-06] 
Layer 'fc8' biases: 4.984338e-02 [6.275983e-05] 
Train error last 27 batches: 0.636847
-------------------------------------------------------
Not saving because 0.630007 > 0.627176 (56.15: -0.03%)
======================================================= (1.735 sec)
115.23... logprob:  0.625359, 0.312500 (0.676 sec)
115.24... logprob:  0.584260, 0.242188 (0.675 sec)
115.25... logprob:  0.629761, 0.320312 (0.674 sec)
115.26... logprob:  0.672181, 0.390625 (0.674 sec)
115.27... logprob:  0.629128, 0.320312 (0.673 sec)
116.1... logprob:  0.677806, 0.398438 (0.674 sec)
116.2... logprob:  0.599138, 0.273438 (0.682 sec)
116.3... logprob:  0.653515, 0.359375 (0.683 sec)
116.4... logprob:  0.597598, 0.273438 (0.683 sec)
116.5... logprob:  0.591139, 0.265625 (0.682 sec)
116.6... logprob:  0.611044, 0.296875 (0.687 sec)
116.7... logprob:  0.644238, 0.343750 (0.685 sec)
116.8... logprob:  0.603595, 0.289062 (0.684 sec)
116.9... logprob:  0.639355, 0.335938 (0.684 sec)
116.10... logprob:  0.596050, 0.281250 (0.683 sec)
116.11... logprob:  0.640533, 0.335938 (0.680 sec)
116.12... logprob:  0.726653, 0.437500 (0.681 sec)
116.13... logprob:  0.660366, 0.359375 (0.691 sec)
116.14... logprob:  0.665696, 0.367188 (0.681 sec)
116.15... logprob:  0.688845, 0.398438 (0.684 sec)
116.16... logprob:  0.627064, 0.320312 (0.684 sec)
116.17... logprob:  0.638477, 0.335938 (0.685 sec)
116.18... logprob:  0.638246, 0.335938 (0.682 sec)
116.19... logprob:  0.633084, 0.328125 (0.683 sec)
116.20... logprob:  0.648495, 0.351562 (0.685 sec)
116.21... logprob:  0.643515, 0.343750 (0.687 sec)
116.22... logprob:  0.629526, 0.320312 (0.684 sec)
116.23... logprob:  0.625340, 0.312500 (0.685 sec)
116.24... logprob:  0.584212, 0.242188 (0.681 sec)
116.25... logprob:  0.629748, 0.320312 (0.690 sec)
116.26... logprob:  0.672192, 0.390625 (0.690 sec)
116.27... logprob:  0.629120, 0.320312 (0.688 sec)
117.1... logprob:  0.677815, 0.398438 (0.694 sec)
117.2... logprob:  0.599127, 0.273438 (0.680 sec)
117.3... logprob:  0.653516, 0.359375 (0.676 sec)
117.4... logprob:  0.597597, 0.273438 (0.676 sec)
117.5... logprob:  0.591144, 0.265625 (0.676 sec)
117.6... logprob:  0.611049, 0.296875 (0.676 sec)
117.7... logprob:  0.644233, 0.343750 (0.676 sec)
117.8... logprob:  0.603606, 0.289062 (0.677 sec)
117.9... logprob:  0.639346, 0.335938 (0.674 sec)
117.10... logprob:  0.596062, 0.281250 (0.686 sec)
117.11... logprob:  0.640518, 0.335938 (0.680 sec)
117.12... logprob:  0.726591, 0.437500 (0.681 sec)
117.13... logprob:  0.660345, 0.359375 (0.679 sec)
117.14... logprob:  0.665679, 0.367188 (0.682 sec)
117.15... logprob:  0.688831, 0.398438 (0.677 sec)
117.16... logprob:  0.627064, 0.320312 (0.679 sec)
117.17... logprob:  0.638478, 0.335938 (0.678 sec)
117.18... logprob:  0.638246, 0.335938 (0.676 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633146, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.967123e-03 [6.547609e-09] 
Layer 'conv1' biases: 1.312409e-07 [1.793357e-10] 
Layer 'conv2' weights[0]: 7.954312e-03 [7.079895e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.546649e-10] 
Layer 'conv3' weights[0]: 7.952529e-03 [6.475276e-09] 
Layer 'conv3' biases: 1.369529e-06 [2.763327e-09] 
Layer 'conv4' weights[0]: 7.984989e-03 [6.859104e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.509080e-08] 
Layer 'conv5' weights[0]: 7.984514e-03 [1.685796e-07] 
Layer 'conv5' biases: 1.000009e+00 [1.842102e-07] 
Layer 'fc6' weights[0]: 7.580891e-03 [1.592204e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.547697e-08] 
Layer 'fc7' weights[0]: 7.733801e-03 [2.295671e-07] 
Layer 'fc7' biases: 9.998609e-01 [2.164010e-07] 
Layer 'fc8' weights[0]: 6.967698e-04 [1.308865e-05] 
Layer 'fc8' biases: 5.143379e-02 [1.607405e-04] 
Train error last 27 batches: 0.636833
-------------------------------------------------------
Not saving because 0.633146 > 0.627176 (56.15: -0.03%)
======================================================= (1.706 sec)
117.19... logprob:  0.633080, 0.328125 (0.682 sec)
117.20... logprob:  0.648496, 0.351562 (0.680 sec)
117.21... logprob:  0.643512, 0.343750 (0.685 sec)
117.22... logprob:  0.629512, 0.320312 (0.682 sec)
117.23... logprob:  0.625321, 0.312500 (0.686 sec)
117.24... logprob:  0.584165, 0.242188 (0.689 sec)
117.25... logprob:  0.629735, 0.320312 (0.694 sec)
117.26... logprob:  0.672203, 0.390625 (0.688 sec)
117.27... logprob:  0.629112, 0.320312 (0.684 sec)
118.1... logprob:  0.677824, 0.398438 (0.682 sec)
118.2... logprob:  0.599117, 0.273438 (0.678 sec)
118.3... logprob:  0.653516, 0.359375 (0.677 sec)
118.4... logprob:  0.597596, 0.273438 (0.682 sec)
118.5... logprob:  0.591149, 0.265625 (0.680 sec)
118.6... logprob:  0.611054, 0.296875 (0.677 sec)
118.7... logprob:  0.644229, 0.343750 (0.678 sec)
118.8... logprob:  0.603615, 0.289062 (0.678 sec)
118.9... logprob:  0.639337, 0.335938 (0.678 sec)
118.10... logprob:  0.596074, 0.281250 (0.687 sec)
118.11... logprob:  0.640504, 0.335938 (0.694 sec)
118.12... logprob:  0.726529, 0.437500 (0.682 sec)
118.13... logprob:  0.660324, 0.359375 (0.684 sec)
118.14... logprob:  0.665662, 0.367188 (0.684 sec)
118.15... logprob:  0.688817, 0.398438 (0.679 sec)
118.16... logprob:  0.627064, 0.320312 (0.675 sec)
118.17... logprob:  0.638479, 0.335938 (0.676 sec)
118.18... logprob:  0.638246, 0.335938 (0.675 sec)
118.19... logprob:  0.633075, 0.328125 (0.678 sec)
118.20... logprob:  0.648498, 0.351562 (0.683 sec)
118.21... logprob:  0.643509, 0.343750 (0.684 sec)
118.22... logprob:  0.629498, 0.320312 (0.679 sec)
118.23... logprob:  0.625303, 0.312500 (0.687 sec)
118.24... logprob:  0.584118, 0.242188 (0.675 sec)
118.25... logprob:  0.629722, 0.320312 (0.676 sec)
118.26... logprob:  0.672213, 0.390625 (0.683 sec)
118.27... logprob:  0.629104, 0.320312 (0.688 sec)
119.1... logprob:  0.677832, 0.398438 (0.691 sec)
119.2... logprob:  0.599107, 0.273438 (0.680 sec)
119.3... logprob:  0.653517, 0.359375 (0.676 sec)
119.4... logprob:  0.597595, 0.273438 (0.673 sec)
119.5... logprob:  0.591154, 0.265625 (0.673 sec)
119.6... logprob:  0.611060, 0.296875 (0.674 sec)
119.7... logprob:  0.644224, 0.343750 (0.676 sec)
119.8... logprob:  0.603625, 0.289062 (0.676 sec)
119.9... logprob:  0.639329, 0.335938 (0.677 sec)
119.10... logprob:  0.596086, 0.281250 (0.678 sec)
119.11... logprob:  0.640489, 0.335938 (0.673 sec)
119.12... logprob:  0.726468, 0.437500 (0.675 sec)
119.13... logprob:  0.660303, 0.359375 (0.675 sec)
119.14... logprob:  0.665645, 0.367188 (0.675 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.694948, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.966921e-03 [6.848497e-09] 
Layer 'conv1' biases: 1.336887e-07 [1.683938e-10] 
Layer 'conv2' weights[0]: 7.954111e-03 [6.836709e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.841669e-10] 
Layer 'conv3' weights[0]: 7.952329e-03 [6.168744e-09] 
Layer 'conv3' biases: 1.384181e-06 [2.518583e-09] 
Layer 'conv4' weights[0]: 7.984789e-03 [6.494061e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.229719e-08] 
Layer 'conv5' weights[0]: 7.984279e-03 [1.495623e-07] 
Layer 'conv5' biases: 1.000008e+00 [1.634701e-07] 
Layer 'fc6' weights[0]: 7.580701e-03 [1.426957e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.379464e-08] 
Layer 'fc7' weights[0]: 7.731798e-03 [2.060965e-07] 
Layer 'fc7' biases: 9.998617e-01 [1.932112e-07] 
Layer 'fc8' weights[0]: 7.492173e-04 [1.167197e-05] 
Layer 'fc8' biases: 5.332031e-02 [1.352043e-04] 
Train error last 27 batches: 0.636818
-------------------------------------------------------
Not saving because 0.694948 > 0.627176 (56.15: -0.03%)
======================================================= (1.716 sec)
119.15... logprob:  0.688804, 0.398438 (0.676 sec)
119.16... logprob:  0.627064, 0.320312 (0.691 sec)
119.17... logprob:  0.638480, 0.335938 (0.675 sec)
119.18... logprob:  0.638245, 0.335938 (0.678 sec)
119.19... logprob:  0.633071, 0.328125 (0.676 sec)
119.20... logprob:  0.648500, 0.351562 (0.676 sec)
119.21... logprob:  0.643506, 0.343750 (0.673 sec)
119.22... logprob:  0.629484, 0.320312 (0.677 sec)
119.23... logprob:  0.625284, 0.312500 (0.681 sec)
119.24... logprob:  0.584071, 0.242188 (0.681 sec)
119.25... logprob:  0.629709, 0.320312 (0.680 sec)
119.26... logprob:  0.672224, 0.390625 (0.690 sec)
119.27... logprob:  0.629097, 0.320312 (0.688 sec)
120.1... logprob:  0.677841, 0.398438 (0.685 sec)
120.2... logprob:  0.599096, 0.273438 (0.683 sec)
120.3... logprob:  0.653517, 0.359375 (0.688 sec)
120.4... logprob:  0.597594, 0.273438 (0.680 sec)
120.5... logprob:  0.591159, 0.265625 (0.686 sec)
120.6... logprob:  0.611065, 0.296875 (0.682 sec)
120.7... logprob:  0.644219, 0.343750 (0.690 sec)
120.8... logprob:  0.603635, 0.289062 (0.686 sec)
120.9... logprob:  0.639321, 0.335938 (0.687 sec)
120.10... logprob:  0.596098, 0.281250 (0.689 sec)
120.11... logprob:  0.640475, 0.335938 (0.683 sec)
120.12... logprob:  0.726406, 0.437500 (0.686 sec)
120.13... logprob:  0.660281, 0.359375 (0.685 sec)
120.14... logprob:  0.665627, 0.367188 (0.678 sec)
120.15... logprob:  0.688789, 0.398438 (0.679 sec)
120.16... logprob:  0.627064, 0.320312 (0.676 sec)
120.17... logprob:  0.638481, 0.335938 (0.684 sec)
120.18... logprob:  0.638245, 0.335938 (0.681 sec)
120.19... logprob:  0.633067, 0.328125 (0.687 sec)
120.20... logprob:  0.648502, 0.351562 (0.689 sec)
120.21... logprob:  0.643504, 0.343750 (0.689 sec)
120.22... logprob:  0.629471, 0.320312 (0.703 sec)
120.23... logprob:  0.625266, 0.312500 (0.696 sec)
120.24... logprob:  0.584024, 0.242188 (0.685 sec)
120.25... logprob:  0.629697, 0.320312 (0.685 sec)
120.26... logprob:  0.672234, 0.390625 (0.682 sec)
120.27... logprob:  0.629088, 0.320312 (0.682 sec)
121.1... logprob:  0.677850, 0.398438 (0.684 sec)
121.2... logprob:  0.599085, 0.273438 (0.692 sec)
121.3... logprob:  0.653518, 0.359375 (0.683 sec)
121.4... logprob:  0.597592, 0.273438 (0.677 sec)
121.5... logprob:  0.591163, 0.265625 (0.681 sec)
121.6... logprob:  0.611070, 0.296875 (0.676 sec)
121.7... logprob:  0.644215, 0.343750 (0.679 sec)
121.8... logprob:  0.603644, 0.289062 (0.682 sec)
121.9... logprob:  0.639313, 0.335938 (0.681 sec)
121.10... logprob:  0.596109, 0.281250 (0.680 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.634076, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.966719e-03 [6.782585e-09] 
Layer 'conv1' biases: 1.363645e-07 [1.154285e-10] 
Layer 'conv2' weights[0]: 7.953903e-03 [5.814791e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.093749e-10] 
Layer 'conv3' weights[0]: 7.952124e-03 [5.942218e-09] 
Layer 'conv3' biases: 1.403102e-06 [2.190237e-09] 
Layer 'conv4' weights[0]: 7.984605e-03 [6.456637e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.152413e-08] 
Layer 'conv5' weights[0]: 7.984090e-03 [1.442667e-07] 
Layer 'conv5' biases: 1.000008e+00 [1.578978e-07] 
Layer 'fc6' weights[0]: 7.580499e-03 [1.365421e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.311727e-08] 
Layer 'fc7' weights[0]: 7.729793e-03 [1.936214e-07] 
Layer 'fc7' biases: 9.998618e-01 [1.795521e-07] 
Layer 'fc8' weights[0]: 7.620410e-04 [1.091699e-05] 
Layer 'fc8' biases: 5.459537e-02 [1.657215e-04] 
Train error last 27 batches: 0.636807
-------------------------------------------------------
Not saving because 0.634076 > 0.627176 (56.15: -0.03%)
======================================================= (1.717 sec)
121.11... logprob:  0.640461, 0.335938 (0.697 sec)
121.12... logprob:  0.726348, 0.437500 (0.688 sec)
121.13... logprob:  0.660261, 0.359375 (0.692 sec)
121.14... logprob:  0.665611, 0.367188 (0.697 sec)
121.15... logprob:  0.688776, 0.398438 (0.691 sec)
121.16... logprob:  0.627064, 0.320312 (0.688 sec)
121.17... logprob:  0.638482, 0.335938 (0.687 sec)
121.18... logprob:  0.638245, 0.335938 (0.697 sec)
121.19... logprob:  0.633063, 0.328125 (0.688 sec)
121.20... logprob:  0.648503, 0.351562 (0.685 sec)
121.21... logprob:  0.643501, 0.343750 (0.684 sec)
121.22... logprob:  0.629457, 0.320312 (0.685 sec)
121.23... logprob:  0.625248, 0.312500 (0.690 sec)
121.24... logprob:  0.583978, 0.242188 (0.691 sec)
121.25... logprob:  0.629684, 0.320312 (0.692 sec)
121.26... logprob:  0.672245, 0.390625 (0.693 sec)
121.27... logprob:  0.629081, 0.320312 (0.688 sec)
122.1... logprob:  0.677858, 0.398438 (0.682 sec)
122.2... logprob:  0.599076, 0.273438 (0.683 sec)
122.3... logprob:  0.653518, 0.359375 (0.686 sec)
122.4... logprob:  0.597593, 0.273438 (0.686 sec)
122.5... logprob:  0.591169, 0.265625 (0.694 sec)
122.6... logprob:  0.611076, 0.296875 (0.683 sec)
122.7... logprob:  0.644210, 0.343750 (0.683 sec)
122.8... logprob:  0.603654, 0.289062 (0.686 sec)
122.9... logprob:  0.639304, 0.335938 (0.684 sec)
122.10... logprob:  0.596121, 0.281250 (0.690 sec)
122.11... logprob:  0.640446, 0.335938 (0.693 sec)
122.12... logprob:  0.726285, 0.437500 (0.683 sec)
122.13... logprob:  0.660239, 0.359375 (0.684 sec)
122.14... logprob:  0.665594, 0.367188 (0.688 sec)
122.15... logprob:  0.688761, 0.398438 (0.692 sec)
122.16... logprob:  0.627063, 0.320312 (0.687 sec)
122.17... logprob:  0.638483, 0.335938 (0.683 sec)
122.18... logprob:  0.638244, 0.335938 (0.684 sec)
122.19... logprob:  0.633059, 0.328125 (0.687 sec)
122.20... logprob:  0.648505, 0.351562 (0.684 sec)
122.21... logprob:  0.643499, 0.343750 (0.691 sec)
122.22... logprob:  0.629443, 0.320312 (0.692 sec)
122.23... logprob:  0.625230, 0.312500 (0.700 sec)
122.24... logprob:  0.583931, 0.242188 (0.683 sec)
122.25... logprob:  0.629672, 0.320312 (0.692 sec)
122.26... logprob:  0.672256, 0.390625 (0.690 sec)
122.27... logprob:  0.629073, 0.320312 (0.687 sec)
123.1... logprob:  0.677867, 0.398438 (0.683 sec)
123.2... logprob:  0.599064, 0.273438 (0.683 sec)
123.3... logprob:  0.653519, 0.359375 (0.688 sec)
123.4... logprob:  0.597590, 0.273438 (0.685 sec)
123.5... logprob:  0.591171, 0.265625 (0.686 sec)
123.6... logprob:  0.611081, 0.296875 (0.685 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627243, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.966507e-03 [7.161562e-09] 
Layer 'conv1' biases: 1.394133e-07 [1.629892e-10] 
Layer 'conv2' weights[0]: 7.953711e-03 [6.478530e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.320857e-10] 
Layer 'conv3' weights[0]: 7.951940e-03 [6.617435e-09] 
Layer 'conv3' biases: 1.427723e-06 [2.784474e-09] 
Layer 'conv4' weights[0]: 7.984405e-03 [7.179562e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.731525e-08] 
Layer 'conv5' weights[0]: 7.983901e-03 [1.824978e-07] 
Layer 'conv5' biases: 1.000009e+00 [1.996759e-07] 
Layer 'fc6' weights[0]: 7.580287e-03 [1.720410e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.668197e-08] 
Layer 'fc7' weights[0]: 7.727820e-03 [2.429246e-07] 
Layer 'fc7' biases: 9.998611e-01 [2.288562e-07] 
Layer 'fc8' weights[0]: 7.202582e-04 [1.388350e-05] 
Layer 'fc8' biases: 5.504632e-02 [2.164525e-04] 
Train error last 27 batches: 0.636791
-------------------------------------------------------
Not saving because 0.627243 > 0.627176 (56.15: -0.03%)
======================================================= (1.730 sec)
123.7... logprob:  0.644206, 0.343750 (0.697 sec)
123.8... logprob:  0.603662, 0.289062 (0.696 sec)
123.9... logprob:  0.639297, 0.335938 (0.684 sec)
123.10... logprob:  0.596132, 0.281250 (0.685 sec)
123.11... logprob:  0.640433, 0.335938 (0.688 sec)
123.12... logprob:  0.726228, 0.437500 (0.690 sec)
123.13... logprob:  0.660219, 0.359375 (0.695 sec)
123.14... logprob:  0.665578, 0.367188 (0.701 sec)
123.15... logprob:  0.688748, 0.398438 (0.694 sec)
123.16... logprob:  0.627063, 0.320312 (0.687 sec)
123.17... logprob:  0.638483, 0.335938 (0.688 sec)
123.18... logprob:  0.638244, 0.335938 (0.685 sec)
123.19... logprob:  0.633056, 0.328125 (0.688 sec)
123.20... logprob:  0.648507, 0.351562 (0.686 sec)
123.21... logprob:  0.643496, 0.343750 (0.687 sec)
123.22... logprob:  0.629430, 0.320312 (0.693 sec)
123.23... logprob:  0.625212, 0.312500 (0.697 sec)
123.24... logprob:  0.583887, 0.242188 (0.692 sec)
123.25... logprob:  0.629659, 0.320312 (0.695 sec)
123.26... logprob:  0.672266, 0.390625 (0.686 sec)
123.27... logprob:  0.629065, 0.320312 (0.688 sec)
124.1... logprob:  0.677876, 0.398438 (0.685 sec)
124.2... logprob:  0.599054, 0.273438 (0.691 sec)
124.3... logprob:  0.653519, 0.359375 (0.692 sec)
124.4... logprob:  0.597589, 0.273438 (0.687 sec)
124.5... logprob:  0.591176, 0.265625 (0.690 sec)
124.6... logprob:  0.611086, 0.296875 (0.688 sec)
124.7... logprob:  0.644201, 0.343750 (0.687 sec)
124.8... logprob:  0.603672, 0.289062 (0.687 sec)
124.9... logprob:  0.639289, 0.335938 (0.687 sec)
124.10... logprob:  0.596144, 0.281250 (0.685 sec)
124.11... logprob:  0.640419, 0.335938 (0.688 sec)
124.12... logprob:  0.726167, 0.437500 (0.686 sec)
124.13... logprob:  0.660199, 0.359375 (0.687 sec)
124.14... logprob:  0.665561, 0.367188 (0.689 sec)
124.15... logprob:  0.688734, 0.398438 (0.686 sec)
124.16... logprob:  0.627063, 0.320312 (0.689 sec)
124.17... logprob:  0.638484, 0.335938 (0.685 sec)
124.18... logprob:  0.638244, 0.335938 (0.689 sec)
124.19... logprob:  0.633052, 0.328125 (0.687 sec)
124.20... logprob:  0.648509, 0.351562 (0.688 sec)
124.21... logprob:  0.643494, 0.343750 (0.684 sec)
124.22... logprob:  0.629416, 0.320312 (0.689 sec)
124.23... logprob:  0.625194, 0.312500 (0.688 sec)
124.24... logprob:  0.583840, 0.242188 (0.688 sec)
124.25... logprob:  0.629647, 0.320312 (0.690 sec)
124.26... logprob:  0.672277, 0.390625 (0.693 sec)
124.27... logprob:  0.629058, 0.320312 (0.691 sec)
125.1... logprob:  0.677885, 0.398438 (0.686 sec)
125.2... logprob:  0.599044, 0.273438 (0.689 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.653516, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.966308e-03 [6.484318e-09] 
Layer 'conv1' biases: 1.424653e-07 [8.176577e-11] 
Layer 'conv2' weights[0]: 7.953517e-03 [4.957651e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.160497e-10] 
Layer 'conv3' weights[0]: 7.951760e-03 [4.958985e-09] 
Layer 'conv3' biases: 1.451998e-06 [1.307696e-09] 
Layer 'conv4' weights[0]: 7.984218e-03 [5.129894e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.178212e-08] 
Layer 'conv5' weights[0]: 7.983716e-03 [7.847978e-08] 
Layer 'conv5' biases: 1.000009e+00 [8.580339e-08] 
Layer 'fc6' weights[0]: 7.580101e-03 [8.251532e-09] 
Layer 'fc6' biases: 9.999999e-01 [7.135130e-09] 
Layer 'fc7' weights[0]: 7.725862e-03 [1.147232e-07] 
Layer 'fc7' biases: 9.998605e-01 [9.687082e-08] 
Layer 'fc8' weights[0]: 6.837138e-04 [5.874424e-06] 
Layer 'fc8' biases: 5.554071e-02 [1.053981e-04] 
Train error last 27 batches: 0.636776
-------------------------------------------------------
Not saving because 0.653516 > 0.627176 (56.15: -0.03%)
======================================================= (1.758 sec)
125.3... logprob:  0.653520, 0.359375 (0.680 sec)
125.4... logprob:  0.597588, 0.273438 (0.680 sec)
125.5... logprob:  0.591181, 0.265625 (0.679 sec)
125.6... logprob:  0.611091, 0.296875 (0.683 sec)
125.7... logprob:  0.644197, 0.343750 (0.685 sec)
125.8... logprob:  0.603682, 0.289062 (0.689 sec)
125.9... logprob:  0.639280, 0.335938 (0.684 sec)
125.10... logprob:  0.596156, 0.281250 (0.686 sec)
125.11... logprob:  0.640404, 0.335938 (0.686 sec)
125.12... logprob:  0.726105, 0.437500 (0.688 sec)
125.13... logprob:  0.660177, 0.359375 (0.686 sec)
125.14... logprob:  0.665543, 0.367188 (0.686 sec)
125.15... logprob:  0.688719, 0.398438 (0.686 sec)
125.16... logprob:  0.627063, 0.320312 (0.687 sec)
125.17... logprob:  0.638485, 0.335938 (0.684 sec)
125.18... logprob:  0.638243, 0.335938 (0.686 sec)
125.19... logprob:  0.633048, 0.328125 (0.685 sec)
125.20... logprob:  0.648510, 0.351562 (0.688 sec)
125.21... logprob:  0.643491, 0.343750 (0.689 sec)
125.22... logprob:  0.629404, 0.320312 (0.723 sec)
125.23... logprob:  0.625177, 0.312500 (0.698 sec)
125.24... logprob:  0.583795, 0.242188 (0.685 sec)
125.25... logprob:  0.629634, 0.320312 (0.687 sec)
125.26... logprob:  0.672288, 0.390625 (0.686 sec)
125.27... logprob:  0.629049, 0.320312 (0.686 sec)
126.1... logprob:  0.677894, 0.398438 (0.684 sec)
126.2... logprob:  0.599032, 0.273438 (0.687 sec)
126.3... logprob:  0.653521, 0.359375 (0.679 sec)
126.4... logprob:  0.597586, 0.273438 (0.678 sec)
126.5... logprob:  0.591184, 0.265625 (0.680 sec)
126.6... logprob:  0.611095, 0.296875 (0.678 sec)
126.7... logprob:  0.644193, 0.343750 (0.680 sec)
126.8... logprob:  0.603690, 0.289062 (0.684 sec)
126.9... logprob:  0.639273, 0.335938 (0.682 sec)
126.10... logprob:  0.596167, 0.281250 (0.685 sec)
126.11... logprob:  0.640392, 0.335938 (0.682 sec)
126.12... logprob:  0.726049, 0.437500 (0.678 sec)
126.13... logprob:  0.660158, 0.359375 (0.678 sec)
126.14... logprob:  0.665527, 0.367188 (0.683 sec)
126.15... logprob:  0.688706, 0.398438 (0.678 sec)
126.16... logprob:  0.627063, 0.320312 (0.682 sec)
126.17... logprob:  0.638486, 0.335938 (0.680 sec)
126.18... logprob:  0.638243, 0.335938 (0.681 sec)
126.19... logprob:  0.633044, 0.328125 (0.680 sec)
126.20... logprob:  0.648512, 0.351562 (0.679 sec)
126.21... logprob:  0.643489, 0.343750 (0.681 sec)
126.22... logprob:  0.629391, 0.320312 (0.679 sec)
126.23... logprob:  0.625160, 0.312500 (0.682 sec)
126.24... logprob:  0.583751, 0.242188 (0.681 sec)
126.25... logprob:  0.629623, 0.320312 (0.693 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.629271, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.966107e-03 [6.200006e-09] 
Layer 'conv1' biases: 1.453763e-07 [7.815684e-11] 
Layer 'conv2' weights[0]: 7.953327e-03 [4.942717e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.425033e-10] 
Layer 'conv3' weights[0]: 7.951539e-03 [4.956497e-09] 
Layer 'conv3' biases: 1.474077e-06 [1.393635e-09] 
Layer 'conv4' weights[0]: 7.984018e-03 [5.211551e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.316042e-08] 
Layer 'conv5' weights[0]: 7.983526e-03 [8.712894e-08] 
Layer 'conv5' biases: 1.000009e+00 [9.527603e-08] 
Layer 'fc6' weights[0]: 7.579907e-03 [9.024527e-09] 
Layer 'fc6' biases: 9.999999e-01 [7.964014e-09] 
Layer 'fc7' weights[0]: 7.723915e-03 [1.249474e-07] 
Layer 'fc7' biases: 9.998601e-01 [1.080787e-07] 
Layer 'fc8' weights[0]: 6.689832e-04 [6.547236e-06] 
Layer 'fc8' biases: 5.636207e-02 [1.242551e-04] 
Train error last 27 batches: 0.636762
-------------------------------------------------------
Not saving because 0.629271 > 0.627176 (56.15: -0.03%)
======================================================= (1.793 sec)
126.26... logprob:  0.672298, 0.390625 (0.683 sec)
126.27... logprob:  0.629042, 0.320312 (0.679 sec)
127.1... logprob:  0.677902, 0.398438 (0.684 sec)
127.2... logprob:  0.599023, 0.273438 (0.682 sec)
127.3... logprob:  0.653522, 0.359375 (0.680 sec)
127.4... logprob:  0.597586, 0.273438 (0.677 sec)
127.5... logprob:  0.591189, 0.265625 (0.684 sec)
127.6... logprob:  0.611101, 0.296875 (0.681 sec)
127.7... logprob:  0.644188, 0.343750 (0.681 sec)
127.8... logprob:  0.603700, 0.289062 (0.687 sec)
127.9... logprob:  0.639265, 0.335938 (0.685 sec)
127.10... logprob:  0.596178, 0.281250 (0.687 sec)
127.11... logprob:  0.640378, 0.335938 (0.684 sec)
127.12... logprob:  0.725989, 0.437500 (0.682 sec)
127.13... logprob:  0.660137, 0.359375 (0.691 sec)
127.14... logprob:  0.665510, 0.367188 (0.707 sec)
127.15... logprob:  0.688692, 0.398438 (0.702 sec)
127.16... logprob:  0.627063, 0.320312 (0.683 sec)
127.17... logprob:  0.638487, 0.335938 (0.678 sec)
127.18... logprob:  0.638243, 0.335938 (0.679 sec)
127.19... logprob:  0.633040, 0.328125 (0.688 sec)
127.20... logprob:  0.648514, 0.351562 (0.676 sec)
127.21... logprob:  0.643486, 0.343750 (0.679 sec)
127.22... logprob:  0.629378, 0.320312 (0.678 sec)
127.23... logprob:  0.625143, 0.312500 (0.677 sec)
127.24... logprob:  0.583706, 0.242188 (0.686 sec)
127.25... logprob:  0.629610, 0.320312 (0.684 sec)
127.26... logprob:  0.672309, 0.390625 (0.680 sec)
127.27... logprob:  0.629034, 0.320312 (0.679 sec)
128.1... logprob:  0.677911, 0.398438 (0.687 sec)
128.2... logprob:  0.599011, 0.273438 (0.683 sec)
128.3... logprob:  0.653522, 0.359375 (0.688 sec)
128.4... logprob:  0.597583, 0.273438 (0.681 sec)
128.5... logprob:  0.591192, 0.265625 (0.682 sec)
128.6... logprob:  0.611105, 0.296875 (0.681 sec)
128.7... logprob:  0.644184, 0.343750 (0.684 sec)
128.8... logprob:  0.603709, 0.289062 (0.681 sec)
128.9... logprob:  0.639258, 0.335938 (0.681 sec)
128.10... logprob:  0.596189, 0.281250 (0.681 sec)
128.11... logprob:  0.640365, 0.335938 (0.681 sec)
128.12... logprob:  0.725932, 0.437500 (0.679 sec)
128.13... logprob:  0.660117, 0.359375 (0.683 sec)
128.14... logprob:  0.665495, 0.367188 (0.678 sec)
128.15... logprob:  0.688679, 0.398438 (0.683 sec)
128.16... logprob:  0.627063, 0.320312 (0.680 sec)
128.17... logprob:  0.638487, 0.335938 (0.679 sec)
128.18... logprob:  0.638243, 0.335938 (0.680 sec)
128.19... logprob:  0.633037, 0.328125 (0.682 sec)
128.20... logprob:  0.648516, 0.351562 (0.683 sec)
128.21... logprob:  0.643484, 0.343750 (0.687 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.634138, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.965906e-03 [6.386287e-09] 
Layer 'conv1' biases: 1.481932e-07 [1.394519e-10] 
Layer 'conv2' weights[0]: 7.953125e-03 [6.069262e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.856375e-10] 
Layer 'conv3' weights[0]: 7.951338e-03 [5.541568e-09] 
Layer 'conv3' biases: 1.494977e-06 [1.968631e-09] 
Layer 'conv4' weights[0]: 7.983827e-03 [5.694916e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.663936e-08] 
Layer 'conv5' weights[0]: 7.983330e-03 [1.105371e-07] 
Layer 'conv5' biases: 1.000009e+00 [1.206921e-07] 
Layer 'fc6' weights[0]: 7.579703e-03 [1.102142e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.035311e-08] 
Layer 'fc7' weights[0]: 7.721953e-03 [1.579366e-07] 
Layer 'fc7' biases: 9.998601e-01 [1.444985e-07] 
Layer 'fc8' weights[0]: 6.652680e-04 [8.681368e-06] 
Layer 'fc8' biases: 5.734344e-02 [1.077967e-04] 
Train error last 27 batches: 0.636750
-------------------------------------------------------
Not saving because 0.634138 > 0.627176 (56.15: -0.03%)
======================================================= (1.772 sec)
128.22... logprob:  0.629365, 0.320312 (0.684 sec)
128.23... logprob:  0.625125, 0.312500 (0.685 sec)
128.24... logprob:  0.583662, 0.242188 (0.682 sec)
128.25... logprob:  0.629599, 0.320312 (0.684 sec)
128.26... logprob:  0.672319, 0.390625 (0.681 sec)
128.27... logprob:  0.629027, 0.320312 (0.680 sec)
129.1... logprob:  0.677919, 0.398438 (0.685 sec)
129.2... logprob:  0.599002, 0.273438 (0.685 sec)
129.3... logprob:  0.653523, 0.359375 (0.692 sec)
129.4... logprob:  0.597582, 0.273438 (0.681 sec)
129.5... logprob:  0.591197, 0.265625 (0.678 sec)
129.6... logprob:  0.611110, 0.296875 (0.684 sec)
129.7... logprob:  0.644180, 0.343750 (0.693 sec)
129.8... logprob:  0.603719, 0.289062 (0.698 sec)
129.9... logprob:  0.639250, 0.335938 (0.679 sec)
129.10... logprob:  0.596201, 0.281250 (0.682 sec)
129.11... logprob:  0.640351, 0.335938 (0.679 sec)
129.12... logprob:  0.725873, 0.437500 (0.683 sec)
129.13... logprob:  0.660097, 0.359375 (0.679 sec)
129.14... logprob:  0.665478, 0.367188 (0.680 sec)
129.15... logprob:  0.688664, 0.398438 (0.680 sec)
129.16... logprob:  0.627063, 0.320312 (0.682 sec)
129.17... logprob:  0.638488, 0.335938 (0.689 sec)
129.18... logprob:  0.638243, 0.335938 (0.687 sec)
129.19... logprob:  0.633033, 0.328125 (0.684 sec)
129.20... logprob:  0.648517, 0.351562 (0.682 sec)
129.21... logprob:  0.643482, 0.343750 (0.682 sec)
129.22... logprob:  0.629352, 0.320312 (0.683 sec)
129.23... logprob:  0.625108, 0.312500 (0.681 sec)
129.24... logprob:  0.583617, 0.242188 (0.682 sec)
129.25... logprob:  0.629586, 0.320312 (0.678 sec)
129.26... logprob:  0.672330, 0.390625 (0.681 sec)
129.27... logprob:  0.629019, 0.320312 (0.678 sec)
130.1... logprob:  0.677928, 0.398438 (0.676 sec)
130.2... logprob:  0.598991, 0.273438 (0.697 sec)
130.3... logprob:  0.653524, 0.359375 (0.703 sec)
130.4... logprob:  0.597580, 0.273438 (0.686 sec)
130.5... logprob:  0.591200, 0.265625 (0.684 sec)
130.6... logprob:  0.611115, 0.296875 (0.685 sec)
130.7... logprob:  0.644176, 0.343750 (0.685 sec)
130.8... logprob:  0.603727, 0.289062 (0.679 sec)
130.9... logprob:  0.639243, 0.335938 (0.682 sec)
130.10... logprob:  0.596212, 0.281250 (0.679 sec)
130.11... logprob:  0.640338, 0.335938 (0.681 sec)
130.12... logprob:  0.725815, 0.437500 (0.681 sec)
130.13... logprob:  0.660077, 0.359375 (0.680 sec)
130.14... logprob:  0.665461, 0.367188 (0.681 sec)
130.15... logprob:  0.688650, 0.398438 (0.686 sec)
130.16... logprob:  0.627062, 0.320312 (0.681 sec)
130.17... logprob:  0.638489, 0.335938 (0.685 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.686848, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.965706e-03 [6.628183e-09] 
Layer 'conv1' biases: 1.507414e-07 [1.816513e-10] 
Layer 'conv2' weights[0]: 7.952921e-03 [7.342280e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.013116e-09] 
Layer 'conv3' weights[0]: 7.951135e-03 [6.685097e-09] 
Layer 'conv3' biases: 1.511273e-06 [2.916195e-09] 
Layer 'conv4' weights[0]: 7.983618e-03 [7.130670e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.658349e-08] 
Layer 'conv5' weights[0]: 7.983116e-03 [1.760747e-07] 
Layer 'conv5' biases: 1.000009e+00 [1.922230e-07] 
Layer 'fc6' weights[0]: 7.579499e-03 [1.693531e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.648178e-08] 
Layer 'fc7' weights[0]: 7.719968e-03 [2.416168e-07] 
Layer 'fc7' biases: 9.998605e-01 [2.287006e-07] 
Layer 'fc8' weights[0]: 7.013012e-04 [1.376393e-05] 
Layer 'fc8' biases: 5.898612e-02 [1.734710e-04] 
Train error last 27 batches: 0.636736
-------------------------------------------------------
Not saving because 0.686848 > 0.627176 (56.15: -0.03%)
======================================================= (1.713 sec)
130.18... logprob:  0.638242, 0.335938 (0.681 sec)
130.19... logprob:  0.633029, 0.328125 (0.686 sec)
130.20... logprob:  0.648519, 0.351562 (0.689 sec)
130.21... logprob:  0.643480, 0.343750 (0.686 sec)
130.22... logprob:  0.629340, 0.320312 (0.678 sec)
130.23... logprob:  0.625092, 0.312500 (0.680 sec)
130.24... logprob:  0.583574, 0.242188 (0.679 sec)
130.25... logprob:  0.629575, 0.320312 (0.679 sec)
130.26... logprob:  0.672340, 0.390625 (0.684 sec)
130.27... logprob:  0.629012, 0.320312 (0.679 sec)
131.1... logprob:  0.677937, 0.398438 (0.686 sec)
131.2... logprob:  0.598980, 0.273438 (0.687 sec)
131.3... logprob:  0.653524, 0.359375 (0.689 sec)
131.4... logprob:  0.597579, 0.273438 (0.689 sec)
131.5... logprob:  0.591203, 0.265625 (0.703 sec)
131.6... logprob:  0.611120, 0.296875 (0.690 sec)
131.7... logprob:  0.644172, 0.343750 (0.687 sec)
131.8... logprob:  0.603736, 0.289062 (0.687 sec)
131.9... logprob:  0.639236, 0.335938 (0.683 sec)
131.10... logprob:  0.596224, 0.281250 (0.683 sec)
131.11... logprob:  0.640325, 0.335938 (0.680 sec)
131.12... logprob:  0.725758, 0.437500 (0.684 sec)
131.13... logprob:  0.660057, 0.359375 (0.682 sec)
131.14... logprob:  0.665445, 0.367188 (0.685 sec)
131.15... logprob:  0.688636, 0.398438 (0.681 sec)
131.16... logprob:  0.627062, 0.320312 (0.682 sec)
131.17... logprob:  0.638489, 0.335938 (0.683 sec)
131.18... logprob:  0.638242, 0.335938 (0.684 sec)
131.19... logprob:  0.633026, 0.328125 (0.689 sec)
131.20... logprob:  0.648521, 0.351562 (0.694 sec)
131.21... logprob:  0.643478, 0.343750 (0.682 sec)
131.22... logprob:  0.629327, 0.320312 (0.683 sec)
131.23... logprob:  0.625075, 0.312500 (0.680 sec)
131.24... logprob:  0.583530, 0.242188 (0.682 sec)
131.25... logprob:  0.629564, 0.320312 (0.681 sec)
131.26... logprob:  0.672351, 0.390625 (0.682 sec)
131.27... logprob:  0.629005, 0.320312 (0.678 sec)
132.1... logprob:  0.677945, 0.398438 (0.680 sec)
132.2... logprob:  0.598970, 0.273438 (0.693 sec)
132.3... logprob:  0.653525, 0.359375 (0.698 sec)
132.4... logprob:  0.597577, 0.273438 (0.679 sec)
132.5... logprob:  0.591207, 0.265625 (0.680 sec)
132.6... logprob:  0.611124, 0.296875 (0.688 sec)
132.7... logprob:  0.644168, 0.343750 (0.682 sec)
132.8... logprob:  0.603745, 0.289062 (0.686 sec)
132.9... logprob:  0.639228, 0.335938 (0.680 sec)
132.10... logprob:  0.596235, 0.281250 (0.686 sec)
132.11... logprob:  0.640312, 0.335938 (0.680 sec)
132.12... logprob:  0.725700, 0.437500 (0.677 sec)
132.13... logprob:  0.660037, 0.359375 (0.683 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633813, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.965505e-03 [6.516880e-09] 
Layer 'conv1' biases: 1.531920e-07 [1.139390e-10] 
Layer 'conv2' weights[0]: 7.952732e-03 [5.785295e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.123058e-10] 
Layer 'conv3' weights[0]: 7.950940e-03 [5.212800e-09] 
Layer 'conv3' biases: 1.527220e-06 [1.717582e-09] 
Layer 'conv4' weights[0]: 7.983431e-03 [5.323286e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.395869e-08] 
Layer 'conv5' weights[0]: 7.982890e-03 [9.216790e-08] 
Layer 'conv5' biases: 1.000008e+00 [1.006150e-07] 
Layer 'fc6' weights[0]: 7.579298e-03 [9.687515e-09] 
Layer 'fc6' biases: 9.999999e-01 [8.721272e-09] 
Layer 'fc7' weights[0]: 7.717983e-03 [1.363929e-07] 
Layer 'fc7' biases: 9.998612e-01 [1.218113e-07] 
Layer 'fc8' weights[0]: 7.501767e-04 [7.309426e-06] 
Layer 'fc8' biases: 6.078923e-02 [7.926687e-05] 
Train error last 27 batches: 0.636723
-------------------------------------------------------
Not saving because 0.633813 > 0.627176 (56.15: -0.03%)
======================================================= (1.728 sec)
132.14... logprob:  0.665428, 0.367188 (0.686 sec)
132.15... logprob:  0.688622, 0.398438 (0.679 sec)
132.16... logprob:  0.627062, 0.320312 (0.679 sec)
132.17... logprob:  0.638490, 0.335938 (0.690 sec)
132.18... logprob:  0.638242, 0.335938 (0.679 sec)
132.19... logprob:  0.633022, 0.328125 (0.679 sec)
132.20... logprob:  0.648523, 0.351562 (0.682 sec)
132.21... logprob:  0.643476, 0.343750 (0.680 sec)
132.22... logprob:  0.629315, 0.320312 (0.679 sec)
132.23... logprob:  0.625058, 0.312500 (0.679 sec)
132.24... logprob:  0.583487, 0.242188 (0.679 sec)
132.25... logprob:  0.629552, 0.320312 (0.678 sec)
132.26... logprob:  0.672361, 0.390625 (0.679 sec)
132.27... logprob:  0.628997, 0.320312 (0.681 sec)
133.1... logprob:  0.677954, 0.398438 (0.677 sec)
133.2... logprob:  0.598959, 0.273438 (0.680 sec)
133.3... logprob:  0.653526, 0.359375 (0.677 sec)
133.4... logprob:  0.597575, 0.273438 (0.678 sec)
133.5... logprob:  0.591210, 0.265625 (0.678 sec)
133.6... logprob:  0.611128, 0.296875 (0.686 sec)
133.7... logprob:  0.644164, 0.343750 (0.691 sec)
133.8... logprob:  0.603754, 0.289062 (0.686 sec)
133.9... logprob:  0.639221, 0.335938 (0.682 sec)
133.10... logprob:  0.596246, 0.281250 (0.683 sec)
133.11... logprob:  0.640299, 0.335938 (0.678 sec)
133.12... logprob:  0.725644, 0.437500 (0.681 sec)
133.13... logprob:  0.660018, 0.359375 (0.681 sec)
133.14... logprob:  0.665413, 0.367188 (0.680 sec)
133.15... logprob:  0.688609, 0.398438 (0.681 sec)
133.16... logprob:  0.627062, 0.320312 (0.683 sec)
133.17... logprob:  0.638491, 0.335938 (0.681 sec)
133.18... logprob:  0.638241, 0.335938 (0.685 sec)
133.19... logprob:  0.633019, 0.328125 (0.682 sec)
133.20... logprob:  0.648525, 0.351562 (0.682 sec)
133.21... logprob:  0.643473, 0.343750 (0.682 sec)
133.22... logprob:  0.629303, 0.320312 (0.686 sec)
133.23... logprob:  0.625042, 0.312500 (0.679 sec)
133.24... logprob:  0.583444, 0.242188 (0.677 sec)
133.25... logprob:  0.629540, 0.320312 (0.681 sec)
133.26... logprob:  0.672371, 0.390625 (0.681 sec)
133.27... logprob:  0.628990, 0.320312 (0.682 sec)
134.1... logprob:  0.677963, 0.398438 (0.679 sec)
134.2... logprob:  0.598949, 0.273438 (0.681 sec)
134.3... logprob:  0.653526, 0.359375 (0.683 sec)
134.4... logprob:  0.597573, 0.273438 (0.680 sec)
134.5... logprob:  0.591213, 0.265625 (0.682 sec)
134.6... logprob:  0.611133, 0.296875 (0.682 sec)
134.7... logprob:  0.644160, 0.343750 (0.681 sec)
134.8... logprob:  0.603763, 0.289062 (0.682 sec)
134.9... logprob:  0.639214, 0.335938 (0.683 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627341, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.965296e-03 [6.551005e-09] 
Layer 'conv1' biases: 1.560247e-07 [1.043906e-10] 
Layer 'conv2' weights[0]: 7.952523e-03 [5.575822e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.355703e-10] 
Layer 'conv3' weights[0]: 7.950733e-03 [5.666075e-09] 
Layer 'conv3' biases: 1.548514e-06 [1.929965e-09] 
Layer 'conv4' weights[0]: 7.983243e-03 [6.086912e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.880238e-08] 
Layer 'conv5' weights[0]: 7.982702e-03 [1.247479e-07] 
Layer 'conv5' biases: 1.000008e+00 [1.363611e-07] 
Layer 'fc6' weights[0]: 7.579113e-03 [1.217268e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.155878e-08] 
Layer 'fc7' weights[0]: 7.716045e-03 [1.712027e-07] 
Layer 'fc7' biases: 9.998611e-01 [1.569528e-07] 
Layer 'fc8' weights[0]: 7.417759e-04 [9.485398e-06] 
Layer 'fc8' biases: 6.171119e-02 [1.519732e-04] 
Train error last 27 batches: 0.636712
-------------------------------------------------------
Not saving because 0.627341 > 0.627176 (56.15: -0.03%)
======================================================= (1.742 sec)
134.10... logprob:  0.596257, 0.281250 (0.683 sec)
134.11... logprob:  0.640286, 0.335938 (0.681 sec)
134.12... logprob:  0.725587, 0.437500 (0.678 sec)
134.13... logprob:  0.659998, 0.359375 (0.680 sec)
134.14... logprob:  0.665396, 0.367188 (0.679 sec)
134.15... logprob:  0.688594, 0.398438 (0.682 sec)
134.16... logprob:  0.627062, 0.320312 (0.678 sec)
134.17... logprob:  0.638491, 0.335938 (0.681 sec)
134.18... logprob:  0.638241, 0.335938 (0.678 sec)
134.19... logprob:  0.633015, 0.328125 (0.681 sec)
134.20... logprob:  0.648527, 0.351562 (0.682 sec)
134.21... logprob:  0.643472, 0.343750 (0.678 sec)
134.22... logprob:  0.629291, 0.320312 (0.676 sec)
134.23... logprob:  0.625026, 0.312500 (0.679 sec)
134.24... logprob:  0.583401, 0.242188 (0.678 sec)
134.25... logprob:  0.629529, 0.320312 (0.679 sec)
134.26... logprob:  0.672382, 0.390625 (0.680 sec)
134.27... logprob:  0.628983, 0.320312 (0.681 sec)
135.1... logprob:  0.677971, 0.398438 (0.677 sec)
135.2... logprob:  0.598939, 0.273438 (0.683 sec)
135.3... logprob:  0.653527, 0.359375 (0.678 sec)
135.4... logprob:  0.597571, 0.273438 (0.680 sec)
135.5... logprob:  0.591217, 0.265625 (0.680 sec)
135.6... logprob:  0.611138, 0.296875 (0.680 sec)
135.7... logprob:  0.644156, 0.343750 (0.683 sec)
135.8... logprob:  0.603771, 0.289062 (0.678 sec)
135.9... logprob:  0.639207, 0.335938 (0.683 sec)
135.10... logprob:  0.596268, 0.281250 (0.684 sec)
135.11... logprob:  0.640274, 0.335938 (0.695 sec)
135.12... logprob:  0.725531, 0.437500 (0.683 sec)
135.13... logprob:  0.659979, 0.359375 (0.679 sec)
135.14... logprob:  0.665380, 0.367188 (0.681 sec)
135.15... logprob:  0.688580, 0.398438 (0.678 sec)
135.16... logprob:  0.627062, 0.320312 (0.681 sec)
135.17... logprob:  0.638492, 0.335938 (0.678 sec)
135.18... logprob:  0.638241, 0.335938 (0.680 sec)
135.19... logprob:  0.633012, 0.328125 (0.678 sec)
135.20... logprob:  0.648528, 0.351562 (0.680 sec)
135.21... logprob:  0.643469, 0.343750 (0.677 sec)
135.22... logprob:  0.629280, 0.320312 (0.691 sec)
135.23... logprob:  0.625010, 0.312500 (0.691 sec)
135.24... logprob:  0.583360, 0.242188 (0.682 sec)
135.25... logprob:  0.629518, 0.320312 (0.680 sec)
135.26... logprob:  0.672392, 0.390625 (0.682 sec)
135.27... logprob:  0.628975, 0.320312 (0.676 sec)
136.1... logprob:  0.677980, 0.398438 (0.685 sec)
136.2... logprob:  0.598927, 0.273438 (0.692 sec)
136.3... logprob:  0.653528, 0.359375 (0.683 sec)
136.4... logprob:  0.597568, 0.273438 (0.678 sec)
136.5... logprob:  0.591219, 0.265625 (0.680 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.654541, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.965084e-03 [7.264311e-09] 
Layer 'conv1' biases: 1.590874e-07 [1.459895e-10] 
Layer 'conv2' weights[0]: 7.952325e-03 [6.236144e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.381684e-10] 
Layer 'conv3' weights[0]: 7.950539e-03 [6.304614e-09] 
Layer 'conv3' biases: 1.573172e-06 [2.475291e-09] 
Layer 'conv4' weights[0]: 7.983039e-03 [6.758191e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.392664e-08] 
Layer 'conv5' weights[0]: 7.982528e-03 [1.583763e-07] 
Layer 'conv5' biases: 1.000008e+00 [1.729266e-07] 
Layer 'fc6' weights[0]: 7.578920e-03 [1.528159e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.476552e-08] 
Layer 'fc7' weights[0]: 7.714046e-03 [2.150477e-07] 
Layer 'fc7' biases: 9.998601e-01 [2.010506e-07] 
Layer 'fc8' weights[0]: 6.988117e-04 [1.211496e-05] 
Layer 'fc8' biases: 6.207651e-02 [1.969385e-04] 
Train error last 27 batches: 0.636698
-------------------------------------------------------
Not saving because 0.654541 > 0.627176 (56.15: -0.03%)
======================================================= (1.740 sec)
136.6... logprob:  0.611141, 0.296875 (0.678 sec)
136.7... logprob:  0.644152, 0.343750 (0.679 sec)
136.8... logprob:  0.603780, 0.289062 (0.681 sec)
136.9... logprob:  0.639201, 0.335938 (0.682 sec)
136.10... logprob:  0.596279, 0.281250 (0.686 sec)
136.11... logprob:  0.640262, 0.335938 (0.689 sec)
136.12... logprob:  0.725478, 0.437500 (0.682 sec)
136.13... logprob:  0.659961, 0.359375 (0.683 sec)
136.14... logprob:  0.665365, 0.367188 (0.681 sec)
136.15... logprob:  0.688567, 0.398438 (0.679 sec)
136.16... logprob:  0.627061, 0.320312 (0.680 sec)
136.17... logprob:  0.638493, 0.335938 (0.681 sec)
136.18... logprob:  0.638241, 0.335938 (0.678 sec)
136.19... logprob:  0.633009, 0.328125 (0.681 sec)
136.20... logprob:  0.648530, 0.351562 (0.680 sec)
136.21... logprob:  0.643468, 0.343750 (0.686 sec)
136.22... logprob:  0.629268, 0.320312 (0.679 sec)
136.23... logprob:  0.624994, 0.312500 (0.680 sec)
136.24... logprob:  0.583318, 0.242188 (0.679 sec)
136.25... logprob:  0.629506, 0.320312 (0.683 sec)
136.26... logprob:  0.672402, 0.390625 (0.683 sec)
136.27... logprob:  0.628969, 0.320312 (0.682 sec)
137.1... logprob:  0.677988, 0.398438 (0.690 sec)
137.2... logprob:  0.598918, 0.273438 (0.692 sec)
137.3... logprob:  0.653529, 0.359375 (0.685 sec)
137.4... logprob:  0.597567, 0.273438 (0.689 sec)
137.5... logprob:  0.591223, 0.265625 (0.678 sec)
137.6... logprob:  0.611146, 0.296875 (0.681 sec)
137.7... logprob:  0.644149, 0.343750 (0.684 sec)
137.8... logprob:  0.603789, 0.289062 (0.682 sec)
137.9... logprob:  0.639193, 0.335938 (0.684 sec)
137.10... logprob:  0.596290, 0.281250 (0.682 sec)
137.11... logprob:  0.640249, 0.335938 (0.684 sec)
137.12... logprob:  0.725420, 0.437500 (0.683 sec)
137.13... logprob:  0.659941, 0.359375 (0.684 sec)
137.14... logprob:  0.665348, 0.367188 (0.685 sec)
137.15... logprob:  0.688553, 0.398438 (0.682 sec)
137.16... logprob:  0.627061, 0.320312 (0.688 sec)
137.17... logprob:  0.638494, 0.335938 (0.683 sec)
137.18... logprob:  0.638241, 0.335938 (0.683 sec)
137.19... logprob:  0.633005, 0.328125 (0.700 sec)
137.20... logprob:  0.648532, 0.351562 (0.679 sec)
137.21... logprob:  0.643466, 0.343750 (0.679 sec)
137.22... logprob:  0.629256, 0.320312 (0.680 sec)
137.23... logprob:  0.624978, 0.312500 (0.681 sec)
137.24... logprob:  0.583275, 0.242188 (0.684 sec)
137.25... logprob:  0.629495, 0.320312 (0.680 sec)
137.26... logprob:  0.672412, 0.390625 (0.679 sec)
137.27... logprob:  0.628961, 0.320312 (0.676 sec)
138.1... logprob:  0.677997, 0.398438 (0.678 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.628690, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.964877e-03 [6.221559e-09] 
Layer 'conv1' biases: 1.620907e-07 [5.757196e-11] 
Layer 'conv2' weights[0]: 7.952120e-03 [4.618646e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.862844e-10] 
Layer 'conv3' weights[0]: 7.950336e-03 [4.317588e-09] 
Layer 'conv3' biases: 1.596498e-06 [5.329452e-10] 
Layer 'conv4' weights[0]: 7.982835e-03 [4.261812e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.993520e-09] 
Layer 'conv5' weights[0]: 7.982335e-03 [1.361618e-08] 
Layer 'conv5' biases: 1.000008e+00 [1.436151e-08] 
Layer 'fc6' weights[0]: 7.578732e-03 [4.012888e-09] 
Layer 'fc6' biases: 9.999999e-01 [1.165032e-09] 
Layer 'fc7' weights[0]: 7.712019e-03 [4.330055e-08] 
Layer 'fc7' biases: 9.998597e-01 [1.480919e-08] 
Layer 'fc8' weights[0]: 6.711591e-04 [8.987282e-07] 
Layer 'fc8' biases: 6.265913e-02 [3.027623e-05] 
Train error last 27 batches: 0.636685
-------------------------------------------------------
Not saving because 0.628690 > 0.627176 (56.15: -0.03%)
======================================================= (1.860 sec)
138.2... logprob:  0.598907, 0.273438 (0.683 sec)
138.3... logprob:  0.653529, 0.359375 (0.678 sec)
138.4... logprob:  0.597565, 0.273438 (0.678 sec)
138.5... logprob:  0.591225, 0.265625 (0.677 sec)
138.6... logprob:  0.611150, 0.296875 (0.680 sec)
138.7... logprob:  0.644145, 0.343750 (0.678 sec)
138.8... logprob:  0.603797, 0.289062 (0.679 sec)
138.9... logprob:  0.639187, 0.335938 (0.679 sec)
138.10... logprob:  0.596301, 0.281250 (0.678 sec)
138.11... logprob:  0.640236, 0.335938 (0.678 sec)
138.12... logprob:  0.725364, 0.437500 (0.677 sec)
138.13... logprob:  0.659921, 0.359375 (0.677 sec)
138.14... logprob:  0.665332, 0.367188 (0.687 sec)
138.15... logprob:  0.688539, 0.398438 (0.683 sec)
138.16... logprob:  0.627061, 0.320312 (0.680 sec)
138.17... logprob:  0.638494, 0.335938 (0.679 sec)
138.18... logprob:  0.638241, 0.335938 (0.680 sec)
138.19... logprob:  0.633002, 0.328125 (0.679 sec)
138.20... logprob:  0.648534, 0.351562 (0.680 sec)
138.21... logprob:  0.643464, 0.343750 (0.685 sec)
138.22... logprob:  0.629244, 0.320312 (0.684 sec)
138.23... logprob:  0.624961, 0.312500 (0.691 sec)
138.24... logprob:  0.583232, 0.242188 (0.682 sec)
138.25... logprob:  0.629484, 0.320312 (0.680 sec)
138.26... logprob:  0.672423, 0.390625 (0.681 sec)
138.27... logprob:  0.628954, 0.320312 (0.678 sec)
139.1... logprob:  0.678005, 0.398438 (0.677 sec)
139.2... logprob:  0.598897, 0.273438 (0.684 sec)
139.3... logprob:  0.653530, 0.359375 (0.682 sec)
139.4... logprob:  0.597564, 0.273438 (0.682 sec)
139.5... logprob:  0.591229, 0.265625 (0.688 sec)
139.6... logprob:  0.611155, 0.296875 (0.692 sec)
139.7... logprob:  0.644141, 0.343750 (0.688 sec)
139.8... logprob:  0.603807, 0.289062 (0.686 sec)
139.9... logprob:  0.639179, 0.335938 (0.684 sec)
139.10... logprob:  0.596313, 0.281250 (0.692 sec)
139.11... logprob:  0.640223, 0.335938 (0.683 sec)
139.12... logprob:  0.725306, 0.437500 (0.680 sec)
139.13... logprob:  0.659901, 0.359375 (0.695 sec)
139.14... logprob:  0.665315, 0.367188 (0.687 sec)
139.15... logprob:  0.688524, 0.398438 (0.680 sec)
139.16... logprob:  0.627061, 0.320312 (0.679 sec)
139.17... logprob:  0.638495, 0.335938 (0.678 sec)
139.18... logprob:  0.638240, 0.335938 (0.677 sec)
139.19... logprob:  0.632999, 0.328125 (0.682 sec)
139.20... logprob:  0.648536, 0.351562 (0.683 sec)
139.21... logprob:  0.643462, 0.343750 (0.681 sec)
139.22... logprob:  0.629232, 0.320312 (0.681 sec)
139.23... logprob:  0.624946, 0.312500 (0.682 sec)
139.24... logprob:  0.583191, 0.242188 (0.680 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.634199, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.964676e-03 [6.082901e-09] 
Layer 'conv1' biases: 1.649973e-07 [6.111348e-11] 
Layer 'conv2' weights[0]: 7.951933e-03 [4.717313e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.368507e-10] 
Layer 'conv3' weights[0]: 7.950127e-03 [4.628084e-09] 
Layer 'conv3' biases: 1.618633e-06 [1.061259e-09] 
Layer 'conv4' weights[0]: 7.982645e-03 [4.748328e-09] 
Layer 'conv4' biases: 1.000001e+00 [9.398658e-09] 
Layer 'conv5' weights[0]: 7.982124e-03 [6.144683e-08] 
Layer 'conv5' biases: 1.000009e+00 [6.693757e-08] 
Layer 'fc6' weights[0]: 7.578536e-03 [6.968622e-09] 
Layer 'fc6' biases: 9.999999e-01 [5.714262e-09] 
Layer 'fc7' weights[0]: 7.710057e-03 [9.496294e-08] 
Layer 'fc7' biases: 9.998593e-01 [7.660724e-08] 
Layer 'fc8' weights[0]: 6.572038e-04 [4.612169e-06] 
Layer 'fc8' biases: 6.344048e-02 [9.689573e-05] 
Train error last 27 batches: 0.636671
-------------------------------------------------------
Not saving because 0.634199 > 0.627176 (56.15: -0.03%)
======================================================= (1.757 sec)
139.25... logprob:  0.629472, 0.320312 (0.680 sec)
139.26... logprob:  0.672433, 0.390625 (0.684 sec)
139.27... logprob:  0.628946, 0.320312 (0.682 sec)
140.1... logprob:  0.678015, 0.398438 (0.684 sec)
140.2... logprob:  0.598885, 0.273438 (0.689 sec)
140.3... logprob:  0.653531, 0.359375 (0.683 sec)
140.4... logprob:  0.597560, 0.273438 (0.682 sec)
140.5... logprob:  0.591231, 0.265625 (0.685 sec)
140.6... logprob:  0.611158, 0.296875 (0.686 sec)
140.7... logprob:  0.644137, 0.343750 (0.688 sec)
140.8... logprob:  0.603814, 0.289062 (0.685 sec)
140.9... logprob:  0.639174, 0.335938 (0.689 sec)
140.10... logprob:  0.596323, 0.281250 (0.691 sec)
140.11... logprob:  0.640212, 0.335938 (0.683 sec)
140.12... logprob:  0.725255, 0.437500 (0.688 sec)
140.13... logprob:  0.659883, 0.359375 (0.688 sec)
140.14... logprob:  0.665300, 0.367188 (0.683 sec)
140.15... logprob:  0.688511, 0.398438 (0.690 sec)
140.16... logprob:  0.627061, 0.320312 (0.689 sec)
140.17... logprob:  0.638495, 0.335938 (0.748 sec)
140.18... logprob:  0.638240, 0.335938 (0.684 sec)
140.19... logprob:  0.632995, 0.328125 (0.690 sec)
140.20... logprob:  0.648538, 0.351562 (0.690 sec)
140.21... logprob:  0.643460, 0.343750 (0.688 sec)
140.22... logprob:  0.629221, 0.320312 (0.698 sec)
140.23... logprob:  0.624931, 0.312500 (0.691 sec)
140.24... logprob:  0.583151, 0.242188 (0.690 sec)
140.25... logprob:  0.629462, 0.320312 (0.698 sec)
140.26... logprob:  0.672442, 0.390625 (0.714 sec)
140.27... logprob:  0.628939, 0.320312 (0.704 sec)
141.1... logprob:  0.678022, 0.398438 (0.694 sec)
141.2... logprob:  0.598876, 0.273438 (0.693 sec)
141.3... logprob:  0.653531, 0.359375 (0.701 sec)
141.4... logprob:  0.597559, 0.273438 (0.703 sec)
141.5... logprob:  0.591234, 0.265625 (0.691 sec)
141.6... logprob:  0.611163, 0.296875 (0.695 sec)
141.7... logprob:  0.644134, 0.343750 (0.688 sec)
141.8... logprob:  0.603823, 0.289062 (0.693 sec)
141.9... logprob:  0.639167, 0.335938 (0.687 sec)
141.10... logprob:  0.596334, 0.281250 (0.687 sec)
141.11... logprob:  0.640200, 0.335938 (0.692 sec)
141.12... logprob:  0.725200, 0.437500 (0.681 sec)
141.13... logprob:  0.659864, 0.359375 (0.683 sec)
141.14... logprob:  0.665284, 0.367188 (0.679 sec)
141.15... logprob:  0.688497, 0.398438 (0.674 sec)
141.16... logprob:  0.627061, 0.320312 (0.675 sec)
141.17... logprob:  0.638496, 0.335938 (0.676 sec)
141.18... logprob:  0.638240, 0.335938 (0.678 sec)
141.19... logprob:  0.632992, 0.328125 (0.674 sec)
141.20... logprob:  0.648539, 0.351562 (0.680 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.682765, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.964488e-03 [6.570663e-09] 
Layer 'conv1' biases: 1.677430e-07 [1.517902e-10] 
Layer 'conv2' weights[0]: 7.951732e-03 [6.360226e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.672103e-10] 
Layer 'conv3' weights[0]: 7.949939e-03 [5.780124e-09] 
Layer 'conv3' biases: 1.638300e-06 [2.193810e-09] 
Layer 'conv4' weights[0]: 7.982465e-03 [5.946147e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.868830e-08] 
Layer 'conv5' weights[0]: 7.981924e-03 [1.228472e-07] 
Layer 'conv5' biases: 1.000008e+00 [1.338315e-07] 
Layer 'fc6' weights[0]: 7.578335e-03 [1.225067e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.171363e-08] 
Layer 'fc7' weights[0]: 7.708037e-03 [1.750875e-07] 
Layer 'fc7' biases: 9.998595e-01 [1.620736e-07] 
Layer 'fc8' weights[0]: 6.668935e-04 [9.685725e-06] 
Layer 'fc8' biases: 6.462260e-02 [1.249532e-04] 
Train error last 27 batches: 0.636660
-------------------------------------------------------
Not saving because 0.682765 > 0.627176 (56.15: -0.03%)
======================================================= (1.714 sec)
141.21... logprob:  0.643458, 0.343750 (0.677 sec)
141.22... logprob:  0.629210, 0.320312 (0.679 sec)
141.23... logprob:  0.624915, 0.312500 (0.675 sec)
141.24... logprob:  0.583110, 0.242188 (0.678 sec)
141.25... logprob:  0.629451, 0.320312 (0.677 sec)
141.26... logprob:  0.672453, 0.390625 (0.679 sec)
141.27... logprob:  0.628932, 0.320312 (0.676 sec)
142.1... logprob:  0.678031, 0.398438 (0.674 sec)
142.2... logprob:  0.598865, 0.273438 (0.675 sec)
142.3... logprob:  0.653533, 0.359375 (0.676 sec)
142.4... logprob:  0.597556, 0.273438 (0.675 sec)
142.5... logprob:  0.591236, 0.265625 (0.675 sec)
142.6... logprob:  0.611166, 0.296875 (0.677 sec)
142.7... logprob:  0.644130, 0.343750 (0.673 sec)
142.8... logprob:  0.603831, 0.289062 (0.676 sec)
142.9... logprob:  0.639160, 0.335938 (0.674 sec)
142.10... logprob:  0.596344, 0.281250 (0.677 sec)
142.11... logprob:  0.640188, 0.335938 (0.676 sec)
142.12... logprob:  0.725147, 0.437500 (0.676 sec)
142.13... logprob:  0.659846, 0.359375 (0.678 sec)
142.14... logprob:  0.665269, 0.367188 (0.679 sec)
142.15... logprob:  0.688483, 0.398438 (0.675 sec)
142.16... logprob:  0.627061, 0.320312 (0.681 sec)
142.17... logprob:  0.638497, 0.335938 (0.677 sec)
142.18... logprob:  0.638240, 0.335938 (0.676 sec)
142.19... logprob:  0.632990, 0.328125 (0.686 sec)
142.20... logprob:  0.648542, 0.351562 (0.685 sec)
142.21... logprob:  0.643457, 0.343750 (0.685 sec)
142.22... logprob:  0.629198, 0.320312 (0.685 sec)
142.23... logprob:  0.624900, 0.312500 (0.694 sec)
142.24... logprob:  0.583069, 0.242188 (0.681 sec)
142.25... logprob:  0.629440, 0.320312 (0.678 sec)
142.26... logprob:  0.672463, 0.390625 (0.682 sec)
142.27... logprob:  0.628926, 0.320312 (0.672 sec)
143.1... logprob:  0.678039, 0.398438 (0.712 sec)
143.2... logprob:  0.598855, 0.273438 (0.678 sec)
143.3... logprob:  0.653533, 0.359375 (0.685 sec)
143.4... logprob:  0.597554, 0.273438 (0.685 sec)
143.5... logprob:  0.591240, 0.265625 (0.684 sec)
143.6... logprob:  0.611171, 0.296875 (0.697 sec)
143.7... logprob:  0.644127, 0.343750 (0.690 sec)
143.8... logprob:  0.603840, 0.289062 (0.680 sec)
143.9... logprob:  0.639153, 0.335938 (0.689 sec)
143.10... logprob:  0.596355, 0.281250 (0.675 sec)
143.11... logprob:  0.640176, 0.335938 (0.675 sec)
143.12... logprob:  0.725091, 0.437500 (0.675 sec)
143.13... logprob:  0.659827, 0.359375 (0.681 sec)
143.14... logprob:  0.665253, 0.367188 (0.675 sec)
143.15... logprob:  0.688468, 0.398438 (0.676 sec)
143.16... logprob:  0.627060, 0.320312 (0.676 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.632844, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.964277e-03 [6.996666e-09] 
Layer 'conv1' biases: 1.703120e-07 [1.956467e-10] 
Layer 'conv2' weights[0]: 7.951533e-03 [7.633080e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.069914e-09] 
Layer 'conv3' weights[0]: 7.949755e-03 [6.893345e-09] 
Layer 'conv3' biases: 1.655289e-06 [3.076117e-09] 
Layer 'conv4' weights[0]: 7.982266e-03 [7.261795e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.707176e-08] 
Layer 'conv5' weights[0]: 7.981697e-03 [1.775520e-07] 
Layer 'conv5' biases: 1.000007e+00 [1.934335e-07] 
Layer 'fc6' weights[0]: 7.578122e-03 [1.738805e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.693483e-08] 
Layer 'fc7' weights[0]: 7.706081e-03 [2.459218e-07] 
Layer 'fc7' biases: 9.998600e-01 [2.332964e-07] 
Layer 'fc8' weights[0]: 7.059412e-04 [1.395137e-05] 
Layer 'fc8' biases: 6.628418e-02 [1.795327e-04] 
Train error last 27 batches: 0.636647
-------------------------------------------------------
Not saving because 0.632844 > 0.627176 (56.15: -0.03%)
======================================================= (1.708 sec)
143.17... logprob:  0.638497, 0.335938 (0.686 sec)
143.18... logprob:  0.638239, 0.335938 (0.678 sec)
143.19... logprob:  0.632987, 0.328125 (0.678 sec)
143.20... logprob:  0.648543, 0.351562 (0.692 sec)
143.21... logprob:  0.643455, 0.343750 (0.685 sec)
143.22... logprob:  0.629188, 0.320312 (0.680 sec)
143.23... logprob:  0.624885, 0.312500 (0.681 sec)
143.24... logprob:  0.583029, 0.242188 (0.683 sec)
143.25... logprob:  0.629429, 0.320312 (0.682 sec)
143.26... logprob:  0.672473, 0.390625 (0.681 sec)
143.27... logprob:  0.628918, 0.320312 (0.680 sec)
144.1... logprob:  0.678049, 0.398438 (0.679 sec)
144.2... logprob:  0.598844, 0.273438 (0.686 sec)
144.3... logprob:  0.653534, 0.359375 (0.676 sec)
144.4... logprob:  0.597551, 0.273438 (0.676 sec)
144.5... logprob:  0.591241, 0.265625 (0.675 sec)
144.6... logprob:  0.611174, 0.296875 (0.679 sec)
144.7... logprob:  0.644123, 0.343750 (0.676 sec)
144.8... logprob:  0.603847, 0.289062 (0.676 sec)
144.9... logprob:  0.639148, 0.335938 (0.681 sec)
144.10... logprob:  0.596366, 0.281250 (0.681 sec)
144.11... logprob:  0.640164, 0.335938 (0.694 sec)
144.12... logprob:  0.725040, 0.437500 (0.688 sec)
144.13... logprob:  0.659809, 0.359375 (0.679 sec)
144.14... logprob:  0.665238, 0.367188 (0.689 sec)
144.15... logprob:  0.688456, 0.398438 (0.681 sec)
144.16... logprob:  0.627060, 0.320312 (0.674 sec)
144.17... logprob:  0.638498, 0.335938 (0.674 sec)
144.18... logprob:  0.638239, 0.335938 (0.675 sec)
144.19... logprob:  0.632983, 0.328125 (0.675 sec)
144.20... logprob:  0.648545, 0.351562 (0.682 sec)
144.21... logprob:  0.643453, 0.343750 (0.676 sec)
144.22... logprob:  0.629176, 0.320312 (0.677 sec)
144.23... logprob:  0.624870, 0.312500 (0.684 sec)
144.24... logprob:  0.582989, 0.242188 (0.680 sec)
144.25... logprob:  0.629419, 0.320312 (0.681 sec)
144.26... logprob:  0.672483, 0.390625 (0.677 sec)
144.27... logprob:  0.628912, 0.320312 (0.675 sec)
145.1... logprob:  0.678056, 0.398438 (0.682 sec)
145.2... logprob:  0.598835, 0.273438 (0.681 sec)
145.3... logprob:  0.653535, 0.359375 (0.676 sec)
145.4... logprob:  0.597549, 0.273438 (0.678 sec)
145.5... logprob:  0.591245, 0.265625 (0.675 sec)
145.6... logprob:  0.611179, 0.296875 (0.675 sec)
145.7... logprob:  0.644120, 0.343750 (0.673 sec)
145.8... logprob:  0.603857, 0.289062 (0.675 sec)
145.9... logprob:  0.639141, 0.335938 (0.676 sec)
145.10... logprob:  0.596378, 0.281250 (0.675 sec)
145.11... logprob:  0.640152, 0.335938 (0.675 sec)
145.12... logprob:  0.724983, 0.437500 (0.676 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627700, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.964090e-03 [6.583285e-09] 
Layer 'conv1' biases: 1.728512e-07 [8.329668e-11] 
Layer 'conv2' weights[0]: 7.951356e-03 [5.131237e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.761157e-10] 
Layer 'conv3' weights[0]: 7.949558e-03 [4.592662e-09] 
Layer 'conv3' biases: 1.672065e-06 [1.039230e-09] 
Layer 'conv4' weights[0]: 7.982082e-03 [4.545142e-09] 
Layer 'conv4' biases: 1.000001e+00 [5.917506e-09] 
Layer 'conv5' weights[0]: 7.981506e-03 [3.883172e-08] 
Layer 'conv5' biases: 1.000007e+00 [4.191913e-08] 
Layer 'fc6' weights[0]: 7.577927e-03 [5.416323e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.780102e-09] 
Layer 'fc7' weights[0]: 7.704071e-03 [7.281373e-08] 
Layer 'fc7' biases: 9.998606e-01 [5.365422e-08] 
Layer 'fc8' weights[0]: 7.468631e-04 [3.161438e-06] 
Layer 'fc8' biases: 6.793882e-02 [2.375129e-05] 
Train error last 27 batches: 0.636635
-------------------------------------------------------
Not saving because 0.627700 > 0.627176 (56.15: -0.03%)
======================================================= (1.779 sec)
145.13... logprob:  0.659789, 0.359375 (0.676 sec)
145.14... logprob:  0.665221, 0.367188 (0.679 sec)
145.15... logprob:  0.688441, 0.398438 (0.675 sec)
145.16... logprob:  0.627060, 0.320312 (0.686 sec)
145.17... logprob:  0.638498, 0.335938 (0.675 sec)
145.18... logprob:  0.638239, 0.335938 (0.674 sec)
145.19... logprob:  0.632980, 0.328125 (0.675 sec)
145.20... logprob:  0.648547, 0.351562 (0.680 sec)
145.21... logprob:  0.643452, 0.343750 (0.679 sec)
145.22... logprob:  0.629165, 0.320312 (0.677 sec)
145.23... logprob:  0.624854, 0.312500 (0.682 sec)
145.24... logprob:  0.582947, 0.242188 (0.680 sec)
145.25... logprob:  0.629408, 0.320312 (0.681 sec)
145.26... logprob:  0.672494, 0.390625 (0.681 sec)
145.27... logprob:  0.628904, 0.320312 (0.681 sec)
146.1... logprob:  0.678066, 0.398438 (0.683 sec)
146.2... logprob:  0.598823, 0.273438 (0.685 sec)
146.3... logprob:  0.653536, 0.359375 (0.685 sec)
146.4... logprob:  0.597547, 0.273438 (0.678 sec)
146.5... logprob:  0.591247, 0.265625 (0.681 sec)
146.6... logprob:  0.611183, 0.296875 (0.680 sec)
146.7... logprob:  0.644116, 0.343750 (0.681 sec)
146.8... logprob:  0.603864, 0.289062 (0.685 sec)
146.9... logprob:  0.639135, 0.335938 (0.682 sec)
146.10... logprob:  0.596388, 0.281250 (0.689 sec)
146.11... logprob:  0.640141, 0.335938 (0.680 sec)
146.12... logprob:  0.724930, 0.437500 (0.683 sec)
146.13... logprob:  0.659771, 0.359375 (0.684 sec)
146.14... logprob:  0.665206, 0.367188 (0.684 sec)
146.15... logprob:  0.688427, 0.398438 (0.684 sec)
146.16... logprob:  0.627060, 0.320312 (0.687 sec)
146.17... logprob:  0.638499, 0.335938 (0.685 sec)
146.18... logprob:  0.638239, 0.335938 (0.685 sec)
146.19... logprob:  0.632977, 0.328125 (0.687 sec)
146.20... logprob:  0.648549, 0.351562 (0.693 sec)
146.21... logprob:  0.643450, 0.343750 (0.683 sec)
146.22... logprob:  0.629155, 0.320312 (0.683 sec)
146.23... logprob:  0.624840, 0.312500 (0.681 sec)
146.24... logprob:  0.582908, 0.242188 (0.676 sec)
146.25... logprob:  0.629398, 0.320312 (0.676 sec)
146.26... logprob:  0.672504, 0.390625 (0.676 sec)
146.27... logprob:  0.628898, 0.320312 (0.682 sec)
147.1... logprob:  0.678074, 0.398438 (0.751 sec)
147.2... logprob:  0.598813, 0.273438 (0.695 sec)
147.3... logprob:  0.653536, 0.359375 (0.691 sec)
147.4... logprob:  0.597544, 0.273438 (0.778 sec)
147.5... logprob:  0.591249, 0.265625 (0.693 sec)
147.6... logprob:  0.611186, 0.296875 (0.702 sec)
147.7... logprob:  0.644113, 0.343750 (0.774 sec)
147.8... logprob:  0.603872, 0.289062 (0.839 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.657086, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.963902e-03 [7.008869e-09] 
Layer 'conv1' biases: 1.758172e-07 [1.355408e-10] 
Layer 'conv2' weights[0]: 7.951163e-03 [6.175401e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.175097e-10] 
Layer 'conv3' weights[0]: 7.949359e-03 [6.231539e-09] 
Layer 'conv3' biases: 1.695154e-06 [2.422438e-09] 
Layer 'conv4' weights[0]: 7.981892e-03 [6.706926e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.349519e-08] 
Layer 'conv5' weights[0]: 7.981306e-03 [1.537156e-07] 
Layer 'conv5' biases: 1.000007e+00 [1.676951e-07] 
Layer 'fc6' weights[0]: 7.577737e-03 [1.505149e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.454085e-08] 
Layer 'fc7' weights[0]: 7.702157e-03 [2.100287e-07] 
Layer 'fc7' biases: 9.998603e-01 [1.962298e-07] 
Layer 'fc8' weights[0]: 7.233066e-04 [1.178658e-05] 
Layer 'fc8' biases: 6.858541e-02 [1.900079e-04] 
Train error last 27 batches: 0.636624
-------------------------------------------------------
Not saving because 0.657086 > 0.627176 (56.15: -0.03%)
======================================================= (1.859 sec)
147.9... logprob:  0.639128, 0.335938 (0.704 sec)
147.10... logprob:  0.596398, 0.281250 (0.700 sec)
147.11... logprob:  0.640129, 0.335938 (0.714 sec)
147.12... logprob:  0.724878, 0.437500 (0.703 sec)
147.13... logprob:  0.659753, 0.359375 (0.690 sec)
147.14... logprob:  0.665191, 0.367188 (0.692 sec)
147.15... logprob:  0.688413, 0.398438 (0.707 sec)
147.16... logprob:  0.627060, 0.320312 (0.701 sec)
147.17... logprob:  0.638500, 0.335938 (0.702 sec)
147.18... logprob:  0.638239, 0.335938 (0.688 sec)
147.19... logprob:  0.632975, 0.328125 (0.735 sec)
147.20... logprob:  0.648551, 0.351562 (0.694 sec)
147.21... logprob:  0.643449, 0.343750 (0.713 sec)
147.22... logprob:  0.629144, 0.320312 (0.771 sec)
147.23... logprob:  0.624825, 0.312500 (0.748 sec)
147.24... logprob:  0.582868, 0.242188 (0.722 sec)
147.25... logprob:  0.629387, 0.320312 (0.710 sec)
147.26... logprob:  0.672514, 0.390625 (0.688 sec)
147.27... logprob:  0.628891, 0.320312 (0.696 sec)
148.1... logprob:  0.678082, 0.398438 (0.687 sec)
148.2... logprob:  0.598803, 0.273438 (0.692 sec)
148.3... logprob:  0.653537, 0.359375 (0.690 sec)
148.4... logprob:  0.597542, 0.273438 (0.692 sec)
148.5... logprob:  0.591251, 0.265625 (0.712 sec)
148.6... logprob:  0.611190, 0.296875 (0.695 sec)
148.7... logprob:  0.644110, 0.343750 (0.688 sec)
148.8... logprob:  0.603881, 0.289062 (0.689 sec)
148.9... logprob:  0.639122, 0.335938 (0.686 sec)
148.10... logprob:  0.596409, 0.281250 (0.687 sec)
148.11... logprob:  0.640118, 0.335938 (0.689 sec)
148.12... logprob:  0.724825, 0.437500 (0.689 sec)
148.13... logprob:  0.659734, 0.359375 (0.688 sec)
148.14... logprob:  0.665175, 0.367188 (0.689 sec)
148.15... logprob:  0.688399, 0.398438 (0.688 sec)
148.16... logprob:  0.627060, 0.320312 (0.688 sec)
148.17... logprob:  0.638500, 0.335938 (0.688 sec)
148.18... logprob:  0.638238, 0.335938 (0.687 sec)
148.19... logprob:  0.632972, 0.328125 (0.693 sec)
148.20... logprob:  0.648553, 0.351562 (0.687 sec)
148.21... logprob:  0.643447, 0.343750 (0.690 sec)
148.22... logprob:  0.629133, 0.320312 (0.698 sec)
148.23... logprob:  0.624810, 0.312500 (0.689 sec)
148.24... logprob:  0.582828, 0.242188 (0.747 sec)
148.25... logprob:  0.629377, 0.320312 (0.716 sec)
148.26... logprob:  0.672524, 0.390625 (0.690 sec)
148.27... logprob:  0.628884, 0.320312 (0.687 sec)
149.1... logprob:  0.678091, 0.398438 (0.687 sec)
149.2... logprob:  0.598793, 0.273438 (0.688 sec)
149.3... logprob:  0.653538, 0.359375 (0.687 sec)
149.4... logprob:  0.597539, 0.273438 (0.687 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627908, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.963709e-03 [6.576050e-09] 
Layer 'conv1' biases: 1.789650e-07 [1.037709e-10] 
Layer 'conv2' weights[0]: 7.950969e-03 [5.367382e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.653114e-10] 
Layer 'conv3' weights[0]: 7.949156e-03 [5.357380e-09] 
Layer 'conv3' biases: 1.720267e-06 [1.650099e-09] 
Layer 'conv4' weights[0]: 7.981697e-03 [5.605149e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.532996e-08] 
Layer 'conv5' weights[0]: 7.981091e-03 [1.004945e-07] 
Layer 'conv5' biases: 1.000007e+00 [1.094711e-07] 
Layer 'fc6' weights[0]: 7.577547e-03 [1.034331e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.505936e-09] 
Layer 'fc7' weights[0]: 7.700185e-03 [1.429901e-07] 
Layer 'fc7' biases: 9.998596e-01 [1.277634e-07] 
Layer 'fc8' weights[0]: 6.798414e-04 [7.655373e-06] 
Layer 'fc8' biases: 6.887707e-02 [1.335227e-04] 
Train error last 27 batches: 0.636611
-------------------------------------------------------
Not saving because 0.627908 > 0.627176 (56.15: -0.03%)
======================================================= (1.889 sec)
149.5... logprob:  0.591253, 0.265625 (0.706 sec)
149.6... logprob:  0.611194, 0.296875 (0.709 sec)
149.7... logprob:  0.644106, 0.343750 (0.688 sec)
149.8... logprob:  0.603889, 0.289062 (0.685 sec)
149.9... logprob:  0.639116, 0.335938 (0.688 sec)
149.10... logprob:  0.596420, 0.281250 (0.688 sec)
149.11... logprob:  0.640106, 0.335938 (0.692 sec)
149.12... logprob:  0.724772, 0.437500 (0.688 sec)
149.13... logprob:  0.659716, 0.359375 (0.691 sec)
149.14... logprob:  0.665159, 0.367188 (0.688 sec)
149.15... logprob:  0.688385, 0.398438 (0.688 sec)
149.16... logprob:  0.627060, 0.320312 (0.688 sec)
149.17... logprob:  0.638501, 0.335938 (0.689 sec)
149.18... logprob:  0.638238, 0.335938 (0.687 sec)
149.19... logprob:  0.632969, 0.328125 (0.688 sec)
149.20... logprob:  0.648555, 0.351562 (0.690 sec)
149.21... logprob:  0.643445, 0.343750 (0.689 sec)
149.22... logprob:  0.629123, 0.320312 (0.689 sec)
149.23... logprob:  0.624796, 0.312500 (0.689 sec)
149.24... logprob:  0.582789, 0.242188 (0.691 sec)
149.25... logprob:  0.629366, 0.320312 (0.695 sec)
149.26... logprob:  0.672534, 0.390625 (0.696 sec)
149.27... logprob:  0.628877, 0.320312 (0.688 sec)
150.1... logprob:  0.678099, 0.398438 (0.691 sec)
150.2... logprob:  0.598782, 0.273438 (0.691 sec)
150.3... logprob:  0.653539, 0.359375 (0.686 sec)
150.4... logprob:  0.597536, 0.273438 (0.687 sec)
150.5... logprob:  0.591254, 0.265625 (0.686 sec)
150.6... logprob:  0.611197, 0.296875 (0.702 sec)
150.7... logprob:  0.644103, 0.343750 (0.689 sec)
150.8... logprob:  0.603896, 0.289062 (0.695 sec)
150.9... logprob:  0.639110, 0.335938 (0.691 sec)
150.10... logprob:  0.596430, 0.281250 (0.698 sec)
150.11... logprob:  0.640096, 0.335938 (0.687 sec)
150.12... logprob:  0.724721, 0.437500 (0.691 sec)
150.13... logprob:  0.659698, 0.359375 (0.687 sec)
150.14... logprob:  0.665144, 0.367188 (0.687 sec)
150.15... logprob:  0.688372, 0.398438 (0.698 sec)
150.16... logprob:  0.627060, 0.320312 (0.686 sec)
150.17... logprob:  0.638501, 0.335938 (0.690 sec)
150.18... logprob:  0.638238, 0.335938 (0.690 sec)
150.19... logprob:  0.632966, 0.328125 (0.691 sec)
150.20... logprob:  0.648557, 0.351562 (0.703 sec)
150.21... logprob:  0.643444, 0.343750 (0.686 sec)
150.22... logprob:  0.629111, 0.320312 (0.688 sec)
150.23... logprob:  0.624781, 0.312500 (0.690 sec)
150.24... logprob:  0.582750, 0.242188 (0.688 sec)
150.25... logprob:  0.629356, 0.320312 (0.688 sec)
150.26... logprob:  0.672544, 0.390625 (0.689 sec)
150.27... logprob:  0.628871, 0.320312 (0.686 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633567, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.963507e-03 [6.274699e-09] 
Layer 'conv1' biases: 1.819577e-07 [6.872867e-11] 
Layer 'conv2' weights[0]: 7.950779e-03 [4.750217e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.286614e-10] 
Layer 'conv3' weights[0]: 7.948954e-03 [4.664070e-09] 
Layer 'conv3' biases: 1.742848e-06 [1.028510e-09] 
Layer 'conv4' weights[0]: 7.981507e-03 [4.778102e-09] 
Layer 'conv4' biases: 1.000001e+00 [8.709037e-09] 
Layer 'conv5' weights[0]: 7.980906e-03 [5.655921e-08] 
Layer 'conv5' biases: 1.000008e+00 [6.156285e-08] 
Layer 'fc6' weights[0]: 7.577351e-03 [6.643351e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.331493e-09] 
Layer 'fc7' weights[0]: 7.698238e-03 [8.982890e-08] 
Layer 'fc7' biases: 9.998592e-01 [7.112008e-08] 
Layer 'fc8' weights[0]: 6.635956e-04 [4.248376e-06] 
Layer 'fc8' biases: 6.960647e-02 [8.609285e-05] 
Train error last 27 batches: 0.636599
-------------------------------------------------------
Not saving because 0.633567 > 0.627176 (56.15: -0.03%)
======================================================= (1.969 sec)
151.1... logprob:  0.678108, 0.398438 (0.709 sec)
151.2... logprob:  0.598772, 0.273438 (0.695 sec)
151.3... logprob:  0.653540, 0.359375 (0.689 sec)
151.4... logprob:  0.597534, 0.273438 (0.687 sec)
151.5... logprob:  0.591258, 0.265625 (0.691 sec)
151.6... logprob:  0.611202, 0.296875 (0.687 sec)
151.7... logprob:  0.644100, 0.343750 (0.688 sec)
151.8... logprob:  0.603905, 0.289062 (0.689 sec)
151.9... logprob:  0.639104, 0.335938 (0.693 sec)
151.10... logprob:  0.596442, 0.281250 (0.705 sec)
151.11... logprob:  0.640084, 0.335938 (0.687 sec)
151.12... logprob:  0.724666, 0.437500 (0.692 sec)
151.13... logprob:  0.659679, 0.359375 (0.687 sec)
151.14... logprob:  0.665128, 0.367188 (0.687 sec)
151.15... logprob:  0.688356, 0.398438 (0.696 sec)
151.16... logprob:  0.627060, 0.320312 (0.745 sec)
151.17... logprob:  0.638502, 0.335938 (0.695 sec)
151.18... logprob:  0.638238, 0.335938 (0.690 sec)
151.19... logprob:  0.632963, 0.328125 (0.688 sec)
151.20... logprob:  0.648559, 0.351562 (0.695 sec)
151.21... logprob:  0.643443, 0.343750 (0.688 sec)
151.22... logprob:  0.629101, 0.320312 (0.687 sec)
151.23... logprob:  0.624767, 0.312500 (0.688 sec)
151.24... logprob:  0.582711, 0.242188 (0.686 sec)
151.25... logprob:  0.629346, 0.320312 (0.688 sec)
151.26... logprob:  0.672554, 0.390625 (0.686 sec)
151.27... logprob:  0.628864, 0.320312 (0.689 sec)
152.1... logprob:  0.678117, 0.398438 (0.689 sec)
152.2... logprob:  0.598761, 0.273438 (0.692 sec)
152.3... logprob:  0.653541, 0.359375 (0.693 sec)
152.4... logprob:  0.597530, 0.273438 (0.686 sec)
152.5... logprob:  0.591258, 0.265625 (0.687 sec)
152.6... logprob:  0.611204, 0.296875 (0.692 sec)
152.7... logprob:  0.644097, 0.343750 (0.688 sec)
152.8... logprob:  0.603912, 0.289062 (0.687 sec)
152.9... logprob:  0.639099, 0.335938 (0.687 sec)
152.10... logprob:  0.596451, 0.281250 (0.692 sec)
152.11... logprob:  0.640074, 0.335938 (0.688 sec)
152.12... logprob:  0.724618, 0.437500 (0.689 sec)
152.13... logprob:  0.659663, 0.359375 (0.697 sec)
152.14... logprob:  0.665114, 0.367188 (0.689 sec)
152.15... logprob:  0.688344, 0.398438 (0.688 sec)
152.16... logprob:  0.627060, 0.320312 (0.688 sec)
152.17... logprob:  0.638502, 0.335938 (0.694 sec)
152.18... logprob:  0.638238, 0.335938 (0.688 sec)
152.19... logprob:  0.632960, 0.328125 (0.685 sec)
152.20... logprob:  0.648561, 0.351562 (0.686 sec)
152.21... logprob:  0.643442, 0.343750 (0.767 sec)
152.22... logprob:  0.629091, 0.320312 (0.695 sec)
152.23... logprob:  0.624753, 0.312500 (0.692 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.681209, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.963311e-03 [5.929089e-09] 
Layer 'conv1' biases: 1.849300e-07 [8.524083e-11] 
Layer 'conv2' weights[0]: 7.950581e-03 [4.891976e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.264425e-10] 
Layer 'conv3' weights[0]: 7.948753e-03 [4.497319e-09] 
Layer 'conv3' biases: 1.765569e-06 [8.324056e-10] 
Layer 'conv4' weights[0]: 7.981296e-03 [4.430257e-09] 
Layer 'conv4' biases: 1.000001e+00 [4.875955e-09] 
Layer 'conv5' weights[0]: 7.980715e-03 [3.196194e-08] 
Layer 'conv5' biases: 1.000008e+00 [3.451927e-08] 
Layer 'fc6' weights[0]: 7.577163e-03 [5.018311e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.138543e-09] 
Layer 'fc7' weights[0]: 7.696259e-03 [6.487544e-08] 
Layer 'fc7' biases: 9.998590e-01 [4.428349e-08] 
Layer 'fc8' weights[0]: 6.475208e-04 [2.605445e-06] 
Layer 'fc8' biases: 7.029974e-02 [2.029618e-05] 
Train error last 27 batches: 0.636588
-------------------------------------------------------
Not saving because 0.681209 > 0.627176 (56.15: -0.03%)
======================================================= (1.895 sec)
152.24... logprob:  0.582674, 0.242188 (0.696 sec)
152.25... logprob:  0.629336, 0.320312 (0.703 sec)
152.26... logprob:  0.672564, 0.390625 (0.699 sec)
152.27... logprob:  0.628857, 0.320312 (0.693 sec)
153.1... logprob:  0.678124, 0.398438 (0.697 sec)
153.2... logprob:  0.598752, 0.273438 (0.693 sec)
153.3... logprob:  0.653542, 0.359375 (0.688 sec)
153.4... logprob:  0.597529, 0.273438 (0.685 sec)
153.5... logprob:  0.591261, 0.265625 (0.687 sec)
153.6... logprob:  0.611209, 0.296875 (0.715 sec)
153.7... logprob:  0.644094, 0.343750 (0.697 sec)
153.8... logprob:  0.603921, 0.289062 (0.695 sec)
153.9... logprob:  0.639093, 0.335938 (0.698 sec)
153.10... logprob:  0.596462, 0.281250 (0.695 sec)
153.11... logprob:  0.640062, 0.335938 (0.743 sec)
153.12... logprob:  0.724565, 0.437500 (0.711 sec)
153.13... logprob:  0.659645, 0.359375 (0.694 sec)
153.14... logprob:  0.665099, 0.367188 (0.687 sec)
153.15... logprob:  0.688330, 0.398438 (0.687 sec)
153.16... logprob:  0.627059, 0.320312 (0.687 sec)
153.17... logprob:  0.638503, 0.335938 (0.687 sec)
153.18... logprob:  0.638238, 0.335938 (0.694 sec)
153.19... logprob:  0.632957, 0.328125 (0.687 sec)
153.20... logprob:  0.648563, 0.351562 (0.717 sec)
153.21... logprob:  0.643440, 0.343750 (0.690 sec)
153.22... logprob:  0.629081, 0.320312 (0.689 sec)
153.23... logprob:  0.624739, 0.312500 (0.689 sec)
153.24... logprob:  0.582635, 0.242188 (0.686 sec)
153.25... logprob:  0.629325, 0.320312 (0.689 sec)
153.26... logprob:  0.672574, 0.390625 (0.699 sec)
153.27... logprob:  0.628851, 0.320312 (0.694 sec)
154.1... logprob:  0.678133, 0.398438 (0.693 sec)
154.2... logprob:  0.598741, 0.273438 (0.725 sec)
154.3... logprob:  0.653542, 0.359375 (0.691 sec)
154.4... logprob:  0.597526, 0.273438 (0.691 sec)
154.5... logprob:  0.591263, 0.265625 (0.691 sec)
154.6... logprob:  0.611212, 0.296875 (0.748 sec)
154.7... logprob:  0.644090, 0.343750 (0.734 sec)
154.8... logprob:  0.603928, 0.289062 (0.690 sec)
154.9... logprob:  0.639086, 0.335938 (0.685 sec)
154.10... logprob:  0.596472, 0.281250 (0.696 sec)
154.11... logprob:  0.640051, 0.335938 (0.684 sec)
154.12... logprob:  0.724514, 0.437500 (0.692 sec)
154.13... logprob:  0.659627, 0.359375 (0.690 sec)
154.14... logprob:  0.665083, 0.367188 (0.689 sec)
154.15... logprob:  0.688315, 0.398438 (0.686 sec)
154.16... logprob:  0.627059, 0.320312 (0.691 sec)
154.17... logprob:  0.638503, 0.335938 (0.714 sec)
154.18... logprob:  0.638238, 0.335938 (0.700 sec)
154.19... logprob:  0.632955, 0.328125 (0.685 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633315, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.963110e-03 [6.602282e-09] 
Layer 'conv1' biases: 1.876277e-07 [1.575281e-10] 
Layer 'conv2' weights[0]: 7.950386e-03 [6.597899e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.006683e-10] 
Layer 'conv3' weights[0]: 7.948560e-03 [5.926062e-09] 
Layer 'conv3' biases: 1.784137e-06 [2.279450e-09] 
Layer 'conv4' weights[0]: 7.981092e-03 [6.095747e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.907133e-08] 
Layer 'conv5' weights[0]: 7.980513e-03 [1.238487e-07] 
Layer 'conv5' biases: 1.000007e+00 [1.346130e-07] 
Layer 'fc6' weights[0]: 7.576954e-03 [1.253375e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.202075e-08] 
Layer 'fc7' weights[0]: 7.694310e-03 [1.776090e-07] 
Layer 'fc7' biases: 9.998593e-01 [1.646517e-07] 
Layer 'fc8' weights[0]: 6.692809e-04 [9.780353e-06] 
Layer 'fc8' biases: 7.167080e-02 [1.283763e-04] 
Train error last 27 batches: 0.636576
-------------------------------------------------------
Not saving because 0.633315 > 0.627176 (56.15: -0.03%)
======================================================= (1.715 sec)
154.20... logprob:  0.648565, 0.351562 (0.680 sec)
154.21... logprob:  0.643439, 0.343750 (0.676 sec)
154.22... logprob:  0.629071, 0.320312 (0.684 sec)
154.23... logprob:  0.624725, 0.312500 (0.680 sec)
154.24... logprob:  0.582597, 0.242188 (0.688 sec)
154.25... logprob:  0.629316, 0.320312 (0.691 sec)
154.26... logprob:  0.672583, 0.390625 (0.687 sec)
154.27... logprob:  0.628844, 0.320312 (0.691 sec)
155.1... logprob:  0.678141, 0.398438 (0.843 sec)
155.2... logprob:  0.598731, 0.273438 (0.748 sec)
155.3... logprob:  0.653543, 0.359375 (0.689 sec)
155.4... logprob:  0.597522, 0.273438 (0.691 sec)
155.5... logprob:  0.591264, 0.265625 (0.712 sec)
155.6... logprob:  0.611215, 0.296875 (0.707 sec)
155.7... logprob:  0.644088, 0.343750 (0.685 sec)
155.8... logprob:  0.603936, 0.289062 (0.679 sec)
155.9... logprob:  0.639081, 0.335938 (0.687 sec)
155.10... logprob:  0.596482, 0.281250 (0.688 sec)
155.11... logprob:  0.640041, 0.335938 (0.689 sec)
155.12... logprob:  0.724464, 0.437500 (0.687 sec)
155.13... logprob:  0.659610, 0.359375 (0.690 sec)
155.14... logprob:  0.665068, 0.367188 (0.679 sec)
155.15... logprob:  0.688302, 0.398438 (0.693 sec)
155.16... logprob:  0.627060, 0.320312 (0.796 sec)
155.17... logprob:  0.638504, 0.335938 (0.805 sec)
155.18... logprob:  0.638237, 0.335938 (0.785 sec)
155.19... logprob:  0.632952, 0.328125 (0.680 sec)
155.20... logprob:  0.648566, 0.351562 (0.678 sec)
155.21... logprob:  0.643437, 0.343750 (0.696 sec)
155.22... logprob:  0.629061, 0.320312 (0.698 sec)
155.23... logprob:  0.624711, 0.312500 (0.694 sec)
155.24... logprob:  0.582561, 0.242188 (0.680 sec)
155.25... logprob:  0.629306, 0.320312 (0.683 sec)
155.26... logprob:  0.672593, 0.390625 (0.683 sec)
155.27... logprob:  0.628838, 0.320312 (0.681 sec)
156.1... logprob:  0.678149, 0.398438 (0.687 sec)
156.2... logprob:  0.598721, 0.273438 (0.702 sec)
156.3... logprob:  0.653544, 0.359375 (0.693 sec)
156.4... logprob:  0.597519, 0.273438 (0.696 sec)
156.5... logprob:  0.591266, 0.265625 (0.687 sec)
156.6... logprob:  0.611218, 0.296875 (0.710 sec)
156.7... logprob:  0.644084, 0.343750 (0.696 sec)
156.8... logprob:  0.603943, 0.289062 (0.698 sec)
156.9... logprob:  0.639076, 0.335938 (0.702 sec)
156.10... logprob:  0.596492, 0.281250 (0.700 sec)
156.11... logprob:  0.640030, 0.335938 (0.700 sec)
156.12... logprob:  0.724415, 0.437500 (0.694 sec)
156.13... logprob:  0.659593, 0.359375 (0.691 sec)
156.14... logprob:  0.665054, 0.367188 (0.691 sec)
156.15... logprob:  0.688289, 0.398438 (0.695 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627153, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.962911e-03 [7.395025e-09] 
Layer 'conv1' biases: 1.901980e-07 [2.169196e-10] 
Layer 'conv2' weights[0]: 7.950188e-03 [8.068334e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.158429e-09] 
Layer 'conv3' weights[0]: 7.948362e-03 [7.192035e-09] 
Layer 'conv3' biases: 1.800788e-06 [3.327428e-09] 
Layer 'conv4' weights[0]: 7.980890e-03 [7.582989e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.911086e-08] 
Layer 'conv5' weights[0]: 7.980297e-03 [1.884201e-07] 
Layer 'conv5' biases: 1.000007e+00 [2.048811e-07] 
Layer 'fc6' weights[0]: 7.576773e-03 [1.872354e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.828311e-08] 
Layer 'fc7' weights[0]: 7.692304e-03 [2.607762e-07] 
Layer 'fc7' biases: 9.998598e-01 [2.490847e-07] 
Layer 'fc8' weights[0]: 7.104110e-04 [1.483573e-05] 
Layer 'fc8' biases: 7.334001e-02 [1.960868e-04] 
Train error last 27 batches: 0.636564
-------------------------------------------------------
Saved checkpoint to /homes/ad6813/Git/pipe-classification/models/scraping_peeling/net_0/saves/ConvNet__2014-07-08_14.54.04
======================================================= (5.561 sec)
156.16... logprob:  0.627059, 0.320312 (0.705 sec)
156.17... logprob:  0.638505, 0.335938 (0.704 sec)
156.18... logprob:  0.638238, 0.335938 (0.703 sec)
156.19... logprob:  0.632949, 0.328125 (0.700 sec)
156.20... logprob:  0.648568, 0.351562 (0.703 sec)
156.21... logprob:  0.643436, 0.343750 (0.701 sec)
156.22... logprob:  0.629051, 0.320312 (0.702 sec)
156.23... logprob:  0.624697, 0.312500 (0.690 sec)
156.24... logprob:  0.582522, 0.242188 (0.681 sec)
156.25... logprob:  0.629296, 0.320312 (0.693 sec)
156.26... logprob:  0.672603, 0.390625 (0.698 sec)
156.27... logprob:  0.628832, 0.320312 (0.702 sec)
157.1... logprob:  0.678158, 0.398438 (0.697 sec)
157.2... logprob:  0.598711, 0.273438 (0.685 sec)
157.3... logprob:  0.653545, 0.359375 (0.679 sec)
157.4... logprob:  0.597517, 0.273438 (0.687 sec)
157.5... logprob:  0.591268, 0.265625 (0.700 sec)
157.6... logprob:  0.611222, 0.296875 (0.697 sec)
157.7... logprob:  0.644082, 0.343750 (0.692 sec)
157.8... logprob:  0.603952, 0.289062 (0.685 sec)
157.9... logprob:  0.639070, 0.335938 (0.684 sec)
157.10... logprob:  0.596503, 0.281250 (0.727 sec)
157.11... logprob:  0.640019, 0.335938 (0.691 sec)
157.12... logprob:  0.724362, 0.437500 (0.683 sec)
157.13... logprob:  0.659575, 0.359375 (0.686 sec)
157.14... logprob:  0.665038, 0.367188 (0.687 sec)
157.15... logprob:  0.688275, 0.398438 (0.685 sec)
157.16... logprob:  0.627059, 0.320312 (0.691 sec)
157.17... logprob:  0.638505, 0.335938 (0.693 sec)
157.18... logprob:  0.638238, 0.335938 (0.686 sec)
157.19... logprob:  0.632947, 0.328125 (0.683 sec)
157.20... logprob:  0.648570, 0.351562 (0.708 sec)
157.21... logprob:  0.643435, 0.343750 (0.683 sec)
157.22... logprob:  0.629040, 0.320312 (0.690 sec)
157.23... logprob:  0.624683, 0.312500 (0.682 sec)
157.24... logprob:  0.582484, 0.242188 (0.680 sec)
157.25... logprob:  0.629286, 0.320312 (0.676 sec)
157.26... logprob:  0.672613, 0.390625 (0.688 sec)
157.27... logprob:  0.628825, 0.320312 (0.687 sec)
158.1... logprob:  0.678166, 0.398438 (0.690 sec)
158.2... logprob:  0.598700, 0.273438 (0.688 sec)
158.3... logprob:  0.653546, 0.359375 (0.682 sec)
158.4... logprob:  0.597514, 0.273438 (0.686 sec)
158.5... logprob:  0.591269, 0.265625 (0.683 sec)
158.6... logprob:  0.611225, 0.296875 (0.685 sec)
158.7... logprob:  0.644078, 0.343750 (0.683 sec)
158.8... logprob:  0.603959, 0.289062 (0.684 sec)
158.9... logprob:  0.639064, 0.335938 (0.688 sec)
158.10... logprob:  0.596514, 0.281250 (0.683 sec)
158.11... logprob:  0.640009, 0.335938 (0.684 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.659879, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.962711e-03 [6.527818e-09] 
Layer 'conv1' biases: 1.928498e-07 [9.416456e-11] 
Layer 'conv2' weights[0]: 7.949991e-03 [5.263130e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.374696e-10] 
Layer 'conv3' weights[0]: 7.948172e-03 [5.248295e-09] 
Layer 'conv3' biases: 1.818569e-06 [1.554604e-09] 
Layer 'conv4' weights[0]: 7.980697e-03 [5.530722e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.489470e-08] 
Layer 'conv5' weights[0]: 7.980105e-03 [9.714592e-08] 
Layer 'conv5' biases: 1.000006e+00 [1.058454e-07] 
Layer 'fc6' weights[0]: 7.576563e-03 [1.014540e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.274932e-09] 
Layer 'fc7' weights[0]: 7.690344e-03 [1.390483e-07] 
Layer 'fc7' biases: 9.998601e-01 [1.235065e-07] 
Layer 'fc8' weights[0]: 7.398229e-04 [7.408726e-06] 
Layer 'fc8' biases: 7.478933e-02 [1.242216e-04] 
Train error last 27 batches: 0.636555
-------------------------------------------------------
Not saving because 0.659879 > 0.627153 (156.15: -0.00%)
======================================================= (1.751 sec)
158.12... logprob:  0.724312, 0.437500 (0.724 sec)
158.13... logprob:  0.659557, 0.359375 (0.718 sec)
158.14... logprob:  0.665024, 0.367188 (0.699 sec)
158.15... logprob:  0.688261, 0.398438 (0.702 sec)
158.16... logprob:  0.627059, 0.320312 (0.718 sec)
158.17... logprob:  0.638505, 0.335938 (0.715 sec)
158.18... logprob:  0.638237, 0.335938 (0.702 sec)
158.19... logprob:  0.632944, 0.328125 (0.699 sec)
158.20... logprob:  0.648572, 0.351562 (0.708 sec)
158.21... logprob:  0.643434, 0.343750 (0.707 sec)
158.22... logprob:  0.629031, 0.320312 (0.696 sec)
158.23... logprob:  0.624670, 0.312500 (0.693 sec)
158.24... logprob:  0.582447, 0.242188 (0.684 sec)
158.25... logprob:  0.629276, 0.320312 (0.684 sec)
158.26... logprob:  0.672623, 0.390625 (0.684 sec)
158.27... logprob:  0.628819, 0.320312 (0.685 sec)
159.1... logprob:  0.678175, 0.398438 (0.686 sec)
159.2... logprob:  0.598690, 0.273438 (0.687 sec)
159.3... logprob:  0.653547, 0.359375 (0.683 sec)
159.4... logprob:  0.597511, 0.273438 (0.686 sec)
159.5... logprob:  0.591271, 0.265625 (0.683 sec)
159.6... logprob:  0.611229, 0.296875 (0.677 sec)
159.7... logprob:  0.644076, 0.343750 (0.678 sec)
159.8... logprob:  0.603967, 0.289062 (0.681 sec)
159.9... logprob:  0.639059, 0.335938 (0.686 sec)
159.10... logprob:  0.596524, 0.281250 (0.684 sec)
159.11... logprob:  0.639998, 0.335938 (0.682 sec)
159.12... logprob:  0.724262, 0.437500 (0.688 sec)
159.13... logprob:  0.659539, 0.359375 (0.690 sec)
159.14... logprob:  0.665008, 0.367188 (0.695 sec)
159.15... logprob:  0.688246, 0.398438 (0.687 sec)
159.16... logprob:  0.627059, 0.320312 (0.683 sec)
159.17... logprob:  0.638506, 0.335938 (0.681 sec)
159.18... logprob:  0.638237, 0.335938 (0.685 sec)
159.19... logprob:  0.632942, 0.328125 (0.683 sec)
159.20... logprob:  0.648574, 0.351562 (0.687 sec)
159.21... logprob:  0.643433, 0.343750 (0.685 sec)
159.22... logprob:  0.629021, 0.320312 (0.689 sec)
159.23... logprob:  0.624656, 0.312500 (0.689 sec)
159.24... logprob:  0.582410, 0.242188 (0.689 sec)
159.25... logprob:  0.629267, 0.320312 (0.686 sec)
159.26... logprob:  0.672632, 0.390625 (0.686 sec)
159.27... logprob:  0.628812, 0.320312 (0.683 sec)
160.1... logprob:  0.678183, 0.398438 (0.683 sec)
160.2... logprob:  0.598680, 0.273438 (0.681 sec)
160.3... logprob:  0.653548, 0.359375 (0.677 sec)
160.4... logprob:  0.597508, 0.273438 (0.678 sec)
160.5... logprob:  0.591272, 0.265625 (0.678 sec)
160.6... logprob:  0.611232, 0.296875 (0.679 sec)
160.7... logprob:  0.644073, 0.343750 (0.680 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627146, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.962517e-03 [6.675153e-09] 
Layer 'conv1' biases: 1.959700e-07 [1.309754e-10] 
Layer 'conv2' weights[0]: 7.949804e-03 [5.839559e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.373532e-10] 
Layer 'conv3' weights[0]: 7.947975e-03 [5.848258e-09] 
Layer 'conv3' biases: 1.843222e-06 [2.122184e-09] 
Layer 'conv4' weights[0]: 7.980506e-03 [6.231681e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.046774e-08] 
Layer 'conv5' weights[0]: 7.979921e-03 [1.324042e-07] 
Layer 'conv5' biases: 1.000006e+00 [1.441407e-07] 
Layer 'fc6' weights[0]: 7.576362e-03 [1.327073e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.274890e-08] 
Layer 'fc7' weights[0]: 7.688421e-03 [1.843127e-07] 
Layer 'fc7' biases: 9.998598e-01 [1.705435e-07] 
Layer 'fc8' weights[0]: 7.035417e-04 [1.017333e-05] 
Layer 'fc8' biases: 7.518514e-02 [1.719738e-04] 
Train error last 27 batches: 0.636542
-------------------------------------------------------
Saved checkpoint to /homes/ad6813/Git/pipe-classification/models/scraping_peeling/net_0/saves/ConvNet__2014-07-08_14.54.04
======================================================= (5.555 sec)
160.8... logprob:  0.603974, 0.289062 (0.679 sec)
160.9... logprob:  0.639053, 0.335938 (0.678 sec)
160.10... logprob:  0.596534, 0.281250 (0.680 sec)
160.11... logprob:  0.639988, 0.335938 (0.680 sec)
160.12... logprob:  0.724214, 0.437500 (0.689 sec)
160.13... logprob:  0.659523, 0.359375 (0.690 sec)
160.14... logprob:  0.664994, 0.367188 (0.681 sec)
160.15... logprob:  0.688233, 0.398438 (0.684 sec)
160.16... logprob:  0.627059, 0.320312 (0.679 sec)
160.17... logprob:  0.638507, 0.335938 (0.683 sec)
160.18... logprob:  0.638237, 0.335938 (0.682 sec)
160.19... logprob:  0.632939, 0.328125 (0.677 sec)
160.20... logprob:  0.648576, 0.351562 (0.687 sec)
160.21... logprob:  0.643431, 0.343750 (0.676 sec)
160.22... logprob:  0.629011, 0.320312 (0.678 sec)
160.23... logprob:  0.624643, 0.312500 (0.675 sec)
160.24... logprob:  0.582374, 0.242188 (0.683 sec)
160.25... logprob:  0.629257, 0.320312 (0.688 sec)
160.26... logprob:  0.672641, 0.390625 (0.677 sec)
160.27... logprob:  0.628806, 0.320312 (0.675 sec)
161.1... logprob:  0.678191, 0.398438 (0.674 sec)
161.2... logprob:  0.598669, 0.273438 (0.681 sec)
161.3... logprob:  0.653549, 0.359375 (0.688 sec)
161.4... logprob:  0.597504, 0.273438 (0.682 sec)
161.5... logprob:  0.591273, 0.265625 (0.681 sec)
161.6... logprob:  0.611235, 0.296875 (0.685 sec)
161.7... logprob:  0.644070, 0.343750 (0.677 sec)
161.8... logprob:  0.603982, 0.289062 (0.685 sec)
161.9... logprob:  0.639048, 0.335938 (0.683 sec)
161.10... logprob:  0.596544, 0.281250 (0.682 sec)
161.11... logprob:  0.639978, 0.335938 (0.680 sec)
161.12... logprob:  0.724165, 0.437500 (0.681 sec)
161.13... logprob:  0.659506, 0.359375 (0.679 sec)
161.14... logprob:  0.664979, 0.367188 (0.680 sec)
161.15... logprob:  0.688219, 0.398438 (0.683 sec)
161.16... logprob:  0.627059, 0.320312 (0.690 sec)
161.17... logprob:  0.638507, 0.335938 (0.688 sec)
161.18... logprob:  0.638237, 0.335938 (0.709 sec)
161.19... logprob:  0.632937, 0.328125 (0.779 sec)
161.20... logprob:  0.648578, 0.351562 (0.812 sec)
161.21... logprob:  0.643430, 0.343750 (0.715 sec)
161.22... logprob:  0.629002, 0.320312 (0.707 sec)
161.23... logprob:  0.624630, 0.312500 (0.708 sec)
161.24... logprob:  0.582338, 0.242188 (0.882 sec)
161.25... logprob:  0.629248, 0.320312 (0.855 sec)
161.26... logprob:  0.672651, 0.390625 (0.847 sec)
161.27... logprob:  0.628800, 0.320312 (0.863 sec)
162.1... logprob:  0.678200, 0.398438 (0.730 sec)
162.2... logprob:  0.598659, 0.273438 (0.745 sec)
162.3... logprob:  0.653550, 0.359375 (0.702 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633251, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.962321e-03 [6.401496e-09] 
Layer 'conv1' biases: 1.991319e-07 [6.984933e-11] 
Layer 'conv2' weights[0]: 7.949620e-03 [4.777642e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.992445e-10] 
Layer 'conv3' weights[0]: 7.947777e-03 [4.590463e-09] 
Layer 'conv3' biases: 1.868460e-06 [8.698071e-10] 
Layer 'conv4' weights[0]: 7.980299e-03 [4.596643e-09] 
Layer 'conv4' biases: 1.000001e+00 [6.888227e-09] 
Layer 'conv5' weights[0]: 7.979736e-03 [4.493260e-08] 
Layer 'conv5' biases: 1.000007e+00 [4.873534e-08] 
Layer 'fc6' weights[0]: 7.576170e-03 [5.797087e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.261531e-09] 
Layer 'fc7' weights[0]: 7.686508e-03 [7.626115e-08] 
Layer 'fc7' biases: 9.998590e-01 [5.627798e-08] 
Layer 'fc8' weights[0]: 6.655848e-04 [3.350798e-06] 
Layer 'fc8' biases: 7.551003e-02 [6.766500e-05] 
Train error last 27 batches: 0.636531
-------------------------------------------------------
Not saving because 0.633251 > 0.627146 (160.7: -0.00%)
======================================================= (1.805 sec)
162.4... logprob:  0.597502, 0.273438 (0.685 sec)
162.5... logprob:  0.591274, 0.265625 (0.686 sec)
162.6... logprob:  0.611238, 0.296875 (0.697 sec)
162.7... logprob:  0.644067, 0.343750 (0.697 sec)
162.8... logprob:  0.603989, 0.289062 (0.701 sec)
162.9... logprob:  0.639043, 0.335938 (0.684 sec)
162.10... logprob:  0.596554, 0.281250 (0.682 sec)
162.11... logprob:  0.639968, 0.335938 (0.683 sec)
162.12... logprob:  0.724116, 0.437500 (0.693 sec)
162.13... logprob:  0.659489, 0.359375 (0.712 sec)
162.14... logprob:  0.664965, 0.367188 (0.685 sec)
162.15... logprob:  0.688206, 0.398438 (0.681 sec)
162.16... logprob:  0.627059, 0.320312 (0.682 sec)
162.17... logprob:  0.638507, 0.335938 (0.689 sec)
162.18... logprob:  0.638237, 0.335938 (0.698 sec)
162.19... logprob:  0.632935, 0.328125 (0.691 sec)
162.20... logprob:  0.648580, 0.351562 (0.691 sec)
162.21... logprob:  0.643429, 0.343750 (0.690 sec)
162.22... logprob:  0.628992, 0.320312 (0.703 sec)
162.23... logprob:  0.624617, 0.312500 (0.714 sec)
162.24... logprob:  0.582302, 0.242188 (0.705 sec)
162.25... logprob:  0.629239, 0.320312 (0.697 sec)
162.26... logprob:  0.672661, 0.390625 (0.688 sec)
162.27... logprob:  0.628793, 0.320312 (0.712 sec)
163.1... logprob:  0.678207, 0.398438 (0.697 sec)
163.2... logprob:  0.598649, 0.273438 (0.707 sec)
163.3... logprob:  0.653551, 0.359375 (0.690 sec)
163.4... logprob:  0.597498, 0.273438 (0.690 sec)
163.5... logprob:  0.591275, 0.265625 (0.689 sec)
163.6... logprob:  0.611241, 0.296875 (0.691 sec)
163.7... logprob:  0.644064, 0.343750 (0.688 sec)
163.8... logprob:  0.603996, 0.289062 (0.692 sec)
163.9... logprob:  0.639038, 0.335938 (0.717 sec)
163.10... logprob:  0.596564, 0.281250 (0.753 sec)
163.11... logprob:  0.639958, 0.335938 (0.717 sec)
163.12... logprob:  0.724067, 0.437500 (0.690 sec)
163.13... logprob:  0.659472, 0.359375 (0.692 sec)
163.14... logprob:  0.664950, 0.367188 (0.691 sec)
163.15... logprob:  0.688192, 0.398438 (0.689 sec)
163.16... logprob:  0.627059, 0.320312 (0.694 sec)
163.17... logprob:  0.638507, 0.335938 (0.689 sec)
163.18... logprob:  0.638237, 0.335938 (0.690 sec)
163.19... logprob:  0.632932, 0.328125 (0.696 sec)
163.20... logprob:  0.648582, 0.351562 (0.692 sec)
163.21... logprob:  0.643428, 0.343750 (0.689 sec)
163.22... logprob:  0.628983, 0.320312 (0.689 sec)
163.23... logprob:  0.624603, 0.312500 (0.693 sec)
163.24... logprob:  0.582264, 0.242188 (0.691 sec)
163.25... logprob:  0.629229, 0.320312 (0.690 sec)
163.26... logprob:  0.672671, 0.390625 (0.702 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.682724, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.962110e-03 [6.111481e-09] 
Layer 'conv1' biases: 2.021261e-07 [5.974874e-11] 
Layer 'conv2' weights[0]: 7.949426e-03 [4.701583e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.445337e-10] 
Layer 'conv3' weights[0]: 7.947597e-03 [4.435543e-09] 
Layer 'conv3' biases: 1.891357e-06 [7.693571e-10] 
Layer 'conv4' weights[0]: 7.980104e-03 [4.431403e-09] 
Layer 'conv4' biases: 1.000001e+00 [5.330514e-09] 
Layer 'conv5' weights[0]: 7.979544e-03 [3.435691e-08] 
Layer 'conv5' biases: 1.000007e+00 [3.720845e-08] 
Layer 'fc6' weights[0]: 7.575977e-03 [5.115732e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.252413e-09] 
Layer 'fc7' weights[0]: 7.684544e-03 [6.450713e-08] 
Layer 'fc7' biases: 9.998589e-01 [4.272494e-08] 
Layer 'fc8' weights[0]: 6.535046e-04 [2.537199e-06] 
Layer 'fc8' biases: 7.626880e-02 [6.036893e-05] 
Train error last 27 batches: 0.636519
-------------------------------------------------------
Not saving because 0.682724 > 0.627146 (160.7: -0.00%)
======================================================= (1.931 sec)
163.27... logprob:  0.628787, 0.320312 (0.706 sec)
164.1... logprob:  0.678216, 0.398438 (0.708 sec)
164.2... logprob:  0.598639, 0.273438 (0.696 sec)
164.3... logprob:  0.653552, 0.359375 (0.691 sec)
164.4... logprob:  0.597496, 0.273438 (0.688 sec)
164.5... logprob:  0.591277, 0.265625 (0.691 sec)
164.6... logprob:  0.611245, 0.296875 (0.690 sec)
164.7... logprob:  0.644061, 0.343750 (0.691 sec)
164.8... logprob:  0.604005, 0.289062 (0.690 sec)
164.9... logprob:  0.639032, 0.335938 (0.765 sec)
164.10... logprob:  0.596575, 0.281250 (0.690 sec)
164.11... logprob:  0.639947, 0.335938 (0.691 sec)
164.12... logprob:  0.724015, 0.437500 (0.703 sec)
164.13... logprob:  0.659454, 0.359375 (0.693 sec)
164.14... logprob:  0.664934, 0.367188 (0.704 sec)
164.15... logprob:  0.688177, 0.398438 (0.695 sec)
164.16... logprob:  0.627058, 0.320312 (0.689 sec)
164.17... logprob:  0.638508, 0.335938 (0.695 sec)
164.18... logprob:  0.638237, 0.335938 (0.691 sec)
164.19... logprob:  0.632930, 0.328125 (0.692 sec)
164.20... logprob:  0.648584, 0.351562 (0.692 sec)
164.21... logprob:  0.643427, 0.343750 (0.726 sec)
164.22... logprob:  0.628973, 0.320312 (0.689 sec)
164.23... logprob:  0.624590, 0.312500 (0.725 sec)
164.24... logprob:  0.582229, 0.242188 (0.688 sec)
164.25... logprob:  0.629220, 0.320312 (0.691 sec)
164.26... logprob:  0.672681, 0.390625 (0.690 sec)
164.27... logprob:  0.628781, 0.320312 (0.690 sec)
165.1... logprob:  0.678225, 0.398438 (0.690 sec)
165.2... logprob:  0.598628, 0.273438 (0.693 sec)
165.3... logprob:  0.653553, 0.359375 (0.694 sec)
165.4... logprob:  0.597492, 0.273438 (0.704 sec)
165.5... logprob:  0.591277, 0.265625 (0.695 sec)
165.6... logprob:  0.611247, 0.296875 (0.691 sec)
165.7... logprob:  0.644059, 0.343750 (0.693 sec)
165.8... logprob:  0.604010, 0.289062 (0.692 sec)
165.9... logprob:  0.639027, 0.335938 (0.691 sec)
165.10... logprob:  0.596584, 0.281250 (0.708 sec)
165.11... logprob:  0.639938, 0.335938 (0.689 sec)
165.12... logprob:  0.723971, 0.437500 (0.692 sec)
165.13... logprob:  0.659439, 0.359375 (0.690 sec)
165.14... logprob:  0.664921, 0.367188 (0.692 sec)
165.15... logprob:  0.688164, 0.398438 (0.688 sec)
165.16... logprob:  0.627059, 0.320312 (0.690 sec)
165.17... logprob:  0.638508, 0.335938 (0.688 sec)
165.18... logprob:  0.638237, 0.335938 (0.690 sec)
165.19... logprob:  0.632928, 0.328125 (0.691 sec)
165.20... logprob:  0.648585, 0.351562 (0.690 sec)
165.21... logprob:  0.643426, 0.343750 (0.694 sec)
165.22... logprob:  0.628965, 0.320312 (0.691 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.634113, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961898e-03 [6.338245e-09] 
Layer 'conv1' biases: 2.050922e-07 [1.210237e-10] 
Layer 'conv2' weights[0]: 7.949220e-03 [5.606844e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.204681e-10] 
Layer 'conv3' weights[0]: 7.947409e-03 [5.059528e-09] 
Layer 'conv3' biases: 1.914108e-06 [1.454991e-09] 
Layer 'conv4' weights[0]: 7.979918e-03 [5.058279e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.072181e-08] 
Layer 'conv5' weights[0]: 7.979352e-03 [6.905861e-08] 
Layer 'conv5' biases: 1.000007e+00 [7.484294e-08] 
Layer 'fc6' weights[0]: 7.575790e-03 [7.896999e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.818912e-09] 
Layer 'fc7' weights[0]: 7.682605e-03 [1.103476e-07] 
Layer 'fc7' biases: 9.998586e-01 [9.345780e-08] 
Layer 'fc8' weights[0]: 6.442141e-04 [5.495217e-06] 
Layer 'fc8' biases: 7.704644e-02 [6.885316e-05] 
Train error last 27 batches: 0.636509
-------------------------------------------------------
Not saving because 0.634113 > 0.627146 (160.7: -0.00%)
======================================================= (1.857 sec)
165.23... logprob:  0.624578, 0.312500 (0.702 sec)
165.24... logprob:  0.582196, 0.242188 (0.696 sec)
165.25... logprob:  0.629211, 0.320312 (0.699 sec)
165.26... logprob:  0.672689, 0.390625 (0.693 sec)
165.27... logprob:  0.628775, 0.320312 (0.689 sec)
166.1... logprob:  0.678232, 0.398438 (0.716 sec)
166.2... logprob:  0.598619, 0.273438 (0.681 sec)
166.3... logprob:  0.653554, 0.359375 (0.681 sec)
166.4... logprob:  0.597488, 0.273438 (0.678 sec)
166.5... logprob:  0.591278, 0.265625 (0.682 sec)
166.6... logprob:  0.611250, 0.296875 (0.679 sec)
166.7... logprob:  0.644056, 0.343750 (0.682 sec)
166.8... logprob:  0.604017, 0.289062 (0.681 sec)
166.9... logprob:  0.639022, 0.335938 (0.680 sec)
166.10... logprob:  0.596593, 0.281250 (0.686 sec)
166.11... logprob:  0.639929, 0.335938 (0.683 sec)
166.12... logprob:  0.723926, 0.437500 (0.681 sec)
166.13... logprob:  0.659423, 0.359375 (0.690 sec)
166.14... logprob:  0.664908, 0.367188 (0.703 sec)
166.15... logprob:  0.688153, 0.398438 (0.715 sec)
166.16... logprob:  0.627059, 0.320312 (0.702 sec)
166.17... logprob:  0.638509, 0.335938 (0.683 sec)
166.18... logprob:  0.638236, 0.335938 (0.683 sec)
166.19... logprob:  0.632925, 0.328125 (0.696 sec)
166.20... logprob:  0.648587, 0.351562 (0.686 sec)
166.21... logprob:  0.643425, 0.343750 (0.689 sec)
166.22... logprob:  0.628955, 0.320312 (0.697 sec)
166.23... logprob:  0.624565, 0.312500 (0.715 sec)
166.24... logprob:  0.582159, 0.242188 (0.682 sec)
166.25... logprob:  0.629201, 0.320312 (0.684 sec)
166.26... logprob:  0.672698, 0.390625 (0.684 sec)
166.27... logprob:  0.628769, 0.320312 (0.683 sec)
167.1... logprob:  0.678240, 0.398438 (0.682 sec)
167.2... logprob:  0.598610, 0.273438 (0.683 sec)
167.3... logprob:  0.653554, 0.359375 (0.688 sec)
167.4... logprob:  0.597487, 0.273438 (0.683 sec)
167.5... logprob:  0.591281, 0.265625 (0.684 sec)
167.6... logprob:  0.611254, 0.296875 (0.686 sec)
167.7... logprob:  0.644053, 0.343750 (0.682 sec)
167.8... logprob:  0.604026, 0.289062 (0.682 sec)
167.9... logprob:  0.639017, 0.335938 (0.685 sec)
167.10... logprob:  0.596604, 0.281250 (0.688 sec)
167.11... logprob:  0.639917, 0.335938 (0.690 sec)
167.12... logprob:  0.723872, 0.437500 (0.693 sec)
167.13... logprob:  0.659405, 0.359375 (0.684 sec)
167.14... logprob:  0.664891, 0.367188 (0.683 sec)
167.15... logprob:  0.688137, 0.398438 (0.684 sec)
167.16... logprob:  0.627058, 0.320312 (0.684 sec)
167.17... logprob:  0.638510, 0.335938 (0.683 sec)
167.18... logprob:  0.638236, 0.335938 (0.691 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627827, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961706e-03 [6.496481e-09] 
Layer 'conv1' biases: 2.078009e-07 [1.761244e-10] 
Layer 'conv2' weights[0]: 7.949007e-03 [6.941163e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.011316e-10] 
Layer 'conv3' weights[0]: 7.947220e-03 [6.272020e-09] 
Layer 'conv3' biases: 1.933014e-06 [2.587148e-09] 
Layer 'conv4' weights[0]: 7.979722e-03 [6.487920e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.194487e-08] 
Layer 'conv5' weights[0]: 7.979141e-03 [1.410582e-07] 
Layer 'conv5' biases: 1.000007e+00 [1.530449e-07] 
Layer 'fc6' weights[0]: 7.575587e-03 [1.432448e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.387304e-08] 
Layer 'fc7' weights[0]: 7.680672e-03 [2.005353e-07] 
Layer 'fc7' biases: 9.998589e-01 [1.879189e-07] 
Layer 'fc8' weights[0]: 6.714601e-04 [1.111517e-05] 
Layer 'fc8' biases: 7.849077e-02 [1.516411e-04] 
Train error last 27 batches: 0.636498
-------------------------------------------------------
Not saving because 0.627827 > 0.627146 (160.7: -0.00%)
======================================================= (1.807 sec)
167.19... logprob:  0.632922, 0.328125 (0.755 sec)
167.20... logprob:  0.648589, 0.351562 (0.701 sec)
167.21... logprob:  0.643424, 0.343750 (0.690 sec)
167.22... logprob:  0.628946, 0.320312 (0.690 sec)
167.23... logprob:  0.624552, 0.312500 (0.692 sec)
167.24... logprob:  0.582122, 0.242188 (0.690 sec)
167.25... logprob:  0.629192, 0.320312 (0.691 sec)
167.26... logprob:  0.672709, 0.390625 (0.706 sec)
167.27... logprob:  0.628762, 0.320312 (0.718 sec)
168.1... logprob:  0.678249, 0.398438 (0.691 sec)
168.2... logprob:  0.598598, 0.273438 (0.695 sec)
168.3... logprob:  0.653556, 0.359375 (0.705 sec)
168.4... logprob:  0.597482, 0.273438 (0.720 sec)
168.5... logprob:  0.591280, 0.265625 (0.692 sec)
168.6... logprob:  0.611256, 0.296875 (0.688 sec)
168.7... logprob:  0.644051, 0.343750 (0.691 sec)
168.8... logprob:  0.604033, 0.289062 (0.691 sec)
168.9... logprob:  0.639012, 0.335938 (0.697 sec)
168.10... logprob:  0.596614, 0.281250 (0.701 sec)
168.11... logprob:  0.639908, 0.335938 (0.716 sec)
168.12... logprob:  0.723826, 0.437500 (0.704 sec)
168.13... logprob:  0.659389, 0.359375 (0.694 sec)
168.14... logprob:  0.664877, 0.367188 (0.688 sec)
168.15... logprob:  0.688123, 0.398438 (0.685 sec)
168.16... logprob:  0.627058, 0.320312 (0.685 sec)
168.17... logprob:  0.638510, 0.335938 (0.684 sec)
168.18... logprob:  0.638236, 0.335938 (0.687 sec)
168.19... logprob:  0.632920, 0.328125 (0.688 sec)
168.20... logprob:  0.648591, 0.351562 (0.693 sec)
168.21... logprob:  0.643423, 0.343750 (0.684 sec)
168.22... logprob:  0.628937, 0.320312 (0.683 sec)
168.23... logprob:  0.624539, 0.312500 (0.688 sec)
168.24... logprob:  0.582087, 0.242188 (0.684 sec)
168.25... logprob:  0.629183, 0.320312 (0.691 sec)
168.26... logprob:  0.672718, 0.390625 (0.683 sec)
168.27... logprob:  0.628756, 0.320312 (0.685 sec)
169.1... logprob:  0.678257, 0.398438 (0.685 sec)
169.2... logprob:  0.598588, 0.273438 (0.703 sec)
169.3... logprob:  0.653557, 0.359375 (0.699 sec)
169.4... logprob:  0.597479, 0.273438 (0.718 sec)
169.5... logprob:  0.591281, 0.265625 (0.688 sec)
169.6... logprob:  0.611259, 0.296875 (0.684 sec)
169.7... logprob:  0.644048, 0.343750 (0.682 sec)
169.8... logprob:  0.604040, 0.289062 (0.684 sec)
169.9... logprob:  0.639007, 0.335938 (0.684 sec)
169.10... logprob:  0.596624, 0.281250 (0.687 sec)
169.11... logprob:  0.639899, 0.335938 (0.686 sec)
169.12... logprob:  0.723779, 0.437500 (0.685 sec)
169.13... logprob:  0.659373, 0.359375 (0.685 sec)
169.14... logprob:  0.664864, 0.367188 (0.683 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.657640, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961519e-03 [6.781818e-09] 
Layer 'conv1' biases: 2.103990e-07 [1.606588e-10] 
Layer 'conv2' weights[0]: 7.948817e-03 [6.575615e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.958150e-10] 
Layer 'conv3' weights[0]: 7.947028e-03 [5.875821e-09] 
Layer 'conv3' biases: 1.950595e-06 [2.252868e-09] 
Layer 'conv4' weights[0]: 7.979518e-03 [6.042976e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.854984e-08] 
Layer 'conv5' weights[0]: 7.978929e-03 [1.192392e-07] 
Layer 'conv5' biases: 1.000006e+00 [1.293732e-07] 
Layer 'fc6' weights[0]: 7.575378e-03 [1.226141e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.174044e-08] 
Layer 'fc7' weights[0]: 7.678701e-03 [1.717607e-07] 
Layer 'fc7' biases: 9.998595e-01 [1.586839e-07] 
Layer 'fc8' weights[0]: 7.153294e-04 [9.398746e-06] 
Layer 'fc8' biases: 8.018152e-02 [1.202733e-04] 
Train error last 27 batches: 0.636487
-------------------------------------------------------
Not saving because 0.657640 > 0.627146 (160.7: -0.00%)
======================================================= (1.750 sec)
169.15... logprob:  0.688111, 0.398438 (0.690 sec)
169.16... logprob:  0.627058, 0.320312 (0.692 sec)
169.17... logprob:  0.638510, 0.335938 (0.690 sec)
169.18... logprob:  0.638237, 0.335938 (0.688 sec)
169.19... logprob:  0.632918, 0.328125 (0.690 sec)
169.20... logprob:  0.648593, 0.351562 (0.690 sec)
169.21... logprob:  0.643422, 0.343750 (0.691 sec)
169.22... logprob:  0.628927, 0.320312 (0.691 sec)
169.23... logprob:  0.624526, 0.312500 (0.693 sec)
169.24... logprob:  0.582051, 0.242188 (0.688 sec)
169.25... logprob:  0.629174, 0.320312 (0.690 sec)
169.26... logprob:  0.672728, 0.390625 (0.684 sec)
169.27... logprob:  0.628750, 0.320312 (0.683 sec)
170.1... logprob:  0.678266, 0.398438 (0.684 sec)
170.2... logprob:  0.598579, 0.273438 (0.686 sec)
170.3... logprob:  0.653557, 0.359375 (0.684 sec)
170.4... logprob:  0.597477, 0.273438 (0.684 sec)
170.5... logprob:  0.591284, 0.265625 (0.685 sec)
170.6... logprob:  0.611263, 0.296875 (0.686 sec)
170.7... logprob:  0.644045, 0.343750 (0.684 sec)
170.8... logprob:  0.604048, 0.289062 (0.685 sec)
170.9... logprob:  0.639001, 0.335938 (0.684 sec)
170.10... logprob:  0.596635, 0.281250 (0.686 sec)
170.11... logprob:  0.639888, 0.335938 (0.683 sec)
170.12... logprob:  0.723726, 0.437500 (0.684 sec)
170.13... logprob:  0.659354, 0.359375 (0.687 sec)
170.14... logprob:  0.664847, 0.367188 (0.683 sec)
170.15... logprob:  0.688095, 0.398438 (0.684 sec)
170.16... logprob:  0.627058, 0.320312 (0.684 sec)
170.17... logprob:  0.638510, 0.335938 (0.684 sec)
170.18... logprob:  0.638236, 0.335938 (0.685 sec)
170.19... logprob:  0.632916, 0.328125 (0.686 sec)
170.20... logprob:  0.648595, 0.351562 (0.687 sec)
170.21... logprob:  0.643421, 0.343750 (0.684 sec)
170.22... logprob:  0.628918, 0.320312 (0.683 sec)
170.23... logprob:  0.624514, 0.312500 (0.685 sec)
170.24... logprob:  0.582016, 0.242188 (0.683 sec)
170.25... logprob:  0.629165, 0.320312 (0.685 sec)
170.26... logprob:  0.672738, 0.390625 (0.683 sec)
170.27... logprob:  0.628744, 0.320312 (0.683 sec)
171.1... logprob:  0.678275, 0.398438 (0.692 sec)
171.2... logprob:  0.598567, 0.273438 (0.686 sec)
171.3... logprob:  0.653559, 0.359375 (0.684 sec)
171.4... logprob:  0.597472, 0.273438 (0.685 sec)
171.5... logprob:  0.591282, 0.265625 (0.687 sec)
171.6... logprob:  0.611264, 0.296875 (0.684 sec)
171.7... logprob:  0.644043, 0.343750 (0.682 sec)
171.8... logprob:  0.604054, 0.289062 (0.682 sec)
171.9... logprob:  0.638997, 0.335938 (0.683 sec)
171.10... logprob:  0.596643, 0.281250 (0.683 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627413, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961314e-03 [6.775847e-09] 
Layer 'conv1' biases: 2.132412e-07 [1.251133e-10] 
Layer 'conv2' weights[0]: 7.948628e-03 [5.891796e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.443167e-10] 
Layer 'conv3' weights[0]: 7.946835e-03 [5.918208e-09] 
Layer 'conv3' biases: 1.971641e-06 [2.155398e-09] 
Layer 'conv4' weights[0]: 7.979326e-03 [6.324584e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.072171e-08] 
Layer 'conv5' weights[0]: 7.978726e-03 [1.328506e-07] 
Layer 'conv5' biases: 1.000005e+00 [1.444365e-07] 
Layer 'fc6' weights[0]: 7.575190e-03 [1.344180e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.294156e-08] 
Layer 'fc7' weights[0]: 7.676731e-03 [1.852463e-07] 
Layer 'fc7' biases: 9.998595e-01 [1.714846e-07] 
Layer 'fc8' weights[0]: 7.235872e-04 [1.020907e-05] 
Layer 'fc8' biases: 8.126649e-02 [1.694845e-04] 
Train error last 27 batches: 0.636478
-------------------------------------------------------
Not saving because 0.627413 > 0.627146 (160.7: -0.00%)
======================================================= (1.739 sec)
171.11... logprob:  0.639879, 0.335938 (0.683 sec)
171.12... logprob:  0.723685, 0.437500 (0.686 sec)
171.13... logprob:  0.659340, 0.359375 (0.683 sec)
171.14... logprob:  0.664834, 0.367188 (0.682 sec)
171.15... logprob:  0.688083, 0.398438 (0.685 sec)
171.16... logprob:  0.627058, 0.320312 (0.685 sec)
171.17... logprob:  0.638511, 0.335938 (0.702 sec)
171.18... logprob:  0.638236, 0.335938 (0.683 sec)
171.19... logprob:  0.632914, 0.328125 (0.683 sec)
171.20... logprob:  0.648597, 0.351562 (0.684 sec)
171.21... logprob:  0.643420, 0.343750 (0.683 sec)
171.22... logprob:  0.628910, 0.320312 (0.684 sec)
171.23... logprob:  0.624502, 0.312500 (0.686 sec)
171.24... logprob:  0.581984, 0.242188 (0.685 sec)
171.25... logprob:  0.629157, 0.320312 (0.683 sec)
171.26... logprob:  0.672746, 0.390625 (0.685 sec)
171.27... logprob:  0.628739, 0.320312 (0.687 sec)
172.1... logprob:  0.678282, 0.398438 (0.696 sec)
172.2... logprob:  0.598559, 0.273438 (0.722 sec)
172.3... logprob:  0.653560, 0.359375 (0.710 sec)
172.4... logprob:  0.597469, 0.273438 (0.682 sec)
172.5... logprob:  0.591284, 0.265625 (0.683 sec)
172.6... logprob:  0.611268, 0.296875 (0.685 sec)
172.7... logprob:  0.644040, 0.343750 (0.685 sec)
172.8... logprob:  0.604061, 0.289062 (0.684 sec)
172.9... logprob:  0.638992, 0.335938 (0.689 sec)
172.10... logprob:  0.596653, 0.281250 (0.682 sec)
172.11... logprob:  0.639869, 0.335938 (0.685 sec)
172.12... logprob:  0.723637, 0.437500 (0.681 sec)
172.13... logprob:  0.659323, 0.359375 (0.684 sec)
172.14... logprob:  0.664820, 0.367188 (0.680 sec)
172.15... logprob:  0.688069, 0.398438 (0.683 sec)
172.16... logprob:  0.627058, 0.320312 (0.702 sec)
172.17... logprob:  0.638511, 0.335938 (0.726 sec)
172.18... logprob:  0.638236, 0.335938 (0.710 sec)
172.19... logprob:  0.632911, 0.328125 (0.693 sec)
172.20... logprob:  0.648599, 0.351562 (0.684 sec)
172.21... logprob:  0.643419, 0.343750 (0.688 sec)
172.22... logprob:  0.628901, 0.320312 (0.687 sec)
172.23... logprob:  0.624490, 0.312500 (0.687 sec)
172.24... logprob:  0.581948, 0.242188 (0.686 sec)
172.25... logprob:  0.629148, 0.320312 (0.688 sec)
172.26... logprob:  0.672756, 0.390625 (0.688 sec)
172.27... logprob:  0.628732, 0.320312 (0.685 sec)
173.1... logprob:  0.678290, 0.398438 (0.687 sec)
173.2... logprob:  0.598548, 0.273438 (0.689 sec)
173.3... logprob:  0.653561, 0.359375 (0.686 sec)
173.4... logprob:  0.597465, 0.273438 (0.685 sec)
173.5... logprob:  0.591284, 0.265625 (0.681 sec)
173.6... logprob:  0.611270, 0.296875 (0.681 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.632796, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961114e-03 [7.037188e-09] 
Layer 'conv1' biases: 2.164239e-07 [1.651434e-10] 
Layer 'conv2' weights[0]: 7.948424e-03 [6.353541e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.076583e-10] 
Layer 'conv3' weights[0]: 7.946651e-03 [6.354547e-09] 
Layer 'conv3' biases: 1.997257e-06 [2.543632e-09] 
Layer 'conv4' weights[0]: 7.979130e-03 [6.734686e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.432296e-08] 
Layer 'conv5' weights[0]: 7.978539e-03 [1.556910e-07] 
Layer 'conv5' biases: 1.000006e+00 [1.692433e-07] 
Layer 'fc6' weights[0]: 7.574989e-03 [1.569821e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.523035e-08] 
Layer 'fc7' weights[0]: 7.674760e-03 [2.160813e-07] 
Layer 'fc7' biases: 9.998590e-01 [2.024233e-07] 
Layer 'fc8' weights[0]: 6.860410e-04 [1.200436e-05] 
Layer 'fc8' biases: 8.158401e-02 [2.058939e-04] 
Train error last 27 batches: 0.636466
-------------------------------------------------------
Not saving because 0.632796 > 0.627146 (160.7: -0.00%)
======================================================= (1.723 sec)
173.7... logprob:  0.644038, 0.343750 (0.681 sec)
173.8... logprob:  0.604068, 0.289062 (0.681 sec)
173.9... logprob:  0.638987, 0.335938 (0.680 sec)
173.10... logprob:  0.596663, 0.281250 (0.682 sec)
173.11... logprob:  0.639860, 0.335938 (0.681 sec)
173.12... logprob:  0.723592, 0.437500 (0.681 sec)
173.13... logprob:  0.659307, 0.359375 (0.679 sec)
173.14... logprob:  0.664806, 0.367188 (0.680 sec)
173.15... logprob:  0.688055, 0.398438 (0.682 sec)
173.16... logprob:  0.627058, 0.320312 (0.682 sec)
173.17... logprob:  0.638511, 0.335938 (0.683 sec)
173.18... logprob:  0.638236, 0.335938 (0.680 sec)
173.19... logprob:  0.632909, 0.328125 (0.682 sec)
173.20... logprob:  0.648600, 0.351562 (0.681 sec)
173.21... logprob:  0.643418, 0.343750 (0.681 sec)
173.22... logprob:  0.628894, 0.320312 (0.681 sec)
173.23... logprob:  0.624478, 0.312500 (0.683 sec)
173.24... logprob:  0.581917, 0.242188 (0.685 sec)
173.25... logprob:  0.629140, 0.320312 (0.682 sec)
173.26... logprob:  0.672764, 0.390625 (0.683 sec)
173.27... logprob:  0.628727, 0.320312 (0.681 sec)
174.1... logprob:  0.678298, 0.398438 (0.683 sec)
174.2... logprob:  0.598538, 0.273438 (0.683 sec)
174.3... logprob:  0.653562, 0.359375 (0.681 sec)
174.4... logprob:  0.597461, 0.273438 (0.681 sec)
174.5... logprob:  0.591284, 0.265625 (0.682 sec)
174.6... logprob:  0.611272, 0.296875 (0.682 sec)
174.7... logprob:  0.644036, 0.343750 (0.680 sec)
174.8... logprob:  0.604073, 0.289062 (0.681 sec)
174.9... logprob:  0.638983, 0.335938 (0.681 sec)
174.10... logprob:  0.596671, 0.281250 (0.686 sec)
174.11... logprob:  0.639852, 0.335938 (0.684 sec)
174.12... logprob:  0.723550, 0.437500 (0.680 sec)
174.13... logprob:  0.659293, 0.359375 (0.682 sec)
174.14... logprob:  0.664794, 0.367188 (0.679 sec)
174.15... logprob:  0.688044, 0.398438 (0.683 sec)
174.16... logprob:  0.627057, 0.320312 (0.682 sec)
174.17... logprob:  0.638512, 0.335938 (0.683 sec)
174.18... logprob:  0.638235, 0.335938 (0.681 sec)
174.19... logprob:  0.632907, 0.328125 (0.682 sec)
174.20... logprob:  0.648603, 0.351562 (0.682 sec)
174.21... logprob:  0.643418, 0.343750 (0.682 sec)
174.22... logprob:  0.628884, 0.320312 (0.683 sec)
174.23... logprob:  0.624466, 0.312500 (0.683 sec)
174.24... logprob:  0.581883, 0.242188 (0.680 sec)
174.25... logprob:  0.629131, 0.320312 (0.682 sec)
174.26... logprob:  0.672773, 0.390625 (0.685 sec)
174.27... logprob:  0.628721, 0.320312 (0.691 sec)
175.1... logprob:  0.678305, 0.398438 (0.694 sec)
175.2... logprob:  0.598530, 0.273438 (0.690 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.683868, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960909e-03 [6.477266e-09] 
Layer 'conv1' biases: 2.195840e-07 [7.714462e-11] 
Layer 'conv2' weights[0]: 7.948245e-03 [4.895904e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.732341e-10] 
Layer 'conv3' weights[0]: 7.946458e-03 [4.768367e-09] 
Layer 'conv3' biases: 2.022089e-06 [1.095497e-09] 
Layer 'conv4' weights[0]: 7.978923e-03 [4.823017e-09] 
Layer 'conv4' biases: 1.000001e+00 [9.232676e-09] 
Layer 'conv5' weights[0]: 7.978354e-03 [5.899849e-08] 
Layer 'conv5' biases: 1.000006e+00 [6.408419e-08] 
Layer 'fc6' weights[0]: 7.574806e-03 [6.975200e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.728759e-09] 
Layer 'fc7' weights[0]: 7.672813e-03 [9.400442e-08] 
Layer 'fc7' biases: 9.998584e-01 [7.538835e-08] 
Layer 'fc8' weights[0]: 6.557591e-04 [4.454615e-06] 
Layer 'fc8' biases: 8.199365e-02 [8.847590e-05] 
Train error last 27 batches: 0.636456
-------------------------------------------------------
Not saving because 0.683868 > 0.627146 (160.7: -0.00%)
======================================================= (1.778 sec)
175.3... logprob:  0.653563, 0.359375 (0.688 sec)
175.4... logprob:  0.597460, 0.273438 (0.690 sec)
175.5... logprob:  0.591287, 0.265625 (0.690 sec)
175.6... logprob:  0.611276, 0.296875 (0.693 sec)
175.7... logprob:  0.644032, 0.343750 (0.694 sec)
175.8... logprob:  0.604082, 0.289062 (0.690 sec)
175.9... logprob:  0.638978, 0.335938 (0.691 sec)
175.10... logprob:  0.596682, 0.281250 (0.691 sec)
175.11... logprob:  0.639842, 0.335938 (0.691 sec)
175.12... logprob:  0.723499, 0.437500 (0.692 sec)
175.13... logprob:  0.659275, 0.359375 (0.687 sec)
175.14... logprob:  0.664778, 0.367188 (0.685 sec)
175.15... logprob:  0.688029, 0.398438 (0.685 sec)
175.16... logprob:  0.627057, 0.320312 (0.686 sec)
175.17... logprob:  0.638512, 0.335938 (0.683 sec)
175.18... logprob:  0.638235, 0.335938 (0.683 sec)
175.19... logprob:  0.632905, 0.328125 (0.690 sec)
175.20... logprob:  0.648604, 0.351562 (0.704 sec)
175.21... logprob:  0.643417, 0.343750 (0.691 sec)
175.22... logprob:  0.628875, 0.320312 (0.689 sec)
175.23... logprob:  0.624453, 0.312500 (0.709 sec)
175.24... logprob:  0.581847, 0.242188 (0.708 sec)
175.25... logprob:  0.629121, 0.320312 (0.689 sec)
175.26... logprob:  0.672784, 0.390625 (0.675 sec)
175.27... logprob:  0.628715, 0.320312 (0.681 sec)
176.1... logprob:  0.678315, 0.398438 (0.692 sec)
176.2... logprob:  0.598518, 0.273438 (0.682 sec)
176.3... logprob:  0.653564, 0.359375 (0.688 sec)
176.4... logprob:  0.597455, 0.273438 (0.685 sec)
176.5... logprob:  0.591286, 0.265625 (0.697 sec)
176.6... logprob:  0.611278, 0.296875 (0.695 sec)
176.7... logprob:  0.644030, 0.343750 (0.686 sec)
176.8... logprob:  0.604088, 0.289062 (0.680 sec)
176.9... logprob:  0.638973, 0.335938 (0.685 sec)
176.10... logprob:  0.596692, 0.281250 (0.684 sec)
176.11... logprob:  0.639833, 0.335938 (0.683 sec)
176.12... logprob:  0.723454, 0.437500 (0.689 sec)
176.13... logprob:  0.659260, 0.359375 (0.691 sec)
176.14... logprob:  0.664764, 0.367188 (0.690 sec)
176.15... logprob:  0.688015, 0.398438 (0.683 sec)
176.16... logprob:  0.627057, 0.320312 (0.683 sec)
176.17... logprob:  0.638512, 0.335938 (0.687 sec)
176.18... logprob:  0.638235, 0.335938 (0.684 sec)
176.19... logprob:  0.632902, 0.328125 (0.723 sec)
176.20... logprob:  0.648606, 0.351562 (0.685 sec)
176.21... logprob:  0.643416, 0.343750 (0.682 sec)
176.22... logprob:  0.628867, 0.320312 (0.685 sec)
176.23... logprob:  0.624441, 0.312500 (0.723 sec)
176.24... logprob:  0.581813, 0.242188 (0.697 sec)
176.25... logprob:  0.629113, 0.320312 (0.722 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633748, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960725e-03 [6.233056e-09] 
Layer 'conv1' biases: 2.226053e-07 [7.453822e-11] 
Layer 'conv2' weights[0]: 7.948037e-03 [4.881483e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.052178e-10] 
Layer 'conv3' weights[0]: 7.946264e-03 [4.801875e-09] 
Layer 'conv3' biases: 2.045313e-06 [1.227880e-09] 
Layer 'conv4' weights[0]: 7.978742e-03 [4.940787e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.101130e-08] 
Layer 'conv5' weights[0]: 7.978160e-03 [6.964967e-08] 
Layer 'conv5' biases: 1.000006e+00 [7.558345e-08] 
Layer 'fc6' weights[0]: 7.574603e-03 [7.943753e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.819483e-09] 
Layer 'fc7' weights[0]: 7.670872e-03 [1.079556e-07] 
Layer 'fc7' biases: 9.998584e-01 [8.998452e-08] 
Layer 'fc8' weights[0]: 6.454294e-04 [5.299567e-06] 
Layer 'fc8' biases: 8.274296e-02 [1.101048e-04] 
Train error last 27 batches: 0.636444
-------------------------------------------------------
Not saving because 0.633748 > 0.627146 (160.7: -0.00%)
======================================================= (1.780 sec)
176.26... logprob:  0.672793, 0.390625 (0.684 sec)
176.27... logprob:  0.628709, 0.320312 (0.698 sec)
177.1... logprob:  0.678322, 0.398438 (0.682 sec)
177.2... logprob:  0.598509, 0.273438 (0.681 sec)
177.3... logprob:  0.653565, 0.359375 (0.674 sec)
177.4... logprob:  0.597452, 0.273438 (0.697 sec)
177.5... logprob:  0.591287, 0.265625 (0.678 sec)
177.6... logprob:  0.611281, 0.296875 (0.678 sec)
177.7... logprob:  0.644028, 0.343750 (0.675 sec)
177.8... logprob:  0.604096, 0.289062 (0.677 sec)
177.9... logprob:  0.638969, 0.335938 (0.679 sec)
177.10... logprob:  0.596702, 0.281250 (0.676 sec)
177.11... logprob:  0.639823, 0.335938 (0.679 sec)
177.12... logprob:  0.723407, 0.437500 (0.678 sec)
177.13... logprob:  0.659243, 0.359375 (0.688 sec)
177.14... logprob:  0.664750, 0.367188 (0.705 sec)
177.15... logprob:  0.688002, 0.398438 (0.678 sec)
177.16... logprob:  0.627058, 0.320312 (0.687 sec)
177.17... logprob:  0.638513, 0.335938 (0.686 sec)
177.18... logprob:  0.638235, 0.335938 (0.677 sec)
177.19... logprob:  0.632900, 0.328125 (0.710 sec)
177.20... logprob:  0.648608, 0.351562 (0.696 sec)
177.21... logprob:  0.643416, 0.343750 (0.680 sec)
177.22... logprob:  0.628858, 0.320312 (0.692 sec)
177.23... logprob:  0.624429, 0.312500 (0.690 sec)
177.24... logprob:  0.581779, 0.242188 (0.681 sec)
177.25... logprob:  0.629104, 0.320312 (0.682 sec)
177.26... logprob:  0.672802, 0.390625 (0.678 sec)
177.27... logprob:  0.628703, 0.320312 (0.679 sec)
178.1... logprob:  0.678331, 0.398438 (0.679 sec)
178.2... logprob:  0.598499, 0.273438 (0.680 sec)
178.3... logprob:  0.653566, 0.359375 (0.681 sec)
178.4... logprob:  0.597448, 0.273438 (0.684 sec)
178.5... logprob:  0.591287, 0.265625 (0.700 sec)
178.6... logprob:  0.611284, 0.296875 (0.685 sec)
178.7... logprob:  0.644025, 0.343750 (0.678 sec)
178.8... logprob:  0.604102, 0.289062 (0.682 sec)
178.9... logprob:  0.638964, 0.335938 (0.680 sec)
178.10... logprob:  0.596712, 0.281250 (0.680 sec)
178.11... logprob:  0.639814, 0.335938 (0.678 sec)
178.12... logprob:  0.723360, 0.437500 (0.681 sec)
178.13... logprob:  0.659227, 0.359375 (0.676 sec)
178.14... logprob:  0.664736, 0.367188 (0.678 sec)
178.15... logprob:  0.687988, 0.398438 (0.695 sec)
178.16... logprob:  0.627058, 0.320312 (0.716 sec)
178.17... logprob:  0.638513, 0.335938 (0.678 sec)
178.18... logprob:  0.638235, 0.335938 (0.678 sec)
178.19... logprob:  0.632898, 0.328125 (0.682 sec)
178.20... logprob:  0.648610, 0.351562 (0.699 sec)
178.21... logprob:  0.643414, 0.343750 (0.681 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.628949, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960528e-03 [6.561903e-09] 
Layer 'conv1' biases: 2.255510e-07 [1.428752e-10] 
Layer 'conv2' weights[0]: 7.947838e-03 [6.199092e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.918260e-10] 
Layer 'conv3' weights[0]: 7.946069e-03 [5.575998e-09] 
Layer 'conv3' biases: 2.067984e-06 [1.976031e-09] 
Layer 'conv4' weights[0]: 7.978560e-03 [5.640217e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.558739e-08] 
Layer 'conv5' weights[0]: 7.977971e-03 [9.911036e-08] 
Layer 'conv5' biases: 1.000006e+00 [1.073143e-07] 
Layer 'fc6' weights[0]: 7.574401e-03 [1.061334e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.892861e-09] 
Layer 'fc7' weights[0]: 7.668949e-03 [1.474231e-07] 
Layer 'fc7' biases: 9.998584e-01 [1.335998e-07] 
Layer 'fc8' weights[0]: 6.435462e-04 [7.832576e-06] 
Layer 'fc8' biases: 8.362632e-02 [1.093756e-04] 
Train error last 27 batches: 0.636435
-------------------------------------------------------
Not saving because 0.628949 > 0.627146 (160.7: -0.00%)
======================================================= (1.736 sec)
178.22... logprob:  0.628850, 0.320312 (0.684 sec)
178.23... logprob:  0.624417, 0.312500 (0.683 sec)
178.24... logprob:  0.581746, 0.242188 (0.689 sec)
178.25... logprob:  0.629096, 0.320312 (0.682 sec)
178.26... logprob:  0.672811, 0.390625 (0.682 sec)
178.27... logprob:  0.628697, 0.320312 (0.682 sec)
179.1... logprob:  0.678339, 0.398438 (0.680 sec)
179.2... logprob:  0.598489, 0.273438 (0.684 sec)
179.3... logprob:  0.653567, 0.359375 (0.682 sec)
179.4... logprob:  0.597444, 0.273438 (0.680 sec)
179.5... logprob:  0.591287, 0.265625 (0.679 sec)
179.6... logprob:  0.611286, 0.296875 (0.678 sec)
179.7... logprob:  0.644023, 0.343750 (0.680 sec)
179.8... logprob:  0.604108, 0.289062 (0.697 sec)
179.9... logprob:  0.638960, 0.335938 (0.683 sec)
179.10... logprob:  0.596720, 0.281250 (0.684 sec)
179.11... logprob:  0.639806, 0.335938 (0.682 sec)
179.12... logprob:  0.723319, 0.437500 (0.684 sec)
179.13... logprob:  0.659213, 0.359375 (0.681 sec)
179.14... logprob:  0.664723, 0.367188 (0.681 sec)
179.15... logprob:  0.687976, 0.398438 (0.681 sec)
179.16... logprob:  0.627057, 0.320312 (0.683 sec)
179.17... logprob:  0.638513, 0.335938 (0.678 sec)
179.18... logprob:  0.638236, 0.335938 (0.682 sec)
179.19... logprob:  0.632896, 0.328125 (0.684 sec)
179.20... logprob:  0.648612, 0.351562 (0.678 sec)
179.21... logprob:  0.643414, 0.343750 (0.682 sec)
179.22... logprob:  0.628841, 0.320312 (0.687 sec)
179.23... logprob:  0.624406, 0.312500 (0.694 sec)
179.24... logprob:  0.581713, 0.242188 (0.695 sec)
179.25... logprob:  0.629088, 0.320312 (0.697 sec)
179.26... logprob:  0.672821, 0.390625 (0.701 sec)
179.27... logprob:  0.628692, 0.320312 (0.695 sec)
180.1... logprob:  0.678347, 0.398438 (0.688 sec)
180.2... logprob:  0.598480, 0.273438 (0.694 sec)
180.3... logprob:  0.653568, 0.359375 (0.688 sec)
180.4... logprob:  0.597442, 0.273438 (0.690 sec)
180.5... logprob:  0.591289, 0.265625 (0.687 sec)
180.6... logprob:  0.611289, 0.296875 (0.695 sec)
180.7... logprob:  0.644020, 0.343750 (0.689 sec)
180.8... logprob:  0.604117, 0.289062 (0.689 sec)
180.9... logprob:  0.638955, 0.335938 (0.694 sec)
180.10... logprob:  0.596731, 0.281250 (0.692 sec)
180.11... logprob:  0.639796, 0.335938 (0.705 sec)
180.12... logprob:  0.723269, 0.437500 (0.689 sec)
180.13... logprob:  0.659196, 0.359375 (0.682 sec)
180.14... logprob:  0.664708, 0.367188 (0.696 sec)
180.15... logprob:  0.687961, 0.398438 (0.714 sec)
180.16... logprob:  0.627057, 0.320312 (0.713 sec)
180.17... logprob:  0.638514, 0.335938 (0.709 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.654644, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960335e-03 [6.532217e-09] 
Layer 'conv1' biases: 2.282473e-07 [1.791634e-10] 
Layer 'conv2' weights[0]: 7.947649e-03 [7.167271e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.511881e-10] 
Layer 'conv3' weights[0]: 7.945874e-03 [6.446920e-09] 
Layer 'conv3' biases: 2.087359e-06 [2.710081e-09] 
Layer 'conv4' weights[0]: 7.978366e-03 [6.717772e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.325410e-08] 
Layer 'conv5' weights[0]: 7.977788e-03 [1.477358e-07] 
Layer 'conv5' biases: 1.000005e+00 [1.601224e-07] 
Layer 'fc6' weights[0]: 7.574203e-03 [1.513453e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.472087e-08] 
Layer 'fc7' weights[0]: 7.666998e-03 [2.095680e-07] 
Layer 'fc7' biases: 9.998587e-01 [1.969026e-07] 
Layer 'fc8' weights[0]: 6.746888e-04 [1.159812e-05] 
Layer 'fc8' biases: 8.511717e-02 [1.619720e-04] 
Train error last 27 batches: 0.636424
-------------------------------------------------------
Not saving because 0.654644 > 0.627146 (160.7: -0.00%)
======================================================= (1.854 sec)
180.18... logprob:  0.638235, 0.335938 (0.777 sec)
180.19... logprob:  0.632894, 0.328125 (0.700 sec)
180.20... logprob:  0.648614, 0.351562 (0.689 sec)
180.21... logprob:  0.643413, 0.343750 (0.730 sec)
180.22... logprob:  0.628834, 0.320312 (0.693 sec)
180.23... logprob:  0.624394, 0.312500 (0.699 sec)
180.24... logprob:  0.581680, 0.242188 (0.681 sec)
180.25... logprob:  0.629079, 0.320312 (0.687 sec)
180.26... logprob:  0.672830, 0.390625 (0.684 sec)
180.27... logprob:  0.628686, 0.320312 (0.680 sec)
181.1... logprob:  0.678355, 0.398438 (0.686 sec)
181.2... logprob:  0.598469, 0.273438 (0.692 sec)
181.3... logprob:  0.653569, 0.359375 (0.694 sec)
181.4... logprob:  0.597437, 0.273438 (0.729 sec)
181.5... logprob:  0.591287, 0.265625 (0.682 sec)
181.6... logprob:  0.611290, 0.296875 (0.763 sec)
181.7... logprob:  0.644019, 0.343750 (0.687 sec)
181.8... logprob:  0.604122, 0.289062 (0.687 sec)
181.9... logprob:  0.638951, 0.335938 (0.688 sec)
181.10... logprob:  0.596739, 0.281250 (0.690 sec)
181.11... logprob:  0.639788, 0.335938 (0.699 sec)
181.12... logprob:  0.723228, 0.437500 (0.687 sec)
181.13... logprob:  0.659182, 0.359375 (0.688 sec)
181.14... logprob:  0.664695, 0.367188 (0.687 sec)
181.15... logprob:  0.687949, 0.398438 (0.689 sec)
181.16... logprob:  0.627057, 0.320312 (0.689 sec)
181.17... logprob:  0.638514, 0.335938 (0.688 sec)
181.18... logprob:  0.638235, 0.335938 (0.688 sec)
181.19... logprob:  0.632892, 0.328125 (0.687 sec)
181.20... logprob:  0.648616, 0.351562 (0.687 sec)
181.21... logprob:  0.643412, 0.343750 (0.688 sec)
181.22... logprob:  0.628825, 0.320312 (0.687 sec)
181.23... logprob:  0.624382, 0.312500 (0.690 sec)
181.24... logprob:  0.581647, 0.242188 (0.688 sec)
181.25... logprob:  0.629070, 0.320312 (0.700 sec)
181.26... logprob:  0.672839, 0.390625 (0.692 sec)
181.27... logprob:  0.628680, 0.320312 (0.724 sec)
182.1... logprob:  0.678363, 0.398438 (0.703 sec)
182.2... logprob:  0.598460, 0.273438 (0.692 sec)
182.3... logprob:  0.653570, 0.359375 (0.687 sec)
182.4... logprob:  0.597435, 0.273438 (0.689 sec)
182.5... logprob:  0.591289, 0.265625 (0.687 sec)
182.6... logprob:  0.611294, 0.296875 (0.687 sec)
182.7... logprob:  0.644016, 0.343750 (0.686 sec)
182.8... logprob:  0.604130, 0.289062 (0.689 sec)
182.9... logprob:  0.638946, 0.335938 (0.705 sec)
182.10... logprob:  0.596750, 0.281250 (0.690 sec)
182.11... logprob:  0.639778, 0.335938 (0.690 sec)
182.12... logprob:  0.723180, 0.437500 (0.692 sec)
182.13... logprob:  0.659165, 0.359375 (0.689 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627354, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960143e-03 [6.439022e-09] 
Layer 'conv1' biases: 2.308667e-07 [1.065725e-10] 
Layer 'conv2' weights[0]: 7.947466e-03 [5.635151e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.509929e-10] 
Layer 'conv3' weights[0]: 7.945676e-03 [5.036630e-09] 
Layer 'conv3' biases: 2.105943e-06 [1.533672e-09] 
Layer 'conv4' weights[0]: 7.978183e-03 [5.053564e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.124941e-08] 
Layer 'conv5' weights[0]: 7.977565e-03 [7.132299e-08] 
Layer 'conv5' biases: 1.000005e+00 [7.716687e-08] 
Layer 'fc6' weights[0]: 7.574011e-03 [8.202230e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.156880e-09] 
Layer 'fc7' weights[0]: 7.665032e-03 [1.134557e-07] 
Layer 'fc7' biases: 9.998592e-01 [9.632738e-08] 
Layer 'fc8' weights[0]: 7.152430e-04 [5.657939e-06] 
Layer 'fc8' biases: 8.673222e-02 [6.679249e-05] 
Train error last 27 batches: 0.636414
-------------------------------------------------------
Not saving because 0.627354 > 0.627146 (160.7: -0.00%)
======================================================= (1.835 sec)
182.14... logprob:  0.664680, 0.367188 (0.687 sec)
182.15... logprob:  0.687934, 0.398438 (0.696 sec)
182.16... logprob:  0.627057, 0.320312 (0.690 sec)
182.17... logprob:  0.638514, 0.335938 (0.689 sec)
182.18... logprob:  0.638235, 0.335938 (0.697 sec)
182.19... logprob:  0.632890, 0.328125 (0.692 sec)
182.20... logprob:  0.648618, 0.351562 (0.690 sec)
182.21... logprob:  0.643412, 0.343750 (0.687 sec)
182.22... logprob:  0.628817, 0.320312 (0.721 sec)
182.23... logprob:  0.624371, 0.312500 (0.694 sec)
182.24... logprob:  0.581614, 0.242188 (0.687 sec)
182.25... logprob:  0.629062, 0.320312 (0.688 sec)
182.26... logprob:  0.672848, 0.390625 (0.687 sec)
182.27... logprob:  0.628674, 0.320312 (0.687 sec)
183.1... logprob:  0.678371, 0.398438 (0.686 sec)
183.2... logprob:  0.598449, 0.273438 (0.689 sec)
183.3... logprob:  0.653571, 0.359375 (0.691 sec)
183.4... logprob:  0.597429, 0.273438 (0.685 sec)
183.5... logprob:  0.591287, 0.265625 (0.687 sec)
183.6... logprob:  0.611295, 0.296875 (0.685 sec)
183.7... logprob:  0.644014, 0.343750 (0.687 sec)
183.8... logprob:  0.604135, 0.289062 (0.689 sec)
183.9... logprob:  0.638942, 0.335938 (0.689 sec)
183.10... logprob:  0.596757, 0.281250 (0.690 sec)
183.11... logprob:  0.639770, 0.335938 (0.688 sec)
183.12... logprob:  0.723139, 0.437500 (0.704 sec)
183.13... logprob:  0.659151, 0.359375 (0.704 sec)
183.14... logprob:  0.664668, 0.367188 (0.723 sec)
183.15... logprob:  0.687922, 0.398438 (0.691 sec)
183.16... logprob:  0.627057, 0.320312 (0.687 sec)
183.17... logprob:  0.638515, 0.335938 (0.690 sec)
183.18... logprob:  0.638235, 0.335938 (0.690 sec)
183.19... logprob:  0.632888, 0.328125 (0.686 sec)
183.20... logprob:  0.648619, 0.351562 (0.698 sec)
183.21... logprob:  0.643411, 0.343750 (0.688 sec)
183.22... logprob:  0.628809, 0.320312 (0.692 sec)
183.23... logprob:  0.624360, 0.312500 (0.686 sec)
183.24... logprob:  0.581583, 0.242188 (0.685 sec)
183.25... logprob:  0.629054, 0.320312 (0.692 sec)
183.26... logprob:  0.672857, 0.390625 (0.685 sec)
183.27... logprob:  0.628669, 0.320312 (0.685 sec)
184.1... logprob:  0.678378, 0.398438 (0.689 sec)
184.2... logprob:  0.598441, 0.273438 (0.774 sec)
184.3... logprob:  0.653572, 0.359375 (0.705 sec)
184.4... logprob:  0.597427, 0.273438 (0.705 sec)
184.5... logprob:  0.591288, 0.265625 (0.686 sec)
184.6... logprob:  0.611298, 0.296875 (0.687 sec)
184.7... logprob:  0.644012, 0.343750 (0.695 sec)
184.8... logprob:  0.604142, 0.289062 (0.685 sec)
184.9... logprob:  0.638937, 0.335938 (0.688 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633186, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959944e-03 [6.538118e-09] 
Layer 'conv1' biases: 2.338482e-07 [1.101821e-10] 
Layer 'conv2' weights[0]: 7.947254e-03 [5.620177e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.610708e-10] 
Layer 'conv3' weights[0]: 7.945476e-03 [5.618146e-09] 
Layer 'conv3' biases: 2.129156e-06 [1.864150e-09] 
Layer 'conv4' weights[0]: 7.977995e-03 [5.944096e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.783629e-08] 
Layer 'conv5' weights[0]: 7.977385e-03 [1.131325e-07] 
Layer 'conv5' biases: 1.000005e+00 [1.227502e-07] 
Layer 'fc6' weights[0]: 7.573812e-03 [1.178796e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.115845e-08] 
Layer 'fc7' weights[0]: 7.663080e-03 [1.605914e-07] 
Layer 'fc7' biases: 9.998589e-01 [1.462885e-07] 
Layer 'fc8' weights[0]: 7.054107e-04 [8.647044e-06] 
Layer 'fc8' biases: 8.748902e-02 [1.514578e-04] 
Train error last 27 batches: 0.636406
-------------------------------------------------------
Not saving because 0.633186 > 0.627146 (160.7: -0.00%)
======================================================= (1.838 sec)
184.10... logprob:  0.596768, 0.281250 (0.692 sec)
184.11... logprob:  0.639762, 0.335938 (0.704 sec)
184.12... logprob:  0.723093, 0.437500 (0.691 sec)
184.13... logprob:  0.659135, 0.359375 (0.686 sec)
184.14... logprob:  0.664654, 0.367188 (0.706 sec)
184.15... logprob:  0.687907, 0.398438 (0.686 sec)
184.16... logprob:  0.627057, 0.320312 (0.689 sec)
184.17... logprob:  0.638515, 0.335938 (0.685 sec)
184.18... logprob:  0.638235, 0.335938 (0.686 sec)
184.19... logprob:  0.632886, 0.328125 (0.685 sec)
184.20... logprob:  0.648621, 0.351562 (0.687 sec)
184.21... logprob:  0.643410, 0.343750 (0.688 sec)
184.22... logprob:  0.628802, 0.320312 (0.687 sec)
184.23... logprob:  0.624349, 0.312500 (0.686 sec)
184.24... logprob:  0.581551, 0.242188 (0.686 sec)
184.25... logprob:  0.629046, 0.320312 (0.715 sec)
184.26... logprob:  0.672866, 0.390625 (0.705 sec)
184.27... logprob:  0.628663, 0.320312 (0.685 sec)
185.1... logprob:  0.678387, 0.398438 (0.686 sec)
185.2... logprob:  0.598430, 0.273438 (0.694 sec)
185.3... logprob:  0.653574, 0.359375 (0.687 sec)
185.4... logprob:  0.597423, 0.273438 (0.685 sec)
185.5... logprob:  0.591288, 0.265625 (0.688 sec)
185.6... logprob:  0.611300, 0.296875 (0.692 sec)
185.7... logprob:  0.644009, 0.343750 (0.687 sec)
185.8... logprob:  0.604148, 0.289062 (0.686 sec)
185.9... logprob:  0.638933, 0.335938 (0.687 sec)
185.10... logprob:  0.596776, 0.281250 (0.687 sec)
185.11... logprob:  0.639753, 0.335938 (0.690 sec)
185.12... logprob:  0.723051, 0.437500 (0.690 sec)
185.13... logprob:  0.659121, 0.359375 (0.693 sec)
185.14... logprob:  0.664641, 0.367188 (0.726 sec)
185.15... logprob:  0.687895, 0.398438 (0.682 sec)
185.16... logprob:  0.627057, 0.320312 (0.681 sec)
185.17... logprob:  0.638515, 0.335938 (0.683 sec)
185.18... logprob:  0.638235, 0.335938 (0.688 sec)
185.19... logprob:  0.632884, 0.328125 (0.691 sec)
185.20... logprob:  0.648623, 0.351562 (0.686 sec)
185.21... logprob:  0.643410, 0.343750 (0.683 sec)
185.22... logprob:  0.628794, 0.320312 (0.682 sec)
185.23... logprob:  0.624337, 0.312500 (0.682 sec)
185.24... logprob:  0.581519, 0.242188 (0.679 sec)
185.25... logprob:  0.629038, 0.320312 (0.684 sec)
185.26... logprob:  0.672874, 0.390625 (0.712 sec)
185.27... logprob:  0.628658, 0.320312 (0.680 sec)
186.1... logprob:  0.678394, 0.398438 (0.679 sec)
186.2... logprob:  0.598421, 0.273438 (0.687 sec)
186.3... logprob:  0.653574, 0.359375 (0.680 sec)
186.4... logprob:  0.597419, 0.273438 (0.681 sec)
186.5... logprob:  0.591288, 0.265625 (0.682 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.686650, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959738e-03 [7.203748e-09] 
Layer 'conv1' biases: 2.370438e-07 [1.454647e-10] 
Layer 'conv2' weights[0]: 7.947063e-03 [6.086315e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.048809e-10] 
Layer 'conv3' weights[0]: 7.945279e-03 [6.049620e-09] 
Layer 'conv3' biases: 2.155054e-06 [2.234837e-09] 
Layer 'conv4' weights[0]: 7.977800e-03 [6.358660e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.118634e-08] 
Layer 'conv5' weights[0]: 7.977201e-03 [1.343559e-07] 
Layer 'conv5' biases: 1.000005e+00 [1.456605e-07] 
Layer 'fc6' weights[0]: 7.573627e-03 [1.382530e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.333301e-08] 
Layer 'fc7' weights[0]: 7.661137e-03 [1.890044e-07] 
Layer 'fc7' biases: 9.998584e-01 [1.753724e-07] 
Layer 'fc8' weights[0]: 6.676991e-04 [1.031837e-05] 
Layer 'fc8' biases: 8.774513e-02 [1.843977e-04] 
Train error last 27 batches: 0.636395
-------------------------------------------------------
Not saving because 0.686650 > 0.627146 (160.7: -0.00%)
======================================================= (1.744 sec)
186.6... logprob:  0.611303, 0.296875 (0.681 sec)
186.7... logprob:  0.644008, 0.343750 (0.680 sec)
186.8... logprob:  0.604155, 0.289062 (0.680 sec)
186.9... logprob:  0.638929, 0.335938 (0.688 sec)
186.10... logprob:  0.596786, 0.281250 (0.704 sec)
186.11... logprob:  0.639745, 0.335938 (0.696 sec)
186.12... logprob:  0.723007, 0.437500 (0.694 sec)
186.13... logprob:  0.659105, 0.359375 (0.724 sec)
186.14... logprob:  0.664627, 0.367188 (0.706 sec)
186.15... logprob:  0.687882, 0.398438 (0.705 sec)
186.16... logprob:  0.627057, 0.320312 (0.704 sec)
186.17... logprob:  0.638515, 0.335938 (0.701 sec)
186.18... logprob:  0.638234, 0.335938 (0.693 sec)
186.19... logprob:  0.632882, 0.328125 (0.704 sec)
186.20... logprob:  0.648625, 0.351562 (0.702 sec)
186.21... logprob:  0.643409, 0.343750 (0.692 sec)
186.22... logprob:  0.628785, 0.320312 (0.700 sec)
186.23... logprob:  0.624326, 0.312500 (0.720 sec)
186.24... logprob:  0.581486, 0.242188 (0.688 sec)
186.25... logprob:  0.629030, 0.320312 (0.688 sec)
186.26... logprob:  0.672884, 0.390625 (0.694 sec)
186.27... logprob:  0.628652, 0.320312 (0.696 sec)
187.1... logprob:  0.678403, 0.398438 (0.697 sec)
187.2... logprob:  0.598411, 0.273438 (0.746 sec)
187.3... logprob:  0.653575, 0.359375 (0.694 sec)
187.4... logprob:  0.597416, 0.273438 (0.713 sec)
187.5... logprob:  0.591288, 0.265625 (0.702 sec)
187.6... logprob:  0.611305, 0.296875 (0.693 sec)
187.7... logprob:  0.644005, 0.343750 (0.695 sec)
187.8... logprob:  0.604161, 0.289062 (0.688 sec)
187.9... logprob:  0.638925, 0.335938 (0.689 sec)
187.10... logprob:  0.596796, 0.281250 (0.690 sec)
187.11... logprob:  0.639735, 0.335938 (0.689 sec)
187.12... logprob:  0.722960, 0.437500 (0.690 sec)
187.13... logprob:  0.659089, 0.359375 (0.689 sec)
187.14... logprob:  0.664613, 0.367188 (0.690 sec)
187.15... logprob:  0.687867, 0.398438 (0.688 sec)
187.16... logprob:  0.627057, 0.320312 (0.688 sec)
187.17... logprob:  0.638516, 0.335938 (0.686 sec)
187.18... logprob:  0.638234, 0.335938 (0.687 sec)
187.19... logprob:  0.632880, 0.328125 (0.690 sec)
187.20... logprob:  0.648627, 0.351562 (0.693 sec)
187.21... logprob:  0.643408, 0.343750 (0.689 sec)
187.22... logprob:  0.628778, 0.320312 (0.687 sec)
187.23... logprob:  0.624315, 0.312500 (0.687 sec)
187.24... logprob:  0.581454, 0.242188 (0.687 sec)
187.25... logprob:  0.629021, 0.320312 (0.688 sec)
187.26... logprob:  0.672893, 0.390625 (0.686 sec)
187.27... logprob:  0.628647, 0.320312 (0.690 sec)
188.1... logprob:  0.678411, 0.398438 (0.692 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633493, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959541e-03 [6.307035e-09] 
Layer 'conv1' biases: 2.401517e-07 [6.150568e-11] 
Layer 'conv2' weights[0]: 7.946866e-03 [4.747350e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.184829e-10] 
Layer 'conv3' weights[0]: 7.945087e-03 [4.327204e-09] 
Layer 'conv3' biases: 2.179504e-06 [5.214631e-10] 
Layer 'conv4' weights[0]: 7.977600e-03 [4.235780e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.750416e-10] 
Layer 'conv5' weights[0]: 7.977030e-03 [4.704087e-09] 
Layer 'conv5' biases: 1.000006e+00 [2.183116e-09] 
Layer 'fc6' weights[0]: 7.573426e-03 [3.807534e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.426501e-10] 
Layer 'fc7' weights[0]: 7.659186e-03 [3.832434e-08] 
Layer 'fc7' biases: 9.998581e-01 [1.904374e-09] 
Layer 'fc8' weights[0]: 6.455122e-04 [1.273153e-07] 
Layer 'fc8' biases: 8.825547e-02 [1.434100e-05] 
Train error last 27 batches: 0.636385
-------------------------------------------------------
Not saving because 0.633493 > 0.627146 (160.7: -0.00%)
======================================================= (1.997 sec)
188.2... logprob:  0.598401, 0.273438 (0.688 sec)
188.3... logprob:  0.653577, 0.359375 (0.685 sec)
188.4... logprob:  0.597411, 0.273438 (0.688 sec)
188.5... logprob:  0.591288, 0.265625 (0.688 sec)
188.6... logprob:  0.611307, 0.296875 (0.693 sec)
188.7... logprob:  0.644003, 0.343750 (0.691 sec)
188.8... logprob:  0.604168, 0.289062 (0.686 sec)
188.9... logprob:  0.638920, 0.335938 (0.687 sec)
188.10... logprob:  0.596805, 0.281250 (0.687 sec)
188.11... logprob:  0.639727, 0.335938 (0.692 sec)
188.12... logprob:  0.722918, 0.437500 (0.686 sec)
188.13... logprob:  0.659074, 0.359375 (0.694 sec)
188.14... logprob:  0.664600, 0.367188 (0.686 sec)
188.15... logprob:  0.687854, 0.398438 (0.687 sec)
188.16... logprob:  0.627057, 0.320312 (0.689 sec)
188.17... logprob:  0.638516, 0.335938 (0.688 sec)
188.18... logprob:  0.638234, 0.335938 (0.687 sec)
188.19... logprob:  0.632878, 0.328125 (0.688 sec)
188.20... logprob:  0.648629, 0.351562 (0.688 sec)
188.21... logprob:  0.643408, 0.343750 (0.688 sec)
188.22... logprob:  0.628770, 0.320312 (0.688 sec)
188.23... logprob:  0.624304, 0.312500 (0.692 sec)
188.24... logprob:  0.581423, 0.242188 (0.690 sec)
188.25... logprob:  0.629014, 0.320312 (0.692 sec)
188.26... logprob:  0.672902, 0.390625 (0.694 sec)
188.27... logprob:  0.628641, 0.320312 (0.695 sec)
189.1... logprob:  0.678419, 0.398438 (0.692 sec)
189.2... logprob:  0.598391, 0.273438 (0.696 sec)
189.3... logprob:  0.653578, 0.359375 (0.686 sec)
189.4... logprob:  0.597408, 0.273438 (0.688 sec)
189.5... logprob:  0.591287, 0.265625 (0.686 sec)
189.6... logprob:  0.611309, 0.296875 (0.688 sec)
189.7... logprob:  0.644001, 0.343750 (0.688 sec)
189.8... logprob:  0.604173, 0.289062 (0.687 sec)
189.9... logprob:  0.638916, 0.335938 (0.703 sec)
189.10... logprob:  0.596814, 0.281250 (0.689 sec)
189.11... logprob:  0.639719, 0.335938 (0.689 sec)
189.12... logprob:  0.722876, 0.437500 (0.687 sec)
189.13... logprob:  0.659060, 0.359375 (0.688 sec)
189.14... logprob:  0.664587, 0.367188 (0.687 sec)
189.15... logprob:  0.687842, 0.398438 (0.709 sec)
189.16... logprob:  0.627057, 0.320312 (0.688 sec)
189.17... logprob:  0.638516, 0.335938 (0.686 sec)
189.18... logprob:  0.638234, 0.335938 (0.687 sec)
189.19... logprob:  0.632876, 0.328125 (0.687 sec)
189.20... logprob:  0.648631, 0.351562 (0.688 sec)
189.21... logprob:  0.643408, 0.343750 (0.688 sec)
189.22... logprob:  0.628762, 0.320312 (0.687 sec)
189.23... logprob:  0.624293, 0.312500 (0.686 sec)
189.24... logprob:  0.581391, 0.242188 (0.689 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.629088, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959334e-03 [6.158569e-09] 
Layer 'conv1' biases: 2.431564e-07 [5.892645e-11] 
Layer 'conv2' weights[0]: 7.946664e-03 [4.736666e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.194297e-10] 
Layer 'conv3' weights[0]: 7.944902e-03 [4.564254e-09] 
Layer 'conv3' biases: 2.202945e-06 [9.666412e-10] 
Layer 'conv4' weights[0]: 7.977395e-03 [4.593013e-09] 
Layer 'conv4' biases: 1.000001e+00 [7.900014e-09] 
Layer 'conv5' weights[0]: 7.976827e-03 [4.955867e-08] 
Layer 'conv5' biases: 1.000006e+00 [5.364497e-08] 
Layer 'fc6' weights[0]: 7.573229e-03 [6.305662e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.918721e-09] 
Layer 'fc7' weights[0]: 7.657242e-03 [8.335827e-08] 
Layer 'fc7' biases: 9.998580e-01 [6.415230e-08] 
Layer 'fc8' weights[0]: 6.353513e-04 [3.744904e-06] 
Layer 'fc8' biases: 8.896598e-02 [8.616397e-05] 
Train error last 27 batches: 0.636374
-------------------------------------------------------
Not saving because 0.629088 > 0.627146 (160.7: -0.00%)
======================================================= (1.877 sec)
189.25... logprob:  0.629006, 0.320312 (0.696 sec)
189.26... logprob:  0.672911, 0.390625 (0.694 sec)
189.27... logprob:  0.628635, 0.320312 (0.693 sec)
190.1... logprob:  0.678427, 0.398438 (0.693 sec)
190.2... logprob:  0.598382, 0.273438 (0.689 sec)
190.3... logprob:  0.653578, 0.359375 (0.686 sec)
190.4... logprob:  0.597405, 0.273438 (0.689 sec)
190.5... logprob:  0.591290, 0.265625 (0.687 sec)
190.6... logprob:  0.611312, 0.296875 (0.687 sec)
190.7... logprob:  0.643998, 0.343750 (0.687 sec)
190.8... logprob:  0.604181, 0.289062 (0.715 sec)
190.9... logprob:  0.638912, 0.335938 (0.682 sec)
190.10... logprob:  0.596824, 0.281250 (0.681 sec)
190.11... logprob:  0.639710, 0.335938 (0.683 sec)
190.12... logprob:  0.722829, 0.437500 (0.686 sec)
190.13... logprob:  0.659044, 0.359375 (0.680 sec)
190.14... logprob:  0.664572, 0.367188 (0.689 sec)
190.15... logprob:  0.687827, 0.398438 (0.682 sec)
190.16... logprob:  0.627057, 0.320312 (0.681 sec)
190.17... logprob:  0.638517, 0.335938 (0.678 sec)
190.18... logprob:  0.638234, 0.335938 (0.682 sec)
190.19... logprob:  0.632875, 0.328125 (0.682 sec)
190.20... logprob:  0.648633, 0.351562 (0.678 sec)
190.21... logprob:  0.643407, 0.343750 (0.689 sec)
190.22... logprob:  0.628754, 0.320312 (0.685 sec)
190.23... logprob:  0.624282, 0.312500 (0.683 sec)
190.24... logprob:  0.581359, 0.242188 (0.679 sec)
190.25... logprob:  0.628998, 0.320312 (0.687 sec)
190.26... logprob:  0.672920, 0.390625 (0.682 sec)
190.27... logprob:  0.628630, 0.320312 (0.684 sec)
191.1... logprob:  0.678435, 0.398438 (0.686 sec)
191.2... logprob:  0.598371, 0.273438 (0.693 sec)
191.3... logprob:  0.653580, 0.359375 (0.683 sec)
191.4... logprob:  0.597399, 0.273438 (0.708 sec)
191.5... logprob:  0.591287, 0.265625 (0.698 sec)
191.6... logprob:  0.611313, 0.296875 (0.688 sec)
191.7... logprob:  0.643997, 0.343750 (0.696 sec)
191.8... logprob:  0.604186, 0.289062 (0.704 sec)
191.9... logprob:  0.638908, 0.335938 (0.705 sec)
191.10... logprob:  0.596832, 0.281250 (0.747 sec)
191.11... logprob:  0.639703, 0.335938 (0.695 sec)
191.12... logprob:  0.722791, 0.437500 (0.724 sec)
191.13... logprob:  0.659030, 0.359375 (0.692 sec)
191.14... logprob:  0.664560, 0.367188 (0.689 sec)
191.15... logprob:  0.687815, 0.398438 (0.699 sec)
191.16... logprob:  0.627057, 0.320312 (0.702 sec)
191.17... logprob:  0.638517, 0.335938 (0.706 sec)
191.18... logprob:  0.638234, 0.335938 (0.698 sec)
191.19... logprob:  0.632873, 0.328125 (0.691 sec)
191.20... logprob:  0.648634, 0.351562 (0.708 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.653489, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959128e-03 [6.656002e-09] 
Layer 'conv1' biases: 2.460318e-07 [1.558609e-10] 
Layer 'conv2' weights[0]: 7.946475e-03 [6.429545e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.630773e-10] 
Layer 'conv3' weights[0]: 7.944708e-03 [5.771971e-09] 
Layer 'conv3' biases: 2.224521e-06 [2.176657e-09] 
Layer 'conv4' weights[0]: 7.977195e-03 [5.827790e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.723869e-08] 
Layer 'conv5' weights[0]: 7.976636e-03 [1.085475e-07] 
Layer 'conv5' biases: 1.000005e+00 [1.172993e-07] 
Layer 'fc6' weights[0]: 7.573045e-03 [1.155733e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.096310e-08] 
Layer 'fc7' weights[0]: 7.655254e-03 [1.593312e-07] 
Layer 'fc7' biases: 9.998581e-01 [1.460316e-07] 
Layer 'fc8' weights[0]: 6.448600e-04 [8.519774e-06] 
Layer 'fc8' biases: 9.004365e-02 [1.226120e-04] 
Train error last 27 batches: 0.636366
-------------------------------------------------------
Not saving because 0.653489 > 0.627146 (160.7: -0.00%)
======================================================= (1.796 sec)
191.21... logprob:  0.643406, 0.343750 (0.681 sec)
191.22... logprob:  0.628747, 0.320312 (0.680 sec)
191.23... logprob:  0.624272, 0.312500 (0.682 sec)
191.24... logprob:  0.581330, 0.242188 (0.685 sec)
191.25... logprob:  0.628991, 0.320312 (0.691 sec)
191.26... logprob:  0.672928, 0.390625 (0.703 sec)
191.27... logprob:  0.628625, 0.320312 (0.733 sec)
192.1... logprob:  0.678442, 0.398438 (0.682 sec)
192.2... logprob:  0.598363, 0.273438 (0.681 sec)
192.3... logprob:  0.653581, 0.359375 (0.680 sec)
192.4... logprob:  0.597396, 0.273438 (0.679 sec)
192.5... logprob:  0.591288, 0.265625 (0.694 sec)
192.6... logprob:  0.611315, 0.296875 (0.690 sec)
192.7... logprob:  0.643995, 0.343750 (0.689 sec)
192.8... logprob:  0.604192, 0.289062 (0.697 sec)
192.9... logprob:  0.638904, 0.335938 (0.692 sec)
192.10... logprob:  0.596841, 0.281250 (0.697 sec)
192.11... logprob:  0.639695, 0.335938 (0.696 sec)
192.12... logprob:  0.722749, 0.437500 (0.688 sec)
192.13... logprob:  0.659016, 0.359375 (0.691 sec)
192.14... logprob:  0.664547, 0.367188 (0.693 sec)
192.15... logprob:  0.687802, 0.398438 (0.688 sec)
192.16... logprob:  0.627057, 0.320312 (0.690 sec)
192.17... logprob:  0.638517, 0.335938 (0.687 sec)
192.18... logprob:  0.638234, 0.335938 (0.687 sec)
192.19... logprob:  0.632871, 0.328125 (0.688 sec)
192.20... logprob:  0.648635, 0.351562 (0.691 sec)
192.21... logprob:  0.643406, 0.343750 (0.693 sec)
192.22... logprob:  0.628740, 0.320312 (0.691 sec)
192.23... logprob:  0.624261, 0.312500 (0.696 sec)
192.24... logprob:  0.581300, 0.242188 (0.688 sec)
192.25... logprob:  0.628983, 0.320312 (0.689 sec)
192.26... logprob:  0.672937, 0.390625 (0.690 sec)
192.27... logprob:  0.628619, 0.320312 (0.693 sec)
193.1... logprob:  0.678450, 0.398438 (0.688 sec)
193.2... logprob:  0.598353, 0.273438 (0.699 sec)
193.3... logprob:  0.653582, 0.359375 (0.686 sec)
193.4... logprob:  0.597392, 0.273438 (0.686 sec)
193.5... logprob:  0.591287, 0.265625 (0.688 sec)
193.6... logprob:  0.611317, 0.296875 (0.687 sec)
193.7... logprob:  0.643993, 0.343750 (0.686 sec)
193.8... logprob:  0.604198, 0.289062 (0.691 sec)
193.9... logprob:  0.638900, 0.335938 (0.687 sec)
193.10... logprob:  0.596850, 0.281250 (0.687 sec)
193.11... logprob:  0.639687, 0.335938 (0.697 sec)
193.12... logprob:  0.722708, 0.437500 (0.693 sec)
193.13... logprob:  0.659002, 0.359375 (0.693 sec)
193.14... logprob:  0.664535, 0.367188 (0.689 sec)
193.15... logprob:  0.687790, 0.398438 (0.690 sec)
193.16... logprob:  0.627056, 0.320312 (0.691 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627209, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958917e-03 [6.895350e-09] 
Layer 'conv1' biases: 2.487754e-07 [1.924697e-10] 
Layer 'conv2' weights[0]: 7.946294e-03 [7.474140e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.012202e-09] 
Layer 'conv3' weights[0]: 7.944510e-03 [6.656470e-09] 
Layer 'conv3' biases: 2.244160e-06 [2.881147e-09] 
Layer 'conv4' weights[0]: 7.976998e-03 [6.861364e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.380444e-08] 
Layer 'conv5' weights[0]: 7.976414e-03 [1.500508e-07] 
Layer 'conv5' biases: 1.000005e+00 [1.622288e-07] 
Layer 'fc6' weights[0]: 7.572851e-03 [1.552366e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.512420e-08] 
Layer 'fc7' weights[0]: 7.653281e-03 [2.127814e-07] 
Layer 'fc7' biases: 9.998585e-01 [2.001734e-07] 
Layer 'fc8' weights[0]: 6.781397e-04 [1.172035e-05] 
Layer 'fc8' biases: 9.155031e-02 [1.669209e-04] 
Train error last 27 batches: 0.636356
-------------------------------------------------------
Not saving because 0.627209 > 0.627146 (160.7: -0.00%)
======================================================= (1.791 sec)
193.17... logprob:  0.638517, 0.335938 (0.687 sec)
193.18... logprob:  0.638234, 0.335938 (0.688 sec)
193.19... logprob:  0.632869, 0.328125 (0.690 sec)
193.20... logprob:  0.648638, 0.351562 (0.692 sec)
193.21... logprob:  0.643405, 0.343750 (0.699 sec)
193.22... logprob:  0.628733, 0.320312 (0.700 sec)
193.23... logprob:  0.624250, 0.312500 (0.689 sec)
193.24... logprob:  0.581269, 0.242188 (0.690 sec)
193.25... logprob:  0.628975, 0.320312 (0.687 sec)
193.26... logprob:  0.672945, 0.390625 (0.690 sec)
193.27... logprob:  0.628614, 0.320312 (0.690 sec)
194.1... logprob:  0.678457, 0.398438 (0.688 sec)
194.2... logprob:  0.598344, 0.273438 (0.688 sec)
194.3... logprob:  0.653583, 0.359375 (0.690 sec)
194.4... logprob:  0.597389, 0.273438 (0.687 sec)
194.5... logprob:  0.591287, 0.265625 (0.688 sec)
194.6... logprob:  0.611320, 0.296875 (0.687 sec)
194.7... logprob:  0.643990, 0.343750 (0.690 sec)
194.8... logprob:  0.604204, 0.289062 (0.686 sec)
194.9... logprob:  0.638896, 0.335938 (0.689 sec)
194.10... logprob:  0.596859, 0.281250 (0.688 sec)
194.11... logprob:  0.639679, 0.335938 (0.705 sec)
194.12... logprob:  0.722666, 0.437500 (0.693 sec)
194.13... logprob:  0.658987, 0.359375 (0.713 sec)
194.14... logprob:  0.664522, 0.367188 (0.682 sec)
194.15... logprob:  0.687777, 0.398438 (0.684 sec)
194.16... logprob:  0.627057, 0.320312 (0.693 sec)
194.17... logprob:  0.638517, 0.335938 (0.701 sec)
194.18... logprob:  0.638234, 0.335938 (0.697 sec)
194.19... logprob:  0.632867, 0.328125 (0.681 sec)
194.20... logprob:  0.648640, 0.351562 (0.680 sec)
194.21... logprob:  0.643405, 0.343750 (0.679 sec)
194.22... logprob:  0.628725, 0.320312 (0.685 sec)
194.23... logprob:  0.624239, 0.312500 (0.685 sec)
194.24... logprob:  0.581238, 0.242188 (0.692 sec)
194.25... logprob:  0.628967, 0.320312 (0.689 sec)
194.26... logprob:  0.672955, 0.390625 (0.689 sec)
194.27... logprob:  0.628609, 0.320312 (0.680 sec)
195.1... logprob:  0.678466, 0.398438 (0.687 sec)
195.2... logprob:  0.598334, 0.273438 (0.687 sec)
195.3... logprob:  0.653584, 0.359375 (0.684 sec)
195.4... logprob:  0.597385, 0.273438 (0.685 sec)
195.5... logprob:  0.591287, 0.265625 (0.683 sec)
195.6... logprob:  0.611322, 0.296875 (0.688 sec)
195.7... logprob:  0.643989, 0.343750 (0.688 sec)
195.8... logprob:  0.604211, 0.289062 (0.685 sec)
195.9... logprob:  0.638892, 0.335938 (0.687 sec)
195.10... logprob:  0.596868, 0.281250 (0.685 sec)
195.11... logprob:  0.639671, 0.335938 (0.686 sec)
195.12... logprob:  0.722622, 0.437500 (0.680 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633692, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958724e-03 [6.630163e-09] 
Layer 'conv1' biases: 2.514850e-07 [8.090429e-11] 
Layer 'conv2' weights[0]: 7.946116e-03 [5.146954e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.514167e-10] 
Layer 'conv3' weights[0]: 7.944317e-03 [4.556981e-09] 
Layer 'conv3' biases: 2.263748e-06 [9.433869e-10] 
Layer 'conv4' weights[0]: 7.976815e-03 [4.466233e-09] 
Layer 'conv4' biases: 1.000001e+00 [4.237129e-09] 
Layer 'conv5' weights[0]: 7.976209e-03 [2.646290e-08] 
Layer 'conv5' biases: 1.000004e+00 [2.823653e-08] 
Layer 'fc6' weights[0]: 7.572645e-03 [4.801638e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.744838e-09] 
Layer 'fc7' weights[0]: 7.651342e-03 [6.002549e-08] 
Layer 'fc7' biases: 9.998589e-01 [3.799609e-08] 
Layer 'fc8' weights[0]: 7.117393e-04 [2.162632e-06] 
Layer 'fc8' biases: 9.302875e-02 [1.465443e-05] 
Train error last 27 batches: 0.636347
-------------------------------------------------------
Not saving because 0.633692 > 0.627146 (160.7: -0.00%)
======================================================= (1.816 sec)
195.13... logprob:  0.658971, 0.359375 (0.687 sec)
195.14... logprob:  0.664507, 0.367188 (0.686 sec)
195.15... logprob:  0.687763, 0.398438 (0.687 sec)
195.16... logprob:  0.627056, 0.320312 (0.685 sec)
195.17... logprob:  0.638517, 0.335938 (0.686 sec)
195.18... logprob:  0.638234, 0.335938 (0.686 sec)
195.19... logprob:  0.632866, 0.328125 (0.686 sec)
195.20... logprob:  0.648642, 0.351562 (0.686 sec)
195.21... logprob:  0.643404, 0.343750 (0.693 sec)
195.22... logprob:  0.628718, 0.320312 (0.692 sec)
195.23... logprob:  0.624229, 0.312500 (0.696 sec)
195.24... logprob:  0.581208, 0.242188 (0.686 sec)
195.25... logprob:  0.628960, 0.320312 (0.690 sec)
195.26... logprob:  0.672964, 0.390625 (0.686 sec)
195.27... logprob:  0.628604, 0.320312 (0.685 sec)
196.1... logprob:  0.678474, 0.398438 (0.684 sec)
196.2... logprob:  0.598324, 0.273438 (0.691 sec)
196.3... logprob:  0.653585, 0.359375 (0.684 sec)
196.4... logprob:  0.597381, 0.273438 (0.685 sec)
196.5... logprob:  0.591286, 0.265625 (0.686 sec)
196.6... logprob:  0.611323, 0.296875 (0.687 sec)
196.7... logprob:  0.643986, 0.343750 (0.688 sec)
196.8... logprob:  0.604216, 0.289062 (0.688 sec)
196.9... logprob:  0.638889, 0.335938 (0.686 sec)
196.10... logprob:  0.596877, 0.281250 (0.691 sec)
196.11... logprob:  0.639663, 0.335938 (0.687 sec)
196.12... logprob:  0.722582, 0.437500 (0.686 sec)
196.13... logprob:  0.658959, 0.359375 (0.686 sec)
196.14... logprob:  0.664496, 0.367188 (0.687 sec)
196.15... logprob:  0.687751, 0.398438 (0.685 sec)
196.16... logprob:  0.627056, 0.320312 (0.688 sec)
196.17... logprob:  0.638518, 0.335938 (0.686 sec)
196.18... logprob:  0.638234, 0.335938 (0.687 sec)
196.19... logprob:  0.632864, 0.328125 (0.690 sec)
196.20... logprob:  0.648643, 0.351562 (0.690 sec)
196.21... logprob:  0.643404, 0.343750 (0.690 sec)
196.22... logprob:  0.628710, 0.320312 (0.692 sec)
196.23... logprob:  0.624219, 0.312500 (0.692 sec)
196.24... logprob:  0.581177, 0.242188 (0.693 sec)
196.25... logprob:  0.628953, 0.320312 (0.694 sec)
196.26... logprob:  0.672972, 0.390625 (0.690 sec)
196.27... logprob:  0.628599, 0.320312 (0.688 sec)
197.1... logprob:  0.678481, 0.398438 (0.691 sec)
197.2... logprob:  0.598316, 0.273438 (0.689 sec)
197.3... logprob:  0.653586, 0.359375 (0.684 sec)
197.4... logprob:  0.597377, 0.273438 (0.682 sec)
197.5... logprob:  0.591286, 0.265625 (0.678 sec)
197.6... logprob:  0.611326, 0.296875 (0.683 sec)
197.7... logprob:  0.643984, 0.343750 (0.684 sec)
197.8... logprob:  0.604223, 0.289062 (0.680 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.691848, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958536e-03 [6.967575e-09] 
Layer 'conv1' biases: 2.545978e-07 [1.400817e-10] 
Layer 'conv2' weights[0]: 7.945929e-03 [6.167091e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.303044e-10] 
Layer 'conv3' weights[0]: 7.944106e-03 [6.117773e-09] 
Layer 'conv3' biases: 2.288863e-06 [2.294541e-09] 
Layer 'conv4' weights[0]: 7.976624e-03 [6.480436e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.183507e-08] 
Layer 'conv5' weights[0]: 7.976021e-03 [1.379222e-07] 
Layer 'conv5' biases: 1.000005e+00 [1.492578e-07] 
Layer 'fc6' weights[0]: 7.572434e-03 [1.424054e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.375381e-08] 
Layer 'fc7' weights[0]: 7.649408e-03 [1.922424e-07] 
Layer 'fc7' biases: 9.998585e-01 [1.787788e-07] 
Layer 'fc8' weights[0]: 6.892745e-04 [1.049944e-05] 
Layer 'fc8' biases: 9.353478e-02 [1.857883e-04] 
Train error last 27 batches: 0.636339
-------------------------------------------------------
Not saving because 0.691848 > 0.627146 (160.7: -0.00%)
======================================================= (1.720 sec)
197.9... logprob:  0.638885, 0.335938 (0.686 sec)
197.10... logprob:  0.596886, 0.281250 (0.709 sec)
197.11... logprob:  0.639655, 0.335938 (0.695 sec)
197.12... logprob:  0.722540, 0.437500 (0.690 sec)
197.13... logprob:  0.658943, 0.359375 (0.689 sec)
197.14... logprob:  0.664482, 0.367188 (0.692 sec)
197.15... logprob:  0.687737, 0.398438 (0.699 sec)
197.16... logprob:  0.627056, 0.320312 (0.689 sec)
197.17... logprob:  0.638518, 0.335938 (0.698 sec)
197.18... logprob:  0.638234, 0.335938 (0.689 sec)
197.19... logprob:  0.632862, 0.328125 (0.693 sec)
197.20... logprob:  0.648645, 0.351562 (0.694 sec)
197.21... logprob:  0.643404, 0.343750 (0.699 sec)
197.22... logprob:  0.628703, 0.320312 (0.690 sec)
197.23... logprob:  0.624209, 0.312500 (0.691 sec)
197.24... logprob:  0.581148, 0.242188 (0.688 sec)
197.25... logprob:  0.628945, 0.320312 (0.684 sec)
197.26... logprob:  0.672981, 0.390625 (0.685 sec)
197.27... logprob:  0.628593, 0.320312 (0.690 sec)
198.1... logprob:  0.678489, 0.398438 (0.696 sec)
198.2... logprob:  0.598306, 0.273438 (0.690 sec)
198.3... logprob:  0.653588, 0.359375 (0.722 sec)
198.4... logprob:  0.597373, 0.273438 (0.693 sec)
198.5... logprob:  0.591286, 0.265625 (0.704 sec)
198.6... logprob:  0.611327, 0.296875 (0.682 sec)
198.7... logprob:  0.643982, 0.343750 (0.683 sec)
198.8... logprob:  0.604228, 0.289062 (0.683 sec)
198.9... logprob:  0.638881, 0.335938 (0.680 sec)
198.10... logprob:  0.596894, 0.281250 (0.684 sec)
198.11... logprob:  0.639647, 0.335938 (0.680 sec)
198.12... logprob:  0.722500, 0.437500 (0.685 sec)
198.13... logprob:  0.658930, 0.359375 (0.681 sec)
198.14... logprob:  0.664470, 0.367188 (0.682 sec)
198.15... logprob:  0.687725, 0.398438 (0.697 sec)
198.16... logprob:  0.627056, 0.320312 (0.848 sec)
198.17... logprob:  0.638518, 0.335938 (0.702 sec)
198.18... logprob:  0.638234, 0.335938 (0.692 sec)
198.19... logprob:  0.632861, 0.328125 (0.697 sec)
198.20... logprob:  0.648647, 0.351562 (0.700 sec)
198.21... logprob:  0.643403, 0.343750 (0.791 sec)
198.22... logprob:  0.628696, 0.320312 (0.748 sec)
198.23... logprob:  0.624198, 0.312500 (0.712 sec)
198.24... logprob:  0.581118, 0.242188 (0.727 sec)
198.25... logprob:  0.628937, 0.320312 (0.703 sec)
198.26... logprob:  0.672990, 0.390625 (0.706 sec)
198.27... logprob:  0.628588, 0.320312 (0.702 sec)
199.1... logprob:  0.678496, 0.398438 (0.692 sec)
199.2... logprob:  0.598297, 0.273438 (0.682 sec)
199.3... logprob:  0.653589, 0.359375 (0.688 sec)
199.4... logprob:  0.597370, 0.273438 (0.683 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633108, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958334e-03 [6.616787e-09] 
Layer 'conv1' biases: 2.578583e-07 [1.013292e-10] 
Layer 'conv2' weights[0]: 7.945740e-03 [5.305058e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.327255e-10] 
Layer 'conv3' weights[0]: 7.943909e-03 [5.181626e-09] 
Layer 'conv3' biases: 2.315668e-06 [1.458014e-09] 
Layer 'conv4' weights[0]: 7.976427e-03 [5.315155e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.311446e-08] 
Layer 'conv5' weights[0]: 7.975857e-03 [8.278344e-08] 
Layer 'conv5' biases: 1.000005e+00 [8.956599e-08] 
Layer 'fc6' weights[0]: 7.572231e-03 [9.293057e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.271538e-09] 
Layer 'fc7' weights[0]: 7.647438e-03 [1.242977e-07] 
Layer 'fc7' biases: 9.998581e-01 [1.072142e-07] 
Layer 'fc8' weights[0]: 6.516575e-04 [6.265004e-06] 
Layer 'fc8' biases: 9.373735e-02 [1.200475e-04] 
Train error last 27 batches: 0.636328
-------------------------------------------------------
Not saving because 0.633108 > 0.627146 (160.7: -0.00%)
======================================================= (1.747 sec)
199.5... logprob:  0.591286, 0.265625 (0.700 sec)
199.6... logprob:  0.611329, 0.296875 (0.736 sec)
199.7... logprob:  0.643981, 0.343750 (0.709 sec)
199.8... logprob:  0.604235, 0.289062 (0.682 sec)
199.9... logprob:  0.638877, 0.335938 (0.680 sec)
199.10... logprob:  0.596904, 0.281250 (0.681 sec)
199.11... logprob:  0.639639, 0.335938 (0.679 sec)
199.12... logprob:  0.722456, 0.437500 (0.699 sec)
199.13... logprob:  0.658915, 0.359375 (0.704 sec)
199.14... logprob:  0.664456, 0.367188 (0.696 sec)
199.15... logprob:  0.687711, 0.398438 (0.696 sec)
199.16... logprob:  0.627056, 0.320312 (0.828 sec)
199.17... logprob:  0.638518, 0.335938 (0.790 sec)
199.18... logprob:  0.638233, 0.335938 (0.736 sec)
199.19... logprob:  0.632859, 0.328125 (0.885 sec)
199.20... logprob:  0.648649, 0.351562 (0.729 sec)
199.21... logprob:  0.643403, 0.343750 (0.842 sec)
199.22... logprob:  0.628689, 0.320312 (0.753 sec)
199.23... logprob:  0.624188, 0.312500 (0.714 sec)
199.24... logprob:  0.581088, 0.242188 (0.762 sec)
199.25... logprob:  0.628930, 0.320312 (0.708 sec)
199.26... logprob:  0.672998, 0.390625 (0.689 sec)
199.27... logprob:  0.628583, 0.320312 (0.694 sec)
200.1... logprob:  0.678505, 0.398438 (0.696 sec)
200.2... logprob:  0.598286, 0.273438 (0.694 sec)
200.3... logprob:  0.653590, 0.359375 (0.697 sec)
200.4... logprob:  0.597365, 0.273438 (0.718 sec)
200.5... logprob:  0.591284, 0.265625 (0.704 sec)
200.6... logprob:  0.611331, 0.296875 (0.681 sec)
200.7... logprob:  0.643979, 0.343750 (0.681 sec)
200.8... logprob:  0.604240, 0.289062 (0.695 sec)
200.9... logprob:  0.638874, 0.335938 (0.701 sec)
200.10... logprob:  0.596912, 0.281250 (0.688 sec)
200.11... logprob:  0.639632, 0.335938 (0.690 sec)
200.12... logprob:  0.722419, 0.437500 (0.688 sec)
200.13... logprob:  0.658902, 0.359375 (0.685 sec)
200.14... logprob:  0.664445, 0.367188 (0.686 sec)
200.15... logprob:  0.687700, 0.398438 (0.700 sec)
200.16... logprob:  0.627056, 0.320312 (0.688 sec)
200.17... logprob:  0.638519, 0.335938 (0.686 sec)
200.18... logprob:  0.638233, 0.335938 (0.709 sec)
200.19... logprob:  0.632857, 0.328125 (0.692 sec)
200.20... logprob:  0.648651, 0.351562 (0.693 sec)
200.21... logprob:  0.643402, 0.343750 (0.687 sec)
200.22... logprob:  0.628681, 0.320312 (0.689 sec)
200.23... logprob:  0.624177, 0.312500 (0.687 sec)
200.24... logprob:  0.581057, 0.242188 (0.687 sec)
200.25... logprob:  0.628923, 0.320312 (0.686 sec)
200.26... logprob:  0.673007, 0.390625 (0.691 sec)
200.27... logprob:  0.628578, 0.320312 (0.686 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.628480, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958126e-03 [6.338406e-09] 
Layer 'conv1' biases: 2.609494e-07 [6.662394e-11] 
Layer 'conv2' weights[0]: 7.945540e-03 [4.766403e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.967118e-10] 
Layer 'conv3' weights[0]: 7.943719e-03 [4.556169e-09] 
Layer 'conv3' biases: 2.340076e-06 [8.793255e-10] 
Layer 'conv4' weights[0]: 7.976227e-03 [4.584486e-09] 
Layer 'conv4' biases: 1.000001e+00 [6.796701e-09] 
Layer 'conv5' weights[0]: 7.975665e-03 [4.276634e-08] 
Layer 'conv5' biases: 1.000005e+00 [4.618208e-08] 
Layer 'fc6' weights[0]: 7.572020e-03 [5.777574e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.236902e-09] 
Layer 'fc7' weights[0]: 7.645444e-03 [7.497075e-08] 
Layer 'fc7' biases: 9.998579e-01 [5.486651e-08] 
Layer 'fc8' weights[0]: 6.394945e-04 [3.175893e-06] 
Layer 'fc8' biases: 9.440255e-02 [7.164699e-05] 
Train error last 27 batches: 0.636319
-------------------------------------------------------
Not saving because 0.628480 > 0.627146 (160.7: -0.00%)
======================================================= (1.881 sec)
201.1... logprob:  0.678512, 0.398438 (0.694 sec)
201.2... logprob:  0.598279, 0.273438 (0.696 sec)
201.3... logprob:  0.653591, 0.359375 (0.693 sec)
201.4... logprob:  0.597363, 0.273438 (0.692 sec)
201.5... logprob:  0.591286, 0.265625 (0.692 sec)
201.6... logprob:  0.611334, 0.296875 (0.692 sec)
201.7... logprob:  0.643976, 0.343750 (0.696 sec)
201.8... logprob:  0.604248, 0.289062 (0.692 sec)
201.9... logprob:  0.638869, 0.335938 (0.694 sec)
201.10... logprob:  0.596923, 0.281250 (0.694 sec)
201.11... logprob:  0.639623, 0.335938 (0.695 sec)
201.12... logprob:  0.722370, 0.437500 (0.696 sec)
201.13... logprob:  0.658885, 0.359375 (0.696 sec)
201.14... logprob:  0.664429, 0.367188 (0.688 sec)
201.15... logprob:  0.687683, 0.398438 (0.686 sec)
201.16... logprob:  0.627056, 0.320312 (0.685 sec)
201.17... logprob:  0.638518, 0.335938 (0.690 sec)
201.18... logprob:  0.638233, 0.335938 (0.692 sec)
201.19... logprob:  0.632856, 0.328125 (0.692 sec)
201.20... logprob:  0.648653, 0.351562 (0.690 sec)
201.21... logprob:  0.643402, 0.343750 (0.710 sec)
201.22... logprob:  0.628675, 0.320312 (0.693 sec)
201.23... logprob:  0.624167, 0.312500 (0.697 sec)
201.24... logprob:  0.581028, 0.242188 (0.693 sec)
201.25... logprob:  0.628915, 0.320312 (0.695 sec)
201.26... logprob:  0.673016, 0.390625 (0.694 sec)
201.27... logprob:  0.628572, 0.320312 (0.695 sec)
202.1... logprob:  0.678520, 0.398438 (0.694 sec)
202.2... logprob:  0.598267, 0.273438 (0.695 sec)
202.3... logprob:  0.653592, 0.359375 (0.694 sec)
202.4... logprob:  0.597356, 0.273438 (0.693 sec)
202.5... logprob:  0.591282, 0.265625 (0.694 sec)
202.6... logprob:  0.611335, 0.296875 (0.693 sec)
202.7... logprob:  0.643975, 0.343750 (0.693 sec)
202.8... logprob:  0.604251, 0.289062 (0.695 sec)
202.9... logprob:  0.638866, 0.335938 (0.694 sec)
202.10... logprob:  0.596929, 0.281250 (0.694 sec)
202.11... logprob:  0.639617, 0.335938 (0.692 sec)
202.12... logprob:  0.722338, 0.437500 (0.693 sec)
202.13... logprob:  0.658873, 0.359375 (0.692 sec)
202.14... logprob:  0.664419, 0.367188 (0.693 sec)
202.15... logprob:  0.687673, 0.398438 (0.695 sec)
202.16... logprob:  0.627056, 0.320312 (0.689 sec)
202.17... logprob:  0.638519, 0.335938 (0.685 sec)
202.18... logprob:  0.638233, 0.335938 (0.690 sec)
202.19... logprob:  0.632854, 0.328125 (0.693 sec)
202.20... logprob:  0.648654, 0.351562 (0.693 sec)
202.21... logprob:  0.643402, 0.343750 (0.690 sec)
202.22... logprob:  0.628668, 0.320312 (0.696 sec)
202.23... logprob:  0.624158, 0.312500 (0.685 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.653169, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957932e-03 [6.074974e-09] 
Layer 'conv1' biases: 2.640501e-07 [9.190399e-11] 
Layer 'conv2' weights[0]: 7.945356e-03 [5.049380e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.588267e-10] 
Layer 'conv3' weights[0]: 7.943525e-03 [4.589219e-09] 
Layer 'conv3' biases: 2.364689e-06 [9.263586e-10] 
Layer 'conv4' weights[0]: 7.976026e-03 [4.498168e-09] 
Layer 'conv4' biases: 1.000001e+00 [5.264599e-09] 
Layer 'conv5' weights[0]: 7.975474e-03 [3.318467e-08] 
Layer 'conv5' biases: 1.000005e+00 [3.549100e-08] 
Layer 'fc6' weights[0]: 7.571829e-03 [5.173583e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.397312e-09] 
Layer 'fc7' weights[0]: 7.643518e-03 [6.635241e-08] 
Layer 'fc7' biases: 9.998575e-01 [4.574095e-08] 
Layer 'fc8' weights[0]: 6.268918e-04 [2.630532e-06] 
Layer 'fc8' biases: 9.502451e-02 [2.727867e-05] 
Train error last 27 batches: 0.636310
-------------------------------------------------------
Not saving because 0.653169 > 0.627146 (160.7: -0.00%)
======================================================= (1.964 sec)
202.24... logprob:  0.581001, 0.242188 (0.701 sec)
202.25... logprob:  0.628908, 0.320312 (0.695 sec)
202.26... logprob:  0.673024, 0.390625 (0.695 sec)
202.27... logprob:  0.628568, 0.320312 (0.693 sec)
203.1... logprob:  0.678527, 0.398438 (0.695 sec)
203.2... logprob:  0.598260, 0.273438 (0.693 sec)
203.3... logprob:  0.653593, 0.359375 (0.696 sec)
203.4... logprob:  0.597354, 0.273438 (0.693 sec)
203.5... logprob:  0.591284, 0.265625 (0.695 sec)
203.6... logprob:  0.611337, 0.296875 (0.693 sec)
203.7... logprob:  0.643973, 0.343750 (0.693 sec)
203.8... logprob:  0.604258, 0.289062 (0.693 sec)
203.9... logprob:  0.638862, 0.335938 (0.694 sec)
203.10... logprob:  0.596938, 0.281250 (0.707 sec)
203.11... logprob:  0.639609, 0.335938 (0.708 sec)
203.12... logprob:  0.722296, 0.437500 (0.693 sec)
203.13... logprob:  0.658859, 0.359375 (0.696 sec)
203.14... logprob:  0.664406, 0.367188 (0.695 sec)
203.15... logprob:  0.687660, 0.398438 (0.694 sec)
203.16... logprob:  0.627056, 0.320312 (0.693 sec)
203.17... logprob:  0.638519, 0.335938 (0.696 sec)
203.18... logprob:  0.638233, 0.335938 (0.699 sec)
203.19... logprob:  0.632852, 0.328125 (0.699 sec)
203.20... logprob:  0.648656, 0.351562 (0.704 sec)
203.21... logprob:  0.643401, 0.343750 (0.695 sec)
203.22... logprob:  0.628661, 0.320312 (0.695 sec)
203.23... logprob:  0.624147, 0.312500 (0.695 sec)
203.24... logprob:  0.580971, 0.242188 (0.692 sec)
203.25... logprob:  0.628901, 0.320312 (0.695 sec)
203.26... logprob:  0.673032, 0.390625 (0.693 sec)
203.27... logprob:  0.628562, 0.320312 (0.710 sec)
204.1... logprob:  0.678535, 0.398438 (0.693 sec)
204.2... logprob:  0.598249, 0.273438 (0.698 sec)
204.3... logprob:  0.653594, 0.359375 (0.691 sec)
204.4... logprob:  0.597349, 0.273438 (0.691 sec)
204.5... logprob:  0.591282, 0.265625 (0.693 sec)
204.6... logprob:  0.611338, 0.296875 (0.695 sec)
204.7... logprob:  0.643971, 0.343750 (0.691 sec)
204.8... logprob:  0.604263, 0.289062 (0.690 sec)
204.9... logprob:  0.638859, 0.335938 (0.706 sec)
204.10... logprob:  0.596947, 0.281250 (0.693 sec)
204.11... logprob:  0.639602, 0.335938 (0.692 sec)
204.12... logprob:  0.722256, 0.437500 (0.693 sec)
204.13... logprob:  0.658845, 0.359375 (0.724 sec)
204.14... logprob:  0.664393, 0.367188 (0.716 sec)
204.15... logprob:  0.687647, 0.398438 (0.705 sec)
204.16... logprob:  0.627056, 0.320312 (0.694 sec)
204.17... logprob:  0.638519, 0.335938 (0.693 sec)
204.18... logprob:  0.638233, 0.335938 (0.694 sec)
204.19... logprob:  0.632851, 0.328125 (0.700 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627995, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957747e-03 [6.681412e-09] 
Layer 'conv1' biases: 2.669809e-07 [1.572154e-10] 
Layer 'conv2' weights[0]: 7.945155e-03 [6.597759e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.822357e-10] 
Layer 'conv3' weights[0]: 7.943317e-03 [5.863760e-09] 
Layer 'conv3' biases: 2.385802e-06 [2.216549e-09] 
Layer 'conv4' weights[0]: 7.975833e-03 [5.920456e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.727850e-08] 
Layer 'conv5' weights[0]: 7.975242e-03 [1.079365e-07] 
Layer 'conv5' biases: 1.000005e+00 [1.163958e-07] 
Layer 'fc6' weights[0]: 7.571634e-03 [1.161410e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.102329e-08] 
Layer 'fc7' weights[0]: 7.641582e-03 [1.586455e-07] 
Layer 'fc7' biases: 9.998577e-01 [1.453059e-07] 
Layer 'fc8' weights[0]: 6.465797e-04 [8.426043e-06] 
Layer 'fc8' biases: 9.628427e-02 [1.228196e-04] 
Train error last 27 batches: 0.636301
-------------------------------------------------------
Not saving because 0.627995 > 0.627146 (160.7: -0.00%)
======================================================= (1.824 sec)
204.20... logprob:  0.648658, 0.351562 (0.685 sec)
204.21... logprob:  0.643401, 0.343750 (0.685 sec)
204.22... logprob:  0.628654, 0.320312 (0.684 sec)
204.23... logprob:  0.624138, 0.312500 (0.686 sec)
204.24... logprob:  0.580942, 0.242188 (0.686 sec)
204.25... logprob:  0.628893, 0.320312 (0.687 sec)
204.26... logprob:  0.673042, 0.390625 (0.687 sec)
204.27... logprob:  0.628557, 0.320312 (0.685 sec)
205.1... logprob:  0.678542, 0.398438 (0.687 sec)
205.2... logprob:  0.598241, 0.273438 (0.687 sec)
205.3... logprob:  0.653596, 0.359375 (0.687 sec)
205.4... logprob:  0.597346, 0.273438 (0.685 sec)
205.5... logprob:  0.591282, 0.265625 (0.690 sec)
205.6... logprob:  0.611341, 0.296875 (0.687 sec)
205.7... logprob:  0.643969, 0.343750 (0.686 sec)
205.8... logprob:  0.604270, 0.289062 (0.684 sec)
205.9... logprob:  0.638855, 0.335938 (0.686 sec)
205.10... logprob:  0.596956, 0.281250 (0.685 sec)
205.11... logprob:  0.639594, 0.335938 (0.686 sec)
205.12... logprob:  0.722214, 0.437500 (0.686 sec)
205.13... logprob:  0.658831, 0.359375 (0.687 sec)
205.14... logprob:  0.664380, 0.367188 (0.687 sec)
205.15... logprob:  0.687633, 0.398438 (0.686 sec)
205.16... logprob:  0.627056, 0.320312 (0.689 sec)
205.17... logprob:  0.638519, 0.335938 (0.724 sec)
205.18... logprob:  0.638233, 0.335938 (0.732 sec)
205.19... logprob:  0.632849, 0.328125 (0.715 sec)
205.20... logprob:  0.648659, 0.351562 (0.690 sec)
205.21... logprob:  0.643400, 0.343750 (0.697 sec)
205.22... logprob:  0.628647, 0.320312 (0.687 sec)
205.23... logprob:  0.624128, 0.312500 (0.687 sec)
205.24... logprob:  0.580913, 0.242188 (0.687 sec)
205.25... logprob:  0.628886, 0.320312 (0.688 sec)
205.26... logprob:  0.673049, 0.390625 (0.687 sec)
205.27... logprob:  0.628552, 0.320312 (0.691 sec)
206.1... logprob:  0.678550, 0.398438 (0.688 sec)
206.2... logprob:  0.598230, 0.273438 (0.691 sec)
206.3... logprob:  0.653597, 0.359375 (0.695 sec)
206.4... logprob:  0.597341, 0.273438 (0.702 sec)
206.5... logprob:  0.591280, 0.265625 (0.704 sec)
206.6... logprob:  0.611342, 0.296875 (0.695 sec)
206.7... logprob:  0.643968, 0.343750 (0.695 sec)
206.8... logprob:  0.604274, 0.289062 (0.695 sec)
206.9... logprob:  0.638851, 0.335938 (0.695 sec)
206.10... logprob:  0.596964, 0.281250 (0.694 sec)
206.11... logprob:  0.639587, 0.335938 (0.694 sec)
206.12... logprob:  0.722177, 0.437500 (0.695 sec)
206.13... logprob:  0.658818, 0.359375 (0.694 sec)
206.14... logprob:  0.664369, 0.367188 (0.693 sec)
206.15... logprob:  0.687623, 0.398438 (0.696 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.632889, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957549e-03 [7.340776e-09] 
Layer 'conv1' biases: 2.698298e-07 [2.138127e-10] 
Layer 'conv2' weights[0]: 7.944954e-03 [7.923056e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.102955e-09] 
Layer 'conv3' weights[0]: 7.943124e-03 [6.979348e-09] 
Layer 'conv3' biases: 2.405533e-06 [3.154451e-09] 
Layer 'conv4' weights[0]: 7.975631e-03 [7.194910e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.594901e-08] 
Layer 'conv5' weights[0]: 7.975031e-03 [1.619209e-07] 
Layer 'conv5' biases: 1.000004e+00 [1.747619e-07] 
Layer 'fc6' weights[0]: 7.571448e-03 [1.686017e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.646590e-08] 
Layer 'fc7' weights[0]: 7.639631e-03 [2.278693e-07] 
Layer 'fc7' biases: 9.998582e-01 [2.153617e-07] 
Layer 'fc8' weights[0]: 6.814272e-04 [1.255144e-05] 
Layer 'fc8' biases: 9.779830e-02 [1.835132e-04] 
Train error last 27 batches: 0.636291
-------------------------------------------------------
Not saving because 0.632889 > 0.627146 (160.7: -0.00%)
======================================================= (1.787 sec)
206.16... logprob:  0.627056, 0.320312 (0.686 sec)
206.17... logprob:  0.638519, 0.335938 (0.687 sec)
206.18... logprob:  0.638233, 0.335938 (0.688 sec)
206.19... logprob:  0.632848, 0.328125 (0.685 sec)
206.20... logprob:  0.648662, 0.351562 (0.688 sec)
206.21... logprob:  0.643400, 0.343750 (0.686 sec)
206.22... logprob:  0.628640, 0.320312 (0.688 sec)
206.23... logprob:  0.624118, 0.312500 (0.686 sec)
206.24... logprob:  0.580884, 0.242188 (0.698 sec)
206.25... logprob:  0.628879, 0.320312 (0.706 sec)
206.26... logprob:  0.673058, 0.390625 (0.687 sec)
206.27... logprob:  0.628547, 0.320312 (0.685 sec)
207.1... logprob:  0.678558, 0.398438 (0.687 sec)
207.2... logprob:  0.598223, 0.273438 (0.695 sec)
207.3... logprob:  0.653598, 0.359375 (0.690 sec)
207.4... logprob:  0.597338, 0.273438 (0.691 sec)
207.5... logprob:  0.591281, 0.265625 (0.685 sec)
207.6... logprob:  0.611344, 0.296875 (0.690 sec)
207.7... logprob:  0.643966, 0.343750 (0.710 sec)
207.8... logprob:  0.604282, 0.289062 (0.699 sec)
207.9... logprob:  0.638848, 0.335938 (0.690 sec)
207.10... logprob:  0.596974, 0.281250 (0.693 sec)
207.11... logprob:  0.639579, 0.335938 (0.692 sec)
207.12... logprob:  0.722132, 0.437500 (0.695 sec)
207.13... logprob:  0.658803, 0.359375 (0.694 sec)
207.14... logprob:  0.664354, 0.367188 (0.695 sec)
207.15... logprob:  0.687607, 0.398438 (0.727 sec)
207.16... logprob:  0.627056, 0.320312 (0.687 sec)
207.17... logprob:  0.638520, 0.335938 (0.687 sec)
207.18... logprob:  0.638233, 0.335938 (0.687 sec)
207.19... logprob:  0.632846, 0.328125 (0.686 sec)
207.20... logprob:  0.648664, 0.351562 (0.688 sec)
207.21... logprob:  0.643400, 0.343750 (0.688 sec)
207.22... logprob:  0.628633, 0.320312 (0.687 sec)
207.23... logprob:  0.624108, 0.312500 (0.689 sec)
207.24... logprob:  0.580854, 0.242188 (0.686 sec)
207.25... logprob:  0.628872, 0.320312 (0.691 sec)
207.26... logprob:  0.673068, 0.390625 (0.685 sec)
207.27... logprob:  0.628543, 0.320312 (0.687 sec)
208.1... logprob:  0.678567, 0.398438 (0.687 sec)
208.2... logprob:  0.598211, 0.273438 (0.689 sec)
208.3... logprob:  0.653600, 0.359375 (0.684 sec)
208.4... logprob:  0.597333, 0.273438 (0.690 sec)
208.5... logprob:  0.591279, 0.265625 (0.688 sec)
208.6... logprob:  0.611345, 0.296875 (0.693 sec)
208.7... logprob:  0.643964, 0.343750 (0.685 sec)
208.8... logprob:  0.604287, 0.289062 (0.687 sec)
208.9... logprob:  0.638844, 0.335938 (0.690 sec)
208.10... logprob:  0.596982, 0.281250 (0.688 sec)
208.11... logprob:  0.639572, 0.335938 (0.686 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.696842, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957363e-03 [6.564952e-09] 
Layer 'conv1' biases: 2.727649e-07 [1.013383e-10] 
Layer 'conv2' weights[0]: 7.944764e-03 [5.395308e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.846847e-10] 
Layer 'conv3' weights[0]: 7.942931e-03 [5.335733e-09] 
Layer 'conv3' biases: 2.426189e-06 [1.608328e-09] 
Layer 'conv4' weights[0]: 7.975423e-03 [5.560490e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.505072e-08] 
Layer 'conv5' weights[0]: 7.974837e-03 [9.473113e-08] 
Layer 'conv5' biases: 1.000004e+00 [1.024620e-07] 
Layer 'fc6' weights[0]: 7.571242e-03 [1.030812e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.473200e-09] 
Layer 'fc7' weights[0]: 7.637664e-03 [1.368615e-07] 
Layer 'fc7' biases: 9.998584e-01 [1.211881e-07] 
Layer 'fc8' weights[0]: 7.051533e-04 [7.117072e-06] 
Layer 'fc8' biases: 9.908653e-02 [1.294747e-04] 
Train error last 27 batches: 0.636284
-------------------------------------------------------
Not saving because 0.696842 > 0.627146 (160.7: -0.00%)
======================================================= (1.758 sec)
208.12... logprob:  0.722095, 0.437500 (0.687 sec)
208.13... logprob:  0.658790, 0.359375 (0.688 sec)
208.14... logprob:  0.664343, 0.367188 (0.687 sec)
208.15... logprob:  0.687595, 0.398438 (0.693 sec)
208.16... logprob:  0.627056, 0.320312 (0.686 sec)
208.17... logprob:  0.638520, 0.335938 (0.686 sec)
208.18... logprob:  0.638233, 0.335938 (0.690 sec)
208.19... logprob:  0.632845, 0.328125 (0.686 sec)
208.20... logprob:  0.648665, 0.351562 (0.685 sec)
208.21... logprob:  0.643400, 0.343750 (0.705 sec)
208.22... logprob:  0.628627, 0.320312 (0.745 sec)
208.23... logprob:  0.624098, 0.312500 (0.702 sec)
208.24... logprob:  0.580827, 0.242188 (0.702 sec)
208.25... logprob:  0.628865, 0.320312 (0.808 sec)
208.26... logprob:  0.673076, 0.390625 (0.853 sec)
208.27... logprob:  0.628537, 0.320312 (0.791 sec)
209.1... logprob:  0.678573, 0.398438 (0.711 sec)
209.2... logprob:  0.598203, 0.273438 (0.705 sec)
209.3... logprob:  0.653601, 0.359375 (0.709 sec)
209.4... logprob:  0.597329, 0.273438 (0.718 sec)
209.5... logprob:  0.591279, 0.265625 (0.722 sec)
209.6... logprob:  0.611347, 0.296875 (0.701 sec)
209.7... logprob:  0.643962, 0.343750 (0.693 sec)
209.8... logprob:  0.604292, 0.289062 (0.691 sec)
209.9... logprob:  0.638841, 0.335938 (0.690 sec)
209.10... logprob:  0.596990, 0.281250 (0.694 sec)
209.11... logprob:  0.639565, 0.335938 (0.698 sec)
209.12... logprob:  0.722057, 0.437500 (0.713 sec)
209.13... logprob:  0.658777, 0.359375 (0.739 sec)
209.14... logprob:  0.664331, 0.367188 (0.691 sec)
209.15... logprob:  0.687583, 0.398438 (0.703 sec)
209.16... logprob:  0.627056, 0.320312 (0.706 sec)
209.17... logprob:  0.638520, 0.335938 (0.698 sec)
209.18... logprob:  0.638232, 0.335938 (0.694 sec)
209.19... logprob:  0.632843, 0.328125 (0.694 sec)
209.20... logprob:  0.648667, 0.351562 (0.693 sec)
209.21... logprob:  0.643399, 0.343750 (0.697 sec)
209.22... logprob:  0.628620, 0.320312 (0.692 sec)
209.23... logprob:  0.624089, 0.312500 (0.693 sec)
209.24... logprob:  0.580799, 0.242188 (0.698 sec)
209.25... logprob:  0.628858, 0.320312 (0.687 sec)
209.26... logprob:  0.673084, 0.390625 (0.686 sec)
209.27... logprob:  0.628533, 0.320312 (0.687 sec)
210.1... logprob:  0.678580, 0.398438 (0.687 sec)
210.2... logprob:  0.598194, 0.273438 (0.690 sec)
210.3... logprob:  0.653601, 0.359375 (0.689 sec)
210.4... logprob:  0.597325, 0.273438 (0.702 sec)
210.5... logprob:  0.591278, 0.265625 (0.700 sec)
210.6... logprob:  0.611349, 0.296875 (0.698 sec)
210.7... logprob:  0.643961, 0.343750 (0.701 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.632854, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957162e-03 [6.682164e-09] 
Layer 'conv1' biases: 2.761427e-07 [1.310578e-10] 
Layer 'conv2' weights[0]: 7.944563e-03 [5.802305e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.314208e-10] 
Layer 'conv3' weights[0]: 7.942720e-03 [5.737649e-09] 
Layer 'conv3' biases: 2.452906e-06 [1.991337e-09] 
Layer 'conv4' weights[0]: 7.975225e-03 [6.013944e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.882667e-08] 
Layer 'conv5' weights[0]: 7.974645e-03 [1.169485e-07] 
Layer 'conv5' biases: 1.000005e+00 [1.264922e-07] 
Layer 'fc6' weights[0]: 7.571065e-03 [1.240687e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.184614e-08] 
Layer 'fc7' weights[0]: 7.635709e-03 [1.668100e-07] 
Layer 'fc7' biases: 9.998579e-01 [1.529547e-07] 
Layer 'fc8' weights[0]: 6.721338e-04 [8.890055e-06] 
Layer 'fc8' biases: 9.936476e-02 [1.648332e-04] 
Train error last 27 batches: 0.636275
-------------------------------------------------------
Not saving because 0.632854 > 0.627146 (160.7: -0.00%)
======================================================= (1.868 sec)
210.8... logprob:  0.604297, 0.289062 (0.685 sec)
210.9... logprob:  0.638837, 0.335938 (0.683 sec)
210.10... logprob:  0.596999, 0.281250 (0.716 sec)
210.11... logprob:  0.639557, 0.335938 (0.682 sec)
210.12... logprob:  0.722018, 0.437500 (0.681 sec)
210.13... logprob:  0.658763, 0.359375 (0.686 sec)
210.14... logprob:  0.664318, 0.367188 (0.682 sec)
210.15... logprob:  0.687571, 0.398438 (0.681 sec)
210.16... logprob:  0.627056, 0.320312 (0.681 sec)
210.17... logprob:  0.638520, 0.335938 (0.677 sec)
210.18... logprob:  0.638233, 0.335938 (0.682 sec)
210.19... logprob:  0.632842, 0.328125 (0.688 sec)
210.20... logprob:  0.648668, 0.351562 (0.686 sec)
210.21... logprob:  0.643399, 0.343750 (0.683 sec)
210.22... logprob:  0.628614, 0.320312 (0.682 sec)
210.23... logprob:  0.624080, 0.312500 (0.682 sec)
210.24... logprob:  0.580771, 0.242188 (0.686 sec)
210.25... logprob:  0.628851, 0.320312 (0.687 sec)
210.26... logprob:  0.673092, 0.390625 (0.685 sec)
210.27... logprob:  0.628528, 0.320312 (0.690 sec)
211.1... logprob:  0.678588, 0.398438 (0.692 sec)
211.2... logprob:  0.598185, 0.273438 (0.687 sec)
211.3... logprob:  0.653603, 0.359375 (0.688 sec)
211.4... logprob:  0.597322, 0.273438 (0.687 sec)
211.5... logprob:  0.591277, 0.265625 (0.690 sec)
211.6... logprob:  0.611350, 0.296875 (0.693 sec)
211.7... logprob:  0.643959, 0.343750 (0.686 sec)
211.8... logprob:  0.604303, 0.289062 (0.685 sec)
211.9... logprob:  0.638834, 0.335938 (0.689 sec)
211.10... logprob:  0.597007, 0.281250 (0.688 sec)
211.11... logprob:  0.639551, 0.335938 (0.679 sec)
211.12... logprob:  0.721980, 0.437500 (0.681 sec)
211.13... logprob:  0.658750, 0.359375 (0.682 sec)
211.14... logprob:  0.664306, 0.367188 (0.683 sec)
211.15... logprob:  0.687558, 0.398438 (0.686 sec)
211.16... logprob:  0.627056, 0.320312 (0.680 sec)
211.17... logprob:  0.638520, 0.335938 (0.682 sec)
211.18... logprob:  0.638233, 0.335938 (0.682 sec)
211.19... logprob:  0.632840, 0.328125 (0.683 sec)
211.20... logprob:  0.648670, 0.351562 (0.682 sec)
211.21... logprob:  0.643399, 0.343750 (0.689 sec)
211.22... logprob:  0.628607, 0.320312 (0.685 sec)
211.23... logprob:  0.624070, 0.312500 (0.684 sec)
211.24... logprob:  0.580743, 0.242188 (0.683 sec)
211.25... logprob:  0.628844, 0.320312 (0.685 sec)
211.26... logprob:  0.673101, 0.390625 (0.689 sec)
211.27... logprob:  0.628523, 0.320312 (0.684 sec)
212.1... logprob:  0.678596, 0.398438 (0.682 sec)
212.2... logprob:  0.598176, 0.273438 (0.685 sec)
212.3... logprob:  0.653603, 0.359375 (0.683 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.628172, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956960e-03 [6.510041e-09] 
Layer 'conv1' biases: 2.795521e-07 [6.538885e-11] 
Layer 'conv2' weights[0]: 7.944357e-03 [4.818469e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.683660e-10] 
Layer 'conv3' weights[0]: 7.942521e-03 [4.510369e-09] 
Layer 'conv3' biases: 2.479562e-06 [7.735272e-10] 
Layer 'conv4' weights[0]: 7.975024e-03 [4.454692e-09] 
Layer 'conv4' biases: 1.000001e+00 [5.118214e-09] 
Layer 'conv5' weights[0]: 7.974467e-03 [3.264870e-08] 
Layer 'conv5' biases: 1.000005e+00 [3.505436e-08] 
Layer 'fc6' weights[0]: 7.570888e-03 [5.104012e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.236076e-09] 
Layer 'fc7' weights[0]: 7.633758e-03 [6.352071e-08] 
Layer 'fc7' biases: 9.998574e-01 [4.133018e-08] 
Layer 'fc8' weights[0]: 6.397172e-04 [2.389461e-06] 
Layer 'fc8' biases: 9.961608e-02 [5.406048e-05] 
Train error last 27 batches: 0.636266
-------------------------------------------------------
Not saving because 0.628172 > 0.627146 (160.7: -0.00%)
======================================================= (1.803 sec)
212.4... logprob:  0.597318, 0.273438 (0.681 sec)
212.5... logprob:  0.591276, 0.265625 (0.681 sec)
212.6... logprob:  0.611352, 0.296875 (0.683 sec)
212.7... logprob:  0.643957, 0.343750 (0.681 sec)
212.8... logprob:  0.604308, 0.289062 (0.680 sec)
212.9... logprob:  0.638831, 0.335938 (0.684 sec)
212.10... logprob:  0.597016, 0.281250 (0.682 sec)
212.11... logprob:  0.639543, 0.335938 (0.682 sec)
212.12... logprob:  0.721941, 0.437500 (0.680 sec)
212.13... logprob:  0.658736, 0.359375 (0.690 sec)
212.14... logprob:  0.664294, 0.367188 (0.687 sec)
212.15... logprob:  0.687545, 0.398438 (0.700 sec)
212.16... logprob:  0.627056, 0.320312 (0.693 sec)
212.17... logprob:  0.638520, 0.335938 (0.685 sec)
212.18... logprob:  0.638232, 0.335938 (0.681 sec)
212.19... logprob:  0.632838, 0.328125 (0.681 sec)
212.20... logprob:  0.648672, 0.351562 (0.680 sec)
212.21... logprob:  0.643398, 0.343750 (0.686 sec)
212.22... logprob:  0.628601, 0.320312 (0.682 sec)
212.23... logprob:  0.624061, 0.312500 (0.679 sec)
212.24... logprob:  0.580717, 0.242188 (0.679 sec)
212.25... logprob:  0.628838, 0.320312 (0.686 sec)
212.26... logprob:  0.673108, 0.390625 (0.682 sec)
212.27... logprob:  0.628518, 0.320312 (0.687 sec)
213.1... logprob:  0.678603, 0.398438 (0.688 sec)
213.2... logprob:  0.598165, 0.273438 (0.683 sec)
213.3... logprob:  0.653605, 0.359375 (0.680 sec)
213.4... logprob:  0.597312, 0.273438 (0.690 sec)
213.5... logprob:  0.591273, 0.265625 (0.688 sec)
213.6... logprob:  0.611352, 0.296875 (0.687 sec)
213.7... logprob:  0.643956, 0.343750 (0.684 sec)
213.8... logprob:  0.604312, 0.289062 (0.679 sec)
213.9... logprob:  0.638828, 0.335938 (0.681 sec)
213.10... logprob:  0.597022, 0.281250 (0.680 sec)
213.11... logprob:  0.639538, 0.335938 (0.681 sec)
213.12... logprob:  0.721906, 0.437500 (0.681 sec)
213.13... logprob:  0.658725, 0.359375 (0.681 sec)
213.14... logprob:  0.664284, 0.367188 (0.684 sec)
213.15... logprob:  0.687534, 0.398438 (0.687 sec)
213.16... logprob:  0.627056, 0.320312 (0.682 sec)
213.17... logprob:  0.638521, 0.335938 (0.682 sec)
213.18... logprob:  0.638232, 0.335938 (0.683 sec)
213.19... logprob:  0.632837, 0.328125 (0.692 sec)
213.20... logprob:  0.648673, 0.351562 (0.692 sec)
213.21... logprob:  0.643398, 0.343750 (0.682 sec)
213.22... logprob:  0.628594, 0.320312 (0.682 sec)
213.23... logprob:  0.624052, 0.312500 (0.683 sec)
213.24... logprob:  0.580688, 0.242188 (0.680 sec)
213.25... logprob:  0.628831, 0.320312 (0.684 sec)
213.26... logprob:  0.673116, 0.390625 (0.683 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.653414, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956755e-03 [6.242245e-09] 
Layer 'conv1' biases: 2.827992e-07 [5.938466e-11] 
Layer 'conv2' weights[0]: 7.944170e-03 [4.794779e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.351206e-10] 
Layer 'conv3' weights[0]: 7.942336e-03 [4.410075e-09] 
Layer 'conv3' biases: 2.504120e-06 [6.956286e-10] 
Layer 'conv4' weights[0]: 7.974835e-03 [4.353055e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.878755e-09] 
Layer 'conv5' weights[0]: 7.974279e-03 [2.418769e-08] 
Layer 'conv5' biases: 1.000005e+00 [2.590645e-08] 
Layer 'fc6' weights[0]: 7.570686e-03 [4.609706e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.396398e-09] 
Layer 'fc7' weights[0]: 7.631818e-03 [5.459644e-08] 
Layer 'fc7' biases: 9.998573e-01 [3.059339e-08] 
Layer 'fc8' weights[0]: 6.311032e-04 [1.750542e-06] 
Layer 'fc8' biases: 1.003157e-01 [4.792184e-05] 
Train error last 27 batches: 0.636257
-------------------------------------------------------
Not saving because 0.653414 > 0.627146 (160.7: -0.00%)
======================================================= (1.820 sec)
213.27... logprob:  0.628514, 0.320312 (0.694 sec)
214.1... logprob:  0.678610, 0.398438 (0.689 sec)
214.2... logprob:  0.598159, 0.273438 (0.696 sec)
214.3... logprob:  0.653606, 0.359375 (0.685 sec)
214.4... logprob:  0.597310, 0.273438 (0.687 sec)
214.5... logprob:  0.591276, 0.265625 (0.686 sec)
214.6... logprob:  0.611356, 0.296875 (0.686 sec)
214.7... logprob:  0.643954, 0.343750 (0.685 sec)
214.8... logprob:  0.604320, 0.289062 (0.683 sec)
214.9... logprob:  0.638824, 0.335938 (0.687 sec)
214.10... logprob:  0.597033, 0.281250 (0.683 sec)
214.11... logprob:  0.639529, 0.335938 (0.685 sec)
214.12... logprob:  0.721862, 0.437500 (0.685 sec)
214.13... logprob:  0.658709, 0.359375 (0.684 sec)
214.14... logprob:  0.664270, 0.367188 (0.686 sec)
214.15... logprob:  0.687520, 0.398438 (0.685 sec)
214.16... logprob:  0.627056, 0.320312 (0.688 sec)
214.17... logprob:  0.638520, 0.335938 (0.685 sec)
214.18... logprob:  0.638232, 0.335938 (0.686 sec)
214.19... logprob:  0.632835, 0.328125 (0.687 sec)
214.20... logprob:  0.648675, 0.351562 (0.689 sec)
214.21... logprob:  0.643398, 0.343750 (0.690 sec)
214.22... logprob:  0.628588, 0.320312 (0.691 sec)
214.23... logprob:  0.624042, 0.312500 (0.685 sec)
214.24... logprob:  0.580660, 0.242188 (0.685 sec)
214.25... logprob:  0.628824, 0.320312 (0.686 sec)
214.26... logprob:  0.673126, 0.390625 (0.685 sec)
214.27... logprob:  0.628508, 0.320312 (0.684 sec)
215.1... logprob:  0.678619, 0.398438 (0.688 sec)
215.2... logprob:  0.598147, 0.273438 (0.689 sec)
215.3... logprob:  0.653608, 0.359375 (0.688 sec)
215.4...nohup: ignoring input
Option --layer-def (Layer definition file) cannot be changed
=========================
Importing _ConvNet C++ module
=========================
Training ConvNet
Always write savepoints, regardless of test err improvement: 0     [DEFAULT]
Check gradients and quit?                                  : 0     [DEFAULT]
Compress checkpoints?                                      : 0     [DEFAULT]
Conserve GPU memory (slower)?                              : 0     [DEFAULT]
Convert given conv layers to unshared local                :       
Cropped DP: crop border size                               : 4     [DEFAULT]
Cropped DP: logreg layer name (for --multiview-test)       :       [DEFAULT]
Cropped DP: test on multiple patches?                      : 0     [DEFAULT]
Cropped Step: crop border step                             : 1     [DEFAULT]
Data batch range: testing                                  : 28-33 
Data batch range: training                                 : 1-27  
Data path                                                  : /data/ad6813/pipe-data/Bluebox/batches/scraping_peeling/net_0 
Data provider                                              : basic-leaf256 
GPU override                                               : -1    [DEFAULT]
Layer definition file                                      : /homes/ad6813/Git/pipe-classification/models/scraping_peeling/net_0/layers.cfg 
Layer parameter file                                       : /homes/ad6813/Git/pipe-classification/models/scraping_peeling/net_0/params.cfg 
Load file                                                  : /homes/ad6813/Git/pipe-classification/models/scraping_peeling/net_0/saves/ConvNet__2014-07-08_14.54.04 
Maximum save file size (MB)                                : 0     [DEFAULT]
Minibatch size                                             : 128   [DEFAULT]
Number of GPUs                                             : 1     [DEFAULT]
Number of epochs                                           : 50000 [DEFAULT]
Save path                                                  : /homes/ad6813/Git/pipe-classification/models/scraping_peeling/net_0/saves 
Test and quit?                                             : 0     [DEFAULT]
Test on more than one batch at a time?                     : -1    [DEFAULT]
Test on one batch at a time?                               : 1     [DEFAULT]
Testing frequency                                          : 50    
Unshare weight matrices in given layers                    :       
=========================
Running on CUDA device(s) -2
Current time: Tue Jul  8 17:24:13 2014
Saving checkpoints to /homes/ad6813/Git/pipe-classification/models/scraping_peeling/net_0/saves/ConvNet__2014-07-08_14.54.04
=========================
160.8... logprob:  0.603974, 0.289062 (1.615 sec)
160.9... logprob:  0.639053, 0.335938 (0.661 sec)
160.10... logprob:  0.596534, 0.281250 (0.660 sec)
160.11... logprob:  0.639988, 0.335938 (0.661 sec)
160.12... logprob:  0.724214, 0.437500 (0.661 sec)
160.13... logprob:  0.659523, 0.359375 (0.661 sec)
160.14... logprob:  0.664994, 0.367188 (0.659 sec)
160.15... logprob:  0.688233, 0.398438 (0.661 sec)
160.16... logprob:  0.627059, 0.320312 (0.661 sec)
160.17... logprob:  0.638507, 0.335938 (0.660 sec)
160.18... logprob:  0.638237, 0.335938 (0.661 sec)
160.19... logprob:  0.632939, 0.328125 (0.655 sec)
160.20... logprob:  0.648576, 0.351562 (0.655 sec)
160.21... logprob:  0.643431, 0.343750 (0.658 sec)
160.22... logprob:  0.629011, 0.320312 (0.658 sec)
160.23... logprob:  0.624643, 0.312500 (0.655 sec)
160.24... logprob:  0.582374, 0.242188 (0.656 sec)
160.25... logprob:  0.629257, 0.320312 (0.661 sec)
160.26... logprob:  0.672641, 0.390625 (0.659 sec)
160.27... logprob:  0.628806, 0.320312 (0.661 sec)
161.1... logprob:  0.678191, 0.398438 (0.660 sec)
161.2... logprob:  0.598669, 0.273438 (0.659 sec)
161.3... logprob:  0.653549, 0.359375 (0.660 sec)
161.4... logprob:  0.597504, 0.273438 (0.655 sec)
161.5... logprob:  0.591273, 0.265625 (0.659 sec)
161.6... logprob:  0.611235, 0.296875 (0.655 sec)
161.7... logprob:  0.644070, 0.343750 (0.657 sec)
161.8... logprob:  0.603982, 0.289062 (0.662 sec)
161.9... logprob:  0.639048, 0.335938 (0.661 sec)
161.10... logprob:  0.596544, 0.281250 (0.660 sec)
161.11... logprob:  0.639978, 0.335938 (0.660 sec)
161.12... logprob:  0.724165, 0.437500 (0.659 sec)
161.13... logprob:  0.659506, 0.359375 (0.661 sec)
161.14... logprob:  0.664979, 0.367188 (0.660 sec)
161.15... logprob:  0.688219, 0.398438 (0.661 sec)
161.16... logprob:  0.627059, 0.320312 (0.661 sec)
161.17... logprob:  0.638507, 0.335938 (0.663 sec)
161.18... logprob:  0.638237, 0.335938 (0.666 sec)
161.19... logprob:  0.632937, 0.328125 (0.669 sec)
161.20... logprob:  0.648578, 0.351562 (0.662 sec)
161.21... logprob:  0.643430, 0.343750 (0.658 sec)
161.22... logprob:  0.629002, 0.320312 (0.662 sec)
161.23... logprob:  0.624630, 0.312500 (0.663 sec)
161.24... logprob:  0.582338, 0.242188 (0.662 sec)
161.25... logprob:  0.629248, 0.320312 (0.662 sec)
161.26... logprob:  0.672651, 0.390625 (0.661 sec)
161.27... logprob:  0.628800, 0.320312 (0.662 sec)
162.1... logprob:  0.678200, 0.398438 (0.663 sec)
162.2... logprob:  0.598659, 0.273438 (0.672 sec)
162.3... logprob:  0.653550, 0.359375 (0.661 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.653657, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.962321e-03 [6.401496e-09] 
Layer 'conv1' biases: 1.991319e-07 [6.984933e-11] 
Layer 'conv2' weights[0]: 7.949620e-03 [4.777642e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.992445e-10] 
Layer 'conv3' weights[0]: 7.947777e-03 [4.590463e-09] 
Layer 'conv3' biases: 1.868460e-06 [8.698071e-10] 
Layer 'conv4' weights[0]: 7.980299e-03 [4.596643e-09] 
Layer 'conv4' biases: 1.000001e+00 [6.888227e-09] 
Layer 'conv5' weights[0]: 7.979736e-03 [4.493260e-08] 
Layer 'conv5' biases: 1.000007e+00 [4.873534e-08] 
Layer 'fc6' weights[0]: 7.576170e-03 [5.797087e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.261531e-09] 
Layer 'fc7' weights[0]: 7.686508e-03 [7.626115e-08] 
Layer 'fc7' biases: 9.998590e-01 [5.627798e-08] 
Layer 'fc8' weights[0]: 6.655848e-04 [3.350798e-06] 
Layer 'fc8' biases: 7.551003e-02 [6.766500e-05] 
Train error last 27 batches: 0.636531
-------------------------------------------------------
Not saving because 0.653657 > 0.627146 (160.7: -0.00%)
======================================================= (1.725 sec)
162.4... logprob:  0.597502, 0.273438 (0.661 sec)
162.5... logprob:  0.591274, 0.265625 (0.662 sec)
162.6... logprob:  0.611238, 0.296875 (0.664 sec)
162.7... logprob:  0.644067, 0.343750 (0.663 sec)
162.8... logprob:  0.603989, 0.289062 (0.660 sec)
162.9... logprob:  0.639043, 0.335938 (0.669 sec)
162.10... logprob:  0.596554, 0.281250 (0.671 sec)
162.11... logprob:  0.639968, 0.335938 (0.666 sec)
162.12... logprob:  0.724116, 0.437500 (0.664 sec)
162.13... logprob:  0.659489, 0.359375 (0.692 sec)
162.14... logprob:  0.664965, 0.367188 (0.661 sec)
162.15... logprob:  0.688206, 0.398438 (0.663 sec)
162.16... logprob:  0.627059, 0.320312 (0.663 sec)
162.17... logprob:  0.638507, 0.335938 (0.663 sec)
162.18... logprob:  0.638237, 0.335938 (0.665 sec)
162.19... logprob:  0.632935, 0.328125 (0.670 sec)
162.20... logprob:  0.648580, 0.351562 (0.664 sec)
162.21... logprob:  0.643429, 0.343750 (0.670 sec)
162.22... logprob:  0.628992, 0.320312 (0.663 sec)
162.23... logprob:  0.624617, 0.312500 (0.661 sec)
162.24... logprob:  0.582302, 0.242188 (0.662 sec)
162.25... logprob:  0.629239, 0.320312 (0.664 sec)
162.26... logprob:  0.672661, 0.390625 (0.661 sec)
162.27... logprob:  0.628793, 0.320312 (0.665 sec)
163.1... logprob:  0.678207, 0.398438 (0.666 sec)
163.2... logprob:  0.598649, 0.273438 (0.668 sec)
163.3... logprob:  0.653551, 0.359375 (0.662 sec)
163.4... logprob:  0.597498, 0.273438 (0.662 sec)
163.5... logprob:  0.591275, 0.265625 (0.663 sec)
163.6... logprob:  0.611241, 0.296875 (0.660 sec)
163.7... logprob:  0.644064, 0.343750 (0.664 sec)
163.8... logprob:  0.603996, 0.289062 (0.663 sec)
163.9... logprob:  0.639038, 0.335938 (0.662 sec)
163.10... logprob:  0.596564, 0.281250 (0.663 sec)
163.11... logprob:  0.639958, 0.335938 (0.661 sec)
163.12... logprob:  0.724067, 0.437500 (0.670 sec)
163.13... logprob:  0.659472, 0.359375 (0.671 sec)
163.14... logprob:  0.664950, 0.367188 (0.663 sec)
163.15... logprob:  0.688192, 0.398438 (0.663 sec)
163.16... logprob:  0.627059, 0.320312 (0.665 sec)
163.17... logprob:  0.638507, 0.335938 (0.665 sec)
163.18... logprob:  0.638237, 0.335938 (0.666 sec)
163.19... logprob:  0.632932, 0.328125 (0.665 sec)
163.20... logprob:  0.648582, 0.351562 (0.665 sec)
163.21... logprob:  0.643428, 0.343750 (0.666 sec)
163.22... logprob:  0.628983, 0.320312 (0.665 sec)
163.23... logprob:  0.624603, 0.312500 (0.664 sec)
163.24... logprob:  0.582264, 0.242188 (0.664 sec)
163.25... logprob:  0.629229, 0.320312 (0.663 sec)
163.26... logprob:  0.672671, 0.390625 (0.660 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.628817, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.962110e-03 [6.111481e-09] 
Layer 'conv1' biases: 2.021261e-07 [5.974874e-11] 
Layer 'conv2' weights[0]: 7.949426e-03 [4.701583e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.445337e-10] 
Layer 'conv3' weights[0]: 7.947597e-03 [4.435543e-09] 
Layer 'conv3' biases: 1.891357e-06 [7.693571e-10] 
Layer 'conv4' weights[0]: 7.980104e-03 [4.431403e-09] 
Layer 'conv4' biases: 1.000001e+00 [5.330514e-09] 
Layer 'conv5' weights[0]: 7.979544e-03 [3.435691e-08] 
Layer 'conv5' biases: 1.000007e+00 [3.720845e-08] 
Layer 'fc6' weights[0]: 7.575977e-03 [5.115732e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.252413e-09] 
Layer 'fc7' weights[0]: 7.684544e-03 [6.450713e-08] 
Layer 'fc7' biases: 9.998589e-01 [4.272494e-08] 
Layer 'fc8' weights[0]: 6.535046e-04 [2.537199e-06] 
Layer 'fc8' biases: 7.626880e-02 [6.036893e-05] 
Train error last 27 batches: 0.636519
-------------------------------------------------------
Not saving because 0.628817 > 0.627146 (160.7: -0.00%)
======================================================= (1.752 sec)
163.27... logprob:  0.628787, 0.320312 (0.662 sec)
164.1... logprob:  0.678216, 0.398438 (0.664 sec)
164.2... logprob:  0.598639, 0.273438 (0.663 sec)
164.3... logprob:  0.653552, 0.359375 (0.662 sec)
164.4... logprob:  0.597496, 0.273438 (0.661 sec)
164.5... logprob:  0.591277, 0.265625 (0.660 sec)
164.6... logprob:  0.611245, 0.296875 (0.662 sec)
164.7... logprob:  0.644061, 0.343750 (0.661 sec)
164.8... logprob:  0.604005, 0.289062 (0.661 sec)
164.9... logprob:  0.639032, 0.335938 (0.663 sec)
164.10... logprob:  0.596575, 0.281250 (0.660 sec)
164.11... logprob:  0.639947, 0.335938 (0.661 sec)
164.12... logprob:  0.724015, 0.437500 (0.659 sec)
164.13... logprob:  0.659454, 0.359375 (0.661 sec)
164.14... logprob:  0.664934, 0.367188 (0.661 sec)
164.15... logprob:  0.688177, 0.398438 (0.663 sec)
164.16... logprob:  0.627058, 0.320312 (0.662 sec)
164.17... logprob:  0.638508, 0.335938 (0.660 sec)
164.18... logprob:  0.638237, 0.335938 (0.662 sec)
164.19... logprob:  0.632930, 0.328125 (0.662 sec)
164.20... logprob:  0.648584, 0.351562 (0.663 sec)
164.21... logprob:  0.643427, 0.343750 (0.664 sec)
164.22... logprob:  0.628973, 0.320312 (0.661 sec)
164.23... logprob:  0.624590, 0.312500 (0.660 sec)
164.24... logprob:  0.582229, 0.242188 (0.661 sec)
164.25... logprob:  0.629220, 0.320312 (0.659 sec)
164.26... logprob:  0.672681, 0.390625 (0.664 sec)
164.27... logprob:  0.628781, 0.320312 (0.660 sec)
165.1... logprob:  0.678225, 0.398438 (0.661 sec)
165.2... logprob:  0.598628, 0.273438 (0.662 sec)
165.3... logprob:  0.653553, 0.359375 (0.658 sec)
165.4... logprob:  0.597492, 0.273438 (0.665 sec)
165.5... logprob:  0.591277, 0.265625 (0.662 sec)
165.6... logprob:  0.611247, 0.296875 (0.665 sec)
165.7... logprob:  0.644059, 0.343750 (0.671 sec)
165.8... logprob:  0.604010, 0.289062 (0.663 sec)
165.9... logprob:  0.639027, 0.335938 (0.663 sec)
165.10... logprob:  0.596584, 0.281250 (0.663 sec)
165.11... logprob:  0.639938, 0.335938 (0.665 sec)
165.12... logprob:  0.723971, 0.437500 (0.664 sec)
165.13... logprob:  0.659439, 0.359375 (0.664 sec)
165.14... logprob:  0.664921, 0.367188 (0.661 sec)
165.15... logprob:  0.688164, 0.398438 (0.659 sec)
165.16... logprob:  0.627059, 0.320312 (0.669 sec)
165.17... logprob:  0.638508, 0.335938 (0.663 sec)
165.18... logprob:  0.638237, 0.335938 (0.665 sec)
165.19... logprob:  0.632928, 0.328125 (0.668 sec)
165.20... logprob:  0.648585, 0.351562 (0.671 sec)
165.21... logprob:  0.643426, 0.343750 (0.662 sec)
165.22... logprob:  0.628965, 0.320312 (0.668 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.634072, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961898e-03 [6.338245e-09] 
Layer 'conv1' biases: 2.050922e-07 [1.210237e-10] 
Layer 'conv2' weights[0]: 7.949220e-03 [5.606844e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.204681e-10] 
Layer 'conv3' weights[0]: 7.947409e-03 [5.059528e-09] 
Layer 'conv3' biases: 1.914108e-06 [1.454991e-09] 
Layer 'conv4' weights[0]: 7.979918e-03 [5.058279e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.072181e-08] 
Layer 'conv5' weights[0]: 7.979352e-03 [6.905861e-08] 
Layer 'conv5' biases: 1.000007e+00 [7.484294e-08] 
Layer 'fc6' weights[0]: 7.575790e-03 [7.896999e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.818912e-09] 
Layer 'fc7' weights[0]: 7.682605e-03 [1.103476e-07] 
Layer 'fc7' biases: 9.998586e-01 [9.345780e-08] 
Layer 'fc8' weights[0]: 6.442141e-04 [5.495217e-06] 
Layer 'fc8' biases: 7.704644e-02 [6.885316e-05] 
Train error last 27 batches: 0.636509
-------------------------------------------------------
Not saving because 0.634072 > 0.627146 (160.7: -0.00%)
======================================================= (1.708 sec)
165.23... logprob:  0.624578, 0.312500 (0.661 sec)
165.24... logprob:  0.582196, 0.242188 (0.661 sec)
165.25... logprob:  0.629211, 0.320312 (0.658 sec)
165.26... logprob:  0.672689, 0.390625 (0.665 sec)
165.27... logprob:  0.628775, 0.320312 (0.660 sec)
166.1... logprob:  0.678232, 0.398438 (0.662 sec)
166.2... logprob:  0.598619, 0.273438 (0.661 sec)
166.3... logprob:  0.653554, 0.359375 (0.663 sec)
166.4... logprob:  0.597488, 0.273438 (0.664 sec)
166.5... logprob:  0.591278, 0.265625 (0.664 sec)
166.6... logprob:  0.611250, 0.296875 (0.660 sec)
166.7... logprob:  0.644056, 0.343750 (0.662 sec)
166.8... logprob:  0.604017, 0.289062 (0.662 sec)
166.9... logprob:  0.639022, 0.335938 (0.659 sec)
166.10... logprob:  0.596593, 0.281250 (0.664 sec)
166.11... logprob:  0.639929, 0.335938 (0.662 sec)
166.12... logprob:  0.723926, 0.437500 (0.665 sec)
166.13... logprob:  0.659423, 0.359375 (0.661 sec)
166.14... logprob:  0.664908, 0.367188 (0.660 sec)
166.15... logprob:  0.688153, 0.398438 (0.661 sec)
166.16... logprob:  0.627059, 0.320312 (0.662 sec)
166.17... logprob:  0.638509, 0.335938 (0.659 sec)
166.18... logprob:  0.638236, 0.335938 (0.657 sec)
166.19... logprob:  0.632925, 0.328125 (0.661 sec)
166.20... logprob:  0.648587, 0.351562 (0.661 sec)
166.21... logprob:  0.643425, 0.343750 (0.661 sec)
166.22... logprob:  0.628955, 0.320312 (0.665 sec)
166.23... logprob:  0.624565, 0.312500 (0.663 sec)
166.24... logprob:  0.582159, 0.242188 (0.663 sec)
166.25... logprob:  0.629201, 0.320312 (0.663 sec)
166.26... logprob:  0.672698, 0.390625 (0.668 sec)
166.27... logprob:  0.628769, 0.320312 (0.666 sec)
167.1... logprob:  0.678240, 0.398438 (0.661 sec)
167.2... logprob:  0.598610, 0.273438 (0.685 sec)
167.3... logprob:  0.653554, 0.359375 (0.677 sec)
167.4... logprob:  0.597487, 0.273438 (0.679 sec)
167.5... logprob:  0.591281, 0.265625 (0.674 sec)
167.6... logprob:  0.611254, 0.296875 (0.682 sec)
167.7... logprob:  0.644053, 0.343750 (0.679 sec)
167.8... logprob:  0.604026, 0.289062 (0.670 sec)
167.9... logprob:  0.639017, 0.335938 (0.663 sec)
167.10... logprob:  0.596604, 0.281250 (0.669 sec)
167.11... logprob:  0.639917, 0.335938 (0.664 sec)
167.12... logprob:  0.723872, 0.437500 (0.666 sec)
167.13... logprob:  0.659405, 0.359375 (0.663 sec)
167.14... logprob:  0.664891, 0.367188 (0.662 sec)
167.15... logprob:  0.688137, 0.398438 (0.668 sec)
167.16... logprob:  0.627058, 0.320312 (0.671 sec)
167.17... logprob:  0.638510, 0.335938 (0.665 sec)
167.18... logprob:  0.638236, 0.335938 (0.668 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.685597, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961706e-03 [6.496481e-09] 
Layer 'conv1' biases: 2.078009e-07 [1.761244e-10] 
Layer 'conv2' weights[0]: 7.949007e-03 [6.941163e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.011316e-10] 
Layer 'conv3' weights[0]: 7.947220e-03 [6.272020e-09] 
Layer 'conv3' biases: 1.933014e-06 [2.587148e-09] 
Layer 'conv4' weights[0]: 7.979722e-03 [6.487920e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.194487e-08] 
Layer 'conv5' weights[0]: 7.979141e-03 [1.410582e-07] 
Layer 'conv5' biases: 1.000007e+00 [1.530449e-07] 
Layer 'fc6' weights[0]: 7.575587e-03 [1.432448e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.387304e-08] 
Layer 'fc7' weights[0]: 7.680672e-03 [2.005353e-07] 
Layer 'fc7' biases: 9.998589e-01 [1.879189e-07] 
Layer 'fc8' weights[0]: 6.714601e-04 [1.111517e-05] 
Layer 'fc8' biases: 7.849077e-02 [1.516411e-04] 
Train error last 27 batches: 0.636498
-------------------------------------------------------
Not saving because 0.685597 > 0.627146 (160.7: -0.00%)
======================================================= (1.683 sec)
167.19... logprob:  0.632922, 0.328125 (0.665 sec)
167.20... logprob:  0.648589, 0.351562 (0.663 sec)
167.21... logprob:  0.643424, 0.343750 (0.665 sec)
167.22... logprob:  0.628946, 0.320312 (0.665 sec)
167.23... logprob:  0.624552, 0.312500 (0.666 sec)
167.24... logprob:  0.582122, 0.242188 (0.663 sec)
167.25... logprob:  0.629192, 0.320312 (0.667 sec)
167.26... logprob:  0.672709, 0.390625 (0.669 sec)
167.27... logprob:  0.628762, 0.320312 (0.665 sec)
168.1... logprob:  0.678249, 0.398438 (0.663 sec)
168.2... logprob:  0.598598, 0.273438 (0.666 sec)
168.3... logprob:  0.653556, 0.359375 (0.661 sec)
168.4... logprob:  0.597482, 0.273438 (0.666 sec)
168.5... logprob:  0.591280, 0.265625 (0.660 sec)
168.6... logprob:  0.611256, 0.296875 (0.661 sec)
168.7... logprob:  0.644051, 0.343750 (0.659 sec)
168.8... logprob:  0.604033, 0.289062 (0.659 sec)
168.9... logprob:  0.639012, 0.335938 (0.662 sec)
168.10... logprob:  0.596614, 0.281250 (0.664 sec)
168.11... logprob:  0.639908, 0.335938 (0.663 sec)
168.12... logprob:  0.723826, 0.437500 (0.662 sec)
168.13... logprob:  0.659389, 0.359375 (0.664 sec)
168.14... logprob:  0.664877, 0.367188 (0.663 sec)
168.15... logprob:  0.688123, 0.398438 (0.662 sec)
168.16... logprob:  0.627058, 0.320312 (0.665 sec)
168.17... logprob:  0.638510, 0.335938 (0.664 sec)
168.18... logprob:  0.638236, 0.335938 (0.667 sec)
168.19... logprob:  0.632920, 0.328125 (0.661 sec)
168.20... logprob:  0.648591, 0.351562 (0.661 sec)
168.21... logprob:  0.643423, 0.343750 (0.666 sec)
168.22... logprob:  0.628937, 0.320312 (0.667 sec)
168.23... logprob:  0.624539, 0.312500 (0.664 sec)
168.24... logprob:  0.582087, 0.242188 (0.664 sec)
168.25... logprob:  0.629183, 0.320312 (0.663 sec)
168.26... logprob:  0.672718, 0.390625 (0.668 sec)
168.27... logprob:  0.628756, 0.320312 (0.668 sec)
169.1... logprob:  0.678257, 0.398438 (0.670 sec)
169.2... logprob:  0.598588, 0.273438 (0.675 sec)
169.3... logprob:  0.653557, 0.359375 (0.660 sec)
169.4... logprob:  0.597479, 0.273438 (0.660 sec)
169.5... logprob:  0.591281, 0.265625 (0.662 sec)
169.6... logprob:  0.611259, 0.296875 (0.661 sec)
169.7... logprob:  0.644048, 0.343750 (0.662 sec)
169.8... logprob:  0.604040, 0.289062 (0.661 sec)
169.9... logprob:  0.639007, 0.335938 (0.661 sec)
169.10... logprob:  0.596624, 0.281250 (0.661 sec)
169.11... logprob:  0.639899, 0.335938 (0.661 sec)
169.12... logprob:  0.723779, 0.437500 (0.662 sec)
169.13... logprob:  0.659373, 0.359375 (0.667 sec)
169.14... logprob:  0.664864, 0.367188 (0.667 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633286, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961519e-03 [6.781818e-09] 
Layer 'conv1' biases: 2.103990e-07 [1.606588e-10] 
Layer 'conv2' weights[0]: 7.948817e-03 [6.575615e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.958150e-10] 
Layer 'conv3' weights[0]: 7.947028e-03 [5.875821e-09] 
Layer 'conv3' biases: 1.950595e-06 [2.252868e-09] 
Layer 'conv4' weights[0]: 7.979518e-03 [6.042976e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.854984e-08] 
Layer 'conv5' weights[0]: 7.978929e-03 [1.192392e-07] 
Layer 'conv5' biases: 1.000006e+00 [1.293732e-07] 
Layer 'fc6' weights[0]: 7.575378e-03 [1.226141e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.174044e-08] 
Layer 'fc7' weights[0]: 7.678701e-03 [1.717607e-07] 
Layer 'fc7' biases: 9.998595e-01 [1.586839e-07] 
Layer 'fc8' weights[0]: 7.153294e-04 [9.398746e-06] 
Layer 'fc8' biases: 8.018152e-02 [1.202733e-04] 
Train error last 27 batches: 0.636487
-------------------------------------------------------
Not saving because 0.633286 > 0.627146 (160.7: -0.00%)
======================================================= (1.686 sec)
169.15... logprob:  0.688111, 0.398438 (0.662 sec)
169.16... logprob:  0.627058, 0.320312 (0.664 sec)
169.17... logprob:  0.638510, 0.335938 (0.662 sec)
169.18... logprob:  0.638237, 0.335938 (0.668 sec)
169.19... logprob:  0.632918, 0.328125 (0.666 sec)
169.20... logprob:  0.648593, 0.351562 (0.665 sec)
169.21... logprob:  0.643422, 0.343750 (0.662 sec)
169.22... logprob:  0.628927, 0.320312 (0.663 sec)
169.23... logprob:  0.624526, 0.312500 (0.665 sec)
169.24... logprob:  0.582051, 0.242188 (0.664 sec)
169.25... logprob:  0.629174, 0.320312 (0.667 sec)
169.26... logprob:  0.672728, 0.390625 (0.664 sec)
169.27... logprob:  0.628750, 0.320312 (0.666 sec)
170.1... logprob:  0.678266, 0.398438 (0.670 sec)
170.2... logprob:  0.598579, 0.273438 (0.666 sec)
170.3... logprob:  0.653557, 0.359375 (0.666 sec)
170.4... logprob:  0.597477, 0.273438 (0.668 sec)
170.5... logprob:  0.591284, 0.265625 (0.666 sec)
170.6... logprob:  0.611263, 0.296875 (0.663 sec)
170.7... logprob:  0.644045, 0.343750 (0.664 sec)
170.8... logprob:  0.604048, 0.289062 (0.662 sec)
170.9... logprob:  0.639001, 0.335938 (0.672 sec)
170.10... logprob:  0.596635, 0.281250 (0.676 sec)
170.11... logprob:  0.639888, 0.335938 (0.676 sec)
170.12... logprob:  0.723726, 0.437500 (0.674 sec)
170.13... logprob:  0.659354, 0.359375 (0.683 sec)
170.14... logprob:  0.664847, 0.367188 (0.670 sec)
170.15... logprob:  0.688095, 0.398438 (0.676 sec)
170.16... logprob:  0.627058, 0.320312 (0.669 sec)
170.17... logprob:  0.638510, 0.335938 (0.668 sec)
170.18... logprob:  0.638236, 0.335938 (0.678 sec)
170.19... logprob:  0.632916, 0.328125 (0.669 sec)
170.20... logprob:  0.648595, 0.351562 (0.674 sec)
170.21... logprob:  0.643421, 0.343750 (0.674 sec)
170.22... logprob:  0.628918, 0.320312 (0.668 sec)
170.23... logprob:  0.624514, 0.312500 (0.673 sec)
170.24... logprob:  0.582016, 0.242188 (0.680 sec)
170.25... logprob:  0.629165, 0.320312 (0.668 sec)
170.26... logprob:  0.672738, 0.390625 (0.670 sec)
170.27... logprob:  0.628744, 0.320312 (0.668 sec)
171.1... logprob:  0.678275, 0.398438 (0.670 sec)
171.2... logprob:  0.598567, 0.273438 (0.671 sec)
171.3... logprob:  0.653559, 0.359375 (0.667 sec)
171.4... logprob:  0.597472, 0.273438 (0.661 sec)
171.5... logprob:  0.591282, 0.265625 (0.663 sec)
171.6... logprob:  0.611264, 0.296875 (0.662 sec)
171.7... logprob:  0.644043, 0.343750 (0.664 sec)
171.8... logprob:  0.604054, 0.289062 (0.665 sec)
171.9... logprob:  0.638997, 0.335938 (0.666 sec)
171.10... logprob:  0.596643, 0.281250 (0.665 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627439, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961314e-03 [6.775847e-09] 
Layer 'conv1' biases: 2.132412e-07 [1.251133e-10] 
Layer 'conv2' weights[0]: 7.948628e-03 [5.891796e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.443167e-10] 
Layer 'conv3' weights[0]: 7.946835e-03 [5.918208e-09] 
Layer 'conv3' biases: 1.971641e-06 [2.155398e-09] 
Layer 'conv4' weights[0]: 7.979326e-03 [6.324584e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.072171e-08] 
Layer 'conv5' weights[0]: 7.978726e-03 [1.328506e-07] 
Layer 'conv5' biases: 1.000005e+00 [1.444365e-07] 
Layer 'fc6' weights[0]: 7.575190e-03 [1.344180e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.294156e-08] 
Layer 'fc7' weights[0]: 7.676731e-03 [1.852463e-07] 
Layer 'fc7' biases: 9.998595e-01 [1.714846e-07] 
Layer 'fc8' weights[0]: 7.235872e-04 [1.020907e-05] 
Layer 'fc8' biases: 8.126649e-02 [1.694845e-04] 
Train error last 27 batches: 0.636478
-------------------------------------------------------
Not saving because 0.627439 > 0.627146 (160.7: -0.00%)
======================================================= (1.701 sec)
171.11... logprob:  0.639879, 0.335938 (0.676 sec)
171.12... logprob:  0.723685, 0.437500 (0.672 sec)
171.13... logprob:  0.659340, 0.359375 (0.673 sec)
171.14... logprob:  0.664834, 0.367188 (0.673 sec)
171.15... logprob:  0.688083, 0.398438 (0.674 sec)
171.16... logprob:  0.627058, 0.320312 (0.673 sec)
171.17... logprob:  0.638511, 0.335938 (0.669 sec)
171.18... logprob:  0.638236, 0.335938 (0.673 sec)
171.19... logprob:  0.632914, 0.328125 (0.672 sec)
171.20... logprob:  0.648597, 0.351562 (0.676 sec)
171.21... logprob:  0.643420, 0.343750 (0.669 sec)
171.22... logprob:  0.628910, 0.320312 (0.668 sec)
171.23... logprob:  0.624502, 0.312500 (0.672 sec)
171.24... logprob:  0.581984, 0.242188 (0.664 sec)
171.25... logprob:  0.629157, 0.320312 (0.666 sec)
171.26... logprob:  0.672746, 0.390625 (0.667 sec)
171.27... logprob:  0.628739, 0.320312 (0.666 sec)
172.1... logprob:  0.678282, 0.398438 (0.664 sec)
172.2... logprob:  0.598559, 0.273438 (0.667 sec)
172.3... logprob:  0.653560, 0.359375 (0.668 sec)
172.4... logprob:  0.597469, 0.273438 (0.668 sec)
172.5... logprob:  0.591284, 0.265625 (0.669 sec)
172.6... logprob:  0.611268, 0.296875 (0.670 sec)
172.7... logprob:  0.644040, 0.343750 (0.667 sec)
172.8... logprob:  0.604061, 0.289062 (0.673 sec)
172.9... logprob:  0.638992, 0.335938 (0.663 sec)
172.10... logprob:  0.596653, 0.281250 (0.666 sec)
172.11... logprob:  0.639869, 0.335938 (0.663 sec)
172.12... logprob:  0.723637, 0.437500 (0.666 sec)
172.13... logprob:  0.659323, 0.359375 (0.664 sec)
172.14... logprob:  0.664820, 0.367188 (0.664 sec)
172.15... logprob:  0.688069, 0.398438 (0.663 sec)
172.16... logprob:  0.627058, 0.320312 (0.665 sec)
172.17... logprob:  0.638511, 0.335938 (0.670 sec)
172.18... logprob:  0.638236, 0.335938 (0.668 sec)
172.19... logprob:  0.632911, 0.328125 (0.671 sec)
172.20... logprob:  0.648599, 0.351562 (0.666 sec)
172.21... logprob:  0.643419, 0.343750 (0.662 sec)
172.22... logprob:  0.628901, 0.320312 (0.662 sec)
172.23... logprob:  0.624490, 0.312500 (0.675 sec)
172.24... logprob:  0.581948, 0.242188 (0.670 sec)
172.25... logprob:  0.629148, 0.320312 (0.673 sec)
172.26... logprob:  0.672756, 0.390625 (0.673 sec)
172.27... logprob:  0.628732, 0.320312 (0.669 sec)
173.1... logprob:  0.678290, 0.398438 (0.672 sec)
173.2... logprob:  0.598548, 0.273438 (0.671 sec)
173.3... logprob:  0.653561, 0.359375 (0.673 sec)
173.4... logprob:  0.597465, 0.273438 (0.678 sec)
173.5... logprob:  0.591284, 0.265625 (0.668 sec)
173.6... logprob:  0.611270, 0.296875 (0.674 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.655139, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961114e-03 [7.037188e-09] 
Layer 'conv1' biases: 2.164239e-07 [1.651434e-10] 
Layer 'conv2' weights[0]: 7.948424e-03 [6.353541e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.076583e-10] 
Layer 'conv3' weights[0]: 7.946651e-03 [6.354547e-09] 
Layer 'conv3' biases: 1.997257e-06 [2.543632e-09] 
Layer 'conv4' weights[0]: 7.979130e-03 [6.734686e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.432296e-08] 
Layer 'conv5' weights[0]: 7.978539e-03 [1.556910e-07] 
Layer 'conv5' biases: 1.000006e+00 [1.692433e-07] 
Layer 'fc6' weights[0]: 7.574989e-03 [1.569821e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.523035e-08] 
Layer 'fc7' weights[0]: 7.674760e-03 [2.160813e-07] 
Layer 'fc7' biases: 9.998590e-01 [2.024233e-07] 
Layer 'fc8' weights[0]: 6.860410e-04 [1.200436e-05] 
Layer 'fc8' biases: 8.158401e-02 [2.058939e-04] 
Train error last 27 batches: 0.636466
-------------------------------------------------------
Not saving because 0.655139 > 0.627146 (160.7: -0.00%)
======================================================= (1.711 sec)
173.7... logprob:  0.644038, 0.343750 (0.670 sec)
173.8... logprob:  0.604068, 0.289062 (0.671 sec)
173.9... logprob:  0.638987, 0.335938 (0.673 sec)
173.10... logprob:  0.596663, 0.281250 (0.674 sec)
173.11... logprob:  0.639860, 0.335938 (0.676 sec)
173.12... logprob:  0.723592, 0.437500 (0.672 sec)
173.13... logprob:  0.659307, 0.359375 (0.675 sec)
173.14... logprob:  0.664806, 0.367188 (0.671 sec)
173.15... logprob:  0.688055, 0.398438 (0.677 sec)
173.16... logprob:  0.627058, 0.320312 (0.683 sec)
173.17... logprob:  0.638511, 0.335938 (0.674 sec)
173.18... logprob:  0.638236, 0.335938 (0.680 sec)
173.19... logprob:  0.632909, 0.328125 (0.671 sec)
173.20... logprob:  0.648600, 0.351562 (0.675 sec)
173.21... logprob:  0.643418, 0.343750 (0.674 sec)
173.22... logprob:  0.628894, 0.320312 (0.679 sec)
173.23... logprob:  0.624478, 0.312500 (0.681 sec)
173.24... logprob:  0.581917, 0.242188 (0.675 sec)
173.25... logprob:  0.629140, 0.320312 (0.673 sec)
173.26... logprob:  0.672764, 0.390625 (0.673 sec)
173.27... logprob:  0.628727, 0.320312 (0.673 sec)
174.1... logprob:  0.678298, 0.398438 (0.673 sec)
174.2... logprob:  0.598538, 0.273438 (0.673 sec)
174.3... logprob:  0.653562, 0.359375 (0.671 sec)
174.4... logprob:  0.597461, 0.273438 (0.672 sec)
174.5... logprob:  0.591284, 0.265625 (0.673 sec)
174.6... logprob:  0.611272, 0.296875 (0.677 sec)
174.7... logprob:  0.644036, 0.343750 (0.677 sec)
174.8... logprob:  0.604073, 0.289062 (0.672 sec)
174.9... logprob:  0.638983, 0.335938 (0.670 sec)
174.10... logprob:  0.596671, 0.281250 (0.668 sec)
174.11... logprob:  0.639852, 0.335938 (0.672 sec)
174.12... logprob:  0.723550, 0.437500 (0.670 sec)
174.13... logprob:  0.659293, 0.359375 (0.670 sec)
174.14... logprob:  0.664794, 0.367188 (0.670 sec)
174.15... logprob:  0.688044, 0.398438 (0.670 sec)
174.16... logprob:  0.627057, 0.320312 (0.668 sec)
174.17... logprob:  0.638512, 0.335938 (0.666 sec)
174.18... logprob:  0.638235, 0.335938 (0.669 sec)
174.19... logprob:  0.632907, 0.328125 (0.671 sec)
174.20... logprob:  0.648603, 0.351562 (0.666 sec)
174.21... logprob:  0.643418, 0.343750 (0.671 sec)
174.22... logprob:  0.628884, 0.320312 (0.676 sec)
174.23... logprob:  0.624466, 0.312500 (0.685 sec)
174.24... logprob:  0.581883, 0.242188 (0.671 sec)
174.25... logprob:  0.629131, 0.320312 (0.669 sec)
174.26... logprob:  0.672773, 0.390625 (0.672 sec)
174.27... logprob:  0.628721, 0.320312 (0.680 sec)
175.1... logprob:  0.678305, 0.398438 (0.671 sec)
175.2... logprob:  0.598530, 0.273438 (0.672 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.628331, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960909e-03 [6.477266e-09] 
Layer 'conv1' biases: 2.195840e-07 [7.714462e-11] 
Layer 'conv2' weights[0]: 7.948245e-03 [4.895904e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.732341e-10] 
Layer 'conv3' weights[0]: 7.946458e-03 [4.768367e-09] 
Layer 'conv3' biases: 2.022089e-06 [1.095497e-09] 
Layer 'conv4' weights[0]: 7.978923e-03 [4.823017e-09] 
Layer 'conv4' biases: 1.000001e+00 [9.232676e-09] 
Layer 'conv5' weights[0]: 7.978354e-03 [5.899849e-08] 
Layer 'conv5' biases: 1.000006e+00 [6.408419e-08] 
Layer 'fc6' weights[0]: 7.574806e-03 [6.975200e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.728759e-09] 
Layer 'fc7' weights[0]: 7.672813e-03 [9.400442e-08] 
Layer 'fc7' biases: 9.998584e-01 [7.538835e-08] 
Layer 'fc8' weights[0]: 6.557591e-04 [4.454615e-06] 
Layer 'fc8' biases: 8.199365e-02 [8.847590e-05] 
Train error last 27 batches: 0.636456
-------------------------------------------------------
Not saving because 0.628331 > 0.627146 (160.7: -0.00%)
======================================================= (1.735 sec)
175.3... logprob:  0.653563, 0.359375 (0.663 sec)
175.4... logprob:  0.597460, 0.273438 (0.662 sec)
175.5... logprob:  0.591287, 0.265625 (0.667 sec)
175.6... logprob:  0.611276, 0.296875 (0.670 sec)
175.7... logprob:  0.644032, 0.343750 (0.669 sec)
175.8... logprob:  0.604082, 0.289062 (0.668 sec)
175.9... logprob:  0.638978, 0.335938 (0.664 sec)
175.10... logprob:  0.596682, 0.281250 (0.667 sec)
175.11... logprob:  0.639842, 0.335938 (0.676 sec)
175.12... logprob:  0.723499, 0.437500 (0.675 sec)
175.13... logprob:  0.659275, 0.359375 (0.684 sec)
175.14... logprob:  0.664778, 0.367188 (0.670 sec)
175.15... logprob:  0.688029, 0.398438 (0.672 sec)
175.16... logprob:  0.627057, 0.320312 (0.672 sec)
175.17... logprob:  0.638512, 0.335938 (0.672 sec)
175.18... logprob:  0.638235, 0.335938 (0.673 sec)
175.19... logprob:  0.632905, 0.328125 (0.682 sec)
175.20... logprob:  0.648604, 0.351562 (0.682 sec)
175.21... logprob:  0.643417, 0.343750 (0.674 sec)
175.22... logprob:  0.628875, 0.320312 (0.675 sec)
175.23... logprob:  0.624453, 0.312500 (0.671 sec)
175.24... logprob:  0.581847, 0.242188 (0.671 sec)
175.25... logprob:  0.629121, 0.320312 (0.671 sec)
175.26... logprob:  0.672784, 0.390625 (0.672 sec)
175.27... logprob:  0.628715, 0.320312 (0.668 sec)
176.1... logprob:  0.678315, 0.398438 (0.671 sec)
176.2... logprob:  0.598518, 0.273438 (0.676 sec)
176.3... logprob:  0.653564, 0.359375 (0.671 sec)
176.4... logprob:  0.597455, 0.273438 (0.673 sec)
176.5... logprob:  0.591286, 0.265625 (0.671 sec)
176.6... logprob:  0.611278, 0.296875 (0.671 sec)
176.7... logprob:  0.644030, 0.343750 (0.671 sec)
176.8... logprob:  0.604088, 0.289062 (0.670 sec)
176.9... logprob:  0.638973, 0.335938 (0.670 sec)
176.10... logprob:  0.596692, 0.281250 (0.667 sec)
176.11... logprob:  0.639833, 0.335938 (0.673 sec)
176.12... logprob:  0.723454, 0.437500 (0.671 sec)
176.13... logprob:  0.659260, 0.359375 (0.674 sec)
176.14... logprob:  0.664764, 0.367188 (0.675 sec)
176.15... logprob:  0.688015, 0.398438 (0.673 sec)
176.16... logprob:  0.627057, 0.320312 (0.673 sec)
176.17... logprob:  0.638512, 0.335938 (0.674 sec)
176.18... logprob:  0.638235, 0.335938 (0.674 sec)
176.19... logprob:  0.632902, 0.328125 (0.674 sec)
176.20... logprob:  0.648606, 0.351562 (0.676 sec)
176.21... logprob:  0.643416, 0.343750 (0.675 sec)
176.22... logprob:  0.628867, 0.320312 (0.673 sec)
176.23... logprob:  0.624441, 0.312500 (0.671 sec)
176.24... logprob:  0.581813, 0.242188 (0.669 sec)
176.25... logprob:  0.629113, 0.320312 (0.676 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633704, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960725e-03 [6.233056e-09] 
Layer 'conv1' biases: 2.226053e-07 [7.453822e-11] 
Layer 'conv2' weights[0]: 7.948037e-03 [4.881483e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.052178e-10] 
Layer 'conv3' weights[0]: 7.946264e-03 [4.801875e-09] 
Layer 'conv3' biases: 2.045313e-06 [1.227880e-09] 
Layer 'conv4' weights[0]: 7.978742e-03 [4.940787e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.101130e-08] 
Layer 'conv5' weights[0]: 7.978160e-03 [6.964967e-08] 
Layer 'conv5' biases: 1.000006e+00 [7.558345e-08] 
Layer 'fc6' weights[0]: 7.574603e-03 [7.943753e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.819483e-09] 
Layer 'fc7' weights[0]: 7.670872e-03 [1.079556e-07] 
Layer 'fc7' biases: 9.998584e-01 [8.998452e-08] 
Layer 'fc8' weights[0]: 6.454294e-04 [5.299567e-06] 
Layer 'fc8' biases: 8.274296e-02 [1.101048e-04] 
Train error last 27 batches: 0.636444
-------------------------------------------------------
Not saving because 0.633704 > 0.627146 (160.7: -0.00%)
======================================================= (1.743 sec)
176.26... logprob:  0.672793, 0.390625 (0.679 sec)
176.27... logprob:  0.628709, 0.320312 (0.669 sec)
177.1... logprob:  0.678322, 0.398438 (0.672 sec)
177.2... logprob:  0.598509, 0.273438 (0.677 sec)
177.3... logprob:  0.653565, 0.359375 (0.669 sec)
177.4... logprob:  0.597452, 0.273438 (0.670 sec)
177.5... logprob:  0.591287, 0.265625 (0.672 sec)
177.6... logprob:  0.611281, 0.296875 (0.670 sec)
177.7... logprob:  0.644028, 0.343750 (0.669 sec)
177.8... logprob:  0.604096, 0.289062 (0.669 sec)
177.9... logprob:  0.638969, 0.335938 (0.668 sec)
177.10... logprob:  0.596702, 0.281250 (0.675 sec)
177.11... logprob:  0.639823, 0.335938 (0.672 sec)
177.12... logprob:  0.723407, 0.437500 (0.677 sec)
177.13... logprob:  0.659243, 0.359375 (0.686 sec)
177.14... logprob:  0.664750, 0.367188 (0.698 sec)
177.15... logprob:  0.688002, 0.398438 (0.661 sec)
177.16... logprob:  0.627058, 0.320312 (0.668 sec)
177.17... logprob:  0.638513, 0.335938 (0.667 sec)
177.18... logprob:  0.638235, 0.335938 (0.667 sec)
177.19... logprob:  0.632900, 0.328125 (0.670 sec)
177.20... logprob:  0.648608, 0.351562 (0.672 sec)
177.21... logprob:  0.643416, 0.343750 (0.673 sec)
177.22... logprob:  0.628858, 0.320312 (0.669 sec)
177.23... logprob:  0.624429, 0.312500 (0.670 sec)
177.24... logprob:  0.581779, 0.242188 (0.671 sec)
177.25... logprob:  0.629104, 0.320312 (0.672 sec)
177.26... logprob:  0.672802, 0.390625 (0.668 sec)
177.27... logprob:  0.628703, 0.320312 (0.668 sec)
178.1... logprob:  0.678331, 0.398438 (0.672 sec)
178.2... logprob:  0.598499, 0.273438 (0.675 sec)
178.3... logprob:  0.653566, 0.359375 (0.671 sec)
178.4... logprob:  0.597448, 0.273438 (0.668 sec)
178.5... logprob:  0.591287, 0.265625 (0.673 sec)
178.6... logprob:  0.611284, 0.296875 (0.675 sec)
178.7... logprob:  0.644025, 0.343750 (0.675 sec)
178.8... logprob:  0.604102, 0.289062 (0.666 sec)
178.9... logprob:  0.638964, 0.335938 (0.666 sec)
178.10... logprob:  0.596712, 0.281250 (0.668 sec)
178.11... logprob:  0.639814, 0.335938 (0.668 sec)
178.12... logprob:  0.723360, 0.437500 (0.677 sec)
178.13... logprob:  0.659227, 0.359375 (0.673 sec)
178.14... logprob:  0.664736, 0.367188 (0.673 sec)
178.15... logprob:  0.687988, 0.398438 (0.672 sec)
178.16... logprob:  0.627058, 0.320312 (0.676 sec)
178.17... logprob:  0.638513, 0.335938 (0.670 sec)
178.18... logprob:  0.638235, 0.335938 (0.674 sec)
178.19... logprob:  0.632898, 0.328125 (0.671 sec)
178.20... logprob:  0.648610, 0.351562 (0.674 sec)
178.21... logprob:  0.643414, 0.343750 (0.678 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.682491, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960528e-03 [6.561903e-09] 
Layer 'conv1' biases: 2.255510e-07 [1.428752e-10] 
Layer 'conv2' weights[0]: 7.947838e-03 [6.199092e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.918260e-10] 
Layer 'conv3' weights[0]: 7.946069e-03 [5.575998e-09] 
Layer 'conv3' biases: 2.067984e-06 [1.976031e-09] 
Layer 'conv4' weights[0]: 7.978560e-03 [5.640217e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.558739e-08] 
Layer 'conv5' weights[0]: 7.977971e-03 [9.911036e-08] 
Layer 'conv5' biases: 1.000006e+00 [1.073143e-07] 
Layer 'fc6' weights[0]: 7.574401e-03 [1.061334e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.892861e-09] 
Layer 'fc7' weights[0]: 7.668949e-03 [1.474231e-07] 
Layer 'fc7' biases: 9.998584e-01 [1.335998e-07] 
Layer 'fc8' weights[0]: 6.435462e-04 [7.832576e-06] 
Layer 'fc8' biases: 8.362632e-02 [1.093756e-04] 
Train error last 27 batches: 0.636435
-------------------------------------------------------
Not saving because 0.682491 > 0.627146 (160.7: -0.00%)
======================================================= (1.722 sec)
178.22... logprob:  0.628850, 0.320312 (0.675 sec)
178.23... logprob:  0.624417, 0.312500 (0.673 sec)
178.24... logprob:  0.581746, 0.242188 (0.682 sec)
178.25... logprob:  0.629096, 0.320312 (0.684 sec)
178.26... logprob:  0.672811, 0.390625 (0.683 sec)
178.27... logprob:  0.628697, 0.320312 (0.674 sec)
179.1... logprob:  0.678339, 0.398438 (0.674 sec)
179.2... logprob:  0.598489, 0.273438 (0.675 sec)
179.3... logprob:  0.653567, 0.359375 (0.674 sec)
179.4... logprob:  0.597444, 0.273438 (0.674 sec)
179.5... logprob:  0.591287, 0.265625 (0.677 sec)
179.6... logprob:  0.611286, 0.296875 (0.681 sec)
179.7... logprob:  0.644023, 0.343750 (0.682 sec)
179.8... logprob:  0.604108, 0.289062 (0.673 sec)
179.9... logprob:  0.638960, 0.335938 (0.675 sec)
179.10... logprob:  0.596720, 0.281250 (0.682 sec)
179.11... logprob:  0.639806, 0.335938 (0.679 sec)
179.12... logprob:  0.723319, 0.437500 (0.672 sec)
179.13... logprob:  0.659213, 0.359375 (0.679 sec)
179.14... logprob:  0.664723, 0.367188 (0.679 sec)
179.15... logprob:  0.687976, 0.398438 (0.676 sec)
179.16... logprob:  0.627057, 0.320312 (0.679 sec)
179.17... logprob:  0.638513, 0.335938 (0.679 sec)
179.18... logprob:  0.638236, 0.335938 (0.684 sec)
179.19... logprob:  0.632896, 0.328125 (0.674 sec)
179.20... logprob:  0.648612, 0.351562 (0.675 sec)
179.21... logprob:  0.643414, 0.343750 (0.674 sec)
179.22... logprob:  0.628841, 0.320312 (0.675 sec)
179.23... logprob:  0.624406, 0.312500 (0.669 sec)
179.24... logprob:  0.581713, 0.242188 (0.671 sec)
179.25... logprob:  0.629088, 0.320312 (0.683 sec)
179.26... logprob:  0.672821, 0.390625 (0.674 sec)
179.27... logprob:  0.628692, 0.320312 (0.677 sec)
180.1... logprob:  0.678347, 0.398438 (0.674 sec)
180.2... logprob:  0.598480, 0.273438 (0.677 sec)
180.3... logprob:  0.653568, 0.359375 (0.675 sec)
180.4... logprob:  0.597442, 0.273438 (0.673 sec)
180.5... logprob:  0.591289, 0.265625 (0.672 sec)
180.6... logprob:  0.611289, 0.296875 (0.674 sec)
180.7... logprob:  0.644020, 0.343750 (0.675 sec)
180.8... logprob:  0.604117, 0.289062 (0.674 sec)
180.9... logprob:  0.638955, 0.335938 (0.677 sec)
180.10... logprob:  0.596731, 0.281250 (0.677 sec)
180.11... logprob:  0.639796, 0.335938 (0.681 sec)
180.12... logprob:  0.723269, 0.437500 (0.676 sec)
180.13... logprob:  0.659196, 0.359375 (0.676 sec)
180.14... logprob:  0.664708, 0.367188 (0.678 sec)
180.15... logprob:  0.687961, 0.398438 (0.704 sec)
180.16... logprob:  0.627057, 0.320312 (0.675 sec)
180.17... logprob:  0.638514, 0.335938 (0.678 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.632878, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960335e-03 [6.532217e-09] 
Layer 'conv1' biases: 2.282473e-07 [1.791634e-10] 
Layer 'conv2' weights[0]: 7.947649e-03 [7.167271e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.511881e-10] 
Layer 'conv3' weights[0]: 7.945874e-03 [6.446920e-09] 
Layer 'conv3' biases: 2.087359e-06 [2.710081e-09] 
Layer 'conv4' weights[0]: 7.978366e-03 [6.717772e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.325410e-08] 
Layer 'conv5' weights[0]: 7.977788e-03 [1.477358e-07] 
Layer 'conv5' biases: 1.000005e+00 [1.601224e-07] 
Layer 'fc6' weights[0]: 7.574203e-03 [1.513453e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.472087e-08] 
Layer 'fc7' weights[0]: 7.666998e-03 [2.095680e-07] 
Layer 'fc7' biases: 9.998587e-01 [1.969026e-07] 
Layer 'fc8' weights[0]: 6.746888e-04 [1.159812e-05] 
Layer 'fc8' biases: 8.511717e-02 [1.619720e-04] 
Train error last 27 batches: 0.636424
-------------------------------------------------------
Not saving because 0.632878 > 0.627146 (160.7: -0.00%)
======================================================= (1.744 sec)
180.18... logprob:  0.638235, 0.335938 (0.695 sec)
180.19... logprob:  0.632894, 0.328125 (0.685 sec)
180.20... logprob:  0.648614, 0.351562 (0.688 sec)
180.21... logprob:  0.643413, 0.343750 (0.687 sec)
180.22... logprob:  0.628834, 0.320312 (0.676 sec)
180.23... logprob:  0.624394, 0.312500 (0.674 sec)
180.24... logprob:  0.581680, 0.242188 (0.685 sec)
180.25... logprob:  0.629079, 0.320312 (0.678 sec)
180.26... logprob:  0.672830, 0.390625 (0.675 sec)
180.27... logprob:  0.628686, 0.320312 (0.674 sec)
181.1... logprob:  0.678355, 0.398438 (0.676 sec)
181.2... logprob:  0.598469, 0.273438 (0.674 sec)
181.3... logprob:  0.653569, 0.359375 (0.676 sec)
181.4... logprob:  0.597437, 0.273438 (0.678 sec)
181.5... logprob:  0.591287, 0.265625 (0.676 sec)
181.6... logprob:  0.611290, 0.296875 (0.678 sec)
181.7... logprob:  0.644019, 0.343750 (0.675 sec)
181.8... logprob:  0.604122, 0.289062 (0.677 sec)
181.9... logprob:  0.638951, 0.335938 (0.687 sec)
181.10... logprob:  0.596739, 0.281250 (0.679 sec)
181.11... logprob:  0.639788, 0.335938 (0.681 sec)
181.12... logprob:  0.723228, 0.437500 (0.676 sec)
181.13... logprob:  0.659182, 0.359375 (0.679 sec)
181.14... logprob:  0.664695, 0.367188 (0.678 sec)
181.15... logprob:  0.687949, 0.398438 (0.677 sec)
181.16... logprob:  0.627057, 0.320312 (0.676 sec)
181.17... logprob:  0.638514, 0.335938 (0.693 sec)
181.18... logprob:  0.638235, 0.335938 (0.683 sec)
181.19... logprob:  0.632892, 0.328125 (0.676 sec)
181.20... logprob:  0.648616, 0.351562 (0.679 sec)
181.21... logprob:  0.643412, 0.343750 (0.677 sec)
181.22... logprob:  0.628825, 0.320312 (0.680 sec)
181.23... logprob:  0.624382, 0.312500 (0.675 sec)
181.24... logprob:  0.581647, 0.242188 (0.676 sec)
181.25... logprob:  0.629070, 0.320312 (0.677 sec)
181.26... logprob:  0.672839, 0.390625 (0.676 sec)
181.27... logprob:  0.628680, 0.320312 (0.674 sec)
182.1... logprob:  0.678363, 0.398438 (0.682 sec)
182.2... logprob:  0.598460, 0.273438 (0.678 sec)
182.3... logprob:  0.653570, 0.359375 (0.678 sec)
182.4... logprob:  0.597435, 0.273438 (0.673 sec)
182.5... logprob:  0.591289, 0.265625 (0.677 sec)
182.6... logprob:  0.611294, 0.296875 (0.676 sec)
182.7... logprob:  0.644016, 0.343750 (0.676 sec)
182.8... logprob:  0.604130, 0.289062 (0.673 sec)
182.9... logprob:  0.638946, 0.335938 (0.678 sec)
182.10... logprob:  0.596750, 0.281250 (0.676 sec)
182.11... logprob:  0.639778, 0.335938 (0.676 sec)
182.12... logprob:  0.723180, 0.437500 (0.674 sec)
182.13... logprob:  0.659165, 0.359375 (0.673 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627383, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960143e-03 [6.439022e-09] 
Layer 'conv1' biases: 2.308667e-07 [1.065725e-10] 
Layer 'conv2' weights[0]: 7.947466e-03 [5.635151e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.509929e-10] 
Layer 'conv3' weights[0]: 7.945676e-03 [5.036630e-09] 
Layer 'conv3' biases: 2.105943e-06 [1.533672e-09] 
Layer 'conv4' weights[0]: 7.978183e-03 [5.053564e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.124941e-08] 
Layer 'conv5' weights[0]: 7.977565e-03 [7.132299e-08] 
Layer 'conv5' biases: 1.000005e+00 [7.716687e-08] 
Layer 'fc6' weights[0]: 7.574011e-03 [8.202230e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.156880e-09] 
Layer 'fc7' weights[0]: 7.665032e-03 [1.134557e-07] 
Layer 'fc7' biases: 9.998592e-01 [9.632738e-08] 
Layer 'fc8' weights[0]: 7.152430e-04 [5.657939e-06] 
Layer 'fc8' biases: 8.673222e-02 [6.679249e-05] 
Train error last 27 batches: 0.636414
-------------------------------------------------------
Not saving because 0.627383 > 0.627146 (160.7: -0.00%)
======================================================= (1.739 sec)
182.14... logprob:  0.664680, 0.367188 (0.672 sec)
182.15... logprob:  0.687934, 0.398438 (0.673 sec)
182.16... logprob:  0.627057, 0.320312 (0.676 sec)
182.17... logprob:  0.638514, 0.335938 (0.676 sec)
182.18... logprob:  0.638235, 0.335938 (0.677 sec)
182.19... logprob:  0.632890, 0.328125 (0.679 sec)
182.20... logprob:  0.648618, 0.351562 (0.681 sec)
182.21... logprob:  0.643412, 0.343750 (0.675 sec)
182.22... logprob:  0.628817, 0.320312 (0.672 sec)
182.23... logprob:  0.624371, 0.312500 (0.674 sec)
182.24... logprob:  0.581614, 0.242188 (0.676 sec)
182.25... logprob:  0.629062, 0.320312 (0.680 sec)
182.26... logprob:  0.672848, 0.390625 (0.667 sec)
182.27... logprob:  0.628674, 0.320312 (0.666 sec)
183.1... logprob:  0.678371, 0.398438 (0.665 sec)
183.2... logprob:  0.598449, 0.273438 (0.668 sec)
183.3... logprob:  0.653571, 0.359375 (0.665 sec)
183.4... logprob:  0.597429, 0.273438 (0.664 sec)
183.5... logprob:  0.591287, 0.265625 (0.672 sec)
183.6... logprob:  0.611295, 0.296875 (0.669 sec)
183.7... logprob:  0.644014, 0.343750 (0.671 sec)
183.8... logprob:  0.604135, 0.289062 (0.671 sec)
183.9... logprob:  0.638942, 0.335938 (0.670 sec)
183.10... logprob:  0.596757, 0.281250 (0.672 sec)
183.11... logprob:  0.639770, 0.335938 (0.673 sec)
183.12... logprob:  0.723139, 0.437500 (0.672 sec)
183.13... logprob:  0.659151, 0.359375 (0.672 sec)
183.14... logprob:  0.664668, 0.367188 (0.679 sec)
183.15... logprob:  0.687922, 0.398438 (0.691 sec)
183.16... logprob:  0.627057, 0.320312 (0.692 sec)
183.17... logprob:  0.638515, 0.335938 (0.701 sec)
183.18... logprob:  0.638235, 0.335938 (0.682 sec)
183.19... logprob:  0.632888, 0.328125 (0.678 sec)
183.20... logprob:  0.648619, 0.351562 (0.674 sec)
183.21... logprob:  0.643411, 0.343750 (0.689 sec)
183.22... logprob:  0.628809, 0.320312 (0.684 sec)
183.23... logprob:  0.624360, 0.312500 (0.679 sec)
183.24... logprob:  0.581583, 0.242188 (0.679 sec)
183.25... logprob:  0.629054, 0.320312 (0.681 sec)
183.26... logprob:  0.672857, 0.390625 (0.680 sec)
183.27... logprob:  0.628669, 0.320312 (0.678 sec)
184.1... logprob:  0.678378, 0.398438 (0.681 sec)
184.2... logprob:  0.598441, 0.273438 (0.686 sec)
184.3... logprob:  0.653572, 0.359375 (0.682 sec)
184.4... logprob:  0.597427, 0.273438 (0.685 sec)
184.5... logprob:  0.591288, 0.265625 (0.683 sec)
184.6... logprob:  0.611298, 0.296875 (0.683 sec)
184.7... logprob:  0.644012, 0.343750 (0.676 sec)
184.8... logprob:  0.604142, 0.289062 (0.676 sec)
184.9... logprob:  0.638937, 0.335938 (0.673 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.657464, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959944e-03 [6.538118e-09] 
Layer 'conv1' biases: 2.338482e-07 [1.101821e-10] 
Layer 'conv2' weights[0]: 7.947254e-03 [5.620177e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.610708e-10] 
Layer 'conv3' weights[0]: 7.945476e-03 [5.618146e-09] 
Layer 'conv3' biases: 2.129156e-06 [1.864150e-09] 
Layer 'conv4' weights[0]: 7.977995e-03 [5.944096e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.783629e-08] 
Layer 'conv5' weights[0]: 7.977385e-03 [1.131325e-07] 
Layer 'conv5' biases: 1.000005e+00 [1.227502e-07] 
Layer 'fc6' weights[0]: 7.573812e-03 [1.178796e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.115845e-08] 
Layer 'fc7' weights[0]: 7.663080e-03 [1.605914e-07] 
Layer 'fc7' biases: 9.998589e-01 [1.462885e-07] 
Layer 'fc8' weights[0]: 7.054107e-04 [8.647044e-06] 
Layer 'fc8' biases: 8.748902e-02 [1.514578e-04] 
Train error last 27 batches: 0.636406
-------------------------------------------------------
Not saving because 0.657464 > 0.627146 (160.7: -0.00%)
======================================================= (1.732 sec)
184.10... logprob:  0.596768, 0.281250 (0.681 sec)
184.11... logprob:  0.639762, 0.335938 (0.686 sec)
184.12... logprob:  0.723093, 0.437500 (0.679 sec)
184.13... logprob:  0.659135, 0.359375 (0.668 sec)
184.14... logprob:  0.664654, 0.367188 (0.666 sec)
184.15... logprob:  0.687907, 0.398438 (0.664 sec)
184.16... logprob:  0.627057, 0.320312 (0.666 sec)
184.17... logprob:  0.638515, 0.335938 (0.665 sec)
184.18... logprob:  0.638235, 0.335938 (0.666 sec)
184.19... logprob:  0.632886, 0.328125 (0.668 sec)
184.20... logprob:  0.648621, 0.351562 (0.667 sec)
184.21... logprob:  0.643410, 0.343750 (0.672 sec)
184.22... logprob:  0.628802, 0.320312 (0.681 sec)
184.23... logprob:  0.624349, 0.312500 (0.664 sec)
184.24... logprob:  0.581551, 0.242188 (0.668 sec)
184.25... logprob:  0.629046, 0.320312 (0.665 sec)
184.26... logprob:  0.672866, 0.390625 (0.666 sec)
184.27... logprob:  0.628663, 0.320312 (0.665 sec)
185.1... logprob:  0.678387, 0.398438 (0.664 sec)
185.2... logprob:  0.598430, 0.273438 (0.668 sec)
185.3... logprob:  0.653574, 0.359375 (0.667 sec)
185.4... logprob:  0.597423, 0.273438 (0.666 sec)
185.5... logprob:  0.591288, 0.265625 (0.673 sec)
185.6... logprob:  0.611300, 0.296875 (0.674 sec)
185.7... logprob:  0.644009, 0.343750 (0.669 sec)
185.8... logprob:  0.604148, 0.289062 (0.665 sec)
185.9... logprob:  0.638933, 0.335938 (0.682 sec)
185.10... logprob:  0.596776, 0.281250 (0.677 sec)
185.11... logprob:  0.639753, 0.335938 (0.666 sec)
185.12... logprob:  0.723051, 0.437500 (0.674 sec)
185.13... logprob:  0.659121, 0.359375 (0.703 sec)
185.14... logprob:  0.664641, 0.367188 (0.693 sec)
185.15... logprob:  0.687895, 0.398438 (0.665 sec)
185.16... logprob:  0.627057, 0.320312 (0.675 sec)
185.17... logprob:  0.638515, 0.335938 (0.665 sec)
185.18... logprob:  0.638235, 0.335938 (0.676 sec)
185.19... logprob:  0.632884, 0.328125 (0.675 sec)
185.20... logprob:  0.648623, 0.351562 (0.672 sec)
185.21... logprob:  0.643410, 0.343750 (0.671 sec)
185.22... logprob:  0.628794, 0.320312 (0.674 sec)
185.23... logprob:  0.624337, 0.312500 (0.670 sec)
185.24... logprob:  0.581519, 0.242188 (0.673 sec)
185.25... logprob:  0.629038, 0.320312 (0.675 sec)
185.26... logprob:  0.672874, 0.390625 (0.673 sec)
185.27... logprob:  0.628658, 0.320312 (0.669 sec)
186.1... logprob:  0.678394, 0.398438 (0.672 sec)
186.2... logprob:  0.598421, 0.273438 (0.673 sec)
186.3... logprob:  0.653574, 0.359375 (0.669 sec)
186.4... logprob:  0.597419, 0.273438 (0.670 sec)
186.5... logprob:  0.591288, 0.265625 (0.672 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627557, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959738e-03 [7.203748e-09] 
Layer 'conv1' biases: 2.370438e-07 [1.454647e-10] 
Layer 'conv2' weights[0]: 7.947063e-03 [6.086315e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.048809e-10] 
Layer 'conv3' weights[0]: 7.945279e-03 [6.049620e-09] 
Layer 'conv3' biases: 2.155054e-06 [2.234837e-09] 
Layer 'conv4' weights[0]: 7.977800e-03 [6.358660e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.118634e-08] 
Layer 'conv5' weights[0]: 7.977201e-03 [1.343559e-07] 
Layer 'conv5' biases: 1.000005e+00 [1.456605e-07] 
Layer 'fc6' weights[0]: 7.573627e-03 [1.382530e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.333301e-08] 
Layer 'fc7' weights[0]: 7.661137e-03 [1.890044e-07] 
Layer 'fc7' biases: 9.998584e-01 [1.753724e-07] 
Layer 'fc8' weights[0]: 6.676991e-04 [1.031837e-05] 
Layer 'fc8' biases: 8.774513e-02 [1.843977e-04] 
Train error last 27 batches: 0.636395
-------------------------------------------------------
Not saving because 0.627557 > 0.627146 (160.7: -0.00%)
======================================================= (1.712 sec)
186.6... logprob:  0.611303, 0.296875 (0.673 sec)
186.7... logprob:  0.644008, 0.343750 (0.686 sec)
186.8... logprob:  0.604155, 0.289062 (0.687 sec)
186.9... logprob:  0.638929, 0.335938 (0.677 sec)
186.10... logprob:  0.596786, 0.281250 (0.682 sec)
186.11... logprob:  0.639745, 0.335938 (0.684 sec)
186.12... logprob:  0.723007, 0.437500 (0.681 sec)
186.13... logprob:  0.659105, 0.359375 (0.679 sec)
186.14... logprob:  0.664627, 0.367188 (0.673 sec)
186.15... logprob:  0.687882, 0.398438 (0.673 sec)
186.16... logprob:  0.627057, 0.320312 (0.671 sec)
186.17... logprob:  0.638515, 0.335938 (0.682 sec)
186.18... logprob:  0.638234, 0.335938 (0.676 sec)
186.19... logprob:  0.632882, 0.328125 (0.679 sec)
186.20... logprob:  0.648625, 0.351562 (0.685 sec)
186.21... logprob:  0.643409, 0.343750 (0.673 sec)
186.22... logprob:  0.628785, 0.320312 (0.670 sec)
186.23... logprob:  0.624326, 0.312500 (0.671 sec)
186.24... logprob:  0.581486, 0.242188 (0.678 sec)
186.25... logprob:  0.629030, 0.320312 (0.675 sec)
186.26... logprob:  0.672884, 0.390625 (0.667 sec)
186.27... logprob:  0.628652, 0.320312 (0.672 sec)
187.1... logprob:  0.678403, 0.398438 (0.674 sec)
187.2... logprob:  0.598411, 0.273438 (0.673 sec)
187.3... logprob:  0.653575, 0.359375 (0.668 sec)
187.4... logprob:  0.597416, 0.273438 (0.668 sec)
187.5... logprob:  0.591288, 0.265625 (0.667 sec)
187.6... logprob:  0.611305, 0.296875 (0.666 sec)
187.7... logprob:  0.644005, 0.343750 (0.669 sec)
187.8... logprob:  0.604161, 0.289062 (0.668 sec)
187.9... logprob:  0.638925, 0.335938 (0.668 sec)
187.10... logprob:  0.596796, 0.281250 (0.667 sec)
187.11... logprob:  0.639735, 0.335938 (0.669 sec)
187.12... logprob:  0.722960, 0.437500 (0.676 sec)
187.13... logprob:  0.659089, 0.359375 (0.682 sec)
187.14... logprob:  0.664613, 0.367188 (0.678 sec)
187.15... logprob:  0.687867, 0.398438 (0.677 sec)
187.16... logprob:  0.627057, 0.320312 (0.706 sec)
187.17... logprob:  0.638516, 0.335938 (0.680 sec)
187.18... logprob:  0.638234, 0.335938 (0.684 sec)
187.19... logprob:  0.632880, 0.328125 (0.682 sec)
187.20... logprob:  0.648627, 0.351562 (0.693 sec)
187.21... logprob:  0.643408, 0.343750 (0.698 sec)
187.22... logprob:  0.628778, 0.320312 (0.703 sec)
187.23... logprob:  0.624315, 0.312500 (0.699 sec)
187.24... logprob:  0.581454, 0.242188 (0.687 sec)
187.25... logprob:  0.629021, 0.320312 (0.673 sec)
187.26... logprob:  0.672893, 0.390625 (0.679 sec)
187.27... logprob:  0.628647, 0.320312 (0.670 sec)
188.1... logprob:  0.678411, 0.398438 (0.673 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633446, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959541e-03 [6.307035e-09] 
Layer 'conv1' biases: 2.401517e-07 [6.150568e-11] 
Layer 'conv2' weights[0]: 7.946866e-03 [4.747350e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.184829e-10] 
Layer 'conv3' weights[0]: 7.945087e-03 [4.327204e-09] 
Layer 'conv3' biases: 2.179504e-06 [5.214631e-10] 
Layer 'conv4' weights[0]: 7.977600e-03 [4.235780e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.750416e-10] 
Layer 'conv5' weights[0]: 7.977030e-03 [4.704087e-09] 
Layer 'conv5' biases: 1.000006e+00 [2.183116e-09] 
Layer 'fc6' weights[0]: 7.573426e-03 [3.807534e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.426501e-10] 
Layer 'fc7' weights[0]: 7.659186e-03 [3.832434e-08] 
Layer 'fc7' biases: 9.998581e-01 [1.904374e-09] 
Layer 'fc8' weights[0]: 6.455122e-04 [1.273153e-07] 
Layer 'fc8' biases: 8.825547e-02 [1.434100e-05] 
Train error last 27 batches: 0.636385
-------------------------------------------------------
Not saving because 0.633446 > 0.627146 (160.7: -0.00%)
======================================================= (1.859 sec)
188.2... logprob:  0.598401, 0.273438 (0.678 sec)
188.3... logprob:  0.653577, 0.359375 (0.677 sec)
188.4... logprob:  0.597411, 0.273438 (0.676 sec)
188.5... logprob:  0.591288, 0.265625 (0.681 sec)
188.6... logprob:  0.611307, 0.296875 (0.672 sec)
188.7... logprob:  0.644003, 0.343750 (0.676 sec)
188.8... logprob:  0.604168, 0.289062 (0.674 sec)
188.9... logprob:  0.638920, 0.335938 (0.674 sec)
188.10... logprob:  0.596805, 0.281250 (0.674 sec)
188.11... logprob:  0.639727, 0.335938 (0.678 sec)
188.12... logprob:  0.722918, 0.437500 (0.677 sec)
188.13... logprob:  0.659074, 0.359375 (0.677 sec)
188.14... logprob:  0.664600, 0.367188 (0.685 sec)
188.15... logprob:  0.687854, 0.398438 (0.682 sec)
188.16... logprob:  0.627057, 0.320312 (0.682 sec)
188.17... logprob:  0.638516, 0.335938 (0.674 sec)
188.18... logprob:  0.638234, 0.335938 (0.675 sec)
188.19... logprob:  0.632878, 0.328125 (0.672 sec)
188.20... logprob:  0.648629, 0.351562 (0.674 sec)
188.21... logprob:  0.643408, 0.343750 (0.672 sec)
188.22... logprob:  0.628770, 0.320312 (0.675 sec)
188.23... logprob:  0.624304, 0.312500 (0.670 sec)
188.24... logprob:  0.581423, 0.242188 (0.672 sec)
188.25... logprob:  0.629014, 0.320312 (0.674 sec)
188.26... logprob:  0.672902, 0.390625 (0.672 sec)
188.27... logprob:  0.628641, 0.320312 (0.675 sec)
189.1... logprob:  0.678419, 0.398438 (0.674 sec)
189.2... logprob:  0.598391, 0.273438 (0.672 sec)
189.3... logprob:  0.653578, 0.359375 (0.672 sec)
189.4... logprob:  0.597408, 0.273438 (0.674 sec)
189.5... logprob:  0.591287, 0.265625 (0.674 sec)
189.6... logprob:  0.611309, 0.296875 (0.674 sec)
189.7... logprob:  0.644001, 0.343750 (0.678 sec)
189.8... logprob:  0.604173, 0.289062 (0.673 sec)
189.9... logprob:  0.638916, 0.335938 (0.671 sec)
189.10... logprob:  0.596814, 0.281250 (0.674 sec)
189.11... logprob:  0.639719, 0.335938 (0.678 sec)
189.12... logprob:  0.722876, 0.437500 (0.673 sec)
189.13... logprob:  0.659060, 0.359375 (0.675 sec)
189.14... logprob:  0.664587, 0.367188 (0.674 sec)
189.15... logprob:  0.687842, 0.398438 (0.673 sec)
189.16... logprob:  0.627057, 0.320312 (0.675 sec)
189.17... logprob:  0.638516, 0.335938 (0.676 sec)
189.18... logprob:  0.638234, 0.335938 (0.681 sec)
189.19... logprob:  0.632876, 0.328125 (0.684 sec)
189.20... logprob:  0.648631, 0.351562 (0.678 sec)
189.21... logprob:  0.643408, 0.343750 (0.676 sec)
189.22... logprob:  0.628762, 0.320312 (0.675 sec)
189.23... logprob:  0.624293, 0.312500 (0.674 sec)
189.24... logprob:  0.581391, 0.242188 (0.672 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.682211, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959334e-03 [6.158569e-09] 
Layer 'conv1' biases: 2.431564e-07 [5.892645e-11] 
Layer 'conv2' weights[0]: 7.946664e-03 [4.736666e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.194297e-10] 
Layer 'conv3' weights[0]: 7.944902e-03 [4.564254e-09] 
Layer 'conv3' biases: 2.202945e-06 [9.666412e-10] 
Layer 'conv4' weights[0]: 7.977395e-03 [4.593013e-09] 
Layer 'conv4' biases: 1.000001e+00 [7.900014e-09] 
Layer 'conv5' weights[0]: 7.976827e-03 [4.955867e-08] 
Layer 'conv5' biases: 1.000006e+00 [5.364497e-08] 
Layer 'fc6' weights[0]: 7.573229e-03 [6.305662e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.918721e-09] 
Layer 'fc7' weights[0]: 7.657242e-03 [8.335827e-08] 
Layer 'fc7' biases: 9.998580e-01 [6.415230e-08] 
Layer 'fc8' weights[0]: 6.353513e-04 [3.744904e-06] 
Layer 'fc8' biases: 8.896598e-02 [8.616397e-05] 
Train error last 27 batches: 0.636374
-------------------------------------------------------
Not saving because 0.682211 > 0.627146 (160.7: -0.00%)
======================================================= (1.768 sec)
189.25... logprob:  0.629006, 0.320312 (0.676 sec)
189.26... logprob:  0.672911, 0.390625 (0.677 sec)
189.27... logprob:  0.628635, 0.320312 (0.674 sec)
190.1... logprob:  0.678427, 0.398438 (0.675 sec)
190.2... logprob:  0.598382, 0.273438 (0.679 sec)
190.3... logprob:  0.653578, 0.359375 (0.674 sec)
190.4... logprob:  0.597405, 0.273438 (0.678 sec)
190.5... logprob:  0.591290, 0.265625 (0.687 sec)
190.6... logprob:  0.611312, 0.296875 (0.677 sec)
190.7... logprob:  0.643998, 0.343750 (0.674 sec)
190.8... logprob:  0.604181, 0.289062 (0.673 sec)
190.9... logprob:  0.638912, 0.335938 (0.675 sec)
190.10... logprob:  0.596824, 0.281250 (0.680 sec)
190.11... logprob:  0.639710, 0.335938 (0.674 sec)
190.12... logprob:  0.722829, 0.437500 (0.674 sec)
190.13... logprob:  0.659044, 0.359375 (0.673 sec)
190.14... logprob:  0.664572, 0.367188 (0.677 sec)
190.15... logprob:  0.687827, 0.398438 (0.675 sec)
190.16... logprob:  0.627057, 0.320312 (0.678 sec)
190.17... logprob:  0.638517, 0.335938 (0.677 sec)
190.18... logprob:  0.638234, 0.335938 (0.676 sec)
190.19... logprob:  0.632875, 0.328125 (0.678 sec)
190.20... logprob:  0.648633, 0.351562 (0.680 sec)
190.21... logprob:  0.643407, 0.343750 (0.682 sec)
190.22... logprob:  0.628754, 0.320312 (0.677 sec)
190.23... logprob:  0.624282, 0.312500 (0.666 sec)
190.24... logprob:  0.581359, 0.242188 (0.667 sec)
190.25... logprob:  0.628998, 0.320312 (0.667 sec)
190.26... logprob:  0.672920, 0.390625 (0.672 sec)
190.27... logprob:  0.628630, 0.320312 (0.675 sec)
191.1... logprob:  0.678435, 0.398438 (0.671 sec)
191.2... logprob:  0.598371, 0.273438 (0.671 sec)
191.3... logprob:  0.653580, 0.359375 (0.670 sec)
191.4... logprob:  0.597399, 0.273438 (0.667 sec)
191.5... logprob:  0.591287, 0.265625 (0.671 sec)
191.6... logprob:  0.611313, 0.296875 (0.669 sec)
191.7... logprob:  0.643997, 0.343750 (0.669 sec)
191.8... logprob:  0.604186, 0.289062 (0.671 sec)
191.9... logprob:  0.638908, 0.335938 (0.671 sec)
191.10... logprob:  0.596832, 0.281250 (0.667 sec)
191.11... logprob:  0.639703, 0.335938 (0.671 sec)
191.12... logprob:  0.722791, 0.437500 (0.671 sec)
191.13... logprob:  0.659030, 0.359375 (0.671 sec)
191.14... logprob:  0.664560, 0.367188 (0.672 sec)
191.15... logprob:  0.687815, 0.398438 (0.670 sec)
191.16... logprob:  0.627057, 0.320312 (0.671 sec)
191.17... logprob:  0.638517, 0.335938 (0.668 sec)
191.18... logprob:  0.638234, 0.335938 (0.669 sec)
191.19... logprob:  0.632873, 0.328125 (0.672 sec)
191.20... logprob:  0.648634, 0.351562 (0.670 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633445, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959128e-03 [6.656002e-09] 
Layer 'conv1' biases: 2.460318e-07 [1.558609e-10] 
Layer 'conv2' weights[0]: 7.946475e-03 [6.429545e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.630773e-10] 
Layer 'conv3' weights[0]: 7.944708e-03 [5.771971e-09] 
Layer 'conv3' biases: 2.224521e-06 [2.176657e-09] 
Layer 'conv4' weights[0]: 7.977195e-03 [5.827790e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.723869e-08] 
Layer 'conv5' weights[0]: 7.976636e-03 [1.085475e-07] 
Layer 'conv5' biases: 1.000005e+00 [1.172993e-07] 
Layer 'fc6' weights[0]: 7.573045e-03 [1.155733e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.096310e-08] 
Layer 'fc7' weights[0]: 7.655254e-03 [1.593312e-07] 
Layer 'fc7' biases: 9.998581e-01 [1.460316e-07] 
Layer 'fc8' weights[0]: 6.448600e-04 [8.519774e-06] 
Layer 'fc8' biases: 9.004365e-02 [1.226120e-04] 
Train error last 27 batches: 0.636366
-------------------------------------------------------
Not saving because 0.633445 > 0.627146 (160.7: -0.00%)
======================================================= (1.713 sec)
191.21... logprob:  0.643406, 0.343750 (0.669 sec)
191.22... logprob:  0.628747, 0.320312 (0.669 sec)
191.23... logprob:  0.624272, 0.312500 (0.672 sec)
191.24... logprob:  0.581330, 0.242188 (0.672 sec)
191.25... logprob:  0.628991, 0.320312 (0.667 sec)
191.26... logprob:  0.672928, 0.390625 (0.669 sec)
191.27... logprob:  0.628625, 0.320312 (0.668 sec)
192.1... logprob:  0.678442, 0.398438 (0.669 sec)
192.2... logprob:  0.598363, 0.273438 (0.667 sec)
192.3... logprob:  0.653581, 0.359375 (0.667 sec)
192.4... logprob:  0.597396, 0.273438 (0.666 sec)
192.5... logprob:  0.591288, 0.265625 (0.668 sec)
192.6... logprob:  0.611315, 0.296875 (0.670 sec)
192.7... logprob:  0.643995, 0.343750 (0.669 sec)
192.8... logprob:  0.604192, 0.289062 (0.671 sec)
192.9... logprob:  0.638904, 0.335938 (0.674 sec)
192.10... logprob:  0.596841, 0.281250 (0.679 sec)
192.11... logprob:  0.639695, 0.335938 (0.668 sec)
192.12... logprob:  0.722749, 0.437500 (0.668 sec)
192.13... logprob:  0.659016, 0.359375 (0.672 sec)
192.14... logprob:  0.664547, 0.367188 (0.672 sec)
192.15... logprob:  0.687802, 0.398438 (0.669 sec)
192.16... logprob:  0.627057, 0.320312 (0.669 sec)
192.17... logprob:  0.638517, 0.335938 (0.670 sec)
192.18... logprob:  0.638234, 0.335938 (0.667 sec)
192.19... logprob:  0.632871, 0.328125 (0.666 sec)
192.20... logprob:  0.648635, 0.351562 (0.669 sec)
192.21... logprob:  0.643406, 0.343750 (0.668 sec)
192.22... logprob:  0.628740, 0.320312 (0.668 sec)
192.23... logprob:  0.624261, 0.312500 (0.668 sec)
192.24... logprob:  0.581300, 0.242188 (0.669 sec)
192.25... logprob:  0.628983, 0.320312 (0.667 sec)
192.26... logprob:  0.672937, 0.390625 (0.668 sec)
192.27... logprob:  0.628619, 0.320312 (0.668 sec)
193.1... logprob:  0.678450, 0.398438 (0.668 sec)
193.2... logprob:  0.598353, 0.273438 (0.669 sec)
193.3... logprob:  0.653582, 0.359375 (0.667 sec)
193.4... logprob:  0.597392, 0.273438 (0.670 sec)
193.5... logprob:  0.591287, 0.265625 (0.671 sec)
193.6... logprob:  0.611317, 0.296875 (0.667 sec)
193.7... logprob:  0.643993, 0.343750 (0.667 sec)
193.8... logprob:  0.604198, 0.289062 (0.670 sec)
193.9... logprob:  0.638900, 0.335938 (0.667 sec)
193.10... logprob:  0.596850, 0.281250 (0.670 sec)
193.11... logprob:  0.639687, 0.335938 (0.675 sec)
193.12... logprob:  0.722708, 0.437500 (0.672 sec)
193.13... logprob:  0.659002, 0.359375 (0.678 sec)
193.14... logprob:  0.664535, 0.367188 (0.666 sec)
193.15... logprob:  0.687790, 0.398438 (0.671 sec)
193.16... logprob:  0.627056, 0.320312 (0.672 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627240, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958917e-03 [6.895350e-09] 
Layer 'conv1' biases: 2.487754e-07 [1.924697e-10] 
Layer 'conv2' weights[0]: 7.946294e-03 [7.474140e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.012202e-09] 
Layer 'conv3' weights[0]: 7.944510e-03 [6.656470e-09] 
Layer 'conv3' biases: 2.244160e-06 [2.881147e-09] 
Layer 'conv4' weights[0]: 7.976998e-03 [6.861364e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.380444e-08] 
Layer 'conv5' weights[0]: 7.976414e-03 [1.500508e-07] 
Layer 'conv5' biases: 1.000005e+00 [1.622288e-07] 
Layer 'fc6' weights[0]: 7.572851e-03 [1.552366e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.512420e-08] 
Layer 'fc7' weights[0]: 7.653281e-03 [2.127814e-07] 
Layer 'fc7' biases: 9.998585e-01 [2.001734e-07] 
Layer 'fc8' weights[0]: 6.781397e-04 [1.172035e-05] 
Layer 'fc8' biases: 9.155031e-02 [1.669209e-04] 
Train error last 27 batches: 0.636356
-------------------------------------------------------
Not saving because 0.627240 > 0.627146 (160.7: -0.00%)
======================================================= (1.702 sec)
193.17... logprob:  0.638517, 0.335938 (0.701 sec)
193.18... logprob:  0.638234, 0.335938 (0.671 sec)
193.19... logprob:  0.632869, 0.328125 (0.672 sec)
193.20... logprob:  0.648638, 0.351562 (0.671 sec)
193.21... logprob:  0.643405, 0.343750 (0.673 sec)
193.22... logprob:  0.628733, 0.320312 (0.673 sec)
193.23... logprob:  0.624250, 0.312500 (0.670 sec)
193.24... logprob:  0.581269, 0.242188 (0.674 sec)
193.25... logprob:  0.628975, 0.320312 (0.671 sec)
193.26... logprob:  0.672945, 0.390625 (0.668 sec)
193.27... logprob:  0.628614, 0.320312 (0.669 sec)
194.1... logprob:  0.678457, 0.398438 (0.670 sec)
194.2... logprob:  0.598344, 0.273438 (0.669 sec)
194.3... logprob:  0.653583, 0.359375 (0.670 sec)
194.4... logprob:  0.597389, 0.273438 (0.667 sec)
194.5... logprob:  0.591287, 0.265625 (0.669 sec)
194.6... logprob:  0.611320, 0.296875 (0.670 sec)
194.7... logprob:  0.643990, 0.343750 (0.669 sec)
194.8... logprob:  0.604204, 0.289062 (0.670 sec)
194.9... logprob:  0.638896, 0.335938 (0.671 sec)
194.10... logprob:  0.596859, 0.281250 (0.669 sec)
194.11... logprob:  0.639679, 0.335938 (0.674 sec)
194.12... logprob:  0.722666, 0.437500 (0.672 sec)
194.13... logprob:  0.658987, 0.359375 (0.700 sec)
194.14... logprob:  0.664522, 0.367188 (0.698 sec)
194.15... logprob:  0.687777, 0.398438 (0.673 sec)
194.16... logprob:  0.627057, 0.320312 (0.674 sec)
194.17... logprob:  0.638517, 0.335938 (0.672 sec)
194.18... logprob:  0.638234, 0.335938 (0.675 sec)
194.19... logprob:  0.632867, 0.328125 (0.674 sec)
194.20... logprob:  0.648640, 0.351562 (0.672 sec)
194.21... logprob:  0.643405, 0.343750 (0.672 sec)
194.22... logprob:  0.628725, 0.320312 (0.676 sec)
194.23... logprob:  0.624239, 0.312500 (0.676 sec)
194.24... logprob:  0.581238, 0.242188 (0.678 sec)
194.25... logprob:  0.628967, 0.320312 (0.673 sec)
194.26... logprob:  0.672955, 0.390625 (0.671 sec)
194.27... logprob:  0.628609, 0.320312 (0.669 sec)
195.1... logprob:  0.678466, 0.398438 (0.670 sec)
195.2... logprob:  0.598334, 0.273438 (0.673 sec)
195.3... logprob:  0.653584, 0.359375 (0.670 sec)
195.4... logprob:  0.597385, 0.273438 (0.668 sec)
195.5... logprob:  0.591287, 0.265625 (0.671 sec)
195.6... logprob:  0.611322, 0.296875 (0.668 sec)
195.7... logprob:  0.643989, 0.343750 (0.670 sec)
195.8... logprob:  0.604211, 0.289062 (0.670 sec)
195.9... logprob:  0.638892, 0.335938 (0.670 sec)
195.10... logprob:  0.596868, 0.281250 (0.670 sec)
195.11... logprob:  0.639671, 0.335938 (0.667 sec)
195.12... logprob:  0.722622, 0.437500 (0.676 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.658937, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958724e-03 [6.630163e-09] 
Layer 'conv1' biases: 2.514850e-07 [8.090429e-11] 
Layer 'conv2' weights[0]: 7.946116e-03 [5.146954e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.514167e-10] 
Layer 'conv3' weights[0]: 7.944317e-03 [4.556981e-09] 
Layer 'conv3' biases: 2.263748e-06 [9.433869e-10] 
Layer 'conv4' weights[0]: 7.976815e-03 [4.466233e-09] 
Layer 'conv4' biases: 1.000001e+00 [4.237129e-09] 
Layer 'conv5' weights[0]: 7.976209e-03 [2.646290e-08] 
Layer 'conv5' biases: 1.000004e+00 [2.823653e-08] 
Layer 'fc6' weights[0]: 7.572645e-03 [4.801638e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.744838e-09] 
Layer 'fc7' weights[0]: 7.651342e-03 [6.002549e-08] 
Layer 'fc7' biases: 9.998589e-01 [3.799609e-08] 
Layer 'fc8' weights[0]: 7.117393e-04 [2.162632e-06] 
Layer 'fc8' biases: 9.302875e-02 [1.465443e-05] 
Train error last 27 batches: 0.636347
-------------------------------------------------------
Not saving because 0.658937 > 0.627146 (160.7: -0.00%)
======================================================= (1.793 sec)
195.13... logprob:  0.658971, 0.359375 (0.672 sec)
195.14... logprob:  0.664507, 0.367188 (0.670 sec)
195.15... logprob:  0.687763, 0.398438 (0.673 sec)
195.16... logprob:  0.627056, 0.320312 (0.671 sec)
195.17... logprob:  0.638517, 0.335938 (0.670 sec)
195.18... logprob:  0.638234, 0.335938 (0.672 sec)
195.19... logprob:  0.632866, 0.328125 (0.669 sec)
195.20... logprob:  0.648642, 0.351562 (0.671 sec)
195.21... logprob:  0.643404, 0.343750 (0.669 sec)
195.22... logprob:  0.628718, 0.320312 (0.674 sec)
195.23... logprob:  0.624229, 0.312500 (0.676 sec)
195.24... logprob:  0.581208, 0.242188 (0.674 sec)
195.25... logprob:  0.628960, 0.320312 (0.671 sec)
195.26... logprob:  0.672964, 0.390625 (0.673 sec)
195.27... logprob:  0.628604, 0.320312 (0.674 sec)
196.1... logprob:  0.678474, 0.398438 (0.674 sec)
196.2... logprob:  0.598324, 0.273438 (0.679 sec)
196.3... logprob:  0.653585, 0.359375 (0.687 sec)
196.4... logprob:  0.597381, 0.273438 (0.675 sec)
196.5... logprob:  0.591286, 0.265625 (0.674 sec)
196.6... logprob:  0.611323, 0.296875 (0.676 sec)
196.7... logprob:  0.643986, 0.343750 (0.676 sec)
196.8... logprob:  0.604216, 0.289062 (0.683 sec)
196.9... logprob:  0.638889, 0.335938 (0.679 sec)
196.10... logprob:  0.596877, 0.281250 (0.676 sec)
196.11... logprob:  0.639663, 0.335938 (0.675 sec)
196.12... logprob:  0.722582, 0.437500 (0.676 sec)
196.13... logprob:  0.658959, 0.359375 (0.676 sec)
196.14... logprob:  0.664496, 0.367188 (0.673 sec)
196.15... logprob:  0.687751, 0.398438 (0.676 sec)
196.16... logprob:  0.627056, 0.320312 (0.672 sec)
196.17... logprob:  0.638518, 0.335938 (0.675 sec)
196.18... logprob:  0.638234, 0.335938 (0.670 sec)
196.19... logprob:  0.632864, 0.328125 (0.669 sec)
196.20... logprob:  0.648643, 0.351562 (0.680 sec)
196.21... logprob:  0.643404, 0.343750 (0.682 sec)
196.22... logprob:  0.628710, 0.320312 (0.671 sec)
196.23... logprob:  0.624219, 0.312500 (0.670 sec)
196.24... logprob:  0.581177, 0.242188 (0.674 sec)
196.25... logprob:  0.628953, 0.320312 (0.674 sec)
196.26... logprob:  0.672972, 0.390625 (0.674 sec)
196.27... logprob:  0.628599, 0.320312 (0.677 sec)
197.1... logprob:  0.678481, 0.398438 (0.668 sec)
197.2... logprob:  0.598316, 0.273438 (0.673 sec)
197.3... logprob:  0.653586, 0.359375 (0.669 sec)
197.4... logprob:  0.597377, 0.273438 (0.678 sec)
197.5... logprob:  0.591286, 0.265625 (0.676 sec)
197.6... logprob:  0.611326, 0.296875 (0.675 sec)
197.7... logprob:  0.643984, 0.343750 (0.676 sec)
197.8... logprob:  0.604223, 0.289062 (0.673 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627114, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958536e-03 [6.967575e-09] 
Layer 'conv1' biases: 2.545978e-07 [1.400817e-10] 
Layer 'conv2' weights[0]: 7.945929e-03 [6.167091e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.303044e-10] 
Layer 'conv3' weights[0]: 7.944106e-03 [6.117773e-09] 
Layer 'conv3' biases: 2.288863e-06 [2.294541e-09] 
Layer 'conv4' weights[0]: 7.976624e-03 [6.480436e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.183507e-08] 
Layer 'conv5' weights[0]: 7.976021e-03 [1.379222e-07] 
Layer 'conv5' biases: 1.000005e+00 [1.492578e-07] 
Layer 'fc6' weights[0]: 7.572434e-03 [1.424054e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.375381e-08] 
Layer 'fc7' weights[0]: 7.649408e-03 [1.922424e-07] 
Layer 'fc7' biases: 9.998585e-01 [1.787788e-07] 
Layer 'fc8' weights[0]: 6.892745e-04 [1.049944e-05] 
Layer 'fc8' biases: 9.353478e-02 [1.857883e-04] 
Train error last 27 batches: 0.636339
-------------------------------------------------------
Saved checkpoint to /homes/ad6813/Git/pipe-classification/models/scraping_peeling/net_0/saves/ConvNet__2014-07-08_14.54.04
======================================================= (7.482 sec)
197.9... logprob:  0.638885, 0.335938 (0.676 sec)
197.10... logprob:  0.596886, 0.281250 (0.678 sec)
197.11... logprob:  0.639655, 0.335938 (0.676 sec)
197.12... logprob:  0.722540, 0.437500 (0.679 sec)
197.13... logprob:  0.658943, 0.359375 (0.678 sec)
197.14... logprob:  0.664482, 0.367188 (0.679 sec)
197.15... logprob:  0.687737, 0.398438 (0.679 sec)
197.16... logprob:  0.627056, 0.320312 (0.682 sec)
197.17... logprob:  0.638518, 0.335938 (0.680 sec)
197.18... logprob:  0.638234, 0.335938 (0.686 sec)
197.19... logprob:  0.632862, 0.328125 (0.678 sec)
197.20... logprob:  0.648645, 0.351562 (0.762 sec)
197.21... logprob:  0.643404, 0.343750 (0.679 sec)
197.22... logprob:  0.628703, 0.320312 (0.677 sec)
197.23... logprob:  0.624209, 0.312500 (0.677 sec)
197.24... logprob:  0.581148, 0.242188 (0.681 sec)
197.25... logprob:  0.628945, 0.320312 (0.678 sec)
197.26... logprob:  0.672981, 0.390625 (0.681 sec)
197.27... logprob:  0.628593, 0.320312 (0.680 sec)
198.1... logprob:  0.678489, 0.398438 (0.679 sec)
198.2... logprob:  0.598306, 0.273438 (0.682 sec)
198.3... logprob:  0.653588, 0.359375 (0.714 sec)
198.4... logprob:  0.597373, 0.273438 (0.672 sec)
198.5... logprob:  0.591286, 0.265625 (0.675 sec)
198.6... logprob:  0.611327, 0.296875 (0.674 sec)
198.7... logprob:  0.643982, 0.343750 (0.668 sec)
198.8... logprob:  0.604228, 0.289062 (0.668 sec)
198.9... logprob:  0.638881, 0.335938 (0.670 sec)
198.10... logprob:  0.596894, 0.281250 (0.673 sec)
198.11... logprob:  0.639647, 0.335938 (0.669 sec)
198.12... logprob:  0.722500, 0.437500 (0.668 sec)
198.13... logprob:  0.658930, 0.359375 (0.670 sec)
198.14... logprob:  0.664470, 0.367188 (0.668 sec)
198.15... logprob:  0.687725, 0.398438 (0.667 sec)
198.16... logprob:  0.627056, 0.320312 (0.669 sec)
198.17... logprob:  0.638518, 0.335938 (0.677 sec)
198.18... logprob:  0.638234, 0.335938 (0.676 sec)
198.19... logprob:  0.632861, 0.328125 (0.677 sec)
198.20... logprob:  0.648647, 0.351562 (0.677 sec)
198.21... logprob:  0.643403, 0.343750 (0.677 sec)
198.22... logprob:  0.628696, 0.320312 (0.677 sec)
198.23... logprob:  0.624198, 0.312500 (0.678 sec)
198.24... logprob:  0.581118, 0.242188 (0.674 sec)
198.25... logprob:  0.628937, 0.320312 (0.674 sec)
198.26... logprob:  0.672990, 0.390625 (0.676 sec)
198.27... logprob:  0.628588, 0.320312 (0.681 sec)
199.1... logprob:  0.678496, 0.398438 (0.680 sec)
199.2... logprob:  0.598297, 0.273438 (0.684 sec)
199.3... logprob:  0.653589, 0.359375 (0.679 sec)
199.4... logprob:  0.597370, 0.273438 (0.675 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633059, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958334e-03 [6.616787e-09] 
Layer 'conv1' biases: 2.578583e-07 [1.013292e-10] 
Layer 'conv2' weights[0]: 7.945740e-03 [5.305058e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.327255e-10] 
Layer 'conv3' weights[0]: 7.943909e-03 [5.181626e-09] 
Layer 'conv3' biases: 2.315668e-06 [1.458014e-09] 
Layer 'conv4' weights[0]: 7.976427e-03 [5.315155e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.311446e-08] 
Layer 'conv5' weights[0]: 7.975857e-03 [8.278344e-08] 
Layer 'conv5' biases: 1.000005e+00 [8.956599e-08] 
Layer 'fc6' weights[0]: 7.572231e-03 [9.293057e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.271538e-09] 
Layer 'fc7' weights[0]: 7.647438e-03 [1.242977e-07] 
Layer 'fc7' biases: 9.998581e-01 [1.072142e-07] 
Layer 'fc8' weights[0]: 6.516575e-04 [6.265004e-06] 
Layer 'fc8' biases: 9.373735e-02 [1.200475e-04] 
Train error last 27 batches: 0.636328
-------------------------------------------------------
Not saving because 0.633059 > 0.627114 (197.8: -0.01%)
======================================================= (1.731 sec)
199.5... logprob:  0.591286, 0.265625 (0.671 sec)
199.6... logprob:  0.611329, 0.296875 (0.667 sec)
199.7... logprob:  0.643981, 0.343750 (0.668 sec)
199.8... logprob:  0.604235, 0.289062 (0.668 sec)
199.9... logprob:  0.638877, 0.335938 (0.668 sec)
199.10... logprob:  0.596904, 0.281250 (0.668 sec)
199.11... logprob:  0.639639, 0.335938 (0.668 sec)
199.12... logprob:  0.722456, 0.437500 (0.677 sec)
199.13... logprob:  0.658915, 0.359375 (0.675 sec)
199.14... logprob:  0.664456, 0.367188 (0.679 sec)
199.15... logprob:  0.687711, 0.398438 (0.679 sec)
199.16... logprob:  0.627056, 0.320312 (0.679 sec)
199.17... logprob:  0.638518, 0.335938 (0.677 sec)
199.18... logprob:  0.638233, 0.335938 (0.678 sec)
199.19... logprob:  0.632859, 0.328125 (0.676 sec)
199.20... logprob:  0.648649, 0.351562 (0.677 sec)
199.21... logprob:  0.643403, 0.343750 (0.676 sec)
199.22... logprob:  0.628689, 0.320312 (0.680 sec)
199.23... logprob:  0.624188, 0.312500 (0.678 sec)
199.24... logprob:  0.581088, 0.242188 (0.674 sec)
199.25... logprob:  0.628930, 0.320312 (0.676 sec)
199.26... logprob:  0.672998, 0.390625 (0.678 sec)
199.27... logprob:  0.628583, 0.320312 (0.676 sec)
200.1... logprob:  0.678505, 0.398438 (0.677 sec)
200.2... logprob:  0.598286, 0.273438 (0.677 sec)
200.3... logprob:  0.653590, 0.359375 (0.677 sec)
200.4... logprob:  0.597365, 0.273438 (0.676 sec)
200.5... logprob:  0.591284, 0.265625 (0.676 sec)
200.6... logprob:  0.611331, 0.296875 (0.676 sec)
200.7... logprob:  0.643979, 0.343750 (0.675 sec)
200.8... logprob:  0.604240, 0.289062 (0.676 sec)
200.9... logprob:  0.638874, 0.335938 (0.682 sec)
200.10... logprob:  0.596912, 0.281250 (0.673 sec)
200.11... logprob:  0.639632, 0.335938 (0.675 sec)
200.12... logprob:  0.722419, 0.437500 (0.674 sec)
200.13... logprob:  0.658902, 0.359375 (0.669 sec)
200.14... logprob:  0.664445, 0.367188 (0.669 sec)
200.15... logprob:  0.687700, 0.398438 (0.670 sec)
200.16... logprob:  0.627056, 0.320312 (0.670 sec)
200.17... logprob:  0.638519, 0.335938 (0.667 sec)
200.18... logprob:  0.638233, 0.335938 (0.669 sec)
200.19... logprob:  0.632857, 0.328125 (0.669 sec)
200.20... logprob:  0.648651, 0.351562 (0.670 sec)
200.21... logprob:  0.643402, 0.343750 (0.668 sec)
200.22... logprob:  0.628681, 0.320312 (0.669 sec)
200.23... logprob:  0.624177, 0.312500 (0.669 sec)
200.24... logprob:  0.581057, 0.242188 (0.668 sec)
200.25... logprob:  0.628923, 0.320312 (0.671 sec)
200.26... logprob:  0.673007, 0.390625 (0.668 sec)
200.27... logprob:  0.628578, 0.320312 (0.668 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.683530, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958126e-03 [6.338406e-09] 
Layer 'conv1' biases: 2.609494e-07 [6.662394e-11] 
Layer 'conv2' weights[0]: 7.945540e-03 [4.766403e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.967118e-10] 
Layer 'conv3' weights[0]: 7.943719e-03 [4.556169e-09] 
Layer 'conv3' biases: 2.340076e-06 [8.793255e-10] 
Layer 'conv4' weights[0]: 7.976227e-03 [4.584486e-09] 
Layer 'conv4' biases: 1.000001e+00 [6.796701e-09] 
Layer 'conv5' weights[0]: 7.975665e-03 [4.276634e-08] 
Layer 'conv5' biases: 1.000005e+00 [4.618208e-08] 
Layer 'fc6' weights[0]: 7.572020e-03 [5.777574e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.236902e-09] 
Layer 'fc7' weights[0]: 7.645444e-03 [7.497075e-08] 
Layer 'fc7' biases: 9.998579e-01 [5.486651e-08] 
Layer 'fc8' weights[0]: 6.394945e-04 [3.175893e-06] 
Layer 'fc8' biases: 9.440255e-02 [7.164699e-05] 
Train error last 27 batches: 0.636319
-------------------------------------------------------
Not saving because 0.683530 > 0.627114 (197.8: -0.01%)
======================================================= (1.751 sec)
201.1... logprob:  0.678512, 0.398438 (0.669 sec)
201.2... logprob:  0.598279, 0.273438 (0.673 sec)
201.3... logprob:  0.653591, 0.359375 (0.668 sec)
201.4... logprob:  0.597363, 0.273438 (0.667 sec)
201.5... logprob:  0.591286, 0.265625 (0.667 sec)
201.6... logprob:  0.611334, 0.296875 (0.667 sec)
201.7... logprob:  0.643976, 0.343750 (0.678 sec)
201.8... logprob:  0.604248, 0.289062 (0.675 sec)
201.9... logprob:  0.638869, 0.335938 (0.680 sec)
201.10... logprob:  0.596923, 0.281250 (0.681 sec)
201.11... logprob:  0.639623, 0.335938 (0.680 sec)
201.12... logprob:  0.722370, 0.437500 (0.690 sec)
201.13... logprob:  0.658885, 0.359375 (0.680 sec)
201.14... logprob:  0.664429, 0.367188 (0.679 sec)
201.15... logprob:  0.687683, 0.398438 (0.681 sec)
201.16... logprob:  0.627056, 0.320312 (0.680 sec)
201.17... logprob:  0.638518, 0.335938 (0.679 sec)
201.18... logprob:  0.638233, 0.335938 (0.678 sec)
201.19... logprob:  0.632856, 0.328125 (0.681 sec)
201.20... logprob:  0.648653, 0.351562 (0.679 sec)
201.21... logprob:  0.643402, 0.343750 (0.682 sec)
201.22... logprob:  0.628675, 0.320312 (0.679 sec)
201.23... logprob:  0.624167, 0.312500 (0.680 sec)
201.24... logprob:  0.581028, 0.242188 (0.679 sec)
201.25... logprob:  0.628915, 0.320312 (0.681 sec)
201.26... logprob:  0.673016, 0.390625 (0.679 sec)
201.27... logprob:  0.628572, 0.320312 (0.679 sec)
202.1... logprob:  0.678520, 0.398438 (0.675 sec)
202.2... logprob:  0.598267, 0.273438 (0.676 sec)
202.3... logprob:  0.653592, 0.359375 (0.679 sec)
202.4... logprob:  0.597356, 0.273438 (0.677 sec)
202.5... logprob:  0.591282, 0.265625 (0.679 sec)
202.6... logprob:  0.611335, 0.296875 (0.679 sec)
202.7... logprob:  0.643975, 0.343750 (0.680 sec)
202.8... logprob:  0.604251, 0.289062 (0.678 sec)
202.9... logprob:  0.638866, 0.335938 (0.679 sec)
202.10... logprob:  0.596929, 0.281250 (0.676 sec)
202.11... logprob:  0.639617, 0.335938 (0.677 sec)
202.12... logprob:  0.722338, 0.437500 (0.676 sec)
202.13... logprob:  0.658873, 0.359375 (0.676 sec)
202.14... logprob:  0.664419, 0.367188 (0.677 sec)
202.15... logprob:  0.687673, 0.398438 (0.678 sec)
202.16... logprob:  0.627056, 0.320312 (0.674 sec)
202.17... logprob:  0.638519, 0.335938 (0.677 sec)
202.18... logprob:  0.638233, 0.335938 (0.676 sec)
202.19... logprob:  0.632854, 0.328125 (0.675 sec)
202.20... logprob:  0.648654, 0.351562 (0.678 sec)
202.21... logprob:  0.643402, 0.343750 (0.679 sec)
202.22... logprob:  0.628668, 0.320312 (0.683 sec)
202.23... logprob:  0.624158, 0.312500 (0.681 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633975, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957932e-03 [6.074974e-09] 
Layer 'conv1' biases: 2.640501e-07 [9.190399e-11] 
Layer 'conv2' weights[0]: 7.945356e-03 [5.049380e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.588267e-10] 
Layer 'conv3' weights[0]: 7.943525e-03 [4.589219e-09] 
Layer 'conv3' biases: 2.364689e-06 [9.263586e-10] 
Layer 'conv4' weights[0]: 7.976026e-03 [4.498168e-09] 
Layer 'conv4' biases: 1.000001e+00 [5.264599e-09] 
Layer 'conv5' weights[0]: 7.975474e-03 [3.318467e-08] 
Layer 'conv5' biases: 1.000005e+00 [3.549100e-08] 
Layer 'fc6' weights[0]: 7.571829e-03 [5.173583e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.397312e-09] 
Layer 'fc7' weights[0]: 7.643518e-03 [6.635241e-08] 
Layer 'fc7' biases: 9.998575e-01 [4.574095e-08] 
Layer 'fc8' weights[0]: 6.268918e-04 [2.630532e-06] 
Layer 'fc8' biases: 9.502451e-02 [2.727867e-05] 
Train error last 27 batches: 0.636310
-------------------------------------------------------
Not saving because 0.633975 > 0.627114 (197.8: -0.01%)
======================================================= (1.801 sec)
202.24... logprob:  0.581001, 0.242188 (0.676 sec)
202.25... logprob:  0.628908, 0.320312 (0.679 sec)
202.26... logprob:  0.673024, 0.390625 (0.679 sec)
202.27... logprob:  0.628568, 0.320312 (0.677 sec)
203.1... logprob:  0.678527, 0.398438 (0.677 sec)
203.2... logprob:  0.598260, 0.273438 (0.679 sec)
203.3... logprob:  0.653593, 0.359375 (0.679 sec)
203.4... logprob:  0.597354, 0.273438 (0.675 sec)
203.5... logprob:  0.591284, 0.265625 (0.677 sec)
203.6... logprob:  0.611337, 0.296875 (0.677 sec)
203.7... logprob:  0.643973, 0.343750 (0.673 sec)
203.8... logprob:  0.604258, 0.289062 (0.677 sec)
203.9... logprob:  0.638862, 0.335938 (0.675 sec)
203.10... logprob:  0.596938, 0.281250 (0.676 sec)
203.11... logprob:  0.639609, 0.335938 (0.675 sec)
203.12... logprob:  0.722296, 0.437500 (0.676 sec)
203.13... logprob:  0.658859, 0.359375 (0.675 sec)
203.14... logprob:  0.664406, 0.367188 (0.674 sec)
203.15... logprob:  0.687660, 0.398438 (0.676 sec)
203.16... logprob:  0.627056, 0.320312 (0.680 sec)
203.17... logprob:  0.638519, 0.335938 (0.676 sec)
203.18... logprob:  0.638233, 0.335938 (0.677 sec)
203.19... logprob:  0.632852, 0.328125 (0.677 sec)
203.20... logprob:  0.648656, 0.351562 (0.676 sec)
203.21... logprob:  0.643401, 0.343750 (0.676 sec)
203.22... logprob:  0.628661, 0.320312 (0.675 sec)
203.23... logprob:  0.624147, 0.312500 (0.676 sec)
203.24... logprob:  0.580971, 0.242188 (0.676 sec)
203.25... logprob:  0.628901, 0.320312 (0.676 sec)
203.26... logprob:  0.673032, 0.390625 (0.676 sec)
203.27... logprob:  0.628562, 0.320312 (0.675 sec)
204.1... logprob:  0.678535, 0.398438 (0.676 sec)
204.2... logprob:  0.598249, 0.273438 (0.677 sec)
204.3... logprob:  0.653594, 0.359375 (0.675 sec)
204.4... logprob:  0.597349, 0.273438 (0.679 sec)
204.5... logprob:  0.591282, 0.265625 (0.679 sec)
204.6... logprob:  0.611338, 0.296875 (0.685 sec)
204.7... logprob:  0.643971, 0.343750 (0.675 sec)
204.8... logprob:  0.604263, 0.289062 (0.673 sec)
204.9... logprob:  0.638859, 0.335938 (0.678 sec)
204.10... logprob:  0.596947, 0.281250 (0.680 sec)
204.11... logprob:  0.639602, 0.335938 (0.679 sec)
204.12... logprob:  0.722256, 0.437500 (0.675 sec)
204.13... logprob:  0.658845, 0.359375 (0.676 sec)
204.14... logprob:  0.664393, 0.367188 (0.677 sec)
204.15... logprob:  0.687647, 0.398438 (0.676 sec)
204.16... logprob:  0.627056, 0.320312 (0.677 sec)
204.17... logprob:  0.638519, 0.335938 (0.677 sec)
204.18... logprob:  0.638233, 0.335938 (0.678 sec)
204.19... logprob:  0.632851, 0.328125 (0.674 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.628028, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957747e-03 [6.681412e-09] 
Layer 'conv1' biases: 2.669809e-07 [1.572154e-10] 
Layer 'conv2' weights[0]: 7.945155e-03 [6.597759e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.822357e-10] 
Layer 'conv3' weights[0]: 7.943317e-03 [5.863760e-09] 
Layer 'conv3' biases: 2.385802e-06 [2.216549e-09] 
Layer 'conv4' weights[0]: 7.975833e-03 [5.920456e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.727850e-08] 
Layer 'conv5' weights[0]: 7.975242e-03 [1.079365e-07] 
Layer 'conv5' biases: 1.000005e+00 [1.163958e-07] 
Layer 'fc6' weights[0]: 7.571634e-03 [1.161410e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.102329e-08] 
Layer 'fc7' weights[0]: 7.641582e-03 [1.586455e-07] 
Layer 'fc7' biases: 9.998577e-01 [1.453059e-07] 
Layer 'fc8' weights[0]: 6.465797e-04 [8.426043e-06] 
Layer 'fc8' biases: 9.628427e-02 [1.228196e-04] 
Train error last 27 batches: 0.636301
-------------------------------------------------------
Not saving because 0.628028 > 0.627114 (197.8: -0.01%)
======================================================= (1.724 sec)
204.20... logprob:  0.648658, 0.351562 (0.677 sec)
204.21... logprob:  0.643401, 0.343750 (0.678 sec)
204.22... logprob:  0.628654, 0.320312 (0.677 sec)
204.23... logprob:  0.624138, 0.312500 (0.673 sec)
204.24... logprob:  0.580942, 0.242188 (0.675 sec)
204.25... logprob:  0.628893, 0.320312 (0.677 sec)
204.26... logprob:  0.673042, 0.390625 (0.677 sec)
204.27... logprob:  0.628557, 0.320312 (0.676 sec)
205.1... logprob:  0.678542, 0.398438 (0.676 sec)
205.2... logprob:  0.598241, 0.273438 (0.677 sec)
205.3... logprob:  0.653596, 0.359375 (0.675 sec)
205.4... logprob:  0.597346, 0.273438 (0.680 sec)
205.5... logprob:  0.591282, 0.265625 (0.680 sec)
205.6... logprob:  0.611341, 0.296875 (0.682 sec)
205.7... logprob:  0.643969, 0.343750 (0.677 sec)
205.8... logprob:  0.604270, 0.289062 (0.678 sec)
205.9... logprob:  0.638855, 0.335938 (0.679 sec)
205.10... logprob:  0.596956, 0.281250 (0.678 sec)
205.11... logprob:  0.639594, 0.335938 (0.676 sec)
205.12... logprob:  0.722214, 0.437500 (0.676 sec)
205.13... logprob:  0.658831, 0.359375 (0.678 sec)
205.14... logprob:  0.664380, 0.367188 (0.681 sec)
205.15... logprob:  0.687633, 0.398438 (0.680 sec)
205.16... logprob:  0.627056, 0.320312 (0.675 sec)
205.17... logprob:  0.638519, 0.335938 (0.680 sec)
205.18... logprob:  0.638233, 0.335938 (0.679 sec)
205.19... logprob:  0.632849, 0.328125 (0.681 sec)
205.20... logprob:  0.648659, 0.351562 (0.681 sec)
205.21... logprob:  0.643400, 0.343750 (0.680 sec)
205.22... logprob:  0.628647, 0.320312 (0.675 sec)
205.23... logprob:  0.624128, 0.312500 (0.682 sec)
205.24... logprob:  0.580913, 0.242188 (0.683 sec)
205.25... logprob:  0.628886, 0.320312 (0.672 sec)
205.26... logprob:  0.673049, 0.390625 (0.674 sec)
205.27... logprob:  0.628552, 0.320312 (0.673 sec)
206.1... logprob:  0.678550, 0.398438 (0.671 sec)
206.2... logprob:  0.598230, 0.273438 (0.677 sec)
206.3... logprob:  0.653597, 0.359375 (0.674 sec)
206.4... logprob:  0.597341, 0.273438 (0.681 sec)
206.5... logprob:  0.591280, 0.265625 (0.679 sec)
206.6... logprob:  0.611342, 0.296875 (0.677 sec)
206.7... logprob:  0.643968, 0.343750 (0.677 sec)
206.8... logprob:  0.604274, 0.289062 (0.677 sec)
206.9... logprob:  0.638851, 0.335938 (0.675 sec)
206.10... logprob:  0.596964, 0.281250 (0.679 sec)
206.11... logprob:  0.639587, 0.335938 (0.677 sec)
206.12... logprob:  0.722177, 0.437500 (0.674 sec)
206.13... logprob:  0.658818, 0.359375 (0.677 sec)
206.14... logprob:  0.664369, 0.367188 (0.675 sec)
206.15... logprob:  0.687623, 0.398438 (0.678 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.656239, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957549e-03 [7.340776e-09] 
Layer 'conv1' biases: 2.698298e-07 [2.138127e-10] 
Layer 'conv2' weights[0]: 7.944954e-03 [7.923056e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.102955e-09] 
Layer 'conv3' weights[0]: 7.943124e-03 [6.979348e-09] 
Layer 'conv3' biases: 2.405533e-06 [3.154451e-09] 
Layer 'conv4' weights[0]: 7.975631e-03 [7.194910e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.594901e-08] 
Layer 'conv5' weights[0]: 7.975031e-03 [1.619209e-07] 
Layer 'conv5' biases: 1.000004e+00 [1.747619e-07] 
Layer 'fc6' weights[0]: 7.571448e-03 [1.686017e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.646590e-08] 
Layer 'fc7' weights[0]: 7.639631e-03 [2.278693e-07] 
Layer 'fc7' biases: 9.998582e-01 [2.153617e-07] 
Layer 'fc8' weights[0]: 6.814272e-04 [1.255144e-05] 
Layer 'fc8' biases: 9.779830e-02 [1.835132e-04] 
Train error last 27 batches: 0.636291
-------------------------------------------------------
Not saving because 0.656239 > 0.627114 (197.8: -0.01%)
======================================================= (1.721 sec)
206.16... logprob:  0.627056, 0.320312 (0.676 sec)
206.17... logprob:  0.638519, 0.335938 (0.675 sec)
206.18... logprob:  0.638233, 0.335938 (0.676 sec)
206.19... logprob:  0.632848, 0.328125 (0.675 sec)
206.20... logprob:  0.648662, 0.351562 (0.678 sec)
206.21... logprob:  0.643400, 0.343750 (0.679 sec)
206.22... logprob:  0.628640, 0.320312 (0.677 sec)
206.23... logprob:  0.624118, 0.312500 (0.679 sec)
206.24... logprob:  0.580884, 0.242188 (0.674 sec)
206.25... logprob:  0.628879, 0.320312 (0.668 sec)
206.26... logprob:  0.673058, 0.390625 (0.678 sec)
206.27... logprob:  0.628547, 0.320312 (0.676 sec)
207.1... logprob:  0.678558, 0.398438 (0.677 sec)
207.2... logprob:  0.598223, 0.273438 (0.677 sec)
207.3... logprob:  0.653598, 0.359375 (0.675 sec)
207.4... logprob:  0.597338, 0.273438 (0.677 sec)
207.5... logprob:  0.591281, 0.265625 (0.675 sec)
207.6... logprob:  0.611344, 0.296875 (0.677 sec)
207.7... logprob:  0.643966, 0.343750 (0.679 sec)
207.8... logprob:  0.604282, 0.289062 (0.679 sec)
207.9... logprob:  0.638848, 0.335938 (0.677 sec)
207.10... logprob:  0.596974, 0.281250 (0.680 sec)
207.11... logprob:  0.639579, 0.335938 (0.679 sec)
207.12... logprob:  0.722132, 0.437500 (0.679 sec)
207.13... logprob:  0.658803, 0.359375 (0.679 sec)
207.14... logprob:  0.664354, 0.367188 (0.678 sec)
207.15... logprob:  0.687607, 0.398438 (0.681 sec)
207.16... logprob:  0.627056, 0.320312 (0.679 sec)
207.17... logprob:  0.638520, 0.335938 (0.675 sec)
207.18... logprob:  0.638233, 0.335938 (0.677 sec)
207.19... logprob:  0.632846, 0.328125 (0.678 sec)
207.20... logprob:  0.648664, 0.351562 (0.679 sec)
207.21... logprob:  0.643400, 0.343750 (0.676 sec)
207.22... logprob:  0.628633, 0.320312 (0.679 sec)
207.23... logprob:  0.624108, 0.312500 (0.677 sec)
207.24... logprob:  0.580854, 0.242188 (0.670 sec)
207.25... logprob:  0.628872, 0.320312 (0.675 sec)
207.26... logprob:  0.673068, 0.390625 (0.673 sec)
207.27... logprob:  0.628543, 0.320312 (0.676 sec)
208.1... logprob:  0.678567, 0.398438 (0.669 sec)
208.2... logprob:  0.598211, 0.273438 (0.674 sec)
208.3... logprob:  0.653600, 0.359375 (0.672 sec)
208.4... logprob:  0.597333, 0.273438 (0.668 sec)
208.5... logprob:  0.591279, 0.265625 (0.673 sec)
208.6... logprob:  0.611345, 0.296875 (0.671 sec)
208.7... logprob:  0.643964, 0.343750 (0.671 sec)
208.8... logprob:  0.604287, 0.289062 (0.671 sec)
208.9... logprob:  0.638844, 0.335938 (0.672 sec)
208.10... logprob:  0.596982, 0.281250 (0.671 sec)
208.11... logprob:  0.639572, 0.335938 (0.670 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627457, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957363e-03 [6.564952e-09] 
Layer 'conv1' biases: 2.727649e-07 [1.013383e-10] 
Layer 'conv2' weights[0]: 7.944764e-03 [5.395308e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.846847e-10] 
Layer 'conv3' weights[0]: 7.942931e-03 [5.335733e-09] 
Layer 'conv3' biases: 2.426189e-06 [1.608328e-09] 
Layer 'conv4' weights[0]: 7.975423e-03 [5.560490e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.505072e-08] 
Layer 'conv5' weights[0]: 7.974837e-03 [9.473113e-08] 
Layer 'conv5' biases: 1.000004e+00 [1.024620e-07] 
Layer 'fc6' weights[0]: 7.571242e-03 [1.030812e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.473200e-09] 
Layer 'fc7' weights[0]: 7.637664e-03 [1.368615e-07] 
Layer 'fc7' biases: 9.998584e-01 [1.211881e-07] 
Layer 'fc8' weights[0]: 7.051533e-04 [7.117072e-06] 
Layer 'fc8' biases: 9.908653e-02 [1.294747e-04] 
Train error last 27 batches: 0.636284
-------------------------------------------------------
Not saving because 0.627457 > 0.627114 (197.8: -0.01%)
======================================================= (1.726 sec)
208.12... logprob:  0.722095, 0.437500 (0.680 sec)
208.13... logprob:  0.658790, 0.359375 (0.688 sec)
208.14... logprob:  0.664343, 0.367188 (0.684 sec)
208.15... logprob:  0.687595, 0.398438 (0.684 sec)
208.16... logprob:  0.627056, 0.320312 (0.682 sec)
208.17... logprob:  0.638520, 0.335938 (0.680 sec)
208.18... logprob:  0.638233, 0.335938 (0.676 sec)
208.19... logprob:  0.632845, 0.328125 (0.675 sec)
208.20... logprob:  0.648665, 0.351562 (0.678 sec)
208.21... logprob:  0.643400, 0.343750 (0.675 sec)
208.22... logprob:  0.628627, 0.320312 (0.679 sec)
208.23... logprob:  0.624098, 0.312500 (0.679 sec)
208.24... logprob:  0.580827, 0.242188 (0.674 sec)
208.25... logprob:  0.628865, 0.320312 (0.676 sec)
208.26... logprob:  0.673076, 0.390625 (0.677 sec)
208.27... logprob:  0.628537, 0.320312 (0.679 sec)
209.1... logprob:  0.678573, 0.398438 (0.673 sec)
209.2... logprob:  0.598203, 0.273438 (0.676 sec)
209.3... logprob:  0.653601, 0.359375 (0.675 sec)
209.4... logprob:  0.597329, 0.273438 (0.670 sec)
209.5... logprob:  0.591279, 0.265625 (0.671 sec)
209.6... logprob:  0.611347, 0.296875 (0.669 sec)
209.7... logprob:  0.643962, 0.343750 (0.669 sec)
209.8... logprob:  0.604292, 0.289062 (0.670 sec)
209.9... logprob:  0.638841, 0.335938 (0.672 sec)
209.10... logprob:  0.596990, 0.281250 (0.675 sec)
209.11... logprob:  0.639565, 0.335938 (0.677 sec)
209.12... logprob:  0.722057, 0.437500 (0.691 sec)
209.13... logprob:  0.658777, 0.359375 (0.678 sec)
209.14... logprob:  0.664331, 0.367188 (0.679 sec)
209.15... logprob:  0.687583, 0.398438 (0.679 sec)
209.16... logprob:  0.627056, 0.320312 (0.679 sec)
209.17... logprob:  0.638520, 0.335938 (0.675 sec)
209.18... logprob:  0.638232, 0.335938 (0.678 sec)
209.19... logprob:  0.632843, 0.328125 (0.676 sec)
209.20... logprob:  0.648667, 0.351562 (0.676 sec)
209.21... logprob:  0.643399, 0.343750 (0.678 sec)
209.22... logprob:  0.628620, 0.320312 (0.678 sec)
209.23... logprob:  0.624089, 0.312500 (0.678 sec)
209.24... logprob:  0.580799, 0.242188 (0.677 sec)
209.25... logprob:  0.628858, 0.320312 (0.682 sec)
209.26... logprob:  0.673084, 0.390625 (0.678 sec)
209.27... logprob:  0.628533, 0.320312 (0.677 sec)
210.1... logprob:  0.678580, 0.398438 (0.678 sec)
210.2... logprob:  0.598194, 0.273438 (0.685 sec)
210.3... logprob:  0.653601, 0.359375 (0.677 sec)
210.4... logprob:  0.597325, 0.273438 (0.677 sec)
210.5... logprob:  0.591278, 0.265625 (0.677 sec)
210.6... logprob:  0.611349, 0.296875 (0.679 sec)
210.7... logprob:  0.643961, 0.343750 (0.676 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.632803, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957162e-03 [6.682164e-09] 
Layer 'conv1' biases: 2.761427e-07 [1.310578e-10] 
Layer 'conv2' weights[0]: 7.944563e-03 [5.802305e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.314208e-10] 
Layer 'conv3' weights[0]: 7.942720e-03 [5.737649e-09] 
Layer 'conv3' biases: 2.452906e-06 [1.991337e-09] 
Layer 'conv4' weights[0]: 7.975225e-03 [6.013944e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.882667e-08] 
Layer 'conv5' weights[0]: 7.974645e-03 [1.169485e-07] 
Layer 'conv5' biases: 1.000005e+00 [1.264922e-07] 
Layer 'fc6' weights[0]: 7.571065e-03 [1.240687e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.184614e-08] 
Layer 'fc7' weights[0]: 7.635709e-03 [1.668100e-07] 
Layer 'fc7' biases: 9.998579e-01 [1.529547e-07] 
Layer 'fc8' weights[0]: 6.721338e-04 [8.890055e-06] 
Layer 'fc8' biases: 9.936476e-02 [1.648332e-04] 
Train error last 27 batches: 0.636275
-------------------------------------------------------
Not saving because 0.632803 > 0.627114 (197.8: -0.01%)
======================================================= (1.716 sec)
210.8... logprob:  0.604297, 0.289062 (0.672 sec)
210.9... logprob:  0.638837, 0.335938 (0.673 sec)
210.10... logprob:  0.596999, 0.281250 (0.678 sec)
210.11... logprob:  0.639557, 0.335938 (0.676 sec)
210.12... logprob:  0.722018, 0.437500 (0.675 sec)
210.13... logprob:  0.658763, 0.359375 (0.674 sec)
210.14... logprob:  0.664318, 0.367188 (0.674 sec)
210.15... logprob:  0.687571, 0.398438 (0.671 sec)
210.16... logprob:  0.627056, 0.320312 (0.675 sec)
210.17... logprob:  0.638520, 0.335938 (0.685 sec)
210.18... logprob:  0.638233, 0.335938 (0.680 sec)
210.19... logprob:  0.632842, 0.328125 (0.681 sec)
210.20... logprob:  0.648668, 0.351562 (0.681 sec)
210.21... logprob:  0.643399, 0.343750 (0.687 sec)
210.22... logprob:  0.628614, 0.320312 (0.683 sec)
210.23... logprob:  0.624080, 0.312500 (0.687 sec)
210.24... logprob:  0.580771, 0.242188 (0.679 sec)
210.25... logprob:  0.628851, 0.320312 (0.678 sec)
210.26... logprob:  0.673092, 0.390625 (0.677 sec)
210.27... logprob:  0.628528, 0.320312 (0.671 sec)
211.1... logprob:  0.678588, 0.398438 (0.669 sec)
211.2... logprob:  0.598185, 0.273438 (0.671 sec)
211.3... logprob:  0.653603, 0.359375 (0.670 sec)
211.4... logprob:  0.597322, 0.273438 (0.668 sec)
211.5... logprob:  0.591277, 0.265625 (0.670 sec)
211.6... logprob:  0.611350, 0.296875 (0.670 sec)
211.7... logprob:  0.643959, 0.343750 (0.670 sec)
211.8... logprob:  0.604303, 0.289062 (0.678 sec)
211.9... logprob:  0.638834, 0.335938 (0.675 sec)
211.10... logprob:  0.597007, 0.281250 (0.677 sec)
211.11... logprob:  0.639551, 0.335938 (0.676 sec)
211.12... logprob:  0.721980, 0.437500 (0.674 sec)
211.13... logprob:  0.658750, 0.359375 (0.680 sec)
211.14... logprob:  0.664306, 0.367188 (0.667 sec)
211.15... logprob:  0.687558, 0.398438 (0.668 sec)
211.16... logprob:  0.627056, 0.320312 (0.669 sec)
211.17... logprob:  0.638520, 0.335938 (0.667 sec)
211.18... logprob:  0.638233, 0.335938 (0.672 sec)
211.19... logprob:  0.632840, 0.328125 (0.668 sec)
211.20... logprob:  0.648670, 0.351562 (0.668 sec)
211.21... logprob:  0.643399, 0.343750 (0.673 sec)
211.22... logprob:  0.628607, 0.320312 (0.670 sec)
211.23... logprob:  0.624070, 0.312500 (0.671 sec)
211.24... logprob:  0.580743, 0.242188 (0.677 sec)
211.25... logprob:  0.628844, 0.320312 (0.675 sec)
211.26... logprob:  0.673101, 0.390625 (0.675 sec)
211.27... logprob:  0.628523, 0.320312 (0.679 sec)
212.1... logprob:  0.678596, 0.398438 (0.667 sec)
212.2... logprob:  0.598176, 0.273438 (0.671 sec)
212.3... logprob:  0.653603, 0.359375 (0.670 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.684366, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956960e-03 [6.510041e-09] 
Layer 'conv1' biases: 2.795521e-07 [6.538885e-11] 
Layer 'conv2' weights[0]: 7.944357e-03 [4.818469e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.683660e-10] 
Layer 'conv3' weights[0]: 7.942521e-03 [4.510369e-09] 
Layer 'conv3' biases: 2.479562e-06 [7.735272e-10] 
Layer 'conv4' weights[0]: 7.975024e-03 [4.454692e-09] 
Layer 'conv4' biases: 1.000001e+00 [5.118214e-09] 
Layer 'conv5' weights[0]: 7.974467e-03 [3.264870e-08] 
Layer 'conv5' biases: 1.000005e+00 [3.505436e-08] 
Layer 'fc6' weights[0]: 7.570888e-03 [5.104012e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.236076e-09] 
Layer 'fc7' weights[0]: 7.633758e-03 [6.352071e-08] 
Layer 'fc7' biases: 9.998574e-01 [4.133018e-08] 
Layer 'fc8' weights[0]: 6.397172e-04 [2.389461e-06] 
Layer 'fc8' biases: 9.961608e-02 [5.406048e-05] 
Train error last 27 batches: 0.636266
-------------------------------------------------------
Not saving because 0.684366 > 0.627114 (197.8: -0.01%)
======================================================= (1.775 sec)
212.4... logprob:  0.597318, 0.273438 (0.686 sec)
212.5... logprob:  0.591276, 0.265625 (0.684 sec)
212.6... logprob:  0.611352, 0.296875 (0.703 sec)
212.7... logprob:  0.643957, 0.343750 (0.696 sec)
212.8... logprob:  0.604308, 0.289062 (0.691 sec)
212.9... logprob:  0.638831, 0.335938 (0.681 sec)
212.10... logprob:  0.597016, 0.281250 (0.681 sec)
212.11... logprob:  0.639543, 0.335938 (0.676 sec)
212.12... logprob:  0.721941, 0.437500 (0.681 sec)
212.13... logprob:  0.658736, 0.359375 (0.678 sec)
212.14... logprob:  0.664294, 0.367188 (0.682 sec)
212.15... logprob:  0.687545, 0.398438 (0.672 sec)
212.16... logprob:  0.627056, 0.320312 (0.671 sec)
212.17... logprob:  0.638520, 0.335938 (0.679 sec)
212.18... logprob:  0.638232, 0.335938 (0.677 sec)
212.19... logprob:  0.632838, 0.328125 (0.676 sec)
212.20... logprob:  0.648672, 0.351562 (0.677 sec)
212.21... logprob:  0.643398, 0.343750 (0.677 sec)
212.22... logprob:  0.628601, 0.320312 (0.678 sec)
212.23... logprob:  0.624061, 0.312500 (0.678 sec)
212.24... logprob:  0.580717, 0.242188 (0.680 sec)
212.25... logprob:  0.628838, 0.320312 (0.677 sec)
212.26... logprob:  0.673108, 0.390625 (0.676 sec)
212.27... logprob:  0.628518, 0.320312 (0.675 sec)
213.1... logprob:  0.678603, 0.398438 (0.676 sec)
213.2... logprob:  0.598165, 0.273438 (0.675 sec)
213.3... logprob:  0.653605, 0.359375 (0.675 sec)
213.4... logprob:  0.597312, 0.273438 (0.675 sec)
213.5... logprob:  0.591273, 0.265625 (0.677 sec)
213.6... logprob:  0.611352, 0.296875 (0.681 sec)
213.7... logprob:  0.643956, 0.343750 (0.670 sec)
213.8... logprob:  0.604312, 0.289062 (0.668 sec)
213.9... logprob:  0.638828, 0.335938 (0.668 sec)
213.10... logprob:  0.597022, 0.281250 (0.669 sec)
213.11... logprob:  0.639538, 0.335938 (0.667 sec)
213.12... logprob:  0.721906, 0.437500 (0.667 sec)
213.13... logprob:  0.658725, 0.359375 (0.669 sec)
213.14... logprob:  0.664284, 0.367188 (0.669 sec)
213.15... logprob:  0.687534, 0.398438 (0.673 sec)
213.16... logprob:  0.627056, 0.320312 (0.673 sec)
213.17... logprob:  0.638521, 0.335938 (0.676 sec)
213.18... logprob:  0.638232, 0.335938 (0.679 sec)
213.19... logprob:  0.632837, 0.328125 (0.669 sec)
213.20... logprob:  0.648673, 0.351562 (0.670 sec)
213.21... logprob:  0.643398, 0.343750 (0.670 sec)
213.22... logprob:  0.628594, 0.320312 (0.668 sec)
213.23... logprob:  0.624052, 0.312500 (0.671 sec)
213.24... logprob:  0.580688, 0.242188 (0.669 sec)
213.25... logprob:  0.628831, 0.320312 (0.678 sec)
213.26... logprob:  0.673116, 0.390625 (0.678 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633527, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956755e-03 [6.242245e-09] 
Layer 'conv1' biases: 2.827992e-07 [5.938466e-11] 
Layer 'conv2' weights[0]: 7.944170e-03 [4.794779e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.351206e-10] 
Layer 'conv3' weights[0]: 7.942336e-03 [4.410075e-09] 
Layer 'conv3' biases: 2.504120e-06 [6.956286e-10] 
Layer 'conv4' weights[0]: 7.974835e-03 [4.353055e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.878755e-09] 
Layer 'conv5' weights[0]: 7.974279e-03 [2.418769e-08] 
Layer 'conv5' biases: 1.000005e+00 [2.590645e-08] 
Layer 'fc6' weights[0]: 7.570686e-03 [4.609706e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.396398e-09] 
Layer 'fc7' weights[0]: 7.631818e-03 [5.459644e-08] 
Layer 'fc7' biases: 9.998573e-01 [3.059339e-08] 
Layer 'fc8' weights[0]: 6.311032e-04 [1.750542e-06] 
Layer 'fc8' biases: 1.003157e-01 [4.792184e-05] 
Train error last 27 batches: 0.636257
-------------------------------------------------------
Not saving because 0.633527 > 0.627114 (197.8: -0.01%)
======================================================= (1.821 sec)
213.27... logprob:  0.628514, 0.320312 (0.677 sec)
214.1... logprob:  0.678610, 0.398438 (0.676 sec)
214.2... logprob:  0.598159, 0.273438 (0.679 sec)
214.3... logprob:  0.653606, 0.359375 (0.680 sec)
214.4... logprob:  0.597310, 0.273438 (0.679 sec)
214.5... logprob:  0.591276, 0.265625 (0.686 sec)
214.6... logprob:  0.611356, 0.296875 (0.678 sec)
214.7... logprob:  0.643954, 0.343750 (0.673 sec)
214.8... logprob:  0.604320, 0.289062 (0.674 sec)
214.9... logprob:  0.638824, 0.335938 (0.670 sec)
214.10... logprob:  0.597033, 0.281250 (0.671 sec)
214.11... logprob:  0.639529, 0.335938 (0.671 sec)
214.12... logprob:  0.721862, 0.437500 (0.669 sec)
214.13... logprob:  0.658709, 0.359375 (0.669 sec)
214.14... logprob:  0.664270, 0.367188 (0.669 sec)
214.15... logprob:  0.687520, 0.398438 (0.670 sec)
214.16... logprob:  0.627056, 0.320312 (0.669 sec)
214.17... logprob:  0.638520, 0.335938 (0.671 sec)
214.18... logprob:  0.638232, 0.335938 (0.670 sec)
214.19... logprob:  0.632835, 0.328125 (0.670 sec)
214.20... logprob:  0.648675, 0.351562 (0.671 sec)
214.21... logprob:  0.643398, 0.343750 (0.673 sec)
214.22... logprob:  0.628588, 0.320312 (0.670 sec)
214.23... logprob:  0.624042, 0.312500 (0.669 sec)
214.24... logprob:  0.580660, 0.242188 (0.672 sec)
214.25... logprob:  0.628824, 0.320312 (0.668 sec)
214.26... logprob:  0.673126, 0.390625 (0.669 sec)
214.27... logprob:  0.628508, 0.320312 (0.676 sec)
215.1... logprob:  0.678619, 0.398438 (0.671 sec)
215.2... logprob:  0.598147, 0.273438 (0.676 sec)
215.3... logprob:  0.653608, 0.359375 (0.669 sec)
215.4... logprob:  0.597303, 0.273438 (0.668 sec)
215.5... logprob:  0.591271, 0.265625 (0.669 sec)
215.6... logprob:  0.611355, 0.296875 (0.670 sec)
215.7... logprob:  0.643953, 0.343750 (0.670 sec)
215.8... logprob:  0.604324, 0.289062 (0.669 sec)
215.9... logprob:  0.638821, 0.335938 (0.668 sec)
215.10... logprob:  0.597040, 0.281250 (0.669 sec)
215.11... logprob:  0.639523, 0.335938 (0.669 sec)
215.12... logprob:  0.721827, 0.437500 (0.669 sec)
215.13... logprob:  0.658697, 0.359375 (0.674 sec)
215.14... logprob:  0.664258, 0.367188 (0.673 sec)
215.15... logprob:  0.687508, 0.398438 (0.670 sec)
215.16... logprob:  0.627056, 0.320312 (0.672 sec)
215.17... logprob:  0.638521, 0.335938 (0.674 sec)
215.18... logprob:  0.638232, 0.335938 (0.672 sec)
215.19... logprob:  0.632834, 0.328125 (0.670 sec)
215.20... logprob:  0.648677, 0.351562 (0.677 sec)
215.21... logprob:  0.643398, 0.343750 (0.676 sec)
215.22... logprob:  0.628581, 0.320312 (0.685 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.628950, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956549e-03 [6.547175e-09] 
Layer 'conv1' biases: 2.860186e-07 [1.255475e-10] 
Layer 'conv2' weights[0]: 7.943974e-03 [5.786194e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.517604e-10] 
Layer 'conv3' weights[0]: 7.942152e-03 [5.152513e-09] 
Layer 'conv3' biases: 2.528626e-06 [1.522456e-09] 
Layer 'conv4' weights[0]: 7.974642e-03 [5.097466e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.052850e-08] 
Layer 'conv5' weights[0]: 7.974080e-03 [6.523847e-08] 
Layer 'conv5' biases: 1.000005e+00 [7.005346e-08] 
Layer 'fc6' weights[0]: 7.570480e-03 [7.811416e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.726988e-09] 
Layer 'fc7' weights[0]: 7.629876e-03 [1.056994e-07] 
Layer 'fc7' biases: 9.998572e-01 [8.845794e-08] 
Layer 'fc8' weights[0]: 6.241007e-04 [5.070601e-06] 
Layer 'fc8' biases: 1.010186e-01 [7.223368e-05] 
Train error last 27 batches: 0.636249
-------------------------------------------------------
Not saving because 0.628950 > 0.627114 (197.8: -0.01%)
======================================================= (1.736 sec)
215.23... logprob:  0.624033, 0.312500 (0.672 sec)
215.24... logprob:  0.580634, 0.242188 (0.669 sec)
215.25... logprob:  0.628817, 0.320312 (0.668 sec)
215.26... logprob:  0.673133, 0.390625 (0.668 sec)
215.27... logprob:  0.628504, 0.320312 (0.674 sec)
216.1... logprob:  0.678625, 0.398438 (0.669 sec)
216.2... logprob:  0.598140, 0.273438 (0.674 sec)
216.3... logprob:  0.653608, 0.359375 (0.670 sec)
216.4... logprob:  0.597301, 0.273438 (0.672 sec)
216.5... logprob:  0.591272, 0.265625 (0.682 sec)
216.6... logprob:  0.611358, 0.296875 (0.667 sec)
216.7... logprob:  0.643951, 0.343750 (0.670 sec)
216.8... logprob:  0.604330, 0.289062 (0.672 sec)
216.9... logprob:  0.638818, 0.335938 (0.676 sec)
216.10... logprob:  0.597048, 0.281250 (0.668 sec)
216.11... logprob:  0.639516, 0.335938 (0.670 sec)
216.12... logprob:  0.721787, 0.437500 (0.672 sec)
216.13... logprob:  0.658684, 0.359375 (0.670 sec)
216.14... logprob:  0.664246, 0.367188 (0.674 sec)
216.15... logprob:  0.687495, 0.398438 (0.676 sec)
216.16... logprob:  0.627056, 0.320312 (0.676 sec)
216.17... logprob:  0.638521, 0.335938 (0.672 sec)
216.18... logprob:  0.638232, 0.335938 (0.670 sec)
216.19... logprob:  0.632832, 0.328125 (0.673 sec)
216.20... logprob:  0.648678, 0.351562 (0.672 sec)
216.21... logprob:  0.643398, 0.343750 (0.672 sec)
216.22... logprob:  0.628576, 0.320312 (0.675 sec)
216.23... logprob:  0.624024, 0.312500 (0.673 sec)
216.24... logprob:  0.580606, 0.242188 (0.676 sec)
216.25... logprob:  0.628811, 0.320312 (0.674 sec)
216.26... logprob:  0.673142, 0.390625 (0.674 sec)
216.27... logprob:  0.628499, 0.320312 (0.673 sec)
217.1... logprob:  0.678633, 0.398438 (0.676 sec)
217.2... logprob:  0.598130, 0.273438 (0.679 sec)
217.3... logprob:  0.653610, 0.359375 (0.672 sec)
217.4... logprob:  0.597296, 0.273438 (0.672 sec)
217.5... logprob:  0.591270, 0.265625 (0.673 sec)
217.6... logprob:  0.611359, 0.296875 (0.676 sec)
217.7... logprob:  0.643949, 0.343750 (0.675 sec)
217.8... logprob:  0.604335, 0.289062 (0.678 sec)
217.9... logprob:  0.638815, 0.335938 (0.678 sec)
217.10... logprob:  0.597056, 0.281250 (0.679 sec)
217.11... logprob:  0.639509, 0.335938 (0.677 sec)
217.12... logprob:  0.721751, 0.437500 (0.671 sec)
217.13... logprob:  0.658671, 0.359375 (0.676 sec)
217.14... logprob:  0.664234, 0.367188 (0.675 sec)
217.15... logprob:  0.687484, 0.398438 (0.674 sec)
217.16... logprob:  0.627056, 0.320312 (0.675 sec)
217.17... logprob:  0.638521, 0.335938 (0.674 sec)
217.18... logprob:  0.638232, 0.335938 (0.677 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.654215, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956360e-03 [6.556718e-09] 
Layer 'conv1' biases: 2.889894e-07 [1.760451e-10] 
Layer 'conv2' weights[0]: 7.943784e-03 [6.905811e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.822473e-10] 
Layer 'conv3' weights[0]: 7.941969e-03 [6.177303e-09] 
Layer 'conv3' biases: 2.549677e-06 [2.505974e-09] 
Layer 'conv4' weights[0]: 7.974442e-03 [6.271325e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.996574e-08] 
Layer 'conv5' weights[0]: 7.973871e-03 [1.235140e-07] 
Layer 'conv5' biases: 1.000005e+00 [1.329867e-07] 
Layer 'fc6' weights[0]: 7.570286e-03 [1.313143e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.266063e-08] 
Layer 'fc7' weights[0]: 7.627940e-03 [1.775193e-07] 
Layer 'fc7' biases: 9.998575e-01 [1.647283e-07] 
Layer 'fc8' weights[0]: 6.481776e-04 [9.516254e-06] 
Layer 'fc8' biases: 1.023458e-01 [1.436579e-04] 
Train error last 27 batches: 0.636240
-------------------------------------------------------
Not saving because 0.654215 > 0.627114 (197.8: -0.01%)
======================================================= (1.727 sec)
217.19... logprob:  0.632832, 0.328125 (0.679 sec)
217.20... logprob:  0.648681, 0.351562 (0.676 sec)
217.21... logprob:  0.643398, 0.343750 (0.678 sec)
217.22... logprob:  0.628569, 0.320312 (0.678 sec)
217.23... logprob:  0.624014, 0.312500 (0.670 sec)
217.24... logprob:  0.580578, 0.242188 (0.668 sec)
217.25... logprob:  0.628804, 0.320312 (0.669 sec)
217.26... logprob:  0.673150, 0.390625 (0.669 sec)
217.27... logprob:  0.628495, 0.320312 (0.667 sec)
218.1... logprob:  0.678640, 0.398438 (0.669 sec)
218.2... logprob:  0.598122, 0.273438 (0.670 sec)
218.3... logprob:  0.653611, 0.359375 (0.669 sec)
218.4... logprob:  0.597293, 0.273438 (0.667 sec)
218.5... logprob:  0.591270, 0.265625 (0.669 sec)
218.6... logprob:  0.611362, 0.296875 (0.668 sec)
218.7... logprob:  0.643948, 0.343750 (0.669 sec)
218.8... logprob:  0.604342, 0.289062 (0.669 sec)
218.9... logprob:  0.638811, 0.335938 (0.672 sec)
218.10... logprob:  0.597066, 0.281250 (0.672 sec)
218.11... logprob:  0.639502, 0.335938 (0.675 sec)
218.12... logprob:  0.721709, 0.437500 (0.672 sec)
218.13... logprob:  0.658656, 0.359375 (0.673 sec)
218.14... logprob:  0.664221, 0.367188 (0.676 sec)
218.15... logprob:  0.687469, 0.398438 (0.673 sec)
218.16... logprob:  0.627056, 0.320312 (0.677 sec)
218.17... logprob:  0.638521, 0.335938 (0.677 sec)
218.18... logprob:  0.638232, 0.335938 (0.673 sec)
218.19... logprob:  0.632829, 0.328125 (0.673 sec)
218.20... logprob:  0.648683, 0.351562 (0.676 sec)
218.21... logprob:  0.643397, 0.343750 (0.672 sec)
218.22... logprob:  0.628563, 0.320312 (0.691 sec)
218.23... logprob:  0.624005, 0.312500 (0.670 sec)
218.24... logprob:  0.580550, 0.242188 (0.681 sec)
218.25... logprob:  0.628797, 0.320312 (0.675 sec)
218.26... logprob:  0.673159, 0.390625 (0.675 sec)
218.27... logprob:  0.628489, 0.320312 (0.675 sec)
219.1... logprob:  0.678649, 0.398438 (0.675 sec)
219.2... logprob:  0.598112, 0.273438 (0.679 sec)
219.3... logprob:  0.653612, 0.359375 (0.679 sec)
219.4... logprob:  0.597288, 0.273438 (0.682 sec)
219.5... logprob:  0.591268, 0.265625 (0.679 sec)
219.6... logprob:  0.611362, 0.296875 (0.676 sec)
219.7... logprob:  0.643946, 0.343750 (0.676 sec)
219.8... logprob:  0.604346, 0.289062 (0.760 sec)
219.9... logprob:  0.638808, 0.335938 (0.804 sec)
219.10... logprob:  0.597073, 0.281250 (0.764 sec)
219.11... logprob:  0.639495, 0.335938 (0.695 sec)
219.12... logprob:  0.721674, 0.437500 (0.840 sec)
219.13... logprob:  0.658644, 0.359375 (0.841 sec)
219.14... logprob:  0.664210, 0.367188 (0.825 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627155, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956158e-03 [6.775498e-09] 
Layer 'conv1' biases: 2.918681e-07 [1.576481e-10] 
Layer 'conv2' weights[0]: 7.943600e-03 [6.489224e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.561928e-10] 
Layer 'conv3' weights[0]: 7.941774e-03 [5.734952e-09] 
Layer 'conv3' biases: 2.569675e-06 [2.127423e-09] 
Layer 'conv4' weights[0]: 7.974248e-03 [5.786901e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.619374e-08] 
Layer 'conv5' weights[0]: 7.973673e-03 [1.002144e-07] 
Layer 'conv5' biases: 1.000004e+00 [1.078560e-07] 
Layer 'fc6' weights[0]: 7.570097e-03 [1.095232e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.029478e-08] 
Layer 'fc7' weights[0]: 7.625993e-03 [1.476401e-07] 
Layer 'fc7' biases: 9.998580e-01 [1.336767e-07] 
Layer 'fc8' weights[0]: 6.853311e-04 [7.726278e-06] 
Layer 'fc8' biases: 1.038840e-01 [1.089416e-04] 
Train error last 27 batches: 0.636231
-------------------------------------------------------
Not saving because 0.627155 > 0.627114 (197.8: -0.01%)
======================================================= (1.965 sec)
219.15... logprob:  0.687457, 0.398438 (0.851 sec)
219.16... logprob:  0.627056, 0.320312 (0.700 sec)
219.17... logprob:  0.638521, 0.335938 (0.693 sec)
219.18... logprob:  0.638232, 0.335938 (0.694 sec)
219.19... logprob:  0.632829, 0.328125 (0.695 sec)
219.20... logprob:  0.648684, 0.351562 (0.698 sec)
219.21... logprob:  0.643397, 0.343750 (0.706 sec)
219.22... logprob:  0.628556, 0.320312 (0.697 sec)
219.23... logprob:  0.623997, 0.312500 (0.713 sec)
219.24... logprob:  0.580524, 0.242188 (0.695 sec)
219.25... logprob:  0.628791, 0.320312 (0.683 sec)
219.26... logprob:  0.673167, 0.390625 (0.726 sec)
219.27... logprob:  0.628485, 0.320312 (0.685 sec)
220.1... logprob:  0.678656, 0.398438 (0.681 sec)
220.2... logprob:  0.598103, 0.273438 (0.680 sec)
220.3... logprob:  0.653613, 0.359375 (0.695 sec)
220.4... logprob:  0.597284, 0.273438 (0.691 sec)
220.5... logprob:  0.591268, 0.265625 (0.704 sec)
220.6... logprob:  0.611364, 0.296875 (0.692 sec)
220.7... logprob:  0.643945, 0.343750 (0.689 sec)
220.8... logprob:  0.604351, 0.289062 (0.689 sec)
220.9... logprob:  0.638805, 0.335938 (0.691 sec)
220.10... logprob:  0.597082, 0.281250 (0.688 sec)
220.11... logprob:  0.639489, 0.335938 (0.691 sec)
220.12... logprob:  0.721637, 0.437500 (0.690 sec)
220.13... logprob:  0.658632, 0.359375 (0.701 sec)
220.14... logprob:  0.664199, 0.367188 (0.695 sec)
220.15... logprob:  0.687446, 0.398438 (0.689 sec)
220.16... logprob:  0.627056, 0.320312 (0.697 sec)
220.17... logprob:  0.638521, 0.335938 (0.687 sec)
220.18... logprob:  0.638232, 0.335938 (0.682 sec)
220.19... logprob:  0.632827, 0.328125 (0.681 sec)
220.20... logprob:  0.648686, 0.351562 (0.684 sec)
220.21... logprob:  0.643398, 0.343750 (0.688 sec)
220.22... logprob:  0.628550, 0.320312 (0.684 sec)
220.23... logprob:  0.623987, 0.312500 (0.685 sec)
220.24... logprob:  0.580497, 0.242188 (0.687 sec)
220.25... logprob:  0.628784, 0.320312 (0.691 sec)
220.26... logprob:  0.673175, 0.390625 (0.683 sec)
220.27... logprob:  0.628481, 0.320312 (0.681 sec)
221.1... logprob:  0.678663, 0.398438 (0.684 sec)
221.2... logprob:  0.598095, 0.273438 (0.706 sec)
221.3... logprob:  0.653614, 0.359375 (0.695 sec)
221.4... logprob:  0.597281, 0.273438 (0.722 sec)
221.5... logprob:  0.591267, 0.265625 (0.684 sec)
221.6... logprob:  0.611366, 0.296875 (0.685 sec)
221.7... logprob:  0.643943, 0.343750 (0.688 sec)
221.8... logprob:  0.604357, 0.289062 (0.686 sec)
221.9... logprob:  0.638801, 0.335938 (0.685 sec)
221.10... logprob:  0.597091, 0.281250 (0.687 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633348, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955964e-03 [6.835511e-09] 
Layer 'conv1' biases: 2.949974e-07 [1.321322e-10] 
Layer 'conv2' weights[0]: 7.943405e-03 [6.005456e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.795619e-10] 
Layer 'conv3' weights[0]: 7.941570e-03 [5.957435e-09] 
Layer 'conv3' biases: 2.592594e-06 [2.147558e-09] 
Layer 'conv4' weights[0]: 7.974058e-03 [6.281400e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.023189e-08] 
Layer 'conv5' weights[0]: 7.973472e-03 [1.252493e-07] 
Layer 'conv5' biases: 1.000004e+00 [1.350978e-07] 
Layer 'fc6' weights[0]: 7.569910e-03 [1.322376e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.271519e-08] 
Layer 'fc7' weights[0]: 7.624050e-03 [1.755856e-07] 
Layer 'fc7' biases: 9.998580e-01 [1.619391e-07] 
Layer 'fc8' weights[0]: 6.906294e-04 [9.421683e-06] 
Layer 'fc8' biases: 1.048257e-01 [1.711094e-04] 
Train error last 27 batches: 0.636225
-------------------------------------------------------
Not saving because 0.633348 > 0.627114 (197.8: -0.01%)
======================================================= (1.746 sec)
221.11... logprob:  0.639482, 0.335938 (0.683 sec)
221.12... logprob:  0.721597, 0.437500 (0.681 sec)
221.13... logprob:  0.658618, 0.359375 (0.687 sec)
221.14... logprob:  0.664186, 0.367188 (0.682 sec)
221.15... logprob:  0.687432, 0.398438 (0.688 sec)
221.16... logprob:  0.627056, 0.320312 (0.687 sec)
221.17... logprob:  0.638522, 0.335938 (0.684 sec)
221.18... logprob:  0.638231, 0.335938 (0.685 sec)
221.19... logprob:  0.632825, 0.328125 (0.685 sec)
221.20... logprob:  0.648688, 0.351562 (0.686 sec)
221.21... logprob:  0.643397, 0.343750 (0.684 sec)
221.22... logprob:  0.628544, 0.320312 (0.682 sec)
221.23... logprob:  0.623979, 0.312500 (0.682 sec)
221.24... logprob:  0.580470, 0.242188 (0.681 sec)
221.25... logprob:  0.628778, 0.320312 (0.681 sec)
221.26... logprob:  0.673184, 0.390625 (0.697 sec)
221.27... logprob:  0.628476, 0.320312 (0.679 sec)
222.1... logprob:  0.678672, 0.398438 (0.681 sec)
222.2... logprob:  0.598085, 0.273438 (0.681 sec)
222.3... logprob:  0.653616, 0.359375 (0.683 sec)
222.4... logprob:  0.597275, 0.273438 (0.680 sec)
222.5... logprob:  0.591264, 0.265625 (0.686 sec)
222.6... logprob:  0.611366, 0.296875 (0.684 sec)
222.7... logprob:  0.643941, 0.343750 (0.686 sec)
222.8... logprob:  0.604361, 0.289062 (0.692 sec)
222.9... logprob:  0.638799, 0.335938 (0.681 sec)
222.10... logprob:  0.597098, 0.281250 (0.683 sec)
222.11... logprob:  0.639476, 0.335938 (0.683 sec)
222.12... logprob:  0.721563, 0.437500 (0.689 sec)
222.13... logprob:  0.658606, 0.359375 (0.681 sec)
222.14... logprob:  0.664175, 0.367188 (0.679 sec)
222.15... logprob:  0.687421, 0.398438 (0.678 sec)
222.16... logprob:  0.627056, 0.320312 (0.681 sec)
222.17... logprob:  0.638521, 0.335938 (0.677 sec)
222.18... logprob:  0.638232, 0.335938 (0.683 sec)
222.19... logprob:  0.632824, 0.328125 (0.679 sec)
222.20... logprob:  0.648690, 0.351562 (0.681 sec)
222.21... logprob:  0.643397, 0.343750 (0.678 sec)
222.22... logprob:  0.628538, 0.320312 (0.686 sec)
222.23... logprob:  0.623970, 0.312500 (0.685 sec)
222.24... logprob:  0.580444, 0.242188 (0.684 sec)
222.25... logprob:  0.628771, 0.320312 (0.685 sec)
222.26... logprob:  0.673191, 0.390625 (0.690 sec)
222.27... logprob:  0.628471, 0.320312 (0.682 sec)
223.1... logprob:  0.678678, 0.398438 (0.689 sec)
223.2... logprob:  0.598077, 0.273438 (0.688 sec)
223.3... logprob:  0.653617, 0.359375 (0.686 sec)
223.4... logprob:  0.597272, 0.273438 (0.680 sec)
223.5... logprob:  0.591265, 0.265625 (0.686 sec)
223.6... logprob:  0.611368, 0.296875 (0.682 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.688123, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955767e-03 [7.153516e-09] 
Layer 'conv1' biases: 2.984344e-07 [1.667124e-10] 
Layer 'conv2' weights[0]: 7.943213e-03 [6.309054e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.952355e-10] 
Layer 'conv3' weights[0]: 7.941380e-03 [6.210492e-09] 
Layer 'conv3' biases: 2.619861e-06 [2.374918e-09] 
Layer 'conv4' weights[0]: 7.973866e-03 [6.479868e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.239935e-08] 
Layer 'conv5' weights[0]: 7.973270e-03 [1.381398e-07] 
Layer 'conv5' biases: 1.000004e+00 [1.489572e-07] 
Layer 'fc6' weights[0]: 7.569719e-03 [1.458591e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.412577e-08] 
Layer 'fc7' weights[0]: 7.622118e-03 [1.941018e-07] 
Layer 'fc7' biases: 9.998573e-01 [1.809004e-07] 
Layer 'fc8' weights[0]: 6.571112e-04 [1.044737e-05] 
Layer 'fc8' biases: 1.050459e-01 [1.966069e-04] 
Train error last 27 batches: 0.636216
-------------------------------------------------------
Not saving because 0.688123 > 0.627114 (197.8: -0.01%)
======================================================= (1.722 sec)
223.7... logprob:  0.643940, 0.343750 (0.730 sec)
223.8... logprob:  0.604367, 0.289062 (0.694 sec)
223.9... logprob:  0.638795, 0.335938 (0.708 sec)
223.10... logprob:  0.597107, 0.281250 (0.755 sec)
223.11... logprob:  0.639469, 0.335938 (0.693 sec)
223.12... logprob:  0.721524, 0.437500 (0.734 sec)
223.13... logprob:  0.658593, 0.359375 (0.694 sec)
223.14... logprob:  0.664162, 0.367188 (0.723 sec)
223.15... logprob:  0.687407, 0.398438 (0.701 sec)
223.16... logprob:  0.627056, 0.320312 (0.852 sec)
223.17... logprob:  0.638521, 0.335938 (0.694 sec)
223.18... logprob:  0.638231, 0.335938 (0.732 sec)
223.19... logprob:  0.632823, 0.328125 (0.807 sec)
223.20... logprob:  0.648691, 0.351562 (0.702 sec)
223.21... logprob:  0.643397, 0.343750 (0.689 sec)
223.22... logprob:  0.628532, 0.320312 (0.688 sec)
223.23... logprob:  0.623962, 0.312500 (0.695 sec)
223.24... logprob:  0.580418, 0.242188 (0.696 sec)
223.25... logprob:  0.628765, 0.320312 (0.733 sec)
223.26... logprob:  0.673199, 0.390625 (0.734 sec)
223.27... logprob:  0.628467, 0.320312 (0.683 sec)
224.1... logprob:  0.678686, 0.398438 (0.684 sec)
224.2... logprob:  0.598067, 0.273438 (0.684 sec)
224.3... logprob:  0.653618, 0.359375 (0.691 sec)
224.4... logprob:  0.597267, 0.273438 (0.791 sec)
224.5... logprob:  0.591262, 0.265625 (0.714 sec)
224.6... logprob:  0.611369, 0.296875 (0.683 sec)
224.7... logprob:  0.643938, 0.343750 (0.684 sec)
224.8... logprob:  0.604372, 0.289062 (0.684 sec)
224.9... logprob:  0.638793, 0.335938 (0.693 sec)
224.10... logprob:  0.597113, 0.281250 (0.700 sec)
224.11... logprob:  0.639463, 0.335938 (0.695 sec)
224.12... logprob:  0.721491, 0.437500 (0.694 sec)
224.13... logprob:  0.658581, 0.359375 (0.688 sec)
224.14... logprob:  0.664151, 0.367188 (0.685 sec)
224.15... logprob:  0.687396, 0.398438 (0.682 sec)
224.16... logprob:  0.627056, 0.320312 (0.682 sec)
224.17... logprob:  0.638521, 0.335938 (0.683 sec)
224.18... logprob:  0.638231, 0.335938 (0.683 sec)
224.19... logprob:  0.632821, 0.328125 (0.683 sec)
224.20... logprob:  0.648693, 0.351562 (0.683 sec)
224.21... logprob:  0.643397, 0.343750 (0.689 sec)
224.22... logprob:  0.628527, 0.320312 (0.685 sec)
224.23... logprob:  0.623953, 0.312500 (0.689 sec)
224.24... logprob:  0.580393, 0.242188 (0.763 sec)
224.25... logprob:  0.628759, 0.320312 (0.729 sec)
224.26... logprob:  0.673207, 0.390625 (0.741 sec)
224.27... logprob:  0.628462, 0.320312 (0.720 sec)
225.1... logprob:  0.678693, 0.398438 (0.685 sec)
225.2... logprob:  0.598058, 0.273438 (0.689 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633307, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955562e-03 [6.637791e-09] 
Layer 'conv1' biases: 3.018409e-07 [7.449014e-11] 
Layer 'conv2' weights[0]: 7.943043e-03 [4.910572e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.413576e-10] 
Layer 'conv3' weights[0]: 7.941189e-03 [4.673044e-09] 
Layer 'conv3' biases: 2.646414e-06 [9.836227e-10] 
Layer 'conv4' weights[0]: 7.973673e-03 [4.658219e-09] 
Layer 'conv4' biases: 1.000001e+00 [7.519502e-09] 
Layer 'conv5' weights[0]: 7.973079e-03 [4.655065e-08] 
Layer 'conv5' biases: 1.000004e+00 [5.008016e-08] 
Layer 'fc6' weights[0]: 7.569499e-03 [6.135135e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.710665e-09] 
Layer 'fc7' weights[0]: 7.620174e-03 [7.957784e-08] 
Layer 'fc7' biases: 9.998571e-01 [5.992470e-08] 
Layer 'fc8' weights[0]: 6.316907e-04 [3.431958e-06] 
Layer 'fc8' biases: 1.053935e-01 [7.528065e-05] 
Train error last 27 batches: 0.636207
-------------------------------------------------------
Not saving because 0.633307 > 0.627114 (197.8: -0.01%)
======================================================= (1.795 sec)
225.3... logprob:  0.653619, 0.359375 (0.817 sec)
225.4... logprob:  0.597263, 0.273438 (0.729 sec)
225.5... logprob:  0.591261, 0.265625 (0.845 sec)
225.6... logprob:  0.611370, 0.296875 (0.932 sec)
225.7... logprob:  0.643937, 0.343750 (0.726 sec)
225.8... logprob:  0.604377, 0.289062 (1.004 sec)
225.9... logprob:  0.638790, 0.335938 (0.854 sec)
225.10... logprob:  0.597122, 0.281250 (0.842 sec)
225.11... logprob:  0.639456, 0.335938 (0.785 sec)
225.12... logprob:  0.721453, 0.437500 (0.874 sec)
225.13... logprob:  0.658568, 0.359375 (0.852 sec)
225.14... logprob:  0.664140, 0.367188 (0.871 sec)
225.15... logprob:  0.687384, 0.398438 (0.843 sec)
225.16... logprob:  0.627056, 0.320312 (0.690 sec)
225.17... logprob:  0.638521, 0.335938 (0.698 sec)
225.18... logprob:  0.638232, 0.335938 (0.684 sec)
225.19... logprob:  0.632820, 0.328125 (0.680 sec)
225.20... logprob:  0.648695, 0.351562 (0.690 sec)
225.21... logprob:  0.643396, 0.343750 (0.691 sec)
225.22... logprob:  0.628520, 0.320312 (0.705 sec)
225.23... logprob:  0.623943, 0.312500 (0.732 sec)
225.24... logprob:  0.580364, 0.242188 (0.700 sec)
225.25... logprob:  0.628752, 0.320312 (0.711 sec)
225.26... logprob:  0.673216, 0.390625 (0.722 sec)
225.27... logprob:  0.628458, 0.320312 (0.703 sec)
226.1... logprob:  0.678700, 0.398438 (0.691 sec)
226.2... logprob:  0.598050, 0.273438 (0.694 sec)
226.3... logprob:  0.653620, 0.359375 (0.691 sec)
226.4... logprob:  0.597260, 0.273438 (0.694 sec)
226.5... logprob:  0.591261, 0.265625 (0.695 sec)
226.6... logprob:  0.611373, 0.296875 (0.688 sec)
226.7... logprob:  0.643935, 0.343750 (0.699 sec)
226.8... logprob:  0.604383, 0.289062 (0.686 sec)
226.9... logprob:  0.638786, 0.335938 (0.687 sec)
226.10... logprob:  0.597132, 0.281250 (0.690 sec)
226.11... logprob:  0.639449, 0.335938 (0.731 sec)
226.12... logprob:  0.721412, 0.437500 (0.691 sec)
226.13... logprob:  0.658554, 0.359375 (0.683 sec)
226.14... logprob:  0.664127, 0.367188 (0.684 sec)
226.15... logprob:  0.687370, 0.398438 (0.683 sec)
226.16... logprob:  0.627056, 0.320312 (0.683 sec)
226.17... logprob:  0.638522, 0.335938 (0.683 sec)
226.18... logprob:  0.638231, 0.335938 (0.683 sec)
226.19... logprob:  0.632819, 0.328125 (0.682 sec)
226.20... logprob:  0.648696, 0.351562 (0.690 sec)
226.21... logprob:  0.643397, 0.343750 (0.683 sec)
226.22... logprob:  0.628514, 0.320312 (0.684 sec)
226.23... logprob:  0.623935, 0.312500 (0.744 sec)
226.24... logprob:  0.580338, 0.242188 (0.687 sec)
226.25... logprob:  0.628746, 0.320312 (0.719 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.628600, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955364e-03 [6.398698e-09] 
Layer 'conv1' biases: 3.051068e-07 [7.359205e-11] 
Layer 'conv2' weights[0]: 7.942838e-03 [4.893853e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.866121e-10] 
Layer 'conv3' weights[0]: 7.940981e-03 [4.735294e-09] 
Layer 'conv3' biases: 2.671194e-06 [1.144665e-09] 
Layer 'conv4' weights[0]: 7.973490e-03 [4.804499e-09] 
Layer 'conv4' biases: 1.000001e+00 [9.708608e-09] 
Layer 'conv5' weights[0]: 7.972886e-03 [5.919963e-08] 
Layer 'conv5' biases: 1.000004e+00 [6.373246e-08] 
Layer 'fc6' weights[0]: 7.569287e-03 [7.247687e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.045682e-09] 
Layer 'fc7' weights[0]: 7.618220e-03 [9.579172e-08] 
Layer 'fc7' biases: 9.998569e-01 [7.746339e-08] 
Layer 'fc8' weights[0]: 6.243705e-04 [4.412662e-06] 
Layer 'fc8' biases: 1.060860e-01 [9.995692e-05] 
Train error last 27 batches: 0.636198
-------------------------------------------------------
Not saving because 0.628600 > 0.627114 (197.8: -0.01%)
======================================================= (1.758 sec)
226.26... logprob:  0.673224, 0.390625 (0.682 sec)
226.27... logprob:  0.628452, 0.320312 (0.681 sec)
227.1... logprob:  0.678708, 0.398438 (0.681 sec)
227.2... logprob:  0.598039, 0.273438 (0.682 sec)
227.3... logprob:  0.653621, 0.359375 (0.682 sec)
227.4... logprob:  0.597253, 0.273438 (0.681 sec)
227.5... logprob:  0.591258, 0.265625 (0.682 sec)
227.6... logprob:  0.611372, 0.296875 (0.683 sec)
227.7... logprob:  0.643934, 0.343750 (0.684 sec)
227.8... logprob:  0.604387, 0.289062 (0.683 sec)
227.9... logprob:  0.638783, 0.335938 (0.682 sec)
227.10... logprob:  0.597139, 0.281250 (0.682 sec)
227.11... logprob:  0.639443, 0.335938 (0.681 sec)
227.12... logprob:  0.721378, 0.437500 (0.681 sec)
227.13... logprob:  0.658542, 0.359375 (0.688 sec)
227.14... logprob:  0.664116, 0.367188 (0.683 sec)
227.15... logprob:  0.687358, 0.398438 (0.689 sec)
227.16... logprob:  0.627056, 0.320312 (0.687 sec)
227.17... logprob:  0.638521, 0.335938 (0.697 sec)
227.18... logprob:  0.638231, 0.335938 (0.697 sec)
227.19... logprob:  0.632818, 0.328125 (0.712 sec)
227.20... logprob:  0.648698, 0.351562 (0.691 sec)
227.21... logprob:  0.643396, 0.343750 (0.719 sec)
227.22... logprob:  0.628509, 0.320312 (0.686 sec)
227.23... logprob:  0.623927, 0.312500 (0.684 sec)
227.24... logprob:  0.580315, 0.242188 (0.684 sec)
227.25... logprob:  0.628740, 0.320312 (0.685 sec)
227.26... logprob:  0.673231, 0.390625 (0.682 sec)
227.27... logprob:  0.628449, 0.320312 (0.678 sec)
228.1... logprob:  0.678714, 0.398438 (0.687 sec)
228.2... logprob:  0.598032, 0.273438 (0.680 sec)
228.3... logprob:  0.653623, 0.359375 (0.683 sec)
228.4... logprob:  0.597250, 0.273438 (0.682 sec)
228.5... logprob:  0.591257, 0.265625 (0.678 sec)
228.6... logprob:  0.611374, 0.296875 (0.684 sec)
228.7... logprob:  0.643933, 0.343750 (0.691 sec)
228.8... logprob:  0.604391, 0.289062 (0.687 sec)
228.9... logprob:  0.638781, 0.335938 (0.692 sec)
228.10... logprob:  0.597145, 0.281250 (0.688 sec)
228.11... logprob:  0.639438, 0.335938 (0.680 sec)
228.12... logprob:  0.721347, 0.437500 (0.683 sec)
228.13... logprob:  0.658532, 0.359375 (0.682 sec)
228.14... logprob:  0.664106, 0.367188 (0.708 sec)
228.15... logprob:  0.687349, 0.398438 (0.694 sec)
228.16... logprob:  0.627056, 0.320312 (0.692 sec)
228.17... logprob:  0.638522, 0.335938 (0.689 sec)
228.18... logprob:  0.638231, 0.335938 (0.699 sec)
228.19... logprob:  0.632816, 0.328125 (0.700 sec)
228.20... logprob:  0.648700, 0.351562 (0.699 sec)
228.21... logprob:  0.643396, 0.343750 (0.687 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.653397, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955156e-03 [6.748011e-09] 
Layer 'conv1' biases: 3.083187e-07 [1.484722e-10] 
Layer 'conv2' weights[0]: 7.942646e-03 [6.349084e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.158273e-10] 
Layer 'conv3' weights[0]: 7.940784e-03 [5.643857e-09] 
Layer 'conv3' biases: 2.695563e-06 [2.020752e-09] 
Layer 'conv4' weights[0]: 7.973308e-03 [5.624655e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.494548e-08] 
Layer 'conv5' weights[0]: 7.972703e-03 [9.141946e-08] 
Layer 'conv5' biases: 1.000004e+00 [9.822557e-08] 
Layer 'fc6' weights[0]: 7.569098e-03 [1.028623e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.494307e-09] 
Layer 'fc7' weights[0]: 7.616273e-03 [1.375458e-07] 
Layer 'fc7' biases: 9.998569e-01 [1.231339e-07] 
Layer 'fc8' weights[0]: 6.235175e-04 [7.031235e-06] 
Layer 'fc8' biases: 1.068893e-01 [1.094465e-04] 
Train error last 27 batches: 0.636191
-------------------------------------------------------
Not saving because 0.653397 > 0.627114 (197.8: -0.01%)
======================================================= (1.733 sec)
228.22... logprob:  0.628503, 0.320312 (0.683 sec)
228.23... logprob:  0.623918, 0.312500 (0.685 sec)
228.24... logprob:  0.580288, 0.242188 (0.676 sec)
228.25... logprob:  0.628733, 0.320312 (0.683 sec)
228.26... logprob:  0.673239, 0.390625 (0.678 sec)
228.27... logprob:  0.628445, 0.320312 (0.679 sec)
229.1... logprob:  0.678721, 0.398438 (0.676 sec)
229.2... logprob:  0.598024, 0.273438 (0.681 sec)
229.3... logprob:  0.653624, 0.359375 (0.680 sec)
229.4... logprob:  0.597248, 0.273438 (0.687 sec)
229.5... logprob:  0.591258, 0.265625 (0.677 sec)
229.6... logprob:  0.611376, 0.296875 (0.679 sec)
229.7... logprob:  0.643930, 0.343750 (0.676 sec)
229.8... logprob:  0.604398, 0.289062 (0.678 sec)
229.9... logprob:  0.638777, 0.335938 (0.679 sec)
229.10... logprob:  0.597155, 0.281250 (0.679 sec)
229.11... logprob:  0.639430, 0.335938 (0.676 sec)
229.12... logprob:  0.721305, 0.437500 (0.677 sec)
229.13... logprob:  0.658517, 0.359375 (0.685 sec)
229.14... logprob:  0.664092, 0.367188 (0.682 sec)
229.15... logprob:  0.687334, 0.398438 (0.682 sec)
229.16... logprob:  0.627056, 0.320312 (0.677 sec)
229.17... logprob:  0.638521, 0.335938 (0.678 sec)
229.18... logprob:  0.638231, 0.335938 (0.684 sec)
229.19... logprob:  0.632815, 0.328125 (0.679 sec)
229.20... logprob:  0.648702, 0.351562 (0.684 sec)
229.21... logprob:  0.643397, 0.343750 (0.686 sec)
229.22... logprob:  0.628496, 0.320312 (0.685 sec)
229.23... logprob:  0.623909, 0.312500 (0.683 sec)
229.24... logprob:  0.580259, 0.242188 (0.679 sec)
229.25... logprob:  0.628727, 0.320312 (0.681 sec)
229.26... logprob:  0.673249, 0.390625 (0.680 sec)
229.27... logprob:  0.628439, 0.320312 (0.675 sec)
230.1... logprob:  0.678730, 0.398438 (0.681 sec)
230.2... logprob:  0.598014, 0.273438 (0.684 sec)
230.3... logprob:  0.653625, 0.359375 (0.681 sec)
230.4... logprob:  0.597243, 0.273438 (0.679 sec)
230.5... logprob:  0.591255, 0.265625 (0.686 sec)
230.6... logprob:  0.611377, 0.296875 (0.684 sec)
230.7... logprob:  0.643930, 0.343750 (0.687 sec)
230.8... logprob:  0.604403, 0.289062 (0.689 sec)
230.9... logprob:  0.638774, 0.335938 (0.684 sec)
230.10... logprob:  0.597163, 0.281250 (0.689 sec)
230.11... logprob:  0.639424, 0.335938 (0.690 sec)
230.12... logprob:  0.721268, 0.437500 (0.688 sec)
230.13... logprob:  0.658504, 0.359375 (0.687 sec)
230.14... logprob:  0.664080, 0.367188 (0.688 sec)
230.15... logprob:  0.687321, 0.398438 (0.689 sec)
230.16... logprob:  0.627056, 0.320312 (0.687 sec)
230.17... logprob:  0.638522, 0.335938 (0.689 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627379, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954964e-03 [6.551202e-09] 
Layer 'conv1' biases: 3.112846e-07 [1.781036e-10] 
Layer 'conv2' weights[0]: 7.942460e-03 [7.105001e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.258587e-10] 
Layer 'conv3' weights[0]: 7.940600e-03 [6.320815e-09] 
Layer 'conv3' biases: 2.716877e-06 [2.621207e-09] 
Layer 'conv4' weights[0]: 7.973111e-03 [6.474534e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.114096e-08] 
Layer 'conv5' weights[0]: 7.972479e-03 [1.295446e-07] 
Layer 'conv5' biases: 1.000004e+00 [1.392209e-07] 
Layer 'fc6' weights[0]: 7.568907e-03 [1.381059e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.339168e-08] 
Layer 'fc7' weights[0]: 7.614305e-03 [1.846708e-07] 
Layer 'fc7' biases: 9.998572e-01 [1.721107e-07] 
Layer 'fc8' weights[0]: 6.507093e-04 [9.885987e-06] 
Layer 'fc8' biases: 1.082588e-01 [1.523774e-04] 
Train error last 27 batches: 0.636182
-------------------------------------------------------
Not saving because 0.627379 > 0.627114 (197.8: -0.01%)
======================================================= (1.732 sec)
230.18... logprob:  0.638231, 0.335938 (0.683 sec)
230.19... logprob:  0.632814, 0.328125 (0.682 sec)
230.20... logprob:  0.648703, 0.351562 (0.680 sec)
230.21... logprob:  0.643396, 0.343750 (0.680 sec)
230.22... logprob:  0.628492, 0.320312 (0.678 sec)
230.23... logprob:  0.623902, 0.312500 (0.680 sec)
230.24... logprob:  0.580238, 0.242188 (0.676 sec)
230.25... logprob:  0.628721, 0.320312 (0.680 sec)
230.26... logprob:  0.673255, 0.390625 (0.685 sec)
230.27...Option --layer-def (Layer definition file) cannot be changed
=========================
Importing _ConvNet C++ module
=========================
Training ConvNet
Always write savepoints, regardless of test err improvement: 0     [DEFAULT]
Check gradients and quit?                                  : 0     [DEFAULT]
Compress checkpoints?                                      : 0     [DEFAULT]
Conserve GPU memory (slower)?                              : 0     [DEFAULT]
Convert given conv layers to unshared local                :       
Cropped DP: crop border size                               : 4     [DEFAULT]
Cropped DP: logreg layer name (for --multiview-test)       :       [DEFAULT]
Cropped DP: test on multiple patches?                      : 0     [DEFAULT]
Cropped Step: crop border step                             : 1     [DEFAULT]
Data batch range: testing                                  : 28-33 
Data batch range: training                                 : 1-27  
Data path                                                  : /data/ad6813/pipe-data/Bluebox/batches/scraping_peeling/net_0 
Data provider                                              : basic-leaf256 
GPU override                                               : -1    [DEFAULT]
Layer definition file                                      : /homes/ad6813/Git/pipe-classification/models/scraping_peeling/net_0/layers.cfg 
Layer parameter file                                       : /homes/ad6813/Git/pipe-classification/models/scraping_peeling/net_0/params.cfg 
Load file                                                  : /data/ad6813/my-nets/saves/ConvNet__2014-07-08_14.54.04 
Maximum save file size (MB)                                : 0     [DEFAULT]
Minibatch size                                             : 128   [DEFAULT]
Number of GPUs                                             : 1     [DEFAULT]
Number of epochs                                           : 50000 [DEFAULT]
Save path                                                  : /homes/ad6813/Git/pipe-classification/models/scraping_peeling/net_0/saves 
Test and quit?                                             : 0     [DEFAULT]
Test on more than one batch at a time?                     : -1    [DEFAULT]
Test on one batch at a time?                               : 1     [DEFAULT]
Testing frequency                                          : 50    
Unshare weight matrices in given layers                    :       
=========================
Running on CUDA device(s) -2
Current time: Tue Jul  8 18:23:47 2014
Saving checkpoints to /data/ad6813/my-nets/saves/ConvNet__2014-07-08_14.54.04
=========================
197.9... logprob:  0.638885, 0.335938 (0.644 sec)
197.10... logprob:  0.596886, 0.281250 (0.644 sec)
197.11... logprob:  0.639655, 0.335938 (0.641 sec)
197.12... logprob:  0.722540, 0.437500 (0.649 sec)
197.13... logprob:  0.658943, 0.359375 (0.647 sec)
197.14... logprob:  0.664482, 0.367188 (0.648 sec)
197.15... logprob:  0.687737, 0.398438 (0.648 sec)
197.16... logprob:  0.627056, 0.320312 (0.641 sec)
197.17... logprob:  0.638518, 0.335938 (0.642 sec)
197.18... logprob:  0.638234, 0.335938 (0.641 sec)
197.19... logprob:  0.632862, 0.328125 (0.640 sec)
197.20... logprob:  0.648645, 0.351562 (0.642 sec)
197.21... logprob:  0.643404, 0.343750 (0.643 sec)
197.22... logprob:  0.628703, 0.320312 (0.640 sec)
197.23... logprob:  0.624209, 0.312500 (0.639 sec)
197.24... logprob:  0.581148, 0.242188 (0.641 sec)
197.25... logprob:  0.628945, 0.320312 (0.642 sec)
197.26... logprob:  0.672981, 0.390625 (0.642 sec)
197.27... logprob:  0.628593, 0.320312 (1.464 sec)
198.1... logprob:  0.678489, 0.398438 (1.461 sec)
198.2... logprob:  0.598306, 0.273438 (1.450 sec)
198.3... logprob:  0.653588, 0.359375 (1.444 sec)
198.4... logprob:  0.597373, 0.273438 (1.456 sec)
198.5... logprob:  0.591286, 0.265625 (1.538 sec)
198.6... logprob:  0.611327, 0.296875 (1.442 sec)
198.7... logprob:  0.643982, 0.343750 (1.454 sec)
198.8... logprob:  0.604228, 0.289062 (0.676 sec)
198.9... logprob:  0.638881, 0.335938 (0.676 sec)
198.10... logprob:  0.596894, 0.281250 (0.673 sec)
198.11... logprob:  0.639647, 0.335938 (0.677 sec)
198.12... logprob:  0.722500, 0.437500 (0.675 sec)
198.13... logprob:  0.658930, 0.359375 (0.675 sec)
198.14... logprob:  0.664470, 0.367188 (0.674 sec)
198.15... logprob:  0.687725, 0.398438 (0.675 sec)
198.16... logprob:  0.627056, 0.320312 (0.676 sec)
198.17... logprob:  0.638518, 0.335938 (0.677 sec)
198.18... logprob:  0.638234, 0.335938 (0.678 sec)
198.19... logprob:  0.632861, 0.328125 (0.672 sec)
198.20... logprob:  0.648647, 0.351562 (0.678 sec)
198.21... logprob:  0.643403, 0.343750 (0.674 sec)
198.22... logprob:  0.628696, 0.320312 (0.675 sec)
198.23... logprob:  0.624198, 0.312500 (0.674 sec)
198.24... logprob:  0.581118, 0.242188 (0.678 sec)
198.25... logprob:  0.628937, 0.320312 (0.676 sec)
198.26... logprob:  0.672990, 0.390625 (0.674 sec)
198.27... logprob:  0.628588, 0.320312 (0.675 sec)
199.1... logprob:  0.678496, 0.398438 (0.676 sec)
199.2... logprob:  0.598297, 0.273438 (0.677 sec)
199.3... logprob:  0.653589, 0.359375 (0.676 sec)
199.4... logprob:  0.597370, 0.273438 (0.677 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.653917, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958334e-03 [6.616787e-09] 
Layer 'conv1' biases: 2.578583e-07 [1.013292e-10] 
Layer 'conv2' weights[0]: 7.945740e-03 [5.305058e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.327255e-10] 
Layer 'conv3' weights[0]: 7.943909e-03 [5.181626e-09] 
Layer 'conv3' biases: 2.315668e-06 [1.458014e-09] 
Layer 'conv4' weights[0]: 7.976427e-03 [5.315155e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.311446e-08] 
Layer 'conv5' weights[0]: 7.975857e-03 [8.278344e-08] 
Layer 'conv5' biases: 1.000005e+00 [8.956599e-08] 
Layer 'fc6' weights[0]: 7.572231e-03 [9.293057e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.271538e-09] 
Layer 'fc7' weights[0]: 7.647438e-03 [1.242977e-07] 
Layer 'fc7' biases: 9.998581e-01 [1.072142e-07] 
Layer 'fc8' weights[0]: 6.516575e-04 [6.265004e-06] 
Layer 'fc8' biases: 9.373735e-02 [1.200475e-04] 
Train error last 27 batches: 0.636328
-------------------------------------------------------
Not saving because 0.653917 > 0.627114 (197.8: -0.01%)
======================================================= (2.139 sec)
199.5... logprob:  0.591286, 0.265625 (0.682 sec)
199.6... logprob:  0.611329, 0.296875 (0.681 sec)
199.7... logprob:  0.643981, 0.343750 (0.682 sec)
199.8... logprob:  0.604235, 0.289062 (0.681 sec)
199.9... logprob:  0.638877, 0.335938 (0.680 sec)
199.10... logprob:  0.596904, 0.281250 (0.679 sec)
199.11... logprob:  0.639639, 0.335938 (0.680 sec)
199.12... logprob:  0.722456, 0.437500 (0.678 sec)
199.13... logprob:  0.658915, 0.359375 (0.679 sec)
199.14... logprob:  0.664456, 0.367188 (0.681 sec)
199.15... logprob:  0.687711, 0.398438 (0.690 sec)
199.16... logprob:  0.627056, 0.320312 (0.680 sec)
199.17... logprob:  0.638518, 0.335938 (0.684 sec)
199.18... logprob:  0.638233, 0.335938 (0.681 sec)
199.19... logprob:  0.632859, 0.328125 (0.683 sec)
199.20... logprob:  0.648649, 0.351562 (0.678 sec)
199.21... logprob:  0.643403, 0.343750 (0.683 sec)
199.22... logprob:  0.628689, 0.320312 (0.679 sec)
199.23... logprob:  0.624188, 0.312500 (0.682 sec)
199.24... logprob:  0.581088, 0.242188 (0.680 sec)
199.25... logprob:  0.628930, 0.320312 (0.683 sec)
199.26... logprob:  0.672998, 0.390625 (0.680 sec)
199.27... logprob:  0.628583, 0.320312 (0.682 sec)
200.1... logprob:  0.678505, 0.398438 (0.680 sec)
200.2... logprob:  0.598286, 0.273438 (0.682 sec)
200.3... logprob:  0.653590, 0.359375 (0.678 sec)
200.4... logprob:  0.597365, 0.273438 (0.682 sec)
200.5... logprob:  0.591284, 0.265625 (0.679 sec)
200.6... logprob:  0.611331, 0.296875 (0.681 sec)
200.7... logprob:  0.643979, 0.343750 (0.679 sec)
200.8... logprob:  0.604240, 0.289062 (0.679 sec)
200.9... logprob:  0.638874, 0.335938 (0.676 sec)
200.10... logprob:  0.596912, 0.281250 (0.678 sec)
200.11... logprob:  0.639632, 0.335938 (0.680 sec)
200.12... logprob:  0.722419, 0.437500 (0.680 sec)
200.13... logprob:  0.658902, 0.359375 (0.679 sec)
200.14... logprob:  0.664445, 0.367188 (0.678 sec)
200.15... logprob:  0.687700, 0.398438 (0.678 sec)
200.16... logprob:  0.627056, 0.320312 (0.678 sec)
200.17... logprob:  0.638519, 0.335938 (0.684 sec)
200.18... logprob:  0.638233, 0.335938 (0.681 sec)
200.19... logprob:  0.632857, 0.328125 (0.681 sec)
200.20... logprob:  0.648651, 0.351562 (0.679 sec)
200.21... logprob:  0.643402, 0.343750 (0.681 sec)
200.22... logprob:  0.628681, 0.320312 (0.676 sec)
200.23... logprob:  0.624177, 0.312500 (0.650 sec)
200.24... logprob:  0.581057, 0.242188 (0.674 sec)
200.25... logprob:  0.628923, 0.320312 (0.680 sec)
200.26... logprob:  0.673007, 0.390625 (0.672 sec)
200.27... logprob:  0.628578, 0.320312 (0.673 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.628448, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958126e-03 [6.338406e-09] 
Layer 'conv1' biases: 2.609494e-07 [6.662394e-11] 
Layer 'conv2' weights[0]: 7.945540e-03 [4.766403e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.967118e-10] 
Layer 'conv3' weights[0]: 7.943719e-03 [4.556169e-09] 
Layer 'conv3' biases: 2.340076e-06 [8.793255e-10] 
Layer 'conv4' weights[0]: 7.976227e-03 [4.584486e-09] 
Layer 'conv4' biases: 1.000001e+00 [6.796701e-09] 
Layer 'conv5' weights[0]: 7.975665e-03 [4.276634e-08] 
Layer 'conv5' biases: 1.000005e+00 [4.618208e-08] 
Layer 'fc6' weights[0]: 7.572020e-03 [5.777574e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.236902e-09] 
Layer 'fc7' weights[0]: 7.645444e-03 [7.497075e-08] 
Layer 'fc7' biases: 9.998579e-01 [5.486651e-08] 
Layer 'fc8' weights[0]: 6.394945e-04 [3.175893e-06] 
Layer 'fc8' biases: 9.440255e-02 [7.164699e-05] 
Train error last 27 batches: 0.636319
-------------------------------------------------------
Not saving because 0.628448 > 0.627114 (197.8: -0.01%)
======================================================= (2.617 sec)
201.1... logprob:  0.678512, 0.398438 (0.656 sec)
201.2... logprob:  0.598279, 0.273438 (0.655 sec)
201.3... logprob:  0.653591, 0.359375 (0.656 sec)
201.4... logprob:  0.597363, 0.273438 (0.655 sec)
201.5... logprob:  0.591286, 0.265625 (0.654 sec)
201.6... logprob:  0.611334, 0.296875 (0.652 sec)
201.7... logprob:  0.643976, 0.343750 (0.653 sec)
201.8... logprob:  0.604248, 0.289062 (0.653 sec)
201.9... logprob:  0.638869, 0.335938 (0.653 sec)
201.10... logprob:  0.596923, 0.281250 (0.652 sec)
201.11... logprob:  0.639623, 0.335938 (0.652 sec)
201.12... logprob:  0.722370, 0.437500 (0.653 sec)
201.13... logprob:  0.658885, 0.359375 (0.652 sec)
201.14... logprob:  0.664429, 0.367188 (0.652 sec)
201.15... logprob:  0.687683, 0.398438 (0.652 sec)
201.16... logprob:  0.627056, 0.320312 (0.654 sec)
201.17... logprob:  0.638518, 0.335938 (0.654 sec)
201.18... logprob:  0.638233, 0.335938 (0.655 sec)
201.19... logprob:  0.632856, 0.328125 (0.654 sec)
201.20... logprob:  0.648653, 0.351562 (0.653 sec)
201.21... logprob:  0.643402, 0.343750 (0.654 sec)
201.22... logprob:  0.628675, 0.320312 (0.652 sec)
201.23... logprob:  0.624167, 0.312500 (0.652 sec)
201.24... logprob:  0.581028, 0.242188 (0.653 sec)
201.25... logprob:  0.628915, 0.320312 (0.653 sec)
201.26... logprob:  0.673016, 0.390625 (0.654 sec)
201.27... logprob:  0.628572, 0.320312 (0.653 sec)
202.1... logprob:  0.678520, 0.398438 (0.653 sec)
202.2... logprob:  0.598267, 0.273438 (0.652 sec)
202.3... logprob:  0.653592, 0.359375 (0.654 sec)
202.4... logprob:  0.597356, 0.273438 (0.653 sec)
202.5... logprob:  0.591282, 0.265625 (0.652 sec)
202.6... logprob:  0.611335, 0.296875 (0.653 sec)
202.7... logprob:  0.643975, 0.343750 (0.653 sec)
202.8... logprob:  0.604251, 0.289062 (0.653 sec)
202.9... logprob:  0.638866, 0.335938 (0.651 sec)
202.10... logprob:  0.596929, 0.281250 (0.654 sec)
202.11... logprob:  0.639617, 0.335938 (0.653 sec)
202.12... logprob:  0.722338, 0.437500 (0.653 sec)
202.13... logprob:  0.658873, 0.359375 (0.654 sec)
202.14... logprob:  0.664419, 0.367188 (0.652 sec)
202.15... logprob:  0.687673, 0.398438 (0.652 sec)
202.16... logprob:  0.627056, 0.320312 (0.653 sec)
202.17... logprob:  0.638519, 0.335938 (0.655 sec)
202.18... logprob:  0.638233, 0.335938 (0.655 sec)
202.19... logprob:  0.632854, 0.328125 (0.654 sec)
202.20... logprob:  0.648654, 0.351562 (0.653 sec)
202.21... logprob:  0.643402, 0.343750 (0.654 sec)
202.22... logprob:  0.628668, 0.320312 (0.653 sec)
202.23... logprob:  0.624158, 0.312500 (0.652 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633927, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957932e-03 [6.074974e-09] 
Layer 'conv1' biases: 2.640501e-07 [9.190399e-11] 
Layer 'conv2' weights[0]: 7.945356e-03 [5.049380e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.588267e-10] 
Layer 'conv3' weights[0]: 7.943525e-03 [4.589219e-09] 
Layer 'conv3' biases: 2.364689e-06 [9.263586e-10] 
Layer 'conv4' weights[0]: 7.976026e-03 [4.498168e-09] 
Layer 'conv4' biases: 1.000001e+00 [5.264599e-09] 
Layer 'conv5' weights[0]: 7.975474e-03 [3.318467e-08] 
Layer 'conv5' biases: 1.000005e+00 [3.549100e-08] 
Layer 'fc6' weights[0]: 7.571829e-03 [5.173583e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.397312e-09] 
Layer 'fc7' weights[0]: 7.643518e-03 [6.635241e-08] 
Layer 'fc7' biases: 9.998575e-01 [4.574095e-08] 
Layer 'fc8' weights[0]: 6.268918e-04 [2.630532e-06] 
Layer 'fc8' biases: 9.502451e-02 [2.727867e-05] 
Train error last 27 batches: 0.636310
-------------------------------------------------------
Not saving because 0.633927 > 0.627114 (197.8: -0.01%)
======================================================= (2.645 sec)
202.24... logprob:  0.581001, 0.242188 (0.648 sec)
202.25... logprob:  0.628908, 0.320312 (0.645 sec)
202.26... logprob:  0.673024, 0.390625 (0.646 sec)
202.27... logprob:  0.628568, 0.320312 (0.645 sec)
203.1... logprob:  0.678527, 0.398438 (0.644 sec)
203.2... logprob:  0.598260, 0.273438 (0.645 sec)
203.3... logprob:  0.653593, 0.359375 (0.645 sec)
203.4... logprob:  0.597354, 0.273438 (0.644 sec)
203.5... logprob:  0.591284, 0.265625 (0.645 sec)
203.6... logprob:  0.611337, 0.296875 (0.644 sec)
203.7... logprob:  0.643973, 0.343750 (0.645 sec)
203.8... logprob:  0.604258, 0.289062 (0.644 sec)
203.9... logprob:  0.638862, 0.335938 (0.644 sec)
203.10... logprob:  0.596938, 0.281250 (0.644 sec)
203.11... logprob:  0.639609, 0.335938 (0.645 sec)
203.12... logprob:  0.722296, 0.437500 (0.646 sec)
203.13... logprob:  0.658859, 0.359375 (0.645 sec)
203.14... logprob:  0.664406, 0.367188 (0.645 sec)
203.15... logprob:  0.687660, 0.398438 (0.645 sec)
203.16... logprob:  0.627056, 0.320312 (0.646 sec)
203.17... logprob:  0.638519, 0.335938 (0.647 sec)
203.18... logprob:  0.638233, 0.335938 (0.646 sec)
203.19... logprob:  0.632852, 0.328125 (0.646 sec)
203.20... logprob:  0.648656, 0.351562 (0.646 sec)
203.21... logprob:  0.643401, 0.343750 (0.647 sec)
203.22... logprob:  0.628661, 0.320312 (0.645 sec)
203.23... logprob:  0.624147, 0.312500 (0.645 sec)
203.24... logprob:  0.580971, 0.242188 (0.644 sec)
203.25... logprob:  0.628901, 0.320312 (0.646 sec)
203.26... logprob:  0.673032, 0.390625 (0.646 sec)
203.27... logprob:  0.628562, 0.320312 (0.645 sec)
204.1... logprob:  0.678535, 0.398438 (0.645 sec)
204.2... logprob:  0.598249, 0.273438 (0.645 sec)
204.3... logprob:  0.653594, 0.359375 (0.645 sec)
204.4... logprob:  0.597349, 0.273438 (0.645 sec)
204.5... logprob:  0.591282, 0.265625 (0.644 sec)
204.6... logprob:  0.611338, 0.296875 (0.645 sec)
204.7... logprob:  0.643971, 0.343750 (0.644 sec)
204.8... logprob:  0.604263, 0.289062 (0.645 sec)
204.9... logprob:  0.638859, 0.335938 (0.645 sec)
204.10... logprob:  0.596947, 0.281250 (0.645 sec)
204.11... logprob:  0.639602, 0.335938 (0.645 sec)
204.12... logprob:  0.722256, 0.437500 (0.646 sec)
204.13... logprob:  0.658845, 0.359375 (0.645 sec)
204.14... logprob:  0.664393, 0.367188 (0.645 sec)
204.15... logprob:  0.687647, 0.398438 (0.645 sec)
204.16... logprob:  0.627056, 0.320312 (0.645 sec)
204.17... logprob:  0.638519, 0.335938 (0.647 sec)
204.18... logprob:  0.638233, 0.335938 (0.646 sec)
204.19... logprob:  0.632851, 0.328125 (0.650 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.684830, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957747e-03 [6.681412e-09] 
Layer 'conv1' biases: 2.669809e-07 [1.572154e-10] 
Layer 'conv2' weights[0]: 7.945155e-03 [6.597759e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.822357e-10] 
Layer 'conv3' weights[0]: 7.943317e-03 [5.863760e-09] 
Layer 'conv3' biases: 2.385802e-06 [2.216549e-09] 
Layer 'conv4' weights[0]: 7.975833e-03 [5.920456e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.727850e-08] 
Layer 'conv5' weights[0]: 7.975242e-03 [1.079365e-07] 
Layer 'conv5' biases: 1.000005e+00 [1.163958e-07] 
Layer 'fc6' weights[0]: 7.571634e-03 [1.161410e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.102329e-08] 
Layer 'fc7' weights[0]: 7.641582e-03 [1.586455e-07] 
Layer 'fc7' biases: 9.998577e-01 [1.453059e-07] 
Layer 'fc8' weights[0]: 6.465797e-04 [8.426043e-06] 
Layer 'fc8' biases: 9.628427e-02 [1.228196e-04] 
Train error last 27 batches: 0.636301
-------------------------------------------------------
Not saving because 0.684830 > 0.627114 (197.8: -0.01%)
======================================================= (2.603 sec)
204.20... logprob:  0.648658, 0.351562 (0.649 sec)
204.21... logprob:  0.643401, 0.343750 (0.649 sec)
204.22... logprob:  0.628654, 0.320312 (0.649 sec)
204.23... logprob:  0.624138, 0.312500 (0.648 sec)
204.24... logprob:  0.580942, 0.242188 (0.646 sec)
204.25... logprob:  0.628893, 0.320312 (0.649 sec)
204.26... logprob:  0.673042, 0.390625 (0.649 sec)
204.27... logprob:  0.628557, 0.320312 (0.647 sec)
205.1... logprob:  0.678542, 0.398438 (0.645 sec)
205.2... logprob:  0.598241, 0.273438 (0.645 sec)
205.3... logprob:  0.653596, 0.359375 (0.645 sec)
205.4... logprob:  0.597346, 0.273438 (0.645 sec)
205.5... logprob:  0.591282, 0.265625 (0.645 sec)
205.6... logprob:  0.611341, 0.296875 (0.645 sec)
205.7... logprob:  0.643969, 0.343750 (0.645 sec)
205.8... logprob:  0.604270, 0.289062 (0.645 sec)
205.9... logprob:  0.638855, 0.335938 (0.645 sec)
205.10... logprob:  0.596956, 0.281250 (0.645 sec)
205.11... logprob:  0.639594, 0.335938 (0.645 sec)
205.12... logprob:  0.722214, 0.437500 (0.646 sec)
205.13... logprob:  0.658831, 0.359375 (0.646 sec)
205.14... logprob:  0.664380, 0.367188 (0.646 sec)
205.15... logprob:  0.687633, 0.398438 (0.645 sec)
205.16... logprob:  0.627056, 0.320312 (0.646 sec)
205.17... logprob:  0.638519, 0.335938 (0.647 sec)
205.18... logprob:  0.638233, 0.335938 (0.647 sec)
205.19... logprob:  0.632849, 0.328125 (0.646 sec)
205.20... logprob:  0.648659, 0.351562 (0.646 sec)
205.21... logprob:  0.643400, 0.343750 (0.647 sec)
205.22... logprob:  0.628647, 0.320312 (0.645 sec)
205.23... logprob:  0.624128, 0.312500 (0.644 sec)
205.24... logprob:  0.580913, 0.242188 (0.645 sec)
205.25... logprob:  0.628886, 0.320312 (0.646 sec)
205.26... logprob:  0.673049, 0.390625 (0.646 sec)
205.27... logprob:  0.628552, 0.320312 (0.646 sec)
206.1... logprob:  0.678550, 0.398438 (0.646 sec)
206.2... logprob:  0.598230, 0.273438 (0.645 sec)
206.3... logprob:  0.653597, 0.359375 (0.646 sec)
206.4... logprob:  0.597341, 0.273438 (0.646 sec)
206.5... logprob:  0.591280, 0.265625 (0.646 sec)
206.6... logprob:  0.611342, 0.296875 (0.645 sec)
206.7... logprob:  0.643968, 0.343750 (0.646 sec)
206.8... logprob:  0.604274, 0.289062 (0.645 sec)
206.9... logprob:  0.638851, 0.335938 (0.645 sec)
206.10... logprob:  0.596964, 0.281250 (0.645 sec)
206.11... logprob:  0.639587, 0.335938 (0.645 sec)
206.12... logprob:  0.722177, 0.437500 (0.647 sec)
206.13... logprob:  0.658818, 0.359375 (0.646 sec)
206.14... logprob:  0.664369, 0.367188 (0.645 sec)
206.15... logprob:  0.687623, 0.398438 (0.645 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.632939, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957549e-03 [7.340776e-09] 
Layer 'conv1' biases: 2.698298e-07 [2.138127e-10] 
Layer 'conv2' weights[0]: 7.944954e-03 [7.923056e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.102955e-09] 
Layer 'conv3' weights[0]: 7.943124e-03 [6.979348e-09] 
Layer 'conv3' biases: 2.405533e-06 [3.154451e-09] 
Layer 'conv4' weights[0]: 7.975631e-03 [7.194910e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.594901e-08] 
Layer 'conv5' weights[0]: 7.975031e-03 [1.619209e-07] 
Layer 'conv5' biases: 1.000004e+00 [1.747619e-07] 
Layer 'fc6' weights[0]: 7.571448e-03 [1.686017e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.646590e-08] 
Layer 'fc7' weights[0]: 7.639631e-03 [2.278693e-07] 
Layer 'fc7' biases: 9.998582e-01 [2.153617e-07] 
Layer 'fc8' weights[0]: 6.814272e-04 [1.255144e-05] 
Layer 'fc8' biases: 9.779830e-02 [1.835132e-04] 
Train error last 27 batches: 0.636291
-------------------------------------------------------
Not saving because 0.632939 > 0.627114 (197.8: -0.01%)
======================================================= (2.543 sec)
206.16... logprob:  0.627056, 0.320312 (0.644 sec)
206.17... logprob:  0.638519, 0.335938 (0.644 sec)
206.18... logprob:  0.638233, 0.335938 (0.643 sec)
206.19... logprob:  0.632848, 0.328125 (0.644 sec)
206.20... logprob:  0.648662, 0.351562 (0.643 sec)
206.21... logprob:  0.643400, 0.343750 (0.644 sec)
206.22... logprob:  0.628640, 0.320312 (0.643 sec)
206.23... logprob:  0.624118, 0.312500 (0.642 sec)
206.24... logprob:  0.580884, 0.242188 (0.642 sec)
206.25... logprob:  0.628879, 0.320312 (0.644 sec)
206.26... logprob:  0.673058, 0.390625 (0.644 sec)
206.27... logprob:  0.628547, 0.320312 (0.643 sec)
207.1... logprob:  0.678558, 0.398438 (0.643 sec)
207.2... logprob:  0.598223, 0.273438 (0.642 sec)
207.3... logprob:  0.653598, 0.359375 (0.643 sec)
207.4... logprob:  0.597338, 0.273438 (0.643 sec)
207.5... logprob:  0.591281, 0.265625 (0.642 sec)
207.6... logprob:  0.611344, 0.296875 (0.642 sec)
207.7... logprob:  0.643966, 0.343750 (0.643 sec)
207.8... logprob:  0.604282, 0.289062 (0.642 sec)
207.9... logprob:  0.638848, 0.335938 (0.643 sec)
207.10... logprob:  0.596974, 0.281250 (0.642 sec)
207.11... logprob:  0.639579, 0.335938 (0.645 sec)
207.12... logprob:  0.722132, 0.437500 (0.644 sec)
207.13... logprob:  0.658803, 0.359375 (0.643 sec)
207.14... logprob:  0.664354, 0.367188 (0.643 sec)
207.15... logprob:  0.687607, 0.398438 (0.643 sec)
207.16... logprob:  0.627056, 0.320312 (0.643 sec)
207.17... logprob:  0.638520, 0.335938 (0.644 sec)
207.18... logprob:  0.638233, 0.335938 (0.644 sec)
207.19... logprob:  0.632846, 0.328125 (0.644 sec)
207.20... logprob:  0.648664, 0.351562 (0.643 sec)
207.21... logprob:  0.643400, 0.343750 (0.644 sec)
207.22... logprob:  0.628633, 0.320312 (0.643 sec)
207.23... logprob:  0.624108, 0.312500 (0.643 sec)
207.24... logprob:  0.580854, 0.242188 (0.643 sec)
207.25... logprob:  0.628872, 0.320312 (0.643 sec)
207.26... logprob:  0.673068, 0.390625 (0.644 sec)
207.27... logprob:  0.628543, 0.320312 (0.643 sec)
208.1... logprob:  0.678567, 0.398438 (0.643 sec)
208.2... logprob:  0.598211, 0.273438 (0.644 sec)
208.3... logprob:  0.653600, 0.359375 (0.642 sec)
208.4... logprob:  0.597333, 0.273438 (0.643 sec)
208.5... logprob:  0.591279, 0.265625 (0.643 sec)
208.6... logprob:  0.611345, 0.296875 (0.643 sec)
208.7... logprob:  0.643964, 0.343750 (0.643 sec)
208.8... logprob:  0.604287, 0.289062 (0.643 sec)
208.9... logprob:  0.638844, 0.335938 (0.643 sec)
208.10... logprob:  0.596982, 0.281250 (0.642 sec)
208.11... logprob:  0.639572, 0.335938 (0.643 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627490, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957363e-03 [6.564952e-09] 
Layer 'conv1' biases: 2.727649e-07 [1.013383e-10] 
Layer 'conv2' weights[0]: 7.944764e-03 [5.395308e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.846847e-10] 
Layer 'conv3' weights[0]: 7.942931e-03 [5.335733e-09] 
Layer 'conv3' biases: 2.426189e-06 [1.608328e-09] 
Layer 'conv4' weights[0]: 7.975423e-03 [5.560490e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.505072e-08] 
Layer 'conv5' weights[0]: 7.974837e-03 [9.473113e-08] 
Layer 'conv5' biases: 1.000004e+00 [1.024620e-07] 
Layer 'fc6' weights[0]: 7.571242e-03 [1.030812e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.473200e-09] 
Layer 'fc7' weights[0]: 7.637664e-03 [1.368615e-07] 
Layer 'fc7' biases: 9.998584e-01 [1.211881e-07] 
Layer 'fc8' weights[0]: 7.051533e-04 [7.117072e-06] 
Layer 'fc8' biases: 9.908653e-02 [1.294747e-04] 
Train error last 27 batches: 0.636284
-------------------------------------------------------
Not saving because 0.627490 > 0.627114 (197.8: -0.01%)
======================================================= (2.559 sec)
208.12... logprob:  0.722095, 0.437500 (0.642 sec)
208.13... logprob:  0.658790, 0.359375 (0.642 sec)
208.14... logprob:  0.664343, 0.367188 (0.641 sec)
208.15... logprob:  0.687595, 0.398438 (0.642 sec)
208.16... logprob:  0.627056, 0.320312 (0.643 sec)
208.17... logprob:  0.638520, 0.335938 (0.644 sec)
208.18... logprob:  0.638233, 0.335938 (0.646 sec)
208.19... logprob:  0.632845, 0.328125 (0.646 sec)
208.20... logprob:  0.648665, 0.351562 (0.647 sec)
208.21... logprob:  0.643400, 0.343750 (0.647 sec)
208.22... logprob:  0.628627, 0.320312 (0.646 sec)
208.23... logprob:  0.624098, 0.312500 (0.645 sec)
208.24... logprob:  0.580827, 0.242188 (0.646 sec)
208.25... logprob:  0.628865, 0.320312 (0.645 sec)
208.26... logprob:  0.673076, 0.390625 (0.651 sec)
208.27... logprob:  0.628537, 0.320312 (0.654 sec)
209.1... logprob:  0.678573, 0.398438 (0.649 sec)
209.2... logprob:  0.598203, 0.273438 (0.649 sec)
209.3... logprob:  0.653601, 0.359375 (0.650 sec)
209.4... logprob:  0.597329, 0.273438 (0.653 sec)
209.5... logprob:  0.591279, 0.265625 (0.652 sec)
209.6... logprob:  0.611347, 0.296875 (0.653 sec)
209.7... logprob:  0.643962, 0.343750 (0.653 sec)
209.8... logprob:  0.604292, 0.289062 (0.651 sec)
209.9... logprob:  0.638841, 0.335938 (0.650 sec)
209.10... logprob:  0.596990, 0.281250 (0.640 sec)
209.11... logprob:  0.639565, 0.335938 (0.640 sec)
209.12... logprob:  0.722057, 0.437500 (0.641 sec)
209.13... logprob:  0.658777, 0.359375 (0.640 sec)
209.14... logprob:  0.664331, 0.367188 (0.641 sec)
209.15... logprob:  0.687583, 0.398438 (0.641 sec)
209.16... logprob:  0.627056, 0.320312 (0.641 sec)
209.17... logprob:  0.638520, 0.335938 (0.642 sec)
209.18... logprob:  0.638232, 0.335938 (0.642 sec)
209.19... logprob:  0.632843, 0.328125 (0.641 sec)
209.20... logprob:  0.648667, 0.351562 (0.641 sec)
209.21... logprob:  0.643399, 0.343750 (0.642 sec)
209.22... logprob:  0.628620, 0.320312 (0.641 sec)
209.23... logprob:  0.624089, 0.312500 (0.640 sec)
209.24... logprob:  0.580799, 0.242188 (0.641 sec)
209.25... logprob:  0.628858, 0.320312 (0.641 sec)
209.26... logprob:  0.673084, 0.390625 (0.642 sec)
209.27... logprob:  0.628533, 0.320312 (0.641 sec)
210.1... logprob:  0.678580, 0.398438 (0.641 sec)
210.2... logprob:  0.598194, 0.273438 (0.641 sec)
210.3... logprob:  0.653601, 0.359375 (0.640 sec)
210.4... logprob:  0.597325, 0.273438 (0.642 sec)
210.5... logprob:  0.591278, 0.265625 (0.640 sec)
210.6... logprob:  0.611349, 0.296875 (0.639 sec)
210.7... logprob:  0.643961, 0.343750 (0.640 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.655595, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957162e-03 [6.682164e-09] 
Layer 'conv1' biases: 2.761427e-07 [1.310578e-10] 
Layer 'conv2' weights[0]: 7.944563e-03 [5.802305e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.314208e-10] 
Layer 'conv3' weights[0]: 7.942720e-03 [5.737649e-09] 
Layer 'conv3' biases: 2.452906e-06 [1.991337e-09] 
Layer 'conv4' weights[0]: 7.975225e-03 [6.013944e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.882667e-08] 
Layer 'conv5' weights[0]: 7.974645e-03 [1.169485e-07] 
Layer 'conv5' biases: 1.000005e+00 [1.264922e-07] 
Layer 'fc6' weights[0]: 7.571065e-03 [1.240687e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.184614e-08] 
Layer 'fc7' weights[0]: 7.635709e-03 [1.668100e-07] 
Layer 'fc7' biases: 9.998579e-01 [1.529547e-07] 
Layer 'fc8' weights[0]: 6.721338e-04 [8.890055e-06] 
Layer 'fc8' biases: 9.936476e-02 [1.648332e-04] 
Train error last 27 batches: 0.636275
-------------------------------------------------------
Not saving because 0.655595 > 0.627114 (197.8: -0.01%)
======================================================= (1.730 sec)
210.8... logprob:  0.604297, 0.289062 (0.639 sec)
210.9... logprob:  0.638837, 0.335938 (0.640 sec)
210.10... logprob:  0.596999, 0.281250 (0.639 sec)
210.11... logprob:  0.639557, 0.335938 (0.640 sec)
210.12... logprob:  0.722018, 0.437500 (0.641 sec)
210.13... logprob:  0.658763, 0.359375 (0.640 sec)
210.14... logprob:  0.664318, 0.367188 (0.640 sec)
210.15... logprob:  0.687571, 0.398438 (0.640 sec)
210.16... logprob:  0.627056, 0.320312 (0.641 sec)
210.17... logprob:  0.638520, 0.335938 (0.642 sec)
210.18... logprob:  0.638233, 0.335938 (0.641 sec)
210.19... logprob:  0.632842, 0.328125 (0.640 sec)
210.20... logprob:  0.648668, 0.351562 (0.640 sec)
210.21... logprob:  0.643399, 0.343750 (0.642 sec)
210.22... logprob:  0.628614, 0.320312 (0.639 sec)
210.23... logprob:  0.624080, 0.312500 (0.640 sec)
210.24... logprob:  0.580771, 0.242188 (0.640 sec)
210.25... logprob:  0.628851, 0.320312 (0.641 sec)
210.26... logprob:  0.673092, 0.390625 (0.641 sec)
210.27... logprob:  0.628528, 0.320312 (0.640 sec)
211.1... logprob:  0.678588, 0.398438 (0.640 sec)
211.2... logprob:  0.598185, 0.273438 (0.640 sec)
211.3... logprob:  0.653603, 0.359375 (0.640 sec)
211.4... logprob:  0.597322, 0.273438 (0.640 sec)
211.5... logprob:  0.591277, 0.265625 (0.640 sec)
211.6... logprob:  0.611350, 0.296875 (0.640 sec)
211.7... logprob:  0.643959, 0.343750 (0.640 sec)
211.8... logprob:  0.604303, 0.289062 (0.641 sec)
211.9... logprob:  0.638834, 0.335938 (0.639 sec)
211.10... logprob:  0.597007, 0.281250 (0.639 sec)
211.11... logprob:  0.639551, 0.335938 (0.639 sec)
211.12... logprob:  0.721980, 0.437500 (0.641 sec)
211.13... logprob:  0.658750, 0.359375 (0.640 sec)
211.14... logprob:  0.664306, 0.367188 (0.640 sec)
211.15... logprob:  0.687558, 0.398438 (0.640 sec)
211.16... logprob:  0.627056, 0.320312 (0.640 sec)
211.17... logprob:  0.638520, 0.335938 (0.642 sec)
211.18... logprob:  0.638233, 0.335938 (0.641 sec)
211.19... logprob:  0.632840, 0.328125 (0.641 sec)
211.20... logprob:  0.648670, 0.351562 (0.641 sec)
211.21... logprob:  0.643399, 0.343750 (0.650 sec)
211.22... logprob:  0.628607, 0.320312 (0.647 sec)
211.23... logprob:  0.624070, 0.312500 (0.649 sec)
211.24... logprob:  0.580743, 0.242188 (0.649 sec)
211.25... logprob:  0.628844, 0.320312 (0.650 sec)
211.26... logprob:  0.673101, 0.390625 (0.650 sec)
211.27... logprob:  0.628523, 0.320312 (0.649 sec)
212.1... logprob:  0.678596, 0.398438 (0.649 sec)
212.2... logprob:  0.598176, 0.273438 (0.649 sec)
212.3... logprob:  0.653603, 0.359375 (0.649 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.628138, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956960e-03 [6.510041e-09] 
Layer 'conv1' biases: 2.795521e-07 [6.538885e-11] 
Layer 'conv2' weights[0]: 7.944357e-03 [4.818469e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.683660e-10] 
Layer 'conv3' weights[0]: 7.942521e-03 [4.510369e-09] 
Layer 'conv3' biases: 2.479562e-06 [7.735272e-10] 
Layer 'conv4' weights[0]: 7.975024e-03 [4.454692e-09] 
Layer 'conv4' biases: 1.000001e+00 [5.118214e-09] 
Layer 'conv5' weights[0]: 7.974467e-03 [3.264870e-08] 
Layer 'conv5' biases: 1.000005e+00 [3.505436e-08] 
Layer 'fc6' weights[0]: 7.570888e-03 [5.104012e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.236076e-09] 
Layer 'fc7' weights[0]: 7.633758e-03 [6.352071e-08] 
Layer 'fc7' biases: 9.998574e-01 [4.133018e-08] 
Layer 'fc8' weights[0]: 6.397172e-04 [2.389461e-06] 
Layer 'fc8' biases: 9.961608e-02 [5.406048e-05] 
Train error last 27 batches: 0.636266
-------------------------------------------------------
Not saving because 0.628138 > 0.627114 (197.8: -0.01%)
======================================================= (1.820 sec)
212.4... logprob:  0.597318, 0.273438 (0.649 sec)
212.5... logprob:  0.591276, 0.265625 (0.649 sec)
212.6... logprob:  0.611352, 0.296875 (0.649 sec)
212.7... logprob:  0.643957, 0.343750 (0.649 sec)
212.8... logprob:  0.604308, 0.289062 (0.648 sec)
212.9... logprob:  0.638831, 0.335938 (0.648 sec)
212.10... logprob:  0.597016, 0.281250 (0.648 sec)
212.11... logprob:  0.639543, 0.335938 (0.648 sec)
212.12... logprob:  0.721941, 0.437500 (0.650 sec)
212.13... logprob:  0.658736, 0.359375 (0.649 sec)
212.14... logprob:  0.664294, 0.367188 (0.648 sec)
212.15... logprob:  0.687545, 0.398438 (0.649 sec)
212.16... logprob:  0.627056, 0.320312 (0.649 sec)
212.17... logprob:  0.638520, 0.335938 (0.651 sec)
212.18... logprob:  0.638232, 0.335938 (0.650 sec)
212.19... logprob:  0.632838, 0.328125 (0.650 sec)
212.20... logprob:  0.648672, 0.351562 (0.649 sec)
212.21... logprob:  0.643398, 0.343750 (0.650 sec)
212.22... logprob:  0.628601, 0.320312 (0.649 sec)
212.23... logprob:  0.624061, 0.312500 (0.649 sec)
212.24... logprob:  0.580717, 0.242188 (0.649 sec)
212.25... logprob:  0.628838, 0.320312 (0.650 sec)
212.26... logprob:  0.673108, 0.390625 (0.650 sec)
212.27... logprob:  0.628518, 0.320312 (0.649 sec)
213.1... logprob:  0.678603, 0.398438 (0.649 sec)
213.2... logprob:  0.598165, 0.273438 (0.649 sec)
213.3... logprob:  0.653605, 0.359375 (0.649 sec)
213.4... logprob:  0.597312, 0.273438 (0.649 sec)
213.5... logprob:  0.591273, 0.265625 (0.649 sec)
213.6... logprob:  0.611352, 0.296875 (0.649 sec)
213.7... logprob:  0.643956, 0.343750 (0.649 sec)
213.8... logprob:  0.604312, 0.289062 (0.649 sec)
213.9... logprob:  0.638828, 0.335938 (0.649 sec)
213.10... logprob:  0.597022, 0.281250 (0.648 sec)
213.11... logprob:  0.639538, 0.335938 (0.649 sec)
213.12... logprob:  0.721906, 0.437500 (0.650 sec)
213.13... logprob:  0.658725, 0.359375 (0.649 sec)
213.14... logprob:  0.664284, 0.367188 (0.648 sec)
213.15... logprob:  0.687534, 0.398438 (0.648 sec)
213.16... logprob:  0.627056, 0.320312 (0.649 sec)
213.17... logprob:  0.638521, 0.335938 (0.651 sec)
213.18... logprob:  0.638232, 0.335938 (0.650 sec)
213.19... logprob:  0.632837, 0.328125 (0.649 sec)
213.20... logprob:  0.648673, 0.351562 (0.650 sec)
213.21... logprob:  0.643398, 0.343750 (0.650 sec)
213.22... logprob:  0.628594, 0.320312 (0.649 sec)
213.23... logprob:  0.624052, 0.312500 (0.649 sec)
213.24... logprob:  0.580688, 0.242188 (0.649 sec)
213.25... logprob:  0.628831, 0.320312 (0.649 sec)
213.26... logprob:  0.673116, 0.390625 (0.650 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633477, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956755e-03 [6.242245e-09] 
Layer 'conv1' biases: 2.827992e-07 [5.938466e-11] 
Layer 'conv2' weights[0]: 7.944170e-03 [4.794779e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.351206e-10] 
Layer 'conv3' weights[0]: 7.942336e-03 [4.410075e-09] 
Layer 'conv3' biases: 2.504120e-06 [6.956286e-10] 
Layer 'conv4' weights[0]: 7.974835e-03 [4.353055e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.878755e-09] 
Layer 'conv5' weights[0]: 7.974279e-03 [2.418769e-08] 
Layer 'conv5' biases: 1.000005e+00 [2.590645e-08] 
Layer 'fc6' weights[0]: 7.570686e-03 [4.609706e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.396398e-09] 
Layer 'fc7' weights[0]: 7.631818e-03 [5.459644e-08] 
Layer 'fc7' biases: 9.998573e-01 [3.059339e-08] 
Layer 'fc8' weights[0]: 6.311032e-04 [1.750542e-06] 
Layer 'fc8' biases: 1.003157e-01 [4.792184e-05] 
Train error last 27 batches: 0.636257
-------------------------------------------------------
Not saving because 0.633477 > 0.627114 (197.8: -0.01%)
======================================================= (1.831 sec)
213.27... logprob:  0.628514, 0.320312 (0.649 sec)
214.1... logprob:  0.678610, 0.398438 (0.649 sec)
214.2... logprob:  0.598159, 0.273438 (0.649 sec)
214.3... logprob:  0.653606, 0.359375 (0.649 sec)
214.4... logprob:  0.597310, 0.273438 (0.649 sec)
214.5... logprob:  0.591276, 0.265625 (0.649 sec)
214.6... logprob:  0.611356, 0.296875 (0.649 sec)
214.7... logprob:  0.643954, 0.343750 (0.649 sec)
214.8... logprob:  0.604320, 0.289062 (0.649 sec)
214.9... logprob:  0.638824, 0.335938 (0.648 sec)
214.10... logprob:  0.597033, 0.281250 (0.649 sec)
214.11... logprob:  0.639529, 0.335938 (0.649 sec)
214.12... logprob:  0.721862, 0.437500 (0.650 sec)
214.13... logprob:  0.658709, 0.359375 (0.649 sec)
214.14... logprob:  0.664270, 0.367188 (0.649 sec)
214.15... logprob:  0.687520, 0.398438 (0.649 sec)
214.16... logprob:  0.627056, 0.320312 (0.649 sec)
214.17... logprob:  0.638520, 0.335938 (0.651 sec)
214.18... logprob:  0.638232, 0.335938 (0.650 sec)
214.19... logprob:  0.632835, 0.328125 (0.650 sec)
214.20... logprob:  0.648675, 0.351562 (0.649 sec)
214.21... logprob:  0.643398, 0.343750 (0.651 sec)
214.22... logprob:  0.628588, 0.320312 (0.649 sec)
214.23... logprob:  0.624042, 0.312500 (0.649 sec)
214.24... logprob:  0.580660, 0.242188 (0.649 sec)
214.25... logprob:  0.628824, 0.320312 (0.650 sec)
214.26... logprob:  0.673126, 0.390625 (0.650 sec)
214.27... logprob:  0.628508, 0.320312 (0.650 sec)
215.1... logprob:  0.678619, 0.398438 (0.649 sec)
215.2... logprob:  0.598147, 0.273438 (0.649 sec)
215.3... logprob:  0.653608, 0.359375 (0.649 sec)
215.4... logprob:  0.597303, 0.273438 (0.649 sec)
215.5... logprob:  0.591271, 0.265625 (0.649 sec)
215.6... logprob:  0.611355, 0.296875 (0.649 sec)
215.7... logprob:  0.643953, 0.343750 (0.649 sec)
215.8... logprob:  0.604324, 0.289062 (0.649 sec)
215.9... logprob:  0.638821, 0.335938 (0.649 sec)
215.10... logprob:  0.597040, 0.281250 (0.648 sec)
215.11... logprob:  0.639523, 0.335938 (0.649 sec)
215.12... logprob:  0.721827, 0.437500 (0.651 sec)
215.13... logprob:  0.658697, 0.359375 (0.649 sec)
215.14... logprob:  0.664258, 0.367188 (0.649 sec)
215.15... logprob:  0.687508, 0.398438 (0.649 sec)
215.16... logprob:  0.627056, 0.320312 (0.649 sec)
215.17... logprob:  0.638521, 0.335938 (0.651 sec)
215.18... logprob:  0.638232, 0.335938 (0.650 sec)
215.19... logprob:  0.632834, 0.328125 (0.650 sec)
215.20... logprob:  0.648677, 0.351562 (0.649 sec)
215.21... logprob:  0.643398, 0.343750 (0.651 sec)
215.22... logprob:  0.628581, 0.320312 (0.649 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.682464, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956549e-03 [6.547175e-09] 
Layer 'conv1' biases: 2.860186e-07 [1.255475e-10] 
Layer 'conv2' weights[0]: 7.943974e-03 [5.786194e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.517604e-10] 
Layer 'conv3' weights[0]: 7.942152e-03 [5.152513e-09] 
Layer 'conv3' biases: 2.528626e-06 [1.522456e-09] 
Layer 'conv4' weights[0]: 7.974642e-03 [5.097466e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.052850e-08] 
Layer 'conv5' weights[0]: 7.974080e-03 [6.523847e-08] 
Layer 'conv5' biases: 1.000005e+00 [7.005346e-08] 
Layer 'fc6' weights[0]: 7.570480e-03 [7.811416e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.726988e-09] 
Layer 'fc7' weights[0]: 7.629876e-03 [1.056994e-07] 
Layer 'fc7' biases: 9.998572e-01 [8.845794e-08] 
Layer 'fc8' weights[0]: 6.241007e-04 [5.070601e-06] 
Layer 'fc8' biases: 1.010186e-01 [7.223368e-05] 
Train error last 27 batches: 0.636249
-------------------------------------------------------
Not saving because 0.682464 > 0.627114 (197.8: -0.01%)
======================================================= (1.768 sec)
215.23... logprob:  0.624033, 0.312500 (0.649 sec)
215.24... logprob:  0.580634, 0.242188 (0.649 sec)
215.25... logprob:  0.628817, 0.320312 (0.650 sec)
215.26... logprob:  0.673133, 0.390625 (0.650 sec)
215.27... logprob:  0.628504, 0.320312 (0.649 sec)
216.1... logprob:  0.678625, 0.398438 (0.649 sec)
216.2... logprob:  0.598140, 0.273438 (0.649 sec)
216.3... logprob:  0.653608, 0.359375 (0.649 sec)
216.4... logprob:  0.597301, 0.273438 (0.649 sec)
216.5... logprob:  0.591272, 0.265625 (0.649 sec)
216.6... logprob:  0.611358, 0.296875 (0.648 sec)
216.7... logprob:  0.643951, 0.343750 (0.649 sec)
216.8... logprob:  0.604330, 0.289062 (0.648 sec)
216.9... logprob:  0.638818, 0.335938 (0.648 sec)
216.10... logprob:  0.597048, 0.281250 (0.648 sec)
216.11... logprob:  0.639516, 0.335938 (0.649 sec)
216.12... logprob:  0.721787, 0.437500 (0.649 sec)
216.13... logprob:  0.658684, 0.359375 (0.649 sec)
216.14... logprob:  0.664246, 0.367188 (0.649 sec)
216.15... logprob:  0.687495, 0.398438 (0.649 sec)
216.16... logprob:  0.627056, 0.320312 (0.650 sec)
216.17... logprob:  0.638521, 0.335938 (0.651 sec)
216.18... logprob:  0.638232, 0.335938 (0.650 sec)
216.19... logprob:  0.632832, 0.328125 (0.653 sec)
216.20... logprob:  0.648678, 0.351562 (0.650 sec)
216.21... logprob:  0.643398, 0.343750 (0.650 sec)
216.22... logprob:  0.628576, 0.320312 (0.650 sec)
216.23... logprob:  0.624024, 0.312500 (0.649 sec)
216.24... logprob:  0.580606, 0.242188 (0.649 sec)
216.25... logprob:  0.628811, 0.320312 (0.651 sec)
216.26... logprob:  0.673142, 0.390625 (0.650 sec)
216.27... logprob:  0.628499, 0.320312 (0.650 sec)
217.1... logprob:  0.678633, 0.398438 (0.650 sec)
217.2... logprob:  0.598130, 0.273438 (0.650 sec)
217.3... logprob:  0.653610, 0.359375 (0.649 sec)
217.4... logprob:  0.597296, 0.273438 (0.649 sec)
217.5... logprob:  0.591270, 0.265625 (0.649 sec)
217.6... logprob:  0.611359, 0.296875 (0.649 sec)
217.7... logprob:  0.643949, 0.343750 (0.649 sec)
217.8... logprob:  0.604335, 0.289062 (0.650 sec)
217.9... logprob:  0.638815, 0.335938 (0.649 sec)
217.10... logprob:  0.597056, 0.281250 (0.649 sec)
217.11... logprob:  0.639509, 0.335938 (0.649 sec)
217.12... logprob:  0.721751, 0.437500 (0.650 sec)
217.13... logprob:  0.658671, 0.359375 (0.649 sec)
217.14... logprob:  0.664234, 0.367188 (0.648 sec)
217.15... logprob:  0.687484, 0.398438 (0.649 sec)
217.16... logprob:  0.627056, 0.320312 (0.649 sec)
217.17... logprob:  0.638521, 0.335938 (0.651 sec)
217.18... logprob:  0.638232, 0.335938 (0.650 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.632975, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956360e-03 [6.556718e-09] 
Layer 'conv1' biases: 2.889894e-07 [1.760451e-10] 
Layer 'conv2' weights[0]: 7.943784e-03 [6.905811e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.822473e-10] 
Layer 'conv3' weights[0]: 7.941969e-03 [6.177303e-09] 
Layer 'conv3' biases: 2.549677e-06 [2.505974e-09] 
Layer 'conv4' weights[0]: 7.974442e-03 [6.271325e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.996574e-08] 
Layer 'conv5' weights[0]: 7.973871e-03 [1.235140e-07] 
Layer 'conv5' biases: 1.000005e+00 [1.329867e-07] 
Layer 'fc6' weights[0]: 7.570286e-03 [1.313143e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.266063e-08] 
Layer 'fc7' weights[0]: 7.627940e-03 [1.775193e-07] 
Layer 'fc7' biases: 9.998575e-01 [1.647283e-07] 
Layer 'fc8' weights[0]: 6.481776e-04 [9.516254e-06] 
Layer 'fc8' biases: 1.023458e-01 [1.436579e-04] 
Train error last 27 batches: 0.636240
-------------------------------------------------------
Not saving because 0.632975 > 0.627114 (197.8: -0.01%)
======================================================= (1.743 sec)
217.19... logprob:  0.632832, 0.328125 (0.647 sec)
217.20... logprob:  0.648681, 0.351562 (0.646 sec)
217.21... logprob:  0.643398, 0.343750 (0.650 sec)
217.22... logprob:  0.628569, 0.320312 (0.649 sec)
217.23... logprob:  0.624014, 0.312500 (0.654 sec)
217.24... logprob:  0.580578, 0.242188 (0.661 sec)
217.25... logprob:  0.628804, 0.320312 (0.663 sec)
217.26... logprob:  0.673150, 0.390625 (0.655 sec)
217.27... logprob:  0.628495, 0.320312 (0.655 sec)
218.1... logprob:  0.678640, 0.398438 (0.653 sec)
218.2... logprob:  0.598122, 0.273438 (0.653 sec)
218.3... logprob:  0.653611, 0.359375 (0.650 sec)
218.4... logprob:  0.597293, 0.273438 (0.655 sec)
218.5... logprob:  0.591270, 0.265625 (0.657 sec)
218.6... logprob:  0.611362, 0.296875 (0.656 sec)
218.7... logprob:  0.643948, 0.343750 (0.648 sec)
218.8... logprob:  0.604342, 0.289062 (0.653 sec)
218.9... logprob:  0.638811, 0.335938 (0.653 sec)
218.10... logprob:  0.597066, 0.281250 (0.657 sec)
218.11... logprob:  0.639502, 0.335938 (0.651 sec)
218.12... logprob:  0.721709, 0.437500 (0.657 sec)
218.13... logprob:  0.658656, 0.359375 (0.660 sec)
218.14... logprob:  0.664221, 0.367188 (0.661 sec)
218.15... logprob:  0.687469, 0.398438 (0.651 sec)
218.16... logprob:  0.627056, 0.320312 (0.660 sec)
218.17... logprob:  0.638521, 0.335938 (0.661 sec)
218.18... logprob:  0.638232, 0.335938 (0.658 sec)
218.19... logprob:  0.632829, 0.328125 (0.659 sec)
218.20... logprob:  0.648683, 0.351562 (0.665 sec)
218.21... logprob:  0.643397, 0.343750 (0.651 sec)
218.22... logprob:  0.628563, 0.320312 (0.656 sec)
218.23... logprob:  0.624005, 0.312500 (0.656 sec)
218.24... logprob:  0.580550, 0.242188 (0.660 sec)
218.25... logprob:  0.628797, 0.320312 (0.658 sec)
218.26... logprob:  0.673159, 0.390625 (0.661 sec)
218.27... logprob:  0.628489, 0.320312 (0.657 sec)
219.1... logprob:  0.678649, 0.398438 (0.665 sec)
219.2... logprob:  0.598112, 0.273438 (0.672 sec)
219.3... logprob:  0.653612, 0.359375 (0.671 sec)
219.4... logprob:  0.597288, 0.273438 (0.667 sec)
219.5... logprob:  0.591268, 0.265625 (0.657 sec)
219.6... logprob:  0.611362, 0.296875 (0.655 sec)
219.7... logprob:  0.643946, 0.343750 (0.659 sec)
219.8... logprob:  0.604346, 0.289062 (0.657 sec)
219.9... logprob:  0.638808, 0.335938 (0.662 sec)
219.10... logprob:  0.597073, 0.281250 (0.671 sec)
219.11... logprob:  0.639495, 0.335938 (0.672 sec)
219.12... logprob:  0.721674, 0.437500 (0.671 sec)
219.13... logprob:  0.658644, 0.359375 (0.656 sec)
219.14... logprob:  0.664210, 0.367188 (0.659 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627190, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956158e-03 [6.775498e-09] 
Layer 'conv1' biases: 2.918681e-07 [1.576481e-10] 
Layer 'conv2' weights[0]: 7.943600e-03 [6.489224e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.561928e-10] 
Layer 'conv3' weights[0]: 7.941774e-03 [5.734952e-09] 
Layer 'conv3' biases: 2.569675e-06 [2.127423e-09] 
Layer 'conv4' weights[0]: 7.974248e-03 [5.786901e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.619374e-08] 
Layer 'conv5' weights[0]: 7.973673e-03 [1.002144e-07] 
Layer 'conv5' biases: 1.000004e+00 [1.078560e-07] 
Layer 'fc6' weights[0]: 7.570097e-03 [1.095232e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.029478e-08] 
Layer 'fc7' weights[0]: 7.625993e-03 [1.476401e-07] 
Layer 'fc7' biases: 9.998580e-01 [1.336767e-07] 
Layer 'fc8' weights[0]: 6.853311e-04 [7.726278e-06] 
Layer 'fc8' biases: 1.038840e-01 [1.089416e-04] 
Train error last 27 batches: 0.636231
-------------------------------------------------------
Not saving because 0.627190 > 0.627114 (197.8: -0.01%)
======================================================= (1.775 sec)
219.15... logprob:  0.687457, 0.398438 (0.671 sec)
219.16... logprob:  0.627056, 0.320312 (0.670 sec)
219.17... logprob:  0.638521, 0.335938 (0.672 sec)
219.18... logprob:  0.638232, 0.335938 (0.672 sec)
219.19... logprob:  0.632829, 0.328125 (0.672 sec)
219.20... logprob:  0.648684, 0.351562 (0.671 sec)
219.21... logprob:  0.643397, 0.343750 (0.672 sec)
219.22... logprob:  0.628556, 0.320312 (0.670 sec)
219.23... logprob:  0.623997, 0.312500 (0.671 sec)
219.24... logprob:  0.580524, 0.242188 (0.671 sec)
219.25... logprob:  0.628791, 0.320312 (0.672 sec)
219.26... logprob:  0.673167, 0.390625 (0.672 sec)
219.27... logprob:  0.628485, 0.320312 (0.671 sec)
220.1... logprob:  0.678656, 0.398438 (0.671 sec)
220.2... logprob:  0.598103, 0.273438 (0.671 sec)
220.3... logprob:  0.653613, 0.359375 (0.671 sec)
220.4... logprob:  0.597284, 0.273438 (0.671 sec)
220.5... logprob:  0.591268, 0.265625 (0.672 sec)
220.6... logprob:  0.611364, 0.296875 (0.671 sec)
220.7... logprob:  0.643945, 0.343750 (0.670 sec)
220.8... logprob:  0.604351, 0.289062 (0.667 sec)
220.9... logprob:  0.638805, 0.335938 (0.655 sec)
220.10... logprob:  0.597082, 0.281250 (0.653 sec)
220.11... logprob:  0.639489, 0.335938 (0.660 sec)
220.12... logprob:  0.721637, 0.437500 (0.669 sec)
220.13... logprob:  0.658632, 0.359375 (0.668 sec)
220.14... logprob:  0.664199, 0.367188 (0.660 sec)
220.15... logprob:  0.687446, 0.398438 (0.653 sec)
220.16... logprob:  0.627056, 0.320312 (0.664 sec)
220.17... logprob:  0.638521, 0.335938 (0.673 sec)
220.18... logprob:  0.638232, 0.335938 (0.672 sec)
220.19... logprob:  0.632827, 0.328125 (0.668 sec)
220.20... logprob:  0.648686, 0.351562 (0.657 sec)
220.21... logprob:  0.643398, 0.343750 (0.656 sec)
220.22... logprob:  0.628550, 0.320312 (0.661 sec)
220.23... logprob:  0.623987, 0.312500 (0.661 sec)
220.24... logprob:  0.580497, 0.242188 (0.652 sec)
220.25... logprob:  0.628784, 0.320312 (0.652 sec)
220.26... logprob:  0.673175, 0.390625 (0.655 sec)
220.27... logprob:  0.628481, 0.320312 (0.652 sec)
221.1... logprob:  0.678663, 0.398438 (0.654 sec)
221.2... logprob:  0.598095, 0.273438 (0.655 sec)
221.3... logprob:  0.653614, 0.359375 (0.655 sec)
221.4... logprob:  0.597281, 0.273438 (0.653 sec)
221.5... logprob:  0.591267, 0.265625 (0.655 sec)
221.6... logprob:  0.611366, 0.296875 (0.656 sec)
221.7... logprob:  0.643943, 0.343750 (0.659 sec)
221.8... logprob:  0.604357, 0.289062 (0.654 sec)
221.9... logprob:  0.638801, 0.335938 (0.655 sec)
221.10... logprob:  0.597091, 0.281250 (0.652 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.657995, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955964e-03 [6.835511e-09] 
Layer 'conv1' biases: 2.949974e-07 [1.321322e-10] 
Layer 'conv2' weights[0]: 7.943405e-03 [6.005456e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.795619e-10] 
Layer 'conv3' weights[0]: 7.941570e-03 [5.957435e-09] 
Layer 'conv3' biases: 2.592594e-06 [2.147558e-09] 
Layer 'conv4' weights[0]: 7.974058e-03 [6.281400e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.023189e-08] 
Layer 'conv5' weights[0]: 7.973472e-03 [1.252493e-07] 
Layer 'conv5' biases: 1.000004e+00 [1.350978e-07] 
Layer 'fc6' weights[0]: 7.569910e-03 [1.322376e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.271519e-08] 
Layer 'fc7' weights[0]: 7.624050e-03 [1.755856e-07] 
Layer 'fc7' biases: 9.998580e-01 [1.619391e-07] 
Layer 'fc8' weights[0]: 6.906294e-04 [9.421683e-06] 
Layer 'fc8' biases: 1.048257e-01 [1.711094e-04] 
Train error last 27 batches: 0.636225
-------------------------------------------------------
Not saving because 0.657995 > 0.627114 (197.8: -0.01%)
======================================================= (1.741 sec)
221.11... logprob:  0.639482, 0.335938 (0.648 sec)
221.12... logprob:  0.721597, 0.437500 (0.649 sec)
221.13... logprob:  0.658618, 0.359375 (0.652 sec)
221.14... logprob:  0.664186, 0.367188 (0.649 sec)
221.15... logprob:  0.687432, 0.398438 (0.648 sec)
221.16... logprob:  0.627056, 0.320312 (0.649 sec)
221.17... logprob:  0.638522, 0.335938 (0.650 sec)
221.18... logprob:  0.638231, 0.335938 (0.649 sec)
221.19... logprob:  0.632825, 0.328125 (0.649 sec)
221.20... logprob:  0.648688, 0.351562 (0.649 sec)
221.21... logprob:  0.643397, 0.343750 (0.650 sec)
221.22... logprob:  0.628544, 0.320312 (0.648 sec)
221.23... logprob:  0.623979, 0.312500 (0.648 sec)
221.24... logprob:  0.580470, 0.242188 (0.648 sec)
221.25... logprob:  0.628778, 0.320312 (0.649 sec)
221.26... logprob:  0.673184, 0.390625 (0.649 sec)
221.27... logprob:  0.628476, 0.320312 (0.649 sec)
222.1... logprob:  0.678672, 0.398438 (0.649 sec)
222.2... logprob:  0.598085, 0.273438 (0.649 sec)
222.3... logprob:  0.653616, 0.359375 (0.648 sec)
222.4... logprob:  0.597275, 0.273438 (0.649 sec)
222.5... logprob:  0.591264, 0.265625 (0.648 sec)
222.6... logprob:  0.611366, 0.296875 (0.648 sec)
222.7... logprob:  0.643941, 0.343750 (0.648 sec)
222.8... logprob:  0.604361, 0.289062 (0.648 sec)
222.9... logprob:  0.638799, 0.335938 (0.648 sec)
222.10... logprob:  0.597098, 0.281250 (0.648 sec)
222.11... logprob:  0.639476, 0.335938 (0.648 sec)
222.12... logprob:  0.721563, 0.437500 (0.650 sec)
222.13... logprob:  0.658606, 0.359375 (0.649 sec)
222.14... logprob:  0.664175, 0.367188 (0.648 sec)
222.15... logprob:  0.687421, 0.398438 (0.648 sec)
222.16... logprob:  0.627056, 0.320312 (0.649 sec)
222.17... logprob:  0.638521, 0.335938 (0.649 sec)
222.18... logprob:  0.638232, 0.335938 (0.649 sec)
222.19... logprob:  0.632824, 0.328125 (0.649 sec)
222.20... logprob:  0.648690, 0.351562 (0.649 sec)
222.21... logprob:  0.643397, 0.343750 (0.649 sec)
222.22... logprob:  0.628538, 0.320312 (0.648 sec)
222.23... logprob:  0.623970, 0.312500 (0.648 sec)
222.24... logprob:  0.580444, 0.242188 (0.648 sec)
222.25... logprob:  0.628771, 0.320312 (0.649 sec)
222.26... logprob:  0.673191, 0.390625 (0.649 sec)
222.27... logprob:  0.628471, 0.320312 (0.649 sec)
223.1... logprob:  0.678678, 0.398438 (0.648 sec)
223.2... logprob:  0.598077, 0.273438 (0.648 sec)
223.3... logprob:  0.653617, 0.359375 (0.648 sec)
223.4... logprob:  0.597272, 0.273438 (0.648 sec)
223.5... logprob:  0.591265, 0.265625 (0.648 sec)
223.6... logprob:  0.611368, 0.296875 (0.648 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627310, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955767e-03 [7.153516e-09] 
Layer 'conv1' biases: 2.984344e-07 [1.667124e-10] 
Layer 'conv2' weights[0]: 7.943213e-03 [6.309054e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.952355e-10] 
Layer 'conv3' weights[0]: 7.941380e-03 [6.210492e-09] 
Layer 'conv3' biases: 2.619861e-06 [2.374918e-09] 
Layer 'conv4' weights[0]: 7.973866e-03 [6.479868e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.239935e-08] 
Layer 'conv5' weights[0]: 7.973270e-03 [1.381398e-07] 
Layer 'conv5' biases: 1.000004e+00 [1.489572e-07] 
Layer 'fc6' weights[0]: 7.569719e-03 [1.458591e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.412577e-08] 
Layer 'fc7' weights[0]: 7.622118e-03 [1.941018e-07] 
Layer 'fc7' biases: 9.998573e-01 [1.809004e-07] 
Layer 'fc8' weights[0]: 6.571112e-04 [1.044737e-05] 
Layer 'fc8' biases: 1.050459e-01 [1.966069e-04] 
Train error last 27 batches: 0.636216
-------------------------------------------------------
Not saving because 0.627310 > 0.627114 (197.8: -0.01%)
======================================================= (1.735 sec)
223.7... logprob:  0.643940, 0.343750 (0.648 sec)
223.8... logprob:  0.604367, 0.289062 (0.648 sec)
223.9... logprob:  0.638795, 0.335938 (0.648 sec)
223.10... logprob:  0.597107, 0.281250 (0.649 sec)
223.11... logprob:  0.639469, 0.335938 (0.648 sec)
223.12... logprob:  0.721524, 0.437500 (0.649 sec)
223.13... logprob:  0.658593, 0.359375 (0.649 sec)
223.14... logprob:  0.664162, 0.367188 (0.648 sec)
223.15... logprob:  0.687407, 0.398438 (0.648 sec)
223.16... logprob:  0.627056, 0.320312 (0.649 sec)
223.17... logprob:  0.638521, 0.335938 (0.650 sec)
223.18... logprob:  0.638231, 0.335938 (0.649 sec)
223.19... logprob:  0.632823, 0.328125 (0.649 sec)
223.20... logprob:  0.648691, 0.351562 (0.649 sec)
223.21... logprob:  0.643397, 0.343750 (0.650 sec)
223.22... logprob:  0.628532, 0.320312 (0.648 sec)
223.23... logprob:  0.623962, 0.312500 (0.648 sec)
223.24... logprob:  0.580418, 0.242188 (0.648 sec)
223.25... logprob:  0.628765, 0.320312 (0.648 sec)
223.26... logprob:  0.673199, 0.390625 (0.649 sec)
223.27... logprob:  0.628467, 0.320312 (0.648 sec)
224.1... logprob:  0.678686, 0.398438 (0.648 sec)
224.2... logprob:  0.598067, 0.273438 (0.649 sec)
224.3... logprob:  0.653618, 0.359375 (0.648 sec)
224.4... logprob:  0.597267, 0.273438 (0.649 sec)
224.5... logprob:  0.591262, 0.265625 (0.648 sec)
224.6... logprob:  0.611369, 0.296875 (0.648 sec)
224.7... logprob:  0.643938, 0.343750 (0.648 sec)
224.8... logprob:  0.604372, 0.289062 (0.648 sec)
224.9... logprob:  0.638793, 0.335938 (0.647 sec)
224.10... logprob:  0.597113, 0.281250 (0.648 sec)
224.11... logprob:  0.639463, 0.335938 (0.648 sec)
224.12... logprob:  0.721491, 0.437500 (0.649 sec)
224.13... logprob:  0.658581, 0.359375 (0.648 sec)
224.14... logprob:  0.664151, 0.367188 (0.648 sec)
224.15... logprob:  0.687396, 0.398438 (0.647 sec)
224.16... logprob:  0.627056, 0.320312 (0.648 sec)
224.17... logprob:  0.638521, 0.335938 (0.650 sec)
224.18... logprob:  0.638231, 0.335938 (0.649 sec)
224.19... logprob:  0.632821, 0.328125 (0.649 sec)
224.20... logprob:  0.648693, 0.351562 (0.649 sec)
224.21... logprob:  0.643397, 0.343750 (0.649 sec)
224.22... logprob:  0.628527, 0.320312 (0.648 sec)
224.23... logprob:  0.623953, 0.312500 (0.648 sec)
224.24... logprob:  0.580393, 0.242188 (0.648 sec)
224.25... logprob:  0.628759, 0.320312 (0.649 sec)
224.26... logprob:  0.673207, 0.390625 (0.649 sec)
224.27... logprob:  0.628462, 0.320312 (0.648 sec)
225.1... logprob:  0.678693, 0.398438 (0.649 sec)
225.2... logprob:  0.598058, 0.273438 (0.649 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633255, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955562e-03 [6.637791e-09] 
Layer 'conv1' biases: 3.018409e-07 [7.449014e-11] 
Layer 'conv2' weights[0]: 7.943043e-03 [4.910572e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.413576e-10] 
Layer 'conv3' weights[0]: 7.941189e-03 [4.673044e-09] 
Layer 'conv3' biases: 2.646414e-06 [9.836227e-10] 
Layer 'conv4' weights[0]: 7.973673e-03 [4.658219e-09] 
Layer 'conv4' biases: 1.000001e+00 [7.519502e-09] 
Layer 'conv5' weights[0]: 7.973079e-03 [4.655065e-08] 
Layer 'conv5' biases: 1.000004e+00 [5.008016e-08] 
Layer 'fc6' weights[0]: 7.569499e-03 [6.135135e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.710665e-09] 
Layer 'fc7' weights[0]: 7.620174e-03 [7.957784e-08] 
Layer 'fc7' biases: 9.998571e-01 [5.992470e-08] 
Layer 'fc8' weights[0]: 6.316907e-04 [3.431958e-06] 
Layer 'fc8' biases: 1.053935e-01 [7.528065e-05] 
Train error last 27 batches: 0.636207
-------------------------------------------------------
Not saving because 0.633255 > 0.627114 (197.8: -0.01%)
======================================================= (1.792 sec)
225.3... logprob:  0.653619, 0.359375 (0.648 sec)
225.4... logprob:  0.597263, 0.273438 (0.648 sec)
225.5... logprob:  0.591261, 0.265625 (0.648 sec)
225.6... logprob:  0.611370, 0.296875 (0.648 sec)
225.7... logprob:  0.643937, 0.343750 (0.648 sec)
225.8... logprob:  0.604377, 0.289062 (0.648 sec)
225.9... logprob:  0.638790, 0.335938 (0.648 sec)
225.10... logprob:  0.597122, 0.281250 (0.648 sec)
225.11... logprob:  0.639456, 0.335938 (0.649 sec)
225.12... logprob:  0.721453, 0.437500 (0.649 sec)
225.13... logprob:  0.658568, 0.359375 (0.649 sec)
225.14... logprob:  0.664140, 0.367188 (0.647 sec)
225.15... logprob:  0.687384, 0.398438 (0.648 sec)
225.16... logprob:  0.627056, 0.320312 (0.648 sec)
225.17... logprob:  0.638521, 0.335938 (0.650 sec)
225.18... logprob:  0.638232, 0.335938 (0.649 sec)
225.19... logprob:  0.632820, 0.328125 (0.649 sec)
225.20... logprob:  0.648695, 0.351562 (0.649 sec)
225.21... logprob:  0.643396, 0.343750 (0.650 sec)
225.22... logprob:  0.628520, 0.320312 (0.648 sec)
225.23... logprob:  0.623943, 0.312500 (0.648 sec)
225.24... logprob:  0.580364, 0.242188 (0.648 sec)
225.25... logprob:  0.628752, 0.320312 (0.648 sec)
225.26... logprob:  0.673216, 0.390625 (0.649 sec)
225.27... logprob:  0.628458, 0.320312 (0.648 sec)
226.1... logprob:  0.678700, 0.398438 (0.647 sec)
226.2... logprob:  0.598050, 0.273438 (0.648 sec)
226.3... logprob:  0.653620, 0.359375 (0.648 sec)
226.4... logprob:  0.597260, 0.273438 (0.648 sec)
226.5... logprob:  0.591261, 0.265625 (0.648 sec)
226.6... logprob:  0.611373, 0.296875 (0.648 sec)
226.7... logprob:  0.643935, 0.343750 (0.648 sec)
226.8... logprob:  0.604383, 0.289062 (0.648 sec)
226.9... logprob:  0.638786, 0.335938 (0.647 sec)
226.10... logprob:  0.597132, 0.281250 (0.647 sec)
226.11... logprob:  0.639449, 0.335938 (0.648 sec)
226.12... logprob:  0.721412, 0.437500 (0.649 sec)
226.13... logprob:  0.658554, 0.359375 (0.648 sec)
226.14... logprob:  0.664127, 0.367188 (0.648 sec)
226.15... logprob:  0.687370, 0.398438 (0.648 sec)
226.16... logprob:  0.627056, 0.320312 (0.649 sec)
226.17... logprob:  0.638522, 0.335938 (0.651 sec)
226.18... logprob:  0.638231, 0.335938 (0.650 sec)
226.19... logprob:  0.632819, 0.328125 (0.649 sec)
226.20... logprob:  0.648696, 0.351562 (0.649 sec)
226.21... logprob:  0.643397, 0.343750 (0.649 sec)
226.22... logprob:  0.628514, 0.320312 (0.648 sec)
226.23... logprob:  0.623935, 0.312500 (0.648 sec)
226.24... logprob:  0.580338, 0.242188 (0.648 sec)
226.25... logprob:  0.628746, 0.320312 (0.649 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.683221, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955364e-03 [6.398698e-09] 
Layer 'conv1' biases: 3.051068e-07 [7.359205e-11] 
Layer 'conv2' weights[0]: 7.942838e-03 [4.893853e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.866121e-10] 
Layer 'conv3' weights[0]: 7.940981e-03 [4.735294e-09] 
Layer 'conv3' biases: 2.671194e-06 [1.144665e-09] 
Layer 'conv4' weights[0]: 7.973490e-03 [4.804499e-09] 
Layer 'conv4' biases: 1.000001e+00 [9.708608e-09] 
Layer 'conv5' weights[0]: 7.972886e-03 [5.919963e-08] 
Layer 'conv5' biases: 1.000004e+00 [6.373246e-08] 
Layer 'fc6' weights[0]: 7.569287e-03 [7.247687e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.045682e-09] 
Layer 'fc7' weights[0]: 7.618220e-03 [9.579172e-08] 
Layer 'fc7' biases: 9.998569e-01 [7.746339e-08] 
Layer 'fc8' weights[0]: 6.243705e-04 [4.412662e-06] 
Layer 'fc8' biases: 1.060860e-01 [9.995692e-05] 
Train error last 27 batches: 0.636198
-------------------------------------------------------
Not saving because 0.683221 > 0.627114 (197.8: -0.01%)
======================================================= (1.777 sec)
226.26... logprob:  0.673224, 0.390625 (0.649 sec)
226.27... logprob:  0.628452, 0.320312 (0.648 sec)
227.1... logprob:  0.678708, 0.398438 (0.648 sec)
227.2... logprob:  0.598039, 0.273438 (0.648 sec)
227.3... logprob:  0.653621, 0.359375 (0.648 sec)
227.4... logprob:  0.597253, 0.273438 (0.648 sec)
227.5... logprob:  0.591258, 0.265625 (0.648 sec)
227.6... logprob:  0.611372, 0.296875 (0.648 sec)
227.7... logprob:  0.643934, 0.343750 (0.648 sec)
227.8... logprob:  0.604387, 0.289062 (0.647 sec)
227.9... logprob:  0.638783, 0.335938 (0.648 sec)
227.10... logprob:  0.597139, 0.281250 (0.648 sec)
227.11... logprob:  0.639443, 0.335938 (0.648 sec)
227.12... logprob:  0.721378, 0.437500 (0.649 sec)
227.13... logprob:  0.658542, 0.359375 (0.649 sec)
227.14... logprob:  0.664116, 0.367188 (0.648 sec)
227.15... logprob:  0.687358, 0.398438 (0.648 sec)
227.16... logprob:  0.627056, 0.320312 (0.648 sec)
227.17... logprob:  0.638521, 0.335938 (0.650 sec)
227.18... logprob:  0.638231, 0.335938 (0.650 sec)
227.19... logprob:  0.632818, 0.328125 (0.650 sec)
227.20... logprob:  0.648698, 0.351562 (0.649 sec)
227.21... logprob:  0.643396, 0.343750 (0.650 sec)
227.22... logprob:  0.628509, 0.320312 (0.648 sec)
227.23... logprob:  0.623927, 0.312500 (0.648 sec)
227.24... logprob:  0.580315, 0.242188 (0.648 sec)
227.25... logprob:  0.628740, 0.320312 (0.649 sec)
227.26... logprob:  0.673231, 0.390625 (0.648 sec)
227.27... logprob:  0.628449, 0.320312 (0.648 sec)
228.1... logprob:  0.678714, 0.398438 (0.648 sec)
228.2... logprob:  0.598032, 0.273438 (0.648 sec)
228.3... logprob:  0.653623, 0.359375 (0.648 sec)
228.4... logprob:  0.597250, 0.273438 (0.648 sec)
228.5... logprob:  0.591257, 0.265625 (0.648 sec)
228.6... logprob:  0.611374, 0.296875 (0.648 sec)
228.7... logprob:  0.643933, 0.343750 (0.648 sec)
228.8... logprob:  0.604391, 0.289062 (0.648 sec)
228.9... logprob:  0.638781, 0.335938 (0.648 sec)
228.10... logprob:  0.597145, 0.281250 (0.648 sec)
228.11... logprob:  0.639438, 0.335938 (0.648 sec)
228.12... logprob:  0.721347, 0.437500 (0.649 sec)
228.13... logprob:  0.658532, 0.359375 (0.648 sec)
228.14... logprob:  0.664106, 0.367188 (0.648 sec)
228.15... logprob:  0.687349, 0.398438 (0.648 sec)
228.16... logprob:  0.627056, 0.320312 (0.648 sec)
228.17... logprob:  0.638522, 0.335938 (0.650 sec)
228.18... logprob:  0.638231, 0.335938 (0.650 sec)
228.19... logprob:  0.632816, 0.328125 (0.649 sec)
228.20... logprob:  0.648700, 0.351562 (0.649 sec)
228.21... logprob:  0.643396, 0.343750 (0.649 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633543, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955156e-03 [6.748011e-09] 
Layer 'conv1' biases: 3.083187e-07 [1.484722e-10] 
Layer 'conv2' weights[0]: 7.942646e-03 [6.349084e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.158273e-10] 
Layer 'conv3' weights[0]: 7.940784e-03 [5.643857e-09] 
Layer 'conv3' biases: 2.695563e-06 [2.020752e-09] 
Layer 'conv4' weights[0]: 7.973308e-03 [5.624655e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.494548e-08] 
Layer 'conv5' weights[0]: 7.972703e-03 [9.141946e-08] 
Layer 'conv5' biases: 1.000004e+00 [9.822557e-08] 
Layer 'fc6' weights[0]: 7.569098e-03 [1.028623e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.494307e-09] 
Layer 'fc7' weights[0]: 7.616273e-03 [1.375458e-07] 
Layer 'fc7' biases: 9.998569e-01 [1.231339e-07] 
Layer 'fc8' weights[0]: 6.235175e-04 [7.031235e-06] 
Layer 'fc8' biases: 1.068893e-01 [1.094465e-04] 
Train error last 27 batches: 0.636191
-------------------------------------------------------
Not saving because 0.633543 > 0.627114 (197.8: -0.01%)
======================================================= (1.746 sec)
228.22... logprob:  0.628503, 0.320312 (0.648 sec)
228.23... logprob:  0.623918, 0.312500 (0.648 sec)
228.24... logprob:  0.580288, 0.242188 (0.649 sec)
228.25... logprob:  0.628733, 0.320312 (0.649 sec)
228.26... logprob:  0.673239, 0.390625 (0.649 sec)
228.27... logprob:  0.628445, 0.320312 (0.649 sec)
229.1... logprob:  0.678721, 0.398438 (0.649 sec)
229.2... logprob:  0.598024, 0.273438 (0.648 sec)
229.3... logprob:  0.653624, 0.359375 (0.649 sec)
229.4... logprob:  0.597248, 0.273438 (0.649 sec)
229.5... logprob:  0.591258, 0.265625 (0.648 sec)
229.6... logprob:  0.611376, 0.296875 (0.648 sec)
229.7... logprob:  0.643930, 0.343750 (0.649 sec)
229.8... logprob:  0.604398, 0.289062 (0.648 sec)
229.9... logprob:  0.638777, 0.335938 (0.648 sec)
229.10... logprob:  0.597155, 0.281250 (0.648 sec)
229.11... logprob:  0.639430, 0.335938 (0.649 sec)
229.12... logprob:  0.721305, 0.437500 (0.649 sec)
229.13... logprob:  0.658517, 0.359375 (0.648 sec)
229.14... logprob:  0.664092, 0.367188 (0.648 sec)
229.15... logprob:  0.687334, 0.398438 (0.648 sec)
229.16... logprob:  0.627056, 0.320312 (0.649 sec)
229.17... logprob:  0.638521, 0.335938 (0.650 sec)
229.18... logprob:  0.638231, 0.335938 (0.649 sec)
229.19... logprob:  0.632815, 0.328125 (0.649 sec)
229.20... logprob:  0.648702, 0.351562 (0.649 sec)
229.21... logprob:  0.643397, 0.343750 (0.650 sec)
229.22... logprob:  0.628496, 0.320312 (0.648 sec)
229.23... logprob:  0.623909, 0.312500 (0.650 sec)
229.24... logprob:  0.580259, 0.242188 (0.648 sec)
229.25... logprob:  0.628727, 0.320312 (0.652 sec)
229.26... logprob:  0.673249, 0.390625 (0.649 sec)
229.27... logprob:  0.628439, 0.320312 (0.648 sec)
230.1... logprob:  0.678730, 0.398438 (0.648 sec)
230.2... logprob:  0.598014, 0.273438 (0.649 sec)
230.3... logprob:  0.653625, 0.359375 (0.648 sec)
230.4... logprob:  0.597243, 0.273438 (0.648 sec)
230.5... logprob:  0.591255, 0.265625 (0.647 sec)
230.6... logprob:  0.611377, 0.296875 (0.648 sec)
230.7... logprob:  0.643930, 0.343750 (0.648 sec)
230.8... logprob:  0.604403, 0.289062 (0.648 sec)
230.9... logprob:  0.638774, 0.335938 (0.648 sec)
230.10... logprob:  0.597163, 0.281250 (0.648 sec)
230.11... logprob:  0.639424, 0.335938 (0.648 sec)
230.12... logprob:  0.721268, 0.437500 (0.649 sec)
230.13... logprob:  0.658504, 0.359375 (0.649 sec)
230.14... logprob:  0.664080, 0.367188 (0.648 sec)
230.15... logprob:  0.687321, 0.398438 (0.648 sec)
230.16... logprob:  0.627056, 0.320312 (0.649 sec)
230.17... logprob:  0.638522, 0.335938 (0.650 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627415, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954964e-03 [6.551202e-09] 
Layer 'conv1' biases: 3.112846e-07 [1.781036e-10] 
Layer 'conv2' weights[0]: 7.942460e-03 [7.105001e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.258587e-10] 
Layer 'conv3' weights[0]: 7.940600e-03 [6.320815e-09] 
Layer 'conv3' biases: 2.716877e-06 [2.621207e-09] 
Layer 'conv4' weights[0]: 7.973111e-03 [6.474534e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.114096e-08] 
Layer 'conv5' weights[0]: 7.972479e-03 [1.295446e-07] 
Layer 'conv5' biases: 1.000004e+00 [1.392209e-07] 
Layer 'fc6' weights[0]: 7.568907e-03 [1.381059e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.339168e-08] 
Layer 'fc7' weights[0]: 7.614305e-03 [1.846708e-07] 
Layer 'fc7' biases: 9.998572e-01 [1.721107e-07] 
Layer 'fc8' weights[0]: 6.507093e-04 [9.885987e-06] 
Layer 'fc8' biases: 1.082588e-01 [1.523774e-04] 
Train error last 27 batches: 0.636182
-------------------------------------------------------
Not saving because 0.627415 > 0.627114 (197.8: -0.01%)
======================================================= (1.730 sec)
230.18... logprob:  0.638231, 0.335938 (0.650 sec)
230.19... logprob:  0.632814, 0.328125 (0.649 sec)
230.20... logprob:  0.648703, 0.351562 (0.649 sec)
230.21... logprob:  0.643396, 0.343750 (0.650 sec)
230.22... logprob:  0.628492, 0.320312 (0.648 sec)
230.23... logprob:  0.623902, 0.312500 (0.648 sec)
230.24... logprob:  0.580238, 0.242188 (0.648 sec)
230.25... logprob:  0.628721, 0.320312 (0.649 sec)
230.26... logprob:  0.673255, 0.390625 (0.649 sec)
230.27... logprob:  0.628435, 0.320312 (0.648 sec)
231.1... logprob:  0.678737, 0.398438 (0.648 sec)
231.2... logprob:  0.598004, 0.273438 (0.648 sec)
231.3... logprob:  0.653627, 0.359375 (0.648 sec)
231.4... logprob:  0.597236, 0.273438 (0.648 sec)
231.5... logprob:  0.591251, 0.265625 (0.648 sec)
231.6... logprob:  0.611377, 0.296875 (0.648 sec)
231.7... logprob:  0.643929, 0.343750 (0.648 sec)
231.8... logprob:  0.604406, 0.289062 (0.648 sec)
231.9... logprob:  0.638772, 0.335938 (0.648 sec)
231.10... logprob:  0.597169, 0.281250 (0.647 sec)
231.11... logprob:  0.639419, 0.335938 (0.648 sec)
231.12... logprob:  0.721241, 0.437500 (0.648 sec)
231.13... logprob:  0.658495, 0.359375 (0.649 sec)
231.14... logprob:  0.664072, 0.367188 (0.648 sec)
231.15... logprob:  0.687312, 0.398438 (0.648 sec)
231.16... logprob:  0.627056, 0.320312 (0.649 sec)
231.17... logprob:  0.638522, 0.335938 (0.650 sec)
231.18... logprob:  0.638231, 0.335938 (0.649 sec)
231.19... logprob:  0.632813, 0.328125 (0.649 sec)
231.20... logprob:  0.648705, 0.351562 (0.649 sec)
231.21... logprob:  0.643396, 0.343750 (0.650 sec)
231.22... logprob:  0.628486, 0.320312 (0.648 sec)
231.23... logprob:  0.623894, 0.312500 (0.648 sec)
231.24... logprob:  0.580213, 0.242188 (0.648 sec)
231.25... logprob:  0.628716, 0.320312 (0.649 sec)
231.26... logprob:  0.673262, 0.390625 (0.649 sec)
231.27... logprob:  0.628431, 0.320312 (0.649 sec)
232.1... logprob:  0.678743, 0.398438 (0.649 sec)
232.2... logprob:  0.597998, 0.273438 (0.649 sec)
232.3... logprob:  0.653627, 0.359375 (0.648 sec)
232.4... logprob:  0.597235, 0.273438 (0.648 sec)
232.5... logprob:  0.591253, 0.265625 (0.648 sec)
232.6... logprob:  0.611379, 0.296875 (0.648 sec)
232.7... logprob:  0.643927, 0.343750 (0.648 sec)
232.8... logprob:  0.604412, 0.289062 (0.648 sec)
232.9... logprob:  0.638769, 0.335938 (0.648 sec)
232.10... logprob:  0.597178, 0.281250 (0.648 sec)
232.11... logprob:  0.639412, 0.335938 (0.648 sec)
232.12... logprob:  0.721200, 0.437500 (0.649 sec)
232.13... logprob:  0.658481, 0.359375 (0.648 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.657952, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954771e-03 [6.522649e-09] 
Layer 'conv1' biases: 3.142042e-07 [1.047104e-10] 
Layer 'conv2' weights[0]: 7.942262e-03 [5.588248e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.253326e-10] 
Layer 'conv3' weights[0]: 7.940402e-03 [4.946404e-09] 
Layer 'conv3' biases: 2.737674e-06 [1.441293e-09] 
Layer 'conv4' weights[0]: 7.972912e-03 [4.902503e-09] 
Layer 'conv4' biases: 1.000001e+00 [9.522587e-09] 
Layer 'conv5' weights[0]: 7.972281e-03 [5.830020e-08] 
Layer 'conv5' biases: 1.000004e+00 [6.259273e-08] 
Layer 'fc6' weights[0]: 7.568698e-03 [7.210265e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.058242e-09] 
Layer 'fc7' weights[0]: 7.612373e-03 [9.641213e-08] 
Layer 'fc7' biases: 9.998578e-01 [7.850974e-08] 
Layer 'fc8' weights[0]: 6.848786e-04 [4.492792e-06] 
Layer 'fc8' biases: 1.097275e-01 [5.761090e-05] 
Train error last 27 batches: 0.636175
-------------------------------------------------------
Not saving because 0.657952 > 0.627114 (197.8: -0.01%)
======================================================= (1.766 sec)
232.14... logprob:  0.664059, 0.367188 (0.648 sec)
232.15... logprob:  0.687298, 0.398438 (0.647 sec)
232.16... logprob:  0.627056, 0.320312 (0.648 sec)
232.17... logprob:  0.638522, 0.335938 (0.649 sec)
232.18... logprob:  0.638231, 0.335938 (0.649 sec)
232.19... logprob:  0.632811, 0.328125 (0.649 sec)
232.20... logprob:  0.648706, 0.351562 (0.649 sec)
232.21... logprob:  0.643396, 0.343750 (0.650 sec)
232.22... logprob:  0.628481, 0.320312 (0.647 sec)
232.23... logprob:  0.623884, 0.312500 (0.648 sec)
232.24... logprob:  0.580187, 0.242188 (0.648 sec)
232.25... logprob:  0.628709, 0.320312 (0.648 sec)
232.26... logprob:  0.673270, 0.390625 (0.649 sec)
232.27... logprob:  0.628427, 0.320312 (0.649 sec)
233.1... logprob:  0.678751, 0.398438 (0.649 sec)
233.2... logprob:  0.597988, 0.273438 (0.648 sec)
233.3... logprob:  0.653629, 0.359375 (0.648 sec)
233.4... logprob:  0.597228, 0.273438 (0.648 sec)
233.5... logprob:  0.591249, 0.265625 (0.648 sec)
233.6... logprob:  0.611379, 0.296875 (0.648 sec)
233.7... logprob:  0.643926, 0.343750 (0.648 sec)
233.8... logprob:  0.604416, 0.289062 (0.648 sec)
233.9... logprob:  0.638767, 0.335938 (0.648 sec)
233.10... logprob:  0.597185, 0.281250 (0.648 sec)
233.11... logprob:  0.639407, 0.335938 (0.649 sec)
233.12... logprob:  0.721169, 0.437500 (0.649 sec)
233.13... logprob:  0.658470, 0.359375 (0.648 sec)
233.14... logprob:  0.664049, 0.367188 (0.648 sec)
233.15... logprob:  0.687289, 0.398438 (0.648 sec)
233.16... logprob:  0.627056, 0.320312 (0.648 sec)
233.17... logprob:  0.638522, 0.335938 (0.650 sec)
233.18... logprob:  0.638231, 0.335938 (0.649 sec)
233.19... logprob:  0.632810, 0.328125 (0.649 sec)
233.20... logprob:  0.648708, 0.351562 (0.649 sec)
233.21... logprob:  0.643396, 0.343750 (0.650 sec)
233.22... logprob:  0.628475, 0.320312 (0.648 sec)
233.23... logprob:  0.623876, 0.312500 (0.648 sec)
233.24... logprob:  0.580161, 0.242188 (0.648 sec)
233.25... logprob:  0.628703, 0.320312 (0.649 sec)
233.26... logprob:  0.673278, 0.390625 (0.649 sec)
233.27... logprob:  0.628423, 0.320312 (0.649 sec)
234.1... logprob:  0.678757, 0.398438 (0.649 sec)
234.2... logprob:  0.597981, 0.273438 (0.648 sec)
234.3... logprob:  0.653630, 0.359375 (0.648 sec)
234.4... logprob:  0.597227, 0.273438 (0.649 sec)
234.5... logprob:  0.591251, 0.265625 (0.648 sec)
234.6... logprob:  0.611382, 0.296875 (0.649 sec)
234.7... logprob:  0.643924, 0.343750 (0.648 sec)
234.8... logprob:  0.604423, 0.289062 (0.648 sec)
234.9... logprob:  0.638763, 0.335938 (0.648 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627119, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954592e-03 [6.590502e-09] 
Layer 'conv1' biases: 3.174943e-07 [1.145249e-10] 
Layer 'conv2' weights[0]: 7.942079e-03 [5.678496e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.771144e-10] 
Layer 'conv3' weights[0]: 7.940195e-03 [5.622305e-09] 
Layer 'conv3' biases: 2.763293e-06 [1.844378e-09] 
Layer 'conv4' weights[0]: 7.972718e-03 [5.867877e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.710126e-08] 
Layer 'conv5' weights[0]: 7.972100e-03 [1.049317e-07] 
Layer 'conv5' biases: 1.000003e+00 [1.130407e-07] 
Layer 'fc6' weights[0]: 7.568503e-03 [1.142324e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.077293e-08] 
Layer 'fc7' weights[0]: 7.610464e-03 [1.504150e-07] 
Layer 'fc7' biases: 9.998577e-01 [1.359143e-07] 
Layer 'fc8' weights[0]: 6.746067e-04 [7.831844e-06] 
Layer 'fc8' biases: 1.103597e-01 [1.498249e-04] 
Train error last 27 batches: 0.636168
-------------------------------------------------------
Not saving because 0.627119 > 0.627114 (197.8: -0.01%)
======================================================= (1.751 sec)
234.10... logprob:  0.597194, 0.281250 (0.648 sec)
234.11... logprob:  0.639399, 0.335938 (0.648 sec)
234.12... logprob:  0.721129, 0.437500 (0.649 sec)
234.13... logprob:  0.658456, 0.359375 (0.649 sec)
234.14... logprob:  0.664036, 0.367188 (0.648 sec)
234.15... logprob:  0.687274, 0.398438 (0.648 sec)
234.16... logprob:  0.627056, 0.320312 (0.648 sec)
234.17... logprob:  0.638522, 0.335938 (0.650 sec)
234.18... logprob:  0.638231, 0.335938 (0.649 sec)
234.19... logprob:  0.632809, 0.328125 (0.649 sec)
234.20... logprob:  0.648710, 0.351562 (0.649 sec)
234.21... logprob:  0.643396, 0.343750 (0.649 sec)
234.22... logprob:  0.628470, 0.320312 (0.648 sec)
234.23... logprob:  0.623868, 0.312500 (0.647 sec)
234.24... logprob:  0.580137, 0.242188 (0.648 sec)
234.25... logprob:  0.628697, 0.320312 (0.649 sec)
234.26... logprob:  0.673286, 0.390625 (0.649 sec)
234.27... logprob:  0.628418, 0.320312 (0.649 sec)
235.1... logprob:  0.678765, 0.398438 (0.648 sec)
235.2... logprob:  0.597970, 0.273438 (0.648 sec)
235.3... logprob:  0.653631, 0.359375 (0.648 sec)
235.4... logprob:  0.597219, 0.273438 (0.648 sec)
235.5... logprob:  0.591246, 0.265625 (0.648 sec)
235.6... logprob:  0.611381, 0.296875 (0.648 sec)
235.7... logprob:  0.643923, 0.343750 (0.648 sec)
235.8... logprob:  0.604425, 0.289062 (0.647 sec)
235.9... logprob:  0.638761, 0.335938 (0.648 sec)
235.10... logprob:  0.597200, 0.281250 (0.647 sec)
235.11... logprob:  0.639394, 0.335938 (0.648 sec)
235.12... logprob:  0.721100, 0.437500 (0.649 sec)
235.13... logprob:  0.658447, 0.359375 (0.649 sec)
235.14... logprob:  0.664027, 0.367188 (0.648 sec)
235.15... logprob:  0.687264, 0.398438 (0.649 sec)
235.16... logprob:  0.627056, 0.320312 (0.649 sec)
235.17... logprob:  0.638522, 0.335938 (0.651 sec)
235.18... logprob:  0.638231, 0.335938 (0.649 sec)
235.19... logprob:  0.632808, 0.328125 (0.649 sec)
235.20... logprob:  0.648711, 0.351562 (0.649 sec)
235.21... logprob:  0.643396, 0.343750 (0.650 sec)
235.22... logprob:  0.628464, 0.320312 (0.648 sec)
235.23... logprob:  0.623860, 0.312500 (0.648 sec)
235.24... logprob:  0.580112, 0.242188 (0.648 sec)
235.25... logprob:  0.628691, 0.320312 (0.649 sec)
235.26... logprob:  0.673294, 0.390625 (0.649 sec)
235.27... logprob:  0.628414, 0.320312 (0.649 sec)
236.1... logprob:  0.678772, 0.398438 (0.648 sec)
236.2... logprob:  0.597964, 0.273438 (0.649 sec)
236.3... logprob:  0.653632, 0.359375 (0.648 sec)
236.4... logprob:  0.597219, 0.273438 (0.648 sec)
236.5... logprob:  0.591248, 0.265625 (0.648 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.632885, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954412e-03 [7.321183e-09] 
Layer 'conv1' biases: 3.209647e-07 [1.450560e-10] 
Layer 'conv2' weights[0]: 7.941882e-03 [6.037631e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.897014e-10] 
Layer 'conv3' weights[0]: 7.939985e-03 [5.928156e-09] 
Layer 'conv3' biases: 2.791364e-06 [2.100511e-09] 
Layer 'conv4' weights[0]: 7.972521e-03 [6.124917e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.935342e-08] 
Layer 'conv5' weights[0]: 7.971914e-03 [1.188737e-07] 
Layer 'conv5' biases: 1.000004e+00 [1.279867e-07] 
Layer 'fc6' weights[0]: 7.568310e-03 [1.276440e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.223884e-08] 
Layer 'fc7' weights[0]: 7.608532e-03 [1.686838e-07] 
Layer 'fc7' biases: 9.998569e-01 [1.550560e-07] 
Layer 'fc8' weights[0]: 6.414203e-04 [8.880787e-06] 
Layer 'fc8' biases: 1.105357e-01 [1.738418e-04] 
Train error last 27 batches: 0.636160
-------------------------------------------------------
Not saving because 0.632885 > 0.627114 (197.8: -0.01%)
======================================================= (1.746 sec)
236.6... logprob:  0.611385, 0.296875 (0.650 sec)
236.7... logprob:  0.643921, 0.343750 (0.648 sec)
236.8... logprob:  0.604433, 0.289062 (0.648 sec)
236.9... logprob:  0.638757, 0.335938 (0.647 sec)
236.10... logprob:  0.597210, 0.281250 (0.648 sec)
236.11... logprob:  0.639387, 0.335938 (0.649 sec)
236.12... logprob:  0.721057, 0.437500 (0.649 sec)
236.13... logprob:  0.658433, 0.359375 (0.648 sec)
236.14... logprob:  0.664013, 0.367188 (0.648 sec)
236.15... logprob:  0.687250, 0.398438 (0.648 sec)
236.16... logprob:  0.627057, 0.320312 (0.649 sec)
236.17... logprob:  0.638522, 0.335938 (0.649 sec)
236.18... logprob:  0.638231, 0.335938 (0.649 sec)
236.19... logprob:  0.632807, 0.328125 (0.649 sec)
236.20... logprob:  0.648713, 0.351562 (0.649 sec)
236.21... logprob:  0.643396, 0.343750 (0.649 sec)
236.22... logprob:  0.628458, 0.320312 (0.648 sec)
236.23... logprob:  0.623851, 0.312500 (0.648 sec)
236.24... logprob:  0.580086, 0.242188 (0.649 sec)
236.25... logprob:  0.628685, 0.320312 (0.649 sec)
236.26... logprob:  0.673302, 0.390625 (0.649 sec)
236.27... logprob:  0.628409, 0.320312 (0.648 sec)
237.1... logprob:  0.678780, 0.398438 (0.648 sec)
237.2... logprob:  0.597953, 0.273438 (0.648 sec)
237.3... logprob:  0.653634, 0.359375 (0.648 sec)
237.4... logprob:  0.597211, 0.273438 (0.648 sec)
237.5... logprob:  0.591243, 0.265625 (0.648 sec)
237.6... logprob:  0.611384, 0.296875 (0.648 sec)
237.7... logprob:  0.643921, 0.343750 (0.648 sec)
237.8... logprob:  0.604435, 0.289062 (0.647 sec)
237.9... logprob:  0.638755, 0.335938 (0.648 sec)
237.10... logprob:  0.597216, 0.281250 (0.648 sec)
237.11... logprob:  0.639382, 0.335938 (0.648 sec)
237.12... logprob:  0.721029, 0.437500 (0.649 sec)
237.13... logprob:  0.658422, 0.359375 (0.648 sec)
237.14... logprob:  0.664004, 0.367188 (0.647 sec)
237.15... logprob:  0.687240, 0.398438 (0.648 sec)
237.16... logprob:  0.627056, 0.320312 (0.648 sec)
237.17... logprob:  0.638522, 0.335938 (0.649 sec)
237.18... logprob:  0.638231, 0.335938 (0.650 sec)
237.19... logprob:  0.632805, 0.328125 (0.649 sec)
237.20... logprob:  0.648715, 0.351562 (0.648 sec)
237.21... logprob:  0.643396, 0.343750 (0.649 sec)
237.22... logprob:  0.628453, 0.320312 (0.648 sec)
237.23... logprob:  0.623844, 0.312500 (0.648 sec)
237.24... logprob:  0.580062, 0.242188 (0.648 sec)
237.25... logprob:  0.628679, 0.320312 (0.649 sec)
237.26... logprob:  0.673310, 0.390625 (0.649 sec)
237.27... logprob:  0.628405, 0.320312 (0.648 sec)
238.1... logprob:  0.678786, 0.398438 (0.648 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.683781, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954209e-03 [6.475236e-09] 
Layer 'conv1' biases: 3.243579e-07 [6.741198e-11] 
Layer 'conv2' weights[0]: 7.941684e-03 [4.886398e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.572429e-10] 
Layer 'conv3' weights[0]: 7.939798e-03 [4.371032e-09] 
Layer 'conv3' biases: 2.818018e-06 [6.178950e-10] 
Layer 'conv4' weights[0]: 7.972327e-03 [4.270674e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.148882e-09] 
Layer 'conv5' weights[0]: 7.971717e-03 [7.475637e-09] 
Layer 'conv5' biases: 1.000004e+00 [6.675797e-09] 
Layer 'fc6' weights[0]: 7.568091e-03 [3.878336e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.658041e-10] 
Layer 'fc7' weights[0]: 7.606585e-03 [4.045373e-08] 
Layer 'fc7' biases: 9.998566e-01 [1.105374e-08] 
Layer 'fc8' weights[0]: 6.232412e-04 [5.754495e-07] 
Layer 'fc8' biases: 1.109919e-01 [2.121065e-06] 
Train error last 27 batches: 0.636152
-------------------------------------------------------
Not saving because 0.683781 > 0.627114 (197.8: -0.01%)
======================================================= (1.879 sec)
238.2... logprob:  0.597946, 0.273438 (0.648 sec)
238.3... logprob:  0.653634, 0.359375 (0.648 sec)
238.4... logprob:  0.597210, 0.273438 (0.648 sec)
238.5... logprob:  0.591244, 0.265625 (0.648 sec)
238.6... logprob:  0.611386, 0.296875 (0.648 sec)
238.7... logprob:  0.643919, 0.343750 (0.647 sec)
238.8... logprob:  0.604442, 0.289062 (0.648 sec)
238.9... logprob:  0.638752, 0.335938 (0.647 sec)
238.10... logprob:  0.597225, 0.281250 (0.648 sec)
238.11... logprob:  0.639376, 0.335938 (0.648 sec)
238.12... logprob:  0.720989, 0.437500 (0.649 sec)
238.13... logprob:  0.658409, 0.359375 (0.648 sec)
238.14... logprob:  0.663991, 0.367188 (0.648 sec)
238.15... logprob:  0.687226, 0.398438 (0.648 sec)
238.16... logprob:  0.627056, 0.320312 (0.649 sec)
238.17... logprob:  0.638522, 0.335938 (0.650 sec)
238.18... logprob:  0.638230, 0.335938 (0.648 sec)
238.19... logprob:  0.632804, 0.328125 (0.649 sec)
238.20... logprob:  0.648716, 0.351562 (0.649 sec)
238.21... logprob:  0.643396, 0.343750 (0.649 sec)
238.22... logprob:  0.628448, 0.320312 (0.648 sec)
238.23... logprob:  0.623836, 0.312500 (0.648 sec)
238.24... logprob:  0.580038, 0.242188 (0.648 sec)
238.25... logprob:  0.628673, 0.320312 (0.649 sec)
238.26... logprob:  0.673317, 0.390625 (0.649 sec)
238.27... logprob:  0.628401, 0.320312 (0.648 sec)
239.1... logprob:  0.678794, 0.398438 (0.648 sec)
239.2... logprob:  0.597936, 0.273438 (0.648 sec)
239.3... logprob:  0.653636, 0.359375 (0.648 sec)
239.4... logprob:  0.597203, 0.273438 (0.648 sec)
239.5... logprob:  0.591240, 0.265625 (0.648 sec)
239.6... logprob:  0.611386, 0.296875 (0.648 sec)
239.7... logprob:  0.643918, 0.343750 (0.649 sec)
239.8... logprob:  0.604445, 0.289062 (0.648 sec)
239.9... logprob:  0.638750, 0.335938 (0.648 sec)
239.10... logprob:  0.597231, 0.281250 (0.648 sec)
239.11... logprob:  0.639371, 0.335938 (0.649 sec)
239.12... logprob:  0.720960, 0.437500 (0.649 sec)
239.13... logprob:  0.658399, 0.359375 (0.649 sec)
239.14... logprob:  0.663981, 0.367188 (0.648 sec)
239.15... logprob:  0.687215, 0.398438 (0.648 sec)
239.16... logprob:  0.627056, 0.320312 (0.649 sec)
239.17... logprob:  0.638522, 0.335938 (0.650 sec)
239.18... logprob:  0.638230, 0.335938 (0.650 sec)
239.19... logprob:  0.632803, 0.328125 (0.649 sec)
239.20... logprob:  0.648717, 0.351562 (0.649 sec)
239.21... logprob:  0.643396, 0.343750 (0.650 sec)
239.22... logprob:  0.628443, 0.320312 (0.648 sec)
239.23... logprob:  0.623829, 0.312500 (0.648 sec)
239.24... logprob:  0.580016, 0.242188 (0.648 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633653, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954001e-03 [6.368897e-09] 
Layer 'conv1' biases: 3.276761e-07 [5.884992e-11] 
Layer 'conv2' weights[0]: 7.941499e-03 [4.783271e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.113092e-10] 
Layer 'conv3' weights[0]: 7.939602e-03 [4.545842e-09] 
Layer 'conv3' biases: 2.843848e-06 [9.203172e-10] 
Layer 'conv4' weights[0]: 7.972136e-03 [4.534065e-09] 
Layer 'conv4' biases: 1.000001e+00 [7.124402e-09] 
Layer 'conv5' weights[0]: 7.971527e-03 [4.302275e-08] 
Layer 'conv5' biases: 1.000004e+00 [4.607715e-08] 
Layer 'fc6' weights[0]: 7.567895e-03 [5.907825e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.417101e-09] 
Layer 'fc7' weights[0]: 7.604646e-03 [7.567066e-08] 
Layer 'fc7' biases: 9.998565e-01 [5.579712e-08] 
Layer 'fc8' weights[0]: 6.157045e-04 [3.150413e-06] 
Layer 'fc8' biases: 1.116463e-01 [7.871006e-05] 
Train error last 27 batches: 0.636143
-------------------------------------------------------
Not saving because 0.633653 > 0.627114 (197.8: -0.01%)
======================================================= (1.793 sec)
239.25... logprob:  0.628668, 0.320312 (0.649 sec)
239.26... logprob:  0.673324, 0.390625 (0.649 sec)
239.27... logprob:  0.628398, 0.320312 (0.649 sec)
240.1... logprob:  0.678799, 0.398438 (0.648 sec)
240.2... logprob:  0.597929, 0.273438 (0.648 sec)
240.3... logprob:  0.653637, 0.359375 (0.648 sec)
240.4... logprob:  0.597200, 0.273438 (0.648 sec)
240.5... logprob:  0.591240, 0.265625 (0.648 sec)
240.6... logprob:  0.611388, 0.296875 (0.655 sec)
240.7... logprob:  0.643916, 0.343750 (0.647 sec)
240.8... logprob:  0.604450, 0.289062 (0.648 sec)
240.9... logprob:  0.638747, 0.335938 (0.648 sec)
240.10... logprob:  0.597238, 0.281250 (0.647 sec)
240.11... logprob:  0.639364, 0.335938 (0.648 sec)
240.12... logprob:  0.720927, 0.437500 (0.649 sec)
240.13... logprob:  0.658387, 0.359375 (0.648 sec)
240.14... logprob:  0.663971, 0.367188 (0.648 sec)
240.15... logprob:  0.687204, 0.398438 (0.649 sec)
240.16... logprob:  0.627057, 0.320312 (0.648 sec)
240.17... logprob:  0.638522, 0.335938 (0.649 sec)
240.18... logprob:  0.638230, 0.335938 (0.649 sec)
240.19... logprob:  0.632802, 0.328125 (0.649 sec)
240.20... logprob:  0.648719, 0.351562 (0.649 sec)
240.21... logprob:  0.643396, 0.343750 (0.649 sec)
240.22... logprob:  0.628438, 0.320312 (0.648 sec)
240.23... logprob:  0.623821, 0.312500 (0.648 sec)
240.24... logprob:  0.579992, 0.242188 (0.649 sec)
240.25... logprob:  0.628662, 0.320312 (0.649 sec)
240.26... logprob:  0.673332, 0.390625 (0.650 sec)
240.27... logprob:  0.628393, 0.320312 (0.648 sec)
241.1... logprob:  0.678807, 0.398438 (0.648 sec)
241.2... logprob:  0.597919, 0.273438 (0.648 sec)
241.3... logprob:  0.653638, 0.359375 (0.648 sec)
241.4... logprob:  0.597195, 0.273438 (0.649 sec)
241.5... logprob:  0.591237, 0.265625 (0.648 sec)
241.6... logprob:  0.611388, 0.296875 (0.648 sec)
241.7... logprob:  0.643915, 0.343750 (0.648 sec)
241.8... logprob:  0.604453, 0.289062 (0.648 sec)
241.9... logprob:  0.638745, 0.335938 (0.648 sec)
241.10... logprob:  0.597246, 0.281250 (0.648 sec)
241.11... logprob:  0.639359, 0.335938 (0.649 sec)
241.12... logprob:  0.720895, 0.437500 (0.650 sec)
241.13... logprob:  0.658376, 0.359375 (0.649 sec)
241.14... logprob:  0.663961, 0.367188 (0.648 sec)
241.15... logprob:  0.687195, 0.398438 (0.648 sec)
241.16... logprob:  0.627056, 0.320312 (0.648 sec)
241.17... logprob:  0.638522, 0.335938 (0.650 sec)
241.18... logprob:  0.638231, 0.335938 (0.649 sec)
241.19... logprob:  0.632801, 0.328125 (0.649 sec)
241.20... logprob:  0.648721, 0.351562 (0.649 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.628211, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.953820e-03 [6.811948e-09] 
Layer 'conv1' biases: 3.308284e-07 [1.595127e-10] 
Layer 'conv2' weights[0]: 7.941299e-03 [6.496193e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.699966e-10] 
Layer 'conv3' weights[0]: 7.939404e-03 [5.769129e-09] 
Layer 'conv3' biases: 2.867849e-06 [2.158367e-09] 
Layer 'conv4' weights[0]: 7.971941e-03 [5.759092e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.624772e-08] 
Layer 'conv5' weights[0]: 7.971326e-03 [9.886724e-08] 
Layer 'conv5' biases: 1.000004e+00 [1.059625e-07] 
Layer 'fc6' weights[0]: 7.567707e-03 [1.097729e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.032429e-08] 
Layer 'fc7' weights[0]: 7.602722e-03 [1.461573e-07] 
Layer 'fc7' biases: 9.998567e-01 [1.323246e-07] 
Layer 'fc8' weights[0]: 6.246581e-04 [7.514702e-06] 
Layer 'fc8' biases: 1.126387e-01 [1.198007e-04] 
Train error last 27 batches: 0.636137
-------------------------------------------------------
Not saving because 0.628211 > 0.627114 (197.8: -0.01%)
======================================================= (1.742 sec)
241.21... logprob:  0.643396, 0.343750 (0.650 sec)
241.22... logprob:  0.628431, 0.320312 (0.648 sec)
241.23... logprob:  0.623812, 0.312500 (0.648 sec)
241.24... logprob:  0.579965, 0.242188 (0.648 sec)
241.25... logprob:  0.628656, 0.320312 (0.649 sec)
241.26... logprob:  0.673340, 0.390625 (0.649 sec)
241.27... logprob:  0.628389, 0.320312 (0.649 sec)
242.1... logprob:  0.678814, 0.398438 (0.648 sec)
242.2... logprob:  0.597913, 0.273438 (0.648 sec)
242.3... logprob:  0.653639, 0.359375 (0.648 sec)
242.4... logprob:  0.597193, 0.273438 (0.649 sec)
242.5... logprob:  0.591238, 0.265625 (0.647 sec)
242.6... logprob:  0.611391, 0.296875 (0.648 sec)
242.7... logprob:  0.643913, 0.343750 (0.648 sec)
242.8... logprob:  0.604461, 0.289062 (0.648 sec)
242.9... logprob:  0.638741, 0.335938 (0.648 sec)
242.10... logprob:  0.597256, 0.281250 (0.647 sec)
242.11... logprob:  0.639352, 0.335938 (0.647 sec)
242.12... logprob:  0.720850, 0.437500 (0.650 sec)
242.13... logprob:  0.658360, 0.359375 (0.648 sec)
242.14... logprob:  0.663947, 0.367188 (0.648 sec)
242.15... logprob:  0.687178, 0.398438 (0.648 sec)
242.16... logprob:  0.627057, 0.320312 (0.649 sec)
242.17... logprob:  0.638521, 0.335938 (0.650 sec)
242.18... logprob:  0.638231, 0.335938 (0.649 sec)
242.19... logprob:  0.632800, 0.328125 (0.649 sec)
242.20... logprob:  0.648723, 0.351562 (0.649 sec)
242.21... logprob:  0.643396, 0.343750 (0.649 sec)
242.22... logprob:  0.628426, 0.320312 (0.648 sec)
242.23... logprob:  0.623804, 0.312500 (0.648 sec)
242.24... logprob:  0.579940, 0.242188 (0.649 sec)
242.25... logprob:  0.628650, 0.320312 (0.649 sec)
242.26... logprob:  0.673349, 0.390625 (0.649 sec)
242.27... logprob:  0.628384, 0.320312 (0.648 sec)
243.1... logprob:  0.678823, 0.398438 (0.648 sec)
243.2... logprob:  0.597901, 0.273438 (0.648 sec)
243.3... logprob:  0.653642, 0.359375 (0.648 sec)
243.4... logprob:  0.597185, 0.273438 (0.648 sec)
243.5... logprob:  0.591233, 0.265625 (0.649 sec)
243.6... logprob:  0.611390, 0.296875 (0.648 sec)
243.7... logprob:  0.643913, 0.343750 (0.648 sec)
243.8... logprob:  0.604463, 0.289062 (0.648 sec)
243.9... logprob:  0.638740, 0.335938 (0.648 sec)
243.10... logprob:  0.597261, 0.281250 (0.648 sec)
243.11... logprob:  0.639348, 0.335938 (0.648 sec)
243.12... logprob:  0.720825, 0.437500 (0.649 sec)
243.13... logprob:  0.658353, 0.359375 (0.649 sec)
243.14... logprob:  0.663938, 0.367188 (0.648 sec)
243.15... logprob:  0.687169, 0.398438 (0.648 sec)
243.16... logprob:  0.627057, 0.320312 (0.648 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.655378, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.953611e-03 [6.982265e-09] 
Layer 'conv1' biases: 3.338280e-07 [1.905221e-10] 
Layer 'conv2' weights[0]: 7.941118e-03 [7.402707e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.821034e-10] 
Layer 'conv3' weights[0]: 7.939201e-03 [6.512263e-09] 
Layer 'conv3' biases: 2.889426e-06 [2.767875e-09] 
Layer 'conv4' weights[0]: 7.971747e-03 [6.622537e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.168655e-08] 
Layer 'conv5' weights[0]: 7.971146e-03 [1.320850e-07] 
Layer 'conv5' biases: 1.000003e+00 [1.418174e-07] 
Layer 'fc6' weights[0]: 7.567522e-03 [1.417452e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.376619e-08] 
Layer 'fc7' weights[0]: 7.600719e-03 [1.873282e-07] 
Layer 'fc7' biases: 9.998570e-01 [1.748283e-07] 
Layer 'fc8' weights[0]: 6.534006e-04 [9.984137e-06] 
Layer 'fc8' biases: 1.140214e-01 [1.567012e-04] 
Train error last 27 batches: 0.636128
-------------------------------------------------------
Not saving because 0.655378 > 0.627114 (197.8: -0.01%)
======================================================= (1.730 sec)
243.17... logprob:  0.638522, 0.335938 (0.650 sec)
243.18... logprob:  0.638230, 0.335938 (0.649 sec)
243.19... logprob:  0.632799, 0.328125 (0.649 sec)
243.20... logprob:  0.648724, 0.351562 (0.649 sec)
243.21... logprob:  0.643396, 0.343750 (0.649 sec)
243.22... logprob:  0.628421, 0.320312 (0.648 sec)
243.23... logprob:  0.623797, 0.312500 (0.648 sec)
243.24... logprob:  0.579918, 0.242188 (0.648 sec)
243.25... logprob:  0.628645, 0.320312 (0.649 sec)
243.26... logprob:  0.673355, 0.390625 (0.649 sec)
243.27... logprob:  0.628381, 0.320312 (0.648 sec)
244.1... logprob:  0.678828, 0.398438 (0.648 sec)
244.2... logprob:  0.597896, 0.273438 (0.648 sec)
244.3... logprob:  0.653642, 0.359375 (0.648 sec)
244.4... logprob:  0.597184, 0.273438 (0.648 sec)
244.5... logprob:  0.591235, 0.265625 (0.647 sec)
244.6... logprob:  0.611392, 0.296875 (0.648 sec)
244.7... logprob:  0.643911, 0.343750 (0.648 sec)
244.8... logprob:  0.604469, 0.289062 (0.648 sec)
244.9... logprob:  0.638737, 0.335938 (0.648 sec)
244.10... logprob:  0.597270, 0.281250 (0.648 sec)
244.11... logprob:  0.639341, 0.335938 (0.648 sec)
244.12... logprob:  0.720788, 0.437500 (0.650 sec)
244.13... logprob:  0.658340, 0.359375 (0.648 sec)
244.14... logprob:  0.663926, 0.367188 (0.648 sec)
244.15... logprob:  0.687157, 0.398438 (0.648 sec)
244.16... logprob:  0.627057, 0.320312 (0.648 sec)
244.17... logprob:  0.638522, 0.335938 (0.650 sec)
244.18... logprob:  0.638230, 0.335938 (0.649 sec)
244.19... logprob:  0.632797, 0.328125 (0.649 sec)
244.20... logprob:  0.648726, 0.351562 (0.649 sec)
244.21... logprob:  0.643397, 0.343750 (0.649 sec)
244.22... logprob:  0.628415, 0.320312 (0.649 sec)
244.23... logprob:  0.623789, 0.312500 (0.648 sec)
244.24... logprob:  0.579892, 0.242188 (0.648 sec)
244.25... logprob:  0.628639, 0.320312 (0.649 sec)
244.26... logprob:  0.673364, 0.390625 (0.649 sec)
244.27... logprob:  0.628376, 0.320312 (0.651 sec)
245.1... logprob:  0.678836, 0.398438 (0.648 sec)
245.2... logprob:  0.597886, 0.273438 (0.648 sec)
245.3... logprob:  0.653643, 0.359375 (0.648 sec)
245.4... logprob:  0.597178, 0.273438 (0.648 sec)
245.5... logprob:  0.591232, 0.265625 (0.648 sec)
245.6... logprob:  0.611393, 0.296875 (0.648 sec)
245.7... logprob:  0.643909, 0.343750 (0.648 sec)
245.8... logprob:  0.604473, 0.289062 (0.648 sec)
245.9... logprob:  0.638734, 0.335938 (0.648 sec)
245.10... logprob:  0.597278, 0.281250 (0.647 sec)
245.11... logprob:  0.639335, 0.335938 (0.648 sec)
245.12... logprob:  0.720753, 0.437500 (0.649 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627299, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.953425e-03 [6.774103e-09] 
Layer 'conv1' biases: 3.368197e-07 [8.335670e-11] 
Layer 'conv2' weights[0]: 7.940938e-03 [5.188258e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.409600e-10] 
Layer 'conv3' weights[0]: 7.939019e-03 [4.551050e-09] 
Layer 'conv3' biases: 2.911017e-06 [8.948425e-10] 
Layer 'conv4' weights[0]: 7.971552e-03 [4.435363e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.222091e-09] 
Layer 'conv5' weights[0]: 7.970919e-03 [1.954834e-08] 
Layer 'conv5' biases: 1.000003e+00 [2.039759e-08] 
Layer 'fc6' weights[0]: 7.567334e-03 [4.386313e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.058323e-09] 
Layer 'fc7' weights[0]: 7.598788e-03 [5.163053e-08] 
Layer 'fc7' biases: 9.998574e-01 [2.784867e-08] 
Layer 'fc8' weights[0]: 6.815298e-04 [1.508834e-06] 
Layer 'fc8' biases: 1.153627e-01 [8.222617e-06] 
Train error last 27 batches: 0.636121
-------------------------------------------------------
Not saving because 0.627299 > 0.627114 (197.8: -0.01%)
======================================================= (1.837 sec)
245.13... logprob:  0.658327, 0.359375 (0.648 sec)
245.14... logprob:  0.663915, 0.367188 (0.648 sec)
245.15... logprob:  0.687144, 0.398438 (0.652 sec)
245.16... logprob:  0.627057, 0.320312 (0.648 sec)
245.17... logprob:  0.638522, 0.335938 (0.650 sec)
245.18... logprob:  0.638230, 0.335938 (0.649 sec)
245.19... logprob:  0.632796, 0.328125 (0.650 sec)
245.20... logprob:  0.648727, 0.351562 (0.649 sec)
245.21... logprob:  0.643397, 0.343750 (0.650 sec)
245.22... logprob:  0.628411, 0.320312 (0.648 sec)
245.23... logprob:  0.623781, 0.312500 (0.648 sec)
245.24... logprob:  0.579870, 0.242188 (0.650 sec)
245.25... logprob:  0.628633, 0.320312 (0.650 sec)
245.26... logprob:  0.673371, 0.390625 (0.650 sec)
245.27... logprob:  0.628372, 0.320312 (0.649 sec)
246.1... logprob:  0.678843, 0.398438 (0.649 sec)
246.2... logprob:  0.597877, 0.273438 (0.649 sec)
246.3... logprob:  0.653645, 0.359375 (0.648 sec)
246.4... logprob:  0.597173, 0.273438 (0.649 sec)
246.5... logprob:  0.591228, 0.265625 (0.648 sec)
246.6... logprob:  0.611392, 0.296875 (0.648 sec)
246.7... logprob:  0.643909, 0.343750 (0.647 sec)
246.8... logprob:  0.604477, 0.289062 (0.648 sec)
246.9... logprob:  0.638732, 0.335938 (0.648 sec)
246.10... logprob:  0.597283, 0.281250 (0.648 sec)
246.11... logprob:  0.639331, 0.335938 (0.648 sec)
246.12... logprob:  0.720725, 0.437500 (0.649 sec)
246.13... logprob:  0.658318, 0.359375 (0.648 sec)
246.14... logprob:  0.663906, 0.367188 (0.648 sec)
246.15... logprob:  0.687134, 0.398438 (0.648 sec)
246.16... logprob:  0.627057, 0.320312 (0.648 sec)
246.17... logprob:  0.638521, 0.335938 (0.650 sec)
246.18... logprob:  0.638230, 0.335938 (0.649 sec)
246.19... logprob:  0.632796, 0.328125 (0.649 sec)
246.20... logprob:  0.648729, 0.351562 (0.649 sec)
246.21... logprob:  0.643396, 0.343750 (0.649 sec)
246.22... logprob:  0.628406, 0.320312 (0.648 sec)
246.23... logprob:  0.623774, 0.312500 (0.647 sec)
246.24... logprob:  0.579848, 0.242188 (0.649 sec)
246.25... logprob:  0.628628, 0.320312 (0.648 sec)
246.26... logprob:  0.673378, 0.390625 (0.649 sec)
246.27... logprob:  0.628369, 0.320312 (0.648 sec)
247.1... logprob:  0.678849, 0.398438 (0.648 sec)
247.2... logprob:  0.597869, 0.273438 (0.648 sec)
247.3... logprob:  0.653646, 0.359375 (0.648 sec)
247.4... logprob:  0.597170, 0.273438 (0.648 sec)
247.5... logprob:  0.591228, 0.265625 (0.648 sec)
247.6... logprob:  0.611394, 0.296875 (0.649 sec)
247.7... logprob:  0.643908, 0.343750 (0.648 sec)
247.8... logprob:  0.604481, 0.289062 (0.647 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.632864, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.953237e-03 [7.082879e-09] 
Layer 'conv1' biases: 3.402215e-07 [1.420090e-10] 
Layer 'conv2' weights[0]: 7.940733e-03 [6.215658e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.436746e-10] 
Layer 'conv3' weights[0]: 7.938809e-03 [6.100100e-09] 
Layer 'conv3' biases: 2.938252e-06 [2.251495e-09] 
Layer 'conv4' weights[0]: 7.971362e-03 [6.351403e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.075872e-08] 
Layer 'conv5' weights[0]: 7.970744e-03 [1.261803e-07] 
Layer 'conv5' biases: 1.000003e+00 [1.355774e-07] 
Layer 'fc6' weights[0]: 7.567135e-03 [1.356893e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.308986e-08] 
Layer 'fc7' weights[0]: 7.596857e-03 [1.774881e-07] 
Layer 'fc7' biases: 9.998572e-01 [1.642312e-07] 
Layer 'fc8' weights[0]: 6.605315e-04 [9.374265e-06] 
Layer 'fc8' biases: 1.157629e-01 [1.813632e-04] 
Train error last 27 batches: 0.636115
-------------------------------------------------------
Not saving because 0.632864 > 0.627114 (197.8: -0.01%)
======================================================= (1.742 sec)
247.9... logprob:  0.638729, 0.335938 (0.648 sec)
247.10... logprob:  0.597291, 0.281250 (0.648 sec)
247.11... logprob:  0.639325, 0.335938 (0.649 sec)
247.12... logprob:  0.720690, 0.437500 (0.649 sec)
247.13... logprob:  0.658306, 0.359375 (0.649 sec)
247.14... logprob:  0.663895, 0.367188 (0.648 sec)
247.15... logprob:  0.687123, 0.398438 (0.648 sec)
247.16... logprob:  0.627057, 0.320312 (0.649 sec)
247.17... logprob:  0.638522, 0.335938 (0.650 sec)
247.18... logprob:  0.638230, 0.335938 (0.649 sec)
247.19... logprob:  0.632794, 0.328125 (0.649 sec)
247.20... logprob:  0.648731, 0.351562 (0.649 sec)
247.21... logprob:  0.643396, 0.343750 (0.650 sec)
247.22... logprob:  0.628401, 0.320312 (0.648 sec)
247.23... logprob:  0.623766, 0.312500 (0.648 sec)
247.24... logprob:  0.579822, 0.242188 (0.649 sec)
247.25... logprob:  0.628622, 0.320312 (0.650 sec)
247.26... logprob:  0.673387, 0.390625 (0.650 sec)
247.27... logprob:  0.628365, 0.320312 (0.650 sec)
248.1... logprob:  0.678857, 0.398438 (0.649 sec)
248.2... logprob:  0.597861, 0.273438 (0.648 sec)
248.3... logprob:  0.653648, 0.359375 (0.648 sec)
248.4... logprob:  0.597166, 0.273438 (0.648 sec)
248.5... logprob:  0.591227, 0.265625 (0.648 sec)
248.6... logprob:  0.611396, 0.296875 (0.648 sec)
248.7... logprob:  0.643906, 0.343750 (0.648 sec)
248.8... logprob:  0.604488, 0.289062 (0.648 sec)
248.9... logprob:  0.638726, 0.335938 (0.647 sec)
248.10... logprob:  0.597300, 0.281250 (0.648 sec)
248.11... logprob:  0.639319, 0.335938 (0.648 sec)
248.12... logprob:  0.720653, 0.437500 (0.649 sec)
248.13... logprob:  0.658293, 0.359375 (0.648 sec)
248.14... logprob:  0.663883, 0.367188 (0.650 sec)
248.15... logprob:  0.687109, 0.398438 (0.648 sec)
248.16... logprob:  0.627057, 0.320312 (0.650 sec)
248.17... logprob:  0.638522, 0.335938 (0.650 sec)
248.18... logprob:  0.638230, 0.335938 (0.649 sec)
248.19... logprob:  0.632794, 0.328125 (0.652 sec)
248.20... logprob:  0.648732, 0.351562 (0.649 sec)
248.21... logprob:  0.643397, 0.343750 (0.650 sec)
248.22... logprob:  0.628395, 0.320312 (0.648 sec)
248.23... logprob:  0.623758, 0.312500 (0.648 sec)
248.24... logprob:  0.579798, 0.242188 (0.648 sec)
248.25... logprob:  0.628616, 0.320312 (0.649 sec)
248.26... logprob:  0.673395, 0.390625 (0.650 sec)
248.27... logprob:  0.628360, 0.320312 (0.648 sec)
249.1... logprob:  0.678864, 0.398438 (0.648 sec)
249.2... logprob:  0.597852, 0.273438 (0.648 sec)
249.3... logprob:  0.653649, 0.359375 (0.648 sec)
249.4... logprob:  0.597161, 0.273438 (0.650 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.685198, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.953033e-03 [6.779035e-09] 
Layer 'conv1' biases: 3.437725e-07 [9.792675e-11] 
Layer 'conv2' weights[0]: 7.940537e-03 [5.293365e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.098270e-10] 
Layer 'conv3' weights[0]: 7.938621e-03 [5.100008e-09] 
Layer 'conv3' biases: 2.966609e-06 [1.369597e-09] 
Layer 'conv4' weights[0]: 7.971173e-03 [5.146509e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.158569e-08] 
Layer 'conv5' weights[0]: 7.970560e-03 [7.066238e-08] 
Layer 'conv5' biases: 1.000003e+00 [7.590798e-08] 
Layer 'fc6' weights[0]: 7.566939e-03 [8.392308e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.319324e-09] 
Layer 'fc7' weights[0]: 7.594918e-03 [1.095913e-07] 
Layer 'fc7' biases: 9.998566e-01 [9.164924e-08] 
Layer 'fc8' weights[0]: 6.277131e-04 [5.201372e-06] 
Layer 'fc8' biases: 1.158996e-01 [1.089757e-04] 
Train error last 27 batches: 0.636107
-------------------------------------------------------
Not saving because 0.685198 > 0.627114 (197.8: -0.01%)
======================================================= (1.766 sec)
249.5... logprob:  0.591224, 0.265625 (0.648 sec)
249.6... logprob:  0.611396, 0.296875 (0.648 sec)
249.7... logprob:  0.643905, 0.343750 (0.648 sec)
249.8... logprob:  0.604491, 0.289062 (0.648 sec)
249.9... logprob:  0.638724, 0.335938 (0.648 sec)
249.10... logprob:  0.597307, 0.281250 (0.648 sec)
249.11... logprob:  0.639314, 0.335938 (0.648 sec)
249.12... logprob:  0.720623, 0.437500 (0.649 sec)
249.13... logprob:  0.658283, 0.359375 (0.649 sec)
249.14... logprob:  0.663873, 0.367188 (0.648 sec)
249.15... logprob:  0.687099, 0.398438 (0.648 sec)
249.16... logprob:  0.627057, 0.320312 (0.648 sec)
249.17... logprob:  0.638522, 0.335938 (0.649 sec)
249.18... logprob:  0.638230, 0.335938 (0.649 sec)
249.19... logprob:  0.632792, 0.328125 (0.649 sec)
249.20... logprob:  0.648734, 0.351562 (0.649 sec)
249.21... logprob:  0.643397, 0.343750 (0.650 sec)
249.22... logprob:  0.628390, 0.320312 (0.648 sec)
249.23... logprob:  0.623751, 0.312500 (0.648 sec)
249.24... logprob:  0.579776, 0.242188 (0.648 sec)
249.25... logprob:  0.628611, 0.320312 (0.649 sec)
249.26... logprob:  0.673401, 0.390625 (0.649 sec)
249.27... logprob:  0.628356, 0.320312 (0.649 sec)
250.1... logprob:  0.678871, 0.398438 (0.648 sec)
250.2... logprob:  0.597844, 0.273438 (0.649 sec)
250.3... logprob:  0.653650, 0.359375 (0.648 sec)
250.4... logprob:  0.597156, 0.273438 (0.649 sec)
250.5... logprob:  0.591223, 0.265625 (0.648 sec)
250.6... logprob:  0.611396, 0.296875 (0.649 sec)
250.7... logprob:  0.643904, 0.343750 (0.648 sec)
250.8... logprob:  0.604496, 0.289062 (0.648 sec)
250.9... logprob:  0.638722, 0.335938 (0.648 sec)
250.10... logprob:  0.597314, 0.281250 (0.648 sec)
250.11... logprob:  0.639308, 0.335938 (0.648 sec)
250.12... logprob:  0.720589, 0.437500 (0.650 sec)
250.13... logprob:  0.658271, 0.359375 (0.648 sec)
250.14... logprob:  0.663862, 0.367188 (0.648 sec)
250.15... logprob:  0.687087, 0.398438 (0.648 sec)
250.16... logprob:  0.627057, 0.320312 (0.648 sec)
250.17... logprob:  0.638522, 0.335938 (0.650 sec)
250.18... logprob:  0.638230, 0.335938 (0.650 sec)
250.19... logprob:  0.632791, 0.328125 (0.649 sec)
250.20... logprob:  0.648736, 0.351562 (0.649 sec)
250.21... logprob:  0.643397, 0.343750 (0.650 sec)
250.22... logprob:  0.628385, 0.320312 (0.647 sec)
250.23... logprob:  0.623743, 0.312500 (0.648 sec)
250.24... logprob:  0.579751, 0.242188 (0.648 sec)
250.25... logprob:  0.628605, 0.320312 (0.649 sec)
250.26... logprob:  0.673410, 0.390625 (0.649 sec)
250.27... logprob:  0.628352, 0.320312 (0.648 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633344, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.952821e-03 [6.503291e-09] 
Layer 'conv1' biases: 3.471811e-07 [6.563986e-11] 
Layer 'conv2' weights[0]: 7.940346e-03 [4.808617e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.774040e-10] 
Layer 'conv3' weights[0]: 7.938428e-03 [4.507985e-09] 
Layer 'conv3' biases: 2.992450e-06 [7.998620e-10] 
Layer 'conv4' weights[0]: 7.970991e-03 [4.490990e-09] 
Layer 'conv4' biases: 1.000001e+00 [5.578832e-09] 
Layer 'conv5' weights[0]: 7.970363e-03 [3.386754e-08] 
Layer 'conv5' biases: 1.000004e+00 [3.613921e-08] 
Layer 'fc6' weights[0]: 7.566723e-03 [5.236644e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.459450e-09] 
Layer 'fc7' weights[0]: 7.592997e-03 [6.503999e-08] 
Layer 'fc7' biases: 9.998565e-01 [4.338723e-08] 
Layer 'fc8' weights[0]: 6.185296e-04 [2.429461e-06] 
Layer 'fc8' biases: 1.165154e-01 [6.067442e-05] 
Train error last 27 batches: 0.636099
-------------------------------------------------------
Not saving because 0.633344 > 0.627114 (197.8: -0.01%)
======================================================= (1.808 sec)
251.1... logprob:  0.678878, 0.398438 (0.648 sec)
251.2... logprob:  0.597836, 0.273438 (0.648 sec)
251.3... logprob:  0.653651, 0.359375 (0.648 sec)
251.4... logprob:  0.597152, 0.273438 (0.648 sec)
251.5... logprob:  0.591221, 0.265625 (0.648 sec)
251.6... logprob:  0.611398, 0.296875 (0.648 sec)
251.7... logprob:  0.643903, 0.343750 (0.648 sec)
251.8... logprob:  0.604500, 0.289062 (0.648 sec)
251.9... logprob:  0.638719, 0.335938 (0.648 sec)
251.10... logprob:  0.597322, 0.281250 (0.648 sec)
251.11... logprob:  0.639302, 0.335938 (0.648 sec)
251.12... logprob:  0.720553, 0.437500 (0.649 sec)
251.13... logprob:  0.658259, 0.359375 (0.649 sec)
251.14... logprob:  0.663850, 0.367188 (0.648 sec)
251.15... logprob:  0.687074, 0.398438 (0.648 sec)
251.16... logprob:  0.627057, 0.320312 (0.649 sec)
251.17... logprob:  0.638521, 0.335938 (0.650 sec)
251.18... logprob:  0.638229, 0.335938 (0.649 sec)
251.19... logprob:  0.632790, 0.328125 (0.650 sec)
251.20... logprob:  0.648737, 0.351562 (0.648 sec)
251.21... logprob:  0.643397, 0.343750 (0.650 sec)
251.22... logprob:  0.628380, 0.320312 (0.648 sec)
251.23... logprob:  0.623736, 0.312500 (0.648 sec)
251.24... logprob:  0.579728, 0.242188 (0.649 sec)
251.25... logprob:  0.628600, 0.320312 (0.649 sec)
251.26... logprob:  0.673417, 0.390625 (0.649 sec)
251.27... logprob:  0.628348, 0.320312 (0.649 sec)
252.1... logprob:  0.678885, 0.398438 (0.649 sec)
252.2... logprob:  0.597826, 0.273438 (0.649 sec)
252.3... logprob:  0.653653, 0.359375 (0.649 sec)
252.4... logprob:  0.597147, 0.273438 (0.649 sec)
252.5... logprob:  0.591218, 0.265625 (0.649 sec)
252.6... logprob:  0.611398, 0.296875 (0.649 sec)
252.7... logprob:  0.643902, 0.343750 (0.649 sec)
252.8... logprob:  0.604504, 0.289062 (0.648 sec)
252.9... logprob:  0.638717, 0.335938 (0.648 sec)
252.10... logprob:  0.597329, 0.281250 (0.648 sec)
252.11... logprob:  0.639298, 0.335938 (0.648 sec)
252.12... logprob:  0.720523, 0.437500 (0.650 sec)
252.13... logprob:  0.658248, 0.359375 (0.648 sec)
252.14... logprob:  0.663841, 0.367188 (0.648 sec)
252.15... logprob:  0.687064, 0.398438 (0.647 sec)
252.16... logprob:  0.627057, 0.320312 (0.648 sec)
252.17... logprob:  0.638522, 0.335938 (0.650 sec)
252.18... logprob:  0.638230, 0.335938 (0.650 sec)
252.19... logprob:  0.632789, 0.328125 (0.649 sec)
252.20... logprob:  0.648739, 0.351562 (0.649 sec)
252.21... logprob:  0.643397, 0.343750 (0.650 sec)
252.22... logprob:  0.628375, 0.320312 (0.648 sec)
252.23... logprob:  0.623727, 0.312500 (0.648 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.628844, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.952616e-03 [6.250261e-09] 
Layer 'conv1' biases: 3.505998e-07 [9.852169e-11] 
Layer 'conv2' weights[0]: 7.940159e-03 [5.177625e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.843564e-10] 
Layer 'conv3' weights[0]: 7.938228e-03 [4.659251e-09] 
Layer 'conv3' biases: 3.018816e-06 [1.002433e-09] 
Layer 'conv4' weights[0]: 7.970807e-03 [4.553376e-09] 
Layer 'conv4' biases: 1.000001e+00 [5.517341e-09] 
Layer 'conv5' weights[0]: 7.970159e-03 [3.353358e-08] 
Layer 'conv5' biases: 1.000004e+00 [3.563916e-08] 
Layer 'fc6' weights[0]: 7.566526e-03 [5.248458e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.526188e-09] 
Layer 'fc7' weights[0]: 7.591081e-03 [6.626277e-08] 
Layer 'fc7' biases: 9.998563e-01 [4.542295e-08] 
Layer 'fc8' weights[0]: 6.083580e-04 [2.546858e-06] 
Layer 'fc8' biases: 1.170788e-01 [3.191966e-05] 
Train error last 27 batches: 0.636092
-------------------------------------------------------
Not saving because 0.628844 > 0.627114 (197.8: -0.01%)
======================================================= (1.807 sec)
252.24... logprob:  0.579704, 0.242188 (0.648 sec)
252.25... logprob:  0.628595, 0.320312 (0.649 sec)
252.26... logprob:  0.673425, 0.390625 (0.650 sec)
252.27... logprob:  0.628345, 0.320312 (0.649 sec)
253.1... logprob:  0.678893, 0.398438 (0.649 sec)
253.2... logprob:  0.597819, 0.273438 (0.649 sec)
253.3... logprob:  0.653654, 0.359375 (0.649 sec)
253.4... logprob:  0.597144, 0.273438 (0.649 sec)
253.5... logprob:  0.591218, 0.265625 (0.649 sec)
253.6... logprob:  0.611400, 0.296875 (0.648 sec)
253.7... logprob:  0.643901, 0.343750 (0.649 sec)
253.8... logprob:  0.604510, 0.289062 (0.648 sec)
253.9... logprob:  0.638714, 0.335938 (0.648 sec)
253.10... logprob:  0.597338, 0.281250 (0.648 sec)
253.11... logprob:  0.639291, 0.335938 (0.649 sec)
253.12... logprob:  0.720487, 0.437500 (0.649 sec)
253.13... logprob:  0.658236, 0.359375 (0.649 sec)
253.14... logprob:  0.663829, 0.367188 (0.647 sec)
253.15... logprob:  0.687050, 0.398438 (0.648 sec)
253.16... logprob:  0.627057, 0.320312 (0.648 sec)
253.17... logprob:  0.638522, 0.335938 (0.650 sec)
253.18... logprob:  0.638229, 0.335938 (0.649 sec)
253.19... logprob:  0.632788, 0.328125 (0.649 sec)
253.20... logprob:  0.648741, 0.351562 (0.649 sec)
253.21... logprob:  0.643397, 0.343750 (0.649 sec)
253.22... logprob:  0.628370, 0.320312 (0.648 sec)
253.23... logprob:  0.623721, 0.312500 (0.648 sec)
253.24... logprob:  0.579682, 0.242188 (0.648 sec)
253.25... logprob:  0.628589, 0.320312 (0.649 sec)
253.26... logprob:  0.673433, 0.390625 (0.649 sec)
253.27... logprob:  0.628340, 0.320312 (0.648 sec)
254.1... logprob:  0.678899, 0.398438 (0.648 sec)
254.2... logprob:  0.597810, 0.273438 (0.648 sec)
254.3... logprob:  0.653655, 0.359375 (0.648 sec)
254.4... logprob:  0.597138, 0.273438 (0.649 sec)
254.5... logprob:  0.591214, 0.265625 (0.648 sec)
254.6... logprob:  0.611400, 0.296875 (0.648 sec)
254.7... logprob:  0.643899, 0.343750 (0.648 sec)
254.8... logprob:  0.604512, 0.289062 (0.648 sec)
254.9... logprob:  0.638712, 0.335938 (0.648 sec)
254.10... logprob:  0.597343, 0.281250 (0.649 sec)
254.11... logprob:  0.639287, 0.335938 (0.648 sec)
254.12... logprob:  0.720459, 0.437500 (0.649 sec)
254.13... logprob:  0.658227, 0.359375 (0.649 sec)
254.14... logprob:  0.663820, 0.367188 (0.648 sec)
254.15... logprob:  0.687040, 0.398438 (0.648 sec)
254.16... logprob:  0.627057, 0.320312 (0.649 sec)
254.17... logprob:  0.638522, 0.335938 (0.650 sec)
254.18... logprob:  0.638229, 0.335938 (0.650 sec)
254.19... logprob:  0.632787, 0.328125 (0.650 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.653965, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.952426e-03 [6.768261e-09] 
Layer 'conv1' biases: 3.537578e-07 [1.585279e-10] 
Layer 'conv2' weights[0]: 7.939965e-03 [6.617437e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.793581e-10] 
Layer 'conv3' weights[0]: 7.938036e-03 [5.822391e-09] 
Layer 'conv3' biases: 3.041861e-06 [2.173088e-09] 
Layer 'conv4' weights[0]: 7.970633e-03 [5.820281e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.610560e-08] 
Layer 'conv5' weights[0]: 7.969966e-03 [9.737065e-08] 
Layer 'conv5' biases: 1.000003e+00 [1.042557e-07] 
Layer 'fc6' weights[0]: 7.566325e-03 [1.088496e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.022280e-08] 
Layer 'fc7' weights[0]: 7.589136e-03 [1.437293e-07] 
Layer 'fc7' biases: 9.998565e-01 [1.297157e-07] 
Layer 'fc8' weights[0]: 6.262193e-04 [7.314143e-06] 
Layer 'fc8' biases: 1.182477e-01 [1.175933e-04] 
Train error last 27 batches: 0.636085
-------------------------------------------------------
Not saving because 0.653965 > 0.627114 (197.8: -0.01%)
======================================================= (1.741 sec)
254.20... logprob:  0.648742, 0.351562 (0.650 sec)
254.21... logprob:  0.643398, 0.343750 (0.650 sec)
254.22... logprob:  0.628366, 0.320312 (0.648 sec)
254.23... logprob:  0.623714, 0.312500 (0.648 sec)
254.24... logprob:  0.579661, 0.242188 (0.649 sec)
254.25... logprob:  0.628584, 0.320312 (0.648 sec)
254.26... logprob:  0.673439, 0.390625 (0.649 sec)
254.27... logprob:  0.628337, 0.320312 (0.648 sec)
255.1... logprob:  0.678906, 0.398438 (0.648 sec)
255.2... logprob:  0.597803, 0.273438 (0.648 sec)
255.3... logprob:  0.653657, 0.359375 (0.649 sec)
255.4... logprob:  0.597134, 0.273438 (0.648 sec)
255.5... logprob:  0.591213, 0.265625 (0.648 sec)
255.6... logprob:  0.611401, 0.296875 (0.648 sec)
255.7... logprob:  0.643898, 0.343750 (0.648 sec)
255.8... logprob:  0.604517, 0.289062 (0.648 sec)
255.9... logprob:  0.638710, 0.335938 (0.648 sec)
255.10... logprob:  0.597350, 0.281250 (0.647 sec)
255.11... logprob:  0.639281, 0.335938 (0.648 sec)
255.12... logprob:  0.720427, 0.437500 (0.670 sec)
255.13... logprob:  0.658215, 0.359375 (0.648 sec)
255.14... logprob:  0.663809, 0.367188 (0.648 sec)
255.15... logprob:  0.687028, 0.398438 (0.648 sec)
255.16... logprob:  0.627057, 0.320312 (0.649 sec)
255.17... logprob:  0.638521, 0.335938 (0.650 sec)
255.18... logprob:  0.638229, 0.335938 (0.649 sec)
255.19... logprob:  0.632785, 0.328125 (0.649 sec)
255.20... logprob:  0.648743, 0.351562 (0.649 sec)
255.21... logprob:  0.643398, 0.343750 (0.650 sec)
255.22... logprob:  0.628361, 0.320312 (0.649 sec)
255.23... logprob:  0.623708, 0.312500 (0.648 sec)
255.24... logprob:  0.579641, 0.242188 (0.648 sec)
255.25... logprob:  0.628579, 0.320312 (0.650 sec)
255.26... logprob:  0.673445, 0.390625 (0.649 sec)
255.27... logprob:  0.628333, 0.320312 (0.648 sec)
256.1... logprob:  0.678912, 0.398438 (0.649 sec)
256.2... logprob:  0.597794, 0.273438 (0.649 sec)
256.3... logprob:  0.653658, 0.359375 (0.648 sec)
256.4... logprob:  0.597130, 0.273438 (0.649 sec)
256.5... logprob:  0.591210, 0.265625 (0.649 sec)
256.6... logprob:  0.611400, 0.296875 (0.648 sec)
256.7... logprob:  0.643898, 0.343750 (0.648 sec)
256.8... logprob:  0.604520, 0.289062 (0.648 sec)
256.9... logprob:  0.638708, 0.335938 (0.648 sec)
256.10... logprob:  0.597356, 0.281250 (0.648 sec)
256.11... logprob:  0.639277, 0.335938 (0.648 sec)
256.12... logprob:  0.720402, 0.437500 (0.649 sec)
256.13... logprob:  0.658207, 0.359375 (0.648 sec)
256.14... logprob:  0.663801, 0.367188 (0.648 sec)
256.15... logprob:  0.687021, 0.398438 (0.649 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627105, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.952227e-03 [7.386941e-09] 
Layer 'conv1' biases: 3.568550e-07 [2.110774e-10] 
Layer 'conv2' weights[0]: 7.939780e-03 [7.817565e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.072046e-09] 
Layer 'conv3' weights[0]: 7.937839e-03 [6.819417e-09] 
Layer 'conv3' biases: 3.063803e-06 [3.022039e-09] 
Layer 'conv4' weights[0]: 7.970450e-03 [6.958543e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.387217e-08] 
Layer 'conv5' weights[0]: 7.969766e-03 [1.439348e-07] 
Layer 'conv5' biases: 1.000003e+00 [1.543374e-07] 
Layer 'fc6' weights[0]: 7.566123e-03 [1.547226e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.509834e-08] 
Layer 'fc7' weights[0]: 7.587203e-03 [2.020619e-07] 
Layer 'fc7' biases: 9.998571e-01 [1.900231e-07] 
Layer 'fc8' weights[0]: 6.561183e-04 [1.078884e-05] 
Layer 'fc8' biases: 1.196375e-01 [1.735455e-04] 
Train error last 27 batches: 0.636078
-------------------------------------------------------
Saved checkpoint to /data/ad6813/my-nets/saves/ConvNet__2014-07-08_14.54.04
======================================================= (2.318 sec)
256.16... logprob:  0.627057, 0.320312 (0.652 sec)
256.17... logprob:  0.638522, 0.335938 (0.653 sec)
256.18... logprob:  0.638229, 0.335938 (0.653 sec)
256.19... logprob:  0.632785, 0.328125 (0.653 sec)
256.20... logprob:  0.648745, 0.351562 (0.653 sec)
256.21... logprob:  0.643398, 0.343750 (0.652 sec)
256.22... logprob:  0.628356, 0.320312 (0.653 sec)
256.23... logprob:  0.623700, 0.312500 (0.658 sec)
256.24... logprob:  0.579618, 0.242188 (0.652 sec)
256.25... logprob:  0.628574, 0.320312 (0.648 sec)
256.26... logprob:  0.673452, 0.390625 (0.650 sec)
256.27... logprob:  0.628329, 0.320312 (0.648 sec)
257.1... logprob:  0.678918, 0.398438 (0.649 sec)
257.2... logprob:  0.597788, 0.273438 (0.648 sec)
257.3... logprob:  0.653658, 0.359375 (0.649 sec)
257.4... logprob:  0.597127, 0.273438 (0.648 sec)
257.5... logprob:  0.591211, 0.265625 (0.650 sec)
257.6... logprob:  0.611403, 0.296875 (0.648 sec)
257.7... logprob:  0.643896, 0.343750 (0.648 sec)
257.8... logprob:  0.604527, 0.289062 (0.648 sec)
257.9... logprob:  0.638705, 0.335938 (0.648 sec)
257.10... logprob:  0.597366, 0.281250 (0.647 sec)
257.11... logprob:  0.639270, 0.335938 (0.649 sec)
257.12... logprob:  0.720362, 0.437500 (0.648 sec)
257.13... logprob:  0.658193, 0.359375 (0.649 sec)
257.14... logprob:  0.663789, 0.367188 (0.647 sec)
257.15... logprob:  0.687006, 0.398438 (0.648 sec)
257.16... logprob:  0.627057, 0.320312 (0.648 sec)
257.17... logprob:  0.638522, 0.335938 (0.650 sec)
257.18... logprob:  0.638229, 0.335938 (0.649 sec)
257.19... logprob:  0.632784, 0.328125 (0.649 sec)
257.20... logprob:  0.648746, 0.351562 (0.648 sec)
257.21... logprob:  0.643398, 0.343750 (0.650 sec)
257.22... logprob:  0.628351, 0.320312 (0.648 sec)
257.23... logprob:  0.623693, 0.312500 (0.648 sec)
257.24... logprob:  0.579593, 0.242188 (0.648 sec)
257.25... logprob:  0.628568, 0.320312 (0.649 sec)
257.26... logprob:  0.673461, 0.390625 (0.649 sec)
257.27... logprob:  0.628325, 0.320312 (0.649 sec)
258.1... logprob:  0.678926, 0.398438 (0.648 sec)
258.2... logprob:  0.597778, 0.273438 (0.649 sec)
258.3... logprob:  0.653660, 0.359375 (0.648 sec)
258.4... logprob:  0.597121, 0.273438 (0.649 sec)
258.5... logprob:  0.591207, 0.265625 (0.647 sec)
258.6... logprob:  0.611402, 0.296875 (0.649 sec)
258.7... logprob:  0.643895, 0.343750 (0.647 sec)
258.8... logprob:  0.604529, 0.289062 (0.648 sec)
258.9... logprob:  0.638703, 0.335938 (0.647 sec)
258.10... logprob:  0.597371, 0.281250 (0.648 sec)
258.11... logprob:  0.639266, 0.335938 (0.648 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633445, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.952045e-03 [6.624620e-09] 
Layer 'conv1' biases: 3.600037e-07 [1.084005e-10] 
Layer 'conv2' weights[0]: 7.939579e-03 [5.525205e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.227741e-10] 
Layer 'conv3' weights[0]: 7.937646e-03 [5.434678e-09] 
Layer 'conv3' biases: 3.086601e-06 [1.687255e-09] 
Layer 'conv4' weights[0]: 7.970265e-03 [5.594525e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.517974e-08] 
Layer 'conv5' weights[0]: 7.969562e-03 [9.202839e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.877530e-08] 
Layer 'fc6' weights[0]: 7.565930e-03 [1.033739e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.518129e-09] 
Layer 'fc7' weights[0]: 7.585273e-03 [1.334766e-07] 
Layer 'fc7' biases: 9.998572e-01 [1.178087e-07] 
Layer 'fc8' weights[0]: 6.757189e-04 [6.732404e-06] 
Layer 'fc8' biases: 1.208006e-01 [1.327625e-04] 
Train error last 27 batches: 0.636072
-------------------------------------------------------
Not saving because 0.633445 > 0.627105 (256.15: -0.00%)
======================================================= (1.754 sec)
258.12... logprob:  0.720335, 0.437500 (0.650 sec)
258.13... logprob:  0.658184, 0.359375 (0.648 sec)
258.14... logprob:  0.663780, 0.367188 (0.650 sec)
258.15... logprob:  0.686997, 0.398438 (0.648 sec)
258.16... logprob:  0.627057, 0.320312 (0.649 sec)
258.17... logprob:  0.638521, 0.335938 (0.649 sec)
258.18... logprob:  0.638229, 0.335938 (0.650 sec)
258.19... logprob:  0.632783, 0.328125 (0.651 sec)
258.20... logprob:  0.648748, 0.351562 (0.650 sec)
258.21... logprob:  0.643398, 0.343750 (0.649 sec)
258.22... logprob:  0.628347, 0.320312 (0.649 sec)
258.23... logprob:  0.623685, 0.312500 (0.647 sec)
258.24... logprob:  0.579572, 0.242188 (0.649 sec)
258.25... logprob:  0.628563, 0.320312 (0.648 sec)
258.26... logprob:  0.673468, 0.390625 (0.650 sec)
258.27... logprob:  0.628321, 0.320312 (0.648 sec)
259.1... logprob:  0.678932, 0.398438 (0.649 sec)
259.2... logprob:  0.597772, 0.273438 (0.648 sec)
259.3... logprob:  0.653661, 0.359375 (0.649 sec)
259.4... logprob:  0.597119, 0.273438 (0.648 sec)
259.5... logprob:  0.591207, 0.265625 (0.649 sec)
259.6... logprob:  0.611405, 0.296875 (0.648 sec)
259.7... logprob:  0.643893, 0.343750 (0.649 sec)
259.8... logprob:  0.604535, 0.289062 (0.647 sec)
259.9... logprob:  0.638700, 0.335938 (0.648 sec)
259.10... logprob:  0.597380, 0.281250 (0.647 sec)
259.11... logprob:  0.639260, 0.335938 (0.649 sec)
259.12... logprob:  0.720299, 0.437500 (0.649 sec)
259.13... logprob:  0.658172, 0.359375 (0.649 sec)
259.14... logprob:  0.663768, 0.367188 (0.647 sec)
259.15... logprob:  0.686983, 0.398438 (0.649 sec)
259.16... logprob:  0.627058, 0.320312 (0.648 sec)
259.17... logprob:  0.638522, 0.335938 (0.651 sec)
259.18... logprob:  0.638228, 0.335938 (0.649 sec)
259.19... logprob:  0.632782, 0.328125 (0.650 sec)
259.20... logprob:  0.648749, 0.351562 (0.649 sec)
259.21... logprob:  0.643398, 0.343750 (0.650 sec)
259.22... logprob:  0.628342, 0.320312 (0.648 sec)
259.23... logprob:  0.623679, 0.312500 (0.649 sec)
259.24... logprob:  0.579551, 0.242188 (0.648 sec)
259.25... logprob:  0.628558, 0.320312 (0.649 sec)
259.26... logprob:  0.673474, 0.390625 (0.649 sec)
259.27... logprob:  0.628318, 0.320312 (0.649 sec)
260.1... logprob:  0.678939, 0.398438 (0.648 sec)
260.2... logprob:  0.597762, 0.273438 (0.649 sec)
260.3... logprob:  0.653663, 0.359375 (0.648 sec)
260.4... logprob:  0.597112, 0.273438 (0.649 sec)
260.5... logprob:  0.591202, 0.265625 (0.648 sec)
260.6... logprob:  0.611402, 0.296875 (0.649 sec)
260.7... logprob:  0.643893, 0.343750 (0.648 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.689184, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.951831e-03 [6.763902e-09] 
Layer 'conv1' biases: 3.635556e-07 [1.320181e-10] 
Layer 'conv2' weights[0]: 7.939394e-03 [5.823275e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.338418e-10] 
Layer 'conv3' weights[0]: 7.937446e-03 [5.707098e-09] 
Layer 'conv3' biases: 3.115239e-06 [1.956058e-09] 
Layer 'conv4' weights[0]: 7.970056e-03 [5.882199e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.767102e-08] 
Layer 'conv5' weights[0]: 7.969379e-03 [1.063282e-07] 
Layer 'conv5' biases: 1.000003e+00 [1.140157e-07] 
Layer 'fc6' weights[0]: 7.565748e-03 [1.171710e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.110520e-08] 
Layer 'fc7' weights[0]: 7.583343e-03 [1.527544e-07] 
Layer 'fc7' biases: 9.998567e-01 [1.387389e-07] 
Layer 'fc8' weights[0]: 6.457433e-04 [7.826156e-06] 
Layer 'fc8' biases: 1.209907e-01 [1.582659e-04] 
Train error last 27 batches: 0.636064
-------------------------------------------------------
Not saving because 0.689184 > 0.627105 (256.15: -0.00%)
======================================================= (1.751 sec)
260.8... logprob:  0.604536, 0.289062 (0.649 sec)
260.9... logprob:  0.638699, 0.335938 (0.648 sec)
260.10... logprob:  0.597384, 0.281250 (0.648 sec)
260.11... logprob:  0.639257, 0.335938 (0.648 sec)
260.12... logprob:  0.720278, 0.437500 (0.650 sec)
260.13... logprob:  0.658165, 0.359375 (0.648 sec)
260.14... logprob:  0.663761, 0.367188 (0.649 sec)
260.15... logprob:  0.686976, 0.398438 (0.648 sec)
260.16... logprob:  0.627057, 0.320312 (0.650 sec)
260.17... logprob:  0.638522, 0.335938 (0.650 sec)
260.18... logprob:  0.638228, 0.335938 (0.650 sec)
260.19... logprob:  0.632781, 0.328125 (0.649 sec)
260.20... logprob:  0.648750, 0.351562 (0.649 sec)
260.21... logprob:  0.643398, 0.343750 (0.649 sec)
260.22... logprob:  0.628338, 0.320312 (0.649 sec)
260.23... logprob:  0.623672, 0.312500 (0.648 sec)
260.24... logprob:  0.579529, 0.242188 (0.649 sec)
260.25... logprob:  0.628553, 0.320312 (0.649 sec)
260.26... logprob:  0.673481, 0.390625 (0.650 sec)
260.27... logprob:  0.628314, 0.320312 (0.648 sec)
261.1... logprob:  0.678945, 0.398438 (0.649 sec)
261.2... logprob:  0.597756, 0.273438 (0.648 sec)
261.3... logprob:  0.653663, 0.359375 (0.649 sec)
261.4... logprob:  0.597110, 0.273438 (0.647 sec)
261.5... logprob:  0.591203, 0.265625 (0.649 sec)
261.6... logprob:  0.611405, 0.296875 (0.648 sec)
261.7... logprob:  0.643892, 0.343750 (0.649 sec)
261.8... logprob:  0.604543, 0.289062 (0.648 sec)
261.9... logprob:  0.638696, 0.335938 (0.649 sec)
261.10... logprob:  0.597394, 0.281250 (0.647 sec)
261.11... logprob:  0.639250, 0.335938 (0.649 sec)
261.12... logprob:  0.720237, 0.437500 (0.649 sec)
261.13... logprob:  0.658150, 0.359375 (0.649 sec)
261.14... logprob:  0.663748, 0.367188 (0.648 sec)
261.15... logprob:  0.686961, 0.398438 (0.649 sec)
261.16... logprob:  0.627057, 0.320312 (0.648 sec)
261.17... logprob:  0.638522, 0.335938 (0.650 sec)
261.18... logprob:  0.638228, 0.335938 (0.649 sec)
261.19... logprob:  0.632780, 0.328125 (0.650 sec)
261.20... logprob:  0.648752, 0.351562 (0.649 sec)
261.21... logprob:  0.643398, 0.343750 (0.651 sec)
261.22... logprob:  0.628332, 0.320312 (0.648 sec)
261.23... logprob:  0.623665, 0.312500 (0.649 sec)
261.24... logprob:  0.579506, 0.242188 (0.649 sec)
261.25... logprob:  0.628547, 0.320312 (0.650 sec)
261.26... logprob:  0.673489, 0.390625 (0.651 sec)
261.27... logprob:  0.628310, 0.320312 (0.650 sec)
262.1... logprob:  0.678953, 0.398438 (0.648 sec)
262.2... logprob:  0.597745, 0.273438 (0.649 sec)
262.3... logprob:  0.653665, 0.359375 (0.648 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633213, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.951636e-03 [6.675673e-09] 
Layer 'conv1' biases: 3.671411e-07 [6.449077e-11] 
Layer 'conv2' weights[0]: 7.939204e-03 [4.878002e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.596354e-10] 
Layer 'conv3' weights[0]: 7.937243e-03 [4.482929e-09] 
Layer 'conv3' biases: 3.143575e-06 [7.263539e-10] 
Layer 'conv4' weights[0]: 7.969855e-03 [4.389159e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.857694e-09] 
Layer 'conv5' weights[0]: 7.969178e-03 [2.418439e-08] 
Layer 'conv5' biases: 1.000003e+00 [2.569690e-08] 
Layer 'fc6' weights[0]: 7.565542e-03 [4.641223e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.449098e-09] 
Layer 'fc7' weights[0]: 7.581373e-03 [5.452000e-08] 
Layer 'fc7' biases: 9.998564e-01 [3.046398e-08] 
Layer 'fc8' weights[0]: 6.177837e-04 [1.704532e-06] 
Layer 'fc8' biases: 1.211866e-01 [4.308810e-05] 
Train error last 27 batches: 0.636057
-------------------------------------------------------
Not saving because 0.633213 > 0.627105 (256.15: -0.00%)
======================================================= (1.832 sec)
262.4... logprob:  0.597103, 0.273438 (0.650 sec)
262.5... logprob:  0.591198, 0.265625 (0.648 sec)
262.6... logprob:  0.611404, 0.296875 (0.649 sec)
262.7... logprob:  0.643891, 0.343750 (0.648 sec)
262.8... logprob:  0.604545, 0.289062 (0.649 sec)
262.9... logprob:  0.638694, 0.335938 (0.648 sec)
262.10... logprob:  0.597399, 0.281250 (0.649 sec)
262.11... logprob:  0.639245, 0.335938 (0.648 sec)
262.12... logprob:  0.720210, 0.437500 (0.650 sec)
262.13... logprob:  0.658141, 0.359375 (0.649 sec)
262.14... logprob:  0.663739, 0.367188 (0.649 sec)
262.15... logprob:  0.686951, 0.398438 (0.648 sec)
262.16... logprob:  0.627058, 0.320312 (0.650 sec)
262.17... logprob:  0.638521, 0.335938 (0.650 sec)
262.18... logprob:  0.638228, 0.335938 (0.650 sec)
262.19... logprob:  0.632778, 0.328125 (0.649 sec)
262.20... logprob:  0.648753, 0.351562 (0.650 sec)
262.21... logprob:  0.643398, 0.343750 (0.650 sec)
262.22... logprob:  0.628328, 0.320312 (0.649 sec)
262.23... logprob:  0.623658, 0.312500 (0.648 sec)
262.24... logprob:  0.579485, 0.242188 (0.649 sec)
262.25... logprob:  0.628543, 0.320312 (0.649 sec)
262.26... logprob:  0.673496, 0.390625 (0.650 sec)
262.27... logprob:  0.628306, 0.320312 (0.649 sec)
263.1... logprob:  0.678959, 0.398438 (0.650 sec)
263.2... logprob:  0.597739, 0.273438 (0.648 sec)
263.3... logprob:  0.653666, 0.359375 (0.649 sec)
263.4... logprob:  0.597100, 0.273438 (0.649 sec)
263.5... logprob:  0.591199, 0.265625 (0.650 sec)
263.6... logprob:  0.611406, 0.296875 (0.649 sec)
263.7... logprob:  0.643890, 0.343750 (0.649 sec)
263.8... logprob:  0.604551, 0.289062 (0.648 sec)
263.9... logprob:  0.638692, 0.335938 (0.649 sec)
263.10... logprob:  0.597407, 0.281250 (0.648 sec)
263.11... logprob:  0.639240, 0.335938 (0.649 sec)
263.12... logprob:  0.720176, 0.437500 (0.649 sec)
263.13... logprob:  0.658130, 0.359375 (0.650 sec)
263.14... logprob:  0.663728, 0.367188 (0.648 sec)
263.15... logprob:  0.686938, 0.398438 (0.650 sec)
263.16... logprob:  0.627058, 0.320312 (0.649 sec)
263.17... logprob:  0.638521, 0.335938 (0.651 sec)
263.18... logprob:  0.638228, 0.335938 (0.649 sec)
263.19... logprob:  0.632778, 0.328125 (0.650 sec)
263.20... logprob:  0.648755, 0.351562 (0.649 sec)
263.21... logprob:  0.643398, 0.343750 (0.651 sec)
263.22... logprob:  0.628324, 0.320312 (0.648 sec)
263.23... logprob:  0.623651, 0.312500 (0.649 sec)
263.24... logprob:  0.579463, 0.242188 (0.648 sec)
263.25... logprob:  0.628538, 0.320312 (0.650 sec)
263.26... logprob:  0.673503, 0.390625 (0.649 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.628373, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.951426e-03 [6.451919e-09] 
Layer 'conv1' biases: 3.705533e-07 [6.491900e-11] 
Layer 'conv2' weights[0]: 7.939020e-03 [4.890542e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.336105e-10] 
Layer 'conv3' weights[0]: 7.937047e-03 [4.410016e-09] 
Layer 'conv3' biases: 3.169634e-06 [6.585988e-10] 
Layer 'conv4' weights[0]: 7.969677e-03 [4.327282e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.873583e-09] 
Layer 'conv5' weights[0]: 7.968995e-03 [1.780066e-08] 
Layer 'conv5' biases: 1.000003e+00 [1.871282e-08] 
Layer 'fc6' weights[0]: 7.565336e-03 [4.273037e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.793508e-09] 
Layer 'fc7' weights[0]: 7.579444e-03 [4.800827e-08] 
Layer 'fc7' biases: 9.998563e-01 [2.233752e-08] 
Layer 'fc8' weights[0]: 6.116358e-04 [1.225898e-06] 
Layer 'fc8' biases: 1.218398e-01 [3.857854e-05] 
Train error last 27 batches: 0.636050
-------------------------------------------------------
Not saving because 0.628373 > 0.627105 (256.15: -0.00%)
======================================================= (1.846 sec)
263.27... logprob:  0.628303, 0.320312 (0.649 sec)
264.1... logprob:  0.678966, 0.398438 (0.648 sec)
264.2... logprob:  0.597729, 0.273438 (0.650 sec)
264.3... logprob:  0.653668, 0.359375 (0.648 sec)
264.4... logprob:  0.597094, 0.273438 (0.650 sec)
264.5... logprob:  0.591194, 0.265625 (0.648 sec)
264.6... logprob:  0.611406, 0.296875 (0.649 sec)
264.7... logprob:  0.643889, 0.343750 (0.648 sec)
264.8... logprob:  0.604553, 0.289062 (0.649 sec)
264.9... logprob:  0.638690, 0.335938 (0.648 sec)
264.10... logprob:  0.597412, 0.281250 (0.649 sec)
264.11... logprob:  0.639235, 0.335938 (0.648 sec)
264.12... logprob:  0.720150, 0.437500 (0.651 sec)
264.13... logprob:  0.658121, 0.359375 (0.648 sec)
264.14... logprob:  0.663720, 0.367188 (0.649 sec)
264.15... logprob:  0.686931, 0.398438 (0.648 sec)
264.16... logprob:  0.627058, 0.320312 (0.649 sec)
264.17... logprob:  0.638521, 0.335938 (0.650 sec)
264.18... logprob:  0.638229, 0.335938 (0.650 sec)
264.19... logprob:  0.632777, 0.328125 (0.649 sec)
264.20... logprob:  0.648757, 0.351562 (0.650 sec)
264.21... logprob:  0.643399, 0.343750 (0.651 sec)
264.22... logprob:  0.628319, 0.320312 (0.655 sec)
264.23... logprob:  0.623644, 0.312500 (0.648 sec)
264.24... logprob:  0.579441, 0.242188 (0.649 sec)
264.25... logprob:  0.628532, 0.320312 (0.649 sec)
264.26... logprob:  0.673510, 0.390625 (0.651 sec)
264.27... logprob:  0.628299, 0.320312 (0.648 sec)
265.1... logprob:  0.678972, 0.398438 (0.649 sec)
265.2... logprob:  0.597723, 0.273438 (0.648 sec)
265.3... logprob:  0.653668, 0.359375 (0.649 sec)
265.4... logprob:  0.597092, 0.273438 (0.649 sec)
265.5... logprob:  0.591195, 0.265625 (0.650 sec)
265.6... logprob:  0.611408, 0.296875 (0.648 sec)
265.7... logprob:  0.643887, 0.343750 (0.650 sec)
265.8... logprob:  0.604559, 0.289062 (0.648 sec)
265.9... logprob:  0.638687, 0.335938 (0.649 sec)
265.10... logprob:  0.597421, 0.281250 (0.649 sec)
265.11... logprob:  0.639230, 0.335938 (0.649 sec)
265.12... logprob:  0.720113, 0.437500 (0.649 sec)
265.13... logprob:  0.658108, 0.359375 (0.649 sec)
265.14... logprob:  0.663708, 0.367188 (0.648 sec)
265.15... logprob:  0.686917, 0.398438 (0.649 sec)
265.16... logprob:  0.627058, 0.320312 (0.653 sec)
265.17... logprob:  0.638521, 0.335938 (0.657 sec)
265.18... logprob:  0.638228, 0.335938 (0.653 sec)
265.19... logprob:  0.632776, 0.328125 (0.653 sec)
265.20... logprob:  0.648758, 0.351562 (0.652 sec)
265.21... logprob:  0.643399, 0.343750 (0.654 sec)
265.22... logprob:  0.628314, 0.320312 (0.652 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.653367, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.951246e-03 [6.716139e-09] 
Layer 'conv1' biases: 3.739530e-07 [1.280524e-10] 
Layer 'conv2' weights[0]: 7.938818e-03 [5.911671e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.687699e-10] 
Layer 'conv3' weights[0]: 7.936841e-03 [5.205599e-09] 
Layer 'conv3' biases: 3.195772e-06 [1.555715e-09] 
Layer 'conv4' weights[0]: 7.969475e-03 [5.125602e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.035384e-08] 
Layer 'conv5' weights[0]: 7.968808e-03 [6.196098e-08] 
Layer 'conv5' biases: 1.000003e+00 [6.614081e-08] 
Layer 'fc6' weights[0]: 7.565136e-03 [7.682513e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.591896e-09] 
Layer 'fc7' weights[0]: 7.577562e-03 [1.009120e-07] 
Layer 'fc7' biases: 9.998561e-01 [8.355916e-08] 
Layer 'fc8' weights[0]: 6.061447e-04 [4.646718e-06] 
Layer 'fc8' biases: 1.224808e-01 [7.404122e-05] 
Train error last 27 batches: 0.636043
-------------------------------------------------------
Not saving because 0.653367 > 0.627105 (256.15: -0.00%)
======================================================= (1.790 sec)
265.23... logprob:  0.623638, 0.312500 (0.648 sec)
265.24... logprob:  0.579418, 0.242188 (0.647 sec)
265.25... logprob:  0.628527, 0.320312 (0.649 sec)
265.26... logprob:  0.673518, 0.390625 (0.648 sec)
265.27... logprob:  0.628295, 0.320312 (0.649 sec)
266.1... logprob:  0.678980, 0.398438 (0.648 sec)
266.2... logprob:  0.597713, 0.273438 (0.649 sec)
266.3... logprob:  0.653670, 0.359375 (0.648 sec)
266.4... logprob:  0.597086, 0.273438 (0.649 sec)
266.5... logprob:  0.591191, 0.265625 (0.647 sec)
266.6... logprob:  0.611407, 0.296875 (0.648 sec)
266.7... logprob:  0.643887, 0.343750 (0.647 sec)
266.8... logprob:  0.604562, 0.289062 (0.648 sec)
266.9... logprob:  0.638685, 0.335938 (0.647 sec)
266.10... logprob:  0.597427, 0.281250 (0.648 sec)
266.11... logprob:  0.639226, 0.335938 (0.647 sec)
266.12... logprob:  0.720086, 0.437500 (0.650 sec)
266.13... logprob:  0.658099, 0.359375 (0.647 sec)
266.14... logprob:  0.663699, 0.367188 (0.648 sec)
266.15... logprob:  0.686907, 0.398438 (0.648 sec)
266.16... logprob:  0.627058, 0.320312 (0.649 sec)
266.17... logprob:  0.638521, 0.335938 (0.649 sec)
266.18... logprob:  0.638229, 0.335938 (0.649 sec)
266.19... logprob:  0.632776, 0.328125 (0.648 sec)
266.20... logprob:  0.648761, 0.351562 (0.649 sec)
266.21... logprob:  0.643400, 0.343750 (0.650 sec)
266.22... logprob:  0.628310, 0.320312 (0.648 sec)
266.23... logprob:  0.623630, 0.312500 (0.647 sec)
266.24... logprob:  0.579395, 0.242188 (0.648 sec)
266.25... logprob:  0.628522, 0.320312 (0.649 sec)
266.26... logprob:  0.673527, 0.390625 (0.650 sec)
266.27... logprob:  0.628292, 0.320312 (0.648 sec)
267.1... logprob:  0.678987, 0.398438 (0.658 sec)
267.2... logprob:  0.597707, 0.273438 (0.647 sec)
267.3... logprob:  0.653672, 0.359375 (0.648 sec)
267.4... logprob:  0.597084, 0.273438 (0.647 sec)
267.5... logprob:  0.591191, 0.265625 (0.648 sec)
267.6... logprob:  0.611409, 0.296875 (0.648 sec)
267.7... logprob:  0.643885, 0.343750 (0.648 sec)
267.8... logprob:  0.604568, 0.289062 (0.647 sec)
267.9... logprob:  0.638682, 0.335938 (0.648 sec)
267.10... logprob:  0.597437, 0.281250 (0.647 sec)
267.11... logprob:  0.639219, 0.335938 (0.648 sec)
267.12... logprob:  0.720047, 0.437500 (0.648 sec)
267.13... logprob:  0.658085, 0.359375 (0.648 sec)
267.14... logprob:  0.663686, 0.367188 (0.647 sec)
267.15... logprob:  0.686892, 0.398438 (0.648 sec)
267.16... logprob:  0.627058, 0.320312 (0.648 sec)
267.17... logprob:  0.638521, 0.335938 (0.650 sec)
267.18... logprob:  0.638228, 0.335938 (0.649 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627565, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.951024e-03 [6.562173e-09] 
Layer 'conv1' biases: 3.771184e-07 [1.751782e-10] 
Layer 'conv2' weights[0]: 7.938628e-03 [6.869523e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.702121e-10] 
Layer 'conv3' weights[0]: 7.936648e-03 [6.082025e-09] 
Layer 'conv3' biases: 3.218727e-06 [2.418227e-09] 
Layer 'conv4' weights[0]: 7.969264e-03 [6.122786e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.849112e-08] 
Layer 'conv5' weights[0]: 7.968602e-03 [1.108522e-07] 
Layer 'conv5' biases: 1.000003e+00 [1.185470e-07] 
Layer 'fc6' weights[0]: 7.564946e-03 [1.220588e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.170756e-08] 
Layer 'fc7' weights[0]: 7.575618e-03 [1.597574e-07] 
Layer 'fc7' biases: 9.998565e-01 [1.467825e-07] 
Layer 'fc8' weights[0]: 6.275232e-04 [8.238489e-06] 
Layer 'fc8' biases: 1.237123e-01 [1.366094e-04] 
Train error last 27 batches: 0.636036
-------------------------------------------------------
Not saving because 0.627565 > 0.627105 (256.15: -0.00%)
======================================================= (1.740 sec)
267.19... logprob:  0.632774, 0.328125 (0.650 sec)
267.20... logprob:  0.648761, 0.351562 (0.648 sec)
267.21... logprob:  0.643399, 0.343750 (0.650 sec)
267.22... logprob:  0.628306, 0.320312 (0.648 sec)
267.23... logprob:  0.623624, 0.312500 (0.648 sec)
267.24... logprob:  0.579376, 0.242188 (0.647 sec)
267.25... logprob:  0.628517, 0.320312 (0.650 sec)
267.26... logprob:  0.673533, 0.390625 (0.648 sec)
267.27... logprob:  0.628288, 0.320312 (0.649 sec)
268.1... logprob:  0.678994, 0.398438 (0.650 sec)
268.2... logprob:  0.597697, 0.273438 (0.649 sec)
268.3... logprob:  0.653673, 0.359375 (0.648 sec)
268.4... logprob:  0.597076, 0.273438 (0.649 sec)
268.5... logprob:  0.591186, 0.265625 (0.648 sec)
268.6... logprob:  0.611408, 0.296875 (0.649 sec)
268.7... logprob:  0.643885, 0.343750 (0.648 sec)
268.8... logprob:  0.604569, 0.289062 (0.648 sec)
268.9... logprob:  0.638681, 0.335938 (0.648 sec)
268.10... logprob:  0.597440, 0.281250 (0.649 sec)
268.11... logprob:  0.639216, 0.335938 (0.648 sec)
268.12... logprob:  0.720028, 0.437500 (0.650 sec)
268.13... logprob:  0.658079, 0.359375 (0.648 sec)
268.14... logprob:  0.663679, 0.367188 (0.649 sec)
268.15... logprob:  0.686885, 0.398438 (0.648 sec)
268.16... logprob:  0.627058, 0.320312 (0.649 sec)
268.17... logprob:  0.638521, 0.335938 (0.650 sec)
268.18... logprob:  0.638228, 0.335938 (0.650 sec)
268.19... logprob:  0.632773, 0.328125 (0.649 sec)
268.20... logprob:  0.648762, 0.351562 (0.649 sec)
268.21... logprob:  0.643399, 0.343750 (0.649 sec)
268.22... logprob:  0.628302, 0.320312 (0.648 sec)
268.23... logprob:  0.623618, 0.312500 (0.647 sec)
268.24... logprob:  0.579358, 0.242188 (0.649 sec)
268.25... logprob:  0.628513, 0.320312 (0.649 sec)
268.26... logprob:  0.673538, 0.390625 (0.650 sec)
268.27... logprob:  0.628285, 0.320312 (0.648 sec)
269.1... logprob:  0.678998, 0.398438 (0.649 sec)
269.2... logprob:  0.597691, 0.273438 (0.648 sec)
269.3... logprob:  0.653674, 0.359375 (0.649 sec)
269.4... logprob:  0.597074, 0.273438 (0.647 sec)
269.5... logprob:  0.591185, 0.265625 (0.648 sec)
269.6... logprob:  0.611409, 0.296875 (0.648 sec)
269.7... logprob:  0.643884, 0.343750 (0.648 sec)
269.8... logprob:  0.604573, 0.289062 (0.647 sec)
269.9... logprob:  0.638679, 0.335938 (0.649 sec)
269.10... logprob:  0.597447, 0.281250 (0.647 sec)
269.11... logprob:  0.639211, 0.335938 (0.649 sec)
269.12... logprob:  0.719999, 0.437500 (0.649 sec)
269.13... logprob:  0.658069, 0.359375 (0.649 sec)
269.14... logprob:  0.663670, 0.367188 (0.650 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633042, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.950847e-03 [6.798760e-09] 
Layer 'conv1' biases: 3.801981e-07 [1.558009e-10] 
Layer 'conv2' weights[0]: 7.938430e-03 [6.404778e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.272901e-10] 
Layer 'conv3' weights[0]: 7.936459e-03 [5.621099e-09] 
Layer 'conv3' biases: 3.240767e-06 [2.031141e-09] 
Layer 'conv4' weights[0]: 7.969061e-03 [5.629572e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.462825e-08] 
Layer 'conv5' weights[0]: 7.968378e-03 [8.762352e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.373774e-08] 
Layer 'fc6' weights[0]: 7.564756e-03 [1.004113e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.213269e-09] 
Layer 'fc7' weights[0]: 7.573722e-03 [1.304374e-07] 
Layer 'fc7' biases: 9.998568e-01 [1.151558e-07] 
Layer 'fc8' weights[0]: 6.593852e-04 [6.484968e-06] 
Layer 'fc8' biases: 1.251288e-01 [1.001457e-04] 
Train error last 27 batches: 0.636030
-------------------------------------------------------
Not saving because 0.633042 > 0.627105 (256.15: -0.00%)
======================================================= (1.754 sec)
269.15... logprob:  0.686875, 0.398438 (0.649 sec)
269.16... logprob:  0.627058, 0.320312 (0.649 sec)
269.17... logprob:  0.638521, 0.335938 (0.652 sec)
269.18... logprob:  0.638228, 0.335938 (0.650 sec)
269.19... logprob:  0.632772, 0.328125 (0.651 sec)
269.20... logprob:  0.648764, 0.351562 (0.649 sec)
269.21... logprob:  0.643400, 0.343750 (0.651 sec)
269.22... logprob:  0.628298, 0.320312 (0.649 sec)
269.23... logprob:  0.623611, 0.312500 (0.650 sec)
269.24... logprob:  0.579336, 0.242188 (0.648 sec)
269.25... logprob:  0.628508, 0.320312 (0.651 sec)
269.26... logprob:  0.673546, 0.390625 (0.650 sec)
269.27... logprob:  0.628282, 0.320312 (0.650 sec)
270.1... logprob:  0.679005, 0.398438 (0.649 sec)
270.2... logprob:  0.597684, 0.273438 (0.650 sec)
270.3... logprob:  0.653675, 0.359375 (0.648 sec)
270.4... logprob:  0.597070, 0.273438 (0.650 sec)
270.5... logprob:  0.591184, 0.265625 (0.649 sec)
270.6... logprob:  0.611410, 0.296875 (0.650 sec)
270.7... logprob:  0.643883, 0.343750 (0.648 sec)
270.8... logprob:  0.604578, 0.289062 (0.650 sec)
270.9... logprob:  0.638677, 0.335938 (0.648 sec)
270.10... logprob:  0.597454, 0.281250 (0.650 sec)
270.11... logprob:  0.639206, 0.335938 (0.649 sec)
270.12... logprob:  0.719966, 0.437500 (0.651 sec)
270.13... logprob:  0.658058, 0.359375 (0.649 sec)
270.14... logprob:  0.663660, 0.367188 (0.649 sec)
270.15... logprob:  0.686864, 0.398438 (0.648 sec)
270.16... logprob:  0.627058, 0.320312 (0.650 sec)
270.17... logprob:  0.638521, 0.335938 (0.651 sec)
270.18... logprob:  0.638228, 0.335938 (0.651 sec)
270.19... logprob:  0.632771, 0.328125 (0.650 sec)
270.20... logprob:  0.648766, 0.351562 (0.650 sec)
270.21... logprob:  0.643400, 0.343750 (0.650 sec)
270.22... logprob:  0.628292, 0.320312 (0.650 sec)
270.23... logprob:  0.623604, 0.312500 (0.648 sec)
270.24... logprob:  0.579313, 0.242188 (0.650 sec)
270.25... logprob:  0.628502, 0.320312 (0.650 sec)
270.26... logprob:  0.673553, 0.390625 (0.651 sec)
270.27... logprob:  0.628277, 0.320312 (0.649 sec)
271.1... logprob:  0.679012, 0.398438 (0.650 sec)
271.2... logprob:  0.597675, 0.273438 (0.648 sec)
271.3... logprob:  0.653676, 0.359375 (0.650 sec)
271.4... logprob:  0.597066, 0.273438 (0.649 sec)
271.5... logprob:  0.591182, 0.265625 (0.650 sec)
271.6... logprob:  0.611411, 0.296875 (0.649 sec)
271.7... logprob:  0.643882, 0.343750 (0.650 sec)
271.8... logprob:  0.604582, 0.289062 (0.648 sec)
271.9... logprob:  0.638675, 0.335938 (0.650 sec)
271.10... logprob:  0.597462, 0.281250 (0.648 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.693794, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.950658e-03 [6.901918e-09] 
Layer 'conv1' biases: 3.834898e-07 [1.373218e-10] 
Layer 'conv2' weights[0]: 7.938240e-03 [6.099695e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.061329e-10] 
Layer 'conv3' weights[0]: 7.936266e-03 [6.011599e-09] 
Layer 'conv3' biases: 3.265828e-06 [2.179527e-09] 
Layer 'conv4' weights[0]: 7.968865e-03 [6.249128e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.983120e-08] 
Layer 'conv5' weights[0]: 7.968179e-03 [1.191770e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.277378e-07] 
Layer 'fc6' weights[0]: 7.564567e-03 [1.297544e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.247341e-08] 
Layer 'fc7' weights[0]: 7.571806e-03 [1.665946e-07] 
Layer 'fc7' biases: 9.998568e-01 [1.531642e-07] 
Layer 'fc8' weights[0]: 6.627431e-04 [8.675472e-06] 
Layer 'fc8' biases: 1.259589e-01 [1.714774e-04] 
Train error last 27 batches: 0.636025
-------------------------------------------------------
Not saving because 0.693794 > 0.627105 (256.15: -0.00%)
======================================================= (1.748 sec)
271.11... logprob:  0.639201, 0.335938 (0.650 sec)
271.12... logprob:  0.719934, 0.437500 (0.650 sec)
271.13... logprob:  0.658047, 0.359375 (0.650 sec)
271.14... logprob:  0.663649, 0.367188 (0.650 sec)
271.15... logprob:  0.686852, 0.398438 (0.649 sec)
271.16... logprob:  0.627058, 0.320312 (0.649 sec)
271.17... logprob:  0.638521, 0.335938 (0.652 sec)
271.18... logprob:  0.638228, 0.335938 (0.650 sec)
271.19... logprob:  0.632770, 0.328125 (0.651 sec)
271.20... logprob:  0.648767, 0.351562 (0.649 sec)
271.21... logprob:  0.643400, 0.343750 (0.651 sec)
271.22... logprob:  0.628288, 0.320312 (0.648 sec)
271.23... logprob:  0.623597, 0.312500 (0.649 sec)
271.24... logprob:  0.579291, 0.242188 (0.649 sec)
271.25... logprob:  0.628498, 0.320312 (0.650 sec)
271.26... logprob:  0.673560, 0.390625 (0.650 sec)
271.27... logprob:  0.628273, 0.320312 (0.650 sec)
272.1... logprob:  0.679019, 0.398438 (0.649 sec)
272.2... logprob:  0.597667, 0.273438 (0.650 sec)
272.3... logprob:  0.653678, 0.359375 (0.649 sec)
272.4... logprob:  0.597061, 0.273438 (0.650 sec)
272.5... logprob:  0.591180, 0.265625 (0.648 sec)
272.6... logprob:  0.611412, 0.296875 (0.650 sec)
272.7... logprob:  0.643881, 0.343750 (0.648 sec)
272.8... logprob:  0.604586, 0.289062 (0.649 sec)
272.9... logprob:  0.638673, 0.335938 (0.648 sec)
272.10... logprob:  0.597468, 0.281250 (0.649 sec)
272.11... logprob:  0.639196, 0.335938 (0.649 sec)
272.12... logprob:  0.719903, 0.437500 (0.650 sec)
272.13... logprob:  0.658037, 0.359375 (0.649 sec)
272.14... logprob:  0.663639, 0.367188 (0.649 sec)
272.15... logprob:  0.686841, 0.398438 (0.648 sec)
272.16... logprob:  0.627058, 0.320312 (0.650 sec)
272.17... logprob:  0.638520, 0.335938 (0.650 sec)
272.18... logprob:  0.638228, 0.335938 (0.651 sec)
272.19... logprob:  0.632770, 0.328125 (0.650 sec)
272.20... logprob:  0.648769, 0.351562 (0.651 sec)
272.21... logprob:  0.643400, 0.343750 (0.650 sec)
272.22... logprob:  0.628284, 0.320312 (0.650 sec)
272.23... logprob:  0.623590, 0.312500 (0.648 sec)
272.24... logprob:  0.579269, 0.242188 (0.650 sec)
272.25... logprob:  0.628493, 0.320312 (0.650 sec)
272.26... logprob:  0.673568, 0.390625 (0.651 sec)
272.27... logprob:  0.628270, 0.320312 (0.732 sec)
273.1... logprob:  0.679026, 0.398438 (0.651 sec)
273.2... logprob:  0.597659, 0.273438 (0.649 sec)
273.3... logprob:  0.653679, 0.359375 (0.650 sec)
273.4... logprob:  0.597056, 0.273438 (0.650 sec)
273.5... logprob:  0.591177, 0.265625 (0.650 sec)
273.6... logprob:  0.611412, 0.296875 (0.649 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.632849, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.950453e-03 [7.261407e-09] 
Layer 'conv1' biases: 3.870740e-07 [1.665080e-10] 
Layer 'conv2' weights[0]: 7.938041e-03 [6.283613e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.842709e-10] 
Layer 'conv3' weights[0]: 7.936073e-03 [6.145387e-09] 
Layer 'conv3' biases: 3.295158e-06 [2.306432e-09] 
Layer 'conv4' weights[0]: 7.968676e-03 [6.314221e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.096444e-08] 
Layer 'conv5' weights[0]: 7.967981e-03 [1.257665e-07] 
Layer 'conv5' biases: 1.000003e+00 [1.347542e-07] 
Layer 'fc6' weights[0]: 7.564368e-03 [1.370046e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.324336e-08] 
Layer 'fc7' weights[0]: 7.569890e-03 [1.770762e-07] 
Layer 'fc7' biases: 9.998564e-01 [1.640319e-07] 
Layer 'fc8' weights[0]: 6.327735e-04 [9.189879e-06] 
Layer 'fc8' biases: 1.261055e-01 [1.885061e-04] 
Train error last 27 batches: 0.636017
-------------------------------------------------------
Not saving because 0.632849 > 0.627105 (256.15: -0.00%)
======================================================= (1.746 sec)
273.7... logprob:  0.643880, 0.343750 (0.650 sec)
273.8... logprob:  0.604590, 0.289062 (0.648 sec)
273.9... logprob:  0.638671, 0.335938 (0.649 sec)
273.10... logprob:  0.597476, 0.281250 (0.648 sec)
273.11... logprob:  0.639192, 0.335938 (0.650 sec)
273.12... logprob:  0.719871, 0.437500 (0.650 sec)
273.13... logprob:  0.658025, 0.359375 (0.650 sec)
273.14... logprob:  0.663628, 0.367188 (0.648 sec)
273.15... logprob:  0.686828, 0.398438 (0.649 sec)
273.16... logprob:  0.627059, 0.320312 (0.649 sec)
273.17... logprob:  0.638520, 0.335938 (0.652 sec)
273.18... logprob:  0.638228, 0.335938 (0.650 sec)
273.19... logprob:  0.632769, 0.328125 (0.651 sec)
273.20... logprob:  0.648769, 0.351562 (0.649 sec)
273.21... logprob:  0.643400, 0.343750 (0.651 sec)
273.22... logprob:  0.628280, 0.320312 (0.649 sec)
273.23... logprob:  0.623585, 0.312500 (0.649 sec)
273.24... logprob:  0.579251, 0.242188 (0.649 sec)
273.25... logprob:  0.628488, 0.320312 (0.651 sec)
273.26... logprob:  0.673574, 0.390625 (0.650 sec)
273.27... logprob:  0.628267, 0.320312 (0.651 sec)
274.1... logprob:  0.679032, 0.398438 (0.649 sec)
274.2... logprob:  0.597651, 0.273438 (0.649 sec)
274.3... logprob:  0.653681, 0.359375 (0.649 sec)
274.4... logprob:  0.597052, 0.273438 (0.650 sec)
274.5... logprob:  0.591174, 0.265625 (0.649 sec)
274.6... logprob:  0.611411, 0.296875 (0.650 sec)
274.7... logprob:  0.643879, 0.343750 (0.648 sec)
274.8... logprob:  0.604593, 0.289062 (0.650 sec)
274.9... logprob:  0.638669, 0.335938 (0.649 sec)
274.10... logprob:  0.597481, 0.281250 (0.650 sec)
274.11... logprob:  0.639187, 0.335938 (0.649 sec)
274.12... logprob:  0.719848, 0.437500 (0.651 sec)
274.13... logprob:  0.658017, 0.359375 (0.649 sec)
274.14... logprob:  0.663621, 0.367188 (0.650 sec)
274.15... logprob:  0.686820, 0.398438 (0.649 sec)
274.16... logprob:  0.627058, 0.320312 (0.650 sec)
274.17... logprob:  0.638521, 0.335938 (0.651 sec)
274.18... logprob:  0.638228, 0.335938 (0.651 sec)
274.19... logprob:  0.632768, 0.328125 (0.649 sec)
274.20... logprob:  0.648772, 0.351562 (0.652 sec)
274.21... logprob:  0.643401, 0.343750 (0.650 sec)
274.22... logprob:  0.628275, 0.320312 (0.650 sec)
274.23... logprob:  0.623578, 0.312500 (0.649 sec)
274.24... logprob:  0.579231, 0.242188 (0.650 sec)
274.25... logprob:  0.628484, 0.320312 (0.649 sec)
274.26... logprob:  0.673581, 0.390625 (0.651 sec)
274.27... logprob:  0.628263, 0.320312 (0.649 sec)
275.1... logprob:  0.679038, 0.398438 (0.650 sec)
275.2... logprob:  0.597645, 0.273438 (0.649 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.628152, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.950271e-03 [6.752044e-09] 
Layer 'conv1' biases: 3.906154e-07 [7.124821e-11] 
Layer 'conv2' weights[0]: 7.937868e-03 [4.934796e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.156710e-10] 
Layer 'conv3' weights[0]: 7.935880e-03 [4.618758e-09] 
Layer 'conv3' biases: 3.323466e-06 [9.046988e-10] 
Layer 'conv4' weights[0]: 7.968471e-03 [4.561980e-09] 
Layer 'conv4' biases: 1.000001e+00 [6.246369e-09] 
Layer 'conv5' weights[0]: 7.967782e-03 [3.772423e-08] 
Layer 'conv5' biases: 1.000003e+00 [4.024816e-08] 
Layer 'fc6' weights[0]: 7.564177e-03 [5.548815e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.929227e-09] 
Layer 'fc7' weights[0]: 7.567970e-03 [6.935098e-08] 
Layer 'fc7' biases: 9.998561e-01 [4.852803e-08] 
Layer 'fc8' weights[0]: 6.112286e-04 [2.694702e-06] 
Layer 'fc8' biases: 1.264057e-01 [6.480867e-05] 
Train error last 27 batches: 0.636010
-------------------------------------------------------
Not saving because 0.628152 > 0.627105 (256.15: -0.00%)
======================================================= (1.803 sec)
275.3... logprob:  0.653681, 0.359375 (0.649 sec)
275.4... logprob:  0.597049, 0.273438 (0.649 sec)
275.5... logprob:  0.591174, 0.265625 (0.650 sec)
275.6... logprob:  0.611413, 0.296875 (0.649 sec)
275.7... logprob:  0.643878, 0.343750 (0.650 sec)
275.8... logprob:  0.604597, 0.289062 (0.649 sec)
275.9... logprob:  0.638667, 0.335938 (0.650 sec)
275.10... logprob:  0.597489, 0.281250 (0.649 sec)
275.11... logprob:  0.639182, 0.335938 (0.650 sec)
275.12... logprob:  0.719815, 0.437500 (0.650 sec)
275.13... logprob:  0.658007, 0.359375 (0.650 sec)
275.14... logprob:  0.663611, 0.367188 (0.648 sec)
275.15... logprob:  0.686809, 0.398438 (0.649 sec)
275.16... logprob:  0.627059, 0.320312 (0.649 sec)
275.17... logprob:  0.638520, 0.335938 (0.651 sec)
275.18... logprob:  0.638227, 0.335938 (0.650 sec)
275.19... logprob:  0.632767, 0.328125 (0.651 sec)
275.20... logprob:  0.648773, 0.351562 (0.650 sec)
275.21... logprob:  0.643401, 0.343750 (0.651 sec)
275.22... logprob:  0.628272, 0.320312 (0.649 sec)
275.23... logprob:  0.623571, 0.312500 (0.650 sec)
275.24... logprob:  0.579208, 0.242188 (0.649 sec)
275.25... logprob:  0.628479, 0.320312 (0.651 sec)
275.26... logprob:  0.673589, 0.390625 (0.650 sec)
275.27... logprob:  0.628260, 0.320312 (0.650 sec)
276.1... logprob:  0.679046, 0.398438 (0.649 sec)
276.2... logprob:  0.597636, 0.273438 (0.650 sec)
276.3... logprob:  0.653683, 0.359375 (0.649 sec)
276.4... logprob:  0.597043, 0.273438 (0.650 sec)
276.5... logprob:  0.591171, 0.265625 (0.648 sec)
276.6... logprob:  0.611413, 0.296875 (0.650 sec)
276.7... logprob:  0.643877, 0.343750 (0.649 sec)
276.8... logprob:  0.604601, 0.289062 (0.650 sec)
276.9... logprob:  0.638664, 0.335938 (0.648 sec)
276.10... logprob:  0.597496, 0.281250 (0.649 sec)
276.11... logprob:  0.639178, 0.335938 (0.651 sec)
276.12... logprob:  0.719784, 0.437500 (0.651 sec)
276.13... logprob:  0.657996, 0.359375 (0.649 sec)
276.14... logprob:  0.663601, 0.367188 (0.650 sec)
276.15... logprob:  0.686797, 0.398438 (0.649 sec)
276.16... logprob:  0.627059, 0.320312 (0.651 sec)
276.17... logprob:  0.638520, 0.335938 (0.650 sec)
276.18... logprob:  0.638228, 0.335938 (0.652 sec)
276.19... logprob:  0.632767, 0.328125 (0.650 sec)
276.20... logprob:  0.648775, 0.351562 (0.651 sec)
276.21... logprob:  0.643402, 0.343750 (0.650 sec)
276.22... logprob:  0.628266, 0.320312 (0.650 sec)
276.23... logprob:  0.623564, 0.312500 (0.648 sec)
276.24... logprob:  0.579186, 0.242188 (0.650 sec)
276.25... logprob:  0.628474, 0.320312 (0.649 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.653514, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.950080e-03 [6.539125e-09] 
Layer 'conv1' biases: 3.940132e-07 [7.195704e-11] 
Layer 'conv2' weights[0]: 7.937676e-03 [4.915346e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.758389e-10] 
Layer 'conv3' weights[0]: 7.935684e-03 [4.698749e-09] 
Layer 'conv3' biases: 3.350265e-06 [1.086463e-09] 
Layer 'conv4' weights[0]: 7.968282e-03 [4.722027e-09] 
Layer 'conv4' biases: 1.000001e+00 [8.786124e-09] 
Layer 'conv5' weights[0]: 7.967591e-03 [5.214376e-08] 
Layer 'conv5' biases: 1.000003e+00 [5.582091e-08] 
Layer 'fc6' weights[0]: 7.563972e-03 [6.773222e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.497097e-09] 
Layer 'fc7' weights[0]: 7.566011e-03 [8.708054e-08] 
Layer 'fc7' biases: 9.998558e-01 [6.835450e-08] 
Layer 'fc8' weights[0]: 6.059768e-04 [3.770151e-06] 
Layer 'fc8' biases: 1.270522e-01 [9.240316e-05] 
Train error last 27 batches: 0.636003
-------------------------------------------------------
Not saving because 0.653514 > 0.627105 (256.15: -0.00%)
======================================================= (1.784 sec)
276.26... logprob:  0.673597, 0.390625 (0.651 sec)
276.27... logprob:  0.628256, 0.320312 (0.649 sec)
277.1... logprob:  0.679052, 0.398438 (0.650 sec)
277.2... logprob:  0.597628, 0.273438 (0.649 sec)
277.3... logprob:  0.653684, 0.359375 (0.650 sec)
277.4... logprob:  0.597040, 0.273438 (0.648 sec)
277.5... logprob:  0.591169, 0.265625 (0.650 sec)
277.6... logprob:  0.611414, 0.296875 (0.649 sec)
277.7... logprob:  0.643876, 0.343750 (0.650 sec)
277.8... logprob:  0.604606, 0.289062 (0.648 sec)
277.9... logprob:  0.638662, 0.335938 (0.649 sec)
277.10... logprob:  0.597503, 0.281250 (0.648 sec)
277.11... logprob:  0.639173, 0.335938 (0.650 sec)
277.12... logprob:  0.719753, 0.437500 (0.649 sec)
277.13... logprob:  0.657986, 0.359375 (0.650 sec)
277.14... logprob:  0.663591, 0.367188 (0.648 sec)
277.15... logprob:  0.686786, 0.398438 (0.649 sec)
277.16... logprob:  0.627059, 0.320312 (0.649 sec)
277.17... logprob:  0.638520, 0.335938 (0.652 sec)
277.18... logprob:  0.638228, 0.335938 (0.649 sec)
277.19... logprob:  0.632766, 0.328125 (0.651 sec)
277.20... logprob:  0.648777, 0.351562 (0.649 sec)
277.21... logprob:  0.643401, 0.343750 (0.652 sec)
277.22... logprob:  0.628262, 0.320312 (0.649 sec)
277.23... logprob:  0.623557, 0.312500 (0.650 sec)
277.24... logprob:  0.579164, 0.242188 (0.649 sec)
277.25... logprob:  0.628469, 0.320312 (0.651 sec)
277.26... logprob:  0.673604, 0.390625 (0.650 sec)
277.27... logprob:  0.628252, 0.320312 (0.650 sec)
278.1... logprob:  0.679060, 0.398438 (0.649 sec)
278.2... logprob:  0.597619, 0.273438 (0.650 sec)
278.3... logprob:  0.653686, 0.359375 (0.648 sec)
278.4... logprob:  0.597035, 0.273438 (0.650 sec)
278.5... logprob:  0.591167, 0.265625 (0.649 sec)
278.6... logprob:  0.611415, 0.296875 (0.650 sec)
278.7... logprob:  0.643875, 0.343750 (0.649 sec)
278.8... logprob:  0.604610, 0.289062 (0.649 sec)
278.9... logprob:  0.638660, 0.335938 (0.648 sec)
278.10... logprob:  0.597511, 0.281250 (0.650 sec)
278.11... logprob:  0.639168, 0.335938 (0.649 sec)
278.12... logprob:  0.719719, 0.437500 (0.651 sec)
278.13... logprob:  0.657974, 0.359375 (0.649 sec)
278.14... logprob:  0.663579, 0.367188 (0.649 sec)
278.15... logprob:  0.686773, 0.398438 (0.648 sec)
278.16... logprob:  0.627059, 0.320312 (0.650 sec)
278.17... logprob:  0.638520, 0.335938 (0.651 sec)
278.18... logprob:  0.638227, 0.335938 (0.651 sec)
278.19... logprob:  0.632765, 0.328125 (0.649 sec)
278.20... logprob:  0.648778, 0.351562 (0.651 sec)
278.21... logprob:  0.643402, 0.343750 (0.650 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.628315, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.949873e-03 [6.836895e-09] 
Layer 'conv1' biases: 3.973609e-07 [1.511620e-10] 
Layer 'conv2' weights[0]: 7.937469e-03 [6.419781e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.242391e-10] 
Layer 'conv3' weights[0]: 7.935483e-03 [5.655674e-09] 
Layer 'conv3' biases: 3.376559e-06 [2.017342e-09] 
Layer 'conv4' weights[0]: 7.968073e-03 [5.606069e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.437342e-08] 
Layer 'conv5' weights[0]: 7.967409e-03 [8.548950e-08] 
Layer 'conv5' biases: 1.000003e+00 [9.123003e-08] 
Layer 'fc6' weights[0]: 7.563777e-03 [9.976262e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.126109e-09] 
Layer 'fc7' weights[0]: 7.564154e-03 [1.293811e-07] 
Layer 'fc7' biases: 9.998557e-01 [1.141679e-07] 
Layer 'fc8' weights[0]: 6.057476e-04 [6.326185e-06] 
Layer 'fc8' biases: 1.277900e-01 [1.086476e-04] 
Train error last 27 batches: 0.635997
-------------------------------------------------------
Not saving because 0.628315 > 0.627105 (256.15: -0.00%)
======================================================= (1.752 sec)
278.22... logprob:  0.628258, 0.320312 (0.649 sec)
278.23... logprob:  0.623551, 0.312500 (0.648 sec)
278.24... logprob:  0.579144, 0.242188 (0.650 sec)
278.25... logprob:  0.628464, 0.320312 (0.649 sec)
278.26... logprob:  0.673611, 0.390625 (0.650 sec)
278.27... logprob:  0.628249, 0.320312 (0.649 sec)
279.1... logprob:  0.679067, 0.398438 (0.650 sec)
279.2... logprob:  0.597611, 0.273438 (0.648 sec)
279.3... logprob:  0.653688, 0.359375 (0.650 sec)
279.4... logprob:  0.597029, 0.273438 (0.649 sec)
279.5... logprob:  0.591163, 0.265625 (0.649 sec)
279.6... logprob:  0.611414, 0.296875 (0.649 sec)
279.7... logprob:  0.643874, 0.343750 (0.650 sec)
279.8... logprob:  0.604613, 0.289062 (0.648 sec)
279.9... logprob:  0.638658, 0.335938 (0.649 sec)
279.10... logprob:  0.597516, 0.281250 (0.648 sec)
279.11... logprob:  0.639164, 0.335938 (0.650 sec)
279.12... logprob:  0.719696, 0.437500 (0.650 sec)
279.13... logprob:  0.657966, 0.359375 (0.650 sec)
279.14... logprob:  0.663572, 0.367188 (0.649 sec)
279.15... logprob:  0.686765, 0.398438 (0.650 sec)
279.16... logprob:  0.627059, 0.320312 (0.650 sec)
279.17... logprob:  0.638520, 0.335938 (0.652 sec)
279.18... logprob:  0.638228, 0.335938 (0.650 sec)
279.19... logprob:  0.632764, 0.328125 (0.651 sec)
279.20... logprob:  0.648780, 0.351562 (0.650 sec)
279.21... logprob:  0.643402, 0.343750 (0.651 sec)
279.22... logprob:  0.628253, 0.320312 (0.648 sec)
279.23... logprob:  0.623545, 0.312500 (0.649 sec)
279.24... logprob:  0.579123, 0.242188 (0.649 sec)
279.25... logprob:  0.628460, 0.320312 (0.650 sec)
279.26... logprob:  0.673619, 0.390625 (0.649 sec)
279.27... logprob:  0.628246, 0.320312 (0.650 sec)
280.1... logprob:  0.679073, 0.398438 (0.649 sec)
280.2... logprob:  0.597605, 0.273438 (0.650 sec)
280.3... logprob:  0.653688, 0.359375 (0.648 sec)
280.4... logprob:  0.597027, 0.273438 (0.650 sec)
280.5... logprob:  0.591163, 0.265625 (0.649 sec)
280.6... logprob:  0.611416, 0.296875 (0.650 sec)
280.7... logprob:  0.643873, 0.343750 (0.648 sec)
280.8... logprob:  0.604618, 0.289062 (0.649 sec)
280.9... logprob:  0.638656, 0.335938 (0.648 sec)
280.10... logprob:  0.597524, 0.281250 (0.649 sec)
280.11... logprob:  0.639159, 0.335938 (0.649 sec)
280.12... logprob:  0.719661, 0.437500 (0.651 sec)
280.13... logprob:  0.657954, 0.359375 (0.649 sec)
280.14... logprob:  0.663561, 0.367188 (0.649 sec)
280.15... logprob:  0.686752, 0.398438 (0.648 sec)
280.16... logprob:  0.627059, 0.320312 (0.650 sec)
280.17... logprob:  0.638520, 0.335938 (0.650 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.632791, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.949677e-03 [6.466700e-09] 
Layer 'conv1' biases: 4.004980e-07 [1.742309e-10] 
Layer 'conv2' weights[0]: 7.937274e-03 [6.989532e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.972180e-10] 
Layer 'conv3' weights[0]: 7.935277e-03 [6.184907e-09] 
Layer 'conv3' biases: 3.399763e-06 [2.494684e-09] 
Layer 'conv4' weights[0]: 7.967882e-03 [6.284154e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.947823e-08] 
Layer 'conv5' weights[0]: 7.967206e-03 [1.165578e-07] 
Layer 'conv5' biases: 1.000003e+00 [1.245966e-07] 
Layer 'fc6' weights[0]: 7.563570e-03 [1.278556e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.232979e-08] 
Layer 'fc7' weights[0]: 7.562264e-03 [1.649561e-07] 
Layer 'fc7' biases: 9.998561e-01 [1.520960e-07] 
Layer 'fc8' weights[0]: 6.295329e-04 [8.541452e-06] 
Layer 'fc8' biases: 1.290598e-01 [1.443173e-04] 
Train error last 27 batches: 0.635990
-------------------------------------------------------
Not saving because 0.632791 > 0.627105 (256.15: -0.00%)
======================================================= (1.742 sec)
280.18... logprob:  0.638228, 0.335938 (0.651 sec)
280.19... logprob:  0.632764, 0.328125 (0.649 sec)
280.20... logprob:  0.648781, 0.351562 (0.651 sec)
280.21... logprob:  0.643403, 0.343750 (0.650 sec)
280.22... logprob:  0.628249, 0.320312 (0.650 sec)
280.23... logprob:  0.623538, 0.312500 (0.648 sec)
280.24... logprob:  0.579099, 0.242188 (0.650 sec)
280.25... logprob:  0.628454, 0.320312 (0.649 sec)
280.26... logprob:  0.673627, 0.390625 (0.651 sec)
280.27... logprob:  0.628241, 0.320312 (0.649 sec)
281.1... logprob:  0.679081, 0.398438 (0.650 sec)
281.2... logprob:  0.597596, 0.273438 (0.648 sec)
281.3... logprob:  0.653691, 0.359375 (0.651 sec)
281.4... logprob:  0.597021, 0.273438 (0.649 sec)
281.5... logprob:  0.591159, 0.265625 (0.650 sec)
281.6... logprob:  0.611417, 0.296875 (0.649 sec)
281.7... logprob:  0.643872, 0.343750 (0.650 sec)
281.8... logprob:  0.604622, 0.289062 (0.648 sec)
281.9... logprob:  0.638654, 0.335938 (0.649 sec)
281.10... logprob:  0.597532, 0.281250 (0.648 sec)
281.11... logprob:  0.639154, 0.335938 (0.649 sec)
281.12... logprob:  0.719630, 0.437500 (0.650 sec)
281.13... logprob:  0.657943, 0.359375 (0.650 sec)
281.14... logprob:  0.663550, 0.367188 (0.648 sec)
281.15... logprob:  0.686739, 0.398438 (0.650 sec)
281.16... logprob:  0.627059, 0.320312 (0.649 sec)
281.17... logprob:  0.638520, 0.335938 (0.651 sec)
281.18... logprob:  0.638228, 0.335938 (0.650 sec)
281.19... logprob:  0.632763, 0.328125 (0.651 sec)
281.20... logprob:  0.648782, 0.351562 (0.649 sec)
281.21... logprob:  0.643403, 0.343750 (0.651 sec)
281.22... logprob:  0.628246, 0.320312 (0.649 sec)
281.23... logprob:  0.623533, 0.312500 (0.649 sec)
281.24... logprob:  0.579083, 0.242188 (0.648 sec)
281.25... logprob:  0.628450, 0.320312 (0.651 sec)
281.26... logprob:  0.673632, 0.390625 (0.649 sec)
281.27... logprob:  0.628239, 0.320312 (0.650 sec)
282.1... logprob:  0.679087, 0.398438 (0.649 sec)
282.2... logprob:  0.597588, 0.273438 (0.650 sec)
282.3... logprob:  0.653692, 0.359375 (0.649 sec)
282.4... logprob:  0.597016, 0.273438 (0.649 sec)
282.5... logprob:  0.591156, 0.265625 (0.648 sec)
282.6... logprob:  0.611416, 0.296875 (0.650 sec)
282.7... logprob:  0.643872, 0.343750 (0.649 sec)
282.8... logprob:  0.604624, 0.289062 (0.650 sec)
282.9... logprob:  0.638653, 0.335938 (0.649 sec)
282.10... logprob:  0.597536, 0.281250 (0.649 sec)
282.11... logprob:  0.639151, 0.335938 (0.649 sec)
282.12... logprob:  0.719609, 0.437500 (0.651 sec)
282.13... logprob:  0.657936, 0.359375 (0.649 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.693953, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.949485e-03 [6.531884e-09] 
Layer 'conv1' biases: 4.036018e-07 [1.021888e-10] 
Layer 'conv2' weights[0]: 7.937074e-03 [5.514851e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.932796e-10] 
Layer 'conv3' weights[0]: 7.935085e-03 [4.866471e-09] 
Layer 'conv3' biases: 3.422292e-06 [1.361947e-09] 
Layer 'conv4' weights[0]: 7.967692e-03 [4.800903e-09] 
Layer 'conv4' biases: 1.000001e+00 [8.321712e-09] 
Layer 'conv5' weights[0]: 7.967012e-03 [4.953320e-08] 
Layer 'conv5' biases: 1.000002e+00 [5.290138e-08] 
Layer 'fc6' weights[0]: 7.563368e-03 [6.526852e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.249111e-09] 
Layer 'fc7' weights[0]: 7.560330e-03 [8.431419e-08] 
Layer 'fc7' biases: 9.998565e-01 [6.553928e-08] 
Layer 'fc8' weights[0]: 6.587738e-04 [3.655476e-06] 
Layer 'fc8' biases: 1.304110e-01 [5.065276e-05] 
Train error last 27 batches: 0.635984
-------------------------------------------------------
Not saving because 0.693953 > 0.627105 (256.15: -0.00%)
======================================================= (1.784 sec)
282.14... logprob:  0.663543, 0.367188 (0.649 sec)
282.15... logprob:  0.686732, 0.398438 (0.649 sec)
282.16... logprob:  0.627059, 0.320312 (0.650 sec)
282.17... logprob:  0.638520, 0.335938 (0.650 sec)
282.18... logprob:  0.638228, 0.335938 (0.650 sec)
282.19... logprob:  0.632762, 0.328125 (0.650 sec)
282.20... logprob:  0.648784, 0.351562 (0.651 sec)
282.21... logprob:  0.643403, 0.343750 (0.650 sec)
282.22... logprob:  0.628242, 0.320312 (0.650 sec)
282.23... logprob:  0.623527, 0.312500 (0.649 sec)
282.24... logprob:  0.579065, 0.242188 (0.649 sec)
282.25... logprob:  0.628446, 0.320312 (0.650 sec)
282.26... logprob:  0.673638, 0.390625 (0.651 sec)
282.27... logprob:  0.628236, 0.320312 (0.649 sec)
283.1... logprob:  0.679092, 0.398438 (0.650 sec)
283.2... logprob:  0.597582, 0.273438 (0.649 sec)
283.3... logprob:  0.653692, 0.359375 (0.650 sec)
283.4... logprob:  0.597013, 0.273438 (0.649 sec)
283.5... logprob:  0.591156, 0.265625 (0.650 sec)
283.6... logprob:  0.611417, 0.296875 (0.648 sec)
283.7... logprob:  0.643871, 0.343750 (0.650 sec)
283.8... logprob:  0.604628, 0.289062 (0.648 sec)
283.9... logprob:  0.638651, 0.335938 (0.650 sec)
283.10... logprob:  0.597543, 0.281250 (0.648 sec)
283.11... logprob:  0.639145, 0.335938 (0.650 sec)
283.12... logprob:  0.719580, 0.437500 (0.649 sec)
283.13... logprob:  0.657926, 0.359375 (0.651 sec)
283.14... logprob:  0.663533, 0.367188 (0.648 sec)
283.15... logprob:  0.686721, 0.398438 (0.650 sec)
283.16... logprob:  0.627060, 0.320312 (0.649 sec)
283.17... logprob:  0.638520, 0.335938 (0.651 sec)
283.18... logprob:  0.638227, 0.335938 (0.649 sec)
283.19... logprob:  0.632761, 0.328125 (0.651 sec)
283.20... logprob:  0.648785, 0.351562 (0.649 sec)
283.21... logprob:  0.643403, 0.343750 (0.651 sec)
283.22... logprob:  0.628238, 0.320312 (0.648 sec)
283.23... logprob:  0.623521, 0.312500 (0.649 sec)
283.24... logprob:  0.579045, 0.242188 (0.649 sec)
283.25... logprob:  0.628442, 0.320312 (0.651 sec)
283.26... logprob:  0.673645, 0.390625 (0.650 sec)
283.27... logprob:  0.628232, 0.320312 (0.650 sec)
284.1... logprob:  0.679098, 0.398438 (0.649 sec)
284.2... logprob:  0.597574, 0.273438 (0.650 sec)
284.3... logprob:  0.653694, 0.359375 (0.649 sec)
284.4... logprob:  0.597008, 0.273438 (0.650 sec)
284.5... logprob:  0.591153, 0.265625 (0.648 sec)
284.6... logprob:  0.611416, 0.296875 (0.650 sec)
284.7... logprob:  0.643870, 0.343750 (0.648 sec)
284.8... logprob:  0.604631, 0.289062 (0.649 sec)
284.9... logprob:  0.638649, 0.335938 (0.649 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.632990, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.949280e-03 [6.643924e-09] 
Layer 'conv1' biases: 4.070496e-07 [1.171517e-10] 
Layer 'conv2' weights[0]: 7.936899e-03 [5.745524e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.925130e-10] 
Layer 'conv3' weights[0]: 7.934885e-03 [5.654972e-09] 
Layer 'conv3' biases: 3.449557e-06 [1.862104e-09] 
Layer 'conv4' weights[0]: 7.967502e-03 [5.827637e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.662498e-08] 
Layer 'conv5' weights[0]: 7.966827e-03 [9.894389e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.059065e-07] 
Layer 'fc6' weights[0]: 7.563194e-03 [1.105693e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.037758e-08] 
Layer 'fc7' weights[0]: 7.558433e-03 [1.415982e-07] 
Layer 'fc7' biases: 9.998564e-01 [1.267085e-07] 
Layer 'fc8' weights[0]: 6.485722e-04 [7.106958e-06] 
Layer 'fc8' biases: 1.309465e-01 [1.476243e-04] 
Train error last 27 batches: 0.635978
-------------------------------------------------------
Not saving because 0.632990 > 0.627105 (256.15: -0.00%)
======================================================= (1.756 sec)
284.10... logprob:  0.597548, 0.281250 (0.649 sec)
284.11... logprob:  0.639141, 0.335938 (0.649 sec)
284.12... logprob:  0.719553, 0.437500 (0.651 sec)
284.13... logprob:  0.657917, 0.359375 (0.649 sec)
284.14... logprob:  0.663524, 0.367188 (0.649 sec)
284.15... logprob:  0.686711, 0.398438 (0.648 sec)
284.16... logprob:  0.627059, 0.320312 (0.650 sec)
284.17... logprob:  0.638519, 0.335938 (0.650 sec)
284.18... logprob:  0.638227, 0.335938 (0.654 sec)
284.19... logprob:  0.632760, 0.328125 (0.649 sec)
284.20... logprob:  0.648786, 0.351562 (0.651 sec)
284.21... logprob:  0.643403, 0.343750 (0.650 sec)
284.22... logprob:  0.628234, 0.320312 (0.650 sec)
284.23... logprob:  0.623515, 0.312500 (0.648 sec)
284.24... logprob:  0.579026, 0.242188 (0.650 sec)
284.25... logprob:  0.628437, 0.320312 (0.649 sec)
284.26... logprob:  0.673651, 0.390625 (0.651 sec)
284.27... logprob:  0.628229, 0.320312 (0.649 sec)
285.1... logprob:  0.679104, 0.398438 (0.650 sec)
285.2... logprob:  0.597566, 0.273438 (0.649 sec)
285.3... logprob:  0.653695, 0.359375 (0.650 sec)
285.4... logprob:  0.597004, 0.273438 (0.648 sec)
285.5... logprob:  0.591150, 0.265625 (0.650 sec)
285.6... logprob:  0.611417, 0.296875 (0.648 sec)
285.7... logprob:  0.643869, 0.343750 (0.650 sec)
285.8... logprob:  0.604635, 0.289062 (0.648 sec)
285.9... logprob:  0.638647, 0.335938 (0.649 sec)
285.10... logprob:  0.597555, 0.281250 (0.648 sec)
285.11... logprob:  0.639137, 0.335938 (0.650 sec)
285.12... logprob:  0.719524, 0.437500 (0.650 sec)
285.13... logprob:  0.657907, 0.359375 (0.650 sec)
285.14... logprob:  0.663515, 0.367188 (0.648 sec)
285.15... logprob:  0.686700, 0.398438 (0.650 sec)
285.16... logprob:  0.627059, 0.320312 (0.649 sec)
285.17... logprob:  0.638520, 0.335938 (0.651 sec)
285.18... logprob:  0.638227, 0.335938 (0.650 sec)
285.19... logprob:  0.632759, 0.328125 (0.651 sec)
285.20... logprob:  0.648788, 0.351562 (0.650 sec)
285.21... logprob:  0.643404, 0.343750 (0.651 sec)
285.22... logprob:  0.628230, 0.320312 (0.648 sec)
285.23... logprob:  0.623509, 0.312500 (0.650 sec)
285.24... logprob:  0.579006, 0.242188 (0.648 sec)
285.25... logprob:  0.628432, 0.320312 (0.650 sec)
285.26... logprob:  0.673658, 0.390625 (0.650 sec)
285.27... logprob:  0.628225, 0.320312 (0.650 sec)
286.1... logprob:  0.679110, 0.398438 (0.649 sec)
286.2... logprob:  0.597560, 0.273438 (0.650 sec)
286.3... logprob:  0.653696, 0.359375 (0.648 sec)
286.4... logprob:  0.597000, 0.273438 (0.650 sec)
286.5... logprob:  0.591149, 0.265625 (0.649 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627623, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.949090e-03 [7.414938e-09] 
Layer 'conv1' biases: 4.106816e-07 [1.435474e-10] 
Layer 'conv2' weights[0]: 7.936699e-03 [6.004292e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.734743e-10] 
Layer 'conv3' weights[0]: 7.934692e-03 [5.866130e-09] 
Layer 'conv3' biases: 3.479179e-06 [2.031906e-09] 
Layer 'conv4' weights[0]: 7.967302e-03 [5.979147e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.800948e-08] 
Layer 'conv5' weights[0]: 7.966662e-03 [1.073775e-07] 
Layer 'conv5' biases: 1.000003e+00 [1.147225e-07] 
Layer 'fc6' weights[0]: 7.563006e-03 [1.193709e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.134306e-08] 
Layer 'fc7' weights[0]: 7.556512e-03 [1.533650e-07] 
Layer 'fc7' biases: 9.998558e-01 [1.394547e-07] 
Layer 'fc8' weights[0]: 6.192490e-04 [7.747023e-06] 
Layer 'fc8' biases: 1.310619e-01 [1.648802e-04] 
Train error last 27 batches: 0.635972
-------------------------------------------------------
Not saving because 0.627623 > 0.627105 (256.15: -0.00%)
======================================================= (1.748 sec)
286.6... logprob:  0.611417, 0.296875 (0.650 sec)
286.7... logprob:  0.643868, 0.343750 (0.649 sec)
286.8... logprob:  0.604638, 0.289062 (0.649 sec)
286.9... logprob:  0.638645, 0.335938 (0.649 sec)
286.10... logprob:  0.597561, 0.281250 (0.649 sec)
286.11... logprob:  0.639133, 0.335938 (0.648 sec)
286.12... logprob:  0.719498, 0.437500 (0.651 sec)
286.13... logprob:  0.657899, 0.359375 (0.649 sec)
286.14... logprob:  0.663506, 0.367188 (0.649 sec)
286.15... logprob:  0.686691, 0.398438 (0.649 sec)
286.16... logprob:  0.627060, 0.320312 (0.651 sec)
286.17... logprob:  0.638519, 0.335938 (0.650 sec)
286.18... logprob:  0.638227, 0.335938 (0.651 sec)
286.19... logprob:  0.632759, 0.328125 (0.649 sec)
286.20... logprob:  0.648789, 0.351562 (0.650 sec)
286.21... logprob:  0.643403, 0.343750 (0.650 sec)
286.22... logprob:  0.628226, 0.320312 (0.649 sec)
286.23... logprob:  0.623503, 0.312500 (0.648 sec)
286.24... logprob:  0.578987, 0.242188 (0.650 sec)
286.25... logprob:  0.628428, 0.320312 (0.649 sec)
286.26... logprob:  0.673665, 0.390625 (0.650 sec)
286.27... logprob:  0.628222, 0.320312 (0.649 sec)
287.1... logprob:  0.679116, 0.398438 (0.650 sec)
287.2... logprob:  0.597552, 0.273438 (0.649 sec)
287.3... logprob:  0.653698, 0.359375 (0.650 sec)
287.4... logprob:  0.596996, 0.273438 (0.648 sec)
287.5... logprob:  0.591146, 0.265625 (0.650 sec)
287.6... logprob:  0.611418, 0.296875 (0.648 sec)
287.7... logprob:  0.643867, 0.343750 (0.650 sec)
287.8... logprob:  0.604642, 0.289062 (0.648 sec)
287.9... logprob:  0.638644, 0.335938 (0.650 sec)
287.10... logprob:  0.597568, 0.281250 (0.648 sec)
287.11... logprob:  0.639129, 0.335938 (0.650 sec)
287.12... logprob:  0.719469, 0.437500 (0.650 sec)
287.13... logprob:  0.657888, 0.359375 (0.650 sec)
287.14... logprob:  0.663496, 0.367188 (0.648 sec)
287.15... logprob:  0.686679, 0.398438 (0.650 sec)
287.16... logprob:  0.627060, 0.320312 (0.649 sec)
287.17... logprob:  0.638519, 0.335938 (0.653 sec)
287.18... logprob:  0.638226, 0.335938 (0.650 sec)
287.19... logprob:  0.632758, 0.328125 (0.650 sec)
287.20... logprob:  0.648790, 0.351562 (0.649 sec)
287.21... logprob:  0.643404, 0.343750 (0.651 sec)
287.22... logprob:  0.628223, 0.320312 (0.648 sec)
287.23... logprob:  0.623497, 0.312500 (0.650 sec)
287.24... logprob:  0.578969, 0.242188 (0.648 sec)
287.25... logprob:  0.628424, 0.320312 (0.650 sec)
287.26... logprob:  0.673670, 0.390625 (0.649 sec)
287.27... logprob:  0.628219, 0.320312 (0.650 sec)
288.1... logprob:  0.679123, 0.398438 (0.649 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.653610, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.948903e-03 [6.590526e-09] 
Layer 'conv1' biases: 4.142112e-07 [7.355654e-11] 
Layer 'conv2' weights[0]: 7.936508e-03 [5.003726e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.882777e-10] 
Layer 'conv3' weights[0]: 7.934488e-03 [4.419188e-09] 
Layer 'conv3' biases: 3.507200e-06 [7.097947e-10] 
Layer 'conv4' weights[0]: 7.967100e-03 [4.322078e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.084613e-09] 
Layer 'conv5' weights[0]: 7.966467e-03 [1.237208e-08] 
Layer 'conv5' biases: 1.000003e+00 [1.236822e-08] 
Layer 'fc6' weights[0]: 7.562801e-03 [4.052705e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.337880e-09] 
Layer 'fc7' weights[0]: 7.554593e-03 [4.425601e-08] 
Layer 'fc7' biases: 9.998556e-01 [1.776895e-08] 
Layer 'fc8' weights[0]: 6.042229e-04 [9.299036e-07] 
Layer 'fc8' biases: 1.314757e-01 [7.476357e-06] 
Train error last 27 batches: 0.635966
-------------------------------------------------------
Not saving because 0.653610 > 0.627105 (256.15: -0.00%)
======================================================= (1.861 sec)
288.2... logprob:  0.597544, 0.273438 (0.650 sec)
288.3... logprob:  0.653699, 0.359375 (0.648 sec)
288.4... logprob:  0.596991, 0.273438 (0.650 sec)
288.5... logprob:  0.591144, 0.265625 (0.649 sec)
288.6... logprob:  0.611418, 0.296875 (0.650 sec)
288.7... logprob:  0.643867, 0.343750 (0.649 sec)
288.8... logprob:  0.604644, 0.289062 (0.649 sec)
288.9... logprob:  0.638642, 0.335938 (0.648 sec)
288.10... logprob:  0.597574, 0.281250 (0.650 sec)
288.11... logprob:  0.639125, 0.335938 (0.649 sec)
288.12... logprob:  0.719444, 0.437500 (0.650 sec)
288.13... logprob:  0.657880, 0.359375 (0.649 sec)
288.14... logprob:  0.663488, 0.367188 (0.650 sec)
288.15... logprob:  0.686670, 0.398438 (0.648 sec)
288.16... logprob:  0.627060, 0.320312 (0.650 sec)
288.17... logprob:  0.638520, 0.335938 (0.650 sec)
288.18... logprob:  0.638227, 0.335938 (0.651 sec)
288.19... logprob:  0.632757, 0.328125 (0.650 sec)
288.20... logprob:  0.648792, 0.351562 (0.651 sec)
288.21... logprob:  0.643404, 0.343750 (0.650 sec)
288.22... logprob:  0.628218, 0.320312 (0.650 sec)
288.23... logprob:  0.623491, 0.312500 (0.648 sec)
288.24... logprob:  0.578947, 0.242188 (0.650 sec)
288.25... logprob:  0.628419, 0.320312 (0.649 sec)
288.26... logprob:  0.673678, 0.390625 (0.651 sec)
288.27... logprob:  0.628216, 0.320312 (0.649 sec)
289.1... logprob:  0.679129, 0.398438 (0.650 sec)
289.2... logprob:  0.597537, 0.273438 (0.648 sec)
289.3... logprob:  0.653700, 0.359375 (0.650 sec)
289.4... logprob:  0.596988, 0.273438 (0.649 sec)
289.5... logprob:  0.591143, 0.265625 (0.650 sec)
289.6... logprob:  0.611419, 0.296875 (0.648 sec)
289.7... logprob:  0.643866, 0.343750 (0.650 sec)
289.8... logprob:  0.604650, 0.289062 (0.648 sec)
289.9... logprob:  0.638640, 0.335938 (0.650 sec)
289.10... logprob:  0.597582, 0.281250 (0.648 sec)
289.11... logprob:  0.639120, 0.335938 (0.650 sec)
289.12... logprob:  0.719410, 0.437500 (0.650 sec)
289.13... logprob:  0.657868, 0.359375 (0.651 sec)
289.14... logprob:  0.663478, 0.367188 (0.648 sec)
289.15... logprob:  0.686658, 0.398438 (0.650 sec)
289.16... logprob:  0.627060, 0.320312 (0.649 sec)
289.17... logprob:  0.638519, 0.335938 (0.652 sec)
289.18... logprob:  0.638227, 0.335938 (0.649 sec)
289.19... logprob:  0.632756, 0.328125 (0.651 sec)
289.20... logprob:  0.648793, 0.351562 (0.649 sec)
289.21... logprob:  0.643404, 0.343750 (0.651 sec)
289.22... logprob:  0.628214, 0.320312 (0.649 sec)
289.23... logprob:  0.623484, 0.312500 (0.649 sec)
289.24... logprob:  0.578927, 0.242188 (0.649 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.628465, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.948686e-03 [6.468904e-09] 
Layer 'conv1' biases: 4.176537e-07 [5.929571e-11] 
Layer 'conv2' weights[0]: 7.936331e-03 [4.825013e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.046165e-10] 
Layer 'conv3' weights[0]: 7.934291e-03 [4.539163e-09] 
Layer 'conv3' biases: 3.534332e-06 [8.799446e-10] 
Layer 'conv4' weights[0]: 7.966915e-03 [4.500179e-09] 
Layer 'conv4' biases: 1.000001e+00 [6.571315e-09] 
Layer 'conv5' weights[0]: 7.966272e-03 [3.875229e-08] 
Layer 'conv5' biases: 1.000003e+00 [4.123434e-08] 
Layer 'fc6' weights[0]: 7.562592e-03 [5.640282e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.057810e-09] 
Layer 'fc7' weights[0]: 7.552622e-03 [7.045789e-08] 
Layer 'fc7' biases: 9.998554e-01 [4.996989e-08] 
Layer 'fc8' weights[0]: 5.985437e-04 [2.721795e-06] 
Layer 'fc8' biases: 1.320832e-01 [7.326664e-05] 
Train error last 27 batches: 0.635959
-------------------------------------------------------
Not saving because 0.628465 > 0.627105 (256.15: -0.00%)
======================================================= (1.801 sec)
289.25... logprob:  0.628415, 0.320312 (0.650 sec)
289.26... logprob:  0.673685, 0.390625 (0.649 sec)
289.27... logprob:  0.628212, 0.320312 (0.650 sec)
290.1... logprob:  0.679136, 0.398438 (0.648 sec)
290.2... logprob:  0.597529, 0.273438 (0.650 sec)
290.3... logprob:  0.653702, 0.359375 (0.649 sec)
290.4... logprob:  0.596981, 0.273438 (0.650 sec)
290.5... logprob:  0.591138, 0.265625 (0.649 sec)
290.6... logprob:  0.611418, 0.296875 (0.650 sec)
290.7... logprob:  0.643865, 0.343750 (0.649 sec)
290.8... logprob:  0.604652, 0.289062 (0.650 sec)
290.9... logprob:  0.638638, 0.335938 (0.648 sec)
290.10... logprob:  0.597587, 0.281250 (0.649 sec)
290.11... logprob:  0.639116, 0.335938 (0.649 sec)
290.12... logprob:  0.719384, 0.437500 (0.651 sec)
290.13... logprob:  0.657860, 0.359375 (0.648 sec)
290.14... logprob:  0.663469, 0.367188 (0.650 sec)
290.15... logprob:  0.686648, 0.398438 (0.648 sec)
290.16... logprob:  0.627060, 0.320312 (0.650 sec)
290.17... logprob:  0.638519, 0.335938 (0.651 sec)
290.18... logprob:  0.638227, 0.335938 (0.651 sec)
290.19... logprob:  0.632756, 0.328125 (0.649 sec)
290.20... logprob:  0.648795, 0.351562 (0.651 sec)
290.21... logprob:  0.643406, 0.343750 (0.650 sec)
290.22... logprob:  0.628210, 0.320312 (0.650 sec)
290.23... logprob:  0.623479, 0.312500 (0.649 sec)
290.24... logprob:  0.578907, 0.242188 (0.650 sec)
290.25... logprob:  0.628410, 0.320312 (0.649 sec)
290.26... logprob:  0.673692, 0.390625 (0.651 sec)
290.27... logprob:  0.628209, 0.320312 (0.649 sec)
291.1... logprob:  0.679143, 0.398438 (0.650 sec)
291.2... logprob:  0.597522, 0.273438 (0.649 sec)
291.3... logprob:  0.653702, 0.359375 (0.650 sec)
291.4... logprob:  0.596979, 0.273438 (0.649 sec)
291.5... logprob:  0.591138, 0.265625 (0.650 sec)
291.6... logprob:  0.611420, 0.296875 (0.649 sec)
291.7... logprob:  0.643864, 0.343750 (0.650 sec)
291.8... logprob:  0.604657, 0.289062 (0.648 sec)
291.9... logprob:  0.638636, 0.335938 (0.650 sec)
291.10... logprob:  0.597594, 0.281250 (0.648 sec)
291.11... logprob:  0.639111, 0.335938 (0.650 sec)
291.12... logprob:  0.719354, 0.437500 (0.650 sec)
291.13... logprob:  0.657849, 0.359375 (0.650 sec)
291.14... logprob:  0.663459, 0.367188 (0.649 sec)
291.15... logprob:  0.686636, 0.398438 (0.650 sec)
291.16... logprob:  0.627060, 0.320312 (0.649 sec)
291.17... logprob:  0.638519, 0.335938 (0.651 sec)
291.18... logprob:  0.638226, 0.335938 (0.650 sec)
291.19... logprob:  0.632755, 0.328125 (0.651 sec)
291.20... logprob:  0.648796, 0.351562 (0.649 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633116, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.948506e-03 [6.820449e-09] 
Layer 'conv1' biases: 4.209674e-07 [1.612855e-10] 
Layer 'conv2' weights[0]: 7.936145e-03 [6.530805e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.756022e-10] 
Layer 'conv3' weights[0]: 7.934096e-03 [5.755403e-09] 
Layer 'conv3' biases: 3.559724e-06 [2.136779e-09] 
Layer 'conv4' weights[0]: 7.966713e-03 [5.708102e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.544483e-08] 
Layer 'conv5' weights[0]: 7.966072e-03 [9.151288e-08] 
Layer 'conv5' biases: 1.000003e+00 [9.760589e-08] 
Layer 'fc6' weights[0]: 7.562391e-03 [1.048987e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.768208e-09] 
Layer 'fc7' weights[0]: 7.550723e-03 [1.354333e-07] 
Layer 'fc7' biases: 9.998556e-01 [1.210084e-07] 
Layer 'fc8' weights[0]: 6.068583e-04 [6.671654e-06] 
Layer 'fc8' biases: 1.330048e-01 [1.167755e-04] 
Train error last 27 batches: 0.635953
-------------------------------------------------------
Not saving because 0.633116 > 0.627105 (256.15: -0.00%)
======================================================= (1.750 sec)
291.21... logprob:  0.643405, 0.343750 (0.651 sec)
291.22... logprob:  0.628207, 0.320312 (0.648 sec)
291.23... logprob:  0.623473, 0.312500 (0.649 sec)
291.24... logprob:  0.578890, 0.242188 (0.649 sec)
291.25... logprob:  0.628406, 0.320312 (0.651 sec)
291.26... logprob:  0.673698, 0.390625 (0.649 sec)
291.27... logprob:  0.628205, 0.320312 (0.650 sec)
292.1... logprob:  0.679149, 0.398438 (0.648 sec)
292.2... logprob:  0.597514, 0.273438 (0.650 sec)
292.3... logprob:  0.653704, 0.359375 (0.648 sec)
292.4... logprob:  0.596973, 0.273438 (0.650 sec)
292.5... logprob:  0.591134, 0.265625 (0.648 sec)
292.6... logprob:  0.611419, 0.296875 (0.650 sec)
292.7... logprob:  0.643863, 0.343750 (0.649 sec)
292.8... logprob:  0.604659, 0.289062 (0.649 sec)
292.9... logprob:  0.638635, 0.335938 (0.648 sec)
292.10... logprob:  0.597599, 0.281250 (0.649 sec)
292.11... logprob:  0.639107, 0.335938 (0.649 sec)
292.12... logprob:  0.719330, 0.437500 (0.651 sec)
292.13... logprob:  0.657842, 0.359375 (0.648 sec)
292.14... logprob:  0.663451, 0.367188 (0.650 sec)
292.15... logprob:  0.686628, 0.398438 (0.649 sec)
292.16... logprob:  0.627060, 0.320312 (0.649 sec)
292.17... logprob:  0.638519, 0.335938 (0.650 sec)
292.18... logprob:  0.638227, 0.335938 (0.651 sec)
292.19... logprob:  0.632754, 0.328125 (0.649 sec)
292.20... logprob:  0.648797, 0.351562 (0.650 sec)
292.21... logprob:  0.643405, 0.343750 (0.650 sec)
292.22... logprob:  0.628203, 0.320312 (0.649 sec)
292.23... logprob:  0.623467, 0.312500 (0.648 sec)
292.24... logprob:  0.578871, 0.242188 (0.650 sec)
292.25... logprob:  0.628401, 0.320312 (0.649 sec)
292.26... logprob:  0.673704, 0.390625 (0.651 sec)
292.27... logprob:  0.628202, 0.320312 (0.649 sec)
293.1... logprob:  0.679154, 0.398438 (0.649 sec)
293.2... logprob:  0.597507, 0.273438 (0.649 sec)
293.3... logprob:  0.653705, 0.359375 (0.650 sec)
293.4... logprob:  0.596970, 0.273438 (0.649 sec)
293.5... logprob:  0.591132, 0.265625 (0.650 sec)
293.6... logprob:  0.611419, 0.296875 (0.649 sec)
293.7... logprob:  0.643863, 0.343750 (0.649 sec)
293.8... logprob:  0.604662, 0.289062 (0.648 sec)
293.9... logprob:  0.638633, 0.335938 (0.650 sec)
293.10... logprob:  0.597606, 0.281250 (0.648 sec)
293.11... logprob:  0.639103, 0.335938 (0.650 sec)
293.12... logprob:  0.719303, 0.437500 (0.649 sec)
293.13... logprob:  0.657832, 0.359375 (0.650 sec)
293.14... logprob:  0.663442, 0.367188 (0.648 sec)
293.15... logprob:  0.686617, 0.398438 (0.650 sec)
293.16... logprob:  0.627060, 0.320312 (0.649 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.689172, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.948296e-03 [6.972056e-09] 
Layer 'conv1' biases: 4.241430e-07 [1.867680e-10] 
Layer 'conv2' weights[0]: 7.935955e-03 [7.317761e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.570414e-10] 
Layer 'conv3' weights[0]: 7.933897e-03 [6.394301e-09] 
Layer 'conv3' biases: 3.583147e-06 [2.662666e-09] 
Layer 'conv4' weights[0]: 7.966515e-03 [6.446332e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.008785e-08] 
Layer 'conv5' weights[0]: 7.965874e-03 [1.190374e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.270592e-07] 
Layer 'fc6' weights[0]: 7.562177e-03 [1.309466e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.265104e-08] 
Layer 'fc7' weights[0]: 7.548759e-03 [1.678474e-07] 
Layer 'fc7' biases: 9.998559e-01 [1.551066e-07] 
Layer 'fc8' weights[0]: 6.317753e-04 [8.632804e-06] 
Layer 'fc8' biases: 1.342858e-01 [1.482435e-04] 
Train error last 27 batches: 0.635947
-------------------------------------------------------
Not saving because 0.689172 > 0.627105 (256.15: -0.00%)
======================================================= (1.740 sec)
293.17... logprob:  0.638519, 0.335938 (0.651 sec)
293.18... logprob:  0.638226, 0.335938 (0.650 sec)
293.19... logprob:  0.632754, 0.328125 (0.651 sec)
293.20... logprob:  0.648798, 0.351562 (0.649 sec)
293.21... logprob:  0.643405, 0.343750 (0.651 sec)
293.22... logprob:  0.628199, 0.320312 (0.649 sec)
293.23... logprob:  0.623461, 0.312500 (0.649 sec)
293.24... logprob:  0.578851, 0.242188 (0.649 sec)
293.25... logprob:  0.628398, 0.320312 (0.651 sec)
293.26... logprob:  0.673711, 0.390625 (0.650 sec)
293.27... logprob:  0.628199, 0.320312 (0.650 sec)
294.1... logprob:  0.679161, 0.398438 (0.649 sec)
294.2... logprob:  0.597500, 0.273438 (0.650 sec)
294.3... logprob:  0.653706, 0.359375 (0.649 sec)
294.4... logprob:  0.596966, 0.273438 (0.650 sec)
294.5... logprob:  0.591131, 0.265625 (0.648 sec)
294.6... logprob:  0.611420, 0.296875 (0.650 sec)
294.7... logprob:  0.643862, 0.343750 (0.649 sec)
294.8... logprob:  0.604666, 0.289062 (0.649 sec)
294.9... logprob:  0.638631, 0.335938 (0.648 sec)
294.10... logprob:  0.597613, 0.281250 (0.650 sec)
294.11... logprob:  0.639099, 0.335938 (0.649 sec)
294.12... logprob:  0.719274, 0.437500 (0.651 sec)
294.13... logprob:  0.657822, 0.359375 (0.649 sec)
294.14... logprob:  0.663433, 0.367188 (0.651 sec)
294.15... logprob:  0.686607, 0.398438 (0.649 sec)
294.16... logprob:  0.627060, 0.320312 (0.651 sec)
294.17... logprob:  0.638519, 0.335938 (0.650 sec)
294.18... logprob:  0.638227, 0.335938 (0.651 sec)
294.19... logprob:  0.632753, 0.328125 (0.650 sec)
294.20... logprob:  0.648801, 0.351562 (0.651 sec)
294.21... logprob:  0.643406, 0.343750 (0.650 sec)
294.22... logprob:  0.628194, 0.320312 (0.650 sec)
294.23... logprob:  0.623454, 0.312500 (0.648 sec)
294.24... logprob:  0.578830, 0.242188 (0.650 sec)
294.25... logprob:  0.628392, 0.320312 (0.650 sec)
294.26... logprob:  0.673719, 0.390625 (0.651 sec)
294.27... logprob:  0.628196, 0.320312 (0.649 sec)
295.1... logprob:  0.679168, 0.398438 (0.650 sec)
295.2... logprob:  0.597492, 0.273438 (0.648 sec)
295.3... logprob:  0.653708, 0.359375 (0.650 sec)
295.4... logprob:  0.596961, 0.273438 (0.649 sec)
295.5... logprob:  0.591128, 0.265625 (0.650 sec)
295.6... logprob:  0.611420, 0.296875 (0.649 sec)
295.7... logprob:  0.643861, 0.343750 (0.650 sec)
295.8... logprob:  0.604670, 0.289062 (0.648 sec)
295.9... logprob:  0.638629, 0.335938 (0.649 sec)
295.10... logprob:  0.597620, 0.281250 (0.648 sec)
295.11... logprob:  0.639094, 0.335938 (0.650 sec)
295.12... logprob:  0.719243, 0.437500 (0.649 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633326, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.948106e-03 [6.867593e-09] 
Layer 'conv1' biases: 4.273130e-07 [8.211677e-11] 
Layer 'conv2' weights[0]: 7.935773e-03 [5.206932e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.278034e-10] 
Layer 'conv3' weights[0]: 7.933708e-03 [4.543250e-09] 
Layer 'conv3' biases: 3.607002e-06 [8.400151e-10] 
Layer 'conv4' weights[0]: 7.966321e-03 [4.416716e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.352990e-09] 
Layer 'conv5' weights[0]: 7.965668e-03 [1.445825e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.467381e-08] 
Layer 'fc6' weights[0]: 7.561990e-03 [4.143741e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.558864e-09] 
Layer 'fc7' weights[0]: 7.546844e-03 [4.631954e-08] 
Layer 'fc7' biases: 9.998563e-01 [2.095808e-08] 
Layer 'fc8' weights[0]: 6.556735e-04 [1.070443e-06] 
Layer 'fc8' biases: 1.355167e-01 [3.557086e-06] 
Train error last 27 batches: 0.635941
-------------------------------------------------------
Not saving because 0.633326 > 0.627105 (256.15: -0.00%)
======================================================= (1.857 sec)
295.13... logprob:  0.657813, 0.359375 (0.649 sec)
295.14... logprob:  0.663423, 0.367188 (0.648 sec)
295.15... logprob:  0.686595, 0.398438 (0.650 sec)
295.16... logprob:  0.627061, 0.320312 (0.649 sec)
295.17... logprob:  0.638519, 0.335938 (0.651 sec)
295.18... logprob:  0.638226, 0.335938 (0.650 sec)
295.19... logprob:  0.632752, 0.328125 (0.651 sec)
295.20... logprob:  0.648801, 0.351562 (0.650 sec)
295.21... logprob:  0.643407, 0.343750 (0.651 sec)
295.22... logprob:  0.628191, 0.320312 (0.648 sec)
295.23... logprob:  0.623449, 0.312500 (0.650 sec)
295.24... logprob:  0.578812, 0.242188 (0.649 sec)
295.25... logprob:  0.628388, 0.320312 (0.650 sec)
295.26... logprob:  0.673725, 0.390625 (0.650 sec)
295.27... logprob:  0.628193, 0.320312 (0.650 sec)
296.1... logprob:  0.679174, 0.398438 (0.648 sec)
296.2... logprob:  0.597484, 0.273438 (0.650 sec)
296.3... logprob:  0.653709, 0.359375 (0.649 sec)
296.4... logprob:  0.596956, 0.273438 (0.650 sec)
296.5... logprob:  0.591125, 0.265625 (0.649 sec)
296.6... logprob:  0.611421, 0.296875 (0.650 sec)
296.7... logprob:  0.643860, 0.343750 (0.649 sec)
296.8... logprob:  0.604673, 0.289062 (0.649 sec)
296.9... logprob:  0.638627, 0.335938 (0.648 sec)
296.10... logprob:  0.597625, 0.281250 (0.649 sec)
296.11... logprob:  0.639090, 0.335938 (0.649 sec)
296.12... logprob:  0.719219, 0.437500 (0.651 sec)
296.13... logprob:  0.657804, 0.359375 (0.649 sec)
296.14... logprob:  0.663415, 0.367188 (0.649 sec)
296.15... logprob:  0.686586, 0.398438 (0.648 sec)
296.16... logprob:  0.627061, 0.320312 (0.650 sec)
296.17... logprob:  0.638518, 0.335938 (0.650 sec)
296.18... logprob:  0.638226, 0.335938 (0.651 sec)
296.19... logprob:  0.632751, 0.328125 (0.649 sec)
296.20... logprob:  0.648803, 0.351562 (0.650 sec)
296.21... logprob:  0.643407, 0.343750 (0.649 sec)
296.22... logprob:  0.628188, 0.320312 (0.649 sec)
296.23... logprob:  0.623444, 0.312500 (0.648 sec)
296.24... logprob:  0.578793, 0.242188 (0.651 sec)
296.25... logprob:  0.628385, 0.320312 (0.653 sec)
296.26... logprob:  0.673732, 0.390625 (0.651 sec)
296.27... logprob:  0.628189, 0.320312 (0.649 sec)
297.1... logprob:  0.679180, 0.398438 (0.650 sec)
297.2... logprob:  0.597478, 0.273438 (0.648 sec)
297.3... logprob:  0.653710, 0.359375 (0.650 sec)
297.4... logprob:  0.596953, 0.273438 (0.648 sec)
297.5... logprob:  0.591124, 0.265625 (0.650 sec)
297.6... logprob:  0.611421, 0.296875 (0.649 sec)
297.7... logprob:  0.643859, 0.343750 (0.650 sec)
297.8... logprob:  0.604677, 0.289062 (0.648 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627156, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.947896e-03 [7.139328e-09] 
Layer 'conv1' biases: 4.308518e-07 [1.440800e-10] 
Layer 'conv2' weights[0]: 7.935590e-03 [6.250186e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.484178e-10] 
Layer 'conv3' weights[0]: 7.933511e-03 [6.092899e-09] 
Layer 'conv3' biases: 3.636223e-06 [2.232762e-09] 
Layer 'conv4' weights[0]: 7.966125e-03 [6.273190e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.992759e-08] 
Layer 'conv5' weights[0]: 7.965490e-03 [1.179809e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.260877e-07] 
Layer 'fc6' weights[0]: 7.561789e-03 [1.297257e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.247330e-08] 
Layer 'fc7' weights[0]: 7.544900e-03 [1.646871e-07] 
Layer 'fc7' biases: 9.998559e-01 [1.512424e-07] 
Layer 'fc8' weights[0]: 6.362600e-04 [8.420499e-06] 
Layer 'fc8' biases: 1.358342e-01 [1.770733e-04] 
Train error last 27 batches: 0.635936
-------------------------------------------------------
Not saving because 0.627156 > 0.627105 (256.15: -0.00%)
======================================================= (1.745 sec)
297.9... logprob:  0.638626, 0.335938 (0.649 sec)
297.10... logprob:  0.597632, 0.281250 (0.648 sec)
297.11... logprob:  0.639086, 0.335938 (0.650 sec)
297.12... logprob:  0.719190, 0.437500 (0.650 sec)
297.13... logprob:  0.657794, 0.359375 (0.650 sec)
297.14... logprob:  0.663405, 0.367188 (0.648 sec)
297.15... logprob:  0.686575, 0.398438 (0.650 sec)
297.16... logprob:  0.627061, 0.320312 (0.649 sec)
297.17... logprob:  0.638518, 0.335938 (0.651 sec)
297.18... logprob:  0.638226, 0.335938 (0.650 sec)
297.19... logprob:  0.632750, 0.328125 (0.650 sec)
297.20... logprob:  0.648804, 0.351562 (0.649 sec)
297.21... logprob:  0.643407, 0.343750 (0.651 sec)
297.22... logprob:  0.628184, 0.320312 (0.649 sec)
297.23... logprob:  0.623437, 0.312500 (0.650 sec)
297.24... logprob:  0.578774, 0.242188 (0.649 sec)
297.25... logprob:  0.628380, 0.320312 (0.650 sec)
297.26... logprob:  0.673738, 0.390625 (0.650 sec)
297.27... logprob:  0.628186, 0.320312 (0.650 sec)
298.1... logprob:  0.679187, 0.398438 (0.649 sec)
298.2... logprob:  0.597469, 0.273438 (0.651 sec)
298.3... logprob:  0.653712, 0.359375 (0.648 sec)
298.4... logprob:  0.596947, 0.273438 (0.649 sec)
298.5... logprob:  0.591119, 0.265625 (0.648 sec)
298.6... logprob:  0.611421, 0.296875 (0.649 sec)
298.7... logprob:  0.643859, 0.343750 (0.648 sec)
298.8... logprob:  0.604680, 0.289062 (0.650 sec)
298.9... logprob:  0.638624, 0.335938 (0.648 sec)
298.10... logprob:  0.597638, 0.281250 (0.649 sec)
298.11... logprob:  0.639082, 0.335938 (0.648 sec)
298.12... logprob:  0.719163, 0.437500 (0.651 sec)
298.13... logprob:  0.657785, 0.359375 (0.648 sec)
298.14... logprob:  0.663397, 0.367188 (0.649 sec)
298.15... logprob:  0.686565, 0.398438 (0.648 sec)
298.16... logprob:  0.627061, 0.320312 (0.650 sec)
298.17... logprob:  0.638518, 0.335938 (0.650 sec)
298.18... logprob:  0.638226, 0.335938 (0.651 sec)
298.19... logprob:  0.632750, 0.328125 (0.649 sec)
298.20... logprob:  0.648806, 0.351562 (0.650 sec)
298.21... logprob:  0.643407, 0.343750 (0.650 sec)
298.22... logprob:  0.628180, 0.320312 (0.650 sec)
298.23... logprob:  0.623432, 0.312500 (0.649 sec)
298.24... logprob:  0.578755, 0.242188 (0.651 sec)
298.25... logprob:  0.628376, 0.320312 (0.649 sec)
298.26... logprob:  0.673745, 0.390625 (0.651 sec)
298.27... logprob:  0.628183, 0.320312 (0.649 sec)
299.1... logprob:  0.679192, 0.398438 (0.650 sec)
299.2... logprob:  0.597463, 0.273438 (0.649 sec)
299.3... logprob:  0.653713, 0.359375 (0.649 sec)
299.4... logprob:  0.596944, 0.273438 (0.649 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.653940, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.947696e-03 [6.850337e-09] 
Layer 'conv1' biases: 4.345110e-07 [9.418688e-11] 
Layer 'conv2' weights[0]: 7.935394e-03 [5.304093e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.898588e-10] 
Layer 'conv3' weights[0]: 7.933309e-03 [5.041029e-09] 
Layer 'conv3' biases: 3.666446e-06 [1.307233e-09] 
Layer 'conv4' weights[0]: 7.965954e-03 [5.038828e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.046961e-08] 
Layer 'conv5' weights[0]: 7.965303e-03 [6.222298e-08] 
Layer 'conv5' biases: 1.000002e+00 [6.643059e-08] 
Layer 'fc6' weights[0]: 7.561603e-03 [7.674447e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.530394e-09] 
Layer 'fc7' weights[0]: 7.542968e-03 [9.768667e-08] 
Layer 'fc7' biases: 9.998554e-01 [7.934582e-08] 
Layer 'fc8' weights[0]: 6.074982e-04 [4.381384e-06] 
Layer 'fc8' biases: 1.359200e-01 [9.976754e-05] 
Train error last 27 batches: 0.635929
-------------------------------------------------------
Not saving because 0.653940 > 0.627105 (256.15: -0.00%)
======================================================= (1.775 sec)
299.5... logprob:  0.591119, 0.265625 (0.650 sec)
299.6... logprob:  0.611422, 0.296875 (0.648 sec)
299.7... logprob:  0.643858, 0.343750 (0.650 sec)
299.8... logprob:  0.604684, 0.289062 (0.647 sec)
299.9... logprob:  0.638622, 0.335938 (0.650 sec)
299.10... logprob:  0.597645, 0.281250 (0.648 sec)
299.11... logprob:  0.639078, 0.335938 (0.650 sec)
299.12... logprob:  0.719134, 0.437500 (0.650 sec)
299.13... logprob:  0.657775, 0.359375 (0.650 sec)
299.14... logprob:  0.663387, 0.367188 (0.648 sec)
299.15... logprob:  0.686554, 0.398438 (0.650 sec)
299.16... logprob:  0.627061, 0.320312 (0.649 sec)
299.17... logprob:  0.638518, 0.335938 (0.652 sec)
299.18... logprob:  0.638226, 0.335938 (0.650 sec)
299.19... logprob:  0.632750, 0.328125 (0.651 sec)
299.20... logprob:  0.648807, 0.351562 (0.649 sec)
299.21... logprob:  0.643408, 0.343750 (0.652 sec)
299.22... logprob:  0.628176, 0.320312 (0.649 sec)
299.23... logprob:  0.623425, 0.312500 (0.649 sec)
299.24... logprob:  0.578735, 0.242188 (0.649 sec)
299.25... logprob:  0.628372, 0.320312 (0.651 sec)
299.26... logprob:  0.673752, 0.390625 (0.649 sec)
299.27... logprob:  0.628180, 0.320312 (0.650 sec)
300.1... logprob:  0.679199, 0.398438 (0.649 sec)
300.2... logprob:  0.597455, 0.273438 (0.649 sec)
300.3... logprob:  0.653715, 0.359375 (0.648 sec)
300.4... logprob:  0.596939, 0.273438 (0.650 sec)
300.5... logprob:  0.591116, 0.265625 (0.648 sec)
300.6... logprob:  0.611422, 0.296875 (0.650 sec)
300.7... logprob:  0.643856, 0.343750 (0.649 sec)
300.8... logprob:  0.604688, 0.289062 (0.649 sec)
300.9... logprob:  0.638621, 0.335938 (0.648 sec)
300.10... logprob:  0.597651, 0.281250 (0.650 sec)
300.11... logprob:  0.639074, 0.335938 (0.648 sec)
300.12... logprob:  0.719108, 0.437500 (0.651 sec)
300.13... logprob:  0.657766, 0.359375 (0.649 sec)
300.14... logprob:  0.663378, 0.367188 (0.649 sec)
300.15... logprob:  0.686543, 0.398438 (0.648 sec)
300.16... logprob:  0.627062, 0.320312 (0.650 sec)
300.17... logprob:  0.638517, 0.335938 (0.650 sec)
300.18... logprob:  0.638226, 0.335938 (0.651 sec)
300.19... logprob:  0.632748, 0.328125 (0.649 sec)
300.20... logprob:  0.648808, 0.351562 (0.651 sec)
300.21... logprob:  0.643408, 0.343750 (0.650 sec)
300.22... logprob:  0.628173, 0.320312 (0.650 sec)
300.23... logprob:  0.623421, 0.312500 (0.648 sec)
300.24... logprob:  0.578718, 0.242188 (0.650 sec)
300.25... logprob:  0.628368, 0.320312 (0.649 sec)
300.26... logprob:  0.673758, 0.390625 (0.651 sec)
300.27... logprob:  0.628177, 0.320312 (0.649 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.628124, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.947503e-03 [6.591126e-09] 
Layer 'conv1' biases: 4.379861e-07 [6.824825e-11] 
Layer 'conv2' weights[0]: 7.935201e-03 [4.862051e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.676364e-10] 
Layer 'conv3' weights[0]: 7.933116e-03 [4.480529e-09] 
Layer 'conv3' biases: 3.694310e-06 [7.492125e-10] 
Layer 'conv4' weights[0]: 7.965754e-03 [4.429844e-09] 
Layer 'conv4' biases: 1.000001e+00 [4.612577e-09] 
Layer 'conv5' weights[0]: 7.965112e-03 [2.757533e-08] 
Layer 'conv5' biases: 1.000003e+00 [2.915199e-08] 
Layer 'fc6' weights[0]: 7.561415e-03 [4.897051e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.861995e-09] 
Layer 'fc7' weights[0]: 7.541127e-03 [5.833576e-08] 
Layer 'fc7' biases: 9.998553e-01 [3.509808e-08] 
Layer 'fc8' weights[0]: 6.005644e-04 [1.898330e-06] 
Layer 'fc8' biases: 1.364969e-01 [5.212807e-05] 
Train error last 27 batches: 0.635923
-------------------------------------------------------
Not saving because 0.628124 > 0.627105 (256.15: -0.00%)
======================================================= (1.821 sec)
301.1... logprob:  0.679205, 0.398438 (0.650 sec)
301.2... logprob:  0.597447, 0.273438 (0.649 sec)
301.3... logprob:  0.653716, 0.359375 (0.650 sec)
301.4... logprob:  0.596934, 0.273438 (0.648 sec)
301.5... logprob:  0.591112, 0.265625 (0.650 sec)
301.6... logprob:  0.611421, 0.296875 (0.649 sec)
301.7... logprob:  0.643857, 0.343750 (0.650 sec)
301.8... logprob:  0.604690, 0.289062 (0.648 sec)
301.9... logprob:  0.638620, 0.335938 (0.649 sec)
301.10... logprob:  0.597656, 0.281250 (0.648 sec)
301.11... logprob:  0.639071, 0.335938 (0.650 sec)
301.12... logprob:  0.719086, 0.437500 (0.649 sec)
301.13... logprob:  0.657759, 0.359375 (0.650 sec)
301.14... logprob:  0.663370, 0.367188 (0.648 sec)
301.15... logprob:  0.686535, 0.398438 (0.649 sec)
301.16... logprob:  0.627061, 0.320312 (0.649 sec)
301.17... logprob:  0.638518, 0.335938 (0.651 sec)
301.18... logprob:  0.638226, 0.335938 (0.650 sec)
301.19... logprob:  0.632747, 0.328125 (0.651 sec)
301.20... logprob:  0.648809, 0.351562 (0.649 sec)
301.21... logprob:  0.643408, 0.343750 (0.651 sec)
301.22... logprob:  0.628170, 0.320312 (0.649 sec)
301.23... logprob:  0.623415, 0.312500 (0.650 sec)
301.24... logprob:  0.578701, 0.242188 (0.649 sec)
301.25... logprob:  0.628364, 0.320312 (0.650 sec)
301.26... logprob:  0.673763, 0.390625 (0.652 sec)
301.27... logprob:  0.628174, 0.320312 (0.650 sec)
302.1... logprob:  0.679211, 0.398438 (0.650 sec)
302.2... logprob:  0.597441, 0.273438 (0.650 sec)
302.3... logprob:  0.653717, 0.359375 (0.648 sec)
302.4... logprob:  0.596930, 0.273438 (0.650 sec)
302.5... logprob:  0.591111, 0.265625 (0.649 sec)
302.6... logprob:  0.611422, 0.296875 (0.650 sec)
302.7... logprob:  0.643856, 0.343750 (0.649 sec)
302.8... logprob:  0.604693, 0.289062 (0.649 sec)
302.9... logprob:  0.638618, 0.335938 (0.648 sec)
302.10... logprob:  0.597662, 0.281250 (0.649 sec)
302.11... logprob:  0.639067, 0.335938 (0.649 sec)
302.12... logprob:  0.719058, 0.437500 (0.651 sec)
302.13... logprob:  0.657750, 0.359375 (0.649 sec)
302.14... logprob:  0.663362, 0.367188 (0.649 sec)
302.15... logprob:  0.686525, 0.398438 (0.648 sec)
302.16... logprob:  0.627062, 0.320312 (0.650 sec)
302.17... logprob:  0.638518, 0.335938 (0.650 sec)
302.18... logprob:  0.638226, 0.335938 (0.651 sec)
302.19... logprob:  0.632747, 0.328125 (0.649 sec)
302.20... logprob:  0.648811, 0.351562 (0.650 sec)
302.21... logprob:  0.643409, 0.343750 (0.650 sec)
302.22... logprob:  0.628165, 0.320312 (0.649 sec)
302.23... logprob:  0.623409, 0.312500 (0.648 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633475, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.947316e-03 [6.325267e-09] 
Layer 'conv1' biases: 4.414583e-07 [1.015566e-10] 
Layer 'conv2' weights[0]: 7.935004e-03 [5.262887e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.003866e-10] 
Layer 'conv3' weights[0]: 7.932917e-03 [4.705202e-09] 
Layer 'conv3' biases: 3.722527e-06 [1.045249e-09] 
Layer 'conv4' weights[0]: 7.965565e-03 [4.585359e-09] 
Layer 'conv4' biases: 1.000001e+00 [5.604640e-09] 
Layer 'conv5' weights[0]: 7.964913e-03 [3.308390e-08] 
Layer 'conv5' biases: 1.000003e+00 [3.496730e-08] 
Layer 'fc6' weights[0]: 7.561208e-03 [5.278154e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.565089e-09] 
Layer 'fc7' weights[0]: 7.539160e-03 [6.552069e-08] 
Layer 'fc7' biases: 9.998549e-01 [4.454009e-08] 
Layer 'fc8' weights[0]: 5.921967e-04 [2.418418e-06] 
Layer 'fc8' biases: 1.370116e-01 [3.506601e-05] 
Train error last 27 batches: 0.635918
-------------------------------------------------------
Not saving because 0.633475 > 0.627105 (256.15: -0.00%)
======================================================= (1.804 sec)
302.24... logprob:  0.578680, 0.242188 (0.650 sec)
302.25... logprob:  0.628359, 0.320312 (0.649 sec)
302.26... logprob:  0.673771, 0.390625 (0.651 sec)
302.27... logprob:  0.628171, 0.320312 (0.649 sec)
303.1... logprob:  0.679217, 0.398438 (0.650 sec)
303.2... logprob:  0.597434, 0.273438 (0.649 sec)
303.3... logprob:  0.653718, 0.359375 (0.650 sec)
303.4... logprob:  0.596927, 0.273438 (0.648 sec)
303.5... logprob:  0.591109, 0.265625 (0.650 sec)
303.6... logprob:  0.611423, 0.296875 (0.649 sec)
303.7... logprob:  0.643855, 0.343750 (0.650 sec)
303.8... logprob:  0.604698, 0.289062 (0.648 sec)
303.9... logprob:  0.638616, 0.335938 (0.650 sec)
303.10... logprob:  0.597669, 0.281250 (0.648 sec)
303.11... logprob:  0.639062, 0.335938 (0.650 sec)
303.12... logprob:  0.719028, 0.437500 (0.649 sec)
303.13... logprob:  0.657740, 0.359375 (0.650 sec)
303.14... logprob:  0.663352, 0.367188 (0.648 sec)
303.15... logprob:  0.686512, 0.398438 (0.650 sec)
303.16... logprob:  0.627062, 0.320312 (0.649 sec)
303.17... logprob:  0.638517, 0.335938 (0.652 sec)
303.18... logprob:  0.638226, 0.335938 (0.650 sec)
303.19... logprob:  0.632746, 0.328125 (0.651 sec)
303.20... logprob:  0.648812, 0.351562 (0.650 sec)
303.21... logprob:  0.643408, 0.343750 (0.651 sec)
303.22... logprob:  0.628162, 0.320312 (0.648 sec)
303.23... logprob:  0.623404, 0.312500 (0.650 sec)
303.24... logprob:  0.578665, 0.242188 (0.648 sec)
303.25... logprob:  0.628356, 0.320312 (0.651 sec)
303.26... logprob:  0.673777, 0.390625 (0.650 sec)
303.27... logprob:  0.628168, 0.320312 (0.650 sec)
304.1... logprob:  0.679224, 0.398438 (0.649 sec)
304.2... logprob:  0.597426, 0.273438 (0.650 sec)
304.3... logprob:  0.653720, 0.359375 (0.648 sec)
304.4... logprob:  0.596920, 0.273438 (0.650 sec)
304.5... logprob:  0.591104, 0.265625 (0.649 sec)
304.6... logprob:  0.611422, 0.296875 (0.650 sec)
304.7... logprob:  0.643855, 0.343750 (0.649 sec)
304.8... logprob:  0.604698, 0.289062 (0.650 sec)
304.9... logprob:  0.638615, 0.335938 (0.648 sec)
304.10... logprob:  0.597673, 0.281250 (0.649 sec)
304.11... logprob:  0.639060, 0.335938 (0.649 sec)
304.12... logprob:  0.719010, 0.437500 (0.651 sec)
304.13... logprob:  0.657734, 0.359375 (0.649 sec)
304.14... logprob:  0.663346, 0.367188 (0.650 sec)
304.15... logprob:  0.686507, 0.398438 (0.648 sec)
304.16... logprob:  0.627062, 0.320312 (0.650 sec)
304.17... logprob:  0.638518, 0.335938 (0.650 sec)
304.18... logprob:  0.638225, 0.335938 (0.651 sec)
304.19... logprob:  0.632745, 0.328125 (0.649 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.685738, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.947126e-03 [6.739938e-09] 
Layer 'conv1' biases: 4.447107e-07 [1.581411e-10] 
Layer 'conv2' weights[0]: 7.934810e-03 [6.616109e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.692436e-10] 
Layer 'conv3' weights[0]: 7.932715e-03 [5.780488e-09] 
Layer 'conv3' biases: 3.748033e-06 [2.129518e-09] 
Layer 'conv4' weights[0]: 7.965357e-03 [5.742698e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.517585e-08] 
Layer 'conv5' weights[0]: 7.964719e-03 [8.916945e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.485483e-08] 
Layer 'fc6' weights[0]: 7.561018e-03 [1.031216e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.538563e-09] 
Layer 'fc7' weights[0]: 7.537221e-03 [1.317385e-07] 
Layer 'fc7' biases: 9.998552e-01 [1.168041e-07] 
Layer 'fc8' weights[0]: 6.081694e-04 [6.412677e-06] 
Layer 'fc8' biases: 1.381047e-01 [1.129260e-04] 
Train error last 27 batches: 0.635912
-------------------------------------------------------
Not saving because 0.685738 > 0.627105 (256.15: -0.00%)
======================================================= (1.751 sec)
304.20... logprob:  0.648814, 0.351562 (0.650 sec)
304.21... logprob:  0.643409, 0.343750 (0.650 sec)
304.22... logprob:  0.628158, 0.320312 (0.650 sec)
304.23... logprob:  0.623398, 0.312500 (0.648 sec)
304.24... logprob:  0.578644, 0.242188 (0.650 sec)
304.25... logprob:  0.628351, 0.320312 (0.649 sec)
304.26... logprob:  0.673783, 0.390625 (0.651 sec)
304.27... logprob:  0.628165, 0.320312 (0.649 sec)
305.1... logprob:  0.679228, 0.398438 (0.650 sec)
305.2... logprob:  0.597421, 0.273438 (0.648 sec)
305.3... logprob:  0.653720, 0.359375 (0.650 sec)
305.4... logprob:  0.596919, 0.273438 (0.649 sec)
305.5... logprob:  0.591106, 0.265625 (0.650 sec)
305.6... logprob:  0.611424, 0.296875 (0.649 sec)
305.7... logprob:  0.643853, 0.343750 (0.650 sec)
305.8... logprob:  0.604705, 0.289062 (0.649 sec)
305.9... logprob:  0.638612, 0.335938 (0.649 sec)
305.10... logprob:  0.597682, 0.281250 (0.648 sec)
305.11... logprob:  0.639054, 0.335938 (0.650 sec)
305.12... logprob:  0.718974, 0.437500 (0.650 sec)
305.13... logprob:  0.657722, 0.359375 (0.650 sec)
305.14... logprob:  0.663334, 0.367188 (0.648 sec)
305.15... logprob:  0.686493, 0.398438 (0.649 sec)
305.16... logprob:  0.627062, 0.320312 (0.649 sec)
305.17... logprob:  0.638517, 0.335938 (0.651 sec)
305.18... logprob:  0.638226, 0.335938 (0.650 sec)
305.19... logprob:  0.632745, 0.328125 (0.651 sec)
305.20... logprob:  0.648815, 0.351562 (0.649 sec)
305.21... logprob:  0.643410, 0.343750 (0.651 sec)
305.22... logprob:  0.628154, 0.320312 (0.648 sec)
305.23... logprob:  0.623392, 0.312500 (0.650 sec)
305.24... logprob:  0.578623, 0.242188 (0.649 sec)
305.25... logprob:  0.628347, 0.320312 (0.650 sec)
305.26... logprob:  0.673792, 0.390625 (0.649 sec)
305.27... logprob:  0.628161, 0.320312 (0.650 sec)
306.1... logprob:  0.679237, 0.398438 (0.648 sec)
306.2... logprob:  0.597410, 0.273438 (0.650 sec)
306.3... logprob:  0.653723, 0.359375 (0.648 sec)
306.4... logprob:  0.596912, 0.273438 (0.650 sec)
306.5... logprob:  0.591100, 0.265625 (0.648 sec)
306.6... logprob:  0.611423, 0.296875 (0.650 sec)
306.7... logprob:  0.643853, 0.343750 (0.648 sec)
306.8... logprob:  0.604707, 0.289062 (0.649 sec)
306.9... logprob:  0.638611, 0.335938 (0.648 sec)
306.10... logprob:  0.597688, 0.281250 (0.650 sec)
306.11... logprob:  0.639051, 0.335938 (0.649 sec)
306.12... logprob:  0.718948, 0.437500 (0.651 sec)
306.13... logprob:  0.657713, 0.359375 (0.649 sec)
306.14... logprob:  0.663326, 0.367188 (0.650 sec)
306.15... logprob:  0.686483, 0.398438 (0.648 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.632892, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.946931e-03 [7.336620e-09] 
Layer 'conv1' biases: 4.478833e-07 [2.078389e-10] 
Layer 'conv2' weights[0]: 7.934622e-03 [7.728017e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.046248e-09] 
Layer 'conv3' weights[0]: 7.932516e-03 [6.706266e-09] 
Layer 'conv3' biases: 3.772185e-06 [2.925233e-09] 
Layer 'conv4' weights[0]: 7.965172e-03 [6.786702e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.233019e-08] 
Layer 'conv5' weights[0]: 7.964534e-03 [1.313658e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.400693e-07] 
Layer 'fc6' weights[0]: 7.560833e-03 [1.437943e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.398225e-08] 
Layer 'fc7' weights[0]: 7.535322e-03 [1.816647e-07] 
Layer 'fc7' biases: 9.998557e-01 [1.693774e-07] 
Layer 'fc8' weights[0]: 6.339927e-04 [9.399258e-06] 
Layer 'fc8' biases: 1.393922e-01 [1.653558e-04] 
Train error last 27 batches: 0.635905
-------------------------------------------------------
Not saving because 0.632892 > 0.627105 (256.15: -0.00%)
======================================================= (1.737 sec)
306.16... logprob:  0.627062, 0.320312 (0.650 sec)
306.17... logprob:  0.638517, 0.335938 (0.650 sec)
306.18... logprob:  0.638226, 0.335938 (0.650 sec)
306.19... logprob:  0.632745, 0.328125 (0.649 sec)
306.20... logprob:  0.648817, 0.351562 (0.651 sec)
306.21... logprob:  0.643410, 0.343750 (0.650 sec)
306.22... logprob:  0.628151, 0.320312 (0.650 sec)
306.23... logprob:  0.623386, 0.312500 (0.648 sec)
306.24... logprob:  0.578606, 0.242188 (0.650 sec)
306.25... logprob:  0.628343, 0.320312 (0.649 sec)
306.26... logprob:  0.673798, 0.390625 (0.651 sec)
306.27... logprob:  0.628159, 0.320312 (0.649 sec)
307.1... logprob:  0.679243, 0.398438 (0.650 sec)
307.2... logprob:  0.597405, 0.273438 (0.648 sec)
307.3... logprob:  0.653724, 0.359375 (0.650 sec)
307.4... logprob:  0.596910, 0.273438 (0.648 sec)
307.5... logprob:  0.591099, 0.265625 (0.650 sec)
307.6... logprob:  0.611423, 0.296875 (0.649 sec)
307.7... logprob:  0.643852, 0.343750 (0.650 sec)
307.8... logprob:  0.604711, 0.289062 (0.648 sec)
307.9... logprob:  0.638609, 0.335938 (0.650 sec)
307.10... logprob:  0.597694, 0.281250 (0.648 sec)
307.11... logprob:  0.639046, 0.335938 (0.650 sec)
307.12... logprob:  0.718921, 0.437500 (0.649 sec)
307.13... logprob:  0.657703, 0.359375 (0.650 sec)
307.14... logprob:  0.663316, 0.367188 (0.648 sec)
307.15... logprob:  0.686472, 0.398438 (0.650 sec)
307.16... logprob:  0.627063, 0.320312 (0.649 sec)
307.17... logprob:  0.638517, 0.335938 (0.652 sec)
307.18... logprob:  0.638225, 0.335938 (0.650 sec)
307.19... logprob:  0.632744, 0.328125 (0.652 sec)
307.20... logprob:  0.648818, 0.351562 (0.649 sec)
307.21... logprob:  0.643410, 0.343750 (0.652 sec)
307.22... logprob:  0.628148, 0.320312 (0.649 sec)
307.23... logprob:  0.623381, 0.312500 (0.649 sec)
307.24... logprob:  0.578589, 0.242188 (0.649 sec)
307.25... logprob:  0.628339, 0.320312 (0.651 sec)
307.26... logprob:  0.673804, 0.390625 (0.649 sec)
307.27... logprob:  0.628156, 0.320312 (0.651 sec)
308.1... logprob:  0.679249, 0.398438 (0.649 sec)
308.2... logprob:  0.597397, 0.273438 (0.650 sec)
308.3... logprob:  0.653725, 0.359375 (0.649 sec)
308.4... logprob:  0.596904, 0.273438 (0.650 sec)
308.5... logprob:  0.591096, 0.265625 (0.648 sec)
308.6... logprob:  0.611423, 0.296875 (0.650 sec)
308.7... logprob:  0.643852, 0.343750 (0.649 sec)
308.8... logprob:  0.604713, 0.289062 (0.649 sec)
308.9... logprob:  0.638608, 0.335938 (0.648 sec)
308.10... logprob:  0.597698, 0.281250 (0.649 sec)
308.11... logprob:  0.639043, 0.335938 (0.648 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627239, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.946729e-03 [6.767475e-09] 
Layer 'conv1' biases: 4.511114e-07 [1.141042e-10] 
Layer 'conv2' weights[0]: 7.934442e-03 [5.651797e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.540193e-10] 
Layer 'conv3' weights[0]: 7.932321e-03 [5.505730e-09] 
Layer 'conv3' biases: 3.797239e-06 [1.739949e-09] 
Layer 'conv4' weights[0]: 7.964983e-03 [5.626029e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.523401e-08] 
Layer 'conv5' weights[0]: 7.964333e-03 [8.987138e-08] 
Layer 'conv5' biases: 1.000001e+00 [9.598888e-08] 
Layer 'fc6' weights[0]: 7.560652e-03 [1.029915e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.479558e-09] 
Layer 'fc7' weights[0]: 7.533418e-03 [1.294990e-07] 
Layer 'fc7' biases: 9.998558e-01 [1.132997e-07] 
Layer 'fc8' weights[0]: 6.504231e-04 [6.326390e-06] 
Layer 'fc8' biases: 1.404548e-01 [1.348595e-04] 
Train error last 27 batches: 0.635900
-------------------------------------------------------
Not saving because 0.627239 > 0.627105 (256.15: -0.00%)
======================================================= (1.762 sec)
308.12... logprob:  0.718901, 0.437500 (0.651 sec)
308.13... logprob:  0.657697, 0.359375 (0.649 sec)
308.14... logprob:  0.663309, 0.367188 (0.649 sec)
308.15... logprob:  0.686464, 0.398438 (0.648 sec)
308.16... logprob:  0.627062, 0.320312 (0.650 sec)
308.17... logprob:  0.638517, 0.335938 (0.650 sec)
308.18... logprob:  0.638225, 0.335938 (0.651 sec)
308.19... logprob:  0.632743, 0.328125 (0.649 sec)
308.20... logprob:  0.648818, 0.351562 (0.651 sec)
308.21... logprob:  0.643411, 0.343750 (0.650 sec)
308.22... logprob:  0.628145, 0.320312 (0.649 sec)
308.23... logprob:  0.623376, 0.312500 (0.649 sec)
308.24... logprob:  0.578573, 0.242188 (0.650 sec)
308.25... logprob:  0.628335, 0.320312 (0.650 sec)
308.26... logprob:  0.673809, 0.390625 (0.652 sec)
308.27... logprob:  0.628153, 0.320312 (0.649 sec)
309.1... logprob:  0.679254, 0.398438 (0.650 sec)
309.2... logprob:  0.597391, 0.273438 (0.649 sec)
309.3... logprob:  0.653726, 0.359375 (0.650 sec)
309.4... logprob:  0.596900, 0.273438 (0.649 sec)
309.5... logprob:  0.591093, 0.265625 (0.650 sec)
309.6... logprob:  0.611423, 0.296875 (0.649 sec)
309.7... logprob:  0.643851, 0.343750 (0.650 sec)
309.8... logprob:  0.604716, 0.289062 (0.648 sec)
309.9... logprob:  0.638606, 0.335938 (0.649 sec)
309.10... logprob:  0.597704, 0.281250 (0.648 sec)
309.11... logprob:  0.639039, 0.335938 (0.650 sec)
309.12... logprob:  0.718874, 0.437500 (0.649 sec)
309.13... logprob:  0.657687, 0.359375 (0.650 sec)
309.14... logprob:  0.663301, 0.367188 (0.648 sec)
309.15... logprob:  0.686454, 0.398438 (0.649 sec)
309.16... logprob:  0.627062, 0.320312 (0.650 sec)
309.17... logprob:  0.638516, 0.335938 (0.652 sec)
309.18... logprob:  0.638226, 0.335938 (0.649 sec)
309.19... logprob:  0.632742, 0.328125 (0.651 sec)
309.20... logprob:  0.648820, 0.351562 (0.649 sec)
309.21... logprob:  0.643411, 0.343750 (0.651 sec)
309.22... logprob:  0.628141, 0.320312 (0.648 sec)
309.23... logprob:  0.623371, 0.312500 (0.650 sec)
309.24... logprob:  0.578554, 0.242188 (0.648 sec)
309.25... logprob:  0.628331, 0.320312 (0.651 sec)
309.26... logprob:  0.673815, 0.390625 (0.650 sec)
309.27... logprob:  0.628150, 0.320312 (0.650 sec)
310.1... logprob:  0.679260, 0.398438 (0.649 sec)
310.2... logprob:  0.597384, 0.273438 (0.650 sec)
310.3... logprob:  0.653727, 0.359375 (0.650 sec)
310.4... logprob:  0.596896, 0.273438 (0.650 sec)
310.5... logprob:  0.591091, 0.265625 (0.648 sec)
310.6... logprob:  0.611423, 0.296875 (0.649 sec)
310.7... logprob:  0.643850, 0.343750 (0.648 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.655190, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.946521e-03 [6.865908e-09] 
Layer 'conv1' biases: 4.547253e-07 [1.309986e-10] 
Layer 'conv2' weights[0]: 7.934258e-03 [5.834641e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.299691e-10] 
Layer 'conv3' weights[0]: 7.932124e-03 [5.668575e-09] 
Layer 'conv3' biases: 3.827596e-06 [1.912060e-09] 
Layer 'conv4' weights[0]: 7.964783e-03 [5.790440e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.679120e-08] 
Layer 'conv5' weights[0]: 7.964144e-03 [9.828616e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.049244e-07] 
Layer 'fc6' weights[0]: 7.560447e-03 [1.111183e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.043518e-08] 
Layer 'fc7' weights[0]: 7.531503e-03 [1.410375e-07] 
Layer 'fc7' biases: 9.998553e-01 [1.263890e-07] 
Layer 'fc8' weights[0]: 6.233041e-04 [6.937721e-06] 
Layer 'fc8' biases: 1.405748e-01 [1.523460e-04] 
Train error last 27 batches: 0.635895
-------------------------------------------------------
Not saving because 0.655190 > 0.627105 (256.15: -0.00%)
======================================================= (1.755 sec)
310.8... logprob:  0.604720, 0.289062 (0.649 sec)
310.9... logprob:  0.638604, 0.335938 (0.648 sec)
310.10... logprob:  0.597711, 0.281250 (0.650 sec)
310.11... logprob:  0.639035, 0.335938 (0.648 sec)
310.12... logprob:  0.718847, 0.437500 (0.650 sec)
310.13... logprob:  0.657679, 0.359375 (0.649 sec)
310.14... logprob:  0.663291, 0.367188 (0.649 sec)
310.15... logprob:  0.686443, 0.398438 (0.648 sec)
310.16... logprob:  0.627062, 0.320312 (0.650 sec)
310.17... logprob:  0.638516, 0.335938 (0.650 sec)
310.18... logprob:  0.638226, 0.335938 (0.651 sec)
310.19... logprob:  0.632742, 0.328125 (0.649 sec)
310.20... logprob:  0.648822, 0.351562 (0.651 sec)
310.21... logprob:  0.643411, 0.343750 (0.650 sec)
310.22... logprob:  0.628137, 0.320312 (0.650 sec)
310.23... logprob:  0.623366, 0.312500 (0.648 sec)
310.24... logprob:  0.578537, 0.242188 (0.650 sec)
310.25... logprob:  0.628327, 0.320312 (0.649 sec)
310.26... logprob:  0.673822, 0.390625 (0.651 sec)
310.27... logprob:  0.628147, 0.320312 (0.649 sec)
311.1... logprob:  0.679266, 0.398438 (0.650 sec)
311.2... logprob:  0.597377, 0.273438 (0.649 sec)
311.3... logprob:  0.653729, 0.359375 (0.650 sec)
311.4... logprob:  0.596892, 0.273438 (0.649 sec)
311.5... logprob:  0.591088, 0.265625 (0.650 sec)
311.6... logprob:  0.611423, 0.296875 (0.649 sec)
311.7... logprob:  0.643849, 0.343750 (0.650 sec)
311.8... logprob:  0.604722, 0.289062 (0.648 sec)
311.9... logprob:  0.638603, 0.335938 (0.650 sec)
311.10... logprob:  0.597716, 0.281250 (0.649 sec)
311.11... logprob:  0.639032, 0.335938 (0.650 sec)
311.12... logprob:  0.718824, 0.437500 (0.650 sec)
311.13... logprob:  0.657671, 0.359375 (0.650 sec)
311.14... logprob:  0.663284, 0.367188 (0.648 sec)
311.15... logprob:  0.686435, 0.398438 (0.650 sec)
311.16... logprob:  0.627062, 0.320312 (0.649 sec)
311.17... logprob:  0.638517, 0.335938 (0.652 sec)
311.18... logprob:  0.638225, 0.335938 (0.650 sec)
311.19... logprob:  0.632741, 0.328125 (0.653 sec)
311.20... logprob:  0.648823, 0.351562 (0.649 sec)
311.21... logprob:  0.643411, 0.343750 (0.651 sec)
311.22... logprob:  0.628134, 0.320312 (0.648 sec)
311.23... logprob:  0.623360, 0.312500 (0.650 sec)
311.24... logprob:  0.578519, 0.242188 (0.649 sec)
311.25... logprob:  0.628323, 0.320312 (0.651 sec)
311.26... logprob:  0.673828, 0.390625 (0.649 sec)
311.27... logprob:  0.628144, 0.320312 (0.650 sec)
312.1... logprob:  0.679272, 0.398438 (0.649 sec)
312.2... logprob:  0.597369, 0.273438 (0.650 sec)
312.3... logprob:  0.653730, 0.359375 (0.648 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627993, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.946327e-03 [6.708263e-09] 
Layer 'conv1' biases: 4.583446e-07 [6.408013e-11] 
Layer 'conv2' weights[0]: 7.934048e-03 [4.939249e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.533410e-10] 
Layer 'conv3' weights[0]: 7.931921e-03 [4.464916e-09] 
Layer 'conv3' biases: 3.857343e-06 [6.805620e-10] 
Layer 'conv4' weights[0]: 7.964598e-03 [4.357998e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.922205e-09] 
Layer 'conv5' weights[0]: 7.963975e-03 [1.786567e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.857124e-08] 
Layer 'fc6' weights[0]: 7.560280e-03 [4.286621e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.822988e-09] 
Layer 'fc7' weights[0]: 7.529571e-03 [4.788090e-08] 
Layer 'fc7' biases: 9.998549e-01 [2.217123e-08] 
Layer 'fc8' weights[0]: 5.990347e-04 [1.204359e-06] 
Layer 'fc8' biases: 1.407279e-01 [3.406861e-05] 
Train error last 27 batches: 0.635889
-------------------------------------------------------
Not saving because 0.627993 > 0.627105 (256.15: -0.00%)
======================================================= (1.846 sec)
312.4... logprob:  0.596888, 0.273438 (0.650 sec)
312.5... logprob:  0.591086, 0.265625 (0.648 sec)
312.6... logprob:  0.611424, 0.296875 (0.650 sec)
312.7... logprob:  0.643849, 0.343750 (0.649 sec)
312.8... logprob:  0.604726, 0.289062 (0.649 sec)
312.9... logprob:  0.638602, 0.335938 (0.648 sec)
312.10... logprob:  0.597723, 0.281250 (0.650 sec)
312.11... logprob:  0.639028, 0.335938 (0.649 sec)
312.12... logprob:  0.718797, 0.437500 (0.651 sec)
312.13... logprob:  0.657661, 0.359375 (0.649 sec)
312.14... logprob:  0.663275, 0.367188 (0.650 sec)
312.15... logprob:  0.686425, 0.398438 (0.648 sec)
312.16... logprob:  0.627063, 0.320312 (0.650 sec)
312.17... logprob:  0.638517, 0.335938 (0.650 sec)
312.18... logprob:  0.638226, 0.335938 (0.651 sec)
312.19... logprob:  0.632741, 0.328125 (0.650 sec)
312.20... logprob:  0.648825, 0.351562 (0.650 sec)
312.21... logprob:  0.643412, 0.343750 (0.650 sec)
312.22... logprob:  0.628130, 0.320312 (0.649 sec)
312.23... logprob:  0.623354, 0.312500 (0.649 sec)
312.24... logprob:  0.578498, 0.242188 (0.650 sec)
312.25... logprob:  0.628319, 0.320312 (0.653 sec)
312.26... logprob:  0.673836, 0.390625 (0.651 sec)
312.27... logprob:  0.628141, 0.320312 (0.649 sec)
313.1... logprob:  0.679279, 0.398438 (0.650 sec)
313.2... logprob:  0.597363, 0.273438 (0.648 sec)
313.3... logprob:  0.653731, 0.359375 (0.651 sec)
313.4... logprob:  0.596884, 0.273438 (0.649 sec)
313.5... logprob:  0.591085, 0.265625 (0.650 sec)
313.6... logprob:  0.611425, 0.296875 (0.649 sec)
313.7... logprob:  0.643848, 0.343750 (0.650 sec)
313.8... logprob:  0.604730, 0.289062 (0.649 sec)
313.9... logprob:  0.638599, 0.335938 (0.650 sec)
313.10... logprob:  0.597731, 0.281250 (0.648 sec)
313.11... logprob:  0.639023, 0.335938 (0.650 sec)
313.12... logprob:  0.718764, 0.437500 (0.650 sec)
313.13... logprob:  0.657650, 0.359375 (0.650 sec)
313.14... logprob:  0.663264, 0.367188 (0.654 sec)
313.15... logprob:  0.686411, 0.398438 (0.655 sec)
313.16... logprob:  0.627063, 0.320312 (0.649 sec)
313.17... logprob:  0.638516, 0.335938 (0.650 sec)
313.18... logprob:  0.638225, 0.335938 (0.655 sec)
313.19... logprob:  0.632740, 0.328125 (0.650 sec)
313.20... logprob:  0.648825, 0.351562 (0.649 sec)
313.21... logprob:  0.643412, 0.343750 (0.651 sec)
313.22... logprob:  0.628127, 0.320312 (0.649 sec)
313.23... logprob:  0.623350, 0.312500 (0.649 sec)
313.24... logprob:  0.578483, 0.242188 (0.649 sec)
313.25... logprob:  0.628316, 0.320312 (0.651 sec)
313.26... logprob:  0.673842, 0.390625 (0.658 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633224, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.946131e-03 [6.517615e-09] 
Layer 'conv1' biases: 4.617843e-07 [6.710280e-11] 
Layer 'conv2' weights[0]: 7.933863e-03 [4.957036e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.355468e-10] 
Layer 'conv3' weights[0]: 7.931728e-03 [4.412245e-09] 
Layer 'conv3' biases: 3.885057e-06 [6.256286e-10] 
Layer 'conv4' weights[0]: 7.964408e-03 [4.318878e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.171449e-09] 
Layer 'conv5' weights[0]: 7.963772e-03 [1.327542e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.357234e-08] 
Layer 'fc6' weights[0]: 7.560080e-03 [4.064541e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.331183e-09] 
Layer 'fc7' weights[0]: 7.527660e-03 [4.367275e-08] 
Layer 'fc7' biases: 9.998547e-01 [1.627094e-08] 
Layer 'fc8' weights[0]: 5.946815e-04 [8.605156e-07] 
Layer 'fc8' biases: 1.413431e-01 [3.130670e-05] 
Train error last 27 batches: 0.635882
-------------------------------------------------------
Not saving because 0.633224 > 0.627105 (256.15: -0.00%)
======================================================= (1.867 sec)
313.27... logprob:  0.628138, 0.320312 (0.655 sec)
314.1... logprob:  0.679285, 0.398438 (0.661 sec)
314.2... logprob:  0.597354, 0.273438 (0.652 sec)
314.3... logprob:  0.653733, 0.359375 (0.653 sec)
314.4... logprob:  0.596877, 0.273438 (0.651 sec)
314.5... logprob:  0.591078, 0.265625 (0.651 sec)
314.6... logprob:  0.611422, 0.296875 (0.646 sec)
314.7... logprob:  0.643848, 0.343750 (0.648 sec)
314.8... logprob:  0.604730, 0.289062 (0.649 sec)
314.9... logprob:  0.638599, 0.335938 (0.648 sec)
314.10... logprob:  0.597733, 0.281250 (0.648 sec)
314.11... logprob:  0.639022, 0.335938 (0.648 sec)
314.12... logprob:  0.718750, 0.437500 (0.650 sec)
314.13... logprob:  0.657646, 0.359375 (0.649 sec)
314.14... logprob:  0.663260, 0.367188 (0.649 sec)
314.15... logprob:  0.686407, 0.398438 (0.648 sec)
314.16... logprob:  0.627063, 0.320312 (0.649 sec)
314.17... logprob:  0.638517, 0.335938 (0.650 sec)
314.18... logprob:  0.638225, 0.335938 (0.650 sec)
314.19... logprob:  0.632740, 0.328125 (0.649 sec)
314.20... logprob:  0.648827, 0.351562 (0.650 sec)
314.21... logprob:  0.643412, 0.343750 (0.650 sec)
314.22... logprob:  0.628123, 0.320312 (0.649 sec)
314.23... logprob:  0.623344, 0.312500 (0.649 sec)
314.24... logprob:  0.578464, 0.242188 (0.649 sec)
314.25... logprob:  0.628311, 0.320312 (0.650 sec)
314.26... logprob:  0.673848, 0.390625 (0.650 sec)
314.27... logprob:  0.628135, 0.320312 (0.649 sec)
315.1... logprob:  0.679290, 0.398438 (0.649 sec)
315.2... logprob:  0.597350, 0.273438 (0.649 sec)
315.3... logprob:  0.653734, 0.359375 (0.649 sec)
315.4... logprob:  0.596877, 0.273438 (0.649 sec)
315.5... logprob:  0.591081, 0.265625 (0.650 sec)
315.6... logprob:  0.611425, 0.296875 (0.648 sec)
315.7... logprob:  0.643846, 0.343750 (0.649 sec)
315.8... logprob:  0.604737, 0.289062 (0.648 sec)
315.9... logprob:  0.638596, 0.335938 (0.648 sec)
315.10... logprob:  0.597743, 0.281250 (0.648 sec)
315.11... logprob:  0.639016, 0.335938 (0.649 sec)
315.12... logprob:  0.718712, 0.437500 (0.649 sec)
315.13... logprob:  0.657633, 0.359375 (0.649 sec)
315.14... logprob:  0.663247, 0.367188 (0.648 sec)
315.15... logprob:  0.686391, 0.398438 (0.649 sec)
315.16... logprob:  0.627063, 0.320312 (0.649 sec)
315.17... logprob:  0.638516, 0.335938 (0.650 sec)
315.18... logprob:  0.638225, 0.335938 (0.649 sec)
315.19... logprob:  0.632739, 0.328125 (0.650 sec)
315.20... logprob:  0.648828, 0.351562 (0.650 sec)
315.21... logprob:  0.643413, 0.343750 (0.650 sec)
315.22... logprob:  0.628120, 0.320312 (0.649 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.683645, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.945932e-03 [6.722173e-09] 
Layer 'conv1' biases: 4.652204e-07 [1.312456e-10] 
Layer 'conv2' weights[0]: 7.933671e-03 [6.009444e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.830437e-10] 
Layer 'conv3' weights[0]: 7.931533e-03 [5.252915e-09] 
Layer 'conv3' biases: 3.912837e-06 [1.585883e-09] 
Layer 'conv4' weights[0]: 7.964216e-03 [5.148336e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.021116e-08] 
Layer 'conv5' weights[0]: 7.963581e-03 [5.940685e-08] 
Layer 'conv5' biases: 1.000002e+00 [6.301381e-08] 
Layer 'fc6' weights[0]: 7.559884e-03 [7.533731e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.410431e-09] 
Layer 'fc7' weights[0]: 7.525675e-03 [9.625732e-08] 
Layer 'fc7' biases: 9.998546e-01 [7.859273e-08] 
Layer 'fc8' weights[0]: 5.903062e-04 [4.250563e-06] 
Layer 'fc8' biases: 1.419320e-01 [7.494687e-05] 
Train error last 27 batches: 0.635877
-------------------------------------------------------
Not saving because 0.683645 > 0.627105 (256.15: -0.00%)
======================================================= (1.774 sec)
315.23... logprob:  0.623339, 0.312500 (0.649 sec)
315.24... logprob:  0.578446, 0.242188 (0.650 sec)
315.25... logprob:  0.628307, 0.320312 (0.651 sec)
315.26... logprob:  0.673855, 0.390625 (0.651 sec)
315.27... logprob:  0.628131, 0.320312 (0.650 sec)
316.1... logprob:  0.679298, 0.398438 (0.650 sec)
316.2... logprob:  0.597339, 0.273438 (0.650 sec)
316.3... logprob:  0.653736, 0.359375 (0.650 sec)
316.4... logprob:  0.596869, 0.273438 (0.651 sec)
316.5... logprob:  0.591075, 0.265625 (0.649 sec)
316.6... logprob:  0.611423, 0.296875 (0.650 sec)
316.7... logprob:  0.643846, 0.343750 (0.650 sec)
316.8... logprob:  0.604738, 0.289062 (0.649 sec)
316.9... logprob:  0.638595, 0.335938 (0.649 sec)
316.10... logprob:  0.597746, 0.281250 (0.649 sec)
316.11... logprob:  0.639014, 0.335938 (0.650 sec)
316.12... logprob:  0.718695, 0.437500 (0.652 sec)
316.13... logprob:  0.657628, 0.359375 (0.649 sec)
316.14... logprob:  0.663241, 0.367188 (0.650 sec)
316.15... logprob:  0.686385, 0.398438 (0.649 sec)
316.16... logprob:  0.627063, 0.320312 (0.650 sec)
316.17... logprob:  0.638516, 0.335938 (0.651 sec)
316.18... logprob:  0.638225, 0.335938 (0.651 sec)
316.19... logprob:  0.632738, 0.328125 (0.650 sec)
316.20... logprob:  0.648829, 0.351562 (0.651 sec)
316.21... logprob:  0.643413, 0.343750 (0.651 sec)
316.22... logprob:  0.628117, 0.320312 (0.650 sec)
316.23... logprob:  0.623334, 0.312500 (0.650 sec)
316.24... logprob:  0.578431, 0.242188 (0.733 sec)
316.25... logprob:  0.628304, 0.320312 (0.650 sec)
316.26... logprob:  0.673859, 0.390625 (0.651 sec)
316.27... logprob:  0.628129, 0.320312 (0.650 sec)
317.1... logprob:  0.679302, 0.398438 (0.650 sec)
317.2... logprob:  0.597335, 0.273438 (0.649 sec)
317.3... logprob:  0.653736, 0.359375 (0.651 sec)
317.4... logprob:  0.596866, 0.273438 (0.650 sec)
317.5... logprob:  0.591073, 0.265625 (0.650 sec)
317.6... logprob:  0.611424, 0.296875 (0.650 sec)
317.7... logprob:  0.643845, 0.343750 (0.650 sec)
317.8... logprob:  0.604741, 0.289062 (0.649 sec)
317.9... logprob:  0.638594, 0.335938 (0.650 sec)
317.10... logprob:  0.597752, 0.281250 (0.649 sec)
317.11... logprob:  0.639010, 0.335938 (0.650 sec)
317.12... logprob:  0.718668, 0.437500 (0.651 sec)
317.13... logprob:  0.657618, 0.359375 (0.650 sec)
317.14... logprob:  0.663233, 0.367188 (0.649 sec)
317.15... logprob:  0.686375, 0.398438 (0.650 sec)
317.16... logprob:  0.627064, 0.320312 (0.650 sec)
317.17... logprob:  0.638516, 0.335938 (0.652 sec)
317.18... logprob:  0.638225, 0.335938 (0.651 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.632907, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.945728e-03 [6.515864e-09] 
Layer 'conv1' biases: 4.684245e-07 [1.740354e-10] 
Layer 'conv2' weights[0]: 7.933486e-03 [6.806783e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.525639e-10] 
Layer 'conv3' weights[0]: 7.931335e-03 [6.006061e-09] 
Layer 'conv3' biases: 3.938015e-06 [2.350010e-09] 
Layer 'conv4' weights[0]: 7.964023e-03 [6.011274e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.739532e-08] 
Layer 'conv5' weights[0]: 7.963400e-03 [1.014252e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.078990e-07] 
Layer 'fc6' weights[0]: 7.559679e-03 [1.145202e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.085791e-08] 
Layer 'fc7' weights[0]: 7.523727e-03 [1.453084e-07] 
Layer 'fc7' biases: 9.998549e-01 [1.314969e-07] 
Layer 'fc8' weights[0]: 6.092599e-04 [7.207821e-06] 
Layer 'fc8' biases: 1.430831e-01 [1.306172e-04] 
Train error last 27 batches: 0.635872
-------------------------------------------------------
Not saving because 0.632907 > 0.627105 (256.15: -0.00%)
======================================================= (1.757 sec)
317.19... logprob:  0.632738, 0.328125 (0.651 sec)
317.20... logprob:  0.648831, 0.351562 (0.650 sec)
317.21... logprob:  0.643414, 0.343750 (0.651 sec)
317.22... logprob:  0.628113, 0.320312 (0.650 sec)
317.23... logprob:  0.623328, 0.312500 (0.649 sec)
317.24... logprob:  0.578410, 0.242188 (0.650 sec)
317.25... logprob:  0.628300, 0.320312 (0.651 sec)
317.26... logprob:  0.673867, 0.390625 (0.650 sec)
317.27... logprob:  0.628126, 0.320312 (0.650 sec)
318.1... logprob:  0.679309, 0.398438 (0.650 sec)
318.2... logprob:  0.597327, 0.273438 (0.650 sec)
318.3... logprob:  0.653738, 0.359375 (0.649 sec)
318.4... logprob:  0.596863, 0.273438 (0.650 sec)
318.5... logprob:  0.591071, 0.265625 (0.650 sec)
318.6... logprob:  0.611425, 0.296875 (0.650 sec)
318.7... logprob:  0.643844, 0.343750 (0.650 sec)
318.8... logprob:  0.604746, 0.289062 (0.650 sec)
318.9... logprob:  0.638592, 0.335938 (0.649 sec)
318.10... logprob:  0.597759, 0.281250 (0.650 sec)
318.11... logprob:  0.639006, 0.335938 (0.650 sec)
318.12... logprob:  0.718639, 0.437500 (0.651 sec)
318.13... logprob:  0.657608, 0.359375 (0.650 sec)
318.14... logprob:  0.663223, 0.367188 (0.649 sec)
318.15... logprob:  0.686363, 0.398438 (0.649 sec)
318.16... logprob:  0.627064, 0.320312 (0.650 sec)
318.17... logprob:  0.638516, 0.335938 (0.651 sec)
318.18... logprob:  0.638225, 0.335938 (0.651 sec)
318.19... logprob:  0.632737, 0.328125 (0.650 sec)
318.20... logprob:  0.648832, 0.351562 (0.651 sec)
318.21... logprob:  0.643414, 0.343750 (0.651 sec)
318.22... logprob:  0.628111, 0.320312 (0.650 sec)
318.23... logprob:  0.623323, 0.312500 (0.649 sec)
318.24... logprob:  0.578395, 0.242188 (0.650 sec)
318.25... logprob:  0.628296, 0.320312 (0.650 sec)
318.26... logprob:  0.673873, 0.390625 (0.651 sec)
318.27... logprob:  0.628123, 0.320312 (0.650 sec)
319.1... logprob:  0.679315, 0.398438 (0.650 sec)
319.2... logprob:  0.597319, 0.273438 (0.650 sec)
319.3... logprob:  0.653740, 0.359375 (0.650 sec)
319.4... logprob:  0.596856, 0.273438 (0.650 sec)
319.5... logprob:  0.591066, 0.265625 (0.650 sec)
319.6... logprob:  0.611423, 0.296875 (0.650 sec)
319.7... logprob:  0.643844, 0.343750 (0.651 sec)
319.8... logprob:  0.604747, 0.289062 (0.649 sec)
319.9... logprob:  0.638591, 0.335938 (0.650 sec)
319.10... logprob:  0.597763, 0.281250 (0.649 sec)
319.11... logprob:  0.639003, 0.335938 (0.650 sec)
319.12... logprob:  0.718619, 0.437500 (0.651 sec)
319.13... logprob:  0.657602, 0.359375 (0.650 sec)
319.14... logprob:  0.663216, 0.367188 (0.649 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627136, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.945529e-03 [6.760249e-09] 
Layer 'conv1' biases: 4.715495e-07 [1.526651e-10] 
Layer 'conv2' weights[0]: 7.933296e-03 [6.306860e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.949307e-10] 
Layer 'conv3' weights[0]: 7.931142e-03 [5.524985e-09] 
Layer 'conv3' biases: 3.962071e-06 [1.945874e-09] 
Layer 'conv4' weights[0]: 7.963837e-03 [5.502266e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.334671e-08] 
Layer 'conv5' weights[0]: 7.963201e-03 [7.765611e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.279208e-08] 
Layer 'fc6' weights[0]: 7.559484e-03 [9.293530e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.326328e-09] 
Layer 'fc7' weights[0]: 7.521802e-03 [1.177562e-07] 
Layer 'fc7' biases: 9.998552e-01 [1.005201e-07] 
Layer 'fc8' weights[0]: 6.368391e-04 [5.527642e-06] 
Layer 'fc8' biases: 1.443989e-01 [9.306803e-05] 
Train error last 27 batches: 0.635866
-------------------------------------------------------
Not saving because 0.627136 > 0.627105 (256.15: -0.00%)
======================================================= (1.763 sec)
319.15... logprob:  0.686355, 0.398438 (0.650 sec)
319.16... logprob:  0.627064, 0.320312 (0.650 sec)
319.17... logprob:  0.638516, 0.335938 (0.653 sec)
319.18... logprob:  0.638225, 0.335938 (0.654 sec)
319.19... logprob:  0.632736, 0.328125 (0.655 sec)
319.20... logprob:  0.648833, 0.351562 (0.653 sec)
319.21... logprob:  0.643414, 0.343750 (0.655 sec)
319.22... logprob:  0.628107, 0.320312 (0.653 sec)
319.23... logprob:  0.623318, 0.312500 (0.652 sec)
319.24... logprob:  0.578378, 0.242188 (0.653 sec)
319.25... logprob:  0.628293, 0.320312 (0.654 sec)
319.26... logprob:  0.673879, 0.390625 (0.653 sec)
319.27... logprob:  0.628121, 0.320312 (0.654 sec)
320.1... logprob:  0.679320, 0.398438 (0.652 sec)
320.2... logprob:  0.597314, 0.273438 (0.650 sec)
320.3... logprob:  0.653741, 0.359375 (0.649 sec)
320.4... logprob:  0.596854, 0.273438 (0.650 sec)
320.5... logprob:  0.591067, 0.265625 (0.650 sec)
320.6... logprob:  0.611425, 0.296875 (0.650 sec)
320.7... logprob:  0.643843, 0.343750 (0.649 sec)
320.8... logprob:  0.604751, 0.289062 (0.650 sec)
320.9... logprob:  0.638590, 0.335938 (0.650 sec)
320.10... logprob:  0.597770, 0.281250 (0.649 sec)
320.11... logprob:  0.638999, 0.335938 (0.650 sec)
320.12... logprob:  0.718591, 0.437500 (0.651 sec)
320.13... logprob:  0.657592, 0.359375 (0.650 sec)
320.14... logprob:  0.663207, 0.367188 (0.650 sec)
320.15... logprob:  0.686345, 0.398438 (0.649 sec)
320.16... logprob:  0.627064, 0.320312 (0.650 sec)
320.17... logprob:  0.638515, 0.335938 (0.652 sec)
320.18... logprob:  0.638225, 0.335938 (0.651 sec)
320.19... logprob:  0.632736, 0.328125 (0.651 sec)
320.20... logprob:  0.648834, 0.351562 (0.650 sec)
320.21... logprob:  0.643414, 0.343750 (0.651 sec)
320.22... logprob:  0.628105, 0.320312 (0.650 sec)
320.23... logprob:  0.623313, 0.312500 (0.650 sec)
320.24... logprob:  0.578362, 0.242188 (0.650 sec)
320.25... logprob:  0.628289, 0.320312 (0.650 sec)
320.26... logprob:  0.673885, 0.390625 (0.651 sec)
320.27... logprob:  0.628117, 0.320312 (0.649 sec)
321.1... logprob:  0.679327, 0.398438 (0.652 sec)
321.2... logprob:  0.597305, 0.273438 (0.650 sec)
321.3... logprob:  0.653742, 0.359375 (0.650 sec)
321.4... logprob:  0.596848, 0.273438 (0.650 sec)
321.5... logprob:  0.591062, 0.265625 (0.650 sec)
321.6... logprob:  0.611424, 0.296875 (0.650 sec)
321.7... logprob:  0.643843, 0.343750 (0.650 sec)
321.8... logprob:  0.604752, 0.289062 (0.649 sec)
321.9... logprob:  0.638589, 0.335938 (0.654 sec)
321.10... logprob:  0.597774, 0.281250 (0.652 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.657003, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.945336e-03 [7.040990e-09] 
Layer 'conv1' biases: 4.748913e-07 [1.428351e-10] 
Layer 'conv2' weights[0]: 7.933109e-03 [6.216353e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.347077e-10] 
Layer 'conv3' weights[0]: 7.930954e-03 [6.069804e-09] 
Layer 'conv3' biases: 3.988949e-06 [2.215452e-09] 
Layer 'conv4' weights[0]: 7.963665e-03 [6.259936e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.957128e-08] 
Layer 'conv5' weights[0]: 7.963000e-03 [1.142159e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.217368e-07] 
Layer 'fc6' weights[0]: 7.559286e-03 [1.264694e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.213449e-08] 
Layer 'fc7' weights[0]: 7.519872e-03 [1.583266e-07] 
Layer 'fc7' biases: 9.998553e-01 [1.447512e-07] 
Layer 'fc8' weights[0]: 6.389598e-04 [7.987163e-06] 
Layer 'fc8' biases: 1.451396e-01 [1.711411e-04] 
Train error last 27 batches: 0.635861
-------------------------------------------------------
Not saving because 0.657003 > 0.627105 (256.15: -0.00%)
======================================================= (1.767 sec)
321.11... logprob:  0.638996, 0.335938 (0.653 sec)
321.12... logprob:  0.718572, 0.437500 (0.653 sec)
321.13... logprob:  0.657586, 0.359375 (0.653 sec)
321.14... logprob:  0.663201, 0.367188 (0.653 sec)
321.15... logprob:  0.686337, 0.398438 (0.653 sec)
321.16... logprob:  0.627064, 0.320312 (0.653 sec)
321.17... logprob:  0.638516, 0.335938 (0.653 sec)
321.18... logprob:  0.638224, 0.335938 (0.651 sec)
321.19... logprob:  0.632735, 0.328125 (0.651 sec)
321.20... logprob:  0.648836, 0.351562 (0.650 sec)
321.21... logprob:  0.643416, 0.343750 (0.651 sec)
321.22... logprob:  0.628100, 0.320312 (0.649 sec)
321.23... logprob:  0.623308, 0.312500 (0.650 sec)
321.24... logprob:  0.578344, 0.242188 (0.649 sec)
321.25... logprob:  0.628285, 0.320312 (0.651 sec)
321.26... logprob:  0.673890, 0.390625 (0.650 sec)
321.27... logprob:  0.628115, 0.320312 (0.650 sec)
322.1... logprob:  0.679331, 0.398438 (0.650 sec)
322.2... logprob:  0.597301, 0.273438 (0.650 sec)
322.3... logprob:  0.653743, 0.359375 (0.650 sec)
322.4... logprob:  0.596846, 0.273438 (0.650 sec)
322.5... logprob:  0.591063, 0.265625 (0.649 sec)
322.6... logprob:  0.611425, 0.296875 (0.652 sec)
322.7... logprob:  0.643842, 0.343750 (0.650 sec)
322.8... logprob:  0.604757, 0.289062 (0.649 sec)
322.9... logprob:  0.638587, 0.335938 (0.650 sec)
322.10... logprob:  0.597782, 0.281250 (0.650 sec)
322.11... logprob:  0.638991, 0.335938 (0.650 sec)
322.12... logprob:  0.718542, 0.437500 (0.651 sec)
322.13... logprob:  0.657576, 0.359375 (0.650 sec)
322.14... logprob:  0.663190, 0.367188 (0.650 sec)
322.15... logprob:  0.686325, 0.398438 (0.649 sec)
322.16... logprob:  0.627064, 0.320312 (0.650 sec)
322.17... logprob:  0.638515, 0.335938 (0.651 sec)
322.18... logprob:  0.638224, 0.335938 (0.651 sec)
322.19... logprob:  0.632735, 0.328125 (0.650 sec)
322.20... logprob:  0.648836, 0.351562 (0.651 sec)
322.21... logprob:  0.643415, 0.343750 (0.651 sec)
322.22... logprob:  0.628098, 0.320312 (0.650 sec)
322.23... logprob:  0.623303, 0.312500 (0.650 sec)
322.24... logprob:  0.578328, 0.242188 (0.651 sec)
322.25... logprob:  0.628281, 0.320312 (0.651 sec)
322.26... logprob:  0.673896, 0.390625 (0.651 sec)
322.27... logprob:  0.628111, 0.320312 (0.650 sec)
323.1... logprob:  0.679337, 0.398438 (0.650 sec)
323.2... logprob:  0.597292, 0.273438 (0.650 sec)
323.3... logprob:  0.653744, 0.359375 (0.650 sec)
323.4... logprob:  0.596840, 0.273438 (0.649 sec)
323.5... logprob:  0.591057, 0.265625 (0.650 sec)
323.6... logprob:  0.611423, 0.296875 (0.650 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627358, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.945144e-03 [7.367290e-09] 
Layer 'conv1' biases: 4.785105e-07 [1.657422e-10] 
Layer 'conv2' weights[0]: 7.932932e-03 [6.301138e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.783136e-10] 
Layer 'conv3' weights[0]: 7.930756e-03 [6.100903e-09] 
Layer 'conv3' biases: 4.019220e-06 [2.257928e-09] 
Layer 'conv4' weights[0]: 7.963480e-03 [6.216224e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.997767e-08] 
Layer 'conv5' weights[0]: 7.962825e-03 [1.163631e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.239256e-07] 
Layer 'fc6' weights[0]: 7.559069e-03 [1.294771e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.244735e-08] 
Layer 'fc7' weights[0]: 7.517970e-03 [1.630590e-07] 
Layer 'fc7' biases: 9.998549e-01 [1.498124e-07] 
Layer 'fc8' weights[0]: 6.121716e-04 [8.154891e-06] 
Layer 'fc8' biases: 1.452287e-01 [1.814313e-04] 
Train error last 27 batches: 0.635855
-------------------------------------------------------
Not saving because 0.627358 > 0.627105 (256.15: -0.00%)
======================================================= (1.746 sec)
323.7... logprob:  0.643841, 0.343750 (0.650 sec)
323.8... logprob:  0.604758, 0.289062 (0.650 sec)
323.9... logprob:  0.638586, 0.335938 (0.650 sec)
323.10... logprob:  0.597785, 0.281250 (0.649 sec)
323.11... logprob:  0.638989, 0.335938 (0.650 sec)
323.12... logprob:  0.718525, 0.437500 (0.651 sec)
323.13... logprob:  0.657570, 0.359375 (0.650 sec)
323.14... logprob:  0.663185, 0.367188 (0.649 sec)
323.15... logprob:  0.686319, 0.398438 (0.650 sec)
323.16... logprob:  0.627065, 0.320312 (0.650 sec)
323.17... logprob:  0.638515, 0.335938 (0.652 sec)
323.18... logprob:  0.638225, 0.335938 (0.650 sec)
323.19... logprob:  0.632734, 0.328125 (0.651 sec)
323.20... logprob:  0.648838, 0.351562 (0.650 sec)
323.21... logprob:  0.643416, 0.343750 (0.652 sec)
323.22... logprob:  0.628094, 0.320312 (0.650 sec)
323.23... logprob:  0.623298, 0.312500 (0.650 sec)
323.24... logprob:  0.578309, 0.242188 (0.650 sec)
323.25... logprob:  0.628278, 0.320312 (0.652 sec)
323.26... logprob:  0.673903, 0.390625 (0.651 sec)
323.27... logprob:  0.628109, 0.320312 (0.651 sec)
324.1... logprob:  0.679342, 0.398438 (0.650 sec)
324.2... logprob:  0.597287, 0.273438 (0.653 sec)
324.3... logprob:  0.653745, 0.359375 (0.649 sec)
324.4... logprob:  0.596838, 0.273438 (0.650 sec)
324.5... logprob:  0.591057, 0.265625 (0.649 sec)
324.6... logprob:  0.611426, 0.296875 (0.650 sec)
324.7... logprob:  0.643841, 0.343750 (0.650 sec)
324.8... logprob:  0.604763, 0.289062 (0.649 sec)
324.9... logprob:  0.638583, 0.335938 (0.649 sec)
324.10... logprob:  0.597794, 0.281250 (0.650 sec)
324.11... logprob:  0.638984, 0.335938 (0.649 sec)
324.12... logprob:  0.718490, 0.437500 (0.651 sec)
324.13... logprob:  0.657558, 0.359375 (0.651 sec)
324.14... logprob:  0.663173, 0.367188 (0.650 sec)
324.15... logprob:  0.686305, 0.398438 (0.650 sec)
324.16... logprob:  0.627065, 0.320312 (0.650 sec)
324.17... logprob:  0.638515, 0.335938 (0.651 sec)
324.18... logprob:  0.638225, 0.335938 (0.651 sec)
324.19... logprob:  0.632733, 0.328125 (0.651 sec)
324.20... logprob:  0.648839, 0.351562 (0.653 sec)
324.21... logprob:  0.643416, 0.343750 (0.651 sec)
324.22... logprob:  0.628091, 0.320312 (0.650 sec)
324.23... logprob:  0.623292, 0.312500 (0.649 sec)
324.24... logprob:  0.578292, 0.242188 (0.651 sec)
324.25... logprob:  0.628273, 0.320312 (0.650 sec)
324.26... logprob:  0.673909, 0.390625 (0.651 sec)
324.27... logprob:  0.628106, 0.320312 (0.650 sec)
325.1... logprob:  0.679350, 0.398438 (0.651 sec)
325.2... logprob:  0.597278, 0.273438 (0.649 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633129, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.944964e-03 [6.809223e-09] 
Layer 'conv1' biases: 4.821067e-07 [7.061421e-11] 
Layer 'conv2' weights[0]: 7.932736e-03 [4.973548e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.977095e-10] 
Layer 'conv3' weights[0]: 7.930560e-03 [4.573327e-09] 
Layer 'conv3' biases: 4.048467e-06 [8.352545e-10] 
Layer 'conv4' weights[0]: 7.963295e-03 [4.496614e-09] 
Layer 'conv4' biases: 1.000001e+00 [5.303352e-09] 
Layer 'conv5' weights[0]: 7.962639e-03 [3.157440e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.335239e-08] 
Layer 'fc6' weights[0]: 7.558871e-03 [5.140217e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.302738e-09] 
Layer 'fc7' weights[0]: 7.516073e-03 [6.210483e-08] 
Layer 'fc7' biases: 9.998544e-01 [3.970647e-08] 
Layer 'fc8' weights[0]: 5.936773e-04 [2.141610e-06] 
Layer 'fc8' biases: 1.454906e-01 [5.622916e-05] 
Train error last 27 batches: 0.635850
-------------------------------------------------------
Not saving because 0.633129 > 0.627105 (256.15: -0.00%)
======================================================= (1.818 sec)
325.3... logprob:  0.653747, 0.359375 (0.650 sec)
325.4... logprob:  0.596831, 0.273438 (0.649 sec)
325.5... logprob:  0.591052, 0.265625 (0.650 sec)
325.6... logprob:  0.611424, 0.296875 (0.650 sec)
325.7... logprob:  0.643841, 0.343750 (0.650 sec)
325.8... logprob:  0.604764, 0.289062 (0.649 sec)
325.9... logprob:  0.638583, 0.335938 (0.652 sec)
325.10... logprob:  0.597798, 0.281250 (0.649 sec)
325.11... logprob:  0.638982, 0.335938 (0.650 sec)
325.12... logprob:  0.718472, 0.437500 (0.651 sec)
325.13... logprob:  0.657552, 0.359375 (0.650 sec)
325.14... logprob:  0.663168, 0.367188 (0.649 sec)
325.15... logprob:  0.686298, 0.398438 (0.649 sec)
325.16... logprob:  0.627064, 0.320312 (0.650 sec)
325.17... logprob:  0.638515, 0.335938 (0.651 sec)
325.18... logprob:  0.638225, 0.335938 (0.651 sec)
325.19... logprob:  0.632733, 0.328125 (0.651 sec)
325.20... logprob:  0.648840, 0.351562 (0.650 sec)
325.21... logprob:  0.643417, 0.343750 (0.651 sec)
325.22... logprob:  0.628088, 0.320312 (0.649 sec)
325.23... logprob:  0.623287, 0.312500 (0.650 sec)
325.24... logprob:  0.578276, 0.242188 (0.650 sec)
325.25... logprob:  0.628270, 0.320312 (0.651 sec)
325.26... logprob:  0.673915, 0.390625 (0.651 sec)
325.27... logprob:  0.628103, 0.320312 (0.651 sec)
326.1... logprob:  0.679355, 0.398438 (0.649 sec)
326.2... logprob:  0.597272, 0.273438 (0.651 sec)
326.3... logprob:  0.653749, 0.359375 (0.650 sec)
326.4... logprob:  0.596828, 0.273438 (0.650 sec)
326.5... logprob:  0.591051, 0.265625 (0.650 sec)
326.6... logprob:  0.611425, 0.296875 (0.650 sec)
326.7... logprob:  0.643840, 0.343750 (0.650 sec)
326.8... logprob:  0.604769, 0.289062 (0.650 sec)
326.9... logprob:  0.638581, 0.335938 (0.649 sec)
326.10... logprob:  0.597804, 0.281250 (0.650 sec)
326.11... logprob:  0.638978, 0.335938 (0.649 sec)
326.12... logprob:  0.718444, 0.437500 (0.650 sec)
326.13... logprob:  0.657543, 0.359375 (0.650 sec)
326.14... logprob:  0.663158, 0.367188 (0.650 sec)
326.15... logprob:  0.686288, 0.398438 (0.649 sec)
326.16... logprob:  0.627065, 0.320312 (0.650 sec)
326.17... logprob:  0.638515, 0.335938 (0.651 sec)
326.18... logprob:  0.638225, 0.335938 (0.651 sec)
326.19... logprob:  0.632733, 0.328125 (0.651 sec)
326.20... logprob:  0.648842, 0.351562 (0.651 sec)
326.21... logprob:  0.643417, 0.343750 (0.651 sec)
326.22... logprob:  0.628084, 0.320312 (0.650 sec)
326.23... logprob:  0.623282, 0.312500 (0.649 sec)
326.24... logprob:  0.578256, 0.242188 (0.650 sec)
326.25... logprob:  0.628266, 0.320312 (0.651 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.684187, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.944761e-03 [6.602268e-09] 
Layer 'conv1' biases: 4.855522e-07 [6.909552e-11] 
Layer 'conv2' weights[0]: 7.932553e-03 [4.932863e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.629159e-10] 
Layer 'conv3' weights[0]: 7.930357e-03 [4.665758e-09] 
Layer 'conv3' biases: 4.076155e-06 [1.034315e-09] 
Layer 'conv4' weights[0]: 7.963097e-03 [4.668017e-09] 
Layer 'conv4' biases: 1.000001e+00 [8.174532e-09] 
Layer 'conv5' weights[0]: 7.962453e-03 [4.735007e-08] 
Layer 'conv5' biases: 1.000002e+00 [5.025678e-08] 
Layer 'fc6' weights[0]: 7.558678e-03 [6.420912e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.063632e-09] 
Layer 'fc7' weights[0]: 7.514133e-03 [8.053430e-08] 
Layer 'fc7' biases: 9.998542e-01 [6.135063e-08] 
Layer 'fc8' weights[0]: 5.899532e-04 [3.278035e-06] 
Layer 'fc8' biases: 1.460982e-01 [8.658256e-05] 
Train error last 27 batches: 0.635844
-------------------------------------------------------
Not saving because 0.684187 > 0.627105 (256.15: -0.00%)
======================================================= (1.791 sec)
326.26... logprob:  0.673923, 0.390625 (0.651 sec)
326.27... logprob:  0.628100, 0.320312 (0.732 sec)
327.1... logprob:  0.679362, 0.398438 (0.651 sec)
327.2... logprob:  0.597265, 0.273438 (0.649 sec)
327.3... logprob:  0.653750, 0.359375 (0.650 sec)
327.4... logprob:  0.596824, 0.273438 (0.650 sec)
327.5... logprob:  0.591049, 0.265625 (0.650 sec)
327.6... logprob:  0.611425, 0.296875 (0.652 sec)
327.7... logprob:  0.643839, 0.343750 (0.650 sec)
327.8... logprob:  0.604772, 0.289062 (0.649 sec)
327.9... logprob:  0.638579, 0.335938 (0.650 sec)
327.10... logprob:  0.597811, 0.281250 (0.650 sec)
327.11... logprob:  0.638974, 0.335938 (0.650 sec)
327.12... logprob:  0.718416, 0.437500 (0.650 sec)
327.13... logprob:  0.657533, 0.359375 (0.650 sec)
327.14... logprob:  0.663149, 0.367188 (0.649 sec)
327.15... logprob:  0.686276, 0.398438 (0.650 sec)
327.16... logprob:  0.627065, 0.320312 (0.650 sec)
327.17... logprob:  0.638514, 0.335938 (0.652 sec)
327.18... logprob:  0.638224, 0.335938 (0.651 sec)
327.19... logprob:  0.632732, 0.328125 (0.652 sec)
327.20... logprob:  0.648843, 0.351562 (0.650 sec)
327.21... logprob:  0.643418, 0.343750 (0.652 sec)
327.22... logprob:  0.628081, 0.320312 (0.650 sec)
327.23... logprob:  0.623278, 0.312500 (0.650 sec)
327.24... logprob:  0.578241, 0.242188 (0.651 sec)
327.25... logprob:  0.628262, 0.320312 (0.652 sec)
327.26... logprob:  0.673928, 0.390625 (0.650 sec)
327.27... logprob:  0.628097, 0.320312 (0.650 sec)
328.1... logprob:  0.679368, 0.398438 (0.650 sec)
328.2... logprob:  0.597257, 0.273438 (0.650 sec)
328.3... logprob:  0.653752, 0.359375 (0.650 sec)
328.4... logprob:  0.596818, 0.273438 (0.650 sec)
328.5... logprob:  0.591044, 0.265625 (0.650 sec)
328.6... logprob:  0.611423, 0.296875 (0.650 sec)
328.7... logprob:  0.643839, 0.343750 (0.650 sec)
328.8... logprob:  0.604773, 0.289062 (0.650 sec)
328.9... logprob:  0.638579, 0.335938 (0.650 sec)
328.10... logprob:  0.597815, 0.281250 (0.649 sec)
328.11... logprob:  0.638972, 0.335938 (0.650 sec)
328.12... logprob:  0.718398, 0.437500 (0.651 sec)
328.13... logprob:  0.657527, 0.359375 (0.650 sec)
328.14... logprob:  0.663143, 0.367188 (0.650 sec)
328.15... logprob:  0.686270, 0.398438 (0.650 sec)
328.16... logprob:  0.627065, 0.320312 (0.650 sec)
328.17... logprob:  0.638515, 0.335938 (0.651 sec)
328.18... logprob:  0.638225, 0.335938 (0.651 sec)
328.19... logprob:  0.632731, 0.328125 (0.650 sec)
328.20... logprob:  0.648845, 0.351562 (0.651 sec)
328.21... logprob:  0.643417, 0.343750 (0.651 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633259, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.944559e-03 [6.847312e-09] 
Layer 'conv1' biases: 4.889429e-07 [1.522186e-10] 
Layer 'conv2' weights[0]: 7.932357e-03 [6.477715e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.323484e-10] 
Layer 'conv3' weights[0]: 7.930153e-03 [5.670519e-09] 
Layer 'conv3' biases: 4.103754e-06 [2.018034e-09] 
Layer 'conv4' weights[0]: 7.962897e-03 [5.594007e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.392971e-08] 
Layer 'conv5' weights[0]: 7.962258e-03 [8.081991e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.565406e-08] 
Layer 'fc6' weights[0]: 7.558477e-03 [9.689121e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.728894e-09] 
Layer 'fc7' weights[0]: 7.512209e-03 [1.222414e-07] 
Layer 'fc7' biases: 9.998543e-01 [1.059301e-07] 
Layer 'fc8' weights[0]: 5.900713e-04 [5.714248e-06] 
Layer 'fc8' biases: 1.467799e-01 [1.076024e-04] 
Train error last 27 batches: 0.635839
-------------------------------------------------------
Not saving because 0.633259 > 0.627105 (256.15: -0.00%)
======================================================= (1.758 sec)
328.22... logprob:  0.628078, 0.320312 (0.650 sec)
328.23... logprob:  0.623272, 0.312500 (0.649 sec)
328.24... logprob:  0.578222, 0.242188 (0.650 sec)
328.25... logprob:  0.628259, 0.320312 (0.651 sec)
328.26... logprob:  0.673935, 0.390625 (0.651 sec)
328.27... logprob:  0.628095, 0.320312 (0.650 sec)
329.1... logprob:  0.679374, 0.398438 (0.650 sec)
329.2... logprob:  0.597252, 0.273438 (0.650 sec)
329.3... logprob:  0.653752, 0.359375 (0.651 sec)
329.4... logprob:  0.596816, 0.273438 (0.650 sec)
329.5... logprob:  0.591044, 0.265625 (0.650 sec)
329.6... logprob:  0.611426, 0.296875 (0.649 sec)
329.7... logprob:  0.643838, 0.343750 (0.650 sec)
329.8... logprob:  0.604780, 0.289062 (0.650 sec)
329.9... logprob:  0.638577, 0.335938 (0.650 sec)
329.10... logprob:  0.597824, 0.281250 (0.650 sec)
329.11... logprob:  0.638966, 0.335938 (0.650 sec)
329.12... logprob:  0.718363, 0.437500 (0.650 sec)
329.13... logprob:  0.657515, 0.359375 (0.650 sec)
329.14... logprob:  0.663131, 0.367188 (0.650 sec)
329.15... logprob:  0.686254, 0.398438 (0.650 sec)
329.16... logprob:  0.627065, 0.320312 (0.651 sec)
329.17... logprob:  0.638514, 0.335938 (0.652 sec)
329.18... logprob:  0.638224, 0.335938 (0.651 sec)
329.19... logprob:  0.632731, 0.328125 (0.651 sec)
329.20... logprob:  0.648845, 0.351562 (0.650 sec)
329.21... logprob:  0.643419, 0.343750 (0.652 sec)
329.22... logprob:  0.628075, 0.320312 (0.650 sec)
329.23... logprob:  0.623268, 0.312500 (0.650 sec)
329.24... logprob:  0.578208, 0.242188 (0.650 sec)
329.25... logprob:  0.628255, 0.320312 (0.651 sec)
329.26... logprob:  0.673940, 0.390625 (0.651 sec)
329.27... logprob:  0.628092, 0.320312 (0.651 sec)
330.1... logprob:  0.679380, 0.398438 (0.650 sec)
330.2... logprob:  0.597243, 0.273438 (0.650 sec)
330.3... logprob:  0.653754, 0.359375 (0.649 sec)
330.4... logprob:  0.596809, 0.273438 (0.650 sec)
330.5... logprob:  0.591038, 0.265625 (0.649 sec)
330.6... logprob:  0.611423, 0.296875 (0.653 sec)
330.7... logprob:  0.643838, 0.343750 (0.650 sec)
330.8... logprob:  0.604778, 0.289062 (0.650 sec)
330.9... logprob:  0.638576, 0.335938 (0.649 sec)
330.10... logprob:  0.597825, 0.281250 (0.650 sec)
330.11... logprob:  0.638965, 0.335938 (0.650 sec)
330.12... logprob:  0.718353, 0.437500 (0.651 sec)
330.13... logprob:  0.657512, 0.359375 (0.650 sec)
330.14... logprob:  0.663127, 0.367188 (0.649 sec)
330.15... logprob:  0.686251, 0.398438 (0.650 sec)
330.16... logprob:  0.627065, 0.320312 (0.653 sec)
330.17... logprob:  0.638514, 0.335938 (0.651 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627361, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.944372e-03 [6.446758e-09] 
Layer 'conv1' biases: 4.921565e-07 [1.719150e-10] 
Layer 'conv2' weights[0]: 7.932171e-03 [6.936955e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.857987e-10] 
Layer 'conv3' weights[0]: 7.929948e-03 [6.107536e-09] 
Layer 'conv3' biases: 4.128711e-06 [2.423610e-09] 
Layer 'conv4' weights[0]: 7.962704e-03 [6.160168e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.832942e-08] 
Layer 'conv5' weights[0]: 7.962035e-03 [1.063868e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.130860e-07] 
Layer 'fc6' weights[0]: 7.558288e-03 [1.196424e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.142535e-08] 
Layer 'fc7' weights[0]: 7.510322e-03 [1.502134e-07] 
Layer 'fc7' biases: 9.998546e-01 [1.367792e-07] 
Layer 'fc8' weights[0]: 6.110880e-04 [7.464110e-06] 
Layer 'fc8' biases: 1.479668e-01 [1.375392e-04] 
Train error last 27 batches: 0.635834
-------------------------------------------------------
Not saving because 0.627361 > 0.627105 (256.15: -0.00%)
======================================================= (1.746 sec)
330.18... logprob:  0.638224, 0.335938 (0.651 sec)
330.19... logprob:  0.632730, 0.328125 (0.650 sec)
330.20... logprob:  0.648846, 0.351562 (0.651 sec)
330.21... logprob:  0.643418, 0.343750 (0.651 sec)
330.22... logprob:  0.628073, 0.320312 (0.650 sec)
330.23... logprob:  0.623264, 0.312500 (0.649 sec)
330.24... logprob:  0.578196, 0.242188 (0.650 sec)
330.25... logprob:  0.628253, 0.320312 (0.650 sec)
330.26... logprob:  0.673945, 0.390625 (0.651 sec)
330.27... logprob:  0.628090, 0.320312 (0.650 sec)
331.1... logprob:  0.679383, 0.398438 (0.650 sec)
331.2... logprob:  0.597239, 0.273438 (0.650 sec)
331.3... logprob:  0.653755, 0.359375 (0.650 sec)
331.4... logprob:  0.596807, 0.273438 (0.649 sec)
331.5... logprob:  0.591037, 0.265625 (0.651 sec)
331.6... logprob:  0.611424, 0.296875 (0.650 sec)
331.7... logprob:  0.643837, 0.343750 (0.650 sec)
331.8... logprob:  0.604782, 0.289062 (0.650 sec)
331.9... logprob:  0.638574, 0.335938 (0.650 sec)
331.10... logprob:  0.597831, 0.281250 (0.652 sec)
331.11... logprob:  0.638961, 0.335938 (0.651 sec)
331.12... logprob:  0.718328, 0.437500 (0.651 sec)
331.13... logprob:  0.657504, 0.359375 (0.651 sec)
331.14... logprob:  0.663120, 0.367188 (0.649 sec)
331.15... logprob:  0.686242, 0.398438 (0.650 sec)
331.16... logprob:  0.627066, 0.320312 (0.650 sec)
331.17... logprob:  0.638514, 0.335938 (0.652 sec)
331.18... logprob:  0.638224, 0.335938 (0.651 sec)
331.19... logprob:  0.632730, 0.328125 (0.651 sec)
331.20... logprob:  0.648848, 0.351562 (0.650 sec)
331.21... logprob:  0.643419, 0.343750 (0.652 sec)
331.22... logprob:  0.628069, 0.320312 (0.649 sec)
331.23... logprob:  0.623258, 0.312500 (0.650 sec)
331.24... logprob:  0.578178, 0.242188 (0.650 sec)
331.25... logprob:  0.628248, 0.320312 (0.651 sec)
331.26... logprob:  0.673951, 0.390625 (0.651 sec)
331.27... logprob:  0.628087, 0.320312 (0.650 sec)
332.1... logprob:  0.679389, 0.398438 (0.650 sec)
332.2... logprob:  0.597232, 0.273438 (0.650 sec)
332.3... logprob:  0.653756, 0.359375 (0.649 sec)
332.4... logprob:  0.596803, 0.273438 (0.651 sec)
332.5... logprob:  0.591035, 0.265625 (0.650 sec)
332.6... logprob:  0.611424, 0.296875 (0.650 sec)
332.7... logprob:  0.643836, 0.343750 (0.650 sec)
332.8... logprob:  0.604785, 0.289062 (0.650 sec)
332.9... logprob:  0.638573, 0.335938 (0.649 sec)
332.10... logprob:  0.597837, 0.281250 (0.650 sec)
332.11... logprob:  0.638958, 0.335938 (0.650 sec)
332.12... logprob:  0.718304, 0.437500 (0.651 sec)
332.13... logprob:  0.657496, 0.359375 (0.651 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.657145, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.944181e-03 [6.543649e-09] 
Layer 'conv1' biases: 4.953257e-07 [1.010350e-10] 
Layer 'conv2' weights[0]: 7.931970e-03 [5.479288e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.746454e-10] 
Layer 'conv3' weights[0]: 7.929745e-03 [4.813888e-09] 
Layer 'conv3' biases: 4.153307e-06 [1.296622e-09] 
Layer 'conv4' weights[0]: 7.962508e-03 [4.727689e-09] 
Layer 'conv4' biases: 1.000001e+00 [7.369337e-09] 
Layer 'conv5' weights[0]: 7.961865e-03 [4.286928e-08] 
Layer 'conv5' biases: 1.000002e+00 [4.551462e-08] 
Layer 'fc6' weights[0]: 7.558088e-03 [6.017386e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.607010e-09] 
Layer 'fc7' weights[0]: 7.508388e-03 [7.551651e-08] 
Layer 'fc7' biases: 9.998549e-01 [5.587381e-08] 
Layer 'fc8' weights[0]: 6.363250e-04 [3.028232e-06] 
Layer 'fc8' biases: 1.492216e-01 [4.518393e-05] 
Train error last 27 batches: 0.635829
-------------------------------------------------------
Not saving because 0.657145 > 0.627105 (256.15: -0.00%)
======================================================= (1.798 sec)
332.14... logprob:  0.663111, 0.367188 (0.649 sec)
332.15... logprob:  0.686232, 0.398438 (0.649 sec)
332.16... logprob:  0.627066, 0.320312 (0.651 sec)
332.17... logprob:  0.638514, 0.335938 (0.651 sec)
332.18... logprob:  0.638224, 0.335938 (0.651 sec)
332.19... logprob:  0.632729, 0.328125 (0.650 sec)
332.20... logprob:  0.648849, 0.351562 (0.651 sec)
332.21... logprob:  0.643420, 0.343750 (0.651 sec)
332.22... logprob:  0.628066, 0.320312 (0.650 sec)
332.23... logprob:  0.623253, 0.312500 (0.649 sec)
332.24... logprob:  0.578160, 0.242188 (0.650 sec)
332.25... logprob:  0.628245, 0.320312 (0.650 sec)
332.26... logprob:  0.673958, 0.390625 (0.651 sec)
332.27... logprob:  0.628084, 0.320312 (0.650 sec)
333.1... logprob:  0.679397, 0.398438 (0.650 sec)
333.2... logprob:  0.597225, 0.273438 (0.650 sec)
333.3... logprob:  0.653758, 0.359375 (0.650 sec)
333.4... logprob:  0.596798, 0.273438 (0.650 sec)
333.5... logprob:  0.591032, 0.265625 (0.650 sec)
333.6... logprob:  0.611425, 0.296875 (0.650 sec)
333.7... logprob:  0.643836, 0.343750 (0.650 sec)
333.8... logprob:  0.604788, 0.289062 (0.649 sec)
333.9... logprob:  0.638571, 0.335938 (0.650 sec)
333.10... logprob:  0.597843, 0.281250 (0.649 sec)
333.11... logprob:  0.638954, 0.335938 (0.650 sec)
333.12... logprob:  0.718275, 0.437500 (0.651 sec)
333.13... logprob:  0.657486, 0.359375 (0.734 sec)
333.14... logprob:  0.663102, 0.367188 (0.649 sec)
333.15... logprob:  0.686220, 0.398438 (0.650 sec)
333.16... logprob:  0.627066, 0.320312 (0.650 sec)
333.17... logprob:  0.638514, 0.335938 (0.651 sec)
333.18... logprob:  0.638224, 0.335938 (0.651 sec)
333.19... logprob:  0.632729, 0.328125 (0.651 sec)
333.20... logprob:  0.648850, 0.351562 (0.650 sec)
333.21... logprob:  0.643419, 0.343750 (0.652 sec)
333.22... logprob:  0.628062, 0.320312 (0.650 sec)
333.23... logprob:  0.623248, 0.312500 (0.650 sec)
333.24... logprob:  0.578143, 0.242188 (0.650 sec)
333.25... logprob:  0.628241, 0.320312 (0.651 sec)
333.26... logprob:  0.673964, 0.390625 (0.650 sec)
333.27... logprob:  0.628082, 0.320312 (0.651 sec)
334.1... logprob:  0.679401, 0.398438 (0.650 sec)
334.2... logprob:  0.597218, 0.273438 (0.650 sec)
334.3... logprob:  0.653759, 0.359375 (0.650 sec)
334.4... logprob:  0.596794, 0.273438 (0.650 sec)
334.5... logprob:  0.591029, 0.265625 (0.650 sec)
334.6... logprob:  0.611424, 0.296875 (0.650 sec)
334.7... logprob:  0.643835, 0.343750 (0.649 sec)
334.8... logprob:  0.604791, 0.289062 (0.650 sec)
334.9... logprob:  0.638570, 0.335938 (0.650 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627087, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943998e-03 [6.706135e-09] 
Layer 'conv1' biases: 4.988202e-07 [1.193181e-10] 
Layer 'conv2' weights[0]: 7.931776e-03 [5.803647e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.014591e-10] 
Layer 'conv3' weights[0]: 7.929555e-03 [5.662216e-09] 
Layer 'conv3' biases: 4.181880e-06 [1.856127e-09] 
Layer 'conv4' weights[0]: 7.962320e-03 [5.792644e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.614222e-08] 
Layer 'conv5' weights[0]: 7.961674e-03 [9.386703e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.984615e-08] 
Layer 'fc6' weights[0]: 7.557897e-03 [1.070831e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.983533e-09] 
Layer 'fc7' weights[0]: 7.506439e-03 [1.337998e-07] 
Layer 'fc7' biases: 9.998547e-01 [1.185113e-07] 
Layer 'fc8' weights[0]: 6.264594e-04 [6.460069e-06] 
Layer 'fc8' biases: 1.496788e-01 [1.452887e-04] 
Train error last 27 batches: 0.635824
-------------------------------------------------------
Saved checkpoint to /data/ad6813/my-nets/saves/ConvNet__2014-07-08_14.54.04
======================================================= (2.317 sec)
334.10... logprob:  0.597849, 0.281250 (0.650 sec)
334.11... logprob:  0.638951, 0.335938 (0.650 sec)
334.12... logprob:  0.718252, 0.437500 (0.652 sec)
334.13... logprob:  0.657479, 0.359375 (0.652 sec)
334.14... logprob:  0.663094, 0.367188 (0.650 sec)
334.15... logprob:  0.686211, 0.398438 (0.651 sec)
334.16... logprob:  0.627066, 0.320312 (0.651 sec)
334.17... logprob:  0.638513, 0.335938 (0.652 sec)
334.18... logprob:  0.638223, 0.335938 (0.653 sec)
334.19... logprob:  0.632728, 0.328125 (0.651 sec)
334.20... logprob:  0.648852, 0.351562 (0.651 sec)
334.21... logprob:  0.643420, 0.343750 (0.652 sec)
334.22... logprob:  0.628061, 0.320312 (0.651 sec)
334.23... logprob:  0.623244, 0.312500 (0.650 sec)
334.24... logprob:  0.578128, 0.242188 (0.651 sec)
334.25... logprob:  0.628238, 0.320312 (0.651 sec)
334.26... logprob:  0.673969, 0.390625 (0.652 sec)
334.27... logprob:  0.628079, 0.320312 (0.651 sec)
335.1... logprob:  0.679408, 0.398438 (0.651 sec)
335.2... logprob:  0.597212, 0.273438 (0.650 sec)
335.3... logprob:  0.653760, 0.359375 (0.651 sec)
335.4... logprob:  0.596789, 0.273438 (0.650 sec)
335.5... logprob:  0.591026, 0.265625 (0.650 sec)
335.6... logprob:  0.611423, 0.296875 (0.650 sec)
335.7... logprob:  0.643835, 0.343750 (0.650 sec)
335.8... logprob:  0.604793, 0.289062 (0.650 sec)
335.9... logprob:  0.638569, 0.335938 (0.650 sec)
335.10... logprob:  0.597853, 0.281250 (0.650 sec)
335.11... logprob:  0.638948, 0.335938 (0.650 sec)
335.12... logprob:  0.718232, 0.437500 (0.651 sec)
335.13... logprob:  0.657472, 0.359375 (0.650 sec)
335.14... logprob:  0.663087, 0.367188 (0.649 sec)
335.15... logprob:  0.686204, 0.398438 (0.651 sec)
335.16... logprob:  0.627066, 0.320312 (0.650 sec)
335.17... logprob:  0.638513, 0.335938 (0.652 sec)
335.18... logprob:  0.638223, 0.335938 (0.652 sec)
335.19... logprob:  0.632727, 0.328125 (0.651 sec)
335.20... logprob:  0.648852, 0.351562 (0.651 sec)
335.21... logprob:  0.643420, 0.343750 (0.652 sec)
335.22... logprob:  0.628057, 0.320312 (0.650 sec)
335.23... logprob:  0.623240, 0.312500 (0.650 sec)
335.24... logprob:  0.578114, 0.242188 (0.651 sec)
335.25... logprob:  0.628235, 0.320312 (0.652 sec)
335.26... logprob:  0.673973, 0.390625 (0.651 sec)
335.27... logprob:  0.628076, 0.320312 (0.651 sec)
336.1... logprob:  0.679412, 0.398438 (0.650 sec)
336.2... logprob:  0.597206, 0.273438 (0.651 sec)
336.3... logprob:  0.653761, 0.359375 (0.651 sec)
336.4... logprob:  0.596785, 0.273438 (0.651 sec)
336.5... logprob:  0.591024, 0.265625 (0.650 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.632881, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943809e-03 [7.469912e-09] 
Layer 'conv1' biases: 5.024789e-07 [1.404259e-10] 
Layer 'conv2' weights[0]: 7.931585e-03 [6.007000e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.634399e-10] 
Layer 'conv3' weights[0]: 7.929346e-03 [5.812473e-09] 
Layer 'conv3' biases: 4.212557e-06 [1.986137e-09] 
Layer 'conv4' weights[0]: 7.962113e-03 [5.872875e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.702538e-08] 
Layer 'conv5' weights[0]: 7.961478e-03 [9.869859e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.048651e-07] 
Layer 'fc6' weights[0]: 7.557716e-03 [1.122318e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.056805e-08] 
Layer 'fc7' weights[0]: 7.504562e-03 [1.409331e-07] 
Layer 'fc7' biases: 9.998543e-01 [1.264582e-07] 
Layer 'fc8' weights[0]: 6.004274e-04 [6.816241e-06] 
Layer 'fc8' biases: 1.497464e-01 [1.572107e-04] 
Train error last 27 batches: 0.635819
-------------------------------------------------------
Not saving because 0.632881 > 0.627087 (334.9: -0.00%)
======================================================= (1.754 sec)
336.6... logprob:  0.611424, 0.296875 (0.650 sec)
336.7... logprob:  0.643834, 0.343750 (0.650 sec)
336.8... logprob:  0.604795, 0.289062 (0.650 sec)
336.9... logprob:  0.638568, 0.335938 (0.650 sec)
336.10... logprob:  0.597858, 0.281250 (0.650 sec)
336.11... logprob:  0.638945, 0.335938 (0.650 sec)
336.12... logprob:  0.718211, 0.437500 (0.651 sec)
336.13... logprob:  0.657465, 0.359375 (0.651 sec)
336.14... logprob:  0.663081, 0.367188 (0.650 sec)
336.15... logprob:  0.686196, 0.398438 (0.650 sec)
336.16... logprob:  0.627066, 0.320312 (0.651 sec)
336.17... logprob:  0.638513, 0.335938 (0.652 sec)
336.18... logprob:  0.638224, 0.335938 (0.651 sec)
336.19... logprob:  0.632727, 0.328125 (0.651 sec)
336.20... logprob:  0.648854, 0.351562 (0.652 sec)
336.21... logprob:  0.643420, 0.343750 (0.651 sec)
336.22... logprob:  0.628054, 0.320312 (0.650 sec)
336.23... logprob:  0.623235, 0.312500 (0.650 sec)
336.24... logprob:  0.578097, 0.242188 (0.651 sec)
336.25... logprob:  0.628231, 0.320312 (0.651 sec)
336.26... logprob:  0.673980, 0.390625 (0.652 sec)
336.27... logprob:  0.628074, 0.320312 (0.651 sec)
337.1... logprob:  0.679418, 0.398438 (0.651 sec)
337.2... logprob:  0.597199, 0.273438 (0.650 sec)
337.3... logprob:  0.653762, 0.359375 (0.651 sec)
337.4... logprob:  0.596782, 0.273438 (0.651 sec)
337.5... logprob:  0.591022, 0.265625 (0.651 sec)
337.6... logprob:  0.611424, 0.296875 (0.650 sec)
337.7... logprob:  0.643834, 0.343750 (0.652 sec)
337.8... logprob:  0.604799, 0.289062 (0.650 sec)
337.9... logprob:  0.638566, 0.335938 (0.650 sec)
337.10... logprob:  0.597865, 0.281250 (0.650 sec)
337.11... logprob:  0.638941, 0.335938 (0.651 sec)
337.12... logprob:  0.718185, 0.437500 (0.651 sec)
337.13... logprob:  0.657456, 0.359375 (0.651 sec)
337.14... logprob:  0.663072, 0.367188 (0.650 sec)
337.15... logprob:  0.686185, 0.398438 (0.650 sec)
337.16... logprob:  0.627067, 0.320312 (0.651 sec)
337.17... logprob:  0.638513, 0.335938 (0.653 sec)
337.18... logprob:  0.638224, 0.335938 (0.652 sec)
337.19... logprob:  0.632727, 0.328125 (0.652 sec)
337.20... logprob:  0.648855, 0.351562 (0.650 sec)
337.21... logprob:  0.643421, 0.343750 (0.652 sec)
337.22... logprob:  0.628051, 0.320312 (0.650 sec)
337.23... logprob:  0.623229, 0.312500 (0.650 sec)
337.24... logprob:  0.578077, 0.242188 (0.650 sec)
337.25... logprob:  0.628227, 0.320312 (0.651 sec)
337.26... logprob:  0.673987, 0.390625 (0.651 sec)
337.27... logprob:  0.628071, 0.320312 (0.651 sec)
338.1... logprob:  0.679424, 0.398438 (0.651 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.684433, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943599e-03 [6.611654e-09] 
Layer 'conv1' biases: 5.060393e-07 [7.932126e-11] 
Layer 'conv2' weights[0]: 7.931391e-03 [5.115207e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.188218e-10] 
Layer 'conv3' weights[0]: 7.929148e-03 [4.478725e-09] 
Layer 'conv3' biases: 4.241472e-06 [8.049087e-10] 
Layer 'conv4' weights[0]: 7.961901e-03 [4.377654e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.952064e-09] 
Layer 'conv5' weights[0]: 7.961278e-03 [1.649814e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.685588e-08] 
Layer 'fc6' weights[0]: 7.557508e-03 [4.256783e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.803053e-09] 
Layer 'fc7' weights[0]: 7.502660e-03 [4.780220e-08] 
Layer 'fc7' biases: 9.998538e-01 [2.288047e-08] 
Layer 'fc8' weights[0]: 5.877151e-04 [1.161885e-06] 
Layer 'fc8' biases: 1.501246e-01 [1.532662e-05] 
Train error last 27 batches: 0.635814
-------------------------------------------------------
Not saving because 0.684433 > 0.627087 (334.9: -0.00%)
======================================================= (1.852 sec)
338.2... logprob:  0.597192, 0.273438 (0.651 sec)
338.3... logprob:  0.653764, 0.359375 (0.650 sec)
338.4... logprob:  0.596778, 0.273438 (0.651 sec)
338.5... logprob:  0.591020, 0.265625 (0.650 sec)
338.6... logprob:  0.611425, 0.296875 (0.650 sec)
338.7... logprob:  0.643833, 0.343750 (0.650 sec)
338.8... logprob:  0.604803, 0.289062 (0.650 sec)
338.9... logprob:  0.638565, 0.335938 (0.650 sec)
338.10... logprob:  0.597872, 0.281250 (0.650 sec)
338.11... logprob:  0.638937, 0.335938 (0.650 sec)
338.12... logprob:  0.718155, 0.437500 (0.652 sec)
338.13... logprob:  0.657446, 0.359375 (0.650 sec)
338.14... logprob:  0.663062, 0.367188 (0.651 sec)
338.15... logprob:  0.686173, 0.398438 (0.650 sec)
338.16... logprob:  0.627067, 0.320312 (0.651 sec)
338.17... logprob:  0.638513, 0.335938 (0.652 sec)
338.18... logprob:  0.638223, 0.335938 (0.652 sec)
338.19... logprob:  0.632726, 0.328125 (0.651 sec)
338.20... logprob:  0.648856, 0.351562 (0.652 sec)
338.21... logprob:  0.643421, 0.343750 (0.652 sec)
338.22... logprob:  0.628048, 0.320312 (0.650 sec)
338.23... logprob:  0.623224, 0.312500 (0.650 sec)
338.24... logprob:  0.578061, 0.242188 (0.651 sec)
338.25... logprob:  0.628223, 0.320312 (0.653 sec)
338.26... logprob:  0.673994, 0.390625 (0.651 sec)
338.27... logprob:  0.628067, 0.320312 (0.650 sec)
339.1... logprob:  0.679432, 0.398438 (0.650 sec)
339.2... logprob:  0.597183, 0.273438 (0.651 sec)
339.3... logprob:  0.653766, 0.359375 (0.651 sec)
339.4... logprob:  0.596771, 0.273438 (0.650 sec)
339.5... logprob:  0.591014, 0.265625 (0.651 sec)
339.6... logprob:  0.611423, 0.296875 (0.650 sec)
339.7... logprob:  0.643833, 0.343750 (0.651 sec)
339.8... logprob:  0.604804, 0.289062 (0.650 sec)
339.9... logprob:  0.638564, 0.335938 (0.650 sec)
339.10... logprob:  0.597876, 0.281250 (0.649 sec)
339.11... logprob:  0.638935, 0.335938 (0.651 sec)
339.12... logprob:  0.718134, 0.437500 (0.651 sec)
339.13... logprob:  0.657439, 0.359375 (0.651 sec)
339.14... logprob:  0.663055, 0.367188 (0.650 sec)
339.15... logprob:  0.686164, 0.398438 (0.650 sec)
339.16... logprob:  0.627067, 0.320312 (0.650 sec)
339.17... logprob:  0.638512, 0.335938 (0.652 sec)
339.18... logprob:  0.638224, 0.335938 (0.651 sec)
339.19... logprob:  0.632726, 0.328125 (0.651 sec)
339.20... logprob:  0.648858, 0.351562 (0.651 sec)
339.21... logprob:  0.643422, 0.343750 (0.652 sec)
339.22... logprob:  0.628045, 0.320312 (0.650 sec)
339.23... logprob:  0.623219, 0.312500 (0.651 sec)
339.24... logprob:  0.578044, 0.242188 (0.650 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633350, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943409e-03 [6.506131e-09] 
Layer 'conv1' biases: 5.095155e-07 [5.977799e-11] 
Layer 'conv2' weights[0]: 7.931200e-03 [4.865339e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.034288e-10] 
Layer 'conv3' weights[0]: 7.928963e-03 [4.532047e-09] 
Layer 'conv3' biases: 4.269868e-06 [8.615453e-10] 
Layer 'conv4' weights[0]: 7.961710e-03 [4.478438e-09] 
Layer 'conv4' biases: 1.000001e+00 [6.197446e-09] 
Layer 'conv5' weights[0]: 7.961098e-03 [3.559838e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.754275e-08] 
Layer 'fc6' weights[0]: 7.557322e-03 [5.435883e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.768765e-09] 
Layer 'fc7' weights[0]: 7.500739e-03 [6.653011e-08] 
Layer 'fc7' biases: 9.998537e-01 [4.545204e-08] 
Layer 'fc8' weights[0]: 5.833537e-04 [2.392896e-06] 
Layer 'fc8' biases: 1.506925e-01 [6.913746e-05] 
Train error last 27 batches: 0.635807
-------------------------------------------------------
Not saving because 0.633350 > 0.627087 (334.9: -0.00%)
======================================================= (1.811 sec)
339.25... logprob:  0.628220, 0.320312 (0.651 sec)
339.26... logprob:  0.674000, 0.390625 (0.651 sec)
339.27... logprob:  0.628066, 0.320312 (0.651 sec)
340.1... logprob:  0.679437, 0.398438 (0.650 sec)
340.2... logprob:  0.597178, 0.273438 (0.650 sec)
340.3... logprob:  0.653767, 0.359375 (0.650 sec)
340.4... logprob:  0.596768, 0.273438 (0.651 sec)
340.5... logprob:  0.591014, 0.265625 (0.650 sec)
340.6... logprob:  0.611424, 0.296875 (0.650 sec)
340.7... logprob:  0.643832, 0.343750 (0.650 sec)
340.8... logprob:  0.604809, 0.289062 (0.650 sec)
340.9... logprob:  0.638562, 0.335938 (0.650 sec)
340.10... logprob:  0.597883, 0.281250 (0.650 sec)
340.11... logprob:  0.638931, 0.335938 (0.651 sec)
340.12... logprob:  0.718106, 0.437500 (0.652 sec)
340.13... logprob:  0.657429, 0.359375 (0.650 sec)
340.14... logprob:  0.663046, 0.367188 (0.650 sec)
340.15... logprob:  0.686153, 0.398438 (0.650 sec)
340.16... logprob:  0.627067, 0.320312 (0.651 sec)
340.17... logprob:  0.638512, 0.335938 (0.652 sec)
340.18... logprob:  0.638223, 0.335938 (0.652 sec)
340.19... logprob:  0.632725, 0.328125 (0.651 sec)
340.20... logprob:  0.648859, 0.351562 (0.651 sec)
340.21... logprob:  0.643422, 0.343750 (0.652 sec)
340.22... logprob:  0.628042, 0.320312 (0.650 sec)
340.23... logprob:  0.623215, 0.312500 (0.650 sec)
340.24... logprob:  0.578030, 0.242188 (0.651 sec)
340.25... logprob:  0.628217, 0.320312 (0.651 sec)
340.26... logprob:  0.674005, 0.390625 (0.652 sec)
340.27... logprob:  0.628062, 0.320312 (0.651 sec)
341.1... logprob:  0.679443, 0.398438 (0.651 sec)
341.2... logprob:  0.597170, 0.273438 (0.650 sec)
341.3... logprob:  0.653768, 0.359375 (0.650 sec)
341.4... logprob:  0.596763, 0.273438 (0.650 sec)
341.5... logprob:  0.591009, 0.265625 (0.650 sec)
341.6... logprob:  0.611423, 0.296875 (0.650 sec)
341.7... logprob:  0.643832, 0.343750 (0.651 sec)
341.8... logprob:  0.604809, 0.289062 (0.649 sec)
341.9... logprob:  0.638562, 0.335938 (0.650 sec)
341.10... logprob:  0.597886, 0.281250 (0.650 sec)
341.11... logprob:  0.638929, 0.335938 (0.650 sec)
341.12... logprob:  0.718091, 0.437500 (0.651 sec)
341.13... logprob:  0.657425, 0.359375 (0.651 sec)
341.14... logprob:  0.663040, 0.367188 (0.649 sec)
341.15... logprob:  0.686147, 0.398438 (0.650 sec)
341.16... logprob:  0.627067, 0.320312 (0.651 sec)
341.17... logprob:  0.638513, 0.335938 (0.652 sec)
341.18... logprob:  0.638223, 0.335938 (0.651 sec)
341.19... logprob:  0.632724, 0.328125 (0.651 sec)
341.20... logprob:  0.648860, 0.351562 (0.651 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627911, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943233e-03 [6.808829e-09] 
Layer 'conv1' biases: 5.128778e-07 [1.614321e-10] 
Layer 'conv2' weights[0]: 7.931004e-03 [6.528406e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.715749e-10] 
Layer 'conv3' weights[0]: 7.928764e-03 [5.730798e-09] 
Layer 'conv3' biases: 4.296639e-06 [2.112211e-09] 
Layer 'conv4' weights[0]: 7.961512e-03 [5.665611e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.481562e-08] 
Layer 'conv5' weights[0]: 7.960926e-03 [8.524237e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.032686e-08] 
Layer 'fc6' weights[0]: 7.557132e-03 [1.005552e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.219645e-09] 
Layer 'fc7' weights[0]: 7.498802e-03 [1.266111e-07] 
Layer 'fc7' biases: 9.998538e-01 [1.110853e-07] 
Layer 'fc8' weights[0]: 5.911113e-04 [5.957574e-06] 
Layer 'fc8' biases: 1.515538e-01 [1.139551e-04] 
Train error last 27 batches: 0.635803
-------------------------------------------------------
Not saving because 0.627911 > 0.627087 (334.9: -0.00%)
======================================================= (1.761 sec)
341.21... logprob:  0.643423, 0.343750 (0.652 sec)
341.22... logprob:  0.628040, 0.320312 (0.650 sec)
341.23... logprob:  0.623211, 0.312500 (0.650 sec)
341.24... logprob:  0.578014, 0.242188 (0.651 sec)
341.25... logprob:  0.628214, 0.320312 (0.651 sec)
341.26... logprob:  0.674011, 0.390625 (0.651 sec)
341.27... logprob:  0.628061, 0.320312 (0.652 sec)
342.1... logprob:  0.679448, 0.398438 (0.651 sec)
342.2... logprob:  0.597166, 0.273438 (0.650 sec)
342.3... logprob:  0.653769, 0.359375 (0.650 sec)
342.4... logprob:  0.596762, 0.273438 (0.650 sec)
342.5... logprob:  0.591010, 0.265625 (0.650 sec)
342.6... logprob:  0.611425, 0.296875 (0.650 sec)
342.7... logprob:  0.643831, 0.343750 (0.650 sec)
342.8... logprob:  0.604814, 0.289062 (0.650 sec)
342.9... logprob:  0.638560, 0.335938 (0.650 sec)
342.10... logprob:  0.597894, 0.281250 (0.650 sec)
342.11... logprob:  0.638924, 0.335938 (0.650 sec)
342.12... logprob:  0.718062, 0.437500 (0.651 sec)
342.13... logprob:  0.657414, 0.359375 (0.650 sec)
342.14... logprob:  0.663030, 0.367188 (0.650 sec)
342.15... logprob:  0.686135, 0.398438 (0.650 sec)
342.16... logprob:  0.627067, 0.320312 (0.650 sec)
342.17... logprob:  0.638512, 0.335938 (0.652 sec)
342.18... logprob:  0.638223, 0.335938 (0.651 sec)
342.19... logprob:  0.632724, 0.328125 (0.651 sec)
342.20... logprob:  0.648860, 0.351562 (0.651 sec)
342.21... logprob:  0.643423, 0.343750 (0.651 sec)
342.22... logprob:  0.628037, 0.320312 (0.650 sec)
342.23... logprob:  0.623207, 0.312500 (0.650 sec)
342.24... logprob:  0.578001, 0.242188 (0.650 sec)
342.25... logprob:  0.628210, 0.320312 (0.651 sec)
342.26... logprob:  0.674016, 0.390625 (0.652 sec)
342.27... logprob:  0.628058, 0.320312 (0.650 sec)
343.1... logprob:  0.679453, 0.398438 (0.651 sec)
343.2... logprob:  0.597159, 0.273438 (0.650 sec)
343.3... logprob:  0.653771, 0.359375 (0.650 sec)
343.4... logprob:  0.596755, 0.273438 (0.651 sec)
343.5... logprob:  0.591005, 0.265625 (0.650 sec)
343.6... logprob:  0.611423, 0.296875 (0.650 sec)
343.7... logprob:  0.643831, 0.343750 (0.651 sec)
343.8... logprob:  0.604814, 0.289062 (0.650 sec)
343.9... logprob:  0.638559, 0.335938 (0.650 sec)
343.10... logprob:  0.597896, 0.281250 (0.650 sec)
343.11... logprob:  0.638922, 0.335938 (0.650 sec)
343.12... logprob:  0.718050, 0.437500 (0.651 sec)
343.13... logprob:  0.657411, 0.359375 (0.651 sec)
343.14... logprob:  0.663026, 0.367188 (0.650 sec)
343.15... logprob:  0.686131, 0.398438 (0.650 sec)
343.16... logprob:  0.627067, 0.320312 (0.651 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.655313, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943031e-03 [6.959765e-09] 
Layer 'conv1' biases: 5.161265e-07 [1.849064e-10] 
Layer 'conv2' weights[0]: 7.930830e-03 [7.229088e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.352452e-10] 
Layer 'conv3' weights[0]: 7.928569e-03 [6.289912e-09] 
Layer 'conv3' biases: 4.321654e-06 [2.572964e-09] 
Layer 'conv4' weights[0]: 7.961331e-03 [6.318902e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.885228e-08] 
Layer 'conv5' weights[0]: 7.960720e-03 [1.089165e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.156835e-07] 
Layer 'fc6' weights[0]: 7.556946e-03 [1.221128e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.170154e-08] 
Layer 'fc7' weights[0]: 7.496867e-03 [1.526004e-07] 
Layer 'fc7' biases: 9.998541e-01 [1.393114e-07] 
Layer 'fc8' weights[0]: 6.130571e-04 [7.545911e-06] 
Layer 'fc8' biases: 1.527501e-01 [1.411891e-04] 
Train error last 27 batches: 0.635798
-------------------------------------------------------
Not saving because 0.655313 > 0.627087 (334.9: -0.00%)
======================================================= (1.745 sec)
343.17... logprob:  0.638512, 0.335938 (0.653 sec)
343.18... logprob:  0.638223, 0.335938 (0.652 sec)
343.19... logprob:  0.632723, 0.328125 (0.652 sec)
343.20... logprob:  0.648861, 0.351562 (0.651 sec)
343.21... logprob:  0.643423, 0.343750 (0.652 sec)
343.22... logprob:  0.628035, 0.320312 (0.651 sec)
343.23... logprob:  0.623204, 0.312500 (0.650 sec)
343.24... logprob:  0.577990, 0.242188 (0.651 sec)
343.25... logprob:  0.628208, 0.320312 (0.652 sec)
343.26... logprob:  0.674020, 0.390625 (0.651 sec)
343.27... logprob:  0.628056, 0.320312 (0.651 sec)
344.1... logprob:  0.679457, 0.398438 (0.650 sec)
344.2... logprob:  0.597154, 0.273438 (0.650 sec)
344.3... logprob:  0.653772, 0.359375 (0.650 sec)
344.4... logprob:  0.596753, 0.273438 (0.651 sec)
344.5... logprob:  0.591003, 0.265625 (0.650 sec)
344.6... logprob:  0.611423, 0.296875 (0.650 sec)
344.7... logprob:  0.643830, 0.343750 (0.651 sec)
344.8... logprob:  0.604816, 0.289062 (0.650 sec)
344.9... logprob:  0.638558, 0.335938 (0.650 sec)
344.10... logprob:  0.597901, 0.281250 (0.650 sec)
344.11... logprob:  0.638920, 0.335938 (0.650 sec)
344.12... logprob:  0.718029, 0.437500 (0.652 sec)
344.13... logprob:  0.657404, 0.359375 (0.650 sec)
344.14... logprob:  0.663020, 0.367188 (0.650 sec)
344.15... logprob:  0.686123, 0.398438 (0.650 sec)
344.16... logprob:  0.627068, 0.320312 (0.650 sec)
344.17... logprob:  0.638512, 0.335938 (0.652 sec)
344.18... logprob:  0.638224, 0.335938 (0.653 sec)
344.19... logprob:  0.632723, 0.328125 (0.651 sec)
344.20... logprob:  0.648863, 0.351562 (0.651 sec)
344.21... logprob:  0.643424, 0.343750 (0.652 sec)
344.22... logprob:  0.628031, 0.320312 (0.650 sec)
344.23... logprob:  0.623198, 0.312500 (0.650 sec)
344.24... logprob:  0.577972, 0.242188 (0.651 sec)
344.25... logprob:  0.628205, 0.320312 (0.650 sec)
344.26... logprob:  0.674027, 0.390625 (0.651 sec)
344.27... logprob:  0.628053, 0.320312 (0.650 sec)
345.1... logprob:  0.679463, 0.398438 (0.651 sec)
345.2... logprob:  0.597147, 0.273438 (0.651 sec)
345.3... logprob:  0.653773, 0.359375 (0.651 sec)
345.4... logprob:  0.596749, 0.273438 (0.651 sec)
345.5... logprob:  0.591001, 0.265625 (0.651 sec)
345.6... logprob:  0.611424, 0.296875 (0.651 sec)
345.7... logprob:  0.643830, 0.343750 (0.650 sec)
345.8... logprob:  0.604821, 0.289062 (0.651 sec)
345.9... logprob:  0.638557, 0.335938 (0.651 sec)
345.10... logprob:  0.597908, 0.281250 (0.649 sec)
345.11... logprob:  0.638916, 0.335938 (0.651 sec)
345.12... logprob:  0.718001, 0.437500 (0.651 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627139, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942824e-03 [6.869832e-09] 
Layer 'conv1' biases: 5.193599e-07 [8.237896e-11] 
Layer 'conv2' weights[0]: 7.930627e-03 [5.242219e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.267736e-10] 
Layer 'conv3' weights[0]: 7.928373e-03 [4.552088e-09] 
Layer 'conv3' biases: 4.346816e-06 [8.234965e-10] 
Layer 'conv4' weights[0]: 7.961137e-03 [4.408260e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.843559e-09] 
Layer 'conv5' weights[0]: 7.960521e-03 [1.153162e-08] 
Layer 'conv5' biases: 1.000001e+00 [1.129423e-08] 
Layer 'fc6' weights[0]: 7.556735e-03 [4.002112e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.204179e-09] 
Layer 'fc7' weights[0]: 7.494924e-03 [4.302304e-08] 
Layer 'fc7' biases: 9.998544e-01 [1.621499e-08] 
Layer 'fc8' weights[0]: 6.336142e-04 [7.678203e-07] 
Layer 'fc8' biases: 1.538906e-01 [7.785235e-08] 
Train error last 27 batches: 0.635794
-------------------------------------------------------
Not saving because 0.627139 > 0.627087 (334.9: -0.00%)
======================================================= (1.868 sec)
345.13... logprob:  0.657394, 0.359375 (0.651 sec)
345.14... logprob:  0.663010, 0.367188 (0.650 sec)
345.15... logprob:  0.686111, 0.398438 (0.650 sec)
345.16... logprob:  0.627068, 0.320312 (0.651 sec)
345.17... logprob:  0.638512, 0.335938 (0.652 sec)
345.18... logprob:  0.638223, 0.335938 (0.651 sec)
345.19... logprob:  0.632722, 0.328125 (0.652 sec)
345.20... logprob:  0.648863, 0.351562 (0.651 sec)
345.21... logprob:  0.643423, 0.343750 (0.651 sec)
345.22... logprob:  0.628028, 0.320312 (0.650 sec)
345.23... logprob:  0.623195, 0.312500 (0.650 sec)
345.24... logprob:  0.577956, 0.242188 (0.650 sec)
345.25... logprob:  0.628201, 0.320312 (0.652 sec)
345.26... logprob:  0.674033, 0.390625 (0.651 sec)
345.27... logprob:  0.628051, 0.320312 (0.651 sec)
346.1... logprob:  0.679469, 0.398438 (0.651 sec)
346.2... logprob:  0.597140, 0.273438 (0.651 sec)
346.3... logprob:  0.653775, 0.359375 (0.650 sec)
346.4... logprob:  0.596743, 0.273438 (0.651 sec)
346.5... logprob:  0.590997, 0.265625 (0.650 sec)
346.6... logprob:  0.611422, 0.296875 (0.650 sec)
346.7... logprob:  0.643830, 0.343750 (0.650 sec)
346.8... logprob:  0.604821, 0.289062 (0.650 sec)
346.9... logprob:  0.638556, 0.335938 (0.650 sec)
346.10... logprob:  0.597912, 0.281250 (0.650 sec)
346.11... logprob:  0.638914, 0.335938 (0.650 sec)
346.12... logprob:  0.717984, 0.437500 (0.651 sec)
346.13... logprob:  0.657389, 0.359375 (0.650 sec)
346.14... logprob:  0.663005, 0.367188 (0.650 sec)
346.15... logprob:  0.686105, 0.398438 (0.650 sec)
346.16... logprob:  0.627068, 0.320312 (0.651 sec)
346.17... logprob:  0.638512, 0.335938 (0.652 sec)
346.18... logprob:  0.638224, 0.335938 (0.652 sec)
346.19... logprob:  0.632722, 0.328125 (0.651 sec)
346.20... logprob:  0.648866, 0.351562 (0.651 sec)
346.21... logprob:  0.643424, 0.343750 (0.652 sec)
346.22... logprob:  0.628025, 0.320312 (0.651 sec)
346.23... logprob:  0.623188, 0.312500 (0.650 sec)
346.24... logprob:  0.577938, 0.242188 (0.651 sec)
346.25... logprob:  0.628197, 0.320312 (0.651 sec)
346.26... logprob:  0.674039, 0.390625 (0.651 sec)
346.27... logprob:  0.628048, 0.320312 (0.651 sec)
347.1... logprob:  0.679475, 0.398438 (0.651 sec)
347.2... logprob:  0.597134, 0.273438 (0.650 sec)
347.3... logprob:  0.653776, 0.359375 (0.650 sec)
347.4... logprob:  0.596741, 0.273438 (0.650 sec)
347.5... logprob:  0.590996, 0.265625 (0.650 sec)
347.6... logprob:  0.611424, 0.296875 (0.651 sec)
347.7... logprob:  0.643829, 0.343750 (0.651 sec)
347.8... logprob:  0.604828, 0.289062 (0.650 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.632789, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942632e-03 [7.176908e-09] 
Layer 'conv1' biases: 5.229596e-07 [1.450449e-10] 
Layer 'conv2' weights[0]: 7.930438e-03 [6.279563e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.502276e-10] 
Layer 'conv3' weights[0]: 7.928184e-03 [6.086446e-09] 
Layer 'conv3' biases: 4.376504e-06 [2.228106e-09] 
Layer 'conv4' weights[0]: 7.960968e-03 [6.224775e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.936406e-08] 
Layer 'conv5' weights[0]: 7.960329e-03 [1.114402e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.183965e-07] 
Layer 'fc6' weights[0]: 7.556541e-03 [1.243259e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.188565e-08] 
Layer 'fc7' weights[0]: 7.493048e-03 [1.542452e-07] 
Layer 'fc7' biases: 9.998540e-01 [1.406653e-07] 
Layer 'fc8' weights[0]: 6.156430e-04 [7.596653e-06] 
Layer 'fc8' biases: 1.541408e-01 [1.730130e-04] 
Train error last 27 batches: 0.635790
-------------------------------------------------------
Not saving because 0.632789 > 0.627087 (334.9: -0.00%)
======================================================= (1.754 sec)
347.9... logprob:  0.638553, 0.335938 (0.650 sec)
347.10... logprob:  0.597920, 0.281250 (0.650 sec)
347.11... logprob:  0.638909, 0.335938 (0.651 sec)
347.12... logprob:  0.717949, 0.437500 (0.651 sec)
347.13... logprob:  0.657377, 0.359375 (0.650 sec)
347.14... logprob:  0.662993, 0.367188 (0.649 sec)
347.15... logprob:  0.686091, 0.398438 (0.651 sec)
347.16... logprob:  0.627069, 0.320312 (0.650 sec)
347.17... logprob:  0.638512, 0.335938 (0.652 sec)
347.18... logprob:  0.638223, 0.335938 (0.651 sec)
347.19... logprob:  0.632721, 0.328125 (0.651 sec)
347.20... logprob:  0.648867, 0.351562 (0.651 sec)
347.21... logprob:  0.643425, 0.343750 (0.652 sec)
347.22... logprob:  0.628022, 0.320312 (0.650 sec)
347.23... logprob:  0.623184, 0.312500 (0.650 sec)
347.24... logprob:  0.577919, 0.242188 (0.650 sec)
347.25... logprob:  0.628193, 0.320312 (0.651 sec)
347.26... logprob:  0.674047, 0.390625 (0.651 sec)
347.27... logprob:  0.628044, 0.320312 (0.651 sec)
348.1... logprob:  0.679483, 0.398438 (0.650 sec)
348.2... logprob:  0.597125, 0.273438 (0.651 sec)
348.3... logprob:  0.653778, 0.359375 (0.650 sec)
348.4... logprob:  0.596734, 0.273438 (0.651 sec)
348.5... logprob:  0.590992, 0.265625 (0.650 sec)
348.6... logprob:  0.611423, 0.296875 (0.650 sec)
348.7... logprob:  0.643827, 0.343750 (0.650 sec)
348.8... logprob:  0.604829, 0.289062 (0.650 sec)
348.9... logprob:  0.638553, 0.335938 (0.650 sec)
348.10... logprob:  0.597925, 0.281250 (0.650 sec)
348.11... logprob:  0.638907, 0.335938 (0.650 sec)
348.12... logprob:  0.717927, 0.437500 (0.651 sec)
348.13... logprob:  0.657370, 0.359375 (0.652 sec)
348.14... logprob:  0.662987, 0.367188 (0.650 sec)
348.15... logprob:  0.686082, 0.398438 (0.650 sec)
348.16... logprob:  0.627068, 0.320312 (0.651 sec)
348.17... logprob:  0.638511, 0.335938 (0.652 sec)
348.18... logprob:  0.638224, 0.335938 (0.651 sec)
348.19... logprob:  0.632722, 0.328125 (0.651 sec)
348.20... logprob:  0.648868, 0.351562 (0.651 sec)
348.21... logprob:  0.643426, 0.343750 (0.651 sec)
348.22... logprob:  0.628019, 0.320312 (0.651 sec)
348.23... logprob:  0.623178, 0.312500 (0.649 sec)
348.24... logprob:  0.577902, 0.242188 (0.651 sec)
348.25... logprob:  0.628190, 0.320312 (0.651 sec)
348.26... logprob:  0.674053, 0.390625 (0.652 sec)
348.27... logprob:  0.628043, 0.320312 (0.650 sec)
349.1... logprob:  0.679488, 0.398438 (0.650 sec)
349.2... logprob:  0.597119, 0.273438 (0.650 sec)
349.3... logprob:  0.653779, 0.359375 (0.650 sec)
349.4... logprob:  0.596731, 0.273438 (0.651 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.685386, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942434e-03 [6.839593e-09] 
Layer 'conv1' biases: 5.266520e-07 [9.001933e-11] 
Layer 'conv2' weights[0]: 7.930252e-03 [5.285264e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.657527e-10] 
Layer 'conv3' weights[0]: 7.927975e-03 [4.967702e-09] 
Layer 'conv3' biases: 4.406897e-06 [1.234343e-09] 
Layer 'conv4' weights[0]: 7.960764e-03 [4.935080e-09] 
Layer 'conv4' biases: 1.000001e+00 [9.498337e-09] 
Layer 'conv5' weights[0]: 7.960120e-03 [5.520047e-08] 
Layer 'conv5' biases: 1.000002e+00 [5.859657e-08] 
Layer 'fc6' weights[0]: 7.556333e-03 [7.095792e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.869787e-09] 
Layer 'fc7' weights[0]: 7.491169e-03 [8.840302e-08] 
Layer 'fc7' biases: 9.998536e-01 [6.967510e-08] 
Layer 'fc8' weights[0]: 5.900746e-04 [3.730312e-06] 
Layer 'fc8' biases: 1.541860e-01 [9.193897e-05] 
Train error last 27 batches: 0.635783
-------------------------------------------------------
Not saving because 0.685386 > 0.627087 (334.9: -0.00%)
======================================================= (1.784 sec)
349.5... logprob:  0.590989, 0.265625 (0.650 sec)
349.6... logprob:  0.611423, 0.296875 (0.650 sec)
349.7... logprob:  0.643827, 0.343750 (0.650 sec)
349.8... logprob:  0.604832, 0.289062 (0.650 sec)
349.9... logprob:  0.638551, 0.335938 (0.650 sec)
349.10... logprob:  0.597931, 0.281250 (0.650 sec)
349.11... logprob:  0.638903, 0.335938 (0.650 sec)
349.12... logprob:  0.717902, 0.437500 (0.651 sec)
349.13... logprob:  0.657361, 0.359375 (0.651 sec)
349.14... logprob:  0.662977, 0.367188 (0.649 sec)
349.15... logprob:  0.686070, 0.398438 (0.650 sec)
349.16... logprob:  0.627069, 0.320312 (0.651 sec)
349.17... logprob:  0.638511, 0.335938 (0.652 sec)
349.18... logprob:  0.638223, 0.335938 (0.651 sec)
349.19... logprob:  0.632721, 0.328125 (0.651 sec)
349.20... logprob:  0.648869, 0.351562 (0.651 sec)
349.21... logprob:  0.643426, 0.343750 (0.652 sec)
349.22... logprob:  0.628017, 0.320312 (0.650 sec)
349.23... logprob:  0.623175, 0.312500 (0.650 sec)
349.24... logprob:  0.577891, 0.242188 (0.650 sec)
349.25... logprob:  0.628187, 0.320312 (0.651 sec)
349.26... logprob:  0.674057, 0.390625 (0.650 sec)
349.27... logprob:  0.628040, 0.320312 (0.650 sec)
350.1... logprob:  0.679493, 0.398438 (0.650 sec)
350.2... logprob:  0.597113, 0.273438 (0.652 sec)
350.3... logprob:  0.653780, 0.359375 (0.650 sec)
350.4... logprob:  0.596726, 0.273438 (0.651 sec)
350.5... logprob:  0.590986, 0.265625 (0.650 sec)
350.6... logprob:  0.611422, 0.296875 (0.651 sec)
350.7... logprob:  0.643827, 0.343750 (0.650 sec)
350.8... logprob:  0.604833, 0.289062 (0.650 sec)
350.9... logprob:  0.638551, 0.335938 (0.650 sec)
350.10... logprob:  0.597934, 0.281250 (0.650 sec)
350.11... logprob:  0.638901, 0.335938 (0.650 sec)
350.12... logprob:  0.717887, 0.437500 (0.652 sec)
350.13... logprob:  0.657356, 0.359375 (0.651 sec)
350.14... logprob:  0.662972, 0.367188 (0.650 sec)
350.15... logprob:  0.686065, 0.398438 (0.650 sec)
350.16... logprob:  0.627069, 0.320312 (0.651 sec)
350.17... logprob:  0.638510, 0.335938 (0.652 sec)
350.18... logprob:  0.638223, 0.335938 (0.652 sec)
350.19... logprob:  0.632720, 0.328125 (0.651 sec)
350.20... logprob:  0.648870, 0.351562 (0.651 sec)
350.21... logprob:  0.643427, 0.343750 (0.652 sec)
350.22... logprob:  0.628015, 0.320312 (0.650 sec)
350.23... logprob:  0.623171, 0.312500 (0.650 sec)
350.24... logprob:  0.577878, 0.242188 (0.651 sec)
350.25... logprob:  0.628185, 0.320312 (0.651 sec)
350.26... logprob:  0.674062, 0.390625 (0.652 sec)
350.27... logprob:  0.628039, 0.320312 (0.650 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633182, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942236e-03 [6.599372e-09] 
Layer 'conv1' biases: 5.301821e-07 [7.045151e-11] 
Layer 'conv2' weights[0]: 7.930059e-03 [4.897719e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.617404e-10] 
Layer 'conv3' weights[0]: 7.927778e-03 [4.458249e-09] 
Layer 'conv3' biases: 4.435046e-06 [7.096429e-10] 
Layer 'conv4' weights[0]: 7.960561e-03 [4.394100e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.942767e-09] 
Layer 'conv5' weights[0]: 7.959929e-03 [2.314568e-08] 
Layer 'conv5' biases: 1.000002e+00 [2.406314e-08] 
Layer 'fc6' weights[0]: 7.556134e-03 [4.606720e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.401361e-09] 
Layer 'fc7' weights[0]: 7.489329e-03 [5.299342e-08] 
Layer 'fc7' biases: 9.998535e-01 [2.890753e-08] 
Layer 'fc8' weights[0]: 5.847317e-04 [1.504345e-06] 
Layer 'fc8' biases: 1.547300e-01 [4.523336e-05] 
Train error last 27 batches: 0.635778
-------------------------------------------------------
Not saving because 0.633182 > 0.627087 (334.9: -0.00%)
======================================================= (1.832 sec)
351.1... logprob:  0.679497, 0.398438 (0.650 sec)
351.2... logprob:  0.597107, 0.273438 (0.651 sec)
351.3... logprob:  0.653781, 0.359375 (0.651 sec)
351.4... logprob:  0.596722, 0.273438 (0.650 sec)
351.5... logprob:  0.590983, 0.265625 (0.651 sec)
351.6... logprob:  0.611422, 0.296875 (0.650 sec)
351.7... logprob:  0.643827, 0.343750 (0.651 sec)
351.8... logprob:  0.604835, 0.289062 (0.650 sec)
351.9... logprob:  0.638549, 0.335938 (0.650 sec)
351.10... logprob:  0.597939, 0.281250 (0.650 sec)
351.11... logprob:  0.638898, 0.335938 (0.651 sec)
351.12... logprob:  0.717867, 0.437500 (0.651 sec)
351.13... logprob:  0.657350, 0.359375 (0.651 sec)
351.14... logprob:  0.662966, 0.367188 (0.650 sec)
351.15... logprob:  0.686058, 0.398438 (0.650 sec)
351.16... logprob:  0.627069, 0.320312 (0.651 sec)
351.17... logprob:  0.638511, 0.335938 (0.653 sec)
351.18... logprob:  0.638223, 0.335938 (0.651 sec)
351.19... logprob:  0.632719, 0.328125 (0.652 sec)
351.20... logprob:  0.648871, 0.351562 (0.651 sec)
351.21... logprob:  0.643427, 0.343750 (0.652 sec)
351.22... logprob:  0.628011, 0.320312 (0.650 sec)
351.23... logprob:  0.623167, 0.312500 (0.651 sec)
351.24... logprob:  0.577861, 0.242188 (0.650 sec)
351.25... logprob:  0.628181, 0.320312 (0.652 sec)
351.26... logprob:  0.674068, 0.390625 (0.651 sec)
351.27... logprob:  0.628035, 0.320312 (0.651 sec)
352.1... logprob:  0.679503, 0.398438 (0.651 sec)
352.2... logprob:  0.597101, 0.273438 (0.651 sec)
352.3... logprob:  0.653783, 0.359375 (0.650 sec)
352.4... logprob:  0.596719, 0.273438 (0.651 sec)
352.5... logprob:  0.590982, 0.265625 (0.651 sec)
352.6... logprob:  0.611422, 0.296875 (0.650 sec)
352.7... logprob:  0.643826, 0.343750 (0.650 sec)
352.8... logprob:  0.604839, 0.289062 (0.651 sec)
352.9... logprob:  0.638548, 0.335938 (0.650 sec)
352.10... logprob:  0.597945, 0.281250 (0.650 sec)
352.11... logprob:  0.638894, 0.335938 (0.650 sec)
352.12... logprob:  0.717842, 0.437500 (0.651 sec)
352.13... logprob:  0.657342, 0.359375 (0.650 sec)
352.14... logprob:  0.662957, 0.367188 (0.650 sec)
352.15... logprob:  0.686047, 0.398438 (0.650 sec)
352.16... logprob:  0.627069, 0.320312 (0.651 sec)
352.17... logprob:  0.638510, 0.335938 (0.652 sec)
352.18... logprob:  0.638223, 0.335938 (0.651 sec)
352.19... logprob:  0.632719, 0.328125 (0.651 sec)
352.20... logprob:  0.648872, 0.351562 (0.652 sec)
352.21... logprob:  0.643427, 0.343750 (0.651 sec)
352.22... logprob:  0.628008, 0.320312 (0.651 sec)
352.23... logprob:  0.623162, 0.312500 (0.649 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.628377, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942038e-03 [6.324094e-09] 
Layer 'conv1' biases: 5.337214e-07 [1.061561e-10] 
Layer 'conv2' weights[0]: 7.929862e-03 [5.341614e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.158240e-10] 
Layer 'conv3' weights[0]: 7.927595e-03 [4.743281e-09] 
Layer 'conv3' biases: 4.463593e-06 [1.086444e-09] 
Layer 'conv4' weights[0]: 7.960384e-03 [4.617817e-09] 
Layer 'conv4' biases: 1.000001e+00 [5.728286e-09] 
Layer 'conv5' weights[0]: 7.959747e-03 [3.286523e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.455239e-08] 
Layer 'fc6' weights[0]: 7.555939e-03 [5.271695e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.552231e-09] 
Layer 'fc7' weights[0]: 7.487424e-03 [6.431602e-08] 
Layer 'fc7' biases: 9.998533e-01 [4.304398e-08] 
Layer 'fc8' weights[0]: 5.776765e-04 [2.272223e-06] 
Layer 'fc8' biases: 1.552033e-01 [3.724947e-05] 
Train error last 27 batches: 0.635774
-------------------------------------------------------
Not saving because 0.628377 > 0.627087 (334.9: -0.00%)
======================================================= (1.812 sec)
352.24... logprob:  0.577846, 0.242188 (0.651 sec)
352.25... logprob:  0.628177, 0.320312 (0.651 sec)
352.26... logprob:  0.674074, 0.390625 (0.651 sec)
352.27... logprob:  0.628033, 0.320312 (0.651 sec)
353.1... logprob:  0.679509, 0.398438 (0.650 sec)
353.2... logprob:  0.597094, 0.273438 (0.650 sec)
353.3... logprob:  0.653783, 0.359375 (0.651 sec)
353.4... logprob:  0.596714, 0.273438 (0.650 sec)
353.5... logprob:  0.590978, 0.265625 (0.650 sec)
353.6... logprob:  0.611422, 0.296875 (0.650 sec)
353.7... logprob:  0.643826, 0.343750 (0.651 sec)
353.8... logprob:  0.604841, 0.289062 (0.649 sec)
353.9... logprob:  0.638547, 0.335938 (0.651 sec)
353.10... logprob:  0.597950, 0.281250 (0.650 sec)
353.11... logprob:  0.638892, 0.335938 (0.650 sec)
353.12... logprob:  0.717821, 0.437500 (0.651 sec)
353.13... logprob:  0.657334, 0.359375 (0.650 sec)
353.14... logprob:  0.662950, 0.367188 (0.649 sec)
353.15... logprob:  0.686039, 0.398438 (0.650 sec)
353.16... logprob:  0.627069, 0.320312 (0.650 sec)
353.17... logprob:  0.638510, 0.335938 (0.652 sec)
353.18... logprob:  0.638222, 0.335938 (0.651 sec)
353.19... logprob:  0.632718, 0.328125 (0.651 sec)
353.20... logprob:  0.648873, 0.351562 (0.651 sec)
353.21... logprob:  0.643428, 0.343750 (0.652 sec)
353.22... logprob:  0.628006, 0.320312 (0.650 sec)
353.23... logprob:  0.623158, 0.312500 (0.651 sec)
353.24... logprob:  0.577832, 0.242188 (0.650 sec)
353.25... logprob:  0.628174, 0.320312 (0.651 sec)
353.26... logprob:  0.674079, 0.390625 (0.651 sec)
353.27... logprob:  0.628031, 0.320312 (0.651 sec)
354.1... logprob:  0.679514, 0.398438 (0.652 sec)
354.2... logprob:  0.597089, 0.273438 (0.651 sec)
354.3... logprob:  0.653785, 0.359375 (0.651 sec)
354.4... logprob:  0.596710, 0.273438 (0.650 sec)
354.5... logprob:  0.590975, 0.265625 (0.650 sec)
354.6... logprob:  0.611422, 0.296875 (0.651 sec)
354.7... logprob:  0.643826, 0.343750 (0.650 sec)
354.8... logprob:  0.604843, 0.289062 (0.650 sec)
354.9... logprob:  0.638545, 0.335938 (0.650 sec)
354.10... logprob:  0.597955, 0.281250 (0.650 sec)
354.11... logprob:  0.638889, 0.335938 (0.650 sec)
354.12... logprob:  0.717799, 0.437500 (0.652 sec)
354.13... logprob:  0.657327, 0.359375 (0.650 sec)
354.14... logprob:  0.662943, 0.367188 (0.650 sec)
354.15... logprob:  0.686030, 0.398438 (0.650 sec)
354.16... logprob:  0.627070, 0.320312 (0.651 sec)
354.17... logprob:  0.638510, 0.335938 (0.652 sec)
354.18... logprob:  0.638222, 0.335938 (0.652 sec)
354.19... logprob:  0.632718, 0.328125 (0.651 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.654180, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941842e-03 [6.773105e-09] 
Layer 'conv1' biases: 5.370661e-07 [1.578852e-10] 
Layer 'conv2' weights[0]: 7.929687e-03 [6.602990e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.653104e-10] 
Layer 'conv3' weights[0]: 7.927404e-03 [5.733608e-09] 
Layer 'conv3' biases: 4.489414e-06 [2.083983e-09] 
Layer 'conv4' weights[0]: 7.960195e-03 [5.680298e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.442859e-08] 
Layer 'conv5' weights[0]: 7.959569e-03 [8.235322e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.723079e-08] 
Layer 'fc6' weights[0]: 7.555750e-03 [9.837752e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.905622e-09] 
Layer 'fc7' weights[0]: 7.485516e-03 [1.224272e-07] 
Layer 'fc7' biases: 9.998536e-01 [1.061660e-07] 
Layer 'fc8' weights[0]: 5.921989e-04 [5.658863e-06] 
Layer 'fc8' biases: 1.562317e-01 [1.086076e-04] 
Train error last 27 batches: 0.635769
-------------------------------------------------------
Not saving because 0.654180 > 0.627087 (334.9: -0.00%)
======================================================= (1.760 sec)
354.20... logprob:  0.648874, 0.351562 (0.652 sec)
354.21... logprob:  0.643428, 0.343750 (0.651 sec)
354.22... logprob:  0.628003, 0.320312 (0.651 sec)
354.23... logprob:  0.623153, 0.312500 (0.650 sec)
354.24... logprob:  0.577816, 0.242188 (0.651 sec)
354.25... logprob:  0.628172, 0.320312 (0.651 sec)
354.26... logprob:  0.674084, 0.390625 (0.652 sec)
354.27... logprob:  0.628028, 0.320312 (0.650 sec)
355.1... logprob:  0.679519, 0.398438 (0.650 sec)
355.2... logprob:  0.597082, 0.273438 (0.650 sec)
355.3... logprob:  0.653786, 0.359375 (0.650 sec)
355.4... logprob:  0.596707, 0.273438 (0.650 sec)
355.5... logprob:  0.590973, 0.265625 (0.651 sec)
355.6... logprob:  0.611421, 0.296875 (0.650 sec)
355.7... logprob:  0.643824, 0.343750 (0.651 sec)
355.8... logprob:  0.604846, 0.289062 (0.650 sec)
355.9... logprob:  0.638544, 0.335938 (0.651 sec)
355.10... logprob:  0.597960, 0.281250 (0.650 sec)
355.11... logprob:  0.638886, 0.335938 (0.650 sec)
355.12... logprob:  0.717778, 0.437500 (0.651 sec)
355.13... logprob:  0.657320, 0.359375 (0.651 sec)
355.14... logprob:  0.662936, 0.367188 (0.649 sec)
355.15... logprob:  0.686022, 0.398438 (0.651 sec)
355.16... logprob:  0.627070, 0.320312 (0.651 sec)
355.17... logprob:  0.638511, 0.335938 (0.652 sec)
355.18... logprob:  0.638223, 0.335938 (0.651 sec)
355.19... logprob:  0.632718, 0.328125 (0.652 sec)
355.20... logprob:  0.648876, 0.351562 (0.651 sec)
355.21... logprob:  0.643428, 0.343750 (0.652 sec)
355.22... logprob:  0.628000, 0.320312 (0.650 sec)
355.23... logprob:  0.623149, 0.312500 (0.650 sec)
355.24... logprob:  0.577799, 0.242188 (0.650 sec)
355.25... logprob:  0.628168, 0.320312 (0.651 sec)
355.26... logprob:  0.674091, 0.390625 (0.651 sec)
355.27... logprob:  0.628025, 0.320312 (0.652 sec)
356.1... logprob:  0.679525, 0.398438 (0.651 sec)
356.2... logprob:  0.597076, 0.273438 (0.650 sec)
356.3... logprob:  0.653788, 0.359375 (0.650 sec)
356.4... logprob:  0.596703, 0.273438 (0.651 sec)
356.5... logprob:  0.590971, 0.265625 (0.650 sec)
356.6... logprob:  0.611422, 0.296875 (0.651 sec)
356.7... logprob:  0.643824, 0.343750 (0.650 sec)
356.8... logprob:  0.604850, 0.289062 (0.650 sec)
356.9... logprob:  0.638543, 0.335938 (0.649 sec)
356.10... logprob:  0.597967, 0.281250 (0.650 sec)
356.11... logprob:  0.638882, 0.335938 (0.650 sec)
356.12... logprob:  0.717750, 0.437500 (0.651 sec)
356.13... logprob:  0.657310, 0.359375 (0.651 sec)
356.14... logprob:  0.662927, 0.367188 (0.651 sec)
356.15... logprob:  0.686010, 0.398438 (0.650 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627106, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941646e-03 [7.307655e-09] 
Layer 'conv1' biases: 5.403054e-07 [2.066142e-10] 
Layer 'conv2' weights[0]: 7.929503e-03 [7.649901e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.032203e-09] 
Layer 'conv3' weights[0]: 7.927208e-03 [6.608337e-09] 
Layer 'conv3' biases: 4.514342e-06 [2.850307e-09] 
Layer 'conv4' weights[0]: 7.959992e-03 [6.664267e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.117810e-08] 
Layer 'conv5' weights[0]: 7.959380e-03 [1.209652e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.284811e-07] 
Layer 'fc6' weights[0]: 7.555558e-03 [1.344674e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.299778e-08] 
Layer 'fc7' weights[0]: 7.483605e-03 [1.660961e-07] 
Layer 'fc7' biases: 9.998539e-01 [1.535064e-07] 
Layer 'fc8' weights[0]: 6.148588e-04 [8.282155e-06] 
Layer 'fc8' biases: 1.574335e-01 [1.586037e-04] 
Train error last 27 batches: 0.635763
-------------------------------------------------------
Not saving because 0.627106 > 0.627087 (334.9: -0.00%)
======================================================= (1.745 sec)
356.16... logprob:  0.627070, 0.320312 (0.651 sec)
356.17... logprob:  0.638510, 0.335938 (0.652 sec)
356.18... logprob:  0.638222, 0.335938 (0.652 sec)
356.19... logprob:  0.632717, 0.328125 (0.651 sec)
356.20... logprob:  0.648877, 0.351562 (0.651 sec)
356.21... logprob:  0.643429, 0.343750 (0.652 sec)
356.22... logprob:  0.627997, 0.320312 (0.650 sec)
356.23... logprob:  0.623144, 0.312500 (0.652 sec)
356.24... logprob:  0.577784, 0.242188 (0.651 sec)
356.25... logprob:  0.628164, 0.320312 (0.651 sec)
356.26... logprob:  0.674098, 0.390625 (0.652 sec)
356.27... logprob:  0.628023, 0.320312 (0.650 sec)
357.1... logprob:  0.679532, 0.398438 (0.651 sec)
357.2... logprob:  0.597068, 0.273438 (0.651 sec)
357.3... logprob:  0.653790, 0.359375 (0.650 sec)
357.4... logprob:  0.596697, 0.273438 (0.650 sec)
357.5... logprob:  0.590966, 0.265625 (0.651 sec)
357.6... logprob:  0.611421, 0.296875 (0.650 sec)
357.7... logprob:  0.643824, 0.343750 (0.650 sec)
357.8... logprob:  0.604851, 0.289062 (0.650 sec)
357.9... logprob:  0.638542, 0.335938 (0.650 sec)
357.10... logprob:  0.597970, 0.281250 (0.650 sec)
357.11... logprob:  0.638880, 0.335938 (0.651 sec)
357.12... logprob:  0.717732, 0.437500 (0.651 sec)
357.13... logprob:  0.657305, 0.359375 (0.651 sec)
357.14... logprob:  0.662920, 0.367188 (0.649 sec)
357.15... logprob:  0.686002, 0.398438 (0.650 sec)
357.16... logprob:  0.627071, 0.320312 (0.650 sec)
357.17... logprob:  0.638510, 0.335938 (0.653 sec)
357.18... logprob:  0.638223, 0.335938 (0.651 sec)
357.19... logprob:  0.632717, 0.328125 (0.652 sec)
357.20... logprob:  0.648878, 0.351562 (0.651 sec)
357.21... logprob:  0.643430, 0.343750 (0.652 sec)
357.22... logprob:  0.627995, 0.320312 (0.651 sec)
357.23... logprob:  0.623140, 0.312500 (0.651 sec)
357.24... logprob:  0.577771, 0.242188 (0.650 sec)
357.25... logprob:  0.628162, 0.320312 (0.652 sec)
357.26... logprob:  0.674102, 0.390625 (0.651 sec)
357.27... logprob:  0.628020, 0.320312 (0.651 sec)
358.1... logprob:  0.679536, 0.398438 (0.651 sec)
358.2... logprob:  0.597064, 0.273438 (0.651 sec)
358.3... logprob:  0.653790, 0.359375 (0.651 sec)
358.4... logprob:  0.596694, 0.273438 (0.651 sec)
358.5... logprob:  0.590966, 0.265625 (0.650 sec)
358.6... logprob:  0.611421, 0.296875 (0.650 sec)
358.7... logprob:  0.643823, 0.343750 (0.650 sec)
358.8... logprob:  0.604854, 0.289062 (0.651 sec)
358.9... logprob:  0.638540, 0.335938 (0.650 sec)
358.10... logprob:  0.597977, 0.281250 (0.650 sec)
358.11... logprob:  0.638877, 0.335938 (0.650 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633125, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941446e-03 [6.785979e-09] 
Layer 'conv1' biases: 5.436109e-07 [1.165629e-10] 
Layer 'conv2' weights[0]: 7.929308e-03 [5.717454e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.662885e-10] 
Layer 'conv3' weights[0]: 7.927005e-03 [5.552378e-09] 
Layer 'conv3' biases: 4.540004e-06 [1.781165e-09] 
Layer 'conv4' weights[0]: 7.959805e-03 [5.645607e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.521148e-08] 
Layer 'conv5' weights[0]: 7.959188e-03 [8.788946e-08] 
Layer 'conv5' biases: 1.000001e+00 [9.346333e-08] 
Layer 'fc6' weights[0]: 7.555365e-03 [1.019726e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.353317e-09] 
Layer 'fc7' weights[0]: 7.481714e-03 [1.256407e-07] 
Layer 'fc7' biases: 9.998542e-01 [1.089903e-07] 
Layer 'fc8' weights[0]: 6.288984e-04 [5.924084e-06] 
Layer 'fc8' biases: 1.584127e-01 [1.361951e-04] 
Train error last 27 batches: 0.635760
-------------------------------------------------------
Not saving because 0.633125 > 0.627087 (334.9: -0.00%)
======================================================= (1.763 sec)
358.12... logprob:  0.717709, 0.437500 (0.652 sec)
358.13... logprob:  0.657297, 0.359375 (0.650 sec)
358.14... logprob:  0.662913, 0.367188 (0.650 sec)
358.15... logprob:  0.685992, 0.398438 (0.650 sec)
358.16... logprob:  0.627070, 0.320312 (0.651 sec)
358.17... logprob:  0.638510, 0.335938 (0.652 sec)
358.18... logprob:  0.638222, 0.335938 (0.652 sec)
358.19... logprob:  0.632716, 0.328125 (0.651 sec)
358.20... logprob:  0.648878, 0.351562 (0.651 sec)
358.21... logprob:  0.643430, 0.343750 (0.651 sec)
358.22... logprob:  0.627993, 0.320312 (0.651 sec)
358.23... logprob:  0.623137, 0.312500 (0.649 sec)
358.24... logprob:  0.577757, 0.242188 (0.651 sec)
358.25... logprob:  0.628159, 0.320312 (0.651 sec)
358.26... logprob:  0.674108, 0.390625 (0.651 sec)
358.27... logprob:  0.628018, 0.320312 (0.650 sec)
359.1... logprob:  0.679542, 0.398438 (0.651 sec)
359.2... logprob:  0.597056, 0.273438 (0.650 sec)
359.3... logprob:  0.653792, 0.359375 (0.651 sec)
359.4... logprob:  0.596689, 0.273438 (0.650 sec)
359.5... logprob:  0.590961, 0.265625 (0.650 sec)
359.6... logprob:  0.611420, 0.296875 (0.650 sec)
359.7... logprob:  0.643823, 0.343750 (0.650 sec)
359.8... logprob:  0.604855, 0.289062 (0.650 sec)
359.9... logprob:  0.638540, 0.335938 (0.650 sec)
359.10... logprob:  0.597980, 0.281250 (0.650 sec)
359.11... logprob:  0.638875, 0.335938 (0.650 sec)
359.12... logprob:  0.717691, 0.437500 (0.651 sec)
359.13... logprob:  0.657290, 0.359375 (0.650 sec)
359.14... logprob:  0.662907, 0.367188 (0.650 sec)
359.15... logprob:  0.685986, 0.398438 (0.651 sec)
359.16... logprob:  0.627071, 0.320312 (0.651 sec)
359.17... logprob:  0.638510, 0.335938 (0.652 sec)
359.18... logprob:  0.638222, 0.335938 (0.651 sec)
359.19... logprob:  0.632715, 0.328125 (0.652 sec)
359.20... logprob:  0.648880, 0.351562 (0.651 sec)
359.21... logprob:  0.643430, 0.343750 (0.653 sec)
359.22... logprob:  0.627989, 0.320312 (0.650 sec)
359.23... logprob:  0.623132, 0.312500 (0.650 sec)
359.24... logprob:  0.577743, 0.242188 (0.651 sec)
359.25... logprob:  0.628156, 0.320312 (0.651 sec)
359.26... logprob:  0.674112, 0.390625 (0.651 sec)
359.27... logprob:  0.628016, 0.320312 (0.652 sec)
360.1... logprob:  0.679546, 0.398438 (0.650 sec)
360.2... logprob:  0.597051, 0.273438 (0.651 sec)
360.3... logprob:  0.653793, 0.359375 (0.650 sec)
360.4... logprob:  0.596686, 0.273438 (0.651 sec)
360.5... logprob:  0.590959, 0.265625 (0.650 sec)
360.6... logprob:  0.611420, 0.296875 (0.651 sec)
360.7... logprob:  0.643823, 0.343750 (0.650 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.688481, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941241e-03 [6.808728e-09] 
Layer 'conv1' biases: 5.472828e-07 [1.278126e-10] 
Layer 'conv2' weights[0]: 7.929123e-03 [5.819381e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.192970e-10] 
Layer 'conv3' weights[0]: 7.926815e-03 [5.644444e-09] 
Layer 'conv3' biases: 4.570663e-06 [1.878583e-09] 
Layer 'conv4' weights[0]: 7.959623e-03 [5.730305e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.620062e-08] 
Layer 'conv5' weights[0]: 7.958987e-03 [9.171188e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.722164e-08] 
Layer 'fc6' weights[0]: 7.555164e-03 [1.059599e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.838399e-09] 
Layer 'fc7' weights[0]: 7.479829e-03 [1.316068e-07] 
Layer 'fc7' biases: 9.998537e-01 [1.162699e-07] 
Layer 'fc8' weights[0]: 6.041682e-04 [6.192191e-06] 
Layer 'fc8' biases: 1.584770e-01 [1.470065e-04] 
Train error last 27 batches: 0.635755
-------------------------------------------------------
Not saving because 0.688481 > 0.627087 (334.9: -0.00%)
======================================================= (1.760 sec)
360.8... logprob:  0.604858, 0.289062 (0.650 sec)
360.9... logprob:  0.638539, 0.335938 (0.650 sec)
360.10... logprob:  0.597986, 0.281250 (0.650 sec)
360.11... logprob:  0.638872, 0.335938 (0.651 sec)
360.12... logprob:  0.717667, 0.437500 (0.651 sec)
360.13... logprob:  0.657283, 0.359375 (0.650 sec)
360.14... logprob:  0.662898, 0.367188 (0.650 sec)
360.15... logprob:  0.685976, 0.398438 (0.649 sec)
360.16... logprob:  0.627070, 0.320312 (0.651 sec)
360.17... logprob:  0.638510, 0.335938 (0.652 sec)
360.18... logprob:  0.638223, 0.335938 (0.651 sec)
360.19... logprob:  0.632716, 0.328125 (0.651 sec)
360.20... logprob:  0.648881, 0.351562 (0.651 sec)
360.21... logprob:  0.643431, 0.343750 (0.651 sec)
360.22... logprob:  0.627987, 0.320312 (0.650 sec)
360.23... logprob:  0.623127, 0.312500 (0.650 sec)
360.24... logprob:  0.577725, 0.242188 (0.651 sec)
360.25... logprob:  0.628152, 0.320312 (0.651 sec)
360.26... logprob:  0.674119, 0.390625 (0.661 sec)
360.27... logprob:  0.628014, 0.320312 (0.650 sec)
361.1... logprob:  0.679553, 0.398438 (0.651 sec)
361.2... logprob:  0.597044, 0.273438 (0.650 sec)
361.3... logprob:  0.653795, 0.359375 (0.650 sec)
361.4... logprob:  0.596681, 0.273438 (0.650 sec)
361.5... logprob:  0.590957, 0.265625 (0.650 sec)
361.6... logprob:  0.611420, 0.296875 (0.650 sec)
361.7... logprob:  0.643822, 0.343750 (0.656 sec)
361.8... logprob:  0.604862, 0.289062 (0.652 sec)
361.9... logprob:  0.638538, 0.335938 (0.651 sec)
361.10... logprob:  0.597992, 0.281250 (0.650 sec)
361.11... logprob:  0.638869, 0.335938 (0.651 sec)
361.12... logprob:  0.717642, 0.437500 (0.652 sec)
361.13... logprob:  0.657275, 0.359375 (0.651 sec)
361.14... logprob:  0.662890, 0.367188 (0.651 sec)
361.15... logprob:  0.685966, 0.398438 (0.650 sec)
361.16... logprob:  0.627071, 0.320312 (0.651 sec)
361.17... logprob:  0.638510, 0.335938 (0.653 sec)
361.18... logprob:  0.638222, 0.335938 (0.651 sec)
361.19... logprob:  0.632715, 0.328125 (0.653 sec)
361.20... logprob:  0.648882, 0.351562 (0.658 sec)
361.21... logprob:  0.643431, 0.343750 (0.653 sec)
361.22... logprob:  0.627984, 0.320312 (0.651 sec)
361.23... logprob:  0.623123, 0.312500 (0.651 sec)
361.24... logprob:  0.577712, 0.242188 (0.651 sec)
361.25... logprob:  0.628148, 0.320312 (0.653 sec)
361.26... logprob:  0.674125, 0.390625 (0.656 sec)
361.27... logprob:  0.628011, 0.320312 (0.652 sec)
362.1... logprob:  0.679558, 0.398438 (0.652 sec)
362.2... logprob:  0.597038, 0.273438 (0.653 sec)
362.3... logprob:  0.653795, 0.359375 (0.654 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633133, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941061e-03 [6.727280e-09] 
Layer 'conv1' biases: 5.509618e-07 [6.456604e-11] 
Layer 'conv2' weights[0]: 7.928913e-03 [4.990184e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.567577e-10] 
Layer 'conv3' weights[0]: 7.926616e-03 [4.455872e-09] 
Layer 'conv3' biases: 4.600678e-06 [6.435132e-10] 
Layer 'conv4' weights[0]: 7.959427e-03 [4.339054e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.069298e-09] 
Layer 'conv5' weights[0]: 7.958799e-03 [1.299053e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.313623e-08] 
Layer 'fc6' weights[0]: 7.554970e-03 [4.055995e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.309913e-09] 
Layer 'fc7' weights[0]: 7.477962e-03 [4.334337e-08] 
Layer 'fc7' biases: 9.998533e-01 [1.590550e-08] 
Layer 'fc8' weights[0]: 5.827683e-04 [8.374635e-07] 
Layer 'fc8' biases: 1.585951e-01 [2.651324e-05] 
Train error last 27 batches: 0.635750
-------------------------------------------------------
Not saving because 0.633133 > 0.627087 (334.9: -0.00%)
======================================================= (1.870 sec)
362.4... logprob:  0.596677, 0.273438 (0.654 sec)
362.5... logprob:  0.590953, 0.265625 (0.653 sec)
362.6... logprob:  0.611419, 0.296875 (0.660 sec)
362.7... logprob:  0.643822, 0.343750 (0.651 sec)
362.8... logprob:  0.604863, 0.289062 (0.650 sec)
362.9... logprob:  0.638536, 0.335938 (0.650 sec)
362.10... logprob:  0.597996, 0.281250 (0.650 sec)
362.11... logprob:  0.638866, 0.335938 (0.650 sec)
362.12... logprob:  0.717625, 0.437500 (0.652 sec)
362.13... logprob:  0.657269, 0.359375 (0.650 sec)
362.14... logprob:  0.662884, 0.367188 (0.650 sec)
362.15... logprob:  0.685959, 0.398438 (0.651 sec)
362.16... logprob:  0.627071, 0.320312 (0.651 sec)
362.17... logprob:  0.638509, 0.335938 (0.652 sec)
362.18... logprob:  0.638223, 0.335938 (0.652 sec)
362.19... logprob:  0.632715, 0.328125 (0.651 sec)
362.20... logprob:  0.648883, 0.351562 (0.651 sec)
362.21... logprob:  0.643431, 0.343750 (0.653 sec)
362.22... logprob:  0.627982, 0.320312 (0.650 sec)
362.23... logprob:  0.623119, 0.312500 (0.652 sec)
362.24... logprob:  0.577697, 0.242188 (0.652 sec)
362.25... logprob:  0.628146, 0.320312 (0.651 sec)
362.26... logprob:  0.674130, 0.390625 (0.652 sec)
362.27... logprob:  0.628009, 0.320312 (0.651 sec)
363.1... logprob:  0.679563, 0.398438 (0.651 sec)
363.2... logprob:  0.597032, 0.273438 (0.651 sec)
363.3... logprob:  0.653797, 0.359375 (0.651 sec)
363.4... logprob:  0.596673, 0.273438 (0.650 sec)
363.5... logprob:  0.590952, 0.265625 (0.651 sec)
363.6... logprob:  0.611420, 0.296875 (0.651 sec)
363.7... logprob:  0.643821, 0.343750 (0.650 sec)
363.8... logprob:  0.604866, 0.289062 (0.651 sec)
363.9... logprob:  0.638535, 0.335938 (0.650 sec)
363.10... logprob:  0.598001, 0.281250 (0.650 sec)
363.11... logprob:  0.638863, 0.335938 (0.651 sec)
363.12... logprob:  0.717603, 0.437500 (0.652 sec)
363.13... logprob:  0.657261, 0.359375 (0.651 sec)
363.14... logprob:  0.662877, 0.367188 (0.650 sec)
363.15... logprob:  0.685951, 0.398438 (0.651 sec)
363.16... logprob:  0.627071, 0.320312 (0.651 sec)
363.17... logprob:  0.638509, 0.335938 (0.653 sec)
363.18... logprob:  0.638223, 0.335938 (0.652 sec)
363.19... logprob:  0.632714, 0.328125 (0.651 sec)
363.20... logprob:  0.648885, 0.351562 (0.651 sec)
363.21... logprob:  0.643432, 0.343750 (0.652 sec)
363.22... logprob:  0.627979, 0.320312 (0.650 sec)
363.23... logprob:  0.623114, 0.312500 (0.651 sec)
363.24... logprob:  0.577680, 0.242188 (0.650 sec)
363.25... logprob:  0.628142, 0.320312 (0.651 sec)
363.26... logprob:  0.674137, 0.390625 (0.651 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.628082, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940839e-03 [6.527430e-09] 
Layer 'conv1' biases: 5.544564e-07 [7.002832e-11] 
Layer 'conv2' weights[0]: 7.928704e-03 [5.011483e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.442157e-10] 
Layer 'conv3' weights[0]: 7.926423e-03 [4.419344e-09] 
Layer 'conv3' biases: 4.628571e-06 [6.151115e-10] 
Layer 'conv4' weights[0]: 7.959231e-03 [4.319123e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.646017e-09] 
Layer 'conv5' weights[0]: 7.958606e-03 [1.013546e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.837323e-09] 
Layer 'fc6' weights[0]: 7.554768e-03 [3.939734e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.814949e-10] 
Layer 'fc7' weights[0]: 7.476034e-03 [4.086998e-08] 
Layer 'fc7' biases: 9.998530e-01 [1.196048e-08] 
Layer 'fc8' weights[0]: 5.796316e-04 [5.990024e-07] 
Layer 'fc8' biases: 1.591768e-01 [2.542960e-05] 
Train error last 27 batches: 0.635745
-------------------------------------------------------
Not saving because 0.628082 > 0.627087 (334.9: -0.00%)
======================================================= (1.876 sec)
363.27... logprob:  0.628006, 0.320312 (0.651 sec)
364.1... logprob:  0.679570, 0.398438 (0.651 sec)
364.2... logprob:  0.597025, 0.273438 (0.651 sec)
364.3... logprob:  0.653799, 0.359375 (0.650 sec)
364.4... logprob:  0.596669, 0.273438 (0.651 sec)
364.5... logprob:  0.590949, 0.265625 (0.651 sec)
364.6... logprob:  0.611419, 0.296875 (0.651 sec)
364.7... logprob:  0.643821, 0.343750 (0.651 sec)
364.8... logprob:  0.604869, 0.289062 (0.651 sec)
364.9... logprob:  0.638535, 0.335938 (0.650 sec)
364.10... logprob:  0.598008, 0.281250 (0.650 sec)
364.11... logprob:  0.638860, 0.335938 (0.650 sec)
364.12... logprob:  0.717575, 0.437500 (0.652 sec)
364.13... logprob:  0.657253, 0.359375 (0.651 sec)
364.14... logprob:  0.662868, 0.367188 (0.651 sec)
364.15... logprob:  0.685938, 0.398438 (0.650 sec)
364.16... logprob:  0.627071, 0.320312 (0.651 sec)
364.17... logprob:  0.638509, 0.335938 (0.652 sec)
364.18... logprob:  0.638221, 0.335938 (0.652 sec)
364.19... logprob:  0.632714, 0.328125 (0.652 sec)
364.20... logprob:  0.648885, 0.351562 (0.651 sec)
364.21... logprob:  0.643433, 0.343750 (0.652 sec)
364.22... logprob:  0.627977, 0.320312 (0.650 sec)
364.23... logprob:  0.623111, 0.312500 (0.650 sec)
364.24... logprob:  0.577668, 0.242188 (0.651 sec)
364.25... logprob:  0.628140, 0.320312 (0.652 sec)
364.26... logprob:  0.674141, 0.390625 (0.652 sec)
364.27... logprob:  0.628005, 0.320312 (0.651 sec)
365.1... logprob:  0.679575, 0.398438 (0.651 sec)
365.2... logprob:  0.597019, 0.273438 (0.650 sec)
365.3... logprob:  0.653800, 0.359375 (0.651 sec)
365.4... logprob:  0.596664, 0.273438 (0.651 sec)
365.5... logprob:  0.590944, 0.265625 (0.651 sec)
365.6... logprob:  0.611418, 0.296875 (0.651 sec)
365.7... logprob:  0.643821, 0.343750 (0.651 sec)
365.8... logprob:  0.604870, 0.289062 (0.650 sec)
365.9... logprob:  0.638534, 0.335938 (0.651 sec)
365.10... logprob:  0.598010, 0.281250 (0.650 sec)
365.11... logprob:  0.638858, 0.335938 (0.651 sec)
365.12... logprob:  0.717561, 0.437500 (0.651 sec)
365.13... logprob:  0.657249, 0.359375 (0.651 sec)
365.14... logprob:  0.662863, 0.367188 (0.650 sec)
365.15... logprob:  0.685934, 0.398438 (0.650 sec)
365.16... logprob:  0.627071, 0.320312 (0.651 sec)
365.17... logprob:  0.638509, 0.335938 (0.652 sec)
365.18... logprob:  0.638222, 0.335938 (0.651 sec)
365.19... logprob:  0.632713, 0.328125 (0.651 sec)
365.20... logprob:  0.648888, 0.351562 (0.651 sec)
365.21... logprob:  0.643433, 0.343750 (0.652 sec)
365.22... logprob:  0.627973, 0.320312 (0.650 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.653599, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940644e-03 [6.719022e-09] 
Layer 'conv1' biases: 5.579616e-07 [1.352668e-10] 
Layer 'conv2' weights[0]: 7.928511e-03 [6.068296e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.968915e-10] 
Layer 'conv3' weights[0]: 7.926232e-03 [5.275657e-09] 
Layer 'conv3' biases: 4.656852e-06 [1.608083e-09] 
Layer 'conv4' weights[0]: 7.959041e-03 [5.160767e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.007351e-08] 
Layer 'conv5' weights[0]: 7.958423e-03 [5.743870e-08] 
Layer 'conv5' biases: 1.000002e+00 [6.058170e-08] 
Layer 'fc6' weights[0]: 7.554562e-03 [7.361806e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.209155e-09] 
Layer 'fc7' weights[0]: 7.474118e-03 [9.200664e-08] 
Layer 'fc7' biases: 9.998528e-01 [7.422702e-08] 
Layer 'fc8' weights[0]: 5.760298e-04 [3.895087e-06] 
Layer 'fc8' biases: 1.597213e-01 [7.541397e-05] 
Train error last 27 batches: 0.635741
-------------------------------------------------------
Not saving because 0.653599 > 0.627087 (334.9: -0.00%)
======================================================= (1.777 sec)
365.23... logprob:  0.623106, 0.312500 (0.650 sec)
365.24... logprob:  0.577651, 0.242188 (0.651 sec)
365.25... logprob:  0.628137, 0.320312 (0.651 sec)
365.26... logprob:  0.674147, 0.390625 (0.651 sec)
365.27... logprob:  0.628002, 0.320312 (0.651 sec)
366.1... logprob:  0.679579, 0.398438 (0.651 sec)
366.2... logprob:  0.597014, 0.273438 (0.734 sec)
366.3... logprob:  0.653801, 0.359375 (0.651 sec)
366.4... logprob:  0.596662, 0.273438 (0.651 sec)
366.5... logprob:  0.590945, 0.265625 (0.650 sec)
366.6... logprob:  0.611420, 0.296875 (0.651 sec)
366.7... logprob:  0.643819, 0.343750 (0.650 sec)
366.8... logprob:  0.604875, 0.289062 (0.650 sec)
366.9... logprob:  0.638532, 0.335938 (0.650 sec)
366.10... logprob:  0.598018, 0.281250 (0.650 sec)
366.11... logprob:  0.638854, 0.335938 (0.651 sec)
366.12... logprob:  0.717532, 0.437500 (0.651 sec)
366.13... logprob:  0.657238, 0.359375 (0.651 sec)
366.14... logprob:  0.662853, 0.367188 (0.651 sec)
366.15... logprob:  0.685921, 0.398438 (0.650 sec)
366.16... logprob:  0.627071, 0.320312 (0.651 sec)
366.17... logprob:  0.638509, 0.335938 (0.652 sec)
366.18... logprob:  0.638221, 0.335938 (0.652 sec)
366.19... logprob:  0.632713, 0.328125 (0.651 sec)
366.20... logprob:  0.648887, 0.351562 (0.651 sec)
366.21... logprob:  0.643433, 0.343750 (0.652 sec)
366.22... logprob:  0.627972, 0.320312 (0.651 sec)
366.23... logprob:  0.623103, 0.312500 (0.650 sec)
366.24... logprob:  0.577638, 0.242188 (0.651 sec)
366.25... logprob:  0.628133, 0.320312 (0.651 sec)
366.26... logprob:  0.674152, 0.390625 (0.651 sec)
366.27... logprob:  0.627999, 0.320312 (0.651 sec)
367.1... logprob:  0.679586, 0.398438 (0.651 sec)
367.2... logprob:  0.597006, 0.273438 (0.650 sec)
367.3... logprob:  0.653803, 0.359375 (0.651 sec)
367.4... logprob:  0.596654, 0.273438 (0.650 sec)
367.5... logprob:  0.590937, 0.265625 (0.651 sec)
367.6... logprob:  0.611417, 0.296875 (0.651 sec)
367.7... logprob:  0.643820, 0.343750 (0.650 sec)
367.8... logprob:  0.604874, 0.289062 (0.650 sec)
367.9... logprob:  0.638532, 0.335938 (0.650 sec)
367.10... logprob:  0.598020, 0.281250 (0.651 sec)
367.11... logprob:  0.638852, 0.335938 (0.651 sec)
367.12... logprob:  0.717519, 0.437500 (0.651 sec)
367.13... logprob:  0.657233, 0.359375 (0.651 sec)
367.14... logprob:  0.662849, 0.367188 (0.650 sec)
367.15... logprob:  0.685916, 0.398438 (0.650 sec)
367.16... logprob:  0.627072, 0.320312 (0.651 sec)
367.17... logprob:  0.638507, 0.335938 (0.653 sec)
367.18... logprob:  0.638222, 0.335938 (0.651 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627461, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940458e-03 [6.512068e-09] 
Layer 'conv1' biases: 5.612656e-07 [1.734726e-10] 
Layer 'conv2' weights[0]: 7.928321e-03 [6.750660e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.407267e-10] 
Layer 'conv3' weights[0]: 7.926042e-03 [5.922536e-09] 
Layer 'conv3' biases: 4.682278e-06 [2.285949e-09] 
Layer 'conv4' weights[0]: 7.958843e-03 [5.919296e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.652948e-08] 
Layer 'conv5' weights[0]: 7.958235e-03 [9.380543e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.937377e-08] 
Layer 'fc6' weights[0]: 7.554360e-03 [1.078106e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.011056e-08] 
Layer 'fc7' weights[0]: 7.472233e-03 [1.341197e-07] 
Layer 'fc7' biases: 9.998536e-01 [1.195877e-07] 
Layer 'fc8' weights[0]: 5.930616e-04 [6.361604e-06] 
Layer 'fc8' biases: 1.608042e-01 [1.253483e-04] 
Train error last 27 batches: 0.635735
-------------------------------------------------------
Not saving because 0.627461 > 0.627087 (334.9: -0.00%)
======================================================= (1.755 sec)
367.19... logprob:  0.632712, 0.328125 (0.652 sec)
367.20... logprob:  0.648889, 0.351562 (0.651 sec)
367.21... logprob:  0.643434, 0.343750 (0.652 sec)
367.22... logprob:  0.627969, 0.320312 (0.650 sec)
367.23... logprob:  0.623099, 0.312500 (0.650 sec)
367.24... logprob:  0.577626, 0.242188 (0.651 sec)
367.25... logprob:  0.628132, 0.320312 (0.652 sec)
367.26... logprob:  0.674157, 0.390625 (0.651 sec)
367.27... logprob:  0.627998, 0.320312 (0.651 sec)
368.1... logprob:  0.679589, 0.398438 (0.651 sec)
368.2... logprob:  0.597003, 0.273438 (0.651 sec)
368.3... logprob:  0.653803, 0.359375 (0.651 sec)
368.4... logprob:  0.596654, 0.273438 (0.651 sec)
368.5... logprob:  0.590938, 0.265625 (0.650 sec)
368.6... logprob:  0.611419, 0.296875 (0.651 sec)
368.7... logprob:  0.643819, 0.343750 (0.651 sec)
368.8... logprob:  0.604878, 0.289062 (0.650 sec)
368.9... logprob:  0.638530, 0.335938 (0.651 sec)
368.10... logprob:  0.598026, 0.281250 (0.651 sec)
368.11... logprob:  0.638849, 0.335938 (0.650 sec)
368.12... logprob:  0.717495, 0.437500 (0.653 sec)
368.13... logprob:  0.657225, 0.359375 (0.651 sec)
368.14... logprob:  0.662841, 0.367188 (0.650 sec)
368.15... logprob:  0.685906, 0.398438 (0.652 sec)
368.16... logprob:  0.627072, 0.320312 (0.651 sec)
368.17... logprob:  0.638508, 0.335938 (0.652 sec)
368.18... logprob:  0.638221, 0.335938 (0.652 sec)
368.19... logprob:  0.632711, 0.328125 (0.651 sec)
368.20... logprob:  0.648889, 0.351562 (0.651 sec)
368.21... logprob:  0.643434, 0.343750 (0.652 sec)
368.22... logprob:  0.627966, 0.320312 (0.651 sec)
368.23... logprob:  0.623094, 0.312500 (0.650 sec)
368.24... logprob:  0.577610, 0.242188 (0.651 sec)
368.25... logprob:  0.628128, 0.320312 (0.651 sec)
368.26... logprob:  0.674163, 0.390625 (0.652 sec)
368.27... logprob:  0.627995, 0.320312 (0.651 sec)
369.1... logprob:  0.679596, 0.398438 (0.651 sec)
369.2... logprob:  0.596994, 0.273438 (0.650 sec)
369.3... logprob:  0.653805, 0.359375 (0.651 sec)
369.4... logprob:  0.596648, 0.273438 (0.651 sec)
369.5... logprob:  0.590934, 0.265625 (0.651 sec)
369.6... logprob:  0.611417, 0.296875 (0.650 sec)
369.7... logprob:  0.643819, 0.343750 (0.651 sec)
369.8... logprob:  0.604879, 0.289062 (0.650 sec)
369.9... logprob:  0.638530, 0.335938 (0.650 sec)
369.10... logprob:  0.598030, 0.281250 (0.650 sec)
369.11... logprob:  0.638847, 0.335938 (0.650 sec)
369.12... logprob:  0.717476, 0.437500 (0.652 sec)
369.13... logprob:  0.657219, 0.359375 (0.651 sec)
369.14... logprob:  0.662835, 0.367188 (0.650 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.632917, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940250e-03 [6.760752e-09] 
Layer 'conv1' biases: 5.644902e-07 [1.507061e-10] 
Layer 'conv2' weights[0]: 7.928136e-03 [6.236709e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.791339e-10] 
Layer 'conv3' weights[0]: 7.925847e-03 [5.441340e-09] 
Layer 'conv3' biases: 4.707016e-06 [1.874059e-09] 
Layer 'conv4' weights[0]: 7.958649e-03 [5.397662e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.240667e-08] 
Layer 'conv5' weights[0]: 7.958066e-03 [7.069391e-08] 
Layer 'conv5' biases: 1.000002e+00 [7.494429e-08] 
Layer 'fc6' weights[0]: 7.554150e-03 [8.596036e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.574780e-09] 
Layer 'fc7' weights[0]: 7.470312e-03 [1.067344e-07] 
Layer 'fc7' biases: 9.998536e-01 [8.928497e-08] 
Layer 'fc8' weights[0]: 6.173427e-04 [4.775065e-06] 
Layer 'fc8' biases: 1.620357e-01 [8.729556e-05] 
Train error last 27 batches: 0.635731
-------------------------------------------------------
Not saving because 0.632917 > 0.627087 (334.9: -0.00%)
======================================================= (1.769 sec)
369.15... logprob:  0.685899, 0.398438 (0.651 sec)
369.16... logprob:  0.627072, 0.320312 (0.651 sec)
369.17... logprob:  0.638508, 0.335938 (0.653 sec)
369.18... logprob:  0.638221, 0.335938 (0.652 sec)
369.19... logprob:  0.632711, 0.328125 (0.651 sec)
369.20... logprob:  0.648891, 0.351562 (0.651 sec)
369.21... logprob:  0.643435, 0.343750 (0.652 sec)
369.22... logprob:  0.627964, 0.320312 (0.650 sec)
369.23... logprob:  0.623090, 0.312500 (0.651 sec)
369.24... logprob:  0.577596, 0.242188 (0.650 sec)
369.25... logprob:  0.628125, 0.320312 (0.651 sec)
369.26... logprob:  0.674169, 0.390625 (0.652 sec)
369.27... logprob:  0.627992, 0.320312 (0.651 sec)
370.1... logprob:  0.679600, 0.398438 (0.651 sec)
370.2... logprob:  0.596990, 0.273438 (0.651 sec)
370.3... logprob:  0.653806, 0.359375 (0.650 sec)
370.4... logprob:  0.596644, 0.273438 (0.651 sec)
370.5... logprob:  0.590932, 0.265625 (0.651 sec)
370.6... logprob:  0.611418, 0.296875 (0.650 sec)
370.7... logprob:  0.643818, 0.343750 (0.651 sec)
370.8... logprob:  0.604882, 0.289062 (0.651 sec)
370.9... logprob:  0.638528, 0.335938 (0.650 sec)
370.10... logprob:  0.598036, 0.281250 (0.650 sec)
370.11... logprob:  0.638844, 0.335938 (0.651 sec)
370.12... logprob:  0.717453, 0.437500 (0.652 sec)
370.13... logprob:  0.657211, 0.359375 (0.651 sec)
370.14... logprob:  0.662827, 0.367188 (0.651 sec)
370.15... logprob:  0.685889, 0.398438 (0.650 sec)
370.16... logprob:  0.627073, 0.320312 (0.651 sec)
370.17... logprob:  0.638508, 0.335938 (0.652 sec)
370.18... logprob:  0.638221, 0.335938 (0.652 sec)
370.19... logprob:  0.632711, 0.328125 (0.651 sec)
370.20... logprob:  0.648892, 0.351562 (0.651 sec)
370.21... logprob:  0.643435, 0.343750 (0.652 sec)
370.22... logprob:  0.627961, 0.320312 (0.650 sec)
370.23... logprob:  0.623086, 0.312500 (0.651 sec)
370.24... logprob:  0.577580, 0.242188 (0.653 sec)
370.25... logprob:  0.628122, 0.320312 (0.651 sec)
370.26... logprob:  0.674175, 0.390625 (0.652 sec)
370.27... logprob:  0.627990, 0.320312 (0.651 sec)
371.1... logprob:  0.679607, 0.398438 (0.651 sec)
371.2... logprob:  0.596982, 0.273438 (0.651 sec)
371.3... logprob:  0.653808, 0.359375 (0.651 sec)
371.4... logprob:  0.596640, 0.273438 (0.650 sec)
371.5... logprob:  0.590928, 0.265625 (0.650 sec)
371.6... logprob:  0.611417, 0.296875 (0.650 sec)
371.7... logprob:  0.643818, 0.343750 (0.651 sec)
371.8... logprob:  0.604885, 0.289062 (0.650 sec)
371.9... logprob:  0.638527, 0.335938 (0.650 sec)
371.10... logprob:  0.598042, 0.281250 (0.650 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.692164, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940060e-03 [7.041691e-09] 
Layer 'conv1' biases: 5.679339e-07 [1.446661e-10] 
Layer 'conv2' weights[0]: 7.927951e-03 [6.268515e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.440806e-10] 
Layer 'conv3' weights[0]: 7.925649e-03 [6.102024e-09] 
Layer 'conv3' biases: 4.734407e-06 [2.234821e-09] 
Layer 'conv4' weights[0]: 7.958451e-03 [6.261169e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.939298e-08] 
Layer 'conv5' weights[0]: 7.957872e-03 [1.101386e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.166182e-07] 
Layer 'fc6' weights[0]: 7.553953e-03 [1.232540e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.177239e-08] 
Layer 'fc7' weights[0]: 7.468417e-03 [1.508689e-07] 
Layer 'fc7' biases: 9.998537e-01 [1.371954e-07] 
Layer 'fc8' weights[0]: 6.185466e-04 [7.362459e-06] 
Layer 'fc8' biases: 1.627016e-01 [1.704574e-04] 
Train error last 27 batches: 0.635727
-------------------------------------------------------
Not saving because 0.692164 > 0.627087 (334.9: -0.00%)
======================================================= (1.755 sec)
371.11... logprob:  0.638841, 0.335938 (0.651 sec)
371.12... logprob:  0.717430, 0.437500 (0.652 sec)
371.13... logprob:  0.657204, 0.359375 (0.651 sec)
371.14... logprob:  0.662819, 0.367188 (0.650 sec)
371.15... logprob:  0.685879, 0.398438 (0.653 sec)
371.16... logprob:  0.627073, 0.320312 (0.651 sec)
371.17... logprob:  0.638507, 0.335938 (0.653 sec)
371.18... logprob:  0.638222, 0.335938 (0.651 sec)
371.19... logprob:  0.632711, 0.328125 (0.652 sec)
371.20... logprob:  0.648893, 0.351562 (0.735 sec)
371.21... logprob:  0.643436, 0.343750 (0.652 sec)
371.22... logprob:  0.627959, 0.320312 (0.651 sec)
371.23... logprob:  0.623082, 0.312500 (0.651 sec)
371.24... logprob:  0.577566, 0.242188 (0.651 sec)
371.25... logprob:  0.628119, 0.320312 (0.652 sec)
371.26... logprob:  0.674181, 0.390625 (0.652 sec)
371.27... logprob:  0.627988, 0.320312 (0.651 sec)
372.1... logprob:  0.679613, 0.398438 (0.651 sec)
372.2... logprob:  0.596976, 0.273438 (0.651 sec)
372.3... logprob:  0.653809, 0.359375 (0.651 sec)
372.4... logprob:  0.596636, 0.273438 (0.651 sec)
372.5... logprob:  0.590926, 0.265625 (0.650 sec)
372.6... logprob:  0.611417, 0.296875 (0.651 sec)
372.7... logprob:  0.643818, 0.343750 (0.650 sec)
372.8... logprob:  0.604888, 0.289062 (0.650 sec)
372.9... logprob:  0.638526, 0.335938 (0.651 sec)
372.10... logprob:  0.598047, 0.281250 (0.650 sec)
372.11... logprob:  0.638838, 0.335938 (0.651 sec)
372.12... logprob:  0.717410, 0.437500 (0.652 sec)
372.13... logprob:  0.657197, 0.359375 (0.651 sec)
372.14... logprob:  0.662813, 0.367188 (0.651 sec)
372.15... logprob:  0.685872, 0.398438 (0.650 sec)
372.16... logprob:  0.627073, 0.320312 (0.651 sec)
372.17... logprob:  0.638508, 0.335938 (0.652 sec)
372.18... logprob:  0.638222, 0.335938 (0.652 sec)
372.19... logprob:  0.632710, 0.328125 (0.651 sec)
372.20... logprob:  0.648894, 0.351562 (0.651 sec)
372.21... logprob:  0.643436, 0.343750 (0.652 sec)
372.22... logprob:  0.627956, 0.320312 (0.650 sec)
372.23... logprob:  0.623078, 0.312500 (0.652 sec)
372.24... logprob:  0.577552, 0.242188 (0.651 sec)
372.25... logprob:  0.628116, 0.320312 (0.651 sec)
372.26... logprob:  0.674186, 0.390625 (0.652 sec)
372.27... logprob:  0.627986, 0.320312 (0.651 sec)
373.1... logprob:  0.679618, 0.398438 (0.650 sec)
373.2... logprob:  0.596971, 0.273438 (0.651 sec)
373.3... logprob:  0.653810, 0.359375 (0.651 sec)
373.4... logprob:  0.596632, 0.273438 (0.650 sec)
373.5... logprob:  0.590923, 0.265625 (0.651 sec)
373.6... logprob:  0.611417, 0.296875 (0.651 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.632858, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.939870e-03 [7.337741e-09] 
Layer 'conv1' biases: 5.716186e-07 [1.615601e-10] 
Layer 'conv2' weights[0]: 7.927783e-03 [6.254104e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.618610e-10] 
Layer 'conv3' weights[0]: 7.925438e-03 [6.042631e-09] 
Layer 'conv3' biases: 4.764973e-06 [2.207980e-09] 
Layer 'conv4' weights[0]: 7.958278e-03 [6.116079e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.909937e-08] 
Layer 'conv5' weights[0]: 7.957657e-03 [1.085971e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.147253e-07] 
Layer 'fc6' weights[0]: 7.553756e-03 [1.224959e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.168998e-08] 
Layer 'fc7' weights[0]: 7.466529e-03 [1.514603e-07] 
Layer 'fc7' biases: 9.998531e-01 [1.378662e-07] 
Layer 'fc8' weights[0]: 5.942826e-04 [7.285884e-06] 
Layer 'fc8' biases: 1.627436e-01 [1.751701e-04] 
Train error last 27 batches: 0.635722
-------------------------------------------------------
Not saving because 0.632858 > 0.627087 (334.9: -0.00%)
======================================================= (1.753 sec)
373.7... logprob:  0.643817, 0.343750 (0.651 sec)
373.8... logprob:  0.604890, 0.289062 (0.650 sec)
373.9... logprob:  0.638525, 0.335938 (0.650 sec)
373.10... logprob:  0.598052, 0.281250 (0.651 sec)
373.11... logprob:  0.638835, 0.335938 (0.651 sec)
373.12... logprob:  0.717388, 0.437500 (0.651 sec)
373.13... logprob:  0.657190, 0.359375 (0.651 sec)
373.14... logprob:  0.662805, 0.367188 (0.734 sec)
373.15... logprob:  0.685861, 0.398438 (0.650 sec)
373.16... logprob:  0.627074, 0.320312 (0.651 sec)
373.17... logprob:  0.638507, 0.335938 (0.652 sec)
373.18... logprob:  0.638221, 0.335938 (0.651 sec)
373.19... logprob:  0.632710, 0.328125 (0.652 sec)
373.20... logprob:  0.648895, 0.351562 (0.651 sec)
373.21... logprob:  0.643436, 0.343750 (0.651 sec)
373.22... logprob:  0.627954, 0.320312 (0.650 sec)
373.23... logprob:  0.623075, 0.312500 (0.650 sec)
373.24... logprob:  0.577540, 0.242188 (0.650 sec)
373.25... logprob:  0.628113, 0.320312 (0.652 sec)
373.26... logprob:  0.674190, 0.390625 (0.651 sec)
373.27... logprob:  0.627984, 0.320312 (0.651 sec)
374.1... logprob:  0.679622, 0.398438 (0.651 sec)
374.2... logprob:  0.596965, 0.273438 (0.651 sec)
374.3... logprob:  0.653812, 0.359375 (0.650 sec)
374.4... logprob:  0.596627, 0.273438 (0.651 sec)
374.5... logprob:  0.590919, 0.265625 (0.651 sec)
374.6... logprob:  0.611416, 0.296875 (0.650 sec)
374.7... logprob:  0.643817, 0.343750 (0.650 sec)
374.8... logprob:  0.604891, 0.289062 (0.650 sec)
374.9... logprob:  0.638524, 0.335938 (0.650 sec)
374.10... logprob:  0.598055, 0.281250 (0.651 sec)
374.11... logprob:  0.638833, 0.335938 (0.651 sec)
374.12... logprob:  0.717372, 0.437500 (0.651 sec)
374.13... logprob:  0.657185, 0.359375 (0.651 sec)
374.14... logprob:  0.662800, 0.367188 (0.650 sec)
374.15... logprob:  0.685855, 0.398438 (0.651 sec)
374.16... logprob:  0.627074, 0.320312 (0.651 sec)
374.17... logprob:  0.638507, 0.335938 (0.652 sec)
374.18... logprob:  0.638221, 0.335938 (0.652 sec)
374.19... logprob:  0.632709, 0.328125 (0.651 sec)
374.20... logprob:  0.648895, 0.351562 (0.652 sec)
374.21... logprob:  0.643436, 0.343750 (0.652 sec)
374.22... logprob:  0.627952, 0.320312 (0.651 sec)
374.23... logprob:  0.623072, 0.312500 (0.650 sec)
374.24... logprob:  0.577528, 0.242188 (0.651 sec)
374.25... logprob:  0.628111, 0.320312 (0.652 sec)
374.26... logprob:  0.674195, 0.390625 (0.652 sec)
374.27... logprob:  0.627982, 0.320312 (0.651 sec)
375.1... logprob:  0.679627, 0.398438 (0.651 sec)
375.2... logprob:  0.596959, 0.273438 (0.650 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627982, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.939662e-03 [6.865907e-09] 
Layer 'conv1' biases: 5.752521e-07 [7.199081e-11] 
Layer 'conv2' weights[0]: 7.927586e-03 [4.990109e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.853588e-10] 
Layer 'conv3' weights[0]: 7.925249e-03 [4.556015e-09] 
Layer 'conv3' biases: 4.794366e-06 [7.956621e-10] 
Layer 'conv4' weights[0]: 7.958107e-03 [4.457526e-09] 
Layer 'conv4' biases: 1.000001e+00 [4.535333e-09] 
Layer 'conv5' weights[0]: 7.957460e-03 [2.657672e-08] 
Layer 'conv5' biases: 1.000002e+00 [2.774982e-08] 
Layer 'fc6' weights[0]: 7.553566e-03 [4.856802e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.788871e-09] 
Layer 'fc7' weights[0]: 7.464638e-03 [5.646557e-08] 
Layer 'fc7' biases: 9.998528e-01 [3.303796e-08] 
Layer 'fc8' weights[0]: 5.782150e-04 [1.724034e-06] 
Layer 'fc8' biases: 1.629751e-01 [4.915620e-05] 
Train error last 27 batches: 0.635718
-------------------------------------------------------
Not saving because 0.627982 > 0.627087 (334.9: -0.00%)
======================================================= (1.830 sec)
375.3... logprob:  0.653812, 0.359375 (0.651 sec)
375.4... logprob:  0.596623, 0.273438 (0.651 sec)
375.5... logprob:  0.590917, 0.265625 (0.650 sec)
375.6... logprob:  0.611416, 0.296875 (0.651 sec)
375.7... logprob:  0.643816, 0.343750 (0.651 sec)
375.8... logprob:  0.604893, 0.289062 (0.650 sec)
375.9... logprob:  0.638523, 0.335938 (0.650 sec)
375.10... logprob:  0.598059, 0.281250 (0.650 sec)
375.11... logprob:  0.638831, 0.335938 (0.651 sec)
375.12... logprob:  0.717354, 0.437500 (0.653 sec)
375.13... logprob:  0.657179, 0.359375 (0.651 sec)
375.14... logprob:  0.662794, 0.367188 (0.650 sec)
375.15... logprob:  0.685848, 0.398438 (0.651 sec)
375.16... logprob:  0.627074, 0.320312 (0.651 sec)
375.17... logprob:  0.638507, 0.335938 (0.654 sec)
375.18... logprob:  0.638222, 0.335938 (0.652 sec)
375.19... logprob:  0.632709, 0.328125 (0.652 sec)
375.20... logprob:  0.648898, 0.351562 (0.651 sec)
375.21... logprob:  0.643437, 0.343750 (0.652 sec)
375.22... logprob:  0.627949, 0.320312 (0.650 sec)
375.23... logprob:  0.623066, 0.312500 (0.650 sec)
375.24... logprob:  0.577511, 0.242188 (0.650 sec)
375.25... logprob:  0.628107, 0.320312 (0.651 sec)
375.26... logprob:  0.674201, 0.390625 (0.652 sec)
375.27... logprob:  0.627979, 0.320312 (0.651 sec)
376.1... logprob:  0.679632, 0.398438 (0.650 sec)
376.2... logprob:  0.596953, 0.273438 (0.650 sec)
376.3... logprob:  0.653814, 0.359375 (0.651 sec)
376.4... logprob:  0.596621, 0.273438 (0.650 sec)
376.5... logprob:  0.590915, 0.265625 (0.650 sec)
376.6... logprob:  0.611416, 0.296875 (0.651 sec)
376.7... logprob:  0.643816, 0.343750 (0.650 sec)
376.8... logprob:  0.604897, 0.289062 (0.650 sec)
376.9... logprob:  0.638522, 0.335938 (0.650 sec)
376.10... logprob:  0.598066, 0.281250 (0.650 sec)
376.11... logprob:  0.638827, 0.335938 (0.651 sec)
376.12... logprob:  0.717328, 0.437500 (0.652 sec)
376.13... logprob:  0.657170, 0.359375 (0.650 sec)
376.14... logprob:  0.662785, 0.367188 (0.650 sec)
376.15... logprob:  0.685837, 0.398438 (0.651 sec)
376.16... logprob:  0.627074, 0.320312 (0.651 sec)
376.17... logprob:  0.638506, 0.335938 (0.652 sec)
376.18... logprob:  0.638221, 0.335938 (0.652 sec)
376.19... logprob:  0.632708, 0.328125 (0.652 sec)
376.20... logprob:  0.648898, 0.351562 (0.651 sec)
376.21... logprob:  0.643437, 0.343750 (0.652 sec)
376.22... logprob:  0.627947, 0.320312 (0.651 sec)
376.23... logprob:  0.623063, 0.312500 (0.651 sec)
376.24... logprob:  0.577497, 0.242188 (0.651 sec)
376.25... logprob:  0.628104, 0.320312 (0.651 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.653726, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.939474e-03 [6.623658e-09] 
Layer 'conv1' biases: 5.787668e-07 [6.886614e-11] 
Layer 'conv2' weights[0]: 7.927392e-03 [4.953717e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.592331e-10] 
Layer 'conv3' weights[0]: 7.925063e-03 [4.651966e-09] 
Layer 'conv3' biases: 4.822377e-06 [1.018819e-09] 
Layer 'conv4' weights[0]: 7.957920e-03 [4.637543e-09] 
Layer 'conv4' biases: 1.000001e+00 [7.811090e-09] 
Layer 'conv5' weights[0]: 7.957258e-03 [4.418971e-08] 
Layer 'conv5' biases: 1.000002e+00 [4.654656e-08] 
Layer 'fc6' weights[0]: 7.553378e-03 [6.144311e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.720971e-09] 
Layer 'fc7' weights[0]: 7.462720e-03 [7.571117e-08] 
Layer 'fc7' biases: 9.998527e-01 [5.613245e-08] 
Layer 'fc8' weights[0]: 5.755635e-04 [2.898945e-06] 
Layer 'fc8' biases: 1.635500e-01 [8.205124e-05] 
Train error last 27 batches: 0.635712
-------------------------------------------------------
Not saving because 0.653726 > 0.627087 (334.9: -0.00%)
======================================================= (1.801 sec)
376.26... logprob:  0.674206, 0.390625 (0.652 sec)
376.27... logprob:  0.627977, 0.320312 (0.651 sec)
377.1... logprob:  0.679638, 0.398438 (0.651 sec)
377.2... logprob:  0.596946, 0.273438 (0.651 sec)
377.3... logprob:  0.653815, 0.359375 (0.734 sec)
377.4... logprob:  0.596614, 0.273438 (0.651 sec)
377.5... logprob:  0.590911, 0.265625 (0.651 sec)
377.6... logprob:  0.611415, 0.296875 (0.651 sec)
377.7... logprob:  0.643815, 0.343750 (0.651 sec)
377.8... logprob:  0.604897, 0.289062 (0.650 sec)
377.9... logprob:  0.638521, 0.335938 (0.650 sec)
377.10... logprob:  0.598069, 0.281250 (0.650 sec)
377.11... logprob:  0.638825, 0.335938 (0.651 sec)
377.12... logprob:  0.717311, 0.437500 (0.651 sec)
377.13... logprob:  0.657164, 0.359375 (0.651 sec)
377.14... logprob:  0.662779, 0.367188 (0.650 sec)
377.15... logprob:  0.685830, 0.398438 (0.650 sec)
377.16... logprob:  0.627074, 0.320312 (0.651 sec)
377.17... logprob:  0.638506, 0.335938 (0.652 sec)
377.18... logprob:  0.638221, 0.335938 (0.652 sec)
377.19... logprob:  0.632708, 0.328125 (0.652 sec)
377.20... logprob:  0.648899, 0.351562 (0.652 sec)
377.21... logprob:  0.643438, 0.343750 (0.652 sec)
377.22... logprob:  0.627944, 0.320312 (0.651 sec)
377.23... logprob:  0.623060, 0.312500 (0.650 sec)
377.24... logprob:  0.577486, 0.242188 (0.650 sec)
377.25... logprob:  0.628102, 0.320312 (0.651 sec)
377.26... logprob:  0.674210, 0.390625 (0.652 sec)
377.27... logprob:  0.627975, 0.320312 (0.651 sec)
378.1... logprob:  0.679642, 0.398438 (0.651 sec)
378.2... logprob:  0.596941, 0.273438 (0.651 sec)
378.3... logprob:  0.653816, 0.359375 (0.651 sec)
378.4... logprob:  0.596612, 0.273438 (0.651 sec)
378.5... logprob:  0.590908, 0.265625 (0.651 sec)
378.6... logprob:  0.611415, 0.296875 (0.650 sec)
378.7... logprob:  0.643815, 0.343750 (0.651 sec)
378.8... logprob:  0.604899, 0.289062 (0.653 sec)
378.9... logprob:  0.638520, 0.335938 (0.650 sec)
378.10... logprob:  0.598074, 0.281250 (0.650 sec)
378.11... logprob:  0.638823, 0.335938 (0.651 sec)
378.12... logprob:  0.717292, 0.437500 (0.652 sec)
378.13... logprob:  0.657158, 0.359375 (0.651 sec)
378.14... logprob:  0.662773, 0.367188 (0.651 sec)
378.15... logprob:  0.685824, 0.398438 (0.650 sec)
378.16... logprob:  0.627074, 0.320312 (0.651 sec)
378.17... logprob:  0.638506, 0.335938 (0.652 sec)
378.18... logprob:  0.638221, 0.335938 (0.652 sec)
378.19... logprob:  0.632708, 0.328125 (0.651 sec)
378.20... logprob:  0.648901, 0.351562 (0.651 sec)
378.21... logprob:  0.643439, 0.343750 (0.652 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627991, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.939257e-03 [6.844723e-09] 
Layer 'conv1' biases: 5.822340e-07 [1.560210e-10] 
Layer 'conv2' weights[0]: 7.927194e-03 [6.515181e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.414061e-10] 
Layer 'conv3' weights[0]: 7.924869e-03 [5.671809e-09] 
Layer 'conv3' biases: 4.850045e-06 [2.022388e-09] 
Layer 'conv4' weights[0]: 7.957724e-03 [5.584313e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.361815e-08] 
Layer 'conv5' weights[0]: 7.957068e-03 [7.708424e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.145612e-08] 
Layer 'fc6' weights[0]: 7.553173e-03 [9.338405e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.351804e-09] 
Layer 'fc7' weights[0]: 7.460800e-03 [1.159747e-07] 
Layer 'fc7' biases: 9.998527e-01 [9.918756e-08] 
Layer 'fc8' weights[0]: 5.758569e-04 [5.181918e-06] 
Layer 'fc8' biases: 1.641833e-01 [1.063253e-04] 
Train error last 27 batches: 0.635709
-------------------------------------------------------
Not saving because 0.627991 > 0.627087 (334.9: -0.00%)
======================================================= (1.763 sec)
378.22... logprob:  0.627942, 0.320312 (0.651 sec)
378.23... logprob:  0.623054, 0.312500 (0.650 sec)
378.24... logprob:  0.577468, 0.242188 (0.651 sec)
378.25... logprob:  0.628099, 0.320312 (0.651 sec)
378.26... logprob:  0.674218, 0.390625 (0.652 sec)
378.27... logprob:  0.627972, 0.320312 (0.651 sec)
379.1... logprob:  0.679649, 0.398438 (0.650 sec)
379.2... logprob:  0.596935, 0.273438 (0.650 sec)
379.3... logprob:  0.653818, 0.359375 (0.651 sec)
379.4... logprob:  0.596608, 0.273438 (0.650 sec)
379.5... logprob:  0.590907, 0.265625 (0.651 sec)
379.6... logprob:  0.611416, 0.296875 (0.651 sec)
379.7... logprob:  0.643814, 0.343750 (0.651 sec)
379.8... logprob:  0.604904, 0.289062 (0.650 sec)
379.9... logprob:  0.638519, 0.335938 (0.650 sec)
379.10... logprob:  0.598082, 0.281250 (0.650 sec)
379.11... logprob:  0.638819, 0.335938 (0.651 sec)
379.12... logprob:  0.717262, 0.437500 (0.652 sec)
379.13... logprob:  0.657148, 0.359375 (0.650 sec)
379.14... logprob:  0.662763, 0.367188 (0.650 sec)
379.15... logprob:  0.685810, 0.398438 (0.651 sec)
379.16... logprob:  0.627074, 0.320312 (0.651 sec)
379.17... logprob:  0.638506, 0.335938 (0.652 sec)
379.18... logprob:  0.638221, 0.335938 (0.652 sec)
379.19... logprob:  0.632708, 0.328125 (0.652 sec)
379.20... logprob:  0.648901, 0.351562 (0.651 sec)
379.21... logprob:  0.643439, 0.343750 (0.652 sec)
379.22... logprob:  0.627939, 0.320312 (0.650 sec)
379.23... logprob:  0.623051, 0.312500 (0.650 sec)
379.24... logprob:  0.577454, 0.242188 (0.650 sec)
379.25... logprob:  0.628096, 0.320312 (0.651 sec)
379.26... logprob:  0.674224, 0.390625 (0.652 sec)
379.27... logprob:  0.627969, 0.320312 (0.652 sec)
380.1... logprob:  0.679655, 0.398438 (0.650 sec)
380.2... logprob:  0.596927, 0.273438 (0.651 sec)
380.3... logprob:  0.653820, 0.359375 (0.650 sec)
380.4... logprob:  0.596603, 0.273438 (0.651 sec)
380.5... logprob:  0.590902, 0.265625 (0.651 sec)
380.6... logprob:  0.611414, 0.296875 (0.650 sec)
380.7... logprob:  0.643814, 0.343750 (0.651 sec)
380.8... logprob:  0.604905, 0.289062 (0.650 sec)
380.9... logprob:  0.638518, 0.335938 (0.650 sec)
380.10... logprob:  0.598084, 0.281250 (0.650 sec)
380.11... logprob:  0.638817, 0.335938 (0.650 sec)
380.12... logprob:  0.717247, 0.437500 (0.651 sec)
380.13... logprob:  0.657144, 0.359375 (0.651 sec)
380.14... logprob:  0.662758, 0.367188 (0.651 sec)
380.15... logprob:  0.685804, 0.398438 (0.650 sec)
380.16... logprob:  0.627075, 0.320312 (0.651 sec)
380.17... logprob:  0.638506, 0.335938 (0.652 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.632777, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.939060e-03 [6.450009e-09] 
Layer 'conv1' biases: 5.855138e-07 [1.710656e-10] 
Layer 'conv2' weights[0]: 7.926995e-03 [6.862130e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.681155e-10] 
Layer 'conv3' weights[0]: 7.924685e-03 [6.026502e-09] 
Layer 'conv3' biases: 4.875243e-06 [2.366257e-09] 
Layer 'conv4' weights[0]: 7.957530e-03 [6.057256e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.741388e-08] 
Layer 'conv5' weights[0]: 7.956890e-03 [9.865035e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.044485e-07] 
Layer 'fc6' weights[0]: 7.552980e-03 [1.118745e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.056594e-08] 
Layer 'fc7' weights[0]: 7.458901e-03 [1.379058e-07] 
Layer 'fc7' biases: 9.998530e-01 [1.237188e-07] 
Layer 'fc8' weights[0]: 5.945516e-04 [6.578225e-06] 
Layer 'fc8' biases: 1.652985e-01 [1.316167e-04] 
Train error last 27 batches: 0.635703
-------------------------------------------------------
Not saving because 0.632777 > 0.627087 (334.9: -0.00%)
======================================================= (1.748 sec)
380.18... logprob:  0.638221, 0.335938 (0.651 sec)
380.19... logprob:  0.632707, 0.328125 (0.651 sec)
380.20... logprob:  0.648903, 0.351562 (0.651 sec)
380.21... logprob:  0.643439, 0.343750 (0.652 sec)
380.22... logprob:  0.627937, 0.320312 (0.651 sec)
380.23... logprob:  0.623046, 0.312500 (0.650 sec)
380.24... logprob:  0.577440, 0.242188 (0.651 sec)
380.25... logprob:  0.628093, 0.320312 (0.651 sec)
380.26... logprob:  0.674228, 0.390625 (0.651 sec)
380.27... logprob:  0.627968, 0.320312 (0.651 sec)
381.1... logprob:  0.679659, 0.398438 (0.651 sec)
381.2... logprob:  0.596923, 0.273438 (0.650 sec)
381.3... logprob:  0.653820, 0.359375 (0.651 sec)
381.4... logprob:  0.596601, 0.273438 (0.651 sec)
381.5... logprob:  0.590901, 0.265625 (0.651 sec)
381.6... logprob:  0.611415, 0.296875 (0.650 sec)
381.7... logprob:  0.643813, 0.343750 (0.650 sec)
381.8... logprob:  0.604908, 0.289062 (0.650 sec)
381.9... logprob:  0.638517, 0.335938 (0.650 sec)
381.10... logprob:  0.598090, 0.281250 (0.650 sec)
381.11... logprob:  0.638814, 0.335938 (0.650 sec)
381.12... logprob:  0.717224, 0.437500 (0.652 sec)
381.13... logprob:  0.657136, 0.359375 (0.651 sec)
381.14... logprob:  0.662750, 0.367188 (0.650 sec)
381.15... logprob:  0.685794, 0.398438 (0.650 sec)
381.16... logprob:  0.627075, 0.320312 (0.651 sec)
381.17... logprob:  0.638506, 0.335938 (0.652 sec)
381.18... logprob:  0.638221, 0.335938 (0.652 sec)
381.19... logprob:  0.632707, 0.328125 (0.651 sec)
381.20... logprob:  0.648903, 0.351562 (0.651 sec)
381.21... logprob:  0.643439, 0.343750 (0.652 sec)
381.22... logprob:  0.627934, 0.320312 (0.651 sec)
381.23... logprob:  0.623044, 0.312500 (0.650 sec)
381.24... logprob:  0.577428, 0.242188 (0.651 sec)
381.25... logprob:  0.628090, 0.320312 (0.651 sec)
381.26... logprob:  0.674233, 0.390625 (0.652 sec)
381.27... logprob:  0.627966, 0.320312 (0.651 sec)
382.1... logprob:  0.679665, 0.398438 (0.650 sec)
382.2... logprob:  0.596916, 0.273438 (0.652 sec)
382.3... logprob:  0.653822, 0.359375 (0.651 sec)
382.4... logprob:  0.596596, 0.273438 (0.650 sec)
382.5... logprob:  0.590898, 0.265625 (0.651 sec)
382.6... logprob:  0.611413, 0.296875 (0.651 sec)
382.7... logprob:  0.643814, 0.343750 (0.650 sec)
382.8... logprob:  0.604909, 0.289062 (0.651 sec)
382.9... logprob:  0.638516, 0.335938 (0.650 sec)
382.10... logprob:  0.598093, 0.281250 (0.650 sec)
382.11... logprob:  0.638813, 0.335938 (0.651 sec)
382.12... logprob:  0.717209, 0.437500 (0.651 sec)
382.13... logprob:  0.657131, 0.359375 (0.650 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.692550, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938856e-03 [6.552808e-09] 
Layer 'conv1' biases: 5.887421e-07 [1.003068e-10] 
Layer 'conv2' weights[0]: 7.926817e-03 [5.428415e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.535270e-10] 
Layer 'conv3' weights[0]: 7.924495e-03 [4.768832e-09] 
Layer 'conv3' biases: 4.899824e-06 [1.244624e-09] 
Layer 'conv4' weights[0]: 7.957340e-03 [4.680368e-09] 
Layer 'conv4' biases: 1.000001e+00 [6.760305e-09] 
Layer 'conv5' weights[0]: 7.956679e-03 [3.843716e-08] 
Layer 'conv5' biases: 1.000002e+00 [4.042311e-08] 
Layer 'fc6' weights[0]: 7.552786e-03 [5.623407e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.074485e-09] 
Layer 'fc7' weights[0]: 7.456994e-03 [6.904825e-08] 
Layer 'fc7' biases: 9.998533e-01 [4.849273e-08] 
Layer 'fc8' weights[0]: 6.167843e-04 [2.550108e-06] 
Layer 'fc8' biases: 1.664721e-01 [4.082955e-05] 
Train error last 27 batches: 0.635699
-------------------------------------------------------
Not saving because 0.692550 > 0.627087 (334.9: -0.00%)
======================================================= (1.804 sec)
382.14... logprob:  0.662744, 0.367188 (0.650 sec)
382.15... logprob:  0.685788, 0.398438 (0.650 sec)
382.16... logprob:  0.627075, 0.320312 (0.651 sec)
382.17... logprob:  0.638506, 0.335938 (0.652 sec)
382.18... logprob:  0.638221, 0.335938 (0.651 sec)
382.19... logprob:  0.632706, 0.328125 (0.651 sec)
382.20... logprob:  0.648904, 0.351562 (0.651 sec)
382.21... logprob:  0.643440, 0.343750 (0.652 sec)
382.22... logprob:  0.627932, 0.320312 (0.651 sec)
382.23... logprob:  0.623039, 0.312500 (0.650 sec)
382.24... logprob:  0.577415, 0.242188 (0.650 sec)
382.25... logprob:  0.628088, 0.320312 (0.652 sec)
382.26... logprob:  0.674238, 0.390625 (0.652 sec)
382.27... logprob:  0.627963, 0.320312 (0.650 sec)
383.1... logprob:  0.679669, 0.398438 (0.651 sec)
383.2... logprob:  0.596911, 0.273438 (0.650 sec)
383.3... logprob:  0.653823, 0.359375 (0.650 sec)
383.4... logprob:  0.596592, 0.273438 (0.650 sec)
383.5... logprob:  0.590896, 0.265625 (0.650 sec)
383.6... logprob:  0.611414, 0.296875 (0.650 sec)
383.7... logprob:  0.643813, 0.343750 (0.650 sec)
383.8... logprob:  0.604911, 0.289062 (0.651 sec)
383.9... logprob:  0.638515, 0.335938 (0.650 sec)
383.10... logprob:  0.598098, 0.281250 (0.650 sec)
383.11... logprob:  0.638810, 0.335938 (0.651 sec)
383.12... logprob:  0.717188, 0.437500 (0.651 sec)
383.13... logprob:  0.657124, 0.359375 (0.651 sec)
383.14... logprob:  0.662737, 0.367188 (0.650 sec)
383.15... logprob:  0.685779, 0.398438 (0.650 sec)
383.16... logprob:  0.627075, 0.320312 (0.651 sec)
383.17... logprob:  0.638505, 0.335938 (0.652 sec)
383.18... logprob:  0.638221, 0.335938 (0.653 sec)
383.19... logprob:  0.632705, 0.328125 (0.652 sec)
383.20... logprob:  0.648905, 0.351562 (0.651 sec)
383.21... logprob:  0.643440, 0.343750 (0.651 sec)
383.22... logprob:  0.627930, 0.320312 (0.650 sec)
383.23... logprob:  0.623036, 0.312500 (0.650 sec)
383.24... logprob:  0.577404, 0.242188 (0.650 sec)
383.25... logprob:  0.628085, 0.320312 (0.651 sec)
383.26... logprob:  0.674242, 0.390625 (0.651 sec)
383.27... logprob:  0.627962, 0.320312 (0.651 sec)
384.1... logprob:  0.679673, 0.398438 (0.650 sec)
384.2... logprob:  0.596906, 0.273438 (0.651 sec)
384.3... logprob:  0.653824, 0.359375 (0.650 sec)
384.4... logprob:  0.596588, 0.273438 (0.650 sec)
384.5... logprob:  0.590892, 0.265625 (0.650 sec)
384.6... logprob:  0.611413, 0.296875 (0.650 sec)
384.7... logprob:  0.643813, 0.343750 (0.651 sec)
384.8... logprob:  0.604912, 0.289062 (0.650 sec)
384.9... logprob:  0.638514, 0.335938 (0.650 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.632890, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938670e-03 [6.729492e-09] 
Layer 'conv1' biases: 5.923058e-07 [1.204808e-10] 
Layer 'conv2' weights[0]: 7.926627e-03 [5.851516e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.125791e-10] 
Layer 'conv3' weights[0]: 7.924308e-03 [5.677190e-09] 
Layer 'conv3' biases: 4.928631e-06 [1.873772e-09] 
Layer 'conv4' weights[0]: 7.957147e-03 [5.779464e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.592752e-08] 
Layer 'conv5' weights[0]: 7.956472e-03 [8.937457e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.444138e-08] 
Layer 'fc6' weights[0]: 7.552600e-03 [1.039205e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.580357e-09] 
Layer 'fc7' weights[0]: 7.455107e-03 [1.274587e-07] 
Layer 'fc7' biases: 9.998531e-01 [1.114993e-07] 
Layer 'fc8' weights[0]: 6.073224e-04 [5.894040e-06] 
Layer 'fc8' biases: 1.668653e-01 [1.428884e-04] 
Train error last 27 batches: 0.635696
-------------------------------------------------------
Not saving because 0.632890 > 0.627087 (334.9: -0.00%)
======================================================= (1.764 sec)
384.10... logprob:  0.598102, 0.281250 (0.650 sec)
384.11... logprob:  0.638808, 0.335938 (0.650 sec)
384.12... logprob:  0.717173, 0.437500 (0.651 sec)
384.13... logprob:  0.657119, 0.359375 (0.650 sec)
384.14... logprob:  0.662733, 0.367188 (0.650 sec)
384.15... logprob:  0.685773, 0.398438 (0.651 sec)
384.16... logprob:  0.627075, 0.320312 (0.651 sec)
384.17... logprob:  0.638506, 0.335938 (0.652 sec)
384.18... logprob:  0.638221, 0.335938 (0.652 sec)
384.19... logprob:  0.632705, 0.328125 (0.651 sec)
384.20... logprob:  0.648906, 0.351562 (0.651 sec)
384.21... logprob:  0.643440, 0.343750 (0.652 sec)
384.22... logprob:  0.627928, 0.320312 (0.650 sec)
384.23... logprob:  0.623032, 0.312500 (0.650 sec)
384.24... logprob:  0.577389, 0.242188 (0.651 sec)
384.25... logprob:  0.628082, 0.320312 (0.651 sec)
384.26... logprob:  0.674248, 0.390625 (0.651 sec)
384.27... logprob:  0.627959, 0.320312 (0.651 sec)
385.1... logprob:  0.679680, 0.398438 (0.650 sec)
385.2... logprob:  0.596899, 0.273438 (0.651 sec)
385.3... logprob:  0.653826, 0.359375 (0.650 sec)
385.4... logprob:  0.596584, 0.273438 (0.650 sec)
385.5... logprob:  0.590890, 0.265625 (0.651 sec)
385.6... logprob:  0.611413, 0.296875 (0.651 sec)
385.7... logprob:  0.643812, 0.343750 (0.651 sec)
385.8... logprob:  0.604916, 0.289062 (0.651 sec)
385.9... logprob:  0.638514, 0.335938 (0.650 sec)
385.10... logprob:  0.598107, 0.281250 (0.649 sec)
385.11... logprob:  0.638804, 0.335938 (0.651 sec)
385.12... logprob:  0.717148, 0.437500 (0.651 sec)
385.13... logprob:  0.657111, 0.359375 (0.650 sec)
385.14... logprob:  0.662724, 0.367188 (0.650 sec)
385.15... logprob:  0.685763, 0.398438 (0.651 sec)
385.16... logprob:  0.627076, 0.320312 (0.650 sec)
385.17... logprob:  0.638506, 0.335938 (0.652 sec)
385.18... logprob:  0.638221, 0.335938 (0.651 sec)
385.19... logprob:  0.632705, 0.328125 (0.651 sec)
385.20... logprob:  0.648907, 0.351562 (0.651 sec)
385.21... logprob:  0.643441, 0.343750 (0.652 sec)
385.22... logprob:  0.627925, 0.320312 (0.650 sec)
385.23... logprob:  0.623028, 0.312500 (0.650 sec)
385.24... logprob:  0.577374, 0.242188 (0.651 sec)
385.25... logprob:  0.628079, 0.320312 (0.652 sec)
385.26... logprob:  0.674253, 0.390625 (0.651 sec)
385.27... logprob:  0.627956, 0.320312 (0.651 sec)
386.1... logprob:  0.679685, 0.398438 (0.650 sec)
386.2... logprob:  0.596894, 0.273438 (0.651 sec)
386.3... logprob:  0.653827, 0.359375 (0.651 sec)
386.4... logprob:  0.596580, 0.273438 (0.651 sec)
386.5... logprob:  0.590887, 0.265625 (0.650 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627615, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938500e-03 [7.483286e-09] 
Layer 'conv1' biases: 5.960130e-07 [1.375020e-10] 
Layer 'conv2' weights[0]: 7.926421e-03 [5.958958e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.419802e-10] 
Layer 'conv3' weights[0]: 7.924100e-03 [5.746114e-09] 
Layer 'conv3' biases: 4.959021e-06 [1.934238e-09] 
Layer 'conv4' weights[0]: 7.956947e-03 [5.775190e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.623126e-08] 
Layer 'conv5' weights[0]: 7.956256e-03 [9.124950e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.649713e-08] 
Layer 'fc6' weights[0]: 7.552421e-03 [1.061649e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.859384e-09] 
Layer 'fc7' weights[0]: 7.453228e-03 [1.309016e-07] 
Layer 'fc7' biases: 9.998525e-01 [1.156539e-07] 
Layer 'fc8' weights[0]: 5.838632e-04 [6.047446e-06] 
Layer 'fc8' biases: 1.668923e-01 [1.505073e-04] 
Train error last 27 batches: 0.635691
-------------------------------------------------------
Not saving because 0.627615 > 0.627087 (334.9: -0.00%)
======================================================= (1.764 sec)
386.6... logprob:  0.611413, 0.296875 (0.650 sec)
386.7... logprob:  0.643812, 0.343750 (0.650 sec)
386.8... logprob:  0.604918, 0.289062 (0.651 sec)
386.9... logprob:  0.638513, 0.335938 (0.650 sec)
386.10... logprob:  0.598113, 0.281250 (0.650 sec)
386.11... logprob:  0.638803, 0.335938 (0.650 sec)
386.12... logprob:  0.717126, 0.437500 (0.651 sec)
386.13... logprob:  0.657104, 0.359375 (0.650 sec)
386.14... logprob:  0.662717, 0.367188 (0.650 sec)
386.15... logprob:  0.685754, 0.398438 (0.650 sec)
386.16... logprob:  0.627076, 0.320312 (0.651 sec)
386.17... logprob:  0.638505, 0.335938 (0.652 sec)
386.18... logprob:  0.638221, 0.335938 (0.651 sec)
386.19... logprob:  0.632705, 0.328125 (0.651 sec)
386.20... logprob:  0.648908, 0.351562 (0.651 sec)
386.21... logprob:  0.643442, 0.343750 (0.651 sec)
386.22... logprob:  0.627923, 0.320312 (0.651 sec)
386.23... logprob:  0.623024, 0.312500 (0.650 sec)
386.24... logprob:  0.577358, 0.242188 (0.651 sec)
386.25... logprob:  0.628076, 0.320312 (0.651 sec)
386.26... logprob:  0.674260, 0.390625 (0.651 sec)
386.27... logprob:  0.627954, 0.320312 (0.651 sec)
387.1... logprob:  0.679691, 0.398438 (0.651 sec)
387.2... logprob:  0.596887, 0.273438 (0.651 sec)
387.3... logprob:  0.653828, 0.359375 (0.650 sec)
387.4... logprob:  0.596575, 0.273438 (0.651 sec)
387.5... logprob:  0.590884, 0.265625 (0.650 sec)
387.6... logprob:  0.611413, 0.296875 (0.651 sec)
387.7... logprob:  0.643812, 0.343750 (0.651 sec)
387.8... logprob:  0.604921, 0.289062 (0.650 sec)
387.9... logprob:  0.638512, 0.335938 (0.650 sec)
387.10... logprob:  0.598119, 0.281250 (0.650 sec)
387.11... logprob:  0.638799, 0.335938 (0.650 sec)
387.12... logprob:  0.717103, 0.437500 (0.651 sec)
387.13... logprob:  0.657095, 0.359375 (0.651 sec)
387.14... logprob:  0.662710, 0.367188 (0.650 sec)
387.15... logprob:  0.685744, 0.398438 (0.650 sec)
387.16... logprob:  0.627076, 0.320312 (0.651 sec)
387.17... logprob:  0.638505, 0.335938 (0.652 sec)
387.18... logprob:  0.638220, 0.335938 (0.651 sec)
387.19... logprob:  0.632705, 0.328125 (0.651 sec)
387.20... logprob:  0.648909, 0.351562 (0.651 sec)
387.21... logprob:  0.643442, 0.343750 (0.652 sec)
387.22... logprob:  0.627920, 0.320312 (0.650 sec)
387.23... logprob:  0.623021, 0.312500 (0.650 sec)
387.24... logprob:  0.577345, 0.242188 (0.650 sec)
387.25... logprob:  0.628073, 0.320312 (0.651 sec)
387.26... logprob:  0.674266, 0.390625 (0.651 sec)
387.27... logprob:  0.627952, 0.320312 (0.651 sec)
388.1... logprob:  0.679697, 0.398438 (0.651 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.653767, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938304e-03 [6.675229e-09] 
Layer 'conv1' biases: 5.996235e-07 [8.427971e-11] 
Layer 'conv2' weights[0]: 7.926249e-03 [5.187108e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.405458e-10] 
Layer 'conv3' weights[0]: 7.923908e-03 [4.514372e-09] 
Layer 'conv3' biases: 4.987811e-06 [8.631627e-10] 
Layer 'conv4' weights[0]: 7.956750e-03 [4.422243e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.492052e-09] 
Layer 'conv5' weights[0]: 7.956072e-03 [1.949815e-08] 
Layer 'conv5' biases: 1.000002e+00 [2.014306e-08] 
Layer 'fc6' weights[0]: 7.552231e-03 [4.430136e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.133133e-09] 
Layer 'fc7' weights[0]: 7.451350e-03 [5.034204e-08] 
Layer 'fc7' biases: 9.998522e-01 [2.631000e-08] 
Layer 'fc8' weights[0]: 5.731040e-04 [1.304224e-06] 
Layer 'fc8' biases: 1.672422e-01 [2.173176e-05] 
Train error last 27 batches: 0.635686
-------------------------------------------------------
Not saving because 0.653767 > 0.627087 (334.9: -0.00%)
======================================================= (1.841 sec)
388.2... logprob:  0.596880, 0.273438 (0.651 sec)
388.3... logprob:  0.653830, 0.359375 (0.650 sec)
388.4... logprob:  0.596571, 0.273438 (0.650 sec)
388.5... logprob:  0.590881, 0.265625 (0.650 sec)
388.6... logprob:  0.611412, 0.296875 (0.651 sec)
388.7... logprob:  0.643811, 0.343750 (0.650 sec)
388.8... logprob:  0.604922, 0.289062 (0.650 sec)
388.9... logprob:  0.638511, 0.335938 (0.651 sec)
388.10... logprob:  0.598122, 0.281250 (0.650 sec)
388.11... logprob:  0.638797, 0.335938 (0.651 sec)
388.12... logprob:  0.717085, 0.437500 (0.652 sec)
388.13... logprob:  0.657089, 0.359375 (0.651 sec)
388.14... logprob:  0.662703, 0.367188 (0.650 sec)
388.15... logprob:  0.685736, 0.398438 (0.650 sec)
388.16... logprob:  0.627077, 0.320312 (0.651 sec)
388.17... logprob:  0.638505, 0.335938 (0.653 sec)
388.18... logprob:  0.638221, 0.335938 (0.652 sec)
388.19... logprob:  0.632705, 0.328125 (0.651 sec)
388.20... logprob:  0.648910, 0.351562 (0.651 sec)
388.21... logprob:  0.643442, 0.343750 (0.652 sec)
388.22... logprob:  0.627918, 0.320312 (0.650 sec)
388.23... logprob:  0.623016, 0.312500 (0.650 sec)
388.24... logprob:  0.577333, 0.242188 (0.650 sec)
388.25... logprob:  0.628070, 0.320312 (0.651 sec)
388.26... logprob:  0.674269, 0.390625 (0.652 sec)
388.27... logprob:  0.627950, 0.320312 (0.650 sec)
389.1... logprob:  0.679700, 0.398438 (0.650 sec)
389.2... logprob:  0.596875, 0.273438 (0.650 sec)
389.3... logprob:  0.653831, 0.359375 (0.650 sec)
389.4... logprob:  0.596567, 0.273438 (0.651 sec)
389.5... logprob:  0.590879, 0.265625 (0.651 sec)
389.6... logprob:  0.611411, 0.296875 (0.650 sec)
389.7... logprob:  0.643811, 0.343750 (0.651 sec)
389.8... logprob:  0.604925, 0.289062 (0.650 sec)
389.9... logprob:  0.638510, 0.335938 (0.650 sec)
389.10... logprob:  0.598127, 0.281250 (0.650 sec)
389.11... logprob:  0.638795, 0.335938 (0.651 sec)
389.12... logprob:  0.717066, 0.437500 (0.651 sec)
389.13... logprob:  0.657084, 0.359375 (0.651 sec)
389.14... logprob:  0.662697, 0.367188 (0.650 sec)
389.15... logprob:  0.685729, 0.398438 (0.650 sec)
389.16... logprob:  0.627076, 0.320312 (0.651 sec)
389.17... logprob:  0.638505, 0.335938 (0.653 sec)
389.18... logprob:  0.638220, 0.335938 (0.651 sec)
389.19... logprob:  0.632704, 0.328125 (0.652 sec)
389.20... logprob:  0.648911, 0.351562 (0.651 sec)
389.21... logprob:  0.643443, 0.343750 (0.652 sec)
389.22... logprob:  0.627916, 0.320312 (0.651 sec)
389.23... logprob:  0.623013, 0.312500 (0.651 sec)
389.24... logprob:  0.577320, 0.242188 (0.651 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.628118, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938106e-03 [6.488791e-09] 
Layer 'conv1' biases: 6.031466e-07 [6.024389e-11] 
Layer 'conv2' weights[0]: 7.926072e-03 [4.877586e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.031846e-10] 
Layer 'conv3' weights[0]: 7.923715e-03 [4.527866e-09] 
Layer 'conv3' biases: 5.015849e-06 [8.494415e-10] 
Layer 'conv4' weights[0]: 7.956558e-03 [4.471194e-09] 
Layer 'conv4' biases: 1.000001e+00 [6.010321e-09] 
Layer 'conv5' weights[0]: 7.955888e-03 [3.360176e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.523304e-08] 
Layer 'fc6' weights[0]: 7.552034e-03 [5.296388e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.556502e-09] 
Layer 'fc7' weights[0]: 7.449465e-03 [6.371494e-08] 
Layer 'fc7' biases: 9.998522e-01 [4.213897e-08] 
Layer 'fc8' weights[0]: 5.697640e-04 [2.142059e-06] 
Layer 'fc8' biases: 1.677758e-01 [6.601750e-05] 
Train error last 27 batches: 0.635682
-------------------------------------------------------
Not saving because 0.628118 > 0.627087 (334.9: -0.00%)
======================================================= (1.812 sec)
389.25... logprob:  0.628068, 0.320312 (0.652 sec)
389.26... logprob:  0.674275, 0.390625 (0.651 sec)
389.27... logprob:  0.627948, 0.320312 (0.652 sec)
390.1... logprob:  0.679705, 0.398438 (0.651 sec)
390.2... logprob:  0.596870, 0.273438 (0.650 sec)
390.3... logprob:  0.653832, 0.359375 (0.650 sec)
390.4... logprob:  0.596564, 0.273438 (0.651 sec)
390.5... logprob:  0.590876, 0.265625 (0.650 sec)
390.6... logprob:  0.611411, 0.296875 (0.650 sec)
390.7... logprob:  0.643810, 0.343750 (0.651 sec)
390.8... logprob:  0.604926, 0.289062 (0.650 sec)
390.9... logprob:  0.638508, 0.335938 (0.650 sec)
390.10... logprob:  0.598132, 0.281250 (0.650 sec)
390.11... logprob:  0.638793, 0.335938 (0.650 sec)
390.12... logprob:  0.717049, 0.437500 (0.651 sec)
390.13... logprob:  0.657077, 0.359375 (0.651 sec)
390.14... logprob:  0.662691, 0.367188 (0.650 sec)
390.15... logprob:  0.685722, 0.398438 (0.650 sec)
390.16... logprob:  0.627077, 0.320312 (0.651 sec)
390.17... logprob:  0.638505, 0.335938 (0.652 sec)
390.18... logprob:  0.638220, 0.335938 (0.651 sec)
390.19... logprob:  0.632703, 0.328125 (0.651 sec)
390.20... logprob:  0.648912, 0.351562 (0.651 sec)
390.21... logprob:  0.643444, 0.343750 (0.652 sec)
390.22... logprob:  0.627914, 0.320312 (0.650 sec)
390.23... logprob:  0.623009, 0.312500 (0.650 sec)
390.24... logprob:  0.577308, 0.242188 (0.651 sec)
390.25... logprob:  0.628065, 0.320312 (0.651 sec)
390.26... logprob:  0.674279, 0.390625 (0.651 sec)
390.27... logprob:  0.627946, 0.320312 (0.651 sec)
391.1... logprob:  0.679710, 0.398438 (0.651 sec)
391.2... logprob:  0.596864, 0.273438 (0.650 sec)
391.3... logprob:  0.653833, 0.359375 (0.650 sec)
391.4... logprob:  0.596560, 0.273438 (0.650 sec)
391.5... logprob:  0.590873, 0.265625 (0.651 sec)
391.6... logprob:  0.611411, 0.296875 (0.650 sec)
391.7... logprob:  0.643810, 0.343750 (0.650 sec)
391.8... logprob:  0.604928, 0.289062 (0.651 sec)
391.9... logprob:  0.638508, 0.335938 (0.650 sec)
391.10... logprob:  0.598136, 0.281250 (0.650 sec)
391.11... logprob:  0.638790, 0.335938 (0.651 sec)
391.12... logprob:  0.717029, 0.437500 (0.651 sec)
391.13... logprob:  0.657071, 0.359375 (0.650 sec)
391.14... logprob:  0.662685, 0.367188 (0.650 sec)
391.15... logprob:  0.685714, 0.398438 (0.651 sec)
391.16... logprob:  0.627077, 0.320312 (0.651 sec)
391.17... logprob:  0.638505, 0.335938 (0.653 sec)
391.18... logprob:  0.638220, 0.335938 (0.652 sec)
391.19... logprob:  0.632703, 0.328125 (0.651 sec)
391.20... logprob:  0.648914, 0.351562 (0.651 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.632982, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937919e-03 [6.830658e-09] 
Layer 'conv1' biases: 6.065565e-07 [1.636807e-10] 
Layer 'conv2' weights[0]: 7.925878e-03 [6.516661e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.703949e-10] 
Layer 'conv3' weights[0]: 7.923516e-03 [5.697262e-09] 
Layer 'conv3' biases: 5.042501e-06 [2.097198e-09] 
Layer 'conv4' weights[0]: 7.956365e-03 [5.628393e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.436067e-08] 
Layer 'conv5' weights[0]: 7.955696e-03 [8.056072e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.496716e-08] 
Layer 'fc6' weights[0]: 7.551845e-03 [9.689275e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.725900e-09] 
Layer 'fc7' weights[0]: 7.447560e-03 [1.195321e-07] 
Layer 'fc7' biases: 9.998523e-01 [1.028771e-07] 
Layer 'fc8' weights[0]: 5.768596e-04 [5.351987e-06] 
Layer 'fc8' biases: 1.685846e-01 [1.112364e-04] 
Train error last 27 batches: 0.635678
-------------------------------------------------------
Not saving because 0.632982 > 0.627087 (334.9: -0.00%)
======================================================= (1.760 sec)
391.21... logprob:  0.643444, 0.343750 (0.652 sec)
391.22... logprob:  0.627912, 0.320312 (0.651 sec)
391.23... logprob:  0.623005, 0.312500 (0.650 sec)
391.24... logprob:  0.577293, 0.242188 (0.650 sec)
391.25... logprob:  0.628062, 0.320312 (0.652 sec)
391.26... logprob:  0.674286, 0.390625 (0.652 sec)
391.27... logprob:  0.627944, 0.320312 (0.650 sec)
392.1... logprob:  0.679716, 0.398438 (0.651 sec)
392.2... logprob:  0.596858, 0.273438 (0.651 sec)
392.3... logprob:  0.653835, 0.359375 (0.650 sec)
392.4... logprob:  0.596556, 0.273438 (0.651 sec)
392.5... logprob:  0.590871, 0.265625 (0.651 sec)
392.6... logprob:  0.611411, 0.296875 (0.651 sec)
392.7... logprob:  0.643810, 0.343750 (0.651 sec)
392.8... logprob:  0.604931, 0.289062 (0.650 sec)
392.9... logprob:  0.638506, 0.335938 (0.650 sec)
392.10... logprob:  0.598142, 0.281250 (0.651 sec)
392.11... logprob:  0.638787, 0.335938 (0.651 sec)
392.12... logprob:  0.717007, 0.437500 (0.652 sec)
392.13... logprob:  0.657064, 0.359375 (0.651 sec)
392.14... logprob:  0.662676, 0.367188 (0.650 sec)
392.15... logprob:  0.685703, 0.398438 (0.650 sec)
392.16... logprob:  0.627077, 0.320312 (0.655 sec)
392.17... logprob:  0.638504, 0.335938 (0.660 sec)
392.18... logprob:  0.638219, 0.335938 (0.657 sec)
392.19... logprob:  0.632702, 0.328125 (0.655 sec)
392.20... logprob:  0.648913, 0.351562 (0.655 sec)
392.21... logprob:  0.643444, 0.343750 (0.656 sec)
392.22... logprob:  0.627909, 0.320312 (0.653 sec)
392.23... logprob:  0.623003, 0.312500 (0.653 sec)
392.24... logprob:  0.577284, 0.242188 (0.654 sec)
392.25... logprob:  0.628060, 0.320312 (0.655 sec)
392.26... logprob:  0.674289, 0.390625 (0.654 sec)
392.27... logprob:  0.627942, 0.320312 (0.644 sec)
393.1... logprob:  0.679720, 0.398438 (0.640 sec)
393.2... logprob:  0.596853, 0.273438 (0.640 sec)
393.3... logprob:  0.653836, 0.359375 (0.639 sec)
393.4... logprob:  0.596551, 0.273438 (0.640 sec)
393.5... logprob:  0.590866, 0.265625 (0.639 sec)
393.6... logprob:  0.611408, 0.296875 (0.640 sec)
393.7... logprob:  0.643810, 0.343750 (0.640 sec)
393.8... logprob:  0.604931, 0.289062 (0.641 sec)
393.9... logprob:  0.638506, 0.335938 (0.641 sec)
393.10... logprob:  0.598143, 0.281250 (0.640 sec)
393.11... logprob:  0.638786, 0.335938 (0.640 sec)
393.12... logprob:  0.716997, 0.437500 (0.641 sec)
393.13... logprob:  0.657060, 0.359375 (0.641 sec)
393.14... logprob:  0.662673, 0.367188 (0.640 sec)
393.15... logprob:  0.685700, 0.398438 (0.640 sec)
393.16... logprob:  0.627077, 0.320312 (0.641 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.688990, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937713e-03 [6.990020e-09] 
Layer 'conv1' biases: 6.098529e-07 [1.838090e-10] 
Layer 'conv2' weights[0]: 7.925677e-03 [7.142791e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.162143e-10] 
Layer 'conv3' weights[0]: 7.923310e-03 [6.202091e-09] 
Layer 'conv3' biases: 5.067647e-06 [2.519309e-09] 
Layer 'conv4' weights[0]: 7.956165e-03 [6.218083e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.792282e-08] 
Layer 'conv5' weights[0]: 7.955500e-03 [1.009558e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.066553e-07] 
Layer 'fc6' weights[0]: 7.551644e-03 [1.145849e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.086141e-08] 
Layer 'fc7' weights[0]: 7.445658e-03 [1.403554e-07] 
Layer 'fc7' biases: 9.998527e-01 [1.263496e-07] 
Layer 'fc8' weights[0]: 5.962883e-04 [6.660804e-06] 
Layer 'fc8' biases: 1.697076e-01 [1.351814e-04] 
Train error last 27 batches: 0.635674
-------------------------------------------------------
Not saving because 0.688990 > 0.627087 (334.9: -0.00%)
======================================================= (1.729 sec)
393.17... logprob:  0.638504, 0.335938 (0.643 sec)
393.18... logprob:  0.638220, 0.335938 (0.642 sec)
393.19... logprob:  0.632702, 0.328125 (0.642 sec)
393.20... logprob:  0.648915, 0.351562 (0.642 sec)
393.21... logprob:  0.643445, 0.343750 (0.643 sec)
393.22... logprob:  0.627908, 0.320312 (0.642 sec)
393.23... logprob:  0.622999, 0.312500 (0.641 sec)
393.24... logprob:  0.577270, 0.242188 (0.642 sec)
393.25... logprob:  0.628058, 0.320312 (0.643 sec)
393.26... logprob:  0.674294, 0.390625 (0.643 sec)
393.27... logprob:  0.627941, 0.320312 (0.641 sec)
394.1... logprob:  0.679725, 0.398438 (0.641 sec)
394.2... logprob:  0.596848, 0.273438 (0.641 sec)
394.3... logprob:  0.653837, 0.359375 (0.641 sec)
394.4... logprob:  0.596549, 0.273438 (0.641 sec)
394.5... logprob:  0.590866, 0.265625 (0.641 sec)
394.6... logprob:  0.611411, 0.296875 (0.641 sec)
394.7... logprob:  0.643809, 0.343750 (0.641 sec)
394.8... logprob:  0.604935, 0.289062 (0.641 sec)
394.9... logprob:  0.638505, 0.335938 (0.641 sec)
394.10... logprob:  0.598150, 0.281250 (0.641 sec)
394.11... logprob:  0.638783, 0.335938 (0.641 sec)
394.12... logprob:  0.716971, 0.437500 (0.642 sec)
394.13... logprob:  0.657053, 0.359375 (0.641 sec)
394.14... logprob:  0.662665, 0.367188 (0.641 sec)
394.15... logprob:  0.685689, 0.398438 (0.640 sec)
394.16... logprob:  0.627077, 0.320312 (0.642 sec)
394.17... logprob:  0.638504, 0.335938 (0.643 sec)
394.18... logprob:  0.638220, 0.335938 (0.642 sec)
394.19... logprob:  0.632702, 0.328125 (0.645 sec)
394.20... logprob:  0.648915, 0.351562 (0.641 sec)
394.21... logprob:  0.643444, 0.343750 (0.652 sec)
394.22... logprob:  0.627905, 0.320312 (0.651 sec)
394.23... logprob:  0.622996, 0.312500 (0.650 sec)
394.24... logprob:  0.577258, 0.242188 (0.653 sec)
394.25... logprob:  0.628055, 0.320312 (0.652 sec)
394.26... logprob:  0.674299, 0.390625 (0.651 sec)
394.27... logprob:  0.627938, 0.320312 (0.651 sec)
395.1... logprob:  0.679730, 0.398438 (0.651 sec)
395.2... logprob:  0.596841, 0.273438 (0.651 sec)
395.3... logprob:  0.653838, 0.359375 (0.651 sec)
395.4... logprob:  0.596543, 0.273438 (0.651 sec)
395.5... logprob:  0.590861, 0.265625 (0.651 sec)
395.6... logprob:  0.611408, 0.296875 (0.652 sec)
395.7... logprob:  0.643809, 0.343750 (0.652 sec)
395.8... logprob:  0.604935, 0.289062 (0.650 sec)
395.9... logprob:  0.638505, 0.335938 (0.651 sec)
395.10... logprob:  0.598151, 0.281250 (0.651 sec)
395.11... logprob:  0.638782, 0.335938 (0.651 sec)
395.12... logprob:  0.716959, 0.437500 (0.652 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633101, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937525e-03 [6.949906e-09] 
Layer 'conv1' biases: 6.131463e-07 [8.339481e-11] 
Layer 'conv2' weights[0]: 7.925495e-03 [5.249461e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.171619e-10] 
Layer 'conv3' weights[0]: 7.923116e-03 [4.549166e-09] 
Layer 'conv3' biases: 5.092717e-06 [7.899574e-10] 
Layer 'conv4' weights[0]: 7.955977e-03 [4.407389e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.388395e-09] 
Layer 'conv5' weights[0]: 7.955317e-03 [8.895920e-09] 
Layer 'conv5' biases: 1.000002e+00 [8.291342e-09] 
Layer 'fc6' weights[0]: 7.551456e-03 [3.915871e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.454708e-10] 
Layer 'fc7' weights[0]: 7.443788e-03 [4.081427e-08] 
Layer 'fc7' biases: 9.998530e-01 [1.279960e-08] 
Layer 'fc8' weights[0]: 6.143480e-04 [5.547134e-07] 
Layer 'fc8' biases: 1.707717e-01 [2.522741e-06] 
Train error last 27 batches: 0.635670
-------------------------------------------------------
Not saving because 0.633101 > 0.627087 (334.9: -0.00%)
======================================================= (1.883 sec)
395.13... logprob:  0.657048, 0.359375 (0.651 sec)
395.14... logprob:  0.662661, 0.367188 (0.650 sec)
395.15... logprob:  0.685686, 0.398438 (0.651 sec)
395.16... logprob:  0.627078, 0.320312 (0.651 sec)
395.17... logprob:  0.638503, 0.335938 (0.653 sec)
395.18... logprob:  0.638221, 0.335938 (0.653 sec)
395.19... logprob:  0.632702, 0.328125 (0.651 sec)
395.20... logprob:  0.648918, 0.351562 (0.652 sec)
395.21... logprob:  0.643445, 0.343750 (0.652 sec)
395.22... logprob:  0.627903, 0.320312 (0.650 sec)
395.23... logprob:  0.622991, 0.312500 (0.651 sec)
395.24... logprob:  0.577242, 0.242188 (0.651 sec)
395.25... logprob:  0.628052, 0.320312 (0.651 sec)
395.26... logprob:  0.674305, 0.390625 (0.666 sec)
395.27... logprob:  0.627937, 0.320312 (0.670 sec)
396.1... logprob:  0.679735, 0.398438 (0.659 sec)
396.2... logprob:  0.596837, 0.273438 (0.658 sec)
396.3... logprob:  0.653840, 0.359375 (0.655 sec)
396.4... logprob:  0.596542, 0.273438 (0.648 sec)
396.5... logprob:  0.590861, 0.265625 (0.651 sec)
396.6... logprob:  0.611410, 0.296875 (0.650 sec)
396.7... logprob:  0.643808, 0.343750 (0.651 sec)
396.8... logprob:  0.604941, 0.289062 (0.651 sec)
396.9... logprob:  0.638503, 0.335938 (0.651 sec)
396.10... logprob:  0.598161, 0.281250 (0.650 sec)
396.11... logprob:  0.638777, 0.335938 (0.651 sec)
396.12... logprob:  0.716927, 0.437500 (0.652 sec)
396.13... logprob:  0.657037, 0.359375 (0.652 sec)
396.14... logprob:  0.662650, 0.367188 (0.650 sec)
396.15... logprob:  0.685670, 0.398438 (0.651 sec)
396.16... logprob:  0.627078, 0.320312 (0.651 sec)
396.17... logprob:  0.638503, 0.335938 (0.653 sec)
396.18... logprob:  0.638219, 0.335938 (0.652 sec)
396.19... logprob:  0.632701, 0.328125 (0.651 sec)
396.20... logprob:  0.648918, 0.351562 (0.651 sec)
396.21... logprob:  0.643445, 0.343750 (0.652 sec)
396.22... logprob:  0.627901, 0.320312 (0.650 sec)
396.23... logprob:  0.622989, 0.312500 (0.650 sec)
396.24... logprob:  0.577231, 0.242188 (0.650 sec)
396.25... logprob:  0.628050, 0.320312 (0.651 sec)
396.26... logprob:  0.674310, 0.390625 (0.651 sec)
396.27... logprob:  0.627934, 0.320312 (0.651 sec)
397.1... logprob:  0.679742, 0.398438 (0.650 sec)
397.2... logprob:  0.596829, 0.273438 (0.651 sec)
397.3... logprob:  0.653842, 0.359375 (0.651 sec)
397.4... logprob:  0.596534, 0.273438 (0.650 sec)
397.5... logprob:  0.590854, 0.265625 (0.650 sec)
397.6... logprob:  0.611407, 0.296875 (0.651 sec)
397.7... logprob:  0.643809, 0.343750 (0.650 sec)
397.8... logprob:  0.604939, 0.289062 (0.650 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627193, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937324e-03 [7.213658e-09] 
Layer 'conv1' biases: 6.168022e-07 [1.443037e-10] 
Layer 'conv2' weights[0]: 7.925310e-03 [6.283921e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.452019e-10] 
Layer 'conv3' weights[0]: 7.922921e-03 [6.061434e-09] 
Layer 'conv3' biases: 5.122572e-06 [2.203408e-09] 
Layer 'conv4' weights[0]: 7.955775e-03 [6.165857e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.878190e-08] 
Layer 'conv5' weights[0]: 7.955136e-03 [1.055757e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.115173e-07] 
Layer 'fc6' weights[0]: 7.551264e-03 [1.192478e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.132729e-08] 
Layer 'fc7' weights[0]: 7.441835e-03 [1.454706e-07] 
Layer 'fc7' biases: 9.998526e-01 [1.314833e-07] 
Layer 'fc8' weights[0]: 5.976921e-04 [6.890406e-06] 
Layer 'fc8' biases: 1.709676e-01 [1.691661e-04] 
Train error last 27 batches: 0.635665
-------------------------------------------------------
Not saving because 0.627193 > 0.627087 (334.9: -0.00%)
======================================================= (1.758 sec)
397.9... logprob:  0.638503, 0.335938 (0.650 sec)
397.10... logprob:  0.598161, 0.281250 (0.650 sec)
397.11... logprob:  0.638777, 0.335938 (0.651 sec)
397.12... logprob:  0.716919, 0.437500 (0.652 sec)
397.13... logprob:  0.657035, 0.359375 (0.651 sec)
397.14... logprob:  0.662647, 0.367188 (0.651 sec)
397.15... logprob:  0.685667, 0.398438 (0.650 sec)
397.16... logprob:  0.627078, 0.320312 (0.651 sec)
397.17... logprob:  0.638503, 0.335938 (0.652 sec)
397.18... logprob:  0.638220, 0.335938 (0.651 sec)
397.19... logprob:  0.632701, 0.328125 (0.651 sec)
397.20... logprob:  0.648920, 0.351562 (0.651 sec)
397.21... logprob:  0.643446, 0.343750 (0.652 sec)
397.22... logprob:  0.627898, 0.320312 (0.650 sec)
397.23... logprob:  0.622985, 0.312500 (0.650 sec)
397.24... logprob:  0.577219, 0.242188 (0.651 sec)
397.25... logprob:  0.628048, 0.320312 (0.652 sec)
397.26... logprob:  0.674314, 0.390625 (0.651 sec)
397.27... logprob:  0.627933, 0.320312 (0.651 sec)
398.1... logprob:  0.679744, 0.398438 (0.651 sec)
398.2... logprob:  0.596826, 0.273438 (0.650 sec)
398.3... logprob:  0.653842, 0.359375 (0.652 sec)
398.4... logprob:  0.596534, 0.273438 (0.651 sec)
398.5... logprob:  0.590855, 0.265625 (0.651 sec)
398.6... logprob:  0.611409, 0.296875 (0.651 sec)
398.7... logprob:  0.643808, 0.343750 (0.652 sec)
398.8... logprob:  0.604944, 0.289062 (0.650 sec)
398.9... logprob:  0.638502, 0.335938 (0.650 sec)
398.10... logprob:  0.598169, 0.281250 (0.651 sec)
398.11... logprob:  0.638773, 0.335938 (0.651 sec)
398.12... logprob:  0.716893, 0.437500 (0.652 sec)
398.13... logprob:  0.657027, 0.359375 (0.651 sec)
398.14... logprob:  0.662638, 0.367188 (0.650 sec)
398.15... logprob:  0.685656, 0.398438 (0.651 sec)
398.16... logprob:  0.627078, 0.320312 (0.651 sec)
398.17... logprob:  0.638502, 0.335938 (0.652 sec)
398.18... logprob:  0.638220, 0.335938 (0.652 sec)
398.19... logprob:  0.632701, 0.328125 (0.652 sec)
398.20... logprob:  0.648920, 0.351562 (0.651 sec)
398.21... logprob:  0.643446, 0.343750 (0.652 sec)
398.22... logprob:  0.627896, 0.320312 (0.651 sec)
398.23... logprob:  0.622982, 0.312500 (0.651 sec)
398.24... logprob:  0.577206, 0.242188 (0.651 sec)
398.25... logprob:  0.628045, 0.320312 (0.652 sec)
398.26... logprob:  0.674320, 0.390625 (0.652 sec)
398.27... logprob:  0.627930, 0.320312 (0.651 sec)
399.1... logprob:  0.679750, 0.398438 (0.651 sec)
399.2... logprob:  0.596819, 0.273438 (0.651 sec)
399.3... logprob:  0.653844, 0.359375 (0.651 sec)
399.4... logprob:  0.596528, 0.273438 (0.650 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.654003, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937150e-03 [6.930311e-09] 
Layer 'conv1' biases: 6.205377e-07 [8.920374e-11] 
Layer 'conv2' weights[0]: 7.925128e-03 [5.304877e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.574923e-10] 
Layer 'conv3' weights[0]: 7.922730e-03 [4.937303e-09] 
Layer 'conv3' biases: 5.153180e-06 [1.197181e-09] 
Layer 'conv4' weights[0]: 7.955577e-03 [4.880625e-09] 
Layer 'conv4' biases: 1.000001e+00 [8.846200e-09] 
Layer 'conv5' weights[0]: 7.954934e-03 [4.995831e-08] 
Layer 'conv5' biases: 1.000002e+00 [5.250861e-08] 
Layer 'fc6' weights[0]: 7.551060e-03 [6.629196e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.318042e-09] 
Layer 'fc7' weights[0]: 7.439928e-03 [8.107565e-08] 
Layer 'fc7' biases: 9.998522e-01 [6.189077e-08] 
Layer 'fc8' weights[0]: 5.748838e-04 [3.215340e-06] 
Layer 'fc8' biases: 1.709799e-01 [8.531362e-05] 
Train error last 27 batches: 0.635661
-------------------------------------------------------
Not saving because 0.654003 > 0.627087 (334.9: -0.00%)
======================================================= (1.793 sec)
399.5... logprob:  0.590850, 0.265625 (0.651 sec)
399.6... logprob:  0.611407, 0.296875 (0.651 sec)
399.7... logprob:  0.643808, 0.343750 (0.650 sec)
399.8... logprob:  0.604944, 0.289062 (0.651 sec)
399.9... logprob:  0.638501, 0.335938 (0.650 sec)
399.10... logprob:  0.598170, 0.281250 (0.651 sec)
399.11... logprob:  0.638772, 0.335938 (0.651 sec)
399.12... logprob:  0.716882, 0.437500 (0.653 sec)
399.13... logprob:  0.657023, 0.359375 (0.651 sec)
399.14... logprob:  0.662635, 0.367188 (0.650 sec)
399.15... logprob:  0.685653, 0.398438 (0.650 sec)
399.16... logprob:  0.627079, 0.320312 (0.652 sec)
399.17... logprob:  0.638503, 0.335938 (0.653 sec)
399.18... logprob:  0.638220, 0.335938 (0.652 sec)
399.19... logprob:  0.632700, 0.328125 (0.651 sec)
399.20... logprob:  0.648921, 0.351562 (0.651 sec)
399.21... logprob:  0.643447, 0.343750 (0.652 sec)
399.22... logprob:  0.627894, 0.320312 (0.651 sec)
399.23... logprob:  0.622978, 0.312500 (0.650 sec)
399.24... logprob:  0.577194, 0.242188 (0.650 sec)
399.25... logprob:  0.628042, 0.320312 (0.651 sec)
399.26... logprob:  0.674324, 0.390625 (0.652 sec)
399.27... logprob:  0.627928, 0.320312 (0.651 sec)
400.1... logprob:  0.679754, 0.398438 (0.652 sec)
400.2... logprob:  0.596815, 0.273438 (0.651 sec)
400.3... logprob:  0.653844, 0.359375 (0.650 sec)
400.4... logprob:  0.596526, 0.273438 (0.651 sec)
400.5... logprob:  0.590850, 0.265625 (0.651 sec)
400.6... logprob:  0.611408, 0.296875 (0.650 sec)
400.7... logprob:  0.643807, 0.343750 (0.651 sec)
400.8... logprob:  0.604947, 0.289062 (0.650 sec)
400.9... logprob:  0.638500, 0.335938 (0.650 sec)
400.10... logprob:  0.598176, 0.281250 (0.650 sec)
400.11... logprob:  0.638769, 0.335938 (0.651 sec)
400.12... logprob:  0.716857, 0.437500 (0.651 sec)
400.13... logprob:  0.657015, 0.359375 (0.651 sec)
400.14... logprob:  0.662626, 0.367188 (0.650 sec)
400.15... logprob:  0.685641, 0.398438 (0.650 sec)
400.16... logprob:  0.627079, 0.320312 (0.651 sec)
400.17... logprob:  0.638503, 0.335938 (0.652 sec)
400.18... logprob:  0.638219, 0.335938 (0.651 sec)
400.19... logprob:  0.632700, 0.328125 (0.653 sec)
400.20... logprob:  0.648922, 0.351562 (0.651 sec)
400.21... logprob:  0.643447, 0.343750 (0.652 sec)
400.22... logprob:  0.627892, 0.320312 (0.650 sec)
400.23... logprob:  0.622974, 0.312500 (0.650 sec)
400.24... logprob:  0.577181, 0.242188 (0.650 sec)
400.25... logprob:  0.628039, 0.320312 (0.651 sec)
400.26... logprob:  0.674329, 0.390625 (0.651 sec)
400.27... logprob:  0.627926, 0.320312 (0.651 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627910, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936958e-03 [6.668037e-09] 
Layer 'conv1' biases: 6.240934e-07 [7.107278e-11] 
Layer 'conv2' weights[0]: 7.924941e-03 [4.926745e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.579898e-10] 
Layer 'conv3' weights[0]: 7.922519e-03 [4.444665e-09] 
Layer 'conv3' biases: 5.181371e-06 [6.838233e-10] 
Layer 'conv4' weights[0]: 7.955371e-03 [4.370421e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.405816e-09] 
Layer 'conv5' weights[0]: 7.954744e-03 [1.964557e-08] 
Layer 'conv5' biases: 1.000002e+00 [2.034029e-08] 
Layer 'fc6' weights[0]: 7.550879e-03 [4.389096e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.028046e-09] 
Layer 'fc7' weights[0]: 7.438046e-03 [4.896279e-08] 
Layer 'fc7' biases: 9.998522e-01 [2.402225e-08] 
Layer 'fc8' weights[0]: 5.707229e-04 [1.209415e-06] 
Layer 'fc8' biases: 1.714949e-01 [3.959363e-05] 
Train error last 27 batches: 0.635657
-------------------------------------------------------
Not saving because 0.627910 > 0.627087 (334.9: -0.00%)
======================================================= (1.846 sec)
401.1... logprob:  0.679760, 0.398438 (0.654 sec)
401.2... logprob:  0.596808, 0.273438 (0.660 sec)
401.3... logprob:  0.653846, 0.359375 (0.650 sec)
401.4... logprob:  0.596520, 0.273438 (0.651 sec)
401.5... logprob:  0.590844, 0.265625 (0.650 sec)
401.6... logprob:  0.611406, 0.296875 (0.653 sec)
401.7... logprob:  0.643808, 0.343750 (0.650 sec)
401.8... logprob:  0.604948, 0.289062 (0.651 sec)
401.9... logprob:  0.638499, 0.335938 (0.650 sec)
401.10... logprob:  0.598180, 0.281250 (0.650 sec)
401.11... logprob:  0.638767, 0.335938 (0.653 sec)
401.12... logprob:  0.716842, 0.437500 (0.652 sec)
401.13... logprob:  0.657010, 0.359375 (0.650 sec)
401.14... logprob:  0.662621, 0.367188 (0.650 sec)
401.15... logprob:  0.685635, 0.398438 (0.650 sec)
401.16... logprob:  0.627079, 0.320312 (0.651 sec)
401.17... logprob:  0.638503, 0.335938 (0.652 sec)
401.18... logprob:  0.638219, 0.335938 (0.652 sec)
401.19... logprob:  0.632699, 0.328125 (0.651 sec)
401.20... logprob:  0.648923, 0.351562 (0.651 sec)
401.21... logprob:  0.643448, 0.343750 (0.652 sec)
401.22... logprob:  0.627889, 0.320312 (0.650 sec)
401.23... logprob:  0.622970, 0.312500 (0.649 sec)
401.24... logprob:  0.577166, 0.242188 (0.650 sec)
401.25... logprob:  0.628037, 0.320312 (0.651 sec)
401.26... logprob:  0.674335, 0.390625 (0.651 sec)
401.27... logprob:  0.627924, 0.320312 (0.650 sec)
402.1... logprob:  0.679764, 0.398438 (0.651 sec)
402.2... logprob:  0.596803, 0.273438 (0.650 sec)
402.3... logprob:  0.653847, 0.359375 (0.650 sec)
402.4... logprob:  0.596517, 0.273438 (0.650 sec)
402.5... logprob:  0.590843, 0.265625 (0.650 sec)
402.6... logprob:  0.611407, 0.296875 (0.650 sec)
402.7... logprob:  0.643806, 0.343750 (0.650 sec)
402.8... logprob:  0.604951, 0.289062 (0.650 sec)
402.9... logprob:  0.638498, 0.335938 (0.650 sec)
402.10... logprob:  0.598186, 0.281250 (0.649 sec)
402.11... logprob:  0.638764, 0.335938 (0.651 sec)
402.12... logprob:  0.716819, 0.437500 (0.651 sec)
402.13... logprob:  0.657002, 0.359375 (0.650 sec)
402.14... logprob:  0.662613, 0.367188 (0.650 sec)
402.15... logprob:  0.685625, 0.398438 (0.651 sec)
402.16... logprob:  0.627079, 0.320312 (0.651 sec)
402.17... logprob:  0.638503, 0.335938 (0.653 sec)
402.18... logprob:  0.638219, 0.335938 (0.661 sec)
402.19... logprob:  0.632699, 0.328125 (0.651 sec)
402.20... logprob:  0.648923, 0.351562 (0.661 sec)
402.21... logprob:  0.643448, 0.343750 (0.652 sec)
402.22... logprob:  0.627888, 0.320312 (0.650 sec)
402.23... logprob:  0.622968, 0.312500 (0.651 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633229, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936765e-03 [6.381396e-09] 
Layer 'conv1' biases: 6.276591e-07 [1.091285e-10] 
Layer 'conv2' weights[0]: 7.924769e-03 [5.381276e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.263056e-10] 
Layer 'conv3' weights[0]: 7.922323e-03 [4.767337e-09] 
Layer 'conv3' biases: 5.209837e-06 [1.114543e-09] 
Layer 'conv4' weights[0]: 7.955190e-03 [4.640043e-09] 
Layer 'conv4' biases: 1.000001e+00 [5.809432e-09] 
Layer 'conv5' weights[0]: 7.954561e-03 [3.243728e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.383430e-08] 
Layer 'fc6' weights[0]: 7.550686e-03 [5.243032e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.502891e-09] 
Layer 'fc7' weights[0]: 7.436187e-03 [6.316270e-08] 
Layer 'fc7' biases: 9.998521e-01 [4.177175e-08] 
Layer 'fc8' weights[0]: 5.647084e-04 [2.125846e-06] 
Layer 'fc8' biases: 1.719319e-01 [3.878906e-05] 
Train error last 27 batches: 0.635653
-------------------------------------------------------
Not saving because 0.633229 > 0.627087 (334.9: -0.00%)
======================================================= (1.816 sec)
402.24... logprob:  0.577157, 0.242188 (0.651 sec)
402.25... logprob:  0.628034, 0.320312 (0.651 sec)
402.26... logprob:  0.674338, 0.390625 (0.651 sec)
402.27... logprob:  0.627922, 0.320312 (0.651 sec)
403.1... logprob:  0.679769, 0.398438 (0.651 sec)
403.2... logprob:  0.596797, 0.273438 (0.651 sec)
403.3... logprob:  0.653848, 0.359375 (0.653 sec)
403.4... logprob:  0.596512, 0.273438 (0.651 sec)
403.5... logprob:  0.590838, 0.265625 (0.650 sec)
403.6... logprob:  0.611404, 0.296875 (0.650 sec)
403.7... logprob:  0.643807, 0.343750 (0.650 sec)
403.8... logprob:  0.604950, 0.289062 (0.650 sec)
403.9... logprob:  0.638498, 0.335938 (0.650 sec)
403.10... logprob:  0.598187, 0.281250 (0.650 sec)
403.11... logprob:  0.638763, 0.335938 (0.650 sec)
403.12... logprob:  0.716810, 0.437500 (0.651 sec)
403.13... logprob:  0.656999, 0.359375 (0.651 sec)
403.14... logprob:  0.662611, 0.367188 (0.650 sec)
403.15... logprob:  0.685622, 0.398438 (0.650 sec)
403.16... logprob:  0.627079, 0.320312 (0.651 sec)
403.17... logprob:  0.638502, 0.335938 (0.652 sec)
403.18... logprob:  0.638220, 0.335938 (0.652 sec)
403.19... logprob:  0.632699, 0.328125 (0.651 sec)
403.20... logprob:  0.648925, 0.351562 (0.652 sec)
403.21... logprob:  0.643449, 0.343750 (0.652 sec)
403.22... logprob:  0.627885, 0.320312 (0.651 sec)
403.23... logprob:  0.622963, 0.312500 (0.650 sec)
403.24... logprob:  0.577140, 0.242188 (0.651 sec)
403.25... logprob:  0.628031, 0.320312 (0.652 sec)
403.26... logprob:  0.674344, 0.390625 (0.652 sec)
403.27... logprob:  0.627920, 0.320312 (0.651 sec)
404.1... logprob:  0.679774, 0.398438 (0.651 sec)
404.2... logprob:  0.596793, 0.273438 (0.651 sec)
404.3... logprob:  0.653849, 0.359375 (0.650 sec)
404.4... logprob:  0.596511, 0.273438 (0.651 sec)
404.5... logprob:  0.590839, 0.265625 (0.651 sec)
404.6... logprob:  0.611407, 0.296875 (0.650 sec)
404.7... logprob:  0.643805, 0.343750 (0.651 sec)
404.8... logprob:  0.604955, 0.289062 (0.650 sec)
404.9... logprob:  0.638496, 0.335938 (0.651 sec)
404.10... logprob:  0.598196, 0.281250 (0.650 sec)
404.11... logprob:  0.638760, 0.335938 (0.651 sec)
404.12... logprob:  0.716778, 0.437500 (0.652 sec)
404.13... logprob:  0.656989, 0.359375 (0.651 sec)
404.14... logprob:  0.662600, 0.367188 (0.650 sec)
404.15... logprob:  0.685607, 0.398438 (0.651 sec)
404.16... logprob:  0.627080, 0.320312 (0.651 sec)
404.17... logprob:  0.638502, 0.335938 (0.652 sec)
404.18... logprob:  0.638219, 0.335938 (0.652 sec)
404.19... logprob:  0.632699, 0.328125 (0.651 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.686289, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936579e-03 [6.812948e-09] 
Layer 'conv1' biases: 6.310164e-07 [1.567588e-10] 
Layer 'conv2' weights[0]: 7.924571e-03 [6.547131e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.533549e-10] 
Layer 'conv3' weights[0]: 7.922128e-03 [5.675233e-09] 
Layer 'conv3' biases: 5.235675e-06 [2.047356e-09] 
Layer 'conv4' weights[0]: 7.955004e-03 [5.617018e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.378769e-08] 
Layer 'conv5' weights[0]: 7.954377e-03 [7.736078e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.144450e-08] 
Layer 'fc6' weights[0]: 7.550483e-03 [9.301141e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.318406e-09] 
Layer 'fc7' weights[0]: 7.434324e-03 [1.141759e-07] 
Layer 'fc7' biases: 9.998522e-01 [9.724299e-08] 
Layer 'fc8' weights[0]: 5.778892e-04 [5.030731e-06] 
Layer 'fc8' biases: 1.729040e-01 [1.047252e-04] 
Train error last 27 batches: 0.635649
-------------------------------------------------------
Not saving because 0.686289 > 0.627087 (334.9: -0.00%)
======================================================= (1.762 sec)
404.20... logprob:  0.648925, 0.351562 (0.650 sec)
404.21... logprob:  0.643449, 0.343750 (0.652 sec)
404.22... logprob:  0.627883, 0.320312 (0.650 sec)
404.23... logprob:  0.622960, 0.312500 (0.650 sec)
404.24... logprob:  0.577128, 0.242188 (0.650 sec)
404.25... logprob:  0.628029, 0.320312 (0.651 sec)
404.26... logprob:  0.674350, 0.390625 (0.651 sec)
404.27... logprob:  0.627917, 0.320312 (0.651 sec)
405.1... logprob:  0.679781, 0.398438 (0.650 sec)
405.2... logprob:  0.596784, 0.273438 (0.650 sec)
405.3... logprob:  0.653851, 0.359375 (0.651 sec)
405.4... logprob:  0.596503, 0.273438 (0.650 sec)
405.5... logprob:  0.590833, 0.265625 (0.650 sec)
405.6... logprob:  0.611405, 0.296875 (0.650 sec)
405.7... logprob:  0.643806, 0.343750 (0.650 sec)
405.8... logprob:  0.604956, 0.289062 (0.650 sec)
405.9... logprob:  0.638496, 0.335938 (0.650 sec)
405.10... logprob:  0.598198, 0.281250 (0.650 sec)
405.11... logprob:  0.638758, 0.335938 (0.650 sec)
405.12... logprob:  0.716766, 0.437500 (0.651 sec)
405.13... logprob:  0.656984, 0.359375 (0.653 sec)
405.14... logprob:  0.662595, 0.367188 (0.650 sec)
405.15... logprob:  0.685602, 0.398438 (0.650 sec)
405.16... logprob:  0.627080, 0.320312 (0.651 sec)
405.17... logprob:  0.638502, 0.335938 (0.652 sec)
405.18... logprob:  0.638219, 0.335938 (0.651 sec)
405.19... logprob:  0.632698, 0.328125 (0.651 sec)
405.20... logprob:  0.648926, 0.351562 (0.651 sec)
405.21... logprob:  0.643449, 0.343750 (0.652 sec)
405.22... logprob:  0.627882, 0.320312 (0.650 sec)
405.23... logprob:  0.622957, 0.312500 (0.650 sec)
405.24... logprob:  0.577120, 0.242188 (0.651 sec)
405.25... logprob:  0.628027, 0.320312 (0.651 sec)
405.26... logprob:  0.674352, 0.390625 (0.651 sec)
405.27... logprob:  0.627916, 0.320312 (0.650 sec)
406.1... logprob:  0.679783, 0.398438 (0.651 sec)
406.2... logprob:  0.596781, 0.273438 (0.651 sec)
406.3... logprob:  0.653852, 0.359375 (0.650 sec)
406.4... logprob:  0.596501, 0.273438 (0.650 sec)
406.5... logprob:  0.590831, 0.265625 (0.651 sec)
406.6... logprob:  0.611405, 0.296875 (0.650 sec)
406.7... logprob:  0.643806, 0.343750 (0.650 sec)
406.8... logprob:  0.604956, 0.289062 (0.650 sec)
406.9... logprob:  0.638495, 0.335938 (0.650 sec)
406.10... logprob:  0.598201, 0.281250 (0.650 sec)
406.11... logprob:  0.638756, 0.335938 (0.651 sec)
406.12... logprob:  0.716753, 0.437500 (0.651 sec)
406.13... logprob:  0.656980, 0.359375 (0.651 sec)
406.14... logprob:  0.662591, 0.367188 (0.650 sec)
406.15... logprob:  0.685598, 0.398438 (0.650 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.632858, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936366e-03 [7.341583e-09] 
Layer 'conv1' biases: 6.342938e-07 [2.030503e-10] 
Layer 'conv2' weights[0]: 7.924378e-03 [7.558491e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.009738e-09] 
Layer 'conv3' weights[0]: 7.921927e-03 [6.509127e-09] 
Layer 'conv3' biases: 5.260428e-06 [2.780309e-09] 
Layer 'conv4' weights[0]: 7.954816e-03 [6.555403e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.021815e-08] 
Layer 'conv5' weights[0]: 7.954157e-03 [1.134973e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.198752e-07] 
Layer 'fc6' weights[0]: 7.550291e-03 [1.264340e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.215100e-08] 
Layer 'fc7' weights[0]: 7.432420e-03 [1.534569e-07] 
Layer 'fc7' biases: 9.998526e-01 [1.403969e-07] 
Layer 'fc8' weights[0]: 5.979069e-04 [7.373619e-06] 
Layer 'fc8' biases: 1.740331e-01 [1.530288e-04] 
Train error last 27 batches: 0.635645
-------------------------------------------------------
Not saving because 0.632858 > 0.627087 (334.9: -0.00%)
======================================================= (1.751 sec)
406.16... logprob:  0.627080, 0.320312 (0.651 sec)
406.17... logprob:  0.638502, 0.335938 (0.654 sec)
406.18... logprob:  0.638219, 0.335938 (0.652 sec)
406.19... logprob:  0.632698, 0.328125 (0.652 sec)
406.20... logprob:  0.648928, 0.351562 (0.651 sec)
406.21... logprob:  0.643450, 0.343750 (0.652 sec)
406.22... logprob:  0.627879, 0.320312 (0.651 sec)
406.23... logprob:  0.622954, 0.312500 (0.650 sec)
406.24... logprob:  0.577106, 0.242188 (0.651 sec)
406.25... logprob:  0.628025, 0.320312 (0.652 sec)
406.26... logprob:  0.674358, 0.390625 (0.662 sec)
406.27... logprob:  0.627914, 0.320312 (0.651 sec)
407.1... logprob:  0.679788, 0.398438 (0.651 sec)
407.2... logprob:  0.596776, 0.273438 (0.652 sec)
407.3... logprob:  0.653852, 0.359375 (0.652 sec)
407.4... logprob:  0.596498, 0.273438 (0.651 sec)
407.5... logprob:  0.590830, 0.265625 (0.650 sec)
407.6... logprob:  0.611405, 0.296875 (0.652 sec)
407.7... logprob:  0.643805, 0.343750 (0.651 sec)
407.8... logprob:  0.604960, 0.289062 (0.650 sec)
407.9... logprob:  0.638494, 0.335938 (0.650 sec)
407.10... logprob:  0.598207, 0.281250 (0.650 sec)
407.11... logprob:  0.638753, 0.335938 (0.650 sec)
407.12... logprob:  0.716729, 0.437500 (0.651 sec)
407.13... logprob:  0.656972, 0.359375 (0.651 sec)
407.14... logprob:  0.662584, 0.367188 (0.650 sec)
407.15... logprob:  0.685588, 0.398438 (0.650 sec)
407.16... logprob:  0.627081, 0.320312 (0.652 sec)
407.17... logprob:  0.638501, 0.335938 (0.652 sec)
407.18... logprob:  0.638219, 0.335938 (0.652 sec)
407.19... logprob:  0.632698, 0.328125 (0.651 sec)
407.20... logprob:  0.648929, 0.351562 (0.651 sec)
407.21... logprob:  0.643451, 0.343750 (0.652 sec)
407.22... logprob:  0.627877, 0.320312 (0.651 sec)
407.23... logprob:  0.622950, 0.312500 (0.650 sec)
407.24... logprob:  0.577093, 0.242188 (0.651 sec)
407.25... logprob:  0.628022, 0.320312 (0.652 sec)
407.26... logprob:  0.674363, 0.390625 (0.652 sec)
407.27... logprob:  0.627912, 0.320312 (0.651 sec)
408.1... logprob:  0.679794, 0.398438 (0.651 sec)
408.2... logprob:  0.596769, 0.273438 (0.650 sec)
408.3... logprob:  0.653855, 0.359375 (0.651 sec)
408.4... logprob:  0.596493, 0.273438 (0.650 sec)
408.5... logprob:  0.590825, 0.265625 (0.651 sec)
408.6... logprob:  0.611403, 0.296875 (0.650 sec)
408.7... logprob:  0.643805, 0.343750 (0.650 sec)
408.8... logprob:  0.604961, 0.289062 (0.650 sec)
408.9... logprob:  0.638493, 0.335938 (0.651 sec)
408.10... logprob:  0.598211, 0.281250 (0.656 sec)
408.11... logprob:  0.638751, 0.335938 (0.658 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627143, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936155e-03 [6.889868e-09] 
Layer 'conv1' biases: 6.376341e-07 [1.218379e-10] 
Layer 'conv2' weights[0]: 7.924192e-03 [5.796939e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.825414e-10] 
Layer 'conv3' weights[0]: 7.921728e-03 [5.593145e-09] 
Layer 'conv3' biases: 5.285970e-06 [1.814189e-09] 
Layer 'conv4' weights[0]: 7.954607e-03 [5.677830e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.532918e-08] 
Layer 'conv5' weights[0]: 7.953960e-03 [8.580265e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.087737e-08] 
Layer 'fc6' weights[0]: 7.550105e-03 [1.004505e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.169491e-09] 
Layer 'fc7' weights[0]: 7.430525e-03 [1.220505e-07] 
Layer 'fc7' biases: 9.998528e-01 [1.051261e-07] 
Layer 'fc8' weights[0]: 6.100723e-04 [5.542519e-06] 
Layer 'fc8' biases: 1.749421e-01 [1.369393e-04] 
Train error last 27 batches: 0.635642
-------------------------------------------------------
Not saving because 0.627143 > 0.627087 (334.9: -0.00%)
======================================================= (1.765 sec)
408.12... logprob:  0.716711, 0.437500 (0.647 sec)
408.13... logprob:  0.656966, 0.359375 (0.646 sec)
408.14... logprob:  0.662577, 0.367188 (0.645 sec)
408.15... logprob:  0.685580, 0.398438 (0.645 sec)
408.16... logprob:  0.627081, 0.320312 (0.647 sec)
408.17... logprob:  0.638501, 0.335938 (0.648 sec)
408.18... logprob:  0.638219, 0.335938 (0.647 sec)
408.19... logprob:  0.632697, 0.328125 (0.652 sec)
408.20... logprob:  0.648929, 0.351562 (0.647 sec)
408.21... logprob:  0.643451, 0.343750 (0.647 sec)
408.22... logprob:  0.627874, 0.320312 (0.646 sec)
408.23... logprob:  0.622946, 0.312500 (0.646 sec)
408.24... logprob:  0.577079, 0.242188 (0.651 sec)
408.25... logprob:  0.628018, 0.320312 (0.655 sec)
408.26... logprob:  0.674370, 0.390625 (0.649 sec)
408.27... logprob:  0.627910, 0.320312 (0.648 sec)
409.1... logprob:  0.679799, 0.398438 (0.647 sec)
409.2... logprob:  0.596763, 0.273438 (0.653 sec)
409.3... logprob:  0.653856, 0.359375 (0.644 sec)
409.4... logprob:  0.596489, 0.273438 (0.646 sec)
409.5... logprob:  0.590822, 0.265625 (0.646 sec)
409.6... logprob:  0.611403, 0.296875 (0.645 sec)
409.7... logprob:  0.643805, 0.343750 (0.645 sec)
409.8... logprob:  0.604964, 0.289062 (0.645 sec)
409.9... logprob:  0.638493, 0.335938 (0.645 sec)
409.10... logprob:  0.598216, 0.281250 (0.645 sec)
409.11... logprob:  0.638749, 0.335938 (0.647 sec)
409.12... logprob:  0.716688, 0.437500 (0.656 sec)
409.13... logprob:  0.656959, 0.359375 (0.647 sec)
409.14... logprob:  0.662569, 0.367188 (0.654 sec)
409.15... logprob:  0.685570, 0.398438 (0.656 sec)
409.16... logprob:  0.627081, 0.320312 (0.657 sec)
409.17... logprob:  0.638501, 0.335938 (0.656 sec)
409.18... logprob:  0.638220, 0.335938 (0.654 sec)
409.19... logprob:  0.632698, 0.328125 (0.653 sec)
409.20... logprob:  0.648930, 0.351562 (0.654 sec)
409.21... logprob:  0.643451, 0.343750 (0.654 sec)
409.22... logprob:  0.627873, 0.320312 (0.646 sec)
409.23... logprob:  0.622943, 0.312500 (0.646 sec)
409.24... logprob:  0.577066, 0.242188 (0.647 sec)
409.25... logprob:  0.628017, 0.320312 (0.647 sec)
409.26... logprob:  0.674376, 0.390625 (0.647 sec)
409.27... logprob:  0.627908, 0.320312 (0.646 sec)
410.1... logprob:  0.679805, 0.398438 (0.646 sec)
410.2... logprob:  0.596758, 0.273438 (0.646 sec)
410.3... logprob:  0.653858, 0.359375 (0.647 sec)
410.4... logprob:  0.596485, 0.273438 (0.646 sec)
410.5... logprob:  0.590820, 0.265625 (0.646 sec)
410.6... logprob:  0.611403, 0.296875 (0.647 sec)
410.7... logprob:  0.643804, 0.343750 (0.646 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.654978, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935951e-03 [6.867361e-09] 
Layer 'conv1' biases: 6.413159e-07 [1.259677e-10] 
Layer 'conv2' weights[0]: 7.923992e-03 [5.787850e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.054142e-10] 
Layer 'conv3' weights[0]: 7.921544e-03 [5.584761e-09] 
Layer 'conv3' biases: 5.316573e-06 [1.837695e-09] 
Layer 'conv4' weights[0]: 7.954411e-03 [5.644705e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.553109e-08] 
Layer 'conv5' weights[0]: 7.953780e-03 [8.688053e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.162800e-08] 
Layer 'fc6' weights[0]: 7.549911e-03 [1.011864e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.260900e-09] 
Layer 'fc7' weights[0]: 7.428622e-03 [1.239700e-07] 
Layer 'fc7' biases: 9.998524e-01 [1.075529e-07] 
Layer 'fc8' weights[0]: 5.874634e-04 [5.561792e-06] 
Layer 'fc8' biases: 1.749599e-01 [1.421609e-04] 
Train error last 27 batches: 0.635637
-------------------------------------------------------
Not saving because 0.654978 > 0.627087 (334.9: -0.00%)
======================================================= (1.763 sec)
410.8... logprob:  0.604966, 0.289062 (0.650 sec)
410.9... logprob:  0.638492, 0.335938 (0.650 sec)
410.10... logprob:  0.598220, 0.281250 (0.649 sec)
410.11... logprob:  0.638747, 0.335938 (0.650 sec)
410.12... logprob:  0.716671, 0.437500 (0.651 sec)
410.13... logprob:  0.656953, 0.359375 (0.650 sec)
410.14... logprob:  0.662564, 0.367188 (0.650 sec)
410.15... logprob:  0.685563, 0.398438 (0.650 sec)
410.16... logprob:  0.627082, 0.320312 (0.650 sec)
410.17... logprob:  0.638501, 0.335938 (0.652 sec)
410.18... logprob:  0.638219, 0.335938 (0.651 sec)
410.19... logprob:  0.632697, 0.328125 (0.651 sec)
410.20... logprob:  0.648931, 0.351562 (0.651 sec)
410.21... logprob:  0.643452, 0.343750 (0.651 sec)
410.22... logprob:  0.627871, 0.320312 (0.650 sec)
410.23... logprob:  0.622939, 0.312500 (0.651 sec)
410.24... logprob:  0.577054, 0.242188 (0.650 sec)
410.25... logprob:  0.628014, 0.320312 (0.651 sec)
410.26... logprob:  0.674380, 0.390625 (0.652 sec)
410.27... logprob:  0.627905, 0.320312 (0.650 sec)
411.1... logprob:  0.679809, 0.398438 (0.650 sec)
411.2... logprob:  0.596752, 0.273438 (0.650 sec)
411.3... logprob:  0.653859, 0.359375 (0.650 sec)
411.4... logprob:  0.596481, 0.273438 (0.650 sec)
411.5... logprob:  0.590816, 0.265625 (0.650 sec)
411.6... logprob:  0.611403, 0.296875 (0.650 sec)
411.7... logprob:  0.643805, 0.343750 (0.650 sec)
411.8... logprob:  0.604968, 0.289062 (0.650 sec)
411.9... logprob:  0.638491, 0.335938 (0.650 sec)
411.10... logprob:  0.598225, 0.281250 (0.650 sec)
411.11... logprob:  0.638744, 0.335938 (0.650 sec)
411.12... logprob:  0.716651, 0.437500 (0.651 sec)
411.13... logprob:  0.656947, 0.359375 (0.650 sec)
411.14... logprob:  0.662558, 0.367188 (0.650 sec)
411.15... logprob:  0.685554, 0.398438 (0.650 sec)
411.16... logprob:  0.627081, 0.320312 (0.650 sec)
411.17... logprob:  0.638500, 0.335938 (0.652 sec)
411.18... logprob:  0.638219, 0.335938 (0.651 sec)
411.19... logprob:  0.632697, 0.328125 (0.651 sec)
411.20... logprob:  0.648933, 0.351562 (0.651 sec)
411.21... logprob:  0.643452, 0.343750 (0.652 sec)
411.22... logprob:  0.627869, 0.320312 (0.650 sec)
411.23... logprob:  0.622935, 0.312500 (0.650 sec)
411.24... logprob:  0.577041, 0.242188 (0.650 sec)
411.25... logprob:  0.628011, 0.320312 (0.651 sec)
411.26... logprob:  0.674386, 0.390625 (0.651 sec)
411.27... logprob:  0.627904, 0.320312 (0.650 sec)
412.1... logprob:  0.679816, 0.398438 (0.652 sec)
412.2... logprob:  0.596746, 0.273438 (0.650 sec)
412.3... logprob:  0.653861, 0.359375 (0.649 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627864, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935760e-03 [6.752067e-09] 
Layer 'conv1' biases: 6.449890e-07 [6.602953e-11] 
Layer 'conv2' weights[0]: 7.923803e-03 [5.018397e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.549199e-10] 
Layer 'conv3' weights[0]: 7.921361e-03 [4.443233e-09] 
Layer 'conv3' biases: 5.346529e-06 [6.247462e-10] 
Layer 'conv4' weights[0]: 7.954222e-03 [4.332347e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.421746e-09] 
Layer 'conv5' weights[0]: 7.953591e-03 [9.416129e-09] 
Layer 'conv5' biases: 1.000002e+00 [9.036313e-09] 
Layer 'fc6' weights[0]: 7.549714e-03 [3.918139e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.200089e-10] 
Layer 'fc7' weights[0]: 7.426757e-03 [4.029033e-08] 
Layer 'fc7' biases: 9.998520e-01 [1.111919e-08] 
Layer 'fc8' weights[0]: 5.685040e-04 [5.625450e-07] 
Layer 'fc8' biases: 1.750486e-01 [2.008508e-05] 
Train error last 27 batches: 0.635633
-------------------------------------------------------
Not saving because 0.627864 > 0.627087 (334.9: -0.00%)
======================================================= (1.880 sec)
412.4... logprob:  0.596477, 0.273438 (0.650 sec)
412.5... logprob:  0.590814, 0.265625 (0.650 sec)
412.6... logprob:  0.611402, 0.296875 (0.650 sec)
412.7... logprob:  0.643804, 0.343750 (0.650 sec)
412.8... logprob:  0.604970, 0.289062 (0.649 sec)
412.9... logprob:  0.638490, 0.335938 (0.650 sec)
412.10... logprob:  0.598230, 0.281250 (0.650 sec)
412.11... logprob:  0.638742, 0.335938 (0.650 sec)
412.12... logprob:  0.716632, 0.437500 (0.652 sec)
412.13... logprob:  0.656941, 0.359375 (0.650 sec)
412.14... logprob:  0.662550, 0.367188 (0.649 sec)
412.15... logprob:  0.685546, 0.398438 (0.650 sec)
412.16... logprob:  0.627081, 0.320312 (0.650 sec)
412.17... logprob:  0.638500, 0.335938 (0.652 sec)
412.18... logprob:  0.638219, 0.335938 (0.651 sec)
412.19... logprob:  0.632696, 0.328125 (0.650 sec)
412.20... logprob:  0.648933, 0.351562 (0.651 sec)
412.21... logprob:  0.643453, 0.343750 (0.656 sec)
412.22... logprob:  0.627866, 0.320312 (0.650 sec)
412.23... logprob:  0.622933, 0.312500 (0.650 sec)
412.24... logprob:  0.577029, 0.242188 (0.650 sec)
412.25... logprob:  0.628009, 0.320312 (0.651 sec)
412.26... logprob:  0.674391, 0.390625 (0.650 sec)
412.27... logprob:  0.627903, 0.320312 (0.650 sec)
413.1... logprob:  0.679820, 0.398438 (0.654 sec)
413.2... logprob:  0.596741, 0.273438 (0.657 sec)
413.3... logprob:  0.653862, 0.359375 (0.650 sec)
413.4... logprob:  0.596473, 0.273438 (0.650 sec)
413.5... logprob:  0.590810, 0.265625 (0.651 sec)
413.6... logprob:  0.611402, 0.296875 (0.650 sec)
413.7... logprob:  0.643804, 0.343750 (0.650 sec)
413.8... logprob:  0.604971, 0.289062 (0.649 sec)
413.9... logprob:  0.638489, 0.335938 (0.649 sec)
413.10... logprob:  0.598233, 0.281250 (0.649 sec)
413.11... logprob:  0.638740, 0.335938 (0.649 sec)
413.12... logprob:  0.716616, 0.437500 (0.651 sec)
413.13... logprob:  0.656935, 0.359375 (0.650 sec)
413.14... logprob:  0.662545, 0.367188 (0.649 sec)
413.15... logprob:  0.685539, 0.398438 (0.650 sec)
413.16... logprob:  0.627082, 0.320312 (0.652 sec)
413.17... logprob:  0.638500, 0.335938 (0.651 sec)
413.18... logprob:  0.638219, 0.335938 (0.651 sec)
413.19... logprob:  0.632696, 0.328125 (0.650 sec)
413.20... logprob:  0.648934, 0.351562 (0.651 sec)
413.21... logprob:  0.643453, 0.343750 (0.651 sec)
413.22... logprob:  0.627866, 0.320312 (0.649 sec)
413.23... logprob:  0.622930, 0.312500 (0.650 sec)
413.24... logprob:  0.577021, 0.242188 (0.650 sec)
413.25... logprob:  0.628007, 0.320312 (0.650 sec)
413.26... logprob:  0.674393, 0.390625 (0.651 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633076, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935561e-03 [6.611603e-09] 
Layer 'conv1' biases: 6.484893e-07 [7.264962e-11] 
Layer 'conv2' weights[0]: 7.923630e-03 [5.053708e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.465554e-10] 
Layer 'conv3' weights[0]: 7.921160e-03 [4.416353e-09] 
Layer 'conv3' biases: 5.374324e-06 [6.036100e-10] 
Layer 'conv4' weights[0]: 7.954026e-03 [4.322458e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.164157e-09] 
Layer 'conv5' weights[0]: 7.953408e-03 [7.786547e-09] 
Layer 'conv5' biases: 1.000002e+00 [7.086515e-09] 
Layer 'fc6' weights[0]: 7.549508e-03 [3.870305e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.325107e-10] 
Layer 'fc7' weights[0]: 7.424862e-03 [3.913890e-08] 
Layer 'fc7' biases: 9.998518e-01 [8.876581e-09] 
Layer 'fc8' weights[0]: 5.663932e-04 [4.184668e-07] 
Layer 'fc8' biases: 1.756031e-01 [2.080489e-05] 
Train error last 27 batches: 0.635629
-------------------------------------------------------
Not saving because 0.633076 > 0.627087 (334.9: -0.00%)
======================================================= (1.890 sec)
413.27... logprob:  0.627901, 0.320312 (0.651 sec)
414.1... logprob:  0.679823, 0.398438 (0.651 sec)
414.2... logprob:  0.596736, 0.273438 (0.650 sec)
414.3... logprob:  0.653863, 0.359375 (0.649 sec)
414.4... logprob:  0.596470, 0.273438 (0.650 sec)
414.5... logprob:  0.590808, 0.265625 (0.650 sec)
414.6... logprob:  0.611401, 0.296875 (0.650 sec)
414.7... logprob:  0.643803, 0.343750 (0.650 sec)
414.8... logprob:  0.604971, 0.289062 (0.650 sec)
414.9... logprob:  0.638488, 0.335938 (0.650 sec)
414.10... logprob:  0.598235, 0.281250 (0.650 sec)
414.11... logprob:  0.638738, 0.335938 (0.651 sec)
414.12... logprob:  0.716605, 0.437500 (0.651 sec)
414.13... logprob:  0.656931, 0.359375 (0.650 sec)
414.14... logprob:  0.662542, 0.367188 (0.650 sec)
414.15... logprob:  0.685535, 0.398438 (0.650 sec)
414.16... logprob:  0.627082, 0.320312 (0.651 sec)
414.17... logprob:  0.638499, 0.335938 (0.652 sec)
414.18... logprob:  0.638220, 0.335938 (0.651 sec)
414.19... logprob:  0.632696, 0.328125 (0.651 sec)
414.20... logprob:  0.648935, 0.351562 (0.651 sec)
414.21... logprob:  0.643453, 0.343750 (0.651 sec)
414.22... logprob:  0.627863, 0.320312 (0.651 sec)
414.23... logprob:  0.622926, 0.312500 (0.650 sec)
414.24... logprob:  0.577008, 0.242188 (0.650 sec)
414.25... logprob:  0.628004, 0.320312 (0.651 sec)
414.26... logprob:  0.674398, 0.390625 (0.651 sec)
414.27... logprob:  0.627899, 0.320312 (0.650 sec)
415.1... logprob:  0.679827, 0.398438 (0.651 sec)
415.2... logprob:  0.596731, 0.273438 (0.650 sec)
415.3... logprob:  0.653864, 0.359375 (0.650 sec)
415.4... logprob:  0.596466, 0.273438 (0.653 sec)
415.5... logprob:  0.590806, 0.265625 (0.655 sec)
415.6... logprob:  0.611401, 0.296875 (0.650 sec)
415.7... logprob:  0.643803, 0.343750 (0.653 sec)
415.8... logprob:  0.604975, 0.289062 (0.650 sec)
415.9... logprob:  0.638487, 0.335938 (0.650 sec)
415.10... logprob:  0.598242, 0.281250 (0.650 sec)
415.11... logprob:  0.638736, 0.335938 (0.650 sec)
415.12... logprob:  0.716581, 0.437500 (0.651 sec)
415.13... logprob:  0.656924, 0.359375 (0.651 sec)
415.14... logprob:  0.662533, 0.367188 (0.650 sec)
415.15... logprob:  0.685524, 0.398438 (0.650 sec)
415.16... logprob:  0.627083, 0.320312 (0.650 sec)
415.17... logprob:  0.638500, 0.335938 (0.651 sec)
415.18... logprob:  0.638219, 0.335938 (0.651 sec)
415.19... logprob:  0.632695, 0.328125 (0.651 sec)
415.20... logprob:  0.648936, 0.351562 (0.651 sec)
415.21... logprob:  0.643454, 0.343750 (0.651 sec)
415.22... logprob:  0.627861, 0.320312 (0.649 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.684495, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935369e-03 [6.749077e-09] 
Layer 'conv1' biases: 6.519783e-07 [1.379891e-10] 
Layer 'conv2' weights[0]: 7.923433e-03 [6.087965e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.007227e-10] 
Layer 'conv3' weights[0]: 7.920958e-03 [5.285343e-09] 
Layer 'conv3' biases: 5.402516e-06 [1.620493e-09] 
Layer 'conv4' weights[0]: 7.953828e-03 [5.160167e-09] 
Layer 'conv4' biases: 1.000001e+00 [9.933155e-09] 
Layer 'conv5' weights[0]: 7.953213e-03 [5.540102e-08] 
Layer 'conv5' biases: 1.000002e+00 [5.821657e-08] 
Layer 'fc6' weights[0]: 7.549307e-03 [7.171568e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.989136e-09] 
Layer 'fc7' weights[0]: 7.422967e-03 [8.829447e-08] 
Layer 'fc7' biases: 9.998516e-01 [7.029662e-08] 
Layer 'fc8' weights[0]: 5.633704e-04 [3.573356e-06] 
Layer 'fc8' biases: 1.761085e-01 [7.541207e-05] 
Train error last 27 batches: 0.635625
-------------------------------------------------------
Not saving because 0.684495 > 0.627087 (334.9: -0.00%)
======================================================= (1.780 sec)
415.23... logprob:  0.622923, 0.312500 (0.650 sec)
415.24... logprob:  0.576993, 0.242188 (0.650 sec)
415.25... logprob:  0.628002, 0.320312 (0.651 sec)
415.26... logprob:  0.674404, 0.390625 (0.650 sec)
415.27... logprob:  0.627897, 0.320312 (0.650 sec)
416.1... logprob:  0.679833, 0.398438 (0.650 sec)
416.2... logprob:  0.596725, 0.273438 (0.650 sec)
416.3... logprob:  0.653866, 0.359375 (0.653 sec)
416.4... logprob:  0.596462, 0.273438 (0.655 sec)
416.5... logprob:  0.590803, 0.265625 (0.649 sec)
416.6... logprob:  0.611400, 0.296875 (0.650 sec)
416.7... logprob:  0.643802, 0.343750 (0.652 sec)
416.8... logprob:  0.604977, 0.289062 (0.649 sec)
416.9... logprob:  0.638487, 0.335938 (0.650 sec)
416.10... logprob:  0.598246, 0.281250 (0.650 sec)
416.11... logprob:  0.638734, 0.335938 (0.649 sec)
416.12... logprob:  0.716564, 0.437500 (0.651 sec)
416.13... logprob:  0.656918, 0.359375 (0.649 sec)
416.14... logprob:  0.662528, 0.367188 (0.650 sec)
416.15... logprob:  0.685516, 0.398438 (0.650 sec)
416.16... logprob:  0.627082, 0.320312 (0.650 sec)
416.17... logprob:  0.638499, 0.335938 (0.651 sec)
416.18... logprob:  0.638218, 0.335938 (0.651 sec)
416.19... logprob:  0.632695, 0.328125 (0.650 sec)
416.20... logprob:  0.648937, 0.351562 (0.652 sec)
416.21... logprob:  0.643455, 0.343750 (0.651 sec)
416.22... logprob:  0.627859, 0.320312 (0.649 sec)
416.23... logprob:  0.622920, 0.312500 (0.650 sec)
416.24... logprob:  0.576982, 0.242188 (0.650 sec)
416.25... logprob:  0.628000, 0.320312 (0.650 sec)
416.26... logprob:  0.674408, 0.390625 (0.651 sec)
416.27... logprob:  0.627895, 0.320312 (0.650 sec)
417.1... logprob:  0.679837, 0.398438 (0.650 sec)
417.2... logprob:  0.596720, 0.273438 (0.650 sec)
417.3... logprob:  0.653866, 0.359375 (0.650 sec)
417.4... logprob:  0.596459, 0.273438 (0.649 sec)
417.5... logprob:  0.590801, 0.265625 (0.650 sec)
417.6... logprob:  0.611401, 0.296875 (0.650 sec)
417.7... logprob:  0.643802, 0.343750 (0.650 sec)
417.8... logprob:  0.604978, 0.289062 (0.649 sec)
417.9... logprob:  0.638486, 0.335938 (0.650 sec)
417.10... logprob:  0.598250, 0.281250 (0.649 sec)
417.11... logprob:  0.638732, 0.335938 (0.650 sec)
417.12... logprob:  0.716546, 0.437500 (0.651 sec)
417.13... logprob:  0.656913, 0.359375 (0.650 sec)
417.14... logprob:  0.662521, 0.367188 (0.649 sec)
417.15... logprob:  0.685510, 0.398438 (0.650 sec)
417.16... logprob:  0.627083, 0.320312 (0.650 sec)
417.17... logprob:  0.638500, 0.335938 (0.651 sec)
417.18... logprob:  0.638218, 0.335938 (0.651 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.632877, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935178e-03 [6.537827e-09] 
Layer 'conv1' biases: 6.552565e-07 [1.704180e-10] 
Layer 'conv2' weights[0]: 7.923234e-03 [6.655757e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.240314e-10] 
Layer 'conv3' weights[0]: 7.920766e-03 [5.842196e-09] 
Layer 'conv3' biases: 5.427807e-06 [2.231071e-09] 
Layer 'conv4' weights[0]: 7.953633e-03 [5.834385e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.573309e-08] 
Layer 'conv5' weights[0]: 7.952995e-03 [8.782312e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.253085e-08] 
Layer 'fc6' weights[0]: 7.549085e-03 [1.023280e-08] 
Layer 'fc6' biases: 9.999999e-01 [9.430476e-09] 
Layer 'fc7' weights[0]: 7.421083e-03 [1.254529e-07] 
Layer 'fc7' biases: 9.998519e-01 [1.096300e-07] 
Layer 'fc8' weights[0]: 5.787202e-04 [5.660458e-06] 
Layer 'fc8' biases: 1.771323e-01 [1.206795e-04] 
Train error last 27 batches: 0.635621
-------------------------------------------------------
Not saving because 0.632877 > 0.627087 (334.9: -0.00%)
======================================================= (1.762 sec)
417.19... logprob:  0.632694, 0.328125 (0.650 sec)
417.20... logprob:  0.648937, 0.351562 (0.650 sec)
417.21... logprob:  0.643455, 0.343750 (0.651 sec)
417.22... logprob:  0.627858, 0.320312 (0.649 sec)
417.23... logprob:  0.622917, 0.312500 (0.650 sec)
417.24... logprob:  0.576972, 0.242188 (0.649 sec)
417.25... logprob:  0.627997, 0.320312 (0.650 sec)
417.26... logprob:  0.674412, 0.390625 (0.650 sec)
417.27... logprob:  0.627893, 0.320312 (0.650 sec)
418.1... logprob:  0.679842, 0.398438 (0.650 sec)
418.2... logprob:  0.596714, 0.273438 (0.650 sec)
418.3... logprob:  0.653867, 0.359375 (0.649 sec)
418.4... logprob:  0.596454, 0.273438 (0.650 sec)
418.5... logprob:  0.590796, 0.265625 (0.649 sec)
418.6... logprob:  0.611399, 0.296875 (0.650 sec)
418.7... logprob:  0.643802, 0.343750 (0.650 sec)
418.8... logprob:  0.604979, 0.289062 (0.649 sec)
418.9... logprob:  0.638486, 0.335938 (0.649 sec)
418.10... logprob:  0.598252, 0.281250 (0.649 sec)
418.11... logprob:  0.638730, 0.335938 (0.650 sec)
418.12... logprob:  0.716534, 0.437500 (0.651 sec)
418.13... logprob:  0.656909, 0.359375 (0.650 sec)
418.14... logprob:  0.662518, 0.367188 (0.649 sec)
418.15... logprob:  0.685506, 0.398438 (0.650 sec)
418.16... logprob:  0.627083, 0.320312 (0.650 sec)
418.17... logprob:  0.638500, 0.335938 (0.651 sec)
418.18... logprob:  0.638219, 0.335938 (0.651 sec)
418.19... logprob:  0.632694, 0.328125 (0.651 sec)
418.20... logprob:  0.648939, 0.351562 (0.651 sec)
418.21... logprob:  0.643456, 0.343750 (0.651 sec)
418.22... logprob:  0.627855, 0.320312 (0.650 sec)
418.23... logprob:  0.622913, 0.312500 (0.649 sec)
418.24... logprob:  0.576956, 0.242188 (0.651 sec)
418.25... logprob:  0.627995, 0.320312 (0.650 sec)
418.26... logprob:  0.674418, 0.390625 (0.651 sec)
418.27... logprob:  0.627891, 0.320312 (0.650 sec)
419.1... logprob:  0.679847, 0.398438 (0.650 sec)
419.2... logprob:  0.596709, 0.273438 (0.649 sec)
419.3... logprob:  0.653869, 0.359375 (0.650 sec)
419.4... logprob:  0.596451, 0.273438 (0.650 sec)
419.5... logprob:  0.590795, 0.265625 (0.650 sec)
419.6... logprob:  0.611400, 0.296875 (0.650 sec)
419.7... logprob:  0.643801, 0.343750 (0.650 sec)
419.8... logprob:  0.604984, 0.289062 (0.649 sec)
419.9... logprob:  0.638484, 0.335938 (0.649 sec)
419.10... logprob:  0.598260, 0.281250 (0.649 sec)
419.11... logprob:  0.638727, 0.335938 (0.650 sec)
419.12... logprob:  0.716506, 0.437500 (0.651 sec)
419.13... logprob:  0.656899, 0.359375 (0.650 sec)
419.14... logprob:  0.662508, 0.367188 (0.649 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627122, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934971e-03 [6.756723e-09] 
Layer 'conv1' biases: 6.584726e-07 [1.459642e-10] 
Layer 'conv2' weights[0]: 7.923049e-03 [6.149775e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.548967e-10] 
Layer 'conv3' weights[0]: 7.920573e-03 [5.366386e-09] 
Layer 'conv3' biases: 5.452425e-06 [1.812785e-09] 
Layer 'conv4' weights[0]: 7.953450e-03 [5.325489e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.168489e-08] 
Layer 'conv5' weights[0]: 7.952793e-03 [6.494828e-08] 
Layer 'conv5' biases: 1.000002e+00 [6.845471e-08] 
Layer 'fc6' weights[0]: 7.548883e-03 [8.012211e-09] 
Layer 'fc6' biases: 9.999999e-01 [6.939384e-09] 
Layer 'fc7' weights[0]: 7.419243e-03 [9.804680e-08] 
Layer 'fc7' biases: 9.998524e-01 [8.024988e-08] 
Layer 'fc8' weights[0]: 6.001733e-04 [4.172453e-06] 
Layer 'fc8' biases: 1.782910e-01 [8.247151e-05] 
Train error last 27 batches: 0.635617
-------------------------------------------------------
Not saving because 0.627122 > 0.627087 (334.9: -0.00%)
======================================================= (1.780 sec)
419.15... logprob:  0.685492, 0.398438 (0.650 sec)
419.16... logprob:  0.627084, 0.320312 (0.650 sec)
419.17... logprob:  0.638499, 0.335938 (0.651 sec)
419.18... logprob:  0.638219, 0.335938 (0.651 sec)
419.19... logprob:  0.632695, 0.328125 (0.651 sec)
419.20... logprob:  0.648940, 0.351562 (0.651 sec)
419.21... logprob:  0.643457, 0.343750 (0.651 sec)
419.22... logprob:  0.627853, 0.320312 (0.650 sec)
419.23... logprob:  0.622909, 0.312500 (0.649 sec)
419.24... logprob:  0.576944, 0.242188 (0.650 sec)
419.25... logprob:  0.627992, 0.320312 (0.650 sec)
419.26... logprob:  0.674424, 0.390625 (0.651 sec)
419.27... logprob:  0.627890, 0.320312 (0.651 sec)
420.1... logprob:  0.679853, 0.398438 (0.650 sec)
420.2... logprob:  0.596702, 0.273438 (0.650 sec)
420.3... logprob:  0.653870, 0.359375 (0.650 sec)
420.4... logprob:  0.596445, 0.273438 (0.650 sec)
420.5... logprob:  0.590791, 0.265625 (0.650 sec)
420.6... logprob:  0.611399, 0.296875 (0.650 sec)
420.7... logprob:  0.643801, 0.343750 (0.651 sec)
420.8... logprob:  0.604984, 0.289062 (0.650 sec)
420.9... logprob:  0.638484, 0.335938 (0.650 sec)
420.10... logprob:  0.598263, 0.281250 (0.650 sec)
420.11... logprob:  0.638725, 0.335938 (0.650 sec)
420.12... logprob:  0.716490, 0.437500 (0.650 sec)
420.13... logprob:  0.656893, 0.359375 (0.651 sec)
420.14... logprob:  0.662503, 0.367188 (0.649 sec)
420.15... logprob:  0.685485, 0.398438 (0.650 sec)
420.16... logprob:  0.627083, 0.320312 (0.651 sec)
420.17... logprob:  0.638499, 0.335938 (0.652 sec)
420.18... logprob:  0.638218, 0.335938 (0.651 sec)
420.19... logprob:  0.632693, 0.328125 (0.651 sec)
420.20... logprob:  0.648940, 0.351562 (0.651 sec)
420.21... logprob:  0.643456, 0.343750 (0.651 sec)
420.22... logprob:  0.627851, 0.320312 (0.650 sec)
420.23... logprob:  0.622908, 0.312500 (0.650 sec)
420.24... logprob:  0.576936, 0.242188 (0.650 sec)
420.25... logprob:  0.627991, 0.320312 (0.651 sec)
420.26... logprob:  0.674427, 0.390625 (0.651 sec)
420.27... logprob:  0.627887, 0.320312 (0.650 sec)
421.1... logprob:  0.679857, 0.398438 (0.650 sec)
421.2... logprob:  0.596699, 0.273438 (0.650 sec)
421.3... logprob:  0.653871, 0.359375 (0.649 sec)
421.4... logprob:  0.596443, 0.273438 (0.650 sec)
421.5... logprob:  0.590788, 0.265625 (0.650 sec)
421.6... logprob:  0.611398, 0.296875 (0.650 sec)
421.7... logprob:  0.643801, 0.343750 (0.651 sec)
421.8... logprob:  0.604985, 0.289062 (0.650 sec)
421.9... logprob:  0.638483, 0.335938 (0.649 sec)
421.10... logprob:  0.598266, 0.281250 (0.650 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.656378, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934762e-03 [7.113789e-09] 
Layer 'conv1' biases: 6.618992e-07 [1.462739e-10] 
Layer 'conv2' weights[0]: 7.922864e-03 [6.317785e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.509025e-10] 
Layer 'conv3' weights[0]: 7.920381e-03 [6.101163e-09] 
Layer 'conv3' biases: 5.479515e-06 [2.230768e-09] 
Layer 'conv4' weights[0]: 7.953265e-03 [6.250214e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.918514e-08] 
Layer 'conv5' weights[0]: 7.952606e-03 [1.071299e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.131615e-07] 
Layer 'fc6' weights[0]: 7.548676e-03 [1.199084e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.141302e-08] 
Layer 'fc7' weights[0]: 7.417367e-03 [1.447596e-07] 
Layer 'fc7' biases: 9.998522e-01 [1.306102e-07] 
Layer 'fc8' weights[0]: 6.008212e-04 [6.807736e-06] 
Layer 'fc8' biases: 1.788958e-01 [1.695314e-04] 
Train error last 27 batches: 0.635614
-------------------------------------------------------
Not saving because 0.656378 > 0.627087 (334.9: -0.00%)
======================================================= (1.755 sec)
421.11... logprob:  0.638723, 0.335938 (0.650 sec)
421.12... logprob:  0.716478, 0.437500 (0.651 sec)
421.13... logprob:  0.656890, 0.359375 (0.651 sec)
421.14... logprob:  0.662499, 0.367188 (0.649 sec)
421.15... logprob:  0.685481, 0.398438 (0.650 sec)
421.16... logprob:  0.627083, 0.320312 (0.651 sec)
421.17... logprob:  0.638498, 0.335938 (0.652 sec)
421.18... logprob:  0.638218, 0.335938 (0.651 sec)
421.19... logprob:  0.632693, 0.328125 (0.651 sec)
421.20... logprob:  0.648942, 0.351562 (0.653 sec)
421.21... logprob:  0.643457, 0.343750 (0.651 sec)
421.22... logprob:  0.627849, 0.320312 (0.649 sec)
421.23... logprob:  0.622903, 0.312500 (0.650 sec)
421.24... logprob:  0.576921, 0.242188 (0.650 sec)
421.25... logprob:  0.627987, 0.320312 (0.650 sec)
421.26... logprob:  0.674432, 0.390625 (0.651 sec)
421.27... logprob:  0.627885, 0.320312 (0.650 sec)
422.1... logprob:  0.679862, 0.398438 (0.649 sec)
422.2... logprob:  0.596693, 0.273438 (0.653 sec)
422.3... logprob:  0.653872, 0.359375 (0.650 sec)
422.4... logprob:  0.596439, 0.273438 (0.650 sec)
422.5... logprob:  0.590787, 0.265625 (0.650 sec)
422.6... logprob:  0.611398, 0.296875 (0.650 sec)
422.7... logprob:  0.643801, 0.343750 (0.650 sec)
422.8... logprob:  0.604988, 0.289062 (0.650 sec)
422.9... logprob:  0.638482, 0.335938 (0.650 sec)
422.10... logprob:  0.598272, 0.281250 (0.649 sec)
422.11... logprob:  0.638720, 0.335938 (0.650 sec)
422.12... logprob:  0.716455, 0.437500 (0.651 sec)
422.13... logprob:  0.656882, 0.359375 (0.650 sec)
422.14... logprob:  0.662491, 0.367188 (0.650 sec)
422.15... logprob:  0.685471, 0.398438 (0.650 sec)
422.16... logprob:  0.627083, 0.320312 (0.650 sec)
422.17... logprob:  0.638499, 0.335938 (0.652 sec)
422.18... logprob:  0.638218, 0.335938 (0.652 sec)
422.19... logprob:  0.632692, 0.328125 (0.651 sec)
422.20... logprob:  0.648942, 0.351562 (0.651 sec)
422.21... logprob:  0.643457, 0.343750 (0.651 sec)
422.22... logprob:  0.627847, 0.320312 (0.650 sec)
422.23... logprob:  0.622900, 0.312500 (0.650 sec)
422.24... logprob:  0.576910, 0.242188 (0.651 sec)
422.25... logprob:  0.627986, 0.320312 (0.651 sec)
422.26... logprob:  0.674436, 0.390625 (0.651 sec)
422.27... logprob:  0.627884, 0.320312 (0.650 sec)
423.1... logprob:  0.679866, 0.398438 (0.652 sec)
423.2... logprob:  0.596687, 0.273438 (0.650 sec)
423.3... logprob:  0.653874, 0.359375 (0.650 sec)
423.4... logprob:  0.596435, 0.273438 (0.650 sec)
423.5... logprob:  0.590782, 0.265625 (0.650 sec)
423.6... logprob:  0.611396, 0.296875 (0.650 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627382, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934584e-03 [7.446803e-09] 
Layer 'conv1' biases: 6.655525e-07 [1.617619e-10] 
Layer 'conv2' weights[0]: 7.922669e-03 [6.256251e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.558385e-10] 
Layer 'conv3' weights[0]: 7.920189e-03 [6.008629e-09] 
Layer 'conv3' biases: 5.510146e-06 [2.182236e-09] 
Layer 'conv4' weights[0]: 7.953071e-03 [6.051635e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.849810e-08] 
Layer 'conv5' weights[0]: 7.952416e-03 [1.030329e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.085530e-07] 
Layer 'fc6' weights[0]: 7.548470e-03 [1.167264e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.105143e-08] 
Layer 'fc7' weights[0]: 7.415496e-03 [1.423028e-07] 
Layer 'fc7' biases: 9.998517e-01 [1.280839e-07] 
Layer 'fc8' weights[0]: 5.788659e-04 [6.561921e-06] 
Layer 'fc8' biases: 1.788988e-01 [1.696712e-04] 
Train error last 27 batches: 0.635609
-------------------------------------------------------
Not saving because 0.627382 > 0.627087 (334.9: -0.00%)
======================================================= (1.756 sec)
423.7... logprob:  0.643801, 0.343750 (0.650 sec)
423.8... logprob:  0.604989, 0.289062 (0.650 sec)
423.9... logprob:  0.638482, 0.335938 (0.650 sec)
423.10... logprob:  0.598275, 0.281250 (0.649 sec)
423.11... logprob:  0.638719, 0.335938 (0.650 sec)
423.12... logprob:  0.716439, 0.437500 (0.651 sec)
423.13... logprob:  0.656878, 0.359375 (0.650 sec)
423.14... logprob:  0.662486, 0.367188 (0.649 sec)
423.15... logprob:  0.685465, 0.398438 (0.650 sec)
423.16... logprob:  0.627084, 0.320312 (0.651 sec)
423.17... logprob:  0.638498, 0.335938 (0.652 sec)
423.18... logprob:  0.638218, 0.335938 (0.653 sec)
423.19... logprob:  0.632692, 0.328125 (0.651 sec)
423.20... logprob:  0.648943, 0.351562 (0.650 sec)
423.21... logprob:  0.643457, 0.343750 (0.651 sec)
423.22... logprob:  0.627846, 0.320312 (0.650 sec)
423.23... logprob:  0.622897, 0.312500 (0.649 sec)
423.24... logprob:  0.576899, 0.242188 (0.650 sec)
423.25... logprob:  0.627983, 0.320312 (0.651 sec)
423.26... logprob:  0.674441, 0.390625 (0.653 sec)
423.27... logprob:  0.627882, 0.320312 (0.650 sec)
424.1... logprob:  0.679870, 0.398438 (0.650 sec)
424.2... logprob:  0.596683, 0.273438 (0.650 sec)
424.3... logprob:  0.653874, 0.359375 (0.650 sec)
424.4... logprob:  0.596433, 0.273438 (0.650 sec)
424.5... logprob:  0.590782, 0.265625 (0.649 sec)
424.6... logprob:  0.611397, 0.296875 (0.650 sec)
424.7... logprob:  0.643800, 0.343750 (0.650 sec)
424.8... logprob:  0.604991, 0.289062 (0.649 sec)
424.9... logprob:  0.638481, 0.335938 (0.649 sec)
424.10... logprob:  0.598279, 0.281250 (0.650 sec)
424.11... logprob:  0.638717, 0.335938 (0.649 sec)
424.12... logprob:  0.716423, 0.437500 (0.651 sec)
424.13... logprob:  0.656871, 0.359375 (0.650 sec)
424.14... logprob:  0.662480, 0.367188 (0.649 sec)
424.15... logprob:  0.685458, 0.398438 (0.650 sec)
424.16... logprob:  0.627084, 0.320312 (0.650 sec)
424.17... logprob:  0.638498, 0.335938 (0.651 sec)
424.18... logprob:  0.638218, 0.335938 (0.651 sec)
424.19... logprob:  0.632692, 0.328125 (0.651 sec)
424.20... logprob:  0.648943, 0.351562 (0.650 sec)
424.21... logprob:  0.643458, 0.343750 (0.651 sec)
424.22... logprob:  0.627843, 0.320312 (0.650 sec)
424.23... logprob:  0.622894, 0.312500 (0.650 sec)
424.24... logprob:  0.576886, 0.242188 (0.650 sec)
424.25... logprob:  0.627981, 0.320312 (0.650 sec)
424.26... logprob:  0.674446, 0.390625 (0.651 sec)
424.27... logprob:  0.627880, 0.320312 (0.650 sec)
425.1... logprob:  0.679877, 0.398438 (0.652 sec)
425.2... logprob:  0.596677, 0.273438 (0.650 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633037, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934384e-03 [6.894984e-09] 
Layer 'conv1' biases: 6.691480e-07 [7.137655e-11] 
Layer 'conv2' weights[0]: 7.922480e-03 [5.003888e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.759114e-10] 
Layer 'conv3' weights[0]: 7.919999e-03 [4.523882e-09] 
Layer 'conv3' biases: 5.539510e-06 [7.511921e-10] 
Layer 'conv4' weights[0]: 7.952900e-03 [4.426391e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.900341e-09] 
Layer 'conv5' weights[0]: 7.952231e-03 [2.251800e-08] 
Layer 'conv5' biases: 1.000002e+00 [2.332396e-08] 
Layer 'fc6' weights[0]: 7.548264e-03 [4.581375e-09] 
Layer 'fc6' biases: 9.999999e-01 [2.357730e-09] 
Layer 'fc7' weights[0]: 7.413666e-03 [5.195410e-08] 
Layer 'fc7' biases: 9.998514e-01 [2.779690e-08] 
Layer 'fc8' weights[0]: 5.647638e-04 [1.399740e-06] 
Layer 'fc8' biases: 1.791033e-01 [4.316027e-05] 
Train error last 27 batches: 0.635606
-------------------------------------------------------
Not saving because 0.633037 > 0.627087 (334.9: -0.00%)
======================================================= (1.839 sec)
425.3... logprob:  0.653876, 0.359375 (0.650 sec)
425.4... logprob:  0.596427, 0.273438 (0.650 sec)
425.5... logprob:  0.590777, 0.265625 (0.650 sec)
425.6... logprob:  0.611396, 0.296875 (0.651 sec)
425.7... logprob:  0.643801, 0.343750 (0.653 sec)
425.8... logprob:  0.604993, 0.289062 (0.649 sec)
425.9... logprob:  0.638481, 0.335938 (0.650 sec)
425.10... logprob:  0.598283, 0.281250 (0.649 sec)
425.11... logprob:  0.638714, 0.335938 (0.650 sec)
425.12... logprob:  0.716403, 0.437500 (0.651 sec)
425.13... logprob:  0.656865, 0.359375 (0.650 sec)
425.14... logprob:  0.662473, 0.367188 (0.649 sec)
425.15... logprob:  0.685449, 0.398438 (0.649 sec)
425.16... logprob:  0.627085, 0.320312 (0.650 sec)
425.17... logprob:  0.638499, 0.335938 (0.652 sec)
425.18... logprob:  0.638218, 0.335938 (0.651 sec)
425.19... logprob:  0.632692, 0.328125 (0.651 sec)
425.20... logprob:  0.648945, 0.351562 (0.651 sec)
425.21... logprob:  0.643458, 0.343750 (0.651 sec)
425.22... logprob:  0.627842, 0.320312 (0.650 sec)
425.23... logprob:  0.622891, 0.312500 (0.650 sec)
425.24... logprob:  0.576875, 0.242188 (0.650 sec)
425.25... logprob:  0.627978, 0.320312 (0.651 sec)
425.26... logprob:  0.674451, 0.390625 (0.651 sec)
425.27... logprob:  0.627878, 0.320312 (0.650 sec)
426.1... logprob:  0.679881, 0.398438 (0.650 sec)
426.2... logprob:  0.596671, 0.273438 (0.650 sec)
426.3... logprob:  0.653877, 0.359375 (0.649 sec)
426.4... logprob:  0.596423, 0.273438 (0.650 sec)
426.5... logprob:  0.590774, 0.265625 (0.650 sec)
426.6... logprob:  0.611395, 0.296875 (0.649 sec)
426.7... logprob:  0.643800, 0.343750 (0.650 sec)
426.8... logprob:  0.604995, 0.289062 (0.650 sec)
426.9... logprob:  0.638480, 0.335938 (0.649 sec)
426.10... logprob:  0.598288, 0.281250 (0.649 sec)
426.11... logprob:  0.638712, 0.335938 (0.650 sec)
426.12... logprob:  0.716385, 0.437500 (0.650 sec)
426.13... logprob:  0.656860, 0.359375 (0.650 sec)
426.14... logprob:  0.662466, 0.367188 (0.649 sec)
426.15... logprob:  0.685440, 0.398438 (0.649 sec)
426.16... logprob:  0.627084, 0.320312 (0.650 sec)
426.17... logprob:  0.638498, 0.335938 (0.651 sec)
426.18... logprob:  0.638217, 0.335938 (0.651 sec)
426.19... logprob:  0.632691, 0.328125 (0.651 sec)
426.20... logprob:  0.648945, 0.351562 (0.651 sec)
426.21... logprob:  0.643458, 0.343750 (0.651 sec)
426.22... logprob:  0.627840, 0.320312 (0.650 sec)
426.23... logprob:  0.622888, 0.312500 (0.649 sec)
426.24... logprob:  0.576866, 0.242188 (0.650 sec)
426.25... logprob:  0.627977, 0.320312 (0.651 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.684907, 0.406250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934199e-03 [6.638252e-09] 
Layer 'conv1' biases: 6.725938e-07 [6.841728e-11] 
Layer 'conv2' weights[0]: 7.922292e-03 [4.961266e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.533157e-10] 
Layer 'conv3' weights[0]: 7.919818e-03 [4.635490e-09] 
Layer 'conv3' biases: 5.567218e-06 [1.000358e-09] 
Layer 'conv4' weights[0]: 7.952712e-03 [4.613386e-09] 
Layer 'conv4' biases: 1.000001e+00 [7.487484e-09] 
Layer 'conv5' weights[0]: 7.952042e-03 [4.140495e-08] 
Layer 'conv5' biases: 1.000002e+00 [4.335442e-08] 
Layer 'fc6' weights[0]: 7.548062e-03 [5.909720e-09] 
Layer 'fc6' biases: 9.999999e-01 [4.425254e-09] 
Layer 'fc7' weights[0]: 7.411740e-03 [7.195258e-08] 
Layer 'fc7' biases: 9.998515e-01 [5.203146e-08] 
Layer 'fc8' weights[0]: 5.629797e-04 [2.595539e-06] 
Layer 'fc8' biases: 1.796498e-01 [7.842293e-05] 
Train error last 27 batches: 0.635602
-------------------------------------------------------
Not saving because 0.684907 > 0.627087 (334.9: -0.00%)
======================================================= (1.801 sec)
426.26... logprob:  0.674454, 0.390625 (0.650 sec)
426.27... logprob:  0.627876, 0.320312 (0.650 sec)
427.1... logprob:  0.679884, 0.398438 (0.650 sec)
427.2... logprob:  0.596667, 0.273438 (0.649 sec)
427.3... logprob:  0.653878, 0.359375 (0.650 sec)
427.4... logprob:  0.596420, 0.273438 (0.650 sec)
427.5... logprob:  0.590772, 0.265625 (0.650 sec)
427.6... logprob:  0.611394, 0.296875 (0.650 sec)
427.7... logprob:  0.643800, 0.343750 (0.650 sec)
427.8... logprob:  0.604995, 0.289062 (0.649 sec)
427.9... logprob:  0.638479, 0.335938 (0.649 sec)
427.10... logprob:  0.598290, 0.281250 (0.649 sec)
427.11... logprob:  0.638711, 0.335938 (0.649 sec)
427.12... logprob:  0.716375, 0.437500 (0.651 sec)
427.13... logprob:  0.656856, 0.359375 (0.650 sec)
427.14... logprob:  0.662464, 0.367188 (0.649 sec)
427.15... logprob:  0.685437, 0.398438 (0.650 sec)
427.16... logprob:  0.627085, 0.320312 (0.650 sec)
427.17... logprob:  0.638497, 0.335938 (0.652 sec)
427.18... logprob:  0.638218, 0.335938 (0.651 sec)
427.19... logprob:  0.632692, 0.328125 (0.651 sec)
427.20... logprob:  0.648947, 0.351562 (0.650 sec)
427.21... logprob:  0.643460, 0.343750 (0.651 sec)
427.22... logprob:  0.627838, 0.320312 (0.650 sec)
427.23... logprob:  0.622885, 0.312500 (0.650 sec)
427.24... logprob:  0.576853, 0.242188 (0.650 sec)
427.25... logprob:  0.627974, 0.320312 (0.650 sec)
427.26... logprob:  0.674460, 0.390625 (0.650 sec)
427.27... logprob:  0.627875, 0.320312 (0.650 sec)
428.1... logprob:  0.679889, 0.398438 (0.650 sec)
428.2... logprob:  0.596662, 0.273438 (0.650 sec)
428.3... logprob:  0.653879, 0.359375 (0.650 sec)
428.4... logprob:  0.596417, 0.273438 (0.650 sec)
428.5... logprob:  0.590770, 0.265625 (0.649 sec)
428.6... logprob:  0.611395, 0.296875 (0.650 sec)
428.7... logprob:  0.643799, 0.343750 (0.650 sec)
428.8... logprob:  0.604998, 0.289062 (0.650 sec)
428.9... logprob:  0.638478, 0.335938 (0.649 sec)
428.10... logprob:  0.598295, 0.281250 (0.649 sec)
428.11... logprob:  0.638709, 0.335938 (0.650 sec)
428.12... logprob:  0.716355, 0.437500 (0.651 sec)
428.13... logprob:  0.656850, 0.359375 (0.650 sec)
428.14... logprob:  0.662457, 0.367188 (0.650 sec)
428.15... logprob:  0.685429, 0.398438 (0.650 sec)
428.16... logprob:  0.627085, 0.320312 (0.650 sec)
428.17... logprob:  0.638497, 0.335938 (0.652 sec)
428.18... logprob:  0.638218, 0.335938 (0.651 sec)
428.19... logprob:  0.632691, 0.328125 (0.651 sec)
428.20... logprob:  0.648948, 0.351562 (0.651 sec)
428.21... logprob:  0.643459, 0.343750 (0.651 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.633108, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934006e-03 [6.845553e-09] 
Layer 'conv1' biases: 6.760263e-07 [1.566482e-10] 
Layer 'conv2' weights[0]: 7.922088e-03 [6.507329e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.423602e-10] 
Layer 'conv3' weights[0]: 7.919630e-03 [5.650646e-09] 
Layer 'conv3' biases: 5.594851e-06 [2.012486e-09] 
Layer 'conv4' weights[0]: 7.952526e-03 [5.567519e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.328574e-08] 
Layer 'conv5' weights[0]: 7.951858e-03 [7.385078e-08] 
Layer 'conv5' biases: 1.000002e+00 [7.754904e-08] 
Layer 'fc6' weights[0]: 7.547866e-03 [9.001782e-09] 
Layer 'fc6' biases: 9.999999e-01 [7.996659e-09] 
Layer 'fc7' weights[0]: 7.409811e-03 [1.101658e-07] 
Layer 'fc7' biases: 9.998512e-01 [9.323809e-08] 
Layer 'fc8' weights[0]: 5.634103e-04 [4.720721e-06] 
Layer 'fc8' biases: 1.802410e-01 [1.049666e-04] 
Train error last 27 batches: 0.635599
-------------------------------------------------------
Not saving because 0.633108 > 0.627087 (334.9: -0.00%)
======================================================= (1.767 sec)
428.22... logprob:  0.627836, 0.320312 (0.650 sec)
428.23... logprob:  0.622881, 0.312500 (0.650 sec)
428.24... logprob:  0.576840, 0.242188 (0.650 sec)
428.25... logprob:  0.627971, 0.320312 (0.651 sec)
428.26... logprob:  0.674466, 0.390625 (0.651 sec)
428.27... logprob:  0.627873, 0.320312 (0.650 sec)
429.1... logprob:  0.679895, 0.398438 (0.653 sec)
429.2... logprob:  0.596656, 0.273438 (0.650 sec)
429.3... logprob:  0.653882, 0.359375 (0.650 sec)
429.4... logprob:  0.596412, 0.273438 (0.650 sec)
429.5... logprob:  0.590766, 0.265625 (0.650 sec)
429.6... logprob:  0.611394, 0.296875 (0.650 sec)
429.7... logprob:  0.643799, 0.343750 (0.650 sec)
429.8... logprob:  0.605000, 0.289062 (0.650 sec)
429.9... logprob:  0.638477, 0.335938 (0.650 sec)
429.10... logprob:  0.598300, 0.281250 (0.650 sec)
429.11... logprob:  0.638707, 0.335938 (0.653 sec)
429.12... logprob:  0.716335, 0.437500 (0.651 sec)
429.13... logprob:  0.656843, 0.359375 (0.651 sec)
429.14... logprob:  0.662450, 0.367188 (0.650 sec)
429.15... logprob:  0.685420, 0.398438 (0.650 sec)
429.16... logprob:  0.627085, 0.320312 (0.651 sec)
429.17... logprob:  0.638497, 0.335938 (0.651 sec)
429.18... logprob:  0.638218, 0.335938 (0.652 sec)
429.19... logprob:  0.632691, 0.328125 (0.651 sec)
429.20... logprob:  0.648949, 0.351562 (0.650 sec)
429.21... logprob:  0.643460, 0.343750 (0.651 sec)
429.22... logprob:  0.627834, 0.320312 (0.650 sec)
429.23... logprob:  0.622877, 0.312500 (0.650 sec)
429.24... logprob:  0.576828, 0.242188 (0.650 sec)
429.25... logprob:  0.627969, 0.320312 (0.651 sec)
429.26... logprob:  0.674470, 0.390625 (0.651 sec)
429.27... logprob:  0.627871, 0.320312 (0.651 sec)
430.1... logprob:  0.679900, 0.398438 (0.651 sec)
430.2... logprob:  0.596651, 0.273438 (0.650 sec)
430.3... logprob:  0.653883, 0.359375 (0.651 sec)
430.4... logprob:  0.596408, 0.273438 (0.650 sec)
430.5... logprob:  0.590764, 0.265625 (0.650 sec)
430.6... logprob:  0.611394, 0.296875 (0.650 sec)
430.7... logprob:  0.643799, 0.343750 (0.650 sec)
430.8... logprob:  0.605001, 0.289062 (0.649 sec)
430.9... logprob:  0.638477, 0.335938 (0.650 sec)
430.10... logprob:  0.598304, 0.281250 (0.649 sec)
430.11... logprob:  0.638705, 0.335938 (0.650 sec)
430.12... logprob:  0.716318, 0.437500 (0.651 sec)
430.13... logprob:  0.656837, 0.359375 (0.652 sec)
430.14... logprob:  0.662444, 0.367188 (0.649 sec)
430.15... logprob:  0.685412, 0.398438 (0.650 sec)
430.16... logprob:  0.627086, 0.320312 (0.650 sec)
430.17... logprob:  0.638497, 0.335938 (0.652 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627340, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.933814e-03 [6.464652e-09] 
Layer 'conv1' biases: 6.792736e-07 [1.665697e-10] 
Layer 'conv2' weights[0]: 7.921893e-03 [6.764281e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.518856e-10] 
Layer 'conv3' weights[0]: 7.919450e-03 [5.933619e-09] 
Layer 'conv3' biases: 5.619584e-06 [2.298645e-09] 
Layer 'conv4' weights[0]: 7.952327e-03 [5.971104e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.658438e-08] 
Layer 'conv5' weights[0]: 7.951654e-03 [9.211993e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.707333e-08] 
Layer 'fc6' weights[0]: 7.547664e-03 [1.057698e-08] 
Layer 'fc6' biases: 9.999999e-01 [9.854340e-09] 
Layer 'fc7' weights[0]: 7.407933e-03 [1.287537e-07] 
Layer 'fc7' biases: 9.998513e-01 [1.134036e-07] 
Layer 'fc8' weights[0]: 5.801711e-04 [5.852537e-06] 
Layer 'fc8' biases: 1.812944e-01 [1.265309e-04] 
Train error last 27 batches: 0.635594
-------------------------------------------------------
Not saving because 0.627340 > 0.627087 (334.9: -0.00%)
======================================================= (1.756 sec)
430.18... logprob:  0.638218, 0.335938 (0.651 sec)
430.19... logprob:  0.632690, 0.328125 (0.651 sec)
430.20... logprob:  0.648948, 0.351562 (0.651 sec)
430.21... logprob:  0.643460, 0.343750 (0.651 sec)
430.22... logprob:  0.627833, 0.320312 (0.650 sec)
430.23... logprob:  0.622875, 0.312500 (0.650 sec)
430.24... logprob:  0.576821, 0.242188 (0.650 sec)
430.25... logprob:  0.627967, 0.320312 (0.650 sec)
430.26... logprob:  0.674473, 0.390625 (0.651 sec)
430.27... logprob:  0.627869, 0.320312 (0.650 sec)
431.1... logprob:  0.679904, 0.398438 (0.650 sec)
431.2... logprob:  0.596645, 0.273438 (0.650 sec)
431.3... logprob:  0.653884, 0.359375 (0.650 sec)
431.4... logprob:  0.596403, 0.273438 (0.650 sec)
431.5... logprob:  0.590760, 0.265625 (0.650 sec)
431.6... logprob:  0.611392, 0.296875 (0.649 sec)
431.7... logprob:  0.643799, 0.343750 (0.650 sec)
431.8... logprob:  0.605002, 0.289062 (0.649 sec)
431.9... logprob:  0.638476, 0.335938 (0.650 sec)
431.10... logprob:  0.598306, 0.281250 (0.649 sec)
431.11... logprob:  0.638703, 0.335938 (0.650 sec)
431.12... logprob:  0.716308, 0.437500 (0.651 sec)
431.13... logprob:  0.656834, 0.359375 (0.650 sec)
431.14... logprob:  0.662441, 0.367188 (0.649 sec)
431.15... logprob:  0.685408, 0.398438 (0.649 sec)
431.16... logprob:  0.627086, 0.320312 (0.650 sec)
431.17... logprob:  0.638497, 0.335938 (0.652 sec)
431.18... logprob:  0.638218, 0.335938 (0.651 sec)
431.19... logprob:  0.632691, 0.328125 (0.651 sec)
431.20... logprob:  0.648950, 0.351562 (0.651 sec)
431.21... logprob:  0.643462, 0.343750 (0.651 sec)
431.22... logprob:  0.627830, 0.320312 (0.650 sec)
431.23... logprob:  0.622872, 0.312500 (0.650 sec)
431.24... logprob:  0.576805, 0.242188 (0.650 sec)
431.25... logprob:  0.627965, 0.320312 (0.651 sec)
431.26... logprob:  0.674480, 0.390625 (0.651 sec)
431.27... logprob:  0.627868, 0.320312 (0.650 sec)
432.1... logprob:  0.679909, 0.398438 (0.650 sec)
432.2... logprob:  0.596641, 0.273438 (0.650 sec)
432.3... logprob:  0.653885, 0.359375 (0.649 sec)
432.4... logprob:  0.596401, 0.273438 (0.650 sec)
432.5... logprob:  0.590759, 0.265625 (0.650 sec)
432.6... logprob:  0.611393, 0.296875 (0.649 sec)
432.7... logprob:  0.643799, 0.343750 (0.650 sec)
432.8... logprob:  0.605006, 0.289062 (0.650 sec)
432.9... logprob:  0.638475, 0.335938 (0.649 sec)
432.10... logprob:  0.598313, 0.281250 (0.649 sec)
432.11... logprob:  0.638700, 0.335938 (0.650 sec)
432.12... logprob:  0.716281, 0.437500 (0.651 sec)
432.13... logprob:  0.656825, 0.359375 (0.650 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.656571, 0.359375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.933631e-03 [6.533796e-09] 
Layer 'conv1' biases: 6.824922e-07 [9.738690e-11] 
Layer 'conv2' weights[0]: 7.921709e-03 [5.382058e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.339728e-10] 
Layer 'conv3' weights[0]: 7.919258e-03 [4.717702e-09] 
Layer 'conv3' biases: 5.643853e-06 [1.191276e-09] 
Layer 'conv4' weights[0]: 7.952133e-03 [4.634341e-09] 
Layer 'conv4' biases: 1.000001e+00 [6.155265e-09] 
Layer 'conv5' weights[0]: 7.951453e-03 [3.448381e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.609743e-08] 
Layer 'fc6' weights[0]: 7.547468e-03 [5.330888e-09] 
Layer 'fc6' biases: 9.999999e-01 [3.648883e-09] 
Layer 'fc7' weights[0]: 7.406004e-03 [6.414984e-08] 
Layer 'fc7' biases: 9.998517e-01 [4.271223e-08] 
Layer 'fc8' weights[0]: 5.997865e-04 [2.176434e-06] 
Layer 'fc8' biases: 1.823977e-01 [3.726870e-05] 
Train error last 27 batches: 0.635591
-------------------------------------------------------
Not saving because 0.656571 > 0.627087 (334.9: -0.00%)
======================================================= (1.812 sec)
432.14... logprob:  0.662433, 0.367188 (0.649 sec)
432.15... logprob:  0.685396, 0.398438 (0.650 sec)
432.16... logprob:  0.627087, 0.320312 (0.650 sec)
432.17... logprob:  0.638497, 0.335938 (0.651 sec)
432.18... logprob:  0.638218, 0.335938 (0.651 sec)
432.19... logprob:  0.632690, 0.328125 (0.651 sec)
432.20... logprob:  0.648952, 0.351562 (0.650 sec)
432.21... logprob:  0.643462, 0.343750 (0.651 sec)
432.22... logprob:  0.627829, 0.320312 (0.650 sec)
432.23... logprob:  0.622868, 0.312500 (0.649 sec)
432.24... logprob:  0.576793, 0.242188 (0.650 sec)
432.25... logprob:  0.627962, 0.320312 (0.650 sec)
432.26... logprob:  0.674484, 0.390625 (0.651 sec)
432.27... logprob:  0.627865, 0.320312 (0.650 sec)
433.1... logprob:  0.679914, 0.398438 (0.650 sec)
433.2... logprob:  0.596634, 0.273438 (0.650 sec)
433.3... logprob:  0.653887, 0.359375 (0.649 sec)
433.4... logprob:  0.596396, 0.273438 (0.650 sec)
433.5... logprob:  0.590754, 0.265625 (0.650 sec)
433.6... logprob:  0.611392, 0.296875 (0.650 sec)
433.7... logprob:  0.643799, 0.343750 (0.649 sec)
433.8... logprob:  0.605006, 0.289062 (0.650 sec)
433.9... logprob:  0.638474, 0.335938 (0.649 sec)
433.10... logprob:  0.598317, 0.281250 (0.649 sec)
433.11... logprob:  0.638699, 0.335938 (0.650 sec)
433.12... logprob:  0.716265, 0.437500 (0.651 sec)
433.13... logprob:  0.656820, 0.359375 (0.650 sec)
433.14... logprob:  0.662426, 0.367188 (0.649 sec)
433.15... logprob:  0.685389, 0.398438 (0.650 sec)
433.16... logprob:  0.627087, 0.320312 (0.650 sec)
433.17... logprob:  0.638497, 0.335938 (0.652 sec)
433.18... logprob:  0.638218, 0.335938 (0.651 sec)
433.19... logprob:  0.632690, 0.328125 (0.650 sec)
433.20... logprob:  0.648952, 0.351562 (0.650 sec)
433.21... logprob:  0.643462, 0.343750 (0.651 sec)
433.22... logprob:  0.627827, 0.320312 (0.649 sec)
433.23... logprob:  0.622866, 0.312500 (0.650 sec)
433.24... logprob:  0.576782, 0.242188 (0.650 sec)
433.25... logprob:  0.627960, 0.320312 (0.651 sec)
433.26... logprob:  0.674489, 0.390625 (0.651 sec)
433.27... logprob:  0.627864, 0.320312 (0.650 sec)
434.1... logprob:  0.679919, 0.398438 (0.650 sec)
434.2... logprob:  0.596629, 0.273438 (0.650 sec)
434.3... logprob:  0.653887, 0.359375 (0.650 sec)
434.4... logprob:  0.596393, 0.273438 (0.650 sec)
434.5... logprob:  0.590751, 0.265625 (0.650 sec)
434.6... logprob:  0.611392, 0.296875 (0.650 sec)
434.7... logprob:  0.643799, 0.343750 (0.650 sec)
434.8... logprob:  0.605009, 0.289062 (0.650 sec)
434.9... logprob:  0.638473, 0.335938 (0.649 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.627105, 0.320312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.933423e-03 [6.758219e-09] 
Layer 'conv1' biases: 6.860046e-07 [1.200655e-10] 
Layer 'conv2' weights[0]: 7.921509e-03 [5.839327e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.037093e-10] 
Layer 'conv3' weights[0]: 7.919071e-03 [5.647646e-09] 
Layer 'conv3' biases: 5.672420e-06 [1.839262e-09] 
Layer 'conv4' weights[0]: 7.951947e-03 [5.738676e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.559008e-08] 
Layer 'conv5' weights[0]: 7.951263e-03 [8.594053e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.068313e-08] 
Layer 'fc6' weights[0]: 7.547292e-03 [1.002665e-08] 
Layer 'fc6' biases: 9.999999e-01 [9.143229e-09] 
Layer 'fc7' weights[0]: 7.404167e-03 [1.218746e-07] 
Layer 'fc7' biases: 9.998513e-01 [1.049941e-07] 
Layer 'fc8' weights[0]: 5.907952e-04 [5.392978e-06] 
Layer 'fc8' biases: 1.827363e-01 [1.405347e-04] 
Train error last 27 batches: 0.635587
-------------------------------------------------------
Not saving because 0.627105 > 0.627087 (334.9: -0.00%)
======================================================= (1.764 sec)
434.10... logprob:  0.598321, 0.281250 (0.650 sec)
434.11... logprob:  0.638697, 0.335938 (0.650 sec)
434.12... logprob:  0.716245, 0.437500 (0.650 sec)
434.13... logprob:  0.656813, 0.359375 (0.650 sec)
434.14... logprob:  0.662420, 0.367188 (0.649 sec)
434.15... logprob:  0.685380, 0.398438 (0.650 sec)
434.16... logprob:  0.627087, 0.320312 (0.650 sec)
434.17... logprob:  0.638496, 0.335938 (0.651 sec)
434.18... logprob:  0.638218, 0.335938 (0.651 sec)
434.19... logprob:  0.632690, 0.328125 (0.650 sec)
434.20... logprob:  0.648952, 0.351562 (0.650 sec)
434.21... logprob:  0.643463, 0.343750 (0.651 sec)
434.22... logprob:  0.627825, 0.320312 (0.650 sec)
434.23... logprob:  0.622863, 0.312500 (0.649 sec)
434.24... logprob:  0.576772, 0.242188 (0.651 sec)
434.25... logprob:  0.627958, 0.320312 (0.651 sec)
434.26... logprob:  0.674494, 0.390625 (0.651 sec)
434.27... logprob:  0.627862, 0.320312 (0.650 sec)
435.1... logprob:  0.679924, 0.398438 (0.650 sec)
435.2... logprob:  0.596624, 0.273438 (0.650 sec)
435.3... logprob:  0.653889, 0.359375 (0.652 sec)
435.4... logprob:  0.596389, 0.273438 (0.650 sec)
435.5... logprob:  0.590748, 0.265625 (0.650 sec)
435.6... logprob:  0.611391, 0.296875 (0.651 sec)
435.7... logprob:  0.643798, 0.343750 (0.650 sec)
435.8... logprob:  0.605009, 0.289062 (0.649 sec)
435.9... logprob:  0.638473, 0.335938 (0.650 sec)
435.10... logprob:  0.598324, 0.281250 (0.649 sec)
435.11... logprob:  0.638695, 0.335938 (0.650 sec)
435.12... logprob:  0.716234, 0.437500 (0.651 sec)
435.13... logprob:  0.656809, 0.359375 (0.650 sec)
435.14... logprob:  0.662416, 0.367188 (0.649 sec)
435.15... logprob:  0.685376, 0.398438 (0.650 sec)
435.16... logprob:  0.627087, 0.320312 (0.650 sec)
435.17... logprob:  0.638496, 0.335938 (0.651 sec)
435.18... logprob:  0.638218, 0.335938 (0.651 sec)
435.19... logprob:  0.632690, 0.328125 (0.651 sec)
435.20... logprob:  0.648953, 0.351562 (0.650 sec)
435.21... logprob:  0.643463, 0.343750 (0.651 sec)
435.22... logprob:  0.627823, 0.320312 (0.650 sec)
435.23... logprob:  0.622859, 0.312500 (0.649 sec)
435.24... logprob:  0.576761, 0.242188 (0.650 sec)
435.25... logprob:  0.627955, 0.320312 (0.651 sec)
435.26... logprob:  0.674497, 0.390625 (0.650 sec)
435.27... logprob:  0.627860, 0.320312 (0.651 sec)
436.1... logprob:  0.679927, 0.398438 (0.650 sec)
436.2... logprob:  0.596619, 0.273438 (0.650 sec)
436.3... logprob:  0.653890, 0.359375 (0.650 sec)
436.4... logprob:  0.596386, 0.273438 (0.650 sec)
436.5... logprob:  0.590746, 0.265625 (0.650 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.632871, 0.328125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.933244e-03 [7.527113e-09] 
Layer 'conv1' biases: 6.897391e-07 [1.353250e-10] 
Layer 'conv2' weights[0]: 7.921325e-03 [5.931455e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.251127e-10] 
Layer 'conv3' weights[0]: 7.918893e-03 [5.690418e-09] 
Layer 'conv3' biases: 5.702784e-06 [1.891291e-09] 
Layer 'conv4' weights[0]: 7.951759e-03 [5.690919e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.555725e-08] 
Layer 'conv5' weights[0]: 7.951058e-03 [8.633433e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.082049e-08] 
Layer 'fc6' weights[0]: 7.547104e-03 [1.009940e-08] 
Layer 'fc6' biases: 9.999999e-01 [9.227335e-09] 
Layer 'fc7' weights[0]: 7.402268e-03 [1.230618e-07] 
Layer 'fc7' biases: 9.998511e-01 [1.065519e-07] 
Layer 'fc8' weights[0]: 5.696883e-04 [5.413885e-06] 
Layer 'fc8' biases: 1.827318e-01 [1.447013e-04] 
Train error last 27 batches: 0.635584
-------------------------------------------------------
Not saving because 0.632871 > 0.627087 (334.9: -0.00%)
======================================================= Giving up...
Option --layer-def (Layer definition file) cannot be changed
=========================
Importing _ConvNet C++ module
=========================
Training ConvNet
Always write savepoints, regardless of test err improvement: 0     [DEFAULT]
Check gradients and quit?                                  : 0     [DEFAULT]
Compress checkpoints?                                      : 0     [DEFAULT]
Conserve GPU memory (slower)?                              : 0     [DEFAULT]
Convert given conv layers to unshared local                :       
Cropped DP: crop border size                               : 4     [DEFAULT]
Cropped DP: logreg layer name (for --multiview-test)       :       [DEFAULT]
Cropped DP: test on multiple patches?                      : 0     [DEFAULT]
Cropped Step: crop border step                             : 1     [DEFAULT]
Data batch range: testing                                  : 28-33 
Data batch range: training                                 : 1-27  
Data path                                                  : /data2/ad6813/pipe-data/Bluebox/batches/scraping_peeling/net_0 
Data provider                                              : basic-leaf256 
GPU override                                               : -1    [DEFAULT]
Layer definition file                                      : /homes/ad6813/Git/pipe-classification/models/scraping_peeling/net_0/layers.cfg 
Layer parameter file                                       : /homes/ad6813/Git/pipe-classification/models/scraping_peeling/net_0/params.cfg 
Load file                                                  : /data2/ad6813/my-nets/saves/ConvNet__2014-07-08_14.54.04 
Maximum save file size (MB)                                : 0     [DEFAULT]
Minibatch size                                             : 128   [DEFAULT]
Number of GPUs                                             : 1     [DEFAULT]
Number of epochs                                           : 50000 [DEFAULT]
Save path                                                  : /homes/ad6813/Git/pipe-classification/models/scraping_peeling/net_0/saves 
Test and quit?                                             : 0     [DEFAULT]
Test on more than one batch at a time?                     : -1    
Test on one batch at a time?                               : 0     
Testing frequency                                          : 17    
Unshare weight matrices in given layers                    :       
=========================
Running on CUDA device(s) -2
Current time: Tue Jul  8 20:01:39 2014
Saving checkpoints to /data2/ad6813/my-nets/saves/ConvNet__2014-07-08_14.54.04
=========================
334.10... logprob:  0.597849, 0.281250 (1.459 sec)
334.11... logprob:  0.638951, 0.335938 (1.457 sec)
334.12... logprob:  0.718252, 0.437500 (1.431 sec)
334.13... logprob:  0.657479, 0.359375 (1.434 sec)
334.14... logprob:  0.663094, 0.367188 (1.447 sec)
334.15... logprob:  0.686211, 0.398438 (0.868 sec)
334.16... logprob:  0.627066, 0.320312 (0.666 sec)
334.17... logprob:  0.638513, 0.335938 (1.185 sec)
334.18... logprob:  0.638223, 0.335938 (0.665 sec)
334.19... logprob:  0.632728, 0.328125 (0.672 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643561, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943958e-03 [6.754668e-09] 
Layer 'conv1' biases: 4.997785e-07 [1.576176e-10] 
Layer 'conv2' weights[0]: 7.931743e-03 [6.605167e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.665344e-10] 
Layer 'conv3' weights[0]: 7.929516e-03 [5.759192e-09] 
Layer 'conv3' biases: 4.190758e-06 [2.106556e-09] 
Layer 'conv4' weights[0]: 7.962279e-03 [5.708307e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.471764e-08] 
Layer 'conv5' weights[0]: 7.961623e-03 [8.473275e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.979907e-08] 
Layer 'fc6' weights[0]: 7.557859e-03 [9.991325e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.139070e-09] 
Layer 'fc7' weights[0]: 7.506086e-03 [1.259385e-07] 
Layer 'fc7' biases: 9.998543e-01 [1.102061e-07] 
Layer 'fc8' weights[0]: 5.984836e-04 [5.942001e-06] 
Layer 'fc8' biases: 1.491689e-01 [1.102321e-04] 
Train error last 27 batches: 0.635822
-------------------------------------------------------
Not saving because 0.643561 > 0.627087 (334.9: -0.00%)
======================================================= (6.180 sec)
334.20... logprob:  0.648852, 0.351562 (0.669 sec)
334.21... logprob:  0.643420, 0.343750 (0.659 sec)
334.22... logprob:  0.628061, 0.320312 (0.664 sec)
334.23... logprob:  0.623244, 0.312500 (0.666 sec)
334.24... logprob:  0.578128, 0.242188 (0.664 sec)
334.25... logprob:  0.628238, 0.320312 (0.667 sec)
334.26... logprob:  0.673969, 0.390625 (0.663 sec)
334.27... logprob:  0.628079, 0.320312 (1.460 sec)
335.1... logprob:  0.679408, 0.398438 (1.437 sec)
335.2... logprob:  0.597212, 0.273438 (1.458 sec)
335.3... logprob:  0.653760, 0.359375 (1.449 sec)
335.4... logprob:  0.596789, 0.273438 (1.433 sec)
335.5... logprob:  0.591026, 0.265625 (1.402 sec)
335.6... logprob:  0.611423, 0.296875 (1.491 sec)
335.7... logprob:  0.643835, 0.343750 (1.476 sec)
335.8... logprob:  0.604793, 0.289062 (1.486 sec)
335.9... logprob:  0.638569, 0.335938 (0.682 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644561, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943886e-03 [6.684268e-09] 
Layer 'conv1' biases: 5.006691e-07 [1.186612e-10] 
Layer 'conv2' weights[0]: 7.931671e-03 [5.788995e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.969396e-10] 
Layer 'conv3' weights[0]: 7.929451e-03 [5.652734e-09] 
Layer 'conv3' biases: 4.196891e-06 [1.843135e-09] 
Layer 'conv4' weights[0]: 7.962206e-03 [5.789471e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.614705e-08] 
Layer 'conv5' weights[0]: 7.961582e-03 [9.325921e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.916781e-08] 
Layer 'fc6' weights[0]: 7.557798e-03 [1.070024e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.967923e-09] 
Layer 'fc7' weights[0]: 7.505435e-03 [1.336505e-07] 
Layer 'fc7' biases: 9.998546e-01 [1.184109e-07] 
Layer 'fc8' weights[0]: 6.260672e-04 [6.448555e-06] 
Layer 'fc8' biases: 1.500371e-01 [1.452273e-04] 
Train error last 27 batches: 0.635821
-------------------------------------------------------
Not saving because 0.644561 > 0.627087 (334.9: -0.00%)
======================================================= (5.097 sec)
335.10... logprob:  0.597853, 0.281250 (0.671 sec)
335.11... logprob:  0.638948, 0.335938 (0.669 sec)
335.12... logprob:  0.718232, 0.437500 (0.668 sec)
335.13... logprob:  0.657472, 0.359375 (0.671 sec)
335.14... logprob:  0.663087, 0.367188 (0.671 sec)
335.15... logprob:  0.686204, 0.398438 (0.670 sec)
335.16... logprob:  0.627066, 0.320312 (0.669 sec)
335.17... logprob:  0.638513, 0.335938 (0.669 sec)
335.18... logprob:  0.638223, 0.335938 (0.670 sec)
335.19... logprob:  0.632727, 0.328125 (0.671 sec)
335.20... logprob:  0.648852, 0.351562 (0.669 sec)
335.21... logprob:  0.643420, 0.343750 (0.669 sec)
335.22... logprob:  0.628057, 0.320312 (0.670 sec)
335.23... logprob:  0.623240, 0.312500 (0.667 sec)
335.24... logprob:  0.578114, 0.242188 (0.668 sec)
335.25... logprob:  0.628235, 0.320312 (0.666 sec)
335.26... logprob:  0.673973, 0.390625 (0.667 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643452, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943828e-03 [6.500296e-09] 
Layer 'conv1' biases: 5.022043e-07 [6.856946e-11] 
Layer 'conv2' weights[0]: 7.931608e-03 [4.995118e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.441171e-10] 
Layer 'conv3' weights[0]: 7.929378e-03 [4.420167e-09] 
Layer 'conv3' biases: 4.210656e-06 [6.232718e-10] 
Layer 'conv4' weights[0]: 7.962134e-03 [4.320496e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.874727e-09] 
Layer 'conv5' weights[0]: 7.961496e-03 [1.171267e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.172685e-08] 
Layer 'fc6' weights[0]: 7.557738e-03 [4.003644e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.172041e-09] 
Layer 'fc7' weights[0]: 7.504819e-03 [4.230909e-08] 
Layer 'fc7' biases: 9.998540e-01 [1.419596e-08] 
Layer 'fc8' weights[0]: 5.879280e-04 [7.361944e-07] 
Layer 'fc8' biases: 1.493782e-01 [2.858930e-05] 
Train error last 27 batches: 0.635819
-------------------------------------------------------
Not saving because 0.643452 > 0.627087 (334.9: -0.00%)
======================================================= (5.181 sec)
335.27... logprob:  0.628076, 0.320312 (0.671 sec)
336.1... logprob:  0.679412, 0.398438 (0.669 sec)
336.2... logprob:  0.597206, 0.273438 (0.669 sec)
336.3... logprob:  0.653761, 0.359375 (0.670 sec)
336.4... logprob:  0.596785, 0.273438 (0.671 sec)
336.5... logprob:  0.591024, 0.265625 (0.669 sec)
336.6... logprob:  0.611424, 0.296875 (0.668 sec)
336.7... logprob:  0.643834, 0.343750 (0.669 sec)
336.8... logprob:  0.604795, 0.289062 (0.673 sec)
336.9... logprob:  0.638568, 0.335938 (0.669 sec)
336.10... logprob:  0.597858, 0.281250 (0.670 sec)
336.11... logprob:  0.638945, 0.335938 (0.669 sec)
336.12... logprob:  0.718211, 0.437500 (0.668 sec)
336.13... logprob:  0.657465, 0.359375 (0.671 sec)
336.14... logprob:  0.663081, 0.367188 (0.668 sec)
336.15... logprob:  0.686196, 0.398438 (0.667 sec)
336.16... logprob:  0.627066, 0.320312 (0.665 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644072, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943757e-03 [6.949933e-09] 
Layer 'conv1' biases: 5.031210e-07 [1.853036e-10] 
Layer 'conv2' weights[0]: 7.931541e-03 [7.257539e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.404061e-10] 
Layer 'conv3' weights[0]: 7.929304e-03 [6.311652e-09] 
Layer 'conv3' biases: 4.217088e-06 [2.594515e-09] 
Layer 'conv4' weights[0]: 7.962066e-03 [6.344406e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.912487e-08] 
Layer 'conv5' weights[0]: 7.961458e-03 [1.102236e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.171181e-07] 
Layer 'fc6' weights[0]: 7.557676e-03 [1.232354e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.182302e-08] 
Layer 'fc7' weights[0]: 7.504142e-03 [1.544187e-07] 
Layer 'fc7' biases: 9.998544e-01 [1.412308e-07] 
Layer 'fc8' weights[0]: 6.154946e-04 [7.683127e-06] 
Layer 'fc8' biases: 1.502616e-01 [1.420984e-04] 
Train error last 27 batches: 0.635817
-------------------------------------------------------
Not saving because 0.644072 > 0.627087 (334.9: -0.00%)
======================================================= (5.060 sec)
336.17... logprob:  0.638513, 0.335938 (0.666 sec)
336.18... logprob:  0.638224, 0.335938 (0.667 sec)
336.19... logprob:  0.632727, 0.328125 (0.665 sec)
336.20... logprob:  0.648854, 0.351562 (0.660 sec)
336.21... logprob:  0.643420, 0.343750 (0.664 sec)
336.22... logprob:  0.628054, 0.320312 (0.665 sec)
336.23... logprob:  0.623235, 0.312500 (0.665 sec)
336.24... logprob:  0.578097, 0.242188 (0.663 sec)
336.25... logprob:  0.628231, 0.320312 (0.663 sec)
336.26... logprob:  0.673980, 0.390625 (0.664 sec)
336.27... logprob:  0.628074, 0.320312 (0.665 sec)
337.1... logprob:  0.679418, 0.398438 (0.667 sec)
337.2... logprob:  0.597199, 0.273438 (0.665 sec)
337.3... logprob:  0.653762, 0.359375 (0.665 sec)
337.4... logprob:  0.596782, 0.273438 (0.665 sec)
337.5... logprob:  0.591022, 0.265625 (0.666 sec)
337.6... logprob:  0.611424, 0.296875 (0.666 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643778, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943692e-03 [7.349181e-09] 
Layer 'conv1' biases: 5.043335e-07 [1.643972e-10] 
Layer 'conv2' weights[0]: 7.931472e-03 [6.287768e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.711536e-10] 
Layer 'conv3' weights[0]: 7.929235e-03 [6.093066e-09] 
Layer 'conv3' biases: 4.227256e-06 [2.249240e-09] 
Layer 'conv4' weights[0]: 7.961996e-03 [6.192472e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.979962e-08] 
Layer 'conv5' weights[0]: 7.961384e-03 [1.141606e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.213124e-07] 
Layer 'fc6' weights[0]: 7.557605e-03 [1.273632e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.222377e-08] 
Layer 'fc7' weights[0]: 7.503488e-03 [1.595626e-07] 
Layer 'fc7' biases: 9.998543e-01 [1.462227e-07] 
Layer 'fc8' weights[0]: 6.069718e-04 [7.894841e-06] 
Layer 'fc8' biases: 1.502829e-01 [1.796076e-04] 
Train error last 27 batches: 0.635816
-------------------------------------------------------
Not saving because 0.643778 > 0.627087 (334.9: -0.00%)
======================================================= (5.058 sec)
337.7... logprob:  0.643834, 0.343750 (0.665 sec)
337.8... logprob:  0.604799, 0.289062 (0.666 sec)
337.9... logprob:  0.638566, 0.335938 (0.669 sec)
337.10... logprob:  0.597865, 0.281250 (0.665 sec)
337.11... logprob:  0.638941, 0.335938 (0.668 sec)
337.12... logprob:  0.718185, 0.437500 (0.667 sec)
337.13... logprob:  0.657456, 0.359375 (0.666 sec)
337.14... logprob:  0.663072, 0.367188 (0.666 sec)
337.15... logprob:  0.686185, 0.398438 (0.664 sec)
337.16... logprob:  0.627067, 0.320312 (0.663 sec)
337.17... logprob:  0.638513, 0.335938 (0.666 sec)
337.18... logprob:  0.638224, 0.335938 (0.665 sec)
337.19... logprob:  0.632727, 0.328125 (0.665 sec)
337.20... logprob:  0.648855, 0.351562 (0.664 sec)
337.21... logprob:  0.643421, 0.343750 (0.664 sec)
337.22... logprob:  0.628051, 0.320312 (0.664 sec)
337.23... logprob:  0.623229, 0.312500 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643444, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943619e-03 [6.339519e-09] 
Layer 'conv1' biases: 5.057618e-07 [1.041906e-10] 
Layer 'conv2' weights[0]: 7.931409e-03 [5.324951e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.129888e-10] 
Layer 'conv3' weights[0]: 7.929169e-03 [4.737035e-09] 
Layer 'conv3' biases: 4.239587e-06 [1.077942e-09] 
Layer 'conv4' weights[0]: 7.961922e-03 [4.608691e-09] 
Layer 'conv4' biases: 1.000001e+00 [5.679744e-09] 
Layer 'conv5' weights[0]: 7.961306e-03 [3.290339e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.458097e-08] 
Layer 'fc6' weights[0]: 7.557532e-03 [5.284885e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.573228e-09] 
Layer 'fc7' weights[0]: 7.502853e-03 [6.475745e-08] 
Layer 'fc7' biases: 9.998537e-01 [4.361572e-08] 
Layer 'fc8' weights[0]: 5.818860e-04 [2.318639e-06] 
Layer 'fc8' biases: 1.499101e-01 [3.671747e-05] 
Train error last 27 batches: 0.635814
-------------------------------------------------------
Not saving because 0.643444 > 0.627087 (334.9: -0.00%)
======================================================= (5.119 sec)
337.24... logprob:  0.578077, 0.242188 (0.667 sec)
337.25... logprob:  0.628227, 0.320312 (0.666 sec)
337.26... logprob:  0.673987, 0.390625 (0.667 sec)
337.27... logprob:  0.628071, 0.320312 (0.668 sec)
338.1... logprob:  0.679424, 0.398438 (0.669 sec)
338.2... logprob:  0.597192, 0.273438 (0.668 sec)
338.3... logprob:  0.653764, 0.359375 (0.670 sec)
338.4... logprob:  0.596778, 0.273438 (0.666 sec)
338.5... logprob:  0.591020, 0.265625 (0.667 sec)
338.6... logprob:  0.611425, 0.296875 (0.669 sec)
338.7... logprob:  0.643833, 0.343750 (0.669 sec)
338.8... logprob:  0.604803, 0.289062 (0.670 sec)
338.9... logprob:  0.638565, 0.335938 (0.671 sec)
338.10... logprob:  0.597872, 0.281250 (0.668 sec)
338.11... logprob:  0.638937, 0.335938 (0.666 sec)
338.12... logprob:  0.718155, 0.437500 (0.665 sec)
338.13... logprob:  0.657446, 0.359375 (0.665 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.645115, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943556e-03 [6.534600e-09] 
Layer 'conv1' biases: 5.064293e-07 [1.012291e-10] 
Layer 'conv2' weights[0]: 7.931342e-03 [5.485417e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.751847e-10] 
Layer 'conv3' weights[0]: 7.929103e-03 [4.816552e-09] 
Layer 'conv3' biases: 4.242998e-06 [1.298378e-09] 
Layer 'conv4' weights[0]: 7.961863e-03 [4.727886e-09] 
Layer 'conv4' biases: 1.000001e+00 [7.371105e-09] 
Layer 'conv5' weights[0]: 7.961248e-03 [4.240575e-08] 
Layer 'conv5' biases: 1.000002e+00 [4.497158e-08] 
Layer 'fc6' weights[0]: 7.557465e-03 [5.955986e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.524502e-09] 
Layer 'fc7' weights[0]: 7.502186e-03 [7.455245e-08] 
Layer 'fc7' biases: 9.998546e-01 [5.475600e-08] 
Layer 'fc8' weights[0]: 6.338266e-04 [2.961275e-06] 
Layer 'fc8' biases: 1.513686e-01 [4.456637e-05] 
Train error last 27 batches: 0.635812
-------------------------------------------------------
Not saving because 0.645115 > 0.627087 (334.9: -0.00%)
======================================================= (5.105 sec)
338.14... logprob:  0.663062, 0.367188 (0.668 sec)
338.15... logprob:  0.686173, 0.398438 (0.665 sec)
338.16... logprob:  0.627067, 0.320312 (0.664 sec)
338.17... logprob:  0.638513, 0.335938 (0.666 sec)
338.18... logprob:  0.638223, 0.335938 (0.664 sec)
338.19... logprob:  0.632726, 0.328125 (0.666 sec)
338.20... logprob:  0.648856, 0.351562 (0.665 sec)
338.21... logprob:  0.643421, 0.343750 (0.666 sec)
338.22... logprob:  0.628048, 0.320312 (0.665 sec)
338.23... logprob:  0.623224, 0.312500 (0.665 sec)
338.24... logprob:  0.578061, 0.242188 (0.670 sec)
338.25... logprob:  0.628223, 0.320312 (0.665 sec)
338.26... logprob:  0.673994, 0.390625 (0.664 sec)
338.27... logprob:  0.628067, 0.320312 (0.665 sec)
339.1... logprob:  0.679432, 0.398438 (0.666 sec)
339.2... logprob:  0.597183, 0.273438 (0.666 sec)
339.3... logprob:  0.653766, 0.359375 (0.666 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643472, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943492e-03 [6.705628e-09] 
Layer 'conv1' biases: 5.079929e-07 [6.440179e-11] 
Layer 'conv2' weights[0]: 7.931281e-03 [4.968786e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.554193e-10] 
Layer 'conv3' weights[0]: 7.929035e-03 [4.465263e-09] 
Layer 'conv3' biases: 4.257290e-06 [6.661372e-10] 
Layer 'conv4' weights[0]: 7.961795e-03 [4.347592e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.433191e-09] 
Layer 'conv5' weights[0]: 7.961172e-03 [1.504277e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.547339e-08] 
Layer 'fc6' weights[0]: 7.557404e-03 [4.151467e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.543569e-09] 
Layer 'fc7' weights[0]: 7.501560e-03 [4.522862e-08] 
Layer 'fc7' biases: 9.998538e-01 [1.861572e-08] 
Layer 'fc8' weights[0]: 5.900470e-04 [9.920600e-07] 
Layer 'fc8' biases: 1.505653e-01 [2.979438e-05] 
Train error last 27 batches: 0.635810
-------------------------------------------------------
Not saving because 0.643472 > 0.627087 (334.9: -0.00%)
======================================================= (5.168 sec)
339.4... logprob:  0.596771, 0.273438 (0.666 sec)
339.5... logprob:  0.591014, 0.265625 (0.664 sec)
339.6... logprob:  0.611423, 0.296875 (0.662 sec)
339.7... logprob:  0.643833, 0.343750 (0.666 sec)
339.8... logprob:  0.604804, 0.289062 (0.667 sec)
339.9... logprob:  0.638564, 0.335938 (0.666 sec)
339.10... logprob:  0.597876, 0.281250 (0.666 sec)
339.11... logprob:  0.638935, 0.335938 (0.666 sec)
339.12... logprob:  0.718134, 0.437500 (0.665 sec)
339.13... logprob:  0.657439, 0.359375 (0.667 sec)
339.14... logprob:  0.663055, 0.367188 (0.664 sec)
339.15... logprob:  0.686164, 0.398438 (0.665 sec)
339.16... logprob:  0.627067, 0.320312 (0.663 sec)
339.17... logprob:  0.638512, 0.335938 (0.665 sec)
339.18... logprob:  0.638224, 0.335938 (0.662 sec)
339.19... logprob:  0.632726, 0.328125 (0.664 sec)
339.20... logprob:  0.648858, 0.351562 (0.663 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643491, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943429e-03 [6.816356e-09] 
Layer 'conv1' biases: 5.091652e-07 [1.622551e-10] 
Layer 'conv2' weights[0]: 7.931213e-03 [6.544308e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.764877e-10] 
Layer 'conv3' weights[0]: 7.928977e-03 [5.741227e-09] 
Layer 'conv3' biases: 4.266800e-06 [2.119779e-09] 
Layer 'conv4' weights[0]: 7.961728e-03 [5.673441e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.486951e-08] 
Layer 'conv5' weights[0]: 7.961111e-03 [8.580346e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.102870e-08] 
Layer 'fc6' weights[0]: 7.557340e-03 [1.007827e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.242178e-09] 
Layer 'fc7' weights[0]: 7.500887e-03 [1.269138e-07] 
Layer 'fc7' biases: 9.998538e-01 [1.114485e-07] 
Layer 'fc8' weights[0]: 5.916610e-04 [5.981583e-06] 
Layer 'fc8' biases: 1.508427e-01 [1.140558e-04] 
Train error last 27 batches: 0.635808
-------------------------------------------------------
Not saving because 0.643491 > 0.627087 (334.9: -0.00%)
======================================================= (5.062 sec)
339.21... logprob:  0.643422, 0.343750 (0.665 sec)
339.22... logprob:  0.628045, 0.320312 (0.664 sec)
339.23... logprob:  0.623219, 0.312500 (0.665 sec)
339.24... logprob:  0.578044, 0.242188 (0.665 sec)
339.25... logprob:  0.628220, 0.320312 (0.664 sec)
339.26... logprob:  0.674000, 0.390625 (0.665 sec)
339.27... logprob:  0.628066, 0.320312 (0.666 sec)
340.1... logprob:  0.679437, 0.398438 (0.668 sec)
340.2... logprob:  0.597178, 0.273438 (0.665 sec)
340.3... logprob:  0.653767, 0.359375 (0.667 sec)
340.4... logprob:  0.596768, 0.273438 (0.665 sec)
340.5... logprob:  0.591014, 0.265625 (0.665 sec)
340.6... logprob:  0.611424, 0.296875 (0.666 sec)
340.7... logprob:  0.643832, 0.343750 (0.665 sec)
340.8... logprob:  0.604809, 0.289062 (0.668 sec)
340.9... logprob:  0.638562, 0.335938 (0.668 sec)
340.10... logprob:  0.597883, 0.281250 (0.666 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644961, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943364e-03 [7.031951e-09] 
Layer 'conv1' biases: 5.099510e-07 [1.427086e-10] 
Layer 'conv2' weights[0]: 7.931146e-03 [6.220286e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.334897e-10] 
Layer 'conv3' weights[0]: 7.928909e-03 [6.071986e-09] 
Layer 'conv3' biases: 4.271449e-06 [2.219984e-09] 
Layer 'conv4' weights[0]: 7.961660e-03 [6.258201e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.950889e-08] 
Layer 'conv5' weights[0]: 7.961059e-03 [1.131146e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.202639e-07] 
Layer 'fc6' weights[0]: 7.557272e-03 [1.252353e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.199122e-08] 
Layer 'fc7' weights[0]: 7.500243e-03 [1.552355e-07] 
Layer 'fc7' biases: 9.998545e-01 [1.415669e-07] 
Layer 'fc8' weights[0]: 6.309085e-04 [7.739684e-06] 
Layer 'fc8' biases: 1.519880e-01 [1.709570e-04] 
Train error last 27 batches: 0.635808
-------------------------------------------------------
Not saving because 0.644961 > 0.627087 (334.9: -0.00%)
======================================================= (5.054 sec)
340.11... logprob:  0.638931, 0.335938 (0.671 sec)
340.12... logprob:  0.718106, 0.437500 (0.671 sec)
340.13... logprob:  0.657429, 0.359375 (0.673 sec)
340.14... logprob:  0.663046, 0.367188 (0.672 sec)
340.15... logprob:  0.686153, 0.398438 (0.681 sec)
340.16... logprob:  0.627067, 0.320312 (0.668 sec)
340.17... logprob:  0.638512, 0.335938 (0.671 sec)
340.18... logprob:  0.638223, 0.335938 (0.671 sec)
340.19... logprob:  0.632725, 0.328125 (0.667 sec)
340.20... logprob:  0.648859, 0.351562 (0.670 sec)
340.21... logprob:  0.643422, 0.343750 (0.680 sec)
340.22... logprob:  0.628042, 0.320312 (0.668 sec)
340.23... logprob:  0.623215, 0.312500 (0.666 sec)
340.24... logprob:  0.578030, 0.242188 (0.668 sec)
340.25... logprob:  0.628217, 0.320312 (0.668 sec)
340.26... logprob:  0.674005, 0.390625 (0.669 sec)
340.27... logprob:  0.628062, 0.320312 (0.668 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643461, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943305e-03 [6.587768e-09] 
Layer 'conv1' biases: 5.115293e-07 [6.950366e-11] 
Layer 'conv2' weights[0]: 7.931093e-03 [4.893660e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.631856e-10] 
Layer 'conv3' weights[0]: 7.928848e-03 [4.465111e-09] 
Layer 'conv3' biases: 4.285765e-06 [7.228209e-10] 
Layer 'conv4' weights[0]: 7.961591e-03 [4.398783e-09] 
Layer 'conv4' biases: 1.000001e+00 [4.075332e-09] 
Layer 'conv5' weights[0]: 7.960992e-03 [2.385813e-08] 
Layer 'conv5' biases: 1.000002e+00 [2.506090e-08] 
Layer 'fc6' weights[0]: 7.557207e-03 [4.659637e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.487140e-09] 
Layer 'fc7' weights[0]: 7.499574e-03 [5.389673e-08] 
Layer 'fc7' biases: 9.998537e-01 [2.993696e-08] 
Layer 'fc8' weights[0]: 5.878048e-04 [1.573316e-06] 
Layer 'fc8' biases: 1.512084e-01 [4.648815e-05] 
Train error last 27 batches: 0.635804
-------------------------------------------------------
Not saving because 0.643461 > 0.627087 (334.9: -0.00%)
======================================================= (5.149 sec)
341.1... logprob:  0.679443, 0.398438 (0.666 sec)
341.2... logprob:  0.597170, 0.273438 (0.666 sec)
341.3... logprob:  0.653768, 0.359375 (0.666 sec)
341.4... logprob:  0.596763, 0.273438 (0.665 sec)
341.5... logprob:  0.591009, 0.265625 (0.665 sec)
341.6... logprob:  0.611423, 0.296875 (0.666 sec)
341.7... logprob:  0.643832, 0.343750 (0.665 sec)
341.8... logprob:  0.604809, 0.289062 (0.667 sec)
341.9... logprob:  0.638562, 0.335938 (0.666 sec)
341.10... logprob:  0.597886, 0.281250 (0.672 sec)
341.11... logprob:  0.638929, 0.335938 (0.671 sec)
341.12... logprob:  0.718091, 0.437500 (0.671 sec)
341.13... logprob:  0.657425, 0.359375 (0.669 sec)
341.14... logprob:  0.663040, 0.367188 (0.670 sec)
341.15... logprob:  0.686147, 0.398438 (0.669 sec)
341.16... logprob:  0.627067, 0.320312 (0.667 sec)
341.17... logprob:  0.638513, 0.335938 (0.669 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643838, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943248e-03 [6.453390e-09] 
Layer 'conv1' biases: 5.125170e-07 [1.716757e-10] 
Layer 'conv2' weights[0]: 7.931015e-03 [6.916787e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.799139e-10] 
Layer 'conv3' weights[0]: 7.928776e-03 [6.085794e-09] 
Layer 'conv3' biases: 4.293110e-06 [2.406481e-09] 
Layer 'conv4' weights[0]: 7.961528e-03 [6.138002e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.811960e-08] 
Layer 'conv5' weights[0]: 7.960921e-03 [1.042650e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.106789e-07] 
Layer 'fc6' weights[0]: 7.557143e-03 [1.175877e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.119459e-08] 
Layer 'fc7' weights[0]: 7.498913e-03 [1.471054e-07] 
Layer 'fc7' biases: 9.998540e-01 [1.334680e-07] 
Layer 'fc8' weights[0]: 6.073505e-04 [7.251360e-06] 
Layer 'fc8' biases: 1.519055e-01 [1.361519e-04] 
Train error last 27 batches: 0.635803
-------------------------------------------------------
Not saving because 0.643838 > 0.627087 (334.9: -0.00%)
======================================================= (5.067 sec)
341.18... logprob:  0.638223, 0.335938 (0.670 sec)
341.19... logprob:  0.632724, 0.328125 (0.666 sec)
341.20... logprob:  0.648860, 0.351562 (0.669 sec)
341.21... logprob:  0.643423, 0.343750 (0.671 sec)
341.22... logprob:  0.628040, 0.320312 (0.670 sec)
341.23... logprob:  0.623211, 0.312500 (0.670 sec)
341.24... logprob:  0.578014, 0.242188 (0.668 sec)
341.25... logprob:  0.628214, 0.320312 (0.670 sec)
341.26... logprob:  0.674011, 0.390625 (0.665 sec)
341.27... logprob:  0.628061, 0.320312 (0.664 sec)
342.1... logprob:  0.679448, 0.398438 (0.666 sec)
342.2... logprob:  0.597166, 0.273438 (0.665 sec)
342.3... logprob:  0.653769, 0.359375 (0.664 sec)
342.4... logprob:  0.596762, 0.273438 (0.666 sec)
342.5... logprob:  0.591010, 0.265625 (0.664 sec)
342.6... logprob:  0.611425, 0.296875 (0.667 sec)
342.7... logprob:  0.643831, 0.343750 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643965, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943177e-03 [6.819803e-09] 
Layer 'conv1' biases: 5.136274e-07 [1.281729e-10] 
Layer 'conv2' weights[0]: 7.930957e-03 [5.803753e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.156543e-10] 
Layer 'conv3' weights[0]: 7.928713e-03 [5.636667e-09] 
Layer 'conv3' biases: 4.301956e-06 [1.883997e-09] 
Layer 'conv4' weights[0]: 7.961458e-03 [5.739257e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.632913e-08] 
Layer 'conv5' weights[0]: 7.960855e-03 [9.383093e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.975097e-08] 
Layer 'fc6' weights[0]: 7.557075e-03 [1.075185e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.003039e-08] 
Layer 'fc7' weights[0]: 7.498263e-03 [1.345333e-07] 
Layer 'fc7' biases: 9.998541e-01 [1.195275e-07] 
Layer 'fc8' weights[0]: 6.108505e-04 [6.444376e-06] 
Layer 'fc8' biases: 1.522070e-01 [1.488685e-04] 
Train error last 27 batches: 0.635802
-------------------------------------------------------
Not saving because 0.643965 > 0.627087 (334.9: -0.00%)
======================================================= (5.068 sec)
342.8... logprob:  0.604814, 0.289062 (0.670 sec)
342.9... logprob:  0.638560, 0.335938 (0.668 sec)
342.10... logprob:  0.597894, 0.281250 (0.667 sec)
342.11... logprob:  0.638924, 0.335938 (0.668 sec)
342.12... logprob:  0.718062, 0.437500 (0.667 sec)
342.13... logprob:  0.657414, 0.359375 (0.669 sec)
342.14... logprob:  0.663030, 0.367188 (0.669 sec)
342.15... logprob:  0.686135, 0.398438 (0.665 sec)
342.16... logprob:  0.627067, 0.320312 (0.668 sec)
342.17... logprob:  0.638512, 0.335938 (0.668 sec)
342.18... logprob:  0.638223, 0.335938 (0.667 sec)
342.19... logprob:  0.632724, 0.328125 (0.666 sec)
342.20... logprob:  0.648860, 0.351562 (0.666 sec)
342.21... logprob:  0.643423, 0.343750 (0.666 sec)
342.22... logprob:  0.628037, 0.320312 (0.666 sec)
342.23... logprob:  0.623207, 0.312500 (0.669 sec)
342.24... logprob:  0.578001, 0.242188 (0.667 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643443, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943110e-03 [6.499391e-09] 
Layer 'conv1' biases: 5.150985e-07 [5.968275e-11] 
Layer 'conv2' weights[0]: 7.930899e-03 [4.864158e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.013872e-10] 
Layer 'conv3' weights[0]: 7.928648e-03 [4.530573e-09] 
Layer 'conv3' biases: 4.314627e-06 [8.573295e-10] 
Layer 'conv4' weights[0]: 7.961397e-03 [4.478781e-09] 
Layer 'conv4' biases: 1.000001e+00 [6.194138e-09] 
Layer 'conv5' weights[0]: 7.960802e-03 [3.528842e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.728866e-08] 
Layer 'fc6' weights[0]: 7.557019e-03 [5.432108e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.760508e-09] 
Layer 'fc7' weights[0]: 7.497606e-03 [6.638490e-08] 
Layer 'fc7' biases: 9.998534e-01 [4.531753e-08] 
Layer 'fc8' weights[0]: 5.825776e-04 [2.383606e-06] 
Layer 'fc8' biases: 1.517587e-01 [6.900890e-05] 
Train error last 27 batches: 0.635799
-------------------------------------------------------
Not saving because 0.643443 > 0.627087 (334.9: -0.00%)
======================================================= (5.118 sec)
342.25... logprob:  0.628210, 0.320312 (0.663 sec)
342.26... logprob:  0.674016, 0.390625 (0.669 sec)
342.27... logprob:  0.628058, 0.320312 (0.666 sec)
343.1... logprob:  0.679453, 0.398438 (0.670 sec)
343.2... logprob:  0.597159, 0.273438 (0.668 sec)
343.3... logprob:  0.653771, 0.359375 (0.669 sec)
343.4... logprob:  0.596755, 0.273438 (0.667 sec)
343.5... logprob:  0.591005, 0.265625 (0.670 sec)
343.6... logprob:  0.611423, 0.296875 (0.669 sec)
343.7... logprob:  0.643831, 0.343750 (0.669 sec)
343.8... logprob:  0.604814, 0.289062 (0.670 sec)
343.9... logprob:  0.638559, 0.335938 (0.670 sec)
343.10... logprob:  0.597896, 0.281250 (0.667 sec)
343.11... logprob:  0.638922, 0.335938 (0.668 sec)
343.12... logprob:  0.718050, 0.437500 (0.669 sec)
343.13... logprob:  0.657411, 0.359375 (0.670 sec)
343.14... logprob:  0.663026, 0.367188 (0.669 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644798, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943036e-03 [6.779323e-09] 
Layer 'conv1' biases: 5.158472e-07 [1.515345e-10] 
Layer 'conv2' weights[0]: 7.930837e-03 [6.281785e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.906622e-10] 
Layer 'conv3' weights[0]: 7.928575e-03 [5.489712e-09] 
Layer 'conv3' biases: 4.318834e-06 [1.906628e-09] 
Layer 'conv4' weights[0]: 7.961336e-03 [5.454220e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.285206e-08] 
Layer 'conv5' weights[0]: 7.960713e-03 [7.421747e-08] 
Layer 'conv5' biases: 1.000002e+00 [7.882111e-08] 
Layer 'fc6' weights[0]: 7.556946e-03 [8.948419e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.953731e-09] 
Layer 'fc7' weights[0]: 7.496946e-03 [1.122477e-07] 
Layer 'fc7' biases: 9.998543e-01 [9.491831e-08] 
Layer 'fc8' weights[0]: 6.273080e-04 [5.146638e-06] 
Layer 'fc8' biases: 1.530517e-01 [9.018392e-05] 
Train error last 27 batches: 0.635798
-------------------------------------------------------
Not saving because 0.644798 > 0.627087 (334.9: -0.00%)
======================================================= (5.069 sec)
343.15... logprob:  0.686131, 0.398438 (0.668 sec)
343.16... logprob:  0.627067, 0.320312 (0.669 sec)
343.17... logprob:  0.638512, 0.335938 (0.668 sec)
343.18... logprob:  0.638223, 0.335938 (0.667 sec)
343.19... logprob:  0.632723, 0.328125 (0.668 sec)
343.20... logprob:  0.648861, 0.351562 (0.666 sec)
343.21... logprob:  0.643423, 0.343750 (0.667 sec)
343.22... logprob:  0.628035, 0.320312 (0.665 sec)
343.23... logprob:  0.623204, 0.312500 (0.668 sec)
343.24... logprob:  0.577990, 0.242188 (0.667 sec)
343.25... logprob:  0.628208, 0.320312 (0.668 sec)
343.26... logprob:  0.674020, 0.390625 (0.668 sec)
343.27... logprob:  0.628056, 0.320312 (0.673 sec)
344.1... logprob:  0.679457, 0.398438 (0.670 sec)
344.2... logprob:  0.597154, 0.273438 (0.668 sec)
344.3... logprob:  0.653772, 0.359375 (0.670 sec)
344.4... logprob:  0.596753, 0.273438 (0.670 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643508, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942977e-03 [6.857901e-09] 
Layer 'conv1' biases: 5.173276e-07 [8.964207e-11] 
Layer 'conv2' weights[0]: 7.930770e-03 [5.299347e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.712241e-10] 
Layer 'conv3' weights[0]: 7.928505e-03 [4.988146e-09] 
Layer 'conv3' biases: 4.332108e-06 [1.248190e-09] 
Layer 'conv4' weights[0]: 7.961272e-03 [4.956472e-09] 
Layer 'conv4' biases: 1.000001e+00 [9.598533e-09] 
Layer 'conv5' weights[0]: 7.960674e-03 [5.600418e-08] 
Layer 'conv5' biases: 1.000002e+00 [5.930897e-08] 
Layer 'fc6' weights[0]: 7.556876e-03 [7.159687e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.947336e-09] 
Layer 'fc7' weights[0]: 7.496326e-03 [8.944513e-08] 
Layer 'fc7' biases: 9.998537e-01 [7.082532e-08] 
Layer 'fc8' weights[0]: 5.918295e-04 [3.794931e-06] 
Layer 'fc8' biases: 1.524307e-01 [9.274571e-05] 
Train error last 27 batches: 0.635797
-------------------------------------------------------
Not saving because 0.643508 > 0.627087 (334.9: -0.00%)
======================================================= (5.092 sec)
344.5... logprob:  0.591003, 0.265625 (0.665 sec)
344.6... logprob:  0.611423, 0.296875 (0.666 sec)
344.7... logprob:  0.643830, 0.343750 (0.666 sec)
344.8... logprob:  0.604816, 0.289062 (0.667 sec)
344.9... logprob:  0.638558, 0.335938 (0.664 sec)
344.10... logprob:  0.597901, 0.281250 (0.667 sec)
344.11... logprob:  0.638920, 0.335938 (0.665 sec)
344.12... logprob:  0.718029, 0.437500 (0.662 sec)
344.13... logprob:  0.657404, 0.359375 (0.665 sec)
344.14... logprob:  0.663020, 0.367188 (0.667 sec)
344.15... logprob:  0.686123, 0.398438 (0.664 sec)
344.16... logprob:  0.627068, 0.320312 (0.665 sec)
344.17... logprob:  0.638512, 0.335938 (0.665 sec)
344.18... logprob:  0.638224, 0.335938 (0.665 sec)
344.19... logprob:  0.632723, 0.328125 (0.664 sec)
344.20... logprob:  0.648863, 0.351562 (0.667 sec)
344.21... logprob:  0.643424, 0.343750 (0.666 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643453, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942903e-03 [6.850263e-09] 
Layer 'conv1' biases: 5.185808e-07 [1.536022e-10] 
Layer 'conv2' weights[0]: 7.930703e-03 [6.506671e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.372453e-10] 
Layer 'conv3' weights[0]: 7.928444e-03 [5.680255e-09] 
Layer 'conv3' biases: 4.342634e-06 [2.018633e-09] 
Layer 'conv4' weights[0]: 7.961208e-03 [5.597842e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.384812e-08] 
Layer 'conv5' weights[0]: 7.960606e-03 [7.943450e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.409789e-08] 
Layer 'fc6' weights[0]: 7.556809e-03 [9.587147e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.623662e-09] 
Layer 'fc7' weights[0]: 7.495675e-03 [1.204094e-07] 
Layer 'fc7' biases: 9.998536e-01 [1.038489e-07] 
Layer 'fc8' weights[0]: 5.854222e-04 [5.537152e-06] 
Layer 'fc8' biases: 1.525094e-01 [1.071951e-04] 
Train error last 27 batches: 0.635796
-------------------------------------------------------
Not saving because 0.643453 > 0.627087 (334.9: -0.00%)
======================================================= (5.066 sec)
344.22... logprob:  0.628031, 0.320312 (0.665 sec)
344.23... logprob:  0.623198, 0.312500 (0.664 sec)
344.24... logprob:  0.577972, 0.242188 (0.660 sec)
344.25... logprob:  0.628205, 0.320312 (0.664 sec)
344.26... logprob:  0.674027, 0.390625 (0.665 sec)
344.27... logprob:  0.628053, 0.320312 (0.665 sec)
345.1... logprob:  0.679463, 0.398438 (0.666 sec)
345.2... logprob:  0.597147, 0.273438 (0.666 sec)
345.3... logprob:  0.653773, 0.359375 (0.666 sec)
345.4... logprob:  0.596749, 0.273438 (0.664 sec)
345.5... logprob:  0.591001, 0.265625 (0.664 sec)
345.6... logprob:  0.611424, 0.296875 (0.668 sec)
345.7... logprob:  0.643830, 0.343750 (0.665 sec)
345.8... logprob:  0.604821, 0.289062 (0.666 sec)
345.9... logprob:  0.638557, 0.335938 (0.667 sec)
345.10... logprob:  0.597908, 0.281250 (0.666 sec)
345.11... logprob:  0.638916, 0.335938 (0.666 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.645315, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942828e-03 [6.789298e-09] 
Layer 'conv1' biases: 5.192841e-07 [1.166521e-10] 
Layer 'conv2' weights[0]: 7.930633e-03 [5.703778e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.644051e-10] 
Layer 'conv3' weights[0]: 7.928377e-03 [5.545441e-09] 
Layer 'conv3' biases: 4.346114e-06 [1.775914e-09] 
Layer 'conv4' weights[0]: 7.961141e-03 [5.640317e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.524902e-08] 
Layer 'conv5' weights[0]: 7.960526e-03 [8.809708e-08] 
Layer 'conv5' biases: 1.000001e+00 [9.378392e-08] 
Layer 'fc6' weights[0]: 7.556738e-03 [1.023874e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.405105e-09] 
Layer 'fc7' weights[0]: 7.494965e-03 [1.268016e-07] 
Layer 'fc7' biases: 9.998544e-01 [1.103688e-07] 
Layer 'fc8' weights[0]: 6.342806e-04 [6.027629e-06] 
Layer 'fc8' biases: 1.538906e-01 [1.359051e-04] 
Train error last 27 batches: 0.635795
-------------------------------------------------------
Not saving because 0.645315 > 0.627087 (334.9: -0.00%)
======================================================= (5.059 sec)
345.12... logprob:  0.718001, 0.437500 (0.663 sec)
345.13... logprob:  0.657394, 0.359375 (0.665 sec)
345.14... logprob:  0.663010, 0.367188 (0.668 sec)
345.15... logprob:  0.686111, 0.398438 (0.664 sec)
345.16... logprob:  0.627068, 0.320312 (0.665 sec)
345.17... logprob:  0.638512, 0.335938 (0.665 sec)
345.18... logprob:  0.638223, 0.335938 (0.664 sec)
345.19... logprob:  0.632722, 0.328125 (0.665 sec)
345.20... logprob:  0.648863, 0.351562 (0.665 sec)
345.21... logprob:  0.643423, 0.343750 (0.666 sec)
345.22... logprob:  0.628028, 0.320312 (0.664 sec)
345.23... logprob:  0.623195, 0.312500 (0.665 sec)
345.24... logprob:  0.577956, 0.242188 (0.664 sec)
345.25... logprob:  0.628201, 0.320312 (0.665 sec)
345.26... logprob:  0.674033, 0.390625 (0.664 sec)
345.27... logprob:  0.628051, 0.320312 (0.666 sec)
346.1... logprob:  0.679469, 0.398438 (0.668 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643455, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942752e-03 [6.648450e-09] 
Layer 'conv1' biases: 5.209145e-07 [8.027693e-11] 
Layer 'conv2' weights[0]: 7.930570e-03 [5.135603e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.242464e-10] 
Layer 'conv3' weights[0]: 7.928317e-03 [4.485319e-09] 
Layer 'conv3' biases: 4.361147e-06 [8.074275e-10] 
Layer 'conv4' weights[0]: 7.961083e-03 [4.384191e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.972547e-09] 
Layer 'conv5' weights[0]: 7.960469e-03 [1.688316e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.726271e-08] 
Layer 'fc6' weights[0]: 7.556674e-03 [4.276116e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.844593e-09] 
Layer 'fc7' weights[0]: 7.494372e-03 [4.807544e-08] 
Layer 'fc7' biases: 9.998536e-01 [2.323570e-08] 
Layer 'fc8' weights[0]: 5.853040e-04 [1.186668e-06] 
Layer 'fc8' biases: 1.529607e-01 [1.636684e-05] 
Train error last 27 batches: 0.635792
-------------------------------------------------------
Not saving because 0.643455 > 0.627087 (334.9: -0.00%)
======================================================= (5.164 sec)
346.2... logprob:  0.597140, 0.273438 (0.666 sec)
346.3... logprob:  0.653775, 0.359375 (0.665 sec)
346.4... logprob:  0.596743, 0.273438 (0.665 sec)
346.5... logprob:  0.590997, 0.265625 (0.665 sec)
346.6... logprob:  0.611422, 0.296875 (0.666 sec)
346.7... logprob:  0.643830, 0.343750 (0.666 sec)
346.8... logprob:  0.604821, 0.289062 (0.667 sec)
346.9... logprob:  0.638556, 0.335938 (0.667 sec)
346.10... logprob:  0.597912, 0.281250 (0.666 sec)
346.11... logprob:  0.638914, 0.335938 (0.666 sec)
346.12... logprob:  0.717984, 0.437500 (0.662 sec)
346.13... logprob:  0.657389, 0.359375 (0.663 sec)
346.14... logprob:  0.663005, 0.367188 (0.665 sec)
346.15... logprob:  0.686105, 0.398438 (0.664 sec)
346.16... logprob:  0.627068, 0.320312 (0.665 sec)
346.17... logprob:  0.638512, 0.335938 (0.665 sec)
346.18... logprob:  0.638224, 0.335938 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643673, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942689e-03 [6.532739e-09] 
Layer 'conv1' biases: 5.219605e-07 [1.740239e-10] 
Layer 'conv2' weights[0]: 7.930505e-03 [6.784188e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.482652e-10] 
Layer 'conv3' weights[0]: 7.928248e-03 [5.965707e-09] 
Layer 'conv3' biases: 4.369123e-06 [2.313037e-09] 
Layer 'conv4' weights[0]: 7.961031e-03 [5.963533e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.685833e-08] 
Layer 'conv5' weights[0]: 7.960401e-03 [9.691823e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.028593e-07] 
Layer 'fc6' weights[0]: 7.556618e-03 [1.106156e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.042348e-08] 
Layer 'fc7' weights[0]: 7.493699e-03 [1.384588e-07] 
Layer 'fc7' biases: 9.998537e-01 [1.242954e-07] 
Layer 'fc8' weights[0]: 5.997400e-04 [6.699147e-06] 
Layer 'fc8' biases: 1.535445e-01 [1.275245e-04] 
Train error last 27 batches: 0.635790
-------------------------------------------------------
Not saving because 0.643673 > 0.627087 (334.9: -0.00%)
======================================================= (5.050 sec)
346.19... logprob:  0.632722, 0.328125 (0.665 sec)
346.20... logprob:  0.648866, 0.351562 (0.665 sec)
346.21... logprob:  0.643424, 0.343750 (0.664 sec)
346.22... logprob:  0.628025, 0.320312 (0.666 sec)
346.23... logprob:  0.623188, 0.312500 (0.663 sec)
346.24... logprob:  0.577938, 0.242188 (0.664 sec)
346.25... logprob:  0.628197, 0.320312 (0.663 sec)
346.26... logprob:  0.674039, 0.390625 (0.665 sec)
346.27... logprob:  0.628048, 0.320312 (0.667 sec)
347.1... logprob:  0.679475, 0.398438 (0.668 sec)
347.2... logprob:  0.597134, 0.273438 (0.665 sec)
347.3... logprob:  0.653776, 0.359375 (0.665 sec)
347.4... logprob:  0.596741, 0.273438 (0.665 sec)
347.5... logprob:  0.590996, 0.265625 (0.666 sec)
347.6... logprob:  0.611424, 0.296875 (0.666 sec)
347.7... logprob:  0.643829, 0.343750 (0.663 sec)
347.8... logprob:  0.604828, 0.289062 (0.667 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644240, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942632e-03 [7.176908e-09] 
Layer 'conv1' biases: 5.229596e-07 [1.450449e-10] 
Layer 'conv2' weights[0]: 7.930438e-03 [6.279563e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.502276e-10] 
Layer 'conv3' weights[0]: 7.928184e-03 [6.086446e-09] 
Layer 'conv3' biases: 4.376504e-06 [2.228106e-09] 
Layer 'conv4' weights[0]: 7.960968e-03 [6.224775e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.936406e-08] 
Layer 'conv5' weights[0]: 7.960329e-03 [1.114402e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.183965e-07] 
Layer 'fc6' weights[0]: 7.556541e-03 [1.243259e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.188565e-08] 
Layer 'fc7' weights[0]: 7.493048e-03 [1.542452e-07] 
Layer 'fc7' biases: 9.998540e-01 [1.406653e-07] 
Layer 'fc8' weights[0]: 6.156430e-04 [7.596653e-06] 
Layer 'fc8' biases: 1.541408e-01 [1.730130e-04] 
Train error last 27 batches: 0.635790
-------------------------------------------------------
Not saving because 0.644240 > 0.627087 (334.9: -0.00%)
======================================================= (5.059 sec)
347.9... logprob:  0.638553, 0.335938 (0.666 sec)
347.10... logprob:  0.597920, 0.281250 (0.666 sec)
347.11... logprob:  0.638909, 0.335938 (0.666 sec)
347.12... logprob:  0.717949, 0.437500 (0.665 sec)
347.13... logprob:  0.657377, 0.359375 (0.666 sec)
347.14... logprob:  0.662993, 0.367188 (0.667 sec)
347.15... logprob:  0.686091, 0.398438 (0.664 sec)
347.16... logprob:  0.627069, 0.320312 (0.664 sec)
347.17... logprob:  0.638512, 0.335938 (0.664 sec)
347.18... logprob:  0.638223, 0.335938 (0.664 sec)
347.19... logprob:  0.632721, 0.328125 (0.665 sec)
347.20... logprob:  0.648867, 0.351562 (0.665 sec)
347.21... logprob:  0.643425, 0.343750 (0.665 sec)
347.22... logprob:  0.628022, 0.320312 (0.664 sec)
347.23... logprob:  0.623184, 0.312500 (0.665 sec)
347.24... logprob:  0.577919, 0.242188 (0.664 sec)
347.25... logprob:  0.628193, 0.320312 (0.665 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643451, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942558e-03 [6.602025e-09] 
Layer 'conv1' biases: 5.244537e-07 [6.924147e-11] 
Layer 'conv2' weights[0]: 7.930378e-03 [4.954801e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.641301e-10] 
Layer 'conv3' weights[0]: 7.928112e-03 [4.670127e-09] 
Layer 'conv3' biases: 4.389391e-06 [1.037172e-09] 
Layer 'conv4' weights[0]: 7.960900e-03 [4.663776e-09] 
Layer 'conv4' biases: 1.000001e+00 [8.075588e-09] 
Layer 'conv5' weights[0]: 7.960265e-03 [4.622953e-08] 
Layer 'conv5' biases: 1.000002e+00 [4.877203e-08] 
Layer 'fc6' weights[0]: 7.556471e-03 [6.298884e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.924069e-09] 
Layer 'fc7' weights[0]: 7.492397e-03 [7.826597e-08] 
Layer 'fc7' biases: 9.998536e-01 [5.884657e-08] 
Layer 'fc8' weights[0]: 5.837224e-04 [3.107479e-06] 
Layer 'fc8' biases: 1.536070e-01 [8.454526e-05] 
Train error last 27 batches: 0.635786
-------------------------------------------------------
Not saving because 0.643451 > 0.627087 (334.9: -0.00%)
======================================================= (5.103 sec)
347.26... logprob:  0.674047, 0.390625 (0.668 sec)
347.27... logprob:  0.628044, 0.320312 (0.668 sec)
348.1... logprob:  0.679483, 0.398438 (0.669 sec)
348.2... logprob:  0.597125, 0.273438 (0.670 sec)
348.3... logprob:  0.653778, 0.359375 (0.669 sec)
348.4... logprob:  0.596734, 0.273438 (0.668 sec)
348.5... logprob:  0.590992, 0.265625 (0.669 sec)
348.6... logprob:  0.611423, 0.296875 (0.666 sec)
348.7... logprob:  0.643827, 0.343750 (0.668 sec)
348.8... logprob:  0.604829, 0.289062 (0.670 sec)
348.9... logprob:  0.638553, 0.335938 (0.670 sec)
348.10... logprob:  0.597925, 0.281250 (0.669 sec)
348.11... logprob:  0.638907, 0.335938 (0.669 sec)
348.12... logprob:  0.717927, 0.437500 (0.668 sec)
348.13... logprob:  0.657370, 0.359375 (0.668 sec)
348.14... logprob:  0.662987, 0.367188 (0.668 sec)
348.15... logprob:  0.686082, 0.398438 (0.666 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644366, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942495e-03 [7.332947e-09] 
Layer 'conv1' biases: 5.253093e-07 [2.060928e-10] 
Layer 'conv2' weights[0]: 7.930316e-03 [7.652699e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.031586e-09] 
Layer 'conv3' weights[0]: 7.928039e-03 [6.621925e-09] 
Layer 'conv3' biases: 4.395103e-06 [2.855860e-09] 
Layer 'conv4' weights[0]: 7.960825e-03 [6.677864e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.132434e-08] 
Layer 'conv5' weights[0]: 7.960198e-03 [1.225568e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.303554e-07] 
Layer 'fc6' weights[0]: 7.556401e-03 [1.357904e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.314157e-08] 
Layer 'fc7' weights[0]: 7.491739e-03 [1.682293e-07] 
Layer 'fc7' biases: 9.998540e-01 [1.556253e-07] 
Layer 'fc8' weights[0]: 6.177971e-04 [8.445041e-06] 
Layer 'fc8' biases: 1.546497e-01 [1.596174e-04] 
Train error last 27 batches: 0.635784
-------------------------------------------------------
Not saving because 0.644366 > 0.627087 (334.9: -0.00%)
======================================================= (5.041 sec)
348.16... logprob:  0.627068, 0.320312 (0.668 sec)
348.17... logprob:  0.638511, 0.335938 (0.670 sec)
348.18... logprob:  0.638224, 0.335938 (0.668 sec)
348.19... logprob:  0.632722, 0.328125 (0.668 sec)
348.20... logprob:  0.648868, 0.351562 (0.666 sec)
348.21... logprob:  0.643426, 0.343750 (0.664 sec)
348.22... logprob:  0.628019, 0.320312 (0.664 sec)
348.23... logprob:  0.623178, 0.312500 (0.664 sec)
348.24... logprob:  0.577902, 0.242188 (0.664 sec)
348.25... logprob:  0.628190, 0.320312 (0.666 sec)
348.26... logprob:  0.674053, 0.390625 (0.667 sec)
348.27... logprob:  0.628043, 0.320312 (0.669 sec)
349.1... logprob:  0.679488, 0.398438 (0.667 sec)
349.2... logprob:  0.597119, 0.273438 (0.669 sec)
349.3... logprob:  0.653779, 0.359375 (0.668 sec)
349.4... logprob:  0.596731, 0.273438 (0.668 sec)
349.5... logprob:  0.590989, 0.265625 (0.668 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643605, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942429e-03 [7.427576e-09] 
Layer 'conv1' biases: 5.266663e-07 [1.389498e-10] 
Layer 'conv2' weights[0]: 7.930248e-03 [5.964575e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.503310e-10] 
Layer 'conv3' weights[0]: 7.927970e-03 [5.773095e-09] 
Layer 'conv3' biases: 4.406829e-06 [1.955281e-09] 
Layer 'conv4' weights[0]: 7.960760e-03 [5.829292e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.676595e-08] 
Layer 'conv5' weights[0]: 7.960121e-03 [9.674043e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.027808e-07] 
Layer 'fc6' weights[0]: 7.556328e-03 [1.103191e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.035329e-08] 
Layer 'fc7' weights[0]: 7.491119e-03 [1.377490e-07] 
Layer 'fc7' biases: 9.998536e-01 [1.230912e-07] 
Layer 'fc8' weights[0]: 5.958503e-04 [6.597218e-06] 
Layer 'fc8' biases: 1.543414e-01 [1.553294e-04] 
Train error last 27 batches: 0.635783
-------------------------------------------------------
Not saving because 0.643605 > 0.627087 (334.9: -0.00%)
======================================================= (5.064 sec)
349.6... logprob:  0.611423, 0.296875 (0.670 sec)
349.7... logprob:  0.643827, 0.343750 (0.664 sec)
349.8... logprob:  0.604832, 0.289062 (0.669 sec)
349.9... logprob:  0.638551, 0.335938 (0.669 sec)
349.10... logprob:  0.597931, 0.281250 (0.668 sec)
349.11... logprob:  0.638903, 0.335938 (0.670 sec)
349.12... logprob:  0.717902, 0.437500 (0.669 sec)
349.13... logprob:  0.657361, 0.359375 (0.666 sec)
349.14... logprob:  0.662977, 0.367188 (0.668 sec)
349.15... logprob:  0.686070, 0.398438 (0.668 sec)
349.16... logprob:  0.627069, 0.320312 (0.665 sec)
349.17... logprob:  0.638511, 0.335938 (0.664 sec)
349.18... logprob:  0.638223, 0.335938 (0.666 sec)
349.19... logprob:  0.632721, 0.328125 (0.667 sec)
349.20... logprob:  0.648869, 0.351562 (0.668 sec)
349.21... logprob:  0.643426, 0.343750 (0.667 sec)
349.22... logprob:  0.628017, 0.320312 (0.667 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643443, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942363e-03 [6.739551e-09] 
Layer 'conv1' biases: 5.280220e-07 [1.352450e-10] 
Layer 'conv2' weights[0]: 7.930180e-03 [6.057632e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.935780e-10] 
Layer 'conv3' weights[0]: 7.927907e-03 [5.273483e-09] 
Layer 'conv3' biases: 4.418118e-06 [1.607869e-09] 
Layer 'conv4' weights[0]: 7.960697e-03 [5.157128e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.009980e-08] 
Layer 'conv5' weights[0]: 7.960055e-03 [5.780909e-08] 
Layer 'conv5' biases: 1.000002e+00 [6.104845e-08] 
Layer 'fc6' weights[0]: 7.556262e-03 [7.416130e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.271466e-09] 
Layer 'fc7' weights[0]: 7.490505e-03 [9.335092e-08] 
Layer 'fc7' biases: 9.998535e-01 [7.553390e-08] 
Layer 'fc8' weights[0]: 5.804895e-04 [4.001474e-06] 
Layer 'fc8' biases: 1.541923e-01 [7.524969e-05] 
Train error last 27 batches: 0.635781
-------------------------------------------------------
Not saving because 0.643443 > 0.627087 (334.9: -0.00%)
======================================================= (5.092 sec)
349.23... logprob:  0.623175, 0.312500 (0.668 sec)
349.24... logprob:  0.577891, 0.242188 (0.665 sec)
349.25... logprob:  0.628187, 0.320312 (0.667 sec)
349.26... logprob:  0.674057, 0.390625 (0.666 sec)
349.27... logprob:  0.628040, 0.320312 (0.667 sec)
350.1... logprob:  0.679493, 0.398438 (0.669 sec)
350.2... logprob:  0.597113, 0.273438 (0.666 sec)
350.3... logprob:  0.653780, 0.359375 (0.666 sec)
350.4... logprob:  0.596726, 0.273438 (0.669 sec)
350.5... logprob:  0.590986, 0.265625 (0.666 sec)
350.6... logprob:  0.611422, 0.296875 (0.668 sec)
350.7... logprob:  0.643827, 0.343750 (0.668 sec)
350.8... logprob:  0.604833, 0.289062 (0.670 sec)
350.9... logprob:  0.638551, 0.335938 (0.669 sec)
350.10... logprob:  0.597934, 0.281250 (0.670 sec)
350.11... logprob:  0.638901, 0.335938 (0.670 sec)
350.12... logprob:  0.717887, 0.437500 (0.667 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.645243, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942292e-03 [6.875915e-09] 
Layer 'conv1' biases: 5.286977e-07 [8.228183e-11] 
Layer 'conv2' weights[0]: 7.930114e-03 [5.253156e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.261485e-10] 
Layer 'conv3' weights[0]: 7.927838e-03 [4.560363e-09] 
Layer 'conv3' biases: 4.421399e-06 [8.164809e-10] 
Layer 'conv4' weights[0]: 7.960629e-03 [4.418075e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.768462e-09] 
Layer 'conv5' weights[0]: 7.960021e-03 [1.076963e-08] 
Layer 'conv5' biases: 1.000001e+00 [1.043406e-08] 
Layer 'fc6' weights[0]: 7.556199e-03 [3.991137e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.172232e-09] 
Layer 'fc7' weights[0]: 7.489847e-03 [4.273874e-08] 
Layer 'fc7' biases: 9.998542e-01 [1.576687e-08] 
Layer 'fc8' weights[0]: 6.315372e-04 [7.431676e-07] 
Layer 'fc8' biases: 1.556416e-01 [2.099416e-07] 
Train error last 27 batches: 0.635780
-------------------------------------------------------
Not saving because 0.645243 > 0.627087 (334.9: -0.00%)
======================================================= (5.176 sec)
350.13... logprob:  0.657356, 0.359375 (0.670 sec)
350.14... logprob:  0.662972, 0.367188 (0.670 sec)
350.15... logprob:  0.686065, 0.398438 (0.667 sec)
350.16... logprob:  0.627069, 0.320312 (0.669 sec)
350.17... logprob:  0.638510, 0.335938 (0.667 sec)
350.18... logprob:  0.638223, 0.335938 (0.669 sec)
350.19... logprob:  0.632720, 0.328125 (0.668 sec)
350.20... logprob:  0.648870, 0.351562 (0.667 sec)
350.21... logprob:  0.643427, 0.343750 (0.667 sec)
350.22... logprob:  0.628015, 0.320312 (0.663 sec)
350.23... logprob:  0.623171, 0.312500 (0.667 sec)
350.24... logprob:  0.577878, 0.242188 (0.667 sec)
350.25... logprob:  0.628185, 0.320312 (0.668 sec)
350.26... logprob:  0.674062, 0.390625 (0.667 sec)
350.27... logprob:  0.628039, 0.320312 (0.668 sec)
351.1... logprob:  0.679497, 0.398438 (0.669 sec)
351.2... logprob:  0.597107, 0.273438 (0.668 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643468, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942229e-03 [6.833301e-09] 
Layer 'conv1' biases: 5.303070e-07 [7.154181e-11] 
Layer 'conv2' weights[0]: 7.930052e-03 [4.982037e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.901306e-10] 
Layer 'conv3' weights[0]: 7.927770e-03 [4.563474e-09] 
Layer 'conv3' biases: 4.436029e-06 [8.125952e-10] 
Layer 'conv4' weights[0]: 7.960555e-03 [4.476910e-09] 
Layer 'conv4' biases: 1.000001e+00 [4.916846e-09] 
Layer 'conv5' weights[0]: 7.959925e-03 [2.885562e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.025562e-08] 
Layer 'fc6' weights[0]: 7.556128e-03 [4.978453e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.021422e-09] 
Layer 'fc7' weights[0]: 7.489249e-03 [5.918168e-08] 
Layer 'fc7' biases: 9.998535e-01 [3.613123e-08] 
Layer 'fc8' weights[0]: 5.854098e-04 [1.910110e-06] 
Layer 'fc8' biases: 1.547654e-01 [5.240266e-05] 
Train error last 27 batches: 0.635778
-------------------------------------------------------
Not saving because 0.643468 > 0.627087 (334.9: -0.00%)
======================================================= (5.131 sec)
351.3... logprob:  0.653781, 0.359375 (0.669 sec)
351.4... logprob:  0.596722, 0.273438 (0.667 sec)
351.5... logprob:  0.590983, 0.265625 (0.670 sec)
351.6... logprob:  0.611422, 0.296875 (0.666 sec)
351.7... logprob:  0.643827, 0.343750 (0.668 sec)
351.8... logprob:  0.604835, 0.289062 (0.669 sec)
351.9... logprob:  0.638549, 0.335938 (0.671 sec)
351.10... logprob:  0.597939, 0.281250 (0.667 sec)
351.11... logprob:  0.638898, 0.335938 (0.668 sec)
351.12... logprob:  0.717867, 0.437500 (0.667 sec)
351.13... logprob:  0.657350, 0.359375 (0.670 sec)
351.14... logprob:  0.662966, 0.367188 (0.670 sec)
351.15... logprob:  0.686058, 0.398438 (0.668 sec)
351.16... logprob:  0.627069, 0.320312 (0.668 sec)
351.17... logprob:  0.638511, 0.335938 (0.667 sec)
351.18... logprob:  0.638223, 0.335938 (0.665 sec)
351.19... logprob:  0.632719, 0.328125 (0.668 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643570, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942167e-03 [6.765278e-09] 
Layer 'conv1' biases: 5.314306e-07 [1.577166e-10] 
Layer 'conv2' weights[0]: 7.929985e-03 [6.604789e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.661357e-10] 
Layer 'conv3' weights[0]: 7.927707e-03 [5.737294e-09] 
Layer 'conv3' biases: 4.444723e-06 [2.091327e-09] 
Layer 'conv4' weights[0]: 7.960491e-03 [5.679749e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.444420e-08] 
Layer 'conv5' weights[0]: 7.959859e-03 [8.269374e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.763623e-08] 
Layer 'fc6' weights[0]: 7.556061e-03 [9.854438e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.929784e-09] 
Layer 'fc7' weights[0]: 7.488600e-03 [1.229232e-07] 
Layer 'fc7' biases: 9.998537e-01 [1.067080e-07] 
Layer 'fc8' weights[0]: 5.931284e-04 [5.700293e-06] 
Layer 'fc8' biases: 1.551874e-01 [1.088643e-04] 
Train error last 27 batches: 0.635777
-------------------------------------------------------
Not saving because 0.643570 > 0.627087 (334.9: -0.00%)
======================================================= (5.075 sec)
351.20... logprob:  0.648871, 0.351562 (0.667 sec)
351.21... logprob:  0.643427, 0.343750 (0.666 sec)
351.22... logprob:  0.628011, 0.320312 (0.668 sec)
351.23... logprob:  0.623167, 0.312500 (0.668 sec)
351.24... logprob:  0.577861, 0.242188 (0.667 sec)
351.25... logprob:  0.628181, 0.320312 (0.668 sec)
351.26... logprob:  0.674068, 0.390625 (0.669 sec)
351.27... logprob:  0.628035, 0.320312 (0.668 sec)
352.1... logprob:  0.679503, 0.398438 (0.669 sec)
352.2... logprob:  0.597101, 0.273438 (0.667 sec)
352.3... logprob:  0.653783, 0.359375 (0.668 sec)
352.4... logprob:  0.596719, 0.273438 (0.669 sec)
352.5... logprob:  0.590982, 0.265625 (0.667 sec)
352.6... logprob:  0.611422, 0.296875 (0.667 sec)
352.7... logprob:  0.643826, 0.343750 (0.665 sec)
352.8... logprob:  0.604839, 0.289062 (0.670 sec)
352.9... logprob:  0.638548, 0.335938 (0.670 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644509, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942097e-03 [6.683111e-09] 
Layer 'conv1' biases: 5.323334e-07 [1.196360e-10] 
Layer 'conv2' weights[0]: 7.929918e-03 [5.815702e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.034600e-10] 
Layer 'conv3' weights[0]: 7.927646e-03 [5.666342e-09] 
Layer 'conv3' biases: 4.450877e-06 [1.857390e-09] 
Layer 'conv4' weights[0]: 7.960432e-03 [5.779868e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.600429e-08] 
Layer 'conv5' weights[0]: 7.959817e-03 [9.172674e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.738648e-08] 
Layer 'fc6' weights[0]: 7.555990e-03 [1.057675e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.820565e-09] 
Layer 'fc7' weights[0]: 7.487912e-03 [1.314062e-07] 
Layer 'fc7' biases: 9.998539e-01 [1.159178e-07] 
Layer 'fc8' weights[0]: 6.192728e-04 [6.247145e-06] 
Layer 'fc8' biases: 1.560308e-01 [1.444265e-04] 
Train error last 27 batches: 0.635776
-------------------------------------------------------
Not saving because 0.644509 > 0.627087 (334.9: -0.00%)
======================================================= (5.065 sec)
352.10... logprob:  0.597945, 0.281250 (0.669 sec)
352.11... logprob:  0.638894, 0.335938 (0.667 sec)
352.12... logprob:  0.717842, 0.437500 (0.669 sec)
352.13... logprob:  0.657342, 0.359375 (0.668 sec)
352.14... logprob:  0.662957, 0.367188 (0.669 sec)
352.15... logprob:  0.686047, 0.398438 (0.668 sec)
352.16... logprob:  0.627069, 0.320312 (0.669 sec)
352.17... logprob:  0.638510, 0.335938 (0.667 sec)
352.18... logprob:  0.638223, 0.335938 (0.671 sec)
352.19... logprob:  0.632719, 0.328125 (0.668 sec)
352.20... logprob:  0.648872, 0.351562 (0.668 sec)
352.21... logprob:  0.643427, 0.343750 (0.667 sec)
352.22... logprob:  0.628008, 0.320312 (0.668 sec)
352.23... logprob:  0.623162, 0.312500 (0.666 sec)
352.24... logprob:  0.577846, 0.242188 (0.667 sec)
352.25... logprob:  0.628177, 0.320312 (0.667 sec)
352.26... logprob:  0.674074, 0.390625 (0.668 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643455, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942026e-03 [6.506288e-09] 
Layer 'conv1' biases: 5.338746e-07 [7.006002e-11] 
Layer 'conv2' weights[0]: 7.929853e-03 [5.007851e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.443123e-10] 
Layer 'conv3' weights[0]: 7.927584e-03 [4.417096e-09] 
Layer 'conv3' biases: 4.464477e-06 [6.175453e-10] 
Layer 'conv4' weights[0]: 7.960371e-03 [4.317943e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.722510e-09] 
Layer 'conv5' weights[0]: 7.959732e-03 [1.082014e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.063493e-08] 
Layer 'fc6' weights[0]: 7.555923e-03 [3.962957e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.057999e-09] 
Layer 'fc7' weights[0]: 7.487304e-03 [4.146339e-08] 
Layer 'fc7' biases: 9.998534e-01 [1.290836e-08] 
Layer 'fc8' weights[0]: 5.828245e-04 [6.513821e-07] 
Layer 'fc8' biases: 1.553823e-01 [2.664707e-05] 
Train error last 27 batches: 0.635773
-------------------------------------------------------
Not saving because 0.643455 > 0.627087 (334.9: -0.00%)
======================================================= (5.183 sec)
352.27... logprob:  0.628033, 0.320312 (0.668 sec)
353.1... logprob:  0.679509, 0.398438 (0.669 sec)
353.2... logprob:  0.597094, 0.273438 (0.670 sec)
353.3... logprob:  0.653783, 0.359375 (0.670 sec)
353.4... logprob:  0.596714, 0.273438 (0.668 sec)
353.5... logprob:  0.590978, 0.265625 (0.669 sec)
353.6... logprob:  0.611422, 0.296875 (0.668 sec)
353.7... logprob:  0.643826, 0.343750 (0.667 sec)
353.8... logprob:  0.604841, 0.289062 (0.668 sec)
353.9... logprob:  0.638547, 0.335938 (0.671 sec)
353.10... logprob:  0.597950, 0.281250 (0.669 sec)
353.11... logprob:  0.638892, 0.335938 (0.669 sec)
353.12... logprob:  0.717821, 0.437500 (0.670 sec)
353.13... logprob:  0.657334, 0.359375 (0.668 sec)
353.14... logprob:  0.662950, 0.367188 (0.668 sec)
353.15... logprob:  0.686039, 0.398438 (0.667 sec)
353.16... logprob:  0.627069, 0.320312 (0.666 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644064, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941958e-03 [6.945506e-09] 
Layer 'conv1' biases: 5.348199e-07 [1.860885e-10] 
Layer 'conv2' weights[0]: 7.929790e-03 [7.234783e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.381094e-10] 
Layer 'conv3' weights[0]: 7.927523e-03 [6.284824e-09] 
Layer 'conv3' biases: 4.470970e-06 [2.573110e-09] 
Layer 'conv4' weights[0]: 7.960308e-03 [6.301337e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.872539e-08] 
Layer 'conv5' weights[0]: 7.959679e-03 [1.071554e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.138223e-07] 
Layer 'fc6' weights[0]: 7.555861e-03 [1.205573e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.152317e-08] 
Layer 'fc7' weights[0]: 7.486653e-03 [1.499160e-07] 
Layer 'fc7' biases: 9.998538e-01 [1.364661e-07] 
Layer 'fc8' weights[0]: 6.094633e-04 [7.351629e-06] 
Layer 'fc8' biases: 1.562543e-01 [1.398757e-04] 
Train error last 27 batches: 0.635771
-------------------------------------------------------
Not saving because 0.644064 > 0.627087 (334.9: -0.00%)
======================================================= (5.056 sec)
353.17... logprob:  0.638510, 0.335938 (0.667 sec)
353.18... logprob:  0.638222, 0.335938 (0.665 sec)
353.19... logprob:  0.632718, 0.328125 (0.665 sec)
353.20... logprob:  0.648873, 0.351562 (0.665 sec)
353.21... logprob:  0.643428, 0.343750 (0.662 sec)
353.22... logprob:  0.628006, 0.320312 (0.665 sec)
353.23... logprob:  0.623158, 0.312500 (0.664 sec)
353.24... logprob:  0.577832, 0.242188 (0.663 sec)
353.25... logprob:  0.628174, 0.320312 (0.663 sec)
353.26... logprob:  0.674079, 0.390625 (0.663 sec)
353.27... logprob:  0.628031, 0.320312 (0.666 sec)
354.1... logprob:  0.679514, 0.398438 (0.665 sec)
354.2... logprob:  0.597089, 0.273438 (0.664 sec)
354.3... logprob:  0.653785, 0.359375 (0.666 sec)
354.4... logprob:  0.596710, 0.273438 (0.664 sec)
354.5... logprob:  0.590975, 0.265625 (0.666 sec)
354.6... logprob:  0.611422, 0.296875 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643769, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941895e-03 [7.340346e-09] 
Layer 'conv1' biases: 5.360512e-07 [1.637642e-10] 
Layer 'conv2' weights[0]: 7.929730e-03 [6.289570e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.710485e-10] 
Layer 'conv3' weights[0]: 7.927454e-03 [6.084581e-09] 
Layer 'conv3' biases: 4.481182e-06 [2.238380e-09] 
Layer 'conv4' weights[0]: 7.960241e-03 [6.167505e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.952138e-08] 
Layer 'conv5' weights[0]: 7.959614e-03 [1.118848e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.187447e-07] 
Layer 'fc6' weights[0]: 7.555800e-03 [1.252384e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.197977e-08] 
Layer 'fc7' weights[0]: 7.485991e-03 [1.556077e-07] 
Layer 'fc7' biases: 9.998537e-01 [1.421219e-07] 
Layer 'fc8' weights[0]: 6.008315e-04 [7.599071e-06] 
Layer 'fc8' biases: 1.562606e-01 [1.774731e-04] 
Train error last 27 batches: 0.635770
-------------------------------------------------------
Not saving because 0.643769 > 0.627087 (334.9: -0.00%)
======================================================= (5.062 sec)
354.7... logprob:  0.643826, 0.343750 (0.666 sec)
354.8... logprob:  0.604843, 0.289062 (0.667 sec)
354.9... logprob:  0.638545, 0.335938 (0.666 sec)
354.10... logprob:  0.597955, 0.281250 (0.667 sec)
354.11... logprob:  0.638889, 0.335938 (0.667 sec)
354.12... logprob:  0.717799, 0.437500 (0.668 sec)
354.13... logprob:  0.657327, 0.359375 (0.666 sec)
354.14... logprob:  0.662943, 0.367188 (0.667 sec)
354.15... logprob:  0.686030, 0.398438 (0.666 sec)
354.16... logprob:  0.627070, 0.320312 (0.666 sec)
354.17... logprob:  0.638510, 0.335938 (0.666 sec)
354.18... logprob:  0.638222, 0.335938 (0.665 sec)
354.19... logprob:  0.632718, 0.328125 (0.664 sec)
354.20... logprob:  0.648874, 0.351562 (0.664 sec)
354.21... logprob:  0.643428, 0.343750 (0.664 sec)
354.22... logprob:  0.628003, 0.320312 (0.664 sec)
354.23... logprob:  0.623153, 0.312500 (0.665 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643442, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941824e-03 [6.342988e-09] 
Layer 'conv1' biases: 5.374851e-07 [1.063227e-10] 
Layer 'conv2' weights[0]: 7.929676e-03 [5.344097e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.163386e-10] 
Layer 'conv3' weights[0]: 7.927384e-03 [4.742375e-09] 
Layer 'conv3' biases: 4.493355e-06 [1.084223e-09] 
Layer 'conv4' weights[0]: 7.960181e-03 [4.616797e-09] 
Layer 'conv4' biases: 1.000001e+00 [5.692856e-09] 
Layer 'conv5' weights[0]: 7.959546e-03 [3.267971e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.433630e-08] 
Layer 'fc6' weights[0]: 7.555731e-03 [5.275369e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.558997e-09] 
Layer 'fc7' weights[0]: 7.485358e-03 [6.432104e-08] 
Layer 'fc7' biases: 9.998534e-01 [4.310182e-08] 
Layer 'fc8' weights[0]: 5.771242e-04 [2.267184e-06] 
Layer 'fc8' biases: 1.558989e-01 [3.732920e-05] 
Train error last 27 batches: 0.635768
-------------------------------------------------------
Not saving because 0.643442 > 0.627087 (334.9: -0.00%)
======================================================= (5.117 sec)
354.24... logprob:  0.577816, 0.242188 (0.664 sec)
354.25... logprob:  0.628172, 0.320312 (0.666 sec)
354.26... logprob:  0.674084, 0.390625 (0.664 sec)
354.27... logprob:  0.628028, 0.320312 (0.664 sec)
355.1... logprob:  0.679519, 0.398438 (0.668 sec)
355.2... logprob:  0.597082, 0.273438 (0.665 sec)
355.3... logprob:  0.653786, 0.359375 (0.666 sec)
355.4... logprob:  0.596707, 0.273438 (0.666 sec)
355.5... logprob:  0.590973, 0.265625 (0.666 sec)
355.6... logprob:  0.611421, 0.296875 (0.665 sec)
355.7... logprob:  0.643824, 0.343750 (0.667 sec)
355.8... logprob:  0.604846, 0.289062 (0.670 sec)
355.9... logprob:  0.638544, 0.335938 (0.669 sec)
355.10... logprob:  0.597960, 0.281250 (0.670 sec)
355.11... logprob:  0.638886, 0.335938 (0.670 sec)
355.12... logprob:  0.717778, 0.437500 (0.664 sec)
355.13... logprob:  0.657320, 0.359375 (0.670 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.645047, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941748e-03 [6.528417e-09] 
Layer 'conv1' biases: 5.381723e-07 [1.014672e-10] 
Layer 'conv2' weights[0]: 7.929614e-03 [5.459820e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.668513e-10] 
Layer 'conv3' weights[0]: 7.927322e-03 [4.794881e-09] 
Layer 'conv3' biases: 4.496848e-06 [1.275423e-09] 
Layer 'conv4' weights[0]: 7.960115e-03 [4.708192e-09] 
Layer 'conv4' biases: 1.000001e+00 [7.111503e-09] 
Layer 'conv5' weights[0]: 7.959486e-03 [4.071597e-08] 
Layer 'conv5' biases: 1.000002e+00 [4.302022e-08] 
Layer 'fc6' weights[0]: 7.555667e-03 [5.815857e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.338402e-09] 
Layer 'fc7' weights[0]: 7.484694e-03 [7.229163e-08] 
Layer 'fc7' biases: 9.998541e-01 [5.212647e-08] 
Layer 'fc8' weights[0]: 6.270117e-04 [2.793113e-06] 
Layer 'fc8' biases: 1.573354e-01 [4.306639e-05] 
Train error last 27 batches: 0.635767
-------------------------------------------------------
Not saving because 0.645047 > 0.627087 (334.9: -0.00%)
======================================================= (5.113 sec)
355.14... logprob:  0.662936, 0.367188 (0.666 sec)
355.15... logprob:  0.686022, 0.398438 (0.665 sec)
355.16... logprob:  0.627070, 0.320312 (0.665 sec)
355.17... logprob:  0.638511, 0.335938 (0.667 sec)
355.18... logprob:  0.638223, 0.335938 (0.664 sec)
355.19... logprob:  0.632718, 0.328125 (0.665 sec)
355.20... logprob:  0.648876, 0.351562 (0.665 sec)
355.21... logprob:  0.643428, 0.343750 (0.661 sec)
355.22... logprob:  0.628000, 0.320312 (0.665 sec)
355.23... logprob:  0.623149, 0.312500 (0.664 sec)
355.24... logprob:  0.577799, 0.242188 (0.662 sec)
355.25... logprob:  0.628168, 0.320312 (0.666 sec)
355.26... logprob:  0.674091, 0.390625 (0.665 sec)
355.27... logprob:  0.628025, 0.320312 (0.666 sec)
356.1... logprob:  0.679525, 0.398438 (0.666 sec)
356.2... logprob:  0.597076, 0.273438 (0.666 sec)
356.3... logprob:  0.653788, 0.359375 (0.667 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643474, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941684e-03 [6.712833e-09] 
Layer 'conv1' biases: 5.397477e-07 [6.485531e-11] 
Layer 'conv2' weights[0]: 7.929560e-03 [4.979383e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.555822e-10] 
Layer 'conv3' weights[0]: 7.927257e-03 [4.455137e-09] 
Layer 'conv3' biases: 4.511039e-06 [6.461447e-10] 
Layer 'conv4' weights[0]: 7.960044e-03 [4.339482e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.188597e-09] 
Layer 'conv5' weights[0]: 7.959407e-03 [1.366548e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.387638e-08] 
Layer 'fc6' weights[0]: 7.555607e-03 [4.077991e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.371853e-09] 
Layer 'fc7' weights[0]: 7.484100e-03 [4.380228e-08] 
Layer 'fc7' biases: 9.998534e-01 [1.658548e-08] 
Layer 'fc8' weights[0]: 5.845927e-04 [8.745483e-07] 
Layer 'fc8' biases: 1.565297e-01 [2.733242e-05] 
Train error last 27 batches: 0.635765
-------------------------------------------------------
Not saving because 0.643474 > 0.627087 (334.9: -0.00%)
======================================================= (5.173 sec)
356.4... logprob:  0.596703, 0.273438 (0.665 sec)
356.5... logprob:  0.590971, 0.265625 (0.665 sec)
356.6... logprob:  0.611422, 0.296875 (0.666 sec)
356.7... logprob:  0.643824, 0.343750 (0.664 sec)
356.8... logprob:  0.604850, 0.289062 (0.666 sec)
356.9... logprob:  0.638543, 0.335938 (0.664 sec)
356.10... logprob:  0.597967, 0.281250 (0.667 sec)
356.11... logprob:  0.638882, 0.335938 (0.667 sec)
356.12... logprob:  0.717750, 0.437500 (0.665 sec)
356.13... logprob:  0.657310, 0.359375 (0.666 sec)
356.14... logprob:  0.662927, 0.367188 (0.666 sec)
356.15... logprob:  0.686010, 0.398438 (0.663 sec)
356.16... logprob:  0.627070, 0.320312 (0.664 sec)
356.17... logprob:  0.638510, 0.335938 (0.665 sec)
356.18... logprob:  0.638222, 0.335938 (0.665 sec)
356.19... logprob:  0.632717, 0.328125 (0.664 sec)
356.20... logprob:  0.648877, 0.351562 (0.662 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643498, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941627e-03 [6.810105e-09] 
Layer 'conv1' biases: 5.409201e-07 [1.626530e-10] 
Layer 'conv2' weights[0]: 7.929490e-03 [6.540571e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.758288e-10] 
Layer 'conv3' weights[0]: 7.927182e-03 [5.724021e-09] 
Layer 'conv3' biases: 4.520383e-06 [2.106208e-09] 
Layer 'conv4' weights[0]: 7.959971e-03 [5.657162e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.467646e-08] 
Layer 'conv5' weights[0]: 7.959343e-03 [8.374463e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.866432e-08] 
Layer 'fc6' weights[0]: 7.555538e-03 [9.954537e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.073210e-09] 
Layer 'fc7' weights[0]: 7.483450e-03 [1.243678e-07] 
Layer 'fc7' biases: 9.998534e-01 [1.084365e-07] 
Layer 'fc8' weights[0]: 5.865776e-04 [5.764407e-06] 
Layer 'fc8' biases: 1.568119e-01 [1.130814e-04] 
Train error last 27 batches: 0.635763
-------------------------------------------------------
Not saving because 0.643498 > 0.627087 (334.9: -0.00%)
======================================================= (5.058 sec)
356.21... logprob:  0.643429, 0.343750 (0.663 sec)
356.22... logprob:  0.627997, 0.320312 (0.665 sec)
356.23... logprob:  0.623144, 0.312500 (0.663 sec)
356.24... logprob:  0.577784, 0.242188 (0.665 sec)
356.25... logprob:  0.628164, 0.320312 (0.665 sec)
356.26... logprob:  0.674098, 0.390625 (0.664 sec)
356.27... logprob:  0.628023, 0.320312 (0.665 sec)
357.1... logprob:  0.679532, 0.398438 (0.666 sec)
357.2... logprob:  0.597068, 0.273438 (0.665 sec)
357.3... logprob:  0.653790, 0.359375 (0.666 sec)
357.4... logprob:  0.596697, 0.273438 (0.666 sec)
357.5... logprob:  0.590966, 0.265625 (0.666 sec)
357.6... logprob:  0.611421, 0.296875 (0.666 sec)
357.7... logprob:  0.643824, 0.343750 (0.665 sec)
357.8... logprob:  0.604851, 0.289062 (0.667 sec)
357.9... logprob:  0.638542, 0.335938 (0.667 sec)
357.10... logprob:  0.597970, 0.281250 (0.665 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644891, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941557e-03 [7.030807e-09] 
Layer 'conv1' biases: 5.417218e-07 [1.442028e-10] 
Layer 'conv2' weights[0]: 7.929425e-03 [6.261066e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.430666e-10] 
Layer 'conv3' weights[0]: 7.927111e-03 [6.095640e-09] 
Layer 'conv3' biases: 4.525144e-06 [2.228493e-09] 
Layer 'conv4' weights[0]: 7.959904e-03 [6.263423e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.945482e-08] 
Layer 'conv5' weights[0]: 7.959292e-03 [1.111936e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.181049e-07] 
Layer 'fc6' weights[0]: 7.555475e-03 [1.241913e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.188600e-08] 
Layer 'fc7' weights[0]: 7.482783e-03 [1.529670e-07] 
Layer 'fc7' biases: 9.998540e-01 [1.393048e-07] 
Layer 'fc8' weights[0]: 6.240112e-04 [7.531085e-06] 
Layer 'fc8' biases: 1.579321e-01 [1.706765e-04] 
Train error last 27 batches: 0.635762
-------------------------------------------------------
Not saving because 0.644891 > 0.627087 (334.9: -0.00%)
======================================================= (5.063 sec)
357.11... logprob:  0.638880, 0.335938 (0.666 sec)
357.12... logprob:  0.717732, 0.437500 (0.665 sec)
357.13... logprob:  0.657305, 0.359375 (0.666 sec)
357.14... logprob:  0.662920, 0.367188 (0.666 sec)
357.15... logprob:  0.686002, 0.398438 (0.664 sec)
357.16... logprob:  0.627071, 0.320312 (0.663 sec)
357.17... logprob:  0.638510, 0.335938 (0.666 sec)
357.18... logprob:  0.638223, 0.335938 (0.665 sec)
357.19... logprob:  0.632717, 0.328125 (0.665 sec)
357.20... logprob:  0.648878, 0.351562 (0.664 sec)
357.21... logprob:  0.643430, 0.343750 (0.665 sec)
357.22... logprob:  0.627995, 0.320312 (0.663 sec)
357.23... logprob:  0.623140, 0.312500 (0.663 sec)
357.24... logprob:  0.577771, 0.242188 (0.665 sec)
357.25... logprob:  0.628162, 0.320312 (0.664 sec)
357.26... logprob:  0.674102, 0.390625 (0.665 sec)
357.27... logprob:  0.628020, 0.320312 (0.666 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643464, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941494e-03 [6.614637e-09] 
Layer 'conv1' biases: 5.433044e-07 [6.983473e-11] 
Layer 'conv2' weights[0]: 7.929352e-03 [4.903378e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.618371e-10] 
Layer 'conv3' weights[0]: 7.927044e-03 [4.460854e-09] 
Layer 'conv3' biases: 4.539321e-06 [7.143407e-10] 
Layer 'conv4' weights[0]: 7.959848e-03 [4.390342e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.916797e-09] 
Layer 'conv5' weights[0]: 7.959214e-03 [2.258147e-08] 
Layer 'conv5' biases: 1.000002e+00 [2.350297e-08] 
Layer 'fc6' weights[0]: 7.555411e-03 [4.567227e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.333261e-09] 
Layer 'fc7' weights[0]: 7.482146e-03 [5.227113e-08] 
Layer 'fc7' biases: 9.998533e-01 [2.799140e-08] 
Layer 'fc8' weights[0]: 5.826203e-04 [1.456170e-06] 
Layer 'fc8' biases: 1.571599e-01 [4.435138e-05] 
Train error last 27 batches: 0.635760
-------------------------------------------------------
Not saving because 0.643464 > 0.627087 (334.9: -0.00%)
======================================================= (5.147 sec)
358.1... logprob:  0.679536, 0.398438 (0.666 sec)
358.2... logprob:  0.597064, 0.273438 (0.666 sec)
358.3... logprob:  0.653790, 0.359375 (0.665 sec)
358.4... logprob:  0.596694, 0.273438 (0.665 sec)
358.5... logprob:  0.590966, 0.265625 (0.666 sec)
358.6... logprob:  0.611421, 0.296875 (0.666 sec)
358.7... logprob:  0.643823, 0.343750 (0.666 sec)
358.8... logprob:  0.604854, 0.289062 (0.667 sec)
358.9... logprob:  0.638540, 0.335938 (0.666 sec)
358.10... logprob:  0.597977, 0.281250 (0.667 sec)
358.11... logprob:  0.638877, 0.335938 (0.666 sec)
358.12... logprob:  0.717709, 0.437500 (0.665 sec)
358.13... logprob:  0.657297, 0.359375 (0.665 sec)
358.14... logprob:  0.662913, 0.367188 (0.666 sec)
358.15... logprob:  0.685992, 0.398438 (0.665 sec)
358.16... logprob:  0.627070, 0.320312 (0.665 sec)
358.17... logprob:  0.638510, 0.335938 (0.665 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643839, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941419e-03 [6.439347e-09] 
Layer 'conv1' biases: 5.442970e-07 [1.715645e-10] 
Layer 'conv2' weights[0]: 7.929292e-03 [6.899709e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.774918e-10] 
Layer 'conv3' weights[0]: 7.926980e-03 [6.053941e-09] 
Layer 'conv3' biases: 4.546718e-06 [2.384275e-09] 
Layer 'conv4' weights[0]: 7.959786e-03 [6.094927e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.776075e-08] 
Layer 'conv5' weights[0]: 7.959153e-03 [1.015727e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.077356e-07] 
Layer 'fc6' weights[0]: 7.555345e-03 [1.151541e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.092985e-08] 
Layer 'fc7' weights[0]: 7.481508e-03 [1.432126e-07] 
Layer 'fc7' biases: 9.998537e-01 [1.293449e-07] 
Layer 'fc8' weights[0]: 6.015980e-04 [6.945753e-06] 
Layer 'fc8' biases: 1.578505e-01 [1.340821e-04] 
Train error last 27 batches: 0.635758
-------------------------------------------------------
Not saving because 0.643839 > 0.627087 (334.9: -0.00%)
======================================================= (5.052 sec)
358.18... logprob:  0.638222, 0.335938 (0.661 sec)
358.19... logprob:  0.632716, 0.328125 (0.665 sec)
358.20... logprob:  0.648878, 0.351562 (0.664 sec)
358.21... logprob:  0.643430, 0.343750 (0.664 sec)
358.22... logprob:  0.627993, 0.320312 (0.664 sec)
358.23... logprob:  0.623137, 0.312500 (0.664 sec)
358.24... logprob:  0.577757, 0.242188 (0.663 sec)
358.25... logprob:  0.628159, 0.320312 (0.662 sec)
358.26... logprob:  0.674108, 0.390625 (0.663 sec)
358.27... logprob:  0.628018, 0.320312 (0.666 sec)
359.1... logprob:  0.679542, 0.398438 (0.661 sec)
359.2... logprob:  0.597056, 0.273438 (0.664 sec)
359.3... logprob:  0.653792, 0.359375 (0.666 sec)
359.4... logprob:  0.596689, 0.273438 (0.665 sec)
359.5... logprob:  0.590961, 0.265625 (0.665 sec)
359.6... logprob:  0.611420, 0.296875 (0.665 sec)
359.7... logprob:  0.643823, 0.343750 (0.665 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643947, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941344e-03 [6.814337e-09] 
Layer 'conv1' biases: 5.454080e-07 [1.275089e-10] 
Layer 'conv2' weights[0]: 7.929223e-03 [5.816983e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.176478e-10] 
Layer 'conv3' weights[0]: 7.926917e-03 [5.633624e-09] 
Layer 'conv3' biases: 4.555700e-06 [1.872269e-09] 
Layer 'conv4' weights[0]: 7.959730e-03 [5.708366e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.605167e-08] 
Layer 'conv5' weights[0]: 7.959087e-03 [9.208689e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.764586e-08] 
Layer 'fc6' weights[0]: 7.555277e-03 [1.059255e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.841321e-09] 
Layer 'fc7' weights[0]: 7.480882e-03 [1.317342e-07] 
Layer 'fc7' biases: 9.998538e-01 [1.164722e-07] 
Layer 'fc8' weights[0]: 6.045474e-04 [6.206770e-06] 
Layer 'fc8' biases: 1.581339e-01 [1.470859e-04] 
Train error last 27 batches: 0.635757
-------------------------------------------------------
Not saving because 0.643947 > 0.627087 (334.9: -0.00%)
======================================================= (5.072 sec)
359.8... logprob:  0.604855, 0.289062 (0.665 sec)
359.9... logprob:  0.638540, 0.335938 (0.663 sec)
359.10... logprob:  0.597980, 0.281250 (0.666 sec)
359.11... logprob:  0.638875, 0.335938 (0.666 sec)
359.12... logprob:  0.717691, 0.437500 (0.667 sec)
359.13... logprob:  0.657290, 0.359375 (0.666 sec)
359.14... logprob:  0.662907, 0.367188 (0.665 sec)
359.15... logprob:  0.685986, 0.398438 (0.663 sec)
359.16... logprob:  0.627071, 0.320312 (0.664 sec)
359.17... logprob:  0.638510, 0.335938 (0.666 sec)
359.18... logprob:  0.638222, 0.335938 (0.664 sec)
359.19... logprob:  0.632715, 0.328125 (0.662 sec)
359.20... logprob:  0.648880, 0.351562 (0.664 sec)
359.21... logprob:  0.643430, 0.343750 (0.664 sec)
359.22... logprob:  0.627989, 0.320312 (0.661 sec)
359.23... logprob:  0.623132, 0.312500 (0.664 sec)
359.24... logprob:  0.577743, 0.242188 (0.665 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643443, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941277e-03 [6.499610e-09] 
Layer 'conv1' biases: 5.468782e-07 [5.965010e-11] 
Layer 'conv2' weights[0]: 7.929160e-03 [4.865933e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.034047e-10] 
Layer 'conv3' weights[0]: 7.926851e-03 [4.532151e-09] 
Layer 'conv3' biases: 4.568275e-06 [8.548910e-10] 
Layer 'conv4' weights[0]: 7.959664e-03 [4.476922e-09] 
Layer 'conv4' biases: 1.000001e+00 [6.169493e-09] 
Layer 'conv5' weights[0]: 7.959023e-03 [3.465521e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.640993e-08] 
Layer 'fc6' weights[0]: 7.555201e-03 [5.375650e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.677302e-09] 
Layer 'fc7' weights[0]: 7.480218e-03 [6.529503e-08] 
Layer 'fc7' biases: 9.998532e-01 [4.397689e-08] 
Layer 'fc8' weights[0]: 5.776855e-04 [2.287991e-06] 
Layer 'fc8' biases: 1.576957e-01 [6.781011e-05] 
Train error last 27 batches: 0.635755
-------------------------------------------------------
Not saving because 0.643443 > 0.627087 (334.9: -0.00%)
======================================================= (5.115 sec)
359.25... logprob:  0.628156, 0.320312 (0.662 sec)
359.26... logprob:  0.674112, 0.390625 (0.663 sec)
359.27... logprob:  0.628016, 0.320312 (0.666 sec)
360.1... logprob:  0.679546, 0.398438 (0.663 sec)
360.2... logprob:  0.597051, 0.273438 (0.665 sec)
360.3... logprob:  0.653793, 0.359375 (0.665 sec)
360.4... logprob:  0.596686, 0.273438 (0.662 sec)
360.5... logprob:  0.590959, 0.265625 (0.665 sec)
360.6... logprob:  0.611420, 0.296875 (0.666 sec)
360.7... logprob:  0.643823, 0.343750 (0.671 sec)
360.8... logprob:  0.604858, 0.289062 (0.672 sec)
360.9... logprob:  0.638539, 0.335938 (0.669 sec)
360.10... logprob:  0.597986, 0.281250 (0.666 sec)
360.11... logprob:  0.638872, 0.335938 (0.670 sec)
360.12... logprob:  0.717667, 0.437500 (0.673 sec)
360.13... logprob:  0.657283, 0.359375 (0.669 sec)
360.14... logprob:  0.662898, 0.367188 (0.670 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644750, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941214e-03 [6.745215e-09] 
Layer 'conv1' biases: 5.476375e-07 [1.515894e-10] 
Layer 'conv2' weights[0]: 7.929096e-03 [6.253936e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.821984e-10] 
Layer 'conv3' weights[0]: 7.926786e-03 [5.458912e-09] 
Layer 'conv3' biases: 4.572639e-06 [1.883650e-09] 
Layer 'conv4' weights[0]: 7.959597e-03 [5.417004e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.255098e-08] 
Layer 'conv5' weights[0]: 7.958964e-03 [7.201741e-08] 
Layer 'conv5' biases: 1.000002e+00 [7.639209e-08] 
Layer 'fc6' weights[0]: 7.555141e-03 [8.714799e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.705059e-09] 
Layer 'fc7' weights[0]: 7.479526e-03 [1.085714e-07] 
Layer 'fc7' biases: 9.998538e-01 [9.120684e-08] 
Layer 'fc8' weights[0]: 6.207002e-04 [4.897616e-06] 
Layer 'fc8' biases: 1.589699e-01 [8.823385e-05] 
Train error last 27 batches: 0.635753
-------------------------------------------------------
Not saving because 0.644750 > 0.627087 (334.9: -0.00%)
======================================================= (5.106 sec)
360.15... logprob:  0.685976, 0.398438 (0.674 sec)
360.16... logprob:  0.627070, 0.320312 (0.674 sec)
360.17... logprob:  0.638510, 0.335938 (0.674 sec)
360.18... logprob:  0.638223, 0.335938 (0.676 sec)
360.19... logprob:  0.632716, 0.328125 (0.673 sec)
360.20... logprob:  0.648881, 0.351562 (0.679 sec)
360.21... logprob:  0.643431, 0.343750 (0.681 sec)
360.22... logprob:  0.627987, 0.320312 (0.672 sec)
360.23... logprob:  0.623127, 0.312500 (0.674 sec)
360.24... logprob:  0.577725, 0.242188 (0.673 sec)
360.25... logprob:  0.628152, 0.320312 (0.672 sec)
360.26... logprob:  0.674119, 0.390625 (0.671 sec)
360.27... logprob:  0.628014, 0.320312 (0.675 sec)
361.1... logprob:  0.679553, 0.398438 (0.677 sec)
361.2... logprob:  0.597044, 0.273438 (0.677 sec)
361.3... logprob:  0.653795, 0.359375 (0.674 sec)
361.4... logprob:  0.596681, 0.273438 (0.675 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643510, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941152e-03 [6.846259e-09] 
Layer 'conv1' biases: 5.491228e-07 [8.911901e-11] 
Layer 'conv2' weights[0]: 7.929027e-03 [5.294742e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.654135e-10] 
Layer 'conv3' weights[0]: 7.926722e-03 [4.964838e-09] 
Layer 'conv3' biases: 4.585910e-06 [1.227583e-09] 
Layer 'conv4' weights[0]: 7.959537e-03 [4.929530e-09] 
Layer 'conv4' biases: 1.000001e+00 [9.347846e-09] 
Layer 'conv5' weights[0]: 7.958901e-03 [5.407741e-08] 
Layer 'conv5' biases: 1.000002e+00 [5.703944e-08] 
Layer 'fc6' weights[0]: 7.555079e-03 [6.981162e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.739018e-09] 
Layer 'fc7' weights[0]: 7.478928e-03 [8.651783e-08] 
Layer 'fc7' biases: 9.998534e-01 [6.771661e-08] 
Layer 'fc8' weights[0]: 5.862075e-04 [3.596954e-06] 
Layer 'fc8' biases: 1.583424e-01 [9.026272e-05] 
Train error last 27 batches: 0.635752
-------------------------------------------------------
Not saving because 0.643510 > 0.627087 (334.9: -0.00%)
======================================================= (5.148 sec)
361.5... logprob:  0.590957, 0.265625 (0.673 sec)
361.6... logprob:  0.611420, 0.296875 (0.676 sec)
361.7... logprob:  0.643822, 0.343750 (0.678 sec)
361.8... logprob:  0.604862, 0.289062 (0.675 sec)
361.9... logprob:  0.638538, 0.335938 (0.672 sec)
361.10... logprob:  0.597992, 0.281250 (0.676 sec)
361.11... logprob:  0.638869, 0.335938 (0.668 sec)
361.12... logprob:  0.717642, 0.437500 (0.672 sec)
361.13... logprob:  0.657275, 0.359375 (0.677 sec)
361.14... logprob:  0.662890, 0.367188 (0.676 sec)
361.15... logprob:  0.685966, 0.398438 (0.674 sec)
361.16... logprob:  0.627071, 0.320312 (0.676 sec)
361.17... logprob:  0.638510, 0.335938 (0.676 sec)
361.18... logprob:  0.638222, 0.335938 (0.677 sec)
361.19... logprob:  0.632715, 0.328125 (0.677 sec)
361.20... logprob:  0.648882, 0.351562 (0.679 sec)
361.21... logprob:  0.643431, 0.343750 (0.685 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643458, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941093e-03 [6.850499e-09] 
Layer 'conv1' biases: 5.503812e-07 [1.555764e-10] 
Layer 'conv2' weights[0]: 7.928956e-03 [6.517779e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.420539e-10] 
Layer 'conv3' weights[0]: 7.926657e-03 [5.682110e-09] 
Layer 'conv3' biases: 4.596212e-06 [2.023852e-09] 
Layer 'conv4' weights[0]: 7.959467e-03 [5.597915e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.376814e-08] 
Layer 'conv5' weights[0]: 7.958833e-03 [7.816137e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.268895e-08] 
Layer 'fc6' weights[0]: 7.555009e-03 [9.457218e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.481498e-09] 
Layer 'fc7' weights[0]: 7.478297e-03 [1.183571e-07] 
Layer 'fc7' biases: 9.998533e-01 [1.016013e-07] 
Layer 'fc8' weights[0]: 5.805226e-04 [5.353274e-06] 
Layer 'fc8' biases: 1.584286e-01 [1.067093e-04] 
Train error last 27 batches: 0.635750
-------------------------------------------------------
Not saving because 0.643458 > 0.627087 (334.9: -0.00%)
======================================================= (5.124 sec)
361.22... logprob:  0.627984, 0.320312 (0.678 sec)
361.23... logprob:  0.623123, 0.312500 (0.679 sec)
361.24... logprob:  0.577712, 0.242188 (0.678 sec)
361.25... logprob:  0.628148, 0.320312 (0.680 sec)
361.26... logprob:  0.674125, 0.390625 (0.678 sec)
361.27... logprob:  0.628011, 0.320312 (0.679 sec)
362.1... logprob:  0.679558, 0.398438 (0.681 sec)
362.2... logprob:  0.597038, 0.273438 (0.679 sec)
362.3... logprob:  0.653795, 0.359375 (0.679 sec)
362.4... logprob:  0.596677, 0.273438 (0.682 sec)
362.5... logprob:  0.590953, 0.265625 (0.682 sec)
362.6... logprob:  0.611419, 0.296875 (0.682 sec)
362.7... logprob:  0.643822, 0.343750 (0.682 sec)
362.8... logprob:  0.604863, 0.289062 (0.681 sec)
362.9... logprob:  0.638536, 0.335938 (0.682 sec)
362.10... logprob:  0.597996, 0.281250 (0.683 sec)
362.11... logprob:  0.638866, 0.335938 (0.681 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.645227, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941027e-03 [6.797335e-09] 
Layer 'conv1' biases: 5.510913e-07 [1.175636e-10] 
Layer 'conv2' weights[0]: 7.928883e-03 [5.729522e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.718909e-10] 
Layer 'conv3' weights[0]: 7.926588e-03 [5.567987e-09] 
Layer 'conv3' biases: 4.599899e-06 [1.794725e-09] 
Layer 'conv4' weights[0]: 7.959391e-03 [5.665615e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.532687e-08] 
Layer 'conv5' weights[0]: 7.958780e-03 [8.772642e-08] 
Layer 'conv5' biases: 1.000001e+00 [9.332188e-08] 
Layer 'fc6' weights[0]: 7.554934e-03 [1.018605e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.342550e-09] 
Layer 'fc7' weights[0]: 7.477623e-03 [1.254003e-07] 
Layer 'fc7' biases: 9.998539e-01 [1.087638e-07] 
Layer 'fc8' weights[0]: 6.273011e-04 [5.892350e-06] 
Layer 'fc8' biases: 1.597848e-01 [1.362483e-04] 
Train error last 27 batches: 0.635749
-------------------------------------------------------
Not saving because 0.645227 > 0.627087 (334.9: -0.00%)
======================================================= (5.172 sec)
362.12... logprob:  0.717625, 0.437500 (0.684 sec)
362.13... logprob:  0.657269, 0.359375 (0.681 sec)
362.14... logprob:  0.662884, 0.367188 (0.716 sec)
362.15... logprob:  0.685959, 0.398438 (0.678 sec)
362.16... logprob:  0.627071, 0.320312 (0.680 sec)
362.17... logprob:  0.638509, 0.335938 (0.673 sec)
362.18... logprob:  0.638223, 0.335938 (0.675 sec)
362.19... logprob:  0.632715, 0.328125 (0.676 sec)
362.20... logprob:  0.648883, 0.351562 (0.670 sec)
362.21... logprob:  0.643431, 0.343750 (0.670 sec)
362.22... logprob:  0.627982, 0.320312 (0.674 sec)
362.23... logprob:  0.623119, 0.312500 (0.674 sec)
362.24... logprob:  0.577697, 0.242188 (0.675 sec)
362.25... logprob:  0.628146, 0.320312 (0.676 sec)
362.26... logprob:  0.674130, 0.390625 (0.672 sec)
362.27... logprob:  0.628009, 0.320312 (0.672 sec)
363.1... logprob:  0.679563, 0.398438 (0.676 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643458, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940954e-03 [6.666087e-09] 
Layer 'conv1' biases: 5.527210e-07 [8.218287e-11] 
Layer 'conv2' weights[0]: 7.928810e-03 [5.145538e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.282849e-10] 
Layer 'conv3' weights[0]: 7.926526e-03 [4.489662e-09] 
Layer 'conv3' biases: 4.614784e-06 [8.289801e-10] 
Layer 'conv4' weights[0]: 7.959323e-03 [4.391775e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.154979e-09] 
Layer 'conv5' weights[0]: 7.958695e-03 [1.786670e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.837687e-08] 
Layer 'fc6' weights[0]: 7.554869e-03 [4.344819e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.974318e-09] 
Layer 'fc7' weights[0]: 7.476995e-03 [4.910980e-08] 
Layer 'fc7' biases: 9.998533e-01 [2.463740e-08] 
Layer 'fc8' weights[0]: 5.801502e-04 [1.240736e-06] 
Layer 'fc8' biases: 1.588600e-01 [1.865195e-05] 
Train error last 27 batches: 0.635747
-------------------------------------------------------
Not saving because 0.643458 > 0.627087 (334.9: -0.00%)
======================================================= (5.227 sec)
363.2... logprob:  0.597032, 0.273438 (0.677 sec)
363.3... logprob:  0.653797, 0.359375 (0.681 sec)
363.4... logprob:  0.596673, 0.273438 (0.675 sec)
363.5... logprob:  0.590952, 0.265625 (0.680 sec)
363.6... logprob:  0.611420, 0.296875 (0.679 sec)
363.7... logprob:  0.643821, 0.343750 (0.675 sec)
363.8... logprob:  0.604866, 0.289062 (0.675 sec)
363.9... logprob:  0.638535, 0.335938 (0.677 sec)
363.10... logprob:  0.598001, 0.281250 (0.677 sec)
363.11... logprob:  0.638863, 0.335938 (0.678 sec)
363.12... logprob:  0.717603, 0.437500 (0.677 sec)
363.13... logprob:  0.657261, 0.359375 (0.676 sec)
363.14... logprob:  0.662877, 0.367188 (0.677 sec)
363.15... logprob:  0.685951, 0.398438 (0.676 sec)
363.16... logprob:  0.627071, 0.320312 (0.676 sec)
363.17... logprob:  0.638509, 0.335938 (0.673 sec)
363.18... logprob:  0.638223, 0.335938 (0.675 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643681, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940876e-03 [6.512418e-09] 
Layer 'conv1' biases: 5.537669e-07 [1.728352e-10] 
Layer 'conv2' weights[0]: 7.928735e-03 [6.746026e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.408826e-10] 
Layer 'conv3' weights[0]: 7.926459e-03 [5.922449e-09] 
Layer 'conv3' biases: 4.622617e-06 [2.286139e-09] 
Layer 'conv4' weights[0]: 7.959264e-03 [5.926089e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.658797e-08] 
Layer 'conv5' weights[0]: 7.958642e-03 [9.467782e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.003963e-07] 
Layer 'fc6' weights[0]: 7.554804e-03 [1.083162e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.016964e-08] 
Layer 'fc7' weights[0]: 7.476323e-03 [1.346756e-07] 
Layer 'fc7' biases: 9.998534e-01 [1.201425e-07] 
Layer 'fc8' weights[0]: 5.943113e-04 [6.421873e-06] 
Layer 'fc8' biases: 1.594412e-01 [1.257331e-04] 
Train error last 27 batches: 0.635746
-------------------------------------------------------
Not saving because 0.643681 > 0.627087 (334.9: -0.00%)
======================================================= (5.120 sec)
363.19... logprob:  0.632714, 0.328125 (0.677 sec)
363.20... logprob:  0.648885, 0.351562 (0.674 sec)
363.21... logprob:  0.643432, 0.343750 (0.686 sec)
363.22... logprob:  0.627979, 0.320312 (0.687 sec)
363.23... logprob:  0.623114, 0.312500 (0.668 sec)
363.24... logprob:  0.577680, 0.242188 (0.669 sec)
363.25... logprob:  0.628142, 0.320312 (0.669 sec)
363.26... logprob:  0.674137, 0.390625 (0.668 sec)
363.27... logprob:  0.628006, 0.320312 (0.670 sec)
364.1... logprob:  0.679570, 0.398438 (0.669 sec)
364.2... logprob:  0.597025, 0.273438 (0.670 sec)
364.3... logprob:  0.653799, 0.359375 (0.670 sec)
364.4... logprob:  0.596669, 0.273438 (0.669 sec)
364.5... logprob:  0.590949, 0.265625 (0.669 sec)
364.6... logprob:  0.611419, 0.296875 (0.669 sec)
364.7... logprob:  0.643821, 0.343750 (0.667 sec)
364.8... logprob:  0.604869, 0.289062 (0.669 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644206, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940799e-03 [7.134903e-09] 
Layer 'conv1' biases: 5.547660e-07 [1.434578e-10] 
Layer 'conv2' weights[0]: 7.928666e-03 [6.270794e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.451868e-10] 
Layer 'conv3' weights[0]: 7.926394e-03 [6.074895e-09] 
Layer 'conv3' biases: 4.630178e-06 [2.212676e-09] 
Layer 'conv4' weights[0]: 7.959197e-03 [6.201996e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.917232e-08] 
Layer 'conv5' weights[0]: 7.958588e-03 [1.095230e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.162562e-07] 
Layer 'fc6' weights[0]: 7.554735e-03 [1.223527e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.168395e-08] 
Layer 'fc7' weights[0]: 7.475675e-03 [1.509308e-07] 
Layer 'fc7' biases: 9.998536e-01 [1.371558e-07] 
Layer 'fc8' weights[0]: 6.091988e-04 [7.342739e-06] 
Layer 'fc8' biases: 1.600159e-01 [1.716628e-04] 
Train error last 27 batches: 0.635745
-------------------------------------------------------
Not saving because 0.644206 > 0.627087 (334.9: -0.00%)
======================================================= (5.073 sec)
364.9... logprob:  0.638535, 0.335938 (0.667 sec)
364.10... logprob:  0.598008, 0.281250 (0.667 sec)
364.11... logprob:  0.638860, 0.335938 (0.667 sec)
364.12... logprob:  0.717575, 0.437500 (0.667 sec)
364.13... logprob:  0.657253, 0.359375 (0.667 sec)
364.14... logprob:  0.662868, 0.367188 (0.666 sec)
364.15... logprob:  0.685938, 0.398438 (0.664 sec)
364.16... logprob:  0.627071, 0.320312 (0.669 sec)
364.17... logprob:  0.638509, 0.335938 (0.670 sec)
364.18... logprob:  0.638221, 0.335938 (0.665 sec)
364.19... logprob:  0.632714, 0.328125 (0.665 sec)
364.20... logprob:  0.648885, 0.351562 (0.666 sec)
364.21... logprob:  0.643433, 0.343750 (0.665 sec)
364.22... logprob:  0.627977, 0.320312 (0.666 sec)
364.23... logprob:  0.623111, 0.312500 (0.664 sec)
364.24... logprob:  0.577668, 0.242188 (0.666 sec)
364.25... logprob:  0.628140, 0.320312 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643454, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940735e-03 [6.593648e-09] 
Layer 'conv1' biases: 5.562623e-07 [6.925751e-11] 
Layer 'conv2' weights[0]: 7.928603e-03 [4.945149e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.598306e-10] 
Layer 'conv3' weights[0]: 7.926328e-03 [4.656021e-09] 
Layer 'conv3' biases: 4.643167e-06 [1.020861e-09] 
Layer 'conv4' weights[0]: 7.959133e-03 [4.646984e-09] 
Layer 'conv4' biases: 1.000001e+00 [7.915753e-09] 
Layer 'conv5' weights[0]: 7.958516e-03 [4.506065e-08] 
Layer 'conv5' biases: 1.000002e+00 [4.747973e-08] 
Layer 'fc6' weights[0]: 7.554662e-03 [6.202404e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.800407e-09] 
Layer 'fc7' weights[0]: 7.475053e-03 [7.668705e-08] 
Layer 'fc7' biases: 9.998530e-01 [5.718755e-08] 
Layer 'fc8' weights[0]: 5.788661e-04 [2.984619e-06] 
Layer 'fc8' biases: 1.594933e-01 [8.307555e-05] 
Train error last 27 batches: 0.635742
-------------------------------------------------------
Not saving because 0.643454 > 0.627087 (334.9: -0.00%)
======================================================= (5.144 sec)
364.26... logprob:  0.674141, 0.390625 (0.674 sec)
364.27... logprob:  0.628005, 0.320312 (0.710 sec)
365.1... logprob:  0.679575, 0.398438 (0.676 sec)
365.2... logprob:  0.597019, 0.273438 (0.678 sec)
365.3... logprob:  0.653800, 0.359375 (0.675 sec)
365.4... logprob:  0.596664, 0.273438 (0.672 sec)
365.5... logprob:  0.590944, 0.265625 (0.670 sec)
365.6... logprob:  0.611418, 0.296875 (0.669 sec)
365.7... logprob:  0.643821, 0.343750 (0.673 sec)
365.8... logprob:  0.604870, 0.289062 (0.673 sec)
365.9... logprob:  0.638534, 0.335938 (0.672 sec)
365.10... logprob:  0.598010, 0.281250 (0.669 sec)
365.11... logprob:  0.638858, 0.335938 (0.672 sec)
365.12... logprob:  0.717561, 0.437500 (0.669 sec)
365.13... logprob:  0.657249, 0.359375 (0.671 sec)
365.14... logprob:  0.662863, 0.367188 (0.669 sec)
365.15... logprob:  0.685934, 0.398438 (0.669 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644343, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940672e-03 [7.312864e-09] 
Layer 'conv1' biases: 5.571335e-07 [2.054525e-10] 
Layer 'conv2' weights[0]: 7.928540e-03 [7.629208e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.025916e-09] 
Layer 'conv3' weights[0]: 7.926257e-03 [6.588725e-09] 
Layer 'conv3' biases: 4.648792e-06 [2.839395e-09] 
Layer 'conv4' weights[0]: 7.959066e-03 [6.646485e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.103336e-08] 
Layer 'conv5' weights[0]: 7.958460e-03 [1.199802e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.273124e-07] 
Layer 'fc6' weights[0]: 7.554593e-03 [1.329319e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.282861e-08] 
Layer 'fc7' weights[0]: 7.474365e-03 [1.632845e-07] 
Layer 'fc7' biases: 9.998536e-01 [1.506698e-07] 
Layer 'fc8' weights[0]: 6.116251e-04 [8.106622e-06] 
Layer 'fc8' biases: 1.605211e-01 [1.575733e-04] 
Train error last 27 batches: 0.635741
-------------------------------------------------------
Not saving because 0.644343 > 0.627087 (334.9: -0.00%)
======================================================= (5.084 sec)
365.16... logprob:  0.627071, 0.320312 (0.666 sec)
365.17... logprob:  0.638509, 0.335938 (0.667 sec)
365.18... logprob:  0.638222, 0.335938 (0.667 sec)
365.19... logprob:  0.632713, 0.328125 (0.667 sec)
365.20... logprob:  0.648888, 0.351562 (0.666 sec)
365.21... logprob:  0.643433, 0.343750 (0.667 sec)
365.22... logprob:  0.627973, 0.320312 (0.666 sec)
365.23... logprob:  0.623106, 0.312500 (0.666 sec)
365.24... logprob:  0.577651, 0.242188 (0.666 sec)
365.25... logprob:  0.628137, 0.320312 (0.667 sec)
365.26... logprob:  0.674147, 0.390625 (0.667 sec)
365.27... logprob:  0.628002, 0.320312 (0.667 sec)
366.1... logprob:  0.679579, 0.398438 (0.668 sec)
366.2... logprob:  0.597014, 0.273438 (0.667 sec)
366.3... logprob:  0.653801, 0.359375 (0.667 sec)
366.4... logprob:  0.596662, 0.273438 (0.667 sec)
366.5... logprob:  0.590945, 0.265625 (0.667 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643603, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940602e-03 [7.413102e-09] 
Layer 'conv1' biases: 5.584905e-07 [1.377277e-10] 
Layer 'conv2' weights[0]: 7.928470e-03 [5.970749e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.497762e-10] 
Layer 'conv3' weights[0]: 7.926193e-03 [5.772388e-09] 
Layer 'conv3' biases: 4.660546e-06 [1.952607e-09] 
Layer 'conv4' weights[0]: 7.958998e-03 [5.814532e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.655573e-08] 
Layer 'conv5' weights[0]: 7.958388e-03 [9.478735e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.002531e-07] 
Layer 'fc6' weights[0]: 7.554521e-03 [1.083266e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.012245e-08] 
Layer 'fc7' weights[0]: 7.473735e-03 [1.343171e-07] 
Layer 'fc7' biases: 9.998533e-01 [1.194065e-07] 
Layer 'fc8' weights[0]: 5.901315e-04 [6.335553e-06] 
Layer 'fc8' biases: 1.602022e-01 [1.530639e-04] 
Train error last 27 batches: 0.635740
-------------------------------------------------------
Not saving because 0.643603 > 0.627087 (334.9: -0.00%)
======================================================= (5.074 sec)
366.6... logprob:  0.611420, 0.296875 (0.667 sec)
366.7... logprob:  0.643819, 0.343750 (0.667 sec)
366.8... logprob:  0.604875, 0.289062 (0.668 sec)
366.9... logprob:  0.638532, 0.335938 (0.667 sec)
366.10... logprob:  0.598018, 0.281250 (0.668 sec)
366.11... logprob:  0.638854, 0.335938 (0.667 sec)
366.12... logprob:  0.717532, 0.437500 (0.665 sec)
366.13... logprob:  0.657238, 0.359375 (0.665 sec)
366.14... logprob:  0.662853, 0.367188 (0.667 sec)
366.15... logprob:  0.685921, 0.398438 (0.667 sec)
366.16... logprob:  0.627071, 0.320312 (0.662 sec)
366.17... logprob:  0.638509, 0.335938 (0.668 sec)
366.18... logprob:  0.638221, 0.335938 (0.667 sec)
366.19... logprob:  0.632713, 0.328125 (0.665 sec)
366.20... logprob:  0.648887, 0.351562 (0.667 sec)
366.21... logprob:  0.643433, 0.343750 (0.666 sec)
366.22... logprob:  0.627972, 0.320312 (0.667 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643443, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940538e-03 [6.727369e-09] 
Layer 'conv1' biases: 5.598341e-07 [1.354298e-10] 
Layer 'conv2' weights[0]: 7.928409e-03 [6.071203e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.969854e-10] 
Layer 'conv3' weights[0]: 7.926133e-03 [5.275183e-09] 
Layer 'conv3' biases: 4.671823e-06 [1.606813e-09] 
Layer 'conv4' weights[0]: 7.958932e-03 [5.161021e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.005045e-08] 
Layer 'conv5' weights[0]: 7.958322e-03 [5.707222e-08] 
Layer 'conv5' biases: 1.000002e+00 [6.023635e-08] 
Layer 'fc6' weights[0]: 7.554451e-03 [7.344658e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.190495e-09] 
Layer 'fc7' weights[0]: 7.473093e-03 [9.196942e-08] 
Layer 'fc7' biases: 9.998528e-01 [7.421009e-08] 
Layer 'fc8' weights[0]: 5.757860e-04 [3.885009e-06] 
Layer 'fc8' biases: 1.600624e-01 [7.532889e-05] 
Train error last 27 batches: 0.635738
-------------------------------------------------------
Not saving because 0.643443 > 0.627087 (334.9: -0.00%)
======================================================= (5.101 sec)
366.23... logprob:  0.623103, 0.312500 (0.667 sec)
366.24... logprob:  0.577638, 0.242188 (0.668 sec)
366.25... logprob:  0.628133, 0.320312 (0.670 sec)
366.26... logprob:  0.674152, 0.390625 (0.669 sec)
366.27... logprob:  0.627999, 0.320312 (0.669 sec)
367.1... logprob:  0.679586, 0.398438 (0.666 sec)
367.2... logprob:  0.597006, 0.273438 (0.669 sec)
367.3... logprob:  0.653803, 0.359375 (0.669 sec)
367.4... logprob:  0.596654, 0.273438 (0.671 sec)
367.5... logprob:  0.590937, 0.265625 (0.669 sec)
367.6... logprob:  0.611417, 0.296875 (0.668 sec)
367.7... logprob:  0.643820, 0.343750 (0.668 sec)
367.8... logprob:  0.604874, 0.289062 (0.670 sec)
367.9... logprob:  0.638532, 0.335938 (0.671 sec)
367.10... logprob:  0.598020, 0.281250 (0.672 sec)
367.11... logprob:  0.638852, 0.335938 (0.669 sec)
367.12... logprob:  0.717519, 0.437500 (0.671 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.645163, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940478e-03 [6.885715e-09] 
Layer 'conv1' biases: 5.605292e-07 [8.287188e-11] 
Layer 'conv2' weights[0]: 7.928345e-03 [5.247059e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.225820e-10] 
Layer 'conv3' weights[0]: 7.926066e-03 [4.549299e-09] 
Layer 'conv3' biases: 4.675173e-06 [8.017501e-10] 
Layer 'conv4' weights[0]: 7.958861e-03 [4.407999e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.652915e-09] 
Layer 'conv5' weights[0]: 7.958272e-03 [1.013428e-08] 
Layer 'conv5' biases: 1.000001e+00 [9.743675e-09] 
Layer 'fc6' weights[0]: 7.554383e-03 [3.957836e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.075907e-09] 
Layer 'fc7' weights[0]: 7.472440e-03 [4.187854e-08] 
Layer 'fc7' biases: 9.998539e-01 [1.448119e-08] 
Layer 'fc8' weights[0]: 6.247325e-04 [6.652023e-07] 
Layer 'fc8' biases: 1.614878e-01 [1.134958e-06] 
Train error last 27 batches: 0.635736
-------------------------------------------------------
Not saving because 0.645163 > 0.627087 (334.9: -0.00%)
======================================================= (5.199 sec)
367.13... logprob:  0.657233, 0.359375 (0.671 sec)
367.14... logprob:  0.662849, 0.367188 (0.671 sec)
367.15... logprob:  0.685916, 0.398438 (0.669 sec)
367.16... logprob:  0.627072, 0.320312 (0.670 sec)
367.17... logprob:  0.638507, 0.335938 (0.671 sec)
367.18... logprob:  0.638222, 0.335938 (0.669 sec)
367.19... logprob:  0.632712, 0.328125 (0.670 sec)
367.20... logprob:  0.648889, 0.351562 (0.670 sec)
367.21... logprob:  0.643434, 0.343750 (0.675 sec)
367.22... logprob:  0.627969, 0.320312 (0.669 sec)
367.23... logprob:  0.623099, 0.312500 (0.669 sec)
367.24... logprob:  0.577626, 0.242188 (0.667 sec)
367.25... logprob:  0.628132, 0.320312 (0.668 sec)
367.26... logprob:  0.674157, 0.390625 (0.670 sec)
367.27... logprob:  0.627998, 0.320312 (0.669 sec)
368.1... logprob:  0.679589, 0.398438 (0.671 sec)
368.2... logprob:  0.597003, 0.273438 (0.670 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643470, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940408e-03 [6.830788e-09] 
Layer 'conv1' biases: 5.621413e-07 [7.157540e-11] 
Layer 'conv2' weights[0]: 7.928276e-03 [4.976745e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.858694e-10] 
Layer 'conv3' weights[0]: 7.926001e-03 [4.548858e-09] 
Layer 'conv3' biases: 4.689597e-06 [7.895857e-10] 
Layer 'conv4' weights[0]: 7.958805e-03 [4.456951e-09] 
Layer 'conv4' biases: 1.000001e+00 [4.675326e-09] 
Layer 'conv5' weights[0]: 7.958190e-03 [2.701875e-08] 
Layer 'conv5' biases: 1.000002e+00 [2.832161e-08] 
Layer 'fc6' weights[0]: 7.554312e-03 [4.888172e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.844073e-09] 
Layer 'fc7' weights[0]: 7.471829e-03 [5.716663e-08] 
Layer 'fc7' biases: 9.998530e-01 [3.377941e-08] 
Layer 'fc8' weights[0]: 5.802196e-04 [1.775303e-06] 
Layer 'fc8' biases: 1.606134e-01 [5.006242e-05] 
Train error last 27 batches: 0.635735
-------------------------------------------------------
Not saving because 0.643470 > 0.627087 (334.9: -0.00%)
======================================================= (5.148 sec)
368.3... logprob:  0.653803, 0.359375 (0.669 sec)
368.4... logprob:  0.596654, 0.273438 (0.669 sec)
368.5... logprob:  0.590938, 0.265625 (0.669 sec)
368.6... logprob:  0.611419, 0.296875 (0.669 sec)
368.7... logprob:  0.643819, 0.343750 (0.669 sec)
368.8... logprob:  0.604878, 0.289062 (0.674 sec)
368.9... logprob:  0.638530, 0.335938 (0.671 sec)
368.10... logprob:  0.598026, 0.281250 (0.669 sec)
368.11... logprob:  0.638849, 0.335938 (0.670 sec)
368.12... logprob:  0.717495, 0.437500 (0.670 sec)
368.13... logprob:  0.657225, 0.359375 (0.666 sec)
368.14... logprob:  0.662841, 0.367188 (0.671 sec)
368.15... logprob:  0.685906, 0.398438 (0.668 sec)
368.16... logprob:  0.627072, 0.320312 (0.669 sec)
368.17... logprob:  0.638508, 0.335938 (0.670 sec)
368.18... logprob:  0.638221, 0.335938 (0.669 sec)
368.19... logprob:  0.632711, 0.328125 (0.669 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643579, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940341e-03 [6.790606e-09] 
Layer 'conv1' biases: 5.632601e-07 [1.580057e-10] 
Layer 'conv2' weights[0]: 7.928215e-03 [6.602050e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.661144e-10] 
Layer 'conv3' weights[0]: 7.925935e-03 [5.725070e-09] 
Layer 'conv3' biases: 4.698409e-06 [2.078287e-09] 
Layer 'conv4' weights[0]: 7.958737e-03 [5.669274e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.428793e-08] 
Layer 'conv5' weights[0]: 7.958128e-03 [8.101636e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.551945e-08] 
Layer 'fc6' weights[0]: 7.554243e-03 [9.686157e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.723543e-09] 
Layer 'fc7' weights[0]: 7.471170e-03 [1.201955e-07] 
Layer 'fc7' biases: 9.998531e-01 [1.035309e-07] 
Layer 'fc8' weights[0]: 5.879895e-04 [5.471401e-06] 
Layer 'fc8' biases: 1.610365e-01 [1.074742e-04] 
Train error last 27 batches: 0.635733
-------------------------------------------------------
Not saving because 0.643579 > 0.627087 (334.9: -0.00%)
======================================================= (5.078 sec)
368.20... logprob:  0.648889, 0.351562 (0.671 sec)
368.21... logprob:  0.643434, 0.343750 (0.668 sec)
368.22... logprob:  0.627966, 0.320312 (0.668 sec)
368.23... logprob:  0.623094, 0.312500 (0.668 sec)
368.24... logprob:  0.577610, 0.242188 (0.668 sec)
368.25... logprob:  0.628128, 0.320312 (0.669 sec)
368.26... logprob:  0.674163, 0.390625 (0.668 sec)
368.27... logprob:  0.627995, 0.320312 (0.670 sec)
369.1... logprob:  0.679596, 0.398438 (0.670 sec)
369.2... logprob:  0.596994, 0.273438 (0.670 sec)
369.3... logprob:  0.653805, 0.359375 (0.670 sec)
369.4... logprob:  0.596648, 0.273438 (0.670 sec)
369.5... logprob:  0.590934, 0.265625 (0.669 sec)
369.6... logprob:  0.611417, 0.296875 (0.669 sec)
369.7... logprob:  0.643819, 0.343750 (0.670 sec)
369.8... logprob:  0.604879, 0.289062 (0.671 sec)
369.9... logprob:  0.638530, 0.335938 (0.669 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644462, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940266e-03 [6.685774e-09] 
Layer 'conv1' biases: 5.641693e-07 [1.196328e-10] 
Layer 'conv2' weights[0]: 7.928154e-03 [5.827795e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.076539e-10] 
Layer 'conv3' weights[0]: 7.925869e-03 [5.672564e-09] 
Layer 'conv3' biases: 4.704675e-06 [1.867130e-09] 
Layer 'conv4' weights[0]: 7.958666e-03 [5.785768e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.598661e-08] 
Layer 'conv5' weights[0]: 7.958082e-03 [9.066141e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.599700e-08] 
Layer 'fc6' weights[0]: 7.554172e-03 [1.046396e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.688305e-09] 
Layer 'fc7' weights[0]: 7.470501e-03 [1.291168e-07] 
Layer 'fc7' biases: 9.998536e-01 [1.133955e-07] 
Layer 'fc8' weights[0]: 6.127495e-04 [6.054398e-06] 
Layer 'fc8' biases: 1.618568e-01 [1.435929e-04] 
Train error last 27 batches: 0.635732
-------------------------------------------------------
Not saving because 0.644462 > 0.627087 (334.9: -0.00%)
======================================================= (5.081 sec)
369.10... logprob:  0.598030, 0.281250 (0.670 sec)
369.11... logprob:  0.638847, 0.335938 (0.671 sec)
369.12... logprob:  0.717476, 0.437500 (0.670 sec)
369.13... logprob:  0.657219, 0.359375 (0.669 sec)
369.14... logprob:  0.662835, 0.367188 (0.671 sec)
369.15... logprob:  0.685899, 0.398438 (0.667 sec)
369.16... logprob:  0.627072, 0.320312 (0.670 sec)
369.17... logprob:  0.638508, 0.335938 (0.671 sec)
369.18... logprob:  0.638221, 0.335938 (0.668 sec)
369.19... logprob:  0.632711, 0.328125 (0.670 sec)
369.20... logprob:  0.648891, 0.351562 (0.670 sec)
369.21... logprob:  0.643435, 0.343750 (0.666 sec)
369.22... logprob:  0.627964, 0.320312 (0.669 sec)
369.23... logprob:  0.623090, 0.312500 (0.670 sec)
369.24... logprob:  0.577596, 0.242188 (0.667 sec)
369.25... logprob:  0.628125, 0.320312 (0.668 sec)
369.26... logprob:  0.674169, 0.390625 (0.668 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643458, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940204e-03 [6.541918e-09] 
Layer 'conv1' biases: 5.657090e-07 [7.075924e-11] 
Layer 'conv2' weights[0]: 7.928100e-03 [5.019134e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.433452e-10] 
Layer 'conv3' weights[0]: 7.925799e-03 [4.418014e-09] 
Layer 'conv3' biases: 4.718174e-06 [6.099586e-10] 
Layer 'conv4' weights[0]: 7.958608e-03 [4.317256e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.551264e-09] 
Layer 'conv5' weights[0]: 7.957991e-03 [9.885951e-09] 
Layer 'conv5' biases: 1.000002e+00 [9.569924e-09] 
Layer 'fc6' weights[0]: 7.554098e-03 [3.931207e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.530381e-10] 
Layer 'fc7' weights[0]: 7.469871e-03 [4.069056e-08] 
Layer 'fc7' biases: 9.998528e-01 [1.167906e-08] 
Layer 'fc8' weights[0]: 5.779407e-04 [5.756870e-07] 
Layer 'fc8' biases: 1.612177e-01 [2.484372e-05] 
Train error last 27 batches: 0.635730
-------------------------------------------------------
Not saving because 0.643458 > 0.627087 (334.9: -0.00%)
======================================================= (5.197 sec)
369.27... logprob:  0.627992, 0.320312 (0.670 sec)
370.1... logprob:  0.679600, 0.398438 (0.669 sec)
370.2... logprob:  0.596990, 0.273438 (0.670 sec)
370.3... logprob:  0.653806, 0.359375 (0.671 sec)
370.4... logprob:  0.596644, 0.273438 (0.670 sec)
370.5... logprob:  0.590932, 0.265625 (0.671 sec)
370.6... logprob:  0.611418, 0.296875 (0.670 sec)
370.7... logprob:  0.643818, 0.343750 (0.669 sec)
370.8... logprob:  0.604882, 0.289062 (0.671 sec)
370.9... logprob:  0.638528, 0.335938 (0.670 sec)
370.10... logprob:  0.598036, 0.281250 (0.670 sec)
370.11... logprob:  0.638844, 0.335938 (0.670 sec)
370.12... logprob:  0.717453, 0.437500 (0.670 sec)
370.13... logprob:  0.657211, 0.359375 (0.670 sec)
370.14... logprob:  0.662827, 0.367188 (0.670 sec)
370.15... logprob:  0.685889, 0.398438 (0.667 sec)
370.16... logprob:  0.627073, 0.320312 (0.668 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644056, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940142e-03 [6.960540e-09] 
Layer 'conv1' biases: 5.666467e-07 [1.848328e-10] 
Layer 'conv2' weights[0]: 7.928034e-03 [7.202896e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.312878e-10] 
Layer 'conv3' weights[0]: 7.925732e-03 [6.253218e-09] 
Layer 'conv3' biases: 4.724809e-06 [2.554181e-09] 
Layer 'conv4' weights[0]: 7.958540e-03 [6.263947e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.842009e-08] 
Layer 'conv5' weights[0]: 7.957943e-03 [1.043849e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.104572e-07] 
Layer 'fc6' weights[0]: 7.554042e-03 [1.178208e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.122547e-08] 
Layer 'fc7' weights[0]: 7.469200e-03 [1.454970e-07] 
Layer 'fc7' biases: 9.998534e-01 [1.318402e-07] 
Layer 'fc8' weights[0]: 6.036374e-04 [7.042169e-06] 
Layer 'fc8' biases: 1.620788e-01 [1.377766e-04] 
Train error last 27 batches: 0.635728
-------------------------------------------------------
Not saving because 0.644056 > 0.627087 (334.9: -0.00%)
======================================================= (5.075 sec)
370.17... logprob:  0.638508, 0.335938 (0.668 sec)
370.18... logprob:  0.638221, 0.335938 (0.666 sec)
370.19... logprob:  0.632711, 0.328125 (0.667 sec)
370.20... logprob:  0.648892, 0.351562 (0.667 sec)
370.21... logprob:  0.643435, 0.343750 (0.666 sec)
370.22... logprob:  0.627961, 0.320312 (0.666 sec)
370.23... logprob:  0.623086, 0.312500 (0.667 sec)
370.24... logprob:  0.577580, 0.242188 (0.666 sec)
370.25... logprob:  0.628122, 0.320312 (0.668 sec)
370.26... logprob:  0.674175, 0.390625 (0.672 sec)
370.27... logprob:  0.627990, 0.320312 (0.673 sec)
371.1... logprob:  0.679607, 0.398438 (0.671 sec)
371.2... logprob:  0.596982, 0.273438 (0.669 sec)
371.3... logprob:  0.653808, 0.359375 (0.670 sec)
371.4... logprob:  0.596640, 0.273438 (0.673 sec)
371.5... logprob:  0.590928, 0.265625 (0.672 sec)
371.6... logprob:  0.611417, 0.296875 (0.666 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643761, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940076e-03 [7.339115e-09] 
Layer 'conv1' biases: 5.678769e-07 [1.629069e-10] 
Layer 'conv2' weights[0]: 7.927972e-03 [6.279662e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.685046e-10] 
Layer 'conv3' weights[0]: 7.925667e-03 [6.071305e-09] 
Layer 'conv3' biases: 4.735094e-06 [2.231604e-09] 
Layer 'conv4' weights[0]: 7.958468e-03 [6.140430e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.925187e-08] 
Layer 'conv5' weights[0]: 7.957876e-03 [1.094035e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.156225e-07] 
Layer 'fc6' weights[0]: 7.553964e-03 [1.228557e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.173208e-08] 
Layer 'fc7' weights[0]: 7.468570e-03 [1.518645e-07] 
Layer 'fc7' biases: 9.998533e-01 [1.382996e-07] 
Layer 'fc8' weights[0]: 5.949405e-04 [7.316763e-06] 
Layer 'fc8' biases: 1.620707e-01 [1.753953e-04] 
Train error last 27 batches: 0.635727
-------------------------------------------------------
Not saving because 0.643761 > 0.627087 (334.9: -0.00%)
======================================================= (5.063 sec)
371.7... logprob:  0.643818, 0.343750 (0.668 sec)
371.8... logprob:  0.604885, 0.289062 (0.669 sec)
371.9... logprob:  0.638527, 0.335938 (0.668 sec)
371.10... logprob:  0.598042, 0.281250 (0.669 sec)
371.11... logprob:  0.638841, 0.335938 (0.669 sec)
371.12... logprob:  0.717430, 0.437500 (0.668 sec)
371.13... logprob:  0.657204, 0.359375 (0.668 sec)
371.14... logprob:  0.662819, 0.367188 (0.669 sec)
371.15... logprob:  0.685879, 0.398438 (0.667 sec)
371.16... logprob:  0.627073, 0.320312 (0.667 sec)
371.17... logprob:  0.638507, 0.335938 (0.666 sec)
371.18... logprob:  0.638222, 0.335938 (0.667 sec)
371.19... logprob:  0.632711, 0.328125 (0.667 sec)
371.20... logprob:  0.648893, 0.351562 (0.667 sec)
371.21... logprob:  0.643436, 0.343750 (0.667 sec)
371.22... logprob:  0.627959, 0.320312 (0.667 sec)
371.23... logprob:  0.623082, 0.312500 (0.663 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643440, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940009e-03 [6.343965e-09] 
Layer 'conv1' biases: 5.693050e-07 [1.071609e-10] 
Layer 'conv2' weights[0]: 7.927908e-03 [5.357350e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.207167e-10] 
Layer 'conv3' weights[0]: 7.925594e-03 [4.749096e-09] 
Layer 'conv3' biases: 4.747301e-06 [1.093788e-09] 
Layer 'conv4' weights[0]: 7.958412e-03 [4.621541e-09] 
Layer 'conv4' biases: 1.000001e+00 [5.715747e-09] 
Layer 'conv5' weights[0]: 7.957801e-03 [3.257256e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.420467e-08] 
Layer 'fc6' weights[0]: 7.553889e-03 [5.260173e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.533741e-09] 
Layer 'fc7' weights[0]: 7.467922e-03 [6.386758e-08] 
Layer 'fc7' biases: 9.998526e-01 [4.257345e-08] 
Layer 'fc8' weights[0]: 5.725306e-04 [2.216624e-06] 
Layer 'fc8' biases: 1.617194e-01 [3.791921e-05] 
Train error last 27 batches: 0.635725
-------------------------------------------------------
Not saving because 0.643440 > 0.627087 (334.9: -0.00%)
======================================================= (5.133 sec)
371.24... logprob:  0.577566, 0.242188 (0.667 sec)
371.25... logprob:  0.628119, 0.320312 (0.666 sec)
371.26... logprob:  0.674181, 0.390625 (0.667 sec)
371.27... logprob:  0.627988, 0.320312 (0.667 sec)
372.1... logprob:  0.679613, 0.398438 (0.668 sec)
372.2... logprob:  0.596976, 0.273438 (0.668 sec)
372.3... logprob:  0.653809, 0.359375 (0.667 sec)
372.4... logprob:  0.596636, 0.273438 (0.668 sec)
372.5... logprob:  0.590926, 0.265625 (0.668 sec)
372.6... logprob:  0.611417, 0.296875 (0.668 sec)
372.7... logprob:  0.643818, 0.343750 (0.668 sec)
372.8... logprob:  0.604888, 0.289062 (0.669 sec)
372.9... logprob:  0.638526, 0.335938 (0.669 sec)
372.10... logprob:  0.598047, 0.281250 (0.668 sec)
372.11... logprob:  0.638838, 0.335938 (0.669 sec)
372.12... logprob:  0.717410, 0.437500 (0.668 sec)
372.13... logprob:  0.657197, 0.359375 (0.669 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644982, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.939946e-03 [6.516338e-09] 
Layer 'conv1' biases: 5.699948e-07 [1.003288e-10] 
Layer 'conv2' weights[0]: 7.927847e-03 [5.429466e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.575648e-10] 
Layer 'conv3' weights[0]: 7.925526e-03 [4.771523e-09] 
Layer 'conv3' biases: 4.750877e-06 [1.250468e-09] 
Layer 'conv4' weights[0]: 7.958348e-03 [4.683131e-09] 
Layer 'conv4' biases: 1.000001e+00 [6.824136e-09] 
Layer 'conv5' weights[0]: 7.957749e-03 [3.889882e-08] 
Layer 'conv5' biases: 1.000002e+00 [4.095592e-08] 
Layer 'fc6' weights[0]: 7.553833e-03 [5.695693e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.170807e-09] 
Layer 'fc7' weights[0]: 7.467301e-03 [7.009849e-08] 
Layer 'fc7' biases: 9.998536e-01 [4.971093e-08] 
Layer 'fc8' weights[0]: 6.204654e-04 [2.634217e-06] 
Layer 'fc8' biases: 1.631345e-01 [4.160473e-05] 
Train error last 27 batches: 0.635723
-------------------------------------------------------
Not saving because 0.644982 > 0.627087 (334.9: -0.00%)
======================================================= (5.131 sec)
372.14... logprob:  0.662813, 0.367188 (0.668 sec)
372.15... logprob:  0.685872, 0.398438 (0.667 sec)
372.16... logprob:  0.627073, 0.320312 (0.667 sec)
372.17... logprob:  0.638508, 0.335938 (0.668 sec)
372.18... logprob:  0.638222, 0.335938 (0.666 sec)
372.19... logprob:  0.632710, 0.328125 (0.665 sec)
372.20... logprob:  0.648894, 0.351562 (0.664 sec)
372.21... logprob:  0.643436, 0.343750 (0.666 sec)
372.22... logprob:  0.627956, 0.320312 (0.665 sec)
372.23... logprob:  0.623078, 0.312500 (0.667 sec)
372.24... logprob:  0.577552, 0.242188 (0.667 sec)
372.25... logprob:  0.628116, 0.320312 (0.668 sec)
372.26... logprob:  0.674186, 0.390625 (0.667 sec)
372.27... logprob:  0.627986, 0.320312 (0.668 sec)
373.1... logprob:  0.679618, 0.398438 (0.668 sec)
373.2... logprob:  0.596971, 0.273438 (0.666 sec)
373.3... logprob:  0.653810, 0.359375 (0.669 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643477, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.939881e-03 [6.728474e-09] 
Layer 'conv1' biases: 5.715657e-07 [6.529178e-11] 
Layer 'conv2' weights[0]: 7.927794e-03 [4.984559e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.552951e-10] 
Layer 'conv3' weights[0]: 7.925451e-03 [4.451379e-09] 
Layer 'conv3' biases: 4.764923e-06 [6.357637e-10] 
Layer 'conv4' weights[0]: 7.958287e-03 [4.334664e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.912892e-09] 
Layer 'conv5' weights[0]: 7.957677e-03 [1.212743e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.210127e-08] 
Layer 'fc6' weights[0]: 7.553767e-03 [4.018020e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.215599e-09] 
Layer 'fc7' weights[0]: 7.466665e-03 [4.258834e-08] 
Layer 'fc7' biases: 9.998527e-01 [1.481011e-08] 
Layer 'fc8' weights[0]: 5.794380e-04 [7.692444e-07] 
Layer 'fc8' biases: 1.623276e-01 [2.498812e-05] 
Train error last 27 batches: 0.635722
-------------------------------------------------------
Not saving because 0.643477 > 0.627087 (334.9: -0.00%)
======================================================= (5.192 sec)
373.4... logprob:  0.596632, 0.273438 (0.668 sec)
373.5... logprob:  0.590923, 0.265625 (0.668 sec)
373.6... logprob:  0.611417, 0.296875 (0.666 sec)
373.7... logprob:  0.643817, 0.343750 (0.667 sec)
373.8... logprob:  0.604890, 0.289062 (0.669 sec)
373.9... logprob:  0.638525, 0.335938 (0.669 sec)
373.10... logprob:  0.598052, 0.281250 (0.666 sec)
373.11... logprob:  0.638835, 0.335938 (0.669 sec)
373.12... logprob:  0.717388, 0.437500 (0.668 sec)
373.13... logprob:  0.657190, 0.359375 (0.668 sec)
373.14... logprob:  0.662805, 0.367188 (0.668 sec)
373.15... logprob:  0.685861, 0.398438 (0.667 sec)
373.16... logprob:  0.627074, 0.320312 (0.667 sec)
373.17... logprob:  0.638507, 0.335938 (0.669 sec)
373.18... logprob:  0.638221, 0.335938 (0.666 sec)
373.19... logprob:  0.632710, 0.328125 (0.668 sec)
373.20... logprob:  0.648895, 0.351562 (0.667 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643505, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.939811e-03 [6.841733e-09] 
Layer 'conv1' biases: 5.727409e-07 [1.623048e-10] 
Layer 'conv2' weights[0]: 7.927722e-03 [6.533611e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.741473e-10] 
Layer 'conv3' weights[0]: 7.925388e-03 [5.713587e-09] 
Layer 'conv3' biases: 4.774358e-06 [2.105869e-09] 
Layer 'conv4' weights[0]: 7.958232e-03 [5.647179e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.456142e-08] 
Layer 'conv5' weights[0]: 7.957609e-03 [8.234980e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.709154e-08] 
Layer 'fc6' weights[0]: 7.553697e-03 [9.840380e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.906156e-09] 
Layer 'fc7' weights[0]: 7.466024e-03 [1.219863e-07] 
Layer 'fc7' biases: 9.998528e-01 [1.057373e-07] 
Layer 'fc8' weights[0]: 5.817319e-04 [5.556885e-06] 
Layer 'fc8' biases: 1.626135e-01 [1.121514e-04] 
Train error last 27 batches: 0.635720
-------------------------------------------------------
Not saving because 0.643505 > 0.627087 (334.9: -0.00%)
======================================================= (5.078 sec)
373.21... logprob:  0.643436, 0.343750 (0.667 sec)
373.22... logprob:  0.627954, 0.320312 (0.667 sec)
373.23... logprob:  0.623075, 0.312500 (0.668 sec)
373.24... logprob:  0.577540, 0.242188 (0.667 sec)
373.25... logprob:  0.628113, 0.320312 (0.678 sec)
373.26... logprob:  0.674190, 0.390625 (0.667 sec)
373.27... logprob:  0.627984, 0.320312 (0.668 sec)
374.1... logprob:  0.679622, 0.398438 (0.668 sec)
374.2... logprob:  0.596965, 0.273438 (0.668 sec)
374.3... logprob:  0.653812, 0.359375 (0.668 sec)
374.4... logprob:  0.596627, 0.273438 (0.668 sec)
374.5... logprob:  0.590919, 0.265625 (0.669 sec)
374.6... logprob:  0.611416, 0.296875 (0.666 sec)
374.7... logprob:  0.643817, 0.343750 (0.681 sec)
374.8... logprob:  0.604891, 0.289062 (0.670 sec)
374.9... logprob:  0.638524, 0.335938 (0.669 sec)
374.10... logprob:  0.598055, 0.281250 (0.669 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644824, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.939736e-03 [7.051089e-09] 
Layer 'conv1' biases: 5.735457e-07 [1.450248e-10] 
Layer 'conv2' weights[0]: 7.927652e-03 [6.278038e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.464985e-10] 
Layer 'conv3' weights[0]: 7.925318e-03 [6.105666e-09] 
Layer 'conv3' biases: 4.779272e-06 [2.237874e-09] 
Layer 'conv4' weights[0]: 7.958170e-03 [6.263975e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.942355e-08] 
Layer 'conv5' weights[0]: 7.957547e-03 [1.100387e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.168252e-07] 
Layer 'fc6' weights[0]: 7.553632e-03 [1.231653e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.175977e-08] 
Layer 'fc7' weights[0]: 7.465364e-03 [1.505881e-07] 
Layer 'fc7' biases: 9.998536e-01 [1.368244e-07] 
Layer 'fc8' weights[0]: 6.174296e-04 [7.329987e-06] 
Layer 'fc8' biases: 1.637100e-01 [1.704096e-04] 
Train error last 27 batches: 0.635720
-------------------------------------------------------
Not saving because 0.644824 > 0.627087 (334.9: -0.00%)
======================================================= (5.085 sec)
374.11... logprob:  0.638833, 0.335938 (0.668 sec)
374.12... logprob:  0.717372, 0.437500 (0.664 sec)
374.13... logprob:  0.657185, 0.359375 (0.668 sec)
374.14... logprob:  0.662800, 0.367188 (0.669 sec)
374.15... logprob:  0.685855, 0.398438 (0.667 sec)
374.16... logprob:  0.627074, 0.320312 (0.667 sec)
374.17... logprob:  0.638507, 0.335938 (0.668 sec)
374.18... logprob:  0.638221, 0.335938 (0.667 sec)
374.19... logprob:  0.632709, 0.328125 (0.667 sec)
374.20... logprob:  0.648895, 0.351562 (0.667 sec)
374.21... logprob:  0.643436, 0.343750 (0.667 sec)
374.22... logprob:  0.627952, 0.320312 (0.667 sec)
374.23... logprob:  0.623072, 0.312500 (0.665 sec)
374.24... logprob:  0.577528, 0.242188 (0.666 sec)
374.25... logprob:  0.628111, 0.320312 (0.664 sec)
374.26... logprob:  0.674195, 0.390625 (0.667 sec)
374.27... logprob:  0.627982, 0.320312 (0.668 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643468, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.939669e-03 [6.619822e-09] 
Layer 'conv1' biases: 5.751259e-07 [7.048868e-11] 
Layer 'conv2' weights[0]: 7.927594e-03 [4.910569e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.597298e-10] 
Layer 'conv3' weights[0]: 7.925256e-03 [4.458433e-09] 
Layer 'conv3' biases: 4.793344e-06 [7.055370e-10] 
Layer 'conv4' weights[0]: 7.958114e-03 [4.380680e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.642260e-09] 
Layer 'conv5' weights[0]: 7.957468e-03 [2.133136e-08] 
Layer 'conv5' biases: 1.000002e+00 [2.208055e-08] 
Layer 'fc6' weights[0]: 7.553576e-03 [4.494165e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.208985e-09] 
Layer 'fc7' weights[0]: 7.464712e-03 [5.090796e-08] 
Layer 'fc7' biases: 9.998528e-01 [2.641134e-08] 
Layer 'fc8' weights[0]: 5.777557e-04 [1.352377e-06] 
Layer 'fc8' biases: 1.629460e-01 [4.239240e-05] 
Train error last 27 batches: 0.635718
-------------------------------------------------------
Not saving because 0.643468 > 0.627087 (334.9: -0.00%)
======================================================= (5.162 sec)
375.1... logprob:  0.679627, 0.398438 (0.668 sec)
375.2... logprob:  0.596959, 0.273438 (0.667 sec)
375.3... logprob:  0.653812, 0.359375 (0.668 sec)
375.4... logprob:  0.596623, 0.273438 (0.668 sec)
375.5... logprob:  0.590917, 0.265625 (0.666 sec)
375.6... logprob:  0.611416, 0.296875 (0.667 sec)
375.7... logprob:  0.643816, 0.343750 (0.665 sec)
375.8... logprob:  0.604893, 0.289062 (0.669 sec)
375.9... logprob:  0.638523, 0.335938 (0.669 sec)
375.10... logprob:  0.598059, 0.281250 (0.667 sec)
375.11... logprob:  0.638831, 0.335938 (0.668 sec)
375.12... logprob:  0.717354, 0.437500 (0.668 sec)
375.13... logprob:  0.657179, 0.359375 (0.668 sec)
375.14... logprob:  0.662794, 0.367188 (0.668 sec)
375.15... logprob:  0.685848, 0.398438 (0.667 sec)
375.16... logprob:  0.627074, 0.320312 (0.666 sec)
375.17... logprob:  0.638507, 0.335938 (0.668 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643841, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.939606e-03 [6.466343e-09] 
Layer 'conv1' biases: 5.761298e-07 [1.715031e-10] 
Layer 'conv2' weights[0]: 7.927535e-03 [6.880134e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.704718e-10] 
Layer 'conv3' weights[0]: 7.925190e-03 [6.036505e-09] 
Layer 'conv3' biases: 4.800836e-06 [2.368825e-09] 
Layer 'conv4' weights[0]: 7.958050e-03 [6.079073e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.757473e-08] 
Layer 'conv5' weights[0]: 7.957407e-03 [9.903172e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.049657e-07] 
Layer 'fc6' weights[0]: 7.553505e-03 [1.128329e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.066730e-08] 
Layer 'fc7' weights[0]: 7.464075e-03 [1.390648e-07] 
Layer 'fc7' biases: 9.998531e-01 [1.249204e-07] 
Layer 'fc8' weights[0]: 5.961237e-04 [6.661085e-06] 
Layer 'fc8' biases: 1.636293e-01 [1.321986e-04] 
Train error last 27 batches: 0.635716
-------------------------------------------------------
Not saving because 0.643841 > 0.627087 (334.9: -0.00%)
======================================================= (5.070 sec)
375.18... logprob:  0.638222, 0.335938 (0.667 sec)
375.19... logprob:  0.632709, 0.328125 (0.667 sec)
375.20... logprob:  0.648898, 0.351562 (0.667 sec)
375.21... logprob:  0.643437, 0.343750 (0.667 sec)
375.22... logprob:  0.627949, 0.320312 (0.667 sec)
375.23... logprob:  0.623066, 0.312500 (0.667 sec)
375.24... logprob:  0.577511, 0.242188 (0.666 sec)
375.25... logprob:  0.628107, 0.320312 (0.668 sec)
375.26... logprob:  0.674201, 0.390625 (0.665 sec)
375.27... logprob:  0.627979, 0.320312 (0.668 sec)
376.1... logprob:  0.679632, 0.398438 (0.669 sec)
376.2... logprob:  0.596953, 0.273438 (0.667 sec)
376.3... logprob:  0.653814, 0.359375 (0.667 sec)
376.4... logprob:  0.596621, 0.273438 (0.668 sec)
376.5... logprob:  0.590915, 0.265625 (0.668 sec)
376.6... logprob:  0.611416, 0.296875 (0.668 sec)
376.7... logprob:  0.643816, 0.343750 (0.669 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643929, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.939542e-03 [6.830713e-09] 
Layer 'conv1' biases: 5.772573e-07 [1.269955e-10] 
Layer 'conv2' weights[0]: 7.927468e-03 [5.804932e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.152335e-10] 
Layer 'conv3' weights[0]: 7.925127e-03 [5.622152e-09] 
Layer 'conv3' biases: 4.809831e-06 [1.869902e-09] 
Layer 'conv4' weights[0]: 7.957983e-03 [5.703673e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.599296e-08] 
Layer 'conv5' weights[0]: 7.957335e-03 [9.001155e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.528203e-08] 
Layer 'fc6' weights[0]: 7.553446e-03 [1.043977e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.649125e-09] 
Layer 'fc7' weights[0]: 7.463428e-03 [1.288380e-07] 
Layer 'fc7' biases: 9.998531e-01 [1.131171e-07] 
Layer 'fc8' weights[0]: 5.985331e-04 [5.978653e-06] 
Layer 'fc8' biases: 1.638947e-01 [1.453977e-04] 
Train error last 27 batches: 0.635715
-------------------------------------------------------
Not saving because 0.643929 > 0.627087 (334.9: -0.00%)
======================================================= (5.088 sec)
376.8... logprob:  0.604897, 0.289062 (0.668 sec)
376.9... logprob:  0.638522, 0.335938 (0.669 sec)
376.10... logprob:  0.598066, 0.281250 (0.667 sec)
376.11... logprob:  0.638827, 0.335938 (0.668 sec)
376.12... logprob:  0.717328, 0.437500 (0.664 sec)
376.13... logprob:  0.657170, 0.359375 (0.668 sec)
376.14... logprob:  0.662785, 0.367188 (0.668 sec)
376.15... logprob:  0.685837, 0.398438 (0.665 sec)
376.16... logprob:  0.627074, 0.320312 (0.667 sec)
376.17... logprob:  0.638506, 0.335938 (0.666 sec)
376.18... logprob:  0.638221, 0.335938 (0.666 sec)
376.19... logprob:  0.632708, 0.328125 (0.667 sec)
376.20... logprob:  0.648898, 0.351562 (0.667 sec)
376.21... logprob:  0.643437, 0.343750 (0.666 sec)
376.22... logprob:  0.627947, 0.320312 (0.667 sec)
376.23... logprob:  0.623063, 0.312500 (0.667 sec)
376.24... logprob:  0.577497, 0.242188 (0.667 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643444, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.939478e-03 [6.512786e-09] 
Layer 'conv1' biases: 5.787252e-07 [6.032746e-11] 
Layer 'conv2' weights[0]: 7.927397e-03 [4.876061e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.035112e-10] 
Layer 'conv3' weights[0]: 7.925068e-03 [4.529533e-09] 
Layer 'conv3' biases: 4.822213e-06 [8.487857e-10] 
Layer 'conv4' weights[0]: 7.957924e-03 [4.470021e-09] 
Layer 'conv4' biases: 1.000001e+00 [6.028251e-09] 
Layer 'conv5' weights[0]: 7.957264e-03 [3.397508e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.565220e-08] 
Layer 'fc6' weights[0]: 7.553382e-03 [5.331099e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.604397e-09] 
Layer 'fc7' weights[0]: 7.462760e-03 [6.439885e-08] 
Layer 'fc7' biases: 9.998527e-01 [4.293634e-08] 
Layer 'fc8' weights[0]: 5.730944e-04 [2.204204e-06] 
Layer 'fc8' biases: 1.634680e-01 [6.677880e-05] 
Train error last 27 batches: 0.635712
-------------------------------------------------------
Not saving because 0.643444 > 0.627087 (334.9: -0.00%)
======================================================= (5.134 sec)
376.25... logprob:  0.628104, 0.320312 (0.667 sec)
376.26... logprob:  0.674206, 0.390625 (0.667 sec)
376.27... logprob:  0.627977, 0.320312 (0.668 sec)
377.1... logprob:  0.679638, 0.398438 (0.665 sec)
377.2... logprob:  0.596946, 0.273438 (0.668 sec)
377.3... logprob:  0.653815, 0.359375 (0.669 sec)
377.4... logprob:  0.596614, 0.273438 (0.668 sec)
377.5... logprob:  0.590911, 0.265625 (0.668 sec)
377.6... logprob:  0.611415, 0.296875 (0.665 sec)
377.7... logprob:  0.643815, 0.343750 (0.668 sec)
377.8... logprob:  0.604897, 0.289062 (0.669 sec)
377.9... logprob:  0.638521, 0.335938 (0.669 sec)
377.10... logprob:  0.598069, 0.281250 (0.669 sec)
377.11... logprob:  0.638825, 0.335938 (0.669 sec)
377.12... logprob:  0.717311, 0.437500 (0.669 sec)
377.13... logprob:  0.657164, 0.359375 (0.668 sec)
377.14... logprob:  0.662779, 0.367188 (0.669 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644704, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.939401e-03 [6.776468e-09] 
Layer 'conv1' biases: 5.794909e-07 [1.505122e-10] 
Layer 'conv2' weights[0]: 7.927327e-03 [6.229802e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.773572e-10] 
Layer 'conv3' weights[0]: 7.925005e-03 [5.434372e-09] 
Layer 'conv3' biases: 4.826659e-06 [1.868262e-09] 
Layer 'conv4' weights[0]: 7.957855e-03 [5.398474e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.233779e-08] 
Layer 'conv5' weights[0]: 7.957218e-03 [6.959198e-08] 
Layer 'conv5' biases: 1.000002e+00 [7.364334e-08] 
Layer 'fc6' weights[0]: 7.553312e-03 [8.505889e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.477181e-09] 
Layer 'fc7' weights[0]: 7.462102e-03 [1.053426e-07] 
Layer 'fc7' biases: 9.998534e-01 [8.789679e-08] 
Layer 'fc8' weights[0]: 6.144439e-04 [4.670908e-06] 
Layer 'fc8' biases: 1.647238e-01 [8.647665e-05] 
Train error last 27 batches: 0.635711
-------------------------------------------------------
Not saving because 0.644704 > 0.627087 (334.9: -0.00%)
======================================================= (5.086 sec)
377.15... logprob:  0.685830, 0.398438 (0.668 sec)
377.16... logprob:  0.627074, 0.320312 (0.667 sec)
377.17... logprob:  0.638506, 0.335938 (0.668 sec)
377.18... logprob:  0.638221, 0.335938 (0.667 sec)
377.19... logprob:  0.632708, 0.328125 (0.666 sec)
377.20... logprob:  0.648899, 0.351562 (0.664 sec)
377.21... logprob:  0.643438, 0.343750 (0.667 sec)
377.22... logprob:  0.627944, 0.320312 (0.664 sec)
377.23... logprob:  0.623060, 0.312500 (0.667 sec)
377.24... logprob:  0.577486, 0.242188 (0.666 sec)
377.25... logprob:  0.628102, 0.320312 (0.667 sec)
377.26... logprob:  0.674210, 0.390625 (0.667 sec)
377.27... logprob:  0.627975, 0.320312 (0.670 sec)
378.1... logprob:  0.679642, 0.398438 (0.671 sec)
378.2... logprob:  0.596941, 0.273438 (0.670 sec)
378.3... logprob:  0.653816, 0.359375 (0.671 sec)
378.4... logprob:  0.596612, 0.273438 (0.671 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643512, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.939336e-03 [6.873009e-09] 
Layer 'conv1' biases: 5.809872e-07 [8.906029e-11] 
Layer 'conv2' weights[0]: 7.927256e-03 [5.305194e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.621704e-10] 
Layer 'conv3' weights[0]: 7.924939e-03 [4.961863e-09] 
Layer 'conv3' biases: 4.839870e-06 [1.217485e-09] 
Layer 'conv4' weights[0]: 7.957790e-03 [4.909452e-09] 
Layer 'conv4' biases: 1.000001e+00 [9.133231e-09] 
Layer 'conv5' weights[0]: 7.957142e-03 [5.192395e-08] 
Layer 'conv5' biases: 1.000002e+00 [5.473967e-08] 
Layer 'fc6' weights[0]: 7.553242e-03 [6.809586e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.539066e-09] 
Layer 'fc7' weights[0]: 7.461428e-03 [8.403895e-08] 
Layer 'fc7' biases: 9.998528e-01 [6.513461e-08] 
Layer 'fc8' weights[0]: 5.809597e-04 [3.418791e-06] 
Layer 'fc8' biases: 1.640913e-01 [8.799302e-05] 
Train error last 27 batches: 0.635710
-------------------------------------------------------
Not saving because 0.643512 > 0.627087 (334.9: -0.00%)
======================================================= (5.123 sec)
378.5... logprob:  0.590908, 0.265625 (0.669 sec)
378.6... logprob:  0.611415, 0.296875 (0.667 sec)
378.7... logprob:  0.643815, 0.343750 (0.669 sec)
378.8... logprob:  0.604899, 0.289062 (0.669 sec)
378.9... logprob:  0.638520, 0.335938 (0.671 sec)
378.10... logprob:  0.598074, 0.281250 (0.672 sec)
378.11... logprob:  0.638823, 0.335938 (0.672 sec)
378.12... logprob:  0.717292, 0.437500 (0.670 sec)
378.13... logprob:  0.657158, 0.359375 (0.671 sec)
378.14... logprob:  0.662773, 0.367188 (0.672 sec)
378.15... logprob:  0.685824, 0.398438 (0.669 sec)
378.16... logprob:  0.627074, 0.320312 (0.670 sec)
378.17... logprob:  0.638506, 0.335938 (0.671 sec)
378.18... logprob:  0.638221, 0.335938 (0.669 sec)
378.19... logprob:  0.632708, 0.328125 (0.670 sec)
378.20... logprob:  0.648901, 0.351562 (0.671 sec)
378.21... logprob:  0.643439, 0.343750 (0.668 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643462, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.939257e-03 [6.844723e-09] 
Layer 'conv1' biases: 5.822340e-07 [1.560210e-10] 
Layer 'conv2' weights[0]: 7.927194e-03 [6.515181e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.414061e-10] 
Layer 'conv3' weights[0]: 7.924869e-03 [5.671809e-09] 
Layer 'conv3' biases: 4.850045e-06 [2.022388e-09] 
Layer 'conv4' weights[0]: 7.957724e-03 [5.584313e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.361815e-08] 
Layer 'conv5' weights[0]: 7.957068e-03 [7.708424e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.145612e-08] 
Layer 'fc6' weights[0]: 7.553173e-03 [9.338405e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.351804e-09] 
Layer 'fc7' weights[0]: 7.460800e-03 [1.159747e-07] 
Layer 'fc7' biases: 9.998527e-01 [9.918756e-08] 
Layer 'fc8' weights[0]: 5.758569e-04 [5.181918e-06] 
Layer 'fc8' biases: 1.641833e-01 [1.063253e-04] 
Train error last 27 batches: 0.635709
-------------------------------------------------------
Not saving because 0.643462 > 0.627087 (334.9: -0.00%)
======================================================= (5.087 sec)
378.22... logprob:  0.627942, 0.320312 (0.671 sec)
378.23... logprob:  0.623054, 0.312500 (0.670 sec)
378.24... logprob:  0.577468, 0.242188 (0.670 sec)
378.25... logprob:  0.628099, 0.320312 (0.669 sec)
378.26... logprob:  0.674218, 0.390625 (0.670 sec)
378.27... logprob:  0.627972, 0.320312 (0.670 sec)
379.1... logprob:  0.679649, 0.398438 (0.671 sec)
379.2... logprob:  0.596935, 0.273438 (0.670 sec)
379.3... logprob:  0.653818, 0.359375 (0.667 sec)
379.4... logprob:  0.596608, 0.273438 (0.669 sec)
379.5... logprob:  0.590907, 0.265625 (0.671 sec)
379.6... logprob:  0.611416, 0.296875 (0.670 sec)
379.7... logprob:  0.643814, 0.343750 (0.669 sec)
379.8... logprob:  0.604904, 0.289062 (0.672 sec)
379.9... logprob:  0.638519, 0.335938 (0.671 sec)
379.10... logprob:  0.598082, 0.281250 (0.671 sec)
379.11... logprob:  0.638819, 0.335938 (0.681 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.645143, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.939193e-03 [6.808937e-09] 
Layer 'conv1' biases: 5.829531e-07 [1.189891e-10] 
Layer 'conv2' weights[0]: 7.927125e-03 [5.750078e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.745703e-10] 
Layer 'conv3' weights[0]: 7.924801e-03 [5.570732e-09] 
Layer 'conv3' biases: 4.853736e-06 [1.799674e-09] 
Layer 'conv4' weights[0]: 7.957656e-03 [5.661988e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.527846e-08] 
Layer 'conv5' weights[0]: 7.957031e-03 [8.710246e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.255487e-08] 
Layer 'fc6' weights[0]: 7.553107e-03 [1.013835e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.280914e-09] 
Layer 'fc7' weights[0]: 7.460131e-03 [1.239853e-07] 
Layer 'fc7' biases: 9.998533e-01 [1.072423e-07] 
Layer 'fc8' weights[0]: 6.206584e-04 [5.760748e-06] 
Layer 'fc8' biases: 1.655152e-01 [1.365855e-04] 
Train error last 27 batches: 0.635708
-------------------------------------------------------
Not saving because 0.645143 > 0.627087 (334.9: -0.00%)
======================================================= (5.091 sec)
379.12... logprob:  0.717262, 0.437500 (0.671 sec)
379.13... logprob:  0.657148, 0.359375 (0.671 sec)
379.14... logprob:  0.662763, 0.367188 (0.669 sec)
379.15... logprob:  0.685810, 0.398438 (0.670 sec)
379.16... logprob:  0.627074, 0.320312 (0.670 sec)
379.17... logprob:  0.638506, 0.335938 (0.671 sec)
379.18... logprob:  0.638221, 0.335938 (0.668 sec)
379.19... logprob:  0.632708, 0.328125 (0.671 sec)
379.20... logprob:  0.648901, 0.351562 (0.667 sec)
379.21... logprob:  0.643439, 0.343750 (0.667 sec)
379.22... logprob:  0.627939, 0.320312 (0.664 sec)
379.23... logprob:  0.623051, 0.312500 (0.668 sec)
379.24... logprob:  0.577454, 0.242188 (0.668 sec)
379.25... logprob:  0.628096, 0.320312 (0.668 sec)
379.26... logprob:  0.674224, 0.390625 (0.665 sec)
379.27... logprob:  0.627969, 0.320312 (0.667 sec)
380.1... logprob:  0.679655, 0.398438 (0.668 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643461, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.939123e-03 [6.670828e-09] 
Layer 'conv1' biases: 5.845772e-07 [8.317921e-11] 
Layer 'conv2' weights[0]: 7.927066e-03 [5.168573e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.348811e-10] 
Layer 'conv3' weights[0]: 7.924737e-03 [4.504664e-09] 
Layer 'conv3' biases: 4.868434e-06 [8.520890e-10] 
Layer 'conv4' weights[0]: 7.957593e-03 [4.410135e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.373623e-09] 
Layer 'conv5' weights[0]: 7.956935e-03 [1.904019e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.958504e-08] 
Layer 'fc6' weights[0]: 7.553044e-03 [4.399229e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.076857e-09] 
Layer 'fc7' weights[0]: 7.459523e-03 [4.986101e-08] 
Layer 'fc7' biases: 9.998526e-01 [2.567758e-08] 
Layer 'fc8' weights[0]: 5.752844e-04 [1.285284e-06] 
Layer 'fc8' biases: 1.645967e-01 [2.077159e-05] 
Train error last 27 batches: 0.635705
-------------------------------------------------------
Not saving because 0.643461 > 0.627087 (334.9: -0.00%)
======================================================= (5.178 sec)
380.2... logprob:  0.596927, 0.273438 (0.667 sec)
380.3... logprob:  0.653820, 0.359375 (0.666 sec)
380.4... logprob:  0.596603, 0.273438 (0.663 sec)
380.5... logprob:  0.590902, 0.265625 (0.667 sec)
380.6... logprob:  0.611414, 0.296875 (0.668 sec)
380.7... logprob:  0.643814, 0.343750 (0.667 sec)
380.8... logprob:  0.604905, 0.289062 (0.669 sec)
380.9... logprob:  0.638518, 0.335938 (0.669 sec)
380.10... logprob:  0.598084, 0.281250 (0.669 sec)
380.11... logprob:  0.638817, 0.335938 (0.668 sec)
380.12... logprob:  0.717247, 0.437500 (0.664 sec)
380.13... logprob:  0.657144, 0.359375 (0.668 sec)
380.14... logprob:  0.662758, 0.367188 (0.667 sec)
380.15... logprob:  0.685804, 0.398438 (0.667 sec)
380.16... logprob:  0.627075, 0.320312 (0.667 sec)
380.17... logprob:  0.638506, 0.335938 (0.668 sec)
380.18... logprob:  0.638221, 0.335938 (0.667 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643687, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.939055e-03 [6.524242e-09] 
Layer 'conv1' biases: 5.856379e-07 [1.737649e-10] 
Layer 'conv2' weights[0]: 7.926990e-03 [6.732654e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.375571e-10] 
Layer 'conv3' weights[0]: 7.924680e-03 [5.910970e-09] 
Layer 'conv3' biases: 4.876416e-06 [2.280375e-09] 
Layer 'conv4' weights[0]: 7.957524e-03 [5.894913e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.629863e-08] 
Layer 'conv5' weights[0]: 7.956883e-03 [9.230183e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.760635e-08] 
Layer 'fc6' weights[0]: 7.552975e-03 [1.062567e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.913156e-09] 
Layer 'fc7' weights[0]: 7.458879e-03 [1.313921e-07] 
Layer 'fc7' biases: 9.998529e-01 [1.165795e-07] 
Layer 'fc8' weights[0]: 5.891474e-04 [6.164967e-06] 
Layer 'fc8' biases: 1.651745e-01 [1.240524e-04] 
Train error last 27 batches: 0.635703
-------------------------------------------------------
Not saving because 0.643687 > 0.627087 (334.9: -0.00%)
======================================================= (5.080 sec)
380.19... logprob:  0.632707, 0.328125 (0.666 sec)
380.20... logprob:  0.648903, 0.351562 (0.668 sec)
380.21... logprob:  0.643439, 0.343750 (0.667 sec)
380.22... logprob:  0.627937, 0.320312 (0.667 sec)
380.23... logprob:  0.623046, 0.312500 (0.668 sec)
380.24... logprob:  0.577440, 0.242188 (0.667 sec)
380.25... logprob:  0.628093, 0.320312 (0.665 sec)
380.26... logprob:  0.674228, 0.390625 (0.667 sec)
380.27... logprob:  0.627968, 0.320312 (0.668 sec)
381.1... logprob:  0.679659, 0.398438 (0.669 sec)
381.2... logprob:  0.596923, 0.273438 (0.674 sec)
381.3... logprob:  0.653820, 0.359375 (0.666 sec)
381.4... logprob:  0.596601, 0.273438 (0.668 sec)
381.5... logprob:  0.590901, 0.265625 (0.668 sec)
381.6... logprob:  0.611415, 0.296875 (0.668 sec)
381.7... logprob:  0.643813, 0.343750 (0.667 sec)
381.8... logprob:  0.604908, 0.289062 (0.669 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644175, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938988e-03 [7.176890e-09] 
Layer 'conv1' biases: 5.866516e-07 [1.447159e-10] 
Layer 'conv2' weights[0]: 7.926931e-03 [6.292949e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.509223e-10] 
Layer 'conv3' weights[0]: 7.924626e-03 [6.080653e-09] 
Layer 'conv3' biases: 4.883905e-06 [2.222765e-09] 
Layer 'conv4' weights[0]: 7.957465e-03 [6.189395e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.902254e-08] 
Layer 'conv5' weights[0]: 7.956807e-03 [1.074940e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.137972e-07] 
Layer 'fc6' weights[0]: 7.552908e-03 [1.204941e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.147655e-08] 
Layer 'fc7' weights[0]: 7.458230e-03 [1.480196e-07] 
Layer 'fc7' biases: 9.998531e-01 [1.342246e-07] 
Layer 'fc8' weights[0]: 6.030989e-04 [7.105354e-06] 
Layer 'fc8' biases: 1.657295e-01 [1.703879e-04] 
Train error last 27 batches: 0.635703
-------------------------------------------------------
Not saving because 0.644175 > 0.627087 (334.9: -0.00%)
======================================================= (5.068 sec)
381.9... logprob:  0.638517, 0.335938 (0.666 sec)
381.10... logprob:  0.598090, 0.281250 (0.668 sec)
381.11... logprob:  0.638814, 0.335938 (0.667 sec)
381.12... logprob:  0.717224, 0.437500 (0.666 sec)
381.13... logprob:  0.657136, 0.359375 (0.668 sec)
381.14... logprob:  0.662750, 0.367188 (0.668 sec)
381.15... logprob:  0.685794, 0.398438 (0.667 sec)
381.16... logprob:  0.627075, 0.320312 (0.667 sec)
381.17... logprob:  0.638506, 0.335938 (0.668 sec)
381.18... logprob:  0.638221, 0.335938 (0.667 sec)
381.19... logprob:  0.632707, 0.328125 (0.667 sec)
381.20... logprob:  0.648903, 0.351562 (0.666 sec)
381.21... logprob:  0.643439, 0.343750 (0.667 sec)
381.22... logprob:  0.627934, 0.320312 (0.666 sec)
381.23... logprob:  0.623044, 0.312500 (0.664 sec)
381.24... logprob:  0.577428, 0.242188 (0.666 sec)
381.25... logprob:  0.628090, 0.320312 (0.667 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643457, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938922e-03 [6.587142e-09] 
Layer 'conv1' biases: 5.881408e-07 [6.810061e-11] 
Layer 'conv2' weights[0]: 7.926870e-03 [4.951067e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.590424e-10] 
Layer 'conv3' weights[0]: 7.924567e-03 [4.648154e-09] 
Layer 'conv3' biases: 4.896555e-06 [1.014663e-09] 
Layer 'conv4' weights[0]: 7.957402e-03 [4.635719e-09] 
Layer 'conv4' biases: 1.000001e+00 [7.788686e-09] 
Layer 'conv5' weights[0]: 7.956736e-03 [4.384268e-08] 
Layer 'conv5' biases: 1.000002e+00 [4.614710e-08] 
Layer 'fc6' weights[0]: 7.552844e-03 [6.118222e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.692981e-09] 
Layer 'fc7' weights[0]: 7.457572e-03 [7.524752e-08] 
Layer 'fc7' biases: 9.998526e-01 [5.564419e-08] 
Layer 'fc8' weights[0]: 5.742260e-04 [2.864814e-06] 
Layer 'fc8' biases: 1.652172e-01 [8.164771e-05] 
Train error last 27 batches: 0.635700
-------------------------------------------------------
Not saving because 0.643457 > 0.627087 (334.9: -0.00%)
======================================================= (5.116 sec)
381.26... logprob:  0.674233, 0.390625 (0.667 sec)
381.27... logprob:  0.627966, 0.320312 (0.668 sec)
382.1... logprob:  0.679665, 0.398438 (0.666 sec)
382.2... logprob:  0.596916, 0.273438 (0.668 sec)
382.3... logprob:  0.653822, 0.359375 (0.667 sec)
382.4... logprob:  0.596596, 0.273438 (0.668 sec)
382.5... logprob:  0.590898, 0.265625 (0.671 sec)
382.6... logprob:  0.611413, 0.296875 (0.667 sec)
382.7... logprob:  0.643814, 0.343750 (0.668 sec)
382.8... logprob:  0.604909, 0.289062 (0.669 sec)
382.9... logprob:  0.638516, 0.335938 (0.668 sec)
382.10... logprob:  0.598093, 0.281250 (0.668 sec)
382.11... logprob:  0.638813, 0.335938 (0.668 sec)
382.12... logprob:  0.717209, 0.437500 (0.669 sec)
382.13... logprob:  0.657131, 0.359375 (0.668 sec)
382.14... logprob:  0.662744, 0.367188 (0.668 sec)
382.15... logprob:  0.685788, 0.398438 (0.667 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644319, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938851e-03 [7.340671e-09] 
Layer 'conv1' biases: 5.890065e-07 [2.060410e-10] 
Layer 'conv2' weights[0]: 7.926807e-03 [7.611712e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.022539e-09] 
Layer 'conv3' weights[0]: 7.924486e-03 [6.568273e-09] 
Layer 'conv3' biases: 4.902360e-06 [2.820215e-09] 
Layer 'conv4' weights[0]: 7.957330e-03 [6.622344e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.074120e-08] 
Layer 'conv5' weights[0]: 7.956663e-03 [1.172155e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.239769e-07] 
Layer 'fc6' weights[0]: 7.552783e-03 [1.300431e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.253416e-08] 
Layer 'fc7' weights[0]: 7.456917e-03 [1.591857e-07] 
Layer 'fc7' biases: 9.998531e-01 [1.463874e-07] 
Layer 'fc8' weights[0]: 6.057764e-04 [7.788314e-06] 
Layer 'fc8' biases: 1.662306e-01 [1.555808e-04] 
Train error last 27 batches: 0.635699
-------------------------------------------------------
Not saving because 0.644319 > 0.627087 (334.9: -0.00%)
======================================================= (5.056 sec)
382.16... logprob:  0.627075, 0.320312 (0.667 sec)
382.17... logprob:  0.638506, 0.335938 (0.668 sec)
382.18... logprob:  0.638221, 0.335938 (0.667 sec)
382.19... logprob:  0.632706, 0.328125 (0.667 sec)
382.20... logprob:  0.648904, 0.351562 (0.667 sec)
382.21... logprob:  0.643440, 0.343750 (0.666 sec)
382.22... logprob:  0.627932, 0.320312 (0.667 sec)
382.23... logprob:  0.623039, 0.312500 (0.667 sec)
382.24... logprob:  0.577415, 0.242188 (0.665 sec)
382.25... logprob:  0.628088, 0.320312 (0.668 sec)
382.26... logprob:  0.674238, 0.390625 (0.668 sec)
382.27... logprob:  0.627963, 0.320312 (0.668 sec)
383.1... logprob:  0.679669, 0.398438 (0.668 sec)
383.2... logprob:  0.596911, 0.273438 (0.668 sec)
383.3... logprob:  0.653823, 0.359375 (0.667 sec)
383.4... logprob:  0.596592, 0.273438 (0.666 sec)
383.5... logprob:  0.590896, 0.265625 (0.668 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643603, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938784e-03 [7.491468e-09] 
Layer 'conv1' biases: 5.903706e-07 [1.384491e-10] 
Layer 'conv2' weights[0]: 7.926733e-03 [5.974589e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.466183e-10] 
Layer 'conv3' weights[0]: 7.924426e-03 [5.767207e-09] 
Layer 'conv3' biases: 4.914170e-06 [1.952273e-09] 
Layer 'conv4' weights[0]: 7.957266e-03 [5.793562e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.635749e-08] 
Layer 'conv5' weights[0]: 7.956597e-03 [9.247988e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.758222e-08] 
Layer 'fc6' weights[0]: 7.552723e-03 [1.064016e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.895698e-09] 
Layer 'fc7' weights[0]: 7.456270e-03 [1.313220e-07] 
Layer 'fc7' biases: 9.998528e-01 [1.160982e-07] 
Layer 'fc8' weights[0]: 5.847951e-04 [6.091673e-06] 
Layer 'fc8' biases: 1.659028e-01 [1.508895e-04] 
Train error last 27 batches: 0.635698
-------------------------------------------------------
Not saving because 0.643603 > 0.627087 (334.9: -0.00%)
======================================================= (5.077 sec)
383.6... logprob:  0.611414, 0.296875 (0.668 sec)
383.7... logprob:  0.643813, 0.343750 (0.667 sec)
383.8... logprob:  0.604911, 0.289062 (0.669 sec)
383.9... logprob:  0.638515, 0.335938 (0.669 sec)
383.10... logprob:  0.598098, 0.281250 (0.669 sec)
383.11... logprob:  0.638810, 0.335938 (0.667 sec)
383.12... logprob:  0.717188, 0.437500 (0.668 sec)
383.13... logprob:  0.657124, 0.359375 (0.668 sec)
383.14... logprob:  0.662737, 0.367188 (0.667 sec)
383.15... logprob:  0.685779, 0.398438 (0.667 sec)
383.16... logprob:  0.627075, 0.320312 (0.667 sec)
383.17... logprob:  0.638505, 0.335938 (0.667 sec)
383.18... logprob:  0.638221, 0.335938 (0.667 sec)
383.19... logprob:  0.632705, 0.328125 (0.668 sec)
383.20... logprob:  0.648905, 0.351562 (0.667 sec)
383.21... logprob:  0.643440, 0.343750 (0.667 sec)
383.22... logprob:  0.627930, 0.320312 (0.667 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643445, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938724e-03 [6.740834e-09] 
Layer 'conv1' biases: 5.917104e-07 [1.377156e-10] 
Layer 'conv2' weights[0]: 7.926677e-03 [6.088562e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.005696e-10] 
Layer 'conv3' weights[0]: 7.924355e-03 [5.288329e-09] 
Layer 'conv3' biases: 4.925482e-06 [1.621824e-09] 
Layer 'conv4' weights[0]: 7.957198e-03 [5.166979e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.002907e-08] 
Layer 'conv5' weights[0]: 7.956532e-03 [5.638634e-08] 
Layer 'conv5' biases: 1.000002e+00 [5.933621e-08] 
Layer 'fc6' weights[0]: 7.552655e-03 [7.298910e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.131147e-09] 
Layer 'fc7' weights[0]: 7.455653e-03 [9.070487e-08] 
Layer 'fc7' biases: 9.998524e-01 [7.291593e-08] 
Layer 'fc8' weights[0]: 5.713318e-04 [3.773957e-06] 
Layer 'fc8' biases: 1.657708e-01 [7.539601e-05] 
Train error last 27 batches: 0.635696
-------------------------------------------------------
Not saving because 0.643445 > 0.627087 (334.9: -0.00%)
======================================================= (5.108 sec)
383.23... logprob:  0.623036, 0.312500 (0.666 sec)
383.24... logprob:  0.577404, 0.242188 (0.664 sec)
383.25... logprob:  0.628085, 0.320312 (0.664 sec)
383.26... logprob:  0.674242, 0.390625 (0.667 sec)
383.27... logprob:  0.627962, 0.320312 (0.671 sec)
384.1... logprob:  0.679673, 0.398438 (0.670 sec)
384.2... logprob:  0.596906, 0.273438 (0.671 sec)
384.3... logprob:  0.653824, 0.359375 (0.670 sec)
384.4... logprob:  0.596588, 0.273438 (0.669 sec)
384.5... logprob:  0.590892, 0.265625 (0.671 sec)
384.6... logprob:  0.611413, 0.296875 (0.671 sec)
384.7... logprob:  0.643813, 0.343750 (0.668 sec)
384.8... logprob:  0.604912, 0.289062 (0.671 sec)
384.9... logprob:  0.638514, 0.335938 (0.672 sec)
384.10... logprob:  0.598102, 0.281250 (0.669 sec)
384.11... logprob:  0.638808, 0.335938 (0.671 sec)
384.12... logprob:  0.717173, 0.437500 (0.672 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.645088, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938657e-03 [6.927077e-09] 
Layer 'conv1' biases: 5.924147e-07 [8.332724e-11] 
Layer 'conv2' weights[0]: 7.926613e-03 [5.250270e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.177807e-10] 
Layer 'conv3' weights[0]: 7.924298e-03 [4.545716e-09] 
Layer 'conv3' biases: 4.928960e-06 [7.911350e-10] 
Layer 'conv4' weights[0]: 7.957137e-03 [4.403671e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.472945e-09] 
Layer 'conv5' weights[0]: 7.956465e-03 [9.334320e-09] 
Layer 'conv5' biases: 1.000002e+00 [8.780985e-09] 
Layer 'fc6' weights[0]: 7.552591e-03 [3.924250e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.663877e-10] 
Layer 'fc7' weights[0]: 7.455002e-03 [4.107901e-08] 
Layer 'fc7' biases: 9.998533e-01 [1.318690e-08] 
Layer 'fc8' weights[0]: 6.183352e-04 [5.951559e-07] 
Layer 'fc8' biases: 1.671741e-01 [2.027965e-06] 
Train error last 27 batches: 0.635695
-------------------------------------------------------
Not saving because 0.645088 > 0.627087 (334.9: -0.00%)
======================================================= (5.201 sec)
384.13... logprob:  0.657119, 0.359375 (0.671 sec)
384.14... logprob:  0.662733, 0.367188 (0.669 sec)
384.15... logprob:  0.685773, 0.398438 (0.670 sec)
384.16... logprob:  0.627075, 0.320312 (0.668 sec)
384.17... logprob:  0.638506, 0.335938 (0.670 sec)
384.18... logprob:  0.638221, 0.335938 (0.670 sec)
384.19... logprob:  0.632705, 0.328125 (0.669 sec)
384.20... logprob:  0.648906, 0.351562 (0.668 sec)
384.21... logprob:  0.643440, 0.343750 (0.670 sec)
384.22... logprob:  0.627928, 0.320312 (0.669 sec)
384.23... logprob:  0.623032, 0.312500 (0.670 sec)
384.24... logprob:  0.577389, 0.242188 (0.670 sec)
384.25... logprob:  0.628082, 0.320312 (0.667 sec)
384.26... logprob:  0.674248, 0.390625 (0.667 sec)
384.27... logprob:  0.627959, 0.320312 (0.669 sec)
385.1... logprob:  0.679680, 0.398438 (0.671 sec)
385.2... logprob:  0.596899, 0.273438 (0.670 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643473, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938599e-03 [6.879643e-09] 
Layer 'conv1' biases: 5.940249e-07 [7.193171e-11] 
Layer 'conv2' weights[0]: 7.926545e-03 [4.996959e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.868122e-10] 
Layer 'conv3' weights[0]: 7.924227e-03 [4.548176e-09] 
Layer 'conv3' biases: 4.943456e-06 [7.863286e-10] 
Layer 'conv4' weights[0]: 7.957074e-03 [4.452961e-09] 
Layer 'conv4' biases: 1.000001e+00 [4.519433e-09] 
Layer 'conv5' weights[0]: 7.956391e-03 [2.593236e-08] 
Layer 'conv5' biases: 1.000002e+00 [2.704673e-08] 
Layer 'fc6' weights[0]: 7.552521e-03 [4.791455e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.687246e-09] 
Layer 'fc7' weights[0]: 7.454383e-03 [5.541055e-08] 
Layer 'fc7' biases: 9.998525e-01 [3.181372e-08] 
Layer 'fc8' weights[0]: 5.753679e-04 [1.650897e-06] 
Layer 'fc8' biases: 1.663021e-01 [4.784638e-05] 
Train error last 27 batches: 0.635694
-------------------------------------------------------
Not saving because 0.643473 > 0.627087 (334.9: -0.00%)
======================================================= (5.149 sec)
385.3... logprob:  0.653826, 0.359375 (0.668 sec)
385.4... logprob:  0.596584, 0.273438 (0.669 sec)
385.5... logprob:  0.590890, 0.265625 (0.671 sec)
385.6... logprob:  0.611413, 0.296875 (0.671 sec)
385.7... logprob:  0.643812, 0.343750 (0.671 sec)
385.8... logprob:  0.604916, 0.289062 (0.672 sec)
385.9... logprob:  0.638514, 0.335938 (0.668 sec)
385.10... logprob:  0.598107, 0.281250 (0.671 sec)
385.11... logprob:  0.638804, 0.335938 (0.670 sec)
385.12... logprob:  0.717148, 0.437500 (0.670 sec)
385.13... logprob:  0.657111, 0.359375 (0.672 sec)
385.14... logprob:  0.662724, 0.367188 (0.671 sec)
385.15... logprob:  0.685763, 0.398438 (0.665 sec)
385.16... logprob:  0.627076, 0.320312 (0.669 sec)
385.17... logprob:  0.638506, 0.335938 (0.671 sec)
385.18... logprob:  0.638221, 0.335938 (0.667 sec)
385.19... logprob:  0.632705, 0.328125 (0.669 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643587, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938544e-03 [6.789463e-09] 
Layer 'conv1' biases: 5.951407e-07 [1.571759e-10] 
Layer 'conv2' weights[0]: 7.926469e-03 [6.564191e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.565277e-10] 
Layer 'conv3' weights[0]: 7.924160e-03 [5.693359e-09] 
Layer 'conv3' biases: 4.952044e-06 [2.051767e-09] 
Layer 'conv4' weights[0]: 7.957000e-03 [5.636362e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.398100e-08] 
Layer 'conv5' weights[0]: 7.956311e-03 [7.878593e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.322532e-08] 
Layer 'fc6' weights[0]: 7.552468e-03 [9.507620e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.536900e-09] 
Layer 'fc7' weights[0]: 7.453737e-03 [1.173535e-07] 
Layer 'fc7' biases: 9.998526e-01 [1.005399e-07] 
Layer 'fc8' weights[0]: 5.831309e-04 [5.257125e-06] 
Layer 'fc8' biases: 1.667250e-01 [1.061864e-04] 
Train error last 27 batches: 0.635692
-------------------------------------------------------
Not saving because 0.643587 > 0.627087 (334.9: -0.00%)
======================================================= (5.093 sec)
385.20... logprob:  0.648907, 0.351562 (0.668 sec)
385.21... logprob:  0.643441, 0.343750 (0.667 sec)
385.22... logprob:  0.627925, 0.320312 (0.666 sec)
385.23... logprob:  0.623028, 0.312500 (0.667 sec)
385.24... logprob:  0.577374, 0.242188 (0.665 sec)
385.25... logprob:  0.628079, 0.320312 (0.667 sec)
385.26... logprob:  0.674253, 0.390625 (0.667 sec)
385.27... logprob:  0.627956, 0.320312 (0.668 sec)
386.1... logprob:  0.679685, 0.398438 (0.668 sec)
386.2... logprob:  0.596894, 0.273438 (0.668 sec)
386.3... logprob:  0.653827, 0.359375 (0.666 sec)
386.4... logprob:  0.596580, 0.273438 (0.668 sec)
386.5... logprob:  0.590887, 0.265625 (0.668 sec)
386.6... logprob:  0.611413, 0.296875 (0.667 sec)
386.7... logprob:  0.643812, 0.343750 (0.668 sec)
386.8... logprob:  0.604918, 0.289062 (0.669 sec)
386.9... logprob:  0.638513, 0.335938 (0.669 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644418, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938485e-03 [6.712006e-09] 
Layer 'conv1' biases: 5.960664e-07 [1.199805e-10] 
Layer 'conv2' weights[0]: 7.926408e-03 [5.836583e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.063332e-10] 
Layer 'conv3' weights[0]: 7.924085e-03 [5.664409e-09] 
Layer 'conv3' biases: 4.958479e-06 [1.857197e-09] 
Layer 'conv4' weights[0]: 7.956931e-03 [5.764061e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.582486e-08] 
Layer 'conv5' weights[0]: 7.956259e-03 [8.894502e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.420182e-08] 
Layer 'fc6' weights[0]: 7.552406e-03 [1.036732e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.552061e-09] 
Layer 'fc7' weights[0]: 7.453090e-03 [1.270910e-07] 
Layer 'fc7' biases: 9.998531e-01 [1.110858e-07] 
Layer 'fc8' weights[0]: 6.065781e-04 [5.869962e-06] 
Layer 'fc8' biases: 1.675232e-01 [1.427908e-04] 
Train error last 27 batches: 0.635691
-------------------------------------------------------
Not saving because 0.644418 > 0.627087 (334.9: -0.00%)
======================================================= (5.079 sec)
386.10... logprob:  0.598113, 0.281250 (0.669 sec)
386.11... logprob:  0.638803, 0.335938 (0.668 sec)
386.12... logprob:  0.717126, 0.437500 (0.667 sec)
386.13... logprob:  0.657104, 0.359375 (0.668 sec)
386.14... logprob:  0.662717, 0.367188 (0.668 sec)
386.15... logprob:  0.685754, 0.398438 (0.667 sec)
386.16... logprob:  0.627076, 0.320312 (0.667 sec)
386.17... logprob:  0.638505, 0.335938 (0.667 sec)
386.18... logprob:  0.638221, 0.335938 (0.666 sec)
386.19... logprob:  0.632705, 0.328125 (0.668 sec)
386.20... logprob:  0.648908, 0.351562 (0.667 sec)
386.21... logprob:  0.643442, 0.343750 (0.670 sec)
386.22... logprob:  0.627923, 0.320312 (0.667 sec)
386.23... logprob:  0.623024, 0.312500 (0.664 sec)
386.24... logprob:  0.577358, 0.242188 (0.670 sec)
386.25... logprob:  0.628076, 0.320312 (0.665 sec)
386.26... logprob:  0.674260, 0.390625 (0.749 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643462, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938412e-03 [6.558144e-09] 
Layer 'conv1' biases: 5.975992e-07 [7.162460e-11] 
Layer 'conv2' weights[0]: 7.926343e-03 [5.036044e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.443660e-10] 
Layer 'conv3' weights[0]: 7.924018e-03 [4.418266e-09] 
Layer 'conv3' biases: 4.971871e-06 [6.039984e-10] 
Layer 'conv4' weights[0]: 7.956874e-03 [4.320330e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.398599e-09] 
Layer 'conv5' weights[0]: 7.956169e-03 [8.877850e-09] 
Layer 'conv5' biases: 1.000002e+00 [8.369400e-09] 
Layer 'fc6' weights[0]: 7.552338e-03 [3.903732e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.590298e-10] 
Layer 'fc7' weights[0]: 7.452442e-03 [3.999886e-08] 
Layer 'fc7' biases: 9.998523e-01 [1.044087e-08] 
Layer 'fc8' weights[0]: 5.733286e-04 [5.076461e-07] 
Layer 'fc8' biases: 1.668938e-01 [2.314749e-05] 
Train error last 27 batches: 0.635689
-------------------------------------------------------
Not saving because 0.643462 > 0.627087 (334.9: -0.00%)
======================================================= (5.200 sec)
386.27... logprob:  0.627954, 0.320312 (0.667 sec)
387.1... logprob:  0.679691, 0.398438 (0.669 sec)
387.2... logprob:  0.596887, 0.273438 (0.668 sec)
387.3... logprob:  0.653828, 0.359375 (0.668 sec)
387.4... logprob:  0.596575, 0.273438 (0.667 sec)
387.5... logprob:  0.590884, 0.265625 (0.668 sec)
387.6... logprob:  0.611413, 0.296875 (0.667 sec)
387.7... logprob:  0.643812, 0.343750 (0.667 sec)
387.8... logprob:  0.604921, 0.289062 (0.669 sec)
387.9... logprob:  0.638512, 0.335938 (0.668 sec)
387.10... logprob:  0.598119, 0.281250 (0.668 sec)
387.11... logprob:  0.638799, 0.335938 (0.667 sec)
387.12... logprob:  0.717103, 0.437500 (0.668 sec)
387.13... logprob:  0.657095, 0.359375 (0.669 sec)
387.14... logprob:  0.662710, 0.367188 (0.668 sec)
387.15... logprob:  0.685744, 0.398438 (0.667 sec)
387.16... logprob:  0.627076, 0.320312 (0.667 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644048, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938354e-03 [6.957518e-09] 
Layer 'conv1' biases: 5.985458e-07 [1.841307e-10] 
Layer 'conv2' weights[0]: 7.926288e-03 [7.160578e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.217790e-10] 
Layer 'conv3' weights[0]: 7.923952e-03 [6.215368e-09] 
Layer 'conv3' biases: 4.978447e-06 [2.525691e-09] 
Layer 'conv4' weights[0]: 7.956804e-03 [6.226052e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.810406e-08] 
Layer 'conv5' weights[0]: 7.956120e-03 [1.016528e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.075494e-07] 
Layer 'fc6' weights[0]: 7.552283e-03 [1.151573e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.092876e-08] 
Layer 'fc7' weights[0]: 7.451816e-03 [1.415256e-07] 
Layer 'fc7' biases: 9.998528e-01 [1.275424e-07] 
Layer 'fc8' weights[0]: 5.981151e-04 [6.751933e-06] 
Layer 'fc8' biases: 1.677441e-01 [1.357622e-04] 
Train error last 27 batches: 0.635687
-------------------------------------------------------
Not saving because 0.644048 > 0.627087 (334.9: -0.00%)
======================================================= (5.078 sec)
387.17... logprob:  0.638505, 0.335938 (0.666 sec)
387.18... logprob:  0.638220, 0.335938 (0.663 sec)
387.19... logprob:  0.632705, 0.328125 (0.667 sec)
387.20... logprob:  0.648909, 0.351562 (0.664 sec)
387.21... logprob:  0.643442, 0.343750 (0.665 sec)
387.22... logprob:  0.627920, 0.320312 (0.666 sec)
387.23... logprob:  0.623021, 0.312500 (0.667 sec)
387.24... logprob:  0.577345, 0.242188 (0.667 sec)
387.25... logprob:  0.628073, 0.320312 (0.667 sec)
387.26... logprob:  0.674266, 0.390625 (0.667 sec)
387.27... logprob:  0.627952, 0.320312 (0.668 sec)
388.1... logprob:  0.679697, 0.398438 (0.668 sec)
388.2... logprob:  0.596880, 0.273438 (0.668 sec)
388.3... logprob:  0.653830, 0.359375 (0.666 sec)
388.4... logprob:  0.596571, 0.273438 (0.668 sec)
388.5... logprob:  0.590881, 0.265625 (0.668 sec)
388.6... logprob:  0.611412, 0.296875 (0.668 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643754, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938283e-03 [7.381416e-09] 
Layer 'conv1' biases: 5.997924e-07 [1.621344e-10] 
Layer 'conv2' weights[0]: 7.926231e-03 [6.263455e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.596344e-10] 
Layer 'conv3' weights[0]: 7.923889e-03 [6.045872e-09] 
Layer 'conv3' biases: 4.988758e-06 [2.209748e-09] 
Layer 'conv4' weights[0]: 7.956731e-03 [6.110088e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.901313e-08] 
Layer 'conv5' weights[0]: 7.956056e-03 [1.067081e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.126883e-07] 
Layer 'fc6' weights[0]: 7.552208e-03 [1.205868e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.148160e-08] 
Layer 'fc7' weights[0]: 7.451172e-03 [1.485185e-07] 
Layer 'fc7' biases: 9.998526e-01 [1.347792e-07] 
Layer 'fc8' weights[0]: 5.894154e-04 [7.053875e-06] 
Layer 'fc8' biases: 1.677230e-01 [1.734279e-04] 
Train error last 27 batches: 0.635686
-------------------------------------------------------
Not saving because 0.643754 > 0.627087 (334.9: -0.00%)
======================================================= (5.068 sec)
388.7... logprob:  0.643811, 0.343750 (0.668 sec)
388.8... logprob:  0.604922, 0.289062 (0.669 sec)
388.9... logprob:  0.638511, 0.335938 (0.669 sec)
388.10... logprob:  0.598122, 0.281250 (0.667 sec)
388.11... logprob:  0.638797, 0.335938 (0.668 sec)
388.12... logprob:  0.717085, 0.437500 (0.667 sec)
388.13... logprob:  0.657089, 0.359375 (0.663 sec)
388.14... logprob:  0.662703, 0.367188 (0.666 sec)
388.15... logprob:  0.685736, 0.398438 (0.667 sec)
388.16... logprob:  0.627077, 0.320312 (0.667 sec)
388.17... logprob:  0.638505, 0.335938 (0.667 sec)
388.18... logprob:  0.638221, 0.335938 (0.666 sec)
388.19... logprob:  0.632705, 0.328125 (0.667 sec)
388.20... logprob:  0.648910, 0.351562 (0.667 sec)
388.21... logprob:  0.643442, 0.343750 (0.666 sec)
388.22... logprob:  0.627918, 0.320312 (0.664 sec)
388.23... logprob:  0.623016, 0.312500 (0.666 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643440, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938219e-03 [6.337340e-09] 
Layer 'conv1' biases: 6.012255e-07 [1.079942e-10] 
Layer 'conv2' weights[0]: 7.926170e-03 [5.373166e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.240224e-10] 
Layer 'conv3' weights[0]: 7.923813e-03 [4.758177e-09] 
Layer 'conv3' biases: 5.000807e-06 [1.104855e-09] 
Layer 'conv4' weights[0]: 7.956679e-03 [4.630120e-09] 
Layer 'conv4' biases: 1.000001e+00 [5.759992e-09] 
Layer 'conv5' weights[0]: 7.955992e-03 [3.257956e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.411958e-08] 
Layer 'fc6' weights[0]: 7.552139e-03 [5.254894e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.525871e-09] 
Layer 'fc7' weights[0]: 7.450539e-03 [6.351311e-08] 
Layer 'fc7' biases: 9.998521e-01 [4.214074e-08] 
Layer 'fc8' weights[0]: 5.681873e-04 [2.167121e-06] 
Layer 'fc8' biases: 1.673814e-01 [3.844080e-05] 
Train error last 27 batches: 0.635684
-------------------------------------------------------
Not saving because 0.643440 > 0.627087 (334.9: -0.00%)
======================================================= (5.128 sec)
388.24... logprob:  0.577333, 0.242188 (0.666 sec)
388.25... logprob:  0.628070, 0.320312 (0.667 sec)
388.26... logprob:  0.674269, 0.390625 (0.667 sec)
388.27... logprob:  0.627950, 0.320312 (0.668 sec)
389.1... logprob:  0.679700, 0.398438 (0.668 sec)
389.2... logprob:  0.596875, 0.273438 (0.667 sec)
389.3... logprob:  0.653831, 0.359375 (0.668 sec)
389.4... logprob:  0.596567, 0.273438 (0.666 sec)
389.5... logprob:  0.590879, 0.265625 (0.668 sec)
389.6... logprob:  0.611411, 0.296875 (0.668 sec)
389.7... logprob:  0.643811, 0.343750 (0.668 sec)
389.8... logprob:  0.604925, 0.289062 (0.669 sec)
389.9... logprob:  0.638510, 0.335938 (0.669 sec)
389.10... logprob:  0.598127, 0.281250 (0.668 sec)
389.11... logprob:  0.638795, 0.335938 (0.668 sec)
389.12... logprob:  0.717066, 0.437500 (0.667 sec)
389.13... logprob:  0.657084, 0.359375 (0.668 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644921, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938150e-03 [6.534046e-09] 
Layer 'conv1' biases: 6.019204e-07 [9.949835e-11] 
Layer 'conv2' weights[0]: 7.926108e-03 [5.411489e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.469686e-10] 
Layer 'conv3' weights[0]: 7.923752e-03 [4.753779e-09] 
Layer 'conv3' biases: 5.004448e-06 [1.233369e-09] 
Layer 'conv4' weights[0]: 7.956603e-03 [4.665527e-09] 
Layer 'conv4' biases: 1.000001e+00 [6.624257e-09] 
Layer 'conv5' weights[0]: 7.955928e-03 [3.713299e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.905460e-08] 
Layer 'fc6' weights[0]: 7.552075e-03 [5.574697e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.005797e-09] 
Layer 'fc7' weights[0]: 7.449886e-03 [6.818320e-08] 
Layer 'fc7' biases: 9.998532e-01 [4.750816e-08] 
Layer 'fc8' weights[0]: 6.142660e-04 [2.491144e-06] 
Layer 'fc8' biases: 1.687762e-01 [4.026399e-05] 
Train error last 27 batches: 0.635683
-------------------------------------------------------
Not saving because 0.644921 > 0.627087 (334.9: -0.00%)
======================================================= (5.135 sec)
389.14... logprob:  0.662697, 0.367188 (0.668 sec)
389.15... logprob:  0.685729, 0.398438 (0.667 sec)
389.16... logprob:  0.627076, 0.320312 (0.666 sec)
389.17... logprob:  0.638505, 0.335938 (0.668 sec)
389.18... logprob:  0.638220, 0.335938 (0.662 sec)
389.19... logprob:  0.632704, 0.328125 (0.667 sec)
389.20... logprob:  0.648911, 0.351562 (0.667 sec)
389.21... logprob:  0.643443, 0.343750 (0.666 sec)
389.22... logprob:  0.627916, 0.320312 (0.667 sec)
389.23... logprob:  0.623013, 0.312500 (0.667 sec)
389.24... logprob:  0.577320, 0.242188 (0.663 sec)
389.25... logprob:  0.628068, 0.320312 (0.666 sec)
389.26... logprob:  0.674275, 0.390625 (0.667 sec)
389.27... logprob:  0.627948, 0.320312 (0.668 sec)
390.1... logprob:  0.679705, 0.398438 (0.668 sec)
390.2... logprob:  0.596870, 0.273438 (0.663 sec)
390.3... logprob:  0.653832, 0.359375 (0.666 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643480, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938082e-03 [6.740408e-09] 
Layer 'conv1' biases: 6.034974e-07 [6.679127e-11] 
Layer 'conv2' weights[0]: 7.926049e-03 [5.003784e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.543822e-10] 
Layer 'conv3' weights[0]: 7.923686e-03 [4.447104e-09] 
Layer 'conv3' biases: 5.018401e-06 [6.287385e-10] 
Layer 'conv4' weights[0]: 7.956540e-03 [4.335098e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.715749e-09] 
Layer 'conv5' weights[0]: 7.955861e-03 [1.090262e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.077999e-08] 
Layer 'fc6' weights[0]: 7.552011e-03 [3.974451e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.091463e-09] 
Layer 'fc7' weights[0]: 7.449229e-03 [4.154909e-08] 
Layer 'fc7' biases: 9.998522e-01 [1.321815e-08] 
Layer 'fc8' weights[0]: 5.745789e-04 [6.745511e-07] 
Layer 'fc8' biases: 1.679685e-01 [2.278388e-05] 
Train error last 27 batches: 0.635682
-------------------------------------------------------
Not saving because 0.643480 > 0.627087 (334.9: -0.00%)
======================================================= (5.189 sec)
390.4... logprob:  0.596564, 0.273438 (0.667 sec)
390.5... logprob:  0.590876, 0.265625 (0.667 sec)
390.6... logprob:  0.611411, 0.296875 (0.668 sec)
390.7... logprob:  0.643810, 0.343750 (0.667 sec)
390.8... logprob:  0.604926, 0.289062 (0.669 sec)
390.9... logprob:  0.638508, 0.335938 (0.668 sec)
390.10... logprob:  0.598132, 0.281250 (0.668 sec)
390.11... logprob:  0.638793, 0.335938 (0.669 sec)
390.12... logprob:  0.717049, 0.437500 (0.666 sec)
390.13... logprob:  0.657077, 0.359375 (0.669 sec)
390.14... logprob:  0.662691, 0.367188 (0.668 sec)
390.15... logprob:  0.685722, 0.398438 (0.667 sec)
390.16... logprob:  0.627077, 0.320312 (0.667 sec)
390.17... logprob:  0.638505, 0.335938 (0.668 sec)
390.18... logprob:  0.638220, 0.335938 (0.667 sec)
390.19... logprob:  0.632703, 0.328125 (0.667 sec)
390.20... logprob:  0.648912, 0.351562 (0.667 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643513, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938017e-03 [6.815036e-09] 
Layer 'conv1' biases: 6.046829e-07 [1.635154e-10] 
Layer 'conv2' weights[0]: 7.925982e-03 [6.518922e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.723970e-10] 
Layer 'conv3' weights[0]: 7.923612e-03 [5.700618e-09] 
Layer 'conv3' biases: 5.027744e-06 [2.101317e-09] 
Layer 'conv4' weights[0]: 7.956478e-03 [5.630262e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.439141e-08] 
Layer 'conv5' weights[0]: 7.955793e-03 [8.112268e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.551589e-08] 
Layer 'fc6' weights[0]: 7.551957e-03 [9.695329e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.730670e-09] 
Layer 'fc7' weights[0]: 7.448600e-03 [1.196801e-07] 
Layer 'fc7' biases: 9.998522e-01 [1.030498e-07] 
Layer 'fc8' weights[0]: 5.771162e-04 [5.363009e-06] 
Layer 'fc8' biases: 1.682574e-01 [1.112872e-04] 
Train error last 27 batches: 0.635680
-------------------------------------------------------
Not saving because 0.643513 > 0.627087 (334.9: -0.00%)
======================================================= (5.076 sec)
390.21... logprob:  0.643444, 0.343750 (0.667 sec)
390.22... logprob:  0.627914, 0.320312 (0.670 sec)
390.23... logprob:  0.623009, 0.312500 (0.662 sec)
390.24... logprob:  0.577308, 0.242188 (0.663 sec)
390.25... logprob:  0.628065, 0.320312 (0.668 sec)
390.26... logprob:  0.674279, 0.390625 (0.752 sec)
390.27... logprob:  0.627946, 0.320312 (0.668 sec)
391.1... logprob:  0.679710, 0.398438 (0.668 sec)
391.2... logprob:  0.596864, 0.273438 (0.667 sec)
391.3... logprob:  0.653833, 0.359375 (0.668 sec)
391.4... logprob:  0.596560, 0.273438 (0.668 sec)
391.5... logprob:  0.590873, 0.265625 (0.668 sec)
391.6... logprob:  0.611411, 0.296875 (0.668 sec)
391.7... logprob:  0.643810, 0.343750 (0.667 sec)
391.8... logprob:  0.604928, 0.289062 (0.669 sec)
391.9... logprob:  0.638508, 0.335938 (0.667 sec)
391.10... logprob:  0.598136, 0.281250 (0.669 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644762, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937958e-03 [7.115684e-09] 
Layer 'conv1' biases: 6.054967e-07 [1.468705e-10] 
Layer 'conv2' weights[0]: 7.925915e-03 [6.317500e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.535955e-10] 
Layer 'conv3' weights[0]: 7.923550e-03 [6.127802e-09] 
Layer 'conv3' biases: 5.032644e-06 [2.251358e-09] 
Layer 'conv4' weights[0]: 7.956405e-03 [6.264982e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.938886e-08] 
Layer 'conv5' weights[0]: 7.955736e-03 [1.092668e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.156227e-07] 
Layer 'fc6' weights[0]: 7.551884e-03 [1.218837e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.162400e-08] 
Layer 'fc7' weights[0]: 7.447939e-03 [1.483055e-07] 
Layer 'fc7' biases: 9.998530e-01 [1.344797e-07] 
Layer 'fc8' weights[0]: 6.111998e-04 [7.132460e-06] 
Layer 'fc8' biases: 1.693310e-01 [1.701156e-04] 
Train error last 27 batches: 0.635680
-------------------------------------------------------
Not saving because 0.644762 > 0.627087 (334.9: -0.00%)
======================================================= (5.077 sec)
391.11... logprob:  0.638790, 0.335938 (0.667 sec)
391.12... logprob:  0.717029, 0.437500 (0.668 sec)
391.13... logprob:  0.657071, 0.359375 (0.668 sec)
391.14... logprob:  0.662685, 0.367188 (0.667 sec)
391.15... logprob:  0.685714, 0.398438 (0.666 sec)
391.16... logprob:  0.627077, 0.320312 (0.667 sec)
391.17... logprob:  0.638505, 0.335938 (0.668 sec)
391.18... logprob:  0.638220, 0.335938 (0.666 sec)
391.19... logprob:  0.632703, 0.328125 (0.668 sec)
391.20... logprob:  0.648914, 0.351562 (0.667 sec)
391.21... logprob:  0.643444, 0.343750 (0.667 sec)
391.22... logprob:  0.627912, 0.320312 (0.667 sec)
391.23... logprob:  0.623005, 0.312500 (0.667 sec)
391.24... logprob:  0.577293, 0.242188 (0.667 sec)
391.25... logprob:  0.628062, 0.320312 (0.666 sec)
391.26... logprob:  0.674286, 0.390625 (0.666 sec)
391.27... logprob:  0.627944, 0.320312 (0.668 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643472, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937891e-03 [6.636851e-09] 
Layer 'conv1' biases: 6.070746e-07 [7.044105e-11] 
Layer 'conv2' weights[0]: 7.925847e-03 [4.908868e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.566928e-10] 
Layer 'conv3' weights[0]: 7.923488e-03 [4.440787e-09] 
Layer 'conv3' biases: 5.046647e-06 [6.835712e-10] 
Layer 'conv4' weights[0]: 7.956340e-03 [4.371815e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.461028e-09] 
Layer 'conv5' weights[0]: 7.955684e-03 [2.008431e-08] 
Layer 'conv5' biases: 1.000002e+00 [2.072618e-08] 
Layer 'fc6' weights[0]: 7.551815e-03 [4.420993e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.086753e-09] 
Layer 'fc7' weights[0]: 7.447278e-03 [4.966020e-08] 
Layer 'fc7' biases: 9.998522e-01 [2.488308e-08] 
Layer 'fc8' weights[0]: 5.731353e-04 [1.253871e-06] 
Layer 'fc8' biases: 1.685746e-01 [4.048265e-05] 
Train error last 27 batches: 0.635677
-------------------------------------------------------
Not saving because 0.643472 > 0.627087 (334.9: -0.00%)
======================================================= (5.170 sec)
392.1... logprob:  0.679716, 0.398438 (0.667 sec)
392.2... logprob:  0.596858, 0.273438 (0.667 sec)
392.3... logprob:  0.653835, 0.359375 (0.668 sec)
392.4... logprob:  0.596556, 0.273438 (0.668 sec)
392.5... logprob:  0.590871, 0.265625 (0.667 sec)
392.6... logprob:  0.611411, 0.296875 (0.668 sec)
392.7... logprob:  0.643810, 0.343750 (0.668 sec)
392.8... logprob:  0.604931, 0.289062 (0.669 sec)
392.9... logprob:  0.638506, 0.335938 (0.668 sec)
392.10... logprob:  0.598142, 0.281250 (0.668 sec)
392.11... logprob:  0.638787, 0.335938 (0.668 sec)
392.12... logprob:  0.717007, 0.437500 (0.668 sec)
392.13... logprob:  0.657064, 0.359375 (0.668 sec)
392.14... logprob:  0.662676, 0.367188 (0.667 sec)
392.15... logprob:  0.685703, 0.398438 (0.668 sec)
392.16... logprob:  0.627077, 0.320312 (0.669 sec)
392.17... logprob:  0.638504, 0.335938 (0.667 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643842, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937825e-03 [6.474726e-09] 
Layer 'conv1' biases: 6.080815e-07 [1.696721e-10] 
Layer 'conv2' weights[0]: 7.925775e-03 [6.824531e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.614829e-10] 
Layer 'conv3' weights[0]: 7.923420e-03 [5.997771e-09] 
Layer 'conv3' biases: 5.053930e-06 [2.343586e-09] 
Layer 'conv4' weights[0]: 7.956271e-03 [6.034312e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.721128e-08] 
Layer 'conv5' weights[0]: 7.955603e-03 [9.665668e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.021269e-07] 
Layer 'fc6' weights[0]: 7.551746e-03 [1.103639e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.040445e-08] 
Layer 'fc7' weights[0]: 7.446642e-03 [1.355769e-07] 
Layer 'fc7' biases: 9.998525e-01 [1.211809e-07] 
Layer 'fc8' weights[0]: 5.909654e-04 [6.390004e-06] 
Layer 'fc8' biases: 1.692511e-01 [1.302887e-04] 
Train error last 27 batches: 0.635675
-------------------------------------------------------
Not saving because 0.643842 > 0.627087 (334.9: -0.00%)
======================================================= (5.066 sec)
392.18... logprob:  0.638219, 0.335938 (0.664 sec)
392.19... logprob:  0.632702, 0.328125 (0.667 sec)
392.20... logprob:  0.648913, 0.351562 (0.667 sec)
392.21... logprob:  0.643444, 0.343750 (0.664 sec)
392.22... logprob:  0.627909, 0.320312 (0.667 sec)
392.23... logprob:  0.623003, 0.312500 (0.666 sec)
392.24... logprob:  0.577284, 0.242188 (0.664 sec)
392.25... logprob:  0.628060, 0.320312 (0.670 sec)
392.26... logprob:  0.674289, 0.390625 (0.667 sec)
392.27... logprob:  0.627942, 0.320312 (0.667 sec)
393.1... logprob:  0.679720, 0.398438 (0.664 sec)
393.2... logprob:  0.596853, 0.273438 (0.666 sec)
393.3... logprob:  0.653836, 0.359375 (0.668 sec)
393.4... logprob:  0.596551, 0.273438 (0.668 sec)
393.5... logprob:  0.590866, 0.265625 (0.668 sec)
393.6... logprob:  0.611408, 0.296875 (0.668 sec)
393.7... logprob:  0.643810, 0.343750 (0.668 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643914, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937755e-03 [6.865366e-09] 
Layer 'conv1' biases: 6.092212e-07 [1.270881e-10] 
Layer 'conv2' weights[0]: 7.925711e-03 [5.817736e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.141117e-10] 
Layer 'conv3' weights[0]: 7.923346e-03 [5.618963e-09] 
Layer 'conv3' biases: 5.062949e-06 [1.862241e-09] 
Layer 'conv4' weights[0]: 7.956201e-03 [5.678316e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.576895e-08] 
Layer 'conv5' weights[0]: 7.955532e-03 [8.847602e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.349194e-08] 
Layer 'fc6' weights[0]: 7.551678e-03 [1.028022e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.454292e-09] 
Layer 'fc7' weights[0]: 7.446006e-03 [1.264317e-07] 
Layer 'fc7' biases: 9.998525e-01 [1.104308e-07] 
Layer 'fc8' weights[0]: 5.929557e-04 [5.765022e-06] 
Layer 'fc8' biases: 1.695010e-01 [1.437464e-04] 
Train error last 27 batches: 0.635674
-------------------------------------------------------
Not saving because 0.643914 > 0.627087 (334.9: -0.00%)
======================================================= (5.088 sec)
393.8... logprob:  0.604931, 0.289062 (0.666 sec)
393.9... logprob:  0.638506, 0.335938 (0.665 sec)
393.10... logprob:  0.598143, 0.281250 (0.667 sec)
393.11... logprob:  0.638786, 0.335938 (0.669 sec)
393.12... logprob:  0.716997, 0.437500 (0.669 sec)
393.13... logprob:  0.657060, 0.359375 (0.668 sec)
393.14... logprob:  0.662673, 0.367188 (0.667 sec)
393.15... logprob:  0.685700, 0.398438 (0.667 sec)
393.16... logprob:  0.627077, 0.320312 (0.667 sec)
393.17... logprob:  0.638504, 0.335938 (0.668 sec)
393.18... logprob:  0.638220, 0.335938 (0.667 sec)
393.19... logprob:  0.632702, 0.328125 (0.664 sec)
393.20... logprob:  0.648915, 0.351562 (0.667 sec)
393.21... logprob:  0.643445, 0.343750 (0.667 sec)
393.22... logprob:  0.627908, 0.320312 (0.664 sec)
393.23... logprob:  0.622999, 0.312500 (0.667 sec)
393.24... logprob:  0.577270, 0.242188 (0.670 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643446, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937681e-03 [6.517026e-09] 
Layer 'conv1' biases: 6.106843e-07 [6.034392e-11] 
Layer 'conv2' weights[0]: 7.925649e-03 [4.881856e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.037971e-10] 
Layer 'conv3' weights[0]: 7.923280e-03 [4.531530e-09] 
Layer 'conv3' biases: 5.075559e-06 [8.461554e-10] 
Layer 'conv4' weights[0]: 7.956139e-03 [4.472642e-09] 
Layer 'conv4' biases: 1.000001e+00 [6.005466e-09] 
Layer 'conv5' weights[0]: 7.955482e-03 [3.352298e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.519029e-08] 
Layer 'fc6' weights[0]: 7.551613e-03 [5.280913e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.536971e-09] 
Layer 'fc7' weights[0]: 7.445341e-03 [6.347760e-08] 
Layer 'fc7' biases: 9.998522e-01 [4.182044e-08] 
Layer 'fc8' weights[0]: 5.687671e-04 [2.124157e-06] 
Layer 'fc8' biases: 1.690835e-01 [6.578303e-05] 
Train error last 27 batches: 0.635673
-------------------------------------------------------
Not saving because 0.643446 > 0.627087 (334.9: -0.00%)
======================================================= (5.136 sec)
393.25... logprob:  0.628058, 0.320312 (0.667 sec)
393.26... logprob:  0.674294, 0.390625 (0.667 sec)
393.27... logprob:  0.627941, 0.320312 (0.668 sec)
394.1... logprob:  0.679725, 0.398438 (0.668 sec)
394.2... logprob:  0.596848, 0.273438 (0.668 sec)
394.3... logprob:  0.653837, 0.359375 (0.668 sec)
394.4... logprob:  0.596549, 0.273438 (0.667 sec)
394.5... logprob:  0.590866, 0.265625 (0.668 sec)
394.6... logprob:  0.611411, 0.296875 (0.668 sec)
394.7... logprob:  0.643809, 0.343750 (0.669 sec)
394.8... logprob:  0.604935, 0.289062 (0.668 sec)
394.9... logprob:  0.638505, 0.335938 (0.667 sec)
394.10... logprob:  0.598150, 0.281250 (0.668 sec)
394.11... logprob:  0.638783, 0.335938 (0.667 sec)
394.12... logprob:  0.716971, 0.437500 (0.668 sec)
394.13... logprob:  0.657053, 0.359375 (0.665 sec)
394.14... logprob:  0.662665, 0.367188 (0.667 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644661, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937616e-03 [6.775867e-09] 
Layer 'conv1' biases: 6.114667e-07 [1.493401e-10] 
Layer 'conv2' weights[0]: 7.925589e-03 [6.190127e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.665786e-10] 
Layer 'conv3' weights[0]: 7.923210e-03 [5.406098e-09] 
Layer 'conv3' biases: 5.079744e-06 [1.845642e-09] 
Layer 'conv4' weights[0]: 7.956069e-03 [5.360478e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.202447e-08] 
Layer 'conv5' weights[0]: 7.955410e-03 [6.762350e-08] 
Layer 'conv5' biases: 1.000002e+00 [7.145858e-08] 
Layer 'fc6' weights[0]: 7.551551e-03 [8.299230e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.250347e-09] 
Layer 'fc7' weights[0]: 7.444734e-03 [1.022468e-07] 
Layer 'fc7' biases: 9.998528e-01 [8.467126e-08] 
Layer 'fc8' weights[0]: 6.085475e-04 [4.457506e-06] 
Layer 'fc8' biases: 1.703223e-01 [8.476499e-05] 
Train error last 27 batches: 0.635672
-------------------------------------------------------
Not saving because 0.644661 > 0.627087 (334.9: -0.00%)
======================================================= (5.082 sec)
394.15... logprob:  0.685689, 0.398438 (0.667 sec)
394.16... logprob:  0.627077, 0.320312 (0.666 sec)
394.17... logprob:  0.638504, 0.335938 (0.668 sec)
394.18... logprob:  0.638220, 0.335938 (0.666 sec)
394.19... logprob:  0.632702, 0.328125 (0.667 sec)
394.20... logprob:  0.648915, 0.351562 (0.663 sec)
394.21... logprob:  0.643444, 0.343750 (0.664 sec)
394.22... logprob:  0.627905, 0.320312 (0.667 sec)
394.23... logprob:  0.622996, 0.312500 (0.667 sec)
394.24... logprob:  0.577258, 0.242188 (0.667 sec)
394.25... logprob:  0.628055, 0.320312 (0.667 sec)
394.26... logprob:  0.674299, 0.390625 (0.667 sec)
394.27... logprob:  0.627938, 0.320312 (0.666 sec)
395.1... logprob:  0.679730, 0.398438 (0.672 sec)
395.2... logprob:  0.596841, 0.273438 (0.669 sec)
395.3... logprob:  0.653838, 0.359375 (0.669 sec)
395.4... logprob:  0.596543, 0.273438 (0.666 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643514, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937550e-03 [6.927485e-09] 
Layer 'conv1' biases: 6.129630e-07 [8.894366e-11] 
Layer 'conv2' weights[0]: 7.925528e-03 [5.307585e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.590726e-10] 
Layer 'conv3' weights[0]: 7.923151e-03 [4.945271e-09] 
Layer 'conv3' biases: 5.093286e-06 [1.204925e-09] 
Layer 'conv4' weights[0]: 7.956000e-03 [4.887633e-09] 
Layer 'conv4' biases: 1.000001e+00 [8.895343e-09] 
Layer 'conv5' weights[0]: 7.955353e-03 [5.029189e-08] 
Layer 'conv5' biases: 1.000002e+00 [5.295150e-08] 
Layer 'fc6' weights[0]: 7.551491e-03 [6.662524e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.354429e-09] 
Layer 'fc7' weights[0]: 7.444086e-03 [8.170493e-08] 
Layer 'fc7' biases: 9.998521e-01 [6.260019e-08] 
Layer 'fc8' weights[0]: 5.760537e-04 [3.252517e-06] 
Layer 'fc8' biases: 1.696851e-01 [8.580769e-05] 
Train error last 27 batches: 0.635670
-------------------------------------------------------
Not saving because 0.643514 > 0.627087 (334.9: -0.00%)
======================================================= (5.114 sec)
395.5... logprob:  0.590861, 0.265625 (0.666 sec)
395.6... logprob:  0.611408, 0.296875 (0.667 sec)
395.7... logprob:  0.643809, 0.343750 (0.666 sec)
395.8... logprob:  0.604935, 0.289062 (0.666 sec)
395.9... logprob:  0.638505, 0.335938 (0.666 sec)
395.10... logprob:  0.598151, 0.281250 (0.668 sec)
395.11... logprob:  0.638782, 0.335938 (0.668 sec)
395.12... logprob:  0.716959, 0.437500 (0.668 sec)
395.13... logprob:  0.657048, 0.359375 (0.668 sec)
395.14... logprob:  0.662661, 0.367188 (0.668 sec)
395.15... logprob:  0.685686, 0.398438 (0.668 sec)
395.16... logprob:  0.627078, 0.320312 (0.666 sec)
395.17... logprob:  0.638503, 0.335938 (0.668 sec)
395.18... logprob:  0.638221, 0.335938 (0.667 sec)
395.19... logprob:  0.632702, 0.328125 (0.667 sec)
395.20... logprob:  0.648918, 0.351562 (0.667 sec)
395.21... logprob:  0.643445, 0.343750 (0.666 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643467, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937488e-03 [6.854128e-09] 
Layer 'conv1' biases: 6.142220e-07 [1.562971e-10] 
Layer 'conv2' weights[0]: 7.925465e-03 [6.511120e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.427787e-10] 
Layer 'conv3' weights[0]: 7.923081e-03 [5.670483e-09] 
Layer 'conv3' biases: 5.103602e-06 [2.025929e-09] 
Layer 'conv4' weights[0]: 7.955935e-03 [5.583083e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.354945e-08] 
Layer 'conv5' weights[0]: 7.955286e-03 [7.616101e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.029334e-08] 
Layer 'fc6' weights[0]: 7.551422e-03 [9.226685e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.237355e-09] 
Layer 'fc7' weights[0]: 7.443423e-03 [1.139351e-07] 
Layer 'fc7' biases: 9.998521e-01 [9.713608e-08] 
Layer 'fc8' weights[0]: 5.714674e-04 [5.018269e-06] 
Layer 'fc8' biases: 1.697826e-01 [1.058961e-04] 
Train error last 27 batches: 0.635669
-------------------------------------------------------
Not saving because 0.643467 > 0.627087 (334.9: -0.00%)
======================================================= (5.075 sec)
395.22... logprob:  0.627903, 0.320312 (0.667 sec)
395.23... logprob:  0.622991, 0.312500 (0.666 sec)
395.24... logprob:  0.577242, 0.242188 (0.667 sec)
395.25... logprob:  0.628052, 0.320312 (0.667 sec)
395.26... logprob:  0.674305, 0.390625 (0.667 sec)
395.27... logprob:  0.627937, 0.320312 (0.664 sec)
396.1... logprob:  0.679735, 0.398438 (0.668 sec)
396.2... logprob:  0.596837, 0.273438 (0.669 sec)
396.3... logprob:  0.653840, 0.359375 (0.667 sec)
396.4... logprob:  0.596542, 0.273438 (0.665 sec)
396.5... logprob:  0.590861, 0.265625 (0.668 sec)
396.6... logprob:  0.611410, 0.296875 (0.668 sec)
396.7... logprob:  0.643808, 0.343750 (0.668 sec)
396.8... logprob:  0.604941, 0.289062 (0.669 sec)
396.9... logprob:  0.638503, 0.335938 (0.669 sec)
396.10... logprob:  0.598161, 0.281250 (0.668 sec)
396.11... logprob:  0.638777, 0.335938 (0.669 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.645067, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937421e-03 [6.881076e-09] 
Layer 'conv1' biases: 6.149655e-07 [1.217008e-10] 
Layer 'conv2' weights[0]: 7.925398e-03 [5.783006e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.796237e-10] 
Layer 'conv3' weights[0]: 7.923015e-03 [5.580924e-09] 
Layer 'conv3' biases: 5.106992e-06 [1.803941e-09] 
Layer 'conv4' weights[0]: 7.955864e-03 [5.664232e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.525703e-08] 
Layer 'conv5' weights[0]: 7.955218e-03 [8.644042e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.168406e-08] 
Layer 'fc6' weights[0]: 7.551357e-03 [1.009208e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.219135e-09] 
Layer 'fc7' weights[0]: 7.442751e-03 [1.227577e-07] 
Layer 'fc7' biases: 9.998530e-01 [1.058937e-07] 
Layer 'fc8' weights[0]: 6.144095e-04 [5.633529e-06] 
Layer 'fc8' biases: 1.710922e-01 [1.368565e-04] 
Train error last 27 batches: 0.635669
-------------------------------------------------------
Not saving because 0.645067 > 0.627087 (334.9: -0.00%)
======================================================= (5.086 sec)
396.12... logprob:  0.716927, 0.437500 (0.668 sec)
396.13... logprob:  0.657037, 0.359375 (0.668 sec)
396.14... logprob:  0.662650, 0.367188 (0.668 sec)
396.15... logprob:  0.685670, 0.398438 (0.667 sec)
396.16... logprob:  0.627078, 0.320312 (0.667 sec)
396.17... logprob:  0.638503, 0.335938 (0.665 sec)
396.18... logprob:  0.638219, 0.335938 (0.667 sec)
396.19... logprob:  0.632701, 0.328125 (0.667 sec)
396.20... logprob:  0.648918, 0.351562 (0.665 sec)
396.21... logprob:  0.643445, 0.343750 (0.666 sec)
396.22... logprob:  0.627901, 0.320312 (0.667 sec)
396.23... logprob:  0.622989, 0.312500 (0.664 sec)
396.24... logprob:  0.577231, 0.242188 (0.665 sec)
396.25... logprob:  0.628050, 0.320312 (0.667 sec)
396.26... logprob:  0.674310, 0.390625 (0.667 sec)
396.27... logprob:  0.627934, 0.320312 (0.668 sec)
397.1... logprob:  0.679742, 0.398438 (0.669 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643464, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937352e-03 [6.704883e-09] 
Layer 'conv1' biases: 6.166061e-07 [8.507850e-11] 
Layer 'conv2' weights[0]: 7.925337e-03 [5.196301e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.414217e-10] 
Layer 'conv3' weights[0]: 7.922944e-03 [4.519367e-09] 
Layer 'conv3' biases: 5.122124e-06 [8.683752e-10] 
Layer 'conv4' weights[0]: 7.955801e-03 [4.429377e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.610013e-09] 
Layer 'conv5' weights[0]: 7.955157e-03 [1.998869e-08] 
Layer 'conv5' biases: 1.000002e+00 [2.057050e-08] 
Layer 'fc6' weights[0]: 7.551292e-03 [4.454747e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.175943e-09] 
Layer 'fc7' weights[0]: 7.442121e-03 [5.064395e-08] 
Layer 'fc7' biases: 9.998521e-01 [2.667572e-08] 
Layer 'fc8' weights[0]: 5.707336e-04 [1.320713e-06] 
Layer 'fc8' biases: 1.701796e-01 [2.271754e-05] 
Train error last 27 batches: 0.635666
-------------------------------------------------------
Not saving because 0.643464 > 0.627087 (334.9: -0.00%)
======================================================= (5.172 sec)
397.2... logprob:  0.596829, 0.273438 (0.668 sec)
397.3... logprob:  0.653842, 0.359375 (0.668 sec)
397.4... logprob:  0.596534, 0.273438 (0.667 sec)
397.5... logprob:  0.590854, 0.265625 (0.668 sec)
397.6... logprob:  0.611407, 0.296875 (0.665 sec)
397.7... logprob:  0.643809, 0.343750 (0.667 sec)
397.8... logprob:  0.604939, 0.289062 (0.669 sec)
397.9... logprob:  0.638503, 0.335938 (0.669 sec)
397.10... logprob:  0.598161, 0.281250 (0.669 sec)
397.11... logprob:  0.638777, 0.335938 (0.666 sec)
397.12... logprob:  0.716919, 0.437500 (0.668 sec)
397.13... logprob:  0.657035, 0.359375 (0.667 sec)
397.14... logprob:  0.662647, 0.367188 (0.667 sec)
397.15... logprob:  0.685667, 0.398438 (0.667 sec)
397.16... logprob:  0.627078, 0.320312 (0.667 sec)
397.17... logprob:  0.638503, 0.335938 (0.668 sec)
397.18... logprob:  0.638220, 0.335938 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643693, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937293e-03 [6.541188e-09] 
Layer 'conv1' biases: 6.176634e-07 [1.741305e-10] 
Layer 'conv2' weights[0]: 7.925282e-03 [6.711215e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.349267e-10] 
Layer 'conv3' weights[0]: 7.922891e-03 [5.893414e-09] 
Layer 'conv3' biases: 5.130039e-06 [2.268751e-09] 
Layer 'conv4' weights[0]: 7.955734e-03 [5.877417e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.609972e-08] 
Layer 'conv5' weights[0]: 7.955094e-03 [9.021201e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.509200e-08] 
Layer 'fc6' weights[0]: 7.551227e-03 [1.044967e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.705150e-09] 
Layer 'fc7' weights[0]: 7.441455e-03 [1.286045e-07] 
Layer 'fc7' biases: 9.998523e-01 [1.132777e-07] 
Layer 'fc8' weights[0]: 5.842639e-04 [5.925368e-06] 
Layer 'fc8' biases: 1.707537e-01 [1.225129e-04] 
Train error last 27 batches: 0.635665
-------------------------------------------------------
Not saving because 0.643693 > 0.627087 (334.9: -0.00%)
======================================================= (5.068 sec)
397.19... logprob:  0.632701, 0.328125 (0.667 sec)
397.20... logprob:  0.648920, 0.351562 (0.667 sec)
397.21... logprob:  0.643446, 0.343750 (0.666 sec)
397.22... logprob:  0.627898, 0.320312 (0.667 sec)
397.23... logprob:  0.622985, 0.312500 (0.667 sec)
397.24... logprob:  0.577219, 0.242188 (0.666 sec)
397.25... logprob:  0.628048, 0.320312 (0.668 sec)
397.26... logprob:  0.674314, 0.390625 (0.665 sec)
397.27... logprob:  0.627933, 0.320312 (0.668 sec)
398.1... logprob:  0.679744, 0.398438 (0.668 sec)
398.2... logprob:  0.596826, 0.273438 (0.666 sec)
398.3... logprob:  0.653842, 0.359375 (0.668 sec)
398.4... logprob:  0.596534, 0.273438 (0.669 sec)
398.5... logprob:  0.590855, 0.265625 (0.668 sec)
398.6... logprob:  0.611409, 0.296875 (0.668 sec)
398.7... logprob:  0.643808, 0.343750 (0.668 sec)
398.8... logprob:  0.604944, 0.289062 (0.669 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644148, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937230e-03 [7.223127e-09] 
Layer 'conv1' biases: 6.186955e-07 [1.452530e-10] 
Layer 'conv2' weights[0]: 7.925213e-03 [6.305052e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.512671e-10] 
Layer 'conv3' weights[0]: 7.922824e-03 [6.079864e-09] 
Layer 'conv3' biases: 5.137604e-06 [2.213804e-09] 
Layer 'conv4' weights[0]: 7.955666e-03 [6.185905e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.894215e-08] 
Layer 'conv5' weights[0]: 7.955033e-03 [1.058300e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.118219e-07] 
Layer 'fc6' weights[0]: 7.551157e-03 [1.191225e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.131623e-08] 
Layer 'fc7' weights[0]: 7.440807e-03 [1.451996e-07] 
Layer 'fc7' biases: 9.998526e-01 [1.311442e-07] 
Layer 'fc8' weights[0]: 5.973194e-04 [6.879433e-06] 
Layer 'fc8' biases: 1.712900e-01 [1.691611e-04] 
Train error last 27 batches: 0.635664
-------------------------------------------------------
Not saving because 0.644148 > 0.627087 (334.9: -0.00%)
======================================================= (5.077 sec)
398.9... logprob:  0.638502, 0.335938 (0.670 sec)
398.10... logprob:  0.598169, 0.281250 (0.669 sec)
398.11... logprob:  0.638773, 0.335938 (0.668 sec)
398.12... logprob:  0.716893, 0.437500 (0.667 sec)
398.13... logprob:  0.657027, 0.359375 (0.668 sec)
398.14... logprob:  0.662638, 0.367188 (0.668 sec)
398.15... logprob:  0.685656, 0.398438 (0.667 sec)
398.16... logprob:  0.627078, 0.320312 (0.666 sec)
398.17... logprob:  0.638502, 0.335938 (0.668 sec)
398.18... logprob:  0.638220, 0.335938 (0.667 sec)
398.19... logprob:  0.632701, 0.328125 (0.665 sec)
398.20... logprob:  0.648920, 0.351562 (0.667 sec)
398.21... logprob:  0.643446, 0.343750 (0.667 sec)
398.22... logprob:  0.627896, 0.320312 (0.668 sec)
398.23... logprob:  0.622982, 0.312500 (0.665 sec)
398.24... logprob:  0.577206, 0.242188 (0.667 sec)
398.25... logprob:  0.628045, 0.320312 (0.666 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643462, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937174e-03 [6.635347e-09] 
Layer 'conv1' biases: 6.201856e-07 [6.856513e-11] 
Layer 'conv2' weights[0]: 7.925146e-03 [4.958608e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.576809e-10] 
Layer 'conv3' weights[0]: 7.922751e-03 [4.641956e-09] 
Layer 'conv3' biases: 5.150542e-06 [1.008718e-09] 
Layer 'conv4' weights[0]: 7.955601e-03 [4.628833e-09] 
Layer 'conv4' biases: 1.000001e+00 [7.685771e-09] 
Layer 'conv5' weights[0]: 7.954956e-03 [4.308273e-08] 
Layer 'conv5' biases: 1.000002e+00 [4.524406e-08] 
Layer 'fc6' weights[0]: 7.551090e-03 [6.037642e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.586920e-09] 
Layer 'fc7' weights[0]: 7.440160e-03 [7.382149e-08] 
Layer 'fc7' biases: 9.998522e-01 [5.400376e-08] 
Layer 'fc8' weights[0]: 5.698263e-04 [2.758007e-06] 
Layer 'fc8' biases: 1.707878e-01 [8.036465e-05] 
Train error last 27 batches: 0.635662
-------------------------------------------------------
Not saving because 0.643462 > 0.627087 (334.9: -0.00%)
======================================================= (5.129 sec)
398.26... logprob:  0.674320, 0.390625 (0.687 sec)
398.27... logprob:  0.627930, 0.320312 (0.669 sec)
399.1... logprob:  0.679750, 0.398438 (0.666 sec)
399.2... logprob:  0.596819, 0.273438 (0.667 sec)
399.3... logprob:  0.653844, 0.359375 (0.681 sec)
399.4... logprob:  0.596528, 0.273438 (0.679 sec)
399.5... logprob:  0.590850, 0.265625 (0.683 sec)
399.6... logprob:  0.611407, 0.296875 (0.680 sec)
399.7... logprob:  0.643808, 0.343750 (0.679 sec)
399.8... logprob:  0.604944, 0.289062 (0.685 sec)
399.9... logprob:  0.638501, 0.335938 (0.683 sec)
399.10... logprob:  0.598170, 0.281250 (0.689 sec)
399.11... logprob:  0.638772, 0.335938 (0.684 sec)
399.12... logprob:  0.716882, 0.437500 (0.687 sec)
399.13... logprob:  0.657023, 0.359375 (0.682 sec)
399.14... logprob:  0.662635, 0.367188 (0.682 sec)
399.15... logprob:  0.685653, 0.398438 (0.689 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644298, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937106e-03 [7.358826e-09] 
Layer 'conv1' biases: 6.210766e-07 [2.034473e-10] 
Layer 'conv2' weights[0]: 7.925085e-03 [7.553949e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.010364e-09] 
Layer 'conv3' weights[0]: 7.922682e-03 [6.521828e-09] 
Layer 'conv3' biases: 5.156078e-06 [2.793975e-09] 
Layer 'conv4' weights[0]: 7.955535e-03 [6.570027e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.033992e-08] 
Layer 'conv5' weights[0]: 7.954908e-03 [1.144779e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.209630e-07] 
Layer 'fc6' weights[0]: 7.551022e-03 [1.274044e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.225779e-08] 
Layer 'fc7' weights[0]: 7.439503e-03 [1.550876e-07] 
Layer 'fc7' biases: 9.998526e-01 [1.420178e-07] 
Layer 'fc8' weights[0]: 6.001724e-04 [7.491453e-06] 
Layer 'fc8' biases: 1.717873e-01 [1.537626e-04] 
Train error last 27 batches: 0.635660
-------------------------------------------------------
Not saving because 0.644298 > 0.627087 (334.9: -0.00%)
======================================================= (5.169 sec)
399.16... logprob:  0.627079, 0.320312 (0.677 sec)
399.17... logprob:  0.638503, 0.335938 (0.685 sec)
399.18... logprob:  0.638220, 0.335938 (0.691 sec)
399.19... logprob:  0.632700, 0.328125 (0.684 sec)
399.20... logprob:  0.648921, 0.351562 (0.688 sec)
399.21... logprob:  0.643447, 0.343750 (0.692 sec)
399.22... logprob:  0.627894, 0.320312 (0.680 sec)
399.23... logprob:  0.622978, 0.312500 (0.686 sec)
399.24... logprob:  0.577194, 0.242188 (0.685 sec)
399.25... logprob:  0.628042, 0.320312 (0.688 sec)
399.26... logprob:  0.674324, 0.390625 (0.684 sec)
399.27... logprob:  0.627928, 0.320312 (0.682 sec)
400.1... logprob:  0.679754, 0.398438 (0.687 sec)
400.2... logprob:  0.596815, 0.273438 (0.691 sec)
400.3... logprob:  0.653844, 0.359375 (0.703 sec)
400.4... logprob:  0.596526, 0.273438 (0.707 sec)
400.5... logprob:  0.590850, 0.265625 (0.694 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643602, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937034e-03 [7.510151e-09] 
Layer 'conv1' biases: 6.224512e-07 [1.363796e-10] 
Layer 'conv2' weights[0]: 7.925030e-03 [5.962718e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.394655e-10] 
Layer 'conv3' weights[0]: 7.922605e-03 [5.744047e-09] 
Layer 'conv3' biases: 5.168024e-06 [1.930454e-09] 
Layer 'conv4' weights[0]: 7.955461e-03 [5.754813e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.605336e-08] 
Layer 'conv5' weights[0]: 7.954824e-03 [9.023645e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.511453e-08] 
Layer 'fc6' weights[0]: 7.550966e-03 [1.045704e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.673771e-09] 
Layer 'fc7' weights[0]: 7.438891e-03 [1.286596e-07] 
Layer 'fc7' biases: 9.998522e-01 [1.129974e-07] 
Layer 'fc8' weights[0]: 5.796624e-04 [5.861797e-06] 
Layer 'fc8' biases: 1.714506e-01 [1.488274e-04] 
Train error last 27 batches: 0.635660
-------------------------------------------------------
Not saving because 0.643602 > 0.627087 (334.9: -0.00%)
======================================================= (5.215 sec)
400.6... logprob:  0.611408, 0.296875 (0.684 sec)
400.7... logprob:  0.643807, 0.343750 (0.679 sec)
400.8... logprob:  0.604947, 0.289062 (0.682 sec)
400.9... logprob:  0.638500, 0.335938 (0.685 sec)
400.10... logprob:  0.598176, 0.281250 (0.693 sec)
400.11... logprob:  0.638769, 0.335938 (0.697 sec)
400.12... logprob:  0.716857, 0.437500 (0.697 sec)
400.13... logprob:  0.657015, 0.359375 (0.698 sec)
400.14... logprob:  0.662626, 0.367188 (0.698 sec)
400.15... logprob:  0.685641, 0.398438 (0.698 sec)
400.16... logprob:  0.627079, 0.320312 (0.698 sec)
400.17... logprob:  0.638503, 0.335938 (0.697 sec)
400.18... logprob:  0.638219, 0.335938 (0.697 sec)
400.19... logprob:  0.632700, 0.328125 (0.696 sec)
400.20... logprob:  0.648922, 0.351562 (0.696 sec)
400.21... logprob:  0.643447, 0.343750 (0.695 sec)
400.22... logprob:  0.627892, 0.320312 (0.702 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643447, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936974e-03 [6.762816e-09] 
Layer 'conv1' biases: 6.237887e-07 [1.382700e-10] 
Layer 'conv2' weights[0]: 7.924961e-03 [6.095966e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.028314e-10] 
Layer 'conv3' weights[0]: 7.922538e-03 [5.292031e-09] 
Layer 'conv3' biases: 5.179375e-06 [1.629102e-09] 
Layer 'conv4' weights[0]: 7.955391e-03 [5.170918e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.001936e-08] 
Layer 'conv5' weights[0]: 7.954767e-03 [5.610518e-08] 
Layer 'conv5' biases: 1.000002e+00 [5.888700e-08] 
Layer 'fc6' weights[0]: 7.550902e-03 [7.230001e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.055659e-09] 
Layer 'fc7' weights[0]: 7.438232e-03 [8.939581e-08] 
Layer 'fc7' biases: 9.998522e-01 [7.145166e-08] 
Layer 'fc8' weights[0]: 5.670302e-04 [3.664543e-06] 
Layer 'fc8' biases: 1.713265e-01 [7.540858e-05] 
Train error last 27 batches: 0.635658
-------------------------------------------------------
Not saving because 0.643447 > 0.627087 (334.9: -0.00%)
======================================================= (5.314 sec)
400.23... logprob:  0.622974, 0.312500 (0.698 sec)
400.24... logprob:  0.577181, 0.242188 (0.698 sec)
400.25... logprob:  0.628039, 0.320312 (0.696 sec)
400.26... logprob:  0.674329, 0.390625 (0.733 sec)
400.27... logprob:  0.627926, 0.320312 (0.683 sec)
401.1... logprob:  0.679760, 0.398438 (0.683 sec)
401.2... logprob:  0.596808, 0.273438 (0.687 sec)
401.3... logprob:  0.653846, 0.359375 (0.697 sec)
401.4... logprob:  0.596520, 0.273438 (0.697 sec)
401.5... logprob:  0.590844, 0.265625 (0.692 sec)
401.6... logprob:  0.611406, 0.296875 (0.685 sec)
401.7... logprob:  0.643808, 0.343750 (0.684 sec)
401.8... logprob:  0.604948, 0.289062 (0.707 sec)
401.9... logprob:  0.638499, 0.335938 (0.701 sec)
401.10... logprob:  0.598180, 0.281250 (0.700 sec)
401.11... logprob:  0.638767, 0.335938 (0.685 sec)
401.12... logprob:  0.716842, 0.437500 (0.684 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.645018, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936918e-03 [6.958338e-09] 
Layer 'conv1' biases: 6.245065e-07 [8.334775e-11] 
Layer 'conv2' weights[0]: 7.924899e-03 [5.247031e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.149351e-10] 
Layer 'conv3' weights[0]: 7.922470e-03 [4.538978e-09] 
Layer 'conv3' biases: 5.182544e-06 [7.860218e-10] 
Layer 'conv4' weights[0]: 7.955330e-03 [4.404329e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.413559e-09] 
Layer 'conv5' weights[0]: 7.954689e-03 [8.756766e-09] 
Layer 'conv5' biases: 1.000002e+00 [8.221311e-09] 
Layer 'fc6' weights[0]: 7.550831e-03 [3.906305e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.017228e-10] 
Layer 'fc7' weights[0]: 7.437593e-03 [4.053285e-08] 
Layer 'fc7' biases: 9.998528e-01 [1.231139e-08] 
Layer 'fc8' weights[0]: 6.121404e-04 [5.318806e-07] 
Layer 'fc8' biases: 1.727085e-01 [2.826485e-06] 
Train error last 27 batches: 0.635656
-------------------------------------------------------
Not saving because 0.645018 > 0.627087 (334.9: -0.00%)
======================================================= (5.277 sec)
401.13... logprob:  0.657010, 0.359375 (0.680 sec)
401.14... logprob:  0.662621, 0.367188 (0.675 sec)
401.15... logprob:  0.685635, 0.398438 (0.683 sec)
401.16... logprob:  0.627079, 0.320312 (0.673 sec)
401.17... logprob:  0.638503, 0.335938 (0.685 sec)
401.18... logprob:  0.638219, 0.335938 (0.683 sec)
401.19... logprob:  0.632699, 0.328125 (0.687 sec)
401.20... logprob:  0.648923, 0.351562 (0.682 sec)
401.21... logprob:  0.643448, 0.343750 (0.702 sec)
401.22... logprob:  0.627889, 0.320312 (0.688 sec)
401.23... logprob:  0.622970, 0.312500 (0.682 sec)
401.24... logprob:  0.577166, 0.242188 (0.677 sec)
401.25... logprob:  0.628037, 0.320312 (0.678 sec)
401.26... logprob:  0.674335, 0.390625 (0.688 sec)
401.27... logprob:  0.627924, 0.320312 (0.680 sec)
402.1... logprob:  0.679764, 0.398438 (0.676 sec)
402.2... logprob:  0.596803, 0.273438 (0.678 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643476, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936851e-03 [6.891831e-09] 
Layer 'conv1' biases: 6.261217e-07 [7.125849e-11] 
Layer 'conv2' weights[0]: 7.924837e-03 [4.998491e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.825349e-10] 
Layer 'conv3' weights[0]: 7.922405e-03 [4.535847e-09] 
Layer 'conv3' biases: 5.197294e-06 [7.671360e-10] 
Layer 'conv4' weights[0]: 7.955262e-03 [4.445371e-09] 
Layer 'conv4' biases: 1.000001e+00 [4.297441e-09] 
Layer 'conv5' weights[0]: 7.954633e-03 [2.467038e-08] 
Layer 'conv5' biases: 1.000002e+00 [2.576103e-08] 
Layer 'fc6' weights[0]: 7.550771e-03 [4.696192e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.546792e-09] 
Layer 'fc7' weights[0]: 7.436981e-03 [5.392068e-08] 
Layer 'fc7' biases: 9.998522e-01 [3.008080e-08] 
Layer 'fc8' weights[0]: 5.706914e-04 [1.539326e-06] 
Layer 'fc8' biases: 1.718390e-01 [4.578460e-05] 
Train error last 27 batches: 0.635655
-------------------------------------------------------
Not saving because 0.643476 > 0.627087 (334.9: -0.00%)
======================================================= (5.204 sec)
402.3... logprob:  0.653847, 0.359375 (0.680 sec)
402.4... logprob:  0.596517, 0.273438 (0.676 sec)
402.5... logprob:  0.590843, 0.265625 (0.677 sec)
402.6... logprob:  0.611407, 0.296875 (0.677 sec)
402.7... logprob:  0.643806, 0.343750 (0.679 sec)
402.8... logprob:  0.604951, 0.289062 (0.677 sec)
402.9... logprob:  0.638498, 0.335938 (0.679 sec)
402.10... logprob:  0.598186, 0.281250 (0.682 sec)
402.11... logprob:  0.638764, 0.335938 (0.679 sec)
402.12... logprob:  0.716819, 0.437500 (0.679 sec)
402.13... logprob:  0.657002, 0.359375 (0.675 sec)
402.14... logprob:  0.662613, 0.367188 (0.682 sec)
402.15... logprob:  0.685625, 0.398438 (0.680 sec)
402.16... logprob:  0.627079, 0.320312 (0.678 sec)
402.17... logprob:  0.638503, 0.335938 (0.678 sec)
402.18... logprob:  0.638219, 0.335938 (0.677 sec)
402.19... logprob:  0.632699, 0.328125 (0.677 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643594, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936782e-03 [6.816628e-09] 
Layer 'conv1' biases: 6.272374e-07 [1.578880e-10] 
Layer 'conv2' weights[0]: 7.924784e-03 [6.555651e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.575885e-10] 
Layer 'conv3' weights[0]: 7.922338e-03 [5.684117e-09] 
Layer 'conv3' biases: 5.205829e-06 [2.053751e-09] 
Layer 'conv4' weights[0]: 7.955207e-03 [5.625222e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.385443e-08] 
Layer 'conv5' weights[0]: 7.954586e-03 [7.741639e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.152580e-08] 
Layer 'fc6' weights[0]: 7.550701e-03 [9.327087e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.345459e-09] 
Layer 'fc7' weights[0]: 7.436311e-03 [1.146359e-07] 
Layer 'fc7' biases: 9.998522e-01 [9.778661e-08] 
Layer 'fc8' weights[0]: 5.784453e-04 [5.056354e-06] 
Layer 'fc8' biases: 1.722623e-01 [1.048926e-04] 
Train error last 27 batches: 0.635653
-------------------------------------------------------
Not saving because 0.643594 > 0.627087 (334.9: -0.00%)
======================================================= (5.142 sec)
402.20... logprob:  0.648923, 0.351562 (0.676 sec)
402.21... logprob:  0.643448, 0.343750 (0.675 sec)
402.22... logprob:  0.627888, 0.320312 (0.686 sec)
402.23... logprob:  0.622968, 0.312500 (0.680 sec)
402.24... logprob:  0.577157, 0.242188 (0.675 sec)
402.25... logprob:  0.628034, 0.320312 (0.679 sec)
402.26... logprob:  0.674338, 0.390625 (0.679 sec)
402.27... logprob:  0.627922, 0.320312 (0.681 sec)
403.1... logprob:  0.679769, 0.398438 (0.676 sec)
403.2... logprob:  0.596797, 0.273438 (0.678 sec)
403.3... logprob:  0.653848, 0.359375 (0.677 sec)
403.4... logprob:  0.596512, 0.273438 (0.680 sec)
403.5... logprob:  0.590838, 0.265625 (0.676 sec)
403.6... logprob:  0.611404, 0.296875 (0.678 sec)
403.7... logprob:  0.643807, 0.343750 (0.676 sec)
403.8... logprob:  0.604950, 0.289062 (0.676 sec)
403.9... logprob:  0.638498, 0.335938 (0.682 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644379, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936710e-03 [6.737151e-09] 
Layer 'conv1' biases: 6.281830e-07 [1.205747e-10] 
Layer 'conv2' weights[0]: 7.924720e-03 [5.848033e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.102846e-10] 
Layer 'conv3' weights[0]: 7.922271e-03 [5.664490e-09] 
Layer 'conv3' biases: 5.212136e-06 [1.861295e-09] 
Layer 'conv4' weights[0]: 7.955142e-03 [5.760306e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.574738e-08] 
Layer 'conv5' weights[0]: 7.954503e-03 [8.791620e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.289712e-08] 
Layer 'fc6' weights[0]: 7.550629e-03 [1.026172e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.425826e-09] 
Layer 'fc7' weights[0]: 7.435701e-03 [1.254947e-07] 
Layer 'fc7' biases: 9.998527e-01 [1.092294e-07] 
Layer 'fc8' weights[0]: 6.007023e-04 [5.696421e-06] 
Layer 'fc8' biases: 1.730408e-01 [1.419677e-04] 
Train error last 27 batches: 0.635652
-------------------------------------------------------
Not saving because 0.644379 > 0.627087 (334.9: -0.00%)
======================================================= (5.136 sec)
403.10... logprob:  0.598187, 0.281250 (0.684 sec)
403.11... logprob:  0.638763, 0.335938 (0.675 sec)
403.12... logprob:  0.716810, 0.437500 (0.678 sec)
403.13... logprob:  0.656999, 0.359375 (0.679 sec)
403.14... logprob:  0.662611, 0.367188 (0.682 sec)
403.15... logprob:  0.685622, 0.398438 (0.677 sec)
403.16... logprob:  0.627079, 0.320312 (0.676 sec)
403.17... logprob:  0.638502, 0.335938 (0.677 sec)
403.18... logprob:  0.638220, 0.335938 (0.677 sec)
403.19... logprob:  0.632699, 0.328125 (0.675 sec)
403.20... logprob:  0.648925, 0.351562 (0.674 sec)
403.21... logprob:  0.643449, 0.343750 (0.679 sec)
403.22... logprob:  0.627885, 0.320312 (0.684 sec)
403.23... logprob:  0.622963, 0.312500 (0.674 sec)
403.24... logprob:  0.577140, 0.242188 (0.677 sec)
403.25... logprob:  0.628031, 0.320312 (0.678 sec)
403.26... logprob:  0.674344, 0.390625 (0.676 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643466, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936641e-03 [6.582737e-09] 
Layer 'conv1' biases: 6.297197e-07 [7.218577e-11] 
Layer 'conv2' weights[0]: 7.924658e-03 [5.046065e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.431628e-10] 
Layer 'conv3' weights[0]: 7.922202e-03 [4.415084e-09] 
Layer 'conv3' biases: 5.225778e-06 [6.003624e-10] 
Layer 'conv4' weights[0]: 7.955078e-03 [4.323190e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.247798e-09] 
Layer 'conv5' weights[0]: 7.954449e-03 [8.113484e-09] 
Layer 'conv5' biases: 1.000002e+00 [7.525047e-09] 
Layer 'fc6' weights[0]: 7.550563e-03 [3.880080e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.696193e-10] 
Layer 'fc7' weights[0]: 7.435065e-03 [3.942763e-08] 
Layer 'fc7' biases: 9.998521e-01 [9.375190e-09] 
Layer 'fc8' weights[0]: 5.688649e-04 [4.469715e-07] 
Layer 'fc8' biases: 1.724192e-01 [2.157861e-05] 
Train error last 27 batches: 0.635651
-------------------------------------------------------
Not saving because 0.643466 > 0.627087 (334.9: -0.00%)
======================================================= (5.252 sec)
403.27... logprob:  0.627920, 0.320312 (0.677 sec)
404.1... logprob:  0.679774, 0.398438 (0.676 sec)
404.2... logprob:  0.596793, 0.273438 (0.677 sec)
404.3... logprob:  0.653849, 0.359375 (0.677 sec)
404.4... logprob:  0.596511, 0.273438 (0.678 sec)
404.5... logprob:  0.590839, 0.265625 (0.677 sec)
404.6... logprob:  0.611407, 0.296875 (0.678 sec)
404.7... logprob:  0.643805, 0.343750 (0.677 sec)
404.8... logprob:  0.604955, 0.289062 (0.680 sec)
404.9... logprob:  0.638496, 0.335938 (0.682 sec)
404.10... logprob:  0.598196, 0.281250 (0.678 sec)
404.11... logprob:  0.638760, 0.335938 (0.675 sec)
404.12... logprob:  0.716778, 0.437500 (0.677 sec)
404.13... logprob:  0.656989, 0.359375 (0.681 sec)
404.14... logprob:  0.662600, 0.367188 (0.677 sec)
404.15... logprob:  0.685607, 0.398438 (0.676 sec)
404.16... logprob:  0.627080, 0.320312 (0.673 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644040, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936587e-03 [6.979112e-09] 
Layer 'conv1' biases: 6.306578e-07 [1.815459e-10] 
Layer 'conv2' weights[0]: 7.924584e-03 [7.114971e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.096522e-10] 
Layer 'conv3' weights[0]: 7.922136e-03 [6.174800e-09] 
Layer 'conv3' biases: 5.232078e-06 [2.494321e-09] 
Layer 'conv4' weights[0]: 7.955019e-03 [6.189000e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.772371e-08] 
Layer 'conv5' weights[0]: 7.954371e-03 [9.953041e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.049685e-07] 
Layer 'fc6' weights[0]: 7.550495e-03 [1.128446e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.068052e-08] 
Layer 'fc7' weights[0]: 7.434422e-03 [1.378739e-07] 
Layer 'fc7' biases: 9.998524e-01 [1.236973e-07] 
Layer 'fc8' weights[0]: 5.928067e-04 [6.483362e-06] 
Layer 'fc8' biases: 1.732595e-01 [1.338824e-04] 
Train error last 27 batches: 0.635649
-------------------------------------------------------
Not saving because 0.644040 > 0.627087 (334.9: -0.00%)
======================================================= (5.124 sec)
404.17... logprob:  0.638502, 0.335938 (0.673 sec)
404.18... logprob:  0.638219, 0.335938 (0.676 sec)
404.19... logprob:  0.632699, 0.328125 (0.676 sec)
404.20... logprob:  0.648925, 0.351562 (0.677 sec)
404.21... logprob:  0.643449, 0.343750 (0.677 sec)
404.22... logprob:  0.627883, 0.320312 (0.680 sec)
404.23... logprob:  0.622960, 0.312500 (0.675 sec)
404.24... logprob:  0.577128, 0.242188 (0.678 sec)
404.25... logprob:  0.628029, 0.320312 (0.677 sec)
404.26... logprob:  0.674350, 0.390625 (0.679 sec)
404.27... logprob:  0.627917, 0.320312 (0.673 sec)
405.1... logprob:  0.679781, 0.398438 (0.679 sec)
405.2... logprob:  0.596784, 0.273438 (0.678 sec)
405.3... logprob:  0.653851, 0.359375 (0.679 sec)
405.4... logprob:  0.596503, 0.273438 (0.681 sec)
405.5... logprob:  0.590833, 0.265625 (0.676 sec)
405.6... logprob:  0.611405, 0.296875 (0.678 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643747, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936522e-03 [7.402019e-09] 
Layer 'conv1' biases: 6.319029e-07 [1.616190e-10] 
Layer 'conv2' weights[0]: 7.924515e-03 [6.256423e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.594225e-10] 
Layer 'conv3' weights[0]: 7.922067e-03 [6.018537e-09] 
Layer 'conv3' biases: 5.242417e-06 [2.192328e-09] 
Layer 'conv4' weights[0]: 7.954956e-03 [6.076847e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.869906e-08] 
Layer 'conv5' weights[0]: 7.954315e-03 [1.052630e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.109833e-07] 
Layer 'fc6' weights[0]: 7.550420e-03 [1.187876e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.128076e-08] 
Layer 'fc7' weights[0]: 7.433795e-03 [1.451833e-07] 
Layer 'fc7' biases: 9.998524e-01 [1.312772e-07] 
Layer 'fc8' weights[0]: 5.841249e-04 [6.809544e-06] 
Layer 'fc8' biases: 1.732267e-01 [1.715730e-04] 
Train error last 27 batches: 0.635648
-------------------------------------------------------
Not saving because 0.643747 > 0.627087 (334.9: -0.00%)
======================================================= (5.133 sec)
405.7... logprob:  0.643806, 0.343750 (0.678 sec)
405.8... logprob:  0.604956, 0.289062 (0.680 sec)
405.9... logprob:  0.638496, 0.335938 (0.679 sec)
405.10... logprob:  0.598198, 0.281250 (0.679 sec)
405.11... logprob:  0.638758, 0.335938 (0.679 sec)
405.12... logprob:  0.716766, 0.437500 (0.676 sec)
405.13... logprob:  0.656984, 0.359375 (0.679 sec)
405.14... logprob:  0.662595, 0.367188 (0.677 sec)
405.15... logprob:  0.685602, 0.398438 (0.678 sec)
405.16... logprob:  0.627080, 0.320312 (0.675 sec)
405.17... logprob:  0.638502, 0.335938 (0.685 sec)
405.18... logprob:  0.638219, 0.335938 (0.676 sec)
405.19... logprob:  0.632698, 0.328125 (0.674 sec)
405.20... logprob:  0.648926, 0.351562 (0.676 sec)
405.21... logprob:  0.643449, 0.343750 (0.677 sec)
405.22... logprob:  0.627882, 0.320312 (0.680 sec)
405.23... logprob:  0.622957, 0.312500 (0.676 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643440, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936449e-03 [6.365804e-09] 
Layer 'conv1' biases: 6.333224e-07 [1.083040e-10] 
Layer 'conv2' weights[0]: 7.924443e-03 [5.378568e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.244438e-10] 
Layer 'conv3' weights[0]: 7.921997e-03 [4.761367e-09] 
Layer 'conv3' biases: 5.254556e-06 [1.111139e-09] 
Layer 'conv4' weights[0]: 7.954886e-03 [4.639212e-09] 
Layer 'conv4' biases: 1.000001e+00 [5.826788e-09] 
Layer 'conv5' weights[0]: 7.954254e-03 [3.247292e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.390998e-08] 
Layer 'fc6' weights[0]: 7.550361e-03 [5.240529e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.496206e-09] 
Layer 'fc7' weights[0]: 7.433145e-03 [6.312950e-08] 
Layer 'fc7' biases: 9.998520e-01 [4.172435e-08] 
Layer 'fc8' weights[0]: 5.639618e-04 [2.117973e-06] 
Layer 'fc8' biases: 1.728939e-01 [3.888744e-05] 
Train error last 27 batches: 0.635646
-------------------------------------------------------
Not saving because 0.643440 > 0.627087 (334.9: -0.00%)
======================================================= (5.185 sec)
405.24... logprob:  0.577120, 0.242188 (0.674 sec)
405.25... logprob:  0.628027, 0.320312 (0.673 sec)
405.26... logprob:  0.674352, 0.390625 (0.675 sec)
405.27... logprob:  0.627916, 0.320312 (0.685 sec)
406.1... logprob:  0.679783, 0.398438 (0.678 sec)
406.2... logprob:  0.596781, 0.273438 (0.680 sec)
406.3... logprob:  0.653852, 0.359375 (0.679 sec)
406.4... logprob:  0.596501, 0.273438 (0.678 sec)
406.5... logprob:  0.590831, 0.265625 (0.679 sec)
406.6... logprob:  0.611405, 0.296875 (0.680 sec)
406.7... logprob:  0.643806, 0.343750 (0.678 sec)
406.8... logprob:  0.604956, 0.289062 (0.680 sec)
406.9... logprob:  0.638495, 0.335938 (0.680 sec)
406.10... logprob:  0.598201, 0.281250 (0.681 sec)
406.11... logprob:  0.638756, 0.335938 (0.679 sec)
406.12... logprob:  0.716753, 0.437500 (0.678 sec)
406.13... logprob:  0.656980, 0.359375 (0.678 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644865, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936376e-03 [6.567822e-09] 
Layer 'conv1' biases: 6.340343e-07 [9.926841e-11] 
Layer 'conv2' weights[0]: 7.924386e-03 [5.406483e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.418349e-10] 
Layer 'conv3' weights[0]: 7.921935e-03 [4.742843e-09] 
Layer 'conv3' biases: 5.257817e-06 [1.221212e-09] 
Layer 'conv4' weights[0]: 7.954826e-03 [4.649699e-09] 
Layer 'conv4' biases: 1.000001e+00 [6.400969e-09] 
Layer 'conv5' weights[0]: 7.954150e-03 [3.638389e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.823008e-08] 
Layer 'fc6' weights[0]: 7.550303e-03 [5.473972e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.866869e-09] 
Layer 'fc7' weights[0]: 7.432501e-03 [6.652876e-08] 
Layer 'fc7' biases: 9.998528e-01 [4.554870e-08] 
Layer 'fc8' weights[0]: 6.082698e-04 [2.361652e-06] 
Layer 'fc8' biases: 1.742699e-01 [3.907203e-05] 
Train error last 27 batches: 0.635645
-------------------------------------------------------
Not saving because 0.644865 > 0.627087 (334.9: -0.00%)
======================================================= (5.183 sec)
406.14... logprob:  0.662591, 0.367188 (0.678 sec)
406.15... logprob:  0.685598, 0.398438 (0.677 sec)
406.16... logprob:  0.627080, 0.320312 (0.676 sec)
406.17... logprob:  0.638502, 0.335938 (0.681 sec)
406.18... logprob:  0.638219, 0.335938 (0.675 sec)
406.19... logprob:  0.632698, 0.328125 (0.677 sec)
406.20... logprob:  0.648928, 0.351562 (0.678 sec)
406.21... logprob:  0.643450, 0.343750 (0.676 sec)
406.22... logprob:  0.627879, 0.320312 (0.684 sec)
406.23... logprob:  0.622954, 0.312500 (0.678 sec)
406.24... logprob:  0.577106, 0.242188 (0.676 sec)
406.25... logprob:  0.628025, 0.320312 (0.677 sec)
406.26... logprob:  0.674358, 0.390625 (0.681 sec)
406.27... logprob:  0.627914, 0.320312 (0.677 sec)
407.1... logprob:  0.679788, 0.398438 (0.677 sec)
407.2... logprob:  0.596776, 0.273438 (0.678 sec)
407.3... logprob:  0.653852, 0.359375 (0.679 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643482, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936308e-03 [6.749078e-09] 
Layer 'conv1' biases: 6.356090e-07 [6.669286e-11] 
Layer 'conv2' weights[0]: 7.924321e-03 [5.019681e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.553857e-10] 
Layer 'conv3' weights[0]: 7.921863e-03 [4.442871e-09] 
Layer 'conv3' biases: 5.272200e-06 [6.247473e-10] 
Layer 'conv4' weights[0]: 7.954760e-03 [4.330452e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.483435e-09] 
Layer 'conv5' weights[0]: 7.954128e-03 [9.812463e-09] 
Layer 'conv5' biases: 1.000002e+00 [9.567085e-09] 
Layer 'fc6' weights[0]: 7.550234e-03 [3.929741e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.570772e-10] 
Layer 'fc7' weights[0]: 7.431846e-03 [4.059615e-08] 
Layer 'fc7' biases: 9.998521e-01 [1.161209e-08] 
Layer 'fc8' weights[0]: 5.698345e-04 [5.881320e-07] 
Layer 'fc8' biases: 1.734608e-01 [2.072105e-05] 
Train error last 27 batches: 0.635645
-------------------------------------------------------
Not saving because 0.643482 > 0.627087 (334.9: -0.00%)
======================================================= (5.252 sec)
407.4... logprob:  0.596498, 0.273438 (0.678 sec)
407.5... logprob:  0.590830, 0.265625 (0.677 sec)
407.6... logprob:  0.611405, 0.296875 (0.677 sec)
407.7... logprob:  0.643805, 0.343750 (0.677 sec)
407.8... logprob:  0.604960, 0.289062 (0.679 sec)
407.9... logprob:  0.638494, 0.335938 (0.676 sec)
407.10... logprob:  0.598207, 0.281250 (0.682 sec)
407.11... logprob:  0.638753, 0.335938 (0.681 sec)
407.12... logprob:  0.716729, 0.437500 (0.682 sec)
407.13... logprob:  0.656972, 0.359375 (0.680 sec)
407.14... logprob:  0.662584, 0.367188 (0.680 sec)
407.15... logprob:  0.685588, 0.398438 (0.680 sec)
407.16... logprob:  0.627081, 0.320312 (0.677 sec)
407.17... logprob:  0.638501, 0.335938 (0.683 sec)
407.18... logprob:  0.638219, 0.335938 (0.677 sec)
407.19... logprob:  0.632698, 0.328125 (0.679 sec)
407.20... logprob:  0.648929, 0.351562 (0.678 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643520, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936232e-03 [6.832638e-09] 
Layer 'conv1' biases: 6.367815e-07 [1.633100e-10] 
Layer 'conv2' weights[0]: 7.924263e-03 [6.520518e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.711096e-10] 
Layer 'conv3' weights[0]: 7.921800e-03 [5.691434e-09] 
Layer 'conv3' biases: 5.281388e-06 [2.100399e-09] 
Layer 'conv4' weights[0]: 7.954692e-03 [5.615921e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.424046e-08] 
Layer 'conv5' weights[0]: 7.954051e-03 [7.943981e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.366699e-08] 
Layer 'fc6' weights[0]: 7.550168e-03 [9.547898e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.580009e-09] 
Layer 'fc7' weights[0]: 7.431199e-03 [1.175056e-07] 
Layer 'fc7' biases: 9.998521e-01 [1.007572e-07] 
Layer 'fc8' weights[0]: 5.725875e-04 [5.179351e-06] 
Layer 'fc8' biases: 1.737528e-01 [1.104239e-04] 
Train error last 27 batches: 0.635643
-------------------------------------------------------
Not saving because 0.643520 > 0.627087 (334.9: -0.00%)
======================================================= (5.141 sec)
407.21... logprob:  0.643451, 0.343750 (0.677 sec)
407.22... logprob:  0.627877, 0.320312 (0.681 sec)
407.23... logprob:  0.622950, 0.312500 (0.676 sec)
407.24... logprob:  0.577093, 0.242188 (0.678 sec)
407.25... logprob:  0.628022, 0.320312 (0.678 sec)
407.26... logprob:  0.674363, 0.390625 (0.678 sec)
407.27... logprob:  0.627912, 0.320312 (0.674 sec)
408.1... logprob:  0.679794, 0.398438 (0.679 sec)
408.2... logprob:  0.596769, 0.273438 (0.676 sec)
408.3... logprob:  0.653855, 0.359375 (0.680 sec)
408.4... logprob:  0.596493, 0.273438 (0.676 sec)
408.5... logprob:  0.590825, 0.265625 (0.677 sec)
408.6... logprob:  0.611403, 0.296875 (0.675 sec)
408.7... logprob:  0.643805, 0.343750 (0.680 sec)
408.8... logprob:  0.604961, 0.289062 (0.685 sec)
408.9... logprob:  0.638493, 0.335938 (0.678 sec)
408.10... logprob:  0.598211, 0.281250 (0.679 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644706, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936159e-03 [7.130263e-09] 
Layer 'conv1' biases: 6.376116e-07 [1.467037e-10] 
Layer 'conv2' weights[0]: 7.924195e-03 [6.318346e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.506716e-10] 
Layer 'conv3' weights[0]: 7.921731e-03 [6.112211e-09] 
Layer 'conv3' biases: 5.286091e-06 [2.238287e-09] 
Layer 'conv4' weights[0]: 7.954611e-03 [6.257372e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.927991e-08] 
Layer 'conv5' weights[0]: 7.953964e-03 [1.074780e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.136922e-07] 
Layer 'fc6' weights[0]: 7.550108e-03 [1.207874e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.150486e-08] 
Layer 'fc7' weights[0]: 7.430560e-03 [1.463730e-07] 
Layer 'fc7' biases: 9.998527e-01 [1.324619e-07] 
Layer 'fc8' weights[0]: 6.051392e-04 [6.945485e-06] 
Layer 'fc8' biases: 1.748052e-01 [1.697900e-04] 
Train error last 27 batches: 0.635642
-------------------------------------------------------
Not saving because 0.644706 > 0.627087 (334.9: -0.00%)
======================================================= (5.124 sec)
408.11... logprob:  0.638751, 0.335938 (0.676 sec)
408.12... logprob:  0.716711, 0.437500 (0.674 sec)
408.13... logprob:  0.656966, 0.359375 (0.676 sec)
408.14... logprob:  0.662577, 0.367188 (0.676 sec)
408.15... logprob:  0.685580, 0.398438 (0.675 sec)
408.16... logprob:  0.627081, 0.320312 (0.674 sec)
408.17... logprob:  0.638501, 0.335938 (0.675 sec)
408.18... logprob:  0.638219, 0.335938 (0.676 sec)
408.19... logprob:  0.632697, 0.328125 (0.679 sec)
408.20... logprob:  0.648929, 0.351562 (0.679 sec)
408.21... logprob:  0.643451, 0.343750 (0.679 sec)
408.22... logprob:  0.627874, 0.320312 (0.675 sec)
408.23... logprob:  0.622946, 0.312500 (0.677 sec)
408.24... logprob:  0.577079, 0.242188 (0.677 sec)
408.25... logprob:  0.628018, 0.320312 (0.677 sec)
408.26... logprob:  0.674370, 0.390625 (0.679 sec)
408.27... logprob:  0.627910, 0.320312 (0.679 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643477, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936093e-03 [6.679558e-09] 
Layer 'conv1' biases: 6.391818e-07 [7.119944e-11] 
Layer 'conv2' weights[0]: 7.924120e-03 [4.932297e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.587988e-10] 
Layer 'conv3' weights[0]: 7.921665e-03 [4.440144e-09] 
Layer 'conv3' biases: 5.300365e-06 [6.804353e-10] 
Layer 'conv4' weights[0]: 7.954546e-03 [4.366581e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.327301e-09] 
Layer 'conv5' weights[0]: 7.953920e-03 [1.902520e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.963904e-08] 
Layer 'fc6' weights[0]: 7.550029e-03 [4.356255e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.966153e-09] 
Layer 'fc7' weights[0]: 7.429916e-03 [4.843791e-08] 
Layer 'fc7' biases: 9.998521e-01 [2.336876e-08] 
Layer 'fc8' weights[0]: 5.685963e-04 [1.167362e-06] 
Layer 'fc8' biases: 1.740561e-01 [3.875969e-05] 
Train error last 27 batches: 0.635640
-------------------------------------------------------
Not saving because 0.643477 > 0.627087 (334.9: -0.00%)
======================================================= (5.237 sec)
409.1... logprob:  0.679799, 0.398438 (0.679 sec)
409.2... logprob:  0.596763, 0.273438 (0.678 sec)
409.3... logprob:  0.653856, 0.359375 (0.682 sec)
409.4... logprob:  0.596489, 0.273438 (0.677 sec)
409.5... logprob:  0.590822, 0.265625 (0.678 sec)
409.6... logprob:  0.611403, 0.296875 (0.679 sec)
409.7... logprob:  0.643805, 0.343750 (0.679 sec)
409.8... logprob:  0.604964, 0.289062 (0.683 sec)
409.9... logprob:  0.638493, 0.335938 (0.678 sec)
409.10... logprob:  0.598216, 0.281250 (0.680 sec)
409.11... logprob:  0.638749, 0.335938 (0.679 sec)
409.12... logprob:  0.716688, 0.437500 (0.682 sec)
409.13... logprob:  0.656959, 0.359375 (0.680 sec)
409.14... logprob:  0.662569, 0.367188 (0.680 sec)
409.15... logprob:  0.685570, 0.398438 (0.679 sec)
409.16... logprob:  0.627081, 0.320312 (0.678 sec)
409.17... logprob:  0.638501, 0.335938 (0.676 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643843, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936019e-03 [6.468488e-09] 
Layer 'conv1' biases: 6.401806e-07 [1.680928e-10] 
Layer 'conv2' weights[0]: 7.924051e-03 [6.793840e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.547398e-10] 
Layer 'conv3' weights[0]: 7.921601e-03 [5.953888e-09] 
Layer 'conv3' biases: 5.307538e-06 [2.317270e-09] 
Layer 'conv4' weights[0]: 7.954485e-03 [5.994674e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.688865e-08] 
Layer 'conv5' weights[0]: 7.953842e-03 [9.462691e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.973716e-08] 
Layer 'fc6' weights[0]: 7.549970e-03 [1.081223e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.014290e-08] 
Layer 'fc7' weights[0]: 7.429276e-03 [1.322302e-07] 
Layer 'fc7' biases: 9.998524e-01 [1.174347e-07] 
Layer 'fc8' weights[0]: 5.859000e-04 [6.139921e-06] 
Layer 'fc8' biases: 1.747258e-01 [1.285645e-04] 
Train error last 27 batches: 0.635638
-------------------------------------------------------
Not saving because 0.643843 > 0.627087 (334.9: -0.00%)
======================================================= (5.140 sec)
409.18... logprob:  0.638220, 0.335938 (0.676 sec)
409.19... logprob:  0.632698, 0.328125 (0.679 sec)
409.20... logprob:  0.648930, 0.351562 (0.679 sec)
409.21... logprob:  0.643451, 0.343750 (0.679 sec)
409.22... logprob:  0.627873, 0.320312 (0.677 sec)
409.23... logprob:  0.622943, 0.312500 (0.678 sec)
409.24... logprob:  0.577066, 0.242188 (0.676 sec)
409.25... logprob:  0.628017, 0.320312 (0.678 sec)
409.26... logprob:  0.674376, 0.390625 (0.674 sec)
409.27... logprob:  0.627908, 0.320312 (0.677 sec)
410.1... logprob:  0.679805, 0.398438 (0.679 sec)
410.2... logprob:  0.596758, 0.273438 (0.674 sec)
410.3... logprob:  0.653858, 0.359375 (0.686 sec)
410.4... logprob:  0.596485, 0.273438 (0.682 sec)
410.5... logprob:  0.590820, 0.265625 (0.684 sec)
410.6... logprob:  0.611403, 0.296875 (0.678 sec)
410.7... logprob:  0.643804, 0.343750 (0.681 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643899, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935951e-03 [6.867361e-09] 
Layer 'conv1' biases: 6.413159e-07 [1.259677e-10] 
Layer 'conv2' weights[0]: 7.923992e-03 [5.787850e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.054142e-10] 
Layer 'conv3' weights[0]: 7.921544e-03 [5.584761e-09] 
Layer 'conv3' biases: 5.316573e-06 [1.837695e-09] 
Layer 'conv4' weights[0]: 7.954411e-03 [5.644705e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.553109e-08] 
Layer 'conv5' weights[0]: 7.953780e-03 [8.688053e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.162800e-08] 
Layer 'fc6' weights[0]: 7.549911e-03 [1.011864e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.260900e-09] 
Layer 'fc7' weights[0]: 7.428622e-03 [1.239700e-07] 
Layer 'fc7' biases: 9.998524e-01 [1.075529e-07] 
Layer 'fc8' weights[0]: 5.874634e-04 [5.561792e-06] 
Layer 'fc8' biases: 1.749599e-01 [1.421609e-04] 
Train error last 27 batches: 0.635637
-------------------------------------------------------
Not saving because 0.643899 > 0.627087 (334.9: -0.00%)
======================================================= (5.151 sec)
410.8... logprob:  0.604966, 0.289062 (0.683 sec)
410.9... logprob:  0.638492, 0.335938 (0.681 sec)
410.10... logprob:  0.598220, 0.281250 (0.680 sec)
410.11... logprob:  0.638747, 0.335938 (0.680 sec)
410.12... logprob:  0.716671, 0.437500 (0.681 sec)
410.13... logprob:  0.656953, 0.359375 (0.680 sec)
410.14... logprob:  0.662564, 0.367188 (0.683 sec)
410.15... logprob:  0.685563, 0.398438 (0.681 sec)
410.16... logprob:  0.627082, 0.320312 (0.675 sec)
410.17... logprob:  0.638501, 0.335938 (0.678 sec)
410.18... logprob:  0.638219, 0.335938 (0.677 sec)
410.19... logprob:  0.632697, 0.328125 (0.679 sec)
410.20... logprob:  0.648931, 0.351562 (0.679 sec)
410.21... logprob:  0.643452, 0.343750 (0.674 sec)
410.22... logprob:  0.627871, 0.320312 (0.677 sec)
410.23... logprob:  0.622939, 0.312500 (0.677 sec)
410.24... logprob:  0.577054, 0.242188 (0.678 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643449, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935882e-03 [6.530789e-09] 
Layer 'conv1' biases: 6.427602e-07 [6.058880e-11] 
Layer 'conv2' weights[0]: 7.923923e-03 [4.888314e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.021136e-10] 
Layer 'conv3' weights[0]: 7.921488e-03 [4.521654e-09] 
Layer 'conv3' biases: 5.329064e-06 [8.436079e-10] 
Layer 'conv4' weights[0]: 7.954346e-03 [4.465198e-09] 
Layer 'conv4' biases: 1.000001e+00 [5.896194e-09] 
Layer 'conv5' weights[0]: 7.953723e-03 [3.297243e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.446057e-08] 
Layer 'fc6' weights[0]: 7.549847e-03 [5.240329e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.465862e-09] 
Layer 'fc7' weights[0]: 7.427997e-03 [6.277659e-08] 
Layer 'fc7' biases: 9.998520e-01 [4.095881e-08] 
Layer 'fc8' weights[0]: 5.644686e-04 [2.052337e-06] 
Layer 'fc8' biases: 1.745525e-01 [6.491147e-05] 
Train error last 27 batches: 0.635635
-------------------------------------------------------
Not saving because 0.643449 > 0.627087 (334.9: -0.00%)
======================================================= (5.182 sec)
410.25... logprob:  0.628014, 0.320312 (0.680 sec)
410.26... logprob:  0.674380, 0.390625 (0.674 sec)
410.27... logprob:  0.627905, 0.320312 (0.677 sec)
411.1... logprob:  0.679809, 0.398438 (0.677 sec)
411.2... logprob:  0.596752, 0.273438 (0.680 sec)
411.3... logprob:  0.653859, 0.359375 (0.678 sec)
411.4... logprob:  0.596481, 0.273438 (0.676 sec)
411.5... logprob:  0.590816, 0.265625 (0.678 sec)
411.6... logprob:  0.611403, 0.296875 (0.677 sec)
411.7... logprob:  0.643805, 0.343750 (0.683 sec)
411.8... logprob:  0.604968, 0.289062 (0.675 sec)
411.9... logprob:  0.638491, 0.335938 (0.677 sec)
411.10... logprob:  0.598225, 0.281250 (0.677 sec)
411.11... logprob:  0.638744, 0.335938 (0.679 sec)
411.12... logprob:  0.716651, 0.437500 (0.679 sec)
411.13... logprob:  0.656947, 0.359375 (0.681 sec)
411.14... logprob:  0.662558, 0.367188 (0.679 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644621, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935820e-03 [6.762988e-09] 
Layer 'conv1' biases: 6.435370e-07 [1.470767e-10] 
Layer 'conv2' weights[0]: 7.923861e-03 [6.167824e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.613524e-10] 
Layer 'conv3' weights[0]: 7.921418e-03 [5.378464e-09] 
Layer 'conv3' biases: 5.333289e-06 [1.824985e-09] 
Layer 'conv4' weights[0]: 7.954285e-03 [5.334850e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.176267e-08] 
Layer 'conv5' weights[0]: 7.953628e-03 [6.572225e-08] 
Layer 'conv5' biases: 1.000002e+00 [6.933787e-08] 
Layer 'fc6' weights[0]: 7.549775e-03 [8.104035e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.037944e-09] 
Layer 'fc7' weights[0]: 7.427339e-03 [9.929411e-08] 
Layer 'fc7' biases: 9.998524e-01 [8.155035e-08] 
Layer 'fc8' weights[0]: 6.027655e-04 [4.261570e-06] 
Layer 'fc8' biases: 1.757743e-01 [8.320219e-05] 
Train error last 27 batches: 0.635634
-------------------------------------------------------
Not saving because 0.644621 > 0.627087 (334.9: -0.00%)
======================================================= (5.170 sec)
411.15... logprob:  0.685554, 0.398438 (0.679 sec)
411.16... logprob:  0.627081, 0.320312 (0.678 sec)
411.17... logprob:  0.638500, 0.335938 (0.679 sec)
411.18... logprob:  0.638219, 0.335938 (0.674 sec)
411.19... logprob:  0.632697, 0.328125 (0.678 sec)
411.20... logprob:  0.648933, 0.351562 (0.677 sec)
411.21... logprob:  0.643452, 0.343750 (0.677 sec)
411.22... logprob:  0.627869, 0.320312 (0.676 sec)
411.23... logprob:  0.622935, 0.312500 (0.679 sec)
411.24... logprob:  0.577041, 0.242188 (0.677 sec)
411.25... logprob:  0.628011, 0.320312 (0.677 sec)
411.26... logprob:  0.674386, 0.390625 (0.679 sec)
411.27... logprob:  0.627904, 0.320312 (0.680 sec)
412.1... logprob:  0.679816, 0.398438 (0.677 sec)
412.2... logprob:  0.596746, 0.273438 (0.684 sec)
412.3... logprob:  0.653861, 0.359375 (0.680 sec)
412.4... logprob:  0.596477, 0.273438 (0.679 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643517, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935757e-03 [6.920233e-09] 
Layer 'conv1' biases: 6.450277e-07 [8.826608e-11] 
Layer 'conv2' weights[0]: 7.923801e-03 [5.295285e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.519369e-10] 
Layer 'conv3' weights[0]: 7.921359e-03 [4.922275e-09] 
Layer 'conv3' biases: 5.346753e-06 [1.180850e-09] 
Layer 'conv4' weights[0]: 7.954217e-03 [4.862226e-09] 
Layer 'conv4' biases: 1.000001e+00 [8.661650e-09] 
Layer 'conv5' weights[0]: 7.953588e-03 [4.855985e-08] 
Layer 'conv5' biases: 1.000002e+00 [5.103247e-08] 
Layer 'fc6' weights[0]: 7.549708e-03 [6.512748e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.177548e-09] 
Layer 'fc7' weights[0]: 7.426716e-03 [7.939975e-08] 
Layer 'fc7' biases: 9.998520e-01 [6.006578e-08] 
Layer 'fc8' weights[0]: 5.712105e-04 [3.095366e-06] 
Layer 'fc8' biases: 1.751323e-01 [8.369552e-05] 
Train error last 27 batches: 0.635633
-------------------------------------------------------
Not saving because 0.643517 > 0.627087 (334.9: -0.00%)
======================================================= (5.192 sec)
412.5... logprob:  0.590814, 0.265625 (0.679 sec)
412.6... logprob:  0.611402, 0.296875 (0.677 sec)
412.7... logprob:  0.643804, 0.343750 (0.675 sec)
412.8... logprob:  0.604970, 0.289062 (0.676 sec)
412.9... logprob:  0.638490, 0.335938 (0.678 sec)
412.10... logprob:  0.598230, 0.281250 (0.678 sec)
412.11... logprob:  0.638742, 0.335938 (0.684 sec)
412.12... logprob:  0.716632, 0.437500 (0.675 sec)
412.13... logprob:  0.656941, 0.359375 (0.678 sec)
412.14... logprob:  0.662550, 0.367188 (0.677 sec)
412.15... logprob:  0.685546, 0.398438 (0.678 sec)
412.16... logprob:  0.627081, 0.320312 (0.677 sec)
412.17... logprob:  0.638500, 0.335938 (0.675 sec)
412.18... logprob:  0.638219, 0.335938 (0.676 sec)
412.19... logprob:  0.632696, 0.328125 (0.673 sec)
412.20... logprob:  0.648933, 0.351562 (0.683 sec)
412.21... logprob:  0.643453, 0.343750 (0.679 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643473, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935683e-03 [6.878733e-09] 
Layer 'conv1' biases: 6.462625e-07 [1.557597e-10] 
Layer 'conv2' weights[0]: 7.923741e-03 [6.512111e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.402571e-10] 
Layer 'conv3' weights[0]: 7.921286e-03 [5.660730e-09] 
Layer 'conv3' biases: 5.356861e-06 [2.021002e-09] 
Layer 'conv4' weights[0]: 7.954155e-03 [5.566657e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.338464e-08] 
Layer 'conv5' weights[0]: 7.953528e-03 [7.487171e-08] 
Layer 'conv5' biases: 1.000002e+00 [7.875584e-08] 
Layer 'fc6' weights[0]: 7.549634e-03 [9.086056e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.088574e-09] 
Layer 'fc7' weights[0]: 7.426066e-03 [1.118462e-07] 
Layer 'fc7' biases: 9.998519e-01 [9.493854e-08] 
Layer 'fc8' weights[0]: 5.671729e-04 [4.858684e-06] 
Layer 'fc8' biases: 1.752362e-01 [1.053469e-04] 
Train error last 27 batches: 0.635631
-------------------------------------------------------
Not saving because 0.643473 > 0.627087 (334.9: -0.00%)
======================================================= (5.157 sec)
412.22... logprob:  0.627866, 0.320312 (0.679 sec)
412.23... logprob:  0.622933, 0.312500 (0.679 sec)
412.24... logprob:  0.577029, 0.242188 (0.678 sec)
412.25... logprob:  0.628009, 0.320312 (0.678 sec)
412.26... logprob:  0.674391, 0.390625 (0.678 sec)
412.27... logprob:  0.627903, 0.320312 (0.679 sec)
413.1... logprob:  0.679820, 0.398438 (0.679 sec)
413.2... logprob:  0.596741, 0.273438 (0.677 sec)
413.3... logprob:  0.653862, 0.359375 (0.678 sec)
413.4... logprob:  0.596473, 0.273438 (0.679 sec)
413.5... logprob:  0.590810, 0.265625 (0.679 sec)
413.6... logprob:  0.611402, 0.296875 (0.684 sec)
413.7... logprob:  0.643804, 0.343750 (0.677 sec)
413.8... logprob:  0.604971, 0.289062 (0.680 sec)
413.9... logprob:  0.638489, 0.335938 (0.680 sec)
413.10... logprob:  0.598233, 0.281250 (0.680 sec)
413.11... logprob:  0.638740, 0.335938 (0.678 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644998, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935619e-03 [6.871615e-09] 
Layer 'conv1' biases: 6.470053e-07 [1.210284e-10] 
Layer 'conv2' weights[0]: 7.923683e-03 [5.782321e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.818729e-10] 
Layer 'conv3' weights[0]: 7.921224e-03 [5.577525e-09] 
Layer 'conv3' biases: 5.360354e-06 [1.803628e-09] 
Layer 'conv4' weights[0]: 7.954079e-03 [5.671314e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.525602e-08] 
Layer 'conv5' weights[0]: 7.953421e-03 [8.554263e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.051087e-08] 
Layer 'fc6' weights[0]: 7.549569e-03 [1.002036e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.135653e-09] 
Layer 'fc7' weights[0]: 7.425406e-03 [1.215641e-07] 
Layer 'fc7' biases: 9.998526e-01 [1.044313e-07] 
Layer 'fc8' weights[0]: 6.083642e-04 [5.507467e-06] 
Layer 'fc8' biases: 1.765248e-01 [1.369985e-04] 
Train error last 27 batches: 0.635631
-------------------------------------------------------
Not saving because 0.644998 > 0.627087 (334.9: -0.00%)
======================================================= (5.146 sec)
413.12... logprob:  0.716616, 0.437500 (0.678 sec)
413.13... logprob:  0.656935, 0.359375 (0.680 sec)
413.14... logprob:  0.662545, 0.367188 (0.679 sec)
413.15... logprob:  0.685539, 0.398438 (0.678 sec)
413.16... logprob:  0.627082, 0.320312 (0.682 sec)
413.17... logprob:  0.638500, 0.335938 (0.673 sec)
413.18... logprob:  0.638219, 0.335938 (0.675 sec)
413.19... logprob:  0.632696, 0.328125 (0.675 sec)
413.20... logprob:  0.648934, 0.351562 (0.680 sec)
413.21... logprob:  0.643453, 0.343750 (0.676 sec)
413.22... logprob:  0.627866, 0.320312 (0.677 sec)
413.23... logprob:  0.622930, 0.312500 (0.677 sec)
413.24... logprob:  0.577021, 0.242188 (0.677 sec)
413.25... logprob:  0.628007, 0.320312 (0.673 sec)
413.26... logprob:  0.674393, 0.390625 (0.675 sec)
413.27... logprob:  0.627901, 0.320312 (0.677 sec)
414.1... logprob:  0.679823, 0.398438 (0.679 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643467, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935551e-03 [6.720263e-09] 
Layer 'conv1' biases: 6.486243e-07 [8.588548e-11] 
Layer 'conv2' weights[0]: 7.923625e-03 [5.217807e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.500220e-10] 
Layer 'conv3' weights[0]: 7.921153e-03 [4.529520e-09] 
Layer 'conv3' biases: 5.375399e-06 [8.890434e-10] 
Layer 'conv4' weights[0]: 7.954020e-03 [4.444567e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.785147e-09] 
Layer 'conv5' weights[0]: 7.953400e-03 [2.072777e-08] 
Layer 'conv5' biases: 1.000002e+00 [2.135853e-08] 
Layer 'fc6' weights[0]: 7.549502e-03 [4.505533e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.266167e-09] 
Layer 'fc7' weights[0]: 7.424784e-03 [5.137765e-08] 
Layer 'fc7' biases: 9.998518e-01 [2.767824e-08] 
Layer 'fc8' weights[0]: 5.662724e-04 [1.352008e-06] 
Layer 'fc8' biases: 1.756169e-01 [2.456140e-05] 
Train error last 27 batches: 0.635629
-------------------------------------------------------
Not saving because 0.643467 > 0.627087 (334.9: -0.00%)
======================================================= (5.211 sec)
414.2... logprob:  0.596736, 0.273438 (0.673 sec)
414.3... logprob:  0.653863, 0.359375 (0.678 sec)
414.4... logprob:  0.596470, 0.273438 (0.680 sec)
414.5... logprob:  0.590808, 0.265625 (0.679 sec)
414.6... logprob:  0.611401, 0.296875 (0.682 sec)
414.7... logprob:  0.643803, 0.343750 (0.678 sec)
414.8... logprob:  0.604971, 0.289062 (0.679 sec)
414.9... logprob:  0.638488, 0.335938 (0.680 sec)
414.10... logprob:  0.598235, 0.281250 (0.679 sec)
414.11... logprob:  0.638738, 0.335938 (0.684 sec)
414.12... logprob:  0.716605, 0.437500 (0.680 sec)
414.13... logprob:  0.656931, 0.359375 (0.678 sec)
414.14... logprob:  0.662542, 0.367188 (0.680 sec)
414.15... logprob:  0.685535, 0.398438 (0.681 sec)
414.16... logprob:  0.627082, 0.320312 (0.678 sec)
414.17... logprob:  0.638499, 0.335938 (0.675 sec)
414.18... logprob:  0.638220, 0.335938 (0.677 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643699, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935492e-03 [6.553789e-09] 
Layer 'conv1' biases: 6.496653e-07 [1.718857e-10] 
Layer 'conv2' weights[0]: 7.923552e-03 [6.675559e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.261934e-10] 
Layer 'conv3' weights[0]: 7.921092e-03 [5.854015e-09] 
Layer 'conv3' biases: 5.383222e-06 [2.238425e-09] 
Layer 'conv4' weights[0]: 7.953951e-03 [5.838402e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.575175e-08] 
Layer 'conv5' weights[0]: 7.953323e-03 [8.816776e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.296354e-08] 
Layer 'fc6' weights[0]: 7.549436e-03 [1.027760e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.485666e-09] 
Layer 'fc7' weights[0]: 7.424135e-03 [1.258065e-07] 
Layer 'fc7' biases: 9.998521e-01 [1.100621e-07] 
Layer 'fc8' weights[0]: 5.795406e-04 [5.700419e-06] 
Layer 'fc8' biases: 1.761881e-01 [1.209925e-04] 
Train error last 27 batches: 0.635628
-------------------------------------------------------
Not saving because 0.643699 > 0.627087 (334.9: -0.00%)
======================================================= (5.146 sec)
414.19... logprob:  0.632696, 0.328125 (0.676 sec)
414.20... logprob:  0.648935, 0.351562 (0.678 sec)
414.21... logprob:  0.643453, 0.343750 (0.677 sec)
414.22... logprob:  0.627863, 0.320312 (0.678 sec)
414.23... logprob:  0.622926, 0.312500 (0.677 sec)
414.24... logprob:  0.577008, 0.242188 (0.677 sec)
414.25... logprob:  0.628004, 0.320312 (0.676 sec)
414.26... logprob:  0.674398, 0.390625 (0.676 sec)
414.27... logprob:  0.627899, 0.320312 (0.677 sec)
415.1... logprob:  0.679827, 0.398438 (0.680 sec)
415.2... logprob:  0.596731, 0.273438 (0.677 sec)
415.3... logprob:  0.653864, 0.359375 (0.677 sec)
415.4... logprob:  0.596466, 0.273438 (0.677 sec)
415.5... logprob:  0.590806, 0.265625 (0.677 sec)
415.6... logprob:  0.611401, 0.296875 (0.682 sec)
415.7... logprob:  0.643803, 0.343750 (0.675 sec)
415.8... logprob:  0.604975, 0.289062 (0.677 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644123, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935421e-03 [7.236365e-09] 
Layer 'conv1' biases: 6.506943e-07 [1.439688e-10] 
Layer 'conv2' weights[0]: 7.923489e-03 [6.283961e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.447118e-10] 
Layer 'conv3' weights[0]: 7.921022e-03 [6.038774e-09] 
Layer 'conv3' biases: 5.390839e-06 [2.183470e-09] 
Layer 'conv4' weights[0]: 7.953881e-03 [6.146471e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.862666e-08] 
Layer 'conv5' weights[0]: 7.953246e-03 [1.040177e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.097454e-07] 
Layer 'fc6' weights[0]: 7.549367e-03 [1.173538e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.112325e-08] 
Layer 'fc7' weights[0]: 7.423471e-03 [1.427526e-07] 
Layer 'fc7' biases: 9.998523e-01 [1.285354e-07] 
Layer 'fc8' weights[0]: 5.917970e-04 [6.663465e-06] 
Layer 'fc8' biases: 1.767065e-01 [1.679073e-04] 
Train error last 27 batches: 0.635627
-------------------------------------------------------
Not saving because 0.644123 > 0.627087 (334.9: -0.00%)
======================================================= (5.143 sec)
415.9... logprob:  0.638487, 0.335938 (0.680 sec)
415.10... logprob:  0.598242, 0.281250 (0.678 sec)
415.11... logprob:  0.638736, 0.335938 (0.680 sec)
415.12... logprob:  0.716581, 0.437500 (0.679 sec)
415.13... logprob:  0.656924, 0.359375 (0.677 sec)
415.14... logprob:  0.662533, 0.367188 (0.679 sec)
415.15... logprob:  0.685524, 0.398438 (0.677 sec)
415.16... logprob:  0.627083, 0.320312 (0.677 sec)
415.17... logprob:  0.638500, 0.335938 (0.678 sec)
415.18... logprob:  0.638219, 0.335938 (0.677 sec)
415.19... logprob:  0.632695, 0.328125 (0.679 sec)
415.20... logprob:  0.648936, 0.351562 (0.676 sec)
415.21... logprob:  0.643454, 0.343750 (0.677 sec)
415.22... logprob:  0.627861, 0.320312 (0.676 sec)
415.23... logprob:  0.622923, 0.312500 (0.677 sec)
415.24... logprob:  0.576993, 0.242188 (0.681 sec)
415.25... logprob:  0.628002, 0.320312 (0.676 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643466, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935359e-03 [6.645752e-09] 
Layer 'conv1' biases: 6.521592e-07 [6.832343e-11] 
Layer 'conv2' weights[0]: 7.923422e-03 [4.957349e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.571013e-10] 
Layer 'conv3' weights[0]: 7.920946e-03 [4.635992e-09] 
Layer 'conv3' biases: 5.403655e-06 [1.004476e-09] 
Layer 'conv4' weights[0]: 7.953821e-03 [4.617534e-09] 
Layer 'conv4' biases: 1.000001e+00 [7.566162e-09] 
Layer 'conv5' weights[0]: 7.953200e-03 [4.209640e-08] 
Layer 'conv5' biases: 1.000002e+00 [4.422544e-08] 
Layer 'fc6' weights[0]: 7.549297e-03 [5.951567e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.475643e-09] 
Layer 'fc7' weights[0]: 7.422860e-03 [7.262826e-08] 
Layer 'fc7' biases: 9.998517e-01 [5.269068e-08] 
Layer 'fc8' weights[0]: 5.655397e-04 [2.654166e-06] 
Layer 'fc8' biases: 1.762131e-01 [7.911590e-05] 
Train error last 27 batches: 0.635625
-------------------------------------------------------
Not saving because 0.643466 > 0.627087 (334.9: -0.00%)
======================================================= (5.202 sec)
415.26... logprob:  0.674404, 0.390625 (0.677 sec)
415.27... logprob:  0.627897, 0.320312 (0.679 sec)
416.1... logprob:  0.679833, 0.398438 (0.677 sec)
416.2... logprob:  0.596725, 0.273438 (0.682 sec)
416.3... logprob:  0.653866, 0.359375 (0.678 sec)
416.4... logprob:  0.596462, 0.273438 (0.678 sec)
416.5... logprob:  0.590803, 0.265625 (0.676 sec)
416.6... logprob:  0.611400, 0.296875 (0.678 sec)
416.7... logprob:  0.643802, 0.343750 (0.676 sec)
416.8... logprob:  0.604977, 0.289062 (0.673 sec)
416.9... logprob:  0.638487, 0.335938 (0.677 sec)
416.10... logprob:  0.598246, 0.281250 (0.683 sec)
416.11... logprob:  0.638734, 0.335938 (0.672 sec)
416.12... logprob:  0.716564, 0.437500 (0.673 sec)
416.13... logprob:  0.656918, 0.359375 (0.678 sec)
416.14... logprob:  0.662528, 0.367188 (0.678 sec)
416.15... logprob:  0.685516, 0.398438 (0.679 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644276, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935294e-03 [7.316107e-09] 
Layer 'conv1' biases: 6.530329e-07 [2.015166e-10] 
Layer 'conv2' weights[0]: 7.923354e-03 [7.510984e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.997247e-10] 
Layer 'conv3' weights[0]: 7.920876e-03 [6.480238e-09] 
Layer 'conv3' biases: 5.409212e-06 [2.760312e-09] 
Layer 'conv4' weights[0]: 7.953759e-03 [6.527605e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.997770e-08] 
Layer 'conv5' weights[0]: 7.953102e-03 [1.117035e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.178878e-07] 
Layer 'fc6' weights[0]: 7.549215e-03 [1.250642e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.199474e-08] 
Layer 'fc7' weights[0]: 7.422195e-03 [1.512522e-07] 
Layer 'fc7' biases: 9.998523e-01 [1.380572e-07] 
Layer 'fc8' weights[0]: 5.947899e-04 [7.210685e-06] 
Layer 'fc8' biases: 1.771993e-01 [1.519653e-04] 
Train error last 27 batches: 0.635623
-------------------------------------------------------
Not saving because 0.644276 > 0.627087 (334.9: -0.00%)
======================================================= (5.136 sec)
416.16... logprob:  0.627082, 0.320312 (0.677 sec)
416.17... logprob:  0.638499, 0.335938 (0.675 sec)
416.18... logprob:  0.638218, 0.335938 (0.678 sec)
416.19... logprob:  0.632695, 0.328125 (0.678 sec)
416.20... logprob:  0.648937, 0.351562 (0.683 sec)
416.21... logprob:  0.643455, 0.343750 (0.678 sec)
416.22... logprob:  0.627859, 0.320312 (0.674 sec)
416.23... logprob:  0.622920, 0.312500 (0.679 sec)
416.24... logprob:  0.576982, 0.242188 (0.676 sec)
416.25... logprob:  0.628000, 0.320312 (0.678 sec)
416.26... logprob:  0.674408, 0.390625 (0.678 sec)
416.27... logprob:  0.627895, 0.320312 (0.679 sec)
417.1... logprob:  0.679837, 0.398438 (0.677 sec)
417.2... logprob:  0.596720, 0.273438 (0.677 sec)
417.3... logprob:  0.653866, 0.359375 (0.677 sec)
417.4... logprob:  0.596459, 0.273438 (0.675 sec)
417.5... logprob:  0.590801, 0.265625 (0.679 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643603, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935233e-03 [7.527928e-09] 
Layer 'conv1' biases: 6.543930e-07 [1.362339e-10] 
Layer 'conv2' weights[0]: 7.923292e-03 [5.947812e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.341677e-10] 
Layer 'conv3' weights[0]: 7.920821e-03 [5.711504e-09] 
Layer 'conv3' biases: 5.421147e-06 [1.906789e-09] 
Layer 'conv4' weights[0]: 7.953687e-03 [5.715179e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.572265e-08] 
Layer 'conv5' weights[0]: 7.953048e-03 [8.807098e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.285178e-08] 
Layer 'fc6' weights[0]: 7.549140e-03 [1.030307e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.468167e-09] 
Layer 'fc7' weights[0]: 7.421580e-03 [1.258538e-07] 
Layer 'fc7' biases: 9.998518e-01 [1.097859e-07] 
Layer 'fc8' weights[0]: 5.747833e-04 [5.643382e-06] 
Layer 'fc8' biases: 1.768550e-01 [1.468342e-04] 
Train error last 27 batches: 0.635622
-------------------------------------------------------
Not saving because 0.643603 > 0.627087 (334.9: -0.00%)
======================================================= (5.153 sec)
417.6... logprob:  0.611401, 0.296875 (0.683 sec)
417.7... logprob:  0.643802, 0.343750 (0.678 sec)
417.8... logprob:  0.604978, 0.289062 (0.681 sec)
417.9... logprob:  0.638486, 0.335938 (0.678 sec)
417.10... logprob:  0.598250, 0.281250 (0.681 sec)
417.11... logprob:  0.638732, 0.335938 (0.685 sec)
417.12... logprob:  0.716546, 0.437500 (0.676 sec)
417.13... logprob:  0.656913, 0.359375 (0.679 sec)
417.14... logprob:  0.662521, 0.367188 (0.679 sec)
417.15... logprob:  0.685510, 0.398438 (0.683 sec)
417.16... logprob:  0.627083, 0.320312 (0.676 sec)
417.17... logprob:  0.638500, 0.335938 (0.677 sec)
417.18... logprob:  0.638218, 0.335938 (0.674 sec)
417.19... logprob:  0.632694, 0.328125 (0.679 sec)
417.20... logprob:  0.648937, 0.351562 (0.676 sec)
417.21... logprob:  0.643455, 0.343750 (0.676 sec)
417.22... logprob:  0.627858, 0.320312 (0.674 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643451, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935158e-03 [6.746561e-09] 
Layer 'conv1' biases: 6.557007e-07 [1.377289e-10] 
Layer 'conv2' weights[0]: 7.923218e-03 [6.087219e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.997743e-10] 
Layer 'conv3' weights[0]: 7.920753e-03 [5.282178e-09] 
Layer 'conv3' biases: 5.432184e-06 [1.614740e-09] 
Layer 'conv4' weights[0]: 7.953624e-03 [5.164237e-09] 
Layer 'conv4' biases: 1.000001e+00 [9.924577e-09] 
Layer 'conv5' weights[0]: 7.953001e-03 [5.530759e-08] 
Layer 'conv5' biases: 1.000002e+00 [5.804806e-08] 
Layer 'fc6' weights[0]: 7.549070e-03 [7.155748e-09] 
Layer 'fc6' biases: 9.999999e-01 [5.969479e-09] 
Layer 'fc7' weights[0]: 7.420952e-03 [8.826205e-08] 
Layer 'fc7' biases: 9.998516e-01 [7.030717e-08] 
Layer 'fc8' weights[0]: 5.629013e-04 [3.561235e-06] 
Layer 'fc8' biases: 1.767380e-01 [7.539698e-05] 
Train error last 27 batches: 0.635621
-------------------------------------------------------
Not saving because 0.643451 > 0.627087 (334.9: -0.00%)
======================================================= (5.173 sec)
417.23... logprob:  0.622917, 0.312500 (0.682 sec)
417.24... logprob:  0.576972, 0.242188 (0.696 sec)
417.25... logprob:  0.627997, 0.320312 (0.695 sec)
417.26... logprob:  0.674412, 0.390625 (0.693 sec)
417.27... logprob:  0.627893, 0.320312 (0.689 sec)
418.1... logprob:  0.679842, 0.398438 (0.687 sec)
418.2... logprob:  0.596714, 0.273438 (0.692 sec)
418.3... logprob:  0.653867, 0.359375 (0.705 sec)
418.4... logprob:  0.596454, 0.273438 (0.703 sec)
418.5... logprob:  0.590796, 0.265625 (0.696 sec)
418.6... logprob:  0.611399, 0.296875 (0.707 sec)
418.7... logprob:  0.643802, 0.343750 (0.701 sec)
418.8... logprob:  0.604979, 0.289062 (0.699 sec)
418.9... logprob:  0.638486, 0.335938 (0.702 sec)
418.10... logprob:  0.598252, 0.281250 (0.704 sec)
418.11... logprob:  0.638730, 0.335938 (0.697 sec)
418.12... logprob:  0.716534, 0.437500 (0.699 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644954, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935095e-03 [6.940546e-09] 
Layer 'conv1' biases: 6.564045e-07 [8.100662e-11] 
Layer 'conv2' weights[0]: 7.923163e-03 [5.250598e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.116053e-10] 
Layer 'conv3' weights[0]: 7.920690e-03 [4.541576e-09] 
Layer 'conv3' biases: 5.435482e-06 [7.780570e-10] 
Layer 'conv4' weights[0]: 7.953555e-03 [4.407209e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.235277e-09] 
Layer 'conv5' weights[0]: 7.952904e-03 [8.111315e-09] 
Layer 'conv5' biases: 1.000002e+00 [7.307263e-09] 
Layer 'fc6' weights[0]: 7.549007e-03 [3.885863e-09] 
Layer 'fc6' biases: 9.999999e-01 [8.366524e-10] 
Layer 'fc7' weights[0]: 7.420316e-03 [3.996561e-08] 
Layer 'fc7' biases: 9.998525e-01 [1.133862e-08] 
Layer 'fc8' weights[0]: 6.062483e-04 [4.767260e-07] 
Layer 'fc8' biases: 1.780997e-01 [3.538047e-06] 
Train error last 27 batches: 0.635620
-------------------------------------------------------
Not saving because 0.644954 > 0.627087 (334.9: -0.00%)
======================================================= (5.329 sec)
418.13... logprob:  0.656909, 0.359375 (0.678 sec)
418.14... logprob:  0.662518, 0.367188 (0.680 sec)
418.15... logprob:  0.685506, 0.398438 (0.681 sec)
418.16... logprob:  0.627083, 0.320312 (0.675 sec)
418.17... logprob:  0.638500, 0.335938 (0.678 sec)
418.18... logprob:  0.638219, 0.335938 (0.672 sec)
418.19... logprob:  0.632694, 0.328125 (0.676 sec)
418.20... logprob:  0.648939, 0.351562 (0.675 sec)
418.21... logprob:  0.643456, 0.343750 (0.675 sec)
418.22... logprob:  0.627855, 0.320312 (0.676 sec)
418.23... logprob:  0.622913, 0.312500 (0.675 sec)
418.24... logprob:  0.576956, 0.242188 (0.675 sec)
418.25... logprob:  0.627995, 0.320312 (0.675 sec)
418.26... logprob:  0.674418, 0.390625 (0.674 sec)
418.27... logprob:  0.627891, 0.320312 (0.679 sec)
419.1... logprob:  0.679847, 0.398438 (0.671 sec)
419.2... logprob:  0.596709, 0.273438 (0.676 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643480, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935020e-03 [6.890272e-09] 
Layer 'conv1' biases: 6.579953e-07 [7.143514e-11] 
Layer 'conv2' weights[0]: 7.923103e-03 [4.999895e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.779886e-10] 
Layer 'conv3' weights[0]: 7.920611e-03 [4.521729e-09] 
Layer 'conv3' biases: 5.450273e-06 [7.536801e-10] 
Layer 'conv4' weights[0]: 7.953499e-03 [4.428453e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.965655e-09] 
Layer 'conv5' weights[0]: 7.952857e-03 [2.295166e-08] 
Layer 'conv5' biases: 1.000002e+00 [2.387176e-08] 
Layer 'fc6' weights[0]: 7.548939e-03 [4.610678e-09] 
Layer 'fc6' biases: 9.999999e-01 [2.409742e-09] 
Layer 'fc7' weights[0]: 7.419685e-03 [5.241174e-08] 
Layer 'fc7' biases: 9.998516e-01 [2.834059e-08] 
Layer 'fc8' weights[0]: 5.662077e-04 [1.432496e-06] 
Layer 'fc8' biases: 1.772323e-01 [4.380268e-05] 
Train error last 27 batches: 0.635619
-------------------------------------------------------
Not saving because 0.643480 > 0.627087 (334.9: -0.00%)
======================================================= (5.217 sec)
419.3... logprob:  0.653869, 0.359375 (0.681 sec)
419.4... logprob:  0.596451, 0.273438 (0.679 sec)
419.5... logprob:  0.590795, 0.265625 (0.679 sec)
419.6... logprob:  0.611400, 0.296875 (0.684 sec)
419.7... logprob:  0.643801, 0.343750 (0.677 sec)
419.8... logprob:  0.604984, 0.289062 (0.681 sec)
419.9... logprob:  0.638484, 0.335938 (0.681 sec)
419.10... logprob:  0.598260, 0.281250 (0.683 sec)
419.11... logprob:  0.638727, 0.335938 (0.681 sec)
419.12... logprob:  0.716506, 0.437500 (0.677 sec)
419.13... logprob:  0.656899, 0.359375 (0.682 sec)
419.14... logprob:  0.662508, 0.367188 (0.683 sec)
419.15... logprob:  0.685492, 0.398438 (0.678 sec)
419.16... logprob:  0.627084, 0.320312 (0.680 sec)
419.17... logprob:  0.638499, 0.335938 (0.681 sec)
419.18... logprob:  0.638219, 0.335938 (0.681 sec)
419.19... logprob:  0.632695, 0.328125 (0.676 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643603, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934953e-03 [6.798021e-09] 
Layer 'conv1' biases: 6.590948e-07 [1.554384e-10] 
Layer 'conv2' weights[0]: 7.923034e-03 [6.525984e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.482822e-10] 
Layer 'conv3' weights[0]: 7.920554e-03 [5.658153e-09] 
Layer 'conv3' biases: 5.458789e-06 [2.029722e-09] 
Layer 'conv4' weights[0]: 7.953432e-03 [5.601188e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.363907e-08] 
Layer 'conv5' weights[0]: 7.952788e-03 [7.574686e-08] 
Layer 'conv5' biases: 1.000002e+00 [7.971528e-08] 
Layer 'fc6' weights[0]: 7.548863e-03 [9.134720e-09] 
Layer 'fc6' biases: 9.999999e-01 [8.139614e-09] 
Layer 'fc7' weights[0]: 7.419060e-03 [1.117866e-07] 
Layer 'fc7' biases: 9.998518e-01 [9.476744e-08] 
Layer 'fc8' weights[0]: 5.739368e-04 [4.863648e-06] 
Layer 'fc8' biases: 1.776554e-01 [1.036750e-04] 
Train error last 27 batches: 0.635617
-------------------------------------------------------
Not saving because 0.643603 > 0.627087 (334.9: -0.00%)
======================================================= (5.149 sec)
419.20... logprob:  0.648940, 0.351562 (0.676 sec)
419.21... logprob:  0.643457, 0.343750 (0.675 sec)
419.22... logprob:  0.627853, 0.320312 (0.676 sec)
419.23... logprob:  0.622909, 0.312500 (0.676 sec)
419.24... logprob:  0.576944, 0.242188 (0.681 sec)
419.25... logprob:  0.627992, 0.320312 (0.674 sec)
419.26... logprob:  0.674424, 0.390625 (0.678 sec)
419.27... logprob:  0.627890, 0.320312 (0.678 sec)
420.1... logprob:  0.679853, 0.398438 (0.681 sec)
420.2... logprob:  0.596702, 0.273438 (0.677 sec)
420.3... logprob:  0.653870, 0.359375 (0.673 sec)
420.4... logprob:  0.596445, 0.273438 (0.677 sec)
420.5... logprob:  0.590791, 0.265625 (0.679 sec)
420.6... logprob:  0.611399, 0.296875 (0.676 sec)
420.7... logprob:  0.643801, 0.343750 (0.676 sec)
420.8... logprob:  0.604984, 0.289062 (0.676 sec)
420.9... logprob:  0.638484, 0.335938 (0.679 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644341, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934877e-03 [6.746469e-09] 
Layer 'conv1' biases: 6.600303e-07 [1.203332e-10] 
Layer 'conv2' weights[0]: 7.922972e-03 [5.839778e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.063228e-10] 
Layer 'conv3' weights[0]: 7.920493e-03 [5.649551e-09] 
Layer 'conv3' biases: 5.464994e-06 [1.842213e-09] 
Layer 'conv4' weights[0]: 7.953368e-03 [5.751871e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.568086e-08] 
Layer 'conv5' weights[0]: 7.952713e-03 [8.691595e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.168512e-08] 
Layer 'fc6' weights[0]: 7.548785e-03 [1.012480e-08] 
Layer 'fc6' biases: 9.999999e-01 [9.263628e-09] 
Layer 'fc7' weights[0]: 7.418438e-03 [1.232833e-07] 
Layer 'fc7' biases: 9.998521e-01 [1.065817e-07] 
Layer 'fc8' weights[0]: 5.950831e-04 [5.526932e-06] 
Layer 'fc8' biases: 1.784138e-01 [1.411833e-04] 
Train error last 27 batches: 0.635616
-------------------------------------------------------
Not saving because 0.644341 > 0.627087 (334.9: -0.00%)
======================================================= (5.129 sec)
420.10... logprob:  0.598263, 0.281250 (0.679 sec)
420.11... logprob:  0.638725, 0.335938 (0.686 sec)
420.12... logprob:  0.716490, 0.437500 (0.679 sec)
420.13... logprob:  0.656893, 0.359375 (0.680 sec)
420.14... logprob:  0.662503, 0.367188 (0.680 sec)
420.15... logprob:  0.685485, 0.398438 (0.682 sec)
420.16... logprob:  0.627083, 0.320312 (0.678 sec)
420.17... logprob:  0.638499, 0.335938 (0.681 sec)
420.18... logprob:  0.638218, 0.335938 (0.679 sec)
420.19... logprob:  0.632693, 0.328125 (0.685 sec)
420.20... logprob:  0.648940, 0.351562 (0.680 sec)
420.21... logprob:  0.643456, 0.343750 (0.679 sec)
420.22... logprob:  0.627851, 0.320312 (0.680 sec)
420.23... logprob:  0.622908, 0.312500 (0.683 sec)
420.24... logprob:  0.576936, 0.242188 (0.683 sec)
420.25... logprob:  0.627991, 0.320312 (0.681 sec)
420.26... logprob:  0.674427, 0.390625 (0.682 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643471, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934808e-03 [6.601972e-09] 
Layer 'conv1' biases: 6.615330e-07 [7.306152e-11] 
Layer 'conv2' weights[0]: 7.922910e-03 [5.060729e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.450330e-10] 
Layer 'conv3' weights[0]: 7.920426e-03 [4.418819e-09] 
Layer 'conv3' biases: 5.478532e-06 [6.032016e-10] 
Layer 'conv4' weights[0]: 7.953306e-03 [4.324777e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.055361e-09] 
Layer 'conv5' weights[0]: 7.952654e-03 [7.434187e-09] 
Layer 'conv5' biases: 1.000002e+00 [6.736540e-09] 
Layer 'fc6' weights[0]: 7.548716e-03 [3.863571e-09] 
Layer 'fc6' biases: 9.999999e-01 [7.051228e-10] 
Layer 'fc7' weights[0]: 7.417780e-03 [3.897405e-08] 
Layer 'fc7' biases: 9.998516e-01 [8.504890e-09] 
Layer 'fc8' weights[0]: 5.646639e-04 [3.966259e-07] 
Layer 'fc8' biases: 1.778024e-01 [2.021014e-05] 
Train error last 27 batches: 0.635614
-------------------------------------------------------
Not saving because 0.643471 > 0.627087 (334.9: -0.00%)
======================================================= (5.282 sec)
420.27... logprob:  0.627887, 0.320312 (0.681 sec)
421.1... logprob:  0.679857, 0.398438 (0.681 sec)
421.2... logprob:  0.596699, 0.273438 (0.688 sec)
421.3... logprob:  0.653871, 0.359375 (0.679 sec)
421.4... logprob:  0.596443, 0.273438 (0.678 sec)
421.5... logprob:  0.590788, 0.265625 (0.679 sec)
421.6... logprob:  0.611398, 0.296875 (0.683 sec)
421.7... logprob:  0.643801, 0.343750 (0.678 sec)
421.8... logprob:  0.604985, 0.289062 (0.680 sec)
421.9... logprob:  0.638483, 0.335938 (0.681 sec)
421.10... logprob:  0.598266, 0.281250 (0.679 sec)
421.11... logprob:  0.638723, 0.335938 (0.679 sec)
421.12... logprob:  0.716478, 0.437500 (0.679 sec)
421.13... logprob:  0.656890, 0.359375 (0.678 sec)
421.14... logprob:  0.662499, 0.367188 (0.681 sec)
421.15... logprob:  0.685481, 0.398438 (0.675 sec)
421.16... logprob:  0.627083, 0.320312 (0.675 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644032, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934738e-03 [6.949227e-09] 
Layer 'conv1' biases: 6.624630e-07 [1.803968e-10] 
Layer 'conv2' weights[0]: 7.922843e-03 [7.077551e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.015458e-10] 
Layer 'conv3' weights[0]: 7.920358e-03 [6.134185e-09] 
Layer 'conv3' biases: 5.484860e-06 [2.460129e-09] 
Layer 'conv4' weights[0]: 7.953239e-03 [6.155192e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.741971e-08] 
Layer 'conv5' weights[0]: 7.952580e-03 [9.710361e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.022805e-07] 
Layer 'fc6' weights[0]: 7.548650e-03 [1.105128e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.041044e-08] 
Layer 'fc7' weights[0]: 7.417158e-03 [1.345393e-07] 
Layer 'fc7' biases: 9.998519e-01 [1.199862e-07] 
Layer 'fc8' weights[0]: 5.878145e-04 [6.235777e-06] 
Layer 'fc8' biases: 1.786325e-01 [1.321914e-04] 
Train error last 27 batches: 0.635613
-------------------------------------------------------
Not saving because 0.644032 > 0.627087 (334.9: -0.00%)
======================================================= (5.142 sec)
421.17... logprob:  0.638498, 0.335938 (0.677 sec)
421.18... logprob:  0.638218, 0.335938 (0.674 sec)
421.19... logprob:  0.632693, 0.328125 (0.674 sec)
421.20... logprob:  0.648942, 0.351562 (0.681 sec)
421.21... logprob:  0.643457, 0.343750 (0.679 sec)
421.22... logprob:  0.627849, 0.320312 (0.679 sec)
421.23... logprob:  0.622903, 0.312500 (0.681 sec)
421.24... logprob:  0.576921, 0.242188 (0.681 sec)
421.25... logprob:  0.627987, 0.320312 (0.675 sec)
421.26... logprob:  0.674432, 0.390625 (0.679 sec)
421.27... logprob:  0.627885, 0.320312 (0.679 sec)
422.1... logprob:  0.679862, 0.398438 (0.682 sec)
422.2... logprob:  0.596693, 0.273438 (0.680 sec)
422.3... logprob:  0.653872, 0.359375 (0.678 sec)
422.4... logprob:  0.596439, 0.273438 (0.676 sec)
422.5... logprob:  0.590787, 0.265625 (0.682 sec)
422.6... logprob:  0.611398, 0.296875 (0.690 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643741, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934682e-03 [7.440758e-09] 
Layer 'conv1' biases: 6.636971e-07 [1.613717e-10] 
Layer 'conv2' weights[0]: 7.922780e-03 [6.237014e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.496597e-10] 
Layer 'conv3' weights[0]: 7.920298e-03 [5.995969e-09] 
Layer 'conv3' biases: 5.495249e-06 [2.168897e-09] 
Layer 'conv4' weights[0]: 7.953176e-03 [6.046350e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.849705e-08] 
Layer 'conv5' weights[0]: 7.952528e-03 [1.027820e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.082671e-07] 
Layer 'fc6' weights[0]: 7.548582e-03 [1.166823e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.104014e-08] 
Layer 'fc7' weights[0]: 7.416516e-03 [1.424337e-07] 
Layer 'fc7' biases: 9.998518e-01 [1.282352e-07] 
Layer 'fc8' weights[0]: 5.791280e-04 [6.574663e-06] 
Layer 'fc8' biases: 1.785874e-01 [1.697706e-04] 
Train error last 27 batches: 0.635612
-------------------------------------------------------
Not saving because 0.643741 > 0.627087 (334.9: -0.00%)
======================================================= (5.158 sec)
422.7... logprob:  0.643801, 0.343750 (0.688 sec)
422.8... logprob:  0.604988, 0.289062 (0.680 sec)
422.9... logprob:  0.638482, 0.335938 (0.681 sec)
422.10... logprob:  0.598272, 0.281250 (0.681 sec)
422.11... logprob:  0.638720, 0.335938 (0.683 sec)
422.12... logprob:  0.716455, 0.437500 (0.679 sec)
422.13... logprob:  0.656882, 0.359375 (0.680 sec)
422.14... logprob:  0.662491, 0.367188 (0.679 sec)
422.15... logprob:  0.685471, 0.398438 (0.680 sec)
422.16... logprob:  0.627083, 0.320312 (0.678 sec)
422.17... logprob:  0.638499, 0.335938 (0.677 sec)
422.18... logprob:  0.638218, 0.335938 (0.677 sec)
422.19... logprob:  0.632692, 0.328125 (0.680 sec)
422.20... logprob:  0.648942, 0.351562 (0.675 sec)
422.21... logprob:  0.643457, 0.343750 (0.675 sec)
422.22... logprob:  0.627847, 0.320312 (0.673 sec)
422.23... logprob:  0.622900, 0.312500 (0.675 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643443, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934623e-03 [6.377913e-09] 
Layer 'conv1' biases: 6.650912e-07 [1.091402e-10] 
Layer 'conv2' weights[0]: 7.922712e-03 [5.380549e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.249800e-10] 
Layer 'conv3' weights[0]: 7.920231e-03 [4.758494e-09] 
Layer 'conv3' biases: 5.507463e-06 [1.107312e-09] 
Layer 'conv4' weights[0]: 7.953112e-03 [4.634466e-09] 
Layer 'conv4' biases: 1.000001e+00 [5.732346e-09] 
Layer 'conv5' weights[0]: 7.952454e-03 [3.218645e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.354421e-08] 
Layer 'fc6' weights[0]: 7.548509e-03 [5.231283e-09] 
Layer 'fc6' biases: 9.999999e-01 [3.487314e-09] 
Layer 'fc7' weights[0]: 7.415882e-03 [6.269525e-08] 
Layer 'fc7' biases: 9.998516e-01 [4.121890e-08] 
Layer 'fc8' weights[0]: 5.599787e-04 [2.069849e-06] 
Layer 'fc8' biases: 1.782634e-01 [3.931941e-05] 
Train error last 27 batches: 0.635610
-------------------------------------------------------
Not saving because 0.643443 > 0.627087 (334.9: -0.00%)
======================================================= (5.201 sec)
422.24... logprob:  0.576910, 0.242188 (0.673 sec)
422.25... logprob:  0.627986, 0.320312 (0.679 sec)
422.26... logprob:  0.674436, 0.390625 (0.672 sec)
422.27... logprob:  0.627884, 0.320312 (0.676 sec)
423.1... logprob:  0.679866, 0.398438 (0.677 sec)
423.2... logprob:  0.596687, 0.273438 (0.679 sec)
423.3... logprob:  0.653874, 0.359375 (0.678 sec)
423.4... logprob:  0.596435, 0.273438 (0.681 sec)
423.5... logprob:  0.590782, 0.265625 (0.681 sec)
423.6... logprob:  0.611396, 0.296875 (0.682 sec)
423.7... logprob:  0.643801, 0.343750 (0.679 sec)
423.8... logprob:  0.604989, 0.289062 (0.684 sec)
423.9... logprob:  0.638482, 0.335938 (0.682 sec)
423.10... logprob:  0.598275, 0.281250 (0.684 sec)
423.11... logprob:  0.638719, 0.335938 (0.684 sec)
423.12... logprob:  0.716439, 0.437500 (0.677 sec)
423.13... logprob:  0.656878, 0.359375 (0.678 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644810, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934556e-03 [6.558653e-09] 
Layer 'conv1' biases: 6.657910e-07 [9.702695e-11] 
Layer 'conv2' weights[0]: 7.922645e-03 [5.383502e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.322578e-10] 
Layer 'conv3' weights[0]: 7.920162e-03 [4.722296e-09] 
Layer 'conv3' biases: 5.510631e-06 [1.192793e-09] 
Layer 'conv4' weights[0]: 7.953051e-03 [4.635806e-09] 
Layer 'conv4' biases: 1.000001e+00 [6.226416e-09] 
Layer 'conv5' weights[0]: 7.952397e-03 [3.490394e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.657505e-08] 
Layer 'fc6' weights[0]: 7.548443e-03 [5.375256e-09] 
Layer 'fc6' biases: 9.999999e-01 [3.714800e-09] 
Layer 'fc7' weights[0]: 7.415231e-03 [6.494965e-08] 
Layer 'fc7' biases: 9.998521e-01 [4.369374e-08] 
Layer 'fc8' weights[0]: 6.026385e-04 [2.238204e-06] 
Layer 'fc8' biases: 1.796206e-01 [3.788104e-05] 
Train error last 27 batches: 0.635609
-------------------------------------------------------
Not saving because 0.644810 > 0.627087 (334.9: -0.00%)
======================================================= (5.217 sec)
423.14... logprob:  0.662486, 0.367188 (0.678 sec)
423.15... logprob:  0.685465, 0.398438 (0.677 sec)
423.16... logprob:  0.627084, 0.320312 (0.676 sec)
423.17... logprob:  0.638498, 0.335938 (0.678 sec)
423.18... logprob:  0.638218, 0.335938 (0.676 sec)
423.19... logprob:  0.632692, 0.328125 (0.675 sec)
423.20... logprob:  0.648943, 0.351562 (0.675 sec)
423.21... logprob:  0.643457, 0.343750 (0.678 sec)
423.22... logprob:  0.627846, 0.320312 (0.676 sec)
423.23... logprob:  0.622897, 0.312500 (0.677 sec)
423.24... logprob:  0.576899, 0.242188 (0.676 sec)
423.25... logprob:  0.627983, 0.320312 (0.679 sec)
423.26... logprob:  0.674441, 0.390625 (0.675 sec)
423.27... logprob:  0.627882, 0.320312 (0.678 sec)
424.1... logprob:  0.679870, 0.398438 (0.678 sec)
424.2... logprob:  0.596683, 0.273438 (0.678 sec)
424.3... logprob:  0.653874, 0.359375 (0.677 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643485, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934492e-03 [6.765909e-09] 
Layer 'conv1' biases: 6.673464e-07 [6.642052e-11] 
Layer 'conv2' weights[0]: 7.922588e-03 [5.022739e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.531430e-10] 
Layer 'conv3' weights[0]: 7.920094e-03 [4.442168e-09] 
Layer 'conv3' biases: 5.525111e-06 [6.209891e-10] 
Layer 'conv4' weights[0]: 7.952993e-03 [4.331385e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.287408e-09] 
Layer 'conv5' weights[0]: 7.952327e-03 [8.728354e-09] 
Layer 'conv5' biases: 1.000002e+00 [8.260223e-09] 
Layer 'fc6' weights[0]: 7.548373e-03 [3.896657e-09] 
Layer 'fc6' biases: 9.999999e-01 [8.426426e-10] 
Layer 'fc7' weights[0]: 7.414637e-03 [3.975690e-08] 
Layer 'fc7' biases: 9.998515e-01 [1.014068e-08] 
Layer 'fc8' weights[0]: 5.654540e-04 [5.099417e-07] 
Layer 'fc8' biases: 1.788114e-01 [1.872737e-05] 
Train error last 27 batches: 0.635608
-------------------------------------------------------
Not saving because 0.643485 > 0.627087 (334.9: -0.00%)
======================================================= (5.381 sec)
424.4... logprob:  0.596433, 0.273438 (0.697 sec)
424.5... logprob:  0.590782, 0.265625 (0.698 sec)
424.6... logprob:  0.611397, 0.296875 (0.700 sec)
424.7... logprob:  0.643800, 0.343750 (0.690 sec)
424.8... logprob:  0.604991, 0.289062 (0.701 sec)
424.9... logprob:  0.638481, 0.335938 (0.702 sec)
424.10... logprob:  0.598279, 0.281250 (0.701 sec)
424.11... logprob:  0.638717, 0.335938 (0.698 sec)
424.12... logprob:  0.716423, 0.437500 (0.696 sec)
424.13... logprob:  0.656871, 0.359375 (0.698 sec)
424.14... logprob:  0.662480, 0.367188 (0.698 sec)
424.15... logprob:  0.685458, 0.398438 (0.688 sec)
424.16... logprob:  0.627084, 0.320312 (0.692 sec)
424.17... logprob:  0.638498, 0.335938 (0.698 sec)
424.18... logprob:  0.638218, 0.335938 (0.697 sec)
424.19... logprob:  0.632692, 0.328125 (0.698 sec)
424.20... logprob:  0.648943, 0.351562 (0.694 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643528, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934426e-03 [6.818577e-09] 
Layer 'conv1' biases: 6.685019e-07 [1.634662e-10] 
Layer 'conv2' weights[0]: 7.922518e-03 [6.499533e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.674054e-10] 
Layer 'conv3' weights[0]: 7.920031e-03 [5.673797e-09] 
Layer 'conv3' biases: 5.534261e-06 [2.083346e-09] 
Layer 'conv4' weights[0]: 7.952935e-03 [5.595544e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.402518e-08] 
Layer 'conv5' weights[0]: 7.952266e-03 [7.805692e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.199863e-08] 
Layer 'fc6' weights[0]: 7.548312e-03 [9.393118e-09] 
Layer 'fc6' biases: 9.999999e-01 [8.412316e-09] 
Layer 'fc7' weights[0]: 7.413993e-03 [1.150749e-07] 
Layer 'fc7' biases: 9.998515e-01 [9.832342e-08] 
Layer 'fc8' weights[0]: 5.683945e-04 [5.005106e-06] 
Layer 'fc8' biases: 1.791060e-01 [1.095687e-04] 
Train error last 27 batches: 0.635607
-------------------------------------------------------
Not saving because 0.643528 > 0.627087 (334.9: -0.00%)
======================================================= (5.262 sec)
424.21... logprob:  0.643458, 0.343750 (0.697 sec)
424.22... logprob:  0.627843, 0.320312 (0.694 sec)
424.23... logprob:  0.622894, 0.312500 (0.691 sec)
424.24... logprob:  0.576886, 0.242188 (0.686 sec)
424.25... logprob:  0.627981, 0.320312 (0.696 sec)
424.26... logprob:  0.674446, 0.390625 (0.699 sec)
424.27... logprob:  0.627880, 0.320312 (0.695 sec)
425.1... logprob:  0.679877, 0.398438 (0.695 sec)
425.2... logprob:  0.596677, 0.273438 (0.696 sec)
425.3... logprob:  0.653876, 0.359375 (0.699 sec)
425.4... logprob:  0.596427, 0.273438 (0.696 sec)
425.5... logprob:  0.590777, 0.265625 (0.698 sec)
425.6... logprob:  0.611396, 0.296875 (0.699 sec)
425.7... logprob:  0.643801, 0.343750 (0.696 sec)
425.8... logprob:  0.604993, 0.289062 (0.700 sec)
425.9... logprob:  0.638481, 0.335938 (0.691 sec)
425.10... logprob:  0.598283, 0.281250 (0.702 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644653, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934347e-03 [7.128606e-09] 
Layer 'conv1' biases: 6.693227e-07 [1.469197e-10] 
Layer 'conv2' weights[0]: 7.922453e-03 [6.316209e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.499603e-10] 
Layer 'conv3' weights[0]: 7.919967e-03 [6.108704e-09] 
Layer 'conv3' biases: 5.538880e-06 [2.237501e-09] 
Layer 'conv4' weights[0]: 7.952869e-03 [6.251412e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.917392e-08] 
Layer 'conv5' weights[0]: 7.952213e-03 [1.065609e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.124402e-07] 
Layer 'fc6' weights[0]: 7.548245e-03 [1.195628e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.136137e-08] 
Layer 'fc7' weights[0]: 7.413333e-03 [1.442261e-07] 
Layer 'fc7' biases: 9.998520e-01 [1.301504e-07] 
Layer 'fc8' weights[0]: 5.995439e-04 [6.765415e-06] 
Layer 'fc8' biases: 1.801378e-01 [1.694505e-04] 
Train error last 27 batches: 0.635606
-------------------------------------------------------
Not saving because 0.644653 > 0.627087 (334.9: -0.00%)
======================================================= (5.269 sec)
425.11... logprob:  0.638714, 0.335938 (0.671 sec)
425.12... logprob:  0.716403, 0.437500 (0.673 sec)
425.13... logprob:  0.656865, 0.359375 (0.673 sec)
425.14... logprob:  0.662473, 0.367188 (0.674 sec)
425.15... logprob:  0.685449, 0.398438 (0.672 sec)
425.16... logprob:  0.627085, 0.320312 (0.671 sec)
425.17... logprob:  0.638499, 0.335938 (0.671 sec)
425.18... logprob:  0.638218, 0.335938 (0.672 sec)
425.19... logprob:  0.632692, 0.328125 (0.672 sec)
425.20... logprob:  0.648945, 0.351562 (0.671 sec)
425.21... logprob:  0.643458, 0.343750 (0.670 sec)
425.22... logprob:  0.627842, 0.320312 (0.672 sec)
425.23... logprob:  0.622891, 0.312500 (0.672 sec)
425.24... logprob:  0.576875, 0.242188 (0.678 sec)
425.25... logprob:  0.627978, 0.320312 (0.672 sec)
425.26... logprob:  0.674451, 0.390625 (0.671 sec)
425.27... logprob:  0.627878, 0.320312 (0.672 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643482, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934287e-03 [6.691972e-09] 
Layer 'conv1' biases: 6.708703e-07 [7.129394e-11] 
Layer 'conv2' weights[0]: 7.922386e-03 [4.935020e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.574994e-10] 
Layer 'conv3' weights[0]: 7.919903e-03 [4.433297e-09] 
Layer 'conv3' biases: 5.553290e-06 [6.696469e-10] 
Layer 'conv4' weights[0]: 7.952802e-03 [4.355013e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.097811e-09] 
Layer 'conv5' weights[0]: 7.952133e-03 [1.793197e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.852715e-08] 
Layer 'fc6' weights[0]: 7.548167e-03 [4.296776e-09] 
Layer 'fc6' biases: 9.999999e-01 [1.850098e-09] 
Layer 'fc7' weights[0]: 7.412720e-03 [4.738783e-08] 
Layer 'fc7' biases: 9.998514e-01 [2.206835e-08] 
Layer 'fc8' weights[0]: 5.644394e-04 [1.087709e-06] 
Layer 'fc8' biases: 1.793962e-01 [3.713309e-05] 
Train error last 27 batches: 0.635604
-------------------------------------------------------
Not saving because 0.643482 > 0.627087 (334.9: -0.00%)
======================================================= (5.201 sec)
426.1... logprob:  0.679881, 0.398438 (0.673 sec)
426.2... logprob:  0.596671, 0.273438 (0.672 sec)
426.3... logprob:  0.653877, 0.359375 (0.670 sec)
426.4... logprob:  0.596423, 0.273438 (0.672 sec)
426.5... logprob:  0.590774, 0.265625 (0.673 sec)
426.6... logprob:  0.611395, 0.296875 (0.669 sec)
426.7... logprob:  0.643800, 0.343750 (0.670 sec)
426.8... logprob:  0.604995, 0.289062 (0.673 sec)
426.9... logprob:  0.638480, 0.335938 (0.674 sec)
426.10... logprob:  0.598288, 0.281250 (0.673 sec)
426.11... logprob:  0.638712, 0.335938 (0.674 sec)
426.12... logprob:  0.716385, 0.437500 (0.672 sec)
426.13... logprob:  0.656860, 0.359375 (0.672 sec)
426.14... logprob:  0.662466, 0.367188 (0.673 sec)
426.15... logprob:  0.685440, 0.398438 (0.672 sec)
426.16... logprob:  0.627084, 0.320312 (0.668 sec)
426.17... logprob:  0.638498, 0.335938 (0.672 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643843, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934228e-03 [6.457245e-09] 
Layer 'conv1' biases: 6.718527e-07 [1.665750e-10] 
Layer 'conv2' weights[0]: 7.922324e-03 [6.758158e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.500229e-10] 
Layer 'conv3' weights[0]: 7.919849e-03 [5.931850e-09] 
Layer 'conv3' biases: 5.560366e-06 [2.296905e-09] 
Layer 'conv4' weights[0]: 7.952741e-03 [5.971377e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.664043e-08] 
Layer 'conv5' weights[0]: 7.952090e-03 [9.258673e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.742677e-08] 
Layer 'fc6' weights[0]: 7.548100e-03 [1.062368e-08] 
Layer 'fc6' biases: 9.999999e-01 [9.911807e-09] 
Layer 'fc7' weights[0]: 7.412037e-03 [1.293518e-07] 
Layer 'fc7' biases: 9.998516e-01 [1.141546e-07] 
Layer 'fc8' weights[0]: 5.812441e-04 [5.905347e-06] 
Layer 'fc8' biases: 1.800593e-01 [1.268892e-04] 
Train error last 27 batches: 0.635602
-------------------------------------------------------
Not saving because 0.643843 > 0.627087 (334.9: -0.00%)
======================================================= (5.114 sec)
426.18... logprob:  0.638217, 0.335938 (0.673 sec)
426.19... logprob:  0.632691, 0.328125 (0.670 sec)
426.20... logprob:  0.648945, 0.351562 (0.671 sec)
426.21... logprob:  0.643458, 0.343750 (0.671 sec)
426.22... logprob:  0.627840, 0.320312 (0.671 sec)
426.23... logprob:  0.622888, 0.312500 (0.670 sec)
426.24... logprob:  0.576866, 0.242188 (0.671 sec)
426.25... logprob:  0.627977, 0.320312 (0.672 sec)
426.26... logprob:  0.674454, 0.390625 (0.672 sec)
426.27... logprob:  0.627876, 0.320312 (0.673 sec)
427.1... logprob:  0.679884, 0.398438 (0.673 sec)
427.2... logprob:  0.596667, 0.273438 (0.673 sec)
427.3... logprob:  0.653878, 0.359375 (0.671 sec)
427.4... logprob:  0.596420, 0.273438 (0.673 sec)
427.5... logprob:  0.590772, 0.265625 (0.668 sec)
427.6... logprob:  0.611394, 0.296875 (0.671 sec)
427.7... logprob:  0.643800, 0.343750 (0.672 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643887, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934161e-03 [6.911483e-09] 
Layer 'conv1' biases: 6.729792e-07 [1.258765e-10] 
Layer 'conv2' weights[0]: 7.922255e-03 [5.789653e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.013630e-10] 
Layer 'conv3' weights[0]: 7.919775e-03 [5.576599e-09] 
Layer 'conv3' biases: 5.569441e-06 [1.829798e-09] 
Layer 'conv4' weights[0]: 7.952680e-03 [5.626955e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.532952e-08] 
Layer 'conv5' weights[0]: 7.952023e-03 [8.492911e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.944606e-08] 
Layer 'fc6' weights[0]: 7.548023e-03 [9.988204e-09] 
Layer 'fc6' biases: 9.999999e-01 [9.087402e-09] 
Layer 'fc7' weights[0]: 7.411381e-03 [1.218881e-07] 
Layer 'fc7' biases: 9.998516e-01 [1.051865e-07] 
Layer 'fc8' weights[0]: 5.824853e-04 [5.374579e-06] 
Layer 'fc8' biases: 1.802798e-01 [1.406672e-04] 
Train error last 27 batches: 0.635601
-------------------------------------------------------
Not saving because 0.643887 > 0.627087 (334.9: -0.00%)
======================================================= (5.127 sec)
427.8... logprob:  0.604995, 0.289062 (0.674 sec)
427.9... logprob:  0.638479, 0.335938 (0.670 sec)
427.10... logprob:  0.598290, 0.281250 (0.673 sec)
427.11... logprob:  0.638711, 0.335938 (0.673 sec)
427.12... logprob:  0.716375, 0.437500 (0.674 sec)
427.13... logprob:  0.656856, 0.359375 (0.673 sec)
427.14... logprob:  0.662464, 0.367188 (0.673 sec)
427.15... logprob:  0.685437, 0.398438 (0.672 sec)
427.16... logprob:  0.627085, 0.320312 (0.672 sec)
427.17... logprob:  0.638497, 0.335938 (0.672 sec)
427.18... logprob:  0.638218, 0.335938 (0.672 sec)
427.19... logprob:  0.632692, 0.328125 (0.669 sec)
427.20... logprob:  0.648947, 0.351562 (0.671 sec)
427.21... logprob:  0.643460, 0.343750 (0.671 sec)
427.22... logprob:  0.627838, 0.320312 (0.672 sec)
427.23... logprob:  0.622885, 0.312500 (0.672 sec)
427.24... logprob:  0.576853, 0.242188 (0.671 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643452, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934102e-03 [6.525333e-09] 
Layer 'conv1' biases: 6.744043e-07 [6.079878e-11] 
Layer 'conv2' weights[0]: 7.922190e-03 [4.885102e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.996309e-10] 
Layer 'conv3' weights[0]: 7.919711e-03 [4.514842e-09] 
Layer 'conv3' biases: 5.581956e-06 [8.300313e-10] 
Layer 'conv4' weights[0]: 7.952616e-03 [4.459428e-09] 
Layer 'conv4' biases: 1.000001e+00 [5.831197e-09] 
Layer 'conv5' weights[0]: 7.951944e-03 [3.239404e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.389155e-08] 
Layer 'fc6' weights[0]: 7.547962e-03 [5.197775e-09] 
Layer 'fc6' biases: 9.999999e-01 [3.395232e-09] 
Layer 'fc7' weights[0]: 7.410741e-03 [6.203205e-08] 
Layer 'fc7' biases: 9.998512e-01 [4.013181e-08] 
Layer 'fc8' weights[0]: 5.605554e-04 [1.985281e-06] 
Layer 'fc8' biases: 1.798811e-01 [6.408680e-05] 
Train error last 27 batches: 0.635600
-------------------------------------------------------
Not saving because 0.643452 > 0.627087 (334.9: -0.00%)
======================================================= (5.179 sec)
427.25... logprob:  0.627974, 0.320312 (0.671 sec)
427.26... logprob:  0.674460, 0.390625 (0.672 sec)
427.27... logprob:  0.627875, 0.320312 (0.673 sec)
428.1... logprob:  0.679889, 0.398438 (0.673 sec)
428.2... logprob:  0.596662, 0.273438 (0.672 sec)
428.3... logprob:  0.653879, 0.359375 (0.673 sec)
428.4... logprob:  0.596417, 0.273438 (0.673 sec)
428.5... logprob:  0.590770, 0.265625 (0.668 sec)
428.6... logprob:  0.611395, 0.296875 (0.673 sec)
428.7... logprob:  0.643799, 0.343750 (0.672 sec)
428.8... logprob:  0.604998, 0.289062 (0.673 sec)
428.9... logprob:  0.638478, 0.335938 (0.673 sec)
428.10... logprob:  0.598295, 0.281250 (0.673 sec)
428.11... logprob:  0.638709, 0.335938 (0.673 sec)
428.12... logprob:  0.716355, 0.437500 (0.673 sec)
428.13... logprob:  0.656850, 0.359375 (0.673 sec)
428.14... logprob:  0.662457, 0.367188 (0.674 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644583, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934030e-03 [6.754874e-09] 
Layer 'conv1' biases: 6.751820e-07 [1.456557e-10] 
Layer 'conv2' weights[0]: 7.922113e-03 [6.137105e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.533309e-10] 
Layer 'conv3' weights[0]: 7.919657e-03 [5.350130e-09] 
Layer 'conv3' biases: 5.585972e-06 [1.799088e-09] 
Layer 'conv4' weights[0]: 7.952553e-03 [5.312818e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.151782e-08] 
Layer 'conv5' weights[0]: 7.951885e-03 [6.400254e-08] 
Layer 'conv5' biases: 1.000002e+00 [6.744346e-08] 
Layer 'fc6' weights[0]: 7.547889e-03 [7.933300e-09] 
Layer 'fc6' biases: 9.999999e-01 [6.850808e-09] 
Layer 'fc7' weights[0]: 7.410044e-03 [9.664586e-08] 
Layer 'fc7' biases: 9.998518e-01 [7.887450e-08] 
Layer 'fc8' weights[0]: 5.974734e-04 [4.080858e-06] 
Layer 'fc8' biases: 1.810873e-01 [8.174778e-05] 
Train error last 27 batches: 0.635599
-------------------------------------------------------
Not saving because 0.644583 > 0.627087 (334.9: -0.00%)
======================================================= (5.131 sec)
428.15... logprob:  0.685429, 0.398438 (0.672 sec)
428.16... logprob:  0.627085, 0.320312 (0.670 sec)
428.17... logprob:  0.638497, 0.335938 (0.671 sec)
428.18... logprob:  0.638218, 0.335938 (0.671 sec)
428.19... logprob:  0.632691, 0.328125 (0.672 sec)
428.20... logprob:  0.648948, 0.351562 (0.672 sec)
428.21... logprob:  0.643459, 0.343750 (0.671 sec)
428.22... logprob:  0.627836, 0.320312 (0.672 sec)
428.23... logprob:  0.622881, 0.312500 (0.672 sec)
428.24... logprob:  0.576840, 0.242188 (0.671 sec)
428.25... logprob:  0.627971, 0.320312 (0.672 sec)
428.26... logprob:  0.674466, 0.390625 (0.671 sec)
428.27... logprob:  0.627873, 0.320312 (0.671 sec)
429.1... logprob:  0.679895, 0.398438 (0.673 sec)
429.2... logprob:  0.596656, 0.273438 (0.673 sec)
429.3... logprob:  0.653882, 0.359375 (0.673 sec)
429.4... logprob:  0.596412, 0.273438 (0.674 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643520, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.933966e-03 [6.917699e-09] 
Layer 'conv1' biases: 6.766620e-07 [8.733950e-11] 
Layer 'conv2' weights[0]: 7.922052e-03 [5.282188e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.422842e-10] 
Layer 'conv3' weights[0]: 7.919601e-03 [4.898608e-09] 
Layer 'conv3' biases: 5.599611e-06 [1.160054e-09] 
Layer 'conv4' weights[0]: 7.952485e-03 [4.833572e-09] 
Layer 'conv4' biases: 1.000001e+00 [8.341824e-09] 
Layer 'conv5' weights[0]: 7.951817e-03 [4.673378e-08] 
Layer 'conv5' biases: 1.000002e+00 [4.907030e-08] 
Layer 'fc6' weights[0]: 7.547820e-03 [6.384493e-09] 
Layer 'fc6' biases: 9.999999e-01 [5.023206e-09] 
Layer 'fc7' weights[0]: 7.409439e-03 [7.748652e-08] 
Layer 'fc7' biases: 9.998512e-01 [5.803782e-08] 
Layer 'fc8' weights[0]: 5.667878e-04 [2.949844e-06] 
Layer 'fc8' biases: 1.804411e-01 [8.172414e-05] 
Train error last 27 batches: 0.635598
-------------------------------------------------------
Not saving because 0.643520 > 0.627087 (334.9: -0.00%)
======================================================= (5.152 sec)
429.5... logprob:  0.590766, 0.265625 (0.672 sec)
429.6... logprob:  0.611394, 0.296875 (0.672 sec)
429.7... logprob:  0.643799, 0.343750 (0.673 sec)
429.8... logprob:  0.605000, 0.289062 (0.673 sec)
429.9... logprob:  0.638477, 0.335938 (0.674 sec)
429.10... logprob:  0.598300, 0.281250 (0.674 sec)
429.11... logprob:  0.638707, 0.335938 (0.674 sec)
429.12... logprob:  0.716335, 0.437500 (0.674 sec)
429.13... logprob:  0.656843, 0.359375 (0.670 sec)
429.14... logprob:  0.662450, 0.367188 (0.673 sec)
429.15... logprob:  0.685420, 0.398438 (0.668 sec)
429.16... logprob:  0.627085, 0.320312 (0.672 sec)
429.17... logprob:  0.638497, 0.335938 (0.673 sec)
429.18... logprob:  0.638218, 0.335938 (0.669 sec)
429.19... logprob:  0.632691, 0.328125 (0.671 sec)
429.20... logprob:  0.648949, 0.351562 (0.672 sec)
429.21... logprob:  0.643460, 0.343750 (0.672 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643478, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.933890e-03 [6.849953e-09] 
Layer 'conv1' biases: 6.778817e-07 [1.559722e-10] 
Layer 'conv2' weights[0]: 7.921979e-03 [6.511998e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.412935e-10] 
Layer 'conv3' weights[0]: 7.919536e-03 [5.651481e-09] 
Layer 'conv3' biases: 5.609549e-06 [2.015907e-09] 
Layer 'conv4' weights[0]: 7.952422e-03 [5.569870e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.334163e-08] 
Layer 'conv5' weights[0]: 7.951754e-03 [7.413368e-08] 
Layer 'conv5' biases: 1.000002e+00 [7.785359e-08] 
Layer 'fc6' weights[0]: 7.547762e-03 [8.980403e-09] 
Layer 'fc6' biases: 9.999999e-01 [7.975854e-09] 
Layer 'fc7' weights[0]: 7.408795e-03 [1.100480e-07] 
Layer 'fc7' biases: 9.998512e-01 [9.309957e-08] 
Layer 'fc8' weights[0]: 5.631740e-04 [4.710626e-06] 
Layer 'fc8' biases: 1.805496e-01 [1.049267e-04] 
Train error last 27 batches: 0.635596
-------------------------------------------------------
Not saving because 0.643478 > 0.627087 (334.9: -0.00%)
======================================================= (5.129 sec)
429.22... logprob:  0.627834, 0.320312 (0.672 sec)
429.23... logprob:  0.622877, 0.312500 (0.672 sec)
429.24... logprob:  0.576828, 0.242188 (0.672 sec)
429.25... logprob:  0.627969, 0.320312 (0.672 sec)
429.26... logprob:  0.674470, 0.390625 (0.672 sec)
429.27... logprob:  0.627871, 0.320312 (0.673 sec)
430.1... logprob:  0.679900, 0.398438 (0.674 sec)
430.2... logprob:  0.596651, 0.273438 (0.670 sec)
430.3... logprob:  0.653883, 0.359375 (0.673 sec)
430.4... logprob:  0.596408, 0.273438 (0.671 sec)
430.5... logprob:  0.590764, 0.265625 (0.673 sec)
430.6... logprob:  0.611394, 0.296875 (0.673 sec)
430.7... logprob:  0.643799, 0.343750 (0.673 sec)
430.8... logprob:  0.605001, 0.289062 (0.674 sec)
430.9... logprob:  0.638477, 0.335938 (0.673 sec)
430.10... logprob:  0.598304, 0.281250 (0.674 sec)
430.11... logprob:  0.638705, 0.335938 (0.673 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644932, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.933836e-03 [6.901059e-09] 
Layer 'conv1' biases: 6.786139e-07 [1.234532e-10] 
Layer 'conv2' weights[0]: 7.921916e-03 [5.809947e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.870645e-10] 
Layer 'conv3' weights[0]: 7.919477e-03 [5.601696e-09] 
Layer 'conv3' biases: 5.612776e-06 [1.820428e-09] 
Layer 'conv4' weights[0]: 7.952356e-03 [5.686291e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.535250e-08] 
Layer 'conv5' weights[0]: 7.951675e-03 [8.566087e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.050103e-08] 
Layer 'fc6' weights[0]: 7.547690e-03 [9.983142e-09] 
Layer 'fc6' biases: 9.999999e-01 [9.082143e-09] 
Layer 'fc7' weights[0]: 7.408158e-03 [1.204054e-07] 
Layer 'fc7' biases: 9.998518e-01 [1.031679e-07] 
Layer 'fc8' weights[0]: 6.027542e-04 [5.384434e-06] 
Layer 'fc8' biases: 1.818177e-01 [1.371584e-04] 
Train error last 27 batches: 0.635596
-------------------------------------------------------
Not saving because 0.644932 > 0.627087 (334.9: -0.00%)
======================================================= (5.110 sec)
430.12... logprob:  0.716318, 0.437500 (0.674 sec)
430.13... logprob:  0.656837, 0.359375 (0.673 sec)
430.14... logprob:  0.662444, 0.367188 (0.673 sec)
430.15... logprob:  0.685412, 0.398438 (0.672 sec)
430.16... logprob:  0.627086, 0.320312 (0.671 sec)
430.17... logprob:  0.638497, 0.335938 (0.671 sec)
430.18... logprob:  0.638218, 0.335938 (0.672 sec)
430.19... logprob:  0.632690, 0.328125 (0.672 sec)
430.20... logprob:  0.648948, 0.351562 (0.672 sec)
430.21... logprob:  0.643460, 0.343750 (0.672 sec)
430.22... logprob:  0.627833, 0.320312 (0.672 sec)
430.23... logprob:  0.622875, 0.312500 (0.672 sec)
430.24... logprob:  0.576821, 0.242188 (0.671 sec)
430.25... logprob:  0.627967, 0.320312 (0.672 sec)
430.26... logprob:  0.674473, 0.390625 (0.669 sec)
430.27... logprob:  0.627869, 0.320312 (0.673 sec)
431.1... logprob:  0.679904, 0.398438 (0.673 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643472, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.933776e-03 [6.696965e-09] 
Layer 'conv1' biases: 6.802215e-07 [8.634053e-11] 
Layer 'conv2' weights[0]: 7.921859e-03 [5.234735e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.538376e-10] 
Layer 'conv3' weights[0]: 7.919405e-03 [4.539642e-09] 
Layer 'conv3' biases: 5.628005e-06 [9.043702e-10] 
Layer 'conv4' weights[0]: 7.952287e-03 [4.457057e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.928447e-09] 
Layer 'conv5' weights[0]: 7.951609e-03 [2.160785e-08] 
Layer 'conv5' biases: 1.000002e+00 [2.228528e-08] 
Layer 'fc6' weights[0]: 7.547625e-03 [4.553307e-09] 
Layer 'fc6' biases: 9.999999e-01 [2.347844e-09] 
Layer 'fc7' weights[0]: 7.407522e-03 [5.193182e-08] 
Layer 'fc7' biases: 9.998511e-01 [2.839709e-08] 
Layer 'fc8' weights[0]: 5.621245e-04 [1.378372e-06] 
Layer 'fc8' biases: 1.809148e-01 [2.632207e-05] 
Train error last 27 batches: 0.635594
-------------------------------------------------------
Not saving because 0.643472 > 0.627087 (334.9: -0.00%)
======================================================= (5.206 sec)
431.2... logprob:  0.596645, 0.273438 (0.672 sec)
431.3... logprob:  0.653884, 0.359375 (0.673 sec)
431.4... logprob:  0.596403, 0.273438 (0.673 sec)
431.5... logprob:  0.590760, 0.265625 (0.673 sec)
431.6... logprob:  0.611392, 0.296875 (0.671 sec)
431.7... logprob:  0.643799, 0.343750 (0.673 sec)
431.8... logprob:  0.605002, 0.289062 (0.674 sec)
431.9... logprob:  0.638476, 0.335938 (0.672 sec)
431.10... logprob:  0.598306, 0.281250 (0.673 sec)
431.11... logprob:  0.638703, 0.335938 (0.672 sec)
431.12... logprob:  0.716308, 0.437500 (0.672 sec)
431.13... logprob:  0.656834, 0.359375 (0.673 sec)
431.14... logprob:  0.662441, 0.367188 (0.673 sec)
431.15... logprob:  0.685408, 0.398438 (0.672 sec)
431.16... logprob:  0.627086, 0.320312 (0.672 sec)
431.17... logprob:  0.638497, 0.335938 (0.672 sec)
431.18... logprob:  0.638218, 0.335938 (0.668 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643704, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.933716e-03 [6.506118e-09] 
Layer 'conv1' biases: 6.812515e-07 [1.696172e-10] 
Layer 'conv2' weights[0]: 7.921793e-03 [6.625908e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.187070e-10] 
Layer 'conv3' weights[0]: 7.919346e-03 [5.817195e-09] 
Layer 'conv3' biases: 5.635502e-06 [2.210574e-09] 
Layer 'conv4' weights[0]: 7.952225e-03 [5.810925e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.555302e-08] 
Layer 'conv5' weights[0]: 7.951552e-03 [8.643100e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.096665e-08] 
Layer 'fc6' weights[0]: 7.547548e-03 [1.010360e-08] 
Layer 'fc6' biases: 9.999999e-01 [9.270790e-09] 
Layer 'fc7' weights[0]: 7.406863e-03 [1.231234e-07] 
Layer 'fc7' biases: 9.998513e-01 [1.069326e-07] 
Layer 'fc8' weights[0]: 5.751000e-04 [5.486443e-06] 
Layer 'fc8' biases: 1.814824e-01 [1.195550e-04] 
Train error last 27 batches: 0.635593
-------------------------------------------------------
Not saving because 0.643704 > 0.627087 (334.9: -0.00%)
======================================================= (5.112 sec)
431.19... logprob:  0.632691, 0.328125 (0.672 sec)
431.20... logprob:  0.648950, 0.351562 (0.671 sec)
431.21... logprob:  0.643462, 0.343750 (0.672 sec)
431.22... logprob:  0.627830, 0.320312 (0.672 sec)
431.23... logprob:  0.622872, 0.312500 (0.672 sec)
431.24... logprob:  0.576805, 0.242188 (0.671 sec)
431.25... logprob:  0.627965, 0.320312 (0.672 sec)
431.26... logprob:  0.674480, 0.390625 (0.672 sec)
431.27... logprob:  0.627868, 0.320312 (0.671 sec)
432.1... logprob:  0.679909, 0.398438 (0.675 sec)
432.2... logprob:  0.596641, 0.273438 (0.674 sec)
432.3... logprob:  0.653885, 0.359375 (0.676 sec)
432.4... logprob:  0.596401, 0.273438 (0.675 sec)
432.5... logprob:  0.590759, 0.265625 (0.674 sec)
432.6... logprob:  0.611393, 0.296875 (0.672 sec)
432.7... logprob:  0.643799, 0.343750 (0.675 sec)
432.8... logprob:  0.605006, 0.289062 (0.674 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644099, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.933649e-03 [7.250728e-09] 
Layer 'conv1' biases: 6.822792e-07 [1.447861e-10] 
Layer 'conv2' weights[0]: 7.921729e-03 [6.284076e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.441778e-10] 
Layer 'conv3' weights[0]: 7.919282e-03 [6.042168e-09] 
Layer 'conv3' biases: 5.643048e-06 [2.186539e-09] 
Layer 'conv4' weights[0]: 7.952154e-03 [6.138669e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.856075e-08] 
Layer 'conv5' weights[0]: 7.951472e-03 [1.025777e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.081542e-07] 
Layer 'fc6' weights[0]: 7.547487e-03 [1.157751e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.094638e-08] 
Layer 'fc7' weights[0]: 7.406209e-03 [1.400692e-07] 
Layer 'fc7' biases: 9.998513e-01 [1.257134e-07] 
Layer 'fc8' weights[0]: 5.866323e-04 [6.454215e-06] 
Layer 'fc8' biases: 1.819837e-01 [1.667105e-04] 
Train error last 27 batches: 0.635592
-------------------------------------------------------
Not saving because 0.644099 > 0.627087 (334.9: -0.00%)
======================================================= (5.119 sec)
432.9... logprob:  0.638475, 0.335938 (0.680 sec)
432.10... logprob:  0.598313, 0.281250 (0.680 sec)
432.11... logprob:  0.638700, 0.335938 (0.681 sec)
432.12... logprob:  0.716281, 0.437500 (0.680 sec)
432.13... logprob:  0.656825, 0.359375 (0.676 sec)
432.14... logprob:  0.662433, 0.367188 (0.673 sec)
432.15... logprob:  0.685396, 0.398438 (0.673 sec)
432.16... logprob:  0.627087, 0.320312 (0.673 sec)
432.17... logprob:  0.638497, 0.335938 (0.674 sec)
432.18... logprob:  0.638218, 0.335938 (0.673 sec)
432.19... logprob:  0.632690, 0.328125 (0.674 sec)
432.20... logprob:  0.648952, 0.351562 (0.675 sec)
432.21... logprob:  0.643462, 0.343750 (0.672 sec)
432.22... logprob:  0.627829, 0.320312 (0.673 sec)
432.23... logprob:  0.622868, 0.312500 (0.675 sec)
432.24... logprob:  0.576793, 0.242188 (0.675 sec)
432.25... logprob:  0.627962, 0.320312 (0.674 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643472, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.933581e-03 [6.619109e-09] 
Layer 'conv1' biases: 6.837379e-07 [6.796565e-11] 
Layer 'conv2' weights[0]: 7.921662e-03 [4.956056e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.514946e-10] 
Layer 'conv3' weights[0]: 7.919208e-03 [4.629586e-09] 
Layer 'conv3' biases: 5.655934e-06 [9.948996e-10] 
Layer 'conv4' weights[0]: 7.952090e-03 [4.608568e-09] 
Layer 'conv4' biases: 1.000001e+00 [7.459420e-09] 
Layer 'conv5' weights[0]: 7.951419e-03 [4.134299e-08] 
Layer 'conv5' biases: 1.000002e+00 [4.335000e-08] 
Layer 'fc6' weights[0]: 7.547425e-03 [5.887051e-09] 
Layer 'fc6' biases: 9.999999e-01 [4.391665e-09] 
Layer 'fc7' weights[0]: 7.405588e-03 [7.151513e-08] 
Layer 'fc7' biases: 9.998510e-01 [5.148887e-08] 
Layer 'fc8' weights[0]: 5.615312e-04 [2.557096e-06] 
Layer 'fc8' biases: 1.814994e-01 [7.797303e-05] 
Train error last 27 batches: 0.635590
-------------------------------------------------------
Not saving because 0.643472 > 0.627087 (334.9: -0.00%)
======================================================= (5.170 sec)
432.26... logprob:  0.674484, 0.390625 (0.671 sec)
432.27... logprob:  0.627865, 0.320312 (0.676 sec)
433.1... logprob:  0.679914, 0.398438 (0.673 sec)
433.2... logprob:  0.596634, 0.273438 (0.673 sec)
433.3... logprob:  0.653887, 0.359375 (0.674 sec)
433.4... logprob:  0.596396, 0.273438 (0.673 sec)
433.5... logprob:  0.590754, 0.265625 (0.673 sec)
433.6... logprob:  0.611392, 0.296875 (0.673 sec)
433.7... logprob:  0.643799, 0.343750 (0.673 sec)
433.8... logprob:  0.605006, 0.289062 (0.676 sec)
433.9... logprob:  0.638474, 0.335938 (0.674 sec)
433.10... logprob:  0.598317, 0.281250 (0.673 sec)
433.11... logprob:  0.638699, 0.335938 (0.673 sec)
433.12... logprob:  0.716265, 0.437500 (0.674 sec)
433.13... logprob:  0.656820, 0.359375 (0.671 sec)
433.14... logprob:  0.662426, 0.367188 (0.673 sec)
433.15... logprob:  0.685389, 0.398438 (0.672 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644256, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.933501e-03 [7.295573e-09] 
Layer 'conv1' biases: 6.845989e-07 [2.001976e-10] 
Layer 'conv2' weights[0]: 7.921583e-03 [7.485340e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.943292e-10] 
Layer 'conv3' weights[0]: 7.919147e-03 [6.449871e-09] 
Layer 'conv3' biases: 5.661278e-06 [2.736386e-09] 
Layer 'conv4' weights[0]: 7.952026e-03 [6.505898e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.979203e-08] 
Layer 'conv5' weights[0]: 7.951347e-03 [1.096021e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.156894e-07] 
Layer 'fc6' weights[0]: 7.547367e-03 [1.222834e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.169894e-08] 
Layer 'fc7' weights[0]: 7.404942e-03 [1.477097e-07] 
Layer 'fc7' biases: 9.998513e-01 [1.342320e-07] 
Layer 'fc8' weights[0]: 5.897820e-04 [6.945706e-06] 
Layer 'fc8' biases: 1.824724e-01 [1.502899e-04] 
Train error last 27 batches: 0.635588
-------------------------------------------------------
Not saving because 0.644256 > 0.627087 (334.9: -0.00%)
======================================================= (5.101 sec)
433.16... logprob:  0.627087, 0.320312 (0.673 sec)
433.17... logprob:  0.638497, 0.335938 (0.673 sec)
433.18... logprob:  0.638218, 0.335938 (0.672 sec)
433.19... logprob:  0.632690, 0.328125 (0.672 sec)
433.20... logprob:  0.648952, 0.351562 (0.673 sec)
433.21... logprob:  0.643462, 0.343750 (0.672 sec)
433.22... logprob:  0.627827, 0.320312 (0.672 sec)
433.23... logprob:  0.622866, 0.312500 (0.672 sec)
433.24... logprob:  0.576782, 0.242188 (0.672 sec)
433.25... logprob:  0.627960, 0.320312 (0.668 sec)
433.26... logprob:  0.674489, 0.390625 (0.672 sec)
433.27... logprob:  0.627864, 0.320312 (0.674 sec)
434.1... logprob:  0.679919, 0.398438 (0.672 sec)
434.2... logprob:  0.596629, 0.273438 (0.672 sec)
434.3... logprob:  0.653887, 0.359375 (0.673 sec)
434.4... logprob:  0.596393, 0.273438 (0.672 sec)
434.5... logprob:  0.590751, 0.265625 (0.675 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643603, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.933443e-03 [7.524071e-09] 
Layer 'conv1' biases: 6.859646e-07 [1.357407e-10] 
Layer 'conv2' weights[0]: 7.921524e-03 [5.934192e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.266799e-10] 
Layer 'conv3' weights[0]: 7.919083e-03 [5.698039e-09] 
Layer 'conv3' biases: 5.673312e-06 [1.898985e-09] 
Layer 'conv4' weights[0]: 7.951959e-03 [5.700797e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.563384e-08] 
Layer 'conv5' weights[0]: 7.951281e-03 [8.636092e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.096256e-08] 
Layer 'fc6' weights[0]: 7.547307e-03 [1.010044e-08] 
Layer 'fc6' biases: 9.999999e-01 [9.230591e-09] 
Layer 'fc7' weights[0]: 7.404323e-03 [1.234218e-07] 
Layer 'fc7' biases: 9.998512e-01 [1.069255e-07] 
Layer 'fc8' weights[0]: 5.701976e-04 [5.435232e-06] 
Layer 'fc8' biases: 1.821207e-01 [1.449070e-04] 
Train error last 27 batches: 0.635587
-------------------------------------------------------
Not saving because 0.643603 > 0.627087 (334.9: -0.00%)
======================================================= (5.113 sec)
434.6... logprob:  0.611392, 0.296875 (0.673 sec)
434.7... logprob:  0.643799, 0.343750 (0.672 sec)
434.8... logprob:  0.605009, 0.289062 (0.674 sec)
434.9... logprob:  0.638473, 0.335938 (0.674 sec)
434.10... logprob:  0.598321, 0.281250 (0.673 sec)
434.11... logprob:  0.638697, 0.335938 (0.673 sec)
434.12... logprob:  0.716245, 0.437500 (0.674 sec)
434.13... logprob:  0.656813, 0.359375 (0.673 sec)
434.14... logprob:  0.662420, 0.367188 (0.672 sec)
434.15... logprob:  0.685380, 0.398438 (0.672 sec)
434.16... logprob:  0.627087, 0.320312 (0.668 sec)
434.17... logprob:  0.638496, 0.335938 (0.673 sec)
434.18... logprob:  0.638218, 0.335938 (0.672 sec)
434.19... logprob:  0.632690, 0.328125 (0.671 sec)
434.20... logprob:  0.648952, 0.351562 (0.675 sec)
434.21... logprob:  0.643463, 0.343750 (0.672 sec)
434.22... logprob:  0.627825, 0.320312 (0.672 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643455, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.933375e-03 [6.702205e-09] 
Layer 'conv1' biases: 6.872999e-07 [1.387041e-10] 
Layer 'conv2' weights[0]: 7.921460e-03 [6.094430e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.028201e-10] 
Layer 'conv3' weights[0]: 7.919022e-03 [5.278148e-09] 
Layer 'conv3' biases: 5.684378e-06 [1.611629e-09] 
Layer 'conv4' weights[0]: 7.951896e-03 [5.163164e-09] 
Layer 'conv4' biases: 1.000001e+00 [9.864614e-09] 
Layer 'conv5' weights[0]: 7.951206e-03 [5.472660e-08] 
Layer 'conv5' biases: 1.000002e+00 [5.734839e-08] 
Layer 'fc6' weights[0]: 7.547247e-03 [7.086458e-09] 
Layer 'fc6' biases: 9.999999e-01 [5.891658e-09] 
Layer 'fc7' weights[0]: 7.403665e-03 [8.700356e-08] 
Layer 'fc7' biases: 9.998510e-01 [6.896153e-08] 
Layer 'fc8' weights[0]: 5.590250e-04 [3.459156e-06] 
Layer 'fc8' biases: 1.820107e-01 [7.534288e-05] 
Train error last 27 batches: 0.635586
-------------------------------------------------------
Not saving because 0.643455 > 0.627087 (334.9: -0.00%)
======================================================= (5.151 sec)
434.23... logprob:  0.622863, 0.312500 (0.671 sec)
434.24... logprob:  0.576772, 0.242188 (0.672 sec)
434.25... logprob:  0.627958, 0.320312 (0.671 sec)
434.26... logprob:  0.674494, 0.390625 (0.668 sec)
434.27... logprob:  0.627862, 0.320312 (0.672 sec)
435.1... logprob:  0.679924, 0.398438 (0.673 sec)
435.2... logprob:  0.596624, 0.273438 (0.673 sec)
435.3... logprob:  0.653889, 0.359375 (0.672 sec)
435.4... logprob:  0.596389, 0.273438 (0.673 sec)
435.5... logprob:  0.590748, 0.265625 (0.672 sec)
435.6... logprob:  0.611391, 0.296875 (0.674 sec)
435.7... logprob:  0.643798, 0.343750 (0.673 sec)
435.8... logprob:  0.605009, 0.289062 (0.674 sec)
435.9... logprob:  0.638473, 0.335938 (0.674 sec)
435.10... logprob:  0.598324, 0.281250 (0.673 sec)
435.11... logprob:  0.638695, 0.335938 (0.674 sec)
435.12... logprob:  0.716234, 0.437500 (0.671 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644892, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.933317e-03 [6.945368e-09] 
Layer 'conv1' biases: 6.879651e-07 [8.011172e-11] 
Layer 'conv2' weights[0]: 7.921399e-03 [5.241551e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.053283e-10] 
Layer 'conv3' weights[0]: 7.918962e-03 [4.529467e-09] 
Layer 'conv3' biases: 5.687290e-06 [7.656842e-10] 
Layer 'conv4' weights[0]: 7.951830e-03 [4.403350e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.223112e-09] 
Layer 'conv5' weights[0]: 7.951124e-03 [7.780621e-09] 
Layer 'conv5' biases: 1.000002e+00 [6.866153e-09] 
Layer 'fc6' weights[0]: 7.547188e-03 [3.877696e-09] 
Layer 'fc6' biases: 9.999999e-01 [7.955049e-10] 
Layer 'fc7' weights[0]: 7.402995e-03 [3.966370e-08] 
Layer 'fc7' biases: 9.998516e-01 [1.077708e-08] 
Layer 'fc8' weights[0]: 6.007978e-04 [4.277094e-07] 
Layer 'fc8' biases: 1.833528e-01 [4.220278e-06] 
Train error last 27 batches: 0.635585
-------------------------------------------------------
Not saving because 0.644892 > 0.627087 (334.9: -0.00%)
======================================================= Giving up...
nohup: ignoring input
Option --layer-def (Layer definition file) cannot be changed
=========================
Importing _ConvNet C++ module
=========================
Training ConvNet
Always write savepoints, regardless of test err improvement: 0     [DEFAULT]
Check gradients and quit?                                  : 0     [DEFAULT]
Compress checkpoints?                                      : 0     [DEFAULT]
Conserve GPU memory (slower)?                              : 0     [DEFAULT]
Convert given conv layers to unshared local                :       
Cropped DP: crop border size                               : 4     [DEFAULT]
Cropped DP: logreg layer name (for --multiview-test)       :       [DEFAULT]
Cropped DP: test on multiple patches?                      : 0     [DEFAULT]
Cropped Step: crop border step                             : 1     [DEFAULT]
Data batch range: testing                                  : 28-33 
Data batch range: training                                 : 1-27  
Data path                                                  : /data2/ad6813/pipe-data/Bluebox/batches/scraping_peeling/net_0 
Data provider                                              : basic-leaf256 
GPU override                                               : -1    [DEFAULT]
Layer definition file                                      : /homes/ad6813/Git/pipe-classification/models/scraping_peeling/net_0/layers.cfg 
Layer parameter file                                       : /homes/ad6813/Git/pipe-classification/models/scraping_peeling/net_0/params.cfg 
Load file                                                  : /data2/ad6813/my-nets/saves/ConvNet__2014-07-08_14.54.04 
Maximum save file size (MB)                                : 0     [DEFAULT]
Minibatch size                                             : 128   [DEFAULT]
Number of GPUs                                             : 1     [DEFAULT]
Number of epochs                                           : 50000 [DEFAULT]
Save path                                                  : /homes/ad6813/Git/pipe-classification/models/scraping_peeling/net_0/saves 
Test and quit?                                             : 0     [DEFAULT]
Test on more than one batch at a time?                     : -1    
Test on one batch at a time?                               : 0     
Testing frequency                                          : 17    
Unshare weight matrices in given layers                    :       
=========================
Running on CUDA device(s) -2
Current time: Tue Jul  8 20:50:52 2014
Saving checkpoints to /data2/ad6813/my-nets/saves/ConvNet__2014-07-08_14.54.04
=========================
334.10... logprob:  0.597849, 0.281250 (0.691 sec)
334.11... logprob:  0.638951, 0.335938 (0.657 sec)
334.12... logprob:  0.718252, 0.437500 (0.657 sec)
334.13... logprob:  0.657479, 0.359375 (0.662 sec)
334.14... logprob:  0.663094, 0.367188 (0.659 sec)
334.15... logprob:  0.686211, 0.398438 (0.658 sec)
334.16... logprob:  0.627066, 0.320312 (0.657 sec)
334.17... logprob:  0.638513, 0.335938 (0.660 sec)
334.18... logprob:  0.638223, 0.335938 (0.657 sec)
334.19... logprob:  0.632728, 0.328125 (0.656 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643561, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943958e-03 [6.754668e-09] 
Layer 'conv1' biases: 4.997785e-07 [1.576176e-10] 
Layer 'conv2' weights[0]: 7.931743e-03 [6.605167e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.665344e-10] 
Layer 'conv3' weights[0]: 7.929516e-03 [5.759192e-09] 
Layer 'conv3' biases: 4.190758e-06 [2.106556e-09] 
Layer 'conv4' weights[0]: 7.962279e-03 [5.708307e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.471764e-08] 
Layer 'conv5' weights[0]: 7.961623e-03 [8.473275e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.979907e-08] 
Layer 'fc6' weights[0]: 7.557859e-03 [9.991325e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.139070e-09] 
Layer 'fc7' weights[0]: 7.506086e-03 [1.259385e-07] 
Layer 'fc7' biases: 9.998543e-01 [1.102061e-07] 
Layer 'fc8' weights[0]: 5.984836e-04 [5.942001e-06] 
Layer 'fc8' biases: 1.491689e-01 [1.102321e-04] 
Train error last 27 batches: 0.635822
-------------------------------------------------------
Not saving because 0.643561 > 0.627087 (334.9: -0.00%)
======================================================= (5.020 sec)
334.20... logprob:  0.648852, 0.351562 (0.657 sec)
334.21... logprob:  0.643420, 0.343750 (0.657 sec)
334.22... logprob:  0.628061, 0.320312 (0.658 sec)
334.23... logprob:  0.623244, 0.312500 (0.659 sec)
334.24... logprob:  0.578128, 0.242188 (0.657 sec)
334.25... logprob:  0.628238, 0.320312 (0.658 sec)
334.26... logprob:  0.673969, 0.390625 (0.657 sec)
334.27... logprob:  0.628079, 0.320312 (0.660 sec)
335.1... logprob:  0.679408, 0.398438 (0.658 sec)
335.2... logprob:  0.597212, 0.273438 (0.656 sec)
335.3... logprob:  0.653760, 0.359375 (0.658 sec)
335.4... logprob:  0.596789, 0.273438 (0.658 sec)
335.5... logprob:  0.591026, 0.265625 (0.659 sec)
335.6... logprob:  0.611423, 0.296875 (0.658 sec)
335.7... logprob:  0.643835, 0.343750 (0.657 sec)
335.8... logprob:  0.604793, 0.289062 (0.659 sec)
335.9... logprob:  0.638569, 0.335938 (0.659 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644561, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943886e-03 [6.684268e-09] 
Layer 'conv1' biases: 5.006691e-07 [1.186612e-10] 
Layer 'conv2' weights[0]: 7.931671e-03 [5.788995e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.969396e-10] 
Layer 'conv3' weights[0]: 7.929451e-03 [5.652734e-09] 
Layer 'conv3' biases: 4.196891e-06 [1.843135e-09] 
Layer 'conv4' weights[0]: 7.962206e-03 [5.789471e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.614705e-08] 
Layer 'conv5' weights[0]: 7.961582e-03 [9.325921e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.916781e-08] 
Layer 'fc6' weights[0]: 7.557798e-03 [1.070024e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.967923e-09] 
Layer 'fc7' weights[0]: 7.505435e-03 [1.336505e-07] 
Layer 'fc7' biases: 9.998546e-01 [1.184109e-07] 
Layer 'fc8' weights[0]: 6.260672e-04 [6.448555e-06] 
Layer 'fc8' biases: 1.500371e-01 [1.452273e-04] 
Train error last 27 batches: 0.635821
-------------------------------------------------------
Not saving because 0.644561 > 0.627087 (334.9: -0.00%)
======================================================= (5.032 sec)
335.10... logprob:  0.597853, 0.281250 (0.660 sec)
335.11... logprob:  0.638948, 0.335938 (0.659 sec)
335.12... logprob:  0.718232, 0.437500 (0.661 sec)
335.13... logprob:  0.657472, 0.359375 (0.657 sec)
335.14... logprob:  0.663087, 0.367188 (0.660 sec)
335.15... logprob:  0.686204, 0.398438 (0.657 sec)
335.16... logprob:  0.627066, 0.320312 (0.659 sec)
335.17... logprob:  0.638513, 0.335938 (0.659 sec)
335.18... logprob:  0.638223, 0.335938 (0.659 sec)
335.19... logprob:  0.632727, 0.328125 (0.657 sec)
335.20... logprob:  0.648852, 0.351562 (0.658 sec)
335.21... logprob:  0.643420, 0.343750 (0.657 sec)
335.22... logprob:  0.628057, 0.320312 (0.657 sec)
335.23... logprob:  0.623240, 0.312500 (0.657 sec)
335.24... logprob:  0.578114, 0.242188 (0.658 sec)
335.25... logprob:  0.628235, 0.320312 (0.657 sec)
335.26... logprob:  0.673973, 0.390625 (0.659 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643452, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943828e-03 [6.500296e-09] 
Layer 'conv1' biases: 5.022043e-07 [6.856946e-11] 
Layer 'conv2' weights[0]: 7.931608e-03 [4.995118e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.441171e-10] 
Layer 'conv3' weights[0]: 7.929378e-03 [4.420167e-09] 
Layer 'conv3' biases: 4.210656e-06 [6.232718e-10] 
Layer 'conv4' weights[0]: 7.962134e-03 [4.320496e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.874727e-09] 
Layer 'conv5' weights[0]: 7.961496e-03 [1.171267e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.172685e-08] 
Layer 'fc6' weights[0]: 7.557738e-03 [4.003644e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.172041e-09] 
Layer 'fc7' weights[0]: 7.504819e-03 [4.230909e-08] 
Layer 'fc7' biases: 9.998540e-01 [1.419596e-08] 
Layer 'fc8' weights[0]: 5.879280e-04 [7.361944e-07] 
Layer 'fc8' biases: 1.493782e-01 [2.858930e-05] 
Train error last 27 batches: 0.635819
-------------------------------------------------------
Not saving because 0.643452 > 0.627087 (334.9: -0.00%)
======================================================= (5.166 sec)
335.27... logprob:  0.628076, 0.320312 (0.656 sec)
336.1... logprob:  0.679412, 0.398438 (0.659 sec)
336.2... logprob:  0.597206, 0.273438 (0.659 sec)
336.3... logprob:  0.653761, 0.359375 (0.659 sec)
336.4... logprob:  0.596785, 0.273438 (0.656 sec)
336.5... logprob:  0.591024, 0.265625 (0.659 sec)
336.6... logprob:  0.611424, 0.296875 (0.658 sec)
336.7... logprob:  0.643834, 0.343750 (0.658 sec)
336.8... logprob:  0.604795, 0.289062 (0.660 sec)
336.9... logprob:  0.638568, 0.335938 (0.660 sec)
336.10... logprob:  0.597858, 0.281250 (0.659 sec)
336.11... logprob:  0.638945, 0.335938 (0.660 sec)
336.12... logprob:  0.718211, 0.437500 (0.658 sec)
336.13... logprob:  0.657465, 0.359375 (0.659 sec)
336.14... logprob:  0.663081, 0.367188 (0.659 sec)
336.15... logprob:  0.686196, 0.398438 (0.656 sec)
336.16... logprob:  0.627066, 0.320312 (0.657 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644072, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943757e-03 [6.949933e-09] 
Layer 'conv1' biases: 5.031210e-07 [1.853036e-10] 
Layer 'conv2' weights[0]: 7.931541e-03 [7.257539e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.404061e-10] 
Layer 'conv3' weights[0]: 7.929304e-03 [6.311652e-09] 
Layer 'conv3' biases: 4.217088e-06 [2.594515e-09] 
Layer 'conv4' weights[0]: 7.962066e-03 [6.344406e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.912487e-08] 
Layer 'conv5' weights[0]: 7.961458e-03 [1.102236e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.171181e-07] 
Layer 'fc6' weights[0]: 7.557676e-03 [1.232354e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.182302e-08] 
Layer 'fc7' weights[0]: 7.504142e-03 [1.544187e-07] 
Layer 'fc7' biases: 9.998544e-01 [1.412308e-07] 
Layer 'fc8' weights[0]: 6.154946e-04 [7.683127e-06] 
Layer 'fc8' biases: 1.502616e-01 [1.420984e-04] 
Train error last 27 batches: 0.635817
-------------------------------------------------------
Not saving because 0.644072 > 0.627087 (334.9: -0.00%)
======================================================= (5.022 sec)
336.17... logprob:  0.638513, 0.335938 (0.659 sec)
336.18... logprob:  0.638224, 0.335938 (0.657 sec)
336.19... logprob:  0.632727, 0.328125 (0.659 sec)
336.20... logprob:  0.648854, 0.351562 (0.657 sec)
336.21... logprob:  0.643420, 0.343750 (0.658 sec)
336.22... logprob:  0.628054, 0.320312 (0.656 sec)
336.23... logprob:  0.623235, 0.312500 (0.659 sec)
336.24... logprob:  0.578097, 0.242188 (0.655 sec)
336.25... logprob:  0.628231, 0.320312 (0.658 sec)
336.26... logprob:  0.673980, 0.390625 (0.657 sec)
336.27... logprob:  0.628074, 0.320312 (0.659 sec)
337.1... logprob:  0.679418, 0.398438 (0.660 sec)
337.2... logprob:  0.597199, 0.273438 (0.660 sec)
337.3... logprob:  0.653762, 0.359375 (0.659 sec)
337.4... logprob:  0.596782, 0.273438 (0.658 sec)
337.5... logprob:  0.591022, 0.265625 (0.658 sec)
337.6... logprob:  0.611424, 0.296875 (0.658 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643778, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943692e-03 [7.349181e-09] 
Layer 'conv1' biases: 5.043335e-07 [1.643972e-10] 
Layer 'conv2' weights[0]: 7.931472e-03 [6.287768e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.711536e-10] 
Layer 'conv3' weights[0]: 7.929235e-03 [6.093066e-09] 
Layer 'conv3' biases: 4.227256e-06 [2.249240e-09] 
Layer 'conv4' weights[0]: 7.961996e-03 [6.192472e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.979962e-08] 
Layer 'conv5' weights[0]: 7.961384e-03 [1.141606e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.213124e-07] 
Layer 'fc6' weights[0]: 7.557605e-03 [1.273632e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.222377e-08] 
Layer 'fc7' weights[0]: 7.503488e-03 [1.595626e-07] 
Layer 'fc7' biases: 9.998543e-01 [1.462227e-07] 
Layer 'fc8' weights[0]: 6.069718e-04 [7.894841e-06] 
Layer 'fc8' biases: 1.502829e-01 [1.796076e-04] 
Train error last 27 batches: 0.635816
-------------------------------------------------------
Not saving because 0.643778 > 0.627087 (334.9: -0.00%)
======================================================= (5.027 sec)
337.7... logprob:  0.643834, 0.343750 (0.658 sec)
337.8... logprob:  0.604799, 0.289062 (0.661 sec)
337.9... logprob:  0.638566, 0.335938 (0.659 sec)
337.10... logprob:  0.597865, 0.281250 (0.661 sec)
337.11... logprob:  0.638941, 0.335938 (0.659 sec)
337.12... logprob:  0.718185, 0.437500 (0.660 sec)
337.13... logprob:  0.657456, 0.359375 (0.657 sec)
337.14... logprob:  0.663072, 0.367188 (0.659 sec)
337.15... logprob:  0.686185, 0.398438 (0.658 sec)
337.16... logprob:  0.627067, 0.320312 (0.658 sec)
337.17... logprob:  0.638513, 0.335938 (0.658 sec)
337.18... logprob:  0.638224, 0.335938 (0.657 sec)
337.19... logprob:  0.632727, 0.328125 (0.657 sec)
337.20... logprob:  0.648855, 0.351562 (0.659 sec)
337.21... logprob:  0.643421, 0.343750 (0.657 sec)
337.22... logprob:  0.628051, 0.320312 (0.658 sec)
337.23... logprob:  0.623229, 0.312500 (0.657 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643444, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943619e-03 [6.339519e-09] 
Layer 'conv1' biases: 5.057618e-07 [1.041906e-10] 
Layer 'conv2' weights[0]: 7.931409e-03 [5.324951e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.129888e-10] 
Layer 'conv3' weights[0]: 7.929169e-03 [4.737035e-09] 
Layer 'conv3' biases: 4.239587e-06 [1.077942e-09] 
Layer 'conv4' weights[0]: 7.961922e-03 [4.608691e-09] 
Layer 'conv4' biases: 1.000001e+00 [5.679744e-09] 
Layer 'conv5' weights[0]: 7.961306e-03 [3.290339e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.458097e-08] 
Layer 'fc6' weights[0]: 7.557532e-03 [5.284885e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.573228e-09] 
Layer 'fc7' weights[0]: 7.502853e-03 [6.475745e-08] 
Layer 'fc7' biases: 9.998537e-01 [4.361572e-08] 
Layer 'fc8' weights[0]: 5.818860e-04 [2.318639e-06] 
Layer 'fc8' biases: 1.499101e-01 [3.671747e-05] 
Train error last 27 batches: 0.635814
-------------------------------------------------------
Not saving because 0.643444 > 0.627087 (334.9: -0.00%)
======================================================= (5.083 sec)
337.24... logprob:  0.578077, 0.242188 (0.655 sec)
337.25... logprob:  0.628227, 0.320312 (0.657 sec)
337.26... logprob:  0.673987, 0.390625 (0.659 sec)
337.27... logprob:  0.628071, 0.320312 (0.655 sec)
338.1... logprob:  0.679424, 0.398438 (0.660 sec)
338.2... logprob:  0.597192, 0.273438 (0.658 sec)
338.3... logprob:  0.653764, 0.359375 (0.660 sec)
338.4... logprob:  0.596778, 0.273438 (0.659 sec)
338.5... logprob:  0.591020, 0.265625 (0.658 sec)
338.6... logprob:  0.611425, 0.296875 (0.657 sec)
338.7... logprob:  0.643833, 0.343750 (0.660 sec)
338.8... logprob:  0.604803, 0.289062 (0.660 sec)
338.9... logprob:  0.638565, 0.335938 (0.660 sec)
338.10... logprob:  0.597872, 0.281250 (0.659 sec)
338.11... logprob:  0.638937, 0.335938 (0.657 sec)
338.12... logprob:  0.718155, 0.437500 (0.658 sec)
338.13... logprob:  0.657446, 0.359375 (0.661 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.645115, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943556e-03 [6.534600e-09] 
Layer 'conv1' biases: 5.064293e-07 [1.012291e-10] 
Layer 'conv2' weights[0]: 7.931342e-03 [5.485417e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.751847e-10] 
Layer 'conv3' weights[0]: 7.929103e-03 [4.816552e-09] 
Layer 'conv3' biases: 4.242998e-06 [1.298378e-09] 
Layer 'conv4' weights[0]: 7.961863e-03 [4.727886e-09] 
Layer 'conv4' biases: 1.000001e+00 [7.371105e-09] 
Layer 'conv5' weights[0]: 7.961248e-03 [4.240575e-08] 
Layer 'conv5' biases: 1.000002e+00 [4.497158e-08] 
Layer 'fc6' weights[0]: 7.557465e-03 [5.955986e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.524502e-09] 
Layer 'fc7' weights[0]: 7.502186e-03 [7.455245e-08] 
Layer 'fc7' biases: 9.998546e-01 [5.475600e-08] 
Layer 'fc8' weights[0]: 6.338266e-04 [2.961275e-06] 
Layer 'fc8' biases: 1.513686e-01 [4.456637e-05] 
Train error last 27 batches: 0.635812
-------------------------------------------------------
Not saving because 0.645115 > 0.627087 (334.9: -0.00%)
======================================================= (5.070 sec)
338.14... logprob:  0.663062, 0.367188 (0.658 sec)
338.15... logprob:  0.686173, 0.398438 (0.658 sec)
338.16... logprob:  0.627067, 0.320312 (0.657 sec)
338.17... logprob:  0.638513, 0.335938 (0.659 sec)
338.18... logprob:  0.638223, 0.335938 (0.657 sec)
338.19... logprob:  0.632726, 0.328125 (0.658 sec)
338.20... logprob:  0.648856, 0.351562 (0.657 sec)
338.21... logprob:  0.643421, 0.343750 (0.658 sec)
338.22... logprob:  0.628048, 0.320312 (0.657 sec)
338.23... logprob:  0.623224, 0.312500 (0.658 sec)
338.24... logprob:  0.578061, 0.242188 (0.657 sec)
338.25... logprob:  0.628223, 0.320312 (0.658 sec)
338.26... logprob:  0.673994, 0.390625 (0.657 sec)
338.27... logprob:  0.628067, 0.320312 (0.660 sec)
339.1... logprob:  0.679432, 0.398438 (0.654 sec)
339.2... logprob:  0.597183, 0.273438 (0.660 sec)
339.3... logprob:  0.653766, 0.359375 (0.658 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643472, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943492e-03 [6.705628e-09] 
Layer 'conv1' biases: 5.079929e-07 [6.440179e-11] 
Layer 'conv2' weights[0]: 7.931281e-03 [4.968786e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.554193e-10] 
Layer 'conv3' weights[0]: 7.929035e-03 [4.465263e-09] 
Layer 'conv3' biases: 4.257290e-06 [6.661372e-10] 
Layer 'conv4' weights[0]: 7.961795e-03 [4.347592e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.433191e-09] 
Layer 'conv5' weights[0]: 7.961172e-03 [1.504277e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.547339e-08] 
Layer 'fc6' weights[0]: 7.557404e-03 [4.151467e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.543569e-09] 
Layer 'fc7' weights[0]: 7.501560e-03 [4.522862e-08] 
Layer 'fc7' biases: 9.998538e-01 [1.861572e-08] 
Layer 'fc8' weights[0]: 5.900470e-04 [9.920600e-07] 
Layer 'fc8' biases: 1.505653e-01 [2.979438e-05] 
Train error last 27 batches: 0.635810
-------------------------------------------------------
Not saving because 0.643472 > 0.627087 (334.9: -0.00%)
======================================================= (5.218 sec)
339.4... logprob:  0.596771, 0.273438 (0.662 sec)
339.5... logprob:  0.591014, 0.265625 (0.664 sec)
339.6... logprob:  0.611423, 0.296875 (0.660 sec)
339.7... logprob:  0.643833, 0.343750 (0.661 sec)
339.8... logprob:  0.604804, 0.289062 (0.668 sec)
339.9... logprob:  0.638564, 0.335938 (0.661 sec)
339.10... logprob:  0.597876, 0.281250 (0.663 sec)
339.11... logprob:  0.638935, 0.335938 (0.663 sec)
339.12... logprob:  0.718134, 0.437500 (0.663 sec)
339.13... logprob:  0.657439, 0.359375 (0.662 sec)
339.14... logprob:  0.663055, 0.367188 (0.663 sec)
339.15... logprob:  0.686164, 0.398438 (0.657 sec)
339.16... logprob:  0.627067, 0.320312 (0.660 sec)
339.17... logprob:  0.638512, 0.335938 (0.661 sec)
339.18... logprob:  0.638224, 0.335938 (0.660 sec)
339.19... logprob:  0.632726, 0.328125 (0.661 sec)
339.20... logprob:  0.648858, 0.351562 (0.661 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643491, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943429e-03 [6.816356e-09] 
Layer 'conv1' biases: 5.091652e-07 [1.622551e-10] 
Layer 'conv2' weights[0]: 7.931213e-03 [6.544308e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.764877e-10] 
Layer 'conv3' weights[0]: 7.928977e-03 [5.741227e-09] 
Layer 'conv3' biases: 4.266800e-06 [2.119779e-09] 
Layer 'conv4' weights[0]: 7.961728e-03 [5.673441e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.486951e-08] 
Layer 'conv5' weights[0]: 7.961111e-03 [8.580346e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.102870e-08] 
Layer 'fc6' weights[0]: 7.557340e-03 [1.007827e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.242178e-09] 
Layer 'fc7' weights[0]: 7.500887e-03 [1.269138e-07] 
Layer 'fc7' biases: 9.998538e-01 [1.114485e-07] 
Layer 'fc8' weights[0]: 5.916610e-04 [5.981583e-06] 
Layer 'fc8' biases: 1.508427e-01 [1.140558e-04] 
Train error last 27 batches: 0.635808
-------------------------------------------------------
Not saving because 0.643491 > 0.627087 (334.9: -0.00%)
======================================================= (5.032 sec)
339.21... logprob:  0.643422, 0.343750 (0.662 sec)
339.22... logprob:  0.628045, 0.320312 (0.661 sec)
339.23... logprob:  0.623219, 0.312500 (0.660 sec)
339.24... logprob:  0.578044, 0.242188 (0.662 sec)
339.25... logprob:  0.628220, 0.320312 (0.661 sec)
339.26... logprob:  0.674000, 0.390625 (0.662 sec)
339.27... logprob:  0.628066, 0.320312 (0.662 sec)
340.1... logprob:  0.679437, 0.398438 (0.665 sec)
340.2... logprob:  0.597178, 0.273438 (0.663 sec)
340.3... logprob:  0.653767, 0.359375 (0.663 sec)
340.4... logprob:  0.596768, 0.273438 (0.666 sec)
340.5... logprob:  0.591014, 0.265625 (0.667 sec)
340.6... logprob:  0.611424, 0.296875 (0.667 sec)
340.7... logprob:  0.643832, 0.343750 (0.667 sec)
340.8... logprob:  0.604809, 0.289062 (0.667 sec)
340.9... logprob:  0.638562, 0.335938 (0.668 sec)
340.10... logprob:  0.597883, 0.281250 (0.666 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644961, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943364e-03 [7.031951e-09] 
Layer 'conv1' biases: 5.099510e-07 [1.427086e-10] 
Layer 'conv2' weights[0]: 7.931146e-03 [6.220286e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.334897e-10] 
Layer 'conv3' weights[0]: 7.928909e-03 [6.071986e-09] 
Layer 'conv3' biases: 4.271449e-06 [2.219984e-09] 
Layer 'conv4' weights[0]: 7.961660e-03 [6.258201e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.950889e-08] 
Layer 'conv5' weights[0]: 7.961059e-03 [1.131146e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.202639e-07] 
Layer 'fc6' weights[0]: 7.557272e-03 [1.252353e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.199122e-08] 
Layer 'fc7' weights[0]: 7.500243e-03 [1.552355e-07] 
Layer 'fc7' biases: 9.998545e-01 [1.415669e-07] 
Layer 'fc8' weights[0]: 6.309085e-04 [7.739684e-06] 
Layer 'fc8' biases: 1.519880e-01 [1.709570e-04] 
Train error last 27 batches: 0.635808
-------------------------------------------------------
Not saving because 0.644961 > 0.627087 (334.9: -0.00%)
======================================================= (5.070 sec)
340.11... logprob:  0.638931, 0.335938 (0.667 sec)
340.12... logprob:  0.718106, 0.437500 (0.666 sec)
340.13... logprob:  0.657429, 0.359375 (0.663 sec)
340.14... logprob:  0.663046, 0.367188 (0.664 sec)
340.15... logprob:  0.686153, 0.398438 (0.663 sec)
340.16... logprob:  0.627067, 0.320312 (0.662 sec)
340.17... logprob:  0.638512, 0.335938 (0.664 sec)
340.18... logprob:  0.638223, 0.335938 (0.662 sec)
340.19... logprob:  0.632725, 0.328125 (0.687 sec)
340.20... logprob:  0.648859, 0.351562 (0.691 sec)
340.21... logprob:  0.643422, 0.343750 (0.692 sec)
340.22... logprob:  0.628042, 0.320312 (0.662 sec)
340.23... logprob:  0.623215, 0.312500 (0.662 sec)
340.24... logprob:  0.578030, 0.242188 (0.662 sec)
340.25... logprob:  0.628217, 0.320312 (0.661 sec)
340.26... logprob:  0.674005, 0.390625 (0.659 sec)
340.27... logprob:  0.628062, 0.320312 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643461, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943305e-03 [6.587768e-09] 
Layer 'conv1' biases: 5.115293e-07 [6.950366e-11] 
Layer 'conv2' weights[0]: 7.931093e-03 [4.893660e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.631856e-10] 
Layer 'conv3' weights[0]: 7.928848e-03 [4.465111e-09] 
Layer 'conv3' biases: 4.285765e-06 [7.228209e-10] 
Layer 'conv4' weights[0]: 7.961591e-03 [4.398783e-09] 
Layer 'conv4' biases: 1.000001e+00 [4.075332e-09] 
Layer 'conv5' weights[0]: 7.960992e-03 [2.385813e-08] 
Layer 'conv5' biases: 1.000002e+00 [2.506090e-08] 
Layer 'fc6' weights[0]: 7.557207e-03 [4.659637e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.487140e-09] 
Layer 'fc7' weights[0]: 7.499574e-03 [5.389673e-08] 
Layer 'fc7' biases: 9.998537e-01 [2.993696e-08] 
Layer 'fc8' weights[0]: 5.878048e-04 [1.573316e-06] 
Layer 'fc8' biases: 1.512084e-01 [4.648815e-05] 
Train error last 27 batches: 0.635804
-------------------------------------------------------
Not saving because 0.643461 > 0.627087 (334.9: -0.00%)
======================================================= (5.141 sec)
341.1... logprob:  0.679443, 0.398438 (0.663 sec)
341.2... logprob:  0.597170, 0.273438 (0.664 sec)
341.3... logprob:  0.653768, 0.359375 (0.664 sec)
341.4... logprob:  0.596763, 0.273438 (0.664 sec)
341.5... logprob:  0.591009, 0.265625 (0.664 sec)
341.6... logprob:  0.611423, 0.296875 (0.665 sec)
341.7... logprob:  0.643832, 0.343750 (0.662 sec)
341.8... logprob:  0.604809, 0.289062 (0.665 sec)
341.9... logprob:  0.638562, 0.335938 (0.664 sec)
341.10... logprob:  0.597886, 0.281250 (0.665 sec)
341.11... logprob:  0.638929, 0.335938 (0.661 sec)
341.12... logprob:  0.718091, 0.437500 (0.664 sec)
341.13... logprob:  0.657425, 0.359375 (0.663 sec)
341.14... logprob:  0.663040, 0.367188 (0.661 sec)
341.15... logprob:  0.686147, 0.398438 (0.662 sec)
341.16... logprob:  0.627067, 0.320312 (0.663 sec)
341.17... logprob:  0.638513, 0.335938 (0.663 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643838, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943248e-03 [6.453390e-09] 
Layer 'conv1' biases: 5.125170e-07 [1.716757e-10] 
Layer 'conv2' weights[0]: 7.931015e-03 [6.916787e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.799139e-10] 
Layer 'conv3' weights[0]: 7.928776e-03 [6.085794e-09] 
Layer 'conv3' biases: 4.293110e-06 [2.406481e-09] 
Layer 'conv4' weights[0]: 7.961528e-03 [6.138002e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.811960e-08] 
Layer 'conv5' weights[0]: 7.960921e-03 [1.042650e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.106789e-07] 
Layer 'fc6' weights[0]: 7.557143e-03 [1.175877e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.119459e-08] 
Layer 'fc7' weights[0]: 7.498913e-03 [1.471054e-07] 
Layer 'fc7' biases: 9.998540e-01 [1.334680e-07] 
Layer 'fc8' weights[0]: 6.073505e-04 [7.251360e-06] 
Layer 'fc8' biases: 1.519055e-01 [1.361519e-04] 
Train error last 27 batches: 0.635803
-------------------------------------------------------
Not saving because 0.643838 > 0.627087 (334.9: -0.00%)
======================================================= (5.054 sec)
341.18... logprob:  0.638223, 0.335938 (0.662 sec)
341.19... logprob:  0.632724, 0.328125 (0.660 sec)
341.20... logprob:  0.648860, 0.351562 (0.663 sec)
341.21... logprob:  0.643423, 0.343750 (0.662 sec)
341.22... logprob:  0.628040, 0.320312 (0.663 sec)
341.23... logprob:  0.623211, 0.312500 (0.659 sec)
341.24... logprob:  0.578014, 0.242188 (0.662 sec)
341.25... logprob:  0.628214, 0.320312 (0.661 sec)
341.26... logprob:  0.674011, 0.390625 (0.663 sec)
341.27... logprob:  0.628061, 0.320312 (0.663 sec)
342.1... logprob:  0.679448, 0.398438 (0.660 sec)
342.2... logprob:  0.597166, 0.273438 (0.661 sec)
342.3... logprob:  0.653769, 0.359375 (0.665 sec)
342.4... logprob:  0.596762, 0.273438 (0.662 sec)
342.5... logprob:  0.591010, 0.265625 (0.665 sec)
342.6... logprob:  0.611425, 0.296875 (0.660 sec)
342.7... logprob:  0.643831, 0.343750 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643965, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943177e-03 [6.819803e-09] 
Layer 'conv1' biases: 5.136274e-07 [1.281729e-10] 
Layer 'conv2' weights[0]: 7.930957e-03 [5.803753e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.156543e-10] 
Layer 'conv3' weights[0]: 7.928713e-03 [5.636667e-09] 
Layer 'conv3' biases: 4.301956e-06 [1.883997e-09] 
Layer 'conv4' weights[0]: 7.961458e-03 [5.739257e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.632913e-08] 
Layer 'conv5' weights[0]: 7.960855e-03 [9.383093e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.975097e-08] 
Layer 'fc6' weights[0]: 7.557075e-03 [1.075185e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.003039e-08] 
Layer 'fc7' weights[0]: 7.498263e-03 [1.345333e-07] 
Layer 'fc7' biases: 9.998541e-01 [1.195275e-07] 
Layer 'fc8' weights[0]: 6.108505e-04 [6.444376e-06] 
Layer 'fc8' biases: 1.522070e-01 [1.488685e-04] 
Train error last 27 batches: 0.635802
-------------------------------------------------------
Not saving because 0.643965 > 0.627087 (334.9: -0.00%)
======================================================= (5.072 sec)
342.8... logprob:  0.604814, 0.289062 (0.663 sec)
342.9... logprob:  0.638560, 0.335938 (0.663 sec)
342.10... logprob:  0.597894, 0.281250 (0.661 sec)
342.11... logprob:  0.638924, 0.335938 (0.665 sec)
342.12... logprob:  0.718062, 0.437500 (0.663 sec)
342.13... logprob:  0.657414, 0.359375 (0.663 sec)
342.14... logprob:  0.663030, 0.367188 (0.663 sec)
342.15... logprob:  0.686135, 0.398438 (0.663 sec)
342.16... logprob:  0.627067, 0.320312 (0.662 sec)
342.17... logprob:  0.638512, 0.335938 (0.664 sec)
342.18... logprob:  0.638223, 0.335938 (0.662 sec)
342.19... logprob:  0.632724, 0.328125 (0.663 sec)
342.20... logprob:  0.648860, 0.351562 (0.661 sec)
342.21... logprob:  0.643423, 0.343750 (0.663 sec)
342.22... logprob:  0.628037, 0.320312 (0.662 sec)
342.23... logprob:  0.623207, 0.312500 (0.660 sec)
342.24... logprob:  0.578001, 0.242188 (0.662 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643443, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943110e-03 [6.499391e-09] 
Layer 'conv1' biases: 5.150985e-07 [5.968275e-11] 
Layer 'conv2' weights[0]: 7.930899e-03 [4.864158e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.013872e-10] 
Layer 'conv3' weights[0]: 7.928648e-03 [4.530573e-09] 
Layer 'conv3' biases: 4.314627e-06 [8.573295e-10] 
Layer 'conv4' weights[0]: 7.961397e-03 [4.478781e-09] 
Layer 'conv4' biases: 1.000001e+00 [6.194138e-09] 
Layer 'conv5' weights[0]: 7.960802e-03 [3.528842e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.728866e-08] 
Layer 'fc6' weights[0]: 7.557019e-03 [5.432108e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.760508e-09] 
Layer 'fc7' weights[0]: 7.497606e-03 [6.638490e-08] 
Layer 'fc7' biases: 9.998534e-01 [4.531753e-08] 
Layer 'fc8' weights[0]: 5.825776e-04 [2.383606e-06] 
Layer 'fc8' biases: 1.517587e-01 [6.900890e-05] 
Train error last 27 batches: 0.635799
-------------------------------------------------------
Not saving because 0.643443 > 0.627087 (334.9: -0.00%)
======================================================= (5.117 sec)
342.25... logprob:  0.628210, 0.320312 (0.663 sec)
342.26... logprob:  0.674016, 0.390625 (0.662 sec)
342.27... logprob:  0.628058, 0.320312 (0.664 sec)
343.1... logprob:  0.679453, 0.398438 (0.663 sec)
343.2... logprob:  0.597159, 0.273438 (0.664 sec)
343.3... logprob:  0.653771, 0.359375 (0.663 sec)
343.4... logprob:  0.596755, 0.273438 (0.663 sec)
343.5... logprob:  0.591005, 0.265625 (0.662 sec)
343.6... logprob:  0.611423, 0.296875 (0.664 sec)
343.7... logprob:  0.643831, 0.343750 (0.663 sec)
343.8... logprob:  0.604814, 0.289062 (0.664 sec)
343.9... logprob:  0.638559, 0.335938 (0.664 sec)
343.10... logprob:  0.597896, 0.281250 (0.661 sec)
343.11... logprob:  0.638922, 0.335938 (0.663 sec)
343.12... logprob:  0.718050, 0.437500 (0.664 sec)
343.13... logprob:  0.657411, 0.359375 (0.663 sec)
343.14... logprob:  0.663026, 0.367188 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644798, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943036e-03 [6.779323e-09] 
Layer 'conv1' biases: 5.158472e-07 [1.515345e-10] 
Layer 'conv2' weights[0]: 7.930837e-03 [6.281785e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.906622e-10] 
Layer 'conv3' weights[0]: 7.928575e-03 [5.489712e-09] 
Layer 'conv3' biases: 4.318834e-06 [1.906628e-09] 
Layer 'conv4' weights[0]: 7.961336e-03 [5.454220e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.285206e-08] 
Layer 'conv5' weights[0]: 7.960713e-03 [7.421747e-08] 
Layer 'conv5' biases: 1.000002e+00 [7.882111e-08] 
Layer 'fc6' weights[0]: 7.556946e-03 [8.948419e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.953731e-09] 
Layer 'fc7' weights[0]: 7.496946e-03 [1.122477e-07] 
Layer 'fc7' biases: 9.998543e-01 [9.491831e-08] 
Layer 'fc8' weights[0]: 6.273080e-04 [5.146638e-06] 
Layer 'fc8' biases: 1.530517e-01 [9.018392e-05] 
Train error last 27 batches: 0.635798
-------------------------------------------------------
Not saving because 0.644798 > 0.627087 (334.9: -0.00%)
======================================================= (5.064 sec)
343.15... logprob:  0.686131, 0.398438 (0.662 sec)
343.16... logprob:  0.627067, 0.320312 (0.663 sec)
343.17... logprob:  0.638512, 0.335938 (0.663 sec)
343.18... logprob:  0.638223, 0.335938 (0.662 sec)
343.19... logprob:  0.632723, 0.328125 (0.662 sec)
343.20... logprob:  0.648861, 0.351562 (0.663 sec)
343.21... logprob:  0.643423, 0.343750 (0.661 sec)
343.22... logprob:  0.628035, 0.320312 (0.663 sec)
343.23... logprob:  0.623204, 0.312500 (0.662 sec)
343.24... logprob:  0.577990, 0.242188 (0.679 sec)
343.25... logprob:  0.628208, 0.320312 (0.664 sec)
343.26... logprob:  0.674020, 0.390625 (0.664 sec)
343.27... logprob:  0.628056, 0.320312 (0.663 sec)
344.1... logprob:  0.679457, 0.398438 (0.664 sec)
344.2... logprob:  0.597154, 0.273438 (0.663 sec)
344.3... logprob:  0.653772, 0.359375 (0.664 sec)
344.4... logprob:  0.596753, 0.273438 (0.663 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643508, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942977e-03 [6.857901e-09] 
Layer 'conv1' biases: 5.173276e-07 [8.964207e-11] 
Layer 'conv2' weights[0]: 7.930770e-03 [5.299347e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.712241e-10] 
Layer 'conv3' weights[0]: 7.928505e-03 [4.988146e-09] 
Layer 'conv3' biases: 4.332108e-06 [1.248190e-09] 
Layer 'conv4' weights[0]: 7.961272e-03 [4.956472e-09] 
Layer 'conv4' biases: 1.000001e+00 [9.598533e-09] 
Layer 'conv5' weights[0]: 7.960674e-03 [5.600418e-08] 
Layer 'conv5' biases: 1.000002e+00 [5.930897e-08] 
Layer 'fc6' weights[0]: 7.556876e-03 [7.159687e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.947336e-09] 
Layer 'fc7' weights[0]: 7.496326e-03 [8.944513e-08] 
Layer 'fc7' biases: 9.998537e-01 [7.082532e-08] 
Layer 'fc8' weights[0]: 5.918295e-04 [3.794931e-06] 
Layer 'fc8' biases: 1.524307e-01 [9.274571e-05] 
Train error last 27 batches: 0.635797
-------------------------------------------------------
Not saving because 0.643508 > 0.627087 (334.9: -0.00%)
======================================================= (5.097 sec)
344.5... logprob:  0.591003, 0.265625 (0.664 sec)
344.6... logprob:  0.611423, 0.296875 (0.663 sec)
344.7... logprob:  0.643830, 0.343750 (0.662 sec)
344.8... logprob:  0.604816, 0.289062 (0.665 sec)
344.9... logprob:  0.638558, 0.335938 (0.664 sec)
344.10... logprob:  0.597901, 0.281250 (0.661 sec)
344.11... logprob:  0.638920, 0.335938 (0.664 sec)
344.12... logprob:  0.718029, 0.437500 (0.664 sec)
344.13... logprob:  0.657404, 0.359375 (0.664 sec)
344.14... logprob:  0.663020, 0.367188 (0.663 sec)
344.15... logprob:  0.686123, 0.398438 (0.662 sec)
344.16... logprob:  0.627068, 0.320312 (0.662 sec)
344.17... logprob:  0.638512, 0.335938 (0.664 sec)
344.18... logprob:  0.638224, 0.335938 (0.662 sec)
344.19... logprob:  0.632723, 0.328125 (0.663 sec)
344.20... logprob:  0.648863, 0.351562 (0.657 sec)
344.21... logprob:  0.643424, 0.343750 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643453, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942903e-03 [6.850263e-09] 
Layer 'conv1' biases: 5.185808e-07 [1.536022e-10] 
Layer 'conv2' weights[0]: 7.930703e-03 [6.506671e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.372453e-10] 
Layer 'conv3' weights[0]: 7.928444e-03 [5.680255e-09] 
Layer 'conv3' biases: 4.342634e-06 [2.018633e-09] 
Layer 'conv4' weights[0]: 7.961208e-03 [5.597842e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.384812e-08] 
Layer 'conv5' weights[0]: 7.960606e-03 [7.943450e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.409789e-08] 
Layer 'fc6' weights[0]: 7.556809e-03 [9.587147e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.623662e-09] 
Layer 'fc7' weights[0]: 7.495675e-03 [1.204094e-07] 
Layer 'fc7' biases: 9.998536e-01 [1.038489e-07] 
Layer 'fc8' weights[0]: 5.854222e-04 [5.537152e-06] 
Layer 'fc8' biases: 1.525094e-01 [1.071951e-04] 
Train error last 27 batches: 0.635796
-------------------------------------------------------
Not saving because 0.643453 > 0.627087 (334.9: -0.00%)
======================================================= (5.148 sec)
344.22... logprob:  0.628031, 0.320312 (0.660 sec)
344.23... logprob:  0.623198, 0.312500 (0.663 sec)
344.24... logprob:  0.577972, 0.242188 (0.662 sec)
344.25... logprob:  0.628205, 0.320312 (0.663 sec)
344.26... logprob:  0.674027, 0.390625 (0.662 sec)
344.27... logprob:  0.628053, 0.320312 (0.664 sec)
345.1... logprob:  0.679463, 0.398438 (0.664 sec)
345.2... logprob:  0.597147, 0.273438 (0.663 sec)
345.3... logprob:  0.653773, 0.359375 (0.665 sec)
345.4... logprob:  0.596749, 0.273438 (0.662 sec)
345.5... logprob:  0.591001, 0.265625 (0.662 sec)
345.6... logprob:  0.611424, 0.296875 (0.664 sec)
345.7... logprob:  0.643830, 0.343750 (0.662 sec)
345.8... logprob:  0.604821, 0.289062 (0.666 sec)
345.9... logprob:  0.638557, 0.335938 (0.663 sec)
345.10... logprob:  0.597908, 0.281250 (0.668 sec)
345.11... logprob:  0.638916, 0.335938 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.645315, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942828e-03 [6.789298e-09] 
Layer 'conv1' biases: 5.192841e-07 [1.166521e-10] 
Layer 'conv2' weights[0]: 7.930633e-03 [5.703778e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.644051e-10] 
Layer 'conv3' weights[0]: 7.928377e-03 [5.545441e-09] 
Layer 'conv3' biases: 4.346114e-06 [1.775914e-09] 
Layer 'conv4' weights[0]: 7.961141e-03 [5.640317e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.524902e-08] 
Layer 'conv5' weights[0]: 7.960526e-03 [8.809708e-08] 
Layer 'conv5' biases: 1.000001e+00 [9.378392e-08] 
Layer 'fc6' weights[0]: 7.556738e-03 [1.023874e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.405105e-09] 
Layer 'fc7' weights[0]: 7.494965e-03 [1.268016e-07] 
Layer 'fc7' biases: 9.998544e-01 [1.103688e-07] 
Layer 'fc8' weights[0]: 6.342806e-04 [6.027629e-06] 
Layer 'fc8' biases: 1.538906e-01 [1.359051e-04] 
Train error last 27 batches: 0.635795
-------------------------------------------------------
Not saving because 0.645315 > 0.627087 (334.9: -0.00%)
======================================================= (5.077 sec)
345.12... logprob:  0.718001, 0.437500 (0.664 sec)
345.13... logprob:  0.657394, 0.359375 (0.663 sec)
345.14... logprob:  0.663010, 0.367188 (0.664 sec)
345.15... logprob:  0.686111, 0.398438 (0.661 sec)
345.16... logprob:  0.627068, 0.320312 (0.664 sec)
345.17... logprob:  0.638512, 0.335938 (0.663 sec)
345.18... logprob:  0.638223, 0.335938 (0.663 sec)
345.19... logprob:  0.632722, 0.328125 (0.662 sec)
345.20... logprob:  0.648863, 0.351562 (0.663 sec)
345.21... logprob:  0.643423, 0.343750 (0.661 sec)
345.22... logprob:  0.628028, 0.320312 (0.663 sec)
345.23... logprob:  0.623195, 0.312500 (0.659 sec)
345.24... logprob:  0.577956, 0.242188 (0.663 sec)
345.25... logprob:  0.628201, 0.320312 (0.662 sec)
345.26... logprob:  0.674033, 0.390625 (0.663 sec)
345.27... logprob:  0.628051, 0.320312 (0.663 sec)
346.1... logprob:  0.679469, 0.398438 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643455, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942752e-03 [6.648450e-09] 
Layer 'conv1' biases: 5.209145e-07 [8.027693e-11] 
Layer 'conv2' weights[0]: 7.930570e-03 [5.135603e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.242464e-10] 
Layer 'conv3' weights[0]: 7.928317e-03 [4.485319e-09] 
Layer 'conv3' biases: 4.361147e-06 [8.074275e-10] 
Layer 'conv4' weights[0]: 7.961083e-03 [4.384191e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.972547e-09] 
Layer 'conv5' weights[0]: 7.960469e-03 [1.688316e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.726271e-08] 
Layer 'fc6' weights[0]: 7.556674e-03 [4.276116e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.844593e-09] 
Layer 'fc7' weights[0]: 7.494372e-03 [4.807544e-08] 
Layer 'fc7' biases: 9.998536e-01 [2.323570e-08] 
Layer 'fc8' weights[0]: 5.853040e-04 [1.186668e-06] 
Layer 'fc8' biases: 1.529607e-01 [1.636684e-05] 
Train error last 27 batches: 0.635792
-------------------------------------------------------
Not saving because 0.643455 > 0.627087 (334.9: -0.00%)
======================================================= (5.169 sec)
346.2... logprob:  0.597140, 0.273438 (0.663 sec)
346.3... logprob:  0.653775, 0.359375 (0.663 sec)
346.4... logprob:  0.596743, 0.273438 (0.663 sec)
346.5... logprob:  0.590997, 0.265625 (0.664 sec)
346.6... logprob:  0.611422, 0.296875 (0.664 sec)
346.7... logprob:  0.643830, 0.343750 (0.664 sec)
346.8... logprob:  0.604821, 0.289062 (0.664 sec)
346.9... logprob:  0.638556, 0.335938 (0.665 sec)
346.10... logprob:  0.597912, 0.281250 (0.664 sec)
346.11... logprob:  0.638914, 0.335938 (0.665 sec)
346.12... logprob:  0.717984, 0.437500 (0.664 sec)
346.13... logprob:  0.657389, 0.359375 (0.663 sec)
346.14... logprob:  0.663005, 0.367188 (0.664 sec)
346.15... logprob:  0.686105, 0.398438 (0.663 sec)
346.16... logprob:  0.627068, 0.320312 (0.662 sec)
346.17... logprob:  0.638512, 0.335938 (0.665 sec)
346.18... logprob:  0.638224, 0.335938 (0.659 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643673, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942689e-03 [6.532739e-09] 
Layer 'conv1' biases: 5.219605e-07 [1.740239e-10] 
Layer 'conv2' weights[0]: 7.930505e-03 [6.784188e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.482652e-10] 
Layer 'conv3' weights[0]: 7.928248e-03 [5.965707e-09] 
Layer 'conv3' biases: 4.369123e-06 [2.313037e-09] 
Layer 'conv4' weights[0]: 7.961031e-03 [5.963533e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.685833e-08] 
Layer 'conv5' weights[0]: 7.960401e-03 [9.691823e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.028593e-07] 
Layer 'fc6' weights[0]: 7.556618e-03 [1.106156e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.042348e-08] 
Layer 'fc7' weights[0]: 7.493699e-03 [1.384588e-07] 
Layer 'fc7' biases: 9.998537e-01 [1.242954e-07] 
Layer 'fc8' weights[0]: 5.997400e-04 [6.699147e-06] 
Layer 'fc8' biases: 1.535445e-01 [1.275245e-04] 
Train error last 27 batches: 0.635790
-------------------------------------------------------
Not saving because 0.643673 > 0.627087 (334.9: -0.00%)
======================================================= (5.051 sec)
346.19... logprob:  0.632722, 0.328125 (0.664 sec)
346.20... logprob:  0.648866, 0.351562 (0.662 sec)
346.21... logprob:  0.643424, 0.343750 (0.663 sec)
346.22... logprob:  0.628025, 0.320312 (0.662 sec)
346.23... logprob:  0.623188, 0.312500 (0.663 sec)
346.24... logprob:  0.577938, 0.242188 (0.660 sec)
346.25... logprob:  0.628197, 0.320312 (0.664 sec)
346.26... logprob:  0.674039, 0.390625 (0.663 sec)
346.27... logprob:  0.628048, 0.320312 (0.661 sec)
347.1... logprob:  0.679475, 0.398438 (0.663 sec)
347.2... logprob:  0.597134, 0.273438 (0.664 sec)
347.3... logprob:  0.653776, 0.359375 (0.661 sec)
347.4... logprob:  0.596741, 0.273438 (0.664 sec)
347.5... logprob:  0.590996, 0.265625 (0.663 sec)
347.6... logprob:  0.611424, 0.296875 (0.662 sec)
347.7... logprob:  0.643829, 0.343750 (0.663 sec)
347.8... logprob:  0.604828, 0.289062 (0.666 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644240, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942632e-03 [7.176908e-09] 
Layer 'conv1' biases: 5.229596e-07 [1.450449e-10] 
Layer 'conv2' weights[0]: 7.930438e-03 [6.279563e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.502276e-10] 
Layer 'conv3' weights[0]: 7.928184e-03 [6.086446e-09] 
Layer 'conv3' biases: 4.376504e-06 [2.228106e-09] 
Layer 'conv4' weights[0]: 7.960968e-03 [6.224775e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.936406e-08] 
Layer 'conv5' weights[0]: 7.960329e-03 [1.114402e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.183965e-07] 
Layer 'fc6' weights[0]: 7.556541e-03 [1.243259e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.188565e-08] 
Layer 'fc7' weights[0]: 7.493048e-03 [1.542452e-07] 
Layer 'fc7' biases: 9.998540e-01 [1.406653e-07] 
Layer 'fc8' weights[0]: 6.156430e-04 [7.596653e-06] 
Layer 'fc8' biases: 1.541408e-01 [1.730130e-04] 
Train error last 27 batches: 0.635790
-------------------------------------------------------
Not saving because 0.644240 > 0.627087 (334.9: -0.00%)
======================================================= (5.061 sec)
347.9... logprob:  0.638553, 0.335938 (0.667 sec)
347.10... logprob:  0.597920, 0.281250 (0.666 sec)
347.11... logprob:  0.638909, 0.335938 (0.665 sec)
347.12... logprob:  0.717949, 0.437500 (0.666 sec)
347.13... logprob:  0.657377, 0.359375 (0.663 sec)
347.14... logprob:  0.662993, 0.367188 (0.666 sec)
347.15... logprob:  0.686091, 0.398438 (0.665 sec)
347.16... logprob:  0.627069, 0.320312 (0.664 sec)
347.17... logprob:  0.638512, 0.335938 (0.665 sec)
347.18... logprob:  0.638223, 0.335938 (0.665 sec)
347.19... logprob:  0.632721, 0.328125 (0.664 sec)
347.20... logprob:  0.648867, 0.351562 (0.664 sec)
347.21... logprob:  0.643425, 0.343750 (0.664 sec)
347.22... logprob:  0.628022, 0.320312 (0.665 sec)
347.23... logprob:  0.623184, 0.312500 (0.664 sec)
347.24... logprob:  0.577919, 0.242188 (0.665 sec)
347.25... logprob:  0.628193, 0.320312 (0.665 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643451, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942558e-03 [6.602025e-09] 
Layer 'conv1' biases: 5.244537e-07 [6.924147e-11] 
Layer 'conv2' weights[0]: 7.930378e-03 [4.954801e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.641301e-10] 
Layer 'conv3' weights[0]: 7.928112e-03 [4.670127e-09] 
Layer 'conv3' biases: 4.389391e-06 [1.037172e-09] 
Layer 'conv4' weights[0]: 7.960900e-03 [4.663776e-09] 
Layer 'conv4' biases: 1.000001e+00 [8.075588e-09] 
Layer 'conv5' weights[0]: 7.960265e-03 [4.622953e-08] 
Layer 'conv5' biases: 1.000002e+00 [4.877203e-08] 
Layer 'fc6' weights[0]: 7.556471e-03 [6.298884e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.924069e-09] 
Layer 'fc7' weights[0]: 7.492397e-03 [7.826597e-08] 
Layer 'fc7' biases: 9.998536e-01 [5.884657e-08] 
Layer 'fc8' weights[0]: 5.837224e-04 [3.107479e-06] 
Layer 'fc8' biases: 1.536070e-01 [8.454526e-05] 
Train error last 27 batches: 0.635786
-------------------------------------------------------
Not saving because 0.643451 > 0.627087 (334.9: -0.00%)
======================================================= (5.113 sec)
347.26... logprob:  0.674047, 0.390625 (0.665 sec)
347.27... logprob:  0.628044, 0.320312 (0.663 sec)
348.1... logprob:  0.679483, 0.398438 (0.660 sec)
348.2... logprob:  0.597125, 0.273438 (0.666 sec)
348.3... logprob:  0.653778, 0.359375 (0.665 sec)
348.4... logprob:  0.596734, 0.273438 (0.663 sec)
348.5... logprob:  0.590992, 0.265625 (0.665 sec)
348.6... logprob:  0.611423, 0.296875 (0.663 sec)
348.7... logprob:  0.643827, 0.343750 (0.664 sec)
348.8... logprob:  0.604829, 0.289062 (0.662 sec)
348.9... logprob:  0.638553, 0.335938 (0.665 sec)
348.10... logprob:  0.597925, 0.281250 (0.664 sec)
348.11... logprob:  0.638907, 0.335938 (0.664 sec)
348.12... logprob:  0.717927, 0.437500 (0.663 sec)
348.13... logprob:  0.657370, 0.359375 (0.664 sec)
348.14... logprob:  0.662987, 0.367188 (0.664 sec)
348.15... logprob:  0.686082, 0.398438 (0.662 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644366, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942495e-03 [7.332947e-09] 
Layer 'conv1' biases: 5.253093e-07 [2.060928e-10] 
Layer 'conv2' weights[0]: 7.930316e-03 [7.652699e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.031586e-09] 
Layer 'conv3' weights[0]: 7.928039e-03 [6.621925e-09] 
Layer 'conv3' biases: 4.395103e-06 [2.855860e-09] 
Layer 'conv4' weights[0]: 7.960825e-03 [6.677864e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.132434e-08] 
Layer 'conv5' weights[0]: 7.960198e-03 [1.225568e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.303554e-07] 
Layer 'fc6' weights[0]: 7.556401e-03 [1.357904e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.314157e-08] 
Layer 'fc7' weights[0]: 7.491739e-03 [1.682293e-07] 
Layer 'fc7' biases: 9.998540e-01 [1.556253e-07] 
Layer 'fc8' weights[0]: 6.177971e-04 [8.445041e-06] 
Layer 'fc8' biases: 1.546497e-01 [1.596174e-04] 
Train error last 27 batches: 0.635784
-------------------------------------------------------
Not saving because 0.644366 > 0.627087 (334.9: -0.00%)
======================================================= (5.048 sec)
348.16... logprob:  0.627068, 0.320312 (0.662 sec)
348.17... logprob:  0.638511, 0.335938 (0.664 sec)
348.18... logprob:  0.638224, 0.335938 (0.662 sec)
348.19... logprob:  0.632722, 0.328125 (0.664 sec)
348.20... logprob:  0.648868, 0.351562 (0.659 sec)
348.21... logprob:  0.643426, 0.343750 (0.663 sec)
348.22... logprob:  0.628019, 0.320312 (0.662 sec)
348.23... logprob:  0.623178, 0.312500 (0.663 sec)
348.24... logprob:  0.577902, 0.242188 (0.661 sec)
348.25... logprob:  0.628190, 0.320312 (0.663 sec)
348.26... logprob:  0.674053, 0.390625 (0.662 sec)
348.27... logprob:  0.628043, 0.320312 (0.663 sec)
349.1... logprob:  0.679488, 0.398438 (0.663 sec)
349.2... logprob:  0.597119, 0.273438 (0.665 sec)
349.3... logprob:  0.653779, 0.359375 (0.663 sec)
349.4... logprob:  0.596731, 0.273438 (0.664 sec)
349.5... logprob:  0.590989, 0.265625 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643605, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942429e-03 [7.427576e-09] 
Layer 'conv1' biases: 5.266663e-07 [1.389498e-10] 
Layer 'conv2' weights[0]: 7.930248e-03 [5.964575e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.503310e-10] 
Layer 'conv3' weights[0]: 7.927970e-03 [5.773095e-09] 
Layer 'conv3' biases: 4.406829e-06 [1.955281e-09] 
Layer 'conv4' weights[0]: 7.960760e-03 [5.829292e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.676595e-08] 
Layer 'conv5' weights[0]: 7.960121e-03 [9.674043e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.027808e-07] 
Layer 'fc6' weights[0]: 7.556328e-03 [1.103191e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.035329e-08] 
Layer 'fc7' weights[0]: 7.491119e-03 [1.377490e-07] 
Layer 'fc7' biases: 9.998536e-01 [1.230912e-07] 
Layer 'fc8' weights[0]: 5.958503e-04 [6.597218e-06] 
Layer 'fc8' biases: 1.543414e-01 [1.553294e-04] 
Train error last 27 batches: 0.635783
-------------------------------------------------------
Not saving because 0.643605 > 0.627087 (334.9: -0.00%)
======================================================= (5.062 sec)
349.6... logprob:  0.611423, 0.296875 (0.664 sec)
349.7... logprob:  0.643827, 0.343750 (0.662 sec)
349.8... logprob:  0.604832, 0.289062 (0.666 sec)
349.9... logprob:  0.638551, 0.335938 (0.661 sec)
349.10... logprob:  0.597931, 0.281250 (0.665 sec)
349.11... logprob:  0.638903, 0.335938 (0.661 sec)
349.12... logprob:  0.717902, 0.437500 (0.666 sec)
349.13... logprob:  0.657361, 0.359375 (0.663 sec)
349.14... logprob:  0.662977, 0.367188 (0.665 sec)
349.15... logprob:  0.686070, 0.398438 (0.662 sec)
349.16... logprob:  0.627069, 0.320312 (0.663 sec)
349.17... logprob:  0.638511, 0.335938 (0.663 sec)
349.18... logprob:  0.638223, 0.335938 (0.662 sec)
349.19... logprob:  0.632721, 0.328125 (0.663 sec)
349.20... logprob:  0.648869, 0.351562 (0.662 sec)
349.21... logprob:  0.643426, 0.343750 (0.662 sec)
349.22... logprob:  0.628017, 0.320312 (0.663 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643443, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942363e-03 [6.739551e-09] 
Layer 'conv1' biases: 5.280220e-07 [1.352450e-10] 
Layer 'conv2' weights[0]: 7.930180e-03 [6.057632e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.935780e-10] 
Layer 'conv3' weights[0]: 7.927907e-03 [5.273483e-09] 
Layer 'conv3' biases: 4.418118e-06 [1.607869e-09] 
Layer 'conv4' weights[0]: 7.960697e-03 [5.157128e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.009980e-08] 
Layer 'conv5' weights[0]: 7.960055e-03 [5.780909e-08] 
Layer 'conv5' biases: 1.000002e+00 [6.104845e-08] 
Layer 'fc6' weights[0]: 7.556262e-03 [7.416130e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.271466e-09] 
Layer 'fc7' weights[0]: 7.490505e-03 [9.335092e-08] 
Layer 'fc7' biases: 9.998535e-01 [7.553390e-08] 
Layer 'fc8' weights[0]: 5.804895e-04 [4.001474e-06] 
Layer 'fc8' biases: 1.541923e-01 [7.524969e-05] 
Train error last 27 batches: 0.635781
-------------------------------------------------------
Not saving because 0.643443 > 0.627087 (334.9: -0.00%)
======================================================= (5.084 sec)
349.23... logprob:  0.623175, 0.312500 (0.657 sec)
349.24... logprob:  0.577891, 0.242188 (0.661 sec)
349.25... logprob:  0.628187, 0.320312 (0.662 sec)
349.26... logprob:  0.674057, 0.390625 (0.664 sec)
349.27... logprob:  0.628040, 0.320312 (0.663 sec)
350.1... logprob:  0.679493, 0.398438 (0.664 sec)
350.2... logprob:  0.597113, 0.273438 (0.661 sec)
350.3... logprob:  0.653780, 0.359375 (0.663 sec)
350.4... logprob:  0.596726, 0.273438 (0.663 sec)
350.5... logprob:  0.590986, 0.265625 (0.664 sec)
350.6... logprob:  0.611422, 0.296875 (0.663 sec)
350.7... logprob:  0.643827, 0.343750 (0.665 sec)
350.8... logprob:  0.604833, 0.289062 (0.663 sec)
350.9... logprob:  0.638551, 0.335938 (0.665 sec)
350.10... logprob:  0.597934, 0.281250 (0.662 sec)
350.11... logprob:  0.638901, 0.335938 (0.664 sec)
350.12... logprob:  0.717887, 0.437500 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.645243, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942292e-03 [6.875915e-09] 
Layer 'conv1' biases: 5.286977e-07 [8.228183e-11] 
Layer 'conv2' weights[0]: 7.930114e-03 [5.253156e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.261485e-10] 
Layer 'conv3' weights[0]: 7.927838e-03 [4.560363e-09] 
Layer 'conv3' biases: 4.421399e-06 [8.164809e-10] 
Layer 'conv4' weights[0]: 7.960629e-03 [4.418075e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.768462e-09] 
Layer 'conv5' weights[0]: 7.960021e-03 [1.076963e-08] 
Layer 'conv5' biases: 1.000001e+00 [1.043406e-08] 
Layer 'fc6' weights[0]: 7.556199e-03 [3.991137e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.172232e-09] 
Layer 'fc7' weights[0]: 7.489847e-03 [4.273874e-08] 
Layer 'fc7' biases: 9.998542e-01 [1.576687e-08] 
Layer 'fc8' weights[0]: 6.315372e-04 [7.431676e-07] 
Layer 'fc8' biases: 1.556416e-01 [2.099416e-07] 
Train error last 27 batches: 0.635780
-------------------------------------------------------
Not saving because 0.645243 > 0.627087 (334.9: -0.00%)
======================================================= (5.180 sec)
350.13... logprob:  0.657356, 0.359375 (0.665 sec)
350.14... logprob:  0.662972, 0.367188 (0.663 sec)
350.15... logprob:  0.686065, 0.398438 (0.663 sec)
350.16... logprob:  0.627069, 0.320312 (0.662 sec)
350.17... logprob:  0.638510, 0.335938 (0.665 sec)
350.18... logprob:  0.638223, 0.335938 (0.662 sec)
350.19... logprob:  0.632720, 0.328125 (0.663 sec)
350.20... logprob:  0.648870, 0.351562 (0.662 sec)
350.21... logprob:  0.643427, 0.343750 (0.662 sec)
350.22... logprob:  0.628015, 0.320312 (0.662 sec)
350.23... logprob:  0.623171, 0.312500 (0.663 sec)
350.24... logprob:  0.577878, 0.242188 (0.661 sec)
350.25... logprob:  0.628185, 0.320312 (0.663 sec)
350.26... logprob:  0.674062, 0.390625 (0.661 sec)
350.27... logprob:  0.628039, 0.320312 (0.664 sec)
351.1... logprob:  0.679497, 0.398438 (0.664 sec)
351.2... logprob:  0.597107, 0.273438 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643468, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942229e-03 [6.833301e-09] 
Layer 'conv1' biases: 5.303070e-07 [7.154181e-11] 
Layer 'conv2' weights[0]: 7.930052e-03 [4.982037e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.901306e-10] 
Layer 'conv3' weights[0]: 7.927770e-03 [4.563474e-09] 
Layer 'conv3' biases: 4.436029e-06 [8.125952e-10] 
Layer 'conv4' weights[0]: 7.960555e-03 [4.476910e-09] 
Layer 'conv4' biases: 1.000001e+00 [4.916846e-09] 
Layer 'conv5' weights[0]: 7.959925e-03 [2.885562e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.025562e-08] 
Layer 'fc6' weights[0]: 7.556128e-03 [4.978453e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.021422e-09] 
Layer 'fc7' weights[0]: 7.489249e-03 [5.918168e-08] 
Layer 'fc7' biases: 9.998535e-01 [3.613123e-08] 
Layer 'fc8' weights[0]: 5.854098e-04 [1.910110e-06] 
Layer 'fc8' biases: 1.547654e-01 [5.240266e-05] 
Train error last 27 batches: 0.635778
-------------------------------------------------------
Not saving because 0.643468 > 0.627087 (334.9: -0.00%)
======================================================= (5.129 sec)
351.3... logprob:  0.653781, 0.359375 (0.663 sec)
351.4... logprob:  0.596722, 0.273438 (0.664 sec)
351.5... logprob:  0.590983, 0.265625 (0.660 sec)
351.6... logprob:  0.611422, 0.296875 (0.665 sec)
351.7... logprob:  0.643827, 0.343750 (0.663 sec)
351.8... logprob:  0.604835, 0.289062 (0.665 sec)
351.9... logprob:  0.638549, 0.335938 (0.664 sec)
351.10... logprob:  0.597939, 0.281250 (0.664 sec)
351.11... logprob:  0.638898, 0.335938 (0.664 sec)
351.12... logprob:  0.717867, 0.437500 (0.664 sec)
351.13... logprob:  0.657350, 0.359375 (0.663 sec)
351.14... logprob:  0.662966, 0.367188 (0.665 sec)
351.15... logprob:  0.686058, 0.398438 (0.661 sec)
351.16... logprob:  0.627069, 0.320312 (0.664 sec)
351.17... logprob:  0.638511, 0.335938 (0.663 sec)
351.18... logprob:  0.638223, 0.335938 (0.663 sec)
351.19... logprob:  0.632719, 0.328125 (0.662 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643570, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942167e-03 [6.765278e-09] 
Layer 'conv1' biases: 5.314306e-07 [1.577166e-10] 
Layer 'conv2' weights[0]: 7.929985e-03 [6.604789e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.661357e-10] 
Layer 'conv3' weights[0]: 7.927707e-03 [5.737294e-09] 
Layer 'conv3' biases: 4.444723e-06 [2.091327e-09] 
Layer 'conv4' weights[0]: 7.960491e-03 [5.679749e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.444420e-08] 
Layer 'conv5' weights[0]: 7.959859e-03 [8.269374e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.763623e-08] 
Layer 'fc6' weights[0]: 7.556061e-03 [9.854438e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.929784e-09] 
Layer 'fc7' weights[0]: 7.488600e-03 [1.229232e-07] 
Layer 'fc7' biases: 9.998537e-01 [1.067080e-07] 
Layer 'fc8' weights[0]: 5.931284e-04 [5.700293e-06] 
Layer 'fc8' biases: 1.551874e-01 [1.088643e-04] 
Train error last 27 batches: 0.635777
-------------------------------------------------------
Not saving because 0.643570 > 0.627087 (334.9: -0.00%)
======================================================= (5.073 sec)
351.20... logprob:  0.648871, 0.351562 (0.662 sec)
351.21... logprob:  0.643427, 0.343750 (0.661 sec)
351.22... logprob:  0.628011, 0.320312 (0.659 sec)
351.23... logprob:  0.623167, 0.312500 (0.659 sec)
351.24... logprob:  0.577861, 0.242188 (0.662 sec)
351.25... logprob:  0.628181, 0.320312 (0.662 sec)
351.26... logprob:  0.674068, 0.390625 (0.663 sec)
351.27... logprob:  0.628035, 0.320312 (0.663 sec)
352.1... logprob:  0.679503, 0.398438 (0.662 sec)
352.2... logprob:  0.597101, 0.273438 (0.663 sec)
352.3... logprob:  0.653783, 0.359375 (0.664 sec)
352.4... logprob:  0.596719, 0.273438 (0.663 sec)
352.5... logprob:  0.590982, 0.265625 (0.663 sec)
352.6... logprob:  0.611422, 0.296875 (0.663 sec)
352.7... logprob:  0.643826, 0.343750 (0.664 sec)
352.8... logprob:  0.604839, 0.289062 (0.665 sec)
352.9... logprob:  0.638548, 0.335938 (0.665 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644509, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942097e-03 [6.683111e-09] 
Layer 'conv1' biases: 5.323334e-07 [1.196360e-10] 
Layer 'conv2' weights[0]: 7.929918e-03 [5.815702e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.034600e-10] 
Layer 'conv3' weights[0]: 7.927646e-03 [5.666342e-09] 
Layer 'conv3' biases: 4.450877e-06 [1.857390e-09] 
Layer 'conv4' weights[0]: 7.960432e-03 [5.779868e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.600429e-08] 
Layer 'conv5' weights[0]: 7.959817e-03 [9.172674e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.738648e-08] 
Layer 'fc6' weights[0]: 7.555990e-03 [1.057675e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.820565e-09] 
Layer 'fc7' weights[0]: 7.487912e-03 [1.314062e-07] 
Layer 'fc7' biases: 9.998539e-01 [1.159178e-07] 
Layer 'fc8' weights[0]: 6.192728e-04 [6.247145e-06] 
Layer 'fc8' biases: 1.560308e-01 [1.444265e-04] 
Train error last 27 batches: 0.635776
-------------------------------------------------------
Not saving because 0.644509 > 0.627087 (334.9: -0.00%)
======================================================= (5.064 sec)
352.10... logprob:  0.597945, 0.281250 (0.664 sec)
352.11... logprob:  0.638894, 0.335938 (0.665 sec)
352.12... logprob:  0.717842, 0.437500 (0.663 sec)
352.13... logprob:  0.657342, 0.359375 (0.664 sec)
352.14... logprob:  0.662957, 0.367188 (0.663 sec)
352.15... logprob:  0.686047, 0.398438 (0.663 sec)
352.16... logprob:  0.627069, 0.320312 (0.664 sec)
352.17... logprob:  0.638510, 0.335938 (0.664 sec)
352.18... logprob:  0.638223, 0.335938 (0.662 sec)
352.19... logprob:  0.632719, 0.328125 (0.663 sec)
352.20... logprob:  0.648872, 0.351562 (0.661 sec)
352.21... logprob:  0.643427, 0.343750 (0.663 sec)
352.22... logprob:  0.628008, 0.320312 (0.665 sec)
352.23... logprob:  0.623162, 0.312500 (0.663 sec)
352.24... logprob:  0.577846, 0.242188 (0.662 sec)
352.25... logprob:  0.628177, 0.320312 (0.664 sec)
352.26... logprob:  0.674074, 0.390625 (0.660 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643455, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.942026e-03 [6.506288e-09] 
Layer 'conv1' biases: 5.338746e-07 [7.006002e-11] 
Layer 'conv2' weights[0]: 7.929853e-03 [5.007851e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.443123e-10] 
Layer 'conv3' weights[0]: 7.927584e-03 [4.417096e-09] 
Layer 'conv3' biases: 4.464477e-06 [6.175453e-10] 
Layer 'conv4' weights[0]: 7.960371e-03 [4.317943e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.722510e-09] 
Layer 'conv5' weights[0]: 7.959732e-03 [1.082014e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.063493e-08] 
Layer 'fc6' weights[0]: 7.555923e-03 [3.962957e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.057999e-09] 
Layer 'fc7' weights[0]: 7.487304e-03 [4.146339e-08] 
Layer 'fc7' biases: 9.998534e-01 [1.290836e-08] 
Layer 'fc8' weights[0]: 5.828245e-04 [6.513821e-07] 
Layer 'fc8' biases: 1.553823e-01 [2.664707e-05] 
Train error last 27 batches: 0.635773
-------------------------------------------------------
Not saving because 0.643455 > 0.627087 (334.9: -0.00%)
======================================================= (5.184 sec)
352.27... logprob:  0.628033, 0.320312 (0.662 sec)
353.1... logprob:  0.679509, 0.398438 (0.659 sec)
353.2... logprob:  0.597094, 0.273438 (0.664 sec)
353.3... logprob:  0.653783, 0.359375 (0.663 sec)
353.4... logprob:  0.596714, 0.273438 (0.665 sec)
353.5... logprob:  0.590978, 0.265625 (0.663 sec)
353.6... logprob:  0.611422, 0.296875 (0.664 sec)
353.7... logprob:  0.643826, 0.343750 (0.663 sec)
353.8... logprob:  0.604841, 0.289062 (0.665 sec)
353.9... logprob:  0.638547, 0.335938 (0.661 sec)
353.10... logprob:  0.597950, 0.281250 (0.662 sec)
353.11... logprob:  0.638892, 0.335938 (0.664 sec)
353.12... logprob:  0.717821, 0.437500 (0.664 sec)
353.13... logprob:  0.657334, 0.359375 (0.663 sec)
353.14... logprob:  0.662950, 0.367188 (0.667 sec)
353.15... logprob:  0.686039, 0.398438 (0.665 sec)
353.16... logprob:  0.627069, 0.320312 (0.666 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644064, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941958e-03 [6.945506e-09] 
Layer 'conv1' biases: 5.348199e-07 [1.860885e-10] 
Layer 'conv2' weights[0]: 7.929790e-03 [7.234783e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.381094e-10] 
Layer 'conv3' weights[0]: 7.927523e-03 [6.284824e-09] 
Layer 'conv3' biases: 4.470970e-06 [2.573110e-09] 
Layer 'conv4' weights[0]: 7.960308e-03 [6.301337e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.872539e-08] 
Layer 'conv5' weights[0]: 7.959679e-03 [1.071554e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.138223e-07] 
Layer 'fc6' weights[0]: 7.555861e-03 [1.205573e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.152317e-08] 
Layer 'fc7' weights[0]: 7.486653e-03 [1.499160e-07] 
Layer 'fc7' biases: 9.998538e-01 [1.364661e-07] 
Layer 'fc8' weights[0]: 6.094633e-04 [7.351629e-06] 
Layer 'fc8' biases: 1.562543e-01 [1.398757e-04] 
Train error last 27 batches: 0.635771
-------------------------------------------------------
Not saving because 0.644064 > 0.627087 (334.9: -0.00%)
======================================================= (5.062 sec)
353.17... logprob:  0.638510, 0.335938 (0.665 sec)
353.18... logprob:  0.638222, 0.335938 (0.664 sec)
353.19... logprob:  0.632718, 0.328125 (0.665 sec)
353.20... logprob:  0.648873, 0.351562 (0.665 sec)
353.21... logprob:  0.643428, 0.343750 (0.665 sec)
353.22... logprob:  0.628006, 0.320312 (0.666 sec)
353.23... logprob:  0.623158, 0.312500 (0.665 sec)
353.24... logprob:  0.577832, 0.242188 (0.666 sec)
353.25... logprob:  0.628174, 0.320312 (0.665 sec)
353.26... logprob:  0.674079, 0.390625 (0.663 sec)
353.27... logprob:  0.628031, 0.320312 (0.666 sec)
354.1... logprob:  0.679514, 0.398438 (0.664 sec)
354.2... logprob:  0.597089, 0.273438 (0.666 sec)
354.3... logprob:  0.653785, 0.359375 (0.667 sec)
354.4... logprob:  0.596710, 0.273438 (0.666 sec)
354.5... logprob:  0.590975, 0.265625 (0.666 sec)
354.6... logprob:  0.611422, 0.296875 (0.666 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643769, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941895e-03 [7.340346e-09] 
Layer 'conv1' biases: 5.360512e-07 [1.637642e-10] 
Layer 'conv2' weights[0]: 7.929730e-03 [6.289570e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.710485e-10] 
Layer 'conv3' weights[0]: 7.927454e-03 [6.084581e-09] 
Layer 'conv3' biases: 4.481182e-06 [2.238380e-09] 
Layer 'conv4' weights[0]: 7.960241e-03 [6.167505e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.952138e-08] 
Layer 'conv5' weights[0]: 7.959614e-03 [1.118848e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.187447e-07] 
Layer 'fc6' weights[0]: 7.555800e-03 [1.252384e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.197977e-08] 
Layer 'fc7' weights[0]: 7.485991e-03 [1.556077e-07] 
Layer 'fc7' biases: 9.998537e-01 [1.421219e-07] 
Layer 'fc8' weights[0]: 6.008315e-04 [7.599071e-06] 
Layer 'fc8' biases: 1.562606e-01 [1.774731e-04] 
Train error last 27 batches: 0.635770
-------------------------------------------------------
Not saving because 0.643769 > 0.627087 (334.9: -0.00%)
======================================================= (5.060 sec)
354.7... logprob:  0.643826, 0.343750 (0.666 sec)
354.8... logprob:  0.604843, 0.289062 (0.666 sec)
354.9... logprob:  0.638545, 0.335938 (0.668 sec)
354.10... logprob:  0.597955, 0.281250 (0.665 sec)
354.11... logprob:  0.638889, 0.335938 (0.668 sec)
354.12... logprob:  0.717799, 0.437500 (0.666 sec)
354.13... logprob:  0.657327, 0.359375 (0.666 sec)
354.14... logprob:  0.662943, 0.367188 (0.665 sec)
354.15... logprob:  0.686030, 0.398438 (0.665 sec)
354.16... logprob:  0.627070, 0.320312 (0.662 sec)
354.17... logprob:  0.638510, 0.335938 (0.667 sec)
354.18... logprob:  0.638222, 0.335938 (0.665 sec)
354.19... logprob:  0.632718, 0.328125 (0.666 sec)
354.20... logprob:  0.648874, 0.351562 (0.664 sec)
354.21... logprob:  0.643428, 0.343750 (0.663 sec)
354.22... logprob:  0.628003, 0.320312 (0.665 sec)
354.23... logprob:  0.623153, 0.312500 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643442, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941824e-03 [6.342988e-09] 
Layer 'conv1' biases: 5.374851e-07 [1.063227e-10] 
Layer 'conv2' weights[0]: 7.929676e-03 [5.344097e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.163386e-10] 
Layer 'conv3' weights[0]: 7.927384e-03 [4.742375e-09] 
Layer 'conv3' biases: 4.493355e-06 [1.084223e-09] 
Layer 'conv4' weights[0]: 7.960181e-03 [4.616797e-09] 
Layer 'conv4' biases: 1.000001e+00 [5.692856e-09] 
Layer 'conv5' weights[0]: 7.959546e-03 [3.267971e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.433630e-08] 
Layer 'fc6' weights[0]: 7.555731e-03 [5.275369e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.558997e-09] 
Layer 'fc7' weights[0]: 7.485358e-03 [6.432104e-08] 
Layer 'fc7' biases: 9.998534e-01 [4.310182e-08] 
Layer 'fc8' weights[0]: 5.771242e-04 [2.267184e-06] 
Layer 'fc8' biases: 1.558989e-01 [3.732920e-05] 
Train error last 27 batches: 0.635768
-------------------------------------------------------
Not saving because 0.643442 > 0.627087 (334.9: -0.00%)
======================================================= (5.124 sec)
354.24... logprob:  0.577816, 0.242188 (0.664 sec)
354.25... logprob:  0.628172, 0.320312 (0.666 sec)
354.26... logprob:  0.674084, 0.390625 (0.664 sec)
354.27... logprob:  0.628028, 0.320312 (0.667 sec)
355.1... logprob:  0.679519, 0.398438 (0.667 sec)
355.2... logprob:  0.597082, 0.273438 (0.666 sec)
355.3... logprob:  0.653786, 0.359375 (0.666 sec)
355.4... logprob:  0.596707, 0.273438 (0.667 sec)
355.5... logprob:  0.590973, 0.265625 (0.664 sec)
355.6... logprob:  0.611421, 0.296875 (0.667 sec)
355.7... logprob:  0.643824, 0.343750 (0.666 sec)
355.8... logprob:  0.604846, 0.289062 (0.668 sec)
355.9... logprob:  0.638544, 0.335938 (0.667 sec)
355.10... logprob:  0.597960, 0.281250 (0.671 sec)
355.11... logprob:  0.638886, 0.335938 (0.664 sec)
355.12... logprob:  0.717778, 0.437500 (0.666 sec)
355.13... logprob:  0.657320, 0.359375 (0.667 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.645047, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941748e-03 [6.528417e-09] 
Layer 'conv1' biases: 5.381723e-07 [1.014672e-10] 
Layer 'conv2' weights[0]: 7.929614e-03 [5.459820e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.668513e-10] 
Layer 'conv3' weights[0]: 7.927322e-03 [4.794881e-09] 
Layer 'conv3' biases: 4.496848e-06 [1.275423e-09] 
Layer 'conv4' weights[0]: 7.960115e-03 [4.708192e-09] 
Layer 'conv4' biases: 1.000001e+00 [7.111503e-09] 
Layer 'conv5' weights[0]: 7.959486e-03 [4.071597e-08] 
Layer 'conv5' biases: 1.000002e+00 [4.302022e-08] 
Layer 'fc6' weights[0]: 7.555667e-03 [5.815857e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.338402e-09] 
Layer 'fc7' weights[0]: 7.484694e-03 [7.229163e-08] 
Layer 'fc7' biases: 9.998541e-01 [5.212647e-08] 
Layer 'fc8' weights[0]: 6.270117e-04 [2.793113e-06] 
Layer 'fc8' biases: 1.573354e-01 [4.306639e-05] 
Train error last 27 batches: 0.635767
-------------------------------------------------------
Not saving because 0.645047 > 0.627087 (334.9: -0.00%)
======================================================= (5.118 sec)
355.14... logprob:  0.662936, 0.367188 (0.667 sec)
355.15... logprob:  0.686022, 0.398438 (0.664 sec)
355.16... logprob:  0.627070, 0.320312 (0.666 sec)
355.17... logprob:  0.638511, 0.335938 (0.667 sec)
355.18... logprob:  0.638223, 0.335938 (0.665 sec)
355.19... logprob:  0.632718, 0.328125 (0.664 sec)
355.20... logprob:  0.648876, 0.351562 (0.666 sec)
355.21... logprob:  0.643428, 0.343750 (0.664 sec)
355.22... logprob:  0.628000, 0.320312 (0.668 sec)
355.23... logprob:  0.623149, 0.312500 (0.670 sec)
355.24... logprob:  0.577799, 0.242188 (0.664 sec)
355.25... logprob:  0.628168, 0.320312 (0.663 sec)
355.26... logprob:  0.674091, 0.390625 (0.667 sec)
355.27... logprob:  0.628025, 0.320312 (0.664 sec)
356.1... logprob:  0.679525, 0.398438 (0.663 sec)
356.2... logprob:  0.597076, 0.273438 (0.663 sec)
356.3... logprob:  0.653788, 0.359375 (0.669 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643474, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941684e-03 [6.712833e-09] 
Layer 'conv1' biases: 5.397477e-07 [6.485531e-11] 
Layer 'conv2' weights[0]: 7.929560e-03 [4.979383e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.555822e-10] 
Layer 'conv3' weights[0]: 7.927257e-03 [4.455137e-09] 
Layer 'conv3' biases: 4.511039e-06 [6.461447e-10] 
Layer 'conv4' weights[0]: 7.960044e-03 [4.339482e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.188597e-09] 
Layer 'conv5' weights[0]: 7.959407e-03 [1.366548e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.387638e-08] 
Layer 'fc6' weights[0]: 7.555607e-03 [4.077991e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.371853e-09] 
Layer 'fc7' weights[0]: 7.484100e-03 [4.380228e-08] 
Layer 'fc7' biases: 9.998534e-01 [1.658548e-08] 
Layer 'fc8' weights[0]: 5.845927e-04 [8.745483e-07] 
Layer 'fc8' biases: 1.565297e-01 [2.733242e-05] 
Train error last 27 batches: 0.635765
-------------------------------------------------------
Not saving because 0.643474 > 0.627087 (334.9: -0.00%)
======================================================= (5.177 sec)
356.4... logprob:  0.596703, 0.273438 (0.662 sec)
356.5... logprob:  0.590971, 0.265625 (0.661 sec)
356.6... logprob:  0.611422, 0.296875 (0.660 sec)
356.7... logprob:  0.643824, 0.343750 (0.664 sec)
356.8... logprob:  0.604850, 0.289062 (0.665 sec)
356.9... logprob:  0.638543, 0.335938 (0.664 sec)
356.10... logprob:  0.597967, 0.281250 (0.664 sec)
356.11... logprob:  0.638882, 0.335938 (0.664 sec)
356.12... logprob:  0.717750, 0.437500 (0.664 sec)
356.13... logprob:  0.657310, 0.359375 (0.662 sec)
356.14... logprob:  0.662927, 0.367188 (0.663 sec)
356.15... logprob:  0.686010, 0.398438 (0.662 sec)
356.16... logprob:  0.627070, 0.320312 (0.662 sec)
356.17... logprob:  0.638510, 0.335938 (0.664 sec)
356.18... logprob:  0.638222, 0.335938 (0.663 sec)
356.19... logprob:  0.632717, 0.328125 (0.658 sec)
356.20... logprob:  0.648877, 0.351562 (0.663 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643498, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941627e-03 [6.810105e-09] 
Layer 'conv1' biases: 5.409201e-07 [1.626530e-10] 
Layer 'conv2' weights[0]: 7.929490e-03 [6.540571e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.758288e-10] 
Layer 'conv3' weights[0]: 7.927182e-03 [5.724021e-09] 
Layer 'conv3' biases: 4.520383e-06 [2.106208e-09] 
Layer 'conv4' weights[0]: 7.959971e-03 [5.657162e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.467646e-08] 
Layer 'conv5' weights[0]: 7.959343e-03 [8.374463e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.866432e-08] 
Layer 'fc6' weights[0]: 7.555538e-03 [9.954537e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.073210e-09] 
Layer 'fc7' weights[0]: 7.483450e-03 [1.243678e-07] 
Layer 'fc7' biases: 9.998534e-01 [1.084365e-07] 
Layer 'fc8' weights[0]: 5.865776e-04 [5.764407e-06] 
Layer 'fc8' biases: 1.568119e-01 [1.130814e-04] 
Train error last 27 batches: 0.635763
-------------------------------------------------------
Not saving because 0.643498 > 0.627087 (334.9: -0.00%)
======================================================= (5.065 sec)
356.21... logprob:  0.643429, 0.343750 (0.661 sec)
356.22... logprob:  0.627997, 0.320312 (0.662 sec)
356.23... logprob:  0.623144, 0.312500 (0.663 sec)
356.24... logprob:  0.577784, 0.242188 (0.660 sec)
356.25... logprob:  0.628164, 0.320312 (0.663 sec)
356.26... logprob:  0.674098, 0.390625 (0.662 sec)
356.27... logprob:  0.628023, 0.320312 (0.664 sec)
357.1... logprob:  0.679532, 0.398438 (0.663 sec)
357.2... logprob:  0.597068, 0.273438 (0.659 sec)
357.3... logprob:  0.653790, 0.359375 (0.664 sec)
357.4... logprob:  0.596697, 0.273438 (0.664 sec)
357.5... logprob:  0.590966, 0.265625 (0.663 sec)
357.6... logprob:  0.611421, 0.296875 (0.663 sec)
357.7... logprob:  0.643824, 0.343750 (0.664 sec)
357.8... logprob:  0.604851, 0.289062 (0.663 sec)
357.9... logprob:  0.638542, 0.335938 (0.666 sec)
357.10... logprob:  0.597970, 0.281250 (0.665 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644891, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941557e-03 [7.030807e-09] 
Layer 'conv1' biases: 5.417218e-07 [1.442028e-10] 
Layer 'conv2' weights[0]: 7.929425e-03 [6.261066e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.430666e-10] 
Layer 'conv3' weights[0]: 7.927111e-03 [6.095640e-09] 
Layer 'conv3' biases: 4.525144e-06 [2.228493e-09] 
Layer 'conv4' weights[0]: 7.959904e-03 [6.263423e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.945482e-08] 
Layer 'conv5' weights[0]: 7.959292e-03 [1.111936e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.181049e-07] 
Layer 'fc6' weights[0]: 7.555475e-03 [1.241913e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.188600e-08] 
Layer 'fc7' weights[0]: 7.482783e-03 [1.529670e-07] 
Layer 'fc7' biases: 9.998540e-01 [1.393048e-07] 
Layer 'fc8' weights[0]: 6.240112e-04 [7.531085e-06] 
Layer 'fc8' biases: 1.579321e-01 [1.706765e-04] 
Train error last 27 batches: 0.635762
-------------------------------------------------------
Not saving because 0.644891 > 0.627087 (334.9: -0.00%)
======================================================= (5.072 sec)
357.11... logprob:  0.638880, 0.335938 (0.668 sec)
357.12... logprob:  0.717732, 0.437500 (0.666 sec)
357.13... logprob:  0.657305, 0.359375 (0.667 sec)
357.14... logprob:  0.662920, 0.367188 (0.665 sec)
357.15... logprob:  0.686002, 0.398438 (0.663 sec)
357.16... logprob:  0.627071, 0.320312 (0.665 sec)
357.17... logprob:  0.638510, 0.335938 (0.666 sec)
357.18... logprob:  0.638223, 0.335938 (0.666 sec)
357.19... logprob:  0.632717, 0.328125 (0.666 sec)
357.20... logprob:  0.648878, 0.351562 (0.666 sec)
357.21... logprob:  0.643430, 0.343750 (0.662 sec)
357.22... logprob:  0.627995, 0.320312 (0.666 sec)
357.23... logprob:  0.623140, 0.312500 (0.666 sec)
357.24... logprob:  0.577771, 0.242188 (0.664 sec)
357.25... logprob:  0.628162, 0.320312 (0.666 sec)
357.26... logprob:  0.674102, 0.390625 (0.663 sec)
357.27... logprob:  0.628020, 0.320312 (0.666 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643464, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941494e-03 [6.614637e-09] 
Layer 'conv1' biases: 5.433044e-07 [6.983473e-11] 
Layer 'conv2' weights[0]: 7.929352e-03 [4.903378e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.618371e-10] 
Layer 'conv3' weights[0]: 7.927044e-03 [4.460854e-09] 
Layer 'conv3' biases: 4.539321e-06 [7.143407e-10] 
Layer 'conv4' weights[0]: 7.959848e-03 [4.390342e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.916797e-09] 
Layer 'conv5' weights[0]: 7.959214e-03 [2.258147e-08] 
Layer 'conv5' biases: 1.000002e+00 [2.350297e-08] 
Layer 'fc6' weights[0]: 7.555411e-03 [4.567227e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.333261e-09] 
Layer 'fc7' weights[0]: 7.482146e-03 [5.227113e-08] 
Layer 'fc7' biases: 9.998533e-01 [2.799140e-08] 
Layer 'fc8' weights[0]: 5.826203e-04 [1.456170e-06] 
Layer 'fc8' biases: 1.571599e-01 [4.435138e-05] 
Train error last 27 batches: 0.635760
-------------------------------------------------------
Not saving because 0.643464 > 0.627087 (334.9: -0.00%)
======================================================= (5.153 sec)
358.1... logprob:  0.679536, 0.398438 (0.667 sec)
358.2... logprob:  0.597064, 0.273438 (0.667 sec)
358.3... logprob:  0.653790, 0.359375 (0.667 sec)
358.4... logprob:  0.596694, 0.273438 (0.667 sec)
358.5... logprob:  0.590966, 0.265625 (0.665 sec)
358.6... logprob:  0.611421, 0.296875 (0.664 sec)
358.7... logprob:  0.643823, 0.343750 (0.662 sec)
358.8... logprob:  0.604854, 0.289062 (0.665 sec)
358.9... logprob:  0.638540, 0.335938 (0.665 sec)
358.10... logprob:  0.597977, 0.281250 (0.665 sec)
358.11... logprob:  0.638877, 0.335938 (0.663 sec)
358.12... logprob:  0.717709, 0.437500 (0.663 sec)
358.13... logprob:  0.657297, 0.359375 (0.664 sec)
358.14... logprob:  0.662913, 0.367188 (0.664 sec)
358.15... logprob:  0.685992, 0.398438 (0.663 sec)
358.16... logprob:  0.627070, 0.320312 (0.663 sec)
358.17... logprob:  0.638510, 0.335938 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643839, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941419e-03 [6.439347e-09] 
Layer 'conv1' biases: 5.442970e-07 [1.715645e-10] 
Layer 'conv2' weights[0]: 7.929292e-03 [6.899709e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.774918e-10] 
Layer 'conv3' weights[0]: 7.926980e-03 [6.053941e-09] 
Layer 'conv3' biases: 4.546718e-06 [2.384275e-09] 
Layer 'conv4' weights[0]: 7.959786e-03 [6.094927e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.776075e-08] 
Layer 'conv5' weights[0]: 7.959153e-03 [1.015727e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.077356e-07] 
Layer 'fc6' weights[0]: 7.555345e-03 [1.151541e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.092985e-08] 
Layer 'fc7' weights[0]: 7.481508e-03 [1.432126e-07] 
Layer 'fc7' biases: 9.998537e-01 [1.293449e-07] 
Layer 'fc8' weights[0]: 6.015980e-04 [6.945753e-06] 
Layer 'fc8' biases: 1.578505e-01 [1.340821e-04] 
Train error last 27 batches: 0.635758
-------------------------------------------------------
Not saving because 0.643839 > 0.627087 (334.9: -0.00%)
======================================================= (5.054 sec)
358.18... logprob:  0.638222, 0.335938 (0.661 sec)
358.19... logprob:  0.632716, 0.328125 (0.663 sec)
358.20... logprob:  0.648878, 0.351562 (0.662 sec)
358.21... logprob:  0.643430, 0.343750 (0.668 sec)
358.22... logprob:  0.627993, 0.320312 (0.663 sec)
358.23... logprob:  0.623137, 0.312500 (0.663 sec)
358.24... logprob:  0.577757, 0.242188 (0.663 sec)
358.25... logprob:  0.628159, 0.320312 (0.663 sec)
358.26... logprob:  0.674108, 0.390625 (0.663 sec)
358.27... logprob:  0.628018, 0.320312 (0.664 sec)
359.1... logprob:  0.679542, 0.398438 (0.661 sec)
359.2... logprob:  0.597056, 0.273438 (0.664 sec)
359.3... logprob:  0.653792, 0.359375 (0.665 sec)
359.4... logprob:  0.596689, 0.273438 (0.663 sec)
359.5... logprob:  0.590961, 0.265625 (0.664 sec)
359.6... logprob:  0.611420, 0.296875 (0.664 sec)
359.7... logprob:  0.643823, 0.343750 (0.663 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643947, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941344e-03 [6.814337e-09] 
Layer 'conv1' biases: 5.454080e-07 [1.275089e-10] 
Layer 'conv2' weights[0]: 7.929223e-03 [5.816983e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.176478e-10] 
Layer 'conv3' weights[0]: 7.926917e-03 [5.633624e-09] 
Layer 'conv3' biases: 4.555700e-06 [1.872269e-09] 
Layer 'conv4' weights[0]: 7.959730e-03 [5.708366e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.605167e-08] 
Layer 'conv5' weights[0]: 7.959087e-03 [9.208689e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.764586e-08] 
Layer 'fc6' weights[0]: 7.555277e-03 [1.059255e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.841321e-09] 
Layer 'fc7' weights[0]: 7.480882e-03 [1.317342e-07] 
Layer 'fc7' biases: 9.998538e-01 [1.164722e-07] 
Layer 'fc8' weights[0]: 6.045474e-04 [6.206770e-06] 
Layer 'fc8' biases: 1.581339e-01 [1.470859e-04] 
Train error last 27 batches: 0.635757
-------------------------------------------------------
Not saving because 0.643947 > 0.627087 (334.9: -0.00%)
======================================================= (5.079 sec)
359.8... logprob:  0.604855, 0.289062 (0.665 sec)
359.9... logprob:  0.638540, 0.335938 (0.663 sec)
359.10... logprob:  0.597980, 0.281250 (0.665 sec)
359.11... logprob:  0.638875, 0.335938 (0.664 sec)
359.12... logprob:  0.717691, 0.437500 (0.664 sec)
359.13... logprob:  0.657290, 0.359375 (0.664 sec)
359.14... logprob:  0.662907, 0.367188 (0.665 sec)
359.15... logprob:  0.685986, 0.398438 (0.660 sec)
359.16... logprob:  0.627071, 0.320312 (0.662 sec)
359.17... logprob:  0.638510, 0.335938 (0.664 sec)
359.18... logprob:  0.638222, 0.335938 (0.663 sec)
359.19... logprob:  0.632715, 0.328125 (0.663 sec)
359.20... logprob:  0.648880, 0.351562 (0.663 sec)
359.21... logprob:  0.643430, 0.343750 (0.662 sec)
359.22... logprob:  0.627989, 0.320312 (0.660 sec)
359.23... logprob:  0.623132, 0.312500 (0.662 sec)
359.24... logprob:  0.577743, 0.242188 (0.663 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643443, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941277e-03 [6.499610e-09] 
Layer 'conv1' biases: 5.468782e-07 [5.965010e-11] 
Layer 'conv2' weights[0]: 7.929160e-03 [4.865933e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.034047e-10] 
Layer 'conv3' weights[0]: 7.926851e-03 [4.532151e-09] 
Layer 'conv3' biases: 4.568275e-06 [8.548910e-10] 
Layer 'conv4' weights[0]: 7.959664e-03 [4.476922e-09] 
Layer 'conv4' biases: 1.000001e+00 [6.169493e-09] 
Layer 'conv5' weights[0]: 7.959023e-03 [3.465521e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.640993e-08] 
Layer 'fc6' weights[0]: 7.555201e-03 [5.375650e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.677302e-09] 
Layer 'fc7' weights[0]: 7.480218e-03 [6.529503e-08] 
Layer 'fc7' biases: 9.998532e-01 [4.397689e-08] 
Layer 'fc8' weights[0]: 5.776855e-04 [2.287991e-06] 
Layer 'fc8' biases: 1.576957e-01 [6.781011e-05] 
Train error last 27 batches: 0.635755
-------------------------------------------------------
Not saving because 0.643443 > 0.627087 (334.9: -0.00%)
======================================================= (5.122 sec)
359.25... logprob:  0.628156, 0.320312 (0.663 sec)
359.26... logprob:  0.674112, 0.390625 (0.663 sec)
359.27... logprob:  0.628016, 0.320312 (0.664 sec)
360.1... logprob:  0.679546, 0.398438 (0.664 sec)
360.2... logprob:  0.597051, 0.273438 (0.662 sec)
360.3... logprob:  0.653793, 0.359375 (0.664 sec)
360.4... logprob:  0.596686, 0.273438 (0.661 sec)
360.5... logprob:  0.590959, 0.265625 (0.664 sec)
360.6... logprob:  0.611420, 0.296875 (0.663 sec)
360.7... logprob:  0.643823, 0.343750 (0.664 sec)
360.8... logprob:  0.604858, 0.289062 (0.662 sec)
360.9... logprob:  0.638539, 0.335938 (0.667 sec)
360.10... logprob:  0.597986, 0.281250 (0.664 sec)
360.11... logprob:  0.638872, 0.335938 (0.665 sec)
360.12... logprob:  0.717667, 0.437500 (0.664 sec)
360.13... logprob:  0.657283, 0.359375 (0.662 sec)
360.14... logprob:  0.662898, 0.367188 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644750, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941214e-03 [6.745215e-09] 
Layer 'conv1' biases: 5.476375e-07 [1.515894e-10] 
Layer 'conv2' weights[0]: 7.929096e-03 [6.253936e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.821984e-10] 
Layer 'conv3' weights[0]: 7.926786e-03 [5.458912e-09] 
Layer 'conv3' biases: 4.572639e-06 [1.883650e-09] 
Layer 'conv4' weights[0]: 7.959597e-03 [5.417004e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.255098e-08] 
Layer 'conv5' weights[0]: 7.958964e-03 [7.201741e-08] 
Layer 'conv5' biases: 1.000002e+00 [7.639209e-08] 
Layer 'fc6' weights[0]: 7.555141e-03 [8.714799e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.705059e-09] 
Layer 'fc7' weights[0]: 7.479526e-03 [1.085714e-07] 
Layer 'fc7' biases: 9.998538e-01 [9.120684e-08] 
Layer 'fc8' weights[0]: 6.207002e-04 [4.897616e-06] 
Layer 'fc8' biases: 1.589699e-01 [8.823385e-05] 
Train error last 27 batches: 0.635753
-------------------------------------------------------
Not saving because 0.644750 > 0.627087 (334.9: -0.00%)
======================================================= (5.078 sec)
360.15... logprob:  0.685976, 0.398438 (0.662 sec)
360.16... logprob:  0.627070, 0.320312 (0.660 sec)
360.17... logprob:  0.638510, 0.335938 (0.664 sec)
360.18... logprob:  0.638223, 0.335938 (0.661 sec)
360.19... logprob:  0.632716, 0.328125 (0.663 sec)
360.20... logprob:  0.648881, 0.351562 (0.663 sec)
360.21... logprob:  0.643431, 0.343750 (0.662 sec)
360.22... logprob:  0.627987, 0.320312 (0.661 sec)
360.23... logprob:  0.623127, 0.312500 (0.659 sec)
360.24... logprob:  0.577725, 0.242188 (0.662 sec)
360.25... logprob:  0.628152, 0.320312 (0.663 sec)
360.26... logprob:  0.674119, 0.390625 (0.663 sec)
360.27... logprob:  0.628014, 0.320312 (0.663 sec)
361.1... logprob:  0.679553, 0.398438 (0.664 sec)
361.2... logprob:  0.597044, 0.273438 (0.664 sec)
361.3... logprob:  0.653795, 0.359375 (0.664 sec)
361.4... logprob:  0.596681, 0.273438 (0.665 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643510, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941152e-03 [6.846259e-09] 
Layer 'conv1' biases: 5.491228e-07 [8.911901e-11] 
Layer 'conv2' weights[0]: 7.929027e-03 [5.294742e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.654135e-10] 
Layer 'conv3' weights[0]: 7.926722e-03 [4.964838e-09] 
Layer 'conv3' biases: 4.585910e-06 [1.227583e-09] 
Layer 'conv4' weights[0]: 7.959537e-03 [4.929530e-09] 
Layer 'conv4' biases: 1.000001e+00 [9.347846e-09] 
Layer 'conv5' weights[0]: 7.958901e-03 [5.407741e-08] 
Layer 'conv5' biases: 1.000002e+00 [5.703944e-08] 
Layer 'fc6' weights[0]: 7.555079e-03 [6.981162e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.739018e-09] 
Layer 'fc7' weights[0]: 7.478928e-03 [8.651783e-08] 
Layer 'fc7' biases: 9.998534e-01 [6.771661e-08] 
Layer 'fc8' weights[0]: 5.862075e-04 [3.596954e-06] 
Layer 'fc8' biases: 1.583424e-01 [9.026272e-05] 
Train error last 27 batches: 0.635752
-------------------------------------------------------
Not saving because 0.643510 > 0.627087 (334.9: -0.00%)
======================================================= (5.101 sec)
361.5... logprob:  0.590957, 0.265625 (0.664 sec)
361.6... logprob:  0.611420, 0.296875 (0.663 sec)
361.7... logprob:  0.643822, 0.343750 (0.664 sec)
361.8... logprob:  0.604862, 0.289062 (0.665 sec)
361.9... logprob:  0.638538, 0.335938 (0.664 sec)
361.10... logprob:  0.597992, 0.281250 (0.664 sec)
361.11... logprob:  0.638869, 0.335938 (0.664 sec)
361.12... logprob:  0.717642, 0.437500 (0.665 sec)
361.13... logprob:  0.657275, 0.359375 (0.664 sec)
361.14... logprob:  0.662890, 0.367188 (0.664 sec)
361.15... logprob:  0.685966, 0.398438 (0.663 sec)
361.16... logprob:  0.627071, 0.320312 (0.663 sec)
361.17... logprob:  0.638510, 0.335938 (0.664 sec)
361.18... logprob:  0.638222, 0.335938 (0.663 sec)
361.19... logprob:  0.632715, 0.328125 (0.663 sec)
361.20... logprob:  0.648882, 0.351562 (0.662 sec)
361.21... logprob:  0.643431, 0.343750 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643458, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941093e-03 [6.850499e-09] 
Layer 'conv1' biases: 5.503812e-07 [1.555764e-10] 
Layer 'conv2' weights[0]: 7.928956e-03 [6.517779e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.420539e-10] 
Layer 'conv3' weights[0]: 7.926657e-03 [5.682110e-09] 
Layer 'conv3' biases: 4.596212e-06 [2.023852e-09] 
Layer 'conv4' weights[0]: 7.959467e-03 [5.597915e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.376814e-08] 
Layer 'conv5' weights[0]: 7.958833e-03 [7.816137e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.268895e-08] 
Layer 'fc6' weights[0]: 7.555009e-03 [9.457218e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.481498e-09] 
Layer 'fc7' weights[0]: 7.478297e-03 [1.183571e-07] 
Layer 'fc7' biases: 9.998533e-01 [1.016013e-07] 
Layer 'fc8' weights[0]: 5.805226e-04 [5.353274e-06] 
Layer 'fc8' biases: 1.584286e-01 [1.067093e-04] 
Train error last 27 batches: 0.635750
-------------------------------------------------------
Not saving because 0.643458 > 0.627087 (334.9: -0.00%)
======================================================= (5.068 sec)
361.22... logprob:  0.627984, 0.320312 (0.663 sec)
361.23... logprob:  0.623123, 0.312500 (0.663 sec)
361.24... logprob:  0.577712, 0.242188 (0.663 sec)
361.25... logprob:  0.628148, 0.320312 (0.661 sec)
361.26... logprob:  0.674125, 0.390625 (0.663 sec)
361.27... logprob:  0.628011, 0.320312 (0.664 sec)
362.1... logprob:  0.679558, 0.398438 (0.663 sec)
362.2... logprob:  0.597038, 0.273438 (0.664 sec)
362.3... logprob:  0.653795, 0.359375 (0.664 sec)
362.4... logprob:  0.596677, 0.273438 (0.664 sec)
362.5... logprob:  0.590953, 0.265625 (0.663 sec)
362.6... logprob:  0.611419, 0.296875 (0.663 sec)
362.7... logprob:  0.643822, 0.343750 (0.663 sec)
362.8... logprob:  0.604863, 0.289062 (0.665 sec)
362.9... logprob:  0.638536, 0.335938 (0.666 sec)
362.10... logprob:  0.597996, 0.281250 (0.665 sec)
362.11... logprob:  0.638866, 0.335938 (0.665 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.645227, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.941027e-03 [6.797335e-09] 
Layer 'conv1' biases: 5.510913e-07 [1.175636e-10] 
Layer 'conv2' weights[0]: 7.928883e-03 [5.729522e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.718909e-10] 
Layer 'conv3' weights[0]: 7.926588e-03 [5.567987e-09] 
Layer 'conv3' biases: 4.599899e-06 [1.794725e-09] 
Layer 'conv4' weights[0]: 7.959391e-03 [5.665615e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.532687e-08] 
Layer 'conv5' weights[0]: 7.958780e-03 [8.772642e-08] 
Layer 'conv5' biases: 1.000001e+00 [9.332188e-08] 
Layer 'fc6' weights[0]: 7.554934e-03 [1.018605e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.342550e-09] 
Layer 'fc7' weights[0]: 7.477623e-03 [1.254003e-07] 
Layer 'fc7' biases: 9.998539e-01 [1.087638e-07] 
Layer 'fc8' weights[0]: 6.273011e-04 [5.892350e-06] 
Layer 'fc8' biases: 1.597848e-01 [1.362483e-04] 
Train error last 27 batches: 0.635749
-------------------------------------------------------
Not saving because 0.645227 > 0.627087 (334.9: -0.00%)
======================================================= (5.079 sec)
362.12... logprob:  0.717625, 0.437500 (0.664 sec)
362.13... logprob:  0.657269, 0.359375 (0.665 sec)
362.14... logprob:  0.662884, 0.367188 (0.662 sec)
362.15... logprob:  0.685959, 0.398438 (0.663 sec)
362.16... logprob:  0.627071, 0.320312 (0.663 sec)
362.17... logprob:  0.638509, 0.335938 (0.664 sec)
362.18... logprob:  0.638223, 0.335938 (0.663 sec)
362.19... logprob:  0.632715, 0.328125 (0.661 sec)
362.20... logprob:  0.648883, 0.351562 (0.663 sec)
362.21... logprob:  0.643431, 0.343750 (0.661 sec)
362.22... logprob:  0.627982, 0.320312 (0.663 sec)
362.23... logprob:  0.623119, 0.312500 (0.662 sec)
362.24... logprob:  0.577697, 0.242188 (0.662 sec)
362.25... logprob:  0.628146, 0.320312 (0.663 sec)
362.26... logprob:  0.674130, 0.390625 (0.663 sec)
362.27... logprob:  0.628009, 0.320312 (0.663 sec)
363.1... logprob:  0.679563, 0.398438 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643458, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940954e-03 [6.666087e-09] 
Layer 'conv1' biases: 5.527210e-07 [8.218287e-11] 
Layer 'conv2' weights[0]: 7.928810e-03 [5.145538e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.282849e-10] 
Layer 'conv3' weights[0]: 7.926526e-03 [4.489662e-09] 
Layer 'conv3' biases: 4.614784e-06 [8.289801e-10] 
Layer 'conv4' weights[0]: 7.959323e-03 [4.391775e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.154979e-09] 
Layer 'conv5' weights[0]: 7.958695e-03 [1.786670e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.837687e-08] 
Layer 'fc6' weights[0]: 7.554869e-03 [4.344819e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.974318e-09] 
Layer 'fc7' weights[0]: 7.476995e-03 [4.910980e-08] 
Layer 'fc7' biases: 9.998533e-01 [2.463740e-08] 
Layer 'fc8' weights[0]: 5.801502e-04 [1.240736e-06] 
Layer 'fc8' biases: 1.588600e-01 [1.865195e-05] 
Train error last 27 batches: 0.635747
-------------------------------------------------------
Not saving because 0.643458 > 0.627087 (334.9: -0.00%)
======================================================= (5.164 sec)
363.2... logprob:  0.597032, 0.273438 (0.664 sec)
363.3... logprob:  0.653797, 0.359375 (0.664 sec)
363.4... logprob:  0.596673, 0.273438 (0.664 sec)
363.5... logprob:  0.590952, 0.265625 (0.664 sec)
363.6... logprob:  0.611420, 0.296875 (0.664 sec)
363.7... logprob:  0.643821, 0.343750 (0.664 sec)
363.8... logprob:  0.604866, 0.289062 (0.665 sec)
363.9... logprob:  0.638535, 0.335938 (0.665 sec)
363.10... logprob:  0.598001, 0.281250 (0.665 sec)
363.11... logprob:  0.638863, 0.335938 (0.665 sec)
363.12... logprob:  0.717603, 0.437500 (0.664 sec)
363.13... logprob:  0.657261, 0.359375 (0.660 sec)
363.14... logprob:  0.662877, 0.367188 (0.665 sec)
363.15... logprob:  0.685951, 0.398438 (0.663 sec)
363.16... logprob:  0.627071, 0.320312 (0.663 sec)
363.17... logprob:  0.638509, 0.335938 (0.664 sec)
363.18... logprob:  0.638223, 0.335938 (0.663 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643681, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940876e-03 [6.512418e-09] 
Layer 'conv1' biases: 5.537669e-07 [1.728352e-10] 
Layer 'conv2' weights[0]: 7.928735e-03 [6.746026e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.408826e-10] 
Layer 'conv3' weights[0]: 7.926459e-03 [5.922449e-09] 
Layer 'conv3' biases: 4.622617e-06 [2.286139e-09] 
Layer 'conv4' weights[0]: 7.959264e-03 [5.926089e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.658797e-08] 
Layer 'conv5' weights[0]: 7.958642e-03 [9.467782e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.003963e-07] 
Layer 'fc6' weights[0]: 7.554804e-03 [1.083162e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.016964e-08] 
Layer 'fc7' weights[0]: 7.476323e-03 [1.346756e-07] 
Layer 'fc7' biases: 9.998534e-01 [1.201425e-07] 
Layer 'fc8' weights[0]: 5.943113e-04 [6.421873e-06] 
Layer 'fc8' biases: 1.594412e-01 [1.257331e-04] 
Train error last 27 batches: 0.635746
-------------------------------------------------------
Not saving because 0.643681 > 0.627087 (334.9: -0.00%)
======================================================= (5.060 sec)
363.19... logprob:  0.632714, 0.328125 (0.663 sec)
363.20... logprob:  0.648885, 0.351562 (0.663 sec)
363.21... logprob:  0.643432, 0.343750 (0.663 sec)
363.22... logprob:  0.627979, 0.320312 (0.662 sec)
363.23... logprob:  0.623114, 0.312500 (0.663 sec)
363.24... logprob:  0.577680, 0.242188 (0.663 sec)
363.25... logprob:  0.628142, 0.320312 (0.663 sec)
363.26... logprob:  0.674137, 0.390625 (0.663 sec)
363.27... logprob:  0.628006, 0.320312 (0.664 sec)
364.1... logprob:  0.679570, 0.398438 (0.664 sec)
364.2... logprob:  0.597025, 0.273438 (0.664 sec)
364.3... logprob:  0.653799, 0.359375 (0.664 sec)
364.4... logprob:  0.596669, 0.273438 (0.664 sec)
364.5... logprob:  0.590949, 0.265625 (0.664 sec)
364.6... logprob:  0.611419, 0.296875 (0.664 sec)
364.7... logprob:  0.643821, 0.343750 (0.664 sec)
364.8... logprob:  0.604869, 0.289062 (0.665 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644206, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940799e-03 [7.134903e-09] 
Layer 'conv1' biases: 5.547660e-07 [1.434578e-10] 
Layer 'conv2' weights[0]: 7.928666e-03 [6.270794e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.451868e-10] 
Layer 'conv3' weights[0]: 7.926394e-03 [6.074895e-09] 
Layer 'conv3' biases: 4.630178e-06 [2.212676e-09] 
Layer 'conv4' weights[0]: 7.959197e-03 [6.201996e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.917232e-08] 
Layer 'conv5' weights[0]: 7.958588e-03 [1.095230e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.162562e-07] 
Layer 'fc6' weights[0]: 7.554735e-03 [1.223527e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.168395e-08] 
Layer 'fc7' weights[0]: 7.475675e-03 [1.509308e-07] 
Layer 'fc7' biases: 9.998536e-01 [1.371558e-07] 
Layer 'fc8' weights[0]: 6.091988e-04 [7.342739e-06] 
Layer 'fc8' biases: 1.600159e-01 [1.716628e-04] 
Train error last 27 batches: 0.635745
-------------------------------------------------------
Not saving because 0.644206 > 0.627087 (334.9: -0.00%)
======================================================= (5.061 sec)
364.9... logprob:  0.638535, 0.335938 (0.665 sec)
364.10... logprob:  0.598008, 0.281250 (0.664 sec)
364.11... logprob:  0.638860, 0.335938 (0.661 sec)
364.12... logprob:  0.717575, 0.437500 (0.664 sec)
364.13... logprob:  0.657253, 0.359375 (0.665 sec)
364.14... logprob:  0.662868, 0.367188 (0.664 sec)
364.15... logprob:  0.685938, 0.398438 (0.663 sec)
364.16... logprob:  0.627071, 0.320312 (0.662 sec)
364.17... logprob:  0.638509, 0.335938 (0.664 sec)
364.18... logprob:  0.638221, 0.335938 (0.663 sec)
364.19... logprob:  0.632714, 0.328125 (0.663 sec)
364.20... logprob:  0.648885, 0.351562 (0.662 sec)
364.21... logprob:  0.643433, 0.343750 (0.662 sec)
364.22... logprob:  0.627977, 0.320312 (0.663 sec)
364.23... logprob:  0.623111, 0.312500 (0.662 sec)
364.24... logprob:  0.577668, 0.242188 (0.663 sec)
364.25... logprob:  0.628140, 0.320312 (0.663 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643454, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940735e-03 [6.593648e-09] 
Layer 'conv1' biases: 5.562623e-07 [6.925751e-11] 
Layer 'conv2' weights[0]: 7.928603e-03 [4.945149e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.598306e-10] 
Layer 'conv3' weights[0]: 7.926328e-03 [4.656021e-09] 
Layer 'conv3' biases: 4.643167e-06 [1.020861e-09] 
Layer 'conv4' weights[0]: 7.959133e-03 [4.646984e-09] 
Layer 'conv4' biases: 1.000001e+00 [7.915753e-09] 
Layer 'conv5' weights[0]: 7.958516e-03 [4.506065e-08] 
Layer 'conv5' biases: 1.000002e+00 [4.747973e-08] 
Layer 'fc6' weights[0]: 7.554662e-03 [6.202404e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.800407e-09] 
Layer 'fc7' weights[0]: 7.475053e-03 [7.668705e-08] 
Layer 'fc7' biases: 9.998530e-01 [5.718755e-08] 
Layer 'fc8' weights[0]: 5.788661e-04 [2.984619e-06] 
Layer 'fc8' biases: 1.594933e-01 [8.307555e-05] 
Train error last 27 batches: 0.635742
-------------------------------------------------------
Not saving because 0.643454 > 0.627087 (334.9: -0.00%)
======================================================= (5.113 sec)
364.26... logprob:  0.674141, 0.390625 (0.663 sec)
364.27... logprob:  0.628005, 0.320312 (0.662 sec)
365.1... logprob:  0.679575, 0.398438 (0.662 sec)
365.2... logprob:  0.597019, 0.273438 (0.664 sec)
365.3... logprob:  0.653800, 0.359375 (0.664 sec)
365.4... logprob:  0.596664, 0.273438 (0.664 sec)
365.5... logprob:  0.590944, 0.265625 (0.664 sec)
365.6... logprob:  0.611418, 0.296875 (0.663 sec)
365.7... logprob:  0.643821, 0.343750 (0.664 sec)
365.8... logprob:  0.604870, 0.289062 (0.665 sec)
365.9... logprob:  0.638534, 0.335938 (0.664 sec)
365.10... logprob:  0.598010, 0.281250 (0.665 sec)
365.11... logprob:  0.638858, 0.335938 (0.664 sec)
365.12... logprob:  0.717561, 0.437500 (0.662 sec)
365.13... logprob:  0.657249, 0.359375 (0.664 sec)
365.14... logprob:  0.662863, 0.367188 (0.664 sec)
365.15... logprob:  0.685934, 0.398438 (0.661 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644343, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940672e-03 [7.312864e-09] 
Layer 'conv1' biases: 5.571335e-07 [2.054525e-10] 
Layer 'conv2' weights[0]: 7.928540e-03 [7.629208e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.025916e-09] 
Layer 'conv3' weights[0]: 7.926257e-03 [6.588725e-09] 
Layer 'conv3' biases: 4.648792e-06 [2.839395e-09] 
Layer 'conv4' weights[0]: 7.959066e-03 [6.646485e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.103336e-08] 
Layer 'conv5' weights[0]: 7.958460e-03 [1.199802e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.273124e-07] 
Layer 'fc6' weights[0]: 7.554593e-03 [1.329319e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.282861e-08] 
Layer 'fc7' weights[0]: 7.474365e-03 [1.632845e-07] 
Layer 'fc7' biases: 9.998536e-01 [1.506698e-07] 
Layer 'fc8' weights[0]: 6.116251e-04 [8.106622e-06] 
Layer 'fc8' biases: 1.605211e-01 [1.575733e-04] 
Train error last 27 batches: 0.635741
-------------------------------------------------------
Not saving because 0.644343 > 0.627087 (334.9: -0.00%)
======================================================= (5.046 sec)
365.16... logprob:  0.627071, 0.320312 (0.663 sec)
365.17... logprob:  0.638509, 0.335938 (0.663 sec)
365.18... logprob:  0.638222, 0.335938 (0.663 sec)
365.19... logprob:  0.632713, 0.328125 (0.663 sec)
365.20... logprob:  0.648888, 0.351562 (0.662 sec)
365.21... logprob:  0.643433, 0.343750 (0.663 sec)
365.22... logprob:  0.627973, 0.320312 (0.663 sec)
365.23... logprob:  0.623106, 0.312500 (0.662 sec)
365.24... logprob:  0.577651, 0.242188 (0.663 sec)
365.25... logprob:  0.628137, 0.320312 (0.663 sec)
365.26... logprob:  0.674147, 0.390625 (0.663 sec)
365.27... logprob:  0.628002, 0.320312 (0.664 sec)
366.1... logprob:  0.679579, 0.398438 (0.664 sec)
366.2... logprob:  0.597014, 0.273438 (0.665 sec)
366.3... logprob:  0.653801, 0.359375 (0.664 sec)
366.4... logprob:  0.596662, 0.273438 (0.663 sec)
366.5... logprob:  0.590945, 0.265625 (0.662 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643603, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940602e-03 [7.413102e-09] 
Layer 'conv1' biases: 5.584905e-07 [1.377277e-10] 
Layer 'conv2' weights[0]: 7.928470e-03 [5.970749e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.497762e-10] 
Layer 'conv3' weights[0]: 7.926193e-03 [5.772388e-09] 
Layer 'conv3' biases: 4.660546e-06 [1.952607e-09] 
Layer 'conv4' weights[0]: 7.958998e-03 [5.814532e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.655573e-08] 
Layer 'conv5' weights[0]: 7.958388e-03 [9.478735e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.002531e-07] 
Layer 'fc6' weights[0]: 7.554521e-03 [1.083266e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.012245e-08] 
Layer 'fc7' weights[0]: 7.473735e-03 [1.343171e-07] 
Layer 'fc7' biases: 9.998533e-01 [1.194065e-07] 
Layer 'fc8' weights[0]: 5.901315e-04 [6.335553e-06] 
Layer 'fc8' biases: 1.602022e-01 [1.530639e-04] 
Train error last 27 batches: 0.635740
-------------------------------------------------------
Not saving because 0.643603 > 0.627087 (334.9: -0.00%)
======================================================= (5.061 sec)
366.6... logprob:  0.611420, 0.296875 (0.664 sec)
366.7... logprob:  0.643819, 0.343750 (0.663 sec)
366.8... logprob:  0.604875, 0.289062 (0.665 sec)
366.9... logprob:  0.638532, 0.335938 (0.664 sec)
366.10... logprob:  0.598018, 0.281250 (0.665 sec)
366.11... logprob:  0.638854, 0.335938 (0.664 sec)
366.12... logprob:  0.717532, 0.437500 (0.664 sec)
366.13... logprob:  0.657238, 0.359375 (0.664 sec)
366.14... logprob:  0.662853, 0.367188 (0.664 sec)
366.15... logprob:  0.685921, 0.398438 (0.664 sec)
366.16... logprob:  0.627071, 0.320312 (0.663 sec)
366.17... logprob:  0.638509, 0.335938 (0.663 sec)
366.18... logprob:  0.638221, 0.335938 (0.663 sec)
366.19... logprob:  0.632713, 0.328125 (0.663 sec)
366.20... logprob:  0.648887, 0.351562 (0.666 sec)
366.21... logprob:  0.643433, 0.343750 (0.660 sec)
366.22... logprob:  0.627972, 0.320312 (0.665 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643443, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940538e-03 [6.727369e-09] 
Layer 'conv1' biases: 5.598341e-07 [1.354298e-10] 
Layer 'conv2' weights[0]: 7.928409e-03 [6.071203e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.969854e-10] 
Layer 'conv3' weights[0]: 7.926133e-03 [5.275183e-09] 
Layer 'conv3' biases: 4.671823e-06 [1.606813e-09] 
Layer 'conv4' weights[0]: 7.958932e-03 [5.161021e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.005045e-08] 
Layer 'conv5' weights[0]: 7.958322e-03 [5.707222e-08] 
Layer 'conv5' biases: 1.000002e+00 [6.023635e-08] 
Layer 'fc6' weights[0]: 7.554451e-03 [7.344658e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.190495e-09] 
Layer 'fc7' weights[0]: 7.473093e-03 [9.196942e-08] 
Layer 'fc7' biases: 9.998528e-01 [7.421009e-08] 
Layer 'fc8' weights[0]: 5.757860e-04 [3.885009e-06] 
Layer 'fc8' biases: 1.600624e-01 [7.532889e-05] 
Train error last 27 batches: 0.635738
-------------------------------------------------------
Not saving because 0.643443 > 0.627087 (334.9: -0.00%)
======================================================= (5.096 sec)
366.23... logprob:  0.623103, 0.312500 (0.660 sec)
366.24... logprob:  0.577638, 0.242188 (0.662 sec)
366.25... logprob:  0.628133, 0.320312 (0.662 sec)
366.26... logprob:  0.674152, 0.390625 (0.661 sec)
366.27... logprob:  0.627999, 0.320312 (0.663 sec)
367.1... logprob:  0.679586, 0.398438 (0.664 sec)
367.2... logprob:  0.597006, 0.273438 (0.664 sec)
367.3... logprob:  0.653803, 0.359375 (0.664 sec)
367.4... logprob:  0.596654, 0.273438 (0.661 sec)
367.5... logprob:  0.590937, 0.265625 (0.665 sec)
367.6... logprob:  0.611417, 0.296875 (0.664 sec)
367.7... logprob:  0.643820, 0.343750 (0.663 sec)
367.8... logprob:  0.604874, 0.289062 (0.665 sec)
367.9... logprob:  0.638532, 0.335938 (0.664 sec)
367.10... logprob:  0.598020, 0.281250 (0.665 sec)
367.11... logprob:  0.638852, 0.335938 (0.664 sec)
367.12... logprob:  0.717519, 0.437500 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.645163, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940478e-03 [6.885715e-09] 
Layer 'conv1' biases: 5.605292e-07 [8.287188e-11] 
Layer 'conv2' weights[0]: 7.928345e-03 [5.247059e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.225820e-10] 
Layer 'conv3' weights[0]: 7.926066e-03 [4.549299e-09] 
Layer 'conv3' biases: 4.675173e-06 [8.017501e-10] 
Layer 'conv4' weights[0]: 7.958861e-03 [4.407999e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.652915e-09] 
Layer 'conv5' weights[0]: 7.958272e-03 [1.013428e-08] 
Layer 'conv5' biases: 1.000001e+00 [9.743675e-09] 
Layer 'fc6' weights[0]: 7.554383e-03 [3.957836e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.075907e-09] 
Layer 'fc7' weights[0]: 7.472440e-03 [4.187854e-08] 
Layer 'fc7' biases: 9.998539e-01 [1.448119e-08] 
Layer 'fc8' weights[0]: 6.247325e-04 [6.652023e-07] 
Layer 'fc8' biases: 1.614878e-01 [1.134958e-06] 
Train error last 27 batches: 0.635736
-------------------------------------------------------
Not saving because 0.645163 > 0.627087 (334.9: -0.00%)
======================================================= (5.182 sec)
367.13... logprob:  0.657233, 0.359375 (0.664 sec)
367.14... logprob:  0.662849, 0.367188 (0.665 sec)
367.15... logprob:  0.685916, 0.398438 (0.661 sec)
367.16... logprob:  0.627072, 0.320312 (0.662 sec)
367.17... logprob:  0.638507, 0.335938 (0.663 sec)
367.18... logprob:  0.638222, 0.335938 (0.664 sec)
367.19... logprob:  0.632712, 0.328125 (0.663 sec)
367.20... logprob:  0.648889, 0.351562 (0.664 sec)
367.21... logprob:  0.643434, 0.343750 (0.663 sec)
367.22... logprob:  0.627969, 0.320312 (0.663 sec)
367.23... logprob:  0.623099, 0.312500 (0.663 sec)
367.24... logprob:  0.577626, 0.242188 (0.663 sec)
367.25... logprob:  0.628132, 0.320312 (0.663 sec)
367.26... logprob:  0.674157, 0.390625 (0.663 sec)
367.27... logprob:  0.627998, 0.320312 (0.664 sec)
368.1... logprob:  0.679589, 0.398438 (0.664 sec)
368.2... logprob:  0.597003, 0.273438 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643470, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940408e-03 [6.830788e-09] 
Layer 'conv1' biases: 5.621413e-07 [7.157540e-11] 
Layer 'conv2' weights[0]: 7.928276e-03 [4.976745e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.858694e-10] 
Layer 'conv3' weights[0]: 7.926001e-03 [4.548858e-09] 
Layer 'conv3' biases: 4.689597e-06 [7.895857e-10] 
Layer 'conv4' weights[0]: 7.958805e-03 [4.456951e-09] 
Layer 'conv4' biases: 1.000001e+00 [4.675326e-09] 
Layer 'conv5' weights[0]: 7.958190e-03 [2.701875e-08] 
Layer 'conv5' biases: 1.000002e+00 [2.832161e-08] 
Layer 'fc6' weights[0]: 7.554312e-03 [4.888172e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.844073e-09] 
Layer 'fc7' weights[0]: 7.471829e-03 [5.716663e-08] 
Layer 'fc7' biases: 9.998530e-01 [3.377941e-08] 
Layer 'fc8' weights[0]: 5.802196e-04 [1.775303e-06] 
Layer 'fc8' biases: 1.606134e-01 [5.006242e-05] 
Train error last 27 batches: 0.635735
-------------------------------------------------------
Not saving because 0.643470 > 0.627087 (334.9: -0.00%)
======================================================= (5.138 sec)
368.3... logprob:  0.653803, 0.359375 (0.664 sec)
368.4... logprob:  0.596654, 0.273438 (0.664 sec)
368.5... logprob:  0.590938, 0.265625 (0.662 sec)
368.6... logprob:  0.611419, 0.296875 (0.662 sec)
368.7... logprob:  0.643819, 0.343750 (0.663 sec)
368.8... logprob:  0.604878, 0.289062 (0.664 sec)
368.9... logprob:  0.638530, 0.335938 (0.665 sec)
368.10... logprob:  0.598026, 0.281250 (0.665 sec)
368.11... logprob:  0.638849, 0.335938 (0.665 sec)
368.12... logprob:  0.717495, 0.437500 (0.664 sec)
368.13... logprob:  0.657225, 0.359375 (0.664 sec)
368.14... logprob:  0.662841, 0.367188 (0.664 sec)
368.15... logprob:  0.685906, 0.398438 (0.662 sec)
368.16... logprob:  0.627072, 0.320312 (0.662 sec)
368.17... logprob:  0.638508, 0.335938 (0.664 sec)
368.18... logprob:  0.638221, 0.335938 (0.663 sec)
368.19... logprob:  0.632711, 0.328125 (0.663 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643579, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940341e-03 [6.790606e-09] 
Layer 'conv1' biases: 5.632601e-07 [1.580057e-10] 
Layer 'conv2' weights[0]: 7.928215e-03 [6.602050e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.661144e-10] 
Layer 'conv3' weights[0]: 7.925935e-03 [5.725070e-09] 
Layer 'conv3' biases: 4.698409e-06 [2.078287e-09] 
Layer 'conv4' weights[0]: 7.958737e-03 [5.669274e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.428793e-08] 
Layer 'conv5' weights[0]: 7.958128e-03 [8.101636e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.551945e-08] 
Layer 'fc6' weights[0]: 7.554243e-03 [9.686157e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.723543e-09] 
Layer 'fc7' weights[0]: 7.471170e-03 [1.201955e-07] 
Layer 'fc7' biases: 9.998531e-01 [1.035309e-07] 
Layer 'fc8' weights[0]: 5.879895e-04 [5.471401e-06] 
Layer 'fc8' biases: 1.610365e-01 [1.074742e-04] 
Train error last 27 batches: 0.635733
-------------------------------------------------------
Not saving because 0.643579 > 0.627087 (334.9: -0.00%)
======================================================= (5.070 sec)
368.20... logprob:  0.648889, 0.351562 (0.663 sec)
368.21... logprob:  0.643434, 0.343750 (0.663 sec)
368.22... logprob:  0.627966, 0.320312 (0.663 sec)
368.23... logprob:  0.623094, 0.312500 (0.662 sec)
368.24... logprob:  0.577610, 0.242188 (0.663 sec)
368.25... logprob:  0.628128, 0.320312 (0.663 sec)
368.26... logprob:  0.674163, 0.390625 (0.663 sec)
368.27... logprob:  0.627995, 0.320312 (0.664 sec)
369.1... logprob:  0.679596, 0.398438 (0.663 sec)
369.2... logprob:  0.596994, 0.273438 (0.664 sec)
369.3... logprob:  0.653805, 0.359375 (0.664 sec)
369.4... logprob:  0.596648, 0.273438 (0.664 sec)
369.5... logprob:  0.590934, 0.265625 (0.664 sec)
369.6... logprob:  0.611417, 0.296875 (0.663 sec)
369.7... logprob:  0.643819, 0.343750 (0.664 sec)
369.8... logprob:  0.604879, 0.289062 (0.664 sec)
369.9... logprob:  0.638530, 0.335938 (0.665 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644462, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940266e-03 [6.685774e-09] 
Layer 'conv1' biases: 5.641693e-07 [1.196328e-10] 
Layer 'conv2' weights[0]: 7.928154e-03 [5.827795e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.076539e-10] 
Layer 'conv3' weights[0]: 7.925869e-03 [5.672564e-09] 
Layer 'conv3' biases: 4.704675e-06 [1.867130e-09] 
Layer 'conv4' weights[0]: 7.958666e-03 [5.785768e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.598661e-08] 
Layer 'conv5' weights[0]: 7.958082e-03 [9.066141e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.599700e-08] 
Layer 'fc6' weights[0]: 7.554172e-03 [1.046396e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.688305e-09] 
Layer 'fc7' weights[0]: 7.470501e-03 [1.291168e-07] 
Layer 'fc7' biases: 9.998536e-01 [1.133955e-07] 
Layer 'fc8' weights[0]: 6.127495e-04 [6.054398e-06] 
Layer 'fc8' biases: 1.618568e-01 [1.435929e-04] 
Train error last 27 batches: 0.635732
-------------------------------------------------------
Not saving because 0.644462 > 0.627087 (334.9: -0.00%)
======================================================= (5.062 sec)
369.10... logprob:  0.598030, 0.281250 (0.665 sec)
369.11... logprob:  0.638847, 0.335938 (0.665 sec)
369.12... logprob:  0.717476, 0.437500 (0.665 sec)
369.13... logprob:  0.657219, 0.359375 (0.664 sec)
369.14... logprob:  0.662835, 0.367188 (0.664 sec)
369.15... logprob:  0.685899, 0.398438 (0.664 sec)
369.16... logprob:  0.627072, 0.320312 (0.664 sec)
369.17... logprob:  0.638508, 0.335938 (0.664 sec)
369.18... logprob:  0.638221, 0.335938 (0.663 sec)
369.19... logprob:  0.632711, 0.328125 (0.658 sec)
369.20... logprob:  0.648891, 0.351562 (0.663 sec)
369.21... logprob:  0.643435, 0.343750 (0.662 sec)
369.22... logprob:  0.627964, 0.320312 (0.663 sec)
369.23... logprob:  0.623090, 0.312500 (0.663 sec)
369.24... logprob:  0.577596, 0.242188 (0.663 sec)
369.25... logprob:  0.628125, 0.320312 (0.660 sec)
369.26... logprob:  0.674169, 0.390625 (0.663 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643458, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940204e-03 [6.541918e-09] 
Layer 'conv1' biases: 5.657090e-07 [7.075924e-11] 
Layer 'conv2' weights[0]: 7.928100e-03 [5.019134e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.433452e-10] 
Layer 'conv3' weights[0]: 7.925799e-03 [4.418014e-09] 
Layer 'conv3' biases: 4.718174e-06 [6.099586e-10] 
Layer 'conv4' weights[0]: 7.958608e-03 [4.317256e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.551264e-09] 
Layer 'conv5' weights[0]: 7.957991e-03 [9.885951e-09] 
Layer 'conv5' biases: 1.000002e+00 [9.569924e-09] 
Layer 'fc6' weights[0]: 7.554098e-03 [3.931207e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.530381e-10] 
Layer 'fc7' weights[0]: 7.469871e-03 [4.069056e-08] 
Layer 'fc7' biases: 9.998528e-01 [1.167906e-08] 
Layer 'fc8' weights[0]: 5.779407e-04 [5.756870e-07] 
Layer 'fc8' biases: 1.612177e-01 [2.484372e-05] 
Train error last 27 batches: 0.635730
-------------------------------------------------------
Not saving because 0.643458 > 0.627087 (334.9: -0.00%)
======================================================= (5.198 sec)
369.27... logprob:  0.627992, 0.320312 (0.664 sec)
370.1... logprob:  0.679600, 0.398438 (0.664 sec)
370.2... logprob:  0.596990, 0.273438 (0.664 sec)
370.3... logprob:  0.653806, 0.359375 (0.665 sec)
370.4... logprob:  0.596644, 0.273438 (0.664 sec)
370.5... logprob:  0.590932, 0.265625 (0.664 sec)
370.6... logprob:  0.611418, 0.296875 (0.664 sec)
370.7... logprob:  0.643818, 0.343750 (0.664 sec)
370.8... logprob:  0.604882, 0.289062 (0.665 sec)
370.9... logprob:  0.638528, 0.335938 (0.665 sec)
370.10... logprob:  0.598036, 0.281250 (0.665 sec)
370.11... logprob:  0.638844, 0.335938 (0.664 sec)
370.12... logprob:  0.717453, 0.437500 (0.663 sec)
370.13... logprob:  0.657211, 0.359375 (0.665 sec)
370.14... logprob:  0.662827, 0.367188 (0.664 sec)
370.15... logprob:  0.685889, 0.398438 (0.663 sec)
370.16... logprob:  0.627073, 0.320312 (0.661 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644056, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940142e-03 [6.960540e-09] 
Layer 'conv1' biases: 5.666467e-07 [1.848328e-10] 
Layer 'conv2' weights[0]: 7.928034e-03 [7.202896e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.312878e-10] 
Layer 'conv3' weights[0]: 7.925732e-03 [6.253218e-09] 
Layer 'conv3' biases: 4.724809e-06 [2.554181e-09] 
Layer 'conv4' weights[0]: 7.958540e-03 [6.263947e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.842009e-08] 
Layer 'conv5' weights[0]: 7.957943e-03 [1.043849e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.104572e-07] 
Layer 'fc6' weights[0]: 7.554042e-03 [1.178208e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.122547e-08] 
Layer 'fc7' weights[0]: 7.469200e-03 [1.454970e-07] 
Layer 'fc7' biases: 9.998534e-01 [1.318402e-07] 
Layer 'fc8' weights[0]: 6.036374e-04 [7.042169e-06] 
Layer 'fc8' biases: 1.620788e-01 [1.377766e-04] 
Train error last 27 batches: 0.635728
-------------------------------------------------------
Not saving because 0.644056 > 0.627087 (334.9: -0.00%)
======================================================= (5.057 sec)
370.17... logprob:  0.638508, 0.335938 (0.661 sec)
370.18... logprob:  0.638221, 0.335938 (0.663 sec)
370.19... logprob:  0.632711, 0.328125 (0.663 sec)
370.20... logprob:  0.648892, 0.351562 (0.663 sec)
370.21... logprob:  0.643435, 0.343750 (0.663 sec)
370.22... logprob:  0.627961, 0.320312 (0.666 sec)
370.23... logprob:  0.623086, 0.312500 (0.667 sec)
370.24... logprob:  0.577580, 0.242188 (0.662 sec)
370.25... logprob:  0.628122, 0.320312 (0.666 sec)
370.26... logprob:  0.674175, 0.390625 (0.662 sec)
370.27... logprob:  0.627990, 0.320312 (0.665 sec)
371.1... logprob:  0.679607, 0.398438 (0.666 sec)
371.2... logprob:  0.596982, 0.273438 (0.667 sec)
371.3... logprob:  0.653808, 0.359375 (0.667 sec)
371.4... logprob:  0.596640, 0.273438 (0.667 sec)
371.5... logprob:  0.590928, 0.265625 (0.665 sec)
371.6... logprob:  0.611417, 0.296875 (0.667 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643761, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940076e-03 [7.339115e-09] 
Layer 'conv1' biases: 5.678769e-07 [1.629069e-10] 
Layer 'conv2' weights[0]: 7.927972e-03 [6.279662e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.685046e-10] 
Layer 'conv3' weights[0]: 7.925667e-03 [6.071305e-09] 
Layer 'conv3' biases: 4.735094e-06 [2.231604e-09] 
Layer 'conv4' weights[0]: 7.958468e-03 [6.140430e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.925187e-08] 
Layer 'conv5' weights[0]: 7.957876e-03 [1.094035e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.156225e-07] 
Layer 'fc6' weights[0]: 7.553964e-03 [1.228557e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.173208e-08] 
Layer 'fc7' weights[0]: 7.468570e-03 [1.518645e-07] 
Layer 'fc7' biases: 9.998533e-01 [1.382996e-07] 
Layer 'fc8' weights[0]: 5.949405e-04 [7.316763e-06] 
Layer 'fc8' biases: 1.620707e-01 [1.753953e-04] 
Train error last 27 batches: 0.635727
-------------------------------------------------------
Not saving because 0.643761 > 0.627087 (334.9: -0.00%)
======================================================= (5.067 sec)
371.7... logprob:  0.643818, 0.343750 (0.665 sec)
371.8... logprob:  0.604885, 0.289062 (0.667 sec)
371.9... logprob:  0.638527, 0.335938 (0.667 sec)
371.10... logprob:  0.598042, 0.281250 (0.666 sec)
371.11... logprob:  0.638841, 0.335938 (0.668 sec)
371.12... logprob:  0.717430, 0.437500 (0.666 sec)
371.13... logprob:  0.657204, 0.359375 (0.666 sec)
371.14... logprob:  0.662819, 0.367188 (0.668 sec)
371.15... logprob:  0.685879, 0.398438 (0.666 sec)
371.16... logprob:  0.627073, 0.320312 (0.666 sec)
371.17... logprob:  0.638507, 0.335938 (0.666 sec)
371.18... logprob:  0.638222, 0.335938 (0.664 sec)
371.19... logprob:  0.632711, 0.328125 (0.666 sec)
371.20... logprob:  0.648893, 0.351562 (0.666 sec)
371.21... logprob:  0.643436, 0.343750 (0.666 sec)
371.22... logprob:  0.627959, 0.320312 (0.666 sec)
371.23... logprob:  0.623082, 0.312500 (0.666 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643440, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.940009e-03 [6.343965e-09] 
Layer 'conv1' biases: 5.693050e-07 [1.071609e-10] 
Layer 'conv2' weights[0]: 7.927908e-03 [5.357350e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.207167e-10] 
Layer 'conv3' weights[0]: 7.925594e-03 [4.749096e-09] 
Layer 'conv3' biases: 4.747301e-06 [1.093788e-09] 
Layer 'conv4' weights[0]: 7.958412e-03 [4.621541e-09] 
Layer 'conv4' biases: 1.000001e+00 [5.715747e-09] 
Layer 'conv5' weights[0]: 7.957801e-03 [3.257256e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.420467e-08] 
Layer 'fc6' weights[0]: 7.553889e-03 [5.260173e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.533741e-09] 
Layer 'fc7' weights[0]: 7.467922e-03 [6.386758e-08] 
Layer 'fc7' biases: 9.998526e-01 [4.257345e-08] 
Layer 'fc8' weights[0]: 5.725306e-04 [2.216624e-06] 
Layer 'fc8' biases: 1.617194e-01 [3.791921e-05] 
Train error last 27 batches: 0.635725
-------------------------------------------------------
Not saving because 0.643440 > 0.627087 (334.9: -0.00%)
======================================================= (5.129 sec)
371.24... logprob:  0.577566, 0.242188 (0.661 sec)
371.25... logprob:  0.628119, 0.320312 (0.665 sec)
371.26... logprob:  0.674181, 0.390625 (0.667 sec)
371.27... logprob:  0.627988, 0.320312 (0.667 sec)
372.1... logprob:  0.679613, 0.398438 (0.667 sec)
372.2... logprob:  0.596976, 0.273438 (0.665 sec)
372.3... logprob:  0.653809, 0.359375 (0.666 sec)
372.4... logprob:  0.596636, 0.273438 (0.666 sec)
372.5... logprob:  0.590926, 0.265625 (0.668 sec)
372.6... logprob:  0.611417, 0.296875 (0.667 sec)
372.7... logprob:  0.643818, 0.343750 (0.665 sec)
372.8... logprob:  0.604888, 0.289062 (0.669 sec)
372.9... logprob:  0.638526, 0.335938 (0.668 sec)
372.10... logprob:  0.598047, 0.281250 (0.668 sec)
372.11... logprob:  0.638838, 0.335938 (0.667 sec)
372.12... logprob:  0.717410, 0.437500 (0.667 sec)
372.13... logprob:  0.657197, 0.359375 (0.667 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644982, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.939946e-03 [6.516338e-09] 
Layer 'conv1' biases: 5.699948e-07 [1.003288e-10] 
Layer 'conv2' weights[0]: 7.927847e-03 [5.429466e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.575648e-10] 
Layer 'conv3' weights[0]: 7.925526e-03 [4.771523e-09] 
Layer 'conv3' biases: 4.750877e-06 [1.250468e-09] 
Layer 'conv4' weights[0]: 7.958348e-03 [4.683131e-09] 
Layer 'conv4' biases: 1.000001e+00 [6.824136e-09] 
Layer 'conv5' weights[0]: 7.957749e-03 [3.889882e-08] 
Layer 'conv5' biases: 1.000002e+00 [4.095592e-08] 
Layer 'fc6' weights[0]: 7.553833e-03 [5.695693e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.170807e-09] 
Layer 'fc7' weights[0]: 7.467301e-03 [7.009849e-08] 
Layer 'fc7' biases: 9.998536e-01 [4.971093e-08] 
Layer 'fc8' weights[0]: 6.204654e-04 [2.634217e-06] 
Layer 'fc8' biases: 1.631345e-01 [4.160473e-05] 
Train error last 27 batches: 0.635723
-------------------------------------------------------
Not saving because 0.644982 > 0.627087 (334.9: -0.00%)
======================================================= (5.128 sec)
372.14... logprob:  0.662813, 0.367188 (0.664 sec)
372.15... logprob:  0.685872, 0.398438 (0.665 sec)
372.16... logprob:  0.627073, 0.320312 (0.663 sec)
372.17... logprob:  0.638508, 0.335938 (0.664 sec)
372.18... logprob:  0.638222, 0.335938 (0.663 sec)
372.19... logprob:  0.632710, 0.328125 (0.663 sec)
372.20... logprob:  0.648894, 0.351562 (0.664 sec)
372.21... logprob:  0.643436, 0.343750 (0.662 sec)
372.22... logprob:  0.627956, 0.320312 (0.663 sec)
372.23... logprob:  0.623078, 0.312500 (0.665 sec)
372.24... logprob:  0.577552, 0.242188 (0.665 sec)
372.25... logprob:  0.628116, 0.320312 (0.660 sec)
372.26... logprob:  0.674186, 0.390625 (0.660 sec)
372.27... logprob:  0.627986, 0.320312 (0.663 sec)
373.1... logprob:  0.679618, 0.398438 (0.662 sec)
373.2... logprob:  0.596971, 0.273438 (0.665 sec)
373.3... logprob:  0.653810, 0.359375 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643477, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.939881e-03 [6.728474e-09] 
Layer 'conv1' biases: 5.715657e-07 [6.529178e-11] 
Layer 'conv2' weights[0]: 7.927794e-03 [4.984559e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.552951e-10] 
Layer 'conv3' weights[0]: 7.925451e-03 [4.451379e-09] 
Layer 'conv3' biases: 4.764923e-06 [6.357637e-10] 
Layer 'conv4' weights[0]: 7.958287e-03 [4.334664e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.912892e-09] 
Layer 'conv5' weights[0]: 7.957677e-03 [1.212743e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.210127e-08] 
Layer 'fc6' weights[0]: 7.553767e-03 [4.018020e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.215599e-09] 
Layer 'fc7' weights[0]: 7.466665e-03 [4.258834e-08] 
Layer 'fc7' biases: 9.998527e-01 [1.481011e-08] 
Layer 'fc8' weights[0]: 5.794380e-04 [7.692444e-07] 
Layer 'fc8' biases: 1.623276e-01 [2.498812e-05] 
Train error last 27 batches: 0.635722
-------------------------------------------------------
Not saving because 0.643477 > 0.627087 (334.9: -0.00%)
======================================================= (5.182 sec)
373.4... logprob:  0.596632, 0.273438 (0.665 sec)
373.5... logprob:  0.590923, 0.265625 (0.664 sec)
373.6... logprob:  0.611417, 0.296875 (0.664 sec)
373.7... logprob:  0.643817, 0.343750 (0.664 sec)
373.8... logprob:  0.604890, 0.289062 (0.666 sec)
373.9... logprob:  0.638525, 0.335938 (0.665 sec)
373.10... logprob:  0.598052, 0.281250 (0.665 sec)
373.11... logprob:  0.638835, 0.335938 (0.666 sec)
373.12... logprob:  0.717388, 0.437500 (0.665 sec)
373.13... logprob:  0.657190, 0.359375 (0.664 sec)
373.14... logprob:  0.662805, 0.367188 (0.664 sec)
373.15... logprob:  0.685861, 0.398438 (0.663 sec)
373.16... logprob:  0.627074, 0.320312 (0.663 sec)
373.17... logprob:  0.638507, 0.335938 (0.664 sec)
373.18... logprob:  0.638221, 0.335938 (0.663 sec)
373.19... logprob:  0.632710, 0.328125 (0.665 sec)
373.20... logprob:  0.648895, 0.351562 (0.662 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643505, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.939811e-03 [6.841733e-09] 
Layer 'conv1' biases: 5.727409e-07 [1.623048e-10] 
Layer 'conv2' weights[0]: 7.927722e-03 [6.533611e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.741473e-10] 
Layer 'conv3' weights[0]: 7.925388e-03 [5.713587e-09] 
Layer 'conv3' biases: 4.774358e-06 [2.105869e-09] 
Layer 'conv4' weights[0]: 7.958232e-03 [5.647179e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.456142e-08] 
Layer 'conv5' weights[0]: 7.957609e-03 [8.234980e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.709154e-08] 
Layer 'fc6' weights[0]: 7.553697e-03 [9.840380e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.906156e-09] 
Layer 'fc7' weights[0]: 7.466024e-03 [1.219863e-07] 
Layer 'fc7' biases: 9.998528e-01 [1.057373e-07] 
Layer 'fc8' weights[0]: 5.817319e-04 [5.556885e-06] 
Layer 'fc8' biases: 1.626135e-01 [1.121514e-04] 
Train error last 27 batches: 0.635720
-------------------------------------------------------
Not saving because 0.643505 > 0.627087 (334.9: -0.00%)
======================================================= (5.082 sec)
373.21... logprob:  0.643436, 0.343750 (0.663 sec)
373.22... logprob:  0.627954, 0.320312 (0.663 sec)
373.23... logprob:  0.623075, 0.312500 (0.662 sec)
373.24... logprob:  0.577540, 0.242188 (0.663 sec)
373.25... logprob:  0.628113, 0.320312 (0.662 sec)
373.26... logprob:  0.674190, 0.390625 (0.663 sec)
373.27... logprob:  0.627984, 0.320312 (0.664 sec)
374.1... logprob:  0.679622, 0.398438 (0.664 sec)
374.2... logprob:  0.596965, 0.273438 (0.665 sec)
374.3... logprob:  0.653812, 0.359375 (0.664 sec)
374.4... logprob:  0.596627, 0.273438 (0.664 sec)
374.5... logprob:  0.590919, 0.265625 (0.665 sec)
374.6... logprob:  0.611416, 0.296875 (0.664 sec)
374.7... logprob:  0.643817, 0.343750 (0.664 sec)
374.8... logprob:  0.604891, 0.289062 (0.665 sec)
374.9... logprob:  0.638524, 0.335938 (0.663 sec)
374.10... logprob:  0.598055, 0.281250 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644824, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.939736e-03 [7.051089e-09] 
Layer 'conv1' biases: 5.735457e-07 [1.450248e-10] 
Layer 'conv2' weights[0]: 7.927652e-03 [6.278038e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.464985e-10] 
Layer 'conv3' weights[0]: 7.925318e-03 [6.105666e-09] 
Layer 'conv3' biases: 4.779272e-06 [2.237874e-09] 
Layer 'conv4' weights[0]: 7.958170e-03 [6.263975e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.942355e-08] 
Layer 'conv5' weights[0]: 7.957547e-03 [1.100387e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.168252e-07] 
Layer 'fc6' weights[0]: 7.553632e-03 [1.231653e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.175977e-08] 
Layer 'fc7' weights[0]: 7.465364e-03 [1.505881e-07] 
Layer 'fc7' biases: 9.998536e-01 [1.368244e-07] 
Layer 'fc8' weights[0]: 6.174296e-04 [7.329987e-06] 
Layer 'fc8' biases: 1.637100e-01 [1.704096e-04] 
Train error last 27 batches: 0.635720
-------------------------------------------------------
Not saving because 0.644824 > 0.627087 (334.9: -0.00%)
======================================================= (5.073 sec)
374.11... logprob:  0.638833, 0.335938 (0.663 sec)
374.12... logprob:  0.717372, 0.437500 (0.665 sec)
374.13... logprob:  0.657185, 0.359375 (0.663 sec)
374.14... logprob:  0.662800, 0.367188 (0.664 sec)
374.15... logprob:  0.685855, 0.398438 (0.663 sec)
374.16... logprob:  0.627074, 0.320312 (0.663 sec)
374.17... logprob:  0.638507, 0.335938 (0.664 sec)
374.18... logprob:  0.638221, 0.335938 (0.661 sec)
374.19... logprob:  0.632709, 0.328125 (0.662 sec)
374.20... logprob:  0.648895, 0.351562 (0.663 sec)
374.21... logprob:  0.643436, 0.343750 (0.660 sec)
374.22... logprob:  0.627952, 0.320312 (0.663 sec)
374.23... logprob:  0.623072, 0.312500 (0.664 sec)
374.24... logprob:  0.577528, 0.242188 (0.662 sec)
374.25... logprob:  0.628111, 0.320312 (0.663 sec)
374.26... logprob:  0.674195, 0.390625 (0.663 sec)
374.27... logprob:  0.627982, 0.320312 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643468, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.939669e-03 [6.619822e-09] 
Layer 'conv1' biases: 5.751259e-07 [7.048868e-11] 
Layer 'conv2' weights[0]: 7.927594e-03 [4.910569e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.597298e-10] 
Layer 'conv3' weights[0]: 7.925256e-03 [4.458433e-09] 
Layer 'conv3' biases: 4.793344e-06 [7.055370e-10] 
Layer 'conv4' weights[0]: 7.958114e-03 [4.380680e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.642260e-09] 
Layer 'conv5' weights[0]: 7.957468e-03 [2.133136e-08] 
Layer 'conv5' biases: 1.000002e+00 [2.208055e-08] 
Layer 'fc6' weights[0]: 7.553576e-03 [4.494165e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.208985e-09] 
Layer 'fc7' weights[0]: 7.464712e-03 [5.090796e-08] 
Layer 'fc7' biases: 9.998528e-01 [2.641134e-08] 
Layer 'fc8' weights[0]: 5.777557e-04 [1.352377e-06] 
Layer 'fc8' biases: 1.629460e-01 [4.239240e-05] 
Train error last 27 batches: 0.635718
-------------------------------------------------------
Not saving because 0.643468 > 0.627087 (334.9: -0.00%)
======================================================= (5.152 sec)
375.1... logprob:  0.679627, 0.398438 (0.664 sec)
375.2... logprob:  0.596959, 0.273438 (0.664 sec)
375.3... logprob:  0.653812, 0.359375 (0.663 sec)
375.4... logprob:  0.596623, 0.273438 (0.662 sec)
375.5... logprob:  0.590917, 0.265625 (0.664 sec)
375.6... logprob:  0.611416, 0.296875 (0.664 sec)
375.7... logprob:  0.643816, 0.343750 (0.662 sec)
375.8... logprob:  0.604893, 0.289062 (0.664 sec)
375.9... logprob:  0.638523, 0.335938 (0.664 sec)
375.10... logprob:  0.598059, 0.281250 (0.663 sec)
375.11... logprob:  0.638831, 0.335938 (0.665 sec)
375.12... logprob:  0.717354, 0.437500 (0.664 sec)
375.13... logprob:  0.657179, 0.359375 (0.664 sec)
375.14... logprob:  0.662794, 0.367188 (0.665 sec)
375.15... logprob:  0.685848, 0.398438 (0.663 sec)
375.16... logprob:  0.627074, 0.320312 (0.660 sec)
375.17... logprob:  0.638507, 0.335938 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643841, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.939606e-03 [6.466343e-09] 
Layer 'conv1' biases: 5.761298e-07 [1.715031e-10] 
Layer 'conv2' weights[0]: 7.927535e-03 [6.880134e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.704718e-10] 
Layer 'conv3' weights[0]: 7.925190e-03 [6.036505e-09] 
Layer 'conv3' biases: 4.800836e-06 [2.368825e-09] 
Layer 'conv4' weights[0]: 7.958050e-03 [6.079073e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.757473e-08] 
Layer 'conv5' weights[0]: 7.957407e-03 [9.903172e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.049657e-07] 
Layer 'fc6' weights[0]: 7.553505e-03 [1.128329e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.066730e-08] 
Layer 'fc7' weights[0]: 7.464075e-03 [1.390648e-07] 
Layer 'fc7' biases: 9.998531e-01 [1.249204e-07] 
Layer 'fc8' weights[0]: 5.961237e-04 [6.661085e-06] 
Layer 'fc8' biases: 1.636293e-01 [1.321986e-04] 
Train error last 27 batches: 0.635716
-------------------------------------------------------
Not saving because 0.643841 > 0.627087 (334.9: -0.00%)
======================================================= (5.055 sec)
375.18... logprob:  0.638222, 0.335938 (0.663 sec)
375.19... logprob:  0.632709, 0.328125 (0.662 sec)
375.20... logprob:  0.648898, 0.351562 (0.663 sec)
375.21... logprob:  0.643437, 0.343750 (0.663 sec)
375.22... logprob:  0.627949, 0.320312 (0.668 sec)
375.23... logprob:  0.623066, 0.312500 (0.659 sec)
375.24... logprob:  0.577511, 0.242188 (0.666 sec)
375.25... logprob:  0.628107, 0.320312 (0.666 sec)
375.26... logprob:  0.674201, 0.390625 (0.663 sec)
375.27... logprob:  0.627979, 0.320312 (0.667 sec)
376.1... logprob:  0.679632, 0.398438 (0.667 sec)
376.2... logprob:  0.596953, 0.273438 (0.665 sec)
376.3... logprob:  0.653814, 0.359375 (0.668 sec)
376.4... logprob:  0.596621, 0.273438 (0.667 sec)
376.5... logprob:  0.590915, 0.265625 (0.666 sec)
376.6... logprob:  0.611416, 0.296875 (0.666 sec)
376.7... logprob:  0.643816, 0.343750 (0.666 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643929, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.939542e-03 [6.830713e-09] 
Layer 'conv1' biases: 5.772573e-07 [1.269955e-10] 
Layer 'conv2' weights[0]: 7.927468e-03 [5.804932e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.152335e-10] 
Layer 'conv3' weights[0]: 7.925127e-03 [5.622152e-09] 
Layer 'conv3' biases: 4.809831e-06 [1.869902e-09] 
Layer 'conv4' weights[0]: 7.957983e-03 [5.703673e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.599296e-08] 
Layer 'conv5' weights[0]: 7.957335e-03 [9.001155e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.528203e-08] 
Layer 'fc6' weights[0]: 7.553446e-03 [1.043977e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.649125e-09] 
Layer 'fc7' weights[0]: 7.463428e-03 [1.288380e-07] 
Layer 'fc7' biases: 9.998531e-01 [1.131171e-07] 
Layer 'fc8' weights[0]: 5.985331e-04 [5.978653e-06] 
Layer 'fc8' biases: 1.638947e-01 [1.453977e-04] 
Train error last 27 batches: 0.635715
-------------------------------------------------------
Not saving because 0.643929 > 0.627087 (334.9: -0.00%)
======================================================= (5.083 sec)
376.8... logprob:  0.604897, 0.289062 (0.667 sec)
376.9... logprob:  0.638522, 0.335938 (0.665 sec)
376.10... logprob:  0.598066, 0.281250 (0.665 sec)
376.11... logprob:  0.638827, 0.335938 (0.665 sec)
376.12... logprob:  0.717328, 0.437500 (0.664 sec)
376.13... logprob:  0.657170, 0.359375 (0.665 sec)
376.14... logprob:  0.662785, 0.367188 (0.665 sec)
376.15... logprob:  0.685837, 0.398438 (0.664 sec)
376.16... logprob:  0.627074, 0.320312 (0.664 sec)
376.17... logprob:  0.638506, 0.335938 (0.664 sec)
376.18... logprob:  0.638221, 0.335938 (0.663 sec)
376.19... logprob:  0.632708, 0.328125 (0.659 sec)
376.20... logprob:  0.648898, 0.351562 (0.662 sec)
376.21... logprob:  0.643437, 0.343750 (0.663 sec)
376.22... logprob:  0.627947, 0.320312 (0.663 sec)
376.23... logprob:  0.623063, 0.312500 (0.661 sec)
376.24... logprob:  0.577497, 0.242188 (0.663 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643444, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.939478e-03 [6.512786e-09] 
Layer 'conv1' biases: 5.787252e-07 [6.032746e-11] 
Layer 'conv2' weights[0]: 7.927397e-03 [4.876061e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.035112e-10] 
Layer 'conv3' weights[0]: 7.925068e-03 [4.529533e-09] 
Layer 'conv3' biases: 4.822213e-06 [8.487857e-10] 
Layer 'conv4' weights[0]: 7.957924e-03 [4.470021e-09] 
Layer 'conv4' biases: 1.000001e+00 [6.028251e-09] 
Layer 'conv5' weights[0]: 7.957264e-03 [3.397508e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.565220e-08] 
Layer 'fc6' weights[0]: 7.553382e-03 [5.331099e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.604397e-09] 
Layer 'fc7' weights[0]: 7.462760e-03 [6.439885e-08] 
Layer 'fc7' biases: 9.998527e-01 [4.293634e-08] 
Layer 'fc8' weights[0]: 5.730944e-04 [2.204204e-06] 
Layer 'fc8' biases: 1.634680e-01 [6.677880e-05] 
Train error last 27 batches: 0.635712
-------------------------------------------------------
Not saving because 0.643444 > 0.627087 (334.9: -0.00%)
======================================================= (5.125 sec)
376.25... logprob:  0.628104, 0.320312 (0.663 sec)
376.26... logprob:  0.674206, 0.390625 (0.662 sec)
376.27... logprob:  0.627977, 0.320312 (0.664 sec)
377.1... logprob:  0.679638, 0.398438 (0.664 sec)
377.2... logprob:  0.596946, 0.273438 (0.661 sec)
377.3... logprob:  0.653815, 0.359375 (0.663 sec)
377.4... logprob:  0.596614, 0.273438 (0.665 sec)
377.5... logprob:  0.590911, 0.265625 (0.664 sec)
377.6... logprob:  0.611415, 0.296875 (0.663 sec)
377.7... logprob:  0.643815, 0.343750 (0.664 sec)
377.8... logprob:  0.604897, 0.289062 (0.664 sec)
377.9... logprob:  0.638521, 0.335938 (0.665 sec)
377.10... logprob:  0.598069, 0.281250 (0.665 sec)
377.11... logprob:  0.638825, 0.335938 (0.665 sec)
377.12... logprob:  0.717311, 0.437500 (0.665 sec)
377.13... logprob:  0.657164, 0.359375 (0.664 sec)
377.14... logprob:  0.662779, 0.367188 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644704, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.939401e-03 [6.776468e-09] 
Layer 'conv1' biases: 5.794909e-07 [1.505122e-10] 
Layer 'conv2' weights[0]: 7.927327e-03 [6.229802e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.773572e-10] 
Layer 'conv3' weights[0]: 7.925005e-03 [5.434372e-09] 
Layer 'conv3' biases: 4.826659e-06 [1.868262e-09] 
Layer 'conv4' weights[0]: 7.957855e-03 [5.398474e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.233779e-08] 
Layer 'conv5' weights[0]: 7.957218e-03 [6.959198e-08] 
Layer 'conv5' biases: 1.000002e+00 [7.364334e-08] 
Layer 'fc6' weights[0]: 7.553312e-03 [8.505889e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.477181e-09] 
Layer 'fc7' weights[0]: 7.462102e-03 [1.053426e-07] 
Layer 'fc7' biases: 9.998534e-01 [8.789679e-08] 
Layer 'fc8' weights[0]: 6.144439e-04 [4.670908e-06] 
Layer 'fc8' biases: 1.647238e-01 [8.647665e-05] 
Train error last 27 batches: 0.635711
-------------------------------------------------------
Not saving because 0.644704 > 0.627087 (334.9: -0.00%)
======================================================= (5.075 sec)
377.15... logprob:  0.685830, 0.398438 (0.663 sec)
377.16... logprob:  0.627074, 0.320312 (0.661 sec)
377.17... logprob:  0.638506, 0.335938 (0.664 sec)
377.18... logprob:  0.638221, 0.335938 (0.663 sec)
377.19... logprob:  0.632708, 0.328125 (0.663 sec)
377.20... logprob:  0.648899, 0.351562 (0.663 sec)
377.21... logprob:  0.643438, 0.343750 (0.663 sec)
377.22... logprob:  0.627944, 0.320312 (0.664 sec)
377.23... logprob:  0.623060, 0.312500 (0.663 sec)
377.24... logprob:  0.577486, 0.242188 (0.663 sec)
377.25... logprob:  0.628102, 0.320312 (0.662 sec)
377.26... logprob:  0.674210, 0.390625 (0.663 sec)
377.27... logprob:  0.627975, 0.320312 (0.664 sec)
378.1... logprob:  0.679642, 0.398438 (0.665 sec)
378.2... logprob:  0.596941, 0.273438 (0.665 sec)
378.3... logprob:  0.653816, 0.359375 (0.665 sec)
378.4... logprob:  0.596612, 0.273438 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643512, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.939336e-03 [6.873009e-09] 
Layer 'conv1' biases: 5.809872e-07 [8.906029e-11] 
Layer 'conv2' weights[0]: 7.927256e-03 [5.305194e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.621704e-10] 
Layer 'conv3' weights[0]: 7.924939e-03 [4.961863e-09] 
Layer 'conv3' biases: 4.839870e-06 [1.217485e-09] 
Layer 'conv4' weights[0]: 7.957790e-03 [4.909452e-09] 
Layer 'conv4' biases: 1.000001e+00 [9.133231e-09] 
Layer 'conv5' weights[0]: 7.957142e-03 [5.192395e-08] 
Layer 'conv5' biases: 1.000002e+00 [5.473967e-08] 
Layer 'fc6' weights[0]: 7.553242e-03 [6.809586e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.539066e-09] 
Layer 'fc7' weights[0]: 7.461428e-03 [8.403895e-08] 
Layer 'fc7' biases: 9.998528e-01 [6.513461e-08] 
Layer 'fc8' weights[0]: 5.809597e-04 [3.418791e-06] 
Layer 'fc8' biases: 1.640913e-01 [8.799302e-05] 
Train error last 27 batches: 0.635710
-------------------------------------------------------
Not saving because 0.643512 > 0.627087 (334.9: -0.00%)
======================================================= (5.104 sec)
378.5... logprob:  0.590908, 0.265625 (0.663 sec)
378.6... logprob:  0.611415, 0.296875 (0.663 sec)
378.7... logprob:  0.643815, 0.343750 (0.660 sec)
378.8... logprob:  0.604899, 0.289062 (0.665 sec)
378.9... logprob:  0.638520, 0.335938 (0.665 sec)
378.10... logprob:  0.598074, 0.281250 (0.665 sec)
378.11... logprob:  0.638823, 0.335938 (0.665 sec)
378.12... logprob:  0.717292, 0.437500 (0.664 sec)
378.13... logprob:  0.657158, 0.359375 (0.664 sec)
378.14... logprob:  0.662773, 0.367188 (0.664 sec)
378.15... logprob:  0.685824, 0.398438 (0.662 sec)
378.16... logprob:  0.627074, 0.320312 (0.666 sec)
378.17... logprob:  0.638506, 0.335938 (0.664 sec)
378.18... logprob:  0.638221, 0.335938 (0.663 sec)
378.19... logprob:  0.632708, 0.328125 (0.664 sec)
378.20... logprob:  0.648901, 0.351562 (0.662 sec)
378.21... logprob:  0.643439, 0.343750 (0.660 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643462, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.939257e-03 [6.844723e-09] 
Layer 'conv1' biases: 5.822340e-07 [1.560210e-10] 
Layer 'conv2' weights[0]: 7.927194e-03 [6.515181e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.414061e-10] 
Layer 'conv3' weights[0]: 7.924869e-03 [5.671809e-09] 
Layer 'conv3' biases: 4.850045e-06 [2.022388e-09] 
Layer 'conv4' weights[0]: 7.957724e-03 [5.584313e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.361815e-08] 
Layer 'conv5' weights[0]: 7.957068e-03 [7.708424e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.145612e-08] 
Layer 'fc6' weights[0]: 7.553173e-03 [9.338405e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.351804e-09] 
Layer 'fc7' weights[0]: 7.460800e-03 [1.159747e-07] 
Layer 'fc7' biases: 9.998527e-01 [9.918756e-08] 
Layer 'fc8' weights[0]: 5.758569e-04 [5.181918e-06] 
Layer 'fc8' biases: 1.641833e-01 [1.063253e-04] 
Train error last 27 batches: 0.635709
-------------------------------------------------------
Not saving because 0.643462 > 0.627087 (334.9: -0.00%)
======================================================= (5.065 sec)
378.22... logprob:  0.627942, 0.320312 (0.663 sec)
378.23... logprob:  0.623054, 0.312500 (0.663 sec)
378.24... logprob:  0.577468, 0.242188 (0.659 sec)
378.25... logprob:  0.628099, 0.320312 (0.660 sec)
378.26... logprob:  0.674218, 0.390625 (0.662 sec)
378.27... logprob:  0.627972, 0.320312 (0.664 sec)
379.1... logprob:  0.679649, 0.398438 (0.664 sec)
379.2... logprob:  0.596935, 0.273438 (0.662 sec)
379.3... logprob:  0.653818, 0.359375 (0.663 sec)
379.4... logprob:  0.596608, 0.273438 (0.664 sec)
379.5... logprob:  0.590907, 0.265625 (0.664 sec)
379.6... logprob:  0.611416, 0.296875 (0.663 sec)
379.7... logprob:  0.643814, 0.343750 (0.664 sec)
379.8... logprob:  0.604904, 0.289062 (0.666 sec)
379.9... logprob:  0.638519, 0.335938 (0.665 sec)
379.10... logprob:  0.598082, 0.281250 (0.664 sec)
379.11... logprob:  0.638819, 0.335938 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.645143, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.939193e-03 [6.808937e-09] 
Layer 'conv1' biases: 5.829531e-07 [1.189891e-10] 
Layer 'conv2' weights[0]: 7.927125e-03 [5.750078e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.745703e-10] 
Layer 'conv3' weights[0]: 7.924801e-03 [5.570732e-09] 
Layer 'conv3' biases: 4.853736e-06 [1.799674e-09] 
Layer 'conv4' weights[0]: 7.957656e-03 [5.661988e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.527846e-08] 
Layer 'conv5' weights[0]: 7.957031e-03 [8.710246e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.255487e-08] 
Layer 'fc6' weights[0]: 7.553107e-03 [1.013835e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.280914e-09] 
Layer 'fc7' weights[0]: 7.460131e-03 [1.239853e-07] 
Layer 'fc7' biases: 9.998533e-01 [1.072423e-07] 
Layer 'fc8' weights[0]: 6.206584e-04 [5.760748e-06] 
Layer 'fc8' biases: 1.655152e-01 [1.365855e-04] 
Train error last 27 batches: 0.635708
-------------------------------------------------------
Not saving because 0.645143 > 0.627087 (334.9: -0.00%)
======================================================= (5.070 sec)
379.12... logprob:  0.717262, 0.437500 (0.664 sec)
379.13... logprob:  0.657148, 0.359375 (0.664 sec)
379.14... logprob:  0.662763, 0.367188 (0.667 sec)
379.15... logprob:  0.685810, 0.398438 (0.662 sec)
379.16... logprob:  0.627074, 0.320312 (0.663 sec)
379.17... logprob:  0.638506, 0.335938 (0.664 sec)
379.18... logprob:  0.638221, 0.335938 (0.662 sec)
379.19... logprob:  0.632708, 0.328125 (0.663 sec)
379.20... logprob:  0.648901, 0.351562 (0.663 sec)
379.21... logprob:  0.643439, 0.343750 (0.662 sec)
379.22... logprob:  0.627939, 0.320312 (0.662 sec)
379.23... logprob:  0.623051, 0.312500 (0.664 sec)
379.24... logprob:  0.577454, 0.242188 (0.663 sec)
379.25... logprob:  0.628096, 0.320312 (0.664 sec)
379.26... logprob:  0.674224, 0.390625 (0.662 sec)
379.27... logprob:  0.627969, 0.320312 (0.663 sec)
380.1... logprob:  0.679655, 0.398438 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643461, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.939123e-03 [6.670828e-09] 
Layer 'conv1' biases: 5.845772e-07 [8.317921e-11] 
Layer 'conv2' weights[0]: 7.927066e-03 [5.168573e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.348811e-10] 
Layer 'conv3' weights[0]: 7.924737e-03 [4.504664e-09] 
Layer 'conv3' biases: 4.868434e-06 [8.520890e-10] 
Layer 'conv4' weights[0]: 7.957593e-03 [4.410135e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.373623e-09] 
Layer 'conv5' weights[0]: 7.956935e-03 [1.904019e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.958504e-08] 
Layer 'fc6' weights[0]: 7.553044e-03 [4.399229e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.076857e-09] 
Layer 'fc7' weights[0]: 7.459523e-03 [4.986101e-08] 
Layer 'fc7' biases: 9.998526e-01 [2.567758e-08] 
Layer 'fc8' weights[0]: 5.752844e-04 [1.285284e-06] 
Layer 'fc8' biases: 1.645967e-01 [2.077159e-05] 
Train error last 27 batches: 0.635705
-------------------------------------------------------
Not saving because 0.643461 > 0.627087 (334.9: -0.00%)
======================================================= (5.155 sec)
380.2... logprob:  0.596927, 0.273438 (0.663 sec)
380.3... logprob:  0.653820, 0.359375 (0.663 sec)
380.4... logprob:  0.596603, 0.273438 (0.664 sec)
380.5... logprob:  0.590902, 0.265625 (0.663 sec)
380.6... logprob:  0.611414, 0.296875 (0.665 sec)
380.7... logprob:  0.643814, 0.343750 (0.663 sec)
380.8... logprob:  0.604905, 0.289062 (0.664 sec)
380.9... logprob:  0.638518, 0.335938 (0.663 sec)
380.10... logprob:  0.598084, 0.281250 (0.664 sec)
380.11... logprob:  0.638817, 0.335938 (0.664 sec)
380.12... logprob:  0.717247, 0.437500 (0.664 sec)
380.13... logprob:  0.657144, 0.359375 (0.664 sec)
380.14... logprob:  0.662758, 0.367188 (0.662 sec)
380.15... logprob:  0.685804, 0.398438 (0.663 sec)
380.16... logprob:  0.627075, 0.320312 (0.663 sec)
380.17... logprob:  0.638506, 0.335938 (0.664 sec)
380.18... logprob:  0.638221, 0.335938 (0.663 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643687, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.939055e-03 [6.524242e-09] 
Layer 'conv1' biases: 5.856379e-07 [1.737649e-10] 
Layer 'conv2' weights[0]: 7.926990e-03 [6.732654e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.375571e-10] 
Layer 'conv3' weights[0]: 7.924680e-03 [5.910970e-09] 
Layer 'conv3' biases: 4.876416e-06 [2.280375e-09] 
Layer 'conv4' weights[0]: 7.957524e-03 [5.894913e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.629863e-08] 
Layer 'conv5' weights[0]: 7.956883e-03 [9.230183e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.760635e-08] 
Layer 'fc6' weights[0]: 7.552975e-03 [1.062567e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.913156e-09] 
Layer 'fc7' weights[0]: 7.458879e-03 [1.313921e-07] 
Layer 'fc7' biases: 9.998529e-01 [1.165795e-07] 
Layer 'fc8' weights[0]: 5.891474e-04 [6.164967e-06] 
Layer 'fc8' biases: 1.651745e-01 [1.240524e-04] 
Train error last 27 batches: 0.635703
-------------------------------------------------------
Not saving because 0.643687 > 0.627087 (334.9: -0.00%)
======================================================= (5.065 sec)
380.19... logprob:  0.632707, 0.328125 (0.664 sec)
380.20... logprob:  0.648903, 0.351562 (0.663 sec)
380.21... logprob:  0.643439, 0.343750 (0.661 sec)
380.22... logprob:  0.627937, 0.320312 (0.661 sec)
380.23... logprob:  0.623046, 0.312500 (0.663 sec)
380.24... logprob:  0.577440, 0.242188 (0.663 sec)
380.25... logprob:  0.628093, 0.320312 (0.663 sec)
380.26... logprob:  0.674228, 0.390625 (0.661 sec)
380.27... logprob:  0.627968, 0.320312 (0.662 sec)
381.1... logprob:  0.679659, 0.398438 (0.664 sec)
381.2... logprob:  0.596923, 0.273438 (0.664 sec)
381.3... logprob:  0.653820, 0.359375 (0.664 sec)
381.4... logprob:  0.596601, 0.273438 (0.664 sec)
381.5... logprob:  0.590901, 0.265625 (0.660 sec)
381.6... logprob:  0.611415, 0.296875 (0.663 sec)
381.7... logprob:  0.643813, 0.343750 (0.664 sec)
381.8... logprob:  0.604908, 0.289062 (0.665 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644175, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938988e-03 [7.176890e-09] 
Layer 'conv1' biases: 5.866516e-07 [1.447159e-10] 
Layer 'conv2' weights[0]: 7.926931e-03 [6.292949e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.509223e-10] 
Layer 'conv3' weights[0]: 7.924626e-03 [6.080653e-09] 
Layer 'conv3' biases: 4.883905e-06 [2.222765e-09] 
Layer 'conv4' weights[0]: 7.957465e-03 [6.189395e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.902254e-08] 
Layer 'conv5' weights[0]: 7.956807e-03 [1.074940e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.137972e-07] 
Layer 'fc6' weights[0]: 7.552908e-03 [1.204941e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.147655e-08] 
Layer 'fc7' weights[0]: 7.458230e-03 [1.480196e-07] 
Layer 'fc7' biases: 9.998531e-01 [1.342246e-07] 
Layer 'fc8' weights[0]: 6.030989e-04 [7.105354e-06] 
Layer 'fc8' biases: 1.657295e-01 [1.703879e-04] 
Train error last 27 batches: 0.635703
-------------------------------------------------------
Not saving because 0.644175 > 0.627087 (334.9: -0.00%)
======================================================= (5.062 sec)
381.9... logprob:  0.638517, 0.335938 (0.665 sec)
381.10... logprob:  0.598090, 0.281250 (0.663 sec)
381.11... logprob:  0.638814, 0.335938 (0.665 sec)
381.12... logprob:  0.717224, 0.437500 (0.665 sec)
381.13... logprob:  0.657136, 0.359375 (0.665 sec)
381.14... logprob:  0.662750, 0.367188 (0.663 sec)
381.15... logprob:  0.685794, 0.398438 (0.663 sec)
381.16... logprob:  0.627075, 0.320312 (0.661 sec)
381.17... logprob:  0.638506, 0.335938 (0.665 sec)
381.18... logprob:  0.638221, 0.335938 (0.661 sec)
381.19... logprob:  0.632707, 0.328125 (0.659 sec)
381.20... logprob:  0.648903, 0.351562 (0.662 sec)
381.21... logprob:  0.643439, 0.343750 (0.662 sec)
381.22... logprob:  0.627934, 0.320312 (0.663 sec)
381.23... logprob:  0.623044, 0.312500 (0.660 sec)
381.24... logprob:  0.577428, 0.242188 (0.661 sec)
381.25... logprob:  0.628090, 0.320312 (0.663 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643457, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938922e-03 [6.587142e-09] 
Layer 'conv1' biases: 5.881408e-07 [6.810061e-11] 
Layer 'conv2' weights[0]: 7.926870e-03 [4.951067e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.590424e-10] 
Layer 'conv3' weights[0]: 7.924567e-03 [4.648154e-09] 
Layer 'conv3' biases: 4.896555e-06 [1.014663e-09] 
Layer 'conv4' weights[0]: 7.957402e-03 [4.635719e-09] 
Layer 'conv4' biases: 1.000001e+00 [7.788686e-09] 
Layer 'conv5' weights[0]: 7.956736e-03 [4.384268e-08] 
Layer 'conv5' biases: 1.000002e+00 [4.614710e-08] 
Layer 'fc6' weights[0]: 7.552844e-03 [6.118222e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.692981e-09] 
Layer 'fc7' weights[0]: 7.457572e-03 [7.524752e-08] 
Layer 'fc7' biases: 9.998526e-01 [5.564419e-08] 
Layer 'fc8' weights[0]: 5.742260e-04 [2.864814e-06] 
Layer 'fc8' biases: 1.652172e-01 [8.164771e-05] 
Train error last 27 batches: 0.635700
-------------------------------------------------------
Not saving because 0.643457 > 0.627087 (334.9: -0.00%)
======================================================= (5.112 sec)
381.26... logprob:  0.674233, 0.390625 (0.662 sec)
381.27... logprob:  0.627966, 0.320312 (0.664 sec)
382.1... logprob:  0.679665, 0.398438 (0.664 sec)
382.2... logprob:  0.596916, 0.273438 (0.663 sec)
382.3... logprob:  0.653822, 0.359375 (0.662 sec)
382.4... logprob:  0.596596, 0.273438 (0.664 sec)
382.5... logprob:  0.590898, 0.265625 (0.664 sec)
382.6... logprob:  0.611413, 0.296875 (0.664 sec)
382.7... logprob:  0.643814, 0.343750 (0.664 sec)
382.8... logprob:  0.604909, 0.289062 (0.665 sec)
382.9... logprob:  0.638516, 0.335938 (0.664 sec)
382.10... logprob:  0.598093, 0.281250 (0.664 sec)
382.11... logprob:  0.638813, 0.335938 (0.664 sec)
382.12... logprob:  0.717209, 0.437500 (0.664 sec)
382.13... logprob:  0.657131, 0.359375 (0.664 sec)
382.14... logprob:  0.662744, 0.367188 (0.664 sec)
382.15... logprob:  0.685788, 0.398438 (0.660 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644319, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938851e-03 [7.340671e-09] 
Layer 'conv1' biases: 5.890065e-07 [2.060410e-10] 
Layer 'conv2' weights[0]: 7.926807e-03 [7.611712e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.022539e-09] 
Layer 'conv3' weights[0]: 7.924486e-03 [6.568273e-09] 
Layer 'conv3' biases: 4.902360e-06 [2.820215e-09] 
Layer 'conv4' weights[0]: 7.957330e-03 [6.622344e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.074120e-08] 
Layer 'conv5' weights[0]: 7.956663e-03 [1.172155e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.239769e-07] 
Layer 'fc6' weights[0]: 7.552783e-03 [1.300431e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.253416e-08] 
Layer 'fc7' weights[0]: 7.456917e-03 [1.591857e-07] 
Layer 'fc7' biases: 9.998531e-01 [1.463874e-07] 
Layer 'fc8' weights[0]: 6.057764e-04 [7.788314e-06] 
Layer 'fc8' biases: 1.662306e-01 [1.555808e-04] 
Train error last 27 batches: 0.635699
-------------------------------------------------------
Not saving because 0.644319 > 0.627087 (334.9: -0.00%)
======================================================= (5.046 sec)
382.16... logprob:  0.627075, 0.320312 (0.663 sec)
382.17... logprob:  0.638506, 0.335938 (0.664 sec)
382.18... logprob:  0.638221, 0.335938 (0.661 sec)
382.19... logprob:  0.632706, 0.328125 (0.659 sec)
382.20... logprob:  0.648904, 0.351562 (0.662 sec)
382.21... logprob:  0.643440, 0.343750 (0.663 sec)
382.22... logprob:  0.627932, 0.320312 (0.663 sec)
382.23... logprob:  0.623039, 0.312500 (0.663 sec)
382.24... logprob:  0.577415, 0.242188 (0.663 sec)
382.25... logprob:  0.628088, 0.320312 (0.663 sec)
382.26... logprob:  0.674238, 0.390625 (0.664 sec)
382.27... logprob:  0.627963, 0.320312 (0.664 sec)
383.1... logprob:  0.679669, 0.398438 (0.664 sec)
383.2... logprob:  0.596911, 0.273438 (0.664 sec)
383.3... logprob:  0.653823, 0.359375 (0.664 sec)
383.4... logprob:  0.596592, 0.273438 (0.663 sec)
383.5... logprob:  0.590896, 0.265625 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643603, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938784e-03 [7.491468e-09] 
Layer 'conv1' biases: 5.903706e-07 [1.384491e-10] 
Layer 'conv2' weights[0]: 7.926733e-03 [5.974589e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.466183e-10] 
Layer 'conv3' weights[0]: 7.924426e-03 [5.767207e-09] 
Layer 'conv3' biases: 4.914170e-06 [1.952273e-09] 
Layer 'conv4' weights[0]: 7.957266e-03 [5.793562e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.635749e-08] 
Layer 'conv5' weights[0]: 7.956597e-03 [9.247988e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.758222e-08] 
Layer 'fc6' weights[0]: 7.552723e-03 [1.064016e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.895698e-09] 
Layer 'fc7' weights[0]: 7.456270e-03 [1.313220e-07] 
Layer 'fc7' biases: 9.998528e-01 [1.160982e-07] 
Layer 'fc8' weights[0]: 5.847951e-04 [6.091673e-06] 
Layer 'fc8' biases: 1.659028e-01 [1.508895e-04] 
Train error last 27 batches: 0.635698
-------------------------------------------------------
Not saving because 0.643603 > 0.627087 (334.9: -0.00%)
======================================================= (5.073 sec)
383.6... logprob:  0.611414, 0.296875 (0.664 sec)
383.7... logprob:  0.643813, 0.343750 (0.664 sec)
383.8... logprob:  0.604911, 0.289062 (0.663 sec)
383.9... logprob:  0.638515, 0.335938 (0.665 sec)
383.10... logprob:  0.598098, 0.281250 (0.664 sec)
383.11... logprob:  0.638810, 0.335938 (0.662 sec)
383.12... logprob:  0.717188, 0.437500 (0.663 sec)
383.13... logprob:  0.657124, 0.359375 (0.664 sec)
383.14... logprob:  0.662737, 0.367188 (0.663 sec)
383.15... logprob:  0.685779, 0.398438 (0.664 sec)
383.16... logprob:  0.627075, 0.320312 (0.663 sec)
383.17... logprob:  0.638505, 0.335938 (0.664 sec)
383.18... logprob:  0.638221, 0.335938 (0.663 sec)
383.19... logprob:  0.632705, 0.328125 (0.664 sec)
383.20... logprob:  0.648905, 0.351562 (0.662 sec)
383.21... logprob:  0.643440, 0.343750 (0.662 sec)
383.22... logprob:  0.627930, 0.320312 (0.662 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643445, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938724e-03 [6.740834e-09] 
Layer 'conv1' biases: 5.917104e-07 [1.377156e-10] 
Layer 'conv2' weights[0]: 7.926677e-03 [6.088562e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.005696e-10] 
Layer 'conv3' weights[0]: 7.924355e-03 [5.288329e-09] 
Layer 'conv3' biases: 4.925482e-06 [1.621824e-09] 
Layer 'conv4' weights[0]: 7.957198e-03 [5.166979e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.002907e-08] 
Layer 'conv5' weights[0]: 7.956532e-03 [5.638634e-08] 
Layer 'conv5' biases: 1.000002e+00 [5.933621e-08] 
Layer 'fc6' weights[0]: 7.552655e-03 [7.298910e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.131147e-09] 
Layer 'fc7' weights[0]: 7.455653e-03 [9.070487e-08] 
Layer 'fc7' biases: 9.998524e-01 [7.291593e-08] 
Layer 'fc8' weights[0]: 5.713318e-04 [3.773957e-06] 
Layer 'fc8' biases: 1.657708e-01 [7.539601e-05] 
Train error last 27 batches: 0.635696
-------------------------------------------------------
Not saving because 0.643445 > 0.627087 (334.9: -0.00%)
======================================================= (5.086 sec)
383.23... logprob:  0.623036, 0.312500 (0.661 sec)
383.24... logprob:  0.577404, 0.242188 (0.662 sec)
383.25... logprob:  0.628085, 0.320312 (0.663 sec)
383.26... logprob:  0.674242, 0.390625 (0.663 sec)
383.27... logprob:  0.627962, 0.320312 (0.714 sec)
384.1... logprob:  0.679673, 0.398438 (0.671 sec)
384.2... logprob:  0.596906, 0.273438 (0.661 sec)
384.3... logprob:  0.653824, 0.359375 (0.662 sec)
384.4... logprob:  0.596588, 0.273438 (0.661 sec)
384.5... logprob:  0.590892, 0.265625 (0.661 sec)
384.6... logprob:  0.611413, 0.296875 (0.661 sec)
384.7... logprob:  0.643813, 0.343750 (0.660 sec)
384.8... logprob:  0.604912, 0.289062 (0.658 sec)
384.9... logprob:  0.638514, 0.335938 (0.661 sec)
384.10... logprob:  0.598102, 0.281250 (0.662 sec)
384.11... logprob:  0.638808, 0.335938 (0.664 sec)
384.12... logprob:  0.717173, 0.437500 (0.661 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.645088, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938657e-03 [6.927077e-09] 
Layer 'conv1' biases: 5.924147e-07 [8.332724e-11] 
Layer 'conv2' weights[0]: 7.926613e-03 [5.250270e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.177807e-10] 
Layer 'conv3' weights[0]: 7.924298e-03 [4.545716e-09] 
Layer 'conv3' biases: 4.928960e-06 [7.911350e-10] 
Layer 'conv4' weights[0]: 7.957137e-03 [4.403671e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.472945e-09] 
Layer 'conv5' weights[0]: 7.956465e-03 [9.334320e-09] 
Layer 'conv5' biases: 1.000002e+00 [8.780985e-09] 
Layer 'fc6' weights[0]: 7.552591e-03 [3.924250e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.663877e-10] 
Layer 'fc7' weights[0]: 7.455002e-03 [4.107901e-08] 
Layer 'fc7' biases: 9.998533e-01 [1.318690e-08] 
Layer 'fc8' weights[0]: 6.183352e-04 [5.951559e-07] 
Layer 'fc8' biases: 1.671741e-01 [2.027965e-06] 
Train error last 27 batches: 0.635695
-------------------------------------------------------
Not saving because 0.645088 > 0.627087 (334.9: -0.00%)
======================================================= (5.204 sec)
384.13... logprob:  0.657119, 0.359375 (0.667 sec)
384.14... logprob:  0.662733, 0.367188 (0.672 sec)
384.15... logprob:  0.685773, 0.398438 (0.660 sec)
384.16... logprob:  0.627075, 0.320312 (0.660 sec)
384.17... logprob:  0.638506, 0.335938 (0.660 sec)
384.18... logprob:  0.638221, 0.335938 (0.657 sec)
384.19... logprob:  0.632705, 0.328125 (0.663 sec)
384.20... logprob:  0.648906, 0.351562 (0.661 sec)
384.21... logprob:  0.643440, 0.343750 (0.660 sec)
384.22... logprob:  0.627928, 0.320312 (0.660 sec)
384.23... logprob:  0.623032, 0.312500 (0.675 sec)
384.24... logprob:  0.577389, 0.242188 (0.661 sec)
384.25... logprob:  0.628082, 0.320312 (0.666 sec)
384.26... logprob:  0.674248, 0.390625 (0.663 sec)
384.27... logprob:  0.627959, 0.320312 (0.673 sec)
385.1... logprob:  0.679680, 0.398438 (0.666 sec)
385.2... logprob:  0.596899, 0.273438 (0.662 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643473, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938599e-03 [6.879643e-09] 
Layer 'conv1' biases: 5.940249e-07 [7.193171e-11] 
Layer 'conv2' weights[0]: 7.926545e-03 [4.996959e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.868122e-10] 
Layer 'conv3' weights[0]: 7.924227e-03 [4.548176e-09] 
Layer 'conv3' biases: 4.943456e-06 [7.863286e-10] 
Layer 'conv4' weights[0]: 7.957074e-03 [4.452961e-09] 
Layer 'conv4' biases: 1.000001e+00 [4.519433e-09] 
Layer 'conv5' weights[0]: 7.956391e-03 [2.593236e-08] 
Layer 'conv5' biases: 1.000002e+00 [2.704673e-08] 
Layer 'fc6' weights[0]: 7.552521e-03 [4.791455e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.687246e-09] 
Layer 'fc7' weights[0]: 7.454383e-03 [5.541055e-08] 
Layer 'fc7' biases: 9.998525e-01 [3.181372e-08] 
Layer 'fc8' weights[0]: 5.753679e-04 [1.650897e-06] 
Layer 'fc8' biases: 1.663021e-01 [4.784638e-05] 
Train error last 27 batches: 0.635694
-------------------------------------------------------
Not saving because 0.643473 > 0.627087 (334.9: -0.00%)
======================================================= (5.119 sec)
385.3... logprob:  0.653826, 0.359375 (0.663 sec)
385.4... logprob:  0.596584, 0.273438 (0.664 sec)
385.5... logprob:  0.590890, 0.265625 (0.660 sec)
385.6... logprob:  0.611413, 0.296875 (0.662 sec)
385.7... logprob:  0.643812, 0.343750 (0.663 sec)
385.8... logprob:  0.604916, 0.289062 (0.664 sec)
385.9... logprob:  0.638514, 0.335938 (0.662 sec)
385.10... logprob:  0.598107, 0.281250 (0.664 sec)
385.11... logprob:  0.638804, 0.335938 (0.664 sec)
385.12... logprob:  0.717148, 0.437500 (0.665 sec)
385.13... logprob:  0.657111, 0.359375 (0.663 sec)
385.14... logprob:  0.662724, 0.367188 (0.664 sec)
385.15... logprob:  0.685763, 0.398438 (0.662 sec)
385.16... logprob:  0.627076, 0.320312 (0.662 sec)
385.17... logprob:  0.638506, 0.335938 (0.663 sec)
385.18... logprob:  0.638221, 0.335938 (0.661 sec)
385.19... logprob:  0.632705, 0.328125 (0.661 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643587, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938544e-03 [6.789463e-09] 
Layer 'conv1' biases: 5.951407e-07 [1.571759e-10] 
Layer 'conv2' weights[0]: 7.926469e-03 [6.564191e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.565277e-10] 
Layer 'conv3' weights[0]: 7.924160e-03 [5.693359e-09] 
Layer 'conv3' biases: 4.952044e-06 [2.051767e-09] 
Layer 'conv4' weights[0]: 7.957000e-03 [5.636362e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.398100e-08] 
Layer 'conv5' weights[0]: 7.956311e-03 [7.878593e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.322532e-08] 
Layer 'fc6' weights[0]: 7.552468e-03 [9.507620e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.536900e-09] 
Layer 'fc7' weights[0]: 7.453737e-03 [1.173535e-07] 
Layer 'fc7' biases: 9.998526e-01 [1.005399e-07] 
Layer 'fc8' weights[0]: 5.831309e-04 [5.257125e-06] 
Layer 'fc8' biases: 1.667250e-01 [1.061864e-04] 
Train error last 27 batches: 0.635692
-------------------------------------------------------
Not saving because 0.643587 > 0.627087 (334.9: -0.00%)
======================================================= (5.054 sec)
385.20... logprob:  0.648907, 0.351562 (0.661 sec)
385.21... logprob:  0.643441, 0.343750 (0.662 sec)
385.22... logprob:  0.627925, 0.320312 (0.664 sec)
385.23... logprob:  0.623028, 0.312500 (0.662 sec)
385.24... logprob:  0.577374, 0.242188 (0.663 sec)
385.25... logprob:  0.628079, 0.320312 (0.660 sec)
385.26... logprob:  0.674253, 0.390625 (0.662 sec)
385.27... logprob:  0.627956, 0.320312 (0.664 sec)
386.1... logprob:  0.679685, 0.398438 (0.663 sec)
386.2... logprob:  0.596894, 0.273438 (0.663 sec)
386.3... logprob:  0.653827, 0.359375 (0.665 sec)
386.4... logprob:  0.596580, 0.273438 (0.662 sec)
386.5... logprob:  0.590887, 0.265625 (0.662 sec)
386.6... logprob:  0.611413, 0.296875 (0.663 sec)
386.7... logprob:  0.643812, 0.343750 (0.662 sec)
386.8... logprob:  0.604918, 0.289062 (0.664 sec)
386.9... logprob:  0.638513, 0.335938 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644418, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938485e-03 [6.712006e-09] 
Layer 'conv1' biases: 5.960664e-07 [1.199805e-10] 
Layer 'conv2' weights[0]: 7.926408e-03 [5.836583e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.063332e-10] 
Layer 'conv3' weights[0]: 7.924085e-03 [5.664409e-09] 
Layer 'conv3' biases: 4.958479e-06 [1.857197e-09] 
Layer 'conv4' weights[0]: 7.956931e-03 [5.764061e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.582486e-08] 
Layer 'conv5' weights[0]: 7.956259e-03 [8.894502e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.420182e-08] 
Layer 'fc6' weights[0]: 7.552406e-03 [1.036732e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.552061e-09] 
Layer 'fc7' weights[0]: 7.453090e-03 [1.270910e-07] 
Layer 'fc7' biases: 9.998531e-01 [1.110858e-07] 
Layer 'fc8' weights[0]: 6.065781e-04 [5.869962e-06] 
Layer 'fc8' biases: 1.675232e-01 [1.427908e-04] 
Train error last 27 batches: 0.635691
-------------------------------------------------------
Not saving because 0.644418 > 0.627087 (334.9: -0.00%)
======================================================= (5.052 sec)
386.10... logprob:  0.598113, 0.281250 (0.664 sec)
386.11... logprob:  0.638803, 0.335938 (0.665 sec)
386.12... logprob:  0.717126, 0.437500 (0.664 sec)
386.13... logprob:  0.657104, 0.359375 (0.663 sec)
386.14... logprob:  0.662717, 0.367188 (0.663 sec)
386.15... logprob:  0.685754, 0.398438 (0.661 sec)
386.16... logprob:  0.627076, 0.320312 (0.662 sec)
386.17... logprob:  0.638505, 0.335938 (0.663 sec)
386.18... logprob:  0.638221, 0.335938 (0.662 sec)
386.19... logprob:  0.632705, 0.328125 (0.661 sec)
386.20... logprob:  0.648908, 0.351562 (0.662 sec)
386.21... logprob:  0.643442, 0.343750 (0.663 sec)
386.22... logprob:  0.627923, 0.320312 (0.662 sec)
386.23... logprob:  0.623024, 0.312500 (0.662 sec)
386.24... logprob:  0.577358, 0.242188 (0.660 sec)
386.25... logprob:  0.628076, 0.320312 (0.662 sec)
386.26... logprob:  0.674260, 0.390625 (0.661 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643462, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938412e-03 [6.558144e-09] 
Layer 'conv1' biases: 5.975992e-07 [7.162460e-11] 
Layer 'conv2' weights[0]: 7.926343e-03 [5.036044e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.443660e-10] 
Layer 'conv3' weights[0]: 7.924018e-03 [4.418266e-09] 
Layer 'conv3' biases: 4.971871e-06 [6.039984e-10] 
Layer 'conv4' weights[0]: 7.956874e-03 [4.320330e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.398599e-09] 
Layer 'conv5' weights[0]: 7.956169e-03 [8.877850e-09] 
Layer 'conv5' biases: 1.000002e+00 [8.369400e-09] 
Layer 'fc6' weights[0]: 7.552338e-03 [3.903732e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.590298e-10] 
Layer 'fc7' weights[0]: 7.452442e-03 [3.999886e-08] 
Layer 'fc7' biases: 9.998523e-01 [1.044087e-08] 
Layer 'fc8' weights[0]: 5.733286e-04 [5.076461e-07] 
Layer 'fc8' biases: 1.668938e-01 [2.314749e-05] 
Train error last 27 batches: 0.635689
-------------------------------------------------------
Not saving because 0.643462 > 0.627087 (334.9: -0.00%)
======================================================= (5.177 sec)
386.27... logprob:  0.627954, 0.320312 (0.664 sec)
387.1... logprob:  0.679691, 0.398438 (0.664 sec)
387.2... logprob:  0.596887, 0.273438 (0.664 sec)
387.3... logprob:  0.653828, 0.359375 (0.664 sec)
387.4... logprob:  0.596575, 0.273438 (0.664 sec)
387.5... logprob:  0.590884, 0.265625 (0.663 sec)
387.6... logprob:  0.611413, 0.296875 (0.664 sec)
387.7... logprob:  0.643812, 0.343750 (0.663 sec)
387.8... logprob:  0.604921, 0.289062 (0.666 sec)
387.9... logprob:  0.638512, 0.335938 (0.662 sec)
387.10... logprob:  0.598119, 0.281250 (0.665 sec)
387.11... logprob:  0.638799, 0.335938 (0.664 sec)
387.12... logprob:  0.717103, 0.437500 (0.663 sec)
387.13... logprob:  0.657095, 0.359375 (0.663 sec)
387.14... logprob:  0.662710, 0.367188 (0.665 sec)
387.15... logprob:  0.685744, 0.398438 (0.662 sec)
387.16... logprob:  0.627076, 0.320312 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644048, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938354e-03 [6.957518e-09] 
Layer 'conv1' biases: 5.985458e-07 [1.841307e-10] 
Layer 'conv2' weights[0]: 7.926288e-03 [7.160578e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.217790e-10] 
Layer 'conv3' weights[0]: 7.923952e-03 [6.215368e-09] 
Layer 'conv3' biases: 4.978447e-06 [2.525691e-09] 
Layer 'conv4' weights[0]: 7.956804e-03 [6.226052e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.810406e-08] 
Layer 'conv5' weights[0]: 7.956120e-03 [1.016528e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.075494e-07] 
Layer 'fc6' weights[0]: 7.552283e-03 [1.151573e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.092876e-08] 
Layer 'fc7' weights[0]: 7.451816e-03 [1.415256e-07] 
Layer 'fc7' biases: 9.998528e-01 [1.275424e-07] 
Layer 'fc8' weights[0]: 5.981151e-04 [6.751933e-06] 
Layer 'fc8' biases: 1.677441e-01 [1.357622e-04] 
Train error last 27 batches: 0.635687
-------------------------------------------------------
Not saving because 0.644048 > 0.627087 (334.9: -0.00%)
======================================================= (5.052 sec)
387.17... logprob:  0.638505, 0.335938 (0.662 sec)
387.18... logprob:  0.638220, 0.335938 (0.661 sec)
387.19... logprob:  0.632705, 0.328125 (0.660 sec)
387.20... logprob:  0.648909, 0.351562 (0.659 sec)
387.21... logprob:  0.643442, 0.343750 (0.660 sec)
387.22... logprob:  0.627920, 0.320312 (0.661 sec)
387.23... logprob:  0.623021, 0.312500 (0.657 sec)
387.24... logprob:  0.577345, 0.242188 (0.660 sec)
387.25... logprob:  0.628073, 0.320312 (0.659 sec)
387.26... logprob:  0.674266, 0.390625 (0.660 sec)
387.27... logprob:  0.627952, 0.320312 (0.659 sec)
388.1... logprob:  0.679697, 0.398438 (0.662 sec)
388.2... logprob:  0.596880, 0.273438 (0.659 sec)
388.3... logprob:  0.653830, 0.359375 (0.662 sec)
388.4... logprob:  0.596571, 0.273438 (0.660 sec)
388.5... logprob:  0.590881, 0.265625 (0.664 sec)
388.6... logprob:  0.611412, 0.296875 (0.659 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643754, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938283e-03 [7.381416e-09] 
Layer 'conv1' biases: 5.997924e-07 [1.621344e-10] 
Layer 'conv2' weights[0]: 7.926231e-03 [6.263455e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.596344e-10] 
Layer 'conv3' weights[0]: 7.923889e-03 [6.045872e-09] 
Layer 'conv3' biases: 4.988758e-06 [2.209748e-09] 
Layer 'conv4' weights[0]: 7.956731e-03 [6.110088e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.901313e-08] 
Layer 'conv5' weights[0]: 7.956056e-03 [1.067081e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.126883e-07] 
Layer 'fc6' weights[0]: 7.552208e-03 [1.205868e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.148160e-08] 
Layer 'fc7' weights[0]: 7.451172e-03 [1.485185e-07] 
Layer 'fc7' biases: 9.998526e-01 [1.347792e-07] 
Layer 'fc8' weights[0]: 5.894154e-04 [7.053875e-06] 
Layer 'fc8' biases: 1.677230e-01 [1.734279e-04] 
Train error last 27 batches: 0.635686
-------------------------------------------------------
Not saving because 0.643754 > 0.627087 (334.9: -0.00%)
======================================================= (5.030 sec)
388.7... logprob:  0.643811, 0.343750 (0.661 sec)
388.8... logprob:  0.604922, 0.289062 (0.661 sec)
388.9... logprob:  0.638511, 0.335938 (0.661 sec)
388.10... logprob:  0.598122, 0.281250 (0.659 sec)
388.11... logprob:  0.638797, 0.335938 (0.661 sec)
388.12... logprob:  0.717085, 0.437500 (0.657 sec)
388.13... logprob:  0.657089, 0.359375 (0.661 sec)
388.14... logprob:  0.662703, 0.367188 (0.660 sec)
388.15... logprob:  0.685736, 0.398438 (0.660 sec)
388.16... logprob:  0.627077, 0.320312 (0.658 sec)
388.17... logprob:  0.638505, 0.335938 (0.661 sec)
388.18... logprob:  0.638221, 0.335938 (0.657 sec)
388.19... logprob:  0.632705, 0.328125 (0.658 sec)
388.20... logprob:  0.648910, 0.351562 (0.658 sec)
388.21... logprob:  0.643442, 0.343750 (0.660 sec)
388.22... logprob:  0.627918, 0.320312 (0.659 sec)
388.23... logprob:  0.623016, 0.312500 (0.660 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643440, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938219e-03 [6.337340e-09] 
Layer 'conv1' biases: 6.012255e-07 [1.079942e-10] 
Layer 'conv2' weights[0]: 7.926170e-03 [5.373166e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.240224e-10] 
Layer 'conv3' weights[0]: 7.923813e-03 [4.758177e-09] 
Layer 'conv3' biases: 5.000807e-06 [1.104855e-09] 
Layer 'conv4' weights[0]: 7.956679e-03 [4.630120e-09] 
Layer 'conv4' biases: 1.000001e+00 [5.759992e-09] 
Layer 'conv5' weights[0]: 7.955992e-03 [3.257956e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.411958e-08] 
Layer 'fc6' weights[0]: 7.552139e-03 [5.254894e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.525871e-09] 
Layer 'fc7' weights[0]: 7.450539e-03 [6.351311e-08] 
Layer 'fc7' biases: 9.998521e-01 [4.214074e-08] 
Layer 'fc8' weights[0]: 5.681873e-04 [2.167121e-06] 
Layer 'fc8' biases: 1.673814e-01 [3.844080e-05] 
Train error last 27 batches: 0.635684
-------------------------------------------------------
Not saving because 0.643440 > 0.627087 (334.9: -0.00%)
======================================================= (5.096 sec)
388.24... logprob:  0.577333, 0.242188 (0.659 sec)
388.25... logprob:  0.628070, 0.320312 (0.660 sec)
388.26... logprob:  0.674269, 0.390625 (0.659 sec)
388.27... logprob:  0.627950, 0.320312 (0.661 sec)
389.1... logprob:  0.679700, 0.398438 (0.660 sec)
389.2... logprob:  0.596875, 0.273438 (0.660 sec)
389.3... logprob:  0.653831, 0.359375 (0.660 sec)
389.4... logprob:  0.596567, 0.273438 (0.661 sec)
389.5... logprob:  0.590879, 0.265625 (0.660 sec)
389.6... logprob:  0.611411, 0.296875 (0.660 sec)
389.7... logprob:  0.643811, 0.343750 (0.658 sec)
389.8... logprob:  0.604925, 0.289062 (0.661 sec)
389.9... logprob:  0.638510, 0.335938 (0.660 sec)
389.10... logprob:  0.598127, 0.281250 (0.662 sec)
389.11... logprob:  0.638795, 0.335938 (0.659 sec)
389.12... logprob:  0.717066, 0.437500 (0.660 sec)
389.13... logprob:  0.657084, 0.359375 (0.661 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644921, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938150e-03 [6.534046e-09] 
Layer 'conv1' biases: 6.019204e-07 [9.949835e-11] 
Layer 'conv2' weights[0]: 7.926108e-03 [5.411489e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.469686e-10] 
Layer 'conv3' weights[0]: 7.923752e-03 [4.753779e-09] 
Layer 'conv3' biases: 5.004448e-06 [1.233369e-09] 
Layer 'conv4' weights[0]: 7.956603e-03 [4.665527e-09] 
Layer 'conv4' biases: 1.000001e+00 [6.624257e-09] 
Layer 'conv5' weights[0]: 7.955928e-03 [3.713299e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.905460e-08] 
Layer 'fc6' weights[0]: 7.552075e-03 [5.574697e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.005797e-09] 
Layer 'fc7' weights[0]: 7.449886e-03 [6.818320e-08] 
Layer 'fc7' biases: 9.998532e-01 [4.750816e-08] 
Layer 'fc8' weights[0]: 6.142660e-04 [2.491144e-06] 
Layer 'fc8' biases: 1.687762e-01 [4.026399e-05] 
Train error last 27 batches: 0.635683
-------------------------------------------------------
Not saving because 0.644921 > 0.627087 (334.9: -0.00%)
======================================================= (5.097 sec)
389.14... logprob:  0.662697, 0.367188 (0.658 sec)
389.15... logprob:  0.685729, 0.398438 (0.658 sec)
389.16... logprob:  0.627076, 0.320312 (0.660 sec)
389.17... logprob:  0.638505, 0.335938 (0.661 sec)
389.18... logprob:  0.638220, 0.335938 (0.659 sec)
389.19... logprob:  0.632704, 0.328125 (0.658 sec)
389.20... logprob:  0.648911, 0.351562 (0.671 sec)
389.21... logprob:  0.643443, 0.343750 (0.663 sec)
389.22... logprob:  0.627916, 0.320312 (0.660 sec)
389.23... logprob:  0.623013, 0.312500 (0.662 sec)
389.24... logprob:  0.577320, 0.242188 (0.663 sec)
389.25... logprob:  0.628068, 0.320312 (0.660 sec)
389.26... logprob:  0.674275, 0.390625 (0.662 sec)
389.27... logprob:  0.627948, 0.320312 (0.663 sec)
390.1... logprob:  0.679705, 0.398438 (0.665 sec)
390.2... logprob:  0.596870, 0.273438 (0.662 sec)
390.3... logprob:  0.653832, 0.359375 (0.661 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643480, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938082e-03 [6.740408e-09] 
Layer 'conv1' biases: 6.034974e-07 [6.679127e-11] 
Layer 'conv2' weights[0]: 7.926049e-03 [5.003784e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.543822e-10] 
Layer 'conv3' weights[0]: 7.923686e-03 [4.447104e-09] 
Layer 'conv3' biases: 5.018401e-06 [6.287385e-10] 
Layer 'conv4' weights[0]: 7.956540e-03 [4.335098e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.715749e-09] 
Layer 'conv5' weights[0]: 7.955861e-03 [1.090262e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.077999e-08] 
Layer 'fc6' weights[0]: 7.552011e-03 [3.974451e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.091463e-09] 
Layer 'fc7' weights[0]: 7.449229e-03 [4.154909e-08] 
Layer 'fc7' biases: 9.998522e-01 [1.321815e-08] 
Layer 'fc8' weights[0]: 5.745789e-04 [6.745511e-07] 
Layer 'fc8' biases: 1.679685e-01 [2.278388e-05] 
Train error last 27 batches: 0.635682
-------------------------------------------------------
Not saving because 0.643480 > 0.627087 (334.9: -0.00%)
======================================================= (5.167 sec)
390.4... logprob:  0.596564, 0.273438 (0.663 sec)
390.5... logprob:  0.590876, 0.265625 (0.664 sec)
390.6... logprob:  0.611411, 0.296875 (0.663 sec)
390.7... logprob:  0.643810, 0.343750 (0.663 sec)
390.8... logprob:  0.604926, 0.289062 (0.665 sec)
390.9... logprob:  0.638508, 0.335938 (0.663 sec)
390.10... logprob:  0.598132, 0.281250 (0.662 sec)
390.11... logprob:  0.638793, 0.335938 (0.664 sec)
390.12... logprob:  0.717049, 0.437500 (0.662 sec)
390.13... logprob:  0.657077, 0.359375 (0.664 sec)
390.14... logprob:  0.662691, 0.367188 (0.664 sec)
390.15... logprob:  0.685722, 0.398438 (0.662 sec)
390.16... logprob:  0.627077, 0.320312 (0.662 sec)
390.17... logprob:  0.638505, 0.335938 (0.664 sec)
390.18... logprob:  0.638220, 0.335938 (0.662 sec)
390.19... logprob:  0.632703, 0.328125 (0.663 sec)
390.20... logprob:  0.648912, 0.351562 (0.662 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643513, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.938017e-03 [6.815036e-09] 
Layer 'conv1' biases: 6.046829e-07 [1.635154e-10] 
Layer 'conv2' weights[0]: 7.925982e-03 [6.518922e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.723970e-10] 
Layer 'conv3' weights[0]: 7.923612e-03 [5.700618e-09] 
Layer 'conv3' biases: 5.027744e-06 [2.101317e-09] 
Layer 'conv4' weights[0]: 7.956478e-03 [5.630262e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.439141e-08] 
Layer 'conv5' weights[0]: 7.955793e-03 [8.112268e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.551589e-08] 
Layer 'fc6' weights[0]: 7.551957e-03 [9.695329e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.730670e-09] 
Layer 'fc7' weights[0]: 7.448600e-03 [1.196801e-07] 
Layer 'fc7' biases: 9.998522e-01 [1.030498e-07] 
Layer 'fc8' weights[0]: 5.771162e-04 [5.363009e-06] 
Layer 'fc8' biases: 1.682574e-01 [1.112872e-04] 
Train error last 27 batches: 0.635680
-------------------------------------------------------
Not saving because 0.643513 > 0.627087 (334.9: -0.00%)
======================================================= (5.045 sec)
390.21... logprob:  0.643444, 0.343750 (0.662 sec)
390.22... logprob:  0.627914, 0.320312 (0.662 sec)
390.23... logprob:  0.623009, 0.312500 (0.662 sec)
390.24... logprob:  0.577308, 0.242188 (0.661 sec)
390.25... logprob:  0.628065, 0.320312 (0.663 sec)
390.26... logprob:  0.674279, 0.390625 (0.663 sec)
390.27... logprob:  0.627946, 0.320312 (0.663 sec)
391.1... logprob:  0.679710, 0.398438 (0.663 sec)
391.2... logprob:  0.596864, 0.273438 (0.657 sec)
391.3... logprob:  0.653833, 0.359375 (0.660 sec)
391.4... logprob:  0.596560, 0.273438 (0.661 sec)
391.5... logprob:  0.590873, 0.265625 (0.658 sec)
391.6... logprob:  0.611411, 0.296875 (0.661 sec)
391.7... logprob:  0.643810, 0.343750 (0.660 sec)
391.8... logprob:  0.604928, 0.289062 (0.662 sec)
391.9... logprob:  0.638508, 0.335938 (0.662 sec)
391.10... logprob:  0.598136, 0.281250 (0.661 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644762, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937958e-03 [7.115684e-09] 
Layer 'conv1' biases: 6.054967e-07 [1.468705e-10] 
Layer 'conv2' weights[0]: 7.925915e-03 [6.317500e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.535955e-10] 
Layer 'conv3' weights[0]: 7.923550e-03 [6.127802e-09] 
Layer 'conv3' biases: 5.032644e-06 [2.251358e-09] 
Layer 'conv4' weights[0]: 7.956405e-03 [6.264982e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.938886e-08] 
Layer 'conv5' weights[0]: 7.955736e-03 [1.092668e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.156227e-07] 
Layer 'fc6' weights[0]: 7.551884e-03 [1.218837e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.162400e-08] 
Layer 'fc7' weights[0]: 7.447939e-03 [1.483055e-07] 
Layer 'fc7' biases: 9.998530e-01 [1.344797e-07] 
Layer 'fc8' weights[0]: 6.111998e-04 [7.132460e-06] 
Layer 'fc8' biases: 1.693310e-01 [1.701156e-04] 
Train error last 27 batches: 0.635680
-------------------------------------------------------
Not saving because 0.644762 > 0.627087 (334.9: -0.00%)
======================================================= (5.041 sec)
391.11... logprob:  0.638790, 0.335938 (0.661 sec)
391.12... logprob:  0.717029, 0.437500 (0.661 sec)
391.13... logprob:  0.657071, 0.359375 (0.659 sec)
391.14... logprob:  0.662685, 0.367188 (0.661 sec)
391.15... logprob:  0.685714, 0.398438 (0.659 sec)
391.16... logprob:  0.627077, 0.320312 (0.660 sec)
391.17... logprob:  0.638505, 0.335938 (0.661 sec)
391.18... logprob:  0.638220, 0.335938 (0.660 sec)
391.19... logprob:  0.632703, 0.328125 (0.659 sec)
391.20... logprob:  0.648914, 0.351562 (0.660 sec)
391.21... logprob:  0.643444, 0.343750 (0.656 sec)
391.22... logprob:  0.627912, 0.320312 (0.659 sec)
391.23... logprob:  0.623005, 0.312500 (0.660 sec)
391.24... logprob:  0.577293, 0.242188 (0.659 sec)
391.25... logprob:  0.628062, 0.320312 (0.660 sec)
391.26... logprob:  0.674286, 0.390625 (0.660 sec)
391.27... logprob:  0.627944, 0.320312 (0.657 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643472, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937891e-03 [6.636851e-09] 
Layer 'conv1' biases: 6.070746e-07 [7.044105e-11] 
Layer 'conv2' weights[0]: 7.925847e-03 [4.908868e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.566928e-10] 
Layer 'conv3' weights[0]: 7.923488e-03 [4.440787e-09] 
Layer 'conv3' biases: 5.046647e-06 [6.835712e-10] 
Layer 'conv4' weights[0]: 7.956340e-03 [4.371815e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.461028e-09] 
Layer 'conv5' weights[0]: 7.955684e-03 [2.008431e-08] 
Layer 'conv5' biases: 1.000002e+00 [2.072618e-08] 
Layer 'fc6' weights[0]: 7.551815e-03 [4.420993e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.086753e-09] 
Layer 'fc7' weights[0]: 7.447278e-03 [4.966020e-08] 
Layer 'fc7' biases: 9.998522e-01 [2.488308e-08] 
Layer 'fc8' weights[0]: 5.731353e-04 [1.253871e-06] 
Layer 'fc8' biases: 1.685746e-01 [4.048265e-05] 
Train error last 27 batches: 0.635677
-------------------------------------------------------
Not saving because 0.643472 > 0.627087 (334.9: -0.00%)
======================================================= (5.132 sec)
392.1... logprob:  0.679716, 0.398438 (0.660 sec)
392.2... logprob:  0.596858, 0.273438 (0.661 sec)
392.3... logprob:  0.653835, 0.359375 (0.660 sec)
392.4... logprob:  0.596556, 0.273438 (0.661 sec)
392.5... logprob:  0.590871, 0.265625 (0.661 sec)
392.6... logprob:  0.611411, 0.296875 (0.661 sec)
392.7... logprob:  0.643810, 0.343750 (0.661 sec)
392.8... logprob:  0.604931, 0.289062 (0.661 sec)
392.9... logprob:  0.638506, 0.335938 (0.662 sec)
392.10... logprob:  0.598142, 0.281250 (0.661 sec)
392.11... logprob:  0.638787, 0.335938 (0.660 sec)
392.12... logprob:  0.717007, 0.437500 (0.661 sec)
392.13... logprob:  0.657064, 0.359375 (0.661 sec)
392.14... logprob:  0.662676, 0.367188 (0.661 sec)
392.15... logprob:  0.685703, 0.398438 (0.660 sec)
392.16... logprob:  0.627077, 0.320312 (0.660 sec)
392.17... logprob:  0.638504, 0.335938 (0.660 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643842, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937825e-03 [6.474726e-09] 
Layer 'conv1' biases: 6.080815e-07 [1.696721e-10] 
Layer 'conv2' weights[0]: 7.925775e-03 [6.824531e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.614829e-10] 
Layer 'conv3' weights[0]: 7.923420e-03 [5.997771e-09] 
Layer 'conv3' biases: 5.053930e-06 [2.343586e-09] 
Layer 'conv4' weights[0]: 7.956271e-03 [6.034312e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.721128e-08] 
Layer 'conv5' weights[0]: 7.955603e-03 [9.665668e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.021269e-07] 
Layer 'fc6' weights[0]: 7.551746e-03 [1.103639e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.040445e-08] 
Layer 'fc7' weights[0]: 7.446642e-03 [1.355769e-07] 
Layer 'fc7' biases: 9.998525e-01 [1.211809e-07] 
Layer 'fc8' weights[0]: 5.909654e-04 [6.390004e-06] 
Layer 'fc8' biases: 1.692511e-01 [1.302887e-04] 
Train error last 27 batches: 0.635675
-------------------------------------------------------
Not saving because 0.643842 > 0.627087 (334.9: -0.00%)
======================================================= (5.035 sec)
392.18... logprob:  0.638219, 0.335938 (0.659 sec)
392.19... logprob:  0.632702, 0.328125 (0.660 sec)
392.20... logprob:  0.648913, 0.351562 (0.660 sec)
392.21... logprob:  0.643444, 0.343750 (0.658 sec)
392.22... logprob:  0.627909, 0.320312 (0.661 sec)
392.23... logprob:  0.623003, 0.312500 (0.660 sec)
392.24... logprob:  0.577284, 0.242188 (0.659 sec)
392.25... logprob:  0.628060, 0.320312 (0.660 sec)
392.26... logprob:  0.674289, 0.390625 (0.660 sec)
392.27... logprob:  0.627942, 0.320312 (0.661 sec)
393.1... logprob:  0.679720, 0.398438 (0.661 sec)
393.2... logprob:  0.596853, 0.273438 (0.661 sec)
393.3... logprob:  0.653836, 0.359375 (0.658 sec)
393.4... logprob:  0.596551, 0.273438 (0.660 sec)
393.5... logprob:  0.590866, 0.265625 (0.660 sec)
393.6... logprob:  0.611408, 0.296875 (0.661 sec)
393.7... logprob:  0.643810, 0.343750 (0.661 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643914, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937755e-03 [6.865366e-09] 
Layer 'conv1' biases: 6.092212e-07 [1.270881e-10] 
Layer 'conv2' weights[0]: 7.925711e-03 [5.817736e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.141117e-10] 
Layer 'conv3' weights[0]: 7.923346e-03 [5.618963e-09] 
Layer 'conv3' biases: 5.062949e-06 [1.862241e-09] 
Layer 'conv4' weights[0]: 7.956201e-03 [5.678316e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.576895e-08] 
Layer 'conv5' weights[0]: 7.955532e-03 [8.847602e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.349194e-08] 
Layer 'fc6' weights[0]: 7.551678e-03 [1.028022e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.454292e-09] 
Layer 'fc7' weights[0]: 7.446006e-03 [1.264317e-07] 
Layer 'fc7' biases: 9.998525e-01 [1.104308e-07] 
Layer 'fc8' weights[0]: 5.929557e-04 [5.765022e-06] 
Layer 'fc8' biases: 1.695010e-01 [1.437464e-04] 
Train error last 27 batches: 0.635674
-------------------------------------------------------
Not saving because 0.643914 > 0.627087 (334.9: -0.00%)
======================================================= (5.059 sec)
393.8... logprob:  0.604931, 0.289062 (0.659 sec)
393.9... logprob:  0.638506, 0.335938 (0.662 sec)
393.10... logprob:  0.598143, 0.281250 (0.661 sec)
393.11... logprob:  0.638786, 0.335938 (0.660 sec)
393.12... logprob:  0.716997, 0.437500 (0.660 sec)
393.13... logprob:  0.657060, 0.359375 (0.661 sec)
393.14... logprob:  0.662673, 0.367188 (0.661 sec)
393.15... logprob:  0.685700, 0.398438 (0.660 sec)
393.16... logprob:  0.627077, 0.320312 (0.659 sec)
393.17... logprob:  0.638504, 0.335938 (0.661 sec)
393.18... logprob:  0.638220, 0.335938 (0.660 sec)
393.19... logprob:  0.632702, 0.328125 (0.657 sec)
393.20... logprob:  0.648915, 0.351562 (0.658 sec)
393.21... logprob:  0.643445, 0.343750 (0.659 sec)
393.22... logprob:  0.627908, 0.320312 (0.660 sec)
393.23... logprob:  0.622999, 0.312500 (0.659 sec)
393.24... logprob:  0.577270, 0.242188 (0.660 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643446, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937681e-03 [6.517026e-09] 
Layer 'conv1' biases: 6.106843e-07 [6.034392e-11] 
Layer 'conv2' weights[0]: 7.925649e-03 [4.881856e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.037971e-10] 
Layer 'conv3' weights[0]: 7.923280e-03 [4.531530e-09] 
Layer 'conv3' biases: 5.075559e-06 [8.461554e-10] 
Layer 'conv4' weights[0]: 7.956139e-03 [4.472642e-09] 
Layer 'conv4' biases: 1.000001e+00 [6.005466e-09] 
Layer 'conv5' weights[0]: 7.955482e-03 [3.352298e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.519029e-08] 
Layer 'fc6' weights[0]: 7.551613e-03 [5.280913e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.536971e-09] 
Layer 'fc7' weights[0]: 7.445341e-03 [6.347760e-08] 
Layer 'fc7' biases: 9.998522e-01 [4.182044e-08] 
Layer 'fc8' weights[0]: 5.687671e-04 [2.124157e-06] 
Layer 'fc8' biases: 1.690835e-01 [6.578303e-05] 
Train error last 27 batches: 0.635673
-------------------------------------------------------
Not saving because 0.643446 > 0.627087 (334.9: -0.00%)
======================================================= (5.262 sec)
393.25... logprob:  0.628058, 0.320312 (0.659 sec)
393.26... logprob:  0.674294, 0.390625 (0.660 sec)
393.27... logprob:  0.627941, 0.320312 (0.660 sec)
394.1... logprob:  0.679725, 0.398438 (0.662 sec)
394.2... logprob:  0.596848, 0.273438 (0.661 sec)
394.3... logprob:  0.653837, 0.359375 (0.661 sec)
394.4... logprob:  0.596549, 0.273438 (0.667 sec)
394.5... logprob:  0.590866, 0.265625 (0.660 sec)
394.6... logprob:  0.611411, 0.296875 (0.662 sec)
394.7... logprob:  0.643809, 0.343750 (0.658 sec)
394.8... logprob:  0.604935, 0.289062 (0.663 sec)
394.9... logprob:  0.638505, 0.335938 (0.662 sec)
394.10... logprob:  0.598150, 0.281250 (0.660 sec)
394.11... logprob:  0.638783, 0.335938 (0.662 sec)
394.12... logprob:  0.716971, 0.437500 (0.660 sec)
394.13... logprob:  0.657053, 0.359375 (0.659 sec)
394.14... logprob:  0.662665, 0.367188 (0.661 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644661, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937616e-03 [6.775867e-09] 
Layer 'conv1' biases: 6.114667e-07 [1.493401e-10] 
Layer 'conv2' weights[0]: 7.925589e-03 [6.190127e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.665786e-10] 
Layer 'conv3' weights[0]: 7.923210e-03 [5.406098e-09] 
Layer 'conv3' biases: 5.079744e-06 [1.845642e-09] 
Layer 'conv4' weights[0]: 7.956069e-03 [5.360478e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.202447e-08] 
Layer 'conv5' weights[0]: 7.955410e-03 [6.762350e-08] 
Layer 'conv5' biases: 1.000002e+00 [7.145858e-08] 
Layer 'fc6' weights[0]: 7.551551e-03 [8.299230e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.250347e-09] 
Layer 'fc7' weights[0]: 7.444734e-03 [1.022468e-07] 
Layer 'fc7' biases: 9.998528e-01 [8.467126e-08] 
Layer 'fc8' weights[0]: 6.085475e-04 [4.457506e-06] 
Layer 'fc8' biases: 1.703223e-01 [8.476499e-05] 
Train error last 27 batches: 0.635672
-------------------------------------------------------
Not saving because 0.644661 > 0.627087 (334.9: -0.00%)
======================================================= (5.058 sec)
394.15... logprob:  0.685689, 0.398438 (0.661 sec)
394.16... logprob:  0.627077, 0.320312 (0.660 sec)
394.17... logprob:  0.638504, 0.335938 (0.661 sec)
394.18... logprob:  0.638220, 0.335938 (0.660 sec)
394.19... logprob:  0.632702, 0.328125 (0.660 sec)
394.20... logprob:  0.648915, 0.351562 (0.660 sec)
394.21... logprob:  0.643444, 0.343750 (0.660 sec)
394.22... logprob:  0.627905, 0.320312 (0.660 sec)
394.23... logprob:  0.622996, 0.312500 (0.660 sec)
394.24... logprob:  0.577258, 0.242188 (0.659 sec)
394.25... logprob:  0.628055, 0.320312 (0.660 sec)
394.26... logprob:  0.674299, 0.390625 (0.659 sec)
394.27... logprob:  0.627938, 0.320312 (0.661 sec)
395.1... logprob:  0.679730, 0.398438 (0.660 sec)
395.2... logprob:  0.596841, 0.273438 (0.656 sec)
395.3... logprob:  0.653838, 0.359375 (0.661 sec)
395.4... logprob:  0.596543, 0.273438 (0.661 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643514, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937550e-03 [6.927485e-09] 
Layer 'conv1' biases: 6.129630e-07 [8.894366e-11] 
Layer 'conv2' weights[0]: 7.925528e-03 [5.307585e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.590726e-10] 
Layer 'conv3' weights[0]: 7.923151e-03 [4.945271e-09] 
Layer 'conv3' biases: 5.093286e-06 [1.204925e-09] 
Layer 'conv4' weights[0]: 7.956000e-03 [4.887633e-09] 
Layer 'conv4' biases: 1.000001e+00 [8.895343e-09] 
Layer 'conv5' weights[0]: 7.955353e-03 [5.029189e-08] 
Layer 'conv5' biases: 1.000002e+00 [5.295150e-08] 
Layer 'fc6' weights[0]: 7.551491e-03 [6.662524e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.354429e-09] 
Layer 'fc7' weights[0]: 7.444086e-03 [8.170493e-08] 
Layer 'fc7' biases: 9.998521e-01 [6.260019e-08] 
Layer 'fc8' weights[0]: 5.760537e-04 [3.252517e-06] 
Layer 'fc8' biases: 1.696851e-01 [8.580769e-05] 
Train error last 27 batches: 0.635670
-------------------------------------------------------
Not saving because 0.643514 > 0.627087 (334.9: -0.00%)
======================================================= (5.082 sec)
395.5... logprob:  0.590861, 0.265625 (0.660 sec)
395.6... logprob:  0.611408, 0.296875 (0.660 sec)
395.7... logprob:  0.643809, 0.343750 (0.660 sec)
395.8... logprob:  0.604935, 0.289062 (0.662 sec)
395.9... logprob:  0.638505, 0.335938 (0.661 sec)
395.10... logprob:  0.598151, 0.281250 (0.661 sec)
395.11... logprob:  0.638782, 0.335938 (0.662 sec)
395.12... logprob:  0.716959, 0.437500 (0.660 sec)
395.13... logprob:  0.657048, 0.359375 (0.661 sec)
395.14... logprob:  0.662661, 0.367188 (0.662 sec)
395.15... logprob:  0.685686, 0.398438 (0.660 sec)
395.16... logprob:  0.627078, 0.320312 (0.660 sec)
395.17... logprob:  0.638503, 0.335938 (0.660 sec)
395.18... logprob:  0.638221, 0.335938 (0.660 sec)
395.19... logprob:  0.632702, 0.328125 (0.659 sec)
395.20... logprob:  0.648918, 0.351562 (0.661 sec)
395.21... logprob:  0.643445, 0.343750 (0.659 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643467, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937488e-03 [6.854128e-09] 
Layer 'conv1' biases: 6.142220e-07 [1.562971e-10] 
Layer 'conv2' weights[0]: 7.925465e-03 [6.511120e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.427787e-10] 
Layer 'conv3' weights[0]: 7.923081e-03 [5.670483e-09] 
Layer 'conv3' biases: 5.103602e-06 [2.025929e-09] 
Layer 'conv4' weights[0]: 7.955935e-03 [5.583083e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.354945e-08] 
Layer 'conv5' weights[0]: 7.955286e-03 [7.616101e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.029334e-08] 
Layer 'fc6' weights[0]: 7.551422e-03 [9.226685e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.237355e-09] 
Layer 'fc7' weights[0]: 7.443423e-03 [1.139351e-07] 
Layer 'fc7' biases: 9.998521e-01 [9.713608e-08] 
Layer 'fc8' weights[0]: 5.714674e-04 [5.018269e-06] 
Layer 'fc8' biases: 1.697826e-01 [1.058961e-04] 
Train error last 27 batches: 0.635669
-------------------------------------------------------
Not saving because 0.643467 > 0.627087 (334.9: -0.00%)
======================================================= (5.054 sec)
395.22... logprob:  0.627903, 0.320312 (0.660 sec)
395.23... logprob:  0.622991, 0.312500 (0.659 sec)
395.24... logprob:  0.577242, 0.242188 (0.660 sec)
395.25... logprob:  0.628052, 0.320312 (0.660 sec)
395.26... logprob:  0.674305, 0.390625 (0.659 sec)
395.27... logprob:  0.627937, 0.320312 (0.661 sec)
396.1... logprob:  0.679735, 0.398438 (0.661 sec)
396.2... logprob:  0.596837, 0.273438 (0.658 sec)
396.3... logprob:  0.653840, 0.359375 (0.661 sec)
396.4... logprob:  0.596542, 0.273438 (0.661 sec)
396.5... logprob:  0.590861, 0.265625 (0.662 sec)
396.6... logprob:  0.611410, 0.296875 (0.661 sec)
396.7... logprob:  0.643808, 0.343750 (0.661 sec)
396.8... logprob:  0.604941, 0.289062 (0.662 sec)
396.9... logprob:  0.638503, 0.335938 (0.662 sec)
396.10... logprob:  0.598161, 0.281250 (0.661 sec)
396.11... logprob:  0.638777, 0.335938 (0.662 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.645067, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937421e-03 [6.881076e-09] 
Layer 'conv1' biases: 6.149655e-07 [1.217008e-10] 
Layer 'conv2' weights[0]: 7.925398e-03 [5.783006e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.796237e-10] 
Layer 'conv3' weights[0]: 7.923015e-03 [5.580924e-09] 
Layer 'conv3' biases: 5.106992e-06 [1.803941e-09] 
Layer 'conv4' weights[0]: 7.955864e-03 [5.664232e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.525703e-08] 
Layer 'conv5' weights[0]: 7.955218e-03 [8.644042e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.168406e-08] 
Layer 'fc6' weights[0]: 7.551357e-03 [1.009208e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.219135e-09] 
Layer 'fc7' weights[0]: 7.442751e-03 [1.227577e-07] 
Layer 'fc7' biases: 9.998530e-01 [1.058937e-07] 
Layer 'fc8' weights[0]: 6.144095e-04 [5.633529e-06] 
Layer 'fc8' biases: 1.710922e-01 [1.368565e-04] 
Train error last 27 batches: 0.635669
-------------------------------------------------------
Not saving because 0.645067 > 0.627087 (334.9: -0.00%)
======================================================= (5.059 sec)
396.12... logprob:  0.716927, 0.437500 (0.661 sec)
396.13... logprob:  0.657037, 0.359375 (0.660 sec)
396.14... logprob:  0.662650, 0.367188 (0.661 sec)
396.15... logprob:  0.685670, 0.398438 (0.658 sec)
396.16... logprob:  0.627078, 0.320312 (0.660 sec)
396.17... logprob:  0.638503, 0.335938 (0.660 sec)
396.18... logprob:  0.638219, 0.335938 (0.660 sec)
396.19... logprob:  0.632701, 0.328125 (0.657 sec)
396.20... logprob:  0.648918, 0.351562 (0.659 sec)
396.21... logprob:  0.643445, 0.343750 (0.660 sec)
396.22... logprob:  0.627901, 0.320312 (0.659 sec)
396.23... logprob:  0.622989, 0.312500 (0.659 sec)
396.24... logprob:  0.577231, 0.242188 (0.660 sec)
396.25... logprob:  0.628050, 0.320312 (0.660 sec)
396.26... logprob:  0.674310, 0.390625 (0.661 sec)
396.27... logprob:  0.627934, 0.320312 (0.660 sec)
397.1... logprob:  0.679742, 0.398438 (0.661 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643464, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937352e-03 [6.704883e-09] 
Layer 'conv1' biases: 6.166061e-07 [8.507850e-11] 
Layer 'conv2' weights[0]: 7.925337e-03 [5.196301e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.414217e-10] 
Layer 'conv3' weights[0]: 7.922944e-03 [4.519367e-09] 
Layer 'conv3' biases: 5.122124e-06 [8.683752e-10] 
Layer 'conv4' weights[0]: 7.955801e-03 [4.429377e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.610013e-09] 
Layer 'conv5' weights[0]: 7.955157e-03 [1.998869e-08] 
Layer 'conv5' biases: 1.000002e+00 [2.057050e-08] 
Layer 'fc6' weights[0]: 7.551292e-03 [4.454747e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.175943e-09] 
Layer 'fc7' weights[0]: 7.442121e-03 [5.064395e-08] 
Layer 'fc7' biases: 9.998521e-01 [2.667572e-08] 
Layer 'fc8' weights[0]: 5.707336e-04 [1.320713e-06] 
Layer 'fc8' biases: 1.701796e-01 [2.271754e-05] 
Train error last 27 batches: 0.635666
-------------------------------------------------------
Not saving because 0.643464 > 0.627087 (334.9: -0.00%)
======================================================= (5.132 sec)
397.2... logprob:  0.596829, 0.273438 (0.661 sec)
397.3... logprob:  0.653842, 0.359375 (0.661 sec)
397.4... logprob:  0.596534, 0.273438 (0.661 sec)
397.5... logprob:  0.590854, 0.265625 (0.661 sec)
397.6... logprob:  0.611407, 0.296875 (0.658 sec)
397.7... logprob:  0.643809, 0.343750 (0.659 sec)
397.8... logprob:  0.604939, 0.289062 (0.662 sec)
397.9... logprob:  0.638503, 0.335938 (0.661 sec)
397.10... logprob:  0.598161, 0.281250 (0.661 sec)
397.11... logprob:  0.638777, 0.335938 (0.662 sec)
397.12... logprob:  0.716919, 0.437500 (0.661 sec)
397.13... logprob:  0.657035, 0.359375 (0.661 sec)
397.14... logprob:  0.662647, 0.367188 (0.661 sec)
397.15... logprob:  0.685667, 0.398438 (0.660 sec)
397.16... logprob:  0.627078, 0.320312 (0.660 sec)
397.17... logprob:  0.638503, 0.335938 (0.661 sec)
397.18... logprob:  0.638220, 0.335938 (0.660 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643693, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937293e-03 [6.541188e-09] 
Layer 'conv1' biases: 6.176634e-07 [1.741305e-10] 
Layer 'conv2' weights[0]: 7.925282e-03 [6.711215e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.349267e-10] 
Layer 'conv3' weights[0]: 7.922891e-03 [5.893414e-09] 
Layer 'conv3' biases: 5.130039e-06 [2.268751e-09] 
Layer 'conv4' weights[0]: 7.955734e-03 [5.877417e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.609972e-08] 
Layer 'conv5' weights[0]: 7.955094e-03 [9.021201e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.509200e-08] 
Layer 'fc6' weights[0]: 7.551227e-03 [1.044967e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.705150e-09] 
Layer 'fc7' weights[0]: 7.441455e-03 [1.286045e-07] 
Layer 'fc7' biases: 9.998523e-01 [1.132777e-07] 
Layer 'fc8' weights[0]: 5.842639e-04 [5.925368e-06] 
Layer 'fc8' biases: 1.707537e-01 [1.225129e-04] 
Train error last 27 batches: 0.635665
-------------------------------------------------------
Not saving because 0.643693 > 0.627087 (334.9: -0.00%)
======================================================= (5.038 sec)
397.19... logprob:  0.632701, 0.328125 (0.660 sec)
397.20... logprob:  0.648920, 0.351562 (0.660 sec)
397.21... logprob:  0.643446, 0.343750 (0.657 sec)
397.22... logprob:  0.627898, 0.320312 (0.660 sec)
397.23... logprob:  0.622985, 0.312500 (0.660 sec)
397.24... logprob:  0.577219, 0.242188 (0.658 sec)
397.25... logprob:  0.628048, 0.320312 (0.660 sec)
397.26... logprob:  0.674314, 0.390625 (0.660 sec)
397.27... logprob:  0.627933, 0.320312 (0.660 sec)
398.1... logprob:  0.679744, 0.398438 (0.661 sec)
398.2... logprob:  0.596826, 0.273438 (0.661 sec)
398.3... logprob:  0.653842, 0.359375 (0.660 sec)
398.4... logprob:  0.596534, 0.273438 (0.658 sec)
398.5... logprob:  0.590855, 0.265625 (0.660 sec)
398.6... logprob:  0.611409, 0.296875 (0.660 sec)
398.7... logprob:  0.643808, 0.343750 (0.661 sec)
398.8... logprob:  0.604944, 0.289062 (0.662 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644148, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937230e-03 [7.223127e-09] 
Layer 'conv1' biases: 6.186955e-07 [1.452530e-10] 
Layer 'conv2' weights[0]: 7.925213e-03 [6.305052e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.512671e-10] 
Layer 'conv3' weights[0]: 7.922824e-03 [6.079864e-09] 
Layer 'conv3' biases: 5.137604e-06 [2.213804e-09] 
Layer 'conv4' weights[0]: 7.955666e-03 [6.185905e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.894215e-08] 
Layer 'conv5' weights[0]: 7.955033e-03 [1.058300e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.118219e-07] 
Layer 'fc6' weights[0]: 7.551157e-03 [1.191225e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.131623e-08] 
Layer 'fc7' weights[0]: 7.440807e-03 [1.451996e-07] 
Layer 'fc7' biases: 9.998526e-01 [1.311442e-07] 
Layer 'fc8' weights[0]: 5.973194e-04 [6.879433e-06] 
Layer 'fc8' biases: 1.712900e-01 [1.691611e-04] 
Train error last 27 batches: 0.635664
-------------------------------------------------------
Not saving because 0.644148 > 0.627087 (334.9: -0.00%)
======================================================= (5.044 sec)
398.9... logprob:  0.638502, 0.335938 (0.663 sec)
398.10... logprob:  0.598169, 0.281250 (0.662 sec)
398.11... logprob:  0.638773, 0.335938 (0.661 sec)
398.12... logprob:  0.716893, 0.437500 (0.661 sec)
398.13... logprob:  0.657027, 0.359375 (0.661 sec)
398.14... logprob:  0.662638, 0.367188 (0.661 sec)
398.15... logprob:  0.685656, 0.398438 (0.660 sec)
398.16... logprob:  0.627078, 0.320312 (0.656 sec)
398.17... logprob:  0.638502, 0.335938 (0.661 sec)
398.18... logprob:  0.638220, 0.335938 (0.660 sec)
398.19... logprob:  0.632701, 0.328125 (0.661 sec)
398.20... logprob:  0.648920, 0.351562 (0.660 sec)
398.21... logprob:  0.643446, 0.343750 (0.659 sec)
398.22... logprob:  0.627896, 0.320312 (0.660 sec)
398.23... logprob:  0.622982, 0.312500 (0.660 sec)
398.24... logprob:  0.577206, 0.242188 (0.659 sec)
398.25... logprob:  0.628045, 0.320312 (0.657 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643462, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937174e-03 [6.635347e-09] 
Layer 'conv1' biases: 6.201856e-07 [6.856513e-11] 
Layer 'conv2' weights[0]: 7.925146e-03 [4.958608e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.576809e-10] 
Layer 'conv3' weights[0]: 7.922751e-03 [4.641956e-09] 
Layer 'conv3' biases: 5.150542e-06 [1.008718e-09] 
Layer 'conv4' weights[0]: 7.955601e-03 [4.628833e-09] 
Layer 'conv4' biases: 1.000001e+00 [7.685771e-09] 
Layer 'conv5' weights[0]: 7.954956e-03 [4.308273e-08] 
Layer 'conv5' biases: 1.000002e+00 [4.524406e-08] 
Layer 'fc6' weights[0]: 7.551090e-03 [6.037642e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.586920e-09] 
Layer 'fc7' weights[0]: 7.440160e-03 [7.382149e-08] 
Layer 'fc7' biases: 9.998522e-01 [5.400376e-08] 
Layer 'fc8' weights[0]: 5.698263e-04 [2.758007e-06] 
Layer 'fc8' biases: 1.707878e-01 [8.036465e-05] 
Train error last 27 batches: 0.635662
-------------------------------------------------------
Not saving because 0.643462 > 0.627087 (334.9: -0.00%)
======================================================= (5.090 sec)
398.26... logprob:  0.674320, 0.390625 (0.659 sec)
398.27... logprob:  0.627930, 0.320312 (0.661 sec)
399.1... logprob:  0.679750, 0.398438 (0.661 sec)
399.2... logprob:  0.596819, 0.273438 (0.660 sec)
399.3... logprob:  0.653844, 0.359375 (0.661 sec)
399.4... logprob:  0.596528, 0.273438 (0.661 sec)
399.5... logprob:  0.590850, 0.265625 (0.661 sec)
399.6... logprob:  0.611407, 0.296875 (0.661 sec)
399.7... logprob:  0.643808, 0.343750 (0.661 sec)
399.8... logprob:  0.604944, 0.289062 (0.662 sec)
399.9... logprob:  0.638501, 0.335938 (0.661 sec)
399.10... logprob:  0.598170, 0.281250 (0.662 sec)
399.11... logprob:  0.638772, 0.335938 (0.661 sec)
399.12... logprob:  0.716882, 0.437500 (0.661 sec)
399.13... logprob:  0.657023, 0.359375 (0.662 sec)
399.14... logprob:  0.662635, 0.367188 (0.662 sec)
399.15... logprob:  0.685653, 0.398438 (0.659 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644298, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937106e-03 [7.358826e-09] 
Layer 'conv1' biases: 6.210766e-07 [2.034473e-10] 
Layer 'conv2' weights[0]: 7.925085e-03 [7.553949e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.010364e-09] 
Layer 'conv3' weights[0]: 7.922682e-03 [6.521828e-09] 
Layer 'conv3' biases: 5.156078e-06 [2.793975e-09] 
Layer 'conv4' weights[0]: 7.955535e-03 [6.570027e-09] 
Layer 'conv4' biases: 1.000001e+00 [2.033992e-08] 
Layer 'conv5' weights[0]: 7.954908e-03 [1.144779e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.209630e-07] 
Layer 'fc6' weights[0]: 7.551022e-03 [1.274044e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.225779e-08] 
Layer 'fc7' weights[0]: 7.439503e-03 [1.550876e-07] 
Layer 'fc7' biases: 9.998526e-01 [1.420178e-07] 
Layer 'fc8' weights[0]: 6.001724e-04 [7.491453e-06] 
Layer 'fc8' biases: 1.717873e-01 [1.537626e-04] 
Train error last 27 batches: 0.635660
-------------------------------------------------------
Not saving because 0.644298 > 0.627087 (334.9: -0.00%)
======================================================= (5.029 sec)
399.16... logprob:  0.627079, 0.320312 (0.659 sec)
399.17... logprob:  0.638503, 0.335938 (0.658 sec)
399.18... logprob:  0.638220, 0.335938 (0.659 sec)
399.19... logprob:  0.632700, 0.328125 (0.660 sec)
399.20... logprob:  0.648921, 0.351562 (0.660 sec)
399.21... logprob:  0.643447, 0.343750 (0.660 sec)
399.22... logprob:  0.627894, 0.320312 (0.659 sec)
399.23... logprob:  0.622978, 0.312500 (0.660 sec)
399.24... logprob:  0.577194, 0.242188 (0.660 sec)
399.25... logprob:  0.628042, 0.320312 (0.660 sec)
399.26... logprob:  0.674324, 0.390625 (0.660 sec)
399.27... logprob:  0.627928, 0.320312 (0.662 sec)
400.1... logprob:  0.679754, 0.398438 (0.662 sec)
400.2... logprob:  0.596815, 0.273438 (0.661 sec)
400.3... logprob:  0.653844, 0.359375 (0.661 sec)
400.4... logprob:  0.596526, 0.273438 (0.658 sec)
400.5... logprob:  0.590850, 0.265625 (0.662 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643602, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.937034e-03 [7.510151e-09] 
Layer 'conv1' biases: 6.224512e-07 [1.363796e-10] 
Layer 'conv2' weights[0]: 7.925030e-03 [5.962718e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.394655e-10] 
Layer 'conv3' weights[0]: 7.922605e-03 [5.744047e-09] 
Layer 'conv3' biases: 5.168024e-06 [1.930454e-09] 
Layer 'conv4' weights[0]: 7.955461e-03 [5.754813e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.605336e-08] 
Layer 'conv5' weights[0]: 7.954824e-03 [9.023645e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.511453e-08] 
Layer 'fc6' weights[0]: 7.550966e-03 [1.045704e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.673771e-09] 
Layer 'fc7' weights[0]: 7.438891e-03 [1.286596e-07] 
Layer 'fc7' biases: 9.998522e-01 [1.129974e-07] 
Layer 'fc8' weights[0]: 5.796624e-04 [5.861797e-06] 
Layer 'fc8' biases: 1.714506e-01 [1.488274e-04] 
Train error last 27 batches: 0.635660
-------------------------------------------------------
Not saving because 0.643602 > 0.627087 (334.9: -0.00%)
======================================================= (5.047 sec)
400.6... logprob:  0.611408, 0.296875 (0.660 sec)
400.7... logprob:  0.643807, 0.343750 (0.658 sec)
400.8... logprob:  0.604947, 0.289062 (0.662 sec)
400.9... logprob:  0.638500, 0.335938 (0.662 sec)
400.10... logprob:  0.598176, 0.281250 (0.662 sec)
400.11... logprob:  0.638769, 0.335938 (0.662 sec)
400.12... logprob:  0.716857, 0.437500 (0.662 sec)
400.13... logprob:  0.657015, 0.359375 (0.662 sec)
400.14... logprob:  0.662626, 0.367188 (0.661 sec)
400.15... logprob:  0.685641, 0.398438 (0.660 sec)
400.16... logprob:  0.627079, 0.320312 (0.660 sec)
400.17... logprob:  0.638503, 0.335938 (0.659 sec)
400.18... logprob:  0.638219, 0.335938 (0.659 sec)
400.19... logprob:  0.632700, 0.328125 (0.660 sec)
400.20... logprob:  0.648922, 0.351562 (0.659 sec)
400.21... logprob:  0.643447, 0.343750 (0.659 sec)
400.22... logprob:  0.627892, 0.320312 (0.656 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643447, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936974e-03 [6.762816e-09] 
Layer 'conv1' biases: 6.237887e-07 [1.382700e-10] 
Layer 'conv2' weights[0]: 7.924961e-03 [6.095966e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.028314e-10] 
Layer 'conv3' weights[0]: 7.922538e-03 [5.292031e-09] 
Layer 'conv3' biases: 5.179375e-06 [1.629102e-09] 
Layer 'conv4' weights[0]: 7.955391e-03 [5.170918e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.001936e-08] 
Layer 'conv5' weights[0]: 7.954767e-03 [5.610518e-08] 
Layer 'conv5' biases: 1.000002e+00 [5.888700e-08] 
Layer 'fc6' weights[0]: 7.550902e-03 [7.230001e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.055659e-09] 
Layer 'fc7' weights[0]: 7.438232e-03 [8.939581e-08] 
Layer 'fc7' biases: 9.998522e-01 [7.145166e-08] 
Layer 'fc8' weights[0]: 5.670302e-04 [3.664543e-06] 
Layer 'fc8' biases: 1.713265e-01 [7.540858e-05] 
Train error last 27 batches: 0.635658
-------------------------------------------------------
Not saving because 0.643447 > 0.627087 (334.9: -0.00%)
======================================================= (5.076 sec)
400.23... logprob:  0.622974, 0.312500 (0.660 sec)
400.24... logprob:  0.577181, 0.242188 (0.656 sec)
400.25... logprob:  0.628039, 0.320312 (0.660 sec)
400.26... logprob:  0.674329, 0.390625 (0.659 sec)
400.27... logprob:  0.627926, 0.320312 (0.661 sec)
401.1... logprob:  0.679760, 0.398438 (0.661 sec)
401.2... logprob:  0.596808, 0.273438 (0.661 sec)
401.3... logprob:  0.653846, 0.359375 (0.661 sec)
401.4... logprob:  0.596520, 0.273438 (0.661 sec)
401.5... logprob:  0.590844, 0.265625 (0.660 sec)
401.6... logprob:  0.611406, 0.296875 (0.661 sec)
401.7... logprob:  0.643808, 0.343750 (0.660 sec)
401.8... logprob:  0.604948, 0.289062 (0.662 sec)
401.9... logprob:  0.638499, 0.335938 (0.660 sec)
401.10... logprob:  0.598180, 0.281250 (0.661 sec)
401.11... logprob:  0.638767, 0.335938 (0.661 sec)
401.12... logprob:  0.716842, 0.437500 (0.661 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.645018, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936918e-03 [6.958338e-09] 
Layer 'conv1' biases: 6.245065e-07 [8.334775e-11] 
Layer 'conv2' weights[0]: 7.924899e-03 [5.247031e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.149351e-10] 
Layer 'conv3' weights[0]: 7.922470e-03 [4.538978e-09] 
Layer 'conv3' biases: 5.182544e-06 [7.860218e-10] 
Layer 'conv4' weights[0]: 7.955330e-03 [4.404329e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.413559e-09] 
Layer 'conv5' weights[0]: 7.954689e-03 [8.756766e-09] 
Layer 'conv5' biases: 1.000002e+00 [8.221311e-09] 
Layer 'fc6' weights[0]: 7.550831e-03 [3.906305e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.017228e-10] 
Layer 'fc7' weights[0]: 7.437593e-03 [4.053285e-08] 
Layer 'fc7' biases: 9.998528e-01 [1.231139e-08] 
Layer 'fc8' weights[0]: 6.121404e-04 [5.318806e-07] 
Layer 'fc8' biases: 1.727085e-01 [2.826485e-06] 
Train error last 27 batches: 0.635656
-------------------------------------------------------
Not saving because 0.645018 > 0.627087 (334.9: -0.00%)
======================================================= (5.163 sec)
401.13... logprob:  0.657010, 0.359375 (0.661 sec)
401.14... logprob:  0.662621, 0.367188 (0.660 sec)
401.15... logprob:  0.685635, 0.398438 (0.660 sec)
401.16... logprob:  0.627079, 0.320312 (0.660 sec)
401.17... logprob:  0.638503, 0.335938 (0.661 sec)
401.18... logprob:  0.638219, 0.335938 (0.660 sec)
401.19... logprob:  0.632699, 0.328125 (0.660 sec)
401.20... logprob:  0.648923, 0.351562 (0.660 sec)
401.21... logprob:  0.643448, 0.343750 (0.654 sec)
401.22... logprob:  0.627889, 0.320312 (0.664 sec)
401.23... logprob:  0.622970, 0.312500 (0.660 sec)
401.24... logprob:  0.577166, 0.242188 (0.659 sec)
401.25... logprob:  0.628037, 0.320312 (0.659 sec)
401.26... logprob:  0.674335, 0.390625 (0.655 sec)
401.27... logprob:  0.627924, 0.320312 (0.662 sec)
402.1... logprob:  0.679764, 0.398438 (0.661 sec)
402.2... logprob:  0.596803, 0.273438 (0.661 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643476, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936851e-03 [6.891831e-09] 
Layer 'conv1' biases: 6.261217e-07 [7.125849e-11] 
Layer 'conv2' weights[0]: 7.924837e-03 [4.998491e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.825349e-10] 
Layer 'conv3' weights[0]: 7.922405e-03 [4.535847e-09] 
Layer 'conv3' biases: 5.197294e-06 [7.671360e-10] 
Layer 'conv4' weights[0]: 7.955262e-03 [4.445371e-09] 
Layer 'conv4' biases: 1.000001e+00 [4.297441e-09] 
Layer 'conv5' weights[0]: 7.954633e-03 [2.467038e-08] 
Layer 'conv5' biases: 1.000002e+00 [2.576103e-08] 
Layer 'fc6' weights[0]: 7.550771e-03 [4.696192e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.546792e-09] 
Layer 'fc7' weights[0]: 7.436981e-03 [5.392068e-08] 
Layer 'fc7' biases: 9.998522e-01 [3.008080e-08] 
Layer 'fc8' weights[0]: 5.706914e-04 [1.539326e-06] 
Layer 'fc8' biases: 1.718390e-01 [4.578460e-05] 
Train error last 27 batches: 0.635655
-------------------------------------------------------
Not saving because 0.643476 > 0.627087 (334.9: -0.00%)
======================================================= (5.121 sec)
402.3... logprob:  0.653847, 0.359375 (0.661 sec)
402.4... logprob:  0.596517, 0.273438 (0.661 sec)
402.5... logprob:  0.590843, 0.265625 (0.661 sec)
402.6... logprob:  0.611407, 0.296875 (0.659 sec)
402.7... logprob:  0.643806, 0.343750 (0.661 sec)
402.8... logprob:  0.604951, 0.289062 (0.662 sec)
402.9... logprob:  0.638498, 0.335938 (0.662 sec)
402.10... logprob:  0.598186, 0.281250 (0.661 sec)
402.11... logprob:  0.638764, 0.335938 (0.662 sec)
402.12... logprob:  0.716819, 0.437500 (0.661 sec)
402.13... logprob:  0.657002, 0.359375 (0.661 sec)
402.14... logprob:  0.662613, 0.367188 (0.661 sec)
402.15... logprob:  0.685625, 0.398438 (0.660 sec)
402.16... logprob:  0.627079, 0.320312 (0.660 sec)
402.17... logprob:  0.638503, 0.335938 (0.661 sec)
402.18... logprob:  0.638219, 0.335938 (0.660 sec)
402.19... logprob:  0.632699, 0.328125 (0.660 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643594, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936782e-03 [6.816628e-09] 
Layer 'conv1' biases: 6.272374e-07 [1.578880e-10] 
Layer 'conv2' weights[0]: 7.924784e-03 [6.555651e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.575885e-10] 
Layer 'conv3' weights[0]: 7.922338e-03 [5.684117e-09] 
Layer 'conv3' biases: 5.205829e-06 [2.053751e-09] 
Layer 'conv4' weights[0]: 7.955207e-03 [5.625222e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.385443e-08] 
Layer 'conv5' weights[0]: 7.954586e-03 [7.741639e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.152580e-08] 
Layer 'fc6' weights[0]: 7.550701e-03 [9.327087e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.345459e-09] 
Layer 'fc7' weights[0]: 7.436311e-03 [1.146359e-07] 
Layer 'fc7' biases: 9.998522e-01 [9.778661e-08] 
Layer 'fc8' weights[0]: 5.784453e-04 [5.056354e-06] 
Layer 'fc8' biases: 1.722623e-01 [1.048926e-04] 
Train error last 27 batches: 0.635653
-------------------------------------------------------
Not saving because 0.643594 > 0.627087 (334.9: -0.00%)
======================================================= (5.060 sec)
402.20... logprob:  0.648923, 0.351562 (0.660 sec)
402.21... logprob:  0.643448, 0.343750 (0.660 sec)
402.22... logprob:  0.627888, 0.320312 (0.660 sec)
402.23... logprob:  0.622968, 0.312500 (0.660 sec)
402.24... logprob:  0.577157, 0.242188 (0.660 sec)
402.25... logprob:  0.628034, 0.320312 (0.661 sec)
402.26... logprob:  0.674338, 0.390625 (0.659 sec)
402.27... logprob:  0.627922, 0.320312 (0.659 sec)
403.1... logprob:  0.679769, 0.398438 (0.661 sec)
403.2... logprob:  0.596797, 0.273438 (0.661 sec)
403.3... logprob:  0.653848, 0.359375 (0.661 sec)
403.4... logprob:  0.596512, 0.273438 (0.661 sec)
403.5... logprob:  0.590838, 0.265625 (0.660 sec)
403.6... logprob:  0.611404, 0.296875 (0.661 sec)
403.7... logprob:  0.643807, 0.343750 (0.661 sec)
403.8... logprob:  0.604950, 0.289062 (0.666 sec)
403.9... logprob:  0.638498, 0.335938 (0.662 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644379, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936710e-03 [6.737151e-09] 
Layer 'conv1' biases: 6.281830e-07 [1.205747e-10] 
Layer 'conv2' weights[0]: 7.924720e-03 [5.848033e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.102846e-10] 
Layer 'conv3' weights[0]: 7.922271e-03 [5.664490e-09] 
Layer 'conv3' biases: 5.212136e-06 [1.861295e-09] 
Layer 'conv4' weights[0]: 7.955142e-03 [5.760306e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.574738e-08] 
Layer 'conv5' weights[0]: 7.954503e-03 [8.791620e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.289712e-08] 
Layer 'fc6' weights[0]: 7.550629e-03 [1.026172e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.425826e-09] 
Layer 'fc7' weights[0]: 7.435701e-03 [1.254947e-07] 
Layer 'fc7' biases: 9.998527e-01 [1.092294e-07] 
Layer 'fc8' weights[0]: 6.007023e-04 [5.696421e-06] 
Layer 'fc8' biases: 1.730408e-01 [1.419677e-04] 
Train error last 27 batches: 0.635652
-------------------------------------------------------
Not saving because 0.644379 > 0.627087 (334.9: -0.00%)
======================================================= (5.043 sec)
403.10... logprob:  0.598187, 0.281250 (0.662 sec)
403.11... logprob:  0.638763, 0.335938 (0.661 sec)
403.12... logprob:  0.716810, 0.437500 (0.662 sec)
403.13... logprob:  0.656999, 0.359375 (0.661 sec)
403.14... logprob:  0.662611, 0.367188 (0.661 sec)
403.15... logprob:  0.685622, 0.398438 (0.660 sec)
403.16... logprob:  0.627079, 0.320312 (0.660 sec)
403.17... logprob:  0.638502, 0.335938 (0.660 sec)
403.18... logprob:  0.638220, 0.335938 (0.660 sec)
403.19... logprob:  0.632699, 0.328125 (0.657 sec)
403.20... logprob:  0.648925, 0.351562 (0.660 sec)
403.21... logprob:  0.643449, 0.343750 (0.660 sec)
403.22... logprob:  0.627885, 0.320312 (0.659 sec)
403.23... logprob:  0.622963, 0.312500 (0.659 sec)
403.24... logprob:  0.577140, 0.242188 (0.660 sec)
403.25... logprob:  0.628031, 0.320312 (0.660 sec)
403.26... logprob:  0.674344, 0.390625 (0.660 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643466, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936641e-03 [6.582737e-09] 
Layer 'conv1' biases: 6.297197e-07 [7.218577e-11] 
Layer 'conv2' weights[0]: 7.924658e-03 [5.046065e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.431628e-10] 
Layer 'conv3' weights[0]: 7.922202e-03 [4.415084e-09] 
Layer 'conv3' biases: 5.225778e-06 [6.003624e-10] 
Layer 'conv4' weights[0]: 7.955078e-03 [4.323190e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.247798e-09] 
Layer 'conv5' weights[0]: 7.954449e-03 [8.113484e-09] 
Layer 'conv5' biases: 1.000002e+00 [7.525047e-09] 
Layer 'fc6' weights[0]: 7.550563e-03 [3.880080e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.696193e-10] 
Layer 'fc7' weights[0]: 7.435065e-03 [3.942763e-08] 
Layer 'fc7' biases: 9.998521e-01 [9.375190e-09] 
Layer 'fc8' weights[0]: 5.688649e-04 [4.469715e-07] 
Layer 'fc8' biases: 1.724192e-01 [2.157861e-05] 
Train error last 27 batches: 0.635651
-------------------------------------------------------
Not saving because 0.643466 > 0.627087 (334.9: -0.00%)
======================================================= (5.177 sec)
403.27... logprob:  0.627920, 0.320312 (0.661 sec)
404.1... logprob:  0.679774, 0.398438 (0.660 sec)
404.2... logprob:  0.596793, 0.273438 (0.661 sec)
404.3... logprob:  0.653849, 0.359375 (0.662 sec)
404.4... logprob:  0.596511, 0.273438 (0.661 sec)
404.5... logprob:  0.590839, 0.265625 (0.661 sec)
404.6... logprob:  0.611407, 0.296875 (0.661 sec)
404.7... logprob:  0.643805, 0.343750 (0.660 sec)
404.8... logprob:  0.604955, 0.289062 (0.661 sec)
404.9... logprob:  0.638496, 0.335938 (0.660 sec)
404.10... logprob:  0.598196, 0.281250 (0.659 sec)
404.11... logprob:  0.638760, 0.335938 (0.662 sec)
404.12... logprob:  0.716778, 0.437500 (0.661 sec)
404.13... logprob:  0.656989, 0.359375 (0.661 sec)
404.14... logprob:  0.662600, 0.367188 (0.661 sec)
404.15... logprob:  0.685607, 0.398438 (0.660 sec)
404.16... logprob:  0.627080, 0.320312 (0.660 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644040, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936587e-03 [6.979112e-09] 
Layer 'conv1' biases: 6.306578e-07 [1.815459e-10] 
Layer 'conv2' weights[0]: 7.924584e-03 [7.114971e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.096522e-10] 
Layer 'conv3' weights[0]: 7.922136e-03 [6.174800e-09] 
Layer 'conv3' biases: 5.232078e-06 [2.494321e-09] 
Layer 'conv4' weights[0]: 7.955019e-03 [6.189000e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.772371e-08] 
Layer 'conv5' weights[0]: 7.954371e-03 [9.953041e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.049685e-07] 
Layer 'fc6' weights[0]: 7.550495e-03 [1.128446e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.068052e-08] 
Layer 'fc7' weights[0]: 7.434422e-03 [1.378739e-07] 
Layer 'fc7' biases: 9.998524e-01 [1.236973e-07] 
Layer 'fc8' weights[0]: 5.928067e-04 [6.483362e-06] 
Layer 'fc8' biases: 1.732595e-01 [1.338824e-04] 
Train error last 27 batches: 0.635649
-------------------------------------------------------
Not saving because 0.644040 > 0.627087 (334.9: -0.00%)
======================================================= (5.047 sec)
404.17... logprob:  0.638502, 0.335938 (0.661 sec)
404.18... logprob:  0.638219, 0.335938 (0.659 sec)
404.19... logprob:  0.632699, 0.328125 (0.660 sec)
404.20... logprob:  0.648925, 0.351562 (0.660 sec)
404.21... logprob:  0.643449, 0.343750 (0.660 sec)
404.22... logprob:  0.627883, 0.320312 (0.660 sec)
404.23... logprob:  0.622960, 0.312500 (0.658 sec)
404.24... logprob:  0.577128, 0.242188 (0.660 sec)
404.25... logprob:  0.628029, 0.320312 (0.657 sec)
404.26... logprob:  0.674350, 0.390625 (0.660 sec)
404.27... logprob:  0.627917, 0.320312 (0.660 sec)
405.1... logprob:  0.679781, 0.398438 (0.661 sec)
405.2... logprob:  0.596784, 0.273438 (0.659 sec)
405.3... logprob:  0.653851, 0.359375 (0.660 sec)
405.4... logprob:  0.596503, 0.273438 (0.661 sec)
405.5... logprob:  0.590833, 0.265625 (0.658 sec)
405.6... logprob:  0.611405, 0.296875 (0.659 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643747, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936522e-03 [7.402019e-09] 
Layer 'conv1' biases: 6.319029e-07 [1.616190e-10] 
Layer 'conv2' weights[0]: 7.924515e-03 [6.256423e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.594225e-10] 
Layer 'conv3' weights[0]: 7.922067e-03 [6.018537e-09] 
Layer 'conv3' biases: 5.242417e-06 [2.192328e-09] 
Layer 'conv4' weights[0]: 7.954956e-03 [6.076847e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.869906e-08] 
Layer 'conv5' weights[0]: 7.954315e-03 [1.052630e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.109833e-07] 
Layer 'fc6' weights[0]: 7.550420e-03 [1.187876e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.128076e-08] 
Layer 'fc7' weights[0]: 7.433795e-03 [1.451833e-07] 
Layer 'fc7' biases: 9.998524e-01 [1.312772e-07] 
Layer 'fc8' weights[0]: 5.841249e-04 [6.809544e-06] 
Layer 'fc8' biases: 1.732267e-01 [1.715730e-04] 
Train error last 27 batches: 0.635648
-------------------------------------------------------
Not saving because 0.643747 > 0.627087 (334.9: -0.00%)
======================================================= (5.029 sec)
405.7... logprob:  0.643806, 0.343750 (0.657 sec)
405.8... logprob:  0.604956, 0.289062 (0.658 sec)
405.9... logprob:  0.638496, 0.335938 (0.657 sec)
405.10... logprob:  0.598198, 0.281250 (0.657 sec)
405.11... logprob:  0.638758, 0.335938 (0.663 sec)
405.12... logprob:  0.716766, 0.437500 (0.661 sec)
405.13... logprob:  0.656984, 0.359375 (0.661 sec)
405.14... logprob:  0.662595, 0.367188 (0.662 sec)
405.15... logprob:  0.685602, 0.398438 (0.659 sec)
405.16... logprob:  0.627080, 0.320312 (0.660 sec)
405.17... logprob:  0.638502, 0.335938 (0.661 sec)
405.18... logprob:  0.638219, 0.335938 (0.660 sec)
405.19... logprob:  0.632698, 0.328125 (0.659 sec)
405.20... logprob:  0.648926, 0.351562 (0.661 sec)
405.21... logprob:  0.643449, 0.343750 (0.659 sec)
405.22... logprob:  0.627882, 0.320312 (0.660 sec)
405.23... logprob:  0.622957, 0.312500 (0.660 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643440, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936449e-03 [6.365804e-09] 
Layer 'conv1' biases: 6.333224e-07 [1.083040e-10] 
Layer 'conv2' weights[0]: 7.924443e-03 [5.378568e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.244438e-10] 
Layer 'conv3' weights[0]: 7.921997e-03 [4.761367e-09] 
Layer 'conv3' biases: 5.254556e-06 [1.111139e-09] 
Layer 'conv4' weights[0]: 7.954886e-03 [4.639212e-09] 
Layer 'conv4' biases: 1.000001e+00 [5.826788e-09] 
Layer 'conv5' weights[0]: 7.954254e-03 [3.247292e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.390998e-08] 
Layer 'fc6' weights[0]: 7.550361e-03 [5.240529e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.496206e-09] 
Layer 'fc7' weights[0]: 7.433145e-03 [6.312950e-08] 
Layer 'fc7' biases: 9.998520e-01 [4.172435e-08] 
Layer 'fc8' weights[0]: 5.639618e-04 [2.117973e-06] 
Layer 'fc8' biases: 1.728939e-01 [3.888744e-05] 
Train error last 27 batches: 0.635646
-------------------------------------------------------
Not saving because 0.643440 > 0.627087 (334.9: -0.00%)
======================================================= (5.100 sec)
405.24... logprob:  0.577120, 0.242188 (0.656 sec)
405.25... logprob:  0.628027, 0.320312 (0.660 sec)
405.26... logprob:  0.674352, 0.390625 (0.660 sec)
405.27... logprob:  0.627916, 0.320312 (0.659 sec)
406.1... logprob:  0.679783, 0.398438 (0.663 sec)
406.2... logprob:  0.596781, 0.273438 (0.661 sec)
406.3... logprob:  0.653852, 0.359375 (0.658 sec)
406.4... logprob:  0.596501, 0.273438 (0.660 sec)
406.5... logprob:  0.590831, 0.265625 (0.662 sec)
406.6... logprob:  0.611405, 0.296875 (0.662 sec)
406.7... logprob:  0.643806, 0.343750 (0.662 sec)
406.8... logprob:  0.604956, 0.289062 (0.660 sec)
406.9... logprob:  0.638495, 0.335938 (0.662 sec)
406.10... logprob:  0.598201, 0.281250 (0.662 sec)
406.11... logprob:  0.638756, 0.335938 (0.660 sec)
406.12... logprob:  0.716753, 0.437500 (0.661 sec)
406.13... logprob:  0.656980, 0.359375 (0.660 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644865, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936376e-03 [6.567822e-09] 
Layer 'conv1' biases: 6.340343e-07 [9.926841e-11] 
Layer 'conv2' weights[0]: 7.924386e-03 [5.406483e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.418349e-10] 
Layer 'conv3' weights[0]: 7.921935e-03 [4.742843e-09] 
Layer 'conv3' biases: 5.257817e-06 [1.221212e-09] 
Layer 'conv4' weights[0]: 7.954826e-03 [4.649699e-09] 
Layer 'conv4' biases: 1.000001e+00 [6.400969e-09] 
Layer 'conv5' weights[0]: 7.954150e-03 [3.638389e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.823008e-08] 
Layer 'fc6' weights[0]: 7.550303e-03 [5.473972e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.866869e-09] 
Layer 'fc7' weights[0]: 7.432501e-03 [6.652876e-08] 
Layer 'fc7' biases: 9.998528e-01 [4.554870e-08] 
Layer 'fc8' weights[0]: 6.082698e-04 [2.361652e-06] 
Layer 'fc8' biases: 1.742699e-01 [3.907203e-05] 
Train error last 27 batches: 0.635645
-------------------------------------------------------
Not saving because 0.644865 > 0.627087 (334.9: -0.00%)
======================================================= (5.106 sec)
406.14... logprob:  0.662591, 0.367188 (0.661 sec)
406.15... logprob:  0.685598, 0.398438 (0.659 sec)
406.16... logprob:  0.627080, 0.320312 (0.660 sec)
406.17... logprob:  0.638502, 0.335938 (0.662 sec)
406.18... logprob:  0.638219, 0.335938 (0.660 sec)
406.19... logprob:  0.632698, 0.328125 (0.661 sec)
406.20... logprob:  0.648928, 0.351562 (0.660 sec)
406.21... logprob:  0.643450, 0.343750 (0.660 sec)
406.22... logprob:  0.627879, 0.320312 (0.660 sec)
406.23... logprob:  0.622954, 0.312500 (0.665 sec)
406.24... logprob:  0.577106, 0.242188 (0.659 sec)
406.25... logprob:  0.628025, 0.320312 (0.660 sec)
406.26... logprob:  0.674358, 0.390625 (0.660 sec)
406.27... logprob:  0.627914, 0.320312 (0.662 sec)
407.1... logprob:  0.679788, 0.398438 (0.660 sec)
407.2... logprob:  0.596776, 0.273438 (0.662 sec)
407.3... logprob:  0.653852, 0.359375 (0.661 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643482, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936308e-03 [6.749078e-09] 
Layer 'conv1' biases: 6.356090e-07 [6.669286e-11] 
Layer 'conv2' weights[0]: 7.924321e-03 [5.019681e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.553857e-10] 
Layer 'conv3' weights[0]: 7.921863e-03 [4.442871e-09] 
Layer 'conv3' biases: 5.272200e-06 [6.247473e-10] 
Layer 'conv4' weights[0]: 7.954760e-03 [4.330452e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.483435e-09] 
Layer 'conv5' weights[0]: 7.954128e-03 [9.812463e-09] 
Layer 'conv5' biases: 1.000002e+00 [9.567085e-09] 
Layer 'fc6' weights[0]: 7.550234e-03 [3.929741e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.570772e-10] 
Layer 'fc7' weights[0]: 7.431846e-03 [4.059615e-08] 
Layer 'fc7' biases: 9.998521e-01 [1.161209e-08] 
Layer 'fc8' weights[0]: 5.698345e-04 [5.881320e-07] 
Layer 'fc8' biases: 1.734608e-01 [2.072105e-05] 
Train error last 27 batches: 0.635645
-------------------------------------------------------
Not saving because 0.643482 > 0.627087 (334.9: -0.00%)
======================================================= (5.176 sec)
407.4... logprob:  0.596498, 0.273438 (0.662 sec)
407.5... logprob:  0.590830, 0.265625 (0.661 sec)
407.6... logprob:  0.611405, 0.296875 (0.662 sec)
407.7... logprob:  0.643805, 0.343750 (0.661 sec)
407.8... logprob:  0.604960, 0.289062 (0.662 sec)
407.9... logprob:  0.638494, 0.335938 (0.659 sec)
407.10... logprob:  0.598207, 0.281250 (0.662 sec)
407.11... logprob:  0.638753, 0.335938 (0.661 sec)
407.12... logprob:  0.716729, 0.437500 (0.662 sec)
407.13... logprob:  0.656972, 0.359375 (0.660 sec)
407.14... logprob:  0.662584, 0.367188 (0.662 sec)
407.15... logprob:  0.685588, 0.398438 (0.660 sec)
407.16... logprob:  0.627081, 0.320312 (0.659 sec)
407.17... logprob:  0.638501, 0.335938 (0.660 sec)
407.18... logprob:  0.638219, 0.335938 (0.657 sec)
407.19... logprob:  0.632698, 0.328125 (0.659 sec)
407.20... logprob:  0.648929, 0.351562 (0.660 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643520, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936232e-03 [6.832638e-09] 
Layer 'conv1' biases: 6.367815e-07 [1.633100e-10] 
Layer 'conv2' weights[0]: 7.924263e-03 [6.520518e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.711096e-10] 
Layer 'conv3' weights[0]: 7.921800e-03 [5.691434e-09] 
Layer 'conv3' biases: 5.281388e-06 [2.100399e-09] 
Layer 'conv4' weights[0]: 7.954692e-03 [5.615921e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.424046e-08] 
Layer 'conv5' weights[0]: 7.954051e-03 [7.943981e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.366699e-08] 
Layer 'fc6' weights[0]: 7.550168e-03 [9.547898e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.580009e-09] 
Layer 'fc7' weights[0]: 7.431199e-03 [1.175056e-07] 
Layer 'fc7' biases: 9.998521e-01 [1.007572e-07] 
Layer 'fc8' weights[0]: 5.725875e-04 [5.179351e-06] 
Layer 'fc8' biases: 1.737528e-01 [1.104239e-04] 
Train error last 27 batches: 0.635643
-------------------------------------------------------
Not saving because 0.643520 > 0.627087 (334.9: -0.00%)
======================================================= (5.047 sec)
407.21... logprob:  0.643451, 0.343750 (0.657 sec)
407.22... logprob:  0.627877, 0.320312 (0.659 sec)
407.23... logprob:  0.622950, 0.312500 (0.658 sec)
407.24... logprob:  0.577093, 0.242188 (0.660 sec)
407.25... logprob:  0.628022, 0.320312 (0.660 sec)
407.26... logprob:  0.674363, 0.390625 (0.661 sec)
407.27... logprob:  0.627912, 0.320312 (0.661 sec)
408.1... logprob:  0.679794, 0.398438 (0.662 sec)
408.2... logprob:  0.596769, 0.273438 (0.661 sec)
408.3... logprob:  0.653855, 0.359375 (0.661 sec)
408.4... logprob:  0.596493, 0.273438 (0.661 sec)
408.5... logprob:  0.590825, 0.265625 (0.661 sec)
408.6... logprob:  0.611403, 0.296875 (0.661 sec)
408.7... logprob:  0.643805, 0.343750 (0.661 sec)
408.8... logprob:  0.604961, 0.289062 (0.662 sec)
408.9... logprob:  0.638493, 0.335938 (0.662 sec)
408.10... logprob:  0.598211, 0.281250 (0.659 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644706, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936159e-03 [7.130263e-09] 
Layer 'conv1' biases: 6.376116e-07 [1.467037e-10] 
Layer 'conv2' weights[0]: 7.924195e-03 [6.318346e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.506716e-10] 
Layer 'conv3' weights[0]: 7.921731e-03 [6.112211e-09] 
Layer 'conv3' biases: 5.286091e-06 [2.238287e-09] 
Layer 'conv4' weights[0]: 7.954611e-03 [6.257372e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.927991e-08] 
Layer 'conv5' weights[0]: 7.953964e-03 [1.074780e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.136922e-07] 
Layer 'fc6' weights[0]: 7.550108e-03 [1.207874e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.150486e-08] 
Layer 'fc7' weights[0]: 7.430560e-03 [1.463730e-07] 
Layer 'fc7' biases: 9.998527e-01 [1.324619e-07] 
Layer 'fc8' weights[0]: 6.051392e-04 [6.945485e-06] 
Layer 'fc8' biases: 1.748052e-01 [1.697900e-04] 
Train error last 27 batches: 0.635642
-------------------------------------------------------
Not saving because 0.644706 > 0.627087 (334.9: -0.00%)
======================================================= (5.051 sec)
408.11... logprob:  0.638751, 0.335938 (0.661 sec)
408.12... logprob:  0.716711, 0.437500 (0.661 sec)
408.13... logprob:  0.656966, 0.359375 (0.660 sec)
408.14... logprob:  0.662577, 0.367188 (0.661 sec)
408.15... logprob:  0.685580, 0.398438 (0.661 sec)
408.16... logprob:  0.627081, 0.320312 (0.657 sec)
408.17... logprob:  0.638501, 0.335938 (0.657 sec)
408.18... logprob:  0.638219, 0.335938 (0.660 sec)
408.19... logprob:  0.632697, 0.328125 (0.658 sec)
408.20... logprob:  0.648929, 0.351562 (0.659 sec)
408.21... logprob:  0.643451, 0.343750 (0.661 sec)
408.22... logprob:  0.627874, 0.320312 (0.660 sec)
408.23... logprob:  0.622946, 0.312500 (0.659 sec)
408.24... logprob:  0.577079, 0.242188 (0.659 sec)
408.25... logprob:  0.628018, 0.320312 (0.660 sec)
408.26... logprob:  0.674370, 0.390625 (0.659 sec)
408.27... logprob:  0.627910, 0.320312 (0.661 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643477, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936093e-03 [6.679558e-09] 
Layer 'conv1' biases: 6.391818e-07 [7.119944e-11] 
Layer 'conv2' weights[0]: 7.924120e-03 [4.932297e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.587988e-10] 
Layer 'conv3' weights[0]: 7.921665e-03 [4.440144e-09] 
Layer 'conv3' biases: 5.300365e-06 [6.804353e-10] 
Layer 'conv4' weights[0]: 7.954546e-03 [4.366581e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.327301e-09] 
Layer 'conv5' weights[0]: 7.953920e-03 [1.902520e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.963904e-08] 
Layer 'fc6' weights[0]: 7.550029e-03 [4.356255e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.966153e-09] 
Layer 'fc7' weights[0]: 7.429916e-03 [4.843791e-08] 
Layer 'fc7' biases: 9.998521e-01 [2.336876e-08] 
Layer 'fc8' weights[0]: 5.685963e-04 [1.167362e-06] 
Layer 'fc8' biases: 1.740561e-01 [3.875969e-05] 
Train error last 27 batches: 0.635640
-------------------------------------------------------
Not saving because 0.643477 > 0.627087 (334.9: -0.00%)
======================================================= (5.132 sec)
409.1... logprob:  0.679799, 0.398438 (0.657 sec)
409.2... logprob:  0.596763, 0.273438 (0.661 sec)
409.3... logprob:  0.653856, 0.359375 (0.660 sec)
409.4... logprob:  0.596489, 0.273438 (0.659 sec)
409.5... logprob:  0.590822, 0.265625 (0.661 sec)
409.6... logprob:  0.611403, 0.296875 (0.661 sec)
409.7... logprob:  0.643805, 0.343750 (0.660 sec)
409.8... logprob:  0.604964, 0.289062 (0.663 sec)
409.9... logprob:  0.638493, 0.335938 (0.661 sec)
409.10... logprob:  0.598216, 0.281250 (0.662 sec)
409.11... logprob:  0.638749, 0.335938 (0.662 sec)
409.12... logprob:  0.716688, 0.437500 (0.662 sec)
409.13... logprob:  0.656959, 0.359375 (0.661 sec)
409.14... logprob:  0.662569, 0.367188 (0.661 sec)
409.15... logprob:  0.685570, 0.398438 (0.660 sec)
409.16... logprob:  0.627081, 0.320312 (0.660 sec)
409.17... logprob:  0.638501, 0.335938 (0.660 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643843, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.936019e-03 [6.468488e-09] 
Layer 'conv1' biases: 6.401806e-07 [1.680928e-10] 
Layer 'conv2' weights[0]: 7.924051e-03 [6.793840e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.547398e-10] 
Layer 'conv3' weights[0]: 7.921601e-03 [5.953888e-09] 
Layer 'conv3' biases: 5.307538e-06 [2.317270e-09] 
Layer 'conv4' weights[0]: 7.954485e-03 [5.994674e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.688865e-08] 
Layer 'conv5' weights[0]: 7.953842e-03 [9.462691e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.973716e-08] 
Layer 'fc6' weights[0]: 7.549970e-03 [1.081223e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.014290e-08] 
Layer 'fc7' weights[0]: 7.429276e-03 [1.322302e-07] 
Layer 'fc7' biases: 9.998524e-01 [1.174347e-07] 
Layer 'fc8' weights[0]: 5.859000e-04 [6.139921e-06] 
Layer 'fc8' biases: 1.747258e-01 [1.285645e-04] 
Train error last 27 batches: 0.635638
-------------------------------------------------------
Not saving because 0.643843 > 0.627087 (334.9: -0.00%)
======================================================= (5.039 sec)
409.18... logprob:  0.638220, 0.335938 (0.660 sec)
409.19... logprob:  0.632698, 0.328125 (0.659 sec)
409.20... logprob:  0.648930, 0.351562 (0.661 sec)
409.21... logprob:  0.643451, 0.343750 (0.660 sec)
409.22... logprob:  0.627873, 0.320312 (0.660 sec)
409.23... logprob:  0.622943, 0.312500 (0.660 sec)
409.24... logprob:  0.577066, 0.242188 (0.661 sec)
409.25... logprob:  0.628017, 0.320312 (0.660 sec)
409.26... logprob:  0.674376, 0.390625 (0.661 sec)
409.27... logprob:  0.627908, 0.320312 (0.661 sec)
410.1... logprob:  0.679805, 0.398438 (0.662 sec)
410.2... logprob:  0.596758, 0.273438 (0.660 sec)
410.3... logprob:  0.653858, 0.359375 (0.662 sec)
410.4... logprob:  0.596485, 0.273438 (0.660 sec)
410.5... logprob:  0.590820, 0.265625 (0.661 sec)
410.6... logprob:  0.611403, 0.296875 (0.661 sec)
410.7... logprob:  0.643804, 0.343750 (0.661 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643899, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935951e-03 [6.867361e-09] 
Layer 'conv1' biases: 6.413159e-07 [1.259677e-10] 
Layer 'conv2' weights[0]: 7.923992e-03 [5.787850e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.054142e-10] 
Layer 'conv3' weights[0]: 7.921544e-03 [5.584761e-09] 
Layer 'conv3' biases: 5.316573e-06 [1.837695e-09] 
Layer 'conv4' weights[0]: 7.954411e-03 [5.644705e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.553109e-08] 
Layer 'conv5' weights[0]: 7.953780e-03 [8.688053e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.162800e-08] 
Layer 'fc6' weights[0]: 7.549911e-03 [1.011864e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.260900e-09] 
Layer 'fc7' weights[0]: 7.428622e-03 [1.239700e-07] 
Layer 'fc7' biases: 9.998524e-01 [1.075529e-07] 
Layer 'fc8' weights[0]: 5.874634e-04 [5.561792e-06] 
Layer 'fc8' biases: 1.749599e-01 [1.421609e-04] 
Train error last 27 batches: 0.635637
-------------------------------------------------------
Not saving because 0.643899 > 0.627087 (334.9: -0.00%)
======================================================= (5.057 sec)
410.8... logprob:  0.604966, 0.289062 (0.662 sec)
410.9... logprob:  0.638492, 0.335938 (0.662 sec)
410.10... logprob:  0.598220, 0.281250 (0.662 sec)
410.11... logprob:  0.638747, 0.335938 (0.662 sec)
410.12... logprob:  0.716671, 0.437500 (0.660 sec)
410.13... logprob:  0.656953, 0.359375 (0.662 sec)
410.14... logprob:  0.662564, 0.367188 (0.661 sec)
410.15... logprob:  0.685563, 0.398438 (0.659 sec)
410.16... logprob:  0.627082, 0.320312 (0.659 sec)
410.17... logprob:  0.638501, 0.335938 (0.662 sec)
410.18... logprob:  0.638219, 0.335938 (0.659 sec)
410.19... logprob:  0.632697, 0.328125 (0.662 sec)
410.20... logprob:  0.648931, 0.351562 (0.660 sec)
410.21... logprob:  0.643452, 0.343750 (0.660 sec)
410.22... logprob:  0.627871, 0.320312 (0.660 sec)
410.23... logprob:  0.622939, 0.312500 (0.661 sec)
410.24... logprob:  0.577054, 0.242188 (0.660 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643449, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935882e-03 [6.530789e-09] 
Layer 'conv1' biases: 6.427602e-07 [6.058880e-11] 
Layer 'conv2' weights[0]: 7.923923e-03 [4.888314e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.021136e-10] 
Layer 'conv3' weights[0]: 7.921488e-03 [4.521654e-09] 
Layer 'conv3' biases: 5.329064e-06 [8.436079e-10] 
Layer 'conv4' weights[0]: 7.954346e-03 [4.465198e-09] 
Layer 'conv4' biases: 1.000001e+00 [5.896194e-09] 
Layer 'conv5' weights[0]: 7.953723e-03 [3.297243e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.446057e-08] 
Layer 'fc6' weights[0]: 7.549847e-03 [5.240329e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.465862e-09] 
Layer 'fc7' weights[0]: 7.427997e-03 [6.277659e-08] 
Layer 'fc7' biases: 9.998520e-01 [4.095881e-08] 
Layer 'fc8' weights[0]: 5.644686e-04 [2.052337e-06] 
Layer 'fc8' biases: 1.745525e-01 [6.491147e-05] 
Train error last 27 batches: 0.635635
-------------------------------------------------------
Not saving because 0.643449 > 0.627087 (334.9: -0.00%)
======================================================= (5.102 sec)
410.25... logprob:  0.628014, 0.320312 (0.660 sec)
410.26... logprob:  0.674380, 0.390625 (0.659 sec)
410.27... logprob:  0.627905, 0.320312 (0.661 sec)
411.1... logprob:  0.679809, 0.398438 (0.661 sec)
411.2... logprob:  0.596752, 0.273438 (0.661 sec)
411.3... logprob:  0.653859, 0.359375 (0.661 sec)
411.4... logprob:  0.596481, 0.273438 (0.661 sec)
411.5... logprob:  0.590816, 0.265625 (0.660 sec)
411.6... logprob:  0.611403, 0.296875 (0.661 sec)
411.7... logprob:  0.643805, 0.343750 (0.660 sec)
411.8... logprob:  0.604968, 0.289062 (0.663 sec)
411.9... logprob:  0.638491, 0.335938 (0.662 sec)
411.10... logprob:  0.598225, 0.281250 (0.662 sec)
411.11... logprob:  0.638744, 0.335938 (0.662 sec)
411.12... logprob:  0.716651, 0.437500 (0.661 sec)
411.13... logprob:  0.656947, 0.359375 (0.661 sec)
411.14... logprob:  0.662558, 0.367188 (0.659 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644621, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935820e-03 [6.762988e-09] 
Layer 'conv1' biases: 6.435370e-07 [1.470767e-10] 
Layer 'conv2' weights[0]: 7.923861e-03 [6.167824e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.613524e-10] 
Layer 'conv3' weights[0]: 7.921418e-03 [5.378464e-09] 
Layer 'conv3' biases: 5.333289e-06 [1.824985e-09] 
Layer 'conv4' weights[0]: 7.954285e-03 [5.334850e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.176267e-08] 
Layer 'conv5' weights[0]: 7.953628e-03 [6.572225e-08] 
Layer 'conv5' biases: 1.000002e+00 [6.933787e-08] 
Layer 'fc6' weights[0]: 7.549775e-03 [8.104035e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.037944e-09] 
Layer 'fc7' weights[0]: 7.427339e-03 [9.929411e-08] 
Layer 'fc7' biases: 9.998524e-01 [8.155035e-08] 
Layer 'fc8' weights[0]: 6.027655e-04 [4.261570e-06] 
Layer 'fc8' biases: 1.757743e-01 [8.320219e-05] 
Train error last 27 batches: 0.635634
-------------------------------------------------------
Not saving because 0.644621 > 0.627087 (334.9: -0.00%)
======================================================= (5.061 sec)
411.15... logprob:  0.685554, 0.398438 (0.659 sec)
411.16... logprob:  0.627081, 0.320312 (0.660 sec)
411.17... logprob:  0.638500, 0.335938 (0.661 sec)
411.18... logprob:  0.638219, 0.335938 (0.661 sec)
411.19... logprob:  0.632697, 0.328125 (0.660 sec)
411.20... logprob:  0.648933, 0.351562 (0.660 sec)
411.21... logprob:  0.643452, 0.343750 (0.659 sec)
411.22... logprob:  0.627869, 0.320312 (0.660 sec)
411.23... logprob:  0.622935, 0.312500 (0.660 sec)
411.24... logprob:  0.577041, 0.242188 (0.660 sec)
411.25... logprob:  0.628011, 0.320312 (0.660 sec)
411.26... logprob:  0.674386, 0.390625 (0.660 sec)
411.27... logprob:  0.627904, 0.320312 (0.661 sec)
412.1... logprob:  0.679816, 0.398438 (0.662 sec)
412.2... logprob:  0.596746, 0.273438 (0.661 sec)
412.3... logprob:  0.653861, 0.359375 (0.662 sec)
412.4... logprob:  0.596477, 0.273438 (0.658 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643517, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935757e-03 [6.920233e-09] 
Layer 'conv1' biases: 6.450277e-07 [8.826608e-11] 
Layer 'conv2' weights[0]: 7.923801e-03 [5.295285e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.519369e-10] 
Layer 'conv3' weights[0]: 7.921359e-03 [4.922275e-09] 
Layer 'conv3' biases: 5.346753e-06 [1.180850e-09] 
Layer 'conv4' weights[0]: 7.954217e-03 [4.862226e-09] 
Layer 'conv4' biases: 1.000001e+00 [8.661650e-09] 
Layer 'conv5' weights[0]: 7.953588e-03 [4.855985e-08] 
Layer 'conv5' biases: 1.000002e+00 [5.103247e-08] 
Layer 'fc6' weights[0]: 7.549708e-03 [6.512748e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.177548e-09] 
Layer 'fc7' weights[0]: 7.426716e-03 [7.939975e-08] 
Layer 'fc7' biases: 9.998520e-01 [6.006578e-08] 
Layer 'fc8' weights[0]: 5.712105e-04 [3.095366e-06] 
Layer 'fc8' biases: 1.751323e-01 [8.369552e-05] 
Train error last 27 batches: 0.635633
-------------------------------------------------------
Not saving because 0.643517 > 0.627087 (334.9: -0.00%)
======================================================= (5.087 sec)
412.5... logprob:  0.590814, 0.265625 (0.661 sec)
412.6... logprob:  0.611402, 0.296875 (0.660 sec)
412.7... logprob:  0.643804, 0.343750 (0.659 sec)
412.8... logprob:  0.604970, 0.289062 (0.663 sec)
412.9... logprob:  0.638490, 0.335938 (0.662 sec)
412.10... logprob:  0.598230, 0.281250 (0.662 sec)
412.11... logprob:  0.638742, 0.335938 (0.662 sec)
412.12... logprob:  0.716632, 0.437500 (0.661 sec)
412.13... logprob:  0.656941, 0.359375 (0.662 sec)
412.14... logprob:  0.662550, 0.367188 (0.661 sec)
412.15... logprob:  0.685546, 0.398438 (0.660 sec)
412.16... logprob:  0.627081, 0.320312 (0.656 sec)
412.17... logprob:  0.638500, 0.335938 (0.665 sec)
412.18... logprob:  0.638219, 0.335938 (0.662 sec)
412.19... logprob:  0.632696, 0.328125 (0.662 sec)
412.20... logprob:  0.648933, 0.351562 (0.663 sec)
412.21... logprob:  0.643453, 0.343750 (0.663 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643473, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935683e-03 [6.878733e-09] 
Layer 'conv1' biases: 6.462625e-07 [1.557597e-10] 
Layer 'conv2' weights[0]: 7.923741e-03 [6.512111e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.402571e-10] 
Layer 'conv3' weights[0]: 7.921286e-03 [5.660730e-09] 
Layer 'conv3' biases: 5.356861e-06 [2.021002e-09] 
Layer 'conv4' weights[0]: 7.954155e-03 [5.566657e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.338464e-08] 
Layer 'conv5' weights[0]: 7.953528e-03 [7.487171e-08] 
Layer 'conv5' biases: 1.000002e+00 [7.875584e-08] 
Layer 'fc6' weights[0]: 7.549634e-03 [9.086056e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.088574e-09] 
Layer 'fc7' weights[0]: 7.426066e-03 [1.118462e-07] 
Layer 'fc7' biases: 9.998519e-01 [9.493854e-08] 
Layer 'fc8' weights[0]: 5.671729e-04 [4.858684e-06] 
Layer 'fc8' biases: 1.752362e-01 [1.053469e-04] 
Train error last 27 batches: 0.635631
-------------------------------------------------------
Not saving because 0.643473 > 0.627087 (334.9: -0.00%)
======================================================= (5.060 sec)
412.22... logprob:  0.627866, 0.320312 (0.661 sec)
412.23... logprob:  0.622933, 0.312500 (0.661 sec)
412.24... logprob:  0.577029, 0.242188 (0.662 sec)
412.25... logprob:  0.628009, 0.320312 (0.662 sec)
412.26... logprob:  0.674391, 0.390625 (0.661 sec)
412.27... logprob:  0.627903, 0.320312 (0.664 sec)
413.1... logprob:  0.679820, 0.398438 (0.662 sec)
413.2... logprob:  0.596741, 0.273438 (0.665 sec)
413.3... logprob:  0.653862, 0.359375 (0.664 sec)
413.4... logprob:  0.596473, 0.273438 (0.664 sec)
413.5... logprob:  0.590810, 0.265625 (0.662 sec)
413.6... logprob:  0.611402, 0.296875 (0.662 sec)
413.7... logprob:  0.643804, 0.343750 (0.663 sec)
413.8... logprob:  0.604971, 0.289062 (0.664 sec)
413.9... logprob:  0.638489, 0.335938 (0.665 sec)
413.10... logprob:  0.598233, 0.281250 (0.664 sec)
413.11... logprob:  0.638740, 0.335938 (0.660 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644998, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935619e-03 [6.871615e-09] 
Layer 'conv1' biases: 6.470053e-07 [1.210284e-10] 
Layer 'conv2' weights[0]: 7.923683e-03 [5.782321e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.818729e-10] 
Layer 'conv3' weights[0]: 7.921224e-03 [5.577525e-09] 
Layer 'conv3' biases: 5.360354e-06 [1.803628e-09] 
Layer 'conv4' weights[0]: 7.954079e-03 [5.671314e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.525602e-08] 
Layer 'conv5' weights[0]: 7.953421e-03 [8.554263e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.051087e-08] 
Layer 'fc6' weights[0]: 7.549569e-03 [1.002036e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.135653e-09] 
Layer 'fc7' weights[0]: 7.425406e-03 [1.215641e-07] 
Layer 'fc7' biases: 9.998526e-01 [1.044313e-07] 
Layer 'fc8' weights[0]: 6.083642e-04 [5.507467e-06] 
Layer 'fc8' biases: 1.765248e-01 [1.369985e-04] 
Train error last 27 batches: 0.635631
-------------------------------------------------------
Not saving because 0.644998 > 0.627087 (334.9: -0.00%)
======================================================= (5.057 sec)
413.12... logprob:  0.716616, 0.437500 (0.663 sec)
413.13... logprob:  0.656935, 0.359375 (0.663 sec)
413.14... logprob:  0.662545, 0.367188 (0.665 sec)
413.15... logprob:  0.685539, 0.398438 (0.662 sec)
413.16... logprob:  0.627082, 0.320312 (0.662 sec)
413.17... logprob:  0.638500, 0.335938 (0.664 sec)
413.18... logprob:  0.638219, 0.335938 (0.664 sec)
413.19... logprob:  0.632696, 0.328125 (0.663 sec)
413.20... logprob:  0.648934, 0.351562 (0.660 sec)
413.21... logprob:  0.643453, 0.343750 (0.663 sec)
413.22... logprob:  0.627866, 0.320312 (0.662 sec)
413.23... logprob:  0.622930, 0.312500 (0.662 sec)
413.24... logprob:  0.577021, 0.242188 (0.663 sec)
413.25... logprob:  0.628007, 0.320312 (0.660 sec)
413.26... logprob:  0.674393, 0.390625 (0.663 sec)
413.27... logprob:  0.627901, 0.320312 (0.664 sec)
414.1... logprob:  0.679823, 0.398438 (0.665 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643467, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935551e-03 [6.720263e-09] 
Layer 'conv1' biases: 6.486243e-07 [8.588548e-11] 
Layer 'conv2' weights[0]: 7.923625e-03 [5.217807e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.500220e-10] 
Layer 'conv3' weights[0]: 7.921153e-03 [4.529520e-09] 
Layer 'conv3' biases: 5.375399e-06 [8.890434e-10] 
Layer 'conv4' weights[0]: 7.954020e-03 [4.444567e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.785147e-09] 
Layer 'conv5' weights[0]: 7.953400e-03 [2.072777e-08] 
Layer 'conv5' biases: 1.000002e+00 [2.135853e-08] 
Layer 'fc6' weights[0]: 7.549502e-03 [4.505533e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.266167e-09] 
Layer 'fc7' weights[0]: 7.424784e-03 [5.137765e-08] 
Layer 'fc7' biases: 9.998518e-01 [2.767824e-08] 
Layer 'fc8' weights[0]: 5.662724e-04 [1.352008e-06] 
Layer 'fc8' biases: 1.756169e-01 [2.456140e-05] 
Train error last 27 batches: 0.635629
-------------------------------------------------------
Not saving because 0.643467 > 0.627087 (334.9: -0.00%)
======================================================= (5.136 sec)
414.2... logprob:  0.596736, 0.273438 (0.664 sec)
414.3... logprob:  0.653863, 0.359375 (0.663 sec)
414.4... logprob:  0.596470, 0.273438 (0.664 sec)
414.5... logprob:  0.590808, 0.265625 (0.664 sec)
414.6... logprob:  0.611401, 0.296875 (0.664 sec)
414.7... logprob:  0.643803, 0.343750 (0.663 sec)
414.8... logprob:  0.604971, 0.289062 (0.666 sec)
414.9... logprob:  0.638488, 0.335938 (0.662 sec)
414.10... logprob:  0.598235, 0.281250 (0.665 sec)
414.11... logprob:  0.638738, 0.335938 (0.664 sec)
414.12... logprob:  0.716605, 0.437500 (0.663 sec)
414.13... logprob:  0.656931, 0.359375 (0.663 sec)
414.14... logprob:  0.662542, 0.367188 (0.661 sec)
414.15... logprob:  0.685535, 0.398438 (0.663 sec)
414.16... logprob:  0.627082, 0.320312 (0.663 sec)
414.17... logprob:  0.638499, 0.335938 (0.663 sec)
414.18... logprob:  0.638220, 0.335938 (0.663 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643699, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935492e-03 [6.553789e-09] 
Layer 'conv1' biases: 6.496653e-07 [1.718857e-10] 
Layer 'conv2' weights[0]: 7.923552e-03 [6.675559e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.261934e-10] 
Layer 'conv3' weights[0]: 7.921092e-03 [5.854015e-09] 
Layer 'conv3' biases: 5.383222e-06 [2.238425e-09] 
Layer 'conv4' weights[0]: 7.953951e-03 [5.838402e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.575175e-08] 
Layer 'conv5' weights[0]: 7.953323e-03 [8.816776e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.296354e-08] 
Layer 'fc6' weights[0]: 7.549436e-03 [1.027760e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.485666e-09] 
Layer 'fc7' weights[0]: 7.424135e-03 [1.258065e-07] 
Layer 'fc7' biases: 9.998521e-01 [1.100621e-07] 
Layer 'fc8' weights[0]: 5.795406e-04 [5.700419e-06] 
Layer 'fc8' biases: 1.761881e-01 [1.209925e-04] 
Train error last 27 batches: 0.635628
-------------------------------------------------------
Not saving because 0.643699 > 0.627087 (334.9: -0.00%)
======================================================= (5.044 sec)
414.19... logprob:  0.632696, 0.328125 (0.663 sec)
414.20... logprob:  0.648935, 0.351562 (0.662 sec)
414.21... logprob:  0.643453, 0.343750 (0.662 sec)
414.22... logprob:  0.627863, 0.320312 (0.663 sec)
414.23... logprob:  0.622926, 0.312500 (0.661 sec)
414.24... logprob:  0.577008, 0.242188 (0.663 sec)
414.25... logprob:  0.628004, 0.320312 (0.663 sec)
414.26... logprob:  0.674398, 0.390625 (0.660 sec)
414.27... logprob:  0.627899, 0.320312 (0.665 sec)
415.1... logprob:  0.679827, 0.398438 (0.664 sec)
415.2... logprob:  0.596731, 0.273438 (0.664 sec)
415.3... logprob:  0.653864, 0.359375 (0.663 sec)
415.4... logprob:  0.596466, 0.273438 (0.664 sec)
415.5... logprob:  0.590806, 0.265625 (0.664 sec)
415.6... logprob:  0.611401, 0.296875 (0.664 sec)
415.7... logprob:  0.643803, 0.343750 (0.662 sec)
415.8... logprob:  0.604975, 0.289062 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644123, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935421e-03 [7.236365e-09] 
Layer 'conv1' biases: 6.506943e-07 [1.439688e-10] 
Layer 'conv2' weights[0]: 7.923489e-03 [6.283961e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.447118e-10] 
Layer 'conv3' weights[0]: 7.921022e-03 [6.038774e-09] 
Layer 'conv3' biases: 5.390839e-06 [2.183470e-09] 
Layer 'conv4' weights[0]: 7.953881e-03 [6.146471e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.862666e-08] 
Layer 'conv5' weights[0]: 7.953246e-03 [1.040177e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.097454e-07] 
Layer 'fc6' weights[0]: 7.549367e-03 [1.173538e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.112325e-08] 
Layer 'fc7' weights[0]: 7.423471e-03 [1.427526e-07] 
Layer 'fc7' biases: 9.998523e-01 [1.285354e-07] 
Layer 'fc8' weights[0]: 5.917970e-04 [6.663465e-06] 
Layer 'fc8' biases: 1.767065e-01 [1.679073e-04] 
Train error last 27 batches: 0.635627
-------------------------------------------------------
Not saving because 0.644123 > 0.627087 (334.9: -0.00%)
======================================================= (5.051 sec)
415.9... logprob:  0.638487, 0.335938 (0.664 sec)
415.10... logprob:  0.598242, 0.281250 (0.665 sec)
415.11... logprob:  0.638736, 0.335938 (0.665 sec)
415.12... logprob:  0.716581, 0.437500 (0.663 sec)
415.13... logprob:  0.656924, 0.359375 (0.663 sec)
415.14... logprob:  0.662533, 0.367188 (0.665 sec)
415.15... logprob:  0.685524, 0.398438 (0.664 sec)
415.16... logprob:  0.627083, 0.320312 (0.662 sec)
415.17... logprob:  0.638500, 0.335938 (0.663 sec)
415.18... logprob:  0.638219, 0.335938 (0.663 sec)
415.19... logprob:  0.632695, 0.328125 (0.664 sec)
415.20... logprob:  0.648936, 0.351562 (0.664 sec)
415.21... logprob:  0.643454, 0.343750 (0.661 sec)
415.22... logprob:  0.627861, 0.320312 (0.662 sec)
415.23... logprob:  0.622923, 0.312500 (0.663 sec)
415.24... logprob:  0.576993, 0.242188 (0.662 sec)
415.25... logprob:  0.628002, 0.320312 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643466, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935359e-03 [6.645752e-09] 
Layer 'conv1' biases: 6.521592e-07 [6.832343e-11] 
Layer 'conv2' weights[0]: 7.923422e-03 [4.957349e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.571013e-10] 
Layer 'conv3' weights[0]: 7.920946e-03 [4.635992e-09] 
Layer 'conv3' biases: 5.403655e-06 [1.004476e-09] 
Layer 'conv4' weights[0]: 7.953821e-03 [4.617534e-09] 
Layer 'conv4' biases: 1.000001e+00 [7.566162e-09] 
Layer 'conv5' weights[0]: 7.953200e-03 [4.209640e-08] 
Layer 'conv5' biases: 1.000002e+00 [4.422544e-08] 
Layer 'fc6' weights[0]: 7.549297e-03 [5.951567e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.475643e-09] 
Layer 'fc7' weights[0]: 7.422860e-03 [7.262826e-08] 
Layer 'fc7' biases: 9.998517e-01 [5.269068e-08] 
Layer 'fc8' weights[0]: 5.655397e-04 [2.654166e-06] 
Layer 'fc8' biases: 1.762131e-01 [7.911590e-05] 
Train error last 27 batches: 0.635625
-------------------------------------------------------
Not saving because 0.643466 > 0.627087 (334.9: -0.00%)
======================================================= (5.104 sec)
415.26... logprob:  0.674404, 0.390625 (0.663 sec)
415.27... logprob:  0.627897, 0.320312 (0.663 sec)
416.1... logprob:  0.679833, 0.398438 (0.664 sec)
416.2... logprob:  0.596725, 0.273438 (0.664 sec)
416.3... logprob:  0.653866, 0.359375 (0.665 sec)
416.4... logprob:  0.596462, 0.273438 (0.663 sec)
416.5... logprob:  0.590803, 0.265625 (0.663 sec)
416.6... logprob:  0.611400, 0.296875 (0.664 sec)
416.7... logprob:  0.643802, 0.343750 (0.665 sec)
416.8... logprob:  0.604977, 0.289062 (0.664 sec)
416.9... logprob:  0.638487, 0.335938 (0.665 sec)
416.10... logprob:  0.598246, 0.281250 (0.662 sec)
416.11... logprob:  0.638734, 0.335938 (0.663 sec)
416.12... logprob:  0.716564, 0.437500 (0.661 sec)
416.13... logprob:  0.656918, 0.359375 (0.663 sec)
416.14... logprob:  0.662528, 0.367188 (0.664 sec)
416.15... logprob:  0.685516, 0.398438 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644276, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935294e-03 [7.316107e-09] 
Layer 'conv1' biases: 6.530329e-07 [2.015166e-10] 
Layer 'conv2' weights[0]: 7.923354e-03 [7.510984e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.997247e-10] 
Layer 'conv3' weights[0]: 7.920876e-03 [6.480238e-09] 
Layer 'conv3' biases: 5.409212e-06 [2.760312e-09] 
Layer 'conv4' weights[0]: 7.953759e-03 [6.527605e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.997770e-08] 
Layer 'conv5' weights[0]: 7.953102e-03 [1.117035e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.178878e-07] 
Layer 'fc6' weights[0]: 7.549215e-03 [1.250642e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.199474e-08] 
Layer 'fc7' weights[0]: 7.422195e-03 [1.512522e-07] 
Layer 'fc7' biases: 9.998523e-01 [1.380572e-07] 
Layer 'fc8' weights[0]: 5.947899e-04 [7.210685e-06] 
Layer 'fc8' biases: 1.771993e-01 [1.519653e-04] 
Train error last 27 batches: 0.635623
-------------------------------------------------------
Not saving because 0.644276 > 0.627087 (334.9: -0.00%)
======================================================= (5.042 sec)
416.16... logprob:  0.627082, 0.320312 (0.661 sec)
416.17... logprob:  0.638499, 0.335938 (0.663 sec)
416.18... logprob:  0.638218, 0.335938 (0.662 sec)
416.19... logprob:  0.632695, 0.328125 (0.662 sec)
416.20... logprob:  0.648937, 0.351562 (0.662 sec)
416.21... logprob:  0.643455, 0.343750 (0.661 sec)
416.22... logprob:  0.627859, 0.320312 (0.662 sec)
416.23... logprob:  0.622920, 0.312500 (0.663 sec)
416.24... logprob:  0.576982, 0.242188 (0.660 sec)
416.25... logprob:  0.628000, 0.320312 (0.662 sec)
416.26... logprob:  0.674408, 0.390625 (0.662 sec)
416.27... logprob:  0.627895, 0.320312 (0.665 sec)
417.1... logprob:  0.679837, 0.398438 (0.663 sec)
417.2... logprob:  0.596720, 0.273438 (0.665 sec)
417.3... logprob:  0.653866, 0.359375 (0.664 sec)
417.4... logprob:  0.596459, 0.273438 (0.665 sec)
417.5... logprob:  0.590801, 0.265625 (0.663 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643603, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935233e-03 [7.527928e-09] 
Layer 'conv1' biases: 6.543930e-07 [1.362339e-10] 
Layer 'conv2' weights[0]: 7.923292e-03 [5.947812e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.341677e-10] 
Layer 'conv3' weights[0]: 7.920821e-03 [5.711504e-09] 
Layer 'conv3' biases: 5.421147e-06 [1.906789e-09] 
Layer 'conv4' weights[0]: 7.953687e-03 [5.715179e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.572265e-08] 
Layer 'conv5' weights[0]: 7.953048e-03 [8.807098e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.285178e-08] 
Layer 'fc6' weights[0]: 7.549140e-03 [1.030307e-08] 
Layer 'fc6' biases: 1.000000e+00 [9.468167e-09] 
Layer 'fc7' weights[0]: 7.421580e-03 [1.258538e-07] 
Layer 'fc7' biases: 9.998518e-01 [1.097859e-07] 
Layer 'fc8' weights[0]: 5.747833e-04 [5.643382e-06] 
Layer 'fc8' biases: 1.768550e-01 [1.468342e-04] 
Train error last 27 batches: 0.635622
-------------------------------------------------------
Not saving because 0.643603 > 0.627087 (334.9: -0.00%)
======================================================= (5.053 sec)
417.6... logprob:  0.611401, 0.296875 (0.664 sec)
417.7... logprob:  0.643802, 0.343750 (0.662 sec)
417.8... logprob:  0.604978, 0.289062 (0.665 sec)
417.9... logprob:  0.638486, 0.335938 (0.665 sec)
417.10... logprob:  0.598250, 0.281250 (0.664 sec)
417.11... logprob:  0.638732, 0.335938 (0.663 sec)
417.12... logprob:  0.716546, 0.437500 (0.662 sec)
417.13... logprob:  0.656913, 0.359375 (0.665 sec)
417.14... logprob:  0.662521, 0.367188 (0.662 sec)
417.15... logprob:  0.685510, 0.398438 (0.661 sec)
417.16... logprob:  0.627083, 0.320312 (0.663 sec)
417.17... logprob:  0.638500, 0.335938 (0.661 sec)
417.18... logprob:  0.638218, 0.335938 (0.665 sec)
417.19... logprob:  0.632694, 0.328125 (0.663 sec)
417.20... logprob:  0.648937, 0.351562 (0.661 sec)
417.21... logprob:  0.643455, 0.343750 (0.660 sec)
417.22... logprob:  0.627858, 0.320312 (0.663 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643451, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935158e-03 [6.746561e-09] 
Layer 'conv1' biases: 6.557007e-07 [1.377289e-10] 
Layer 'conv2' weights[0]: 7.923218e-03 [6.087219e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.997743e-10] 
Layer 'conv3' weights[0]: 7.920753e-03 [5.282178e-09] 
Layer 'conv3' biases: 5.432184e-06 [1.614740e-09] 
Layer 'conv4' weights[0]: 7.953624e-03 [5.164237e-09] 
Layer 'conv4' biases: 1.000001e+00 [9.924577e-09] 
Layer 'conv5' weights[0]: 7.953001e-03 [5.530759e-08] 
Layer 'conv5' biases: 1.000002e+00 [5.804806e-08] 
Layer 'fc6' weights[0]: 7.549070e-03 [7.155748e-09] 
Layer 'fc6' biases: 9.999999e-01 [5.969479e-09] 
Layer 'fc7' weights[0]: 7.420952e-03 [8.826205e-08] 
Layer 'fc7' biases: 9.998516e-01 [7.030717e-08] 
Layer 'fc8' weights[0]: 5.629013e-04 [3.561235e-06] 
Layer 'fc8' biases: 1.767380e-01 [7.539698e-05] 
Train error last 27 batches: 0.635621
-------------------------------------------------------
Not saving because 0.643451 > 0.627087 (334.9: -0.00%)
======================================================= (5.077 sec)
417.23... logprob:  0.622917, 0.312500 (0.662 sec)
417.24... logprob:  0.576972, 0.242188 (0.662 sec)
417.25... logprob:  0.627997, 0.320312 (0.663 sec)
417.26... logprob:  0.674412, 0.390625 (0.658 sec)
417.27... logprob:  0.627893, 0.320312 (0.665 sec)
418.1... logprob:  0.679842, 0.398438 (0.665 sec)
418.2... logprob:  0.596714, 0.273438 (0.661 sec)
418.3... logprob:  0.653867, 0.359375 (0.665 sec)
418.4... logprob:  0.596454, 0.273438 (0.664 sec)
418.5... logprob:  0.590796, 0.265625 (0.664 sec)
418.6... logprob:  0.611399, 0.296875 (0.664 sec)
418.7... logprob:  0.643802, 0.343750 (0.663 sec)
418.8... logprob:  0.604979, 0.289062 (0.663 sec)
418.9... logprob:  0.638486, 0.335938 (0.664 sec)
418.10... logprob:  0.598252, 0.281250 (0.661 sec)
418.11... logprob:  0.638730, 0.335938 (0.664 sec)
418.12... logprob:  0.716534, 0.437500 (0.663 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644954, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935095e-03 [6.940546e-09] 
Layer 'conv1' biases: 6.564045e-07 [8.100662e-11] 
Layer 'conv2' weights[0]: 7.923163e-03 [5.250598e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.116053e-10] 
Layer 'conv3' weights[0]: 7.920690e-03 [4.541576e-09] 
Layer 'conv3' biases: 5.435482e-06 [7.780570e-10] 
Layer 'conv4' weights[0]: 7.953555e-03 [4.407209e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.235277e-09] 
Layer 'conv5' weights[0]: 7.952904e-03 [8.111315e-09] 
Layer 'conv5' biases: 1.000002e+00 [7.307263e-09] 
Layer 'fc6' weights[0]: 7.549007e-03 [3.885863e-09] 
Layer 'fc6' biases: 9.999999e-01 [8.366524e-10] 
Layer 'fc7' weights[0]: 7.420316e-03 [3.996561e-08] 
Layer 'fc7' biases: 9.998525e-01 [1.133862e-08] 
Layer 'fc8' weights[0]: 6.062483e-04 [4.767260e-07] 
Layer 'fc8' biases: 1.780997e-01 [3.538047e-06] 
Train error last 27 batches: 0.635620
-------------------------------------------------------
Not saving because 0.644954 > 0.627087 (334.9: -0.00%)
======================================================= (5.177 sec)
418.13... logprob:  0.656909, 0.359375 (0.665 sec)
418.14... logprob:  0.662518, 0.367188 (0.664 sec)
418.15... logprob:  0.685506, 0.398438 (0.663 sec)
418.16... logprob:  0.627083, 0.320312 (0.663 sec)
418.17... logprob:  0.638500, 0.335938 (0.664 sec)
418.18... logprob:  0.638219, 0.335938 (0.662 sec)
418.19... logprob:  0.632694, 0.328125 (0.663 sec)
418.20... logprob:  0.648939, 0.351562 (0.663 sec)
418.21... logprob:  0.643456, 0.343750 (0.663 sec)
418.22... logprob:  0.627855, 0.320312 (0.662 sec)
418.23... logprob:  0.622913, 0.312500 (0.662 sec)
418.24... logprob:  0.576956, 0.242188 (0.661 sec)
418.25... logprob:  0.627995, 0.320312 (0.662 sec)
418.26... logprob:  0.674418, 0.390625 (0.663 sec)
418.27... logprob:  0.627891, 0.320312 (0.664 sec)
419.1... logprob:  0.679847, 0.398438 (0.665 sec)
419.2... logprob:  0.596709, 0.273438 (0.665 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643480, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935020e-03 [6.890272e-09] 
Layer 'conv1' biases: 6.579953e-07 [7.143514e-11] 
Layer 'conv2' weights[0]: 7.923103e-03 [4.999895e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.779886e-10] 
Layer 'conv3' weights[0]: 7.920611e-03 [4.521729e-09] 
Layer 'conv3' biases: 5.450273e-06 [7.536801e-10] 
Layer 'conv4' weights[0]: 7.953499e-03 [4.428453e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.965655e-09] 
Layer 'conv5' weights[0]: 7.952857e-03 [2.295166e-08] 
Layer 'conv5' biases: 1.000002e+00 [2.387176e-08] 
Layer 'fc6' weights[0]: 7.548939e-03 [4.610678e-09] 
Layer 'fc6' biases: 9.999999e-01 [2.409742e-09] 
Layer 'fc7' weights[0]: 7.419685e-03 [5.241174e-08] 
Layer 'fc7' biases: 9.998516e-01 [2.834059e-08] 
Layer 'fc8' weights[0]: 5.662077e-04 [1.432496e-06] 
Layer 'fc8' biases: 1.772323e-01 [4.380268e-05] 
Train error last 27 batches: 0.635619
-------------------------------------------------------
Not saving because 0.643480 > 0.627087 (334.9: -0.00%)
======================================================= (5.127 sec)
419.3... logprob:  0.653869, 0.359375 (0.665 sec)
419.4... logprob:  0.596451, 0.273438 (0.662 sec)
419.5... logprob:  0.590795, 0.265625 (0.664 sec)
419.6... logprob:  0.611400, 0.296875 (0.662 sec)
419.7... logprob:  0.643801, 0.343750 (0.664 sec)
419.8... logprob:  0.604984, 0.289062 (0.666 sec)
419.9... logprob:  0.638484, 0.335938 (0.666 sec)
419.10... logprob:  0.598260, 0.281250 (0.665 sec)
419.11... logprob:  0.638727, 0.335938 (0.661 sec)
419.12... logprob:  0.716506, 0.437500 (0.663 sec)
419.13... logprob:  0.656899, 0.359375 (0.664 sec)
419.14... logprob:  0.662508, 0.367188 (0.664 sec)
419.15... logprob:  0.685492, 0.398438 (0.663 sec)
419.16... logprob:  0.627084, 0.320312 (0.663 sec)
419.17... logprob:  0.638499, 0.335938 (0.663 sec)
419.18... logprob:  0.638219, 0.335938 (0.663 sec)
419.19... logprob:  0.632695, 0.328125 (0.663 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643603, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934953e-03 [6.798021e-09] 
Layer 'conv1' biases: 6.590948e-07 [1.554384e-10] 
Layer 'conv2' weights[0]: 7.923034e-03 [6.525984e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.482822e-10] 
Layer 'conv3' weights[0]: 7.920554e-03 [5.658153e-09] 
Layer 'conv3' biases: 5.458789e-06 [2.029722e-09] 
Layer 'conv4' weights[0]: 7.953432e-03 [5.601188e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.363907e-08] 
Layer 'conv5' weights[0]: 7.952788e-03 [7.574686e-08] 
Layer 'conv5' biases: 1.000002e+00 [7.971528e-08] 
Layer 'fc6' weights[0]: 7.548863e-03 [9.134720e-09] 
Layer 'fc6' biases: 9.999999e-01 [8.139614e-09] 
Layer 'fc7' weights[0]: 7.419060e-03 [1.117866e-07] 
Layer 'fc7' biases: 9.998518e-01 [9.476744e-08] 
Layer 'fc8' weights[0]: 5.739368e-04 [4.863648e-06] 
Layer 'fc8' biases: 1.776554e-01 [1.036750e-04] 
Train error last 27 batches: 0.635617
-------------------------------------------------------
Not saving because 0.643603 > 0.627087 (334.9: -0.00%)
======================================================= (5.062 sec)
419.20... logprob:  0.648940, 0.351562 (0.661 sec)
419.21... logprob:  0.643457, 0.343750 (0.663 sec)
419.22... logprob:  0.627853, 0.320312 (0.662 sec)
419.23... logprob:  0.622909, 0.312500 (0.663 sec)
419.24... logprob:  0.576944, 0.242188 (0.664 sec)
419.25... logprob:  0.627992, 0.320312 (0.663 sec)
419.26... logprob:  0.674424, 0.390625 (0.661 sec)
419.27... logprob:  0.627890, 0.320312 (0.664 sec)
420.1... logprob:  0.679853, 0.398438 (0.664 sec)
420.2... logprob:  0.596702, 0.273438 (0.664 sec)
420.3... logprob:  0.653870, 0.359375 (0.665 sec)
420.4... logprob:  0.596445, 0.273438 (0.662 sec)
420.5... logprob:  0.590791, 0.265625 (0.665 sec)
420.6... logprob:  0.611399, 0.296875 (0.664 sec)
420.7... logprob:  0.643801, 0.343750 (0.663 sec)
420.8... logprob:  0.604984, 0.289062 (0.662 sec)
420.9... logprob:  0.638484, 0.335938 (0.666 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644341, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934877e-03 [6.746469e-09] 
Layer 'conv1' biases: 6.600303e-07 [1.203332e-10] 
Layer 'conv2' weights[0]: 7.922972e-03 [5.839778e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.063228e-10] 
Layer 'conv3' weights[0]: 7.920493e-03 [5.649551e-09] 
Layer 'conv3' biases: 5.464994e-06 [1.842213e-09] 
Layer 'conv4' weights[0]: 7.953368e-03 [5.751871e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.568086e-08] 
Layer 'conv5' weights[0]: 7.952713e-03 [8.691595e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.168512e-08] 
Layer 'fc6' weights[0]: 7.548785e-03 [1.012480e-08] 
Layer 'fc6' biases: 9.999999e-01 [9.263628e-09] 
Layer 'fc7' weights[0]: 7.418438e-03 [1.232833e-07] 
Layer 'fc7' biases: 9.998521e-01 [1.065817e-07] 
Layer 'fc8' weights[0]: 5.950831e-04 [5.526932e-06] 
Layer 'fc8' biases: 1.784138e-01 [1.411833e-04] 
Train error last 27 batches: 0.635616
-------------------------------------------------------
Not saving because 0.644341 > 0.627087 (334.9: -0.00%)
======================================================= (5.059 sec)
420.10... logprob:  0.598263, 0.281250 (0.663 sec)
420.11... logprob:  0.638725, 0.335938 (0.665 sec)
420.12... logprob:  0.716490, 0.437500 (0.664 sec)
420.13... logprob:  0.656893, 0.359375 (0.662 sec)
420.14... logprob:  0.662503, 0.367188 (0.663 sec)
420.15... logprob:  0.685485, 0.398438 (0.663 sec)
420.16... logprob:  0.627083, 0.320312 (0.658 sec)
420.17... logprob:  0.638499, 0.335938 (0.664 sec)
420.18... logprob:  0.638218, 0.335938 (0.663 sec)
420.19... logprob:  0.632693, 0.328125 (0.662 sec)
420.20... logprob:  0.648940, 0.351562 (0.667 sec)
420.21... logprob:  0.643456, 0.343750 (0.662 sec)
420.22... logprob:  0.627851, 0.320312 (0.661 sec)
420.23... logprob:  0.622908, 0.312500 (0.663 sec)
420.24... logprob:  0.576936, 0.242188 (0.663 sec)
420.25... logprob:  0.627991, 0.320312 (0.662 sec)
420.26... logprob:  0.674427, 0.390625 (0.662 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643471, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934808e-03 [6.601972e-09] 
Layer 'conv1' biases: 6.615330e-07 [7.306152e-11] 
Layer 'conv2' weights[0]: 7.922910e-03 [5.060729e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.450330e-10] 
Layer 'conv3' weights[0]: 7.920426e-03 [4.418819e-09] 
Layer 'conv3' biases: 5.478532e-06 [6.032016e-10] 
Layer 'conv4' weights[0]: 7.953306e-03 [4.324777e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.055361e-09] 
Layer 'conv5' weights[0]: 7.952654e-03 [7.434187e-09] 
Layer 'conv5' biases: 1.000002e+00 [6.736540e-09] 
Layer 'fc6' weights[0]: 7.548716e-03 [3.863571e-09] 
Layer 'fc6' biases: 9.999999e-01 [7.051228e-10] 
Layer 'fc7' weights[0]: 7.417780e-03 [3.897405e-08] 
Layer 'fc7' biases: 9.998516e-01 [8.504890e-09] 
Layer 'fc8' weights[0]: 5.646639e-04 [3.966259e-07] 
Layer 'fc8' biases: 1.778024e-01 [2.021014e-05] 
Train error last 27 batches: 0.635614
-------------------------------------------------------
Not saving because 0.643471 > 0.627087 (334.9: -0.00%)
======================================================= (5.183 sec)
420.27... logprob:  0.627887, 0.320312 (0.663 sec)
421.1... logprob:  0.679857, 0.398438 (0.663 sec)
421.2... logprob:  0.596699, 0.273438 (0.663 sec)
421.3... logprob:  0.653871, 0.359375 (0.661 sec)
421.4... logprob:  0.596443, 0.273438 (0.663 sec)
421.5... logprob:  0.590788, 0.265625 (0.662 sec)
421.6... logprob:  0.611398, 0.296875 (0.663 sec)
421.7... logprob:  0.643801, 0.343750 (0.664 sec)
421.8... logprob:  0.604985, 0.289062 (0.666 sec)
421.9... logprob:  0.638483, 0.335938 (0.663 sec)
421.10... logprob:  0.598266, 0.281250 (0.665 sec)
421.11... logprob:  0.638723, 0.335938 (0.663 sec)
421.12... logprob:  0.716478, 0.437500 (0.665 sec)
421.13... logprob:  0.656890, 0.359375 (0.664 sec)
421.14... logprob:  0.662499, 0.367188 (0.664 sec)
421.15... logprob:  0.685481, 0.398438 (0.663 sec)
421.16... logprob:  0.627083, 0.320312 (0.664 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644032, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934738e-03 [6.949227e-09] 
Layer 'conv1' biases: 6.624630e-07 [1.803968e-10] 
Layer 'conv2' weights[0]: 7.922843e-03 [7.077551e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.015458e-10] 
Layer 'conv3' weights[0]: 7.920358e-03 [6.134185e-09] 
Layer 'conv3' biases: 5.484860e-06 [2.460129e-09] 
Layer 'conv4' weights[0]: 7.953239e-03 [6.155192e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.741971e-08] 
Layer 'conv5' weights[0]: 7.952580e-03 [9.710361e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.022805e-07] 
Layer 'fc6' weights[0]: 7.548650e-03 [1.105128e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.041044e-08] 
Layer 'fc7' weights[0]: 7.417158e-03 [1.345393e-07] 
Layer 'fc7' biases: 9.998519e-01 [1.199862e-07] 
Layer 'fc8' weights[0]: 5.878145e-04 [6.235777e-06] 
Layer 'fc8' biases: 1.786325e-01 [1.321914e-04] 
Train error last 27 batches: 0.635613
-------------------------------------------------------
Not saving because 0.644032 > 0.627087 (334.9: -0.00%)
======================================================= (5.050 sec)
421.17... logprob:  0.638498, 0.335938 (0.662 sec)
421.18... logprob:  0.638218, 0.335938 (0.660 sec)
421.19... logprob:  0.632693, 0.328125 (0.657 sec)
421.20... logprob:  0.648942, 0.351562 (0.661 sec)
421.21... logprob:  0.643457, 0.343750 (0.660 sec)
421.22... logprob:  0.627849, 0.320312 (0.660 sec)
421.23... logprob:  0.622903, 0.312500 (0.659 sec)
421.24... logprob:  0.576921, 0.242188 (0.660 sec)
421.25... logprob:  0.627987, 0.320312 (0.660 sec)
421.26... logprob:  0.674432, 0.390625 (0.658 sec)
421.27... logprob:  0.627885, 0.320312 (0.661 sec)
422.1... logprob:  0.679862, 0.398438 (0.662 sec)
422.2... logprob:  0.596693, 0.273438 (0.661 sec)
422.3... logprob:  0.653872, 0.359375 (0.661 sec)
422.4... logprob:  0.596439, 0.273438 (0.661 sec)
422.5... logprob:  0.590787, 0.265625 (0.661 sec)
422.6... logprob:  0.611398, 0.296875 (0.660 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643741, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934682e-03 [7.440758e-09] 
Layer 'conv1' biases: 6.636971e-07 [1.613717e-10] 
Layer 'conv2' weights[0]: 7.922780e-03 [6.237014e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.496597e-10] 
Layer 'conv3' weights[0]: 7.920298e-03 [5.995969e-09] 
Layer 'conv3' biases: 5.495249e-06 [2.168897e-09] 
Layer 'conv4' weights[0]: 7.953176e-03 [6.046350e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.849705e-08] 
Layer 'conv5' weights[0]: 7.952528e-03 [1.027820e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.082671e-07] 
Layer 'fc6' weights[0]: 7.548582e-03 [1.166823e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.104014e-08] 
Layer 'fc7' weights[0]: 7.416516e-03 [1.424337e-07] 
Layer 'fc7' biases: 9.998518e-01 [1.282352e-07] 
Layer 'fc8' weights[0]: 5.791280e-04 [6.574663e-06] 
Layer 'fc8' biases: 1.785874e-01 [1.697706e-04] 
Train error last 27 batches: 0.635612
-------------------------------------------------------
Not saving because 0.643741 > 0.627087 (334.9: -0.00%)
======================================================= (5.044 sec)
422.7... logprob:  0.643801, 0.343750 (0.661 sec)
422.8... logprob:  0.604988, 0.289062 (0.662 sec)
422.9... logprob:  0.638482, 0.335938 (0.663 sec)
422.10... logprob:  0.598272, 0.281250 (0.662 sec)
422.11... logprob:  0.638720, 0.335938 (0.662 sec)
422.12... logprob:  0.716455, 0.437500 (0.661 sec)
422.13... logprob:  0.656882, 0.359375 (0.662 sec)
422.14... logprob:  0.662491, 0.367188 (0.658 sec)
422.15... logprob:  0.685471, 0.398438 (0.661 sec)
422.16... logprob:  0.627083, 0.320312 (0.659 sec)
422.17... logprob:  0.638499, 0.335938 (0.661 sec)
422.18... logprob:  0.638218, 0.335938 (0.660 sec)
422.19... logprob:  0.632692, 0.328125 (0.662 sec)
422.20... logprob:  0.648942, 0.351562 (0.659 sec)
422.21... logprob:  0.643457, 0.343750 (0.660 sec)
422.22... logprob:  0.627847, 0.320312 (0.660 sec)
422.23... logprob:  0.622900, 0.312500 (0.661 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643443, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934623e-03 [6.377913e-09] 
Layer 'conv1' biases: 6.650912e-07 [1.091402e-10] 
Layer 'conv2' weights[0]: 7.922712e-03 [5.380549e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.249800e-10] 
Layer 'conv3' weights[0]: 7.920231e-03 [4.758494e-09] 
Layer 'conv3' biases: 5.507463e-06 [1.107312e-09] 
Layer 'conv4' weights[0]: 7.953112e-03 [4.634466e-09] 
Layer 'conv4' biases: 1.000001e+00 [5.732346e-09] 
Layer 'conv5' weights[0]: 7.952454e-03 [3.218645e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.354421e-08] 
Layer 'fc6' weights[0]: 7.548509e-03 [5.231283e-09] 
Layer 'fc6' biases: 9.999999e-01 [3.487314e-09] 
Layer 'fc7' weights[0]: 7.415882e-03 [6.269525e-08] 
Layer 'fc7' biases: 9.998516e-01 [4.121890e-08] 
Layer 'fc8' weights[0]: 5.599787e-04 [2.069849e-06] 
Layer 'fc8' biases: 1.782634e-01 [3.931941e-05] 
Train error last 27 batches: 0.635610
-------------------------------------------------------
Not saving because 0.643443 > 0.627087 (334.9: -0.00%)
======================================================= (5.101 sec)
422.24... logprob:  0.576910, 0.242188 (0.660 sec)
422.25... logprob:  0.627986, 0.320312 (0.660 sec)
422.26... logprob:  0.674436, 0.390625 (0.660 sec)
422.27... logprob:  0.627884, 0.320312 (0.662 sec)
423.1... logprob:  0.679866, 0.398438 (0.657 sec)
423.2... logprob:  0.596687, 0.273438 (0.661 sec)
423.3... logprob:  0.653874, 0.359375 (0.662 sec)
423.4... logprob:  0.596435, 0.273438 (0.659 sec)
423.5... logprob:  0.590782, 0.265625 (0.660 sec)
423.6... logprob:  0.611396, 0.296875 (0.662 sec)
423.7... logprob:  0.643801, 0.343750 (0.661 sec)
423.8... logprob:  0.604989, 0.289062 (0.661 sec)
423.9... logprob:  0.638482, 0.335938 (0.662 sec)
423.10... logprob:  0.598275, 0.281250 (0.662 sec)
423.11... logprob:  0.638719, 0.335938 (0.661 sec)
423.12... logprob:  0.716439, 0.437500 (0.662 sec)
423.13... logprob:  0.656878, 0.359375 (0.661 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644810, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934556e-03 [6.558653e-09] 
Layer 'conv1' biases: 6.657910e-07 [9.702695e-11] 
Layer 'conv2' weights[0]: 7.922645e-03 [5.383502e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.322578e-10] 
Layer 'conv3' weights[0]: 7.920162e-03 [4.722296e-09] 
Layer 'conv3' biases: 5.510631e-06 [1.192793e-09] 
Layer 'conv4' weights[0]: 7.953051e-03 [4.635806e-09] 
Layer 'conv4' biases: 1.000001e+00 [6.226416e-09] 
Layer 'conv5' weights[0]: 7.952397e-03 [3.490394e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.657505e-08] 
Layer 'fc6' weights[0]: 7.548443e-03 [5.375256e-09] 
Layer 'fc6' biases: 9.999999e-01 [3.714800e-09] 
Layer 'fc7' weights[0]: 7.415231e-03 [6.494965e-08] 
Layer 'fc7' biases: 9.998521e-01 [4.369374e-08] 
Layer 'fc8' weights[0]: 6.026385e-04 [2.238204e-06] 
Layer 'fc8' biases: 1.796206e-01 [3.788104e-05] 
Train error last 27 batches: 0.635609
-------------------------------------------------------
Not saving because 0.644810 > 0.627087 (334.9: -0.00%)
======================================================= (5.101 sec)
423.14... logprob:  0.662486, 0.367188 (0.660 sec)
423.15... logprob:  0.685465, 0.398438 (0.660 sec)
423.16... logprob:  0.627084, 0.320312 (0.660 sec)
423.17... logprob:  0.638498, 0.335938 (0.661 sec)
423.18... logprob:  0.638218, 0.335938 (0.661 sec)
423.19... logprob:  0.632692, 0.328125 (0.661 sec)
423.20... logprob:  0.648943, 0.351562 (0.660 sec)
423.21... logprob:  0.643457, 0.343750 (0.660 sec)
423.22... logprob:  0.627846, 0.320312 (0.661 sec)
423.23... logprob:  0.622897, 0.312500 (0.659 sec)
423.24... logprob:  0.576899, 0.242188 (0.660 sec)
423.25... logprob:  0.627983, 0.320312 (0.660 sec)
423.26... logprob:  0.674441, 0.390625 (0.660 sec)
423.27... logprob:  0.627882, 0.320312 (0.661 sec)
424.1... logprob:  0.679870, 0.398438 (0.662 sec)
424.2... logprob:  0.596683, 0.273438 (0.667 sec)
424.3... logprob:  0.653874, 0.359375 (0.661 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643485, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934492e-03 [6.765909e-09] 
Layer 'conv1' biases: 6.673464e-07 [6.642052e-11] 
Layer 'conv2' weights[0]: 7.922588e-03 [5.022739e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.531430e-10] 
Layer 'conv3' weights[0]: 7.920094e-03 [4.442168e-09] 
Layer 'conv3' biases: 5.525111e-06 [6.209891e-10] 
Layer 'conv4' weights[0]: 7.952993e-03 [4.331385e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.287408e-09] 
Layer 'conv5' weights[0]: 7.952327e-03 [8.728354e-09] 
Layer 'conv5' biases: 1.000002e+00 [8.260223e-09] 
Layer 'fc6' weights[0]: 7.548373e-03 [3.896657e-09] 
Layer 'fc6' biases: 9.999999e-01 [8.426426e-10] 
Layer 'fc7' weights[0]: 7.414637e-03 [3.975690e-08] 
Layer 'fc7' biases: 9.998515e-01 [1.014068e-08] 
Layer 'fc8' weights[0]: 5.654540e-04 [5.099417e-07] 
Layer 'fc8' biases: 1.788114e-01 [1.872737e-05] 
Train error last 27 batches: 0.635608
-------------------------------------------------------
Not saving because 0.643485 > 0.627087 (334.9: -0.00%)
======================================================= (5.182 sec)
424.4... logprob:  0.596433, 0.273438 (0.660 sec)
424.5... logprob:  0.590782, 0.265625 (0.662 sec)
424.6... logprob:  0.611397, 0.296875 (0.661 sec)
424.7... logprob:  0.643800, 0.343750 (0.662 sec)
424.8... logprob:  0.604991, 0.289062 (0.662 sec)
424.9... logprob:  0.638481, 0.335938 (0.661 sec)
424.10... logprob:  0.598279, 0.281250 (0.661 sec)
424.11... logprob:  0.638717, 0.335938 (0.661 sec)
424.12... logprob:  0.716423, 0.437500 (0.660 sec)
424.13... logprob:  0.656871, 0.359375 (0.662 sec)
424.14... logprob:  0.662480, 0.367188 (0.661 sec)
424.15... logprob:  0.685458, 0.398438 (0.661 sec)
424.16... logprob:  0.627084, 0.320312 (0.660 sec)
424.17... logprob:  0.638498, 0.335938 (0.660 sec)
424.18... logprob:  0.638218, 0.335938 (0.659 sec)
424.19... logprob:  0.632692, 0.328125 (0.661 sec)
424.20... logprob:  0.648943, 0.351562 (0.660 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643528, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934426e-03 [6.818577e-09] 
Layer 'conv1' biases: 6.685019e-07 [1.634662e-10] 
Layer 'conv2' weights[0]: 7.922518e-03 [6.499533e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.674054e-10] 
Layer 'conv3' weights[0]: 7.920031e-03 [5.673797e-09] 
Layer 'conv3' biases: 5.534261e-06 [2.083346e-09] 
Layer 'conv4' weights[0]: 7.952935e-03 [5.595544e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.402518e-08] 
Layer 'conv5' weights[0]: 7.952266e-03 [7.805692e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.199863e-08] 
Layer 'fc6' weights[0]: 7.548312e-03 [9.393118e-09] 
Layer 'fc6' biases: 9.999999e-01 [8.412316e-09] 
Layer 'fc7' weights[0]: 7.413993e-03 [1.150749e-07] 
Layer 'fc7' biases: 9.998515e-01 [9.832342e-08] 
Layer 'fc8' weights[0]: 5.683945e-04 [5.005106e-06] 
Layer 'fc8' biases: 1.791060e-01 [1.095687e-04] 
Train error last 27 batches: 0.635607
-------------------------------------------------------
Not saving because 0.643528 > 0.627087 (334.9: -0.00%)
======================================================= (5.054 sec)
424.21... logprob:  0.643458, 0.343750 (0.662 sec)
424.22... logprob:  0.627843, 0.320312 (0.661 sec)
424.23... logprob:  0.622894, 0.312500 (0.658 sec)
424.24... logprob:  0.576886, 0.242188 (0.659 sec)
424.25... logprob:  0.627981, 0.320312 (0.660 sec)
424.26... logprob:  0.674446, 0.390625 (0.659 sec)
424.27... logprob:  0.627880, 0.320312 (0.659 sec)
425.1... logprob:  0.679877, 0.398438 (0.661 sec)
425.2... logprob:  0.596677, 0.273438 (0.660 sec)
425.3... logprob:  0.653876, 0.359375 (0.663 sec)
425.4... logprob:  0.596427, 0.273438 (0.670 sec)
425.5... logprob:  0.590777, 0.265625 (0.674 sec)
425.6... logprob:  0.611396, 0.296875 (0.669 sec)
425.7... logprob:  0.643801, 0.343750 (0.662 sec)
425.8... logprob:  0.604993, 0.289062 (0.668 sec)
425.9... logprob:  0.638481, 0.335938 (0.684 sec)
425.10... logprob:  0.598283, 0.281250 (0.662 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644653, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934347e-03 [7.128606e-09] 
Layer 'conv1' biases: 6.693227e-07 [1.469197e-10] 
Layer 'conv2' weights[0]: 7.922453e-03 [6.316209e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.499603e-10] 
Layer 'conv3' weights[0]: 7.919967e-03 [6.108704e-09] 
Layer 'conv3' biases: 5.538880e-06 [2.237501e-09] 
Layer 'conv4' weights[0]: 7.952869e-03 [6.251412e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.917392e-08] 
Layer 'conv5' weights[0]: 7.952213e-03 [1.065609e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.124402e-07] 
Layer 'fc6' weights[0]: 7.548245e-03 [1.195628e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.136137e-08] 
Layer 'fc7' weights[0]: 7.413333e-03 [1.442261e-07] 
Layer 'fc7' biases: 9.998520e-01 [1.301504e-07] 
Layer 'fc8' weights[0]: 5.995439e-04 [6.765415e-06] 
Layer 'fc8' biases: 1.801378e-01 [1.694505e-04] 
Train error last 27 batches: 0.635606
-------------------------------------------------------
Not saving because 0.644653 > 0.627087 (334.9: -0.00%)
======================================================= (5.074 sec)
425.11... logprob:  0.638714, 0.335938 (0.662 sec)
425.12... logprob:  0.716403, 0.437500 (0.672 sec)
425.13... logprob:  0.656865, 0.359375 (0.675 sec)
425.14... logprob:  0.662473, 0.367188 (0.676 sec)
425.15... logprob:  0.685449, 0.398438 (0.673 sec)
425.16... logprob:  0.627085, 0.320312 (0.675 sec)
425.17... logprob:  0.638499, 0.335938 (0.674 sec)
425.18... logprob:  0.638218, 0.335938 (0.676 sec)
425.19... logprob:  0.632692, 0.328125 (0.669 sec)
425.20... logprob:  0.648945, 0.351562 (0.686 sec)
425.21... logprob:  0.643458, 0.343750 (0.685 sec)
425.22... logprob:  0.627842, 0.320312 (0.681 sec)
425.23... logprob:  0.622891, 0.312500 (0.671 sec)
425.24... logprob:  0.576875, 0.242188 (0.671 sec)
425.25... logprob:  0.627978, 0.320312 (0.683 sec)
425.26... logprob:  0.674451, 0.390625 (0.679 sec)
425.27... logprob:  0.627878, 0.320312 (0.681 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643482, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934287e-03 [6.691972e-09] 
Layer 'conv1' biases: 6.708703e-07 [7.129394e-11] 
Layer 'conv2' weights[0]: 7.922386e-03 [4.935020e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.574994e-10] 
Layer 'conv3' weights[0]: 7.919903e-03 [4.433297e-09] 
Layer 'conv3' biases: 5.553290e-06 [6.696469e-10] 
Layer 'conv4' weights[0]: 7.952802e-03 [4.355013e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.097811e-09] 
Layer 'conv5' weights[0]: 7.952133e-03 [1.793197e-08] 
Layer 'conv5' biases: 1.000002e+00 [1.852715e-08] 
Layer 'fc6' weights[0]: 7.548167e-03 [4.296776e-09] 
Layer 'fc6' biases: 9.999999e-01 [1.850098e-09] 
Layer 'fc7' weights[0]: 7.412720e-03 [4.738783e-08] 
Layer 'fc7' biases: 9.998514e-01 [2.206835e-08] 
Layer 'fc8' weights[0]: 5.644394e-04 [1.087709e-06] 
Layer 'fc8' biases: 1.793962e-01 [3.713309e-05] 
Train error last 27 batches: 0.635604
-------------------------------------------------------
Not saving because 0.643482 > 0.627087 (334.9: -0.00%)
======================================================= (5.207 sec)
426.1... logprob:  0.679881, 0.398438 (0.673 sec)
426.2... logprob:  0.596671, 0.273438 (0.674 sec)
426.3... logprob:  0.653877, 0.359375 (0.675 sec)
426.4... logprob:  0.596423, 0.273438 (0.682 sec)
426.5... logprob:  0.590774, 0.265625 (0.675 sec)
426.6... logprob:  0.611395, 0.296875 (0.689 sec)
426.7... logprob:  0.643800, 0.343750 (0.695 sec)
426.8... logprob:  0.604995, 0.289062 (0.689 sec)
426.9... logprob:  0.638480, 0.335938 (0.683 sec)
426.10... logprob:  0.598288, 0.281250 (0.676 sec)
426.11... logprob:  0.638712, 0.335938 (0.681 sec)
426.12... logprob:  0.716385, 0.437500 (0.673 sec)
426.13... logprob:  0.656860, 0.359375 (0.677 sec)
426.14... logprob:  0.662466, 0.367188 (0.678 sec)
426.15... logprob:  0.685440, 0.398438 (0.683 sec)
426.16... logprob:  0.627084, 0.320312 (0.686 sec)
426.17... logprob:  0.638498, 0.335938 (0.680 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643843, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934228e-03 [6.457245e-09] 
Layer 'conv1' biases: 6.718527e-07 [1.665750e-10] 
Layer 'conv2' weights[0]: 7.922324e-03 [6.758158e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.500229e-10] 
Layer 'conv3' weights[0]: 7.919849e-03 [5.931850e-09] 
Layer 'conv3' biases: 5.560366e-06 [2.296905e-09] 
Layer 'conv4' weights[0]: 7.952741e-03 [5.971377e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.664043e-08] 
Layer 'conv5' weights[0]: 7.952090e-03 [9.258673e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.742677e-08] 
Layer 'fc6' weights[0]: 7.548100e-03 [1.062368e-08] 
Layer 'fc6' biases: 9.999999e-01 [9.911807e-09] 
Layer 'fc7' weights[0]: 7.412037e-03 [1.293518e-07] 
Layer 'fc7' biases: 9.998516e-01 [1.141546e-07] 
Layer 'fc8' weights[0]: 5.812441e-04 [5.905347e-06] 
Layer 'fc8' biases: 1.800593e-01 [1.268892e-04] 
Train error last 27 batches: 0.635602
-------------------------------------------------------
Not saving because 0.643843 > 0.627087 (334.9: -0.00%)
======================================================= (5.150 sec)
426.18... logprob:  0.638217, 0.335938 (0.688 sec)
426.19... logprob:  0.632691, 0.328125 (0.688 sec)
426.20... logprob:  0.648945, 0.351562 (0.693 sec)
426.21... logprob:  0.643458, 0.343750 (0.687 sec)
426.22... logprob:  0.627840, 0.320312 (0.686 sec)
426.23... logprob:  0.622888, 0.312500 (0.689 sec)
426.24... logprob:  0.576866, 0.242188 (0.686 sec)
426.25... logprob:  0.627977, 0.320312 (0.689 sec)
426.26... logprob:  0.674454, 0.390625 (0.684 sec)
426.27... logprob:  0.627876, 0.320312 (0.689 sec)
427.1... logprob:  0.679884, 0.398438 (0.687 sec)
427.2... logprob:  0.596667, 0.273438 (0.727 sec)
427.3... logprob:  0.653878, 0.359375 (0.690 sec)
427.4... logprob:  0.596420, 0.273438 (0.688 sec)
427.5... logprob:  0.590772, 0.265625 (0.690 sec)
427.6... logprob:  0.611394, 0.296875 (0.689 sec)
427.7... logprob:  0.643800, 0.343750 (0.687 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643887, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934161e-03 [6.911483e-09] 
Layer 'conv1' biases: 6.729792e-07 [1.258765e-10] 
Layer 'conv2' weights[0]: 7.922255e-03 [5.789653e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.013630e-10] 
Layer 'conv3' weights[0]: 7.919775e-03 [5.576599e-09] 
Layer 'conv3' biases: 5.569441e-06 [1.829798e-09] 
Layer 'conv4' weights[0]: 7.952680e-03 [5.626955e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.532952e-08] 
Layer 'conv5' weights[0]: 7.952023e-03 [8.492911e-08] 
Layer 'conv5' biases: 1.000002e+00 [8.944606e-08] 
Layer 'fc6' weights[0]: 7.548023e-03 [9.988204e-09] 
Layer 'fc6' biases: 9.999999e-01 [9.087402e-09] 
Layer 'fc7' weights[0]: 7.411381e-03 [1.218881e-07] 
Layer 'fc7' biases: 9.998516e-01 [1.051865e-07] 
Layer 'fc8' weights[0]: 5.824853e-04 [5.374579e-06] 
Layer 'fc8' biases: 1.802798e-01 [1.406672e-04] 
Train error last 27 batches: 0.635601
-------------------------------------------------------
Not saving because 0.643887 > 0.627087 (334.9: -0.00%)
======================================================= (5.177 sec)
427.8... logprob:  0.604995, 0.289062 (0.691 sec)
427.9... logprob:  0.638479, 0.335938 (0.722 sec)
427.10... logprob:  0.598290, 0.281250 (0.673 sec)
427.11... logprob:  0.638711, 0.335938 (0.677 sec)
427.12... logprob:  0.716375, 0.437500 (0.683 sec)
427.13... logprob:  0.656856, 0.359375 (0.686 sec)
427.14... logprob:  0.662464, 0.367188 (0.687 sec)
427.15... logprob:  0.685437, 0.398438 (0.681 sec)
427.16... logprob:  0.627085, 0.320312 (0.675 sec)
427.17... logprob:  0.638497, 0.335938 (0.686 sec)
427.18... logprob:  0.638218, 0.335938 (0.668 sec)
427.19... logprob:  0.632692, 0.328125 (0.670 sec)
427.20... logprob:  0.648947, 0.351562 (0.675 sec)
427.21... logprob:  0.643460, 0.343750 (0.672 sec)
427.22... logprob:  0.627838, 0.320312 (0.673 sec)
427.23... logprob:  0.622885, 0.312500 (0.722 sec)
427.24... logprob:  0.576853, 0.242188 (0.674 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643452, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934102e-03 [6.525333e-09] 
Layer 'conv1' biases: 6.744043e-07 [6.079878e-11] 
Layer 'conv2' weights[0]: 7.922190e-03 [4.885102e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.996309e-10] 
Layer 'conv3' weights[0]: 7.919711e-03 [4.514842e-09] 
Layer 'conv3' biases: 5.581956e-06 [8.300313e-10] 
Layer 'conv4' weights[0]: 7.952616e-03 [4.459428e-09] 
Layer 'conv4' biases: 1.000001e+00 [5.831197e-09] 
Layer 'conv5' weights[0]: 7.951944e-03 [3.239404e-08] 
Layer 'conv5' biases: 1.000002e+00 [3.389155e-08] 
Layer 'fc6' weights[0]: 7.547962e-03 [5.197775e-09] 
Layer 'fc6' biases: 9.999999e-01 [3.395232e-09] 
Layer 'fc7' weights[0]: 7.410741e-03 [6.203205e-08] 
Layer 'fc7' biases: 9.998512e-01 [4.013181e-08] 
Layer 'fc8' weights[0]: 5.605554e-04 [1.985281e-06] 
Layer 'fc8' biases: 1.798811e-01 [6.408680e-05] 
Train error last 27 batches: 0.635600
-------------------------------------------------------
Not saving because 0.643452 > 0.627087 (334.9: -0.00%)
======================================================= (5.172 sec)
427.25... logprob:  0.627974, 0.320312 (0.681 sec)
427.26... logprob:  0.674460, 0.390625 (0.670 sec)
427.27... logprob:  0.627875, 0.320312 (0.672 sec)
428.1... logprob:  0.679889, 0.398438 (0.669 sec)
428.2... logprob:  0.596662, 0.273438 (0.675 sec)
428.3... logprob:  0.653879, 0.359375 (0.677 sec)
428.4... logprob:  0.596417, 0.273438 (0.704 sec)
428.5... logprob:  0.590770, 0.265625 (0.674 sec)
428.6... logprob:  0.611395, 0.296875 (0.671 sec)
428.7... logprob:  0.643799, 0.343750 (0.673 sec)
428.8... logprob:  0.604998, 0.289062 (0.684 sec)
428.9... logprob:  0.638478, 0.335938 (0.671 sec)
428.10... logprob:  0.598295, 0.281250 (0.671 sec)
428.11... logprob:  0.638709, 0.335938 (0.672 sec)
428.12... logprob:  0.716355, 0.437500 (0.675 sec)
428.13... logprob:  0.656850, 0.359375 (0.668 sec)
428.14... logprob:  0.662457, 0.367188 (0.670 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644583, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.934030e-03 [6.754874e-09] 
Layer 'conv1' biases: 6.751820e-07 [1.456557e-10] 
Layer 'conv2' weights[0]: 7.922113e-03 [6.137105e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.533309e-10] 
Layer 'conv3' weights[0]: 7.919657e-03 [5.350130e-09] 
Layer 'conv3' biases: 5.585972e-06 [1.799088e-09] 
Layer 'conv4' weights[0]: 7.952553e-03 [5.312818e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.151782e-08] 
Layer 'conv5' weights[0]: 7.951885e-03 [6.400254e-08] 
Layer 'conv5' biases: 1.000002e+00 [6.744346e-08] 
Layer 'fc6' weights[0]: 7.547889e-03 [7.933300e-09] 
Layer 'fc6' biases: 9.999999e-01 [6.850808e-09] 
Layer 'fc7' weights[0]: 7.410044e-03 [9.664586e-08] 
Layer 'fc7' biases: 9.998518e-01 [7.887450e-08] 
Layer 'fc8' weights[0]: 5.974734e-04 [4.080858e-06] 
Layer 'fc8' biases: 1.810873e-01 [8.174778e-05] 
Train error last 27 batches: 0.635599
-------------------------------------------------------
Not saving because 0.644583 > 0.627087 (334.9: -0.00%)
======================================================= (5.098 sec)
428.15... logprob:  0.685429, 0.398438 (0.676 sec)
428.16... logprob:  0.627085, 0.320312 (0.825 sec)
428.17... logprob:  0.638497, 0.335938 (0.674 sec)
428.18... logprob:  0.638218, 0.335938 (0.668 sec)
428.19... logprob:  0.632691, 0.328125 (0.669 sec)
428.20... logprob:  0.648948, 0.351562 (0.669 sec)
428.21... logprob:  0.643459, 0.343750 (0.671 sec)
428.22... logprob:  0.627836, 0.320312 (0.664 sec)
428.23... logprob:  0.622881, 0.312500 (0.669 sec)
428.24... logprob:  0.576840, 0.242188 (0.666 sec)
428.25... logprob:  0.627971, 0.320312 (0.687 sec)
428.26... logprob:  0.674466, 0.390625 (0.668 sec)
428.27... logprob:  0.627873, 0.320312 (0.671 sec)
429.1... logprob:  0.679895, 0.398438 (0.669 sec)
429.2... logprob:  0.596656, 0.273438 (0.670 sec)
429.3... logprob:  0.653882, 0.359375 (0.674 sec)
429.4... logprob:  0.596412, 0.273438 (0.670 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643520, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.933966e-03 [6.917699e-09] 
Layer 'conv1' biases: 6.766620e-07 [8.733950e-11] 
Layer 'conv2' weights[0]: 7.922052e-03 [5.282188e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.422842e-10] 
Layer 'conv3' weights[0]: 7.919601e-03 [4.898608e-09] 
Layer 'conv3' biases: 5.599611e-06 [1.160054e-09] 
Layer 'conv4' weights[0]: 7.952485e-03 [4.833572e-09] 
Layer 'conv4' biases: 1.000001e+00 [8.341824e-09] 
Layer 'conv5' weights[0]: 7.951817e-03 [4.673378e-08] 
Layer 'conv5' biases: 1.000002e+00 [4.907030e-08] 
Layer 'fc6' weights[0]: 7.547820e-03 [6.384493e-09] 
Layer 'fc6' biases: 9.999999e-01 [5.023206e-09] 
Layer 'fc7' weights[0]: 7.409439e-03 [7.748652e-08] 
Layer 'fc7' biases: 9.998512e-01 [5.803782e-08] 
Layer 'fc8' weights[0]: 5.667878e-04 [2.949844e-06] 
Layer 'fc8' biases: 1.804411e-01 [8.172414e-05] 
Train error last 27 batches: 0.635598
-------------------------------------------------------
Not saving because 0.643520 > 0.627087 (334.9: -0.00%)
======================================================= (5.132 sec)
429.5... logprob:  0.590766, 0.265625 (0.672 sec)
429.6... logprob:  0.611394, 0.296875 (0.665 sec)
429.7... logprob:  0.643799, 0.343750 (0.665 sec)
429.8... logprob:  0.605000, 0.289062 (0.669 sec)
429.9... logprob:  0.638477, 0.335938 (0.665 sec)
429.10... logprob:  0.598300, 0.281250 (0.665 sec)
429.11... logprob:  0.638707, 0.335938 (0.666 sec)
429.12... logprob:  0.716335, 0.437500 (0.673 sec)
429.13... logprob:  0.656843, 0.359375 (0.665 sec)
429.14... logprob:  0.662450, 0.367188 (0.667 sec)
429.15... logprob:  0.685420, 0.398438 (0.666 sec)
429.16... logprob:  0.627085, 0.320312 (0.666 sec)
429.17... logprob:  0.638497, 0.335938 (0.668 sec)
429.18... logprob:  0.638218, 0.335938 (0.663 sec)
429.19... logprob:  0.632691, 0.328125 (0.665 sec)
429.20... logprob:  0.648949, 0.351562 (0.666 sec)
429.21... logprob:  0.643460, 0.343750 (0.671 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643478, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.933890e-03 [6.849953e-09] 
Layer 'conv1' biases: 6.778817e-07 [1.559722e-10] 
Layer 'conv2' weights[0]: 7.921979e-03 [6.511998e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.412935e-10] 
Layer 'conv3' weights[0]: 7.919536e-03 [5.651481e-09] 
Layer 'conv3' biases: 5.609549e-06 [2.015907e-09] 
Layer 'conv4' weights[0]: 7.952422e-03 [5.569870e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.334163e-08] 
Layer 'conv5' weights[0]: 7.951754e-03 [7.413368e-08] 
Layer 'conv5' biases: 1.000002e+00 [7.785359e-08] 
Layer 'fc6' weights[0]: 7.547762e-03 [8.980403e-09] 
Layer 'fc6' biases: 9.999999e-01 [7.975854e-09] 
Layer 'fc7' weights[0]: 7.408795e-03 [1.100480e-07] 
Layer 'fc7' biases: 9.998512e-01 [9.309957e-08] 
Layer 'fc8' weights[0]: 5.631740e-04 [4.710626e-06] 
Layer 'fc8' biases: 1.805496e-01 [1.049267e-04] 
Train error last 27 batches: 0.635596
-------------------------------------------------------
Not saving because 0.643478 > 0.627087 (334.9: -0.00%)
======================================================= (5.105 sec)
429.22... logprob:  0.627834, 0.320312 (0.672 sec)
429.23... logprob:  0.622877, 0.312500 (0.669 sec)
429.24... logprob:  0.576828, 0.242188 (0.670 sec)
429.25... logprob:  0.627969, 0.320312 (0.670 sec)
429.26... logprob:  0.674470, 0.390625 (0.664 sec)
429.27... logprob:  0.627871, 0.320312 (0.671 sec)
430.1... logprob:  0.679900, 0.398438 (0.672 sec)
430.2... logprob:  0.596651, 0.273438 (0.670 sec)
430.3... logprob:  0.653883, 0.359375 (0.671 sec)
430.4... logprob:  0.596408, 0.273438 (0.669 sec)
430.5... logprob:  0.590764, 0.265625 (0.671 sec)
430.6... logprob:  0.611394, 0.296875 (0.671 sec)
430.7... logprob:  0.643799, 0.343750 (0.673 sec)
430.8... logprob:  0.605001, 0.289062 (0.673 sec)
430.9... logprob:  0.638477, 0.335938 (0.671 sec)
430.10... logprob:  0.598304, 0.281250 (0.671 sec)
430.11... logprob:  0.638705, 0.335938 (0.668 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644932, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.933836e-03 [6.901059e-09] 
Layer 'conv1' biases: 6.786139e-07 [1.234532e-10] 
Layer 'conv2' weights[0]: 7.921916e-03 [5.809947e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.870645e-10] 
Layer 'conv3' weights[0]: 7.919477e-03 [5.601696e-09] 
Layer 'conv3' biases: 5.612776e-06 [1.820428e-09] 
Layer 'conv4' weights[0]: 7.952356e-03 [5.686291e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.535250e-08] 
Layer 'conv5' weights[0]: 7.951675e-03 [8.566087e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.050103e-08] 
Layer 'fc6' weights[0]: 7.547690e-03 [9.983142e-09] 
Layer 'fc6' biases: 9.999999e-01 [9.082143e-09] 
Layer 'fc7' weights[0]: 7.408158e-03 [1.204054e-07] 
Layer 'fc7' biases: 9.998518e-01 [1.031679e-07] 
Layer 'fc8' weights[0]: 6.027542e-04 [5.384434e-06] 
Layer 'fc8' biases: 1.818177e-01 [1.371584e-04] 
Train error last 27 batches: 0.635596
-------------------------------------------------------
Not saving because 0.644932 > 0.627087 (334.9: -0.00%)
======================================================= (5.106 sec)
430.12... logprob:  0.716318, 0.437500 (0.670 sec)
430.13... logprob:  0.656837, 0.359375 (0.674 sec)
430.14... logprob:  0.662444, 0.367188 (0.666 sec)
430.15... logprob:  0.685412, 0.398438 (0.668 sec)
430.16... logprob:  0.627086, 0.320312 (0.669 sec)
430.17... logprob:  0.638497, 0.335938 (0.671 sec)
430.18... logprob:  0.638218, 0.335938 (0.668 sec)
430.19... logprob:  0.632690, 0.328125 (0.668 sec)
430.20... logprob:  0.648948, 0.351562 (0.668 sec)
430.21... logprob:  0.643460, 0.343750 (0.669 sec)
430.22... logprob:  0.627833, 0.320312 (0.666 sec)
430.23... logprob:  0.622875, 0.312500 (0.665 sec)
430.24... logprob:  0.576821, 0.242188 (0.666 sec)
430.25... logprob:  0.627967, 0.320312 (0.668 sec)
430.26... logprob:  0.674473, 0.390625 (0.674 sec)
430.27... logprob:  0.627869, 0.320312 (0.670 sec)
431.1... logprob:  0.679904, 0.398438 (0.671 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643472, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.933776e-03 [6.696965e-09] 
Layer 'conv1' biases: 6.802215e-07 [8.634053e-11] 
Layer 'conv2' weights[0]: 7.921859e-03 [5.234735e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.538376e-10] 
Layer 'conv3' weights[0]: 7.919405e-03 [4.539642e-09] 
Layer 'conv3' biases: 5.628005e-06 [9.043702e-10] 
Layer 'conv4' weights[0]: 7.952287e-03 [4.457057e-09] 
Layer 'conv4' biases: 1.000001e+00 [3.928447e-09] 
Layer 'conv5' weights[0]: 7.951609e-03 [2.160785e-08] 
Layer 'conv5' biases: 1.000002e+00 [2.228528e-08] 
Layer 'fc6' weights[0]: 7.547625e-03 [4.553307e-09] 
Layer 'fc6' biases: 9.999999e-01 [2.347844e-09] 
Layer 'fc7' weights[0]: 7.407522e-03 [5.193182e-08] 
Layer 'fc7' biases: 9.998511e-01 [2.839709e-08] 
Layer 'fc8' weights[0]: 5.621245e-04 [1.378372e-06] 
Layer 'fc8' biases: 1.809148e-01 [2.632207e-05] 
Train error last 27 batches: 0.635594
-------------------------------------------------------
Not saving because 0.643472 > 0.627087 (334.9: -0.00%)
======================================================= (5.174 sec)
431.2... logprob:  0.596645, 0.273438 (0.673 sec)
431.3... logprob:  0.653884, 0.359375 (0.671 sec)
431.4... logprob:  0.596403, 0.273438 (0.674 sec)
431.5... logprob:  0.590760, 0.265625 (0.670 sec)
431.6... logprob:  0.611392, 0.296875 (0.672 sec)
431.7... logprob:  0.643799, 0.343750 (0.671 sec)
431.8... logprob:  0.605002, 0.289062 (0.671 sec)
431.9... logprob:  0.638476, 0.335938 (0.669 sec)
431.10... logprob:  0.598306, 0.281250 (0.670 sec)
431.11... logprob:  0.638703, 0.335938 (0.672 sec)
431.12... logprob:  0.716308, 0.437500 (0.673 sec)
431.13... logprob:  0.656834, 0.359375 (0.666 sec)
431.14... logprob:  0.662441, 0.367188 (0.669 sec)
431.15... logprob:  0.685408, 0.398438 (0.669 sec)
431.16... logprob:  0.627086, 0.320312 (0.669 sec)
431.17... logprob:  0.638497, 0.335938 (0.673 sec)
431.18... logprob:  0.638218, 0.335938 (0.669 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643704, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.933716e-03 [6.506118e-09] 
Layer 'conv1' biases: 6.812515e-07 [1.696172e-10] 
Layer 'conv2' weights[0]: 7.921793e-03 [6.625908e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.187070e-10] 
Layer 'conv3' weights[0]: 7.919346e-03 [5.817195e-09] 
Layer 'conv3' biases: 5.635502e-06 [2.210574e-09] 
Layer 'conv4' weights[0]: 7.952225e-03 [5.810925e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.555302e-08] 
Layer 'conv5' weights[0]: 7.951552e-03 [8.643100e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.096665e-08] 
Layer 'fc6' weights[0]: 7.547548e-03 [1.010360e-08] 
Layer 'fc6' biases: 9.999999e-01 [9.270790e-09] 
Layer 'fc7' weights[0]: 7.406863e-03 [1.231234e-07] 
Layer 'fc7' biases: 9.998513e-01 [1.069326e-07] 
Layer 'fc8' weights[0]: 5.751000e-04 [5.486443e-06] 
Layer 'fc8' biases: 1.814824e-01 [1.195550e-04] 
Train error last 27 batches: 0.635593
-------------------------------------------------------
Not saving because 0.643704 > 0.627087 (334.9: -0.00%)
======================================================= (5.097 sec)
431.19... logprob:  0.632691, 0.328125 (0.666 sec)
431.20... logprob:  0.648950, 0.351562 (0.664 sec)
431.21... logprob:  0.643462, 0.343750 (0.668 sec)
431.22... logprob:  0.627830, 0.320312 (0.671 sec)
431.23... logprob:  0.622872, 0.312500 (0.666 sec)
431.24... logprob:  0.576805, 0.242188 (0.667 sec)
431.25... logprob:  0.627965, 0.320312 (0.666 sec)
431.26... logprob:  0.674480, 0.390625 (0.666 sec)
431.27... logprob:  0.627868, 0.320312 (0.668 sec)
432.1... logprob:  0.679909, 0.398438 (0.668 sec)
432.2... logprob:  0.596641, 0.273438 (0.668 sec)
432.3... logprob:  0.653885, 0.359375 (0.671 sec)
432.4... logprob:  0.596401, 0.273438 (0.668 sec)
432.5... logprob:  0.590759, 0.265625 (0.666 sec)
432.6... logprob:  0.611393, 0.296875 (0.668 sec)
432.7... logprob:  0.643799, 0.343750 (0.665 sec)
432.8... logprob:  0.605006, 0.289062 (0.674 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644099, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.933649e-03 [7.250728e-09] 
Layer 'conv1' biases: 6.822792e-07 [1.447861e-10] 
Layer 'conv2' weights[0]: 7.921729e-03 [6.284076e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.441778e-10] 
Layer 'conv3' weights[0]: 7.919282e-03 [6.042168e-09] 
Layer 'conv3' biases: 5.643048e-06 [2.186539e-09] 
Layer 'conv4' weights[0]: 7.952154e-03 [6.138669e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.856075e-08] 
Layer 'conv5' weights[0]: 7.951472e-03 [1.025777e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.081542e-07] 
Layer 'fc6' weights[0]: 7.547487e-03 [1.157751e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.094638e-08] 
Layer 'fc7' weights[0]: 7.406209e-03 [1.400692e-07] 
Layer 'fc7' biases: 9.998513e-01 [1.257134e-07] 
Layer 'fc8' weights[0]: 5.866323e-04 [6.454215e-06] 
Layer 'fc8' biases: 1.819837e-01 [1.667105e-04] 
Train error last 27 batches: 0.635592
-------------------------------------------------------
Not saving because 0.644099 > 0.627087 (334.9: -0.00%)
======================================================= (5.081 sec)
432.9... logprob:  0.638475, 0.335938 (0.676 sec)
432.10... logprob:  0.598313, 0.281250 (0.672 sec)
432.11... logprob:  0.638700, 0.335938 (0.673 sec)
432.12... logprob:  0.716281, 0.437500 (0.672 sec)
432.13... logprob:  0.656825, 0.359375 (0.670 sec)
432.14... logprob:  0.662433, 0.367188 (0.672 sec)
432.15... logprob:  0.685396, 0.398438 (0.671 sec)
432.16... logprob:  0.627087, 0.320312 (0.671 sec)
432.17... logprob:  0.638497, 0.335938 (0.675 sec)
432.18... logprob:  0.638218, 0.335938 (0.670 sec)
432.19... logprob:  0.632690, 0.328125 (0.669 sec)
432.20... logprob:  0.648952, 0.351562 (0.671 sec)
432.21... logprob:  0.643462, 0.343750 (0.671 sec)
432.22... logprob:  0.627829, 0.320312 (0.673 sec)
432.23... logprob:  0.622868, 0.312500 (0.669 sec)
432.24... logprob:  0.576793, 0.242188 (0.669 sec)
432.25... logprob:  0.627962, 0.320312 (0.669 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643472, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.933581e-03 [6.619109e-09] 
Layer 'conv1' biases: 6.837379e-07 [6.796565e-11] 
Layer 'conv2' weights[0]: 7.921662e-03 [4.956056e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.514946e-10] 
Layer 'conv3' weights[0]: 7.919208e-03 [4.629586e-09] 
Layer 'conv3' biases: 5.655934e-06 [9.948996e-10] 
Layer 'conv4' weights[0]: 7.952090e-03 [4.608568e-09] 
Layer 'conv4' biases: 1.000001e+00 [7.459420e-09] 
Layer 'conv5' weights[0]: 7.951419e-03 [4.134299e-08] 
Layer 'conv5' biases: 1.000002e+00 [4.335000e-08] 
Layer 'fc6' weights[0]: 7.547425e-03 [5.887051e-09] 
Layer 'fc6' biases: 9.999999e-01 [4.391665e-09] 
Layer 'fc7' weights[0]: 7.405588e-03 [7.151513e-08] 
Layer 'fc7' biases: 9.998510e-01 [5.148887e-08] 
Layer 'fc8' weights[0]: 5.615312e-04 [2.557096e-06] 
Layer 'fc8' biases: 1.814994e-01 [7.797303e-05] 
Train error last 27 batches: 0.635590
-------------------------------------------------------
Not saving because 0.643472 > 0.627087 (334.9: -0.00%)
======================================================= (5.156 sec)
432.26... logprob:  0.674484, 0.390625 (0.666 sec)
432.27... logprob:  0.627865, 0.320312 (0.672 sec)
433.1... logprob:  0.679914, 0.398438 (0.667 sec)
433.2... logprob:  0.596634, 0.273438 (0.667 sec)
433.3... logprob:  0.653887, 0.359375 (0.669 sec)
433.4... logprob:  0.596396, 0.273438 (0.670 sec)
433.5... logprob:  0.590754, 0.265625 (0.670 sec)
433.6... logprob:  0.611392, 0.296875 (0.666 sec)
433.7... logprob:  0.643799, 0.343750 (0.667 sec)
433.8... logprob:  0.605006, 0.289062 (0.673 sec)
433.9... logprob:  0.638474, 0.335938 (0.668 sec)
433.10... logprob:  0.598317, 0.281250 (0.669 sec)
433.11... logprob:  0.638699, 0.335938 (0.669 sec)
433.12... logprob:  0.716265, 0.437500 (0.669 sec)
433.13... logprob:  0.656820, 0.359375 (0.672 sec)
433.14... logprob:  0.662426, 0.367188 (0.668 sec)
433.15... logprob:  0.685389, 0.398438 (0.668 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644256, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.933501e-03 [7.295573e-09] 
Layer 'conv1' biases: 6.845989e-07 [2.001976e-10] 
Layer 'conv2' weights[0]: 7.921583e-03 [7.485340e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.943292e-10] 
Layer 'conv3' weights[0]: 7.919147e-03 [6.449871e-09] 
Layer 'conv3' biases: 5.661278e-06 [2.736386e-09] 
Layer 'conv4' weights[0]: 7.952026e-03 [6.505898e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.979203e-08] 
Layer 'conv5' weights[0]: 7.951347e-03 [1.096021e-07] 
Layer 'conv5' biases: 1.000002e+00 [1.156894e-07] 
Layer 'fc6' weights[0]: 7.547367e-03 [1.222834e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.169894e-08] 
Layer 'fc7' weights[0]: 7.404942e-03 [1.477097e-07] 
Layer 'fc7' biases: 9.998513e-01 [1.342320e-07] 
Layer 'fc8' weights[0]: 5.897820e-04 [6.945706e-06] 
Layer 'fc8' biases: 1.824724e-01 [1.502899e-04] 
Train error last 27 batches: 0.635588
-------------------------------------------------------
Not saving because 0.644256 > 0.627087 (334.9: -0.00%)
======================================================= (5.079 sec)
433.16... logprob:  0.627087, 0.320312 (0.669 sec)
433.17... logprob:  0.638497, 0.335938 (0.669 sec)
433.18... logprob:  0.638218, 0.335938 (0.669 sec)
433.19... logprob:  0.632690, 0.328125 (0.668 sec)
433.20... logprob:  0.648952, 0.351562 (0.668 sec)
433.21... logprob:  0.643462, 0.343750 (0.667 sec)
433.22... logprob:  0.627827, 0.320312 (0.669 sec)
433.23... logprob:  0.622866, 0.312500 (0.751 sec)
433.24... logprob:  0.576782, 0.242188 (0.667 sec)
433.25... logprob:  0.627960, 0.320312 (0.667 sec)
433.26... logprob:  0.674489, 0.390625 (0.669 sec)
433.27... logprob:  0.627864, 0.320312 (0.669 sec)
434.1... logprob:  0.679919, 0.398438 (0.668 sec)
434.2... logprob:  0.596629, 0.273438 (0.668 sec)
434.3... logprob:  0.653887, 0.359375 (0.670 sec)
434.4... logprob:  0.596393, 0.273438 (0.674 sec)
434.5... logprob:  0.590751, 0.265625 (0.669 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643603, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.933443e-03 [7.524071e-09] 
Layer 'conv1' biases: 6.859646e-07 [1.357407e-10] 
Layer 'conv2' weights[0]: 7.921524e-03 [5.934192e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.266799e-10] 
Layer 'conv3' weights[0]: 7.919083e-03 [5.698039e-09] 
Layer 'conv3' biases: 5.673312e-06 [1.898985e-09] 
Layer 'conv4' weights[0]: 7.951959e-03 [5.700797e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.563384e-08] 
Layer 'conv5' weights[0]: 7.951281e-03 [8.636092e-08] 
Layer 'conv5' biases: 1.000002e+00 [9.096256e-08] 
Layer 'fc6' weights[0]: 7.547307e-03 [1.010044e-08] 
Layer 'fc6' biases: 9.999999e-01 [9.230591e-09] 
Layer 'fc7' weights[0]: 7.404323e-03 [1.234218e-07] 
Layer 'fc7' biases: 9.998512e-01 [1.069255e-07] 
Layer 'fc8' weights[0]: 5.701976e-04 [5.435232e-06] 
Layer 'fc8' biases: 1.821207e-01 [1.449070e-04] 
Train error last 27 batches: 0.635587
-------------------------------------------------------
Not saving because 0.643603 > 0.627087 (334.9: -0.00%)
======================================================= (5.096 sec)
434.6... logprob:  0.611392, 0.296875 (0.668 sec)
434.7... logprob:  0.643799, 0.343750 (0.668 sec)
434.8... logprob:  0.605009, 0.289062 (0.671 sec)
434.9... logprob:  0.638473, 0.335938 (0.673 sec)
434.10... logprob:  0.598321, 0.281250 (0.668 sec)
434.11... logprob:  0.638697, 0.335938 (0.670 sec)
434.12... logprob:  0.716245, 0.437500 (0.669 sec)
434.13... logprob:  0.656813, 0.359375 (0.676 sec)
434.14... logprob:  0.662420, 0.367188 (0.667 sec)
434.15... logprob:  0.685380, 0.398438 (0.668 sec)
434.16... logprob:  0.627087, 0.320312 (0.667 sec)
434.17... logprob:  0.638496, 0.335938 (0.667 sec)
434.18... logprob:  0.638218, 0.335938 (0.671 sec)
434.19... logprob:  0.632690, 0.328125 (0.665 sec)
434.20... logprob:  0.648952, 0.351562 (0.666 sec)
434.21... logprob:  0.643463, 0.343750 (0.666 sec)
434.22... logprob:  0.627825, 0.320312 (0.670 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.643455, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.933375e-03 [6.702205e-09] 
Layer 'conv1' biases: 6.872999e-07 [1.387041e-10] 
Layer 'conv2' weights[0]: 7.921460e-03 [6.094430e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.028201e-10] 
Layer 'conv3' weights[0]: 7.919022e-03 [5.278148e-09] 
Layer 'conv3' biases: 5.684378e-06 [1.611629e-09] 
Layer 'conv4' weights[0]: 7.951896e-03 [5.163164e-09] 
Layer 'conv4' biases: 1.000001e+00 [9.864614e-09] 
Layer 'conv5' weights[0]: 7.951206e-03 [5.472660e-08] 
Layer 'conv5' biases: 1.000002e+00 [5.734839e-08] 
Layer 'fc6' weights[0]: 7.547247e-03 [7.086458e-09] 
Layer 'fc6' biases: 9.999999e-01 [5.891658e-09] 
Layer 'fc7' weights[0]: 7.403665e-03 [8.700356e-08] 
Layer 'fc7' biases: 9.998510e-01 [6.896153e-08] 
Layer 'fc8' weights[0]: 5.590250e-04 [3.459156e-06] 
Layer 'fc8' biases: 1.820107e-01 [7.534288e-05] 
Train error last 27 batches: 0.635586
-------------------------------------------------------
Not saving because 0.643455 > 0.627087 (334.9: -0.00%)
======================================================= (5.102 sec)
434.23... logprob:  0.622863, 0.312500 (0.667 sec)
434.24... logprob:  0.576772, 0.242188 (0.667 sec)
434.25... logprob:  0.627958, 0.320312 (0.671 sec)
434.26... logprob:  0.674494, 0.390625 (0.669 sec)
434.27... logprob:  0.627862, 0.320312 (0.674 sec)
435.1... logprob:  0.679924, 0.398438 (0.672 sec)
435.2... logprob:  0.596624, 0.273438 (0.671 sec)
435.3... logprob:  0.653889, 0.359375 (0.671 sec)
435.4... logprob:  0.596389, 0.273438 (0.667 sec)
435.5... logprob:  0.590748, 0.265625 (0.671 sec)
435.6... logprob:  0.611391, 0.296875 (0.671 sec)
435.7... logprob:  0.643798, 0.343750 (0.671 sec)
435.8... logprob:  0.605009, 0.289062 (0.669 sec)
435.9... logprob:  0.638473, 0.335938 (0.675 sec)
435.10... logprob:  0.598324, 0.281250 (0.675 sec)
435.11... logprob:  0.638695, 0.335938 (0.674 sec)
435.12... logprob:  0.716234, 0.437500 (0.671 sec)
=========================
Testing all batches

======================Test output======================
logprob:  0.644892, 0.343750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.933317e-03 [6.945368e-09] 
Layer 'conv1' biases: 6.879651e-07 [8.011172e-11] 
Layer 'conv2' weights[0]: 7.921399e-03 [5.241551e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.053283e-10] 
Layer 'conv3' weights[0]: 7.918962e-03 [4.529467e-09] 
Layer 'conv3' biases: 5.687290e-06 [7.656842e-10] 
Layer 'conv4' weights[0]: 7.951830e-03 [4.403350e-09] 
Layer 'conv4' biases: 1.000001e+00 [1.223112e-09] 
Layer 'conv5' weights[0]: 7.951124e-03 [7.780621e-09] 
Layer 'conv5' biases: 1.000002e+00 [6.866153e-09] 
Layer 'fc6' weights[0]: 7.547188e-03 [3.877696e-09] 
Layer 'fc6' biases: 9.999999e-01 [7.955049e-10] 
Layer 'fc7' weights[0]: 7.402995e-03 [3.966370e-08] 
Layer 'fc7' biases: 9.998516e-01 [1.077708e-08] 
Layer 'fc8' weights[0]: 6.007978e-04 [4.277094e-07] 
Layer 'fc8' biases: 1.833528e-01 [4.220278e-06] 
Train error last 27 batches: 0.635585
-------------------------------------------------------
Not saving because 0.644892 > 0.627087 (334.9: -0.00%)
======================================================= Giving up...
