Initialized data layer 'data', producing 196608 outputs
Initialized data layer 'labels', producing 1 outputs
Initialized convolutional layer 'conv1', producing 63x63 48-channel output
Initialized max-pooling layer 'pool1', producing 31x31 48-channel output
Initialized cross-map response-normalization layer 'rnorm1', producing 31x31 48-channel output
Initialized convolutional layer 'conv2', producing 31x31 128-channel output
Initialized max-pooling layer 'pool2', producing 15x15 128-channel output
Initialized cross-map response-normalization layer 'rnorm2', producing 15x15 128-channel output
Initialized convolutional layer 'conv3', producing 15x15 192-channel output
Initialized convolutional layer 'conv4', producing 15x15 192-channel output
Initialized convolutional layer 'conv5', producing 15x15 128-channel output
Initialized max-pooling layer 'pool5', producing 7x7 128-channel output
Initialized fully-connected layer 'fc6', producing 4096 outputs
Initialized fully-connected layer 'fc7', producing 4096 outputs
Initialized fully-connected layer 'fc8', producing 3 outputs
Initialized softmax layer 'probs', producing 3 outputs
Initialized logistic regression cost 'logprob'
Initialized neuron layer 'conv1_neuron', producing 190512 outputs
Initialized neuron layer 'conv2_neuron', producing 123008 outputs
Initialized neuron layer 'conv3_neuron', producing 43200 outputs
Initialized neuron layer 'conv4_neuron', producing 43200 outputs
Initialized neuron layer 'conv5_neuron', producing 28800 outputs
Initialized neuron layer 'fc6_neuron', producing 4096 outputs
Initialized neuron layer 'fc7_neuron', producing 4096 outputs
=========================
Importing _ConvNet C++ module
=========================
Training ConvNet
Always write savepoints, regardless of test err improvement: 0     [DEFAULT]
Check gradients and quit?                                  : 0     [DEFAULT]
Compress checkpoints?                                      : 0     [DEFAULT]
Conserve GPU memory (slower)?                              : 0     [DEFAULT]
Convert given conv layers to unshared local                :       
Cropped DP: crop border size                               : 4     [DEFAULT]
Cropped DP: logreg layer name (for --multiview-test)       :       [DEFAULT]
Cropped DP: test on multiple patches?                      : 0     [DEFAULT]
Cropped Step: crop border step                             : 1     [DEFAULT]
Data batch range: testing                                  : 871-886 
Data batch range: training                                 : 1-870 
Data path                                                  : /data2/ad6813/pipe-data/Redbox/batches/clamp_detection 
Data provider                                              : basic-leaf256 
GPU override                                               : -1    [DEFAULT]
Layer definition file                                      : /homes/ad6813/Git/pipe-classification/models/decaf-net/zero_init/10-06-2014/layers_decaf.cfg 
Layer parameter file                                       : /homes/ad6813/Git/pipe-classification/models/decaf-net/zero_init/10-06-2014/params_decaf.cfg 
Load file                                                  :       [DEFAULT]
Maximum save file size (MB)                                : 0     [DEFAULT]
Minibatch size                                             : 128   [DEFAULT]
Number of GPUs                                             : 1     [DEFAULT]
Number of epochs                                           : 50000 [DEFAULT]
Save path                                                  : /data2/ad6813/my-nets/saves 
Test and quit?                                             : 0     [DEFAULT]
Test on more than one batch at a time?                     : -1    
Test on one batch at a time?                               : 0     
Testing frequency                                          : 50    
Unshare weight matrices in given layers                    :       
=========================
Running on CUDA device(s) -2
Current time: Tue Jun 17 23:06:02 2014
Saving checkpoints to /data2/ad6813/my-nets/saves/ConvNet__2014-06-17_23.05.49
=========================
1.1... logprob:  1.038718, 0.093750 (1.404 sec)
1.2... logprob:  0.679273, 0.117188 (1.448 sec)
1.3... logprob:  0.976268, 0.101562 (1.419 sec)
1.4... logprob:  1.417891, 0.117188 (1.408 sec)
1.5... logprob:  1.534568, 0.117188 (1.445 sec)
1.6... logprob:  1.777397, 0.140625 (1.396 sec)
1.7... logprob:  0.961413, 0.085938 (1.429 sec)
1.8... logprob:  0.923372, 0.109375 (1.394 sec)
1.9... logprob:  0.482921, 0.085938 (1.402 sec)
1.10... logprob:  0.682210, 0.093750 (1.406 sec)
1.11... logprob:  0.474515, 0.078125 (1.439 sec)
1.12... logprob:  0.514871, 0.125000 (1.226 sec)
1.13... logprob:  0.634068, 0.117188 (1.424 sec)
1.14... logprob:  0.676197, 0.117188 (1.397 sec)
1.15... logprob:  0.730810, 0.101562 (1.401 sec)
1.16... logprob:  0.683186, 0.109375 (1.403 sec)
1.17... logprob:  0.760758, 0.140625 (1.386 sec)
1.18... logprob:  0.292621, 0.054688 (1.393 sec)
1.19... logprob:  0.344561, 0.062500 (1.401 sec)
1.20... logprob:  0.433824, 0.109375 (1.408 sec)
1.21... logprob:  0.470375, 0.117188 (0.979 sec)
1.22... logprob:  0.639229, 0.148438 (1.331 sec)
1.23... logprob:  0.564473, 0.148438 (1.410 sec)
1.24... logprob:  0.333476, 0.070312 (0.990 sec)
1.25... logprob:  0.394871, 0.085938 (0.960 sec)
1.26... logprob:  0.541354, 0.125000 (1.446 sec)
1.27... logprob:  0.394093, 0.101562 (1.393 sec)
1.28... logprob:  0.481288, 0.109375 (1.407 sec)
1.29... logprob:  0.484547, 0.101562 (1.421 sec)
1.30... logprob:  0.386061, 0.093750 (1.420 sec)
1.31... logprob:  0.529434, 0.132812 (1.404 sec)
1.32... logprob:  0.474290, 0.125000 (1.386 sec)
1.33... logprob:  0.544571, 0.125000 (1.446 sec)
1.34... logprob:  0.627058, 0.125000 (1.389 sec)
1.35... logprob:  0.349383, 0.070312 (1.402 sec)
1.36... logprob:  0.567082, 0.132812 (1.401 sec)
1.37... logprob:  0.485056, 0.109375 (1.406 sec)
1.38... logprob:  0.401366, 0.101562 (1.398 sec)
1.39... logprob:  0.614808, 0.187500 (1.436 sec)
1.40... logprob:  0.618337, 0.117188 (1.415 sec)
1.41... logprob:  0.398517, 0.085938 (1.430 sec)
1.42... logprob:  0.436871, 0.101562 (1.413 sec)
1.43... logprob:  0.585568, 0.117188 (1.411 sec)
1.44... logprob:  0.740815, 0.148438 (1.440 sec)
1.45... logprob:  0.421840, 0.093750 (1.390 sec)
1.46... logprob:  0.522758, 0.132812 (1.397 sec)
1.47... logprob:  0.496233, 0.078125 (1.395 sec)
1.48... logprob:  0.496955, 0.140625 (1.429 sec)
1.49... logprob:  0.581236, 0.148438 (1.415 sec)
1.50... logprob:  0.422560, 0.101562 (1.452 sec)
=========================
Testing all batches
batch 871: ({'logprob': [44.05051803588867, 10.0]}, 128)
batch 872: ({'logprob': [72.10887908935547, 19.0]}, 128)
batch 873: ({'logprob': [39.07986831665039, 9.0]}, 128)
batch 874: ({'logprob': [46.331298828125, 11.0]}, 128)
batch 875: ({'logprob': [52.5078239440918, 13.0]}, 128)
batch 876: ({'logprob': [68.7518539428711, 18.0]}, 128)
batch 877: ({'logprob': [45.794254302978516, 11.0]}, 128)
batch 878: ({'logprob': [64.8603515625, 17.0]}, 128)
batch 879: ({'logprob': [76.67420196533203, 21.0]}, 128)
batch 880: ({'logprob': [52.50773239135742, 13.0]}, 128)
batch 881: ({'logprob': [27.266904830932617, 5.0]}, 128)
batch 882: ({'logprob': [54.25267791748047, 14.0]}, 128)
batch 883: ({'logprob': [64.85870361328125, 17.0]}, 128)
batch 884: ({'logprob': [51.97224044799805, 13.0]}, 128)
batch 885: ({'logprob': [50.896453857421875, 13.0]}, 128)
batch 886: ({'logprob': [64.32311248779297, 17.0]}, 128)

======================Test output======================
logprob:  0.427850, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979687e-03 [1.021403e-09] 
Layer 'conv1' biases: 1.475825e-09 [1.979790e-11] 
Layer 'conv2' weights[0]: 7.966606e-03 [1.036612e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.285871e-10] 
Layer 'conv3' weights[0]: 7.964987e-03 [1.105896e-09] 
Layer 'conv3' biases: 3.798307e-08 [4.280873e-10] 
Layer 'conv4' weights[0]: 7.997469e-03 [1.259980e-09] 
Layer 'conv4' biases: 1.000000e+00 [4.451847e-09] 
Layer 'conv5' weights[0]: 7.996368e-03 [2.548105e-08] 
Layer 'conv5' biases: 9.999974e-01 [2.751480e-08] 
Layer 'fc6' weights[0]: 7.593240e-03 [3.775884e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.739887e-09] 
Layer 'fc7' weights[0]: 7.852535e-03 [2.620619e-07] 
Layer 'fc7' biases: 9.999955e-01 [2.501241e-07] 
Layer 'fc8' weights[0]: 5.274193e-04 [2.305847e-05] 
Layer 'fc8' biases: 2.467480e-04 [2.525557e-05] 
Train error last 870 batches: 0.620479
-------------------------------------------------------
Saved checkpoint to /data2/ad6813/my-nets/saves/ConvNet__2014-06-17_23.05.49
======================================================= (12.604 sec)
1.51... logprob:  0.545533, 0.140625 (1.427 sec)
1.52... logprob:  0.523128, 0.148438 (1.405 sec)
1.53... logprob:  0.398817, 0.062500 (1.446 sec)
1.54... logprob:  0.398671, 0.109375 (2.661 sec)
1.55... logprob:  0.326407, 0.078125 (1.404 sec)
1.56... logprob:  0.495967, 0.109375 (1.404 sec)
1.57... logprob:  0.731182, 0.164062 (3.061 sec)
1.58... logprob:  0.453600, 0.101562 (1.414 sec)
1.59... logprob:  0.394475, 0.078125 (1.463 sec)
1.60... logprob:  0.610670, 0.179688 (1.418 sec)
1.61... logprob:  0.393810, 0.093750 (1.458 sec)
1.62... logprob:  0.515464, 0.132812 (1.457 sec)
1.63... logprob:  0.426763, 0.101562 (1.437 sec)
1.64... logprob:  0.519635, 0.125000 (1.411 sec)
1.65... logprob:  0.385683, 0.093750 (1.398 sec)
1.66... logprob:  0.350003, 0.085938 (1.452 sec)
1.67... logprob:  0.299720, 0.062500 (1.386 sec)
1.68... logprob:  0.406701, 0.101562 (1.403 sec)
1.69... logprob:  0.512389, 0.140625 (1.428 sec)
1.70... logprob:  0.333792, 0.078125 (1.421 sec)
1.71... logprob:  0.372184, 0.101562 (1.468 sec)
1.72... logprob:  0.524262, 0.132812 (1.403 sec)
1.73... logprob:  0.461061, 0.117188 (1.424 sec)
1.74... logprob:  0.441558, 0.117188 (1.419 sec)
1.75... logprob:  0.384796, 0.093750 (1.419 sec)
1.76... logprob:  0.436199, 0.109375 (1.439 sec)
1.77... logprob:  0.411228, 0.101562 (1.428 sec)
1.78... logprob:  0.545224, 0.140625 (1.453 sec)
1.79... logprob:  0.465324, 0.125000 (1.407 sec)
1.80... logprob:  0.517387, 0.132812 (1.414 sec)
1.81... logprob:  0.438346, 0.109375 (1.442 sec)
1.82... logprob:  0.246693, 0.039062 (1.420 sec)
1.83... logprob:  0.545554, 0.140625 (1.406 sec)
1.84... logprob:  0.524851, 0.125000 (1.464 sec)
1.85... logprob:  0.459926, 0.117188 (1.422 sec)
1.86... logprob:  0.416937, 0.109375 (1.419 sec)
1.87... logprob:  0.616954, 0.187500 (1.419 sec)
1.88... logprob:  0.575222, 0.156250 (1.410 sec)
1.89... logprob:  0.436657, 0.109375 (1.437 sec)
1.90... logprob:  0.618065, 0.171875 (1.386 sec)
1.91... logprob:  0.333228, 0.078125 (1.399 sec)
1.92... logprob:  0.498614, 0.125000 (1.404 sec)
1.93... logprob:  0.511425, 0.140625 (1.400 sec)
1.94... logprob:  0.442742, 0.109375 (1.396 sec)
1.95... logprob:  0.500683, 0.125000 (1.406 sec)
1.96... logprob:  0.574999, 0.171875 (1.401 sec)
1.97... logprob:  0.448290, 0.117188 (1.394 sec)
1.98... logprob:  0.376917, 0.093750 (1.437 sec)
1.99... logprob:  0.501334, 0.132812 (1.412 sec)
1.100... logprob:  0.299363, 0.070312 (1.403 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.62724304199219, 10.0]}, 128)
batch 872: ({'logprob': [68.30297088623047, 19.0]}, 128)
batch 873: ({'logprob': [39.83127212524414, 9.0]}, 128)
batch 874: ({'logprob': [44.731658935546875, 11.0]}, 128)
batch 875: ({'logprob': [50.95597839355469, 13.0]}, 128)
batch 876: ({'logprob': [65.5218505859375, 18.0]}, 128)
batch 877: ({'logprob': [45.39423751831055, 11.0]}, 128)
batch 878: ({'logprob': [63.40519332885742, 17.0]}, 128)
batch 879: ({'logprob': [76.51545715332031, 21.0]}, 128)
batch 880: ({'logprob': [50.956321716308594, 13.0]}, 128)
batch 881: ({'logprob': [26.72191047668457, 5.0]}, 128)
batch 882: ({'logprob': [55.72450637817383, 14.0]}, 128)
batch 883: ({'logprob': [63.4038200378418, 17.0]}, 128)
batch 884: ({'logprob': [51.620140075683594, 13.0]}, 128)
batch 885: ({'logprob': [52.9434700012207, 13.0]}, 128)
batch 886: ({'logprob': [64.06768035888672, 17.0]}, 128)

======================Test output======================
logprob:  0.420275, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979646e-03 [8.798390e-10] 
Layer 'conv1' biases: 1.679096e-09 [6.828901e-12] 
Layer 'conv2' weights[0]: 7.966564e-03 [8.432779e-10] 
Layer 'conv2' biases: 1.000000e+00 [4.218008e-11] 
Layer 'conv3' weights[0]: 7.964947e-03 [8.352692e-10] 
Layer 'conv3' biases: 4.310792e-08 [1.236323e-10] 
Layer 'conv4' weights[0]: 7.997426e-03 [8.746814e-10] 
Layer 'conv4' biases: 1.000000e+00 [1.208584e-09] 
Layer 'conv5' weights[0]: 7.996326e-03 [6.721693e-09] 
Layer 'conv5' biases: 9.999972e-01 [6.802457e-09] 
Layer 'fc6' weights[0]: 7.593202e-03 [1.571827e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.367694e-09] 
Layer 'fc7' weights[0]: 7.850613e-03 [7.369241e-08] 
Layer 'fc7' biases: 9.999923e-01 [5.488958e-08] 
Layer 'fc8' weights[0]: 5.301495e-04 [2.964901e-05] 
Layer 'fc8' biases: 2.687548e-04 [3.429228e-05] 
Train error last 870 batches: 0.539724
-------------------------------------------------------
Saved checkpoint to /data2/ad6813/my-nets/saves/ConvNet__2014-06-17_23.05.49
======================================================= (12.597 sec)
1.101... logprob:  0.299811, 0.062500 (1.451 sec)
1.102... logprob:  0.581409, 0.156250 (1.396 sec)
1.103... logprob:  0.540859, 0.156250 (1.405 sec)
1.104... logprob:  0.420300, 0.101562 (1.407 sec)
1.105... logprob:  0.604946, 0.179688 (1.398 sec)
1.106... logprob:  0.365246, 0.085938 (1.400 sec)
1.107... logprob:  0.330524, 0.078125 (1.447 sec)
1.108... logprob:  0.684656, 0.171875 (1.402 sec)
1.109... logprob:  0.331158, 0.078125 (1.404 sec)
1.110... logprob:  0.591462, 0.164062 (1.395 sec)
1.111... logprob:  0.427664, 0.101562 (1.398 sec)
1.112... logprob:  0.423755, 0.093750 (1.399 sec)
1.113... logprob:  0.357863, 0.085938 (1.403 sec)
1.114... logprob:  0.467455, 0.117188 (1.469 sec)
1.115... logprob:  0.589306, 0.140625 (1.448 sec)
1.116... logprob:  0.406555, 0.101562 (1.404 sec)
1.117... logprob:  0.446353, 0.117188 (1.450 sec)
1.118... logprob:  0.452195, 0.101562 (1.387 sec)
1.119... logprob:  0.370602, 0.085938 (1.404 sec)
1.120... logprob:  0.554613, 0.156250 (1.403 sec)
1.121... logprob:  0.425826, 0.109375 (1.399 sec)
1.122... logprob:  0.543581, 0.148438 (3.986 sec)
1.123... logprob:  0.462743, 0.125000 (1.391 sec)
1.124... logprob:  0.459993, 0.125000 (1.403 sec)
1.125... logprob:  0.507630, 0.140625 (1.406 sec)
1.126... logprob:  0.497228, 0.125000 (1.390 sec)
1.127... logprob:  0.494998, 0.125000 (1.401 sec)
1.128... logprob:  0.426420, 0.109375 (1.417 sec)
1.129... logprob:  0.591647, 0.164062 (1.423 sec)
1.130... logprob:  0.407040, 0.093750 (1.414 sec)
1.131... logprob:  0.486542, 0.132812 (1.413 sec)
1.132... logprob:  0.516556, 0.140625 (1.433 sec)
1.133... logprob:  0.448153, 0.117188 (1.394 sec)
1.134... logprob:  0.399236, 0.101562 (1.397 sec)
1.135... logprob:  0.467642, 0.125000 (1.406 sec)
1.136... logprob:  0.584878, 0.164062 (1.397 sec)
1.137... logprob:  0.492059, 0.125000 (1.401 sec)
1.138... logprob:  0.358124, 0.070312 (1.444 sec)
1.139... logprob:  0.385236, 0.101562 (1.399 sec)
1.140... logprob:  0.632974, 0.164062 (1.417 sec)
1.141... logprob:  0.490857, 0.125000 (1.436 sec)
1.142... logprob:  0.465812, 0.125000 (1.395 sec)
1.143... logprob:  0.348620, 0.062500 (1.422 sec)
1.144... logprob:  0.468488, 0.125000 (1.417 sec)
1.145... logprob:  0.330691, 0.078125 (1.415 sec)
1.146... logprob:  0.511147, 0.132812 (1.408 sec)
1.147... logprob:  0.245805, 0.054688 (1.433 sec)
1.148... logprob:  0.470575, 0.125000 (1.389 sec)
1.149... logprob:  0.466810, 0.117188 (1.394 sec)
1.150... logprob:  0.371085, 0.085938 (1.400 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.180973052978516, 10.0]}, 128)
batch 872: ({'logprob': [67.98101806640625, 19.0]}, 128)
batch 873: ({'logprob': [45.892845153808594, 9.0]}, 128)
batch 874: ({'logprob': [48.01866912841797, 11.0]}, 128)
batch 875: ({'logprob': [53.96440887451172, 13.0]}, 128)
batch 876: ({'logprob': [65.96329498291016, 18.0]}, 128)
batch 877: ({'logprob': [49.92947006225586, 11.0]}, 128)
batch 878: ({'logprob': [65.8577880859375, 17.0]}, 128)
batch 879: ({'logprob': [79.66022491455078, 21.0]}, 128)
batch 880: ({'logprob': [53.965213775634766, 13.0]}, 128)
batch 881: ({'logprob': [32.09130096435547, 5.0]}, 128)
batch 882: ({'logprob': [61.71502685546875, 14.0]}, 128)
batch 883: ({'logprob': [65.85658264160156, 17.0]}, 128)
batch 884: ({'logprob': [55.876914978027344, 13.0]}, 128)
batch 885: ({'logprob': [59.696773529052734, 13.0]}, 128)
batch 886: ({'logprob': [67.76853942871094, 17.0]}, 128)

======================Test output======================
logprob:  0.447470, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979605e-03 [8.508857e-10] 
Layer 'conv1' biases: 1.851087e-09 [7.671625e-12] 
Layer 'conv2' weights[0]: 7.966528e-03 [8.441320e-10] 
Layer 'conv2' biases: 1.000000e+00 [5.111571e-11] 
Layer 'conv3' weights[0]: 7.964902e-03 [8.526191e-10] 
Layer 'conv3' biases: 4.718412e-08 [1.486438e-10] 
Layer 'conv4' weights[0]: 7.997385e-03 [9.017286e-10] 
Layer 'conv4' biases: 1.000000e+00 [1.583431e-09] 
Layer 'conv5' weights[0]: 7.996299e-03 [9.141637e-09] 
Layer 'conv5' biases: 9.999968e-01 [9.534753e-09] 
Layer 'fc6' weights[0]: 7.593163e-03 [2.067258e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.911626e-09] 
Layer 'fc7' weights[0]: 7.848716e-03 [8.074217e-08] 
Layer 'fc7' biases: 9.999901e-01 [6.338202e-08] 
Layer 'fc8' weights[0]: 5.419921e-04 [1.420897e-05] 
Layer 'fc8' biases: 2.761763e-04 [1.693742e-05] 
Train error last 870 batches: 0.513183
-------------------------------------------------------
Not saving because 0.447470 > 0.420275 (1.100: -1.77%)
======================================================= (12.088 sec)
1.151... logprob:  0.360232, 0.085938 (1.406 sec)
1.152... logprob:  0.816312, 0.234375 (1.396 sec)
1.153... logprob:  0.412306, 0.093750 (1.446 sec)
1.154... logprob:  0.513344, 0.148438 (1.400 sec)
1.155... logprob:  0.454212, 0.117188 (1.407 sec)
1.156... logprob:  0.312843, 0.062500 (1.443 sec)
1.157... logprob:  0.255035, 0.054688 (1.392 sec)
1.158... logprob:  0.543636, 0.125000 (1.407 sec)
1.159... logprob:  0.585029, 0.132812 (1.393 sec)
1.160... logprob:  0.476661, 0.117188 (1.392 sec)
1.161... logprob:  0.356006, 0.078125 (1.402 sec)
1.162... logprob:  0.597534, 0.179688 (1.405 sec)
1.163... logprob:  0.504889, 0.125000 (1.430 sec)
1.164... logprob:  0.471822, 0.125000 (1.416 sec)
1.165... logprob:  0.566054, 0.156250 (1.423 sec)
1.166... logprob:  0.486221, 0.125000 (1.448 sec)
1.167... logprob:  0.349817, 0.085938 (1.426 sec)
1.168... logprob:  0.354441, 0.085938 (1.424 sec)
1.169... logprob:  0.411175, 0.101562 (1.465 sec)
1.170... logprob:  0.462524, 0.125000 (1.402 sec)
1.171... logprob:  0.534322, 0.156250 (1.425 sec)
1.172... logprob:  0.457045, 0.109375 (1.415 sec)
1.173... logprob:  0.443887, 0.117188 (1.422 sec)
1.174... logprob:  0.592039, 0.171875 (1.406 sec)
1.175... logprob:  0.508808, 0.140625 (1.466 sec)
1.176... logprob:  0.504815, 0.132812 (1.419 sec)
1.177... logprob:  0.291260, 0.054688 (1.427 sec)
1.178... logprob:  0.377988, 0.093750 (1.459 sec)
1.179... logprob:  0.424031, 0.101562 (1.415 sec)
1.180... logprob:  0.518122, 0.125000 (1.424 sec)
1.181... logprob:  0.584023, 0.156250 (1.416 sec)
1.182... logprob:  0.381962, 0.093750 (1.419 sec)
1.183... logprob:  0.485726, 0.109375 (1.421 sec)
1.184... logprob:  0.491907, 0.132812 (1.416 sec)
1.185... logprob:  0.280482, 0.062500 (1.396 sec)
1.186... logprob:  0.392656, 0.093750 (1.406 sec)
1.187... logprob:  0.636871, 0.148438 (1.398 sec)
1.188... logprob:  0.505416, 0.125000 (1.426 sec)
1.189... logprob:  0.441770, 0.117188 (1.387 sec)
1.190... logprob:  0.435558, 0.093750 (1.435 sec)
1.191... logprob:  0.500472, 0.132812 (1.413 sec)
1.192... logprob:  0.512994, 0.148438 (1.414 sec)
1.193... logprob:  0.307408, 0.070312 (1.425 sec)
1.194... logprob:  0.429009, 0.109375 (1.416 sec)
1.195... logprob:  0.269622, 0.062500 (1.401 sec)
1.196... logprob:  0.425762, 0.109375 (1.391 sec)
1.197... logprob:  0.494955, 0.132812 (1.405 sec)
1.198... logprob:  0.393947, 0.085938 (1.401 sec)
1.199... logprob:  0.455657, 0.117188 (1.393 sec)
1.200... logprob:  0.450825, 0.117188 (1.439 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.777252197265625, 10.0]}, 128)
batch 872: ({'logprob': [67.35987854003906, 19.0]}, 128)
batch 873: ({'logprob': [40.24964141845703, 9.0]}, 128)
batch 874: ({'logprob': [44.82658004760742, 11.0]}, 128)
batch 875: ({'logprob': [50.81245803833008, 13.0]}, 128)
batch 876: ({'logprob': [64.71947479248047, 18.0]}, 128)
batch 877: ({'logprob': [45.53168869018555, 11.0]}, 128)
batch 878: ({'logprob': [62.7855339050293, 17.0]}, 128)
batch 879: ({'logprob': [75.46171569824219, 21.0]}, 128)
batch 880: ({'logprob': [50.81305694580078, 13.0]}, 128)
batch 881: ({'logprob': [27.573894500732422, 5.0]}, 128)
batch 882: ({'logprob': [55.568546295166016, 14.0]}, 128)
batch 883: ({'logprob': [62.78390884399414, 17.0]}, 128)
batch 884: ({'logprob': [51.51917266845703, 13.0]}, 128)
batch 885: ({'logprob': [52.9278678894043, 13.0]}, 128)
batch 886: ({'logprob': [63.4904670715332, 17.0]}, 128)

======================Test output======================
logprob:  0.418555, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979562e-03 [9.344219e-10] 
Layer 'conv1' biases: 2.041342e-09 [9.747940e-12] 
Layer 'conv2' weights[0]: 7.966487e-03 [8.650688e-10] 
Layer 'conv2' biases: 1.000000e+00 [5.293111e-11] 
Layer 'conv3' weights[0]: 7.964860e-03 [8.718228e-10] 
Layer 'conv3' biases: 5.154800e-08 [1.887686e-10] 
Layer 'conv4' weights[0]: 7.997349e-03 [9.175811e-10] 
Layer 'conv4' biases: 1.000000e+00 [1.778920e-09] 
Layer 'conv5' weights[0]: 7.996259e-03 [9.975352e-09] 
Layer 'conv5' biases: 9.999966e-01 [1.033301e-08] 
Layer 'fc6' weights[0]: 7.593124e-03 [2.208375e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.059354e-09] 
Layer 'fc7' weights[0]: 7.846853e-03 [9.305820e-08] 
Layer 'fc7' biases: 9.999875e-01 [7.597939e-08] 
Layer 'fc8' weights[0]: 5.278504e-04 [4.666912e-05] 
Layer 'fc8' biases: 2.878107e-04 [5.723435e-05] 
Train error last 870 batches: 0.498985
-------------------------------------------------------
Saved checkpoint to /data2/ad6813/my-nets/saves/ConvNet__2014-06-17_23.05.49
======================================================= (12.536 sec)
1.201... logprob:  0.438235, 0.117188 (1.418 sec)
1.202... logprob:  0.544116, 0.148438 (1.415 sec)
1.203... logprob:  0.425106, 0.109375 (1.450 sec)
1.204... logprob:  0.520672, 0.140625 (2.669 sec)
1.205... logprob:  0.373229, 0.078125 (1.409 sec)
1.206... logprob:  0.391004, 0.093750 (1.405 sec)
1.207... logprob:  0.381217, 0.093750 (3.019 sec)
1.208... logprob:  0.530326, 0.140625 (1.400 sec)
1.209... logprob:  0.338999, 0.078125 (1.430 sec)
1.210... logprob:  0.623984, 0.171875 (1.424 sec)
1.211... logprob:  0.562396, 0.132812 (1.414 sec)
1.212... logprob:  0.565575, 0.148438 (1.416 sec)
1.213... logprob:  0.533896, 0.140625 (1.457 sec)
1.214... logprob:  0.463840, 0.125000 (1.428 sec)
1.215... logprob:  0.424501, 0.101562 (1.418 sec)
1.216... logprob:  0.510480, 0.140625 (1.470 sec)
1.217... logprob:  0.346211, 0.070312 (1.403 sec)
1.218... logprob:  0.502951, 0.125000 (1.424 sec)
1.219... logprob:  0.554348, 0.140625 (1.420 sec)
1.220... logprob:  0.428978, 0.109375 (1.426 sec)
1.221... logprob:  0.400074, 0.101562 (1.405 sec)
1.222... logprob:  0.546224, 0.164062 (1.459 sec)
1.223... logprob:  0.616262, 0.164062 (1.430 sec)
1.224... logprob:  0.458943, 0.101562 (1.436 sec)
1.225... logprob:  0.384601, 0.101562 (1.450 sec)
1.226... logprob:  0.450122, 0.109375 (1.421 sec)
1.227... logprob:  0.510890, 0.125000 (1.420 sec)
1.228... logprob:  0.435812, 0.109375 (1.416 sec)
1.229... logprob:  0.484690, 0.132812 (1.419 sec)
1.230... logprob:  0.487920, 0.125000 (1.424 sec)
1.231... logprob:  0.493098, 0.125000 (1.406 sec)
1.232... logprob:  0.494107, 0.140625 (1.460 sec)
1.233... logprob:  0.453156, 0.132812 (1.426 sec)
1.234... logprob:  0.597619, 0.164062 (1.423 sec)
1.235... logprob:  0.523074, 0.132812 (1.467 sec)
1.236... logprob:  0.488026, 0.109375 (1.400 sec)
1.237... logprob:  0.353594, 0.078125 (1.424 sec)
1.238... logprob:  0.407898, 0.093750 (1.413 sec)
1.239... logprob:  0.527940, 0.132812 (1.422 sec)
1.240... logprob:  0.513259, 0.132812 (1.404 sec)
1.241... logprob:  0.482678, 0.132812 (1.463 sec)
1.242... logprob:  0.416625, 0.078125 (1.427 sec)
1.243... logprob:  0.407362, 0.093750 (1.434 sec)
1.244... logprob:  0.311369, 0.070312 (1.444 sec)
1.245... logprob:  0.552180, 0.132812 (1.428 sec)
1.246... logprob:  0.475836, 0.109375 (1.415 sec)
1.247... logprob:  0.370458, 0.085938 (1.415 sec)
1.248... logprob:  0.304563, 0.070312 (1.421 sec)
1.249... logprob:  0.543806, 0.156250 (1.420 sec)
1.250... logprob:  0.595332, 0.164062 (1.409 sec)
=========================
Testing all batches
batch 871: ({'logprob': [53.2812385559082, 10.0]}, 128)
batch 872: ({'logprob': [69.58546447753906, 19.0]}, 128)
batch 873: ({'logprob': [53.919471740722656, 9.0]}, 128)
batch 874: ({'logprob': [56.19892120361328, 11.0]}, 128)
batch 875: ({'logprob': [59.90125274658203, 13.0]}, 128)
batch 876: ({'logprob': [68.09039306640625, 18.0]}, 128)
batch 877: ({'logprob': [56.910953521728516, 11.0]}, 128)
batch 878: ({'logprob': [67.30809020996094, 17.0]}, 128)
batch 879: ({'logprob': [75.42379760742188, 21.0]}, 128)
batch 880: ({'logprob': [59.90194320678711, 13.0]}, 128)
batch 881: ({'logprob': [45.80327224731445, 5.0]}, 128)
batch 882: ({'logprob': [63.53319549560547, 14.0]}, 128)
batch 883: ({'logprob': [67.30659484863281, 17.0]}, 128)
batch 884: ({'logprob': [60.614131927490234, 13.0]}, 128)
batch 885: ({'logprob': [62.037593841552734, 13.0]}, 128)
batch 886: ({'logprob': [68.0193099975586, 17.0]}, 128)

======================Test output======================
logprob:  0.482342, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979526e-03 [8.707131e-10] 
Layer 'conv1' biases: 2.264873e-09 [8.581588e-12] 
Layer 'conv2' weights[0]: 7.966450e-03 [8.675001e-10] 
Layer 'conv2' biases: 1.000000e+00 [5.152850e-11] 
Layer 'conv3' weights[0]: 7.964815e-03 [8.597895e-10] 
Layer 'conv3' biases: 5.710929e-08 [1.564274e-10] 
Layer 'conv4' weights[0]: 7.997311e-03 [9.181909e-10] 
Layer 'conv4' biases: 1.000000e+00 [1.722450e-09] 
Layer 'conv5' weights[0]: 7.996203e-03 [1.027439e-08] 
Layer 'conv5' biases: 9.999964e-01 [1.070004e-08] 
Layer 'fc6' weights[0]: 7.593081e-03 [2.307215e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.166115e-09] 
Layer 'fc7' weights[0]: 7.844957e-03 [1.560567e-07] 
Layer 'fc7' biases: 9.999839e-01 [1.431499e-07] 
Layer 'fc8' weights[0]: 4.816190e-04 [3.625226e-05] 
Layer 'fc8' biases: 1.746482e-04 [4.610371e-05] 
Train error last 870 batches: 0.493378
-------------------------------------------------------
Not saving because 0.482342 > 0.418555 (1.200: -0.41%)
======================================================= (12.051 sec)
1.251... logprob:  0.444616, 0.085938 (1.464 sec)
1.252... logprob:  0.366022, 0.085938 (1.435 sec)
1.253... logprob:  0.380918, 0.093750 (1.459 sec)
1.254... logprob:  0.509528, 0.117188 (1.511 sec)
1.255... logprob:  0.399848, 0.085938 (1.399 sec)
1.256... logprob:  0.403749, 0.093750 (1.429 sec)
1.257... logprob:  0.339992, 0.078125 (1.415 sec)
1.258... logprob:  0.466527, 0.109375 (1.421 sec)
1.259... logprob:  0.456217, 0.117188 (1.402 sec)
1.260... logprob:  0.349736, 0.070312 (1.460 sec)
1.261... logprob:  0.386014, 0.101562 (1.430 sec)
1.262... logprob:  0.488381, 0.148438 (1.429 sec)
1.263... logprob:  0.505217, 0.109375 (1.453 sec)
1.264... logprob:  0.412515, 0.093750 (1.420 sec)
1.265... logprob:  0.468935, 0.117188 (1.417 sec)
1.266... logprob:  0.466648, 0.117188 (1.420 sec)
1.267... logprob:  0.469480, 0.109375 (1.418 sec)
1.268... logprob:  0.463633, 0.125000 (1.425 sec)
1.269... logprob:  0.566929, 0.164062 (1.407 sec)
1.270... logprob:  0.537710, 0.156250 (1.460 sec)
1.271... logprob:  0.487844, 0.117188 (1.429 sec)
1.272... logprob:  0.407838, 0.093750 (1.420 sec)
1.273... logprob:  0.534374, 0.140625 (1.467 sec)
1.274... logprob:  0.613201, 0.156250 (1.404 sec)
1.275... logprob:  0.514606, 0.132812 (1.425 sec)
1.276... logprob:  0.378971, 0.093750 (1.418 sec)
1.277... logprob:  0.425680, 0.109375 (1.423 sec)
1.278... logprob:  0.339579, 0.070312 (1.420 sec)
1.279... logprob:  0.317449, 0.070312 (1.467 sec)
1.280... logprob:  0.174370, 0.031250 (1.405 sec)
1.281... logprob:  0.465003, 0.109375 (1.423 sec)
1.282... logprob:  0.467224, 0.109375 (1.423 sec)
1.283... logprob:  0.431578, 0.101562 (1.419 sec)
1.284... logprob:  0.408428, 0.101562 (1.414 sec)
1.285... logprob:  0.498388, 0.117188 (1.437 sec)
1.286... logprob:  0.615636, 0.140625 (1.443 sec)
1.287... logprob:  0.373126, 0.085938 (1.433 sec)
1.288... logprob:  0.335052, 0.078125 (1.433 sec)
1.289... logprob:  0.467747, 0.117188 (1.448 sec)
1.290... logprob:  0.556125, 0.132812 (1.406 sec)
1.291... logprob:  0.504205, 0.117188 (1.415 sec)
1.292... logprob:  0.571961, 0.156250 (1.423 sec)
1.293... logprob:  0.497717, 0.117188 (1.423 sec)
1.294... logprob:  0.395326, 0.085938 (1.401 sec)
1.295... logprob:  0.350625, 0.078125 (1.459 sec)
1.296... logprob:  0.355047, 0.085938 (1.421 sec)
1.297... logprob:  0.417400, 0.101562 (1.424 sec)
1.298... logprob:  0.493073, 0.125000 (1.468 sec)
1.299... logprob:  0.382566, 0.078125 (1.404 sec)
1.300... logprob:  0.490256, 0.101562 (1.423 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.66097640991211, 10.0]}, 128)
batch 872: ({'logprob': [72.63255310058594, 19.0]}, 128)
batch 873: ({'logprob': [47.640235900878906, 9.0]}, 128)
batch 874: ({'logprob': [49.35667419433594, 11.0]}, 128)
batch 875: ({'logprob': [56.54304122924805, 13.0]}, 128)
batch 876: ({'logprob': [70.4070053100586, 18.0]}, 128)
batch 877: ({'logprob': [52.0925407409668, 11.0]}, 128)
batch 878: ({'logprob': [70.91837310791016, 17.0]}, 128)
batch 879: ({'logprob': [88.02708435058594, 21.0]}, 128)
batch 880: ({'logprob': [56.544376373291016, 13.0]}, 128)
batch 881: ({'logprob': [30.53173828125, 5.0]}, 128)
batch 882: ({'logprob': [66.97679901123047, 14.0]}, 128)
batch 883: ({'logprob': [70.91687774658203, 17.0]}, 128)
batch 884: ({'logprob': [59.280574798583984, 13.0]}, 128)
batch 885: ({'logprob': [64.7501220703125, 13.0]}, 128)
batch 886: ({'logprob': [73.65414428710938, 17.0]}, 128)

======================Test output======================
logprob:  0.474577, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979491e-03 [1.004718e-09] 
Layer 'conv1' biases: 2.492449e-09 [2.062941e-11] 
Layer 'conv2' weights[0]: 7.966413e-03 [9.354543e-10] 
Layer 'conv2' biases: 1.000000e+00 [1.098509e-10] 
Layer 'conv3' weights[0]: 7.964776e-03 [1.010852e-09] 
Layer 'conv3' biases: 6.218569e-08 [3.817251e-10] 
Layer 'conv4' weights[0]: 7.997272e-03 [1.124852e-09] 
Layer 'conv4' biases: 1.000000e+00 [3.917765e-09] 
Layer 'conv5' weights[0]: 7.996158e-03 [2.334923e-08] 
Layer 'conv5' biases: 9.999962e-01 [2.501754e-08] 
Layer 'fc6' weights[0]: 7.593038e-03 [4.731811e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.680849e-09] 
Layer 'fc7' weights[0]: 7.843132e-03 [1.916798e-07] 
Layer 'fc7' biases: 9.999787e-01 [1.793806e-07] 
Layer 'fc8' weights[0]: 6.087216e-04 [2.828343e-05] 
Layer 'fc8' biases: 4.605104e-04 [3.771483e-05] 
Train error last 870 batches: 0.484992
-------------------------------------------------------
Not saving because 0.474577 > 0.418555 (1.200: -0.41%)
======================================================= (12.026 sec)
1.301... logprob:  0.441750, 0.101562 (1.426 sec)
1.302... logprob:  0.598180, 0.179688 (1.420 sec)
1.303... logprob:  0.502007, 0.125000 (1.405 sec)
1.304... logprob:  0.485675, 0.125000 (1.446 sec)
1.305... logprob:  0.455712, 0.125000 (1.438 sec)
1.306... logprob:  0.442492, 0.117188 (1.435 sec)
1.307... logprob:  0.430748, 0.109375 (1.442 sec)
1.308... logprob:  0.403445, 0.093750 (1.460 sec)
1.309... logprob:  0.519488, 0.125000 (1.414 sec)
1.310... logprob:  0.473931, 0.125000 (1.424 sec)
1.311... logprob:  0.521312, 0.140625 (1.432 sec)
1.312... logprob:  0.483251, 0.132812 (1.437 sec)
1.313... logprob:  0.468987, 0.125000 (1.424 sec)
1.314... logprob:  0.492596, 0.117188 (1.471 sec)
1.315... logprob:  0.322890, 0.070312 (1.437 sec)
1.316... logprob:  0.496599, 0.125000 (1.424 sec)
1.317... logprob:  0.363335, 0.085938 (1.479 sec)
1.318... logprob:  0.515942, 0.125000 (1.417 sec)
1.319... logprob:  0.454131, 0.117188 (1.424 sec)
1.320... logprob:  0.412030, 0.109375 (1.426 sec)
1.321... logprob:  0.371996, 0.085938 (1.428 sec)
1.322... logprob:  0.413144, 0.101562 (1.414 sec)
1.323... logprob:  0.423707, 0.109375 (1.478 sec)
1.324... logprob:  0.501497, 0.140625 (1.424 sec)
1.325... logprob:  0.350334, 0.085938 (1.440 sec)
1.326... logprob:  0.572929, 0.148438 (1.465 sec)
1.327... logprob:  0.567804, 0.164062 (1.424 sec)
1.328... logprob:  0.554995, 0.156250 (1.434 sec)
1.329... logprob:  0.466485, 0.101562 (1.421 sec)
1.330... logprob:  0.432533, 0.101562 (1.416 sec)
1.331... logprob:  0.355687, 0.085938 (1.424 sec)
1.332... logprob:  0.522437, 0.132812 (1.452 sec)
1.333... logprob:  0.366847, 0.085938 (1.440 sec)
1.334... logprob:  0.688414, 0.171875 (1.445 sec)
1.335... logprob:  0.351427, 0.085938 (1.443 sec)
1.336... logprob:  0.438478, 0.125000 (1.459 sec)
1.337... logprob:  0.609991, 0.164062 (1.424 sec)
1.338... logprob:  0.488805, 0.125000 (1.433 sec)
1.339... logprob:  0.505804, 0.132812 (1.429 sec)
1.340... logprob:  0.447247, 0.117188 (1.426 sec)
1.341... logprob:  0.568111, 0.148438 (1.418 sec)
1.342... logprob:  0.430160, 0.109375 (1.465 sec)
1.343... logprob:  0.422986, 0.109375 (1.434 sec)
1.344... logprob:  0.523235, 0.125000 (1.482 sec)
1.345... logprob:  0.501701, 0.132812 (1.438 sec)
1.346... logprob:  0.459066, 0.117188 (1.440 sec)
1.347... logprob:  0.365809, 0.085938 (1.484 sec)
1.348... logprob:  0.396476, 0.101562 (1.437 sec)
1.349... logprob:  0.518916, 0.140625 (1.434 sec)
1.350... logprob:  0.365612, 0.085938 (1.437 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.25495147705078, 10.0]}, 128)
batch 872: ({'logprob': [68.85942840576172, 19.0]}, 128)
batch 873: ({'logprob': [42.391666412353516, 9.0]}, 128)
batch 874: ({'logprob': [45.83348083496094, 11.0]}, 128)
batch 875: ({'logprob': [52.36135482788086, 13.0]}, 128)
batch 876: ({'logprob': [66.3673095703125, 18.0]}, 128)
batch 877: ({'logprob': [47.3771858215332, 11.0]}, 128)
batch 878: ({'logprob': [65.41951751708984, 17.0]}, 128)
batch 879: ({'logprob': [80.0186538696289, 21.0]}, 128)
batch 880: ({'logprob': [52.36259841918945, 13.0]}, 128)
batch 881: ({'logprob': [27.792064666748047, 5.0]}, 128)
batch 882: ({'logprob': [59.48543930053711, 14.0]}, 128)
batch 883: ({'logprob': [65.41777038574219, 17.0]}, 128)
batch 884: ({'logprob': [53.9065055847168, 13.0]}, 128)
batch 885: ({'logprob': [56.9923095703125, 13.0]}, 128)
batch 886: ({'logprob': [66.96299743652344, 17.0]}, 128)

======================Test output======================
logprob:  0.435451, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979444e-03 [8.968098e-10] 
Layer 'conv1' biases: 2.696162e-09 [7.165614e-12] 
Layer 'conv2' weights[0]: 7.966370e-03 [8.373758e-10] 
Layer 'conv2' biases: 1.000000e+00 [3.913271e-11] 
Layer 'conv3' weights[0]: 7.964733e-03 [8.358933e-10] 
Layer 'conv3' biases: 6.616514e-08 [1.402334e-10] 
Layer 'conv4' weights[0]: 7.997235e-03 [8.588387e-10] 
Layer 'conv4' biases: 1.000000e+00 [1.277255e-09] 
Layer 'conv5' weights[0]: 7.996102e-03 [7.364033e-09] 
Layer 'conv5' biases: 9.999961e-01 [7.748081e-09] 
Layer 'fc6' weights[0]: 7.592986e-03 [1.761075e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.581019e-09] 
Layer 'fc7' weights[0]: 7.841322e-03 [1.021615e-07] 
Layer 'fc7' biases: 9.999734e-01 [8.626269e-08] 
Layer 'fc8' weights[0]: 5.669293e-04 [1.457303e-05] 
Layer 'fc8' biases: 4.030901e-04 [2.037892e-05] 
Train error last 870 batches: 0.482185
-------------------------------------------------------
Not saving because 0.435451 > 0.418555 (1.200: -0.41%)
======================================================= (12.098 sec)
1.351... logprob:  0.542599, 0.140625 (1.434 sec)
1.352... logprob:  0.355536, 0.093750 (1.437 sec)
1.353... logprob:  0.499228, 0.148438 (1.484 sec)
1.354... logprob:  0.663125, 0.203125 (1.433 sec)
1.355... logprob:  0.424190, 0.085938 (1.451 sec)
1.356... logprob:  0.483023, 0.132812 (1.479 sec)
1.357... logprob:  0.347110, 0.085938 (1.428 sec)
1.358... logprob:  0.304072, 0.070312 (1.446 sec)
1.359... logprob:  0.655172, 0.164062 (1.432 sec)
1.360... logprob:  0.468080, 0.117188 (1.429 sec)
1.361... logprob:  0.396854, 0.101562 (1.435 sec)
1.362... logprob:  0.474736, 0.117188 (1.481 sec)
1.363... logprob:  0.489263, 0.132812 (1.441 sec)
1.364... logprob:  0.477070, 0.125000 (1.456 sec)
1.365... logprob:  0.434052, 0.109375 (1.464 sec)
1.366... logprob:  0.409476, 0.109375 (1.451 sec)
1.367... logprob:  0.311834, 0.078125 (1.437 sec)
1.368... logprob:  0.664842, 0.171875 (1.433 sec)
1.369... logprob:  0.392433, 0.093750 (1.423 sec)
1.370... logprob:  0.391385, 0.093750 (1.437 sec)
1.371... logprob:  0.408369, 0.101562 (1.458 sec)
1.372... logprob:  0.529542, 0.156250 (1.459 sec)
1.373... logprob:  0.467461, 0.125000 (1.456 sec)
1.374... logprob:  0.522587, 0.148438 (1.450 sec)
1.375... logprob:  0.415035, 0.101562 (1.466 sec)
1.376... logprob:  0.383588, 0.093750 (1.442 sec)
1.377... logprob:  0.283241, 0.062500 (1.423 sec)
1.378... logprob:  0.497318, 0.125000 (1.438 sec)
1.379... logprob:  0.450288, 0.109375 (1.435 sec)
1.380... logprob:  0.683323, 0.179688 (1.442 sec)
1.381... logprob:  0.466022, 0.125000 (1.472 sec)
1.382... logprob:  0.542417, 0.148438 (1.456 sec)
1.383... logprob:  0.464221, 0.085938 (1.436 sec)
1.384... logprob:  0.520816, 0.148438 (1.487 sec)
1.385... logprob:  0.529473, 0.148438 (1.434 sec)
1.386... logprob:  0.623364, 0.171875 (1.426 sec)
1.387... logprob:  0.452036, 0.117188 (1.441 sec)
1.388... logprob:  0.528992, 0.148438 (1.432 sec)
1.389... logprob:  0.428987, 0.109375 (1.439 sec)
1.390... logprob:  0.431460, 0.109375 (1.478 sec)
1.391... logprob:  0.319029, 0.070312 (1.447 sec)
1.392... logprob:  0.437560, 0.117188 (1.433 sec)
1.393... logprob:  0.350571, 0.093750 (1.490 sec)
1.394... logprob:  0.348040, 0.078125 (1.436 sec)
1.395... logprob:  0.330445, 0.078125 (1.432 sec)
1.396... logprob:  0.251012, 0.046875 (1.437 sec)
1.397... logprob:  0.543112, 0.132812 (1.431 sec)
1.398... logprob:  0.511977, 0.125000 (1.438 sec)
1.399... logprob:  0.421055, 0.117188 (1.486 sec)
1.400... logprob:  0.520793, 0.148438 (1.436 sec)
=========================
Testing all batches
batch 871: ({'logprob': [48.95374298095703, 10.0]}, 128)
batch 872: ({'logprob': [67.9359130859375, 19.0]}, 128)
batch 873: ({'logprob': [51.257049560546875, 9.0]}, 128)
batch 874: ({'logprob': [53.055274963378906, 11.0]}, 128)
batch 875: ({'logprob': [57.41581726074219, 13.0]}, 128)
batch 876: ({'logprob': [66.39664459228516, 18.0]}, 128)
batch 877: ({'logprob': [54.33726501464844, 11.0]}, 128)
batch 878: ({'logprob': [66.13946533203125, 17.0]}, 128)
batch 879: ({'logprob': [76.14116668701172, 21.0]}, 128)
batch 880: ({'logprob': [57.4169807434082, 13.0]}, 128)
batch 881: ({'logprob': [41.25433349609375, 5.0]}, 128)
batch 882: ({'logprob': [62.801063537597656, 14.0]}, 128)
batch 883: ({'logprob': [66.13773345947266, 17.0]}, 128)
batch 884: ({'logprob': [58.69803237915039, 13.0]}, 128)
batch 885: ({'logprob': [61.260581970214844, 13.0]}, 128)
batch 886: ({'logprob': [67.420166015625, 17.0]}, 128)

======================Test output======================
logprob:  0.467100, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979408e-03 [8.641905e-10] 
Layer 'conv1' biases: 2.859200e-09 [7.266958e-12] 
Layer 'conv2' weights[0]: 7.966328e-03 [8.407337e-10] 
Layer 'conv2' biases: 1.000000e+00 [4.072809e-11] 
Layer 'conv3' weights[0]: 7.964693e-03 [8.416632e-10] 
Layer 'conv3' biases: 6.943551e-08 [1.349284e-10] 
Layer 'conv4' weights[0]: 7.997190e-03 [8.785048e-10] 
Layer 'conv4' biases: 1.000000e+00 [1.427384e-09] 
Layer 'conv5' weights[0]: 7.996062e-03 [8.393819e-09] 
Layer 'conv5' biases: 9.999961e-01 [8.772645e-09] 
Layer 'fc6' weights[0]: 7.592941e-03 [2.054252e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.894490e-09] 
Layer 'fc7' weights[0]: 7.839493e-03 [1.604429e-07] 
Layer 'fc7' biases: 9.999694e-01 [1.476960e-07] 
Layer 'fc8' weights[0]: 5.050590e-04 [4.278927e-05] 
Layer 'fc8' biases: 2.682872e-04 [6.222387e-05] 
Train error last 870 batches: 0.479027
-------------------------------------------------------
Not saving because 0.467100 > 0.418555 (1.200: -0.41%)
======================================================= (12.062 sec)
1.401... logprob:  0.484668, 0.125000 (1.448 sec)
1.402... logprob:  0.485534, 0.125000 (1.485 sec)
1.403... logprob:  0.458416, 0.125000 (1.428 sec)
1.404... logprob:  0.466631, 0.125000 (1.431 sec)
1.405... logprob:  0.587659, 0.156250 (1.437 sec)
1.406... logprob:  0.358834, 0.085938 (1.428 sec)
1.407... logprob:  0.533700, 0.140625 (1.440 sec)
1.408... logprob:  0.340972, 0.078125 (1.478 sec)
1.409... logprob:  0.400274, 0.101562 (1.436 sec)
1.410... logprob:  0.588242, 0.171875 (1.450 sec)
1.411... logprob:  0.398505, 0.101562 (1.477 sec)
1.412... logprob:  0.546091, 0.156250 (1.432 sec)
1.413... logprob:  0.558073, 0.156250 (1.437 sec)
1.414... logprob:  0.476836, 0.125000 (1.432 sec)
1.415... logprob:  0.396695, 0.101562 (1.424 sec)
1.416... logprob:  0.421253, 0.109375 (1.441 sec)
1.417... logprob:  0.385246, 0.093750 (1.469 sec)
1.418... logprob:  0.380508, 0.093750 (1.452 sec)
1.419... logprob:  0.399071, 0.101562 (1.453 sec)
1.420... logprob:  0.366432, 0.085938 (1.457 sec)
1.421... logprob:  0.452276, 0.101562 (1.458 sec)
1.422... logprob:  0.558068, 0.148438 (1.445 sec)
1.423... logprob:  0.423767, 0.109375 (1.420 sec)
1.424... logprob:  0.351416, 0.078125 (1.430 sec)
1.425... logprob:  0.334092, 0.070312 (1.439 sec)
1.426... logprob:  0.455401, 0.117188 (1.443 sec)
1.427... logprob:  0.554723, 0.156250 (1.469 sec)
1.428... logprob:  0.601893, 0.171875 (1.451 sec)
1.429... logprob:  0.456753, 0.109375 (1.449 sec)
1.430... logprob:  0.329741, 0.070312 (1.474 sec)
1.431... logprob:  0.602227, 0.171875 (1.438 sec)
1.432... logprob:  0.412842, 0.093750 (1.429 sec)
1.433... logprob:  0.326718, 0.078125 (1.445 sec)
1.434... logprob:  0.545764, 0.148438 (1.438 sec)
1.435... logprob:  0.581220, 0.156250 (1.449 sec)
1.436... logprob:  0.388124, 0.093750 (1.474 sec)
1.437... logprob:  0.515446, 0.140625 (1.445 sec)
1.438... logprob:  0.543369, 0.156250 (1.432 sec)
1.439... logprob:  0.403142, 0.093750 (1.489 sec)
1.440... logprob:  0.440678, 0.117188 (1.431 sec)
1.441... logprob:  0.471528, 0.125000 (1.428 sec)
1.442... logprob:  0.364135, 0.093750 (1.440 sec)
1.443... logprob:  0.518700, 0.140625 (1.434 sec)
1.444... logprob:  0.353898, 0.093750 (1.437 sec)
1.445... logprob:  0.372151, 0.085938 (1.480 sec)
1.446... logprob:  0.409984, 0.101562 (1.441 sec)
1.447... logprob:  0.606132, 0.164062 (1.439 sec)
1.448... logprob:  0.342915, 0.078125 (1.486 sec)
1.449... logprob:  0.408654, 0.101562 (1.433 sec)
1.450... logprob:  0.244039, 0.046875 (1.437 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.558658599853516, 10.0]}, 128)
batch 872: ({'logprob': [69.30686950683594, 19.0]}, 128)
batch 873: ({'logprob': [39.08250427246094, 9.0]}, 128)
batch 874: ({'logprob': [44.91582107543945, 11.0]}, 128)
batch 875: ({'logprob': [51.10133743286133, 13.0]}, 128)
batch 876: ({'logprob': [66.30291748046875, 18.0]}, 128)
batch 877: ({'logprob': [45.09253692626953, 11.0]}, 128)
batch 878: ({'logprob': [63.47513198852539, 17.0]}, 128)
batch 879: ({'logprob': [76.0223617553711, 21.0]}, 128)
batch 880: ({'logprob': [51.10272216796875, 13.0]}, 128)
batch 881: ({'logprob': [26.533964157104492, 5.0]}, 128)
batch 882: ({'logprob': [54.63681411743164, 14.0]}, 128)
batch 883: ({'logprob': [63.47298049926758, 17.0]}, 128)
batch 884: ({'logprob': [51.279296875, 13.0]}, 128)
batch 885: ({'logprob': [51.631446838378906, 13.0]}, 128)
batch 886: ({'logprob': [63.651424407958984, 17.0]}, 128)

======================Test output======================
logprob:  0.419515, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979368e-03 [9.475076e-10] 
Layer 'conv1' biases: 2.935653e-09 [1.594055e-11] 
Layer 'conv2' weights[0]: 7.966297e-03 [9.290899e-10] 
Layer 'conv2' biases: 1.000000e+00 [8.725073e-11] 
Layer 'conv3' weights[0]: 7.964651e-03 [9.650611e-10] 
Layer 'conv3' biases: 7.107424e-08 [2.878233e-10] 
Layer 'conv4' weights[0]: 7.997150e-03 [1.027728e-09] 
Layer 'conv4' biases: 1.000000e+00 [2.697882e-09] 
Layer 'conv5' weights[0]: 7.996032e-03 [1.493123e-08] 
Layer 'conv5' biases: 9.999961e-01 [1.549443e-08] 
Layer 'fc6' weights[0]: 7.592902e-03 [3.033013e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.975291e-09] 
Layer 'fc7' weights[0]: 7.837722e-03 [6.714163e-08] 
Layer 'fc7' biases: 9.999652e-01 [4.680692e-08] 
Layer 'fc8' weights[0]: 5.496173e-04 [4.760322e-05] 
Layer 'fc8' biases: 4.308583e-04 [7.188254e-05] 
Train error last 870 batches: 0.475587
-------------------------------------------------------
Not saving because 0.419515 > 0.418555 (1.200: -0.41%)
======================================================= (12.076 sec)
1.451... logprob:  0.466910, 0.125000 (1.446 sec)
1.452... logprob:  0.451500, 0.117188 (1.437 sec)
1.453... logprob:  0.481472, 0.125000 (1.435 sec)
1.454... logprob:  0.491016, 0.132812 (1.484 sec)
1.455... logprob:  0.504467, 0.140625 (1.443 sec)
1.456... logprob:  0.474814, 0.125000 (1.447 sec)
1.457... logprob:  0.410390, 0.093750 (1.473 sec)
1.458... logprob:  0.363526, 0.085938 (1.437 sec)
1.459... logprob:  0.529683, 0.140625 (1.442 sec)
1.460... logprob:  0.257471, 0.054688 (1.434 sec)
1.461... logprob:  0.504094, 0.125000 (1.426 sec)
1.462... logprob:  0.514519, 0.125000 (1.438 sec)
1.463... logprob:  0.431267, 0.109375 (1.472 sec)
1.464... logprob:  0.485550, 0.132812 (1.451 sec)
1.465... logprob:  0.432997, 0.109375 (1.453 sec)
1.466... logprob:  0.372111, 0.070312 (1.460 sec)
1.467... logprob:  0.429483, 0.109375 (1.453 sec)
1.468... logprob:  0.397435, 0.101562 (1.446 sec)
1.469... logprob:  0.327613, 0.078125 (1.431 sec)
1.470... logprob:  0.420456, 0.101562 (1.428 sec)
1.471... logprob:  0.599810, 0.148438 (1.443 sec)
1.472... logprob:  0.423326, 0.109375 (1.450 sec)
1.473... logprob:  0.377631, 0.093750 (1.457 sec)
1.474... logprob:  0.472007, 0.125000 (1.452 sec)
1.475... logprob:  0.503456, 0.140625 (1.450 sec)
1.476... logprob:  0.519735, 0.140625 (1.473 sec)
1.477... logprob:  0.365841, 0.078125 (1.441 sec)
1.478... logprob:  0.464099, 0.125000 (1.421 sec)
1.479... logprob:  0.304462, 0.070312 (1.438 sec)
1.480... logprob:  0.471127, 0.117188 (1.439 sec)
1.481... logprob:  0.620400, 0.156250 (1.438 sec)
1.482... logprob:  0.457495, 0.117188 (1.474 sec)
1.483... logprob:  0.513618, 0.140625 (1.452 sec)
1.484... logprob:  0.492752, 0.132812 (1.434 sec)
1.485... logprob:  0.465138, 0.109375 (1.485 sec)
1.486... logprob:  0.401224, 0.085938 (1.438 sec)
1.487... logprob:  0.526423, 0.148438 (1.427 sec)
1.488... logprob:  0.434723, 0.109375 (1.441 sec)
1.489... logprob:  0.424748, 0.109375 (1.431 sec)
1.490... logprob:  0.468486, 0.117188 (1.436 sec)
1.491... logprob:  0.291768, 0.070312 (1.482 sec)
1.492... logprob:  0.478314, 0.125000 (1.445 sec)
1.493... logprob:  0.535264, 0.148438 (1.434 sec)
1.494... logprob:  0.440413, 0.125000 (1.490 sec)
1.495... logprob:  0.428507, 0.093750 (1.430 sec)
1.496... logprob:  0.551308, 0.156250 (1.438 sec)
1.497... logprob:  0.468597, 0.125000 (1.435 sec)
1.498... logprob:  0.482876, 0.132812 (1.433 sec)
1.499... logprob:  0.469946, 0.125000 (1.437 sec)
1.500... logprob:  0.359747, 0.085938 (1.486 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.38252258300781, 10.0]}, 128)
batch 872: ({'logprob': [69.6734619140625, 19.0]}, 128)
batch 873: ({'logprob': [39.436500549316406, 9.0]}, 128)
batch 874: ({'logprob': [45.840763092041016, 11.0]}, 128)
batch 875: ({'logprob': [51.64965057373047, 13.0]}, 128)
batch 876: ({'logprob': [66.62100219726562, 18.0]}, 128)
batch 877: ({'logprob': [45.543731689453125, 11.0]}, 128)
batch 878: ({'logprob': [63.270538330078125, 17.0]}, 128)
batch 879: ({'logprob': [74.59078216552734, 21.0]}, 128)
batch 880: ({'logprob': [51.651180267333984, 13.0]}, 128)
batch 881: ({'logprob': [28.114635467529297, 5.0]}, 128)
batch 882: ({'logprob': [53.812381744384766, 14.0]}, 128)
batch 883: ({'logprob': [63.268245697021484, 17.0]}, 128)
batch 884: ({'logprob': [51.3536491394043, 13.0]}, 128)
batch 885: ({'logprob': [50.75840759277344, 13.0]}, 128)
batch 886: ({'logprob': [62.97285079956055, 17.0]}, 128)

======================Test output======================
logprob:  0.420869, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979326e-03 [8.457579e-10] 
Layer 'conv1' biases: 3.058527e-09 [5.852072e-12] 
Layer 'conv2' weights[0]: 7.966259e-03 [8.275383e-10] 
Layer 'conv2' biases: 1.000000e+00 [3.099188e-11] 
Layer 'conv3' weights[0]: 7.964614e-03 [8.196220e-10] 
Layer 'conv3' biases: 7.368589e-08 [9.458057e-11] 
Layer 'conv4' weights[0]: 7.997110e-03 [8.433076e-10] 
Layer 'conv4' biases: 1.000000e+00 [9.658764e-10] 
Layer 'conv5' weights[0]: 7.996001e-03 [5.267050e-09] 
Layer 'conv5' biases: 9.999960e-01 [5.269693e-09] 
Layer 'fc6' weights[0]: 7.592856e-03 [1.392098e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.152575e-09] 
Layer 'fc7' weights[0]: 7.835864e-03 [6.734644e-08] 
Layer 'fc7' biases: 9.999603e-01 [4.836573e-08] 
Layer 'fc8' weights[0]: 5.428588e-04 [1.001153e-05] 
Layer 'fc8' biases: 4.334683e-04 [1.590700e-05] 
Train error last 870 batches: 0.473149
-------------------------------------------------------
Not saving because 0.420869 > 0.418555 (1.200: -0.41%)
======================================================= (12.091 sec)
1.501... logprob:  0.331956, 0.078125 (1.444 sec)
1.502... logprob:  0.477114, 0.125000 (1.446 sec)
1.503... logprob:  0.401039, 0.101562 (1.478 sec)
1.504... logprob:  0.493124, 0.132812 (1.434 sec)
1.505... logprob:  0.571252, 0.164062 (1.444 sec)
1.506... logprob:  0.481257, 0.132812 (1.440 sec)
1.507... logprob:  0.425537, 0.093750 (1.429 sec)
1.508... logprob:  0.397250, 0.093750 (1.432 sec)
1.509... logprob:  0.323619, 0.070312 (1.484 sec)
1.510... logprob:  0.399157, 0.101562 (1.439 sec)
1.511... logprob:  0.446214, 0.109375 (1.457 sec)
1.512... logprob:  0.526051, 0.125000 (1.465 sec)
1.513... logprob:  0.327051, 0.078125 (1.447 sec)
1.514... logprob:  0.416365, 0.101562 (1.438 sec)
1.515... logprob:  0.455524, 0.125000 (1.434 sec)
1.516... logprob:  0.397824, 0.109375 (1.428 sec)
1.517... logprob:  0.608969, 0.179688 (1.439 sec)
1.518... logprob:  0.475222, 0.117188 (1.459 sec)
1.519... logprob:  0.529357, 0.140625 (1.459 sec)
1.520... logprob:  0.410745, 0.109375 (1.451 sec)
1.521... logprob:  0.427069, 0.109375 (1.450 sec)
1.522... logprob:  0.586172, 0.156250 (1.460 sec)
1.523... logprob:  0.328257, 0.078125 (1.439 sec)
1.524... logprob:  0.450712, 0.117188 (1.421 sec)
1.525... logprob:  0.422983, 0.109375 (1.428 sec)
1.526... logprob:  0.344268, 0.078125 (1.444 sec)
1.527... logprob:  0.503646, 0.140625 (1.437 sec)
1.528... logprob:  0.442660, 0.117188 (1.470 sec)
1.529... logprob:  0.363030, 0.085938 (1.453 sec)
1.530... logprob:  0.440411, 0.117188 (1.444 sec)
1.531... logprob:  0.441290, 0.117188 (1.480 sec)
1.532... logprob:  0.471088, 0.125000 (1.435 sec)
1.533... logprob:  0.573224, 0.164062 (1.431 sec)
1.534... logprob:  0.328775, 0.078125 (1.436 sec)
1.535... logprob:  0.547293, 0.156250 (1.436 sec)
1.536... logprob:  0.507991, 0.140625 (1.437 sec)
1.537... logprob:  0.514826, 0.140625 (1.479 sec)
1.538... logprob:  0.489801, 0.132812 (1.447 sec)
1.539... logprob:  0.308365, 0.062500 (1.436 sec)
1.540... logprob:  0.444485, 0.117188 (1.488 sec)
1.541... logprob:  0.407984, 0.101562 (1.432 sec)
1.542... logprob:  0.440010, 0.109375 (1.456 sec)
1.543... logprob:  0.198688, 0.039062 (1.440 sec)
1.544... logprob:  0.304673, 0.070312 (1.431 sec)
1.545... logprob:  0.355293, 0.085938 (1.437 sec)
1.546... logprob:  0.376364, 0.093750 (1.486 sec)
1.547... logprob:  0.447267, 0.117188 (1.434 sec)
1.548... logprob:  0.436253, 0.125000 (1.448 sec)
1.549... logprob:  0.484892, 0.132812 (1.477 sec)
1.550... logprob:  0.404470, 0.093750 (1.438 sec)
=========================
Testing all batches
batch 871: ({'logprob': [45.17775344848633, 10.0]}, 128)
batch 872: ({'logprob': [66.80493927001953, 19.0]}, 128)
batch 873: ({'logprob': [47.77759552001953, 9.0]}, 128)
batch 874: ({'logprob': [49.839805603027344, 11.0]}, 128)
batch 875: ({'logprob': [54.80691146850586, 13.0]}, 128)
batch 876: ({'logprob': [65.04821014404297, 18.0]}, 128)
batch 877: ({'logprob': [51.293155670166016, 11.0]}, 128)
batch 878: ({'logprob': [64.74417877197266, 17.0]}, 128)
batch 879: ({'logprob': [76.13017272949219, 21.0]}, 128)
batch 880: ({'logprob': [54.8083610534668, 13.0]}, 128)
batch 881: ({'logprob': [36.38985824584961, 5.0]}, 128)
batch 882: ({'logprob': [60.92362594604492, 14.0]}, 128)
batch 883: ({'logprob': [64.74211883544922, 17.0]}, 128)
batch 884: ({'logprob': [56.26018142700195, 13.0]}, 128)
batch 885: ({'logprob': [59.16508102416992, 13.0]}, 128)
batch 886: ({'logprob': [66.19596862792969, 17.0]}, 128)

======================Test output======================
logprob:  0.449271, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979290e-03 [9.820008e-10] 
Layer 'conv1' biases: 3.097555e-09 [2.495917e-11] 
Layer 'conv2' weights[0]: 7.966221e-03 [9.492236e-10] 
Layer 'conv2' biases: 1.000000e+00 [1.144541e-10] 
Layer 'conv3' weights[0]: 7.964571e-03 [1.009063e-09] 
Layer 'conv3' biases: 7.539935e-08 [3.381887e-10] 
Layer 'conv4' weights[0]: 7.997071e-03 [1.054228e-09] 
Layer 'conv4' biases: 1.000000e+00 [3.098311e-09] 
Layer 'conv5' weights[0]: 7.995963e-03 [1.722435e-08] 
Layer 'conv5' biases: 9.999959e-01 [1.771422e-08] 
Layer 'fc6' weights[0]: 7.592815e-03 [3.386522e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.344439e-09] 
Layer 'fc7' weights[0]: 7.834080e-03 [5.171518e-08] 
Layer 'fc7' biases: 9.999565e-01 [2.790011e-08] 
Layer 'fc8' weights[0]: 5.359004e-04 [1.639990e-05] 
Layer 'fc8' biases: 3.808152e-04 [2.671285e-05] 
Train error last 870 batches: 0.469566
-------------------------------------------------------
Not saving because 0.449271 > 0.418555 (1.200: -0.41%)
======================================================= (12.073 sec)
1.551... logprob:  0.455640, 0.117188 (1.440 sec)
1.552... logprob:  0.477863, 0.125000 (1.437 sec)
1.553... logprob:  0.351467, 0.085938 (1.422 sec)
1.554... logprob:  0.531608, 0.140625 (1.431 sec)
1.555... logprob:  0.435131, 0.109375 (1.480 sec)
1.556... logprob:  0.353551, 0.085938 (1.440 sec)
1.557... logprob:  0.398581, 0.101562 (1.456 sec)
1.558... logprob:  0.398004, 0.101562 (1.470 sec)
1.559... logprob:  0.459542, 0.125000 (1.440 sec)
1.560... logprob:  0.349090, 0.078125 (1.439 sec)
1.561... logprob:  0.415766, 0.109375 (1.434 sec)
1.562... logprob:  0.503582, 0.140625 (1.424 sec)
1.563... logprob:  0.373316, 0.093750 (1.437 sec)
1.564... logprob:  0.469793, 0.132812 (1.463 sec)
1.565... logprob:  0.621666, 0.187500 (1.453 sec)
1.566... logprob:  0.384478, 0.093750 (1.451 sec)
1.567... logprob:  0.445050, 0.109375 (1.469 sec)
1.568... logprob:  0.502072, 0.140625 (1.455 sec)
1.569... logprob:  0.518139, 0.140625 (1.440 sec)
1.570... logprob:  0.546156, 0.164062 (1.431 sec)
1.571... logprob:  0.454760, 0.125000 (1.429 sec)
1.572... logprob:  0.500243, 0.140625 (1.443 sec)
1.573... logprob:  0.515024, 0.148438 (1.453 sec)
1.574... logprob:  0.430479, 0.109375 (1.461 sec)
1.575... logprob:  0.346155, 0.078125 (1.457 sec)
1.576... logprob:  0.420106, 0.109375 (1.443 sec)
1.577... logprob:  0.472296, 0.125000 (1.475 sec)
1.578... logprob:  0.326016, 0.078125 (1.437 sec)
1.579... logprob:  0.456139, 0.117188 (1.425 sec)
1.580... logprob:  0.575583, 0.156250 (1.438 sec)
1.581... logprob:  0.538161, 0.156250 (1.438 sec)
1.582... logprob:  0.444391, 0.125000 (1.436 sec)
1.583... logprob:  0.593682, 0.171875 (1.477 sec)
1.584... logprob:  0.502422, 0.132812 (1.449 sec)
1.585... logprob:  0.384388, 0.085938 (1.436 sec)
1.586... logprob:  0.306648, 0.070312 (1.489 sec)
1.587... logprob:  0.421197, 0.101562 (1.432 sec)
1.588... logprob:  0.492288, 0.117188 (1.434 sec)
1.589... logprob:  0.409654, 0.093750 (1.434 sec)
1.590... logprob:  0.630147, 0.148438 (1.437 sec)
1.591... logprob:  0.413061, 0.101562 (1.432 sec)
1.592... logprob:  0.457447, 0.125000 (1.486 sec)
1.593... logprob:  0.484054, 0.125000 (1.439 sec)
1.594... logprob:  0.432414, 0.085938 (1.442 sec)
1.595... logprob:  0.458934, 0.109375 (1.479 sec)
1.596... logprob:  0.459589, 0.125000 (1.441 sec)
1.597... logprob:  0.399668, 0.101562 (1.429 sec)
1.598... logprob:  0.412374, 0.101562 (1.443 sec)
1.599... logprob:  0.307962, 0.070312 (1.429 sec)
1.600... logprob:  0.378747, 0.085938 (1.433 sec)
=========================
Testing all batches
batch 871: ({'logprob': [44.292701721191406, 10.0]}, 128)
batch 872: ({'logprob': [77.14984130859375, 19.0]}, 128)
batch 873: ({'logprob': [39.210689544677734, 9.0]}, 128)
batch 874: ({'logprob': [47.29695510864258, 11.0]}, 128)
batch 875: ({'logprob': [54.551326751708984, 13.0]}, 128)
batch 876: ({'logprob': [73.31596374511719, 18.0]}, 128)
batch 877: ({'logprob': [46.88146209716797, 11.0]}, 128)
batch 878: ({'logprob': [69.06431579589844, 17.0]}, 128)
batch 879: ({'logprob': [83.15819549560547, 21.0]}, 128)
batch 880: ({'logprob': [54.55331802368164, 13.0]}, 128)
batch 881: ({'logprob': [25.114316940307617, 5.0]}, 128)
batch 882: ({'logprob': [57.14206314086914, 14.0]}, 128)
batch 883: ({'logprob': [69.06179809570312, 17.0]}, 128)
batch 884: ({'logprob': [54.137447357177734, 13.0]}, 128)
batch 885: ({'logprob': [53.30594253540039, 13.0]}, 128)
batch 886: ({'logprob': [68.64881896972656, 17.0]}, 128)

======================Test output======================
logprob:  0.447698, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979254e-03 [9.354985e-10] 
Layer 'conv1' biases: 3.178360e-09 [2.125686e-11] 
Layer 'conv2' weights[0]: 7.966187e-03 [9.652859e-10] 
Layer 'conv2' biases: 1.000000e+00 [1.100480e-10] 
Layer 'conv3' weights[0]: 7.964536e-03 [1.012634e-09] 
Layer 'conv3' biases: 7.728471e-08 [3.448594e-10] 
Layer 'conv4' weights[0]: 7.997031e-03 [1.053465e-09] 
Layer 'conv4' biases: 1.000000e+00 [3.057764e-09] 
Layer 'conv5' weights[0]: 7.995939e-03 [1.724335e-08] 
Layer 'conv5' biases: 9.999959e-01 [1.783736e-08] 
Layer 'fc6' weights[0]: 7.592780e-03 [3.542112e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.510489e-09] 
Layer 'fc7' weights[0]: 7.832312e-03 [1.407573e-07] 
Layer 'fc7' biases: 9.999524e-01 [1.276066e-07] 
Layer 'fc8' weights[0]: 6.160027e-04 [5.746717e-06] 
Layer 'fc8' biases: 6.379565e-04 [9.445402e-06] 
Train error last 870 batches: 0.467793
-------------------------------------------------------
Not saving because 0.447698 > 0.418555 (1.200: -0.41%)
======================================================= (12.039 sec)
1.601... logprob:  0.422943, 0.101562 (1.490 sec)
1.602... logprob:  0.277992, 0.062500 (1.440 sec)
1.603... logprob:  0.252141, 0.054688 (1.444 sec)
1.604... logprob:  0.401534, 0.101562 (1.478 sec)
1.605... logprob:  0.537270, 0.148438 (1.439 sec)
1.606... logprob:  0.320817, 0.070312 (1.435 sec)
1.607... logprob:  0.483859, 0.132812 (1.440 sec)
1.608... logprob:  0.371464, 0.085938 (1.430 sec)
1.609... logprob:  0.363892, 0.085938 (1.440 sec)
1.610... logprob:  0.487235, 0.132812 (1.475 sec)
1.611... logprob:  0.515094, 0.140625 (1.447 sec)
1.612... logprob:  0.446544, 0.117188 (1.542 sec)
1.613... logprob:  0.282088, 0.062500 (1.457 sec)
1.614... logprob:  0.505608, 0.140625 (1.455 sec)
1.615... logprob:  0.348280, 0.085938 (1.438 sec)
1.616... logprob:  0.411051, 0.109375 (1.429 sec)
1.617... logprob:  0.418161, 0.109375 (1.427 sec)
1.618... logprob:  0.561426, 0.156250 (1.444 sec)
1.619... logprob:  0.523690, 0.140625 (1.450 sec)
1.620... logprob:  0.537608, 0.156250 (1.461 sec)
1.621... logprob:  0.379380, 0.085938 (1.457 sec)
1.622... logprob:  0.369236, 0.085938 (1.447 sec)
1.623... logprob:  0.419921, 0.109375 (1.471 sec)
1.624... logprob:  0.375940, 0.093750 (1.454 sec)
1.625... logprob:  0.456165, 0.117188 (1.428 sec)
1.626... logprob:  0.462015, 0.117188 (1.436 sec)
1.627... logprob:  0.459734, 0.117188 (1.438 sec)
1.628... logprob:  0.467856, 0.125000 (1.440 sec)
1.629... logprob:  0.380990, 0.093750 (1.471 sec)
1.630... logprob:  0.426955, 0.109375 (1.451 sec)
1.631... logprob:  0.615343, 0.187500 (1.441 sec)
1.632... logprob:  0.420383, 0.101562 (1.483 sec)
1.633... logprob:  0.394580, 0.093750 (1.436 sec)
1.634... logprob:  0.651000, 0.195312 (1.429 sec)
1.635... logprob:  0.374388, 0.093750 (1.437 sec)
1.636... logprob:  0.481224, 0.132812 (1.436 sec)
1.637... logprob:  0.323030, 0.078125 (1.433 sec)
1.638... logprob:  0.531883, 0.140625 (1.485 sec)
1.639... logprob:  0.417455, 0.109375 (1.440 sec)
1.640... logprob:  0.535335, 0.148438 (1.441 sec)
1.641... logprob:  0.414760, 0.109375 (1.485 sec)
1.642... logprob:  0.500941, 0.140625 (1.434 sec)
1.643... logprob:  0.613378, 0.187500 (1.437 sec)
1.644... logprob:  0.356062, 0.070312 (1.436 sec)
1.645... logprob:  0.421932, 0.109375 (1.433 sec)
1.646... logprob:  0.383009, 0.093750 (1.432 sec)
1.647... logprob:  0.463620, 0.125000 (1.493 sec)
1.648... logprob:  0.515391, 0.140625 (1.431 sec)
1.649... logprob:  0.360956, 0.093750 (1.473 sec)
1.650... logprob:  0.414701, 0.109375 (1.481 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.52720260620117, 10.0]}, 128)
batch 872: ({'logprob': [67.45934295654297, 19.0]}, 128)
batch 873: ({'logprob': [41.950435638427734, 9.0]}, 128)
batch 874: ({'logprob': [45.5135383605957, 11.0]}, 128)
batch 875: ({'logprob': [51.64008331298828, 13.0]}, 128)
batch 876: ({'logprob': [65.03768157958984, 18.0]}, 128)
batch 877: ({'logprob': [46.79592514038086, 11.0]}, 128)
batch 878: ({'logprob': [63.896949768066406, 17.0]}, 128)
batch 879: ({'logprob': [77.4317626953125, 21.0]}, 128)
batch 880: ({'logprob': [51.64183044433594, 13.0]}, 128)
batch 881: ({'logprob': [28.413061141967773, 5.0]}, 128)
batch 882: ({'logprob': [57.910282135009766, 14.0]}, 128)
batch 883: ({'logprob': [63.894737243652344, 17.0]}, 128)
batch 884: ({'logprob': [52.92305374145508, 13.0]}, 128)
batch 885: ({'logprob': [55.48638153076172, 13.0]}, 128)
batch 886: ({'logprob': [65.17842102050781, 17.0]}, 128)

======================Test output======================
logprob:  0.427588, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979211e-03 [9.211652e-10] 
Layer 'conv1' biases: 3.241865e-09 [1.714507e-11] 
Layer 'conv2' weights[0]: 7.966150e-03 [9.344889e-10] 
Layer 'conv2' biases: 1.000000e+00 [9.097578e-11] 
Layer 'conv3' weights[0]: 7.964495e-03 [9.568032e-10] 
Layer 'conv3' biases: 7.853846e-08 [2.827353e-10] 
Layer 'conv4' weights[0]: 7.996995e-03 [9.862149e-10] 
Layer 'conv4' biases: 1.000000e+00 [2.420791e-09] 
Layer 'conv5' weights[0]: 7.995902e-03 [1.370455e-08] 
Layer 'conv5' biases: 9.999959e-01 [1.405290e-08] 
Layer 'fc6' weights[0]: 7.592743e-03 [2.810200e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.741577e-09] 
Layer 'fc7' weights[0]: 7.830521e-03 [8.705427e-08] 
Layer 'fc7' biases: 9.999493e-01 [7.000855e-08] 
Layer 'fc8' weights[0]: 5.855670e-04 [3.082099e-05] 
Layer 'fc8' biases: 5.541862e-04 [5.294826e-05] 
Train error last 870 batches: 0.465434
-------------------------------------------------------
Not saving because 0.427588 > 0.418555 (1.200: -0.41%)
======================================================= (12.118 sec)
1.651... logprob:  0.403449, 0.101562 (1.440 sec)
1.652... logprob:  0.527465, 0.140625 (1.437 sec)
1.653... logprob:  0.557165, 0.156250 (1.436 sec)
1.654... logprob:  0.493145, 0.140625 (1.427 sec)
1.655... logprob:  0.451454, 0.117188 (1.438 sec)
1.656... logprob:  0.426979, 0.109375 (1.476 sec)
1.657... logprob:  0.449984, 0.117188 (1.438 sec)
1.658... logprob:  0.348115, 0.085938 (1.452 sec)
1.659... logprob:  0.475711, 0.125000 (1.479 sec)
1.660... logprob:  0.486854, 0.125000 (1.443 sec)
1.661... logprob:  0.378773, 0.093750 (1.438 sec)
1.662... logprob:  0.497188, 0.132812 (1.439 sec)
1.663... logprob:  0.312542, 0.070312 (1.423 sec)
1.664... logprob:  0.293110, 0.062500 (1.442 sec)
1.665... logprob:  0.401351, 0.101562 (1.463 sec)
1.666... logprob:  0.442615, 0.117188 (1.454 sec)
1.667... logprob:  0.566249, 0.164062 (1.456 sec)
1.668... logprob:  0.492667, 0.140625 (1.452 sec)
1.669... logprob:  0.452671, 0.109375 (1.461 sec)
1.670... logprob:  0.389720, 0.085938 (1.446 sec)
1.671... logprob:  0.363144, 0.093750 (1.421 sec)
1.672... logprob:  0.442955, 0.117188 (1.428 sec)
1.673... logprob:  0.441123, 0.117188 (1.440 sec)
1.674... logprob:  0.451030, 0.117188 (1.441 sec)
1.675... logprob:  0.365677, 0.093750 (1.471 sec)
1.676... logprob:  0.461016, 0.125000 (1.455 sec)
1.677... logprob:  0.467260, 0.125000 (1.439 sec)
1.678... logprob:  0.463234, 0.125000 (1.482 sec)
1.679... logprob:  0.458700, 0.125000 (1.439 sec)
1.680... logprob:  0.368989, 0.078125 (1.425 sec)
1.681... logprob:  0.379808, 0.093750 (1.438 sec)
1.682... logprob:  0.332795, 0.078125 (1.442 sec)
1.683... logprob:  0.424835, 0.109375 (1.437 sec)
1.684... logprob:  0.356914, 0.085938 (1.478 sec)
1.685... logprob:  0.254504, 0.054688 (1.445 sec)
1.686... logprob:  0.307263, 0.070312 (1.437 sec)
1.687... logprob:  0.280164, 0.062500 (1.497 sec)
1.688... logprob:  0.340008, 0.078125 (1.431 sec)
1.689... logprob:  0.503886, 0.125000 (1.436 sec)
1.690... logprob:  0.532863, 0.140625 (1.435 sec)
1.691... logprob:  0.511142, 0.140625 (1.436 sec)
1.692... logprob:  0.416235, 0.101562 (1.434 sec)
1.693... logprob:  0.473254, 0.125000 (1.483 sec)
1.694... logprob:  0.406541, 0.078125 (1.440 sec)
1.695... logprob:  0.388189, 0.085938 (1.442 sec)
1.696... logprob:  0.558953, 0.148438 (1.482 sec)
1.697... logprob:  0.499474, 0.125000 (1.435 sec)
1.698... logprob:  0.617838, 0.156250 (1.434 sec)
1.699... logprob:  0.489334, 0.125000 (1.439 sec)
1.700... logprob:  0.435897, 0.117188 (1.428 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.73558807373047, 10.0]}, 128)
batch 872: ({'logprob': [65.9673843383789, 19.0]}, 128)
batch 873: ({'logprob': [41.917808532714844, 9.0]}, 128)
batch 874: ({'logprob': [45.72589874267578, 11.0]}, 128)
batch 875: ({'logprob': [51.2026252746582, 13.0]}, 128)
batch 876: ({'logprob': [63.647117614746094, 18.0]}, 128)
batch 877: ({'logprob': [46.56099319458008, 11.0]}, 128)
batch 878: ({'logprob': [62.15996551513672, 17.0]}, 128)
batch 879: ({'logprob': [73.94769287109375, 21.0]}, 128)
batch 880: ({'logprob': [51.20442199707031, 13.0]}, 128)
batch 881: ({'logprob': [30.12737274169922, 5.0]}, 128)
batch 882: ({'logprob': [56.02922439575195, 14.0]}, 128)
batch 883: ({'logprob': [62.15763854980469, 17.0]}, 128)
batch 884: ({'logprob': [52.03786849975586, 13.0]}, 128)
batch 885: ({'logprob': [53.706504821777344, 13.0]}, 128)
batch 886: ({'logprob': [62.993778228759766, 17.0]}, 128)

======================Test output======================
logprob:  0.420470, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979175e-03 [1.099308e-09] 
Layer 'conv1' biases: 3.323931e-09 [2.532219e-11] 
Layer 'conv2' weights[0]: 7.966108e-03 [1.136115e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.589416e-10] 
Layer 'conv3' weights[0]: 7.964452e-03 [1.193413e-09] 
Layer 'conv3' biases: 8.038243e-08 [5.192399e-10] 
Layer 'conv4' weights[0]: 7.996954e-03 [1.275564e-09] 
Layer 'conv4' biases: 1.000000e+00 [4.920704e-09] 
Layer 'conv5' weights[0]: 7.995866e-03 [2.837173e-08] 
Layer 'conv5' biases: 9.999959e-01 [2.927611e-08] 
Layer 'fc6' weights[0]: 7.592711e-03 [5.639176e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.710700e-09] 
Layer 'fc7' weights[0]: 7.828709e-03 [2.407968e-07] 
Layer 'fc7' biases: 9.999466e-01 [2.284053e-07] 
Layer 'fc8' weights[0]: 5.561472e-04 [5.227326e-05] 
Layer 'fc8' biases: 5.150985e-04 [9.217911e-05] 
Train error last 870 batches: 0.463103
-------------------------------------------------------
Not saving because 0.420470 > 0.418555 (1.200: -0.41%)
======================================================= (11.986 sec)
1.701... logprob:  0.424677, 0.109375 (1.435 sec)
1.702... logprob:  0.525457, 0.148438 (1.483 sec)
1.703... logprob:  0.430642, 0.101562 (1.440 sec)
1.704... logprob:  0.423313, 0.101562 (1.446 sec)
1.705... logprob:  0.420885, 0.109375 (1.478 sec)
1.706... logprob:  0.466047, 0.125000 (1.436 sec)
1.707... logprob:  0.498923, 0.132812 (1.442 sec)
1.708... logprob:  0.430927, 0.109375 (1.432 sec)
1.709... logprob:  0.428470, 0.109375 (1.430 sec)
1.710... logprob:  0.640596, 0.179688 (1.439 sec)
1.711... logprob:  0.464137, 0.125000 (1.466 sec)
1.712... logprob:  0.360466, 0.078125 (1.459 sec)
1.713... logprob:  0.584347, 0.179688 (1.459 sec)
1.714... logprob:  0.481006, 0.125000 (1.455 sec)
1.715... logprob:  0.433276, 0.109375 (1.468 sec)
1.716... logprob:  0.345562, 0.078125 (1.437 sec)
1.717... logprob:  0.427077, 0.117188 (1.430 sec)
1.718... logprob:  0.521120, 0.132812 (1.426 sec)
1.719... logprob:  0.411348, 0.109375 (1.445 sec)
1.720... logprob:  0.445594, 0.117188 (1.448 sec)
1.721... logprob:  0.481007, 0.117188 (1.460 sec)
1.722... logprob:  0.534990, 0.156250 (1.457 sec)
1.723... logprob:  0.426358, 0.109375 (1.450 sec)
1.724... logprob:  0.428481, 0.109375 (1.472 sec)
1.725... logprob:  0.493737, 0.140625 (1.440 sec)
1.726... logprob:  0.346403, 0.085938 (1.426 sec)
1.727... logprob:  0.393689, 0.101562 (1.434 sec)
1.728... logprob:  0.423820, 0.109375 (1.442 sec)
1.729... logprob:  0.387521, 0.093750 (1.431 sec)
1.730... logprob:  0.618551, 0.164062 (1.480 sec)
1.731... logprob:  0.473752, 0.125000 (1.445 sec)
1.732... logprob:  0.303707, 0.070312 (1.438 sec)
1.733... logprob:  0.553045, 0.156250 (1.485 sec)
1.734... logprob:  0.349891, 0.078125 (1.438 sec)
1.735... logprob:  0.521287, 0.148438 (1.427 sec)
1.736... logprob:  0.615619, 0.187500 (1.440 sec)
1.737... logprob:  0.523027, 0.148438 (1.434 sec)
1.738... logprob:  0.473913, 0.125000 (1.438 sec)
1.739... logprob:  0.484116, 0.132812 (1.479 sec)
1.740... logprob:  0.341673, 0.078125 (1.442 sec)
1.741... logprob:  0.390211, 0.101562 (1.438 sec)
1.742... logprob:  0.423206, 0.109375 (1.483 sec)
1.743... logprob:  0.358160, 0.085938 (1.439 sec)
1.744... logprob:  0.569749, 0.148438 (1.430 sec)
1.745... logprob:  0.504090, 0.132812 (1.440 sec)
1.746... logprob:  0.448860, 0.117188 (1.430 sec)
1.747... logprob:  0.440360, 0.109375 (1.436 sec)
1.748... logprob:  0.398793, 0.093750 (1.492 sec)
1.749... logprob:  0.435234, 0.109375 (1.430 sec)
1.750... logprob:  0.511876, 0.140625 (1.450 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.537479400634766, 10.0]}, 128)
batch 872: ({'logprob': [66.20814514160156, 19.0]}, 128)
batch 873: ({'logprob': [41.252708435058594, 9.0]}, 128)
batch 874: ({'logprob': [45.77476119995117, 11.0]}, 128)
batch 875: ({'logprob': [51.07722854614258, 13.0]}, 128)
batch 876: ({'logprob': [63.75310516357422, 18.0]}, 128)
batch 877: ({'logprob': [46.165828704833984, 11.0]}, 128)
batch 878: ({'logprob': [61.686492919921875, 17.0]}, 128)
batch 879: ({'logprob': [72.68191528320312, 21.0]}, 128)
batch 880: ({'logprob': [51.07920837402344, 13.0]}, 128)
batch 881: ({'logprob': [30.254247665405273, 5.0]}, 128)
batch 882: ({'logprob': [54.70660400390625, 14.0]}, 128)
batch 883: ({'logprob': [61.6840705871582, 17.0]}, 128)
batch 884: ({'logprob': [51.468238830566406, 13.0]}, 128)
batch 885: ({'logprob': [52.24884033203125, 13.0]}, 128)
batch 886: ({'logprob': [62.07607650756836, 17.0]}, 128)

======================Test output======================
logprob:  0.417312, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979139e-03 [9.517164e-10] 
Layer 'conv1' biases: 3.383235e-09 [1.340434e-11] 
Layer 'conv2' weights[0]: 7.966069e-03 [9.237461e-10] 
Layer 'conv2' biases: 1.000000e+00 [6.789952e-11] 
Layer 'conv3' weights[0]: 7.964416e-03 [9.066272e-10] 
Layer 'conv3' biases: 8.174962e-08 [2.098000e-10] 
Layer 'conv4' weights[0]: 7.996908e-03 [9.397898e-10] 
Layer 'conv4' biases: 1.000000e+00 [1.861030e-09] 
Layer 'conv5' weights[0]: 7.995835e-03 [9.720380e-09] 
Layer 'conv5' biases: 9.999961e-01 [9.915762e-09] 
Layer 'fc6' weights[0]: 7.592677e-03 [1.938129e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.776428e-09] 
Layer 'fc7' weights[0]: 7.826857e-03 [8.006467e-08] 
Layer 'fc7' biases: 9.999407e-01 [6.198968e-08] 
Layer 'fc8' weights[0]: 5.514277e-04 [3.589909e-05] 
Layer 'fc8' biases: 5.463667e-04 [6.688465e-05] 
Train error last 870 batches: 0.462655
-------------------------------------------------------
Saved checkpoint to /data2/ad6813/my-nets/saves/ConvNet__2014-06-17_23.05.49
======================================================= (12.590 sec)
1.751... logprob:  0.274745, 0.054688 (1.500 sec)
1.752... logprob:  0.515171, 0.140625 (1.439 sec)
1.753... logprob:  0.450587, 0.117188 (1.443 sec)
1.754... logprob:  0.520256, 0.132812 (2.714 sec)
1.755... logprob:  0.523956, 0.140625 (1.427 sec)
1.756... logprob:  0.447520, 0.117188 (1.438 sec)
1.757... logprob:  0.545063, 0.156250 (3.104 sec)
1.758... logprob:  0.414544, 0.101562 (1.447 sec)
1.759... logprob:  0.468966, 0.125000 (1.454 sec)
1.760... logprob:  0.489754, 0.132812 (1.466 sec)
1.761... logprob:  0.422088, 0.109375 (1.450 sec)
1.762... logprob:  0.516335, 0.148438 (1.439 sec)
1.763... logprob:  0.572740, 0.164062 (1.432 sec)
1.764... logprob:  0.515518, 0.140625 (1.432 sec)
1.765... logprob:  0.304556, 0.062500 (1.441 sec)
1.766... logprob:  0.487978, 0.132812 (1.452 sec)
1.767... logprob:  0.365375, 0.085938 (1.465 sec)
1.768... logprob:  0.428218, 0.117188 (1.462 sec)
1.769... logprob:  0.498155, 0.140625 (1.469 sec)
1.770... logprob:  0.400221, 0.101562 (1.492 sec)
1.771... logprob:  0.554693, 0.156250 (1.460 sec)
1.772... logprob:  0.415966, 0.109375 (1.445 sec)
1.773... logprob:  0.551170, 0.164062 (1.450 sec)
1.774... logprob:  0.382294, 0.085938 (1.458 sec)
1.775... logprob:  0.417365, 0.101562 (1.468 sec)
1.776... logprob:  0.436413, 0.117188 (1.481 sec)
1.777... logprob:  0.377586, 0.093750 (1.474 sec)
1.778... logprob:  0.443602, 0.117188 (1.466 sec)
1.779... logprob:  0.523980, 0.140625 (1.492 sec)
1.780... logprob:  0.392643, 0.101562 (1.451 sec)
1.781... logprob:  0.366589, 0.085938 (1.451 sec)
1.782... logprob:  0.350483, 0.085938 (1.446 sec)
1.783... logprob:  0.555953, 0.156250 (1.458 sec)
1.784... logprob:  0.440224, 0.117188 (1.455 sec)
1.785... logprob:  0.532978, 0.156250 (1.488 sec)
1.786... logprob:  0.477203, 0.132812 (1.498 sec)
1.787... logprob:  0.540432, 0.156250 (1.460 sec)
1.788... logprob:  0.556672, 0.164062 (1.500 sec)
1.789... logprob:  0.318649, 0.054688 (1.475 sec)
1.790... logprob:  0.409377, 0.101562 (1.448 sec)
1.791... logprob:  0.393530, 0.101562 (1.450 sec)
1.792... logprob:  0.352257, 0.085938 (1.465 sec)
1.793... logprob:  0.364682, 0.085938 (1.454 sec)
1.794... logprob:  0.396537, 0.093750 (1.495 sec)
1.795... logprob:  0.511182, 0.125000 (1.471 sec)
1.796... logprob:  0.441450, 0.109375 (1.456 sec)
1.797... logprob:  0.352739, 0.085938 (1.504 sec)
1.798... logprob:  0.407660, 0.101562 (1.452 sec)
1.799... logprob:  0.344219, 0.078125 (1.451 sec)
1.800... logprob:  0.393701, 0.093750 (1.448 sec)
=========================
Testing all batches
batch 871: ({'logprob': [44.902191162109375, 10.0]}, 128)
batch 872: ({'logprob': [67.6944808959961, 19.0]}, 128)
batch 873: ({'logprob': [41.74113845825195, 9.0]}, 128)
batch 874: ({'logprob': [47.15044021606445, 11.0]}, 128)
batch 875: ({'logprob': [52.19390106201172, 13.0]}, 128)
batch 876: ({'logprob': [65.08268737792969, 18.0]}, 128)
batch 877: ({'logprob': [46.96854019165039, 11.0]}, 128)
batch 878: ({'logprob': [62.285606384277344, 17.0]}, 128)
batch 879: ({'logprob': [72.19026184082031, 21.0]}, 128)
batch 880: ({'logprob': [52.1961555480957, 13.0]}, 128)
batch 881: ({'logprob': [31.833332061767578, 5.0]}, 128)
batch 882: ({'logprob': [54.26117706298828, 14.0]}, 128)
batch 883: ({'logprob': [62.282955169677734, 17.0]}, 128)
batch 884: ({'logprob': [52.01174545288086, 13.0]}, 128)
batch 885: ({'logprob': [51.64628219604492, 13.0]}, 128)
batch 886: ({'logprob': [62.10198974609375, 17.0]}, 128)

======================Test output======================
logprob:  0.423117, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979102e-03 [9.208526e-10] 
Layer 'conv1' biases: 3.465282e-09 [1.493018e-11] 
Layer 'conv2' weights[0]: 7.966025e-03 [9.033120e-10] 
Layer 'conv2' biases: 1.000000e+00 [9.004596e-11] 
Layer 'conv3' weights[0]: 7.964382e-03 [9.440602e-10] 
Layer 'conv3' biases: 8.342595e-08 [2.724198e-10] 
Layer 'conv4' weights[0]: 7.996867e-03 [1.022102e-09] 
Layer 'conv4' biases: 1.000000e+00 [2.840991e-09] 
Layer 'conv5' weights[0]: 7.995792e-03 [1.663957e-08] 
Layer 'conv5' biases: 9.999960e-01 [1.728159e-08] 
Layer 'fc6' weights[0]: 7.592641e-03 [3.345280e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.300011e-09] 
Layer 'fc7' weights[0]: 7.825050e-03 [7.045757e-08] 
Layer 'fc7' biases: 9.999376e-01 [5.178834e-08] 
Layer 'fc8' weights[0]: 5.445279e-04 [1.592689e-05] 
Layer 'fc8' biases: 5.448944e-04 [3.082643e-05] 
Train error last 870 batches: 0.461444
-------------------------------------------------------
Not saving because 0.423117 > 0.417312 (1.750: -0.30%)
======================================================= (12.062 sec)
1.801... logprob:  0.444338, 0.117188 (1.493 sec)
1.802... logprob:  0.423157, 0.109375 (1.460 sec)
1.803... logprob:  0.483718, 0.132812 (1.489 sec)
1.804... logprob:  0.353018, 0.085938 (1.470 sec)
1.805... logprob:  0.452807, 0.117188 (1.453 sec)
1.806... logprob:  0.426314, 0.109375 (1.504 sec)
1.807... logprob:  0.443628, 0.117188 (1.456 sec)
1.808... logprob:  0.458657, 0.125000 (1.451 sec)
1.809... logprob:  0.573785, 0.171875 (1.454 sec)
1.810... logprob:  0.451034, 0.117188 (1.454 sec)
1.811... logprob:  0.467229, 0.125000 (1.458 sec)
1.812... logprob:  0.476209, 0.125000 (1.491 sec)
1.813... logprob:  0.498853, 0.132812 (1.460 sec)
1.814... logprob:  0.473815, 0.132812 (1.454 sec)
1.815... logprob:  0.362711, 0.085938 (1.505 sec)
1.816... logprob:  0.398665, 0.101562 (1.451 sec)
1.817... logprob:  0.424637, 0.109375 (1.455 sec)
1.818... logprob:  0.603536, 0.164062 (1.450 sec)
1.819... logprob:  0.524118, 0.140625 (1.464 sec)
1.820... logprob:  0.423687, 0.109375 (1.455 sec)
1.821... logprob:  0.403350, 0.101562 (0.678 sec)
1.822... logprob:  0.446564, 0.117188 (0.690 sec)
1.823... logprob:  0.354252, 0.078125 (0.690 sec)
1.824... logprob:  0.486595, 0.132812 (0.688 sec)
1.825... logprob:  0.292035, 0.062500 (0.691 sec)
1.826... logprob:  0.374898, 0.093750 (0.692 sec)
1.827... logprob:  0.427625, 0.109375 (0.690 sec)
1.828... logprob:  0.457484, 0.117188 (0.688 sec)
1.829... logprob:  0.520719, 0.140625 (0.688 sec)
1.830... logprob:  0.443077, 0.117188 (1.510 sec)
1.831... logprob:  0.507008, 0.140625 (1.449 sec)
1.832... logprob:  0.358879, 0.078125 (1.466 sec)
1.833... logprob:  0.491233, 0.132812 (1.498 sec)
1.834... logprob:  0.431114, 0.117188 (1.451 sec)
1.835... logprob:  0.554539, 0.148438 (1.459 sec)
1.836... logprob:  0.384252, 0.093750 (1.446 sec)
1.837... logprob:  0.313000, 0.070312 (1.455 sec)
1.838... logprob:  0.444704, 0.117188 (1.458 sec)
1.839... logprob:  0.480250, 0.125000 (1.501 sec)
1.840... logprob:  0.579832, 0.156250 (1.458 sec)
1.841... logprob:  0.409564, 0.101562 (1.462 sec)
1.842... logprob:  0.525125, 0.140625 (1.496 sec)
1.843... logprob:  0.467377, 0.125000 (1.452 sec)
1.844... logprob:  0.517643, 0.140625 (1.464 sec)
1.845... logprob:  0.491652, 0.132812 (1.445 sec)
1.846... logprob:  0.474807, 0.125000 (1.448 sec)
1.847... logprob:  0.377310, 0.085938 (1.453 sec)
1.848... logprob:  0.395501, 0.101562 (1.496 sec)
1.849... logprob:  0.350076, 0.085938 (1.459 sec)
1.850... logprob:  0.499444, 0.132812 (1.472 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.49784851074219, 10.0]}, 128)
batch 872: ({'logprob': [70.96776580810547, 19.0]}, 128)
batch 873: ({'logprob': [40.045257568359375, 9.0]}, 128)
batch 874: ({'logprob': [45.207496643066406, 11.0]}, 128)
batch 875: ({'logprob': [52.071475982666016, 13.0]}, 128)
batch 876: ({'logprob': [67.9624252319336, 18.0]}, 128)
batch 877: ({'logprob': [46.05867004394531, 11.0]}, 128)
batch 878: ({'logprob': [65.80484008789062, 17.0]}, 128)
batch 879: ({'logprob': [80.38451385498047, 21.0]}, 128)
batch 880: ({'logprob': [52.07374954223633, 13.0]}, 128)
batch 881: ({'logprob': [25.461158752441406, 5.0]}, 128)
batch 882: ({'logprob': [57.6342658996582, 14.0]}, 128)
batch 883: ({'logprob': [65.80250549316406, 17.0]}, 128)
batch 884: ({'logprob': [52.923439025878906, 13.0]}, 128)
batch 885: ({'logprob': [54.62567138671875, 13.0]}, 128)
batch 886: ({'logprob': [66.6556396484375, 17.0]}, 128)

======================Test output======================
logprob:  0.431727, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979066e-03 [9.437596e-10] 
Layer 'conv1' biases: 3.489339e-09 [1.457153e-11] 
Layer 'conv2' weights[0]: 7.965990e-03 [9.152392e-10] 
Layer 'conv2' biases: 1.000000e+00 [7.819587e-11] 
Layer 'conv3' weights[0]: 7.964341e-03 [9.327291e-10] 
Layer 'conv3' biases: 8.453703e-08 [2.551482e-10] 
Layer 'conv4' weights[0]: 7.996830e-03 [9.611054e-10] 
Layer 'conv4' biases: 1.000000e+00 [2.179141e-09] 
Layer 'conv5' weights[0]: 7.995757e-03 [1.284476e-08] 
Layer 'conv5' biases: 9.999962e-01 [1.341616e-08] 
Layer 'fc6' weights[0]: 7.592599e-03 [2.465213e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.333147e-09] 
Layer 'fc7' weights[0]: 7.823260e-03 [5.880407e-08] 
Layer 'fc7' biases: 9.999350e-01 [3.637315e-08] 
Layer 'fc8' weights[0]: 6.500960e-04 [3.012822e-05] 
Layer 'fc8' biases: 8.298136e-04 [5.947550e-05] 
Train error last 870 batches: 0.460681
-------------------------------------------------------
Not saving because 0.431727 > 0.417312 (1.750: -0.30%)
======================================================= (12.068 sec)
1.851... logprob:  0.460448, 0.117188 (1.498 sec)
1.852... logprob:  0.591559, 0.156250 (1.458 sec)
1.853... logprob:  0.364326, 0.093750 (1.463 sec)
1.854... logprob:  0.299476, 0.070312 (1.459 sec)
1.855... logprob:  0.497791, 0.132812 (1.451 sec)
1.856... logprob:  0.464166, 0.117188 (1.462 sec)
1.857... logprob:  0.383011, 0.093750 (1.497 sec)
1.858... logprob:  0.403848, 0.101562 (1.463 sec)
1.859... logprob:  0.316266, 0.070312 (1.472 sec)
1.860... logprob:  0.575452, 0.156250 (1.488 sec)
1.861... logprob:  0.420369, 0.109375 (1.457 sec)
1.862... logprob:  0.328645, 0.078125 (1.459 sec)
1.863... logprob:  0.400319, 0.101562 (1.452 sec)
1.864... logprob:  0.443245, 0.117188 (1.443 sec)
1.865... logprob:  0.499863, 0.132812 (1.465 sec)
1.866... logprob:  0.517431, 0.140625 (1.495 sec)
1.867... logprob:  0.516880, 0.140625 (1.473 sec)
1.868... logprob:  0.410289, 0.101562 (1.473 sec)
1.869... logprob:  0.394199, 0.093750 (1.480 sec)
1.870... logprob:  0.542478, 0.156250 (1.403 sec)
2.1... logprob:  0.382456, 0.093750 (1.409 sec)
2.2... logprob:  0.445120, 0.117188 (1.449 sec)
2.3... logprob:  0.395395, 0.101562 (1.423 sec)
2.4... logprob:  0.446933, 0.117188 (1.405 sec)
2.5... logprob:  0.448575, 0.117188 (1.448 sec)
2.6... logprob:  0.511729, 0.140625 (1.406 sec)
2.7... logprob:  0.358175, 0.085938 (1.426 sec)
2.8... logprob:  0.416633, 0.109375 (1.405 sec)
2.9... logprob:  0.359601, 0.085938 (1.407 sec)
2.10... logprob:  0.378531, 0.093750 (1.422 sec)
2.11... logprob:  0.337101, 0.078125 (1.457 sec)
2.12... logprob:  0.469837, 0.125000 (1.399 sec)
2.13... logprob:  0.443685, 0.117188 (1.426 sec)
2.14... logprob:  0.446032, 0.117188 (1.407 sec)
2.15... logprob:  0.395756, 0.101562 (1.419 sec)
2.16... logprob:  0.420322, 0.109375 (1.410 sec)
2.17... logprob:  0.508657, 0.140625 (1.401 sec)
2.18... logprob:  0.277881, 0.054688 (1.402 sec)
2.19... logprob:  0.293146, 0.062500 (1.414 sec)
2.20... logprob:  0.420384, 0.109375 (1.405 sec)
2.21... logprob:  0.444519, 0.117188 (0.889 sec)
2.22... logprob:  0.541212, 0.148438 (1.329 sec)
2.23... logprob:  0.533463, 0.148438 (1.424 sec)
2.24... logprob:  0.317007, 0.070312 (0.999 sec)
2.25... logprob:  0.363528, 0.085938 (0.962 sec)
2.26... logprob:  0.462956, 0.125000 (1.449 sec)
2.27... logprob:  0.410687, 0.101562 (1.399 sec)
2.28... logprob:  0.422274, 0.109375 (1.445 sec)
2.29... logprob:  0.396461, 0.101562 (1.439 sec)
2.30... logprob:  0.374696, 0.093750 (1.436 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.01349639892578, 10.0]}, 128)
batch 872: ({'logprob': [68.51029205322266, 19.0]}, 128)
batch 873: ({'logprob': [39.34825134277344, 9.0]}, 128)
batch 874: ({'logprob': [45.08308410644531, 11.0]}, 128)
batch 875: ({'logprob': [50.978485107421875, 13.0]}, 128)
batch 876: ({'logprob': [65.6042709350586, 18.0]}, 128)
batch 877: ({'logprob': [45.16410446166992, 11.0]}, 128)
batch 878: ({'logprob': [62.775028228759766, 17.0]}, 128)
batch 879: ({'logprob': [74.64728546142578, 21.0]}, 128)
batch 880: ({'logprob': [50.981075286865234, 13.0]}, 128)
batch 881: ({'logprob': [27.471715927124023, 5.0]}, 128)
batch 882: ({'logprob': [54.13053894042969, 14.0]}, 128)
batch 883: ({'logprob': [62.772361755371094, 17.0]}, 128)
batch 884: ({'logprob': [51.059654235839844, 13.0]}, 128)
batch 885: ({'logprob': [51.220890045166016, 13.0]}, 128)
batch 886: ({'logprob': [62.854949951171875, 17.0]}, 128)

======================Test output======================
logprob:  0.417293, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979020e-03 [8.820604e-10] 
Layer 'conv1' biases: 3.572480e-09 [7.317426e-12] 
Layer 'conv2' weights[0]: 7.965948e-03 [8.445761e-10] 
Layer 'conv2' biases: 1.000000e+00 [3.427435e-11] 
Layer 'conv3' weights[0]: 7.964299e-03 [8.389962e-10] 
Layer 'conv3' biases: 8.571997e-08 [1.140440e-10] 
Layer 'conv4' weights[0]: 7.996790e-03 [8.623201e-10] 
Layer 'conv4' biases: 1.000000e+00 [1.026488e-09] 
Layer 'conv5' weights[0]: 7.995724e-03 [5.839888e-09] 
Layer 'conv5' biases: 9.999963e-01 [5.978443e-09] 
Layer 'fc6' weights[0]: 7.592561e-03 [1.372723e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.123856e-09] 
Layer 'fc7' weights[0]: 7.821435e-03 [4.551618e-08] 
Layer 'fc7' biases: 9.999315e-01 [1.872817e-08] 
Layer 'fc8' weights[0]: 5.998227e-04 [1.137619e-05] 
Layer 'fc8' biases: 7.339797e-04 [2.315567e-05] 
Train error last 870 batches: 0.450716
-------------------------------------------------------
Saved checkpoint to /data2/ad6813/my-nets/saves/ConvNet__2014-06-17_23.05.49
======================================================= (13.018 sec)
2.31... logprob:  0.489182, 0.132812 (1.425 sec)
2.32... logprob:  0.463111, 0.125000 (1.395 sec)
2.33... logprob:  0.462132, 0.125000 (1.466 sec)
2.34... logprob:  0.467099, 0.125000 (2.821 sec)
2.35... logprob:  0.323894, 0.070312 (1.407 sec)
2.36... logprob:  0.468197, 0.132812 (1.400 sec)
2.37... logprob:  0.418455, 0.109375 (3.013 sec)
2.38... logprob:  0.387363, 0.101562 (1.401 sec)
2.39... logprob:  0.639287, 0.187500 (1.447 sec)
2.40... logprob:  0.457234, 0.117188 (1.417 sec)
2.41... logprob:  0.351867, 0.085938 (1.428 sec)
2.42... logprob:  0.386986, 0.101562 (1.434 sec)
2.43... logprob:  0.441771, 0.117188 (1.420 sec)
2.44... logprob:  0.521896, 0.148438 (1.438 sec)
2.45... logprob:  0.382170, 0.093750 (1.405 sec)
2.46... logprob:  0.489834, 0.132812 (1.396 sec)
2.47... logprob:  0.329877, 0.078125 (1.397 sec)
2.48... logprob:  0.501478, 0.140625 (1.425 sec)
2.49... logprob:  0.515076, 0.148438 (1.416 sec)
2.50... logprob:  0.396203, 0.101562 (1.423 sec)
2.51... logprob:  0.488440, 0.140625 (1.419 sec)
2.52... logprob:  0.522963, 0.148438 (1.398 sec)
2.53... logprob:  0.315080, 0.062500 (1.450 sec)
2.54... logprob:  0.402070, 0.109375 (1.392 sec)
2.55... logprob:  0.329418, 0.078125 (1.406 sec)
2.56... logprob:  0.426004, 0.109375 (1.405 sec)
2.57... logprob:  0.606574, 0.164062 (1.433 sec)
2.58... logprob:  0.414800, 0.101562 (1.410 sec)
2.59... logprob:  0.328263, 0.078125 (1.553 sec)
2.60... logprob:  0.641263, 0.179688 (1.431 sec)
2.61... logprob:  0.381688, 0.093750 (1.427 sec)
2.62... logprob:  0.474396, 0.132812 (1.498 sec)
2.63... logprob:  0.406548, 0.101562 (1.437 sec)
2.64... logprob:  0.459074, 0.125000 (1.418 sec)
2.65... logprob:  0.388844, 0.093750 (1.398 sec)
2.66... logprob:  0.362132, 0.085938 (1.449 sec)
2.67... logprob:  0.290838, 0.062500 (1.389 sec)
2.68... logprob:  0.399382, 0.101562 (1.400 sec)
2.69... logprob:  0.533979, 0.140625 (1.423 sec)
2.70... logprob:  0.326330, 0.078125 (1.423 sec)
2.71... logprob:  0.397512, 0.101562 (1.457 sec)
2.72... logprob:  0.514301, 0.132812 (1.408 sec)
2.73... logprob:  0.453726, 0.117188 (1.425 sec)
2.74... logprob:  0.442998, 0.117188 (1.420 sec)
2.75... logprob:  0.395329, 0.093750 (1.414 sec)
2.76... logprob:  0.419641, 0.109375 (1.437 sec)
2.77... logprob:  0.409834, 0.101562 (1.428 sec)
2.78... logprob:  0.484952, 0.140625 (1.458 sec)
2.79... logprob:  0.454752, 0.125000 (1.400 sec)
2.80... logprob:  0.507159, 0.132812 (1.417 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.68783187866211, 10.0]}, 128)
batch 872: ({'logprob': [66.71148681640625, 19.0]}, 128)
batch 873: ({'logprob': [40.42253112792969, 9.0]}, 128)
batch 874: ({'logprob': [45.15200424194336, 11.0]}, 128)
batch 875: ({'logprob': [50.76005172729492, 13.0]}, 128)
batch 876: ({'logprob': [64.12854766845703, 18.0]}, 128)
batch 877: ({'logprob': [45.592098236083984, 11.0]}, 128)
batch 878: ({'logprob': [61.981597900390625, 17.0]}, 128)
batch 879: ({'logprob': [73.63758850097656, 21.0]}, 128)
batch 880: ({'logprob': [50.7624626159668, 13.0]}, 128)
batch 881: ({'logprob': [28.76218605041504, 5.0]}, 128)
batch 882: ({'logprob': [54.665374755859375, 14.0]}, 128)
batch 883: ({'logprob': [61.978965759277344, 17.0]}, 128)
batch 884: ({'logprob': [51.19982147216797, 13.0]}, 128)
batch 885: ({'logprob': [52.07872772216797, 13.0]}, 128)
batch 886: ({'logprob': [62.42008590698242, 17.0]}, 128)

======================Test output======================
logprob:  0.415987, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.978983e-03 [9.266178e-10] 
Layer 'conv1' biases: 3.629197e-09 [1.047289e-11] 
Layer 'conv2' weights[0]: 7.965910e-03 [8.808384e-10] 
Layer 'conv2' biases: 1.000000e+00 [4.281243e-11] 
Layer 'conv3' weights[0]: 7.964259e-03 [8.509637e-10] 
Layer 'conv3' biases: 8.678154e-08 [1.516757e-10] 
Layer 'conv4' weights[0]: 7.996755e-03 [8.748125e-10] 
Layer 'conv4' biases: 1.000000e+00 [1.377652e-09] 
Layer 'conv5' weights[0]: 7.995678e-03 [7.617411e-09] 
Layer 'conv5' biases: 9.999964e-01 [7.708953e-09] 
Layer 'fc6' weights[0]: 7.592521e-03 [1.621192e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.427823e-09] 
Layer 'fc7' weights[0]: 7.819581e-03 [5.984898e-08] 
Layer 'fc7' biases: 9.999295e-01 [3.801702e-08] 
Layer 'fc8' weights[0]: 5.912560e-04 [2.118546e-05] 
Layer 'fc8' biases: 7.212826e-04 [4.396206e-05] 
Train error last 870 batches: 0.448388
-------------------------------------------------------
Saved checkpoint to /data2/ad6813/my-nets/saves/ConvNet__2014-06-17_23.05.49
======================================================= (12.603 sec)
2.81... logprob:  0.416787, 0.109375 (1.427 sec)
2.82... logprob:  0.220820, 0.039062 (1.429 sec)
2.83... logprob:  0.513566, 0.140625 (1.405 sec)
2.84... logprob:  0.473463, 0.125000 (1.466 sec)
2.85... logprob:  0.445135, 0.117188 (1.428 sec)
2.86... logprob:  0.420117, 0.109375 (1.417 sec)
2.87... logprob:  0.639210, 0.187500 (1.416 sec)
2.88... logprob:  0.535797, 0.156250 (1.412 sec)
2.89... logprob:  0.430354, 0.109375 (1.435 sec)
2.90... logprob:  0.574086, 0.171875 (1.393 sec)
2.91... logprob:  0.396838, 0.078125 (1.393 sec)
2.92... logprob:  0.473288, 0.125000 (1.424 sec)
2.93... logprob:  0.491223, 0.140625 (1.395 sec)
2.94... logprob:  0.426918, 0.109375 (1.405 sec)
2.95... logprob:  0.484116, 0.125000 (1.407 sec)
2.96... logprob:  0.624706, 0.171875 (1.408 sec)
2.97... logprob:  0.437325, 0.117188 (1.396 sec)
2.98... logprob:  0.382381, 0.093750 (1.441 sec)
2.99... logprob:  0.476938, 0.132812 (1.412 sec)
2.100... logprob:  0.312325, 0.070312 (1.400 sec)
2.101... logprob:  0.319885, 0.062500 (1.454 sec)
2.102... logprob:  0.543747, 0.156250 (3.836 sec)
2.103... logprob:  0.539451, 0.156250 (1.401 sec)
2.104... logprob:  0.392033, 0.101562 (1.407 sec)
2.105... logprob:  0.608416, 0.179688 (1.396 sec)
2.106... logprob:  0.354048, 0.085938 (1.401 sec)
2.107... logprob:  0.348629, 0.078125 (1.441 sec)
2.108... logprob:  0.576882, 0.171875 (1.397 sec)
2.109... logprob:  0.342551, 0.078125 (1.401 sec)
2.110... logprob:  0.562967, 0.164062 (1.402 sec)
2.111... logprob:  0.407073, 0.101562 (1.401 sec)
2.112... logprob:  0.363564, 0.093750 (1.402 sec)
2.113... logprob:  0.351969, 0.085938 (1.401 sec)
2.114... logprob:  0.442403, 0.117188 (1.434 sec)
2.115... logprob:  0.515586, 0.140625 (1.445 sec)
2.116... logprob:  0.391933, 0.101562 (1.402 sec)
2.117... logprob:  0.441215, 0.117188 (1.445 sec)
2.118... logprob:  0.409407, 0.101562 (1.396 sec)
2.119... logprob:  0.347220, 0.085938 (1.396 sec)
2.120... logprob:  0.546873, 0.156250 (1.404 sec)
2.121... logprob:  0.414480, 0.109375 (1.397 sec)
2.122... logprob:  0.517169, 0.148438 (1.448 sec)
2.123... logprob:  0.463559, 0.125000 (1.387 sec)
2.124... logprob:  0.449291, 0.125000 (1.411 sec)
2.125... logprob:  0.500405, 0.140625 (1.398 sec)
2.126... logprob:  0.481650, 0.125000 (1.391 sec)
2.127... logprob:  0.483612, 0.125000 (1.406 sec)
2.128... logprob:  0.422025, 0.109375 (1.421 sec)
2.129... logprob:  0.574436, 0.164062 (1.425 sec)
2.130... logprob:  0.378252, 0.093750 (1.415 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.17310333251953, 10.0]}, 128)
batch 872: ({'logprob': [68.13446807861328, 19.0]}, 128)
batch 873: ({'logprob': [40.02409362792969, 9.0]}, 128)
batch 874: ({'logprob': [45.77659225463867, 11.0]}, 128)
batch 875: ({'logprob': [51.309471130371094, 13.0]}, 128)
batch 876: ({'logprob': [65.31492614746094, 18.0]}, 128)
batch 877: ({'logprob': [45.66773223876953, 11.0]}, 128)
batch 878: ({'logprob': [62.381507873535156, 17.0]}, 128)
batch 879: ({'logprob': [73.33908081054688, 21.0]}, 128)
batch 880: ({'logprob': [51.31219482421875, 13.0]}, 128)
batch 881: ({'logprob': [29.062108993530273, 5.0]}, 128)
batch 882: ({'logprob': [53.80525207519531, 14.0]}, 128)
batch 883: ({'logprob': [62.37874984741211, 17.0]}, 128)
batch 884: ({'logprob': [51.20042419433594, 13.0]}, 128)
batch 885: ({'logprob': [50.9815559387207, 13.0]}, 128)
batch 886: ({'logprob': [62.27108383178711, 17.0]}, 128)

======================Test output======================
logprob:  0.418033, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.978946e-03 [8.800850e-10] 
Layer 'conv1' biases: 3.687102e-09 [5.361420e-12] 
Layer 'conv2' weights[0]: 7.965867e-03 [8.255954e-10] 
Layer 'conv2' biases: 1.000000e+00 [2.439371e-11] 
Layer 'conv3' weights[0]: 7.964220e-03 [8.117418e-10] 
Layer 'conv3' biases: 8.780967e-08 [7.979977e-11] 
Layer 'conv4' weights[0]: 7.996717e-03 [8.133033e-10] 
Layer 'conv4' biases: 1.000000e+00 [4.796490e-10] 
Layer 'conv5' weights[0]: 7.995644e-03 [2.622151e-09] 
Layer 'conv5' biases: 9.999964e-01 [2.530302e-09] 
Layer 'fc6' weights[0]: 7.592483e-03 [8.793520e-10] 
Layer 'fc6' biases: 1.000000e+00 [4.276704e-10] 
Layer 'fc7' weights[0]: 7.817782e-03 [5.190009e-08] 
Layer 'fc7' biases: 9.999269e-01 [2.774567e-08] 
Layer 'fc8' weights[0]: 5.922015e-04 [2.187965e-05] 
Layer 'fc8' biases: 7.458668e-04 [4.627591e-05] 
Train error last 870 batches: 0.447509
-------------------------------------------------------
Not saving because 0.418033 > 0.415987 (2.80: -0.31%)
======================================================= (12.084 sec)
2.131... logprob:  0.483938, 0.132812 (1.414 sec)
2.132... logprob:  0.508629, 0.140625 (1.445 sec)
2.133... logprob:  0.447365, 0.117188 (1.393 sec)
2.134... logprob:  0.412223, 0.101562 (1.398 sec)
2.135... logprob:  0.476367, 0.125000 (1.402 sec)
2.136... logprob:  0.576311, 0.164062 (1.402 sec)
2.137... logprob:  0.467199, 0.125000 (1.392 sec)
2.138... logprob:  0.326026, 0.070312 (1.447 sec)
2.139... logprob:  0.399046, 0.101562 (1.398 sec)
2.140... logprob:  0.561568, 0.164062 (1.414 sec)
2.141... logprob:  0.470437, 0.125000 (1.442 sec)
2.142... logprob:  0.475116, 0.125000 (1.396 sec)
2.143... logprob:  0.306774, 0.062500 (1.423 sec)
2.144... logprob:  0.447608, 0.125000 (1.418 sec)
2.145... logprob:  0.301814, 0.078125 (1.420 sec)
2.146... logprob:  0.489132, 0.132812 (1.411 sec)
2.147... logprob:  0.255472, 0.054688 (1.431 sec)
2.148... logprob:  0.457058, 0.125000 (1.394 sec)
2.149... logprob:  0.456379, 0.117188 (1.428 sec)
2.150... logprob:  0.343939, 0.085938 (1.406 sec)
2.151... logprob:  0.343970, 0.085938 (1.405 sec)
2.152... logprob:  0.788230, 0.234375 (1.403 sec)
2.153... logprob:  0.406310, 0.093750 (1.449 sec)
2.154... logprob:  0.514243, 0.148438 (1.396 sec)
2.155... logprob:  0.425818, 0.117188 (1.411 sec)
2.156... logprob:  0.342801, 0.062500 (1.434 sec)
2.157... logprob:  0.290978, 0.054688 (1.394 sec)
2.158... logprob:  0.457151, 0.125000 (1.402 sec)
2.159... logprob:  0.496727, 0.132812 (1.401 sec)
2.160... logprob:  0.456561, 0.117188 (1.391 sec)
2.161... logprob:  0.330687, 0.078125 (1.401 sec)
2.162... logprob:  0.668263, 0.179688 (1.401 sec)
2.163... logprob:  0.479134, 0.125000 (1.429 sec)
2.164... logprob:  0.465334, 0.125000 (1.417 sec)
2.165... logprob:  0.544338, 0.156250 (1.423 sec)
2.166... logprob:  0.478003, 0.125000 (1.468 sec)
2.167... logprob:  0.402632, 0.085938 (1.432 sec)
2.168... logprob:  0.394678, 0.085938 (1.419 sec)
2.169... logprob:  0.413395, 0.101562 (1.460 sec)
2.170... logprob:  0.460432, 0.125000 (1.399 sec)
2.171... logprob:  0.555931, 0.156250 (1.420 sec)
2.172... logprob:  0.446090, 0.109375 (1.418 sec)
2.173... logprob:  0.453143, 0.117188 (1.419 sec)
2.174... logprob:  0.644019, 0.171875 (1.415 sec)
2.175... logprob:  0.517734, 0.140625 (1.470 sec)
2.176... logprob:  0.478438, 0.132812 (1.414 sec)
2.177... logprob:  0.315614, 0.054688 (1.431 sec)
2.178... logprob:  0.397671, 0.093750 (1.457 sec)
2.179... logprob:  0.403407, 0.101562 (1.413 sec)
2.180... logprob:  0.463710, 0.125000 (1.417 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.82271957397461, 10.0]}, 128)
batch 872: ({'logprob': [67.83574676513672, 19.0]}, 128)
batch 873: ({'logprob': [39.993282318115234, 9.0]}, 128)
batch 874: ({'logprob': [45.57879638671875, 11.0]}, 128)
batch 875: ({'logprob': [51.13349533081055, 13.0]}, 128)
batch 876: ({'logprob': [65.05252075195312, 18.0]}, 128)
batch 877: ({'logprob': [45.564327239990234, 11.0]}, 128)
batch 878: ({'logprob': [62.24940872192383, 17.0]}, 128)
batch 879: ({'logprob': [73.34494018554688, 21.0]}, 128)
batch 880: ({'logprob': [51.1363639831543, 13.0]}, 128)
batch 881: ({'logprob': [28.892864227294922, 5.0]}, 128)
batch 882: ({'logprob': [53.876155853271484, 14.0]}, 128)
batch 883: ({'logprob': [62.24658203125, 17.0]}, 128)
batch 884: ({'logprob': [51.11860275268555, 13.0]}, 128)
batch 885: ({'logprob': [51.08856964111328, 13.0]}, 128)
batch 886: ({'logprob': [62.23324966430664, 17.0]}, 128)

======================Test output======================
logprob:  0.417074, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.978914e-03 [9.708728e-10] 
Layer 'conv1' biases: 3.886816e-09 [1.830775e-11] 
Layer 'conv2' weights[0]: 7.965827e-03 [9.671152e-10] 
Layer 'conv2' biases: 1.000000e+00 [9.793953e-11] 
Layer 'conv3' weights[0]: 7.964184e-03 [9.896035e-10] 
Layer 'conv3' biases: 9.013044e-08 [3.065629e-10] 
Layer 'conv4' weights[0]: 7.996681e-03 [1.033484e-09] 
Layer 'conv4' biases: 1.000000e+00 [2.590150e-09] 
Layer 'conv5' weights[0]: 7.995603e-03 [1.577589e-08] 
Layer 'conv5' biases: 9.999965e-01 [1.653244e-08] 
Layer 'fc6' weights[0]: 7.592443e-03 [2.603037e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.500136e-09] 
Layer 'fc7' weights[0]: 7.816036e-03 [5.751902e-08] 
Layer 'fc7' biases: 9.999232e-01 [3.490376e-08] 
Layer 'fc8' weights[0]: 6.045714e-04 [2.930085e-05] 
Layer 'fc8' biases: 8.109649e-04 [6.473785e-05] 
Train error last 870 batches: 0.447066
-------------------------------------------------------
Not saving because 0.417074 > 0.415987 (2.80: -0.31%)
======================================================= (12.077 sec)
2.181... logprob:  0.551729, 0.156250 (1.422 sec)
2.182... logprob:  0.378576, 0.093750 (1.419 sec)
2.183... logprob:  0.421866, 0.109375 (1.416 sec)
2.184... logprob:  0.490722, 0.132812 (1.420 sec)
2.185... logprob:  0.285370, 0.062500 (1.391 sec)
2.186... logprob:  0.373187, 0.093750 (1.404 sec)
2.187... logprob:  0.536800, 0.148438 (1.399 sec)
2.188... logprob:  0.460003, 0.125000 (1.401 sec)
2.189... logprob:  0.440467, 0.117188 (1.385 sec)
2.190... logprob:  0.380945, 0.093750 (1.443 sec)
2.191... logprob:  0.483865, 0.132812 (1.408 sec)
2.192... logprob:  0.507088, 0.148438 (1.416 sec)
2.193... logprob:  0.332791, 0.070312 (1.419 sec)
2.194... logprob:  0.413379, 0.109375 (1.419 sec)
2.195... logprob:  0.287356, 0.062500 (1.400 sec)
2.196... logprob:  0.405446, 0.109375 (1.395 sec)
2.197... logprob:  0.486871, 0.132812 (1.397 sec)
2.198... logprob:  0.357162, 0.085938 (1.408 sec)
2.199... logprob:  0.447216, 0.117188 (1.391 sec)
2.200... logprob:  0.451986, 0.117188 (1.471 sec)
2.201... logprob:  0.441297, 0.117188 (1.412 sec)
2.202... logprob:  0.550451, 0.148438 (1.403 sec)
2.203... logprob:  0.424347, 0.109375 (1.445 sec)
2.204... logprob:  0.501211, 0.140625 (1.388 sec)
2.205... logprob:  0.358007, 0.078125 (1.403 sec)
2.206... logprob:  0.377635, 0.093750 (1.405 sec)
2.207... logprob:  0.387806, 0.093750 (1.393 sec)
2.208... logprob:  0.495937, 0.140625 (1.397 sec)
2.209... logprob:  0.330215, 0.078125 (1.422 sec)
2.210... logprob:  0.608893, 0.171875 (1.416 sec)
2.211... logprob:  0.495140, 0.132812 (1.418 sec)
2.212... logprob:  0.534806, 0.148438 (1.411 sec)
2.213... logprob:  0.512375, 0.140625 (1.461 sec)
2.214... logprob:  0.460421, 0.125000 (1.426 sec)
2.215... logprob:  0.407124, 0.101562 (1.420 sec)
2.216... logprob:  0.513406, 0.140625 (1.467 sec)
2.217... logprob:  0.341774, 0.070312 (1.406 sec)
2.218... logprob:  0.463480, 0.125000 (1.422 sec)
2.219... logprob:  0.503868, 0.140625 (1.418 sec)
2.220... logprob:  0.418809, 0.109375 (1.422 sec)
2.221... logprob:  0.397798, 0.101562 (1.403 sec)
2.222... logprob:  0.583403, 0.164062 (1.454 sec)
2.223... logprob:  0.584054, 0.164062 (1.420 sec)
2.224... logprob:  0.402696, 0.101562 (1.434 sec)
2.225... logprob:  0.393146, 0.101562 (1.451 sec)
2.226... logprob:  0.428371, 0.109375 (1.425 sec)
2.227... logprob:  0.452351, 0.125000 (1.413 sec)
2.228... logprob:  0.420845, 0.109375 (1.420 sec)
2.229... logprob:  0.492699, 0.132812 (1.419 sec)
2.230... logprob:  0.459605, 0.125000 (1.435 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.81621551513672, 10.0]}, 128)
batch 872: ({'logprob': [66.19205474853516, 19.0]}, 128)
batch 873: ({'logprob': [41.120994567871094, 9.0]}, 128)
batch 874: ({'logprob': [45.43323516845703, 11.0]}, 128)
batch 875: ({'logprob': [50.91312789916992, 13.0]}, 128)
batch 876: ({'logprob': [63.745548248291016, 18.0]}, 128)
batch 877: ({'logprob': [46.017913818359375, 11.0]}, 128)
batch 878: ({'logprob': [61.87873077392578, 17.0]}, 128)
batch 879: ({'logprob': [73.42264556884766, 21.0]}, 128)
batch 880: ({'logprob': [50.91576385498047, 13.0]}, 128)
batch 881: ({'logprob': [29.571840286254883, 5.0]}, 128)
batch 882: ({'logprob': [55.11542892456055, 14.0]}, 128)
batch 883: ({'logprob': [61.8759651184082, 17.0]}, 128)
batch 884: ({'logprob': [51.49673843383789, 13.0]}, 128)
batch 885: ({'logprob': [52.66465759277344, 13.0]}, 128)
batch 886: ({'logprob': [62.461326599121094, 17.0]}, 128)

======================Test output======================
logprob:  0.417306, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.978880e-03 [9.155359e-10] 
Layer 'conv1' biases: 4.090937e-09 [9.268253e-12] 
Layer 'conv2' weights[0]: 7.965788e-03 [8.588325e-10] 
Layer 'conv2' biases: 1.000000e+00 [3.918197e-11] 
Layer 'conv3' weights[0]: 7.964139e-03 [8.399645e-10] 
Layer 'conv3' biases: 9.186818e-08 [1.255625e-10] 
Layer 'conv4' weights[0]: 7.996641e-03 [8.416869e-10] 
Layer 'conv4' biases: 1.000000e+00 [7.961986e-10] 
Layer 'conv5' weights[0]: 7.995565e-03 [4.247312e-09] 
Layer 'conv5' biases: 9.999966e-01 [4.295130e-09] 
Layer 'fc6' weights[0]: 7.592396e-03 [1.034136e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.685615e-10] 
Layer 'fc7' weights[0]: 7.814180e-03 [4.138175e-08] 
Layer 'fc7' biases: 9.999200e-01 [1.080736e-08] 
Layer 'fc8' weights[0]: 6.133866e-04 [9.560405e-06] 
Layer 'fc8' biases: 8.518346e-04 [2.200713e-05] 
Train error last 870 batches: 0.446057
-------------------------------------------------------
Not saving because 0.417306 > 0.415987 (2.80: -0.31%)
======================================================= (12.091 sec)
2.231... logprob:  0.450627, 0.125000 (1.415 sec)
2.232... logprob:  0.494275, 0.140625 (1.466 sec)
2.233... logprob:  0.459178, 0.132812 (1.442 sec)
2.234... logprob:  0.564096, 0.164062 (1.419 sec)
2.235... logprob:  0.485719, 0.132812 (1.469 sec)
2.236... logprob:  0.439252, 0.109375 (1.401 sec)
2.237... logprob:  0.353029, 0.078125 (1.428 sec)
2.238... logprob:  0.397098, 0.093750 (1.417 sec)
2.239... logprob:  0.480333, 0.132812 (1.420 sec)
2.240... logprob:  0.492660, 0.132812 (1.406 sec)
2.241... logprob:  0.499379, 0.132812 (1.456 sec)
2.242... logprob:  0.330153, 0.078125 (1.438 sec)
2.243... logprob:  0.376312, 0.093750 (1.440 sec)
2.244... logprob:  0.307491, 0.070312 (1.449 sec)
2.245... logprob:  0.491139, 0.132812 (1.426 sec)
2.246... logprob:  0.431062, 0.109375 (1.425 sec)
2.247... logprob:  0.354595, 0.085938 (1.415 sec)
2.248... logprob:  0.314468, 0.070312 (1.421 sec)
2.249... logprob:  0.573282, 0.156250 (1.431 sec)
2.250... logprob:  0.574131, 0.164062 (1.408 sec)
2.251... logprob:  0.361813, 0.085938 (1.457 sec)
2.252... logprob:  0.367310, 0.085938 (1.420 sec)
2.253... logprob:  0.381814, 0.093750 (1.420 sec)
2.254... logprob:  0.442412, 0.117188 (1.469 sec)
2.255... logprob:  0.355124, 0.085938 (1.402 sec)
2.256... logprob:  0.380297, 0.093750 (1.423 sec)
2.257... logprob:  0.331263, 0.078125 (1.421 sec)
2.258... logprob:  0.414290, 0.109375 (1.419 sec)
2.259... logprob:  0.449820, 0.117188 (1.407 sec)
2.260... logprob:  0.304586, 0.070312 (1.459 sec)
2.261... logprob:  0.384094, 0.101562 (1.426 sec)
2.262... logprob:  0.511839, 0.148438 (1.432 sec)
2.263... logprob:  0.449900, 0.109375 (1.449 sec)
2.264... logprob:  0.382817, 0.093750 (1.426 sec)
2.265... logprob:  0.438323, 0.117188 (1.413 sec)
2.266... logprob:  0.439289, 0.117188 (1.416 sec)
2.267... logprob:  0.439581, 0.109375 (1.422 sec)
2.268... logprob:  0.455048, 0.125000 (1.421 sec)
2.269... logprob:  0.563670, 0.164062 (1.410 sec)
2.270... logprob:  0.537944, 0.156250 (1.458 sec)
2.271... logprob:  0.452366, 0.117188 (1.431 sec)
2.272... logprob:  0.388424, 0.093750 (1.415 sec)
2.273... logprob:  0.500692, 0.140625 (1.480 sec)
2.274... logprob:  0.544160, 0.156250 (1.400 sec)
2.275... logprob:  0.483955, 0.132812 (1.460 sec)
2.276... logprob:  0.384055, 0.093750 (1.418 sec)
2.277... logprob:  0.423351, 0.109375 (1.424 sec)
2.278... logprob:  0.322978, 0.070312 (1.425 sec)
2.279... logprob:  0.312064, 0.070312 (1.464 sec)
2.280... logprob:  0.188310, 0.031250 (1.402 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.82562255859375, 10.0]}, 128)
batch 872: ({'logprob': [73.0057601928711, 19.0]}, 128)
batch 873: ({'logprob': [38.76930236816406, 9.0]}, 128)
batch 874: ({'logprob': [45.86090087890625, 11.0]}, 128)
batch 875: ({'logprob': [52.5418586730957, 13.0]}, 128)
batch 876: ({'logprob': [69.56490325927734, 18.0]}, 128)
batch 877: ({'logprob': [45.6560173034668, 11.0]}, 128)
batch 878: ({'logprob': [65.91221618652344, 17.0]}, 128)
batch 879: ({'logprob': [79.07183837890625, 21.0]}, 128)
batch 880: ({'logprob': [52.54537582397461, 13.0]}, 128)
batch 881: ({'logprob': [25.6033992767334, 5.0]}, 128)
batch 882: ({'logprob': [55.37474822998047, 14.0]}, 128)
batch 883: ({'logprob': [65.90934753417969, 17.0]}, 128)
batch 884: ({'logprob': [52.33767318725586, 13.0]}, 128)
batch 885: ({'logprob': [51.92877960205078, 13.0]}, 128)
batch 886: ({'logprob': [65.70682525634766, 17.0]}, 128)

======================Test output======================
logprob:  0.430964, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.978839e-03 [1.263553e-09] 
Layer 'conv1' biases: 4.191688e-09 [3.416007e-11] 
Layer 'conv2' weights[0]: 7.965753e-03 [1.264496e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.053222e-10] 
Layer 'conv3' weights[0]: 7.964108e-03 [1.366243e-09] 
Layer 'conv3' biases: 9.252212e-08 [6.500827e-10] 
Layer 'conv4' weights[0]: 7.996601e-03 [1.484479e-09] 
Layer 'conv4' biases: 1.000000e+00 [6.200249e-09] 
Layer 'conv5' weights[0]: 7.995529e-03 [3.890344e-08] 
Layer 'conv5' biases: 9.999966e-01 [4.123663e-08] 
Layer 'fc6' weights[0]: 7.592357e-03 [5.859086e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.921014e-09] 
Layer 'fc7' weights[0]: 7.812356e-03 [1.656482e-07] 
Layer 'fc7' biases: 9.999183e-01 [1.526939e-07] 
Layer 'fc8' weights[0]: 6.954888e-04 [4.634772e-05] 
Layer 'fc8' biases: 1.108603e-03 [1.074453e-04] 
Train error last 870 batches: 0.444760
-------------------------------------------------------
Not saving because 0.430964 > 0.415987 (2.80: -0.31%)
======================================================= (12.045 sec)
2.281... logprob:  0.437435, 0.109375 (1.433 sec)
2.282... logprob:  0.446516, 0.109375 (1.421 sec)
2.283... logprob:  0.417636, 0.101562 (1.415 sec)
2.284... logprob:  0.412778, 0.101562 (1.414 sec)
2.285... logprob:  0.465241, 0.117188 (1.438 sec)
2.286... logprob:  0.543817, 0.140625 (1.436 sec)
2.287... logprob:  0.345369, 0.085938 (1.433 sec)
2.288... logprob:  0.346380, 0.078125 (1.436 sec)
2.289... logprob:  0.438831, 0.117188 (1.442 sec)
2.290... logprob:  0.473635, 0.132812 (1.415 sec)
2.291... logprob:  0.435834, 0.117188 (1.417 sec)
2.292... logprob:  0.554590, 0.156250 (1.418 sec)
2.293... logprob:  0.421919, 0.117188 (1.421 sec)
2.294... logprob:  0.367614, 0.085938 (1.399 sec)
2.295... logprob:  0.336016, 0.078125 (1.463 sec)
2.296... logprob:  0.350107, 0.085938 (1.417 sec)
2.297... logprob:  0.395353, 0.101562 (1.423 sec)
2.298... logprob:  0.469265, 0.125000 (1.468 sec)
2.299... logprob:  0.331340, 0.078125 (1.403 sec)
2.300... logprob:  0.412224, 0.101562 (1.426 sec)
2.301... logprob:  0.403206, 0.101562 (1.415 sec)
2.302... logprob:  0.633894, 0.179688 (1.418 sec)
2.303... logprob:  0.463004, 0.125000 (1.414 sec)
2.304... logprob:  0.459671, 0.125000 (1.437 sec)
2.305... logprob:  0.459816, 0.125000 (1.443 sec)
2.306... logprob:  0.459164, 0.117188 (1.432 sec)
2.307... logprob:  0.447074, 0.109375 (1.437 sec)
2.308... logprob:  0.396537, 0.093750 (1.472 sec)
2.309... logprob:  0.451276, 0.125000 (1.416 sec)
2.310... logprob:  0.473185, 0.125000 (1.428 sec)
2.311... logprob:  0.510754, 0.140625 (1.432 sec)
2.312... logprob:  0.490532, 0.132812 (1.427 sec)
2.313... logprob:  0.465899, 0.125000 (1.422 sec)
2.314... logprob:  0.452527, 0.117188 (1.467 sec)
2.315... logprob:  0.305326, 0.070312 (1.432 sec)
2.316... logprob:  0.467316, 0.125000 (1.429 sec)
2.317... logprob:  0.353381, 0.085938 (1.475 sec)
2.318... logprob:  0.460089, 0.125000 (1.412 sec)
2.319... logprob:  0.433724, 0.117188 (1.420 sec)
2.320... logprob:  0.415810, 0.109375 (1.431 sec)
2.321... logprob:  0.354027, 0.085938 (1.423 sec)
2.322... logprob:  0.389709, 0.101562 (1.413 sec)
2.323... logprob:  0.416738, 0.109375 (1.477 sec)
2.324... logprob:  0.494290, 0.140625 (1.426 sec)
2.325... logprob:  0.353591, 0.085938 (1.439 sec)
2.326... logprob:  0.552617, 0.148438 (1.461 sec)
2.327... logprob:  0.543100, 0.164062 (1.426 sec)
2.328... logprob:  0.576733, 0.156250 (1.424 sec)
2.329... logprob:  0.414397, 0.101562 (1.428 sec)
2.330... logprob:  0.392659, 0.101562 (1.420 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.943817138671875, 10.0]}, 128)
batch 872: ({'logprob': [65.6426010131836, 19.0]}, 128)
batch 873: ({'logprob': [43.4673957824707, 9.0]}, 128)
batch 874: ({'logprob': [46.840599060058594, 11.0]}, 128)
batch 875: ({'logprob': [51.98130798339844, 13.0]}, 128)
batch 876: ({'logprob': [63.51536178588867, 18.0]}, 128)
batch 877: ({'logprob': [47.72530746459961, 11.0]}, 128)
batch 878: ({'logprob': [62.26803207397461, 17.0]}, 128)
batch 879: ({'logprob': [73.4322280883789, 21.0]}, 128)
batch 880: ({'logprob': [51.983863830566406, 13.0]}, 128)
batch 881: ({'logprob': [32.29753112792969, 5.0]}, 128)
batch 882: ({'logprob': [56.7625732421875, 14.0]}, 128)
batch 883: ({'logprob': [62.265167236328125, 17.0]}, 128)
batch 884: ({'logprob': [52.863834381103516, 13.0]}, 128)
batch 885: ({'logprob': [54.63100051879883, 13.0]}, 128)
batch 886: ({'logprob': [63.14975357055664, 17.0]}, 128)

======================Test output======================
logprob:  0.425669, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.978801e-03 [1.052772e-09] 
Layer 'conv1' biases: 4.524633e-09 [1.900785e-11] 
Layer 'conv2' weights[0]: 7.965709e-03 [1.009523e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.010295e-10] 
Layer 'conv3' weights[0]: 7.964068e-03 [1.007273e-09] 
Layer 'conv3' biases: 9.527823e-08 [3.120195e-10] 
Layer 'conv4' weights[0]: 7.996561e-03 [1.033127e-09] 
Layer 'conv4' biases: 1.000000e+00 [2.614560e-09] 
Layer 'conv5' weights[0]: 7.995507e-03 [1.510250e-08] 
Layer 'conv5' biases: 9.999970e-01 [1.589645e-08] 
Layer 'fc6' weights[0]: 7.592326e-03 [2.346797e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.200755e-09] 
Layer 'fc7' weights[0]: 7.810410e-03 [6.459015e-08] 
Layer 'fc7' biases: 9.999137e-01 [4.476841e-08] 
Layer 'fc8' weights[0]: 6.182831e-04 [1.093785e-05] 
Layer 'fc8' biases: 8.940241e-04 [2.659598e-05] 
Train error last 870 batches: 0.443467
-------------------------------------------------------
Not saving because 0.425669 > 0.415987 (2.80: -0.31%)
======================================================= (12.050 sec)
2.331... logprob:  0.359074, 0.085938 (1.432 sec)
2.332... logprob:  0.484580, 0.132812 (1.453 sec)
2.333... logprob:  0.334262, 0.085938 (1.439 sec)
2.334... logprob:  0.577030, 0.171875 (1.444 sec)
2.335... logprob:  0.351527, 0.085938 (1.441 sec)
2.336... logprob:  0.447341, 0.125000 (1.458 sec)
2.337... logprob:  0.579127, 0.164062 (1.415 sec)
2.338... logprob:  0.449267, 0.125000 (1.427 sec)
2.339... logprob:  0.491100, 0.132812 (1.423 sec)
2.340... logprob:  0.444567, 0.117188 (1.440 sec)
2.341... logprob:  0.530888, 0.148438 (1.416 sec)
2.342... logprob:  0.435757, 0.109375 (1.478 sec)
2.343... logprob:  0.436847, 0.109375 (1.433 sec)
2.344... logprob:  0.450213, 0.125000 (1.479 sec)
2.345... logprob:  0.484499, 0.132812 (1.443 sec)
2.346... logprob:  0.438857, 0.117188 (1.436 sec)
2.347... logprob:  0.358077, 0.085938 (1.487 sec)
2.348... logprob:  0.398163, 0.101562 (1.435 sec)
2.349... logprob:  0.514737, 0.140625 (1.436 sec)
2.350... logprob:  0.352989, 0.085938 (1.433 sec)
2.351... logprob:  0.515466, 0.140625 (1.435 sec)
2.352... logprob:  0.375580, 0.093750 (1.435 sec)
2.353... logprob:  0.528391, 0.148438 (1.491 sec)
2.354... logprob:  0.670320, 0.203125 (1.428 sec)
2.355... logprob:  0.369587, 0.085938 (1.446 sec)
2.356... logprob:  0.481896, 0.132812 (1.479 sec)
2.357... logprob:  0.371949, 0.085938 (1.430 sec)
2.358... logprob:  0.359799, 0.070312 (1.442 sec)
2.359... logprob:  0.547555, 0.164062 (1.432 sec)
2.360... logprob:  0.449422, 0.117188 (1.432 sec)
2.361... logprob:  0.416952, 0.101562 (1.433 sec)
2.362... logprob:  0.422931, 0.117188 (1.483 sec)
2.363... logprob:  0.503218, 0.132812 (1.438 sec)
2.364... logprob:  0.490826, 0.125000 (1.460 sec)
2.365... logprob:  0.428056, 0.109375 (1.463 sec)
2.366... logprob:  0.410731, 0.109375 (1.449 sec)
2.367... logprob:  0.321726, 0.078125 (1.437 sec)
2.368... logprob:  0.597628, 0.171875 (1.430 sec)
2.369... logprob:  0.382746, 0.093750 (1.431 sec)
2.370... logprob:  0.385327, 0.093750 (1.439 sec)
2.371... logprob:  0.404133, 0.101562 (1.458 sec)
2.372... logprob:  0.538516, 0.156250 (1.462 sec)
2.373... logprob:  0.462652, 0.125000 (1.450 sec)
2.374... logprob:  0.522834, 0.148438 (1.455 sec)
2.375... logprob:  0.399726, 0.101562 (1.462 sec)
2.376... logprob:  0.378977, 0.093750 (1.441 sec)
2.377... logprob:  0.296845, 0.062500 (1.427 sec)
2.378... logprob:  0.456628, 0.125000 (1.432 sec)
2.379... logprob:  0.421356, 0.109375 (1.438 sec)
2.380... logprob:  0.624512, 0.179688 (1.444 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.925437927246094, 10.0]}, 128)
batch 872: ({'logprob': [67.47188568115234, 19.0]}, 128)
batch 873: ({'logprob': [40.007179260253906, 9.0]}, 128)
batch 874: ({'logprob': [44.791629791259766, 11.0]}, 128)
batch 875: ({'logprob': [50.7537841796875, 13.0]}, 128)
batch 876: ({'logprob': [64.78694152832031, 18.0]}, 128)
batch 877: ({'logprob': [45.38102340698242, 11.0]}, 128)
batch 878: ({'logprob': [62.685211181640625, 17.0]}, 128)
batch 879: ({'logprob': [75.19912719726562, 21.0]}, 128)
batch 880: ({'logprob': [50.75695037841797, 13.0]}, 128)
batch 881: ({'logprob': [27.48654556274414, 5.0]}, 128)
batch 882: ({'logprob': [55.21053695678711, 14.0]}, 128)
batch 883: ({'logprob': [62.682369232177734, 17.0]}, 128)
batch 884: ({'logprob': [51.34239196777344, 13.0]}, 128)
batch 885: ({'logprob': [52.52065658569336, 13.0]}, 128)
batch 886: ({'logprob': [63.27289581298828, 17.0]}, 128)

======================Test output======================
logprob:  0.417615, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.978762e-03 [1.511626e-09] 
Layer 'conv1' biases: 4.689689e-09 [5.223097e-11] 
Layer 'conv2' weights[0]: 7.965669e-03 [1.419232e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.726867e-10] 
Layer 'conv3' weights[0]: 7.964029e-03 [1.536321e-09] 
Layer 'conv3' biases: 9.677857e-08 [8.428153e-10] 
Layer 'conv4' weights[0]: 7.996524e-03 [1.603986e-09] 
Layer 'conv4' biases: 1.000000e+00 [7.525604e-09] 
Layer 'conv5' weights[0]: 7.995469e-03 [4.727769e-08] 
Layer 'conv5' biases: 9.999972e-01 [5.015869e-08] 
Layer 'fc6' weights[0]: 7.592286e-03 [6.626317e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.716316e-09] 
Layer 'fc7' weights[0]: 7.808467e-03 [8.957150e-08] 
Layer 'fc7' biases: 9.999117e-01 [7.303261e-08] 
Layer 'fc8' weights[0]: 6.763240e-04 [2.016125e-05] 
Layer 'fc8' biases: 1.114606e-03 [4.961981e-05] 
Train error last 870 batches: 0.442666
-------------------------------------------------------
Not saving because 0.417615 > 0.415987 (2.80: -0.31%)
======================================================= (12.047 sec)
2.381... logprob:  0.468712, 0.125000 (1.477 sec)
2.382... logprob:  0.536625, 0.148438 (1.451 sec)
2.383... logprob:  0.362835, 0.085938 (1.441 sec)
2.384... logprob:  0.519047, 0.148438 (1.482 sec)
2.385... logprob:  0.523899, 0.148438 (1.435 sec)
2.386... logprob:  0.577959, 0.171875 (1.432 sec)
2.387... logprob:  0.432157, 0.117188 (1.433 sec)
2.388... logprob:  0.524909, 0.148438 (1.440 sec)
2.389... logprob:  0.434789, 0.109375 (1.429 sec)
2.390... logprob:  0.419820, 0.109375 (1.482 sec)
2.391... logprob:  0.306957, 0.070312 (1.443 sec)
2.392... logprob:  0.437343, 0.117188 (1.439 sec)
2.393... logprob:  0.360327, 0.093750 (1.487 sec)
2.394... logprob:  0.331236, 0.078125 (1.435 sec)
2.395... logprob:  0.323670, 0.078125 (1.433 sec)
2.396... logprob:  0.230431, 0.046875 (1.439 sec)
2.397... logprob:  0.523989, 0.132812 (1.431 sec)
2.398... logprob:  0.501896, 0.125000 (1.437 sec)
2.399... logprob:  0.446827, 0.117188 (1.485 sec)
2.400... logprob:  0.543374, 0.148438 (1.437 sec)
2.401... logprob:  0.457671, 0.125000 (1.444 sec)
2.402... logprob:  0.469778, 0.125000 (1.482 sec)
2.403... logprob:  0.461898, 0.125000 (1.432 sec)
2.404... logprob:  0.494119, 0.125000 (1.432 sec)
2.405... logprob:  0.534586, 0.156250 (1.435 sec)
2.406... logprob:  0.399973, 0.085938 (1.431 sec)
2.407... logprob:  0.492437, 0.140625 (1.435 sec)
2.408... logprob:  0.343856, 0.078125 (1.485 sec)
2.409... logprob:  0.396404, 0.101562 (1.439 sec)
2.410... logprob:  0.612806, 0.171875 (1.454 sec)
2.411... logprob:  0.398651, 0.101562 (1.475 sec)
2.412... logprob:  0.576186, 0.156250 (1.439 sec)
2.413... logprob:  0.570961, 0.156250 (1.439 sec)
2.414... logprob:  0.466812, 0.125000 (1.431 sec)
2.415... logprob:  0.397585, 0.101562 (1.428 sec)
2.416... logprob:  0.423095, 0.109375 (1.450 sec)
2.417... logprob:  0.394844, 0.093750 (1.464 sec)
2.418... logprob:  0.388181, 0.093750 (1.449 sec)
2.419... logprob:  0.410040, 0.101562 (1.451 sec)
2.420... logprob:  0.360442, 0.085938 (1.453 sec)
2.421... logprob:  0.395576, 0.101562 (1.453 sec)
2.422... logprob:  0.533664, 0.148438 (1.440 sec)
2.423... logprob:  0.422130, 0.109375 (1.428 sec)
2.424... logprob:  0.324762, 0.078125 (1.432 sec)
2.425... logprob:  0.304509, 0.070312 (1.436 sec)
2.426... logprob:  0.452291, 0.117188 (1.440 sec)
2.427... logprob:  0.556062, 0.156250 (1.461 sec)
2.428... logprob:  0.593274, 0.171875 (1.451 sec)
2.429... logprob:  0.430028, 0.109375 (1.448 sec)
2.430... logprob:  0.313851, 0.070312 (1.474 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.02532958984375, 10.0]}, 128)
batch 872: ({'logprob': [65.6820068359375, 19.0]}, 128)
batch 873: ({'logprob': [43.8255729675293, 9.0]}, 128)
batch 874: ({'logprob': [47.040069580078125, 11.0]}, 128)
batch 875: ({'logprob': [52.18006896972656, 13.0]}, 128)
batch 876: ({'logprob': [63.59457015991211, 18.0]}, 128)
batch 877: ({'logprob': [48.0037727355957, 11.0]}, 128)
batch 878: ({'logprob': [62.46534729003906, 17.0]}, 128)
batch 879: ({'logprob': [73.7064208984375, 21.0]}, 128)
batch 880: ({'logprob': [52.18268585205078, 13.0]}, 128)
batch 881: ({'logprob': [32.57794189453125, 5.0]}, 128)
batch 882: ({'logprob': [57.157798767089844, 14.0]}, 128)
batch 883: ({'logprob': [62.462547302246094, 17.0]}, 128)
batch 884: ({'logprob': [53.14085388183594, 13.0]}, 128)
batch 885: ({'logprob': [55.065608978271484, 13.0]}, 128)
batch 886: ({'logprob': [63.42548751831055, 17.0]}, 128)

======================Test output======================
logprob:  0.427508, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.978724e-03 [9.415605e-10] 
Layer 'conv1' biases: 4.937236e-09 [1.685184e-11] 
Layer 'conv2' weights[0]: 7.965628e-03 [8.911384e-10] 
Layer 'conv2' biases: 1.000000e+00 [8.402594e-11] 
Layer 'conv3' weights[0]: 7.963989e-03 [9.186677e-10] 
Layer 'conv3' biases: 9.938191e-08 [2.534935e-10] 
Layer 'conv4' weights[0]: 7.996486e-03 [9.547071e-10] 
Layer 'conv4' biases: 1.000000e+00 [2.214943e-09] 
Layer 'conv5' weights[0]: 7.995425e-03 [1.386576e-08] 
Layer 'conv5' biases: 9.999974e-01 [1.471769e-08] 
Layer 'fc6' weights[0]: 7.592247e-03 [2.017735e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.858788e-09] 
Layer 'fc7' weights[0]: 7.806507e-03 [1.194459e-07] 
Layer 'fc7' biases: 9.999074e-01 [1.041834e-07] 
Layer 'fc8' weights[0]: 6.464073e-04 [1.497067e-05] 
Layer 'fc8' biases: 1.046594e-03 [3.797133e-05] 
Train error last 870 batches: 0.442218
-------------------------------------------------------
Not saving because 0.427508 > 0.415987 (2.80: -0.31%)
======================================================= (11.995 sec)
2.431... logprob:  0.584683, 0.171875 (1.437 sec)
2.432... logprob:  0.421160, 0.093750 (1.428 sec)
2.433... logprob:  0.350485, 0.078125 (1.433 sec)
2.434... logprob:  0.531687, 0.148438 (1.441 sec)
2.435... logprob:  0.527445, 0.156250 (1.434 sec)
2.436... logprob:  0.379526, 0.093750 (1.476 sec)
2.437... logprob:  0.503752, 0.140625 (1.449 sec)
2.438... logprob:  0.555291, 0.156250 (1.434 sec)
2.439... logprob:  0.371624, 0.093750 (1.485 sec)
2.440... logprob:  0.438511, 0.117188 (1.431 sec)
2.441... logprob:  0.464790, 0.125000 (1.431 sec)
2.442... logprob:  0.374844, 0.093750 (1.440 sec)
2.443... logprob:  0.502490, 0.140625 (1.431 sec)
2.444... logprob:  0.373157, 0.093750 (1.438 sec)
2.445... logprob:  0.358017, 0.085938 (1.483 sec)
2.446... logprob:  0.397092, 0.101562 (1.441 sec)
2.447... logprob:  0.573342, 0.164062 (1.439 sec)
2.448... logprob:  0.332420, 0.078125 (1.482 sec)
2.449... logprob:  0.400217, 0.101562 (1.452 sec)
2.450... logprob:  0.241233, 0.046875 (1.437 sec)
2.451... logprob:  0.452244, 0.125000 (1.435 sec)
2.452... logprob:  0.457954, 0.117188 (1.434 sec)
2.453... logprob:  0.452979, 0.125000 (1.431 sec)
2.454... logprob:  0.486157, 0.132812 (1.480 sec)
2.455... logprob:  0.497607, 0.140625 (1.436 sec)
2.456... logprob:  0.466644, 0.125000 (1.454 sec)
2.457... logprob:  0.384219, 0.093750 (1.479 sec)
2.458... logprob:  0.363784, 0.085938 (1.438 sec)
2.459... logprob:  0.514411, 0.140625 (1.440 sec)
2.460... logprob:  0.291206, 0.054688 (1.437 sec)
2.461... logprob:  0.459763, 0.125000 (1.422 sec)
2.462... logprob:  0.473106, 0.125000 (1.432 sec)
2.463... logprob:  0.420455, 0.109375 (1.475 sec)
2.464... logprob:  0.489049, 0.132812 (1.447 sec)
2.465... logprob:  0.421072, 0.109375 (1.457 sec)
2.466... logprob:  0.307652, 0.070312 (1.458 sec)
2.467... logprob:  0.421408, 0.109375 (1.449 sec)
2.468... logprob:  0.399050, 0.101562 (1.438 sec)
2.469... logprob:  0.330596, 0.078125 (1.430 sec)
2.470... logprob:  0.398907, 0.101562 (1.425 sec)
2.471... logprob:  0.536208, 0.148438 (1.435 sec)
2.472... logprob:  0.418008, 0.109375 (1.451 sec)
2.473... logprob:  0.376164, 0.093750 (1.465 sec)
2.474... logprob:  0.463131, 0.125000 (1.454 sec)
2.475... logprob:  0.499400, 0.140625 (1.448 sec)
2.476... logprob:  0.504199, 0.140625 (1.469 sec)
2.477... logprob:  0.349317, 0.078125 (1.443 sec)
2.478... logprob:  0.464730, 0.125000 (1.424 sec)
2.479... logprob:  0.316998, 0.070312 (1.436 sec)
2.480... logprob:  0.445226, 0.117188 (1.435 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.54852294921875, 10.0]}, 128)
batch 872: ({'logprob': [66.48629760742188, 19.0]}, 128)
batch 873: ({'logprob': [40.708763122558594, 9.0]}, 128)
batch 874: ({'logprob': [45.190547943115234, 11.0]}, 128)
batch 875: ({'logprob': [50.79195022583008, 13.0]}, 128)
batch 876: ({'logprob': [63.96717834472656, 18.0]}, 128)
batch 877: ({'logprob': [45.75107192993164, 11.0]}, 128)
batch 878: ({'logprob': [62.00171661376953, 17.0]}, 128)
batch 879: ({'logprob': [73.76445770263672, 21.0]}, 128)
batch 880: ({'logprob': [50.79510498046875, 13.0]}, 128)
batch 881: ({'logprob': [28.93877410888672, 5.0]}, 128)
batch 882: ({'logprob': [54.99484634399414, 14.0]}, 128)
batch 883: ({'logprob': [61.99890899658203, 17.0]}, 128)
batch 884: ({'logprob': [51.35062026977539, 13.0]}, 128)
batch 885: ({'logprob': [52.470333099365234, 13.0]}, 128)
batch 886: ({'logprob': [62.55964279174805, 17.0]}, 128)

======================Test output======================
logprob:  0.416660, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.978680e-03 [1.056038e-09] 
Layer 'conv1' biases: 5.013089e-09 [2.258953e-11] 
Layer 'conv2' weights[0]: 7.965589e-03 [1.040322e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.344811e-10] 
Layer 'conv3' weights[0]: 7.963949e-03 [1.080808e-09] 
Layer 'conv3' biases: 1.000984e-07 [4.186245e-10] 
Layer 'conv4' weights[0]: 7.996449e-03 [1.152737e-09] 
Layer 'conv4' biases: 1.000000e+00 [3.794286e-09] 
Layer 'conv5' weights[0]: 7.995384e-03 [2.409443e-08] 
Layer 'conv5' biases: 9.999974e-01 [2.564031e-08] 
Layer 'fc6' weights[0]: 7.592214e-03 [3.236036e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.194776e-09] 
Layer 'fc7' weights[0]: 7.804506e-03 [9.204894e-08] 
Layer 'fc7' biases: 9.999059e-01 [7.515679e-08] 
Layer 'fc8' weights[0]: 6.795901e-04 [2.052076e-05] 
Layer 'fc8' biases: 1.208411e-03 [5.490192e-05] 
Train error last 870 batches: 0.441578
-------------------------------------------------------
Not saving because 0.416660 > 0.415987 (2.80: -0.31%)
======================================================= (12.058 sec)
2.481... logprob:  0.547857, 0.156250 (1.442 sec)
2.482... logprob:  0.445099, 0.117188 (1.483 sec)
2.483... logprob:  0.506109, 0.140625 (1.449 sec)
2.484... logprob:  0.488841, 0.132812 (1.434 sec)
2.485... logprob:  0.406095, 0.109375 (1.483 sec)
2.486... logprob:  0.358640, 0.085938 (1.431 sec)
2.487... logprob:  0.525452, 0.148438 (1.433 sec)
2.488... logprob:  0.424635, 0.109375 (1.436 sec)
2.489... logprob:  0.414553, 0.109375 (1.438 sec)
2.490... logprob:  0.440327, 0.117188 (1.432 sec)
2.491... logprob:  0.311206, 0.070312 (1.482 sec)
2.492... logprob:  0.460226, 0.125000 (1.443 sec)
2.493... logprob:  0.525555, 0.148438 (1.438 sec)
2.494... logprob:  0.450453, 0.125000 (1.487 sec)
2.495... logprob:  0.380907, 0.093750 (1.432 sec)
2.496... logprob:  0.552073, 0.156250 (1.438 sec)
2.497... logprob:  0.468661, 0.125000 (1.438 sec)
2.498... logprob:  0.473828, 0.132812 (1.429 sec)
2.499... logprob:  0.455290, 0.125000 (1.433 sec)
2.500... logprob:  0.362499, 0.085938 (1.492 sec)
2.501... logprob:  0.347775, 0.078125 (1.431 sec)
2.502... logprob:  0.459478, 0.125000 (1.442 sec)
2.503... logprob:  0.401038, 0.101562 (1.493 sec)
2.504... logprob:  0.489904, 0.132812 (1.433 sec)
2.505... logprob:  0.579109, 0.164062 (1.437 sec)
2.506... logprob:  0.483308, 0.132812 (1.431 sec)
2.507... logprob:  0.381707, 0.093750 (1.431 sec)
2.508... logprob:  0.374947, 0.093750 (1.432 sec)
2.509... logprob:  0.318815, 0.070312 (1.484 sec)
2.510... logprob:  0.394670, 0.101562 (1.443 sec)
2.511... logprob:  0.416128, 0.109375 (1.454 sec)
2.512... logprob:  0.468303, 0.125000 (1.465 sec)
2.513... logprob:  0.327069, 0.078125 (1.445 sec)
2.514... logprob:  0.402464, 0.101562 (1.441 sec)
2.515... logprob:  0.461701, 0.125000 (1.431 sec)
2.516... logprob:  0.407547, 0.109375 (1.426 sec)
2.517... logprob:  0.626975, 0.179688 (1.437 sec)
2.518... logprob:  0.436378, 0.117188 (1.456 sec)
2.519... logprob:  0.515249, 0.140625 (1.457 sec)
2.520... logprob:  0.411873, 0.109375 (1.452 sec)
2.521... logprob:  0.441667, 0.109375 (1.457 sec)
2.522... logprob:  0.523804, 0.156250 (1.462 sec)
2.523... logprob:  0.343525, 0.078125 (1.450 sec)
2.524... logprob:  0.438746, 0.117188 (1.426 sec)
2.525... logprob:  0.429511, 0.109375 (1.435 sec)
2.526... logprob:  0.349978, 0.078125 (1.437 sec)
2.527... logprob:  0.515214, 0.140625 (1.441 sec)
2.528... logprob:  0.445463, 0.117188 (1.471 sec)
2.529... logprob:  0.346484, 0.085938 (1.453 sec)
2.530... logprob:  0.448470, 0.117188 (1.439 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.22721862792969, 10.0]}, 128)
batch 872: ({'logprob': [69.23422241210938, 19.0]}, 128)
batch 873: ({'logprob': [39.17900085449219, 9.0]}, 128)
batch 874: ({'logprob': [44.818538665771484, 11.0]}, 128)
batch 875: ({'logprob': [51.073116302490234, 13.0]}, 128)
batch 876: ({'logprob': [66.26286315917969, 18.0]}, 128)
batch 877: ({'logprob': [45.12646484375, 11.0]}, 128)
batch 878: ({'logprob': [63.59127426147461, 17.0]}, 128)
batch 879: ({'logprob': [76.409912109375, 21.0]}, 128)
batch 880: ({'logprob': [51.07688522338867, 13.0]}, 128)
batch 881: ({'logprob': [26.352176666259766, 5.0]}, 128)
batch 882: ({'logprob': [54.97406768798828, 14.0]}, 128)
batch 883: ({'logprob': [63.58835220336914, 17.0]}, 128)
batch 884: ({'logprob': [51.38042068481445, 13.0]}, 128)
batch 885: ({'logprob': [51.99667739868164, 13.0]}, 128)
batch 886: ({'logprob': [63.89774703979492, 17.0]}, 128)

======================Test output======================
logprob:  0.420014, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.978643e-03 [1.227407e-09] 
Layer 'conv1' biases: 5.190209e-09 [2.538660e-11] 
Layer 'conv2' weights[0]: 7.965542e-03 [1.130171e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.616672e-10] 
Layer 'conv3' weights[0]: 7.963911e-03 [1.156480e-09] 
Layer 'conv3' biases: 1.020244e-07 [5.063281e-10] 
Layer 'conv4' weights[0]: 7.996409e-03 [1.222572e-09] 
Layer 'conv4' biases: 1.000000e+00 [4.706247e-09] 
Layer 'conv5' weights[0]: 7.995344e-03 [3.033723e-08] 
Layer 'conv5' biases: 9.999974e-01 [3.236667e-08] 
Layer 'fc6' weights[0]: 7.592176e-03 [4.018629e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.975259e-09] 
Layer 'fc7' weights[0]: 7.802526e-03 [7.135751e-08] 
Layer 'fc7' biases: 9.999053e-01 [5.334678e-08] 
Layer 'fc8' weights[0]: 7.336962e-04 [7.614835e-06] 
Layer 'fc8' biases: 1.404202e-03 [2.031863e-05] 
Train error last 870 batches: 0.440969
-------------------------------------------------------
Not saving because 0.420014 > 0.415987 (2.80: -0.31%)
======================================================= (12.037 sec)
2.531... logprob:  0.447882, 0.117188 (1.486 sec)
2.532... logprob:  0.472980, 0.125000 (1.440 sec)
2.533... logprob:  0.575496, 0.164062 (1.426 sec)
2.534... logprob:  0.329869, 0.078125 (1.435 sec)
2.535... logprob:  0.544644, 0.156250 (1.439 sec)
2.536... logprob:  0.503032, 0.140625 (1.435 sec)
2.537... logprob:  0.507690, 0.140625 (1.477 sec)
2.538... logprob:  0.490993, 0.132812 (1.439 sec)
2.539... logprob:  0.332988, 0.062500 (1.434 sec)
2.540... logprob:  0.452349, 0.117188 (1.493 sec)
2.541... logprob:  0.396645, 0.101562 (1.431 sec)
2.542... logprob:  0.414220, 0.109375 (1.431 sec)
2.543... logprob:  0.215884, 0.039062 (1.442 sec)
2.544... logprob:  0.305726, 0.070312 (1.429 sec)
2.545... logprob:  0.351674, 0.085938 (1.438 sec)
2.546... logprob:  0.383059, 0.093750 (1.483 sec)
2.547... logprob:  0.475041, 0.117188 (1.436 sec)
2.548... logprob:  0.489138, 0.125000 (1.447 sec)
2.549... logprob:  0.521159, 0.132812 (1.481 sec)
2.550... logprob:  0.369612, 0.093750 (1.432 sec)
2.551... logprob:  0.442604, 0.117188 (1.439 sec)
2.552... logprob:  0.473339, 0.125000 (1.436 sec)
2.553... logprob:  0.364176, 0.085938 (1.432 sec)
2.554... logprob:  0.499872, 0.140625 (1.432 sec)
2.555... logprob:  0.444507, 0.109375 (1.483 sec)
2.556... logprob:  0.391759, 0.085938 (1.448 sec)
2.557... logprob:  0.412316, 0.101562 (1.454 sec)
2.558... logprob:  0.382492, 0.101562 (1.474 sec)
2.559... logprob:  0.437013, 0.125000 (1.439 sec)
2.560... logprob:  0.330264, 0.078125 (1.438 sec)
2.561... logprob:  0.414906, 0.109375 (1.432 sec)
2.562... logprob:  0.523741, 0.140625 (1.422 sec)
2.563... logprob:  0.373190, 0.093750 (1.438 sec)
2.564... logprob:  0.488564, 0.132812 (1.463 sec)
2.565... logprob:  0.648931, 0.187500 (1.455 sec)
2.566... logprob:  0.371094, 0.093750 (1.452 sec)
2.567... logprob:  0.422470, 0.109375 (1.469 sec)
2.568... logprob:  0.495691, 0.140625 (1.455 sec)
2.569... logprob:  0.508308, 0.140625 (1.443 sec)
2.570... logprob:  0.538938, 0.164062 (1.427 sec)
2.571... logprob:  0.466184, 0.125000 (1.433 sec)
2.572... logprob:  0.508495, 0.140625 (1.438 sec)
2.573... logprob:  0.515545, 0.148438 (1.449 sec)
2.574... logprob:  0.435662, 0.109375 (1.466 sec)
2.575... logprob:  0.345070, 0.078125 (1.450 sec)
2.576... logprob:  0.422147, 0.109375 (1.442 sec)
2.577... logprob:  0.462040, 0.125000 (1.474 sec)
2.578... logprob:  0.323814, 0.078125 (1.439 sec)
2.579... logprob:  0.450196, 0.117188 (1.423 sec)
2.580... logprob:  0.580925, 0.156250 (1.431 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.14440155029297, 10.0]}, 128)
batch 872: ({'logprob': [70.2635498046875, 19.0]}, 128)
batch 873: ({'logprob': [39.133148193359375, 9.0]}, 128)
batch 874: ({'logprob': [44.93156433105469, 11.0]}, 128)
batch 875: ({'logprob': [51.437992095947266, 13.0]}, 128)
batch 876: ({'logprob': [67.18955993652344, 18.0]}, 128)
batch 877: ({'logprob': [45.285667419433594, 11.0]}, 128)
batch 878: ({'logprob': [64.46056365966797, 17.0]}, 128)
batch 879: ({'logprob': [77.8294906616211, 21.0]}, 128)
batch 880: ({'logprob': [51.441917419433594, 13.0]}, 128)
batch 881: ({'logprob': [25.754840850830078, 5.0]}, 128)
batch 882: ({'logprob': [55.58133316040039, 14.0]}, 128)
batch 883: ({'logprob': [64.45787811279297, 17.0]}, 128)
batch 884: ({'logprob': [51.7913703918457, 13.0]}, 128)
batch 885: ({'logprob': [52.50082778930664, 13.0]}, 128)
batch 886: ({'logprob': [64.81341552734375, 17.0]}, 128)

======================Test output======================
logprob:  0.423837, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.978608e-03 [2.085428e-09] 
Layer 'conv1' biases: 5.349782e-09 [5.979968e-11] 
Layer 'conv2' weights[0]: 7.965500e-03 [1.937678e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.785049e-10] 
Layer 'conv3' weights[0]: 7.963871e-03 [2.010194e-09] 
Layer 'conv3' biases: 1.045310e-07 [1.182255e-09] 
Layer 'conv4' weights[0]: 7.996371e-03 [2.222035e-09] 
Layer 'conv4' biases: 1.000000e+00 [1.144126e-08] 
Layer 'conv5' weights[0]: 7.995314e-03 [7.436594e-08] 
Layer 'conv5' biases: 9.999976e-01 [7.980898e-08] 
Layer 'fc6' weights[0]: 7.592142e-03 [9.322612e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.350829e-09] 
Layer 'fc7' weights[0]: 7.800592e-03 [1.145837e-07] 
Layer 'fc7' biases: 9.999020e-01 [9.959584e-08] 
Layer 'fc8' weights[0]: 7.852853e-04 [5.710771e-06] 
Layer 'fc8' biases: 1.660926e-03 [1.583631e-05] 
Train error last 870 batches: 0.441066
-------------------------------------------------------
Not saving because 0.423837 > 0.415987 (2.80: -0.31%)
======================================================= (12.052 sec)
2.581... logprob:  0.570202, 0.156250 (1.449 sec)
2.582... logprob:  0.458228, 0.125000 (1.442 sec)
2.583... logprob:  0.602047, 0.171875 (1.476 sec)
2.584... logprob:  0.469940, 0.132812 (1.450 sec)
2.585... logprob:  0.362837, 0.085938 (1.428 sec)
2.586... logprob:  0.342021, 0.070312 (1.485 sec)
2.587... logprob:  0.422769, 0.101562 (1.434 sec)
2.588... logprob:  0.424789, 0.117188 (1.433 sec)
2.589... logprob:  0.370075, 0.093750 (1.444 sec)
2.590... logprob:  0.521411, 0.148438 (1.434 sec)
2.591... logprob:  0.398658, 0.101562 (1.439 sec)
2.592... logprob:  0.457472, 0.125000 (1.485 sec)
2.593... logprob:  0.473275, 0.125000 (1.437 sec)
2.594... logprob:  0.350227, 0.085938 (1.440 sec)
2.595... logprob:  0.433108, 0.109375 (1.484 sec)
2.596... logprob:  0.469502, 0.125000 (1.433 sec)
2.597... logprob:  0.398137, 0.101562 (1.434 sec)
2.598... logprob:  0.397309, 0.101562 (1.436 sec)
2.599... logprob:  0.308393, 0.070312 (1.435 sec)
2.600... logprob:  0.340965, 0.085938 (1.432 sec)
2.601... logprob:  0.400664, 0.101562 (1.485 sec)
2.602... logprob:  0.287283, 0.062500 (1.432 sec)
2.603... logprob:  0.264139, 0.054688 (1.447 sec)
2.604... logprob:  0.403417, 0.101562 (1.479 sec)
2.605... logprob:  0.553548, 0.148438 (1.431 sec)
2.606... logprob:  0.301189, 0.070312 (1.444 sec)
2.607... logprob:  0.496688, 0.132812 (1.435 sec)
2.608... logprob:  0.353222, 0.085938 (1.425 sec)
2.609... logprob:  0.352938, 0.085938 (1.441 sec)
2.610... logprob:  0.491635, 0.132812 (1.471 sec)
2.611... logprob:  0.514636, 0.140625 (1.449 sec)
2.612... logprob:  0.442310, 0.117188 (1.452 sec)
2.613... logprob:  0.303971, 0.062500 (1.465 sec)
2.614... logprob:  0.508561, 0.140625 (1.449 sec)
2.615... logprob:  0.363998, 0.085938 (1.441 sec)
2.616... logprob:  0.422211, 0.109375 (1.428 sec)
2.617... logprob:  0.420027, 0.109375 (1.426 sec)
2.618... logprob:  0.547487, 0.156250 (1.435 sec)
2.619... logprob:  0.508228, 0.140625 (1.458 sec)
2.620... logprob:  0.540229, 0.156250 (1.468 sec)
2.621... logprob:  0.362904, 0.085938 (1.457 sec)
2.622... logprob:  0.363991, 0.085938 (1.447 sec)
2.623... logprob:  0.422921, 0.109375 (1.473 sec)
2.624... logprob:  0.379446, 0.093750 (1.436 sec)
2.625... logprob:  0.441242, 0.117188 (1.427 sec)
2.626... logprob:  0.436725, 0.117188 (1.435 sec)
2.627... logprob:  0.432362, 0.117188 (1.438 sec)
2.628... logprob:  0.473859, 0.125000 (1.441 sec)
2.629... logprob:  0.365907, 0.093750 (1.473 sec)
2.630... logprob:  0.427222, 0.109375 (1.459 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.001033782958984, 10.0]}, 128)
batch 872: ({'logprob': [67.11054229736328, 19.0]}, 128)
batch 873: ({'logprob': [40.25945281982422, 9.0]}, 128)
batch 874: ({'logprob': [44.87605667114258, 11.0]}, 128)
batch 875: ({'logprob': [50.744415283203125, 13.0]}, 128)
batch 876: ({'logprob': [64.4911117553711, 18.0]}, 128)
batch 877: ({'logprob': [45.502315521240234, 11.0]}, 128)
batch 878: ({'logprob': [62.48934555053711, 17.0]}, 128)
batch 879: ({'logprob': [74.85214233398438, 21.0]}, 128)
batch 880: ({'logprob': [50.74790954589844, 13.0]}, 128)
batch 881: ({'logprob': [27.887361526489258, 5.0]}, 128)
batch 882: ({'logprob': [55.24609375, 14.0]}, 128)
batch 883: ({'logprob': [62.4865608215332, 17.0]}, 128)
batch 884: ({'logprob': [51.36835479736328, 13.0]}, 128)
batch 885: ({'logprob': [52.62025451660156, 13.0]}, 128)
batch 886: ({'logprob': [63.11294937133789, 17.0]}, 128)

======================Test output======================
logprob:  0.417381, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.978568e-03 [1.120231e-09] 
Layer 'conv1' biases: 5.596596e-09 [1.646400e-11] 
Layer 'conv2' weights[0]: 7.965463e-03 [9.243082e-10] 
Layer 'conv2' biases: 1.000000e+00 [8.180655e-11] 
Layer 'conv3' weights[0]: 7.963830e-03 [9.192289e-10] 
Layer 'conv3' biases: 1.073905e-07 [2.475081e-10] 
Layer 'conv4' weights[0]: 7.996328e-03 [9.538449e-10] 
Layer 'conv4' biases: 1.000000e+00 [2.258689e-09] 
Layer 'conv5' weights[0]: 7.995268e-03 [1.467462e-08] 
Layer 'conv5' biases: 9.999979e-01 [1.573115e-08] 
Layer 'fc6' weights[0]: 7.592105e-03 [1.952033e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.788329e-09] 
Layer 'fc7' weights[0]: 7.798663e-03 [5.992388e-08] 
Layer 'fc7' biases: 9.998990e-01 [3.934557e-08] 
Layer 'fc8' weights[0]: 7.556807e-04 [4.729654e-06] 
Layer 'fc8' biases: 1.612025e-03 [1.390445e-05] 
Train error last 870 batches: 0.440560
-------------------------------------------------------
Not saving because 0.417381 > 0.415987 (2.80: -0.31%)
======================================================= (12.102 sec)
2.631... logprob:  0.646285, 0.187500 (1.445 sec)
2.632... logprob:  0.401535, 0.101562 (1.485 sec)
2.633... logprob:  0.378784, 0.093750 (1.432 sec)
2.634... logprob:  0.649819, 0.195312 (1.434 sec)
2.635... logprob:  0.380479, 0.093750 (1.434 sec)
2.636... logprob:  0.479019, 0.132812 (1.437 sec)
2.637... logprob:  0.344572, 0.078125 (1.431 sec)
2.638... logprob:  0.515414, 0.140625 (1.485 sec)
2.639... logprob:  0.421456, 0.109375 (1.440 sec)
2.640... logprob:  0.526544, 0.148438 (1.440 sec)
2.641... logprob:  0.414854, 0.109375 (1.484 sec)
2.642... logprob:  0.503256, 0.140625 (1.437 sec)
2.643... logprob:  0.631536, 0.187500 (1.436 sec)
2.644... logprob:  0.315671, 0.070312 (1.433 sec)
2.645... logprob:  0.415294, 0.109375 (1.430 sec)
2.646... logprob:  0.380369, 0.093750 (1.428 sec)
2.647... logprob:  0.458052, 0.125000 (1.486 sec)
2.648... logprob:  0.495369, 0.140625 (1.429 sec)
2.649... logprob:  0.366242, 0.093750 (1.449 sec)
2.650... logprob:  0.412145, 0.109375 (1.476 sec)
2.651... logprob:  0.397148, 0.101562 (1.436 sec)
2.652... logprob:  0.511735, 0.140625 (1.440 sec)
2.653... logprob:  0.550340, 0.156250 (1.436 sec)
2.654... logprob:  0.491490, 0.140625 (1.427 sec)
2.655... logprob:  0.436983, 0.117188 (1.437 sec)
2.656... logprob:  0.421001, 0.109375 (1.479 sec)
2.657... logprob:  0.460962, 0.117188 (1.444 sec)
2.658... logprob:  0.348548, 0.085938 (1.451 sec)
2.659... logprob:  0.468389, 0.125000 (1.469 sec)
2.660... logprob:  0.441562, 0.125000 (1.442 sec)
2.661... logprob:  0.379708, 0.093750 (1.438 sec)
2.662... logprob:  0.469355, 0.132812 (1.435 sec)
2.663... logprob:  0.306319, 0.070312 (1.437 sec)
2.664... logprob:  0.278058, 0.062500 (1.441 sec)
2.665... logprob:  0.402843, 0.101562 (1.461 sec)
2.666... logprob:  0.448025, 0.117188 (1.455 sec)
2.667... logprob:  0.584094, 0.164062 (1.458 sec)
2.668... logprob:  0.507909, 0.140625 (1.456 sec)
2.669... logprob:  0.432257, 0.109375 (1.460 sec)
2.670... logprob:  0.361450, 0.085938 (1.435 sec)
2.671... logprob:  0.364230, 0.093750 (1.430 sec)
2.672... logprob:  0.440613, 0.117188 (1.431 sec)
2.673... logprob:  0.436482, 0.117188 (1.443 sec)
2.674... logprob:  0.445284, 0.117188 (1.440 sec)
2.675... logprob:  0.365728, 0.093750 (1.469 sec)
2.676... logprob:  0.451356, 0.125000 (1.457 sec)
2.677... logprob:  0.467979, 0.125000 (1.439 sec)
2.678... logprob:  0.463766, 0.125000 (1.486 sec)
2.679... logprob:  0.455368, 0.125000 (1.432 sec)
2.680... logprob:  0.348501, 0.078125 (1.432 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.703678131103516, 10.0]}, 128)
batch 872: ({'logprob': [66.51056671142578, 19.0]}, 128)
batch 873: ({'logprob': [40.65428924560547, 9.0]}, 128)
batch 874: ({'logprob': [45.2296142578125, 11.0]}, 128)
batch 875: ({'logprob': [50.793949127197266, 13.0]}, 128)
batch 876: ({'logprob': [63.9775505065918, 18.0]}, 128)
batch 877: ({'logprob': [45.72484588623047, 11.0]}, 128)
batch 878: ({'logprob': [61.93082809448242, 17.0]}, 128)
batch 879: ({'logprob': [73.55425262451172, 21.0]}, 128)
batch 880: ({'logprob': [50.79759979248047, 13.0]}, 128)
batch 881: ({'logprob': [29.02174186706543, 5.0]}, 128)
batch 882: ({'logprob': [54.81489562988281, 14.0]}, 128)
batch 883: ({'logprob': [61.92790985107422, 17.0]}, 128)
batch 884: ({'logprob': [51.28623962402344, 13.0]}, 128)
batch 885: ({'logprob': [52.275211334228516, 13.0]}, 128)
batch 886: ({'logprob': [62.42277908325195, 17.0]}, 128)

======================Test output======================
logprob:  0.416321, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.978528e-03 [1.452612e-09] 
Layer 'conv1' biases: 5.702534e-09 [3.229426e-11] 
Layer 'conv2' weights[0]: 7.965423e-03 [1.149794e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.545490e-10] 
Layer 'conv3' weights[0]: 7.963782e-03 [1.151254e-09] 
Layer 'conv3' biases: 1.087739e-07 [4.571976e-10] 
Layer 'conv4' weights[0]: 7.996287e-03 [1.223406e-09] 
Layer 'conv4' biases: 1.000000e+00 [3.920317e-09] 
Layer 'conv5' weights[0]: 7.995231e-03 [2.464038e-08] 
Layer 'conv5' biases: 9.999982e-01 [2.633092e-08] 
Layer 'fc6' weights[0]: 7.592065e-03 [3.045960e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.999910e-09] 
Layer 'fc7' weights[0]: 7.796714e-03 [7.091620e-08] 
Layer 'fc7' biases: 9.998984e-01 [5.197489e-08] 
Layer 'fc8' weights[0]: 7.371011e-04 [1.253647e-05] 
Layer 'fc8' biases: 1.579926e-03 [3.830064e-05] 
Train error last 870 batches: 0.440278
-------------------------------------------------------
Not saving because 0.416321 > 0.415987 (2.80: -0.31%)
======================================================= (12.088 sec)
2.681... logprob:  0.373144, 0.093750 (1.448 sec)
2.682... logprob:  0.334716, 0.078125 (1.438 sec)
2.683... logprob:  0.414525, 0.109375 (1.430 sec)
2.684... logprob:  0.352820, 0.085938 (1.484 sec)
2.685... logprob:  0.267265, 0.054688 (1.439 sec)
2.686... logprob:  0.307619, 0.070312 (1.429 sec)
2.687... logprob:  0.276356, 0.062500 (1.491 sec)
2.688... logprob:  0.328044, 0.078125 (1.433 sec)
2.689... logprob:  0.491263, 0.125000 (1.432 sec)
2.690... logprob:  0.544749, 0.140625 (1.442 sec)
2.691... logprob:  0.535926, 0.140625 (1.438 sec)
2.692... logprob:  0.399182, 0.101562 (1.436 sec)
2.693... logprob:  0.461877, 0.125000 (1.492 sec)
2.694... logprob:  0.335631, 0.078125 (1.440 sec)
2.695... logprob:  0.364625, 0.085938 (1.440 sec)
2.696... logprob:  0.525537, 0.148438 (1.481 sec)
2.697... logprob:  0.465882, 0.125000 (1.432 sec)
2.698... logprob:  0.538965, 0.156250 (1.431 sec)
2.699... logprob:  0.464895, 0.125000 (1.434 sec)
2.700... logprob:  0.439654, 0.117188 (1.432 sec)
2.701... logprob:  0.430484, 0.109375 (1.435 sec)
2.702... logprob:  0.522457, 0.148438 (1.485 sec)
2.703... logprob:  0.401666, 0.101562 (1.439 sec)
2.704... logprob:  0.398556, 0.101562 (1.452 sec)
2.705... logprob:  0.412425, 0.109375 (1.470 sec)
2.706... logprob:  0.470653, 0.125000 (1.433 sec)
2.707... logprob:  0.493672, 0.132812 (1.437 sec)
2.708... logprob:  0.414995, 0.109375 (1.436 sec)
2.709... logprob:  0.421961, 0.109375 (1.421 sec)
2.710... logprob:  0.627141, 0.179688 (1.437 sec)
2.711... logprob:  0.471825, 0.125000 (1.468 sec)
2.712... logprob:  0.336918, 0.078125 (1.448 sec)
2.713... logprob:  0.589168, 0.179688 (1.456 sec)
2.714... logprob:  0.466189, 0.125000 (1.462 sec)
2.715... logprob:  0.423284, 0.109375 (1.450 sec)
2.716... logprob:  0.353250, 0.078125 (1.437 sec)
2.717... logprob:  0.434769, 0.117188 (1.423 sec)
2.718... logprob:  0.489339, 0.132812 (1.433 sec)
2.719... logprob:  0.408946, 0.109375 (1.444 sec)
2.720... logprob:  0.432950, 0.117188 (1.444 sec)
2.721... logprob:  0.452977, 0.117188 (1.468 sec)
2.722... logprob:  0.536401, 0.156250 (1.452 sec)
2.723... logprob:  0.416501, 0.109375 (1.447 sec)
2.724... logprob:  0.411742, 0.109375 (1.473 sec)
2.725... logprob:  0.496406, 0.140625 (1.432 sec)
2.726... logprob:  0.330469, 0.085938 (1.424 sec)
2.727... logprob:  0.391543, 0.101562 (1.436 sec)
2.728... logprob:  0.424097, 0.109375 (1.437 sec)
2.729... logprob:  0.393878, 0.093750 (1.441 sec)
2.730... logprob:  0.573084, 0.164062 (1.472 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.08205032348633, 10.0]}, 128)
batch 872: ({'logprob': [66.46549987792969, 19.0]}, 128)
batch 873: ({'logprob': [41.367000579833984, 9.0]}, 128)
batch 874: ({'logprob': [45.30337905883789, 11.0]}, 128)
batch 875: ({'logprob': [51.04109191894531, 13.0]}, 128)
batch 876: ({'logprob': [64.04845428466797, 18.0]}, 128)
batch 877: ({'logprob': [46.20436096191406, 11.0]}, 128)
batch 878: ({'logprob': [62.52393341064453, 17.0]}, 128)
batch 879: ({'logprob': [74.89871215820312, 21.0]}, 128)
batch 880: ({'logprob': [51.04428482055664, 13.0]}, 128)
batch 881: ({'logprob': [28.98223114013672, 5.0]}, 128)
batch 882: ({'logprob': [56.16297149658203, 14.0]}, 128)
batch 883: ({'logprob': [62.521270751953125, 17.0]}, 128)
batch 884: ({'logprob': [51.93873977661133, 13.0]}, 128)
batch 885: ({'logprob': [53.73955154418945, 13.0]}, 128)
batch 886: ({'logprob': [63.421539306640625, 17.0]}, 128)

======================Test output======================
logprob:  0.420286, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.978488e-03 [1.471757e-09] 
Layer 'conv1' biases: 5.929431e-09 [3.789831e-11] 
Layer 'conv2' weights[0]: 7.965385e-03 [1.316920e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.072198e-10] 
Layer 'conv3' weights[0]: 7.963750e-03 [1.328312e-09] 
Layer 'conv3' biases: 1.112594e-07 [6.398021e-10] 
Layer 'conv4' weights[0]: 7.996250e-03 [1.458340e-09] 
Layer 'conv4' biases: 1.000000e+00 [6.337287e-09] 
Layer 'conv5' weights[0]: 7.995199e-03 [4.175315e-08] 
Layer 'conv5' biases: 9.999983e-01 [4.498344e-08] 
Layer 'fc6' weights[0]: 7.592017e-03 [4.938408e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.909287e-09] 
Layer 'fc7' weights[0]: 7.794743e-03 [8.374187e-08] 
Layer 'fc7' biases: 9.998971e-01 [6.728842e-08] 
Layer 'fc8' weights[0]: 7.760528e-04 [7.042751e-06] 
Layer 'fc8' biases: 1.748537e-03 [2.146513e-05] 
Train error last 870 batches: 0.439637
-------------------------------------------------------
Not saving because 0.420286 > 0.415987 (2.80: -0.31%)
======================================================= (12.064 sec)
2.731... logprob:  0.448463, 0.125000 (1.453 sec)
2.732... logprob:  0.311162, 0.070312 (1.447 sec)
2.733... logprob:  0.564393, 0.156250 (1.481 sec)
2.734... logprob:  0.343831, 0.078125 (1.438 sec)
2.735... logprob:  0.529497, 0.148438 (1.429 sec)
2.736... logprob:  0.644470, 0.187500 (1.449 sec)
2.737... logprob:  0.514971, 0.148438 (1.432 sec)
2.738... logprob:  0.460164, 0.125000 (1.433 sec)
2.739... logprob:  0.479002, 0.132812 (1.487 sec)
2.740... logprob:  0.349789, 0.078125 (1.435 sec)
2.741... logprob:  0.401074, 0.101562 (1.438 sec)
2.742... logprob:  0.421992, 0.109375 (1.483 sec)
2.743... logprob:  0.362359, 0.085938 (1.430 sec)
2.744... logprob:  0.523350, 0.148438 (1.431 sec)
2.745... logprob:  0.482589, 0.132812 (1.435 sec)
2.746... logprob:  0.441371, 0.117188 (1.435 sec)
2.747... logprob:  0.422632, 0.109375 (1.430 sec)
2.748... logprob:  0.374949, 0.093750 (1.489 sec)
2.749... logprob:  0.420822, 0.109375 (1.436 sec)
2.750... logprob:  0.515233, 0.140625 (1.444 sec)
2.751... logprob:  0.260388, 0.054688 (1.472 sec)
2.752... logprob:  0.518440, 0.140625 (1.437 sec)
2.753... logprob:  0.441729, 0.117188 (1.439 sec)
2.754... logprob:  0.476244, 0.132812 (1.436 sec)
2.755... logprob:  0.504275, 0.140625 (1.427 sec)
2.756... logprob:  0.440398, 0.117188 (1.437 sec)
2.757... logprob:  0.544050, 0.156250 (1.473 sec)
2.758... logprob:  0.400684, 0.101562 (1.449 sec)
2.759... logprob:  0.461789, 0.125000 (1.452 sec)
2.760... logprob:  0.486704, 0.132812 (1.465 sec)
2.761... logprob:  0.423775, 0.109375 (1.448 sec)
2.762... logprob:  0.513992, 0.148438 (1.445 sec)
2.763... logprob:  0.557451, 0.164062 (1.429 sec)
2.764... logprob:  0.504294, 0.140625 (1.427 sec)
2.765... logprob:  0.309423, 0.062500 (1.438 sec)
2.766... logprob:  0.482173, 0.132812 (1.455 sec)
2.767... logprob:  0.363740, 0.085938 (1.455 sec)
2.768... logprob:  0.429557, 0.117188 (1.461 sec)
2.769... logprob:  0.496574, 0.140625 (1.474 sec)
2.770... logprob:  0.399915, 0.101562 (1.488 sec)
2.771... logprob:  0.563744, 0.156250 (1.462 sec)
2.772... logprob:  0.413239, 0.109375 (1.443 sec)
2.773... logprob:  0.564644, 0.164062 (1.452 sec)
2.774... logprob:  0.361822, 0.085938 (1.459 sec)
2.775... logprob:  0.410694, 0.101562 (1.466 sec)
2.776... logprob:  0.432264, 0.117188 (1.479 sec)
2.777... logprob:  0.384243, 0.093750 (1.471 sec)
2.778... logprob:  0.432808, 0.117188 (1.464 sec)
2.779... logprob:  0.501457, 0.140625 (1.489 sec)
2.780... logprob:  0.387228, 0.101562 (1.456 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.107173919677734, 10.0]}, 128)
batch 872: ({'logprob': [66.17823791503906, 19.0]}, 128)
batch 873: ({'logprob': [41.153602600097656, 9.0]}, 128)
batch 874: ({'logprob': [45.557579040527344, 11.0]}, 128)
batch 875: ({'logprob': [50.95878982543945, 13.0]}, 128)
batch 876: ({'logprob': [63.728858947753906, 18.0]}, 128)
batch 877: ({'logprob': [46.05706787109375, 11.0]}, 128)
batch 878: ({'logprob': [61.769344329833984, 17.0]}, 128)
batch 879: ({'logprob': [73.07022857666016, 21.0]}, 128)
batch 880: ({'logprob': [50.96250534057617, 13.0]}, 128)
batch 881: ({'logprob': [29.8431396484375, 5.0]}, 128)
batch 882: ({'logprob': [54.90782928466797, 14.0]}, 128)
batch 883: ({'logprob': [61.76641845703125, 17.0]}, 128)
batch 884: ({'logprob': [51.45451354980469, 13.0]}, 128)
batch 885: ({'logprob': [52.451332092285156, 13.0]}, 128)
batch 886: ({'logprob': [62.26487731933594, 17.0]}, 128)

======================Test output======================
logprob:  0.417105, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.978447e-03 [1.182904e-09] 
Layer 'conv1' biases: 6.116496e-09 [1.560751e-11] 
Layer 'conv2' weights[0]: 7.965350e-03 [1.001421e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.009544e-10] 
Layer 'conv3' weights[0]: 7.963708e-03 [9.441797e-10] 
Layer 'conv3' biases: 1.133854e-07 [2.974239e-10] 
Layer 'conv4' weights[0]: 7.996214e-03 [9.820774e-10] 
Layer 'conv4' biases: 1.000000e+00 [2.751874e-09] 
Layer 'conv5' weights[0]: 7.995160e-03 [1.790171e-08] 
Layer 'conv5' biases: 9.999985e-01 [1.925206e-08] 
Layer 'fc6' weights[0]: 7.591977e-03 [2.248918e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.098473e-09] 
Layer 'fc7' weights[0]: 7.792749e-03 [4.605157e-08] 
Layer 'fc7' biases: 9.998958e-01 [1.988654e-08] 
Layer 'fc8' weights[0]: 7.487295e-04 [5.275578e-06] 
Layer 'fc8' biases: 1.712613e-03 [1.704247e-05] 
Train error last 870 batches: 0.439294
-------------------------------------------------------
Not saving because 0.417105 > 0.415987 (2.80: -0.31%)
======================================================= (12.104 sec)
2.781... logprob:  0.375404, 0.085938 (1.455 sec)
2.782... logprob:  0.354192, 0.085938 (1.448 sec)
2.783... logprob:  0.552766, 0.156250 (1.461 sec)
2.784... logprob:  0.440804, 0.117188 (1.456 sec)
2.785... logprob:  0.545143, 0.156250 (1.487 sec)
2.786... logprob:  0.478529, 0.132812 (1.472 sec)
2.787... logprob:  0.545745, 0.156250 (1.466 sec)
2.788... logprob:  0.561276, 0.164062 (1.491 sec)
2.789... logprob:  0.288657, 0.054688 (1.459 sec)
2.790... logprob:  0.411677, 0.101562 (1.446 sec)
2.791... logprob:  0.400209, 0.101562 (1.454 sec)
2.792... logprob:  0.361453, 0.085938 (1.458 sec)
2.793... logprob:  0.367156, 0.085938 (1.458 sec)
2.794... logprob:  0.382572, 0.093750 (1.489 sec)
2.795... logprob:  0.471615, 0.125000 (1.467 sec)
2.796... logprob:  0.424202, 0.109375 (1.462 sec)
2.797... logprob:  0.353760, 0.085938 (1.498 sec)
2.798... logprob:  0.399666, 0.101562 (1.457 sec)
2.799... logprob:  0.328397, 0.078125 (1.449 sec)
2.800... logprob:  0.377638, 0.093750 (1.450 sec)
2.801... logprob:  0.453131, 0.117188 (1.459 sec)
2.802... logprob:  0.426940, 0.109375 (1.491 sec)
2.803... logprob:  0.497738, 0.132812 (1.492 sec)
2.804... logprob:  0.352974, 0.085938 (1.462 sec)
2.805... logprob:  0.444176, 0.117188 (1.455 sec)
2.806... logprob:  0.421011, 0.109375 (1.504 sec)
2.807... logprob:  0.442076, 0.117188 (1.450 sec)
2.808... logprob:  0.462151, 0.125000 (1.451 sec)
2.809... logprob:  0.579065, 0.171875 (1.454 sec)
2.810... logprob:  0.445916, 0.117188 (1.453 sec)
2.811... logprob:  0.463843, 0.125000 (1.451 sec)
2.812... logprob:  0.466982, 0.125000 (1.494 sec)
2.813... logprob:  0.490485, 0.132812 (1.464 sec)
2.814... logprob:  0.476755, 0.132812 (1.457 sec)
2.815... logprob:  0.374658, 0.085938 (1.500 sec)
2.816... logprob:  0.405529, 0.101562 (1.453 sec)
2.817... logprob:  0.421182, 0.109375 (1.457 sec)
2.818... logprob:  0.572941, 0.164062 (1.447 sec)
2.819... logprob:  0.503214, 0.140625 (1.459 sec)
2.820... logprob:  0.416948, 0.109375 (1.451 sec)
2.821... logprob:  0.403740, 0.101562 (1.502 sec)
2.822... logprob:  0.441709, 0.117188 (1.144 sec)
2.823... logprob:  0.333501, 0.078125 (1.151 sec)
2.824... logprob:  0.497607, 0.132812 (0.706 sec)
2.825... logprob:  0.281679, 0.062500 (0.689 sec)
2.826... logprob:  0.374936, 0.093750 (0.687 sec)
2.827... logprob:  0.420741, 0.109375 (0.687 sec)
2.828... logprob:  0.442725, 0.117188 (0.685 sec)
2.829... logprob:  0.501736, 0.140625 (0.688 sec)
2.830... logprob:  0.439159, 0.117188 (1.508 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.82258605957031, 10.0]}, 128)
batch 872: ({'logprob': [66.97920989990234, 19.0]}, 128)
batch 873: ({'logprob': [40.191932678222656, 9.0]}, 128)
batch 874: ({'logprob': [45.142276763916016, 11.0]}, 128)
batch 875: ({'logprob': [50.766143798828125, 13.0]}, 128)
batch 876: ({'logprob': [64.3379135131836, 18.0]}, 128)
batch 877: ({'logprob': [45.47978591918945, 11.0]}, 128)
batch 878: ({'logprob': [62.023399353027344, 17.0]}, 128)
batch 879: ({'logprob': [73.60888671875, 21.0]}, 128)
batch 880: ({'logprob': [50.77032470703125, 13.0]}, 128)
batch 881: ({'logprob': [28.59609031677246, 5.0]}, 128)
batch 882: ({'logprob': [54.423187255859375, 14.0]}, 128)
batch 883: ({'logprob': [62.020442962646484, 17.0]}, 128)
batch 884: ({'logprob': [51.100364685058594, 13.0]}, 128)
batch 885: ({'logprob': [51.77420425415039, 13.0]}, 128)
batch 886: ({'logprob': [62.357452392578125, 17.0]}, 128)

======================Test output======================
logprob:  0.415720, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.978410e-03 [1.517135e-09] 
Layer 'conv1' biases: 6.337155e-09 [3.230760e-11] 
Layer 'conv2' weights[0]: 7.965314e-03 [1.286872e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.878232e-10] 
Layer 'conv3' weights[0]: 7.963668e-03 [1.274751e-09] 
Layer 'conv3' biases: 1.161816e-07 [5.907655e-10] 
Layer 'conv4' weights[0]: 7.996176e-03 [1.352443e-09] 
Layer 'conv4' biases: 1.000000e+00 [5.270788e-09] 
Layer 'conv5' weights[0]: 7.995123e-03 [3.376909e-08] 
Layer 'conv5' biases: 9.999985e-01 [3.638592e-08] 
Layer 'fc6' weights[0]: 7.591942e-03 [3.962948e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.914921e-09] 
Layer 'fc7' weights[0]: 7.790770e-03 [1.213067e-07] 
Layer 'fc7' biases: 9.998951e-01 [1.063854e-07] 
Layer 'fc8' weights[0]: 7.809698e-04 [1.346488e-05] 
Layer 'fc8' biases: 1.882273e-03 [4.362380e-05] 
Train error last 870 batches: 0.439063
-------------------------------------------------------
Saved checkpoint to /data2/ad6813/my-nets/saves/ConvNet__2014-06-17_23.05.49
======================================================= (12.574 sec)
2.831... logprob:  0.505224, 0.140625 (1.458 sec)
2.832... logprob:  0.338113, 0.078125 (1.464 sec)
2.833... logprob:  0.482224, 0.132812 (1.496 sec)
2.834... logprob:  0.430655, 0.117188 (2.736 sec)
2.835... logprob:  0.537364, 0.148438 (1.452 sec)
2.836... logprob:  0.383677, 0.093750 (1.455 sec)
2.837... logprob:  0.325384, 0.070312 (3.100 sec)
2.838... logprob:  0.437371, 0.117188 (1.456 sec)
2.839... logprob:  0.473045, 0.125000 (1.500 sec)
2.840... logprob:  0.558189, 0.156250 (1.457 sec)
2.841... logprob:  0.394626, 0.101562 (1.497 sec)
2.842... logprob:  0.502743, 0.140625 (1.503 sec)
2.843... logprob:  0.465169, 0.125000 (1.454 sec)
2.844... logprob:  0.502926, 0.140625 (1.461 sec)
2.845... logprob:  0.486129, 0.132812 (1.452 sec)
2.846... logprob:  0.465313, 0.125000 (1.449 sec)
2.847... logprob:  0.360270, 0.085938 (1.457 sec)
2.848... logprob:  0.399356, 0.101562 (1.496 sec)
2.849... logprob:  0.359608, 0.085938 (1.456 sec)
2.850... logprob:  0.481926, 0.132812 (1.467 sec)
2.851... logprob:  0.440858, 0.117188 (1.486 sec)
2.852... logprob:  0.547721, 0.156250 (1.463 sec)
2.853... logprob:  0.372975, 0.093750 (1.467 sec)
2.854... logprob:  0.308287, 0.070312 (1.451 sec)
2.855... logprob:  0.484481, 0.132812 (1.447 sec)
2.856... logprob:  0.444145, 0.117188 (1.456 sec)
2.857... logprob:  0.372139, 0.093750 (1.492 sec)
2.858... logprob:  0.396259, 0.101562 (1.466 sec)
2.859... logprob:  0.310266, 0.070312 (1.468 sec)
2.860... logprob:  0.569147, 0.156250 (1.488 sec)
2.861... logprob:  0.417018, 0.109375 (1.462 sec)
2.862... logprob:  0.330096, 0.078125 (1.587 sec)
2.863... logprob:  0.400763, 0.101562 (1.442 sec)
2.864... logprob:  0.454890, 0.117188 (1.438 sec)
2.865... logprob:  0.483420, 0.132812 (1.453 sec)
2.866... logprob:  0.506623, 0.140625 (1.489 sec)
2.867... logprob:  0.500871, 0.140625 (1.472 sec)
2.868... logprob:  0.407781, 0.101562 (1.472 sec)
2.869... logprob:  0.386262, 0.093750 (1.477 sec)
2.870... logprob:  0.549207, 0.156250 (1.400 sec)
3.1... logprob:  0.383018, 0.093750 (1.407 sec)
3.2... logprob:  0.446744, 0.117188 (1.450 sec)
3.3... logprob:  0.401826, 0.101562 (1.416 sec)
3.4... logprob:  0.442999, 0.117188 (1.409 sec)
3.5... logprob:  0.442721, 0.117188 (1.433 sec)
3.6... logprob:  0.506256, 0.140625 (1.394 sec)
3.7... logprob:  0.357426, 0.085938 (1.431 sec)
3.8... logprob:  0.421645, 0.109375 (1.397 sec)
3.9... logprob:  0.355161, 0.085938 (1.415 sec)
3.10... logprob:  0.376454, 0.093750 (1.407 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.2247428894043, 10.0]}, 128)
batch 872: ({'logprob': [68.703369140625, 19.0]}, 128)
batch 873: ({'logprob': [39.32674789428711, 9.0]}, 128)
batch 874: ({'logprob': [45.18531036376953, 11.0]}, 128)
batch 875: ({'logprob': [51.0660285949707, 13.0]}, 128)
batch 876: ({'logprob': [65.77134704589844, 18.0]}, 128)
batch 877: ({'logprob': [45.19707107543945, 11.0]}, 128)
batch 878: ({'logprob': [62.83888626098633, 17.0]}, 128)
batch 879: ({'logprob': [74.6143798828125, 21.0]}, 128)
batch 880: ({'logprob': [51.070926666259766, 13.0]}, 128)
batch 881: ({'logprob': [27.540334701538086, 5.0]}, 128)
batch 882: ({'logprob': [54.03927993774414, 14.0]}, 128)
batch 883: ({'logprob': [62.83585739135742, 17.0]}, 128)
batch 884: ({'logprob': [51.07530975341797, 13.0]}, 128)
batch 885: ({'logprob': [51.09880828857422, 13.0]}, 128)
batch 886: ({'logprob': [62.847930908203125, 17.0]}, 128)

======================Test output======================
logprob:  0.417694, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.978369e-03 [1.221314e-09] 
Layer 'conv1' biases: 6.433626e-09 [1.535745e-11] 
Layer 'conv2' weights[0]: 7.965276e-03 [1.043136e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.039980e-10] 
Layer 'conv3' weights[0]: 7.963626e-03 [9.795586e-10] 
Layer 'conv3' biases: 1.171799e-07 [2.970344e-10] 
Layer 'conv4' weights[0]: 7.996140e-03 [1.028422e-09] 
Layer 'conv4' biases: 1.000000e+00 [2.819956e-09] 
Layer 'conv5' weights[0]: 7.995076e-03 [1.859618e-08] 
Layer 'conv5' biases: 9.999984e-01 [2.004611e-08] 
Layer 'fc6' weights[0]: 7.591909e-03 [2.256784e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.107175e-09] 
Layer 'fc7' weights[0]: 7.788801e-03 [1.054536e-07] 
Layer 'fc7' biases: 9.998947e-01 [8.925110e-08] 
Layer 'fc8' weights[0]: 8.127903e-04 [1.359649e-05] 
Layer 'fc8' biases: 2.026576e-03 [4.539922e-05] 
Train error last 870 batches: 0.438695
-------------------------------------------------------
Not saving because 0.417694 > 0.415720 (2.830: -0.06%)
======================================================= (12.080 sec)
3.11... logprob:  0.330134, 0.078125 (1.448 sec)
3.12... logprob:  0.470540, 0.125000 (1.395 sec)
3.13... logprob:  0.447301, 0.117188 (1.424 sec)
3.14... logprob:  0.447605, 0.117188 (1.405 sec)
3.15... logprob:  0.397845, 0.101562 (1.414 sec)
3.16... logprob:  0.421731, 0.109375 (1.405 sec)
3.17... logprob:  0.513774, 0.140625 (1.391 sec)
3.18... logprob:  0.267456, 0.054688 (1.400 sec)
3.19... logprob:  0.284344, 0.062500 (1.403 sec)
3.20... logprob:  0.419927, 0.109375 (1.409 sec)
3.21... logprob:  0.440877, 0.117188 (0.887 sec)
3.22... logprob:  0.529476, 0.148438 (1.323 sec)
3.23... logprob:  0.524797, 0.148438 (1.414 sec)
3.24... logprob:  0.318964, 0.070312 (0.989 sec)
3.25... logprob:  0.362502, 0.085938 (0.957 sec)
3.26... logprob:  0.463145, 0.125000 (1.485 sec)
3.27... logprob:  0.411014, 0.101562 (1.392 sec)
3.28... logprob:  0.423266, 0.109375 (1.410 sec)
3.29... logprob:  0.394323, 0.101562 (1.428 sec)
3.30... logprob:  0.371359, 0.093750 (1.415 sec)
3.31... logprob:  0.481171, 0.132812 (1.409 sec)
3.32... logprob:  0.457769, 0.125000 (1.388 sec)
3.33... logprob:  0.461978, 0.125000 (1.451 sec)
3.34... logprob:  0.467077, 0.125000 (1.389 sec)
3.35... logprob:  0.312846, 0.070312 (1.403 sec)
3.36... logprob:  0.474214, 0.132812 (1.405 sec)
3.37... logprob:  0.416769, 0.109375 (1.401 sec)
3.38... logprob:  0.389527, 0.101562 (1.400 sec)
3.39... logprob:  0.632467, 0.187500 (1.434 sec)
3.40... logprob:  0.449843, 0.117188 (1.409 sec)
3.41... logprob:  0.353985, 0.085938 (1.444 sec)
3.42... logprob:  0.390749, 0.101562 (1.414 sec)
3.43... logprob:  0.441483, 0.117188 (1.411 sec)
3.44... logprob:  0.515056, 0.148438 (1.434 sec)
3.45... logprob:  0.386230, 0.093750 (1.403 sec)
3.46... logprob:  0.488929, 0.132812 (1.392 sec)
3.47... logprob:  0.331301, 0.078125 (1.394 sec)
3.48... logprob:  0.499144, 0.140625 (1.422 sec)
3.49... logprob:  0.510079, 0.148438 (1.418 sec)
3.50... logprob:  0.392120, 0.101562 (1.422 sec)
3.51... logprob:  0.489232, 0.140625 (1.415 sec)
3.52... logprob:  0.528113, 0.148438 (1.400 sec)
3.53... logprob:  0.295233, 0.062500 (1.445 sec)
3.54... logprob:  0.400500, 0.109375 (1.389 sec)
3.55... logprob:  0.331490, 0.078125 (1.402 sec)
3.56... logprob:  0.423119, 0.109375 (1.400 sec)
3.57... logprob:  0.576423, 0.164062 (1.429 sec)
3.58... logprob:  0.409702, 0.101562 (1.408 sec)
3.59... logprob:  0.333073, 0.078125 (1.468 sec)
3.60... logprob:  0.623118, 0.179688 (1.426 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.242549896240234, 10.0]}, 128)
batch 872: ({'logprob': [66.62260437011719, 19.0]}, 128)
batch 873: ({'logprob': [40.668540954589844, 9.0]}, 128)
batch 874: ({'logprob': [45.07533645629883, 11.0]}, 128)
batch 875: ({'logprob': [50.783809661865234, 13.0]}, 128)
batch 876: ({'logprob': [64.09589385986328, 18.0]}, 128)
batch 877: ({'logprob': [45.7266960144043, 11.0]}, 128)
batch 878: ({'logprob': [62.209922790527344, 17.0]}, 128)
batch 879: ({'logprob': [74.27754211425781, 21.0]}, 128)
batch 880: ({'logprob': [50.78776168823242, 13.0]}, 128)
batch 881: ({'logprob': [28.5897274017334, 5.0]}, 128)
batch 882: ({'logprob': [55.26759338378906, 14.0]}, 128)
batch 883: ({'logprob': [62.20692443847656, 17.0]}, 128)
batch 884: ({'logprob': [51.431514739990234, 13.0]}, 128)
batch 885: ({'logprob': [52.73316192626953, 13.0]}, 128)
batch 886: ({'logprob': [62.857666015625, 17.0]}, 128)

======================Test output======================
logprob:  0.417274, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.978334e-03 [1.746534e-09] 
Layer 'conv1' biases: 6.622549e-09 [4.497440e-11] 
Layer 'conv2' weights[0]: 7.965229e-03 [1.524764e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.859336e-10] 
Layer 'conv3' weights[0]: 7.963595e-03 [1.628591e-09] 
Layer 'conv3' biases: 1.194686e-07 [8.963930e-10] 
Layer 'conv4' weights[0]: 7.996101e-03 [1.784371e-09] 
Layer 'conv4' biases: 1.000000e+00 [8.957950e-09] 
Layer 'conv5' weights[0]: 7.995041e-03 [5.954848e-08] 
Layer 'conv5' biases: 9.999989e-01 [6.435011e-08] 
Layer 'fc6' weights[0]: 7.591869e-03 [6.622525e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.692882e-09] 
Layer 'fc7' weights[0]: 7.786866e-03 [1.042173e-07] 
Layer 'fc7' biases: 9.998939e-01 [8.869777e-08] 
Layer 'fc8' weights[0]: 8.067266e-04 [1.219015e-05] 
Layer 'fc8' biases: 2.002846e-03 [4.052332e-05] 
Train error last 870 batches: 0.438529
-------------------------------------------------------
Not saving because 0.417274 > 0.415720 (2.830: -0.06%)
======================================================= (12.020 sec)
3.61... logprob:  0.382098, 0.093750 (1.437 sec)
3.62... logprob:  0.475962, 0.132812 (1.467 sec)
3.63... logprob:  0.396959, 0.101562 (1.442 sec)
3.64... logprob:  0.451985, 0.125000 (1.412 sec)
3.65... logprob:  0.374403, 0.093750 (1.401 sec)
3.66... logprob:  0.355168, 0.085938 (1.445 sec)
3.67... logprob:  0.295403, 0.062500 (1.392 sec)
3.68... logprob:  0.396501, 0.101562 (1.399 sec)
3.69... logprob:  0.501085, 0.140625 (1.419 sec)
3.70... logprob:  0.326202, 0.078125 (1.431 sec)
3.71... logprob:  0.386645, 0.101562 (1.469 sec)
3.72... logprob:  0.493835, 0.132812 (1.401 sec)
3.73... logprob:  0.447042, 0.117188 (1.428 sec)
3.74... logprob:  0.442649, 0.117188 (1.415 sec)
3.75... logprob:  0.379232, 0.093750 (1.444 sec)
3.76... logprob:  0.412893, 0.109375 (1.440 sec)
3.77... logprob:  0.396331, 0.101562 (1.424 sec)
3.78... logprob:  0.492626, 0.140625 (1.454 sec)
3.79... logprob:  0.455602, 0.125000 (1.400 sec)
3.80... logprob:  0.505954, 0.132812 (1.430 sec)
3.81... logprob:  0.418190, 0.109375 (1.417 sec)
3.82... logprob:  0.241891, 0.039062 (1.426 sec)
3.83... logprob:  0.492760, 0.140625 (1.413 sec)
3.84... logprob:  0.467602, 0.125000 (1.469 sec)
3.85... logprob:  0.432550, 0.117188 (1.428 sec)
3.86... logprob:  0.416844, 0.109375 (1.417 sec)
3.87... logprob:  0.637389, 0.187500 (1.412 sec)
3.88... logprob:  0.537932, 0.156250 (1.414 sec)
3.89... logprob:  0.410412, 0.109375 (1.434 sec)
3.90... logprob:  0.578308, 0.171875 (1.392 sec)
3.91... logprob:  0.350028, 0.078125 (1.401 sec)
3.92... logprob:  0.465120, 0.125000 (1.401 sec)
3.93... logprob:  0.491838, 0.140625 (1.401 sec)
3.94... logprob:  0.429922, 0.109375 (1.390 sec)
3.95... logprob:  0.472766, 0.125000 (1.403 sec)
3.96... logprob:  0.577585, 0.171875 (1.408 sec)
3.97... logprob:  0.430288, 0.117188 (1.395 sec)
3.98... logprob:  0.388902, 0.093750 (1.441 sec)
3.99... logprob:  0.475140, 0.132812 (1.410 sec)
3.100... logprob:  0.307019, 0.070312 (1.401 sec)
3.101... logprob:  0.303854, 0.062500 (1.442 sec)
3.102... logprob:  0.552929, 0.156250 (1.393 sec)
3.103... logprob:  0.550187, 0.156250 (1.402 sec)
3.104... logprob:  0.390277, 0.101562 (1.406 sec)
3.105... logprob:  0.625530, 0.179688 (1.394 sec)
3.106... logprob:  0.344965, 0.085938 (1.394 sec)
3.107... logprob:  0.336785, 0.078125 (1.447 sec)
3.108... logprob:  0.582322, 0.171875 (1.396 sec)
3.109... logprob:  0.341075, 0.078125 (1.407 sec)
3.110... logprob:  0.557679, 0.164062 (1.400 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.548912048339844, 10.0]}, 128)
batch 872: ({'logprob': [65.8544692993164, 19.0]}, 128)
batch 873: ({'logprob': [41.914798736572266, 9.0]}, 128)
batch 874: ({'logprob': [46.02001190185547, 11.0]}, 128)
batch 875: ({'logprob': [51.25847244262695, 13.0]}, 128)
batch 876: ({'logprob': [63.520626068115234, 18.0]}, 128)
batch 877: ({'logprob': [46.58776092529297, 11.0]}, 128)
batch 878: ({'logprob': [61.743858337402344, 17.0]}, 128)
batch 879: ({'logprob': [72.78678894042969, 21.0]}, 128)
batch 880: ({'logprob': [51.262393951416016, 13.0]}, 128)
batch 881: ({'logprob': [30.861417770385742, 5.0]}, 128)
batch 882: ({'logprob': [55.29561233520508, 14.0]}, 128)
batch 883: ({'logprob': [61.74067687988281, 17.0]}, 128)
batch 884: ({'logprob': [51.82143783569336, 13.0]}, 128)
batch 885: ({'logprob': [52.953895568847656, 13.0]}, 128)
batch 886: ({'logprob': [62.30677032470703, 17.0]}, 128)

======================Test output======================
logprob:  0.419179, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.978292e-03 [1.254636e-09] 
Layer 'conv1' biases: 6.862062e-09 [2.361378e-11] 
Layer 'conv2' weights[0]: 7.965182e-03 [1.152551e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.262678e-10] 
Layer 'conv3' weights[0]: 7.963561e-03 [1.128470e-09] 
Layer 'conv3' biases: 1.218928e-07 [4.123347e-10] 
Layer 'conv4' weights[0]: 7.996062e-03 [1.195104e-09] 
Layer 'conv4' biases: 1.000000e+00 [3.650604e-09] 
Layer 'conv5' weights[0]: 7.995005e-03 [2.428485e-08] 
Layer 'conv5' biases: 9.999989e-01 [2.617764e-08] 
Layer 'fc6' weights[0]: 7.591833e-03 [2.770087e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.696807e-09] 
Layer 'fc7' weights[0]: 7.784863e-03 [1.147004e-07] 
Layer 'fc7' biases: 9.998927e-01 [9.944815e-08] 
Layer 'fc8' weights[0]: 7.674765e-04 [1.229721e-05] 
Layer 'fc8' biases: 1.881268e-03 [4.112060e-05] 
Train error last 870 batches: 0.438195
-------------------------------------------------------
Not saving because 0.419179 > 0.415720 (2.830: -0.06%)
======================================================= (12.091 sec)
3.111... logprob:  0.409337, 0.101562 (1.401 sec)
3.112... logprob:  0.369941, 0.093750 (1.407 sec)
3.113... logprob:  0.360109, 0.085938 (1.399 sec)
3.114... logprob:  0.441008, 0.117188 (1.432 sec)
3.115... logprob:  0.506715, 0.140625 (1.416 sec)
3.116... logprob:  0.393001, 0.101562 (1.400 sec)
3.117... logprob:  0.440671, 0.117188 (1.449 sec)
3.118... logprob:  0.409500, 0.101562 (1.397 sec)
3.119... logprob:  0.343262, 0.085938 (1.396 sec)
3.120... logprob:  0.554225, 0.156250 (1.404 sec)
3.121... logprob:  0.413330, 0.109375 (1.402 sec)
3.122... logprob:  0.524755, 0.148438 (1.440 sec)
3.123... logprob:  0.465011, 0.125000 (1.394 sec)
3.124... logprob:  0.448180, 0.125000 (1.406 sec)
3.125... logprob:  0.501934, 0.140625 (1.401 sec)
3.126... logprob:  0.477544, 0.125000 (1.391 sec)
3.127... logprob:  0.482219, 0.125000 (1.405 sec)
3.128... logprob:  0.425545, 0.109375 (1.413 sec)
3.129... logprob:  0.571034, 0.164062 (1.422 sec)
3.130... logprob:  0.387511, 0.093750 (1.420 sec)
3.131... logprob:  0.491383, 0.132812 (1.408 sec)
3.132... logprob:  0.504140, 0.140625 (1.437 sec)
3.133... logprob:  0.443982, 0.117188 (1.388 sec)
3.134... logprob:  0.403379, 0.101562 (1.402 sec)
3.135... logprob:  0.464483, 0.125000 (1.398 sec)
3.136... logprob:  0.569961, 0.164062 (1.403 sec)
3.137... logprob:  0.464850, 0.125000 (1.391 sec)
3.138... logprob:  0.317677, 0.070312 (1.444 sec)
3.139... logprob:  0.403349, 0.101562 (1.404 sec)
3.140... logprob:  0.577382, 0.164062 (1.410 sec)
3.141... logprob:  0.464767, 0.125000 (1.437 sec)
3.142... logprob:  0.464534, 0.125000 (1.395 sec)
3.143... logprob:  0.292227, 0.062500 (1.425 sec)
3.144... logprob:  0.459244, 0.125000 (1.414 sec)
3.145... logprob:  0.325272, 0.078125 (1.421 sec)
3.146... logprob:  0.481721, 0.132812 (1.410 sec)
3.147... logprob:  0.264098, 0.054688 (1.435 sec)
3.148... logprob:  0.453098, 0.125000 (1.389 sec)
3.149... logprob:  0.442092, 0.117188 (1.399 sec)
3.150... logprob:  0.345475, 0.085938 (1.402 sec)
3.151... logprob:  0.344920, 0.085938 (1.409 sec)
3.152... logprob:  0.772666, 0.234375 (1.391 sec)
3.153... logprob:  0.395432, 0.093750 (1.443 sec)
3.154... logprob:  0.518203, 0.148438 (1.404 sec)
3.155... logprob:  0.413359, 0.117188 (1.409 sec)
3.156... logprob:  0.313344, 0.062500 (1.439 sec)
3.157... logprob:  0.279825, 0.054688 (1.399 sec)
3.158... logprob:  0.455470, 0.125000 (1.404 sec)
3.159... logprob:  0.489900, 0.132812 (1.397 sec)
3.160... logprob:  0.453085, 0.117188 (1.392 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.941062927246094, 10.0]}, 128)
batch 872: ({'logprob': [66.61280822753906, 19.0]}, 128)
batch 873: ({'logprob': [41.39299011230469, 9.0]}, 128)
batch 874: ({'logprob': [45.2840461730957, 11.0]}, 128)
batch 875: ({'logprob': [51.091590881347656, 13.0]}, 128)
batch 876: ({'logprob': [64.19005584716797, 18.0]}, 128)
batch 877: ({'logprob': [46.24253463745117, 11.0]}, 128)
batch 878: ({'logprob': [62.71530532836914, 17.0]}, 128)
batch 879: ({'logprob': [75.28706359863281, 21.0]}, 128)
batch 880: ({'logprob': [51.095184326171875, 13.0]}, 128)
batch 881: ({'logprob': [28.809188842773438, 5.0]}, 128)
batch 882: ({'logprob': [56.392364501953125, 14.0]}, 128)
batch 883: ({'logprob': [62.7123908996582, 17.0]}, 128)
batch 884: ({'logprob': [52.04597091674805, 13.0]}, 128)
batch 885: ({'logprob': [53.96194839477539, 13.0]}, 128)
batch 886: ({'logprob': [63.669944763183594, 17.0]}, 128)

======================Test output======================
logprob:  0.421115, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.978252e-03 [1.060610e-09] 
Layer 'conv1' biases: 7.070484e-09 [1.838403e-11] 
Layer 'conv2' weights[0]: 7.965147e-03 [9.756350e-10] 
Layer 'conv2' biases: 1.000000e+00 [8.010793e-11] 
Layer 'conv3' weights[0]: 7.963521e-03 [9.315429e-10] 
Layer 'conv3' biases: 1.233002e-07 [2.552226e-10] 
Layer 'conv4' weights[0]: 7.996025e-03 [9.352567e-10] 
Layer 'conv4' biases: 1.000000e+00 [1.923803e-09] 
Layer 'conv5' weights[0]: 7.994960e-03 [1.109975e-08] 
Layer 'conv5' biases: 9.999989e-01 [1.149920e-08] 
Layer 'fc6' weights[0]: 7.591796e-03 [1.579266e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.378204e-09] 
Layer 'fc7' weights[0]: 7.782912e-03 [5.157189e-08] 
Layer 'fc7' biases: 9.998923e-01 [2.737626e-08] 
Layer 'fc8' weights[0]: 8.424107e-04 [1.533095e-05] 
Layer 'fc8' biases: 2.168200e-03 [5.322735e-05] 
Train error last 870 batches: 0.438088
-------------------------------------------------------
Not saving because 0.421115 > 0.415720 (2.830: -0.06%)
======================================================= (12.112 sec)
3.161... logprob:  0.357225, 0.078125 (1.402 sec)
3.162... logprob:  0.629589, 0.179688 (1.405 sec)
3.163... logprob:  0.451307, 0.125000 (1.428 sec)
3.164... logprob:  0.473094, 0.125000 (1.415 sec)
3.165... logprob:  0.555198, 0.156250 (1.418 sec)
3.166... logprob:  0.447732, 0.125000 (1.449 sec)
3.167... logprob:  0.349376, 0.085938 (1.435 sec)
3.168... logprob:  0.361883, 0.085938 (1.424 sec)
3.169... logprob:  0.405980, 0.101562 (1.460 sec)
3.170... logprob:  0.459854, 0.125000 (1.405 sec)
3.171... logprob:  0.538399, 0.156250 (1.420 sec)
3.172... logprob:  0.427974, 0.109375 (1.414 sec)
3.173... logprob:  0.440736, 0.117188 (1.420 sec)
3.174... logprob:  0.590566, 0.171875 (1.414 sec)
3.175... logprob:  0.503505, 0.140625 (1.469 sec)
3.176... logprob:  0.481273, 0.132812 (1.421 sec)
3.177... logprob:  0.287820, 0.054688 (1.424 sec)
3.178... logprob:  0.383198, 0.093750 (1.462 sec)
3.179... logprob:  0.400523, 0.101562 (1.406 sec)
3.180... logprob:  0.463778, 0.125000 (1.423 sec)
3.181... logprob:  0.550656, 0.156250 (1.422 sec)
3.182... logprob:  0.376600, 0.093750 (1.421 sec)
3.183... logprob:  0.420506, 0.109375 (1.417 sec)
3.184... logprob:  0.486638, 0.132812 (1.442 sec)
3.185... logprob:  0.287096, 0.062500 (1.409 sec)
3.186... logprob:  0.372218, 0.093750 (1.400 sec)
3.187... logprob:  0.533141, 0.148438 (1.398 sec)
3.188... logprob:  0.460674, 0.125000 (1.398 sec)
3.189... logprob:  0.441115, 0.117188 (1.392 sec)
3.190... logprob:  0.376044, 0.093750 (1.439 sec)
3.191... logprob:  0.484381, 0.132812 (1.406 sec)
3.192... logprob:  0.514190, 0.148438 (1.422 sec)
3.193... logprob:  0.318744, 0.070312 (1.415 sec)
3.194... logprob:  0.412613, 0.109375 (1.415 sec)
3.195... logprob:  0.291525, 0.062500 (1.398 sec)
3.196... logprob:  0.406007, 0.109375 (1.396 sec)
3.197... logprob:  0.473972, 0.132812 (1.396 sec)
3.198... logprob:  0.359792, 0.085938 (1.408 sec)
3.199... logprob:  0.436675, 0.117188 (1.389 sec)
3.200... logprob:  0.443715, 0.117188 (1.442 sec)
3.201... logprob:  0.437562, 0.117188 (1.404 sec)
3.202... logprob:  0.550538, 0.148438 (1.409 sec)
3.203... logprob:  0.423864, 0.109375 (1.440 sec)
3.204... logprob:  0.507654, 0.140625 (1.402 sec)
3.205... logprob:  0.334293, 0.078125 (1.398 sec)
3.206... logprob:  0.356085, 0.093750 (1.405 sec)
3.207... logprob:  0.383966, 0.093750 (1.392 sec)
3.208... logprob:  0.488805, 0.140625 (1.403 sec)
3.209... logprob:  0.334427, 0.078125 (1.418 sec)
3.210... logprob:  0.587444, 0.171875 (1.417 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.59917449951172, 10.0]}, 128)
batch 872: ({'logprob': [66.29483032226562, 19.0]}, 128)
batch 873: ({'logprob': [41.001365661621094, 9.0]}, 128)
batch 874: ({'logprob': [45.31069564819336, 11.0]}, 128)
batch 875: ({'logprob': [50.863670349121094, 13.0]}, 128)
batch 876: ({'logprob': [63.83149719238281, 18.0]}, 128)
batch 877: ({'logprob': [45.93324279785156, 11.0]}, 128)
batch 878: ({'logprob': [61.97909164428711, 17.0]}, 128)
batch 879: ({'logprob': [73.7064437866211, 21.0]}, 128)
batch 880: ({'logprob': [50.86787033081055, 13.0]}, 128)
batch 881: ({'logprob': [29.262174606323242, 5.0]}, 128)
batch 882: ({'logprob': [55.196746826171875, 14.0]}, 128)
batch 883: ({'logprob': [61.975914001464844, 17.0]}, 128)
batch 884: ({'logprob': [51.4818000793457, 13.0]}, 128)
batch 885: ({'logprob': [52.72502899169922, 13.0]}, 128)
batch 886: ({'logprob': [62.5972900390625, 17.0]}, 128)

======================Test output======================
logprob:  0.417298, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.978210e-03 [1.379692e-09] 
Layer 'conv1' biases: 7.497284e-09 [4.762301e-11] 
Layer 'conv2' weights[0]: 7.965108e-03 [1.193783e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.213172e-10] 
Layer 'conv3' weights[0]: 7.963484e-03 [1.277958e-09] 
Layer 'conv3' biases: 1.264897e-07 [6.451172e-10] 
Layer 'conv4' weights[0]: 7.995984e-03 [1.370578e-09] 
Layer 'conv4' biases: 1.000000e+00 [6.251175e-09] 
Layer 'conv5' weights[0]: 7.994934e-03 [4.186523e-08] 
Layer 'conv5' biases: 9.999992e-01 [4.522158e-08] 
Layer 'fc6' weights[0]: 7.591758e-03 [4.587991e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.548660e-09] 
Layer 'fc7' weights[0]: 7.780906e-03 [9.379163e-08] 
Layer 'fc7' biases: 9.998908e-01 [7.805115e-08] 
Layer 'fc8' weights[0]: 8.252381e-04 [7.469217e-06] 
Layer 'fc8' biases: 2.165309e-03 [2.600273e-05] 
Train error last 870 batches: 0.437604
-------------------------------------------------------
Not saving because 0.417298 > 0.415720 (2.830: -0.06%)
======================================================= (12.059 sec)
3.211... logprob:  0.489081, 0.132812 (1.428 sec)
3.212... logprob:  0.525990, 0.148438 (1.413 sec)
3.213... logprob:  0.514364, 0.140625 (1.467 sec)
3.214... logprob:  0.459786, 0.125000 (1.425 sec)
3.215... logprob:  0.399132, 0.101562 (1.417 sec)
3.216... logprob:  0.513502, 0.140625 (1.472 sec)
3.217... logprob:  0.328616, 0.070312 (1.401 sec)
3.218... logprob:  0.463082, 0.125000 (1.460 sec)
3.219... logprob:  0.501229, 0.140625 (1.416 sec)
3.220... logprob:  0.418370, 0.109375 (1.423 sec)
3.221... logprob:  0.399188, 0.101562 (1.403 sec)
3.222... logprob:  0.565796, 0.164062 (1.457 sec)
3.223... logprob:  0.571087, 0.164062 (1.428 sec)
3.224... logprob:  0.401189, 0.101562 (1.433 sec)
3.225... logprob:  0.395856, 0.101562 (1.452 sec)
3.226... logprob:  0.422033, 0.109375 (1.424 sec)
3.227... logprob:  0.457488, 0.125000 (1.413 sec)
3.228... logprob:  0.418213, 0.109375 (1.418 sec)
3.229... logprob:  0.487487, 0.132812 (1.420 sec)
3.230... logprob:  0.460212, 0.125000 (1.423 sec)
3.231... logprob:  0.454487, 0.125000 (1.408 sec)
3.232... logprob:  0.495550, 0.140625 (1.459 sec)
3.233... logprob:  0.464143, 0.132812 (1.440 sec)
3.234... logprob:  0.560372, 0.164062 (1.432 sec)
3.235... logprob:  0.482926, 0.132812 (1.466 sec)
3.236... logprob:  0.432860, 0.109375 (1.409 sec)
3.237... logprob:  0.349850, 0.078125 (1.426 sec)
3.238... logprob:  0.398983, 0.093750 (1.416 sec)
3.239... logprob:  0.478150, 0.132812 (1.419 sec)
3.240... logprob:  0.489517, 0.132812 (1.406 sec)
3.241... logprob:  0.500264, 0.132812 (1.456 sec)
3.242... logprob:  0.338780, 0.078125 (1.432 sec)
3.243... logprob:  0.384696, 0.093750 (1.426 sec)
3.244... logprob:  0.308412, 0.070312 (1.444 sec)
3.245... logprob:  0.499748, 0.132812 (1.426 sec)
3.246... logprob:  0.420561, 0.109375 (1.416 sec)
3.247... logprob:  0.353827, 0.085938 (1.417 sec)
3.248... logprob:  0.304146, 0.070312 (1.417 sec)
3.249... logprob:  0.569859, 0.156250 (1.426 sec)
3.250... logprob:  0.592111, 0.164062 (1.404 sec)
3.251... logprob:  0.353146, 0.085938 (1.465 sec)
3.252... logprob:  0.355515, 0.085938 (1.428 sec)
3.253... logprob:  0.376583, 0.093750 (1.418 sec)
3.254... logprob:  0.443203, 0.117188 (1.465 sec)
3.255... logprob:  0.359084, 0.085938 (1.405 sec)
3.256... logprob:  0.378512, 0.093750 (1.422 sec)
3.257... logprob:  0.336886, 0.078125 (1.427 sec)
3.258... logprob:  0.424427, 0.109375 (1.421 sec)
3.259... logprob:  0.443626, 0.117188 (1.403 sec)
3.260... logprob:  0.311219, 0.070312 (1.470 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.37501525878906, 10.0]}, 128)
batch 872: ({'logprob': [68.18850708007812, 19.0]}, 128)
batch 873: ({'logprob': [39.60053634643555, 9.0]}, 128)
batch 874: ({'logprob': [45.283905029296875, 11.0]}, 128)
batch 875: ({'logprob': [51.01784133911133, 13.0]}, 128)
batch 876: ({'logprob': [65.33734130859375, 18.0]}, 128)
batch 877: ({'logprob': [45.31011199951172, 11.0]}, 128)
batch 878: ({'logprob': [62.498321533203125, 17.0]}, 128)
batch 879: ({'logprob': [73.99469757080078, 21.0]}, 128)
batch 880: ({'logprob': [51.02330780029297, 13.0]}, 128)
batch 881: ({'logprob': [28.09191131591797, 5.0]}, 128)
batch 882: ({'logprob': [53.953369140625, 14.0]}, 128)
batch 883: ({'logprob': [62.494991302490234, 17.0]}, 128)
batch 884: ({'logprob': [51.04072952270508, 13.0]}, 128)
batch 885: ({'logprob': [51.09248352050781, 13.0]}, 128)
batch 886: ({'logprob': [62.5210075378418, 17.0]}, 128)

======================Test output======================
logprob:  0.416906, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.978176e-03 [1.277871e-09] 
Layer 'conv1' biases: 7.725915e-09 [3.327415e-11] 
Layer 'conv2' weights[0]: 7.965078e-03 [1.268840e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.927149e-10] 
Layer 'conv3' weights[0]: 7.963449e-03 [1.316247e-09] 
Layer 'conv3' biases: 1.279494e-07 [6.040328e-10] 
Layer 'conv4' weights[0]: 7.995944e-03 [1.472928e-09] 
Layer 'conv4' biases: 1.000000e+00 [6.155795e-09] 
Layer 'conv5' weights[0]: 7.994887e-03 [4.122537e-08] 
Layer 'conv5' biases: 9.999992e-01 [4.457215e-08] 
Layer 'fc6' weights[0]: 7.591707e-03 [4.470010e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.425440e-09] 
Layer 'fc7' weights[0]: 7.778925e-03 [1.120813e-07] 
Layer 'fc7' biases: 9.998897e-01 [9.591565e-08] 
Layer 'fc8' weights[0]: 8.542406e-04 [1.508152e-05] 
Layer 'fc8' biases: 2.333875e-03 [5.516283e-05] 
Train error last 870 batches: 0.437523
-------------------------------------------------------
Not saving because 0.416906 > 0.415720 (2.830: -0.06%)
======================================================= (11.997 sec)
3.261... logprob:  0.398007, 0.101562 (1.440 sec)
3.262... logprob:  0.530279, 0.148438 (1.430 sec)
3.263... logprob:  0.425912, 0.109375 (1.448 sec)
3.264... logprob:  0.374887, 0.093750 (1.425 sec)
3.265... logprob:  0.438817, 0.117188 (1.419 sec)
3.266... logprob:  0.437785, 0.117188 (1.413 sec)
3.267... logprob:  0.425128, 0.109375 (1.420 sec)
3.268... logprob:  0.456165, 0.125000 (1.435 sec)
3.269... logprob:  0.567369, 0.164062 (1.403 sec)
3.270... logprob:  0.539674, 0.156250 (1.465 sec)
3.271... logprob:  0.455082, 0.117188 (1.424 sec)
3.272... logprob:  0.394139, 0.093750 (1.420 sec)
3.273... logprob:  0.501819, 0.140625 (1.468 sec)
3.274... logprob:  0.546944, 0.156250 (1.404 sec)
3.275... logprob:  0.496292, 0.132812 (1.422 sec)
3.276... logprob:  0.395471, 0.093750 (1.420 sec)
3.277... logprob:  0.431268, 0.109375 (1.421 sec)
3.278... logprob:  0.317481, 0.070312 (1.425 sec)
3.279... logprob:  0.318356, 0.070312 (1.462 sec)
3.280... logprob:  0.200198, 0.031250 (1.407 sec)
3.281... logprob:  0.419497, 0.109375 (1.428 sec)
3.282... logprob:  0.420012, 0.109375 (1.416 sec)
3.283... logprob:  0.401720, 0.101562 (1.422 sec)
3.284... logprob:  0.404318, 0.101562 (1.412 sec)
3.285... logprob:  0.462163, 0.117188 (1.437 sec)
3.286... logprob:  0.545142, 0.140625 (1.443 sec)
3.287... logprob:  0.350863, 0.085938 (1.433 sec)
3.288... logprob:  0.328806, 0.078125 (1.437 sec)
3.289... logprob:  0.446932, 0.117188 (1.441 sec)
3.290... logprob:  0.488985, 0.132812 (1.410 sec)
3.291... logprob:  0.437918, 0.117188 (1.422 sec)
3.292... logprob:  0.552799, 0.156250 (1.417 sec)
3.293... logprob:  0.429738, 0.117188 (1.459 sec)
3.294... logprob:  0.367480, 0.085938 (1.405 sec)
3.295... logprob:  0.351162, 0.078125 (1.460 sec)
3.296... logprob:  0.369103, 0.085938 (1.412 sec)
3.297... logprob:  0.401298, 0.101562 (1.419 sec)
3.298... logprob:  0.447882, 0.125000 (1.462 sec)
3.299... logprob:  0.345235, 0.078125 (1.406 sec)
3.300... logprob:  0.407127, 0.101562 (1.427 sec)
3.301... logprob:  0.396534, 0.101562 (1.417 sec)
3.302... logprob:  0.604290, 0.179688 (1.423 sec)
3.303... logprob:  0.464227, 0.125000 (1.406 sec)
3.304... logprob:  0.464340, 0.125000 (1.445 sec)
3.305... logprob:  0.458462, 0.125000 (1.436 sec)
3.306... logprob:  0.442641, 0.117188 (1.439 sec)
3.307... logprob:  0.422380, 0.109375 (1.441 sec)
3.308... logprob:  0.372388, 0.093750 (1.460 sec)
3.309... logprob:  0.449347, 0.125000 (1.414 sec)
3.310... logprob:  0.477933, 0.125000 (1.424 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.72835159301758, 10.0]}, 128)
batch 872: ({'logprob': [66.03820037841797, 19.0]}, 128)
batch 873: ({'logprob': [41.55315017700195, 9.0]}, 128)
batch 874: ({'logprob': [45.56821060180664, 11.0]}, 128)
batch 875: ({'logprob': [51.04763412475586, 13.0]}, 128)
batch 876: ({'logprob': [63.666587829589844, 18.0]}, 128)
batch 877: ({'logprob': [46.3010139465332, 11.0]}, 128)
batch 878: ({'logprob': [62.015628814697266, 17.0]}, 128)
batch 879: ({'logprob': [73.70504760742188, 21.0]}, 128)
batch 880: ({'logprob': [51.05173873901367, 13.0]}, 128)
batch 881: ({'logprob': [29.85080337524414, 5.0]}, 128)
batch 882: ({'logprob': [55.618507385253906, 14.0]}, 128)
batch 883: ({'logprob': [62.01256561279297, 17.0]}, 128)
batch 884: ({'logprob': [51.774898529052734, 13.0]}, 128)
batch 885: ({'logprob': [53.23808288574219, 13.0]}, 128)
batch 886: ({'logprob': [62.74336242675781, 17.0]}, 128)

======================Test output======================
logprob:  0.418903, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.978129e-03 [1.431917e-09] 
Layer 'conv1' biases: 8.239497e-09 [2.402691e-11] 
Layer 'conv2' weights[0]: 7.965037e-03 [1.002770e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.800856e-11] 
Layer 'conv3' weights[0]: 7.963413e-03 [9.825368e-10] 
Layer 'conv3' biases: 1.325908e-07 [3.465933e-10] 
Layer 'conv4' weights[0]: 7.995904e-03 [1.024295e-09] 
Layer 'conv4' biases: 1.000000e+00 [3.079654e-09] 
Layer 'conv5' weights[0]: 7.994869e-03 [2.024695e-08] 
Layer 'conv5' biases: 9.999995e-01 [2.169535e-08] 
Layer 'fc6' weights[0]: 7.591668e-03 [2.310186e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.161936e-09] 
Layer 'fc7' weights[0]: 7.776993e-03 [1.217331e-07] 
Layer 'fc7' biases: 9.998876e-01 [1.071671e-07] 
Layer 'fc8' weights[0]: 8.637867e-04 [7.737615e-06] 
Layer 'fc8' biases: 2.457445e-03 [2.744749e-05] 
Train error last 870 batches: 0.437443
-------------------------------------------------------
Not saving because 0.418903 > 0.415720 (2.830: -0.06%)
======================================================= (12.067 sec)
3.311... logprob:  0.503033, 0.140625 (1.435 sec)
3.312... logprob:  0.478340, 0.132812 (1.427 sec)
3.313... logprob:  0.454622, 0.125000 (1.424 sec)
3.314... logprob:  0.458515, 0.117188 (1.460 sec)
3.315... logprob:  0.321469, 0.070312 (1.431 sec)
3.316... logprob:  0.469153, 0.125000 (1.422 sec)
3.317... logprob:  0.358278, 0.085938 (1.481 sec)
3.318... logprob:  0.455754, 0.125000 (1.417 sec)
3.319... logprob:  0.426211, 0.117188 (1.421 sec)
3.320... logprob:  0.413400, 0.109375 (1.424 sec)
3.321... logprob:  0.348423, 0.085938 (1.431 sec)
3.322... logprob:  0.389211, 0.101562 (1.425 sec)
3.323... logprob:  0.417449, 0.109375 (1.474 sec)
3.324... logprob:  0.503445, 0.140625 (1.429 sec)
3.325... logprob:  0.349848, 0.085938 (1.435 sec)
3.326... logprob:  0.544907, 0.148438 (1.488 sec)
3.327... logprob:  0.557782, 0.164062 (1.428 sec)
3.328... logprob:  0.564726, 0.156250 (1.425 sec)
3.329... logprob:  0.402966, 0.101562 (1.424 sec)
3.330... logprob:  0.390192, 0.101562 (1.412 sec)
3.331... logprob:  0.356513, 0.085938 (1.416 sec)
3.332... logprob:  0.483161, 0.132812 (1.447 sec)
3.333... logprob:  0.342553, 0.085938 (1.448 sec)
3.334... logprob:  0.561186, 0.171875 (1.442 sec)
3.335... logprob:  0.361855, 0.085938 (1.439 sec)
3.336... logprob:  0.443324, 0.125000 (1.453 sec)
3.337... logprob:  0.567993, 0.164062 (1.415 sec)
3.338... logprob:  0.448341, 0.125000 (1.425 sec)
3.339... logprob:  0.491431, 0.132812 (1.425 sec)
3.340... logprob:  0.442915, 0.117188 (1.439 sec)
3.341... logprob:  0.533902, 0.148438 (1.417 sec)
3.342... logprob:  0.430624, 0.109375 (1.469 sec)
3.343... logprob:  0.435434, 0.109375 (1.441 sec)
3.344... logprob:  0.443869, 0.125000 (1.487 sec)
3.345... logprob:  0.488846, 0.132812 (1.441 sec)
3.346... logprob:  0.435956, 0.117188 (1.436 sec)
3.347... logprob:  0.367930, 0.085938 (1.482 sec)
3.348... logprob:  0.397077, 0.101562 (1.435 sec)
3.349... logprob:  0.500710, 0.140625 (1.436 sec)
3.350... logprob:  0.355911, 0.085938 (1.440 sec)
3.351... logprob:  0.508379, 0.140625 (1.429 sec)
3.352... logprob:  0.368356, 0.093750 (1.438 sec)
3.353... logprob:  0.519990, 0.148438 (1.571 sec)
3.354... logprob:  0.675817, 0.203125 (1.438 sec)
3.355... logprob:  0.358099, 0.085938 (1.443 sec)
3.356... logprob:  0.479078, 0.132812 (1.482 sec)
3.357... logprob:  0.353815, 0.085938 (1.429 sec)
3.358... logprob:  0.330560, 0.070312 (1.445 sec)
3.359... logprob:  0.552914, 0.164062 (1.432 sec)
3.360... logprob:  0.444719, 0.117188 (1.429 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.59697723388672, 10.0]}, 128)
batch 872: ({'logprob': [65.96975708007812, 19.0]}, 128)
batch 873: ({'logprob': [41.68137741088867, 9.0]}, 128)
batch 874: ({'logprob': [45.951377868652344, 11.0]}, 128)
batch 875: ({'logprob': [51.195106506347656, 13.0]}, 128)
batch 876: ({'logprob': [63.59354782104492, 18.0]}, 128)
batch 877: ({'logprob': [46.43937301635742, 11.0]}, 128)
batch 878: ({'logprob': [61.69233322143555, 17.0]}, 128)
batch 879: ({'logprob': [72.66593170166016, 21.0]}, 128)
batch 880: ({'logprob': [51.199745178222656, 13.0]}, 128)
batch 881: ({'logprob': [30.695058822631836, 5.0]}, 128)
batch 882: ({'logprob': [55.03510665893555, 14.0]}, 128)
batch 883: ({'logprob': [61.68901443481445, 17.0]}, 128)
batch 884: ({'logprob': [51.67702102661133, 13.0]}, 128)
batch 885: ({'logprob': [52.649566650390625, 13.0]}, 128)
batch 886: ({'logprob': [62.17458724975586, 17.0]}, 128)

======================Test output======================
logprob:  0.418411, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.978090e-03 [1.419406e-09] 
Layer 'conv1' biases: 8.494548e-09 [2.382055e-11] 
Layer 'conv2' weights[0]: 7.965000e-03 [1.084843e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.713545e-11] 
Layer 'conv3' weights[0]: 7.963373e-03 [9.969959e-10] 
Layer 'conv3' biases: 1.348598e-07 [3.066230e-10] 
Layer 'conv4' weights[0]: 7.995869e-03 [1.053418e-09] 
Layer 'conv4' biases: 1.000000e+00 [2.611578e-09] 
Layer 'conv5' weights[0]: 7.994832e-03 [1.754906e-08] 
Layer 'conv5' biases: 9.999995e-01 [1.907167e-08] 
Layer 'fc6' weights[0]: 7.591628e-03 [1.988597e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.827539e-09] 
Layer 'fc7' weights[0]: 7.775051e-03 [4.713053e-08] 
Layer 'fc7' biases: 9.998863e-01 [2.161474e-08] 
Layer 'fc8' weights[0]: 8.489505e-04 [4.825575e-06] 
Layer 'fc8' biases: 2.466480e-03 [1.905791e-05] 
Train error last 870 batches: 0.437279
-------------------------------------------------------
Not saving because 0.418411 > 0.415720 (2.830: -0.06%)
======================================================= (12.104 sec)
3.361... logprob:  0.411396, 0.101562 (1.441 sec)
3.362... logprob:  0.425667, 0.117188 (1.484 sec)
3.363... logprob:  0.486268, 0.132812 (1.447 sec)
3.364... logprob:  0.475217, 0.125000 (1.452 sec)
3.365... logprob:  0.424521, 0.109375 (1.466 sec)
3.366... logprob:  0.409838, 0.109375 (1.447 sec)
3.367... logprob:  0.323031, 0.078125 (1.441 sec)
3.368... logprob:  0.600522, 0.171875 (1.429 sec)
3.369... logprob:  0.379558, 0.093750 (1.427 sec)
3.370... logprob:  0.379296, 0.093750 (1.438 sec)
3.371... logprob:  0.399451, 0.101562 (1.464 sec)
3.372... logprob:  0.542572, 0.156250 (1.454 sec)
3.373... logprob:  0.464477, 0.125000 (1.458 sec)
3.374... logprob:  0.528130, 0.148438 (1.449 sec)
3.375... logprob:  0.394260, 0.101562 (1.470 sec)
3.376... logprob:  0.375330, 0.093750 (1.439 sec)
3.377... logprob:  0.298144, 0.062500 (1.426 sec)
3.378... logprob:  0.453625, 0.125000 (1.432 sec)
3.379... logprob:  0.420482, 0.109375 (1.442 sec)
3.380... logprob:  0.602373, 0.179688 (1.440 sec)
3.381... logprob:  0.463231, 0.125000 (1.468 sec)
3.382... logprob:  0.528322, 0.148438 (1.457 sec)
3.383... logprob:  0.361458, 0.085938 (1.437 sec)
3.384... logprob:  0.519533, 0.148438 (1.486 sec)
3.385... logprob:  0.522809, 0.148438 (1.430 sec)
3.386... logprob:  0.580865, 0.171875 (1.424 sec)
3.387... logprob:  0.427683, 0.117188 (1.438 sec)
3.388... logprob:  0.521604, 0.148438 (1.439 sec)
3.389... logprob:  0.427762, 0.109375 (1.432 sec)
3.390... logprob:  0.419690, 0.109375 (1.483 sec)
3.391... logprob:  0.315313, 0.070312 (1.443 sec)
3.392... logprob:  0.437972, 0.117188 (1.436 sec)
3.393... logprob:  0.363245, 0.093750 (1.487 sec)
3.394... logprob:  0.340079, 0.078125 (1.438 sec)
3.395... logprob:  0.326499, 0.078125 (1.431 sec)
3.396... logprob:  0.244630, 0.046875 (1.439 sec)
3.397... logprob:  0.493349, 0.132812 (1.431 sec)
3.398... logprob:  0.481091, 0.125000 (1.447 sec)
3.399... logprob:  0.439910, 0.117188 (1.487 sec)
3.400... logprob:  0.549154, 0.148438 (1.431 sec)
3.401... logprob:  0.470303, 0.125000 (1.446 sec)
3.402... logprob:  0.476931, 0.125000 (1.483 sec)
3.403... logprob:  0.460772, 0.125000 (1.436 sec)
3.404... logprob:  0.475088, 0.125000 (1.434 sec)
3.405... logprob:  0.536168, 0.156250 (1.440 sec)
3.406... logprob:  0.366440, 0.085938 (1.427 sec)
3.407... logprob:  0.489642, 0.140625 (1.438 sec)
3.408... logprob:  0.354341, 0.078125 (1.481 sec)
3.409... logprob:  0.410223, 0.101562 (1.444 sec)
3.410... logprob:  0.579020, 0.171875 (1.447 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.82533645629883, 10.0]}, 128)
batch 872: ({'logprob': [65.63043212890625, 19.0]}, 128)
batch 873: ({'logprob': [43.85040283203125, 9.0]}, 128)
batch 874: ({'logprob': [47.35159683227539, 11.0]}, 128)
batch 875: ({'logprob': [52.27245330810547, 13.0]}, 128)
batch 876: ({'logprob': [63.52665710449219, 18.0]}, 128)
batch 877: ({'logprob': [48.06282043457031, 11.0]}, 128)
batch 878: ({'logprob': [62.121952056884766, 17.0]}, 128)
batch 879: ({'logprob': [72.67031860351562, 21.0]}, 128)
batch 880: ({'logprob': [52.27650833129883, 13.0]}, 128)
batch 881: ({'logprob': [33.289493560791016, 5.0]}, 128)
batch 882: ({'logprob': [56.505733489990234, 14.0]}, 128)
batch 883: ({'logprob': [62.11857223510742, 17.0]}, 128)
batch 884: ({'logprob': [52.97590255737305, 13.0]}, 128)
batch 885: ({'logprob': [54.392887115478516, 13.0]}, 128)
batch 886: ({'logprob': [62.825958251953125, 17.0]}, 128)

======================Test output======================
logprob:  0.426610, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.978052e-03 [1.216138e-09] 
Layer 'conv1' biases: 8.824102e-09 [3.197643e-11] 
Layer 'conv2' weights[0]: 7.964959e-03 [1.059202e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.448950e-10] 
Layer 'conv3' weights[0]: 7.963340e-03 [1.092060e-09] 
Layer 'conv3' biases: 1.379911e-07 [4.166948e-10] 
Layer 'conv4' weights[0]: 7.995827e-03 [1.130078e-09] 
Layer 'conv4' biases: 1.000000e+00 [3.668081e-09] 
Layer 'conv5' weights[0]: 7.994791e-03 [2.332308e-08] 
Layer 'conv5' biases: 9.999998e-01 [2.525736e-08] 
Layer 'fc6' weights[0]: 7.591591e-03 [2.564205e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.456523e-09] 
Layer 'fc7' weights[0]: 7.773051e-03 [6.781593e-08] 
Layer 'fc7' biases: 9.998852e-01 [4.906179e-08] 
Layer 'fc8' weights[0]: 8.324516e-04 [7.447529e-06] 
Layer 'fc8' biases: 2.453134e-03 [3.255083e-05] 
Train error last 870 batches: 0.437095
-------------------------------------------------------
Not saving because 0.426610 > 0.415720 (2.830: -0.06%)
======================================================= (12.086 sec)
3.411... logprob:  0.402834, 0.101562 (1.474 sec)
3.412... logprob:  0.540146, 0.156250 (1.442 sec)
3.413... logprob:  0.545145, 0.156250 (1.443 sec)
3.414... logprob:  0.465338, 0.125000 (1.433 sec)
3.415... logprob:  0.397866, 0.101562 (1.424 sec)
3.416... logprob:  0.422719, 0.109375 (1.436 sec)
3.417... logprob:  0.393835, 0.093750 (1.463 sec)
3.418... logprob:  0.374294, 0.093750 (1.453 sec)
3.419... logprob:  0.406867, 0.101562 (1.459 sec)
3.420... logprob:  0.351353, 0.085938 (1.456 sec)
3.421... logprob:  0.390248, 0.101562 (1.456 sec)
3.422... logprob:  0.539123, 0.148438 (1.443 sec)
3.423... logprob:  0.423443, 0.109375 (1.425 sec)
3.424... logprob:  0.326292, 0.078125 (1.434 sec)
3.425... logprob:  0.304420, 0.070312 (1.439 sec)
3.426... logprob:  0.448177, 0.117188 (1.445 sec)
3.427... logprob:  0.560017, 0.156250 (1.467 sec)
3.428... logprob:  0.601214, 0.171875 (1.456 sec)
3.429... logprob:  0.422483, 0.109375 (1.442 sec)
3.430... logprob:  0.307919, 0.070312 (1.481 sec)
3.431... logprob:  0.586350, 0.171875 (1.430 sec)
3.432... logprob:  0.391940, 0.093750 (1.431 sec)
3.433... logprob:  0.340951, 0.078125 (1.454 sec)
3.434... logprob:  0.525399, 0.148438 (1.435 sec)
3.435... logprob:  0.528169, 0.156250 (1.440 sec)
3.436... logprob:  0.387277, 0.093750 (1.476 sec)
3.437... logprob:  0.500201, 0.140625 (1.442 sec)
3.438... logprob:  0.547678, 0.156250 (1.431 sec)
3.439... logprob:  0.377803, 0.093750 (1.492 sec)
3.440... logprob:  0.438124, 0.117188 (1.434 sec)
3.441... logprob:  0.467894, 0.125000 (1.435 sec)
3.442... logprob:  0.372598, 0.093750 (1.442 sec)
3.443... logprob:  0.498053, 0.140625 (1.433 sec)
3.444... logprob:  0.365490, 0.093750 (1.437 sec)
3.445... logprob:  0.356708, 0.085938 (1.486 sec)
3.446... logprob:  0.396264, 0.101562 (1.435 sec)
3.447... logprob:  0.580729, 0.164062 (1.446 sec)
3.448... logprob:  0.329167, 0.078125 (1.478 sec)
3.449... logprob:  0.400726, 0.101562 (1.439 sec)
3.450... logprob:  0.234952, 0.046875 (1.433 sec)
3.451... logprob:  0.453900, 0.125000 (1.441 sec)
3.452... logprob:  0.457686, 0.117188 (1.428 sec)
3.453... logprob:  0.454212, 0.125000 (1.435 sec)
3.454... logprob:  0.486877, 0.132812 (1.487 sec)
3.455... logprob:  0.501195, 0.140625 (1.438 sec)
3.456... logprob:  0.466130, 0.125000 (1.449 sec)
3.457... logprob:  0.377745, 0.093750 (1.474 sec)
3.458... logprob:  0.355710, 0.085938 (1.441 sec)
3.459... logprob:  0.511289, 0.140625 (1.434 sec)
3.460... logprob:  0.285489, 0.054688 (1.439 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.28093338012695, 10.0]}, 128)
batch 872: ({'logprob': [65.92701721191406, 19.0]}, 128)
batch 873: ({'logprob': [41.67723846435547, 9.0]}, 128)
batch 874: ({'logprob': [45.82001495361328, 11.0]}, 128)
batch 875: ({'logprob': [51.13534927368164, 13.0]}, 128)
batch 876: ({'logprob': [63.56462097167969, 18.0]}, 128)
batch 877: ({'logprob': [46.40719223022461, 11.0]}, 128)
batch 878: ({'logprob': [61.77572250366211, 17.0]}, 128)
batch 879: ({'logprob': [72.99102783203125, 21.0]}, 128)
batch 880: ({'logprob': [51.139888763427734, 13.0]}, 128)
batch 881: ({'logprob': [30.447982788085938, 5.0]}, 128)
batch 882: ({'logprob': [55.25893783569336, 14.0]}, 128)
batch 883: ({'logprob': [61.772605895996094, 17.0]}, 128)
batch 884: ({'logprob': [51.715850830078125, 13.0]}, 128)
batch 885: ({'logprob': [52.88676071166992, 13.0]}, 128)
batch 886: ({'logprob': [62.35683059692383, 17.0]}, 128)

======================Test output======================
logprob:  0.418534, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.978015e-03 [1.919769e-09] 
Layer 'conv1' biases: 9.133832e-09 [5.889555e-11] 
Layer 'conv2' weights[0]: 7.964921e-03 [2.083385e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.715551e-10] 
Layer 'conv3' weights[0]: 7.963293e-03 [2.102236e-09] 
Layer 'conv3' biases: 1.405791e-07 [1.134869e-09] 
Layer 'conv4' weights[0]: 7.995790e-03 [2.344938e-09] 
Layer 'conv4' biases: 1.000000e+00 [1.127196e-08] 
Layer 'conv5' weights[0]: 7.994747e-03 [7.561429e-08] 
Layer 'conv5' biases: 1.000000e+00 [8.199608e-08] 
Layer 'fc6' weights[0]: 7.591551e-03 [7.695794e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.745467e-09] 
Layer 'fc7' weights[0]: 7.771106e-03 [4.324955e-08] 
Layer 'fc7' biases: 9.998843e-01 [1.492819e-08] 
Layer 'fc8' weights[0]: 8.937638e-04 [6.938045e-06] 
Layer 'fc8' biases: 2.844272e-03 [2.976193e-05] 
Train error last 870 batches: 0.436910
-------------------------------------------------------
Not saving because 0.418534 > 0.415720 (2.830: -0.06%)
======================================================= (12.078 sec)
3.461... logprob:  0.459572, 0.125000 (1.432 sec)
3.462... logprob:  0.472582, 0.125000 (1.449 sec)
3.463... logprob:  0.421621, 0.109375 (1.474 sec)
3.464... logprob:  0.482554, 0.132812 (1.451 sec)
3.465... logprob:  0.420714, 0.109375 (1.453 sec)
3.466... logprob:  0.315449, 0.070312 (1.488 sec)
3.467... logprob:  0.414370, 0.109375 (1.452 sec)
3.468... logprob:  0.394020, 0.101562 (1.439 sec)
3.469... logprob:  0.330583, 0.078125 (1.431 sec)
3.470... logprob:  0.398942, 0.101562 (1.431 sec)
3.471... logprob:  0.536394, 0.148438 (1.438 sec)
3.472... logprob:  0.414838, 0.109375 (1.457 sec)
3.473... logprob:  0.374792, 0.093750 (1.456 sec)
3.474... logprob:  0.467559, 0.125000 (1.456 sec)
3.475... logprob:  0.507861, 0.140625 (1.450 sec)
3.476... logprob:  0.510304, 0.140625 (1.468 sec)
3.477... logprob:  0.334887, 0.078125 (1.443 sec)
3.478... logprob:  0.463156, 0.125000 (1.424 sec)
3.479... logprob:  0.310524, 0.070312 (1.436 sec)
3.480... logprob:  0.443068, 0.117188 (1.436 sec)
3.481... logprob:  0.543798, 0.156250 (1.440 sec)
3.482... logprob:  0.443352, 0.117188 (1.473 sec)
3.483... logprob:  0.500869, 0.140625 (1.453 sec)
3.484... logprob:  0.484688, 0.132812 (1.438 sec)
3.485... logprob:  0.410797, 0.109375 (1.483 sec)
3.486... logprob:  0.364343, 0.085938 (1.436 sec)
3.487... logprob:  0.522226, 0.148438 (1.427 sec)
3.488... logprob:  0.425473, 0.109375 (1.440 sec)
3.489... logprob:  0.415310, 0.109375 (1.436 sec)
3.490... logprob:  0.440343, 0.117188 (1.444 sec)
3.491... logprob:  0.310097, 0.070312 (1.479 sec)
3.492... logprob:  0.460212, 0.125000 (1.445 sec)
3.493... logprob:  0.525358, 0.148438 (1.437 sec)
3.494... logprob:  0.450461, 0.125000 (1.496 sec)
3.495... logprob:  0.379783, 0.093750 (1.433 sec)
3.496... logprob:  0.554955, 0.156250 (1.435 sec)
3.497... logprob:  0.469179, 0.125000 (1.434 sec)
3.498... logprob:  0.476098, 0.132812 (1.435 sec)
3.499... logprob:  0.455641, 0.125000 (1.435 sec)
3.500... logprob:  0.355723, 0.085938 (1.491 sec)
3.501... logprob:  0.341895, 0.078125 (1.430 sec)
3.502... logprob:  0.459519, 0.125000 (1.451 sec)
3.503... logprob:  0.402341, 0.101562 (1.481 sec)
3.504... logprob:  0.487603, 0.132812 (1.438 sec)
3.505... logprob:  0.569392, 0.164062 (1.439 sec)
3.506... logprob:  0.478945, 0.132812 (1.437 sec)
3.507... logprob:  0.386844, 0.093750 (1.442 sec)
3.508... logprob:  0.375583, 0.093750 (1.434 sec)
3.509... logprob:  0.324105, 0.070312 (1.484 sec)
3.510... logprob:  0.391061, 0.101562 (1.440 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.833106994628906, 10.0]}, 128)
batch 872: ({'logprob': [66.78547668457031, 19.0]}, 128)
batch 873: ({'logprob': [40.36878967285156, 9.0]}, 128)
batch 874: ({'logprob': [45.19426727294922, 11.0]}, 128)
batch 875: ({'logprob': [50.775875091552734, 13.0]}, 128)
batch 876: ({'logprob': [64.18635559082031, 18.0]}, 128)
batch 877: ({'logprob': [45.57306671142578, 11.0]}, 128)
batch 878: ({'logprob': [61.951045989990234, 17.0]}, 128)
batch 879: ({'logprob': [73.49298858642578, 21.0]}, 128)
batch 880: ({'logprob': [50.781158447265625, 13.0]}, 128)
batch 881: ({'logprob': [28.812292098999023, 5.0]}, 128)
batch 882: ({'logprob': [54.51459503173828, 14.0]}, 128)
batch 883: ({'logprob': [61.947872161865234, 17.0]}, 128)
batch 884: ({'logprob': [51.14914321899414, 13.0]}, 128)
batch 885: ({'logprob': [51.905067443847656, 13.0]}, 128)
batch 886: ({'logprob': [62.324798583984375, 17.0]}, 128)

======================Test output======================
logprob:  0.415818, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.977972e-03 [1.962332e-09] 
Layer 'conv1' biases: 9.360241e-09 [5.604920e-11] 
Layer 'conv2' weights[0]: 7.964882e-03 [1.618138e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.850389e-10] 
Layer 'conv3' weights[0]: 7.963249e-03 [1.697528e-09] 
Layer 'conv3' biases: 1.421286e-07 [8.645906e-10] 
Layer 'conv4' weights[0]: 7.995754e-03 [1.888191e-09] 
Layer 'conv4' biases: 1.000000e+00 [8.435087e-09] 
Layer 'conv5' weights[0]: 7.994711e-03 [5.740326e-08] 
Layer 'conv5' biases: 1.000000e+00 [6.221682e-08] 
Layer 'fc6' weights[0]: 7.591521e-03 [5.751753e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.815609e-09] 
Layer 'fc7' weights[0]: 7.769119e-03 [1.350464e-07] 
Layer 'fc7' biases: 9.998843e-01 [1.206590e-07] 
Layer 'fc8' weights[0]: 9.297999e-04 [1.209660e-05] 
Layer 'fc8' biases: 3.064335e-03 [5.065194e-05] 
Train error last 870 batches: 0.436860
-------------------------------------------------------
Not saving because 0.415818 > 0.415720 (2.830: -0.06%)
======================================================= (12.142 sec)
3.511... logprob:  0.411199, 0.109375 (1.458 sec)
3.512... logprob:  0.470173, 0.125000 (1.472 sec)
3.513... logprob:  0.324969, 0.078125 (1.445 sec)
3.514... logprob:  0.404477, 0.101562 (1.438 sec)
3.515... logprob:  0.459371, 0.125000 (1.432 sec)
3.516... logprob:  0.405839, 0.109375 (1.424 sec)
3.517... logprob:  0.631230, 0.179688 (1.434 sec)
3.518... logprob:  0.438697, 0.117188 (1.461 sec)
3.519... logprob:  0.515395, 0.140625 (1.457 sec)
3.520... logprob:  0.410290, 0.109375 (1.452 sec)
3.521... logprob:  0.428024, 0.109375 (1.453 sec)
3.522... logprob:  0.531155, 0.156250 (1.456 sec)
3.523... logprob:  0.335692, 0.078125 (1.442 sec)
3.524... logprob:  0.438400, 0.117188 (1.425 sec)
3.525... logprob:  0.428954, 0.109375 (1.435 sec)
3.526... logprob:  0.357188, 0.078125 (1.437 sec)
3.527... logprob:  0.504684, 0.140625 (1.437 sec)
3.528... logprob:  0.440759, 0.117188 (1.473 sec)
3.529... logprob:  0.352141, 0.085938 (1.447 sec)
3.530... logprob:  0.440274, 0.117188 (1.444 sec)
3.531... logprob:  0.440462, 0.117188 (1.481 sec)
3.532... logprob:  0.468684, 0.125000 (1.435 sec)
3.533... logprob:  0.566532, 0.164062 (1.433 sec)
3.534... logprob:  0.323808, 0.078125 (1.433 sec)
3.535... logprob:  0.555019, 0.156250 (1.440 sec)
3.536... logprob:  0.508883, 0.140625 (1.432 sec)
3.537... logprob:  0.510596, 0.140625 (1.483 sec)
3.538... logprob:  0.485951, 0.132812 (1.441 sec)
3.539... logprob:  0.297782, 0.062500 (1.440 sec)
3.540... logprob:  0.447051, 0.117188 (1.519 sec)
3.541... logprob:  0.391286, 0.101562 (1.438 sec)
3.542... logprob:  0.413146, 0.109375 (1.428 sec)
3.543... logprob:  0.236944, 0.039062 (1.432 sec)
3.544... logprob:  0.318551, 0.070312 (1.431 sec)
3.545... logprob:  0.349466, 0.085938 (1.436 sec)
3.546... logprob:  0.369057, 0.093750 (1.482 sec)
3.547... logprob:  0.441681, 0.117188 (1.434 sec)
3.548... logprob:  0.456994, 0.125000 (1.439 sec)
3.549... logprob:  0.493568, 0.132812 (1.478 sec)
3.550... logprob:  0.368174, 0.093750 (1.430 sec)
3.551... logprob:  0.442734, 0.117188 (1.441 sec)
3.552... logprob:  0.472363, 0.125000 (1.434 sec)
3.553... logprob:  0.349621, 0.085938 (1.432 sec)
3.554... logprob:  0.505109, 0.140625 (1.432 sec)
3.555... logprob:  0.422367, 0.109375 (1.484 sec)
3.556... logprob:  0.359085, 0.085938 (1.439 sec)
3.557... logprob:  0.398214, 0.101562 (1.454 sec)
3.558... logprob:  0.381205, 0.101562 (1.470 sec)
3.559... logprob:  0.436590, 0.125000 (1.433 sec)
3.560... logprob:  0.339083, 0.078125 (1.439 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.706180572509766, 10.0]}, 128)
batch 872: ({'logprob': [65.99247741699219, 19.0]}, 128)
batch 873: ({'logprob': [41.8220100402832, 9.0]}, 128)
batch 874: ({'logprob': [45.67333221435547, 11.0]}, 128)
batch 875: ({'logprob': [51.15635681152344, 13.0]}, 128)
batch 876: ({'logprob': [63.66091537475586, 18.0]}, 128)
batch 877: ({'logprob': [46.48970413208008, 11.0]}, 128)
batch 878: ({'logprob': [62.132015228271484, 17.0]}, 128)
batch 879: ({'logprob': [73.9112319946289, 21.0]}, 128)
batch 880: ({'logprob': [51.16066360473633, 13.0]}, 128)
batch 881: ({'logprob': [30.02777099609375, 5.0]}, 128)
batch 882: ({'logprob': [55.93720626831055, 14.0]}, 128)
batch 883: ({'logprob': [62.12887191772461, 17.0]}, 128)
batch 884: ({'logprob': [51.96588134765625, 13.0]}, 128)
batch 885: ({'logprob': [53.59587097167969, 13.0]}, 128)
batch 886: ({'logprob': [62.94236373901367, 17.0]}, 128)

======================Test output======================
logprob:  0.420070, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.977936e-03 [1.868223e-09] 
Layer 'conv1' biases: 9.665866e-09 [5.451168e-11] 
Layer 'conv2' weights[0]: 7.964843e-03 [1.653880e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.019742e-10] 
Layer 'conv3' weights[0]: 7.963213e-03 [1.793414e-09] 
Layer 'conv3' biases: 1.460793e-07 [8.936074e-10] 
Layer 'conv4' weights[0]: 7.995722e-03 [2.012582e-09] 
Layer 'conv4' biases: 1.000000e+00 [9.048609e-09] 
Layer 'conv5' weights[0]: 7.994663e-03 [6.157389e-08] 
Layer 'conv5' biases: 1.000000e+00 [6.671678e-08] 
Layer 'fc6' weights[0]: 7.591474e-03 [6.152098e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.221674e-09] 
Layer 'fc7' weights[0]: 7.767151e-03 [6.324949e-08] 
Layer 'fc7' biases: 9.998834e-01 [4.285332e-08] 
Layer 'fc8' weights[0]: 9.368423e-04 [5.826589e-06] 
Layer 'fc8' biases: 3.144970e-03 [2.490927e-05] 
Train error last 870 batches: 0.436588
-------------------------------------------------------
Not saving because 0.420070 > 0.415720 (2.830: -0.06%)
======================================================= (12.011 sec)
3.561... logprob:  0.411603, 0.109375 (1.441 sec)
3.562... logprob:  0.504224, 0.140625 (1.427 sec)
3.563... logprob:  0.374408, 0.093750 (1.436 sec)
3.564... logprob:  0.466768, 0.132812 (1.466 sec)
3.565... logprob:  0.610614, 0.187500 (1.446 sec)
3.566... logprob:  0.374737, 0.093750 (1.456 sec)
3.567... logprob:  0.425384, 0.109375 (1.455 sec)
3.568... logprob:  0.497485, 0.140625 (1.452 sec)
3.569... logprob:  0.511155, 0.140625 (1.438 sec)
3.570... logprob:  0.543163, 0.164062 (1.432 sec)
3.571... logprob:  0.454801, 0.125000 (1.427 sec)
3.572... logprob:  0.502866, 0.140625 (1.444 sec)
3.573... logprob:  0.512827, 0.148438 (1.479 sec)
3.574... logprob:  0.429515, 0.109375 (1.462 sec)
3.575... logprob:  0.343739, 0.078125 (1.451 sec)
3.576... logprob:  0.427630, 0.109375 (1.441 sec)
3.577... logprob:  0.460649, 0.125000 (1.473 sec)
3.578... logprob:  0.334674, 0.078125 (1.433 sec)
3.579... logprob:  0.441171, 0.117188 (1.431 sec)
3.580... logprob:  0.548970, 0.156250 (1.434 sec)
3.581... logprob:  0.536737, 0.156250 (1.447 sec)
3.582... logprob:  0.443294, 0.125000 (1.439 sec)
3.583... logprob:  0.594256, 0.171875 (1.474 sec)
3.584... logprob:  0.470656, 0.132812 (1.451 sec)
3.585... logprob:  0.350860, 0.085938 (1.431 sec)
3.586... logprob:  0.314764, 0.070312 (1.492 sec)
3.587... logprob:  0.403678, 0.101562 (1.431 sec)
3.588... logprob:  0.421439, 0.117188 (1.436 sec)
3.589... logprob:  0.364135, 0.093750 (1.433 sec)
3.590... logprob:  0.522668, 0.148438 (1.427 sec)
3.591... logprob:  0.397683, 0.101562 (1.437 sec)
3.592... logprob:  0.455179, 0.125000 (1.484 sec)
3.593... logprob:  0.466445, 0.125000 (1.440 sec)
3.594... logprob:  0.353513, 0.085938 (1.440 sec)
3.595... logprob:  0.428161, 0.109375 (1.479 sec)
3.596... logprob:  0.461316, 0.125000 (1.431 sec)
3.597... logprob:  0.397119, 0.101562 (1.435 sec)
3.598... logprob:  0.396906, 0.101562 (1.438 sec)
3.599... logprob:  0.312011, 0.070312 (1.430 sec)
3.600... logprob:  0.340962, 0.085938 (1.431 sec)
3.601... logprob:  0.401375, 0.101562 (1.483 sec)
3.602... logprob:  0.286802, 0.062500 (1.437 sec)
3.603... logprob:  0.263191, 0.054688 (1.446 sec)
3.604... logprob:  0.406626, 0.101562 (1.480 sec)
3.605... logprob:  0.563842, 0.148438 (1.436 sec)
3.606... logprob:  0.296888, 0.070312 (1.442 sec)
3.607... logprob:  0.505052, 0.132812 (1.433 sec)
3.608... logprob:  0.357767, 0.085938 (1.425 sec)
3.609... logprob:  0.354427, 0.085938 (1.440 sec)
3.610... logprob:  0.494426, 0.132812 (1.472 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.71837615966797, 10.0]}, 128)
batch 872: ({'logprob': [68.65858459472656, 19.0]}, 128)
batch 873: ({'logprob': [39.26374435424805, 9.0]}, 128)
batch 874: ({'logprob': [44.95280838012695, 11.0]}, 128)
batch 875: ({'logprob': [50.95001983642578, 13.0]}, 128)
batch 876: ({'logprob': [65.7404556274414, 18.0]}, 128)
batch 877: ({'logprob': [45.1073112487793, 11.0]}, 128)
batch 878: ({'logprob': [62.95949935913086, 17.0]}, 128)
batch 879: ({'logprob': [75.11134338378906, 21.0]}, 128)
batch 880: ({'logprob': [50.95621109008789, 13.0]}, 128)
batch 881: ({'logprob': [27.09589958190918, 5.0]}, 128)
batch 882: ({'logprob': [54.339683532714844, 14.0]}, 128)
batch 883: ({'logprob': [62.9562873840332, 17.0]}, 128)
batch 884: ({'logprob': [51.100379943847656, 13.0]}, 128)
batch 885: ({'logprob': [51.40996170043945, 13.0]}, 128)
batch 886: ({'logprob': [63.11015701293945, 17.0]}, 128)

======================Test output======================
logprob:  0.417691, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.977896e-03 [1.881894e-09] 
Layer 'conv1' biases: 1.002757e-08 [6.524133e-11] 
Layer 'conv2' weights[0]: 7.964803e-03 [2.000366e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.765499e-10] 
Layer 'conv3' weights[0]: 7.963174e-03 [2.012280e-09] 
Layer 'conv3' biases: 1.494900e-07 [1.159986e-09] 
Layer 'conv4' weights[0]: 7.995684e-03 [2.316240e-09] 
Layer 'conv4' biases: 1.000000e+00 [1.178589e-08] 
Layer 'conv5' weights[0]: 7.994631e-03 [7.994794e-08] 
Layer 'conv5' biases: 1.000000e+00 [8.673384e-08] 
Layer 'fc6' weights[0]: 7.591434e-03 [8.055785e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.105098e-09] 
Layer 'fc7' weights[0]: 7.765178e-03 [2.259696e-07] 
Layer 'fc7' biases: 9.998837e-01 [2.136304e-07] 
Layer 'fc8' weights[0]: 1.000931e-03 [1.800534e-05] 
Layer 'fc8' biases: 3.526558e-03 [7.443450e-05] 
Train error last 870 batches: 0.436320
-------------------------------------------------------
Not saving because 0.417691 > 0.415720 (2.830: -0.06%)
======================================================= (12.077 sec)
3.611... logprob:  0.513492, 0.140625 (1.456 sec)
3.612... logprob:  0.445042, 0.117188 (1.464 sec)
3.613... logprob:  0.287219, 0.062500 (1.457 sec)
3.614... logprob:  0.505490, 0.140625 (1.453 sec)
3.615... logprob:  0.357024, 0.085938 (1.441 sec)
3.616... logprob:  0.419969, 0.109375 (1.428 sec)
3.617... logprob:  0.420743, 0.109375 (1.431 sec)
3.618... logprob:  0.544378, 0.156250 (1.437 sec)
3.619... logprob:  0.504410, 0.140625 (1.457 sec)
3.620... logprob:  0.539626, 0.156250 (1.460 sec)
3.621... logprob:  0.366017, 0.085938 (1.456 sec)
3.622... logprob:  0.366302, 0.085938 (1.446 sec)
3.623... logprob:  0.423337, 0.109375 (1.471 sec)
3.624... logprob:  0.381803, 0.093750 (1.436 sec)
3.625... logprob:  0.440535, 0.117188 (1.420 sec)
3.626... logprob:  0.437680, 0.117188 (1.438 sec)
3.627... logprob:  0.434829, 0.117188 (1.437 sec)
3.628... logprob:  0.467121, 0.125000 (1.436 sec)
3.629... logprob:  0.369243, 0.093750 (1.477 sec)
3.630... logprob:  0.423858, 0.109375 (1.449 sec)
3.631... logprob:  0.645849, 0.187500 (1.438 sec)
3.632... logprob:  0.399789, 0.101562 (1.487 sec)
3.633... logprob:  0.375826, 0.093750 (1.431 sec)
3.634... logprob:  0.662473, 0.195312 (1.433 sec)
3.635... logprob:  0.373633, 0.093750 (1.436 sec)
3.636... logprob:  0.478817, 0.132812 (1.432 sec)
3.637... logprob:  0.331341, 0.078125 (1.431 sec)
3.638... logprob:  0.520408, 0.140625 (1.483 sec)
3.639... logprob:  0.418913, 0.109375 (1.445 sec)
3.640... logprob:  0.529982, 0.148438 (1.437 sec)
3.641... logprob:  0.408888, 0.109375 (1.486 sec)
3.642... logprob:  0.500237, 0.140625 (1.434 sec)
3.643... logprob:  0.621033, 0.187500 (1.435 sec)
3.644... logprob:  0.323123, 0.070312 (1.440 sec)
3.645... logprob:  0.413604, 0.109375 (1.429 sec)
3.646... logprob:  0.386283, 0.093750 (1.438 sec)
3.647... logprob:  0.456147, 0.125000 (1.516 sec)
3.648... logprob:  0.490879, 0.140625 (1.440 sec)
3.649... logprob:  0.367769, 0.093750 (1.441 sec)
3.650... logprob:  0.412920, 0.109375 (1.476 sec)
3.651... logprob:  0.396662, 0.101562 (1.429 sec)
3.652... logprob:  0.510006, 0.140625 (1.444 sec)
3.653... logprob:  0.551239, 0.156250 (1.432 sec)
3.654... logprob:  0.496551, 0.140625 (1.428 sec)
3.655... logprob:  0.436126, 0.117188 (1.436 sec)
3.656... logprob:  0.416684, 0.109375 (1.480 sec)
3.657... logprob:  0.451545, 0.117188 (1.444 sec)
3.658... logprob:  0.345273, 0.085938 (1.456 sec)
3.659... logprob:  0.465262, 0.125000 (1.471 sec)
3.660... logprob:  0.443973, 0.125000 (1.439 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.8245735168457, 10.0]}, 128)
batch 872: ({'logprob': [66.01642608642578, 19.0]}, 128)
batch 873: ({'logprob': [41.54050064086914, 9.0]}, 128)
batch 874: ({'logprob': [45.595802307128906, 11.0]}, 128)
batch 875: ({'logprob': [51.04415512084961, 13.0]}, 128)
batch 876: ({'logprob': [63.64277648925781, 18.0]}, 128)
batch 877: ({'logprob': [46.29304504394531, 11.0]}, 128)
batch 878: ({'logprob': [61.95145797729492, 17.0]}, 128)
batch 879: ({'logprob': [73.54267120361328, 21.0]}, 128)
batch 880: ({'logprob': [51.04889678955078, 13.0]}, 128)
batch 881: ({'logprob': [29.933671951293945, 5.0]}, 128)
batch 882: ({'logprob': [55.509796142578125, 14.0]}, 128)
batch 883: ({'logprob': [61.94816207885742, 17.0]}, 128)
batch 884: ({'logprob': [51.73427200317383, 13.0]}, 128)
batch 885: ({'logprob': [53.12562561035156, 13.0]}, 128)
batch 886: ({'logprob': [62.64234161376953, 17.0]}, 128)

======================Test output======================
logprob:  0.418649, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.977855e-03 [1.189821e-09] 
Layer 'conv1' biases: 1.036164e-08 [1.484299e-11] 
Layer 'conv2' weights[0]: 7.964762e-03 [1.007238e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.334466e-11] 
Layer 'conv3' weights[0]: 7.963133e-03 [9.082946e-10] 
Layer 'conv3' biases: 1.525260e-07 [1.846155e-10] 
Layer 'conv4' weights[0]: 7.995646e-03 [9.182871e-10] 
Layer 'conv4' biases: 1.000000e+00 [1.108428e-09] 
Layer 'conv5' weights[0]: 7.994584e-03 [7.144322e-09] 
Layer 'conv5' biases: 1.000000e+00 [7.524398e-09] 
Layer 'fc6' weights[0]: 7.591392e-03 [1.083697e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.318424e-10] 
Layer 'fc7' weights[0]: 7.763188e-03 [4.249312e-08] 
Layer 'fc7' biases: 9.998820e-01 [1.435115e-08] 
Layer 'fc8' weights[0]: 9.560615e-04 [3.606770e-06] 
Layer 'fc8' biases: 3.375160e-03 [1.527593e-05] 
Train error last 870 batches: 0.436247
-------------------------------------------------------
Not saving because 0.418649 > 0.415720 (2.830: -0.06%)
======================================================= (12.166 sec)
3.661... logprob:  0.380250, 0.093750 (1.439 sec)
3.662... logprob:  0.467748, 0.132812 (1.438 sec)
3.663... logprob:  0.312784, 0.070312 (1.420 sec)
3.664... logprob:  0.286511, 0.062500 (1.440 sec)
3.665... logprob:  0.402916, 0.101562 (1.463 sec)
3.666... logprob:  0.442591, 0.117188 (1.455 sec)
3.667... logprob:  0.565776, 0.164062 (1.457 sec)
3.668... logprob:  0.498993, 0.140625 (1.453 sec)
3.669... logprob:  0.434150, 0.109375 (1.464 sec)
3.670... logprob:  0.362595, 0.085938 (1.441 sec)
3.671... logprob:  0.360564, 0.093750 (1.426 sec)
3.672... logprob:  0.441959, 0.117188 (1.433 sec)
3.673... logprob:  0.436446, 0.117188 (1.439 sec)
3.674... logprob:  0.446533, 0.117188 (1.442 sec)
3.675... logprob:  0.357296, 0.093750 (1.471 sec)
3.676... logprob:  0.450568, 0.125000 (1.454 sec)
3.677... logprob:  0.470461, 0.125000 (1.443 sec)
3.678... logprob:  0.465131, 0.125000 (1.480 sec)
3.679... logprob:  0.454948, 0.125000 (1.435 sec)
3.680... logprob:  0.351544, 0.078125 (1.457 sec)
3.681... logprob:  0.374543, 0.093750 (1.431 sec)
3.682... logprob:  0.340138, 0.078125 (1.438 sec)
3.683... logprob:  0.412380, 0.109375 (1.428 sec)
3.684... logprob:  0.356413, 0.085938 (1.487 sec)
3.685... logprob:  0.280375, 0.054688 (1.444 sec)
3.686... logprob:  0.314221, 0.070312 (1.428 sec)
3.687... logprob:  0.279858, 0.062500 (1.490 sec)
3.688... logprob:  0.324290, 0.078125 (1.431 sec)
3.689... logprob:  0.476610, 0.125000 (1.427 sec)
3.690... logprob:  0.532644, 0.140625 (1.440 sec)
3.691... logprob:  0.526907, 0.140625 (1.433 sec)
3.692... logprob:  0.395093, 0.101562 (1.435 sec)
3.693... logprob:  0.465189, 0.125000 (1.487 sec)
3.694... logprob:  0.329681, 0.078125 (1.439 sec)
3.695... logprob:  0.355345, 0.085938 (1.440 sec)
3.696... logprob:  0.534888, 0.148438 (1.484 sec)
3.697... logprob:  0.463859, 0.125000 (1.432 sec)
3.698... logprob:  0.544979, 0.156250 (1.438 sec)
3.699... logprob:  0.459727, 0.125000 (1.436 sec)
3.700... logprob:  0.436151, 0.117188 (1.428 sec)
3.701... logprob:  0.426658, 0.109375 (1.432 sec)
3.702... logprob:  0.521403, 0.148438 (1.482 sec)
3.703... logprob:  0.409152, 0.101562 (1.439 sec)
3.704... logprob:  0.408772, 0.101562 (1.450 sec)
3.705... logprob:  0.420504, 0.109375 (1.478 sec)
3.706... logprob:  0.468518, 0.125000 (1.435 sec)
3.707... logprob:  0.485631, 0.132812 (1.439 sec)
3.708... logprob:  0.414870, 0.109375 (1.435 sec)
3.709... logprob:  0.421023, 0.109375 (1.427 sec)
3.710... logprob:  0.609349, 0.179688 (1.438 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.745426177978516, 10.0]}, 128)
batch 872: ({'logprob': [66.57483673095703, 19.0]}, 128)
batch 873: ({'logprob': [40.58171463012695, 9.0]}, 128)
batch 874: ({'logprob': [45.222232818603516, 11.0]}, 128)
batch 875: ({'logprob': [50.78539276123047, 13.0]}, 128)
batch 876: ({'logprob': [64.02667236328125, 18.0]}, 128)
batch 877: ({'logprob': [45.684234619140625, 11.0]}, 128)
batch 878: ({'logprob': [61.9240837097168, 17.0]}, 128)
batch 879: ({'logprob': [73.51172637939453, 21.0]}, 128)
batch 880: ({'logprob': [50.790740966796875, 13.0]}, 128)
batch 881: ({'logprob': [28.977951049804688, 5.0]}, 128)
batch 882: ({'logprob': [54.72228240966797, 14.0]}, 128)
batch 883: ({'logprob': [61.92086410522461, 17.0]}, 128)
batch 884: ({'logprob': [51.24087142944336, 13.0]}, 128)
batch 885: ({'logprob': [52.162811279296875, 13.0]}, 128)
batch 886: ({'logprob': [62.380306243896484, 17.0]}, 128)

======================Test output======================
logprob:  0.416139, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.977817e-03 [2.273354e-09] 
Layer 'conv1' biases: 1.060297e-08 [4.187201e-11] 
Layer 'conv2' weights[0]: 7.964724e-03 [1.869840e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.045533e-10] 
Layer 'conv3' weights[0]: 7.963098e-03 [1.762161e-09] 
Layer 'conv3' biases: 1.542283e-07 [9.951386e-10] 
Layer 'conv4' weights[0]: 7.995604e-03 [1.947974e-09] 
Layer 'conv4' biases: 9.999999e-01 [9.723111e-09] 
Layer 'conv5' weights[0]: 7.994546e-03 [6.629974e-08] 
Layer 'conv5' biases: 1.000000e+00 [7.181681e-08] 
Layer 'fc6' weights[0]: 7.591346e-03 [6.492126e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.568265e-09] 
Layer 'fc7' weights[0]: 7.761231e-03 [6.357502e-08] 
Layer 'fc7' biases: 9.998814e-01 [4.333920e-08] 
Layer 'fc8' weights[0]: 9.832312e-04 [5.309034e-06] 
Layer 'fc8' biases: 3.624235e-03 [2.697022e-05] 
Train error last 870 batches: 0.436193
-------------------------------------------------------
Not saving because 0.416139 > 0.415720 (2.830: -0.06%)
======================================================= (12.078 sec)
3.711... logprob:  0.470975, 0.125000 (1.473 sec)
3.712... logprob:  0.336427, 0.078125 (1.455 sec)
3.713... logprob:  0.593815, 0.179688 (1.478 sec)
3.714... logprob:  0.467393, 0.125000 (1.458 sec)
3.715... logprob:  0.416808, 0.109375 (1.459 sec)
3.716... logprob:  0.334247, 0.078125 (1.440 sec)
3.717... logprob:  0.429545, 0.117188 (1.425 sec)
3.718... logprob:  0.490708, 0.132812 (1.430 sec)
3.719... logprob:  0.405663, 0.109375 (1.440 sec)
3.720... logprob:  0.432582, 0.117188 (1.453 sec)
3.721... logprob:  0.452635, 0.117188 (1.460 sec)
3.722... logprob:  0.533153, 0.156250 (1.457 sec)
3.723... logprob:  0.417108, 0.109375 (1.453 sec)
3.724... logprob:  0.412867, 0.109375 (1.476 sec)
3.725... logprob:  0.492373, 0.140625 (1.436 sec)
3.726... logprob:  0.338307, 0.085938 (1.431 sec)
3.727... logprob:  0.394177, 0.101562 (1.432 sec)
3.728... logprob:  0.423032, 0.109375 (1.442 sec)
3.729... logprob:  0.391369, 0.093750 (1.434 sec)
3.730... logprob:  0.566501, 0.164062 (1.479 sec)
3.731... logprob:  0.449149, 0.125000 (1.446 sec)
3.732... logprob:  0.310566, 0.070312 (1.444 sec)
3.733... logprob:  0.561094, 0.156250 (1.488 sec)
3.734... logprob:  0.339939, 0.078125 (1.433 sec)
3.735... logprob:  0.530598, 0.148438 (1.432 sec)
3.736... logprob:  0.649113, 0.187500 (1.440 sec)
3.737... logprob:  0.517619, 0.148438 (1.434 sec)
3.738... logprob:  0.459608, 0.125000 (1.435 sec)
3.739... logprob:  0.477924, 0.132812 (1.486 sec)
3.740... logprob:  0.339126, 0.078125 (1.437 sec)
3.741... logprob:  0.393681, 0.101562 (1.444 sec)
3.742... logprob:  0.419959, 0.109375 (1.480 sec)
3.743... logprob:  0.364838, 0.085938 (1.440 sec)
3.744... logprob:  0.519355, 0.148438 (1.431 sec)
3.745... logprob:  0.478399, 0.132812 (1.437 sec)
3.746... logprob:  0.440345, 0.117188 (1.431 sec)
3.747... logprob:  0.424513, 0.109375 (1.435 sec)
3.748... logprob:  0.377575, 0.093750 (1.489 sec)
3.749... logprob:  0.420281, 0.109375 (1.437 sec)
3.750... logprob:  0.511533, 0.140625 (1.444 sec)
3.751... logprob:  0.263488, 0.054688 (1.481 sec)
3.752... logprob:  0.518897, 0.140625 (1.436 sec)
3.753... logprob:  0.441640, 0.117188 (1.439 sec)
3.754... logprob:  0.475412, 0.132812 (1.465 sec)
3.755... logprob:  0.507927, 0.140625 (1.431 sec)
3.756... logprob:  0.440972, 0.117188 (1.435 sec)
3.757... logprob:  0.550928, 0.156250 (1.472 sec)
3.758... logprob:  0.395273, 0.101562 (1.442 sec)
3.759... logprob:  0.460014, 0.125000 (1.452 sec)
3.760... logprob:  0.484402, 0.132812 (1.468 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.066612243652344, 10.0]}, 128)
batch 872: ({'logprob': [66.13567352294922, 19.0]}, 128)
batch 873: ({'logprob': [41.692970275878906, 9.0]}, 128)
batch 874: ({'logprob': [46.16468048095703, 11.0]}, 128)
batch 875: ({'logprob': [51.32389831542969, 13.0]}, 128)
batch 876: ({'logprob': [63.730682373046875, 18.0]}, 128)
batch 877: ({'logprob': [46.50991439819336, 11.0]}, 128)
batch 878: ({'logprob': [61.654075622558594, 17.0]}, 128)
batch 879: ({'logprob': [72.31590270996094, 21.0]}, 128)
batch 880: ({'logprob': [51.32941818237305, 13.0]}, 128)
batch 881: ({'logprob': [31.01569366455078, 5.0]}, 128)
batch 882: ({'logprob': [54.763572692871094, 14.0]}, 128)
batch 883: ({'logprob': [61.650550842285156, 17.0]}, 128)
batch 884: ({'logprob': [51.66102981567383, 13.0]}, 128)
batch 885: ({'logprob': [52.346805572509766, 13.0]}, 128)
batch 886: ({'logprob': [61.99191665649414, 17.0]}, 128)

======================Test output======================
logprob:  0.418630, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.977776e-03 [1.428093e-09] 
Layer 'conv1' biases: 1.108423e-08 [2.115515e-11] 
Layer 'conv2' weights[0]: 7.964696e-03 [1.141310e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.408501e-11] 
Layer 'conv3' weights[0]: 7.963051e-03 [1.005338e-09] 
Layer 'conv3' biases: 1.598052e-07 [2.836646e-10] 
Layer 'conv4' weights[0]: 7.995564e-03 [1.029592e-09] 
Layer 'conv4' biases: 9.999999e-01 [2.115949e-09] 
Layer 'conv5' weights[0]: 7.994506e-03 [1.446101e-08] 
Layer 'conv5' biases: 1.000001e+00 [1.570680e-08] 
Layer 'fc6' weights[0]: 7.591310e-03 [1.622176e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.430661e-09] 
Layer 'fc7' weights[0]: 7.759236e-03 [1.621215e-07] 
Layer 'fc7' biases: 9.998797e-01 [1.498700e-07] 
Layer 'fc8' weights[0]: 9.487337e-04 [1.079370e-05] 
Layer 'fc8' biases: 3.530010e-03 [4.754661e-05] 
Train error last 870 batches: 0.436127
-------------------------------------------------------
Not saving because 0.418630 > 0.415720 (2.830: -0.06%)
======================================================= (12.086 sec)
3.761... logprob:  0.419795, 0.109375 (1.455 sec)
3.762... logprob:  0.516151, 0.148438 (1.451 sec)
3.763... logprob:  0.557897, 0.164062 (1.425 sec)
3.764... logprob:  0.503285, 0.140625 (1.429 sec)
3.765... logprob:  0.315310, 0.062500 (1.445 sec)
3.766... logprob:  0.482616, 0.132812 (1.449 sec)
3.767... logprob:  0.371729, 0.085938 (1.455 sec)
3.768... logprob:  0.432365, 0.117188 (1.465 sec)
3.769... logprob:  0.490933, 0.140625 (1.471 sec)
3.770... logprob:  0.402022, 0.101562 (1.482 sec)
3.771... logprob:  0.552114, 0.156250 (1.460 sec)
3.772... logprob:  0.413255, 0.109375 (1.448 sec)
3.773... logprob:  0.560379, 0.164062 (1.444 sec)
3.774... logprob:  0.360840, 0.085938 (1.458 sec)
3.775... logprob:  0.408263, 0.101562 (1.463 sec)
3.776... logprob:  0.432832, 0.117188 (1.479 sec)
3.777... logprob:  0.380132, 0.093750 (1.478 sec)
3.778... logprob:  0.433176, 0.117188 (1.471 sec)
3.779... logprob:  0.505895, 0.140625 (1.489 sec)
3.780... logprob:  0.384655, 0.101562 (1.459 sec)
3.781... logprob:  0.372251, 0.085938 (1.445 sec)
3.782... logprob:  0.351943, 0.085938 (1.454 sec)
3.783... logprob:  0.554775, 0.156250 (1.462 sec)
3.784... logprob:  0.440784, 0.117188 (1.454 sec)
3.785... logprob:  0.541731, 0.156250 (1.498 sec)
3.786... logprob:  0.476283, 0.132812 (1.470 sec)
3.787... logprob:  0.544669, 0.156250 (1.464 sec)
3.788... logprob:  0.561051, 0.164062 (1.493 sec)
3.789... logprob:  0.285699, 0.054688 (1.458 sec)
3.790... logprob:  0.410812, 0.101562 (1.448 sec)
3.791... logprob:  0.399255, 0.101562 (1.450 sec)
3.792... logprob:  0.362379, 0.085938 (1.461 sec)
3.793... logprob:  0.370972, 0.085938 (1.457 sec)
3.794... logprob:  0.386559, 0.093750 (1.487 sec)
3.795... logprob:  0.469877, 0.125000 (1.472 sec)
3.796... logprob:  0.422968, 0.109375 (1.456 sec)
3.797... logprob:  0.356455, 0.085938 (1.503 sec)
3.798... logprob:  0.394575, 0.101562 (1.450 sec)
3.799... logprob:  0.329947, 0.078125 (1.453 sec)
3.800... logprob:  0.373604, 0.093750 (1.448 sec)
3.801... logprob:  0.451198, 0.117188 (1.464 sec)
3.802... logprob:  0.425196, 0.109375 (1.452 sec)
3.803... logprob:  0.496855, 0.132812 (1.496 sec)
3.804... logprob:  0.351288, 0.085938 (1.461 sec)
3.805... logprob:  0.449595, 0.117188 (1.453 sec)
3.806... logprob:  0.423142, 0.109375 (1.501 sec)
3.807... logprob:  0.443869, 0.117188 (1.454 sec)
3.808... logprob:  0.464051, 0.125000 (1.452 sec)
3.809... logprob:  0.591110, 0.171875 (1.451 sec)
3.810... logprob:  0.442217, 0.117188 (1.459 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.2953987121582, 10.0]}, 128)
batch 872: ({'logprob': [66.60973358154297, 19.0]}, 128)
batch 873: ({'logprob': [41.2795524597168, 9.0]}, 128)
batch 874: ({'logprob': [46.14302062988281, 11.0]}, 128)
batch 875: ({'logprob': [51.33633041381836, 13.0]}, 128)
batch 876: ({'logprob': [64.09867095947266, 18.0]}, 128)
batch 877: ({'logprob': [46.30956268310547, 11.0]}, 128)
batch 878: ({'logprob': [61.736045837402344, 17.0]}, 128)
batch 879: ({'logprob': [72.2887954711914, 21.0]}, 128)
batch 880: ({'logprob': [51.34245300292969, 13.0]}, 128)
batch 881: ({'logprob': [30.711109161376953, 5.0]}, 128)
batch 882: ({'logprob': [54.3472785949707, 14.0]}, 128)
batch 883: ({'logprob': [61.73247528076172, 17.0]}, 128)
batch 884: ({'logprob': [51.49504852294922, 13.0]}, 128)
batch 885: ({'logprob': [51.82371520996094, 13.0]}, 128)
batch 886: ({'logprob': [61.89537811279297, 17.0]}, 128)

======================Test output======================
logprob:  0.418186, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.977733e-03 [1.798905e-09] 
Layer 'conv1' biases: 1.153824e-08 [4.713941e-11] 
Layer 'conv2' weights[0]: 7.964656e-03 [1.791192e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.814979e-10] 
Layer 'conv3' weights[0]: 7.963016e-03 [1.777042e-09] 
Layer 'conv3' biases: 1.647818e-07 [8.846635e-10] 
Layer 'conv4' weights[0]: 7.995524e-03 [1.962427e-09] 
Layer 'conv4' biases: 1.000000e+00 [8.264847e-09] 
Layer 'conv5' weights[0]: 7.994472e-03 [5.558298e-08] 
Layer 'conv5' biases: 1.000001e+00 [6.039236e-08] 
Layer 'fc6' weights[0]: 7.591265e-03 [5.442754e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.505586e-09] 
Layer 'fc7' weights[0]: 7.757261e-03 [3.262473e-07] 
Layer 'fc7' biases: 9.998791e-01 [3.145362e-07] 
Layer 'fc8' weights[0]: 9.653175e-04 [2.158371e-05] 
Layer 'fc8' biases: 3.706498e-03 [9.585222e-05] 
Train error last 870 batches: 0.436116
-------------------------------------------------------
Not saving because 0.418186 > 0.415720 (2.830: -0.06%)
======================================================= (12.025 sec)
3.811... logprob:  0.461330, 0.125000 (1.463 sec)
3.812... logprob:  0.463327, 0.125000 (1.500 sec)
3.813... logprob:  0.486288, 0.132812 (1.456 sec)
3.814... logprob:  0.479737, 0.132812 (1.454 sec)
3.815... logprob:  0.376685, 0.085938 (1.499 sec)
3.816... logprob:  0.411287, 0.101562 (1.458 sec)
3.817... logprob:  0.427038, 0.109375 (1.451 sec)
3.818... logprob:  0.560133, 0.164062 (1.451 sec)
3.819... logprob:  0.497808, 0.140625 (1.477 sec)
3.820... logprob:  0.419987, 0.109375 (1.452 sec)
3.821... logprob:  0.405292, 0.101562 (1.496 sec)
3.822... logprob:  0.440291, 0.117188 (1.132 sec)
3.823... logprob:  0.337418, 0.078125 (1.151 sec)
3.824... logprob:  0.493242, 0.132812 (0.707 sec)
3.825... logprob:  0.282988, 0.062500 (0.689 sec)
3.826... logprob:  0.374777, 0.093750 (0.689 sec)
3.827... logprob:  0.421870, 0.109375 (0.692 sec)
3.828... logprob:  0.445493, 0.117188 (0.687 sec)
3.829... logprob:  0.506730, 0.140625 (0.687 sec)
3.830... logprob:  0.442945, 0.117188 (1.512 sec)
3.831... logprob:  0.514285, 0.140625 (1.451 sec)
3.832... logprob:  0.331624, 0.078125 (1.463 sec)
3.833... logprob:  0.487638, 0.132812 (1.495 sec)
3.834... logprob:  0.430649, 0.117188 (1.456 sec)
3.835... logprob:  0.542384, 0.148438 (1.459 sec)
3.836... logprob:  0.378370, 0.093750 (1.450 sec)
3.837... logprob:  0.319526, 0.070312 (1.452 sec)
3.838... logprob:  0.437038, 0.117188 (1.456 sec)
3.839... logprob:  0.474084, 0.125000 (1.501 sec)
3.840... logprob:  0.555737, 0.156250 (1.458 sec)
3.841... logprob:  0.397011, 0.101562 (1.464 sec)
3.842... logprob:  0.497385, 0.140625 (1.495 sec)
3.843... logprob:  0.465771, 0.125000 (1.452 sec)
3.844... logprob:  0.497715, 0.140625 (1.460 sec)
3.845... logprob:  0.486833, 0.132812 (1.452 sec)
3.846... logprob:  0.467836, 0.125000 (1.447 sec)
3.847... logprob:  0.361161, 0.085938 (1.449 sec)
3.848... logprob:  0.396462, 0.101562 (1.501 sec)
3.849... logprob:  0.358253, 0.085938 (1.456 sec)
3.850... logprob:  0.480790, 0.132812 (1.471 sec)
3.851... logprob:  0.440505, 0.117188 (1.489 sec)
3.852... logprob:  0.548722, 0.156250 (1.457 sec)
3.853... logprob:  0.372108, 0.093750 (1.461 sec)
3.854... logprob:  0.306597, 0.070312 (1.450 sec)
3.855... logprob:  0.485773, 0.132812 (1.446 sec)
3.856... logprob:  0.443881, 0.117188 (1.458 sec)
3.857... logprob:  0.372564, 0.093750 (1.492 sec)
3.858... logprob:  0.396296, 0.101562 (1.463 sec)
3.859... logprob:  0.308571, 0.070312 (1.476 sec)
3.860... logprob:  0.564277, 0.156250 (1.482 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.36901092529297, 10.0]}, 128)
batch 872: ({'logprob': [67.44348907470703, 19.0]}, 128)
batch 873: ({'logprob': [39.847225189208984, 9.0]}, 128)
batch 874: ({'logprob': [44.884735107421875, 11.0]}, 128)
batch 875: ({'logprob': [50.71652603149414, 13.0]}, 128)
batch 876: ({'logprob': [64.72940063476562, 18.0]}, 128)
batch 877: ({'logprob': [45.282222747802734, 11.0]}, 128)
batch 878: ({'logprob': [62.39453125, 17.0]}, 128)
batch 879: ({'logprob': [74.45647430419922, 21.0]}, 128)
batch 880: ({'logprob': [50.72248840332031, 13.0]}, 128)
batch 881: ({'logprob': [27.767440795898438, 5.0]}, 128)
batch 882: ({'logprob': [54.62898254394531, 14.0]}, 128)
batch 883: ({'logprob': [62.391326904296875, 17.0]}, 128)
batch 884: ({'logprob': [51.10799026489258, 13.0]}, 128)
batch 885: ({'logprob': [51.90258026123047, 13.0]}, 128)
batch 886: ({'logprob': [62.786888122558594, 17.0]}, 128)

======================Test output======================
logprob:  0.416226, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.977694e-03 [2.503304e-09] 
Layer 'conv1' biases: 1.174203e-08 [4.616385e-11] 
Layer 'conv2' weights[0]: 7.964615e-03 [1.926637e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.302462e-10] 
Layer 'conv3' weights[0]: 7.962976e-03 [1.802353e-09] 
Layer 'conv3' biases: 1.652956e-07 [1.033315e-09] 
Layer 'conv4' weights[0]: 7.995481e-03 [1.968206e-09] 
Layer 'conv4' biases: 1.000000e+00 [9.978199e-09] 
Layer 'conv5' weights[0]: 7.994420e-03 [6.816829e-08] 
Layer 'conv5' biases: 1.000001e+00 [7.393146e-08] 
Layer 'fc6' weights[0]: 7.591226e-03 [6.594730e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.663232e-09] 
Layer 'fc7' weights[0]: 7.755278e-03 [6.436812e-08] 
Layer 'fc7' biases: 9.998795e-01 [4.542702e-08] 
Layer 'fc8' weights[0]: 1.051112e-03 [2.633617e-06] 
Layer 'fc8' biases: 4.250349e-03 [1.109251e-05] 
Train error last 870 batches: 0.436103
-------------------------------------------------------
Not saving because 0.416226 > 0.415720 (2.830: -0.06%)
======================================================= (12.044 sec)
3.861... logprob:  0.417506, 0.109375 (1.470 sec)
3.862... logprob:  0.329779, 0.078125 (1.465 sec)
3.863... logprob:  0.399434, 0.101562 (1.449 sec)
3.864... logprob:  0.451024, 0.117188 (1.447 sec)
3.865... logprob:  0.483338, 0.132812 (1.461 sec)
3.866... logprob:  0.506365, 0.140625 (1.485 sec)
3.867... logprob:  0.501764, 0.140625 (1.479 sec)
3.868... logprob:  0.406197, 0.101562 (1.472 sec)
3.869... logprob:  0.384281, 0.093750 (1.482 sec)
3.870... logprob:  0.551491, 0.156250 (1.396 sec)
4.1... logprob:  0.380606, 0.093750 (1.404 sec)
4.2... logprob:  0.448009, 0.117188 (1.445 sec)
4.3... logprob:  0.398705, 0.101562 (1.419 sec)
4.4... logprob:  0.443094, 0.117188 (1.410 sec)
4.5... logprob:  0.442911, 0.117188 (1.429 sec)
4.6... logprob:  0.500718, 0.140625 (1.395 sec)
4.7... logprob:  0.361192, 0.085938 (1.423 sec)
4.8... logprob:  0.419457, 0.109375 (1.394 sec)
4.9... logprob:  0.357475, 0.085938 (1.402 sec)
4.10... logprob:  0.376924, 0.093750 (1.411 sec)
4.11... logprob:  0.333128, 0.078125 (1.440 sec)
4.12... logprob:  0.466992, 0.125000 (1.398 sec)
4.13... logprob:  0.443660, 0.117188 (1.422 sec)
4.14... logprob:  0.445398, 0.117188 (1.398 sec)
4.15... logprob:  0.397038, 0.101562 (1.413 sec)
4.16... logprob:  0.421876, 0.109375 (1.412 sec)
4.17... logprob:  0.515784, 0.140625 (1.392 sec)
4.18... logprob:  0.262302, 0.054688 (1.406 sec)
4.19... logprob:  0.281212, 0.062500 (1.400 sec)
4.20... logprob:  0.421180, 0.109375 (1.404 sec)
4.21... logprob:  0.443526, 0.117188 (0.892 sec)
4.22... logprob:  0.535120, 0.148438 (1.321 sec)
4.23... logprob:  0.531084, 0.148438 (1.417 sec)
4.24... logprob:  0.312276, 0.070312 (0.987 sec)
4.25... logprob:  0.357505, 0.085938 (0.957 sec)
4.26... logprob:  0.463201, 0.125000 (1.455 sec)
4.27... logprob:  0.406123, 0.101562 (1.383 sec)
4.28... logprob:  0.422269, 0.109375 (1.434 sec)
4.29... logprob:  0.395923, 0.101562 (1.425 sec)
4.30... logprob:  0.373792, 0.093750 (1.416 sec)
4.31... logprob:  0.479199, 0.132812 (1.405 sec)
4.32... logprob:  0.456375, 0.125000 (1.390 sec)
4.33... logprob:  0.460435, 0.125000 (1.451 sec)
4.34... logprob:  0.465460, 0.125000 (1.391 sec)
4.35... logprob:  0.315614, 0.070312 (1.404 sec)
4.36... logprob:  0.474187, 0.132812 (1.401 sec)
4.37... logprob:  0.417072, 0.109375 (1.407 sec)
4.38... logprob:  0.390501, 0.101562 (1.392 sec)
4.39... logprob:  0.633302, 0.187500 (1.441 sec)
4.40... logprob:  0.447908, 0.117188 (1.407 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.017826080322266, 10.0]}, 128)
batch 872: ({'logprob': [66.21754455566406, 19.0]}, 128)
batch 873: ({'logprob': [41.08393859863281, 9.0]}, 128)
batch 874: ({'logprob': [45.49665069580078, 11.0]}, 128)
batch 875: ({'logprob': [50.92488479614258, 13.0]}, 128)
batch 876: ({'logprob': [63.76009750366211, 18.0]}, 128)
batch 877: ({'logprob': [46.00530242919922, 11.0]}, 128)
batch 878: ({'logprob': [61.793766021728516, 17.0]}, 128)
batch 879: ({'logprob': [73.15709686279297, 21.0]}, 128)
batch 880: ({'logprob': [50.93045425415039, 13.0]}, 128)
batch 881: ({'logprob': [29.70331573486328, 5.0]}, 128)
batch 882: ({'logprob': [54.90933609008789, 14.0]}, 128)
batch 883: ({'logprob': [61.790348052978516, 17.0]}, 128)
batch 884: ({'logprob': [51.42564392089844, 13.0]}, 128)
batch 885: ({'logprob': [52.43980026245117, 13.0]}, 128)
batch 886: ({'logprob': [62.29558181762695, 17.0]}, 128)

======================Test output======================
logprob:  0.416969, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.977653e-03 [1.971709e-09] 
Layer 'conv1' biases: 1.211342e-08 [4.557233e-11] 
Layer 'conv2' weights[0]: 7.964568e-03 [1.515356e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.494262e-10] 
Layer 'conv3' weights[0]: 7.962936e-03 [1.501761e-09] 
Layer 'conv3' biases: 1.694552e-07 [7.780796e-10] 
Layer 'conv4' weights[0]: 7.995441e-03 [1.664079e-09] 
Layer 'conv4' biases: 9.999999e-01 [7.338709e-09] 
Layer 'conv5' weights[0]: 7.994380e-03 [5.016879e-08] 
Layer 'conv5' biases: 1.000001e+00 [5.444493e-08] 
Layer 'fc6' weights[0]: 7.591182e-03 [4.903707e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.871697e-09] 
Layer 'fc7' weights[0]: 7.753277e-03 [1.030701e-07] 
Layer 'fc7' biases: 9.998786e-01 [8.766334e-08] 
Layer 'fc8' weights[0]: 1.014012e-03 [7.650330e-06] 
Layer 'fc8' biases: 4.114673e-03 [3.557125e-05] 
Train error last 870 batches: 0.436073
-------------------------------------------------------
Not saving because 0.416969 > 0.415720 (2.830: -0.06%)
======================================================= (12.043 sec)
4.41... logprob:  0.351478, 0.085938 (1.434 sec)
4.42... logprob:  0.389846, 0.101562 (1.423 sec)
4.43... logprob:  0.440488, 0.117188 (1.409 sec)
4.44... logprob:  0.517029, 0.148438 (1.434 sec)
4.45... logprob:  0.383755, 0.093750 (1.404 sec)
4.46... logprob:  0.488144, 0.132812 (1.396 sec)
4.47... logprob:  0.331624, 0.078125 (1.397 sec)
4.48... logprob:  0.498181, 0.140625 (1.428 sec)
4.49... logprob:  0.507925, 0.148438 (1.415 sec)
4.50... logprob:  0.392872, 0.101562 (1.424 sec)
4.51... logprob:  0.487744, 0.140625 (1.428 sec)
4.52... logprob:  0.526762, 0.148438 (1.398 sec)
4.53... logprob:  0.295984, 0.062500 (1.445 sec)
4.54... logprob:  0.400955, 0.109375 (1.390 sec)
4.55... logprob:  0.331809, 0.078125 (1.403 sec)
4.56... logprob:  0.422868, 0.109375 (1.400 sec)
4.57... logprob:  0.574384, 0.164062 (1.428 sec)
4.58... logprob:  0.409600, 0.101562 (1.400 sec)
4.59... logprob:  0.333811, 0.078125 (1.468 sec)
4.60... logprob:  0.621464, 0.179688 (1.419 sec)
4.61... logprob:  0.383090, 0.093750 (1.432 sec)
4.62... logprob:  0.475373, 0.132812 (1.458 sec)
4.63... logprob:  0.397088, 0.101562 (1.441 sec)
4.64... logprob:  0.450670, 0.125000 (1.412 sec)
4.65... logprob:  0.373021, 0.093750 (1.402 sec)
4.66... logprob:  0.353647, 0.085938 (1.447 sec)
4.67... logprob:  0.294525, 0.062500 (1.388 sec)
4.68... logprob:  0.396578, 0.101562 (1.401 sec)
4.69... logprob:  0.498174, 0.140625 (1.427 sec)
4.70... logprob:  0.326103, 0.078125 (1.433 sec)
4.71... logprob:  0.383703, 0.101562 (1.462 sec)
4.72... logprob:  0.492825, 0.132812 (1.403 sec)
4.73... logprob:  0.446764, 0.117188 (1.429 sec)
4.74... logprob:  0.442203, 0.117188 (1.417 sec)
4.75... logprob:  0.379628, 0.093750 (1.418 sec)
4.76... logprob:  0.412772, 0.109375 (1.444 sec)
4.77... logprob:  0.396213, 0.101562 (1.427 sec)
4.78... logprob:  0.494273, 0.140625 (1.462 sec)
4.79... logprob:  0.456662, 0.125000 (1.398 sec)
4.80... logprob:  0.504748, 0.132812 (1.421 sec)
4.81... logprob:  0.416929, 0.109375 (1.424 sec)
4.82... logprob:  0.233640, 0.039062 (1.420 sec)
4.83... logprob:  0.494178, 0.140625 (1.407 sec)
4.84... logprob:  0.467191, 0.125000 (1.464 sec)
4.85... logprob:  0.432821, 0.117188 (1.419 sec)
4.86... logprob:  0.417191, 0.109375 (1.422 sec)
4.87... logprob:  0.632894, 0.187500 (1.409 sec)
4.88... logprob:  0.535949, 0.156250 (1.409 sec)
4.89... logprob:  0.411176, 0.109375 (1.435 sec)
4.90... logprob:  0.577724, 0.171875 (1.392 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.15494155883789, 10.0]}, 128)
batch 872: ({'logprob': [65.81915283203125, 19.0]}, 128)
batch 873: ({'logprob': [42.35041427612305, 9.0]}, 128)
batch 874: ({'logprob': [46.44449996948242, 11.0]}, 128)
batch 875: ({'logprob': [51.530731201171875, 13.0]}, 128)
batch 876: ({'logprob': [63.52672576904297, 18.0]}, 128)
batch 877: ({'logprob': [46.94205093383789, 11.0]}, 128)
batch 878: ({'logprob': [61.71432876586914, 17.0]}, 128)
batch 879: ({'logprob': [72.38088989257812, 21.0]}, 128)
batch 880: ({'logprob': [51.53609848022461, 13.0]}, 128)
batch 881: ({'logprob': [31.66724967956543, 5.0]}, 128)
batch 882: ({'logprob': [55.313026428222656, 14.0]}, 128)
batch 883: ({'logprob': [61.71070098876953, 17.0]}, 128)
batch 884: ({'logprob': [52.01884078979492, 13.0]}, 128)
batch 885: ({'logprob': [53.00828170776367, 13.0]}, 128)
batch 886: ({'logprob': [62.20350646972656, 17.0]}, 128)

======================Test output======================
logprob:  0.420567, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.977612e-03 [2.242797e-09] 
Layer 'conv1' biases: 1.260602e-08 [5.254821e-11] 
Layer 'conv2' weights[0]: 7.964528e-03 [1.775308e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.878131e-10] 
Layer 'conv3' weights[0]: 7.962898e-03 [1.615574e-09] 
Layer 'conv3' biases: 1.734531e-07 [9.038970e-10] 
Layer 'conv4' weights[0]: 7.995400e-03 [1.823812e-09] 
Layer 'conv4' biases: 9.999999e-01 [8.659248e-09] 
Layer 'conv5' weights[0]: 7.994345e-03 [5.859147e-08] 
Layer 'conv5' biases: 1.000001e+00 [6.372426e-08] 
Layer 'fc6' weights[0]: 7.591139e-03 [5.598964e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.679647e-09] 
Layer 'fc7' weights[0]: 7.751268e-03 [1.866376e-07] 
Layer 'fc7' biases: 9.998779e-01 [1.746688e-07] 
Layer 'fc8' weights[0]: 9.810061e-04 [1.253874e-05] 
Layer 'fc8' biases: 3.974151e-03 [5.913938e-05] 
Train error last 870 batches: 0.436031
-------------------------------------------------------
Not saving because 0.420567 > 0.415720 (2.830: -0.06%)
======================================================= (12.072 sec)
4.91... logprob:  0.348706, 0.078125 (1.409 sec)
4.92... logprob:  0.464461, 0.125000 (1.414 sec)
4.93... logprob:  0.492313, 0.140625 (1.397 sec)
4.94... logprob:  0.428945, 0.109375 (1.399 sec)
4.95... logprob:  0.472112, 0.125000 (1.425 sec)
4.96... logprob:  0.576685, 0.171875 (1.406 sec)
4.97... logprob:  0.430575, 0.117188 (1.395 sec)
4.98... logprob:  0.390573, 0.093750 (1.436 sec)
4.99... logprob:  0.474497, 0.132812 (1.411 sec)
4.100... logprob:  0.309498, 0.070312 (1.404 sec)
4.101... logprob:  0.309152, 0.062500 (1.443 sec)
4.102... logprob:  0.547654, 0.156250 (1.392 sec)
4.103... logprob:  0.543186, 0.156250 (1.403 sec)
4.104... logprob:  0.389228, 0.101562 (1.402 sec)
4.105... logprob:  0.621385, 0.179688 (1.402 sec)
4.106... logprob:  0.344498, 0.085938 (1.396 sec)
4.107... logprob:  0.335502, 0.078125 (1.441 sec)
4.108... logprob:  0.586586, 0.171875 (1.396 sec)
4.109... logprob:  0.336715, 0.078125 (1.409 sec)
4.110... logprob:  0.563358, 0.164062 (1.399 sec)
4.111... logprob:  0.405384, 0.101562 (1.396 sec)
4.112... logprob:  0.366578, 0.093750 (1.406 sec)
4.113... logprob:  0.355708, 0.085938 (1.399 sec)
4.114... logprob:  0.440386, 0.117188 (1.432 sec)
4.115... logprob:  0.506573, 0.140625 (1.415 sec)
4.116... logprob:  0.393522, 0.101562 (1.399 sec)
4.117... logprob:  0.440471, 0.117188 (1.444 sec)
4.118... logprob:  0.410053, 0.101562 (1.395 sec)
4.119... logprob:  0.345798, 0.085938 (1.396 sec)
4.120... logprob:  0.547638, 0.156250 (1.405 sec)
4.121... logprob:  0.412613, 0.109375 (1.395 sec)
4.122... logprob:  0.519946, 0.148438 (1.448 sec)
4.123... logprob:  0.464116, 0.125000 (1.387 sec)
4.124... logprob:  0.447543, 0.125000 (1.410 sec)
4.125... logprob:  0.502322, 0.140625 (1.398 sec)
4.126... logprob:  0.476761, 0.125000 (1.396 sec)
4.127... logprob:  0.480771, 0.125000 (1.396 sec)
4.128... logprob:  0.422544, 0.109375 (1.418 sec)
4.129... logprob:  0.574952, 0.164062 (1.423 sec)
4.130... logprob:  0.382809, 0.093750 (1.415 sec)
4.131... logprob:  0.494383, 0.132812 (1.410 sec)
4.132... logprob:  0.505738, 0.140625 (1.439 sec)
4.133... logprob:  0.444112, 0.117188 (1.389 sec)
4.134... logprob:  0.402049, 0.101562 (1.399 sec)
4.135... logprob:  0.461133, 0.125000 (1.405 sec)
4.136... logprob:  0.563561, 0.164062 (1.396 sec)
4.137... logprob:  0.462699, 0.125000 (1.394 sec)
4.138... logprob:  0.319903, 0.070312 (1.446 sec)
4.139... logprob:  0.399087, 0.101562 (1.401 sec)
4.140... logprob:  0.565561, 0.164062 (1.411 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.79282760620117, 10.0]}, 128)
batch 872: ({'logprob': [67.11924743652344, 19.0]}, 128)
batch 873: ({'logprob': [40.475215911865234, 9.0]}, 128)
batch 874: ({'logprob': [45.667354583740234, 11.0]}, 128)
batch 875: ({'logprob': [51.078514099121094, 13.0]}, 128)
batch 876: ({'logprob': [64.4721908569336, 18.0]}, 128)
batch 877: ({'logprob': [45.77830123901367, 11.0]}, 128)
batch 878: ({'logprob': [61.91600799560547, 17.0]}, 128)
batch 879: ({'logprob': [72.85054016113281, 21.0]}, 128)
batch 880: ({'logprob': [51.08522033691406, 13.0]}, 128)
batch 881: ({'logprob': [29.523591995239258, 5.0]}, 128)
batch 882: ({'logprob': [54.06171798706055, 14.0]}, 128)
batch 883: ({'logprob': [61.91236114501953, 17.0]}, 128)
batch 884: ({'logprob': [51.182167053222656, 13.0]}, 128)
batch 885: ({'logprob': [51.40106964111328, 13.0]}, 128)
batch 886: ({'logprob': [62.02031326293945, 17.0]}, 128)

======================Test output======================
logprob:  0.416668, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.977566e-03 [1.687827e-09] 
Layer 'conv1' biases: 1.284896e-08 [3.449512e-11] 
Layer 'conv2' weights[0]: 7.964478e-03 [1.280606e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.842007e-10] 
Layer 'conv3' weights[0]: 7.962850e-03 [1.204120e-09] 
Layer 'conv3' biases: 1.738236e-07 [5.736807e-10] 
Layer 'conv4' weights[0]: 7.995352e-03 [1.236244e-09] 
Layer 'conv4' biases: 9.999999e-01 [4.646674e-09] 
Layer 'conv5' weights[0]: 7.994311e-03 [2.721241e-08] 
Layer 'conv5' biases: 1.000001e+00 [2.930775e-08] 
Layer 'fc6' weights[0]: 7.591095e-03 [2.850451e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.795385e-09] 
Layer 'fc7' weights[0]: 7.749293e-03 [7.004040e-08] 
Layer 'fc7' biases: 9.998779e-01 [5.110121e-08] 
Layer 'fc8' weights[0]: 1.024545e-03 [6.071697e-06] 
Layer 'fc8' biases: 4.263160e-03 [2.955981e-05] 
Train error last 870 batches: 0.435963
-------------------------------------------------------
Not saving because 0.416668 > 0.415720 (2.830: -0.06%)
======================================================= (12.058 sec)
4.141... logprob:  0.463822, 0.125000 (1.449 sec)
4.142... logprob:  0.463932, 0.125000 (1.407 sec)
4.143... logprob:  0.293820, 0.062500 (1.430 sec)
4.144... logprob:  0.460128, 0.125000 (1.422 sec)
4.145... logprob:  0.328109, 0.078125 (1.415 sec)
4.146... logprob:  0.484000, 0.132812 (1.415 sec)
4.147... logprob:  0.263150, 0.054688 (1.430 sec)
4.148... logprob:  0.459104, 0.125000 (1.396 sec)
4.149... logprob:  0.442370, 0.117188 (1.394 sec)
4.150... logprob:  0.347330, 0.085938 (1.405 sec)
4.151... logprob:  0.346586, 0.085938 (1.398 sec)
4.152... logprob:  0.781224, 0.234375 (1.394 sec)
4.153... logprob:  0.384056, 0.093750 (1.442 sec)
4.154... logprob:  0.521773, 0.148438 (1.402 sec)
4.155... logprob:  0.421359, 0.117188 (1.413 sec)
4.156... logprob:  0.300156, 0.062500 (1.437 sec)
4.157... logprob:  0.273134, 0.054688 (1.394 sec)
4.158... logprob:  0.454406, 0.125000 (1.407 sec)
4.159... logprob:  0.484824, 0.132812 (1.399 sec)
4.160... logprob:  0.448390, 0.117188 (1.393 sec)
4.161... logprob:  0.356733, 0.078125 (1.411 sec)
4.162... logprob:  0.615572, 0.179688 (1.408 sec)
4.163... logprob:  0.448639, 0.125000 (1.430 sec)
4.164... logprob:  0.472019, 0.125000 (1.424 sec)
4.165... logprob:  0.551375, 0.156250 (1.420 sec)
4.166... logprob:  0.443761, 0.125000 (1.453 sec)
4.167... logprob:  0.347547, 0.085938 (1.430 sec)
4.168... logprob:  0.363137, 0.085938 (1.423 sec)
4.169... logprob:  0.409224, 0.101562 (1.466 sec)
4.170... logprob:  0.459704, 0.125000 (1.402 sec)
4.171... logprob:  0.536509, 0.156250 (1.448 sec)
4.172... logprob:  0.434775, 0.109375 (1.411 sec)
4.173... logprob:  0.440432, 0.117188 (1.422 sec)
4.174... logprob:  0.601043, 0.171875 (1.409 sec)
4.175... logprob:  0.505882, 0.140625 (1.466 sec)
4.176... logprob:  0.478928, 0.132812 (1.410 sec)
4.177... logprob:  0.287833, 0.054688 (1.433 sec)
4.178... logprob:  0.382687, 0.093750 (1.456 sec)
4.179... logprob:  0.396388, 0.101562 (1.414 sec)
4.180... logprob:  0.464710, 0.125000 (1.426 sec)
4.181... logprob:  0.542375, 0.156250 (1.422 sec)
4.182... logprob:  0.374480, 0.093750 (1.416 sec)
4.183... logprob:  0.420078, 0.109375 (1.421 sec)
4.184... logprob:  0.483805, 0.132812 (1.422 sec)
4.185... logprob:  0.290938, 0.062500 (1.397 sec)
4.186... logprob:  0.373425, 0.093750 (1.401 sec)
4.187... logprob:  0.529743, 0.148438 (1.403 sec)
4.188... logprob:  0.461061, 0.125000 (1.394 sec)
4.189... logprob:  0.441261, 0.117188 (1.393 sec)
4.190... logprob:  0.375800, 0.093750 (1.439 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.89544677734375, 10.0]}, 128)
batch 872: ({'logprob': [67.20475769042969, 19.0]}, 128)
batch 873: ({'logprob': [40.035648345947266, 9.0]}, 128)
batch 874: ({'logprob': [45.13506317138672, 11.0]}, 128)
batch 875: ({'logprob': [50.782752990722656, 13.0]}, 128)
batch 876: ({'logprob': [64.52166748046875, 18.0]}, 128)
batch 877: ({'logprob': [45.410064697265625, 11.0]}, 128)
batch 878: ({'logprob': [62.09355545043945, 17.0]}, 128)
batch 879: ({'logprob': [73.66502380371094, 21.0]}, 128)
batch 880: ({'logprob': [50.78934860229492, 13.0]}, 128)
batch 881: ({'logprob': [28.445863723754883, 5.0]}, 128)
batch 882: ({'logprob': [54.295936584472656, 14.0]}, 128)
batch 883: ({'logprob': [62.08998107910156, 17.0]}, 128)
batch 884: ({'logprob': [51.05093765258789, 13.0]}, 128)
batch 885: ({'logprob': [51.59933853149414, 13.0]}, 128)
batch 886: ({'logprob': [62.36252975463867, 17.0]}, 128)

======================Test output======================
logprob:  0.415712, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.977526e-03 [1.564394e-09] 
Layer 'conv1' biases: 1.329969e-08 [2.745009e-11] 
Layer 'conv2' weights[0]: 7.964439e-03 [1.213586e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.946001e-11] 
Layer 'conv3' weights[0]: 7.962809e-03 [1.003684e-09] 
Layer 'conv3' biases: 1.784730e-07 [2.367019e-10] 
Layer 'conv4' weights[0]: 7.995312e-03 [9.861068e-10] 
Layer 'conv4' biases: 9.999999e-01 [5.068393e-10] 
Layer 'conv5' weights[0]: 7.994269e-03 [2.557643e-09] 
Layer 'conv5' biases: 1.000001e+00 [2.290671e-09] 
Layer 'fc6' weights[0]: 7.591055e-03 [8.067936e-10] 
Layer 'fc6' biases: 1.000000e+00 [2.627417e-10] 
Layer 'fc7' weights[0]: 7.747315e-03 [4.241048e-08] 
Layer 'fc7' biases: 9.998778e-01 [1.377702e-08] 
Layer 'fc8' weights[0]: 1.067530e-03 [4.955673e-06] 
Layer 'fc8' biases: 4.536463e-03 [2.400343e-05] 
Train error last 870 batches: 0.435927
-------------------------------------------------------
Saved checkpoint to /data2/ad6813/my-nets/saves/ConvNet__2014-06-17_23.05.49
======================================================= (12.720 sec)
4.191... logprob:  0.485166, 0.132812 (1.415 sec)
4.192... logprob:  0.521738, 0.148438 (1.451 sec)
4.193... logprob:  0.312875, 0.070312 (1.426 sec)
4.194... logprob:  0.414551, 0.109375 (2.668 sec)
4.195... logprob:  0.287849, 0.062500 (1.404 sec)
4.196... logprob:  0.410434, 0.109375 (1.392 sec)
4.197... logprob:  0.477435, 0.132812 (3.038 sec)
4.198... logprob:  0.356300, 0.085938 (1.409 sec)
4.199... logprob:  0.436729, 0.117188 (1.393 sec)
4.200... logprob:  0.441022, 0.117188 (1.449 sec)
4.201... logprob:  0.436619, 0.117188 (1.410 sec)
4.202... logprob:  0.540497, 0.148438 (1.443 sec)
4.203... logprob:  0.421419, 0.109375 (1.446 sec)
4.204... logprob:  0.504453, 0.140625 (1.394 sec)
4.205... logprob:  0.335105, 0.078125 (1.402 sec)
4.206... logprob:  0.358649, 0.093750 (1.404 sec)
4.207... logprob:  0.383760, 0.093750 (1.401 sec)
4.208... logprob:  0.488327, 0.140625 (1.405 sec)
4.209... logprob:  0.335029, 0.078125 (1.419 sec)
4.210... logprob:  0.586754, 0.171875 (1.419 sec)
4.211... logprob:  0.490081, 0.132812 (1.445 sec)
4.212... logprob:  0.527446, 0.148438 (1.417 sec)
4.213... logprob:  0.517845, 0.140625 (1.465 sec)
4.214... logprob:  0.459691, 0.125000 (1.430 sec)
4.215... logprob:  0.395715, 0.101562 (1.419 sec)
4.216... logprob:  0.519282, 0.140625 (1.469 sec)
4.217... logprob:  0.325133, 0.070312 (1.406 sec)
4.218... logprob:  0.463839, 0.125000 (1.424 sec)
4.219... logprob:  0.500495, 0.140625 (1.415 sec)
4.220... logprob:  0.415016, 0.109375 (1.423 sec)
4.221... logprob:  0.399191, 0.101562 (1.399 sec)
4.222... logprob:  0.556401, 0.164062 (1.461 sec)
4.223... logprob:  0.569127, 0.164062 (1.436 sec)
4.224... logprob:  0.404577, 0.101562 (1.428 sec)
4.225... logprob:  0.393265, 0.101562 (1.446 sec)
4.226... logprob:  0.423594, 0.109375 (1.419 sec)
4.227... logprob:  0.454697, 0.125000 (1.413 sec)
4.228... logprob:  0.417801, 0.109375 (1.414 sec)
4.229... logprob:  0.487845, 0.132812 (1.419 sec)
4.230... logprob:  0.460257, 0.125000 (1.435 sec)
4.231... logprob:  0.455243, 0.125000 (1.405 sec)
4.232... logprob:  0.497532, 0.140625 (1.488 sec)
4.233... logprob:  0.468686, 0.132812 (1.435 sec)
4.234... logprob:  0.563251, 0.164062 (1.418 sec)
4.235... logprob:  0.481879, 0.132812 (1.467 sec)
4.236... logprob:  0.426248, 0.109375 (1.408 sec)
4.237... logprob:  0.342801, 0.078125 (1.422 sec)
4.238... logprob:  0.390615, 0.093750 (1.419 sec)
4.239... logprob:  0.478103, 0.132812 (1.422 sec)
4.240... logprob:  0.486083, 0.132812 (1.404 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.30460739135742, 10.0]}, 128)
batch 872: ({'logprob': [66.04979705810547, 19.0]}, 128)
batch 873: ({'logprob': [41.426849365234375, 9.0]}, 128)
batch 874: ({'logprob': [45.73532485961914, 11.0]}, 128)
batch 875: ({'logprob': [51.062538146972656, 13.0]}, 128)
batch 876: ({'logprob': [63.64390182495117, 18.0]}, 128)
batch 877: ({'logprob': [46.24587631225586, 11.0]}, 128)
batch 878: ({'logprob': [61.72977828979492, 17.0]}, 128)
batch 879: ({'logprob': [72.89228820800781, 21.0]}, 128)
batch 880: ({'logprob': [51.068443298339844, 13.0]}, 128)
batch 881: ({'logprob': [30.246225357055664, 5.0]}, 128)
batch 882: ({'logprob': [54.99998474121094, 14.0]}, 128)
batch 883: ({'logprob': [61.726016998291016, 17.0]}, 128)
batch 884: ({'logprob': [51.564231872558594, 13.0]}, 128)
batch 885: ({'logprob': [52.581077575683594, 13.0]}, 128)
batch 886: ({'logprob': [62.23252487182617, 17.0]}, 128)

======================Test output======================
logprob:  0.417729, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.977480e-03 [1.515755e-09] 
Layer 'conv1' biases: 1.375190e-08 [2.763772e-11] 
Layer 'conv2' weights[0]: 7.964399e-03 [1.167755e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.070879e-10] 
Layer 'conv3' weights[0]: 7.962764e-03 [1.030126e-09] 
Layer 'conv3' biases: 1.818410e-07 [3.074492e-10] 
Layer 'conv4' weights[0]: 7.995272e-03 [1.028498e-09] 
Layer 'conv4' biases: 9.999999e-01 [2.032068e-09] 
Layer 'conv5' weights[0]: 7.994226e-03 [1.223379e-08] 
Layer 'conv5' biases: 1.000001e+00 [1.322530e-08] 
Layer 'fc6' weights[0]: 7.591009e-03 [1.442417e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.218193e-09] 
Layer 'fc7' weights[0]: 7.745377e-03 [8.409948e-08] 
Layer 'fc7' biases: 9.998771e-01 [6.692292e-08] 
Layer 'fc8' weights[0]: 1.040796e-03 [4.969131e-06] 
Layer 'fc8' biases: 4.422047e-03 [2.538927e-05] 
Train error last 870 batches: 0.435883
-------------------------------------------------------
Not saving because 0.417729 > 0.415712 (4.190: -0.00%)
======================================================= (12.107 sec)
4.241... logprob:  0.494209, 0.132812 (1.467 sec)
4.242... logprob:  0.341559, 0.078125 (1.438 sec)
4.243... logprob:  0.385807, 0.093750 (1.440 sec)
4.244... logprob:  0.314094, 0.070312 (1.445 sec)
4.245... logprob:  0.494633, 0.132812 (1.425 sec)
4.246... logprob:  0.417353, 0.109375 (1.419 sec)
4.247... logprob:  0.356101, 0.085938 (1.418 sec)
4.248... logprob:  0.306501, 0.070312 (1.414 sec)
4.249... logprob:  0.559334, 0.156250 (1.424 sec)
4.250... logprob:  0.592366, 0.164062 (1.407 sec)
4.251... logprob:  0.352525, 0.085938 (1.465 sec)
4.252... logprob:  0.349858, 0.085938 (1.422 sec)
4.253... logprob:  0.377804, 0.093750 (1.424 sec)
4.254... logprob:  0.444007, 0.117188 (1.469 sec)
4.255... logprob:  0.352610, 0.085938 (1.399 sec)
4.256... logprob:  0.377560, 0.093750 (1.426 sec)
4.257... logprob:  0.332207, 0.078125 (1.415 sec)
4.258... logprob:  0.418803, 0.109375 (1.423 sec)
4.259... logprob:  0.442796, 0.117188 (1.404 sec)
4.260... logprob:  0.309367, 0.070312 (1.459 sec)
4.261... logprob:  0.395695, 0.101562 (1.431 sec)
4.262... logprob:  0.527594, 0.148438 (1.430 sec)
4.263... logprob:  0.424327, 0.109375 (1.449 sec)
4.264... logprob:  0.375525, 0.093750 (1.422 sec)
4.265... logprob:  0.439519, 0.117188 (1.421 sec)
4.266... logprob:  0.438820, 0.117188 (1.414 sec)
4.267... logprob:  0.422258, 0.109375 (1.421 sec)
4.268... logprob:  0.458188, 0.125000 (1.420 sec)
4.269... logprob:  0.566665, 0.164062 (1.410 sec)
4.270... logprob:  0.541142, 0.156250 (1.460 sec)
4.271... logprob:  0.447449, 0.117188 (1.429 sec)
4.272... logprob:  0.386191, 0.093750 (1.420 sec)
4.273... logprob:  0.500070, 0.140625 (1.465 sec)
4.274... logprob:  0.543519, 0.156250 (1.408 sec)
4.275... logprob:  0.490068, 0.132812 (1.421 sec)
4.276... logprob:  0.391427, 0.093750 (1.418 sec)
4.277... logprob:  0.429831, 0.109375 (1.446 sec)
4.278... logprob:  0.321456, 0.070312 (1.425 sec)
4.279... logprob:  0.324125, 0.070312 (1.464 sec)
4.280... logprob:  0.212499, 0.031250 (1.405 sec)
4.281... logprob:  0.416942, 0.109375 (1.427 sec)
4.282... logprob:  0.411318, 0.109375 (1.416 sec)
4.283... logprob:  0.394130, 0.101562 (1.415 sec)
4.284... logprob:  0.395432, 0.101562 (1.411 sec)
4.285... logprob:  0.453823, 0.117188 (1.439 sec)
4.286... logprob:  0.539858, 0.140625 (1.443 sec)
4.287... logprob:  0.347031, 0.085938 (1.431 sec)
4.288... logprob:  0.329992, 0.078125 (1.438 sec)
4.289... logprob:  0.446456, 0.117188 (1.443 sec)
4.290... logprob:  0.490719, 0.132812 (1.415 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.020225524902344, 10.0]}, 128)
batch 872: ({'logprob': [68.48927307128906, 19.0]}, 128)
batch 873: ({'logprob': [39.45487594604492, 9.0]}, 128)
batch 874: ({'logprob': [44.7409553527832, 11.0]}, 128)
batch 875: ({'logprob': [50.88508987426758, 13.0]}, 128)
batch 876: ({'logprob': [65.63554382324219, 18.0]}, 128)
batch 877: ({'logprob': [45.169864654541016, 11.0]}, 128)
batch 878: ({'logprob': [63.190277099609375, 17.0]}, 128)
batch 879: ({'logprob': [75.90982818603516, 21.0]}, 128)
batch 880: ({'logprob': [50.89175033569336, 13.0]}, 128)
batch 881: ({'logprob': [26.715164184570312, 5.0]}, 128)
batch 882: ({'logprob': [55.035377502441406, 14.0]}, 128)
batch 883: ({'logprob': [63.186946868896484, 17.0]}, 128)
batch 884: ({'logprob': [51.30877685546875, 13.0]}, 128)
batch 885: ({'logprob': [52.16813278198242, 13.0]}, 128)
batch 886: ({'logprob': [63.61478042602539, 17.0]}, 128)

======================Test output======================
logprob:  0.418661, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.977446e-03 [3.446113e-09] 
Layer 'conv1' biases: 1.427072e-08 [1.071295e-10] 
Layer 'conv2' weights[0]: 7.964356e-03 [2.978011e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.193838e-10] 
Layer 'conv3' weights[0]: 7.962725e-03 [3.030724e-09] 
Layer 'conv3' biases: 1.854221e-07 [1.903019e-09] 
Layer 'conv4' weights[0]: 7.995237e-03 [3.413433e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.888198e-08] 
Layer 'conv5' weights[0]: 7.994188e-03 [1.290237e-07] 
Layer 'conv5' biases: 1.000001e+00 [1.400416e-07] 
Layer 'fc6' weights[0]: 7.590974e-03 [1.224690e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.249929e-08] 
Layer 'fc7' weights[0]: 7.743415e-03 [2.803939e-07] 
Layer 'fc7' biases: 9.998780e-01 [2.691901e-07] 
Layer 'fc8' weights[0]: 1.144995e-03 [1.515059e-05] 
Layer 'fc8' biases: 5.079340e-03 [6.726226e-05] 
Train error last 870 batches: 0.435777
-------------------------------------------------------
Not saving because 0.418661 > 0.415712 (4.190: -0.00%)
======================================================= (12.013 sec)
4.291... logprob:  0.438930, 0.117188 (1.419 sec)
4.292... logprob:  0.565369, 0.156250 (1.417 sec)
4.293... logprob:  0.427023, 0.117188 (1.424 sec)
4.294... logprob:  0.357378, 0.085938 (1.403 sec)
4.295... logprob:  0.337100, 0.078125 (1.467 sec)
4.296... logprob:  0.358004, 0.085938 (1.420 sec)
4.297... logprob:  0.395806, 0.101562 (1.428 sec)
4.298... logprob:  0.447409, 0.125000 (1.461 sec)
4.299... logprob:  0.344522, 0.078125 (1.408 sec)
4.300... logprob:  0.407869, 0.101562 (1.420 sec)
4.301... logprob:  0.398200, 0.101562 (1.415 sec)
4.302... logprob:  0.591041, 0.179688 (1.419 sec)
4.303... logprob:  0.459897, 0.125000 (1.409 sec)
4.304... logprob:  0.459958, 0.125000 (1.441 sec)
4.305... logprob:  0.455221, 0.125000 (1.437 sec)
4.306... logprob:  0.440807, 0.117188 (1.436 sec)
4.307... logprob:  0.421745, 0.109375 (1.445 sec)
4.308... logprob:  0.373925, 0.093750 (1.457 sec)
4.309... logprob:  0.450180, 0.125000 (1.418 sec)
4.310... logprob:  0.474904, 0.125000 (1.419 sec)
4.311... logprob:  0.503254, 0.140625 (1.432 sec)
4.312... logprob:  0.479028, 0.132812 (1.422 sec)
4.313... logprob:  0.454844, 0.125000 (1.427 sec)
4.314... logprob:  0.455194, 0.117188 (1.465 sec)
4.315... logprob:  0.314635, 0.070312 (1.433 sec)
4.316... logprob:  0.468660, 0.125000 (1.429 sec)
4.317... logprob:  0.355576, 0.085938 (1.475 sec)
4.318... logprob:  0.455606, 0.125000 (1.417 sec)
4.319... logprob:  0.424131, 0.117188 (1.425 sec)
4.320... logprob:  0.412589, 0.109375 (1.430 sec)
4.321... logprob:  0.348635, 0.085938 (1.418 sec)
4.322... logprob:  0.388096, 0.101562 (1.412 sec)
4.323... logprob:  0.416577, 0.109375 (1.473 sec)
4.324... logprob:  0.498860, 0.140625 (1.422 sec)
4.325... logprob:  0.350807, 0.085938 (1.437 sec)
4.326... logprob:  0.542454, 0.148438 (1.461 sec)
4.327... logprob:  0.554262, 0.164062 (1.428 sec)
4.328... logprob:  0.564380, 0.156250 (1.421 sec)
4.329... logprob:  0.402318, 0.101562 (1.430 sec)
4.330... logprob:  0.388946, 0.101562 (1.416 sec)
4.331... logprob:  0.353099, 0.085938 (1.422 sec)
4.332... logprob:  0.482878, 0.132812 (1.452 sec)
4.333... logprob:  0.339640, 0.085938 (1.445 sec)
4.334... logprob:  0.564345, 0.171875 (1.446 sec)
4.335... logprob:  0.359306, 0.085938 (1.440 sec)
4.336... logprob:  0.444176, 0.125000 (1.460 sec)
4.337... logprob:  0.567067, 0.164062 (1.425 sec)
4.338... logprob:  0.449024, 0.125000 (1.418 sec)
4.339... logprob:  0.489763, 0.132812 (1.431 sec)
4.340... logprob:  0.442556, 0.117188 (1.434 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.226768493652344, 10.0]}, 128)
batch 872: ({'logprob': [65.78750610351562, 19.0]}, 128)
batch 873: ({'logprob': [42.19731903076172, 9.0]}, 128)
batch 874: ({'logprob': [46.0106201171875, 11.0]}, 128)
batch 875: ({'logprob': [51.32398986816406, 13.0]}, 128)
batch 876: ({'logprob': [63.50834274291992, 18.0]}, 128)
batch 877: ({'logprob': [46.76151657104492, 11.0]}, 128)
batch 878: ({'logprob': [61.96207046508789, 17.0]}, 128)
batch 879: ({'logprob': [73.33512878417969, 21.0]}, 128)
batch 880: ({'logprob': [51.32926559448242, 13.0]}, 128)
batch 881: ({'logprob': [30.805389404296875, 5.0]}, 128)
batch 882: ({'logprob': [55.85404586791992, 14.0]}, 128)
batch 883: ({'logprob': [61.95844650268555, 17.0]}, 128)
batch 884: ({'logprob': [52.06513977050781, 13.0]}, 128)
batch 885: ({'logprob': [53.56230545043945, 13.0]}, 128)
batch 886: ({'logprob': [62.70463943481445, 17.0]}, 128)

======================Test output======================
logprob:  0.420602, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.977398e-03 [1.745605e-09] 
Layer 'conv1' biases: 1.471422e-08 [2.093495e-11] 
Layer 'conv2' weights[0]: 7.964315e-03 [1.292719e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.127964e-11] 
Layer 'conv3' weights[0]: 7.962685e-03 [1.053862e-09] 
Layer 'conv3' biases: 1.890929e-07 [2.842928e-10] 
Layer 'conv4' weights[0]: 7.995191e-03 [1.058343e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.542577e-09] 
Layer 'conv5' weights[0]: 7.994149e-03 [8.179011e-09] 
Layer 'conv5' biases: 1.000001e+00 [8.676700e-09] 
Layer 'fc6' weights[0]: 7.590942e-03 [1.165566e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.368323e-10] 
Layer 'fc7' weights[0]: 7.741483e-03 [3.918683e-08] 
Layer 'fc7' biases: 9.998764e-01 [5.550659e-09] 
Layer 'fc8' weights[0]: 1.064200e-03 [7.959646e-07] 
Layer 'fc8' biases: 4.766489e-03 [4.502932e-06] 
Train error last 870 batches: 0.435669
-------------------------------------------------------
Not saving because 0.420602 > 0.415712 (4.190: -0.00%)
======================================================= (12.194 sec)
4.341... logprob:  0.531419, 0.148438 (1.423 sec)
4.342... logprob:  0.430557, 0.109375 (1.475 sec)
4.343... logprob:  0.435657, 0.109375 (1.434 sec)
4.344... logprob:  0.443844, 0.125000 (1.474 sec)
4.345... logprob:  0.488651, 0.132812 (1.438 sec)
4.346... logprob:  0.436141, 0.117188 (1.437 sec)
4.347... logprob:  0.371220, 0.085938 (1.483 sec)
4.348... logprob:  0.397946, 0.101562 (1.435 sec)
4.349... logprob:  0.498847, 0.140625 (1.437 sec)
4.350... logprob:  0.357416, 0.085938 (1.434 sec)
4.351... logprob:  0.508747, 0.140625 (1.435 sec)
4.352... logprob:  0.365009, 0.093750 (1.436 sec)
4.353... logprob:  0.515769, 0.148438 (1.488 sec)
4.354... logprob:  0.676613, 0.203125 (1.433 sec)
4.355... logprob:  0.356978, 0.085938 (1.449 sec)
4.356... logprob:  0.479405, 0.132812 (1.475 sec)
4.357... logprob:  0.348824, 0.085938 (1.439 sec)
4.358... logprob:  0.326110, 0.070312 (1.435 sec)
4.359... logprob:  0.555116, 0.164062 (1.437 sec)
4.360... logprob:  0.444184, 0.117188 (1.431 sec)
4.361... logprob:  0.410258, 0.101562 (1.432 sec)
4.362... logprob:  0.425588, 0.117188 (1.481 sec)
4.363... logprob:  0.486031, 0.132812 (1.442 sec)
4.364... logprob:  0.474455, 0.125000 (1.451 sec)
4.365... logprob:  0.424764, 0.109375 (1.470 sec)
4.366... logprob:  0.410541, 0.109375 (1.443 sec)
4.367... logprob:  0.325799, 0.078125 (1.445 sec)
4.368... logprob:  0.595563, 0.171875 (1.432 sec)
4.369... logprob:  0.380800, 0.093750 (1.428 sec)
4.370... logprob:  0.380389, 0.093750 (1.437 sec)
4.371... logprob:  0.399869, 0.101562 (1.460 sec)
4.372... logprob:  0.539740, 0.156250 (1.458 sec)
4.373... logprob:  0.463928, 0.125000 (1.455 sec)
4.374... logprob:  0.527751, 0.148438 (1.448 sec)
4.375... logprob:  0.394018, 0.101562 (1.469 sec)
4.376... logprob:  0.374395, 0.093750 (1.438 sec)
4.377... logprob:  0.295007, 0.062500 (1.426 sec)
4.378... logprob:  0.454307, 0.125000 (1.434 sec)
4.379... logprob:  0.420166, 0.109375 (1.439 sec)
4.380... logprob:  0.605700, 0.179688 (1.442 sec)
4.381... logprob:  0.463454, 0.125000 (1.472 sec)
4.382... logprob:  0.529151, 0.148438 (1.459 sec)
4.383... logprob:  0.359355, 0.085938 (1.437 sec)
4.384... logprob:  0.520540, 0.148438 (1.478 sec)
4.385... logprob:  0.523201, 0.148438 (1.468 sec)
4.386... logprob:  0.581742, 0.171875 (1.428 sec)
4.387... logprob:  0.428244, 0.117188 (1.441 sec)
4.388... logprob:  0.521396, 0.148438 (1.436 sec)
4.389... logprob:  0.426772, 0.109375 (1.436 sec)
4.390... logprob:  0.419961, 0.109375 (1.481 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.838661193847656, 10.0]}, 128)
batch 872: ({'logprob': [65.785888671875, 19.0]}, 128)
batch 873: ({'logprob': [43.0847053527832, 9.0]}, 128)
batch 874: ({'logprob': [47.03513717651367, 11.0]}, 128)
batch 875: ({'logprob': [51.96082305908203, 13.0]}, 128)
batch 876: ({'logprob': [63.56962966918945, 18.0]}, 128)
batch 877: ({'logprob': [47.524742126464844, 11.0]}, 128)
batch 878: ({'logprob': [61.82372283935547, 17.0]}, 128)
batch 879: ({'logprob': [72.15985870361328, 21.0]}, 128)
batch 880: ({'logprob': [51.966773986816406, 13.0]}, 128)
batch 881: ({'logprob': [32.730628967285156, 5.0]}, 128)
batch 882: ({'logprob': [55.640506744384766, 14.0]}, 128)
batch 883: ({'logprob': [61.81968307495117, 17.0]}, 128)
batch 884: ({'logprob': [52.43910598754883, 13.0]}, 128)
batch 885: ({'logprob': [53.41062927246094, 13.0]}, 128)
batch 886: ({'logprob': [62.30323028564453, 17.0]}, 128)

======================Test output======================
logprob:  0.423386, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.977362e-03 [1.859942e-09] 
Layer 'conv1' biases: 1.524341e-08 [6.455846e-11] 
Layer 'conv2' weights[0]: 7.964282e-03 [1.994278e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.189512e-10] 
Layer 'conv3' weights[0]: 7.962641e-03 [2.153397e-09] 
Layer 'conv3' biases: 1.940293e-07 [1.251708e-09] 
Layer 'conv4' weights[0]: 7.995159e-03 [2.434858e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.304241e-08] 
Layer 'conv5' weights[0]: 7.994115e-03 [8.959684e-08] 
Layer 'conv5' biases: 1.000001e+00 [9.738486e-08] 
Layer 'fc6' weights[0]: 7.590901e-03 [8.364602e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.416321e-09] 
Layer 'fc7' weights[0]: 7.739471e-03 [5.884883e-08] 
Layer 'fc7' biases: 9.998755e-01 [3.745967e-08] 
Layer 'fc8' weights[0]: 1.028064e-03 [3.706893e-06] 
Layer 'fc8' biases: 4.633056e-03 [1.989067e-05] 
Train error last 870 batches: 0.435649
-------------------------------------------------------
Not saving because 0.423386 > 0.415712 (4.190: -0.00%)
======================================================= (12.116 sec)
4.391... logprob:  0.317637, 0.070312 (1.453 sec)
4.392... logprob:  0.439179, 0.117188 (1.436 sec)
4.393... logprob:  0.367189, 0.093750 (1.494 sec)
4.394... logprob:  0.343747, 0.078125 (1.436 sec)
4.395... logprob:  0.330727, 0.078125 (1.433 sec)
4.396... logprob:  0.251398, 0.046875 (1.436 sec)
4.397... logprob:  0.485892, 0.132812 (1.434 sec)
4.398... logprob:  0.473300, 0.125000 (1.434 sec)
4.399... logprob:  0.434273, 0.117188 (1.488 sec)
4.400... logprob:  0.540732, 0.148438 (1.429 sec)
4.401... logprob:  0.467190, 0.125000 (1.440 sec)
4.402... logprob:  0.475641, 0.125000 (1.493 sec)
4.403... logprob:  0.462349, 0.125000 (1.432 sec)
4.404... logprob:  0.475903, 0.125000 (1.438 sec)
4.405... logprob:  0.542721, 0.156250 (1.441 sec)
4.406... logprob:  0.359284, 0.085938 (1.427 sec)
4.407... logprob:  0.491527, 0.140625 (1.431 sec)
4.408... logprob:  0.342032, 0.078125 (1.486 sec)
4.409... logprob:  0.402628, 0.101562 (1.440 sec)
4.410... logprob:  0.581418, 0.171875 (1.452 sec)
4.411... logprob:  0.399314, 0.101562 (1.475 sec)
4.412... logprob:  0.540448, 0.156250 (1.435 sec)
4.413... logprob:  0.545432, 0.156250 (1.441 sec)
4.414... logprob:  0.467256, 0.125000 (1.433 sec)
4.415... logprob:  0.401556, 0.101562 (1.426 sec)
4.416... logprob:  0.427257, 0.109375 (1.442 sec)
4.417... logprob:  0.404252, 0.093750 (1.465 sec)
4.418... logprob:  0.378801, 0.093750 (1.448 sec)
4.419... logprob:  0.414881, 0.101562 (1.451 sec)
4.420... logprob:  0.354332, 0.085938 (1.457 sec)
4.421... logprob:  0.379992, 0.101562 (1.456 sec)
4.422... logprob:  0.527091, 0.148438 (1.441 sec)
4.423... logprob:  0.421265, 0.109375 (1.431 sec)
4.424... logprob:  0.324890, 0.078125 (1.429 sec)
4.425... logprob:  0.305001, 0.070312 (1.440 sec)
4.426... logprob:  0.449203, 0.117188 (1.455 sec)
4.427... logprob:  0.559314, 0.156250 (1.465 sec)
4.428... logprob:  0.605400, 0.171875 (1.455 sec)
4.429... logprob:  0.424759, 0.109375 (1.443 sec)
4.430... logprob:  0.301821, 0.070312 (1.473 sec)
4.431... logprob:  0.596579, 0.171875 (1.431 sec)
4.432... logprob:  0.386466, 0.093750 (1.425 sec)
4.433... logprob:  0.332533, 0.078125 (1.493 sec)
4.434... logprob:  0.527234, 0.148438 (1.442 sec)
4.435... logprob:  0.531848, 0.156250 (1.434 sec)
4.436... logprob:  0.383125, 0.093750 (1.476 sec)
4.437... logprob:  0.500110, 0.140625 (1.450 sec)
4.438... logprob:  0.546152, 0.156250 (1.431 sec)
4.439... logprob:  0.380399, 0.093750 (1.488 sec)
4.440... logprob:  0.440245, 0.117188 (1.439 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.589046478271484, 10.0]}, 128)
batch 872: ({'logprob': [65.84364318847656, 19.0]}, 128)
batch 873: ({'logprob': [42.67267608642578, 9.0]}, 128)
batch 874: ({'logprob': [46.76164627075195, 11.0]}, 128)
batch 875: ({'logprob': [51.751182556152344, 13.0]}, 128)
batch 876: ({'logprob': [63.57681655883789, 18.0]}, 128)
batch 877: ({'logprob': [47.21376037597656, 11.0]}, 128)
batch 878: ({'logprob': [61.7421989440918, 17.0]}, 128)
batch 879: ({'logprob': [72.16902160644531, 21.0]}, 128)
batch 880: ({'logprob': [51.757232666015625, 13.0]}, 128)
batch 881: ({'logprob': [32.22731399536133, 5.0]}, 128)
batch 882: ({'logprob': [55.36967468261719, 14.0]}, 128)
batch 883: ({'logprob': [61.73837661743164, 17.0]}, 128)
batch 884: ({'logprob': [52.191978454589844, 13.0]}, 128)
batch 885: ({'logprob': [53.08891677856445, 13.0]}, 128)
batch 886: ({'logprob': [62.1843376159668, 17.0]}, 128)

======================Test output======================
logprob:  0.421815, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.977320e-03 [2.536817e-09] 
Layer 'conv1' biases: 1.567962e-08 [5.401687e-11] 
Layer 'conv2' weights[0]: 7.964243e-03 [2.143464e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.959785e-10] 
Layer 'conv3' weights[0]: 7.962601e-03 [2.140644e-09] 
Layer 'conv3' biases: 1.971826e-07 [1.232328e-09] 
Layer 'conv4' weights[0]: 7.995122e-03 [2.382132e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.239872e-08] 
Layer 'conv5' weights[0]: 7.994076e-03 [8.534788e-08] 
Layer 'conv5' biases: 1.000001e+00 [9.277438e-08] 
Layer 'fc6' weights[0]: 7.590864e-03 [7.912709e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.970160e-09] 
Layer 'fc7' weights[0]: 7.737517e-03 [7.263124e-08] 
Layer 'fc7' biases: 9.998745e-01 [5.424181e-08] 
Layer 'fc8' weights[0]: 1.054425e-03 [3.546005e-06] 
Layer 'fc8' biases: 5.044987e-03 [2.273644e-05] 
Train error last 870 batches: 0.435631
-------------------------------------------------------
Not saving because 0.421815 > 0.415712 (4.190: -0.00%)
======================================================= (12.077 sec)
4.441... logprob:  0.468086, 0.125000 (1.440 sec)
4.442... logprob:  0.378477, 0.093750 (1.438 sec)
4.443... logprob:  0.496648, 0.140625 (1.431 sec)
4.444... logprob:  0.371052, 0.093750 (1.436 sec)
4.445... logprob:  0.360999, 0.085938 (1.487 sec)
4.446... logprob:  0.397475, 0.101562 (1.436 sec)
4.447... logprob:  0.572476, 0.164062 (1.445 sec)
4.448... logprob:  0.331453, 0.078125 (1.482 sec)
4.449... logprob:  0.400127, 0.101562 (1.434 sec)
4.450... logprob:  0.237083, 0.046875 (1.431 sec)
4.451... logprob:  0.453873, 0.125000 (1.444 sec)
4.452... logprob:  0.457284, 0.117188 (1.427 sec)
4.453... logprob:  0.456023, 0.125000 (1.437 sec)
4.454... logprob:  0.489704, 0.132812 (1.485 sec)
4.455... logprob:  0.505812, 0.140625 (1.437 sec)
4.456... logprob:  0.468704, 0.125000 (1.448 sec)
4.457... logprob:  0.375718, 0.093750 (1.479 sec)
4.458... logprob:  0.351862, 0.085938 (1.434 sec)
4.459... logprob:  0.513447, 0.140625 (1.441 sec)
4.460... logprob:  0.277200, 0.054688 (1.435 sec)
4.461... logprob:  0.459752, 0.125000 (1.426 sec)
4.462... logprob:  0.472595, 0.125000 (1.436 sec)
4.463... logprob:  0.421418, 0.109375 (1.474 sec)
4.464... logprob:  0.482617, 0.132812 (1.446 sec)
4.465... logprob:  0.421433, 0.109375 (1.459 sec)
4.466... logprob:  0.318815, 0.070312 (1.458 sec)
4.467... logprob:  0.413878, 0.109375 (1.457 sec)
4.468... logprob:  0.394191, 0.101562 (1.436 sec)
4.469... logprob:  0.333958, 0.078125 (1.433 sec)
4.470... logprob:  0.399730, 0.101562 (1.428 sec)
4.471... logprob:  0.530709, 0.148438 (1.436 sec)
4.472... logprob:  0.411086, 0.109375 (1.450 sec)
4.473... logprob:  0.375049, 0.093750 (1.459 sec)
4.474... logprob:  0.466249, 0.125000 (1.454 sec)
4.475... logprob:  0.505742, 0.140625 (1.460 sec)
4.476... logprob:  0.510825, 0.140625 (1.468 sec)
4.477... logprob:  0.334100, 0.078125 (1.441 sec)
4.478... logprob:  0.464178, 0.125000 (1.422 sec)
4.479... logprob:  0.306455, 0.070312 (1.431 sec)
4.480... logprob:  0.443290, 0.117188 (1.440 sec)
4.481... logprob:  0.547301, 0.156250 (1.435 sec)
4.482... logprob:  0.443075, 0.117188 (1.476 sec)
4.483... logprob:  0.502290, 0.140625 (1.449 sec)
4.484... logprob:  0.485020, 0.132812 (1.439 sec)
4.485... logprob:  0.409969, 0.109375 (1.484 sec)
4.486... logprob:  0.362306, 0.085938 (1.436 sec)
4.487... logprob:  0.522433, 0.148438 (1.429 sec)
4.488... logprob:  0.425178, 0.109375 (1.439 sec)
4.489... logprob:  0.416227, 0.109375 (1.435 sec)
4.490... logprob:  0.440753, 0.117188 (1.437 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.60557556152344, 10.0]}, 128)
batch 872: ({'logprob': [66.18234252929688, 19.0]}, 128)
batch 873: ({'logprob': [41.33869171142578, 9.0]}, 128)
batch 874: ({'logprob': [45.83317184448242, 11.0]}, 128)
batch 875: ({'logprob': [51.10911178588867, 13.0]}, 128)
batch 876: ({'logprob': [63.74300003051758, 18.0]}, 128)
batch 877: ({'logprob': [46.22526931762695, 11.0]}, 128)
batch 878: ({'logprob': [61.67498779296875, 17.0]}, 128)
batch 879: ({'logprob': [72.6169204711914, 21.0]}, 128)
batch 880: ({'logprob': [51.11561584472656, 13.0]}, 128)
batch 881: ({'logprob': [30.377403259277344, 5.0]}, 128)
batch 882: ({'logprob': [54.72450256347656, 14.0]}, 128)
batch 883: ({'logprob': [61.67123794555664, 17.0]}, 128)
batch 884: ({'logprob': [51.49151611328125, 13.0]}, 128)
batch 885: ({'logprob': [52.27092361450195, 13.0]}, 128)
batch 886: ({'logprob': [62.05859375, 17.0]}, 128)

======================Test output======================
logprob:  0.417499, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.977278e-03 [1.614692e-09] 
Layer 'conv1' biases: 1.604602e-08 [3.174799e-11] 
Layer 'conv2' weights[0]: 7.964207e-03 [1.475058e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.209145e-10] 
Layer 'conv3' weights[0]: 7.962559e-03 [1.436570e-09] 
Layer 'conv3' biases: 1.997845e-07 [6.715071e-10] 
Layer 'conv4' weights[0]: 7.995082e-03 [1.614711e-09] 
Layer 'conv4' biases: 9.999999e-01 [6.924600e-09] 
Layer 'conv5' weights[0]: 7.994046e-03 [4.771552e-08] 
Layer 'conv5' biases: 1.000001e+00 [5.190941e-08] 
Layer 'fc6' weights[0]: 7.590826e-03 [4.510889e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.466840e-09] 
Layer 'fc7' weights[0]: 7.735496e-03 [9.677191e-08] 
Layer 'fc7' biases: 9.998749e-01 [8.044297e-08] 
Layer 'fc8' weights[0]: 1.094091e-03 [4.540111e-06] 
Layer 'fc8' biases: 5.403904e-03 [2.516876e-05] 
Train error last 870 batches: 0.435638
-------------------------------------------------------
Not saving because 0.417499 > 0.415712 (4.190: -0.00%)
======================================================= (12.083 sec)
4.491... logprob:  0.313790, 0.070312 (1.492 sec)
4.492... logprob:  0.459725, 0.125000 (1.448 sec)
4.493... logprob:  0.522323, 0.148438 (1.439 sec)
4.494... logprob:  0.450323, 0.125000 (1.486 sec)
4.495... logprob:  0.380442, 0.093750 (1.432 sec)
4.496... logprob:  0.551248, 0.156250 (1.434 sec)
4.497... logprob:  0.467565, 0.125000 (1.437 sec)
4.498... logprob:  0.476322, 0.132812 (1.434 sec)
4.499... logprob:  0.456159, 0.125000 (1.435 sec)
4.500... logprob:  0.354932, 0.085938 (1.491 sec)
4.501... logprob:  0.339472, 0.078125 (1.432 sec)
4.502... logprob:  0.459736, 0.125000 (1.446 sec)
4.503... logprob:  0.401045, 0.101562 (1.476 sec)
4.504... logprob:  0.487754, 0.132812 (1.436 sec)
4.505... logprob:  0.570997, 0.164062 (1.438 sec)
4.506... logprob:  0.479588, 0.132812 (1.440 sec)
4.507... logprob:  0.385713, 0.093750 (1.427 sec)
4.508... logprob:  0.374813, 0.093750 (1.436 sec)
4.509... logprob:  0.323685, 0.070312 (1.476 sec)
4.510... logprob:  0.390443, 0.101562 (1.447 sec)
4.511... logprob:  0.410191, 0.109375 (1.449 sec)
4.512... logprob:  0.470742, 0.125000 (1.472 sec)
4.513... logprob:  0.325059, 0.078125 (1.445 sec)
4.514... logprob:  0.405967, 0.101562 (1.440 sec)
4.515... logprob:  0.456291, 0.125000 (1.431 sec)
4.516... logprob:  0.401671, 0.109375 (1.430 sec)
4.517... logprob:  0.628361, 0.179688 (1.435 sec)
4.518... logprob:  0.437918, 0.117188 (1.466 sec)
4.519... logprob:  0.516020, 0.140625 (1.453 sec)
4.520... logprob:  0.409749, 0.109375 (1.458 sec)
4.521... logprob:  0.427766, 0.109375 (1.450 sec)
4.522... logprob:  0.532710, 0.156250 (1.474 sec)
4.523... logprob:  0.332342, 0.078125 (1.439 sec)
4.524... logprob:  0.437365, 0.117188 (1.427 sec)
4.525... logprob:  0.426817, 0.109375 (1.436 sec)
4.526... logprob:  0.353355, 0.078125 (1.436 sec)
4.527... logprob:  0.504611, 0.140625 (1.442 sec)
4.528... logprob:  0.440662, 0.117188 (1.475 sec)
4.529... logprob:  0.352944, 0.085938 (1.447 sec)
4.530... logprob:  0.440257, 0.117188 (1.445 sec)
4.531... logprob:  0.440147, 0.117188 (1.480 sec)
4.532... logprob:  0.467597, 0.125000 (1.437 sec)
4.533... logprob:  0.561850, 0.164062 (1.426 sec)
4.534... logprob:  0.325465, 0.078125 (1.436 sec)
4.535... logprob:  0.552313, 0.156250 (1.441 sec)
4.536... logprob:  0.507724, 0.140625 (1.434 sec)
4.537... logprob:  0.510233, 0.140625 (1.492 sec)
4.538... logprob:  0.486124, 0.132812 (1.442 sec)
4.539... logprob:  0.296167, 0.062500 (1.436 sec)
4.540... logprob:  0.446987, 0.117188 (1.487 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.50074768066406, 10.0]}, 128)
batch 872: ({'logprob': [66.19487762451172, 19.0]}, 128)
batch 873: ({'logprob': [41.268646240234375, 9.0]}, 128)
batch 874: ({'logprob': [45.762969970703125, 11.0]}, 128)
batch 875: ({'logprob': [51.066410064697266, 13.0]}, 128)
batch 876: ({'logprob': [63.748878479003906, 18.0]}, 128)
batch 877: ({'logprob': [46.16888427734375, 11.0]}, 128)
batch 878: ({'logprob': [61.68767166137695, 17.0]}, 128)
batch 879: ({'logprob': [72.69854736328125, 21.0]}, 128)
batch 880: ({'logprob': [51.07305908203125, 13.0]}, 128)
batch 881: ({'logprob': [30.23819351196289, 5.0]}, 128)
batch 882: ({'logprob': [54.730384826660156, 14.0]}, 128)
batch 883: ({'logprob': [61.6837158203125, 17.0]}, 128)
batch 884: ({'logprob': [51.46268081665039, 13.0]}, 128)
batch 885: ({'logprob': [52.26992416381836, 13.0]}, 128)
batch 886: ({'logprob': [62.08513259887695, 17.0]}, 128)

======================Test output======================
logprob:  0.417305, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.977235e-03 [2.079095e-09] 
Layer 'conv1' biases: 1.650044e-08 [4.302206e-11] 
Layer 'conv2' weights[0]: 7.964164e-03 [1.436665e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.285476e-10] 
Layer 'conv3' weights[0]: 7.962522e-03 [1.402632e-09] 
Layer 'conv3' biases: 2.050329e-07 [6.820361e-10] 
Layer 'conv4' weights[0]: 7.995041e-03 [1.550171e-09] 
Layer 'conv4' biases: 9.999999e-01 [6.307619e-09] 
Layer 'conv5' weights[0]: 7.994006e-03 [4.220576e-08] 
Layer 'conv5' biases: 1.000001e+00 [4.598811e-08] 
Layer 'fc6' weights[0]: 7.590782e-03 [4.046858e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.001834e-09] 
Layer 'fc7' weights[0]: 7.733541e-03 [5.475010e-08] 
Layer 'fc7' biases: 9.998749e-01 [3.268196e-08] 
Layer 'fc8' weights[0]: 1.101532e-03 [5.335867e-06] 
Layer 'fc8' biases: 5.510666e-03 [2.753697e-05] 
Train error last 870 batches: 0.435595
-------------------------------------------------------
Not saving because 0.417305 > 0.415712 (4.190: -0.00%)
======================================================= (12.111 sec)
4.541... logprob:  0.389494, 0.101562 (1.436 sec)
4.542... logprob:  0.411836, 0.109375 (1.444 sec)
4.543... logprob:  0.233799, 0.039062 (1.439 sec)
4.544... logprob:  0.317853, 0.070312 (1.431 sec)
4.545... logprob:  0.349137, 0.085938 (1.440 sec)
4.546... logprob:  0.368711, 0.093750 (1.486 sec)
4.547... logprob:  0.440454, 0.117188 (1.433 sec)
4.548... logprob:  0.454359, 0.125000 (1.450 sec)
4.549... logprob:  0.491037, 0.132812 (1.478 sec)
4.550... logprob:  0.367904, 0.093750 (1.436 sec)
4.551... logprob:  0.441853, 0.117188 (1.435 sec)
4.552... logprob:  0.471266, 0.125000 (1.439 sec)
4.553... logprob:  0.349499, 0.085938 (1.427 sec)
4.554... logprob:  0.506135, 0.140625 (1.439 sec)
4.555... logprob:  0.421654, 0.109375 (1.478 sec)
4.556... logprob:  0.356757, 0.085938 (1.433 sec)
4.557... logprob:  0.396922, 0.101562 (1.455 sec)
4.558... logprob:  0.382232, 0.101562 (1.472 sec)
4.559... logprob:  0.439637, 0.125000 (1.438 sec)
4.560... logprob:  0.336299, 0.078125 (1.439 sec)
4.561... logprob:  0.411606, 0.109375 (1.433 sec)
4.562... logprob:  0.503539, 0.140625 (1.429 sec)
4.563... logprob:  0.374078, 0.093750 (1.438 sec)
4.564... logprob:  0.467499, 0.132812 (1.468 sec)
4.565... logprob:  0.609939, 0.187500 (1.450 sec)
4.566... logprob:  0.375105, 0.093750 (1.457 sec)
4.567... logprob:  0.424590, 0.109375 (1.453 sec)
4.568... logprob:  0.496682, 0.140625 (1.459 sec)
4.569... logprob:  0.509467, 0.140625 (1.438 sec)
4.570... logprob:  0.542847, 0.164062 (1.432 sec)
4.571... logprob:  0.454865, 0.125000 (1.429 sec)
4.572... logprob:  0.502384, 0.140625 (1.440 sec)
4.573... logprob:  0.512762, 0.148438 (1.451 sec)
4.574... logprob:  0.429031, 0.109375 (1.463 sec)
4.575... logprob:  0.343237, 0.078125 (1.455 sec)
4.576... logprob:  0.427871, 0.109375 (1.447 sec)
4.577... logprob:  0.461059, 0.125000 (1.473 sec)
4.578... logprob:  0.335848, 0.078125 (1.436 sec)
4.579... logprob:  0.441992, 0.117188 (1.426 sec)
4.580... logprob:  0.547749, 0.156250 (1.438 sec)
4.581... logprob:  0.532569, 0.156250 (1.440 sec)
4.582... logprob:  0.439225, 0.125000 (1.434 sec)
4.583... logprob:  0.593537, 0.171875 (1.482 sec)
4.584... logprob:  0.468861, 0.132812 (1.443 sec)
4.585... logprob:  0.349899, 0.085938 (1.439 sec)
4.586... logprob:  0.313338, 0.070312 (1.487 sec)
4.587... logprob:  0.403902, 0.101562 (1.434 sec)
4.588... logprob:  0.419689, 0.117188 (1.431 sec)
4.589... logprob:  0.362357, 0.093750 (1.439 sec)
4.590... logprob:  0.523964, 0.148438 (1.434 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.31809616088867, 10.0]}, 128)
batch 872: ({'logprob': [66.39024353027344, 19.0]}, 128)
batch 873: ({'logprob': [41.02983856201172, 9.0]}, 128)
batch 874: ({'logprob': [45.22872543334961, 11.0]}, 128)
batch 875: ({'logprob': [50.87385559082031, 13.0]}, 128)
batch 876: ({'logprob': [63.93243408203125, 18.0]}, 128)
batch 877: ({'logprob': [45.95218276977539, 11.0]}, 128)
batch 878: ({'logprob': [62.178077697753906, 17.0]}, 128)
batch 879: ({'logprob': [74.18924713134766, 21.0]}, 128)
batch 880: ({'logprob': [50.87977600097656, 13.0]}, 128)
batch 881: ({'logprob': [28.997802734375, 5.0]}, 128)
batch 882: ({'logprob': [55.50496292114258, 14.0]}, 128)
batch 883: ({'logprob': [62.17436599731445, 17.0]}, 128)
batch 884: ({'logprob': [51.58876037597656, 13.0]}, 128)
batch 885: ({'logprob': [53.03351974487305, 13.0]}, 128)
batch 886: ({'logprob': [62.894248962402344, 17.0]}, 128)

======================Test output======================
logprob:  0.418050, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.977197e-03 [1.836070e-09] 
Layer 'conv1' biases: 1.690386e-08 [3.727680e-11] 
Layer 'conv2' weights[0]: 7.964122e-03 [1.510207e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.833822e-10] 
Layer 'conv3' weights[0]: 7.962479e-03 [1.295758e-09] 
Layer 'conv3' biases: 2.072639e-07 [5.466643e-10] 
Layer 'conv4' weights[0]: 7.994997e-03 [1.346706e-09] 
Layer 'conv4' biases: 9.999999e-01 [4.192294e-09] 
Layer 'conv5' weights[0]: 7.993970e-03 [2.840270e-08] 
Layer 'conv5' biases: 1.000001e+00 [3.085205e-08] 
Layer 'fc6' weights[0]: 7.590745e-03 [2.775023e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.705534e-09] 
Layer 'fc7' weights[0]: 7.731549e-03 [5.619866e-08] 
Layer 'fc7' biases: 9.998755e-01 [3.424636e-08] 
Layer 'fc8' weights[0]: 1.144391e-03 [3.311559e-06] 
Layer 'fc8' biases: 5.837522e-03 [1.761500e-05] 
Train error last 870 batches: 0.435552
-------------------------------------------------------
Not saving because 0.418050 > 0.415712 (4.190: -0.00%)
======================================================= (12.102 sec)
4.591... logprob:  0.397485, 0.101562 (1.434 sec)
4.592... logprob:  0.455469, 0.125000 (1.488 sec)
4.593... logprob:  0.466838, 0.125000 (1.434 sec)
4.594... logprob:  0.353094, 0.085938 (1.440 sec)
4.595... logprob:  0.428114, 0.109375 (1.495 sec)
4.596... logprob:  0.461283, 0.125000 (1.431 sec)
4.597... logprob:  0.397205, 0.101562 (1.439 sec)
4.598... logprob:  0.397031, 0.101562 (1.435 sec)
4.599... logprob:  0.312885, 0.070312 (1.428 sec)
4.600... logprob:  0.341294, 0.085938 (1.437 sec)
4.601... logprob:  0.401531, 0.101562 (1.487 sec)
4.602... logprob:  0.288478, 0.062500 (1.439 sec)
4.603... logprob:  0.265365, 0.054688 (1.443 sec)
4.604... logprob:  0.406560, 0.101562 (1.484 sec)
4.605... logprob:  0.562297, 0.148438 (1.433 sec)
4.606... logprob:  0.296532, 0.070312 (1.441 sec)
4.607... logprob:  0.504411, 0.132812 (1.433 sec)
4.608... logprob:  0.359583, 0.085938 (1.427 sec)
4.609... logprob:  0.355586, 0.085938 (1.437 sec)
4.610... logprob:  0.494157, 0.132812 (1.472 sec)
4.611... logprob:  0.512364, 0.140625 (1.453 sec)
4.612... logprob:  0.447035, 0.117188 (1.453 sec)
4.613... logprob:  0.282180, 0.062500 (1.466 sec)
4.614... logprob:  0.505028, 0.140625 (1.446 sec)
4.615... logprob:  0.353061, 0.085938 (1.438 sec)
4.616... logprob:  0.417289, 0.109375 (1.433 sec)
4.617... logprob:  0.418982, 0.109375 (1.431 sec)
4.618... logprob:  0.545899, 0.156250 (1.438 sec)
4.619... logprob:  0.505129, 0.140625 (1.456 sec)
4.620... logprob:  0.540020, 0.156250 (1.457 sec)
4.621... logprob:  0.364780, 0.085938 (1.455 sec)
4.622... logprob:  0.365725, 0.085938 (1.452 sec)
4.623... logprob:  0.423584, 0.109375 (1.469 sec)
4.624... logprob:  0.382913, 0.093750 (1.442 sec)
4.625... logprob:  0.441161, 0.117188 (1.423 sec)
4.626... logprob:  0.438564, 0.117188 (1.436 sec)
4.627... logprob:  0.435952, 0.117188 (1.439 sec)
4.628... logprob:  0.465265, 0.125000 (1.438 sec)
4.629... logprob:  0.371597, 0.093750 (1.477 sec)
4.630... logprob:  0.422563, 0.109375 (1.446 sec)
4.631... logprob:  0.640605, 0.187500 (1.442 sec)
4.632... logprob:  0.399227, 0.101562 (1.482 sec)
4.633... logprob:  0.375876, 0.093750 (1.438 sec)
4.634... logprob:  0.661468, 0.195312 (1.425 sec)
4.635... logprob:  0.373753, 0.093750 (1.435 sec)
4.636... logprob:  0.479892, 0.132812 (1.430 sec)
4.637... logprob:  0.330263, 0.078125 (1.438 sec)
4.638... logprob:  0.517680, 0.140625 (1.479 sec)
4.639... logprob:  0.418029, 0.109375 (1.444 sec)
4.640... logprob:  0.529702, 0.148438 (1.438 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.6797981262207, 10.0]}, 128)
batch 872: ({'logprob': [66.12138366699219, 19.0]}, 128)
batch 873: ({'logprob': [41.46988296508789, 9.0]}, 128)
batch 874: ({'logprob': [45.91120910644531, 11.0]}, 128)
batch 875: ({'logprob': [51.15823745727539, 13.0]}, 128)
batch 876: ({'logprob': [63.702796936035156, 18.0]}, 128)
batch 877: ({'logprob': [46.315574645996094, 11.0]}, 128)
batch 878: ({'logprob': [61.66680145263672, 17.0]}, 128)
batch 879: ({'logprob': [72.56290435791016, 21.0]}, 128)
batch 880: ({'logprob': [51.16498947143555, 13.0]}, 128)
batch 881: ({'logprob': [30.553747177124023, 5.0]}, 128)
batch 882: ({'logprob': [54.78931427001953, 14.0]}, 128)
batch 883: ({'logprob': [61.66274642944336, 17.0]}, 128)
batch 884: ({'logprob': [51.55241394042969, 13.0]}, 128)
batch 885: ({'logprob': [52.35580825805664, 13.0]}, 128)
batch 886: ({'logprob': [62.06217575073242, 17.0]}, 128)

======================Test output======================
logprob:  0.417837, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.977157e-03 [2.195517e-09] 
Layer 'conv1' biases: 1.741728e-08 [3.573074e-11] 
Layer 'conv2' weights[0]: 7.964081e-03 [1.563737e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.801506e-10] 
Layer 'conv3' weights[0]: 7.962438e-03 [1.288857e-09] 
Layer 'conv3' biases: 2.131894e-07 [5.963090e-10] 
Layer 'conv4' weights[0]: 7.994961e-03 [1.397131e-09] 
Layer 'conv4' biases: 9.999999e-01 [4.819957e-09] 
Layer 'conv5' weights[0]: 7.993932e-03 [3.284354e-08] 
Layer 'conv5' biases: 1.000001e+00 [3.561680e-08] 
Layer 'fc6' weights[0]: 7.590707e-03 [3.114701e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.066216e-09] 
Layer 'fc7' weights[0]: 7.729588e-03 [1.199906e-07] 
Layer 'fc7' biases: 9.998744e-01 [1.053413e-07] 
Layer 'fc8' weights[0]: 1.114469e-03 [5.034094e-06] 
Layer 'fc8' biases: 5.792674e-03 [2.540866e-05] 
Train error last 870 batches: 0.435536
-------------------------------------------------------
Not saving because 0.417837 > 0.415712 (4.190: -0.00%)
======================================================= (12.055 sec)
4.641... logprob:  0.409198, 0.109375 (1.492 sec)
4.642... logprob:  0.500613, 0.140625 (1.443 sec)
4.643... logprob:  0.622425, 0.187500 (1.431 sec)
4.644... logprob:  0.321820, 0.070312 (1.432 sec)
4.645... logprob:  0.413701, 0.109375 (1.428 sec)
4.646... logprob:  0.386505, 0.093750 (1.434 sec)
4.647... logprob:  0.456283, 0.125000 (1.488 sec)
4.648... logprob:  0.490177, 0.140625 (1.433 sec)
4.649... logprob:  0.369115, 0.093750 (1.443 sec)
4.650... logprob:  0.413431, 0.109375 (1.478 sec)
4.651... logprob:  0.397354, 0.101562 (1.431 sec)
4.652... logprob:  0.508100, 0.140625 (1.443 sec)
4.653... logprob:  0.548642, 0.156250 (1.434 sec)
4.654... logprob:  0.495573, 0.140625 (1.430 sec)
4.655... logprob:  0.436073, 0.117188 (1.432 sec)
4.656... logprob:  0.416662, 0.109375 (1.479 sec)
4.657... logprob:  0.450673, 0.117188 (1.436 sec)
4.658... logprob:  0.344960, 0.085938 (1.453 sec)
4.659... logprob:  0.464980, 0.125000 (1.471 sec)
4.660... logprob:  0.444820, 0.125000 (1.439 sec)
4.661... logprob:  0.379001, 0.093750 (1.438 sec)
4.662... logprob:  0.468636, 0.132812 (1.433 sec)
4.663... logprob:  0.311219, 0.070312 (1.424 sec)
4.664... logprob:  0.285427, 0.062500 (1.439 sec)
4.665... logprob:  0.402513, 0.101562 (1.464 sec)
4.666... logprob:  0.442383, 0.117188 (1.456 sec)
4.667... logprob:  0.564539, 0.164062 (1.452 sec)
4.668... logprob:  0.498045, 0.140625 (1.446 sec)
4.669... logprob:  0.433875, 0.109375 (1.456 sec)
4.670... logprob:  0.362919, 0.085938 (1.441 sec)
4.671... logprob:  0.360628, 0.093750 (1.429 sec)
4.672... logprob:  0.441891, 0.117188 (1.430 sec)
4.673... logprob:  0.436307, 0.117188 (1.442 sec)
4.674... logprob:  0.446770, 0.117188 (1.440 sec)
4.675... logprob:  0.356694, 0.093750 (1.464 sec)
4.676... logprob:  0.450224, 0.125000 (1.450 sec)
4.677... logprob:  0.471013, 0.125000 (1.446 sec)
4.678... logprob:  0.465534, 0.125000 (1.479 sec)
4.679... logprob:  0.454936, 0.125000 (1.439 sec)
4.680... logprob:  0.351556, 0.078125 (1.424 sec)
4.681... logprob:  0.374078, 0.093750 (1.439 sec)
4.682... logprob:  0.340252, 0.078125 (1.438 sec)
4.683... logprob:  0.411908, 0.109375 (1.434 sec)
4.684... logprob:  0.357091, 0.085938 (1.477 sec)
4.685... logprob:  0.283699, 0.054688 (1.443 sec)
4.686... logprob:  0.316808, 0.070312 (1.434 sec)
4.687... logprob:  0.280955, 0.062500 (1.491 sec)
4.688... logprob:  0.323505, 0.078125 (1.430 sec)
4.689... logprob:  0.472883, 0.125000 (1.432 sec)
4.690... logprob:  0.528933, 0.140625 (1.442 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.131412506103516, 10.0]}, 128)
batch 872: ({'logprob': [70.0343017578125, 19.0]}, 128)
batch 873: ({'logprob': [39.146602630615234, 9.0]}, 128)
batch 874: ({'logprob': [44.89381408691406, 11.0]}, 128)
batch 875: ({'logprob': [51.346641540527344, 13.0]}, 128)
batch 876: ({'logprob': [66.98905944824219, 18.0]}, 128)
batch 877: ({'logprob': [45.246116638183594, 11.0]}, 128)
batch 878: ({'logprob': [64.27275848388672, 17.0]}, 128)
batch 879: ({'logprob': [77.53553771972656, 21.0]}, 128)
batch 880: ({'logprob': [51.35438537597656, 13.0]}, 128)
batch 881: ({'logprob': [25.86111068725586, 5.0]}, 128)
batch 882: ({'logprob': [55.463783264160156, 14.0]}, 128)
batch 883: ({'logprob': [64.26910400390625, 17.0]}, 128)
batch 884: ({'logprob': [51.69478988647461, 13.0]}, 128)
batch 885: ({'logprob': [52.40333557128906, 13.0]}, 128)
batch 886: ({'logprob': [64.62158203125, 17.0]}, 128)

======================Test output======================
logprob:  0.422981, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.977113e-03 [3.366690e-09] 
Layer 'conv1' biases: 1.763921e-08 [1.102577e-10] 
Layer 'conv2' weights[0]: 7.964037e-03 [3.116579e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.902967e-10] 
Layer 'conv3' weights[0]: 7.962400e-03 [3.370013e-09] 
Layer 'conv3' biases: 2.125698e-07 [2.167057e-09] 
Layer 'conv4' weights[0]: 7.994921e-03 [3.748988e-09] 
Layer 'conv4' biases: 9.999999e-01 [2.188131e-08] 
Layer 'conv5' weights[0]: 7.993885e-03 [1.501495e-07] 
Layer 'conv5' biases: 1.000000e+00 [1.630054e-07] 
Layer 'fc6' weights[0]: 7.590662e-03 [1.406913e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.428361e-08] 
Layer 'fc7' weights[0]: 7.727539e-03 [5.423306e-08] 
Layer 'fc7' biases: 9.998767e-01 [3.162258e-08] 
Layer 'fc8' weights[0]: 1.244408e-03 [7.322272e-06] 
Layer 'fc8' biases: 6.572490e-03 [4.052482e-05] 
Train error last 870 batches: 0.435524
-------------------------------------------------------
Not saving because 0.422981 > 0.415712 (4.190: -0.00%)
======================================================= (12.101 sec)
4.691... logprob:  0.520505, 0.140625 (1.441 sec)
4.692... logprob:  0.389493, 0.101562 (1.437 sec)
4.693... logprob:  0.460147, 0.125000 (1.489 sec)
4.694... logprob:  0.330176, 0.078125 (1.440 sec)
4.695... logprob:  0.355931, 0.085938 (1.439 sec)
4.696... logprob:  0.537366, 0.148438 (1.485 sec)
4.697... logprob:  0.465001, 0.125000 (1.456 sec)
4.698... logprob:  0.547656, 0.156250 (1.436 sec)
4.699... logprob:  0.459647, 0.125000 (1.441 sec)
4.700... logprob:  0.434850, 0.117188 (1.429 sec)
4.701... logprob:  0.424020, 0.109375 (1.432 sec)
4.702... logprob:  0.521253, 0.148438 (1.486 sec)
4.703... logprob:  0.406503, 0.101562 (1.438 sec)
4.704... logprob:  0.407089, 0.101562 (1.455 sec)
4.705... logprob:  0.420699, 0.109375 (1.472 sec)
4.706... logprob:  0.468225, 0.125000 (1.441 sec)
4.707... logprob:  0.485383, 0.132812 (1.436 sec)
4.708... logprob:  0.416801, 0.109375 (1.434 sec)
4.709... logprob:  0.422198, 0.109375 (1.428 sec)
4.710... logprob:  0.603821, 0.179688 (1.437 sec)
4.711... logprob:  0.469719, 0.125000 (1.469 sec)
4.712... logprob:  0.339439, 0.078125 (1.454 sec)
4.713... logprob:  0.589000, 0.179688 (1.454 sec)
4.714... logprob:  0.466540, 0.125000 (1.464 sec)
4.715... logprob:  0.417045, 0.109375 (1.458 sec)
4.716... logprob:  0.334829, 0.078125 (1.437 sec)
4.717... logprob:  0.429829, 0.117188 (1.430 sec)
4.718... logprob:  0.490677, 0.132812 (1.427 sec)
4.719... logprob:  0.405971, 0.109375 (1.436 sec)
4.720... logprob:  0.433037, 0.117188 (1.448 sec)
4.721... logprob:  0.452043, 0.117188 (1.467 sec)
4.722... logprob:  0.535996, 0.156250 (1.451 sec)
4.723... logprob:  0.416676, 0.109375 (1.446 sec)
4.724... logprob:  0.412592, 0.109375 (1.477 sec)
4.725... logprob:  0.493872, 0.140625 (1.436 sec)
4.726... logprob:  0.338025, 0.085938 (1.430 sec)
4.727... logprob:  0.393562, 0.101562 (1.429 sec)
4.728... logprob:  0.422098, 0.109375 (1.437 sec)
4.729... logprob:  0.389529, 0.093750 (1.435 sec)
4.730... logprob:  0.565724, 0.164062 (1.475 sec)
4.731... logprob:  0.449565, 0.125000 (1.452 sec)
4.732... logprob:  0.311729, 0.070312 (1.429 sec)
4.733... logprob:  0.558246, 0.156250 (1.482 sec)
4.734... logprob:  0.340809, 0.078125 (1.440 sec)
4.735... logprob:  0.528543, 0.148438 (1.427 sec)
4.736... logprob:  0.645193, 0.187500 (1.437 sec)
4.737... logprob:  0.516473, 0.148438 (1.438 sec)
4.738... logprob:  0.459586, 0.125000 (1.431 sec)
4.739... logprob:  0.477877, 0.132812 (1.489 sec)
4.740... logprob:  0.338978, 0.078125 (1.435 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.8680305480957, 10.0]}, 128)
batch 872: ({'logprob': [65.75729370117188, 19.0]}, 128)
batch 873: ({'logprob': [42.33660888671875, 9.0]}, 128)
batch 874: ({'logprob': [46.316646575927734, 11.0]}, 128)
batch 875: ({'logprob': [51.46141815185547, 13.0]}, 128)
batch 876: ({'logprob': [63.47911834716797, 18.0]}, 128)
batch 877: ({'logprob': [46.90049743652344, 11.0]}, 128)
batch 878: ({'logprob': [61.763790130615234, 17.0]}, 128)
batch 879: ({'logprob': [72.63253784179688, 21.0]}, 128)
batch 880: ({'logprob': [51.4675178527832, 13.0]}, 128)
batch 881: ({'logprob': [31.44744873046875, 5.0]}, 128)
batch 882: ({'logprob': [55.487815856933594, 14.0]}, 128)
batch 883: ({'logprob': [61.759742736816406, 17.0]}, 128)
batch 884: ({'logprob': [52.03378677368164, 13.0]}, 128)
batch 885: ({'logprob': [53.195045471191406, 13.0]}, 128)
batch 886: ({'logprob': [62.337650299072266, 17.0]}, 128)

======================Test output======================
logprob:  0.420530, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.977067e-03 [1.973318e-09] 
Layer 'conv1' biases: 1.835537e-08 [4.336076e-11] 
Layer 'conv2' weights[0]: 7.964004e-03 [2.178469e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.566303e-10] 
Layer 'conv3' weights[0]: 7.962362e-03 [2.128997e-09] 
Layer 'conv3' biases: 2.213393e-07 [1.155575e-09] 
Layer 'conv4' weights[0]: 7.994885e-03 [2.438410e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.171736e-08] 
Layer 'conv5' weights[0]: 7.993858e-03 [8.047874e-08] 
Layer 'conv5' biases: 1.000001e+00 [8.743771e-08] 
Layer 'fc6' weights[0]: 7.590624e-03 [7.382693e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.445066e-09] 
Layer 'fc7' weights[0]: 7.725602e-03 [7.886371e-08] 
Layer 'fc7' biases: 9.998735e-01 [6.221035e-08] 
Layer 'fc8' weights[0]: 1.117044e-03 [4.644862e-06] 
Layer 'fc8' biases: 6.018064e-03 [2.411787e-05] 
Train error last 870 batches: 0.435487
-------------------------------------------------------
Not saving because 0.420530 > 0.415712 (4.190: -0.00%)
======================================================= (12.072 sec)
4.741... logprob:  0.392972, 0.101562 (1.439 sec)
4.742... logprob:  0.419608, 0.109375 (1.485 sec)
4.743... logprob:  0.364593, 0.085938 (1.434 sec)
4.744... logprob:  0.519482, 0.148438 (1.432 sec)
4.745... logprob:  0.478287, 0.132812 (1.440 sec)
4.746... logprob:  0.440508, 0.117188 (1.429 sec)
4.747... logprob:  0.425349, 0.109375 (1.438 sec)
4.748... logprob:  0.377879, 0.093750 (1.483 sec)
4.749... logprob:  0.420668, 0.109375 (1.433 sec)
4.750... logprob:  0.512316, 0.140625 (1.443 sec)
4.751... logprob:  0.263695, 0.054688 (1.482 sec)
4.752... logprob:  0.520779, 0.140625 (1.437 sec)
4.753... logprob:  0.441301, 0.117188 (1.437 sec)
4.754... logprob:  0.471262, 0.132812 (1.437 sec)
4.755... logprob:  0.507283, 0.140625 (1.425 sec)
4.756... logprob:  0.440825, 0.117188 (1.439 sec)
4.757... logprob:  0.551668, 0.156250 (1.472 sec)
4.758... logprob:  0.394382, 0.101562 (1.445 sec)
4.759... logprob:  0.459873, 0.125000 (1.448 sec)
4.760... logprob:  0.484870, 0.132812 (1.465 sec)
4.761... logprob:  0.418897, 0.109375 (1.449 sec)
4.762... logprob:  0.516388, 0.148438 (1.440 sec)
4.763... logprob:  0.558698, 0.164062 (1.433 sec)
4.764... logprob:  0.503170, 0.140625 (1.425 sec)
4.765... logprob:  0.312836, 0.062500 (1.443 sec)
4.766... logprob:  0.482374, 0.132812 (1.454 sec)
4.767... logprob:  0.371159, 0.085938 (1.459 sec)
4.768... logprob:  0.433151, 0.117188 (1.464 sec)
4.769... logprob:  0.491337, 0.140625 (1.473 sec)
4.770... logprob:  0.402686, 0.101562 (1.480 sec)
4.771... logprob:  0.549867, 0.156250 (1.461 sec)
4.772... logprob:  0.414060, 0.109375 (1.446 sec)
4.773... logprob:  0.558636, 0.164062 (1.450 sec)
4.774... logprob:  0.361386, 0.085938 (1.460 sec)
4.775... logprob:  0.407511, 0.101562 (1.466 sec)
4.776... logprob:  0.433258, 0.117188 (1.478 sec)
4.777... logprob:  0.379986, 0.093750 (1.466 sec)
4.778... logprob:  0.433583, 0.117188 (1.466 sec)
4.779... logprob:  0.505682, 0.140625 (1.484 sec)
4.780... logprob:  0.385463, 0.101562 (1.456 sec)
4.781... logprob:  0.370461, 0.085938 (1.449 sec)
4.782... logprob:  0.351601, 0.085938 (1.450 sec)
4.783... logprob:  0.555577, 0.156250 (1.462 sec)
4.784... logprob:  0.441022, 0.117188 (1.456 sec)
4.785... logprob:  0.543239, 0.156250 (1.497 sec)
4.786... logprob:  0.477091, 0.132812 (1.467 sec)
4.787... logprob:  0.545936, 0.156250 (1.456 sec)
4.788... logprob:  0.562505, 0.164062 (1.500 sec)
4.789... logprob:  0.282365, 0.054688 (1.451 sec)
4.790... logprob:  0.409173, 0.101562 (1.454 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.081947326660156, 10.0]}, 128)
batch 872: ({'logprob': [65.8641357421875, 19.0]}, 128)
batch 873: ({'logprob': [42.194984436035156, 9.0]}, 128)
batch 874: ({'logprob': [46.35277557373047, 11.0]}, 128)
batch 875: ({'logprob': [51.46162033081055, 13.0]}, 128)
batch 876: ({'logprob': [63.55082702636719, 18.0]}, 128)
batch 877: ({'logprob': [46.83005905151367, 11.0]}, 128)
batch 878: ({'logprob': [61.692955017089844, 17.0]}, 128)
batch 879: ({'logprob': [72.38401794433594, 21.0]}, 128)
batch 880: ({'logprob': [51.468170166015625, 13.0]}, 128)
batch 881: ({'logprob': [31.48356819152832, 5.0]}, 128)
batch 882: ({'logprob': [55.2037239074707, 14.0]}, 128)
batch 883: ({'logprob': [61.68876266479492, 17.0]}, 128)
batch 884: ({'logprob': [51.92741775512695, 13.0]}, 128)
batch 885: ({'logprob': [52.875267028808594, 13.0]}, 128)
batch 886: ({'logprob': [62.16014862060547, 17.0]}, 128)

======================Test output======================
logprob:  0.420029, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.977024e-03 [2.195863e-09] 
Layer 'conv1' biases: 1.883589e-08 [5.766632e-11] 
Layer 'conv2' weights[0]: 7.963968e-03 [2.244442e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.991176e-10] 
Layer 'conv3' weights[0]: 7.962321e-03 [2.244314e-09] 
Layer 'conv3' biases: 2.255416e-07 [1.295654e-09] 
Layer 'conv4' weights[0]: 7.994833e-03 [2.493590e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.274949e-08] 
Layer 'conv5' weights[0]: 7.993821e-03 [8.720175e-08] 
Layer 'conv5' biases: 1.000001e+00 [9.485073e-08] 
Layer 'fc6' weights[0]: 7.590580e-03 [8.030157e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.076448e-09] 
Layer 'fc7' weights[0]: 7.723636e-03 [7.588398e-08] 
Layer 'fc7' biases: 9.998731e-01 [5.915086e-08] 
Layer 'fc8' weights[0]: 1.118723e-03 [2.627364e-06] 
Layer 'fc8' biases: 6.133594e-03 [1.149157e-05] 
Train error last 870 batches: 0.435480
-------------------------------------------------------
Not saving because 0.420029 > 0.415712 (4.190: -0.00%)
======================================================= (12.067 sec)
4.791... logprob:  0.398335, 0.101562 (1.457 sec)
4.792... logprob:  0.361659, 0.085938 (1.465 sec)
4.793... logprob:  0.371009, 0.085938 (1.452 sec)
4.794... logprob:  0.387384, 0.093750 (1.498 sec)
4.795... logprob:  0.470067, 0.125000 (1.472 sec)
4.796... logprob:  0.423454, 0.109375 (1.454 sec)
4.797... logprob:  0.358282, 0.085938 (1.494 sec)
4.798... logprob:  0.393509, 0.101562 (1.454 sec)
4.799... logprob:  0.331536, 0.078125 (1.451 sec)
4.800... logprob:  0.372295, 0.093750 (1.448 sec)
4.801... logprob:  0.450285, 0.117188 (1.473 sec)
4.802... logprob:  0.423584, 0.109375 (1.454 sec)
4.803... logprob:  0.493466, 0.132812 (1.492 sec)
4.804... logprob:  0.350403, 0.085938 (1.491 sec)
4.805... logprob:  0.451264, 0.117188 (1.455 sec)
4.806... logprob:  0.423857, 0.109375 (1.500 sec)
4.807... logprob:  0.443792, 0.117188 (1.458 sec)
4.808... logprob:  0.463363, 0.125000 (1.450 sec)
4.809... logprob:  0.591271, 0.171875 (1.453 sec)
4.810... logprob:  0.442304, 0.117188 (1.456 sec)
4.811... logprob:  0.460794, 0.125000 (1.457 sec)
4.812... logprob:  0.462595, 0.125000 (1.493 sec)
4.813... logprob:  0.485786, 0.132812 (1.464 sec)
4.814... logprob:  0.478798, 0.132812 (1.454 sec)
4.815... logprob:  0.373377, 0.085938 (1.503 sec)
4.816... logprob:  0.409686, 0.101562 (1.457 sec)
4.817... logprob:  0.426668, 0.109375 (1.454 sec)
4.818... logprob:  0.559858, 0.164062 (1.450 sec)
4.819... logprob:  0.498268, 0.140625 (1.454 sec)
4.820... logprob:  0.421508, 0.109375 (1.456 sec)
4.821... logprob:  0.406372, 0.101562 (1.499 sec)
4.822... logprob:  0.440942, 0.117188 (1.148 sec)
4.823... logprob:  0.339982, 0.078125 (1.160 sec)
4.824... logprob:  0.490623, 0.132812 (0.705 sec)
4.825... logprob:  0.286587, 0.062500 (0.688 sec)
4.826... logprob:  0.375170, 0.093750 (0.690 sec)
4.827... logprob:  0.420876, 0.109375 (0.685 sec)
4.828... logprob:  0.444144, 0.117188 (0.685 sec)
4.829... logprob:  0.505597, 0.140625 (0.690 sec)
4.830... logprob:  0.442678, 0.117188 (1.509 sec)
4.831... logprob:  0.514483, 0.140625 (1.455 sec)
4.832... logprob:  0.330997, 0.078125 (1.463 sec)
4.833... logprob:  0.488916, 0.132812 (1.505 sec)
4.834... logprob:  0.432425, 0.117188 (1.451 sec)
4.835... logprob:  0.543065, 0.148438 (1.461 sec)
4.836... logprob:  0.376715, 0.093750 (1.449 sec)
4.837... logprob:  0.315781, 0.070312 (1.456 sec)
4.838... logprob:  0.436898, 0.117188 (1.452 sec)
4.839... logprob:  0.472855, 0.125000 (1.502 sec)
4.840... logprob:  0.555937, 0.156250 (1.458 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.65824890136719, 10.0]}, 128)
batch 872: ({'logprob': [66.13261413574219, 19.0]}, 128)
batch 873: ({'logprob': [41.441558837890625, 9.0]}, 128)
batch 874: ({'logprob': [45.89181900024414, 11.0]}, 128)
batch 875: ({'logprob': [51.14570236206055, 13.0]}, 128)
batch 876: ({'logprob': [63.710269927978516, 18.0]}, 128)
batch 877: ({'logprob': [46.29511260986328, 11.0]}, 128)
batch 878: ({'logprob': [61.66853713989258, 17.0]}, 128)
batch 879: ({'logprob': [72.57740783691406, 21.0]}, 128)
batch 880: ({'logprob': [51.15261459350586, 13.0]}, 128)
batch 881: ({'logprob': [30.511798858642578, 5.0]}, 128)
batch 882: ({'logprob': [54.77766036987305, 14.0]}, 128)
batch 883: ({'logprob': [61.664432525634766, 17.0]}, 128)
batch 884: ({'logprob': [51.538429260253906, 13.0]}, 128)
batch 885: ({'logprob': [52.339805603027344, 13.0]}, 128)
batch 886: ({'logprob': [62.0626106262207, 17.0]}, 128)

======================Test output======================
logprob:  0.417758, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.976990e-03 [2.719936e-09] 
Layer 'conv1' biases: 1.927514e-08 [5.240641e-11] 
Layer 'conv2' weights[0]: 7.963928e-03 [2.011975e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.082045e-10] 
Layer 'conv3' weights[0]: 7.962279e-03 [1.785034e-09] 
Layer 'conv3' biases: 2.294562e-07 [9.708196e-10] 
Layer 'conv4' weights[0]: 7.994802e-03 [1.966631e-09] 
Layer 'conv4' biases: 9.999999e-01 [8.978574e-09] 
Layer 'conv5' weights[0]: 7.993785e-03 [6.116835e-08] 
Layer 'conv5' biases: 1.000001e+00 [6.626084e-08] 
Layer 'fc6' weights[0]: 7.590537e-03 [5.591471e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.646775e-09] 
Layer 'fc7' weights[0]: 7.721726e-03 [1.811072e-07] 
Layer 'fc7' biases: 9.998732e-01 [1.692081e-07] 
Layer 'fc8' weights[0]: 1.144205e-03 [8.958847e-06] 
Layer 'fc8' biases: 6.504296e-03 [4.874606e-05] 
Train error last 870 batches: 0.435467
-------------------------------------------------------
Not saving because 0.417758 > 0.415712 (4.190: -0.00%)
======================================================= (12.045 sec)
4.841... logprob:  0.396366, 0.101562 (1.472 sec)
4.842... logprob:  0.497557, 0.140625 (1.502 sec)
4.843... logprob:  0.465791, 0.125000 (1.452 sec)
4.844... logprob:  0.497463, 0.140625 (1.456 sec)
4.845... logprob:  0.487121, 0.132812 (1.449 sec)
4.846... logprob:  0.468652, 0.125000 (1.446 sec)
4.847... logprob:  0.362727, 0.085938 (1.458 sec)
4.848... logprob:  0.396806, 0.101562 (1.499 sec)
4.849... logprob:  0.359859, 0.085938 (1.459 sec)
4.850... logprob:  0.479671, 0.132812 (1.471 sec)
4.851... logprob:  0.440266, 0.117188 (1.495 sec)
4.852... logprob:  0.546528, 0.156250 (1.458 sec)
4.853... logprob:  0.371888, 0.093750 (1.462 sec)
4.854... logprob:  0.306975, 0.070312 (1.450 sec)
4.855... logprob:  0.485221, 0.132812 (1.444 sec)
4.856... logprob:  0.443924, 0.117188 (1.452 sec)
4.857... logprob:  0.372407, 0.093750 (1.490 sec)
4.858... logprob:  0.396272, 0.101562 (1.459 sec)
4.859... logprob:  0.308035, 0.070312 (1.471 sec)
4.860... logprob:  0.565566, 0.156250 (1.490 sec)
4.861... logprob:  0.417849, 0.109375 (1.457 sec)
4.862... logprob:  0.329108, 0.078125 (1.462 sec)
4.863... logprob:  0.399435, 0.101562 (1.446 sec)
4.864... logprob:  0.451250, 0.117188 (1.450 sec)
4.865... logprob:  0.484277, 0.132812 (1.456 sec)
4.866... logprob:  0.507313, 0.140625 (1.491 sec)
4.867... logprob:  0.502625, 0.140625 (1.464 sec)
4.868... logprob:  0.405587, 0.101562 (1.478 sec)
4.869... logprob:  0.383564, 0.093750 (1.479 sec)
4.870... logprob:  0.551780, 0.156250 (1.401 sec)
5.1... logprob:  0.380311, 0.093750 (1.407 sec)
5.2... logprob:  0.448088, 0.117188 (1.449 sec)
5.3... logprob:  0.398610, 0.101562 (1.418 sec)
5.4... logprob:  0.443305, 0.117188 (1.404 sec)
5.5... logprob:  0.443203, 0.117188 (1.438 sec)
5.6... logprob:  0.499814, 0.140625 (1.397 sec)
5.7... logprob:  0.362490, 0.085938 (1.421 sec)
5.8... logprob:  0.419355, 0.109375 (1.395 sec)
5.9... logprob:  0.358428, 0.085938 (1.407 sec)
5.10... logprob:  0.377342, 0.093750 (1.405 sec)
5.11... logprob:  0.334186, 0.078125 (1.468 sec)
5.12... logprob:  0.466495, 0.125000 (1.394 sec)
5.13... logprob:  0.442764, 0.117188 (1.427 sec)
5.14... logprob:  0.444894, 0.117188 (1.397 sec)
5.15... logprob:  0.396277, 0.101562 (1.401 sec)
5.16... logprob:  0.421609, 0.109375 (1.406 sec)
5.17... logprob:  0.515913, 0.140625 (1.396 sec)
5.18... logprob:  0.262058, 0.054688 (1.402 sec)
5.19... logprob:  0.280321, 0.062500 (1.401 sec)
5.20... logprob:  0.421435, 0.109375 (1.409 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.67562484741211, 10.0]}, 128)
batch 872: ({'logprob': [68.35113525390625, 19.0]}, 128)
batch 873: ({'logprob': [39.37899398803711, 9.0]}, 128)
batch 874: ({'logprob': [44.937957763671875, 11.0]}, 128)
batch 875: ({'logprob': [50.8777961730957, 13.0]}, 128)
batch 876: ({'logprob': [65.4813461303711, 18.0]}, 128)
batch 877: ({'logprob': [45.128944396972656, 11.0]}, 128)
batch 878: ({'logprob': [62.77783203125, 17.0]}, 128)
batch 879: ({'logprob': [74.8524169921875, 21.0]}, 128)
batch 880: ({'logprob': [50.88605499267578, 13.0]}, 128)
batch 881: ({'logprob': [27.281986236572266, 5.0]}, 128)
batch 882: ({'logprob': [54.33126449584961, 14.0]}, 128)
batch 883: ({'logprob': [62.77375793457031, 17.0]}, 128)
batch 884: ({'logprob': [51.06242752075195, 13.0]}, 128)
batch 885: ({'logprob': [51.445167541503906, 13.0]}, 128)
batch 886: ({'logprob': [62.96327590942383, 17.0]}, 128)

======================Test output======================
logprob:  0.417093, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.976949e-03 [2.002117e-09] 
Layer 'conv1' biases: 1.963487e-08 [2.844942e-11] 
Layer 'conv2' weights[0]: 7.963887e-03 [1.363832e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.051039e-10] 
Layer 'conv3' weights[0]: 7.962243e-03 [1.094740e-09] 
Layer 'conv3' biases: 2.308659e-07 [2.950894e-10] 
Layer 'conv4' weights[0]: 7.994760e-03 [1.101604e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.197048e-09] 
Layer 'conv5' weights[0]: 7.993748e-03 [7.680451e-09] 
Layer 'conv5' biases: 1.000001e+00 [8.105055e-09] 
Layer 'fc6' weights[0]: 7.590499e-03 [1.084187e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.294656e-10] 
Layer 'fc7' weights[0]: 7.719689e-03 [5.537659e-08] 
Layer 'fc7' biases: 9.998748e-01 [3.332737e-08] 
Layer 'fc8' weights[0]: 1.220676e-03 [2.986190e-06] 
Layer 'fc8' biases: 7.058441e-03 [1.663603e-05] 
Train error last 870 batches: 0.435468
-------------------------------------------------------
Not saving because 0.417093 > 0.415712 (4.190: -0.00%)
======================================================= (12.158 sec)
5.21... logprob:  0.444012, 0.117188 (0.894 sec)
5.22... logprob:  0.536447, 0.148438 (1.322 sec)
5.23... logprob:  0.532574, 0.148438 (1.419 sec)
5.24... logprob:  0.311040, 0.070312 (0.982 sec)
5.25... logprob:  0.356545, 0.085938 (0.964 sec)
5.26... logprob:  0.463593, 0.125000 (1.459 sec)
5.27... logprob:  0.404960, 0.101562 (1.393 sec)
5.28... logprob:  0.421952, 0.109375 (1.414 sec)
5.29... logprob:  0.396082, 0.101562 (1.427 sec)
5.30... logprob:  0.374116, 0.093750 (1.416 sec)
5.31... logprob:  0.479680, 0.132812 (1.408 sec)
5.32... logprob:  0.456983, 0.125000 (1.385 sec)
5.33... logprob:  0.460570, 0.125000 (1.451 sec)
5.34... logprob:  0.464951, 0.125000 (1.392 sec)
5.35... logprob:  0.316188, 0.070312 (1.399 sec)
5.36... logprob:  0.475093, 0.132812 (1.407 sec)
5.37... logprob:  0.417466, 0.109375 (1.403 sec)
5.38... logprob:  0.391742, 0.101562 (1.395 sec)
5.39... logprob:  0.632048, 0.187500 (1.438 sec)
5.40... logprob:  0.446715, 0.117188 (1.413 sec)
5.41... logprob:  0.352249, 0.085938 (1.420 sec)
5.42... logprob:  0.390942, 0.101562 (1.423 sec)
5.43... logprob:  0.440261, 0.117188 (1.411 sec)
5.44... logprob:  0.517757, 0.148438 (1.440 sec)
5.45... logprob:  0.382601, 0.093750 (1.394 sec)
5.46... logprob:  0.487215, 0.132812 (1.394 sec)
5.47... logprob:  0.331599, 0.078125 (1.398 sec)
5.48... logprob:  0.498519, 0.140625 (1.425 sec)
5.49... logprob:  0.509214, 0.148438 (1.420 sec)
5.50... logprob:  0.393027, 0.101562 (1.427 sec)
5.51... logprob:  0.488763, 0.140625 (1.422 sec)
5.52... logprob:  0.526317, 0.148438 (1.407 sec)
5.53... logprob:  0.295370, 0.062500 (1.460 sec)
5.54... logprob:  0.401906, 0.109375 (1.393 sec)
5.55... logprob:  0.331760, 0.078125 (1.412 sec)
5.56... logprob:  0.422360, 0.109375 (1.412 sec)
5.57... logprob:  0.573412, 0.164062 (1.439 sec)
5.58... logprob:  0.408973, 0.101562 (1.403 sec)
5.59... logprob:  0.334058, 0.078125 (1.473 sec)
5.60... logprob:  0.620080, 0.179688 (1.431 sec)
5.61... logprob:  0.383316, 0.093750 (1.443 sec)
5.62... logprob:  0.474955, 0.132812 (1.462 sec)
5.63... logprob:  0.397326, 0.101562 (1.455 sec)
5.64... logprob:  0.450189, 0.125000 (1.422 sec)
5.65... logprob:  0.373132, 0.093750 (1.410 sec)
5.66... logprob:  0.353814, 0.085938 (1.452 sec)
5.67... logprob:  0.295078, 0.062500 (1.401 sec)
5.68... logprob:  0.396771, 0.101562 (1.404 sec)
5.69... logprob:  0.497291, 0.140625 (1.428 sec)
5.70... logprob:  0.325912, 0.078125 (1.440 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.03715133666992, 10.0]}, 128)
batch 872: ({'logprob': [67.13955688476562, 19.0]}, 128)
batch 873: ({'logprob': [40.208858489990234, 9.0]}, 128)
batch 874: ({'logprob': [44.86997985839844, 11.0]}, 128)
batch 875: ({'logprob': [50.729026794433594, 13.0]}, 128)
batch 876: ({'logprob': [64.51359558105469, 18.0]}, 128)
batch 877: ({'logprob': [45.46910858154297, 11.0]}, 128)
batch 878: ({'logprob': [62.464073181152344, 17.0]}, 128)
batch 879: ({'logprob': [74.78107452392578, 21.0]}, 128)
batch 880: ({'logprob': [50.73586654663086, 13.0]}, 128)
batch 881: ({'logprob': [27.86906623840332, 5.0]}, 128)
batch 882: ({'logprob': [55.15938186645508, 14.0]}, 128)
batch 883: ({'logprob': [62.460140228271484, 17.0]}, 128)
batch 884: ({'logprob': [51.32041931152344, 13.0]}, 128)
batch 885: ({'logprob': [52.518226623535156, 13.0]}, 128)
batch 886: ({'logprob': [63.05671691894531, 17.0]}, 128)

======================Test output======================
logprob:  0.417154, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.976902e-03 [1.655528e-09] 
Layer 'conv1' biases: 2.013289e-08 [3.360652e-11] 
Layer 'conv2' weights[0]: 7.963847e-03 [1.276130e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.613163e-10] 
Layer 'conv3' weights[0]: 7.962203e-03 [1.234311e-09] 
Layer 'conv3' biases: 2.341908e-07 [5.170332e-10] 
Layer 'conv4' weights[0]: 7.994725e-03 [1.334862e-09] 
Layer 'conv4' biases: 9.999999e-01 [4.908187e-09] 
Layer 'conv5' weights[0]: 7.993706e-03 [3.381134e-08] 
Layer 'conv5' biases: 1.000000e+00 [3.672631e-08] 
Layer 'fc6' weights[0]: 7.590452e-03 [3.185275e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.135148e-09] 
Layer 'fc7' weights[0]: 7.717697e-03 [1.360910e-07] 
Layer 'fc7' biases: 9.998747e-01 [1.219754e-07] 
Layer 'fc8' weights[0]: 1.213283e-03 [6.598231e-06] 
Layer 'fc8' biases: 7.047123e-03 [3.638600e-05] 
Train error last 870 batches: 0.435469
-------------------------------------------------------
Not saving because 0.417154 > 0.415712 (4.190: -0.00%)
======================================================= (12.342 sec)
5.71... logprob:  0.382396, 0.101562 (1.483 sec)
5.72... logprob:  0.493566, 0.132812 (1.417 sec)
5.73... logprob:  0.447464, 0.117188 (1.439 sec)
5.74... logprob:  0.442487, 0.117188 (1.427 sec)
5.75... logprob:  0.380252, 0.093750 (1.425 sec)
5.76... logprob:  0.412369, 0.109375 (1.454 sec)
5.77... logprob:  0.396275, 0.101562 (1.432 sec)
5.78... logprob:  0.493685, 0.140625 (1.465 sec)
5.79... logprob:  0.456597, 0.125000 (1.423 sec)
5.80... logprob:  0.506503, 0.132812 (1.419 sec)
5.81... logprob:  0.416749, 0.109375 (1.432 sec)
5.82... logprob:  0.232240, 0.039062 (1.421 sec)
5.83... logprob:  0.494035, 0.140625 (1.405 sec)
5.84... logprob:  0.467617, 0.125000 (1.466 sec)
5.85... logprob:  0.432478, 0.117188 (1.418 sec)
5.86... logprob:  0.417113, 0.109375 (1.420 sec)
5.87... logprob:  0.632883, 0.187500 (1.421 sec)
5.88... logprob:  0.535582, 0.156250 (1.417 sec)
5.89... logprob:  0.411021, 0.109375 (1.446 sec)
5.90... logprob:  0.577680, 0.171875 (1.402 sec)
5.91... logprob:  0.348476, 0.078125 (1.409 sec)
5.92... logprob:  0.464367, 0.125000 (1.407 sec)
5.93... logprob:  0.492467, 0.140625 (1.400 sec)
5.94... logprob:  0.428741, 0.109375 (1.388 sec)
5.95... logprob:  0.471802, 0.125000 (1.438 sec)
5.96... logprob:  0.576490, 0.171875 (1.405 sec)
5.97... logprob:  0.430904, 0.117188 (1.396 sec)
5.98... logprob:  0.390795, 0.093750 (1.438 sec)
5.99... logprob:  0.474528, 0.132812 (1.409 sec)
5.100... logprob:  0.310358, 0.070312 (1.404 sec)
5.101... logprob:  0.310057, 0.062500 (1.445 sec)
5.102... logprob:  0.546682, 0.156250 (1.392 sec)
5.103... logprob:  0.541882, 0.156250 (1.400 sec)
5.104... logprob:  0.389168, 0.101562 (1.403 sec)
5.105... logprob:  0.620121, 0.179688 (1.404 sec)
5.106... logprob:  0.344601, 0.085938 (1.398 sec)
5.107... logprob:  0.335571, 0.078125 (1.446 sec)
5.108... logprob:  0.586791, 0.171875 (1.397 sec)
5.109... logprob:  0.336301, 0.078125 (1.403 sec)
5.110... logprob:  0.564207, 0.164062 (1.400 sec)
5.111... logprob:  0.404874, 0.101562 (1.398 sec)
5.112... logprob:  0.366274, 0.093750 (1.405 sec)
5.113... logprob:  0.354902, 0.085938 (1.405 sec)
5.114... logprob:  0.440293, 0.117188 (1.430 sec)
5.115... logprob:  0.506798, 0.140625 (1.414 sec)
5.116... logprob:  0.393399, 0.101562 (1.400 sec)
5.117... logprob:  0.440424, 0.117188 (1.450 sec)
5.118... logprob:  0.409568, 0.101562 (1.396 sec)
5.119... logprob:  0.346015, 0.085938 (1.400 sec)
5.120... logprob:  0.547249, 0.156250 (1.399 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.669647216796875, 10.0]}, 128)
batch 872: ({'logprob': [66.494873046875, 19.0]}, 128)
batch 873: ({'logprob': [40.68488693237305, 9.0]}, 128)
batch 874: ({'logprob': [45.225852966308594, 11.0]}, 128)
batch 875: ({'logprob': [50.791683197021484, 13.0]}, 128)
batch 876: ({'logprob': [63.972198486328125, 18.0]}, 128)
batch 877: ({'logprob': [45.7391357421875, 11.0]}, 128)
batch 878: ({'logprob': [61.93979263305664, 17.0]}, 128)
batch 879: ({'logprob': [73.58369445800781, 21.0]}, 128)
batch 880: ({'logprob': [50.798641204833984, 13.0]}, 128)
batch 881: ({'logprob': [29.018861770629883, 5.0]}, 128)
batch 882: ({'logprob': [54.858001708984375, 14.0]}, 128)
batch 883: ({'logprob': [61.93564987182617, 17.0]}, 128)
batch 884: ({'logprob': [51.29589080810547, 13.0]}, 128)
batch 885: ({'logprob': [52.31974792480469, 13.0]}, 128)
batch 886: ({'logprob': [62.44518280029297, 17.0]}, 128)

======================Test output======================
logprob:  0.416393, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.976870e-03 [2.056300e-09] 
Layer 'conv1' biases: 2.066079e-08 [3.551849e-11] 
Layer 'conv2' weights[0]: 7.963809e-03 [1.551130e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.181555e-10] 
Layer 'conv3' weights[0]: 7.962160e-03 [1.408603e-09] 
Layer 'conv3' biases: 2.388182e-07 [7.236794e-10] 
Layer 'conv4' weights[0]: 7.994685e-03 [1.504248e-09] 
Layer 'conv4' biases: 9.999999e-01 [6.483567e-09] 
Layer 'conv5' weights[0]: 7.993674e-03 [4.464185e-08] 
Layer 'conv5' biases: 1.000001e+00 [4.846305e-08] 
Layer 'fc6' weights[0]: 7.590420e-03 [4.179304e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.135857e-09] 
Layer 'fc7' weights[0]: 7.715733e-03 [3.946644e-08] 
Layer 'fc7' biases: 9.998736e-01 [7.872726e-09] 
Layer 'fc8' weights[0]: 1.186887e-03 [8.479667e-07] 
Layer 'fc8' biases: 6.977358e-03 [4.390932e-06] 
Train error last 870 batches: 0.435465
-------------------------------------------------------
Not saving because 0.416393 > 0.415712 (4.190: -0.00%)
======================================================= (12.118 sec)
5.121... logprob:  0.412697, 0.109375 (1.402 sec)
5.122... logprob:  0.519459, 0.148438 (1.446 sec)
5.123... logprob:  0.463921, 0.125000 (1.385 sec)
5.124... logprob:  0.447555, 0.125000 (1.411 sec)
5.125... logprob:  0.502130, 0.140625 (1.397 sec)
5.126... logprob:  0.476337, 0.125000 (1.397 sec)
5.127... logprob:  0.480303, 0.125000 (1.401 sec)
5.128... logprob:  0.422476, 0.109375 (1.415 sec)
5.129... logprob:  0.575155, 0.164062 (1.422 sec)
5.130... logprob:  0.382692, 0.093750 (1.415 sec)
5.131... logprob:  0.495266, 0.132812 (1.413 sec)
5.132... logprob:  0.506251, 0.140625 (1.432 sec)
5.133... logprob:  0.444426, 0.117188 (1.394 sec)
5.134... logprob:  0.401839, 0.101562 (1.396 sec)
5.135... logprob:  0.460509, 0.125000 (1.405 sec)
5.136... logprob:  0.562988, 0.164062 (1.395 sec)
5.137... logprob:  0.462530, 0.125000 (1.395 sec)
5.138... logprob:  0.319507, 0.070312 (1.450 sec)
5.139... logprob:  0.397037, 0.101562 (1.402 sec)
5.140... logprob:  0.562388, 0.164062 (1.415 sec)
5.141... logprob:  0.464129, 0.125000 (1.434 sec)
5.142... logprob:  0.464214, 0.125000 (1.399 sec)
5.143... logprob:  0.294246, 0.062500 (1.435 sec)
5.144... logprob:  0.458640, 0.125000 (1.417 sec)
5.145... logprob:  0.326705, 0.078125 (1.421 sec)
5.146... logprob:  0.483594, 0.132812 (1.410 sec)
5.147... logprob:  0.263086, 0.054688 (1.434 sec)
5.148... logprob:  0.459272, 0.125000 (1.390 sec)
5.149... logprob:  0.442482, 0.117188 (1.411 sec)
5.150... logprob:  0.347781, 0.085938 (1.402 sec)
5.151... logprob:  0.347153, 0.085938 (1.396 sec)
5.152... logprob:  0.783612, 0.234375 (1.394 sec)
5.153... logprob:  0.382205, 0.093750 (1.445 sec)
5.154... logprob:  0.523576, 0.148438 (1.403 sec)
5.155... logprob:  0.424573, 0.117188 (1.406 sec)
5.156... logprob:  0.297058, 0.062500 (1.442 sec)
5.157... logprob:  0.271275, 0.054688 (1.394 sec)
5.158... logprob:  0.454912, 0.125000 (1.402 sec)
5.159... logprob:  0.483609, 0.132812 (1.402 sec)
5.160... logprob:  0.446073, 0.117188 (1.393 sec)
5.161... logprob:  0.352601, 0.078125 (1.404 sec)
5.162... logprob:  0.612966, 0.179688 (1.402 sec)
5.163... logprob:  0.449600, 0.125000 (1.433 sec)
5.164... logprob:  0.470024, 0.125000 (1.421 sec)
5.165... logprob:  0.549203, 0.156250 (1.416 sec)
5.166... logprob:  0.444925, 0.125000 (1.456 sec)
5.167... logprob:  0.349242, 0.085938 (1.430 sec)
5.168... logprob:  0.363758, 0.085938 (1.423 sec)
5.169... logprob:  0.409335, 0.101562 (1.463 sec)
5.170... logprob:  0.459610, 0.125000 (1.408 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.86756896972656, 10.0]}, 128)
batch 872: ({'logprob': [66.128662109375, 19.0]}, 128)
batch 873: ({'logprob': [41.24778366088867, 9.0]}, 128)
batch 874: ({'logprob': [45.49751281738281, 11.0]}, 128)
batch 875: ({'logprob': [50.94816589355469, 13.0]}, 128)
batch 876: ({'logprob': [63.7073974609375, 18.0]}, 128)
batch 877: ({'logprob': [46.09895706176758, 11.0]}, 128)
batch 878: ({'logprob': [61.86479568481445, 17.0]}, 128)
batch 879: ({'logprob': [73.36479187011719, 21.0]}, 128)
batch 880: ({'logprob': [50.954864501953125, 13.0]}, 128)
batch 881: ({'logprob': [29.72554588317871, 5.0]}, 128)
batch 882: ({'logprob': [55.17528533935547, 14.0]}, 128)
batch 883: ({'logprob': [61.86052703857422, 17.0]}, 128)
batch 884: ({'logprob': [51.539459228515625, 13.0]}, 128)
batch 885: ({'logprob': [52.73838424682617, 13.0]}, 128)
batch 886: ({'logprob': [62.45745849609375, 17.0]}, 128)

======================Test output======================
logprob:  0.417567, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.976825e-03 [1.754536e-09] 
Layer 'conv1' biases: 2.115398e-08 [3.538944e-11] 
Layer 'conv2' weights[0]: 7.963769e-03 [1.457814e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.994918e-10] 
Layer 'conv3' weights[0]: 7.962123e-03 [1.492739e-09] 
Layer 'conv3' biases: 2.433892e-07 [6.300083e-10] 
Layer 'conv4' weights[0]: 7.994645e-03 [1.650970e-09] 
Layer 'conv4' biases: 9.999999e-01 [6.147886e-09] 
Layer 'conv5' weights[0]: 7.993637e-03 [4.152919e-08] 
Layer 'conv5' biases: 1.000001e+00 [4.516795e-08] 
Layer 'fc6' weights[0]: 7.590378e-03 [3.891688e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.843499e-09] 
Layer 'fc7' weights[0]: 7.713814e-03 [1.275114e-07] 
Layer 'fc7' biases: 9.998729e-01 [1.125257e-07] 
Layer 'fc8' weights[0]: 1.184635e-03 [7.403656e-06] 
Layer 'fc8' biases: 7.037182e-03 [4.269907e-05] 
Train error last 870 batches: 0.435445
-------------------------------------------------------
Not saving because 0.417567 > 0.415712 (4.190: -0.00%)
======================================================= (12.078 sec)
5.171... logprob:  0.535596, 0.156250 (1.431 sec)
5.172... logprob:  0.435472, 0.109375 (1.416 sec)
5.173... logprob:  0.440569, 0.117188 (1.424 sec)
5.174... logprob:  0.601742, 0.171875 (1.401 sec)
5.175... logprob:  0.506289, 0.140625 (1.470 sec)
5.176... logprob:  0.478650, 0.132812 (1.417 sec)
5.177... logprob:  0.289150, 0.054688 (1.428 sec)
5.178... logprob:  0.383142, 0.093750 (1.465 sec)
5.179... logprob:  0.395083, 0.101562 (1.406 sec)
5.180... logprob:  0.465849, 0.125000 (1.422 sec)
5.181... logprob:  0.540443, 0.156250 (1.420 sec)
5.182... logprob:  0.372310, 0.093750 (1.418 sec)
5.183... logprob:  0.419927, 0.109375 (1.416 sec)
5.184... logprob:  0.483558, 0.132812 (1.425 sec)
5.185... logprob:  0.290230, 0.062500 (1.396 sec)
5.186... logprob:  0.371623, 0.093750 (1.402 sec)
5.187... logprob:  0.529497, 0.148438 (1.403 sec)
5.188... logprob:  0.459777, 0.125000 (1.423 sec)
5.189... logprob:  0.440974, 0.117188 (1.386 sec)
5.190... logprob:  0.375752, 0.093750 (1.442 sec)
5.191... logprob:  0.485055, 0.132812 (1.407 sec)
5.192... logprob:  0.521028, 0.148438 (1.421 sec)
5.193... logprob:  0.312767, 0.070312 (1.417 sec)
5.194... logprob:  0.414505, 0.109375 (1.421 sec)
5.195... logprob:  0.287682, 0.062500 (1.398 sec)
5.196... logprob:  0.410902, 0.109375 (1.394 sec)
5.197... logprob:  0.478058, 0.132812 (1.399 sec)
5.198... logprob:  0.355875, 0.085938 (1.409 sec)
5.199... logprob:  0.437106, 0.117188 (1.388 sec)
5.200... logprob:  0.440816, 0.117188 (1.444 sec)
5.201... logprob:  0.436966, 0.117188 (1.407 sec)
5.202... logprob:  0.538543, 0.148438 (1.402 sec)
5.203... logprob:  0.420710, 0.109375 (1.441 sec)
5.204... logprob:  0.504193, 0.140625 (1.397 sec)
5.205... logprob:  0.334556, 0.078125 (1.402 sec)
5.206... logprob:  0.360697, 0.093750 (1.399 sec)
5.207... logprob:  0.382488, 0.093750 (1.398 sec)
5.208... logprob:  0.489778, 0.140625 (1.405 sec)
5.209... logprob:  0.334746, 0.078125 (1.421 sec)
5.210... logprob:  0.586335, 0.171875 (1.412 sec)
5.211... logprob:  0.488858, 0.132812 (1.417 sec)
5.212... logprob:  0.526599, 0.148438 (1.407 sec)
5.213... logprob:  0.516097, 0.140625 (1.463 sec)
5.214... logprob:  0.459543, 0.125000 (1.426 sec)
5.215... logprob:  0.395911, 0.101562 (1.422 sec)
5.216... logprob:  0.518296, 0.140625 (1.465 sec)
5.217... logprob:  0.325145, 0.070312 (1.408 sec)
5.218... logprob:  0.463884, 0.125000 (1.419 sec)
5.219... logprob:  0.500442, 0.140625 (1.417 sec)
5.220... logprob:  0.414885, 0.109375 (1.424 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.5087890625, 10.0]}, 128)
batch 872: ({'logprob': [66.04402160644531, 19.0]}, 128)
batch 873: ({'logprob': [41.51283264160156, 9.0]}, 128)
batch 874: ({'logprob': [45.85177230834961, 11.0]}, 128)
batch 875: ({'logprob': [51.126251220703125, 13.0]}, 128)
batch 876: ({'logprob': [63.64463806152344, 18.0]}, 128)
batch 877: ({'logprob': [46.321136474609375, 11.0]}, 128)
batch 878: ({'logprob': [61.690956115722656, 17.0]}, 128)
batch 879: ({'logprob': [72.7065200805664, 21.0]}, 128)
batch 880: ({'logprob': [51.13350296020508, 13.0]}, 128)
batch 881: ({'logprob': [30.47525405883789, 5.0]}, 128)
batch 882: ({'logprob': [54.93351745605469, 14.0]}, 128)
batch 883: ({'logprob': [61.686378479003906, 17.0]}, 128)
batch 884: ({'logprob': [51.58463668823242, 13.0]}, 128)
batch 885: ({'logprob': [52.517860412597656, 13.0]}, 128)
batch 886: ({'logprob': [62.15066909790039, 17.0]}, 128)

======================Test output======================
logprob:  0.417914, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.976792e-03 [1.835334e-09] 
Layer 'conv1' biases: 2.176370e-08 [4.423018e-11] 
Layer 'conv2' weights[0]: 7.963723e-03 [1.591697e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.519079e-10] 
Layer 'conv3' weights[0]: 7.962080e-03 [1.554149e-09] 
Layer 'conv3' biases: 2.488673e-07 [7.225006e-10] 
Layer 'conv4' weights[0]: 7.994607e-03 [1.700370e-09] 
Layer 'conv4' biases: 9.999999e-01 [7.183568e-09] 
Layer 'conv5' weights[0]: 7.993586e-03 [4.967329e-08] 
Layer 'conv5' biases: 1.000001e+00 [5.395236e-08] 
Layer 'fc6' weights[0]: 7.590331e-03 [4.594172e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.548541e-09] 
Layer 'fc7' weights[0]: 7.711845e-03 [9.316459e-08] 
Layer 'fc7' biases: 9.998724e-01 [7.643219e-08] 
Layer 'fc8' weights[0]: 1.175364e-03 [7.545449e-06] 
Layer 'fc8' biases: 7.044834e-03 [4.390887e-05] 
Train error last 870 batches: 0.435430
-------------------------------------------------------
Not saving because 0.417914 > 0.415712 (4.190: -0.00%)
======================================================= (12.025 sec)
5.221... logprob:  0.399440, 0.101562 (1.414 sec)
5.222... logprob:  0.555002, 0.164062 (1.486 sec)
5.223... logprob:  0.569361, 0.164062 (1.421 sec)
5.224... logprob:  0.405558, 0.101562 (1.437 sec)
5.225... logprob:  0.392287, 0.101562 (1.447 sec)
5.226... logprob:  0.424309, 0.109375 (1.424 sec)
5.227... logprob:  0.453332, 0.125000 (1.417 sec)
5.228... logprob:  0.417406, 0.109375 (1.421 sec)
5.229... logprob:  0.488860, 0.132812 (1.416 sec)
5.230... logprob:  0.460000, 0.125000 (1.433 sec)
5.231... logprob:  0.454093, 0.125000 (1.408 sec)
5.232... logprob:  0.496678, 0.140625 (1.458 sec)
5.233... logprob:  0.467111, 0.132812 (1.432 sec)
5.234... logprob:  0.563645, 0.164062 (1.413 sec)
5.235... logprob:  0.482011, 0.132812 (1.474 sec)
5.236... logprob:  0.425908, 0.109375 (1.399 sec)
5.237... logprob:  0.341783, 0.078125 (1.429 sec)
5.238... logprob:  0.389720, 0.093750 (1.410 sec)
5.239... logprob:  0.478188, 0.132812 (1.421 sec)
5.240... logprob:  0.485870, 0.132812 (1.400 sec)
5.241... logprob:  0.493683, 0.132812 (1.461 sec)
5.242... logprob:  0.341622, 0.078125 (1.429 sec)
5.243... logprob:  0.385913, 0.093750 (1.428 sec)
5.244... logprob:  0.314885, 0.070312 (1.449 sec)
5.245... logprob:  0.494207, 0.132812 (1.428 sec)
5.246... logprob:  0.417093, 0.109375 (1.416 sec)
5.247... logprob:  0.356816, 0.085938 (1.414 sec)
5.248... logprob:  0.307323, 0.070312 (1.422 sec)
5.249... logprob:  0.556861, 0.156250 (1.422 sec)
5.250... logprob:  0.591580, 0.164062 (1.411 sec)
5.251... logprob:  0.352724, 0.085938 (1.460 sec)
5.252... logprob:  0.349110, 0.085938 (1.423 sec)
5.253... logprob:  0.378525, 0.093750 (1.422 sec)
5.254... logprob:  0.444134, 0.117188 (1.464 sec)
5.255... logprob:  0.351947, 0.085938 (1.400 sec)
5.256... logprob:  0.378095, 0.093750 (1.426 sec)
5.257... logprob:  0.331934, 0.078125 (1.413 sec)
5.258... logprob:  0.417236, 0.109375 (1.425 sec)
5.259... logprob:  0.442610, 0.117188 (1.403 sec)
5.260... logprob:  0.308676, 0.070312 (1.466 sec)
5.261... logprob:  0.394259, 0.101562 (1.430 sec)
5.262... logprob:  0.526414, 0.148438 (1.437 sec)
5.263... logprob:  0.424819, 0.109375 (1.447 sec)
5.264... logprob:  0.375374, 0.093750 (1.430 sec)
5.265... logprob:  0.439705, 0.117188 (1.414 sec)
5.266... logprob:  0.439096, 0.117188 (1.421 sec)
5.267... logprob:  0.422018, 0.109375 (1.423 sec)
5.268... logprob:  0.458787, 0.125000 (1.440 sec)
5.269... logprob:  0.567146, 0.164062 (1.408 sec)
5.270... logprob:  0.541832, 0.156250 (1.466 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.636898040771484, 10.0]}, 128)
batch 872: ({'logprob': [66.22233581542969, 19.0]}, 128)
batch 873: ({'logprob': [41.30006408691406, 9.0]}, 128)
batch 874: ({'logprob': [45.83405685424805, 11.0]}, 128)
batch 875: ({'logprob': [51.1085319519043, 13.0]}, 128)
batch 876: ({'logprob': [63.774513244628906, 18.0]}, 128)
batch 877: ({'logprob': [46.20603561401367, 11.0]}, 128)
batch 878: ({'logprob': [61.674095153808594, 17.0]}, 128)
batch 879: ({'logprob': [72.59325408935547, 21.0]}, 128)
batch 880: ({'logprob': [51.11614227294922, 13.0]}, 128)
batch 881: ({'logprob': [30.3588924407959, 5.0]}, 128)
batch 882: ({'logprob': [54.672828674316406, 14.0]}, 128)
batch 883: ({'logprob': [61.66952133178711, 17.0]}, 128)
batch 884: ({'logprob': [51.4697265625, 13.0]}, 128)
batch 885: ({'logprob': [52.20817947387695, 13.0]}, 128)
batch 886: ({'logprob': [62.036476135253906, 17.0]}, 128)

======================Test output======================
logprob:  0.417423, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.976747e-03 [3.345578e-09] 
Layer 'conv1' biases: 2.240095e-08 [8.824208e-11] 
Layer 'conv2' weights[0]: 7.963684e-03 [2.903695e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.662057e-10] 
Layer 'conv3' weights[0]: 7.962040e-03 [2.782441e-09] 
Layer 'conv3' biases: 2.543431e-07 [1.767843e-09] 
Layer 'conv4' weights[0]: 7.994573e-03 [3.208811e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.767868e-08] 
Layer 'conv5' weights[0]: 7.993539e-03 [1.211394e-07] 
Layer 'conv5' biases: 1.000001e+00 [1.317339e-07] 
Layer 'fc6' weights[0]: 7.590293e-03 [1.092012e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.115639e-08] 
Layer 'fc7' weights[0]: 7.709917e-03 [3.030486e-07] 
Layer 'fc7' biases: 9.998721e-01 [2.916686e-07] 
Layer 'fc8' weights[0]: 1.184932e-03 [1.585883e-05] 
Layer 'fc8' biases: 7.167731e-03 [8.914275e-05] 
Train error last 870 batches: 0.435417
-------------------------------------------------------
Not saving because 0.417423 > 0.415712 (4.190: -0.00%)
======================================================= (12.021 sec)
5.271... logprob:  0.446303, 0.117188 (1.439 sec)
5.272... logprob:  0.385180, 0.093750 (1.426 sec)
5.273... logprob:  0.500131, 0.140625 (1.468 sec)
5.274... logprob:  0.542877, 0.156250 (1.401 sec)
5.275... logprob:  0.488563, 0.132812 (1.430 sec)
5.276... logprob:  0.390563, 0.093750 (1.414 sec)
5.277... logprob:  0.429140, 0.109375 (1.423 sec)
5.278... logprob:  0.322647, 0.070312 (1.419 sec)
5.279... logprob:  0.324824, 0.070312 (1.459 sec)
5.280... logprob:  0.214570, 0.031250 (1.411 sec)
5.281... logprob:  0.417105, 0.109375 (1.429 sec)
5.282... logprob:  0.411210, 0.109375 (1.422 sec)
5.283... logprob:  0.393756, 0.101562 (1.417 sec)
5.284... logprob:  0.394718, 0.101562 (1.411 sec)
5.285... logprob:  0.452494, 0.117188 (1.445 sec)
5.286... logprob:  0.538137, 0.140625 (1.433 sec)
5.287... logprob:  0.346685, 0.085938 (1.434 sec)
5.288... logprob:  0.330071, 0.078125 (1.439 sec)
5.289... logprob:  0.446101, 0.117188 (1.440 sec)
5.290... logprob:  0.490612, 0.132812 (1.414 sec)
5.291... logprob:  0.439044, 0.117188 (1.420 sec)
5.292... logprob:  0.566848, 0.156250 (1.414 sec)
5.293... logprob:  0.427159, 0.117188 (1.427 sec)
5.294... logprob:  0.356502, 0.085938 (1.401 sec)
5.295... logprob:  0.335540, 0.078125 (1.469 sec)
5.296... logprob:  0.356568, 0.085938 (1.419 sec)
5.297... logprob:  0.394973, 0.101562 (1.452 sec)
5.298... logprob:  0.447565, 0.125000 (1.462 sec)
5.299... logprob:  0.343285, 0.078125 (1.407 sec)
5.300... logprob:  0.407294, 0.101562 (1.420 sec)
5.301... logprob:  0.398086, 0.101562 (1.413 sec)
5.302... logprob:  0.590967, 0.179688 (1.420 sec)
5.303... logprob:  0.459773, 0.125000 (1.409 sec)
5.304... logprob:  0.459796, 0.125000 (1.442 sec)
5.305... logprob:  0.455155, 0.125000 (1.440 sec)
5.306... logprob:  0.440746, 0.117188 (1.434 sec)
5.307... logprob:  0.421777, 0.109375 (1.447 sec)
5.308... logprob:  0.374418, 0.093750 (1.453 sec)
5.309... logprob:  0.450270, 0.125000 (1.418 sec)
5.310... logprob:  0.474322, 0.125000 (1.426 sec)
5.311... logprob:  0.502866, 0.140625 (1.422 sec)
5.312... logprob:  0.478895, 0.132812 (1.441 sec)
5.313... logprob:  0.454849, 0.125000 (1.418 sec)
5.314... logprob:  0.454932, 0.117188 (1.466 sec)
5.315... logprob:  0.314539, 0.070312 (1.435 sec)
5.316... logprob:  0.468698, 0.125000 (1.428 sec)
5.317... logprob:  0.355456, 0.085938 (1.476 sec)
5.318... logprob:  0.455524, 0.125000 (1.419 sec)
5.319... logprob:  0.423560, 0.117188 (1.420 sec)
5.320... logprob:  0.412382, 0.109375 (1.434 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.502593994140625, 10.0]}, 128)
batch 872: ({'logprob': [66.5795669555664, 19.0]}, 128)
batch 873: ({'logprob': [40.60547637939453, 9.0]}, 128)
batch 874: ({'logprob': [45.138832092285156, 11.0]}, 128)
batch 875: ({'logprob': [50.763999938964844, 13.0]}, 128)
batch 876: ({'logprob': [64.04412841796875, 18.0]}, 128)
batch 877: ({'logprob': [45.68545150756836, 11.0]}, 128)
batch 878: ({'logprob': [62.03154373168945, 17.0]}, 128)
batch 879: ({'logprob': [73.82746887207031, 21.0]}, 128)
batch 880: ({'logprob': [50.77129364013672, 13.0]}, 128)
batch 881: ({'logprob': [28.78641700744629, 5.0]}, 128)
batch 882: ({'logprob': [54.94396209716797, 14.0]}, 128)
batch 883: ({'logprob': [62.02716064453125, 17.0]}, 128)
batch 884: ({'logprob': [51.301570892333984, 13.0]}, 128)
batch 885: ({'logprob': [52.39241027832031, 13.0]}, 128)
batch 886: ({'logprob': [62.5703010559082, 17.0]}, 128)

======================Test output======================
logprob:  0.416490, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.976706e-03 [1.637732e-09] 
Layer 'conv1' biases: 2.289095e-08 [2.302872e-11] 
Layer 'conv2' weights[0]: 7.963649e-03 [1.364561e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.154509e-10] 
Layer 'conv3' weights[0]: 7.961999e-03 [1.119304e-09] 
Layer 'conv3' biases: 2.557191e-07 [3.490270e-10] 
Layer 'conv4' weights[0]: 7.994535e-03 [1.225116e-09] 
Layer 'conv4' biases: 9.999999e-01 [2.838906e-09] 
Layer 'conv5' weights[0]: 7.993517e-03 [1.871580e-08] 
Layer 'conv5' biases: 1.000000e+00 [2.013655e-08] 
Layer 'fc6' weights[0]: 7.590252e-03 [1.915517e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.740699e-09] 
Layer 'fc7' weights[0]: 7.707916e-03 [1.060962e-07] 
Layer 'fc7' biases: 9.998727e-01 [9.013988e-08] 
Layer 'fc8' weights[0]: 1.223209e-03 [4.181190e-06] 
Layer 'fc8' biases: 7.631694e-03 [2.489333e-05] 
Train error last 870 batches: 0.435401
-------------------------------------------------------
Not saving because 0.416490 > 0.415712 (4.190: -0.00%)
======================================================= (12.076 sec)
5.321... logprob:  0.348375, 0.085938 (1.432 sec)
5.322... logprob:  0.387779, 0.101562 (1.419 sec)
5.323... logprob:  0.416559, 0.109375 (1.488 sec)
5.324... logprob:  0.498747, 0.140625 (1.426 sec)
5.325... logprob:  0.350747, 0.085938 (1.432 sec)
5.326... logprob:  0.542824, 0.148438 (1.460 sec)
5.327... logprob:  0.554348, 0.164062 (1.422 sec)
5.328... logprob:  0.564679, 0.156250 (1.426 sec)
5.329... logprob:  0.402128, 0.101562 (1.424 sec)
5.330... logprob:  0.388818, 0.101562 (1.442 sec)
5.331... logprob:  0.352751, 0.085938 (1.429 sec)
5.332... logprob:  0.482844, 0.132812 (1.447 sec)
5.333... logprob:  0.339625, 0.085938 (1.449 sec)
5.334... logprob:  0.564843, 0.171875 (1.440 sec)
5.335... logprob:  0.359068, 0.085938 (1.445 sec)
5.336... logprob:  0.444586, 0.125000 (1.453 sec)
5.337... logprob:  0.566685, 0.164062 (1.421 sec)
5.338... logprob:  0.449337, 0.125000 (1.417 sec)
5.339... logprob:  0.489140, 0.132812 (1.424 sec)
5.340... logprob:  0.442288, 0.117188 (1.426 sec)
5.341... logprob:  0.530639, 0.148438 (1.424 sec)
5.342... logprob:  0.430112, 0.109375 (1.461 sec)
5.343... logprob:  0.435203, 0.109375 (1.434 sec)
5.344... logprob:  0.444138, 0.125000 (1.486 sec)
5.345... logprob:  0.488473, 0.132812 (1.437 sec)
5.346... logprob:  0.436245, 0.117188 (1.434 sec)
5.347... logprob:  0.371962, 0.085938 (1.483 sec)
5.348... logprob:  0.398285, 0.101562 (1.437 sec)
5.349... logprob:  0.498326, 0.140625 (1.430 sec)
5.350... logprob:  0.358104, 0.085938 (1.431 sec)
5.351... logprob:  0.508756, 0.140625 (1.431 sec)
5.352... logprob:  0.364180, 0.093750 (1.436 sec)
5.353... logprob:  0.514013, 0.148438 (1.487 sec)
5.354... logprob:  0.675845, 0.203125 (1.438 sec)
5.355... logprob:  0.357211, 0.085938 (1.443 sec)
5.356... logprob:  0.479366, 0.132812 (1.481 sec)
5.357... logprob:  0.347709, 0.085938 (1.433 sec)
5.358... logprob:  0.325920, 0.070312 (1.442 sec)
5.359... logprob:  0.555309, 0.164062 (1.432 sec)
5.360... logprob:  0.444343, 0.117188 (1.426 sec)
5.361... logprob:  0.410461, 0.101562 (1.433 sec)
5.362... logprob:  0.424834, 0.117188 (1.474 sec)
5.363... logprob:  0.486361, 0.132812 (1.437 sec)
5.364... logprob:  0.474998, 0.125000 (1.448 sec)
5.365... logprob:  0.424948, 0.109375 (1.465 sec)
5.366... logprob:  0.410159, 0.109375 (1.449 sec)
5.367... logprob:  0.325509, 0.078125 (1.437 sec)
5.368... logprob:  0.595474, 0.171875 (1.434 sec)
5.369... logprob:  0.381212, 0.093750 (1.426 sec)
5.370... logprob:  0.380828, 0.093750 (1.442 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.83732223510742, 10.0]}, 128)
batch 872: ({'logprob': [66.59848022460938, 19.0]}, 128)
batch 873: ({'logprob': [40.565093994140625, 9.0]}, 128)
batch 874: ({'logprob': [45.253273010253906, 11.0]}, 128)
batch 875: ({'logprob': [50.794776916503906, 13.0]}, 128)
batch 876: ({'logprob': [64.04551696777344, 18.0]}, 128)
batch 877: ({'logprob': [45.681034088134766, 11.0]}, 128)
batch 878: ({'logprob': [61.895755767822266, 17.0]}, 128)
batch 879: ({'logprob': [73.40606689453125, 21.0]}, 128)
batch 880: ({'logprob': [50.80260467529297, 13.0]}, 128)
batch 881: ({'logprob': [29.03176498413086, 5.0]}, 128)
batch 882: ({'logprob': [54.63541793823242, 14.0]}, 128)
batch 883: ({'logprob': [61.891136169433594, 17.0]}, 128)
batch 884: ({'logprob': [51.213294982910156, 13.0]}, 128)
batch 885: ({'logprob': [52.06580352783203, 13.0]}, 128)
batch 886: ({'logprob': [62.315311431884766, 17.0]}, 128)

======================Test output======================
logprob:  0.416032, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.976667e-03 [1.853965e-09] 
Layer 'conv1' biases: 2.339470e-08 [3.888545e-11] 
Layer 'conv2' weights[0]: 7.963613e-03 [1.661098e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.185085e-10] 
Layer 'conv3' weights[0]: 7.961959e-03 [1.527495e-09] 
Layer 'conv3' biases: 2.604628e-07 [6.800459e-10] 
Layer 'conv4' weights[0]: 7.994499e-03 [1.670446e-09] 
Layer 'conv4' biases: 9.999999e-01 [6.499094e-09] 
Layer 'conv5' weights[0]: 7.993479e-03 [4.392380e-08] 
Layer 'conv5' biases: 1.000001e+00 [4.776765e-08] 
Layer 'fc6' weights[0]: 7.590212e-03 [4.123941e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.070629e-09] 
Layer 'fc7' weights[0]: 7.705947e-03 [1.073203e-07] 
Layer 'fc7' biases: 9.998726e-01 [9.117147e-08] 
Layer 'fc8' weights[0]: 1.220651e-03 [7.048457e-06] 
Layer 'fc8' biases: 7.695350e-03 [4.096243e-05] 
Train error last 870 batches: 0.435395
-------------------------------------------------------
Not saving because 0.416032 > 0.415712 (4.190: -0.00%)
======================================================= (12.073 sec)
5.371... logprob:  0.400137, 0.101562 (1.469 sec)
5.372... logprob:  0.538516, 0.156250 (1.457 sec)
5.373... logprob:  0.463816, 0.125000 (1.452 sec)
5.374... logprob:  0.527364, 0.148438 (1.453 sec)
5.375... logprob:  0.393940, 0.101562 (1.459 sec)
5.376... logprob:  0.374393, 0.093750 (1.438 sec)
5.377... logprob:  0.295129, 0.062500 (1.430 sec)
5.378... logprob:  0.454133, 0.125000 (1.430 sec)
5.379... logprob:  0.420189, 0.109375 (1.439 sec)
5.380... logprob:  0.605926, 0.179688 (1.443 sec)
5.381... logprob:  0.463509, 0.125000 (1.468 sec)
5.382... logprob:  0.529345, 0.148438 (1.455 sec)
5.383... logprob:  0.358904, 0.085938 (1.440 sec)
5.384... logprob:  0.520877, 0.148438 (1.484 sec)
5.385... logprob:  0.523382, 0.148438 (1.430 sec)
5.386... logprob:  0.582159, 0.171875 (1.434 sec)
5.387... logprob:  0.428606, 0.117188 (1.433 sec)
5.388... logprob:  0.521335, 0.148438 (1.440 sec)
5.389... logprob:  0.426239, 0.109375 (1.433 sec)
5.390... logprob:  0.419949, 0.109375 (1.483 sec)
5.391... logprob:  0.318085, 0.070312 (1.440 sec)
5.392... logprob:  0.439340, 0.117188 (1.439 sec)
5.393... logprob:  0.368286, 0.093750 (1.484 sec)
5.394... logprob:  0.343809, 0.078125 (1.437 sec)
5.395... logprob:  0.331461, 0.078125 (1.435 sec)
5.396... logprob:  0.252059, 0.046875 (1.436 sec)
5.397... logprob:  0.484949, 0.132812 (1.429 sec)
5.398... logprob:  0.471960, 0.125000 (1.437 sec)
5.399... logprob:  0.433669, 0.117188 (1.491 sec)
5.400... logprob:  0.539039, 0.148438 (1.434 sec)
5.401... logprob:  0.466374, 0.125000 (1.441 sec)
5.402... logprob:  0.474769, 0.125000 (1.486 sec)
5.403... logprob:  0.462242, 0.125000 (1.439 sec)
5.404... logprob:  0.475345, 0.125000 (1.462 sec)
5.405... logprob:  0.543442, 0.156250 (1.442 sec)
5.406... logprob:  0.358440, 0.085938 (1.431 sec)
5.407... logprob:  0.492232, 0.140625 (1.428 sec)
5.408... logprob:  0.340474, 0.078125 (1.482 sec)
5.409... logprob:  0.401548, 0.101562 (1.443 sec)
5.410... logprob:  0.581809, 0.171875 (1.450 sec)
5.411... logprob:  0.398531, 0.101562 (1.472 sec)
5.412... logprob:  0.540408, 0.156250 (1.439 sec)
5.413... logprob:  0.545216, 0.156250 (1.444 sec)
5.414... logprob:  0.467003, 0.125000 (1.432 sec)
5.415... logprob:  0.401668, 0.101562 (1.426 sec)
5.416... logprob:  0.427607, 0.109375 (1.438 sec)
5.417... logprob:  0.405421, 0.093750 (1.467 sec)
5.418... logprob:  0.379669, 0.093750 (1.454 sec)
5.419... logprob:  0.416815, 0.101562 (1.456 sec)
5.420... logprob:  0.355337, 0.085938 (1.458 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.60648727416992, 10.0]}, 128)
batch 872: ({'logprob': [66.64901733398438, 19.0]}, 128)
batch 873: ({'logprob': [40.50445556640625, 9.0]}, 128)
batch 874: ({'logprob': [45.14466094970703, 11.0]}, 128)
batch 875: ({'logprob': [50.75525665283203, 13.0]}, 128)
batch 876: ({'logprob': [64.09075164794922, 18.0]}, 128)
batch 877: ({'logprob': [45.63071823120117, 11.0]}, 128)
batch 878: ({'logprob': [61.994171142578125, 17.0]}, 128)
batch 879: ({'logprob': [73.70069885253906, 21.0]}, 128)
batch 880: ({'logprob': [50.762882232666016, 13.0]}, 128)
batch 881: ({'logprob': [28.774648666381836, 5.0]}, 128)
batch 882: ({'logprob': [54.776634216308594, 14.0]}, 128)
batch 883: ({'logprob': [61.98963165283203, 17.0]}, 128)
batch 884: ({'logprob': [51.23228073120117, 13.0]}, 128)
batch 885: ({'logprob': [52.201881408691406, 13.0]}, 128)
batch 886: ({'logprob': [62.472267150878906, 17.0]}, 128)

======================Test output======================
logprob:  0.416155, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.976622e-03 [2.564851e-09] 
Layer 'conv1' biases: 2.388786e-08 [9.080283e-11] 
Layer 'conv2' weights[0]: 7.963573e-03 [2.886151e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.591363e-10] 
Layer 'conv3' weights[0]: 7.961919e-03 [2.966215e-09] 
Layer 'conv3' biases: 2.617044e-07 [1.738798e-09] 
Layer 'conv4' weights[0]: 7.994451e-03 [3.293928e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.720667e-08] 
Layer 'conv5' weights[0]: 7.993425e-03 [1.176743e-07] 
Layer 'conv5' biases: 1.000000e+00 [1.280638e-07] 
Layer 'fc6' weights[0]: 7.590178e-03 [1.062640e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.082218e-08] 
Layer 'fc7' weights[0]: 7.703959e-03 [3.799119e-07] 
Layer 'fc7' biases: 9.998726e-01 [3.660956e-07] 
Layer 'fc8' weights[0]: 1.229550e-03 [2.147447e-05] 
Layer 'fc8' biases: 7.984597e-03 [1.288191e-04] 
Train error last 870 batches: 0.435393
-------------------------------------------------------
Not saving because 0.416155 > 0.415712 (4.190: -0.00%)
======================================================= (12.034 sec)
5.421... logprob:  0.377696, 0.101562 (1.464 sec)
5.422... logprob:  0.524489, 0.148438 (1.440 sec)
5.423... logprob:  0.421082, 0.109375 (1.427 sec)
5.424... logprob:  0.324698, 0.078125 (1.432 sec)
5.425... logprob:  0.305650, 0.070312 (1.441 sec)
5.426... logprob:  0.449277, 0.117188 (1.445 sec)
5.427... logprob:  0.556807, 0.156250 (1.467 sec)
5.428... logprob:  0.603734, 0.171875 (1.455 sec)
5.429... logprob:  0.425599, 0.109375 (1.442 sec)
5.430... logprob:  0.300699, 0.070312 (1.479 sec)
5.431... logprob:  0.598228, 0.171875 (1.434 sec)
5.432... logprob:  0.386950, 0.093750 (1.432 sec)
5.433... logprob:  0.331131, 0.078125 (1.430 sec)
5.434... logprob:  0.528322, 0.148438 (1.438 sec)
5.435... logprob:  0.532161, 0.156250 (1.433 sec)
5.436... logprob:  0.382136, 0.093750 (1.476 sec)
5.437... logprob:  0.500172, 0.140625 (1.474 sec)
5.438... logprob:  0.546449, 0.156250 (1.433 sec)
5.439... logprob:  0.379813, 0.093750 (1.489 sec)
5.440... logprob:  0.440104, 0.117188 (1.435 sec)
5.441... logprob:  0.468020, 0.125000 (1.433 sec)
5.442... logprob:  0.378901, 0.093750 (1.435 sec)
5.443... logprob:  0.496661, 0.140625 (1.438 sec)
5.444... logprob:  0.371897, 0.093750 (1.430 sec)
5.445... logprob:  0.361754, 0.085938 (1.484 sec)
5.446... logprob:  0.397870, 0.101562 (1.444 sec)
5.447... logprob:  0.571072, 0.164062 (1.440 sec)
5.448... logprob:  0.332133, 0.078125 (1.483 sec)
5.449... logprob:  0.400042, 0.101562 (1.436 sec)
5.450... logprob:  0.238140, 0.046875 (1.433 sec)
5.451... logprob:  0.453533, 0.125000 (1.441 sec)
5.452... logprob:  0.456621, 0.117188 (1.425 sec)
5.453... logprob:  0.455900, 0.125000 (1.431 sec)
5.454... logprob:  0.489555, 0.132812 (1.484 sec)
5.455... logprob:  0.506124, 0.140625 (1.441 sec)
5.456... logprob:  0.468805, 0.125000 (1.448 sec)
5.457... logprob:  0.375514, 0.093750 (1.476 sec)
5.458... logprob:  0.351496, 0.085938 (1.435 sec)
5.459... logprob:  0.513559, 0.140625 (1.437 sec)
5.460... logprob:  0.275618, 0.054688 (1.437 sec)
5.461... logprob:  0.459884, 0.125000 (1.424 sec)
5.462... logprob:  0.472181, 0.125000 (1.433 sec)
5.463... logprob:  0.421159, 0.109375 (1.472 sec)
5.464... logprob:  0.482671, 0.132812 (1.448 sec)
5.465... logprob:  0.421324, 0.109375 (1.460 sec)
5.466... logprob:  0.318780, 0.070312 (1.458 sec)
5.467... logprob:  0.413866, 0.109375 (1.454 sec)
5.468... logprob:  0.394253, 0.101562 (1.439 sec)
5.469... logprob:  0.334401, 0.078125 (1.431 sec)
5.470... logprob:  0.399966, 0.101562 (1.429 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.513328552246094, 10.0]}, 128)
batch 872: ({'logprob': [66.99403381347656, 19.0]}, 128)
batch 873: ({'logprob': [40.171531677246094, 9.0]}, 128)
batch 874: ({'logprob': [45.013916015625, 11.0]}, 128)
batch 875: ({'logprob': [50.71529769897461, 13.0]}, 128)
batch 876: ({'logprob': [64.36274719238281, 18.0]}, 128)
batch 877: ({'logprob': [45.44416427612305, 11.0]}, 128)
batch 878: ({'logprob': [62.13679122924805, 17.0]}, 128)
batch 879: ({'logprob': [73.97023010253906, 21.0]}, 128)
batch 880: ({'logprob': [50.723209381103516, 13.0]}, 128)
batch 881: ({'logprob': [28.314496994018555, 5.0]}, 128)
batch 882: ({'logprob': [54.64404296875, 14.0]}, 128)
batch 883: ({'logprob': [62.132320404052734, 17.0]}, 128)
batch 884: ({'logprob': [51.13716506958008, 13.0]}, 128)
batch 885: ({'logprob': [51.996028900146484, 13.0]}, 128)
batch 886: ({'logprob': [62.559608459472656, 17.0]}, 128)

======================Test output======================
logprob:  0.415932, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.976582e-03 [2.074722e-09] 
Layer 'conv1' biases: 2.442973e-08 [5.526358e-11] 
Layer 'conv2' weights[0]: 7.963537e-03 [1.972493e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.182574e-10] 
Layer 'conv3' weights[0]: 7.961879e-03 [2.002392e-09] 
Layer 'conv3' biases: 2.666164e-07 [1.025409e-09] 
Layer 'conv4' weights[0]: 7.994410e-03 [2.274961e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.007219e-08] 
Layer 'conv5' weights[0]: 7.993387e-03 [6.908651e-08] 
Layer 'conv5' biases: 1.000000e+00 [7.523624e-08] 
Layer 'fc6' weights[0]: 7.590144e-03 [6.278642e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.351052e-09] 
Layer 'fc7' weights[0]: 7.702002e-03 [2.316038e-07] 
Layer 'fc7' biases: 9.998726e-01 [2.182481e-07] 
Layer 'fc8' weights[0]: 1.244799e-03 [1.054145e-05] 
Layer 'fc8' biases: 8.335603e-03 [6.300466e-05] 
Train error last 870 batches: 0.435383
-------------------------------------------------------
Not saving because 0.415932 > 0.415712 (4.190: -0.00%)
======================================================= (12.062 sec)
5.471... logprob:  0.530042, 0.148438 (1.445 sec)
5.472... logprob:  0.410451, 0.109375 (1.455 sec)
5.473... logprob:  0.375206, 0.093750 (1.454 sec)
5.474... logprob:  0.465996, 0.125000 (1.457 sec)
5.475... logprob:  0.504990, 0.140625 (1.466 sec)
5.476... logprob:  0.510648, 0.140625 (1.474 sec)
5.477... logprob:  0.334369, 0.078125 (1.437 sec)
5.478... logprob:  0.464267, 0.125000 (1.426 sec)
5.479... logprob:  0.306060, 0.070312 (1.434 sec)
5.480... logprob:  0.443457, 0.117188 (1.440 sec)
5.481... logprob:  0.547626, 0.156250 (1.438 sec)
5.482... logprob:  0.443194, 0.117188 (1.473 sec)
5.483... logprob:  0.502481, 0.140625 (1.452 sec)
5.484... logprob:  0.485235, 0.132812 (1.435 sec)
5.485... logprob:  0.409452, 0.109375 (1.481 sec)
5.486... logprob:  0.361879, 0.085938 (1.435 sec)
5.487... logprob:  0.522599, 0.148438 (1.426 sec)
5.488... logprob:  0.425051, 0.109375 (1.437 sec)
5.489... logprob:  0.416098, 0.109375 (1.431 sec)
5.490... logprob:  0.440718, 0.117188 (1.436 sec)
5.491... logprob:  0.313814, 0.070312 (1.482 sec)
5.492... logprob:  0.459719, 0.125000 (1.438 sec)
5.493... logprob:  0.522143, 0.148438 (1.442 sec)
5.494... logprob:  0.450394, 0.125000 (1.485 sec)
5.495... logprob:  0.380494, 0.093750 (1.433 sec)
5.496... logprob:  0.550798, 0.156250 (1.429 sec)
5.497... logprob:  0.467274, 0.125000 (1.436 sec)
5.498... logprob:  0.476386, 0.132812 (1.434 sec)
5.499... logprob:  0.456271, 0.125000 (1.431 sec)
5.500... logprob:  0.355033, 0.085938 (1.491 sec)
5.501... logprob:  0.339274, 0.078125 (1.433 sec)
5.502... logprob:  0.459741, 0.125000 (1.448 sec)
5.503... logprob:  0.400846, 0.101562 (1.476 sec)
5.504... logprob:  0.487546, 0.132812 (1.438 sec)
5.505... logprob:  0.570939, 0.164062 (1.440 sec)
5.506... logprob:  0.479676, 0.132812 (1.435 sec)
5.507... logprob:  0.385392, 0.093750 (1.428 sec)
5.508... logprob:  0.374793, 0.093750 (1.433 sec)
5.509... logprob:  0.323445, 0.070312 (1.478 sec)
5.510... logprob:  0.390451, 0.101562 (1.446 sec)
5.511... logprob:  0.410138, 0.109375 (1.470 sec)
5.512... logprob:  0.470801, 0.125000 (1.474 sec)
5.513... logprob:  0.325013, 0.078125 (1.448 sec)
5.514... logprob:  0.406187, 0.101562 (1.439 sec)
5.515... logprob:  0.455919, 0.125000 (1.433 sec)
5.516... logprob:  0.400973, 0.109375 (1.428 sec)
5.517... logprob:  0.628249, 0.179688 (1.439 sec)
5.518... logprob:  0.437833, 0.117188 (1.460 sec)
5.519... logprob:  0.516140, 0.140625 (1.458 sec)
5.520... logprob:  0.409683, 0.109375 (1.451 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.97342300415039, 10.0]}, 128)
batch 872: ({'logprob': [66.37255859375, 19.0]}, 128)
batch 873: ({'logprob': [40.85649108886719, 9.0]}, 128)
batch 874: ({'logprob': [45.40109634399414, 11.0]}, 128)
batch 875: ({'logprob': [50.86602020263672, 13.0]}, 128)
batch 876: ({'logprob': [63.8746337890625, 18.0]}, 128)
batch 877: ({'logprob': [45.862483978271484, 11.0]}, 128)
batch 878: ({'logprob': [61.81334686279297, 17.0]}, 128)
batch 879: ({'logprob': [73.20321655273438, 21.0]}, 128)
batch 880: ({'logprob': [50.87375259399414, 13.0]}, 128)
batch 881: ({'logprob': [29.443450927734375, 5.0]}, 128)
batch 882: ({'logprob': [54.75123977661133, 14.0]}, 128)
batch 883: ({'logprob': [61.80862045288086, 17.0]}, 128)
batch 884: ({'logprob': [51.31748962402344, 13.0]}, 128)
batch 885: ({'logprob': [52.236488342285156, 13.0]}, 128)
batch 886: ({'logprob': [62.26595687866211, 17.0]}, 128)

======================Test output======================
logprob:  0.416465, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.976544e-03 [2.166151e-09] 
Layer 'conv1' biases: 2.503399e-08 [4.313227e-11] 
Layer 'conv2' weights[0]: 7.963504e-03 [1.890204e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.727840e-10] 
Layer 'conv3' weights[0]: 7.961840e-03 [1.619280e-09] 
Layer 'conv3' biases: 2.750184e-07 [8.384876e-10] 
Layer 'conv4' weights[0]: 7.994373e-03 [1.784422e-09] 
Layer 'conv4' biases: 9.999999e-01 [7.688602e-09] 
Layer 'conv5' weights[0]: 7.993345e-03 [5.245224e-08] 
Layer 'conv5' biases: 1.000001e+00 [5.713705e-08] 
Layer 'fc6' weights[0]: 7.590101e-03 [4.907295e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.866866e-09] 
Layer 'fc7' weights[0]: 7.700019e-03 [2.330272e-07] 
Layer 'fc7' biases: 9.998720e-01 [2.207409e-07] 
Layer 'fc8' weights[0]: 1.222758e-03 [1.040018e-05] 
Layer 'fc8' biases: 8.278891e-03 [5.777601e-05] 
Train error last 870 batches: 0.435377
-------------------------------------------------------
Not saving because 0.416465 > 0.415712 (4.190: -0.00%)
======================================================= (11.950 sec)
5.521... logprob:  0.427700, 0.109375 (1.457 sec)
5.522... logprob:  0.532931, 0.156250 (1.463 sec)
5.523... logprob:  0.332038, 0.078125 (1.441 sec)
5.524... logprob:  0.437310, 0.117188 (1.421 sec)
5.525... logprob:  0.426472, 0.109375 (1.431 sec)
5.526... logprob:  0.352637, 0.078125 (1.441 sec)
5.527... logprob:  0.504565, 0.140625 (1.441 sec)
5.528... logprob:  0.440627, 0.117188 (1.471 sec)
5.529... logprob:  0.353029, 0.085938 (1.450 sec)
5.530... logprob:  0.440261, 0.117188 (1.443 sec)
5.531... logprob:  0.440120, 0.117188 (1.480 sec)
5.532... logprob:  0.467518, 0.125000 (1.430 sec)
5.533... logprob:  0.561218, 0.164062 (1.429 sec)
5.534... logprob:  0.325663, 0.078125 (1.435 sec)
5.535... logprob:  0.551989, 0.156250 (1.439 sec)
5.536... logprob:  0.507579, 0.140625 (1.435 sec)
5.537... logprob:  0.510190, 0.140625 (1.478 sec)
5.538... logprob:  0.486155, 0.132812 (1.447 sec)
5.539... logprob:  0.296149, 0.062500 (1.438 sec)
5.540... logprob:  0.447109, 0.117188 (1.485 sec)
5.541... logprob:  0.389141, 0.101562 (1.437 sec)
5.542... logprob:  0.411540, 0.109375 (1.430 sec)
5.543... logprob:  0.233540, 0.039062 (1.439 sec)
5.544... logprob:  0.317898, 0.070312 (1.456 sec)
5.545... logprob:  0.348969, 0.085938 (1.446 sec)
5.546... logprob:  0.368493, 0.093750 (1.486 sec)
5.547... logprob:  0.440285, 0.117188 (1.430 sec)
5.548... logprob:  0.453766, 0.125000 (1.442 sec)
5.549... logprob:  0.490863, 0.132812 (1.483 sec)
5.550... logprob:  0.367836, 0.093750 (1.436 sec)
5.551... logprob:  0.441864, 0.117188 (1.431 sec)
5.552... logprob:  0.471276, 0.125000 (1.442 sec)
5.553... logprob:  0.349455, 0.085938 (1.428 sec)
5.554... logprob:  0.506490, 0.140625 (1.434 sec)
5.555... logprob:  0.421513, 0.109375 (1.487 sec)
5.556... logprob:  0.356292, 0.085938 (1.434 sec)
5.557... logprob:  0.396712, 0.101562 (1.452 sec)
5.558... logprob:  0.382766, 0.101562 (1.477 sec)
5.559... logprob:  0.440683, 0.125000 (1.436 sec)
5.560... logprob:  0.335777, 0.078125 (1.441 sec)
5.561... logprob:  0.411763, 0.109375 (1.434 sec)
5.562... logprob:  0.503304, 0.140625 (1.424 sec)
5.563... logprob:  0.373971, 0.093750 (1.437 sec)
5.564... logprob:  0.468011, 0.132812 (1.470 sec)
5.565... logprob:  0.610480, 0.187500 (1.452 sec)
5.566... logprob:  0.375032, 0.093750 (1.457 sec)
5.567... logprob:  0.424015, 0.109375 (1.457 sec)
5.568... logprob:  0.496512, 0.140625 (1.457 sec)
5.569... logprob:  0.508620, 0.140625 (1.440 sec)
5.570... logprob:  0.543236, 0.164062 (1.425 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.455387115478516, 10.0]}, 128)
batch 872: ({'logprob': [65.70677185058594, 19.0]}, 128)
batch 873: ({'logprob': [42.60226058959961, 9.0]}, 128)
batch 874: ({'logprob': [46.26849365234375, 11.0]}, 128)
batch 875: ({'logprob': [51.516536712646484, 13.0]}, 128)
batch 876: ({'logprob': [63.481754302978516, 18.0]}, 128)
batch 877: ({'logprob': [47.06063461303711, 11.0]}, 128)
batch 878: ({'logprob': [62.026241302490234, 17.0]}, 128)
batch 879: ({'logprob': [73.30811309814453, 21.0]}, 128)
batch 880: ({'logprob': [51.52292251586914, 13.0]}, 128)
batch 881: ({'logprob': [31.297277450561523, 5.0]}, 128)
batch 882: ({'logprob': [56.11532974243164, 14.0]}, 128)
batch 883: ({'logprob': [62.021461486816406, 17.0]}, 128)
batch 884: ({'logprob': [52.296478271484375, 13.0]}, 128)
batch 885: ({'logprob': [53.8745231628418, 13.0]}, 128)
batch 886: ({'logprob': [62.80774688720703, 17.0]}, 128)

======================Test output======================
logprob:  0.422052, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.976497e-03 [2.145521e-09] 
Layer 'conv1' biases: 2.555387e-08 [5.119175e-11] 
Layer 'conv2' weights[0]: 7.963471e-03 [2.119885e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.582976e-10] 
Layer 'conv3' weights[0]: 7.961799e-03 [2.015150e-09] 
Layer 'conv3' biases: 2.793328e-07 [1.150476e-09] 
Layer 'conv4' weights[0]: 7.994334e-03 [2.189257e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.079650e-08] 
Layer 'conv5' weights[0]: 7.993306e-03 [7.425089e-08] 
Layer 'conv5' biases: 1.000001e+00 [8.061050e-08] 
Layer 'fc6' weights[0]: 7.590060e-03 [6.702377e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.783935e-09] 
Layer 'fc7' weights[0]: 7.698089e-03 [1.736458e-07] 
Layer 'fc7' biases: 9.998719e-01 [1.617277e-07] 
Layer 'fc8' weights[0]: 1.198415e-03 [8.031178e-06] 
Layer 'fc8' biases: 8.232854e-03 [4.533681e-05] 
Train error last 870 batches: 0.435373
-------------------------------------------------------
Not saving because 0.422052 > 0.415712 (4.190: -0.00%)
======================================================= (12.042 sec)
5.571... logprob:  0.454865, 0.125000 (1.446 sec)
5.572... logprob:  0.501951, 0.140625 (1.447 sec)
5.573... logprob:  0.512704, 0.148438 (1.443 sec)
5.574... logprob:  0.428647, 0.109375 (1.464 sec)
5.575... logprob:  0.343360, 0.078125 (1.458 sec)
5.576... logprob:  0.427728, 0.109375 (1.445 sec)
5.577... logprob:  0.461035, 0.125000 (1.494 sec)
5.578... logprob:  0.336291, 0.078125 (1.433 sec)
5.579... logprob:  0.442130, 0.117188 (1.431 sec)
5.580... logprob:  0.547396, 0.156250 (1.437 sec)
5.581... logprob:  0.531666, 0.156250 (1.442 sec)
5.582... logprob:  0.438334, 0.125000 (1.441 sec)
5.583... logprob:  0.593344, 0.171875 (1.477 sec)
5.584... logprob:  0.468385, 0.132812 (1.448 sec)
5.585... logprob:  0.349797, 0.085938 (1.433 sec)
5.586... logprob:  0.313229, 0.070312 (1.490 sec)
5.587... logprob:  0.404179, 0.101562 (1.434 sec)
5.588... logprob:  0.419027, 0.117188 (1.429 sec)
5.589... logprob:  0.361761, 0.093750 (1.441 sec)
5.590... logprob:  0.524421, 0.148438 (1.436 sec)
5.591... logprob:  0.397533, 0.101562 (1.433 sec)
5.592... logprob:  0.455573, 0.125000 (1.485 sec)
5.593... logprob:  0.467238, 0.125000 (1.438 sec)
5.594... logprob:  0.352961, 0.085938 (1.443 sec)
5.595... logprob:  0.428447, 0.109375 (1.482 sec)
5.596... logprob:  0.461450, 0.125000 (1.432 sec)
5.597... logprob:  0.397312, 0.101562 (1.438 sec)
5.598... logprob:  0.397147, 0.101562 (1.436 sec)
5.599... logprob:  0.313191, 0.070312 (1.431 sec)
5.600... logprob:  0.341094, 0.085938 (1.435 sec)
5.601... logprob:  0.401835, 0.101562 (1.488 sec)
5.602... logprob:  0.289097, 0.062500 (1.432 sec)
5.603... logprob:  0.266185, 0.054688 (1.449 sec)
5.604... logprob:  0.407022, 0.101562 (1.480 sec)
5.605... logprob:  0.562927, 0.148438 (1.436 sec)
5.606... logprob:  0.296248, 0.070312 (1.434 sec)
5.607... logprob:  0.504665, 0.132812 (1.432 sec)
5.608... logprob:  0.360636, 0.085938 (1.423 sec)
5.609... logprob:  0.356255, 0.085938 (1.440 sec)
5.610... logprob:  0.493787, 0.132812 (1.474 sec)
5.611... logprob:  0.511337, 0.140625 (1.448 sec)
5.612... logprob:  0.447745, 0.117188 (1.455 sec)
5.613... logprob:  0.280917, 0.062500 (1.463 sec)
5.614... logprob:  0.504254, 0.140625 (1.450 sec)
5.615... logprob:  0.352047, 0.085938 (1.440 sec)
5.616... logprob:  0.416322, 0.109375 (1.429 sec)
5.617... logprob:  0.418442, 0.109375 (1.427 sec)
5.618... logprob:  0.546286, 0.156250 (1.467 sec)
5.619... logprob:  0.505519, 0.140625 (1.458 sec)
5.620... logprob:  0.539874, 0.156250 (1.454 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.461814880371094, 10.0]}, 128)
batch 872: ({'logprob': [66.28472900390625, 19.0]}, 128)
batch 873: ({'logprob': [41.8027229309082, 9.0]}, 128)
batch 874: ({'logprob': [46.39038848876953, 11.0]}, 128)
batch 875: ({'logprob': [51.48188018798828, 13.0]}, 128)
batch 876: ({'logprob': [63.86964416503906, 18.0]}, 128)
batch 877: ({'logprob': [46.64473342895508, 11.0]}, 128)
batch 878: ({'logprob': [61.68254089355469, 17.0]}, 128)
batch 879: ({'logprob': [72.11810302734375, 21.0]}, 128)
batch 880: ({'logprob': [51.49028778076172, 13.0]}, 128)
batch 881: ({'logprob': [31.344768524169922, 5.0]}, 128)
batch 882: ({'logprob': [54.65885925292969, 14.0]}, 128)
batch 883: ({'logprob': [61.67734909057617, 17.0]}, 128)
batch 884: ({'logprob': [51.72431564331055, 13.0]}, 128)
batch 885: ({'logprob': [52.225589752197266, 13.0]}, 128)
batch 886: ({'logprob': [61.92597198486328, 17.0]}, 128)

======================Test output======================
logprob:  0.419328, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.976464e-03 [3.396215e-09] 
Layer 'conv1' biases: 2.610669e-08 [5.718410e-11] 
Layer 'conv2' weights[0]: 7.963430e-03 [2.579740e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.757209e-10] 
Layer 'conv3' weights[0]: 7.961759e-03 [2.205188e-09] 
Layer 'conv3' biases: 2.851709e-07 [1.178379e-09] 
Layer 'conv4' weights[0]: 7.994297e-03 [2.468974e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.115041e-08] 
Layer 'conv5' weights[0]: 7.993260e-03 [7.630184e-08] 
Layer 'conv5' biases: 1.000001e+00 [8.306446e-08] 
Layer 'fc6' weights[0]: 7.590020e-03 [6.886275e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.954513e-09] 
Layer 'fc7' weights[0]: 7.696100e-03 [2.604314e-07] 
Layer 'fc7' biases: 9.998706e-01 [2.488954e-07] 
Layer 'fc8' weights[0]: 1.198922e-03 [1.075326e-05] 
Layer 'fc8' biases: 8.374746e-03 [6.169674e-05] 
Train error last 870 batches: 0.435369
-------------------------------------------------------
Not saving because 0.419328 > 0.415712 (4.190: -0.00%)
======================================================= (12.021 sec)
5.621... logprob:  0.364347, 0.085938 (1.455 sec)
5.622... logprob:  0.365335, 0.085938 (1.447 sec)
5.623... logprob:  0.423419, 0.109375 (1.469 sec)
5.624... logprob:  0.382777, 0.093750 (1.440 sec)
5.625... logprob:  0.441144, 0.117188 (1.482 sec)
5.626... logprob:  0.438596, 0.117188 (1.435 sec)
5.627... logprob:  0.436062, 0.117188 (1.438 sec)
5.628... logprob:  0.465107, 0.125000 (1.444 sec)
5.629... logprob:  0.371958, 0.093750 (1.473 sec)
5.630... logprob:  0.422391, 0.109375 (1.453 sec)
5.631... logprob:  0.639955, 0.187500 (1.434 sec)
5.632... logprob:  0.399137, 0.101562 (1.489 sec)
5.633... logprob:  0.375950, 0.093750 (1.431 sec)
5.634... logprob:  0.660923, 0.195312 (1.433 sec)
5.635... logprob:  0.374011, 0.093750 (1.434 sec)
5.636... logprob:  0.480125, 0.132812 (1.438 sec)
5.637... logprob:  0.330725, 0.078125 (1.437 sec)
5.638... logprob:  0.516418, 0.140625 (1.480 sec)
5.639... logprob:  0.418131, 0.109375 (1.441 sec)
5.640... logprob:  0.529204, 0.148438 (1.438 sec)
5.641... logprob:  0.409955, 0.109375 (1.490 sec)
5.642... logprob:  0.500728, 0.140625 (1.433 sec)
5.643... logprob:  0.622614, 0.187500 (1.435 sec)
5.644... logprob:  0.321641, 0.070312 (1.436 sec)
5.645... logprob:  0.414122, 0.109375 (1.435 sec)
5.646... logprob:  0.386127, 0.093750 (1.434 sec)
5.647... logprob:  0.456511, 0.125000 (1.488 sec)
5.648... logprob:  0.490702, 0.140625 (1.442 sec)
5.649... logprob:  0.369610, 0.093750 (1.451 sec)
5.650... logprob:  0.413691, 0.109375 (1.476 sec)
5.651... logprob:  0.397343, 0.101562 (1.451 sec)
5.652... logprob:  0.507757, 0.140625 (1.443 sec)
5.653... logprob:  0.548370, 0.156250 (1.431 sec)
5.654... logprob:  0.495814, 0.140625 (1.433 sec)
5.655... logprob:  0.436142, 0.117188 (1.432 sec)
5.656... logprob:  0.416656, 0.109375 (1.484 sec)
5.657... logprob:  0.450055, 0.117188 (1.441 sec)
5.658... logprob:  0.345321, 0.085938 (1.451 sec)
5.659... logprob:  0.464692, 0.125000 (1.479 sec)
5.660... logprob:  0.445302, 0.125000 (1.442 sec)
5.661... logprob:  0.378805, 0.093750 (1.442 sec)
5.662... logprob:  0.468947, 0.132812 (1.428 sec)
5.663... logprob:  0.311142, 0.070312 (1.427 sec)
5.664... logprob:  0.285458, 0.062500 (1.442 sec)
5.665... logprob:  0.402271, 0.101562 (1.462 sec)
5.666... logprob:  0.442262, 0.117188 (1.453 sec)
5.667... logprob:  0.564439, 0.164062 (1.459 sec)
5.668... logprob:  0.497992, 0.140625 (1.450 sec)
5.669... logprob:  0.433631, 0.109375 (1.465 sec)
5.670... logprob:  0.362812, 0.085938 (1.439 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.12113571166992, 10.0]}, 128)
batch 872: ({'logprob': [66.67494201660156, 19.0]}, 128)
batch 873: ({'logprob': [40.70612335205078, 9.0]}, 128)
batch 874: ({'logprob': [45.05195617675781, 11.0]}, 128)
batch 875: ({'logprob': [50.80018615722656, 13.0]}, 128)
batch 876: ({'logprob': [64.15592956542969, 18.0]}, 128)
batch 877: ({'logprob': [45.75360107421875, 11.0]}, 128)
batch 878: ({'logprob': [62.31426239013672, 17.0]}, 128)
batch 879: ({'logprob': [74.51054382324219, 21.0]}, 128)
batch 880: ({'logprob': [50.807491302490234, 13.0]}, 128)
batch 881: ({'logprob': [28.48532485961914, 5.0]}, 128)
batch 882: ({'logprob': [55.42995071411133, 14.0]}, 128)
batch 883: ({'logprob': [62.30949020385742, 17.0]}, 128)
batch 884: ({'logprob': [51.49296951293945, 13.0]}, 128)
batch 885: ({'logprob': [52.89445114135742, 13.0]}, 128)
batch 886: ({'logprob': [63.008094787597656, 17.0]}, 128)

======================Test output======================
logprob:  0.417733, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.976425e-03 [1.986536e-09] 
Layer 'conv1' biases: 2.658072e-08 [2.705728e-11] 
Layer 'conv2' weights[0]: 7.963391e-03 [1.358003e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.286420e-10] 
Layer 'conv3' weights[0]: 7.961716e-03 [1.113517e-09] 
Layer 'conv3' biases: 2.870523e-07 [4.047241e-10] 
Layer 'conv4' weights[0]: 7.994261e-03 [1.103288e-09] 
Layer 'conv4' biases: 9.999999e-01 [2.868419e-09] 
Layer 'conv5' weights[0]: 7.993232e-03 [1.763090e-08] 
Layer 'conv5' biases: 1.000001e+00 [1.875384e-08] 
Layer 'fc6' weights[0]: 7.589991e-03 [1.840034e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.668567e-09] 
Layer 'fc7' weights[0]: 7.694104e-03 [8.775199e-08] 
Layer 'fc7' biases: 9.998724e-01 [7.213028e-08] 
Layer 'fc8' weights[0]: 1.260008e-03 [3.787622e-06] 
Layer 'fc8' biases: 8.830151e-03 [2.044011e-05] 
Train error last 870 batches: 0.435368
-------------------------------------------------------
Not saving because 0.417733 > 0.415712 (4.190: -0.00%)
======================================================= (12.125 sec)
5.671... logprob:  0.360693, 0.093750 (1.430 sec)
5.672... logprob:  0.441869, 0.117188 (1.443 sec)
5.673... logprob:  0.436288, 0.117188 (1.444 sec)
5.674... logprob:  0.446794, 0.117188 (1.440 sec)
5.675... logprob:  0.356581, 0.093750 (1.474 sec)
5.676... logprob:  0.450131, 0.125000 (1.450 sec)
5.677... logprob:  0.471135, 0.125000 (1.444 sec)
5.678... logprob:  0.465628, 0.125000 (1.479 sec)
5.679... logprob:  0.454909, 0.125000 (1.438 sec)
5.680... logprob:  0.351747, 0.078125 (1.428 sec)
5.681... logprob:  0.374038, 0.093750 (1.435 sec)
5.682... logprob:  0.340445, 0.078125 (1.447 sec)
5.683... logprob:  0.411754, 0.109375 (1.436 sec)
5.684... logprob:  0.357365, 0.085938 (1.502 sec)
5.685... logprob:  0.284894, 0.054688 (1.448 sec)
5.686... logprob:  0.317729, 0.070312 (1.434 sec)
5.687... logprob:  0.281209, 0.062500 (1.492 sec)
5.688... logprob:  0.323231, 0.078125 (1.429 sec)
5.689... logprob:  0.472224, 0.125000 (1.436 sec)
5.690... logprob:  0.528578, 0.140625 (1.433 sec)
5.691... logprob:  0.518765, 0.140625 (1.437 sec)
5.692... logprob:  0.387313, 0.101562 (1.430 sec)
5.693... logprob:  0.458012, 0.125000 (1.490 sec)
5.694... logprob:  0.330535, 0.078125 (1.436 sec)
5.695... logprob:  0.356418, 0.085938 (1.447 sec)
5.696... logprob:  0.538011, 0.148438 (1.477 sec)
5.697... logprob:  0.465295, 0.125000 (1.438 sec)
5.698... logprob:  0.548057, 0.156250 (1.431 sec)
5.699... logprob:  0.459616, 0.125000 (1.433 sec)
5.700... logprob:  0.434485, 0.117188 (1.431 sec)
5.701... logprob:  0.423725, 0.109375 (1.433 sec)
5.702... logprob:  0.521315, 0.148438 (1.487 sec)
5.703... logprob:  0.406070, 0.101562 (1.438 sec)
5.704... logprob:  0.406727, 0.101562 (1.452 sec)
5.705... logprob:  0.420563, 0.109375 (1.471 sec)
5.706... logprob:  0.468105, 0.125000 (1.443 sec)
5.707... logprob:  0.485314, 0.132812 (1.436 sec)
5.708... logprob:  0.416978, 0.109375 (1.436 sec)
5.709... logprob:  0.422302, 0.109375 (1.425 sec)
5.710... logprob:  0.603350, 0.179688 (1.439 sec)
5.711... logprob:  0.469579, 0.125000 (1.468 sec)
5.712... logprob:  0.339845, 0.078125 (1.450 sec)
5.713... logprob:  0.588363, 0.179688 (1.457 sec)
5.714... logprob:  0.466412, 0.125000 (1.458 sec)
5.715... logprob:  0.417114, 0.109375 (1.457 sec)
5.716... logprob:  0.335044, 0.078125 (1.439 sec)
5.717... logprob:  0.429927, 0.117188 (1.427 sec)
5.718... logprob:  0.490498, 0.132812 (1.432 sec)
5.719... logprob:  0.406167, 0.109375 (1.439 sec)
5.720... logprob:  0.433194, 0.117188 (1.455 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.6433219909668, 10.0]}, 128)
batch 872: ({'logprob': [66.61314392089844, 19.0]}, 128)
batch 873: ({'logprob': [40.54279708862305, 9.0]}, 128)
batch 874: ({'logprob': [45.17041015625, 11.0]}, 128)
batch 875: ({'logprob': [50.764244079589844, 13.0]}, 128)
batch 876: ({'logprob': [64.06261444091797, 18.0]}, 128)
batch 877: ({'logprob': [45.65450668334961, 11.0]}, 128)
batch 878: ({'logprob': [61.9705924987793, 17.0]}, 128)
batch 879: ({'logprob': [73.64179229736328, 21.0]}, 128)
batch 880: ({'logprob': [50.77219009399414, 13.0]}, 128)
batch 881: ({'logprob': [28.847471237182617, 5.0]}, 128)
batch 882: ({'logprob': [54.77245330810547, 14.0]}, 128)
batch 883: ({'logprob': [61.96571731567383, 17.0]}, 128)
batch 884: ({'logprob': [51.23908233642578, 13.0]}, 128)
batch 885: ({'logprob': [52.204566955566406, 13.0]}, 128)
batch 886: ({'logprob': [62.44639587402344, 17.0]}, 128)

======================Test output======================
logprob:  0.416168, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.976380e-03 [1.594982e-09] 
Layer 'conv1' biases: 2.698148e-08 [3.271355e-11] 
Layer 'conv2' weights[0]: 7.963355e-03 [1.195757e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.196327e-10] 
Layer 'conv3' weights[0]: 7.961675e-03 [1.057930e-09] 
Layer 'conv3' biases: 2.906416e-07 [3.625255e-10] 
Layer 'conv4' weights[0]: 7.994220e-03 [1.016135e-09] 
Layer 'conv4' biases: 1.000000e+00 [1.997025e-09] 
Layer 'conv5' weights[0]: 7.993193e-03 [9.134550e-09] 
Layer 'conv5' biases: 1.000001e+00 [9.243147e-09] 
Layer 'fc6' weights[0]: 7.589949e-03 [1.177671e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.580204e-10] 
Layer 'fc7' weights[0]: 7.692128e-03 [5.883044e-08] 
Layer 'fc7' biases: 9.998719e-01 [3.715934e-08] 
Layer 'fc8' weights[0]: 1.253202e-03 [5.600847e-06] 
Layer 'fc8' biases: 8.995539e-03 [3.349589e-05] 
Train error last 870 batches: 0.435363
-------------------------------------------------------
Not saving because 0.416168 > 0.415712 (4.190: -0.00%)
======================================================= (12.133 sec)
5.721... logprob:  0.451751, 0.117188 (1.469 sec)
5.722... logprob:  0.536521, 0.156250 (1.458 sec)
5.723... logprob:  0.416667, 0.109375 (1.449 sec)
5.724... logprob:  0.412702, 0.109375 (1.476 sec)
5.725... logprob:  0.494315, 0.140625 (1.439 sec)
5.726... logprob:  0.338463, 0.085938 (1.428 sec)
5.727... logprob:  0.393511, 0.101562 (1.433 sec)
5.728... logprob:  0.421737, 0.109375 (1.441 sec)
5.729... logprob:  0.388604, 0.093750 (1.436 sec)
5.730... logprob:  0.565773, 0.164062 (1.476 sec)
5.731... logprob:  0.449948, 0.125000 (1.450 sec)
5.732... logprob:  0.311649, 0.070312 (1.433 sec)
5.733... logprob:  0.557448, 0.156250 (1.490 sec)
5.734... logprob:  0.340522, 0.078125 (1.431 sec)
5.735... logprob:  0.528077, 0.148438 (1.434 sec)
5.736... logprob:  0.644121, 0.187500 (1.438 sec)
5.737... logprob:  0.516323, 0.148438 (1.437 sec)
5.738... logprob:  0.459540, 0.125000 (1.434 sec)
5.739... logprob:  0.477858, 0.132812 (1.484 sec)
5.740... logprob:  0.339364, 0.078125 (1.437 sec)
5.741... logprob:  0.393188, 0.101562 (1.444 sec)
5.742... logprob:  0.419717, 0.109375 (1.485 sec)
5.743... logprob:  0.364788, 0.085938 (1.508 sec)
5.744... logprob:  0.519413, 0.148438 (1.437 sec)
5.745... logprob:  0.478245, 0.132812 (1.434 sec)
5.746... logprob:  0.440570, 0.117188 (1.433 sec)
5.747... logprob:  0.425596, 0.109375 (1.433 sec)
5.748... logprob:  0.377978, 0.093750 (1.491 sec)
5.749... logprob:  0.420818, 0.109375 (1.432 sec)
5.750... logprob:  0.512752, 0.140625 (1.452 sec)
5.751... logprob:  0.263560, 0.054688 (1.480 sec)
5.752... logprob:  0.521813, 0.140625 (1.440 sec)
5.753... logprob:  0.441317, 0.117188 (1.437 sec)
5.754... logprob:  0.469750, 0.132812 (1.435 sec)
5.755... logprob:  0.507215, 0.140625 (1.432 sec)
5.756... logprob:  0.440823, 0.117188 (1.432 sec)
5.757... logprob:  0.551991, 0.156250 (1.477 sec)
5.758... logprob:  0.394037, 0.101562 (1.463 sec)
5.759... logprob:  0.459773, 0.125000 (1.455 sec)
5.760... logprob:  0.485125, 0.132812 (1.463 sec)
5.761... logprob:  0.418690, 0.109375 (1.449 sec)
5.762... logprob:  0.516165, 0.148438 (1.440 sec)
5.763... logprob:  0.558724, 0.164062 (1.432 sec)
5.764... logprob:  0.503242, 0.140625 (1.424 sec)
5.765... logprob:  0.312604, 0.062500 (1.434 sec)
5.766... logprob:  0.482354, 0.132812 (1.455 sec)
5.767... logprob:  0.371148, 0.085938 (1.460 sec)
5.768... logprob:  0.433006, 0.117188 (1.465 sec)
5.769... logprob:  0.491210, 0.140625 (1.469 sec)
5.770... logprob:  0.402739, 0.101562 (1.483 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.34065628051758, 10.0]}, 128)
batch 872: ({'logprob': [66.25403594970703, 19.0]}, 128)
batch 873: ({'logprob': [41.118194580078125, 9.0]}, 128)
batch 874: ({'logprob': [45.64228439331055, 11.0]}, 128)
batch 875: ({'logprob': [50.99391174316406, 13.0]}, 128)
batch 876: ({'logprob': [63.7899169921875, 18.0]}, 128)
batch 877: ({'logprob': [46.057716369628906, 11.0]}, 128)
batch 878: ({'logprob': [61.715240478515625, 17.0]}, 128)
batch 879: ({'logprob': [72.83235168457031, 21.0]}, 128)
batch 880: ({'logprob': [51.00194549560547, 13.0]}, 128)
batch 881: ({'logprob': [29.977523803710938, 5.0]}, 128)
batch 882: ({'logprob': [54.70646667480469, 14.0]}, 128)
batch 883: ({'logprob': [61.710140228271484, 17.0]}, 128)
batch 884: ({'logprob': [51.398616790771484, 13.0]}, 128)
batch 885: ({'logprob': [52.224525451660156, 13.0]}, 128)
batch 886: ({'logprob': [62.12099075317383, 17.0]}, 128)

======================Test output======================
logprob:  0.416936, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.976339e-03 [1.937372e-09] 
Layer 'conv1' biases: 2.751925e-08 [6.545725e-11] 
Layer 'conv2' weights[0]: 7.963321e-03 [1.770626e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.642663e-10] 
Layer 'conv3' weights[0]: 7.961637e-03 [1.944549e-09] 
Layer 'conv3' biases: 2.942665e-07 [1.086282e-09] 
Layer 'conv4' weights[0]: 7.994185e-03 [2.205395e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.124082e-08] 
Layer 'conv5' weights[0]: 7.993152e-03 [7.763840e-08] 
Layer 'conv5' biases: 1.000000e+00 [8.449405e-08] 
Layer 'fc6' weights[0]: 7.589913e-03 [6.939251e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.013070e-09] 
Layer 'fc7' weights[0]: 7.690168e-03 [2.552112e-07] 
Layer 'fc7' biases: 9.998711e-01 [2.426007e-07] 
Layer 'fc8' weights[0]: 1.232692e-03 [1.023436e-05] 
Layer 'fc8' biases: 8.974044e-03 [6.475552e-05] 
Train error last 870 batches: 0.435360
-------------------------------------------------------
Not saving because 0.416936 > 0.415712 (4.190: -0.00%)
======================================================= (12.078 sec)
5.771... logprob:  0.549757, 0.156250 (1.469 sec)
5.772... logprob:  0.414106, 0.109375 (1.454 sec)
5.773... logprob:  0.558523, 0.164062 (1.443 sec)
5.774... logprob:  0.361394, 0.085938 (1.464 sec)
5.775... logprob:  0.407340, 0.101562 (1.461 sec)
5.776... logprob:  0.433357, 0.117188 (1.484 sec)
5.777... logprob:  0.379930, 0.093750 (1.474 sec)
5.778... logprob:  0.433688, 0.117188 (1.465 sec)
5.779... logprob:  0.505617, 0.140625 (1.490 sec)
5.780... logprob:  0.385704, 0.101562 (1.457 sec)
5.781... logprob:  0.369991, 0.085938 (1.446 sec)
5.782... logprob:  0.351605, 0.085938 (1.451 sec)
5.783... logprob:  0.555519, 0.156250 (1.463 sec)
5.784... logprob:  0.441017, 0.117188 (1.458 sec)
5.785... logprob:  0.543427, 0.156250 (1.497 sec)
5.786... logprob:  0.477253, 0.132812 (1.471 sec)
5.787... logprob:  0.546020, 0.156250 (1.462 sec)
5.788... logprob:  0.562654, 0.164062 (1.495 sec)
5.789... logprob:  0.281999, 0.054688 (1.452 sec)
5.790... logprob:  0.408785, 0.101562 (1.452 sec)
5.791... logprob:  0.398306, 0.101562 (1.455 sec)
5.792... logprob:  0.361532, 0.085938 (1.467 sec)
5.793... logprob:  0.370685, 0.085938 (1.452 sec)
5.794... logprob:  0.387262, 0.093750 (1.494 sec)
5.795... logprob:  0.469998, 0.125000 (1.463 sec)
5.796... logprob:  0.423511, 0.109375 (1.456 sec)
5.797... logprob:  0.358538, 0.085938 (1.497 sec)
5.798... logprob:  0.393342, 0.101562 (1.454 sec)
5.799... logprob:  0.331850, 0.078125 (1.449 sec)
5.800... logprob:  0.372044, 0.093750 (1.453 sec)
5.801... logprob:  0.450417, 0.117188 (1.458 sec)
5.802... logprob:  0.423384, 0.109375 (1.458 sec)
5.803... logprob:  0.492736, 0.132812 (1.491 sec)
5.804... logprob:  0.350166, 0.085938 (1.467 sec)
5.805... logprob:  0.451861, 0.117188 (1.451 sec)
5.806... logprob:  0.424061, 0.109375 (1.509 sec)
5.807... logprob:  0.443587, 0.117188 (1.452 sec)
5.808... logprob:  0.462782, 0.125000 (1.456 sec)
5.809... logprob:  0.590182, 0.171875 (1.449 sec)
5.810... logprob:  0.442381, 0.117188 (1.460 sec)
5.811... logprob:  0.460592, 0.125000 (1.451 sec)
5.812... logprob:  0.462540, 0.125000 (1.497 sec)
5.813... logprob:  0.485915, 0.132812 (1.545 sec)
5.814... logprob:  0.478512, 0.132812 (1.459 sec)
5.815... logprob:  0.372991, 0.085938 (1.500 sec)
5.816... logprob:  0.409408, 0.101562 (1.451 sec)
5.817... logprob:  0.426478, 0.109375 (1.453 sec)
5.818... logprob:  0.559912, 0.164062 (1.446 sec)
5.819... logprob:  0.498286, 0.140625 (1.460 sec)
5.820... logprob:  0.421550, 0.109375 (1.452 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.29107666015625, 10.0]}, 128)
batch 872: ({'logprob': [66.19631958007812, 19.0]}, 128)
batch 873: ({'logprob': [41.78248977661133, 9.0]}, 128)
batch 874: ({'logprob': [46.3009147644043, 11.0]}, 128)
batch 875: ({'logprob': [51.41576385498047, 13.0]}, 128)
batch 876: ({'logprob': [63.79286193847656, 18.0]}, 128)
batch 877: ({'logprob': [46.60150909423828, 11.0]}, 128)
batch 878: ({'logprob': [61.66330337524414, 17.0]}, 128)
batch 879: ({'logprob': [72.19154357910156, 21.0]}, 128)
batch 880: ({'logprob': [51.42416763305664, 13.0]}, 128)
batch 881: ({'logprob': [31.23130226135254, 5.0]}, 128)
batch 882: ({'logprob': [54.720184326171875, 14.0]}, 128)
batch 883: ({'logprob': [61.65802764892578, 17.0]}, 128)
batch 884: ({'logprob': [51.704280853271484, 13.0]}, 128)
batch 885: ({'logprob': [52.29828643798828, 13.0]}, 128)
batch 886: ({'logprob': [61.9528923034668, 17.0]}, 128)

======================Test output======================
logprob:  0.419055, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.976298e-03 [2.354081e-09] 
Layer 'conv1' biases: 2.813428e-08 [6.716511e-11] 
Layer 'conv2' weights[0]: 7.963279e-03 [1.792612e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.374205e-10] 
Layer 'conv3' weights[0]: 7.961600e-03 [1.848762e-09] 
Layer 'conv3' biases: 3.009714e-07 [1.033568e-09] 
Layer 'conv4' weights[0]: 7.994148e-03 [2.061826e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.042496e-08] 
Layer 'conv5' weights[0]: 7.993111e-03 [7.234834e-08] 
Layer 'conv5' biases: 1.000001e+00 [7.870189e-08] 
Layer 'fc6' weights[0]: 7.589877e-03 [6.414269e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.492283e-09] 
Layer 'fc7' weights[0]: 7.688213e-03 [1.831563e-07] 
Layer 'fc7' biases: 9.998701e-01 [1.703054e-07] 
Layer 'fc8' weights[0]: 1.212830e-03 [7.015580e-06] 
Layer 'fc8' biases: 9.046595e-03 [4.819875e-05] 
Train error last 870 batches: 0.435355
-------------------------------------------------------
Not saving because 0.419055 > 0.415712 (4.190: -0.00%)
======================================================= (12.057 sec)
5.821... logprob:  0.406349, 0.101562 (1.513 sec)
5.822... logprob:  0.441003, 0.117188 (1.145 sec)
5.823... logprob:  0.340119, 0.078125 (1.156 sec)
5.824... logprob:  0.490343, 0.132812 (0.709 sec)
5.825... logprob:  0.286968, 0.062500 (0.686 sec)
5.826... logprob:  0.375226, 0.093750 (0.687 sec)
5.827... logprob:  0.420783, 0.109375 (0.687 sec)
5.828... logprob:  0.443978, 0.117188 (0.686 sec)
5.829... logprob:  0.505390, 0.140625 (0.690 sec)
5.830... logprob:  0.442597, 0.117188 (1.509 sec)
5.831... logprob:  0.514363, 0.140625 (1.457 sec)
5.832... logprob:  0.330928, 0.078125 (1.459 sec)
5.833... logprob:  0.488936, 0.132812 (1.491 sec)
5.834... logprob:  0.432846, 0.117188 (1.455 sec)
5.835... logprob:  0.542595, 0.148438 (1.456 sec)
5.836... logprob:  0.376575, 0.093750 (1.460 sec)
5.837... logprob:  0.315425, 0.070312 (1.450 sec)
5.838... logprob:  0.437031, 0.117188 (1.458 sec)
5.839... logprob:  0.472278, 0.125000 (1.500 sec)
5.840... logprob:  0.555517, 0.156250 (1.458 sec)
5.841... logprob:  0.396394, 0.101562 (1.463 sec)
5.842... logprob:  0.497689, 0.140625 (1.496 sec)
5.843... logprob:  0.465670, 0.125000 (1.455 sec)
5.844... logprob:  0.497524, 0.140625 (1.461 sec)
5.845... logprob:  0.487028, 0.132812 (1.448 sec)
5.846... logprob:  0.468642, 0.125000 (1.453 sec)
5.847... logprob:  0.362878, 0.085938 (1.452 sec)
5.848... logprob:  0.396834, 0.101562 (1.502 sec)
5.849... logprob:  0.360002, 0.085938 (1.459 sec)
5.850... logprob:  0.479541, 0.132812 (1.472 sec)
5.851... logprob:  0.440236, 0.117188 (1.487 sec)
5.852... logprob:  0.546311, 0.156250 (1.457 sec)
5.853... logprob:  0.371763, 0.093750 (1.462 sec)
5.854... logprob:  0.306915, 0.070312 (1.447 sec)
5.855... logprob:  0.485166, 0.132812 (1.452 sec)
5.856... logprob:  0.443964, 0.117188 (1.452 sec)
5.857... logprob:  0.372351, 0.093750 (1.503 sec)
5.858... logprob:  0.396257, 0.101562 (1.462 sec)
5.859... logprob:  0.307987, 0.070312 (1.471 sec)
5.860... logprob:  0.565774, 0.156250 (1.489 sec)
5.861... logprob:  0.417866, 0.109375 (1.461 sec)
5.862... logprob:  0.329046, 0.078125 (1.457 sec)
5.863... logprob:  0.399458, 0.101562 (1.445 sec)
5.864... logprob:  0.451323, 0.117188 (1.444 sec)
5.865... logprob:  0.484322, 0.132812 (1.463 sec)
5.866... logprob:  0.507367, 0.140625 (1.482 sec)
5.867... logprob:  0.502653, 0.140625 (1.480 sec)
5.868... logprob:  0.405560, 0.101562 (1.475 sec)
5.869... logprob:  0.383535, 0.093750 (1.476 sec)
5.870... logprob:  0.551819, 0.156250 (1.399 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.751983642578125, 10.0]}, 128)
batch 872: ({'logprob': [66.28697967529297, 19.0]}, 128)
batch 873: ({'logprob': [41.27973175048828, 9.0]}, 128)
batch 874: ({'logprob': [45.87982940673828, 11.0]}, 128)
batch 875: ({'logprob': [51.13777160644531, 13.0]}, 128)
batch 876: ({'logprob': [63.82754898071289, 18.0]}, 128)
batch 877: ({'logprob': [46.210777282714844, 11.0]}, 128)
batch 878: ({'logprob': [61.672245025634766, 17.0]}, 128)
batch 879: ({'logprob': [72.51783752441406, 21.0]}, 128)
batch 880: ({'logprob': [51.146240234375, 13.0]}, 128)
batch 881: ({'logprob': [30.410663604736328, 5.0]}, 128)
batch 882: ({'logprob': [54.59158706665039, 14.0]}, 128)
batch 883: ({'logprob': [61.66691207885742, 17.0]}, 128)
batch 884: ({'logprob': [51.45756149291992, 13.0]}, 128)
batch 885: ({'logprob': [52.11374282836914, 13.0]}, 128)
batch 886: ({'logprob': [61.993080139160156, 17.0]}, 128)

======================Test output======================
logprob:  0.417453, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.976257e-03 [2.201749e-09] 
Layer 'conv1' biases: 2.882843e-08 [4.414930e-11] 
Layer 'conv2' weights[0]: 7.963239e-03 [1.669433e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.949491e-10] 
Layer 'conv3' weights[0]: 7.961559e-03 [1.598512e-09] 
Layer 'conv3' biases: 3.077430e-07 [9.243183e-10] 
Layer 'conv4' weights[0]: 7.994103e-03 [1.809458e-09] 
Layer 'conv4' biases: 9.999999e-01 [8.988107e-09] 
Layer 'conv5' weights[0]: 7.993053e-03 [6.213299e-08] 
Layer 'conv5' biases: 1.000001e+00 [6.740574e-08] 
Layer 'fc6' weights[0]: 7.589838e-03 [5.534729e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.601013e-09] 
Layer 'fc7' weights[0]: 7.686262e-03 [2.515212e-07] 
Layer 'fc7' biases: 9.998708e-01 [2.397918e-07] 
Layer 'fc8' weights[0]: 1.228264e-03 [9.904794e-06] 
Layer 'fc8' biases: 9.330545e-03 [5.779793e-05] 
Train error last 870 batches: 0.435353
-------------------------------------------------------
Not saving because 0.417453 > 0.415712 (4.190: -0.00%)
======================================================= (12.017 sec)
6.1... logprob:  0.380323, 0.093750 (1.411 sec)
6.2... logprob:  0.448202, 0.117188 (1.454 sec)
6.3... logprob:  0.398552, 0.101562 (1.417 sec)
6.4... logprob:  0.443365, 0.117188 (1.411 sec)
6.5... logprob:  0.443285, 0.117188 (1.433 sec)
6.6... logprob:  0.499547, 0.140625 (1.392 sec)
6.7... logprob:  0.362730, 0.085938 (1.415 sec)
6.8... logprob:  0.419217, 0.109375 (1.391 sec)
6.9... logprob:  0.358515, 0.085938 (1.407 sec)
6.10... logprob:  0.377320, 0.093750 (1.407 sec)
6.11... logprob:  0.334310, 0.078125 (1.443 sec)
6.12... logprob:  0.466579, 0.125000 (1.393 sec)
6.13... logprob:  0.442610, 0.117188 (1.420 sec)
6.14... logprob:  0.444899, 0.117188 (1.402 sec)
6.15... logprob:  0.395984, 0.101562 (1.408 sec)
6.16... logprob:  0.421554, 0.109375 (1.407 sec)
6.17... logprob:  0.516024, 0.140625 (1.396 sec)
6.18... logprob:  0.262107, 0.054688 (1.396 sec)
6.19... logprob:  0.280021, 0.062500 (1.401 sec)
6.20... logprob:  0.421430, 0.109375 (1.406 sec)
6.21... logprob:  0.444003, 0.117188 (0.891 sec)
6.22... logprob:  0.536522, 0.148438 (1.336 sec)
6.23... logprob:  0.532644, 0.148438 (1.422 sec)
6.24... logprob:  0.310955, 0.070312 (0.991 sec)
6.25... logprob:  0.356459, 0.085938 (0.957 sec)
6.26... logprob:  0.463621, 0.125000 (1.448 sec)
6.27... logprob:  0.404762, 0.101562 (1.395 sec)
6.28... logprob:  0.421907, 0.109375 (1.410 sec)
6.29... logprob:  0.396141, 0.101562 (1.430 sec)
6.30... logprob:  0.374215, 0.093750 (1.414 sec)
6.31... logprob:  0.479816, 0.132812 (1.405 sec)
6.32... logprob:  0.457176, 0.125000 (1.402 sec)
6.33... logprob:  0.460646, 0.125000 (1.451 sec)
6.34... logprob:  0.464817, 0.125000 (1.391 sec)
6.35... logprob:  0.316167, 0.070312 (1.406 sec)
6.36... logprob:  0.475530, 0.132812 (1.402 sec)
6.37... logprob:  0.417579, 0.109375 (1.406 sec)
6.38... logprob:  0.392155, 0.101562 (1.397 sec)
6.39... logprob:  0.632051, 0.187500 (1.435 sec)
6.40... logprob:  0.446268, 0.117188 (1.410 sec)
6.41... logprob:  0.352510, 0.085938 (1.418 sec)
6.42... logprob:  0.391418, 0.101562 (1.421 sec)
6.43... logprob:  0.440205, 0.117188 (1.410 sec)
6.44... logprob:  0.518134, 0.148438 (1.432 sec)
6.45... logprob:  0.382158, 0.093750 (1.395 sec)
6.46... logprob:  0.486803, 0.132812 (1.402 sec)
6.47... logprob:  0.331716, 0.078125 (1.393 sec)
6.48... logprob:  0.498695, 0.140625 (1.429 sec)
6.49... logprob:  0.509916, 0.148438 (1.411 sec)
6.50... logprob:  0.393176, 0.101562 (1.430 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.80374526977539, 10.0]}, 128)
batch 872: ({'logprob': [66.2348861694336, 19.0]}, 128)
batch 873: ({'logprob': [41.05823516845703, 9.0]}, 128)
batch 874: ({'logprob': [45.404273986816406, 11.0]}, 128)
batch 875: ({'logprob': [50.88825607299805, 13.0]}, 128)
batch 876: ({'logprob': [63.78224182128906, 18.0]}, 128)
batch 877: ({'logprob': [45.974456787109375, 11.0]}, 128)
batch 878: ({'logprob': [61.874107360839844, 17.0]}, 128)
batch 879: ({'logprob': [73.4100570678711, 21.0]}, 128)
batch 880: ({'logprob': [50.896060943603516, 13.0]}, 128)
batch 881: ({'logprob': [29.497846603393555, 5.0]}, 128)
batch 882: ({'logprob': [55.054847717285156, 14.0]}, 128)
batch 883: ({'logprob': [61.86888885498047, 17.0]}, 128)
batch 884: ({'logprob': [51.44815444946289, 13.0]}, 128)
batch 885: ({'logprob': [52.58466720581055, 13.0]}, 128)
batch 886: ({'logprob': [62.43513870239258, 17.0]}, 128)

======================Test output======================
logprob:  0.417098, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.976218e-03 [1.781079e-09] 
Layer 'conv1' biases: 2.935035e-08 [3.196588e-11] 
Layer 'conv2' weights[0]: 7.963195e-03 [1.399294e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.263953e-10] 
Layer 'conv3' weights[0]: 7.961519e-03 [1.131157e-09] 
Layer 'conv3' biases: 3.105050e-07 [3.503451e-10] 
Layer 'conv4' weights[0]: 7.994068e-03 [1.106142e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.308061e-09] 
Layer 'conv5' weights[0]: 7.993028e-03 [7.095970e-09] 
Layer 'conv5' biases: 1.000001e+00 [7.144767e-09] 
Layer 'fc6' weights[0]: 7.589794e-03 [1.012119e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.339175e-10] 
Layer 'fc7' weights[0]: 7.684282e-03 [4.650536e-08] 
Layer 'fc7' biases: 9.998714e-01 [2.087928e-08] 
Layer 'fc8' weights[0]: 1.248795e-03 [6.244485e-06] 
Layer 'fc8' biases: 9.536231e-03 [3.672581e-05] 
Train error last 870 batches: 0.435355
-------------------------------------------------------
Not saving because 0.417098 > 0.415712 (4.190: -0.00%)
======================================================= (12.162 sec)
6.51... logprob:  0.489357, 0.140625 (1.424 sec)
6.52... logprob:  0.526025, 0.148438 (1.406 sec)
6.53... logprob:  0.295232, 0.062500 (1.448 sec)
6.54... logprob:  0.402569, 0.109375 (1.385 sec)
6.55... logprob:  0.331791, 0.078125 (1.405 sec)
6.56... logprob:  0.422036, 0.109375 (1.401 sec)
6.57... logprob:  0.573002, 0.164062 (1.425 sec)
6.58... logprob:  0.408420, 0.101562 (1.408 sec)
6.59... logprob:  0.333961, 0.078125 (1.470 sec)
6.60... logprob:  0.619596, 0.179688 (1.425 sec)
6.61... logprob:  0.383137, 0.093750 (1.433 sec)
6.62... logprob:  0.474928, 0.132812 (1.457 sec)
6.63... logprob:  0.397347, 0.101562 (1.436 sec)
6.64... logprob:  0.450168, 0.125000 (1.412 sec)
6.65... logprob:  0.373215, 0.093750 (1.400 sec)
6.66... logprob:  0.353912, 0.085938 (1.451 sec)
6.67... logprob:  0.295280, 0.062500 (1.395 sec)
6.68... logprob:  0.396831, 0.101562 (1.400 sec)
6.69... logprob:  0.497047, 0.140625 (1.423 sec)
6.70... logprob:  0.325890, 0.078125 (1.430 sec)
6.71... logprob:  0.382038, 0.101562 (1.460 sec)
6.72... logprob:  0.493813, 0.132812 (1.406 sec)
6.73... logprob:  0.447711, 0.117188 (1.425 sec)
6.74... logprob:  0.442593, 0.117188 (1.420 sec)
6.75... logprob:  0.380504, 0.093750 (1.414 sec)
6.76... logprob:  0.412214, 0.109375 (1.440 sec)
6.77... logprob:  0.396321, 0.101562 (1.432 sec)
6.78... logprob:  0.493336, 0.140625 (1.451 sec)
6.79... logprob:  0.456508, 0.125000 (1.406 sec)
6.80... logprob:  0.507309, 0.132812 (1.419 sec)
6.81... logprob:  0.416720, 0.109375 (1.422 sec)
6.82... logprob:  0.232094, 0.039062 (1.421 sec)
6.83... logprob:  0.493838, 0.140625 (1.406 sec)
6.84... logprob:  0.467874, 0.125000 (1.465 sec)
6.85... logprob:  0.432266, 0.117188 (1.429 sec)
6.86... logprob:  0.417072, 0.109375 (1.416 sec)
6.87... logprob:  0.633036, 0.187500 (1.421 sec)
6.88... logprob:  0.535362, 0.156250 (1.407 sec)
6.89... logprob:  0.410830, 0.109375 (1.441 sec)
6.90... logprob:  0.577620, 0.171875 (1.391 sec)
6.91... logprob:  0.348535, 0.078125 (1.394 sec)
6.92... logprob:  0.464405, 0.125000 (1.406 sec)
6.93... logprob:  0.492416, 0.140625 (1.396 sec)
6.94... logprob:  0.428753, 0.109375 (1.395 sec)
6.95... logprob:  0.471824, 0.125000 (1.407 sec)
6.96... logprob:  0.576471, 0.171875 (1.406 sec)
6.97... logprob:  0.430855, 0.117188 (1.391 sec)
6.98... logprob:  0.390867, 0.093750 (1.441 sec)
6.99... logprob:  0.474478, 0.132812 (1.406 sec)
6.100... logprob:  0.310361, 0.070312 (1.405 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.21881866455078, 10.0]}, 128)
batch 872: ({'logprob': [66.16273498535156, 19.0]}, 128)
batch 873: ({'logprob': [41.21299743652344, 9.0]}, 128)
batch 874: ({'logprob': [45.62320327758789, 11.0]}, 128)
batch 875: ({'logprob': [50.988685607910156, 13.0]}, 128)
batch 876: ({'logprob': [63.723777770996094, 18.0]}, 128)
batch 877: ({'logprob': [46.10246658325195, 11.0]}, 128)
batch 878: ({'logprob': [61.73784255981445, 17.0]}, 128)
batch 879: ({'logprob': [72.946044921875, 21.0]}, 128)
batch 880: ({'logprob': [50.99675369262695, 13.0]}, 128)
batch 881: ({'logprob': [29.980703353881836, 5.0]}, 128)
batch 882: ({'logprob': [54.86772537231445, 14.0]}, 128)
batch 883: ({'logprob': [61.73250198364258, 17.0]}, 128)
batch 884: ({'logprob': [51.45716857910156, 13.0]}, 128)
batch 885: ({'logprob': [52.41069030761719, 13.0]}, 128)
batch 886: ({'logprob': [62.207305908203125, 17.0]}, 128)

======================Test output======================
logprob:  0.417173, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.976172e-03 [3.240196e-09] 
Layer 'conv1' biases: 2.983970e-08 [9.237940e-11] 
Layer 'conv2' weights[0]: 7.963161e-03 [3.240680e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.544130e-10] 
Layer 'conv3' weights[0]: 7.961481e-03 [3.289266e-09] 
Layer 'conv3' biases: 3.135153e-07 [2.030930e-09] 
Layer 'conv4' weights[0]: 7.994032e-03 [3.810517e-09] 
Layer 'conv4' biases: 9.999999e-01 [2.114098e-08] 
Layer 'conv5' weights[0]: 7.992996e-03 [1.459117e-07] 
Layer 'conv5' biases: 1.000000e+00 [1.586393e-07] 
Layer 'fc6' weights[0]: 7.589754e-03 [1.290478e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.313766e-08] 
Layer 'fc7' weights[0]: 7.682336e-03 [2.861885e-07] 
Layer 'fc7' biases: 9.998709e-01 [2.740323e-07] 
Layer 'fc8' weights[0]: 1.240708e-03 [1.167016e-05] 
Layer 'fc8' biases: 9.549695e-03 [7.220588e-05] 
Train error last 870 batches: 0.435354
-------------------------------------------------------
Not saving because 0.417173 > 0.415712 (4.190: -0.00%)
======================================================= (12.032 sec)
6.101... logprob:  0.310225, 0.062500 (1.444 sec)
6.102... logprob:  0.546614, 0.156250 (1.392 sec)
6.103... logprob:  0.541682, 0.156250 (1.401 sec)
6.104... logprob:  0.389066, 0.101562 (1.401 sec)
6.105... logprob:  0.620044, 0.179688 (1.397 sec)
6.106... logprob:  0.344537, 0.085938 (1.392 sec)
6.107... logprob:  0.335608, 0.078125 (1.437 sec)
6.108... logprob:  0.586786, 0.171875 (1.395 sec)
6.109... logprob:  0.336261, 0.078125 (1.406 sec)
6.110... logprob:  0.564292, 0.164062 (1.396 sec)
6.111... logprob:  0.404792, 0.101562 (1.399 sec)
6.112... logprob:  0.366303, 0.093750 (1.399 sec)
6.113... logprob:  0.354826, 0.085938 (1.405 sec)
6.114... logprob:  0.440271, 0.117188 (1.430 sec)
6.115... logprob:  0.506775, 0.140625 (1.415 sec)
6.116... logprob:  0.393418, 0.101562 (1.402 sec)
6.117... logprob:  0.440408, 0.117188 (1.444 sec)
6.118... logprob:  0.409360, 0.101562 (1.392 sec)
6.119... logprob:  0.346105, 0.085938 (1.398 sec)
6.120... logprob:  0.547204, 0.156250 (1.406 sec)
6.121... logprob:  0.412741, 0.109375 (1.394 sec)
6.122... logprob:  0.519441, 0.148438 (1.441 sec)
6.123... logprob:  0.463858, 0.125000 (1.388 sec)
6.124... logprob:  0.447660, 0.125000 (1.406 sec)
6.125... logprob:  0.502095, 0.140625 (1.404 sec)
6.126... logprob:  0.476069, 0.125000 (1.392 sec)
6.127... logprob:  0.479981, 0.125000 (1.400 sec)
6.128... logprob:  0.422450, 0.109375 (1.415 sec)
6.129... logprob:  0.575037, 0.164062 (1.425 sec)
6.130... logprob:  0.382746, 0.093750 (1.410 sec)
6.131... logprob:  0.495445, 0.132812 (1.416 sec)
6.132... logprob:  0.506367, 0.140625 (1.435 sec)
6.133... logprob:  0.444583, 0.117188 (1.389 sec)
6.134... logprob:  0.401891, 0.101562 (1.398 sec)
6.135... logprob:  0.460365, 0.125000 (1.406 sec)
6.136... logprob:  0.562833, 0.164062 (1.396 sec)
6.137... logprob:  0.462536, 0.125000 (1.393 sec)
6.138... logprob:  0.319387, 0.070312 (1.447 sec)
6.139... logprob:  0.396307, 0.101562 (1.395 sec)
6.140... logprob:  0.561408, 0.164062 (1.418 sec)
6.141... logprob:  0.464340, 0.125000 (1.462 sec)
6.142... logprob:  0.464419, 0.125000 (1.403 sec)
6.143... logprob:  0.294238, 0.062500 (1.429 sec)
6.144... logprob:  0.457971, 0.125000 (1.421 sec)
6.145... logprob:  0.325754, 0.078125 (1.415 sec)
6.146... logprob:  0.483434, 0.132812 (1.416 sec)
6.147... logprob:  0.262781, 0.054688 (1.439 sec)
6.148... logprob:  0.459128, 0.125000 (1.392 sec)
6.149... logprob:  0.442551, 0.117188 (1.404 sec)
6.150... logprob:  0.347753, 0.085938 (1.405 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.27735900878906, 10.0]}, 128)
batch 872: ({'logprob': [67.88853454589844, 19.0]}, 128)
batch 873: ({'logprob': [39.61164093017578, 9.0]}, 128)
batch 874: ({'logprob': [44.81420135498047, 11.0]}, 128)
batch 875: ({'logprob': [50.75896453857422, 13.0]}, 128)
batch 876: ({'logprob': [65.10778045654297, 18.0]}, 128)
batch 877: ({'logprob': [45.186031341552734, 11.0]}, 128)
batch 878: ({'logprob': [62.67109680175781, 17.0]}, 128)
batch 879: ({'logprob': [74.93579864501953, 21.0]}, 128)
batch 880: ({'logprob': [50.768001556396484, 13.0]}, 128)
batch 881: ({'logprob': [27.321680068969727, 5.0]}, 128)
batch 882: ({'logprob': [54.66740417480469, 14.0]}, 128)
batch 883: ({'logprob': [62.66582489013672, 17.0]}, 128)
batch 884: ({'logprob': [51.124053955078125, 13.0]}, 128)
batch 885: ({'logprob': [51.8681526184082, 13.0]}, 128)
batch 886: ({'logprob': [63.036582946777344, 17.0]}, 128)

======================Test output======================
logprob:  0.416847, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.976136e-03 [1.935843e-09] 
Layer 'conv1' biases: 3.031905e-08 [3.167858e-11] 
Layer 'conv2' weights[0]: 7.963122e-03 [1.309451e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.220070e-10] 
Layer 'conv3' weights[0]: 7.961444e-03 [1.074956e-09] 
Layer 'conv3' biases: 3.171426e-07 [3.190604e-10] 
Layer 'conv4' weights[0]: 7.993999e-03 [1.053582e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.426241e-09] 
Layer 'conv5' weights[0]: 7.992953e-03 [6.719690e-09] 
Layer 'conv5' biases: 1.000000e+00 [6.669853e-09] 
Layer 'fc6' weights[0]: 7.589713e-03 [9.795784e-10] 
Layer 'fc6' biases: 1.000000e+00 [5.847832e-10] 
Layer 'fc7' weights[0]: 7.680403e-03 [1.209694e-07] 
Layer 'fc7' biases: 9.998719e-01 [1.054143e-07] 
Layer 'fc8' weights[0]: 1.302401e-03 [1.028441e-05] 
Layer 'fc8' biases: 1.001573e-02 [6.067318e-05] 
Train error last 870 batches: 0.435349
-------------------------------------------------------
Not saving because 0.416847 > 0.415712 (4.190: -0.00%)
======================================================= (12.145 sec)
6.151... logprob:  0.347193, 0.085938 (1.406 sec)
6.152... logprob:  0.784390, 0.234375 (1.408 sec)
6.153... logprob:  0.381848, 0.093750 (1.440 sec)
6.154... logprob:  0.523998, 0.148438 (1.409 sec)
6.155... logprob:  0.425436, 0.117188 (1.413 sec)
6.156... logprob:  0.296525, 0.062500 (1.440 sec)
6.157... logprob:  0.271148, 0.054688 (1.394 sec)
6.158... logprob:  0.455165, 0.125000 (1.415 sec)
6.159... logprob:  0.483311, 0.132812 (1.402 sec)
6.160... logprob:  0.445419, 0.117188 (1.399 sec)
6.161... logprob:  0.351257, 0.078125 (1.400 sec)
6.162... logprob:  0.612269, 0.179688 (1.403 sec)
6.163... logprob:  0.450070, 0.125000 (1.424 sec)
6.164... logprob:  0.469288, 0.125000 (1.417 sec)
6.165... logprob:  0.548526, 0.156250 (1.423 sec)
6.166... logprob:  0.445559, 0.125000 (1.446 sec)
6.167... logprob:  0.349860, 0.085938 (1.436 sec)
6.168... logprob:  0.363715, 0.085938 (1.432 sec)
6.169... logprob:  0.409027, 0.101562 (1.460 sec)
6.170... logprob:  0.459558, 0.125000 (1.407 sec)
6.171... logprob:  0.535559, 0.156250 (1.423 sec)
6.172... logprob:  0.435223, 0.109375 (1.416 sec)
6.173... logprob:  0.440554, 0.117188 (1.423 sec)
6.174... logprob:  0.601595, 0.171875 (1.409 sec)
6.175... logprob:  0.506280, 0.140625 (1.494 sec)
6.176... logprob:  0.478595, 0.132812 (1.415 sec)
6.177... logprob:  0.289598, 0.054688 (1.425 sec)
6.178... logprob:  0.383369, 0.093750 (1.465 sec)
6.179... logprob:  0.394871, 0.101562 (1.407 sec)
6.180... logprob:  0.466191, 0.125000 (1.421 sec)
6.181... logprob:  0.539860, 0.156250 (1.422 sec)
6.182... logprob:  0.371776, 0.093750 (1.415 sec)
6.183... logprob:  0.419956, 0.109375 (1.421 sec)
6.184... logprob:  0.483536, 0.132812 (1.424 sec)
6.185... logprob:  0.290043, 0.062500 (1.392 sec)
6.186... logprob:  0.370999, 0.093750 (1.403 sec)
6.187... logprob:  0.529572, 0.148438 (1.403 sec)
6.188... logprob:  0.459346, 0.125000 (1.396 sec)
6.189... logprob:  0.440920, 0.117188 (1.393 sec)
6.190... logprob:  0.375719, 0.093750 (1.434 sec)
6.191... logprob:  0.485086, 0.132812 (1.413 sec)
6.192... logprob:  0.520594, 0.148438 (1.417 sec)
6.193... logprob:  0.312725, 0.070312 (1.417 sec)
6.194... logprob:  0.414308, 0.109375 (1.421 sec)
6.195... logprob:  0.287503, 0.062500 (1.397 sec)
6.196... logprob:  0.410769, 0.109375 (1.397 sec)
6.197... logprob:  0.478086, 0.132812 (1.394 sec)
6.198... logprob:  0.355817, 0.085938 (1.410 sec)
6.199... logprob:  0.437173, 0.117188 (1.389 sec)
6.200... logprob:  0.440805, 0.117188 (1.439 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.38620376586914, 10.0]}, 128)
batch 872: ({'logprob': [66.88579559326172, 19.0]}, 128)
batch 873: ({'logprob': [40.291175842285156, 9.0]}, 128)
batch 874: ({'logprob': [45.00127029418945, 11.0]}, 128)
batch 875: ({'logprob': [50.71430587768555, 13.0]}, 128)
batch 876: ({'logprob': [64.2855453491211, 18.0]}, 128)
batch 877: ({'logprob': [45.50370407104492, 11.0]}, 128)
batch 878: ({'logprob': [62.160728454589844, 17.0]}, 128)
batch 879: ({'logprob': [74.08943176269531, 21.0]}, 128)
batch 880: ({'logprob': [50.722808837890625, 13.0]}, 128)
batch 881: ({'logprob': [28.33719253540039, 5.0]}, 128)
batch 882: ({'logprob': [54.82958984375, 14.0]}, 128)
batch 883: ({'logprob': [62.15532684326172, 17.0]}, 128)
batch 884: ({'logprob': [51.208133697509766, 13.0]}, 128)
batch 885: ({'logprob': [52.21107482910156, 13.0]}, 128)
batch 886: ({'logprob': [62.655250549316406, 17.0]}, 128)

======================Test output======================
logprob:  0.416229, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.976099e-03 [2.773357e-09] 
Layer 'conv1' biases: 3.100021e-08 [7.345371e-11] 
Layer 'conv2' weights[0]: 7.963088e-03 [1.825369e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.133655e-10] 
Layer 'conv3' weights[0]: 7.961403e-03 [1.389478e-09] 
Layer 'conv3' biases: 3.232083e-07 [5.491004e-10] 
Layer 'conv4' weights[0]: 7.993956e-03 [1.410756e-09] 
Layer 'conv4' biases: 9.999999e-01 [3.400880e-09] 
Layer 'conv5' weights[0]: 7.992907e-03 [2.334820e-08] 
Layer 'conv5' biases: 1.000000e+00 [2.534165e-08] 
Layer 'fc6' weights[0]: 7.589672e-03 [2.277669e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.134458e-09] 
Layer 'fc7' weights[0]: 7.678476e-03 [5.558853e-08] 
Layer 'fc7' biases: 9.998716e-01 [3.307429e-08] 
Layer 'fc8' weights[0]: 1.286358e-03 [5.691424e-06] 
Layer 'fc8' biases: 1.000572e-02 [3.409327e-05] 
Train error last 870 batches: 0.435343
-------------------------------------------------------
Not saving because 0.416229 > 0.415712 (4.190: -0.00%)
======================================================= (12.080 sec)
6.201... logprob:  0.437059, 0.117188 (1.419 sec)
6.202... logprob:  0.538200, 0.148438 (1.410 sec)
6.203... logprob:  0.420574, 0.109375 (1.456 sec)
6.204... logprob:  0.504157, 0.140625 (1.395 sec)
6.205... logprob:  0.334477, 0.078125 (1.400 sec)
6.206... logprob:  0.361293, 0.093750 (1.400 sec)
6.207... logprob:  0.382170, 0.093750 (1.400 sec)
6.208... logprob:  0.490236, 0.140625 (1.392 sec)
6.209... logprob:  0.334676, 0.078125 (1.432 sec)
6.210... logprob:  0.586293, 0.171875 (1.421 sec)
6.211... logprob:  0.488473, 0.132812 (1.412 sec)
6.212... logprob:  0.526339, 0.148438 (1.416 sec)
6.213... logprob:  0.515405, 0.140625 (1.460 sec)
6.214... logprob:  0.459495, 0.125000 (1.429 sec)
6.215... logprob:  0.396053, 0.101562 (1.413 sec)
6.216... logprob:  0.517683, 0.140625 (1.474 sec)
6.217... logprob:  0.325186, 0.070312 (1.402 sec)
6.218... logprob:  0.463827, 0.125000 (1.425 sec)
6.219... logprob:  0.500406, 0.140625 (1.413 sec)
6.220... logprob:  0.414939, 0.109375 (1.427 sec)
6.221... logprob:  0.399507, 0.101562 (1.399 sec)
6.222... logprob:  0.554770, 0.164062 (1.457 sec)
6.223... logprob:  0.569399, 0.164062 (1.440 sec)
6.224... logprob:  0.405749, 0.101562 (1.430 sec)
6.225... logprob:  0.392085, 0.101562 (1.451 sec)
6.226... logprob:  0.424485, 0.109375 (1.426 sec)
6.227... logprob:  0.453007, 0.125000 (1.416 sec)
6.228... logprob:  0.417307, 0.109375 (1.420 sec)
6.229... logprob:  0.489172, 0.132812 (1.418 sec)
6.230... logprob:  0.459951, 0.125000 (1.421 sec)
6.231... logprob:  0.453763, 0.125000 (1.412 sec)
6.232... logprob:  0.496416, 0.140625 (1.458 sec)
6.233... logprob:  0.466567, 0.132812 (1.429 sec)
6.234... logprob:  0.563733, 0.164062 (1.415 sec)
6.235... logprob:  0.482046, 0.132812 (1.553 sec)
6.236... logprob:  0.425885, 0.109375 (1.407 sec)
6.237... logprob:  0.341613, 0.078125 (1.421 sec)
6.238... logprob:  0.389582, 0.093750 (1.420 sec)
6.239... logprob:  0.478196, 0.132812 (1.419 sec)
6.240... logprob:  0.485848, 0.132812 (1.406 sec)
6.241... logprob:  0.493641, 0.132812 (1.457 sec)
6.242... logprob:  0.341640, 0.078125 (1.430 sec)
6.243... logprob:  0.385990, 0.093750 (1.428 sec)
6.244... logprob:  0.315043, 0.070312 (1.451 sec)
6.245... logprob:  0.494316, 0.132812 (1.425 sec)
6.246... logprob:  0.417010, 0.109375 (1.416 sec)
6.247... logprob:  0.357078, 0.085938 (1.415 sec)
6.248... logprob:  0.307509, 0.070312 (1.420 sec)
6.249... logprob:  0.556264, 0.156250 (1.424 sec)
6.250... logprob:  0.591766, 0.164062 (1.435 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.468711853027344, 10.0]}, 128)
batch 872: ({'logprob': [67.9852523803711, 19.0]}, 128)
batch 873: ({'logprob': [39.53894805908203, 9.0]}, 128)
batch 874: ({'logprob': [44.87098693847656, 11.0]}, 128)
batch 875: ({'logprob': [50.7855224609375, 13.0]}, 128)
batch 876: ({'logprob': [65.17993927001953, 18.0]}, 128)
batch 877: ({'logprob': [45.16317367553711, 11.0]}, 128)
batch 878: ({'logprob': [62.63824462890625, 17.0]}, 128)
batch 879: ({'logprob': [74.76335144042969, 21.0]}, 128)
batch 880: ({'logprob': [50.795135498046875, 13.0]}, 128)
batch 881: ({'logprob': [27.38823127746582, 5.0]}, 128)
batch 882: ({'logprob': [54.479942321777344, 14.0]}, 128)
batch 883: ({'logprob': [62.63261032104492, 17.0]}, 128)
batch 884: ({'logprob': [51.071048736572266, 13.0]}, 128)
batch 885: ({'logprob': [51.65553283691406, 13.0]}, 128)
batch 886: ({'logprob': [62.923892974853516, 17.0]}, 128)

======================Test output======================
logprob:  0.416670, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.976064e-03 [5.707358e-09] 
Layer 'conv1' biases: 3.160017e-08 [1.308756e-10] 
Layer 'conv2' weights[0]: 7.963049e-03 [4.581934e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.244067e-10] 
Layer 'conv3' weights[0]: 7.961368e-03 [4.267388e-09] 
Layer 'conv3' biases: 3.276123e-07 [2.896938e-09] 
Layer 'conv4' weights[0]: 7.993915e-03 [4.943539e-09] 
Layer 'conv4' biases: 9.999999e-01 [2.962262e-08] 
Layer 'conv5' weights[0]: 7.992869e-03 [2.044822e-07] 
Layer 'conv5' biases: 1.000000e+00 [2.222064e-07] 
Layer 'fc6' weights[0]: 7.589638e-03 [1.843452e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.861820e-08] 
Layer 'fc7' weights[0]: 7.676527e-03 [1.821339e-07] 
Layer 'fc7' biases: 9.998717e-01 [1.704536e-07] 
Layer 'fc8' weights[0]: 1.312653e-03 [1.002684e-05] 
Layer 'fc8' biases: 1.024100e-02 [5.823368e-05] 
Train error last 870 batches: 0.435340
-------------------------------------------------------
Not saving because 0.416670 > 0.415712 (4.190: -0.00%)
======================================================= (12.045 sec)
6.251... logprob:  0.352811, 0.085938 (1.467 sec)
6.252... logprob:  0.348778, 0.085938 (1.435 sec)
6.253... logprob:  0.378883, 0.093750 (1.419 sec)
6.254... logprob:  0.444168, 0.117188 (1.463 sec)
6.255... logprob:  0.351740, 0.085938 (1.396 sec)
6.256... logprob:  0.378421, 0.093750 (1.424 sec)
6.257... logprob:  0.332001, 0.078125 (1.422 sec)
6.258... logprob:  0.416489, 0.109375 (1.418 sec)
6.259... logprob:  0.442453, 0.117188 (1.403 sec)
6.260... logprob:  0.308554, 0.070312 (1.463 sec)
6.261... logprob:  0.393533, 0.101562 (1.434 sec)
6.262... logprob:  0.525537, 0.148438 (1.434 sec)
6.263... logprob:  0.425145, 0.109375 (1.443 sec)
6.264... logprob:  0.375300, 0.093750 (1.420 sec)
6.265... logprob:  0.439679, 0.117188 (1.420 sec)
6.266... logprob:  0.439108, 0.117188 (1.415 sec)
6.267... logprob:  0.421990, 0.109375 (1.418 sec)
6.268... logprob:  0.458921, 0.125000 (1.423 sec)
6.269... logprob:  0.567327, 0.164062 (1.409 sec)
6.270... logprob:  0.542044, 0.156250 (1.463 sec)
6.271... logprob:  0.446003, 0.117188 (1.424 sec)
6.272... logprob:  0.384957, 0.093750 (1.421 sec)
6.273... logprob:  0.500182, 0.140625 (1.467 sec)
6.274... logprob:  0.542689, 0.156250 (1.406 sec)
6.275... logprob:  0.488105, 0.132812 (1.424 sec)
6.276... logprob:  0.390354, 0.093750 (1.419 sec)
6.277... logprob:  0.428920, 0.109375 (1.424 sec)
6.278... logprob:  0.323033, 0.070312 (1.422 sec)
6.279... logprob:  0.324860, 0.070312 (1.465 sec)
6.280... logprob:  0.214785, 0.031250 (1.402 sec)
6.281... logprob:  0.417178, 0.109375 (1.429 sec)
6.282... logprob:  0.411399, 0.109375 (1.416 sec)
6.283... logprob:  0.393828, 0.101562 (1.418 sec)
6.284... logprob:  0.394757, 0.101562 (1.423 sec)
6.285... logprob:  0.452436, 0.117188 (1.439 sec)
6.286... logprob:  0.537987, 0.140625 (1.441 sec)
6.287... logprob:  0.346709, 0.085938 (1.428 sec)
6.288... logprob:  0.330043, 0.078125 (1.434 sec)
6.289... logprob:  0.446096, 0.117188 (1.439 sec)
6.290... logprob:  0.490614, 0.132812 (1.407 sec)
6.291... logprob:  0.439060, 0.117188 (1.417 sec)
6.292... logprob:  0.566839, 0.156250 (1.418 sec)
6.293... logprob:  0.427274, 0.117188 (1.428 sec)
6.294... logprob:  0.356434, 0.085938 (1.403 sec)
6.295... logprob:  0.335464, 0.078125 (1.467 sec)
6.296... logprob:  0.356509, 0.085938 (1.418 sec)
6.297... logprob:  0.394978, 0.101562 (1.423 sec)
6.298... logprob:  0.447802, 0.125000 (1.468 sec)
6.299... logprob:  0.343064, 0.078125 (1.402 sec)
6.300... logprob:  0.407051, 0.101562 (1.428 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.00473403930664, 10.0]}, 128)
batch 872: ({'logprob': [66.16000366210938, 19.0]}, 128)
batch 873: ({'logprob': [41.181060791015625, 9.0]}, 128)
batch 874: ({'logprob': [45.52543258666992, 11.0]}, 128)
batch 875: ({'logprob': [50.944393157958984, 13.0]}, 128)
batch 876: ({'logprob': [63.72428894042969, 18.0]}, 128)
batch 877: ({'logprob': [46.0642204284668, 11.0]}, 128)
batch 878: ({'logprob': [61.800811767578125, 17.0]}, 128)
batch 879: ({'logprob': [73.17520904541016, 21.0]}, 128)
batch 880: ({'logprob': [50.95258331298828, 13.0]}, 128)
batch 881: ({'logprob': [29.781858444213867, 5.0]}, 128)
batch 882: ({'logprob': [54.9994010925293, 14.0]}, 128)
batch 883: ({'logprob': [61.7952766418457, 17.0]}, 128)
batch 884: ({'logprob': [51.47248840332031, 13.0]}, 128)
batch 885: ({'logprob': [52.54539108276367, 13.0]}, 128)
batch 886: ({'logprob': [62.32986068725586, 17.0]}, 128)

======================Test output======================
logprob:  0.417215, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.976026e-03 [2.711666e-09] 
Layer 'conv1' biases: 3.228267e-08 [6.210694e-11] 
Layer 'conv2' weights[0]: 7.963011e-03 [2.961541e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.711151e-10] 
Layer 'conv3' weights[0]: 7.961323e-03 [2.752051e-09] 
Layer 'conv3' biases: 3.322613e-07 [1.505260e-09] 
Layer 'conv4' weights[0]: 7.993874e-03 [3.101757e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.470362e-08] 
Layer 'conv5' weights[0]: 7.992826e-03 [1.006129e-07] 
Layer 'conv5' biases: 1.000000e+00 [1.093993e-07] 
Layer 'fc6' weights[0]: 7.589607e-03 [9.077828e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.107882e-09] 
Layer 'fc7' weights[0]: 7.674595e-03 [1.670268e-07] 
Layer 'fc7' biases: 9.998704e-01 [1.539454e-07] 
Layer 'fc8' weights[0]: 1.263799e-03 [6.267717e-06] 
Layer 'fc8' biases: 1.017649e-02 [4.474732e-05] 
Train error last 870 batches: 0.435337
-------------------------------------------------------
Not saving because 0.417215 > 0.415712 (4.190: -0.00%)
======================================================= (12.031 sec)
6.301... logprob:  0.398031, 0.101562 (1.428 sec)
6.302... logprob:  0.591274, 0.179688 (1.417 sec)
6.303... logprob:  0.459757, 0.125000 (1.411 sec)
6.304... logprob:  0.459781, 0.125000 (1.441 sec)
6.305... logprob:  0.455209, 0.125000 (1.436 sec)
6.306... logprob:  0.440695, 0.117188 (1.441 sec)
6.307... logprob:  0.421693, 0.109375 (1.439 sec)
6.308... logprob:  0.374444, 0.093750 (1.460 sec)
6.309... logprob:  0.450386, 0.125000 (1.415 sec)
6.310... logprob:  0.474074, 0.125000 (1.423 sec)
6.311... logprob:  0.502797, 0.140625 (1.428 sec)
6.312... logprob:  0.478875, 0.132812 (1.426 sec)
6.313... logprob:  0.454863, 0.125000 (1.425 sec)
6.314... logprob:  0.454782, 0.117188 (1.464 sec)
6.315... logprob:  0.314637, 0.070312 (1.436 sec)
6.316... logprob:  0.468675, 0.125000 (1.424 sec)
6.317... logprob:  0.355526, 0.085938 (1.505 sec)
6.318... logprob:  0.455472, 0.125000 (1.415 sec)
6.319... logprob:  0.423356, 0.117188 (1.424 sec)
6.320... logprob:  0.412318, 0.109375 (1.428 sec)
6.321... logprob:  0.348332, 0.085938 (1.424 sec)
6.322... logprob:  0.387661, 0.101562 (1.424 sec)
6.323... logprob:  0.416551, 0.109375 (1.476 sec)
6.324... logprob:  0.498706, 0.140625 (1.429 sec)
6.325... logprob:  0.350713, 0.085938 (1.434 sec)
6.326... logprob:  0.543057, 0.148438 (1.467 sec)
6.327... logprob:  0.554392, 0.164062 (1.423 sec)
6.328... logprob:  0.564860, 0.156250 (1.432 sec)
6.329... logprob:  0.402086, 0.101562 (1.431 sec)
6.330... logprob:  0.388783, 0.101562 (1.418 sec)
6.331... logprob:  0.352695, 0.085938 (1.432 sec)
6.332... logprob:  0.482831, 0.132812 (1.451 sec)
6.333... logprob:  0.339662, 0.085938 (1.441 sec)
6.334... logprob:  0.564963, 0.171875 (1.442 sec)
6.335... logprob:  0.359008, 0.085938 (1.445 sec)
6.336... logprob:  0.444724, 0.125000 (1.454 sec)
6.337... logprob:  0.566589, 0.164062 (1.429 sec)
6.338... logprob:  0.449448, 0.125000 (1.419 sec)
6.339... logprob:  0.488925, 0.132812 (1.425 sec)
6.340... logprob:  0.442175, 0.117188 (1.425 sec)
6.341... logprob:  0.530382, 0.148438 (1.423 sec)
6.342... logprob:  0.429904, 0.109375 (1.464 sec)
6.343... logprob:  0.434979, 0.109375 (1.434 sec)
6.344... logprob:  0.444270, 0.125000 (1.481 sec)
6.345... logprob:  0.488387, 0.132812 (1.443 sec)
6.346... logprob:  0.436272, 0.117188 (1.437 sec)
6.347... logprob:  0.372152, 0.085938 (1.488 sec)
6.348... logprob:  0.398384, 0.101562 (1.434 sec)
6.349... logprob:  0.498171, 0.140625 (1.433 sec)
6.350... logprob:  0.358330, 0.085938 (1.431 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.4935302734375, 10.0]}, 128)
batch 872: ({'logprob': [66.543212890625, 19.0]}, 128)
batch 873: ({'logprob': [40.65534591674805, 9.0]}, 128)
batch 874: ({'logprob': [45.15199661254883, 11.0]}, 128)
batch 875: ({'logprob': [50.77200698852539, 13.0]}, 128)
batch 876: ({'logprob': [64.0193862915039, 18.0]}, 128)
batch 877: ({'logprob': [45.71474075317383, 11.0]}, 128)
batch 878: ({'logprob': [62.031734466552734, 17.0]}, 128)
batch 879: ({'logprob': [73.83348083496094, 21.0]}, 128)
batch 880: ({'logprob': [50.78041458129883, 13.0]}, 128)
batch 881: ({'logprob': [28.82820701599121, 5.0]}, 128)
batch 882: ({'logprob': [54.990234375, 14.0]}, 128)
batch 883: ({'logprob': [62.0261116027832, 17.0]}, 128)
batch 884: ({'logprob': [51.32548141479492, 13.0]}, 128)
batch 885: ({'logprob': [52.44822692871094, 13.0]}, 128)
batch 886: ({'logprob': [62.58591842651367, 17.0]}, 128)

======================Test output======================
logprob:  0.416602, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.975988e-03 [2.432591e-09] 
Layer 'conv1' biases: 3.279247e-08 [3.800440e-11] 
Layer 'conv2' weights[0]: 7.962968e-03 [1.824747e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.589121e-10] 
Layer 'conv3' weights[0]: 7.961281e-03 [1.709819e-09] 
Layer 'conv3' biases: 3.361127e-07 [8.193233e-10] 
Layer 'conv4' weights[0]: 7.993833e-03 [1.820182e-09] 
Layer 'conv4' biases: 9.999999e-01 [7.461221e-09] 
Layer 'conv5' weights[0]: 7.992787e-03 [5.069969e-08] 
Layer 'conv5' biases: 1.000000e+00 [5.514825e-08] 
Layer 'fc6' weights[0]: 7.589556e-03 [4.664514e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.614209e-09] 
Layer 'fc7' weights[0]: 7.672591e-03 [1.657987e-07] 
Layer 'fc7' biases: 9.998711e-01 [1.526861e-07] 
Layer 'fc8' weights[0]: 1.283896e-03 [1.076002e-05] 
Layer 'fc8' biases: 1.041381e-02 [6.566340e-05] 
Train error last 870 batches: 0.435336
-------------------------------------------------------
Not saving because 0.416602 > 0.415712 (4.190: -0.00%)
======================================================= (12.061 sec)
6.351... logprob:  0.508782, 0.140625 (1.431 sec)
6.352... logprob:  0.363903, 0.093750 (1.436 sec)
6.353... logprob:  0.513408, 0.148438 (1.484 sec)
6.354... logprob:  0.675550, 0.203125 (1.427 sec)
6.355... logprob:  0.357353, 0.085938 (1.442 sec)
6.356... logprob:  0.479320, 0.132812 (1.476 sec)
6.357... logprob:  0.347410, 0.085938 (1.435 sec)
6.358... logprob:  0.326048, 0.070312 (1.437 sec)
6.359... logprob:  0.555246, 0.164062 (1.432 sec)
6.360... logprob:  0.444443, 0.117188 (1.425 sec)
6.361... logprob:  0.410643, 0.101562 (1.438 sec)
6.362... logprob:  0.424504, 0.117188 (1.473 sec)
6.363... logprob:  0.486505, 0.132812 (1.440 sec)
6.364... logprob:  0.475287, 0.125000 (1.456 sec)
6.365... logprob:  0.425050, 0.109375 (1.464 sec)
6.366... logprob:  0.409949, 0.109375 (1.438 sec)
6.367... logprob:  0.325269, 0.078125 (1.444 sec)
6.368... logprob:  0.595635, 0.171875 (1.428 sec)
6.369... logprob:  0.381356, 0.093750 (1.431 sec)
6.370... logprob:  0.380982, 0.093750 (1.439 sec)
6.371... logprob:  0.400239, 0.101562 (1.458 sec)
6.372... logprob:  0.538094, 0.156250 (1.458 sec)
6.373... logprob:  0.463832, 0.125000 (1.450 sec)
6.374... logprob:  0.527283, 0.148438 (1.445 sec)
6.375... logprob:  0.393867, 0.101562 (1.461 sec)
6.376... logprob:  0.374375, 0.093750 (1.439 sec)
6.377... logprob:  0.295258, 0.062500 (1.426 sec)
6.378... logprob:  0.453972, 0.125000 (1.432 sec)
6.379... logprob:  0.420215, 0.109375 (1.433 sec)
6.380... logprob:  0.605870, 0.179688 (1.441 sec)
6.381... logprob:  0.463529, 0.125000 (1.474 sec)
6.382... logprob:  0.529408, 0.148438 (1.447 sec)
6.383... logprob:  0.358836, 0.085938 (1.435 sec)
6.384... logprob:  0.520929, 0.148438 (1.477 sec)
6.385... logprob:  0.523405, 0.148438 (1.432 sec)
6.386... logprob:  0.582209, 0.171875 (1.421 sec)
6.387... logprob:  0.428732, 0.117188 (1.435 sec)
6.388... logprob:  0.521307, 0.148438 (1.438 sec)
6.389... logprob:  0.426150, 0.109375 (1.433 sec)
6.390... logprob:  0.420017, 0.109375 (1.476 sec)
6.391... logprob:  0.318306, 0.070312 (1.457 sec)
6.392... logprob:  0.439377, 0.117188 (1.433 sec)
6.393... logprob:  0.368569, 0.093750 (1.486 sec)
6.394... logprob:  0.343570, 0.078125 (1.429 sec)
6.395... logprob:  0.331449, 0.078125 (1.433 sec)
6.396... logprob:  0.251749, 0.046875 (1.433 sec)
6.397... logprob:  0.485009, 0.132812 (1.429 sec)
6.398... logprob:  0.471883, 0.125000 (1.432 sec)
6.399... logprob:  0.433858, 0.117188 (1.490 sec)
6.400... logprob:  0.539080, 0.148438 (1.434 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.632286071777344, 10.0]}, 128)
batch 872: ({'logprob': [68.89982604980469, 19.0]}, 128)
batch 873: ({'logprob': [39.65557098388672, 9.0]}, 128)
batch 874: ({'logprob': [44.74735641479492, 11.0]}, 128)
batch 875: ({'logprob': [51.08811950683594, 13.0]}, 128)
batch 876: ({'logprob': [66.04782104492188, 18.0]}, 128)
batch 877: ({'logprob': [45.37158966064453, 11.0]}, 128)
batch 878: ({'logprob': [63.792911529541016, 17.0]}, 128)
batch 879: ({'logprob': [77.10192108154297, 21.0]}, 128)
batch 880: ({'logprob': [51.097015380859375, 13.0]}, 128)
batch 881: ({'logprob': [26.31955337524414, 5.0]}, 128)
batch 882: ({'logprob': [55.82898712158203, 14.0]}, 128)
batch 883: ({'logprob': [63.787418365478516, 17.0]}, 128)
batch 884: ({'logprob': [51.70740509033203, 13.0]}, 128)
batch 885: ({'logprob': [52.95893478393555, 13.0]}, 128)
batch 886: ({'logprob': [64.41228485107422, 17.0]}, 128)

======================Test output======================
logprob:  0.421606, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.975950e-03 [4.194712e-09] 
Layer 'conv1' biases: 3.335845e-08 [1.290135e-10] 
Layer 'conv2' weights[0]: 7.962917e-03 [4.170203e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.562241e-10] 
Layer 'conv3' weights[0]: 7.961242e-03 [4.076191e-09] 
Layer 'conv3' biases: 3.398673e-07 [2.711361e-09] 
Layer 'conv4' weights[0]: 7.993791e-03 [4.745366e-09] 
Layer 'conv4' biases: 9.999999e-01 [2.763522e-08] 
Layer 'conv5' weights[0]: 7.992755e-03 [1.891589e-07] 
Layer 'conv5' biases: 9.999999e-01 [2.056469e-07] 
Layer 'fc6' weights[0]: 7.589511e-03 [1.725170e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.742816e-08] 
Layer 'fc7' weights[0]: 7.670612e-03 [4.608787e-08] 
Layer 'fc7' biases: 9.998728e-01 [2.099722e-08] 
Layer 'fc8' weights[0]: 1.351123e-03 [5.834015e-06] 
Layer 'fc8' biases: 1.093669e-02 [2.882058e-05] 
Train error last 870 batches: 0.435335
-------------------------------------------------------
Not saving because 0.421606 > 0.415712 (4.190: -0.00%)
======================================================= (12.058 sec)
6.401... logprob:  0.466410, 0.125000 (1.454 sec)
6.402... logprob:  0.474611, 0.125000 (1.482 sec)
6.403... logprob:  0.462274, 0.125000 (1.431 sec)
6.404... logprob:  0.475047, 0.125000 (1.444 sec)
6.405... logprob:  0.543519, 0.156250 (1.442 sec)
6.406... logprob:  0.358272, 0.085938 (1.424 sec)
6.407... logprob:  0.492381, 0.140625 (1.435 sec)
6.408... logprob:  0.340359, 0.078125 (1.485 sec)
6.409... logprob:  0.401445, 0.101562 (1.439 sec)
6.410... logprob:  0.581622, 0.171875 (1.444 sec)
6.411... logprob:  0.398569, 0.101562 (1.481 sec)
6.412... logprob:  0.540279, 0.156250 (1.430 sec)
6.413... logprob:  0.544997, 0.156250 (1.435 sec)
6.414... logprob:  0.466892, 0.125000 (1.436 sec)
6.415... logprob:  0.401756, 0.101562 (1.424 sec)
6.416... logprob:  0.427618, 0.109375 (1.442 sec)
6.417... logprob:  0.405445, 0.093750 (1.462 sec)
6.418... logprob:  0.379772, 0.093750 (1.445 sec)
6.419... logprob:  0.417177, 0.101562 (1.458 sec)
6.420... logprob:  0.355452, 0.085938 (1.452 sec)
6.421... logprob:  0.376967, 0.101562 (1.454 sec)
6.422... logprob:  0.524075, 0.148438 (1.438 sec)
6.423... logprob:  0.421164, 0.109375 (1.429 sec)
6.424... logprob:  0.324551, 0.078125 (1.456 sec)
6.425... logprob:  0.305794, 0.070312 (1.439 sec)
6.426... logprob:  0.449508, 0.117188 (1.442 sec)
6.427... logprob:  0.556124, 0.156250 (1.464 sec)
6.428... logprob:  0.603187, 0.171875 (1.455 sec)
6.429... logprob:  0.425937, 0.109375 (1.443 sec)
6.430... logprob:  0.300373, 0.070312 (1.480 sec)
6.431... logprob:  0.598485, 0.171875 (1.434 sec)
6.432... logprob:  0.387369, 0.093750 (1.429 sec)
6.433... logprob:  0.330916, 0.078125 (1.437 sec)
6.434... logprob:  0.528569, 0.148438 (1.436 sec)
6.435... logprob:  0.531940, 0.156250 (1.435 sec)
6.436... logprob:  0.382091, 0.093750 (1.477 sec)
6.437... logprob:  0.500178, 0.140625 (1.447 sec)
6.438... logprob:  0.546564, 0.156250 (1.436 sec)
6.439... logprob:  0.379717, 0.093750 (1.486 sec)
6.440... logprob:  0.440067, 0.117188 (1.427 sec)
6.441... logprob:  0.468058, 0.125000 (1.425 sec)
6.442... logprob:  0.378891, 0.093750 (1.436 sec)
6.443... logprob:  0.496642, 0.140625 (1.437 sec)
6.444... logprob:  0.371887, 0.093750 (1.436 sec)
6.445... logprob:  0.361776, 0.085938 (1.479 sec)
6.446... logprob:  0.397878, 0.101562 (1.431 sec)
6.447... logprob:  0.571058, 0.164062 (1.434 sec)
6.448... logprob:  0.332139, 0.078125 (1.486 sec)
6.449... logprob:  0.400036, 0.101562 (1.433 sec)
6.450... logprob:  0.238163, 0.046875 (1.436 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.016639709472656, 10.0]}, 128)
batch 872: ({'logprob': [67.79418182373047, 19.0]}, 128)
batch 873: ({'logprob': [39.75279998779297, 9.0]}, 128)
batch 874: ({'logprob': [44.76169204711914, 11.0]}, 128)
batch 875: ({'logprob': [50.75708770751953, 13.0]}, 128)
batch 876: ({'logprob': [65.0491714477539, 18.0]}, 128)
batch 877: ({'logprob': [45.25543212890625, 11.0]}, 128)
batch 878: ({'logprob': [62.77031326293945, 17.0]}, 128)
batch 879: ({'logprob': [75.25704193115234, 21.0]}, 128)
batch 880: ({'logprob': [50.766109466552734, 13.0]}, 128)
batch 881: ({'logprob': [27.23984718322754, 5.0]}, 128)
batch 882: ({'logprob': [54.995723724365234, 14.0]}, 128)
batch 883: ({'logprob': [62.764739990234375, 17.0]}, 128)
batch 884: ({'logprob': [51.24418258666992, 13.0]}, 128)
batch 885: ({'logprob': [52.232208251953125, 13.0]}, 128)
batch 886: ({'logprob': [63.25760269165039, 17.0]}, 128)

======================Test output======================
logprob:  0.417439, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.975916e-03 [3.222760e-09] 
Layer 'conv1' biases: 3.389514e-08 [8.550277e-11] 
Layer 'conv2' weights[0]: 7.962874e-03 [3.172399e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.457677e-10] 
Layer 'conv3' weights[0]: 7.961204e-03 [2.971221e-09] 
Layer 'conv3' biases: 3.440141e-07 [1.745924e-09] 
Layer 'conv4' weights[0]: 7.993752e-03 [3.408819e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.723963e-08] 
Layer 'conv5' weights[0]: 7.992714e-03 [1.185181e-07] 
Layer 'conv5' biases: 9.999999e-01 [1.289824e-07] 
Layer 'fc6' weights[0]: 7.589473e-03 [1.059969e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.079095e-08] 
Layer 'fc7' weights[0]: 7.668689e-03 [3.571291e-07] 
Layer 'fc7' biases: 9.998717e-01 [3.438375e-07] 
Layer 'fc8' weights[0]: 1.321954e-03 [1.439634e-05] 
Layer 'fc8' biases: 1.113750e-02 [8.970171e-05] 
Train error last 870 batches: 0.435333
-------------------------------------------------------
Not saving because 0.417439 > 0.415712 (4.190: -0.00%)
======================================================= (12.154 sec)
6.451... logprob:  0.453506, 0.125000 (1.443 sec)
6.452... logprob:  0.456614, 0.117188 (1.429 sec)
6.453... logprob:  0.455884, 0.125000 (1.433 sec)
6.454... logprob:  0.489538, 0.132812 (1.479 sec)
6.455... logprob:  0.506160, 0.140625 (1.436 sec)
6.456... logprob:  0.468773, 0.125000 (1.452 sec)
6.457... logprob:  0.375480, 0.093750 (1.492 sec)
6.458... logprob:  0.351478, 0.085938 (1.435 sec)
6.459... logprob:  0.513419, 0.140625 (1.440 sec)
6.460... logprob:  0.275465, 0.054688 (1.436 sec)
6.461... logprob:  0.459883, 0.125000 (1.429 sec)
6.462... logprob:  0.471978, 0.125000 (1.435 sec)
6.463... logprob:  0.421115, 0.109375 (1.469 sec)
6.464... logprob:  0.482640, 0.132812 (1.445 sec)
6.465... logprob:  0.421315, 0.109375 (1.453 sec)
6.466... logprob:  0.318842, 0.070312 (1.464 sec)
6.467... logprob:  0.413883, 0.109375 (1.450 sec)
6.468... logprob:  0.394269, 0.101562 (1.440 sec)
6.469... logprob:  0.334458, 0.078125 (1.433 sec)
6.470... logprob:  0.400003, 0.101562 (1.426 sec)
6.471... logprob:  0.530021, 0.148438 (1.440 sec)
6.472... logprob:  0.410296, 0.109375 (1.457 sec)
6.473... logprob:  0.375223, 0.093750 (1.459 sec)
6.474... logprob:  0.466027, 0.125000 (1.455 sec)
6.475... logprob:  0.504907, 0.140625 (1.450 sec)
6.476... logprob:  0.510704, 0.140625 (1.468 sec)
6.477... logprob:  0.334406, 0.078125 (1.435 sec)
6.478... logprob:  0.464307, 0.125000 (1.425 sec)
6.479... logprob:  0.305950, 0.070312 (1.430 sec)
6.480... logprob:  0.443505, 0.117188 (1.443 sec)
6.481... logprob:  0.547649, 0.156250 (1.438 sec)
6.482... logprob:  0.443227, 0.117188 (1.476 sec)
6.483... logprob:  0.502474, 0.140625 (1.444 sec)
6.484... logprob:  0.485270, 0.132812 (1.434 sec)
6.485... logprob:  0.409324, 0.109375 (1.486 sec)
6.486... logprob:  0.361892, 0.085938 (1.431 sec)
6.487... logprob:  0.522594, 0.148438 (1.433 sec)
6.488... logprob:  0.425059, 0.109375 (1.433 sec)
6.489... logprob:  0.416074, 0.109375 (1.439 sec)
6.490... logprob:  0.440712, 0.117188 (1.437 sec)
6.491... logprob:  0.313786, 0.070312 (1.480 sec)
6.492... logprob:  0.459712, 0.125000 (1.444 sec)
6.493... logprob:  0.522147, 0.148438 (1.436 sec)
6.494... logprob:  0.450412, 0.125000 (1.485 sec)
6.495... logprob:  0.380457, 0.093750 (1.436 sec)
6.496... logprob:  0.550809, 0.156250 (1.436 sec)
6.497... logprob:  0.467226, 0.125000 (1.435 sec)
6.498... logprob:  0.476442, 0.132812 (1.458 sec)
6.499... logprob:  0.456317, 0.125000 (1.433 sec)
6.500... logprob:  0.355032, 0.085938 (1.493 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.0118293762207, 10.0]}, 128)
batch 872: ({'logprob': [66.31179809570312, 19.0]}, 128)
batch 873: ({'logprob': [40.945167541503906, 9.0]}, 128)
batch 874: ({'logprob': [45.44623565673828, 11.0]}, 128)
batch 875: ({'logprob': [50.88961410522461, 13.0]}, 128)
batch 876: ({'logprob': [63.831146240234375, 18.0]}, 128)
batch 877: ({'logprob': [45.91905212402344, 11.0]}, 128)
batch 878: ({'logprob': [61.79608917236328, 17.0]}, 128)
batch 879: ({'logprob': [73.154296875, 21.0]}, 128)
batch 880: ({'logprob': [50.898345947265625, 13.0]}, 128)
batch 881: ({'logprob': [29.5620059967041, 5.0]}, 128)
batch 882: ({'logprob': [54.79283905029297, 14.0]}, 128)
batch 883: ({'logprob': [61.790283203125, 17.0]}, 128)
batch 884: ({'logprob': [51.35226821899414, 13.0]}, 128)
batch 885: ({'logprob': [52.29353713989258, 13.0]}, 128)
batch 886: ({'logprob': [62.25933074951172, 17.0]}, 128)

======================Test output======================
logprob:  0.416628, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.975877e-03 [1.894443e-09] 
Layer 'conv1' biases: 3.456184e-08 [3.361418e-11] 
Layer 'conv2' weights[0]: 7.962836e-03 [1.621888e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.808077e-10] 
Layer 'conv3' weights[0]: 7.961165e-03 [1.469371e-09] 
Layer 'conv3' biases: 3.513251e-07 [6.014836e-10] 
Layer 'conv4' weights[0]: 7.993716e-03 [1.680638e-09] 
Layer 'conv4' biases: 9.999999e-01 [6.087231e-09] 
Layer 'conv5' weights[0]: 7.992664e-03 [4.204202e-08] 
Layer 'conv5' biases: 1.000001e+00 [4.569828e-08] 
Layer 'fc6' weights[0]: 7.589433e-03 [3.820100e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.773708e-09] 
Layer 'fc7' weights[0]: 7.666730e-03 [3.994634e-08] 
Layer 'fc7' biases: 9.998702e-01 [9.252444e-09] 
Layer 'fc8' weights[0]: 1.269769e-03 [2.972018e-06] 
Layer 'fc8' biases: 1.096560e-02 [1.738921e-05] 
Train error last 870 batches: 0.435332
-------------------------------------------------------
Not saving because 0.416628 > 0.415712 (4.190: -0.00%)
======================================================= (12.115 sec)
6.501... logprob:  0.339187, 0.078125 (1.434 sec)
6.502... logprob:  0.459740, 0.125000 (1.448 sec)
6.503... logprob:  0.400780, 0.101562 (1.476 sec)
6.504... logprob:  0.487466, 0.132812 (1.430 sec)
6.505... logprob:  0.570879, 0.164062 (1.446 sec)
6.506... logprob:  0.479684, 0.132812 (1.431 sec)
6.507... logprob:  0.385314, 0.093750 (1.432 sec)
6.508... logprob:  0.374838, 0.093750 (1.431 sec)
6.509... logprob:  0.323439, 0.070312 (1.480 sec)
6.510... logprob:  0.390485, 0.101562 (1.446 sec)
6.511... logprob:  0.410130, 0.109375 (1.455 sec)
6.512... logprob:  0.470800, 0.125000 (1.464 sec)
6.513... logprob:  0.325001, 0.078125 (1.449 sec)
6.514... logprob:  0.406250, 0.101562 (1.436 sec)
6.515... logprob:  0.455816, 0.125000 (1.436 sec)
6.516... logprob:  0.400747, 0.109375 (1.426 sec)
6.517... logprob:  0.628315, 0.179688 (1.440 sec)
6.518... logprob:  0.437817, 0.117188 (1.470 sec)
6.519... logprob:  0.516180, 0.140625 (1.453 sec)
6.520... logprob:  0.409674, 0.109375 (1.458 sec)
6.521... logprob:  0.427659, 0.109375 (1.452 sec)
6.522... logprob:  0.532985, 0.156250 (1.463 sec)
6.523... logprob:  0.332023, 0.078125 (1.442 sec)
6.524... logprob:  0.437318, 0.117188 (1.422 sec)
6.525... logprob:  0.426362, 0.109375 (1.435 sec)
6.526... logprob:  0.352407, 0.078125 (1.442 sec)
6.527... logprob:  0.504535, 0.140625 (1.443 sec)
6.528... logprob:  0.440607, 0.117188 (1.467 sec)
6.529... logprob:  0.353042, 0.085938 (1.455 sec)
6.530... logprob:  0.440257, 0.117188 (1.439 sec)
6.531... logprob:  0.440106, 0.117188 (1.499 sec)
6.532... logprob:  0.467506, 0.125000 (1.432 sec)
6.533... logprob:  0.561117, 0.164062 (1.434 sec)
6.534... logprob:  0.325675, 0.078125 (1.435 sec)
6.535... logprob:  0.551948, 0.156250 (1.433 sec)
6.536... logprob:  0.507556, 0.140625 (1.435 sec)
6.537... logprob:  0.510178, 0.140625 (1.480 sec)
6.538... logprob:  0.486155, 0.132812 (1.450 sec)
6.539... logprob:  0.296215, 0.062500 (1.431 sec)
6.540... logprob:  0.447160, 0.117188 (1.491 sec)
6.541... logprob:  0.389052, 0.101562 (1.431 sec)
6.542... logprob:  0.411454, 0.109375 (1.430 sec)
6.543... logprob:  0.233554, 0.039062 (1.436 sec)
6.544... logprob:  0.317945, 0.070312 (1.434 sec)
6.545... logprob:  0.348890, 0.085938 (1.435 sec)
6.546... logprob:  0.368390, 0.093750 (1.484 sec)
6.547... logprob:  0.440271, 0.117188 (1.440 sec)
6.548... logprob:  0.453598, 0.125000 (1.441 sec)
6.549... logprob:  0.490926, 0.132812 (1.481 sec)
6.550... logprob:  0.367809, 0.093750 (1.433 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.85383605957031, 10.0]}, 128)
batch 872: ({'logprob': [68.43876647949219, 19.0]}, 128)
batch 873: ({'logprob': [39.57194900512695, 9.0]}, 128)
batch 874: ({'logprob': [44.72114181518555, 11.0]}, 128)
batch 875: ({'logprob': [50.89776611328125, 13.0]}, 128)
batch 876: ({'logprob': [65.61378479003906, 18.0]}, 128)
batch 877: ({'logprob': [45.235107421875, 11.0]}, 128)
batch 878: ({'logprob': [63.274845123291016, 17.0]}, 128)
batch 879: ({'logprob': [76.14564514160156, 21.0]}, 128)
batch 880: ({'logprob': [50.907047271728516, 13.0]}, 128)
batch 881: ({'logprob': [26.67449951171875, 5.0]}, 128)
batch 882: ({'logprob': [55.2800178527832, 14.0]}, 128)
batch 883: ({'logprob': [63.26900100708008, 17.0]}, 128)
batch 884: ({'logprob': [51.40634536743164, 13.0]}, 128)
batch 885: ({'logprob': [52.4364013671875, 13.0]}, 128)
batch 886: ({'logprob': [63.78337860107422, 17.0]}, 128)

======================Test output======================
logprob:  0.419194, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.975835e-03 [2.770068e-09] 
Layer 'conv1' biases: 3.501505e-08 [5.869781e-11] 
Layer 'conv2' weights[0]: 7.962793e-03 [2.601594e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.979527e-10] 
Layer 'conv3' weights[0]: 7.961129e-03 [2.262685e-09] 
Layer 'conv3' biases: 3.551470e-07 [1.276725e-09] 
Layer 'conv4' weights[0]: 7.993673e-03 [2.603181e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.212700e-08] 
Layer 'conv5' weights[0]: 7.992627e-03 [8.130363e-08] 
Layer 'conv5' biases: 1.000000e+00 [8.845847e-08] 
Layer 'fc6' weights[0]: 7.589402e-03 [7.430979e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.498646e-09] 
Layer 'fc7' weights[0]: 7.664775e-03 [4.742806e-08] 
Layer 'fc7' biases: 9.998721e-01 [2.255036e-08] 
Layer 'fc8' weights[0]: 1.337880e-03 [8.049166e-06] 
Layer 'fc8' biases: 1.148863e-02 [4.333306e-05] 
Train error last 870 batches: 0.435330
-------------------------------------------------------
Not saving because 0.419194 > 0.415712 (4.190: -0.00%)
======================================================= (12.067 sec)
6.551... logprob:  0.441922, 0.117188 (1.440 sec)
6.552... logprob:  0.471350, 0.125000 (1.438 sec)
6.553... logprob:  0.349435, 0.085938 (1.425 sec)
6.554... logprob:  0.506621, 0.140625 (1.437 sec)
6.555... logprob:  0.421463, 0.109375 (1.480 sec)
6.556... logprob:  0.356163, 0.085938 (1.438 sec)
6.557... logprob:  0.396656, 0.101562 (1.446 sec)
6.558... logprob:  0.382989, 0.101562 (1.474 sec)
6.559... logprob:  0.441056, 0.125000 (1.441 sec)
6.560... logprob:  0.335676, 0.078125 (1.437 sec)
6.561... logprob:  0.411847, 0.109375 (1.437 sec)
6.562... logprob:  0.503193, 0.140625 (1.424 sec)
6.563... logprob:  0.373958, 0.093750 (1.440 sec)
6.564... logprob:  0.468228, 0.132812 (1.492 sec)
6.565... logprob:  0.610754, 0.187500 (1.455 sec)
6.566... logprob:  0.374994, 0.093750 (1.456 sec)
6.567... logprob:  0.423767, 0.109375 (1.455 sec)
6.568... logprob:  0.496469, 0.140625 (1.459 sec)
6.569... logprob:  0.508274, 0.140625 (1.437 sec)
6.570... logprob:  0.543478, 0.164062 (1.430 sec)
6.571... logprob:  0.454867, 0.125000 (1.433 sec)
6.572... logprob:  0.501754, 0.140625 (1.435 sec)
6.573... logprob:  0.512691, 0.148438 (1.453 sec)
6.574... logprob:  0.428440, 0.109375 (1.462 sec)
6.575... logprob:  0.343399, 0.078125 (1.453 sec)
6.576... logprob:  0.427597, 0.109375 (1.448 sec)
6.577... logprob:  0.460978, 0.125000 (1.477 sec)
6.578... logprob:  0.336395, 0.078125 (1.440 sec)
6.579... logprob:  0.442130, 0.117188 (1.426 sec)
6.580... logprob:  0.547296, 0.156250 (1.433 sec)
6.581... logprob:  0.531457, 0.156250 (1.443 sec)
6.582... logprob:  0.438113, 0.125000 (1.432 sec)
6.583... logprob:  0.593293, 0.171875 (1.477 sec)
6.584... logprob:  0.468254, 0.132812 (1.450 sec)
6.585... logprob:  0.349787, 0.085938 (1.430 sec)
6.586... logprob:  0.313238, 0.070312 (1.485 sec)
6.587... logprob:  0.404282, 0.101562 (1.436 sec)
6.588... logprob:  0.418817, 0.117188 (1.431 sec)
6.589... logprob:  0.361574, 0.093750 (1.438 sec)
6.590... logprob:  0.524559, 0.148438 (1.515 sec)
6.591... logprob:  0.397561, 0.101562 (1.435 sec)
6.592... logprob:  0.455605, 0.125000 (1.487 sec)
6.593... logprob:  0.467385, 0.125000 (1.439 sec)
6.594... logprob:  0.352931, 0.085938 (1.438 sec)
6.595... logprob:  0.428593, 0.109375 (1.486 sec)
6.596... logprob:  0.461518, 0.125000 (1.431 sec)
6.597... logprob:  0.397366, 0.101562 (1.438 sec)
6.598... logprob:  0.397203, 0.101562 (1.435 sec)
6.599... logprob:  0.313328, 0.070312 (1.431 sec)
6.600... logprob:  0.340988, 0.085938 (1.439 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.997215270996094, 10.0]}, 128)
batch 872: ({'logprob': [66.91895294189453, 19.0]}, 128)
batch 873: ({'logprob': [40.48512649536133, 9.0]}, 128)
batch 874: ({'logprob': [44.943687438964844, 11.0]}, 128)
batch 875: ({'logprob': [50.770896911621094, 13.0]}, 128)
batch 876: ({'logprob': [64.35321807861328, 18.0]}, 128)
batch 877: ({'logprob': [45.62861251831055, 11.0]}, 128)
batch 878: ({'logprob': [62.44573974609375, 17.0]}, 128)
batch 879: ({'logprob': [74.7844009399414, 21.0]}, 128)
batch 880: ({'logprob': [50.77925109863281, 13.0]}, 128)
batch 881: ({'logprob': [28.120250701904297, 5.0]}, 128)
batch 882: ({'logprob': [55.400360107421875, 14.0]}, 128)
batch 883: ({'logprob': [62.439884185791016, 17.0]}, 128)
batch 884: ({'logprob': [51.44780349731445, 13.0]}, 128)
batch 885: ({'logprob': [52.81648635864258, 13.0]}, 128)
batch 886: ({'logprob': [63.123016357421875, 17.0]}, 128)

======================Test output======================
logprob:  0.417703, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.975794e-03 [2.242710e-09] 
Layer 'conv1' biases: 3.566360e-08 [6.113570e-11] 
Layer 'conv2' weights[0]: 7.962753e-03 [1.998094e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.803310e-10] 
Layer 'conv3' weights[0]: 7.961094e-03 [2.070140e-09] 
Layer 'conv3' biases: 3.605254e-07 [1.224731e-09] 
Layer 'conv4' weights[0]: 7.993636e-03 [2.370150e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.243219e-08] 
Layer 'conv5' weights[0]: 7.992593e-03 [8.554113e-08] 
Layer 'conv5' biases: 1.000000e+00 [9.309966e-08] 
Layer 'fc6' weights[0]: 7.589365e-03 [7.704632e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.767142e-09] 
Layer 'fc7' weights[0]: 7.662825e-03 [1.615194e-07] 
Layer 'fc7' biases: 9.998714e-01 [1.484500e-07] 
Layer 'fc8' weights[0]: 1.304853e-03 [7.565416e-06] 
Layer 'fc8' biases: 1.140433e-02 [4.512042e-05] 
Train error last 870 batches: 0.435330
-------------------------------------------------------
Not saving because 0.417703 > 0.415712 (4.190: -0.00%)
======================================================= (12.048 sec)
6.601... logprob:  0.401985, 0.101562 (1.497 sec)
6.602... logprob:  0.289338, 0.062500 (1.438 sec)
6.603... logprob:  0.266499, 0.054688 (1.442 sec)
6.604... logprob:  0.407290, 0.101562 (1.477 sec)
6.605... logprob:  0.563428, 0.148438 (1.439 sec)
6.606... logprob:  0.296094, 0.070312 (1.438 sec)
6.607... logprob:  0.504910, 0.132812 (1.439 sec)
6.608... logprob:  0.361145, 0.085938 (1.426 sec)
6.609... logprob:  0.356583, 0.085938 (1.436 sec)
6.610... logprob:  0.493644, 0.132812 (1.476 sec)
6.611... logprob:  0.510861, 0.140625 (1.443 sec)
6.612... logprob:  0.448053, 0.117188 (1.459 sec)
6.613... logprob:  0.280478, 0.062500 (1.459 sec)
6.614... logprob:  0.503824, 0.140625 (1.455 sec)
6.615... logprob:  0.351701, 0.085938 (1.436 sec)
6.616... logprob:  0.415913, 0.109375 (1.434 sec)
6.617... logprob:  0.418238, 0.109375 (1.424 sec)
6.618... logprob:  0.546385, 0.156250 (1.443 sec)
6.619... logprob:  0.505692, 0.140625 (1.452 sec)
6.620... logprob:  0.539721, 0.156250 (1.456 sec)
6.621... logprob:  0.364249, 0.085938 (1.451 sec)
6.622... logprob:  0.365224, 0.085938 (1.455 sec)
6.623... logprob:  0.423346, 0.109375 (1.468 sec)
6.624... logprob:  0.382669, 0.093750 (1.436 sec)
6.625... logprob:  0.441088, 0.117188 (1.424 sec)
6.626... logprob:  0.438525, 0.117188 (1.428 sec)
6.627... logprob:  0.435997, 0.117188 (1.443 sec)
6.628... logprob:  0.465128, 0.125000 (1.438 sec)
6.629... logprob:  0.371945, 0.093750 (1.478 sec)
6.630... logprob:  0.422370, 0.109375 (1.445 sec)
6.631... logprob:  0.640001, 0.187500 (1.443 sec)
6.632... logprob:  0.399109, 0.101562 (1.479 sec)
6.633... logprob:  0.375960, 0.093750 (1.438 sec)
6.634... logprob:  0.660809, 0.195312 (1.430 sec)
6.635... logprob:  0.374100, 0.093750 (1.447 sec)
6.636... logprob:  0.480181, 0.132812 (1.434 sec)
6.637... logprob:  0.330974, 0.078125 (1.436 sec)
6.638... logprob:  0.515943, 0.140625 (1.497 sec)
6.639... logprob:  0.418216, 0.109375 (1.445 sec)
6.640... logprob:  0.528952, 0.148438 (1.437 sec)
6.641... logprob:  0.410310, 0.109375 (1.484 sec)
6.642... logprob:  0.500750, 0.140625 (1.434 sec)
6.643... logprob:  0.622570, 0.187500 (1.435 sec)
6.644... logprob:  0.321710, 0.070312 (1.441 sec)
6.645... logprob:  0.414363, 0.109375 (1.430 sec)
6.646... logprob:  0.385985, 0.093750 (1.436 sec)
6.647... logprob:  0.456627, 0.125000 (1.486 sec)
6.648... logprob:  0.490992, 0.140625 (1.436 sec)
6.649... logprob:  0.369800, 0.093750 (1.446 sec)
6.650... logprob:  0.413794, 0.109375 (1.480 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.91472244262695, 10.0]}, 128)
batch 872: ({'logprob': [66.35441589355469, 19.0]}, 128)
batch 873: ({'logprob': [40.873050689697266, 9.0]}, 128)
batch 874: ({'logprob': [45.382965087890625, 11.0]}, 128)
batch 875: ({'logprob': [50.85847091674805, 13.0]}, 128)
batch 876: ({'logprob': [63.863887786865234, 18.0]}, 128)
batch 877: ({'logprob': [45.867431640625, 11.0]}, 128)
batch 878: ({'logprob': [61.829925537109375, 17.0]}, 128)
batch 879: ({'logprob': [73.26432800292969, 21.0]}, 128)
batch 880: ({'logprob': [50.86738204956055, 13.0]}, 128)
batch 881: ({'logprob': [29.413301467895508, 5.0]}, 128)
batch 882: ({'logprob': [54.80741882324219, 14.0]}, 128)
batch 883: ({'logprob': [61.82381820678711, 17.0]}, 128)
batch 884: ({'logprob': [51.3330078125, 13.0]}, 128)
batch 885: ({'logprob': [52.29768753051758, 13.0]}, 128)
batch 886: ({'logprob': [62.30490493774414, 17.0]}, 128)

======================Test output======================
logprob:  0.416532, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.975750e-03 [1.689527e-09] 
Layer 'conv1' biases: 3.626873e-08 [4.094608e-11] 
Layer 'conv2' weights[0]: 7.962712e-03 [1.663479e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.089012e-10] 
Layer 'conv3' weights[0]: 7.961052e-03 [1.717815e-09] 
Layer 'conv3' biases: 3.656761e-07 [9.908216e-10] 
Layer 'conv4' weights[0]: 7.993601e-03 [1.957365e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.016109e-08] 
Layer 'conv5' weights[0]: 7.992552e-03 [7.046838e-08] 
Layer 'conv5' biases: 1.000000e+00 [7.662555e-08] 
Layer 'fc6' weights[0]: 7.589324e-03 [6.211668e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.294344e-09] 
Layer 'fc7' weights[0]: 7.660862e-03 [2.350270e-07] 
Layer 'fc7' biases: 9.998700e-01 [2.217414e-07] 
Layer 'fc8' weights[0]: 1.280030e-03 [1.108674e-05] 
Layer 'fc8' biases: 1.139393e-02 [6.976570e-05] 
Train error last 870 batches: 0.435331
-------------------------------------------------------
Not saving because 0.416532 > 0.415712 (4.190: -0.00%)
======================================================= (12.039 sec)
6.651... logprob:  0.397285, 0.101562 (1.436 sec)
6.652... logprob:  0.507699, 0.140625 (1.443 sec)
6.653... logprob:  0.548423, 0.156250 (1.431 sec)
6.654... logprob:  0.496059, 0.140625 (1.431 sec)
6.655... logprob:  0.436197, 0.117188 (1.432 sec)
6.656... logprob:  0.416651, 0.109375 (1.481 sec)
6.657... logprob:  0.449729, 0.117188 (1.442 sec)
6.658... logprob:  0.345524, 0.085938 (1.456 sec)
6.659... logprob:  0.464536, 0.125000 (1.475 sec)
6.660... logprob:  0.445576, 0.125000 (1.446 sec)
6.661... logprob:  0.378731, 0.093750 (1.436 sec)
6.662... logprob:  0.469112, 0.132812 (1.437 sec)
6.663... logprob:  0.311182, 0.070312 (1.425 sec)
6.664... logprob:  0.285560, 0.062500 (1.439 sec)
6.665... logprob:  0.402126, 0.101562 (1.463 sec)
6.666... logprob:  0.442179, 0.117188 (1.454 sec)
6.667... logprob:  0.564425, 0.164062 (1.459 sec)
6.668... logprob:  0.497998, 0.140625 (1.453 sec)
6.669... logprob:  0.433435, 0.109375 (1.465 sec)
6.670... logprob:  0.362703, 0.085938 (1.445 sec)
6.671... logprob:  0.360770, 0.093750 (1.456 sec)
6.672... logprob:  0.441835, 0.117188 (1.429 sec)
6.673... logprob:  0.436278, 0.117188 (1.436 sec)
6.674... logprob:  0.446755, 0.117188 (1.439 sec)
6.675... logprob:  0.356605, 0.093750 (1.468 sec)
6.676... logprob:  0.450121, 0.125000 (1.453 sec)
6.677... logprob:  0.471131, 0.125000 (1.440 sec)
6.678... logprob:  0.465637, 0.125000 (1.483 sec)
6.679... logprob:  0.454900, 0.125000 (1.434 sec)
6.680... logprob:  0.351791, 0.078125 (1.431 sec)
6.681... logprob:  0.374030, 0.093750 (1.434 sec)
6.682... logprob:  0.340510, 0.078125 (1.438 sec)
6.683... logprob:  0.411701, 0.109375 (1.438 sec)
6.684... logprob:  0.357460, 0.085938 (1.476 sec)
6.685... logprob:  0.285314, 0.054688 (1.444 sec)
6.686... logprob:  0.318062, 0.070312 (1.438 sec)
6.687... logprob:  0.281269, 0.062500 (1.487 sec)
6.688... logprob:  0.323119, 0.078125 (1.435 sec)
6.689... logprob:  0.472090, 0.125000 (1.431 sec)
6.690... logprob:  0.528622, 0.140625 (1.440 sec)
6.691... logprob:  0.518188, 0.140625 (1.429 sec)
6.692... logprob:  0.386427, 0.101562 (1.438 sec)
6.693... logprob:  0.457122, 0.125000 (1.483 sec)
6.694... logprob:  0.330712, 0.078125 (1.440 sec)
6.695... logprob:  0.356661, 0.085938 (1.441 sec)
6.696... logprob:  0.538227, 0.148438 (1.485 sec)
6.697... logprob:  0.465381, 0.125000 (1.434 sec)
6.698... logprob:  0.548097, 0.156250 (1.433 sec)
6.699... logprob:  0.459585, 0.125000 (1.441 sec)
6.700... logprob:  0.434345, 0.117188 (1.428 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.19483184814453, 10.0]}, 128)
batch 872: ({'logprob': [65.93125915527344, 19.0]}, 128)
batch 873: ({'logprob': [42.14164733886719, 9.0]}, 128)
batch 874: ({'logprob': [46.38302993774414, 11.0]}, 128)
batch 875: ({'logprob': [51.47428512573242, 13.0]}, 128)
batch 876: ({'logprob': [63.603546142578125, 18.0]}, 128)
batch 877: ({'logprob': [46.810604095458984, 11.0]}, 128)
batch 878: ({'logprob': [61.675315856933594, 17.0]}, 128)
batch 879: ({'logprob': [72.28178405761719, 21.0]}, 128)
batch 880: ({'logprob': [51.483062744140625, 13.0]}, 128)
batch 881: ({'logprob': [31.51066780090332, 5.0]}, 128)
batch 882: ({'logprob': [55.08330535888672, 14.0]}, 128)
batch 883: ({'logprob': [61.66907501220703, 17.0]}, 128)
batch 884: ({'logprob': [51.889034271240234, 13.0]}, 128)
batch 885: ({'logprob': [52.7359619140625, 13.0]}, 128)
batch 886: ({'logprob': [62.09088134765625, 17.0]}, 128)

======================Test output======================
logprob:  0.419902, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.975713e-03 [2.243199e-09] 
Layer 'conv1' biases: 3.691712e-08 [3.106615e-11] 
Layer 'conv2' weights[0]: 7.962675e-03 [1.532589e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.307560e-10] 
Layer 'conv3' weights[0]: 7.961015e-03 [1.183595e-09] 
Layer 'conv3' biases: 3.737621e-07 [4.236596e-10] 
Layer 'conv4' weights[0]: 7.993569e-03 [1.153673e-09] 
Layer 'conv4' biases: 9.999999e-01 [2.053911e-09] 
Layer 'conv5' weights[0]: 7.992524e-03 [1.168944e-08] 
Layer 'conv5' biases: 1.000001e+00 [1.253018e-08] 
Layer 'fc6' weights[0]: 7.589290e-03 [1.346754e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.100066e-09] 
Layer 'fc7' weights[0]: 7.658937e-03 [3.559938e-07] 
Layer 'fc7' biases: 9.998690e-01 [3.438909e-07] 
Layer 'fc8' weights[0]: 1.249062e-03 [1.415808e-05] 
Layer 'fc8' biases: 1.132215e-02 [8.057322e-05] 
Train error last 870 batches: 0.435330
-------------------------------------------------------
Not saving because 0.419902 > 0.415712 (4.190: -0.00%)
======================================================= (12.078 sec)
6.701... logprob:  0.423717, 0.109375 (1.451 sec)
6.702... logprob:  0.521340, 0.148438 (1.482 sec)
6.703... logprob:  0.406022, 0.101562 (1.439 sec)
6.704... logprob:  0.406675, 0.101562 (1.457 sec)
6.705... logprob:  0.420508, 0.109375 (1.480 sec)
6.706... logprob:  0.468089, 0.125000 (1.434 sec)
6.707... logprob:  0.485302, 0.132812 (1.443 sec)
6.708... logprob:  0.416942, 0.109375 (1.430 sec)
6.709... logprob:  0.422278, 0.109375 (1.428 sec)
6.710... logprob:  0.603385, 0.179688 (1.439 sec)
6.711... logprob:  0.469585, 0.125000 (1.468 sec)
6.712... logprob:  0.339854, 0.078125 (1.450 sec)
6.713... logprob:  0.588240, 0.179688 (1.457 sec)
6.714... logprob:  0.466413, 0.125000 (1.455 sec)
6.715... logprob:  0.417114, 0.109375 (1.462 sec)
6.716... logprob:  0.335071, 0.078125 (1.435 sec)
6.717... logprob:  0.429928, 0.117188 (1.428 sec)
6.718... logprob:  0.490453, 0.132812 (1.431 sec)
6.719... logprob:  0.406213, 0.109375 (1.444 sec)
6.720... logprob:  0.433235, 0.117188 (1.445 sec)
6.721... logprob:  0.451650, 0.117188 (1.465 sec)
6.722... logprob:  0.536628, 0.156250 (1.454 sec)
6.723... logprob:  0.416673, 0.109375 (1.445 sec)
6.724... logprob:  0.412763, 0.109375 (1.478 sec)
6.725... logprob:  0.494436, 0.140625 (1.433 sec)
6.726... logprob:  0.338726, 0.085938 (1.432 sec)
6.727... logprob:  0.393532, 0.101562 (1.430 sec)
6.728... logprob:  0.421608, 0.109375 (1.441 sec)
6.729... logprob:  0.388245, 0.093750 (1.440 sec)
6.730... logprob:  0.565789, 0.164062 (1.475 sec)
6.731... logprob:  0.450127, 0.125000 (1.448 sec)
6.732... logprob:  0.311586, 0.070312 (1.440 sec)
6.733... logprob:  0.557143, 0.156250 (1.491 sec)
6.734... logprob:  0.340332, 0.078125 (1.432 sec)
6.735... logprob:  0.527927, 0.148438 (1.434 sec)
6.736... logprob:  0.643751, 0.187500 (1.439 sec)
6.737... logprob:  0.516314, 0.148438 (1.430 sec)
6.738... logprob:  0.459511, 0.125000 (1.437 sec)
6.739... logprob:  0.477851, 0.132812 (1.486 sec)
6.740... logprob:  0.339549, 0.078125 (1.439 sec)
6.741... logprob:  0.393332, 0.101562 (1.441 sec)
6.742... logprob:  0.419769, 0.109375 (1.482 sec)
6.743... logprob:  0.364852, 0.085938 (1.437 sec)
6.744... logprob:  0.519380, 0.148438 (1.431 sec)
6.745... logprob:  0.478233, 0.132812 (1.468 sec)
6.746... logprob:  0.440582, 0.117188 (1.428 sec)
6.747... logprob:  0.425651, 0.109375 (1.431 sec)
6.748... logprob:  0.377995, 0.093750 (1.483 sec)
6.749... logprob:  0.420863, 0.109375 (1.438 sec)
6.750... logprob:  0.512924, 0.140625 (1.449 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.46576690673828, 10.0]}, 128)
batch 872: ({'logprob': [66.74143981933594, 19.0]}, 128)
batch 873: ({'logprob': [40.422088623046875, 9.0]}, 128)
batch 874: ({'logprob': [45.06800079345703, 11.0]}, 128)
batch 875: ({'logprob': [50.7318000793457, 13.0]}, 128)
batch 876: ({'logprob': [64.17013549804688, 18.0]}, 128)
batch 877: ({'logprob': [45.57820510864258, 11.0]}, 128)
batch 878: ({'logprob': [62.08084487915039, 17.0]}, 128)
batch 879: ({'logprob': [73.9186782836914, 21.0]}, 128)
batch 880: ({'logprob': [50.74076843261719, 13.0]}, 128)
batch 881: ({'logprob': [28.558191299438477, 5.0]}, 128)
batch 882: ({'logprob': [54.841766357421875, 14.0]}, 128)
batch 883: ({'logprob': [62.074737548828125, 17.0]}, 128)
batch 884: ({'logprob': [51.233245849609375, 13.0]}, 128)
batch 885: ({'logprob': [52.251182556152344, 13.0]}, 128)
batch 886: ({'logprob': [62.582611083984375, 17.0]}, 128)

======================Test output======================
logprob:  0.416240, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.975670e-03 [2.406010e-09] 
Layer 'conv1' biases: 3.737450e-08 [5.729585e-11] 
Layer 'conv2' weights[0]: 7.962640e-03 [1.810203e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.026443e-10] 
Layer 'conv3' weights[0]: 7.960973e-03 [1.633805e-09] 
Layer 'conv3' biases: 3.755745e-07 [9.057567e-10] 
Layer 'conv4' weights[0]: 7.993526e-03 [1.812434e-09] 
Layer 'conv4' biases: 9.999999e-01 [8.119230e-09] 
Layer 'conv5' weights[0]: 7.992471e-03 [5.598267e-08] 
Layer 'conv5' biases: 1.000000e+00 [6.080661e-08] 
Layer 'fc6' weights[0]: 7.589237e-03 [5.024977e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.024225e-09] 
Layer 'fc7' weights[0]: 7.656971e-03 [6.770116e-08] 
Layer 'fc7' biases: 9.998703e-01 [4.835143e-08] 
Layer 'fc8' weights[0]: 1.301931e-03 [7.192220e-06] 
Layer 'fc8' biases: 1.182102e-02 [4.471998e-05] 
Train error last 870 batches: 0.435329
-------------------------------------------------------
Not saving because 0.416240 > 0.415712 (4.190: -0.00%)
======================================================= (12.054 sec)
6.751... logprob:  0.263481, 0.054688 (1.489 sec)
6.752... logprob:  0.522226, 0.140625 (1.445 sec)
6.753... logprob:  0.441336, 0.117188 (1.434 sec)
6.754... logprob:  0.469185, 0.132812 (1.434 sec)
6.755... logprob:  0.507198, 0.140625 (1.432 sec)
6.756... logprob:  0.440825, 0.117188 (1.434 sec)
6.757... logprob:  0.552094, 0.156250 (1.476 sec)
6.758... logprob:  0.393918, 0.101562 (1.448 sec)
6.759... logprob:  0.459728, 0.125000 (1.450 sec)
6.760... logprob:  0.485228, 0.132812 (1.462 sec)
6.761... logprob:  0.418637, 0.109375 (1.448 sec)
6.762... logprob:  0.516032, 0.148438 (1.437 sec)
6.763... logprob:  0.558682, 0.164062 (1.434 sec)
6.764... logprob:  0.503282, 0.140625 (1.425 sec)
6.765... logprob:  0.312641, 0.062500 (1.441 sec)
6.766... logprob:  0.482359, 0.132812 (1.458 sec)
6.767... logprob:  0.371185, 0.085938 (1.456 sec)
6.768... logprob:  0.432875, 0.117188 (1.470 sec)
6.769... logprob:  0.491101, 0.140625 (1.467 sec)
6.770... logprob:  0.402720, 0.101562 (1.485 sec)
6.771... logprob:  0.549842, 0.156250 (1.461 sec)
6.772... logprob:  0.414057, 0.109375 (1.441 sec)
6.773... logprob:  0.558553, 0.164062 (1.451 sec)
6.774... logprob:  0.361358, 0.085938 (1.468 sec)
6.775... logprob:  0.407302, 0.101562 (1.464 sec)
6.776... logprob:  0.433359, 0.117188 (1.485 sec)
6.777... logprob:  0.379908, 0.093750 (1.475 sec)
6.778... logprob:  0.433700, 0.117188 (1.472 sec)
6.779... logprob:  0.505606, 0.140625 (1.493 sec)
6.780... logprob:  0.385748, 0.101562 (1.453 sec)
6.781... logprob:  0.369883, 0.085938 (1.445 sec)
6.782... logprob:  0.351614, 0.085938 (1.453 sec)
6.783... logprob:  0.555455, 0.156250 (1.464 sec)
6.784... logprob:  0.440995, 0.117188 (1.456 sec)
6.785... logprob:  0.543405, 0.156250 (1.489 sec)
6.786... logprob:  0.477266, 0.132812 (1.473 sec)
6.787... logprob:  0.545971, 0.156250 (1.459 sec)
6.788... logprob:  0.562620, 0.164062 (1.496 sec)
6.789... logprob:  0.282046, 0.054688 (1.456 sec)
6.790... logprob:  0.408704, 0.101562 (1.450 sec)
6.791... logprob:  0.398360, 0.101562 (1.447 sec)
6.792... logprob:  0.361534, 0.085938 (1.462 sec)
6.793... logprob:  0.370550, 0.085938 (1.458 sec)
6.794... logprob:  0.387176, 0.093750 (1.489 sec)
6.795... logprob:  0.469958, 0.125000 (1.468 sec)
6.796... logprob:  0.423511, 0.109375 (1.465 sec)
6.797... logprob:  0.358559, 0.085938 (1.502 sec)
6.798... logprob:  0.393289, 0.101562 (1.458 sec)
6.799... logprob:  0.331904, 0.078125 (1.453 sec)
6.800... logprob:  0.371958, 0.093750 (1.451 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.224056243896484, 10.0]}, 128)
batch 872: ({'logprob': [68.52716064453125, 19.0]}, 128)
batch 873: ({'logprob': [39.36431884765625, 9.0]}, 128)
batch 874: ({'logprob': [44.7850227355957, 11.0]}, 128)
batch 875: ({'logprob': [50.87870407104492, 13.0]}, 128)
batch 876: ({'logprob': [65.65568542480469, 18.0]}, 128)
batch 877: ({'logprob': [45.122257232666016, 11.0]}, 128)
batch 878: ({'logprob': [63.09183120727539, 17.0]}, 128)
batch 879: ({'logprob': [75.62157440185547, 21.0]}, 128)
batch 880: ({'logprob': [50.88886260986328, 13.0]}, 128)
batch 881: ({'logprob': [26.807790756225586, 5.0]}, 128)
batch 882: ({'logprob': [54.778106689453125, 14.0]}, 128)
batch 883: ({'logprob': [63.08558654785156, 17.0]}, 128)
batch 884: ({'logprob': [51.210697174072266, 13.0]}, 128)
batch 885: ({'logprob': [51.886817932128906, 13.0]}, 128)
batch 886: ({'logprob': [63.42340850830078, 17.0]}, 128)

======================Test output======================
logprob:  0.418141, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.975635e-03 [2.097201e-09] 
Layer 'conv1' biases: 3.795317e-08 [4.605679e-11] 
Layer 'conv2' weights[0]: 7.962601e-03 [1.418381e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.646243e-10] 
Layer 'conv3' weights[0]: 7.960936e-03 [1.171944e-09] 
Layer 'conv3' biases: 3.796693e-07 [4.070511e-10] 
Layer 'conv4' weights[0]: 7.993485e-03 [1.246653e-09] 
Layer 'conv4' biases: 9.999999e-01 [3.702342e-09] 
Layer 'conv5' weights[0]: 7.992431e-03 [2.569540e-08] 
Layer 'conv5' biases: 9.999998e-01 [2.791278e-08] 
Layer 'fc6' weights[0]: 7.589196e-03 [2.453763e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.317527e-09] 
Layer 'fc7' weights[0]: 7.655039e-03 [2.512893e-07] 
Layer 'fc7' biases: 9.998714e-01 [2.386206e-07] 
Layer 'fc8' weights[0]: 1.344026e-03 [1.050218e-05] 
Layer 'fc8' biases: 1.223547e-02 [6.620155e-05] 
Train error last 870 batches: 0.435328
-------------------------------------------------------
Not saving because 0.418141 > 0.415712 (4.190: -0.00%)
======================================================= (12.040 sec)
6.801... logprob:  0.450559, 0.117188 (1.467 sec)
6.802... logprob:  0.423382, 0.109375 (1.461 sec)
6.803... logprob:  0.492572, 0.132812 (1.493 sec)
6.804... logprob:  0.350084, 0.085938 (1.464 sec)
6.805... logprob:  0.452111, 0.117188 (1.458 sec)
6.806... logprob:  0.424138, 0.109375 (1.503 sec)
6.807... logprob:  0.443488, 0.117188 (1.456 sec)
6.808... logprob:  0.462511, 0.125000 (1.452 sec)
6.809... logprob:  0.589589, 0.171875 (1.447 sec)
6.810... logprob:  0.442402, 0.117188 (1.484 sec)
6.811... logprob:  0.460503, 0.125000 (1.455 sec)
6.812... logprob:  0.462537, 0.125000 (1.501 sec)
6.813... logprob:  0.485991, 0.132812 (1.469 sec)
6.814... logprob:  0.478425, 0.132812 (1.452 sec)
6.815... logprob:  0.373015, 0.085938 (1.505 sec)
6.816... logprob:  0.409392, 0.101562 (1.455 sec)
6.817... logprob:  0.426428, 0.109375 (1.453 sec)
6.818... logprob:  0.559939, 0.164062 (1.453 sec)
6.819... logprob:  0.498271, 0.140625 (1.455 sec)
6.820... logprob:  0.421491, 0.109375 (1.453 sec)
6.821... logprob:  0.406266, 0.101562 (1.501 sec)
6.822... logprob:  0.440981, 0.117188 (1.144 sec)
6.823... logprob:  0.340013, 0.078125 (1.162 sec)
6.824... logprob:  0.490330, 0.132812 (0.717 sec)
6.825... logprob:  0.286907, 0.062500 (0.689 sec)
6.826... logprob:  0.375210, 0.093750 (0.686 sec)
6.827... logprob:  0.420796, 0.109375 (0.691 sec)
6.828... logprob:  0.443988, 0.117188 (0.692 sec)
6.829... logprob:  0.505375, 0.140625 (0.692 sec)
6.830... logprob:  0.442595, 0.117188 (1.515 sec)
6.831... logprob:  0.514339, 0.140625 (1.456 sec)
6.832... logprob:  0.330914, 0.078125 (1.465 sec)
6.833... logprob:  0.488890, 0.132812 (1.492 sec)
6.834... logprob:  0.432960, 0.117188 (1.455 sec)
6.835... logprob:  0.542308, 0.148438 (1.458 sec)
6.836... logprob:  0.376581, 0.093750 (1.460 sec)
6.837... logprob:  0.315453, 0.070312 (1.456 sec)
6.838... logprob:  0.437095, 0.117188 (1.453 sec)
6.839... logprob:  0.472030, 0.125000 (1.501 sec)
6.840... logprob:  0.555251, 0.156250 (1.456 sec)
6.841... logprob:  0.396466, 0.101562 (1.467 sec)
6.842... logprob:  0.497730, 0.140625 (1.495 sec)
6.843... logprob:  0.465622, 0.125000 (1.454 sec)
6.844... logprob:  0.497556, 0.140625 (1.458 sec)
6.845... logprob:  0.486969, 0.132812 (1.454 sec)
6.846... logprob:  0.468604, 0.125000 (1.451 sec)
6.847... logprob:  0.362888, 0.085938 (1.454 sec)
6.848... logprob:  0.396813, 0.101562 (1.498 sec)
6.849... logprob:  0.359965, 0.085938 (1.461 sec)
6.850... logprob:  0.479524, 0.132812 (1.466 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.35869598388672, 10.0]}, 128)
batch 872: ({'logprob': [66.5392074584961, 19.0]}, 128)
batch 873: ({'logprob': [40.7784423828125, 9.0]}, 128)
batch 874: ({'logprob': [45.542022705078125, 11.0]}, 128)
batch 875: ({'logprob': [50.94109344482422, 13.0]}, 128)
batch 876: ({'logprob': [64.0048828125, 18.0]}, 128)
batch 877: ({'logprob': [45.861942291259766, 11.0]}, 128)
batch 878: ({'logprob': [61.761173248291016, 17.0]}, 128)
batch 879: ({'logprob': [72.87964630126953, 21.0]}, 128)
batch 880: ({'logprob': [50.95071792602539, 13.0]}, 128)
batch 881: ({'logprob': [29.63481903076172, 5.0]}, 128)
batch 882: ({'logprob': [54.44065856933594, 14.0]}, 128)
batch 883: ({'logprob': [61.754764556884766, 17.0]}, 128)
batch 884: ({'logprob': [51.2510871887207, 13.0]}, 128)
batch 885: ({'logprob': [51.88623809814453, 13.0]}, 128)
batch 886: ({'logprob': [62.07141876220703, 17.0]}, 128)

======================Test output======================
logprob:  0.416336, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.975599e-03 [2.153889e-09] 
Layer 'conv1' biases: 3.857806e-08 [4.990345e-11] 
Layer 'conv2' weights[0]: 7.962565e-03 [1.727750e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.733136e-10] 
Layer 'conv3' weights[0]: 7.960906e-03 [1.697067e-09] 
Layer 'conv3' biases: 3.861487e-07 [9.236073e-10] 
Layer 'conv4' weights[0]: 7.993448e-03 [1.985703e-09] 
Layer 'conv4' biases: 9.999999e-01 [9.525116e-09] 
Layer 'conv5' weights[0]: 7.992393e-03 [6.617309e-08] 
Layer 'conv5' biases: 1.000000e+00 [7.194484e-08] 
Layer 'fc6' weights[0]: 7.589157e-03 [5.789922e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.873900e-09] 
Layer 'fc7' weights[0]: 7.653104e-03 [2.493658e-07] 
Layer 'fc7' biases: 9.998695e-01 [2.366267e-07] 
Layer 'fc8' weights[0]: 1.278425e-03 [9.507564e-06] 
Layer 'fc8' biases: 1.209029e-02 [6.234492e-05] 
Train error last 870 batches: 0.435325
-------------------------------------------------------
Not saving because 0.416336 > 0.415712 (4.190: -0.00%)
======================================================= (12.055 sec)
6.851... logprob:  0.440215, 0.117188 (1.497 sec)
6.852... logprob:  0.546349, 0.156250 (1.465 sec)
6.853... logprob:  0.371678, 0.093750 (1.466 sec)
6.854... logprob:  0.306805, 0.070312 (1.449 sec)
6.855... logprob:  0.485198, 0.132812 (1.450 sec)
6.856... logprob:  0.443994, 0.117188 (1.453 sec)
6.857... logprob:  0.372318, 0.093750 (1.495 sec)
6.858... logprob:  0.396253, 0.101562 (1.466 sec)
6.859... logprob:  0.307968, 0.070312 (1.468 sec)
6.860... logprob:  0.565827, 0.156250 (1.491 sec)
6.861... logprob:  0.417857, 0.109375 (1.459 sec)
6.862... logprob:  0.329046, 0.078125 (1.455 sec)
6.863... logprob:  0.399462, 0.101562 (1.452 sec)
6.864... logprob:  0.451316, 0.117188 (1.449 sec)
6.865... logprob:  0.484272, 0.132812 (1.457 sec)
6.866... logprob:  0.507311, 0.140625 (1.484 sec)
6.867... logprob:  0.502599, 0.140625 (1.472 sec)
6.868... logprob:  0.405568, 0.101562 (1.473 sec)
6.869... logprob:  0.383568, 0.093750 (1.482 sec)
6.870... logprob:  0.551780, 0.156250 (1.398 sec)
7.1... logprob:  0.380374, 0.093750 (1.408 sec)
7.2... logprob:  0.448264, 0.117188 (1.449 sec)
7.3... logprob:  0.398544, 0.101562 (1.413 sec)
7.4... logprob:  0.443389, 0.117188 (1.407 sec)
7.5... logprob:  0.443318, 0.117188 (1.431 sec)
7.6... logprob:  0.499442, 0.140625 (1.394 sec)
7.7... logprob:  0.362782, 0.085938 (1.423 sec)
7.8... logprob:  0.419134, 0.109375 (1.399 sec)
7.9... logprob:  0.358484, 0.085938 (1.401 sec)
7.10... logprob:  0.377264, 0.093750 (1.407 sec)
7.11... logprob:  0.334291, 0.078125 (1.447 sec)
7.12... logprob:  0.466674, 0.125000 (1.390 sec)
7.13... logprob:  0.442589, 0.117188 (1.421 sec)
7.14... logprob:  0.444949, 0.117188 (1.403 sec)
7.15... logprob:  0.395862, 0.101562 (1.411 sec)
7.16... logprob:  0.421549, 0.109375 (1.403 sec)
7.17... logprob:  0.516109, 0.140625 (1.395 sec)
7.18... logprob:  0.262134, 0.054688 (1.412 sec)
7.19... logprob:  0.279886, 0.062500 (1.401 sec)
7.20... logprob:  0.421409, 0.109375 (1.409 sec)
7.21... logprob:  0.443960, 0.117188 (0.888 sec)
7.22... logprob:  0.536466, 0.148438 (1.329 sec)
7.23... logprob:  0.532570, 0.148438 (1.411 sec)
7.24... logprob:  0.310994, 0.070312 (0.984 sec)
7.25... logprob:  0.356477, 0.085938 (0.966 sec)
7.26... logprob:  0.463599, 0.125000 (1.454 sec)
7.27... logprob:  0.404730, 0.101562 (1.386 sec)
7.28... logprob:  0.421904, 0.109375 (1.405 sec)
7.29... logprob:  0.396163, 0.101562 (1.428 sec)
7.30... logprob:  0.374253, 0.093750 (1.415 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.39498519897461, 10.0]}, 128)
batch 872: ({'logprob': [66.88532257080078, 19.0]}, 128)
batch 873: ({'logprob': [40.46126937866211, 9.0]}, 128)
batch 874: ({'logprob': [45.46876907348633, 11.0]}, 128)
batch 875: ({'logprob': [50.925899505615234, 13.0]}, 128)
batch 876: ({'logprob': [64.27590942382812, 18.0]}, 128)
batch 877: ({'logprob': [45.69584655761719, 11.0]}, 128)
batch 878: ({'logprob': [61.86357498168945, 17.0]}, 128)
batch 879: ({'logprob': [73.0068130493164, 21.0]}, 128)
batch 880: ({'logprob': [50.93610763549805, 13.0]}, 128)
batch 881: ({'logprob': [29.292726516723633, 5.0]}, 128)
batch 882: ({'logprob': [54.22392654418945, 14.0]}, 128)
batch 883: ({'logprob': [61.85692596435547, 17.0]}, 128)
batch 884: ({'logprob': [51.14377212524414, 13.0]}, 128)
batch 885: ({'logprob': [51.59398651123047, 13.0]}, 128)
batch 886: ({'logprob': [62.08147430419922, 17.0]}, 128)

======================Test output======================
logprob:  0.416068, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.975558e-03 [2.234558e-09] 
Layer 'conv1' biases: 3.923959e-08 [5.320278e-11] 
Layer 'conv2' weights[0]: 7.962532e-03 [2.005896e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.167807e-10] 
Layer 'conv3' weights[0]: 7.960863e-03 [1.991477e-09] 
Layer 'conv3' biases: 3.922837e-07 [1.037023e-09] 
Layer 'conv4' weights[0]: 7.993410e-03 [2.246086e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.021808e-08] 
Layer 'conv5' weights[0]: 7.992356e-03 [7.075056e-08] 
Layer 'conv5' biases: 1.000001e+00 [7.689438e-08] 
Layer 'fc6' weights[0]: 7.589123e-03 [6.236979e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.311121e-09] 
Layer 'fc7' weights[0]: 7.651158e-03 [5.639563e-08] 
Layer 'fc7' biases: 9.998696e-01 [3.503713e-08] 
Layer 'fc8' weights[0]: 1.284912e-03 [1.900117e-06] 
Layer 'fc8' biases: 1.226624e-02 [1.235297e-05] 
Train error last 870 batches: 0.435325
-------------------------------------------------------
Not saving because 0.416068 > 0.415712 (4.190: -0.00%)
======================================================= (12.097 sec)
7.31... logprob:  0.479847, 0.132812 (1.412 sec)
7.32... logprob:  0.457230, 0.125000 (1.398 sec)
7.33... logprob:  0.460673, 0.125000 (1.453 sec)
7.34... logprob:  0.464770, 0.125000 (1.394 sec)
7.35... logprob:  0.316121, 0.070312 (1.399 sec)
7.36... logprob:  0.475708, 0.132812 (1.407 sec)
7.37... logprob:  0.417609, 0.109375 (1.412 sec)
7.38... logprob:  0.392301, 0.101562 (1.395 sec)
7.39... logprob:  0.632153, 0.187500 (1.437 sec)
7.40... logprob:  0.446089, 0.117188 (1.412 sec)
7.41... logprob:  0.352595, 0.085938 (1.428 sec)
7.42... logprob:  0.391611, 0.101562 (1.415 sec)
7.43... logprob:  0.440185, 0.117188 (1.411 sec)
7.44... logprob:  0.518316, 0.148438 (1.436 sec)
7.45... logprob:  0.381973, 0.093750 (1.394 sec)
7.46... logprob:  0.486627, 0.132812 (1.394 sec)
7.47... logprob:  0.331778, 0.078125 (1.400 sec)
7.48... logprob:  0.498779, 0.140625 (1.426 sec)
7.49... logprob:  0.510243, 0.148438 (1.427 sec)
7.50... logprob:  0.393252, 0.101562 (1.431 sec)
7.51... logprob:  0.489640, 0.140625 (1.416 sec)
7.52... logprob:  0.525885, 0.148438 (1.416 sec)
7.53... logprob:  0.295204, 0.062500 (1.447 sec)
7.54... logprob:  0.402904, 0.109375 (1.394 sec)
7.55... logprob:  0.331824, 0.078125 (1.395 sec)
7.56... logprob:  0.421884, 0.109375 (1.408 sec)
7.57... logprob:  0.572820, 0.164062 (1.428 sec)
7.58... logprob:  0.408132, 0.101562 (1.405 sec)
7.59... logprob:  0.333890, 0.078125 (1.464 sec)
7.60... logprob:  0.619399, 0.179688 (1.421 sec)
7.61... logprob:  0.383009, 0.093750 (1.426 sec)
7.62... logprob:  0.474945, 0.132812 (1.464 sec)
7.63... logprob:  0.397338, 0.101562 (1.440 sec)
7.64... logprob:  0.450199, 0.125000 (1.414 sec)
7.65... logprob:  0.373252, 0.093750 (1.398 sec)
7.66... logprob:  0.353950, 0.085938 (1.448 sec)
7.67... logprob:  0.295337, 0.062500 (1.394 sec)
7.68... logprob:  0.396843, 0.101562 (1.395 sec)
7.69... logprob:  0.496976, 0.140625 (1.421 sec)
7.70... logprob:  0.325883, 0.078125 (1.425 sec)
7.71... logprob:  0.381932, 0.101562 (1.463 sec)
7.72... logprob:  0.493892, 0.132812 (1.403 sec)
7.73... logprob:  0.447791, 0.117188 (1.427 sec)
7.74... logprob:  0.442628, 0.117188 (1.419 sec)
7.75... logprob:  0.380591, 0.093750 (1.415 sec)
7.76... logprob:  0.412157, 0.109375 (1.441 sec)
7.77... logprob:  0.396340, 0.101562 (1.426 sec)
7.78... logprob:  0.493186, 0.140625 (1.459 sec)
7.79... logprob:  0.456463, 0.125000 (1.549 sec)
7.80... logprob:  0.507607, 0.132812 (1.417 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.70801544189453, 10.0]}, 128)
batch 872: ({'logprob': [66.31028747558594, 19.0]}, 128)
batch 873: ({'logprob': [40.9460334777832, 9.0]}, 128)
batch 874: ({'logprob': [45.328826904296875, 11.0]}, 128)
batch 875: ({'logprob': [50.85005569458008, 13.0]}, 128)
batch 876: ({'logprob': [63.84035873413086, 18.0]}, 128)
batch 877: ({'logprob': [45.89960479736328, 11.0]}, 128)
batch 878: ({'logprob': [61.9130744934082, 17.0]}, 128)
batch 879: ({'logprob': [73.52472686767578, 21.0]}, 128)
batch 880: ({'logprob': [50.85889434814453, 13.0]}, 128)
batch 881: ({'logprob': [29.308279037475586, 5.0]}, 128)
batch 882: ({'logprob': [55.03797149658203, 14.0]}, 128)
batch 883: ({'logprob': [61.906707763671875, 17.0]}, 128)
batch 884: ({'logprob': [51.411014556884766, 13.0]}, 128)
batch 885: ({'logprob': [52.54863739013672, 13.0]}, 128)
batch 886: ({'logprob': [62.47443389892578, 17.0]}, 128)

======================Test output======================
logprob:  0.416927, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.975514e-03 [2.964657e-09] 
Layer 'conv1' biases: 3.998593e-08 [6.420233e-11] 
Layer 'conv2' weights[0]: 7.962495e-03 [2.493846e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.423250e-10] 
Layer 'conv3' weights[0]: 7.960832e-03 [2.255932e-09] 
Layer 'conv3' biases: 3.976812e-07 [1.407282e-09] 
Layer 'conv4' weights[0]: 7.993368e-03 [2.703887e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.467720e-08] 
Layer 'conv5' weights[0]: 7.992313e-03 [1.016500e-07] 
Layer 'conv5' biases: 1.000001e+00 [1.104413e-07] 
Layer 'fc6' weights[0]: 7.589079e-03 [9.040124e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.098831e-09] 
Layer 'fc7' weights[0]: 7.649190e-03 [2.628977e-07] 
Layer 'fc7' biases: 9.998699e-01 [2.516067e-07] 
Layer 'fc8' weights[0]: 1.289287e-03 [9.502889e-06] 
Layer 'fc8' biases: 1.232173e-02 [5.597758e-05] 
Train error last 870 batches: 0.435326
-------------------------------------------------------
Not saving because 0.416927 > 0.415712 (4.190: -0.00%)
======================================================= (12.066 sec)
7.81... logprob:  0.416719, 0.109375 (1.432 sec)
7.82... logprob:  0.232112, 0.039062 (1.432 sec)
7.83... logprob:  0.493741, 0.140625 (1.407 sec)
7.84... logprob:  0.467981, 0.125000 (1.466 sec)
7.85... logprob:  0.432173, 0.117188 (1.417 sec)
7.86... logprob:  0.417056, 0.109375 (1.433 sec)
7.87... logprob:  0.633105, 0.187500 (1.415 sec)
7.88... logprob:  0.535255, 0.156250 (1.412 sec)
7.89... logprob:  0.410740, 0.109375 (1.434 sec)
7.90... logprob:  0.577583, 0.171875 (1.390 sec)
7.91... logprob:  0.348582, 0.078125 (1.400 sec)
7.92... logprob:  0.464433, 0.125000 (1.401 sec)
7.93... logprob:  0.492374, 0.140625 (1.403 sec)
7.94... logprob:  0.428771, 0.109375 (1.386 sec)
7.95... logprob:  0.471856, 0.125000 (1.402 sec)
7.96... logprob:  0.576471, 0.171875 (1.409 sec)
7.97... logprob:  0.430796, 0.117188 (1.390 sec)
7.98... logprob:  0.390900, 0.093750 (1.442 sec)
7.99... logprob:  0.474435, 0.132812 (1.406 sec)
7.100... logprob:  0.310289, 0.070312 (1.405 sec)
7.101... logprob:  0.310278, 0.062500 (1.442 sec)
7.102... logprob:  0.546634, 0.156250 (1.392 sec)
7.103... logprob:  0.541639, 0.156250 (1.399 sec)
7.104... logprob:  0.388990, 0.101562 (1.407 sec)
7.105... logprob:  0.620090, 0.179688 (1.394 sec)
7.106... logprob:  0.344475, 0.085938 (1.397 sec)
7.107... logprob:  0.335631, 0.078125 (1.438 sec)
7.108... logprob:  0.586770, 0.171875 (1.397 sec)
7.109... logprob:  0.336266, 0.078125 (1.406 sec)
7.110... logprob:  0.564285, 0.164062 (1.398 sec)
7.111... logprob:  0.404786, 0.101562 (1.393 sec)
7.112... logprob:  0.366321, 0.093750 (1.404 sec)
7.113... logprob:  0.354831, 0.085938 (1.404 sec)
7.114... logprob:  0.440262, 0.117188 (1.430 sec)
7.115... logprob:  0.506744, 0.140625 (1.415 sec)
7.116... logprob:  0.393435, 0.101562 (1.398 sec)
7.117... logprob:  0.440403, 0.117188 (1.450 sec)
7.118... logprob:  0.409285, 0.101562 (1.388 sec)
7.119... logprob:  0.346141, 0.085938 (1.403 sec)
7.120... logprob:  0.547193, 0.156250 (1.398 sec)
7.121... logprob:  0.412750, 0.109375 (1.403 sec)
7.122... logprob:  0.519448, 0.148438 (1.441 sec)
7.123... logprob:  0.463833, 0.125000 (1.395 sec)
7.124... logprob:  0.447708, 0.125000 (1.404 sec)
7.125... logprob:  0.502084, 0.140625 (1.398 sec)
7.126... logprob:  0.475949, 0.125000 (1.394 sec)
7.127... logprob:  0.479830, 0.125000 (1.404 sec)
7.128... logprob:  0.422435, 0.109375 (1.424 sec)
7.129... logprob:  0.574963, 0.164062 (1.423 sec)
7.130... logprob:  0.382777, 0.093750 (1.419 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.018062591552734, 10.0]}, 128)
batch 872: ({'logprob': [65.93804931640625, 19.0]}, 128)
batch 873: ({'logprob': [41.99639892578125, 9.0]}, 128)
batch 874: ({'logprob': [46.250240325927734, 11.0]}, 128)
batch 875: ({'logprob': [51.38371276855469, 13.0]}, 128)
batch 876: ({'logprob': [63.59720230102539, 18.0]}, 128)
batch 877: ({'logprob': [46.692745208740234, 11.0]}, 128)
batch 878: ({'logprob': [61.67011642456055, 17.0]}, 128)
batch 879: ({'logprob': [72.3764419555664, 21.0]}, 128)
batch 880: ({'logprob': [51.39274215698242, 13.0]}, 128)
batch 881: ({'logprob': [31.26522445678711, 5.0]}, 128)
batch 882: ({'logprob': [55.05210494995117, 14.0]}, 128)
batch 883: ({'logprob': [61.66348648071289, 17.0]}, 128)
batch 884: ({'logprob': [51.81385803222656, 13.0]}, 128)
batch 885: ({'logprob': [52.691123962402344, 13.0]}, 128)
batch 886: ({'logprob': [62.10082244873047, 17.0]}, 128)

======================Test output======================
logprob:  0.419386, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.975472e-03 [1.644972e-09] 
Layer 'conv1' biases: 4.047429e-08 [4.560160e-11] 
Layer 'conv2' weights[0]: 7.962453e-03 [1.458829e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.364480e-10] 
Layer 'conv3' weights[0]: 7.960788e-03 [1.448377e-09] 
Layer 'conv3' biases: 4.015751e-07 [7.842780e-10] 
Layer 'conv4' weights[0]: 7.993327e-03 [1.559287e-09] 
Layer 'conv4' biases: 9.999999e-01 [7.466326e-09] 
Layer 'conv5' weights[0]: 7.992269e-03 [4.832329e-08] 
Layer 'conv5' biases: 1.000001e+00 [5.264140e-08] 
Layer 'fc6' weights[0]: 7.589035e-03 [4.403722e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.369801e-09] 
Layer 'fc7' weights[0]: 7.647235e-03 [7.934295e-08] 
Layer 'fc7' biases: 9.998690e-01 [6.243326e-08] 
Layer 'fc8' weights[0]: 1.253639e-03 [7.961214e-06] 
Layer 'fc8' biases: 1.219243e-02 [4.945595e-05] 
Train error last 870 batches: 0.435325
-------------------------------------------------------
Not saving because 0.419386 > 0.415712 (4.190: -0.00%)
======================================================= (12.067 sec)
7.131... logprob:  0.495491, 0.132812 (1.417 sec)
7.132... logprob:  0.506398, 0.140625 (1.437 sec)
7.133... logprob:  0.444649, 0.117188 (1.386 sec)
7.134... logprob:  0.401927, 0.101562 (1.400 sec)
7.135... logprob:  0.460316, 0.125000 (1.402 sec)
7.136... logprob:  0.562771, 0.164062 (1.402 sec)
7.137... logprob:  0.462547, 0.125000 (1.391 sec)
7.138... logprob:  0.319339, 0.070312 (1.442 sec)
7.139... logprob:  0.396017, 0.101562 (1.401 sec)
7.140... logprob:  0.561043, 0.164062 (1.412 sec)
7.141... logprob:  0.464440, 0.125000 (1.442 sec)
7.142... logprob:  0.464519, 0.125000 (1.394 sec)
7.143... logprob:  0.294204, 0.062500 (1.428 sec)
7.144... logprob:  0.457687, 0.125000 (1.418 sec)
7.145... logprob:  0.325308, 0.078125 (1.416 sec)
7.146... logprob:  0.483375, 0.132812 (1.413 sec)
7.147... logprob:  0.262611, 0.054688 (1.432 sec)
7.148... logprob:  0.459043, 0.125000 (1.396 sec)
7.149... logprob:  0.442585, 0.117188 (1.393 sec)
7.150... logprob:  0.347710, 0.085938 (1.409 sec)
7.151... logprob:  0.347182, 0.085938 (1.400 sec)
7.152... logprob:  0.784698, 0.234375 (1.388 sec)
7.153... logprob:  0.381746, 0.093750 (1.447 sec)
7.154... logprob:  0.524123, 0.148438 (1.396 sec)
7.155... logprob:  0.425725, 0.117188 (1.416 sec)
7.156... logprob:  0.296395, 0.062500 (1.435 sec)
7.157... logprob:  0.271184, 0.054688 (1.398 sec)
7.158... logprob:  0.455265, 0.125000 (1.400 sec)
7.159... logprob:  0.483201, 0.132812 (1.403 sec)
7.160... logprob:  0.445180, 0.117188 (1.394 sec)
7.161... logprob:  0.350758, 0.078125 (1.402 sec)
7.162... logprob:  0.612013, 0.179688 (1.415 sec)
7.163... logprob:  0.450267, 0.125000 (1.427 sec)
7.164... logprob:  0.468999, 0.125000 (1.418 sec)
7.165... logprob:  0.548273, 0.156250 (1.423 sec)
7.166... logprob:  0.445831, 0.125000 (1.450 sec)
7.167... logprob:  0.350106, 0.085938 (1.433 sec)
7.168... logprob:  0.363664, 0.085938 (1.419 sec)
7.169... logprob:  0.408856, 0.101562 (1.460 sec)
7.170... logprob:  0.459536, 0.125000 (1.402 sec)
7.171... logprob:  0.535594, 0.156250 (1.423 sec)
7.172... logprob:  0.435054, 0.109375 (1.415 sec)
7.173... logprob:  0.440537, 0.117188 (1.427 sec)
7.174... logprob:  0.601502, 0.171875 (1.399 sec)
7.175... logprob:  0.506257, 0.140625 (1.469 sec)
7.176... logprob:  0.478575, 0.132812 (1.420 sec)
7.177... logprob:  0.289743, 0.054688 (1.430 sec)
7.178... logprob:  0.383455, 0.093750 (1.461 sec)
7.179... logprob:  0.394815, 0.101562 (1.414 sec)
7.180... logprob:  0.466306, 0.125000 (1.426 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.03227615356445, 10.0]}, 128)
batch 872: ({'logprob': [66.5335922241211, 19.0]}, 128)
batch 873: ({'logprob': [40.67194366455078, 9.0]}, 128)
batch 874: ({'logprob': [45.36667251586914, 11.0]}, 128)
batch 875: ({'logprob': [50.84514236450195, 13.0]}, 128)
batch 876: ({'logprob': [63.996952056884766, 18.0]}, 128)
batch 877: ({'logprob': [45.76060104370117, 11.0]}, 128)
batch 878: ({'logprob': [61.82453918457031, 17.0]}, 128)
batch 879: ({'logprob': [73.17559051513672, 21.0]}, 128)
batch 880: ({'logprob': [50.85488510131836, 13.0]}, 128)
batch 881: ({'logprob': [29.29493522644043, 5.0]}, 128)
batch 882: ({'logprob': [54.57019805908203, 14.0]}, 128)
batch 883: ({'logprob': [61.817832946777344, 17.0]}, 128)
batch 884: ({'logprob': [51.22950744628906, 13.0]}, 128)
batch 885: ({'logprob': [52.01308059692383, 13.0]}, 128)
batch 886: ({'logprob': [62.208980560302734, 17.0]}, 128)

======================Test output======================
logprob:  0.416112, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.975440e-03 [1.925310e-09] 
Layer 'conv1' biases: 4.107377e-08 [4.057864e-11] 
Layer 'conv2' weights[0]: 7.962419e-03 [1.577107e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.906590e-10] 
Layer 'conv3' weights[0]: 7.960748e-03 [1.477856e-09] 
Layer 'conv3' biases: 4.063495e-07 [6.297622e-10] 
Layer 'conv4' weights[0]: 7.993291e-03 [1.584870e-09] 
Layer 'conv4' biases: 9.999999e-01 [5.110557e-09] 
Layer 'conv5' weights[0]: 7.992249e-03 [3.342819e-08] 
Layer 'conv5' biases: 1.000000e+00 [3.622452e-08] 
Layer 'fc6' weights[0]: 7.588993e-03 [3.066238e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.016493e-09] 
Layer 'fc7' weights[0]: 7.645226e-03 [1.192342e-07] 
Layer 'fc7' biases: 9.998696e-01 [1.032509e-07] 
Layer 'fc8' weights[0]: 1.295508e-03 [1.098117e-05] 
Layer 'fc8' biases: 1.256953e-02 [6.910801e-05] 
Train error last 870 batches: 0.435322
-------------------------------------------------------
Not saving because 0.416112 > 0.415712 (4.190: -0.00%)
======================================================= (12.066 sec)
7.181... logprob:  0.539639, 0.156250 (1.435 sec)
7.182... logprob:  0.371601, 0.093750 (1.417 sec)
7.183... logprob:  0.419973, 0.109375 (1.415 sec)
7.184... logprob:  0.483527, 0.132812 (1.425 sec)
7.185... logprob:  0.289988, 0.062500 (1.390 sec)
7.186... logprob:  0.370764, 0.093750 (1.403 sec)
7.187... logprob:  0.529615, 0.148438 (1.398 sec)
7.188... logprob:  0.459183, 0.125000 (1.402 sec)
7.189... logprob:  0.440908, 0.117188 (1.387 sec)
7.190... logprob:  0.375712, 0.093750 (1.440 sec)
7.191... logprob:  0.485105, 0.132812 (1.408 sec)
7.192... logprob:  0.520405, 0.148438 (1.419 sec)
7.193... logprob:  0.312710, 0.070312 (1.418 sec)
7.194... logprob:  0.414215, 0.109375 (1.418 sec)
7.195... logprob:  0.287419, 0.062500 (1.428 sec)
7.196... logprob:  0.410682, 0.109375 (1.390 sec)
7.197... logprob:  0.478075, 0.132812 (1.400 sec)
7.198... logprob:  0.355800, 0.085938 (1.404 sec)
7.199... logprob:  0.437190, 0.117188 (1.386 sec)
7.200... logprob:  0.440806, 0.117188 (1.439 sec)
7.201... logprob:  0.437090, 0.117188 (1.410 sec)
7.202... logprob:  0.538109, 0.148438 (1.402 sec)
7.203... logprob:  0.420530, 0.109375 (1.444 sec)
7.204... logprob:  0.504144, 0.140625 (1.397 sec)
7.205... logprob:  0.334461, 0.078125 (1.405 sec)
7.206... logprob:  0.361503, 0.093750 (1.399 sec)
7.207... logprob:  0.382064, 0.093750 (1.396 sec)
7.208... logprob:  0.490394, 0.140625 (1.400 sec)
7.209... logprob:  0.334656, 0.078125 (1.422 sec)
7.210... logprob:  0.586280, 0.171875 (1.420 sec)
7.211... logprob:  0.488332, 0.132812 (1.415 sec)
7.212... logprob:  0.526242, 0.148438 (1.411 sec)
7.213... logprob:  0.515128, 0.140625 (1.461 sec)
7.214... logprob:  0.459478, 0.125000 (1.428 sec)
7.215... logprob:  0.396124, 0.101562 (1.415 sec)
7.216... logprob:  0.517418, 0.140625 (1.474 sec)
7.217... logprob:  0.325216, 0.070312 (1.401 sec)
7.218... logprob:  0.463796, 0.125000 (1.422 sec)
7.219... logprob:  0.500386, 0.140625 (1.419 sec)
7.220... logprob:  0.414966, 0.109375 (1.420 sec)
7.221... logprob:  0.399523, 0.101562 (1.406 sec)
7.222... logprob:  0.554713, 0.164062 (1.458 sec)
7.223... logprob:  0.569413, 0.164062 (1.425 sec)
7.224... logprob:  0.405798, 0.101562 (1.435 sec)
7.225... logprob:  0.392012, 0.101562 (1.447 sec)
7.226... logprob:  0.424542, 0.109375 (1.425 sec)
7.227... logprob:  0.452892, 0.125000 (1.414 sec)
7.228... logprob:  0.417265, 0.109375 (1.418 sec)
7.229... logprob:  0.489290, 0.132812 (1.421 sec)
7.230... logprob:  0.459936, 0.125000 (1.431 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.009986877441406, 10.0]}, 128)
batch 872: ({'logprob': [66.48442840576172, 19.0]}, 128)
batch 873: ({'logprob': [40.72307586669922, 9.0]}, 128)
batch 874: ({'logprob': [45.373199462890625, 11.0]}, 128)
batch 875: ({'logprob': [50.84796142578125, 13.0]}, 128)
batch 876: ({'logprob': [63.959896087646484, 18.0]}, 128)
batch 877: ({'logprob': [45.7875862121582, 11.0]}, 128)
batch 878: ({'logprob': [61.82001876831055, 17.0]}, 128)
batch 879: ({'logprob': [73.1838607788086, 21.0]}, 128)
batch 880: ({'logprob': [50.857818603515625, 13.0]}, 128)
batch 881: ({'logprob': [29.33306121826172, 5.0]}, 128)
batch 882: ({'logprob': [54.62220001220703, 14.0]}, 128)
batch 883: ({'logprob': [61.813133239746094, 17.0]}, 128)
batch 884: ({'logprob': [51.25270462036133, 13.0]}, 128)
batch 885: ({'logprob': [52.077152252197266, 13.0]}, 128)
batch 886: ({'logprob': [62.22482681274414, 17.0]}, 128)

======================Test output======================
logprob:  0.416197, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.975394e-03 [1.757653e-09] 
Layer 'conv1' biases: 4.172558e-08 [4.056049e-11] 
Layer 'conv2' weights[0]: 7.962376e-03 [1.528595e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.747852e-10] 
Layer 'conv3' weights[0]: 7.960706e-03 [1.273655e-09] 
Layer 'conv3' biases: 4.121207e-07 [5.192790e-10] 
Layer 'conv4' weights[0]: 7.993244e-03 [1.311601e-09] 
Layer 'conv4' biases: 9.999999e-01 [3.816815e-09] 
Layer 'conv5' weights[0]: 7.992210e-03 [2.639037e-08] 
Layer 'conv5' biases: 1.000000e+00 [2.867576e-08] 
Layer 'fc6' weights[0]: 7.588952e-03 [2.486095e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.361628e-09] 
Layer 'fc7' weights[0]: 7.643273e-03 [4.203290e-08] 
Layer 'fc7' biases: 9.998695e-01 [1.409111e-08] 
Layer 'fc8' weights[0]: 1.298486e-03 [2.032126e-06] 
Layer 'fc8' biases: 1.264674e-02 [1.319153e-05] 
Train error last 870 batches: 0.435320
-------------------------------------------------------
Not saving because 0.416197 > 0.415712 (4.190: -0.00%)
======================================================= (12.087 sec)
7.231... logprob:  0.453647, 0.125000 (1.415 sec)
7.232... logprob:  0.496321, 0.140625 (1.470 sec)
7.233... logprob:  0.466363, 0.132812 (1.421 sec)
7.234... logprob:  0.563755, 0.164062 (1.420 sec)
7.235... logprob:  0.482052, 0.132812 (1.472 sec)
7.236... logprob:  0.425884, 0.109375 (1.401 sec)
7.237... logprob:  0.341579, 0.078125 (1.427 sec)
7.238... logprob:  0.389547, 0.093750 (1.413 sec)
7.239... logprob:  0.478193, 0.132812 (1.427 sec)
7.240... logprob:  0.485837, 0.132812 (1.400 sec)
7.241... logprob:  0.493629, 0.132812 (1.460 sec)
7.242... logprob:  0.341648, 0.078125 (1.426 sec)
7.243... logprob:  0.386017, 0.093750 (1.436 sec)
7.244... logprob:  0.315088, 0.070312 (1.447 sec)
7.245... logprob:  0.494388, 0.132812 (1.426 sec)
7.246... logprob:  0.416976, 0.109375 (1.424 sec)
7.247... logprob:  0.357180, 0.085938 (1.415 sec)
7.248... logprob:  0.307563, 0.070312 (1.427 sec)
7.249... logprob:  0.556067, 0.156250 (1.426 sec)
7.250... logprob:  0.591922, 0.164062 (1.407 sec)
7.251... logprob:  0.352849, 0.085938 (1.463 sec)
7.252... logprob:  0.348633, 0.085938 (1.424 sec)
7.253... logprob:  0.379044, 0.093750 (1.424 sec)
7.254... logprob:  0.444182, 0.117188 (1.465 sec)
7.255... logprob:  0.351655, 0.085938 (1.408 sec)
7.256... logprob:  0.378580, 0.093750 (1.429 sec)
7.257... logprob:  0.332055, 0.078125 (1.420 sec)
7.258... logprob:  0.416146, 0.109375 (1.419 sec)
7.259... logprob:  0.442373, 0.117188 (1.400 sec)
7.260... logprob:  0.308524, 0.070312 (1.461 sec)
7.261... logprob:  0.393191, 0.101562 (1.440 sec)
7.262... logprob:  0.525086, 0.148438 (1.428 sec)
7.263... logprob:  0.425308, 0.109375 (1.450 sec)
7.264... logprob:  0.375262, 0.093750 (1.425 sec)
7.265... logprob:  0.439647, 0.117188 (1.416 sec)
7.266... logprob:  0.439090, 0.117188 (1.417 sec)
7.267... logprob:  0.421991, 0.109375 (1.422 sec)
7.268... logprob:  0.458951, 0.125000 (1.419 sec)
7.269... logprob:  0.567391, 0.164062 (1.407 sec)
7.270... logprob:  0.542114, 0.156250 (1.490 sec)
7.271... logprob:  0.445900, 0.117188 (1.426 sec)
7.272... logprob:  0.384893, 0.093750 (1.418 sec)
7.273... logprob:  0.500202, 0.140625 (1.465 sec)
7.274... logprob:  0.542615, 0.156250 (1.400 sec)
7.275... logprob:  0.487937, 0.132812 (1.420 sec)
7.276... logprob:  0.390294, 0.093750 (1.423 sec)
7.277... logprob:  0.428840, 0.109375 (1.421 sec)
7.278... logprob:  0.323179, 0.070312 (1.427 sec)
7.279... logprob:  0.324838, 0.070312 (1.461 sec)
7.280... logprob:  0.214775, 0.031250 (1.409 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.89155197143555, 10.0]}, 128)
batch 872: ({'logprob': [66.71173095703125, 19.0]}, 128)
batch 873: ({'logprob': [40.453922271728516, 9.0]}, 128)
batch 874: ({'logprob': [45.24249267578125, 11.0]}, 128)
batch 875: ({'logprob': [50.79017639160156, 13.0]}, 128)
batch 876: ({'logprob': [64.13459014892578, 18.0]}, 128)
batch 877: ({'logprob': [45.623992919921875, 11.0]}, 128)
batch 878: ({'logprob': [61.90884017944336, 17.0]}, 128)
batch 879: ({'logprob': [73.3865737915039, 21.0]}, 128)
batch 880: ({'logprob': [50.80017852783203, 13.0]}, 128)
batch 881: ({'logprob': [28.94985008239746, 5.0]}, 128)
batch 882: ({'logprob': [54.51996612548828, 14.0]}, 128)
batch 883: ({'logprob': [61.90198516845703, 17.0]}, 128)
batch 884: ({'logprob': [51.16270065307617, 13.0]}, 128)
batch 885: ({'logprob': [51.922096252441406, 13.0]}, 128)
batch 886: ({'logprob': [62.281253814697266, 17.0]}, 128)

======================Test output======================
logprob:  0.415860, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.975354e-03 [6.674263e-09] 
Layer 'conv1' biases: 4.234011e-08 [2.284186e-10] 
Layer 'conv2' weights[0]: 7.962334e-03 [6.742249e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.461164e-09] 
Layer 'conv3' weights[0]: 7.960668e-03 [6.913144e-09] 
Layer 'conv3' biases: 4.138896e-07 [4.582197e-09] 
Layer 'conv4' weights[0]: 7.993202e-03 [7.890888e-09] 
Layer 'conv4' biases: 9.999999e-01 [4.687977e-08] 
Layer 'conv5' weights[0]: 7.992168e-03 [3.233878e-07] 
Layer 'conv5' biases: 9.999998e-01 [3.518376e-07] 
Layer 'fc6' weights[0]: 7.588913e-03 [2.825883e-08] 
Layer 'fc6' biases: 1.000000e+00 [2.878364e-08] 
Layer 'fc7' weights[0]: 7.641276e-03 [6.632762e-07] 
Layer 'fc7' biases: 9.998695e-01 [6.450933e-07] 
Layer 'fc8' weights[0]: 1.309979e-03 [2.535789e-05] 
Layer 'fc8' biases: 1.281843e-02 [1.658037e-04] 
Train error last 870 batches: 0.435319
-------------------------------------------------------
Not saving because 0.415860 > 0.415712 (4.190: -0.00%)
======================================================= (12.040 sec)
7.281... logprob:  0.417203, 0.109375 (1.433 sec)
7.282... logprob:  0.411495, 0.109375 (1.421 sec)
7.283... logprob:  0.393887, 0.101562 (1.409 sec)
7.284... logprob:  0.394818, 0.101562 (1.419 sec)
7.285... logprob:  0.452493, 0.117188 (1.443 sec)
7.286... logprob:  0.538030, 0.140625 (1.435 sec)
7.287... logprob:  0.346738, 0.085938 (1.435 sec)
7.288... logprob:  0.330022, 0.078125 (1.434 sec)
7.289... logprob:  0.446117, 0.117188 (1.451 sec)
7.290... logprob:  0.490627, 0.132812 (1.404 sec)
7.291... logprob:  0.439065, 0.117188 (1.422 sec)
7.292... logprob:  0.566751, 0.156250 (1.417 sec)
7.293... logprob:  0.427333, 0.117188 (1.426 sec)
7.294... logprob:  0.356442, 0.085938 (1.405 sec)
7.295... logprob:  0.335509, 0.078125 (1.463 sec)
7.296... logprob:  0.356558, 0.085938 (1.425 sec)
7.297... logprob:  0.395029, 0.101562 (1.419 sec)
7.298... logprob:  0.447938, 0.125000 (1.469 sec)
7.299... logprob:  0.343011, 0.078125 (1.404 sec)
7.300... logprob:  0.406940, 0.101562 (1.426 sec)
7.301... logprob:  0.398010, 0.101562 (1.418 sec)
7.302... logprob:  0.591454, 0.179688 (1.415 sec)
7.303... logprob:  0.459748, 0.125000 (1.415 sec)
7.304... logprob:  0.459778, 0.125000 (1.443 sec)
7.305... logprob:  0.455246, 0.125000 (1.435 sec)
7.306... logprob:  0.440666, 0.117188 (1.435 sec)
7.307... logprob:  0.421637, 0.109375 (1.446 sec)
7.308... logprob:  0.374430, 0.093750 (1.451 sec)
7.309... logprob:  0.450453, 0.125000 (1.416 sec)
7.310... logprob:  0.473952, 0.125000 (1.425 sec)
7.311... logprob:  0.502780, 0.140625 (1.455 sec)
7.312... logprob:  0.478872, 0.132812 (1.430 sec)
7.313... logprob:  0.454873, 0.125000 (1.422 sec)
7.314... logprob:  0.454690, 0.117188 (1.464 sec)
7.315... logprob:  0.314691, 0.070312 (1.436 sec)
7.316... logprob:  0.468648, 0.125000 (1.423 sec)
7.317... logprob:  0.355568, 0.085938 (1.481 sec)
7.318... logprob:  0.455450, 0.125000 (1.411 sec)
7.319... logprob:  0.423286, 0.117188 (1.428 sec)
7.320... logprob:  0.412297, 0.109375 (1.427 sec)
7.321... logprob:  0.348327, 0.085938 (1.425 sec)
7.322... logprob:  0.387614, 0.101562 (1.426 sec)
7.323... logprob:  0.416546, 0.109375 (1.471 sec)
7.324... logprob:  0.498688, 0.140625 (1.427 sec)
7.325... logprob:  0.350697, 0.085938 (1.441 sec)
7.326... logprob:  0.543156, 0.148438 (1.462 sec)
7.327... logprob:  0.554412, 0.164062 (1.426 sec)
7.328... logprob:  0.564933, 0.156250 (1.424 sec)
7.329... logprob:  0.402069, 0.101562 (1.427 sec)
7.330... logprob:  0.388770, 0.101562 (1.420 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.13740921020508, 10.0]}, 128)
batch 872: ({'logprob': [65.96104431152344, 19.0]}, 128)
batch 873: ({'logprob': [41.5915412902832, 9.0]}, 128)
batch 874: ({'logprob': [45.73012924194336, 11.0]}, 128)
batch 875: ({'logprob': [51.08291244506836, 13.0]}, 128)
batch 876: ({'logprob': [63.59421920776367, 18.0]}, 128)
batch 877: ({'logprob': [46.339202880859375, 11.0]}, 128)
batch 878: ({'logprob': [61.8082160949707, 17.0]}, 128)
batch 879: ({'logprob': [73.11931610107422, 21.0]}, 128)
batch 880: ({'logprob': [51.09184265136719, 13.0]}, 128)
batch 881: ({'logprob': [30.254274368286133, 5.0]}, 128)
batch 882: ({'logprob': [55.2796630859375, 14.0]}, 128)
batch 883: ({'logprob': [61.80137634277344, 17.0]}, 128)
batch 884: ({'logprob': [51.68079376220703, 13.0]}, 128)
batch 885: ({'logprob': [52.89305877685547, 13.0]}, 128)
batch 886: ({'logprob': [62.406578063964844, 17.0]}, 128)

======================Test output======================
logprob:  0.418345, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.975319e-03 [2.068335e-09] 
Layer 'conv1' biases: 4.316015e-08 [3.120969e-11] 
Layer 'conv2' weights[0]: 7.962301e-03 [1.503776e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.262870e-10] 
Layer 'conv3' weights[0]: 7.960630e-03 [1.141095e-09] 
Layer 'conv3' biases: 4.230514e-07 [3.085491e-10] 
Layer 'conv4' weights[0]: 7.993166e-03 [1.111431e-09] 
Layer 'conv4' biases: 9.999999e-01 [9.224708e-10] 
Layer 'conv5' weights[0]: 7.992131e-03 [6.299196e-09] 
Layer 'conv5' biases: 1.000001e+00 [6.801459e-09] 
Layer 'fc6' weights[0]: 7.588871e-03 [9.463680e-10] 
Layer 'fc6' biases: 1.000000e+00 [5.356824e-10] 
Layer 'fc7' weights[0]: 7.639303e-03 [2.150870e-07] 
Layer 'fc7' biases: 9.998692e-01 [2.031792e-07] 
Layer 'fc8' weights[0]: 1.284670e-03 [8.325759e-06] 
Layer 'fc8' biases: 1.292160e-02 [4.833454e-05] 
Train error last 870 batches: 0.435319
-------------------------------------------------------
Not saving because 0.418345 > 0.415712 (4.190: -0.00%)
======================================================= (12.160 sec)
7.331... logprob:  0.352685, 0.085938 (1.423 sec)
7.332... logprob:  0.482821, 0.132812 (1.456 sec)
7.333... logprob:  0.339691, 0.085938 (1.444 sec)
7.334... logprob:  0.565002, 0.171875 (1.444 sec)
7.335... logprob:  0.358985, 0.085938 (1.440 sec)
7.336... logprob:  0.444780, 0.125000 (1.459 sec)
7.337... logprob:  0.566554, 0.164062 (1.423 sec)
7.338... logprob:  0.449491, 0.125000 (1.424 sec)
7.339... logprob:  0.488837, 0.132812 (1.427 sec)
7.340... logprob:  0.442125, 0.117188 (1.432 sec)
7.341... logprob:  0.530281, 0.148438 (1.424 sec)
7.342... logprob:  0.429808, 0.109375 (1.470 sec)
7.343... logprob:  0.434878, 0.109375 (1.438 sec)
7.344... logprob:  0.444328, 0.125000 (1.484 sec)
7.345... logprob:  0.488348, 0.132812 (1.440 sec)
7.346... logprob:  0.436277, 0.117188 (1.436 sec)
7.347... logprob:  0.372218, 0.085938 (1.480 sec)
7.348... logprob:  0.398416, 0.101562 (1.435 sec)
7.349... logprob:  0.498104, 0.140625 (1.436 sec)
7.350... logprob:  0.358416, 0.085938 (1.436 sec)
7.351... logprob:  0.508793, 0.140625 (1.430 sec)
7.352... logprob:  0.363788, 0.093750 (1.431 sec)
7.353... logprob:  0.513161, 0.148438 (1.494 sec)
7.354... logprob:  0.675425, 0.203125 (1.429 sec)
7.355... logprob:  0.357419, 0.085938 (1.440 sec)
7.356... logprob:  0.479294, 0.132812 (1.477 sec)
7.357... logprob:  0.347298, 0.085938 (1.430 sec)
7.358... logprob:  0.326128, 0.070312 (1.435 sec)
7.359... logprob:  0.555196, 0.164062 (1.434 sec)
7.360... logprob:  0.444489, 0.117188 (1.425 sec)
7.361... logprob:  0.410736, 0.101562 (1.427 sec)
7.362... logprob:  0.424356, 0.117188 (1.472 sec)
7.363... logprob:  0.486563, 0.132812 (1.434 sec)
7.364... logprob:  0.475419, 0.125000 (1.448 sec)
7.365... logprob:  0.425096, 0.109375 (1.464 sec)
7.366... logprob:  0.409849, 0.109375 (1.439 sec)
7.367... logprob:  0.325149, 0.078125 (1.443 sec)
7.368... logprob:  0.595725, 0.171875 (1.430 sec)
7.369... logprob:  0.381419, 0.093750 (1.420 sec)
7.370... logprob:  0.381048, 0.093750 (1.438 sec)
7.371... logprob:  0.400283, 0.101562 (1.453 sec)
7.372... logprob:  0.537919, 0.156250 (1.450 sec)
7.373... logprob:  0.463848, 0.125000 (1.455 sec)
7.374... logprob:  0.527254, 0.148438 (1.450 sec)
7.375... logprob:  0.393828, 0.101562 (1.460 sec)
7.376... logprob:  0.374360, 0.093750 (1.442 sec)
7.377... logprob:  0.295323, 0.062500 (1.426 sec)
7.378... logprob:  0.453888, 0.125000 (1.464 sec)
7.379... logprob:  0.420229, 0.109375 (1.441 sec)
7.380... logprob:  0.605826, 0.179688 (1.437 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.82609939575195, 10.0]}, 128)
batch 872: ({'logprob': [66.6314697265625, 19.0]}, 128)
batch 873: ({'logprob': [40.52680969238281, 9.0]}, 128)
batch 874: ({'logprob': [45.23713684082031, 11.0]}, 128)
batch 875: ({'logprob': [50.786014556884766, 13.0]}, 128)
batch 876: ({'logprob': [64.07354736328125, 18.0]}, 128)
batch 877: ({'logprob': [45.65835952758789, 11.0]}, 128)
batch 878: ({'logprob': [61.90697479248047, 17.0]}, 128)
batch 879: ({'logprob': [73.4264144897461, 21.0]}, 128)
batch 880: ({'logprob': [50.79607391357422, 13.0]}, 128)
batch 881: ({'logprob': [28.98093605041504, 5.0]}, 128)
batch 882: ({'logprob': [54.61557388305664, 14.0]}, 128)
batch 883: ({'logprob': [61.89995193481445, 17.0]}, 128)
batch 884: ({'logprob': [51.19829177856445, 13.0]}, 128)
batch 885: ({'logprob': [52.037052154541016, 13.0]}, 128)
batch 886: ({'logprob': [62.319053649902344, 17.0]}, 128)

======================Test output======================
logprob:  0.415976, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.975276e-03 [3.197961e-09] 
Layer 'conv1' biases: 4.369378e-08 [1.161706e-10] 
Layer 'conv2' weights[0]: 7.962259e-03 [2.717958e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.241109e-10] 
Layer 'conv3' weights[0]: 7.960588e-03 [2.920826e-09] 
Layer 'conv3' biases: 4.266687e-07 [1.936504e-09] 
Layer 'conv4' weights[0]: 7.993126e-03 [3.122774e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.853987e-08] 
Layer 'conv5' weights[0]: 7.992090e-03 [1.260818e-07] 
Layer 'conv5' biases: 1.000000e+00 [1.373910e-07] 
Layer 'fc6' weights[0]: 7.588832e-03 [1.112670e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.139791e-08] 
Layer 'fc7' weights[0]: 7.637401e-03 [1.154878e-07] 
Layer 'fc7' biases: 9.998696e-01 [1.009002e-07] 
Layer 'fc8' weights[0]: 1.309238e-03 [5.193860e-06] 
Layer 'fc8' biases: 1.316539e-02 [3.128908e-05] 
Train error last 870 batches: 0.435318
-------------------------------------------------------
Not saving because 0.415976 > 0.415712 (4.190: -0.00%)
======================================================= (12.029 sec)
7.381... logprob:  0.463535, 0.125000 (1.471 sec)
7.382... logprob:  0.529436, 0.148438 (1.450 sec)
7.383... logprob:  0.358819, 0.085938 (1.442 sec)
7.384... logprob:  0.520941, 0.148438 (1.480 sec)
7.385... logprob:  0.523407, 0.148438 (1.429 sec)
7.386... logprob:  0.582213, 0.171875 (1.430 sec)
7.387... logprob:  0.428772, 0.117188 (1.432 sec)
7.388... logprob:  0.521293, 0.148438 (1.433 sec)
7.389... logprob:  0.426128, 0.109375 (1.434 sec)
7.390... logprob:  0.420053, 0.109375 (1.480 sec)
7.391... logprob:  0.318407, 0.070312 (1.445 sec)
7.392... logprob:  0.439390, 0.117188 (1.433 sec)
7.393... logprob:  0.368662, 0.093750 (1.480 sec)
7.394... logprob:  0.343435, 0.078125 (1.431 sec)
7.395... logprob:  0.331396, 0.078125 (1.431 sec)
7.396... logprob:  0.251539, 0.046875 (1.437 sec)
7.397... logprob:  0.485092, 0.132812 (1.425 sec)
7.398... logprob:  0.471915, 0.125000 (1.426 sec)
7.399... logprob:  0.433994, 0.117188 (1.481 sec)
7.400... logprob:  0.539200, 0.148438 (1.433 sec)
7.401... logprob:  0.466480, 0.125000 (1.441 sec)
7.402... logprob:  0.474575, 0.125000 (1.487 sec)
7.403... logprob:  0.462302, 0.125000 (1.435 sec)
7.404... logprob:  0.474916, 0.125000 (1.433 sec)
7.405... logprob:  0.543534, 0.156250 (1.430 sec)
7.406... logprob:  0.358216, 0.085938 (1.423 sec)
7.407... logprob:  0.492429, 0.140625 (1.433 sec)
7.408... logprob:  0.340370, 0.078125 (1.479 sec)
7.409... logprob:  0.401439, 0.101562 (1.437 sec)
7.410... logprob:  0.581492, 0.171875 (1.448 sec)
7.411... logprob:  0.398633, 0.101562 (1.500 sec)
7.412... logprob:  0.540205, 0.156250 (1.432 sec)
7.413... logprob:  0.544876, 0.156250 (1.432 sec)
7.414... logprob:  0.466840, 0.125000 (1.437 sec)
7.415... logprob:  0.401806, 0.101562 (1.422 sec)
7.416... logprob:  0.427605, 0.109375 (1.431 sec)
7.417... logprob:  0.405388, 0.093750 (1.465 sec)
7.418... logprob:  0.379783, 0.093750 (1.449 sec)
7.419... logprob:  0.417266, 0.101562 (1.454 sec)
7.420... logprob:  0.355458, 0.085938 (1.459 sec)
7.421... logprob:  0.376682, 0.101562 (1.459 sec)
7.422... logprob:  0.523976, 0.148438 (1.440 sec)
7.423... logprob:  0.421212, 0.109375 (1.427 sec)
7.424... logprob:  0.324476, 0.078125 (1.426 sec)
7.425... logprob:  0.305837, 0.070312 (1.437 sec)
7.426... logprob:  0.449633, 0.117188 (1.446 sec)
7.427... logprob:  0.555885, 0.156250 (1.456 sec)
7.428... logprob:  0.602979, 0.171875 (1.449 sec)
7.429... logprob:  0.426083, 0.109375 (1.443 sec)
7.430... logprob:  0.300249, 0.070312 (1.472 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.27186965942383, 10.0]}, 128)
batch 872: ({'logprob': [67.17729187011719, 19.0]}, 128)
batch 873: ({'logprob': [40.061546325683594, 9.0]}, 128)
batch 874: ({'logprob': [44.900569915771484, 11.0]}, 128)
batch 875: ({'logprob': [50.700374603271484, 13.0]}, 128)
batch 876: ({'logprob': [64.52462005615234, 18.0]}, 128)
batch 877: ({'logprob': [45.38228225708008, 11.0]}, 128)
batch 878: ({'logprob': [62.3239860534668, 17.0]}, 128)
batch 879: ({'logprob': [74.40686798095703, 21.0]}, 128)
batch 880: ({'logprob': [50.71030807495117, 13.0]}, 128)
batch 881: ({'logprob': [27.951557159423828, 5.0]}, 128)
batch 882: ({'logprob': [54.809669494628906, 14.0]}, 128)
batch 883: ({'logprob': [62.31713104248047, 17.0]}, 128)
batch 884: ({'logprob': [51.17476272583008, 13.0]}, 128)
batch 885: ({'logprob': [52.1367073059082, 13.0]}, 128)
batch 886: ({'logprob': [62.79792022705078, 17.0]}, 128)

======================Test output======================
logprob:  0.416332, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.975234e-03 [1.709699e-09] 
Layer 'conv1' biases: 4.432289e-08 [2.801385e-11] 
Layer 'conv2' weights[0]: 7.962225e-03 [1.487386e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.724604e-10] 
Layer 'conv3' weights[0]: 7.960544e-03 [1.285456e-09] 
Layer 'conv3' biases: 4.313420e-07 [5.373613e-10] 
Layer 'conv4' weights[0]: 7.993088e-03 [1.340399e-09] 
Layer 'conv4' biases: 9.999999e-01 [4.434807e-09] 
Layer 'conv5' weights[0]: 7.992049e-03 [2.910913e-08] 
Layer 'conv5' biases: 1.000001e+00 [3.163015e-08] 
Layer 'fc6' weights[0]: 7.588787e-03 [2.760704e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.693546e-09] 
Layer 'fc7' weights[0]: 7.635460e-03 [2.405415e-07] 
Layer 'fc7' biases: 9.998701e-01 [2.284860e-07] 
Layer 'fc8' weights[0]: 1.329310e-03 [9.446405e-06] 
Layer 'fc8' biases: 1.363288e-02 [4.934526e-05] 
Train error last 870 batches: 0.435317
-------------------------------------------------------
Not saving because 0.416332 > 0.415712 (4.190: -0.00%)
======================================================= (12.053 sec)
7.431... logprob:  0.598553, 0.171875 (1.441 sec)
7.432... logprob:  0.387566, 0.093750 (1.426 sec)
7.433... logprob:  0.330863, 0.078125 (1.434 sec)
7.434... logprob:  0.528643, 0.148438 (1.438 sec)
7.435... logprob:  0.531801, 0.156250 (1.431 sec)
7.436... logprob:  0.382116, 0.093750 (1.479 sec)
7.437... logprob:  0.500175, 0.140625 (1.445 sec)
7.438... logprob:  0.546606, 0.156250 (1.430 sec)
7.439... logprob:  0.379698, 0.093750 (1.487 sec)
7.440... logprob:  0.440056, 0.117188 (1.432 sec)
7.441... logprob:  0.468084, 0.125000 (1.429 sec)
7.442... logprob:  0.378868, 0.093750 (1.435 sec)
7.443... logprob:  0.496628, 0.140625 (1.430 sec)
7.444... logprob:  0.371835, 0.093750 (1.464 sec)
7.445... logprob:  0.361752, 0.085938 (1.484 sec)
7.446... logprob:  0.397862, 0.101562 (1.434 sec)
7.447... logprob:  0.571118, 0.164062 (1.438 sec)
7.448... logprob:  0.332105, 0.078125 (1.482 sec)
7.449... logprob:  0.400035, 0.101562 (1.436 sec)
7.450... logprob:  0.238121, 0.046875 (1.433 sec)
7.451... logprob:  0.453497, 0.125000 (1.439 sec)
7.452... logprob:  0.456657, 0.117188 (1.427 sec)
7.453... logprob:  0.455872, 0.125000 (1.429 sec)
7.454... logprob:  0.489534, 0.132812 (1.487 sec)
7.455... logprob:  0.506164, 0.140625 (1.428 sec)
7.456... logprob:  0.468754, 0.125000 (1.445 sec)
7.457... logprob:  0.375470, 0.093750 (1.474 sec)
7.458... logprob:  0.351479, 0.085938 (1.436 sec)
7.459... logprob:  0.513342, 0.140625 (1.442 sec)
7.460... logprob:  0.275454, 0.054688 (1.431 sec)
7.461... logprob:  0.459875, 0.125000 (1.427 sec)
7.462... logprob:  0.471892, 0.125000 (1.435 sec)
7.463... logprob:  0.421104, 0.109375 (1.468 sec)
7.464... logprob:  0.482619, 0.132812 (1.451 sec)
7.465... logprob:  0.421317, 0.109375 (1.453 sec)
7.466... logprob:  0.318883, 0.070312 (1.462 sec)
7.467... logprob:  0.413892, 0.109375 (1.446 sec)
7.468... logprob:  0.394272, 0.101562 (1.440 sec)
7.469... logprob:  0.334471, 0.078125 (1.424 sec)
7.470... logprob:  0.400011, 0.101562 (1.424 sec)
7.471... logprob:  0.530037, 0.148438 (1.440 sec)
7.472... logprob:  0.410234, 0.109375 (1.456 sec)
7.473... logprob:  0.375226, 0.093750 (1.457 sec)
7.474... logprob:  0.466055, 0.125000 (1.445 sec)
7.475... logprob:  0.504892, 0.140625 (1.446 sec)
7.476... logprob:  0.510744, 0.140625 (1.468 sec)
7.477... logprob:  0.334410, 0.078125 (1.441 sec)
7.478... logprob:  0.464324, 0.125000 (1.427 sec)
7.479... logprob:  0.305902, 0.070312 (1.433 sec)
7.480... logprob:  0.443521, 0.117188 (1.437 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.7961311340332, 10.0]}, 128)
batch 872: ({'logprob': [66.70450592041016, 19.0]}, 128)
batch 873: ({'logprob': [40.44710159301758, 9.0]}, 128)
batch 874: ({'logprob': [45.20138931274414, 11.0]}, 128)
batch 875: ({'logprob': [50.771881103515625, 13.0]}, 128)
batch 876: ({'logprob': [64.1302261352539, 18.0]}, 128)
batch 877: ({'logprob': [45.61138916015625, 11.0]}, 128)
batch 878: ({'logprob': [61.9361686706543, 17.0]}, 128)
batch 879: ({'logprob': [73.48786926269531, 21.0]}, 128)
batch 880: ({'logprob': [50.781883239746094, 13.0]}, 128)
batch 881: ({'logprob': [28.869001388549805, 5.0]}, 128)
batch 882: ({'logprob': [54.58462905883789, 14.0]}, 128)
batch 883: ({'logprob': [61.92914962768555, 17.0]}, 128)
batch 884: ({'logprob': [51.17322540283203, 13.0]}, 128)
batch 885: ({'logprob': [51.98984146118164, 13.0]}, 128)
batch 886: ({'logprob': [62.337181091308594, 17.0]}, 128)

======================Test output======================
logprob:  0.415894, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.975190e-03 [1.757995e-09] 
Layer 'conv1' biases: 4.490065e-08 [2.609911e-11] 
Layer 'conv2' weights[0]: 7.962184e-03 [1.250254e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.121534e-10] 
Layer 'conv3' weights[0]: 7.960502e-03 [1.062874e-09] 
Layer 'conv3' biases: 4.356582e-07 [3.485181e-10] 
Layer 'conv4' weights[0]: 7.993052e-03 [1.104726e-09] 
Layer 'conv4' biases: 9.999999e-01 [2.613877e-09] 
Layer 'conv5' weights[0]: 7.992008e-03 [1.774239e-08] 
Layer 'conv5' biases: 1.000000e+00 [1.932321e-08] 
Layer 'fc6' weights[0]: 7.588739e-03 [1.776126e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.600426e-09] 
Layer 'fc7' weights[0]: 7.633538e-03 [5.351037e-08] 
Layer 'fc7' biases: 9.998696e-01 [3.255134e-08] 
Layer 'fc8' weights[0]: 1.306184e-03 [1.581146e-06] 
Layer 'fc8' biases: 1.373777e-02 [8.962212e-06] 
Train error last 870 batches: 0.435317
-------------------------------------------------------
Not saving because 0.415894 > 0.415712 (4.190: -0.00%)
======================================================= (12.085 sec)
7.481... logprob:  0.547646, 0.156250 (1.440 sec)
7.482... logprob:  0.443234, 0.117188 (1.473 sec)
7.483... logprob:  0.502461, 0.140625 (1.449 sec)
7.484... logprob:  0.485274, 0.132812 (1.438 sec)
7.485... logprob:  0.409280, 0.109375 (1.476 sec)
7.486... logprob:  0.361918, 0.085938 (1.436 sec)
7.487... logprob:  0.522578, 0.148438 (1.430 sec)
7.488... logprob:  0.425065, 0.109375 (1.440 sec)
7.489... logprob:  0.416068, 0.109375 (1.435 sec)
7.490... logprob:  0.440711, 0.117188 (1.436 sec)
7.491... logprob:  0.313772, 0.070312 (1.480 sec)
7.492... logprob:  0.459704, 0.125000 (1.440 sec)
7.493... logprob:  0.522151, 0.148438 (1.433 sec)
7.494... logprob:  0.450418, 0.125000 (1.485 sec)
7.495... logprob:  0.380435, 0.093750 (1.430 sec)
7.496... logprob:  0.550832, 0.156250 (1.432 sec)
7.497... logprob:  0.467209, 0.125000 (1.433 sec)
7.498... logprob:  0.476465, 0.132812 (1.425 sec)
7.499... logprob:  0.456334, 0.125000 (1.436 sec)
7.500... logprob:  0.355025, 0.085938 (1.490 sec)
7.501... logprob:  0.339145, 0.078125 (1.432 sec)
7.502... logprob:  0.459736, 0.125000 (1.446 sec)
7.503... logprob:  0.400751, 0.101562 (1.482 sec)
7.504... logprob:  0.487429, 0.132812 (1.428 sec)
7.505... logprob:  0.570848, 0.164062 (1.435 sec)
7.506... logprob:  0.479682, 0.132812 (1.434 sec)
7.507... logprob:  0.385283, 0.093750 (1.428 sec)
7.508... logprob:  0.374860, 0.093750 (1.431 sec)
7.509... logprob:  0.323443, 0.070312 (1.478 sec)
7.510... logprob:  0.390504, 0.101562 (1.447 sec)
7.511... logprob:  0.410127, 0.109375 (1.453 sec)
7.512... logprob:  0.470794, 0.125000 (1.468 sec)
7.513... logprob:  0.324995, 0.078125 (1.444 sec)
7.514... logprob:  0.406273, 0.101562 (1.439 sec)
7.515... logprob:  0.455772, 0.125000 (1.429 sec)
7.516... logprob:  0.400649, 0.109375 (1.422 sec)
7.517... logprob:  0.628349, 0.179688 (1.439 sec)
7.518... logprob:  0.437809, 0.117188 (1.495 sec)
7.519... logprob:  0.516194, 0.140625 (1.454 sec)
7.520... logprob:  0.409671, 0.109375 (1.459 sec)
7.521... logprob:  0.427635, 0.109375 (1.453 sec)
7.522... logprob:  0.533001, 0.156250 (1.461 sec)
7.523... logprob:  0.332025, 0.078125 (1.442 sec)
7.524... logprob:  0.437323, 0.117188 (1.425 sec)
7.525... logprob:  0.426312, 0.109375 (1.433 sec)
7.526... logprob:  0.352309, 0.078125 (1.443 sec)
7.527... logprob:  0.504521, 0.140625 (1.440 sec)
7.528... logprob:  0.440594, 0.117188 (1.470 sec)
7.529... logprob:  0.353042, 0.085938 (1.453 sec)
7.530... logprob:  0.440254, 0.117188 (1.440 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.861785888671875, 10.0]}, 128)
batch 872: ({'logprob': [66.42013549804688, 19.0]}, 128)
batch 873: ({'logprob': [40.77920150756836, 9.0]}, 128)
batch 874: ({'logprob': [45.33091735839844, 11.0]}, 128)
batch 875: ({'logprob': [50.8313102722168, 13.0]}, 128)
batch 876: ({'logprob': [63.91398620605469, 18.0]}, 128)
batch 877: ({'logprob': [45.807273864746094, 11.0]}, 128)
batch 878: ({'logprob': [61.85464096069336, 17.0]}, 128)
batch 879: ({'logprob': [73.33136749267578, 21.0]}, 128)
batch 880: ({'logprob': [50.84114074707031, 13.0]}, 128)
batch 881: ({'logprob': [29.276216506958008, 5.0]}, 128)
batch 882: ({'logprob': [54.77358627319336, 14.0]}, 128)
batch 883: ({'logprob': [61.84748077392578, 17.0]}, 128)
batch 884: ({'logprob': [51.298343658447266, 13.0]}, 128)
batch 885: ({'logprob': [52.2469596862793, 13.0]}, 128)
batch 886: ({'logprob': [62.32150650024414, 17.0]}, 128)

======================Test output======================
logprob:  0.416375, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.975154e-03 [1.938633e-09] 
Layer 'conv1' biases: 4.546242e-08 [5.537231e-11] 
Layer 'conv2' weights[0]: 7.962147e-03 [1.802758e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.678096e-10] 
Layer 'conv3' weights[0]: 7.960468e-03 [1.737916e-09] 
Layer 'conv3' biases: 4.413522e-07 [8.270357e-10] 
Layer 'conv4' weights[0]: 7.993010e-03 [1.934709e-09] 
Layer 'conv4' biases: 9.999999e-01 [7.902518e-09] 
Layer 'conv5' weights[0]: 7.991971e-03 [5.437648e-08] 
Layer 'conv5' biases: 1.000000e+00 [5.919367e-08] 
Layer 'fc6' weights[0]: 7.588702e-03 [4.901824e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.862758e-09] 
Layer 'fc7' weights[0]: 7.631582e-03 [1.889599e-07] 
Layer 'fc7' biases: 9.998696e-01 [1.761995e-07] 
Layer 'fc8' weights[0]: 1.297098e-03 [7.262364e-06] 
Layer 'fc8' biases: 1.376349e-02 [4.731898e-05] 
Train error last 870 batches: 0.435317
-------------------------------------------------------
Not saving because 0.416375 > 0.415712 (4.190: -0.00%)
======================================================= (12.045 sec)
7.531... logprob:  0.440094, 0.117188 (1.488 sec)
7.532... logprob:  0.467500, 0.125000 (1.438 sec)
7.533... logprob:  0.561085, 0.164062 (1.425 sec)
7.534... logprob:  0.325671, 0.078125 (1.437 sec)
7.535... logprob:  0.551937, 0.156250 (1.435 sec)
7.536... logprob:  0.507547, 0.140625 (1.438 sec)
7.537... logprob:  0.510170, 0.140625 (1.476 sec)
7.538... logprob:  0.486151, 0.132812 (1.440 sec)
7.539... logprob:  0.296249, 0.062500 (1.433 sec)
7.540... logprob:  0.447181, 0.117188 (1.481 sec)
7.541... logprob:  0.389020, 0.101562 (1.435 sec)
7.542... logprob:  0.411420, 0.109375 (1.426 sec)
7.543... logprob:  0.233572, 0.039062 (1.437 sec)
7.544... logprob:  0.317967, 0.070312 (1.434 sec)
7.545... logprob:  0.348854, 0.085938 (1.433 sec)
7.546... logprob:  0.368344, 0.093750 (1.491 sec)
7.547... logprob:  0.440270, 0.117188 (1.435 sec)
7.548... logprob:  0.453530, 0.125000 (1.445 sec)
7.549... logprob:  0.490966, 0.132812 (1.480 sec)
7.550... logprob:  0.367794, 0.093750 (1.433 sec)
7.551... logprob:  0.441949, 0.117188 (1.472 sec)
7.552... logprob:  0.471390, 0.125000 (1.434 sec)
7.553... logprob:  0.349428, 0.085938 (1.434 sec)
7.554... logprob:  0.506679, 0.140625 (1.431 sec)
7.555... logprob:  0.421441, 0.109375 (1.486 sec)
7.556... logprob:  0.356111, 0.085938 (1.436 sec)
7.557... logprob:  0.396631, 0.101562 (1.451 sec)
7.558... logprob:  0.383081, 0.101562 (1.469 sec)
7.559... logprob:  0.441212, 0.125000 (1.437 sec)
7.560... logprob:  0.335642, 0.078125 (1.443 sec)
7.561... logprob:  0.411884, 0.109375 (1.431 sec)
7.562... logprob:  0.503141, 0.140625 (1.426 sec)
7.563... logprob:  0.373955, 0.093750 (1.440 sec)
7.564... logprob:  0.468322, 0.132812 (1.466 sec)
7.565... logprob:  0.610880, 0.187500 (1.453 sec)
7.566... logprob:  0.374975, 0.093750 (1.452 sec)
7.567... logprob:  0.423654, 0.109375 (1.462 sec)
7.568... logprob:  0.496453, 0.140625 (1.452 sec)
7.569... logprob:  0.508121, 0.140625 (1.433 sec)
7.570... logprob:  0.543598, 0.164062 (1.429 sec)
7.571... logprob:  0.454869, 0.125000 (1.429 sec)
7.572... logprob:  0.501663, 0.140625 (1.442 sec)
7.573... logprob:  0.512684, 0.148438 (1.448 sec)
7.574... logprob:  0.428339, 0.109375 (1.459 sec)
7.575... logprob:  0.343409, 0.078125 (1.451 sec)
7.576... logprob:  0.427526, 0.109375 (1.440 sec)
7.577... logprob:  0.460941, 0.125000 (1.475 sec)
7.578... logprob:  0.336427, 0.078125 (1.438 sec)
7.579... logprob:  0.442118, 0.117188 (1.425 sec)
7.580... logprob:  0.547253, 0.156250 (1.437 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.36780548095703, 10.0]}, 128)
batch 872: ({'logprob': [66.31512451171875, 19.0]}, 128)
batch 873: ({'logprob': [41.14693069458008, 9.0]}, 128)
batch 874: ({'logprob': [45.28873062133789, 11.0]}, 128)
batch 875: ({'logprob': [50.905418395996094, 13.0]}, 128)
batch 876: ({'logprob': [63.8819580078125, 18.0]}, 128)
batch 877: ({'logprob': [46.027523040771484, 11.0]}, 128)
batch 878: ({'logprob': [62.159523010253906, 17.0]}, 128)
batch 879: ({'logprob': [74.12906646728516, 21.0]}, 128)
batch 880: ({'logprob': [50.91424560546875, 13.0]}, 128)
batch 881: ({'logprob': [29.15046501159668, 5.0]}, 128)
batch 882: ({'logprob': [55.56175231933594, 14.0]}, 128)
batch 883: ({'logprob': [62.15249252319336, 17.0]}, 128)
batch 884: ({'logprob': [51.63496017456055, 13.0]}, 128)
batch 885: ({'logprob': [53.1091194152832, 13.0]}, 128)
batch 886: ({'logprob': [62.88909912109375, 17.0]}, 128)

======================Test output======================
logprob:  0.418278, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.975119e-03 [2.080809e-09] 
Layer 'conv1' biases: 4.610168e-08 [3.323255e-11] 
Layer 'conv2' weights[0]: 7.962107e-03 [1.500888e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.116659e-10] 
Layer 'conv3' weights[0]: 7.960425e-03 [1.384430e-09] 
Layer 'conv3' biases: 4.459614e-07 [6.968073e-10] 
Layer 'conv4' weights[0]: 7.992972e-03 [1.490103e-09] 
Layer 'conv4' biases: 9.999999e-01 [6.192144e-09] 
Layer 'conv5' weights[0]: 7.991933e-03 [4.280091e-08] 
Layer 'conv5' biases: 9.999999e-01 [4.654366e-08] 
Layer 'fc6' weights[0]: 7.588660e-03 [3.866111e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.833754e-09] 
Layer 'fc7' weights[0]: 7.629639e-03 [1.670481e-07] 
Layer 'fc7' biases: 9.998698e-01 [1.540915e-07] 
Layer 'fc8' weights[0]: 1.302860e-03 [9.072121e-06] 
Layer 'fc8' biases: 1.393091e-02 [5.836060e-05] 
Train error last 870 batches: 0.435316
-------------------------------------------------------
Not saving because 0.418278 > 0.415712 (4.190: -0.00%)
======================================================= (12.022 sec)
7.581... logprob:  0.531385, 0.156250 (1.444 sec)
7.582... logprob:  0.438041, 0.125000 (1.432 sec)
7.583... logprob:  0.593263, 0.171875 (1.478 sec)
7.584... logprob:  0.468209, 0.132812 (1.468 sec)
7.585... logprob:  0.349786, 0.085938 (1.430 sec)
7.586... logprob:  0.313244, 0.070312 (1.486 sec)
7.587... logprob:  0.404319, 0.101562 (1.430 sec)
7.588... logprob:  0.418741, 0.117188 (1.430 sec)
7.589... logprob:  0.361500, 0.093750 (1.431 sec)
7.590... logprob:  0.524609, 0.148438 (1.432 sec)
7.591... logprob:  0.397570, 0.101562 (1.435 sec)
7.592... logprob:  0.455617, 0.125000 (1.485 sec)
7.593... logprob:  0.467438, 0.125000 (1.441 sec)
7.594... logprob:  0.352921, 0.085938 (1.438 sec)
7.595... logprob:  0.428651, 0.109375 (1.487 sec)
7.596... logprob:  0.461546, 0.125000 (1.433 sec)
7.597... logprob:  0.397391, 0.101562 (1.435 sec)
7.598... logprob:  0.397227, 0.101562 (1.437 sec)
7.599... logprob:  0.313393, 0.070312 (1.433 sec)
7.600... logprob:  0.340941, 0.085938 (1.433 sec)
7.601... logprob:  0.402053, 0.101562 (1.490 sec)
7.602... logprob:  0.289446, 0.062500 (1.433 sec)
7.603... logprob:  0.266636, 0.054688 (1.449 sec)
7.604... logprob:  0.407416, 0.101562 (1.475 sec)
7.605... logprob:  0.563670, 0.148438 (1.439 sec)
7.606... logprob:  0.296021, 0.070312 (1.440 sec)
7.607... logprob:  0.505031, 0.132812 (1.435 sec)
7.608... logprob:  0.361381, 0.085938 (1.427 sec)
7.609... logprob:  0.356736, 0.085938 (1.435 sec)
7.610... logprob:  0.493582, 0.132812 (1.478 sec)
7.611... logprob:  0.510649, 0.140625 (1.446 sec)
7.612... logprob:  0.448193, 0.117188 (1.457 sec)
7.613... logprob:  0.280288, 0.062500 (1.458 sec)
7.614... logprob:  0.503623, 0.140625 (1.446 sec)
7.615... logprob:  0.351554, 0.085938 (1.438 sec)
7.616... logprob:  0.415723, 0.109375 (1.432 sec)
7.617... logprob:  0.418150, 0.109375 (1.429 sec)
7.618... logprob:  0.546428, 0.156250 (1.436 sec)
7.619... logprob:  0.505775, 0.140625 (1.459 sec)
7.620... logprob:  0.539640, 0.156250 (1.455 sec)
7.621... logprob:  0.364211, 0.085938 (1.452 sec)
7.622... logprob:  0.365179, 0.085938 (1.454 sec)
7.623... logprob:  0.423312, 0.109375 (1.472 sec)
7.624... logprob:  0.382615, 0.093750 (1.439 sec)
7.625... logprob:  0.441055, 0.117188 (1.454 sec)
7.626... logprob:  0.438476, 0.117188 (1.428 sec)
7.627... logprob:  0.435945, 0.117188 (1.434 sec)
7.628... logprob:  0.465149, 0.125000 (1.431 sec)
7.629... logprob:  0.371913, 0.093750 (1.476 sec)
7.630... logprob:  0.422371, 0.109375 (1.447 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.71965789794922, 10.0]}, 128)
batch 872: ({'logprob': [67.20698547363281, 19.0]}, 128)
batch 873: ({'logprob': [40.00647735595703, 9.0]}, 128)
batch 874: ({'logprob': [45.05398178100586, 11.0]}, 128)
batch 875: ({'logprob': [50.74262237548828, 13.0]}, 128)
batch 876: ({'logprob': [64.53060150146484, 18.0]}, 128)
batch 877: ({'logprob': [45.376502990722656, 11.0]}, 128)
batch 878: ({'logprob': [62.14558792114258, 17.0]}, 128)
batch 879: ({'logprob': [73.84840393066406, 21.0]}, 128)
batch 880: ({'logprob': [50.7534065246582, 13.0]}, 128)
batch 881: ({'logprob': [28.27691650390625, 5.0]}, 128)
batch 882: ({'logprob': [54.39828109741211, 14.0]}, 128)
batch 883: ({'logprob': [62.13814163208008, 17.0]}, 128)
batch 884: ({'logprob': [51.05778503417969, 13.0]}, 128)
batch 885: ({'logprob': [51.70054626464844, 13.0]}, 128)
batch 886: ({'logprob': [62.45998001098633, 17.0]}, 128)

======================Test output======================
logprob:  0.415730, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.975085e-03 [1.974922e-09] 
Layer 'conv1' biases: 4.672046e-08 [2.359897e-11] 
Layer 'conv2' weights[0]: 7.962067e-03 [1.414211e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.135993e-10] 
Layer 'conv3' weights[0]: 7.960381e-03 [1.124939e-09] 
Layer 'conv3' biases: 4.515969e-07 [3.493575e-10] 
Layer 'conv4' weights[0]: 7.992931e-03 [1.197618e-09] 
Layer 'conv4' biases: 9.999999e-01 [2.485553e-09] 
Layer 'conv5' weights[0]: 7.991887e-03 [1.720199e-08] 
Layer 'conv5' biases: 1.000000e+00 [1.870073e-08] 
Layer 'fc6' weights[0]: 7.588617e-03 [1.718365e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.534802e-09] 
Layer 'fc7' weights[0]: 7.627652e-03 [1.881150e-07] 
Layer 'fc7' biases: 9.998695e-01 [1.754270e-07] 
Layer 'fc8' weights[0]: 1.323394e-03 [6.596375e-06] 
Layer 'fc8' biases: 1.421536e-02 [4.394219e-05] 
Train error last 870 batches: 0.435316
-------------------------------------------------------
Not saving because 0.415730 > 0.415712 (4.190: -0.00%)
======================================================= (12.097 sec)
7.631... logprob:  0.640041, 0.187500 (1.445 sec)
7.632... logprob:  0.399099, 0.101562 (1.483 sec)
7.633... logprob:  0.375962, 0.093750 (1.435 sec)
7.634... logprob:  0.660767, 0.195312 (1.430 sec)
7.635... logprob:  0.374130, 0.093750 (1.436 sec)
7.636... logprob:  0.480196, 0.132812 (1.437 sec)
7.637... logprob:  0.331077, 0.078125 (1.434 sec)
7.638... logprob:  0.515756, 0.140625 (1.488 sec)
7.639... logprob:  0.418252, 0.109375 (1.445 sec)
7.640... logprob:  0.528838, 0.148438 (1.438 sec)
7.641... logprob:  0.410458, 0.109375 (1.487 sec)
7.642... logprob:  0.500756, 0.140625 (1.434 sec)
7.643... logprob:  0.622544, 0.187500 (1.436 sec)
7.644... logprob:  0.321749, 0.070312 (1.433 sec)
7.645... logprob:  0.414470, 0.109375 (1.427 sec)
7.646... logprob:  0.385924, 0.093750 (1.434 sec)
7.647... logprob:  0.456679, 0.125000 (1.491 sec)
7.648... logprob:  0.491123, 0.140625 (1.433 sec)
7.649... logprob:  0.369882, 0.093750 (1.449 sec)
7.650... logprob:  0.413837, 0.109375 (1.477 sec)
7.651... logprob:  0.397254, 0.101562 (1.436 sec)
7.652... logprob:  0.507679, 0.140625 (1.437 sec)
7.653... logprob:  0.548462, 0.156250 (1.438 sec)
7.654... logprob:  0.496183, 0.140625 (1.427 sec)
7.655... logprob:  0.436224, 0.117188 (1.437 sec)
7.656... logprob:  0.416650, 0.109375 (1.477 sec)
7.657... logprob:  0.449570, 0.117188 (1.449 sec)
7.658... logprob:  0.345624, 0.085938 (1.482 sec)
7.659... logprob:  0.464461, 0.125000 (1.470 sec)
7.660... logprob:  0.445712, 0.125000 (1.442 sec)
7.661... logprob:  0.378694, 0.093750 (1.451 sec)
7.662... logprob:  0.469194, 0.132812 (1.430 sec)
7.663... logprob:  0.311204, 0.070312 (1.424 sec)
7.664... logprob:  0.285612, 0.062500 (1.437 sec)
7.665... logprob:  0.402047, 0.101562 (1.460 sec)
7.666... logprob:  0.442136, 0.117188 (1.458 sec)
7.667... logprob:  0.564422, 0.164062 (1.451 sec)
7.668... logprob:  0.498002, 0.140625 (1.456 sec)
7.669... logprob:  0.433322, 0.109375 (1.458 sec)
7.670... logprob:  0.362637, 0.085938 (1.435 sec)
7.671... logprob:  0.360815, 0.093750 (1.424 sec)
7.672... logprob:  0.441816, 0.117188 (1.436 sec)
7.673... logprob:  0.436272, 0.117188 (1.436 sec)
7.674... logprob:  0.446725, 0.117188 (1.445 sec)
7.675... logprob:  0.356633, 0.093750 (1.467 sec)
7.676... logprob:  0.450124, 0.125000 (1.456 sec)
7.677... logprob:  0.471113, 0.125000 (1.439 sec)
7.678... logprob:  0.465633, 0.125000 (1.485 sec)
7.679... logprob:  0.454895, 0.125000 (1.432 sec)
7.680... logprob:  0.351795, 0.078125 (1.429 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.74528121948242, 10.0]}, 128)
batch 872: ({'logprob': [66.13247680664062, 19.0]}, 128)
batch 873: ({'logprob': [41.27468490600586, 9.0]}, 128)
batch 874: ({'logprob': [45.46303939819336, 11.0]}, 128)
batch 875: ({'logprob': [50.9450798034668, 13.0]}, 128)
batch 876: ({'logprob': [63.72151565551758, 18.0]}, 128)
batch 877: ({'logprob': [46.111751556396484, 11.0]}, 128)
batch 878: ({'logprob': [61.93032455444336, 17.0]}, 128)
batch 879: ({'logprob': [73.54042053222656, 21.0]}, 128)
batch 880: ({'logprob': [50.954349517822266, 13.0]}, 128)
batch 881: ({'logprob': [29.637798309326172, 5.0]}, 128)
batch 882: ({'logprob': [55.3074951171875, 14.0]}, 128)
batch 883: ({'logprob': [61.92304229736328, 17.0]}, 128)
batch 884: ({'logprob': [51.58373260498047, 13.0]}, 128)
batch 885: ({'logprob': [52.87628936767578, 13.0]}, 128)
batch 886: ({'logprob': [62.56892776489258, 17.0]}, 128)

======================Test output======================
logprob:  0.417830, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.975042e-03 [3.226038e-09] 
Layer 'conv1' biases: 4.730618e-08 [6.914671e-11] 
Layer 'conv2' weights[0]: 7.962027e-03 [2.022554e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.254558e-10] 
Layer 'conv3' weights[0]: 7.960342e-03 [1.845507e-09] 
Layer 'conv3' biases: 4.572940e-07 [9.718095e-10] 
Layer 'conv4' weights[0]: 7.992896e-03 [1.975667e-09] 
Layer 'conv4' biases: 9.999999e-01 [8.032199e-09] 
Layer 'conv5' weights[0]: 7.991858e-03 [5.060076e-08] 
Layer 'conv5' biases: 1.000000e+00 [5.485748e-08] 
Layer 'fc6' weights[0]: 7.588575e-03 [4.627694e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.590266e-09] 
Layer 'fc7' weights[0]: 7.625722e-03 [4.992442e-08] 
Layer 'fc7' biases: 9.998692e-01 [2.681980e-08] 
Layer 'fc8' weights[0]: 1.298268e-03 [4.595615e-06] 
Layer 'fc8' biases: 1.412925e-02 [2.863307e-05] 
Train error last 870 batches: 0.435317
-------------------------------------------------------
Not saving because 0.417830 > 0.415712 (4.190: -0.00%)
======================================================= (12.000 sec)
7.681... logprob:  0.374023, 0.093750 (1.447 sec)
7.682... logprob:  0.340531, 0.078125 (1.440 sec)
7.683... logprob:  0.411681, 0.109375 (1.428 sec)
7.684... logprob:  0.357499, 0.085938 (1.476 sec)
7.685... logprob:  0.285486, 0.054688 (1.439 sec)
7.686... logprob:  0.318203, 0.070312 (1.439 sec)
7.687... logprob:  0.281295, 0.062500 (1.486 sec)
7.688... logprob:  0.323073, 0.078125 (1.439 sec)
7.689... logprob:  0.472036, 0.125000 (1.427 sec)
7.690... logprob:  0.528649, 0.140625 (1.444 sec)
7.691... logprob:  0.517939, 0.140625 (1.462 sec)
7.692... logprob:  0.386034, 0.101562 (1.438 sec)
7.693... logprob:  0.456726, 0.125000 (1.487 sec)
7.694... logprob:  0.330794, 0.078125 (1.437 sec)
7.695... logprob:  0.356773, 0.085938 (1.443 sec)
7.696... logprob:  0.538326, 0.148438 (1.479 sec)
7.697... logprob:  0.465417, 0.125000 (1.439 sec)
7.698... logprob:  0.548110, 0.156250 (1.434 sec)
7.699... logprob:  0.459570, 0.125000 (1.438 sec)
7.700... logprob:  0.434280, 0.117188 (1.428 sec)
7.701... logprob:  0.423716, 0.109375 (1.437 sec)
7.702... logprob:  0.521354, 0.148438 (1.481 sec)
7.703... logprob:  0.406005, 0.101562 (1.444 sec)
7.704... logprob:  0.406659, 0.101562 (1.446 sec)
7.705... logprob:  0.420479, 0.109375 (1.481 sec)
7.706... logprob:  0.468089, 0.125000 (1.433 sec)
7.707... logprob:  0.485300, 0.132812 (1.443 sec)
7.708... logprob:  0.416914, 0.109375 (1.430 sec)
7.709... logprob:  0.422264, 0.109375 (1.427 sec)
7.710... logprob:  0.603409, 0.179688 (1.438 sec)
7.711... logprob:  0.469596, 0.125000 (1.476 sec)
7.712... logprob:  0.339851, 0.078125 (1.451 sec)
7.713... logprob:  0.588171, 0.179688 (1.459 sec)
7.714... logprob:  0.466420, 0.125000 (1.462 sec)
7.715... logprob:  0.417109, 0.109375 (1.454 sec)
7.716... logprob:  0.335077, 0.078125 (1.433 sec)
7.717... logprob:  0.429915, 0.117188 (1.426 sec)
7.718... logprob:  0.490440, 0.132812 (1.429 sec)
7.719... logprob:  0.406221, 0.109375 (1.440 sec)
7.720... logprob:  0.433245, 0.117188 (1.450 sec)
7.721... logprob:  0.451614, 0.117188 (1.460 sec)
7.722... logprob:  0.536657, 0.156250 (1.459 sec)
7.723... logprob:  0.416672, 0.109375 (1.445 sec)
7.724... logprob:  0.412788, 0.109375 (1.476 sec)
7.725... logprob:  0.494479, 0.140625 (1.434 sec)
7.726... logprob:  0.338839, 0.085938 (1.432 sec)
7.727... logprob:  0.393539, 0.101562 (1.429 sec)
7.728... logprob:  0.421550, 0.109375 (1.444 sec)
7.729... logprob:  0.388092, 0.093750 (1.433 sec)
7.730... logprob:  0.565794, 0.164062 (1.477 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.64839172363281, 10.0]}, 128)
batch 872: ({'logprob': [66.24580383300781, 19.0]}, 128)
batch 873: ({'logprob': [41.07709503173828, 9.0]}, 128)
batch 874: ({'logprob': [45.3546142578125, 11.0]}, 128)
batch 875: ({'logprob': [50.88066864013672, 13.0]}, 128)
batch 876: ({'logprob': [63.8016242980957, 18.0]}, 128)
batch 877: ({'logprob': [45.98065948486328, 11.0]}, 128)
batch 878: ({'logprob': [61.95439529418945, 17.0]}, 128)
batch 879: ({'logprob': [73.63050079345703, 21.0]}, 128)
batch 880: ({'logprob': [50.88998031616211, 13.0]}, 128)
batch 881: ({'logprob': [29.374055862426758, 5.0]}, 128)
batch 882: ({'logprob': [55.209320068359375, 14.0]}, 128)
batch 883: ({'logprob': [61.94715118408203, 17.0]}, 128)
batch 884: ({'logprob': [51.49706268310547, 13.0]}, 128)
batch 885: ({'logprob': [52.7448616027832, 13.0]}, 128)
batch 886: ({'logprob': [62.57067108154297, 17.0]}, 128)

======================Test output======================
logprob:  0.417386, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.975011e-03 [2.541104e-09] 
Layer 'conv1' biases: 4.789683e-08 [6.786018e-11] 
Layer 'conv2' weights[0]: 7.961995e-03 [1.986857e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.341122e-10] 
Layer 'conv3' weights[0]: 7.960300e-03 [1.829909e-09] 
Layer 'conv3' biases: 4.618815e-07 [1.016543e-09] 
Layer 'conv4' weights[0]: 7.992854e-03 [2.028150e-09] 
Layer 'conv4' biases: 9.999999e-01 [9.875660e-09] 
Layer 'conv5' weights[0]: 7.991817e-03 [6.841127e-08] 
Layer 'conv5' biases: 1.000000e+00 [7.434220e-08] 
Layer 'fc6' weights[0]: 7.588533e-03 [6.018267e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.106632e-09] 
Layer 'fc7' weights[0]: 7.623797e-03 [4.446362e-08] 
Layer 'fc7' biases: 9.998692e-01 [1.905026e-08] 
Layer 'fc8' weights[0]: 1.304168e-03 [3.304126e-06] 
Layer 'fc8' biases: 1.438237e-02 [1.968131e-05] 
Train error last 870 batches: 0.435316
-------------------------------------------------------
Not saving because 0.417386 > 0.415712 (4.190: -0.00%)
======================================================= (12.179 sec)
7.731... logprob:  0.450208, 0.125000 (1.455 sec)
7.732... logprob:  0.311553, 0.070312 (1.442 sec)
7.733... logprob:  0.557007, 0.156250 (1.490 sec)
7.734... logprob:  0.340243, 0.078125 (1.430 sec)
7.735... logprob:  0.527862, 0.148438 (1.435 sec)
7.736... logprob:  0.643587, 0.187500 (1.434 sec)
7.737... logprob:  0.516313, 0.148438 (1.437 sec)
7.738... logprob:  0.459494, 0.125000 (1.434 sec)
7.739... logprob:  0.477847, 0.132812 (1.486 sec)
7.740... logprob:  0.339631, 0.078125 (1.440 sec)
7.741... logprob:  0.393401, 0.101562 (1.438 sec)
7.742... logprob:  0.419789, 0.109375 (1.486 sec)
7.743... logprob:  0.364873, 0.085938 (1.434 sec)
7.744... logprob:  0.519360, 0.148438 (1.433 sec)
7.745... logprob:  0.478227, 0.132812 (1.440 sec)
7.746... logprob:  0.440581, 0.117188 (1.428 sec)
7.747... logprob:  0.425662, 0.109375 (1.438 sec)
7.748... logprob:  0.377998, 0.093750 (1.484 sec)
7.749... logprob:  0.420877, 0.109375 (1.436 sec)
7.750... logprob:  0.512990, 0.140625 (1.450 sec)
7.751... logprob:  0.263445, 0.054688 (1.476 sec)
7.752... logprob:  0.522398, 0.140625 (1.436 sec)
7.753... logprob:  0.441340, 0.117188 (1.439 sec)
7.754... logprob:  0.468950, 0.132812 (1.438 sec)
7.755... logprob:  0.507188, 0.140625 (1.425 sec)
7.756... logprob:  0.440826, 0.117188 (1.439 sec)
7.757... logprob:  0.552135, 0.156250 (1.477 sec)
7.758... logprob:  0.393867, 0.101562 (1.444 sec)
7.759... logprob:  0.459708, 0.125000 (1.457 sec)
7.760... logprob:  0.485275, 0.132812 (1.463 sec)
7.761... logprob:  0.418612, 0.109375 (1.448 sec)
7.762... logprob:  0.515971, 0.148438 (1.445 sec)
7.763... logprob:  0.558659, 0.164062 (1.427 sec)
7.764... logprob:  0.503300, 0.140625 (1.429 sec)
7.765... logprob:  0.312662, 0.062500 (1.471 sec)
7.766... logprob:  0.482360, 0.132812 (1.458 sec)
7.767... logprob:  0.371207, 0.085938 (1.457 sec)
7.768... logprob:  0.432806, 0.117188 (1.464 sec)
7.769... logprob:  0.491041, 0.140625 (1.464 sec)
7.770... logprob:  0.402709, 0.101562 (1.482 sec)
7.771... logprob:  0.549891, 0.156250 (1.459 sec)
7.772... logprob:  0.414023, 0.109375 (1.443 sec)
7.773... logprob:  0.558563, 0.164062 (1.451 sec)
7.774... logprob:  0.361343, 0.085938 (1.544 sec)
7.775... logprob:  0.407291, 0.101562 (1.462 sec)
7.776... logprob:  0.433347, 0.117188 (1.477 sec)
7.777... logprob:  0.379899, 0.093750 (1.472 sec)
7.778... logprob:  0.433695, 0.117188 (1.469 sec)
7.779... logprob:  0.505598, 0.140625 (1.489 sec)
7.780... logprob:  0.385756, 0.101562 (1.455 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.49578094482422, 10.0]}, 128)
batch 872: ({'logprob': [66.88251495361328, 19.0]}, 128)
batch 873: ({'logprob': [40.27251052856445, 9.0]}, 128)
batch 874: ({'logprob': [45.03510284423828, 11.0]}, 128)
batch 875: ({'logprob': [50.7172966003418, 13.0]}, 128)
batch 876: ({'logprob': [64.27880859375, 18.0]}, 128)
batch 877: ({'logprob': [45.496700286865234, 11.0]}, 128)
batch 878: ({'logprob': [62.10615158081055, 17.0]}, 128)
batch 879: ({'logprob': [73.93343353271484, 21.0]}, 128)
batch 880: ({'logprob': [50.7275390625, 13.0]}, 128)
batch 881: ({'logprob': [28.418115615844727, 5.0]}, 128)
batch 882: ({'logprob': [54.71646499633789, 14.0]}, 128)
batch 883: ({'logprob': [62.09872055053711, 17.0]}, 128)
batch 884: ({'logprob': [51.1710205078125, 13.0]}, 128)
batch 885: ({'logprob': [52.09166717529297, 13.0]}, 128)
batch 886: ({'logprob': [62.55927658081055, 17.0]}, 128)

======================Test output======================
logprob:  0.416016, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.974971e-03 [2.051057e-09] 
Layer 'conv1' biases: 4.847687e-08 [4.383605e-11] 
Layer 'conv2' weights[0]: 7.961957e-03 [1.750429e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.104830e-10] 
Layer 'conv3' weights[0]: 7.960267e-03 [1.424057e-09] 
Layer 'conv3' biases: 4.670468e-07 [5.872430e-10] 
Layer 'conv4' weights[0]: 7.992812e-03 [1.421622e-09] 
Layer 'conv4' biases: 9.999999e-01 [3.482656e-09] 
Layer 'conv5' weights[0]: 7.991776e-03 [1.825786e-08] 
Layer 'conv5' biases: 1.000000e+00 [1.943698e-08] 
Layer 'fc6' weights[0]: 7.588494e-03 [1.829028e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.660261e-09] 
Layer 'fc7' weights[0]: 7.621846e-03 [4.565677e-08] 
Layer 'fc7' biases: 9.998694e-01 [2.006644e-08] 
Layer 'fc8' weights[0]: 1.322284e-03 [3.664593e-06] 
Layer 'fc8' biases: 1.463240e-02 [2.317993e-05] 
Train error last 870 batches: 0.435315
-------------------------------------------------------
Not saving because 0.416016 > 0.415712 (4.190: -0.00%)
======================================================= (12.118 sec)
7.781... logprob:  0.369848, 0.085938 (1.449 sec)
7.782... logprob:  0.351614, 0.085938 (1.456 sec)
7.783... logprob:  0.555423, 0.156250 (1.460 sec)
7.784... logprob:  0.440980, 0.117188 (1.460 sec)
7.785... logprob:  0.543381, 0.156250 (1.494 sec)
7.786... logprob:  0.477267, 0.132812 (1.474 sec)
7.787... logprob:  0.545945, 0.156250 (1.459 sec)
7.788... logprob:  0.562602, 0.164062 (1.495 sec)
7.789... logprob:  0.282074, 0.054688 (1.455 sec)
7.790... logprob:  0.408671, 0.101562 (1.450 sec)
7.791... logprob:  0.398383, 0.101562 (1.449 sec)
7.792... logprob:  0.361531, 0.085938 (1.466 sec)
7.793... logprob:  0.370487, 0.085938 (1.452 sec)
7.794... logprob:  0.387136, 0.093750 (1.493 sec)
7.795... logprob:  0.469937, 0.125000 (1.467 sec)
7.796... logprob:  0.423507, 0.109375 (1.462 sec)
7.797... logprob:  0.358559, 0.085938 (1.522 sec)
7.798... logprob:  0.393267, 0.101562 (1.458 sec)
7.799... logprob:  0.331924, 0.078125 (1.448 sec)
7.800... logprob:  0.371917, 0.093750 (1.451 sec)
7.801... logprob:  0.450622, 0.117188 (1.450 sec)
7.802... logprob:  0.423384, 0.109375 (1.451 sec)
7.803... logprob:  0.492506, 0.132812 (1.494 sec)
7.804... logprob:  0.350048, 0.085938 (1.463 sec)
7.805... logprob:  0.452219, 0.117188 (1.457 sec)
7.806... logprob:  0.424169, 0.109375 (1.510 sec)
7.807... logprob:  0.443445, 0.117188 (1.458 sec)
7.808... logprob:  0.462389, 0.125000 (1.449 sec)
7.809... logprob:  0.589323, 0.171875 (1.453 sec)
7.810... logprob:  0.442409, 0.117188 (1.455 sec)
7.811... logprob:  0.460463, 0.125000 (1.459 sec)
7.812... logprob:  0.462533, 0.125000 (1.497 sec)
7.813... logprob:  0.486023, 0.132812 (1.469 sec)
7.814... logprob:  0.478384, 0.132812 (1.455 sec)
7.815... logprob:  0.373027, 0.085938 (1.502 sec)
7.816... logprob:  0.409386, 0.101562 (1.456 sec)
7.817... logprob:  0.426400, 0.109375 (1.454 sec)
7.818... logprob:  0.559952, 0.164062 (1.448 sec)
7.819... logprob:  0.498259, 0.140625 (1.459 sec)
7.820... logprob:  0.421457, 0.109375 (1.452 sec)
7.821... logprob:  0.406227, 0.101562 (1.504 sec)
7.822... logprob:  0.440968, 0.117188 (1.144 sec)
7.823... logprob:  0.339962, 0.078125 (1.160 sec)
7.824... logprob:  0.490326, 0.132812 (0.719 sec)
7.825... logprob:  0.286873, 0.062500 (0.694 sec)
7.826... logprob:  0.375202, 0.093750 (0.690 sec)
7.827... logprob:  0.420802, 0.109375 (0.692 sec)
7.828... logprob:  0.443990, 0.117188 (0.691 sec)
7.829... logprob:  0.505351, 0.140625 (0.693 sec)
7.830... logprob:  0.442589, 0.117188 (1.513 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.24986267089844, 10.0]}, 128)
batch 872: ({'logprob': [68.36251831054688, 19.0]}, 128)
batch 873: ({'logprob': [39.41364288330078, 9.0]}, 128)
batch 874: ({'logprob': [44.790985107421875, 11.0]}, 128)
batch 875: ({'logprob': [50.841766357421875, 13.0]}, 128)
batch 876: ({'logprob': [65.5137939453125, 18.0]}, 128)
batch 877: ({'logprob': [45.1290283203125, 11.0]}, 128)
batch 878: ({'logprob': [62.97138214111328, 17.0]}, 128)
batch 879: ({'logprob': [75.41658020019531, 21.0]}, 128)
batch 880: ({'logprob': [50.8529167175293, 13.0]}, 128)
batch 881: ({'logprob': [26.94066619873047, 5.0]}, 128)
batch 882: ({'logprob': [54.722251892089844, 14.0]}, 128)
batch 883: ({'logprob': [62.9638557434082, 17.0]}, 128)
batch 884: ({'logprob': [51.17499923706055, 13.0]}, 128)
batch 885: ({'logprob': [51.85205078125, 13.0]}, 128)
batch 886: ({'logprob': [63.30335235595703, 17.0]}, 128)

======================Test output======================
logprob:  0.417724, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.974929e-03 [3.705631e-09] 
Layer 'conv1' biases: 4.911165e-08 [1.052927e-10] 
Layer 'conv2' weights[0]: 7.961917e-03 [3.169068e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.257361e-10] 
Layer 'conv3' weights[0]: 7.960228e-03 [3.129463e-09] 
Layer 'conv3' biases: 4.725259e-07 [1.973053e-09] 
Layer 'conv4' weights[0]: 7.992764e-03 [3.431442e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.885965e-08] 
Layer 'conv5' weights[0]: 7.991728e-03 [1.268771e-07] 
Layer 'conv5' biases: 9.999999e-01 [1.379968e-07] 
Layer 'fc6' weights[0]: 7.588455e-03 [1.124784e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.151293e-08] 
Layer 'fc7' weights[0]: 7.619888e-03 [7.134186e-08] 
Layer 'fc7' biases: 9.998702e-01 [5.381177e-08] 
Layer 'fc8' weights[0]: 1.355924e-03 [6.557263e-06] 
Layer 'fc8' biases: 1.509492e-02 [3.505225e-05] 
Train error last 870 batches: 0.435314
-------------------------------------------------------
Not saving because 0.417724 > 0.415712 (4.190: -0.00%)
======================================================= (12.091 sec)
7.831... logprob:  0.514326, 0.140625 (1.463 sec)
7.832... logprob:  0.330907, 0.078125 (1.464 sec)
7.833... logprob:  0.488864, 0.132812 (1.510 sec)
7.834... logprob:  0.433005, 0.117188 (1.451 sec)
7.835... logprob:  0.542185, 0.148438 (1.462 sec)
7.836... logprob:  0.376584, 0.093750 (1.450 sec)
7.837... logprob:  0.315465, 0.070312 (1.449 sec)
7.838... logprob:  0.437121, 0.117188 (1.459 sec)
7.839... logprob:  0.471917, 0.125000 (1.505 sec)
7.840... logprob:  0.555129, 0.156250 (1.451 sec)
7.841... logprob:  0.396496, 0.101562 (1.467 sec)
7.842... logprob:  0.497745, 0.140625 (1.492 sec)
7.843... logprob:  0.465601, 0.125000 (1.457 sec)
7.844... logprob:  0.497571, 0.140625 (1.459 sec)
7.845... logprob:  0.486937, 0.132812 (1.448 sec)
7.846... logprob:  0.468579, 0.125000 (1.454 sec)
7.847... logprob:  0.362895, 0.085938 (1.452 sec)
7.848... logprob:  0.396806, 0.101562 (1.504 sec)
7.849... logprob:  0.359945, 0.085938 (1.456 sec)
7.850... logprob:  0.479518, 0.132812 (1.478 sec)
7.851... logprob:  0.440202, 0.117188 (1.492 sec)
7.852... logprob:  0.546365, 0.156250 (1.463 sec)
7.853... logprob:  0.371641, 0.093750 (1.462 sec)
7.854... logprob:  0.306753, 0.070312 (1.450 sec)
7.855... logprob:  0.485210, 0.132812 (1.449 sec)
7.856... logprob:  0.444002, 0.117188 (1.454 sec)
7.857... logprob:  0.372299, 0.093750 (1.495 sec)
7.858... logprob:  0.396252, 0.101562 (1.464 sec)
7.859... logprob:  0.307959, 0.070312 (1.468 sec)
7.860... logprob:  0.565848, 0.156250 (1.491 sec)
7.861... logprob:  0.417848, 0.109375 (1.453 sec)
7.862... logprob:  0.329045, 0.078125 (1.455 sec)
7.863... logprob:  0.399465, 0.101562 (1.452 sec)
7.864... logprob:  0.451308, 0.117188 (1.447 sec)
7.865... logprob:  0.484244, 0.132812 (1.454 sec)
7.866... logprob:  0.507284, 0.140625 (1.491 sec)
7.867... logprob:  0.502575, 0.140625 (1.466 sec)
7.868... logprob:  0.405566, 0.101562 (1.474 sec)
7.869... logprob:  0.383578, 0.093750 (1.483 sec)
7.870... logprob:  0.551760, 0.156250 (1.394 sec)
8.1... logprob:  0.380394, 0.093750 (1.404 sec)
8.2... logprob:  0.448291, 0.117188 (1.447 sec)
8.3... logprob:  0.398540, 0.101562 (1.417 sec)
8.4... logprob:  0.443396, 0.117188 (1.433 sec)
8.5... logprob:  0.443337, 0.117188 (1.435 sec)
8.6... logprob:  0.499389, 0.140625 (1.394 sec)
8.7... logprob:  0.362806, 0.085938 (1.423 sec)
8.8... logprob:  0.419095, 0.109375 (1.393 sec)
8.9... logprob:  0.358467, 0.085938 (1.400 sec)
8.10... logprob:  0.377238, 0.093750 (1.408 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.126312255859375, 10.0]}, 128)
batch 872: ({'logprob': [67.17784118652344, 19.0]}, 128)
batch 873: ({'logprob': [40.12013244628906, 9.0]}, 128)
batch 874: ({'logprob': [45.25817108154297, 11.0]}, 128)
batch 875: ({'logprob': [50.838706970214844, 13.0]}, 128)
batch 876: ({'logprob': [64.50627136230469, 18.0]}, 128)
batch 877: ({'logprob': [45.48185348510742, 11.0]}, 128)
batch 878: ({'logprob': [62.02635192871094, 17.0]}, 128)
batch 879: ({'logprob': [73.41468811035156, 21.0]}, 128)
batch 880: ({'logprob': [50.85000991821289, 13.0]}, 128)
batch 881: ({'logprob': [28.705211639404297, 5.0]}, 128)
batch 882: ({'logprob': [54.192779541015625, 14.0]}, 128)
batch 883: ({'logprob': [62.018531799316406, 17.0]}, 128)
batch 884: ({'logprob': [51.05474090576172, 13.0]}, 128)
batch 885: ({'logprob': [51.4991455078125, 13.0]}, 128)
batch 886: ({'logprob': [62.241451263427734, 17.0]}, 128)

======================Test output======================
logprob:  0.415777, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.974894e-03 [2.716470e-09] 
Layer 'conv1' biases: 4.983816e-08 [7.713676e-11] 
Layer 'conv2' weights[0]: 7.961884e-03 [2.364482e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.760891e-10] 
Layer 'conv3' weights[0]: 7.960182e-03 [2.378914e-09] 
Layer 'conv3' biases: 4.779636e-07 [1.434492e-09] 
Layer 'conv4' weights[0]: 7.992725e-03 [2.736261e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.495430e-08] 
Layer 'conv5' weights[0]: 7.991688e-03 [1.031237e-07] 
Layer 'conv5' biases: 9.999998e-01 [1.122160e-07] 
Layer 'fc6' weights[0]: 7.588416e-03 [9.096663e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.162059e-09] 
Layer 'fc7' weights[0]: 7.617969e-03 [2.905850e-07] 
Layer 'fc7' biases: 9.998692e-01 [2.784716e-07] 
Layer 'fc8' weights[0]: 1.312336e-03 [1.105919e-05] 
Layer 'fc8' biases: 1.499530e-02 [7.141764e-05] 
Train error last 870 batches: 0.435314
-------------------------------------------------------
Not saving because 0.415777 > 0.415712 (4.190: -0.00%)
======================================================= (12.061 sec)
8.11... logprob:  0.334283, 0.078125 (1.452 sec)
8.12... logprob:  0.466716, 0.125000 (1.400 sec)
8.13... logprob:  0.442578, 0.117188 (1.424 sec)
8.14... logprob:  0.444969, 0.117188 (1.400 sec)
8.15... logprob:  0.395804, 0.101562 (1.410 sec)
8.16... logprob:  0.421546, 0.109375 (1.401 sec)
8.17... logprob:  0.516150, 0.140625 (1.399 sec)
8.18... logprob:  0.262144, 0.054688 (1.401 sec)
8.19... logprob:  0.279819, 0.062500 (1.401 sec)
8.20... logprob:  0.421396, 0.109375 (1.410 sec)
8.21... logprob:  0.443936, 0.117188 (0.887 sec)
8.22... logprob:  0.536431, 0.148438 (1.323 sec)
8.23... logprob:  0.532532, 0.148438 (1.414 sec)
8.24... logprob:  0.311012, 0.070312 (0.986 sec)
8.25... logprob:  0.356487, 0.085938 (0.958 sec)
8.26... logprob:  0.463587, 0.125000 (1.451 sec)
8.27... logprob:  0.404720, 0.101562 (1.392 sec)
8.28... logprob:  0.421904, 0.109375 (1.413 sec)
8.29... logprob:  0.396166, 0.101562 (1.429 sec)
8.30... logprob:  0.374263, 0.093750 (1.416 sec)
8.31... logprob:  0.479857, 0.132812 (1.404 sec)
8.32... logprob:  0.457246, 0.125000 (1.389 sec)
8.33... logprob:  0.460682, 0.125000 (1.449 sec)
8.34... logprob:  0.464745, 0.125000 (1.390 sec)
8.35... logprob:  0.316100, 0.070312 (1.403 sec)
8.36... logprob:  0.475781, 0.132812 (1.406 sec)
8.37... logprob:  0.417616, 0.109375 (1.403 sec)
8.38... logprob:  0.392363, 0.101562 (1.399 sec)
8.39... logprob:  0.632197, 0.187500 (1.461 sec)
8.40... logprob:  0.446008, 0.117188 (1.410 sec)
8.41... logprob:  0.352633, 0.085938 (1.419 sec)
8.42... logprob:  0.391697, 0.101562 (1.422 sec)
8.43... logprob:  0.440174, 0.117188 (1.407 sec)
8.44... logprob:  0.518401, 0.148438 (1.436 sec)
8.45... logprob:  0.381891, 0.093750 (1.393 sec)
8.46... logprob:  0.486544, 0.132812 (1.397 sec)
8.47... logprob:  0.331804, 0.078125 (1.401 sec)
8.48... logprob:  0.498818, 0.140625 (1.421 sec)
8.49... logprob:  0.510397, 0.148438 (1.416 sec)
8.50... logprob:  0.393283, 0.101562 (1.424 sec)
8.51... logprob:  0.489776, 0.140625 (1.417 sec)
8.52... logprob:  0.525822, 0.148438 (1.395 sec)
8.53... logprob:  0.295190, 0.062500 (1.451 sec)
8.54... logprob:  0.403063, 0.109375 (1.387 sec)
8.55... logprob:  0.331838, 0.078125 (1.404 sec)
8.56... logprob:  0.421813, 0.109375 (1.401 sec)
8.57... logprob:  0.572732, 0.164062 (1.432 sec)
8.58... logprob:  0.407990, 0.101562 (1.406 sec)
8.59... logprob:  0.333855, 0.078125 (1.466 sec)
8.60... logprob:  0.619304, 0.179688 (1.425 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.33256912231445, 10.0]}, 128)
batch 872: ({'logprob': [66.45694732666016, 19.0]}, 128)
batch 873: ({'logprob': [40.87382888793945, 9.0]}, 128)
batch 874: ({'logprob': [45.17473602294922, 11.0]}, 128)
batch 875: ({'logprob': [50.8231086730957, 13.0]}, 128)
batch 876: ({'logprob': [63.97671890258789, 18.0]}, 128)
batch 877: ({'logprob': [45.85006332397461, 11.0]}, 128)
batch 878: ({'logprob': [62.14238739013672, 17.0]}, 128)
batch 879: ({'logprob': [74.11305236816406, 21.0]}, 128)
batch 880: ({'logprob': [50.83262634277344, 13.0]}, 128)
batch 881: ({'logprob': [28.87565803527832, 5.0]}, 128)
batch 882: ({'logprob': [55.33780288696289, 14.0]}, 128)
batch 883: ({'logprob': [62.13491439819336, 17.0]}, 128)
batch 884: ({'logprob': [51.48970413208008, 13.0]}, 128)
batch 885: ({'logprob': [52.83713912963867, 13.0]}, 128)
batch 886: ({'logprob': [62.808677673339844, 17.0]}, 128)

======================Test output======================
logprob:  0.417510, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.974860e-03 [3.407351e-09] 
Layer 'conv1' biases: 5.051285e-08 [9.226958e-11] 
Layer 'conv2' weights[0]: 7.961853e-03 [2.703347e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.762981e-10] 
Layer 'conv3' weights[0]: 7.960145e-03 [2.827205e-09] 
Layer 'conv3' biases: 4.836215e-07 [1.824194e-09] 
Layer 'conv4' weights[0]: 7.992678e-03 [3.152467e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.833687e-08] 
Layer 'conv5' weights[0]: 7.991647e-03 [1.267320e-07] 
Layer 'conv5' biases: 1.000000e+00 [1.378764e-07] 
Layer 'fc6' weights[0]: 7.588381e-03 [1.104823e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.131298e-08] 
Layer 'fc7' weights[0]: 7.616050e-03 [1.019824e-07] 
Layer 'fc7' biases: 9.998695e-01 [8.733225e-08] 
Layer 'fc8' weights[0]: 1.312830e-03 [3.002511e-06] 
Layer 'fc8' biases: 1.505207e-02 [1.724348e-05] 
Train error last 870 batches: 0.435314
-------------------------------------------------------
Not saving because 0.417510 > 0.415712 (4.190: -0.00%)
======================================================= (12.053 sec)
8.61... logprob:  0.382942, 0.093750 (1.436 sec)
8.62... logprob:  0.474954, 0.132812 (1.465 sec)
8.63... logprob:  0.397330, 0.101562 (1.436 sec)
8.64... logprob:  0.450222, 0.125000 (1.409 sec)
8.65... logprob:  0.373270, 0.093750 (1.404 sec)
8.66... logprob:  0.353967, 0.085938 (1.446 sec)
8.67... logprob:  0.295356, 0.062500 (1.387 sec)
8.68... logprob:  0.396843, 0.101562 (1.404 sec)
8.69... logprob:  0.496947, 0.140625 (1.423 sec)
8.70... logprob:  0.325879, 0.078125 (1.429 sec)
8.71... logprob:  0.381894, 0.101562 (1.462 sec)
8.72... logprob:  0.493914, 0.132812 (1.405 sec)
8.73... logprob:  0.447816, 0.117188 (1.427 sec)
8.74... logprob:  0.442636, 0.117188 (1.416 sec)
8.75... logprob:  0.380623, 0.093750 (1.417 sec)
8.76... logprob:  0.412132, 0.109375 (1.437 sec)
8.77... logprob:  0.396346, 0.101562 (1.433 sec)
8.78... logprob:  0.493122, 0.140625 (1.458 sec)
8.79... logprob:  0.456443, 0.125000 (1.399 sec)
8.80... logprob:  0.507726, 0.132812 (1.426 sec)
8.81... logprob:  0.416720, 0.109375 (1.417 sec)
8.82... logprob:  0.232115, 0.039062 (1.425 sec)
8.83... logprob:  0.493700, 0.140625 (1.410 sec)
8.84... logprob:  0.468027, 0.125000 (1.465 sec)
8.85... logprob:  0.432129, 0.117188 (1.421 sec)
8.86... logprob:  0.417045, 0.109375 (1.418 sec)
8.87... logprob:  0.633135, 0.187500 (1.421 sec)
8.88... logprob:  0.535203, 0.156250 (1.407 sec)
8.89... logprob:  0.410698, 0.109375 (1.441 sec)
8.90... logprob:  0.577562, 0.171875 (1.390 sec)
8.91... logprob:  0.348601, 0.078125 (1.399 sec)
8.92... logprob:  0.464447, 0.125000 (1.406 sec)
8.93... logprob:  0.492349, 0.140625 (1.405 sec)
8.94... logprob:  0.428780, 0.109375 (1.399 sec)
8.95... logprob:  0.471871, 0.125000 (1.400 sec)
8.96... logprob:  0.576465, 0.171875 (1.414 sec)
8.97... logprob:  0.430764, 0.117188 (1.400 sec)
8.98... logprob:  0.390920, 0.093750 (1.436 sec)
8.99... logprob:  0.474408, 0.132812 (1.411 sec)
8.100... logprob:  0.310252, 0.070312 (1.401 sec)
8.101... logprob:  0.310309, 0.062500 (1.446 sec)
8.102... logprob:  0.546635, 0.156250 (1.391 sec)
8.103... logprob:  0.541614, 0.156250 (1.400 sec)
8.104... logprob:  0.388949, 0.101562 (1.406 sec)
8.105... logprob:  0.620105, 0.179688 (1.393 sec)
8.106... logprob:  0.344442, 0.085938 (1.393 sec)
8.107... logprob:  0.335645, 0.078125 (1.444 sec)
8.108... logprob:  0.586764, 0.171875 (1.396 sec)
8.109... logprob:  0.336268, 0.078125 (1.403 sec)
8.110... logprob:  0.564282, 0.164062 (1.401 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.75548553466797, 10.0]}, 128)
batch 872: ({'logprob': [66.4509506225586, 19.0]}, 128)
batch 873: ({'logprob': [40.735164642333984, 9.0]}, 128)
batch 874: ({'logprob': [45.27495193481445, 11.0]}, 128)
batch 875: ({'logprob': [50.807945251464844, 13.0]}, 128)
batch 876: ({'logprob': [63.94029235839844, 18.0]}, 128)
batch 877: ({'logprob': [45.773719787597656, 11.0]}, 128)
batch 878: ({'logprob': [61.897674560546875, 17.0]}, 128)
batch 879: ({'logprob': [73.46233367919922, 21.0]}, 128)
batch 880: ({'logprob': [50.8181037902832, 13.0]}, 128)
batch 881: ({'logprob': [29.143535614013672, 5.0]}, 128)
batch 882: ({'logprob': [54.823238372802734, 14.0]}, 128)
batch 883: ({'logprob': [61.88999557495117, 17.0]}, 128)
batch 884: ({'logprob': [51.297760009765625, 13.0]}, 128)
batch 885: ({'logprob': [52.29119873046875, 13.0]}, 128)
batch 886: ({'logprob': [62.38694763183594, 17.0]}, 128)

======================Test output======================
logprob:  0.416381, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.974818e-03 [3.141388e-09] 
Layer 'conv1' biases: 5.114554e-08 [8.162878e-11] 
Layer 'conv2' weights[0]: 7.961817e-03 [2.892910e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.006501e-10] 
Layer 'conv3' weights[0]: 7.960106e-03 [2.750422e-09] 
Layer 'conv3' biases: 4.888617e-07 [1.591961e-09] 
Layer 'conv4' weights[0]: 7.992631e-03 [3.077449e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.545294e-08] 
Layer 'conv5' weights[0]: 7.991614e-03 [1.061128e-07] 
Layer 'conv5' biases: 1.000000e+00 [1.154345e-07] 
Layer 'fc6' weights[0]: 7.588340e-03 [9.468023e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.509588e-09] 
Layer 'fc7' weights[0]: 7.614133e-03 [1.830075e-07] 
Layer 'fc7' biases: 9.998693e-01 [1.714229e-07] 
Layer 'fc8' weights[0]: 1.306241e-03 [7.196156e-06] 
Layer 'fc8' biases: 1.511119e-02 [4.191987e-05] 
Train error last 870 batches: 0.435314
-------------------------------------------------------
Not saving because 0.416381 > 0.415712 (4.190: -0.00%)
======================================================= (12.023 sec)
8.111... logprob:  0.404786, 0.101562 (1.397 sec)
8.112... logprob:  0.366321, 0.093750 (1.402 sec)
8.113... logprob:  0.354831, 0.085938 (1.404 sec)
8.114... logprob:  0.440258, 0.117188 (1.436 sec)
8.115... logprob:  0.506726, 0.140625 (1.418 sec)
8.116... logprob:  0.393441, 0.101562 (1.403 sec)
8.117... logprob:  0.440401, 0.117188 (1.443 sec)
8.118... logprob:  0.409253, 0.101562 (1.402 sec)
8.119... logprob:  0.346153, 0.085938 (1.408 sec)
8.120... logprob:  0.547189, 0.156250 (1.409 sec)
8.121... logprob:  0.412747, 0.109375 (1.409 sec)
8.122... logprob:  0.519448, 0.148438 (1.459 sec)
8.123... logprob:  0.463818, 0.125000 (1.395 sec)
8.124... logprob:  0.447726, 0.125000 (1.415 sec)
8.125... logprob:  0.502077, 0.140625 (1.410 sec)
8.126... logprob:  0.475894, 0.125000 (1.403 sec)
8.127... logprob:  0.479759, 0.125000 (1.403 sec)
8.128... logprob:  0.422426, 0.109375 (1.429 sec)
8.129... logprob:  0.574927, 0.164062 (1.427 sec)
8.130... logprob:  0.382790, 0.093750 (1.425 sec)
8.131... logprob:  0.495506, 0.132812 (1.427 sec)
8.132... logprob:  0.506406, 0.140625 (1.446 sec)
8.133... logprob:  0.444676, 0.117188 (1.395 sec)
8.134... logprob:  0.401943, 0.101562 (1.400 sec)
8.135... logprob:  0.460295, 0.125000 (1.419 sec)
8.136... logprob:  0.562734, 0.164062 (1.405 sec)
8.137... logprob:  0.462553, 0.125000 (1.392 sec)
8.138... logprob:  0.319319, 0.070312 (1.449 sec)
8.139... logprob:  0.395894, 0.101562 (1.413 sec)
8.140... logprob:  0.560878, 0.164062 (1.423 sec)
8.141... logprob:  0.464486, 0.125000 (1.452 sec)
8.142... logprob:  0.464564, 0.125000 (1.410 sec)
8.143... logprob:  0.294189, 0.062500 (1.439 sec)
8.144... logprob:  0.457555, 0.125000 (1.435 sec)
8.145... logprob:  0.325104, 0.078125 (1.434 sec)
8.146... logprob:  0.483346, 0.132812 (1.426 sec)
8.147... logprob:  0.262530, 0.054688 (1.443 sec)
8.148... logprob:  0.458995, 0.125000 (1.430 sec)
8.149... logprob:  0.442598, 0.117188 (1.405 sec)
8.150... logprob:  0.347685, 0.085938 (1.406 sec)
8.151... logprob:  0.347172, 0.085938 (1.406 sec)
8.152... logprob:  0.784833, 0.234375 (1.393 sec)
8.153... logprob:  0.381708, 0.093750 (1.456 sec)
8.154... logprob:  0.524177, 0.148438 (1.415 sec)
8.155... logprob:  0.425842, 0.117188 (1.417 sec)
8.156... logprob:  0.296331, 0.062500 (1.435 sec)
8.157... logprob:  0.271192, 0.054688 (1.394 sec)
8.158... logprob:  0.455308, 0.125000 (1.405 sec)
8.159... logprob:  0.483154, 0.132812 (1.415 sec)
8.160... logprob:  0.445074, 0.117188 (1.400 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.915916442871094, 10.0]}, 128)
batch 872: ({'logprob': [66.10604858398438, 19.0]}, 128)
batch 873: ({'logprob': [41.28264236450195, 9.0]}, 128)
batch 874: ({'logprob': [45.52854919433594, 11.0]}, 128)
batch 875: ({'logprob': [50.96052169799805, 13.0]}, 128)
batch 876: ({'logprob': [63.69377517700195, 18.0]}, 128)
batch 877: ({'logprob': [46.12389373779297, 11.0]}, 128)
batch 878: ({'logprob': [61.84672164916992, 17.0]}, 128)
batch 879: ({'logprob': [73.30366516113281, 21.0]}, 128)
batch 880: ({'logprob': [50.970306396484375, 13.0]}, 128)
batch 881: ({'logprob': [29.798669815063477, 5.0]}, 128)
batch 882: ({'logprob': [55.16434860229492, 14.0]}, 128)
batch 883: ({'logprob': [61.838924407958984, 17.0]}, 128)
batch 884: ({'logprob': [51.54567337036133, 13.0]}, 128)
batch 885: ({'logprob': [52.73093032836914, 13.0]}, 128)
batch 886: ({'logprob': [62.431583404541016, 17.0]}, 128)

======================Test output======================
logprob:  0.417599, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.974785e-03 [1.714141e-09] 
Layer 'conv1' biases: 5.174317e-08 [2.823649e-11] 
Layer 'conv2' weights[0]: 7.961782e-03 [1.349259e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.102125e-10] 
Layer 'conv3' weights[0]: 7.960065e-03 [1.118195e-09] 
Layer 'conv3' biases: 4.937556e-07 [3.396447e-10] 
Layer 'conv4' weights[0]: 7.992591e-03 [1.085735e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.616924e-09] 
Layer 'conv5' weights[0]: 7.991570e-03 [8.399486e-09] 
Layer 'conv5' biases: 1.000000e+00 [8.863503e-09] 
Layer 'fc6' weights[0]: 7.588295e-03 [1.100114e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.559785e-10] 
Layer 'fc7' weights[0]: 7.612186e-03 [4.145930e-08] 
Layer 'fc7' biases: 9.998689e-01 [1.311999e-08] 
Layer 'fc8' weights[0]: 1.299110e-03 [4.299852e-06] 
Layer 'fc8' biases: 1.515225e-02 [2.459835e-05] 
Train error last 870 batches: 0.435313
-------------------------------------------------------
Not saving because 0.417599 > 0.415712 (4.190: -0.00%)
======================================================= (12.291 sec)
8.161... logprob:  0.350540, 0.078125 (1.421 sec)
8.162... logprob:  0.611906, 0.179688 (1.411 sec)
8.163... logprob:  0.450352, 0.125000 (1.436 sec)
8.164... logprob:  0.468873, 0.125000 (1.423 sec)
8.165... logprob:  0.548161, 0.156250 (1.421 sec)
8.166... logprob:  0.445950, 0.125000 (1.453 sec)
8.167... logprob:  0.350216, 0.085938 (1.435 sec)
8.168... logprob:  0.363640, 0.085938 (1.431 sec)
8.169... logprob:  0.408774, 0.101562 (1.460 sec)
8.170... logprob:  0.459525, 0.125000 (1.401 sec)
8.171... logprob:  0.535608, 0.156250 (1.426 sec)
8.172... logprob:  0.434969, 0.109375 (1.426 sec)
8.173... logprob:  0.440527, 0.117188 (1.426 sec)
8.174... logprob:  0.601444, 0.171875 (1.409 sec)
8.175... logprob:  0.506238, 0.140625 (1.480 sec)
8.176... logprob:  0.478563, 0.132812 (1.417 sec)
8.177... logprob:  0.289793, 0.054688 (1.428 sec)
8.178... logprob:  0.383488, 0.093750 (1.469 sec)
8.179... logprob:  0.394793, 0.101562 (1.410 sec)
8.180... logprob:  0.466350, 0.125000 (1.420 sec)
8.181... logprob:  0.539542, 0.156250 (1.419 sec)
8.182... logprob:  0.371529, 0.093750 (1.420 sec)
8.183... logprob:  0.419979, 0.109375 (1.413 sec)
8.184... logprob:  0.483519, 0.132812 (1.424 sec)
8.185... logprob:  0.289964, 0.062500 (1.390 sec)
8.186... logprob:  0.370663, 0.093750 (1.403 sec)
8.187... logprob:  0.529634, 0.148438 (1.402 sec)
8.188... logprob:  0.459112, 0.125000 (1.398 sec)
8.189... logprob:  0.440905, 0.117188 (1.388 sec)
8.190... logprob:  0.375713, 0.093750 (1.437 sec)
8.191... logprob:  0.485113, 0.132812 (1.410 sec)
8.192... logprob:  0.520316, 0.148438 (1.417 sec)
8.193... logprob:  0.312700, 0.070312 (1.421 sec)
8.194... logprob:  0.414172, 0.109375 (1.414 sec)
8.195... logprob:  0.287376, 0.062500 (1.404 sec)
8.196... logprob:  0.410637, 0.109375 (1.391 sec)
8.197... logprob:  0.478065, 0.132812 (1.405 sec)
8.198... logprob:  0.355795, 0.085938 (1.404 sec)
8.199... logprob:  0.437195, 0.117188 (1.388 sec)
8.200... logprob:  0.440804, 0.117188 (1.442 sec)
8.201... logprob:  0.437101, 0.117188 (1.405 sec)
8.202... logprob:  0.538071, 0.148438 (1.406 sec)
8.203... logprob:  0.420510, 0.109375 (1.440 sec)
8.204... logprob:  0.504138, 0.140625 (1.394 sec)
8.205... logprob:  0.334453, 0.078125 (1.401 sec)
8.206... logprob:  0.361585, 0.093750 (1.407 sec)
8.207... logprob:  0.382016, 0.093750 (1.391 sec)
8.208... logprob:  0.490457, 0.140625 (1.401 sec)
8.209... logprob:  0.334646, 0.078125 (1.421 sec)
8.210... logprob:  0.586274, 0.171875 (1.421 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.68267822265625, 10.0]}, 128)
batch 872: ({'logprob': [66.32674407958984, 19.0]}, 128)
batch 873: ({'logprob': [40.92251968383789, 9.0]}, 128)
batch 874: ({'logprob': [45.31128692626953, 11.0]}, 128)
batch 875: ({'logprob': [50.84127426147461, 13.0]}, 128)
batch 876: ({'logprob': [63.85456848144531, 18.0]}, 128)
batch 877: ({'logprob': [45.884071350097656, 11.0]}, 128)
batch 878: ({'logprob': [61.924591064453125, 17.0]}, 128)
batch 879: ({'logprob': [73.55612182617188, 21.0]}, 128)
batch 880: ({'logprob': [50.85139846801758, 13.0]}, 128)
batch 881: ({'logprob': [29.26359748840332, 5.0]}, 128)
batch 882: ({'logprob': [55.03940963745117, 14.0]}, 128)
batch 883: ({'logprob': [61.91666793823242, 17.0]}, 128)
batch 884: ({'logprob': [51.404762268066406, 13.0]}, 128)
batch 885: ({'logprob': [52.54584884643555, 13.0]}, 128)
batch 886: ({'logprob': [62.48757553100586, 17.0]}, 128)

======================Test output======================
logprob:  0.416901, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.974744e-03 [2.393396e-09] 
Layer 'conv1' biases: 5.244423e-08 [9.617363e-11] 
Layer 'conv2' weights[0]: 7.961740e-03 [1.892663e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.337678e-10] 
Layer 'conv3' weights[0]: 7.960028e-03 [2.009051e-09] 
Layer 'conv3' biases: 4.995324e-07 [1.254553e-09] 
Layer 'conv4' weights[0]: 7.992549e-03 [2.153872e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.224720e-08] 
Layer 'conv5' weights[0]: 7.991533e-03 [8.390869e-08] 
Layer 'conv5' biases: 1.000000e+00 [9.112647e-08] 
Layer 'fc6' weights[0]: 7.588256e-03 [7.409960e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.495326e-09] 
Layer 'fc7' weights[0]: 7.610253e-03 [8.071997e-08] 
Layer 'fc7' biases: 9.998690e-01 [6.453090e-08] 
Layer 'fc8' weights[0]: 1.313474e-03 [4.784893e-06] 
Layer 'fc8' biases: 1.532178e-02 [2.926827e-05] 
Train error last 870 batches: 0.435311
-------------------------------------------------------
Not saving because 0.416901 > 0.415712 (4.190: -0.00%)
======================================================= (12.033 sec)
8.211... logprob:  0.488272, 0.132812 (1.424 sec)
8.212... logprob:  0.526200, 0.148438 (1.421 sec)
8.213... logprob:  0.515003, 0.140625 (1.464 sec)
8.214... logprob:  0.459470, 0.125000 (1.430 sec)
8.215... logprob:  0.396156, 0.101562 (1.453 sec)
8.216... logprob:  0.517296, 0.140625 (1.463 sec)
8.217... logprob:  0.325223, 0.070312 (1.406 sec)
8.218... logprob:  0.463777, 0.125000 (1.419 sec)
8.219... logprob:  0.500372, 0.140625 (1.422 sec)
8.220... logprob:  0.414978, 0.109375 (1.419 sec)
8.221... logprob:  0.399528, 0.101562 (1.417 sec)
8.222... logprob:  0.554688, 0.164062 (1.464 sec)
8.223... logprob:  0.569408, 0.164062 (1.430 sec)
8.224... logprob:  0.405817, 0.101562 (1.429 sec)
8.225... logprob:  0.391981, 0.101562 (1.448 sec)
8.226... logprob:  0.424567, 0.109375 (1.425 sec)
8.227... logprob:  0.452840, 0.125000 (1.416 sec)
8.228... logprob:  0.417243, 0.109375 (1.422 sec)
8.229... logprob:  0.489338, 0.132812 (1.413 sec)
8.230... logprob:  0.459929, 0.125000 (1.437 sec)
8.231... logprob:  0.453599, 0.125000 (1.405 sec)
8.232... logprob:  0.496281, 0.140625 (1.461 sec)
8.233... logprob:  0.466275, 0.132812 (1.431 sec)
8.234... logprob:  0.563763, 0.164062 (1.417 sec)
8.235... logprob:  0.482051, 0.132812 (1.463 sec)
8.236... logprob:  0.425880, 0.109375 (1.409 sec)
8.237... logprob:  0.341557, 0.078125 (1.425 sec)
8.238... logprob:  0.389526, 0.093750 (1.414 sec)
8.239... logprob:  0.478188, 0.132812 (1.419 sec)
8.240... logprob:  0.485829, 0.132812 (1.397 sec)
8.241... logprob:  0.493622, 0.132812 (1.462 sec)
8.242... logprob:  0.341651, 0.078125 (1.427 sec)
8.243... logprob:  0.386026, 0.093750 (1.434 sec)
8.244... logprob:  0.315110, 0.070312 (1.448 sec)
8.245... logprob:  0.494417, 0.132812 (1.426 sec)
8.246... logprob:  0.416959, 0.109375 (1.414 sec)
8.247... logprob:  0.357229, 0.085938 (1.421 sec)
8.248... logprob:  0.307591, 0.070312 (1.417 sec)
8.249... logprob:  0.555961, 0.156250 (1.424 sec)
8.250... logprob:  0.591985, 0.164062 (1.409 sec)
8.251... logprob:  0.352867, 0.085938 (1.459 sec)
8.252... logprob:  0.348566, 0.085938 (1.427 sec)
8.253... logprob:  0.379115, 0.093750 (1.419 sec)
8.254... logprob:  0.444188, 0.117188 (1.466 sec)
8.255... logprob:  0.351613, 0.085938 (1.409 sec)
8.256... logprob:  0.378655, 0.093750 (1.420 sec)
8.257... logprob:  0.332079, 0.078125 (1.443 sec)
8.258... logprob:  0.415986, 0.109375 (1.420 sec)
8.259... logprob:  0.442336, 0.117188 (1.407 sec)
8.260... logprob:  0.308508, 0.070312 (1.459 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.89011764526367, 10.0]}, 128)
batch 872: ({'logprob': [67.85900115966797, 19.0]}, 128)
batch 873: ({'logprob': [39.63121795654297, 9.0]}, 128)
batch 874: ({'logprob': [45.05595016479492, 11.0]}, 128)
batch 875: ({'logprob': [50.834537506103516, 13.0]}, 128)
batch 876: ({'logprob': [65.06709289550781, 18.0]}, 128)
batch 877: ({'logprob': [45.235233306884766, 11.0]}, 128)
batch 878: ({'logprob': [62.42097473144531, 17.0]}, 128)
batch 879: ({'logprob': [74.16324615478516, 21.0]}, 128)
batch 880: ({'logprob': [50.84663772583008, 13.0]}, 128)
batch 881: ({'logprob': [27.861448287963867, 5.0]}, 128)
batch 882: ({'logprob': [54.179935455322266, 14.0]}, 128)
batch 883: ({'logprob': [62.41265106201172, 17.0]}, 128)
batch 884: ({'logprob': [51.007896423339844, 13.0]}, 128)
batch 885: ({'logprob': [51.36507034301758, 13.0]}, 128)
batch 886: ({'logprob': [62.592750549316406, 17.0]}, 128)

======================Test output======================
logprob:  0.416223, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.974706e-03 [1.835865e-09] 
Layer 'conv1' biases: 5.312598e-08 [4.829357e-11] 
Layer 'conv2' weights[0]: 7.961702e-03 [1.595118e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.496625e-10] 
Layer 'conv3' weights[0]: 7.959987e-03 [1.584265e-09] 
Layer 'conv3' biases: 5.036978e-07 [7.916867e-10] 
Layer 'conv4' weights[0]: 7.992510e-03 [1.790274e-09] 
Layer 'conv4' biases: 9.999999e-01 [8.043136e-09] 
Layer 'conv5' weights[0]: 7.991489e-03 [5.560100e-08] 
Layer 'conv5' biases: 9.999999e-01 [6.041905e-08] 
Layer 'fc6' weights[0]: 7.588213e-03 [4.948130e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.934313e-09] 
Layer 'fc7' weights[0]: 7.608304e-03 [7.874561e-08] 
Layer 'fc7' biases: 9.998693e-01 [6.159538e-08] 
Layer 'fc8' weights[0]: 1.346476e-03 [2.620775e-06] 
Layer 'fc8' biases: 1.563221e-02 [1.730190e-05] 
Train error last 870 batches: 0.435311
-------------------------------------------------------
Not saving because 0.416223 > 0.415712 (4.190: -0.00%)
======================================================= (12.094 sec)
8.261... logprob:  0.393030, 0.101562 (1.446 sec)
8.262... logprob:  0.524872, 0.148438 (1.439 sec)
8.263... logprob:  0.425386, 0.109375 (1.449 sec)
8.264... logprob:  0.375240, 0.093750 (1.426 sec)
8.265... logprob:  0.439630, 0.117188 (1.419 sec)
8.266... logprob:  0.439075, 0.117188 (1.416 sec)
8.267... logprob:  0.421994, 0.109375 (1.421 sec)
8.268... logprob:  0.458957, 0.125000 (1.421 sec)
8.269... logprob:  0.567418, 0.164062 (1.408 sec)
8.270... logprob:  0.542143, 0.156250 (1.458 sec)
8.271... logprob:  0.445855, 0.117188 (1.433 sec)
8.272... logprob:  0.384866, 0.093750 (1.414 sec)
8.273... logprob:  0.500210, 0.140625 (1.471 sec)
8.274... logprob:  0.542582, 0.156250 (1.400 sec)
8.275... logprob:  0.487864, 0.132812 (1.513 sec)
8.276... logprob:  0.390267, 0.093750 (1.412 sec)
8.277... logprob:  0.428804, 0.109375 (1.428 sec)
8.278... logprob:  0.323246, 0.070312 (1.420 sec)
8.279... logprob:  0.324832, 0.070312 (1.467 sec)
8.280... logprob:  0.214778, 0.031250 (1.405 sec)
8.281... logprob:  0.417211, 0.109375 (1.425 sec)
8.282... logprob:  0.411532, 0.109375 (1.419 sec)
8.283... logprob:  0.393912, 0.101562 (1.416 sec)
8.284... logprob:  0.394840, 0.101562 (1.417 sec)
8.285... logprob:  0.452508, 0.117188 (1.439 sec)
8.286... logprob:  0.538033, 0.140625 (1.440 sec)
8.287... logprob:  0.346749, 0.085938 (1.432 sec)
8.288... logprob:  0.330010, 0.078125 (1.438 sec)
8.289... logprob:  0.446123, 0.117188 (1.440 sec)
8.290... logprob:  0.490635, 0.132812 (1.443 sec)
8.291... logprob:  0.439071, 0.117188 (1.422 sec)
8.292... logprob:  0.566722, 0.156250 (1.416 sec)
8.293... logprob:  0.427366, 0.117188 (1.421 sec)
8.294... logprob:  0.356435, 0.085938 (1.408 sec)
8.295... logprob:  0.335515, 0.078125 (1.464 sec)
8.296... logprob:  0.356567, 0.085938 (1.423 sec)
8.297... logprob:  0.395042, 0.101562 (1.423 sec)
8.298... logprob:  0.448008, 0.125000 (1.467 sec)
8.299... logprob:  0.342974, 0.078125 (1.410 sec)
8.300... logprob:  0.406880, 0.101562 (1.423 sec)
8.301... logprob:  0.397999, 0.101562 (1.420 sec)
8.302... logprob:  0.591539, 0.179688 (1.418 sec)
8.303... logprob:  0.459737, 0.125000 (1.412 sec)
8.304... logprob:  0.459773, 0.125000 (1.436 sec)
8.305... logprob:  0.455261, 0.125000 (1.444 sec)
8.306... logprob:  0.440649, 0.117188 (1.432 sec)
8.307... logprob:  0.421609, 0.109375 (1.445 sec)
8.308... logprob:  0.374428, 0.093750 (1.457 sec)
8.309... logprob:  0.450484, 0.125000 (1.417 sec)
8.310... logprob:  0.473889, 0.125000 (1.421 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.73825454711914, 10.0]}, 128)
batch 872: ({'logprob': [66.21082305908203, 19.0]}, 128)
batch 873: ({'logprob': [41.11201095581055, 9.0]}, 128)
batch 874: ({'logprob': [45.399620056152344, 11.0]}, 128)
batch 875: ({'logprob': [50.8953971862793, 13.0]}, 128)
batch 876: ({'logprob': [63.7723503112793, 18.0]}, 128)
batch 877: ({'logprob': [46.005855560302734, 11.0]}, 128)
batch 878: ({'logprob': [61.909828186035156, 17.0]}, 128)
batch 879: ({'logprob': [73.50574493408203, 21.0]}, 128)
batch 880: ({'logprob': [50.905372619628906, 13.0]}, 128)
batch 881: ({'logprob': [29.48872947692871, 5.0]}, 128)
batch 882: ({'logprob': [55.159446716308594, 14.0]}, 128)
batch 883: ({'logprob': [61.901859283447266, 17.0]}, 128)
batch 884: ({'logprob': [51.4920539855957, 13.0]}, 128)
batch 885: ({'logprob': [52.6996955871582, 13.0]}, 128)
batch 886: ({'logprob': [62.50598907470703, 17.0]}, 128)

======================Test output======================
logprob:  0.417335, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.974661e-03 [2.100430e-09] 
Layer 'conv1' biases: 5.391342e-08 [3.657409e-11] 
Layer 'conv2' weights[0]: 7.961659e-03 [1.277641e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.148298e-10] 
Layer 'conv3' weights[0]: 7.959955e-03 [1.072142e-09] 
Layer 'conv3' biases: 5.097912e-07 [3.763605e-10] 
Layer 'conv4' weights[0]: 7.992473e-03 [1.061401e-09] 
Layer 'conv4' biases: 9.999999e-01 [2.462374e-09] 
Layer 'conv5' weights[0]: 7.991449e-03 [1.587817e-08] 
Layer 'conv5' biases: 1.000000e+00 [1.691729e-08] 
Layer 'fc6' weights[0]: 7.588178e-03 [1.611122e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.415365e-09] 
Layer 'fc7' weights[0]: 7.606370e-03 [4.131493e-08] 
Layer 'fc7' biases: 9.998689e-01 [1.314332e-08] 
Layer 'fc8' weights[0]: 1.310071e-03 [5.981079e-07] 
Layer 'fc8' biases: 1.567140e-02 [6.298577e-06] 
Train error last 870 batches: 0.435310
-------------------------------------------------------
Not saving because 0.417335 > 0.415712 (4.190: -0.00%)
======================================================= (12.068 sec)
8.311... logprob:  0.502768, 0.140625 (1.444 sec)
8.312... logprob:  0.478866, 0.132812 (1.437 sec)
8.313... logprob:  0.454878, 0.125000 (1.421 sec)
8.314... logprob:  0.454637, 0.117188 (1.464 sec)
8.315... logprob:  0.314714, 0.070312 (1.438 sec)
8.316... logprob:  0.468629, 0.125000 (1.421 sec)
8.317... logprob:  0.355583, 0.085938 (1.492 sec)
8.318... logprob:  0.455439, 0.125000 (1.411 sec)
8.319... logprob:  0.423257, 0.117188 (1.425 sec)
8.320... logprob:  0.412288, 0.109375 (1.431 sec)
8.321... logprob:  0.348324, 0.085938 (1.424 sec)
8.322... logprob:  0.387591, 0.101562 (1.416 sec)
8.323... logprob:  0.416542, 0.109375 (1.499 sec)
8.324... logprob:  0.498678, 0.140625 (1.431 sec)
8.325... logprob:  0.350690, 0.085938 (1.434 sec)
8.326... logprob:  0.543196, 0.148438 (1.466 sec)
8.327... logprob:  0.554421, 0.164062 (1.422 sec)
8.328... logprob:  0.564965, 0.156250 (1.432 sec)
8.329... logprob:  0.402057, 0.101562 (1.424 sec)
8.330... logprob:  0.388759, 0.101562 (1.421 sec)
8.331... logprob:  0.352675, 0.085938 (1.422 sec)
8.332... logprob:  0.482814, 0.132812 (1.447 sec)
8.333... logprob:  0.339703, 0.085938 (1.448 sec)
8.334... logprob:  0.565020, 0.171875 (1.442 sec)
8.335... logprob:  0.358969, 0.085938 (1.438 sec)
8.336... logprob:  0.444804, 0.125000 (1.462 sec)
8.337... logprob:  0.566536, 0.164062 (1.418 sec)
8.338... logprob:  0.449509, 0.125000 (1.419 sec)
8.339... logprob:  0.488795, 0.132812 (1.429 sec)
8.340... logprob:  0.442102, 0.117188 (1.426 sec)
8.341... logprob:  0.530236, 0.148438 (1.420 sec)
8.342... logprob:  0.429761, 0.109375 (1.465 sec)
8.343... logprob:  0.434832, 0.109375 (1.432 sec)
8.344... logprob:  0.444357, 0.125000 (1.479 sec)
8.345... logprob:  0.488326, 0.132812 (1.438 sec)
8.346... logprob:  0.436276, 0.117188 (1.440 sec)
8.347... logprob:  0.372249, 0.085938 (1.483 sec)
8.348... logprob:  0.398428, 0.101562 (1.439 sec)
8.349... logprob:  0.498064, 0.140625 (1.428 sec)
8.350... logprob:  0.358456, 0.085938 (1.434 sec)
8.351... logprob:  0.508790, 0.140625 (1.427 sec)
8.352... logprob:  0.363735, 0.093750 (1.431 sec)
8.353... logprob:  0.513044, 0.148438 (1.488 sec)
8.354... logprob:  0.675359, 0.203125 (1.435 sec)
8.355... logprob:  0.357449, 0.085938 (1.446 sec)
8.356... logprob:  0.479279, 0.132812 (1.479 sec)
8.357... logprob:  0.347240, 0.085938 (1.435 sec)
8.358... logprob:  0.326157, 0.070312 (1.437 sec)
8.359... logprob:  0.555174, 0.164062 (1.431 sec)
8.360... logprob:  0.444508, 0.117188 (1.424 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.11030197143555, 10.0]}, 128)
batch 872: ({'logprob': [66.11100006103516, 19.0]}, 128)
batch 873: ({'logprob': [41.274818420410156, 9.0]}, 128)
batch 874: ({'logprob': [45.60107421875, 11.0]}, 128)
batch 875: ({'logprob': [50.98354721069336, 13.0]}, 128)
batch 876: ({'logprob': [63.691280364990234, 18.0]}, 128)
batch 877: ({'logprob': [46.1317253112793, 11.0]}, 128)
batch 878: ({'logprob': [61.771507263183594, 17.0]}, 128)
batch 879: ({'logprob': [73.06509399414062, 21.0]}, 128)
batch 880: ({'logprob': [50.99385070800781, 13.0]}, 128)
batch 881: ({'logprob': [29.954118728637695, 5.0]}, 128)
batch 882: ({'logprob': [55.000831604003906, 14.0]}, 128)
batch 883: ({'logprob': [61.763309478759766, 17.0]}, 128)
batch 884: ({'logprob': [51.504024505615234, 13.0]}, 128)
batch 885: ({'logprob': [52.55945587158203, 13.0]}, 128)
batch 886: ({'logprob': [62.29142379760742, 17.0]}, 128)

======================Test output======================
logprob:  0.417386, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.974623e-03 [2.567392e-09] 
Layer 'conv1' biases: 5.452088e-08 [3.916326e-11] 
Layer 'conv2' weights[0]: 7.961618e-03 [1.694454e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.319640e-10] 
Layer 'conv3' weights[0]: 7.959914e-03 [1.246942e-09] 
Layer 'conv3' biases: 5.150010e-07 [3.778056e-10] 
Layer 'conv4' weights[0]: 7.992432e-03 [1.211618e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.179782e-09] 
Layer 'conv5' weights[0]: 7.991422e-03 [7.920961e-09] 
Layer 'conv5' biases: 1.000000e+00 [8.400857e-09] 
Layer 'fc6' weights[0]: 7.588141e-03 [1.063411e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.061430e-10] 
Layer 'fc7' weights[0]: 7.604442e-03 [6.481005e-08] 
Layer 'fc7' biases: 9.998687e-01 [4.677570e-08] 
Layer 'fc8' weights[0]: 1.302612e-03 [1.609265e-06] 
Layer 'fc8' biases: 1.572207e-02 [8.557506e-06] 
Train error last 870 batches: 0.435310
-------------------------------------------------------
Not saving because 0.417386 > 0.415712 (4.190: -0.00%)
======================================================= (12.123 sec)
8.361... logprob:  0.410777, 0.101562 (1.441 sec)
8.362... logprob:  0.424283, 0.117188 (1.480 sec)
8.363... logprob:  0.486586, 0.132812 (1.437 sec)
8.364... logprob:  0.475479, 0.125000 (1.447 sec)
8.365... logprob:  0.425113, 0.109375 (1.459 sec)
8.366... logprob:  0.409799, 0.109375 (1.448 sec)
8.367... logprob:  0.325090, 0.078125 (1.439 sec)
8.368... logprob:  0.595761, 0.171875 (1.434 sec)
8.369... logprob:  0.381451, 0.093750 (1.426 sec)
8.370... logprob:  0.381080, 0.093750 (1.442 sec)
8.371... logprob:  0.400303, 0.101562 (1.455 sec)
8.372... logprob:  0.537833, 0.156250 (1.450 sec)
8.373... logprob:  0.463854, 0.125000 (1.457 sec)
8.374... logprob:  0.527234, 0.148438 (1.451 sec)
8.375... logprob:  0.393808, 0.101562 (1.466 sec)
8.376... logprob:  0.374351, 0.093750 (1.436 sec)
8.377... logprob:  0.295352, 0.062500 (1.423 sec)
8.378... logprob:  0.453845, 0.125000 (1.428 sec)
8.379... logprob:  0.420235, 0.109375 (1.434 sec)
8.380... logprob:  0.605801, 0.179688 (1.439 sec)
8.381... logprob:  0.463533, 0.125000 (1.461 sec)
8.382... logprob:  0.529451, 0.148438 (1.457 sec)
8.383... logprob:  0.358806, 0.085938 (1.436 sec)
8.384... logprob:  0.520950, 0.148438 (1.479 sec)
8.385... logprob:  0.523410, 0.148438 (1.437 sec)
8.386... logprob:  0.582218, 0.171875 (1.423 sec)
8.387... logprob:  0.428779, 0.117188 (1.429 sec)
8.388... logprob:  0.521288, 0.148438 (1.441 sec)
8.389... logprob:  0.426109, 0.109375 (1.431 sec)
8.390... logprob:  0.420061, 0.109375 (1.476 sec)
8.391... logprob:  0.318446, 0.070312 (1.441 sec)
8.392... logprob:  0.439397, 0.117188 (1.429 sec)
8.393... logprob:  0.368703, 0.093750 (1.483 sec)
8.394... logprob:  0.343379, 0.078125 (1.432 sec)
8.395... logprob:  0.331376, 0.078125 (1.427 sec)
8.396... logprob:  0.251462, 0.046875 (1.439 sec)
8.397... logprob:  0.485113, 0.132812 (1.431 sec)
8.398... logprob:  0.471912, 0.125000 (1.436 sec)
8.399... logprob:  0.434042, 0.117188 (1.484 sec)
8.400... logprob:  0.539231, 0.148438 (1.434 sec)
8.401... logprob:  0.466501, 0.125000 (1.439 sec)
8.402... logprob:  0.474550, 0.125000 (1.478 sec)
8.403... logprob:  0.462313, 0.125000 (1.429 sec)
8.404... logprob:  0.474861, 0.125000 (1.438 sec)
8.405... logprob:  0.543553, 0.156250 (1.434 sec)
8.406... logprob:  0.358180, 0.085938 (1.425 sec)
8.407... logprob:  0.492459, 0.140625 (1.431 sec)
8.408... logprob:  0.340350, 0.078125 (1.486 sec)
8.409... logprob:  0.401420, 0.101562 (1.439 sec)
8.410... logprob:  0.581446, 0.171875 (1.455 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.074562072753906, 10.0]}, 128)
batch 872: ({'logprob': [65.67084503173828, 19.0]}, 128)
batch 873: ({'logprob': [42.77769470214844, 9.0]}, 128)
batch 874: ({'logprob': [46.58187484741211, 11.0]}, 128)
batch 875: ({'logprob': [51.66594314575195, 13.0]}, 128)
batch 876: ({'logprob': [63.45553207397461, 18.0]}, 128)
batch 877: ({'logprob': [47.22489547729492, 11.0]}, 128)
batch 878: ({'logprob': [61.85371398925781, 17.0]}, 128)
batch 879: ({'logprob': [72.65856170654297, 21.0]}, 128)
batch 880: ({'logprob': [51.67544174194336, 13.0]}, 128)
batch 881: ({'logprob': [31.946447372436523, 5.0]}, 128)
batch 882: ({'logprob': [55.80917739868164, 14.0]}, 128)
batch 883: ({'logprob': [61.84552764892578, 17.0]}, 128)
batch 884: ({'logprob': [52.29583740234375, 13.0]}, 128)
batch 885: ({'logprob': [53.57261276245117, 13.0]}, 128)
batch 886: ({'logprob': [62.48362731933594, 17.0]}, 128)

======================Test output======================
logprob:  0.422164, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.974590e-03 [2.300924e-09] 
Layer 'conv1' biases: 5.519042e-08 [3.210056e-11] 
Layer 'conv2' weights[0]: 7.961582e-03 [1.508483e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.382785e-10] 
Layer 'conv3' weights[0]: 7.959874e-03 [1.226285e-09] 
Layer 'conv3' biases: 5.206507e-07 [4.535997e-10] 
Layer 'conv4' weights[0]: 7.992396e-03 [1.354403e-09] 
Layer 'conv4' biases: 9.999999e-01 [3.935893e-09] 
Layer 'conv5' weights[0]: 7.991376e-03 [2.712830e-08] 
Layer 'conv5' biases: 1.000001e+00 [2.931845e-08] 
Layer 'fc6' weights[0]: 7.588099e-03 [2.507176e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.384072e-09] 
Layer 'fc7' weights[0]: 7.602520e-03 [2.148412e-07] 
Layer 'fc7' biases: 9.998682e-01 [2.030861e-07] 
Layer 'fc8' weights[0]: 1.268296e-03 [8.122884e-06] 
Layer 'fc8' biases: 1.570166e-02 [4.254480e-05] 
Train error last 870 batches: 0.435310
-------------------------------------------------------
Not saving because 0.422164 > 0.415712 (4.190: -0.00%)
======================================================= (12.055 sec)
8.411... logprob:  0.398648, 0.101562 (1.484 sec)
8.412... logprob:  0.540173, 0.156250 (1.435 sec)
8.413... logprob:  0.544814, 0.156250 (1.440 sec)
8.414... logprob:  0.466808, 0.125000 (1.436 sec)
8.415... logprob:  0.401828, 0.101562 (1.422 sec)
8.416... logprob:  0.427595, 0.109375 (1.442 sec)
8.417... logprob:  0.405357, 0.093750 (1.465 sec)
8.418... logprob:  0.379796, 0.093750 (1.454 sec)
8.419... logprob:  0.417304, 0.101562 (1.454 sec)
8.420... logprob:  0.355474, 0.085938 (1.455 sec)
8.421... logprob:  0.376565, 0.101562 (1.462 sec)
8.422... logprob:  0.523905, 0.148438 (1.439 sec)
8.423... logprob:  0.421224, 0.109375 (1.420 sec)
8.424... logprob:  0.324449, 0.078125 (1.431 sec)
8.425... logprob:  0.305864, 0.070312 (1.437 sec)
8.426... logprob:  0.449677, 0.117188 (1.450 sec)
8.427... logprob:  0.555758, 0.156250 (1.464 sec)
8.428... logprob:  0.602870, 0.171875 (1.447 sec)
8.429... logprob:  0.426150, 0.109375 (1.445 sec)
8.430... logprob:  0.300189, 0.070312 (1.470 sec)
8.431... logprob:  0.598610, 0.171875 (1.434 sec)
8.432... logprob:  0.387647, 0.093750 (1.425 sec)
8.433... logprob:  0.330819, 0.078125 (1.427 sec)
8.434... logprob:  0.528688, 0.148438 (1.433 sec)
8.435... logprob:  0.531750, 0.156250 (1.426 sec)
8.436... logprob:  0.382108, 0.093750 (1.474 sec)
8.437... logprob:  0.500175, 0.140625 (1.443 sec)
8.438... logprob:  0.546628, 0.156250 (1.428 sec)
8.439... logprob:  0.379671, 0.093750 (1.488 sec)
8.440... logprob:  0.440045, 0.117188 (1.435 sec)
8.441... logprob:  0.468094, 0.125000 (1.428 sec)
8.442... logprob:  0.378860, 0.093750 (1.441 sec)
8.443... logprob:  0.496619, 0.140625 (1.432 sec)
8.444... logprob:  0.371819, 0.093750 (1.430 sec)
8.445... logprob:  0.361756, 0.085938 (1.482 sec)
8.446... logprob:  0.397863, 0.101562 (1.440 sec)
8.447... logprob:  0.571117, 0.164062 (1.442 sec)
8.448... logprob:  0.332102, 0.078125 (1.479 sec)
8.449... logprob:  0.400034, 0.101562 (1.426 sec)
8.450... logprob:  0.238126, 0.046875 (1.431 sec)
8.451... logprob:  0.453472, 0.125000 (1.435 sec)
8.452... logprob:  0.456669, 0.117188 (1.430 sec)
8.453... logprob:  0.455851, 0.125000 (1.428 sec)
8.454... logprob:  0.489521, 0.132812 (1.482 sec)
8.455... logprob:  0.506164, 0.140625 (1.434 sec)
8.456... logprob:  0.468748, 0.125000 (1.446 sec)
8.457... logprob:  0.375463, 0.093750 (1.472 sec)
8.458... logprob:  0.351468, 0.085938 (1.432 sec)
8.459... logprob:  0.513323, 0.140625 (1.436 sec)
8.460... logprob:  0.275418, 0.054688 (1.432 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.766693115234375, 10.0]}, 128)
batch 872: ({'logprob': [66.34664916992188, 19.0]}, 128)
batch 873: ({'logprob': [40.879432678222656, 9.0]}, 128)
batch 874: ({'logprob': [45.32764434814453, 11.0]}, 128)
batch 875: ({'logprob': [50.83892822265625, 13.0]}, 128)
batch 876: ({'logprob': [63.86443328857422, 18.0]}, 128)
batch 877: ({'logprob': [45.86145782470703, 11.0]}, 128)
batch 878: ({'logprob': [61.88536834716797, 17.0]}, 128)
batch 879: ({'logprob': [73.44087219238281, 21.0]}, 128)
batch 880: ({'logprob': [50.849334716796875, 13.0]}, 128)
batch 881: ({'logprob': [29.296602249145508, 5.0]}, 128)
batch 882: ({'logprob': [54.93061447143555, 14.0]}, 128)
batch 883: ({'logprob': [61.87720489501953, 17.0]}, 128)
batch 884: ({'logprob': [51.36376190185547, 13.0]}, 128)
batch 885: ({'logprob': [52.426856994628906, 13.0]}, 128)
batch 886: ({'logprob': [62.40933609008789, 17.0]}, 128)

======================Test output======================
logprob:  0.416682, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.974554e-03 [2.339049e-09] 
Layer 'conv1' biases: 5.580056e-08 [6.921111e-11] 
Layer 'conv2' weights[0]: 7.961544e-03 [2.436047e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.206164e-10] 
Layer 'conv3' weights[0]: 7.959832e-03 [2.414416e-09] 
Layer 'conv3' biases: 5.251719e-07 [1.307844e-09] 
Layer 'conv4' weights[0]: 7.992360e-03 [2.673895e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.274961e-08] 
Layer 'conv5' weights[0]: 7.991344e-03 [8.526461e-08] 
Layer 'conv5' biases: 1.000000e+00 [9.265337e-08] 
Layer 'fc6' weights[0]: 7.588064e-03 [7.564133e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.638966e-09] 
Layer 'fc7' weights[0]: 7.600569e-03 [9.576708e-08] 
Layer 'fc7' biases: 9.998690e-01 [8.103839e-08] 
Layer 'fc8' weights[0]: 1.308860e-03 [3.003058e-06] 
Layer 'fc8' biases: 1.632337e-02 [1.624677e-05] 
Train error last 870 batches: 0.435309
-------------------------------------------------------
Not saving because 0.416682 > 0.415712 (4.190: -0.00%)
======================================================= (12.056 sec)
8.461... logprob:  0.459874, 0.125000 (1.432 sec)
8.462... logprob:  0.471857, 0.125000 (1.439 sec)
8.463... logprob:  0.421092, 0.109375 (1.467 sec)
8.464... logprob:  0.482613, 0.132812 (1.441 sec)
8.465... logprob:  0.421314, 0.109375 (1.447 sec)
8.466... logprob:  0.318892, 0.070312 (1.460 sec)
8.467... logprob:  0.413894, 0.109375 (1.447 sec)
8.468... logprob:  0.394274, 0.101562 (1.437 sec)
8.469... logprob:  0.334484, 0.078125 (1.427 sec)
8.470... logprob:  0.400014, 0.101562 (1.429 sec)
8.471... logprob:  0.530028, 0.148438 (1.434 sec)
8.472... logprob:  0.410202, 0.109375 (1.451 sec)
8.473... logprob:  0.375232, 0.093750 (1.459 sec)
8.474... logprob:  0.466057, 0.125000 (1.451 sec)
8.475... logprob:  0.504868, 0.140625 (1.444 sec)
8.476... logprob:  0.510751, 0.140625 (1.467 sec)
8.477... logprob:  0.334412, 0.078125 (1.436 sec)
8.478... logprob:  0.464330, 0.125000 (1.422 sec)
8.479... logprob:  0.305876, 0.070312 (1.429 sec)
8.480... logprob:  0.443527, 0.117188 (1.441 sec)
8.481... logprob:  0.547648, 0.156250 (1.435 sec)
8.482... logprob:  0.443233, 0.117188 (1.486 sec)
8.483... logprob:  0.502459, 0.140625 (1.444 sec)
8.484... logprob:  0.485274, 0.132812 (1.429 sec)
8.485... logprob:  0.409255, 0.109375 (1.476 sec)
8.486... logprob:  0.361918, 0.085938 (1.431 sec)
8.487... logprob:  0.522570, 0.148438 (1.421 sec)
8.488... logprob:  0.425058, 0.109375 (1.431 sec)
8.489... logprob:  0.416060, 0.109375 (1.432 sec)
8.490... logprob:  0.440711, 0.117188 (1.429 sec)
8.491... logprob:  0.313763, 0.070312 (1.483 sec)
8.492... logprob:  0.459695, 0.125000 (1.439 sec)
8.493... logprob:  0.522143, 0.148438 (1.430 sec)
8.494... logprob:  0.450419, 0.125000 (1.476 sec)
8.495... logprob:  0.380432, 0.093750 (1.432 sec)
8.496... logprob:  0.550829, 0.156250 (1.430 sec)
8.497... logprob:  0.467194, 0.125000 (1.432 sec)
8.498... logprob:  0.476467, 0.132812 (1.428 sec)
8.499... logprob:  0.456337, 0.125000 (1.430 sec)
8.500... logprob:  0.355023, 0.085938 (1.486 sec)
8.501... logprob:  0.339125, 0.078125 (1.428 sec)
8.502... logprob:  0.459729, 0.125000 (1.445 sec)
8.503... logprob:  0.400736, 0.101562 (1.482 sec)
8.504... logprob:  0.487409, 0.132812 (1.430 sec)
8.505... logprob:  0.570833, 0.164062 (1.444 sec)
8.506... logprob:  0.479680, 0.132812 (1.434 sec)
8.507... logprob:  0.385264, 0.093750 (1.426 sec)
8.508... logprob:  0.374864, 0.093750 (1.425 sec)
8.509... logprob:  0.323434, 0.070312 (1.476 sec)
8.510... logprob:  0.390511, 0.101562 (1.444 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.81611633300781, 10.0]}, 128)
batch 872: ({'logprob': [66.58961486816406, 19.0]}, 128)
batch 873: ({'logprob': [40.56999206542969, 9.0]}, 128)
batch 874: ({'logprob': [45.24636459350586, 11.0]}, 128)
batch 875: ({'logprob': [50.78929138183594, 13.0]}, 128)
batch 876: ({'logprob': [64.0428466796875, 18.0]}, 128)
batch 877: ({'logprob': [45.68206024169922, 11.0]}, 128)
batch 878: ({'logprob': [61.90034103393555, 17.0]}, 128)
batch 879: ({'logprob': [73.42266082763672, 21.0]}, 128)
batch 880: ({'logprob': [50.800209045410156, 13.0]}, 128)
batch 881: ({'logprob': [29.020538330078125, 5.0]}, 128)
batch 882: ({'logprob': [54.65281295776367, 14.0]}, 128)
batch 883: ({'logprob': [61.89198303222656, 17.0]}, 128)
batch 884: ({'logprob': [51.21670150756836, 13.0]}, 128)
batch 885: ({'logprob': [52.084110260009766, 13.0]}, 128)
batch 886: ({'logprob': [62.32672119140625, 17.0]}, 128)

======================Test output======================
logprob:  0.416041, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.974520e-03 [3.226359e-09] 
Layer 'conv1' biases: 5.630593e-08 [1.013505e-10] 
Layer 'conv2' weights[0]: 7.961500e-03 [2.463990e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.837331e-10] 
Layer 'conv3' weights[0]: 7.959794e-03 [2.545192e-09] 
Layer 'conv3' biases: 5.297127e-07 [1.461364e-09] 
Layer 'conv4' weights[0]: 7.992321e-03 [2.876409e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.447390e-08] 
Layer 'conv5' weights[0]: 7.991277e-03 [9.978519e-08] 
Layer 'conv5' biases: 9.999998e-01 [1.085031e-07] 
Layer 'fc6' weights[0]: 7.588025e-03 [8.793512e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.863325e-09] 
Layer 'fc7' weights[0]: 7.598671e-03 [1.716068e-07] 
Layer 'fc7' biases: 9.998690e-01 [1.588201e-07] 
Layer 'fc8' weights[0]: 1.311929e-03 [6.564239e-06] 
Layer 'fc8' biases: 1.645956e-02 [4.212496e-05] 
Train error last 870 batches: 0.435309
-------------------------------------------------------
Not saving because 0.416041 > 0.415712 (4.190: -0.00%)
======================================================= (12.045 sec)
8.511... logprob:  0.410123, 0.109375 (1.459 sec)
8.512... logprob:  0.470787, 0.125000 (1.469 sec)
8.513... logprob:  0.324992, 0.078125 (1.441 sec)
8.514... logprob:  0.406281, 0.101562 (1.434 sec)
8.515... logprob:  0.455745, 0.125000 (1.429 sec)
8.516... logprob:  0.400597, 0.109375 (1.420 sec)
8.517... logprob:  0.628348, 0.179688 (1.443 sec)
8.518... logprob:  0.437800, 0.117188 (1.460 sec)
8.519... logprob:  0.516196, 0.140625 (1.453 sec)
8.520... logprob:  0.409670, 0.109375 (1.457 sec)
8.521... logprob:  0.427617, 0.109375 (1.461 sec)
8.522... logprob:  0.533009, 0.156250 (1.463 sec)
8.523... logprob:  0.332015, 0.078125 (1.444 sec)
8.524... logprob:  0.437321, 0.117188 (1.424 sec)
8.525... logprob:  0.426280, 0.109375 (1.428 sec)
8.526... logprob:  0.352252, 0.078125 (1.436 sec)
8.527... logprob:  0.504516, 0.140625 (1.435 sec)
8.528... logprob:  0.440584, 0.117188 (1.467 sec)
8.529... logprob:  0.353039, 0.085938 (1.453 sec)
8.530... logprob:  0.440251, 0.117188 (1.439 sec)
8.531... logprob:  0.440084, 0.117188 (1.472 sec)
8.532... logprob:  0.467491, 0.125000 (1.430 sec)
8.533... logprob:  0.561055, 0.164062 (1.427 sec)
8.534... logprob:  0.325672, 0.078125 (1.430 sec)
8.535... logprob:  0.551921, 0.156250 (1.435 sec)
8.536... logprob:  0.507537, 0.140625 (1.438 sec)
8.537... logprob:  0.510161, 0.140625 (1.485 sec)
8.538... logprob:  0.486147, 0.132812 (1.455 sec)
8.539... logprob:  0.296258, 0.062500 (1.436 sec)
8.540... logprob:  0.447188, 0.117188 (1.486 sec)
8.541... logprob:  0.389001, 0.101562 (1.433 sec)
8.542... logprob:  0.411402, 0.109375 (1.429 sec)
8.543... logprob:  0.233573, 0.039062 (1.438 sec)
8.544... logprob:  0.317974, 0.070312 (1.433 sec)
8.545... logprob:  0.348837, 0.085938 (1.431 sec)
8.546... logprob:  0.368322, 0.093750 (1.478 sec)
8.547... logprob:  0.440264, 0.117188 (1.433 sec)
8.548... logprob:  0.453488, 0.125000 (1.443 sec)
8.549... logprob:  0.490974, 0.132812 (1.479 sec)
8.550... logprob:  0.367782, 0.093750 (1.436 sec)
8.551... logprob:  0.441953, 0.117188 (1.438 sec)
8.552... logprob:  0.471405, 0.125000 (1.437 sec)
8.553... logprob:  0.349425, 0.085938 (1.426 sec)
8.554... logprob:  0.506711, 0.140625 (1.434 sec)
8.555... logprob:  0.421431, 0.109375 (1.491 sec)
8.556... logprob:  0.356083, 0.085938 (1.435 sec)
8.557... logprob:  0.396614, 0.101562 (1.449 sec)
8.558... logprob:  0.383116, 0.101562 (1.466 sec)
8.559... logprob:  0.441284, 0.125000 (1.432 sec)
8.560... logprob:  0.335617, 0.078125 (1.437 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.68684768676758, 10.0]}, 128)
batch 872: ({'logprob': [66.18209075927734, 19.0]}, 128)
batch 873: ({'logprob': [41.18878936767578, 9.0]}, 128)
batch 874: ({'logprob': [45.40992736816406, 11.0]}, 128)
batch 875: ({'logprob': [50.914981842041016, 13.0]}, 128)
batch 876: ({'logprob': [63.758155822753906, 18.0]}, 128)
batch 877: ({'logprob': [46.054100036621094, 11.0]}, 128)
batch 878: ({'logprob': [61.94818878173828, 17.0]}, 128)
batch 879: ({'logprob': [73.6003646850586, 21.0]}, 128)
batch 880: ({'logprob': [50.92507553100586, 13.0]}, 128)
batch 881: ({'logprob': [29.509170532226562, 5.0]}, 128)
batch 882: ({'logprob': [55.27871322631836, 14.0]}, 128)
batch 883: ({'logprob': [61.939849853515625, 17.0]}, 128)
batch 884: ({'logprob': [51.54986572265625, 13.0]}, 128)
batch 885: ({'logprob': [52.83350372314453, 13.0]}, 128)
batch 886: ({'logprob': [62.58234405517578, 17.0]}, 128)

======================Test output======================
logprob:  0.417657, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.974477e-03 [2.841363e-09] 
Layer 'conv1' biases: 5.701744e-08 [8.517128e-11] 
Layer 'conv2' weights[0]: 7.961462e-03 [2.163232e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.159862e-10] 
Layer 'conv3' weights[0]: 7.959751e-03 [2.325008e-09] 
Layer 'conv3' biases: 5.362526e-07 [1.242857e-09] 
Layer 'conv4' weights[0]: 7.992283e-03 [2.635599e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.255518e-08] 
Layer 'conv5' weights[0]: 7.991242e-03 [8.673646e-08] 
Layer 'conv5' biases: 9.999999e-01 [9.426671e-08] 
Layer 'fc6' weights[0]: 7.587986e-03 [7.636674e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.707967e-09] 
Layer 'fc7' weights[0]: 7.596685e-03 [4.800657e-08] 
Layer 'fc7' biases: 9.998690e-01 [2.348018e-08] 
Layer 'fc8' weights[0]: 1.303036e-03 [5.425491e-06] 
Layer 'fc8' biases: 1.653566e-02 [3.184281e-05] 
Train error last 870 batches: 0.435308
-------------------------------------------------------
Not saving because 0.417657 > 0.415712 (4.190: -0.00%)
======================================================= (12.064 sec)
8.561... logprob:  0.411895, 0.109375 (1.438 sec)
8.562... logprob:  0.503117, 0.140625 (1.424 sec)
8.563... logprob:  0.373950, 0.093750 (1.440 sec)
8.564... logprob:  0.468364, 0.132812 (1.468 sec)
8.565... logprob:  0.610937, 0.187500 (1.452 sec)
8.566... logprob:  0.374965, 0.093750 (1.451 sec)
8.567... logprob:  0.423598, 0.109375 (1.454 sec)
8.568... logprob:  0.496443, 0.140625 (1.452 sec)
8.569... logprob:  0.508046, 0.140625 (1.433 sec)
8.570... logprob:  0.543654, 0.164062 (1.421 sec)
8.571... logprob:  0.454871, 0.125000 (1.429 sec)
8.572... logprob:  0.501616, 0.140625 (1.435 sec)
8.573... logprob:  0.512678, 0.148438 (1.446 sec)
8.574... logprob:  0.428288, 0.109375 (1.461 sec)
8.575... logprob:  0.343409, 0.078125 (1.448 sec)
8.576... logprob:  0.427489, 0.109375 (1.440 sec)
8.577... logprob:  0.460919, 0.125000 (1.475 sec)
8.578... logprob:  0.336444, 0.078125 (1.432 sec)
8.579... logprob:  0.442110, 0.117188 (1.428 sec)
8.580... logprob:  0.547221, 0.156250 (1.430 sec)
8.581... logprob:  0.531342, 0.156250 (1.443 sec)
8.582... logprob:  0.438010, 0.125000 (1.435 sec)
8.583... logprob:  0.593232, 0.171875 (1.476 sec)
8.584... logprob:  0.468189, 0.132812 (1.450 sec)
8.585... logprob:  0.349784, 0.085938 (1.436 sec)
8.586... logprob:  0.313242, 0.070312 (1.484 sec)
8.587... logprob:  0.404331, 0.101562 (1.433 sec)
8.588... logprob:  0.418710, 0.117188 (1.427 sec)
8.589... logprob:  0.361460, 0.093750 (1.434 sec)
8.590... logprob:  0.524631, 0.148438 (1.438 sec)
8.591... logprob:  0.397569, 0.101562 (1.431 sec)
8.592... logprob:  0.455623, 0.125000 (1.488 sec)
8.593... logprob:  0.467456, 0.125000 (1.436 sec)
8.594... logprob:  0.352914, 0.085938 (1.444 sec)
8.595... logprob:  0.428673, 0.109375 (1.481 sec)
8.596... logprob:  0.461558, 0.125000 (1.445 sec)
8.597... logprob:  0.397402, 0.101562 (1.431 sec)
8.598... logprob:  0.397237, 0.101562 (1.431 sec)
8.599... logprob:  0.313426, 0.070312 (1.429 sec)
8.600... logprob:  0.340921, 0.085938 (1.428 sec)
8.601... logprob:  0.402083, 0.101562 (1.490 sec)
8.602... logprob:  0.289501, 0.062500 (1.434 sec)
8.603... logprob:  0.266705, 0.054688 (1.450 sec)
8.604... logprob:  0.407473, 0.101562 (1.474 sec)
8.605... logprob:  0.563767, 0.148438 (1.429 sec)
8.606... logprob:  0.295986, 0.070312 (1.437 sec)
8.607... logprob:  0.505076, 0.132812 (1.430 sec)
8.608... logprob:  0.361492, 0.085938 (1.424 sec)
8.609... logprob:  0.356807, 0.085938 (1.440 sec)
8.610... logprob:  0.493551, 0.132812 (1.475 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.144859313964844, 10.0]}, 128)
batch 872: ({'logprob': [68.18811798095703, 19.0]}, 128)
batch 873: ({'logprob': [39.51152801513672, 9.0]}, 128)
batch 874: ({'logprob': [44.7666015625, 11.0]}, 128)
batch 875: ({'logprob': [50.8079948425293, 13.0]}, 128)
batch 876: ({'logprob': [65.37309265136719, 18.0]}, 128)
batch 877: ({'logprob': [45.16135025024414, 11.0]}, 128)
batch 878: ({'logprob': [62.92008590698242, 17.0]}, 128)
batch 879: ({'logprob': [75.40304565429688, 21.0]}, 128)
batch 880: ({'logprob': [50.81972122192383, 13.0]}, 128)
batch 881: ({'logprob': [27.000070571899414, 5.0]}, 128)
batch 882: ({'logprob': [54.82587814331055, 14.0]}, 128)
batch 883: ({'logprob': [62.91152572631836, 17.0]}, 128)
batch 884: ({'logprob': [51.198448181152344, 13.0]}, 128)
batch 885: ({'logprob': [51.988433837890625, 13.0]}, 128)
batch 886: ({'logprob': [63.308555603027344, 17.0]}, 128)

======================Test output======================
logprob:  0.417641, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.974438e-03 [2.867016e-09] 
Layer 'conv1' biases: 5.771050e-08 [1.027256e-10] 
Layer 'conv2' weights[0]: 7.961415e-03 [2.917635e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.732313e-10] 
Layer 'conv3' weights[0]: 7.959714e-03 [2.863230e-09] 
Layer 'conv3' biases: 5.416446e-07 [1.790400e-09] 
Layer 'conv4' weights[0]: 7.992242e-03 [3.349458e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.825367e-08] 
Layer 'conv5' weights[0]: 7.991206e-03 [1.256348e-07] 
Layer 'conv5' biases: 9.999998e-01 [1.366253e-07] 
Layer 'fc6' weights[0]: 7.587947e-03 [1.102697e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.128485e-08] 
Layer 'fc7' weights[0]: 7.594668e-03 [2.538301e-07] 
Layer 'fc7' biases: 9.998698e-01 [2.425336e-07] 
Layer 'fc8' weights[0]: 1.361991e-03 [1.456994e-05] 
Layer 'fc8' biases: 1.702718e-02 [8.472218e-05] 
Train error last 870 batches: 0.435309
-------------------------------------------------------
Not saving because 0.417641 > 0.415712 (4.190: -0.00%)
======================================================= (12.026 sec)
8.611... logprob:  0.510554, 0.140625 (1.455 sec)
8.612... logprob:  0.448259, 0.117188 (1.457 sec)
8.613... logprob:  0.280188, 0.062500 (1.458 sec)
8.614... logprob:  0.503535, 0.140625 (1.451 sec)
8.615... logprob:  0.351476, 0.085938 (1.441 sec)
8.616... logprob:  0.415626, 0.109375 (1.432 sec)
8.617... logprob:  0.418106, 0.109375 (1.424 sec)
8.618... logprob:  0.546458, 0.156250 (1.439 sec)
8.619... logprob:  0.505816, 0.140625 (1.452 sec)
8.620... logprob:  0.539603, 0.156250 (1.457 sec)
8.621... logprob:  0.364183, 0.085938 (1.457 sec)
8.622... logprob:  0.365150, 0.085938 (1.447 sec)
8.623... logprob:  0.423293, 0.109375 (1.465 sec)
8.624... logprob:  0.382590, 0.093750 (1.438 sec)
8.625... logprob:  0.441037, 0.117188 (1.428 sec)
8.626... logprob:  0.438449, 0.117188 (1.433 sec)
8.627... logprob:  0.435915, 0.117188 (1.439 sec)
8.628... logprob:  0.465157, 0.125000 (1.437 sec)
8.629... logprob:  0.371899, 0.093750 (1.478 sec)
8.630... logprob:  0.422373, 0.109375 (1.488 sec)
8.631... logprob:  0.640027, 0.187500 (1.439 sec)
8.632... logprob:  0.399095, 0.101562 (1.479 sec)
8.633... logprob:  0.375966, 0.093750 (1.428 sec)
8.634... logprob:  0.660739, 0.195312 (1.427 sec)
8.635... logprob:  0.374140, 0.093750 (1.435 sec)
8.636... logprob:  0.480202, 0.132812 (1.435 sec)
8.637... logprob:  0.331110, 0.078125 (1.433 sec)
8.638... logprob:  0.515682, 0.140625 (1.478 sec)
8.639... logprob:  0.418262, 0.109375 (1.437 sec)
8.640... logprob:  0.528787, 0.148438 (1.435 sec)
8.641... logprob:  0.410518, 0.109375 (1.486 sec)
8.642... logprob:  0.500760, 0.140625 (1.431 sec)
8.643... logprob:  0.622546, 0.187500 (1.430 sec)
8.644... logprob:  0.321749, 0.070312 (1.437 sec)
8.645... logprob:  0.414516, 0.109375 (1.465 sec)
8.646... logprob:  0.385892, 0.093750 (1.432 sec)
8.647... logprob:  0.456704, 0.125000 (1.492 sec)
8.648... logprob:  0.491181, 0.140625 (1.431 sec)
8.649... logprob:  0.369926, 0.093750 (1.437 sec)
8.650... logprob:  0.413858, 0.109375 (1.475 sec)
8.651... logprob:  0.397242, 0.101562 (1.432 sec)
8.652... logprob:  0.507658, 0.140625 (1.439 sec)
8.653... logprob:  0.548463, 0.156250 (1.435 sec)
8.654... logprob:  0.496234, 0.140625 (1.427 sec)
8.655... logprob:  0.436235, 0.117188 (1.438 sec)
8.656... logprob:  0.416651, 0.109375 (1.477 sec)
8.657... logprob:  0.449489, 0.117188 (1.436 sec)
8.658... logprob:  0.345671, 0.085938 (1.449 sec)
8.659... logprob:  0.464425, 0.125000 (1.478 sec)
8.660... logprob:  0.445779, 0.125000 (1.446 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.730464935302734, 10.0]}, 128)
batch 872: ({'logprob': [66.19692993164062, 19.0]}, 128)
batch 873: ({'logprob': [41.14055252075195, 9.0]}, 128)
batch 874: ({'logprob': [45.407379150390625, 11.0]}, 128)
batch 875: ({'logprob': [50.90279769897461, 13.0]}, 128)
batch 876: ({'logprob': [63.76416778564453, 18.0]}, 128)
batch 877: ({'logprob': [46.02402114868164, 11.0]}, 128)
batch 878: ({'logprob': [61.9172477722168, 17.0]}, 128)
batch 879: ({'logprob': [73.5229263305664, 21.0]}, 128)
batch 880: ({'logprob': [50.9130973815918, 13.0]}, 128)
batch 881: ({'logprob': [29.507356643676758, 5.0]}, 128)
batch 882: ({'logprob': [55.19289016723633, 14.0]}, 128)
batch 883: ({'logprob': [61.90877914428711, 17.0]}, 128)
batch 884: ({'logprob': [51.51015853881836, 13.0]}, 128)
batch 885: ({'logprob': [52.73836135864258, 13.0]}, 128)
batch 886: ({'logprob': [62.523719787597656, 17.0]}, 128)

======================Test output======================
logprob:  0.417432, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.974399e-03 [1.776184e-09] 
Layer 'conv1' biases: 5.834822e-08 [2.347190e-11] 
Layer 'conv2' weights[0]: 7.961376e-03 [1.263905e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.123892e-10] 
Layer 'conv3' weights[0]: 7.959684e-03 [1.016574e-09] 
Layer 'conv3' biases: 5.472492e-07 [3.079028e-10] 
Layer 'conv4' weights[0]: 7.992207e-03 [1.004038e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.514930e-09] 
Layer 'conv5' weights[0]: 7.991161e-03 [6.638424e-09] 
Layer 'conv5' biases: 9.999998e-01 [6.621035e-09] 
Layer 'fc6' weights[0]: 7.587909e-03 [9.237391e-10] 
Layer 'fc6' biases: 1.000000e+00 [4.997621e-10] 
Layer 'fc7' weights[0]: 7.592791e-03 [4.233302e-08] 
Layer 'fc7' biases: 9.998689e-01 [1.493093e-08] 
Layer 'fc8' weights[0]: 1.308539e-03 [4.777969e-06] 
Layer 'fc8' biases: 1.681444e-02 [2.946930e-05] 
Train error last 870 batches: 0.435308
-------------------------------------------------------
Not saving because 0.417432 > 0.415712 (4.190: -0.00%)
======================================================= (12.160 sec)
8.661... logprob:  0.378671, 0.093750 (1.446 sec)
8.662... logprob:  0.469235, 0.132812 (1.435 sec)
8.663... logprob:  0.311205, 0.070312 (1.431 sec)
8.664... logprob:  0.285629, 0.062500 (1.440 sec)
8.665... logprob:  0.402003, 0.101562 (1.458 sec)
8.666... logprob:  0.442114, 0.117188 (1.451 sec)
8.667... logprob:  0.564415, 0.164062 (1.454 sec)
8.668... logprob:  0.497998, 0.140625 (1.454 sec)
8.669... logprob:  0.433261, 0.109375 (1.461 sec)
8.670... logprob:  0.362599, 0.085938 (1.431 sec)
8.671... logprob:  0.360837, 0.093750 (1.430 sec)
8.672... logprob:  0.441807, 0.117188 (1.428 sec)
8.673... logprob:  0.436268, 0.117188 (1.435 sec)
8.674... logprob:  0.446707, 0.117188 (1.440 sec)
8.675... logprob:  0.356649, 0.093750 (1.461 sec)
8.676... logprob:  0.450128, 0.125000 (1.456 sec)
8.677... logprob:  0.471099, 0.125000 (1.440 sec)
8.678... logprob:  0.465631, 0.125000 (1.477 sec)
8.679... logprob:  0.454892, 0.125000 (1.434 sec)
8.680... logprob:  0.351791, 0.078125 (1.425 sec)
8.681... logprob:  0.374016, 0.093750 (1.434 sec)
8.682... logprob:  0.340536, 0.078125 (1.431 sec)
8.683... logprob:  0.411671, 0.109375 (1.431 sec)
8.684... logprob:  0.357519, 0.085938 (1.476 sec)
8.685... logprob:  0.285571, 0.054688 (1.451 sec)
8.686... logprob:  0.318274, 0.070312 (1.431 sec)
8.687... logprob:  0.281316, 0.062500 (1.491 sec)
8.688... logprob:  0.323055, 0.078125 (1.432 sec)
8.689... logprob:  0.471991, 0.125000 (1.432 sec)
8.690... logprob:  0.528635, 0.140625 (1.438 sec)
8.691... logprob:  0.517796, 0.140625 (1.435 sec)
8.692... logprob:  0.385841, 0.101562 (1.434 sec)
8.693... logprob:  0.456533, 0.125000 (1.484 sec)
8.694... logprob:  0.330831, 0.078125 (1.441 sec)
8.695... logprob:  0.356824, 0.085938 (1.440 sec)
8.696... logprob:  0.538390, 0.148438 (1.482 sec)
8.697... logprob:  0.465439, 0.125000 (1.436 sec)
8.698... logprob:  0.548134, 0.156250 (1.436 sec)
8.699... logprob:  0.459564, 0.125000 (1.439 sec)
8.700... logprob:  0.434241, 0.117188 (1.432 sec)
8.701... logprob:  0.423697, 0.109375 (1.429 sec)
8.702... logprob:  0.521365, 0.148438 (1.488 sec)
8.703... logprob:  0.405975, 0.101562 (1.442 sec)
8.704... logprob:  0.406638, 0.101562 (1.444 sec)
8.705... logprob:  0.420459, 0.109375 (1.470 sec)
8.706... logprob:  0.468090, 0.125000 (1.436 sec)
8.707... logprob:  0.485300, 0.132812 (1.439 sec)
8.708... logprob:  0.416907, 0.109375 (1.436 sec)
8.709... logprob:  0.422266, 0.109375 (1.424 sec)
8.710... logprob:  0.603388, 0.179688 (1.438 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.299652099609375, 10.0]}, 128)
batch 872: ({'logprob': [66.2210464477539, 19.0]}, 128)
batch 873: ({'logprob': [41.14659118652344, 9.0]}, 128)
batch 874: ({'logprob': [45.63438415527344, 11.0]}, 128)
batch 875: ({'logprob': [50.98823928833008, 13.0]}, 128)
batch 876: ({'logprob': [63.768672943115234, 18.0]}, 128)
batch 877: ({'logprob': [46.07032775878906, 11.0]}, 128)
batch 878: ({'logprob': [61.72042465209961, 17.0]}, 128)
batch 879: ({'logprob': [72.86336517333984, 21.0]}, 128)
batch 880: ({'logprob': [50.99911117553711, 13.0]}, 128)
batch 881: ({'logprob': [29.97669219970703, 5.0]}, 128)
batch 882: ({'logprob': [54.75507354736328, 14.0]}, 128)
batch 883: ({'logprob': [61.71180725097656, 17.0]}, 128)
batch 884: ({'logprob': [51.41441345214844, 13.0]}, 128)
batch 885: ({'logprob': [52.28025436401367, 13.0]}, 128)
batch 886: ({'logprob': [62.14563751220703, 17.0]}, 128)

======================Test output======================
logprob:  0.416990, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.974363e-03 [2.967080e-09] 
Layer 'conv1' biases: 5.882523e-08 [4.774304e-11] 
Layer 'conv2' weights[0]: 7.961335e-03 [2.175179e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.182225e-10] 
Layer 'conv3' weights[0]: 7.959641e-03 [1.876225e-09] 
Layer 'conv3' biases: 5.512392e-07 [1.071642e-09] 
Layer 'conv4' weights[0]: 7.992164e-03 [2.050394e-09] 
Layer 'conv4' biases: 9.999998e-01 [9.956117e-09] 
Layer 'conv5' weights[0]: 7.991119e-03 [6.848913e-08] 
Layer 'conv5' biases: 9.999997e-01 [7.432219e-08] 
Layer 'fc6' weights[0]: 7.587882e-03 [5.988314e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.074794e-09] 
Layer 'fc7' weights[0]: 7.590857e-03 [1.181691e-07] 
Layer 'fc7' biases: 9.998685e-01 [1.026840e-07] 
Layer 'fc8' weights[0]: 1.300453e-03 [3.862267e-06] 
Layer 'fc8' biases: 1.696183e-02 [3.089715e-05] 
Train error last 870 batches: 0.435307
-------------------------------------------------------
Not saving because 0.416990 > 0.415712 (4.190: -0.00%)
======================================================= (12.024 sec)
8.711... logprob:  0.469599, 0.125000 (1.470 sec)
8.712... logprob:  0.339872, 0.078125 (1.453 sec)
8.713... logprob:  0.588099, 0.179688 (1.453 sec)
8.714... logprob:  0.466420, 0.125000 (1.470 sec)
8.715... logprob:  0.417107, 0.109375 (1.453 sec)
8.716... logprob:  0.335085, 0.078125 (1.443 sec)
8.717... logprob:  0.429902, 0.117188 (1.423 sec)
8.718... logprob:  0.490434, 0.132812 (1.433 sec)
8.719... logprob:  0.406221, 0.109375 (1.439 sec)
8.720... logprob:  0.433248, 0.117188 (1.451 sec)
8.721... logprob:  0.451601, 0.117188 (1.462 sec)
8.722... logprob:  0.536675, 0.156250 (1.457 sec)
8.723... logprob:  0.416667, 0.109375 (1.446 sec)
8.724... logprob:  0.412798, 0.109375 (1.472 sec)
8.725... logprob:  0.494503, 0.140625 (1.440 sec)
8.726... logprob:  0.338874, 0.085938 (1.425 sec)
8.727... logprob:  0.393533, 0.101562 (1.438 sec)
8.728... logprob:  0.421517, 0.109375 (1.434 sec)
8.729... logprob:  0.388016, 0.093750 (1.431 sec)
8.730... logprob:  0.565796, 0.164062 (1.475 sec)
8.731... logprob:  0.450247, 0.125000 (1.450 sec)
8.732... logprob:  0.311536, 0.070312 (1.434 sec)
8.733... logprob:  0.556936, 0.156250 (1.490 sec)
8.734... logprob:  0.340206, 0.078125 (1.432 sec)
8.735... logprob:  0.527824, 0.148438 (1.432 sec)
8.736... logprob:  0.643492, 0.187500 (1.438 sec)
8.737... logprob:  0.516307, 0.148438 (1.434 sec)
8.738... logprob:  0.459483, 0.125000 (1.434 sec)
8.739... logprob:  0.477844, 0.132812 (1.483 sec)
8.740... logprob:  0.339665, 0.078125 (1.439 sec)
8.741... logprob:  0.393432, 0.101562 (1.443 sec)
8.742... logprob:  0.419793, 0.109375 (1.482 sec)
8.743... logprob:  0.364879, 0.085938 (1.438 sec)
8.744... logprob:  0.519346, 0.148438 (1.430 sec)
8.745... logprob:  0.478222, 0.132812 (1.442 sec)
8.746... logprob:  0.440580, 0.117188 (1.428 sec)
8.747... logprob:  0.425662, 0.109375 (1.432 sec)
8.748... logprob:  0.378001, 0.093750 (1.490 sec)
8.749... logprob:  0.420879, 0.109375 (1.434 sec)
8.750... logprob:  0.513011, 0.140625 (1.451 sec)
8.751... logprob:  0.263435, 0.054688 (1.476 sec)
8.752... logprob:  0.522472, 0.140625 (1.454 sec)
8.753... logprob:  0.441336, 0.117188 (1.435 sec)
8.754... logprob:  0.468837, 0.132812 (1.439 sec)
8.755... logprob:  0.507180, 0.140625 (1.427 sec)
8.756... logprob:  0.440825, 0.117188 (1.440 sec)
8.757... logprob:  0.552159, 0.156250 (1.470 sec)
8.758... logprob:  0.393839, 0.101562 (1.450 sec)
8.759... logprob:  0.459699, 0.125000 (1.454 sec)
8.760... logprob:  0.485301, 0.132812 (1.467 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.67930603027344, 10.0]}, 128)
batch 872: ({'logprob': [66.10041809082031, 19.0]}, 128)
batch 873: ({'logprob': [41.50027084350586, 9.0]}, 128)
batch 874: ({'logprob': [45.92157745361328, 11.0]}, 128)
batch 875: ({'logprob': [51.16184616088867, 13.0]}, 128)
batch 876: ({'logprob': [63.693077087402344, 18.0]}, 128)
batch 877: ({'logprob': [46.33432388305664, 11.0]}, 128)
batch 878: ({'logprob': [61.66638946533203, 17.0]}, 128)
batch 879: ({'logprob': [72.55812072753906, 21.0]}, 128)
batch 880: ({'logprob': [51.1727409362793, 13.0]}, 128)
batch 881: ({'logprob': [30.5817928314209, 5.0]}, 128)
batch 882: ({'logprob': [54.81211853027344, 14.0]}, 128)
batch 883: ({'logprob': [61.65766906738281, 17.0]}, 128)
batch 884: ({'logprob': [51.563873291015625, 13.0]}, 128)
batch 885: ({'logprob': [52.38200759887695, 13.0]}, 128)
batch 886: ({'logprob': [62.067527770996094, 17.0]}, 128)

======================Test output======================
logprob:  0.417897, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.974326e-03 [2.079086e-09] 
Layer 'conv1' biases: 5.956153e-08 [3.626340e-11] 
Layer 'conv2' weights[0]: 7.961296e-03 [1.593387e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.813769e-10] 
Layer 'conv3' weights[0]: 7.959602e-03 [1.380007e-09] 
Layer 'conv3' biases: 5.585039e-07 [6.017344e-10] 
Layer 'conv4' weights[0]: 7.992127e-03 [1.458038e-09] 
Layer 'conv4' biases: 9.999999e-01 [5.366263e-09] 
Layer 'conv5' weights[0]: 7.991083e-03 [3.698224e-08] 
Layer 'conv5' biases: 1.000000e+00 [4.024729e-08] 
Layer 'fc6' weights[0]: 7.587846e-03 [3.315233e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.274331e-09] 
Layer 'fc7' weights[0]: 7.588903e-03 [2.310343e-07] 
Layer 'fc7' biases: 9.998683e-01 [2.191122e-07] 
Layer 'fc8' weights[0]: 1.291484e-03 [8.202005e-06] 
Layer 'fc8' biases: 1.702380e-02 [4.948753e-05] 
Train error last 870 batches: 0.435307
-------------------------------------------------------
Not saving because 0.417897 > 0.415712 (4.190: -0.00%)
======================================================= (12.059 sec)
8.761... logprob:  0.418589, 0.109375 (1.457 sec)
8.762... logprob:  0.515947, 0.148438 (1.446 sec)
8.763... logprob:  0.558656, 0.164062 (1.426 sec)
8.764... logprob:  0.503306, 0.140625 (1.424 sec)
8.765... logprob:  0.312651, 0.062500 (1.437 sec)
8.766... logprob:  0.482357, 0.132812 (1.459 sec)
8.767... logprob:  0.371215, 0.085938 (1.461 sec)
8.768... logprob:  0.432771, 0.117188 (1.462 sec)
8.769... logprob:  0.491008, 0.140625 (1.470 sec)
8.770... logprob:  0.402710, 0.101562 (1.482 sec)
8.771... logprob:  0.549900, 0.156250 (1.460 sec)
8.772... logprob:  0.414009, 0.109375 (1.448 sec)
8.773... logprob:  0.558544, 0.164062 (1.444 sec)
8.774... logprob:  0.361346, 0.085938 (1.465 sec)
8.775... logprob:  0.407290, 0.101562 (1.465 sec)
8.776... logprob:  0.433334, 0.117188 (1.479 sec)
8.777... logprob:  0.379896, 0.093750 (1.477 sec)
8.778... logprob:  0.433688, 0.117188 (1.462 sec)
8.779... logprob:  0.505588, 0.140625 (1.493 sec)
8.780... logprob:  0.385757, 0.101562 (1.453 sec)
8.781... logprob:  0.369830, 0.085938 (1.453 sec)
8.782... logprob:  0.351607, 0.085938 (1.444 sec)
8.783... logprob:  0.555413, 0.156250 (1.454 sec)
8.784... logprob:  0.440972, 0.117188 (1.459 sec)
8.785... logprob:  0.543377, 0.156250 (1.497 sec)
8.786... logprob:  0.477273, 0.132812 (1.468 sec)
8.787... logprob:  0.545947, 0.156250 (1.462 sec)
8.788... logprob:  0.562608, 0.164062 (1.491 sec)
8.789... logprob:  0.282054, 0.054688 (1.452 sec)
8.790... logprob:  0.408640, 0.101562 (1.451 sec)
8.791... logprob:  0.398381, 0.101562 (1.451 sec)
8.792... logprob:  0.361515, 0.085938 (1.462 sec)
8.793... logprob:  0.370452, 0.085938 (1.454 sec)
8.794... logprob:  0.387120, 0.093750 (1.493 sec)
8.795... logprob:  0.469923, 0.125000 (1.465 sec)
8.796... logprob:  0.423504, 0.109375 (1.465 sec)
8.797... logprob:  0.358566, 0.085938 (1.501 sec)
8.798... logprob:  0.393258, 0.101562 (1.451 sec)
8.799... logprob:  0.331944, 0.078125 (1.445 sec)
8.800... logprob:  0.371892, 0.093750 (1.444 sec)
8.801... logprob:  0.450633, 0.117188 (1.461 sec)
8.802... logprob:  0.423374, 0.109375 (1.456 sec)
8.803... logprob:  0.492455, 0.132812 (1.494 sec)
8.804... logprob:  0.350031, 0.085938 (1.466 sec)
8.805... logprob:  0.452268, 0.117188 (1.460 sec)
8.806... logprob:  0.424181, 0.109375 (1.508 sec)
8.807... logprob:  0.443429, 0.117188 (1.454 sec)
8.808... logprob:  0.462338, 0.125000 (1.450 sec)
8.809... logprob:  0.589223, 0.171875 (1.452 sec)
8.810... logprob:  0.442414, 0.117188 (1.455 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.63374710083008, 10.0]}, 128)
batch 872: ({'logprob': [66.60398864746094, 19.0]}, 128)
batch 873: ({'logprob': [40.84490966796875, 9.0]}, 128)
batch 874: ({'logprob': [45.68940353393555, 11.0]}, 128)
batch 875: ({'logprob': [51.03303909301758, 13.0]}, 128)
batch 876: ({'logprob': [64.06562805175781, 18.0]}, 128)
batch 877: ({'logprob': [45.94231033325195, 11.0]}, 128)
batch 878: ({'logprob': [61.74689865112305, 17.0]}, 128)
batch 879: ({'logprob': [72.68866729736328, 21.0]}, 128)
batch 880: ({'logprob': [51.0447883605957, 13.0]}, 128)
batch 881: ({'logprob': [29.876405715942383, 5.0]}, 128)
batch 882: ({'logprob': [54.33845520019531, 14.0]}, 128)
batch 883: ({'logprob': [61.73798370361328, 17.0]}, 128)
batch 884: ({'logprob': [51.27680206298828, 13.0]}, 128)
batch 885: ({'logprob': [51.77671432495117, 13.0]}, 128)
batch 886: ({'logprob': [61.98931121826172, 17.0]}, 128)

======================Test output======================
logprob:  0.416645, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.974287e-03 [3.031829e-09] 
Layer 'conv1' biases: 6.031973e-08 [9.252757e-11] 
Layer 'conv2' weights[0]: 7.961257e-03 [2.991939e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.354290e-10] 
Layer 'conv3' weights[0]: 7.959568e-03 [2.927974e-09] 
Layer 'conv3' biases: 5.654374e-07 [1.684059e-09] 
Layer 'conv4' weights[0]: 7.992083e-03 [3.247473e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.590450e-08] 
Layer 'conv5' weights[0]: 7.991041e-03 [1.076212e-07] 
Layer 'conv5' biases: 1.000000e+00 [1.169159e-07] 
Layer 'fc6' weights[0]: 7.587810e-03 [9.589799e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.627826e-09] 
Layer 'fc7' weights[0]: 7.586971e-03 [4.353067e-07] 
Layer 'fc7' biases: 9.998684e-01 [4.210737e-07] 
Layer 'fc8' weights[0]: 1.302745e-03 [1.638461e-05] 
Layer 'fc8' biases: 1.728243e-02 [9.725997e-05] 
Train error last 870 batches: 0.435306
-------------------------------------------------------
Not saving because 0.416645 > 0.415712 (4.190: -0.00%)
======================================================= (12.026 sec)
8.811... logprob:  0.460443, 0.125000 (1.458 sec)
8.812... logprob:  0.462525, 0.125000 (1.505 sec)
8.813... logprob:  0.486033, 0.132812 (1.459 sec)
8.814... logprob:  0.478355, 0.132812 (1.455 sec)
8.815... logprob:  0.372997, 0.085938 (1.504 sec)
8.816... logprob:  0.409364, 0.101562 (1.454 sec)
8.817... logprob:  0.426374, 0.109375 (1.474 sec)
8.818... logprob:  0.559957, 0.164062 (1.448 sec)
8.819... logprob:  0.498250, 0.140625 (1.459 sec)
8.820... logprob:  0.421448, 0.109375 (1.453 sec)
8.821... logprob:  0.406223, 0.101562 (1.497 sec)
8.822... logprob:  0.440968, 0.117188 (1.461 sec)
8.823... logprob:  0.339968, 0.078125 (1.202 sec)
8.824... logprob:  0.490307, 0.132812 (0.711 sec)
8.825... logprob:  0.286890, 0.062500 (0.695 sec)
8.826... logprob:  0.375207, 0.093750 (0.690 sec)
8.827... logprob:  0.420797, 0.109375 (0.692 sec)
8.828... logprob:  0.443971, 0.117188 (0.693 sec)
8.829... logprob:  0.505303, 0.140625 (0.690 sec)
8.830... logprob:  0.442575, 0.117188 (1.506 sec)
8.831... logprob:  0.514312, 0.140625 (1.454 sec)
8.832... logprob:  0.330902, 0.078125 (1.462 sec)
8.833... logprob:  0.488858, 0.132812 (1.496 sec)
8.834... logprob:  0.433032, 0.117188 (1.456 sec)
8.835... logprob:  0.542153, 0.148438 (1.459 sec)
8.836... logprob:  0.376571, 0.093750 (1.453 sec)
8.837... logprob:  0.315435, 0.070312 (1.450 sec)
8.838... logprob:  0.437129, 0.117188 (1.454 sec)
8.839... logprob:  0.471860, 0.125000 (1.505 sec)
8.840... logprob:  0.555084, 0.156250 (1.455 sec)
8.841... logprob:  0.396497, 0.101562 (1.464 sec)
8.842... logprob:  0.497753, 0.140625 (1.495 sec)
8.843... logprob:  0.465591, 0.125000 (1.453 sec)
8.844... logprob:  0.497579, 0.140625 (1.460 sec)
8.845... logprob:  0.486918, 0.132812 (1.452 sec)
8.846... logprob:  0.468564, 0.125000 (1.450 sec)
8.847... logprob:  0.362913, 0.085938 (1.453 sec)
8.848... logprob:  0.396815, 0.101562 (1.502 sec)
8.849... logprob:  0.359952, 0.085938 (1.456 sec)
8.850... logprob:  0.479512, 0.132812 (1.471 sec)
8.851... logprob:  0.440193, 0.117188 (1.498 sec)
8.852... logprob:  0.546348, 0.156250 (1.464 sec)
8.853... logprob:  0.371633, 0.093750 (1.463 sec)
8.854... logprob:  0.306742, 0.070312 (1.449 sec)
8.855... logprob:  0.485204, 0.132812 (1.450 sec)
8.856... logprob:  0.443998, 0.117188 (1.453 sec)
8.857... logprob:  0.372286, 0.093750 (1.495 sec)
8.858... logprob:  0.396251, 0.101562 (1.464 sec)
8.859... logprob:  0.307953, 0.070312 (1.473 sec)
8.860... logprob:  0.565863, 0.156250 (1.484 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.29399871826172, 10.0]}, 128)
batch 872: ({'logprob': [67.64768981933594, 19.0]}, 128)
batch 873: ({'logprob': [39.73482894897461, 9.0]}, 128)
batch 874: ({'logprob': [44.838016510009766, 11.0]}, 128)
batch 875: ({'logprob': [50.7263298034668, 13.0]}, 128)
batch 876: ({'logprob': [64.90896606445312, 18.0]}, 128)
batch 877: ({'logprob': [45.23258972167969, 11.0]}, 128)
batch 878: ({'logprob': [62.531829833984375, 17.0]}, 128)
batch 879: ({'logprob': [74.70747375488281, 21.0]}, 128)
batch 880: ({'logprob': [50.73810577392578, 13.0]}, 128)
batch 881: ({'logprob': [27.530845642089844, 5.0]}, 128)
batch 882: ({'logprob': [54.66542053222656, 14.0]}, 128)
batch 883: ({'logprob': [62.52299880981445, 17.0]}, 128)
batch 884: ({'logprob': [51.1155891418457, 13.0]}, 128)
batch 885: ({'logprob': [51.90392303466797, 13.0]}, 128)
batch 886: ({'logprob': [62.91925811767578, 17.0]}, 128)

======================Test output======================
logprob:  0.416513, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.974248e-03 [3.755066e-09] 
Layer 'conv1' biases: 6.086246e-08 [7.947962e-11] 
Layer 'conv2' weights[0]: 7.961215e-03 [2.794731e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.171771e-10] 
Layer 'conv3' weights[0]: 7.959524e-03 [2.602460e-09] 
Layer 'conv3' biases: 5.696011e-07 [1.647984e-09] 
Layer 'conv4' weights[0]: 7.992050e-03 [2.862253e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.585238e-08] 
Layer 'conv5' weights[0]: 7.990990e-03 [1.095031e-07] 
Layer 'conv5' biases: 9.999996e-01 [1.191569e-07] 
Layer 'fc6' weights[0]: 7.587780e-03 [9.688616e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.747617e-09] 
Layer 'fc7' weights[0]: 7.585020e-03 [5.690053e-08] 
Layer 'fc7' biases: 9.998692e-01 [3.703201e-08] 
Layer 'fc8' weights[0]: 1.346026e-03 [1.464046e-06] 
Layer 'fc8' biases: 1.780610e-02 [6.356732e-06] 
Train error last 870 batches: 0.435306
-------------------------------------------------------
Not saving because 0.416513 > 0.415712 (4.190: -0.00%)
======================================================= (12.071 sec)
8.861... logprob:  0.417842, 0.109375 (1.466 sec)
8.862... logprob:  0.329039, 0.078125 (1.458 sec)
8.863... logprob:  0.399469, 0.101562 (1.448 sec)
8.864... logprob:  0.451309, 0.117188 (1.446 sec)
8.865... logprob:  0.484240, 0.132812 (1.463 sec)
8.866... logprob:  0.507283, 0.140625 (1.492 sec)
8.867... logprob:  0.502580, 0.140625 (1.469 sec)
8.868... logprob:  0.405555, 0.101562 (1.475 sec)
8.869... logprob:  0.383569, 0.093750 (1.481 sec)
8.870... logprob:  0.551760, 0.156250 (1.397 sec)
9.1... logprob:  0.380391, 0.093750 (1.405 sec)
9.2... logprob:  0.448301, 0.117188 (1.445 sec)
9.3... logprob:  0.398532, 0.101562 (1.423 sec)
9.4... logprob:  0.443396, 0.117188 (1.405 sec)
9.5... logprob:  0.443349, 0.117188 (1.427 sec)
9.6... logprob:  0.499355, 0.140625 (1.392 sec)
9.7... logprob:  0.362828, 0.085938 (1.421 sec)
9.8... logprob:  0.419079, 0.109375 (1.393 sec)
9.9... logprob:  0.358470, 0.085938 (1.407 sec)
9.10... logprob:  0.377234, 0.093750 (1.406 sec)
9.11... logprob:  0.334293, 0.078125 (1.443 sec)
9.12... logprob:  0.466722, 0.125000 (1.401 sec)
9.13... logprob:  0.442564, 0.117188 (1.419 sec)
9.14... logprob:  0.444968, 0.117188 (1.405 sec)
9.15... logprob:  0.395771, 0.101562 (1.413 sec)
9.16... logprob:  0.421540, 0.109375 (1.411 sec)
9.17... logprob:  0.516165, 0.140625 (1.392 sec)
9.18... logprob:  0.262145, 0.054688 (1.398 sec)
9.19... logprob:  0.279780, 0.062500 (1.399 sec)
9.20... logprob:  0.421390, 0.109375 (1.406 sec)
9.21... logprob:  0.443926, 0.117188 (0.893 sec)
9.22... logprob:  0.536424, 0.148438 (1.330 sec)
9.23... logprob:  0.532530, 0.148438 (1.423 sec)
9.24... logprob:  0.311006, 0.070312 (0.985 sec)
9.25... logprob:  0.356483, 0.085938 (0.958 sec)
9.26... logprob:  0.463586, 0.125000 (1.461 sec)
9.27... logprob:  0.404710, 0.101562 (1.388 sec)
9.28... logprob:  0.421902, 0.109375 (1.409 sec)
9.29... logprob:  0.396161, 0.101562 (1.424 sec)
9.30... logprob:  0.374262, 0.093750 (1.418 sec)
9.31... logprob:  0.479864, 0.132812 (1.399 sec)
9.32... logprob:  0.457249, 0.125000 (1.395 sec)
9.33... logprob:  0.460685, 0.125000 (1.445 sec)
9.34... logprob:  0.464727, 0.125000 (1.393 sec)
9.35... logprob:  0.316098, 0.070312 (1.404 sec)
9.36... logprob:  0.475809, 0.132812 (1.405 sec)
9.37... logprob:  0.417616, 0.109375 (1.403 sec)
9.38... logprob:  0.392396, 0.101562 (1.398 sec)
9.39... logprob:  0.632196, 0.187500 (1.434 sec)
9.40... logprob:  0.445965, 0.117188 (1.413 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.240020751953125, 10.0]}, 128)
batch 872: ({'logprob': [66.39213562011719, 19.0]}, 128)
batch 873: ({'logprob': [40.89755630493164, 9.0]}, 128)
batch 874: ({'logprob': [45.52663040161133, 11.0]}, 128)
batch 875: ({'logprob': [50.92605972290039, 13.0]}, 128)
batch 876: ({'logprob': [63.89360046386719, 18.0]}, 128)
batch 877: ({'logprob': [45.91482925415039, 11.0]}, 128)
batch 878: ({'logprob': [61.75074768066406, 17.0]}, 128)
batch 879: ({'logprob': [72.93826293945312, 21.0]}, 128)
batch 880: ({'logprob': [50.937442779541016, 13.0]}, 128)
batch 881: ({'logprob': [29.682857513427734, 5.0]}, 128)
batch 882: ({'logprob': [54.597713470458984, 14.0]}, 128)
batch 883: ({'logprob': [61.74171829223633, 17.0]}, 128)
batch 884: ({'logprob': [51.30519485473633, 13.0]}, 128)
batch 885: ({'logprob': [52.07622146606445, 13.0]}, 128)
batch 886: ({'logprob': [62.128692626953125, 17.0]}, 128)

======================Test output======================
logprob:  0.416479, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.974206e-03 [3.084690e-09] 
Layer 'conv1' biases: 6.157970e-08 [7.214476e-11] 
Layer 'conv2' weights[0]: 7.961184e-03 [2.058306e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.522123e-10] 
Layer 'conv3' weights[0]: 7.959490e-03 [1.930541e-09] 
Layer 'conv3' biases: 5.760988e-07 [1.091655e-09] 
Layer 'conv4' weights[0]: 7.992010e-03 [2.118583e-09] 
Layer 'conv4' biases: 9.999999e-01 [9.976997e-09] 
Layer 'conv5' weights[0]: 7.990965e-03 [6.883616e-08] 
Layer 'conv5' biases: 1.000000e+00 [7.490016e-08] 
Layer 'fc6' weights[0]: 7.587739e-03 [6.007965e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.102247e-09] 
Layer 'fc7' weights[0]: 7.583102e-03 [1.181183e-07] 
Layer 'fc7' biases: 9.998686e-01 [1.035160e-07] 
Layer 'fc8' weights[0]: 1.300332e-03 [7.219042e-06] 
Layer 'fc8' biases: 1.763380e-02 [4.485861e-05] 
Train error last 870 batches: 0.435306
-------------------------------------------------------
Not saving because 0.416479 > 0.415712 (4.190: -0.00%)
======================================================= (12.068 sec)
9.41... logprob:  0.352656, 0.085938 (1.429 sec)
9.42... logprob:  0.391741, 0.101562 (1.426 sec)
9.43... logprob:  0.440165, 0.117188 (1.415 sec)
9.44... logprob:  0.518442, 0.148438 (1.437 sec)
9.45... logprob:  0.381852, 0.093750 (1.391 sec)
9.46... logprob:  0.486499, 0.132812 (1.398 sec)
9.47... logprob:  0.331811, 0.078125 (1.398 sec)
9.48... logprob:  0.498838, 0.140625 (1.425 sec)
9.49... logprob:  0.510475, 0.148438 (1.412 sec)
9.50... logprob:  0.393293, 0.101562 (1.431 sec)
9.51... logprob:  0.489846, 0.140625 (1.416 sec)
9.52... logprob:  0.525794, 0.148438 (1.401 sec)
9.53... logprob:  0.295175, 0.062500 (1.445 sec)
9.54... logprob:  0.403139, 0.109375 (1.391 sec)
9.55... logprob:  0.331841, 0.078125 (1.402 sec)
9.56... logprob:  0.421779, 0.109375 (1.404 sec)
9.57... logprob:  0.572684, 0.164062 (1.432 sec)
9.58... logprob:  0.407918, 0.101562 (1.401 sec)
9.59... logprob:  0.333841, 0.078125 (1.486 sec)
9.60... logprob:  0.619248, 0.179688 (1.425 sec)
9.61... logprob:  0.382909, 0.093750 (1.441 sec)
9.62... logprob:  0.474954, 0.132812 (1.464 sec)
9.63... logprob:  0.397325, 0.101562 (1.433 sec)
9.64... logprob:  0.450236, 0.125000 (1.417 sec)
9.65... logprob:  0.373281, 0.093750 (1.403 sec)
9.66... logprob:  0.353976, 0.085938 (1.449 sec)
9.67... logprob:  0.295364, 0.062500 (1.389 sec)
9.68... logprob:  0.396840, 0.101562 (1.400 sec)
9.69... logprob:  0.496928, 0.140625 (1.428 sec)
9.70... logprob:  0.325878, 0.078125 (1.422 sec)
9.71... logprob:  0.381877, 0.101562 (1.470 sec)
9.72... logprob:  0.493916, 0.132812 (1.408 sec)
9.73... logprob:  0.447821, 0.117188 (1.425 sec)
9.74... logprob:  0.442636, 0.117188 (1.422 sec)
9.75... logprob:  0.380635, 0.093750 (1.414 sec)
9.76... logprob:  0.412119, 0.109375 (1.438 sec)
9.77... logprob:  0.396348, 0.101562 (1.429 sec)
9.78... logprob:  0.493094, 0.140625 (1.454 sec)
9.79... logprob:  0.456435, 0.125000 (1.407 sec)
9.80... logprob:  0.507779, 0.132812 (1.420 sec)
9.81... logprob:  0.416722, 0.109375 (1.421 sec)
9.82... logprob:  0.232095, 0.039062 (1.432 sec)
9.83... logprob:  0.493686, 0.140625 (1.401 sec)
9.84... logprob:  0.468047, 0.125000 (1.470 sec)
9.85... logprob:  0.432105, 0.117188 (1.426 sec)
9.86... logprob:  0.417037, 0.109375 (1.419 sec)
9.87... logprob:  0.633149, 0.187500 (1.414 sec)
9.88... logprob:  0.535175, 0.156250 (1.411 sec)
9.89... logprob:  0.410678, 0.109375 (1.440 sec)
9.90... logprob:  0.577550, 0.171875 (1.386 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.123680114746094, 10.0]}, 128)
batch 872: ({'logprob': [65.81156158447266, 19.0]}, 128)
batch 873: ({'logprob': [42.345252990722656, 9.0]}, 128)
batch 874: ({'logprob': [46.428531646728516, 11.0]}, 128)
batch 875: ({'logprob': [51.51690673828125, 13.0]}, 128)
batch 876: ({'logprob': [63.52649688720703, 18.0]}, 128)
batch 877: ({'logprob': [46.934627532958984, 11.0]}, 128)
batch 878: ({'logprob': [61.71590042114258, 17.0]}, 128)
batch 879: ({'logprob': [72.39462280273438, 21.0]}, 128)
batch 880: ({'logprob': [51.527374267578125, 13.0]}, 128)
batch 881: ({'logprob': [31.63994026184082, 5.0]}, 128)
batch 882: ({'logprob': [55.32154083251953, 14.0]}, 128)
batch 883: ({'logprob': [61.706947326660156, 17.0]}, 128)
batch 884: ({'logprob': [52.01068115234375, 13.0]}, 128)
batch 885: ({'logprob': [53.01372528076172, 13.0]}, 128)
batch 886: ({'logprob': [62.20912170410156, 17.0]}, 128)

======================Test output======================
logprob:  0.420521, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.974168e-03 [3.219964e-09] 
Layer 'conv1' biases: 6.238623e-08 [8.127943e-11] 
Layer 'conv2' weights[0]: 7.961152e-03 [2.520075e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.399418e-10] 
Layer 'conv3' weights[0]: 7.959449e-03 [2.202966e-09] 
Layer 'conv3' biases: 5.818571e-07 [1.373531e-09] 
Layer 'conv4' weights[0]: 7.991970e-03 [2.471792e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.281712e-08] 
Layer 'conv5' weights[0]: 7.990924e-03 [8.633121e-08] 
Layer 'conv5' biases: 1.000000e+00 [9.385078e-08] 
Layer 'fc6' weights[0]: 7.587698e-03 [7.581078e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.666634e-09] 
Layer 'fc7' weights[0]: 7.581188e-03 [2.531511e-07] 
Layer 'fc7' biases: 9.998679e-01 [2.417331e-07] 
Layer 'fc8' weights[0]: 1.271455e-03 [9.693309e-06] 
Layer 'fc8' biases: 1.748476e-02 [6.070978e-05] 
Train error last 870 batches: 0.435306
-------------------------------------------------------
Not saving because 0.420521 > 0.415712 (4.190: -0.00%)
======================================================= (12.043 sec)
9.91... logprob:  0.348605, 0.078125 (1.407 sec)
9.92... logprob:  0.464454, 0.125000 (1.411 sec)
9.93... logprob:  0.492334, 0.140625 (1.408 sec)
9.94... logprob:  0.428784, 0.109375 (1.389 sec)
9.95... logprob:  0.471877, 0.125000 (1.404 sec)
9.96... logprob:  0.576455, 0.171875 (1.402 sec)
9.97... logprob:  0.430750, 0.117188 (1.393 sec)
9.98... logprob:  0.390935, 0.093750 (1.441 sec)
9.99... logprob:  0.474389, 0.132812 (1.406 sec)
9.100... logprob:  0.310243, 0.070312 (1.404 sec)
9.101... logprob:  0.310336, 0.062500 (1.441 sec)
9.102... logprob:  0.546617, 0.156250 (1.396 sec)
9.103... logprob:  0.541584, 0.156250 (1.400 sec)
9.104... logprob:  0.388925, 0.101562 (1.403 sec)
9.105... logprob:  0.620091, 0.179688 (1.393 sec)
9.106... logprob:  0.344427, 0.085938 (1.396 sec)
9.107... logprob:  0.335655, 0.078125 (1.440 sec)
9.108... logprob:  0.586765, 0.171875 (1.401 sec)
9.109... logprob:  0.336265, 0.078125 (1.401 sec)
9.110... logprob:  0.564291, 0.164062 (1.402 sec)
9.111... logprob:  0.404783, 0.101562 (1.394 sec)
9.112... logprob:  0.366311, 0.093750 (1.404 sec)
9.113... logprob:  0.354821, 0.085938 (1.397 sec)
9.114... logprob:  0.440253, 0.117188 (1.435 sec)
9.115... logprob:  0.506718, 0.140625 (1.412 sec)
9.116... logprob:  0.393442, 0.101562 (1.404 sec)
9.117... logprob:  0.440400, 0.117188 (1.442 sec)
9.118... logprob:  0.409235, 0.101562 (1.393 sec)
9.119... logprob:  0.346156, 0.085938 (1.539 sec)
9.120... logprob:  0.547184, 0.156250 (1.404 sec)
9.121... logprob:  0.412740, 0.109375 (1.397 sec)
9.122... logprob:  0.519442, 0.148438 (1.447 sec)
9.123... logprob:  0.463807, 0.125000 (1.387 sec)
9.124... logprob:  0.447732, 0.125000 (1.411 sec)
9.125... logprob:  0.502070, 0.140625 (1.400 sec)
9.126... logprob:  0.475867, 0.125000 (1.394 sec)
9.127... logprob:  0.479722, 0.125000 (1.395 sec)
9.128... logprob:  0.422419, 0.109375 (1.421 sec)
9.129... logprob:  0.574911, 0.164062 (1.418 sec)
9.130... logprob:  0.382791, 0.093750 (1.420 sec)
9.131... logprob:  0.495510, 0.132812 (1.409 sec)
9.132... logprob:  0.506407, 0.140625 (1.434 sec)
9.133... logprob:  0.444685, 0.117188 (1.394 sec)
9.134... logprob:  0.401947, 0.101562 (1.393 sec)
9.135... logprob:  0.460283, 0.125000 (1.417 sec)
9.136... logprob:  0.562707, 0.164062 (1.394 sec)
9.137... logprob:  0.462556, 0.125000 (1.403 sec)
9.138... logprob:  0.319312, 0.070312 (1.445 sec)
9.139... logprob:  0.395840, 0.101562 (1.398 sec)
9.140... logprob:  0.560789, 0.164062 (1.417 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.47993469238281, 10.0]}, 128)
batch 872: ({'logprob': [66.72138977050781, 19.0]}, 128)
batch 873: ({'logprob': [40.6480712890625, 9.0]}, 128)
batch 874: ({'logprob': [45.56005859375, 11.0]}, 128)
batch 875: ({'logprob': [50.96321105957031, 13.0]}, 128)
batch 876: ({'logprob': [64.1517562866211, 18.0]}, 128)
batch 877: ({'logprob': [45.809043884277344, 11.0]}, 128)
batch 878: ({'logprob': [61.797218322753906, 17.0]}, 128)
batch 879: ({'logprob': [72.85490417480469, 21.0]}, 128)
batch 880: ({'logprob': [50.97529602050781, 13.0]}, 128)
batch 881: ({'logprob': [29.563371658325195, 5.0]}, 128)
batch 882: ({'logprob': [54.28977966308594, 14.0]}, 128)
batch 883: ({'logprob': [61.78794860839844, 17.0]}, 128)
batch 884: ({'logprob': [51.203773498535156, 13.0]}, 128)
batch 885: ({'logprob': [51.69631576538086, 13.0]}, 128)
batch 886: ({'logprob': [62.036109924316406, 17.0]}, 128)

======================Test output======================
logprob:  0.416278, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.974125e-03 [2.424396e-09] 
Layer 'conv1' biases: 6.289019e-08 [4.754321e-11] 
Layer 'conv2' weights[0]: 7.961119e-03 [1.655236e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.460119e-10] 
Layer 'conv3' weights[0]: 7.959408e-03 [1.440425e-09] 
Layer 'conv3' biases: 5.848675e-07 [7.607887e-10] 
Layer 'conv4' weights[0]: 7.991934e-03 [1.425124e-09] 
Layer 'conv4' biases: 9.999998e-01 [5.751215e-09] 
Layer 'conv5' weights[0]: 7.990875e-03 [3.090266e-08] 
Layer 'conv5' biases: 9.999996e-01 [3.326918e-08] 
Layer 'fc6' weights[0]: 7.587662e-03 [2.843540e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.788540e-09] 
Layer 'fc7' weights[0]: 7.579225e-03 [1.101655e-07] 
Layer 'fc7' biases: 9.998685e-01 [9.465784e-08] 
Layer 'fc8' weights[0]: 1.306103e-03 [3.913492e-06] 
Layer 'fc8' biases: 1.782294e-02 [2.652364e-05] 
Train error last 870 batches: 0.435305
-------------------------------------------------------
Not saving because 0.416278 > 0.415712 (4.190: -0.00%)
======================================================= (12.040 sec)
9.141... logprob:  0.464508, 0.125000 (1.443 sec)
9.142... logprob:  0.464585, 0.125000 (1.401 sec)
9.143... logprob:  0.294186, 0.062500 (1.425 sec)
9.144... logprob:  0.457486, 0.125000 (1.420 sec)
9.145... logprob:  0.325008, 0.078125 (1.415 sec)
9.146... logprob:  0.483328, 0.132812 (1.412 sec)
9.147... logprob:  0.262493, 0.054688 (1.433 sec)
9.148... logprob:  0.458963, 0.125000 (1.396 sec)
9.149... logprob:  0.442600, 0.117188 (1.396 sec)
9.150... logprob:  0.347670, 0.085938 (1.401 sec)
9.151... logprob:  0.347167, 0.085938 (1.401 sec)
9.152... logprob:  0.784895, 0.234375 (1.388 sec)
9.153... logprob:  0.381692, 0.093750 (1.451 sec)
9.154... logprob:  0.524211, 0.148438 (1.404 sec)
9.155... logprob:  0.425894, 0.117188 (1.414 sec)
9.156... logprob:  0.296276, 0.062500 (1.434 sec)
9.157... logprob:  0.271169, 0.054688 (1.399 sec)
9.158... logprob:  0.455329, 0.125000 (1.404 sec)
9.159... logprob:  0.483134, 0.132812 (1.396 sec)
9.160... logprob:  0.445020, 0.117188 (1.398 sec)
9.161... logprob:  0.350431, 0.078125 (1.398 sec)
9.162... logprob:  0.611857, 0.179688 (1.409 sec)
9.163... logprob:  0.450389, 0.125000 (1.425 sec)
9.164... logprob:  0.468811, 0.125000 (1.420 sec)
9.165... logprob:  0.548103, 0.156250 (1.421 sec)
9.166... logprob:  0.446002, 0.125000 (1.452 sec)
9.167... logprob:  0.350272, 0.085938 (1.440 sec)
9.168... logprob:  0.363633, 0.085938 (1.427 sec)
9.169... logprob:  0.408735, 0.101562 (1.469 sec)
9.170... logprob:  0.459518, 0.125000 (1.404 sec)
9.171... logprob:  0.535604, 0.156250 (1.422 sec)
9.172... logprob:  0.434929, 0.109375 (1.418 sec)
9.173... logprob:  0.440521, 0.117188 (1.422 sec)
9.174... logprob:  0.601400, 0.171875 (1.404 sec)
9.175... logprob:  0.506221, 0.140625 (1.467 sec)
9.176... logprob:  0.478552, 0.132812 (1.420 sec)
9.177... logprob:  0.289809, 0.054688 (1.426 sec)
9.178... logprob:  0.383500, 0.093750 (1.464 sec)
9.179... logprob:  0.394780, 0.101562 (1.407 sec)
9.180... logprob:  0.466369, 0.125000 (1.424 sec)
9.181... logprob:  0.539495, 0.156250 (1.415 sec)
9.182... logprob:  0.371494, 0.093750 (1.421 sec)
9.183... logprob:  0.419979, 0.109375 (1.415 sec)
9.184... logprob:  0.483512, 0.132812 (1.425 sec)
9.185... logprob:  0.289948, 0.062500 (1.396 sec)
9.186... logprob:  0.370614, 0.093750 (1.404 sec)
9.187... logprob:  0.529641, 0.148438 (1.398 sec)
9.188... logprob:  0.459075, 0.125000 (1.399 sec)
9.189... logprob:  0.440903, 0.117188 (1.390 sec)
9.190... logprob:  0.375716, 0.093750 (1.439 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.694541931152344, 10.0]}, 128)
batch 872: ({'logprob': [67.04327392578125, 19.0]}, 128)
batch 873: ({'logprob': [40.1283073425293, 9.0]}, 128)
batch 874: ({'logprob': [45.073219299316406, 11.0]}, 128)
batch 875: ({'logprob': [50.73463821411133, 13.0]}, 128)
batch 876: ({'logprob': [64.40100860595703, 18.0]}, 128)
batch 877: ({'logprob': [45.43418502807617, 11.0]}, 128)
batch 878: ({'logprob': [62.08599853515625, 17.0]}, 128)
batch 879: ({'logprob': [73.77284240722656, 21.0]}, 128)
batch 880: ({'logprob': [50.74669647216797, 13.0]}, 128)
batch 881: ({'logprob': [28.41334342956543, 5.0]}, 128)
batch 882: ({'logprob': [54.47333908081055, 14.0]}, 128)
batch 883: ({'logprob': [62.076690673828125, 17.0]}, 128)
batch 884: ({'logprob': [51.08881759643555, 13.0]}, 128)
batch 885: ({'logprob': [51.807491302490234, 13.0]}, 128)
batch 886: ({'logprob': [62.43826675415039, 17.0]}, 128)

======================Test output======================
logprob:  0.415729, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.974080e-03 [2.074223e-09] 
Layer 'conv1' biases: 6.364294e-08 [3.885250e-11] 
Layer 'conv2' weights[0]: 7.961075e-03 [1.493083e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.086971e-10] 
Layer 'conv3' weights[0]: 7.959373e-03 [1.149275e-09] 
Layer 'conv3' biases: 5.918045e-07 [3.230168e-10] 
Layer 'conv4' weights[0]: 7.991898e-03 [1.110632e-09] 
Layer 'conv4' biases: 9.999998e-01 [5.054354e-10] 
Layer 'conv5' weights[0]: 7.990839e-03 [2.549980e-09] 
Layer 'conv5' biases: 9.999998e-01 [2.198305e-09] 
Layer 'fc6' weights[0]: 7.587615e-03 [7.830688e-10] 
Layer 'fc6' biases: 1.000000e+00 [1.898616e-10] 
Layer 'fc7' weights[0]: 7.577316e-03 [3.848411e-08] 
Layer 'fc7' biases: 9.998688e-01 [6.603309e-09] 
Layer 'fc8' weights[0]: 1.334937e-03 [1.035253e-06] 
Layer 'fc8' biases: 1.811230e-02 [5.532294e-06] 
Train error last 870 batches: 0.435304
-------------------------------------------------------
Not saving because 0.415729 > 0.415712 (4.190: -0.00%)
======================================================= (12.204 sec)
9.191... logprob:  0.485115, 0.132812 (1.416 sec)
9.192... logprob:  0.520271, 0.148438 (1.426 sec)
9.193... logprob:  0.312690, 0.070312 (1.423 sec)
9.194... logprob:  0.414152, 0.109375 (1.417 sec)
9.195... logprob:  0.287348, 0.062500 (1.402 sec)
9.196... logprob:  0.410612, 0.109375 (1.394 sec)
9.197... logprob:  0.478058, 0.132812 (1.398 sec)
9.198... logprob:  0.355793, 0.085938 (1.408 sec)
9.199... logprob:  0.437196, 0.117188 (1.389 sec)
9.200... logprob:  0.440801, 0.117188 (1.440 sec)
9.201... logprob:  0.437104, 0.117188 (1.408 sec)
9.202... logprob:  0.538051, 0.148438 (1.434 sec)
9.203... logprob:  0.420498, 0.109375 (1.445 sec)
9.204... logprob:  0.504135, 0.140625 (1.392 sec)
9.205... logprob:  0.334446, 0.078125 (1.404 sec)
9.206... logprob:  0.361619, 0.093750 (1.402 sec)
9.207... logprob:  0.381989, 0.093750 (1.392 sec)
9.208... logprob:  0.490484, 0.140625 (1.402 sec)
9.209... logprob:  0.334639, 0.078125 (1.418 sec)
9.210... logprob:  0.586269, 0.171875 (1.420 sec)
9.211... logprob:  0.488244, 0.132812 (1.416 sec)
9.212... logprob:  0.526182, 0.148438 (1.413 sec)
9.213... logprob:  0.514940, 0.140625 (1.458 sec)
9.214... logprob:  0.459464, 0.125000 (1.432 sec)
9.215... logprob:  0.396167, 0.101562 (1.414 sec)
9.216... logprob:  0.517235, 0.140625 (1.469 sec)
9.217... logprob:  0.325217, 0.070312 (1.405 sec)
9.218... logprob:  0.463764, 0.125000 (1.422 sec)
9.219... logprob:  0.500361, 0.140625 (1.419 sec)
9.220... logprob:  0.414984, 0.109375 (1.423 sec)
9.221... logprob:  0.399530, 0.101562 (1.409 sec)
9.222... logprob:  0.554672, 0.164062 (1.457 sec)
9.223... logprob:  0.569392, 0.164062 (1.440 sec)
9.224... logprob:  0.405828, 0.101562 (1.428 sec)
9.225... logprob:  0.391968, 0.101562 (1.449 sec)
9.226... logprob:  0.424581, 0.109375 (1.432 sec)
9.227... logprob:  0.452811, 0.125000 (1.428 sec)
9.228... logprob:  0.417231, 0.109375 (1.419 sec)
9.229... logprob:  0.489359, 0.132812 (1.416 sec)
9.230... logprob:  0.459923, 0.125000 (1.429 sec)
9.231... logprob:  0.453578, 0.125000 (1.413 sec)
9.232... logprob:  0.496262, 0.140625 (1.458 sec)
9.233... logprob:  0.466234, 0.132812 (1.428 sec)
9.234... logprob:  0.563769, 0.164062 (1.430 sec)
9.235... logprob:  0.482049, 0.132812 (1.475 sec)
9.236... logprob:  0.425872, 0.109375 (1.407 sec)
9.237... logprob:  0.341530, 0.078125 (1.429 sec)
9.238... logprob:  0.389507, 0.093750 (1.413 sec)
9.239... logprob:  0.478182, 0.132812 (1.425 sec)
9.240... logprob:  0.485824, 0.132812 (1.400 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.33122634887695, 10.0]}, 128)
batch 872: ({'logprob': [66.07848358154297, 19.0]}, 128)
batch 873: ({'logprob': [41.381500244140625, 9.0]}, 128)
batch 874: ({'logprob': [45.72972869873047, 11.0]}, 128)
batch 875: ({'logprob': [51.050846099853516, 13.0]}, 128)
batch 876: ({'logprob': [63.669681549072266, 18.0]}, 128)
batch 877: ({'logprob': [46.219417572021484, 11.0]}, 128)
batch 878: ({'logprob': [61.71802520751953, 17.0]}, 128)
batch 879: ({'logprob': [72.84818267822266, 21.0]}, 128)
batch 880: ({'logprob': [51.062137603759766, 13.0]}, 128)
batch 881: ({'logprob': [30.22372055053711, 5.0]}, 128)
batch 882: ({'logprob': [54.93489074707031, 14.0]}, 128)
batch 883: ({'logprob': [61.70866394042969, 17.0]}, 128)
batch 884: ({'logprob': [51.530399322509766, 13.0]}, 128)
batch 885: ({'logprob': [52.50286102294922, 13.0]}, 128)
batch 886: ({'logprob': [62.19640350341797, 17.0]}, 128)

======================Test output======================
logprob:  0.417571, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.974038e-03 [2.129360e-09] 
Layer 'conv1' biases: 6.426959e-08 [4.148768e-11] 
Layer 'conv2' weights[0]: 7.961040e-03 [1.435225e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.387872e-10] 
Layer 'conv3' weights[0]: 7.959328e-03 [1.167368e-09] 
Layer 'conv3' biases: 5.972785e-07 [4.034360e-10] 
Layer 'conv4' weights[0]: 7.991864e-03 [1.135192e-09] 
Layer 'conv4' biases: 9.999999e-01 [2.411011e-09] 
Layer 'conv5' weights[0]: 7.990797e-03 [1.280663e-08] 
Layer 'conv5' biases: 9.999998e-01 [1.372936e-08] 
Layer 'fc6' weights[0]: 7.587576e-03 [1.383418e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.146536e-09] 
Layer 'fc7' weights[0]: 7.575397e-03 [8.179457e-08] 
Layer 'fc7' biases: 9.998682e-01 [6.500942e-08] 
Layer 'fc8' weights[0]: 1.302961e-03 [2.728121e-06] 
Layer 'fc8' biases: 1.795392e-02 [1.885620e-05] 
Train error last 870 batches: 0.435304
-------------------------------------------------------
Not saving because 0.417571 > 0.415712 (4.190: -0.00%)
======================================================= (12.084 sec)
9.241... logprob:  0.493617, 0.132812 (1.469 sec)
9.242... logprob:  0.341653, 0.078125 (1.435 sec)
9.243... logprob:  0.386029, 0.093750 (1.431 sec)
9.244... logprob:  0.315128, 0.070312 (1.447 sec)
9.245... logprob:  0.494422, 0.132812 (1.429 sec)
9.246... logprob:  0.416948, 0.109375 (1.421 sec)
9.247... logprob:  0.357258, 0.085938 (1.420 sec)
9.248... logprob:  0.307614, 0.070312 (1.415 sec)
9.249... logprob:  0.555878, 0.156250 (1.421 sec)
9.250... logprob:  0.591991, 0.164062 (1.411 sec)
9.251... logprob:  0.352877, 0.085938 (1.459 sec)
9.252... logprob:  0.348535, 0.085938 (1.431 sec)
9.253... logprob:  0.379147, 0.093750 (1.414 sec)
9.254... logprob:  0.444189, 0.117188 (1.472 sec)
9.255... logprob:  0.351586, 0.085938 (1.404 sec)
9.256... logprob:  0.378691, 0.093750 (1.425 sec)
9.257... logprob:  0.332087, 0.078125 (1.416 sec)
9.258... logprob:  0.415906, 0.109375 (1.420 sec)
9.259... logprob:  0.442319, 0.117188 (1.402 sec)
9.260... logprob:  0.308493, 0.070312 (1.463 sec)
9.261... logprob:  0.392950, 0.101562 (1.425 sec)
9.262... logprob:  0.524773, 0.148438 (1.434 sec)
9.263... logprob:  0.425423, 0.109375 (1.447 sec)
9.264... logprob:  0.375224, 0.093750 (1.427 sec)
9.265... logprob:  0.439621, 0.117188 (1.414 sec)
9.266... logprob:  0.439065, 0.117188 (1.421 sec)
9.267... logprob:  0.421996, 0.109375 (1.417 sec)
9.268... logprob:  0.458957, 0.125000 (1.420 sec)
9.269... logprob:  0.567432, 0.164062 (1.411 sec)
9.270... logprob:  0.542159, 0.156250 (1.458 sec)
9.271... logprob:  0.445829, 0.117188 (1.432 sec)
9.272... logprob:  0.384847, 0.093750 (1.416 sec)
9.273... logprob:  0.500213, 0.140625 (1.471 sec)
9.274... logprob:  0.542565, 0.156250 (1.399 sec)
9.275... logprob:  0.487825, 0.132812 (1.427 sec)
9.276... logprob:  0.390251, 0.093750 (1.417 sec)
9.277... logprob:  0.428784, 0.109375 (1.439 sec)
9.278... logprob:  0.323284, 0.070312 (1.426 sec)
9.279... logprob:  0.324841, 0.070312 (1.462 sec)
9.280... logprob:  0.214810, 0.031250 (1.408 sec)
9.281... logprob:  0.417214, 0.109375 (1.424 sec)
9.282... logprob:  0.411540, 0.109375 (1.421 sec)
9.283... logprob:  0.393918, 0.101562 (1.418 sec)
9.284... logprob:  0.394837, 0.101562 (1.410 sec)
9.285... logprob:  0.452487, 0.117188 (1.444 sec)
9.286... logprob:  0.537993, 0.140625 (1.438 sec)
9.287... logprob:  0.346746, 0.085938 (1.434 sec)
9.288... logprob:  0.330002, 0.078125 (1.434 sec)
9.289... logprob:  0.446117, 0.117188 (1.447 sec)
9.290... logprob:  0.490641, 0.132812 (1.409 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.9820442199707, 10.0]}, 128)
batch 872: ({'logprob': [68.56195831298828, 19.0]}, 128)
batch 873: ({'logprob': [39.450347900390625, 9.0]}, 128)
batch 874: ({'logprob': [44.73637771606445, 11.0]}, 128)
batch 875: ({'logprob': [50.90170669555664, 13.0]}, 128)
batch 876: ({'logprob': [65.70899200439453, 18.0]}, 128)
batch 877: ({'logprob': [45.177650451660156, 11.0]}, 128)
batch 878: ({'logprob': [63.26342010498047, 17.0]}, 128)
batch 879: ({'logprob': [76.0414047241211, 21.0]}, 128)
batch 880: ({'logprob': [50.914005279541016, 13.0]}, 128)
batch 881: ({'logprob': [26.642749786376953, 5.0]}, 128)
batch 882: ({'logprob': [55.09960174560547, 14.0]}, 128)
batch 883: ({'logprob': [63.254127502441406, 17.0]}, 128)
batch 884: ({'logprob': [51.33977127075195, 13.0]}, 128)
batch 885: ({'logprob': [52.223331451416016, 13.0]}, 128)
batch 886: ({'logprob': [63.69891357421875, 17.0]}, 128)

======================Test output======================
logprob:  0.418944, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.973998e-03 [4.740209e-09] 
Layer 'conv1' biases: 6.502970e-08 [1.512925e-10] 
Layer 'conv2' weights[0]: 7.960999e-03 [4.004977e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.454109e-10] 
Layer 'conv3' weights[0]: 7.959286e-03 [4.013764e-09] 
Layer 'conv3' biases: 6.021994e-07 [2.618859e-09] 
Layer 'conv4' weights[0]: 7.991828e-03 [4.453253e-09] 
Layer 'conv4' biases: 9.999999e-01 [2.524721e-08] 
Layer 'conv5' weights[0]: 7.990758e-03 [1.717314e-07] 
Layer 'conv5' biases: 9.999999e-01 [1.865628e-07] 
Layer 'fc6' weights[0]: 7.587542e-03 [1.522635e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.546727e-08] 
Layer 'fc7' weights[0]: 7.573474e-03 [2.939279e-07] 
Layer 'fc7' biases: 9.998698e-01 [2.831047e-07] 
Layer 'fc8' weights[0]: 1.382398e-03 [1.171592e-05] 
Layer 'fc8' biases: 1.866427e-02 [6.066057e-05] 
Train error last 870 batches: 0.435303
-------------------------------------------------------
Not saving because 0.418944 > 0.415712 (4.190: -0.00%)
======================================================= (12.033 sec)
9.291... logprob:  0.439081, 0.117188 (1.430 sec)
9.292... logprob:  0.566735, 0.156250 (1.425 sec)
9.293... logprob:  0.427388, 0.117188 (1.420 sec)
9.294... logprob:  0.356413, 0.085938 (1.408 sec)
9.295... logprob:  0.335487, 0.078125 (1.464 sec)
9.296... logprob:  0.356541, 0.085938 (1.417 sec)
9.297... logprob:  0.395029, 0.101562 (1.420 sec)
9.298... logprob:  0.448043, 0.125000 (1.463 sec)
9.299... logprob:  0.342933, 0.078125 (1.406 sec)
9.300... logprob:  0.406841, 0.101562 (1.424 sec)
9.301... logprob:  0.397993, 0.101562 (1.420 sec)
9.302... logprob:  0.591571, 0.179688 (1.419 sec)
9.303... logprob:  0.459723, 0.125000 (1.414 sec)
9.304... logprob:  0.459766, 0.125000 (1.445 sec)
9.305... logprob:  0.455266, 0.125000 (1.434 sec)
9.306... logprob:  0.440639, 0.117188 (1.441 sec)
9.307... logprob:  0.421598, 0.109375 (1.441 sec)
9.308... logprob:  0.374438, 0.093750 (1.456 sec)
9.309... logprob:  0.450497, 0.125000 (1.417 sec)
9.310... logprob:  0.473854, 0.125000 (1.458 sec)
9.311... logprob:  0.502755, 0.140625 (1.442 sec)
9.312... logprob:  0.478858, 0.132812 (1.430 sec)
9.313... logprob:  0.454880, 0.125000 (1.419 sec)
9.314... logprob:  0.454606, 0.117188 (1.466 sec)
9.315... logprob:  0.314720, 0.070312 (1.432 sec)
9.316... logprob:  0.468617, 0.125000 (1.430 sec)
9.317... logprob:  0.355583, 0.085938 (1.479 sec)
9.318... logprob:  0.455433, 0.125000 (1.412 sec)
9.319... logprob:  0.423243, 0.117188 (1.426 sec)
9.320... logprob:  0.412283, 0.109375 (1.427 sec)
9.321... logprob:  0.348322, 0.085938 (1.428 sec)
9.322... logprob:  0.387578, 0.101562 (1.412 sec)
9.323... logprob:  0.416539, 0.109375 (1.479 sec)
9.324... logprob:  0.498670, 0.140625 (1.425 sec)
9.325... logprob:  0.350686, 0.085938 (1.439 sec)
9.326... logprob:  0.543210, 0.148438 (1.462 sec)
9.327... logprob:  0.554423, 0.164062 (1.427 sec)
9.328... logprob:  0.564980, 0.156250 (1.420 sec)
9.329... logprob:  0.402048, 0.101562 (1.431 sec)
9.330... logprob:  0.388747, 0.101562 (1.420 sec)
9.331... logprob:  0.352661, 0.085938 (1.422 sec)
9.332... logprob:  0.482809, 0.132812 (1.448 sec)
9.333... logprob:  0.339703, 0.085938 (1.451 sec)
9.334... logprob:  0.565034, 0.171875 (1.440 sec)
9.335... logprob:  0.358954, 0.085938 (1.444 sec)
9.336... logprob:  0.444815, 0.125000 (1.453 sec)
9.337... logprob:  0.566524, 0.164062 (1.421 sec)
9.338... logprob:  0.449516, 0.125000 (1.418 sec)
9.339... logprob:  0.488772, 0.132812 (1.428 sec)
9.340... logprob:  0.442091, 0.117188 (1.432 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.30515670776367, 10.0]}, 128)
batch 872: ({'logprob': [65.79202270507812, 19.0]}, 128)
batch 873: ({'logprob': [42.104774475097656, 9.0]}, 128)
batch 874: ({'logprob': [45.99991989135742, 11.0]}, 128)
batch 875: ({'logprob': [51.287437438964844, 13.0]}, 128)
batch 876: ({'logprob': [63.5042839050293, 18.0]}, 128)
batch 877: ({'logprob': [46.69898986816406, 11.0]}, 128)
batch 878: ({'logprob': [61.88475036621094, 17.0]}, 128)
batch 879: ({'logprob': [73.1539077758789, 21.0]}, 128)
batch 880: ({'logprob': [51.29771423339844, 13.0]}, 128)
batch 881: ({'logprob': [30.807842254638672, 5.0]}, 128)
batch 882: ({'logprob': [55.67601776123047, 14.0]}, 128)
batch 883: ({'logprob': [61.87558364868164, 17.0]}, 128)
batch 884: ({'logprob': [51.97535705566406, 13.0]}, 128)
batch 885: ({'logprob': [53.36600112915039, 13.0]}, 128)
batch 886: ({'logprob': [62.5718994140625, 17.0]}, 128)

======================Test output======================
logprob:  0.420069, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.973957e-03 [2.285395e-09] 
Layer 'conv1' biases: 6.571629e-08 [3.113829e-11] 
Layer 'conv2' weights[0]: 7.960962e-03 [1.592762e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.314148e-10] 
Layer 'conv3' weights[0]: 7.959249e-03 [1.235253e-09] 
Layer 'conv3' biases: 6.080355e-07 [4.095110e-10] 
Layer 'conv4' weights[0]: 7.991787e-03 [1.226692e-09] 
Layer 'conv4' biases: 9.999999e-01 [2.298857e-09] 
Layer 'conv5' weights[0]: 7.990715e-03 [1.249378e-08] 
Layer 'conv5' biases: 1.000000e+00 [1.334327e-08] 
Layer 'fc6' weights[0]: 7.587502e-03 [1.365634e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.114771e-09] 
Layer 'fc7' weights[0]: 7.571590e-03 [3.806457e-08] 
Layer 'fc7' biases: 9.998682e-01 [4.197529e-09] 
Layer 'fc8' weights[0]: 1.292937e-03 [1.302721e-06] 
Layer 'fc8' biases: 1.827110e-02 [7.567847e-06] 
Train error last 870 batches: 0.435303
-------------------------------------------------------
Not saving because 0.420069 > 0.415712 (4.190: -0.00%)
======================================================= (12.171 sec)
9.341... logprob:  0.530212, 0.148438 (1.424 sec)
9.342... logprob:  0.429737, 0.109375 (1.475 sec)
9.343... logprob:  0.434810, 0.109375 (1.436 sec)
9.344... logprob:  0.444373, 0.125000 (1.482 sec)
9.345... logprob:  0.488313, 0.132812 (1.438 sec)
9.346... logprob:  0.436272, 0.117188 (1.434 sec)
9.347... logprob:  0.372268, 0.085938 (1.480 sec)
9.348... logprob:  0.398432, 0.101562 (1.433 sec)
9.349... logprob:  0.498033, 0.140625 (1.436 sec)
9.350... logprob:  0.358479, 0.085938 (1.436 sec)
9.351... logprob:  0.508779, 0.140625 (1.428 sec)
9.352... logprob:  0.363709, 0.093750 (1.428 sec)
9.353... logprob:  0.512980, 0.148438 (1.489 sec)
9.354... logprob:  0.675316, 0.203125 (1.436 sec)
9.355... logprob:  0.357462, 0.085938 (1.443 sec)
9.356... logprob:  0.479271, 0.132812 (1.482 sec)
9.357... logprob:  0.347203, 0.085938 (1.433 sec)
9.358... logprob:  0.326158, 0.070312 (1.523 sec)
9.359... logprob:  0.555169, 0.164062 (1.434 sec)
9.360... logprob:  0.444516, 0.117188 (1.433 sec)
9.361... logprob:  0.410793, 0.101562 (1.433 sec)
9.362... logprob:  0.424243, 0.117188 (1.480 sec)
9.363... logprob:  0.486593, 0.132812 (1.441 sec)
9.364... logprob:  0.475506, 0.125000 (1.450 sec)
9.365... logprob:  0.425117, 0.109375 (1.465 sec)
9.366... logprob:  0.409772, 0.109375 (1.447 sec)
9.367... logprob:  0.325061, 0.078125 (1.441 sec)
9.368... logprob:  0.595770, 0.171875 (1.428 sec)
9.369... logprob:  0.381470, 0.093750 (1.423 sec)
9.370... logprob:  0.381098, 0.093750 (1.435 sec)
9.371... logprob:  0.400315, 0.101562 (1.457 sec)
9.372... logprob:  0.537781, 0.156250 (1.447 sec)
9.373... logprob:  0.463855, 0.125000 (1.454 sec)
9.374... logprob:  0.527213, 0.148438 (1.450 sec)
9.375... logprob:  0.393799, 0.101562 (1.467 sec)
9.376... logprob:  0.374343, 0.093750 (1.441 sec)
9.377... logprob:  0.295365, 0.062500 (1.426 sec)
9.378... logprob:  0.453822, 0.125000 (1.430 sec)
9.379... logprob:  0.420238, 0.109375 (1.442 sec)
9.380... logprob:  0.605788, 0.179688 (1.440 sec)
9.381... logprob:  0.463528, 0.125000 (1.472 sec)
9.382... logprob:  0.529462, 0.148438 (1.450 sec)
9.383... logprob:  0.358793, 0.085938 (1.441 sec)
9.384... logprob:  0.520961, 0.148438 (1.485 sec)
9.385... logprob:  0.523415, 0.148438 (1.443 sec)
9.386... logprob:  0.582229, 0.171875 (1.425 sec)
9.387... logprob:  0.428774, 0.117188 (1.433 sec)
9.388... logprob:  0.521287, 0.148438 (1.435 sec)
9.389... logprob:  0.426086, 0.109375 (1.436 sec)
9.390... logprob:  0.420054, 0.109375 (1.478 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.866668701171875, 10.0]}, 128)
batch 872: ({'logprob': [65.84854125976562, 19.0]}, 128)
batch 873: ({'logprob': [42.946414947509766, 9.0]}, 128)
batch 874: ({'logprob': [46.993553161621094, 11.0]}, 128)
batch 875: ({'logprob': [51.918025970458984, 13.0]}, 128)
batch 876: ({'logprob': [63.61373519897461, 18.0]}, 128)
batch 877: ({'logprob': [47.436500549316406, 11.0]}, 128)
batch 878: ({'logprob': [61.78943634033203, 17.0]}, 128)
batch 879: ({'logprob': [72.07626342773438, 21.0]}, 128)
batch 880: ({'logprob': [51.92910385131836, 13.0]}, 128)
batch 881: ({'logprob': [32.633235931396484, 5.0]}, 128)
batch 882: ({'logprob': [55.480491638183594, 14.0]}, 128)
batch 883: ({'logprob': [61.779903411865234, 17.0]}, 128)
batch 884: ({'logprob': [52.34746170043945, 13.0]}, 128)
batch 885: ({'logprob': [53.22206497192383, 13.0]}, 128)
batch 886: ({'logprob': [62.21811294555664, 17.0]}, 128)

======================Test output======================
logprob:  0.422900, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.973907e-03 [2.365770e-09] 
Layer 'conv1' biases: 6.651219e-08 [9.428265e-11] 
Layer 'conv2' weights[0]: 7.960924e-03 [2.551896e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.585741e-10] 
Layer 'conv3' weights[0]: 7.959208e-03 [2.737505e-09] 
Layer 'conv3' biases: 6.145984e-07 [1.688730e-09] 
Layer 'conv4' weights[0]: 7.991750e-03 [3.096797e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.742948e-08] 
Layer 'conv5' weights[0]: 7.990683e-03 [1.201962e-07] 
Layer 'conv5' biases: 1.000000e+00 [1.309057e-07] 
Layer 'fc6' weights[0]: 7.587464e-03 [1.034549e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.051295e-08] 
Layer 'fc7' weights[0]: 7.569663e-03 [5.339639e-08] 
Layer 'fc7' biases: 9.998668e-01 [3.155973e-08] 
Layer 'fc8' weights[0]: 1.267167e-03 [2.801132e-06] 
Layer 'fc8' biases: 1.818393e-02 [1.960344e-05] 
Train error last 870 batches: 0.435303
-------------------------------------------------------
Not saving because 0.422900 > 0.415712 (4.190: -0.00%)
======================================================= (12.143 sec)
9.391... logprob:  0.318456, 0.070312 (1.446 sec)
9.392... logprob:  0.439402, 0.117188 (1.434 sec)
9.393... logprob:  0.368729, 0.093750 (1.488 sec)
9.394... logprob:  0.343365, 0.078125 (1.435 sec)
9.395... logprob:  0.331380, 0.078125 (1.434 sec)
9.396... logprob:  0.251460, 0.046875 (1.436 sec)
9.397... logprob:  0.485094, 0.132812 (1.433 sec)
9.398... logprob:  0.471878, 0.125000 (1.432 sec)
9.399... logprob:  0.434038, 0.117188 (1.491 sec)
9.400... logprob:  0.539198, 0.148438 (1.436 sec)
9.401... logprob:  0.466487, 0.125000 (1.443 sec)
9.402... logprob:  0.474521, 0.125000 (1.491 sec)
9.403... logprob:  0.462313, 0.125000 (1.429 sec)
9.404... logprob:  0.474838, 0.125000 (1.433 sec)
9.405... logprob:  0.543582, 0.156250 (1.435 sec)
9.406... logprob:  0.358146, 0.085938 (1.429 sec)
9.407... logprob:  0.492487, 0.140625 (1.432 sec)
9.408... logprob:  0.340299, 0.078125 (1.486 sec)
9.409... logprob:  0.401383, 0.101562 (1.438 sec)
9.410... logprob:  0.581448, 0.171875 (1.452 sec)
9.411... logprob:  0.398630, 0.101562 (1.474 sec)
9.412... logprob:  0.540162, 0.156250 (1.441 sec)
9.413... logprob:  0.544782, 0.156250 (1.437 sec)
9.414... logprob:  0.466783, 0.125000 (1.430 sec)
9.415... logprob:  0.401836, 0.101562 (1.421 sec)
9.416... logprob:  0.427589, 0.109375 (1.437 sec)
9.417... logprob:  0.405348, 0.093750 (1.459 sec)
9.418... logprob:  0.379822, 0.093750 (1.463 sec)
9.419... logprob:  0.417336, 0.101562 (1.456 sec)
9.420... logprob:  0.355507, 0.085938 (1.453 sec)
9.421... logprob:  0.376518, 0.101562 (1.454 sec)
9.422... logprob:  0.523824, 0.148438 (1.437 sec)
9.423... logprob:  0.421216, 0.109375 (1.429 sec)
9.424... logprob:  0.324448, 0.078125 (1.429 sec)
9.425... logprob:  0.305891, 0.070312 (1.442 sec)
9.426... logprob:  0.449679, 0.117188 (1.444 sec)
9.427... logprob:  0.555664, 0.156250 (1.459 sec)
9.428... logprob:  0.602795, 0.171875 (1.451 sec)
9.429... logprob:  0.426186, 0.109375 (1.440 sec)
9.430... logprob:  0.300150, 0.070312 (1.468 sec)
9.431... logprob:  0.598678, 0.171875 (1.430 sec)
9.432... logprob:  0.387675, 0.093750 (1.428 sec)
9.433... logprob:  0.330766, 0.078125 (1.436 sec)
9.434... logprob:  0.528731, 0.148438 (1.438 sec)
9.435... logprob:  0.531747, 0.156250 (1.433 sec)
9.436... logprob:  0.382072, 0.093750 (1.474 sec)
9.437... logprob:  0.500177, 0.140625 (1.442 sec)
9.438... logprob:  0.546644, 0.156250 (1.427 sec)
9.439... logprob:  0.379634, 0.093750 (1.492 sec)
9.440... logprob:  0.440031, 0.117188 (1.432 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.59695053100586, 10.0]}, 128)
batch 872: ({'logprob': [65.83961486816406, 19.0]}, 128)
batch 873: ({'logprob': [42.68696594238281, 9.0]}, 128)
batch 874: ({'logprob': [46.77059555053711, 11.0]}, 128)
batch 875: ({'logprob': [51.754215240478516, 13.0]}, 128)
batch 876: ({'logprob': [63.58088302612305, 18.0]}, 128)
batch 877: ({'logprob': [47.22465515136719, 11.0]}, 128)
batch 878: ({'logprob': [61.744041442871094, 17.0]}, 128)
batch 879: ({'logprob': [72.16068267822266, 21.0]}, 128)
batch 880: ({'logprob': [51.76518249511719, 13.0]}, 128)
batch 881: ({'logprob': [32.243873596191406, 5.0]}, 128)
batch 882: ({'logprob': [55.375064849853516, 14.0]}, 128)
batch 883: ({'logprob': [61.73462677001953, 17.0]}, 128)
batch 884: ({'logprob': [52.19538116455078, 13.0]}, 128)
batch 885: ({'logprob': [53.09294891357422, 13.0]}, 128)
batch 886: ({'logprob': [62.18434524536133, 17.0]}, 128)

======================Test output======================
logprob:  0.421851, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.973867e-03 [3.337601e-09] 
Layer 'conv1' biases: 6.711275e-08 [7.354660e-11] 
Layer 'conv2' weights[0]: 7.960884e-03 [2.666165e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.025689e-10] 
Layer 'conv3' weights[0]: 7.959166e-03 [2.608066e-09] 
Layer 'conv3' biases: 6.193430e-07 [1.567487e-09] 
Layer 'conv4' weights[0]: 7.991721e-03 [2.904615e-09] 
Layer 'conv4' biases: 1.000000e+00 [1.575658e-08] 
Layer 'conv5' weights[0]: 7.990637e-03 [1.087849e-07] 
Layer 'conv5' biases: 1.000000e+00 [1.183844e-07] 
Layer 'fc6' weights[0]: 7.587421e-03 [9.457470e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.513701e-09] 
Layer 'fc7' weights[0]: 7.567723e-03 [5.809282e-08] 
Layer 'fc7' biases: 9.998671e-01 [3.738497e-08] 
Layer 'fc8' weights[0]: 1.267214e-03 [1.263008e-06] 
Layer 'fc8' biases: 1.859820e-02 [1.425400e-05] 
Train error last 870 batches: 0.435302
-------------------------------------------------------
Not saving because 0.421851 > 0.415712 (4.190: -0.00%)
======================================================= (12.066 sec)
9.441... logprob:  0.468096, 0.125000 (1.435 sec)
9.442... logprob:  0.378862, 0.093750 (1.437 sec)
9.443... logprob:  0.496613, 0.140625 (1.432 sec)
9.444... logprob:  0.371830, 0.093750 (1.432 sec)
9.445... logprob:  0.361782, 0.085938 (1.479 sec)
9.446... logprob:  0.397877, 0.101562 (1.437 sec)
9.447... logprob:  0.571072, 0.164062 (1.445 sec)
9.448... logprob:  0.332123, 0.078125 (1.482 sec)
9.449... logprob:  0.400032, 0.101562 (1.443 sec)
9.450... logprob:  0.238168, 0.046875 (1.452 sec)
9.451... logprob:  0.453436, 0.125000 (1.442 sec)
9.452... logprob:  0.456658, 0.117188 (1.424 sec)
9.453... logprob:  0.455824, 0.125000 (1.425 sec)
9.454... logprob:  0.489501, 0.132812 (1.488 sec)
9.455... logprob:  0.506165, 0.140625 (1.436 sec)
9.456... logprob:  0.468750, 0.125000 (1.445 sec)
9.457... logprob:  0.375456, 0.093750 (1.474 sec)
9.458... logprob:  0.351447, 0.085938 (1.436 sec)
9.459... logprob:  0.513335, 0.140625 (1.441 sec)
9.460... logprob:  0.275354, 0.054688 (1.434 sec)
9.461... logprob:  0.459880, 0.125000 (1.425 sec)
9.462... logprob:  0.471846, 0.125000 (1.439 sec)
9.463... logprob:  0.421079, 0.109375 (1.472 sec)
9.464... logprob:  0.482613, 0.132812 (1.453 sec)
9.465... logprob:  0.421308, 0.109375 (1.451 sec)
9.466... logprob:  0.318883, 0.070312 (1.463 sec)
9.467... logprob:  0.413894, 0.109375 (1.449 sec)
9.468... logprob:  0.394275, 0.101562 (1.442 sec)
9.469... logprob:  0.334501, 0.078125 (1.428 sec)
9.470... logprob:  0.400018, 0.101562 (1.431 sec)
9.471... logprob:  0.529999, 0.148438 (1.442 sec)
9.472... logprob:  0.410182, 0.109375 (1.451 sec)
9.473... logprob:  0.375240, 0.093750 (1.462 sec)
9.474... logprob:  0.466042, 0.125000 (1.452 sec)
9.475... logprob:  0.504831, 0.140625 (1.445 sec)
9.476... logprob:  0.510739, 0.140625 (1.550 sec)
9.477... logprob:  0.334418, 0.078125 (1.440 sec)
9.478... logprob:  0.464330, 0.125000 (1.430 sec)
9.479... logprob:  0.305859, 0.070312 (1.430 sec)
9.480... logprob:  0.443529, 0.117188 (1.443 sec)
9.481... logprob:  0.547654, 0.156250 (1.433 sec)
9.482... logprob:  0.443229, 0.117188 (1.472 sec)
9.483... logprob:  0.502466, 0.140625 (1.445 sec)
9.484... logprob:  0.485274, 0.132812 (1.440 sec)
9.485... logprob:  0.409235, 0.109375 (1.484 sec)
9.486... logprob:  0.361900, 0.085938 (1.437 sec)
9.487... logprob:  0.522569, 0.148438 (1.430 sec)
9.488... logprob:  0.425045, 0.109375 (1.435 sec)
9.489... logprob:  0.416051, 0.109375 (1.437 sec)
9.490... logprob:  0.440710, 0.117188 (1.432 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.59992980957031, 10.0]}, 128)
batch 872: ({'logprob': [66.17618560791016, 19.0]}, 128)
batch 873: ({'logprob': [41.34203338623047, 9.0]}, 128)
batch 874: ({'logprob': [45.831817626953125, 11.0]}, 128)
batch 875: ({'logprob': [51.104183197021484, 13.0]}, 128)
batch 876: ({'logprob': [63.74436569213867, 18.0]}, 128)
batch 877: ({'logprob': [46.22661209106445, 11.0]}, 128)
batch 878: ({'logprob': [61.67451095581055, 17.0]}, 128)
batch 879: ({'logprob': [72.61320495605469, 21.0]}, 128)
batch 880: ({'logprob': [51.115821838378906, 13.0]}, 128)
batch 881: ({'logprob': [30.376272201538086, 5.0]}, 128)
batch 882: ({'logprob': [54.72686767578125, 14.0]}, 128)
batch 883: ({'logprob': [61.66498947143555, 17.0]}, 128)
batch 884: ({'logprob': [51.4891242980957, 13.0]}, 128)
batch 885: ({'logprob': [52.271583557128906, 13.0]}, 128)
batch 886: ({'logprob': [62.0579719543457, 17.0]}, 128)

======================Test output======================
logprob:  0.417488, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.973819e-03 [2.011735e-09] 
Layer 'conv1' biases: 6.770669e-08 [4.501082e-11] 
Layer 'conv2' weights[0]: 7.960838e-03 [1.746855e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.732472e-10] 
Layer 'conv3' weights[0]: 7.959125e-03 [1.677228e-09] 
Layer 'conv3' biases: 6.238712e-07 [8.492077e-10] 
Layer 'conv4' weights[0]: 7.991685e-03 [1.898511e-09] 
Layer 'conv4' biases: 9.999998e-01 [8.704486e-09] 
Layer 'conv5' weights[0]: 7.990585e-03 [6.008136e-08] 
Layer 'conv5' biases: 9.999998e-01 [6.541121e-08] 
Layer 'fc6' weights[0]: 7.587386e-03 [5.250701e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.285547e-09] 
Layer 'fc7' weights[0]: 7.565756e-03 [1.014040e-07] 
Layer 'fc7' biases: 9.998679e-01 [8.575738e-08] 
Layer 'fc8' weights[0]: 1.292197e-03 [3.192592e-06] 
Layer 'fc8' biases: 1.897160e-02 [2.210320e-05] 
Train error last 870 batches: 0.435302
-------------------------------------------------------
Not saving because 0.417488 > 0.415712 (4.190: -0.00%)
======================================================= (12.046 sec)
9.491... logprob:  0.313758, 0.070312 (1.489 sec)
9.492... logprob:  0.459686, 0.125000 (1.440 sec)
9.493... logprob:  0.522128, 0.148438 (1.437 sec)
9.494... logprob:  0.450416, 0.125000 (1.484 sec)
9.495... logprob:  0.380438, 0.093750 (1.430 sec)
9.496... logprob:  0.550808, 0.156250 (1.431 sec)
9.497... logprob:  0.467178, 0.125000 (1.437 sec)
9.498... logprob:  0.476460, 0.132812 (1.434 sec)
9.499... logprob:  0.456334, 0.125000 (1.433 sec)
9.500... logprob:  0.355024, 0.085938 (1.485 sec)
9.501... logprob:  0.339115, 0.078125 (1.430 sec)
9.502... logprob:  0.459722, 0.125000 (1.444 sec)
9.503... logprob:  0.400727, 0.101562 (1.472 sec)
9.504... logprob:  0.487396, 0.132812 (1.432 sec)
9.505... logprob:  0.570825, 0.164062 (1.436 sec)
9.506... logprob:  0.479679, 0.132812 (1.438 sec)
9.507... logprob:  0.385248, 0.093750 (1.425 sec)
9.508... logprob:  0.374859, 0.093750 (1.435 sec)
9.509... logprob:  0.323417, 0.070312 (1.481 sec)
9.510... logprob:  0.390513, 0.101562 (1.440 sec)
9.511... logprob:  0.410119, 0.109375 (1.455 sec)
9.512... logprob:  0.470781, 0.125000 (1.468 sec)
9.513... logprob:  0.324990, 0.078125 (1.443 sec)
9.514... logprob:  0.406284, 0.101562 (1.443 sec)
9.515... logprob:  0.455725, 0.125000 (1.431 sec)
9.516... logprob:  0.400565, 0.109375 (1.426 sec)
9.517... logprob:  0.628328, 0.179688 (1.438 sec)
9.518... logprob:  0.437791, 0.117188 (1.463 sec)
9.519... logprob:  0.516193, 0.140625 (1.454 sec)
9.520... logprob:  0.409668, 0.109375 (1.455 sec)
9.521... logprob:  0.427604, 0.109375 (1.447 sec)
9.522... logprob:  0.533016, 0.156250 (1.464 sec)
9.523... logprob:  0.331996, 0.078125 (1.438 sec)
9.524... logprob:  0.437315, 0.117188 (1.430 sec)
9.525... logprob:  0.426256, 0.109375 (1.439 sec)
9.526... logprob:  0.352212, 0.078125 (1.439 sec)
9.527... logprob:  0.504516, 0.140625 (1.440 sec)
9.528... logprob:  0.440575, 0.117188 (1.466 sec)
9.529... logprob:  0.353036, 0.085938 (1.450 sec)
9.530... logprob:  0.440250, 0.117188 (1.442 sec)
9.531... logprob:  0.440075, 0.117188 (1.481 sec)
9.532... logprob:  0.467482, 0.125000 (1.429 sec)
9.533... logprob:  0.561022, 0.164062 (1.426 sec)
9.534... logprob:  0.325679, 0.078125 (1.429 sec)
9.535... logprob:  0.551900, 0.156250 (1.439 sec)
9.536... logprob:  0.507524, 0.140625 (1.435 sec)
9.537... logprob:  0.510153, 0.140625 (1.482 sec)
9.538... logprob:  0.486143, 0.132812 (1.443 sec)
9.539... logprob:  0.296254, 0.062500 (1.435 sec)
9.540... logprob:  0.447190, 0.117188 (1.482 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.4602165222168, 10.0]}, 128)
batch 872: ({'logprob': [66.16361236572266, 19.0]}, 128)
batch 873: ({'logprob': [41.29313659667969, 9.0]}, 128)
batch 874: ({'logprob': [45.753692626953125, 11.0]}, 128)
batch 875: ({'logprob': [51.05763244628906, 13.0]}, 128)
batch 876: ({'logprob': [63.73146057128906, 18.0]}, 128)
batch 877: ({'logprob': [46.178863525390625, 11.0]}, 128)
batch 878: ({'logprob': [61.69144821166992, 17.0]}, 128)
batch 879: ({'logprob': [72.72370910644531, 21.0]}, 128)
batch 880: ({'logprob': [51.0693359375, 13.0]}, 128)
batch 881: ({'logprob': [30.23360252380371, 5.0]}, 128)
batch 882: ({'logprob': [54.7724723815918, 14.0]}, 128)
batch 883: ({'logprob': [61.68172836303711, 17.0]}, 128)
batch 884: ({'logprob': [51.47322082519531, 13.0]}, 128)
batch 885: ({'logprob': [52.31669998168945, 13.0]}, 128)
batch 886: ({'logprob': [62.105438232421875, 17.0]}, 128)

======================Test output======================
logprob:  0.417337, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.973780e-03 [2.569809e-09] 
Layer 'conv1' biases: 6.838903e-08 [5.938155e-11] 
Layer 'conv2' weights[0]: 7.960800e-03 [1.724279e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.069929e-10] 
Layer 'conv3' weights[0]: 7.959086e-03 [1.708382e-09] 
Layer 'conv3' biases: 6.310318e-07 [9.299452e-10] 
Layer 'conv4' weights[0]: 7.991646e-03 [1.879145e-09] 
Layer 'conv4' biases: 9.999999e-01 [8.511544e-09] 
Layer 'conv5' weights[0]: 7.990549e-03 [5.514327e-08] 
Layer 'conv5' biases: 9.999999e-01 [5.994450e-08] 
Layer 'fc6' weights[0]: 7.587342e-03 [4.922532e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.905142e-09] 
Layer 'fc7' weights[0]: 7.563854e-03 [5.089983e-08] 
Layer 'fc7' biases: 9.998681e-01 [2.858687e-08] 
Layer 'fc8' weights[0]: 1.293958e-03 [4.414317e-06] 
Layer 'fc8' biases: 1.907261e-02 [2.743467e-05] 
Train error last 870 batches: 0.435301
-------------------------------------------------------
Not saving because 0.417337 > 0.415712 (4.190: -0.00%)
======================================================= (12.015 sec)
9.541... logprob:  0.388987, 0.101562 (1.435 sec)
9.542... logprob:  0.411390, 0.109375 (1.430 sec)
9.543... logprob:  0.233563, 0.039062 (1.438 sec)
9.544... logprob:  0.317976, 0.070312 (1.434 sec)
9.545... logprob:  0.348830, 0.085938 (1.433 sec)
9.546... logprob:  0.368311, 0.093750 (1.484 sec)
9.547... logprob:  0.440254, 0.117188 (1.432 sec)
9.548... logprob:  0.453453, 0.125000 (1.442 sec)
9.549... logprob:  0.490961, 0.132812 (1.477 sec)
9.550... logprob:  0.367772, 0.093750 (1.431 sec)
9.551... logprob:  0.441944, 0.117188 (1.438 sec)
9.552... logprob:  0.471407, 0.125000 (1.439 sec)
9.553... logprob:  0.349425, 0.085938 (1.425 sec)
9.554... logprob:  0.506732, 0.140625 (1.437 sec)
9.555... logprob:  0.421425, 0.109375 (1.479 sec)
9.556... logprob:  0.356061, 0.085938 (1.435 sec)
9.557... logprob:  0.396598, 0.101562 (1.449 sec)
9.558... logprob:  0.383126, 0.101562 (1.487 sec)
9.559... logprob:  0.441322, 0.125000 (1.434 sec)
9.560... logprob:  0.335590, 0.078125 (1.442 sec)
9.561... logprob:  0.411897, 0.109375 (1.430 sec)
9.562... logprob:  0.503107, 0.140625 (1.428 sec)
9.563... logprob:  0.373943, 0.093750 (1.438 sec)
9.564... logprob:  0.468384, 0.132812 (1.469 sec)
9.565... logprob:  0.610965, 0.187500 (1.452 sec)
9.566... logprob:  0.374958, 0.093750 (1.451 sec)
9.567... logprob:  0.423566, 0.109375 (1.452 sec)
9.568... logprob:  0.496434, 0.140625 (1.457 sec)
9.569... logprob:  0.508005, 0.140625 (1.440 sec)
9.570... logprob:  0.543681, 0.164062 (1.426 sec)
9.571... logprob:  0.454871, 0.125000 (1.428 sec)
9.572... logprob:  0.501590, 0.140625 (1.436 sec)
9.573... logprob:  0.512673, 0.148438 (1.450 sec)
9.574... logprob:  0.428259, 0.109375 (1.463 sec)
9.575... logprob:  0.343405, 0.078125 (1.454 sec)
9.576... logprob:  0.427469, 0.109375 (1.438 sec)
9.577... logprob:  0.460905, 0.125000 (1.478 sec)
9.578... logprob:  0.336458, 0.078125 (1.434 sec)
9.579... logprob:  0.442105, 0.117188 (1.430 sec)
9.580... logprob:  0.547192, 0.156250 (1.430 sec)
9.581... logprob:  0.531305, 0.156250 (1.438 sec)
9.582... logprob:  0.437991, 0.125000 (1.434 sec)
9.583... logprob:  0.593196, 0.171875 (1.478 sec)
9.584... logprob:  0.468178, 0.132812 (1.442 sec)
9.585... logprob:  0.349781, 0.085938 (1.431 sec)
9.586... logprob:  0.313236, 0.070312 (1.485 sec)
9.587... logprob:  0.404334, 0.101562 (1.430 sec)
9.588... logprob:  0.418696, 0.117188 (1.432 sec)
9.589... logprob:  0.361434, 0.093750 (1.432 sec)
9.590... logprob:  0.524644, 0.148438 (1.431 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.21147537231445, 10.0]}, 128)
batch 872: ({'logprob': [66.44557189941406, 19.0]}, 128)
batch 873: ({'logprob': [41.0389404296875, 9.0]}, 128)
batch 874: ({'logprob': [45.20103073120117, 11.0]}, 128)
batch 875: ({'logprob': [50.88289260864258, 13.0]}, 128)
batch 876: ({'logprob': [63.99332809448242, 18.0]}, 128)
batch 877: ({'logprob': [45.96303939819336, 11.0]}, 128)
batch 878: ({'logprob': [62.27177810668945, 17.0]}, 128)
batch 879: ({'logprob': [74.39584350585938, 21.0]}, 128)
batch 880: ({'logprob': [50.89358139038086, 13.0]}, 128)
batch 881: ({'logprob': [28.886049270629883, 5.0]}, 128)
batch 882: ({'logprob': [55.63215637207031, 14.0]}, 128)
batch 883: ({'logprob': [62.2623405456543, 17.0]}, 128)
batch 884: ({'logprob': [51.637306213378906, 13.0]}, 128)
batch 885: ({'logprob': [53.15765380859375, 13.0]}, 128)
batch 886: ({'logprob': [63.0245246887207, 17.0]}, 128)

======================Test output======================
logprob:  0.418407, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.973735e-03 [2.416009e-09] 
Layer 'conv1' biases: 6.907191e-08 [5.280475e-11] 
Layer 'conv2' weights[0]: 7.960756e-03 [1.928127e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.596336e-10] 
Layer 'conv3' weights[0]: 7.959047e-03 [1.594670e-09] 
Layer 'conv3' biases: 6.354962e-07 [7.578541e-10] 
Layer 'conv4' weights[0]: 7.991605e-03 [1.662110e-09] 
Layer 'conv4' biases: 9.999999e-01 [6.043546e-09] 
Layer 'conv5' weights[0]: 7.990509e-03 [4.063670e-08] 
Layer 'conv5' biases: 9.999995e-01 [4.408264e-08] 
Layer 'fc6' weights[0]: 7.587298e-03 [3.680934e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.645999e-09] 
Layer 'fc7' weights[0]: 7.561957e-03 [6.474968e-08] 
Layer 'fc7' biases: 9.998689e-01 [4.577127e-08] 
Layer 'fc8' weights[0]: 1.321843e-03 [2.511776e-06] 
Layer 'fc8' biases: 1.938767e-02 [1.595018e-05] 
Train error last 870 batches: 0.435301
-------------------------------------------------------
Not saving because 0.418407 > 0.415712 (4.190: -0.00%)
======================================================= (12.076 sec)
9.591... logprob:  0.397566, 0.101562 (1.442 sec)
9.592... logprob:  0.455627, 0.125000 (1.487 sec)
9.593... logprob:  0.467462, 0.125000 (1.435 sec)
9.594... logprob:  0.352910, 0.085938 (1.441 sec)
9.595... logprob:  0.428681, 0.109375 (1.482 sec)
9.596... logprob:  0.461563, 0.125000 (1.431 sec)
9.597... logprob:  0.397407, 0.101562 (1.430 sec)
9.598... logprob:  0.397240, 0.101562 (1.438 sec)
9.599... logprob:  0.313444, 0.070312 (1.422 sec)
9.600... logprob:  0.340911, 0.085938 (1.430 sec)
9.601... logprob:  0.402097, 0.101562 (1.484 sec)
9.602... logprob:  0.289534, 0.062500 (1.425 sec)
9.603... logprob:  0.266747, 0.054688 (1.446 sec)
9.604... logprob:  0.407498, 0.101562 (1.475 sec)
9.605... logprob:  0.563793, 0.148438 (1.431 sec)
9.606... logprob:  0.295970, 0.070312 (1.438 sec)
9.607... logprob:  0.505084, 0.132812 (1.433 sec)
9.608... logprob:  0.361547, 0.085938 (1.428 sec)
9.609... logprob:  0.356842, 0.085938 (1.433 sec)
9.610... logprob:  0.493531, 0.132812 (1.469 sec)
9.611... logprob:  0.510511, 0.140625 (1.438 sec)
9.612... logprob:  0.448293, 0.117188 (1.450 sec)
9.613... logprob:  0.280123, 0.062500 (1.458 sec)
9.614... logprob:  0.503500, 0.140625 (1.446 sec)
9.615... logprob:  0.351427, 0.085938 (1.438 sec)
9.616... logprob:  0.415570, 0.109375 (1.432 sec)
9.617... logprob:  0.418081, 0.109375 (1.426 sec)
9.618... logprob:  0.546485, 0.156250 (1.435 sec)
9.619... logprob:  0.505841, 0.140625 (1.452 sec)
9.620... logprob:  0.539589, 0.156250 (1.455 sec)
9.621... logprob:  0.364155, 0.085938 (1.454 sec)
9.622... logprob:  0.365125, 0.085938 (1.447 sec)
9.623... logprob:  0.423281, 0.109375 (1.466 sec)
9.624... logprob:  0.382578, 0.093750 (1.436 sec)
9.625... logprob:  0.441028, 0.117188 (1.419 sec)
9.626... logprob:  0.438435, 0.117188 (1.435 sec)
9.627... logprob:  0.435899, 0.117188 (1.436 sec)
9.628... logprob:  0.465157, 0.125000 (1.436 sec)
9.629... logprob:  0.371899, 0.093750 (1.472 sec)
9.630... logprob:  0.422374, 0.109375 (1.447 sec)
9.631... logprob:  0.639978, 0.187500 (1.435 sec)
9.632... logprob:  0.399094, 0.101562 (1.489 sec)
9.633... logprob:  0.375970, 0.093750 (1.432 sec)
9.634... logprob:  0.660711, 0.195312 (1.423 sec)
9.635... logprob:  0.374141, 0.093750 (1.439 sec)
9.636... logprob:  0.480206, 0.132812 (1.434 sec)
9.637... logprob:  0.331111, 0.078125 (1.436 sec)
9.638... logprob:  0.515652, 0.140625 (1.480 sec)
9.639... logprob:  0.418257, 0.109375 (1.444 sec)
9.640... logprob:  0.528765, 0.148438 (1.437 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.757789611816406, 10.0]}, 128)
batch 872: ({'logprob': [66.21469116210938, 19.0]}, 128)
batch 873: ({'logprob': [41.37572479248047, 9.0]}, 128)
batch 874: ({'logprob': [45.914371490478516, 11.0]}, 128)
batch 875: ({'logprob': [51.155540466308594, 13.0]}, 128)
batch 876: ({'logprob': [63.77882766723633, 18.0]}, 128)
batch 877: ({'logprob': [46.269405364990234, 11.0]}, 128)
batch 878: ({'logprob': [61.664363861083984, 17.0]}, 128)
batch 879: ({'logprob': [72.50127410888672, 21.0]}, 128)
batch 880: ({'logprob': [51.16756057739258, 13.0]}, 128)
batch 881: ({'logprob': [30.511625289916992, 5.0]}, 128)
batch 882: ({'logprob': [54.663124084472656, 14.0]}, 128)
batch 883: ({'logprob': [61.6544189453125, 17.0]}, 128)
batch 884: ({'logprob': [51.500667572021484, 13.0]}, 128)
batch 885: ({'logprob': [52.20314025878906, 13.0]}, 128)
batch 886: ({'logprob': [62.007781982421875, 17.0]}, 128)

======================Test output======================
logprob:  0.417647, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.973694e-03 [2.805369e-09] 
Layer 'conv1' biases: 6.976996e-08 [4.888281e-11] 
Layer 'conv2' weights[0]: 7.960714e-03 [1.921943e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.331704e-10] 
Layer 'conv3' weights[0]: 7.959009e-03 [1.502861e-09] 
Layer 'conv3' biases: 6.425411e-07 [7.644603e-10] 
Layer 'conv4' weights[0]: 7.991569e-03 [1.622516e-09] 
Layer 'conv4' biases: 9.999999e-01 [5.957801e-09] 
Layer 'conv5' weights[0]: 7.990479e-03 [4.130767e-08] 
Layer 'conv5' biases: 1.000000e+00 [4.481814e-08] 
Layer 'fc6' weights[0]: 7.587255e-03 [3.629717e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.602921e-09] 
Layer 'fc7' weights[0]: 7.560070e-03 [1.298143e-07] 
Layer 'fc7' biases: 9.998676e-01 [1.167621e-07] 
Layer 'fc8' weights[0]: 1.294275e-03 [4.292135e-06] 
Layer 'fc8' biases: 1.936735e-02 [2.530772e-05] 
Train error last 870 batches: 0.435301
-------------------------------------------------------
Not saving because 0.417647 > 0.415712 (4.190: -0.00%)
======================================================= (12.069 sec)
9.641... logprob:  0.410539, 0.109375 (1.495 sec)
9.642... logprob:  0.500765, 0.140625 (1.434 sec)
9.643... logprob:  0.622564, 0.187500 (1.430 sec)
9.644... logprob:  0.321729, 0.070312 (1.431 sec)
9.645... logprob:  0.414533, 0.109375 (1.433 sec)
9.646... logprob:  0.385872, 0.093750 (1.433 sec)
9.647... logprob:  0.456717, 0.125000 (1.490 sec)
9.648... logprob:  0.491206, 0.140625 (1.432 sec)
9.649... logprob:  0.369955, 0.093750 (1.440 sec)
9.650... logprob:  0.413871, 0.109375 (1.478 sec)
9.651... logprob:  0.397241, 0.101562 (1.435 sec)
9.652... logprob:  0.507632, 0.140625 (1.441 sec)
9.653... logprob:  0.548442, 0.156250 (1.431 sec)
9.654... logprob:  0.496248, 0.140625 (1.423 sec)
9.655... logprob:  0.436237, 0.117188 (1.432 sec)
9.656... logprob:  0.416653, 0.109375 (1.475 sec)
9.657... logprob:  0.449443, 0.117188 (1.437 sec)
9.658... logprob:  0.345695, 0.085938 (1.447 sec)
9.659... logprob:  0.464406, 0.125000 (1.464 sec)
9.660... logprob:  0.445814, 0.125000 (1.444 sec)
9.661... logprob:  0.378653, 0.093750 (1.440 sec)
9.662... logprob:  0.469258, 0.132812 (1.434 sec)
9.663... logprob:  0.311194, 0.070312 (1.423 sec)
9.664... logprob:  0.285627, 0.062500 (1.438 sec)
9.665... logprob:  0.401975, 0.101562 (1.463 sec)
9.666... logprob:  0.442102, 0.117188 (1.445 sec)
9.667... logprob:  0.564404, 0.164062 (1.457 sec)
9.668... logprob:  0.497991, 0.140625 (1.451 sec)
9.669... logprob:  0.433225, 0.109375 (1.454 sec)
9.670... logprob:  0.362576, 0.085938 (1.439 sec)
9.671... logprob:  0.360846, 0.093750 (1.422 sec)
9.672... logprob:  0.441804, 0.117188 (1.428 sec)
9.673... logprob:  0.436265, 0.117188 (1.437 sec)
9.674... logprob:  0.446697, 0.117188 (1.446 sec)
9.675... logprob:  0.356657, 0.093750 (1.466 sec)
9.676... logprob:  0.450131, 0.125000 (1.455 sec)
9.677... logprob:  0.471091, 0.125000 (1.438 sec)
9.678... logprob:  0.465631, 0.125000 (1.478 sec)
9.679... logprob:  0.454889, 0.125000 (1.428 sec)
9.680... logprob:  0.351784, 0.078125 (1.425 sec)
9.681... logprob:  0.374008, 0.093750 (1.433 sec)
9.682... logprob:  0.340536, 0.078125 (1.431 sec)
9.683... logprob:  0.411666, 0.109375 (1.437 sec)
9.684... logprob:  0.357531, 0.085938 (1.475 sec)
9.685... logprob:  0.285622, 0.054688 (1.438 sec)
9.686... logprob:  0.318318, 0.070312 (1.433 sec)
9.687... logprob:  0.281336, 0.062500 (1.484 sec)
9.688... logprob:  0.323050, 0.078125 (1.436 sec)
9.689... logprob:  0.471944, 0.125000 (1.427 sec)
9.690... logprob:  0.528596, 0.140625 (1.432 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.91202926635742, 10.0]}, 128)
batch 872: ({'logprob': [69.72288513183594, 19.0]}, 128)
batch 873: ({'logprob': [39.30215072631836, 9.0]}, 128)
batch 874: ({'logprob': [44.82987976074219, 11.0]}, 128)
batch 875: ({'logprob': [51.269805908203125, 13.0]}, 128)
batch 876: ({'logprob': [66.74156951904297, 18.0]}, 128)
batch 877: ({'logprob': [45.2873420715332, 11.0]}, 128)
batch 878: ({'logprob': [64.18315887451172, 17.0]}, 128)
batch 879: ({'logprob': [77.5286636352539, 21.0]}, 128)
batch 880: ({'logprob': [51.28268814086914, 13.0]}, 128)
batch 881: ({'logprob': [25.92618751525879, 5.0]}, 128)
batch 882: ({'logprob': [55.64922332763672, 14.0]}, 128)
batch 883: ({'logprob': [64.17324829101562, 17.0]}, 128)
batch 884: ({'logprob': [51.726348876953125, 13.0]}, 128)
batch 885: ({'logprob': [52.644187927246094, 13.0]}, 128)
batch 886: ({'logprob': [64.63629150390625, 17.0]}, 128)

======================Test output======================
logprob:  0.422762, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.973655e-03 [4.156243e-09] 
Layer 'conv1' biases: 7.018508e-08 [1.444091e-10] 
Layer 'conv2' weights[0]: 7.960673e-03 [3.685021e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.319989e-10] 
Layer 'conv3' weights[0]: 7.958973e-03 [3.983530e-09] 
Layer 'conv3' biases: 6.445838e-07 [2.610543e-09] 
Layer 'conv4' weights[0]: 7.991527e-03 [4.406335e-09] 
Layer 'conv4' biases: 9.999999e-01 [2.604212e-08] 
Layer 'conv5' weights[0]: 7.990426e-03 [1.785865e-07] 
Layer 'conv5' biases: 9.999991e-01 [1.940480e-07] 
Layer 'fc6' weights[0]: 7.587209e-03 [1.581841e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.606709e-08] 
Layer 'fc7' weights[0]: 7.558025e-03 [5.058775e-08] 
Layer 'fc7' biases: 9.998702e-01 [2.772037e-08] 
Layer 'fc8' weights[0]: 1.402147e-03 [7.410898e-06] 
Layer 'fc8' biases: 2.013320e-02 [4.799027e-05] 
Train error last 870 batches: 0.435301
-------------------------------------------------------
Not saving because 0.422762 > 0.415712 (4.190: -0.00%)
======================================================= (12.060 sec)
9.691... logprob:  0.517694, 0.140625 (1.440 sec)
9.692... logprob:  0.385732, 0.101562 (1.437 sec)
9.693... logprob:  0.456425, 0.125000 (1.479 sec)
9.694... logprob:  0.330850, 0.078125 (1.433 sec)
9.695... logprob:  0.356848, 0.085938 (1.441 sec)
9.696... logprob:  0.538440, 0.148438 (1.484 sec)
9.697... logprob:  0.465456, 0.125000 (1.431 sec)
9.698... logprob:  0.548168, 0.156250 (1.439 sec)
9.699... logprob:  0.459562, 0.125000 (1.437 sec)
9.700... logprob:  0.434213, 0.117188 (1.427 sec)
9.701... logprob:  0.423667, 0.109375 (1.439 sec)
9.702... logprob:  0.521374, 0.148438 (1.482 sec)
9.703... logprob:  0.405935, 0.101562 (1.441 sec)
9.704... logprob:  0.406611, 0.101562 (1.446 sec)
9.705... logprob:  0.420441, 0.109375 (1.465 sec)
9.706... logprob:  0.468090, 0.125000 (1.435 sec)
9.707... logprob:  0.485301, 0.132812 (1.437 sec)
9.708... logprob:  0.416913, 0.109375 (1.434 sec)
9.709... logprob:  0.422278, 0.109375 (1.425 sec)
9.710... logprob:  0.603340, 0.179688 (1.441 sec)
9.711... logprob:  0.469595, 0.125000 (1.467 sec)
9.712... logprob:  0.339910, 0.078125 (1.449 sec)
9.713... logprob:  0.588022, 0.179688 (1.451 sec)
9.714... logprob:  0.466415, 0.125000 (1.454 sec)
9.715... logprob:  0.417107, 0.109375 (1.452 sec)
9.716... logprob:  0.335098, 0.078125 (1.437 sec)
9.717... logprob:  0.429891, 0.117188 (1.428 sec)
9.718... logprob:  0.490429, 0.132812 (1.431 sec)
9.719... logprob:  0.406219, 0.109375 (1.440 sec)
9.720... logprob:  0.433248, 0.117188 (1.442 sec)
9.721... logprob:  0.451597, 0.117188 (1.460 sec)
9.722... logprob:  0.536693, 0.156250 (1.449 sec)
9.723... logprob:  0.416660, 0.109375 (1.446 sec)
9.724... logprob:  0.412800, 0.109375 (1.471 sec)
9.725... logprob:  0.494521, 0.140625 (1.435 sec)
9.726... logprob:  0.338876, 0.085938 (1.424 sec)
9.727... logprob:  0.393520, 0.101562 (1.431 sec)
9.728... logprob:  0.421494, 0.109375 (1.439 sec)
9.729... logprob:  0.387974, 0.093750 (1.432 sec)
9.730... logprob:  0.565797, 0.164062 (1.471 sec)
9.731... logprob:  0.450267, 0.125000 (1.449 sec)
9.732... logprob:  0.311527, 0.070312 (1.434 sec)
9.733... logprob:  0.556891, 0.156250 (1.490 sec)
9.734... logprob:  0.340193, 0.078125 (1.429 sec)
9.735... logprob:  0.527795, 0.148438 (1.434 sec)
9.736... logprob:  0.643425, 0.187500 (1.441 sec)
9.737... logprob:  0.516298, 0.148438 (1.432 sec)
9.738... logprob:  0.459475, 0.125000 (1.436 sec)
9.739... logprob:  0.477840, 0.132812 (1.509 sec)
9.740... logprob:  0.339677, 0.078125 (1.440 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.95778274536133, 10.0]}, 128)
batch 872: ({'logprob': [65.75112915039062, 19.0]}, 128)
batch 873: ({'logprob': [42.39823532104492, 9.0]}, 128)
batch 874: ({'logprob': [46.378562927246094, 11.0]}, 128)
batch 875: ({'logprob': [51.497711181640625, 13.0]}, 128)
batch 876: ({'logprob': [63.48466110229492, 18.0]}, 128)
batch 877: ({'logprob': [46.951683044433594, 11.0]}, 128)
batch 878: ({'logprob': [61.75910568237305, 17.0]}, 128)
batch 879: ({'logprob': [72.56573486328125, 21.0]}, 128)
batch 880: ({'logprob': [51.508575439453125, 13.0]}, 128)
batch 881: ({'logprob': [31.564308166503906, 5.0]}, 128)
batch 882: ({'logprob': [55.48554229736328, 14.0]}, 128)
batch 883: ({'logprob': [61.74940872192383, 17.0]}, 128)
batch 884: ({'logprob': [52.0588264465332, 13.0]}, 128)
batch 885: ({'logprob': [53.195701599121094, 13.0]}, 128)
batch 886: ({'logprob': [62.31916046142578, 17.0]}, 128)

======================Test output======================
logprob:  0.420716, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.973625e-03 [2.526274e-09] 
Layer 'conv1' biases: 7.109499e-08 [6.510488e-11] 
Layer 'conv2' weights[0]: 7.960631e-03 [2.764369e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.716605e-10] 
Layer 'conv3' weights[0]: 7.958925e-03 [2.671590e-09] 
Layer 'conv3' biases: 6.534305e-07 [1.537407e-09] 
Layer 'conv4' weights[0]: 7.991482e-03 [3.065587e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.545082e-08] 
Layer 'conv5' weights[0]: 7.990392e-03 [1.059885e-07] 
Layer 'conv5' biases: 9.999999e-01 [1.152155e-07] 
Layer 'fc6' weights[0]: 7.587177e-03 [9.234189e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.287588e-09] 
Layer 'fc7' weights[0]: 7.556229e-03 [7.295614e-08] 
Layer 'fc7' biases: 9.998674e-01 [5.648735e-08] 
Layer 'fc8' weights[0]: 1.279370e-03 [2.980133e-06] 
Layer 'fc8' biases: 1.955055e-02 [1.756414e-05] 
Train error last 870 batches: 0.435300
-------------------------------------------------------
Not saving because 0.420716 > 0.415712 (4.190: -0.00%)
======================================================= (11.976 sec)
9.741... logprob:  0.393444, 0.101562 (1.440 sec)
9.742... logprob:  0.419791, 0.109375 (1.483 sec)
9.743... logprob:  0.364881, 0.085938 (1.432 sec)
9.744... logprob:  0.519334, 0.148438 (1.434 sec)
9.745... logprob:  0.478217, 0.132812 (1.438 sec)
9.746... logprob:  0.440577, 0.117188 (1.425 sec)
9.747... logprob:  0.425659, 0.109375 (1.434 sec)
9.748... logprob:  0.378005, 0.093750 (1.489 sec)
9.749... logprob:  0.420878, 0.109375 (1.433 sec)
9.750... logprob:  0.513013, 0.140625 (1.444 sec)
9.751... logprob:  0.263437, 0.054688 (1.481 sec)
9.752... logprob:  0.522504, 0.140625 (1.430 sec)
9.753... logprob:  0.441329, 0.117188 (1.438 sec)
9.754... logprob:  0.468776, 0.132812 (1.436 sec)
9.755... logprob:  0.507172, 0.140625 (1.425 sec)
9.756... logprob:  0.440824, 0.117188 (1.440 sec)
9.757... logprob:  0.552177, 0.156250 (1.468 sec)
9.758... logprob:  0.393819, 0.101562 (1.444 sec)
9.759... logprob:  0.459694, 0.125000 (1.455 sec)
9.760... logprob:  0.485319, 0.132812 (1.459 sec)
9.761... logprob:  0.418567, 0.109375 (1.455 sec)
9.762... logprob:  0.515940, 0.148438 (1.437 sec)
9.763... logprob:  0.558663, 0.164062 (1.432 sec)
9.764... logprob:  0.503308, 0.140625 (1.432 sec)
9.765... logprob:  0.312621, 0.062500 (1.442 sec)
9.766... logprob:  0.482353, 0.132812 (1.455 sec)
9.767... logprob:  0.371216, 0.085938 (1.453 sec)
9.768... logprob:  0.432754, 0.117188 (1.464 sec)
9.769... logprob:  0.490987, 0.140625 (1.472 sec)
9.770... logprob:  0.402718, 0.101562 (1.481 sec)
9.771... logprob:  0.549889, 0.156250 (1.457 sec)
9.772... logprob:  0.414004, 0.109375 (1.457 sec)
9.773... logprob:  0.558511, 0.164062 (1.444 sec)
9.774... logprob:  0.361360, 0.085938 (1.456 sec)
9.775... logprob:  0.407291, 0.101562 (1.467 sec)
9.776... logprob:  0.433322, 0.117188 (1.476 sec)
9.777... logprob:  0.379896, 0.093750 (1.472 sec)
9.778... logprob:  0.433681, 0.117188 (1.469 sec)
9.779... logprob:  0.505577, 0.140625 (1.482 sec)
9.780... logprob:  0.385757, 0.101562 (1.461 sec)
9.781... logprob:  0.369815, 0.085938 (1.443 sec)
9.782... logprob:  0.351596, 0.085938 (1.446 sec)
9.783... logprob:  0.555412, 0.156250 (1.460 sec)
9.784... logprob:  0.440967, 0.117188 (1.459 sec)
9.785... logprob:  0.543384, 0.156250 (1.496 sec)
9.786... logprob:  0.477284, 0.132812 (1.473 sec)
9.787... logprob:  0.545962, 0.156250 (1.458 sec)
9.788... logprob:  0.562629, 0.164062 (1.492 sec)
9.789... logprob:  0.282007, 0.054688 (1.453 sec)
9.790... logprob:  0.408608, 0.101562 (1.446 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.09718322753906, 10.0]}, 128)
batch 872: ({'logprob': [65.900146484375, 19.0]}, 128)
batch 873: ({'logprob': [42.123939514160156, 9.0]}, 128)
batch 874: ({'logprob': [46.33285903930664, 11.0]}, 128)
batch 875: ({'logprob': [51.44032669067383, 13.0]}, 128)
batch 876: ({'logprob': [63.579891204833984, 18.0]}, 128)
batch 877: ({'logprob': [46.78614807128906, 11.0]}, 128)
batch 878: ({'logprob': [61.67985153198242, 17.0]}, 128)
batch 879: ({'logprob': [72.34498596191406, 21.0]}, 128)
batch 880: ({'logprob': [51.45182418823242, 13.0]}, 128)
batch 881: ({'logprob': [31.431751251220703, 5.0]}, 128)
batch 882: ({'logprob': [55.12370681762695, 14.0]}, 128)
batch 883: ({'logprob': [61.66989517211914, 17.0]}, 128)
batch 884: ({'logprob': [51.882102966308594, 13.0]}, 128)
batch 885: ({'logprob': [52.77946090698242, 13.0]}, 128)
batch 886: ({'logprob': [62.12029266357422, 17.0]}, 128)

======================Test output======================
logprob:  0.419797, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.973583e-03 [2.665808e-09] 
Layer 'conv1' biases: 7.175530e-08 [8.171040e-11] 
Layer 'conv2' weights[0]: 7.960590e-03 [2.749090e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.076777e-10] 
Layer 'conv3' weights[0]: 7.958883e-03 [2.727885e-09] 
Layer 'conv3' biases: 6.594930e-07 [1.655523e-09] 
Layer 'conv4' weights[0]: 7.991446e-03 [2.997367e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.587308e-08] 
Layer 'conv5' weights[0]: 7.990362e-03 [1.072407e-07] 
Layer 'conv5' biases: 1.000000e+00 [1.163894e-07] 
Layer 'fc6' weights[0]: 7.587144e-03 [9.391378e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.431954e-09] 
Layer 'fc7' weights[0]: 7.554303e-03 [8.100498e-08] 
Layer 'fc7' biases: 9.998673e-01 [6.543475e-08] 
Layer 'fc8' weights[0]: 1.279631e-03 [2.515202e-06] 
Layer 'fc8' biases: 1.969572e-02 [1.219758e-05] 
Train error last 870 batches: 0.435300
-------------------------------------------------------
Not saving because 0.419797 > 0.415712 (4.190: -0.00%)
======================================================= (12.050 sec)
9.791... logprob:  0.398366, 0.101562 (1.463 sec)
9.792... logprob:  0.361492, 0.085938 (1.469 sec)
9.793... logprob:  0.370429, 0.085938 (1.454 sec)
9.794... logprob:  0.387115, 0.093750 (1.487 sec)
9.795... logprob:  0.469911, 0.125000 (1.472 sec)
9.796... logprob:  0.423502, 0.109375 (1.455 sec)
9.797... logprob:  0.358577, 0.085938 (1.502 sec)
9.798... logprob:  0.393255, 0.101562 (1.453 sec)
9.799... logprob:  0.331966, 0.078125 (1.447 sec)
9.800... logprob:  0.371874, 0.093750 (1.448 sec)
9.801... logprob:  0.450618, 0.117188 (1.459 sec)
9.802... logprob:  0.423356, 0.109375 (1.456 sec)
9.803... logprob:  0.492407, 0.132812 (1.491 sec)
9.804... logprob:  0.350021, 0.085938 (1.489 sec)
9.805... logprob:  0.452289, 0.117188 (1.449 sec)
9.806... logprob:  0.424187, 0.109375 (1.503 sec)
9.807... logprob:  0.443424, 0.117188 (1.457 sec)
9.808... logprob:  0.462318, 0.125000 (1.452 sec)
9.809... logprob:  0.589200, 0.171875 (1.450 sec)
9.810... logprob:  0.442417, 0.117188 (1.459 sec)
9.811... logprob:  0.460434, 0.125000 (1.450 sec)
9.812... logprob:  0.462514, 0.125000 (1.507 sec)
9.813... logprob:  0.486034, 0.132812 (1.461 sec)
9.814... logprob:  0.478329, 0.132812 (1.457 sec)
9.815... logprob:  0.372943, 0.085938 (1.503 sec)
9.816... logprob:  0.409333, 0.101562 (1.453 sec)
9.817... logprob:  0.426348, 0.109375 (1.455 sec)
9.818... logprob:  0.559959, 0.164062 (1.450 sec)
9.819... logprob:  0.498245, 0.140625 (1.457 sec)
9.820... logprob:  0.421451, 0.109375 (1.453 sec)
9.821... logprob:  0.406236, 0.101562 (1.500 sec)
9.822... logprob:  0.440975, 0.117188 (1.460 sec)
9.823... logprob:  0.340002, 0.078125 (1.199 sec)
9.824... logprob:  0.490279, 0.132812 (0.719 sec)
9.825... logprob:  0.286936, 0.062500 (0.692 sec)
9.826... logprob:  0.375217, 0.093750 (0.689 sec)
9.827... logprob:  0.420785, 0.109375 (0.693 sec)
9.828... logprob:  0.443942, 0.117188 (0.693 sec)
9.829... logprob:  0.505243, 0.140625 (0.691 sec)
9.830... logprob:  0.442556, 0.117188 (1.505 sec)
9.831... logprob:  0.514297, 0.140625 (1.452 sec)
9.832... logprob:  0.330896, 0.078125 (1.465 sec)
9.833... logprob:  0.488862, 0.132812 (1.611 sec)
9.834... logprob:  0.433053, 0.117188 (1.451 sec)
9.835... logprob:  0.542163, 0.148438 (1.454 sec)
9.836... logprob:  0.376551, 0.093750 (1.449 sec)
9.837... logprob:  0.315382, 0.070312 (1.454 sec)
9.838... logprob:  0.437129, 0.117188 (1.454 sec)
9.839... logprob:  0.471829, 0.125000 (1.502 sec)
9.840... logprob:  0.555075, 0.156250 (1.458 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.6875, 10.0]}, 128)
batch 872: ({'logprob': [66.1821060180664, 19.0]}, 128)
batch 873: ({'logprob': [41.380279541015625, 9.0]}, 128)
batch 874: ({'logprob': [45.88407516479492, 11.0]}, 128)
batch 875: ({'logprob': [51.13618850708008, 13.0]}, 128)
batch 876: ({'logprob': [63.75245666503906, 18.0]}, 128)
batch 877: ({'logprob': [46.26201629638672, 11.0]}, 128)
batch 878: ({'logprob': [61.66694259643555, 17.0]}, 128)
batch 879: ({'logprob': [72.54856872558594, 21.0]}, 128)
batch 880: ({'logprob': [51.14814376831055, 13.0]}, 128)
batch 881: ({'logprob': [30.471391677856445, 5.0]}, 128)
batch 882: ({'logprob': [54.70674133300781, 14.0]}, 128)
batch 883: ({'logprob': [61.65693283081055, 17.0]}, 128)
batch 884: ({'logprob': [51.504356384277344, 13.0]}, 128)
batch 885: ({'logprob': [52.25281524658203, 13.0]}, 128)
batch 886: ({'logprob': [62.033321380615234, 17.0]}, 128)

======================Test output======================
logprob:  0.417614, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.973545e-03 [3.478213e-09] 
Layer 'conv1' biases: 7.241315e-08 [6.530508e-11] 
Layer 'conv2' weights[0]: 7.960556e-03 [2.444319e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.871852e-10] 
Layer 'conv3' weights[0]: 7.958844e-03 [2.125262e-09] 
Layer 'conv3' biases: 6.652378e-07 [1.210006e-09] 
Layer 'conv4' weights[0]: 7.991408e-03 [2.323553e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.108855e-08] 
Layer 'conv5' weights[0]: 7.990309e-03 [7.595853e-08] 
Layer 'conv5' biases: 1.000000e+00 [8.243224e-08] 
Layer 'fc6' weights[0]: 7.587100e-03 [6.530972e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.615789e-09] 
Layer 'fc7' weights[0]: 7.552342e-03 [2.022502e-07] 
Layer 'fc7' biases: 9.998677e-01 [1.908541e-07] 
Layer 'fc8' weights[0]: 1.291424e-03 [7.371755e-06] 
Layer 'fc8' biases: 2.006478e-02 [4.591859e-05] 
Train error last 870 batches: 0.435299
-------------------------------------------------------
Not saving because 0.417614 > 0.415712 (4.190: -0.00%)
======================================================= (12.068 sec)
9.841... logprob:  0.396484, 0.101562 (1.475 sec)
9.842... logprob:  0.497759, 0.140625 (1.505 sec)
9.843... logprob:  0.465585, 0.125000 (1.457 sec)
9.844... logprob:  0.497584, 0.140625 (1.457 sec)
9.845... logprob:  0.486904, 0.132812 (1.454 sec)
9.846... logprob:  0.468553, 0.125000 (1.449 sec)
9.847... logprob:  0.362938, 0.085938 (1.452 sec)
9.848... logprob:  0.396831, 0.101562 (1.502 sec)
9.849... logprob:  0.359974, 0.085938 (1.460 sec)
9.850... logprob:  0.479505, 0.132812 (1.470 sec)
9.851... logprob:  0.440186, 0.117188 (1.487 sec)
9.852... logprob:  0.546312, 0.156250 (1.459 sec)
9.853... logprob:  0.371638, 0.093750 (1.460 sec)
9.854... logprob:  0.306753, 0.070312 (1.447 sec)
9.855... logprob:  0.485188, 0.132812 (1.445 sec)
9.856... logprob:  0.443988, 0.117188 (1.452 sec)
9.857... logprob:  0.372277, 0.093750 (1.494 sec)
9.858... logprob:  0.396250, 0.101562 (1.460 sec)
9.859... logprob:  0.307950, 0.070312 (1.468 sec)
9.860... logprob:  0.565876, 0.156250 (1.489 sec)
9.861... logprob:  0.417838, 0.109375 (1.453 sec)
9.862... logprob:  0.329030, 0.078125 (1.460 sec)
9.863... logprob:  0.399473, 0.101562 (1.447 sec)
9.864... logprob:  0.451314, 0.117188 (1.448 sec)
9.865... logprob:  0.484247, 0.132812 (1.458 sec)
9.866... logprob:  0.507296, 0.140625 (1.491 sec)
9.867... logprob:  0.502597, 0.140625 (1.462 sec)
9.868... logprob:  0.405540, 0.101562 (1.478 sec)
9.869... logprob:  0.383551, 0.093750 (1.481 sec)
9.870... logprob:  0.551772, 0.156250 (1.404 sec)
10.1... logprob:  0.380378, 0.093750 (1.403 sec)
10.2... logprob:  0.448304, 0.117188 (1.448 sec)
10.3... logprob:  0.398522, 0.101562 (1.418 sec)
10.4... logprob:  0.443393, 0.117188 (1.404 sec)
10.5... logprob:  0.443360, 0.117188 (1.437 sec)
10.6... logprob:  0.499331, 0.140625 (1.396 sec)
10.7... logprob:  0.362852, 0.085938 (1.429 sec)
10.8... logprob:  0.419075, 0.109375 (1.395 sec)
10.9... logprob:  0.358483, 0.085938 (1.406 sec)
10.10... logprob:  0.377242, 0.093750 (1.408 sec)
10.11... logprob:  0.334314, 0.078125 (1.470 sec)
10.12... logprob:  0.466712, 0.125000 (1.392 sec)
10.13... logprob:  0.442546, 0.117188 (1.425 sec)
10.14... logprob:  0.444954, 0.117188 (1.402 sec)
10.15... logprob:  0.395750, 0.101562 (1.406 sec)
10.16... logprob:  0.421532, 0.109375 (1.410 sec)
10.17... logprob:  0.516168, 0.140625 (1.394 sec)
10.18... logprob:  0.262141, 0.054688 (1.405 sec)
10.19... logprob:  0.279753, 0.062500 (1.399 sec)
10.20... logprob:  0.421387, 0.109375 (1.406 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.626304626464844, 10.0]}, 128)
batch 872: ({'logprob': [68.3158950805664, 19.0]}, 128)
batch 873: ({'logprob': [39.38897705078125, 9.0]}, 128)
batch 874: ({'logprob': [44.91872787475586, 11.0]}, 128)
batch 875: ({'logprob': [50.85966110229492, 13.0]}, 128)
batch 876: ({'logprob': [65.45905303955078, 18.0]}, 128)
batch 877: ({'logprob': [45.12704086303711, 11.0]}, 128)
batch 878: ({'logprob': [62.77490997314453, 17.0]}, 128)
batch 879: ({'logprob': [74.87275695800781, 21.0]}, 128)
batch 880: ({'logprob': [50.87322235107422, 13.0]}, 128)
batch 881: ({'logprob': [27.26218605041504, 5.0]}, 128)
batch 882: ({'logprob': [54.36247253417969, 14.0]}, 128)
batch 883: ({'logprob': [62.76449203491211, 17.0]}, 128)
batch 884: ({'logprob': [51.06465148925781, 13.0]}, 128)
batch 885: ({'logprob': [51.48085403442383, 13.0]}, 128)
batch 886: ({'logprob': [62.97665786743164, 17.0]}, 128)

======================Test output======================
logprob:  0.417055, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.973508e-03 [2.469878e-09] 
Layer 'conv1' biases: 7.302935e-08 [3.541455e-11] 
Layer 'conv2' weights[0]: 7.960521e-03 [1.546864e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.253522e-10] 
Layer 'conv3' weights[0]: 7.958799e-03 [1.185735e-09] 
Layer 'conv3' biases: 6.697427e-07 [3.481769e-10] 
Layer 'conv4' weights[0]: 7.991369e-03 [1.192620e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.411922e-09] 
Layer 'conv5' weights[0]: 7.990269e-03 [8.871549e-09] 
Layer 'conv5' biases: 9.999995e-01 [9.378539e-09] 
Layer 'fc6' weights[0]: 7.587064e-03 [1.120468e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.791487e-10] 
Layer 'fc7' weights[0]: 7.550388e-03 [5.871205e-08] 
Layer 'fc7' biases: 9.998692e-01 [3.835697e-08] 
Layer 'fc8' weights[0]: 1.355027e-03 [1.917030e-06] 
Layer 'fc8' biases: 2.062742e-02 [1.239378e-05] 
Train error last 870 batches: 0.435299
-------------------------------------------------------
Not saving because 0.417055 > 0.415712 (4.190: -0.00%)
======================================================= (12.123 sec)
10.21... logprob:  0.443923, 0.117188 (0.898 sec)
10.22... logprob:  0.536431, 0.148438 (1.324 sec)
10.23... logprob:  0.532548, 0.148438 (1.432 sec)
10.24... logprob:  0.310987, 0.070312 (0.980 sec)
10.25... logprob:  0.356470, 0.085938 (0.966 sec)
10.26... logprob:  0.463591, 0.125000 (1.449 sec)
10.27... logprob:  0.404699, 0.101562 (1.390 sec)
10.28... logprob:  0.421899, 0.109375 (1.409 sec)
10.29... logprob:  0.396151, 0.101562 (1.421 sec)
10.30... logprob:  0.374257, 0.093750 (1.420 sec)
10.31... logprob:  0.479869, 0.132812 (1.402 sec)
10.32... logprob:  0.457250, 0.125000 (1.393 sec)
10.33... logprob:  0.460686, 0.125000 (1.453 sec)
10.34... logprob:  0.464713, 0.125000 (1.395 sec)
10.35... logprob:  0.316104, 0.070312 (1.403 sec)
10.36... logprob:  0.475819, 0.132812 (1.399 sec)
10.37... logprob:  0.417614, 0.109375 (1.407 sec)
10.38... logprob:  0.392418, 0.101562 (1.395 sec)
10.39... logprob:  0.632174, 0.187500 (1.436 sec)
10.40... logprob:  0.445938, 0.117188 (1.413 sec)
10.41... logprob:  0.352674, 0.085938 (1.430 sec)
10.42... logprob:  0.391766, 0.101562 (1.417 sec)
10.43... logprob:  0.440158, 0.117188 (1.407 sec)
10.44... logprob:  0.518463, 0.148438 (1.436 sec)
10.45... logprob:  0.381831, 0.093750 (1.405 sec)
10.46... logprob:  0.486471, 0.132812 (1.405 sec)
10.47... logprob:  0.331809, 0.078125 (1.397 sec)
10.48... logprob:  0.498848, 0.140625 (1.425 sec)
10.49... logprob:  0.510520, 0.148438 (1.418 sec)
10.50... logprob:  0.393292, 0.101562 (1.423 sec)
10.51... logprob:  0.489888, 0.140625 (1.422 sec)
10.52... logprob:  0.525782, 0.148438 (1.410 sec)
10.53... logprob:  0.295158, 0.062500 (1.453 sec)
10.54... logprob:  0.403178, 0.109375 (1.388 sec)
10.55... logprob:  0.331839, 0.078125 (1.397 sec)
10.56... logprob:  0.421760, 0.109375 (1.410 sec)
10.57... logprob:  0.572652, 0.164062 (1.428 sec)
10.58... logprob:  0.407876, 0.101562 (1.403 sec)
10.59... logprob:  0.333837, 0.078125 (1.466 sec)
10.60... logprob:  0.619208, 0.179688 (1.429 sec)
10.61... logprob:  0.382892, 0.093750 (1.430 sec)
10.62... logprob:  0.474950, 0.132812 (1.462 sec)
10.63... logprob:  0.397321, 0.101562 (1.437 sec)
10.64... logprob:  0.450245, 0.125000 (1.417 sec)
10.65... logprob:  0.373289, 0.093750 (1.401 sec)
10.66... logprob:  0.353982, 0.085938 (1.448 sec)
10.67... logprob:  0.295369, 0.062500 (1.398 sec)
10.68... logprob:  0.396837, 0.101562 (1.403 sec)
10.69... logprob:  0.496913, 0.140625 (1.423 sec)
10.70... logprob:  0.325876, 0.078125 (1.428 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.00419998168945, 10.0]}, 128)
batch 872: ({'logprob': [67.10108184814453, 19.0]}, 128)
batch 873: ({'logprob': [40.265899658203125, 9.0]}, 128)
batch 874: ({'logprob': [44.877655029296875, 11.0]}, 128)
batch 875: ({'logprob': [50.73488235473633, 13.0]}, 128)
batch 876: ({'logprob': [64.49361419677734, 18.0]}, 128)
batch 877: ({'logprob': [45.5025749206543, 11.0]}, 128)
batch 878: ({'logprob': [62.47783660888672, 17.0]}, 128)
batch 879: ({'logprob': [74.81890106201172, 21.0]}, 128)
batch 880: ({'logprob': [50.74661636352539, 13.0]}, 128)
batch 881: ({'logprob': [27.895301818847656, 5.0]}, 128)
batch 882: ({'logprob': [55.2329216003418, 14.0]}, 128)
batch 883: ({'logprob': [62.467918395996094, 17.0]}, 128)
batch 884: ({'logprob': [51.35422897338867, 13.0]}, 128)
batch 885: ({'logprob': [52.60200500488281, 13.0]}, 128)
batch 886: ({'logprob': [63.09480667114258, 17.0]}, 128)

======================Test output======================
logprob:  0.417320, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.973470e-03 [2.024499e-09] 
Layer 'conv1' biases: 7.369979e-08 [4.706924e-11] 
Layer 'conv2' weights[0]: 7.960478e-03 [1.470629e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.050867e-10] 
Layer 'conv3' weights[0]: 7.958760e-03 [1.392198e-09] 
Layer 'conv3' biases: 6.747392e-07 [6.419352e-10] 
Layer 'conv4' weights[0]: 7.991333e-03 [1.500966e-09] 
Layer 'conv4' biases: 9.999999e-01 [6.037112e-09] 
Layer 'conv5' weights[0]: 7.990237e-03 [4.160693e-08] 
Layer 'conv5' biases: 9.999993e-01 [4.521058e-08] 
Layer 'fc6' weights[0]: 7.587017e-03 [3.710221e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.674485e-09] 
Layer 'fc7' weights[0]: 7.548453e-03 [1.609449e-07] 
Layer 'fc7' biases: 9.998689e-01 [1.481739e-07] 
Layer 'fc8' weights[0]: 1.342788e-03 [6.108943e-06] 
Layer 'fc8' biases: 2.058662e-02 [3.827162e-05] 
Train error last 870 batches: 0.435299
-------------------------------------------------------
Not saving because 0.417320 > 0.415712 (4.190: -0.00%)
======================================================= (12.053 sec)
10.71... logprob:  0.381868, 0.101562 (1.475 sec)
10.72... logprob:  0.493910, 0.132812 (1.413 sec)
10.73... logprob:  0.447819, 0.117188 (1.427 sec)
10.74... logprob:  0.442631, 0.117188 (1.421 sec)
10.75... logprob:  0.380640, 0.093750 (1.415 sec)
10.76... logprob:  0.412111, 0.109375 (1.437 sec)
10.77... logprob:  0.396348, 0.101562 (1.433 sec)
10.78... logprob:  0.493081, 0.140625 (1.453 sec)
10.79... logprob:  0.456432, 0.125000 (1.423 sec)
10.80... logprob:  0.507808, 0.132812 (1.421 sec)
10.81... logprob:  0.416723, 0.109375 (1.417 sec)
10.82... logprob:  0.232062, 0.039062 (1.423 sec)
10.83... logprob:  0.493683, 0.140625 (1.405 sec)
10.84... logprob:  0.468058, 0.125000 (1.466 sec)
10.85... logprob:  0.432089, 0.117188 (1.417 sec)
10.86... logprob:  0.417030, 0.109375 (1.419 sec)
10.87... logprob:  0.633158, 0.187500 (1.420 sec)
10.88... logprob:  0.535158, 0.156250 (1.409 sec)
10.89... logprob:  0.410666, 0.109375 (1.436 sec)
10.90... logprob:  0.577541, 0.171875 (1.391 sec)
10.91... logprob:  0.348602, 0.078125 (1.396 sec)
10.92... logprob:  0.464458, 0.125000 (1.406 sec)
10.93... logprob:  0.492324, 0.140625 (1.397 sec)
10.94... logprob:  0.428785, 0.109375 (1.389 sec)
10.95... logprob:  0.471877, 0.125000 (1.403 sec)
10.96... logprob:  0.576442, 0.171875 (1.412 sec)
10.97... logprob:  0.430745, 0.117188 (1.393 sec)
10.98... logprob:  0.390949, 0.093750 (1.446 sec)
10.99... logprob:  0.474375, 0.132812 (1.404 sec)
10.100... logprob:  0.310249, 0.070312 (1.408 sec)
10.101... logprob:  0.310363, 0.062500 (1.446 sec)
10.102... logprob:  0.546589, 0.156250 (1.394 sec)
10.103... logprob:  0.541552, 0.156250 (1.401 sec)
10.104... logprob:  0.388912, 0.101562 (1.401 sec)
10.105... logprob:  0.620061, 0.179688 (1.395 sec)
10.106... logprob:  0.344421, 0.085938 (1.401 sec)
10.107... logprob:  0.335662, 0.078125 (1.437 sec)
10.108... logprob:  0.586770, 0.171875 (1.401 sec)
10.109... logprob:  0.336258, 0.078125 (1.401 sec)
10.110... logprob:  0.564307, 0.164062 (1.397 sec)
10.111... logprob:  0.404777, 0.101562 (1.402 sec)
10.112... logprob:  0.366296, 0.093750 (1.407 sec)
10.113... logprob:  0.354805, 0.085938 (1.401 sec)
10.114... logprob:  0.440250, 0.117188 (1.434 sec)
10.115... logprob:  0.506715, 0.140625 (1.408 sec)
10.116... logprob:  0.393439, 0.101562 (1.406 sec)
10.117... logprob:  0.440400, 0.117188 (1.441 sec)
10.118... logprob:  0.409222, 0.101562 (1.392 sec)
10.119... logprob:  0.346155, 0.085938 (1.402 sec)
10.120... logprob:  0.547179, 0.156250 (1.397 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.687076568603516, 10.0]}, 128)
batch 872: ({'logprob': [66.4925537109375, 19.0]}, 128)
batch 873: ({'logprob': [40.681053161621094, 9.0]}, 128)
batch 874: ({'logprob': [45.231285095214844, 11.0]}, 128)
batch 875: ({'logprob': [50.78860092163086, 13.0]}, 128)
batch 876: ({'logprob': [63.97538757324219, 18.0]}, 128)
batch 877: ({'logprob': [45.737857818603516, 11.0]}, 128)
batch 878: ({'logprob': [61.93107604980469, 17.0]}, 128)
batch 879: ({'logprob': [73.55302429199219, 21.0]}, 128)
batch 880: ({'logprob': [50.8005256652832, 13.0]}, 128)
batch 881: ({'logprob': [29.030624389648438, 5.0]}, 128)
batch 882: ({'logprob': [54.83735275268555, 14.0]}, 128)
batch 883: ({'logprob': [61.92097473144531, 17.0]}, 128)
batch 884: ({'logprob': [51.28769302368164, 13.0]}, 128)
batch 885: ({'logprob': [52.29615783691406, 13.0]}, 128)
batch 886: ({'logprob': [62.427982330322266, 17.0]}, 128)

======================Test output======================
logprob:  0.416347, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.973435e-03 [2.390198e-09] 
Layer 'conv1' biases: 7.442904e-08 [4.317765e-11] 
Layer 'conv2' weights[0]: 7.960438e-03 [1.766286e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.610015e-10] 
Layer 'conv3' weights[0]: 7.958719e-03 [1.592347e-09] 
Layer 'conv3' biases: 6.804592e-07 [8.703773e-10] 
Layer 'conv4' weights[0]: 7.991292e-03 [1.693132e-09] 
Layer 'conv4' biases: 9.999999e-01 [7.678991e-09] 
Layer 'conv5' weights[0]: 7.990199e-03 [5.273411e-08] 
Layer 'conv5' biases: 9.999995e-01 [5.722883e-08] 
Layer 'fc6' weights[0]: 7.586976e-03 [4.696568e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.659841e-09] 
Layer 'fc7' weights[0]: 7.546559e-03 [3.938915e-08] 
Layer 'fc7' biases: 9.998683e-01 [1.024751e-08] 
Layer 'fc8' weights[0]: 1.316953e-03 [7.314182e-07] 
Layer 'fc8' biases: 2.052618e-02 [4.142541e-06] 
Train error last 870 batches: 0.435299
-------------------------------------------------------
Not saving because 0.416347 > 0.415712 (4.190: -0.00%)
======================================================= (12.101 sec)
10.121... logprob:  0.412731, 0.109375 (1.404 sec)
10.122... logprob:  0.519432, 0.148438 (1.455 sec)
10.123... logprob:  0.463798, 0.125000 (1.393 sec)
10.124... logprob:  0.447732, 0.125000 (1.404 sec)
10.125... logprob:  0.502061, 0.140625 (1.402 sec)
10.126... logprob:  0.475852, 0.125000 (1.395 sec)
10.127... logprob:  0.479700, 0.125000 (1.399 sec)
10.128... logprob:  0.422413, 0.109375 (1.420 sec)
10.129... logprob:  0.574903, 0.164062 (1.417 sec)
10.130... logprob:  0.382788, 0.093750 (1.420 sec)
10.131... logprob:  0.495510, 0.132812 (1.407 sec)
10.132... logprob:  0.506405, 0.140625 (1.440 sec)
10.133... logprob:  0.444689, 0.117188 (1.388 sec)
10.134... logprob:  0.401945, 0.101562 (1.397 sec)
10.135... logprob:  0.460274, 0.125000 (1.407 sec)
10.136... logprob:  0.562685, 0.164062 (1.394 sec)
10.137... logprob:  0.462558, 0.125000 (1.411 sec)
10.138... logprob:  0.319312, 0.070312 (1.447 sec)
10.139... logprob:  0.395814, 0.101562 (1.396 sec)
10.140... logprob:  0.560729, 0.164062 (1.413 sec)
10.141... logprob:  0.464519, 0.125000 (1.439 sec)
10.142... logprob:  0.464595, 0.125000 (1.398 sec)
10.143... logprob:  0.294192, 0.062500 (1.426 sec)
10.144... logprob:  0.457443, 0.125000 (1.419 sec)
10.145... logprob:  0.324959, 0.078125 (1.417 sec)
10.146... logprob:  0.483313, 0.132812 (1.412 sec)
10.147... logprob:  0.262477, 0.054688 (1.430 sec)
10.148... logprob:  0.458939, 0.125000 (1.395 sec)
10.149... logprob:  0.442598, 0.117188 (1.396 sec)
10.150... logprob:  0.347661, 0.085938 (1.400 sec)
10.151... logprob:  0.347163, 0.085938 (1.413 sec)
10.152... logprob:  0.784930, 0.234375 (1.389 sec)
10.153... logprob:  0.381684, 0.093750 (1.448 sec)
10.154... logprob:  0.524239, 0.148438 (1.406 sec)
10.155... logprob:  0.425921, 0.117188 (1.437 sec)
10.156... logprob:  0.296222, 0.062500 (1.435 sec)
10.157... logprob:  0.271128, 0.054688 (1.399 sec)
10.158... logprob:  0.455340, 0.125000 (1.406 sec)
10.159... logprob:  0.483125, 0.132812 (1.404 sec)
10.160... logprob:  0.444987, 0.117188 (1.398 sec)
10.161... logprob:  0.350364, 0.078125 (1.400 sec)
10.162... logprob:  0.611832, 0.179688 (1.409 sec)
10.163... logprob:  0.450406, 0.125000 (1.424 sec)
10.164... logprob:  0.468777, 0.125000 (1.421 sec)
10.165... logprob:  0.548068, 0.156250 (1.417 sec)
10.166... logprob:  0.446027, 0.125000 (1.458 sec)
10.167... logprob:  0.350306, 0.085938 (1.425 sec)
10.168... logprob:  0.363633, 0.085938 (1.437 sec)
10.169... logprob:  0.408716, 0.101562 (1.461 sec)
10.170... logprob:  0.459513, 0.125000 (1.403 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.93693161010742, 10.0]}, 128)
batch 872: ({'logprob': [66.12496948242188, 19.0]}, 128)
batch 873: ({'logprob': [41.238685607910156, 9.0]}, 128)
batch 874: ({'logprob': [45.52037048339844, 11.0]}, 128)
batch 875: ({'logprob': [50.948768615722656, 13.0]}, 128)
batch 876: ({'logprob': [63.7068977355957, 18.0]}, 128)
batch 877: ({'logprob': [46.09700012207031, 11.0]}, 128)
batch 878: ({'logprob': [61.83199691772461, 17.0]}, 128)
batch 879: ({'logprob': [73.2639389038086, 21.0]}, 128)
batch 880: ({'logprob': [50.96043014526367, 13.0]}, 128)
batch 881: ({'logprob': [29.778268814086914, 5.0]}, 128)
batch 882: ({'logprob': [55.10547637939453, 14.0]}, 128)
batch 883: ({'logprob': [61.82180404663086, 17.0]}, 128)
batch 884: ({'logprob': [51.51638412475586, 13.0]}, 128)
batch 885: ({'logprob': [52.66339874267578, 13.0]}, 128)
batch 886: ({'logprob': [62.39778518676758, 17.0]}, 128)

======================Test output======================
logprob:  0.417438, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.973390e-03 [2.073384e-09] 
Layer 'conv1' biases: 7.514916e-08 [4.642261e-11] 
Layer 'conv2' weights[0]: 7.960403e-03 [1.746011e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.584930e-10] 
Layer 'conv3' weights[0]: 7.958673e-03 [1.781843e-09] 
Layer 'conv3' biases: 6.868493e-07 [8.343186e-10] 
Layer 'conv4' weights[0]: 7.991253e-03 [1.958023e-09] 
Layer 'conv4' biases: 9.999999e-01 [8.004044e-09] 
Layer 'conv5' weights[0]: 7.990156e-03 [5.320506e-08] 
Layer 'conv5' biases: 9.999995e-01 [5.775379e-08] 
Layer 'fc6' weights[0]: 7.586941e-03 [4.749944e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.705855e-09] 
Layer 'fc7' weights[0]: 7.544654e-03 [1.546891e-07] 
Layer 'fc7' biases: 9.998680e-01 [1.417336e-07] 
Layer 'fc8' weights[0]: 1.309063e-03 [6.044793e-06] 
Layer 'fc8' biases: 2.057153e-02 [4.051505e-05] 
Train error last 870 batches: 0.435298
-------------------------------------------------------
Not saving because 0.417438 > 0.415712 (4.190: -0.00%)
======================================================= (12.042 sec)
10.171... logprob:  0.535590, 0.156250 (1.432 sec)
10.172... logprob:  0.434908, 0.109375 (1.426 sec)
10.173... logprob:  0.440516, 0.117188 (1.421 sec)
10.174... logprob:  0.601361, 0.171875 (1.412 sec)
10.175... logprob:  0.506205, 0.140625 (1.464 sec)
10.176... logprob:  0.478543, 0.132812 (1.421 sec)
10.177... logprob:  0.289810, 0.054688 (1.426 sec)
10.178... logprob:  0.383504, 0.093750 (1.460 sec)
10.179... logprob:  0.394770, 0.101562 (1.415 sec)
10.180... logprob:  0.466377, 0.125000 (1.428 sec)
10.181... logprob:  0.539469, 0.156250 (1.416 sec)
10.182... logprob:  0.371472, 0.093750 (1.420 sec)
10.183... logprob:  0.419978, 0.109375 (1.415 sec)
10.184... logprob:  0.483505, 0.132812 (1.423 sec)
10.185... logprob:  0.289936, 0.062500 (1.395 sec)
10.186... logprob:  0.370586, 0.093750 (1.404 sec)
10.187... logprob:  0.529642, 0.148438 (1.400 sec)
10.188... logprob:  0.459054, 0.125000 (1.396 sec)
10.189... logprob:  0.440903, 0.117188 (1.400 sec)
10.190... logprob:  0.375719, 0.093750 (1.440 sec)
10.191... logprob:  0.485114, 0.132812 (1.409 sec)
10.192... logprob:  0.520244, 0.148438 (1.414 sec)
10.193... logprob:  0.312680, 0.070312 (1.424 sec)
10.194... logprob:  0.414141, 0.109375 (1.414 sec)
10.195... logprob:  0.287326, 0.062500 (1.403 sec)
10.196... logprob:  0.410598, 0.109375 (1.399 sec)
10.197... logprob:  0.478052, 0.132812 (1.402 sec)
10.198... logprob:  0.355792, 0.085938 (1.405 sec)
10.199... logprob:  0.437196, 0.117188 (1.388 sec)
10.200... logprob:  0.440797, 0.117188 (1.444 sec)
10.201... logprob:  0.437105, 0.117188 (1.404 sec)
10.202... logprob:  0.538035, 0.148438 (1.408 sec)
10.203... logprob:  0.420490, 0.109375 (1.440 sec)
10.204... logprob:  0.504132, 0.140625 (1.400 sec)
10.205... logprob:  0.334438, 0.078125 (1.405 sec)
10.206... logprob:  0.361632, 0.093750 (1.399 sec)
10.207... logprob:  0.381971, 0.093750 (1.394 sec)
10.208... logprob:  0.490498, 0.140625 (1.399 sec)
10.209... logprob:  0.334632, 0.078125 (1.419 sec)
10.210... logprob:  0.586265, 0.171875 (1.422 sec)
10.211... logprob:  0.488228, 0.132812 (1.415 sec)
10.212... logprob:  0.526172, 0.148438 (1.407 sec)
10.213... logprob:  0.514903, 0.140625 (1.466 sec)
10.214... logprob:  0.459460, 0.125000 (1.433 sec)
10.215... logprob:  0.396170, 0.101562 (1.422 sec)
10.216... logprob:  0.517200, 0.140625 (1.471 sec)
10.217... logprob:  0.325204, 0.070312 (1.409 sec)
10.218... logprob:  0.463752, 0.125000 (1.420 sec)
10.219... logprob:  0.500352, 0.140625 (1.421 sec)
10.220... logprob:  0.414988, 0.109375 (1.420 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.5272216796875, 10.0]}, 128)
batch 872: ({'logprob': [66.02339172363281, 19.0]}, 128)
batch 873: ({'logprob': [41.55132293701172, 9.0]}, 128)
batch 874: ({'logprob': [45.873626708984375, 11.0]}, 128)
batch 875: ({'logprob': [51.136924743652344, 13.0]}, 128)
batch 876: ({'logprob': [63.63651657104492, 18.0]}, 128)
batch 877: ({'logprob': [46.34798049926758, 11.0]}, 128)
batch 878: ({'logprob': [61.68992233276367, 17.0]}, 128)
batch 879: ({'logprob': [72.68900299072266, 21.0]}, 128)
batch 880: ({'logprob': [51.14899826049805, 13.0]}, 128)
batch 881: ({'logprob': [30.524246215820312, 5.0]}, 128)
batch 882: ({'logprob': [54.95341491699219, 14.0]}, 128)
batch 883: ({'logprob': [61.67945861816406, 17.0]}, 128)
batch 884: ({'logprob': [51.601165771484375, 13.0]}, 128)
batch 885: ({'logprob': [52.54192352294922, 13.0]}, 128)
batch 886: ({'logprob': [62.15239715576172, 17.0]}, 128)

======================Test output======================
logprob:  0.418007, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.973353e-03 [2.219437e-09] 
Layer 'conv1' biases: 7.587596e-08 [5.760049e-11] 
Layer 'conv2' weights[0]: 7.960355e-03 [1.872357e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.048982e-10] 
Layer 'conv3' weights[0]: 7.958630e-03 [1.788472e-09] 
Layer 'conv3' biases: 6.934097e-07 [8.917814e-10] 
Layer 'conv4' weights[0]: 7.991223e-03 [1.962471e-09] 
Layer 'conv4' biases: 9.999999e-01 [8.822023e-09] 
Layer 'conv5' weights[0]: 7.990121e-03 [6.087358e-08] 
Layer 'conv5' biases: 9.999997e-01 [6.617842e-08] 
Layer 'fc6' weights[0]: 7.586906e-03 [5.291347e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.336287e-09] 
Layer 'fc7' weights[0]: 7.542732e-03 [1.108536e-07] 
Layer 'fc7' biases: 9.998674e-01 [9.531502e-08] 
Layer 'fc8' weights[0]: 1.299466e-03 [6.129034e-06] 
Layer 'fc8' biases: 2.058299e-02 [4.062366e-05] 
Train error last 870 batches: 0.435297
-------------------------------------------------------
Not saving because 0.418007 > 0.415712 (4.190: -0.00%)
======================================================= (12.059 sec)
10.221... logprob:  0.399532, 0.101562 (1.413 sec)
10.222... logprob:  0.554656, 0.164062 (1.483 sec)
10.223... logprob:  0.569371, 0.164062 (1.428 sec)
10.224... logprob:  0.405836, 0.101562 (1.438 sec)
10.225... logprob:  0.391963, 0.101562 (1.452 sec)
10.226... logprob:  0.424591, 0.109375 (1.427 sec)
10.227... logprob:  0.452793, 0.125000 (1.412 sec)
10.228... logprob:  0.417223, 0.109375 (1.421 sec)
10.229... logprob:  0.489367, 0.132812 (1.414 sec)
10.230... logprob:  0.459919, 0.125000 (1.434 sec)
10.231... logprob:  0.453566, 0.125000 (1.410 sec)
10.232... logprob:  0.496252, 0.140625 (1.458 sec)
10.233... logprob:  0.466212, 0.132812 (1.429 sec)
10.234... logprob:  0.563774, 0.164062 (1.419 sec)
10.235... logprob:  0.482046, 0.132812 (1.473 sec)
10.236... logprob:  0.425862, 0.109375 (1.406 sec)
10.237... logprob:  0.341501, 0.078125 (1.426 sec)
10.238... logprob:  0.389488, 0.093750 (1.416 sec)
10.239... logprob:  0.478175, 0.132812 (1.423 sec)
10.240... logprob:  0.485820, 0.132812 (1.403 sec)
10.241... logprob:  0.493615, 0.132812 (1.455 sec)
10.242... logprob:  0.341654, 0.078125 (1.436 sec)
10.243... logprob:  0.386029, 0.093750 (1.434 sec)
10.244... logprob:  0.315145, 0.070312 (1.450 sec)
10.245... logprob:  0.494417, 0.132812 (1.424 sec)
10.246... logprob:  0.416940, 0.109375 (1.420 sec)
10.247... logprob:  0.357279, 0.085938 (1.415 sec)
10.248... logprob:  0.307636, 0.070312 (1.421 sec)
10.249... logprob:  0.555803, 0.156250 (1.435 sec)
10.250... logprob:  0.591969, 0.164062 (1.412 sec)
10.251... logprob:  0.352884, 0.085938 (1.460 sec)
10.252... logprob:  0.348518, 0.085938 (1.425 sec)
10.253... logprob:  0.379161, 0.093750 (1.416 sec)
10.254... logprob:  0.444189, 0.117188 (1.472 sec)
10.255... logprob:  0.351566, 0.085938 (1.402 sec)
10.256... logprob:  0.378710, 0.093750 (1.423 sec)
10.257... logprob:  0.332085, 0.078125 (1.419 sec)
10.258... logprob:  0.415862, 0.109375 (1.424 sec)
10.259... logprob:  0.442312, 0.117188 (1.402 sec)
10.260... logprob:  0.308477, 0.070312 (1.460 sec)
10.261... logprob:  0.392905, 0.101562 (1.428 sec)
10.262... logprob:  0.524725, 0.148438 (1.427 sec)
10.263... logprob:  0.425443, 0.109375 (1.454 sec)
10.264... logprob:  0.375211, 0.093750 (1.431 sec)
10.265... logprob:  0.439617, 0.117188 (1.418 sec)
10.266... logprob:  0.439058, 0.117188 (1.415 sec)
10.267... logprob:  0.421997, 0.109375 (1.417 sec)
10.268... logprob:  0.458955, 0.125000 (1.425 sec)
10.269... logprob:  0.567440, 0.164062 (1.407 sec)
10.270... logprob:  0.542170, 0.156250 (1.459 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.68873596191406, 10.0]}, 128)
batch 872: ({'logprob': [66.28263092041016, 19.0]}, 128)
batch 873: ({'logprob': [41.24346160888672, 9.0]}, 128)
batch 874: ({'logprob': [45.83900833129883, 11.0]}, 128)
batch 875: ({'logprob': [51.108612060546875, 13.0]}, 128)
batch 876: ({'logprob': [63.82631301879883, 18.0]}, 128)
batch 877: ({'logprob': [46.18013381958008, 11.0]}, 128)
batch 878: ({'logprob': [61.675899505615234, 17.0]}, 128)
batch 879: ({'logprob': [72.5562973022461, 21.0]}, 128)
batch 880: ({'logprob': [51.121299743652344, 13.0]}, 128)
batch 881: ({'logprob': [30.335193634033203, 5.0]}, 128)
batch 882: ({'logprob': [54.59638595581055, 14.0]}, 128)
batch 883: ({'logprob': [61.6652717590332, 17.0]}, 128)
batch 884: ({'logprob': [51.44024658203125, 13.0]}, 128)
batch 885: ({'logprob': [52.11469650268555, 13.0]}, 128)
batch 886: ({'logprob': [62.0053596496582, 17.0]}, 128)

======================Test output======================
logprob:  0.417324, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.973321e-03 [4.128490e-09] 
Layer 'conv1' biases: 7.669957e-08 [1.147851e-10] 
Layer 'conv2' weights[0]: 7.960318e-03 [3.511688e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.953551e-10] 
Layer 'conv3' weights[0]: 7.958592e-03 [3.361527e-09] 
Layer 'conv3' biases: 6.996582e-07 [2.197337e-09] 
Layer 'conv4' weights[0]: 7.991183e-03 [3.772801e-09] 
Layer 'conv4' biases: 9.999999e-01 [2.114263e-08] 
Layer 'conv5' weights[0]: 7.990098e-03 [1.429204e-07] 
Layer 'conv5' biases: 1.000000e+00 [1.551152e-07] 
Layer 'fc6' weights[0]: 7.586869e-03 [1.231810e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.261416e-08] 
Layer 'fc7' weights[0]: 7.540788e-03 [3.410454e-07] 
Layer 'fc7' biases: 9.998673e-01 [3.296688e-07] 
Layer 'fc8' weights[0]: 1.307824e-03 [1.394169e-05] 
Layer 'fc8' biases: 2.072232e-02 [8.765008e-05] 
Train error last 870 batches: 0.435297
-------------------------------------------------------
Not saving because 0.417324 > 0.415712 (4.190: -0.00%)
======================================================= (12.024 sec)
10.271... logprob:  0.445812, 0.117188 (1.447 sec)
10.272... logprob:  0.384832, 0.093750 (1.428 sec)
10.273... logprob:  0.500215, 0.140625 (1.468 sec)
10.274... logprob:  0.542555, 0.156250 (1.402 sec)
10.275... logprob:  0.487802, 0.132812 (1.422 sec)
10.276... logprob:  0.390237, 0.093750 (1.419 sec)
10.277... logprob:  0.428770, 0.109375 (1.424 sec)
10.278... logprob:  0.323309, 0.070312 (1.422 sec)
10.279... logprob:  0.324856, 0.070312 (1.468 sec)
10.280... logprob:  0.214857, 0.031250 (1.402 sec)
10.281... logprob:  0.417215, 0.109375 (1.430 sec)
10.282... logprob:  0.411536, 0.109375 (1.415 sec)
10.283... logprob:  0.393914, 0.101562 (1.422 sec)
10.284... logprob:  0.394822, 0.101562 (1.411 sec)
10.285... logprob:  0.452446, 0.117188 (1.438 sec)
10.286... logprob:  0.537928, 0.140625 (1.440 sec)
10.287... logprob:  0.346739, 0.085938 (1.434 sec)
10.288... logprob:  0.329997, 0.078125 (1.437 sec)
10.289... logprob:  0.446106, 0.117188 (1.446 sec)
10.290... logprob:  0.490645, 0.132812 (1.417 sec)
10.291... logprob:  0.439092, 0.117188 (1.416 sec)
10.292... logprob:  0.566771, 0.156250 (1.422 sec)
10.293... logprob:  0.427407, 0.117188 (1.436 sec)
10.294... logprob:  0.356382, 0.085938 (1.406 sec)
10.295... logprob:  0.335440, 0.078125 (1.467 sec)
10.296... logprob:  0.356498, 0.085938 (1.417 sec)
10.297... logprob:  0.395002, 0.101562 (1.460 sec)
10.298... logprob:  0.448063, 0.125000 (1.462 sec)
10.299... logprob:  0.342888, 0.078125 (1.405 sec)
10.300... logprob:  0.406811, 0.101562 (1.424 sec)
10.301... logprob:  0.397988, 0.101562 (1.412 sec)
10.302... logprob:  0.591581, 0.179688 (1.414 sec)
10.303... logprob:  0.459709, 0.125000 (1.417 sec)
10.304... logprob:  0.459758, 0.125000 (1.447 sec)
10.305... logprob:  0.455265, 0.125000 (1.436 sec)
10.306... logprob:  0.440633, 0.117188 (1.436 sec)
10.307... logprob:  0.421594, 0.109375 (1.445 sec)
10.308... logprob:  0.374453, 0.093750 (1.459 sec)
10.309... logprob:  0.450502, 0.125000 (1.414 sec)
10.310... logprob:  0.473831, 0.125000 (1.424 sec)
10.311... logprob:  0.502741, 0.140625 (1.425 sec)
10.312... logprob:  0.478849, 0.132812 (1.438 sec)
10.313... logprob:  0.454879, 0.125000 (1.419 sec)
10.314... logprob:  0.454584, 0.117188 (1.470 sec)
10.315... logprob:  0.314720, 0.070312 (1.439 sec)
10.316... logprob:  0.468609, 0.125000 (1.427 sec)
10.317... logprob:  0.355578, 0.085938 (1.484 sec)
10.318... logprob:  0.455430, 0.125000 (1.419 sec)
10.319... logprob:  0.423235, 0.117188 (1.422 sec)
10.320... logprob:  0.412279, 0.109375 (1.431 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.48765182495117, 10.0]}, 128)
batch 872: ({'logprob': [66.55406188964844, 19.0]}, 128)
batch 873: ({'logprob': [40.63670349121094, 9.0]}, 128)
batch 874: ({'logprob': [45.14392852783203, 11.0]}, 128)
batch 875: ({'logprob': [50.76508331298828, 13.0]}, 128)
batch 876: ({'logprob': [64.03182220458984, 18.0]}, 128)
batch 877: ({'logprob': [45.70375442504883, 11.0]}, 128)
batch 878: ({'logprob': [62.03558349609375, 17.0]}, 128)
batch 879: ({'logprob': [73.83820343017578, 21.0]}, 128)
batch 880: ({'logprob': [50.77718734741211, 13.0]}, 128)
batch 881: ({'logprob': [28.80499267578125, 5.0]}, 128)
batch 882: ({'logprob': [54.97953414916992, 14.0]}, 128)
batch 883: ({'logprob': [62.02518081665039, 17.0]}, 128)
batch 884: ({'logprob': [51.31781005859375, 13.0]}, 128)
batch 885: ({'logprob': [52.433109283447266, 13.0]}, 128)
batch 886: ({'logprob': [62.586002349853516, 17.0]}, 128)

======================Test output======================
logprob:  0.416563, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.973278e-03 [1.918163e-09] 
Layer 'conv1' biases: 7.737586e-08 [2.837513e-11] 
Layer 'conv2' weights[0]: 7.960281e-03 [1.533440e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.410967e-10] 
Layer 'conv3' weights[0]: 7.958556e-03 [1.229827e-09] 
Layer 'conv3' biases: 7.038911e-07 [4.263359e-10] 
Layer 'conv4' weights[0]: 7.991142e-03 [1.361006e-09] 
Layer 'conv4' biases: 9.999999e-01 [3.566959e-09] 
Layer 'conv5' weights[0]: 7.990040e-03 [2.363009e-08] 
Layer 'conv5' biases: 9.999993e-01 [2.545931e-08] 
Layer 'fc6' weights[0]: 7.586829e-03 [2.230952e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.076127e-09] 
Layer 'fc7' weights[0]: 7.538839e-03 [1.213944e-07] 
Layer 'fc7' biases: 9.998681e-01 [1.064757e-07] 
Layer 'fc8' weights[0]: 1.329993e-03 [3.912673e-06] 
Layer 'fc8' biases: 2.116219e-02 [2.604505e-05] 
Train error last 870 batches: 0.435297
-------------------------------------------------------
Not saving because 0.416563 > 0.415712 (4.190: -0.00%)
======================================================= (12.061 sec)
10.321... logprob:  0.348318, 0.085938 (1.439 sec)
10.322... logprob:  0.387567, 0.101562 (1.422 sec)
10.323... logprob:  0.416536, 0.109375 (1.476 sec)
10.324... logprob:  0.498663, 0.140625 (1.424 sec)
10.325... logprob:  0.350684, 0.085938 (1.440 sec)
10.326... logprob:  0.543213, 0.148438 (1.459 sec)
10.327... logprob:  0.554422, 0.164062 (1.431 sec)
10.328... logprob:  0.564989, 0.156250 (1.423 sec)
10.329... logprob:  0.402040, 0.101562 (1.428 sec)
10.330... logprob:  0.388735, 0.101562 (1.445 sec)
10.331... logprob:  0.352644, 0.085938 (1.429 sec)
10.332... logprob:  0.482805, 0.132812 (1.450 sec)
10.333... logprob:  0.339698, 0.085938 (1.443 sec)
10.334... logprob:  0.565046, 0.171875 (1.439 sec)
10.335... logprob:  0.358939, 0.085938 (1.442 sec)
10.336... logprob:  0.444821, 0.125000 (1.454 sec)
10.337... logprob:  0.566515, 0.164062 (1.416 sec)
10.338... logprob:  0.449519, 0.125000 (1.426 sec)
10.339... logprob:  0.488757, 0.132812 (1.428 sec)
10.340... logprob:  0.442086, 0.117188 (1.435 sec)
10.341... logprob:  0.530196, 0.148438 (1.428 sec)
10.342... logprob:  0.429721, 0.109375 (1.462 sec)
10.343... logprob:  0.434799, 0.109375 (1.437 sec)
10.344... logprob:  0.444385, 0.125000 (1.478 sec)
10.345... logprob:  0.488302, 0.132812 (1.445 sec)
10.346... logprob:  0.436268, 0.117188 (1.436 sec)
10.347... logprob:  0.372283, 0.085938 (1.486 sec)
10.348... logprob:  0.398434, 0.101562 (1.434 sec)
10.349... logprob:  0.498007, 0.140625 (1.434 sec)
10.350... logprob:  0.358494, 0.085938 (1.435 sec)
10.351... logprob:  0.508765, 0.140625 (1.425 sec)
10.352... logprob:  0.363695, 0.093750 (1.438 sec)
10.353... logprob:  0.512938, 0.148438 (1.486 sec)
10.354... logprob:  0.675284, 0.203125 (1.434 sec)
10.355... logprob:  0.357469, 0.085938 (1.449 sec)
10.356... logprob:  0.479266, 0.132812 (1.477 sec)
10.357... logprob:  0.347173, 0.085938 (1.436 sec)
10.358... logprob:  0.326146, 0.070312 (1.439 sec)
10.359... logprob:  0.555172, 0.164062 (1.435 sec)
10.360... logprob:  0.444519, 0.117188 (1.427 sec)
10.361... logprob:  0.410799, 0.101562 (1.437 sec)
10.362... logprob:  0.424218, 0.117188 (1.478 sec)
10.363... logprob:  0.486595, 0.132812 (1.443 sec)
10.364... logprob:  0.475520, 0.125000 (1.455 sec)
10.365... logprob:  0.425116, 0.109375 (1.465 sec)
10.366... logprob:  0.409754, 0.109375 (1.448 sec)
10.367... logprob:  0.325044, 0.078125 (1.440 sec)
10.368... logprob:  0.595766, 0.171875 (1.427 sec)
10.369... logprob:  0.381484, 0.093750 (1.424 sec)
10.370... logprob:  0.381112, 0.093750 (1.438 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.81467819213867, 10.0]}, 128)
batch 872: ({'logprob': [66.54195404052734, 19.0]}, 128)
batch 873: ({'logprob': [40.62166213989258, 9.0]}, 128)
batch 874: ({'logprob': [45.261817932128906, 11.0]}, 128)
batch 875: ({'logprob': [50.79514694213867, 13.0]}, 128)
batch 876: ({'logprob': [64.00869750976562, 18.0]}, 128)
batch 877: ({'logprob': [45.711708068847656, 11.0]}, 128)
batch 878: ({'logprob': [61.8907356262207, 17.0]}, 128)
batch 879: ({'logprob': [73.40843963623047, 21.0]}, 128)
batch 880: ({'logprob': [50.807796478271484, 13.0]}, 128)
batch 881: ({'logprob': [29.07524299621582, 5.0]}, 128)
batch 882: ({'logprob': [54.69039535522461, 14.0]}, 128)
batch 883: ({'logprob': [61.88008117675781, 17.0]}, 128)
batch 884: ({'logprob': [51.2376823425293, 13.0]}, 128)
batch 885: ({'logprob': [52.132408142089844, 13.0]}, 128)
batch 886: ({'logprob': [62.33079528808594, 17.0]}, 128)

======================Test output======================
logprob:  0.416118, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.973236e-03 [2.201366e-09] 
Layer 'conv1' biases: 7.803091e-08 [4.833461e-11] 
Layer 'conv2' weights[0]: 7.960235e-03 [1.904333e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.655456e-10] 
Layer 'conv3' weights[0]: 7.958515e-03 [1.757959e-09] 
Layer 'conv3' biases: 7.097479e-07 [8.603978e-10] 
Layer 'conv4' weights[0]: 7.991100e-03 [1.887589e-09] 
Layer 'conv4' biases: 9.999999e-01 [7.820741e-09] 
Layer 'conv5' weights[0]: 7.989996e-03 [5.088959e-08] 
Layer 'conv5' biases: 9.999995e-01 [5.513028e-08] 
Layer 'fc6' weights[0]: 7.586794e-03 [4.550418e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.514683e-09] 
Layer 'fc7' weights[0]: 7.536914e-03 [1.118514e-07] 
Layer 'fc7' biases: 9.998679e-01 [9.628160e-08] 
Layer 'fc8' weights[0]: 1.325829e-03 [6.871899e-06] 
Layer 'fc8' biases: 2.122942e-02 [4.423355e-05] 
Train error last 870 batches: 0.435296
-------------------------------------------------------
Not saving because 0.416118 > 0.415712 (4.190: -0.00%)
======================================================= (12.065 sec)
10.371... logprob:  0.400322, 0.101562 (1.472 sec)
10.372... logprob:  0.537745, 0.156250 (1.454 sec)
10.373... logprob:  0.463853, 0.125000 (1.450 sec)
10.374... logprob:  0.527193, 0.148438 (1.450 sec)
10.375... logprob:  0.393794, 0.101562 (1.462 sec)
10.376... logprob:  0.374338, 0.093750 (1.445 sec)
10.377... logprob:  0.295371, 0.062500 (1.421 sec)
10.378... logprob:  0.453809, 0.125000 (1.435 sec)
10.379... logprob:  0.420239, 0.109375 (1.435 sec)
10.380... logprob:  0.605780, 0.179688 (1.437 sec)
10.381... logprob:  0.463522, 0.125000 (1.468 sec)
10.382... logprob:  0.529470, 0.148438 (1.447 sec)
10.383... logprob:  0.358778, 0.085938 (1.439 sec)
10.384... logprob:  0.520973, 0.148438 (1.482 sec)
10.385... logprob:  0.523422, 0.148438 (1.438 sec)
10.386... logprob:  0.582243, 0.171875 (1.426 sec)
10.387... logprob:  0.428763, 0.117188 (1.436 sec)
10.388... logprob:  0.521288, 0.148438 (1.429 sec)
10.389... logprob:  0.426062, 0.109375 (1.429 sec)
10.390... logprob:  0.420040, 0.109375 (1.478 sec)
10.391... logprob:  0.318454, 0.070312 (1.447 sec)
10.392... logprob:  0.439406, 0.117188 (1.437 sec)
10.393... logprob:  0.368749, 0.093750 (1.485 sec)
10.394... logprob:  0.343370, 0.078125 (1.437 sec)
10.395... logprob:  0.331397, 0.078125 (1.429 sec)
10.396... logprob:  0.251493, 0.046875 (1.440 sec)
10.397... logprob:  0.485055, 0.132812 (1.432 sec)
10.398... logprob:  0.471827, 0.125000 (1.437 sec)
10.399... logprob:  0.434010, 0.117188 (1.484 sec)
10.400... logprob:  0.539134, 0.148438 (1.437 sec)
10.401... logprob:  0.466457, 0.125000 (1.447 sec)
10.402... logprob:  0.474490, 0.125000 (1.478 sec)
10.403... logprob:  0.462308, 0.125000 (1.437 sec)
10.404... logprob:  0.474829, 0.125000 (1.434 sec)
10.405... logprob:  0.543616, 0.156250 (1.440 sec)
10.406... logprob:  0.358112, 0.085938 (1.428 sec)
10.407... logprob:  0.492514, 0.140625 (1.433 sec)
10.408... logprob:  0.340232, 0.078125 (1.484 sec)
10.409... logprob:  0.401337, 0.101562 (1.438 sec)
10.410... logprob:  0.581472, 0.171875 (1.455 sec)
10.411... logprob:  0.398595, 0.101562 (1.474 sec)
10.412... logprob:  0.540161, 0.156250 (1.436 sec)
10.413... logprob:  0.544763, 0.156250 (1.436 sec)
10.414... logprob:  0.466760, 0.125000 (1.424 sec)
10.415... logprob:  0.401836, 0.101562 (1.423 sec)
10.416... logprob:  0.427586, 0.109375 (1.442 sec)
10.417... logprob:  0.405350, 0.093750 (1.460 sec)
10.418... logprob:  0.379853, 0.093750 (1.448 sec)
10.419... logprob:  0.417365, 0.101562 (1.453 sec)
10.420... logprob:  0.355549, 0.085938 (1.453 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.57990264892578, 10.0]}, 128)
batch 872: ({'logprob': [66.56866455078125, 19.0]}, 128)
batch 873: ({'logprob': [40.596744537353516, 9.0]}, 128)
batch 874: ({'logprob': [45.16400146484375, 11.0]}, 128)
batch 875: ({'logprob': [50.76326370239258, 13.0]}, 128)
batch 876: ({'logprob': [64.03704833984375, 18.0]}, 128)
batch 877: ({'logprob': [45.683074951171875, 11.0]}, 128)
batch 878: ({'logprob': [61.990447998046875, 17.0]}, 128)
batch 879: ({'logprob': [73.70881652832031, 21.0]}, 128)
batch 880: ({'logprob': [50.775630950927734, 13.0]}, 128)
batch 881: ({'logprob': [28.849416732788086, 5.0]}, 128)
batch 882: ({'logprob': [54.86490249633789, 14.0]}, 128)
batch 883: ({'logprob': [61.97986602783203, 17.0]}, 128)
batch 884: ({'logprob': [51.27535629272461, 13.0]}, 128)
batch 885: ({'logprob': [52.30891799926758, 13.0]}, 128)
batch 886: ({'logprob': [62.49994659423828, 17.0]}, 128)

======================Test output======================
logprob:  0.416331, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.973196e-03 [3.023602e-09] 
Layer 'conv1' biases: 7.871328e-08 [1.226443e-10] 
Layer 'conv2' weights[0]: 7.960191e-03 [3.422852e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.801074e-10] 
Layer 'conv3' weights[0]: 7.958475e-03 [3.529908e-09] 
Layer 'conv3' biases: 7.129812e-07 [2.120188e-09] 
Layer 'conv4' weights[0]: 7.991062e-03 [3.808457e-09] 
Layer 'conv4' biases: 9.999999e-01 [2.026337e-08] 
Layer 'conv5' weights[0]: 7.989954e-03 [1.359925e-07] 
Layer 'conv5' biases: 9.999990e-01 [1.475732e-07] 
Layer 'fc6' weights[0]: 7.586753e-03 [1.172228e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.202026e-08] 
Layer 'fc7' weights[0]: 7.535001e-03 [4.234729e-07] 
Layer 'fc7' biases: 9.998680e-01 [4.090777e-07] 
Layer 'fc8' weights[0]: 1.325044e-03 [1.913978e-05] 
Layer 'fc8' biases: 2.150481e-02 [1.274967e-04] 
Train error last 870 batches: 0.435296
-------------------------------------------------------
Not saving because 0.416331 > 0.415712 (4.190: -0.00%)
======================================================= (12.028 sec)
10.421... logprob:  0.376501, 0.101562 (1.461 sec)
10.422... logprob:  0.523736, 0.148438 (1.442 sec)
10.423... logprob:  0.421199, 0.109375 (1.423 sec)
10.424... logprob:  0.324459, 0.078125 (1.434 sec)
10.425... logprob:  0.305918, 0.070312 (1.438 sec)
10.426... logprob:  0.449661, 0.117188 (1.451 sec)
10.427... logprob:  0.555582, 0.156250 (1.461 sec)
10.428... logprob:  0.602733, 0.171875 (1.455 sec)
10.429... logprob:  0.426207, 0.109375 (1.445 sec)
10.430... logprob:  0.300121, 0.070312 (1.481 sec)
10.431... logprob:  0.598751, 0.171875 (1.432 sec)
10.432... logprob:  0.387680, 0.093750 (1.429 sec)
10.433... logprob:  0.330707, 0.078125 (1.436 sec)
10.434... logprob:  0.528773, 0.148438 (1.436 sec)
10.435... logprob:  0.531767, 0.156250 (1.430 sec)
10.436... logprob:  0.382023, 0.093750 (1.477 sec)
10.437... logprob:  0.500180, 0.140625 (1.448 sec)
10.438... logprob:  0.546659, 0.156250 (1.433 sec)
10.439... logprob:  0.379590, 0.093750 (1.492 sec)
10.440... logprob:  0.440016, 0.117188 (1.432 sec)
10.441... logprob:  0.468093, 0.125000 (1.433 sec)
10.442... logprob:  0.378869, 0.093750 (1.435 sec)
10.443... logprob:  0.496609, 0.140625 (1.438 sec)
10.444... logprob:  0.371853, 0.093750 (1.434 sec)
10.445... logprob:  0.361819, 0.085938 (1.484 sec)
10.446... logprob:  0.397898, 0.101562 (1.435 sec)
10.447... logprob:  0.571004, 0.164062 (1.437 sec)
10.448... logprob:  0.332156, 0.078125 (1.480 sec)
10.449... logprob:  0.400030, 0.101562 (1.435 sec)
10.450... logprob:  0.238229, 0.046875 (1.437 sec)
10.451... logprob:  0.453395, 0.125000 (1.434 sec)
10.452... logprob:  0.456635, 0.117188 (1.425 sec)
10.453... logprob:  0.455795, 0.125000 (1.432 sec)
10.454... logprob:  0.489477, 0.132812 (1.480 sec)
10.455... logprob:  0.506166, 0.140625 (1.435 sec)
10.456... logprob:  0.468756, 0.125000 (1.450 sec)
10.457... logprob:  0.375448, 0.093750 (1.479 sec)
10.458... logprob:  0.351422, 0.085938 (1.431 sec)
10.459... logprob:  0.513362, 0.140625 (1.435 sec)
10.460... logprob:  0.275276, 0.054688 (1.432 sec)
10.461... logprob:  0.459889, 0.125000 (1.430 sec)
10.462... logprob:  0.471844, 0.125000 (1.434 sec)
10.463... logprob:  0.421065, 0.109375 (1.475 sec)
10.464... logprob:  0.482618, 0.132812 (1.447 sec)
10.465... logprob:  0.421299, 0.109375 (1.458 sec)
10.466... logprob:  0.318865, 0.070312 (1.458 sec)
10.467... logprob:  0.413893, 0.109375 (1.448 sec)
10.468... logprob:  0.394276, 0.101562 (1.434 sec)
10.469... logprob:  0.334519, 0.078125 (1.426 sec)
10.470... logprob:  0.400021, 0.101562 (1.426 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.50166702270508, 10.0]}, 128)
batch 872: ({'logprob': [66.95886993408203, 19.0]}, 128)
batch 873: ({'logprob': [40.198387145996094, 9.0]}, 128)
batch 874: ({'logprob': [45.01689910888672, 11.0]}, 128)
batch 875: ({'logprob': [50.71107864379883, 13.0]}, 128)
batch 876: ({'logprob': [64.3410415649414, 18.0]}, 128)
batch 877: ({'logprob': [45.457740783691406, 11.0]}, 128)
batch 878: ({'logprob': [62.1295051574707, 17.0]}, 128)
batch 879: ({'logprob': [73.9613037109375, 21.0]}, 128)
batch 880: ({'logprob': [50.72384262084961, 13.0]}, 128)
batch 881: ({'logprob': [28.337574005126953, 5.0]}, 128)
batch 882: ({'logprob': [54.66670227050781, 14.0]}, 128)
batch 883: ({'logprob': [62.11882019042969, 17.0]}, 128)
batch 884: ({'logprob': [51.14612579345703, 13.0]}, 128)
batch 885: ({'logprob': [52.0242805480957, 13.0]}, 128)
batch 886: ({'logprob': [62.56159973144531, 17.0]}, 128)

======================Test output======================
logprob:  0.415945, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.973162e-03 [2.435753e-09] 
Layer 'conv1' biases: 7.939299e-08 [7.066414e-11] 
Layer 'conv2' weights[0]: 7.960145e-03 [2.266717e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.837556e-10] 
Layer 'conv3' weights[0]: 7.958437e-03 [2.262210e-09] 
Layer 'conv3' biases: 7.189918e-07 [1.211474e-09] 
Layer 'conv4' weights[0]: 7.991024e-03 [2.555207e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.160452e-08] 
Layer 'conv5' weights[0]: 7.989927e-03 [7.882287e-08] 
Layer 'conv5' biases: 9.999992e-01 [8.563770e-08] 
Layer 'fc6' weights[0]: 7.586718e-03 [6.878923e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.971617e-09] 
Layer 'fc7' weights[0]: 7.533044e-03 [2.519774e-07] 
Layer 'fc7' biases: 9.998683e-01 [2.396206e-07] 
Layer 'fc8' weights[0]: 1.332321e-03 [9.685435e-06] 
Layer 'fc8' biases: 2.186482e-02 [6.357998e-05] 
Train error last 870 batches: 0.435296
-------------------------------------------------------
Not saving because 0.415945 > 0.415712 (4.190: -0.00%)
======================================================= (12.023 sec)
10.471... logprob:  0.529961, 0.148438 (1.445 sec)
10.472... logprob:  0.410166, 0.109375 (1.454 sec)
10.473... logprob:  0.375251, 0.093750 (1.457 sec)
10.474... logprob:  0.466020, 0.125000 (1.458 sec)
10.475... logprob:  0.504788, 0.140625 (1.444 sec)
10.476... logprob:  0.510718, 0.140625 (1.470 sec)
10.477... logprob:  0.334424, 0.078125 (1.434 sec)
10.478... logprob:  0.464327, 0.125000 (1.430 sec)
10.479... logprob:  0.305846, 0.070312 (1.428 sec)
10.480... logprob:  0.443529, 0.117188 (1.433 sec)
10.481... logprob:  0.547664, 0.156250 (1.439 sec)
10.482... logprob:  0.443223, 0.117188 (1.478 sec)
10.483... logprob:  0.502476, 0.140625 (1.449 sec)
10.484... logprob:  0.485274, 0.132812 (1.434 sec)
10.485... logprob:  0.409217, 0.109375 (1.478 sec)
10.486... logprob:  0.361874, 0.085938 (1.436 sec)
10.487... logprob:  0.522570, 0.148438 (1.431 sec)
10.488... logprob:  0.425028, 0.109375 (1.438 sec)
10.489... logprob:  0.416041, 0.109375 (1.434 sec)
10.490... logprob:  0.440710, 0.117188 (1.435 sec)
10.491... logprob:  0.313754, 0.070312 (1.485 sec)
10.492... logprob:  0.459676, 0.125000 (1.441 sec)
10.493... logprob:  0.522109, 0.148438 (1.436 sec)
10.494... logprob:  0.450412, 0.125000 (1.487 sec)
10.495... logprob:  0.380449, 0.093750 (1.431 sec)
10.496... logprob:  0.550779, 0.156250 (1.429 sec)
10.497... logprob:  0.467163, 0.125000 (1.436 sec)
10.498... logprob:  0.476448, 0.132812 (1.434 sec)
10.499... logprob:  0.456329, 0.125000 (1.432 sec)
10.500... logprob:  0.355028, 0.085938 (1.492 sec)
10.501... logprob:  0.339110, 0.078125 (1.433 sec)
10.502... logprob:  0.459715, 0.125000 (1.443 sec)
10.503... logprob:  0.400720, 0.101562 (1.482 sec)
10.504... logprob:  0.487387, 0.132812 (1.432 sec)
10.505... logprob:  0.570822, 0.164062 (1.442 sec)
10.506... logprob:  0.479679, 0.132812 (1.431 sec)
10.507... logprob:  0.385234, 0.093750 (1.424 sec)
10.508... logprob:  0.374849, 0.093750 (1.431 sec)
10.509... logprob:  0.323396, 0.070312 (1.472 sec)
10.510... logprob:  0.390512, 0.101562 (1.444 sec)
10.511... logprob:  0.410114, 0.109375 (1.457 sec)
10.512... logprob:  0.470776, 0.125000 (1.473 sec)
10.513... logprob:  0.324988, 0.078125 (1.444 sec)
10.514... logprob:  0.406284, 0.101562 (1.441 sec)
10.515... logprob:  0.455707, 0.125000 (1.432 sec)
10.516... logprob:  0.400541, 0.109375 (1.426 sec)
10.517... logprob:  0.628299, 0.179688 (1.438 sec)
10.518... logprob:  0.437782, 0.117188 (1.452 sec)
10.519... logprob:  0.516188, 0.140625 (1.454 sec)
10.520... logprob:  0.409667, 0.109375 (1.451 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.96532440185547, 10.0]}, 128)
batch 872: ({'logprob': [66.38135528564453, 19.0]}, 128)
batch 873: ({'logprob': [40.83753204345703, 9.0]}, 128)
batch 874: ({'logprob': [45.39178466796875, 11.0]}, 128)
batch 875: ({'logprob': [50.8571662902832, 13.0]}, 128)
batch 876: ({'logprob': [63.886497497558594, 18.0]}, 128)
batch 877: ({'logprob': [45.850860595703125, 11.0]}, 128)
batch 878: ({'logprob': [61.816429138183594, 17.0]}, 128)
batch 879: ({'logprob': [73.20671081542969, 21.0]}, 128)
batch 880: ({'logprob': [50.869720458984375, 13.0]}, 128)
batch 881: ({'logprob': [29.41880989074707, 5.0]}, 128)
batch 882: ({'logprob': [54.740379333496094, 14.0]}, 128)
batch 883: ({'logprob': [61.80563735961914, 17.0]}, 128)
batch 884: ({'logprob': [51.30847930908203, 13.0]}, 128)
batch 885: ({'logprob': [52.22087860107422, 13.0]}, 128)
batch 886: ({'logprob': [62.26523208618164, 17.0]}, 128)

======================Test output======================
logprob:  0.416417, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.973117e-03 [2.636353e-09] 
Layer 'conv1' biases: 8.012425e-08 [5.596100e-11] 
Layer 'conv2' weights[0]: 7.960097e-03 [2.224364e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.259620e-10] 
Layer 'conv3' weights[0]: 7.958396e-03 [1.866077e-09] 
Layer 'conv3' biases: 7.278319e-07 [1.025815e-09] 
Layer 'conv4' weights[0]: 7.990992e-03 [1.993564e-09] 
Layer 'conv4' biases: 9.999999e-01 [8.849580e-09] 
Layer 'conv5' weights[0]: 7.989891e-03 [5.912565e-08] 
Layer 'conv5' biases: 9.999997e-01 [6.422486e-08] 
Layer 'fc6' weights[0]: 7.586674e-03 [5.242947e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.280050e-09] 
Layer 'fc7' weights[0]: 7.531139e-03 [2.469955e-07] 
Layer 'fc7' biases: 9.998676e-01 [2.356600e-07] 
Layer 'fc8' weights[0]: 1.310572e-03 [9.593343e-06] 
Layer 'fc8' biases: 2.181125e-02 [5.765877e-05] 
Train error last 870 batches: 0.435295
-------------------------------------------------------
Not saving because 0.416417 > 0.415712 (4.190: -0.00%)
======================================================= (12.038 sec)
10.521... logprob:  0.427592, 0.109375 (1.459 sec)
10.522... logprob:  0.533021, 0.156250 (1.461 sec)
10.523... logprob:  0.331973, 0.078125 (1.438 sec)
10.524... logprob:  0.437307, 0.117188 (1.429 sec)
10.525... logprob:  0.426234, 0.109375 (1.432 sec)
10.526... logprob:  0.352178, 0.078125 (1.437 sec)
10.527... logprob:  0.504517, 0.140625 (1.438 sec)
10.528... logprob:  0.440567, 0.117188 (1.465 sec)
10.529... logprob:  0.353033, 0.085938 (1.448 sec)
10.530... logprob:  0.440249, 0.117188 (1.437 sec)
10.531... logprob:  0.440066, 0.117188 (1.474 sec)
10.532... logprob:  0.467472, 0.125000 (1.428 sec)
10.533... logprob:  0.560987, 0.164062 (1.429 sec)
10.534... logprob:  0.325689, 0.078125 (1.436 sec)
10.535... logprob:  0.551877, 0.156250 (1.434 sec)
10.536... logprob:  0.507511, 0.140625 (1.431 sec)
10.537... logprob:  0.510144, 0.140625 (1.480 sec)
10.538... logprob:  0.486139, 0.132812 (1.447 sec)
10.539... logprob:  0.296244, 0.062500 (1.433 sec)
10.540... logprob:  0.447189, 0.117188 (1.491 sec)
10.541... logprob:  0.388974, 0.101562 (1.432 sec)
10.542... logprob:  0.411380, 0.109375 (1.425 sec)
10.543... logprob:  0.233548, 0.039062 (1.438 sec)
10.544... logprob:  0.317974, 0.070312 (1.429 sec)
10.545... logprob:  0.348825, 0.085938 (1.438 sec)
10.546... logprob:  0.368306, 0.093750 (1.488 sec)
10.547... logprob:  0.440243, 0.117188 (1.437 sec)
10.548... logprob:  0.453422, 0.125000 (1.445 sec)
10.549... logprob:  0.490939, 0.132812 (1.479 sec)
10.550... logprob:  0.367762, 0.093750 (1.435 sec)
10.551... logprob:  0.441930, 0.117188 (1.435 sec)
10.552... logprob:  0.471403, 0.125000 (1.435 sec)
10.553... logprob:  0.349426, 0.085938 (1.425 sec)
10.554... logprob:  0.506748, 0.140625 (1.432 sec)
10.555... logprob:  0.421422, 0.109375 (1.485 sec)
10.556... logprob:  0.356044, 0.085938 (1.443 sec)
10.557... logprob:  0.396584, 0.101562 (1.446 sec)
10.558... logprob:  0.383125, 0.101562 (1.477 sec)
10.559... logprob:  0.441346, 0.125000 (1.433 sec)
10.560... logprob:  0.335562, 0.078125 (1.453 sec)
10.561... logprob:  0.411893, 0.109375 (1.429 sec)
10.562... logprob:  0.503103, 0.140625 (1.421 sec)
10.563... logprob:  0.373935, 0.093750 (1.436 sec)
10.564... logprob:  0.468393, 0.132812 (1.469 sec)
10.565... logprob:  0.610980, 0.187500 (1.449 sec)
10.566... logprob:  0.374952, 0.093750 (1.451 sec)
10.567... logprob:  0.423545, 0.109375 (1.453 sec)
10.568... logprob:  0.496427, 0.140625 (1.453 sec)
10.569... logprob:  0.507979, 0.140625 (1.439 sec)
10.570... logprob:  0.543694, 0.164062 (1.430 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.49057388305664, 10.0]}, 128)
batch 872: ({'logprob': [65.70453643798828, 19.0]}, 128)
batch 873: ({'logprob': [42.523197174072266, 9.0]}, 128)
batch 874: ({'logprob': [46.246856689453125, 11.0]}, 128)
batch 875: ({'logprob': [51.48020935058594, 13.0]}, 128)
batch 876: ({'logprob': [63.47429656982422, 18.0]}, 128)
batch 877: ({'logprob': [47.00522994995117, 11.0]}, 128)
batch 878: ({'logprob': [61.970394134521484, 17.0]}, 128)
batch 879: ({'logprob': [73.18946838378906, 21.0]}, 128)
batch 880: ({'logprob': [51.491180419921875, 13.0]}, 128)
batch 881: ({'logprob': [31.275836944580078, 5.0]}, 128)
batch 882: ({'logprob': [55.98936080932617, 14.0]}, 128)
batch 883: ({'logprob': [61.95982360839844, 17.0]}, 128)
batch 884: ({'logprob': [52.227420806884766, 13.0]}, 128)
batch 885: ({'logprob': [53.73560333251953, 13.0]}, 128)
batch 886: ({'logprob': [62.71613311767578, 17.0]}, 128)

======================Test output======================
logprob:  0.421621, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.973084e-03 [2.507399e-09] 
Layer 'conv1' biases: 8.085102e-08 [6.088654e-11] 
Layer 'conv2' weights[0]: 7.960060e-03 [2.415166e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.160679e-10] 
Layer 'conv3' weights[0]: 7.958358e-03 [2.280600e-09] 
Layer 'conv3' biases: 7.337824e-07 [1.336940e-09] 
Layer 'conv4' weights[0]: 7.990954e-03 [2.424245e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.212056e-08] 
Layer 'conv5' weights[0]: 7.989840e-03 [8.213998e-08] 
Layer 'conv5' biases: 9.999995e-01 [8.901056e-08] 
Layer 'fc6' weights[0]: 7.586631e-03 [7.158017e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.250231e-09] 
Layer 'fc7' weights[0]: 7.529208e-03 [1.841417e-07] 
Layer 'fc7' biases: 9.998673e-01 [1.727876e-07] 
Layer 'fc8' weights[0]: 1.280801e-03 [7.590818e-06] 
Layer 'fc8' biases: 2.173839e-02 [4.639983e-05] 
Train error last 870 batches: 0.435295
-------------------------------------------------------
Not saving because 0.421621 > 0.415712 (4.190: -0.00%)
======================================================= (12.031 sec)
10.571... logprob:  0.454872, 0.125000 (1.441 sec)
10.572... logprob:  0.501572, 0.140625 (1.443 sec)
10.573... logprob:  0.512667, 0.148438 (1.442 sec)
10.574... logprob:  0.428240, 0.109375 (1.460 sec)
10.575... logprob:  0.343400, 0.078125 (1.452 sec)
10.576... logprob:  0.427457, 0.109375 (1.448 sec)
10.577... logprob:  0.460895, 0.125000 (1.474 sec)
10.578... logprob:  0.336471, 0.078125 (1.446 sec)
10.579... logprob:  0.442101, 0.117188 (1.424 sec)
10.580... logprob:  0.547164, 0.156250 (1.432 sec)
10.581... logprob:  0.531271, 0.156250 (1.435 sec)
10.582... logprob:  0.437978, 0.125000 (1.438 sec)
10.583... logprob:  0.593160, 0.171875 (1.472 sec)
10.584... logprob:  0.468171, 0.132812 (1.442 sec)
10.585... logprob:  0.349778, 0.085938 (1.432 sec)
10.586... logprob:  0.313227, 0.070312 (1.485 sec)
10.587... logprob:  0.404334, 0.101562 (1.436 sec)
10.588... logprob:  0.418689, 0.117188 (1.428 sec)
10.589... logprob:  0.361414, 0.093750 (1.435 sec)
10.590... logprob:  0.524652, 0.148438 (1.431 sec)
10.591... logprob:  0.397560, 0.101562 (1.431 sec)
10.592... logprob:  0.455629, 0.125000 (1.488 sec)
10.593... logprob:  0.467461, 0.125000 (1.435 sec)
10.594... logprob:  0.352905, 0.085938 (1.436 sec)
10.595... logprob:  0.428683, 0.109375 (1.489 sec)
10.596... logprob:  0.461567, 0.125000 (1.437 sec)
10.597... logprob:  0.397409, 0.101562 (1.431 sec)
10.598... logprob:  0.397240, 0.101562 (1.442 sec)
10.599... logprob:  0.313456, 0.070312 (1.430 sec)
10.600... logprob:  0.340907, 0.085938 (1.435 sec)
10.601... logprob:  0.402104, 0.101562 (1.487 sec)
10.602... logprob:  0.289557, 0.062500 (1.436 sec)
10.603... logprob:  0.266777, 0.054688 (1.446 sec)
10.604... logprob:  0.407508, 0.101562 (1.479 sec)
10.605... logprob:  0.563789, 0.148438 (1.436 sec)
10.606... logprob:  0.295961, 0.070312 (1.440 sec)
10.607... logprob:  0.505075, 0.132812 (1.434 sec)
10.608... logprob:  0.361577, 0.085938 (1.427 sec)
10.609... logprob:  0.356860, 0.085938 (1.438 sec)
10.610... logprob:  0.493516, 0.132812 (1.472 sec)
10.611... logprob:  0.510490, 0.140625 (1.449 sec)
10.612... logprob:  0.448313, 0.117188 (1.453 sec)
10.613... logprob:  0.280074, 0.062500 (1.465 sec)
10.614... logprob:  0.503487, 0.140625 (1.449 sec)
10.615... logprob:  0.351389, 0.085938 (1.441 sec)
10.616... logprob:  0.415531, 0.109375 (1.428 sec)
10.617... logprob:  0.418063, 0.109375 (1.429 sec)
10.618... logprob:  0.546510, 0.156250 (1.435 sec)
10.619... logprob:  0.505857, 0.140625 (1.459 sec)
10.620... logprob:  0.539585, 0.156250 (1.461 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.36858367919922, 10.0]}, 128)
batch 872: ({'logprob': [66.23505401611328, 19.0]}, 128)
batch 873: ({'logprob': [41.78615951538086, 9.0]}, 128)
batch 874: ({'logprob': [46.339656829833984, 11.0]}, 128)
batch 875: ({'logprob': [51.440792083740234, 13.0]}, 128)
batch 876: ({'logprob': [63.8315544128418, 18.0]}, 128)
batch 877: ({'logprob': [46.61818313598633, 11.0]}, 128)
batch 878: ({'logprob': [61.6710205078125, 17.0]}, 128)
batch 879: ({'logprob': [72.1512680053711, 21.0]}, 128)
batch 880: ({'logprob': [51.45378494262695, 13.0]}, 128)
batch 881: ({'logprob': [31.27875328063965, 5.0]}, 128)
batch 882: ({'logprob': [54.68581771850586, 14.0]}, 128)
batch 883: ({'logprob': [61.65991973876953, 17.0]}, 128)
batch 884: ({'logprob': [51.70890808105469, 13.0]}, 128)
batch 885: ({'logprob': [52.2564811706543, 13.0]}, 128)
batch 886: ({'logprob': [61.93683624267578, 17.0]}, 128)

======================Test output======================
logprob:  0.419152, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.973045e-03 [4.152991e-09] 
Layer 'conv1' biases: 8.157124e-08 [7.283295e-11] 
Layer 'conv2' weights[0]: 7.960023e-03 [3.050971e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.477389e-10] 
Layer 'conv3' weights[0]: 7.958322e-03 [2.589659e-09] 
Layer 'conv3' biases: 7.403110e-07 [1.438399e-09] 
Layer 'conv4' weights[0]: 7.990913e-03 [2.816783e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.293461e-08] 
Layer 'conv5' weights[0]: 7.989809e-03 [8.730530e-08] 
Layer 'conv5' biases: 9.999999e-01 [9.485500e-08] 
Layer 'fc6' weights[0]: 7.586587e-03 [7.609739e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.687118e-09] 
Layer 'fc7' weights[0]: 7.527326e-03 [2.782883e-07] 
Layer 'fc7' biases: 9.998667e-01 [2.675270e-07] 
Layer 'fc8' weights[0]: 1.284460e-03 [9.919487e-06] 
Layer 'fc8' biases: 2.191698e-02 [6.153451e-05] 
Train error last 870 batches: 0.435294
-------------------------------------------------------
Not saving because 0.419152 > 0.415712 (4.190: -0.00%)
======================================================= (12.059 sec)
10.621... logprob:  0.364128, 0.085938 (1.465 sec)
10.622... logprob:  0.365103, 0.085938 (1.453 sec)
10.623... logprob:  0.423272, 0.109375 (1.465 sec)
10.624... logprob:  0.382572, 0.093750 (1.435 sec)
10.625... logprob:  0.441023, 0.117188 (1.421 sec)
10.626... logprob:  0.438426, 0.117188 (1.432 sec)
10.627... logprob:  0.435890, 0.117188 (1.441 sec)
10.628... logprob:  0.465152, 0.125000 (1.438 sec)
10.629... logprob:  0.371904, 0.093750 (1.476 sec)
10.630... logprob:  0.422374, 0.109375 (1.446 sec)
10.631... logprob:  0.639914, 0.187500 (1.432 sec)
10.632... logprob:  0.399094, 0.101562 (1.488 sec)
10.633... logprob:  0.375976, 0.093750 (1.428 sec)
10.634... logprob:  0.660684, 0.195312 (1.427 sec)
10.635... logprob:  0.374140, 0.093750 (1.434 sec)
10.636... logprob:  0.480210, 0.132812 (1.433 sec)
10.637... logprob:  0.331099, 0.078125 (1.430 sec)
10.638... logprob:  0.515643, 0.140625 (1.478 sec)
10.639... logprob:  0.418248, 0.109375 (1.442 sec)
10.640... logprob:  0.528754, 0.148438 (1.434 sec)
10.641... logprob:  0.410542, 0.109375 (1.488 sec)
10.642... logprob:  0.500770, 0.140625 (1.431 sec)
10.643... logprob:  0.622591, 0.187500 (1.427 sec)
10.644... logprob:  0.321698, 0.070312 (1.440 sec)
10.645... logprob:  0.414537, 0.109375 (1.430 sec)
10.646... logprob:  0.385856, 0.093750 (1.436 sec)
10.647... logprob:  0.456724, 0.125000 (1.489 sec)
10.648... logprob:  0.491217, 0.140625 (1.431 sec)
10.649... logprob:  0.369978, 0.093750 (1.440 sec)
10.650... logprob:  0.413881, 0.109375 (1.477 sec)
10.651... logprob:  0.397245, 0.101562 (1.434 sec)
10.652... logprob:  0.507605, 0.140625 (1.439 sec)
10.653... logprob:  0.548412, 0.156250 (1.438 sec)
10.654... logprob:  0.496247, 0.140625 (1.424 sec)
10.655... logprob:  0.436237, 0.117188 (1.430 sec)
10.656... logprob:  0.416655, 0.109375 (1.479 sec)
10.657... logprob:  0.449413, 0.117188 (1.437 sec)
10.658... logprob:  0.345709, 0.085938 (1.450 sec)
10.659... logprob:  0.464395, 0.125000 (1.466 sec)
10.660... logprob:  0.445834, 0.125000 (1.436 sec)
10.661... logprob:  0.378638, 0.093750 (1.437 sec)
10.662... logprob:  0.469273, 0.132812 (1.428 sec)
10.663... logprob:  0.311179, 0.070312 (1.428 sec)
10.664... logprob:  0.285617, 0.062500 (1.440 sec)
10.665... logprob:  0.401954, 0.101562 (1.460 sec)
10.666... logprob:  0.442095, 0.117188 (1.451 sec)
10.667... logprob:  0.564392, 0.164062 (1.455 sec)
10.668... logprob:  0.497981, 0.140625 (1.449 sec)
10.669... logprob:  0.433201, 0.109375 (1.458 sec)
10.670... logprob:  0.362561, 0.085938 (1.434 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.13896942138672, 10.0]}, 128)
batch 872: ({'logprob': [66.6680679321289, 19.0]}, 128)
batch 873: ({'logprob': [40.68852996826172, 9.0]}, 128)
batch 874: ({'logprob': [45.050838470458984, 11.0]}, 128)
batch 875: ({'logprob': [50.789390563964844, 13.0]}, 128)
batch 876: ({'logprob': [64.15302276611328, 18.0]}, 128)
batch 877: ({'logprob': [45.741668701171875, 11.0]}, 128)
batch 878: ({'logprob': [62.295013427734375, 17.0]}, 128)
batch 879: ({'logprob': [74.4629135131836, 21.0]}, 128)
batch 880: ({'logprob': [50.801483154296875, 13.0]}, 128)
batch 881: ({'logprob': [28.490888595581055, 5.0]}, 128)
batch 882: ({'logprob': [55.39097595214844, 14.0]}, 128)
batch 883: ({'logprob': [62.284236907958984, 17.0]}, 128)
batch 884: ({'logprob': [51.47389221191406, 13.0]}, 128)
batch 885: ({'logprob': [52.85166931152344, 13.0]}, 128)
batch 886: ({'logprob': [62.976829528808594, 17.0]}, 128)

======================Test output======================
logprob:  0.417607, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.973017e-03 [2.404965e-09] 
Layer 'conv1' biases: 8.223268e-08 [3.333358e-11] 
Layer 'conv2' weights[0]: 7.959991e-03 [1.522490e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.599444e-10] 
Layer 'conv3' weights[0]: 7.958286e-03 [1.219307e-09] 
Layer 'conv3' biases: 7.448939e-07 [4.815441e-10] 
Layer 'conv4' weights[0]: 7.990882e-03 [1.182716e-09] 
Layer 'conv4' biases: 9.999998e-01 [3.323553e-09] 
Layer 'conv5' weights[0]: 7.989770e-03 [1.966735e-08] 
Layer 'conv5' biases: 9.999993e-01 [2.097799e-08] 
Layer 'fc6' weights[0]: 7.586545e-03 [1.902363e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.738856e-09] 
Layer 'fc7' weights[0]: 7.525336e-03 [8.765181e-08] 
Layer 'fc7' biases: 9.998682e-01 [7.267776e-08] 
Layer 'fc8' weights[0]: 1.334690e-03 [2.988921e-06] 
Layer 'fc8' biases: 2.233954e-02 [1.696365e-05] 
Train error last 870 batches: 0.435294
-------------------------------------------------------
Not saving because 0.417607 > 0.415712 (4.190: -0.00%)
======================================================= (12.076 sec)
10.671... logprob:  0.360851, 0.093750 (1.430 sec)
10.672... logprob:  0.441803, 0.117188 (1.432 sec)
10.673... logprob:  0.436262, 0.117188 (1.436 sec)
10.674... logprob:  0.446690, 0.117188 (1.436 sec)
10.675... logprob:  0.356661, 0.093750 (1.460 sec)
10.676... logprob:  0.450133, 0.125000 (1.449 sec)
10.677... logprob:  0.471085, 0.125000 (1.439 sec)
10.678... logprob:  0.465631, 0.125000 (1.482 sec)
10.679... logprob:  0.454887, 0.125000 (1.435 sec)
10.680... logprob:  0.351779, 0.078125 (1.429 sec)
10.681... logprob:  0.374000, 0.093750 (1.435 sec)
10.682... logprob:  0.340533, 0.078125 (1.439 sec)
10.683... logprob:  0.411662, 0.109375 (1.432 sec)
10.684... logprob:  0.357542, 0.085938 (1.473 sec)
10.685... logprob:  0.285659, 0.054688 (1.452 sec)
10.686... logprob:  0.318349, 0.070312 (1.431 sec)
10.687... logprob:  0.281357, 0.062500 (1.486 sec)
10.688... logprob:  0.323050, 0.078125 (1.432 sec)
10.689... logprob:  0.471897, 0.125000 (1.429 sec)
10.690... logprob:  0.528545, 0.140625 (1.432 sec)
10.691... logprob:  0.517610, 0.140625 (1.430 sec)
10.692... logprob:  0.385659, 0.101562 (1.433 sec)
10.693... logprob:  0.456355, 0.125000 (1.485 sec)
10.694... logprob:  0.330859, 0.078125 (1.439 sec)
10.695... logprob:  0.356860, 0.085938 (1.443 sec)
10.696... logprob:  0.538485, 0.148438 (1.481 sec)
10.697... logprob:  0.465471, 0.125000 (1.431 sec)
10.698... logprob:  0.548207, 0.156250 (1.430 sec)
10.699... logprob:  0.459563, 0.125000 (1.439 sec)
10.700... logprob:  0.434189, 0.117188 (1.429 sec)
10.701... logprob:  0.423631, 0.109375 (1.434 sec)
10.702... logprob:  0.521383, 0.148438 (1.482 sec)
10.703... logprob:  0.405890, 0.101562 (1.436 sec)
10.704... logprob:  0.406582, 0.101562 (1.449 sec)
10.705... logprob:  0.420426, 0.109375 (1.473 sec)
10.706... logprob:  0.468090, 0.125000 (1.429 sec)
10.707... logprob:  0.485301, 0.132812 (1.434 sec)
10.708... logprob:  0.416925, 0.109375 (1.434 sec)
10.709... logprob:  0.422294, 0.109375 (1.426 sec)
10.710... logprob:  0.603279, 0.179688 (1.435 sec)
10.711... logprob:  0.469588, 0.125000 (1.463 sec)
10.712... logprob:  0.339955, 0.078125 (1.442 sec)
10.713... logprob:  0.587942, 0.179688 (1.458 sec)
10.714... logprob:  0.466407, 0.125000 (1.454 sec)
10.715... logprob:  0.417109, 0.109375 (1.449 sec)
10.716... logprob:  0.335112, 0.078125 (1.441 sec)
10.717... logprob:  0.429883, 0.117188 (1.424 sec)
10.718... logprob:  0.490424, 0.132812 (1.428 sec)
10.719... logprob:  0.406216, 0.109375 (1.434 sec)
10.720... logprob:  0.433247, 0.117188 (1.446 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.64829635620117, 10.0]}, 128)
batch 872: ({'logprob': [66.62425994873047, 19.0]}, 128)
batch 873: ({'logprob': [40.52363967895508, 9.0]}, 128)
batch 874: ({'logprob': [45.166568756103516, 11.0]}, 128)
batch 875: ({'logprob': [50.75804138183594, 13.0]}, 128)
batch 876: ({'logprob': [64.07614135742188, 18.0]}, 128)
batch 877: ({'logprob': [45.644126892089844, 11.0]}, 128)
batch 878: ({'logprob': [61.97069549560547, 17.0]}, 128)
batch 879: ({'logprob': [73.63277435302734, 21.0]}, 128)
batch 880: ({'logprob': [50.77077102661133, 13.0]}, 128)
batch 881: ({'logprob': [28.83251953125, 5.0]}, 128)
batch 882: ({'logprob': [54.75257110595703, 14.0]}, 128)
batch 883: ({'logprob': [61.95973587036133, 17.0]}, 128)
batch 884: ({'logprob': [51.22895431518555, 13.0]}, 128)
batch 885: ({'logprob': [52.17940902709961, 13.0]}, 128)
batch 886: ({'logprob': [62.43873596191406, 17.0]}, 128)

======================Test output======================
logprob:  0.416117, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.972980e-03 [1.779863e-09] 
Layer 'conv1' biases: 8.274549e-08 [4.143812e-11] 
Layer 'conv2' weights[0]: 7.959952e-03 [1.313563e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.622860e-10] 
Layer 'conv3' weights[0]: 7.958253e-03 [1.166190e-09] 
Layer 'conv3' biases: 7.496402e-07 [4.705574e-10] 
Layer 'conv4' weights[0]: 7.990840e-03 [1.104198e-09] 
Layer 'conv4' biases: 9.999998e-01 [2.760347e-09] 
Layer 'conv5' weights[0]: 7.989723e-03 [1.225708e-08] 
Layer 'conv5' biases: 9.999992e-01 [1.245317e-08] 
Layer 'fc6' weights[0]: 7.586505e-03 [1.256216e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.718086e-10] 
Layer 'fc7' weights[0]: 7.523457e-03 [6.209547e-08] 
Layer 'fc7' biases: 9.998676e-01 [4.222730e-08] 
Layer 'fc8' weights[0]: 1.326056e-03 [5.109268e-06] 
Layer 'fc8' biases: 2.251582e-02 [3.297345e-05] 
Train error last 870 batches: 0.435293
-------------------------------------------------------
Not saving because 0.416117 > 0.415712 (4.190: -0.00%)
======================================================= (12.101 sec)
10.721... logprob:  0.451595, 0.117188 (1.471 sec)
10.722... logprob:  0.536710, 0.156250 (1.457 sec)
10.723... logprob:  0.416652, 0.109375 (1.439 sec)
10.724... logprob:  0.412799, 0.109375 (1.469 sec)
10.725... logprob:  0.494537, 0.140625 (1.429 sec)
10.726... logprob:  0.338862, 0.085938 (1.428 sec)
10.727... logprob:  0.393504, 0.101562 (1.427 sec)
10.728... logprob:  0.421476, 0.109375 (1.442 sec)
10.729... logprob:  0.387945, 0.093750 (1.434 sec)
10.730... logprob:  0.565798, 0.164062 (1.478 sec)
10.731... logprob:  0.450279, 0.125000 (1.447 sec)
10.732... logprob:  0.311521, 0.070312 (1.442 sec)
10.733... logprob:  0.556857, 0.156250 (1.481 sec)
10.734... logprob:  0.340191, 0.078125 (1.440 sec)
10.735... logprob:  0.527771, 0.148438 (1.423 sec)
10.736... logprob:  0.643369, 0.187500 (1.431 sec)
10.737... logprob:  0.516288, 0.148438 (1.438 sec)
10.738... logprob:  0.459468, 0.125000 (1.430 sec)
10.739... logprob:  0.477837, 0.132812 (1.481 sec)
10.740... logprob:  0.339680, 0.078125 (1.433 sec)
10.741... logprob:  0.393449, 0.101562 (1.439 sec)
10.742... logprob:  0.419785, 0.109375 (1.481 sec)
10.743... logprob:  0.364879, 0.085938 (1.436 sec)
10.744... logprob:  0.519323, 0.148438 (1.433 sec)
10.745... logprob:  0.478212, 0.132812 (1.441 sec)
10.746... logprob:  0.440575, 0.117188 (1.428 sec)
10.747... logprob:  0.425655, 0.109375 (1.433 sec)
10.748... logprob:  0.378010, 0.093750 (1.481 sec)
10.749... logprob:  0.420875, 0.109375 (1.436 sec)
10.750... logprob:  0.513007, 0.140625 (1.446 sec)
10.751... logprob:  0.263444, 0.054688 (1.479 sec)
10.752... logprob:  0.522517, 0.140625 (1.438 sec)
10.753... logprob:  0.441319, 0.117188 (1.435 sec)
10.754... logprob:  0.468737, 0.132812 (1.423 sec)
10.755... logprob:  0.507165, 0.140625 (1.422 sec)
10.756... logprob:  0.440824, 0.117188 (1.438 sec)
10.757... logprob:  0.552193, 0.156250 (1.473 sec)
10.758... logprob:  0.393803, 0.101562 (1.442 sec)
10.759... logprob:  0.459693, 0.125000 (1.485 sec)
10.760... logprob:  0.485333, 0.132812 (1.456 sec)
10.761... logprob:  0.418544, 0.109375 (1.443 sec)
10.762... logprob:  0.515940, 0.148438 (1.440 sec)
10.763... logprob:  0.558675, 0.164062 (1.431 sec)
10.764... logprob:  0.503307, 0.140625 (1.430 sec)
10.765... logprob:  0.312582, 0.062500 (1.438 sec)
10.766... logprob:  0.482347, 0.132812 (1.459 sec)
10.767... logprob:  0.371214, 0.085938 (1.455 sec)
10.768... logprob:  0.432742, 0.117188 (1.464 sec)
10.769... logprob:  0.490971, 0.140625 (1.462 sec)
10.770... logprob:  0.402729, 0.101562 (1.474 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.32129669189453, 10.0]}, 128)
batch 872: ({'logprob': [66.24536895751953, 19.0]}, 128)
batch 873: ({'logprob': [41.116485595703125, 9.0]}, 128)
batch 874: ({'logprob': [45.63362121582031, 11.0]}, 128)
batch 875: ({'logprob': [50.98545837402344, 13.0]}, 128)
batch 876: ({'logprob': [63.7884407043457, 18.0]}, 128)
batch 877: ({'logprob': [46.05492401123047, 11.0]}, 128)
batch 878: ({'logprob': [61.717811584472656, 17.0]}, 128)
batch 879: ({'logprob': [72.84288787841797, 21.0]}, 128)
batch 880: ({'logprob': [50.998199462890625, 13.0]}, 128)
batch 881: ({'logprob': [29.963138580322266, 5.0]}, 128)
batch 882: ({'logprob': [54.71613311767578, 14.0]}, 128)
batch 883: ({'logprob': [61.706748962402344, 17.0]}, 128)
batch 884: ({'logprob': [51.398284912109375, 13.0]}, 128)
batch 885: ({'logprob': [52.23384094238281, 13.0]}, 128)
batch 886: ({'logprob': [62.12800979614258, 17.0]}, 128)

======================Test output======================
logprob:  0.416919, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.972938e-03 [2.269471e-09] 
Layer 'conv1' biases: 8.344420e-08 [8.063962e-11] 
Layer 'conv2' weights[0]: 7.959913e-03 [1.964134e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.079436e-10] 
Layer 'conv3' weights[0]: 7.958215e-03 [2.119284e-09] 
Layer 'conv3' biases: 7.547323e-07 [1.204962e-09] 
Layer 'conv4' weights[0]: 7.990800e-03 [2.384950e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.238211e-08] 
Layer 'conv5' weights[0]: 7.989692e-03 [8.517559e-08] 
Layer 'conv5' biases: 9.999990e-01 [9.275561e-08] 
Layer 'fc6' weights[0]: 7.586468e-03 [7.348616e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.440184e-09] 
Layer 'fc7' weights[0]: 7.521574e-03 [2.698052e-07] 
Layer 'fc7' biases: 9.998673e-01 [2.579108e-07] 
Layer 'fc8' weights[0]: 1.304777e-03 [9.399613e-06] 
Layer 'fc8' biases: 2.249319e-02 [6.445978e-05] 
Train error last 870 batches: 0.435293
-------------------------------------------------------
Not saving because 0.416919 > 0.415712 (4.190: -0.00%)
======================================================= (12.052 sec)
10.771... logprob:  0.549868, 0.156250 (1.472 sec)
10.772... logprob:  0.414003, 0.109375 (1.445 sec)
10.773... logprob:  0.558471, 0.164062 (1.444 sec)
10.774... logprob:  0.361378, 0.085938 (1.464 sec)
10.775... logprob:  0.407293, 0.101562 (1.460 sec)
10.776... logprob:  0.433310, 0.117188 (1.478 sec)
10.777... logprob:  0.379897, 0.093750 (1.469 sec)
10.778... logprob:  0.433673, 0.117188 (1.462 sec)
10.779... logprob:  0.505564, 0.140625 (1.486 sec)
10.780... logprob:  0.385757, 0.101562 (1.450 sec)
10.781... logprob:  0.369803, 0.085938 (1.445 sec)
10.782... logprob:  0.351585, 0.085938 (1.443 sec)
10.783... logprob:  0.555416, 0.156250 (1.454 sec)
10.784... logprob:  0.440964, 0.117188 (1.461 sec)
10.785... logprob:  0.543398, 0.156250 (1.490 sec)
10.786... logprob:  0.477297, 0.132812 (1.468 sec)
10.787... logprob:  0.545984, 0.156250 (1.462 sec)
10.788... logprob:  0.562656, 0.164062 (1.492 sec)
10.789... logprob:  0.281948, 0.054688 (1.453 sec)
10.790... logprob:  0.408574, 0.101562 (1.444 sec)
10.791... logprob:  0.398344, 0.101562 (1.444 sec)
10.792... logprob:  0.361465, 0.085938 (1.458 sec)
10.793... logprob:  0.370410, 0.085938 (1.450 sec)
10.794... logprob:  0.387115, 0.093750 (1.489 sec)
10.795... logprob:  0.469900, 0.125000 (1.469 sec)
10.796... logprob:  0.423501, 0.109375 (1.460 sec)
10.797... logprob:  0.358591, 0.085938 (1.498 sec)
10.798... logprob:  0.393254, 0.101562 (1.457 sec)
10.799... logprob:  0.331990, 0.078125 (1.447 sec)
10.800... logprob:  0.371860, 0.093750 (1.441 sec)
10.801... logprob:  0.450591, 0.117188 (1.456 sec)
10.802... logprob:  0.423334, 0.109375 (1.451 sec)
10.803... logprob:  0.492360, 0.132812 (1.495 sec)
10.804... logprob:  0.350014, 0.085938 (1.469 sec)
10.805... logprob:  0.452299, 0.117188 (1.454 sec)
10.806... logprob:  0.424189, 0.109375 (1.504 sec)
10.807... logprob:  0.443425, 0.117188 (1.453 sec)
10.808... logprob:  0.462312, 0.125000 (1.454 sec)
10.809... logprob:  0.589212, 0.171875 (1.448 sec)
10.810... logprob:  0.442420, 0.117188 (1.450 sec)
10.811... logprob:  0.460429, 0.125000 (1.452 sec)
10.812... logprob:  0.462502, 0.125000 (1.489 sec)
10.813... logprob:  0.486030, 0.132812 (1.457 sec)
10.814... logprob:  0.478305, 0.132812 (1.457 sec)
10.815... logprob:  0.372877, 0.085938 (1.502 sec)
10.816... logprob:  0.409296, 0.101562 (1.454 sec)
10.817... logprob:  0.426323, 0.109375 (1.451 sec)
10.818... logprob:  0.559959, 0.164062 (1.454 sec)
10.819... logprob:  0.498240, 0.140625 (1.454 sec)
10.820... logprob:  0.421460, 0.109375 (1.453 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.280033111572266, 10.0]}, 128)
batch 872: ({'logprob': [66.20039367675781, 19.0]}, 128)
batch 873: ({'logprob': [41.76179885864258, 9.0]}, 128)
batch 874: ({'logprob': [46.28886795043945, 11.0]}, 128)
batch 875: ({'logprob': [51.40424346923828, 13.0]}, 128)
batch 876: ({'logprob': [63.800106048583984, 18.0]}, 128)
batch 877: ({'logprob': [46.58768844604492, 11.0]}, 128)
batch 878: ({'logprob': [61.663089752197266, 17.0]}, 128)
batch 879: ({'logprob': [72.19209289550781, 21.0]}, 128)
batch 880: ({'logprob': [51.417213439941406, 13.0]}, 128)
batch 881: ({'logprob': [31.20549964904785, 5.0]}, 128)
batch 882: ({'logprob': [54.7075080871582, 14.0]}, 128)
batch 883: ({'logprob': [61.65189743041992, 17.0]}, 128)
batch 884: ({'logprob': [51.692848205566406, 13.0]}, 128)
batch 885: ({'logprob': [52.28133010864258, 13.0]}, 128)
batch 886: ({'logprob': [61.94933319091797, 17.0]}, 128)

======================Test output======================
logprob:  0.418986, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.972910e-03 [2.722195e-09] 
Layer 'conv1' biases: 8.421047e-08 [8.554337e-11] 
Layer 'conv2' weights[0]: 7.959875e-03 [1.979625e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.798357e-10] 
Layer 'conv3' weights[0]: 7.958177e-03 [2.003517e-09] 
Layer 'conv3' biases: 7.624249e-07 [1.141626e-09] 
Layer 'conv4' weights[0]: 7.990760e-03 [2.211019e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.138010e-08] 
Layer 'conv5' weights[0]: 7.989657e-03 [7.865448e-08] 
Layer 'conv5' biases: 9.999992e-01 [8.558762e-08] 
Layer 'fc6' weights[0]: 7.586431e-03 [6.718760e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.820577e-09] 
Layer 'fc7' weights[0]: 7.519669e-03 [1.925787e-07] 
Layer 'fc7' biases: 9.998667e-01 [1.801741e-07] 
Layer 'fc8' weights[0]: 1.282527e-03 [6.296298e-06] 
Layer 'fc8' biases: 2.256631e-02 [4.726777e-05] 
Train error last 870 batches: 0.435293
-------------------------------------------------------
Not saving because 0.418986 > 0.415712 (4.190: -0.00%)
======================================================= (12.037 sec)
10.821... logprob:  0.406256, 0.101562 (1.507 sec)
10.822... logprob:  0.440986, 0.117188 (1.461 sec)
10.823... logprob:  0.340051, 0.078125 (1.197 sec)
10.824... logprob:  0.490247, 0.132812 (0.711 sec)
10.825... logprob:  0.286997, 0.062500 (0.689 sec)
10.826... logprob:  0.375231, 0.093750 (0.687 sec)
10.827... logprob:  0.420770, 0.109375 (0.685 sec)
10.828... logprob:  0.443907, 0.117188 (0.684 sec)
10.829... logprob:  0.505177, 0.140625 (0.689 sec)
10.830... logprob:  0.442534, 0.117188 (1.505 sec)
10.831... logprob:  0.514281, 0.140625 (1.456 sec)
10.832... logprob:  0.330890, 0.078125 (1.461 sec)
10.833... logprob:  0.488871, 0.132812 (1.486 sec)
10.834... logprob:  0.433073, 0.117188 (1.461 sec)
10.835... logprob:  0.542191, 0.148438 (1.454 sec)
10.836... logprob:  0.376526, 0.093750 (1.455 sec)
10.837... logprob:  0.315316, 0.070312 (1.449 sec)
10.838... logprob:  0.437126, 0.117188 (1.459 sec)
10.839... logprob:  0.471808, 0.125000 (1.499 sec)
10.840... logprob:  0.555084, 0.156250 (1.455 sec)
10.841... logprob:  0.396464, 0.101562 (1.467 sec)
10.842... logprob:  0.497763, 0.140625 (1.495 sec)
10.843... logprob:  0.465581, 0.125000 (1.453 sec)
10.844... logprob:  0.497588, 0.140625 (1.460 sec)
10.845... logprob:  0.486893, 0.132812 (1.448 sec)
10.846... logprob:  0.468544, 0.125000 (1.455 sec)
10.847... logprob:  0.362966, 0.085938 (1.451 sec)
10.848... logprob:  0.396852, 0.101562 (1.496 sec)
10.849... logprob:  0.360003, 0.085938 (1.458 sec)
10.850... logprob:  0.479497, 0.132812 (1.465 sec)
10.851... logprob:  0.440180, 0.117188 (1.494 sec)
10.852... logprob:  0.546267, 0.156250 (1.453 sec)
10.853... logprob:  0.371651, 0.093750 (1.465 sec)
10.854... logprob:  0.306774, 0.070312 (1.445 sec)
10.855... logprob:  0.485167, 0.132812 (1.451 sec)
10.856... logprob:  0.443974, 0.117188 (1.452 sec)
10.857... logprob:  0.372270, 0.093750 (1.497 sec)
10.858... logprob:  0.396250, 0.101562 (1.461 sec)
10.859... logprob:  0.307948, 0.070312 (1.467 sec)
10.860... logprob:  0.565888, 0.156250 (1.485 sec)
10.861... logprob:  0.417835, 0.109375 (1.461 sec)
10.862... logprob:  0.329019, 0.078125 (1.460 sec)
10.863... logprob:  0.399477, 0.101562 (1.446 sec)
10.864... logprob:  0.451322, 0.117188 (1.456 sec)
10.865... logprob:  0.484261, 0.132812 (1.463 sec)
10.866... logprob:  0.507316, 0.140625 (1.492 sec)
10.867... logprob:  0.502621, 0.140625 (1.469 sec)
10.868... logprob:  0.405523, 0.101562 (1.508 sec)
10.869... logprob:  0.383529, 0.093750 (1.481 sec)
10.870... logprob:  0.551789, 0.156250 (1.402 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.75570297241211, 10.0]}, 128)
batch 872: ({'logprob': [66.27436828613281, 19.0]}, 128)
batch 873: ({'logprob': [41.2923698425293, 9.0]}, 128)
batch 874: ({'logprob': [45.88594055175781, 11.0]}, 128)
batch 875: ({'logprob': [51.13783264160156, 13.0]}, 128)
batch 876: ({'logprob': [63.823516845703125, 18.0]}, 128)
batch 877: ({'logprob': [46.2194709777832, 11.0]}, 128)
batch 878: ({'logprob': [61.67064666748047, 17.0]}, 128)
batch 879: ({'logprob': [72.5082778930664, 21.0]}, 128)
batch 880: ({'logprob': [51.15093231201172, 13.0]}, 128)
batch 881: ({'logprob': [30.426870346069336, 5.0]}, 128)
batch 882: ({'logprob': [54.598262786865234, 14.0]}, 128)
batch 883: ({'logprob': [61.65930938720703, 17.0]}, 128)
batch 884: ({'logprob': [51.46232604980469, 13.0]}, 128)
batch 885: ({'logprob': [52.12157440185547, 13.0]}, 128)
batch 886: ({'logprob': [61.99253845214844, 17.0]}, 128)

======================Test output======================
logprob:  0.417471, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.972870e-03 [2.562857e-09] 
Layer 'conv1' biases: 8.501170e-08 [5.110446e-11] 
Layer 'conv2' weights[0]: 7.959846e-03 [1.805517e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.265722e-10] 
Layer 'conv3' weights[0]: 7.958139e-03 [1.727086e-09] 
Layer 'conv3' biases: 7.698660e-07 [1.034749e-09] 
Layer 'conv4' weights[0]: 7.990726e-03 [1.942420e-09] 
Layer 'conv4' biases: 9.999999e-01 [9.866592e-09] 
Layer 'conv5' weights[0]: 7.989607e-03 [6.799684e-08] 
Layer 'conv5' biases: 9.999996e-01 [7.373777e-08] 
Layer 'fc6' weights[0]: 7.586390e-03 [5.809071e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.905648e-09] 
Layer 'fc7' weights[0]: 7.517751e-03 [2.636606e-07] 
Layer 'fc7' biases: 9.998670e-01 [2.527407e-07] 
Layer 'fc8' weights[0]: 1.292027e-03 [9.315809e-06] 
Layer 'fc8' biases: 2.283904e-02 [5.787487e-05] 
Train error last 870 batches: 0.435293
-------------------------------------------------------
Not saving because 0.417471 > 0.415712 (4.190: -0.00%)
======================================================= (12.045 sec)
11.1... logprob:  0.380358, 0.093750 (1.411 sec)
11.2... logprob:  0.448304, 0.117188 (1.457 sec)
11.3... logprob:  0.398512, 0.101562 (1.419 sec)
11.4... logprob:  0.443389, 0.117188 (1.407 sec)
11.5... logprob:  0.443369, 0.117188 (1.429 sec)
11.6... logprob:  0.499310, 0.140625 (1.399 sec)
11.7... logprob:  0.362877, 0.085938 (1.414 sec)
11.8... logprob:  0.419076, 0.109375 (1.391 sec)
11.9... logprob:  0.358501, 0.085938 (1.408 sec)
11.10... logprob:  0.377256, 0.093750 (1.405 sec)
11.11... logprob:  0.334341, 0.078125 (1.445 sec)
11.12... logprob:  0.466694, 0.125000 (1.391 sec)
11.13... logprob:  0.442526, 0.117188 (1.420 sec)
11.14... logprob:  0.444936, 0.117188 (1.404 sec)
11.15... logprob:  0.395733, 0.101562 (1.418 sec)
11.16... logprob:  0.421524, 0.109375 (1.404 sec)
11.17... logprob:  0.516164, 0.140625 (1.398 sec)
11.18... logprob:  0.262136, 0.054688 (1.399 sec)
11.19... logprob:  0.279732, 0.062500 (1.405 sec)
11.20... logprob:  0.421385, 0.109375 (1.407 sec)
11.21... logprob:  0.443924, 0.117188 (0.889 sec)
11.22... logprob:  0.536445, 0.148438 (1.324 sec)
11.23... logprob:  0.532574, 0.148438 (1.413 sec)
11.24... logprob:  0.310962, 0.070312 (0.987 sec)
11.25... logprob:  0.356453, 0.085938 (0.960 sec)
11.26... logprob:  0.463598, 0.125000 (1.451 sec)
11.27... logprob:  0.404687, 0.101562 (1.390 sec)
11.28... logprob:  0.421896, 0.109375 (1.416 sec)
11.29... logprob:  0.396140, 0.101562 (1.423 sec)
11.30... logprob:  0.374249, 0.093750 (1.418 sec)
11.31... logprob:  0.479874, 0.132812 (1.404 sec)
11.32... logprob:  0.457247, 0.125000 (1.391 sec)
11.33... logprob:  0.460685, 0.125000 (1.457 sec)
11.34... logprob:  0.464700, 0.125000 (1.393 sec)
11.35... logprob:  0.316115, 0.070312 (1.402 sec)
11.36... logprob:  0.475820, 0.132812 (1.403 sec)
11.37... logprob:  0.417611, 0.109375 (1.406 sec)
11.38... logprob:  0.392435, 0.101562 (1.394 sec)
11.39... logprob:  0.632140, 0.187500 (1.436 sec)
11.40... logprob:  0.445918, 0.117188 (1.414 sec)
11.41... logprob:  0.352689, 0.085938 (1.426 sec)
11.42... logprob:  0.391783, 0.101562 (1.417 sec)
11.43... logprob:  0.440151, 0.117188 (1.413 sec)
11.44... logprob:  0.518476, 0.148438 (1.435 sec)
11.45... logprob:  0.381818, 0.093750 (1.394 sec)
11.46... logprob:  0.486450, 0.132812 (1.393 sec)
11.47... logprob:  0.331804, 0.078125 (1.399 sec)
11.48... logprob:  0.498855, 0.140625 (1.428 sec)
11.49... logprob:  0.510549, 0.148438 (1.414 sec)
11.50... logprob:  0.393287, 0.101562 (1.430 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.84437561035156, 10.0]}, 128)
batch 872: ({'logprob': [66.25872039794922, 19.0]}, 128)
batch 873: ({'logprob': [41.00640869140625, 9.0]}, 128)
batch 874: ({'logprob': [45.401519775390625, 11.0]}, 128)
batch 875: ({'logprob': [50.8759651184082, 13.0]}, 128)
batch 876: ({'logprob': [63.80177307128906, 18.0]}, 128)
batch 877: ({'logprob': [45.94475173950195, 11.0]}, 128)
batch 878: ({'logprob': [61.853416442871094, 17.0]}, 128)
batch 879: ({'logprob': [73.34516143798828, 21.0]}, 128)
batch 880: ({'logprob': [50.88850784301758, 13.0]}, 128)
batch 881: ({'logprob': [29.48570442199707, 5.0]}, 128)
batch 882: ({'logprob': [54.97389602661133, 14.0]}, 128)
batch 883: ({'logprob': [61.84220886230469, 17.0]}, 128)
batch 884: ({'logprob': [51.411373138427734, 13.0]}, 128)
batch 885: ({'logprob': [52.49190139770508, 13.0]}, 128)
batch 886: ({'logprob': [62.386234283447266, 17.0]}, 128)

======================Test output======================
logprob:  0.416900, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.972827e-03 [2.089763e-09] 
Layer 'conv1' biases: 8.574420e-08 [3.689687e-11] 
Layer 'conv2' weights[0]: 7.959807e-03 [1.614632e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.545181e-10] 
Layer 'conv3' weights[0]: 7.958096e-03 [1.237474e-09] 
Layer 'conv3' biases: 7.751053e-07 [4.297089e-10] 
Layer 'conv4' weights[0]: 7.990690e-03 [1.207563e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.897171e-09] 
Layer 'conv5' weights[0]: 7.989579e-03 [9.560702e-09] 
Layer 'conv5' biases: 9.999993e-01 [9.726345e-09] 
Layer 'fc6' weights[0]: 7.586353e-03 [1.101203e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.569960e-10] 
Layer 'fc7' weights[0]: 7.515836e-03 [4.801699e-08] 
Layer 'fc7' biases: 9.998674e-01 [2.414248e-08] 
Layer 'fc8' weights[0]: 1.308777e-03 [6.517976e-06] 
Layer 'fc8' biases: 2.303828e-02 [4.086109e-05] 
Train error last 870 batches: 0.435292
-------------------------------------------------------
Not saving because 0.416900 > 0.415712 (4.190: -0.00%)
======================================================= (12.163 sec)
11.51... logprob:  0.489916, 0.140625 (1.421 sec)
11.52... logprob:  0.525777, 0.148438 (1.410 sec)
11.53... logprob:  0.295141, 0.062500 (1.449 sec)
11.54... logprob:  0.403201, 0.109375 (1.393 sec)
11.55... logprob:  0.331833, 0.078125 (1.397 sec)
11.56... logprob:  0.421748, 0.109375 (1.408 sec)
11.57... logprob:  0.572628, 0.164062 (1.427 sec)
11.58... logprob:  0.407849, 0.101562 (1.403 sec)
11.59... logprob:  0.333837, 0.078125 (1.469 sec)
11.60... logprob:  0.619175, 0.179688 (1.418 sec)
11.61... logprob:  0.382883, 0.093750 (1.432 sec)
11.62... logprob:  0.474944, 0.132812 (1.456 sec)
11.63... logprob:  0.397319, 0.101562 (1.438 sec)
11.64... logprob:  0.450251, 0.125000 (1.410 sec)
11.65... logprob:  0.373294, 0.093750 (1.403 sec)
11.66... logprob:  0.353986, 0.085938 (1.465 sec)
11.67... logprob:  0.295372, 0.062500 (1.389 sec)
11.68... logprob:  0.396834, 0.101562 (1.397 sec)
11.69... logprob:  0.496899, 0.140625 (1.425 sec)
11.70... logprob:  0.325876, 0.078125 (1.438 sec)
11.71... logprob:  0.381861, 0.101562 (1.463 sec)
11.72... logprob:  0.493900, 0.132812 (1.405 sec)
11.73... logprob:  0.447813, 0.117188 (1.423 sec)
11.74... logprob:  0.442625, 0.117188 (1.422 sec)
11.75... logprob:  0.380642, 0.093750 (1.413 sec)
11.76... logprob:  0.412105, 0.109375 (1.439 sec)
11.77... logprob:  0.396348, 0.101562 (1.429 sec)
11.78... logprob:  0.493075, 0.140625 (1.459 sec)
11.79... logprob:  0.456432, 0.125000 (1.410 sec)
11.80... logprob:  0.507825, 0.132812 (1.424 sec)
11.81... logprob:  0.416723, 0.109375 (1.413 sec)
11.82... logprob:  0.232023, 0.039062 (1.426 sec)
11.83... logprob:  0.493686, 0.140625 (1.403 sec)
11.84... logprob:  0.468064, 0.125000 (1.472 sec)
11.85... logprob:  0.432077, 0.117188 (1.422 sec)
11.86... logprob:  0.417023, 0.109375 (1.422 sec)
11.87... logprob:  0.633164, 0.187500 (1.415 sec)
11.88... logprob:  0.535145, 0.156250 (1.412 sec)
11.89... logprob:  0.410658, 0.109375 (1.437 sec)
11.90... logprob:  0.577535, 0.171875 (1.389 sec)
11.91... logprob:  0.348595, 0.078125 (1.396 sec)
11.92... logprob:  0.464460, 0.125000 (1.403 sec)
11.93... logprob:  0.492315, 0.140625 (1.405 sec)
11.94... logprob:  0.428786, 0.109375 (1.394 sec)
11.95... logprob:  0.471875, 0.125000 (1.407 sec)
11.96... logprob:  0.576428, 0.171875 (1.406 sec)
11.97... logprob:  0.430744, 0.117188 (1.396 sec)
11.98... logprob:  0.390961, 0.093750 (1.436 sec)
11.99... logprob:  0.474364, 0.132812 (1.411 sec)
11.100... logprob:  0.310262, 0.070312 (1.400 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.20815658569336, 10.0]}, 128)
batch 872: ({'logprob': [66.15096282958984, 19.0]}, 128)
batch 873: ({'logprob': [41.22146224975586, 9.0]}, 128)
batch 874: ({'logprob': [45.62202453613281, 11.0]}, 128)
batch 875: ({'logprob': [50.985294342041016, 13.0]}, 128)
batch 876: ({'logprob': [63.720481872558594, 18.0]}, 128)
batch 877: ({'logprob': [46.10730743408203, 11.0]}, 128)
batch 878: ({'logprob': [61.74022674560547, 17.0]}, 128)
batch 879: ({'logprob': [72.95143127441406, 21.0]}, 128)
batch 880: ({'logprob': [50.99793243408203, 13.0]}, 128)
batch 881: ({'logprob': [29.98175048828125, 5.0]}, 128)
batch 882: ({'logprob': [54.88138961791992, 14.0]}, 128)
batch 883: ({'logprob': [61.72896194458008, 17.0]}, 128)
batch 884: ({'logprob': [51.46200180053711, 13.0]}, 128)
batch 885: ({'logprob': [52.425418853759766, 13.0]}, 128)
batch 886: ({'logprob': [62.2143440246582, 17.0]}, 128)

======================Test output======================
logprob:  0.417187, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.972780e-03 [3.568400e-09] 
Layer 'conv1' biases: 8.639363e-08 [1.131341e-10] 
Layer 'conv2' weights[0]: 7.959769e-03 [3.575887e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.260465e-10] 
Layer 'conv3' weights[0]: 7.958062e-03 [3.606843e-09] 
Layer 'conv3' biases: 7.793212e-07 [2.258852e-09] 
Layer 'conv4' weights[0]: 7.990650e-03 [4.142695e-09] 
Layer 'conv4' biases: 9.999999e-01 [2.312141e-08] 
Layer 'conv5' weights[0]: 7.989548e-03 [1.588387e-07] 
Layer 'conv5' biases: 9.999990e-01 [1.727107e-07] 
Layer 'fc6' weights[0]: 7.586313e-03 [1.357380e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.386201e-08] 
Layer 'fc7' weights[0]: 7.513890e-03 [3.011590e-07] 
Layer 'fc7' biases: 9.998673e-01 [2.892887e-07] 
Layer 'fc8' weights[0]: 1.300579e-03 [1.095426e-05] 
Layer 'fc8' biases: 2.305240e-02 [7.236747e-05] 
Train error last 870 batches: 0.435292
-------------------------------------------------------
Not saving because 0.417187 > 0.415712 (4.190: -0.00%)
======================================================= (12.015 sec)
11.101... logprob:  0.310389, 0.062500 (1.457 sec)
11.102... logprob:  0.546555, 0.156250 (1.403 sec)
11.103... logprob:  0.541520, 0.156250 (1.402 sec)
11.104... logprob:  0.388902, 0.101562 (1.409 sec)
11.105... logprob:  0.620025, 0.179688 (1.396 sec)
11.106... logprob:  0.344419, 0.085938 (1.403 sec)
11.107... logprob:  0.335669, 0.078125 (1.435 sec)
11.108... logprob:  0.586777, 0.171875 (1.402 sec)
11.109... logprob:  0.336250, 0.078125 (1.407 sec)
11.110... logprob:  0.564325, 0.164062 (1.399 sec)
11.111... logprob:  0.404771, 0.101562 (1.399 sec)
11.112... logprob:  0.366280, 0.093750 (1.397 sec)
11.113... logprob:  0.354786, 0.085938 (1.405 sec)
11.114... logprob:  0.440247, 0.117188 (1.431 sec)
11.115... logprob:  0.506713, 0.140625 (1.412 sec)
11.116... logprob:  0.393435, 0.101562 (1.403 sec)
11.117... logprob:  0.440399, 0.117188 (1.445 sec)
11.118... logprob:  0.409212, 0.101562 (1.392 sec)
11.119... logprob:  0.346153, 0.085938 (1.398 sec)
11.120... logprob:  0.547175, 0.156250 (1.404 sec)
11.121... logprob:  0.412722, 0.109375 (1.400 sec)
11.122... logprob:  0.519422, 0.148438 (1.441 sec)
11.123... logprob:  0.463789, 0.125000 (1.388 sec)
11.124... logprob:  0.447730, 0.125000 (1.411 sec)
11.125... logprob:  0.502053, 0.140625 (1.397 sec)
11.126... logprob:  0.475841, 0.125000 (1.394 sec)
11.127... logprob:  0.479685, 0.125000 (1.399 sec)
11.128... logprob:  0.422406, 0.109375 (1.422 sec)
11.129... logprob:  0.574899, 0.164062 (1.421 sec)
11.130... logprob:  0.382784, 0.093750 (1.414 sec)
11.131... logprob:  0.495509, 0.132812 (1.412 sec)
11.132... logprob:  0.506402, 0.140625 (1.438 sec)
11.133... logprob:  0.444689, 0.117188 (1.389 sec)
11.134... logprob:  0.401941, 0.101562 (1.399 sec)
11.135... logprob:  0.460268, 0.125000 (1.399 sec)
11.136... logprob:  0.562665, 0.164062 (1.402 sec)
11.137... logprob:  0.462560, 0.125000 (1.395 sec)
11.138... logprob:  0.319313, 0.070312 (1.457 sec)
11.139... logprob:  0.395802, 0.101562 (1.401 sec)
11.140... logprob:  0.560684, 0.164062 (1.414 sec)
11.141... logprob:  0.464524, 0.125000 (1.443 sec)
11.142... logprob:  0.464600, 0.125000 (1.418 sec)
11.143... logprob:  0.294201, 0.062500 (1.425 sec)
11.144... logprob:  0.457413, 0.125000 (1.421 sec)
11.145... logprob:  0.324932, 0.078125 (1.424 sec)
11.146... logprob:  0.483299, 0.132812 (1.419 sec)
11.147... logprob:  0.262470, 0.054688 (1.432 sec)
11.148... logprob:  0.458918, 0.125000 (1.391 sec)
11.149... logprob:  0.442593, 0.117188 (1.397 sec)
11.150... logprob:  0.347654, 0.085938 (1.407 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.2680778503418, 10.0]}, 128)
batch 872: ({'logprob': [67.91088104248047, 19.0]}, 128)
batch 873: ({'logprob': [39.59832763671875, 9.0]}, 128)
batch 874: ({'logprob': [44.80949020385742, 11.0]}, 128)
batch 875: ({'logprob': [50.75808334350586, 13.0]}, 128)
batch 876: ({'logprob': [65.13275909423828, 18.0]}, 128)
batch 877: ({'logprob': [45.1812858581543, 11.0]}, 128)
batch 878: ({'logprob': [62.68962097167969, 17.0]}, 128)
batch 879: ({'logprob': [74.9649887084961, 21.0]}, 128)
batch 880: ({'logprob': [50.77207946777344, 13.0]}, 128)
batch 881: ({'logprob': [27.292882919311523, 5.0]}, 128)
batch 882: ({'logprob': [54.67314910888672, 14.0]}, 128)
batch 883: ({'logprob': [62.67797088623047, 17.0]}, 128)
batch 884: ({'logprob': [51.12687301635742, 13.0]}, 128)
batch 885: ({'logprob': [51.868980407714844, 13.0]}, 128)
batch 886: ({'logprob': [63.05439758300781, 17.0]}, 128)

======================Test output======================
logprob:  0.416885, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.972732e-03 [2.253738e-09] 
Layer 'conv1' biases: 8.702723e-08 [3.855496e-11] 
Layer 'conv2' weights[0]: 7.959733e-03 [1.428334e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.510987e-10] 
Layer 'conv3' weights[0]: 7.958023e-03 [1.138002e-09] 
Layer 'conv3' biases: 7.844825e-07 [3.921552e-10] 
Layer 'conv4' weights[0]: 7.990608e-03 [1.108833e-09] 
Layer 'conv4' biases: 9.999999e-01 [2.011690e-09] 
Layer 'conv5' weights[0]: 7.989500e-03 [8.996676e-09] 
Layer 'conv5' biases: 9.999991e-01 [9.082474e-09] 
Layer 'fc6' weights[0]: 7.586281e-03 [1.033725e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.639718e-10] 
Layer 'fc7' weights[0]: 7.511955e-03 [1.237314e-07] 
Layer 'fc7' biases: 9.998685e-01 [1.091451e-07] 
Layer 'fc8' weights[0]: 1.358558e-03 [9.229266e-06] 
Layer 'fc8' biases: 2.352774e-02 [5.770350e-05] 
Train error last 870 batches: 0.435292
-------------------------------------------------------
Not saving because 0.416885 > 0.415712 (4.190: -0.00%)
======================================================= (12.108 sec)
11.151... logprob:  0.347161, 0.085938 (1.407 sec)
11.152... logprob:  0.784950, 0.234375 (1.392 sec)
11.153... logprob:  0.381679, 0.093750 (1.440 sec)
11.154... logprob:  0.524264, 0.148438 (1.404 sec)
11.155... logprob:  0.425936, 0.117188 (1.412 sec)
11.156... logprob:  0.296168, 0.062500 (1.434 sec)
11.157... logprob:  0.271081, 0.054688 (1.398 sec)
11.158... logprob:  0.455347, 0.125000 (1.402 sec)
11.159... logprob:  0.483120, 0.132812 (1.403 sec)
11.160... logprob:  0.444964, 0.117188 (1.474 sec)
11.161... logprob:  0.350319, 0.078125 (1.403 sec)
11.162... logprob:  0.611819, 0.179688 (1.406 sec)
11.163... logprob:  0.450415, 0.125000 (1.431 sec)
11.164... logprob:  0.468755, 0.125000 (1.417 sec)
11.165... logprob:  0.548043, 0.156250 (1.421 sec)
11.166... logprob:  0.446039, 0.125000 (1.451 sec)
11.167... logprob:  0.350328, 0.085938 (1.432 sec)
11.168... logprob:  0.363637, 0.085938 (1.422 sec)
11.169... logprob:  0.408705, 0.101562 (1.464 sec)
11.170... logprob:  0.459509, 0.125000 (1.405 sec)
11.171... logprob:  0.535572, 0.156250 (1.429 sec)
11.172... logprob:  0.434896, 0.109375 (1.416 sec)
11.173... logprob:  0.440513, 0.117188 (1.426 sec)
11.174... logprob:  0.601325, 0.171875 (1.403 sec)
11.175... logprob:  0.506190, 0.140625 (1.467 sec)
11.176... logprob:  0.478534, 0.132812 (1.421 sec)
11.177... logprob:  0.289806, 0.054688 (1.430 sec)
11.178... logprob:  0.383503, 0.093750 (1.455 sec)
11.179... logprob:  0.394761, 0.101562 (1.416 sec)
11.180... logprob:  0.466380, 0.125000 (1.425 sec)
11.181... logprob:  0.539452, 0.156250 (1.422 sec)
11.182... logprob:  0.371457, 0.093750 (1.418 sec)
11.183... logprob:  0.419975, 0.109375 (1.418 sec)
11.184... logprob:  0.483499, 0.132812 (1.426 sec)
11.185... logprob:  0.289925, 0.062500 (1.395 sec)
11.186... logprob:  0.370568, 0.093750 (1.396 sec)
11.187... logprob:  0.529641, 0.148438 (1.411 sec)
11.188... logprob:  0.459039, 0.125000 (1.408 sec)
11.189... logprob:  0.440903, 0.117188 (1.407 sec)
11.190... logprob:  0.375724, 0.093750 (1.454 sec)
11.191... logprob:  0.485112, 0.132812 (1.423 sec)
11.192... logprob:  0.520225, 0.148438 (1.426 sec)
11.193... logprob:  0.312670, 0.070312 (1.428 sec)
11.194... logprob:  0.414134, 0.109375 (1.418 sec)
11.195... logprob:  0.287308, 0.062500 (1.398 sec)
11.196... logprob:  0.410588, 0.109375 (1.400 sec)
11.197... logprob:  0.478047, 0.132812 (1.408 sec)
11.198... logprob:  0.355792, 0.085938 (1.411 sec)
11.199... logprob:  0.437195, 0.117188 (1.398 sec)
11.200... logprob:  0.440793, 0.117188 (1.446 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.390342712402344, 10.0]}, 128)
batch 872: ({'logprob': [66.89927673339844, 19.0]}, 128)
batch 873: ({'logprob': [40.27080154418945, 9.0]}, 128)
batch 874: ({'logprob': [44.99702835083008, 11.0]}, 128)
batch 875: ({'logprob': [50.70850372314453, 13.0]}, 128)
batch 876: ({'logprob': [64.30103302001953, 18.0]}, 128)
batch 877: ({'logprob': [45.49296569824219, 11.0]}, 128)
batch 878: ({'logprob': [62.162841796875, 17.0]}, 128)
batch 879: ({'logprob': [74.08413696289062, 21.0]}, 128)
batch 880: ({'logprob': [50.721824645996094, 13.0]}, 128)
batch 881: ({'logprob': [28.319604873657227, 5.0]}, 128)
batch 882: ({'logprob': [54.81079864501953, 14.0]}, 128)
batch 883: ({'logprob': [62.15127944946289, 17.0]}, 128)
batch 884: ({'logprob': [51.198951721191406, 13.0]}, 128)
batch 885: ({'logprob': [52.186805725097656, 13.0]}, 128)
batch 886: ({'logprob': [62.649898529052734, 17.0]}, 128)

======================Test output======================
logprob:  0.416185, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.972695e-03 [3.119509e-09] 
Layer 'conv1' biases: 8.782887e-08 [8.789671e-11] 
Layer 'conv2' weights[0]: 7.959691e-03 [2.025493e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.496411e-10] 
Layer 'conv3' weights[0]: 7.957985e-03 [1.503704e-09] 
Layer 'conv3' biases: 7.912968e-07 [6.306493e-10] 
Layer 'conv4' weights[0]: 7.990571e-03 [1.512630e-09] 
Layer 'conv4' biases: 9.999999e-01 [3.852681e-09] 
Layer 'conv5' weights[0]: 7.989463e-03 [2.587272e-08] 
Layer 'conv5' biases: 9.999992e-01 [2.798012e-08] 
Layer 'fc6' weights[0]: 7.586240e-03 [2.427207e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.291565e-09] 
Layer 'fc7' weights[0]: 7.510048e-03 [5.438972e-08] 
Layer 'fc7' biases: 9.998676e-01 [3.250617e-08] 
Layer 'fc8' weights[0]: 1.340343e-03 [5.077203e-06] 
Layer 'fc8' biases: 2.350671e-02 [3.219717e-05] 
Train error last 870 batches: 0.435291
-------------------------------------------------------
Not saving because 0.416185 > 0.415712 (4.190: -0.00%)
======================================================= (12.333 sec)
11.201... logprob:  0.437104, 0.117188 (1.429 sec)
11.202... logprob:  0.538022, 0.148438 (1.417 sec)
11.203... logprob:  0.420483, 0.109375 (1.454 sec)
11.204... logprob:  0.504130, 0.140625 (1.410 sec)
11.205... logprob:  0.334429, 0.078125 (1.419 sec)
11.206... logprob:  0.361636, 0.093750 (1.418 sec)
11.207... logprob:  0.381956, 0.093750 (1.411 sec)
11.208... logprob:  0.490505, 0.140625 (1.410 sec)
11.209... logprob:  0.334625, 0.078125 (1.462 sec)
11.210... logprob:  0.586262, 0.171875 (1.428 sec)
11.211... logprob:  0.488219, 0.132812 (1.423 sec)
11.212... logprob:  0.526166, 0.148438 (1.429 sec)
11.213... logprob:  0.514878, 0.140625 (1.464 sec)
11.214... logprob:  0.459456, 0.125000 (1.434 sec)
11.215... logprob:  0.396169, 0.101562 (1.431 sec)
11.216... logprob:  0.517177, 0.140625 (1.475 sec)
11.217... logprob:  0.325187, 0.070312 (1.408 sec)
11.218... logprob:  0.463742, 0.125000 (1.425 sec)
11.219... logprob:  0.500344, 0.140625 (1.414 sec)
11.220... logprob:  0.414990, 0.109375 (1.426 sec)
11.221... logprob:  0.399534, 0.101562 (1.415 sec)
11.222... logprob:  0.554642, 0.164062 (1.463 sec)
11.223... logprob:  0.569347, 0.164062 (1.436 sec)
11.224... logprob:  0.405843, 0.101562 (1.441 sec)
11.225... logprob:  0.391962, 0.101562 (1.452 sec)
11.226... logprob:  0.424600, 0.109375 (1.429 sec)
11.227... logprob:  0.452779, 0.125000 (1.420 sec)
11.228... logprob:  0.417216, 0.109375 (1.415 sec)
11.229... logprob:  0.489371, 0.132812 (1.420 sec)
11.230... logprob:  0.459915, 0.125000 (1.429 sec)
11.231... logprob:  0.453560, 0.125000 (1.410 sec)
11.232... logprob:  0.496246, 0.140625 (1.460 sec)
11.233... logprob:  0.466198, 0.132812 (1.427 sec)
11.234... logprob:  0.563779, 0.164062 (1.420 sec)
11.235... logprob:  0.482043, 0.132812 (1.479 sec)
11.236... logprob:  0.425850, 0.109375 (1.408 sec)
11.237... logprob:  0.341470, 0.078125 (1.429 sec)
11.238... logprob:  0.389468, 0.093750 (1.422 sec)
11.239... logprob:  0.478170, 0.132812 (1.423 sec)
11.240... logprob:  0.485817, 0.132812 (1.404 sec)
11.241... logprob:  0.493613, 0.132812 (1.452 sec)
11.242... logprob:  0.341654, 0.078125 (1.437 sec)
11.243... logprob:  0.386028, 0.093750 (1.436 sec)
11.244... logprob:  0.315161, 0.070312 (1.450 sec)
11.245... logprob:  0.494407, 0.132812 (1.432 sec)
11.246... logprob:  0.416933, 0.109375 (1.417 sec)
11.247... logprob:  0.357296, 0.085938 (1.415 sec)
11.248... logprob:  0.307658, 0.070312 (1.418 sec)
11.249... logprob:  0.555732, 0.156250 (1.435 sec)
11.250... logprob:  0.591935, 0.164062 (1.402 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.42894744873047, 10.0]}, 128)
batch 872: ({'logprob': [67.91063690185547, 19.0]}, 128)
batch 873: ({'logprob': [39.573612213134766, 9.0]}, 128)
batch 874: ({'logprob': [44.860504150390625, 11.0]}, 128)
batch 875: ({'logprob': [50.7665901184082, 13.0]}, 128)
batch 876: ({'logprob': [65.12439727783203, 18.0]}, 128)
batch 877: ({'logprob': [45.17342758178711, 11.0]}, 128)
batch 878: ({'logprob': [62.61366271972656, 17.0]}, 128)
batch 879: ({'logprob': [74.74528503417969, 21.0]}, 128)
batch 880: ({'logprob': [50.78105545043945, 13.0]}, 128)
batch 881: ({'logprob': [27.411813735961914, 5.0]}, 128)
batch 882: ({'logprob': [54.512977600097656, 14.0]}, 128)
batch 883: ({'logprob': [62.60171890258789, 17.0]}, 128)
batch 884: ({'logprob': [51.07639694213867, 13.0]}, 128)
batch 885: ({'logprob': [51.70022201538086, 13.0]}, 128)
batch 886: ({'logprob': [62.91925811767578, 17.0]}, 128)

======================Test output======================
logprob:  0.416602, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.972655e-03 [6.533958e-09] 
Layer 'conv1' biases: 8.856335e-08 [1.549369e-10] 
Layer 'conv2' weights[0]: 7.959647e-03 [5.043912e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.011709e-09] 
Layer 'conv3' weights[0]: 7.957941e-03 [4.701664e-09] 
Layer 'conv3' biases: 7.968032e-07 [3.234196e-09] 
Layer 'conv4' weights[0]: 7.990534e-03 [5.307495e-09] 
Layer 'conv4' biases: 9.999999e-01 [3.178676e-08] 
Layer 'conv5' weights[0]: 7.989427e-03 [2.181277e-07] 
Layer 'conv5' biases: 9.999993e-01 [2.369482e-07] 
Layer 'fc6' weights[0]: 7.586200e-03 [1.907113e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.925846e-08] 
Layer 'fc7' weights[0]: 7.508132e-03 [1.861142e-07] 
Layer 'fc7' biases: 9.998680e-01 [1.750192e-07] 
Layer 'fc8' weights[0]: 1.363712e-03 [9.652754e-06] 
Layer 'fc8' biases: 2.373792e-02 [5.914154e-05] 
Train error last 870 batches: 0.435291
-------------------------------------------------------
Not saving because 0.416602 > 0.415712 (4.190: -0.00%)
======================================================= (12.057 sec)
11.251... logprob:  0.352890, 0.085938 (1.474 sec)
11.252... logprob:  0.348508, 0.085938 (1.436 sec)
11.253... logprob:  0.379168, 0.093750 (1.423 sec)
11.254... logprob:  0.444188, 0.117188 (1.471 sec)
11.255... logprob:  0.351549, 0.085938 (1.404 sec)
11.256... logprob:  0.378722, 0.093750 (1.422 sec)
11.257... logprob:  0.332081, 0.078125 (1.422 sec)
11.258... logprob:  0.415833, 0.109375 (1.417 sec)
11.259... logprob:  0.442309, 0.117188 (1.403 sec)
11.260... logprob:  0.308461, 0.070312 (1.465 sec)
11.261... logprob:  0.392877, 0.101562 (1.428 sec)
11.262... logprob:  0.524699, 0.148438 (1.425 sec)
11.263... logprob:  0.425454, 0.109375 (1.450 sec)
11.264... logprob:  0.375199, 0.093750 (1.426 sec)
11.265... logprob:  0.439616, 0.117188 (1.416 sec)
11.266... logprob:  0.439053, 0.117188 (1.419 sec)
11.267... logprob:  0.421999, 0.109375 (1.422 sec)
11.268... logprob:  0.458952, 0.125000 (1.418 sec)
11.269... logprob:  0.567446, 0.164062 (1.409 sec)
11.270... logprob:  0.542179, 0.156250 (1.460 sec)
11.271... logprob:  0.445797, 0.117188 (1.431 sec)
11.272... logprob:  0.384817, 0.093750 (1.418 sec)
11.273... logprob:  0.500216, 0.140625 (1.470 sec)
11.274... logprob:  0.542548, 0.156250 (1.399 sec)
11.275... logprob:  0.487784, 0.132812 (1.428 sec)
11.276... logprob:  0.390224, 0.093750 (1.414 sec)
11.277... logprob:  0.428759, 0.109375 (1.426 sec)
11.278... logprob:  0.323329, 0.070312 (1.421 sec)
11.279... logprob:  0.324876, 0.070312 (1.468 sec)
11.280... logprob:  0.214912, 0.031250 (1.404 sec)
11.281... logprob:  0.417215, 0.109375 (1.421 sec)
11.282... logprob:  0.411525, 0.109375 (1.425 sec)
11.283... logprob:  0.393906, 0.101562 (1.413 sec)
11.284... logprob:  0.394801, 0.101562 (1.452 sec)
11.285... logprob:  0.452396, 0.117188 (1.446 sec)
11.286... logprob:  0.537851, 0.140625 (1.441 sec)
11.287... logprob:  0.346729, 0.085938 (1.431 sec)
11.288... logprob:  0.329992, 0.078125 (1.438 sec)
11.289... logprob:  0.446091, 0.117188 (1.441 sec)
11.290... logprob:  0.490648, 0.132812 (1.413 sec)
11.291... logprob:  0.439104, 0.117188 (1.417 sec)
11.292... logprob:  0.566816, 0.156250 (1.417 sec)
11.293... logprob:  0.427424, 0.117188 (1.426 sec)
11.294... logprob:  0.356348, 0.085938 (1.404 sec)
11.295... logprob:  0.335385, 0.078125 (1.473 sec)
11.296... logprob:  0.356447, 0.085938 (1.422 sec)
11.297... logprob:  0.394969, 0.101562 (1.420 sec)
11.298... logprob:  0.448076, 0.125000 (1.468 sec)
11.299... logprob:  0.342842, 0.078125 (1.400 sec)
11.300... logprob:  0.406784, 0.101562 (1.430 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.01448059082031, 10.0]}, 128)
batch 872: ({'logprob': [66.17284393310547, 19.0]}, 128)
batch 873: ({'logprob': [41.15127944946289, 9.0]}, 128)
batch 874: ({'logprob': [45.51884841918945, 11.0]}, 128)
batch 875: ({'logprob': [50.93470001220703, 13.0]}, 128)
batch 876: ({'logprob': [63.737640380859375, 18.0]}, 128)
batch 877: ({'logprob': [46.04682540893555, 11.0]}, 128)
batch 878: ({'logprob': [61.79515838623047, 17.0]}, 128)
batch 879: ({'logprob': [73.1539306640625, 21.0]}, 128)
batch 880: ({'logprob': [50.947509765625, 13.0]}, 128)
batch 881: ({'logprob': [29.763429641723633, 5.0]}, 128)
batch 882: ({'logprob': [54.96429443359375, 14.0]}, 128)
batch 883: ({'logprob': [61.783626556396484, 17.0]}, 128)
batch 884: ({'logprob': [51.454437255859375, 13.0]}, 128)
batch 885: ({'logprob': [52.5034294128418, 13.0]}, 128)
batch 886: ({'logprob': [62.312103271484375, 17.0]}, 128)

======================Test output======================
logprob:  0.417116, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.972617e-03 [3.063439e-09] 
Layer 'conv1' biases: 8.939699e-08 [7.478539e-11] 
Layer 'conv2' weights[0]: 7.959611e-03 [3.276359e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.232641e-10] 
Layer 'conv3' weights[0]: 7.957900e-03 [3.031700e-09] 
Layer 'conv3' biases: 8.029767e-07 [1.689292e-09] 
Layer 'conv4' weights[0]: 7.990493e-03 [3.341837e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.602275e-08] 
Layer 'conv5' weights[0]: 7.989382e-03 [1.074140e-07] 
Layer 'conv5' biases: 9.999992e-01 [1.163941e-07] 
Layer 'fc6' weights[0]: 7.586159e-03 [9.397335e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.438245e-09] 
Layer 'fc7' weights[0]: 7.506258e-03 [1.732611e-07] 
Layer 'fc7' biases: 9.998671e-01 [1.607448e-07] 
Layer 'fc8' weights[0]: 1.312950e-03 [5.719757e-06] 
Layer 'fc8' biases: 2.366870e-02 [4.391816e-05] 
Train error last 870 batches: 0.435290
-------------------------------------------------------
Not saving because 0.417116 > 0.415712 (4.190: -0.00%)
======================================================= (12.015 sec)
11.301... logprob:  0.397983, 0.101562 (1.420 sec)
11.302... logprob:  0.591581, 0.179688 (1.419 sec)
11.303... logprob:  0.459694, 0.125000 (1.408 sec)
11.304... logprob:  0.459749, 0.125000 (1.439 sec)
11.305... logprob:  0.455262, 0.125000 (1.443 sec)
11.306... logprob:  0.440627, 0.117188 (1.436 sec)
11.307... logprob:  0.421593, 0.109375 (1.439 sec)
11.308... logprob:  0.374472, 0.093750 (1.451 sec)
11.309... logprob:  0.450502, 0.125000 (1.434 sec)
11.310... logprob:  0.473814, 0.125000 (1.424 sec)
11.311... logprob:  0.502727, 0.140625 (1.434 sec)
11.312... logprob:  0.478840, 0.132812 (1.423 sec)
11.313... logprob:  0.454879, 0.125000 (1.424 sec)
11.314... logprob:  0.454567, 0.117188 (1.467 sec)
11.315... logprob:  0.314716, 0.070312 (1.434 sec)
11.316... logprob:  0.468603, 0.125000 (1.426 sec)
11.317... logprob:  0.355569, 0.085938 (1.509 sec)
11.318... logprob:  0.455427, 0.125000 (1.419 sec)
11.319... logprob:  0.423229, 0.117188 (1.423 sec)
11.320... logprob:  0.412276, 0.109375 (1.422 sec)
11.321... logprob:  0.348314, 0.085938 (1.422 sec)
11.322... logprob:  0.387558, 0.101562 (1.416 sec)
11.323... logprob:  0.416534, 0.109375 (1.475 sec)
11.324... logprob:  0.498657, 0.140625 (1.430 sec)
11.325... logprob:  0.350683, 0.085938 (1.439 sec)
11.326... logprob:  0.543211, 0.148438 (1.470 sec)
11.327... logprob:  0.554419, 0.164062 (1.421 sec)
11.328... logprob:  0.564995, 0.156250 (1.430 sec)
11.329... logprob:  0.402032, 0.101562 (1.423 sec)
11.330... logprob:  0.388722, 0.101562 (1.420 sec)
11.331... logprob:  0.352626, 0.085938 (1.419 sec)
11.332... logprob:  0.482801, 0.132812 (1.454 sec)
11.333... logprob:  0.339690, 0.085938 (1.444 sec)
11.334... logprob:  0.565057, 0.171875 (1.441 sec)
11.335... logprob:  0.358925, 0.085938 (1.444 sec)
11.336... logprob:  0.444825, 0.125000 (1.459 sec)
11.337... logprob:  0.566507, 0.164062 (1.412 sec)
11.338... logprob:  0.449519, 0.125000 (1.425 sec)
11.339... logprob:  0.488745, 0.132812 (1.428 sec)
11.340... logprob:  0.442082, 0.117188 (1.430 sec)
11.341... logprob:  0.530185, 0.148438 (1.416 sec)
11.342... logprob:  0.429711, 0.109375 (1.471 sec)
11.343... logprob:  0.434793, 0.109375 (1.435 sec)
11.344... logprob:  0.444393, 0.125000 (1.488 sec)
11.345... logprob:  0.488294, 0.132812 (1.439 sec)
11.346... logprob:  0.436264, 0.117188 (1.441 sec)
11.347... logprob:  0.372296, 0.085938 (1.481 sec)
11.348... logprob:  0.398434, 0.101562 (1.439 sec)
11.349... logprob:  0.497983, 0.140625 (1.432 sec)
11.350... logprob:  0.358505, 0.085938 (1.441 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.49136734008789, 10.0]}, 128)
batch 872: ({'logprob': [66.50989532470703, 19.0]}, 128)
batch 873: ({'logprob': [40.694061279296875, 9.0]}, 128)
batch 874: ({'logprob': [45.16434860229492, 11.0]}, 128)
batch 875: ({'logprob': [50.77609634399414, 13.0]}, 128)
batch 876: ({'logprob': [64.00028228759766, 18.0]}, 128)
batch 877: ({'logprob': [45.73848342895508, 11.0]}, 128)
batch 878: ({'logprob': [62.02956008911133, 17.0]}, 128)
batch 879: ({'logprob': [73.82755279541016, 21.0]}, 128)
batch 880: ({'logprob': [50.789100646972656, 13.0]}, 128)
batch 881: ({'logprob': [28.866289138793945, 5.0]}, 128)
batch 882: ({'logprob': [55.02187728881836, 14.0]}, 128)
batch 883: ({'logprob': [62.01791763305664, 17.0]}, 128)
batch 884: ({'logprob': [51.34366226196289, 13.0]}, 128)
batch 885: ({'logprob': [52.486778259277344, 13.0]}, 128)
batch 886: ({'logprob': [62.59393310546875, 17.0]}, 128)

======================Test output======================
logprob:  0.416675, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.972572e-03 [2.708434e-09] 
Layer 'conv1' biases: 9.000993e-08 [4.830656e-11] 
Layer 'conv2' weights[0]: 7.959572e-03 [1.975813e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.879982e-10] 
Layer 'conv3' weights[0]: 7.957862e-03 [1.857377e-09] 
Layer 'conv3' biases: 8.077664e-07 [9.286333e-10] 
Layer 'conv4' weights[0]: 7.990451e-03 [1.963660e-09] 
Layer 'conv4' biases: 9.999999e-01 [8.428974e-09] 
Layer 'conv5' weights[0]: 7.989350e-03 [5.570353e-08] 
Layer 'conv5' biases: 9.999991e-01 [6.033058e-08] 
Layer 'fc6' weights[0]: 7.586128e-03 [4.932055e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.915129e-09] 
Layer 'fc7' weights[0]: 7.504345e-03 [1.753080e-07] 
Layer 'fc7' biases: 9.998673e-01 [1.628437e-07] 
Layer 'fc8' weights[0]: 1.329414e-03 [1.028488e-05] 
Layer 'fc8' biases: 2.389613e-02 [6.608840e-05] 
Train error last 870 batches: 0.435290
-------------------------------------------------------
Not saving because 0.416675 > 0.415712 (4.190: -0.00%)
======================================================= (12.043 sec)
11.351... logprob:  0.508749, 0.140625 (1.437 sec)
11.352... logprob:  0.363686, 0.093750 (1.437 sec)
11.353... logprob:  0.512906, 0.148438 (1.484 sec)
11.354... logprob:  0.675255, 0.203125 (1.436 sec)
11.355... logprob:  0.357471, 0.085938 (1.449 sec)
11.356... logprob:  0.479262, 0.132812 (1.473 sec)
11.357... logprob:  0.347146, 0.085938 (1.433 sec)
11.358... logprob:  0.326129, 0.070312 (1.440 sec)
11.359... logprob:  0.555179, 0.164062 (1.438 sec)
11.360... logprob:  0.444520, 0.117188 (1.424 sec)
11.361... logprob:  0.410799, 0.101562 (1.432 sec)
11.362... logprob:  0.424199, 0.117188 (1.477 sec)
11.363... logprob:  0.486595, 0.132812 (1.451 sec)
11.364... logprob:  0.475528, 0.125000 (1.458 sec)
11.365... logprob:  0.425112, 0.109375 (1.464 sec)
11.366... logprob:  0.409741, 0.109375 (1.446 sec)
11.367... logprob:  0.325033, 0.078125 (1.443 sec)
11.368... logprob:  0.595755, 0.171875 (1.428 sec)
11.369... logprob:  0.381495, 0.093750 (1.431 sec)
11.370... logprob:  0.381123, 0.093750 (1.434 sec)
11.371... logprob:  0.400328, 0.101562 (1.455 sec)
11.372... logprob:  0.537715, 0.156250 (1.458 sec)
11.373... logprob:  0.463849, 0.125000 (1.450 sec)
11.374... logprob:  0.527172, 0.148438 (1.448 sec)
11.375... logprob:  0.393790, 0.101562 (1.461 sec)
11.376... logprob:  0.374333, 0.093750 (1.437 sec)
11.377... logprob:  0.295374, 0.062500 (1.425 sec)
11.378... logprob:  0.453799, 0.125000 (1.431 sec)
11.379... logprob:  0.420239, 0.109375 (1.440 sec)
11.380... logprob:  0.605774, 0.179688 (1.445 sec)
11.381... logprob:  0.463515, 0.125000 (1.467 sec)
11.382... logprob:  0.529476, 0.148438 (1.455 sec)
11.383... logprob:  0.358763, 0.085938 (1.438 sec)
11.384... logprob:  0.520986, 0.148438 (1.478 sec)
11.385... logprob:  0.523429, 0.148438 (1.431 sec)
11.386... logprob:  0.582258, 0.171875 (1.431 sec)
11.387... logprob:  0.428750, 0.117188 (1.436 sec)
11.388... logprob:  0.521291, 0.148438 (1.435 sec)
11.389... logprob:  0.426035, 0.109375 (1.440 sec)
11.390... logprob:  0.420023, 0.109375 (1.475 sec)
11.391... logprob:  0.318445, 0.070312 (1.440 sec)
11.392... logprob:  0.439410, 0.117188 (1.432 sec)
11.393... logprob:  0.368767, 0.093750 (1.491 sec)
11.394... logprob:  0.343383, 0.078125 (1.432 sec)
11.395... logprob:  0.331419, 0.078125 (1.436 sec)
11.396... logprob:  0.251541, 0.046875 (1.435 sec)
11.397... logprob:  0.485007, 0.132812 (1.435 sec)
11.398... logprob:  0.471769, 0.125000 (1.437 sec)
11.399... logprob:  0.433972, 0.117188 (1.483 sec)
11.400... logprob:  0.539055, 0.148438 (1.436 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.64369583129883, 10.0]}, 128)
batch 872: ({'logprob': [68.89398193359375, 19.0]}, 128)
batch 873: ({'logprob': [39.638999938964844, 9.0]}, 128)
batch 874: ({'logprob': [44.744728088378906, 11.0]}, 128)
batch 875: ({'logprob': [51.077598571777344, 13.0]}, 128)
batch 876: ({'logprob': [66.04631042480469, 18.0]}, 128)
batch 877: ({'logprob': [45.36042022705078, 11.0]}, 128)
batch 878: ({'logprob': [63.77811050415039, 17.0]}, 128)
batch 879: ({'logprob': [77.06570434570312, 21.0]}, 128)
batch 880: ({'logprob': [51.09141540527344, 13.0]}, 128)
batch 881: ({'logprob': [26.31964874267578, 5.0]}, 128)
batch 882: ({'logprob': [55.797874450683594, 14.0]}, 128)
batch 883: ({'logprob': [63.766265869140625, 17.0]}, 128)
batch 884: ({'logprob': [51.692481994628906, 13.0]}, 128)
batch 885: ({'logprob': [52.92465591430664, 13.0]}, 128)
batch 886: ({'logprob': [64.38845825195312, 17.0]}, 128)

======================Test output======================
logprob:  0.421499, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.972530e-03 [4.685139e-09] 
Layer 'conv1' biases: 9.074122e-08 [1.572330e-10] 
Layer 'conv2' weights[0]: 7.959530e-03 [4.647812e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.554617e-10] 
Layer 'conv3' weights[0]: 7.957827e-03 [4.541478e-09] 
Layer 'conv3' biases: 8.131115e-07 [3.052320e-09] 
Layer 'conv4' weights[0]: 7.990412e-03 [5.113701e-09] 
Layer 'conv4' biases: 9.999999e-01 [2.980363e-08] 
Layer 'conv5' weights[0]: 7.989291e-03 [2.005487e-07] 
Layer 'conv5' biases: 9.999988e-01 [2.172827e-07] 
Layer 'fc6' weights[0]: 7.586096e-03 [1.771673e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.792615e-08] 
Layer 'fc7' weights[0]: 7.502375e-03 [4.562797e-08] 
Layer 'fc7' biases: 9.998693e-01 [2.122483e-08] 
Layer 'fc8' weights[0]: 1.392510e-03 [5.814618e-06] 
Layer 'fc8' biases: 2.442241e-02 [2.995284e-05] 
Train error last 870 batches: 0.435290
-------------------------------------------------------
Not saving because 0.421499 > 0.415712 (4.190: -0.00%)
======================================================= (12.063 sec)
11.401... logprob:  0.466420, 0.125000 (1.446 sec)
11.402... logprob:  0.474457, 0.125000 (1.483 sec)
11.403... logprob:  0.462301, 0.125000 (1.428 sec)
11.404... logprob:  0.474826, 0.125000 (1.433 sec)
11.405... logprob:  0.543652, 0.156250 (1.432 sec)
11.406... logprob:  0.358079, 0.085938 (1.433 sec)
11.407... logprob:  0.492540, 0.140625 (1.434 sec)
11.408... logprob:  0.340159, 0.078125 (1.485 sec)
11.409... logprob:  0.401287, 0.101562 (1.436 sec)
11.410... logprob:  0.581506, 0.171875 (1.445 sec)
11.411... logprob:  0.398553, 0.101562 (1.469 sec)
11.412... logprob:  0.540165, 0.156250 (1.436 sec)
11.413... logprob:  0.544750, 0.156250 (1.444 sec)
11.414... logprob:  0.466739, 0.125000 (1.430 sec)
11.415... logprob:  0.401833, 0.101562 (1.424 sec)
11.416... logprob:  0.427583, 0.109375 (1.436 sec)
11.417... logprob:  0.405357, 0.093750 (1.464 sec)
11.418... logprob:  0.379885, 0.093750 (1.455 sec)
11.419... logprob:  0.417393, 0.101562 (1.454 sec)
11.420... logprob:  0.355594, 0.085938 (1.468 sec)
11.421... logprob:  0.376497, 0.101562 (1.455 sec)
11.422... logprob:  0.523647, 0.148438 (1.442 sec)
11.423... logprob:  0.421178, 0.109375 (1.426 sec)
11.424... logprob:  0.324476, 0.078125 (1.450 sec)
11.425... logprob:  0.305946, 0.070312 (1.436 sec)
11.426... logprob:  0.449634, 0.117188 (1.449 sec)
11.427... logprob:  0.555505, 0.156250 (1.464 sec)
11.428... logprob:  0.602676, 0.171875 (1.455 sec)
11.429... logprob:  0.426221, 0.109375 (1.443 sec)
11.430... logprob:  0.300096, 0.070312 (1.473 sec)
11.431... logprob:  0.598826, 0.171875 (1.432 sec)
11.432... logprob:  0.387674, 0.093750 (1.432 sec)
11.433... logprob:  0.330645, 0.078125 (1.432 sec)
11.434... logprob:  0.528816, 0.148438 (1.444 sec)
11.435... logprob:  0.531797, 0.156250 (1.431 sec)
11.436... logprob:  0.381968, 0.093750 (1.480 sec)
11.437... logprob:  0.500185, 0.140625 (1.443 sec)
11.438... logprob:  0.546673, 0.156250 (1.437 sec)
11.439... logprob:  0.379542, 0.093750 (1.487 sec)
11.440... logprob:  0.440000, 0.117188 (1.439 sec)
11.441... logprob:  0.468089, 0.125000 (1.428 sec)
11.442... logprob:  0.378877, 0.093750 (1.438 sec)
11.443... logprob:  0.496605, 0.140625 (1.435 sec)
11.444... logprob:  0.371882, 0.093750 (1.431 sec)
11.445... logprob:  0.361861, 0.085938 (1.480 sec)
11.446... logprob:  0.397922, 0.101562 (1.435 sec)
11.447... logprob:  0.570926, 0.164062 (1.437 sec)
11.448... logprob:  0.332196, 0.078125 (1.483 sec)
11.449... logprob:  0.400028, 0.101562 (1.432 sec)
11.450... logprob:  0.238299, 0.046875 (1.438 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.01432800292969, 10.0]}, 128)
batch 872: ({'logprob': [67.77064514160156, 19.0]}, 128)
batch 873: ({'logprob': [39.76177978515625, 9.0]}, 128)
batch 874: ({'logprob': [44.762351989746094, 11.0]}, 128)
batch 875: ({'logprob': [50.750484466552734, 13.0]}, 128)
batch 876: ({'logprob': [65.03514862060547, 18.0]}, 128)
batch 877: ({'logprob': [45.25898361206055, 11.0]}, 128)
batch 878: ({'logprob': [62.7601432800293, 17.0]}, 128)
batch 879: ({'logprob': [75.23772430419922, 21.0]}, 128)
batch 880: ({'logprob': [50.76424789428711, 13.0]}, 128)
batch 881: ({'logprob': [27.253639221191406, 5.0]}, 128)
batch 882: ({'logprob': [54.99695587158203, 14.0]}, 128)
batch 883: ({'logprob': [62.748321533203125, 17.0]}, 128)
batch 884: ({'logprob': [51.24415588378906, 13.0]}, 128)
batch 885: ({'logprob': [52.235721588134766, 13.0]}, 128)
batch 886: ({'logprob': [63.24964141845703, 17.0]}, 128)

======================Test output======================
logprob:  0.417404, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.972494e-03 [3.509752e-09] 
Layer 'conv1' biases: 9.141823e-08 [1.020223e-10] 
Layer 'conv2' weights[0]: 7.959484e-03 [3.485589e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.054519e-10] 
Layer 'conv3' weights[0]: 7.957795e-03 [3.269864e-09] 
Layer 'conv3' biases: 8.183284e-07 [1.952914e-09] 
Layer 'conv4' weights[0]: 7.990372e-03 [3.655844e-09] 
Layer 'conv4' biases: 1.000000e+00 [1.859192e-08] 
Layer 'conv5' weights[0]: 7.989259e-03 [1.261783e-07] 
Layer 'conv5' biases: 9.999985e-01 [1.369814e-07] 
Layer 'fc6' weights[0]: 7.586058e-03 [1.092995e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.117581e-08] 
Layer 'fc7' weights[0]: 7.500465e-03 [3.706915e-07] 
Layer 'fc7' biases: 9.998681e-01 [3.577443e-07] 
Layer 'fc8' weights[0]: 1.359665e-03 [1.381309e-05] 
Layer 'fc8' biases: 2.462065e-02 [9.027795e-05] 
Train error last 870 batches: 0.435289
-------------------------------------------------------
Not saving because 0.417404 > 0.415712 (4.190: -0.00%)
======================================================= (12.046 sec)
11.451... logprob:  0.453352, 0.125000 (1.442 sec)
11.452... logprob:  0.456607, 0.117188 (1.432 sec)
11.453... logprob:  0.455763, 0.125000 (1.432 sec)
11.454... logprob:  0.489452, 0.132812 (1.487 sec)
11.455... logprob:  0.506166, 0.140625 (1.436 sec)
11.456... logprob:  0.468762, 0.125000 (1.451 sec)
11.457... logprob:  0.375440, 0.093750 (1.500 sec)
11.458... logprob:  0.351395, 0.085938 (1.437 sec)
11.459... logprob:  0.513395, 0.140625 (1.436 sec)
11.460... logprob:  0.275191, 0.054688 (1.437 sec)
11.461... logprob:  0.459899, 0.125000 (1.424 sec)
11.462... logprob:  0.471847, 0.125000 (1.441 sec)
11.463... logprob:  0.421050, 0.109375 (1.468 sec)
11.464... logprob:  0.482624, 0.132812 (1.444 sec)
11.465... logprob:  0.421290, 0.109375 (1.452 sec)
11.466... logprob:  0.318843, 0.070312 (1.465 sec)
11.467... logprob:  0.413891, 0.109375 (1.450 sec)
11.468... logprob:  0.394277, 0.101562 (1.435 sec)
11.469... logprob:  0.334538, 0.078125 (1.429 sec)
11.470... logprob:  0.400025, 0.101562 (1.425 sec)
11.471... logprob:  0.529920, 0.148438 (1.443 sec)
11.472... logprob:  0.410153, 0.109375 (1.457 sec)
11.473... logprob:  0.375262, 0.093750 (1.454 sec)
11.474... logprob:  0.465994, 0.125000 (1.454 sec)
11.475... logprob:  0.504743, 0.140625 (1.459 sec)
11.476... logprob:  0.510692, 0.140625 (1.470 sec)
11.477... logprob:  0.334432, 0.078125 (1.440 sec)
11.478... logprob:  0.464324, 0.125000 (1.423 sec)
11.479... logprob:  0.305836, 0.070312 (1.431 sec)
11.480... logprob:  0.443528, 0.117188 (1.436 sec)
11.481... logprob:  0.547675, 0.156250 (1.441 sec)
11.482... logprob:  0.443217, 0.117188 (1.473 sec)
11.483... logprob:  0.502488, 0.140625 (1.452 sec)
11.484... logprob:  0.485275, 0.132812 (1.436 sec)
11.485... logprob:  0.409200, 0.109375 (1.482 sec)
11.486... logprob:  0.361844, 0.085938 (1.431 sec)
11.487... logprob:  0.522574, 0.148438 (1.425 sec)
11.488... logprob:  0.425010, 0.109375 (1.433 sec)
11.489... logprob:  0.416031, 0.109375 (1.433 sec)
11.490... logprob:  0.440709, 0.117188 (1.429 sec)
11.491... logprob:  0.313750, 0.070312 (1.482 sec)
11.492... logprob:  0.459666, 0.125000 (1.439 sec)
11.493... logprob:  0.522089, 0.148438 (1.434 sec)
11.494... logprob:  0.450408, 0.125000 (1.484 sec)
11.495... logprob:  0.380462, 0.093750 (1.436 sec)
11.496... logprob:  0.550747, 0.156250 (1.429 sec)
11.497... logprob:  0.467146, 0.125000 (1.432 sec)
11.498... logprob:  0.476435, 0.132812 (1.432 sec)
11.499... logprob:  0.456322, 0.125000 (1.436 sec)
11.500... logprob:  0.355033, 0.085938 (1.499 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.019020080566406, 10.0]}, 128)
batch 872: ({'logprob': [66.31593322753906, 19.0]}, 128)
batch 873: ({'logprob': [40.93312454223633, 9.0]}, 128)
batch 874: ({'logprob': [45.44536209106445, 11.0]}, 128)
batch 875: ({'logprob': [50.884952545166016, 13.0]}, 128)
batch 876: ({'logprob': [63.83892059326172, 18.0]}, 128)
batch 877: ({'logprob': [45.91302490234375, 11.0]}, 128)
batch 878: ({'logprob': [61.79408645629883, 17.0]}, 128)
batch 879: ({'logprob': [73.1412124633789, 21.0]}, 128)
batch 880: ({'logprob': [50.89825439453125, 13.0]}, 128)
batch 881: ({'logprob': [29.557069778442383, 5.0]}, 128)
batch 882: ({'logprob': [54.77687454223633, 14.0]}, 128)
batch 883: ({'logprob': [61.78227233886719, 17.0]}, 128)
batch 884: ({'logprob': [51.345211029052734, 13.0]}, 128)
batch 885: ({'logprob': [52.27400588989258, 13.0]}, 128)
batch 886: ({'logprob': [62.2511100769043, 17.0]}, 128)

======================Test output======================
logprob:  0.416587, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.972453e-03 [2.138203e-09] 
Layer 'conv1' biases: 9.216783e-08 [3.685108e-11] 
Layer 'conv2' weights[0]: 7.959457e-03 [1.745148e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.935462e-10] 
Layer 'conv3' weights[0]: 7.957753e-03 [1.552293e-09] 
Layer 'conv3' biases: 8.260120e-07 [6.484593e-10] 
Layer 'conv4' weights[0]: 7.990327e-03 [1.775322e-09] 
Layer 'conv4' biases: 9.999999e-01 [6.524043e-09] 
Layer 'conv5' weights[0]: 7.989235e-03 [4.478290e-08] 
Layer 'conv5' biases: 9.999992e-01 [4.867239e-08] 
Layer 'fc6' weights[0]: 7.586015e-03 [3.941723e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.905511e-09] 
Layer 'fc7' weights[0]: 7.498545e-03 [3.948013e-08] 
Layer 'fc7' biases: 9.998671e-01 [1.004055e-08] 
Layer 'fc8' weights[0]: 1.308099e-03 [2.861195e-06] 
Layer 'fc8' biases: 2.444869e-02 [1.747434e-05] 
Train error last 870 batches: 0.435289
-------------------------------------------------------
Not saving because 0.416587 > 0.415712 (4.190: -0.00%)
======================================================= (12.128 sec)
11.501... logprob:  0.339108, 0.078125 (1.435 sec)
11.502... logprob:  0.459707, 0.125000 (1.450 sec)
11.503... logprob:  0.400715, 0.101562 (1.492 sec)
11.504... logprob:  0.487380, 0.132812 (1.433 sec)
11.505... logprob:  0.570820, 0.164062 (1.441 sec)
11.506... logprob:  0.479679, 0.132812 (1.433 sec)
11.507... logprob:  0.385220, 0.093750 (1.431 sec)
11.508... logprob:  0.374837, 0.093750 (1.431 sec)
11.509... logprob:  0.323373, 0.070312 (1.484 sec)
11.510... logprob:  0.390510, 0.101562 (1.442 sec)
11.511... logprob:  0.410110, 0.109375 (1.454 sec)
11.512... logprob:  0.470771, 0.125000 (1.464 sec)
11.513... logprob:  0.324986, 0.078125 (1.447 sec)
11.514... logprob:  0.406283, 0.101562 (1.440 sec)
11.515... logprob:  0.455691, 0.125000 (1.430 sec)
11.516... logprob:  0.400521, 0.109375 (1.503 sec)
11.517... logprob:  0.628266, 0.179688 (1.436 sec)
11.518... logprob:  0.437772, 0.117188 (1.453 sec)
11.519... logprob:  0.516183, 0.140625 (1.451 sec)
11.520... logprob:  0.409665, 0.109375 (1.453 sec)
11.521... logprob:  0.427581, 0.109375 (1.453 sec)
11.522... logprob:  0.533027, 0.156250 (1.456 sec)
11.523... logprob:  0.331948, 0.078125 (1.438 sec)
11.524... logprob:  0.437298, 0.117188 (1.422 sec)
11.525... logprob:  0.426213, 0.109375 (1.431 sec)
11.526... logprob:  0.352147, 0.078125 (1.439 sec)
11.527... logprob:  0.504520, 0.140625 (1.444 sec)
11.528... logprob:  0.440559, 0.117188 (1.470 sec)
11.529... logprob:  0.353030, 0.085938 (1.452 sec)
11.530... logprob:  0.440248, 0.117188 (1.441 sec)
11.531... logprob:  0.440058, 0.117188 (1.501 sec)
11.532... logprob:  0.467463, 0.125000 (1.433 sec)
11.533... logprob:  0.560950, 0.164062 (1.429 sec)
11.534... logprob:  0.325700, 0.078125 (1.438 sec)
11.535... logprob:  0.551852, 0.156250 (1.438 sec)
11.536... logprob:  0.507497, 0.140625 (1.430 sec)
11.537... logprob:  0.510136, 0.140625 (1.483 sec)
11.538... logprob:  0.486136, 0.132812 (1.442 sec)
11.539... logprob:  0.296232, 0.062500 (1.437 sec)
11.540... logprob:  0.447188, 0.117188 (1.490 sec)
11.541... logprob:  0.388963, 0.101562 (1.429 sec)
11.542... logprob:  0.411371, 0.109375 (1.425 sec)
11.543... logprob:  0.233530, 0.039062 (1.434 sec)
11.544... logprob:  0.317971, 0.070312 (1.431 sec)
11.545... logprob:  0.348822, 0.085938 (1.434 sec)
11.546... logprob:  0.368302, 0.093750 (1.487 sec)
11.547... logprob:  0.440230, 0.117188 (1.436 sec)
11.548... logprob:  0.453392, 0.125000 (1.446 sec)
11.549... logprob:  0.490914, 0.132812 (1.478 sec)
11.550... logprob:  0.367752, 0.093750 (1.428 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.849002838134766, 10.0]}, 128)
batch 872: ({'logprob': [68.44357299804688, 19.0]}, 128)
batch 873: ({'logprob': [39.56926727294922, 9.0]}, 128)
batch 874: ({'logprob': [44.72019577026367, 11.0]}, 128)
batch 875: ({'logprob': [50.89612579345703, 13.0]}, 128)
batch 876: ({'logprob': [65.6240463256836, 18.0]}, 128)
batch 877: ({'logprob': [45.23533248901367, 11.0]}, 128)
batch 878: ({'logprob': [63.283050537109375, 17.0]}, 128)
batch 879: ({'logprob': [76.15644073486328, 21.0]}, 128)
batch 880: ({'logprob': [50.91028594970703, 13.0]}, 128)
batch 881: ({'logprob': [26.664836883544922, 5.0]}, 128)
batch 882: ({'logprob': [55.28547668457031, 14.0]}, 128)
batch 883: ({'logprob': [63.27088165283203, 17.0]}, 128)
batch 884: ({'logprob': [51.40989303588867, 13.0]}, 128)
batch 885: ({'logprob': [52.440040588378906, 13.0]}, 128)
batch 886: ({'logprob': [63.79222106933594, 17.0]}, 128)

======================Test output======================
logprob:  0.419214, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.972409e-03 [3.125777e-09] 
Layer 'conv1' biases: 9.277207e-08 [6.928223e-11] 
Layer 'conv2' weights[0]: 7.959421e-03 [2.925083e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.548588e-10] 
Layer 'conv3' weights[0]: 7.957715e-03 [2.540099e-09] 
Layer 'conv3' biases: 8.316811e-07 [1.475794e-09] 
Layer 'conv4' weights[0]: 7.990287e-03 [2.816523e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.327566e-08] 
Layer 'conv5' weights[0]: 7.989186e-03 [8.598328e-08] 
Layer 'conv5' biases: 9.999987e-01 [9.320380e-08] 
Layer 'fc6' weights[0]: 7.585983e-03 [7.583906e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.690062e-09] 
Layer 'fc7' weights[0]: 7.496634e-03 [4.797249e-08] 
Layer 'fc7' biases: 9.998689e-01 [2.428648e-08] 
Layer 'fc8' weights[0]: 1.372627e-03 [7.694894e-06] 
Layer 'fc8' biases: 2.497130e-02 [4.285712e-05] 
Train error last 870 batches: 0.435288
-------------------------------------------------------
Not saving because 0.419214 > 0.415712 (4.190: -0.00%)
======================================================= (12.056 sec)
11.551... logprob:  0.441914, 0.117188 (1.441 sec)
11.552... logprob:  0.471397, 0.125000 (1.438 sec)
11.553... logprob:  0.349427, 0.085938 (1.426 sec)
11.554... logprob:  0.506762, 0.140625 (1.437 sec)
11.555... logprob:  0.421420, 0.109375 (1.480 sec)
11.556... logprob:  0.356028, 0.085938 (1.434 sec)
11.557... logprob:  0.396571, 0.101562 (1.450 sec)
11.558... logprob:  0.383119, 0.101562 (1.477 sec)
11.559... logprob:  0.441363, 0.125000 (1.435 sec)
11.560... logprob:  0.335534, 0.078125 (1.450 sec)
11.561... logprob:  0.411887, 0.109375 (1.433 sec)
11.562... logprob:  0.503102, 0.140625 (1.425 sec)
11.563... logprob:  0.373926, 0.093750 (1.442 sec)
11.564... logprob:  0.468399, 0.132812 (1.495 sec)
11.565... logprob:  0.610989, 0.187500 (1.449 sec)
11.566... logprob:  0.374947, 0.093750 (1.453 sec)
11.567... logprob:  0.423528, 0.109375 (1.456 sec)
11.568... logprob:  0.496419, 0.140625 (1.459 sec)
11.569... logprob:  0.507958, 0.140625 (1.437 sec)
11.570... logprob:  0.543701, 0.164062 (1.423 sec)
11.571... logprob:  0.454872, 0.125000 (1.432 sec)
11.572... logprob:  0.501557, 0.140625 (1.437 sec)
11.573... logprob:  0.512661, 0.148438 (1.452 sec)
11.574... logprob:  0.428225, 0.109375 (1.461 sec)
11.575... logprob:  0.343394, 0.078125 (1.458 sec)
11.576... logprob:  0.427448, 0.109375 (1.442 sec)
11.577... logprob:  0.460887, 0.125000 (1.471 sec)
11.578... logprob:  0.336485, 0.078125 (1.434 sec)
11.579... logprob:  0.442098, 0.117188 (1.427 sec)
11.580... logprob:  0.547137, 0.156250 (1.435 sec)
11.581... logprob:  0.531237, 0.156250 (1.442 sec)
11.582... logprob:  0.437967, 0.125000 (1.433 sec)
11.583... logprob:  0.593123, 0.171875 (1.480 sec)
11.584... logprob:  0.468165, 0.132812 (1.446 sec)
11.585... logprob:  0.349776, 0.085938 (1.433 sec)
11.586... logprob:  0.313218, 0.070312 (1.483 sec)
11.587... logprob:  0.404332, 0.101562 (1.435 sec)
11.588... logprob:  0.418686, 0.117188 (1.432 sec)
11.589... logprob:  0.361397, 0.093750 (1.432 sec)
11.590... logprob:  0.524659, 0.148438 (1.428 sec)
11.591... logprob:  0.397554, 0.101562 (1.430 sec)
11.592... logprob:  0.455631, 0.125000 (1.479 sec)
11.593... logprob:  0.467458, 0.125000 (1.434 sec)
11.594... logprob:  0.352901, 0.085938 (1.445 sec)
11.595... logprob:  0.428682, 0.109375 (1.477 sec)
11.596... logprob:  0.461569, 0.125000 (1.432 sec)
11.597... logprob:  0.397410, 0.101562 (1.430 sec)
11.598... logprob:  0.397239, 0.101562 (1.442 sec)
11.599... logprob:  0.313466, 0.070312 (1.426 sec)
11.600... logprob:  0.340905, 0.085938 (1.427 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.99081802368164, 10.0]}, 128)
batch 872: ({'logprob': [66.89514923095703, 19.0]}, 128)
batch 873: ({'logprob': [40.51513671875, 9.0]}, 128)
batch 874: ({'logprob': [44.95210266113281, 11.0]}, 128)
batch 875: ({'logprob': [50.774078369140625, 13.0]}, 128)
batch 876: ({'logprob': [64.34170532226562, 18.0]}, 128)
batch 877: ({'logprob': [45.647525787353516, 11.0]}, 128)
batch 878: ({'logprob': [62.44855499267578, 17.0]}, 128)
batch 879: ({'logprob': [74.78868103027344, 21.0]}, 128)
batch 880: ({'logprob': [50.78700256347656, 13.0]}, 128)
batch 881: ({'logprob': [28.144533157348633, 5.0]}, 128)
batch 882: ({'logprob': [55.4305534362793, 14.0]}, 128)
batch 883: ({'logprob': [62.43666458129883, 17.0]}, 128)
batch 884: ({'logprob': [51.46455001831055, 13.0]}, 128)
batch 885: ({'logprob': [52.85185623168945, 13.0]}, 128)
batch 886: ({'logprob': [63.1353645324707, 17.0]}, 128)

======================Test output======================
logprob:  0.417776, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.972382e-03 [2.491810e-09] 
Layer 'conv1' biases: 9.357736e-08 [7.465598e-11] 
Layer 'conv2' weights[0]: 7.959385e-03 [2.194436e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.184835e-10] 
Layer 'conv3' weights[0]: 7.957674e-03 [2.239001e-09] 
Layer 'conv3' biases: 8.379234e-07 [1.353604e-09] 
Layer 'conv4' weights[0]: 7.990245e-03 [2.513480e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.328012e-08] 
Layer 'conv5' weights[0]: 7.989149e-03 [9.021600e-08] 
Layer 'conv5' biases: 9.999987e-01 [9.801063e-08] 
Layer 'fc6' weights[0]: 7.585948e-03 [7.891829e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.982979e-09] 
Layer 'fc7' weights[0]: 7.494719e-03 [1.635265e-07] 
Layer 'fc7' biases: 9.998677e-01 [1.510277e-07] 
Layer 'fc8' weights[0]: 1.338364e-03 [7.388109e-06] 
Layer 'fc8' biases: 2.487389e-02 [4.580037e-05] 
Train error last 870 batches: 0.435288
-------------------------------------------------------
Not saving because 0.417776 > 0.415712 (4.190: -0.00%)
======================================================= (12.054 sec)
11.601... logprob:  0.402109, 0.101562 (1.494 sec)
11.602... logprob:  0.289577, 0.062500 (1.434 sec)
11.603... logprob:  0.266801, 0.054688 (1.449 sec)
11.604... logprob:  0.407512, 0.101562 (1.477 sec)
11.605... logprob:  0.563770, 0.148438 (1.432 sec)
11.606... logprob:  0.295956, 0.070312 (1.442 sec)
11.607... logprob:  0.505059, 0.132812 (1.432 sec)
11.608... logprob:  0.361598, 0.085938 (1.429 sec)
11.609... logprob:  0.356872, 0.085938 (1.443 sec)
11.610... logprob:  0.493504, 0.132812 (1.473 sec)
11.611... logprob:  0.510478, 0.140625 (1.451 sec)
11.612... logprob:  0.448327, 0.117188 (1.450 sec)
11.613... logprob:  0.280031, 0.062500 (1.459 sec)
11.614... logprob:  0.503485, 0.140625 (1.450 sec)
11.615... logprob:  0.351356, 0.085938 (1.438 sec)
11.616... logprob:  0.415500, 0.109375 (1.429 sec)
11.617... logprob:  0.418049, 0.109375 (1.430 sec)
11.618... logprob:  0.546535, 0.156250 (1.436 sec)
11.619... logprob:  0.505871, 0.140625 (1.446 sec)
11.620... logprob:  0.539586, 0.156250 (1.456 sec)
11.621... logprob:  0.364100, 0.085938 (1.453 sec)
11.622... logprob:  0.365081, 0.085938 (1.452 sec)
11.623... logprob:  0.423265, 0.109375 (1.464 sec)
11.624... logprob:  0.382569, 0.093750 (1.435 sec)
11.625... logprob:  0.441019, 0.117188 (1.425 sec)
11.626... logprob:  0.438420, 0.117188 (1.436 sec)
11.627... logprob:  0.435884, 0.117188 (1.437 sec)
11.628... logprob:  0.465145, 0.125000 (1.440 sec)
11.629... logprob:  0.371914, 0.093750 (1.473 sec)
11.630... logprob:  0.422374, 0.109375 (1.453 sec)
11.631... logprob:  0.639841, 0.187500 (1.439 sec)
11.632... logprob:  0.399094, 0.101562 (1.483 sec)
11.633... logprob:  0.375981, 0.093750 (1.436 sec)
11.634... logprob:  0.660656, 0.195312 (1.430 sec)
11.635... logprob:  0.374137, 0.093750 (1.436 sec)
11.636... logprob:  0.480213, 0.132812 (1.437 sec)
11.637... logprob:  0.331080, 0.078125 (1.431 sec)
11.638... logprob:  0.515642, 0.140625 (1.502 sec)
11.639... logprob:  0.418236, 0.109375 (1.440 sec)
11.640... logprob:  0.528750, 0.148438 (1.432 sec)
11.641... logprob:  0.410538, 0.109375 (1.487 sec)
11.642... logprob:  0.500776, 0.140625 (1.430 sec)
11.643... logprob:  0.622622, 0.187500 (1.439 sec)
11.644... logprob:  0.321663, 0.070312 (1.431 sec)
11.645... logprob:  0.414537, 0.109375 (1.429 sec)
11.646... logprob:  0.385842, 0.093750 (1.432 sec)
11.647... logprob:  0.456729, 0.125000 (1.489 sec)
11.648... logprob:  0.491222, 0.140625 (1.435 sec)
11.649... logprob:  0.369999, 0.093750 (1.445 sec)
11.650... logprob:  0.413888, 0.109375 (1.482 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.931846618652344, 10.0]}, 128)
batch 872: ({'logprob': [66.36959838867188, 19.0]}, 128)
batch 873: ({'logprob': [40.84678268432617, 9.0]}, 128)
batch 874: ({'logprob': [45.38128662109375, 11.0]}, 128)
batch 875: ({'logprob': [50.852500915527344, 13.0]}, 128)
batch 876: ({'logprob': [63.87944793701172, 18.0]}, 128)
batch 877: ({'logprob': [45.85365676879883, 11.0]}, 128)
batch 878: ({'logprob': [61.82558822631836, 17.0]}, 128)
batch 879: ({'logprob': [73.24102783203125, 21.0]}, 128)
batch 880: ({'logprob': [50.86600112915039, 13.0]}, 128)
batch 881: ({'logprob': [29.4021053314209, 5.0]}, 128)
batch 882: ({'logprob': [54.772499084472656, 14.0]}, 128)
batch 883: ({'logprob': [61.8134651184082, 17.0]}, 128)
batch 884: ({'logprob': [51.31779479980469, 13.0]}, 128)
batch 885: ({'logprob': [52.256065368652344, 13.0]}, 128)
batch 886: ({'logprob': [62.287410736083984, 17.0]}, 128)

======================Test output======================
logprob:  0.416454, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.972343e-03 [1.915633e-09] 
Layer 'conv1' biases: 9.429735e-08 [4.923723e-11] 
Layer 'conv2' weights[0]: 7.959350e-03 [1.762915e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.316969e-10] 
Layer 'conv3' weights[0]: 7.957630e-03 [1.797209e-09] 
Layer 'conv3' biases: 8.441415e-07 [1.058148e-09] 
Layer 'conv4' weights[0]: 7.990199e-03 [2.053821e-09] 
Layer 'conv4' biases: 9.999999e-01 [1.080075e-08] 
Layer 'conv5' weights[0]: 7.989113e-03 [7.459166e-08] 
Layer 'conv5' biases: 9.999989e-01 [8.108953e-08] 
Layer 'fc6' weights[0]: 7.585904e-03 [6.363121e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.463321e-09] 
Layer 'fc7' weights[0]: 7.492828e-03 [2.412592e-07] 
Layer 'fc7' biases: 9.998670e-01 [2.287392e-07] 
Layer 'fc8' weights[0]: 1.314107e-03 [1.081332e-05] 
Layer 'fc8' biases: 2.487116e-02 [7.102436e-05] 
Train error last 870 batches: 0.435288
-------------------------------------------------------
Not saving because 0.416454 > 0.415712 (4.190: -0.00%)
======================================================= (12.073 sec)
11.651... logprob:  0.397251, 0.101562 (1.444 sec)
11.652... logprob:  0.507576, 0.140625 (1.438 sec)
11.653... logprob:  0.548376, 0.156250 (1.435 sec)
11.654... logprob:  0.496237, 0.140625 (1.429 sec)
11.655... logprob:  0.436233, 0.117188 (1.434 sec)
11.656... logprob:  0.416657, 0.109375 (1.478 sec)
11.657... logprob:  0.449389, 0.117188 (1.438 sec)
11.658... logprob:  0.345719, 0.085938 (1.451 sec)
11.659... logprob:  0.464388, 0.125000 (1.478 sec)
11.660... logprob:  0.445847, 0.125000 (1.439 sec)
11.661... logprob:  0.378624, 0.093750 (1.436 sec)
11.662... logprob:  0.469284, 0.132812 (1.428 sec)
11.663... logprob:  0.311161, 0.070312 (1.422 sec)
11.664... logprob:  0.285603, 0.062500 (1.438 sec)
11.665... logprob:  0.401937, 0.101562 (1.457 sec)
11.666... logprob:  0.442090, 0.117188 (1.451 sec)
11.667... logprob:  0.564380, 0.164062 (1.453 sec)
11.668... logprob:  0.497971, 0.140625 (1.446 sec)
11.669... logprob:  0.433182, 0.109375 (1.457 sec)
11.670... logprob:  0.362549, 0.085938 (1.439 sec)
11.671... logprob:  0.360852, 0.093750 (1.447 sec)
11.672... logprob:  0.441804, 0.117188 (1.430 sec)
11.673... logprob:  0.436259, 0.117188 (1.437 sec)
11.674... logprob:  0.446686, 0.117188 (1.441 sec)
11.675... logprob:  0.356663, 0.093750 (1.465 sec)
11.676... logprob:  0.450135, 0.125000 (1.449 sec)
11.677... logprob:  0.471080, 0.125000 (1.437 sec)
11.678... logprob:  0.465633, 0.125000 (1.485 sec)
11.679... logprob:  0.454884, 0.125000 (1.433 sec)
11.680... logprob:  0.351772, 0.078125 (1.431 sec)
11.681... logprob:  0.373991, 0.093750 (1.436 sec)
11.682... logprob:  0.340528, 0.078125 (1.435 sec)
11.683... logprob:  0.411659, 0.109375 (1.428 sec)
11.684... logprob:  0.357550, 0.085938 (1.482 sec)
11.685... logprob:  0.285690, 0.054688 (1.443 sec)
11.686... logprob:  0.318376, 0.070312 (1.435 sec)
11.687... logprob:  0.281379, 0.062500 (1.491 sec)
11.688... logprob:  0.323052, 0.078125 (1.431 sec)
11.689... logprob:  0.471847, 0.125000 (1.428 sec)
11.690... logprob:  0.528488, 0.140625 (1.437 sec)
11.691... logprob:  0.517533, 0.140625 (1.431 sec)
11.692... logprob:  0.385604, 0.101562 (1.437 sec)
11.693... logprob:  0.456303, 0.125000 (1.482 sec)
11.694... logprob:  0.330865, 0.078125 (1.434 sec)
11.695... logprob:  0.356867, 0.085938 (1.439 sec)
11.696... logprob:  0.538528, 0.148438 (1.476 sec)
11.697... logprob:  0.465486, 0.125000 (1.434 sec)
11.698... logprob:  0.548248, 0.156250 (1.438 sec)
11.699... logprob:  0.459564, 0.125000 (1.434 sec)
11.700... logprob:  0.434168, 0.117188 (1.433 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.15020751953125, 10.0]}, 128)
batch 872: ({'logprob': [65.92350769042969, 19.0]}, 128)
batch 873: ({'logprob': [42.113346099853516, 9.0]}, 128)
batch 874: ({'logprob': [46.3526611328125, 11.0]}, 128)
batch 875: ({'logprob': [51.4506950378418, 13.0]}, 128)
batch 876: ({'logprob': [63.59998321533203, 18.0]}, 128)
batch 877: ({'logprob': [46.78693771362305, 11.0]}, 128)
batch 878: ({'logprob': [61.67469787597656, 17.0]}, 128)
batch 879: ({'logprob': [72.3021011352539, 21.0]}, 128)
batch 880: ({'logprob': [51.46379089355469, 13.0]}, 128)
batch 881: ({'logprob': [31.45769691467285, 5.0]}, 128)
batch 882: ({'logprob': [55.08250045776367, 14.0]}, 128)
batch 883: ({'logprob': [61.66262435913086, 17.0]}, 128)
batch 884: ({'logprob': [51.87424087524414, 13.0]}, 128)
batch 885: ({'logprob': [52.73232650756836, 13.0]}, 128)
batch 886: ({'logprob': [62.09554672241211, 17.0]}, 128)

======================Test output======================
logprob:  0.419787, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.972311e-03 [2.525839e-09] 
Layer 'conv1' biases: 9.501720e-08 [3.746513e-11] 
Layer 'conv2' weights[0]: 7.959310e-03 [1.633948e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.495537e-10] 
Layer 'conv3' weights[0]: 7.957598e-03 [1.264883e-09] 
Layer 'conv3' biases: 8.524419e-07 [5.070250e-10] 
Layer 'conv4' weights[0]: 7.990163e-03 [1.220409e-09] 
Layer 'conv4' biases: 9.999999e-01 [2.616502e-09] 
Layer 'conv5' weights[0]: 7.989073e-03 [1.433036e-08] 
Layer 'conv5' biases: 9.999998e-01 [1.534839e-08] 
Layer 'fc6' weights[0]: 7.585866e-03 [1.486271e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.277415e-09] 
Layer 'fc7' weights[0]: 7.490955e-03 [3.660384e-07] 
Layer 'fc7' biases: 9.998661e-01 [3.542996e-07] 
Layer 'fc8' weights[0]: 1.283843e-03 [1.373871e-05] 
Layer 'fc8' biases: 2.480149e-02 [8.101426e-05] 
Train error last 870 batches: 0.435287
-------------------------------------------------------
Not saving because 0.419787 > 0.415712 (4.190: -0.00%)
======================================================= (12.172 sec)
11.701... logprob:  0.423593, 0.109375 (1.437 sec)
11.702... logprob:  0.521392, 0.148438 (1.486 sec)
11.703... logprob:  0.405842, 0.101562 (1.436 sec)
11.704... logprob:  0.406550, 0.101562 (1.485 sec)
11.705... logprob:  0.420410, 0.109375 (1.471 sec)
11.706... logprob:  0.468089, 0.125000 (1.428 sec)
11.707... logprob:  0.485300, 0.132812 (1.439 sec)
11.708... logprob:  0.416940, 0.109375 (1.431 sec)
11.709... logprob:  0.422312, 0.109375 (1.422 sec)
11.710... logprob:  0.603213, 0.179688 (1.437 sec)
11.711... logprob:  0.469579, 0.125000 (1.462 sec)
11.712... logprob:  0.340005, 0.078125 (1.445 sec)
11.713... logprob:  0.587861, 0.179688 (1.461 sec)
11.714... logprob:  0.466397, 0.125000 (1.452 sec)
11.715... logprob:  0.417111, 0.109375 (1.452 sec)
11.716... logprob:  0.335128, 0.078125 (1.439 sec)
11.717... logprob:  0.429875, 0.117188 (1.426 sec)
11.718... logprob:  0.490419, 0.132812 (1.421 sec)
11.719... logprob:  0.406214, 0.109375 (1.434 sec)
11.720... logprob:  0.433246, 0.117188 (1.443 sec)
11.721... logprob:  0.451595, 0.117188 (1.461 sec)
11.722... logprob:  0.536728, 0.156250 (1.458 sec)
11.723... logprob:  0.416645, 0.109375 (1.443 sec)
11.724... logprob:  0.412797, 0.109375 (1.470 sec)
11.725... logprob:  0.494552, 0.140625 (1.437 sec)
11.726... logprob:  0.338840, 0.085938 (1.428 sec)
11.727... logprob:  0.393487, 0.101562 (1.431 sec)
11.728... logprob:  0.421459, 0.109375 (1.443 sec)
11.729... logprob:  0.387923, 0.093750 (1.436 sec)
11.730... logprob:  0.565800, 0.164062 (1.474 sec)
11.731... logprob:  0.450288, 0.125000 (1.448 sec)
11.732... logprob:  0.311517, 0.070312 (1.442 sec)
11.733... logprob:  0.556830, 0.156250 (1.483 sec)
11.734... logprob:  0.340194, 0.078125 (1.435 sec)
11.735... logprob:  0.527749, 0.148438 (1.430 sec)
11.736... logprob:  0.643320, 0.187500 (1.441 sec)
11.737... logprob:  0.516276, 0.148438 (1.429 sec)
11.738... logprob:  0.459462, 0.125000 (1.430 sec)
11.739... logprob:  0.477834, 0.132812 (1.485 sec)
11.740... logprob:  0.339679, 0.078125 (1.438 sec)
11.741... logprob:  0.393450, 0.101562 (1.437 sec)
11.742... logprob:  0.419779, 0.109375 (1.480 sec)
11.743... logprob:  0.364878, 0.085938 (1.434 sec)
11.744... logprob:  0.519313, 0.148438 (1.431 sec)
11.745... logprob:  0.478207, 0.132812 (1.433 sec)
11.746... logprob:  0.440572, 0.117188 (1.430 sec)
11.747... logprob:  0.425651, 0.109375 (1.435 sec)
11.748... logprob:  0.378015, 0.093750 (1.487 sec)
11.749... logprob:  0.420870, 0.109375 (1.438 sec)
11.750... logprob:  0.512996, 0.140625 (1.445 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.45284652709961, 10.0]}, 128)
batch 872: ({'logprob': [66.72565460205078, 19.0]}, 128)
batch 873: ({'logprob': [40.435447692871094, 9.0]}, 128)
batch 874: ({'logprob': [45.067657470703125, 11.0]}, 128)
batch 875: ({'logprob': [50.72916793823242, 13.0]}, 128)
batch 876: ({'logprob': [64.1637954711914, 18.0]}, 128)
batch 877: ({'logprob': [45.585899353027344, 11.0]}, 128)
batch 878: ({'logprob': [62.083927154541016, 17.0]}, 128)
batch 879: ({'logprob': [73.92693328857422, 21.0]}, 128)
batch 880: ({'logprob': [50.742713928222656, 13.0]}, 128)
batch 881: ({'logprob': [28.562355041503906, 5.0]}, 128)
batch 882: ({'logprob': [54.861637115478516, 14.0]}, 128)
batch 883: ({'logprob': [62.07173538208008, 17.0]}, 128)
batch 884: ({'logprob': [51.241825103759766, 13.0]}, 128)
batch 885: ({'logprob': [52.27352523803711, 13.0]}, 128)
batch 886: ({'logprob': [62.59275817871094, 17.0]}, 128)

======================Test output======================
logprob:  0.416268, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.972271e-03 [2.739758e-09] 
Layer 'conv1' biases: 9.562979e-08 [6.922084e-11] 
Layer 'conv2' weights[0]: 7.959270e-03 [1.992029e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.336932e-10] 
Layer 'conv3' weights[0]: 7.957564e-03 [1.753301e-09] 
Layer 'conv3' biases: 8.560655e-07 [9.991636e-10] 
Layer 'conv4' weights[0]: 7.990127e-03 [1.911550e-09] 
Layer 'conv4' biases: 9.999998e-01 [8.607916e-09] 
Layer 'conv5' weights[0]: 7.989026e-03 [5.913754e-08] 
Layer 'conv5' biases: 9.999987e-01 [6.418649e-08] 
Layer 'fc6' weights[0]: 7.585831e-03 [5.142438e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.156551e-09] 
Layer 'fc7' weights[0]: 7.489061e-03 [7.012813e-08] 
Layer 'fc7' biases: 9.998674e-01 [5.177417e-08] 
Layer 'fc8' weights[0]: 1.332099e-03 [6.920120e-06] 
Layer 'fc8' biases: 2.529052e-02 [4.471677e-05] 
Train error last 870 batches: 0.435287
-------------------------------------------------------
Not saving because 0.416268 > 0.415712 (4.190: -0.00%)
======================================================= (12.080 sec)
11.751... logprob:  0.263455, 0.054688 (1.485 sec)
11.752... logprob:  0.522522, 0.140625 (1.452 sec)
11.753... logprob:  0.441310, 0.117188 (1.437 sec)
11.754... logprob:  0.468708, 0.132812 (1.431 sec)
11.755... logprob:  0.507158, 0.140625 (1.425 sec)
11.756... logprob:  0.440823, 0.117188 (1.431 sec)
11.757... logprob:  0.552207, 0.156250 (1.471 sec)
11.758... logprob:  0.393789, 0.101562 (1.445 sec)
11.759... logprob:  0.459691, 0.125000 (1.455 sec)
11.760... logprob:  0.485346, 0.132812 (1.461 sec)
11.761... logprob:  0.418521, 0.109375 (1.441 sec)
11.762... logprob:  0.515944, 0.148438 (1.435 sec)
11.763... logprob:  0.558688, 0.164062 (1.430 sec)
11.764... logprob:  0.503305, 0.140625 (1.429 sec)
11.765... logprob:  0.312539, 0.062500 (1.436 sec)
11.766... logprob:  0.482340, 0.132812 (1.452 sec)
11.767... logprob:  0.371210, 0.085938 (1.457 sec)
11.768... logprob:  0.432736, 0.117188 (1.469 sec)
11.769... logprob:  0.490959, 0.140625 (1.466 sec)
11.770... logprob:  0.402741, 0.101562 (1.474 sec)
11.771... logprob:  0.549843, 0.156250 (1.455 sec)
11.772... logprob:  0.414006, 0.109375 (1.446 sec)
11.773... logprob:  0.558428, 0.164062 (1.445 sec)
11.774... logprob:  0.361398, 0.085938 (1.459 sec)
11.775... logprob:  0.407295, 0.101562 (1.457 sec)
11.776... logprob:  0.433299, 0.117188 (1.478 sec)
11.777... logprob:  0.379899, 0.093750 (1.473 sec)
11.778... logprob:  0.433666, 0.117188 (1.503 sec)
11.779... logprob:  0.505552, 0.140625 (1.485 sec)
11.780... logprob:  0.385756, 0.101562 (1.457 sec)
11.781... logprob:  0.369791, 0.085938 (1.445 sec)
11.782... logprob:  0.351573, 0.085938 (1.454 sec)
11.783... logprob:  0.555422, 0.156250 (1.458 sec)
11.784... logprob:  0.440962, 0.117188 (1.460 sec)
11.785... logprob:  0.543414, 0.156250 (1.493 sec)
11.786... logprob:  0.477310, 0.132812 (1.465 sec)
11.787... logprob:  0.546011, 0.156250 (1.465 sec)
11.788... logprob:  0.562687, 0.164062 (1.493 sec)
11.789... logprob:  0.281882, 0.054688 (1.456 sec)
11.790... logprob:  0.408539, 0.101562 (1.450 sec)
11.791... logprob:  0.398320, 0.101562 (1.447 sec)
11.792... logprob:  0.361437, 0.085938 (1.455 sec)
11.793... logprob:  0.370392, 0.085938 (1.456 sec)
11.794... logprob:  0.387117, 0.093750 (1.490 sec)
11.795... logprob:  0.469889, 0.125000 (1.466 sec)
11.796... logprob:  0.423500, 0.109375 (1.452 sec)
11.797... logprob:  0.358606, 0.085938 (1.498 sec)
11.798... logprob:  0.393255, 0.101562 (1.452 sec)
11.799... logprob:  0.332014, 0.078125 (1.444 sec)
11.800... logprob:  0.371847, 0.093750 (1.445 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.206939697265625, 10.0]}, 128)
batch 872: ({'logprob': [68.47431945800781, 19.0]}, 128)
batch 873: ({'logprob': [39.38270568847656, 9.0]}, 128)
batch 874: ({'logprob': [44.7795295715332, 11.0]}, 128)
batch 875: ({'logprob': [50.863494873046875, 13.0]}, 128)
batch 876: ({'logprob': [65.61688232421875, 18.0]}, 128)
batch 877: ({'logprob': [45.12626647949219, 11.0]}, 128)
batch 878: ({'logprob': [63.06814193725586, 17.0]}, 128)
batch 879: ({'logprob': [75.5906982421875, 21.0]}, 128)
batch 880: ({'logprob': [50.878360748291016, 13.0]}, 128)
batch 881: ({'logprob': [26.829315185546875, 5.0]}, 128)
batch 882: ({'logprob': [54.78609848022461, 14.0]}, 128)
batch 883: ({'logprob': [63.05561065673828, 17.0]}, 128)
batch 884: ({'logprob': [51.208988189697266, 13.0]}, 128)
batch 885: ({'logprob': [51.90167236328125, 13.0]}, 128)
batch 886: ({'logprob': [63.40861129760742, 17.0]}, 128)

======================Test output======================
logprob:  0.418055, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.972225e-03 [2.362309e-09] 
Layer 'conv1' biases: 9.634366e-08 [5.457416e-11] 
Layer 'conv2' weights[0]: 7.959220e-03 [1.517498e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.840155e-10] 
Layer 'conv3' weights[0]: 7.957525e-03 [1.237870e-09] 
Layer 'conv3' biases: 8.614720e-07 [4.551853e-10] 
Layer 'conv4' weights[0]: 7.990084e-03 [1.309539e-09] 
Layer 'conv4' biases: 9.999998e-01 [4.105818e-09] 
Layer 'conv5' weights[0]: 7.988984e-03 [2.811576e-08] 
Layer 'conv5' biases: 9.999983e-01 [3.052104e-08] 
Layer 'fc6' weights[0]: 7.585789e-03 [2.577758e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.476654e-09] 
Layer 'fc7' weights[0]: 7.487163e-03 [2.583677e-07] 
Layer 'fc7' biases: 9.998680e-01 [2.464855e-07] 
Layer 'fc8' weights[0]: 1.371115e-03 [1.017339e-05] 
Layer 'fc8' biases: 2.570429e-02 [6.669324e-05] 
Train error last 870 batches: 0.435286
-------------------------------------------------------
Not saving because 0.418055 > 0.415712 (4.190: -0.00%)
======================================================= (12.032 sec)
11.801... logprob:  0.450559, 0.117188 (1.464 sec)
11.802... logprob:  0.423310, 0.109375 (1.455 sec)
11.803... logprob:  0.492312, 0.132812 (1.487 sec)
11.804... logprob:  0.350009, 0.085938 (1.460 sec)
11.805... logprob:  0.452302, 0.117188 (1.456 sec)
11.806... logprob:  0.424189, 0.109375 (1.501 sec)
11.807... logprob:  0.443428, 0.117188 (1.455 sec)
11.808... logprob:  0.462313, 0.125000 (1.451 sec)
11.809... logprob:  0.589239, 0.171875 (1.445 sec)
11.810... logprob:  0.442423, 0.117188 (1.456 sec)
11.811... logprob:  0.460426, 0.125000 (1.458 sec)
11.812... logprob:  0.462490, 0.125000 (1.491 sec)
11.813... logprob:  0.486024, 0.132812 (1.457 sec)
11.814... logprob:  0.478282, 0.132812 (1.456 sec)
11.815... logprob:  0.372806, 0.085938 (1.499 sec)
11.816... logprob:  0.409256, 0.101562 (1.451 sec)
11.817... logprob:  0.426297, 0.109375 (1.450 sec)
11.818... logprob:  0.559960, 0.164062 (1.446 sec)
11.819... logprob:  0.498236, 0.140625 (1.455 sec)
11.820... logprob:  0.421472, 0.109375 (1.456 sec)
11.821... logprob:  0.406280, 0.101562 (1.498 sec)
11.822... logprob:  0.440999, 0.117188 (1.459 sec)
11.823... logprob:  0.340106, 0.078125 (1.192 sec)
11.824... logprob:  0.490213, 0.132812 (0.715 sec)
11.825... logprob:  0.287066, 0.062500 (0.683 sec)
11.826... logprob:  0.375247, 0.093750 (0.689 sec)
11.827... logprob:  0.420753, 0.109375 (0.686 sec)
11.828... logprob:  0.443869, 0.117188 (0.684 sec)
11.829... logprob:  0.505108, 0.140625 (0.689 sec)
11.830... logprob:  0.442511, 0.117188 (1.511 sec)
11.831... logprob:  0.514264, 0.140625 (1.450 sec)
11.832... logprob:  0.330885, 0.078125 (1.461 sec)
11.833... logprob:  0.488882, 0.132812 (1.498 sec)
11.834... logprob:  0.433090, 0.117188 (1.454 sec)
11.835... logprob:  0.542229, 0.148438 (1.458 sec)
11.836... logprob:  0.376500, 0.093750 (1.453 sec)
11.837... logprob:  0.315246, 0.070312 (1.450 sec)
11.838... logprob:  0.437121, 0.117188 (1.456 sec)
11.839... logprob:  0.471794, 0.125000 (1.583 sec)
11.840... logprob:  0.555101, 0.156250 (1.448 sec)
11.841... logprob:  0.396440, 0.101562 (1.464 sec)
11.842... logprob:  0.497768, 0.140625 (1.495 sec)
11.843... logprob:  0.465577, 0.125000 (1.455 sec)
11.844... logprob:  0.497591, 0.140625 (1.459 sec)
11.845... logprob:  0.486884, 0.132812 (1.451 sec)
11.846... logprob:  0.468536, 0.125000 (1.449 sec)
11.847... logprob:  0.362995, 0.085938 (1.446 sec)
11.848... logprob:  0.396874, 0.101562 (1.491 sec)
11.849... logprob:  0.360035, 0.085938 (1.453 sec)
11.850... logprob:  0.479489, 0.132812 (1.467 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.36669158935547, 10.0]}, 128)
batch 872: ({'logprob': [66.52197265625, 19.0]}, 128)
batch 873: ({'logprob': [40.79438018798828, 9.0]}, 128)
batch 874: ({'logprob': [45.5506591796875, 11.0]}, 128)
batch 875: ({'logprob': [50.941986083984375, 13.0]}, 128)
batch 876: ({'logprob': [63.99677658081055, 18.0]}, 128)
batch 877: ({'logprob': [45.87265396118164, 11.0]}, 128)
batch 878: ({'logprob': [61.75646209716797, 17.0]}, 128)
batch 879: ({'logprob': [72.8631820678711, 21.0]}, 128)
batch 880: ({'logprob': [50.95601272583008, 13.0]}, 128)
batch 881: ({'logprob': [29.658939361572266, 5.0]}, 128)
batch 882: ({'logprob': [54.44620895385742, 14.0]}, 128)
batch 883: ({'logprob': [61.744110107421875, 17.0]}, 128)
batch 884: ({'logprob': [51.256858825683594, 13.0]}, 128)
batch 885: ({'logprob': [51.89399337768555, 13.0]}, 128)
batch 886: ({'logprob': [62.0677375793457, 17.0]}, 128)

======================Test output======================
logprob:  0.416352, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.972177e-03 [2.339234e-09] 
Layer 'conv1' biases: 9.708293e-08 [5.699669e-11] 
Layer 'conv2' weights[0]: 7.959179e-03 [1.855230e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.989571e-10] 
Layer 'conv3' weights[0]: 7.957485e-03 [1.808547e-09] 
Layer 'conv3' biases: 8.686820e-07 [1.009939e-09] 
Layer 'conv4' weights[0]: 7.990047e-03 [2.103415e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.023401e-08] 
Layer 'conv5' weights[0]: 7.988964e-03 [7.052069e-08] 
Layer 'conv5' biases: 9.999987e-01 [7.665668e-08] 
Layer 'fc6' weights[0]: 7.585752e-03 [6.003272e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.100448e-09] 
Layer 'fc7' weights[0]: 7.485310e-03 [2.558331e-07] 
Layer 'fc7' biases: 9.998666e-01 [2.437995e-07] 
Layer 'fc8' weights[0]: 1.305204e-03 [9.161851e-06] 
Layer 'fc8' biases: 2.555429e-02 [6.251691e-05] 
Train error last 870 batches: 0.435286
-------------------------------------------------------
Not saving because 0.416352 > 0.415712 (4.190: -0.00%)
======================================================= (12.048 sec)
11.851... logprob:  0.440175, 0.117188 (1.505 sec)
11.852... logprob:  0.546217, 0.156250 (1.454 sec)
11.853... logprob:  0.371666, 0.093750 (1.459 sec)
11.854... logprob:  0.306800, 0.070312 (1.442 sec)
11.855... logprob:  0.485143, 0.132812 (1.447 sec)
11.856... logprob:  0.443960, 0.117188 (1.449 sec)
11.857... logprob:  0.372264, 0.093750 (1.491 sec)
11.858... logprob:  0.396249, 0.101562 (1.458 sec)
11.859... logprob:  0.307947, 0.070312 (1.470 sec)
11.860... logprob:  0.565900, 0.156250 (1.483 sec)
11.861... logprob:  0.417832, 0.109375 (1.455 sec)
11.862... logprob:  0.329007, 0.078125 (1.464 sec)
11.863... logprob:  0.399482, 0.101562 (1.446 sec)
11.864... logprob:  0.451330, 0.117188 (1.447 sec)
11.865... logprob:  0.484277, 0.132812 (1.460 sec)
11.866... logprob:  0.507340, 0.140625 (1.486 sec)
11.867... logprob:  0.502649, 0.140625 (1.468 sec)
11.868... logprob:  0.405505, 0.101562 (1.477 sec)
11.869... logprob:  0.383505, 0.093750 (1.477 sec)
11.870... logprob:  0.551809, 0.156250 (1.399 sec)
12.1... logprob:  0.380336, 0.093750 (1.407 sec)
12.2... logprob:  0.448301, 0.117188 (1.576 sec)
12.3... logprob:  0.398500, 0.101562 (1.422 sec)
12.4... logprob:  0.443385, 0.117188 (1.410 sec)
12.5... logprob:  0.443378, 0.117188 (1.434 sec)
12.6... logprob:  0.499292, 0.140625 (1.397 sec)
12.7... logprob:  0.362902, 0.085938 (1.416 sec)
12.8... logprob:  0.419079, 0.109375 (1.396 sec)
12.9... logprob:  0.358522, 0.085938 (1.411 sec)
12.10... logprob:  0.377272, 0.093750 (1.416 sec)
12.11... logprob:  0.334370, 0.078125 (1.449 sec)
12.12... logprob:  0.466671, 0.125000 (1.392 sec)
12.13... logprob:  0.442505, 0.117188 (1.428 sec)
12.14... logprob:  0.444914, 0.117188 (1.402 sec)
12.15... logprob:  0.395718, 0.101562 (1.408 sec)
12.16... logprob:  0.421515, 0.109375 (1.410 sec)
12.17... logprob:  0.516157, 0.140625 (1.392 sec)
12.18... logprob:  0.262131, 0.054688 (1.406 sec)
12.19... logprob:  0.279713, 0.062500 (1.401 sec)
12.20... logprob:  0.421384, 0.109375 (1.407 sec)
12.21... logprob:  0.443928, 0.117188 (0.891 sec)
12.22... logprob:  0.536463, 0.148438 (1.328 sec)
12.23... logprob:  0.532606, 0.148438 (1.416 sec)
12.24... logprob:  0.310935, 0.070312 (0.985 sec)
12.25... logprob:  0.356435, 0.085938 (0.959 sec)
12.26... logprob:  0.463608, 0.125000 (1.454 sec)
12.27... logprob:  0.404675, 0.101562 (1.389 sec)
12.28... logprob:  0.421893, 0.109375 (1.416 sec)
12.29... logprob:  0.396128, 0.101562 (1.418 sec)
12.30... logprob:  0.374240, 0.093750 (1.422 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.39518356323242, 10.0]}, 128)
batch 872: ({'logprob': [66.88472747802734, 19.0]}, 128)
batch 873: ({'logprob': [40.4564323425293, 9.0]}, 128)
batch 874: ({'logprob': [45.46778106689453, 11.0]}, 128)
batch 875: ({'logprob': [50.922096252441406, 13.0]}, 128)
batch 876: ({'logprob': [64.28045654296875, 18.0]}, 128)
batch 877: ({'logprob': [45.69384765625, 11.0]}, 128)
batch 878: ({'logprob': [61.864463806152344, 17.0]}, 128)
batch 879: ({'logprob': [73.0032958984375, 21.0]}, 128)
batch 880: ({'logprob': [50.93683624267578, 13.0]}, 128)
batch 881: ({'logprob': [29.288787841796875, 5.0]}, 128)
batch 882: ({'logprob': [54.22003173828125, 14.0]}, 128)
batch 883: ({'logprob': [61.85173416137695, 17.0]}, 128)
batch 884: ({'logprob': [51.142208099365234, 13.0]}, 128)
batch 885: ({'logprob': [51.58836364746094, 13.0]}, 128)
batch 886: ({'logprob': [62.08053207397461, 17.0]}, 128)

======================Test output======================
logprob:  0.416053, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.972137e-03 [2.316196e-09] 
Layer 'conv1' biases: 9.785268e-08 [5.989286e-11] 
Layer 'conv2' weights[0]: 7.959144e-03 [2.132323e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.375342e-10] 
Layer 'conv3' weights[0]: 7.957444e-03 [2.084270e-09] 
Layer 'conv3' biases: 8.759644e-07 [1.093258e-09] 
Layer 'conv4' weights[0]: 7.990009e-03 [2.342972e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.070524e-08] 
Layer 'conv5' weights[0]: 7.988909e-03 [7.375736e-08] 
Layer 'conv5' biases: 9.999991e-01 [8.014137e-08] 
Layer 'fc6' weights[0]: 7.585718e-03 [6.321377e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.405254e-09] 
Layer 'fc7' weights[0]: 7.483397e-03 [5.487257e-08] 
Layer 'fc7' biases: 9.998667e-01 [3.404891e-08] 
Layer 'fc8' weights[0]: 1.310870e-03 [1.719177e-06] 
Layer 'fc8' biases: 2.573512e-02 [1.167280e-05] 
Train error last 870 batches: 0.435286
-------------------------------------------------------
Not saving because 0.416053 > 0.415712 (4.190: -0.00%)
======================================================= (12.114 sec)
12.31... logprob:  0.479879, 0.132812 (1.406 sec)
12.32... logprob:  0.457245, 0.125000 (1.400 sec)
12.33... logprob:  0.460684, 0.125000 (1.445 sec)
12.34... logprob:  0.464687, 0.125000 (1.395 sec)
12.35... logprob:  0.316128, 0.070312 (1.398 sec)
12.36... logprob:  0.475819, 0.132812 (1.403 sec)
12.37... logprob:  0.417608, 0.109375 (1.410 sec)
12.38... logprob:  0.392450, 0.101562 (1.393 sec)
12.39... logprob:  0.632102, 0.187500 (1.436 sec)
12.40... logprob:  0.445903, 0.117188 (1.415 sec)
12.41... logprob:  0.352704, 0.085938 (1.426 sec)
12.42... logprob:  0.391796, 0.101562 (1.419 sec)
12.43... logprob:  0.440145, 0.117188 (1.409 sec)
12.44... logprob:  0.518484, 0.148438 (1.438 sec)
12.45... logprob:  0.381809, 0.093750 (1.392 sec)
12.46... logprob:  0.486432, 0.132812 (1.397 sec)
12.47... logprob:  0.331797, 0.078125 (1.396 sec)
12.48... logprob:  0.498860, 0.140625 (1.427 sec)
12.49... logprob:  0.510571, 0.148438 (1.414 sec)
12.50... logprob:  0.393280, 0.101562 (1.428 sec)
12.51... logprob:  0.489938, 0.140625 (1.416 sec)
12.52... logprob:  0.525776, 0.148438 (1.404 sec)
12.53... logprob:  0.295122, 0.062500 (1.447 sec)
12.54... logprob:  0.403215, 0.109375 (1.389 sec)
12.55... logprob:  0.331826, 0.078125 (1.398 sec)
12.56... logprob:  0.421740, 0.109375 (1.405 sec)
12.57... logprob:  0.572608, 0.164062 (1.429 sec)
12.58... logprob:  0.407829, 0.101562 (1.407 sec)
12.59... logprob:  0.333839, 0.078125 (1.466 sec)
12.60... logprob:  0.619145, 0.179688 (1.419 sec)
12.61... logprob:  0.382878, 0.093750 (1.426 sec)
12.62... logprob:  0.474936, 0.132812 (1.464 sec)
12.63... logprob:  0.397317, 0.101562 (1.439 sec)
12.64... logprob:  0.450255, 0.125000 (1.416 sec)
12.65... logprob:  0.373300, 0.093750 (1.401 sec)
12.66... logprob:  0.353990, 0.085938 (1.444 sec)
12.67... logprob:  0.295375, 0.062500 (1.392 sec)
12.68... logprob:  0.396830, 0.101562 (1.398 sec)
12.69... logprob:  0.496886, 0.140625 (1.429 sec)
12.70... logprob:  0.325876, 0.078125 (1.434 sec)
12.71... logprob:  0.381856, 0.101562 (1.462 sec)
12.72... logprob:  0.493889, 0.132812 (1.403 sec)
12.73... logprob:  0.447806, 0.117188 (1.428 sec)
12.74... logprob:  0.442619, 0.117188 (1.412 sec)
12.75... logprob:  0.380642, 0.093750 (1.423 sec)
12.76... logprob:  0.412101, 0.109375 (1.435 sec)
12.77... logprob:  0.396347, 0.101562 (1.429 sec)
12.78... logprob:  0.493071, 0.140625 (1.459 sec)
12.79... logprob:  0.456433, 0.125000 (1.402 sec)
12.80... logprob:  0.507837, 0.132812 (1.425 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.69032669067383, 10.0]}, 128)
batch 872: ({'logprob': [66.3088150024414, 19.0]}, 128)
batch 873: ({'logprob': [40.943172454833984, 9.0]}, 128)
batch 874: ({'logprob': [45.32158279418945, 11.0]}, 128)
batch 875: ({'logprob': [50.84465026855469, 13.0]}, 128)
batch 876: ({'logprob': [63.84492492675781, 18.0]}, 128)
batch 877: ({'logprob': [45.897804260253906, 11.0]}, 128)
batch 878: ({'logprob': [61.921165466308594, 17.0]}, 128)
batch 879: ({'logprob': [73.54325866699219, 21.0]}, 128)
batch 880: ({'logprob': [50.857940673828125, 13.0]}, 128)
batch 881: ({'logprob': [29.291229248046875, 5.0]}, 128)
batch 882: ({'logprob': [55.05029296875, 14.0]}, 128)
batch 883: ({'logprob': [61.90889358520508, 17.0]}, 128)
batch 884: ({'logprob': [51.41392135620117, 13.0]}, 128)
batch 885: ({'logprob': [52.5600471496582, 13.0]}, 128)
batch 886: ({'logprob': [62.48695373535156, 17.0]}, 128)

======================Test output======================
logprob:  0.416936, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.972101e-03 [3.320776e-09] 
Layer 'conv1' biases: 9.871948e-08 [7.330316e-11] 
Layer 'conv2' weights[0]: 7.959100e-03 [2.709738e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.765491e-10] 
Layer 'conv3' weights[0]: 7.957410e-03 [2.445248e-09] 
Layer 'conv3' biases: 8.823467e-07 [1.555330e-09] 
Layer 'conv4' weights[0]: 7.989976e-03 [2.865640e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.562745e-08] 
Layer 'conv5' weights[0]: 7.988881e-03 [1.074114e-07] 
Layer 'conv5' biases: 9.999992e-01 [1.167099e-07] 
Layer 'fc6' weights[0]: 7.585689e-03 [9.295661e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.359661e-09] 
Layer 'fc7' weights[0]: 7.481442e-03 [2.684310e-07] 
Layer 'fc7' biases: 9.998670e-01 [2.577407e-07] 
Layer 'fc8' weights[0]: 1.314781e-03 [9.225199e-06] 
Layer 'fc8' biases: 2.578455e-02 [5.603332e-05] 
Train error last 870 batches: 0.435286
-------------------------------------------------------
Not saving because 0.416936 > 0.415712 (4.190: -0.00%)
======================================================= (12.018 sec)
12.81... logprob:  0.416724, 0.109375 (1.423 sec)
12.82... logprob:  0.231980, 0.039062 (1.434 sec)
12.83... logprob:  0.493691, 0.140625 (1.397 sec)
12.84... logprob:  0.468068, 0.125000 (1.470 sec)
12.85... logprob:  0.432067, 0.117188 (1.422 sec)
12.86... logprob:  0.417016, 0.109375 (1.446 sec)
12.87... logprob:  0.633169, 0.187500 (1.418 sec)
12.88... logprob:  0.535135, 0.156250 (1.413 sec)
12.89... logprob:  0.410651, 0.109375 (1.433 sec)
12.90... logprob:  0.577529, 0.171875 (1.395 sec)
12.91... logprob:  0.348586, 0.078125 (1.394 sec)
12.92... logprob:  0.464461, 0.125000 (1.406 sec)
12.93... logprob:  0.492308, 0.140625 (1.400 sec)
12.94... logprob:  0.428785, 0.109375 (1.398 sec)
12.95... logprob:  0.471872, 0.125000 (1.402 sec)
12.96... logprob:  0.576413, 0.171875 (1.401 sec)
12.97... logprob:  0.430745, 0.117188 (1.396 sec)
12.98... logprob:  0.390974, 0.093750 (1.438 sec)
12.99... logprob:  0.474353, 0.132812 (1.410 sec)
12.100... logprob:  0.310279, 0.070312 (1.404 sec)
12.101... logprob:  0.310416, 0.062500 (1.452 sec)
12.102... logprob:  0.546519, 0.156250 (1.388 sec)
12.103... logprob:  0.541486, 0.156250 (1.404 sec)
12.104... logprob:  0.388895, 0.101562 (1.402 sec)
12.105... logprob:  0.619984, 0.179688 (1.394 sec)
12.106... logprob:  0.344420, 0.085938 (1.394 sec)
12.107... logprob:  0.335675, 0.078125 (1.443 sec)
12.108... logprob:  0.586784, 0.171875 (1.394 sec)
12.109... logprob:  0.336242, 0.078125 (1.406 sec)
12.110... logprob:  0.564344, 0.164062 (1.400 sec)
12.111... logprob:  0.404765, 0.101562 (1.401 sec)
12.112... logprob:  0.366263, 0.093750 (1.406 sec)
12.113... logprob:  0.354766, 0.085938 (1.399 sec)
12.114... logprob:  0.440244, 0.117188 (1.433 sec)
12.115... logprob:  0.506714, 0.140625 (1.410 sec)
12.116... logprob:  0.393430, 0.101562 (1.400 sec)
12.117... logprob:  0.440399, 0.117188 (1.450 sec)
12.118... logprob:  0.409204, 0.101562 (1.397 sec)
12.119... logprob:  0.346151, 0.085938 (1.399 sec)
12.120... logprob:  0.547170, 0.156250 (1.406 sec)
12.121... logprob:  0.412713, 0.109375 (1.395 sec)
12.122... logprob:  0.519411, 0.148438 (1.451 sec)
12.123... logprob:  0.463781, 0.125000 (1.394 sec)
12.124... logprob:  0.447727, 0.125000 (1.409 sec)
12.125... logprob:  0.502044, 0.140625 (1.398 sec)
12.126... logprob:  0.475834, 0.125000 (1.399 sec)
12.127... logprob:  0.479673, 0.125000 (1.406 sec)
12.128... logprob:  0.422401, 0.109375 (1.447 sec)
12.129... logprob:  0.574898, 0.164062 (1.423 sec)
12.130... logprob:  0.382778, 0.093750 (1.419 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.02067184448242, 10.0]}, 128)
batch 872: ({'logprob': [65.9321517944336, 19.0]}, 128)
batch 873: ({'logprob': [42.00064468383789, 9.0]}, 128)
batch 874: ({'logprob': [46.253231048583984, 11.0]}, 128)
batch 875: ({'logprob': [51.38277816772461, 13.0]}, 128)
batch 876: ({'logprob': [63.59785842895508, 18.0]}, 128)
batch 877: ({'logprob': [46.69671630859375, 11.0]}, 128)
batch 878: ({'logprob': [61.670677185058594, 17.0]}, 128)
batch 879: ({'logprob': [72.37100219726562, 21.0]}, 128)
batch 880: ({'logprob': [51.3961067199707, 13.0]}, 128)
batch 881: ({'logprob': [31.27207374572754, 5.0]}, 128)
batch 882: ({'logprob': [55.054359436035156, 14.0]}, 128)
batch 883: ({'logprob': [61.65825653076172, 17.0]}, 128)
batch 884: ({'logprob': [51.816165924072266, 13.0]}, 128)
batch 885: ({'logprob': [52.693092346191406, 13.0]}, 128)
batch 886: ({'logprob': [62.10110092163086, 17.0]}, 128)

======================Test output======================
logprob:  0.419393, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.972067e-03 [1.767599e-09] 
Layer 'conv1' biases: 9.932524e-08 [5.256109e-11] 
Layer 'conv2' weights[0]: 7.959056e-03 [1.606310e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.768388e-10] 
Layer 'conv3' weights[0]: 7.957370e-03 [1.597219e-09] 
Layer 'conv3' biases: 8.871843e-07 [9.151400e-10] 
Layer 'conv4' weights[0]: 7.989931e-03 [1.672025e-09] 
Layer 'conv4' biases: 9.999998e-01 [8.217715e-09] 
Layer 'conv5' weights[0]: 7.988841e-03 [5.080428e-08] 
Layer 'conv5' biases: 9.999994e-01 [5.507216e-08] 
Layer 'fc6' weights[0]: 7.585648e-03 [4.483799e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.464672e-09] 
Layer 'fc7' weights[0]: 7.479599e-03 [8.102928e-08] 
Layer 'fc7' biases: 9.998660e-01 [6.502093e-08] 
Layer 'fc8' weights[0]: 1.279107e-03 [7.655360e-06] 
Layer 'fc8' biases: 2.565309e-02 [4.918782e-05] 
Train error last 870 batches: 0.435286
-------------------------------------------------------
Not saving because 0.419393 > 0.415712 (4.190: -0.00%)
======================================================= (12.065 sec)
12.131... logprob:  0.495508, 0.132812 (1.410 sec)
12.132... logprob:  0.506398, 0.140625 (1.448 sec)
12.133... logprob:  0.444688, 0.117188 (1.391 sec)
12.134... logprob:  0.401937, 0.101562 (1.398 sec)
12.135... logprob:  0.460262, 0.125000 (1.404 sec)
12.136... logprob:  0.562645, 0.164062 (1.404 sec)
12.137... logprob:  0.462561, 0.125000 (1.404 sec)
12.138... logprob:  0.319317, 0.070312 (1.449 sec)
12.139... logprob:  0.395796, 0.101562 (1.398 sec)
12.140... logprob:  0.560645, 0.164062 (1.413 sec)
12.141... logprob:  0.464528, 0.125000 (1.444 sec)
12.142... logprob:  0.464603, 0.125000 (1.393 sec)
12.143... logprob:  0.294211, 0.062500 (1.426 sec)
12.144... logprob:  0.457389, 0.125000 (1.416 sec)
12.145... logprob:  0.324915, 0.078125 (1.419 sec)
12.146... logprob:  0.483287, 0.132812 (1.408 sec)
12.147... logprob:  0.262468, 0.054688 (1.435 sec)
12.148... logprob:  0.458898, 0.125000 (1.390 sec)
12.149... logprob:  0.442587, 0.117188 (1.402 sec)
12.150... logprob:  0.347648, 0.085938 (1.405 sec)
12.151... logprob:  0.347160, 0.085938 (1.404 sec)
12.152... logprob:  0.784964, 0.234375 (1.390 sec)
12.153... logprob:  0.381676, 0.093750 (1.444 sec)
12.154... logprob:  0.524288, 0.148438 (1.400 sec)
12.155... logprob:  0.425947, 0.117188 (1.410 sec)
12.156... logprob:  0.296113, 0.062500 (1.437 sec)
12.157... logprob:  0.271029, 0.054688 (1.400 sec)
12.158... logprob:  0.455351, 0.125000 (1.403 sec)
12.159... logprob:  0.483118, 0.132812 (1.393 sec)
12.160... logprob:  0.444946, 0.117188 (1.392 sec)
12.161... logprob:  0.350281, 0.078125 (1.402 sec)
12.162... logprob:  0.611812, 0.179688 (1.422 sec)
12.163... logprob:  0.450419, 0.125000 (1.431 sec)
12.164... logprob:  0.468739, 0.125000 (1.427 sec)
12.165... logprob:  0.548024, 0.156250 (1.421 sec)
12.166... logprob:  0.446045, 0.125000 (1.449 sec)
12.167... logprob:  0.350346, 0.085938 (1.431 sec)
12.168... logprob:  0.363643, 0.085938 (1.423 sec)
12.169... logprob:  0.408698, 0.101562 (1.466 sec)
12.170... logprob:  0.459506, 0.125000 (1.401 sec)
12.171... logprob:  0.535553, 0.156250 (1.422 sec)
12.172... logprob:  0.434889, 0.109375 (1.416 sec)
12.173... logprob:  0.440510, 0.117188 (1.430 sec)
12.174... logprob:  0.601291, 0.171875 (1.417 sec)
12.175... logprob:  0.506176, 0.140625 (1.466 sec)
12.176... logprob:  0.478525, 0.132812 (1.423 sec)
12.177... logprob:  0.289800, 0.054688 (1.426 sec)
12.178... logprob:  0.383501, 0.093750 (1.458 sec)
12.179... logprob:  0.394754, 0.101562 (1.410 sec)
12.180... logprob:  0.466381, 0.125000 (1.426 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.01462173461914, 10.0]}, 128)
batch 872: ({'logprob': [66.51248931884766, 19.0]}, 128)
batch 873: ({'logprob': [40.68497085571289, 9.0]}, 128)
batch 874: ({'logprob': [45.36348342895508, 11.0]}, 128)
batch 875: ({'logprob': [50.83984375, 13.0]}, 128)
batch 876: ({'logprob': [63.985782623291016, 18.0]}, 128)
batch 877: ({'logprob': [45.76681137084961, 11.0]}, 128)
batch 878: ({'logprob': [61.82496643066406, 17.0]}, 128)
batch 879: ({'logprob': [73.1827621459961, 21.0]}, 128)
batch 880: ({'logprob': [50.85405349731445, 13.0]}, 128)
batch 881: ({'logprob': [29.2976131439209, 5.0]}, 128)
batch 882: ({'logprob': [54.590660095214844, 14.0]}, 128)
batch 883: ({'logprob': [61.81224822998047, 17.0]}, 128)
batch 884: ({'logprob': [51.236568450927734, 13.0]}, 128)
batch 885: ({'logprob': [52.0366096496582, 13.0]}, 128)
batch 886: ({'logprob': [62.217796325683594, 17.0]}, 128)

======================Test output======================
logprob:  0.416124, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.972032e-03 [2.148857e-09] 
Layer 'conv1' biases: 1.000669e-07 [4.988013e-11] 
Layer 'conv2' weights[0]: 7.959019e-03 [1.680576e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.147050e-10] 
Layer 'conv3' weights[0]: 7.957332e-03 [1.588847e-09] 
Layer 'conv3' biases: 8.929505e-07 [7.190925e-10] 
Layer 'conv4' weights[0]: 7.989895e-03 [1.662307e-09] 
Layer 'conv4' biases: 9.999998e-01 [5.578220e-09] 
Layer 'conv5' weights[0]: 7.988791e-03 [3.491495e-08] 
Layer 'conv5' biases: 9.999988e-01 [3.769660e-08] 
Layer 'fc6' weights[0]: 7.585612e-03 [3.110196e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.066143e-09] 
Layer 'fc7' weights[0]: 7.477698e-03 [1.223507e-07] 
Layer 'fc7' biases: 9.998666e-01 [1.073696e-07] 
Layer 'fc8' weights[0]: 1.318723e-03 [1.060187e-05] 
Layer 'fc8' biases: 2.603072e-02 [6.896440e-05] 
Train error last 870 batches: 0.435285
-------------------------------------------------------
Not saving because 0.416124 > 0.415712 (4.190: -0.00%)
======================================================= (12.105 sec)
12.181... logprob:  0.539439, 0.156250 (1.433 sec)
12.182... logprob:  0.371446, 0.093750 (1.424 sec)
12.183... logprob:  0.419972, 0.109375 (1.423 sec)
12.184... logprob:  0.483494, 0.132812 (1.421 sec)
12.185... logprob:  0.289914, 0.062500 (1.397 sec)
12.186... logprob:  0.370554, 0.093750 (1.403 sec)
12.187... logprob:  0.529639, 0.148438 (1.409 sec)
12.188... logprob:  0.459027, 0.125000 (1.399 sec)
12.189... logprob:  0.440904, 0.117188 (1.393 sec)
12.190... logprob:  0.375728, 0.093750 (1.434 sec)
12.191... logprob:  0.485110, 0.132812 (1.408 sec)
12.192... logprob:  0.520211, 0.148438 (1.420 sec)
12.193... logprob:  0.312660, 0.070312 (1.420 sec)
12.194... logprob:  0.414129, 0.109375 (1.415 sec)
12.195... logprob:  0.287292, 0.062500 (1.415 sec)
12.196... logprob:  0.410579, 0.109375 (1.407 sec)
12.197... logprob:  0.478043, 0.132812 (1.402 sec)
12.198... logprob:  0.355792, 0.085938 (1.403 sec)
12.199... logprob:  0.437195, 0.117188 (1.385 sec)
12.200... logprob:  0.440789, 0.117188 (1.446 sec)
12.201... logprob:  0.437103, 0.117188 (1.404 sec)
12.202... logprob:  0.538010, 0.148438 (1.408 sec)
12.203... logprob:  0.420478, 0.109375 (1.440 sec)
12.204... logprob:  0.504129, 0.140625 (1.397 sec)
12.205... logprob:  0.334421, 0.078125 (1.405 sec)
12.206... logprob:  0.361637, 0.093750 (1.403 sec)
12.207... logprob:  0.381943, 0.093750 (1.391 sec)
12.208... logprob:  0.490509, 0.140625 (1.405 sec)
12.209... logprob:  0.334619, 0.078125 (1.427 sec)
12.210... logprob:  0.586258, 0.171875 (1.421 sec)
12.211... logprob:  0.488212, 0.132812 (1.422 sec)
12.212... logprob:  0.526162, 0.148438 (1.414 sec)
12.213... logprob:  0.514860, 0.140625 (1.467 sec)
12.214... logprob:  0.459452, 0.125000 (1.428 sec)
12.215... logprob:  0.396166, 0.101562 (1.417 sec)
12.216... logprob:  0.517160, 0.140625 (1.469 sec)
12.217... logprob:  0.325170, 0.070312 (1.399 sec)
12.218... logprob:  0.463733, 0.125000 (1.427 sec)
12.219... logprob:  0.500335, 0.140625 (1.418 sec)
12.220... logprob:  0.414992, 0.109375 (1.418 sec)
12.221... logprob:  0.399535, 0.101562 (1.416 sec)
12.222... logprob:  0.554628, 0.164062 (1.463 sec)
12.223... logprob:  0.569323, 0.164062 (1.432 sec)
12.224... logprob:  0.405850, 0.101562 (1.428 sec)
12.225... logprob:  0.391962, 0.101562 (1.451 sec)
12.226... logprob:  0.424608, 0.109375 (1.425 sec)
12.227... logprob:  0.452768, 0.125000 (1.413 sec)
12.228... logprob:  0.417212, 0.109375 (1.422 sec)
12.229... logprob:  0.489372, 0.132812 (1.421 sec)
12.230... logprob:  0.459911, 0.125000 (1.428 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.99626541137695, 10.0]}, 128)
batch 872: ({'logprob': [66.47234344482422, 19.0]}, 128)
batch 873: ({'logprob': [40.72750473022461, 9.0]}, 128)
batch 874: ({'logprob': [45.369041442871094, 11.0]}, 128)
batch 875: ({'logprob': [50.84251403808594, 13.0]}, 128)
batch 876: ({'logprob': [63.955692291259766, 18.0]}, 128)
batch 877: ({'logprob': [45.7894401550293, 11.0]}, 128)
batch 878: ({'logprob': [61.82181167602539, 17.0]}, 128)
batch 879: ({'logprob': [73.19047546386719, 21.0]}, 128)
batch 880: ({'logprob': [50.8568115234375, 13.0]}, 128)
batch 881: ({'logprob': [29.329099655151367, 5.0]}, 128)
batch 882: ({'logprob': [54.634246826171875, 14.0]}, 128)
batch 883: ({'logprob': [61.80891418457031, 17.0]}, 128)
batch 884: ({'logprob': [51.25618362426758, 13.0]}, 128)
batch 885: ({'logprob': [52.0900993347168, 13.0]}, 128)
batch 886: ({'logprob': [62.2315788269043, 17.0]}, 128)

======================Test output======================
logprob:  0.416197, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.971990e-03 [1.911891e-09] 
Layer 'conv1' biases: 1.008284e-07 [4.515710e-11] 
Layer 'conv2' weights[0]: 7.958980e-03 [1.629024e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.892754e-10] 
Layer 'conv3' weights[0]: 7.957288e-03 [1.331624e-09] 
Layer 'conv3' biases: 9.000261e-07 [5.578991e-10] 
Layer 'conv4' weights[0]: 7.989855e-03 [1.356391e-09] 
Layer 'conv4' biases: 9.999998e-01 [4.030683e-09] 
Layer 'conv5' weights[0]: 7.988757e-03 [2.742905e-08] 
Layer 'conv5' biases: 9.999989e-01 [2.981005e-08] 
Layer 'fc6' weights[0]: 7.585573e-03 [2.511307e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.399346e-09] 
Layer 'fc7' weights[0]: 7.475739e-03 [4.221342e-08] 
Layer 'fc7' biases: 9.998665e-01 [1.577972e-08] 
Layer 'fc8' weights[0]: 1.321118e-03 [2.024475e-06] 
Layer 'fc8' biases: 2.610624e-02 [1.356462e-05] 
Train error last 870 batches: 0.435285
-------------------------------------------------------
Not saving because 0.416197 > 0.415712 (4.190: -0.00%)
======================================================= (12.098 sec)
12.231... logprob:  0.453555, 0.125000 (1.418 sec)
12.232... logprob:  0.496241, 0.140625 (1.470 sec)
12.233... logprob:  0.466189, 0.132812 (1.432 sec)
12.234... logprob:  0.563784, 0.164062 (1.424 sec)
12.235... logprob:  0.482040, 0.132812 (1.474 sec)
12.236... logprob:  0.425839, 0.109375 (1.398 sec)
12.237... logprob:  0.341439, 0.078125 (1.429 sec)
12.238... logprob:  0.389448, 0.093750 (1.422 sec)
12.239... logprob:  0.478163, 0.132812 (1.424 sec)
12.240... logprob:  0.485815, 0.132812 (1.403 sec)
12.241... logprob:  0.493611, 0.132812 (1.469 sec)
12.242... logprob:  0.341654, 0.078125 (1.431 sec)
12.243... logprob:  0.386027, 0.093750 (1.440 sec)
12.244... logprob:  0.315176, 0.070312 (1.454 sec)
12.245... logprob:  0.494395, 0.132812 (1.419 sec)
12.246... logprob:  0.416926, 0.109375 (1.421 sec)
12.247... logprob:  0.357311, 0.085938 (1.415 sec)
12.248... logprob:  0.307679, 0.070312 (1.420 sec)
12.249... logprob:  0.555663, 0.156250 (1.422 sec)
12.250... logprob:  0.591895, 0.164062 (1.407 sec)
12.251... logprob:  0.352895, 0.085938 (1.458 sec)
12.252... logprob:  0.348502, 0.085938 (1.431 sec)
12.253... logprob:  0.379172, 0.093750 (1.414 sec)
12.254... logprob:  0.444187, 0.117188 (1.472 sec)
12.255... logprob:  0.351534, 0.085938 (1.402 sec)
12.256... logprob:  0.378729, 0.093750 (1.424 sec)
12.257... logprob:  0.332074, 0.078125 (1.419 sec)
12.258... logprob:  0.415813, 0.109375 (1.422 sec)
12.259... logprob:  0.442309, 0.117188 (1.404 sec)
12.260... logprob:  0.308445, 0.070312 (1.456 sec)
12.261... logprob:  0.392856, 0.101562 (1.428 sec)
12.262... logprob:  0.524686, 0.148438 (1.433 sec)
12.263... logprob:  0.425462, 0.109375 (1.448 sec)
12.264... logprob:  0.375187, 0.093750 (1.426 sec)
12.265... logprob:  0.439615, 0.117188 (1.419 sec)
12.266... logprob:  0.439048, 0.117188 (1.419 sec)
12.267... logprob:  0.422000, 0.109375 (1.424 sec)
12.268... logprob:  0.458950, 0.125000 (1.427 sec)
12.269... logprob:  0.567452, 0.164062 (1.407 sec)
12.270... logprob:  0.542187, 0.156250 (1.466 sec)
12.271... logprob:  0.445785, 0.117188 (1.432 sec)
12.272... logprob:  0.384804, 0.093750 (1.421 sec)
12.273... logprob:  0.500216, 0.140625 (1.467 sec)
12.274... logprob:  0.542543, 0.156250 (1.405 sec)
12.275... logprob:  0.487770, 0.132812 (1.423 sec)
12.276... logprob:  0.390212, 0.093750 (1.414 sec)
12.277... logprob:  0.428749, 0.109375 (1.429 sec)
12.278... logprob:  0.323346, 0.070312 (1.422 sec)
12.279... logprob:  0.324897, 0.070312 (1.468 sec)
12.280... logprob:  0.214971, 0.031250 (1.409 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.91220474243164, 10.0]}, 128)
batch 872: ({'logprob': [66.70503234863281, 19.0]}, 128)
batch 873: ({'logprob': [40.45820999145508, 9.0]}, 128)
batch 874: ({'logprob': [45.252532958984375, 11.0]}, 128)
batch 875: ({'logprob': [50.79111862182617, 13.0]}, 128)
batch 876: ({'logprob': [64.13412475585938, 18.0]}, 128)
batch 877: ({'logprob': [45.62901306152344, 11.0]}, 128)
batch 878: ({'logprob': [61.90171813964844, 17.0]}, 128)
batch 879: ({'logprob': [73.35816192626953, 21.0]}, 128)
batch 880: ({'logprob': [50.80562973022461, 13.0]}, 128)
batch 881: ({'logprob': [28.971982955932617, 5.0]}, 128)
batch 882: ({'logprob': [54.50727462768555, 14.0]}, 128)
batch 883: ({'logprob': [61.88884353637695, 17.0]}, 128)
batch 884: ({'logprob': [51.16179656982422, 13.0]}, 128)
batch 885: ({'logprob': [51.9086799621582, 13.0]}, 128)
batch 886: ({'logprob': [62.268226623535156, 17.0]}, 128)

======================Test output======================
logprob:  0.415847, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.971952e-03 [7.437359e-09] 
Layer 'conv1' biases: 1.016033e-07 [2.783646e-10] 
Layer 'conv2' weights[0]: 7.958941e-03 [7.338015e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.598722e-09] 
Layer 'conv3' weights[0]: 7.957243e-03 [7.551852e-09] 
Layer 'conv3' biases: 9.030747e-07 [5.036956e-09] 
Layer 'conv4' weights[0]: 7.989813e-03 [8.346163e-09] 
Layer 'conv4' biases: 9.999998e-01 [4.949098e-08] 
Layer 'conv5' weights[0]: 7.988737e-03 [3.364881e-07] 
Layer 'conv5' biases: 9.999982e-01 [3.652590e-07] 
Layer 'fc6' weights[0]: 7.585533e-03 [2.870234e-08] 
Layer 'fc6' biases: 1.000000e+00 [2.928492e-08] 
Layer 'fc7' weights[0]: 7.473840e-03 [6.758452e-07] 
Layer 'fc7' biases: 9.998664e-01 [6.582751e-07] 
Layer 'fc8' weights[0]: 1.330984e-03 [2.449628e-05] 
Layer 'fc8' biases: 2.627432e-02 [1.657508e-04] 
Train error last 870 batches: 0.435285
-------------------------------------------------------
Not saving because 0.415847 > 0.415712 (4.190: -0.00%)
======================================================= (12.036 sec)
12.281... logprob:  0.417215, 0.109375 (1.435 sec)
12.282... logprob:  0.411512, 0.109375 (1.428 sec)
12.283... logprob:  0.393897, 0.101562 (1.421 sec)
12.284... logprob:  0.394777, 0.101562 (1.415 sec)
12.285... logprob:  0.452343, 0.117188 (1.449 sec)
12.286... logprob:  0.537770, 0.140625 (1.439 sec)
12.287... logprob:  0.346717, 0.085938 (1.430 sec)
12.288... logprob:  0.329988, 0.078125 (1.439 sec)
12.289... logprob:  0.446076, 0.117188 (1.444 sec)
12.290... logprob:  0.490650, 0.132812 (1.408 sec)
12.291... logprob:  0.439116, 0.117188 (1.420 sec)
12.292... logprob:  0.566865, 0.156250 (1.416 sec)
12.293... logprob:  0.427441, 0.117188 (1.428 sec)
12.294... logprob:  0.356312, 0.085938 (1.409 sec)
12.295... logprob:  0.335326, 0.078125 (1.467 sec)
12.296... logprob:  0.356393, 0.085938 (1.418 sec)
12.297... logprob:  0.394933, 0.101562 (1.426 sec)
12.298... logprob:  0.448086, 0.125000 (1.464 sec)
12.299... logprob:  0.342794, 0.078125 (1.404 sec)
12.300... logprob:  0.406761, 0.101562 (1.424 sec)
12.301... logprob:  0.397979, 0.101562 (1.417 sec)
12.302... logprob:  0.591576, 0.179688 (1.421 sec)
12.303... logprob:  0.459680, 0.125000 (1.406 sec)
12.304... logprob:  0.459740, 0.125000 (1.474 sec)
12.305... logprob:  0.455258, 0.125000 (1.442 sec)
12.306... logprob:  0.440623, 0.117188 (1.434 sec)
12.307... logprob:  0.421594, 0.109375 (1.438 sec)
12.308... logprob:  0.374491, 0.093750 (1.454 sec)
12.309... logprob:  0.450501, 0.125000 (1.417 sec)
12.310... logprob:  0.473800, 0.125000 (1.432 sec)
12.311... logprob:  0.502713, 0.140625 (1.424 sec)
12.312... logprob:  0.478830, 0.132812 (1.430 sec)
12.313... logprob:  0.454878, 0.125000 (1.420 sec)
12.314... logprob:  0.454553, 0.117188 (1.468 sec)
12.315... logprob:  0.314711, 0.070312 (1.436 sec)
12.316... logprob:  0.468597, 0.125000 (1.422 sec)
12.317... logprob:  0.355559, 0.085938 (1.481 sec)
12.318... logprob:  0.455425, 0.125000 (1.414 sec)
12.319... logprob:  0.423224, 0.117188 (1.423 sec)
12.320... logprob:  0.412273, 0.109375 (1.430 sec)
12.321... logprob:  0.348310, 0.085938 (1.426 sec)
12.322... logprob:  0.387550, 0.101562 (1.413 sec)
12.323... logprob:  0.416532, 0.109375 (1.474 sec)
12.324... logprob:  0.498651, 0.140625 (1.431 sec)
12.325... logprob:  0.350683, 0.085938 (1.435 sec)
12.326... logprob:  0.543208, 0.148438 (1.465 sec)
12.327... logprob:  0.554417, 0.164062 (1.424 sec)
12.328... logprob:  0.565000, 0.156250 (1.424 sec)
12.329... logprob:  0.402025, 0.101562 (1.424 sec)
12.330... logprob:  0.388709, 0.101562 (1.427 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.12510299682617, 10.0]}, 128)
batch 872: ({'logprob': [65.9638900756836, 19.0]}, 128)
batch 873: ({'logprob': [41.573143005371094, 9.0]}, 128)
batch 874: ({'logprob': [45.71855545043945, 11.0]}, 128)
batch 875: ({'logprob': [51.07245635986328, 13.0]}, 128)
batch 876: ({'logprob': [63.600406646728516, 18.0]}, 128)
batch 877: ({'logprob': [46.32709884643555, 11.0]}, 128)
batch 878: ({'logprob': [61.809478759765625, 17.0]}, 128)
batch 879: ({'logprob': [73.1231689453125, 21.0]}, 128)
batch 880: ({'logprob': [51.08575439453125, 13.0]}, 128)
batch 881: ({'logprob': [30.229719161987305, 5.0]}, 128)
batch 882: ({'logprob': [55.271263122558594, 14.0]}, 128)
batch 883: ({'logprob': [61.79683303833008, 17.0]}, 128)
batch 884: ({'logprob': [51.67234420776367, 13.0]}, 128)
batch 885: ({'logprob': [52.881072998046875, 13.0]}, 128)
batch 886: ({'logprob': [62.40610122680664, 17.0]}, 128)

======================Test output======================
logprob:  0.418289, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.971919e-03 [2.298239e-09] 
Layer 'conv1' biases: 1.024601e-07 [3.658163e-11] 
Layer 'conv2' weights[0]: 7.958903e-03 [1.628914e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.384987e-10] 
Layer 'conv3' weights[0]: 7.957207e-03 [1.199346e-09] 
Layer 'conv3' biases: 9.129465e-07 [3.413001e-10] 
Layer 'conv4' weights[0]: 7.989775e-03 [1.141167e-09] 
Layer 'conv4' biases: 9.999998e-01 [8.536734e-10] 
Layer 'conv5' weights[0]: 7.988684e-03 [5.825850e-09] 
Layer 'conv5' biases: 9.999995e-01 [6.290390e-09] 
Layer 'fc6' weights[0]: 7.585501e-03 [9.120017e-10] 
Layer 'fc6' biases: 1.000000e+00 [4.810036e-10] 
Layer 'fc7' weights[0]: 7.471973e-03 [2.187182e-07] 
Layer 'fc7' biases: 9.998662e-01 [2.072873e-07] 
Layer 'fc8' weights[0]: 1.304999e-03 [8.167271e-06] 
Layer 'fc8' biases: 2.637482e-02 [4.868064e-05] 
Train error last 870 batches: 0.435284
-------------------------------------------------------
Not saving because 0.418289 > 0.415712 (4.190: -0.00%)
======================================================= (12.111 sec)
12.331... logprob:  0.352607, 0.085938 (1.431 sec)
12.332... logprob:  0.482798, 0.132812 (1.450 sec)
12.333... logprob:  0.339680, 0.085938 (1.447 sec)
12.334... logprob:  0.565068, 0.171875 (1.440 sec)
12.335... logprob:  0.358911, 0.085938 (1.444 sec)
12.336... logprob:  0.444827, 0.125000 (1.453 sec)
12.337... logprob:  0.566500, 0.164062 (1.442 sec)
12.338... logprob:  0.449519, 0.125000 (1.426 sec)
12.339... logprob:  0.488735, 0.132812 (1.434 sec)
12.340... logprob:  0.442080, 0.117188 (1.429 sec)
12.341... logprob:  0.530176, 0.148438 (1.421 sec)
12.342... logprob:  0.429703, 0.109375 (1.466 sec)
12.343... logprob:  0.434790, 0.109375 (1.438 sec)
12.344... logprob:  0.444401, 0.125000 (1.487 sec)
12.345... logprob:  0.488287, 0.132812 (1.438 sec)
12.346... logprob:  0.436259, 0.117188 (1.437 sec)
12.347... logprob:  0.372309, 0.085938 (1.485 sec)
12.348... logprob:  0.398434, 0.101562 (1.434 sec)
12.349... logprob:  0.497959, 0.140625 (1.439 sec)
12.350... logprob:  0.358516, 0.085938 (1.433 sec)
12.351... logprob:  0.508734, 0.140625 (1.433 sec)
12.352... logprob:  0.363679, 0.093750 (1.432 sec)
12.353... logprob:  0.512879, 0.148438 (1.495 sec)
12.354... logprob:  0.675229, 0.203125 (1.430 sec)
12.355... logprob:  0.357473, 0.085938 (1.447 sec)
12.356... logprob:  0.479259, 0.132812 (1.481 sec)
12.357... logprob:  0.347122, 0.085938 (1.430 sec)
12.358... logprob:  0.326108, 0.070312 (1.442 sec)
12.359... logprob:  0.555188, 0.164062 (1.431 sec)
12.360... logprob:  0.444519, 0.117188 (1.433 sec)
12.361... logprob:  0.410796, 0.101562 (1.432 sec)
12.362... logprob:  0.424183, 0.117188 (1.481 sec)
12.363... logprob:  0.486592, 0.132812 (1.448 sec)
12.364... logprob:  0.475532, 0.125000 (1.456 sec)
12.365... logprob:  0.425107, 0.109375 (1.465 sec)
12.366... logprob:  0.409730, 0.109375 (1.443 sec)
12.367... logprob:  0.325024, 0.078125 (1.438 sec)
12.368... logprob:  0.595743, 0.171875 (1.433 sec)
12.369... logprob:  0.381505, 0.093750 (1.426 sec)
12.370... logprob:  0.381132, 0.093750 (1.441 sec)
12.371... logprob:  0.400332, 0.101562 (1.456 sec)
12.372... logprob:  0.537689, 0.156250 (1.458 sec)
12.373... logprob:  0.463845, 0.125000 (1.455 sec)
12.374... logprob:  0.527152, 0.148438 (1.452 sec)
12.375... logprob:  0.393788, 0.101562 (1.466 sec)
12.376... logprob:  0.374328, 0.093750 (1.440 sec)
12.377... logprob:  0.295376, 0.062500 (1.428 sec)
12.378... logprob:  0.453792, 0.125000 (1.448 sec)
12.379... logprob:  0.420239, 0.109375 (1.439 sec)
12.380... logprob:  0.605770, 0.179688 (1.441 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.81587219238281, 10.0]}, 128)
batch 872: ({'logprob': [66.62747192382812, 19.0]}, 128)
batch 873: ({'logprob': [40.52333450317383, 9.0]}, 128)
batch 874: ({'logprob': [45.232093811035156, 11.0]}, 128)
batch 875: ({'logprob': [50.780311584472656, 13.0]}, 128)
batch 876: ({'logprob': [64.07550048828125, 18.0]}, 128)
batch 877: ({'logprob': [45.656124114990234, 11.0]}, 128)
batch 878: ({'logprob': [61.90985107421875, 17.0]}, 128)
batch 879: ({'logprob': [73.43238830566406, 21.0]}, 128)
batch 880: ({'logprob': [50.79481506347656, 13.0]}, 128)
batch 881: ({'logprob': [28.970853805541992, 5.0]}, 128)
batch 882: ({'logprob': [54.619869232177734, 14.0]}, 128)
batch 883: ({'logprob': [61.89682388305664, 17.0]}, 128)
batch 884: ({'logprob': [51.19850540161133, 13.0]}, 128)
batch 885: ({'logprob': [52.040374755859375, 13.0]}, 128)
batch 886: ({'logprob': [62.32380676269531, 17.0]}, 128)

======================Test output======================
logprob:  0.415966, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.971875e-03 [3.553595e-09] 
Layer 'conv1' biases: 1.031290e-07 [1.332858e-10] 
Layer 'conv2' weights[0]: 7.958861e-03 [2.966198e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.895783e-10] 
Layer 'conv3' weights[0]: 7.957171e-03 [3.215645e-09] 
Layer 'conv3' biases: 9.174469e-07 [2.169085e-09] 
Layer 'conv4' weights[0]: 7.989733e-03 [3.307826e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.966187e-08] 
Layer 'conv5' weights[0]: 7.988640e-03 [1.308400e-07] 
Layer 'conv5' biases: 9.999990e-01 [1.418859e-07] 
Layer 'fc6' weights[0]: 7.585467e-03 [1.122979e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.151498e-08] 
Layer 'fc7' weights[0]: 7.470086e-03 [1.148586e-07] 
Layer 'fc7' biases: 9.998665e-01 [1.007366e-07] 
Layer 'fc8' weights[0]: 1.328394e-03 [4.881016e-06] 
Layer 'fc8' biases: 2.662106e-02 [3.021240e-05] 
Train error last 870 batches: 0.435284
-------------------------------------------------------
Not saving because 0.415966 > 0.415712 (4.190: -0.00%)
======================================================= (12.076 sec)
12.381... logprob:  0.463508, 0.125000 (1.480 sec)
12.382... logprob:  0.529482, 0.148438 (1.450 sec)
12.383... logprob:  0.358749, 0.085938 (1.445 sec)
12.384... logprob:  0.520998, 0.148438 (1.485 sec)
12.385... logprob:  0.523437, 0.148438 (1.435 sec)
12.386... logprob:  0.582274, 0.171875 (1.433 sec)
12.387... logprob:  0.428737, 0.117188 (1.437 sec)
12.388... logprob:  0.521294, 0.148438 (1.442 sec)
12.389... logprob:  0.426009, 0.109375 (1.434 sec)
12.390... logprob:  0.420005, 0.109375 (1.480 sec)
12.391... logprob:  0.318433, 0.070312 (1.447 sec)
12.392... logprob:  0.439414, 0.117188 (1.430 sec)
12.393... logprob:  0.368783, 0.093750 (1.486 sec)
12.394... logprob:  0.343400, 0.078125 (1.429 sec)
12.395... logprob:  0.331444, 0.078125 (1.429 sec)
12.396... logprob:  0.251597, 0.046875 (1.433 sec)
12.397... logprob:  0.484955, 0.132812 (1.434 sec)
12.398... logprob:  0.471707, 0.125000 (1.439 sec)
12.399... logprob:  0.433928, 0.117188 (1.485 sec)
12.400... logprob:  0.538969, 0.148438 (1.438 sec)
12.401... logprob:  0.466378, 0.125000 (1.441 sec)
12.402... logprob:  0.474423, 0.125000 (1.483 sec)
12.403... logprob:  0.462291, 0.125000 (1.434 sec)
12.404... logprob:  0.474827, 0.125000 (1.439 sec)
12.405... logprob:  0.543689, 0.156250 (1.435 sec)
12.406... logprob:  0.358046, 0.085938 (1.426 sec)
12.407... logprob:  0.492567, 0.140625 (1.431 sec)
12.408... logprob:  0.340083, 0.078125 (1.479 sec)
12.409... logprob:  0.401235, 0.101562 (1.434 sec)
12.410... logprob:  0.581546, 0.171875 (1.453 sec)
12.411... logprob:  0.398508, 0.101562 (1.497 sec)
12.412... logprob:  0.540171, 0.156250 (1.435 sec)
12.413... logprob:  0.544741, 0.156250 (1.437 sec)
12.414... logprob:  0.466719, 0.125000 (1.435 sec)
12.415... logprob:  0.401827, 0.101562 (1.424 sec)
12.416... logprob:  0.427581, 0.109375 (1.441 sec)
12.417... logprob:  0.405367, 0.093750 (1.464 sec)
12.418... logprob:  0.379919, 0.093750 (1.455 sec)
12.419... logprob:  0.417422, 0.101562 (1.457 sec)
12.420... logprob:  0.355642, 0.085938 (1.454 sec)
12.421... logprob:  0.376500, 0.101562 (1.460 sec)
12.422... logprob:  0.523555, 0.148438 (1.439 sec)
12.423... logprob:  0.421154, 0.109375 (1.425 sec)
12.424... logprob:  0.324495, 0.078125 (1.433 sec)
12.425... logprob:  0.305975, 0.070312 (1.439 sec)
12.426... logprob:  0.449603, 0.117188 (1.449 sec)
12.427... logprob:  0.555429, 0.156250 (1.464 sec)
12.428... logprob:  0.602621, 0.171875 (1.452 sec)
12.429... logprob:  0.426232, 0.109375 (1.443 sec)
12.430... logprob:  0.300074, 0.070312 (1.475 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.242618560791016, 10.0]}, 128)
batch 872: ({'logprob': [67.18780517578125, 19.0]}, 128)
batch 873: ({'logprob': [40.056236267089844, 9.0]}, 128)
batch 874: ({'logprob': [44.889774322509766, 11.0]}, 128)
batch 875: ({'logprob': [50.696929931640625, 13.0]}, 128)
batch 876: ({'logprob': [64.5400619506836, 18.0]}, 128)
batch 877: ({'logprob': [45.38025665283203, 11.0]}, 128)
batch 878: ({'logprob': [62.34527587890625, 17.0]}, 128)
batch 879: ({'logprob': [74.45349884033203, 21.0]}, 128)
batch 880: ({'logprob': [50.7113151550293, 13.0]}, 128)
batch 881: ({'logprob': [27.917251586914062, 5.0]}, 128)
batch 882: ({'logprob': [54.835453033447266, 14.0]}, 128)
batch 883: ({'logprob': [62.332454681396484, 17.0]}, 128)
batch 884: ({'logprob': [51.183570861816406, 13.0]}, 128)
batch 885: ({'logprob': [52.16056442260742, 13.0]}, 128)
batch 886: ({'logprob': [62.82725143432617, 17.0]}, 128)

======================Test output======================
logprob:  0.416387, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.971839e-03 [1.914859e-09] 
Layer 'conv1' biases: 1.038712e-07 [3.285553e-11] 
Layer 'conv2' weights[0]: 7.958824e-03 [1.606384e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.989995e-10] 
Layer 'conv3' weights[0]: 7.957132e-03 [1.372087e-09] 
Layer 'conv3' biases: 9.227980e-07 [6.119124e-10] 
Layer 'conv4' weights[0]: 7.989694e-03 [1.408151e-09] 
Layer 'conv4' biases: 9.999998e-01 [4.810863e-09] 
Layer 'conv5' weights[0]: 7.988605e-03 [3.062020e-08] 
Layer 'conv5' biases: 9.999991e-01 [3.304983e-08] 
Layer 'fc6' weights[0]: 7.585422e-03 [2.804742e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.746954e-09] 
Layer 'fc7' weights[0]: 7.468204e-03 [2.371104e-07] 
Layer 'fc7' biases: 9.998673e-01 [2.254876e-07] 
Layer 'fc8' weights[0]: 1.346215e-03 [9.072411e-06] 
Layer 'fc8' biases: 2.708859e-02 [4.825411e-05] 
Train error last 870 batches: 0.435283
-------------------------------------------------------
Not saving because 0.416387 > 0.415712 (4.190: -0.00%)
======================================================= (12.070 sec)
12.431... logprob:  0.598902, 0.171875 (1.440 sec)
12.432... logprob:  0.387664, 0.093750 (1.429 sec)
12.433... logprob:  0.330583, 0.078125 (1.430 sec)
12.434... logprob:  0.528859, 0.148438 (1.443 sec)
12.435... logprob:  0.531833, 0.156250 (1.434 sec)
12.436... logprob:  0.381910, 0.093750 (1.480 sec)
12.437... logprob:  0.500190, 0.140625 (1.443 sec)
12.438... logprob:  0.546687, 0.156250 (1.435 sec)
12.439... logprob:  0.379493, 0.093750 (1.490 sec)
12.440... logprob:  0.439983, 0.117188 (1.433 sec)
12.441... logprob:  0.468083, 0.125000 (1.435 sec)
12.442... logprob:  0.378886, 0.093750 (1.432 sec)
12.443... logprob:  0.496602, 0.140625 (1.439 sec)
12.444... logprob:  0.371913, 0.093750 (1.469 sec)
12.445... logprob:  0.361905, 0.085938 (1.483 sec)
12.446... logprob:  0.397948, 0.101562 (1.436 sec)
12.447... logprob:  0.570844, 0.164062 (1.434 sec)
12.448... logprob:  0.332237, 0.078125 (1.486 sec)
12.449... logprob:  0.400026, 0.101562 (1.434 sec)
12.450... logprob:  0.238373, 0.046875 (1.433 sec)
12.451... logprob:  0.453306, 0.125000 (1.439 sec)
12.452... logprob:  0.456576, 0.117188 (1.427 sec)
12.453... logprob:  0.455730, 0.125000 (1.431 sec)
12.454... logprob:  0.489425, 0.132812 (1.484 sec)
12.455... logprob:  0.506166, 0.140625 (1.441 sec)
12.456... logprob:  0.468770, 0.125000 (1.445 sec)
12.457... logprob:  0.375432, 0.093750 (1.479 sec)
12.458... logprob:  0.351368, 0.085938 (1.434 sec)
12.459... logprob:  0.513431, 0.140625 (1.442 sec)
12.460... logprob:  0.275103, 0.054688 (1.433 sec)
12.461... logprob:  0.459910, 0.125000 (1.427 sec)
12.462... logprob:  0.471852, 0.125000 (1.434 sec)
12.463... logprob:  0.421035, 0.109375 (1.477 sec)
12.464... logprob:  0.482631, 0.132812 (1.450 sec)
12.465... logprob:  0.421280, 0.109375 (1.451 sec)
12.466... logprob:  0.318817, 0.070312 (1.464 sec)
12.467... logprob:  0.413889, 0.109375 (1.449 sec)
12.468... logprob:  0.394278, 0.101562 (1.442 sec)
12.469... logprob:  0.334557, 0.078125 (1.429 sec)
12.470... logprob:  0.400029, 0.101562 (1.426 sec)
12.471... logprob:  0.529876, 0.148438 (1.444 sec)
12.472... logprob:  0.410141, 0.109375 (1.450 sec)
12.473... logprob:  0.375273, 0.093750 (1.463 sec)
12.474... logprob:  0.465967, 0.125000 (1.454 sec)
12.475... logprob:  0.504695, 0.140625 (1.448 sec)
12.476... logprob:  0.510664, 0.140625 (1.470 sec)
12.477... logprob:  0.334441, 0.078125 (1.440 sec)
12.478... logprob:  0.464319, 0.125000 (1.425 sec)
12.479... logprob:  0.305827, 0.070312 (1.438 sec)
12.480... logprob:  0.443527, 0.117188 (1.435 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.78346252441406, 10.0]}, 128)
batch 872: ({'logprob': [66.70455169677734, 19.0]}, 128)
batch 873: ({'logprob': [40.4393196105957, 9.0]}, 128)
batch 874: ({'logprob': [45.19413757324219, 11.0]}, 128)
batch 875: ({'logprob': [50.76539993286133, 13.0]}, 128)
batch 876: ({'logprob': [64.13529968261719, 18.0]}, 128)
batch 877: ({'logprob': [45.60657501220703, 11.0]}, 128)
batch 878: ({'logprob': [61.9410514831543, 17.0]}, 128)
batch 879: ({'logprob': [73.49845886230469, 21.0]}, 128)
batch 880: ({'logprob': [50.7797966003418, 13.0]}, 128)
batch 881: ({'logprob': [28.852100372314453, 5.0]}, 128)
batch 882: ({'logprob': [54.588050842285156, 14.0]}, 128)
batch 883: ({'logprob': [61.92817306518555, 17.0]}, 128)
batch 884: ({'logprob': [51.17238998413086, 13.0]}, 128)
batch 885: ({'logprob': [51.99147033691406, 13.0]}, 128)
batch 886: ({'logprob': [62.34364700317383, 17.0]}, 128)

======================Test output======================
logprob:  0.415881, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.971796e-03 [1.982925e-09] 
Layer 'conv1' biases: 1.045464e-07 [2.858234e-11] 
Layer 'conv2' weights[0]: 7.958788e-03 [1.349765e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.230994e-10] 
Layer 'conv3' weights[0]: 7.957090e-03 [1.099376e-09] 
Layer 'conv3' biases: 9.280796e-07 [3.774048e-10] 
Layer 'conv4' weights[0]: 7.989654e-03 [1.132264e-09] 
Layer 'conv4' biases: 9.999998e-01 [2.762077e-09] 
Layer 'conv5' weights[0]: 7.988564e-03 [1.822577e-08] 
Layer 'conv5' biases: 9.999990e-01 [1.971510e-08] 
Layer 'fc6' weights[0]: 7.585380e-03 [1.768139e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.595268e-09] 
Layer 'fc7' weights[0]: 7.466282e-03 [5.146508e-08] 
Layer 'fc7' biases: 9.998665e-01 [3.085342e-08] 
Layer 'fc8' weights[0]: 1.321615e-03 [1.552046e-06] 
Layer 'fc8' biases: 2.718892e-02 [9.012574e-06] 
Train error last 870 batches: 0.435283
-------------------------------------------------------
Not saving because 0.415881 > 0.415712 (4.190: -0.00%)
======================================================= (12.107 sec)
12.481... logprob:  0.547686, 0.156250 (1.443 sec)
12.482... logprob:  0.443212, 0.117188 (1.472 sec)
12.483... logprob:  0.502501, 0.140625 (1.450 sec)
12.484... logprob:  0.485276, 0.132812 (1.434 sec)
12.485... logprob:  0.409184, 0.109375 (1.482 sec)
12.486... logprob:  0.361811, 0.085938 (1.430 sec)
12.487... logprob:  0.522578, 0.148438 (1.432 sec)
12.488... logprob:  0.424992, 0.109375 (1.437 sec)
12.489... logprob:  0.416020, 0.109375 (1.437 sec)
12.490... logprob:  0.440708, 0.117188 (1.434 sec)
12.491... logprob:  0.313745, 0.070312 (1.483 sec)
12.492... logprob:  0.459657, 0.125000 (1.440 sec)
12.493... logprob:  0.522069, 0.148438 (1.440 sec)
12.494... logprob:  0.450403, 0.125000 (1.483 sec)
12.495... logprob:  0.380475, 0.093750 (1.435 sec)
12.496... logprob:  0.550714, 0.156250 (1.436 sec)
12.497... logprob:  0.467130, 0.125000 (1.434 sec)
12.498... logprob:  0.476421, 0.132812 (1.435 sec)
12.499... logprob:  0.456316, 0.125000 (1.432 sec)
12.500... logprob:  0.355038, 0.085938 (1.492 sec)
12.501... logprob:  0.339107, 0.078125 (1.431 sec)
12.502... logprob:  0.459701, 0.125000 (1.448 sec)
12.503... logprob:  0.400710, 0.101562 (1.485 sec)
12.504... logprob:  0.487374, 0.132812 (1.435 sec)
12.505... logprob:  0.570819, 0.164062 (1.438 sec)
12.506... logprob:  0.479679, 0.132812 (1.440 sec)
12.507... logprob:  0.385208, 0.093750 (1.432 sec)
12.508... logprob:  0.374825, 0.093750 (1.434 sec)
12.509... logprob:  0.323350, 0.070312 (1.480 sec)
12.510... logprob:  0.390506, 0.101562 (1.444 sec)
12.511... logprob:  0.410106, 0.109375 (1.456 sec)
12.512... logprob:  0.470767, 0.125000 (1.464 sec)
12.513... logprob:  0.324985, 0.078125 (1.446 sec)
12.514... logprob:  0.406283, 0.101562 (1.441 sec)
12.515... logprob:  0.455676, 0.125000 (1.434 sec)
12.516... logprob:  0.400503, 0.109375 (1.424 sec)
12.517... logprob:  0.628233, 0.179688 (1.440 sec)
12.518... logprob:  0.437764, 0.117188 (1.475 sec)
12.519... logprob:  0.516178, 0.140625 (1.447 sec)
12.520... logprob:  0.409664, 0.109375 (1.449 sec)
12.521... logprob:  0.427572, 0.109375 (1.454 sec)
12.522... logprob:  0.533033, 0.156250 (1.455 sec)
12.523... logprob:  0.331922, 0.078125 (1.439 sec)
12.524... logprob:  0.437289, 0.117188 (1.429 sec)
12.525... logprob:  0.426193, 0.109375 (1.430 sec)
12.526... logprob:  0.352118, 0.078125 (1.435 sec)
12.527... logprob:  0.504523, 0.140625 (1.441 sec)
12.528... logprob:  0.440552, 0.117188 (1.472 sec)
12.529... logprob:  0.353027, 0.085938 (1.448 sec)
12.530... logprob:  0.440248, 0.117188 (1.436 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.86959457397461, 10.0]}, 128)
batch 872: ({'logprob': [66.41056823730469, 19.0]}, 128)
batch 873: ({'logprob': [40.78481674194336, 9.0]}, 128)
batch 874: ({'logprob': [45.33607482910156, 11.0]}, 128)
batch 875: ({'logprob': [50.83027267456055, 13.0]}, 128)
batch 876: ({'logprob': [63.91134262084961, 18.0]}, 128)
batch 877: ({'logprob': [45.81190872192383, 11.0]}, 128)
batch 878: ({'logprob': [61.850852966308594, 17.0]}, 128)
batch 879: ({'logprob': [73.31610870361328, 21.0]}, 128)
batch 880: ({'logprob': [50.84447479248047, 13.0]}, 128)
batch 881: ({'logprob': [29.28990936279297, 5.0]}, 128)
batch 882: ({'logprob': [54.77125930786133, 14.0]}, 128)
batch 883: ({'logprob': [61.83783721923828, 17.0]}, 128)
batch 884: ({'logprob': [51.299781799316406, 13.0]}, 128)
batch 885: ({'logprob': [52.244850158691406, 13.0]}, 128)
batch 886: ({'logprob': [62.316261291503906, 17.0]}, 128)

======================Test output======================
logprob:  0.416370, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.971760e-03 [1.990437e-09] 
Layer 'conv1' biases: 1.052535e-07 [6.539706e-11] 
Layer 'conv2' weights[0]: 7.958742e-03 [1.930880e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.933698e-10] 
Layer 'conv3' weights[0]: 7.957053e-03 [1.832211e-09] 
Layer 'conv3' biases: 9.353247e-07 [8.925015e-10] 
Layer 'conv4' weights[0]: 7.989612e-03 [2.013013e-09] 
Layer 'conv4' biases: 9.999998e-01 [8.283210e-09] 
Layer 'conv5' weights[0]: 7.988538e-03 [5.612734e-08] 
Layer 'conv5' biases: 9.999985e-01 [6.090284e-08] 
Layer 'fc6' weights[0]: 7.585346e-03 [4.930046e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.910206e-09] 
Layer 'fc7' weights[0]: 7.464380e-03 [1.889464e-07] 
Layer 'fc7' biases: 9.998664e-01 [1.767149e-07] 
Layer 'fc8' weights[0]: 1.311790e-03 [6.994712e-06] 
Layer 'fc8' biases: 2.720691e-02 [4.684002e-05] 
Train error last 870 batches: 0.435282
-------------------------------------------------------
Not saving because 0.416370 > 0.415712 (4.190: -0.00%)
======================================================= (12.064 sec)
12.531... logprob:  0.440050, 0.117188 (1.487 sec)
12.532... logprob:  0.467453, 0.125000 (1.437 sec)
12.533... logprob:  0.560912, 0.164062 (1.424 sec)
12.534... logprob:  0.325712, 0.078125 (1.438 sec)
12.535... logprob:  0.551827, 0.156250 (1.436 sec)
12.536... logprob:  0.507483, 0.140625 (1.434 sec)
12.537... logprob:  0.510128, 0.140625 (1.488 sec)
12.538... logprob:  0.486132, 0.132812 (1.443 sec)
12.539... logprob:  0.296219, 0.062500 (1.439 sec)
12.540... logprob:  0.447187, 0.117188 (1.488 sec)
12.541... logprob:  0.388951, 0.101562 (1.430 sec)
12.542... logprob:  0.411362, 0.109375 (1.429 sec)
12.543... logprob:  0.233511, 0.039062 (1.434 sec)
12.544... logprob:  0.317968, 0.070312 (1.435 sec)
12.545... logprob:  0.348821, 0.085938 (1.437 sec)
12.546... logprob:  0.368299, 0.093750 (1.483 sec)
12.547... logprob:  0.440217, 0.117188 (1.439 sec)
12.548... logprob:  0.453362, 0.125000 (1.439 sec)
12.549... logprob:  0.490886, 0.132812 (1.479 sec)
12.550... logprob:  0.367743, 0.093750 (1.429 sec)
12.551... logprob:  0.441897, 0.117188 (1.466 sec)
12.552... logprob:  0.471389, 0.125000 (1.433 sec)
12.553... logprob:  0.349428, 0.085938 (1.433 sec)
12.554... logprob:  0.506775, 0.140625 (1.432 sec)
12.555... logprob:  0.421419, 0.109375 (1.485 sec)
12.556... logprob:  0.356013, 0.085938 (1.438 sec)
12.557... logprob:  0.396558, 0.101562 (1.453 sec)
12.558... logprob:  0.383111, 0.101562 (1.473 sec)
12.559... logprob:  0.441377, 0.125000 (1.440 sec)
12.560... logprob:  0.335506, 0.078125 (1.436 sec)
12.561... logprob:  0.411881, 0.109375 (1.431 sec)
12.562... logprob:  0.503103, 0.140625 (1.422 sec)
12.563... logprob:  0.373917, 0.093750 (1.442 sec)
12.564... logprob:  0.468403, 0.132812 (1.465 sec)
12.565... logprob:  0.610996, 0.187500 (1.457 sec)
12.566... logprob:  0.374943, 0.093750 (1.453 sec)
12.567... logprob:  0.423515, 0.109375 (1.456 sec)
12.568... logprob:  0.496413, 0.140625 (1.454 sec)
12.569... logprob:  0.507942, 0.140625 (1.437 sec)
12.570... logprob:  0.543706, 0.164062 (1.427 sec)
12.571... logprob:  0.454872, 0.125000 (1.432 sec)
12.572... logprob:  0.501545, 0.140625 (1.438 sec)
12.573... logprob:  0.512655, 0.148438 (1.449 sec)
12.574... logprob:  0.428213, 0.109375 (1.462 sec)
12.575... logprob:  0.343389, 0.078125 (1.458 sec)
12.576... logprob:  0.427442, 0.109375 (1.445 sec)
12.577... logprob:  0.460880, 0.125000 (1.478 sec)
12.578... logprob:  0.336498, 0.078125 (1.436 sec)
12.579... logprob:  0.442096, 0.117188 (1.432 sec)
12.580... logprob:  0.547109, 0.156250 (1.431 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.38169860839844, 10.0]}, 128)
batch 872: ({'logprob': [66.2961654663086, 19.0]}, 128)
batch 873: ({'logprob': [41.16468811035156, 9.0]}, 128)
batch 874: ({'logprob': [45.30021667480469, 11.0]}, 128)
batch 875: ({'logprob': [50.90745162963867, 13.0]}, 128)
batch 876: ({'logprob': [63.872222900390625, 18.0]}, 128)
batch 877: ({'logprob': [46.03977966308594, 11.0]}, 128)
batch 878: ({'logprob': [62.15214157104492, 17.0]}, 128)
batch 879: ({'logprob': [74.10458374023438, 21.0]}, 128)
batch 880: ({'logprob': [50.920650482177734, 13.0]}, 128)
batch 881: ({'logprob': [29.181720733642578, 5.0]}, 128)
batch 882: ({'logprob': [55.563907623291016, 14.0]}, 128)
batch 883: ({'logprob': [62.13935470581055, 17.0]}, 128)
batch 884: ({'logprob': [51.64061737060547, 13.0]}, 128)
batch 885: ({'logprob': [53.113712310791016, 13.0]}, 128)
batch 886: ({'logprob': [62.8814582824707, 17.0]}, 128)

======================Test output======================
logprob:  0.418291, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.971712e-03 [2.236293e-09] 
Layer 'conv1' biases: 1.060453e-07 [3.618837e-11] 
Layer 'conv2' weights[0]: 7.958705e-03 [1.591428e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.269737e-10] 
Layer 'conv3' weights[0]: 7.957019e-03 [1.449342e-09] 
Layer 'conv3' biases: 9.409424e-07 [7.509814e-10] 
Layer 'conv4' weights[0]: 7.989574e-03 [1.522044e-09] 
Layer 'conv4' biases: 9.999998e-01 [6.293248e-09] 
Layer 'conv5' weights[0]: 7.988482e-03 [4.318907e-08] 
Layer 'conv5' biases: 9.999983e-01 [4.691545e-08] 
Layer 'fc6' weights[0]: 7.585308e-03 [3.799252e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.772920e-09] 
Layer 'fc7' weights[0]: 7.462495e-03 [1.706370e-07] 
Layer 'fc7' biases: 9.998670e-01 [1.582638e-07] 
Layer 'fc8' weights[0]: 1.316491e-03 [8.714563e-06] 
Layer 'fc8' biases: 2.736567e-02 [5.755813e-05] 
Train error last 870 batches: 0.435282
-------------------------------------------------------
Not saving because 0.418291 > 0.415712 (4.190: -0.00%)
======================================================= (12.020 sec)
12.581... logprob:  0.531204, 0.156250 (1.446 sec)
12.582... logprob:  0.437957, 0.125000 (1.434 sec)
12.583... logprob:  0.593085, 0.171875 (1.472 sec)
12.584... logprob:  0.468159, 0.132812 (1.470 sec)
12.585... logprob:  0.349774, 0.085938 (1.430 sec)
12.586... logprob:  0.313209, 0.070312 (1.483 sec)
12.587... logprob:  0.404329, 0.101562 (1.434 sec)
12.588... logprob:  0.418683, 0.117188 (1.431 sec)
12.589... logprob:  0.361381, 0.093750 (1.441 sec)
12.590... logprob:  0.524666, 0.148438 (1.434 sec)
12.591... logprob:  0.397549, 0.101562 (1.433 sec)
12.592... logprob:  0.455633, 0.125000 (1.486 sec)
12.593... logprob:  0.467455, 0.125000 (1.436 sec)
12.594... logprob:  0.352897, 0.085938 (1.444 sec)
12.595... logprob:  0.428680, 0.109375 (1.479 sec)
12.596... logprob:  0.461571, 0.125000 (1.437 sec)
12.597... logprob:  0.397411, 0.101562 (1.434 sec)
12.598... logprob:  0.397238, 0.101562 (1.440 sec)
12.599... logprob:  0.313473, 0.070312 (1.427 sec)
12.600... logprob:  0.340903, 0.085938 (1.429 sec)
12.601... logprob:  0.402111, 0.101562 (1.486 sec)
12.602... logprob:  0.289594, 0.062500 (1.439 sec)
12.603... logprob:  0.266823, 0.054688 (1.443 sec)
12.604... logprob:  0.407513, 0.101562 (1.474 sec)
12.605... logprob:  0.563745, 0.148438 (1.431 sec)
12.606... logprob:  0.295953, 0.070312 (1.444 sec)
12.607... logprob:  0.505039, 0.132812 (1.431 sec)
12.608... logprob:  0.361613, 0.085938 (1.431 sec)
12.609... logprob:  0.356881, 0.085938 (1.438 sec)
12.610... logprob:  0.493493, 0.132812 (1.468 sec)
12.611... logprob:  0.510470, 0.140625 (1.441 sec)
12.612... logprob:  0.448338, 0.117188 (1.458 sec)
12.613... logprob:  0.279992, 0.062500 (1.458 sec)
12.614... logprob:  0.503489, 0.140625 (1.454 sec)
12.615... logprob:  0.351326, 0.085938 (1.437 sec)
12.616... logprob:  0.415473, 0.109375 (1.432 sec)
12.617... logprob:  0.418037, 0.109375 (1.427 sec)
12.618... logprob:  0.546560, 0.156250 (1.441 sec)
12.619... logprob:  0.505882, 0.140625 (1.452 sec)
12.620... logprob:  0.539590, 0.156250 (1.456 sec)
12.621... logprob:  0.364073, 0.085938 (1.451 sec)
12.622... logprob:  0.365060, 0.085938 (1.446 sec)
12.623... logprob:  0.423257, 0.109375 (1.469 sec)
12.624... logprob:  0.382567, 0.093750 (1.436 sec)
12.625... logprob:  0.441017, 0.117188 (1.442 sec)
12.626... logprob:  0.438415, 0.117188 (1.435 sec)
12.627... logprob:  0.435880, 0.117188 (1.437 sec)
12.628... logprob:  0.465138, 0.125000 (1.442 sec)
12.629... logprob:  0.371925, 0.093750 (1.479 sec)
12.630... logprob:  0.422374, 0.109375 (1.453 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.729156494140625, 10.0]}, 128)
batch 872: ({'logprob': [67.18609619140625, 19.0]}, 128)
batch 873: ({'logprob': [40.01749038696289, 9.0]}, 128)
batch 874: ({'logprob': [45.060482025146484, 11.0]}, 128)
batch 875: ({'logprob': [50.73998260498047, 13.0]}, 128)
batch 876: ({'logprob': [64.51847839355469, 18.0]}, 128)
batch 877: ({'logprob': [45.38306427001953, 11.0]}, 128)
batch 878: ({'logprob': [62.13469314575195, 17.0]}, 128)
batch 879: ({'logprob': [73.82121276855469, 21.0]}, 128)
batch 880: ({'logprob': [50.75518035888672, 13.0]}, 128)
batch 881: ({'logprob': [28.30078125, 5.0]}, 128)
batch 882: ({'logprob': [54.39474105834961, 14.0]}, 128)
batch 883: ({'logprob': [62.12124252319336, 17.0]}, 128)
batch 884: ({'logprob': [51.05864334106445, 13.0]}, 128)
batch 885: ({'logprob': [51.698970794677734, 13.0]}, 128)
batch 886: ({'logprob': [62.44829177856445, 17.0]}, 128)

======================Test output======================
logprob:  0.415707, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.971671e-03 [2.161365e-09] 
Layer 'conv1' biases: 1.067683e-07 [2.621515e-11] 
Layer 'conv2' weights[0]: 7.958666e-03 [1.512160e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.271763e-10] 
Layer 'conv3' weights[0]: 7.956984e-03 [1.172373e-09] 
Layer 'conv3' biases: 9.474487e-07 [3.795788e-10] 
Layer 'conv4' weights[0]: 7.989532e-03 [1.246492e-09] 
Layer 'conv4' biases: 9.999998e-01 [2.767097e-09] 
Layer 'conv5' weights[0]: 7.988441e-03 [1.896550e-08] 
Layer 'conv5' biases: 9.999985e-01 [2.047326e-08] 
Layer 'fc6' weights[0]: 7.585274e-03 [1.819042e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.647480e-09] 
Layer 'fc7' weights[0]: 7.460603e-03 [1.908615e-07] 
Layer 'fc7' biases: 9.998667e-01 [1.786266e-07] 
Layer 'fc8' weights[0]: 1.335960e-03 [6.455842e-06] 
Layer 'fc8' biases: 2.765733e-02 [4.416330e-05] 
Train error last 870 batches: 0.435282
-------------------------------------------------------
Saved checkpoint to /data2/ad6813/my-nets/saves/ConvNet__2014-06-17_23.05.49
======================================================= (12.603 sec)
12.631... logprob:  0.639765, 0.187500 (1.446 sec)
12.632... logprob:  0.399095, 0.101562 (1.484 sec)
12.633... logprob:  0.375987, 0.093750 (1.438 sec)
12.634... logprob:  0.660628, 0.195312 (2.699 sec)
12.635... logprob:  0.374134, 0.093750 (1.449 sec)
12.636... logprob:  0.480216, 0.132812 (1.440 sec)
12.637... logprob:  0.331060, 0.078125 (3.051 sec)
12.638... logprob:  0.515645, 0.140625 (1.482 sec)
12.639... logprob:  0.418224, 0.109375 (1.438 sec)
12.640... logprob:  0.528748, 0.148438 (1.442 sec)
12.641... logprob:  0.410532, 0.109375 (1.481 sec)
12.642... logprob:  0.500782, 0.140625 (1.440 sec)
12.643... logprob:  0.622654, 0.187500 (1.429 sec)
12.644... logprob:  0.321626, 0.070312 (1.441 sec)
12.645... logprob:  0.414533, 0.109375 (1.453 sec)
12.646... logprob:  0.385829, 0.093750 (1.434 sec)
12.647... logprob:  0.456733, 0.125000 (1.493 sec)
12.648... logprob:  0.491223, 0.140625 (1.432 sec)
12.649... logprob:  0.370017, 0.093750 (1.448 sec)
12.650... logprob:  0.413896, 0.109375 (1.476 sec)
12.651... logprob:  0.397259, 0.101562 (1.432 sec)
12.652... logprob:  0.507548, 0.140625 (1.440 sec)
12.653... logprob:  0.548339, 0.156250 (1.441 sec)
12.654... logprob:  0.496224, 0.140625 (1.429 sec)
12.655... logprob:  0.436230, 0.117188 (1.432 sec)
12.656... logprob:  0.416660, 0.109375 (1.488 sec)
12.657... logprob:  0.449370, 0.117188 (1.446 sec)
12.658... logprob:  0.345726, 0.085938 (1.452 sec)
12.659... logprob:  0.464382, 0.125000 (1.468 sec)
12.660... logprob:  0.445858, 0.125000 (1.442 sec)
12.661... logprob:  0.378610, 0.093750 (1.441 sec)
12.662... logprob:  0.469293, 0.132812 (1.430 sec)
12.663... logprob:  0.311142, 0.070312 (1.431 sec)
12.664... logprob:  0.285588, 0.062500 (1.435 sec)
12.665... logprob:  0.401922, 0.101562 (1.465 sec)
12.666... logprob:  0.442085, 0.117188 (1.460 sec)
12.667... logprob:  0.564368, 0.164062 (1.460 sec)
12.668... logprob:  0.497961, 0.140625 (1.451 sec)
12.669... logprob:  0.433167, 0.109375 (1.454 sec)
12.670... logprob:  0.362538, 0.085938 (1.444 sec)
12.671... logprob:  0.360853, 0.093750 (1.425 sec)
12.672... logprob:  0.441805, 0.117188 (1.434 sec)
12.673... logprob:  0.436256, 0.117188 (1.438 sec)
12.674... logprob:  0.446682, 0.117188 (1.444 sec)
12.675... logprob:  0.356664, 0.093750 (1.468 sec)
12.676... logprob:  0.450137, 0.125000 (1.454 sec)
12.677... logprob:  0.471076, 0.125000 (1.440 sec)
12.678... logprob:  0.465634, 0.125000 (1.485 sec)
12.679... logprob:  0.454882, 0.125000 (1.433 sec)
12.680... logprob:  0.351766, 0.078125 (1.426 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.74235916137695, 10.0]}, 128)
batch 872: ({'logprob': [66.12953186035156, 19.0]}, 128)
batch 873: ({'logprob': [41.2711296081543, 9.0]}, 128)
batch 874: ({'logprob': [45.460899353027344, 11.0]}, 128)
batch 875: ({'logprob': [50.94087219238281, 13.0]}, 128)
batch 876: ({'logprob': [63.72396469116211, 18.0]}, 128)
batch 877: ({'logprob': [46.11019515991211, 11.0]}, 128)
batch 878: ({'logprob': [61.93120574951172, 17.0]}, 128)
batch 879: ({'logprob': [73.53860473632812, 21.0]}, 128)
batch 880: ({'logprob': [50.954410552978516, 13.0]}, 128)
batch 881: ({'logprob': [29.633432388305664, 5.0]}, 128)
batch 882: ({'logprob': [55.30643081665039, 14.0]}, 128)
batch 883: ({'logprob': [61.918190002441406, 17.0]}, 128)
batch 884: ({'logprob': [51.58279037475586, 13.0]}, 128)
batch 885: ({'logprob': [52.87390899658203, 13.0]}, 128)
batch 886: ({'logprob': [62.5693244934082, 17.0]}, 128)

======================Test output======================
logprob:  0.417816, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.971638e-03 [3.551075e-09] 
Layer 'conv1' biases: 1.074218e-07 [8.594906e-11] 
Layer 'conv2' weights[0]: 7.958631e-03 [2.222922e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.847959e-10] 
Layer 'conv3' weights[0]: 7.956945e-03 [2.039790e-09] 
Layer 'conv3' biases: 9.541460e-07 [1.115759e-09] 
Layer 'conv4' weights[0]: 7.989495e-03 [2.107950e-09] 
Layer 'conv4' biases: 9.999998e-01 [8.753818e-09] 
Layer 'conv5' weights[0]: 7.988406e-03 [5.216655e-08] 
Layer 'conv5' biases: 9.999988e-01 [5.637428e-08] 
Layer 'fc6' weights[0]: 7.585232e-03 [4.635000e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.610105e-09] 
Layer 'fc7' weights[0]: 7.458680e-03 [5.031330e-08] 
Layer 'fc7' biases: 9.998663e-01 [2.834493e-08] 
Layer 'fc8' weights[0]: 1.311703e-03 [4.394853e-06] 
Layer 'fc8' biases: 2.756620e-02 [2.803131e-05] 
Train error last 870 batches: 0.435281
-------------------------------------------------------
Not saving because 0.417816 > 0.415707 (12.630: -0.00%)
======================================================= (12.082 sec)
12.681... logprob:  0.373983, 0.093750 (1.439 sec)
12.682... logprob:  0.340524, 0.078125 (1.436 sec)
12.683... logprob:  0.411657, 0.109375 (1.434 sec)
12.684... logprob:  0.357558, 0.085938 (1.486 sec)
12.685... logprob:  0.285719, 0.054688 (1.446 sec)
12.686... logprob:  0.318400, 0.070312 (1.427 sec)
12.687... logprob:  0.281400, 0.062500 (1.484 sec)
12.688... logprob:  0.323056, 0.078125 (1.433 sec)
12.689... logprob:  0.471798, 0.125000 (1.442 sec)
12.690... logprob:  0.528429, 0.140625 (1.434 sec)
12.691... logprob:  0.517459, 0.140625 (1.436 sec)
12.692... logprob:  0.385556, 0.101562 (1.434 sec)
12.693... logprob:  0.456257, 0.125000 (1.490 sec)
12.694... logprob:  0.330870, 0.078125 (1.430 sec)
12.695... logprob:  0.356872, 0.085938 (1.440 sec)
12.696... logprob:  0.538569, 0.148438 (1.481 sec)
12.697... logprob:  0.465501, 0.125000 (1.432 sec)
12.698... logprob:  0.548291, 0.156250 (1.439 sec)
12.699... logprob:  0.459566, 0.125000 (1.433 sec)
12.700... logprob:  0.434147, 0.117188 (1.425 sec)
12.701... logprob:  0.423554, 0.109375 (1.435 sec)
12.702... logprob:  0.521401, 0.148438 (1.478 sec)
12.703... logprob:  0.405793, 0.101562 (1.523 sec)
12.704... logprob:  0.406518, 0.101562 (1.450 sec)
12.705... logprob:  0.420394, 0.109375 (1.473 sec)
12.706... logprob:  0.468088, 0.125000 (1.431 sec)
12.707... logprob:  0.485300, 0.132812 (1.443 sec)
12.708... logprob:  0.416956, 0.109375 (1.430 sec)
12.709... logprob:  0.422331, 0.109375 (1.423 sec)
12.710... logprob:  0.603145, 0.179688 (1.444 sec)
12.711... logprob:  0.469571, 0.125000 (1.465 sec)
12.712... logprob:  0.340056, 0.078125 (1.442 sec)
12.713... logprob:  0.587779, 0.179688 (1.460 sec)
12.714... logprob:  0.466387, 0.125000 (1.530 sec)
12.715... logprob:  0.417115, 0.109375 (1.458 sec)
12.716... logprob:  0.335145, 0.078125 (1.437 sec)
12.717... logprob:  0.429868, 0.117188 (1.431 sec)
12.718... logprob:  0.490414, 0.132812 (1.426 sec)
12.719... logprob:  0.406212, 0.109375 (1.436 sec)
12.720... logprob:  0.433245, 0.117188 (1.441 sec)
12.721... logprob:  0.451596, 0.117188 (1.461 sec)
12.722... logprob:  0.536746, 0.156250 (1.458 sec)
12.723... logprob:  0.416637, 0.109375 (1.442 sec)
12.724... logprob:  0.412794, 0.109375 (1.470 sec)
12.725... logprob:  0.494568, 0.140625 (1.434 sec)
12.726... logprob:  0.338816, 0.085938 (1.432 sec)
12.727... logprob:  0.393470, 0.101562 (1.429 sec)
12.728... logprob:  0.421444, 0.109375 (1.435 sec)
12.729... logprob:  0.387902, 0.093750 (1.433 sec)
12.730... logprob:  0.565802, 0.164062 (1.491 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.651309967041016, 10.0]}, 128)
batch 872: ({'logprob': [66.25040435791016, 19.0]}, 128)
batch 873: ({'logprob': [41.05673599243164, 9.0]}, 128)
batch 874: ({'logprob': [45.348388671875, 11.0]}, 128)
batch 875: ({'logprob': [50.871986389160156, 13.0]}, 128)
batch 876: ({'logprob': [63.80860137939453, 18.0]}, 128)
batch 877: ({'logprob': [45.968467712402344, 11.0]}, 128)
batch 878: ({'logprob': [61.95018768310547, 17.0]}, 128)
batch 879: ({'logprob': [73.61646270751953, 21.0]}, 128)
batch 880: ({'logprob': [50.88561248779297, 13.0]}, 128)
batch 881: ({'logprob': [29.360071182250977, 5.0]}, 128)
batch 882: ({'logprob': [55.1873893737793, 14.0]}, 128)
batch 883: ({'logprob': [61.93719482421875, 17.0]}, 128)
batch 884: ({'logprob': [51.485267639160156, 13.0]}, 128)
batch 885: ({'logprob': [52.718528747558594, 13.0]}, 128)
batch 886: ({'logprob': [62.559452056884766, 17.0]}, 128)

======================Test output======================
logprob:  0.417313, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.971595e-03 [2.926047e-09] 
Layer 'conv1' biases: 1.081117e-07 [7.430517e-11] 
Layer 'conv2' weights[0]: 7.958592e-03 [2.197689e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.648560e-10] 
Layer 'conv3' weights[0]: 7.956905e-03 [1.982878e-09] 
Layer 'conv3' biases: 9.598075e-07 [1.135744e-09] 
Layer 'conv4' weights[0]: 7.989452e-03 [2.133576e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.039867e-08] 
Layer 'conv5' weights[0]: 7.988362e-03 [7.118011e-08] 
Layer 'conv5' biases: 9.999986e-01 [7.731951e-08] 
Layer 'fc6' weights[0]: 7.585194e-03 [6.123909e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.220863e-09] 
Layer 'fc7' weights[0]: 7.456786e-03 [4.616793e-08] 
Layer 'fc7' biases: 9.998663e-01 [2.269862e-08] 
Layer 'fc8' weights[0]: 1.316548e-03 [3.397565e-06] 
Layer 'fc8' biases: 2.781941e-02 [2.075262e-05] 
Train error last 870 batches: 0.435281
-------------------------------------------------------
Not saving because 0.417313 > 0.415707 (12.630: -0.00%)
======================================================= (12.049 sec)
12.731... logprob:  0.450294, 0.125000 (1.454 sec)
12.732... logprob:  0.311513, 0.070312 (1.436 sec)
12.733... logprob:  0.556806, 0.156250 (1.482 sec)
12.734... logprob:  0.340199, 0.078125 (1.433 sec)
12.735... logprob:  0.527727, 0.148438 (1.427 sec)
12.736... logprob:  0.643272, 0.187500 (1.440 sec)
12.737... logprob:  0.516265, 0.148438 (1.433 sec)
12.738... logprob:  0.459457, 0.125000 (1.436 sec)
12.739... logprob:  0.477831, 0.132812 (1.485 sec)
12.740... logprob:  0.339676, 0.078125 (1.437 sec)
12.741... logprob:  0.393450, 0.101562 (1.440 sec)
12.742... logprob:  0.419772, 0.109375 (1.484 sec)
12.743... logprob:  0.364876, 0.085938 (1.432 sec)
12.744... logprob:  0.519302, 0.148438 (1.432 sec)
12.745... logprob:  0.478202, 0.132812 (1.436 sec)
12.746... logprob:  0.440570, 0.117188 (1.430 sec)
12.747... logprob:  0.425647, 0.109375 (1.436 sec)
12.748... logprob:  0.378021, 0.093750 (1.487 sec)
12.749... logprob:  0.420867, 0.109375 (1.434 sec)
12.750... logprob:  0.512984, 0.140625 (1.447 sec)
12.751... logprob:  0.263467, 0.054688 (1.480 sec)
12.752... logprob:  0.522523, 0.140625 (1.433 sec)
12.753... logprob:  0.441300, 0.117188 (1.438 sec)
12.754... logprob:  0.468682, 0.132812 (1.436 sec)
12.755... logprob:  0.507151, 0.140625 (1.426 sec)
12.756... logprob:  0.440823, 0.117188 (1.425 sec)
12.757... logprob:  0.552222, 0.156250 (1.473 sec)
12.758... logprob:  0.393775, 0.101562 (1.443 sec)
12.759... logprob:  0.459691, 0.125000 (1.457 sec)
12.760... logprob:  0.485358, 0.132812 (1.460 sec)
12.761... logprob:  0.418499, 0.109375 (1.445 sec)
12.762... logprob:  0.515950, 0.148438 (1.439 sec)
12.763... logprob:  0.558704, 0.164062 (1.442 sec)
12.764... logprob:  0.503302, 0.140625 (1.427 sec)
12.765... logprob:  0.312494, 0.062500 (1.440 sec)
12.766... logprob:  0.482333, 0.132812 (1.454 sec)
12.767... logprob:  0.371205, 0.085938 (1.450 sec)
12.768... logprob:  0.432730, 0.117188 (1.465 sec)
12.769... logprob:  0.490948, 0.140625 (1.464 sec)
12.770... logprob:  0.402755, 0.101562 (1.488 sec)
12.771... logprob:  0.549815, 0.156250 (1.457 sec)
12.772... logprob:  0.414009, 0.109375 (1.440 sec)
12.773... logprob:  0.558383, 0.164062 (1.446 sec)
12.774... logprob:  0.361419, 0.085938 (1.460 sec)
12.775... logprob:  0.407299, 0.101562 (1.464 sec)
12.776... logprob:  0.433289, 0.117188 (1.484 sec)
12.777... logprob:  0.379902, 0.093750 (1.470 sec)
12.778... logprob:  0.433658, 0.117188 (1.463 sec)
12.779... logprob:  0.505539, 0.140625 (1.485 sec)
12.780... logprob:  0.385756, 0.101562 (1.453 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.493892669677734, 10.0]}, 128)
batch 872: ({'logprob': [66.88172149658203, 19.0]}, 128)
batch 873: ({'logprob': [40.267051696777344, 9.0]}, 128)
batch 874: ({'logprob': [45.03300476074219, 11.0]}, 128)
batch 875: ({'logprob': [50.71305847167969, 13.0]}, 128)
batch 876: ({'logprob': [64.28301239013672, 18.0]}, 128)
batch 877: ({'logprob': [45.49421691894531, 11.0]}, 128)
batch 878: ({'logprob': [62.10746765136719, 17.0]}, 128)
batch 879: ({'logprob': [73.9317855834961, 21.0]}, 128)
batch 880: ({'logprob': [50.727664947509766, 13.0]}, 128)
batch 881: ({'logprob': [28.412166595458984, 5.0]}, 128)
batch 882: ({'logprob': [54.71361541748047, 14.0]}, 128)
batch 883: ({'logprob': [62.094154357910156, 17.0]}, 128)
batch 884: ({'logprob': [51.1697998046875, 13.0]}, 128)
batch 885: ({'logprob': [52.087100982666016, 13.0]}, 128)
batch 886: ({'logprob': [62.55940246582031, 17.0]}, 128)

======================Test output======================
logprob:  0.416001, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.971555e-03 [2.316596e-09] 
Layer 'conv1' biases: 1.088038e-07 [4.999278e-11] 
Layer 'conv2' weights[0]: 7.958561e-03 [1.955384e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.467942e-10] 
Layer 'conv3' weights[0]: 7.956867e-03 [1.556167e-09] 
Layer 'conv3' biases: 9.659496e-07 [6.828573e-10] 
Layer 'conv4' weights[0]: 7.989423e-03 [1.522156e-09] 
Layer 'conv4' biases: 9.999998e-01 [4.018682e-09] 
Layer 'conv5' weights[0]: 7.988327e-03 [1.949409e-08] 
Layer 'conv5' biases: 9.999986e-01 [2.044488e-08] 
Layer 'fc6' weights[0]: 7.585161e-03 [1.856394e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.692907e-09] 
Layer 'fc7' weights[0]: 7.454901e-03 [4.718931e-08] 
Layer 'fc7' biases: 9.998665e-01 [2.347064e-08] 
Layer 'fc8' weights[0]: 1.333569e-03 [3.561351e-06] 
Layer 'fc8' biases: 2.807042e-02 [2.314617e-05] 
Train error last 870 batches: 0.435280
-------------------------------------------------------
Not saving because 0.416001 > 0.415707 (12.630: -0.00%)
======================================================= (12.140 sec)
12.781... logprob:  0.369779, 0.085938 (1.455 sec)
12.782... logprob:  0.351561, 0.085938 (1.451 sec)
12.783... logprob:  0.555430, 0.156250 (1.456 sec)
12.784... logprob:  0.440960, 0.117188 (1.457 sec)
12.785... logprob:  0.543431, 0.156250 (1.499 sec)
12.786... logprob:  0.477325, 0.132812 (1.469 sec)
12.787... logprob:  0.546038, 0.156250 (1.463 sec)
12.788... logprob:  0.562720, 0.164062 (1.494 sec)
12.789... logprob:  0.281813, 0.054688 (1.457 sec)
12.790... logprob:  0.408504, 0.101562 (1.447 sec)
12.791... logprob:  0.398294, 0.101562 (1.450 sec)
12.792... logprob:  0.361408, 0.085938 (1.459 sec)
12.793... logprob:  0.370375, 0.085938 (1.450 sec)
12.794... logprob:  0.387118, 0.093750 (1.487 sec)
12.795... logprob:  0.469878, 0.125000 (1.496 sec)
12.796... logprob:  0.423499, 0.109375 (1.452 sec)
12.797... logprob:  0.358621, 0.085938 (1.498 sec)
12.798... logprob:  0.393256, 0.101562 (1.448 sec)
12.799... logprob:  0.332040, 0.078125 (1.448 sec)
12.800... logprob:  0.371835, 0.093750 (1.445 sec)
12.801... logprob:  0.450523, 0.117188 (1.459 sec)
12.802... logprob:  0.423284, 0.109375 (1.457 sec)
12.803... logprob:  0.492263, 0.132812 (1.489 sec)
12.804... logprob:  0.350004, 0.085938 (1.459 sec)
12.805... logprob:  0.452303, 0.117188 (1.454 sec)
12.806... logprob:  0.424189, 0.109375 (1.501 sec)
12.807... logprob:  0.443432, 0.117188 (1.450 sec)
12.808... logprob:  0.462316, 0.125000 (1.450 sec)
12.809... logprob:  0.589273, 0.171875 (1.453 sec)
12.810... logprob:  0.442426, 0.117188 (1.459 sec)
12.811... logprob:  0.460424, 0.125000 (1.453 sec)
12.812... logprob:  0.462478, 0.125000 (1.496 sec)
12.813... logprob:  0.486018, 0.132812 (1.461 sec)
12.814... logprob:  0.478259, 0.132812 (1.459 sec)
12.815... logprob:  0.372731, 0.085938 (1.502 sec)
12.816... logprob:  0.409215, 0.101562 (1.450 sec)
12.817... logprob:  0.426271, 0.109375 (1.450 sec)
12.818... logprob:  0.559961, 0.164062 (1.448 sec)
12.819... logprob:  0.498232, 0.140625 (1.460 sec)
12.820... logprob:  0.421485, 0.109375 (1.450 sec)
12.821... logprob:  0.406306, 0.101562 (1.496 sec)
12.822... logprob:  0.441013, 0.117188 (1.455 sec)
12.823... logprob:  0.340163, 0.078125 (1.205 sec)
12.824... logprob:  0.490179, 0.132812 (0.711 sec)
12.825... logprob:  0.287138, 0.062500 (0.684 sec)
12.826... logprob:  0.375264, 0.093750 (0.689 sec)
12.827... logprob:  0.420736, 0.109375 (0.686 sec)
12.828... logprob:  0.443830, 0.117188 (0.690 sec)
12.829... logprob:  0.505036, 0.140625 (0.692 sec)
12.830... logprob:  0.442487, 0.117188 (1.515 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.25123977661133, 10.0]}, 128)
batch 872: ({'logprob': [68.34830474853516, 19.0]}, 128)
batch 873: ({'logprob': [39.414268493652344, 9.0]}, 128)
batch 874: ({'logprob': [44.79081726074219, 11.0]}, 128)
batch 875: ({'logprob': [50.835609436035156, 13.0]}, 128)
batch 876: ({'logprob': [65.50668334960938, 18.0]}, 128)
batch 877: ({'logprob': [45.12856674194336, 11.0]}, 128)
batch 878: ({'logprob': [62.96341323852539, 17.0]}, 128)
batch 879: ({'logprob': [75.39874267578125, 21.0]}, 128)
batch 880: ({'logprob': [50.85116958618164, 13.0]}, 128)
batch 881: ({'logprob': [26.947608947753906, 5.0]}, 128)
batch 882: ({'logprob': [54.71631622314453, 14.0]}, 128)
batch 883: ({'logprob': [62.94986343383789, 17.0]}, 128)
batch 884: ({'logprob': [51.172515869140625, 13.0]}, 128)
batch 885: ({'logprob': [51.84640121459961, 13.0]}, 128)
batch 886: ({'logprob': [63.29458236694336, 17.0]}, 128)

======================Test output======================
logprob:  0.417684, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.971523e-03 [4.092550e-09] 
Layer 'conv1' biases: 1.095815e-07 [1.203895e-10] 
Layer 'conv2' weights[0]: 7.958531e-03 [3.511515e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.911148e-10] 
Layer 'conv3' weights[0]: 7.956825e-03 [3.416779e-09] 
Layer 'conv3' biases: 9.723052e-07 [2.174549e-09] 
Layer 'conv4' weights[0]: 7.989390e-03 [3.597288e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.965532e-08] 
Layer 'conv5' weights[0]: 7.988285e-03 [1.291642e-07] 
Layer 'conv5' biases: 9.999985e-01 [1.399292e-07] 
Layer 'fc6' weights[0]: 7.585130e-03 [1.113741e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.141142e-08] 
Layer 'fc7' weights[0]: 7.453001e-03 [6.608362e-08] 
Layer 'fc7' biases: 9.998674e-01 [4.805536e-08] 
Layer 'fc8' weights[0]: 1.365185e-03 [6.277989e-06] 
Layer 'fc8' biases: 2.853152e-02 [3.412598e-05] 
Train error last 870 batches: 0.435280
-------------------------------------------------------
Not saving because 0.417684 > 0.415707 (12.630: -0.00%)
======================================================= (12.077 sec)
12.831... logprob:  0.514245, 0.140625 (1.485 sec)
12.832... logprob:  0.330880, 0.078125 (1.464 sec)
12.833... logprob:  0.488894, 0.132812 (1.493 sec)
12.834... logprob:  0.433108, 0.117188 (1.449 sec)
12.835... logprob:  0.542269, 0.148438 (1.455 sec)
12.836... logprob:  0.376473, 0.093750 (1.442 sec)
12.837... logprob:  0.315173, 0.070312 (1.450 sec)
12.838... logprob:  0.437116, 0.117188 (1.454 sec)
12.839... logprob:  0.471782, 0.125000 (1.501 sec)
12.840... logprob:  0.555121, 0.156250 (1.458 sec)
12.841... logprob:  0.396415, 0.101562 (1.460 sec)
12.842... logprob:  0.497773, 0.140625 (1.494 sec)
12.843... logprob:  0.465573, 0.125000 (1.447 sec)
12.844... logprob:  0.497594, 0.140625 (1.463 sec)
12.845... logprob:  0.486875, 0.132812 (1.446 sec)
12.846... logprob:  0.468529, 0.125000 (1.446 sec)
12.847... logprob:  0.363023, 0.085938 (1.451 sec)
12.848... logprob:  0.396897, 0.101562 (1.495 sec)
12.849... logprob:  0.360069, 0.085938 (1.455 sec)
12.850... logprob:  0.479481, 0.132812 (1.464 sec)
12.851... logprob:  0.440171, 0.117188 (1.489 sec)
12.852... logprob:  0.546166, 0.156250 (1.451 sec)
12.853... logprob:  0.371683, 0.093750 (1.453 sec)
12.854... logprob:  0.306830, 0.070312 (1.443 sec)
12.855... logprob:  0.485119, 0.132812 (1.444 sec)
12.856... logprob:  0.443945, 0.117188 (1.453 sec)
12.857... logprob:  0.372259, 0.093750 (1.495 sec)
12.858... logprob:  0.396249, 0.101562 (1.463 sec)
12.859... logprob:  0.307946, 0.070312 (1.473 sec)
12.860... logprob:  0.565911, 0.156250 (1.486 sec)
12.861... logprob:  0.417829, 0.109375 (1.460 sec)
12.862... logprob:  0.328995, 0.078125 (1.455 sec)
12.863... logprob:  0.399488, 0.101562 (1.444 sec)
12.864... logprob:  0.451340, 0.117188 (1.446 sec)
12.865... logprob:  0.484295, 0.132812 (1.454 sec)
12.866... logprob:  0.507365, 0.140625 (1.484 sec)
12.867... logprob:  0.502677, 0.140625 (1.464 sec)
12.868... logprob:  0.405486, 0.101562 (1.470 sec)
12.869... logprob:  0.383479, 0.093750 (1.476 sec)
12.870... logprob:  0.551831, 0.156250 (1.404 sec)
13.1... logprob:  0.380313, 0.093750 (1.402 sec)
13.2... logprob:  0.448298, 0.117188 (1.456 sec)
13.3... logprob:  0.398488, 0.101562 (1.416 sec)
13.4... logprob:  0.443380, 0.117188 (1.408 sec)
13.5... logprob:  0.443385, 0.117188 (1.437 sec)
13.6... logprob:  0.499275, 0.140625 (1.395 sec)
13.7... logprob:  0.362927, 0.085938 (1.420 sec)
13.8... logprob:  0.419083, 0.109375 (1.399 sec)
13.9... logprob:  0.358545, 0.085938 (1.402 sec)
13.10... logprob:  0.377290, 0.093750 (1.412 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.12912368774414, 10.0]}, 128)
batch 872: ({'logprob': [67.14656066894531, 19.0]}, 128)
batch 873: ({'logprob': [40.13910675048828, 9.0]}, 128)
batch 874: ({'logprob': [45.263999938964844, 11.0]}, 128)
batch 875: ({'logprob': [50.83515548706055, 13.0]}, 128)
batch 876: ({'logprob': [64.48583221435547, 18.0]}, 128)
batch 877: ({'logprob': [45.49190902709961, 11.0]}, 128)
batch 878: ({'logprob': [62.01372146606445, 17.0]}, 128)
batch 879: ({'logprob': [73.3893814086914, 21.0]}, 128)
batch 880: ({'logprob': [50.85076904296875, 13.0]}, 128)
batch 881: ({'logprob': [28.733715057373047, 5.0]}, 128)
batch 882: ({'logprob': [54.19847106933594, 14.0]}, 128)
batch 883: ({'logprob': [62.00001907348633, 17.0]}, 128)
batch 884: ({'logprob': [51.058746337890625, 13.0]}, 128)
batch 885: ({'logprob': [51.50908279418945, 13.0]}, 128)
batch 886: ({'logprob': [62.2322883605957, 17.0]}, 128)

======================Test output======================
logprob:  0.415761, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.971483e-03 [2.965847e-09] 
Layer 'conv1' biases: 1.104237e-07 [9.217745e-11] 
Layer 'conv2' weights[0]: 7.958493e-03 [2.517883e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.074992e-10] 
Layer 'conv3' weights[0]: 7.956787e-03 [2.542731e-09] 
Layer 'conv3' biases: 9.786971e-07 [1.561466e-09] 
Layer 'conv4' weights[0]: 7.989354e-03 [2.860783e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.572419e-08] 
Layer 'conv5' weights[0]: 7.988237e-03 [1.068592e-07] 
Layer 'conv5' biases: 9.999984e-01 [1.161003e-07] 
Layer 'fc6' weights[0]: 7.585092e-03 [9.252673e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.308227e-09] 
Layer 'fc7' weights[0]: 7.451101e-03 [2.934679e-07] 
Layer 'fc7' biases: 9.998664e-01 [2.817301e-07] 
Layer 'fc8' weights[0]: 1.321115e-03 [1.086017e-05] 
Layer 'fc8' biases: 2.842750e-02 [7.188050e-05] 
Train error last 870 batches: 0.435280
-------------------------------------------------------
Not saving because 0.415761 > 0.415707 (12.630: -0.00%)
======================================================= (12.024 sec)
13.11... logprob:  0.334401, 0.078125 (1.457 sec)
13.12... logprob:  0.466647, 0.125000 (1.395 sec)
13.13... logprob:  0.442484, 0.117188 (1.426 sec)
13.14... logprob:  0.444892, 0.117188 (1.401 sec)
13.15... logprob:  0.395704, 0.101562 (1.407 sec)
13.16... logprob:  0.421506, 0.109375 (1.408 sec)
13.17... logprob:  0.516148, 0.140625 (1.397 sec)
13.18... logprob:  0.262126, 0.054688 (1.400 sec)
13.19... logprob:  0.279696, 0.062500 (1.405 sec)
13.20... logprob:  0.421383, 0.109375 (1.403 sec)
13.21... logprob:  0.443931, 0.117188 (0.892 sec)
13.22... logprob:  0.536482, 0.148438 (1.331 sec)
13.23... logprob:  0.532639, 0.148438 (1.423 sec)
13.24... logprob:  0.310906, 0.070312 (0.985 sec)
13.25... logprob:  0.356415, 0.085938 (0.960 sec)
13.26... logprob:  0.463619, 0.125000 (1.459 sec)
13.27... logprob:  0.404663, 0.101562 (1.386 sec)
13.28... logprob:  0.421889, 0.109375 (1.410 sec)
13.29... logprob:  0.396115, 0.101562 (1.419 sec)
13.30... logprob:  0.374230, 0.093750 (1.423 sec)
13.31... logprob:  0.479884, 0.132812 (1.401 sec)
13.32... logprob:  0.457243, 0.125000 (1.393 sec)
13.33... logprob:  0.460683, 0.125000 (1.454 sec)
13.34... logprob:  0.464675, 0.125000 (1.390 sec)
13.35... logprob:  0.316141, 0.070312 (1.406 sec)
13.36... logprob:  0.475817, 0.132812 (1.399 sec)
13.37... logprob:  0.417606, 0.109375 (1.409 sec)
13.38... logprob:  0.392465, 0.101562 (1.392 sec)
13.39... logprob:  0.632063, 0.187500 (1.441 sec)
13.40... logprob:  0.445888, 0.117188 (1.411 sec)
13.41... logprob:  0.352719, 0.085938 (1.427 sec)
13.42... logprob:  0.391809, 0.101562 (1.415 sec)
13.43... logprob:  0.440139, 0.117188 (1.415 sec)
13.44... logprob:  0.518491, 0.148438 (1.435 sec)
13.45... logprob:  0.381802, 0.093750 (1.394 sec)
13.46... logprob:  0.486416, 0.132812 (1.399 sec)
13.47... logprob:  0.331790, 0.078125 (1.398 sec)
13.48... logprob:  0.498865, 0.140625 (1.428 sec)
13.49... logprob:  0.510591, 0.148438 (1.417 sec)
13.50... logprob:  0.393273, 0.101562 (1.428 sec)
13.51... logprob:  0.489958, 0.140625 (1.416 sec)
13.52... logprob:  0.525776, 0.148438 (1.399 sec)
13.53... logprob:  0.295103, 0.062500 (1.446 sec)
13.54... logprob:  0.403227, 0.109375 (1.394 sec)
13.55... logprob:  0.331819, 0.078125 (1.396 sec)
13.56... logprob:  0.421732, 0.109375 (1.407 sec)
13.57... logprob:  0.572590, 0.164062 (1.431 sec)
13.58... logprob:  0.407811, 0.101562 (1.405 sec)
13.59... logprob:  0.333842, 0.078125 (1.467 sec)
13.60... logprob:  0.619117, 0.179688 (1.423 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.34379959106445, 10.0]}, 128)
batch 872: ({'logprob': [66.45023345947266, 19.0]}, 128)
batch 873: ({'logprob': [40.866416931152344, 9.0]}, 128)
batch 874: ({'logprob': [45.1757926940918, 11.0]}, 128)
batch 875: ({'logprob': [50.81740951538086, 13.0]}, 128)
batch 876: ({'logprob': [63.974822998046875, 18.0]}, 128)
batch 877: ({'logprob': [45.84585189819336, 11.0]}, 128)
batch 878: ({'logprob': [62.13251495361328, 17.0]}, 128)
batch 879: ({'logprob': [74.08551788330078, 21.0]}, 128)
batch 880: ({'logprob': [50.83124542236328, 13.0]}, 128)
batch 881: ({'logprob': [28.882465362548828, 5.0]}, 128)
batch 882: ({'logprob': [55.318450927734375, 14.0]}, 128)
batch 883: ({'logprob': [62.11933135986328, 17.0]}, 128)
batch 884: ({'logprob': [51.48171615600586, 13.0]}, 128)
batch 885: ({'logprob': [52.81587219238281, 13.0]}, 128)
batch 886: ({'logprob': [62.792606353759766, 17.0]}, 128)

======================Test output======================
logprob:  0.417448, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.971441e-03 [3.630566e-09] 
Layer 'conv1' biases: 1.111815e-07 [1.077802e-10] 
Layer 'conv2' weights[0]: 7.958454e-03 [2.869241e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.123163e-10] 
Layer 'conv3' weights[0]: 7.956744e-03 [3.004254e-09] 
Layer 'conv3' biases: 9.857154e-07 [1.955782e-09] 
Layer 'conv4' weights[0]: 7.989309e-03 [3.256551e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.890511e-08] 
Layer 'conv5' weights[0]: 7.988208e-03 [1.294435e-07] 
Layer 'conv5' biases: 9.999986e-01 [1.405327e-07] 
Layer 'fc6' weights[0]: 7.585053e-03 [1.105003e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.131178e-08] 
Layer 'fc7' weights[0]: 7.449251e-03 [1.018844e-07] 
Layer 'fc7' biases: 9.998665e-01 [8.772584e-08] 
Layer 'fc8' weights[0]: 1.322007e-03 [2.907549e-06] 
Layer 'fc8' biases: 2.848159e-02 [1.696124e-05] 
Train error last 870 batches: 0.435280
-------------------------------------------------------
Not saving because 0.417448 > 0.415707 (12.630: -0.00%)
======================================================= (12.064 sec)
13.61... logprob:  0.382874, 0.093750 (1.439 sec)
13.62... logprob:  0.474929, 0.132812 (1.467 sec)
13.63... logprob:  0.397315, 0.101562 (1.441 sec)
13.64... logprob:  0.450259, 0.125000 (1.408 sec)
13.65... logprob:  0.373305, 0.093750 (1.403 sec)
13.66... logprob:  0.353994, 0.085938 (1.443 sec)
13.67... logprob:  0.295378, 0.062500 (1.393 sec)
13.68... logprob:  0.396828, 0.101562 (1.396 sec)
13.69... logprob:  0.496872, 0.140625 (1.431 sec)
13.70... logprob:  0.325876, 0.078125 (1.453 sec)
13.71... logprob:  0.381852, 0.101562 (1.464 sec)
13.72... logprob:  0.493878, 0.132812 (1.409 sec)
13.73... logprob:  0.447799, 0.117188 (1.424 sec)
13.74... logprob:  0.442612, 0.117188 (1.417 sec)
13.75... logprob:  0.380643, 0.093750 (1.421 sec)
13.76... logprob:  0.412097, 0.109375 (1.431 sec)
13.77... logprob:  0.396346, 0.101562 (1.434 sec)
13.78... logprob:  0.493069, 0.140625 (1.457 sec)
13.79... logprob:  0.456435, 0.125000 (1.404 sec)
13.80... logprob:  0.507850, 0.132812 (1.417 sec)
13.81... logprob:  0.416724, 0.109375 (1.423 sec)
13.82... logprob:  0.231936, 0.039062 (1.421 sec)
13.83... logprob:  0.493698, 0.140625 (1.405 sec)
13.84... logprob:  0.468072, 0.125000 (1.532 sec)
13.85... logprob:  0.432057, 0.117188 (1.421 sec)
13.86... logprob:  0.417009, 0.109375 (1.420 sec)
13.87... logprob:  0.633174, 0.187500 (1.412 sec)
13.88... logprob:  0.535126, 0.156250 (1.415 sec)
13.89... logprob:  0.410645, 0.109375 (1.438 sec)
13.90... logprob:  0.577524, 0.171875 (1.393 sec)
13.91... logprob:  0.348577, 0.078125 (1.401 sec)
13.92... logprob:  0.464461, 0.125000 (1.402 sec)
13.93... logprob:  0.492301, 0.140625 (1.397 sec)
13.94... logprob:  0.428785, 0.109375 (1.405 sec)
13.95... logprob:  0.471869, 0.125000 (1.406 sec)
13.96... logprob:  0.576399, 0.171875 (1.414 sec)
13.97... logprob:  0.430747, 0.117188 (1.392 sec)
13.98... logprob:  0.390988, 0.093750 (1.439 sec)
13.99... logprob:  0.474343, 0.132812 (1.407 sec)
13.100... logprob:  0.310298, 0.070312 (1.401 sec)
13.101... logprob:  0.310444, 0.062500 (1.447 sec)
13.102... logprob:  0.546482, 0.156250 (1.390 sec)
13.103... logprob:  0.541451, 0.156250 (1.404 sec)
13.104... logprob:  0.388889, 0.101562 (1.411 sec)
13.105... logprob:  0.619942, 0.179688 (1.402 sec)
13.106... logprob:  0.344421, 0.085938 (1.393 sec)
13.107... logprob:  0.335681, 0.078125 (1.451 sec)
13.108... logprob:  0.586790, 0.171875 (1.395 sec)
13.109... logprob:  0.336233, 0.078125 (1.405 sec)
13.110... logprob:  0.564364, 0.164062 (1.402 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.74357223510742, 10.0]}, 128)
batch 872: ({'logprob': [66.45620727539062, 19.0]}, 128)
batch 873: ({'logprob': [40.720943450927734, 9.0]}, 128)
batch 874: ({'logprob': [45.26588821411133, 11.0]}, 128)
batch 875: ({'logprob': [50.800621032714844, 13.0]}, 128)
batch 876: ({'logprob': [63.94901657104492, 18.0]}, 128)
batch 877: ({'logprob': [45.76527786254883, 11.0]}, 128)
batch 878: ({'logprob': [61.90312576293945, 17.0]}, 128)
batch 879: ({'logprob': [73.47313690185547, 21.0]}, 128)
batch 880: ({'logprob': [50.815040588378906, 13.0]}, 128)
batch 881: ({'logprob': [29.120731353759766, 5.0]}, 128)
batch 882: ({'logprob': [54.8213005065918, 14.0]}, 128)
batch 883: ({'logprob': [61.88970184326172, 17.0]}, 128)
batch 884: ({'logprob': [51.294071197509766, 13.0]}, 128)
batch 885: ({'logprob': [52.286102294921875, 13.0]}, 128)
batch 886: ({'logprob': [62.39213180541992, 17.0]}, 128)

======================Test output======================
logprob:  0.416356, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.971400e-03 [3.305935e-09] 
Layer 'conv1' biases: 1.119170e-07 [9.341658e-11] 
Layer 'conv2' weights[0]: 7.958419e-03 [3.113942e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.413984e-10] 
Layer 'conv3' weights[0]: 7.956700e-03 [2.937862e-09] 
Layer 'conv3' biases: 9.918685e-07 [1.731374e-09] 
Layer 'conv4' weights[0]: 7.989270e-03 [3.218893e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.620448e-08] 
Layer 'conv5' weights[0]: 7.988158e-03 [1.092696e-07] 
Layer 'conv5' biases: 9.999988e-01 [1.182472e-07] 
Layer 'fc6' weights[0]: 7.585015e-03 [9.525098e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.566851e-09] 
Layer 'fc7' weights[0]: 7.447321e-03 [1.820496e-07] 
Layer 'fc7' biases: 9.998661e-01 [1.708838e-07] 
Layer 'fc8' weights[0]: 1.315709e-03 [7.005150e-06] 
Layer 'fc8' biases: 2.854603e-02 [4.160198e-05] 
Train error last 870 batches: 0.435280
-------------------------------------------------------
Not saving because 0.416356 > 0.415707 (12.630: -0.00%)
======================================================= (12.046 sec)
13.111... logprob:  0.404758, 0.101562 (1.408 sec)
13.112... logprob:  0.366246, 0.093750 (1.412 sec)
13.113... logprob:  0.354746, 0.085938 (1.405 sec)
13.114... logprob:  0.440242, 0.117188 (1.435 sec)
13.115... logprob:  0.506716, 0.140625 (1.413 sec)
13.116... logprob:  0.393425, 0.101562 (1.398 sec)
13.117... logprob:  0.440398, 0.117188 (1.449 sec)
13.118... logprob:  0.409196, 0.101562 (1.388 sec)
13.119... logprob:  0.346148, 0.085938 (1.400 sec)
13.120... logprob:  0.547166, 0.156250 (1.403 sec)
13.121... logprob:  0.412704, 0.109375 (1.397 sec)
13.122... logprob:  0.519400, 0.148438 (1.448 sec)
13.123... logprob:  0.463773, 0.125000 (1.386 sec)
13.124... logprob:  0.447724, 0.125000 (1.409 sec)
13.125... logprob:  0.502036, 0.140625 (1.398 sec)
13.126... logprob:  0.475827, 0.125000 (1.395 sec)
13.127... logprob:  0.479662, 0.125000 (1.399 sec)
13.128... logprob:  0.422396, 0.109375 (1.420 sec)
13.129... logprob:  0.574897, 0.164062 (1.422 sec)
13.130... logprob:  0.382772, 0.093750 (1.426 sec)
13.131... logprob:  0.495506, 0.132812 (1.415 sec)
13.132... logprob:  0.506395, 0.140625 (1.439 sec)
13.133... logprob:  0.444687, 0.117188 (1.387 sec)
13.134... logprob:  0.401932, 0.101562 (1.401 sec)
13.135... logprob:  0.460257, 0.125000 (1.399 sec)
13.136... logprob:  0.562627, 0.164062 (1.405 sec)
13.137... logprob:  0.462563, 0.125000 (1.387 sec)
13.138... logprob:  0.319322, 0.070312 (1.451 sec)
13.139... logprob:  0.395792, 0.101562 (1.404 sec)
13.140... logprob:  0.560608, 0.164062 (1.414 sec)
13.141... logprob:  0.464530, 0.125000 (1.435 sec)
13.142... logprob:  0.464605, 0.125000 (1.398 sec)
13.143... logprob:  0.294223, 0.062500 (1.429 sec)
13.144... logprob:  0.457366, 0.125000 (1.417 sec)
13.145... logprob:  0.324902, 0.078125 (1.420 sec)
13.146... logprob:  0.483274, 0.132812 (1.420 sec)
13.147... logprob:  0.262467, 0.054688 (1.437 sec)
13.148... logprob:  0.458880, 0.125000 (1.395 sec)
13.149... logprob:  0.442582, 0.117188 (1.393 sec)
13.150... logprob:  0.347643, 0.085938 (1.406 sec)
13.151... logprob:  0.347158, 0.085938 (1.399 sec)
13.152... logprob:  0.784976, 0.234375 (1.388 sec)
13.153... logprob:  0.381673, 0.093750 (1.450 sec)
13.154... logprob:  0.524312, 0.148438 (1.397 sec)
13.155... logprob:  0.425956, 0.117188 (1.416 sec)
13.156... logprob:  0.296059, 0.062500 (1.432 sec)
13.157... logprob:  0.270975, 0.054688 (1.399 sec)
13.158... logprob:  0.455356, 0.125000 (1.403 sec)
13.159... logprob:  0.483117, 0.132812 (1.401 sec)
13.160... logprob:  0.444929, 0.117188 (1.394 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.92047882080078, 10.0]}, 128)
batch 872: ({'logprob': [66.11372375488281, 19.0]}, 128)
batch 873: ({'logprob': [41.256221771240234, 9.0]}, 128)
batch 874: ({'logprob': [45.52070999145508, 11.0]}, 128)
batch 875: ({'logprob': [50.95038604736328, 13.0]}, 128)
batch 876: ({'logprob': [63.70260238647461, 18.0]}, 128)
batch 877: ({'logprob': [46.10792922973633, 11.0]}, 128)
batch 878: ({'logprob': [61.84112548828125, 17.0]}, 128)
batch 879: ({'logprob': [73.28639221191406, 21.0]}, 128)
batch 880: ({'logprob': [50.96438980102539, 13.0]}, 128)
batch 881: ({'logprob': [29.78069496154785, 5.0]}, 128)
batch 882: ({'logprob': [55.13550567626953, 14.0]}, 128)
batch 883: ({'logprob': [61.82774353027344, 17.0]}, 128)
batch 884: ({'logprob': [51.5301513671875, 13.0]}, 128)
batch 885: ({'logprob': [52.696533203125, 13.0]}, 128)
batch 886: ({'logprob': [62.4168701171875, 17.0]}, 128)

======================Test output======================
logprob:  0.417506, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.971365e-03 [1.880466e-09] 
Layer 'conv1' biases: 1.126335e-07 [3.262017e-11] 
Layer 'conv2' weights[0]: 7.958383e-03 [1.436064e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.218751e-10] 
Layer 'conv3' weights[0]: 7.956660e-03 [1.158146e-09] 
Layer 'conv3' biases: 9.980472e-07 [3.621870e-10] 
Layer 'conv4' weights[0]: 7.989234e-03 [1.112314e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.742072e-09] 
Layer 'conv5' weights[0]: 7.988120e-03 [8.337708e-09] 
Layer 'conv5' biases: 9.999987e-01 [8.600081e-09] 
Layer 'fc6' weights[0]: 7.584974e-03 [1.064847e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.114160e-10] 
Layer 'fc7' weights[0]: 7.445424e-03 [4.187621e-08] 
Layer 'fc7' biases: 9.998659e-01 [1.529143e-08] 
Layer 'fc8' weights[0]: 1.308153e-03 [4.382789e-06] 
Layer 'fc8' biases: 2.858374e-02 [2.522718e-05] 
Train error last 870 batches: 0.435279
-------------------------------------------------------
Not saving because 0.417506 > 0.415707 (12.630: -0.00%)
======================================================= (12.153 sec)
13.161... logprob:  0.350247, 0.078125 (1.409 sec)
13.162... logprob:  0.611807, 0.179688 (1.418 sec)
13.163... logprob:  0.450422, 0.125000 (1.434 sec)
13.164... logprob:  0.468725, 0.125000 (1.424 sec)
13.165... logprob:  0.548006, 0.156250 (1.418 sec)
13.166... logprob:  0.446050, 0.125000 (1.455 sec)
13.167... logprob:  0.350363, 0.085938 (1.427 sec)
13.168... logprob:  0.363649, 0.085938 (1.428 sec)
13.169... logprob:  0.408693, 0.101562 (1.465 sec)
13.170... logprob:  0.459503, 0.125000 (1.399 sec)
13.171... logprob:  0.535532, 0.156250 (1.423 sec)
13.172... logprob:  0.434884, 0.109375 (1.417 sec)
13.173... logprob:  0.440507, 0.117188 (1.425 sec)
13.174... logprob:  0.601256, 0.171875 (1.411 sec)
13.175... logprob:  0.506162, 0.140625 (1.472 sec)
13.176... logprob:  0.478516, 0.132812 (1.414 sec)
13.177... logprob:  0.289793, 0.054688 (1.432 sec)
13.178... logprob:  0.383498, 0.093750 (1.456 sec)
13.179... logprob:  0.394747, 0.101562 (1.432 sec)
13.180... logprob:  0.466382, 0.125000 (1.436 sec)
13.181... logprob:  0.539429, 0.156250 (1.419 sec)
13.182... logprob:  0.371435, 0.093750 (1.416 sec)
13.183... logprob:  0.419969, 0.109375 (1.419 sec)
13.184... logprob:  0.483489, 0.132812 (1.418 sec)
13.185... logprob:  0.289904, 0.062500 (1.394 sec)
13.186... logprob:  0.370541, 0.093750 (1.406 sec)
13.187... logprob:  0.529636, 0.148438 (1.401 sec)
13.188... logprob:  0.459017, 0.125000 (1.401 sec)
13.189... logprob:  0.440904, 0.117188 (1.385 sec)
13.190... logprob:  0.375732, 0.093750 (1.441 sec)
13.191... logprob:  0.485107, 0.132812 (1.406 sec)
13.192... logprob:  0.520198, 0.148438 (1.421 sec)
13.193... logprob:  0.312650, 0.070312 (1.423 sec)
13.194... logprob:  0.414125, 0.109375 (1.415 sec)
13.195... logprob:  0.287276, 0.062500 (1.399 sec)
13.196... logprob:  0.410572, 0.109375 (1.392 sec)
13.197... logprob:  0.478039, 0.132812 (1.403 sec)
13.198... logprob:  0.355792, 0.085938 (1.406 sec)
13.199... logprob:  0.437194, 0.117188 (1.393 sec)
13.200... logprob:  0.440785, 0.117188 (1.442 sec)
13.201... logprob:  0.437102, 0.117188 (1.412 sec)
13.202... logprob:  0.537999, 0.148438 (1.412 sec)
13.203... logprob:  0.420473, 0.109375 (1.450 sec)
13.204... logprob:  0.504128, 0.140625 (1.388 sec)
13.205... logprob:  0.334413, 0.078125 (1.402 sec)
13.206... logprob:  0.361637, 0.093750 (1.404 sec)
13.207... logprob:  0.381931, 0.093750 (1.398 sec)
13.208... logprob:  0.490514, 0.140625 (1.400 sec)
13.209... logprob:  0.334613, 0.078125 (1.425 sec)
13.210... logprob:  0.586256, 0.171875 (1.418 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.689056396484375, 10.0]}, 128)
batch 872: ({'logprob': [66.32682037353516, 19.0]}, 128)
batch 873: ({'logprob': [40.91220474243164, 9.0]}, 128)
batch 874: ({'logprob': [45.31018829345703, 11.0]}, 128)
batch 875: ({'logprob': [50.836181640625, 13.0]}, 128)
batch 876: ({'logprob': [63.85852813720703, 18.0]}, 128)
batch 877: ({'logprob': [45.8786735534668, 11.0]}, 128)
batch 878: ({'logprob': [61.920753479003906, 17.0]}, 128)
batch 879: ({'logprob': [73.54110717773438, 21.0]}, 128)
batch 880: ({'logprob': [50.850582122802734, 13.0]}, 128)
batch 881: ({'logprob': [29.261178970336914, 5.0]}, 128)
batch 882: ({'logprob': [55.02445602416992, 14.0]}, 128)
batch 883: ({'logprob': [61.90712356567383, 17.0]}, 128)
batch 884: ({'logprob': [51.39829635620117, 13.0]}, 128)
batch 885: ({'logprob': [52.528079986572266, 13.0]}, 128)
batch 886: ({'logprob': [62.4785041809082, 17.0]}, 128)

======================Test output======================
logprob:  0.416856, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.971328e-03 [2.667381e-09] 
Layer 'conv1' biases: 1.134306e-07 [1.065839e-10] 
Layer 'conv2' weights[0]: 7.958339e-03 [2.035558e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.773716e-10] 
Layer 'conv3' weights[0]: 7.956623e-03 [2.165875e-09] 
Layer 'conv3' biases: 1.004733e-06 [1.396603e-09] 
Layer 'conv4' weights[0]: 7.989196e-03 [2.242705e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.278145e-08] 
Layer 'conv5' weights[0]: 7.988077e-03 [8.570131e-08] 
Layer 'conv5' biases: 9.999988e-01 [9.274159e-08] 
Layer 'fc6' weights[0]: 7.584937e-03 [7.390544e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.497087e-09] 
Layer 'fc7' weights[0]: 7.443533e-03 [8.091760e-08] 
Layer 'fc7' biases: 9.998659e-01 [6.518199e-08] 
Layer 'fc8' weights[0]: 1.321614e-03 [4.748864e-06] 
Layer 'fc8' biases: 2.875055e-02 [2.966059e-05] 
Train error last 870 batches: 0.435279
-------------------------------------------------------
Not saving because 0.416856 > 0.415707 (12.630: -0.00%)
======================================================= (12.063 sec)
13.211... logprob:  0.488206, 0.132812 (1.422 sec)
13.212... logprob:  0.526159, 0.148438 (1.422 sec)
13.213... logprob:  0.514843, 0.140625 (1.492 sec)
13.214... logprob:  0.459448, 0.125000 (1.440 sec)
13.215... logprob:  0.396162, 0.101562 (1.420 sec)
13.216... logprob:  0.517143, 0.140625 (1.478 sec)
13.217... logprob:  0.325151, 0.070312 (1.397 sec)
13.218... logprob:  0.463723, 0.125000 (1.424 sec)
13.219... logprob:  0.500328, 0.140625 (1.422 sec)
13.220... logprob:  0.414994, 0.109375 (1.423 sec)
13.221... logprob:  0.399537, 0.101562 (1.410 sec)
13.222... logprob:  0.554614, 0.164062 (1.459 sec)
13.223... logprob:  0.569298, 0.164062 (1.425 sec)
13.224... logprob:  0.405857, 0.101562 (1.436 sec)
13.225... logprob:  0.391964, 0.101562 (1.448 sec)
13.226... logprob:  0.424616, 0.109375 (1.424 sec)
13.227... logprob:  0.452757, 0.125000 (1.426 sec)
13.228... logprob:  0.417208, 0.109375 (1.415 sec)
13.229... logprob:  0.489372, 0.132812 (1.422 sec)
13.230... logprob:  0.459907, 0.125000 (1.440 sec)
13.231... logprob:  0.453551, 0.125000 (1.403 sec)
13.232... logprob:  0.496236, 0.140625 (1.464 sec)
13.233... logprob:  0.466181, 0.132812 (1.426 sec)
13.234... logprob:  0.563789, 0.164062 (1.418 sec)
13.235... logprob:  0.482038, 0.132812 (1.470 sec)
13.236... logprob:  0.425827, 0.109375 (1.403 sec)
13.237... logprob:  0.341407, 0.078125 (1.426 sec)
13.238... logprob:  0.389428, 0.093750 (1.415 sec)
13.239... logprob:  0.478158, 0.132812 (1.422 sec)
13.240... logprob:  0.485812, 0.132812 (1.404 sec)
13.241... logprob:  0.493610, 0.132812 (1.459 sec)
13.242... logprob:  0.341654, 0.078125 (1.440 sec)
13.243... logprob:  0.386025, 0.093750 (1.434 sec)
13.244... logprob:  0.315192, 0.070312 (1.454 sec)
13.245... logprob:  0.494383, 0.132812 (1.420 sec)
13.246... logprob:  0.416920, 0.109375 (1.419 sec)
13.247... logprob:  0.357327, 0.085938 (1.421 sec)
13.248... logprob:  0.307702, 0.070312 (1.415 sec)
13.249... logprob:  0.555594, 0.156250 (1.425 sec)
13.250... logprob:  0.591852, 0.164062 (1.416 sec)
13.251... logprob:  0.352901, 0.085938 (1.460 sec)
13.252... logprob:  0.348496, 0.085938 (1.426 sec)
13.253... logprob:  0.379174, 0.093750 (1.421 sec)
13.254... logprob:  0.444185, 0.117188 (1.464 sec)
13.255... logprob:  0.351520, 0.085938 (1.417 sec)
13.256... logprob:  0.378737, 0.093750 (1.423 sec)
13.257... logprob:  0.332067, 0.078125 (1.415 sec)
13.258... logprob:  0.415795, 0.109375 (1.426 sec)
13.259... logprob:  0.442309, 0.117188 (1.401 sec)
13.260... logprob:  0.308428, 0.070312 (1.459 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.86751937866211, 10.0]}, 128)
batch 872: ({'logprob': [67.85102081298828, 19.0]}, 128)
batch 873: ({'logprob': [39.62660217285156, 9.0]}, 128)
batch 874: ({'logprob': [45.04508590698242, 11.0]}, 128)
batch 875: ({'logprob': [50.82524871826172, 13.0]}, 128)
batch 876: ({'logprob': [65.06554412841797, 18.0]}, 128)
batch 877: ({'logprob': [45.230613708496094, 11.0]}, 128)
batch 878: ({'logprob': [62.42474365234375, 17.0]}, 128)
batch 879: ({'logprob': [74.17857360839844, 21.0]}, 128)
batch 880: ({'logprob': [50.84172821044922, 13.0]}, 128)
batch 881: ({'logprob': [27.842056274414062, 5.0]}, 128)
batch 882: ({'logprob': [54.19075012207031, 14.0]}, 128)
batch 883: ({'logprob': [62.41047668457031, 17.0]}, 128)
batch 884: ({'logprob': [51.00862503051758, 13.0]}, 128)
batch 885: ({'logprob': [51.3755989074707, 13.0]}, 128)
batch 886: ({'logprob': [62.60220718383789, 17.0]}, 128)

======================Test output======================
logprob:  0.416204, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.971288e-03 [1.945932e-09] 
Layer 'conv1' biases: 1.142349e-07 [5.428899e-11] 
Layer 'conv2' weights[0]: 7.958299e-03 [1.661694e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.587882e-10] 
Layer 'conv3' weights[0]: 7.956591e-03 [1.630802e-09] 
Layer 'conv3' biases: 1.009941e-06 [8.180971e-10] 
Layer 'conv4' weights[0]: 7.989149e-03 [1.825591e-09] 
Layer 'conv4' biases: 9.999998e-01 [8.186911e-09] 
Layer 'conv5' weights[0]: 7.988038e-03 [5.594716e-08] 
Layer 'conv5' biases: 9.999986e-01 [6.071659e-08] 
Layer 'fc6' weights[0]: 7.584897e-03 [4.903145e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.877438e-09] 
Layer 'fc7' weights[0]: 7.441617e-03 [7.816116e-08] 
Layer 'fc7' biases: 9.998665e-01 [6.142680e-08] 
Layer 'fc8' weights[0]: 1.353968e-03 [2.564837e-06] 
Layer 'fc8' biases: 2.906737e-02 [1.726886e-05] 
Train error last 870 batches: 0.435278
-------------------------------------------------------
Not saving because 0.416204 > 0.415707 (12.630: -0.00%)
======================================================= (12.052 sec)
13.261... logprob:  0.392838, 0.101562 (1.436 sec)
13.262... logprob:  0.524676, 0.148438 (1.433 sec)
13.263... logprob:  0.425469, 0.109375 (1.455 sec)
13.264... logprob:  0.375177, 0.093750 (1.423 sec)
13.265... logprob:  0.439615, 0.117188 (1.418 sec)
13.266... logprob:  0.439045, 0.117188 (1.415 sec)
13.267... logprob:  0.422002, 0.109375 (1.421 sec)
13.268... logprob:  0.458949, 0.125000 (1.422 sec)
13.269... logprob:  0.567458, 0.164062 (1.408 sec)
13.270... logprob:  0.542195, 0.156250 (1.462 sec)
13.271... logprob:  0.445773, 0.117188 (1.425 sec)
13.272... logprob:  0.384790, 0.093750 (1.421 sec)
13.273... logprob:  0.500217, 0.140625 (1.463 sec)
13.274... logprob:  0.542539, 0.156250 (1.406 sec)
13.275... logprob:  0.487757, 0.132812 (1.427 sec)
13.276... logprob:  0.390200, 0.093750 (1.423 sec)
13.277... logprob:  0.428740, 0.109375 (1.427 sec)
13.278... logprob:  0.323363, 0.070312 (1.428 sec)
13.279... logprob:  0.324920, 0.070312 (1.468 sec)
13.280... logprob:  0.215032, 0.031250 (1.413 sec)
13.281... logprob:  0.417216, 0.109375 (1.425 sec)
13.282... logprob:  0.411498, 0.109375 (1.418 sec)
13.283... logprob:  0.393886, 0.101562 (1.419 sec)
13.284... logprob:  0.394752, 0.101562 (1.413 sec)
13.285... logprob:  0.452286, 0.117188 (1.449 sec)
13.286... logprob:  0.537683, 0.140625 (1.438 sec)
13.287... logprob:  0.346705, 0.085938 (1.433 sec)
13.288... logprob:  0.329985, 0.078125 (1.470 sec)
13.289... logprob:  0.446060, 0.117188 (1.444 sec)
13.290... logprob:  0.490652, 0.132812 (1.410 sec)
13.291... logprob:  0.439129, 0.117188 (1.419 sec)
13.292... logprob:  0.566917, 0.156250 (1.418 sec)
13.293... logprob:  0.427458, 0.117188 (1.421 sec)
13.294... logprob:  0.356275, 0.085938 (1.409 sec)
13.295... logprob:  0.335264, 0.078125 (1.466 sec)
13.296... logprob:  0.356335, 0.085938 (1.419 sec)
13.297... logprob:  0.394896, 0.101562 (1.427 sec)
13.298... logprob:  0.448095, 0.125000 (1.469 sec)
13.299... logprob:  0.342744, 0.078125 (1.407 sec)
13.300... logprob:  0.406737, 0.101562 (1.422 sec)
13.301... logprob:  0.397975, 0.101562 (1.423 sec)
13.302... logprob:  0.591571, 0.179688 (1.414 sec)
13.303... logprob:  0.459666, 0.125000 (1.413 sec)
13.304... logprob:  0.459731, 0.125000 (1.439 sec)
13.305... logprob:  0.455253, 0.125000 (1.440 sec)
13.306... logprob:  0.440619, 0.117188 (1.434 sec)
13.307... logprob:  0.421596, 0.109375 (1.446 sec)
13.308... logprob:  0.374512, 0.093750 (1.454 sec)
13.309... logprob:  0.450499, 0.125000 (1.414 sec)
13.310... logprob:  0.473786, 0.125000 (1.420 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.75275421142578, 10.0]}, 128)
batch 872: ({'logprob': [66.20068359375, 19.0]}, 128)
batch 873: ({'logprob': [41.117305755615234, 9.0]}, 128)
batch 874: ({'logprob': [45.40705108642578, 11.0]}, 128)
batch 875: ({'logprob': [50.89502716064453, 13.0]}, 128)
batch 876: ({'logprob': [63.76879119873047, 18.0]}, 128)
batch 877: ({'logprob': [46.01063919067383, 11.0]}, 128)
batch 878: ({'logprob': [61.9028434753418, 17.0]}, 128)
batch 879: ({'logprob': [73.48139953613281, 21.0]}, 128)
batch 880: ({'logprob': [50.90922164916992, 13.0]}, 128)
batch 881: ({'logprob': [29.508190155029297, 5.0]}, 128)
batch 882: ({'logprob': [55.15115737915039, 14.0]}, 128)
batch 883: ({'logprob': [61.889278411865234, 17.0]}, 128)
batch 884: ({'logprob': [51.49180221557617, 13.0]}, 128)
batch 885: ({'logprob': [52.69132995605469, 13.0]}, 128)
batch 886: ({'logprob': [62.495391845703125, 17.0]}, 128)

======================Test output======================
logprob:  0.417321, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.971250e-03 [2.215222e-09] 
Layer 'conv1' biases: 1.151087e-07 [3.915790e-11] 
Layer 'conv2' weights[0]: 7.958258e-03 [1.349300e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.251871e-10] 
Layer 'conv3' weights[0]: 7.956551e-03 [1.111006e-09] 
Layer 'conv3' biases: 1.017090e-06 [3.970024e-10] 
Layer 'conv4' weights[0]: 7.989112e-03 [1.091889e-09] 
Layer 'conv4' biases: 9.999998e-01 [2.556595e-09] 
Layer 'conv5' weights[0]: 7.987999e-03 [1.580949e-08] 
Layer 'conv5' biases: 9.999986e-01 [1.677091e-08] 
Layer 'fc6' weights[0]: 7.584864e-03 [1.560086e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.358586e-09] 
Layer 'fc7' weights[0]: 7.439751e-03 [4.189921e-08] 
Layer 'fc7' biases: 9.998658e-01 [1.572690e-08] 
Layer 'fc8' weights[0]: 1.316491e-03 [6.240568e-07] 
Layer 'fc8' biases: 2.909344e-02 [6.756495e-06] 
Train error last 870 batches: 0.435278
-------------------------------------------------------
Not saving because 0.417321 > 0.415707 (12.630: -0.00%)
======================================================= (12.148 sec)
13.311... logprob:  0.502698, 0.140625 (1.439 sec)
13.312... logprob:  0.478821, 0.132812 (1.443 sec)
13.313... logprob:  0.454876, 0.125000 (1.417 sec)
13.314... logprob:  0.454540, 0.117188 (1.468 sec)
13.315... logprob:  0.314705, 0.070312 (1.437 sec)
13.316... logprob:  0.468592, 0.125000 (1.420 sec)
13.317... logprob:  0.355549, 0.085938 (1.481 sec)
13.318... logprob:  0.455423, 0.125000 (1.414 sec)
13.319... logprob:  0.423220, 0.117188 (1.429 sec)
13.320... logprob:  0.412270, 0.109375 (1.424 sec)
13.321... logprob:  0.348305, 0.085938 (1.453 sec)
13.322... logprob:  0.387543, 0.101562 (1.409 sec)
13.323... logprob:  0.416530, 0.109375 (1.473 sec)
13.324... logprob:  0.498646, 0.140625 (1.425 sec)
13.325... logprob:  0.350682, 0.085938 (1.440 sec)
13.326... logprob:  0.543205, 0.148438 (1.463 sec)
13.327... logprob:  0.554414, 0.164062 (1.427 sec)
13.328... logprob:  0.565006, 0.156250 (1.421 sec)
13.329... logprob:  0.402017, 0.101562 (1.426 sec)
13.330... logprob:  0.388697, 0.101562 (1.427 sec)
13.331... logprob:  0.352586, 0.085938 (1.418 sec)
13.332... logprob:  0.482796, 0.132812 (1.449 sec)
13.333... logprob:  0.339669, 0.085938 (1.442 sec)
13.334... logprob:  0.565080, 0.171875 (1.449 sec)
13.335... logprob:  0.358898, 0.085938 (1.435 sec)
13.336... logprob:  0.444829, 0.125000 (1.463 sec)
13.337... logprob:  0.566493, 0.164062 (1.424 sec)
13.338... logprob:  0.449519, 0.125000 (1.420 sec)
13.339... logprob:  0.488726, 0.132812 (1.436 sec)
13.340... logprob:  0.442079, 0.117188 (1.432 sec)
13.341... logprob:  0.530166, 0.148438 (1.417 sec)
13.342... logprob:  0.429696, 0.109375 (1.466 sec)
13.343... logprob:  0.434787, 0.109375 (1.437 sec)
13.344... logprob:  0.444409, 0.125000 (1.481 sec)
13.345... logprob:  0.488280, 0.132812 (1.443 sec)
13.346... logprob:  0.436255, 0.117188 (1.435 sec)
13.347... logprob:  0.372322, 0.085938 (1.486 sec)
13.348... logprob:  0.398436, 0.101562 (1.437 sec)
13.349... logprob:  0.497936, 0.140625 (1.432 sec)
13.350... logprob:  0.358527, 0.085938 (1.441 sec)
13.351... logprob:  0.508718, 0.140625 (1.431 sec)
13.352... logprob:  0.363674, 0.093750 (1.431 sec)
13.353... logprob:  0.512853, 0.148438 (1.494 sec)
13.354... logprob:  0.675203, 0.203125 (1.431 sec)
13.355... logprob:  0.357474, 0.085938 (1.447 sec)
13.356... logprob:  0.479257, 0.132812 (1.480 sec)
13.357... logprob:  0.347097, 0.085938 (1.429 sec)
13.358... logprob:  0.326087, 0.070312 (1.441 sec)
13.359... logprob:  0.555198, 0.164062 (1.435 sec)
13.360... logprob:  0.444519, 0.117188 (1.430 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.09009552001953, 10.0]}, 128)
batch 872: ({'logprob': [66.113037109375, 19.0]}, 128)
batch 873: ({'logprob': [41.25927734375, 9.0]}, 128)
batch 874: ({'logprob': [45.58761215209961, 11.0]}, 128)
batch 875: ({'logprob': [50.973350524902344, 13.0]}, 128)
batch 876: ({'logprob': [63.69716262817383, 18.0]}, 128)
batch 877: ({'logprob': [46.121185302734375, 11.0]}, 128)
batch 878: ({'logprob': [61.77679443359375, 17.0]}, 128)
batch 879: ({'logprob': [73.0807876586914, 21.0]}, 128)
batch 880: ({'logprob': [50.987815856933594, 13.0]}, 128)
batch 881: ({'logprob': [29.92514991760254, 5.0]}, 128)
batch 882: ({'logprob': [55.002201080322266, 14.0]}, 128)
batch 883: ({'logprob': [61.76307678222656, 17.0]}, 128)
batch 884: ({'logprob': [51.49945068359375, 13.0]}, 128)
batch 885: ({'logprob': [52.558021545410156, 13.0]}, 128)
batch 886: ({'logprob': [62.298675537109375, 17.0]}, 128)

======================Test output======================
logprob:  0.417350, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.971212e-03 [2.830449e-09] 
Layer 'conv1' biases: 1.157976e-07 [4.454033e-11] 
Layer 'conv2' weights[0]: 7.958210e-03 [1.793025e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.448286e-10] 
Layer 'conv3' weights[0]: 7.956507e-03 [1.294118e-09] 
Layer 'conv3' biases: 1.023190e-06 [4.087184e-10] 
Layer 'conv4' weights[0]: 7.989066e-03 [1.246706e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.408609e-09] 
Layer 'conv5' weights[0]: 7.987962e-03 [9.447832e-09] 
Layer 'conv5' biases: 9.999989e-01 [1.008384e-08] 
Layer 'fc6' weights[0]: 7.584820e-03 [1.149231e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.208449e-10] 
Layer 'fc7' weights[0]: 7.437848e-03 [6.533710e-08] 
Layer 'fc7' biases: 9.998657e-01 [4.806125e-08] 
Layer 'fc8' weights[0]: 1.309725e-03 [1.607910e-06] 
Layer 'fc8' biases: 2.914917e-02 [8.749509e-06] 
Train error last 870 batches: 0.435278
-------------------------------------------------------
Not saving because 0.417350 > 0.415707 (12.630: -0.00%)
======================================================= (12.121 sec)
13.361... logprob:  0.410793, 0.101562 (1.442 sec)
13.362... logprob:  0.424167, 0.117188 (1.478 sec)
13.363... logprob:  0.486591, 0.132812 (1.444 sec)
13.364... logprob:  0.475537, 0.125000 (1.450 sec)
13.365... logprob:  0.425103, 0.109375 (1.469 sec)
13.366... logprob:  0.409720, 0.109375 (1.445 sec)
13.367... logprob:  0.325017, 0.078125 (1.444 sec)
13.368... logprob:  0.595730, 0.171875 (1.427 sec)
13.369... logprob:  0.381514, 0.093750 (1.429 sec)
13.370... logprob:  0.381142, 0.093750 (1.437 sec)
13.371... logprob:  0.400337, 0.101562 (1.461 sec)
13.372... logprob:  0.537661, 0.156250 (1.455 sec)
13.373... logprob:  0.463841, 0.125000 (1.447 sec)
13.374... logprob:  0.527131, 0.148438 (1.456 sec)
13.375... logprob:  0.393786, 0.101562 (1.461 sec)
13.376... logprob:  0.374325, 0.093750 (1.436 sec)
13.377... logprob:  0.295378, 0.062500 (1.424 sec)
13.378... logprob:  0.453785, 0.125000 (1.433 sec)
13.379... logprob:  0.420240, 0.109375 (1.441 sec)
13.380... logprob:  0.605766, 0.179688 (1.440 sec)
13.381... logprob:  0.463502, 0.125000 (1.473 sec)
13.382... logprob:  0.529489, 0.148438 (1.450 sec)
13.383... logprob:  0.358734, 0.085938 (1.441 sec)
13.384... logprob:  0.521012, 0.148438 (1.481 sec)
13.385... logprob:  0.523445, 0.148438 (1.438 sec)
13.386... logprob:  0.582292, 0.171875 (1.427 sec)
13.387... logprob:  0.428722, 0.117188 (1.435 sec)
13.388... logprob:  0.521298, 0.148438 (1.439 sec)
13.389... logprob:  0.425982, 0.109375 (1.439 sec)
13.390... logprob:  0.419985, 0.109375 (1.479 sec)
13.391... logprob:  0.318419, 0.070312 (1.439 sec)
13.392... logprob:  0.439417, 0.117188 (1.432 sec)
13.393... logprob:  0.368799, 0.093750 (1.485 sec)
13.394... logprob:  0.343419, 0.078125 (1.437 sec)
13.395... logprob:  0.331471, 0.078125 (1.461 sec)
13.396... logprob:  0.251657, 0.046875 (1.442 sec)
13.397... logprob:  0.484901, 0.132812 (1.431 sec)
13.398... logprob:  0.471642, 0.125000 (1.437 sec)
13.399... logprob:  0.433881, 0.117188 (1.484 sec)
13.400... logprob:  0.538877, 0.148438 (1.432 sec)
13.401... logprob:  0.466334, 0.125000 (1.440 sec)
13.402... logprob:  0.474388, 0.125000 (1.485 sec)
13.403... logprob:  0.462281, 0.125000 (1.429 sec)
13.404... logprob:  0.474827, 0.125000 (1.430 sec)
13.405... logprob:  0.543726, 0.156250 (1.440 sec)
13.406... logprob:  0.358013, 0.085938 (1.428 sec)
13.407... logprob:  0.492595, 0.140625 (1.436 sec)
13.408... logprob:  0.340005, 0.078125 (1.480 sec)
13.409... logprob:  0.401182, 0.101562 (1.442 sec)
13.410... logprob:  0.581590, 0.171875 (1.450 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.039058685302734, 10.0]}, 128)
batch 872: ({'logprob': [65.6744155883789, 19.0]}, 128)
batch 873: ({'logprob': [42.72053146362305, 9.0]}, 128)
batch 874: ({'logprob': [46.54376220703125, 11.0]}, 128)
batch 875: ({'logprob': [51.63431930541992, 13.0]}, 128)
batch 876: ({'logprob': [63.45779037475586, 18.0]}, 128)
batch 877: ({'logprob': [47.182762145996094, 11.0]}, 128)
batch 878: ({'logprob': [61.843448638916016, 17.0]}, 128)
batch 879: ({'logprob': [72.65735626220703, 21.0]}, 128)
batch 880: ({'logprob': [51.64788055419922, 13.0]}, 128)
batch 881: ({'logprob': [31.877260208129883, 5.0]}, 128)
batch 882: ({'logprob': [55.772789001464844, 14.0]}, 128)
batch 883: ({'logprob': [61.82988739013672, 17.0]}, 128)
batch 884: ({'logprob': [52.26226043701172, 13.0]}, 128)
batch 885: ({'logprob': [53.52837371826172, 13.0]}, 128)
batch 886: ({'logprob': [62.46808624267578, 17.0]}, 128)

======================Test output======================
logprob:  0.421943, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.971174e-03 [2.505661e-09] 
Layer 'conv1' biases: 1.165537e-07 [3.547971e-11] 
Layer 'conv2' weights[0]: 7.958158e-03 [1.614455e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.527106e-10] 
Layer 'conv3' weights[0]: 7.956473e-03 [1.299096e-09] 
Layer 'conv3' biases: 1.029284e-06 [5.134092e-10] 
Layer 'conv4' weights[0]: 7.989028e-03 [1.439445e-09] 
Layer 'conv4' biases: 9.999998e-01 [4.460219e-09] 
Layer 'conv5' weights[0]: 7.987921e-03 [3.048753e-08] 
Layer 'conv5' biases: 9.999990e-01 [3.298282e-08] 
Layer 'fc6' weights[0]: 7.584778e-03 [2.704129e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.620883e-09] 
Layer 'fc7' weights[0]: 7.435944e-03 [2.192114e-07] 
Layer 'fc7' biases: 9.998651e-01 [2.078886e-07] 
Layer 'fc8' weights[0]: 1.275956e-03 [8.192453e-06] 
Layer 'fc8' biases: 2.912652e-02 [4.390994e-05] 
Train error last 870 batches: 0.435277
-------------------------------------------------------
Not saving because 0.421943 > 0.415707 (12.630: -0.00%)
======================================================= (12.084 sec)
13.411... logprob:  0.398460, 0.101562 (1.494 sec)
13.412... logprob:  0.540179, 0.156250 (1.438 sec)
13.413... logprob:  0.544733, 0.156250 (1.436 sec)
13.414... logprob:  0.466699, 0.125000 (1.436 sec)
13.415... logprob:  0.401820, 0.101562 (1.423 sec)
13.416... logprob:  0.427578, 0.109375 (1.441 sec)
13.417... logprob:  0.405378, 0.093750 (1.464 sec)
13.418... logprob:  0.379955, 0.093750 (1.456 sec)
13.419... logprob:  0.417451, 0.101562 (1.453 sec)
13.420... logprob:  0.355693, 0.085938 (1.459 sec)
13.421... logprob:  0.376505, 0.101562 (1.454 sec)
13.422... logprob:  0.523461, 0.148438 (1.443 sec)
13.423... logprob:  0.421131, 0.109375 (1.426 sec)
13.424... logprob:  0.324517, 0.078125 (1.431 sec)
13.425... logprob:  0.306004, 0.070312 (1.443 sec)
13.426... logprob:  0.449570, 0.117188 (1.443 sec)
13.427... logprob:  0.555351, 0.156250 (1.468 sec)
13.428... logprob:  0.602565, 0.171875 (1.489 sec)
13.429... logprob:  0.426242, 0.109375 (1.443 sec)
13.430... logprob:  0.300052, 0.070312 (1.478 sec)
13.431... logprob:  0.598978, 0.171875 (1.435 sec)
13.432... logprob:  0.387652, 0.093750 (1.427 sec)
13.433... logprob:  0.330520, 0.078125 (1.439 sec)
13.434... logprob:  0.528904, 0.148438 (1.435 sec)
13.435... logprob:  0.531872, 0.156250 (1.430 sec)
13.436... logprob:  0.381851, 0.093750 (1.475 sec)
13.437... logprob:  0.500195, 0.140625 (1.458 sec)
13.438... logprob:  0.546702, 0.156250 (1.430 sec)
13.439... logprob:  0.379443, 0.093750 (1.485 sec)
13.440... logprob:  0.439966, 0.117188 (1.430 sec)
13.441... logprob:  0.468077, 0.125000 (1.429 sec)
13.442... logprob:  0.378895, 0.093750 (1.430 sec)
13.443... logprob:  0.496599, 0.140625 (1.431 sec)
13.444... logprob:  0.371946, 0.093750 (1.433 sec)
13.445... logprob:  0.361951, 0.085938 (1.487 sec)
13.446... logprob:  0.397974, 0.101562 (1.435 sec)
13.447... logprob:  0.570760, 0.164062 (1.446 sec)
13.448... logprob:  0.332282, 0.078125 (1.480 sec)
13.449... logprob:  0.400024, 0.101562 (1.438 sec)
13.450... logprob:  0.238450, 0.046875 (1.429 sec)
13.451... logprob:  0.453260, 0.125000 (1.445 sec)
13.452... logprob:  0.456543, 0.117188 (1.428 sec)
13.453... logprob:  0.455697, 0.125000 (1.435 sec)
13.454... logprob:  0.489397, 0.132812 (1.483 sec)
13.455... logprob:  0.506164, 0.140625 (1.438 sec)
13.456... logprob:  0.468777, 0.125000 (1.454 sec)
13.457... logprob:  0.375424, 0.093750 (1.473 sec)
13.458... logprob:  0.351340, 0.085938 (1.435 sec)
13.459... logprob:  0.513469, 0.140625 (1.439 sec)
13.460... logprob:  0.275015, 0.054688 (1.439 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.73863983154297, 10.0]}, 128)
batch 872: ({'logprob': [66.3702621459961, 19.0]}, 128)
batch 873: ({'logprob': [40.83875274658203, 9.0]}, 128)
batch 874: ({'logprob': [45.303287506103516, 11.0]}, 128)
batch 875: ({'logprob': [50.82387924194336, 13.0]}, 128)
batch 876: ({'logprob': [63.88682556152344, 18.0]}, 128)
batch 877: ({'logprob': [45.83588790893555, 11.0]}, 128)
batch 878: ({'logprob': [61.8979606628418, 17.0]}, 128)
batch 879: ({'logprob': [73.4719009399414, 21.0]}, 128)
batch 880: ({'logprob': [50.83846664428711, 13.0]}, 128)
batch 881: ({'logprob': [29.234331130981445, 5.0]}, 128)
batch 882: ({'logprob': [54.920005798339844, 14.0]}, 128)
batch 883: ({'logprob': [61.88417053222656, 17.0]}, 128)
batch 884: ({'logprob': [51.3504638671875, 13.0]}, 128)
batch 885: ({'logprob': [52.408424377441406, 13.0]}, 128)
batch 886: ({'logprob': [62.41986083984375, 17.0]}, 128)

======================Test output======================
logprob:  0.416613, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.971133e-03 [2.445761e-09] 
Layer 'conv1' biases: 1.172739e-07 [7.894349e-11] 
Layer 'conv2' weights[0]: 7.958119e-03 [2.582379e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.513594e-10] 
Layer 'conv3' weights[0]: 7.956435e-03 [2.552476e-09] 
Layer 'conv3' biases: 1.034861e-06 [1.400824e-09] 
Layer 'conv4' weights[0]: 7.988987e-03 [2.745247e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.307573e-08] 
Layer 'conv5' weights[0]: 7.987875e-03 [8.499425e-08] 
Layer 'conv5' biases: 9.999989e-01 [9.195198e-08] 
Layer 'fc6' weights[0]: 7.584743e-03 [7.328831e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.428503e-09] 
Layer 'fc7' weights[0]: 7.434020e-03 [9.704639e-08] 
Layer 'fc7' biases: 9.998661e-01 [8.291487e-08] 
Layer 'fc8' weights[0]: 1.314756e-03 [3.020152e-06] 
Layer 'fc8' biases: 2.975181e-02 [1.643455e-05] 
Train error last 870 batches: 0.435277
-------------------------------------------------------
Not saving because 0.416613 > 0.415707 (12.630: -0.00%)
======================================================= (12.087 sec)
13.461... logprob:  0.459922, 0.125000 (1.457 sec)
13.462... logprob:  0.471858, 0.125000 (1.439 sec)
13.463... logprob:  0.421020, 0.109375 (1.477 sec)
13.464... logprob:  0.482639, 0.132812 (1.448 sec)
13.465... logprob:  0.421269, 0.109375 (1.454 sec)
13.466... logprob:  0.318790, 0.070312 (1.461 sec)
13.467... logprob:  0.413886, 0.109375 (1.456 sec)
13.468... logprob:  0.394278, 0.101562 (1.434 sec)
13.469... logprob:  0.334575, 0.078125 (1.426 sec)
13.470... logprob:  0.400033, 0.101562 (1.426 sec)
13.471... logprob:  0.529833, 0.148438 (1.444 sec)
13.472... logprob:  0.410129, 0.109375 (1.452 sec)
13.473... logprob:  0.375284, 0.093750 (1.459 sec)
13.474... logprob:  0.465939, 0.125000 (1.456 sec)
13.475... logprob:  0.504648, 0.140625 (1.449 sec)
13.476... logprob:  0.510635, 0.140625 (1.472 sec)
13.477... logprob:  0.334450, 0.078125 (1.438 sec)
13.478... logprob:  0.464315, 0.125000 (1.430 sec)
13.479... logprob:  0.305819, 0.070312 (1.430 sec)
13.480... logprob:  0.443525, 0.117188 (1.437 sec)
13.481... logprob:  0.547697, 0.156250 (1.435 sec)
13.482... logprob:  0.443206, 0.117188 (1.477 sec)
13.483... logprob:  0.502514, 0.140625 (1.444 sec)
13.484... logprob:  0.485278, 0.132812 (1.440 sec)
13.485... logprob:  0.409167, 0.109375 (1.485 sec)
13.486... logprob:  0.361779, 0.085938 (1.433 sec)
13.487... logprob:  0.522583, 0.148438 (1.431 sec)
13.488... logprob:  0.424974, 0.109375 (1.439 sec)
13.489... logprob:  0.416008, 0.109375 (1.432 sec)
13.490... logprob:  0.440707, 0.117188 (1.436 sec)
13.491... logprob:  0.313740, 0.070312 (1.482 sec)
13.492... logprob:  0.459648, 0.125000 (1.442 sec)
13.493... logprob:  0.522048, 0.148438 (1.437 sec)
13.494... logprob:  0.450399, 0.125000 (1.485 sec)
13.495... logprob:  0.380489, 0.093750 (1.435 sec)
13.496... logprob:  0.550680, 0.156250 (1.434 sec)
13.497... logprob:  0.467114, 0.125000 (1.438 sec)
13.498... logprob:  0.476406, 0.132812 (1.432 sec)
13.499... logprob:  0.456309, 0.125000 (1.433 sec)
13.500... logprob:  0.355044, 0.085938 (1.490 sec)
13.501... logprob:  0.339106, 0.078125 (1.434 sec)
13.502... logprob:  0.459693, 0.125000 (1.471 sec)
13.503... logprob:  0.400706, 0.101562 (1.488 sec)
13.504... logprob:  0.487368, 0.132812 (1.437 sec)
13.505... logprob:  0.570817, 0.164062 (1.436 sec)
13.506... logprob:  0.479679, 0.132812 (1.438 sec)
13.507... logprob:  0.385195, 0.093750 (1.425 sec)
13.508... logprob:  0.374813, 0.093750 (1.438 sec)
13.509... logprob:  0.323326, 0.070312 (1.475 sec)
13.510... logprob:  0.390503, 0.101562 (1.440 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.81365203857422, 10.0]}, 128)
batch 872: ({'logprob': [66.58728790283203, 19.0]}, 128)
batch 873: ({'logprob': [40.56553268432617, 9.0]}, 128)
batch 874: ({'logprob': [45.2441291809082, 11.0]}, 128)
batch 875: ({'logprob': [50.78498458862305, 13.0]}, 128)
batch 876: ({'logprob': [64.04561614990234, 18.0]}, 128)
batch 877: ({'logprob': [45.680030822753906, 11.0]}, 128)
batch 878: ({'logprob': [61.90121078491211, 17.0]}, 128)
batch 879: ({'logprob': [73.42091369628906, 21.0]}, 128)
batch 880: ({'logprob': [50.80018615722656, 13.0]}, 128)
batch 881: ({'logprob': [29.015623092651367, 5.0]}, 128)
batch 882: ({'logprob': [54.65094757080078, 14.0]}, 128)
batch 883: ({'logprob': [61.887142181396484, 17.0]}, 128)
batch 884: ({'logprob': [51.2156867980957, 13.0]}, 128)
batch 885: ({'logprob': [52.080787658691406, 13.0]}, 128)
batch 886: ({'logprob': [62.32691192626953, 17.0]}, 128)

======================Test output======================
logprob:  0.416026, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.971091e-03 [3.508119e-09] 
Layer 'conv1' biases: 1.178766e-07 [1.174684e-10] 
Layer 'conv2' weights[0]: 7.958065e-03 [2.657983e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.202631e-10] 
Layer 'conv3' weights[0]: 7.956397e-03 [2.664026e-09] 
Layer 'conv3' biases: 1.040317e-06 [1.539186e-09] 
Layer 'conv4' weights[0]: 7.988951e-03 [2.969977e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.491047e-08] 
Layer 'conv5' weights[0]: 7.987847e-03 [1.011607e-07] 
Layer 'conv5' biases: 9.999985e-01 [1.096845e-07] 
Layer 'fc6' weights[0]: 7.584695e-03 [8.742670e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.814774e-09] 
Layer 'fc7' weights[0]: 7.432139e-03 [1.705116e-07] 
Layer 'fc7' biases: 9.998659e-01 [1.581826e-07] 
Layer 'fc8' weights[0]: 1.316372e-03 [6.411323e-06] 
Layer 'fc8' biases: 2.987975e-02 [4.191620e-05] 
Train error last 870 batches: 0.435276
-------------------------------------------------------
Not saving because 0.416026 > 0.415707 (12.630: -0.00%)
======================================================= (12.064 sec)
13.511... logprob:  0.410101, 0.109375 (1.466 sec)
13.512... logprob:  0.470763, 0.125000 (1.467 sec)
13.513... logprob:  0.324983, 0.078125 (1.443 sec)
13.514... logprob:  0.406281, 0.101562 (1.437 sec)
13.515... logprob:  0.455661, 0.125000 (1.433 sec)
13.516... logprob:  0.400487, 0.109375 (1.426 sec)
13.517... logprob:  0.628198, 0.179688 (1.438 sec)
13.518... logprob:  0.437754, 0.117188 (1.465 sec)
13.519... logprob:  0.516173, 0.140625 (1.455 sec)
13.520... logprob:  0.409663, 0.109375 (1.455 sec)
13.521... logprob:  0.427562, 0.109375 (1.453 sec)
13.522... logprob:  0.533039, 0.156250 (1.467 sec)
13.523... logprob:  0.331896, 0.078125 (1.435 sec)
13.524... logprob:  0.437280, 0.117188 (1.430 sec)
13.525... logprob:  0.426174, 0.109375 (1.430 sec)
13.526... logprob:  0.352089, 0.078125 (1.439 sec)
13.527... logprob:  0.504526, 0.140625 (1.442 sec)
13.528... logprob:  0.440544, 0.117188 (1.472 sec)
13.529... logprob:  0.353025, 0.085938 (1.449 sec)
13.530... logprob:  0.440248, 0.117188 (1.438 sec)
13.531... logprob:  0.440042, 0.117188 (1.478 sec)
13.532... logprob:  0.467443, 0.125000 (1.436 sec)
13.533... logprob:  0.560875, 0.164062 (1.430 sec)
13.534... logprob:  0.325724, 0.078125 (1.435 sec)
13.535... logprob:  0.551803, 0.156250 (1.471 sec)
13.536... logprob:  0.507469, 0.140625 (1.433 sec)
13.537... logprob:  0.510120, 0.140625 (1.483 sec)
13.538... logprob:  0.486129, 0.132812 (1.442 sec)
13.539... logprob:  0.296205, 0.062500 (1.436 sec)
13.540... logprob:  0.447185, 0.117188 (1.490 sec)
13.541... logprob:  0.388940, 0.101562 (1.433 sec)
13.542... logprob:  0.411354, 0.109375 (1.433 sec)
13.543... logprob:  0.233492, 0.039062 (1.442 sec)
13.544... logprob:  0.317964, 0.070312 (1.428 sec)
13.545... logprob:  0.348819, 0.085938 (1.436 sec)
13.546... logprob:  0.368297, 0.093750 (1.484 sec)
13.547... logprob:  0.440205, 0.117188 (1.439 sec)
13.548... logprob:  0.453332, 0.125000 (1.441 sec)
13.549... logprob:  0.490858, 0.132812 (1.476 sec)
13.550... logprob:  0.367734, 0.093750 (1.433 sec)
13.551... logprob:  0.441879, 0.117188 (1.439 sec)
13.552... logprob:  0.471381, 0.125000 (1.436 sec)
13.553... logprob:  0.349429, 0.085938 (1.431 sec)
13.554... logprob:  0.506788, 0.140625 (1.429 sec)
13.555... logprob:  0.421417, 0.109375 (1.477 sec)
13.556... logprob:  0.355998, 0.085938 (1.441 sec)
13.557... logprob:  0.396545, 0.101562 (1.449 sec)
13.558... logprob:  0.383103, 0.101562 (1.478 sec)
13.559... logprob:  0.441390, 0.125000 (1.437 sec)
13.560... logprob:  0.335477, 0.078125 (1.441 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.6782112121582, 10.0]}, 128)
batch 872: ({'logprob': [66.19080352783203, 19.0]}, 128)
batch 873: ({'logprob': [41.162933349609375, 9.0]}, 128)
batch 874: ({'logprob': [45.397377014160156, 11.0]}, 128)
batch 875: ({'logprob': [50.903865814208984, 13.0]}, 128)
batch 876: ({'logprob': [63.76837158203125, 18.0]}, 128)
batch 877: ({'logprob': [46.03794479370117, 11.0]}, 128)
batch 878: ({'logprob': [61.948917388916016, 17.0]}, 128)
batch 879: ({'logprob': [73.60124969482422, 21.0]}, 128)
batch 880: ({'logprob': [50.91818618774414, 13.0]}, 128)
batch 881: ({'logprob': [29.48002052307129, 5.0]}, 128)
batch 882: ({'logprob': [55.261932373046875, 14.0]}, 128)
batch 883: ({'logprob': [61.93501663208008, 17.0]}, 128)
batch 884: ({'logprob': [51.53794860839844, 13.0]}, 128)
batch 885: ({'logprob': [52.81159973144531, 13.0]}, 128)
batch 886: ({'logprob': [62.57854461669922, 17.0]}, 128)

======================Test output======================
logprob:  0.417584, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.971038e-03 [3.136458e-09] 
Layer 'conv1' biases: 1.187439e-07 [9.820116e-11] 
Layer 'conv2' weights[0]: 7.958024e-03 [2.266692e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.395203e-10] 
Layer 'conv3' weights[0]: 7.956361e-03 [2.432990e-09] 
Layer 'conv3' biases: 1.048013e-06 [1.312584e-09] 
Layer 'conv4' weights[0]: 7.988914e-03 [2.686587e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.277476e-08] 
Layer 'conv5' weights[0]: 7.987803e-03 [8.707309e-08] 
Layer 'conv5' biases: 9.999985e-01 [9.448286e-08] 
Layer 'fc6' weights[0]: 7.584659e-03 [7.509339e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.593146e-09] 
Layer 'fc7' weights[0]: 7.430223e-03 [4.746341e-08] 
Layer 'fc7' biases: 9.998659e-01 [2.379754e-08] 
Layer 'fc8' weights[0]: 1.308060e-03 [5.456165e-06] 
Layer 'fc8' biases: 2.995375e-02 [3.172715e-05] 
Train error last 870 batches: 0.435276
-------------------------------------------------------
Not saving because 0.417584 > 0.415707 (12.630: -0.00%)
======================================================= (12.117 sec)
13.561... logprob:  0.411875, 0.109375 (1.433 sec)
13.562... logprob:  0.503104, 0.140625 (1.427 sec)
13.563... logprob:  0.373908, 0.093750 (1.436 sec)
13.564... logprob:  0.468406, 0.132812 (1.469 sec)
13.565... logprob:  0.611003, 0.187500 (1.450 sec)
13.566... logprob:  0.374938, 0.093750 (1.457 sec)
13.567... logprob:  0.423502, 0.109375 (1.455 sec)
13.568... logprob:  0.496406, 0.140625 (1.483 sec)
13.569... logprob:  0.507926, 0.140625 (1.441 sec)
13.570... logprob:  0.543710, 0.164062 (1.426 sec)
13.571... logprob:  0.454873, 0.125000 (1.426 sec)
13.572... logprob:  0.501533, 0.140625 (1.437 sec)
13.573... logprob:  0.512651, 0.148438 (1.451 sec)
13.574... logprob:  0.428201, 0.109375 (1.464 sec)
13.575... logprob:  0.343383, 0.078125 (1.456 sec)
13.576... logprob:  0.427435, 0.109375 (1.443 sec)
13.577... logprob:  0.460873, 0.125000 (1.477 sec)
13.578... logprob:  0.336512, 0.078125 (1.434 sec)
13.579... logprob:  0.442095, 0.117188 (1.427 sec)
13.580... logprob:  0.547082, 0.156250 (1.439 sec)
13.581... logprob:  0.531170, 0.156250 (1.437 sec)
13.582... logprob:  0.437946, 0.125000 (1.437 sec)
13.583... logprob:  0.593047, 0.171875 (1.473 sec)
13.584... logprob:  0.468154, 0.132812 (1.444 sec)
13.585... logprob:  0.349772, 0.085938 (1.434 sec)
13.586... logprob:  0.313199, 0.070312 (1.486 sec)
13.587... logprob:  0.404326, 0.101562 (1.437 sec)
13.588... logprob:  0.418682, 0.117188 (1.431 sec)
13.589... logprob:  0.361366, 0.093750 (1.436 sec)
13.590... logprob:  0.524672, 0.148438 (1.427 sec)
13.591... logprob:  0.397543, 0.101562 (1.437 sec)
13.592... logprob:  0.455636, 0.125000 (1.485 sec)
13.593... logprob:  0.467452, 0.125000 (1.438 sec)
13.594... logprob:  0.352894, 0.085938 (1.442 sec)
13.595... logprob:  0.428678, 0.109375 (1.482 sec)
13.596... logprob:  0.461572, 0.125000 (1.437 sec)
13.597... logprob:  0.397411, 0.101562 (1.433 sec)
13.598... logprob:  0.397237, 0.101562 (1.438 sec)
13.599... logprob:  0.313480, 0.070312 (1.428 sec)
13.600... logprob:  0.340902, 0.085938 (1.430 sec)
13.601... logprob:  0.402114, 0.101562 (1.486 sec)
13.602... logprob:  0.289611, 0.062500 (1.435 sec)
13.603... logprob:  0.266844, 0.054688 (1.450 sec)
13.604... logprob:  0.407513, 0.101562 (1.475 sec)
13.605... logprob:  0.563718, 0.148438 (1.438 sec)
13.606... logprob:  0.295951, 0.070312 (1.443 sec)
13.607... logprob:  0.505018, 0.132812 (1.428 sec)
13.608... logprob:  0.361626, 0.085938 (1.428 sec)
13.609... logprob:  0.356889, 0.085938 (1.460 sec)
13.610... logprob:  0.493481, 0.132812 (1.471 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.128482818603516, 10.0]}, 128)
batch 872: ({'logprob': [68.16630554199219, 19.0]}, 128)
batch 873: ({'logprob': [39.52167510986328, 9.0]}, 128)
batch 874: ({'logprob': [44.762569427490234, 11.0]}, 128)
batch 875: ({'logprob': [50.80133819580078, 13.0]}, 128)
batch 876: ({'logprob': [65.3607406616211, 18.0]}, 128)
batch 877: ({'logprob': [45.165489196777344, 11.0]}, 128)
batch 878: ({'logprob': [62.91789245605469, 17.0]}, 128)
batch 879: ({'logprob': [75.40557861328125, 21.0]}, 128)
batch 880: ({'logprob': [50.81737518310547, 13.0]}, 128)
batch 881: ({'logprob': [27.002092361450195, 5.0]}, 128)
batch 882: ({'logprob': [54.84169006347656, 14.0]}, 128)
batch 883: ({'logprob': [62.903404235839844, 17.0]}, 128)
batch 884: ({'logprob': [51.203712463378906, 13.0]}, 128)
batch 885: ({'logprob': [52.00704574584961, 13.0]}, 128)
batch 886: ({'logprob': [63.31388473510742, 17.0]}, 128)

======================Test output======================
logprob:  0.417636, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.970994e-03 [3.175258e-09] 
Layer 'conv1' biases: 1.195405e-07 [1.201806e-10] 
Layer 'conv2' weights[0]: 7.957983e-03 [3.133099e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.191448e-10] 
Layer 'conv3' weights[0]: 7.956325e-03 [3.050208e-09] 
Layer 'conv3' biases: 1.054065e-06 [1.923950e-09] 
Layer 'conv4' weights[0]: 7.988876e-03 [3.458407e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.876658e-08] 
Layer 'conv5' weights[0]: 7.987756e-03 [1.274839e-07] 
Layer 'conv5' biases: 9.999985e-01 [1.382953e-07] 
Layer 'fc6' weights[0]: 7.584619e-03 [1.096950e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.122037e-08] 
Layer 'fc7' weights[0]: 7.428302e-03 [2.534210e-07] 
Layer 'fc7' biases: 9.998668e-01 [2.426569e-07] 
Layer 'fc8' weights[0]: 1.365099e-03 [1.436744e-05] 
Layer 'fc8' biases: 3.044610e-02 [8.498147e-05] 
Train error last 870 batches: 0.435276
-------------------------------------------------------
Not saving because 0.417636 > 0.415707 (12.630: -0.00%)
======================================================= (12.026 sec)
13.611... logprob:  0.510465, 0.140625 (1.446 sec)
13.612... logprob:  0.448348, 0.117188 (1.457 sec)
13.613... logprob:  0.279954, 0.062500 (1.456 sec)
13.614... logprob:  0.503493, 0.140625 (1.448 sec)
13.615... logprob:  0.351296, 0.085938 (1.439 sec)
13.616... logprob:  0.415448, 0.109375 (1.429 sec)
13.617... logprob:  0.418024, 0.109375 (1.430 sec)
13.618... logprob:  0.546585, 0.156250 (1.437 sec)
13.619... logprob:  0.505894, 0.140625 (1.457 sec)
13.620... logprob:  0.539594, 0.156250 (1.459 sec)
13.621... logprob:  0.364045, 0.085938 (1.454 sec)
13.622... logprob:  0.365039, 0.085938 (1.449 sec)
13.623... logprob:  0.423250, 0.109375 (1.473 sec)
13.624... logprob:  0.382565, 0.093750 (1.438 sec)
13.625... logprob:  0.441014, 0.117188 (1.425 sec)
13.626... logprob:  0.438411, 0.117188 (1.434 sec)
13.627... logprob:  0.435876, 0.117188 (1.437 sec)
13.628... logprob:  0.465130, 0.125000 (1.435 sec)
13.629... logprob:  0.371937, 0.093750 (1.473 sec)
13.630... logprob:  0.422374, 0.109375 (1.450 sec)
13.631... logprob:  0.639689, 0.187500 (1.439 sec)
13.632... logprob:  0.399096, 0.101562 (1.480 sec)
13.633... logprob:  0.375994, 0.093750 (1.433 sec)
13.634... logprob:  0.660599, 0.195312 (1.428 sec)
13.635... logprob:  0.374131, 0.093750 (1.437 sec)
13.636... logprob:  0.480219, 0.132812 (1.433 sec)
13.637... logprob:  0.331039, 0.078125 (1.438 sec)
13.638... logprob:  0.515649, 0.140625 (1.478 sec)
13.639... logprob:  0.418211, 0.109375 (1.446 sec)
13.640... logprob:  0.528746, 0.148438 (1.434 sec)
13.641... logprob:  0.410524, 0.109375 (1.489 sec)
13.642... logprob:  0.500787, 0.140625 (1.467 sec)
13.643... logprob:  0.622688, 0.187500 (1.431 sec)
13.644... logprob:  0.321588, 0.070312 (1.443 sec)
13.645... logprob:  0.414529, 0.109375 (1.428 sec)
13.646... logprob:  0.385816, 0.093750 (1.433 sec)
13.647... logprob:  0.456736, 0.125000 (1.491 sec)
13.648... logprob:  0.491224, 0.140625 (1.430 sec)
13.649... logprob:  0.370036, 0.093750 (1.441 sec)
13.650... logprob:  0.413903, 0.109375 (1.482 sec)
13.651... logprob:  0.397267, 0.101562 (1.432 sec)
13.652... logprob:  0.507519, 0.140625 (1.438 sec)
13.653... logprob:  0.548301, 0.156250 (1.439 sec)
13.654... logprob:  0.496210, 0.140625 (1.426 sec)
13.655... logprob:  0.436226, 0.117188 (1.436 sec)
13.656... logprob:  0.416663, 0.109375 (1.478 sec)
13.657... logprob:  0.449351, 0.117188 (1.440 sec)
13.658... logprob:  0.345733, 0.085938 (1.448 sec)
13.659... logprob:  0.464376, 0.125000 (1.476 sec)
13.660... logprob:  0.445868, 0.125000 (1.447 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.72934341430664, 10.0]}, 128)
batch 872: ({'logprob': [66.20170593261719, 19.0]}, 128)
batch 873: ({'logprob': [41.12118148803711, 9.0]}, 128)
batch 874: ({'logprob': [45.39997863769531, 11.0]}, 128)
batch 875: ({'logprob': [50.89430618286133, 13.0]}, 128)
batch 876: ({'logprob': [63.771366119384766, 18.0]}, 128)
batch 877: ({'logprob': [46.012393951416016, 11.0]}, 128)
batch 878: ({'logprob': [61.915340423583984, 17.0]}, 128)
batch 879: ({'logprob': [73.51524353027344, 21.0]}, 128)
batch 880: ({'logprob': [50.908756256103516, 13.0]}, 128)
batch 881: ({'logprob': [29.490549087524414, 5.0]}, 128)
batch 882: ({'logprob': [55.17573547363281, 14.0]}, 128)
batch 883: ({'logprob': [61.90129089355469, 17.0]}, 128)
batch 884: ({'logprob': [51.50012969970703, 13.0]}, 128)
batch 885: ({'logprob': [52.71708679199219, 13.0]}, 128)
batch 886: ({'logprob': [62.51658248901367, 17.0]}, 128)

======================Test output======================
logprob:  0.417369, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.970957e-03 [1.918021e-09] 
Layer 'conv1' biases: 1.202779e-07 [2.696036e-11] 
Layer 'conv2' weights[0]: 7.957946e-03 [1.321781e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.251900e-10] 
Layer 'conv3' weights[0]: 7.956274e-03 [1.041060e-09] 
Layer 'conv3' biases: 1.060660e-06 [3.419816e-10] 
Layer 'conv4' weights[0]: 7.988834e-03 [1.030830e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.837205e-09] 
Layer 'conv5' weights[0]: 7.987721e-03 [8.042473e-09] 
Layer 'conv5' biases: 9.999984e-01 [8.123664e-09] 
Layer 'fc6' weights[0]: 7.584581e-03 [9.776468e-10] 
Layer 'fc6' biases: 1.000000e+00 [5.858538e-10] 
Layer 'fc7' weights[0]: 7.426430e-03 [4.292016e-08] 
Layer 'fc7' biases: 9.998657e-01 [1.715390e-08] 
Layer 'fc8' weights[0]: 1.312701e-03 [4.780586e-06] 
Layer 'fc8' biases: 3.022839e-02 [3.005682e-05] 
Train error last 870 batches: 0.435275
-------------------------------------------------------
Not saving because 0.417369 > 0.415707 (12.630: -0.00%)
======================================================= (12.174 sec)
13.661... logprob:  0.378598, 0.093750 (1.443 sec)
13.662... logprob:  0.469301, 0.132812 (1.440 sec)
13.663... logprob:  0.311124, 0.070312 (1.421 sec)
13.664... logprob:  0.285572, 0.062500 (1.433 sec)
13.665... logprob:  0.401907, 0.101562 (1.460 sec)
13.666... logprob:  0.442081, 0.117188 (1.451 sec)
13.667... logprob:  0.564356, 0.164062 (1.451 sec)
13.668... logprob:  0.497951, 0.140625 (1.459 sec)
13.669... logprob:  0.433152, 0.109375 (1.462 sec)
13.670... logprob:  0.362528, 0.085938 (1.446 sec)
13.671... logprob:  0.360853, 0.093750 (1.428 sec)
13.672... logprob:  0.441806, 0.117188 (1.430 sec)
13.673... logprob:  0.436254, 0.117188 (1.439 sec)
13.674... logprob:  0.446679, 0.117188 (1.438 sec)
13.675... logprob:  0.356664, 0.093750 (1.500 sec)
13.676... logprob:  0.450140, 0.125000 (1.454 sec)
13.677... logprob:  0.471072, 0.125000 (1.444 sec)
13.678... logprob:  0.465636, 0.125000 (1.478 sec)
13.679... logprob:  0.454880, 0.125000 (1.439 sec)
13.680... logprob:  0.351761, 0.078125 (1.426 sec)
13.681... logprob:  0.373975, 0.093750 (1.439 sec)
13.682... logprob:  0.340520, 0.078125 (1.435 sec)
13.683... logprob:  0.411655, 0.109375 (1.437 sec)
13.684... logprob:  0.357566, 0.085938 (1.477 sec)
13.685... logprob:  0.285746, 0.054688 (1.447 sec)
13.686... logprob:  0.318423, 0.070312 (1.434 sec)
13.687... logprob:  0.281422, 0.062500 (1.491 sec)
13.688... logprob:  0.323060, 0.078125 (1.432 sec)
13.689... logprob:  0.471749, 0.125000 (1.434 sec)
13.690... logprob:  0.528370, 0.140625 (1.436 sec)
13.691... logprob:  0.517387, 0.140625 (1.435 sec)
13.692... logprob:  0.385511, 0.101562 (1.434 sec)
13.693... logprob:  0.456215, 0.125000 (1.489 sec)
13.694... logprob:  0.330873, 0.078125 (1.433 sec)
13.695... logprob:  0.356875, 0.085938 (1.446 sec)
13.696... logprob:  0.538610, 0.148438 (1.479 sec)
13.697... logprob:  0.465515, 0.125000 (1.437 sec)
13.698... logprob:  0.548334, 0.156250 (1.432 sec)
13.699... logprob:  0.459569, 0.125000 (1.432 sec)
13.700... logprob:  0.434127, 0.117188 (1.427 sec)
13.701... logprob:  0.423515, 0.109375 (1.430 sec)
13.702... logprob:  0.521410, 0.148438 (1.486 sec)
13.703... logprob:  0.405744, 0.101562 (1.436 sec)
13.704... logprob:  0.406485, 0.101562 (1.450 sec)
13.705... logprob:  0.420379, 0.109375 (1.478 sec)
13.706... logprob:  0.468087, 0.125000 (1.432 sec)
13.707... logprob:  0.485300, 0.132812 (1.437 sec)
13.708... logprob:  0.416973, 0.109375 (1.432 sec)
13.709... logprob:  0.422350, 0.109375 (1.426 sec)
13.710... logprob:  0.603077, 0.179688 (1.438 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.33049774169922, 10.0]}, 128)
batch 872: ({'logprob': [66.19855499267578, 19.0]}, 128)
batch 873: ({'logprob': [41.18264389038086, 9.0]}, 128)
batch 874: ({'logprob': [45.65998458862305, 11.0]}, 128)
batch 875: ({'logprob': [51.000205993652344, 13.0]}, 128)
batch 876: ({'logprob': [63.75727844238281, 18.0]}, 128)
batch 877: ({'logprob': [46.09663391113281, 11.0]}, 128)
batch 878: ({'logprob': [61.71376037597656, 17.0]}, 128)
batch 879: ({'logprob': [72.83080291748047, 21.0]}, 128)
batch 880: ({'logprob': [51.0151252746582, 13.0]}, 128)
batch 881: ({'logprob': [30.03567886352539, 5.0]}, 128)
batch 882: ({'logprob': [54.76434326171875, 14.0]}, 128)
batch 883: ({'logprob': [61.69961929321289, 17.0]}, 128)
batch 884: ({'logprob': [51.42962646484375, 13.0]}, 128)
batch 885: ({'logprob': [52.29409408569336, 13.0]}, 128)
batch 886: ({'logprob': [62.138572692871094, 17.0]}, 128)

======================Test output======================
logprob:  0.417064, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.970917e-03 [3.163544e-09] 
Layer 'conv1' biases: 1.208442e-07 [4.885159e-11] 
Layer 'conv2' weights[0]: 7.957908e-03 [2.255861e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.219415e-10] 
Layer 'conv3' weights[0]: 7.956236e-03 [1.928656e-09] 
Layer 'conv3' biases: 1.065383e-06 [1.122524e-09] 
Layer 'conv4' weights[0]: 7.988795e-03 [2.082226e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.000445e-08] 
Layer 'conv5' weights[0]: 7.987677e-03 [6.761427e-08] 
Layer 'conv5' biases: 9.999983e-01 [7.312972e-08] 
Layer 'fc6' weights[0]: 7.584541e-03 [5.790504e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.884899e-09] 
Layer 'fc7' weights[0]: 7.424575e-03 [1.174055e-07] 
Layer 'fc7' biases: 9.998653e-01 [1.024399e-07] 
Layer 'fc8' weights[0]: 1.302702e-03 [3.763579e-06] 
Layer 'fc8' biases: 3.036646e-02 [3.075599e-05] 
Train error last 870 batches: 0.435275
-------------------------------------------------------
Not saving because 0.417064 > 0.415707 (12.630: -0.00%)
======================================================= (12.043 sec)
13.711... logprob:  0.469562, 0.125000 (1.471 sec)
13.712... logprob:  0.340108, 0.078125 (1.456 sec)
13.713... logprob:  0.587698, 0.179688 (1.455 sec)
13.714... logprob:  0.466377, 0.125000 (1.462 sec)
13.715... logprob:  0.417118, 0.109375 (1.453 sec)
13.716... logprob:  0.335163, 0.078125 (1.443 sec)
13.717... logprob:  0.429861, 0.117188 (1.428 sec)
13.718... logprob:  0.490409, 0.132812 (1.428 sec)
13.719... logprob:  0.406209, 0.109375 (1.442 sec)
13.720... logprob:  0.433244, 0.117188 (1.447 sec)
13.721... logprob:  0.451597, 0.117188 (1.462 sec)
13.722... logprob:  0.536764, 0.156250 (1.459 sec)
13.723... logprob:  0.416630, 0.109375 (1.453 sec)
13.724... logprob:  0.412792, 0.109375 (1.479 sec)
13.725... logprob:  0.494584, 0.140625 (1.431 sec)
13.726... logprob:  0.338791, 0.085938 (1.420 sec)
13.727... logprob:  0.393452, 0.101562 (1.438 sec)
13.728... logprob:  0.421429, 0.109375 (1.439 sec)
13.729... logprob:  0.387883, 0.093750 (1.435 sec)
13.730... logprob:  0.565805, 0.164062 (1.479 sec)
13.731... logprob:  0.450300, 0.125000 (1.445 sec)
13.732... logprob:  0.311508, 0.070312 (1.437 sec)
13.733... logprob:  0.556783, 0.156250 (1.482 sec)
13.734... logprob:  0.340205, 0.078125 (1.433 sec)
13.735... logprob:  0.527707, 0.148438 (1.430 sec)
13.736... logprob:  0.643226, 0.187500 (1.435 sec)
13.737... logprob:  0.516253, 0.148438 (1.434 sec)
13.738... logprob:  0.459452, 0.125000 (1.431 sec)
13.739... logprob:  0.477827, 0.132812 (1.480 sec)
13.740... logprob:  0.339673, 0.078125 (1.435 sec)
13.741... logprob:  0.393449, 0.101562 (1.437 sec)
13.742... logprob:  0.419766, 0.109375 (1.486 sec)
13.743... logprob:  0.364875, 0.085938 (1.434 sec)
13.744... logprob:  0.519292, 0.148438 (1.435 sec)
13.745... logprob:  0.478197, 0.132812 (1.436 sec)
13.746... logprob:  0.440568, 0.117188 (1.434 sec)
13.747... logprob:  0.425643, 0.109375 (1.431 sec)
13.748... logprob:  0.378027, 0.093750 (1.490 sec)
13.749... logprob:  0.420862, 0.109375 (1.458 sec)
13.750... logprob:  0.512972, 0.140625 (1.451 sec)
13.751... logprob:  0.263479, 0.054688 (1.476 sec)
13.752... logprob:  0.522523, 0.140625 (1.436 sec)
13.753... logprob:  0.441290, 0.117188 (1.440 sec)
13.754... logprob:  0.468659, 0.132812 (1.428 sec)
13.755... logprob:  0.507143, 0.140625 (1.426 sec)
13.756... logprob:  0.440823, 0.117188 (1.432 sec)
13.757... logprob:  0.552235, 0.156250 (1.470 sec)
13.758... logprob:  0.393761, 0.101562 (1.449 sec)
13.759... logprob:  0.459691, 0.125000 (1.453 sec)
13.760... logprob:  0.485369, 0.132812 (1.466 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.653038024902344, 10.0]}, 128)
batch 872: ({'logprob': [66.09966278076172, 19.0]}, 128)
batch 873: ({'logprob': [41.47905349731445, 9.0]}, 128)
batch 874: ({'logprob': [45.90269470214844, 11.0]}, 128)
batch 875: ({'logprob': [51.147132873535156, 13.0]}, 128)
batch 876: ({'logprob': [63.695777893066406, 18.0]}, 128)
batch 877: ({'logprob': [46.31862258911133, 11.0]}, 128)
batch 878: ({'logprob': [61.66872024536133, 17.0]}, 128)
batch 879: ({'logprob': [72.5726547241211, 21.0]}, 128)
batch 880: ({'logprob': [51.162071228027344, 13.0]}, 128)
batch 881: ({'logprob': [30.545440673828125, 5.0]}, 128)
batch 882: ({'logprob': [54.81005096435547, 14.0]}, 128)
batch 883: ({'logprob': [61.65446853637695, 17.0]}, 128)
batch 884: ({'logprob': [51.55491256713867, 13.0]}, 128)
batch 885: ({'logprob': [52.376853942871094, 13.0]}, 128)
batch 886: ({'logprob': [62.07202911376953, 17.0]}, 128)

======================Test output======================
logprob:  0.417829, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.970878e-03 [2.276196e-09] 
Layer 'conv1' biases: 1.216539e-07 [3.831243e-11] 
Layer 'conv2' weights[0]: 7.957873e-03 [1.690063e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.964818e-10] 
Layer 'conv3' weights[0]: 7.956198e-03 [1.445016e-09] 
Layer 'conv3' biases: 1.073882e-06 [6.531060e-10] 
Layer 'conv4' weights[0]: 7.988755e-03 [1.509944e-09] 
Layer 'conv4' biases: 9.999998e-01 [5.706547e-09] 
Layer 'conv5' weights[0]: 7.987639e-03 [3.890136e-08] 
Layer 'conv5' biases: 9.999989e-01 [4.218644e-08] 
Layer 'fc6' weights[0]: 7.584506e-03 [3.404870e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.372041e-09] 
Layer 'fc7' weights[0]: 7.422681e-03 [2.320312e-07] 
Layer 'fc7' biases: 9.998651e-01 [2.206356e-07] 
Layer 'fc8' weights[0]: 1.295165e-03 [8.090742e-06] 
Layer 'fc8' biases: 3.043728e-02 [4.967660e-05] 
Train error last 870 batches: 0.435274
-------------------------------------------------------
Not saving because 0.417829 > 0.415707 (12.630: -0.00%)
======================================================= (12.068 sec)
13.761... logprob:  0.418476, 0.109375 (1.456 sec)
13.762... logprob:  0.515956, 0.148438 (1.439 sec)
13.763... logprob:  0.558719, 0.164062 (1.428 sec)
13.764... logprob:  0.503300, 0.140625 (1.429 sec)
13.765... logprob:  0.312448, 0.062500 (1.436 sec)
13.766... logprob:  0.482326, 0.132812 (1.459 sec)
13.767... logprob:  0.371199, 0.085938 (1.460 sec)
13.768... logprob:  0.432725, 0.117188 (1.463 sec)
13.769... logprob:  0.490938, 0.140625 (1.466 sec)
13.770... logprob:  0.402768, 0.101562 (1.479 sec)
13.771... logprob:  0.549788, 0.156250 (1.456 sec)
13.772... logprob:  0.414014, 0.109375 (1.441 sec)
13.773... logprob:  0.558339, 0.164062 (1.447 sec)
13.774... logprob:  0.361440, 0.085938 (1.460 sec)
13.775... logprob:  0.407302, 0.101562 (1.466 sec)
13.776... logprob:  0.433279, 0.117188 (1.481 sec)
13.777... logprob:  0.379905, 0.093750 (1.473 sec)
13.778... logprob:  0.433651, 0.117188 (1.462 sec)
13.779... logprob:  0.505527, 0.140625 (1.485 sec)
13.780... logprob:  0.385756, 0.101562 (1.460 sec)
13.781... logprob:  0.369768, 0.085938 (1.446 sec)
13.782... logprob:  0.351550, 0.085938 (1.461 sec)
13.783... logprob:  0.555437, 0.156250 (1.460 sec)
13.784... logprob:  0.440958, 0.117188 (1.456 sec)
13.785... logprob:  0.543449, 0.156250 (1.482 sec)
13.786... logprob:  0.477339, 0.132812 (1.469 sec)
13.787... logprob:  0.546066, 0.156250 (1.456 sec)
13.788... logprob:  0.562752, 0.164062 (1.504 sec)
13.789... logprob:  0.281743, 0.054688 (1.458 sec)
13.790... logprob:  0.408469, 0.101562 (1.447 sec)
13.791... logprob:  0.398268, 0.101562 (1.447 sec)
13.792... logprob:  0.361378, 0.085938 (1.457 sec)
13.793... logprob:  0.370358, 0.085938 (1.452 sec)
13.794... logprob:  0.387121, 0.093750 (1.483 sec)
13.795... logprob:  0.469868, 0.125000 (1.468 sec)
13.796... logprob:  0.423499, 0.109375 (1.458 sec)
13.797... logprob:  0.358637, 0.085938 (1.503 sec)
13.798... logprob:  0.393258, 0.101562 (1.453 sec)
13.799... logprob:  0.332065, 0.078125 (1.447 sec)
13.800... logprob:  0.371824, 0.093750 (1.444 sec)
13.801... logprob:  0.450488, 0.117188 (1.461 sec)
13.802... logprob:  0.423260, 0.109375 (1.453 sec)
13.803... logprob:  0.492215, 0.132812 (1.496 sec)
13.804... logprob:  0.350000, 0.085938 (1.462 sec)
13.805... logprob:  0.452303, 0.117188 (1.450 sec)
13.806... logprob:  0.424189, 0.109375 (1.501 sec)
13.807... logprob:  0.443436, 0.117188 (1.457 sec)
13.808... logprob:  0.462320, 0.125000 (1.452 sec)
13.809... logprob:  0.589308, 0.171875 (1.450 sec)
13.810... logprob:  0.442429, 0.117188 (1.458 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.59428024291992, 10.0]}, 128)
batch 872: ({'logprob': [66.61338806152344, 19.0]}, 128)
batch 873: ({'logprob': [40.80772399902344, 9.0]}, 128)
batch 874: ({'logprob': [45.65988540649414, 11.0]}, 128)
batch 875: ({'logprob': [51.01274108886719, 13.0]}, 128)
batch 876: ({'logprob': [64.07587432861328, 18.0]}, 128)
batch 877: ({'logprob': [45.915802001953125, 11.0]}, 128)
batch 878: ({'logprob': [61.7540283203125, 17.0]}, 128)
batch 879: ({'logprob': [72.71842956542969, 21.0]}, 128)
batch 880: ({'logprob': [51.028560638427734, 13.0]}, 128)
batch 881: ({'logprob': [29.813621520996094, 5.0]}, 128)
batch 882: ({'logprob': [54.33328628540039, 14.0]}, 128)
batch 883: ({'logprob': [61.73955535888672, 17.0]}, 128)
batch 884: ({'logprob': [51.26247787475586, 13.0]}, 128)
batch 885: ({'logprob': [51.765899658203125, 13.0]}, 128)
batch 886: ({'logprob': [61.998619079589844, 17.0]}, 128)

======================Test output======================
logprob:  0.416550, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.970839e-03 [3.475439e-09] 
Layer 'conv1' biases: 1.225214e-07 [1.106391e-10] 
Layer 'conv2' weights[0]: 7.957842e-03 [3.289042e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.973350e-10] 
Layer 'conv3' weights[0]: 7.956158e-03 [3.208672e-09] 
Layer 'conv3' biases: 1.081780e-06 [1.880943e-09] 
Layer 'conv4' weights[0]: 7.988715e-03 [3.419840e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.679010e-08] 
Layer 'conv5' weights[0]: 7.987593e-03 [1.114329e-07] 
Layer 'conv5' biases: 9.999991e-01 [1.205917e-07] 
Layer 'fc6' weights[0]: 7.584463e-03 [9.694430e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.738900e-09] 
Layer 'fc7' weights[0]: 7.420778e-03 [4.338150e-07] 
Layer 'fc7' biases: 9.998652e-01 [4.202866e-07] 
Layer 'fc8' weights[0]: 1.306211e-03 [1.608996e-05] 
Layer 'fc8' biases: 3.069988e-02 [9.719589e-05] 
Train error last 870 batches: 0.435274
-------------------------------------------------------
Not saving because 0.416550 > 0.415707 (12.630: -0.00%)
======================================================= (12.057 sec)
13.811... logprob:  0.460422, 0.125000 (1.466 sec)
13.812... logprob:  0.462467, 0.125000 (1.496 sec)
13.813... logprob:  0.486012, 0.132812 (1.458 sec)
13.814... logprob:  0.478236, 0.132812 (1.467 sec)
13.815... logprob:  0.372657, 0.085938 (1.499 sec)
13.816... logprob:  0.409174, 0.101562 (1.452 sec)
13.817... logprob:  0.426246, 0.109375 (1.451 sec)
13.818... logprob:  0.559961, 0.164062 (1.451 sec)
13.819... logprob:  0.498229, 0.140625 (1.459 sec)
13.820... logprob:  0.421497, 0.109375 (1.447 sec)
13.821... logprob:  0.406330, 0.101562 (1.494 sec)
13.822... logprob:  0.441027, 0.117188 (1.461 sec)
13.823... logprob:  0.340221, 0.078125 (1.201 sec)
13.824... logprob:  0.490144, 0.132812 (0.713 sec)
13.825... logprob:  0.287210, 0.062500 (0.684 sec)
13.826... logprob:  0.375280, 0.093750 (0.772 sec)
13.827... logprob:  0.420718, 0.109375 (0.686 sec)
13.828... logprob:  0.443791, 0.117188 (0.689 sec)
13.829... logprob:  0.504966, 0.140625 (0.691 sec)
13.830... logprob:  0.442463, 0.117188 (1.510 sec)
13.831... logprob:  0.514226, 0.140625 (1.453 sec)
13.832... logprob:  0.330875, 0.078125 (1.460 sec)
13.833... logprob:  0.488906, 0.132812 (1.498 sec)
13.834... logprob:  0.433125, 0.117188 (1.453 sec)
13.835... logprob:  0.542310, 0.148438 (1.453 sec)
13.836... logprob:  0.376447, 0.093750 (1.452 sec)
13.837... logprob:  0.315101, 0.070312 (1.514 sec)
13.838... logprob:  0.437111, 0.117188 (1.446 sec)
13.839... logprob:  0.471770, 0.125000 (1.501 sec)
13.840... logprob:  0.555143, 0.156250 (1.453 sec)
13.841... logprob:  0.396390, 0.101562 (1.462 sec)
13.842... logprob:  0.497778, 0.140625 (1.487 sec)
13.843... logprob:  0.465569, 0.125000 (1.458 sec)
13.844... logprob:  0.497598, 0.140625 (1.454 sec)
13.845... logprob:  0.486866, 0.132812 (1.445 sec)
13.846... logprob:  0.468521, 0.125000 (1.449 sec)
13.847... logprob:  0.363052, 0.085938 (1.450 sec)
13.848... logprob:  0.396919, 0.101562 (1.498 sec)
13.849... logprob:  0.360103, 0.085938 (1.457 sec)
13.850... logprob:  0.479473, 0.132812 (1.463 sec)
13.851... logprob:  0.440166, 0.117188 (1.491 sec)
13.852... logprob:  0.546115, 0.156250 (1.453 sec)
13.853... logprob:  0.371701, 0.093750 (1.466 sec)
13.854... logprob:  0.306860, 0.070312 (1.444 sec)
13.855... logprob:  0.485094, 0.132812 (1.444 sec)
13.856... logprob:  0.443931, 0.117188 (1.455 sec)
13.857... logprob:  0.372255, 0.093750 (1.492 sec)
13.858... logprob:  0.396248, 0.101562 (1.492 sec)
13.859... logprob:  0.307947, 0.070312 (1.467 sec)
13.860... logprob:  0.565920, 0.156250 (1.490 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.28827667236328, 10.0]}, 128)
batch 872: ({'logprob': [67.65474700927734, 19.0]}, 128)
batch 873: ({'logprob': [39.72698211669922, 9.0]}, 128)
batch 874: ({'logprob': [44.83460998535156, 11.0]}, 128)
batch 875: ({'logprob': [50.72355270385742, 13.0]}, 128)
batch 876: ({'logprob': [64.91996002197266, 18.0]}, 128)
batch 877: ({'logprob': [45.22959899902344, 11.0]}, 128)
batch 878: ({'logprob': [62.53987121582031, 17.0]}, 128)
batch 879: ({'logprob': [74.7188949584961, 21.0]}, 128)
batch 880: ({'logprob': [50.73959732055664, 13.0]}, 128)
batch 881: ({'logprob': [27.51629066467285, 5.0]}, 128)
batch 882: ({'logprob': [54.66730880737305, 14.0]}, 128)
batch 883: ({'logprob': [62.52528762817383, 17.0]}, 128)
batch 884: ({'logprob': [51.1168098449707, 13.0]}, 128)
batch 885: ({'logprob': [51.90314865112305, 13.0]}, 128)
batch 886: ({'logprob': [62.92705535888672, 17.0]}, 128)

======================Test output======================
logprob:  0.416520, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.970799e-03 [4.045072e-09] 
Layer 'conv1' biases: 1.232053e-07 [9.240523e-11] 
Layer 'conv2' weights[0]: 7.957806e-03 [2.924221e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.511909e-10] 
Layer 'conv3' weights[0]: 7.956117e-03 [2.738521e-09] 
Layer 'conv3' biases: 1.086384e-06 [1.750087e-09] 
Layer 'conv4' weights[0]: 7.988675e-03 [2.955285e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.632650e-08] 
Layer 'conv5' weights[0]: 7.987551e-03 [1.113693e-07] 
Layer 'conv5' biases: 9.999982e-01 [1.210037e-07] 
Layer 'fc6' weights[0]: 7.584434e-03 [9.693192e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.736848e-09] 
Layer 'fc7' weights[0]: 7.418876e-03 [5.329753e-08] 
Layer 'fc7' biases: 9.998665e-01 [3.339600e-08] 
Layer 'fc8' weights[0]: 1.347756e-03 [1.306877e-06] 
Layer 'fc8' biases: 3.121905e-02 [5.448349e-06] 
Train error last 870 batches: 0.435274
-------------------------------------------------------
Not saving because 0.416520 > 0.415707 (12.630: -0.00%)
======================================================= (12.057 sec)
13.861... logprob:  0.417827, 0.109375 (1.462 sec)
13.862... logprob:  0.328983, 0.078125 (1.464 sec)
13.863... logprob:  0.399493, 0.101562 (1.442 sec)
13.864... logprob:  0.451350, 0.117188 (1.450 sec)
13.865... logprob:  0.484314, 0.132812 (1.457 sec)
13.866... logprob:  0.507391, 0.140625 (1.491 sec)
13.867... logprob:  0.502707, 0.140625 (1.462 sec)
13.868... logprob:  0.405468, 0.101562 (1.478 sec)
13.869... logprob:  0.383454, 0.093750 (1.478 sec)
13.870... logprob:  0.551853, 0.156250 (1.400 sec)
14.1... logprob:  0.380289, 0.093750 (1.404 sec)
14.2... logprob:  0.448296, 0.117188 (1.455 sec)
14.3... logprob:  0.398476, 0.101562 (1.422 sec)
14.4... logprob:  0.443374, 0.117188 (1.405 sec)
14.5... logprob:  0.443393, 0.117188 (1.431 sec)
14.6... logprob:  0.499258, 0.140625 (1.397 sec)
14.7... logprob:  0.362952, 0.085938 (1.422 sec)
14.8... logprob:  0.419088, 0.109375 (1.404 sec)
14.9... logprob:  0.358568, 0.085938 (1.400 sec)
14.10... logprob:  0.377308, 0.093750 (1.412 sec)
14.11... logprob:  0.334432, 0.078125 (1.446 sec)
14.12... logprob:  0.466623, 0.125000 (1.395 sec)
14.13... logprob:  0.442463, 0.117188 (1.416 sec)
14.14... logprob:  0.444869, 0.117188 (1.401 sec)
14.15... logprob:  0.395691, 0.101562 (1.412 sec)
14.16... logprob:  0.421497, 0.109375 (1.405 sec)
14.17... logprob:  0.516139, 0.140625 (1.403 sec)
14.18... logprob:  0.262121, 0.054688 (1.398 sec)
14.19... logprob:  0.279680, 0.062500 (1.405 sec)
14.20... logprob:  0.421382, 0.109375 (1.403 sec)
14.21... logprob:  0.443935, 0.117188 (0.892 sec)
14.22... logprob:  0.536502, 0.148438 (1.352 sec)
14.23... logprob:  0.532673, 0.148438 (1.417 sec)
14.24... logprob:  0.310877, 0.070312 (0.984 sec)
14.25... logprob:  0.356395, 0.085938 (0.955 sec)
14.26... logprob:  0.463629, 0.125000 (1.459 sec)
14.27... logprob:  0.404651, 0.101562 (1.384 sec)
14.28... logprob:  0.421886, 0.109375 (1.406 sec)
14.29... logprob:  0.396103, 0.101562 (1.427 sec)
14.30... logprob:  0.374220, 0.093750 (1.419 sec)
14.31... logprob:  0.479888, 0.132812 (1.400 sec)
14.32... logprob:  0.457241, 0.125000 (1.389 sec)
14.33... logprob:  0.460682, 0.125000 (1.452 sec)
14.34... logprob:  0.464664, 0.125000 (1.391 sec)
14.35... logprob:  0.316155, 0.070312 (1.399 sec)
14.36... logprob:  0.475813, 0.132812 (1.407 sec)
14.37... logprob:  0.417603, 0.109375 (1.405 sec)
14.38... logprob:  0.392478, 0.101562 (1.393 sec)
14.39... logprob:  0.632022, 0.187500 (1.441 sec)
14.40... logprob:  0.445874, 0.117188 (1.406 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.25217056274414, 10.0]}, 128)
batch 872: ({'logprob': [66.391845703125, 19.0]}, 128)
batch 873: ({'logprob': [40.89533615112305, 9.0]}, 128)
batch 874: ({'logprob': [45.53135681152344, 11.0]}, 128)
batch 875: ({'logprob': [50.925628662109375, 13.0]}, 128)
batch 876: ({'logprob': [63.89788818359375, 18.0]}, 128)
batch 877: ({'logprob': [45.91582107543945, 11.0]}, 128)
batch 878: ({'logprob': [61.748924255371094, 17.0]}, 128)
batch 879: ({'logprob': [72.92341613769531, 21.0]}, 128)
batch 880: ({'logprob': [50.941158294677734, 13.0]}, 128)
batch 881: ({'logprob': [29.690738677978516, 5.0]}, 128)
batch 882: ({'logprob': [54.58803939819336, 14.0]}, 128)
batch 883: ({'logprob': [61.734336853027344, 17.0]}, 128)
batch 884: ({'logprob': [51.30387496948242, 13.0]}, 128)
batch 885: ({'logprob': [52.06468963623047, 13.0]}, 128)
batch 886: ({'logprob': [62.1221923828125, 17.0]}, 128)

======================Test output======================
logprob:  0.416468, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.970753e-03 [3.604231e-09] 
Layer 'conv1' biases: 1.240093e-07 [8.424383e-11] 
Layer 'conv2' weights[0]: 7.957768e-03 [2.270933e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.866487e-10] 
Layer 'conv3' weights[0]: 7.956082e-03 [2.061661e-09] 
Layer 'conv3' biases: 1.094033e-06 [1.188934e-09] 
Layer 'conv4' weights[0]: 7.988637e-03 [2.183723e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.016665e-08] 
Layer 'conv5' weights[0]: 7.987524e-03 [6.911823e-08] 
Layer 'conv5' biases: 9.999986e-01 [7.497707e-08] 
Layer 'fc6' weights[0]: 7.584385e-03 [5.916582e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.012536e-09] 
Layer 'fc7' weights[0]: 7.417007e-03 [1.161849e-07] 
Layer 'fc7' biases: 9.998655e-01 [1.019670e-07] 
Layer 'fc8' weights[0]: 1.301850e-03 [7.101124e-06] 
Layer 'fc8' biases: 3.104167e-02 [4.493821e-05] 
Train error last 870 batches: 0.435274
-------------------------------------------------------
Not saving because 0.416468 > 0.415707 (12.630: -0.00%)
======================================================= (12.032 sec)
14.41... logprob:  0.352734, 0.085938 (1.424 sec)
14.42... logprob:  0.391820, 0.101562 (1.418 sec)
14.43... logprob:  0.440133, 0.117188 (1.407 sec)
14.44... logprob:  0.518496, 0.148438 (1.437 sec)
14.45... logprob:  0.381796, 0.093750 (1.394 sec)
14.46... logprob:  0.486400, 0.132812 (1.400 sec)
14.47... logprob:  0.331783, 0.078125 (1.395 sec)
14.48... logprob:  0.498869, 0.140625 (1.422 sec)
14.49... logprob:  0.510609, 0.148438 (1.420 sec)
14.50... logprob:  0.393265, 0.101562 (1.420 sec)
14.51... logprob:  0.489976, 0.140625 (1.417 sec)
14.52... logprob:  0.525776, 0.148438 (1.404 sec)
14.53... logprob:  0.295085, 0.062500 (1.448 sec)
14.54... logprob:  0.403237, 0.109375 (1.392 sec)
14.55... logprob:  0.331812, 0.078125 (1.398 sec)
14.56... logprob:  0.421725, 0.109375 (1.427 sec)
14.57... logprob:  0.572572, 0.164062 (1.425 sec)
14.58... logprob:  0.407795, 0.101562 (1.403 sec)
14.59... logprob:  0.333845, 0.078125 (1.469 sec)
14.60... logprob:  0.619091, 0.179688 (1.425 sec)
14.61... logprob:  0.382870, 0.093750 (1.429 sec)
14.62... logprob:  0.474922, 0.132812 (1.462 sec)
14.63... logprob:  0.397313, 0.101562 (1.441 sec)
14.64... logprob:  0.450263, 0.125000 (1.415 sec)
14.65... logprob:  0.373310, 0.093750 (1.406 sec)
14.66... logprob:  0.353997, 0.085938 (1.447 sec)
14.67... logprob:  0.295380, 0.062500 (1.390 sec)
14.68... logprob:  0.396825, 0.101562 (1.400 sec)
14.69... logprob:  0.496859, 0.140625 (1.425 sec)
14.70... logprob:  0.325876, 0.078125 (1.428 sec)
14.71... logprob:  0.381848, 0.101562 (1.458 sec)
14.72... logprob:  0.493865, 0.132812 (1.405 sec)
14.73... logprob:  0.447791, 0.117188 (1.425 sec)
14.74... logprob:  0.442605, 0.117188 (1.419 sec)
14.75... logprob:  0.380642, 0.093750 (1.420 sec)
14.76... logprob:  0.412093, 0.109375 (1.434 sec)
14.77... logprob:  0.396345, 0.101562 (1.431 sec)
14.78... logprob:  0.493069, 0.140625 (1.458 sec)
14.79... logprob:  0.456437, 0.125000 (1.404 sec)
14.80... logprob:  0.507858, 0.132812 (1.414 sec)
14.81... logprob:  0.416725, 0.109375 (1.420 sec)
14.82... logprob:  0.231892, 0.039062 (1.429 sec)
14.83... logprob:  0.493705, 0.140625 (1.401 sec)
14.84... logprob:  0.468075, 0.125000 (1.471 sec)
14.85... logprob:  0.432048, 0.117188 (1.426 sec)
14.86... logprob:  0.417003, 0.109375 (1.416 sec)
14.87... logprob:  0.633179, 0.187500 (1.419 sec)
14.88... logprob:  0.535118, 0.156250 (1.412 sec)
14.89... logprob:  0.410640, 0.109375 (1.433 sec)
14.90... logprob:  0.577520, 0.171875 (1.396 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.118011474609375, 10.0]}, 128)
batch 872: ({'logprob': [65.80715942382812, 19.0]}, 128)
batch 873: ({'logprob': [42.34082794189453, 9.0]}, 128)
batch 874: ({'logprob': [46.42453384399414, 11.0]}, 128)
batch 875: ({'logprob': [51.51164245605469, 13.0]}, 128)
batch 876: ({'logprob': [63.52726745605469, 18.0]}, 128)
batch 877: ({'logprob': [46.93206787109375, 11.0]}, 128)
batch 878: ({'logprob': [61.716434478759766, 17.0]}, 128)
batch 879: ({'logprob': [72.39421844482422, 21.0]}, 128)
batch 880: ({'logprob': [51.52613830566406, 13.0]}, 128)
batch 881: ({'logprob': [31.633676528930664, 5.0]}, 128)
batch 882: ({'logprob': [55.321292877197266, 14.0]}, 128)
batch 883: ({'logprob': [61.70210647583008, 17.0]}, 128)
batch 884: ({'logprob': [52.00901412963867, 13.0]}, 128)
batch 885: ({'logprob': [53.012229919433594, 13.0]}, 128)
batch 886: ({'logprob': [62.20987319946289, 17.0]}, 128)

======================Test output======================
logprob:  0.420501, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.970714e-03 [3.497607e-09] 
Layer 'conv1' biases: 1.249128e-07 [9.243607e-11] 
Layer 'conv2' weights[0]: 7.957725e-03 [2.717792e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.802929e-10] 
Layer 'conv3' weights[0]: 7.956045e-03 [2.376318e-09] 
Layer 'conv3' biases: 1.100682e-06 [1.510629e-09] 
Layer 'conv4' weights[0]: 7.988592e-03 [2.576526e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.333987e-08] 
Layer 'conv5' weights[0]: 7.987480e-03 [8.809948e-08] 
Layer 'conv5' biases: 9.999989e-01 [9.524631e-08] 
Layer 'fc6' weights[0]: 7.584347e-03 [7.534728e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.641528e-09] 
Layer 'fc7' weights[0]: 7.415110e-03 [2.540230e-07] 
Layer 'fc7' biases: 9.998644e-01 [2.431441e-07] 
Layer 'fc8' weights[0]: 1.273730e-03 [9.593395e-06] 
Layer 'fc8' biases: 3.088983e-02 [6.111253e-05] 
Train error last 870 batches: 0.435274
-------------------------------------------------------
Not saving because 0.420501 > 0.415707 (12.630: -0.00%)
======================================================= (12.044 sec)
14.91... logprob:  0.348567, 0.078125 (1.414 sec)
14.92... logprob:  0.464462, 0.125000 (1.407 sec)
14.93... logprob:  0.492294, 0.140625 (1.402 sec)
14.94... logprob:  0.428785, 0.109375 (1.397 sec)
14.95... logprob:  0.471866, 0.125000 (1.408 sec)
14.96... logprob:  0.576384, 0.171875 (1.406 sec)
14.97... logprob:  0.430749, 0.117188 (1.401 sec)
14.98... logprob:  0.391001, 0.093750 (1.433 sec)
14.99... logprob:  0.474334, 0.132812 (1.415 sec)
14.100... logprob:  0.310317, 0.070312 (1.409 sec)
14.101... logprob:  0.310471, 0.062500 (1.444 sec)
14.102... logprob:  0.546444, 0.156250 (1.389 sec)
14.103... logprob:  0.541418, 0.156250 (1.405 sec)
14.104... logprob:  0.388883, 0.101562 (1.400 sec)
14.105... logprob:  0.619900, 0.179688 (1.397 sec)
14.106... logprob:  0.344424, 0.085938 (1.397 sec)
14.107... logprob:  0.335687, 0.078125 (1.439 sec)
14.108... logprob:  0.586797, 0.171875 (1.398 sec)
14.109... logprob:  0.336225, 0.078125 (1.408 sec)
14.110... logprob:  0.564385, 0.164062 (1.395 sec)
14.111... logprob:  0.404751, 0.101562 (1.404 sec)
14.112... logprob:  0.366228, 0.093750 (1.408 sec)
14.113... logprob:  0.354725, 0.085938 (1.403 sec)
14.114... logprob:  0.440239, 0.117188 (1.432 sec)
14.115... logprob:  0.506717, 0.140625 (1.413 sec)
14.116... logprob:  0.393420, 0.101562 (1.408 sec)
14.117... logprob:  0.440397, 0.117188 (1.444 sec)
14.118... logprob:  0.409188, 0.101562 (1.389 sec)
14.119... logprob:  0.346144, 0.085938 (1.403 sec)
14.120... logprob:  0.547162, 0.156250 (1.401 sec)
14.121... logprob:  0.412696, 0.109375 (1.399 sec)
14.122... logprob:  0.519389, 0.148438 (1.442 sec)
14.123... logprob:  0.463765, 0.125000 (1.392 sec)
14.124... logprob:  0.447720, 0.125000 (1.408 sec)
14.125... logprob:  0.502028, 0.140625 (1.401 sec)
14.126... logprob:  0.475821, 0.125000 (1.390 sec)
14.127... logprob:  0.479652, 0.125000 (1.402 sec)
14.128... logprob:  0.422391, 0.109375 (1.420 sec)
14.129... logprob:  0.574896, 0.164062 (1.417 sec)
14.130... logprob:  0.382766, 0.093750 (1.417 sec)
14.131... logprob:  0.495505, 0.132812 (1.409 sec)
14.132... logprob:  0.506391, 0.140625 (1.472 sec)
14.133... logprob:  0.444685, 0.117188 (1.389 sec)
14.134... logprob:  0.401926, 0.101562 (1.399 sec)
14.135... logprob:  0.460251, 0.125000 (1.402 sec)
14.136... logprob:  0.562609, 0.164062 (1.402 sec)
14.137... logprob:  0.462564, 0.125000 (1.388 sec)
14.138... logprob:  0.319325, 0.070312 (1.446 sec)
14.139... logprob:  0.395790, 0.101562 (1.402 sec)
14.140... logprob:  0.560573, 0.164062 (1.409 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.47684860229492, 10.0]}, 128)
batch 872: ({'logprob': [66.70130157470703, 19.0]}, 128)
batch 873: ({'logprob': [40.659881591796875, 9.0]}, 128)
batch 874: ({'logprob': [45.562049865722656, 11.0]}, 128)
batch 875: ({'logprob': [50.9599494934082, 13.0]}, 128)
batch 876: ({'logprob': [64.14044952392578, 18.0]}, 128)
batch 877: ({'logprob': [45.81559753417969, 11.0]}, 128)
batch 878: ({'logprob': [61.79242706298828, 17.0]}, 128)
batch 879: ({'logprob': [72.8454360961914, 21.0]}, 128)
batch 880: ({'logprob': [50.97613525390625, 13.0]}, 128)
batch 881: ({'logprob': [29.577072143554688, 5.0]}, 128)
batch 882: ({'logprob': [54.29821014404297, 14.0]}, 128)
batch 883: ({'logprob': [61.77756881713867, 17.0]}, 128)
batch 884: ({'logprob': [51.20804977416992, 13.0]}, 128)
batch 885: ({'logprob': [51.70709228515625, 13.0]}, 128)
batch 886: ({'logprob': [62.035030364990234, 17.0]}, 128)

======================Test output======================
logprob:  0.416276, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.970679e-03 [2.760673e-09] 
Layer 'conv1' biases: 1.255264e-07 [5.160799e-11] 
Layer 'conv2' weights[0]: 7.957685e-03 [1.829401e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.798485e-10] 
Layer 'conv3' weights[0]: 7.956007e-03 [1.554937e-09] 
Layer 'conv3' biases: 1.104210e-06 [8.513671e-10] 
Layer 'conv4' weights[0]: 7.988549e-03 [1.515641e-09] 
Layer 'conv4' biases: 9.999998e-01 [6.245274e-09] 
Layer 'conv5' weights[0]: 7.987438e-03 [3.149046e-08] 
Layer 'conv5' biases: 9.999983e-01 [3.368808e-08] 
Layer 'fc6' weights[0]: 7.584312e-03 [2.811686e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.761596e-09] 
Layer 'fc7' weights[0]: 7.413270e-03 [1.116694e-07] 
Layer 'fc7' biases: 9.998652e-01 [9.670314e-08] 
Layer 'fc8' weights[0]: 1.307021e-03 [3.911901e-06] 
Layer 'fc8' biases: 3.122978e-02 [2.697977e-05] 
Train error last 870 batches: 0.435273
-------------------------------------------------------
Not saving because 0.416276 > 0.415707 (12.630: -0.00%)
======================================================= (12.041 sec)
14.141... logprob:  0.464533, 0.125000 (1.439 sec)
14.142... logprob:  0.464606, 0.125000 (1.404 sec)
14.143... logprob:  0.294234, 0.062500 (1.428 sec)
14.144... logprob:  0.457345, 0.125000 (1.417 sec)
14.145... logprob:  0.324892, 0.078125 (1.420 sec)
14.146... logprob:  0.483262, 0.132812 (1.409 sec)
14.147... logprob:  0.262468, 0.054688 (1.437 sec)
14.148... logprob:  0.458863, 0.125000 (1.388 sec)
14.149... logprob:  0.442576, 0.117188 (1.403 sec)
14.150... logprob:  0.347639, 0.085938 (1.408 sec)
14.151... logprob:  0.347157, 0.085938 (1.398 sec)
14.152... logprob:  0.784986, 0.234375 (1.394 sec)
14.153... logprob:  0.381671, 0.093750 (1.441 sec)
14.154... logprob:  0.524335, 0.148438 (1.405 sec)
14.155... logprob:  0.425964, 0.117188 (1.406 sec)
14.156... logprob:  0.296006, 0.062500 (1.442 sec)
14.157... logprob:  0.270922, 0.054688 (1.392 sec)
14.158... logprob:  0.455360, 0.125000 (1.404 sec)
14.159... logprob:  0.483116, 0.132812 (1.402 sec)
14.160... logprob:  0.444914, 0.117188 (1.393 sec)
14.161... logprob:  0.350214, 0.078125 (1.414 sec)
14.162... logprob:  0.611803, 0.179688 (1.412 sec)
14.163... logprob:  0.450424, 0.125000 (1.427 sec)
14.164... logprob:  0.468713, 0.125000 (1.417 sec)
14.165... logprob:  0.547989, 0.156250 (1.422 sec)
14.166... logprob:  0.446054, 0.125000 (1.449 sec)
14.167... logprob:  0.350378, 0.085938 (1.434 sec)
14.168... logprob:  0.363656, 0.085938 (1.422 sec)
14.169... logprob:  0.408689, 0.101562 (1.466 sec)
14.170... logprob:  0.459500, 0.125000 (1.408 sec)
14.171... logprob:  0.535512, 0.156250 (1.417 sec)
14.172... logprob:  0.434879, 0.109375 (1.416 sec)
14.173... logprob:  0.440504, 0.117188 (1.420 sec)
14.174... logprob:  0.601222, 0.171875 (1.414 sec)
14.175... logprob:  0.506148, 0.140625 (1.468 sec)
14.176... logprob:  0.478508, 0.132812 (1.419 sec)
14.177... logprob:  0.289786, 0.054688 (1.427 sec)
14.178... logprob:  0.383496, 0.093750 (1.459 sec)
14.179... logprob:  0.394740, 0.101562 (1.409 sec)
14.180... logprob:  0.466382, 0.125000 (1.422 sec)
14.181... logprob:  0.539419, 0.156250 (1.421 sec)
14.182... logprob:  0.371424, 0.093750 (1.419 sec)
14.183... logprob:  0.419966, 0.109375 (1.425 sec)
14.184... logprob:  0.483484, 0.132812 (1.423 sec)
14.185... logprob:  0.289894, 0.062500 (1.398 sec)
14.186... logprob:  0.370530, 0.093750 (1.399 sec)
14.187... logprob:  0.529634, 0.148438 (1.405 sec)
14.188... logprob:  0.459007, 0.125000 (1.400 sec)
14.189... logprob:  0.440905, 0.117188 (1.394 sec)
14.190... logprob:  0.375736, 0.093750 (1.435 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.684837341308594, 10.0]}, 128)
batch 872: ({'logprob': [67.03465270996094, 19.0]}, 128)
batch 873: ({'logprob': [40.128868103027344, 9.0]}, 128)
batch 874: ({'logprob': [45.06950378417969, 11.0]}, 128)
batch 875: ({'logprob': [50.72943115234375, 13.0]}, 128)
batch 876: ({'logprob': [64.39891815185547, 18.0]}, 128)
batch 877: ({'logprob': [45.434181213378906, 11.0]}, 128)
batch 878: ({'logprob': [62.08712387084961, 17.0]}, 128)
batch 879: ({'logprob': [73.77620697021484, 21.0]}, 128)
batch 880: ({'logprob': [50.74571990966797, 13.0]}, 128)
batch 881: ({'logprob': [28.40857696533203, 5.0]}, 128)
batch 882: ({'logprob': [54.47981643676758, 14.0]}, 128)
batch 883: ({'logprob': [62.07216262817383, 17.0]}, 128)
batch 884: ({'logprob': [51.09067916870117, 13.0]}, 128)
batch 885: ({'logprob': [51.813968658447266, 13.0]}, 128)
batch 886: ({'logprob': [62.44242858886719, 17.0]}, 128)

======================Test output======================
logprob:  0.415721, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.970644e-03 [2.261332e-09] 
Layer 'conv1' biases: 1.263936e-07 [4.110251e-11] 
Layer 'conv2' weights[0]: 7.957652e-03 [1.566320e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.183386e-10] 
Layer 'conv3' weights[0]: 7.955968e-03 [1.176779e-09] 
Layer 'conv3' biases: 1.111914e-06 [3.326396e-10] 
Layer 'conv4' weights[0]: 7.988507e-03 [1.133214e-09] 
Layer 'conv4' biases: 9.999998e-01 [5.473424e-10] 
Layer 'conv5' weights[0]: 7.987403e-03 [2.705004e-09] 
Layer 'conv5' biases: 9.999985e-01 [2.389277e-09] 
Layer 'fc6' weights[0]: 7.584277e-03 [7.847966e-10] 
Layer 'fc6' biases: 1.000000e+00 [1.989774e-10] 
Layer 'fc7' weights[0]: 7.411402e-03 [3.762956e-08] 
Layer 'fc7' biases: 9.998658e-01 [6.302600e-09] 
Layer 'fc8' weights[0]: 1.335639e-03 [9.462465e-07] 
Layer 'fc8' biases: 3.152114e-02 [5.078053e-06] 
Train error last 870 batches: 0.435273
-------------------------------------------------------
Not saving because 0.415721 > 0.415707 (12.630: -0.00%)
======================================================= (12.151 sec)
14.191... logprob:  0.485105, 0.132812 (1.410 sec)
14.192... logprob:  0.520186, 0.148438 (1.426 sec)
14.193... logprob:  0.312640, 0.070312 (1.419 sec)
14.194... logprob:  0.414121, 0.109375 (1.414 sec)
14.195... logprob:  0.287260, 0.062500 (1.405 sec)
14.196... logprob:  0.410565, 0.109375 (1.389 sec)
14.197... logprob:  0.478035, 0.132812 (1.401 sec)
14.198... logprob:  0.355792, 0.085938 (1.409 sec)
14.199... logprob:  0.437193, 0.117188 (1.428 sec)
14.200... logprob:  0.440781, 0.117188 (1.443 sec)
14.201... logprob:  0.437101, 0.117188 (1.404 sec)
14.202... logprob:  0.537988, 0.148438 (1.399 sec)
14.203... logprob:  0.420467, 0.109375 (1.440 sec)
14.204... logprob:  0.504127, 0.140625 (1.390 sec)
14.205... logprob:  0.334404, 0.078125 (1.405 sec)
14.206... logprob:  0.361635, 0.093750 (1.405 sec)
14.207... logprob:  0.381920, 0.093750 (1.397 sec)
14.208... logprob:  0.490517, 0.140625 (1.402 sec)
14.209... logprob:  0.334607, 0.078125 (1.420 sec)
14.210... logprob:  0.586252, 0.171875 (1.420 sec)
14.211... logprob:  0.488201, 0.132812 (1.414 sec)
14.212... logprob:  0.526157, 0.148438 (1.411 sec)
14.213... logprob:  0.514827, 0.140625 (1.462 sec)
14.214... logprob:  0.459445, 0.125000 (1.424 sec)
14.215... logprob:  0.396158, 0.101562 (1.422 sec)
14.216... logprob:  0.517130, 0.140625 (1.466 sec)
14.217... logprob:  0.325133, 0.070312 (1.406 sec)
14.218... logprob:  0.463714, 0.125000 (1.424 sec)
14.219... logprob:  0.500320, 0.140625 (1.412 sec)
14.220... logprob:  0.414996, 0.109375 (1.426 sec)
14.221... logprob:  0.399538, 0.101562 (1.408 sec)
14.222... logprob:  0.554601, 0.164062 (1.458 sec)
14.223... logprob:  0.569273, 0.164062 (1.429 sec)
14.224... logprob:  0.405865, 0.101562 (1.436 sec)
14.225... logprob:  0.391966, 0.101562 (1.446 sec)
14.226... logprob:  0.424624, 0.109375 (1.428 sec)
14.227... logprob:  0.452747, 0.125000 (1.424 sec)
14.228... logprob:  0.417204, 0.109375 (1.413 sec)
14.229... logprob:  0.489372, 0.132812 (1.423 sec)
14.230... logprob:  0.459903, 0.125000 (1.423 sec)
14.231... logprob:  0.453547, 0.125000 (1.410 sec)
14.232... logprob:  0.496232, 0.140625 (1.455 sec)
14.233... logprob:  0.466173, 0.132812 (1.429 sec)
14.234... logprob:  0.563793, 0.164062 (1.419 sec)
14.235... logprob:  0.482035, 0.132812 (1.468 sec)
14.236... logprob:  0.425815, 0.109375 (1.414 sec)
14.237... logprob:  0.341376, 0.078125 (1.426 sec)
14.238... logprob:  0.389408, 0.093750 (1.421 sec)
14.239... logprob:  0.478152, 0.132812 (1.421 sec)
14.240... logprob:  0.485810, 0.132812 (1.403 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.32733917236328, 10.0]}, 128)
batch 872: ({'logprob': [66.07654571533203, 19.0]}, 128)
batch 873: ({'logprob': [41.3747673034668, 9.0]}, 128)
batch 874: ({'logprob': [45.72587966918945, 11.0]}, 128)
batch 875: ({'logprob': [51.04560089111328, 13.0]}, 128)
batch 876: ({'logprob': [63.67241668701172, 18.0]}, 128)
batch 877: ({'logprob': [46.21571350097656, 11.0]}, 128)
batch 878: ({'logprob': [61.71858215332031, 17.0]}, 128)
batch 879: ({'logprob': [72.84674835205078, 21.0]}, 128)
batch 880: ({'logprob': [51.060943603515625, 13.0]}, 128)
batch 881: ({'logprob': [30.21611785888672, 5.0]}, 128)
batch 882: ({'logprob': [54.9317512512207, 14.0]}, 128)
batch 883: ({'logprob': [61.703792572021484, 17.0]}, 128)
batch 884: ({'logprob': [51.52790069580078, 13.0]}, 128)
batch 885: ({'logprob': [52.49785614013672, 13.0]}, 128)
batch 886: ({'logprob': [62.196109771728516, 17.0]}, 128)

======================Test output======================
logprob:  0.417548, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.970607e-03 [2.371561e-09] 
Layer 'conv1' biases: 1.271138e-07 [4.769799e-11] 
Layer 'conv2' weights[0]: 7.957616e-03 [1.517359e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.462749e-10] 
Layer 'conv3' weights[0]: 7.955936e-03 [1.211293e-09] 
Layer 'conv3' biases: 1.118593e-06 [4.365182e-10] 
Layer 'conv4' weights[0]: 7.988465e-03 [1.163955e-09] 
Layer 'conv4' biases: 9.999998e-01 [2.587882e-09] 
Layer 'conv5' weights[0]: 7.987362e-03 [1.273906e-08] 
Layer 'conv5' biases: 9.999985e-01 [1.346129e-08] 
Layer 'fc6' weights[0]: 7.584231e-03 [1.353136e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.106526e-09] 
Layer 'fc7' weights[0]: 7.409505e-03 [7.908909e-08] 
Layer 'fc7' biases: 9.998648e-01 [6.253797e-08] 
Layer 'fc8' weights[0]: 1.304216e-03 [2.595385e-06] 
Layer 'fc8' biases: 3.135842e-02 [1.826478e-05] 
Train error last 870 batches: 0.435273
-------------------------------------------------------
Not saving because 0.417548 > 0.415707 (12.630: -0.00%)
======================================================= (12.238 sec)
14.241... logprob:  0.493608, 0.132812 (1.467 sec)
14.242... logprob:  0.341654, 0.078125 (1.444 sec)
14.243... logprob:  0.386023, 0.093750 (1.446 sec)
14.244... logprob:  0.315207, 0.070312 (1.454 sec)
14.245... logprob:  0.494370, 0.132812 (1.429 sec)
14.246... logprob:  0.416915, 0.109375 (1.426 sec)
14.247... logprob:  0.357341, 0.085938 (1.422 sec)
14.248... logprob:  0.307723, 0.070312 (1.420 sec)
14.249... logprob:  0.555527, 0.156250 (1.442 sec)
14.250... logprob:  0.591809, 0.164062 (1.413 sec)
14.251... logprob:  0.352905, 0.085938 (1.460 sec)
14.252... logprob:  0.348492, 0.085938 (1.434 sec)
14.253... logprob:  0.379176, 0.093750 (1.430 sec)
14.254... logprob:  0.444184, 0.117188 (1.476 sec)
14.255... logprob:  0.351506, 0.085938 (1.399 sec)
14.256... logprob:  0.378743, 0.093750 (1.435 sec)
14.257... logprob:  0.332059, 0.078125 (1.426 sec)
14.258... logprob:  0.415778, 0.109375 (1.425 sec)
14.259... logprob:  0.442309, 0.117188 (1.412 sec)
14.260... logprob:  0.308413, 0.070312 (1.476 sec)
14.261... logprob:  0.392821, 0.101562 (1.443 sec)
14.262... logprob:  0.524668, 0.148438 (1.446 sec)
14.263... logprob:  0.425474, 0.109375 (1.457 sec)
14.264... logprob:  0.375167, 0.093750 (1.432 sec)
14.265... logprob:  0.439614, 0.117188 (1.425 sec)
14.266... logprob:  0.439041, 0.117188 (1.425 sec)
14.267... logprob:  0.422003, 0.109375 (1.432 sec)
14.268... logprob:  0.458946, 0.125000 (1.433 sec)
14.269... logprob:  0.567464, 0.164062 (1.425 sec)
14.270... logprob:  0.542203, 0.156250 (1.475 sec)
14.271... logprob:  0.445761, 0.117188 (1.427 sec)
14.272... logprob:  0.384776, 0.093750 (1.436 sec)
14.273... logprob:  0.500217, 0.140625 (1.477 sec)
14.274... logprob:  0.542535, 0.156250 (1.431 sec)
14.275... logprob:  0.487745, 0.132812 (1.439 sec)
14.276... logprob:  0.390189, 0.093750 (1.421 sec)
14.277... logprob:  0.428731, 0.109375 (1.425 sec)
14.278... logprob:  0.323379, 0.070312 (1.420 sec)
14.279... logprob:  0.324942, 0.070312 (1.469 sec)
14.280... logprob:  0.215093, 0.031250 (1.417 sec)
14.281... logprob:  0.417216, 0.109375 (1.431 sec)
14.282... logprob:  0.411484, 0.109375 (1.424 sec)
14.283... logprob:  0.393875, 0.101562 (1.431 sec)
14.284... logprob:  0.394727, 0.101562 (1.426 sec)
14.285... logprob:  0.452230, 0.117188 (1.449 sec)
14.286... logprob:  0.537598, 0.140625 (1.443 sec)
14.287... logprob:  0.346693, 0.085938 (1.440 sec)
14.288... logprob:  0.329982, 0.078125 (1.492 sec)
14.289... logprob:  0.446043, 0.117188 (1.444 sec)
14.290... logprob:  0.490653, 0.132812 (1.416 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.9799919128418, 10.0]}, 128)
batch 872: ({'logprob': [68.57755279541016, 19.0]}, 128)
batch 873: ({'logprob': [39.44247817993164, 9.0]}, 128)
batch 874: ({'logprob': [44.735836029052734, 11.0]}, 128)
batch 875: ({'logprob': [50.90260314941406, 13.0]}, 128)
batch 876: ({'logprob': [65.72764587402344, 18.0]}, 128)
batch 877: ({'logprob': [45.17662048339844, 11.0]}, 128)
batch 878: ({'logprob': [63.27714920043945, 17.0]}, 128)
batch 879: ({'logprob': [76.05961608886719, 21.0]}, 128)
batch 880: ({'logprob': [50.91932678222656, 13.0]}, 128)
batch 881: ({'logprob': [26.627059936523438, 5.0]}, 128)
batch 882: ({'logprob': [55.10349655151367, 14.0]}, 128)
batch 883: ({'logprob': [63.26201629638672, 17.0]}, 128)
batch 884: ({'logprob': [51.344154357910156, 13.0]}, 128)
batch 885: ({'logprob': [52.22349166870117, 13.0]}, 128)
batch 886: ({'logprob': [63.71162414550781, 17.0]}, 128)

======================Test output======================
logprob:  0.418980, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.970573e-03 [5.222717e-09] 
Layer 'conv1' biases: 1.279704e-07 [1.726675e-10] 
Layer 'conv2' weights[0]: 7.957570e-03 [4.364282e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.306502e-10] 
Layer 'conv3' weights[0]: 7.955895e-03 [4.365111e-09] 
Layer 'conv3' biases: 1.124259e-06 [2.876963e-09] 
Layer 'conv4' weights[0]: 7.988429e-03 [4.640806e-09] 
Layer 'conv4' biases: 9.999998e-01 [2.618620e-08] 
Layer 'conv5' weights[0]: 7.987324e-03 [1.744239e-07] 
Layer 'conv5' biases: 9.999985e-01 [1.885754e-07] 
Layer 'fc6' weights[0]: 7.584186e-03 [1.507629e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.535985e-08] 
Layer 'fc7' weights[0]: 7.407576e-03 [2.868185e-07] 
Layer 'fc7' biases: 9.998668e-01 [2.766253e-07] 
Layer 'fc8' weights[0]: 1.382447e-03 [1.135649e-05] 
Layer 'fc8' biases: 3.207553e-02 [5.948338e-05] 
Train error last 870 batches: 0.435272
-------------------------------------------------------
Not saving because 0.418980 > 0.415707 (12.630: -0.00%)
======================================================= (12.095 sec)
14.291... logprob:  0.439141, 0.117188 (1.432 sec)
14.292... logprob:  0.566969, 0.156250 (1.424 sec)
14.293... logprob:  0.427475, 0.117188 (1.434 sec)
14.294... logprob:  0.356239, 0.085938 (1.411 sec)
14.295... logprob:  0.335204, 0.078125 (1.481 sec)
14.296... logprob:  0.356279, 0.085938 (1.421 sec)
14.297... logprob:  0.394859, 0.101562 (1.422 sec)
14.298... logprob:  0.448103, 0.125000 (1.469 sec)
14.299... logprob:  0.342696, 0.078125 (1.406 sec)
14.300... logprob:  0.406714, 0.101562 (1.430 sec)
14.301... logprob:  0.397970, 0.101562 (1.421 sec)
14.302... logprob:  0.591565, 0.179688 (1.425 sec)
14.303... logprob:  0.459653, 0.125000 (1.422 sec)
14.304... logprob:  0.459723, 0.125000 (1.442 sec)
14.305... logprob:  0.455248, 0.125000 (1.438 sec)
14.306... logprob:  0.440616, 0.117188 (1.437 sec)
14.307... logprob:  0.421597, 0.109375 (1.468 sec)
14.308... logprob:  0.374532, 0.093750 (1.457 sec)
14.309... logprob:  0.450497, 0.125000 (1.417 sec)
14.310... logprob:  0.473774, 0.125000 (1.424 sec)
14.311... logprob:  0.502684, 0.140625 (1.423 sec)
14.312... logprob:  0.478811, 0.132812 (1.437 sec)
14.313... logprob:  0.454875, 0.125000 (1.420 sec)
14.314... logprob:  0.454527, 0.117188 (1.469 sec)
14.315... logprob:  0.314700, 0.070312 (1.432 sec)
14.316... logprob:  0.468587, 0.125000 (1.427 sec)
14.317... logprob:  0.355539, 0.085938 (1.481 sec)
14.318... logprob:  0.455421, 0.125000 (1.419 sec)
14.319... logprob:  0.423216, 0.117188 (1.427 sec)
14.320... logprob:  0.412267, 0.109375 (1.428 sec)
14.321... logprob:  0.348301, 0.085938 (1.425 sec)
14.322... logprob:  0.387535, 0.101562 (1.421 sec)
14.323... logprob:  0.416528, 0.109375 (1.481 sec)
14.324... logprob:  0.498641, 0.140625 (1.423 sec)
14.325... logprob:  0.350682, 0.085938 (1.441 sec)
14.326... logprob:  0.543200, 0.148438 (1.462 sec)
14.327... logprob:  0.554411, 0.164062 (1.492 sec)
14.328... logprob:  0.565011, 0.156250 (1.425 sec)
14.329... logprob:  0.402011, 0.101562 (1.426 sec)
14.330... logprob:  0.388684, 0.101562 (1.421 sec)
14.331... logprob:  0.352567, 0.085938 (1.417 sec)
14.332... logprob:  0.482793, 0.132812 (1.453 sec)
14.333... logprob:  0.339658, 0.085938 (1.444 sec)
14.334... logprob:  0.565091, 0.171875 (1.445 sec)
14.335... logprob:  0.358884, 0.085938 (1.443 sec)
14.336... logprob:  0.444830, 0.125000 (1.452 sec)
14.337... logprob:  0.566486, 0.164062 (1.430 sec)
14.338... logprob:  0.449518, 0.125000 (1.419 sec)
14.339... logprob:  0.488717, 0.132812 (1.428 sec)
14.340... logprob:  0.442078, 0.117188 (1.436 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.31190490722656, 10.0]}, 128)
batch 872: ({'logprob': [65.78726196289062, 19.0]}, 128)
batch 873: ({'logprob': [42.10420608520508, 9.0]}, 128)
batch 874: ({'logprob': [46.002445220947266, 11.0]}, 128)
batch 875: ({'logprob': [51.285499572753906, 13.0]}, 128)
batch 876: ({'logprob': [63.504859924316406, 18.0]}, 128)
batch 877: ({'logprob': [46.700042724609375, 11.0]}, 128)
batch 878: ({'logprob': [61.88218307495117, 17.0]}, 128)
batch 879: ({'logprob': [73.14105987548828, 21.0]}, 128)
batch 880: ({'logprob': [51.29981231689453, 13.0]}, 128)
batch 881: ({'logprob': [30.814634323120117, 5.0]}, 128)
batch 882: ({'logprob': [55.67011642456055, 14.0]}, 128)
batch 883: ({'logprob': [61.86766815185547, 17.0]}, 128)
batch 884: ({'logprob': [51.97422409057617, 13.0]}, 128)
batch 885: ({'logprob': [53.358943939208984, 13.0]}, 128)
batch 886: ({'logprob': [62.566646575927734, 17.0]}, 128)

======================Test output======================
logprob:  0.420054, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.970527e-03 [2.424894e-09] 
Layer 'conv1' biases: 1.287499e-07 [3.549378e-11] 
Layer 'conv2' weights[0]: 7.957527e-03 [1.685964e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.440365e-10] 
Layer 'conv3' weights[0]: 7.955853e-03 [1.295846e-09] 
Layer 'conv3' biases: 1.130982e-06 [4.554628e-10] 
Layer 'conv4' weights[0]: 7.988385e-03 [1.262360e-09] 
Layer 'conv4' biases: 9.999997e-01 [2.569903e-09] 
Layer 'conv5' weights[0]: 7.987278e-03 [1.312281e-08] 
Layer 'conv5' biases: 9.999984e-01 [1.392827e-08] 
Layer 'fc6' weights[0]: 7.584145e-03 [1.384083e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.143614e-09] 
Layer 'fc7' weights[0]: 7.405682e-03 [3.736131e-08] 
Layer 'fc7' biases: 9.998648e-01 [4.716200e-09] 
Layer 'fc8' weights[0]: 1.293688e-03 [1.344887e-06] 
Layer 'fc8' biases: 3.166852e-02 [7.829773e-06] 
Train error last 870 batches: 0.435272
-------------------------------------------------------
Not saving because 0.420054 > 0.415707 (12.630: -0.00%)
======================================================= (12.180 sec)
14.341... logprob:  0.530158, 0.148438 (1.429 sec)
14.342... logprob:  0.429689, 0.109375 (1.474 sec)
14.343... logprob:  0.434786, 0.109375 (1.433 sec)
14.344... logprob:  0.444415, 0.125000 (1.484 sec)
14.345... logprob:  0.488273, 0.132812 (1.445 sec)
14.346... logprob:  0.436251, 0.117188 (1.435 sec)
14.347... logprob:  0.372334, 0.085938 (1.485 sec)
14.348... logprob:  0.398437, 0.101562 (1.438 sec)
14.349... logprob:  0.497914, 0.140625 (1.430 sec)
14.350... logprob:  0.358536, 0.085938 (1.441 sec)
14.351... logprob:  0.508702, 0.140625 (1.428 sec)
14.352... logprob:  0.363669, 0.093750 (1.436 sec)
14.353... logprob:  0.512829, 0.148438 (1.494 sec)
14.354... logprob:  0.675179, 0.203125 (1.429 sec)
14.355... logprob:  0.357474, 0.085938 (1.449 sec)
14.356... logprob:  0.479255, 0.132812 (1.481 sec)
14.357... logprob:  0.347074, 0.085938 (1.429 sec)
14.358... logprob:  0.326065, 0.070312 (1.440 sec)
14.359... logprob:  0.555208, 0.164062 (1.430 sec)
14.360... logprob:  0.444518, 0.117188 (1.424 sec)
14.361... logprob:  0.410788, 0.101562 (1.433 sec)
14.362... logprob:  0.424154, 0.117188 (1.478 sec)
14.363... logprob:  0.486588, 0.132812 (1.444 sec)
14.364... logprob:  0.475540, 0.125000 (1.453 sec)
14.365... logprob:  0.425097, 0.109375 (1.465 sec)
14.366... logprob:  0.409710, 0.109375 (1.450 sec)
14.367... logprob:  0.325011, 0.078125 (1.435 sec)
14.368... logprob:  0.595716, 0.171875 (1.427 sec)
14.369... logprob:  0.381524, 0.093750 (1.427 sec)
14.370... logprob:  0.381150, 0.093750 (1.441 sec)
14.371... logprob:  0.400342, 0.101562 (1.456 sec)
14.372... logprob:  0.537636, 0.156250 (1.450 sec)
14.373... logprob:  0.463837, 0.125000 (1.460 sec)
14.374... logprob:  0.527111, 0.148438 (1.447 sec)
14.375... logprob:  0.393785, 0.101562 (1.462 sec)
14.376... logprob:  0.374321, 0.093750 (1.438 sec)
14.377... logprob:  0.295379, 0.062500 (1.427 sec)
14.378... logprob:  0.453778, 0.125000 (1.430 sec)
14.379... logprob:  0.420239, 0.109375 (1.442 sec)
14.380... logprob:  0.605762, 0.179688 (1.437 sec)
14.381... logprob:  0.463495, 0.125000 (1.484 sec)
14.382... logprob:  0.529495, 0.148438 (1.449 sec)
14.383... logprob:  0.358720, 0.085938 (1.444 sec)
14.384... logprob:  0.521025, 0.148438 (1.480 sec)
14.385... logprob:  0.523453, 0.148438 (1.428 sec)
14.386... logprob:  0.582309, 0.171875 (1.426 sec)
14.387... logprob:  0.428709, 0.117188 (1.442 sec)
14.388... logprob:  0.521302, 0.148438 (1.433 sec)
14.389... logprob:  0.425955, 0.109375 (1.455 sec)
14.390... logprob:  0.419966, 0.109375 (1.475 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.85727310180664, 10.0]}, 128)
batch 872: ({'logprob': [65.84725189208984, 19.0]}, 128)
batch 873: ({'logprob': [42.92844009399414, 9.0]}, 128)
batch 874: ({'logprob': [46.982398986816406, 11.0]}, 128)
batch 875: ({'logprob': [51.906982421875, 13.0]}, 128)
batch 876: ({'logprob': [63.61561965942383, 18.0]}, 128)
batch 877: ({'logprob': [47.42425537109375, 11.0]}, 128)
batch 878: ({'logprob': [61.786678314208984, 17.0]}, 128)
batch 879: ({'logprob': [72.07257843017578, 21.0]}, 128)
batch 880: ({'logprob': [51.92198181152344, 13.0]}, 128)
batch 881: ({'logprob': [32.613624572753906, 5.0]}, 128)
batch 882: ({'logprob': [55.46861267089844, 14.0]}, 128)
batch 883: ({'logprob': [61.771873474121094, 17.0]}, 128)
batch 884: ({'logprob': [52.33727264404297, 13.0]}, 128)
batch 885: ({'logprob': [53.20694351196289, 13.0]}, 128)
batch 886: ({'logprob': [62.21295166015625, 17.0]}, 128)

======================Test output======================
logprob:  0.422829, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.970489e-03 [2.500943e-09] 
Layer 'conv1' biases: 1.296854e-07 [1.090605e-10] 
Layer 'conv2' weights[0]: 7.957494e-03 [2.687952e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.886929e-10] 
Layer 'conv3' weights[0]: 7.955821e-03 [2.865219e-09] 
Layer 'conv3' biases: 1.138252e-06 [1.772389e-09] 
Layer 'conv4' weights[0]: 7.988349e-03 [3.163083e-09] 
Layer 'conv4' biases: 9.999997e-01 [1.777128e-08] 
Layer 'conv5' weights[0]: 7.987249e-03 [1.206487e-07] 
Layer 'conv5' biases: 9.999987e-01 [1.310785e-07] 
Layer 'fc6' weights[0]: 7.584108e-03 [1.024877e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.038062e-08] 
Layer 'fc7' weights[0]: 7.403842e-03 [5.044298e-08] 
Layer 'fc7' biases: 9.998637e-01 [2.855988e-08] 
Layer 'fc8' weights[0]: 1.268147e-03 [2.685921e-06] 
Layer 'fc8' biases: 3.158384e-02 [1.916686e-05] 
Train error last 870 batches: 0.435271
-------------------------------------------------------
Not saving because 0.422829 > 0.415707 (12.630: -0.00%)
======================================================= (12.037 sec)
14.391... logprob:  0.318405, 0.070312 (1.445 sec)
14.392... logprob:  0.439420, 0.117188 (1.439 sec)
14.393... logprob:  0.368815, 0.093750 (1.489 sec)
14.394... logprob:  0.343438, 0.078125 (1.434 sec)
14.395... logprob:  0.331498, 0.078125 (1.434 sec)
14.396... logprob:  0.251717, 0.046875 (1.439 sec)
14.397... logprob:  0.484847, 0.132812 (1.430 sec)
14.398... logprob:  0.471579, 0.125000 (1.436 sec)
14.399... logprob:  0.433833, 0.117188 (1.486 sec)
14.400... logprob:  0.538787, 0.148438 (1.435 sec)
14.401... logprob:  0.466290, 0.125000 (1.445 sec)
14.402... logprob:  0.474353, 0.125000 (1.485 sec)
14.403... logprob:  0.462271, 0.125000 (1.432 sec)
14.404... logprob:  0.474828, 0.125000 (1.436 sec)
14.405... logprob:  0.543763, 0.156250 (1.439 sec)
14.406... logprob:  0.357981, 0.085938 (1.426 sec)
14.407... logprob:  0.492622, 0.140625 (1.439 sec)
14.408... logprob:  0.339927, 0.078125 (1.481 sec)
14.409... logprob:  0.401129, 0.101562 (1.443 sec)
14.410... logprob:  0.581633, 0.171875 (1.451 sec)
14.411... logprob:  0.398412, 0.101562 (1.480 sec)
14.412... logprob:  0.540187, 0.156250 (1.438 sec)
14.413... logprob:  0.544726, 0.156250 (1.439 sec)
14.414... logprob:  0.466678, 0.125000 (1.450 sec)
14.415... logprob:  0.401813, 0.101562 (1.424 sec)
14.416... logprob:  0.427575, 0.109375 (1.441 sec)
14.417... logprob:  0.405388, 0.093750 (1.464 sec)
14.418... logprob:  0.379990, 0.093750 (1.448 sec)
14.419... logprob:  0.417480, 0.101562 (1.454 sec)
14.420... logprob:  0.355743, 0.085938 (1.458 sec)
14.421... logprob:  0.376512, 0.101562 (1.455 sec)
14.422... logprob:  0.523369, 0.148438 (1.442 sec)
14.423... logprob:  0.421108, 0.109375 (1.426 sec)
14.424... logprob:  0.324539, 0.078125 (1.429 sec)
14.425... logprob:  0.306034, 0.070312 (1.434 sec)
14.426... logprob:  0.449536, 0.117188 (1.446 sec)
14.427... logprob:  0.555274, 0.156250 (1.466 sec)
14.428... logprob:  0.602508, 0.171875 (1.456 sec)
14.429... logprob:  0.426251, 0.109375 (1.442 sec)
14.430... logprob:  0.300031, 0.070312 (1.479 sec)
14.431... logprob:  0.599053, 0.171875 (1.431 sec)
14.432... logprob:  0.387640, 0.093750 (1.425 sec)
14.433... logprob:  0.330458, 0.078125 (1.431 sec)
14.434... logprob:  0.528949, 0.148438 (1.439 sec)
14.435... logprob:  0.531912, 0.156250 (1.439 sec)
14.436... logprob:  0.381790, 0.093750 (1.474 sec)
14.437... logprob:  0.500202, 0.140625 (1.450 sec)
14.438... logprob:  0.546717, 0.156250 (1.433 sec)
14.439... logprob:  0.379391, 0.093750 (1.492 sec)
14.440... logprob:  0.439948, 0.117188 (1.430 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.59109878540039, 10.0]}, 128)
batch 872: ({'logprob': [65.83564758300781, 19.0]}, 128)
batch 873: ({'logprob': [42.68012619018555, 9.0]}, 128)
batch 874: ({'logprob': [46.76544952392578, 11.0]}, 128)
batch 875: ({'logprob': [51.74799728393555, 13.0]}, 128)
batch 876: ({'logprob': [63.581642150878906, 18.0]}, 128)
batch 877: ({'logprob': [47.220375061035156, 11.0]}, 128)
batch 878: ({'logprob': [61.743690490722656, 17.0]}, 128)
batch 879: ({'logprob': [72.15911865234375, 21.0]}, 128)
batch 880: ({'logprob': [51.76288986206055, 13.0]}, 128)
batch 881: ({'logprob': [32.23569107055664, 5.0]}, 128)
batch 882: ({'logprob': [55.372398376464844, 14.0]}, 128)
batch 883: ({'logprob': [61.72909164428711, 17.0]}, 128)
batch 884: ({'logprob': [52.19203567504883, 13.0]}, 128)
batch 885: ({'logprob': [53.08867263793945, 13.0]}, 128)
batch 886: ({'logprob': [62.18364334106445, 17.0]}, 128)

======================Test output======================
logprob:  0.421821, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.970459e-03 [3.589818e-09] 
Layer 'conv1' biases: 1.303625e-07 [8.461711e-11] 
Layer 'conv2' weights[0]: 7.957454e-03 [2.777379e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.138968e-10] 
Layer 'conv3' weights[0]: 7.955789e-03 [2.700855e-09] 
Layer 'conv3' biases: 1.143558e-06 [1.628302e-09] 
Layer 'conv4' weights[0]: 7.988312e-03 [2.945934e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.594411e-08] 
Layer 'conv5' weights[0]: 7.987198e-03 [1.083496e-07] 
Layer 'conv5' biases: 9.999986e-01 [1.175668e-07] 
Layer 'fc6' weights[0]: 7.584069e-03 [9.267147e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.311533e-09] 
Layer 'fc7' weights[0]: 7.401939e-03 [5.035082e-08] 
Layer 'fc7' biases: 9.998639e-01 [2.854721e-08] 
Layer 'fc8' weights[0]: 1.267217e-03 [8.982436e-07] 
Layer 'fc8' biases: 3.199431e-02 [1.201170e-05] 
Train error last 870 batches: 0.435271
-------------------------------------------------------
Not saving because 0.421821 > 0.415707 (12.630: -0.00%)
======================================================= (12.071 sec)
14.441... logprob:  0.468070, 0.125000 (1.440 sec)
14.442... logprob:  0.378903, 0.093750 (1.436 sec)
14.443... logprob:  0.496596, 0.140625 (1.435 sec)
14.444... logprob:  0.371979, 0.093750 (1.432 sec)
14.445... logprob:  0.361996, 0.085938 (1.490 sec)
14.446... logprob:  0.398001, 0.101562 (1.441 sec)
14.447... logprob:  0.570676, 0.164062 (1.466 sec)
14.448... logprob:  0.332326, 0.078125 (1.481 sec)
14.449... logprob:  0.400023, 0.101562 (1.437 sec)
14.450... logprob:  0.238528, 0.046875 (1.434 sec)
14.451... logprob:  0.453213, 0.125000 (1.431 sec)
14.452... logprob:  0.456510, 0.117188 (1.429 sec)
14.453... logprob:  0.455662, 0.125000 (1.438 sec)
14.454... logprob:  0.489369, 0.132812 (1.481 sec)
14.455... logprob:  0.506161, 0.140625 (1.441 sec)
14.456... logprob:  0.468784, 0.125000 (1.447 sec)
14.457... logprob:  0.375416, 0.093750 (1.475 sec)
14.458... logprob:  0.351313, 0.085938 (1.437 sec)
14.459... logprob:  0.513508, 0.140625 (1.443 sec)
14.460... logprob:  0.274925, 0.054688 (1.431 sec)
14.461... logprob:  0.459934, 0.125000 (1.430 sec)
14.462... logprob:  0.471865, 0.125000 (1.437 sec)
14.463... logprob:  0.421005, 0.109375 (1.470 sec)
14.464... logprob:  0.482647, 0.132812 (1.452 sec)
14.465... logprob:  0.421259, 0.109375 (1.451 sec)
14.466... logprob:  0.318762, 0.070312 (1.464 sec)
14.467... logprob:  0.413884, 0.109375 (1.450 sec)
14.468... logprob:  0.394278, 0.101562 (1.442 sec)
14.469... logprob:  0.334593, 0.078125 (1.428 sec)
14.470... logprob:  0.400037, 0.101562 (1.430 sec)
14.471... logprob:  0.529789, 0.148438 (1.440 sec)
14.472... logprob:  0.410118, 0.109375 (1.455 sec)
14.473... logprob:  0.375296, 0.093750 (1.459 sec)
14.474... logprob:  0.465910, 0.125000 (1.456 sec)
14.475... logprob:  0.504600, 0.140625 (1.446 sec)
14.476... logprob:  0.510605, 0.140625 (1.472 sec)
14.477... logprob:  0.334460, 0.078125 (1.434 sec)
14.478... logprob:  0.464310, 0.125000 (1.419 sec)
14.479... logprob:  0.305812, 0.070312 (1.429 sec)
14.480... logprob:  0.443524, 0.117188 (1.435 sec)
14.481... logprob:  0.547708, 0.156250 (1.445 sec)
14.482... logprob:  0.443201, 0.117188 (1.472 sec)
14.483... logprob:  0.502527, 0.140625 (1.449 sec)
14.484... logprob:  0.485279, 0.132812 (1.436 sec)
14.485... logprob:  0.409151, 0.109375 (1.488 sec)
14.486... logprob:  0.361745, 0.085938 (1.436 sec)
14.487... logprob:  0.522589, 0.148438 (1.426 sec)
14.488... logprob:  0.424956, 0.109375 (1.466 sec)
14.489... logprob:  0.415997, 0.109375 (1.432 sec)
14.490... logprob:  0.440707, 0.117188 (1.439 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.598236083984375, 10.0]}, 128)
batch 872: ({'logprob': [66.17259216308594, 19.0]}, 128)
batch 873: ({'logprob': [41.33871078491211, 9.0]}, 128)
batch 874: ({'logprob': [45.83008575439453, 11.0]}, 128)
batch 875: ({'logprob': [51.100250244140625, 13.0]}, 128)
batch 876: ({'logprob': [63.74589538574219, 18.0]}, 128)
batch 877: ({'logprob': [46.22529220581055, 11.0]}, 128)
batch 878: ({'logprob': [61.6748046875, 17.0]}, 128)
batch 879: ({'logprob': [72.61016082763672, 21.0]}, 128)
batch 880: ({'logprob': [51.11590576171875, 13.0]}, 128)
batch 881: ({'logprob': [30.373489379882812, 5.0]}, 128)
batch 882: ({'logprob': [54.725276947021484, 14.0]}, 128)
batch 883: ({'logprob': [61.65987777709961, 17.0]}, 128)
batch 884: ({'logprob': [51.48822021484375, 13.0]}, 128)
batch 885: ({'logprob': [52.268707275390625, 13.0]}, 128)
batch 886: ({'logprob': [62.05760955810547, 17.0]}, 128)

======================Test output======================
logprob:  0.417473, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.970415e-03 [2.132144e-09] 
Layer 'conv1' biases: 1.310273e-07 [5.127046e-11] 
Layer 'conv2' weights[0]: 7.957417e-03 [1.827188e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.862999e-10] 
Layer 'conv3' weights[0]: 7.955748e-03 [1.749420e-09] 
Layer 'conv3' biases: 1.148840e-06 [9.013551e-10] 
Layer 'conv4' weights[0]: 7.988274e-03 [1.939405e-09] 
Layer 'conv4' biases: 9.999998e-01 [8.836690e-09] 
Layer 'conv5' weights[0]: 7.987157e-03 [6.004750e-08] 
Layer 'conv5' biases: 9.999985e-01 [6.513362e-08] 
Layer 'fc6' weights[0]: 7.584023e-03 [5.159694e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.185656e-09] 
Layer 'fc7' weights[0]: 7.400020e-03 [9.692854e-08] 
Layer 'fc7' biases: 9.998646e-01 [8.158432e-08] 
Layer 'fc8' weights[0]: 1.291477e-03 [2.987344e-06] 
Layer 'fc8' biases: 3.236816e-02 [2.107554e-05] 
Train error last 870 batches: 0.435271
-------------------------------------------------------
Not saving because 0.417473 > 0.415707 (12.630: -0.00%)
======================================================= (12.045 sec)
14.491... logprob:  0.313735, 0.070312 (1.486 sec)
14.492... logprob:  0.459639, 0.125000 (1.444 sec)
14.493... logprob:  0.522029, 0.148438 (1.433 sec)
14.494... logprob:  0.450395, 0.125000 (1.487 sec)
14.495... logprob:  0.380503, 0.093750 (1.432 sec)
14.496... logprob:  0.550646, 0.156250 (1.437 sec)
14.497... logprob:  0.467098, 0.125000 (1.433 sec)
14.498... logprob:  0.476392, 0.132812 (1.435 sec)
14.499... logprob:  0.456303, 0.125000 (1.429 sec)
14.500... logprob:  0.355051, 0.085938 (1.488 sec)
14.501... logprob:  0.339106, 0.078125 (1.429 sec)
14.502... logprob:  0.459687, 0.125000 (1.448 sec)
14.503... logprob:  0.400702, 0.101562 (1.486 sec)
14.504... logprob:  0.487362, 0.132812 (1.436 sec)
14.505... logprob:  0.570816, 0.164062 (1.436 sec)
14.506... logprob:  0.479680, 0.132812 (1.437 sec)
14.507... logprob:  0.385183, 0.093750 (1.426 sec)
14.508... logprob:  0.374801, 0.093750 (1.439 sec)
14.509... logprob:  0.323302, 0.070312 (1.477 sec)
14.510... logprob:  0.390500, 0.101562 (1.445 sec)
14.511... logprob:  0.410097, 0.109375 (1.451 sec)
14.512... logprob:  0.470759, 0.125000 (1.477 sec)
14.513... logprob:  0.324982, 0.078125 (1.527 sec)
14.514... logprob:  0.406280, 0.101562 (1.454 sec)
14.515... logprob:  0.455647, 0.125000 (1.431 sec)
14.516... logprob:  0.400471, 0.109375 (1.433 sec)
14.517... logprob:  0.628164, 0.179688 (1.441 sec)
14.518... logprob:  0.437746, 0.117188 (1.461 sec)
14.519... logprob:  0.516168, 0.140625 (1.451 sec)
14.520... logprob:  0.409661, 0.109375 (1.459 sec)
14.521... logprob:  0.427553, 0.109375 (1.468 sec)
14.522... logprob:  0.533046, 0.156250 (1.468 sec)
14.523... logprob:  0.331869, 0.078125 (1.434 sec)
14.524... logprob:  0.437270, 0.117188 (1.426 sec)
14.525... logprob:  0.426155, 0.109375 (1.438 sec)
14.526... logprob:  0.352061, 0.078125 (1.434 sec)
14.527... logprob:  0.504529, 0.140625 (1.445 sec)
14.528... logprob:  0.440538, 0.117188 (1.472 sec)
14.529... logprob:  0.353022, 0.085938 (1.449 sec)
14.530... logprob:  0.440247, 0.117188 (1.445 sec)
14.531... logprob:  0.440035, 0.117188 (1.477 sec)
14.532... logprob:  0.467434, 0.125000 (1.432 sec)
14.533... logprob:  0.560838, 0.164062 (1.426 sec)
14.534... logprob:  0.325737, 0.078125 (1.438 sec)
14.535... logprob:  0.551778, 0.156250 (1.439 sec)
14.536... logprob:  0.507456, 0.140625 (1.434 sec)
14.537... logprob:  0.510112, 0.140625 (1.479 sec)
14.538... logprob:  0.486125, 0.132812 (1.446 sec)
14.539... logprob:  0.296192, 0.062500 (1.433 sec)
14.540... logprob:  0.447184, 0.117188 (1.490 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.45094299316406, 10.0]}, 128)
batch 872: ({'logprob': [66.16283416748047, 19.0]}, 128)
batch 873: ({'logprob': [41.2824592590332, 9.0]}, 128)
batch 874: ({'logprob': [45.74614715576172, 11.0]}, 128)
batch 875: ({'logprob': [51.050228118896484, 13.0]}, 128)
batch 876: ({'logprob': [63.73476791381836, 18.0]}, 128)
batch 877: ({'logprob': [46.17212677001953, 11.0]}, 128)
batch 878: ({'logprob': [61.69288635253906, 17.0]}, 128)
batch 879: ({'logprob': [72.7269058227539, 21.0]}, 128)
batch 880: ({'logprob': [51.06594467163086, 13.0]}, 128)
batch 881: ({'logprob': [30.21841049194336, 5.0]}, 128)
batch 882: ({'logprob': [54.769569396972656, 14.0]}, 128)
batch 883: ({'logprob': [61.677799224853516, 17.0]}, 128)
batch 884: ({'logprob': [51.46923065185547, 13.0]}, 128)
batch 885: ({'logprob': [52.3115119934082, 13.0]}, 128)
batch 886: ({'logprob': [62.10667419433594, 17.0]}, 128)

======================Test output======================
logprob:  0.417304, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.970357e-03 [2.696515e-09] 
Layer 'conv1' biases: 1.317977e-07 [6.838990e-11] 
Layer 'conv2' weights[0]: 7.957377e-03 [1.807291e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.394726e-10] 
Layer 'conv3' weights[0]: 7.955710e-03 [1.809514e-09] 
Layer 'conv3' biases: 1.157318e-06 [1.013156e-09] 
Layer 'conv4' weights[0]: 7.988237e-03 [1.946516e-09] 
Layer 'conv4' biases: 9.999998e-01 [8.883186e-09] 
Layer 'conv5' weights[0]: 7.987116e-03 [5.577924e-08] 
Layer 'conv5' biases: 9.999984e-01 [6.038891e-08] 
Layer 'fc6' weights[0]: 7.583982e-03 [4.881386e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.857322e-09] 
Layer 'fc7' weights[0]: 7.398142e-03 [5.054635e-08] 
Layer 'fc7' biases: 9.998647e-01 [2.897168e-08] 
Layer 'fc8' weights[0]: 1.293541e-03 [4.320482e-06] 
Layer 'fc8' biases: 3.246803e-02 [2.754677e-05] 
Train error last 870 batches: 0.435270
-------------------------------------------------------
Not saving because 0.417304 > 0.415707 (12.630: -0.00%)
======================================================= (12.015 sec)
14.541... logprob:  0.388930, 0.101562 (1.440 sec)
14.542... logprob:  0.411346, 0.109375 (1.438 sec)
14.543... logprob:  0.233472, 0.039062 (1.434 sec)
14.544... logprob:  0.317961, 0.070312 (1.434 sec)
14.545... logprob:  0.348817, 0.085938 (1.435 sec)
14.546... logprob:  0.368295, 0.093750 (1.485 sec)
14.547... logprob:  0.440192, 0.117188 (1.439 sec)
14.548... logprob:  0.453302, 0.125000 (1.446 sec)
14.549... logprob:  0.490829, 0.132812 (1.478 sec)
14.550... logprob:  0.367725, 0.093750 (1.435 sec)
14.551... logprob:  0.441862, 0.117188 (1.440 sec)
14.552... logprob:  0.471372, 0.125000 (1.435 sec)
14.553... logprob:  0.349431, 0.085938 (1.426 sec)
14.554... logprob:  0.506800, 0.140625 (1.467 sec)
14.555... logprob:  0.421416, 0.109375 (1.486 sec)
14.556... logprob:  0.355984, 0.085938 (1.443 sec)
14.557... logprob:  0.396532, 0.101562 (1.446 sec)
14.558... logprob:  0.383095, 0.101562 (1.469 sec)
14.559... logprob:  0.441404, 0.125000 (1.434 sec)
14.560... logprob:  0.335449, 0.078125 (1.446 sec)
14.561... logprob:  0.411868, 0.109375 (1.427 sec)
14.562... logprob:  0.503107, 0.140625 (1.425 sec)
14.563... logprob:  0.373899, 0.093750 (1.436 sec)
14.564... logprob:  0.468410, 0.132812 (1.464 sec)
14.565... logprob:  0.611009, 0.187500 (1.455 sec)
14.566... logprob:  0.374934, 0.093750 (1.451 sec)
14.567... logprob:  0.423489, 0.109375 (1.471 sec)
14.568... logprob:  0.496400, 0.140625 (1.458 sec)
14.569... logprob:  0.507910, 0.140625 (1.439 sec)
14.570... logprob:  0.543714, 0.164062 (1.426 sec)
14.571... logprob:  0.454873, 0.125000 (1.434 sec)
14.572... logprob:  0.501522, 0.140625 (1.439 sec)
14.573... logprob:  0.512646, 0.148438 (1.443 sec)
14.574... logprob:  0.428190, 0.109375 (1.459 sec)
14.575... logprob:  0.343378, 0.078125 (1.456 sec)
14.576... logprob:  0.427430, 0.109375 (1.448 sec)
14.577... logprob:  0.460866, 0.125000 (1.474 sec)
14.578... logprob:  0.336527, 0.078125 (1.437 sec)
14.579... logprob:  0.442093, 0.117188 (1.426 sec)
14.580... logprob:  0.547055, 0.156250 (1.432 sec)
14.581... logprob:  0.531136, 0.156250 (1.444 sec)
14.582... logprob:  0.437937, 0.125000 (1.436 sec)
14.583... logprob:  0.593009, 0.171875 (1.473 sec)
14.584... logprob:  0.468149, 0.132812 (1.451 sec)
14.585... logprob:  0.349770, 0.085938 (1.431 sec)
14.586... logprob:  0.313189, 0.070312 (1.487 sec)
14.587... logprob:  0.404324, 0.101562 (1.429 sec)
14.588... logprob:  0.418680, 0.117188 (1.430 sec)
14.589... logprob:  0.361351, 0.093750 (1.441 sec)
14.590... logprob:  0.524678, 0.148438 (1.435 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.20343017578125, 10.0]}, 128)
batch 872: ({'logprob': [66.44815826416016, 19.0]}, 128)
batch 873: ({'logprob': [41.032344818115234, 9.0]}, 128)
batch 874: ({'logprob': [45.196353912353516, 11.0]}, 128)
batch 875: ({'logprob': [50.87885665893555, 13.0]}, 128)
batch 876: ({'logprob': [64.00028991699219, 18.0]}, 128)
batch 877: ({'logprob': [45.96003723144531, 11.0]}, 128)
batch 878: ({'logprob': [62.27760696411133, 17.0]}, 128)
batch 879: ({'logprob': [74.40510559082031, 21.0]}, 128)
batch 880: ({'logprob': [50.89361572265625, 13.0]}, 128)
batch 881: ({'logprob': [28.872812271118164, 5.0]}, 128)
batch 882: ({'logprob': [55.6348762512207, 14.0]}, 128)
batch 883: ({'logprob': [62.26274490356445, 17.0]}, 128)
batch 884: ({'logprob': [51.63774871826172, 13.0]}, 128)
batch 885: ({'logprob': [53.158267974853516, 13.0]}, 128)
batch 886: ({'logprob': [63.03104019165039, 17.0]}, 128)

======================Test output======================
logprob:  0.418405, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.970313e-03 [2.691288e-09] 
Layer 'conv1' biases: 1.326155e-07 [5.778304e-11] 
Layer 'conv2' weights[0]: 7.957331e-03 [2.099741e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.881342e-10] 
Layer 'conv3' weights[0]: 7.955667e-03 [1.708837e-09] 
Layer 'conv3' biases: 1.162563e-06 [8.344892e-10] 
Layer 'conv4' weights[0]: 7.988198e-03 [1.734796e-09] 
Layer 'conv4' biases: 9.999998e-01 [6.335918e-09] 
Layer 'conv5' weights[0]: 7.987090e-03 [4.184524e-08] 
Layer 'conv5' biases: 9.999979e-01 [4.520472e-08] 
Layer 'fc6' weights[0]: 7.583945e-03 [3.692452e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.667970e-09] 
Layer 'fc7' weights[0]: 7.396240e-03 [6.502125e-08] 
Layer 'fc7' biases: 9.998657e-01 [4.678419e-08] 
Layer 'fc8' weights[0]: 1.321584e-03 [2.492350e-06] 
Layer 'fc8' biases: 3.278092e-02 [1.606050e-05] 
Train error last 870 batches: 0.435270
-------------------------------------------------------
Not saving because 0.418405 > 0.415707 (12.630: -0.00%)
======================================================= (12.041 sec)
14.591... logprob:  0.397537, 0.101562 (1.434 sec)
14.592... logprob:  0.455638, 0.125000 (1.487 sec)
14.593... logprob:  0.467448, 0.125000 (1.431 sec)
14.594... logprob:  0.352890, 0.085938 (1.439 sec)
14.595... logprob:  0.428676, 0.109375 (1.481 sec)
14.596... logprob:  0.461574, 0.125000 (1.436 sec)
14.597... logprob:  0.397411, 0.101562 (1.431 sec)
14.598... logprob:  0.397235, 0.101562 (1.440 sec)
14.599... logprob:  0.313487, 0.070312 (1.429 sec)
14.600... logprob:  0.340901, 0.085938 (1.438 sec)
14.601... logprob:  0.402116, 0.101562 (1.486 sec)
14.602... logprob:  0.289628, 0.062500 (1.432 sec)
14.603... logprob:  0.266865, 0.054688 (1.445 sec)
14.604... logprob:  0.407513, 0.101562 (1.474 sec)
14.605... logprob:  0.563689, 0.148438 (1.441 sec)
14.606... logprob:  0.295950, 0.070312 (1.437 sec)
14.607... logprob:  0.504997, 0.132812 (1.437 sec)
14.608... logprob:  0.361639, 0.085938 (1.423 sec)
14.609... logprob:  0.356897, 0.085938 (1.438 sec)
14.610... logprob:  0.493471, 0.132812 (1.475 sec)
14.611... logprob:  0.510460, 0.140625 (1.445 sec)
14.612... logprob:  0.448358, 0.117188 (1.459 sec)
14.613... logprob:  0.279916, 0.062500 (1.465 sec)
14.614... logprob:  0.503499, 0.140625 (1.448 sec)
14.615... logprob:  0.351267, 0.085938 (1.435 sec)
14.616... logprob:  0.415423, 0.109375 (1.425 sec)
14.617... logprob:  0.418013, 0.109375 (1.435 sec)
14.618... logprob:  0.546610, 0.156250 (1.442 sec)
14.619... logprob:  0.505905, 0.140625 (1.451 sec)
14.620... logprob:  0.539600, 0.156250 (1.464 sec)
14.621... logprob:  0.364017, 0.085938 (1.452 sec)
14.622... logprob:  0.365017, 0.085938 (1.451 sec)
14.623... logprob:  0.423243, 0.109375 (1.470 sec)
14.624... logprob:  0.382563, 0.093750 (1.433 sec)
14.625... logprob:  0.441012, 0.117188 (1.425 sec)
14.626... logprob:  0.438407, 0.117188 (1.432 sec)
14.627... logprob:  0.435873, 0.117188 (1.439 sec)
14.628... logprob:  0.465122, 0.125000 (1.455 sec)
14.629... logprob:  0.371950, 0.093750 (1.472 sec)
14.630... logprob:  0.422373, 0.109375 (1.455 sec)
14.631... logprob:  0.639610, 0.187500 (1.436 sec)
14.632... logprob:  0.399096, 0.101562 (1.477 sec)
14.633... logprob:  0.376000, 0.093750 (1.435 sec)
14.634... logprob:  0.660570, 0.195312 (1.429 sec)
14.635... logprob:  0.374129, 0.093750 (1.437 sec)
14.636... logprob:  0.480222, 0.132812 (1.433 sec)
14.637... logprob:  0.331017, 0.078125 (1.439 sec)
14.638... logprob:  0.515653, 0.140625 (1.480 sec)
14.639... logprob:  0.418198, 0.109375 (1.446 sec)
14.640... logprob:  0.528746, 0.148438 (1.431 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.73930358886719, 10.0]}, 128)
batch 872: ({'logprob': [66.22315979003906, 19.0]}, 128)
batch 873: ({'logprob': [41.345741271972656, 9.0]}, 128)
batch 874: ({'logprob': [45.89605712890625, 11.0]}, 128)
batch 875: ({'logprob': [51.14122772216797, 13.0]}, 128)
batch 876: ({'logprob': [63.788360595703125, 18.0]}, 128)
batch 877: ({'logprob': [46.24955749511719, 11.0]}, 128)
batch 878: ({'logprob': [61.666603088378906, 17.0]}, 128)
batch 879: ({'logprob': [72.5107192993164, 21.0]}, 128)
batch 880: ({'logprob': [51.15724563598633, 13.0]}, 128)
batch 881: ({'logprob': [30.47173309326172, 5.0]}, 128)
batch 882: ({'logprob': [54.64946746826172, 14.0]}, 128)
batch 883: ({'logprob': [61.65128707885742, 17.0]}, 128)
batch 884: ({'logprob': [51.487483978271484, 13.0]}, 128)
batch 885: ({'logprob': [52.18412399291992, 13.0]}, 128)
batch 886: ({'logprob': [62.00751495361328, 17.0]}, 128)

======================Test output======================
logprob:  0.417563, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.970288e-03 [3.186537e-09] 
Layer 'conv1' biases: 1.333927e-07 [5.578574e-11] 
Layer 'conv2' weights[0]: 7.957291e-03 [2.100525e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.590154e-10] 
Layer 'conv3' weights[0]: 7.955631e-03 [1.603669e-09] 
Layer 'conv3' biases: 1.170412e-06 [8.500229e-10] 
Layer 'conv4' weights[0]: 7.988159e-03 [1.700875e-09] 
Layer 'conv4' biases: 9.999998e-01 [6.369397e-09] 
Layer 'conv5' weights[0]: 7.987034e-03 [4.345620e-08] 
Layer 'conv5' biases: 9.999985e-01 [4.715856e-08] 
Layer 'fc6' weights[0]: 7.583903e-03 [3.748355e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.726142e-09] 
Layer 'fc7' weights[0]: 7.394409e-03 [1.302707e-07] 
Layer 'fc7' biases: 9.998643e-01 [1.177613e-07] 
Layer 'fc8' weights[0]: 1.293792e-03 [4.261416e-06] 
Layer 'fc8' biases: 3.276332e-02 [2.559026e-05] 
Train error last 870 batches: 0.435269
-------------------------------------------------------
Not saving because 0.417563 > 0.415707 (12.630: -0.00%)
======================================================= (12.029 sec)
14.641... logprob:  0.410516, 0.109375 (1.496 sec)
14.642... logprob:  0.500793, 0.140625 (1.432 sec)
14.643... logprob:  0.622722, 0.187500 (1.433 sec)
14.644... logprob:  0.321548, 0.070312 (1.437 sec)
14.645... logprob:  0.414524, 0.109375 (1.432 sec)
14.646... logprob:  0.385803, 0.093750 (1.435 sec)
14.647... logprob:  0.456740, 0.125000 (1.488 sec)
14.648... logprob:  0.491225, 0.140625 (1.435 sec)
14.649... logprob:  0.370053, 0.093750 (1.446 sec)
14.650... logprob:  0.413910, 0.109375 (1.475 sec)
14.651... logprob:  0.397275, 0.101562 (1.436 sec)
14.652... logprob:  0.507491, 0.140625 (1.441 sec)
14.653... logprob:  0.548262, 0.156250 (1.435 sec)
14.654... logprob:  0.496196, 0.140625 (1.428 sec)
14.655... logprob:  0.436222, 0.117188 (1.436 sec)
14.656... logprob:  0.416665, 0.109375 (1.492 sec)
14.657... logprob:  0.449332, 0.117188 (1.436 sec)
14.658... logprob:  0.345739, 0.085938 (1.445 sec)
14.659... logprob:  0.464371, 0.125000 (1.472 sec)
14.660... logprob:  0.445877, 0.125000 (1.442 sec)
14.661... logprob:  0.378585, 0.093750 (1.469 sec)
14.662... logprob:  0.469310, 0.132812 (1.429 sec)
14.663... logprob:  0.311105, 0.070312 (1.430 sec)
14.664... logprob:  0.285557, 0.062500 (1.438 sec)
14.665... logprob:  0.401893, 0.101562 (1.461 sec)
14.666... logprob:  0.442078, 0.117188 (1.451 sec)
14.667... logprob:  0.564345, 0.164062 (1.457 sec)
14.668... logprob:  0.497941, 0.140625 (1.452 sec)
14.669... logprob:  0.433138, 0.109375 (1.463 sec)
14.670... logprob:  0.362518, 0.085938 (1.444 sec)
14.671... logprob:  0.360853, 0.093750 (1.424 sec)
14.672... logprob:  0.441808, 0.117188 (1.434 sec)
14.673... logprob:  0.436251, 0.117188 (1.440 sec)
14.674... logprob:  0.446675, 0.117188 (1.445 sec)
14.675... logprob:  0.356665, 0.093750 (1.465 sec)
14.676... logprob:  0.450142, 0.125000 (1.452 sec)
14.677... logprob:  0.471068, 0.125000 (1.443 sec)
14.678... logprob:  0.465638, 0.125000 (1.485 sec)
14.679... logprob:  0.454878, 0.125000 (1.431 sec)
14.680... logprob:  0.351755, 0.078125 (1.436 sec)
14.681... logprob:  0.373967, 0.093750 (1.436 sec)
14.682... logprob:  0.340516, 0.078125 (1.433 sec)
14.683... logprob:  0.411653, 0.109375 (1.431 sec)
14.684... logprob:  0.357575, 0.085938 (1.480 sec)
14.685... logprob:  0.285774, 0.054688 (1.448 sec)
14.686... logprob:  0.318447, 0.070312 (1.437 sec)
14.687... logprob:  0.281443, 0.062500 (1.486 sec)
14.688... logprob:  0.323065, 0.078125 (1.431 sec)
14.689... logprob:  0.471700, 0.125000 (1.432 sec)
14.690... logprob:  0.528310, 0.140625 (1.437 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.899715423583984, 10.0]}, 128)
batch 872: ({'logprob': [69.6717529296875, 19.0]}, 128)
batch 873: ({'logprob': [39.31043243408203, 9.0]}, 128)
batch 874: ({'logprob': [44.82193374633789, 11.0]}, 128)
batch 875: ({'logprob': [51.25138854980469, 13.0]}, 128)
batch 876: ({'logprob': [66.70231628417969, 18.0]}, 128)
batch 877: ({'logprob': [45.28474426269531, 11.0]}, 128)
batch 878: ({'logprob': [64.15367889404297, 17.0]}, 128)
batch 879: ({'logprob': [77.48570251464844, 21.0]}, 128)
batch 880: ({'logprob': [51.268672943115234, 13.0]}, 128)
batch 881: ({'logprob': [25.94451332092285, 5.0]}, 128)
batch 882: ({'logprob': [55.642398834228516, 14.0]}, 128)
batch 883: ({'logprob': [64.13794708251953, 17.0]}, 128)
batch 884: ({'logprob': [51.7174072265625, 13.0]}, 128)
batch 885: ({'logprob': [52.64253234863281, 13.0]}, 128)
batch 886: ({'logprob': [64.6116714477539, 17.0]}, 128)

======================Test output======================
logprob:  0.422630, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.970244e-03 [4.522388e-09] 
Layer 'conv1' biases: 1.339172e-07 [1.627036e-10] 
Layer 'conv2' weights[0]: 7.957250e-03 [3.886995e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.874154e-10] 
Layer 'conv3' weights[0]: 7.955590e-03 [4.211244e-09] 
Layer 'conv3' biases: 1.172997e-06 [2.789111e-09] 
Layer 'conv4' weights[0]: 7.988110e-03 [4.533956e-09] 
Layer 'conv4' biases: 9.999998e-01 [2.667928e-08] 
Layer 'conv5' weights[0]: 7.987003e-03 [1.797396e-07] 
Layer 'conv5' biases: 9.999976e-01 [1.945727e-07] 
Layer 'fc6' weights[0]: 7.583866e-03 [1.556954e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.583757e-08] 
Layer 'fc7' weights[0]: 7.392448e-03 [5.116688e-08] 
Layer 'fc7' biases: 9.998671e-01 [2.937498e-08] 
Layer 'fc8' weights[0]: 1.399308e-03 [7.424730e-06] 
Layer 'fc8' biases: 3.352488e-02 [4.872804e-05] 
Train error last 870 batches: 0.435269
-------------------------------------------------------
Not saving because 0.422630 > 0.415707 (12.630: -0.00%)
======================================================= (12.068 sec)
14.691... logprob:  0.517315, 0.140625 (1.445 sec)
14.692... logprob:  0.385467, 0.101562 (1.437 sec)
14.693... logprob:  0.456174, 0.125000 (1.481 sec)
14.694... logprob:  0.330877, 0.078125 (1.462 sec)
14.695... logprob:  0.356879, 0.085938 (1.443 sec)
14.696... logprob:  0.538651, 0.148438 (1.483 sec)
14.697... logprob:  0.465530, 0.125000 (1.432 sec)
14.698... logprob:  0.548377, 0.156250 (1.434 sec)
14.699... logprob:  0.459572, 0.125000 (1.433 sec)
14.700... logprob:  0.434107, 0.117188 (1.427 sec)
14.701... logprob:  0.423477, 0.109375 (1.439 sec)
14.702... logprob:  0.521419, 0.148438 (1.480 sec)
14.703... logprob:  0.405695, 0.101562 (1.435 sec)
14.704... logprob:  0.406452, 0.101562 (1.450 sec)
14.705... logprob:  0.420363, 0.109375 (1.479 sec)
14.706... logprob:  0.468086, 0.125000 (1.433 sec)
14.707... logprob:  0.485300, 0.132812 (1.438 sec)
14.708... logprob:  0.416990, 0.109375 (1.436 sec)
14.709... logprob:  0.422371, 0.109375 (1.425 sec)
14.710... logprob:  0.603008, 0.179688 (1.440 sec)
14.711... logprob:  0.469554, 0.125000 (1.467 sec)
14.712... logprob:  0.340160, 0.078125 (1.450 sec)
14.713... logprob:  0.587617, 0.179688 (1.457 sec)
14.714... logprob:  0.466367, 0.125000 (1.460 sec)
14.715... logprob:  0.417122, 0.109375 (1.454 sec)
14.716... logprob:  0.335180, 0.078125 (1.436 sec)
14.717... logprob:  0.429855, 0.117188 (1.423 sec)
14.718... logprob:  0.490404, 0.132812 (1.426 sec)
14.719... logprob:  0.406208, 0.109375 (1.442 sec)
14.720... logprob:  0.433242, 0.117188 (1.445 sec)
14.721... logprob:  0.451598, 0.117188 (1.463 sec)
14.722... logprob:  0.536782, 0.156250 (1.458 sec)
14.723... logprob:  0.416623, 0.109375 (1.449 sec)
14.724... logprob:  0.412789, 0.109375 (1.470 sec)
14.725... logprob:  0.494599, 0.140625 (1.441 sec)
14.726... logprob:  0.338765, 0.085938 (1.428 sec)
14.727... logprob:  0.393434, 0.101562 (1.434 sec)
14.728... logprob:  0.421413, 0.109375 (1.437 sec)
14.729... logprob:  0.387865, 0.093750 (1.428 sec)
14.730... logprob:  0.565809, 0.164062 (1.481 sec)
14.731... logprob:  0.450307, 0.125000 (1.446 sec)
14.732... logprob:  0.311503, 0.070312 (1.434 sec)
14.733... logprob:  0.556761, 0.156250 (1.490 sec)
14.734... logprob:  0.340211, 0.078125 (1.434 sec)
14.735... logprob:  0.527687, 0.148438 (1.450 sec)
14.736... logprob:  0.643181, 0.187500 (1.436 sec)
14.737... logprob:  0.516241, 0.148438 (1.433 sec)
14.738... logprob:  0.459446, 0.125000 (1.433 sec)
14.739... logprob:  0.477824, 0.132812 (1.485 sec)
14.740... logprob:  0.339669, 0.078125 (1.435 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.95875930786133, 10.0]}, 128)
batch 872: ({'logprob': [65.74876403808594, 19.0]}, 128)
batch 873: ({'logprob': [42.39280319213867, 9.0]}, 128)
batch 874: ({'logprob': [46.37696838378906, 11.0]}, 128)
batch 875: ({'logprob': [51.493682861328125, 13.0]}, 128)
batch 876: ({'logprob': [63.4868049621582, 18.0]}, 128)
batch 877: ({'logprob': [46.9492073059082, 11.0]}, 128)
batch 878: ({'logprob': [61.7581672668457, 17.0]}, 128)
batch 879: ({'logprob': [72.55899810791016, 21.0]}, 128)
batch 880: ({'logprob': [51.508445739746094, 13.0]}, 128)
batch 881: ({'logprob': [31.561979293823242, 5.0]}, 128)
batch 882: ({'logprob': [55.479896545410156, 14.0]}, 128)
batch 883: ({'logprob': [61.743289947509766, 17.0]}, 128)
batch 884: ({'logprob': [52.05598449707031, 13.0]}, 128)
batch 885: ({'logprob': [53.18821334838867, 13.0]}, 128)
batch 886: ({'logprob': [62.31608581542969, 17.0]}, 128)

======================Test output======================
logprob:  0.420692, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.970199e-03 [2.714688e-09] 
Layer 'conv1' biases: 1.349642e-07 [7.669149e-11] 
Layer 'conv2' weights[0]: 7.957211e-03 [2.967487e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.053749e-10] 
Layer 'conv3' weights[0]: 7.955561e-03 [2.835439e-09] 
Layer 'conv3' biases: 1.183085e-06 [1.651188e-09] 
Layer 'conv4' weights[0]: 7.988078e-03 [3.170470e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.597502e-08] 
Layer 'conv5' weights[0]: 7.986958e-03 [1.076078e-07] 
Layer 'conv5' biases: 9.999984e-01 [1.164180e-07] 
Layer 'fc6' weights[0]: 7.583827e-03 [9.216012e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.260245e-09] 
Layer 'fc7' weights[0]: 7.390622e-03 [7.213549e-08] 
Layer 'fc7' biases: 9.998642e-01 [5.619598e-08] 
Layer 'fc8' weights[0]: 1.278542e-03 [2.880124e-06] 
Layer 'fc8' biases: 3.293578e-02 [1.721448e-05] 
Train error last 870 batches: 0.435269
-------------------------------------------------------
Not saving because 0.420692 > 0.415707 (12.630: -0.00%)
======================================================= (12.078 sec)
14.741... logprob:  0.393449, 0.101562 (1.452 sec)
14.742... logprob:  0.419759, 0.109375 (1.482 sec)
14.743... logprob:  0.364873, 0.085938 (1.432 sec)
14.744... logprob:  0.519282, 0.148438 (1.436 sec)
14.745... logprob:  0.478193, 0.132812 (1.436 sec)
14.746... logprob:  0.440566, 0.117188 (1.432 sec)
14.747... logprob:  0.425639, 0.109375 (1.434 sec)
14.748... logprob:  0.378033, 0.093750 (1.491 sec)
14.749... logprob:  0.420858, 0.109375 (1.431 sec)
14.750... logprob:  0.512959, 0.140625 (1.443 sec)
14.751... logprob:  0.263493, 0.054688 (1.472 sec)
14.752... logprob:  0.522522, 0.140625 (1.508 sec)
14.753... logprob:  0.441280, 0.117188 (1.436 sec)
14.754... logprob:  0.468637, 0.132812 (1.432 sec)
14.755... logprob:  0.507136, 0.140625 (1.423 sec)
14.756... logprob:  0.440823, 0.117188 (1.440 sec)
14.757... logprob:  0.552249, 0.156250 (1.471 sec)
14.758... logprob:  0.393748, 0.101562 (1.447 sec)
14.759... logprob:  0.459691, 0.125000 (1.457 sec)
14.760... logprob:  0.485381, 0.132812 (1.460 sec)
14.761... logprob:  0.418454, 0.109375 (1.452 sec)
14.762... logprob:  0.515963, 0.148438 (1.443 sec)
14.763... logprob:  0.558735, 0.164062 (1.430 sec)
14.764... logprob:  0.503297, 0.140625 (1.426 sec)
14.765... logprob:  0.312401, 0.062500 (1.437 sec)
14.766... logprob:  0.482318, 0.132812 (1.459 sec)
14.767... logprob:  0.371193, 0.085938 (1.459 sec)
14.768... logprob:  0.432720, 0.117188 (1.489 sec)
14.769... logprob:  0.490928, 0.140625 (1.471 sec)
14.770... logprob:  0.402781, 0.101562 (1.482 sec)
14.771... logprob:  0.549760, 0.156250 (1.459 sec)
14.772... logprob:  0.414018, 0.109375 (1.443 sec)
14.773... logprob:  0.558293, 0.164062 (1.441 sec)
14.774... logprob:  0.361462, 0.085938 (1.466 sec)
14.775... logprob:  0.407307, 0.101562 (1.462 sec)
14.776... logprob:  0.433269, 0.117188 (1.483 sec)
14.777... logprob:  0.379908, 0.093750 (1.473 sec)
14.778... logprob:  0.433644, 0.117188 (1.466 sec)
14.779... logprob:  0.505515, 0.140625 (1.486 sec)
14.780... logprob:  0.385757, 0.101562 (1.451 sec)
14.781... logprob:  0.369757, 0.085938 (1.452 sec)
14.782... logprob:  0.351538, 0.085938 (1.445 sec)
14.783... logprob:  0.555444, 0.156250 (1.465 sec)
14.784... logprob:  0.440958, 0.117188 (1.456 sec)
14.785... logprob:  0.543467, 0.156250 (1.500 sec)
14.786... logprob:  0.477354, 0.132812 (1.468 sec)
14.787... logprob:  0.546095, 0.156250 (1.462 sec)
14.788... logprob:  0.562787, 0.164062 (1.498 sec)
14.789... logprob:  0.281672, 0.054688 (1.451 sec)
14.790... logprob:  0.408433, 0.101562 (1.451 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.07472229003906, 10.0]}, 128)
batch 872: ({'logprob': [65.90284729003906, 19.0]}, 128)
batch 873: ({'logprob': [42.09248352050781, 9.0]}, 128)
batch 874: ({'logprob': [46.31126022338867, 11.0]}, 128)
batch 875: ({'logprob': [51.42262268066406, 13.0]}, 128)
batch 876: ({'logprob': [63.58400344848633, 18.0]}, 128)
batch 877: ({'logprob': [46.7637939453125, 11.0]}, 128)
batch 878: ({'logprob': [61.67795944213867, 17.0]}, 128)
batch 879: ({'logprob': [72.35025024414062, 21.0]}, 128)
batch 880: ({'logprob': [51.437992095947266, 13.0]}, 128)
batch 881: ({'logprob': [31.39049530029297, 5.0]}, 128)
batch 882: ({'logprob': [55.108055114746094, 14.0]}, 128)
batch 883: ({'logprob': [61.66279602050781, 17.0]}, 128)
batch 884: ({'logprob': [51.86589813232422, 13.0]}, 128)
batch 885: ({'logprob': [52.75891876220703, 13.0]}, 128)
batch 886: ({'logprob': [62.11649703979492, 17.0]}, 128)

======================Test output======================
logprob:  0.419688, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.970160e-03 [2.838050e-09] 
Layer 'conv1' biases: 1.356968e-07 [9.453832e-11] 
Layer 'conv2' weights[0]: 7.957168e-03 [2.934895e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.470965e-10] 
Layer 'conv3' weights[0]: 7.955514e-03 [2.868885e-09] 
Layer 'conv3' biases: 1.190218e-06 [1.760837e-09] 
Layer 'conv4' weights[0]: 7.988039e-03 [3.061099e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.618218e-08] 
Layer 'conv5' weights[0]: 7.986920e-03 [1.070380e-07] 
Layer 'conv5' biases: 9.999985e-01 [1.156449e-07] 
Layer 'fc6' weights[0]: 7.583782e-03 [9.155865e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.217780e-09] 
Layer 'fc7' weights[0]: 7.388745e-03 [8.424971e-08] 
Layer 'fc7' biases: 9.998642e-01 [6.943599e-08] 
Layer 'fc8' weights[0]: 1.279020e-03 [2.638816e-06] 
Layer 'fc8' biases: 3.308543e-02 [1.322955e-05] 
Train error last 870 batches: 0.435268
-------------------------------------------------------
Not saving because 0.419688 > 0.415707 (12.630: -0.00%)
======================================================= (12.086 sec)
14.791... logprob:  0.398241, 0.101562 (1.460 sec)
14.792... logprob:  0.361349, 0.085938 (1.460 sec)
14.793... logprob:  0.370341, 0.085938 (1.452 sec)
14.794... logprob:  0.387123, 0.093750 (1.483 sec)
14.795... logprob:  0.469857, 0.125000 (1.467 sec)
14.796... logprob:  0.423499, 0.109375 (1.454 sec)
14.797... logprob:  0.358653, 0.085938 (1.497 sec)
14.798... logprob:  0.393260, 0.101562 (1.457 sec)
14.799... logprob:  0.332091, 0.078125 (1.446 sec)
14.800... logprob:  0.371813, 0.093750 (1.445 sec)
14.801... logprob:  0.450451, 0.117188 (1.459 sec)
14.802... logprob:  0.423234, 0.109375 (1.449 sec)
14.803... logprob:  0.492166, 0.132812 (1.496 sec)
14.804... logprob:  0.349996, 0.085938 (1.465 sec)
14.805... logprob:  0.452302, 0.117188 (1.451 sec)
14.806... logprob:  0.424188, 0.109375 (1.503 sec)
14.807... logprob:  0.443441, 0.117188 (1.456 sec)
14.808... logprob:  0.462325, 0.125000 (1.454 sec)
14.809... logprob:  0.589345, 0.171875 (1.449 sec)
14.810... logprob:  0.442432, 0.117188 (1.456 sec)
14.811... logprob:  0.460422, 0.125000 (1.454 sec)
14.812... logprob:  0.462456, 0.125000 (1.496 sec)
14.813... logprob:  0.486005, 0.132812 (1.465 sec)
14.814... logprob:  0.478215, 0.132812 (1.453 sec)
14.815... logprob:  0.372581, 0.085938 (1.498 sec)
14.816... logprob:  0.409131, 0.101562 (1.452 sec)
14.817... logprob:  0.426219, 0.109375 (1.457 sec)
14.818... logprob:  0.559963, 0.164062 (1.445 sec)
14.819... logprob:  0.498226, 0.140625 (1.450 sec)
14.820... logprob:  0.421510, 0.109375 (1.455 sec)
14.821... logprob:  0.406356, 0.101562 (1.498 sec)
14.822... logprob:  0.441042, 0.117188 (1.458 sec)
14.823... logprob:  0.340280, 0.078125 (1.221 sec)
14.824... logprob:  0.490109, 0.132812 (0.713 sec)
14.825... logprob:  0.287284, 0.062500 (0.684 sec)
14.826... logprob:  0.375299, 0.093750 (0.689 sec)
14.827... logprob:  0.420700, 0.109375 (0.690 sec)
14.828... logprob:  0.443751, 0.117188 (0.687 sec)
14.829... logprob:  0.504893, 0.140625 (0.690 sec)
14.830... logprob:  0.442438, 0.117188 (1.507 sec)
14.831... logprob:  0.514205, 0.140625 (1.455 sec)
14.832... logprob:  0.330871, 0.078125 (1.457 sec)
14.833... logprob:  0.488918, 0.132812 (1.492 sec)
14.834... logprob:  0.433142, 0.117188 (1.453 sec)
14.835... logprob:  0.542352, 0.148438 (1.458 sec)
14.836... logprob:  0.376421, 0.093750 (1.449 sec)
14.837... logprob:  0.315027, 0.070312 (1.456 sec)
14.838... logprob:  0.437106, 0.117188 (1.453 sec)
14.839... logprob:  0.471760, 0.125000 (1.504 sec)
14.840... logprob:  0.555167, 0.156250 (1.451 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.66132736206055, 10.0]}, 128)
batch 872: ({'logprob': [66.1930160522461, 19.0]}, 128)
batch 873: ({'logprob': [41.342918395996094, 9.0]}, 128)
batch 874: ({'logprob': [45.85973358154297, 11.0]}, 128)
batch 875: ({'logprob': [51.118247985839844, 13.0]}, 128)
batch 876: ({'logprob': [63.763328552246094, 18.0]}, 128)
batch 877: ({'logprob': [46.23652267456055, 11.0]}, 128)
batch 878: ({'logprob': [61.66996765136719, 17.0]}, 128)
batch 879: ({'logprob': [72.56379699707031, 21.0]}, 128)
batch 880: ({'logprob': [51.13406753540039, 13.0]}, 128)
batch 881: ({'logprob': [30.419078826904297, 5.0]}, 128)
batch 882: ({'logprob': [54.691429138183594, 14.0]}, 128)
batch 883: ({'logprob': [61.6547966003418, 17.0]}, 128)
batch 884: ({'logprob': [51.487762451171875, 13.0]}, 128)
batch 885: ({'logprob': [52.231231689453125, 13.0]}, 128)
batch 886: ({'logprob': [62.03425216674805, 17.0]}, 128)

======================Test output======================
logprob:  0.417510, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.970124e-03 [3.870772e-09] 
Layer 'conv1' biases: 1.364894e-07 [7.472134e-11] 
Layer 'conv2' weights[0]: 7.957126e-03 [2.656179e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.285785e-10] 
Layer 'conv3' weights[0]: 7.955472e-03 [2.290485e-09] 
Layer 'conv3' biases: 1.196510e-06 [1.315181e-09] 
Layer 'conv4' weights[0]: 7.987998e-03 [2.461163e-09] 
Layer 'conv4' biases: 9.999997e-01 [1.184469e-08] 
Layer 'conv5' weights[0]: 7.986882e-03 [8.024648e-08] 
Layer 'conv5' biases: 9.999985e-01 [8.700395e-08] 
Layer 'fc6' weights[0]: 7.583735e-03 [6.763921e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.861587e-09] 
Layer 'fc7' weights[0]: 7.386897e-03 [2.081761e-07] 
Layer 'fc7' biases: 9.998644e-01 [1.971468e-07] 
Layer 'fc8' weights[0]: 1.290405e-03 [7.336920e-06] 
Layer 'fc8' biases: 3.345575e-02 [4.640536e-05] 
Train error last 870 batches: 0.435268
-------------------------------------------------------
Not saving because 0.417510 > 0.415707 (12.630: -0.00%)
======================================================= (12.041 sec)
14.841... logprob:  0.396365, 0.101562 (1.472 sec)
14.842... logprob:  0.497783, 0.140625 (1.495 sec)
14.843... logprob:  0.465565, 0.125000 (1.449 sec)
14.844... logprob:  0.497602, 0.140625 (1.457 sec)
14.845... logprob:  0.486857, 0.132812 (1.447 sec)
14.846... logprob:  0.468514, 0.125000 (1.447 sec)
14.847... logprob:  0.363081, 0.085938 (1.451 sec)
14.848... logprob:  0.396942, 0.101562 (1.495 sec)
14.849... logprob:  0.360138, 0.085938 (1.452 sec)
14.850... logprob:  0.479465, 0.132812 (1.472 sec)
14.851... logprob:  0.440163, 0.117188 (1.488 sec)
14.852... logprob:  0.546062, 0.156250 (1.457 sec)
14.853... logprob:  0.371720, 0.093750 (1.458 sec)
14.854... logprob:  0.306893, 0.070312 (1.440 sec)
14.855... logprob:  0.485068, 0.132812 (1.447 sec)
14.856... logprob:  0.443915, 0.117188 (1.449 sec)
14.857... logprob:  0.372251, 0.093750 (1.489 sec)
14.858... logprob:  0.396248, 0.101562 (1.464 sec)
14.859... logprob:  0.307947, 0.070312 (1.469 sec)
14.860... logprob:  0.565930, 0.156250 (1.492 sec)
14.861... logprob:  0.417825, 0.109375 (1.455 sec)
14.862... logprob:  0.328972, 0.078125 (1.464 sec)
14.863... logprob:  0.399499, 0.101562 (1.445 sec)
14.864... logprob:  0.451360, 0.117188 (1.442 sec)
14.865... logprob:  0.484333, 0.132812 (1.456 sec)
14.866... logprob:  0.507417, 0.140625 (1.500 sec)
14.867... logprob:  0.502736, 0.140625 (1.463 sec)
14.868... logprob:  0.405450, 0.101562 (1.470 sec)
14.869... logprob:  0.383428, 0.093750 (1.477 sec)
14.870... logprob:  0.551876, 0.156250 (1.400 sec)
15.1... logprob:  0.380265, 0.093750 (1.411 sec)
15.2... logprob:  0.448293, 0.117188 (1.446 sec)
15.3... logprob:  0.398463, 0.101562 (1.417 sec)
15.4... logprob:  0.443369, 0.117188 (1.406 sec)
15.5... logprob:  0.443401, 0.117188 (1.438 sec)
15.6... logprob:  0.499242, 0.140625 (1.394 sec)
15.7... logprob:  0.362977, 0.085938 (1.438 sec)
15.8... logprob:  0.419093, 0.109375 (1.399 sec)
15.9... logprob:  0.358591, 0.085938 (1.402 sec)
15.10... logprob:  0.377327, 0.093750 (1.411 sec)
15.11... logprob:  0.334464, 0.078125 (1.450 sec)
15.12... logprob:  0.466598, 0.125000 (1.390 sec)
15.13... logprob:  0.442442, 0.117188 (1.422 sec)
15.14... logprob:  0.444845, 0.117188 (1.403 sec)
15.15... logprob:  0.395678, 0.101562 (1.412 sec)
15.16... logprob:  0.421487, 0.109375 (1.410 sec)
15.17... logprob:  0.516129, 0.140625 (1.394 sec)
15.18... logprob:  0.262117, 0.054688 (1.405 sec)
15.19... logprob:  0.279664, 0.062500 (1.402 sec)
15.20... logprob:  0.421382, 0.109375 (1.403 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.616485595703125, 10.0]}, 128)
batch 872: ({'logprob': [68.32440185546875, 19.0]}, 128)
batch 873: ({'logprob': [39.381309509277344, 9.0]}, 128)
batch 874: ({'logprob': [44.9140739440918, 11.0]}, 128)
batch 875: ({'logprob': [50.857017517089844, 13.0]}, 128)
batch 876: ({'logprob': [65.47132873535156, 18.0]}, 128)
batch 877: ({'logprob': [45.124244689941406, 11.0]}, 128)
batch 878: ({'logprob': [62.78578567504883, 17.0]}, 128)
batch 879: ({'logprob': [74.89158630371094, 21.0]}, 128)
batch 880: ({'logprob': [50.87482452392578, 13.0]}, 128)
batch 881: ({'logprob': [27.243587493896484, 5.0]}, 128)
batch 882: ({'logprob': [54.3688850402832, 14.0]}, 128)
batch 883: ({'logprob': [62.7697639465332, 17.0]}, 128)
batch 884: ({'logprob': [51.067665100097656, 13.0]}, 128)
batch 885: ({'logprob': [51.48456573486328, 13.0]}, 128)
batch 886: ({'logprob': [62.9888916015625, 17.0]}, 128)

======================Test output======================
logprob:  0.417072, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.970082e-03 [2.716661e-09] 
Layer 'conv1' biases: 1.371992e-07 [3.951659e-11] 
Layer 'conv2' weights[0]: 7.957088e-03 [1.644126e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.348422e-10] 
Layer 'conv3' weights[0]: 7.955435e-03 [1.220702e-09] 
Layer 'conv3' biases: 1.201407e-06 [3.707265e-10] 
Layer 'conv4' weights[0]: 7.987961e-03 [1.221981e-09] 
Layer 'conv4' biases: 9.999998e-01 [1.450337e-09] 
Layer 'conv5' weights[0]: 7.986849e-03 [9.013764e-09] 
Layer 'conv5' biases: 9.999976e-01 [9.481521e-09] 
Layer 'fc6' weights[0]: 7.583694e-03 [1.113030e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.711485e-10] 
Layer 'fc7' weights[0]: 7.384979e-03 [6.076270e-08] 
Layer 'fc7' biases: 9.998659e-01 [4.164350e-08] 
Layer 'fc8' weights[0]: 1.352578e-03 [1.894214e-06] 
Layer 'fc8' biases: 3.402191e-02 [1.245422e-05] 
Train error last 870 batches: 0.435268
-------------------------------------------------------
Not saving because 0.417072 > 0.415707 (12.630: -0.00%)
======================================================= (12.125 sec)
15.21... logprob:  0.443939, 0.117188 (0.895 sec)
15.22... logprob:  0.536522, 0.148438 (1.323 sec)
15.23... logprob:  0.532707, 0.148438 (1.427 sec)
15.24... logprob:  0.310848, 0.070312 (0.990 sec)
15.25... logprob:  0.356376, 0.085938 (0.961 sec)
15.26... logprob:  0.463640, 0.125000 (1.451 sec)
15.27... logprob:  0.404639, 0.101562 (1.391 sec)
15.28... logprob:  0.421883, 0.109375 (1.413 sec)
15.29... logprob:  0.396090, 0.101562 (1.426 sec)
15.30... logprob:  0.374209, 0.093750 (1.424 sec)
15.31... logprob:  0.479894, 0.132812 (1.401 sec)
15.32... logprob:  0.457239, 0.125000 (1.393 sec)
15.33... logprob:  0.460681, 0.125000 (1.447 sec)
15.34... logprob:  0.464652, 0.125000 (1.395 sec)
15.35... logprob:  0.316168, 0.070312 (1.397 sec)
15.36... logprob:  0.475810, 0.132812 (1.408 sec)
15.37... logprob:  0.417601, 0.109375 (1.402 sec)
15.38... logprob:  0.392492, 0.101562 (1.395 sec)
15.39... logprob:  0.631981, 0.187500 (1.443 sec)
15.40... logprob:  0.445860, 0.117188 (1.411 sec)
15.41... logprob:  0.352750, 0.085938 (1.426 sec)
15.42... logprob:  0.391832, 0.101562 (1.439 sec)
15.43... logprob:  0.440128, 0.117188 (1.414 sec)
15.44... logprob:  0.518502, 0.148438 (1.445 sec)
15.45... logprob:  0.381789, 0.093750 (1.388 sec)
15.46... logprob:  0.486386, 0.132812 (1.403 sec)
15.47... logprob:  0.331776, 0.078125 (1.392 sec)
15.48... logprob:  0.498874, 0.140625 (1.429 sec)
15.49... logprob:  0.510627, 0.148438 (1.411 sec)
15.50... logprob:  0.393258, 0.101562 (1.431 sec)
15.51... logprob:  0.489996, 0.140625 (1.415 sec)
15.52... logprob:  0.525777, 0.148438 (1.405 sec)
15.53... logprob:  0.295065, 0.062500 (1.443 sec)
15.54... logprob:  0.403247, 0.109375 (1.394 sec)
15.55... logprob:  0.331804, 0.078125 (1.395 sec)
15.56... logprob:  0.421718, 0.109375 (1.409 sec)
15.57... logprob:  0.572555, 0.164062 (1.427 sec)
15.58... logprob:  0.407778, 0.101562 (1.405 sec)
15.59... logprob:  0.333848, 0.078125 (1.463 sec)
15.60... logprob:  0.619063, 0.179688 (1.432 sec)
15.61... logprob:  0.382866, 0.093750 (1.430 sec)
15.62... logprob:  0.474915, 0.132812 (1.456 sec)
15.63... logprob:  0.397312, 0.101562 (1.433 sec)
15.64... logprob:  0.450267, 0.125000 (1.417 sec)
15.65... logprob:  0.373315, 0.093750 (1.398 sec)
15.66... logprob:  0.354001, 0.085938 (1.445 sec)
15.67... logprob:  0.295383, 0.062500 (1.392 sec)
15.68... logprob:  0.396822, 0.101562 (1.398 sec)
15.69... logprob:  0.496845, 0.140625 (1.422 sec)
15.70... logprob:  0.325876, 0.078125 (1.422 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.00568771362305, 10.0]}, 128)
batch 872: ({'logprob': [67.0891342163086, 19.0]}, 128)
batch 873: ({'logprob': [40.269683837890625, 9.0]}, 128)
batch 874: ({'logprob': [44.87910842895508, 11.0]}, 128)
batch 875: ({'logprob': [50.73140335083008, 13.0]}, 128)
batch 876: ({'logprob': [64.48846435546875, 18.0]}, 128)
batch 877: ({'logprob': [45.505069732666016, 11.0]}, 128)
batch 878: ({'logprob': [62.473388671875, 17.0]}, 128)
batch 879: ({'logprob': [74.80677032470703, 21.0]}, 128)
batch 880: ({'logprob': [50.74726486206055, 13.0]}, 128)
batch 881: ({'logprob': [27.90367889404297, 5.0]}, 128)
batch 882: ({'logprob': [55.232215881347656, 14.0]}, 128)
batch 883: ({'logprob': [62.458091735839844, 17.0]}, 128)
batch 884: ({'logprob': [51.354976654052734, 13.0]}, 128)
batch 885: ({'logprob': [52.60161590576172, 13.0]}, 128)
batch 886: ({'logprob': [63.09069061279297, 17.0]}, 128)

======================Test output======================
logprob:  0.417303, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.970045e-03 [2.191644e-09] 
Layer 'conv1' biases: 1.379455e-07 [5.575078e-11] 
Layer 'conv2' weights[0]: 7.957052e-03 [1.577156e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.230435e-10] 
Layer 'conv3' weights[0]: 7.955397e-03 [1.452460e-09] 
Layer 'conv3' biases: 1.207089e-06 [6.896688e-10] 
Layer 'conv4' weights[0]: 7.987919e-03 [1.539915e-09] 
Layer 'conv4' biases: 9.999998e-01 [6.251588e-09] 
Layer 'conv5' weights[0]: 7.986814e-03 [4.251194e-08] 
Layer 'conv5' biases: 9.999976e-01 [4.603537e-08] 
Layer 'fc6' weights[0]: 7.583644e-03 [3.718862e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.689500e-09] 
Layer 'fc7' weights[0]: 7.383097e-03 [1.612663e-07] 
Layer 'fc7' biases: 9.998658e-01 [1.489710e-07] 
Layer 'fc8' weights[0]: 1.340360e-03 [6.069515e-06] 
Layer 'fc8' biases: 3.397292e-02 [3.857705e-05] 
Train error last 870 batches: 0.435268
-------------------------------------------------------
Not saving because 0.417303 > 0.415707 (12.630: -0.00%)
======================================================= (12.052 sec)
15.71... logprob:  0.381844, 0.101562 (1.473 sec)
15.72... logprob:  0.493854, 0.132812 (1.417 sec)
15.73... logprob:  0.447783, 0.117188 (1.426 sec)
15.74... logprob:  0.442599, 0.117188 (1.420 sec)
15.75... logprob:  0.380643, 0.093750 (1.415 sec)
15.76... logprob:  0.412090, 0.109375 (1.439 sec)
15.77... logprob:  0.396345, 0.101562 (1.433 sec)
15.78... logprob:  0.493068, 0.140625 (1.459 sec)
15.79... logprob:  0.456439, 0.125000 (1.406 sec)
15.80... logprob:  0.507870, 0.132812 (1.423 sec)
15.81... logprob:  0.416724, 0.109375 (1.416 sec)
15.82... logprob:  0.231847, 0.039062 (1.425 sec)
15.83... logprob:  0.493713, 0.140625 (1.403 sec)
15.84... logprob:  0.468080, 0.125000 (1.466 sec)
15.85... logprob:  0.432040, 0.117188 (1.426 sec)
15.86... logprob:  0.416998, 0.109375 (1.422 sec)
15.87... logprob:  0.633185, 0.187500 (1.424 sec)
15.88... logprob:  0.535110, 0.156250 (1.411 sec)
15.89... logprob:  0.410634, 0.109375 (1.435 sec)
15.90... logprob:  0.577516, 0.171875 (1.391 sec)
15.91... logprob:  0.348557, 0.078125 (1.397 sec)
15.92... logprob:  0.464462, 0.125000 (1.404 sec)
15.93... logprob:  0.492288, 0.140625 (1.399 sec)
15.94... logprob:  0.428784, 0.109375 (1.391 sec)
15.95... logprob:  0.471863, 0.125000 (1.407 sec)
15.96... logprob:  0.576369, 0.171875 (1.409 sec)
15.97... logprob:  0.430752, 0.117188 (1.398 sec)
15.98... logprob:  0.391014, 0.093750 (1.440 sec)
15.99... logprob:  0.474325, 0.132812 (1.410 sec)
15.100... logprob:  0.310337, 0.070312 (1.401 sec)
15.101... logprob:  0.310501, 0.062500 (1.443 sec)
15.102... logprob:  0.546406, 0.156250 (1.391 sec)
15.103... logprob:  0.541383, 0.156250 (1.402 sec)
15.104... logprob:  0.388877, 0.101562 (1.402 sec)
15.105... logprob:  0.619857, 0.179688 (1.396 sec)
15.106... logprob:  0.344426, 0.085938 (1.395 sec)
15.107... logprob:  0.335694, 0.078125 (1.442 sec)
15.108... logprob:  0.586803, 0.171875 (1.397 sec)
15.109... logprob:  0.336216, 0.078125 (1.402 sec)
15.110... logprob:  0.564406, 0.164062 (1.400 sec)
15.111... logprob:  0.404744, 0.101562 (1.395 sec)
15.112... logprob:  0.366211, 0.093750 (1.406 sec)
15.113... logprob:  0.354703, 0.085938 (1.401 sec)
15.114... logprob:  0.440236, 0.117188 (1.437 sec)
15.115... logprob:  0.506720, 0.140625 (1.411 sec)
15.116... logprob:  0.393415, 0.101562 (1.403 sec)
15.117... logprob:  0.440397, 0.117188 (1.447 sec)
15.118... logprob:  0.409181, 0.101562 (1.405 sec)
15.119... logprob:  0.346140, 0.085938 (1.398 sec)
15.120... logprob:  0.547157, 0.156250 (1.407 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.690574645996094, 10.0]}, 128)
batch 872: ({'logprob': [66.48526763916016, 19.0]}, 128)
batch 873: ({'logprob': [40.682823181152344, 9.0]}, 128)
batch 874: ({'logprob': [45.233272552490234, 11.0]}, 128)
batch 875: ({'logprob': [50.78631591796875, 13.0]}, 128)
batch 876: ({'logprob': [63.97404861450195, 18.0]}, 128)
batch 877: ({'logprob': [45.73989486694336, 11.0]}, 128)
batch 878: ({'logprob': [61.928794860839844, 17.0]}, 128)
batch 879: ({'logprob': [73.54302978515625, 21.0]}, 128)
batch 880: ({'logprob': [50.80224609375, 13.0]}, 128)
batch 881: ({'logprob': [29.03720474243164, 5.0]}, 128)
batch 882: ({'logprob': [54.83542251586914, 14.0]}, 128)
batch 883: ({'logprob': [61.913387298583984, 17.0]}, 128)
batch 884: ({'logprob': [51.28829574584961, 13.0]}, 128)
batch 885: ({'logprob': [52.29376220703125, 13.0]}, 128)
batch 886: ({'logprob': [62.42483139038086, 17.0]}, 128)

======================Test output======================
logprob:  0.416337, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.970005e-03 [2.487917e-09] 
Layer 'conv1' biases: 1.387840e-07 [4.757747e-11] 
Layer 'conv2' weights[0]: 7.957004e-03 [1.839668e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.764451e-10] 
Layer 'conv3' weights[0]: 7.955359e-03 [1.670730e-09] 
Layer 'conv3' biases: 1.213754e-06 [9.369124e-10] 
Layer 'conv4' weights[0]: 7.987878e-03 [1.742101e-09] 
Layer 'conv4' biases: 9.999997e-01 [7.938721e-09] 
Layer 'conv5' weights[0]: 7.986762e-03 [5.344246e-08] 
Layer 'conv5' biases: 9.999979e-01 [5.778039e-08] 
Layer 'fc6' weights[0]: 7.583606e-03 [4.674457e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.639022e-09] 
Layer 'fc7' weights[0]: 7.381230e-03 [3.950396e-08] 
Layer 'fc7' biases: 9.998651e-01 [1.249346e-08] 
Layer 'fc8' weights[0]: 1.314595e-03 [7.572552e-07] 
Layer 'fc8' biases: 3.391171e-02 [4.373057e-06] 
Train error last 870 batches: 0.435268
-------------------------------------------------------
Not saving because 0.416337 > 0.415707 (12.630: -0.00%)
======================================================= (12.078 sec)
15.121... logprob:  0.412688, 0.109375 (1.411 sec)
15.122... logprob:  0.519379, 0.148438 (1.453 sec)
15.123... logprob:  0.463758, 0.125000 (1.386 sec)
15.124... logprob:  0.447717, 0.125000 (1.406 sec)
15.125... logprob:  0.502019, 0.140625 (1.404 sec)
15.126... logprob:  0.475815, 0.125000 (1.391 sec)
15.127... logprob:  0.479641, 0.125000 (1.403 sec)
15.128... logprob:  0.422386, 0.109375 (1.421 sec)
15.129... logprob:  0.574895, 0.164062 (1.424 sec)
15.130... logprob:  0.382760, 0.093750 (1.417 sec)
15.131... logprob:  0.495503, 0.132812 (1.407 sec)
15.132... logprob:  0.506389, 0.140625 (1.439 sec)
15.133... logprob:  0.444684, 0.117188 (1.392 sec)
15.134... logprob:  0.401922, 0.101562 (1.397 sec)
15.135... logprob:  0.460246, 0.125000 (1.403 sec)
15.136... logprob:  0.562592, 0.164062 (1.396 sec)
15.137... logprob:  0.462566, 0.125000 (1.394 sec)
15.138... logprob:  0.319331, 0.070312 (1.446 sec)
15.139... logprob:  0.395787, 0.101562 (1.398 sec)
15.140... logprob:  0.560538, 0.164062 (1.415 sec)
15.141... logprob:  0.464536, 0.125000 (1.435 sec)
15.142... logprob:  0.464608, 0.125000 (1.396 sec)
15.143... logprob:  0.294246, 0.062500 (1.425 sec)
15.144... logprob:  0.457325, 0.125000 (1.430 sec)
15.145... logprob:  0.324881, 0.078125 (1.419 sec)
15.146... logprob:  0.483250, 0.132812 (1.410 sec)
15.147... logprob:  0.262468, 0.054688 (1.438 sec)
15.148... logprob:  0.458846, 0.125000 (1.389 sec)
15.149... logprob:  0.442571, 0.117188 (1.400 sec)
15.150... logprob:  0.347633, 0.085938 (1.398 sec)
15.151... logprob:  0.347156, 0.085938 (1.404 sec)
15.152... logprob:  0.784998, 0.234375 (1.389 sec)
15.153... logprob:  0.381669, 0.093750 (1.448 sec)
15.154... logprob:  0.524359, 0.148438 (1.399 sec)
15.155... logprob:  0.425973, 0.117188 (1.411 sec)
15.156... logprob:  0.295951, 0.062500 (1.441 sec)
15.157... logprob:  0.270866, 0.054688 (1.405 sec)
15.158... logprob:  0.455365, 0.125000 (1.406 sec)
15.159... logprob:  0.483115, 0.132812 (1.402 sec)
15.160... logprob:  0.444899, 0.117188 (1.394 sec)
15.161... logprob:  0.350181, 0.078125 (1.405 sec)
15.162... logprob:  0.611800, 0.179688 (1.404 sec)
15.163... logprob:  0.450426, 0.125000 (1.430 sec)
15.164... logprob:  0.468700, 0.125000 (1.425 sec)
15.165... logprob:  0.547972, 0.156250 (1.419 sec)
15.166... logprob:  0.446059, 0.125000 (1.454 sec)
15.167... logprob:  0.350395, 0.085938 (1.429 sec)
15.168... logprob:  0.363663, 0.085938 (1.429 sec)
15.169... logprob:  0.408685, 0.101562 (1.458 sec)
15.170... logprob:  0.459497, 0.125000 (1.404 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.95368957519531, 10.0]}, 128)
batch 872: ({'logprob': [66.11415100097656, 19.0]}, 128)
batch 873: ({'logprob': [41.24890899658203, 9.0]}, 128)
batch 874: ({'logprob': [45.530662536621094, 11.0]}, 128)
batch 875: ({'logprob': [50.951019287109375, 13.0]}, 128)
batch 876: ({'logprob': [63.70296096801758, 18.0]}, 128)
batch 877: ({'logprob': [46.10547637939453, 11.0]}, 128)
batch 878: ({'logprob': [61.8263053894043, 17.0]}, 128)
batch 879: ({'logprob': [73.24066925048828, 21.0]}, 128)
batch 880: ({'logprob': [50.966636657714844, 13.0]}, 128)
batch 881: ({'logprob': [29.803253173828125, 5.0]}, 128)
batch 882: ({'logprob': [55.1011962890625, 14.0]}, 128)
batch 883: ({'logprob': [61.8109130859375, 17.0]}, 128)
batch 884: ({'logprob': [51.519371032714844, 13.0]}, 128)
batch 885: ({'logprob': [52.659603118896484, 13.0]}, 128)
batch 886: ({'logprob': [62.389251708984375, 17.0]}, 128)

======================Test output======================
logprob:  0.417443, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.969957e-03 [2.161017e-09] 
Layer 'conv1' biases: 1.395978e-07 [5.109295e-11] 
Layer 'conv2' weights[0]: 7.956963e-03 [1.870190e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.800265e-10] 
Layer 'conv3' weights[0]: 7.955318e-03 [1.913388e-09] 
Layer 'conv3' biases: 1.220932e-06 [9.276688e-10] 
Layer 'conv4' weights[0]: 7.987845e-03 [2.037934e-09] 
Layer 'conv4' biases: 9.999998e-01 [8.445336e-09] 
Layer 'conv5' weights[0]: 7.986725e-03 [5.492009e-08] 
Layer 'conv5' biases: 9.999977e-01 [5.940197e-08] 
Layer 'fc6' weights[0]: 7.583566e-03 [4.790575e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.754731e-09] 
Layer 'fc7' weights[0]: 7.379354e-03 [1.542557e-07] 
Layer 'fc7' biases: 9.998647e-01 [1.417348e-07] 
Layer 'fc8' weights[0]: 1.306358e-03 [5.966195e-06] 
Layer 'fc8' biases: 3.395271e-02 [4.063187e-05] 
Train error last 870 batches: 0.435267
-------------------------------------------------------
Not saving because 0.417443 > 0.415707 (12.630: -0.00%)
======================================================= (12.048 sec)
15.171... logprob:  0.535491, 0.156250 (1.435 sec)
15.172... logprob:  0.434874, 0.109375 (1.428 sec)
15.173... logprob:  0.440501, 0.117188 (1.429 sec)
15.174... logprob:  0.601188, 0.171875 (1.406 sec)
15.175... logprob:  0.506134, 0.140625 (1.471 sec)
15.176... logprob:  0.478500, 0.132812 (1.424 sec)
15.177... logprob:  0.289779, 0.054688 (1.422 sec)
15.178... logprob:  0.383493, 0.093750 (1.464 sec)
15.179... logprob:  0.394734, 0.101562 (1.407 sec)
15.180... logprob:  0.466382, 0.125000 (1.423 sec)
15.181... logprob:  0.539409, 0.156250 (1.419 sec)
15.182... logprob:  0.371414, 0.093750 (1.418 sec)
15.183... logprob:  0.419963, 0.109375 (1.416 sec)
15.184... logprob:  0.483480, 0.132812 (1.421 sec)
15.185... logprob:  0.289883, 0.062500 (1.414 sec)
15.186... logprob:  0.370518, 0.093750 (1.403 sec)
15.187... logprob:  0.529632, 0.148438 (1.398 sec)
15.188... logprob:  0.458997, 0.125000 (1.399 sec)
15.189... logprob:  0.440906, 0.117188 (1.393 sec)
15.190... logprob:  0.375740, 0.093750 (1.434 sec)
15.191... logprob:  0.485103, 0.132812 (1.412 sec)
15.192... logprob:  0.520175, 0.148438 (1.418 sec)
15.193... logprob:  0.312630, 0.070312 (1.419 sec)
15.194... logprob:  0.414116, 0.109375 (1.419 sec)
15.195... logprob:  0.287244, 0.062500 (1.397 sec)
15.196... logprob:  0.410558, 0.109375 (1.396 sec)
15.197... logprob:  0.478031, 0.132812 (1.397 sec)
15.198... logprob:  0.355793, 0.085938 (1.409 sec)
15.199... logprob:  0.437193, 0.117188 (1.387 sec)
15.200... logprob:  0.440777, 0.117188 (1.441 sec)
15.201... logprob:  0.437100, 0.117188 (1.406 sec)
15.202... logprob:  0.537978, 0.148438 (1.410 sec)
15.203... logprob:  0.420463, 0.109375 (1.446 sec)
15.204... logprob:  0.504126, 0.140625 (1.394 sec)
15.205... logprob:  0.334396, 0.078125 (1.409 sec)
15.206... logprob:  0.361634, 0.093750 (1.403 sec)
15.207... logprob:  0.381909, 0.093750 (1.392 sec)
15.208... logprob:  0.490520, 0.140625 (1.402 sec)
15.209... logprob:  0.334602, 0.078125 (1.426 sec)
15.210... logprob:  0.586250, 0.171875 (1.420 sec)
15.211... logprob:  0.488195, 0.132812 (1.416 sec)
15.212... logprob:  0.526154, 0.148438 (1.415 sec)
15.213... logprob:  0.514812, 0.140625 (1.465 sec)
15.214... logprob:  0.459441, 0.125000 (1.428 sec)
15.215... logprob:  0.396153, 0.101562 (1.419 sec)
15.216... logprob:  0.517115, 0.140625 (1.466 sec)
15.217... logprob:  0.325114, 0.070312 (1.406 sec)
15.218... logprob:  0.463705, 0.125000 (1.422 sec)
15.219... logprob:  0.500313, 0.140625 (1.420 sec)
15.220... logprob:  0.414997, 0.109375 (1.422 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.53399658203125, 10.0]}, 128)
batch 872: ({'logprob': [66.01712799072266, 19.0]}, 128)
batch 873: ({'logprob': [41.55680847167969, 9.0]}, 128)
batch 874: ({'logprob': [45.87861633300781, 11.0]}, 128)
batch 875: ({'logprob': [51.13734436035156, 13.0]}, 128)
batch 876: ({'logprob': [63.636322021484375, 18.0]}, 128)
batch 877: ({'logprob': [46.353187561035156, 11.0]}, 128)
batch 878: ({'logprob': [61.689395904541016, 17.0]}, 128)
batch 879: ({'logprob': [72.67989349365234, 21.0]}, 128)
batch 880: ({'logprob': [51.15336227416992, 13.0]}, 128)
batch 881: ({'logprob': [30.535629272460938, 5.0]}, 128)
batch 882: ({'logprob': [54.95417404174805, 14.0]}, 128)
batch 883: ({'logprob': [61.67372131347656, 17.0]}, 128)
batch 884: ({'logprob': [51.60422134399414, 13.0]}, 128)
batch 885: ({'logprob': [52.542442321777344, 13.0]}, 128)
batch 886: ({'logprob': [62.15101623535156, 17.0]}, 128)

======================Test output======================
logprob:  0.418016, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.969918e-03 [2.437454e-09] 
Layer 'conv1' biases: 1.404330e-07 [6.516101e-11] 
Layer 'conv2' weights[0]: 7.956929e-03 [1.991335e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.155966e-10] 
Layer 'conv3' weights[0]: 7.955277e-03 [1.860781e-09] 
Layer 'conv3' biases: 1.228577e-06 [9.324397e-10] 
Layer 'conv4' weights[0]: 7.987803e-03 [2.017580e-09] 
Layer 'conv4' biases: 9.999998e-01 [9.114186e-09] 
Layer 'conv5' weights[0]: 7.986666e-03 [6.171313e-08] 
Layer 'conv5' biases: 9.999979e-01 [6.682318e-08] 
Layer 'fc6' weights[0]: 7.583526e-03 [5.274820e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.315613e-09] 
Layer 'fc7' weights[0]: 7.377494e-03 [1.089445e-07] 
Layer 'fc7' biases: 9.998642e-01 [9.380457e-08] 
Layer 'fc8' weights[0]: 1.296848e-03 [5.972534e-06] 
Layer 'fc8' biases: 3.396454e-02 [4.021336e-05] 
Train error last 870 batches: 0.435267
-------------------------------------------------------
Not saving because 0.418016 > 0.415707 (12.630: -0.00%)
======================================================= (12.058 sec)
15.221... logprob:  0.399540, 0.101562 (1.414 sec)
15.222... logprob:  0.554587, 0.164062 (1.465 sec)
15.223... logprob:  0.569249, 0.164062 (1.429 sec)
15.224... logprob:  0.405872, 0.101562 (1.439 sec)
15.225... logprob:  0.391968, 0.101562 (1.447 sec)
15.226... logprob:  0.424632, 0.109375 (1.428 sec)
15.227... logprob:  0.452738, 0.125000 (1.420 sec)
15.228... logprob:  0.417200, 0.109375 (1.415 sec)
15.229... logprob:  0.489372, 0.132812 (1.420 sec)
15.230... logprob:  0.459899, 0.125000 (1.427 sec)
15.231... logprob:  0.453544, 0.125000 (1.404 sec)
15.232... logprob:  0.496228, 0.140625 (1.464 sec)
15.233... logprob:  0.466166, 0.132812 (1.425 sec)
15.234... logprob:  0.563798, 0.164062 (1.428 sec)
15.235... logprob:  0.482033, 0.132812 (1.469 sec)
15.236... logprob:  0.425803, 0.109375 (1.404 sec)
15.237... logprob:  0.341345, 0.078125 (1.422 sec)
15.238... logprob:  0.389387, 0.093750 (1.415 sec)
15.239... logprob:  0.478147, 0.132812 (1.424 sec)
15.240... logprob:  0.485808, 0.132812 (1.403 sec)
15.241... logprob:  0.493607, 0.132812 (1.459 sec)
15.242... logprob:  0.341653, 0.078125 (1.432 sec)
15.243... logprob:  0.386021, 0.093750 (1.436 sec)
15.244... logprob:  0.315222, 0.070312 (1.533 sec)
15.245... logprob:  0.494358, 0.132812 (1.422 sec)
15.246... logprob:  0.416909, 0.109375 (1.417 sec)
15.247... logprob:  0.357356, 0.085938 (1.419 sec)
15.248... logprob:  0.307745, 0.070312 (1.417 sec)
15.249... logprob:  0.555460, 0.156250 (1.435 sec)
15.250... logprob:  0.591765, 0.164062 (1.405 sec)
15.251... logprob:  0.352911, 0.085938 (1.459 sec)
15.252... logprob:  0.348488, 0.085938 (1.427 sec)
15.253... logprob:  0.379177, 0.093750 (1.420 sec)
15.254... logprob:  0.444182, 0.117188 (1.467 sec)
15.255... logprob:  0.351493, 0.085938 (1.403 sec)
15.256... logprob:  0.378750, 0.093750 (1.429 sec)
15.257... logprob:  0.332052, 0.078125 (1.414 sec)
15.258... logprob:  0.415761, 0.109375 (1.423 sec)
15.259... logprob:  0.442309, 0.117188 (1.402 sec)
15.260... logprob:  0.308396, 0.070312 (1.486 sec)
15.261... logprob:  0.392805, 0.101562 (1.437 sec)
15.262... logprob:  0.524660, 0.148438 (1.429 sec)
15.263... logprob:  0.425480, 0.109375 (1.449 sec)
15.264... logprob:  0.375156, 0.093750 (1.422 sec)
15.265... logprob:  0.439614, 0.117188 (1.419 sec)
15.266... logprob:  0.439038, 0.117188 (1.420 sec)
15.267... logprob:  0.422005, 0.109375 (1.413 sec)
15.268... logprob:  0.458945, 0.125000 (1.427 sec)
15.269... logprob:  0.567469, 0.164062 (1.406 sec)
15.270... logprob:  0.542211, 0.156250 (1.461 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.68265914916992, 10.0]}, 128)
batch 872: ({'logprob': [66.28617095947266, 19.0]}, 128)
batch 873: ({'logprob': [41.228450775146484, 9.0]}, 128)
batch 874: ({'logprob': [45.83140563964844, 11.0]}, 128)
batch 875: ({'logprob': [51.10121154785156, 13.0]}, 128)
batch 876: ({'logprob': [63.83279800415039, 18.0]}, 128)
batch 877: ({'logprob': [46.17123031616211, 11.0]}, 128)
batch 878: ({'logprob': [61.67738342285156, 17.0]}, 128)
batch 879: ({'logprob': [72.5575942993164, 21.0]}, 128)
batch 880: ({'logprob': [51.11790466308594, 13.0]}, 128)
batch 881: ({'logprob': [30.317747116088867, 5.0]}, 128)
batch 882: ({'logprob': [54.588165283203125, 14.0]}, 128)
batch 883: ({'logprob': [61.66148376464844, 17.0]}, 128)
batch 884: ({'logprob': [51.434181213378906, 13.0]}, 128)
batch 885: ({'logprob': [52.10310363769531, 13.0]}, 128)
batch 886: ({'logprob': [62.00458908081055, 17.0]}, 128)

======================Test output======================
logprob:  0.417283, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.969878e-03 [4.580390e-09] 
Layer 'conv1' biases: 1.413430e-07 [1.306933e-10] 
Layer 'conv2' weights[0]: 7.956889e-03 [3.807643e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.654966e-10] 
Layer 'conv3' weights[0]: 7.955238e-03 [3.635388e-09] 
Layer 'conv3' biases: 1.236025e-06 [2.402986e-09] 
Layer 'conv4' weights[0]: 7.987760e-03 [3.926962e-09] 
Layer 'conv4' biases: 9.999997e-01 [2.193812e-08] 
Layer 'conv5' weights[0]: 7.986646e-03 [1.454043e-07] 
Layer 'conv5' biases: 9.999987e-01 [1.571438e-07] 
Layer 'fc6' weights[0]: 7.583486e-03 [1.227761e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.257009e-08] 
Layer 'fc7' weights[0]: 7.375694e-03 [3.405146e-07] 
Layer 'fc7' biases: 9.998640e-01 [3.299601e-07] 
Layer 'fc8' weights[0]: 1.305276e-03 [1.374048e-05] 
Layer 'fc8' biases: 3.410738e-02 [8.776567e-05] 
Train error last 870 batches: 0.435266
-------------------------------------------------------
Not saving because 0.417283 > 0.415707 (12.630: -0.00%)
======================================================= (12.037 sec)
15.271... logprob:  0.445750, 0.117188 (1.431 sec)
15.272... logprob:  0.384762, 0.093750 (1.420 sec)
15.273... logprob:  0.500217, 0.140625 (1.464 sec)
15.274... logprob:  0.542532, 0.156250 (1.407 sec)
15.275... logprob:  0.487733, 0.132812 (1.423 sec)
15.276... logprob:  0.390177, 0.093750 (1.415 sec)
15.277... logprob:  0.428722, 0.109375 (1.425 sec)
15.278... logprob:  0.323395, 0.070312 (1.428 sec)
15.279... logprob:  0.324965, 0.070312 (1.462 sec)
15.280... logprob:  0.215155, 0.031250 (1.404 sec)
15.281... logprob:  0.417217, 0.109375 (1.424 sec)
15.282... logprob:  0.411471, 0.109375 (1.422 sec)
15.283... logprob:  0.393864, 0.101562 (1.416 sec)
15.284... logprob:  0.394702, 0.101562 (1.413 sec)
15.285... logprob:  0.452173, 0.117188 (1.438 sec)
15.286... logprob:  0.537511, 0.140625 (1.442 sec)
15.287... logprob:  0.346681, 0.085938 (1.435 sec)
15.288... logprob:  0.329979, 0.078125 (1.433 sec)
15.289... logprob:  0.446027, 0.117188 (1.445 sec)
15.290... logprob:  0.490654, 0.132812 (1.412 sec)
15.291... logprob:  0.439154, 0.117188 (1.415 sec)
15.292... logprob:  0.567021, 0.156250 (1.424 sec)
15.293... logprob:  0.427492, 0.117188 (1.429 sec)
15.294... logprob:  0.356203, 0.085938 (1.408 sec)
15.295... logprob:  0.335143, 0.078125 (1.472 sec)
15.296... logprob:  0.356222, 0.085938 (1.423 sec)
15.297... logprob:  0.394822, 0.101562 (1.419 sec)
15.298... logprob:  0.448111, 0.125000 (1.466 sec)
15.299... logprob:  0.342647, 0.078125 (1.406 sec)
15.300... logprob:  0.406691, 0.101562 (1.425 sec)
15.301... logprob:  0.397965, 0.101562 (1.420 sec)
15.302... logprob:  0.591561, 0.179688 (1.416 sec)
15.303... logprob:  0.459639, 0.125000 (1.412 sec)
15.304... logprob:  0.459714, 0.125000 (1.438 sec)
15.305... logprob:  0.455244, 0.125000 (1.441 sec)
15.306... logprob:  0.440612, 0.117188 (1.433 sec)
15.307... logprob:  0.421599, 0.109375 (1.446 sec)
15.308... logprob:  0.374553, 0.093750 (1.457 sec)
15.309... logprob:  0.450494, 0.125000 (1.417 sec)
15.310... logprob:  0.473761, 0.125000 (1.429 sec)
15.311... logprob:  0.502669, 0.140625 (1.428 sec)
15.312... logprob:  0.478801, 0.132812 (1.437 sec)
15.313... logprob:  0.454873, 0.125000 (1.420 sec)
15.314... logprob:  0.454515, 0.117188 (1.474 sec)
15.315... logprob:  0.314696, 0.070312 (1.435 sec)
15.316... logprob:  0.468581, 0.125000 (1.428 sec)
15.317... logprob:  0.355529, 0.085938 (1.474 sec)
15.318... logprob:  0.455420, 0.125000 (1.420 sec)
15.319... logprob:  0.423213, 0.117188 (1.421 sec)
15.320... logprob:  0.412265, 0.109375 (1.432 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.4827766418457, 10.0]}, 128)
batch 872: ({'logprob': [66.5531005859375, 19.0]}, 128)
batch 873: ({'logprob': [40.63170623779297, 9.0]}, 128)
batch 874: ({'logprob': [45.140647888183594, 11.0]}, 128)
batch 875: ({'logprob': [50.76083755493164, 13.0]}, 128)
batch 876: ({'logprob': [64.03558349609375, 18.0]}, 128)
batch 877: ({'logprob': [45.70148468017578, 11.0]}, 128)
batch 878: ({'logprob': [62.038150787353516, 17.0]}, 128)
batch 879: ({'logprob': [73.84072875976562, 21.0]}, 128)
batch 880: ({'logprob': [50.77703857421875, 13.0]}, 128)
batch 881: ({'logprob': [28.79708480834961, 5.0]}, 128)
batch 882: ({'logprob': [54.979759216308594, 14.0]}, 128)
batch 883: ({'logprob': [62.022403717041016, 17.0]}, 128)
batch 884: ({'logprob': [51.31753158569336, 13.0]}, 128)
batch 885: ({'logprob': [52.4316291809082, 13.0]}, 128)
batch 886: ({'logprob': [62.58867645263672, 17.0]}, 128)

======================Test output======================
logprob:  0.416552, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.969831e-03 [1.998886e-09] 
Layer 'conv1' biases: 1.421270e-07 [3.092376e-11] 
Layer 'conv2' weights[0]: 7.956853e-03 [1.611932e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.539760e-10] 
Layer 'conv3' weights[0]: 7.955202e-03 [1.269934e-09] 
Layer 'conv3' biases: 1.240554e-06 [4.573911e-10] 
Layer 'conv4' weights[0]: 7.987724e-03 [1.393847e-09] 
Layer 'conv4' biases: 9.999997e-01 [3.724439e-09] 
Layer 'conv5' weights[0]: 7.986613e-03 [2.414487e-08] 
Layer 'conv5' biases: 9.999976e-01 [2.595286e-08] 
Layer 'fc6' weights[0]: 7.583450e-03 [2.227157e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.075967e-09] 
Layer 'fc7' weights[0]: 7.373799e-03 [1.212779e-07] 
Layer 'fc7' biases: 9.998649e-01 [1.068122e-07] 
Layer 'fc8' weights[0]: 1.327113e-03 [3.872780e-06] 
Layer 'fc8' biases: 3.454527e-02 [2.614094e-05] 
Train error last 870 batches: 0.435266
-------------------------------------------------------
Not saving because 0.416552 > 0.415707 (12.630: -0.00%)
======================================================= (12.059 sec)
15.321... logprob:  0.348296, 0.085938 (1.433 sec)
15.322... logprob:  0.387528, 0.101562 (1.421 sec)
15.323... logprob:  0.416526, 0.109375 (1.477 sec)
15.324... logprob:  0.498637, 0.140625 (1.428 sec)
15.325... logprob:  0.350681, 0.085938 (1.436 sec)
15.326... logprob:  0.543197, 0.148438 (1.463 sec)
15.327... logprob:  0.554409, 0.164062 (1.432 sec)
15.328... logprob:  0.565016, 0.156250 (1.428 sec)
15.329... logprob:  0.402004, 0.101562 (1.430 sec)
15.330... logprob:  0.388671, 0.101562 (1.425 sec)
15.331... logprob:  0.352547, 0.085938 (1.417 sec)
15.332... logprob:  0.482791, 0.132812 (1.454 sec)
15.333... logprob:  0.339647, 0.085938 (1.443 sec)
15.334... logprob:  0.565103, 0.171875 (1.445 sec)
15.335... logprob:  0.358871, 0.085938 (1.438 sec)
15.336... logprob:  0.444832, 0.125000 (1.462 sec)
15.337... logprob:  0.566480, 0.164062 (1.411 sec)
15.338... logprob:  0.449517, 0.125000 (1.427 sec)
15.339... logprob:  0.488708, 0.132812 (1.425 sec)
15.340... logprob:  0.442077, 0.117188 (1.427 sec)
15.341... logprob:  0.530150, 0.148438 (1.425 sec)
15.342... logprob:  0.429683, 0.109375 (1.465 sec)
15.343... logprob:  0.434784, 0.109375 (1.438 sec)
15.344... logprob:  0.444422, 0.125000 (1.484 sec)
15.345... logprob:  0.488266, 0.132812 (1.439 sec)
15.346... logprob:  0.436247, 0.117188 (1.443 sec)
15.347... logprob:  0.372346, 0.085938 (1.480 sec)
15.348... logprob:  0.398438, 0.101562 (1.440 sec)
15.349... logprob:  0.497891, 0.140625 (1.430 sec)
15.350... logprob:  0.358546, 0.085938 (1.440 sec)
15.351... logprob:  0.508687, 0.140625 (1.429 sec)
15.352... logprob:  0.363665, 0.093750 (1.438 sec)
15.353... logprob:  0.512804, 0.148438 (1.487 sec)
15.354... logprob:  0.675154, 0.203125 (1.431 sec)
15.355... logprob:  0.357475, 0.085938 (1.439 sec)
15.356... logprob:  0.479253, 0.132812 (1.479 sec)
15.357... logprob:  0.347051, 0.085938 (1.435 sec)
15.358... logprob:  0.326043, 0.070312 (1.440 sec)
15.359... logprob:  0.555218, 0.164062 (1.438 sec)
15.360... logprob:  0.444517, 0.117188 (1.424 sec)
15.361... logprob:  0.410785, 0.101562 (1.431 sec)
15.362... logprob:  0.424140, 0.117188 (1.474 sec)
15.363... logprob:  0.486587, 0.132812 (1.447 sec)
15.364... logprob:  0.475543, 0.125000 (1.457 sec)
15.365... logprob:  0.425092, 0.109375 (1.465 sec)
15.366... logprob:  0.409701, 0.109375 (1.444 sec)
15.367... logprob:  0.325004, 0.078125 (1.441 sec)
15.368... logprob:  0.595704, 0.171875 (1.467 sec)
15.369... logprob:  0.381533, 0.093750 (1.426 sec)
15.370... logprob:  0.381159, 0.093750 (1.438 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.82072830200195, 10.0]}, 128)
batch 872: ({'logprob': [66.52605438232422, 19.0]}, 128)
batch 873: ({'logprob': [40.633914947509766, 9.0]}, 128)
batch 874: ({'logprob': [45.26814651489258, 11.0]}, 128)
batch 875: ({'logprob': [50.79493713378906, 13.0]}, 128)
batch 876: ({'logprob': [64.00080108642578, 18.0]}, 128)
batch 877: ({'logprob': [45.720062255859375, 11.0]}, 128)
batch 878: ({'logprob': [61.88607406616211, 17.0]}, 128)
batch 879: ({'logprob': [73.39349365234375, 21.0]}, 128)
batch 880: ({'logprob': [50.81159973144531, 13.0]}, 128)
batch 881: ({'logprob': [29.094905853271484, 5.0]}, 128)
batch 882: ({'logprob': [54.694332122802734, 14.0]}, 128)
batch 883: ({'logprob': [61.870059967041016, 17.0]}, 128)
batch 884: ({'logprob': [51.242366790771484, 13.0]}, 128)
batch 885: ({'logprob': [52.13793182373047, 13.0]}, 128)
batch 886: ({'logprob': [62.32722473144531, 17.0]}, 128)

======================Test output======================
logprob:  0.416124, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.969792e-03 [2.424530e-09] 
Layer 'conv1' biases: 1.428829e-07 [5.526240e-11] 
Layer 'conv2' weights[0]: 7.956817e-03 [2.028122e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.937878e-10] 
Layer 'conv3' weights[0]: 7.955170e-03 [1.883382e-09] 
Layer 'conv3' biases: 1.247250e-06 [9.473224e-10] 
Layer 'conv4' weights[0]: 7.987679e-03 [1.965861e-09] 
Layer 'conv4' biases: 9.999998e-01 [8.269264e-09] 
Layer 'conv5' weights[0]: 7.986564e-03 [5.217241e-08] 
Layer 'conv5' biases: 9.999978e-01 [5.630794e-08] 
Layer 'fc6' weights[0]: 7.583408e-03 [4.556223e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.531365e-09] 
Layer 'fc7' weights[0]: 7.371949e-03 [1.102077e-07] 
Layer 'fc7' biases: 9.998646e-01 [9.505800e-08] 
Layer 'fc8' weights[0]: 1.322266e-03 [6.802859e-06] 
Layer 'fc8' biases: 3.460863e-02 [4.445172e-05] 
Train error last 870 batches: 0.435266
-------------------------------------------------------
Not saving because 0.416124 > 0.415707 (12.630: -0.00%)
======================================================= (12.041 sec)
15.371... logprob:  0.400347, 0.101562 (1.464 sec)
15.372... logprob:  0.537611, 0.156250 (1.455 sec)
15.373... logprob:  0.463833, 0.125000 (1.454 sec)
15.374... logprob:  0.527090, 0.148438 (1.452 sec)
15.375... logprob:  0.393783, 0.101562 (1.462 sec)
15.376... logprob:  0.374317, 0.093750 (1.444 sec)
15.377... logprob:  0.295381, 0.062500 (1.422 sec)
15.378... logprob:  0.453771, 0.125000 (1.434 sec)
15.379... logprob:  0.420239, 0.109375 (1.443 sec)
15.380... logprob:  0.605757, 0.179688 (1.439 sec)
15.381... logprob:  0.463488, 0.125000 (1.470 sec)
15.382... logprob:  0.529500, 0.148438 (1.452 sec)
15.383... logprob:  0.358705, 0.085938 (1.444 sec)
15.384... logprob:  0.521037, 0.148438 (1.478 sec)
15.385... logprob:  0.523461, 0.148438 (1.439 sec)
15.386... logprob:  0.582326, 0.171875 (1.428 sec)
15.387... logprob:  0.428695, 0.117188 (1.437 sec)
15.388... logprob:  0.521306, 0.148438 (1.437 sec)
15.389... logprob:  0.425929, 0.109375 (1.434 sec)
15.390... logprob:  0.419946, 0.109375 (1.478 sec)
15.391... logprob:  0.318390, 0.070312 (1.448 sec)
15.392... logprob:  0.439423, 0.117188 (1.435 sec)
15.393... logprob:  0.368830, 0.093750 (1.484 sec)
15.394... logprob:  0.343457, 0.078125 (1.436 sec)
15.395... logprob:  0.331525, 0.078125 (1.433 sec)
15.396... logprob:  0.251777, 0.046875 (1.440 sec)
15.397... logprob:  0.484794, 0.132812 (1.430 sec)
15.398... logprob:  0.471516, 0.125000 (1.433 sec)
15.399... logprob:  0.433787, 0.117188 (1.492 sec)
15.400... logprob:  0.538696, 0.148438 (1.432 sec)
15.401... logprob:  0.466246, 0.125000 (1.471 sec)
15.402... logprob:  0.474318, 0.125000 (1.484 sec)
15.403... logprob:  0.462260, 0.125000 (1.429 sec)
15.404... logprob:  0.474829, 0.125000 (1.437 sec)
15.405... logprob:  0.543800, 0.156250 (1.440 sec)
15.406... logprob:  0.357949, 0.085938 (1.429 sec)
15.407... logprob:  0.492648, 0.140625 (1.430 sec)
15.408... logprob:  0.339851, 0.078125 (1.477 sec)
15.409... logprob:  0.401078, 0.101562 (1.438 sec)
15.410... logprob:  0.581677, 0.171875 (1.445 sec)
15.411... logprob:  0.398365, 0.101562 (1.482 sec)
15.412... logprob:  0.540195, 0.156250 (1.437 sec)
15.413... logprob:  0.544720, 0.156250 (1.444 sec)
15.414... logprob:  0.466659, 0.125000 (1.431 sec)
15.415... logprob:  0.401805, 0.101562 (1.424 sec)
15.416... logprob:  0.427572, 0.109375 (1.443 sec)
15.417... logprob:  0.405397, 0.093750 (1.463 sec)
15.418... logprob:  0.380023, 0.093750 (1.457 sec)
15.419... logprob:  0.417508, 0.101562 (1.449 sec)
15.420... logprob:  0.355793, 0.085938 (1.461 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.61317825317383, 10.0]}, 128)
batch 872: ({'logprob': [66.52267456054688, 19.0]}, 128)
batch 873: ({'logprob': [40.642330169677734, 9.0]}, 128)
batch 874: ({'logprob': [45.19105529785156, 11.0]}, 128)
batch 875: ({'logprob': [50.77109909057617, 13.0]}, 128)
batch 876: ({'logprob': [64.0053482055664, 18.0]}, 128)
batch 877: ({'logprob': [45.71213912963867, 11.0]}, 128)
batch 878: ({'logprob': [61.96820831298828, 17.0]}, 128)
batch 879: ({'logprob': [73.65072631835938, 21.0]}, 128)
batch 880: ({'logprob': [50.7874641418457, 13.0]}, 128)
batch 881: ({'logprob': [28.928056716918945, 5.0]}, 128)
batch 882: ({'logprob': [54.87019348144531, 14.0]}, 128)
batch 883: ({'logprob': [61.95237731933594, 17.0]}, 128)
batch 884: ({'logprob': [51.28792190551758, 13.0]}, 128)
batch 885: ({'logprob': [52.32209396362305, 13.0]}, 128)
batch 886: ({'logprob': [62.47871398925781, 17.0]}, 128)

======================Test output======================
logprob:  0.416359, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.969763e-03 [3.272463e-09] 
Layer 'conv1' biases: 1.436613e-07 [1.452579e-10] 
Layer 'conv2' weights[0]: 7.956770e-03 [3.745838e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.551040e-10] 
Layer 'conv3' weights[0]: 7.955128e-03 [3.848660e-09] 
Layer 'conv3' biases: 1.250631e-06 [2.331253e-09] 
Layer 'conv4' weights[0]: 7.987638e-03 [4.019854e-09] 
Layer 'conv4' biases: 9.999997e-01 [2.142626e-08] 
Layer 'conv5' weights[0]: 7.986522e-03 [1.403376e-07] 
Layer 'conv5' biases: 9.999973e-01 [1.517304e-07] 
Layer 'fc6' weights[0]: 7.583369e-03 [1.187071e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.214693e-08] 
Layer 'fc7' weights[0]: 7.370034e-03 [4.202119e-07] 
Layer 'fc7' biases: 9.998647e-01 [4.068077e-07] 
Layer 'fc8' weights[0]: 1.320155e-03 [1.881215e-05] 
Layer 'fc8' biases: 3.487370e-02 [1.273504e-04] 
Train error last 870 batches: 0.435265
-------------------------------------------------------
Not saving because 0.416359 > 0.415707 (12.630: -0.00%)
======================================================= (12.015 sec)
15.421... logprob:  0.376520, 0.101562 (1.466 sec)
15.422... logprob:  0.523278, 0.148438 (1.445 sec)
15.423... logprob:  0.421084, 0.109375 (1.421 sec)
15.424... logprob:  0.324562, 0.078125 (1.436 sec)
15.425... logprob:  0.306064, 0.070312 (1.433 sec)
15.426... logprob:  0.449502, 0.117188 (1.445 sec)
15.427... logprob:  0.555196, 0.156250 (1.464 sec)
15.428... logprob:  0.602451, 0.171875 (1.452 sec)
15.429... logprob:  0.426258, 0.109375 (1.449 sec)
15.430... logprob:  0.300011, 0.070312 (1.476 sec)
15.431... logprob:  0.599127, 0.171875 (1.435 sec)
15.432... logprob:  0.387628, 0.093750 (1.427 sec)
15.433... logprob:  0.330397, 0.078125 (1.435 sec)
15.434... logprob:  0.528994, 0.148438 (1.472 sec)
15.435... logprob:  0.531952, 0.156250 (1.440 sec)
15.436... logprob:  0.381731, 0.093750 (1.474 sec)
15.437... logprob:  0.500208, 0.140625 (1.449 sec)
15.438... logprob:  0.546732, 0.156250 (1.438 sec)
15.439... logprob:  0.379340, 0.093750 (1.482 sec)
15.440... logprob:  0.439930, 0.117188 (1.435 sec)
15.441... logprob:  0.468063, 0.125000 (1.433 sec)
15.442... logprob:  0.378909, 0.093750 (1.439 sec)
15.443... logprob:  0.496594, 0.140625 (1.435 sec)
15.444... logprob:  0.372012, 0.093750 (1.431 sec)
15.445... logprob:  0.362042, 0.085938 (1.486 sec)
15.446... logprob:  0.398027, 0.101562 (1.441 sec)
15.447... logprob:  0.570593, 0.164062 (1.445 sec)
15.448... logprob:  0.332371, 0.078125 (1.489 sec)
15.449... logprob:  0.400022, 0.101562 (1.434 sec)
15.450... logprob:  0.238607, 0.046875 (1.433 sec)
15.451... logprob:  0.453167, 0.125000 (1.440 sec)
15.452... logprob:  0.456476, 0.117188 (1.428 sec)
15.453... logprob:  0.455627, 0.125000 (1.438 sec)
15.454... logprob:  0.489340, 0.132812 (1.485 sec)
15.455... logprob:  0.506158, 0.140625 (1.438 sec)
15.456... logprob:  0.468791, 0.125000 (1.449 sec)
15.457... logprob:  0.375409, 0.093750 (1.474 sec)
15.458... logprob:  0.351287, 0.085938 (1.440 sec)
15.459... logprob:  0.513547, 0.140625 (1.438 sec)
15.460... logprob:  0.274838, 0.054688 (1.436 sec)
15.461... logprob:  0.459946, 0.125000 (1.428 sec)
15.462... logprob:  0.471872, 0.125000 (1.436 sec)
15.463... logprob:  0.420990, 0.109375 (1.472 sec)
15.464... logprob:  0.482655, 0.132812 (1.449 sec)
15.465... logprob:  0.421248, 0.109375 (1.450 sec)
15.466... logprob:  0.318734, 0.070312 (1.456 sec)
15.467... logprob:  0.413881, 0.109375 (1.451 sec)
15.468... logprob:  0.394279, 0.101562 (1.442 sec)
15.469... logprob:  0.334610, 0.078125 (1.429 sec)
15.470... logprob:  0.400041, 0.101562 (1.430 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.518253326416016, 10.0]}, 128)
batch 872: ({'logprob': [66.9260482788086, 19.0]}, 128)
batch 873: ({'logprob': [40.220489501953125, 9.0]}, 128)
batch 874: ({'logprob': [45.0290412902832, 11.0]}, 128)
batch 875: ({'logprob': [50.710418701171875, 13.0]}, 128)
batch 876: ({'logprob': [64.31877136230469, 18.0]}, 128)
batch 877: ({'logprob': [45.47077178955078, 11.0]}, 128)
batch 878: ({'logprob': [62.11183166503906, 17.0]}, 128)
batch 879: ({'logprob': [73.91988372802734, 21.0]}, 128)
batch 880: ({'logprob': [50.727176666259766, 13.0]}, 128)
batch 881: ({'logprob': [28.380556106567383, 5.0]}, 128)
batch 882: ({'logprob': [54.66423797607422, 14.0]}, 128)
batch 883: ({'logprob': [62.095882415771484, 17.0]}, 128)
batch 884: ({'logprob': [51.14931869506836, 13.0]}, 128)
batch 885: ({'logprob': [52.025997161865234, 13.0]}, 128)
batch 886: ({'logprob': [62.5439453125, 17.0]}, 128)

======================Test output======================
logprob:  0.415924, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.969712e-03 [2.694754e-09] 
Layer 'conv1' biases: 1.443984e-07 [8.239898e-11] 
Layer 'conv2' weights[0]: 7.956727e-03 [2.455868e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.278179e-10] 
Layer 'conv3' weights[0]: 7.955089e-03 [2.409830e-09] 
Layer 'conv3' biases: 1.257602e-06 [1.306865e-09] 
Layer 'conv4' weights[0]: 7.987595e-03 [2.664474e-09] 
Layer 'conv4' biases: 9.999996e-01 [1.215501e-08] 
Layer 'conv5' weights[0]: 7.986483e-03 [8.100525e-08] 
Layer 'conv5' biases: 9.999976e-01 [8.754041e-08] 
Layer 'fc6' weights[0]: 7.583334e-03 [6.910753e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.012523e-09] 
Layer 'fc7' weights[0]: 7.368148e-03 [2.471747e-07] 
Layer 'fc7' biases: 9.998649e-01 [2.352337e-07] 
Layer 'fc8' weights[0]: 1.327502e-03 [9.434458e-06] 
Layer 'fc8' biases: 3.523818e-02 [6.293365e-05] 
Train error last 870 batches: 0.435265
-------------------------------------------------------
Not saving because 0.415924 > 0.415707 (12.630: -0.00%)
======================================================= (12.071 sec)
15.471... logprob:  0.529746, 0.148438 (1.452 sec)
15.472... logprob:  0.410107, 0.109375 (1.462 sec)
15.473... logprob:  0.375308, 0.093750 (1.458 sec)
15.474... logprob:  0.465882, 0.125000 (1.452 sec)
15.475... logprob:  0.504552, 0.140625 (1.450 sec)
15.476... logprob:  0.510576, 0.140625 (1.476 sec)
15.477... logprob:  0.334470, 0.078125 (1.434 sec)
15.478... logprob:  0.464305, 0.125000 (1.429 sec)
15.479... logprob:  0.305806, 0.070312 (1.432 sec)
15.480... logprob:  0.443523, 0.117188 (1.442 sec)
15.481... logprob:  0.547718, 0.156250 (1.442 sec)
15.482... logprob:  0.443196, 0.117188 (1.478 sec)
15.483... logprob:  0.502540, 0.140625 (1.446 sec)
15.484... logprob:  0.485281, 0.132812 (1.442 sec)
15.485... logprob:  0.409135, 0.109375 (1.482 sec)
15.486... logprob:  0.361712, 0.085938 (1.438 sec)
15.487... logprob:  0.522595, 0.148438 (1.428 sec)
15.488... logprob:  0.424938, 0.109375 (1.437 sec)
15.489... logprob:  0.415985, 0.109375 (1.439 sec)
15.490... logprob:  0.440705, 0.117188 (1.431 sec)
15.491... logprob:  0.313729, 0.070312 (1.487 sec)
15.492... logprob:  0.459630, 0.125000 (1.438 sec)
15.493... logprob:  0.522010, 0.148438 (1.441 sec)
15.494... logprob:  0.450391, 0.125000 (1.487 sec)
15.495... logprob:  0.380517, 0.093750 (1.431 sec)
15.496... logprob:  0.550613, 0.156250 (1.438 sec)
15.497... logprob:  0.467083, 0.125000 (1.432 sec)
15.498... logprob:  0.476378, 0.132812 (1.434 sec)
15.499... logprob:  0.456296, 0.125000 (1.435 sec)
15.500... logprob:  0.355058, 0.085938 (1.491 sec)
15.501... logprob:  0.339106, 0.078125 (1.431 sec)
15.502... logprob:  0.459680, 0.125000 (1.448 sec)
15.503... logprob:  0.400699, 0.101562 (1.485 sec)
15.504... logprob:  0.487357, 0.132812 (1.438 sec)
15.505... logprob:  0.570815, 0.164062 (1.437 sec)
15.506... logprob:  0.479680, 0.132812 (1.438 sec)
15.507... logprob:  0.385171, 0.093750 (1.423 sec)
15.508... logprob:  0.374789, 0.093750 (1.464 sec)
15.509... logprob:  0.323280, 0.070312 (1.478 sec)
15.510... logprob:  0.390496, 0.101562 (1.444 sec)
15.511... logprob:  0.410093, 0.109375 (1.452 sec)
15.512... logprob:  0.470755, 0.125000 (1.468 sec)
15.513... logprob:  0.324980, 0.078125 (1.451 sec)
15.514... logprob:  0.406279, 0.101562 (1.444 sec)
15.515... logprob:  0.455633, 0.125000 (1.432 sec)
15.516... logprob:  0.400455, 0.109375 (1.427 sec)
15.517... logprob:  0.628132, 0.179688 (1.434 sec)
15.518... logprob:  0.437738, 0.117188 (1.458 sec)
15.519... logprob:  0.516164, 0.140625 (1.452 sec)
15.520... logprob:  0.409660, 0.109375 (1.459 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.957786560058594, 10.0]}, 128)
batch 872: ({'logprob': [66.38394165039062, 19.0]}, 128)
batch 873: ({'logprob': [40.825767517089844, 9.0]}, 128)
batch 874: ({'logprob': [45.384918212890625, 11.0]}, 128)
batch 875: ({'logprob': [50.850746154785156, 13.0]}, 128)
batch 876: ({'logprob': [63.89261245727539, 18.0]}, 128)
batch 877: ({'logprob': [45.84406280517578, 11.0]}, 128)
batch 878: ({'logprob': [61.81932830810547, 17.0]}, 128)
batch 879: ({'logprob': [73.21125030517578, 21.0]}, 128)
batch 880: ({'logprob': [50.86725997924805, 13.0]}, 128)
batch 881: ({'logprob': [29.402660369873047, 5.0]}, 128)
batch 882: ({'logprob': [54.73665237426758, 14.0]}, 128)
batch 883: ({'logprob': [61.8033447265625, 17.0]}, 128)
batch 884: ({'logprob': [51.30488967895508, 13.0]}, 128)
batch 885: ({'logprob': [52.21430206298828, 13.0]}, 128)
batch 886: ({'logprob': [62.26722717285156, 17.0]}, 128)

======================Test output======================
logprob:  0.416390, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.969668e-03 [2.917226e-09] 
Layer 'conv1' biases: 1.452119e-07 [6.527601e-11] 
Layer 'conv2' weights[0]: 7.956690e-03 [2.427098e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.607663e-10] 
Layer 'conv3' weights[0]: 7.955050e-03 [2.003542e-09] 
Layer 'conv3' biases: 1.268256e-06 [1.125729e-09] 
Layer 'conv4' weights[0]: 7.987557e-03 [2.067536e-09] 
Layer 'conv4' biases: 9.999996e-01 [9.190542e-09] 
Layer 'conv5' weights[0]: 7.986447e-03 [6.001722e-08] 
Layer 'conv5' biases: 9.999981e-01 [6.490426e-08] 
Layer 'fc6' weights[0]: 7.583293e-03 [5.209550e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.244476e-09] 
Layer 'fc7' weights[0]: 7.366259e-03 [2.443520e-07] 
Layer 'fc7' biases: 9.998645e-01 [2.333704e-07] 
Layer 'fc8' weights[0]: 1.307260e-03 [9.424521e-06] 
Layer 'fc8' biases: 3.518832e-02 [5.753977e-05] 
Train error last 870 batches: 0.435264
-------------------------------------------------------
Not saving because 0.416390 > 0.415707 (12.630: -0.00%)
======================================================= (11.951 sec)
15.521... logprob:  0.427543, 0.109375 (1.459 sec)
15.522... logprob:  0.533053, 0.156250 (1.464 sec)
15.523... logprob:  0.331843, 0.078125 (1.439 sec)
15.524... logprob:  0.437261, 0.117188 (1.424 sec)
15.525... logprob:  0.426137, 0.109375 (1.434 sec)
15.526... logprob:  0.352033, 0.078125 (1.439 sec)
15.527... logprob:  0.504533, 0.140625 (1.440 sec)
15.528... logprob:  0.440531, 0.117188 (1.474 sec)
15.529... logprob:  0.353020, 0.085938 (1.450 sec)
15.530... logprob:  0.440248, 0.117188 (1.443 sec)
15.531... logprob:  0.440028, 0.117188 (1.480 sec)
15.532... logprob:  0.467425, 0.125000 (1.437 sec)
15.533... logprob:  0.560802, 0.164062 (1.428 sec)
15.534... logprob:  0.325750, 0.078125 (1.438 sec)
15.535... logprob:  0.551753, 0.156250 (1.434 sec)
15.536... logprob:  0.507442, 0.140625 (1.437 sec)
15.537... logprob:  0.510104, 0.140625 (1.477 sec)
15.538... logprob:  0.486122, 0.132812 (1.449 sec)
15.539... logprob:  0.296179, 0.062500 (1.433 sec)
15.540... logprob:  0.447182, 0.117188 (1.485 sec)
15.541... logprob:  0.388919, 0.101562 (1.461 sec)
15.542... logprob:  0.411338, 0.109375 (1.428 sec)
15.543... logprob:  0.233453, 0.039062 (1.436 sec)
15.544... logprob:  0.317957, 0.070312 (1.434 sec)
15.545... logprob:  0.348816, 0.085938 (1.432 sec)
15.546... logprob:  0.368294, 0.093750 (1.489 sec)
15.547... logprob:  0.440179, 0.117188 (1.436 sec)
15.548... logprob:  0.453273, 0.125000 (1.446 sec)
15.549... logprob:  0.490800, 0.132812 (1.476 sec)
15.550... logprob:  0.367716, 0.093750 (1.435 sec)
15.551... logprob:  0.441844, 0.117188 (1.435 sec)
15.552... logprob:  0.471363, 0.125000 (1.439 sec)
15.553... logprob:  0.349432, 0.085938 (1.426 sec)
15.554... logprob:  0.506813, 0.140625 (1.438 sec)
15.555... logprob:  0.421415, 0.109375 (1.482 sec)
15.556... logprob:  0.355970, 0.085938 (1.443 sec)
15.557... logprob:  0.396519, 0.101562 (1.448 sec)
15.558... logprob:  0.383087, 0.101562 (1.478 sec)
15.559... logprob:  0.441417, 0.125000 (1.435 sec)
15.560... logprob:  0.335420, 0.078125 (1.443 sec)
15.561... logprob:  0.411862, 0.109375 (1.437 sec)
15.562... logprob:  0.503109, 0.140625 (1.431 sec)
15.563... logprob:  0.373889, 0.093750 (1.439 sec)
15.564... logprob:  0.468414, 0.132812 (1.465 sec)
15.565... logprob:  0.611016, 0.187500 (1.449 sec)
15.566... logprob:  0.374930, 0.093750 (1.461 sec)
15.567... logprob:  0.423477, 0.109375 (1.452 sec)
15.568... logprob:  0.496394, 0.140625 (1.477 sec)
15.569... logprob:  0.507895, 0.140625 (1.437 sec)
15.570... logprob:  0.543717, 0.164062 (1.431 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.49740982055664, 10.0]}, 128)
batch 872: ({'logprob': [65.70038604736328, 19.0]}, 128)
batch 873: ({'logprob': [42.518089294433594, 9.0]}, 128)
batch 874: ({'logprob': [46.247291564941406, 11.0]}, 128)
batch 875: ({'logprob': [51.47639846801758, 13.0]}, 128)
batch 876: ({'logprob': [63.474605560302734, 18.0]}, 128)
batch 877: ({'logprob': [47.00304412841797, 11.0]}, 128)
batch 878: ({'logprob': [61.965694427490234, 17.0]}, 128)
batch 879: ({'logprob': [73.17326354980469, 21.0]}, 128)
batch 880: ({'logprob': [51.49119186401367, 13.0]}, 128)
batch 881: ({'logprob': [31.2795467376709, 5.0]}, 128)
batch 882: ({'logprob': [55.978214263916016, 14.0]}, 128)
batch 883: ({'logprob': [61.95021057128906, 17.0]}, 128)
batch 884: ({'logprob': [52.222984313964844, 13.0]}, 128)
batch 885: ({'logprob': [53.72260665893555, 13.0]}, 128)
batch 886: ({'logprob': [62.707515716552734, 17.0]}, 128)

======================Test output======================
logprob:  0.421586, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.969628e-03 [2.796029e-09] 
Layer 'conv1' biases: 1.460464e-07 [6.615891e-11] 
Layer 'conv2' weights[0]: 7.956652e-03 [2.579661e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.493184e-10] 
Layer 'conv3' weights[0]: 7.955004e-03 [2.423928e-09] 
Layer 'conv3' biases: 1.275010e-06 [1.437597e-09] 
Layer 'conv4' weights[0]: 7.987525e-03 [2.503567e-09] 
Layer 'conv4' biases: 9.999996e-01 [1.249726e-08] 
Layer 'conv5' weights[0]: 7.986416e-03 [8.290809e-08] 
Layer 'conv5' biases: 9.999979e-01 [8.940410e-08] 
Layer 'fc6' weights[0]: 7.583253e-03 [7.055346e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.158615e-09] 
Layer 'fc7' weights[0]: 7.364403e-03 [1.831632e-07] 
Layer 'fc7' biases: 9.998641e-01 [1.722832e-07] 
Layer 'fc8' weights[0]: 1.277841e-03 [7.534700e-06] 
Layer 'fc8' biases: 3.510633e-02 [4.676751e-05] 
Train error last 870 batches: 0.435264
-------------------------------------------------------
Not saving because 0.421586 > 0.415707 (12.630: -0.00%)
======================================================= (12.020 sec)
15.571... logprob:  0.454873, 0.125000 (1.437 sec)
15.572... logprob:  0.501512, 0.140625 (1.440 sec)
15.573... logprob:  0.512642, 0.148438 (1.440 sec)
15.574... logprob:  0.428180, 0.109375 (1.490 sec)
15.575... logprob:  0.343373, 0.078125 (1.450 sec)
15.576... logprob:  0.427424, 0.109375 (1.449 sec)
15.577... logprob:  0.460860, 0.125000 (1.474 sec)
15.578... logprob:  0.336542, 0.078125 (1.436 sec)
15.579... logprob:  0.442092, 0.117188 (1.429 sec)
15.580... logprob:  0.547027, 0.156250 (1.434 sec)
15.581... logprob:  0.531102, 0.156250 (1.438 sec)
15.582... logprob:  0.437927, 0.125000 (1.439 sec)
15.583... logprob:  0.592970, 0.171875 (1.475 sec)
15.584... logprob:  0.468143, 0.132812 (1.447 sec)
15.585... logprob:  0.349768, 0.085938 (1.434 sec)
15.586... logprob:  0.313180, 0.070312 (1.493 sec)
15.587... logprob:  0.404321, 0.101562 (1.431 sec)
15.588... logprob:  0.418678, 0.117188 (1.431 sec)
15.589... logprob:  0.361337, 0.093750 (1.437 sec)
15.590... logprob:  0.524684, 0.148438 (1.437 sec)
15.591... logprob:  0.397531, 0.101562 (1.431 sec)
15.592... logprob:  0.455640, 0.125000 (1.488 sec)
15.593... logprob:  0.467445, 0.125000 (1.435 sec)
15.594... logprob:  0.352886, 0.085938 (1.445 sec)
15.595... logprob:  0.428674, 0.109375 (1.481 sec)
15.596... logprob:  0.461576, 0.125000 (1.438 sec)
15.597... logprob:  0.397412, 0.101562 (1.430 sec)
15.598... logprob:  0.397234, 0.101562 (1.441 sec)
15.599... logprob:  0.313493, 0.070312 (1.505 sec)
15.600... logprob:  0.340901, 0.085938 (1.435 sec)
15.601... logprob:  0.402117, 0.101562 (1.485 sec)
15.602... logprob:  0.289645, 0.062500 (1.440 sec)
15.603... logprob:  0.266886, 0.054688 (1.444 sec)
15.604... logprob:  0.407513, 0.101562 (1.478 sec)
15.605... logprob:  0.563661, 0.148438 (1.439 sec)
15.606... logprob:  0.295949, 0.070312 (1.437 sec)
15.607... logprob:  0.504975, 0.132812 (1.436 sec)
15.608... logprob:  0.361652, 0.085938 (1.424 sec)
15.609... logprob:  0.356905, 0.085938 (1.440 sec)
15.610... logprob:  0.493460, 0.132812 (1.470 sec)
15.611... logprob:  0.510454, 0.140625 (1.451 sec)
15.612... logprob:  0.448368, 0.117188 (1.452 sec)
15.613... logprob:  0.279879, 0.062500 (1.464 sec)
15.614... logprob:  0.503505, 0.140625 (1.452 sec)
15.615... logprob:  0.351238, 0.085938 (1.472 sec)
15.616... logprob:  0.415400, 0.109375 (1.431 sec)
15.617... logprob:  0.418001, 0.109375 (1.428 sec)
15.618... logprob:  0.546636, 0.156250 (1.438 sec)
15.619... logprob:  0.505917, 0.140625 (1.452 sec)
15.620... logprob:  0.539606, 0.156250 (1.454 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.34310531616211, 10.0]}, 128)
batch 872: ({'logprob': [66.23114013671875, 19.0]}, 128)
batch 873: ({'logprob': [41.76369857788086, 9.0]}, 128)
batch 874: ({'logprob': [46.319862365722656, 11.0]}, 128)
batch 875: ({'logprob': [51.4244499206543, 13.0]}, 128)
batch 876: ({'logprob': [63.83074951171875, 18.0]}, 128)
batch 877: ({'logprob': [46.60098648071289, 11.0]}, 128)
batch 878: ({'logprob': [61.66965103149414, 17.0]}, 128)
batch 879: ({'logprob': [72.15980529785156, 21.0]}, 128)
batch 880: ({'logprob': [51.441219329833984, 13.0]}, 128)
batch 881: ({'logprob': [31.24390983581543, 5.0]}, 128)
batch 882: ({'logprob': [54.679805755615234, 14.0]}, 128)
batch 883: ({'logprob': [61.653472900390625, 17.0]}, 128)
batch 884: ({'logprob': [51.69755554199219, 13.0]}, 128)
batch 885: ({'logprob': [52.2474479675293, 13.0]}, 128)
batch 886: ({'logprob': [61.936946868896484, 17.0]}, 128)

======================Test output======================
logprob:  0.419064, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.969592e-03 [4.611563e-09] 
Layer 'conv1' biases: 1.468681e-07 [8.077008e-11] 
Layer 'conv2' weights[0]: 7.956609e-03 [3.348695e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.934838e-10] 
Layer 'conv3' weights[0]: 7.954963e-03 [2.812082e-09] 
Layer 'conv3' biases: 1.282439e-06 [1.583888e-09] 
Layer 'conv4' weights[0]: 7.987487e-03 [2.965185e-09] 
Layer 'conv4' biases: 9.999996e-01 [1.357747e-08] 
Layer 'conv5' weights[0]: 7.986370e-03 [9.013837e-08] 
Layer 'conv5' biases: 9.999983e-01 [9.737393e-08] 
Layer 'fc6' weights[0]: 7.583216e-03 [7.673487e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.770289e-09] 
Layer 'fc7' weights[0]: 7.362581e-03 [2.808766e-07] 
Layer 'fc7' biases: 9.998634e-01 [2.705806e-07] 
Layer 'fc8' weights[0]: 1.281243e-03 [9.924898e-06] 
Layer 'fc8' biases: 3.529168e-02 [6.259841e-05] 
Train error last 870 batches: 0.435264
-------------------------------------------------------
Not saving because 0.419064 > 0.415707 (12.630: -0.00%)
======================================================= (12.055 sec)
15.621... logprob:  0.363989, 0.085938 (1.461 sec)
15.622... logprob:  0.364995, 0.085938 (1.458 sec)
15.623... logprob:  0.423236, 0.109375 (1.466 sec)
15.624... logprob:  0.382561, 0.093750 (1.441 sec)
15.625... logprob:  0.441010, 0.117188 (1.424 sec)
15.626... logprob:  0.438403, 0.117188 (1.436 sec)
15.627... logprob:  0.435870, 0.117188 (1.437 sec)
15.628... logprob:  0.465114, 0.125000 (1.442 sec)
15.629... logprob:  0.371963, 0.093750 (1.472 sec)
15.630... logprob:  0.422373, 0.109375 (1.450 sec)
15.631... logprob:  0.639531, 0.187500 (1.436 sec)
15.632... logprob:  0.399098, 0.101562 (1.488 sec)
15.633... logprob:  0.376007, 0.093750 (1.432 sec)
15.634... logprob:  0.660541, 0.195312 (1.432 sec)
15.635... logprob:  0.374126, 0.093750 (1.438 sec)
15.636... logprob:  0.480225, 0.132812 (1.435 sec)
15.637... logprob:  0.330997, 0.078125 (1.432 sec)
15.638... logprob:  0.515658, 0.140625 (1.479 sec)
15.639... logprob:  0.418185, 0.109375 (1.439 sec)
15.640... logprob:  0.528747, 0.148438 (1.440 sec)
15.641... logprob:  0.410508, 0.109375 (1.484 sec)
15.642... logprob:  0.500800, 0.140625 (1.438 sec)
15.643... logprob:  0.622757, 0.187500 (1.428 sec)
15.644... logprob:  0.321509, 0.070312 (1.434 sec)
15.645... logprob:  0.414520, 0.109375 (1.427 sec)
15.646... logprob:  0.385789, 0.093750 (1.438 sec)
15.647... logprob:  0.456743, 0.125000 (1.486 sec)
15.648... logprob:  0.491227, 0.140625 (1.464 sec)
15.649... logprob:  0.370071, 0.093750 (1.440 sec)
15.650... logprob:  0.413917, 0.109375 (1.476 sec)
15.651... logprob:  0.397283, 0.101562 (1.434 sec)
15.652... logprob:  0.507462, 0.140625 (1.438 sec)
15.653... logprob:  0.548225, 0.156250 (1.437 sec)
15.654... logprob:  0.496182, 0.140625 (1.425 sec)
15.655... logprob:  0.436219, 0.117188 (1.437 sec)
15.656... logprob:  0.416668, 0.109375 (1.481 sec)
15.657... logprob:  0.449314, 0.117188 (1.441 sec)
15.658... logprob:  0.345746, 0.085938 (1.456 sec)
15.659... logprob:  0.464365, 0.125000 (1.466 sec)
15.660... logprob:  0.445887, 0.125000 (1.443 sec)
15.661... logprob:  0.378572, 0.093750 (1.443 sec)
15.662... logprob:  0.469319, 0.132812 (1.429 sec)
15.663... logprob:  0.311087, 0.070312 (1.431 sec)
15.664... logprob:  0.285541, 0.062500 (1.436 sec)
15.665... logprob:  0.401879, 0.101562 (1.463 sec)
15.666... logprob:  0.442074, 0.117188 (1.455 sec)
15.667... logprob:  0.564333, 0.164062 (1.454 sec)
15.668... logprob:  0.497932, 0.140625 (1.454 sec)
15.669... logprob:  0.433124, 0.109375 (1.464 sec)
15.670... logprob:  0.362508, 0.085938 (1.439 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.13917541503906, 10.0]}, 128)
batch 872: ({'logprob': [66.66602325439453, 19.0]}, 128)
batch 873: ({'logprob': [40.68229293823242, 9.0]}, 128)
batch 874: ({'logprob': [45.04874038696289, 11.0]}, 128)
batch 875: ({'logprob': [50.78487014770508, 13.0]}, 128)
batch 876: ({'logprob': [64.1554183959961, 18.0]}, 128)
batch 877: ({'logprob': [45.738548278808594, 11.0]}, 128)
batch 878: ({'logprob': [62.29386901855469, 17.0]}, 128)
batch 879: ({'logprob': [74.45631408691406, 21.0]}, 128)
batch 880: ({'logprob': [50.800865173339844, 13.0]}, 128)
batch 881: ({'logprob': [28.487014770507812, 5.0]}, 128)
batch 882: ({'logprob': [55.38473892211914, 14.0]}, 128)
batch 883: ({'logprob': [62.27790451049805, 17.0]}, 128)
batch 884: ({'logprob': [51.47116470336914, 13.0]}, 128)
batch 885: ({'logprob': [52.8435173034668, 13.0]}, 128)
batch 886: ({'logprob': [62.973670959472656, 17.0]}, 128)

======================Test output======================
logprob:  0.417580, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.969545e-03 [2.643533e-09] 
Layer 'conv1' biases: 1.476316e-07 [3.733322e-11] 
Layer 'conv2' weights[0]: 7.956582e-03 [1.631871e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.767527e-10] 
Layer 'conv3' weights[0]: 7.954928e-03 [1.282348e-09] 
Layer 'conv3' biases: 1.287440e-06 [5.268064e-10] 
Layer 'conv4' weights[0]: 7.987447e-03 [1.222651e-09] 
Layer 'conv4' biases: 9.999996e-01 [3.575343e-09] 
Layer 'conv5' weights[0]: 7.986339e-03 [2.091646e-08] 
Layer 'conv5' biases: 9.999976e-01 [2.226310e-08] 
Layer 'fc6' weights[0]: 7.583177e-03 [1.950091e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.791759e-09] 
Layer 'fc7' weights[0]: 7.360643e-03 [8.723308e-08] 
Layer 'fc7' biases: 9.998652e-01 [7.276276e-08] 
Layer 'fc8' weights[0]: 1.331139e-03 [2.896021e-06] 
Layer 'fc8' biases: 3.571025e-02 [1.662743e-05] 
Train error last 870 batches: 0.435263
-------------------------------------------------------
Not saving because 0.417580 > 0.415707 (12.630: -0.00%)
======================================================= (12.058 sec)
15.671... logprob:  0.360853, 0.093750 (1.427 sec)
15.672... logprob:  0.441810, 0.117188 (1.436 sec)
15.673... logprob:  0.436249, 0.117188 (1.432 sec)
15.674... logprob:  0.446673, 0.117188 (1.450 sec)
15.675... logprob:  0.356666, 0.093750 (1.463 sec)
15.676... logprob:  0.450144, 0.125000 (1.453 sec)
15.677... logprob:  0.471065, 0.125000 (1.443 sec)
15.678... logprob:  0.465639, 0.125000 (1.484 sec)
15.679... logprob:  0.454876, 0.125000 (1.430 sec)
15.680... logprob:  0.351748, 0.078125 (1.431 sec)
15.681... logprob:  0.373959, 0.093750 (1.443 sec)
15.682... logprob:  0.340512, 0.078125 (1.441 sec)
15.683... logprob:  0.411651, 0.109375 (1.433 sec)
15.684... logprob:  0.357583, 0.085938 (1.481 sec)
15.685... logprob:  0.285802, 0.054688 (1.444 sec)
15.686... logprob:  0.318470, 0.070312 (1.434 sec)
15.687... logprob:  0.281466, 0.062500 (1.491 sec)
15.688... logprob:  0.323069, 0.078125 (1.434 sec)
15.689... logprob:  0.471649, 0.125000 (1.434 sec)
15.690... logprob:  0.528247, 0.140625 (1.438 sec)
15.691... logprob:  0.517241, 0.140625 (1.429 sec)
15.692... logprob:  0.385422, 0.101562 (1.438 sec)
15.693... logprob:  0.456130, 0.125000 (1.484 sec)
15.694... logprob:  0.330881, 0.078125 (1.439 sec)
15.695... logprob:  0.356883, 0.085938 (1.444 sec)
15.696... logprob:  0.538693, 0.148438 (1.479 sec)
15.697... logprob:  0.465546, 0.125000 (1.435 sec)
15.698... logprob:  0.548423, 0.156250 (1.439 sec)
15.699... logprob:  0.459576, 0.125000 (1.436 sec)
15.700... logprob:  0.434086, 0.117188 (1.427 sec)
15.701... logprob:  0.423438, 0.109375 (1.436 sec)
15.702... logprob:  0.521428, 0.148438 (1.484 sec)
15.703... logprob:  0.405645, 0.101562 (1.441 sec)
15.704... logprob:  0.406417, 0.101562 (1.449 sec)
15.705... logprob:  0.420346, 0.109375 (1.476 sec)
15.706... logprob:  0.468084, 0.125000 (1.439 sec)
15.707... logprob:  0.485300, 0.132812 (1.436 sec)
15.708... logprob:  0.417007, 0.109375 (1.437 sec)
15.709... logprob:  0.422391, 0.109375 (1.426 sec)
15.710... logprob:  0.602939, 0.179688 (1.442 sec)
15.711... logprob:  0.469546, 0.125000 (1.462 sec)
15.712... logprob:  0.340215, 0.078125 (1.448 sec)
15.713... logprob:  0.587533, 0.179688 (1.451 sec)
15.714... logprob:  0.466357, 0.125000 (1.453 sec)
15.715... logprob:  0.417126, 0.109375 (1.457 sec)
15.716... logprob:  0.335200, 0.078125 (1.437 sec)
15.717... logprob:  0.429849, 0.117188 (1.429 sec)
15.718... logprob:  0.490398, 0.132812 (1.427 sec)
15.719... logprob:  0.406205, 0.109375 (1.447 sec)
15.720... logprob:  0.433241, 0.117188 (1.445 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.63844680786133, 10.0]}, 128)
batch 872: ({'logprob': [66.63156127929688, 19.0]}, 128)
batch 873: ({'logprob': [40.50931167602539, 9.0]}, 128)
batch 874: ({'logprob': [45.15839767456055, 11.0]}, 128)
batch 875: ({'logprob': [50.75189971923828, 13.0]}, 128)
batch 876: ({'logprob': [64.08619689941406, 18.0]}, 128)
batch 877: ({'logprob': [45.63612365722656, 11.0]}, 128)
batch 878: ({'logprob': [61.97688674926758, 17.0]}, 128)
batch 879: ({'logprob': [73.64384460449219, 21.0]}, 128)
batch 880: ({'logprob': [50.76850509643555, 13.0]}, 128)
batch 881: ({'logprob': [28.81045150756836, 5.0]}, 128)
batch 882: ({'logprob': [54.75010299682617, 14.0]}, 128)
batch 883: ({'logprob': [61.960784912109375, 17.0]}, 128)
batch 884: ({'logprob': [51.2258415222168, 13.0]}, 128)
batch 885: ({'logprob': [52.17337417602539, 13.0]}, 128)
batch 886: ({'logprob': [62.44418716430664, 17.0]}, 128)

======================Test output======================
logprob:  0.416097, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.969504e-03 [1.871947e-09] 
Layer 'conv1' biases: 1.482407e-07 [4.453408e-11] 
Layer 'conv2' weights[0]: 7.956546e-03 [1.369877e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.814792e-10] 
Layer 'conv3' weights[0]: 7.954884e-03 [1.218858e-09] 
Layer 'conv3' biases: 1.292721e-06 [5.169545e-10] 
Layer 'conv4' weights[0]: 7.987408e-03 [1.149396e-09] 
Layer 'conv4' biases: 9.999996e-01 [3.100279e-09] 
Layer 'conv5' weights[0]: 7.986289e-03 [1.364532e-08] 
Layer 'conv5' biases: 9.999976e-01 [1.382287e-08] 
Layer 'fc6' weights[0]: 7.583140e-03 [1.305172e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.041952e-09] 
Layer 'fc7' weights[0]: 7.358734e-03 [6.551775e-08] 
Layer 'fc7' biases: 9.998646e-01 [4.718646e-08] 
Layer 'fc8' weights[0]: 1.322413e-03 [5.081877e-06] 
Layer 'fc8' biases: 3.588840e-02 [3.330740e-05] 
Train error last 870 batches: 0.435263
-------------------------------------------------------
Not saving because 0.416097 > 0.415707 (12.630: -0.00%)
======================================================= (12.124 sec)
15.721... logprob:  0.451599, 0.117188 (1.468 sec)
15.722... logprob:  0.536801, 0.156250 (1.455 sec)
15.723... logprob:  0.416616, 0.109375 (1.445 sec)
15.724... logprob:  0.412786, 0.109375 (1.470 sec)
15.725... logprob:  0.494617, 0.140625 (1.441 sec)
15.726... logprob:  0.338740, 0.085938 (1.424 sec)
15.727... logprob:  0.393417, 0.101562 (1.434 sec)
15.728... logprob:  0.421398, 0.109375 (1.443 sec)
15.729... logprob:  0.387845, 0.093750 (1.435 sec)
15.730... logprob:  0.565814, 0.164062 (1.475 sec)
15.731... logprob:  0.450313, 0.125000 (1.451 sec)
15.732... logprob:  0.311498, 0.070312 (1.432 sec)
15.733... logprob:  0.556740, 0.156250 (1.493 sec)
15.734... logprob:  0.340216, 0.078125 (1.430 sec)
15.735... logprob:  0.527666, 0.148438 (1.435 sec)
15.736... logprob:  0.643135, 0.187500 (1.434 sec)
15.737... logprob:  0.516230, 0.148438 (1.438 sec)
15.738... logprob:  0.459442, 0.125000 (1.431 sec)
15.739... logprob:  0.477822, 0.132812 (1.488 sec)
15.740... logprob:  0.339667, 0.078125 (1.435 sec)
15.741... logprob:  0.393449, 0.101562 (1.442 sec)
15.742... logprob:  0.419753, 0.109375 (1.484 sec)
15.743... logprob:  0.364873, 0.085938 (1.437 sec)
15.744... logprob:  0.519272, 0.148438 (1.431 sec)
15.745... logprob:  0.478188, 0.132812 (1.441 sec)
15.746... logprob:  0.440564, 0.117188 (1.429 sec)
15.747... logprob:  0.425636, 0.109375 (1.438 sec)
15.748... logprob:  0.378039, 0.093750 (1.484 sec)
15.749... logprob:  0.420854, 0.109375 (1.432 sec)
15.750... logprob:  0.512946, 0.140625 (1.444 sec)
15.751... logprob:  0.263507, 0.054688 (1.478 sec)
15.752... logprob:  0.522521, 0.140625 (1.434 sec)
15.753... logprob:  0.441271, 0.117188 (1.439 sec)
15.754... logprob:  0.468613, 0.132812 (1.435 sec)
15.755... logprob:  0.507130, 0.140625 (1.460 sec)
15.756... logprob:  0.440823, 0.117188 (1.439 sec)
15.757... logprob:  0.552264, 0.156250 (1.471 sec)
15.758... logprob:  0.393735, 0.101562 (1.443 sec)
15.759... logprob:  0.459691, 0.125000 (1.450 sec)
15.760... logprob:  0.485392, 0.132812 (1.460 sec)
15.761... logprob:  0.418433, 0.109375 (1.448 sec)
15.762... logprob:  0.515969, 0.148438 (1.443 sec)
15.763... logprob:  0.558752, 0.164062 (1.423 sec)
15.764... logprob:  0.503295, 0.140625 (1.427 sec)
15.765... logprob:  0.312353, 0.062500 (1.437 sec)
15.766... logprob:  0.482311, 0.132812 (1.459 sec)
15.767... logprob:  0.371186, 0.085938 (1.454 sec)
15.768... logprob:  0.432716, 0.117188 (1.465 sec)
15.769... logprob:  0.490918, 0.140625 (1.471 sec)
15.770... logprob:  0.402796, 0.101562 (1.483 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.34122848510742, 10.0]}, 128)
batch 872: ({'logprob': [66.22860717773438, 19.0]}, 128)
batch 873: ({'logprob': [41.140357971191406, 9.0]}, 128)
batch 874: ({'logprob': [45.6502685546875, 11.0]}, 128)
batch 875: ({'logprob': [50.99245834350586, 13.0]}, 128)
batch 876: ({'logprob': [63.78066635131836, 18.0]}, 128)
batch 877: ({'logprob': [46.07257843017578, 11.0]}, 128)
batch 878: ({'logprob': [61.71338653564453, 17.0]}, 128)
batch 879: ({'logprob': [72.82032775878906, 21.0]}, 128)
batch 880: ({'logprob': [51.008968353271484, 13.0]}, 128)
batch 881: ({'logprob': [30.0024356842041, 5.0]}, 128)
batch 882: ({'logprob': [54.72264099121094, 14.0]}, 128)
batch 883: ({'logprob': [61.69723129272461, 17.0]}, 128)
batch 884: ({'logprob': [51.40864562988281, 13.0]}, 128)
batch 885: ({'logprob': [52.243011474609375, 13.0]}, 128)
batch 886: ({'logprob': [62.12345504760742, 17.0]}, 128)

======================Test output======================
logprob:  0.416966, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.969471e-03 [2.483667e-09] 
Layer 'conv1' biases: 1.490147e-07 [9.552463e-11] 
Layer 'conv2' weights[0]: 7.956513e-03 [2.115992e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.416145e-10] 
Layer 'conv3' weights[0]: 7.954848e-03 [2.245378e-09] 
Layer 'conv3' biases: 1.298380e-06 [1.298662e-09] 
Layer 'conv4' weights[0]: 7.987375e-03 [2.473990e-09] 
Layer 'conv4' biases: 9.999996e-01 [1.286691e-08] 
Layer 'conv5' weights[0]: 7.986250e-03 [8.699830e-08] 
Layer 'conv5' biases: 9.999973e-01 [9.432929e-08] 
Layer 'fc6' weights[0]: 7.583103e-03 [7.380705e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.470753e-09] 
Layer 'fc7' weights[0]: 7.356860e-03 [2.665523e-07] 
Layer 'fc7' biases: 9.998640e-01 [2.550885e-07] 
Layer 'fc8' weights[0]: 1.300097e-03 [9.186616e-06] 
Layer 'fc8' biases: 3.585616e-02 [6.404980e-05] 
Train error last 870 batches: 0.435263
-------------------------------------------------------
Not saving because 0.416966 > 0.415707 (12.630: -0.00%)
======================================================= (11.995 sec)
15.771... logprob:  0.549732, 0.156250 (1.457 sec)
15.772... logprob:  0.414023, 0.109375 (1.449 sec)
15.773... logprob:  0.558248, 0.164062 (1.441 sec)
15.774... logprob:  0.361485, 0.085938 (1.457 sec)
15.775... logprob:  0.407312, 0.101562 (1.464 sec)
15.776... logprob:  0.433260, 0.117188 (1.480 sec)
15.777... logprob:  0.379912, 0.093750 (1.472 sec)
15.778... logprob:  0.433637, 0.117188 (1.468 sec)
15.779... logprob:  0.505502, 0.140625 (1.486 sec)
15.780... logprob:  0.385757, 0.101562 (1.459 sec)
15.781... logprob:  0.369746, 0.085938 (1.451 sec)
15.782... logprob:  0.351528, 0.085938 (1.445 sec)
15.783... logprob:  0.555452, 0.156250 (1.464 sec)
15.784... logprob:  0.440957, 0.117188 (1.456 sec)
15.785... logprob:  0.543486, 0.156250 (1.491 sec)
15.786... logprob:  0.477368, 0.132812 (1.470 sec)
15.787... logprob:  0.546124, 0.156250 (1.457 sec)
15.788... logprob:  0.562821, 0.164062 (1.496 sec)
15.789... logprob:  0.281600, 0.054688 (1.449 sec)
15.790... logprob:  0.408396, 0.101562 (1.453 sec)
15.791... logprob:  0.398214, 0.101562 (1.446 sec)
15.792... logprob:  0.361319, 0.085938 (1.460 sec)
15.793... logprob:  0.370323, 0.085938 (1.451 sec)
15.794... logprob:  0.387125, 0.093750 (1.490 sec)
15.795... logprob:  0.469847, 0.125000 (1.465 sec)
15.796... logprob:  0.423499, 0.109375 (1.454 sec)
15.797... logprob:  0.358670, 0.085938 (1.498 sec)
15.798... logprob:  0.393261, 0.101562 (1.455 sec)
15.799... logprob:  0.332118, 0.078125 (1.450 sec)
15.800... logprob:  0.371803, 0.093750 (1.453 sec)
15.801... logprob:  0.450415, 0.117188 (1.458 sec)
15.802... logprob:  0.423208, 0.109375 (1.454 sec)
15.803... logprob:  0.492116, 0.132812 (1.493 sec)
15.804... logprob:  0.349992, 0.085938 (1.469 sec)
15.805... logprob:  0.452301, 0.117188 (1.450 sec)
15.806... logprob:  0.424188, 0.109375 (1.498 sec)
15.807... logprob:  0.443445, 0.117188 (1.458 sec)
15.808... logprob:  0.462330, 0.125000 (1.451 sec)
15.809... logprob:  0.589381, 0.171875 (1.451 sec)
15.810... logprob:  0.442435, 0.117188 (1.456 sec)
15.811... logprob:  0.460421, 0.125000 (1.455 sec)
15.812... logprob:  0.462445, 0.125000 (1.498 sec)
15.813... logprob:  0.485999, 0.132812 (1.461 sec)
15.814... logprob:  0.478192, 0.132812 (1.458 sec)
15.815... logprob:  0.372504, 0.085938 (1.498 sec)
15.816... logprob:  0.409088, 0.101562 (1.451 sec)
15.817... logprob:  0.426192, 0.109375 (1.452 sec)
15.818... logprob:  0.559964, 0.164062 (1.450 sec)
15.819... logprob:  0.498222, 0.140625 (1.457 sec)
15.820... logprob:  0.421523, 0.109375 (1.458 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.310096740722656, 10.0]}, 128)
batch 872: ({'logprob': [66.19103240966797, 19.0]}, 128)
batch 873: ({'logprob': [41.792510986328125, 9.0]}, 128)
batch 874: ({'logprob': [46.313655853271484, 11.0]}, 128)
batch 875: ({'logprob': [51.41876983642578, 13.0]}, 128)
batch 876: ({'logprob': [63.799381256103516, 18.0]}, 128)
batch 877: ({'logprob': [46.612430572509766, 11.0]}, 128)
batch 878: ({'logprob': [61.664695739746094, 17.0]}, 128)
batch 879: ({'logprob': [72.17324829101562, 21.0]}, 128)
batch 880: ({'logprob': [51.4354133605957, 13.0]}, 128)
batch 881: ({'logprob': [31.25421905517578, 5.0]}, 128)
batch 882: ({'logprob': [54.718536376953125, 14.0]}, 128)
batch 883: ({'logprob': [61.64855194091797, 17.0]}, 128)
batch 884: ({'logprob': [51.7094612121582, 13.0]}, 128)
batch 885: ({'logprob': [52.29487228393555, 13.0]}, 128)
batch 886: ({'logprob': [61.949729919433594, 17.0]}, 128)

======================Test output======================
logprob:  0.419085, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.969433e-03 [2.988129e-09] 
Layer 'conv1' biases: 1.499131e-07 [1.000997e-10] 
Layer 'conv2' weights[0]: 7.956482e-03 [2.107349e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.082426e-10] 
Layer 'conv3' weights[0]: 7.954812e-03 [2.085891e-09] 
Layer 'conv3' biases: 1.307209e-06 [1.190716e-09] 
Layer 'conv4' weights[0]: 7.987340e-03 [2.285686e-09] 
Layer 'conv4' biases: 9.999996e-01 [1.176717e-08] 
Layer 'conv5' weights[0]: 7.986202e-03 [8.013244e-08] 
Layer 'conv5' biases: 9.999974e-01 [8.690097e-08] 
Layer 'fc6' weights[0]: 7.583054e-03 [6.737120e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.842367e-09] 
Layer 'fc7' weights[0]: 7.354989e-03 [1.866884e-07] 
Layer 'fc7' biases: 9.998633e-01 [1.747555e-07] 
Layer 'fc8' weights[0]: 1.277695e-03 [6.003504e-06] 
Layer 'fc8' biases: 3.592639e-02 [4.598718e-05] 
Train error last 870 batches: 0.435262
-------------------------------------------------------
Not saving because 0.419085 > 0.415707 (12.630: -0.00%)
======================================================= (12.026 sec)
15.821... logprob:  0.406382, 0.101562 (1.505 sec)
15.822... logprob:  0.441057, 0.117188 (1.466 sec)
15.823... logprob:  0.340339, 0.078125 (1.214 sec)
15.824... logprob:  0.490076, 0.132812 (0.716 sec)
15.825... logprob:  0.287359, 0.062500 (0.683 sec)
15.826... logprob:  0.375316, 0.093750 (0.693 sec)
15.827... logprob:  0.420682, 0.109375 (0.688 sec)
15.828... logprob:  0.443711, 0.117188 (0.687 sec)
15.829... logprob:  0.504820, 0.140625 (0.691 sec)
15.830... logprob:  0.442413, 0.117188 (1.517 sec)
15.831... logprob:  0.514185, 0.140625 (1.451 sec)
15.832... logprob:  0.330867, 0.078125 (1.467 sec)
15.833... logprob:  0.488930, 0.132812 (1.491 sec)
15.834... logprob:  0.433159, 0.117188 (1.452 sec)
15.835... logprob:  0.542393, 0.148438 (1.453 sec)
15.836... logprob:  0.376396, 0.093750 (1.444 sec)
15.837... logprob:  0.314955, 0.070312 (1.456 sec)
15.838... logprob:  0.437101, 0.117188 (1.454 sec)
15.839... logprob:  0.471751, 0.125000 (1.500 sec)
15.840... logprob:  0.555192, 0.156250 (1.452 sec)
15.841... logprob:  0.396339, 0.101562 (1.463 sec)
15.842... logprob:  0.497789, 0.140625 (1.495 sec)
15.843... logprob:  0.465561, 0.125000 (1.452 sec)
15.844... logprob:  0.497605, 0.140625 (1.460 sec)
15.845... logprob:  0.486848, 0.132812 (1.453 sec)
15.846... logprob:  0.468506, 0.125000 (1.452 sec)
15.847... logprob:  0.363108, 0.085938 (1.451 sec)
15.848... logprob:  0.396964, 0.101562 (1.502 sec)
15.849... logprob:  0.360171, 0.085938 (1.455 sec)
15.850... logprob:  0.479457, 0.132812 (1.468 sec)
15.851... logprob:  0.440160, 0.117188 (1.502 sec)
15.852... logprob:  0.546011, 0.156250 (1.451 sec)
15.853... logprob:  0.371738, 0.093750 (1.458 sec)
15.854... logprob:  0.306925, 0.070312 (1.448 sec)
15.855... logprob:  0.485043, 0.132812 (1.449 sec)
15.856... logprob:  0.443901, 0.117188 (1.453 sec)
15.857... logprob:  0.372247, 0.093750 (1.498 sec)
15.858... logprob:  0.396248, 0.101562 (1.462 sec)
15.859... logprob:  0.307947, 0.070312 (1.473 sec)
15.860... logprob:  0.565938, 0.156250 (1.483 sec)
15.861... logprob:  0.417823, 0.109375 (1.453 sec)
15.862... logprob:  0.328960, 0.078125 (1.463 sec)
15.863... logprob:  0.399504, 0.101562 (1.447 sec)
15.864... logprob:  0.451370, 0.117188 (1.471 sec)
15.865... logprob:  0.484353, 0.132812 (1.463 sec)
15.866... logprob:  0.507444, 0.140625 (1.490 sec)
15.867... logprob:  0.502767, 0.140625 (1.465 sec)
15.868... logprob:  0.405432, 0.101562 (1.471 sec)
15.869... logprob:  0.383402, 0.093750 (1.481 sec)
15.870... logprob:  0.551899, 0.156250 (1.397 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.73651123046875, 10.0]}, 128)
batch 872: ({'logprob': [66.27859497070312, 19.0]}, 128)
batch 873: ({'logprob': [41.26882553100586, 9.0]}, 128)
batch 874: ({'logprob': [45.869380950927734, 11.0]}, 128)
batch 875: ({'logprob': [51.12493896484375, 13.0]}, 128)
batch 876: ({'logprob': [63.82979202270508, 18.0]}, 128)
batch 877: ({'logprob': [46.20339584350586, 11.0]}, 128)
batch 878: ({'logprob': [61.672882080078125, 17.0]}, 128)
batch 879: ({'logprob': [72.51869201660156, 21.0]}, 128)
batch 880: ({'logprob': [51.141746520996094, 13.0]}, 128)
batch 881: ({'logprob': [30.392574310302734, 5.0]}, 128)
batch 882: ({'logprob': [54.59033966064453, 14.0]}, 128)
batch 883: ({'logprob': [61.656585693359375, 17.0]}, 128)
batch 884: ({'logprob': [51.452308654785156, 13.0]}, 128)
batch 885: ({'logprob': [52.10957717895508, 13.0]}, 128)
batch 886: ({'logprob': [61.9942512512207, 17.0]}, 128)

======================Test output======================
logprob:  0.417403, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.969395e-03 [2.902882e-09] 
Layer 'conv1' biases: 1.508447e-07 [5.960244e-11] 
Layer 'conv2' weights[0]: 7.956446e-03 [1.919823e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.541806e-10] 
Layer 'conv3' weights[0]: 7.954772e-03 [1.843017e-09] 
Layer 'conv3' biases: 1.315830e-06 [1.131804e-09] 
Layer 'conv4' weights[0]: 7.987301e-03 [2.037758e-09] 
Layer 'conv4' biases: 9.999996e-01 [1.041460e-08] 
Layer 'conv5' weights[0]: 7.986172e-03 [7.079775e-08] 
Layer 'conv5' biases: 9.999980e-01 [7.671790e-08] 
Layer 'fc6' weights[0]: 7.583014e-03 [5.955690e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.046079e-09] 
Layer 'fc7' weights[0]: 7.353074e-03 [2.675712e-07] 
Layer 'fc7' biases: 9.998639e-01 [2.571386e-07] 
Layer 'fc8' weights[0]: 1.288236e-03 [9.255272e-06] 
Layer 'fc8' biases: 3.620879e-02 [5.833655e-05] 
Train error last 870 batches: 0.435262
-------------------------------------------------------
Not saving because 0.417403 > 0.415707 (12.630: -0.00%)
======================================================= (12.023 sec)
16.1... logprob:  0.380241, 0.093750 (1.413 sec)
16.2... logprob:  0.448289, 0.117188 (1.458 sec)
16.3... logprob:  0.398450, 0.101562 (1.418 sec)
16.4... logprob:  0.443364, 0.117188 (1.411 sec)
16.5... logprob:  0.443408, 0.117188 (1.430 sec)
16.6... logprob:  0.499228, 0.140625 (1.404 sec)
16.7... logprob:  0.363002, 0.085938 (1.423 sec)
16.8... logprob:  0.419098, 0.109375 (1.403 sec)
16.9... logprob:  0.358616, 0.085938 (1.402 sec)
16.10... logprob:  0.377347, 0.093750 (1.415 sec)
16.11... logprob:  0.334496, 0.078125 (1.449 sec)
16.12... logprob:  0.466573, 0.125000 (1.396 sec)
16.13... logprob:  0.442420, 0.117188 (1.426 sec)
16.14... logprob:  0.444822, 0.117188 (1.403 sec)
16.15... logprob:  0.395665, 0.101562 (1.413 sec)
16.16... logprob:  0.421478, 0.109375 (1.408 sec)
16.17... logprob:  0.516117, 0.140625 (1.400 sec)
16.18... logprob:  0.262113, 0.054688 (1.399 sec)
16.19... logprob:  0.279648, 0.062500 (1.399 sec)
16.20... logprob:  0.421381, 0.109375 (1.410 sec)
16.21... logprob:  0.443944, 0.117188 (0.888 sec)
16.22... logprob:  0.536543, 0.148438 (1.323 sec)
16.23... logprob:  0.532742, 0.148438 (1.423 sec)
16.24... logprob:  0.310818, 0.070312 (0.986 sec)
16.25... logprob:  0.356355, 0.085938 (0.959 sec)
16.26... logprob:  0.463652, 0.125000 (1.453 sec)
16.27... logprob:  0.404627, 0.101562 (1.384 sec)
16.28... logprob:  0.421879, 0.109375 (1.410 sec)
16.29... logprob:  0.396077, 0.101562 (1.422 sec)
16.30... logprob:  0.374198, 0.093750 (1.421 sec)
16.31... logprob:  0.479899, 0.132812 (1.400 sec)
16.32... logprob:  0.457237, 0.125000 (1.392 sec)
16.33... logprob:  0.460680, 0.125000 (1.446 sec)
16.34... logprob:  0.464641, 0.125000 (1.395 sec)
16.35... logprob:  0.316182, 0.070312 (1.403 sec)
16.36... logprob:  0.475808, 0.132812 (1.402 sec)
16.37... logprob:  0.417600, 0.109375 (1.410 sec)
16.38... logprob:  0.392507, 0.101562 (1.396 sec)
16.39... logprob:  0.631939, 0.187500 (1.440 sec)
16.40... logprob:  0.445846, 0.117188 (1.411 sec)
16.41... logprob:  0.352766, 0.085938 (1.426 sec)
16.42... logprob:  0.391844, 0.101562 (1.418 sec)
16.43... logprob:  0.440123, 0.117188 (1.408 sec)
16.44... logprob:  0.518507, 0.148438 (1.437 sec)
16.45... logprob:  0.381784, 0.093750 (1.393 sec)
16.46... logprob:  0.486370, 0.132812 (1.397 sec)
16.47... logprob:  0.331770, 0.078125 (1.399 sec)
16.48... logprob:  0.498878, 0.140625 (1.423 sec)
16.49... logprob:  0.510646, 0.148438 (1.420 sec)
16.50... logprob:  0.393251, 0.101562 (1.430 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.842796325683594, 10.0]}, 128)
batch 872: ({'logprob': [66.2632064819336, 19.0]}, 128)
batch 873: ({'logprob': [40.991146087646484, 9.0]}, 128)
batch 874: ({'logprob': [45.39563751220703, 11.0]}, 128)
batch 875: ({'logprob': [50.86940383911133, 13.0]}, 128)
batch 876: ({'logprob': [63.80879592895508, 18.0]}, 128)
batch 877: ({'logprob': [45.9360466003418, 11.0]}, 128)
batch 878: ({'logprob': [61.853515625, 17.0]}, 128)
batch 879: ({'logprob': [73.34148406982422, 21.0]}, 128)
batch 880: ({'logprob': [50.88581848144531, 13.0]}, 128)
batch 881: ({'logprob': [29.471433639526367, 5.0]}, 128)
batch 882: ({'logprob': [54.96196365356445, 14.0]}, 128)
batch 883: ({'logprob': [61.83733367919922, 17.0]}, 128)
batch 884: ({'logprob': [51.404579162597656, 13.0]}, 128)
batch 885: ({'logprob': [52.47623062133789, 13.0]}, 128)
batch 886: ({'logprob': [62.38254928588867, 17.0]}, 128)

======================Test output======================
logprob:  0.416856, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.969357e-03 [2.337234e-09] 
Layer 'conv1' biases: 1.516461e-07 [3.988590e-11] 
Layer 'conv2' weights[0]: 7.956405e-03 [1.779916e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.700546e-10] 
Layer 'conv3' weights[0]: 7.954730e-03 [1.298687e-09] 
Layer 'conv3' biases: 1.321616e-06 [4.688148e-10] 
Layer 'conv4' weights[0]: 7.987264e-03 [1.266081e-09] 
Layer 'conv4' biases: 9.999996e-01 [2.137418e-09] 
Layer 'conv5' weights[0]: 7.986133e-03 [1.052777e-08] 
Layer 'conv5' biases: 9.999976e-01 [1.074940e-08] 
Layer 'fc6' weights[0]: 7.582969e-03 [1.137227e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.048816e-10] 
Layer 'fc7' weights[0]: 7.351224e-03 [4.932737e-08] 
Layer 'fc7' biases: 9.998643e-01 [2.678850e-08] 
Layer 'fc8' weights[0]: 1.304716e-03 [6.492013e-06] 
Layer 'fc8' biases: 3.640641e-02 [4.135275e-05] 
Train error last 870 batches: 0.435262
-------------------------------------------------------
Not saving because 0.416856 > 0.415707 (12.630: -0.00%)
======================================================= (12.133 sec)
16.51... logprob:  0.490014, 0.140625 (1.422 sec)
16.52... logprob:  0.525778, 0.148438 (1.409 sec)
16.53... logprob:  0.295045, 0.062500 (1.449 sec)
16.54... logprob:  0.403257, 0.109375 (1.396 sec)
16.55... logprob:  0.331795, 0.078125 (1.400 sec)
16.56... logprob:  0.421711, 0.109375 (1.401 sec)
16.57... logprob:  0.572538, 0.164062 (1.438 sec)
16.58... logprob:  0.407762, 0.101562 (1.406 sec)
16.59... logprob:  0.333851, 0.078125 (1.473 sec)
16.60... logprob:  0.619036, 0.179688 (1.427 sec)
16.61... logprob:  0.382862, 0.093750 (1.430 sec)
16.62... logprob:  0.474908, 0.132812 (1.483 sec)
16.63... logprob:  0.397310, 0.101562 (1.438 sec)
16.64... logprob:  0.450270, 0.125000 (1.413 sec)
16.65... logprob:  0.373320, 0.093750 (1.408 sec)
16.66... logprob:  0.354004, 0.085938 (1.443 sec)
16.67... logprob:  0.295386, 0.062500 (1.395 sec)
16.68... logprob:  0.396820, 0.101562 (1.403 sec)
16.69... logprob:  0.496832, 0.140625 (1.419 sec)
16.70... logprob:  0.325878, 0.078125 (1.429 sec)
16.71... logprob:  0.381840, 0.101562 (1.462 sec)
16.72... logprob:  0.493843, 0.132812 (1.402 sec)
16.73... logprob:  0.447776, 0.117188 (1.436 sec)
16.74... logprob:  0.442592, 0.117188 (1.420 sec)
16.75... logprob:  0.380643, 0.093750 (1.416 sec)
16.76... logprob:  0.412086, 0.109375 (1.437 sec)
16.77... logprob:  0.396344, 0.101562 (1.431 sec)
16.78... logprob:  0.493067, 0.140625 (1.454 sec)
16.79... logprob:  0.456441, 0.125000 (1.407 sec)
16.80... logprob:  0.507881, 0.132812 (1.417 sec)
16.81... logprob:  0.416724, 0.109375 (1.421 sec)
16.82... logprob:  0.231801, 0.039062 (1.423 sec)
16.83... logprob:  0.493721, 0.140625 (1.404 sec)
16.84... logprob:  0.468083, 0.125000 (1.466 sec)
16.85... logprob:  0.432031, 0.117188 (1.421 sec)
16.86... logprob:  0.416992, 0.109375 (1.417 sec)
16.87... logprob:  0.633191, 0.187500 (1.416 sec)
16.88... logprob:  0.535102, 0.156250 (1.413 sec)
16.89... logprob:  0.410628, 0.109375 (1.434 sec)
16.90... logprob:  0.577512, 0.171875 (1.395 sec)
16.91... logprob:  0.348548, 0.078125 (1.396 sec)
16.92... logprob:  0.464462, 0.125000 (1.406 sec)
16.93... logprob:  0.492282, 0.140625 (1.396 sec)
16.94... logprob:  0.428784, 0.109375 (1.390 sec)
16.95... logprob:  0.471860, 0.125000 (1.400 sec)
16.96... logprob:  0.576355, 0.171875 (1.408 sec)
16.97... logprob:  0.430755, 0.117188 (1.398 sec)
16.98... logprob:  0.391028, 0.093750 (1.444 sec)
16.99... logprob:  0.474316, 0.132812 (1.417 sec)
16.100... logprob:  0.310358, 0.070312 (1.407 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.21995162963867, 10.0]}, 128)
batch 872: ({'logprob': [66.138671875, 19.0]}, 128)
batch 873: ({'logprob': [41.236488342285156, 9.0]}, 128)
batch 874: ({'logprob': [45.63227462768555, 11.0]}, 128)
batch 875: ({'logprob': [50.98867416381836, 13.0]}, 128)
batch 876: ({'logprob': [63.71580123901367, 18.0]}, 128)
batch 877: ({'logprob': [46.118717193603516, 11.0]}, 128)
batch 878: ({'logprob': [61.7377815246582, 17.0]}, 128)
batch 879: ({'logprob': [72.93667602539062, 21.0]}, 128)
batch 880: ({'logprob': [51.00511932373047, 13.0]}, 128)
batch 881: ({'logprob': [30.006406784057617, 5.0]}, 128)
batch 882: ({'logprob': [54.8861083984375, 14.0]}, 128)
batch 883: ({'logprob': [61.7215461730957, 17.0]}, 128)
batch 884: ({'logprob': [51.468963623046875, 13.0]}, 128)
batch 885: ({'logprob': [52.431549072265625, 13.0]}, 128)
batch 886: ({'logprob': [62.212013244628906, 17.0]}, 128)

======================Test output======================
logprob:  0.417215, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.969317e-03 [3.838914e-09] 
Layer 'conv1' biases: 1.523646e-07 [1.299135e-10] 
Layer 'conv2' weights[0]: 7.956369e-03 [3.841274e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.807884e-10] 
Layer 'conv3' weights[0]: 7.954691e-03 [3.830559e-09] 
Layer 'conv3' biases: 1.326482e-06 [2.411178e-09] 
Layer 'conv4' weights[0]: 7.987227e-03 [4.286540e-09] 
Layer 'conv4' biases: 9.999996e-01 [2.388060e-08] 
Layer 'conv5' weights[0]: 7.986098e-03 [1.613893e-07] 
Layer 'conv5' biases: 9.999973e-01 [1.748531e-07] 
Layer 'fc6' weights[0]: 7.582924e-03 [1.355937e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.384981e-08] 
Layer 'fc7' weights[0]: 7.349396e-03 [3.000854e-07] 
Layer 'fc7' biases: 9.998640e-01 [2.887591e-07] 
Layer 'fc8' weights[0]: 1.295816e-03 [1.083408e-05] 
Layer 'fc8' biases: 3.641492e-02 [7.272686e-05] 
Train error last 870 batches: 0.435262
-------------------------------------------------------
Not saving because 0.417215 > 0.415707 (12.630: -0.00%)
======================================================= (12.088 sec)
16.101... logprob:  0.310530, 0.062500 (1.454 sec)
16.102... logprob:  0.546369, 0.156250 (1.395 sec)
16.103... logprob:  0.541348, 0.156250 (1.409 sec)
16.104... logprob:  0.388871, 0.101562 (1.397 sec)
16.105... logprob:  0.619814, 0.179688 (1.401 sec)
16.106... logprob:  0.344429, 0.085938 (1.397 sec)
16.107... logprob:  0.335700, 0.078125 (1.440 sec)
16.108... logprob:  0.586809, 0.171875 (1.396 sec)
16.109... logprob:  0.336208, 0.078125 (1.412 sec)
16.110... logprob:  0.564426, 0.164062 (1.397 sec)
16.111... logprob:  0.404738, 0.101562 (1.400 sec)
16.112... logprob:  0.366194, 0.093750 (1.408 sec)
16.113... logprob:  0.354682, 0.085938 (1.404 sec)
16.114... logprob:  0.440234, 0.117188 (1.441 sec)
16.115... logprob:  0.506723, 0.140625 (1.418 sec)
16.116... logprob:  0.393410, 0.101562 (1.405 sec)
16.117... logprob:  0.440396, 0.117188 (1.443 sec)
16.118... logprob:  0.409174, 0.101562 (1.389 sec)
16.119... logprob:  0.346137, 0.085938 (1.402 sec)
16.120... logprob:  0.547154, 0.156250 (1.400 sec)
16.121... logprob:  0.412680, 0.109375 (1.399 sec)
16.122... logprob:  0.519369, 0.148438 (1.444 sec)
16.123... logprob:  0.463751, 0.125000 (1.392 sec)
16.124... logprob:  0.447714, 0.125000 (1.414 sec)
16.125... logprob:  0.502010, 0.140625 (1.402 sec)
16.126... logprob:  0.475809, 0.125000 (1.392 sec)
16.127... logprob:  0.479630, 0.125000 (1.399 sec)
16.128... logprob:  0.422381, 0.109375 (1.419 sec)
16.129... logprob:  0.574895, 0.164062 (1.423 sec)
16.130... logprob:  0.382755, 0.093750 (1.412 sec)
16.131... logprob:  0.495502, 0.132812 (1.413 sec)
16.132... logprob:  0.506386, 0.140625 (1.436 sec)
16.133... logprob:  0.444683, 0.117188 (1.391 sec)
16.134... logprob:  0.401918, 0.101562 (1.397 sec)
16.135... logprob:  0.460242, 0.125000 (1.406 sec)
16.136... logprob:  0.562575, 0.164062 (1.404 sec)
16.137... logprob:  0.462567, 0.125000 (1.401 sec)
16.138... logprob:  0.319336, 0.070312 (1.462 sec)
16.139... logprob:  0.395784, 0.101562 (1.403 sec)
16.140... logprob:  0.560503, 0.164062 (1.411 sec)
16.141... logprob:  0.464538, 0.125000 (1.438 sec)
16.142... logprob:  0.464610, 0.125000 (1.395 sec)
16.143... logprob:  0.294259, 0.062500 (1.424 sec)
16.144... logprob:  0.457304, 0.125000 (1.416 sec)
16.145... logprob:  0.324870, 0.078125 (1.416 sec)
16.146... logprob:  0.483238, 0.132812 (1.413 sec)
16.147... logprob:  0.262469, 0.054688 (1.437 sec)
16.148... logprob:  0.458829, 0.125000 (1.396 sec)
16.149... logprob:  0.442565, 0.117188 (1.400 sec)
16.150... logprob:  0.347629, 0.085938 (1.399 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.26528549194336, 10.0]}, 128)
batch 872: ({'logprob': [67.9087905883789, 19.0]}, 128)
batch 873: ({'logprob': [39.595481872558594, 9.0]}, 128)
batch 874: ({'logprob': [44.80788803100586, 11.0]}, 128)
batch 875: ({'logprob': [50.75471115112305, 13.0]}, 128)
batch 876: ({'logprob': [65.13565826416016, 18.0]}, 128)
batch 877: ({'logprob': [45.18048095703125, 11.0]}, 128)
batch 878: ({'logprob': [62.691436767578125, 17.0]}, 128)
batch 879: ({'logprob': [74.96536254882812, 21.0]}, 128)
batch 880: ({'logprob': [50.7727165222168, 13.0]}, 128)
batch 881: ({'logprob': [27.28856658935547, 5.0]}, 128)
batch 882: ({'logprob': [54.67356872558594, 14.0]}, 128)
batch 883: ({'logprob': [62.674556732177734, 17.0]}, 128)
batch 884: ({'logprob': [51.12771224975586, 13.0]}, 128)
batch 885: ({'logprob': [51.868003845214844, 13.0]}, 128)
batch 886: ({'logprob': [63.05634307861328, 17.0]}, 128)

======================Test output======================
logprob:  0.416878, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.969275e-03 [2.432740e-09] 
Layer 'conv1' biases: 1.530708e-07 [4.279762e-11] 
Layer 'conv2' weights[0]: 7.956324e-03 [1.492820e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.681474e-10] 
Layer 'conv3' weights[0]: 7.954651e-03 [1.176485e-09] 
Layer 'conv3' biases: 1.332677e-06 [4.299614e-10] 
Layer 'conv4' weights[0]: 7.987184e-03 [1.138043e-09] 
Layer 'conv4' biases: 9.999996e-01 [2.280139e-09] 
Layer 'conv5' weights[0]: 7.986058e-03 [1.016172e-08] 
Layer 'conv5' biases: 9.999971e-01 [1.028638e-08] 
Layer 'fc6' weights[0]: 7.582882e-03 [1.083530e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.329483e-10] 
Layer 'fc7' weights[0]: 7.347456e-03 [1.261137e-07] 
Layer 'fc7' biases: 9.998651e-01 [1.122734e-07] 
Layer 'fc8' weights[0]: 1.353454e-03 [9.063620e-06] 
Layer 'fc8' biases: 3.689840e-02 [5.758691e-05] 
Train error last 870 batches: 0.435261
-------------------------------------------------------
Not saving because 0.416878 > 0.415707 (12.630: -0.00%)
======================================================= (12.102 sec)
16.151... logprob:  0.347154, 0.085938 (1.411 sec)
16.152... logprob:  0.785009, 0.234375 (1.402 sec)
16.153... logprob:  0.381667, 0.093750 (1.446 sec)
16.154... logprob:  0.524383, 0.148438 (1.406 sec)
16.155... logprob:  0.425982, 0.117188 (1.408 sec)
16.156... logprob:  0.295897, 0.062500 (1.441 sec)
16.157... logprob:  0.270811, 0.054688 (1.402 sec)
16.158... logprob:  0.455369, 0.125000 (1.401 sec)
16.159... logprob:  0.483115, 0.132812 (1.404 sec)
16.160... logprob:  0.444885, 0.117188 (1.404 sec)
16.161... logprob:  0.350148, 0.078125 (1.410 sec)
16.162... logprob:  0.611797, 0.179688 (1.408 sec)
16.163... logprob:  0.450429, 0.125000 (1.433 sec)
16.164... logprob:  0.468687, 0.125000 (1.423 sec)
16.165... logprob:  0.547957, 0.156250 (1.424 sec)
16.166... logprob:  0.446064, 0.125000 (1.450 sec)
16.167... logprob:  0.350411, 0.085938 (1.433 sec)
16.168... logprob:  0.363670, 0.085938 (1.430 sec)
16.169... logprob:  0.408681, 0.101562 (1.466 sec)
16.170... logprob:  0.459494, 0.125000 (1.401 sec)
16.171... logprob:  0.535471, 0.156250 (1.426 sec)
16.172... logprob:  0.434870, 0.109375 (1.428 sec)
16.173... logprob:  0.440499, 0.117188 (1.423 sec)
16.174... logprob:  0.601153, 0.171875 (1.418 sec)
16.175... logprob:  0.506120, 0.140625 (1.468 sec)
16.176... logprob:  0.478492, 0.132812 (1.416 sec)
16.177... logprob:  0.289773, 0.054688 (1.430 sec)
16.178... logprob:  0.383491, 0.093750 (1.460 sec)
16.179... logprob:  0.394728, 0.101562 (1.411 sec)
16.180... logprob:  0.466382, 0.125000 (1.423 sec)
16.181... logprob:  0.539400, 0.156250 (1.420 sec)
16.182... logprob:  0.371404, 0.093750 (1.414 sec)
16.183... logprob:  0.419960, 0.109375 (1.421 sec)
16.184... logprob:  0.483476, 0.132812 (1.417 sec)
16.185... logprob:  0.289873, 0.062500 (1.391 sec)
16.186... logprob:  0.370507, 0.093750 (1.403 sec)
16.187... logprob:  0.529630, 0.148438 (1.400 sec)
16.188... logprob:  0.458987, 0.125000 (1.409 sec)
16.189... logprob:  0.440906, 0.117188 (1.390 sec)
16.190... logprob:  0.375744, 0.093750 (1.433 sec)
16.191... logprob:  0.485101, 0.132812 (1.411 sec)
16.192... logprob:  0.520164, 0.148438 (1.420 sec)
16.193... logprob:  0.312620, 0.070312 (1.419 sec)
16.194... logprob:  0.414112, 0.109375 (1.419 sec)
16.195... logprob:  0.287229, 0.062500 (1.398 sec)
16.196... logprob:  0.410551, 0.109375 (1.396 sec)
16.197... logprob:  0.478027, 0.132812 (1.400 sec)
16.198... logprob:  0.355793, 0.085938 (1.405 sec)
16.199... logprob:  0.437193, 0.117188 (1.391 sec)
16.200... logprob:  0.440773, 0.117188 (1.437 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.39096450805664, 10.0]}, 128)
batch 872: ({'logprob': [66.89539337158203, 19.0]}, 128)
batch 873: ({'logprob': [40.268211364746094, 9.0]}, 128)
batch 874: ({'logprob': [44.99647903442383, 11.0]}, 128)
batch 875: ({'logprob': [50.70505142211914, 13.0]}, 128)
batch 876: ({'logprob': [64.30216979980469, 18.0]}, 128)
batch 877: ({'logprob': [45.492218017578125, 11.0]}, 128)
batch 878: ({'logprob': [62.16201400756836, 17.0]}, 128)
batch 879: ({'logprob': [74.07818603515625, 21.0]}, 128)
batch 880: ({'logprob': [50.722320556640625, 13.0]}, 128)
batch 881: ({'logprob': [28.319332122802734, 5.0]}, 128)
batch 882: ({'logprob': [54.8077507019043, 14.0]}, 128)
batch 883: ({'logprob': [62.14531707763672, 17.0]}, 128)
batch 884: ({'logprob': [51.198272705078125, 13.0]}, 128)
batch 885: ({'logprob': [52.18240737915039, 13.0]}, 128)
batch 886: ({'logprob': [62.648033142089844, 17.0]}, 128)

======================Test output======================
logprob:  0.416169, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.969235e-03 [3.327654e-09] 
Layer 'conv1' biases: 1.539758e-07 [9.768270e-11] 
Layer 'conv2' weights[0]: 7.956285e-03 [2.166128e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.736051e-10] 
Layer 'conv3' weights[0]: 7.954613e-03 [1.576887e-09] 
Layer 'conv3' biases: 1.340542e-06 [6.818014e-10] 
Layer 'conv4' weights[0]: 7.987138e-03 [1.557802e-09] 
Layer 'conv4' biases: 9.999996e-01 [3.988460e-09] 
Layer 'conv5' weights[0]: 7.986020e-03 [2.623596e-08] 
Layer 'conv5' biases: 9.999973e-01 [2.830261e-08] 
Layer 'fc6' weights[0]: 7.582845e-03 [2.409476e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.276018e-09] 
Layer 'fc7' weights[0]: 7.345619e-03 [5.435487e-08] 
Layer 'fc7' biases: 9.998646e-01 [3.322658e-08] 
Layer 'fc8' weights[0]: 1.335371e-03 [4.960004e-06] 
Layer 'fc8' biases: 3.687346e-02 [3.193728e-05] 
Train error last 870 batches: 0.435261
-------------------------------------------------------
Not saving because 0.416169 > 0.415707 (12.630: -0.00%)
======================================================= (12.072 sec)
16.201... logprob:  0.437099, 0.117188 (1.417 sec)
16.202... logprob:  0.537967, 0.148438 (1.410 sec)
16.203... logprob:  0.420458, 0.109375 (1.442 sec)
16.204... logprob:  0.504126, 0.140625 (1.390 sec)
16.205... logprob:  0.334387, 0.078125 (1.417 sec)
16.206... logprob:  0.361634, 0.093750 (1.402 sec)
16.207... logprob:  0.381898, 0.093750 (1.399 sec)
16.208... logprob:  0.490524, 0.140625 (1.406 sec)
16.209... logprob:  0.334597, 0.078125 (1.426 sec)
16.210... logprob:  0.586248, 0.171875 (1.421 sec)
16.211... logprob:  0.488190, 0.132812 (1.413 sec)
16.212... logprob:  0.526151, 0.148438 (1.411 sec)
16.213... logprob:  0.514797, 0.140625 (1.465 sec)
16.214... logprob:  0.459437, 0.125000 (1.426 sec)
16.215... logprob:  0.396149, 0.101562 (1.415 sec)
16.216... logprob:  0.517100, 0.140625 (1.469 sec)
16.217... logprob:  0.325096, 0.070312 (1.407 sec)
16.218... logprob:  0.463696, 0.125000 (1.421 sec)
16.219... logprob:  0.500306, 0.140625 (1.420 sec)
16.220... logprob:  0.415000, 0.109375 (1.418 sec)
16.221... logprob:  0.399543, 0.101562 (1.418 sec)
16.222... logprob:  0.554573, 0.164062 (1.466 sec)
16.223... logprob:  0.569225, 0.164062 (1.427 sec)
16.224... logprob:  0.405880, 0.101562 (1.432 sec)
16.225... logprob:  0.391970, 0.101562 (1.445 sec)
16.226... logprob:  0.424640, 0.109375 (1.430 sec)
16.227... logprob:  0.452729, 0.125000 (1.420 sec)
16.228... logprob:  0.417197, 0.109375 (1.419 sec)
16.229... logprob:  0.489372, 0.132812 (1.416 sec)
16.230... logprob:  0.459896, 0.125000 (1.437 sec)
16.231... logprob:  0.453540, 0.125000 (1.405 sec)
16.232... logprob:  0.496224, 0.140625 (1.461 sec)
16.233... logprob:  0.466158, 0.132812 (1.426 sec)
16.234... logprob:  0.563804, 0.164062 (1.422 sec)
16.235... logprob:  0.482031, 0.132812 (1.466 sec)
16.236... logprob:  0.425791, 0.109375 (1.405 sec)
16.237... logprob:  0.341313, 0.078125 (1.425 sec)
16.238... logprob:  0.389366, 0.093750 (1.416 sec)
16.239... logprob:  0.478142, 0.132812 (1.422 sec)
16.240... logprob:  0.485807, 0.132812 (1.401 sec)
16.241... logprob:  0.493606, 0.132812 (1.464 sec)
16.242... logprob:  0.341653, 0.078125 (1.428 sec)
16.243... logprob:  0.386019, 0.093750 (1.440 sec)
16.244... logprob:  0.315238, 0.070312 (1.444 sec)
16.245... logprob:  0.494345, 0.132812 (1.429 sec)
16.246... logprob:  0.416904, 0.109375 (1.415 sec)
16.247... logprob:  0.357372, 0.085938 (1.428 sec)
16.248... logprob:  0.307768, 0.070312 (1.421 sec)
16.249... logprob:  0.555391, 0.156250 (1.433 sec)
16.250... logprob:  0.591720, 0.164062 (1.409 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.42762756347656, 10.0]}, 128)
batch 872: ({'logprob': [67.8823013305664, 19.0]}, 128)
batch 873: ({'logprob': [39.583351135253906, 9.0]}, 128)
batch 874: ({'logprob': [44.860931396484375, 11.0]}, 128)
batch 875: ({'logprob': [50.75932312011719, 13.0]}, 128)
batch 876: ({'logprob': [65.10514831542969, 18.0]}, 128)
batch 877: ({'logprob': [45.17696762084961, 11.0]}, 128)
batch 878: ({'logprob': [62.599849700927734, 17.0]}, 128)
batch 879: ({'logprob': [74.72058868408203, 21.0]}, 128)
batch 880: ({'logprob': [50.777767181396484, 13.0]}, 128)
batch 881: ({'logprob': [27.429553985595703, 5.0]}, 128)
batch 882: ({'logprob': [54.51239013671875, 14.0]}, 128)
batch 883: ({'logprob': [62.58259582519531, 17.0]}, 128)
batch 884: ({'logprob': [51.075653076171875, 13.0]}, 128)
batch 885: ({'logprob': [51.70230484008789, 13.0]}, 128)
batch 886: ({'logprob': [62.907867431640625, 17.0]}, 128)

======================Test output======================
logprob:  0.416555, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.969199e-03 [6.992041e-09] 
Layer 'conv1' biases: 1.547961e-07 [1.725493e-10] 
Layer 'conv2' weights[0]: 7.956247e-03 [5.353812e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.085511e-09] 
Layer 'conv3' weights[0]: 7.954579e-03 [4.982384e-09] 
Layer 'conv3' biases: 1.346880e-06 [3.446475e-09] 
Layer 'conv4' weights[0]: 7.987101e-03 [5.452442e-09] 
Layer 'conv4' biases: 9.999995e-01 [3.253085e-08] 
Layer 'conv5' weights[0]: 7.985976e-03 [2.190508e-07] 
Layer 'conv5' biases: 9.999974e-01 [2.369361e-07] 
Layer 'fc6' weights[0]: 7.582809e-03 [1.886559e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.900655e-08] 
Layer 'fc7' weights[0]: 7.343694e-03 [1.825521e-07] 
Layer 'fc7' biases: 9.998648e-01 [1.719301e-07] 
Layer 'fc8' weights[0]: 1.357724e-03 [9.465411e-06] 
Layer 'fc8' biases: 3.710303e-02 [5.892268e-05] 
Train error last 870 batches: 0.435261
-------------------------------------------------------
Not saving because 0.416555 > 0.415707 (12.630: -0.00%)
======================================================= (12.029 sec)
16.251... logprob:  0.352917, 0.085938 (1.474 sec)
16.252... logprob:  0.348484, 0.085938 (1.436 sec)
16.253... logprob:  0.379180, 0.093750 (1.416 sec)
16.254... logprob:  0.444180, 0.117188 (1.471 sec)
16.255... logprob:  0.351480, 0.085938 (1.401 sec)
16.256... logprob:  0.378757, 0.093750 (1.425 sec)
16.257... logprob:  0.332045, 0.078125 (1.413 sec)
16.258... logprob:  0.415745, 0.109375 (1.424 sec)
16.259... logprob:  0.442310, 0.117188 (1.402 sec)
16.260... logprob:  0.308380, 0.070312 (1.463 sec)
16.261... logprob:  0.392788, 0.101562 (1.431 sec)
16.262... logprob:  0.524652, 0.148438 (1.436 sec)
16.263... logprob:  0.425487, 0.109375 (1.445 sec)
16.264... logprob:  0.375146, 0.093750 (1.430 sec)
16.265... logprob:  0.439614, 0.117188 (1.421 sec)
16.266... logprob:  0.439035, 0.117188 (1.420 sec)
16.267... logprob:  0.422007, 0.109375 (1.415 sec)
16.268... logprob:  0.458944, 0.125000 (1.434 sec)
16.269... logprob:  0.567476, 0.164062 (1.406 sec)
16.270... logprob:  0.542219, 0.156250 (1.463 sec)
16.271... logprob:  0.445739, 0.117188 (1.435 sec)
16.272... logprob:  0.384748, 0.093750 (1.416 sec)
16.273... logprob:  0.500219, 0.140625 (1.472 sec)
16.274... logprob:  0.542528, 0.156250 (1.400 sec)
16.275... logprob:  0.487721, 0.132812 (1.426 sec)
16.276... logprob:  0.390165, 0.093750 (1.414 sec)
16.277... logprob:  0.428713, 0.109375 (1.428 sec)
16.278... logprob:  0.323412, 0.070312 (1.420 sec)
16.279... logprob:  0.324988, 0.070312 (1.466 sec)
16.280... logprob:  0.215218, 0.031250 (1.419 sec)
16.281... logprob:  0.417218, 0.109375 (1.427 sec)
16.282... logprob:  0.411457, 0.109375 (1.421 sec)
16.283... logprob:  0.393853, 0.101562 (1.416 sec)
16.284... logprob:  0.394677, 0.101562 (1.415 sec)
16.285... logprob:  0.452117, 0.117188 (1.444 sec)
16.286... logprob:  0.537424, 0.140625 (1.443 sec)
16.287... logprob:  0.346669, 0.085938 (1.429 sec)
16.288... logprob:  0.329976, 0.078125 (1.442 sec)
16.289... logprob:  0.446011, 0.117188 (1.441 sec)
16.290... logprob:  0.490655, 0.132812 (1.411 sec)
16.291... logprob:  0.439167, 0.117188 (1.415 sec)
16.292... logprob:  0.567074, 0.156250 (1.422 sec)
16.293... logprob:  0.427510, 0.117188 (1.422 sec)
16.294... logprob:  0.356166, 0.085938 (1.408 sec)
16.295... logprob:  0.335081, 0.078125 (1.462 sec)
16.296... logprob:  0.356164, 0.085938 (1.418 sec)
16.297... logprob:  0.394785, 0.101562 (1.428 sec)
16.298... logprob:  0.448120, 0.125000 (1.462 sec)
16.299... logprob:  0.342596, 0.078125 (1.403 sec)
16.300... logprob:  0.406667, 0.101562 (1.429 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.01127624511719, 10.0]}, 128)
batch 872: ({'logprob': [66.17457580566406, 19.0]}, 128)
batch 873: ({'logprob': [41.139732360839844, 9.0]}, 128)
batch 874: ({'logprob': [45.5135498046875, 11.0]}, 128)
batch 875: ({'logprob': [50.928680419921875, 13.0]}, 128)
batch 876: ({'logprob': [63.742706298828125, 18.0]}, 128)
batch 877: ({'logprob': [46.0402946472168, 11.0]}, 128)
batch 878: ({'logprob': [61.795692443847656, 17.0]}, 128)
batch 879: ({'logprob': [73.15209197998047, 21.0]}, 128)
batch 880: ({'logprob': [50.9453239440918, 13.0]}, 128)
batch 881: ({'logprob': [29.751562118530273, 5.0]}, 128)
batch 882: ({'logprob': [54.956695556640625, 14.0]}, 128)
batch 883: ({'logprob': [61.779178619384766, 17.0]}, 128)
batch 884: ({'logprob': [51.44966125488281, 13.0]}, 128)
batch 885: ({'logprob': [52.492889404296875, 13.0]}, 128)
batch 886: ({'logprob': [62.31037521362305, 17.0]}, 128)

======================Test output======================
logprob:  0.417082, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.969155e-03 [3.290351e-09] 
Layer 'conv1' biases: 1.557385e-07 [8.375189e-11] 
Layer 'conv2' weights[0]: 7.956204e-03 [3.475780e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.488958e-10] 
Layer 'conv3' weights[0]: 7.954533e-03 [3.180058e-09] 
Layer 'conv3' biases: 1.354047e-06 [1.773162e-09] 
Layer 'conv4' weights[0]: 7.987056e-03 [3.409763e-09] 
Layer 'conv4' biases: 9.999996e-01 [1.629487e-08] 
Layer 'conv5' weights[0]: 7.985945e-03 [1.069838e-07] 
Layer 'conv5' biases: 9.999973e-01 [1.154988e-07] 
Layer 'fc6' weights[0]: 7.582775e-03 [9.138218e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.201780e-09] 
Layer 'fc7' weights[0]: 7.341894e-03 [1.643966e-07] 
Layer 'fc7' biases: 9.998637e-01 [1.522417e-07] 
Layer 'fc8' weights[0]: 1.308166e-03 [5.329687e-06] 
Layer 'fc8' biases: 3.703272e-02 [4.189050e-05] 
Train error last 870 batches: 0.435260
-------------------------------------------------------
Not saving because 0.417082 > 0.415707 (12.630: -0.00%)
======================================================= (12.036 sec)
16.301... logprob:  0.397960, 0.101562 (1.424 sec)
16.302... logprob:  0.591558, 0.179688 (1.430 sec)
16.303... logprob:  0.459627, 0.125000 (1.422 sec)
16.304... logprob:  0.459706, 0.125000 (1.441 sec)
16.305... logprob:  0.455239, 0.125000 (1.437 sec)
16.306... logprob:  0.440609, 0.117188 (1.438 sec)
16.307... logprob:  0.421601, 0.109375 (1.442 sec)
16.308... logprob:  0.374574, 0.093750 (1.457 sec)
16.309... logprob:  0.450492, 0.125000 (1.417 sec)
16.310... logprob:  0.473748, 0.125000 (1.423 sec)
16.311... logprob:  0.502654, 0.140625 (1.423 sec)
16.312... logprob:  0.478792, 0.132812 (1.433 sec)
16.313... logprob:  0.454872, 0.125000 (1.421 sec)
16.314... logprob:  0.454503, 0.117188 (1.473 sec)
16.315... logprob:  0.314691, 0.070312 (1.433 sec)
16.316... logprob:  0.468576, 0.125000 (1.426 sec)
16.317... logprob:  0.355520, 0.085938 (1.487 sec)
16.318... logprob:  0.455418, 0.125000 (1.416 sec)
16.319... logprob:  0.423209, 0.117188 (1.422 sec)
16.320... logprob:  0.412262, 0.109375 (1.430 sec)
16.321... logprob:  0.348292, 0.085938 (1.424 sec)
16.322... logprob:  0.387521, 0.101562 (1.425 sec)
16.323... logprob:  0.416524, 0.109375 (1.473 sec)
16.324... logprob:  0.498632, 0.140625 (1.429 sec)
16.325... logprob:  0.350681, 0.085938 (1.434 sec)
16.326... logprob:  0.543194, 0.148438 (1.468 sec)
16.327... logprob:  0.554407, 0.164062 (1.421 sec)
16.328... logprob:  0.565024, 0.156250 (1.428 sec)
16.329... logprob:  0.401997, 0.101562 (1.423 sec)
16.330... logprob:  0.388659, 0.101562 (1.424 sec)
16.331... logprob:  0.352526, 0.085938 (1.417 sec)
16.332... logprob:  0.482790, 0.132812 (1.453 sec)
16.333... logprob:  0.339636, 0.085938 (1.441 sec)
16.334... logprob:  0.565116, 0.171875 (1.446 sec)
16.335... logprob:  0.358857, 0.085938 (1.439 sec)
16.336... logprob:  0.444834, 0.125000 (1.456 sec)
16.337... logprob:  0.566474, 0.164062 (1.415 sec)
16.338... logprob:  0.449517, 0.125000 (1.428 sec)
16.339... logprob:  0.488699, 0.132812 (1.426 sec)
16.340... logprob:  0.442076, 0.117188 (1.430 sec)
16.341... logprob:  0.530141, 0.148438 (1.419 sec)
16.342... logprob:  0.429676, 0.109375 (1.470 sec)
16.343... logprob:  0.434782, 0.109375 (1.437 sec)
16.344... logprob:  0.444429, 0.125000 (1.485 sec)
16.345... logprob:  0.488260, 0.132812 (1.439 sec)
16.346... logprob:  0.436243, 0.117188 (1.439 sec)
16.347... logprob:  0.372360, 0.085938 (1.485 sec)
16.348... logprob:  0.398441, 0.101562 (1.433 sec)
16.349... logprob:  0.497869, 0.140625 (1.436 sec)
16.350... logprob:  0.358557, 0.085938 (1.439 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.4973258972168, 10.0]}, 128)
batch 872: ({'logprob': [66.4947280883789, 19.0]}, 128)
batch 873: ({'logprob': [40.705718994140625, 9.0]}, 128)
batch 874: ({'logprob': [45.170433044433594, 11.0]}, 128)
batch 875: ({'logprob': [50.77592086791992, 13.0]}, 128)
batch 876: ({'logprob': [63.99278259277344, 18.0]}, 128)
batch 877: ({'logprob': [45.7464599609375, 11.0]}, 128)
batch 878: ({'logprob': [62.02497863769531, 17.0]}, 128)
batch 879: ({'logprob': [73.81291961669922, 21.0]}, 128)
batch 880: ({'logprob': [50.79278564453125, 13.0]}, 128)
batch 881: ({'logprob': [28.88519859313965, 5.0]}, 128)
batch 882: ({'logprob': [55.025367736816406, 14.0]}, 128)
batch 883: ({'logprob': [62.00834655761719, 17.0]}, 128)
batch 884: ({'logprob': [51.348114013671875, 13.0]}, 128)
batch 885: ({'logprob': [52.49168014526367, 13.0]}, 128)
batch 886: ({'logprob': [62.59038162231445, 17.0]}, 128)

======================Test output======================
logprob:  0.416681, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.969115e-03 [2.965843e-09] 
Layer 'conv1' biases: 1.564211e-07 [5.696014e-11] 
Layer 'conv2' weights[0]: 7.956167e-03 [2.083516e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.105828e-10] 
Layer 'conv3' weights[0]: 7.954492e-03 [1.965039e-09] 
Layer 'conv3' biases: 1.359409e-06 [1.004914e-09] 
Layer 'conv4' weights[0]: 7.987018e-03 [2.030661e-09] 
Layer 'conv4' biases: 9.999995e-01 [8.870871e-09] 
Layer 'conv5' weights[0]: 7.985900e-03 [5.722625e-08] 
Layer 'conv5' biases: 9.999973e-01 [6.173646e-08] 
Layer 'fc6' weights[0]: 7.582726e-03 [4.952400e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.948693e-09] 
Layer 'fc7' weights[0]: 7.339987e-03 [1.754638e-07] 
Layer 'fc7' biases: 9.998643e-01 [1.634102e-07] 
Layer 'fc8' weights[0]: 1.323967e-03 [1.018668e-05] 
Layer 'fc8' biases: 3.725585e-02 [6.645660e-05] 
Train error last 870 batches: 0.435260
-------------------------------------------------------
Not saving because 0.416681 > 0.415707 (12.630: -0.00%)
======================================================= (12.039 sec)
16.351... logprob:  0.508672, 0.140625 (1.435 sec)
16.352... logprob:  0.363660, 0.093750 (1.437 sec)
16.353... logprob:  0.512779, 0.148438 (1.487 sec)
16.354... logprob:  0.675128, 0.203125 (1.431 sec)
16.355... logprob:  0.357476, 0.085938 (1.449 sec)
16.356... logprob:  0.479251, 0.132812 (1.478 sec)
16.357... logprob:  0.347027, 0.085938 (1.432 sec)
16.358... logprob:  0.326021, 0.070312 (1.443 sec)
16.359... logprob:  0.555229, 0.164062 (1.434 sec)
16.360... logprob:  0.444517, 0.117188 (1.429 sec)
16.361... logprob:  0.410781, 0.101562 (1.433 sec)
16.362... logprob:  0.424125, 0.117188 (1.476 sec)
16.363... logprob:  0.486586, 0.132812 (1.448 sec)
16.364... logprob:  0.475547, 0.125000 (1.455 sec)
16.365... logprob:  0.425088, 0.109375 (1.463 sec)
16.366... logprob:  0.409692, 0.109375 (1.452 sec)
16.367... logprob:  0.324998, 0.078125 (1.441 sec)
16.368... logprob:  0.595691, 0.171875 (1.427 sec)
16.369... logprob:  0.381542, 0.093750 (1.426 sec)
16.370... logprob:  0.381169, 0.093750 (1.439 sec)
16.371... logprob:  0.400352, 0.101562 (1.465 sec)
16.372... logprob:  0.537583, 0.156250 (1.452 sec)
16.373... logprob:  0.463829, 0.125000 (1.458 sec)
16.374... logprob:  0.527070, 0.148438 (1.448 sec)
16.375... logprob:  0.393782, 0.101562 (1.459 sec)
16.376... logprob:  0.374315, 0.093750 (1.441 sec)
16.377... logprob:  0.295383, 0.062500 (1.427 sec)
16.378... logprob:  0.453764, 0.125000 (1.431 sec)
16.379... logprob:  0.420239, 0.109375 (1.444 sec)
16.380... logprob:  0.605753, 0.179688 (1.436 sec)
16.381... logprob:  0.463482, 0.125000 (1.473 sec)
16.382... logprob:  0.529507, 0.148438 (1.451 sec)
16.383... logprob:  0.358691, 0.085938 (1.443 sec)
16.384... logprob:  0.521050, 0.148438 (1.481 sec)
16.385... logprob:  0.523470, 0.148438 (1.434 sec)
16.386... logprob:  0.582344, 0.171875 (1.429 sec)
16.387... logprob:  0.428681, 0.117188 (1.438 sec)
16.388... logprob:  0.521311, 0.148438 (1.442 sec)
16.389... logprob:  0.425903, 0.109375 (1.432 sec)
16.390... logprob:  0.419927, 0.109375 (1.477 sec)
16.391... logprob:  0.318375, 0.070312 (1.449 sec)
16.392... logprob:  0.439426, 0.117188 (1.430 sec)
16.393... logprob:  0.368845, 0.093750 (1.490 sec)
16.394... logprob:  0.343477, 0.078125 (1.432 sec)
16.395... logprob:  0.331553, 0.078125 (1.429 sec)
16.396... logprob:  0.251839, 0.046875 (1.437 sec)
16.397... logprob:  0.484740, 0.132812 (1.431 sec)
16.398... logprob:  0.471452, 0.125000 (1.437 sec)
16.399... logprob:  0.433739, 0.117188 (1.485 sec)
16.400... logprob:  0.538603, 0.148438 (1.438 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.646175384521484, 10.0]}, 128)
batch 872: ({'logprob': [68.84622955322266, 19.0]}, 128)
batch 873: ({'logprob': [39.64152908325195, 9.0]}, 128)
batch 874: ({'logprob': [44.74027633666992, 11.0]}, 128)
batch 875: ({'logprob': [51.059715270996094, 13.0]}, 128)
batch 876: ({'logprob': [66.00850677490234, 18.0]}, 128)
batch 877: ({'logprob': [45.355133056640625, 11.0]}, 128)
batch 878: ({'logprob': [63.74234390258789, 17.0]}, 128)
batch 879: ({'logprob': [77.003662109375, 21.0]}, 128)
batch 880: ({'logprob': [51.077674865722656, 13.0]}, 128)
batch 881: ({'logprob': [26.345298767089844, 5.0]}, 128)
batch 882: ({'logprob': [55.7737922668457, 14.0]}, 128)
batch 883: ({'logprob': [63.72521209716797, 17.0]}, 128)
batch 884: ({'logprob': [51.67735290527344, 13.0]}, 128)
batch 885: ({'logprob': [52.904090881347656, 13.0]}, 128)
batch 886: ({'logprob': [64.35124206542969, 17.0]}, 128)

======================Test output======================
logprob:  0.421337, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.969073e-03 [4.917401e-09] 
Layer 'conv1' biases: 1.572566e-07 [1.740836e-10] 
Layer 'conv2' weights[0]: 7.956121e-03 [5.002900e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.032924e-09] 
Layer 'conv3' weights[0]: 7.954455e-03 [4.831996e-09] 
Layer 'conv3' biases: 1.365446e-06 [3.260939e-09] 
Layer 'conv4' weights[0]: 7.986982e-03 [5.248391e-09] 
Layer 'conv4' biases: 9.999996e-01 [3.042350e-08] 
Layer 'conv5' weights[0]: 7.985871e-03 [2.008329e-07] 
Layer 'conv5' biases: 9.999968e-01 [2.167112e-07] 
Layer 'fc6' weights[0]: 7.582682e-03 [1.730222e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.756547e-08] 
Layer 'fc7' weights[0]: 7.338098e-03 [4.405405e-08] 
Layer 'fc7' biases: 9.998659e-01 [1.966845e-08] 
Layer 'fc8' weights[0]: 1.385995e-03 [5.601997e-06] 
Layer 'fc8' biases: 3.778268e-02 [2.943135e-05] 
Train error last 870 batches: 0.435260
-------------------------------------------------------
Not saving because 0.421337 > 0.415707 (12.630: -0.00%)
======================================================= (12.075 sec)
16.401... logprob:  0.466201, 0.125000 (1.451 sec)
16.402... logprob:  0.474283, 0.125000 (1.484 sec)
16.403... logprob:  0.462249, 0.125000 (1.440 sec)
16.404... logprob:  0.474830, 0.125000 (1.433 sec)
16.405... logprob:  0.543836, 0.156250 (1.440 sec)
16.406... logprob:  0.357917, 0.085938 (1.429 sec)
16.407... logprob:  0.492676, 0.140625 (1.433 sec)
16.408... logprob:  0.339774, 0.078125 (1.479 sec)
16.409... logprob:  0.401026, 0.101562 (1.444 sec)
16.410... logprob:  0.581722, 0.171875 (1.450 sec)
16.411... logprob:  0.398317, 0.101562 (1.474 sec)
16.412... logprob:  0.540203, 0.156250 (1.441 sec)
16.413... logprob:  0.544714, 0.156250 (1.439 sec)
16.414... logprob:  0.466638, 0.125000 (1.431 sec)
16.415... logprob:  0.401797, 0.101562 (1.428 sec)
16.416... logprob:  0.427569, 0.109375 (1.437 sec)
16.417... logprob:  0.405406, 0.093750 (1.468 sec)
16.418... logprob:  0.380058, 0.093750 (1.449 sec)
16.419... logprob:  0.417537, 0.101562 (1.456 sec)
16.420... logprob:  0.355843, 0.085938 (1.460 sec)
16.421... logprob:  0.376528, 0.101562 (1.464 sec)
16.422... logprob:  0.523185, 0.148438 (1.442 sec)
16.423... logprob:  0.421061, 0.109375 (1.428 sec)
16.424... logprob:  0.324585, 0.078125 (1.429 sec)
16.425... logprob:  0.306095, 0.070312 (1.445 sec)
16.426... logprob:  0.449467, 0.117188 (1.443 sec)
16.427... logprob:  0.555116, 0.156250 (1.467 sec)
16.428... logprob:  0.602393, 0.171875 (1.450 sec)
16.429... logprob:  0.426266, 0.109375 (1.442 sec)
16.430... logprob:  0.299991, 0.070312 (1.478 sec)
16.431... logprob:  0.599201, 0.171875 (1.431 sec)
16.432... logprob:  0.387617, 0.093750 (1.433 sec)
16.433... logprob:  0.330336, 0.078125 (1.433 sec)
16.434... logprob:  0.529040, 0.148438 (1.442 sec)
16.435... logprob:  0.531993, 0.156250 (1.432 sec)
16.436... logprob:  0.381670, 0.093750 (1.480 sec)
16.437... logprob:  0.500215, 0.140625 (1.443 sec)
16.438... logprob:  0.546749, 0.156250 (1.437 sec)
16.439... logprob:  0.379288, 0.093750 (1.490 sec)
16.440... logprob:  0.439912, 0.117188 (1.436 sec)
16.441... logprob:  0.468056, 0.125000 (1.428 sec)
16.442... logprob:  0.378916, 0.093750 (1.441 sec)
16.443... logprob:  0.496591, 0.140625 (1.432 sec)
16.444... logprob:  0.372045, 0.093750 (1.432 sec)
16.445... logprob:  0.362087, 0.085938 (1.487 sec)
16.446... logprob:  0.398054, 0.101562 (1.440 sec)
16.447... logprob:  0.570509, 0.164062 (1.440 sec)
16.448... logprob:  0.332417, 0.078125 (1.484 sec)
16.449... logprob:  0.400022, 0.101562 (1.435 sec)
16.450... logprob:  0.238687, 0.046875 (1.435 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.0254020690918, 10.0]}, 128)
batch 872: ({'logprob': [67.71973419189453, 19.0]}, 128)
batch 873: ({'logprob': [39.779781341552734, 9.0]}, 128)
batch 874: ({'logprob': [44.76762390136719, 11.0]}, 128)
batch 875: ({'logprob': [50.74006652832031, 13.0]}, 128)
batch 876: ({'logprob': [64.99604034423828, 18.0]}, 128)
batch 877: ({'logprob': [45.26508331298828, 11.0]}, 128)
batch 878: ({'logprob': [62.72691345214844, 17.0]}, 128)
batch 879: ({'logprob': [75.17508697509766, 21.0]}, 128)
batch 880: ({'logprob': [50.757808685302734, 13.0]}, 128)
batch 881: ({'logprob': [27.29813575744629, 5.0]}, 128)
batch 882: ({'logprob': [54.98314666748047, 14.0]}, 128)
batch 883: ({'logprob': [62.71000289916992, 17.0]}, 128)
batch 884: ({'logprob': [51.23775100708008, 13.0]}, 128)
batch 885: ({'logprob': [52.227394104003906, 13.0]}, 128)
batch 886: ({'logprob': [63.21648406982422, 17.0]}, 128)

======================Test output======================
logprob:  0.417298, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.969042e-03 [3.753982e-09] 
Layer 'conv1' biases: 1.579997e-07 [1.166286e-10] 
Layer 'conv2' weights[0]: 7.956081e-03 [3.791510e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.712392e-10] 
Layer 'conv3' weights[0]: 7.954418e-03 [3.545836e-09] 
Layer 'conv3' biases: 1.371366e-06 [2.138193e-09] 
Layer 'conv4' weights[0]: 7.986941e-03 [3.841335e-09] 
Layer 'conv4' biases: 9.999995e-01 [1.961657e-08] 
Layer 'conv5' weights[0]: 7.985819e-03 [1.308180e-07] 
Layer 'conv5' biases: 9.999967e-01 [1.413243e-07] 
Layer 'fc6' weights[0]: 7.582640e-03 [1.110350e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.134086e-08] 
Layer 'fc7' weights[0]: 7.336258e-03 [3.740676e-07] 
Layer 'fc7' biases: 9.998649e-01 [3.616324e-07] 
Layer 'fc8' weights[0]: 1.352677e-03 [1.386484e-05] 
Layer 'fc8' biases: 3.797522e-02 [9.203223e-05] 
Train error last 870 batches: 0.435259
-------------------------------------------------------
Not saving because 0.417298 > 0.415707 (12.630: -0.00%)
======================================================= (12.027 sec)
16.451... logprob:  0.453120, 0.125000 (1.443 sec)
16.452... logprob:  0.456442, 0.117188 (1.429 sec)
16.453... logprob:  0.455591, 0.125000 (1.437 sec)
16.454... logprob:  0.489311, 0.132812 (1.491 sec)
16.455... logprob:  0.506153, 0.140625 (1.439 sec)
16.456... logprob:  0.468797, 0.125000 (1.447 sec)
16.457... logprob:  0.375401, 0.093750 (1.479 sec)
16.458... logprob:  0.351261, 0.085938 (1.432 sec)
16.459... logprob:  0.513586, 0.140625 (1.442 sec)
16.460... logprob:  0.274749, 0.054688 (1.434 sec)
16.461... logprob:  0.459958, 0.125000 (1.426 sec)
16.462... logprob:  0.471880, 0.125000 (1.438 sec)
16.463... logprob:  0.420975, 0.109375 (1.475 sec)
16.464... logprob:  0.482664, 0.132812 (1.447 sec)
16.465... logprob:  0.421238, 0.109375 (1.453 sec)
16.466... logprob:  0.318704, 0.070312 (1.464 sec)
16.467... logprob:  0.413878, 0.109375 (1.452 sec)
16.468... logprob:  0.394279, 0.101562 (1.441 sec)
16.469... logprob:  0.334627, 0.078125 (1.426 sec)
16.470... logprob:  0.400046, 0.101562 (1.430 sec)
16.471... logprob:  0.529703, 0.148438 (1.443 sec)
16.472... logprob:  0.410097, 0.109375 (1.450 sec)
16.473... logprob:  0.375320, 0.093750 (1.463 sec)
16.474... logprob:  0.465854, 0.125000 (1.451 sec)
16.475... logprob:  0.504504, 0.140625 (1.453 sec)
16.476... logprob:  0.510546, 0.140625 (1.469 sec)
16.477... logprob:  0.334481, 0.078125 (1.436 sec)
16.478... logprob:  0.464300, 0.125000 (1.428 sec)
16.479... logprob:  0.305800, 0.070312 (1.431 sec)
16.480... logprob:  0.443521, 0.117188 (1.442 sec)
16.481... logprob:  0.547728, 0.156250 (1.437 sec)
16.482... logprob:  0.443191, 0.117188 (1.482 sec)
16.483... logprob:  0.502553, 0.140625 (1.448 sec)
16.484... logprob:  0.485284, 0.132812 (1.434 sec)
16.485... logprob:  0.409119, 0.109375 (1.486 sec)
16.486... logprob:  0.361678, 0.085938 (1.433 sec)
16.487... logprob:  0.522602, 0.148438 (1.427 sec)
16.488... logprob:  0.424920, 0.109375 (1.440 sec)
16.489... logprob:  0.415974, 0.109375 (1.433 sec)
16.490... logprob:  0.440705, 0.117188 (1.439 sec)
16.491... logprob:  0.313723, 0.070312 (1.479 sec)
16.492... logprob:  0.459622, 0.125000 (1.445 sec)
16.493... logprob:  0.521992, 0.148438 (1.436 sec)
16.494... logprob:  0.450387, 0.125000 (1.487 sec)
16.495... logprob:  0.380530, 0.093750 (1.442 sec)
16.496... logprob:  0.550581, 0.156250 (1.437 sec)
16.497... logprob:  0.467068, 0.125000 (1.430 sec)
16.498... logprob:  0.476364, 0.132812 (1.436 sec)
16.499... logprob:  0.456290, 0.125000 (1.432 sec)
16.500... logprob:  0.355064, 0.085938 (1.485 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.02251434326172, 10.0]}, 128)
batch 872: ({'logprob': [66.31155395507812, 19.0]}, 128)
batch 873: ({'logprob': [40.93266296386719, 9.0]}, 128)
batch 874: ({'logprob': [45.44670486450195, 11.0]}, 128)
batch 875: ({'logprob': [50.88279724121094, 13.0]}, 128)
batch 876: ({'logprob': [63.83959197998047, 18.0]}, 128)
batch 877: ({'logprob': [45.91397476196289, 11.0]}, 128)
batch 878: ({'logprob': [61.792938232421875, 17.0]}, 128)
batch 879: ({'logprob': [73.13308715820312, 21.0]}, 128)
batch 880: ({'logprob': [50.89993667602539, 13.0]}, 128)
batch 881: ({'logprob': [29.560932159423828, 5.0]}, 128)
batch 882: ({'logprob': [54.773868560791016, 14.0]}, 128)
batch 883: ({'logprob': [61.77617645263672, 17.0]}, 128)
batch 884: ({'logprob': [51.345184326171875, 13.0]}, 128)
batch 885: ({'logprob': [52.269901275634766, 13.0]}, 128)
batch 886: ({'logprob': [62.248531341552734, 17.0]}, 128)

======================Test output======================
logprob:  0.416577, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.969011e-03 [2.372547e-09] 
Layer 'conv1' biases: 1.588358e-07 [4.009236e-11] 
Layer 'conv2' weights[0]: 7.956048e-03 [1.869944e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.053032e-10] 
Layer 'conv3' weights[0]: 7.954377e-03 [1.634100e-09] 
Layer 'conv3' biases: 1.380439e-06 [6.966632e-10] 
Layer 'conv4' weights[0]: 7.986901e-03 [1.839358e-09] 
Layer 'conv4' biases: 9.999995e-01 [6.797192e-09] 
Layer 'conv5' weights[0]: 7.985781e-03 [4.599077e-08] 
Layer 'conv5' biases: 9.999974e-01 [4.981199e-08] 
Layer 'fc6' weights[0]: 7.582606e-03 [3.983628e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.949133e-09] 
Layer 'fc7' weights[0]: 7.334432e-03 [3.898536e-08] 
Layer 'fc7' biases: 9.998638e-01 [1.051162e-08] 
Layer 'fc8' weights[0]: 1.302560e-03 [2.761743e-06] 
Layer 'fc8' biases: 3.780457e-02 [1.716153e-05] 
Train error last 870 batches: 0.435259
-------------------------------------------------------
Not saving because 0.416577 > 0.415707 (12.630: -0.00%)
======================================================= (12.102 sec)
16.501... logprob:  0.339106, 0.078125 (1.441 sec)
16.502... logprob:  0.459674, 0.125000 (1.448 sec)
16.503... logprob:  0.400695, 0.101562 (1.473 sec)
16.504... logprob:  0.487351, 0.132812 (1.438 sec)
16.505... logprob:  0.570813, 0.164062 (1.439 sec)
16.506... logprob:  0.479681, 0.132812 (1.434 sec)
16.507... logprob:  0.385159, 0.093750 (1.428 sec)
16.508... logprob:  0.374778, 0.093750 (1.438 sec)
16.509... logprob:  0.323256, 0.070312 (1.476 sec)
16.510... logprob:  0.390493, 0.101562 (1.445 sec)
16.511... logprob:  0.410089, 0.109375 (1.452 sec)
16.512... logprob:  0.470751, 0.125000 (1.471 sec)
16.513... logprob:  0.324979, 0.078125 (1.443 sec)
16.514... logprob:  0.406279, 0.101562 (1.443 sec)
16.515... logprob:  0.455619, 0.125000 (1.428 sec)
16.516... logprob:  0.400439, 0.109375 (1.431 sec)
16.517... logprob:  0.628099, 0.179688 (1.436 sec)
16.518... logprob:  0.437730, 0.117188 (1.460 sec)
16.519... logprob:  0.516160, 0.140625 (1.461 sec)
16.520... logprob:  0.409658, 0.109375 (1.451 sec)
16.521... logprob:  0.427534, 0.109375 (1.454 sec)
16.522... logprob:  0.533060, 0.156250 (1.467 sec)
16.523... logprob:  0.331816, 0.078125 (1.440 sec)
16.524... logprob:  0.437252, 0.117188 (1.424 sec)
16.525... logprob:  0.426118, 0.109375 (1.434 sec)
16.526... logprob:  0.352004, 0.078125 (1.437 sec)
16.527... logprob:  0.504536, 0.140625 (1.445 sec)
16.528... logprob:  0.440525, 0.117188 (1.476 sec)
16.529... logprob:  0.353018, 0.085938 (1.449 sec)
16.530... logprob:  0.440248, 0.117188 (1.437 sec)
16.531... logprob:  0.440022, 0.117188 (1.480 sec)
16.532... logprob:  0.467416, 0.125000 (1.437 sec)
16.533... logprob:  0.560764, 0.164062 (1.427 sec)
16.534... logprob:  0.325764, 0.078125 (1.438 sec)
16.535... logprob:  0.551728, 0.156250 (1.435 sec)
16.536... logprob:  0.507429, 0.140625 (1.440 sec)
16.537... logprob:  0.510096, 0.140625 (1.478 sec)
16.538... logprob:  0.486119, 0.132812 (1.440 sec)
16.539... logprob:  0.296167, 0.062500 (1.430 sec)
16.540... logprob:  0.447182, 0.117188 (1.489 sec)
16.541... logprob:  0.388909, 0.101562 (1.435 sec)
16.542... logprob:  0.411329, 0.109375 (1.429 sec)
16.543... logprob:  0.233433, 0.039062 (1.442 sec)
16.544... logprob:  0.317954, 0.070312 (1.428 sec)
16.545... logprob:  0.348815, 0.085938 (1.438 sec)
16.546... logprob:  0.368292, 0.093750 (1.483 sec)
16.547... logprob:  0.440166, 0.117188 (1.440 sec)
16.548... logprob:  0.453242, 0.125000 (1.441 sec)
16.549... logprob:  0.490772, 0.132812 (1.484 sec)
16.550... logprob:  0.367708, 0.093750 (1.429 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.8489875793457, 10.0]}, 128)
batch 872: ({'logprob': [68.42618560791016, 19.0]}, 128)
batch 873: ({'logprob': [39.57070541381836, 9.0]}, 128)
batch 874: ({'logprob': [44.71918487548828, 11.0]}, 128)
batch 875: ({'logprob': [50.88918685913086, 13.0]}, 128)
batch 876: ({'logprob': [65.61355590820312, 18.0]}, 128)
batch 877: ({'logprob': [45.23490905761719, 11.0]}, 128)
batch 878: ({'logprob': [63.27314758300781, 17.0]}, 128)
batch 879: ({'logprob': [76.13676452636719, 21.0]}, 128)
batch 880: ({'logprob': [50.907386779785156, 13.0]}, 128)
batch 881: ({'logprob': [26.673002243041992, 5.0]}, 128)
batch 882: ({'logprob': [55.27979278564453, 14.0]}, 128)
batch 883: ({'logprob': [63.25578308105469, 17.0]}, 128)
batch 884: ({'logprob': [51.4071044921875, 13.0]}, 128)
batch 885: ({'logprob': [52.43488311767578, 13.0]}, 128)
batch 886: ({'logprob': [63.782344818115234, 17.0]}, 128)

======================Test output======================
logprob:  0.419166, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.968969e-03 [3.370149e-09] 
Layer 'conv1' biases: 1.595005e-07 [7.618227e-11] 
Layer 'conv2' weights[0]: 7.956007e-03 [3.151839e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.967434e-10] 
Layer 'conv3' weights[0]: 7.954339e-03 [2.704187e-09] 
Layer 'conv3' biases: 1.386680e-06 [1.588233e-09] 
Layer 'conv4' weights[0]: 7.986868e-03 [2.911476e-09] 
Layer 'conv4' biases: 9.999995e-01 [1.364542e-08] 
Layer 'conv5' weights[0]: 7.985753e-03 [8.613833e-08] 
Layer 'conv5' biases: 9.999968e-01 [9.315691e-08] 
Layer 'fc6' weights[0]: 7.582565e-03 [7.432209e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.552255e-09] 
Layer 'fc7' weights[0]: 7.332521e-03 [4.897114e-08] 
Layer 'fc7' biases: 9.998656e-01 [2.644435e-08] 
Layer 'fc8' weights[0]: 1.366486e-03 [7.516285e-06] 
Layer 'fc8' biases: 3.832848e-02 [4.249199e-05] 
Train error last 870 batches: 0.435258
-------------------------------------------------------
Not saving because 0.419166 > 0.415707 (12.630: -0.00%)
======================================================= (12.064 sec)
16.551... logprob:  0.441828, 0.117188 (1.443 sec)
16.552... logprob:  0.471355, 0.125000 (1.436 sec)
16.553... logprob:  0.349434, 0.085938 (1.430 sec)
16.554... logprob:  0.506825, 0.140625 (1.433 sec)
16.555... logprob:  0.421414, 0.109375 (1.487 sec)
16.556... logprob:  0.355955, 0.085938 (1.446 sec)
16.557... logprob:  0.396507, 0.101562 (1.450 sec)
16.558... logprob:  0.383079, 0.101562 (1.476 sec)
16.559... logprob:  0.441430, 0.125000 (1.435 sec)
16.560... logprob:  0.335392, 0.078125 (1.442 sec)
16.561... logprob:  0.411855, 0.109375 (1.440 sec)
16.562... logprob:  0.503111, 0.140625 (1.428 sec)
16.563... logprob:  0.373880, 0.093750 (1.439 sec)
16.564... logprob:  0.468417, 0.132812 (1.468 sec)
16.565... logprob:  0.611023, 0.187500 (1.451 sec)
16.566... logprob:  0.374926, 0.093750 (1.453 sec)
16.567... logprob:  0.423465, 0.109375 (1.469 sec)
16.568... logprob:  0.496388, 0.140625 (1.453 sec)
16.569... logprob:  0.507880, 0.140625 (1.439 sec)
16.570... logprob:  0.543721, 0.164062 (1.433 sec)
16.571... logprob:  0.454874, 0.125000 (1.428 sec)
16.572... logprob:  0.501500, 0.140625 (1.443 sec)
16.573... logprob:  0.512637, 0.148438 (1.444 sec)
16.574... logprob:  0.428169, 0.109375 (1.467 sec)
16.575... logprob:  0.343368, 0.078125 (1.449 sec)
16.576... logprob:  0.427419, 0.109375 (1.448 sec)
16.577... logprob:  0.460854, 0.125000 (1.475 sec)
16.578... logprob:  0.336557, 0.078125 (1.439 sec)
16.579... logprob:  0.442090, 0.117188 (1.427 sec)
16.580... logprob:  0.547000, 0.156250 (1.434 sec)
16.581... logprob:  0.531068, 0.156250 (1.441 sec)
16.582... logprob:  0.437917, 0.125000 (1.433 sec)
16.583... logprob:  0.592931, 0.171875 (1.479 sec)
16.584... logprob:  0.468138, 0.132812 (1.447 sec)
16.585... logprob:  0.349767, 0.085938 (1.436 sec)
16.586... logprob:  0.313171, 0.070312 (1.486 sec)
16.587... logprob:  0.404319, 0.101562 (1.436 sec)
16.588... logprob:  0.418676, 0.117188 (1.428 sec)
16.589... logprob:  0.361323, 0.093750 (1.430 sec)
16.590... logprob:  0.524690, 0.148438 (1.439 sec)
16.591... logprob:  0.397526, 0.101562 (1.430 sec)
16.592... logprob:  0.455642, 0.125000 (1.491 sec)
16.593... logprob:  0.467442, 0.125000 (1.433 sec)
16.594... logprob:  0.352882, 0.085938 (1.443 sec)
16.595... logprob:  0.428672, 0.109375 (1.482 sec)
16.596... logprob:  0.461579, 0.125000 (1.438 sec)
16.597... logprob:  0.397412, 0.101562 (1.435 sec)
16.598... logprob:  0.397233, 0.101562 (1.433 sec)
16.599... logprob:  0.313500, 0.070312 (1.432 sec)
16.600... logprob:  0.340900, 0.085938 (1.434 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.99177551269531, 10.0]}, 128)
batch 872: ({'logprob': [66.88349151611328, 19.0]}, 128)
batch 873: ({'logprob': [40.521583557128906, 9.0]}, 128)
batch 874: ({'logprob': [44.95450973510742, 11.0]}, 128)
batch 875: ({'logprob': [50.771995544433594, 13.0]}, 128)
batch 876: ({'logprob': [64.33687591552734, 18.0]}, 128)
batch 877: ({'logprob': [45.65199661254883, 11.0]}, 128)
batch 878: ({'logprob': [62.44590377807617, 17.0]}, 128)
batch 879: ({'logprob': [74.77983856201172, 21.0]}, 128)
batch 880: ({'logprob': [50.788848876953125, 13.0]}, 128)
batch 881: ({'logprob': [28.154165267944336, 5.0]}, 128)
batch 882: ({'logprob': [55.4336051940918, 14.0]}, 128)
batch 883: ({'logprob': [62.429012298583984, 17.0]}, 128)
batch 884: ({'logprob': [51.46746063232422, 13.0]}, 128)
batch 885: ({'logprob': [52.85546875, 13.0]}, 128)
batch 886: ({'logprob': [63.133949279785156, 17.0]}, 128)

======================Test output======================
logprob:  0.417774, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.968932e-03 [2.698554e-09] 
Layer 'conv1' biases: 1.604374e-07 [8.635535e-11] 
Layer 'conv2' weights[0]: 7.955967e-03 [2.372698e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.573520e-10] 
Layer 'conv3' weights[0]: 7.954293e-03 [2.381965e-09] 
Layer 'conv3' biases: 1.393748e-06 [1.456882e-09] 
Layer 'conv4' weights[0]: 7.986833e-03 [2.592227e-09] 
Layer 'conv4' biases: 9.999995e-01 [1.367793e-08] 
Layer 'conv5' weights[0]: 7.985706e-03 [9.138892e-08] 
Layer 'conv5' biases: 9.999968e-01 [9.885279e-08] 
Layer 'fc6' weights[0]: 7.582528e-03 [7.827943e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.929629e-09] 
Layer 'fc7' weights[0]: 7.330680e-03 [1.608537e-07] 
Layer 'fc7' biases: 9.998648e-01 [1.487055e-07] 
Layer 'fc8' weights[0]: 1.332793e-03 [7.285056e-06] 
Layer 'fc8' biases: 3.822651e-02 [4.580473e-05] 
Train error last 870 batches: 0.435258
-------------------------------------------------------
Not saving because 0.417774 > 0.415707 (12.630: -0.00%)
======================================================= (12.024 sec)
16.601... logprob:  0.402120, 0.101562 (1.490 sec)
16.602... logprob:  0.289662, 0.062500 (1.436 sec)
16.603... logprob:  0.266907, 0.054688 (1.448 sec)
16.604... logprob:  0.407513, 0.101562 (1.477 sec)
16.605... logprob:  0.563632, 0.148438 (1.437 sec)
16.606... logprob:  0.295948, 0.070312 (1.439 sec)
16.607... logprob:  0.504954, 0.132812 (1.437 sec)
16.608... logprob:  0.361665, 0.085938 (1.424 sec)
16.609... logprob:  0.356913, 0.085938 (1.439 sec)
16.610... logprob:  0.493448, 0.132812 (1.474 sec)
16.611... logprob:  0.510448, 0.140625 (1.441 sec)
16.612... logprob:  0.448378, 0.117188 (1.455 sec)
16.613... logprob:  0.279842, 0.062500 (1.461 sec)
16.614... logprob:  0.503510, 0.140625 (1.451 sec)
16.615... logprob:  0.351209, 0.085938 (1.437 sec)
16.616... logprob:  0.415376, 0.109375 (1.433 sec)
16.617... logprob:  0.417989, 0.109375 (1.427 sec)
16.618... logprob:  0.546662, 0.156250 (1.441 sec)
16.619... logprob:  0.505928, 0.140625 (1.452 sec)
16.620... logprob:  0.539613, 0.156250 (1.456 sec)
16.621... logprob:  0.363961, 0.085938 (1.453 sec)
16.622... logprob:  0.364973, 0.085938 (1.450 sec)
16.623... logprob:  0.423229, 0.109375 (1.468 sec)
16.624... logprob:  0.382559, 0.093750 (1.441 sec)
16.625... logprob:  0.441007, 0.117188 (1.425 sec)
16.626... logprob:  0.438399, 0.117188 (1.432 sec)
16.627... logprob:  0.435866, 0.117188 (1.442 sec)
16.628... logprob:  0.465107, 0.125000 (1.438 sec)
16.629... logprob:  0.371975, 0.093750 (1.486 sec)
16.630... logprob:  0.422373, 0.109375 (1.447 sec)
16.631... logprob:  0.639452, 0.187500 (1.437 sec)
16.632... logprob:  0.399099, 0.101562 (1.486 sec)
16.633... logprob:  0.376013, 0.093750 (1.435 sec)
16.634... logprob:  0.660510, 0.195312 (1.431 sec)
16.635... logprob:  0.374125, 0.093750 (1.445 sec)
16.636... logprob:  0.480228, 0.132812 (1.436 sec)
16.637... logprob:  0.330976, 0.078125 (1.434 sec)
16.638... logprob:  0.515663, 0.140625 (1.481 sec)
16.639... logprob:  0.418173, 0.109375 (1.443 sec)
16.640... logprob:  0.528747, 0.148438 (1.439 sec)
16.641... logprob:  0.410500, 0.109375 (1.487 sec)
16.642... logprob:  0.500807, 0.140625 (1.434 sec)
16.643... logprob:  0.622792, 0.187500 (1.430 sec)
16.644... logprob:  0.321470, 0.070312 (1.441 sec)
16.645... logprob:  0.414516, 0.109375 (1.429 sec)
16.646... logprob:  0.385775, 0.093750 (1.435 sec)
16.647... logprob:  0.456747, 0.125000 (1.494 sec)
16.648... logprob:  0.491228, 0.140625 (1.439 sec)
16.649... logprob:  0.370089, 0.093750 (1.447 sec)
16.650... logprob:  0.413925, 0.109375 (1.477 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.950782775878906, 10.0]}, 128)
batch 872: ({'logprob': [66.35676574707031, 19.0]}, 128)
batch 873: ({'logprob': [40.85946273803711, 9.0]}, 128)
batch 874: ({'logprob': [45.39314651489258, 11.0]}, 128)
batch 875: ({'logprob': [50.85542678833008, 13.0]}, 128)
batch 876: ({'logprob': [63.87367630004883, 18.0]}, 128)
batch 877: ({'logprob': [45.86368942260742, 11.0]}, 128)
batch 878: ({'logprob': [61.81850814819336, 17.0]}, 128)
batch 879: ({'logprob': [73.21461486816406, 21.0]}, 128)
batch 880: ({'logprob': [50.872703552246094, 13.0]}, 128)
batch 881: ({'logprob': [29.431480407714844, 5.0]}, 128)
batch 882: ({'logprob': [54.768184661865234, 14.0]}, 128)
batch 883: ({'logprob': [61.801483154296875, 17.0]}, 128)
batch 884: ({'logprob': [51.32135772705078, 13.0]}, 128)
batch 885: ({'logprob': [52.25260543823242, 13.0]}, 128)
batch 886: ({'logprob': [62.27747344970703, 17.0]}, 128)

======================Test output======================
logprob:  0.416461, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.968886e-03 [2.160238e-09] 
Layer 'conv1' biases: 1.612212e-07 [5.608741e-11] 
Layer 'conv2' weights[0]: 7.955929e-03 [1.864071e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.571375e-10] 
Layer 'conv3' weights[0]: 7.954249e-03 [1.872184e-09] 
Layer 'conv3' biases: 1.400855e-06 [1.103202e-09] 
Layer 'conv4' weights[0]: 7.986798e-03 [2.126033e-09] 
Layer 'conv4' biases: 9.999995e-01 [1.121801e-08] 
Layer 'conv5' weights[0]: 7.985671e-03 [7.625314e-08] 
Layer 'conv5' biases: 9.999969e-01 [8.279842e-08] 
Layer 'fc6' weights[0]: 7.582483e-03 [6.411098e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.513319e-09] 
Layer 'fc7' weights[0]: 7.328802e-03 [2.398148e-07] 
Layer 'fc7' biases: 9.998637e-01 [2.276151e-07] 
Layer 'fc8' weights[0]: 1.308053e-03 [1.065262e-05] 
Layer 'fc8' biases: 3.821965e-02 [7.112263e-05] 
Train error last 870 batches: 0.435258
-------------------------------------------------------
Not saving because 0.416461 > 0.415707 (12.630: -0.00%)
======================================================= (12.071 sec)
16.651... logprob:  0.397292, 0.101562 (1.439 sec)
16.652... logprob:  0.507434, 0.140625 (1.443 sec)
16.653... logprob:  0.548187, 0.156250 (1.437 sec)
16.654... logprob:  0.496168, 0.140625 (1.430 sec)
16.655... logprob:  0.436215, 0.117188 (1.435 sec)
16.656... logprob:  0.416671, 0.109375 (1.480 sec)
16.657... logprob:  0.449296, 0.117188 (1.442 sec)
16.658... logprob:  0.345754, 0.085938 (1.454 sec)
16.659... logprob:  0.464360, 0.125000 (1.477 sec)
16.660... logprob:  0.445896, 0.125000 (1.446 sec)
16.661... logprob:  0.378560, 0.093750 (1.437 sec)
16.662... logprob:  0.469328, 0.132812 (1.436 sec)
16.663... logprob:  0.311069, 0.070312 (1.430 sec)
16.664... logprob:  0.285526, 0.062500 (1.441 sec)
16.665... logprob:  0.401865, 0.101562 (1.463 sec)
16.666... logprob:  0.442071, 0.117188 (1.459 sec)
16.667... logprob:  0.564323, 0.164062 (1.452 sec)
16.668... logprob:  0.497924, 0.140625 (1.464 sec)
16.669... logprob:  0.433110, 0.109375 (1.461 sec)
16.670... logprob:  0.362498, 0.085938 (1.439 sec)
16.671... logprob:  0.360854, 0.093750 (1.431 sec)
16.672... logprob:  0.441811, 0.117188 (1.429 sec)
16.673... logprob:  0.436246, 0.117188 (1.442 sec)
16.674... logprob:  0.446670, 0.117188 (1.442 sec)
16.675... logprob:  0.356666, 0.093750 (1.468 sec)
16.676... logprob:  0.450146, 0.125000 (1.453 sec)
16.677... logprob:  0.471062, 0.125000 (1.469 sec)
16.678... logprob:  0.465641, 0.125000 (1.479 sec)
16.679... logprob:  0.454875, 0.125000 (1.440 sec)
16.680... logprob:  0.351742, 0.078125 (1.425 sec)
16.681... logprob:  0.373951, 0.093750 (1.518 sec)
16.682... logprob:  0.340508, 0.078125 (1.440 sec)
16.683... logprob:  0.411650, 0.109375 (1.435 sec)
16.684... logprob:  0.357591, 0.085938 (1.475 sec)
16.685... logprob:  0.285830, 0.054688 (1.449 sec)
16.686... logprob:  0.318494, 0.070312 (1.432 sec)
16.687... logprob:  0.281489, 0.062500 (1.490 sec)
16.688... logprob:  0.323074, 0.078125 (1.437 sec)
16.689... logprob:  0.471599, 0.125000 (1.430 sec)
16.690... logprob:  0.528185, 0.140625 (1.439 sec)
16.691... logprob:  0.517167, 0.140625 (1.428 sec)
16.692... logprob:  0.385377, 0.101562 (1.430 sec)
16.693... logprob:  0.456087, 0.125000 (1.484 sec)
16.694... logprob:  0.330885, 0.078125 (1.437 sec)
16.695... logprob:  0.356886, 0.085938 (1.444 sec)
16.696... logprob:  0.538734, 0.148438 (1.479 sec)
16.697... logprob:  0.465562, 0.125000 (1.439 sec)
16.698... logprob:  0.548467, 0.156250 (1.433 sec)
16.699... logprob:  0.459579, 0.125000 (1.441 sec)
16.700... logprob:  0.434065, 0.117188 (1.427 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.099891662597656, 10.0]}, 128)
batch 872: ({'logprob': [65.927734375, 19.0]}, 128)
batch 873: ({'logprob': [42.05868148803711, 9.0]}, 128)
batch 874: ({'logprob': [46.30994415283203, 11.0]}, 128)
batch 875: ({'logprob': [51.41875457763672, 13.0]}, 128)
batch 876: ({'logprob': [63.6030387878418, 18.0]}, 128)
batch 877: ({'logprob': [46.74578857421875, 11.0]}, 128)
batch 878: ({'logprob': [61.67189025878906, 17.0]}, 128)
batch 879: ({'logprob': [72.32247161865234, 21.0]}, 128)
batch 880: ({'logprob': [51.43555450439453, 13.0]}, 128)
batch 881: ({'logprob': [31.377429962158203, 5.0]}, 128)
batch 882: ({'logprob': [55.06166076660156, 14.0]}, 128)
batch 883: ({'logprob': [61.65507888793945, 17.0]}, 128)
batch 884: ({'logprob': [51.84600067138672, 13.0]}, 128)
batch 885: ({'logprob': [52.704280853271484, 13.0]}, 128)
batch 886: ({'logprob': [62.09325408935547, 17.0]}, 128)

======================Test output======================
logprob:  0.419595, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.968851e-03 [2.780347e-09] 
Layer 'conv1' biases: 1.620676e-07 [4.502456e-11] 
Layer 'conv2' weights[0]: 7.955890e-03 [1.717388e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.688793e-10] 
Layer 'conv3' weights[0]: 7.954212e-03 [1.334151e-09] 
Layer 'conv3' biases: 1.410284e-06 [5.725913e-10] 
Layer 'conv4' weights[0]: 7.986765e-03 [1.274819e-09] 
Layer 'conv4' biases: 9.999996e-01 [3.124443e-09] 
Layer 'conv5' weights[0]: 7.985621e-03 [1.710856e-08] 
Layer 'conv5' biases: 9.999979e-01 [1.830348e-08] 
Layer 'fc6' weights[0]: 7.582449e-03 [1.669858e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.491083e-09] 
Layer 'fc7' weights[0]: 7.326979e-03 [3.666795e-07] 
Layer 'fc7' biases: 9.998630e-01 [3.555870e-07] 
Layer 'fc8' weights[0]: 1.279697e-03 [1.368596e-05] 
Layer 'fc8' biases: 3.815773e-02 [8.202057e-05] 
Train error last 870 batches: 0.435257
-------------------------------------------------------
Not saving because 0.419595 > 0.415707 (12.630: -0.00%)
======================================================= (12.068 sec)
16.701... logprob:  0.423399, 0.109375 (1.452 sec)
16.702... logprob:  0.521438, 0.148438 (1.481 sec)
16.703... logprob:  0.405594, 0.101562 (1.440 sec)
16.704... logprob:  0.406383, 0.101562 (1.450 sec)
16.705... logprob:  0.420330, 0.109375 (1.555 sec)
16.706... logprob:  0.468082, 0.125000 (1.433 sec)
16.707... logprob:  0.485300, 0.132812 (1.437 sec)
16.708... logprob:  0.417024, 0.109375 (1.438 sec)
16.709... logprob:  0.422412, 0.109375 (1.422 sec)
16.710... logprob:  0.602871, 0.179688 (1.443 sec)
16.711... logprob:  0.469538, 0.125000 (1.462 sec)
16.712... logprob:  0.340269, 0.078125 (1.446 sec)
16.713... logprob:  0.587451, 0.179688 (1.454 sec)
16.714... logprob:  0.466348, 0.125000 (1.460 sec)
16.715... logprob:  0.417130, 0.109375 (1.454 sec)
16.716... logprob:  0.335220, 0.078125 (1.443 sec)
16.717... logprob:  0.429842, 0.117188 (1.428 sec)
16.718... logprob:  0.490392, 0.132812 (1.431 sec)
16.719... logprob:  0.406203, 0.109375 (1.441 sec)
16.720... logprob:  0.433240, 0.117188 (1.445 sec)
16.721... logprob:  0.451600, 0.117188 (1.468 sec)
16.722... logprob:  0.536818, 0.156250 (1.453 sec)
16.723... logprob:  0.416610, 0.109375 (1.445 sec)
16.724... logprob:  0.412783, 0.109375 (1.475 sec)
16.725... logprob:  0.494634, 0.140625 (1.436 sec)
16.726... logprob:  0.338714, 0.085938 (1.427 sec)
16.727... logprob:  0.393399, 0.101562 (1.439 sec)
16.728... logprob:  0.421384, 0.109375 (1.439 sec)
16.729... logprob:  0.387826, 0.093750 (1.437 sec)
16.730... logprob:  0.565820, 0.164062 (1.473 sec)
16.731... logprob:  0.450319, 0.125000 (1.447 sec)
16.732... logprob:  0.311492, 0.070312 (1.437 sec)
16.733... logprob:  0.556719, 0.156250 (1.490 sec)
16.734... logprob:  0.340222, 0.078125 (1.433 sec)
16.735... logprob:  0.527646, 0.148438 (1.431 sec)
16.736... logprob:  0.643090, 0.187500 (1.436 sec)
16.737... logprob:  0.516219, 0.148438 (1.435 sec)
16.738... logprob:  0.459437, 0.125000 (1.435 sec)
16.739... logprob:  0.477819, 0.132812 (1.486 sec)
16.740... logprob:  0.339664, 0.078125 (1.437 sec)
16.741... logprob:  0.393450, 0.101562 (1.443 sec)
16.742... logprob:  0.419747, 0.109375 (1.489 sec)
16.743... logprob:  0.364873, 0.085938 (1.439 sec)
16.744... logprob:  0.519262, 0.148438 (1.431 sec)
16.745... logprob:  0.478184, 0.132812 (1.440 sec)
16.746... logprob:  0.440562, 0.117188 (1.428 sec)
16.747... logprob:  0.425632, 0.109375 (1.438 sec)
16.748... logprob:  0.378046, 0.093750 (1.485 sec)
16.749... logprob:  0.420850, 0.109375 (1.438 sec)
16.750... logprob:  0.512933, 0.140625 (1.449 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.45564651489258, 10.0]}, 128)
batch 872: ({'logprob': [66.71215057373047, 19.0]}, 128)
batch 873: ({'logprob': [40.44330978393555, 9.0]}, 128)
batch 874: ({'logprob': [45.0710334777832, 11.0]}, 128)
batch 875: ({'logprob': [50.72737503051758, 13.0]}, 128)
batch 876: ({'logprob': [64.15734100341797, 18.0]}, 128)
batch 877: ({'logprob': [45.591182708740234, 11.0]}, 128)
batch 878: ({'logprob': [62.079776763916016, 17.0]}, 128)
batch 879: ({'logprob': [73.91497802734375, 21.0]}, 128)
batch 880: ({'logprob': [50.744747161865234, 13.0]}, 128)
batch 881: ({'logprob': [28.57533073425293, 5.0]}, 128)
batch 882: ({'logprob': [54.86397933959961, 14.0]}, 128)
batch 883: ({'logprob': [62.06273651123047, 17.0]}, 128)
batch 884: ({'logprob': [51.24468231201172, 13.0]}, 128)
batch 885: ({'logprob': [52.27668762207031, 13.0]}, 128)
batch 886: ({'logprob': [62.58967208862305, 17.0]}, 128)

======================Test output======================
logprob:  0.416265, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.968813e-03 [3.130049e-09] 
Layer 'conv1' biases: 1.627922e-07 [7.658574e-11] 
Layer 'conv2' weights[0]: 7.955850e-03 [2.155335e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.546493e-10] 
Layer 'conv3' weights[0]: 7.954178e-03 [1.841356e-09] 
Layer 'conv3' biases: 1.414227e-06 [1.063843e-09] 
Layer 'conv4' weights[0]: 7.986730e-03 [1.962983e-09] 
Layer 'conv4' biases: 9.999996e-01 [8.737090e-09] 
Layer 'conv5' weights[0]: 7.985587e-03 [5.917173e-08] 
Layer 'conv5' biases: 9.999968e-01 [6.411525e-08] 
Layer 'fc6' weights[0]: 7.582393e-03 [5.077761e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.083354e-09] 
Layer 'fc7' weights[0]: 7.325093e-03 [7.120774e-08] 
Layer 'fc7' biases: 9.998642e-01 [5.358427e-08] 
Layer 'fc8' weights[0]: 1.326092e-03 [6.855347e-06] 
Layer 'fc8' biases: 3.863892e-02 [4.498100e-05] 
Train error last 870 batches: 0.435257
-------------------------------------------------------
Not saving because 0.416265 > 0.415707 (12.630: -0.00%)
======================================================= (12.062 sec)
16.751... logprob:  0.263520, 0.054688 (1.495 sec)
16.752... logprob:  0.522520, 0.140625 (1.441 sec)
16.753... logprob:  0.441261, 0.117188 (1.441 sec)
16.754... logprob:  0.468590, 0.132812 (1.439 sec)
16.755... logprob:  0.507123, 0.140625 (1.423 sec)
16.756... logprob:  0.440823, 0.117188 (1.441 sec)
16.757... logprob:  0.552279, 0.156250 (1.473 sec)
16.758... logprob:  0.393722, 0.101562 (1.446 sec)
16.759... logprob:  0.459691, 0.125000 (1.457 sec)
16.760... logprob:  0.485404, 0.132812 (1.463 sec)
16.761... logprob:  0.418412, 0.109375 (1.446 sec)
16.762... logprob:  0.515976, 0.148438 (1.437 sec)
16.763... logprob:  0.558769, 0.164062 (1.426 sec)
16.764... logprob:  0.503292, 0.140625 (1.433 sec)
16.765... logprob:  0.312306, 0.062500 (1.437 sec)
16.766... logprob:  0.482303, 0.132812 (1.457 sec)
16.767... logprob:  0.371179, 0.085938 (1.460 sec)
16.768... logprob:  0.432712, 0.117188 (1.462 sec)
16.769... logprob:  0.490909, 0.140625 (1.481 sec)
16.770... logprob:  0.402810, 0.101562 (1.480 sec)
16.771... logprob:  0.549704, 0.156250 (1.462 sec)
16.772... logprob:  0.414029, 0.109375 (1.444 sec)
16.773... logprob:  0.558203, 0.164062 (1.449 sec)
16.774... logprob:  0.361507, 0.085938 (1.475 sec)
16.775... logprob:  0.407317, 0.101562 (1.466 sec)
16.776... logprob:  0.433251, 0.117188 (1.483 sec)
16.777... logprob:  0.379916, 0.093750 (1.470 sec)
16.778... logprob:  0.433630, 0.117188 (1.461 sec)
16.779... logprob:  0.505489, 0.140625 (1.487 sec)
16.780... logprob:  0.385757, 0.101562 (1.459 sec)
16.781... logprob:  0.369736, 0.085938 (1.450 sec)
16.782... logprob:  0.351517, 0.085938 (1.450 sec)
16.783... logprob:  0.555460, 0.156250 (1.458 sec)
16.784... logprob:  0.440957, 0.117188 (1.457 sec)
16.785... logprob:  0.543504, 0.156250 (1.490 sec)
16.786... logprob:  0.477383, 0.132812 (1.469 sec)
16.787... logprob:  0.546153, 0.156250 (1.460 sec)
16.788... logprob:  0.562856, 0.164062 (1.498 sec)
16.789... logprob:  0.281528, 0.054688 (1.456 sec)
16.790... logprob:  0.408360, 0.101562 (1.446 sec)
16.791... logprob:  0.398187, 0.101562 (1.453 sec)
16.792... logprob:  0.361288, 0.085938 (1.460 sec)
16.793... logprob:  0.370306, 0.085938 (1.455 sec)
16.794... logprob:  0.387127, 0.093750 (1.490 sec)
16.795... logprob:  0.469837, 0.125000 (1.471 sec)
16.796... logprob:  0.423500, 0.109375 (1.455 sec)
16.797... logprob:  0.358687, 0.085938 (1.493 sec)
16.798... logprob:  0.393263, 0.101562 (1.455 sec)
16.799... logprob:  0.332144, 0.078125 (1.530 sec)
16.800... logprob:  0.371793, 0.093750 (1.446 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.20966720581055, 10.0]}, 128)
batch 872: ({'logprob': [68.4164810180664, 19.0]}, 128)
batch 873: ({'logprob': [39.39784240722656, 9.0]}, 128)
batch 874: ({'logprob': [44.77922821044922, 11.0]}, 128)
batch 875: ({'logprob': [50.847930908203125, 13.0]}, 128)
batch 876: ({'logprob': [65.57144165039062, 18.0]}, 128)
batch 877: ({'logprob': [45.128360748291016, 11.0]}, 128)
batch 878: ({'logprob': [63.03077697753906, 17.0]}, 128)
batch 879: ({'logprob': [75.5267105102539, 21.0]}, 128)
batch 880: ({'logprob': [50.86674118041992, 13.0]}, 128)
batch 881: ({'logprob': [26.868213653564453, 5.0]}, 128)
batch 882: ({'logprob': [54.77155303955078, 14.0]}, 128)
batch 883: ({'logprob': [63.01313781738281, 17.0]}, 128)
batch 884: ({'logprob': [51.199275970458984, 13.0]}, 128)
batch 885: ({'logprob': [51.89318084716797, 13.0]}, 128)
batch 886: ({'logprob': [63.373046875, 17.0]}, 128)

======================Test output======================
logprob:  0.417917, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.968767e-03 [2.583597e-09] 
Layer 'conv1' biases: 1.635820e-07 [6.233014e-11] 
Layer 'conv2' weights[0]: 7.955809e-03 [1.592510e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.051758e-10] 
Layer 'conv3' weights[0]: 7.954139e-03 [1.303024e-09] 
Layer 'conv3' biases: 1.420232e-06 [5.086368e-10] 
Layer 'conv4' weights[0]: 7.986690e-03 [1.375256e-09] 
Layer 'conv4' biases: 9.999996e-01 [4.564251e-09] 
Layer 'conv5' weights[0]: 7.985541e-03 [3.068529e-08] 
Layer 'conv5' biases: 9.999966e-01 [3.316345e-08] 
Layer 'fc6' weights[0]: 7.582352e-03 [2.731663e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.657039e-09] 
Layer 'fc7' weights[0]: 7.323152e-03 [2.589472e-07] 
Layer 'fc7' biases: 9.998648e-01 [2.475957e-07] 
Layer 'fc8' weights[0]: 1.363647e-03 [1.014471e-05] 
Layer 'fc8' biases: 3.905051e-02 [6.758044e-05] 
Train error last 870 batches: 0.435257
-------------------------------------------------------
Not saving because 0.417917 > 0.415707 (12.630: -0.00%)
======================================================= (12.045 sec)
16.801... logprob:  0.450378, 0.117188 (1.468 sec)
16.802... logprob:  0.423182, 0.109375 (1.452 sec)
16.803... logprob:  0.492066, 0.132812 (1.495 sec)
16.804... logprob:  0.349988, 0.085938 (1.461 sec)
16.805... logprob:  0.452300, 0.117188 (1.467 sec)
16.806... logprob:  0.424187, 0.109375 (1.503 sec)
16.807... logprob:  0.443449, 0.117188 (1.462 sec)
16.808... logprob:  0.462334, 0.125000 (1.449 sec)
16.809... logprob:  0.589417, 0.171875 (1.450 sec)
16.810... logprob:  0.442439, 0.117188 (1.453 sec)
16.811... logprob:  0.460420, 0.125000 (1.452 sec)
16.812... logprob:  0.462434, 0.125000 (1.490 sec)
16.813... logprob:  0.485994, 0.132812 (1.467 sec)
16.814... logprob:  0.478171, 0.132812 (1.452 sec)
16.815... logprob:  0.372427, 0.085938 (1.506 sec)
16.816... logprob:  0.409044, 0.101562 (1.452 sec)
16.817... logprob:  0.426166, 0.109375 (1.454 sec)
16.818... logprob:  0.559966, 0.164062 (1.450 sec)
16.819... logprob:  0.498219, 0.140625 (1.455 sec)
16.820... logprob:  0.421536, 0.109375 (1.458 sec)
16.821... logprob:  0.406407, 0.101562 (1.496 sec)
16.822... logprob:  0.441073, 0.117188 (1.460 sec)
16.823... logprob:  0.340398, 0.078125 (1.226 sec)
16.824... logprob:  0.490042, 0.132812 (0.713 sec)
16.825... logprob:  0.287434, 0.062500 (0.684 sec)
16.826... logprob:  0.375335, 0.093750 (0.690 sec)
16.827... logprob:  0.420665, 0.109375 (0.692 sec)
16.828... logprob:  0.443671, 0.117188 (0.686 sec)
16.829... logprob:  0.504746, 0.140625 (0.688 sec)
16.830... logprob:  0.442387, 0.117188 (1.514 sec)
16.831... logprob:  0.514163, 0.140625 (1.458 sec)
16.832... logprob:  0.330863, 0.078125 (1.459 sec)
16.833... logprob:  0.488941, 0.132812 (1.499 sec)
16.834... logprob:  0.433176, 0.117188 (1.453 sec)
16.835... logprob:  0.542435, 0.148438 (1.457 sec)
16.836... logprob:  0.376370, 0.093750 (1.453 sec)
16.837... logprob:  0.314882, 0.070312 (1.451 sec)
16.838... logprob:  0.437097, 0.117188 (1.455 sec)
16.839... logprob:  0.471741, 0.125000 (1.502 sec)
16.840... logprob:  0.555217, 0.156250 (1.450 sec)
16.841... logprob:  0.396313, 0.101562 (1.464 sec)
16.842... logprob:  0.497795, 0.140625 (1.497 sec)
16.843... logprob:  0.465556, 0.125000 (1.454 sec)
16.844... logprob:  0.497609, 0.140625 (1.459 sec)
16.845... logprob:  0.486840, 0.132812 (1.453 sec)
16.846... logprob:  0.468498, 0.125000 (1.447 sec)
16.847... logprob:  0.363136, 0.085938 (1.458 sec)
16.848... logprob:  0.396987, 0.101562 (1.497 sec)
16.849... logprob:  0.360206, 0.085938 (1.461 sec)
16.850... logprob:  0.479449, 0.132812 (1.466 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.39649200439453, 10.0]}, 128)
batch 872: ({'logprob': [66.49732971191406, 19.0]}, 128)
batch 873: ({'logprob': [40.82875442504883, 9.0]}, 128)
batch 874: ({'logprob': [45.574607849121094, 11.0]}, 128)
batch 875: ({'logprob': [50.952274322509766, 13.0]}, 128)
batch 876: ({'logprob': [63.9826545715332, 18.0]}, 128)
batch 877: ({'logprob': [45.89720916748047, 11.0]}, 128)
batch 878: ({'logprob': [61.74720001220703, 17.0]}, 128)
batch 879: ({'logprob': [72.82759094238281, 21.0]}, 128)
batch 880: ({'logprob': [50.97001266479492, 13.0]}, 128)
batch 881: ({'logprob': [29.717147827148438, 5.0]}, 128)
batch 882: ({'logprob': [54.45294189453125, 14.0]}, 128)
batch 883: ({'logprob': [61.73003005981445, 17.0]}, 128)
batch 884: ({'logprob': [51.270145416259766, 13.0]}, 128)
batch 885: ({'logprob': [51.90518569946289, 13.0]}, 128)
batch 886: ({'logprob': [62.058013916015625, 17.0]}, 128)

======================Test output======================
logprob:  0.416410, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.968736e-03 [2.455527e-09] 
Layer 'conv1' biases: 1.644665e-07 [6.521077e-11] 
Layer 'conv2' weights[0]: 7.955768e-03 [1.977232e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.301030e-10] 
Layer 'conv3' weights[0]: 7.954099e-03 [1.905309e-09] 
Layer 'conv3' biases: 1.428264e-06 [1.084675e-09] 
Layer 'conv4' weights[0]: 7.986658e-03 [2.202533e-09] 
Layer 'conv4' biases: 9.999996e-01 [1.080166e-08] 
Layer 'conv5' weights[0]: 7.985500e-03 [7.322267e-08] 
Layer 'conv5' biases: 9.999968e-01 [7.936557e-08] 
Layer 'fc6' weights[0]: 7.582314e-03 [6.147167e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.241851e-09] 
Layer 'fc7' weights[0]: 7.321327e-03 [2.540060e-07] 
Layer 'fc7' biases: 9.998634e-01 [2.423558e-07] 
Layer 'fc8' weights[0]: 1.298216e-03 [9.018061e-06] 
Layer 'fc8' biases: 3.889482e-02 [6.265505e-05] 
Train error last 870 batches: 0.435256
-------------------------------------------------------
Not saving because 0.416410 > 0.415707 (12.630: -0.00%)
======================================================= (12.040 sec)
16.851... logprob:  0.440157, 0.117188 (1.496 sec)
16.852... logprob:  0.545959, 0.156250 (1.456 sec)
16.853... logprob:  0.371758, 0.093750 (1.454 sec)
16.854... logprob:  0.306959, 0.070312 (1.445 sec)
16.855... logprob:  0.485017, 0.132812 (1.449 sec)
16.856... logprob:  0.443886, 0.117188 (1.457 sec)
16.857... logprob:  0.372244, 0.093750 (1.490 sec)
16.858... logprob:  0.396247, 0.101562 (1.457 sec)
16.859... logprob:  0.307948, 0.070312 (1.472 sec)
16.860... logprob:  0.565946, 0.156250 (1.492 sec)
16.861... logprob:  0.417821, 0.109375 (1.458 sec)
16.862... logprob:  0.328949, 0.078125 (1.461 sec)
16.863... logprob:  0.399510, 0.101562 (1.448 sec)
16.864... logprob:  0.451380, 0.117188 (1.446 sec)
16.865... logprob:  0.484373, 0.132812 (1.461 sec)
16.866... logprob:  0.507471, 0.140625 (1.483 sec)
16.867... logprob:  0.502797, 0.140625 (1.464 sec)
16.868... logprob:  0.405414, 0.101562 (1.471 sec)
16.869... logprob:  0.383376, 0.093750 (1.484 sec)
16.870... logprob:  0.551923, 0.156250 (1.402 sec)
17.1... logprob:  0.380216, 0.093750 (1.405 sec)
17.2... logprob:  0.448286, 0.117188 (1.454 sec)
17.3... logprob:  0.398436, 0.101562 (1.412 sec)
17.4... logprob:  0.443358, 0.117188 (1.414 sec)
17.5... logprob:  0.443415, 0.117188 (1.433 sec)
17.6... logprob:  0.499212, 0.140625 (1.398 sec)
17.7... logprob:  0.363027, 0.085938 (1.426 sec)
17.8... logprob:  0.419104, 0.109375 (1.399 sec)
17.9... logprob:  0.358640, 0.085938 (1.406 sec)
17.10... logprob:  0.377367, 0.093750 (1.411 sec)
17.11... logprob:  0.334529, 0.078125 (1.443 sec)
17.12... logprob:  0.466548, 0.125000 (1.398 sec)
17.13... logprob:  0.442399, 0.117188 (1.425 sec)
17.14... logprob:  0.444798, 0.117188 (1.413 sec)
17.15... logprob:  0.395652, 0.101562 (1.408 sec)
17.16... logprob:  0.421469, 0.109375 (1.405 sec)
17.17... logprob:  0.516106, 0.140625 (1.394 sec)
17.18... logprob:  0.262110, 0.054688 (1.403 sec)
17.19... logprob:  0.279633, 0.062500 (1.403 sec)
17.20... logprob:  0.421380, 0.109375 (1.403 sec)
17.21... logprob:  0.443949, 0.117188 (0.891 sec)
17.22... logprob:  0.536563, 0.148438 (1.322 sec)
17.23... logprob:  0.532776, 0.148438 (1.411 sec)
17.24... logprob:  0.310789, 0.070312 (0.991 sec)
17.25... logprob:  0.356335, 0.085938 (0.957 sec)
17.26... logprob:  0.463664, 0.125000 (1.453 sec)
17.27... logprob:  0.404616, 0.101562 (1.387 sec)
17.28... logprob:  0.421876, 0.109375 (1.411 sec)
17.29... logprob:  0.396065, 0.101562 (1.417 sec)
17.30... logprob:  0.374188, 0.093750 (1.424 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.39036560058594, 10.0]}, 128)
batch 872: ({'logprob': [66.88565063476562, 19.0]}, 128)
batch 873: ({'logprob': [40.44831466674805, 9.0]}, 128)
batch 874: ({'logprob': [45.46333694458008, 11.0]}, 128)
batch 875: ({'logprob': [50.91720199584961, 13.0]}, 128)
batch 876: ({'logprob': [64.28519439697266, 18.0]}, 128)
batch 877: ({'logprob': [45.68958282470703, 11.0]}, 128)
batch 878: ({'logprob': [61.86676025390625, 17.0]}, 128)
batch 879: ({'logprob': [73.00569152832031, 21.0]}, 128)
batch 880: ({'logprob': [50.93571472167969, 13.0]}, 128)
batch 881: ({'logprob': [29.278087615966797, 5.0]}, 128)
batch 882: ({'logprob': [54.217567443847656, 14.0]}, 128)
batch 883: ({'logprob': [61.84912872314453, 17.0]}, 128)
batch 884: ({'logprob': [51.14020538330078, 13.0]}, 128)
batch 885: ({'logprob': [51.58352279663086, 13.0]}, 128)
batch 886: ({'logprob': [62.0821418762207, 17.0]}, 128)

======================Test output======================
logprob:  0.416034, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.968700e-03 [2.344069e-09] 
Layer 'conv1' biases: 1.652962e-07 [6.463643e-11] 
Layer 'conv2' weights[0]: 7.955727e-03 [2.227325e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.516964e-10] 
Layer 'conv3' weights[0]: 7.954054e-03 [2.140462e-09] 
Layer 'conv3' biases: 1.436487e-06 [1.116782e-09] 
Layer 'conv4' weights[0]: 7.986620e-03 [2.383191e-09] 
Layer 'conv4' biases: 9.999996e-01 [1.083550e-08] 
Layer 'conv5' weights[0]: 7.985473e-03 [7.332687e-08] 
Layer 'conv5' biases: 9.999970e-01 [7.948081e-08] 
Layer 'fc6' weights[0]: 7.582276e-03 [6.188566e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.276219e-09] 
Layer 'fc7' weights[0]: 7.319454e-03 [5.039863e-08] 
Layer 'fc7' biases: 9.998636e-01 [2.918144e-08] 
Layer 'fc8' weights[0]: 1.304847e-03 [1.588732e-06] 
Layer 'fc8' biases: 3.908643e-02 [1.103294e-05] 
Train error last 870 batches: 0.435256
-------------------------------------------------------
Not saving because 0.416034 > 0.415707 (12.630: -0.00%)
======================================================= (12.077 sec)
17.31... logprob:  0.479904, 0.132812 (1.409 sec)
17.32... logprob:  0.457236, 0.125000 (1.402 sec)
17.33... logprob:  0.460679, 0.125000 (1.450 sec)
17.34... logprob:  0.464630, 0.125000 (1.395 sec)
17.35... logprob:  0.316195, 0.070312 (1.402 sec)
17.36... logprob:  0.475805, 0.132812 (1.403 sec)
17.37... logprob:  0.417598, 0.109375 (1.411 sec)
17.38... logprob:  0.392520, 0.101562 (1.398 sec)
17.39... logprob:  0.631897, 0.187500 (1.435 sec)
17.40... logprob:  0.445832, 0.117188 (1.412 sec)
17.41... logprob:  0.352782, 0.085938 (1.430 sec)
17.42... logprob:  0.391856, 0.101562 (1.422 sec)
17.43... logprob:  0.440119, 0.117188 (1.419 sec)
17.44... logprob:  0.518512, 0.148438 (1.432 sec)
17.45... logprob:  0.381778, 0.093750 (1.398 sec)
17.46... logprob:  0.486355, 0.132812 (1.399 sec)
17.47... logprob:  0.331764, 0.078125 (1.396 sec)
17.48... logprob:  0.498882, 0.140625 (1.425 sec)
17.49... logprob:  0.510664, 0.148438 (1.421 sec)
17.50... logprob:  0.393244, 0.101562 (1.425 sec)
17.51... logprob:  0.490033, 0.140625 (1.421 sec)
17.52... logprob:  0.525779, 0.148438 (1.397 sec)
17.53... logprob:  0.295025, 0.062500 (1.450 sec)
17.54... logprob:  0.403267, 0.109375 (1.386 sec)
17.55... logprob:  0.331787, 0.078125 (1.402 sec)
17.56... logprob:  0.421704, 0.109375 (1.403 sec)
17.57... logprob:  0.572522, 0.164062 (1.424 sec)
17.58... logprob:  0.407746, 0.101562 (1.401 sec)
17.59... logprob:  0.333854, 0.078125 (1.469 sec)
17.60... logprob:  0.619010, 0.179688 (1.417 sec)
17.61... logprob:  0.382858, 0.093750 (1.432 sec)
17.62... logprob:  0.474901, 0.132812 (1.459 sec)
17.63... logprob:  0.397308, 0.101562 (1.436 sec)
17.64... logprob:  0.450274, 0.125000 (1.409 sec)
17.65... logprob:  0.373325, 0.093750 (1.403 sec)
17.66... logprob:  0.354007, 0.085938 (1.448 sec)
17.67... logprob:  0.295389, 0.062500 (1.395 sec)
17.68... logprob:  0.396818, 0.101562 (1.402 sec)
17.69... logprob:  0.496819, 0.140625 (1.426 sec)
17.70... logprob:  0.325878, 0.078125 (1.428 sec)
17.71... logprob:  0.381836, 0.101562 (1.460 sec)
17.72... logprob:  0.493831, 0.132812 (1.409 sec)
17.73... logprob:  0.447768, 0.117188 (1.428 sec)
17.74... logprob:  0.442586, 0.117188 (1.422 sec)
17.75... logprob:  0.380644, 0.093750 (1.415 sec)
17.76... logprob:  0.412082, 0.109375 (1.437 sec)
17.77... logprob:  0.396344, 0.101562 (1.432 sec)
17.78... logprob:  0.493066, 0.140625 (1.455 sec)
17.79... logprob:  0.456444, 0.125000 (1.407 sec)
17.80... logprob:  0.507892, 0.132812 (1.425 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.67555236816406, 10.0]}, 128)
batch 872: ({'logprob': [66.31484985351562, 19.0]}, 128)
batch 873: ({'logprob': [40.928348541259766, 9.0]}, 128)
batch 874: ({'logprob': [45.311004638671875, 11.0]}, 128)
batch 875: ({'logprob': [50.837196350097656, 13.0]}, 128)
batch 876: ({'logprob': [63.85372543334961, 18.0]}, 128)
batch 877: ({'logprob': [45.88887023925781, 11.0]}, 128)
batch 878: ({'logprob': [61.92779541015625, 17.0]}, 128)
batch 879: ({'logprob': [73.55811309814453, 21.0]}, 128)
batch 880: ({'logprob': [50.85424041748047, 13.0]}, 128)
batch 881: ({'logprob': [29.265453338623047, 5.0]}, 128)
batch 882: ({'logprob': [55.05034637451172, 14.0]}, 128)
batch 883: ({'logprob': [61.910728454589844, 17.0]}, 128)
batch 884: ({'logprob': [51.410648345947266, 13.0]}, 128)
batch 885: ({'logprob': [52.55669403076172, 13.0]}, 128)
batch 886: ({'logprob': [62.49427795410156, 17.0]}, 128)

======================Test output======================
logprob:  0.416913, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.968664e-03 [3.566881e-09] 
Layer 'conv1' biases: 1.662469e-07 [8.618409e-11] 
Layer 'conv2' weights[0]: 7.955689e-03 [2.901472e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.125663e-10] 
Layer 'conv3' weights[0]: 7.954019e-03 [2.611741e-09] 
Layer 'conv3' biases: 1.443637e-06 [1.689153e-09] 
Layer 'conv4' weights[0]: 7.986584e-03 [2.969624e-09] 
Layer 'conv4' biases: 9.999996e-01 [1.613744e-08] 
Layer 'conv5' weights[0]: 7.985427e-03 [1.093466e-07] 
Layer 'conv5' biases: 9.999973e-01 [1.185343e-07] 
Layer 'fc6' weights[0]: 7.582239e-03 [9.347376e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.391288e-09] 
Layer 'fc7' weights[0]: 7.317604e-03 [2.674116e-07] 
Layer 'fc7' biases: 9.998640e-01 [2.570847e-07] 
Layer 'fc8' weights[0]: 1.309382e-03 [9.108206e-06] 
Layer 'fc8' biases: 3.913494e-02 [5.615784e-05] 
Train error last 870 batches: 0.435256
-------------------------------------------------------
Not saving because 0.416913 > 0.415707 (12.630: -0.00%)
======================================================= (12.044 sec)
17.81... logprob:  0.416724, 0.109375 (1.426 sec)
17.82... logprob:  0.231756, 0.039062 (1.458 sec)
17.83... logprob:  0.493729, 0.140625 (1.408 sec)
17.84... logprob:  0.468088, 0.125000 (1.466 sec)
17.85... logprob:  0.432022, 0.117188 (1.420 sec)
17.86... logprob:  0.416986, 0.109375 (1.420 sec)
17.87... logprob:  0.633198, 0.187500 (1.413 sec)
17.88... logprob:  0.535095, 0.156250 (1.412 sec)
17.89... logprob:  0.410622, 0.109375 (1.440 sec)
17.90... logprob:  0.577509, 0.171875 (1.391 sec)
17.91... logprob:  0.348538, 0.078125 (1.394 sec)
17.92... logprob:  0.464462, 0.125000 (1.406 sec)
17.93... logprob:  0.492275, 0.140625 (1.405 sec)
17.94... logprob:  0.428783, 0.109375 (1.390 sec)
17.95... logprob:  0.471857, 0.125000 (1.407 sec)
17.96... logprob:  0.576340, 0.171875 (1.409 sec)
17.97... logprob:  0.430757, 0.117188 (1.395 sec)
17.98... logprob:  0.391041, 0.093750 (1.435 sec)
17.99... logprob:  0.474308, 0.132812 (1.411 sec)
17.100... logprob:  0.310378, 0.070312 (1.406 sec)
17.101... logprob:  0.310559, 0.062500 (1.449 sec)
17.102... logprob:  0.546331, 0.156250 (1.389 sec)
17.103... logprob:  0.541313, 0.156250 (1.406 sec)
17.104... logprob:  0.388866, 0.101562 (1.398 sec)
17.105... logprob:  0.619771, 0.179688 (1.399 sec)
17.106... logprob:  0.344432, 0.085938 (1.394 sec)
17.107... logprob:  0.335707, 0.078125 (1.443 sec)
17.108... logprob:  0.586815, 0.171875 (1.394 sec)
17.109... logprob:  0.336200, 0.078125 (1.407 sec)
17.110... logprob:  0.564446, 0.164062 (1.397 sec)
17.111... logprob:  0.404731, 0.101562 (1.393 sec)
17.112... logprob:  0.366177, 0.093750 (1.407 sec)
17.113... logprob:  0.354661, 0.085938 (1.397 sec)
17.114... logprob:  0.440231, 0.117188 (1.437 sec)
17.115... logprob:  0.506726, 0.140625 (1.416 sec)
17.116... logprob:  0.393405, 0.101562 (1.404 sec)
17.117... logprob:  0.440396, 0.117188 (1.442 sec)
17.118... logprob:  0.409166, 0.101562 (1.396 sec)
17.119... logprob:  0.346133, 0.085938 (1.396 sec)
17.120... logprob:  0.547150, 0.156250 (1.406 sec)
17.121... logprob:  0.412672, 0.109375 (1.394 sec)
17.122... logprob:  0.519359, 0.148438 (1.445 sec)
17.123... logprob:  0.463744, 0.125000 (1.393 sec)
17.124... logprob:  0.447711, 0.125000 (1.423 sec)
17.125... logprob:  0.502002, 0.140625 (1.400 sec)
17.126... logprob:  0.475803, 0.125000 (1.391 sec)
17.127... logprob:  0.479620, 0.125000 (1.404 sec)
17.128... logprob:  0.422377, 0.109375 (1.423 sec)
17.129... logprob:  0.574894, 0.164062 (1.424 sec)
17.130... logprob:  0.382750, 0.093750 (1.418 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.01671600341797, 10.0]}, 128)
batch 872: ({'logprob': [65.92940521240234, 19.0]}, 128)
batch 873: ({'logprob': [41.994632720947266, 9.0]}, 128)
batch 874: ({'logprob': [46.249298095703125, 11.0]}, 128)
batch 875: ({'logprob': [51.37775802612305, 13.0]}, 128)
batch 876: ({'logprob': [63.59941482543945, 18.0]}, 128)
batch 877: ({'logprob': [46.69335174560547, 11.0]}, 128)
batch 878: ({'logprob': [61.6707649230957, 17.0]}, 128)
batch 879: ({'logprob': [72.3692855834961, 21.0]}, 128)
batch 880: ({'logprob': [51.394683837890625, 13.0]}, 128)
batch 881: ({'logprob': [31.265453338623047, 5.0]}, 128)
batch 882: ({'logprob': [55.05165100097656, 14.0]}, 128)
batch 883: ({'logprob': [61.6536750793457, 17.0]}, 128)
batch 884: ({'logprob': [51.81369400024414, 13.0]}, 128)
batch 885: ({'logprob': [52.688602447509766, 13.0]}, 128)
batch 886: ({'logprob': [62.10059356689453, 17.0]}, 128)

======================Test output======================
logprob:  0.419370, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.968627e-03 [1.858957e-09] 
Layer 'conv1' biases: 1.669253e-07 [5.849024e-11] 
Layer 'conv2' weights[0]: 7.955650e-03 [1.696575e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.057535e-10] 
Layer 'conv3' weights[0]: 7.953972e-03 [1.685193e-09] 
Layer 'conv3' biases: 1.449184e-06 [9.862377e-10] 
Layer 'conv4' weights[0]: 7.986543e-03 [1.723365e-09] 
Layer 'conv4' biases: 9.999996e-01 [8.543077e-09] 
Layer 'conv5' weights[0]: 7.985390e-03 [5.118018e-08] 
Layer 'conv5' biases: 9.999973e-01 [5.535054e-08] 
Layer 'fc6' weights[0]: 7.582205e-03 [4.428384e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.418379e-09] 
Layer 'fc7' weights[0]: 7.315720e-03 [8.226768e-08] 
Layer 'fc7' biases: 9.998630e-01 [6.693146e-08] 
Layer 'fc8' weights[0]: 1.273493e-03 [7.530513e-06] 
Layer 'fc8' biases: 3.899881e-02 [4.916013e-05] 
Train error last 870 batches: 0.435256
-------------------------------------------------------
Not saving because 0.419370 > 0.415707 (12.630: -0.00%)
======================================================= (12.067 sec)
17.131... logprob:  0.495501, 0.132812 (1.415 sec)
17.132... logprob:  0.506383, 0.140625 (1.444 sec)
17.133... logprob:  0.444683, 0.117188 (1.390 sec)
17.134... logprob:  0.401913, 0.101562 (1.393 sec)
17.135... logprob:  0.460237, 0.125000 (1.406 sec)
17.136... logprob:  0.562558, 0.164062 (1.404 sec)
17.137... logprob:  0.462569, 0.125000 (1.396 sec)
17.138... logprob:  0.319341, 0.070312 (1.446 sec)
17.139... logprob:  0.395781, 0.101562 (1.402 sec)
17.140... logprob:  0.560469, 0.164062 (1.410 sec)
17.141... logprob:  0.464541, 0.125000 (1.439 sec)
17.142... logprob:  0.464611, 0.125000 (1.402 sec)
17.143... logprob:  0.294271, 0.062500 (1.432 sec)
17.144... logprob:  0.457284, 0.125000 (1.416 sec)
17.145... logprob:  0.324859, 0.078125 (1.420 sec)
17.146... logprob:  0.483226, 0.132812 (1.408 sec)
17.147... logprob:  0.262470, 0.054688 (1.434 sec)
17.148... logprob:  0.458811, 0.125000 (1.393 sec)
17.149... logprob:  0.442560, 0.117188 (1.393 sec)
17.150... logprob:  0.347624, 0.085938 (1.405 sec)
17.151... logprob:  0.347153, 0.085938 (1.401 sec)
17.152... logprob:  0.785018, 0.234375 (1.386 sec)
17.153... logprob:  0.381665, 0.093750 (1.450 sec)
17.154... logprob:  0.524407, 0.148438 (1.397 sec)
17.155... logprob:  0.425990, 0.117188 (1.416 sec)
17.156... logprob:  0.295844, 0.062500 (1.432 sec)
17.157... logprob:  0.270758, 0.054688 (1.402 sec)
17.158... logprob:  0.455374, 0.125000 (1.439 sec)
17.159... logprob:  0.483115, 0.132812 (1.402 sec)
17.160... logprob:  0.444870, 0.117188 (1.392 sec)
17.161... logprob:  0.350116, 0.078125 (1.397 sec)
17.162... logprob:  0.611795, 0.179688 (1.403 sec)
17.163... logprob:  0.450431, 0.125000 (1.430 sec)
17.164... logprob:  0.468675, 0.125000 (1.426 sec)
17.165... logprob:  0.547941, 0.156250 (1.421 sec)
17.166... logprob:  0.446068, 0.125000 (1.451 sec)
17.167... logprob:  0.350426, 0.085938 (1.430 sec)
17.168... logprob:  0.363677, 0.085938 (1.428 sec)
17.169... logprob:  0.408677, 0.101562 (1.459 sec)
17.170... logprob:  0.459492, 0.125000 (1.406 sec)
17.171... logprob:  0.535452, 0.156250 (1.418 sec)
17.172... logprob:  0.434866, 0.109375 (1.418 sec)
17.173... logprob:  0.440496, 0.117188 (1.427 sec)
17.174... logprob:  0.601119, 0.171875 (1.408 sec)
17.175... logprob:  0.506106, 0.140625 (1.474 sec)
17.176... logprob:  0.478484, 0.132812 (1.417 sec)
17.177... logprob:  0.289767, 0.054688 (1.429 sec)
17.178... logprob:  0.383488, 0.093750 (1.457 sec)
17.179... logprob:  0.394722, 0.101562 (1.413 sec)
17.180... logprob:  0.466382, 0.125000 (1.428 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.00907897949219, 10.0]}, 128)
batch 872: ({'logprob': [66.50626373291016, 19.0]}, 128)
batch 873: ({'logprob': [40.684547424316406, 9.0]}, 128)
batch 874: ({'logprob': [45.361026763916016, 11.0]}, 128)
batch 875: ({'logprob': [50.83584213256836, 13.0]}, 128)
batch 876: ({'logprob': [63.985076904296875, 18.0]}, 128)
batch 877: ({'logprob': [45.7668342590332, 11.0]}, 128)
batch 878: ({'logprob': [61.825740814208984, 17.0]}, 128)
batch 879: ({'logprob': [73.18334197998047, 21.0]}, 128)
batch 880: ({'logprob': [50.85379409790039, 13.0]}, 128)
batch 881: ({'logprob': [29.294797897338867, 5.0]}, 128)
batch 882: ({'logprob': [54.593955993652344, 14.0]}, 128)
batch 883: ({'logprob': [61.80815505981445, 17.0]}, 128)
batch 884: ({'logprob': [51.23760986328125, 13.0]}, 128)
batch 885: ({'logprob': [52.03921890258789, 13.0]}, 128)
batch 886: ({'logprob': [62.22011947631836, 17.0]}, 128)

======================Test output======================
logprob:  0.416116, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.968598e-03 [2.308287e-09] 
Layer 'conv1' biases: 1.677671e-07 [5.455557e-11] 
Layer 'conv2' weights[0]: 7.955614e-03 [1.748879e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.324057e-10] 
Layer 'conv3' weights[0]: 7.953929e-03 [1.662497e-09] 
Layer 'conv3' biases: 1.455850e-06 [7.678160e-10] 
Layer 'conv4' weights[0]: 7.986498e-03 [1.699876e-09] 
Layer 'conv4' biases: 9.999996e-01 [5.751222e-09] 
Layer 'conv5' weights[0]: 7.985344e-03 [3.508648e-08] 
Layer 'conv5' biases: 9.999968e-01 [3.786263e-08] 
Layer 'fc6' weights[0]: 7.582156e-03 [3.073776e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.027287e-09] 
Layer 'fc7' weights[0]: 7.313858e-03 [1.221172e-07] 
Layer 'fc7' biases: 9.998635e-01 [1.076322e-07] 
Layer 'fc8' weights[0]: 1.312458e-03 [1.044760e-05] 
Layer 'fc8' biases: 3.937847e-02 [6.903318e-05] 
Train error last 870 batches: 0.435256
-------------------------------------------------------
Not saving because 0.416116 > 0.415707 (12.630: -0.00%)
======================================================= (12.075 sec)
17.181... logprob:  0.539391, 0.156250 (1.428 sec)
17.182... logprob:  0.371394, 0.093750 (1.428 sec)
17.183... logprob:  0.419958, 0.109375 (1.420 sec)
17.184... logprob:  0.483472, 0.132812 (1.425 sec)
17.185... logprob:  0.289863, 0.062500 (1.397 sec)
17.186... logprob:  0.370495, 0.093750 (1.402 sec)
17.187... logprob:  0.529628, 0.148438 (1.398 sec)
17.188... logprob:  0.458978, 0.125000 (1.402 sec)
17.189... logprob:  0.440907, 0.117188 (1.399 sec)
17.190... logprob:  0.375748, 0.093750 (1.437 sec)
17.191... logprob:  0.485100, 0.132812 (1.407 sec)
17.192... logprob:  0.520153, 0.148438 (1.421 sec)
17.193... logprob:  0.312610, 0.070312 (1.417 sec)
17.194... logprob:  0.414108, 0.109375 (1.416 sec)
17.195... logprob:  0.287213, 0.062500 (1.402 sec)
17.196... logprob:  0.410544, 0.109375 (1.390 sec)
17.197... logprob:  0.478023, 0.132812 (1.405 sec)
17.198... logprob:  0.355793, 0.085938 (1.405 sec)
17.199... logprob:  0.437193, 0.117188 (1.391 sec)
17.200... logprob:  0.440770, 0.117188 (1.439 sec)
17.201... logprob:  0.437098, 0.117188 (1.411 sec)
17.202... logprob:  0.537957, 0.148438 (1.412 sec)
17.203... logprob:  0.420454, 0.109375 (1.438 sec)
17.204... logprob:  0.504125, 0.140625 (1.395 sec)
17.205... logprob:  0.334379, 0.078125 (1.401 sec)
17.206... logprob:  0.361633, 0.093750 (1.405 sec)
17.207... logprob:  0.381887, 0.093750 (1.391 sec)
17.208... logprob:  0.490528, 0.140625 (1.401 sec)
17.209... logprob:  0.334591, 0.078125 (1.418 sec)
17.210... logprob:  0.586246, 0.171875 (1.418 sec)
17.211... logprob:  0.488185, 0.132812 (1.420 sec)
17.212... logprob:  0.526149, 0.148438 (1.410 sec)
17.213... logprob:  0.514783, 0.140625 (1.459 sec)
17.214... logprob:  0.459434, 0.125000 (1.431 sec)
17.215... logprob:  0.396144, 0.101562 (1.419 sec)
17.216... logprob:  0.517086, 0.140625 (1.475 sec)
17.217... logprob:  0.325077, 0.070312 (1.401 sec)
17.218... logprob:  0.463687, 0.125000 (1.427 sec)
17.219... logprob:  0.500299, 0.140625 (1.420 sec)
17.220... logprob:  0.415001, 0.109375 (1.427 sec)
17.221... logprob:  0.399544, 0.101562 (1.399 sec)
17.222... logprob:  0.554559, 0.164062 (1.462 sec)
17.223... logprob:  0.569201, 0.164062 (1.518 sec)
17.224... logprob:  0.405887, 0.101562 (1.435 sec)
17.225... logprob:  0.391972, 0.101562 (1.444 sec)
17.226... logprob:  0.424648, 0.109375 (1.429 sec)
17.227... logprob:  0.452720, 0.125000 (1.414 sec)
17.228... logprob:  0.417194, 0.109375 (1.418 sec)
17.229... logprob:  0.489372, 0.132812 (1.416 sec)
17.230... logprob:  0.459892, 0.125000 (1.426 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.99494171142578, 10.0]}, 128)
batch 872: ({'logprob': [66.4648666381836, 19.0]}, 128)
batch 873: ({'logprob': [40.72970199584961, 9.0]}, 128)
batch 874: ({'logprob': [45.369239807128906, 11.0]}, 128)
batch 875: ({'logprob': [50.839839935302734, 13.0]}, 128)
batch 876: ({'logprob': [63.95401382446289, 18.0]}, 128)
batch 877: ({'logprob': [45.79143524169922, 11.0]}, 128)
batch 878: ({'logprob': [61.821346282958984, 17.0]}, 128)
batch 879: ({'logprob': [73.18653106689453, 21.0]}, 128)
batch 880: ({'logprob': [50.857906341552734, 13.0]}, 128)
batch 881: ({'logprob': [29.332134246826172, 5.0]}, 128)
batch 882: ({'logprob': [54.636627197265625, 14.0]}, 128)
batch 883: ({'logprob': [61.80357360839844, 17.0]}, 128)
batch 884: ({'logprob': [51.25787353515625, 13.0]}, 128)
batch 885: ({'logprob': [52.09211349487305, 13.0]}, 128)
batch 886: ({'logprob': [62.23197937011719, 17.0]}, 128)

======================Test output======================
logprob:  0.416193, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.968555e-03 [2.097419e-09] 
Layer 'conv1' biases: 1.686209e-07 [4.865587e-11] 
Layer 'conv2' weights[0]: 7.955580e-03 [1.710932e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.030477e-10] 
Layer 'conv3' weights[0]: 7.953900e-03 [1.374807e-09] 
Layer 'conv3' biases: 1.464074e-06 [5.949106e-10] 
Layer 'conv4' weights[0]: 7.986461e-03 [1.377480e-09] 
Layer 'conv4' biases: 9.999996e-01 [4.062989e-09] 
Layer 'conv5' weights[0]: 7.985302e-03 [2.728197e-08] 
Layer 'conv5' biases: 9.999968e-01 [2.950667e-08] 
Layer 'fc6' weights[0]: 7.582112e-03 [2.470881e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.348792e-09] 
Layer 'fc7' weights[0]: 7.311965e-03 [4.255983e-08] 
Layer 'fc7' biases: 9.998634e-01 [1.754668e-08] 
Layer 'fc8' weights[0]: 1.314699e-03 [2.041760e-06] 
Layer 'fc8' biases: 3.945218e-02 [1.387176e-05] 
Train error last 870 batches: 0.435255
-------------------------------------------------------
Not saving because 0.416193 > 0.415707 (12.630: -0.00%)
======================================================= (12.090 sec)
17.231... logprob:  0.453537, 0.125000 (1.410 sec)
17.232... logprob:  0.496219, 0.140625 (1.468 sec)
17.233... logprob:  0.466151, 0.132812 (1.428 sec)
17.234... logprob:  0.563809, 0.164062 (1.415 sec)
17.235... logprob:  0.482029, 0.132812 (1.472 sec)
17.236... logprob:  0.425780, 0.109375 (1.399 sec)
17.237... logprob:  0.341282, 0.078125 (1.426 sec)
17.238... logprob:  0.389346, 0.093750 (1.413 sec)
17.239... logprob:  0.478136, 0.132812 (1.428 sec)
17.240... logprob:  0.485806, 0.132812 (1.398 sec)
17.241... logprob:  0.493605, 0.132812 (1.463 sec)
17.242... logprob:  0.341652, 0.078125 (1.437 sec)
17.243... logprob:  0.386017, 0.093750 (1.432 sec)
17.244... logprob:  0.315252, 0.070312 (1.444 sec)
17.245... logprob:  0.494333, 0.132812 (1.429 sec)
17.246... logprob:  0.416899, 0.109375 (1.412 sec)
17.247... logprob:  0.357387, 0.085938 (1.421 sec)
17.248... logprob:  0.307790, 0.070312 (1.419 sec)
17.249... logprob:  0.555324, 0.156250 (1.428 sec)
17.250... logprob:  0.591677, 0.164062 (1.411 sec)
17.251... logprob:  0.352922, 0.085938 (1.458 sec)
17.252... logprob:  0.348480, 0.085938 (1.429 sec)
17.253... logprob:  0.379182, 0.093750 (1.423 sec)
17.254... logprob:  0.444178, 0.117188 (1.473 sec)
17.255... logprob:  0.351467, 0.085938 (1.401 sec)
17.256... logprob:  0.378764, 0.093750 (1.428 sec)
17.257... logprob:  0.332037, 0.078125 (1.413 sec)
17.258... logprob:  0.415728, 0.109375 (1.425 sec)
17.259... logprob:  0.442311, 0.117188 (1.402 sec)
17.260... logprob:  0.308364, 0.070312 (1.456 sec)
17.261... logprob:  0.392772, 0.101562 (1.432 sec)
17.262... logprob:  0.524644, 0.148438 (1.427 sec)
17.263... logprob:  0.425494, 0.109375 (1.454 sec)
17.264... logprob:  0.375136, 0.093750 (1.421 sec)
17.265... logprob:  0.439614, 0.117188 (1.420 sec)
17.266... logprob:  0.439033, 0.117188 (1.416 sec)
17.267... logprob:  0.422009, 0.109375 (1.432 sec)
17.268... logprob:  0.458943, 0.125000 (1.426 sec)
17.269... logprob:  0.567482, 0.164062 (1.405 sec)
17.270... logprob:  0.542227, 0.156250 (1.464 sec)
17.271... logprob:  0.445727, 0.117188 (1.435 sec)
17.272... logprob:  0.384734, 0.093750 (1.421 sec)
17.273... logprob:  0.500219, 0.140625 (1.482 sec)
17.274... logprob:  0.542525, 0.156250 (1.407 sec)
17.275... logprob:  0.487708, 0.132812 (1.419 sec)
17.276... logprob:  0.390153, 0.093750 (1.417 sec)
17.277... logprob:  0.428704, 0.109375 (1.428 sec)
17.278... logprob:  0.323429, 0.070312 (1.422 sec)
17.279... logprob:  0.325012, 0.070312 (1.468 sec)
17.280... logprob:  0.215280, 0.031250 (1.404 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.936771392822266, 10.0]}, 128)
batch 872: ({'logprob': [66.68108367919922, 19.0]}, 128)
batch 873: ({'logprob': [40.48133087158203, 9.0]}, 128)
batch 874: ({'logprob': [45.26952362060547, 11.0]}, 128)
batch 875: ({'logprob': [50.7955322265625, 13.0]}, 128)
batch 876: ({'logprob': [64.11946105957031, 18.0]}, 128)
batch 877: ({'logprob': [45.64503860473633, 11.0]}, 128)
batch 878: ({'logprob': [61.88889694213867, 17.0]}, 128)
batch 879: ({'logprob': [73.3196792602539, 21.0]}, 128)
batch 880: ({'logprob': [50.813812255859375, 13.0]}, 128)
batch 881: ({'logprob': [29.01813316345215, 5.0]}, 128)
batch 882: ({'logprob': [54.504791259765625, 14.0]}, 128)
batch 883: ({'logprob': [61.87107849121094, 17.0]}, 128)
batch 884: ({'logprob': [51.167823791503906, 13.0]}, 128)
batch 885: ({'logprob': [51.90928649902344, 13.0]}, 128)
batch 886: ({'logprob': [62.253448486328125, 17.0]}, 128)

======================Test output======================
logprob:  0.415857, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.968522e-03 [8.109350e-09] 
Layer 'conv1' biases: 1.694467e-07 [3.216915e-10] 
Layer 'conv2' weights[0]: 7.955538e-03 [7.935675e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.726992e-09] 
Layer 'conv3' weights[0]: 7.953870e-03 [8.108126e-09] 
Layer 'conv3' biases: 1.467814e-06 [5.419300e-09] 
Layer 'conv4' weights[0]: 7.986415e-03 [8.650012e-09] 
Layer 'conv4' biases: 9.999996e-01 [5.101733e-08] 
Layer 'conv5' weights[0]: 7.985260e-03 [3.411863e-07] 
Layer 'conv5' biases: 9.999962e-01 [3.686765e-07] 
Layer 'fc6' weights[0]: 7.582068e-03 [2.856703e-08] 
Layer 'fc6' biases: 1.000000e+00 [2.915939e-08] 
Layer 'fc7' weights[0]: 7.310087e-03 [6.686058e-07] 
Layer 'fc7' biases: 9.998634e-01 [6.525568e-07] 
Layer 'fc8' weights[0]: 1.323541e-03 [2.406149e-05] 
Layer 'fc8' biases: 3.961493e-02 [1.656727e-04] 
Train error last 870 batches: 0.435255
-------------------------------------------------------
Not saving because 0.415857 > 0.415707 (12.630: -0.00%)
======================================================= (12.013 sec)
17.281... logprob:  0.417219, 0.109375 (1.428 sec)
17.282... logprob:  0.411444, 0.109375 (1.430 sec)
17.283... logprob:  0.393842, 0.101562 (1.423 sec)
17.284... logprob:  0.394652, 0.101562 (1.410 sec)
17.285... logprob:  0.452060, 0.117188 (1.443 sec)
17.286... logprob:  0.537336, 0.140625 (1.440 sec)
17.287... logprob:  0.346657, 0.085938 (1.430 sec)
17.288... logprob:  0.329973, 0.078125 (1.439 sec)
17.289... logprob:  0.445995, 0.117188 (1.441 sec)
17.290... logprob:  0.490656, 0.132812 (1.411 sec)
17.291... logprob:  0.439179, 0.117188 (1.420 sec)
17.292... logprob:  0.567126, 0.156250 (1.420 sec)
17.293... logprob:  0.427528, 0.117188 (1.429 sec)
17.294... logprob:  0.356130, 0.085938 (1.406 sec)
17.295... logprob:  0.335020, 0.078125 (1.466 sec)
17.296... logprob:  0.356107, 0.085938 (1.420 sec)
17.297... logprob:  0.394748, 0.101562 (1.422 sec)
17.298... logprob:  0.448129, 0.125000 (1.467 sec)
17.299... logprob:  0.342545, 0.078125 (1.410 sec)
17.300... logprob:  0.406644, 0.101562 (1.456 sec)
17.301... logprob:  0.397955, 0.101562 (1.424 sec)
17.302... logprob:  0.591555, 0.179688 (1.418 sec)
17.303... logprob:  0.459615, 0.125000 (1.406 sec)
17.304... logprob:  0.459697, 0.125000 (1.443 sec)
17.305... logprob:  0.455234, 0.125000 (1.437 sec)
17.306... logprob:  0.440606, 0.117188 (1.440 sec)
17.307... logprob:  0.421603, 0.109375 (1.449 sec)
17.308... logprob:  0.374595, 0.093750 (1.458 sec)
17.309... logprob:  0.450490, 0.125000 (1.436 sec)
17.310... logprob:  0.473736, 0.125000 (1.434 sec)
17.311... logprob:  0.502640, 0.140625 (1.433 sec)
17.312... logprob:  0.478782, 0.132812 (1.449 sec)
17.313... logprob:  0.454871, 0.125000 (1.426 sec)
17.314... logprob:  0.454491, 0.117188 (1.470 sec)
17.315... logprob:  0.314687, 0.070312 (1.438 sec)
17.316... logprob:  0.468571, 0.125000 (1.435 sec)
17.317... logprob:  0.355511, 0.085938 (1.487 sec)
17.318... logprob:  0.455417, 0.125000 (1.421 sec)
17.319... logprob:  0.423205, 0.117188 (1.436 sec)
17.320... logprob:  0.412260, 0.109375 (1.440 sec)
17.321... logprob:  0.348287, 0.085938 (1.429 sec)
17.322... logprob:  0.387513, 0.101562 (1.431 sec)
17.323... logprob:  0.416522, 0.109375 (1.502 sec)
17.324... logprob:  0.498629, 0.140625 (1.431 sec)
17.325... logprob:  0.350681, 0.085938 (1.437 sec)
17.326... logprob:  0.543191, 0.148438 (1.470 sec)
17.327... logprob:  0.554406, 0.164062 (1.439 sec)
17.328... logprob:  0.565030, 0.156250 (1.439 sec)
17.329... logprob:  0.401990, 0.101562 (1.442 sec)
17.330... logprob:  0.388647, 0.101562 (1.439 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.1099853515625, 10.0]}, 128)
batch 872: ({'logprob': [65.96774291992188, 19.0]}, 128)
batch 873: ({'logprob': [41.5536003112793, 9.0]}, 128)
batch 874: ({'logprob': [45.70529556274414, 11.0]}, 128)
batch 875: ({'logprob': [51.061946868896484, 13.0]}, 128)
batch 876: ({'logprob': [63.606597900390625, 18.0]}, 128)
batch 877: ({'logprob': [46.314247131347656, 11.0]}, 128)
batch 878: ({'logprob': [61.8118782043457, 17.0]}, 128)
batch 879: ({'logprob': [73.13140106201172, 21.0]}, 128)
batch 880: ({'logprob': [51.07891845703125, 13.0]}, 128)
batch 881: ({'logprob': [30.201745986938477, 5.0]}, 128)
batch 882: ({'logprob': [55.2646369934082, 14.0]}, 128)
batch 883: ({'logprob': [61.7945442199707, 17.0]}, 128)
batch 884: ({'logprob': [51.664451599121094, 13.0]}, 128)
batch 885: ({'logprob': [52.87063980102539, 13.0]}, 128)
batch 886: ({'logprob': [62.40786361694336, 17.0]}, 128)

======================Test output======================
logprob:  0.418235, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.968480e-03 [2.436869e-09] 
Layer 'conv1' biases: 1.704194e-07 [3.970285e-11] 
Layer 'conv2' weights[0]: 7.955500e-03 [1.724991e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.444851e-10] 
Layer 'conv3' weights[0]: 7.953835e-03 [1.236435e-09] 
Layer 'conv3' biases: 1.478763e-06 [3.548786e-10] 
Layer 'conv4' weights[0]: 7.986380e-03 [1.158434e-09] 
Layer 'conv4' biases: 9.999996e-01 [7.670167e-10] 
Layer 'conv5' weights[0]: 7.985236e-03 [5.198109e-09] 
Layer 'conv5' biases: 9.999973e-01 [5.550459e-09] 
Layer 'fc6' weights[0]: 7.582030e-03 [8.762530e-10] 
Layer 'fc6' biases: 1.000000e+00 [4.188862e-10] 
Layer 'fc7' weights[0]: 7.308255e-03 [2.174810e-07] 
Layer 'fc7' biases: 9.998634e-01 [2.065165e-07] 
Layer 'fc8' weights[0]: 1.299206e-03 [8.089312e-06] 
Layer 'fc8' biases: 3.971974e-02 [4.897844e-05] 
Train error last 870 batches: 0.435254
-------------------------------------------------------
Not saving because 0.418235 > 0.415707 (12.630: -0.00%)
======================================================= (12.577 sec)
17.331... logprob:  0.352506, 0.085938 (1.432 sec)
17.332... logprob:  0.482788, 0.132812 (1.458 sec)
17.333... logprob:  0.339624, 0.085938 (1.472 sec)
17.334... logprob:  0.565128, 0.171875 (1.447 sec)
17.335... logprob:  0.358844, 0.085938 (1.443 sec)
17.336... logprob:  0.444835, 0.125000 (1.475 sec)
17.337... logprob:  0.566468, 0.164062 (1.424 sec)
17.338... logprob:  0.449516, 0.125000 (1.421 sec)
17.339... logprob:  0.488690, 0.132812 (1.439 sec)
17.340... logprob:  0.442075, 0.117188 (1.438 sec)
17.341... logprob:  0.530132, 0.148438 (1.431 sec)
17.342... logprob:  0.429670, 0.109375 (1.475 sec)
17.343... logprob:  0.434781, 0.109375 (1.449 sec)
17.344... logprob:  0.444436, 0.125000 (1.484 sec)
17.345... logprob:  0.488254, 0.132812 (1.440 sec)
17.346... logprob:  0.436240, 0.117188 (1.437 sec)
17.347... logprob:  0.372373, 0.085938 (1.492 sec)
17.348... logprob:  0.398443, 0.101562 (1.440 sec)
17.349... logprob:  0.497847, 0.140625 (1.434 sec)
17.350... logprob:  0.358568, 0.085938 (1.435 sec)
17.351... logprob:  0.508657, 0.140625 (1.434 sec)
17.352... logprob:  0.363656, 0.093750 (1.435 sec)
17.353... logprob:  0.512754, 0.148438 (1.490 sec)
17.354... logprob:  0.675103, 0.203125 (1.432 sec)
17.355... logprob:  0.357478, 0.085938 (1.449 sec)
17.356... logprob:  0.479249, 0.132812 (1.475 sec)
17.357... logprob:  0.347004, 0.085938 (1.436 sec)
17.358... logprob:  0.325999, 0.070312 (1.440 sec)
17.359... logprob:  0.555240, 0.164062 (1.434 sec)
17.360... logprob:  0.444517, 0.117188 (1.432 sec)
17.361... logprob:  0.410777, 0.101562 (1.439 sec)
17.362... logprob:  0.424112, 0.117188 (1.488 sec)
17.363... logprob:  0.486585, 0.132812 (1.440 sec)
17.364... logprob:  0.475550, 0.125000 (1.455 sec)
17.365... logprob:  0.425084, 0.109375 (1.469 sec)
17.366... logprob:  0.409682, 0.109375 (1.443 sec)
17.367... logprob:  0.324991, 0.078125 (1.442 sec)
17.368... logprob:  0.595678, 0.171875 (1.431 sec)
17.369... logprob:  0.381551, 0.093750 (1.431 sec)
17.370... logprob:  0.381179, 0.093750 (1.436 sec)
17.371... logprob:  0.400357, 0.101562 (1.456 sec)
17.372... logprob:  0.537556, 0.156250 (1.451 sec)
17.373... logprob:  0.463826, 0.125000 (1.457 sec)
17.374... logprob:  0.527050, 0.148438 (1.470 sec)
17.375... logprob:  0.393781, 0.101562 (1.462 sec)
17.376... logprob:  0.374311, 0.093750 (1.444 sec)
17.377... logprob:  0.295385, 0.062500 (1.423 sec)
17.378... logprob:  0.453756, 0.125000 (1.435 sec)
17.379... logprob:  0.420239, 0.109375 (1.434 sec)
17.380... logprob:  0.605748, 0.179688 (1.438 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.81013870239258, 10.0]}, 128)
batch 872: ({'logprob': [66.62598419189453, 19.0]}, 128)
batch 873: ({'logprob': [40.518280029296875, 9.0]}, 128)
batch 874: ({'logprob': [45.22829818725586, 11.0]}, 128)
batch 875: ({'logprob': [50.775882720947266, 13.0]}, 128)
batch 876: ({'logprob': [64.07847595214844, 18.0]}, 128)
batch 877: ({'logprob': [45.65360641479492, 11.0]}, 128)
batch 878: ({'logprob': [61.91208267211914, 17.0]}, 128)
batch 879: ({'logprob': [73.43510437011719, 21.0]}, 128)
batch 880: ({'logprob': [50.79416275024414, 13.0]}, 128)
batch 881: ({'logprob': [28.96260643005371, 5.0]}, 128)
batch 882: ({'logprob': [54.620277404785156, 14.0]}, 128)
batch 883: ({'logprob': [61.89418411254883, 17.0]}, 128)
batch 884: ({'logprob': [51.19801330566406, 13.0]}, 128)
batch 885: ({'logprob': [52.03905487060547, 13.0]}, 128)
batch 886: ({'logprob': [62.32638931274414, 17.0]}, 128)

======================Test output======================
logprob:  0.415953, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.968447e-03 [3.787939e-09] 
Layer 'conv1' biases: 1.711728e-07 [1.464464e-10] 
Layer 'conv2' weights[0]: 7.955457e-03 [3.164854e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.460974e-10] 
Layer 'conv3' weights[0]: 7.953788e-03 [3.448206e-09] 
Layer 'conv3' biases: 1.483683e-06 [2.341977e-09] 
Layer 'conv4' weights[0]: 7.986344e-03 [3.423359e-09] 
Layer 'conv4' biases: 9.999996e-01 [2.029745e-08] 
Layer 'conv5' weights[0]: 7.985183e-03 [1.322530e-07] 
Layer 'conv5' biases: 9.999968e-01 [1.429449e-07] 
Layer 'fc6' weights[0]: 7.581987e-03 [1.116940e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.142438e-08] 
Layer 'fc7' weights[0]: 7.306394e-03 [1.121682e-07] 
Layer 'fc7' biases: 9.998634e-01 [9.833033e-08] 
Layer 'fc8' weights[0]: 1.321967e-03 [4.737428e-06] 
Layer 'fc8' biases: 3.996622e-02 [2.980042e-05] 
Train error last 870 batches: 0.435254
-------------------------------------------------------
Not saving because 0.415953 > 0.415707 (12.630: -0.00%)
======================================================= (12.061 sec)
17.381... logprob:  0.463476, 0.125000 (1.479 sec)
17.382... logprob:  0.529513, 0.148438 (1.449 sec)
17.383... logprob:  0.358677, 0.085938 (1.441 sec)
17.384... logprob:  0.521063, 0.148438 (1.481 sec)
17.385... logprob:  0.523479, 0.148438 (1.438 sec)
17.386... logprob:  0.582362, 0.171875 (1.427 sec)
17.387... logprob:  0.428667, 0.117188 (1.437 sec)
17.388... logprob:  0.521316, 0.148438 (1.437 sec)
17.389... logprob:  0.425876, 0.109375 (1.439 sec)
17.390... logprob:  0.419907, 0.109375 (1.477 sec)
17.391... logprob:  0.318359, 0.070312 (1.445 sec)
17.392... logprob:  0.439429, 0.117188 (1.432 sec)
17.393... logprob:  0.368861, 0.093750 (1.493 sec)
17.394... logprob:  0.343496, 0.078125 (1.432 sec)
17.395... logprob:  0.331581, 0.078125 (1.435 sec)
17.396... logprob:  0.251899, 0.046875 (1.438 sec)
17.397... logprob:  0.484687, 0.132812 (1.429 sec)
17.398... logprob:  0.471388, 0.125000 (1.433 sec)
17.399... logprob:  0.433690, 0.117188 (1.480 sec)
17.400... logprob:  0.538509, 0.148438 (1.438 sec)
17.401... logprob:  0.466155, 0.125000 (1.446 sec)
17.402... logprob:  0.474247, 0.125000 (1.482 sec)
17.403... logprob:  0.462237, 0.125000 (1.429 sec)
17.404... logprob:  0.474830, 0.125000 (1.441 sec)
17.405... logprob:  0.543873, 0.156250 (1.431 sec)
17.406... logprob:  0.357886, 0.085938 (1.433 sec)
17.407... logprob:  0.492704, 0.140625 (1.441 sec)
17.408... logprob:  0.339697, 0.078125 (1.486 sec)
17.409... logprob:  0.400973, 0.101562 (1.437 sec)
17.410... logprob:  0.581768, 0.171875 (1.455 sec)
17.411... logprob:  0.398269, 0.101562 (1.471 sec)
17.412... logprob:  0.540211, 0.156250 (1.441 sec)
17.413... logprob:  0.544708, 0.156250 (1.434 sec)
17.414... logprob:  0.466617, 0.125000 (1.436 sec)
17.415... logprob:  0.401788, 0.101562 (1.426 sec)
17.416... logprob:  0.427565, 0.109375 (1.443 sec)
17.417... logprob:  0.405415, 0.093750 (1.461 sec)
17.418... logprob:  0.380093, 0.093750 (1.447 sec)
17.419... logprob:  0.417566, 0.101562 (1.454 sec)
17.420... logprob:  0.355896, 0.085938 (1.460 sec)
17.421... logprob:  0.376535, 0.101562 (1.455 sec)
17.422... logprob:  0.523093, 0.148438 (1.443 sec)
17.423... logprob:  0.421038, 0.109375 (1.426 sec)
17.424... logprob:  0.324609, 0.078125 (1.430 sec)
17.425... logprob:  0.306126, 0.070312 (1.444 sec)
17.426... logprob:  0.449432, 0.117188 (1.441 sec)
17.427... logprob:  0.555035, 0.156250 (1.457 sec)
17.428... logprob:  0.602332, 0.171875 (1.458 sec)
17.429... logprob:  0.426275, 0.109375 (1.442 sec)
17.430... logprob:  0.299971, 0.070312 (1.482 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.222755432128906, 10.0]}, 128)
batch 872: ({'logprob': [67.2113265991211, 19.0]}, 128)
batch 873: ({'logprob': [40.03872299194336, 9.0]}, 128)
batch 874: ({'logprob': [44.87899398803711, 11.0]}, 128)
batch 875: ({'logprob': [50.69424819946289, 13.0]}, 128)
batch 876: ({'logprob': [64.56454467773438, 18.0]}, 128)
batch 877: ({'logprob': [45.37238311767578, 11.0]}, 128)
batch 878: ({'logprob': [62.36701965332031, 17.0]}, 128)
batch 879: ({'logprob': [74.49520111083984, 21.0]}, 128)
batch 880: ({'logprob': [50.712493896484375, 13.0]}, 128)
batch 881: ({'logprob': [27.876937866210938, 5.0]}, 128)
batch 882: ({'logprob': [54.846405029296875, 14.0]}, 128)
batch 883: ({'logprob': [62.34928894042969, 17.0]}, 128)
batch 884: ({'logprob': [51.18684005737305, 13.0]}, 128)
batch 885: ({'logprob': [52.16623306274414, 13.0]}, 128)
batch 886: ({'logprob': [62.851165771484375, 17.0]}, 128)

======================Test output======================
logprob:  0.416423, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.968406e-03 [2.033160e-09] 
Layer 'conv1' biases: 1.719981e-07 [3.689464e-11] 
Layer 'conv2' weights[0]: 7.955418e-03 [1.697178e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.191523e-10] 
Layer 'conv3' weights[0]: 7.953745e-03 [1.438945e-09] 
Layer 'conv3' biases: 1.489559e-06 [6.614723e-10] 
Layer 'conv4' weights[0]: 7.986308e-03 [1.452896e-09] 
Layer 'conv4' biases: 9.999996e-01 [5.027156e-09] 
Layer 'conv5' weights[0]: 7.985144e-03 [3.125780e-08] 
Layer 'conv5' biases: 9.999970e-01 [3.368126e-08] 
Layer 'fc6' weights[0]: 7.581947e-03 [2.804814e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.746853e-09] 
Layer 'fc7' weights[0]: 7.304477e-03 [2.276626e-07] 
Layer 'fc7' biases: 9.998640e-01 [2.166406e-07] 
Layer 'fc8' weights[0]: 1.340197e-03 [8.682605e-06] 
Layer 'fc8' biases: 4.043751e-02 [4.670531e-05] 
Train error last 870 batches: 0.435254
-------------------------------------------------------
Not saving because 0.416423 > 0.415707 (12.630: -0.00%)
======================================================= (12.079 sec)
17.431... logprob:  0.599274, 0.171875 (1.445 sec)
17.432... logprob:  0.387607, 0.093750 (1.432 sec)
17.433... logprob:  0.330274, 0.078125 (1.431 sec)
17.434... logprob:  0.529087, 0.148438 (1.440 sec)
17.435... logprob:  0.532035, 0.156250 (1.433 sec)
17.436... logprob:  0.381610, 0.093750 (1.482 sec)
17.437... logprob:  0.500222, 0.140625 (1.444 sec)
17.438... logprob:  0.546767, 0.156250 (1.436 sec)
17.439... logprob:  0.379234, 0.093750 (1.484 sec)
17.440... logprob:  0.439893, 0.117188 (1.440 sec)
17.441... logprob:  0.468049, 0.125000 (1.428 sec)
17.442... logprob:  0.378922, 0.093750 (1.437 sec)
17.443... logprob:  0.496588, 0.140625 (1.439 sec)
17.444... logprob:  0.372077, 0.093750 (1.434 sec)
17.445... logprob:  0.362133, 0.085938 (1.485 sec)
17.446... logprob:  0.398081, 0.101562 (1.438 sec)
17.447... logprob:  0.570426, 0.164062 (1.438 sec)
17.448... logprob:  0.332464, 0.078125 (1.488 sec)
17.449... logprob:  0.400022, 0.101562 (1.430 sec)
17.450... logprob:  0.238768, 0.046875 (1.439 sec)
17.451... logprob:  0.453071, 0.125000 (1.434 sec)
17.452... logprob:  0.456408, 0.117188 (1.434 sec)
17.453... logprob:  0.455555, 0.125000 (1.431 sec)
17.454... logprob:  0.489280, 0.132812 (1.488 sec)
17.455... logprob:  0.506148, 0.140625 (1.435 sec)
17.456... logprob:  0.468803, 0.125000 (1.453 sec)
17.457... logprob:  0.375394, 0.093750 (1.472 sec)
17.458... logprob:  0.351235, 0.085938 (1.433 sec)
17.459... logprob:  0.513625, 0.140625 (1.436 sec)
17.460... logprob:  0.274661, 0.054688 (1.438 sec)
17.461... logprob:  0.459971, 0.125000 (1.425 sec)
17.462... logprob:  0.471888, 0.125000 (1.439 sec)
17.463... logprob:  0.420961, 0.109375 (1.473 sec)
17.464... logprob:  0.482673, 0.132812 (1.446 sec)
17.465... logprob:  0.421228, 0.109375 (1.456 sec)
17.466... logprob:  0.318674, 0.070312 (1.459 sec)
17.467... logprob:  0.413875, 0.109375 (1.459 sec)
17.468... logprob:  0.394278, 0.101562 (1.443 sec)
17.469... logprob:  0.334643, 0.078125 (1.427 sec)
17.470... logprob:  0.400050, 0.101562 (1.433 sec)
17.471... logprob:  0.529661, 0.148438 (1.439 sec)
17.472... logprob:  0.410087, 0.109375 (1.455 sec)
17.473... logprob:  0.375332, 0.093750 (1.461 sec)
17.474... logprob:  0.465827, 0.125000 (1.452 sec)
17.475... logprob:  0.504456, 0.140625 (1.455 sec)
17.476... logprob:  0.510516, 0.140625 (1.465 sec)
17.477... logprob:  0.334492, 0.078125 (1.439 sec)
17.478... logprob:  0.464295, 0.125000 (1.427 sec)
17.479... logprob:  0.305795, 0.070312 (1.434 sec)
17.480... logprob:  0.443520, 0.117188 (1.439 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.773826599121094, 10.0]}, 128)
batch 872: ({'logprob': [66.70830535888672, 19.0]}, 128)
batch 873: ({'logprob': [40.42875289916992, 9.0]}, 128)
batch 874: ({'logprob': [45.18720626831055, 11.0]}, 128)
batch 875: ({'logprob': [50.75978088378906, 13.0]}, 128)
batch 876: ({'logprob': [64.142333984375, 18.0]}, 128)
batch 877: ({'logprob': [45.60071563720703, 11.0]}, 128)
batch 878: ({'logprob': [61.94612121582031, 17.0]}, 128)
batch 879: ({'logprob': [73.50796508789062, 21.0]}, 128)
batch 880: ({'logprob': [50.77798080444336, 13.0]}, 128)
batch 881: ({'logprob': [28.834522247314453, 5.0]}, 128)
batch 882: ({'logprob': [54.58794403076172, 14.0]}, 128)
batch 883: ({'logprob': [61.928375244140625, 17.0]}, 128)
batch 884: ({'logprob': [51.17061233520508, 13.0]}, 128)
batch 885: ({'logprob': [51.988582611083984, 13.0]}, 128)
batch 886: ({'logprob': [62.3489875793457, 17.0]}, 128)

======================Test output======================
logprob:  0.415865, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.968368e-03 [2.153405e-09] 
Layer 'conv1' biases: 1.727086e-07 [3.202338e-11] 
Layer 'conv2' weights[0]: 7.955379e-03 [1.434485e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.351887e-10] 
Layer 'conv3' weights[0]: 7.953706e-03 [1.132293e-09] 
Layer 'conv3' biases: 1.495529e-06 [4.031168e-10] 
Layer 'conv4' weights[0]: 7.986273e-03 [1.154196e-09] 
Layer 'conv4' biases: 9.999996e-01 [2.836882e-09] 
Layer 'conv5' weights[0]: 7.985108e-03 [1.834967e-08] 
Layer 'conv5' biases: 9.999967e-01 [1.979152e-08] 
Layer 'fc6' weights[0]: 7.581911e-03 [1.753537e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.581301e-09] 
Layer 'fc7' weights[0]: 7.302634e-03 [4.824129e-08] 
Layer 'fc7' biases: 9.998635e-01 [2.741679e-08] 
Layer 'fc8' weights[0]: 1.315045e-03 [1.483726e-06] 
Layer 'fc8' biases: 4.053156e-02 [8.744252e-06] 
Train error last 870 batches: 0.435253
-------------------------------------------------------
Not saving because 0.415865 > 0.415707 (12.630: -0.00%)
======================================================= (12.040 sec)
17.481... logprob:  0.547737, 0.156250 (1.450 sec)
17.482... logprob:  0.443186, 0.117188 (1.481 sec)
17.483... logprob:  0.502565, 0.140625 (1.447 sec)
17.484... logprob:  0.485286, 0.132812 (1.439 sec)
17.485... logprob:  0.409103, 0.109375 (1.486 sec)
17.486... logprob:  0.361645, 0.085938 (1.432 sec)
17.487... logprob:  0.522608, 0.148438 (1.435 sec)
17.488... logprob:  0.424902, 0.109375 (1.432 sec)
17.489... logprob:  0.415962, 0.109375 (1.438 sec)
17.490... logprob:  0.440703, 0.117188 (1.432 sec)
17.491... logprob:  0.313716, 0.070312 (1.487 sec)
17.492... logprob:  0.459613, 0.125000 (1.439 sec)
17.493... logprob:  0.521974, 0.148438 (1.439 sec)
17.494... logprob:  0.450383, 0.125000 (1.489 sec)
17.495... logprob:  0.380543, 0.093750 (1.440 sec)
17.496... logprob:  0.550549, 0.156250 (1.435 sec)
17.497... logprob:  0.467053, 0.125000 (1.435 sec)
17.498... logprob:  0.476351, 0.132812 (1.431 sec)
17.499... logprob:  0.456284, 0.125000 (1.439 sec)
17.500... logprob:  0.355071, 0.085938 (1.489 sec)
17.501... logprob:  0.339107, 0.078125 (1.432 sec)
17.502... logprob:  0.459668, 0.125000 (1.443 sec)
17.503... logprob:  0.400692, 0.101562 (1.489 sec)
17.504... logprob:  0.487346, 0.132812 (1.433 sec)
17.505... logprob:  0.570811, 0.164062 (1.441 sec)
17.506... logprob:  0.479681, 0.132812 (1.436 sec)
17.507... logprob:  0.385148, 0.093750 (1.429 sec)
17.508... logprob:  0.374767, 0.093750 (1.434 sec)
17.509... logprob:  0.323234, 0.070312 (1.476 sec)
17.510... logprob:  0.390490, 0.101562 (1.439 sec)
17.511... logprob:  0.410085, 0.109375 (1.455 sec)
17.512... logprob:  0.470747, 0.125000 (1.462 sec)
17.513... logprob:  0.324977, 0.078125 (1.447 sec)
17.514... logprob:  0.406278, 0.101562 (1.450 sec)
17.515... logprob:  0.455606, 0.125000 (1.431 sec)
17.516... logprob:  0.400424, 0.109375 (1.424 sec)
17.517... logprob:  0.628067, 0.179688 (1.443 sec)
17.518... logprob:  0.437722, 0.117188 (1.457 sec)
17.519... logprob:  0.516156, 0.140625 (1.459 sec)
17.520... logprob:  0.409657, 0.109375 (1.453 sec)
17.521... logprob:  0.427526, 0.109375 (1.457 sec)
17.522... logprob:  0.533067, 0.156250 (1.466 sec)
17.523... logprob:  0.331790, 0.078125 (1.443 sec)
17.524... logprob:  0.437243, 0.117188 (1.429 sec)
17.525... logprob:  0.426100, 0.109375 (1.524 sec)
17.526... logprob:  0.351976, 0.078125 (1.439 sec)
17.527... logprob:  0.504540, 0.140625 (1.439 sec)
17.528... logprob:  0.440519, 0.117188 (1.468 sec)
17.529... logprob:  0.353016, 0.085938 (1.450 sec)
17.530... logprob:  0.440248, 0.117188 (1.438 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.87946701049805, 10.0]}, 128)
batch 872: ({'logprob': [66.39903259277344, 19.0]}, 128)
batch 873: ({'logprob': [40.79395294189453, 9.0]}, 128)
batch 874: ({'logprob': [45.343017578125, 11.0]}, 128)
batch 875: ({'logprob': [50.83087158203125, 13.0]}, 128)
batch 876: ({'logprob': [63.906463623046875, 18.0]}, 128)
batch 877: ({'logprob': [45.81897735595703, 11.0]}, 128)
batch 878: ({'logprob': [61.84642791748047, 17.0]}, 128)
batch 879: ({'logprob': [73.29932403564453, 21.0]}, 128)
batch 880: ({'logprob': [50.848785400390625, 13.0]}, 128)
batch 881: ({'logprob': [29.308839797973633, 5.0]}, 128)
batch 882: ({'logprob': [54.77071762084961, 14.0]}, 128)
batch 883: ({'logprob': [61.8286018371582, 17.0]}, 128)
batch 884: ({'logprob': [51.30295944213867, 13.0]}, 128)
batch 885: ({'logprob': [52.244834899902344, 13.0]}, 128)
batch 886: ({'logprob': [62.31092071533203, 17.0]}, 128)

======================Test output======================
logprob:  0.416374, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.968330e-03 [2.083209e-09] 
Layer 'conv1' biases: 1.735005e-07 [7.279383e-11] 
Layer 'conv2' weights[0]: 7.955337e-03 [2.040999e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.141821e-10] 
Layer 'conv3' weights[0]: 7.953670e-03 [1.925250e-09] 
Layer 'conv3' biases: 1.504042e-06 [9.499675e-10] 
Layer 'conv4' weights[0]: 7.986239e-03 [2.072099e-09] 
Layer 'conv4' biases: 9.999996e-01 [8.548219e-09] 
Layer 'conv5' weights[0]: 7.985086e-03 [5.693911e-08] 
Layer 'conv5' biases: 9.999965e-01 [6.144873e-08] 
Layer 'fc6' weights[0]: 7.581867e-03 [4.911968e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.887247e-09] 
Layer 'fc7' weights[0]: 7.300744e-03 [1.850859e-07] 
Layer 'fc7' biases: 9.998634e-01 [1.733302e-07] 
Layer 'fc8' weights[0]: 1.304805e-03 [6.816335e-06] 
Layer 'fc8' biases: 4.054160e-02 [4.637940e-05] 
Train error last 870 batches: 0.435253
-------------------------------------------------------
Not saving because 0.416374 > 0.415707 (12.630: -0.00%)
======================================================= (12.035 sec)
17.531... logprob:  0.440015, 0.117188 (1.491 sec)
17.532... logprob:  0.467407, 0.125000 (1.439 sec)
17.533... logprob:  0.560728, 0.164062 (1.425 sec)
17.534... logprob:  0.325777, 0.078125 (1.435 sec)
17.535... logprob:  0.551704, 0.156250 (1.438 sec)
17.536... logprob:  0.507415, 0.140625 (1.440 sec)
17.537... logprob:  0.510088, 0.140625 (1.495 sec)
17.538... logprob:  0.486115, 0.132812 (1.444 sec)
17.539... logprob:  0.296154, 0.062500 (1.436 sec)
17.540... logprob:  0.447181, 0.117188 (1.490 sec)
17.541... logprob:  0.388899, 0.101562 (1.431 sec)
17.542... logprob:  0.411321, 0.109375 (1.432 sec)
17.543... logprob:  0.233414, 0.039062 (1.437 sec)
17.544... logprob:  0.317951, 0.070312 (1.434 sec)
17.545... logprob:  0.348813, 0.085938 (1.435 sec)
17.546... logprob:  0.368290, 0.093750 (1.484 sec)
17.547... logprob:  0.440154, 0.117188 (1.441 sec)
17.548... logprob:  0.453213, 0.125000 (1.442 sec)
17.549... logprob:  0.490743, 0.132812 (1.482 sec)
17.550... logprob:  0.367699, 0.093750 (1.432 sec)
17.551... logprob:  0.441811, 0.117188 (1.440 sec)
17.552... logprob:  0.471346, 0.125000 (1.437 sec)
17.553... logprob:  0.349435, 0.085938 (1.427 sec)
17.554... logprob:  0.506838, 0.140625 (1.437 sec)
17.555... logprob:  0.421414, 0.109375 (1.478 sec)
17.556... logprob:  0.355942, 0.085938 (1.436 sec)
17.557... logprob:  0.396495, 0.101562 (1.445 sec)
17.558... logprob:  0.383071, 0.101562 (1.468 sec)
17.559... logprob:  0.441443, 0.125000 (1.443 sec)
17.560... logprob:  0.335364, 0.078125 (1.437 sec)
17.561... logprob:  0.411849, 0.109375 (1.435 sec)
17.562... logprob:  0.503114, 0.140625 (1.423 sec)
17.563... logprob:  0.373871, 0.093750 (1.438 sec)
17.564... logprob:  0.468421, 0.132812 (1.473 sec)
17.565... logprob:  0.611031, 0.187500 (1.447 sec)
17.566... logprob:  0.374921, 0.093750 (1.454 sec)
17.567... logprob:  0.423452, 0.109375 (1.469 sec)
17.568... logprob:  0.496383, 0.140625 (1.459 sec)
17.569... logprob:  0.507865, 0.140625 (1.438 sec)
17.570... logprob:  0.543724, 0.164062 (1.430 sec)
17.571... logprob:  0.454874, 0.125000 (1.428 sec)
17.572... logprob:  0.501490, 0.140625 (1.438 sec)
17.573... logprob:  0.512633, 0.148438 (1.451 sec)
17.574... logprob:  0.428158, 0.109375 (1.464 sec)
17.575... logprob:  0.343364, 0.078125 (1.453 sec)
17.576... logprob:  0.427414, 0.109375 (1.449 sec)
17.577... logprob:  0.460848, 0.125000 (1.475 sec)
17.578... logprob:  0.336572, 0.078125 (1.437 sec)
17.579... logprob:  0.442089, 0.117188 (1.424 sec)
17.580... logprob:  0.546973, 0.156250 (1.437 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.396484375, 10.0]}, 128)
batch 872: ({'logprob': [66.27802276611328, 19.0]}, 128)
batch 873: ({'logprob': [41.18107986450195, 9.0]}, 128)
batch 874: ({'logprob': [45.31123733520508, 11.0]}, 128)
batch 875: ({'logprob': [50.909645080566406, 13.0]}, 128)
batch 876: ({'logprob': [63.86219024658203, 18.0]}, 128)
batch 877: ({'logprob': [46.051292419433594, 11.0]}, 128)
batch 878: ({'logprob': [62.1441535949707, 17.0]}, 128)
batch 879: ({'logprob': [74.07928466796875, 21.0]}, 128)
batch 880: ({'logprob': [50.926578521728516, 13.0]}, 128)
batch 881: ({'logprob': [29.212677001953125, 5.0]}, 128)
batch 882: ({'logprob': [55.56425094604492, 14.0]}, 128)
batch 883: ({'logprob': [62.12664031982422, 17.0]}, 128)
batch 884: ({'logprob': [51.64558410644531, 13.0]}, 128)
batch 885: ({'logprob': [53.116024017333984, 13.0]}, 128)
batch 886: ({'logprob': [62.872859954833984, 17.0]}, 128)

======================Test output======================
logprob:  0.418300, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.968285e-03 [2.320551e-09] 
Layer 'conv1' biases: 1.743762e-07 [4.155582e-11] 
Layer 'conv2' weights[0]: 7.955292e-03 [1.673351e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.408564e-10] 
Layer 'conv3' weights[0]: 7.953630e-03 [1.498730e-09] 
Layer 'conv3' biases: 1.510240e-06 [7.892114e-10] 
Layer 'conv4' weights[0]: 7.986198e-03 [1.545251e-09] 
Layer 'conv4' biases: 9.999996e-01 [6.306569e-09] 
Layer 'conv5' weights[0]: 7.985037e-03 [4.266398e-08] 
Layer 'conv5' biases: 9.999962e-01 [4.622913e-08] 
Layer 'fc6' weights[0]: 7.581829e-03 [3.691579e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.664883e-09] 
Layer 'fc7' weights[0]: 7.298898e-03 [1.703147e-07] 
Layer 'fc7' biases: 9.998640e-01 [1.584195e-07] 
Layer 'fc8' weights[0]: 1.309562e-03 [8.571700e-06] 
Layer 'fc8' biases: 4.069575e-02 [5.750614e-05] 
Train error last 870 batches: 0.435252
-------------------------------------------------------
Not saving because 0.418300 > 0.415707 (12.630: -0.00%)
======================================================= (12.027 sec)
17.581... logprob:  0.531035, 0.156250 (1.440 sec)
17.582... logprob:  0.437908, 0.125000 (1.436 sec)
17.583... logprob:  0.592893, 0.171875 (1.481 sec)
17.584... logprob:  0.468133, 0.132812 (1.449 sec)
17.585... logprob:  0.349766, 0.085938 (1.431 sec)
17.586... logprob:  0.313161, 0.070312 (1.491 sec)
17.587... logprob:  0.404317, 0.101562 (1.436 sec)
17.588... logprob:  0.418675, 0.117188 (1.427 sec)
17.589... logprob:  0.361310, 0.093750 (1.433 sec)
17.590... logprob:  0.524696, 0.148438 (1.435 sec)
17.591... logprob:  0.397520, 0.101562 (1.432 sec)
17.592... logprob:  0.455644, 0.125000 (1.487 sec)
17.593... logprob:  0.467439, 0.125000 (1.435 sec)
17.594... logprob:  0.352878, 0.085938 (1.446 sec)
17.595... logprob:  0.428670, 0.109375 (1.479 sec)
17.596... logprob:  0.461581, 0.125000 (1.439 sec)
17.597... logprob:  0.397412, 0.101562 (1.430 sec)
17.598... logprob:  0.397231, 0.101562 (1.443 sec)
17.599... logprob:  0.313506, 0.070312 (1.427 sec)
17.600... logprob:  0.340899, 0.085938 (1.436 sec)
17.601... logprob:  0.402121, 0.101562 (1.484 sec)
17.602... logprob:  0.289678, 0.062500 (1.432 sec)
17.603... logprob:  0.266928, 0.054688 (1.448 sec)
17.604... logprob:  0.407513, 0.101562 (1.474 sec)
17.605... logprob:  0.563604, 0.148438 (1.436 sec)
17.606... logprob:  0.295947, 0.070312 (1.442 sec)
17.607... logprob:  0.504933, 0.132812 (1.432 sec)
17.608... logprob:  0.361678, 0.085938 (1.429 sec)
17.609... logprob:  0.356921, 0.085938 (1.435 sec)
17.610... logprob:  0.493437, 0.132812 (1.477 sec)
17.611... logprob:  0.510442, 0.140625 (1.445 sec)
17.612... logprob:  0.448388, 0.117188 (1.456 sec)
17.613... logprob:  0.279805, 0.062500 (1.460 sec)
17.614... logprob:  0.503516, 0.140625 (1.455 sec)
17.615... logprob:  0.351179, 0.085938 (1.446 sec)
17.616... logprob:  0.415352, 0.109375 (1.432 sec)
17.617... logprob:  0.417977, 0.109375 (1.428 sec)
17.618... logprob:  0.546688, 0.156250 (1.438 sec)
17.619... logprob:  0.505941, 0.140625 (1.449 sec)
17.620... logprob:  0.539618, 0.156250 (1.458 sec)
17.621... logprob:  0.363933, 0.085938 (1.458 sec)
17.622... logprob:  0.364952, 0.085938 (1.445 sec)
17.623... logprob:  0.423222, 0.109375 (1.471 sec)
17.624... logprob:  0.382556, 0.093750 (1.435 sec)
17.625... logprob:  0.441005, 0.117188 (1.430 sec)
17.626... logprob:  0.438395, 0.117188 (1.431 sec)
17.627... logprob:  0.435863, 0.117188 (1.440 sec)
17.628... logprob:  0.465099, 0.125000 (1.439 sec)
17.629... logprob:  0.371988, 0.093750 (1.475 sec)
17.630... logprob:  0.422373, 0.109375 (1.451 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.74381637573242, 10.0]}, 128)
batch 872: ({'logprob': [67.15753936767578, 19.0]}, 128)
batch 873: ({'logprob': [40.035587310791016, 9.0]}, 128)
batch 874: ({'logprob': [45.07069778442383, 11.0]}, 128)
batch 875: ({'logprob': [50.738868713378906, 13.0]}, 128)
batch 876: ({'logprob': [64.49922943115234, 18.0]}, 128)
batch 877: ({'logprob': [45.39381790161133, 11.0]}, 128)
batch 878: ({'logprob': [62.118961334228516, 17.0]}, 128)
batch 879: ({'logprob': [73.7841796875, 21.0]}, 128)
batch 880: ({'logprob': [50.757850646972656, 13.0]}, 128)
batch 881: ({'logprob': [28.337650299072266, 5.0]}, 128)
batch 882: ({'logprob': [54.3913459777832, 14.0]}, 128)
batch 883: ({'logprob': [62.10062026977539, 17.0]}, 128)
batch 884: ({'logprob': [51.06086730957031, 13.0]}, 128)
batch 885: ({'logprob': [51.69879150390625, 13.0]}, 128)
batch 886: ({'logprob': [62.43225860595703, 17.0]}, 128)

======================Test output======================
logprob:  0.415685, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.968246e-03 [2.313955e-09] 
Layer 'conv1' biases: 1.751720e-07 [2.804621e-11] 
Layer 'conv2' weights[0]: 7.955258e-03 [1.614627e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.393857e-10] 
Layer 'conv3' weights[0]: 7.953587e-03 [1.227452e-09] 
Layer 'conv3' biases: 1.517532e-06 [4.277893e-10] 
Layer 'conv4' weights[0]: 7.986160e-03 [1.301222e-09] 
Layer 'conv4' biases: 9.999996e-01 [3.122104e-09] 
Layer 'conv5' weights[0]: 7.984995e-03 [2.098449e-08] 
Layer 'conv5' biases: 9.999963e-01 [2.259006e-08] 
Layer 'fc6' weights[0]: 7.581788e-03 [1.957459e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.797914e-09] 
Layer 'fc7' weights[0]: 7.297055e-03 [1.918152e-07] 
Layer 'fc7' biases: 9.998637e-01 [1.800783e-07] 
Layer 'fc8' weights[0]: 1.328132e-03 [6.445114e-06] 
Layer 'fc8' biases: 4.098938e-02 [4.480627e-05] 
Train error last 870 batches: 0.435252
-------------------------------------------------------
Saved checkpoint to /data2/ad6813/my-nets/saves/ConvNet__2014-06-17_23.05.49
======================================================= (12.687 sec)
17.631... logprob:  0.639375, 0.187500 (1.445 sec)
17.632... logprob:  0.399099, 0.101562 (1.490 sec)
17.633... logprob:  0.376020, 0.093750 (1.436 sec)
17.634... logprob:  0.660480, 0.195312 (2.928 sec)
17.635... logprob:  0.374123, 0.093750 (1.438 sec)
17.636... logprob:  0.480231, 0.132812 (1.476 sec)
17.637... logprob:  0.330956, 0.078125 (2.922 sec)
17.638... logprob:  0.515667, 0.140625 (1.483 sec)
17.639... logprob:  0.418161, 0.109375 (1.440 sec)
17.640... logprob:  0.528747, 0.148438 (1.439 sec)
17.641... logprob:  0.410492, 0.109375 (1.486 sec)
17.642... logprob:  0.500813, 0.140625 (1.436 sec)
17.643... logprob:  0.622827, 0.187500 (1.434 sec)
17.644... logprob:  0.321431, 0.070312 (1.436 sec)
17.645... logprob:  0.414511, 0.109375 (1.429 sec)
17.646... logprob:  0.385762, 0.093750 (1.437 sec)
17.647... logprob:  0.456750, 0.125000 (1.489 sec)
17.648... logprob:  0.491229, 0.140625 (1.433 sec)
17.649... logprob:  0.370106, 0.093750 (1.450 sec)
17.650... logprob:  0.413932, 0.109375 (1.474 sec)
17.651... logprob:  0.397301, 0.101562 (1.462 sec)
17.652... logprob:  0.507406, 0.140625 (1.438 sec)
17.653... logprob:  0.548150, 0.156250 (1.471 sec)
17.654... logprob:  0.496154, 0.140625 (1.434 sec)
17.655... logprob:  0.436211, 0.117188 (1.436 sec)
17.656... logprob:  0.416674, 0.109375 (1.482 sec)
17.657... logprob:  0.449278, 0.117188 (1.443 sec)
17.658... logprob:  0.345762, 0.085938 (1.456 sec)
17.659... logprob:  0.464355, 0.125000 (1.466 sec)
17.660... logprob:  0.445906, 0.125000 (1.445 sec)
17.661... logprob:  0.378548, 0.093750 (1.439 sec)
17.662... logprob:  0.469337, 0.132812 (1.431 sec)
17.663... logprob:  0.311051, 0.070312 (1.429 sec)
17.664... logprob:  0.285512, 0.062500 (1.437 sec)
17.665... logprob:  0.401851, 0.101562 (1.460 sec)
17.666... logprob:  0.442067, 0.117188 (1.450 sec)
17.667... logprob:  0.564312, 0.164062 (1.455 sec)
17.668... logprob:  0.497916, 0.140625 (1.450 sec)
17.669... logprob:  0.433096, 0.109375 (1.462 sec)
17.670... logprob:  0.362488, 0.085938 (1.439 sec)
17.671... logprob:  0.360854, 0.093750 (1.422 sec)
17.672... logprob:  0.441812, 0.117188 (1.435 sec)
17.673... logprob:  0.436245, 0.117188 (1.439 sec)
17.674... logprob:  0.446667, 0.117188 (1.444 sec)
17.675... logprob:  0.356667, 0.093750 (1.468 sec)
17.676... logprob:  0.450149, 0.125000 (1.450 sec)
17.677... logprob:  0.471059, 0.125000 (1.442 sec)
17.678... logprob:  0.465643, 0.125000 (1.478 sec)
17.679... logprob:  0.454873, 0.125000 (1.434 sec)
17.680... logprob:  0.351737, 0.078125 (1.425 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.73914337158203, 10.0]}, 128)
batch 872: ({'logprob': [66.1277847290039, 19.0]}, 128)
batch 873: ({'logprob': [41.265933990478516, 9.0]}, 128)
batch 874: ({'logprob': [45.457862854003906, 11.0]}, 128)
batch 875: ({'logprob': [50.93662643432617, 13.0]}, 128)
batch 876: ({'logprob': [63.726505279541016, 18.0]}, 128)
batch 877: ({'logprob': [46.107666015625, 11.0]}, 128)
batch 878: ({'logprob': [61.932132720947266, 17.0]}, 128)
batch 879: ({'logprob': [73.53765869140625, 21.0]}, 128)
batch 880: ({'logprob': [50.95391082763672, 13.0]}, 128)
batch 881: ({'logprob': [29.627464294433594, 5.0]}, 128)
batch 882: ({'logprob': [55.304466247558594, 14.0]}, 128)
batch 883: ({'logprob': [61.91442108154297, 17.0]}, 128)
batch 884: ({'logprob': [51.5814094543457, 13.0]}, 128)
batch 885: ({'logprob': [52.870094299316406, 13.0]}, 128)
batch 886: ({'logprob': [62.569740295410156, 17.0]}, 128)

======================Test output======================
logprob:  0.417799, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.968207e-03 [3.829065e-09] 
Layer 'conv1' biases: 1.759217e-07 [9.947844e-11] 
Layer 'conv2' weights[0]: 7.955220e-03 [2.373170e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.213327e-10] 
Layer 'conv3' weights[0]: 7.953552e-03 [2.159135e-09] 
Layer 'conv3' biases: 1.525149e-06 [1.201702e-09] 
Layer 'conv4' weights[0]: 7.986118e-03 [2.187924e-09] 
Layer 'conv4' biases: 9.999996e-01 [9.092572e-09] 
Layer 'conv5' weights[0]: 7.984951e-03 [5.234716e-08] 
Layer 'conv5' biases: 9.999966e-01 [5.651728e-08] 
Layer 'fc6' weights[0]: 7.581749e-03 [4.573356e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.556363e-09] 
Layer 'fc7' weights[0]: 7.295231e-03 [5.095939e-08] 
Layer 'fc7' biases: 9.998634e-01 [3.004232e-08] 
Layer 'fc8' weights[0]: 1.305366e-03 [4.276536e-06] 
Layer 'fc8' biases: 4.089811e-02 [2.768223e-05] 
Train error last 870 batches: 0.435252
-------------------------------------------------------
Not saving because 0.417799 > 0.415685 (17.630: -0.01%)
======================================================= (12.103 sec)
17.681... logprob:  0.373944, 0.093750 (1.445 sec)
17.682... logprob:  0.340504, 0.078125 (1.445 sec)
17.683... logprob:  0.411648, 0.109375 (1.431 sec)
17.684... logprob:  0.357599, 0.085938 (1.507 sec)
17.685... logprob:  0.285858, 0.054688 (1.446 sec)
17.686... logprob:  0.318517, 0.070312 (1.458 sec)
17.687... logprob:  0.281511, 0.062500 (1.490 sec)
17.688... logprob:  0.323079, 0.078125 (1.437 sec)
17.689... logprob:  0.471550, 0.125000 (1.429 sec)
17.690... logprob:  0.528125, 0.140625 (1.437 sec)
17.691... logprob:  0.517096, 0.140625 (1.437 sec)
17.692... logprob:  0.385334, 0.101562 (1.431 sec)
17.693... logprob:  0.456046, 0.125000 (1.489 sec)
17.694... logprob:  0.330889, 0.078125 (1.436 sec)
17.695... logprob:  0.356890, 0.085938 (1.445 sec)
17.696... logprob:  0.538774, 0.148438 (1.479 sec)
17.697... logprob:  0.465578, 0.125000 (1.434 sec)
17.698... logprob:  0.548511, 0.156250 (1.438 sec)
17.699... logprob:  0.459582, 0.125000 (1.432 sec)
17.700... logprob:  0.434045, 0.117188 (1.424 sec)
17.701... logprob:  0.423362, 0.109375 (1.436 sec)
17.702... logprob:  0.521447, 0.148438 (1.483 sec)
17.703... logprob:  0.405545, 0.101562 (1.439 sec)
17.704... logprob:  0.406349, 0.101562 (1.451 sec)
17.705... logprob:  0.420313, 0.109375 (1.478 sec)
17.706... logprob:  0.468080, 0.125000 (1.438 sec)
17.707... logprob:  0.485300, 0.132812 (1.434 sec)
17.708... logprob:  0.417041, 0.109375 (1.436 sec)
17.709... logprob:  0.422432, 0.109375 (1.424 sec)
17.710... logprob:  0.602805, 0.179688 (1.442 sec)
17.711... logprob:  0.469531, 0.125000 (1.464 sec)
17.712... logprob:  0.340322, 0.078125 (1.454 sec)
17.713... logprob:  0.587370, 0.179688 (1.453 sec)
17.714... logprob:  0.466338, 0.125000 (1.460 sec)
17.715... logprob:  0.417135, 0.109375 (1.459 sec)
17.716... logprob:  0.335239, 0.078125 (1.436 sec)
17.717... logprob:  0.429837, 0.117188 (1.426 sec)
17.718... logprob:  0.490386, 0.132812 (1.435 sec)
17.719... logprob:  0.406201, 0.109375 (1.436 sec)
17.720... logprob:  0.433239, 0.117188 (1.453 sec)
17.721... logprob:  0.451600, 0.117188 (1.462 sec)
17.722... logprob:  0.536836, 0.156250 (1.454 sec)
17.723... logprob:  0.416604, 0.109375 (1.450 sec)
17.724... logprob:  0.412781, 0.109375 (1.477 sec)
17.725... logprob:  0.494651, 0.140625 (1.459 sec)
17.726... logprob:  0.338688, 0.085938 (1.427 sec)
17.727... logprob:  0.393382, 0.101562 (1.435 sec)
17.728... logprob:  0.421369, 0.109375 (1.443 sec)
17.729... logprob:  0.387807, 0.093750 (1.433 sec)
17.730... logprob:  0.565826, 0.164062 (1.474 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.64958953857422, 10.0]}, 128)
batch 872: ({'logprob': [66.25147247314453, 19.0]}, 128)
batch 873: ({'logprob': [41.046302795410156, 9.0]}, 128)
batch 874: ({'logprob': [45.34402847290039, 11.0]}, 128)
batch 875: ({'logprob': [50.86646270751953, 13.0]}, 128)
batch 876: ({'logprob': [63.812931060791016, 18.0]}, 128)
batch 877: ({'logprob': [45.96263885498047, 11.0]}, 128)
batch 878: ({'logprob': [61.94989013671875, 17.0]}, 128)
batch 879: ({'logprob': [73.6125717163086, 21.0]}, 128)
batch 880: ({'logprob': [50.8837776184082, 13.0]}, 128)
batch 881: ({'logprob': [29.35057258605957, 5.0]}, 128)
batch 882: ({'logprob': [55.179325103759766, 14.0]}, 128)
batch 883: ({'logprob': [61.93227005004883, 17.0]}, 128)
batch 884: ({'logprob': [51.480709075927734, 13.0]}, 128)
batch 885: ({'logprob': [52.70766830444336, 13.0]}, 128)
batch 886: ({'logprob': [62.556766510009766, 17.0]}, 128)

======================Test output======================
logprob:  0.417279, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.968170e-03 [3.193308e-09] 
Layer 'conv1' biases: 1.767120e-07 [8.265732e-11] 
Layer 'conv2' weights[0]: 7.955176e-03 [2.382043e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.010811e-10] 
Layer 'conv3' weights[0]: 7.953517e-03 [2.135172e-09] 
Layer 'conv3' biases: 1.531430e-06 [1.252492e-09] 
Layer 'conv4' weights[0]: 7.986081e-03 [2.226472e-09] 
Layer 'conv4' biases: 9.999996e-01 [1.083510e-08] 
Layer 'conv5' weights[0]: 7.984920e-03 [7.284190e-08] 
Layer 'conv5' biases: 9.999964e-01 [7.878658e-08] 
Layer 'fc6' weights[0]: 7.581702e-03 [6.164287e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.264689e-09] 
Layer 'fc7' weights[0]: 7.293346e-03 [4.810932e-08] 
Layer 'fc7' biases: 9.998634e-01 [2.632760e-08] 
Layer 'fc8' weights[0]: 1.310028e-03 [3.464678e-06] 
Layer 'fc8' biases: 4.115131e-02 [2.154384e-05] 
Train error last 870 batches: 0.435251
-------------------------------------------------------
Not saving because 0.417279 > 0.415685 (17.630: -0.01%)
======================================================= (12.067 sec)
17.731... logprob:  0.450326, 0.125000 (1.448 sec)
17.732... logprob:  0.311486, 0.070312 (1.435 sec)
17.733... logprob:  0.556699, 0.156250 (1.489 sec)
17.734... logprob:  0.340226, 0.078125 (1.436 sec)
17.735... logprob:  0.527627, 0.148438 (1.432 sec)
17.736... logprob:  0.643047, 0.187500 (1.439 sec)
17.737... logprob:  0.516208, 0.148438 (1.433 sec)
17.738... logprob:  0.459432, 0.125000 (1.435 sec)
17.739... logprob:  0.477816, 0.132812 (1.477 sec)
17.740... logprob:  0.339661, 0.078125 (1.439 sec)
17.741... logprob:  0.393450, 0.101562 (1.438 sec)
17.742... logprob:  0.419741, 0.109375 (1.486 sec)
17.743... logprob:  0.364872, 0.085938 (1.432 sec)
17.744... logprob:  0.519252, 0.148438 (1.437 sec)
17.745... logprob:  0.478179, 0.132812 (1.435 sec)
17.746... logprob:  0.440560, 0.117188 (1.430 sec)
17.747... logprob:  0.425629, 0.109375 (1.438 sec)
17.748... logprob:  0.378053, 0.093750 (1.486 sec)
17.749... logprob:  0.420846, 0.109375 (1.435 sec)
17.750... logprob:  0.512920, 0.140625 (1.451 sec)
17.751... logprob:  0.263534, 0.054688 (1.477 sec)
17.752... logprob:  0.522519, 0.140625 (1.443 sec)
17.753... logprob:  0.441252, 0.117188 (1.439 sec)
17.754... logprob:  0.468567, 0.132812 (1.429 sec)
17.755... logprob:  0.507117, 0.140625 (1.434 sec)
17.756... logprob:  0.440823, 0.117188 (1.435 sec)
17.757... logprob:  0.552293, 0.156250 (1.472 sec)
17.758... logprob:  0.393708, 0.101562 (1.482 sec)
17.759... logprob:  0.459691, 0.125000 (1.453 sec)
17.760... logprob:  0.485416, 0.132812 (1.468 sec)
17.761... logprob:  0.418390, 0.109375 (1.447 sec)
17.762... logprob:  0.515983, 0.148438 (1.438 sec)
17.763... logprob:  0.558785, 0.164062 (1.431 sec)
17.764... logprob:  0.503290, 0.140625 (1.432 sec)
17.765... logprob:  0.312259, 0.062500 (1.435 sec)
17.766... logprob:  0.482295, 0.132812 (1.458 sec)
17.767... logprob:  0.371172, 0.085938 (1.456 sec)
17.768... logprob:  0.432707, 0.117188 (1.468 sec)
17.769... logprob:  0.490899, 0.140625 (1.466 sec)
17.770... logprob:  0.402824, 0.101562 (1.478 sec)
17.771... logprob:  0.549677, 0.156250 (1.457 sec)
17.772... logprob:  0.414035, 0.109375 (1.441 sec)
17.773... logprob:  0.558158, 0.164062 (1.449 sec)
17.774... logprob:  0.361530, 0.085938 (1.458 sec)
17.775... logprob:  0.407322, 0.101562 (1.468 sec)
17.776... logprob:  0.433242, 0.117188 (1.480 sec)
17.777... logprob:  0.379920, 0.093750 (1.476 sec)
17.778... logprob:  0.433623, 0.117188 (1.464 sec)
17.779... logprob:  0.505476, 0.140625 (1.486 sec)
17.780... logprob:  0.385758, 0.101562 (1.462 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.49089431762695, 10.0]}, 128)
batch 872: ({'logprob': [66.88128662109375, 19.0]}, 128)
batch 873: ({'logprob': [40.262115478515625, 9.0]}, 128)
batch 874: ({'logprob': [45.030452728271484, 11.0]}, 128)
batch 875: ({'logprob': [50.70936584472656, 13.0]}, 128)
batch 876: ({'logprob': [64.28678131103516, 18.0]}, 128)
batch 877: ({'logprob': [45.49211502075195, 11.0]}, 128)
batch 878: ({'logprob': [62.1094856262207, 17.0]}, 128)
batch 879: ({'logprob': [73.93264770507812, 21.0]}, 128)
batch 880: ({'logprob': [50.7277717590332, 13.0]}, 128)
batch 881: ({'logprob': [28.405715942382812, 5.0]}, 128)
batch 882: ({'logprob': [54.71248245239258, 14.0]}, 128)
batch 883: ({'logprob': [62.09135055541992, 17.0]}, 128)
batch 884: ({'logprob': [51.16934585571289, 13.0]}, 128)
batch 885: ({'logprob': [52.084075927734375, 13.0]}, 128)
batch 886: ({'logprob': [62.5610466003418, 17.0]}, 128)

======================Test output======================
logprob:  0.415990, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.968134e-03 [2.590273e-09] 
Layer 'conv1' biases: 1.774551e-07 [5.556654e-11] 
Layer 'conv2' weights[0]: 7.955140e-03 [2.091964e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.661502e-10] 
Layer 'conv3' weights[0]: 7.953477e-03 [1.634983e-09] 
Layer 'conv3' biases: 1.538082e-06 [7.312354e-10] 
Layer 'conv4' weights[0]: 7.986046e-03 [1.574437e-09] 
Layer 'conv4' biases: 9.999996e-01 [4.200203e-09] 
Layer 'conv5' weights[0]: 7.984879e-03 [1.982253e-08] 
Layer 'conv5' biases: 9.999965e-01 [2.061944e-08] 
Layer 'fc6' weights[0]: 7.581661e-03 [1.834884e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.671316e-09] 
Layer 'fc7' weights[0]: 7.291457e-03 [4.953457e-08] 
Layer 'fc7' biases: 9.998636e-01 [2.765078e-08] 
Layer 'fc8' weights[0]: 1.326735e-03 [3.545218e-06] 
Layer 'fc8' biases: 4.140343e-02 [2.344006e-05] 
Train error last 870 batches: 0.435251
-------------------------------------------------------
Not saving because 0.415990 > 0.415685 (17.630: -0.01%)
======================================================= (12.132 sec)
17.781... logprob:  0.369726, 0.085938 (1.449 sec)
17.782... logprob:  0.351507, 0.085938 (1.457 sec)
17.783... logprob:  0.555467, 0.156250 (1.461 sec)
17.784... logprob:  0.440956, 0.117188 (1.455 sec)
17.785... logprob:  0.543523, 0.156250 (1.495 sec)
17.786... logprob:  0.477398, 0.132812 (1.466 sec)
17.787... logprob:  0.546182, 0.156250 (1.465 sec)
17.788... logprob:  0.562890, 0.164062 (1.492 sec)
17.789... logprob:  0.281457, 0.054688 (1.454 sec)
17.790... logprob:  0.408324, 0.101562 (1.451 sec)
17.791... logprob:  0.398160, 0.101562 (1.452 sec)
17.792... logprob:  0.361258, 0.085938 (1.458 sec)
17.793... logprob:  0.370287, 0.085938 (1.457 sec)
17.794... logprob:  0.387128, 0.093750 (1.491 sec)
17.795... logprob:  0.469827, 0.125000 (1.466 sec)
17.796... logprob:  0.423500, 0.109375 (1.462 sec)
17.797... logprob:  0.358704, 0.085938 (1.500 sec)
17.798... logprob:  0.393265, 0.101562 (1.451 sec)
17.799... logprob:  0.332170, 0.078125 (1.456 sec)
17.800... logprob:  0.371783, 0.093750 (1.445 sec)
17.801... logprob:  0.450342, 0.117188 (1.459 sec)
17.802... logprob:  0.423157, 0.109375 (1.455 sec)
17.803... logprob:  0.492017, 0.132812 (1.497 sec)
17.804... logprob:  0.349985, 0.085938 (1.463 sec)
17.805... logprob:  0.452298, 0.117188 (1.457 sec)
17.806... logprob:  0.424187, 0.109375 (1.500 sec)
17.807... logprob:  0.443452, 0.117188 (1.452 sec)
17.808... logprob:  0.462338, 0.125000 (1.450 sec)
17.809... logprob:  0.589451, 0.171875 (1.451 sec)
17.810... logprob:  0.442442, 0.117188 (1.458 sec)
17.811... logprob:  0.460419, 0.125000 (1.453 sec)
17.812... logprob:  0.462424, 0.125000 (1.497 sec)
17.813... logprob:  0.485989, 0.132812 (1.462 sec)
17.814... logprob:  0.478149, 0.132812 (1.455 sec)
17.815... logprob:  0.372352, 0.085938 (1.505 sec)
17.816... logprob:  0.409002, 0.101562 (1.452 sec)
17.817... logprob:  0.426139, 0.109375 (1.456 sec)
17.818... logprob:  0.559968, 0.164062 (1.449 sec)
17.819... logprob:  0.498216, 0.140625 (1.459 sec)
17.820... logprob:  0.421548, 0.109375 (1.452 sec)
17.821... logprob:  0.406431, 0.101562 (1.502 sec)
17.822... logprob:  0.441088, 0.117188 (1.454 sec)
17.823... logprob:  0.340455, 0.078125 (1.223 sec)
17.824... logprob:  0.490009, 0.132812 (0.712 sec)
17.825... logprob:  0.287507, 0.062500 (0.687 sec)
17.826... logprob:  0.375353, 0.093750 (0.692 sec)
17.827... logprob:  0.420647, 0.109375 (0.689 sec)
17.828... logprob:  0.443631, 0.117188 (0.690 sec)
17.829... logprob:  0.504674, 0.140625 (0.691 sec)
17.830... logprob:  0.442362, 0.117188 (1.503 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.25250244140625, 10.0]}, 128)
batch 872: ({'logprob': [68.33063507080078, 19.0]}, 128)
batch 873: ({'logprob': [39.416629791259766, 9.0]}, 128)
batch 874: ({'logprob': [44.79064178466797, 11.0]}, 128)
batch 875: ({'logprob': [50.82923126220703, 13.0]}, 128)
batch 876: ({'logprob': [65.49577331542969, 18.0]}, 128)
batch 877: ({'logprob': [45.128841400146484, 11.0]}, 128)
batch 878: ({'logprob': [62.953224182128906, 17.0]}, 128)
batch 879: ({'logprob': [75.37809753417969, 21.0]}, 128)
batch 880: ({'logprob': [50.848724365234375, 13.0]}, 128)
batch 881: ({'logprob': [26.957666397094727, 5.0]}, 128)
batch 882: ({'logprob': [54.71061325073242, 14.0]}, 128)
batch 883: ({'logprob': [62.93470764160156, 17.0]}, 128)
batch 884: ({'logprob': [51.169986724853516, 13.0]}, 128)
batch 885: ({'logprob': [51.84131622314453, 13.0]}, 128)
batch 886: ({'logprob': [63.28425979614258, 17.0]}, 128)

======================Test output======================
logprob:  0.417638, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.968093e-03 [4.408241e-09] 
Layer 'conv1' biases: 1.783762e-07 [1.313902e-10] 
Layer 'conv2' weights[0]: 7.955095e-03 [3.774034e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.468782e-10] 
Layer 'conv3' weights[0]: 7.953440e-03 [3.623500e-09] 
Layer 'conv3' biases: 1.545168e-06 [2.315432e-09] 
Layer 'conv4' weights[0]: 7.986011e-03 [3.686149e-09] 
Layer 'conv4' biases: 9.999996e-01 [1.999377e-08] 
Layer 'conv5' weights[0]: 7.984837e-03 [1.283978e-07] 
Layer 'conv5' biases: 9.999964e-01 [1.386358e-07] 
Layer 'fc6' weights[0]: 7.581622e-03 [1.091043e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.115140e-08] 
Layer 'fc7' weights[0]: 7.289573e-03 [5.950994e-08] 
Layer 'fc7' biases: 9.998643e-01 [4.024818e-08] 
Layer 'fc8' weights[0]: 1.357422e-03 [5.987379e-06] 
Layer 'fc8' biases: 4.186354e-02 [3.294843e-05] 
Train error last 870 batches: 0.435251
-------------------------------------------------------
Not saving because 0.417638 > 0.415685 (17.630: -0.01%)
======================================================= (12.099 sec)
17.831... logprob:  0.514141, 0.140625 (1.467 sec)
17.832... logprob:  0.330860, 0.078125 (1.459 sec)
17.833... logprob:  0.488952, 0.132812 (1.498 sec)
17.834... logprob:  0.433193, 0.117188 (1.451 sec)
17.835... logprob:  0.542475, 0.148438 (1.462 sec)
17.836... logprob:  0.376346, 0.093750 (1.447 sec)
17.837... logprob:  0.314811, 0.070312 (1.456 sec)
17.838... logprob:  0.437093, 0.117188 (1.452 sec)
17.839... logprob:  0.471732, 0.125000 (1.506 sec)
17.840... logprob:  0.555242, 0.156250 (1.452 sec)
17.841... logprob:  0.396288, 0.101562 (1.475 sec)
17.842... logprob:  0.497801, 0.140625 (1.499 sec)
17.843... logprob:  0.465552, 0.125000 (1.449 sec)
17.844... logprob:  0.497614, 0.140625 (1.460 sec)
17.845... logprob:  0.486831, 0.132812 (1.453 sec)
17.846... logprob:  0.468491, 0.125000 (1.448 sec)
17.847... logprob:  0.363162, 0.085938 (1.455 sec)
17.848... logprob:  0.397008, 0.101562 (1.500 sec)
17.849... logprob:  0.360239, 0.085938 (1.460 sec)
17.850... logprob:  0.479442, 0.132812 (1.466 sec)
17.851... logprob:  0.440154, 0.117188 (1.502 sec)
17.852... logprob:  0.545908, 0.156250 (1.452 sec)
17.853... logprob:  0.371777, 0.093750 (1.465 sec)
17.854... logprob:  0.306992, 0.070312 (1.448 sec)
17.855... logprob:  0.484992, 0.132812 (1.450 sec)
17.856... logprob:  0.443871, 0.117188 (1.452 sec)
17.857... logprob:  0.372241, 0.093750 (1.497 sec)
17.858... logprob:  0.396247, 0.101562 (1.460 sec)
17.859... logprob:  0.307950, 0.070312 (1.472 sec)
17.860... logprob:  0.565953, 0.156250 (1.488 sec)
17.861... logprob:  0.417819, 0.109375 (1.459 sec)
17.862... logprob:  0.328938, 0.078125 (1.462 sec)
17.863... logprob:  0.399516, 0.101562 (1.450 sec)
17.864... logprob:  0.451389, 0.117188 (1.445 sec)
17.865... logprob:  0.484393, 0.132812 (1.460 sec)
17.866... logprob:  0.507498, 0.140625 (1.483 sec)
17.867... logprob:  0.502826, 0.140625 (1.495 sec)
17.868... logprob:  0.405396, 0.101562 (1.476 sec)
17.869... logprob:  0.383351, 0.093750 (1.480 sec)
17.870... logprob:  0.551948, 0.156250 (1.407 sec)
18.1... logprob:  0.380191, 0.093750 (1.409 sec)
18.2... logprob:  0.448283, 0.117188 (1.456 sec)
18.3... logprob:  0.398422, 0.101562 (1.418 sec)
18.4... logprob:  0.443353, 0.117188 (1.404 sec)
18.5... logprob:  0.443422, 0.117188 (1.437 sec)
18.6... logprob:  0.499198, 0.140625 (1.398 sec)
18.7... logprob:  0.363051, 0.085938 (1.426 sec)
18.8... logprob:  0.419109, 0.109375 (1.400 sec)
18.9... logprob:  0.358664, 0.085938 (1.405 sec)
18.10... logprob:  0.377386, 0.093750 (1.411 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.1450080871582, 10.0]}, 128)
batch 872: ({'logprob': [67.11471557617188, 19.0]}, 128)
batch 873: ({'logprob': [40.163856506347656, 9.0]}, 128)
batch 874: ({'logprob': [45.2770881652832, 11.0]}, 128)
batch 875: ({'logprob': [50.836185455322266, 13.0]}, 128)
batch 876: ({'logprob': [64.46435546875, 18.0]}, 128)
batch 877: ({'logprob': [45.506988525390625, 11.0]}, 128)
batch 878: ({'logprob': [61.998416900634766, 17.0]}, 128)
batch 879: ({'logprob': [73.35260009765625, 21.0]}, 128)
batch 880: ({'logprob': [50.85548782348633, 13.0]}, 128)
batch 881: ({'logprob': [28.777467727661133, 5.0]}, 128)
batch 882: ({'logprob': [54.20042419433594, 14.0]}, 128)
batch 883: ({'logprob': [61.979881286621094, 17.0]}, 128)
batch 884: ({'logprob': [51.06441879272461, 13.0]}, 128)
batch 885: ({'logprob': [51.51542663574219, 13.0]}, 128)
batch 886: ({'logprob': [62.21806716918945, 17.0]}, 128)

======================Test output======================
logprob:  0.415757, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.968049e-03 [3.094432e-09] 
Layer 'conv1' biases: 1.793128e-07 [1.051164e-10] 
Layer 'conv2' weights[0]: 7.955053e-03 [2.689735e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.472421e-10] 
Layer 'conv3' weights[0]: 7.953399e-03 [2.724248e-09] 
Layer 'conv3' biases: 1.552165e-06 [1.701759e-09] 
Layer 'conv4' weights[0]: 7.985978e-03 [2.975765e-09] 
Layer 'conv4' biases: 9.999996e-01 [1.641005e-08] 
Layer 'conv5' weights[0]: 7.984808e-03 [1.097869e-07] 
Layer 'conv5' biases: 9.999962e-01 [1.187158e-07] 
Layer 'fc6' weights[0]: 7.581582e-03 [9.348956e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.395051e-09] 
Layer 'fc7' weights[0]: 7.287703e-03 [2.915145e-07] 
Layer 'fc7' biases: 9.998634e-01 [2.804465e-07] 
Layer 'fc8' weights[0]: 1.312924e-03 [1.072837e-05] 
Layer 'fc8' biases: 4.175367e-02 [7.232500e-05] 
Train error last 870 batches: 0.435251
-------------------------------------------------------
Not saving because 0.415757 > 0.415685 (17.630: -0.01%)
======================================================= (12.042 sec)
18.11... logprob:  0.334562, 0.078125 (1.455 sec)
18.12... logprob:  0.466524, 0.125000 (1.401 sec)
18.13... logprob:  0.442378, 0.117188 (1.426 sec)
18.14... logprob:  0.444775, 0.117188 (1.403 sec)
18.15... logprob:  0.395639, 0.101562 (1.414 sec)
18.16... logprob:  0.421459, 0.109375 (1.407 sec)
18.17... logprob:  0.516094, 0.140625 (1.392 sec)
18.18... logprob:  0.262108, 0.054688 (1.400 sec)
18.19... logprob:  0.279618, 0.062500 (1.402 sec)
18.20... logprob:  0.421379, 0.109375 (1.406 sec)
18.21... logprob:  0.443953, 0.117188 (0.892 sec)
18.22... logprob:  0.536584, 0.148438 (1.330 sec)
18.23... logprob:  0.532811, 0.148438 (1.425 sec)
18.24... logprob:  0.310760, 0.070312 (0.990 sec)
18.25... logprob:  0.356316, 0.085938 (0.961 sec)
18.26... logprob:  0.463676, 0.125000 (1.450 sec)
18.27... logprob:  0.404604, 0.101562 (1.387 sec)
18.28... logprob:  0.421873, 0.109375 (1.408 sec)
18.29... logprob:  0.396052, 0.101562 (1.427 sec)
18.30... logprob:  0.374177, 0.093750 (1.415 sec)
18.31... logprob:  0.479909, 0.132812 (1.406 sec)
18.32... logprob:  0.457234, 0.125000 (1.398 sec)
18.33... logprob:  0.460679, 0.125000 (1.445 sec)
18.34... logprob:  0.464620, 0.125000 (1.392 sec)
18.35... logprob:  0.316208, 0.070312 (1.402 sec)
18.36... logprob:  0.475803, 0.132812 (1.406 sec)
18.37... logprob:  0.417597, 0.109375 (1.409 sec)
18.38... logprob:  0.392535, 0.101562 (1.399 sec)
18.39... logprob:  0.631856, 0.187500 (1.435 sec)
18.40... logprob:  0.445819, 0.117188 (1.413 sec)
18.41... logprob:  0.352798, 0.085938 (1.430 sec)
18.42... logprob:  0.391868, 0.101562 (1.414 sec)
18.43... logprob:  0.440114, 0.117188 (1.414 sec)
18.44... logprob:  0.518517, 0.148438 (1.435 sec)
18.45... logprob:  0.381773, 0.093750 (1.394 sec)
18.46... logprob:  0.486340, 0.132812 (1.396 sec)
18.47... logprob:  0.331758, 0.078125 (1.397 sec)
18.48... logprob:  0.498887, 0.140625 (1.426 sec)
18.49... logprob:  0.510682, 0.148438 (1.412 sec)
18.50... logprob:  0.393238, 0.101562 (1.431 sec)
18.51... logprob:  0.490052, 0.140625 (1.418 sec)
18.52... logprob:  0.525780, 0.148438 (1.396 sec)
18.53... logprob:  0.295006, 0.062500 (1.452 sec)
18.54... logprob:  0.403278, 0.109375 (1.387 sec)
18.55... logprob:  0.331779, 0.078125 (1.403 sec)
18.56... logprob:  0.421696, 0.109375 (1.401 sec)
18.57... logprob:  0.572505, 0.164062 (1.434 sec)
18.58... logprob:  0.407729, 0.101562 (1.403 sec)
18.59... logprob:  0.333856, 0.078125 (1.469 sec)
18.60... logprob:  0.618985, 0.179688 (1.423 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.35077667236328, 10.0]}, 128)
batch 872: ({'logprob': [66.44242095947266, 19.0]}, 128)
batch 873: ({'logprob': [40.86566925048828, 9.0]}, 128)
batch 874: ({'logprob': [45.177791595458984, 11.0]}, 128)
batch 875: ({'logprob': [50.814292907714844, 13.0]}, 128)
batch 876: ({'logprob': [63.972164154052734, 18.0]}, 128)
batch 877: ({'logprob': [45.84610366821289, 11.0]}, 128)
batch 878: ({'logprob': [62.126800537109375, 17.0]}, 128)
batch 879: ({'logprob': [74.06803131103516, 21.0]}, 128)
batch 880: ({'logprob': [50.83183288574219, 13.0]}, 128)
batch 881: ({'logprob': [28.8907470703125, 5.0]}, 128)
batch 882: ({'logprob': [55.31011962890625, 14.0]}, 128)
batch 883: ({'logprob': [62.1088981628418, 17.0]}, 128)
batch 884: ({'logprob': [51.47935104370117, 13.0]}, 128)
batch 885: ({'logprob': [52.80652618408203, 13.0]}, 128)
batch 886: ({'logprob': [62.78416442871094, 17.0]}, 128)

======================Test output======================
logprob:  0.417420, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.968001e-03 [3.874405e-09] 
Layer 'conv1' biases: 1.801658e-07 [1.227704e-10] 
Layer 'conv2' weights[0]: 7.955020e-03 [3.051599e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.597767e-10] 
Layer 'conv3' weights[0]: 7.953361e-03 [3.178440e-09] 
Layer 'conv3' biases: 1.559969e-06 [2.078555e-09] 
Layer 'conv4' weights[0]: 7.985940e-03 [3.341887e-09] 
Layer 'conv4' biases: 9.999996e-01 [1.934281e-08] 
Layer 'conv5' weights[0]: 7.984760e-03 [1.302202e-07] 
Layer 'conv5' biases: 9.999965e-01 [1.408376e-07] 
Layer 'fc6' weights[0]: 7.581545e-03 [1.096196e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.120019e-08] 
Layer 'fc7' weights[0]: 7.285811e-03 [1.010250e-07] 
Layer 'fc7' biases: 9.998637e-01 [8.723236e-08] 
Layer 'fc8' weights[0]: 1.314879e-03 [2.878028e-06] 
Layer 'fc8' biases: 4.180992e-02 [1.708504e-05] 
Train error last 870 batches: 0.435251
-------------------------------------------------------
Not saving because 0.417420 > 0.415685 (17.630: -0.01%)
======================================================= (12.024 sec)
18.61... logprob:  0.382854, 0.093750 (1.443 sec)
18.62... logprob:  0.474894, 0.132812 (1.466 sec)
18.63... logprob:  0.397306, 0.101562 (1.442 sec)
18.64... logprob:  0.450278, 0.125000 (1.412 sec)
18.65... logprob:  0.373330, 0.093750 (1.419 sec)
18.66... logprob:  0.354010, 0.085938 (1.453 sec)
18.67... logprob:  0.295391, 0.062500 (1.393 sec)
18.68... logprob:  0.396816, 0.101562 (1.396 sec)
18.69... logprob:  0.496805, 0.140625 (1.426 sec)
18.70... logprob:  0.325880, 0.078125 (1.434 sec)
18.71... logprob:  0.381832, 0.101562 (1.465 sec)
18.72... logprob:  0.493820, 0.132812 (1.409 sec)
18.73... logprob:  0.447760, 0.117188 (1.427 sec)
18.74... logprob:  0.442579, 0.117188 (1.422 sec)
18.75... logprob:  0.380644, 0.093750 (1.415 sec)
18.76... logprob:  0.412079, 0.109375 (1.439 sec)
18.77... logprob:  0.396343, 0.101562 (1.432 sec)
18.78... logprob:  0.493065, 0.140625 (1.455 sec)
18.79... logprob:  0.456446, 0.125000 (1.408 sec)
18.80... logprob:  0.507903, 0.132812 (1.422 sec)
18.81... logprob:  0.416724, 0.109375 (1.417 sec)
18.82... logprob:  0.231711, 0.039062 (1.428 sec)
18.83... logprob:  0.493737, 0.140625 (1.406 sec)
18.84... logprob:  0.468092, 0.125000 (1.470 sec)
18.85... logprob:  0.432014, 0.117188 (1.425 sec)
18.86... logprob:  0.416980, 0.109375 (1.422 sec)
18.87... logprob:  0.633205, 0.187500 (1.413 sec)
18.88... logprob:  0.535087, 0.156250 (1.412 sec)
18.89... logprob:  0.410616, 0.109375 (1.438 sec)
18.90... logprob:  0.577505, 0.171875 (1.390 sec)
18.91... logprob:  0.348528, 0.078125 (1.399 sec)
18.92... logprob:  0.464462, 0.125000 (1.401 sec)
18.93... logprob:  0.492269, 0.140625 (1.402 sec)
18.94... logprob:  0.428783, 0.109375 (1.396 sec)
18.95... logprob:  0.471853, 0.125000 (1.406 sec)
18.96... logprob:  0.576326, 0.171875 (1.409 sec)
18.97... logprob:  0.430760, 0.117188 (1.391 sec)
18.98... logprob:  0.391055, 0.093750 (1.441 sec)
18.99... logprob:  0.474299, 0.132812 (1.409 sec)
18.100... logprob:  0.310399, 0.070312 (1.403 sec)
18.101... logprob:  0.310588, 0.062500 (1.441 sec)
18.102... logprob:  0.546294, 0.156250 (1.393 sec)
18.103... logprob:  0.541279, 0.156250 (1.403 sec)
18.104... logprob:  0.388861, 0.101562 (1.401 sec)
18.105... logprob:  0.619728, 0.179688 (1.396 sec)
18.106... logprob:  0.344435, 0.085938 (1.395 sec)
18.107... logprob:  0.335714, 0.078125 (1.457 sec)
18.108... logprob:  0.586820, 0.171875 (1.396 sec)
18.109... logprob:  0.336193, 0.078125 (1.405 sec)
18.110... logprob:  0.564466, 0.164062 (1.397 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.72999572753906, 10.0]}, 128)
batch 872: ({'logprob': [66.46387481689453, 19.0]}, 128)
batch 873: ({'logprob': [40.704551696777344, 9.0]}, 128)
batch 874: ({'logprob': [45.25536346435547, 11.0]}, 128)
batch 875: ({'logprob': [50.793216705322266, 13.0]}, 128)
batch 876: ({'logprob': [63.95896530151367, 18.0]}, 128)
batch 877: ({'logprob': [45.75555419921875, 11.0]}, 128)
batch 878: ({'logprob': [61.90985107421875, 17.0]}, 128)
batch 879: ({'logprob': [73.48735809326172, 21.0]}, 128)
batch 880: ({'logprob': [50.81137466430664, 13.0]}, 128)
batch 881: ({'logprob': [29.09412956237793, 5.0]}, 128)
batch 882: ({'logprob': [54.81946563720703, 14.0]}, 128)
batch 883: ({'logprob': [61.891658782958984, 17.0]}, 128)
batch 884: ({'logprob': [51.29008102416992, 13.0]}, 128)
batch 885: ({'logprob': [52.28047561645508, 13.0]}, 128)
batch 886: ({'logprob': [62.39875411987305, 17.0]}, 128)

======================Test output======================
logprob:  0.416330, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.967963e-03 [3.464841e-09] 
Layer 'conv1' biases: 1.809588e-07 [1.051777e-10] 
Layer 'conv2' weights[0]: 7.954985e-03 [3.359578e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.889186e-10] 
Layer 'conv3' weights[0]: 7.953317e-03 [3.125981e-09] 
Layer 'conv3' biases: 1.566811e-06 [1.846989e-09] 
Layer 'conv4' weights[0]: 7.985900e-03 [3.330907e-09] 
Layer 'conv4' biases: 9.999996e-01 [1.673600e-08] 
Layer 'conv5' weights[0]: 7.984722e-03 [1.108471e-07] 
Layer 'conv5' biases: 9.999966e-01 [1.194903e-07] 
Layer 'fc6' weights[0]: 7.581504e-03 [9.484000e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.533471e-09] 
Layer 'fc7' weights[0]: 7.283967e-03 [1.781995e-07] 
Layer 'fc7' biases: 9.998634e-01 [1.673917e-07] 
Layer 'fc8' weights[0]: 1.309136e-03 [6.824352e-06] 
Layer 'fc8' biases: 4.187921e-02 [4.114589e-05] 
Train error last 870 batches: 0.435250
-------------------------------------------------------
Not saving because 0.416330 > 0.415685 (17.630: -0.01%)
======================================================= (12.063 sec)
18.111... logprob:  0.404724, 0.101562 (1.402 sec)
18.112... logprob:  0.366160, 0.093750 (1.412 sec)
18.113... logprob:  0.354640, 0.085938 (1.403 sec)
18.114... logprob:  0.440229, 0.117188 (1.434 sec)
18.115... logprob:  0.506730, 0.140625 (1.413 sec)
18.116... logprob:  0.393400, 0.101562 (1.404 sec)
18.117... logprob:  0.440395, 0.117188 (1.443 sec)
18.118... logprob:  0.409159, 0.101562 (1.395 sec)
18.119... logprob:  0.346129, 0.085938 (1.403 sec)
18.120... logprob:  0.547147, 0.156250 (1.403 sec)
18.121... logprob:  0.412665, 0.109375 (1.396 sec)
18.122... logprob:  0.519348, 0.148438 (1.447 sec)
18.123... logprob:  0.463737, 0.125000 (1.393 sec)
18.124... logprob:  0.447709, 0.125000 (1.547 sec)
18.125... logprob:  0.501994, 0.140625 (1.399 sec)
18.126... logprob:  0.475797, 0.125000 (1.396 sec)
18.127... logprob:  0.479610, 0.125000 (1.399 sec)
18.128... logprob:  0.422372, 0.109375 (1.420 sec)
18.129... logprob:  0.574894, 0.164062 (1.419 sec)
18.130... logprob:  0.382745, 0.093750 (1.414 sec)
18.131... logprob:  0.495500, 0.132812 (1.414 sec)
18.132... logprob:  0.506380, 0.140625 (1.433 sec)
18.133... logprob:  0.444683, 0.117188 (1.392 sec)
18.134... logprob:  0.401908, 0.101562 (1.397 sec)
18.135... logprob:  0.460232, 0.125000 (1.403 sec)
18.136... logprob:  0.562541, 0.164062 (1.401 sec)
18.137... logprob:  0.462570, 0.125000 (1.389 sec)
18.138... logprob:  0.319346, 0.070312 (1.451 sec)
18.139... logprob:  0.395778, 0.101562 (1.404 sec)
18.140... logprob:  0.560434, 0.164062 (1.414 sec)
18.141... logprob:  0.464544, 0.125000 (1.450 sec)
18.142... logprob:  0.464613, 0.125000 (1.398 sec)
18.143... logprob:  0.294284, 0.062500 (1.427 sec)
18.144... logprob:  0.457263, 0.125000 (1.417 sec)
18.145... logprob:  0.324849, 0.078125 (1.417 sec)
18.146... logprob:  0.483214, 0.132812 (1.416 sec)
18.147... logprob:  0.262471, 0.054688 (1.439 sec)
18.148... logprob:  0.458794, 0.125000 (1.395 sec)
18.149... logprob:  0.442554, 0.117188 (1.393 sec)
18.150... logprob:  0.347620, 0.085938 (1.406 sec)
18.151... logprob:  0.347152, 0.085938 (1.396 sec)
18.152... logprob:  0.785028, 0.234375 (1.396 sec)
18.153... logprob:  0.381663, 0.093750 (1.446 sec)
18.154... logprob:  0.524431, 0.148438 (1.401 sec)
18.155... logprob:  0.425999, 0.117188 (1.408 sec)
18.156... logprob:  0.295790, 0.062500 (1.438 sec)
18.157... logprob:  0.270704, 0.054688 (1.395 sec)
18.158... logprob:  0.455378, 0.125000 (1.405 sec)
18.159... logprob:  0.483115, 0.132812 (1.399 sec)
18.160... logprob:  0.444856, 0.117188 (1.397 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.9158935546875, 10.0]}, 128)
batch 872: ({'logprob': [66.1187744140625, 19.0]}, 128)
batch 873: ({'logprob': [41.23756790161133, 9.0]}, 128)
batch 874: ({'logprob': [45.51211929321289, 11.0]}, 128)
batch 875: ({'logprob': [50.942100524902344, 13.0]}, 128)
batch 876: ({'logprob': [63.709564208984375, 18.0]}, 128)
batch 877: ({'logprob': [46.09659194946289, 11.0]}, 128)
batch 878: ({'logprob': [61.84093475341797, 17.0]}, 128)
batch 879: ({'logprob': [73.28408813476562, 21.0]}, 128)
batch 880: ({'logprob': [50.95978927612305, 13.0]}, 128)
batch 881: ({'logprob': [29.761516571044922, 5.0]}, 128)
batch 882: ({'logprob': [55.12214660644531, 14.0]}, 128)
batch 883: ({'logprob': [61.82286071777344, 17.0]}, 128)
batch 884: ({'logprob': [51.521461486816406, 13.0]}, 128)
batch 885: ({'logprob': [52.67900466918945, 13.0]}, 128)
batch 886: ({'logprob': [62.41295623779297, 17.0]}, 128)

======================Test output======================
logprob:  0.417450, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.967926e-03 [2.035278e-09] 
Layer 'conv1' biases: 1.817464e-07 [3.598873e-11] 
Layer 'conv2' weights[0]: 7.954950e-03 [1.520896e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.322006e-10] 
Layer 'conv3' weights[0]: 7.953271e-03 [1.189524e-09] 
Layer 'conv3' biases: 1.574051e-06 [3.755975e-10] 
Layer 'conv4' weights[0]: 7.985862e-03 [1.126119e-09] 
Layer 'conv4' biases: 9.999996e-01 [1.696299e-09] 
Layer 'conv5' weights[0]: 7.984678e-03 [7.760407e-09] 
Layer 'conv5' biases: 9.999965e-01 [7.857858e-09] 
Layer 'fc6' weights[0]: 7.581466e-03 [1.008428e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.335492e-10] 
Layer 'fc7' weights[0]: 7.282112e-03 [4.258983e-08] 
Layer 'fc7' biases: 9.998632e-01 [1.775260e-08] 
Layer 'fc8' weights[0]: 1.301385e-03 [4.437055e-06] 
Layer 'fc8' biases: 4.191406e-02 [2.605437e-05] 
Train error last 870 batches: 0.435250
-------------------------------------------------------
Not saving because 0.417450 > 0.415685 (17.630: -0.01%)
======================================================= (12.154 sec)
18.161... logprob:  0.350083, 0.078125 (1.405 sec)
18.162... logprob:  0.611793, 0.179688 (1.414 sec)
18.163... logprob:  0.450434, 0.125000 (1.430 sec)
18.164... logprob:  0.468663, 0.125000 (1.422 sec)
18.165... logprob:  0.547926, 0.156250 (1.426 sec)
18.166... logprob:  0.446073, 0.125000 (1.450 sec)
18.167... logprob:  0.350441, 0.085938 (1.438 sec)
18.168... logprob:  0.363683, 0.085938 (1.423 sec)
18.169... logprob:  0.408674, 0.101562 (1.463 sec)
18.170... logprob:  0.459489, 0.125000 (1.400 sec)
18.171... logprob:  0.535432, 0.156250 (1.429 sec)
18.172... logprob:  0.434861, 0.109375 (1.423 sec)
18.173... logprob:  0.440493, 0.117188 (1.420 sec)
18.174... logprob:  0.601085, 0.171875 (1.424 sec)
18.175... logprob:  0.506092, 0.140625 (1.464 sec)
18.176... logprob:  0.478477, 0.132812 (1.423 sec)
18.177... logprob:  0.289761, 0.054688 (1.427 sec)
18.178... logprob:  0.383486, 0.093750 (1.462 sec)
18.179... logprob:  0.394716, 0.101562 (1.406 sec)
18.180... logprob:  0.466383, 0.125000 (1.426 sec)
18.181... logprob:  0.539382, 0.156250 (1.421 sec)
18.182... logprob:  0.371384, 0.093750 (1.419 sec)
18.183... logprob:  0.419955, 0.109375 (1.430 sec)
18.184... logprob:  0.483468, 0.132812 (1.418 sec)
18.185... logprob:  0.289853, 0.062500 (1.403 sec)
18.186... logprob:  0.370484, 0.093750 (1.394 sec)
18.187... logprob:  0.529626, 0.148438 (1.407 sec)
18.188... logprob:  0.458968, 0.125000 (1.405 sec)
18.189... logprob:  0.440908, 0.117188 (1.391 sec)
18.190... logprob:  0.375752, 0.093750 (1.437 sec)
18.191... logprob:  0.485098, 0.132812 (1.413 sec)
18.192... logprob:  0.520142, 0.148438 (1.418 sec)
18.193... logprob:  0.312600, 0.070312 (1.420 sec)
18.194... logprob:  0.414103, 0.109375 (1.422 sec)
18.195... logprob:  0.287198, 0.062500 (1.399 sec)
18.196... logprob:  0.410537, 0.109375 (1.395 sec)
18.197... logprob:  0.478020, 0.132812 (1.398 sec)
18.198... logprob:  0.355794, 0.085938 (1.409 sec)
18.199... logprob:  0.437193, 0.117188 (1.387 sec)
18.200... logprob:  0.440766, 0.117188 (1.528 sec)
18.201... logprob:  0.437097, 0.117188 (1.408 sec)
18.202... logprob:  0.537947, 0.148438 (1.410 sec)
18.203... logprob:  0.420449, 0.109375 (1.442 sec)
18.204... logprob:  0.504125, 0.140625 (1.388 sec)
18.205... logprob:  0.334371, 0.078125 (1.406 sec)
18.206... logprob:  0.361632, 0.093750 (1.401 sec)
18.207... logprob:  0.381876, 0.093750 (1.395 sec)
18.208... logprob:  0.490532, 0.140625 (1.397 sec)
18.209... logprob:  0.334586, 0.078125 (1.424 sec)
18.210... logprob:  0.586244, 0.171875 (1.413 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.6909065246582, 10.0]}, 128)
batch 872: ({'logprob': [66.3251953125, 19.0]}, 128)
batch 873: ({'logprob': [40.906410217285156, 9.0]}, 128)
batch 874: ({'logprob': [45.30888366699219, 11.0]}, 128)
batch 875: ({'logprob': [50.83231735229492, 13.0]}, 128)
batch 876: ({'logprob': [63.860992431640625, 18.0]}, 128)
batch 877: ({'logprob': [45.87605285644531, 11.0]}, 128)
batch 878: ({'logprob': [61.91950988769531, 17.0]}, 128)
batch 879: ({'logprob': [73.53363037109375, 21.0]}, 128)
batch 880: ({'logprob': [50.8504524230957, 13.0]}, 128)
batch 881: ({'logprob': [29.258922576904297, 5.0]}, 128)
batch 882: ({'logprob': [55.01775360107422, 14.0]}, 128)
batch 883: ({'logprob': [61.90113830566406, 17.0]}, 128)
batch 884: ({'logprob': [51.39559555053711, 13.0]}, 128)
batch 885: ({'logprob': [52.5192985534668, 13.0]}, 128)
batch 886: ({'logprob': [62.4749641418457, 17.0]}, 128)

======================Test output======================
logprob:  0.416832, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.967891e-03 [2.839364e-09] 
Layer 'conv1' biases: 1.826252e-07 [1.187184e-10] 
Layer 'conv2' weights[0]: 7.954911e-03 [2.150070e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.173789e-10] 
Layer 'conv3' weights[0]: 7.953228e-03 [2.304204e-09] 
Layer 'conv3' biases: 1.581552e-06 [1.514648e-09] 
Layer 'conv4' weights[0]: 7.985819e-03 [2.311928e-09] 
Layer 'conv4' biases: 9.999996e-01 [1.314765e-08] 
Layer 'conv5' weights[0]: 7.984638e-03 [8.665763e-08] 
Layer 'conv5' biases: 9.999966e-01 [9.345528e-08] 
Layer 'fc6' weights[0]: 7.581429e-03 [7.327683e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.440963e-09] 
Layer 'fc7' weights[0]: 7.280226e-03 [8.048440e-08] 
Layer 'fc7' biases: 9.998632e-01 [6.513719e-08] 
Layer 'fc8' weights[0]: 1.314334e-03 [4.707163e-06] 
Layer 'fc8' biases: 4.207877e-02 [2.989289e-05] 
Train error last 870 batches: 0.435250
-------------------------------------------------------
Not saving because 0.416832 > 0.415685 (17.630: -0.01%)
======================================================= (12.040 sec)
18.211... logprob:  0.488180, 0.132812 (1.423 sec)
18.212... logprob:  0.526146, 0.148438 (1.424 sec)
18.213... logprob:  0.514769, 0.140625 (1.463 sec)
18.214... logprob:  0.459430, 0.125000 (1.425 sec)
18.215... logprob:  0.396140, 0.101562 (1.430 sec)
18.216... logprob:  0.517072, 0.140625 (1.465 sec)
18.217... logprob:  0.325059, 0.070312 (1.408 sec)
18.218... logprob:  0.463678, 0.125000 (1.419 sec)
18.219... logprob:  0.500292, 0.140625 (1.423 sec)
18.220... logprob:  0.415004, 0.109375 (1.422 sec)
18.221... logprob:  0.399547, 0.101562 (1.408 sec)
18.222... logprob:  0.554546, 0.164062 (1.459 sec)
18.223... logprob:  0.569177, 0.164062 (1.438 sec)
18.224... logprob:  0.405894, 0.101562 (1.432 sec)
18.225... logprob:  0.391975, 0.101562 (1.448 sec)
18.226... logprob:  0.424656, 0.109375 (1.425 sec)
18.227... logprob:  0.452711, 0.125000 (1.413 sec)
18.228... logprob:  0.417191, 0.109375 (1.418 sec)
18.229... logprob:  0.489371, 0.132812 (1.420 sec)
18.230... logprob:  0.459888, 0.125000 (1.425 sec)
18.231... logprob:  0.453533, 0.125000 (1.405 sec)
18.232... logprob:  0.496215, 0.140625 (1.464 sec)
18.233... logprob:  0.466144, 0.132812 (1.423 sec)
18.234... logprob:  0.563814, 0.164062 (1.431 sec)
18.235... logprob:  0.482027, 0.132812 (1.469 sec)
18.236... logprob:  0.425768, 0.109375 (1.401 sec)
18.237... logprob:  0.341251, 0.078125 (1.423 sec)
18.238... logprob:  0.389326, 0.093750 (1.422 sec)
18.239... logprob:  0.478131, 0.132812 (1.419 sec)
18.240... logprob:  0.485804, 0.132812 (1.407 sec)
18.241... logprob:  0.493604, 0.132812 (1.458 sec)
18.242... logprob:  0.341651, 0.078125 (1.424 sec)
18.243... logprob:  0.386015, 0.093750 (1.436 sec)
18.244... logprob:  0.315267, 0.070312 (1.448 sec)
18.245... logprob:  0.494322, 0.132812 (1.425 sec)
18.246... logprob:  0.416894, 0.109375 (1.416 sec)
18.247... logprob:  0.357402, 0.085938 (1.413 sec)
18.248... logprob:  0.307813, 0.070312 (1.423 sec)
18.249... logprob:  0.555259, 0.156250 (1.427 sec)
18.250... logprob:  0.591634, 0.164062 (1.417 sec)
18.251... logprob:  0.352928, 0.085938 (1.474 sec)
18.252... logprob:  0.348476, 0.085938 (1.430 sec)
18.253... logprob:  0.379185, 0.093750 (1.422 sec)
18.254... logprob:  0.444177, 0.117188 (1.466 sec)
18.255... logprob:  0.351454, 0.085938 (1.405 sec)
18.256... logprob:  0.378771, 0.093750 (1.427 sec)
18.257... logprob:  0.332031, 0.078125 (1.415 sec)
18.258... logprob:  0.415712, 0.109375 (1.422 sec)
18.259... logprob:  0.442311, 0.117188 (1.400 sec)
18.260... logprob:  0.308349, 0.070312 (1.464 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.85383224487305, 10.0]}, 128)
batch 872: ({'logprob': [67.85307312011719, 19.0]}, 128)
batch 873: ({'logprob': [39.618988037109375, 9.0]}, 128)
batch 874: ({'logprob': [45.03769302368164, 11.0]}, 128)
batch 875: ({'logprob': [50.81981658935547, 13.0]}, 128)
batch 876: ({'logprob': [65.07159423828125, 18.0]}, 128)
batch 877: ({'logprob': [45.22634506225586, 11.0]}, 128)
batch 878: ({'logprob': [62.43159866333008, 17.0]}, 128)
batch 879: ({'logprob': [74.19366455078125, 21.0]}, 128)
batch 880: ({'logprob': [50.840084075927734, 13.0]}, 128)
batch 881: ({'logprob': [27.823585510253906, 5.0]}, 128)
batch 882: ({'logprob': [54.19655227661133, 14.0]}, 128)
batch 883: ({'logprob': [62.412315368652344, 17.0]}, 128)
batch 884: ({'logprob': [51.00947952270508, 13.0]}, 128)
batch 885: ({'logprob': [51.379295349121094, 13.0]}, 128)
batch 886: ({'logprob': [62.61144256591797, 17.0]}, 128)

======================Test output======================
logprob:  0.416201, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.967846e-03 [2.043255e-09] 
Layer 'conv1' biases: 1.834850e-07 [6.022088e-11] 
Layer 'conv2' weights[0]: 7.954865e-03 [1.742305e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.715367e-10] 
Layer 'conv3' weights[0]: 7.953188e-03 [1.685823e-09] 
Layer 'conv3' biases: 1.587145e-06 [8.516281e-10] 
Layer 'conv4' weights[0]: 7.985782e-03 [1.852297e-09] 
Layer 'conv4' biases: 9.999995e-01 [8.268412e-09] 
Layer 'conv5' weights[0]: 7.984615e-03 [5.556953e-08] 
Layer 'conv5' biases: 9.999965e-01 [6.002796e-08] 
Layer 'fc6' weights[0]: 7.581386e-03 [4.810589e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.773361e-09] 
Layer 'fc7' weights[0]: 7.278395e-03 [7.662338e-08] 
Layer 'fc7' biases: 9.998635e-01 [6.019653e-08] 
Layer 'fc8' weights[0]: 1.346444e-03 [2.509229e-06] 
Layer 'fc8' biases: 4.240115e-02 [1.714245e-05] 
Train error last 870 batches: 0.435249
-------------------------------------------------------
Not saving because 0.416201 > 0.415685 (17.630: -0.01%)
======================================================= (12.057 sec)
18.261... logprob:  0.392755, 0.101562 (1.443 sec)
18.262... logprob:  0.524634, 0.148438 (1.443 sec)
18.263... logprob:  0.425501, 0.109375 (1.451 sec)
18.264... logprob:  0.375126, 0.093750 (1.426 sec)
18.265... logprob:  0.439614, 0.117188 (1.416 sec)
18.266... logprob:  0.439030, 0.117188 (1.416 sec)
18.267... logprob:  0.422010, 0.109375 (1.419 sec)
18.268... logprob:  0.458942, 0.125000 (1.424 sec)
18.269... logprob:  0.567489, 0.164062 (1.409 sec)
18.270... logprob:  0.542235, 0.156250 (1.462 sec)
18.271... logprob:  0.445716, 0.117188 (1.435 sec)
18.272... logprob:  0.384720, 0.093750 (1.424 sec)
18.273... logprob:  0.500220, 0.140625 (1.472 sec)
18.274... logprob:  0.542522, 0.156250 (1.398 sec)
18.275... logprob:  0.487697, 0.132812 (1.428 sec)
18.276... logprob:  0.390141, 0.093750 (1.414 sec)
18.277... logprob:  0.428695, 0.109375 (1.423 sec)
18.278... logprob:  0.323445, 0.070312 (1.427 sec)
18.279... logprob:  0.325034, 0.070312 (1.464 sec)
18.280... logprob:  0.215342, 0.031250 (1.404 sec)
18.281... logprob:  0.417221, 0.109375 (1.428 sec)
18.282... logprob:  0.411431, 0.109375 (1.416 sec)
18.283... logprob:  0.393831, 0.101562 (1.447 sec)
18.284... logprob:  0.394628, 0.101562 (1.409 sec)
18.285... logprob:  0.452003, 0.117188 (1.444 sec)
18.286... logprob:  0.537249, 0.140625 (1.434 sec)
18.287... logprob:  0.346645, 0.085938 (1.440 sec)
18.288... logprob:  0.329970, 0.078125 (1.433 sec)
18.289... logprob:  0.445978, 0.117188 (1.442 sec)
18.290... logprob:  0.490656, 0.132812 (1.409 sec)
18.291... logprob:  0.439191, 0.117188 (1.426 sec)
18.292... logprob:  0.567177, 0.156250 (1.423 sec)
18.293... logprob:  0.427546, 0.117188 (1.427 sec)
18.294... logprob:  0.356095, 0.085938 (1.403 sec)
18.295... logprob:  0.334960, 0.078125 (1.465 sec)
18.296... logprob:  0.356051, 0.085938 (1.420 sec)
18.297... logprob:  0.394712, 0.101562 (1.425 sec)
18.298... logprob:  0.448137, 0.125000 (1.466 sec)
18.299... logprob:  0.342495, 0.078125 (1.410 sec)
18.300... logprob:  0.406621, 0.101562 (1.426 sec)
18.301... logprob:  0.397950, 0.101562 (1.416 sec)
18.302... logprob:  0.591553, 0.179688 (1.423 sec)
18.303... logprob:  0.459603, 0.125000 (1.408 sec)
18.304... logprob:  0.459689, 0.125000 (1.442 sec)
18.305... logprob:  0.455230, 0.125000 (1.437 sec)
18.306... logprob:  0.440603, 0.117188 (1.440 sec)
18.307... logprob:  0.421605, 0.109375 (1.441 sec)
18.308... logprob:  0.374615, 0.093750 (1.456 sec)
18.309... logprob:  0.450488, 0.125000 (1.415 sec)
18.310... logprob:  0.473723, 0.125000 (1.429 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.768680572509766, 10.0]}, 128)
batch 872: ({'logprob': [66.18753814697266, 19.0]}, 128)
batch 873: ({'logprob': [41.129451751708984, 9.0]}, 128)
batch 874: ({'logprob': [45.41737747192383, 11.0]}, 128)
batch 875: ({'logprob': [50.89723587036133, 13.0]}, 128)
batch 876: ({'logprob': [63.76256561279297, 18.0]}, 128)
batch 877: ({'logprob': [46.01999282836914, 11.0]}, 128)
batch 878: ({'logprob': [61.89626693725586, 17.0]}, 128)
batch 879: ({'logprob': [73.45759582519531, 21.0]}, 128)
batch 880: ({'logprob': [50.915069580078125, 13.0]}, 128)
batch 881: ({'logprob': [29.534948348999023, 5.0]}, 128)
batch 882: ({'logprob': [55.14836883544922, 14.0]}, 128)
batch 883: ({'logprob': [61.87807846069336, 17.0]}, 128)
batch 884: ({'logprob': [51.49531173706055, 13.0]}, 128)
batch 885: ({'logprob': [52.68938446044922, 13.0]}, 128)
batch 886: ({'logprob': [62.48677062988281, 17.0]}, 128)

======================Test output======================
logprob:  0.417326, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.967810e-03 [2.279425e-09] 
Layer 'conv1' biases: 1.844828e-07 [4.041413e-11] 
Layer 'conv2' weights[0]: 7.954834e-03 [1.392413e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.308158e-10] 
Layer 'conv3' weights[0]: 7.953154e-03 [1.129438e-09] 
Layer 'conv3' biases: 1.595241e-06 [3.980080e-10] 
Layer 'conv4' weights[0]: 7.985741e-03 [1.107763e-09] 
Layer 'conv4' biases: 9.999996e-01 [2.514854e-09] 
Layer 'conv5' weights[0]: 7.984575e-03 [1.495520e-08] 
Layer 'conv5' biases: 9.999964e-01 [1.583854e-08] 
Layer 'fc6' weights[0]: 7.581353e-03 [1.476960e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.263329e-09] 
Layer 'fc7' weights[0]: 7.276472e-03 [4.282804e-08] 
Layer 'fc7' biases: 9.998631e-01 [1.847609e-08] 
Layer 'fc8' weights[0]: 1.308538e-03 [7.178945e-07] 
Layer 'fc8' biases: 4.241535e-02 [7.402231e-06] 
Train error last 870 batches: 0.435249
-------------------------------------------------------
Not saving because 0.417326 > 0.415685 (17.630: -0.01%)
======================================================= (12.150 sec)
18.311... logprob:  0.502625, 0.140625 (1.443 sec)
18.312... logprob:  0.478773, 0.132812 (1.443 sec)
18.313... logprob:  0.454869, 0.125000 (1.425 sec)
18.314... logprob:  0.454479, 0.117188 (1.467 sec)
18.315... logprob:  0.314684, 0.070312 (1.436 sec)
18.316... logprob:  0.468566, 0.125000 (1.452 sec)
18.317... logprob:  0.355502, 0.085938 (1.473 sec)
18.318... logprob:  0.455415, 0.125000 (1.417 sec)
18.319... logprob:  0.423202, 0.117188 (1.429 sec)
18.320... logprob:  0.412257, 0.109375 (1.425 sec)
18.321... logprob:  0.348283, 0.085938 (1.425 sec)
18.322... logprob:  0.387506, 0.101562 (1.424 sec)
18.323... logprob:  0.416520, 0.109375 (1.483 sec)
18.324... logprob:  0.498625, 0.140625 (1.431 sec)
18.325... logprob:  0.350681, 0.085938 (1.433 sec)
18.326... logprob:  0.543189, 0.148438 (1.466 sec)
18.327... logprob:  0.554404, 0.164062 (1.423 sec)
18.328... logprob:  0.565037, 0.156250 (1.428 sec)
18.329... logprob:  0.401984, 0.101562 (1.425 sec)
18.330... logprob:  0.388634, 0.101562 (1.424 sec)
18.331... logprob:  0.352485, 0.085938 (1.420 sec)
18.332... logprob:  0.482787, 0.132812 (1.451 sec)
18.333... logprob:  0.339612, 0.085938 (1.441 sec)
18.334... logprob:  0.565141, 0.171875 (1.448 sec)
18.335... logprob:  0.358830, 0.085938 (1.437 sec)
18.336... logprob:  0.444837, 0.125000 (1.458 sec)
18.337... logprob:  0.566462, 0.164062 (1.421 sec)
18.338... logprob:  0.449516, 0.125000 (1.436 sec)
18.339... logprob:  0.488682, 0.132812 (1.430 sec)
18.340... logprob:  0.442074, 0.117188 (1.425 sec)
18.341... logprob:  0.530124, 0.148438 (1.422 sec)
18.342... logprob:  0.429664, 0.109375 (1.464 sec)
18.343... logprob:  0.434780, 0.109375 (1.436 sec)
18.344... logprob:  0.444443, 0.125000 (1.481 sec)
18.345... logprob:  0.488248, 0.132812 (1.443 sec)
18.346... logprob:  0.436236, 0.117188 (1.436 sec)
18.347... logprob:  0.372386, 0.085938 (1.486 sec)
18.348... logprob:  0.398445, 0.101562 (1.434 sec)
18.349... logprob:  0.497826, 0.140625 (1.436 sec)
18.350... logprob:  0.358578, 0.085938 (1.435 sec)
18.351... logprob:  0.508642, 0.140625 (1.434 sec)
18.352... logprob:  0.363652, 0.093750 (1.433 sec)
18.353... logprob:  0.512730, 0.148438 (1.493 sec)
18.354... logprob:  0.675078, 0.203125 (1.430 sec)
18.355... logprob:  0.357478, 0.085938 (1.446 sec)
18.356... logprob:  0.479248, 0.132812 (1.479 sec)
18.357... logprob:  0.346981, 0.085938 (1.437 sec)
18.358... logprob:  0.325978, 0.070312 (1.438 sec)
18.359... logprob:  0.555251, 0.164062 (1.432 sec)
18.360... logprob:  0.444517, 0.117188 (1.426 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.07284164428711, 10.0]}, 128)
batch 872: ({'logprob': [66.1168441772461, 19.0]}, 128)
batch 873: ({'logprob': [41.24223327636719, 9.0]}, 128)
batch 874: ({'logprob': [45.57465744018555, 11.0]}, 128)
batch 875: ({'logprob': [50.96371078491211, 13.0]}, 128)
batch 876: ({'logprob': [63.70354080200195, 18.0]}, 128)
batch 877: ({'logprob': [46.10995864868164, 11.0]}, 128)
batch 878: ({'logprob': [61.781349182128906, 17.0]}, 128)
batch 879: ({'logprob': [73.09376525878906, 21.0]}, 128)
batch 880: ({'logprob': [50.98185729980469, 13.0]}, 128)
batch 881: ({'logprob': [29.897029876708984, 5.0]}, 128)
batch 882: ({'logprob': [55.00028610229492, 14.0]}, 128)
batch 883: ({'logprob': [61.76290512084961, 17.0]}, 128)
batch 884: ({'logprob': [51.493919372558594, 13.0]}, 128)
batch 885: ({'logprob': [52.552650451660156, 13.0]}, 128)
batch 886: ({'logprob': [62.303958892822266, 17.0]}, 128)

======================Test output======================
logprob:  0.417310, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.967769e-03 [3.054001e-09] 
Layer 'conv1' biases: 1.852579e-07 [4.847798e-11] 
Layer 'conv2' weights[0]: 7.954797e-03 [1.886094e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.551347e-10] 
Layer 'conv3' weights[0]: 7.953113e-03 [1.332353e-09] 
Layer 'conv3' biases: 1.601988e-06 [4.264643e-10] 
Layer 'conv4' weights[0]: 7.985701e-03 [1.278965e-09] 
Layer 'conv4' biases: 9.999994e-01 [1.610604e-09] 
Layer 'conv5' weights[0]: 7.984528e-03 [1.078474e-08] 
Layer 'conv5' biases: 9.999967e-01 [1.151450e-08] 
Layer 'fc6' weights[0]: 7.581310e-03 [1.224201e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.187835e-10] 
Layer 'fc7' weights[0]: 7.274635e-03 [6.566071e-08] 
Layer 'fc7' biases: 9.998628e-01 [4.895339e-08] 
Layer 'fc8' weights[0]: 1.302776e-03 [1.617639e-06] 
Layer 'fc8' biases: 4.247688e-02 [9.006966e-06] 
Train error last 870 batches: 0.435249
-------------------------------------------------------
Not saving because 0.417310 > 0.415685 (17.630: -0.01%)
======================================================= (12.137 sec)
18.361... logprob:  0.410773, 0.101562 (1.443 sec)
18.362... logprob:  0.424098, 0.117188 (1.485 sec)
18.363... logprob:  0.486584, 0.132812 (1.439 sec)
18.364... logprob:  0.475554, 0.125000 (1.448 sec)
18.365... logprob:  0.425079, 0.109375 (1.468 sec)
18.366... logprob:  0.409673, 0.109375 (1.441 sec)
18.367... logprob:  0.324984, 0.078125 (1.446 sec)
18.368... logprob:  0.595666, 0.171875 (1.429 sec)
18.369... logprob:  0.381560, 0.093750 (1.430 sec)
18.370... logprob:  0.381188, 0.093750 (1.437 sec)
18.371... logprob:  0.400362, 0.101562 (1.459 sec)
18.372... logprob:  0.537530, 0.156250 (1.461 sec)
18.373... logprob:  0.463822, 0.125000 (1.452 sec)
18.374... logprob:  0.527030, 0.148438 (1.453 sec)
18.375... logprob:  0.393779, 0.101562 (1.463 sec)
18.376... logprob:  0.374309, 0.093750 (1.441 sec)
18.377... logprob:  0.295388, 0.062500 (1.430 sec)
18.378... logprob:  0.453749, 0.125000 (1.428 sec)
18.379... logprob:  0.420239, 0.109375 (1.444 sec)
18.380... logprob:  0.605743, 0.179688 (1.436 sec)
18.381... logprob:  0.463470, 0.125000 (1.469 sec)
18.382... logprob:  0.529518, 0.148438 (1.449 sec)
18.383... logprob:  0.358664, 0.085938 (1.439 sec)
18.384... logprob:  0.521076, 0.148438 (1.486 sec)
18.385... logprob:  0.523487, 0.148438 (1.432 sec)
18.386... logprob:  0.582379, 0.171875 (1.433 sec)
18.387... logprob:  0.428653, 0.117188 (1.435 sec)
18.388... logprob:  0.521320, 0.148438 (1.439 sec)
18.389... logprob:  0.425850, 0.109375 (1.433 sec)
18.390... logprob:  0.419887, 0.109375 (1.495 sec)
18.391... logprob:  0.318343, 0.070312 (1.449 sec)
18.392... logprob:  0.439432, 0.117188 (1.431 sec)
18.393... logprob:  0.368875, 0.093750 (1.489 sec)
18.394... logprob:  0.343515, 0.078125 (1.433 sec)
18.395... logprob:  0.331607, 0.078125 (1.435 sec)
18.396... logprob:  0.251958, 0.046875 (1.435 sec)
18.397... logprob:  0.484635, 0.132812 (1.432 sec)
18.398... logprob:  0.471326, 0.125000 (1.440 sec)
18.399... logprob:  0.433645, 0.117188 (1.482 sec)
18.400... logprob:  0.538419, 0.148438 (1.433 sec)
18.401... logprob:  0.466111, 0.125000 (1.443 sec)
18.402... logprob:  0.474212, 0.125000 (1.483 sec)
18.403... logprob:  0.462226, 0.125000 (1.430 sec)
18.404... logprob:  0.474830, 0.125000 (1.442 sec)
18.405... logprob:  0.543908, 0.156250 (1.432 sec)
18.406... logprob:  0.357855, 0.085938 (1.431 sec)
18.407... logprob:  0.492731, 0.140625 (1.439 sec)
18.408... logprob:  0.339623, 0.078125 (1.478 sec)
18.409... logprob:  0.400923, 0.101562 (1.444 sec)
18.410... logprob:  0.581812, 0.171875 (1.452 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.99100875854492, 10.0]}, 128)
batch 872: ({'logprob': [65.67857360839844, 19.0]}, 128)
batch 873: ({'logprob': [42.658084869384766, 9.0]}, 128)
batch 874: ({'logprob': [46.49831008911133, 11.0]}, 128)
batch 875: ({'logprob': [51.59896469116211, 13.0]}, 128)
batch 876: ({'logprob': [63.45954513549805, 18.0]}, 128)
batch 877: ({'logprob': [47.13597869873047, 11.0]}, 128)
batch 878: ({'logprob': [61.83536148071289, 17.0]}, 128)
batch 879: ({'logprob': [72.6676254272461, 21.0]}, 128)
batch 880: ({'logprob': [51.6160774230957, 13.0]}, 128)
batch 881: ({'logprob': [31.794002532958984, 5.0]}, 128)
batch 882: ({'logprob': [55.74043273925781, 14.0]}, 128)
batch 883: ({'logprob': [61.817291259765625, 17.0]}, 128)
batch 884: ({'logprob': [52.22740173339844, 13.0]}, 128)
batch 885: ({'logprob': [53.48760223388672, 13.0]}, 128)
batch 886: ({'logprob': [62.457496643066406, 17.0]}, 128)

======================Test output======================
logprob:  0.421711, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.967730e-03 [2.751347e-09] 
Layer 'conv1' biases: 1.861360e-07 [3.859678e-11] 
Layer 'conv2' weights[0]: 7.954764e-03 [1.745907e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.765059e-10] 
Layer 'conv3' weights[0]: 7.953076e-03 [1.412682e-09] 
Layer 'conv3' biases: 1.608712e-06 [6.096006e-10] 
Layer 'conv4' weights[0]: 7.985663e-03 [1.537557e-09] 
Layer 'conv4' biases: 9.999996e-01 [5.030362e-09] 
Layer 'conv5' weights[0]: 7.984485e-03 [3.397271e-08] 
Layer 'conv5' biases: 9.999969e-01 [3.671235e-08] 
Layer 'fc6' weights[0]: 7.581273e-03 [2.943203e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.887280e-09] 
Layer 'fc7' weights[0]: 7.272788e-03 [2.221012e-07] 
Layer 'fc7' biases: 9.998627e-01 [2.112472e-07] 
Layer 'fc8' weights[0]: 1.270108e-03 [8.281632e-06] 
Layer 'fc8' biases: 4.245432e-02 [4.541529e-05] 
Train error last 870 batches: 0.435248
-------------------------------------------------------
Not saving because 0.421711 > 0.415685 (17.630: -0.01%)
======================================================= (12.059 sec)
18.411... logprob:  0.398222, 0.101562 (1.482 sec)
18.412... logprob:  0.540220, 0.156250 (1.445 sec)
18.413... logprob:  0.544702, 0.156250 (1.440 sec)
18.414... logprob:  0.466597, 0.125000 (1.432 sec)
18.415... logprob:  0.401778, 0.101562 (1.425 sec)
18.416... logprob:  0.427560, 0.109375 (1.442 sec)
18.417... logprob:  0.405422, 0.093750 (1.462 sec)
18.418... logprob:  0.380126, 0.093750 (1.456 sec)
18.419... logprob:  0.417593, 0.101562 (1.457 sec)
18.420... logprob:  0.355945, 0.085938 (1.453 sec)
18.421... logprob:  0.376544, 0.101562 (1.460 sec)
18.422... logprob:  0.523004, 0.148438 (1.437 sec)
18.423... logprob:  0.421016, 0.109375 (1.455 sec)
18.424... logprob:  0.324633, 0.078125 (1.430 sec)
18.425... logprob:  0.306156, 0.070312 (1.443 sec)
18.426... logprob:  0.449398, 0.117188 (1.443 sec)
18.427... logprob:  0.554955, 0.156250 (1.461 sec)
18.428... logprob:  0.602272, 0.171875 (1.454 sec)
18.429... logprob:  0.426282, 0.109375 (1.443 sec)
18.430... logprob:  0.299952, 0.070312 (1.476 sec)
18.431... logprob:  0.599345, 0.171875 (1.438 sec)
18.432... logprob:  0.387597, 0.093750 (1.425 sec)
18.433... logprob:  0.330215, 0.078125 (1.439 sec)
18.434... logprob:  0.529132, 0.148438 (1.437 sec)
18.435... logprob:  0.532075, 0.156250 (1.436 sec)
18.436... logprob:  0.381551, 0.093750 (1.478 sec)
18.437... logprob:  0.500229, 0.140625 (1.443 sec)
18.438... logprob:  0.546783, 0.156250 (1.436 sec)
18.439... logprob:  0.379182, 0.093750 (1.486 sec)
18.440... logprob:  0.439875, 0.117188 (1.436 sec)
18.441... logprob:  0.468042, 0.125000 (1.435 sec)
18.442... logprob:  0.378926, 0.093750 (1.435 sec)
18.443... logprob:  0.496585, 0.140625 (1.433 sec)
18.444... logprob:  0.372108, 0.093750 (1.440 sec)
18.445... logprob:  0.362177, 0.085938 (1.482 sec)
18.446... logprob:  0.398107, 0.101562 (1.439 sec)
18.447... logprob:  0.570345, 0.164062 (1.441 sec)
18.448... logprob:  0.332509, 0.078125 (1.483 sec)
18.449... logprob:  0.400022, 0.101562 (1.436 sec)
18.450... logprob:  0.238847, 0.046875 (1.438 sec)
18.451... logprob:  0.453025, 0.125000 (1.435 sec)
18.452... logprob:  0.456374, 0.117188 (1.432 sec)
18.453... logprob:  0.455519, 0.125000 (1.432 sec)
18.454... logprob:  0.489250, 0.132812 (1.487 sec)
18.455... logprob:  0.506141, 0.140625 (1.438 sec)
18.456... logprob:  0.468809, 0.125000 (1.448 sec)
18.457... logprob:  0.375387, 0.093750 (1.477 sec)
18.458... logprob:  0.351210, 0.085938 (1.433 sec)
18.459... logprob:  0.513663, 0.140625 (1.443 sec)
18.460... logprob:  0.274575, 0.054688 (1.431 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.70490646362305, 10.0]}, 128)
batch 872: ({'logprob': [66.39813995361328, 19.0]}, 128)
batch 873: ({'logprob': [40.79486083984375, 9.0]}, 128)
batch 874: ({'logprob': [45.27576446533203, 11.0]}, 128)
batch 875: ({'logprob': [50.808319091796875, 13.0]}, 128)
batch 876: ({'logprob': [63.912010192871094, 18.0]}, 128)
batch 877: ({'logprob': [45.808353424072266, 11.0]}, 128)
batch 878: ({'logprob': [61.91420364379883, 17.0]}, 128)
batch 879: ({'logprob': [73.5125503540039, 21.0]}, 128)
batch 880: ({'logprob': [50.826622009277344, 13.0]}, 128)
batch 881: ({'logprob': [29.163358688354492, 5.0]}, 128)
batch 882: ({'logprob': [54.912391662597656, 14.0]}, 128)
batch 883: ({'logprob': [61.895809173583984, 17.0]}, 128)
batch 884: ({'logprob': [51.337501525878906, 13.0]}, 128)
batch 885: ({'logprob': [52.39210510253906, 13.0]}, 128)
batch 886: ({'logprob': [62.435184478759766, 17.0]}, 128)

======================Test output======================
logprob:  0.416549, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.967691e-03 [2.590797e-09] 
Layer 'conv1' biases: 1.869106e-07 [8.693764e-11] 
Layer 'conv2' weights[0]: 7.954723e-03 [2.715425e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.748535e-10] 
Layer 'conv3' weights[0]: 7.953042e-03 [2.647284e-09] 
Layer 'conv3' biases: 1.614937e-06 [1.457179e-09] 
Layer 'conv4' weights[0]: 7.985626e-03 [2.770631e-09] 
Layer 'conv4' biases: 9.999995e-01 [1.309522e-08] 
Layer 'conv5' weights[0]: 7.984453e-03 [8.309714e-08] 
Layer 'conv5' biases: 9.999965e-01 [8.970508e-08] 
Layer 'fc6' weights[0]: 7.581233e-03 [7.045603e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.145757e-09] 
Layer 'fc7' weights[0]: 7.270901e-03 [9.737715e-08] 
Layer 'fc7' biases: 9.998631e-01 [8.364593e-08] 
Layer 'fc8' weights[0]: 1.308316e-03 [3.017116e-06] 
Layer 'fc8' biases: 4.308298e-02 [1.656346e-05] 
Train error last 870 batches: 0.435248
-------------------------------------------------------
Not saving because 0.416549 > 0.415685 (17.630: -0.01%)
======================================================= (12.071 sec)
18.461... logprob:  0.459984, 0.125000 (1.432 sec)
18.462... logprob:  0.471896, 0.125000 (1.439 sec)
18.463... logprob:  0.420947, 0.109375 (1.472 sec)
18.464... logprob:  0.482682, 0.132812 (1.450 sec)
18.465... logprob:  0.421217, 0.109375 (1.453 sec)
18.466... logprob:  0.318643, 0.070312 (1.463 sec)
18.467... logprob:  0.413871, 0.109375 (1.450 sec)
18.468... logprob:  0.394278, 0.101562 (1.441 sec)
18.469... logprob:  0.334658, 0.078125 (1.426 sec)
18.470... logprob:  0.400055, 0.101562 (1.430 sec)
18.471... logprob:  0.529621, 0.148438 (1.438 sec)
18.472... logprob:  0.410076, 0.109375 (1.458 sec)
18.473... logprob:  0.375344, 0.093750 (1.459 sec)
18.474... logprob:  0.465799, 0.125000 (1.457 sec)
18.475... logprob:  0.504409, 0.140625 (1.446 sec)
18.476... logprob:  0.510486, 0.140625 (1.468 sec)
18.477... logprob:  0.334503, 0.078125 (1.442 sec)
18.478... logprob:  0.464290, 0.125000 (1.429 sec)
18.479... logprob:  0.305790, 0.070312 (1.437 sec)
18.480... logprob:  0.443518, 0.117188 (1.434 sec)
18.481... logprob:  0.547746, 0.156250 (1.558 sec)
18.482... logprob:  0.443181, 0.117188 (1.475 sec)
18.483... logprob:  0.502578, 0.140625 (1.446 sec)
18.484... logprob:  0.485288, 0.132812 (1.441 sec)
18.485... logprob:  0.409087, 0.109375 (1.482 sec)
18.486... logprob:  0.361613, 0.085938 (1.439 sec)
18.487... logprob:  0.522615, 0.148438 (1.429 sec)
18.488... logprob:  0.424885, 0.109375 (1.443 sec)
18.489... logprob:  0.415950, 0.109375 (1.439 sec)
18.490... logprob:  0.440702, 0.117188 (1.430 sec)
18.491... logprob:  0.313709, 0.070312 (1.484 sec)
18.492... logprob:  0.459605, 0.125000 (1.446 sec)
18.493... logprob:  0.521957, 0.148438 (1.436 sec)
18.494... logprob:  0.450379, 0.125000 (1.486 sec)
18.495... logprob:  0.380556, 0.093750 (1.432 sec)
18.496... logprob:  0.550518, 0.156250 (1.438 sec)
18.497... logprob:  0.467038, 0.125000 (1.451 sec)
18.498... logprob:  0.476338, 0.132812 (1.433 sec)
18.499... logprob:  0.456279, 0.125000 (1.432 sec)
18.500... logprob:  0.355078, 0.085938 (1.494 sec)
18.501... logprob:  0.339108, 0.078125 (1.433 sec)
18.502... logprob:  0.459662, 0.125000 (1.443 sec)
18.503... logprob:  0.400689, 0.101562 (1.482 sec)
18.504... logprob:  0.487340, 0.132812 (1.429 sec)
18.505... logprob:  0.570809, 0.164062 (1.445 sec)
18.506... logprob:  0.479682, 0.132812 (1.431 sec)
18.507... logprob:  0.385136, 0.093750 (1.429 sec)
18.508... logprob:  0.374756, 0.093750 (1.436 sec)
18.509... logprob:  0.323212, 0.070312 (1.482 sec)
18.510... logprob:  0.390486, 0.101562 (1.445 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.8099479675293, 10.0]}, 128)
batch 872: ({'logprob': [66.5867691040039, 19.0]}, 128)
batch 873: ({'logprob': [40.559776306152344, 9.0]}, 128)
batch 874: ({'logprob': [45.24087142944336, 11.0]}, 128)
batch 875: ({'logprob': [50.780826568603516, 13.0]}, 128)
batch 876: ({'logprob': [64.04914093017578, 18.0]}, 128)
batch 877: ({'logprob': [45.67728805541992, 11.0]}, 128)
batch 878: ({'logprob': [61.90301513671875, 17.0]}, 128)
batch 879: ({'logprob': [73.4217758178711, 21.0]}, 128)
batch 880: ({'logprob': [50.79971694946289, 13.0]}, 128)
batch 881: ({'logprob': [29.008167266845703, 5.0]}, 128)
batch 882: ({'logprob': [54.64940643310547, 14.0]}, 128)
batch 883: ({'logprob': [61.88425827026367, 17.0]}, 128)
batch 884: ({'logprob': [51.21461486816406, 13.0]}, 128)
batch 885: ({'logprob': [52.07719421386719, 13.0]}, 128)
batch 886: ({'logprob': [62.32825469970703, 17.0]}, 128)

======================Test output======================
logprob:  0.416011, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.967652e-03 [3.856596e-09] 
Layer 'conv1' biases: 1.875684e-07 [1.321710e-10] 
Layer 'conv2' weights[0]: 7.954686e-03 [2.859124e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.645047e-10] 
Layer 'conv3' weights[0]: 7.953005e-03 [2.802212e-09] 
Layer 'conv3' biases: 1.621382e-06 [1.629864e-09] 
Layer 'conv4' weights[0]: 7.985587e-03 [3.048490e-09] 
Layer 'conv4' biases: 9.999995e-01 [1.521489e-08] 
Layer 'conv5' weights[0]: 7.984424e-03 [1.016435e-07] 
Layer 'conv5' biases: 9.999960e-01 [1.097358e-07] 
Layer 'fc6' weights[0]: 7.581185e-03 [8.620967e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.700868e-09] 
Layer 'fc7' weights[0]: 7.269063e-03 [1.675228e-07] 
Layer 'fc7' biases: 9.998631e-01 [1.556507e-07] 
Layer 'fc8' weights[0]: 1.308779e-03 [6.275962e-06] 
Layer 'fc8' biases: 4.320131e-02 [4.169618e-05] 
Train error last 870 batches: 0.435247
-------------------------------------------------------
Not saving because 0.416011 > 0.415685 (17.630: -0.01%)
======================================================= (12.054 sec)
18.511... logprob:  0.410081, 0.109375 (1.458 sec)
18.512... logprob:  0.470744, 0.125000 (1.467 sec)
18.513... logprob:  0.324976, 0.078125 (1.442 sec)
18.514... logprob:  0.406277, 0.101562 (1.440 sec)
18.515... logprob:  0.455593, 0.125000 (1.435 sec)
18.516... logprob:  0.400409, 0.109375 (1.422 sec)
18.517... logprob:  0.628036, 0.179688 (1.442 sec)
18.518... logprob:  0.437714, 0.117188 (1.458 sec)
18.519... logprob:  0.516152, 0.140625 (1.459 sec)
18.520... logprob:  0.409656, 0.109375 (1.452 sec)
18.521... logprob:  0.427517, 0.109375 (1.466 sec)
18.522... logprob:  0.533074, 0.156250 (1.461 sec)
18.523... logprob:  0.331765, 0.078125 (1.444 sec)
18.524... logprob:  0.437234, 0.117188 (1.424 sec)
18.525... logprob:  0.426082, 0.109375 (1.430 sec)
18.526... logprob:  0.351949, 0.078125 (1.443 sec)
18.527... logprob:  0.504543, 0.140625 (1.438 sec)
18.528... logprob:  0.440513, 0.117188 (1.473 sec)
18.529... logprob:  0.353014, 0.085938 (1.450 sec)
18.530... logprob:  0.440248, 0.117188 (1.469 sec)
18.531... logprob:  0.440009, 0.117188 (1.479 sec)
18.532... logprob:  0.467399, 0.125000 (1.437 sec)
18.533... logprob:  0.560692, 0.164062 (1.427 sec)
18.534... logprob:  0.325790, 0.078125 (1.435 sec)
18.535... logprob:  0.551680, 0.156250 (1.441 sec)
18.536... logprob:  0.507402, 0.140625 (1.434 sec)
18.537... logprob:  0.510080, 0.140625 (1.479 sec)
18.538... logprob:  0.486112, 0.132812 (1.442 sec)
18.539... logprob:  0.296142, 0.062500 (1.432 sec)
18.540... logprob:  0.447180, 0.117188 (1.488 sec)
18.541... logprob:  0.388889, 0.101562 (1.435 sec)
18.542... logprob:  0.411314, 0.109375 (1.431 sec)
18.543... logprob:  0.233395, 0.039062 (1.436 sec)
18.544... logprob:  0.317947, 0.070312 (1.436 sec)
18.545... logprob:  0.348812, 0.085938 (1.433 sec)
18.546... logprob:  0.368288, 0.093750 (1.488 sec)
18.547... logprob:  0.440141, 0.117188 (1.434 sec)
18.548... logprob:  0.453183, 0.125000 (1.447 sec)
18.549... logprob:  0.490715, 0.132812 (1.476 sec)
18.550... logprob:  0.367691, 0.093750 (1.441 sec)
18.551... logprob:  0.441794, 0.117188 (1.430 sec)
18.552... logprob:  0.471338, 0.125000 (1.438 sec)
18.553... logprob:  0.349436, 0.085938 (1.432 sec)
18.554... logprob:  0.506850, 0.140625 (1.431 sec)
18.555... logprob:  0.421413, 0.109375 (1.485 sec)
18.556... logprob:  0.355928, 0.085938 (1.438 sec)
18.557... logprob:  0.396482, 0.101562 (1.454 sec)
18.558... logprob:  0.383064, 0.101562 (1.474 sec)
18.559... logprob:  0.441456, 0.125000 (1.440 sec)
18.560... logprob:  0.335336, 0.078125 (1.437 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.66547775268555, 10.0]}, 128)
batch 872: ({'logprob': [66.20023345947266, 19.0]}, 128)
batch 873: ({'logprob': [41.139381408691406, 9.0]}, 128)
batch 874: ({'logprob': [45.384124755859375, 11.0]}, 128)
batch 875: ({'logprob': [50.893775939941406, 13.0]}, 128)
batch 876: ({'logprob': [63.77880859375, 18.0]}, 128)
batch 877: ({'logprob': [46.02330780029297, 11.0]}, 128)
batch 878: ({'logprob': [61.95274353027344, 17.0]}, 128)
batch 879: ({'logprob': [73.61003112792969, 21.0]}, 128)
batch 880: ({'logprob': [50.911781311035156, 13.0]}, 128)
batch 881: ({'logprob': [29.448760986328125, 5.0]}, 128)
batch 882: ({'logprob': [55.2515869140625, 14.0]}, 128)
batch 883: ({'logprob': [61.93419647216797, 17.0]}, 128)
batch 884: ({'logprob': [51.528865814208984, 13.0]}, 128)
batch 885: ({'logprob': [52.79623794555664, 13.0]}, 128)
batch 886: ({'logprob': [62.579933166503906, 17.0]}, 128)

======================Test output======================
logprob:  0.417529, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.967611e-03 [3.380648e-09] 
Layer 'conv1' biases: 1.885164e-07 [1.096150e-10] 
Layer 'conv2' weights[0]: 7.954647e-03 [2.390623e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.643145e-10] 
Layer 'conv3' weights[0]: 7.952964e-03 [2.544327e-09] 
Layer 'conv3' biases: 1.629625e-06 [1.378036e-09] 
Layer 'conv4' weights[0]: 7.985549e-03 [2.726165e-09] 
Layer 'conv4' biases: 9.999995e-01 [1.287308e-08] 
Layer 'conv5' weights[0]: 7.984381e-03 [8.637548e-08] 
Layer 'conv5' biases: 9.999963e-01 [9.339660e-08] 
Layer 'fc6' weights[0]: 7.581141e-03 [7.331891e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.420559e-09] 
Layer 'fc7' weights[0]: 7.267243e-03 [4.680418e-08] 
Layer 'fc7' biases: 9.998633e-01 [2.385683e-08] 
Layer 'fc8' weights[0]: 1.301158e-03 [5.470391e-06] 
Layer 'fc8' biases: 4.327429e-02 [3.215520e-05] 
Train error last 870 batches: 0.435247
-------------------------------------------------------
Not saving because 0.417529 > 0.415685 (17.630: -0.01%)
======================================================= (12.088 sec)
18.561... logprob:  0.411843, 0.109375 (1.439 sec)
18.562... logprob:  0.503116, 0.140625 (1.429 sec)
18.563... logprob:  0.373861, 0.093750 (1.460 sec)
18.564... logprob:  0.468426, 0.132812 (1.470 sec)
18.565... logprob:  0.611039, 0.187500 (1.451 sec)
18.566... logprob:  0.374917, 0.093750 (1.456 sec)
18.567... logprob:  0.423440, 0.109375 (1.454 sec)
18.568... logprob:  0.496377, 0.140625 (1.457 sec)
18.569... logprob:  0.507851, 0.140625 (1.442 sec)
18.570... logprob:  0.543728, 0.164062 (1.427 sec)
18.571... logprob:  0.454875, 0.125000 (1.428 sec)
18.572... logprob:  0.501479, 0.140625 (1.441 sec)
18.573... logprob:  0.512629, 0.148438 (1.448 sec)
18.574... logprob:  0.428148, 0.109375 (1.462 sec)
18.575... logprob:  0.343359, 0.078125 (1.454 sec)
18.576... logprob:  0.427409, 0.109375 (1.452 sec)
18.577... logprob:  0.460843, 0.125000 (1.473 sec)
18.578... logprob:  0.336587, 0.078125 (1.437 sec)
18.579... logprob:  0.442088, 0.117188 (1.427 sec)
18.580... logprob:  0.546946, 0.156250 (1.434 sec)
18.581... logprob:  0.531002, 0.156250 (1.438 sec)
18.582... logprob:  0.437898, 0.125000 (1.439 sec)
18.583... logprob:  0.592855, 0.171875 (1.471 sec)
18.584... logprob:  0.468128, 0.132812 (1.441 sec)
18.585... logprob:  0.349765, 0.085938 (1.433 sec)
18.586... logprob:  0.313152, 0.070312 (1.485 sec)
18.587... logprob:  0.404314, 0.101562 (1.430 sec)
18.588... logprob:  0.418673, 0.117188 (1.432 sec)
18.589... logprob:  0.361296, 0.093750 (1.441 sec)
18.590... logprob:  0.524702, 0.148438 (1.431 sec)
18.591... logprob:  0.397514, 0.101562 (1.438 sec)
18.592... logprob:  0.455646, 0.125000 (1.480 sec)
18.593... logprob:  0.467436, 0.125000 (1.439 sec)
18.594... logprob:  0.352874, 0.085938 (1.446 sec)
18.595... logprob:  0.428669, 0.109375 (1.478 sec)
18.596... logprob:  0.461583, 0.125000 (1.439 sec)
18.597... logprob:  0.397412, 0.101562 (1.432 sec)
18.598... logprob:  0.397230, 0.101562 (1.449 sec)
18.599... logprob:  0.313513, 0.070312 (1.429 sec)
18.600... logprob:  0.340898, 0.085938 (1.435 sec)
18.601... logprob:  0.402123, 0.101562 (1.488 sec)
18.602... logprob:  0.289695, 0.062500 (1.435 sec)
18.603... logprob:  0.266949, 0.054688 (1.447 sec)
18.604... logprob:  0.407514, 0.101562 (1.514 sec)
18.605... logprob:  0.563577, 0.148438 (1.432 sec)
18.606... logprob:  0.295946, 0.070312 (1.444 sec)
18.607... logprob:  0.504913, 0.132812 (1.433 sec)
18.608... logprob:  0.361692, 0.085938 (1.424 sec)
18.609... logprob:  0.356929, 0.085938 (1.442 sec)
18.610... logprob:  0.493426, 0.132812 (1.468 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.119136810302734, 10.0]}, 128)
batch 872: ({'logprob': [68.15472412109375, 19.0]}, 128)
batch 873: ({'logprob': [39.525840759277344, 9.0]}, 128)
batch 874: ({'logprob': [44.760009765625, 11.0]}, 128)
batch 875: ({'logprob': [50.796836853027344, 13.0]}, 128)
batch 876: ({'logprob': [65.35578155517578, 18.0]}, 128)
batch 877: ({'logprob': [45.1676025390625, 11.0]}, 128)
batch 878: ({'logprob': [62.917869567871094, 17.0]}, 128)
batch 879: ({'logprob': [75.407470703125, 21.0]}, 128)
batch 880: ({'logprob': [50.81669616699219, 13.0]}, 128)
batch 881: ({'logprob': [27.001514434814453, 5.0]}, 128)
batch 882: ({'logprob': [54.850257873535156, 14.0]}, 128)
batch 883: ({'logprob': [62.8985710144043, 17.0]}, 128)
batch 884: ({'logprob': [51.20716094970703, 13.0]}, 128)
batch 885: ({'logprob': [52.01614761352539, 13.0]}, 128)
batch 886: ({'logprob': [63.31783676147461, 17.0]}, 128)

======================Test output======================
logprob:  0.417634, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.967569e-03 [3.515553e-09] 
Layer 'conv1' biases: 1.893901e-07 [1.352928e-10] 
Layer 'conv2' weights[0]: 7.954599e-03 [3.377606e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.815406e-10] 
Layer 'conv3' weights[0]: 7.952921e-03 [3.235068e-09] 
Layer 'conv3' biases: 1.636254e-06 [2.057981e-09] 
Layer 'conv4' weights[0]: 7.985509e-03 [3.558598e-09] 
Layer 'conv4' biases: 9.999995e-01 [1.920373e-08] 
Layer 'conv5' weights[0]: 7.984361e-03 [1.284166e-07] 
Layer 'conv5' biases: 9.999962e-01 [1.387098e-07] 
Layer 'fc6' weights[0]: 7.581095e-03 [1.087243e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.110530e-08] 
Layer 'fc7' weights[0]: 7.265346e-03 [2.507075e-07] 
Layer 'fc7' biases: 9.998640e-01 [2.403285e-07] 
Layer 'fc8' weights[0]: 1.357030e-03 [1.413729e-05] 
Layer 'fc8' biases: 4.376741e-02 [8.499562e-05] 
Train error last 870 batches: 0.435247
-------------------------------------------------------
Not saving because 0.417634 > 0.415685 (17.630: -0.01%)
======================================================= (12.028 sec)
18.611... logprob:  0.510435, 0.140625 (1.456 sec)
18.612... logprob:  0.448398, 0.117188 (1.454 sec)
18.613... logprob:  0.279769, 0.062500 (1.471 sec)
18.614... logprob:  0.503521, 0.140625 (1.449 sec)
18.615... logprob:  0.351150, 0.085938 (1.441 sec)
18.616... logprob:  0.415328, 0.109375 (1.432 sec)
18.617... logprob:  0.417965, 0.109375 (1.425 sec)
18.618... logprob:  0.546714, 0.156250 (1.444 sec)
18.619... logprob:  0.505953, 0.140625 (1.451 sec)
18.620... logprob:  0.539625, 0.156250 (1.464 sec)
18.621... logprob:  0.363905, 0.085938 (1.453 sec)
18.622... logprob:  0.364930, 0.085938 (1.451 sec)
18.623... logprob:  0.423214, 0.109375 (1.466 sec)
18.624... logprob:  0.382554, 0.093750 (1.441 sec)
18.625... logprob:  0.441003, 0.117188 (1.424 sec)
18.626... logprob:  0.438392, 0.117188 (1.434 sec)
18.627... logprob:  0.435860, 0.117188 (1.440 sec)
18.628... logprob:  0.465092, 0.125000 (1.440 sec)
18.629... logprob:  0.372001, 0.093750 (1.472 sec)
18.630... logprob:  0.422374, 0.109375 (1.452 sec)
18.631... logprob:  0.639297, 0.187500 (1.434 sec)
18.632... logprob:  0.399100, 0.101562 (1.481 sec)
18.633... logprob:  0.376027, 0.093750 (1.432 sec)
18.634... logprob:  0.660449, 0.195312 (1.431 sec)
18.635... logprob:  0.374122, 0.093750 (1.436 sec)
18.636... logprob:  0.480233, 0.132812 (1.437 sec)
18.637... logprob:  0.330937, 0.078125 (1.460 sec)
18.638... logprob:  0.515671, 0.140625 (1.482 sec)
18.639... logprob:  0.418149, 0.109375 (1.444 sec)
18.640... logprob:  0.528747, 0.148438 (1.437 sec)
18.641... logprob:  0.410484, 0.109375 (1.486 sec)
18.642... logprob:  0.500820, 0.140625 (1.435 sec)
18.643... logprob:  0.622863, 0.187500 (1.433 sec)
18.644... logprob:  0.321391, 0.070312 (1.440 sec)
18.645... logprob:  0.414506, 0.109375 (1.426 sec)
18.646... logprob:  0.385747, 0.093750 (1.433 sec)
18.647... logprob:  0.456753, 0.125000 (1.488 sec)
18.648... logprob:  0.491231, 0.140625 (1.432 sec)
18.649... logprob:  0.370123, 0.093750 (1.443 sec)
18.650... logprob:  0.413940, 0.109375 (1.480 sec)
18.651... logprob:  0.397310, 0.101562 (1.435 sec)
18.652... logprob:  0.507379, 0.140625 (1.437 sec)
18.653... logprob:  0.548113, 0.156250 (1.435 sec)
18.654... logprob:  0.496140, 0.140625 (1.426 sec)
18.655... logprob:  0.436208, 0.117188 (1.430 sec)
18.656... logprob:  0.416677, 0.109375 (1.481 sec)
18.657... logprob:  0.449259, 0.117188 (1.438 sec)
18.658... logprob:  0.345770, 0.085938 (1.450 sec)
18.659... logprob:  0.464349, 0.125000 (1.471 sec)
18.660... logprob:  0.445916, 0.125000 (1.441 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.72463607788086, 10.0]}, 128)
batch 872: ({'logprob': [66.20609283447266, 19.0]}, 128)
batch 873: ({'logprob': [41.105201721191406, 9.0]}, 128)
batch 874: ({'logprob': [45.39244842529297, 11.0]}, 128)
batch 875: ({'logprob': [50.88697814941406, 13.0]}, 128)
batch 876: ({'logprob': [63.777931213378906, 18.0]}, 128)
batch 877: ({'logprob': [46.00296401977539, 11.0]}, 128)
batch 878: ({'logprob': [61.91597366333008, 17.0]}, 128)
batch 879: ({'logprob': [73.51441955566406, 21.0]}, 128)
batch 880: ({'logprob': [50.905094146728516, 13.0]}, 128)
batch 881: ({'logprob': [29.4733943939209, 5.0]}, 128)
batch 882: ({'logprob': [55.16524887084961, 14.0]}, 128)
batch 883: ({'logprob': [61.89738845825195, 17.0]}, 128)
batch 884: ({'logprob': [51.49325942993164, 13.0]}, 128)
batch 885: ({'logprob': [52.7027702331543, 13.0]}, 128)
batch 886: ({'logprob': [62.51425552368164, 17.0]}, 128)

======================Test output======================
logprob:  0.417323, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.967522e-03 [2.092599e-09] 
Layer 'conv1' biases: 1.902158e-07 [3.082644e-11] 
Layer 'conv2' weights[0]: 7.954558e-03 [1.393332e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.370464e-10] 
Layer 'conv3' weights[0]: 7.952880e-03 [1.067153e-09] 
Layer 'conv3' biases: 1.643846e-06 [3.661968e-10] 
Layer 'conv4' weights[0]: 7.985472e-03 [1.047532e-09] 
Layer 'conv4' biases: 9.999995e-01 [1.986705e-09] 
Layer 'conv5' weights[0]: 7.984316e-03 [8.682281e-09] 
Layer 'conv5' biases: 9.999962e-01 [8.830288e-09] 
Layer 'fc6' weights[0]: 7.581052e-03 [1.005714e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.270383e-10] 
Layer 'fc7' weights[0]: 7.263510e-03 [4.330614e-08] 
Layer 'fc7' biases: 9.998631e-01 [1.887364e-08] 
Layer 'fc8' weights[0]: 1.305422e-03 [4.720531e-06] 
Layer 'fc8' biases: 4.354487e-02 [3.022145e-05] 
Train error last 870 batches: 0.435246
-------------------------------------------------------
Not saving because 0.417323 > 0.415685 (17.630: -0.01%)
======================================================= (12.144 sec)
18.661... logprob:  0.378536, 0.093750 (1.437 sec)
18.662... logprob:  0.469347, 0.132812 (1.437 sec)
18.663... logprob:  0.311034, 0.070312 (1.423 sec)
18.664... logprob:  0.285497, 0.062500 (1.443 sec)
18.665... logprob:  0.401838, 0.101562 (1.460 sec)
18.666... logprob:  0.442064, 0.117188 (1.455 sec)
18.667... logprob:  0.564303, 0.164062 (1.456 sec)
18.668... logprob:  0.497909, 0.140625 (1.451 sec)
18.669... logprob:  0.433082, 0.109375 (1.463 sec)
18.670... logprob:  0.362478, 0.085938 (1.468 sec)
18.671... logprob:  0.360855, 0.093750 (1.425 sec)
18.672... logprob:  0.441814, 0.117188 (1.433 sec)
18.673... logprob:  0.436243, 0.117188 (1.438 sec)
18.674... logprob:  0.446664, 0.117188 (1.446 sec)
18.675... logprob:  0.356668, 0.093750 (1.470 sec)
18.676... logprob:  0.450152, 0.125000 (1.453 sec)
18.677... logprob:  0.471055, 0.125000 (1.438 sec)
18.678... logprob:  0.465645, 0.125000 (1.478 sec)
18.679... logprob:  0.454872, 0.125000 (1.433 sec)
18.680... logprob:  0.351730, 0.078125 (1.427 sec)
18.681... logprob:  0.373936, 0.093750 (1.439 sec)
18.682... logprob:  0.340500, 0.078125 (1.433 sec)
18.683... logprob:  0.411646, 0.109375 (1.438 sec)
18.684... logprob:  0.357607, 0.085938 (1.478 sec)
18.685... logprob:  0.285886, 0.054688 (1.446 sec)
18.686... logprob:  0.318541, 0.070312 (1.432 sec)
18.687... logprob:  0.281534, 0.062500 (1.491 sec)
18.688... logprob:  0.323084, 0.078125 (1.431 sec)
18.689... logprob:  0.471500, 0.125000 (1.428 sec)
18.690... logprob:  0.528064, 0.140625 (1.435 sec)
18.691... logprob:  0.517022, 0.140625 (1.433 sec)
18.692... logprob:  0.385289, 0.101562 (1.433 sec)
18.693... logprob:  0.456003, 0.125000 (1.489 sec)
18.694... logprob:  0.330894, 0.078125 (1.436 sec)
18.695... logprob:  0.356895, 0.085938 (1.445 sec)
18.696... logprob:  0.538815, 0.148438 (1.476 sec)
18.697... logprob:  0.465594, 0.125000 (1.441 sec)
18.698... logprob:  0.548555, 0.156250 (1.429 sec)
18.699... logprob:  0.459585, 0.125000 (1.434 sec)
18.700... logprob:  0.434025, 0.117188 (1.427 sec)
18.701... logprob:  0.423324, 0.109375 (1.439 sec)
18.702... logprob:  0.521457, 0.148438 (1.479 sec)
18.703... logprob:  0.405496, 0.101562 (1.438 sec)
18.704... logprob:  0.406315, 0.101562 (1.456 sec)
18.705... logprob:  0.420296, 0.109375 (1.474 sec)
18.706... logprob:  0.468079, 0.125000 (1.432 sec)
18.707... logprob:  0.485300, 0.132812 (1.434 sec)
18.708... logprob:  0.417057, 0.109375 (1.436 sec)
18.709... logprob:  0.422452, 0.109375 (1.424 sec)
18.710... logprob:  0.602739, 0.179688 (1.444 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.36671829223633, 10.0]}, 128)
batch 872: ({'logprob': [66.17547607421875, 19.0]}, 128)
batch 873: ({'logprob': [41.22359085083008, 9.0]}, 128)
batch 874: ({'logprob': [45.6895637512207, 11.0]}, 128)
batch 875: ({'logprob': [51.01515197753906, 13.0]}, 128)
batch 876: ({'logprob': [63.7449836730957, 18.0]}, 128)
batch 877: ({'logprob': [46.12680435180664, 11.0]}, 128)
batch 878: ({'logprob': [61.70685577392578, 17.0]}, 128)
batch 879: ({'logprob': [72.79521179199219, 21.0]}, 128)
batch 880: ({'logprob': [51.03368377685547, 13.0]}, 128)
batch 881: ({'logprob': [30.10294532775879, 5.0]}, 128)
batch 882: ({'logprob': [54.774837493896484, 14.0]}, 128)
batch 883: ({'logprob': [61.688148498535156, 17.0]}, 128)
batch 884: ({'logprob': [51.447288513183594, 13.0]}, 128)
batch 885: ({'logprob': [52.30936813354492, 13.0]}, 128)
batch 886: ({'logprob': [62.131072998046875, 17.0]}, 128)

======================Test output======================
logprob:  0.417154, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.967478e-03 [3.348572e-09] 
Layer 'conv1' biases: 1.908691e-07 [5.075718e-11] 
Layer 'conv2' weights[0]: 7.954523e-03 [2.336718e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.329077e-10] 
Layer 'conv3' weights[0]: 7.952840e-03 [1.969666e-09] 
Layer 'conv3' biases: 1.649171e-06 [1.155571e-09] 
Layer 'conv4' weights[0]: 7.985430e-03 [2.094870e-09] 
Layer 'conv4' biases: 9.999995e-01 [9.935898e-09] 
Layer 'conv5' weights[0]: 7.984273e-03 [6.603887e-08] 
Layer 'conv5' biases: 9.999960e-01 [7.122679e-08] 
Layer 'fc6' weights[0]: 7.581017e-03 [5.571028e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.645200e-09] 
Layer 'fc7' weights[0]: 7.261719e-03 [1.154424e-07] 
Layer 'fc7' biases: 9.998626e-01 [1.008701e-07] 
Layer 'fc8' weights[0]: 1.293882e-03 [3.679172e-06] 
Layer 'fc8' biases: 4.367202e-02 [3.060070e-05] 
Train error last 870 batches: 0.435246
-------------------------------------------------------
Not saving because 0.417154 > 0.415685 (17.630: -0.01%)
======================================================= (12.072 sec)
18.711... logprob:  0.469524, 0.125000 (1.480 sec)
18.712... logprob:  0.340375, 0.078125 (1.464 sec)
18.713... logprob:  0.587288, 0.179688 (1.453 sec)
18.714... logprob:  0.466329, 0.125000 (1.466 sec)
18.715... logprob:  0.417139, 0.109375 (1.455 sec)
18.716... logprob:  0.335259, 0.078125 (1.440 sec)
18.717... logprob:  0.429831, 0.117188 (1.432 sec)
18.718... logprob:  0.490379, 0.132812 (1.427 sec)
18.719... logprob:  0.406199, 0.109375 (1.443 sec)
18.720... logprob:  0.433238, 0.117188 (1.445 sec)
18.721... logprob:  0.451600, 0.117188 (1.461 sec)
18.722... logprob:  0.536853, 0.156250 (1.452 sec)
18.723... logprob:  0.416598, 0.109375 (1.449 sec)
18.724... logprob:  0.412779, 0.109375 (1.477 sec)
18.725... logprob:  0.494668, 0.140625 (1.431 sec)
18.726... logprob:  0.338663, 0.085938 (1.422 sec)
18.727... logprob:  0.393366, 0.101562 (1.435 sec)
18.728... logprob:  0.421355, 0.109375 (1.440 sec)
18.729... logprob:  0.387787, 0.093750 (1.437 sec)
18.730... logprob:  0.565832, 0.164062 (1.476 sec)
18.731... logprob:  0.450332, 0.125000 (1.444 sec)
18.732... logprob:  0.311480, 0.070312 (1.439 sec)
18.733... logprob:  0.556678, 0.156250 (1.486 sec)
18.734... logprob:  0.340231, 0.078125 (1.436 sec)
18.735... logprob:  0.527608, 0.148438 (1.429 sec)
18.736... logprob:  0.643003, 0.187500 (1.440 sec)
18.737... logprob:  0.516197, 0.148438 (1.430 sec)
18.738... logprob:  0.459428, 0.125000 (1.445 sec)
18.739... logprob:  0.477813, 0.132812 (1.486 sec)
18.740... logprob:  0.339659, 0.078125 (1.437 sec)
18.741... logprob:  0.393451, 0.101562 (1.439 sec)
18.742... logprob:  0.419735, 0.109375 (1.487 sec)
18.743... logprob:  0.364872, 0.085938 (1.433 sec)
18.744... logprob:  0.519242, 0.148438 (1.472 sec)
18.745... logprob:  0.478175, 0.132812 (1.431 sec)
18.746... logprob:  0.440558, 0.117188 (1.435 sec)
18.747... logprob:  0.425625, 0.109375 (1.433 sec)
18.748... logprob:  0.378059, 0.093750 (1.487 sec)
18.749... logprob:  0.420842, 0.109375 (1.439 sec)
18.750... logprob:  0.512907, 0.140625 (1.448 sec)
18.751... logprob:  0.263547, 0.054688 (1.474 sec)
18.752... logprob:  0.522518, 0.140625 (1.438 sec)
18.753... logprob:  0.441243, 0.117188 (1.441 sec)
18.754... logprob:  0.468545, 0.132812 (1.436 sec)
18.755... logprob:  0.507110, 0.140625 (1.424 sec)
18.756... logprob:  0.440824, 0.117188 (1.439 sec)
18.757... logprob:  0.552307, 0.156250 (1.473 sec)
18.758... logprob:  0.393696, 0.101562 (1.449 sec)
18.759... logprob:  0.459692, 0.125000 (1.452 sec)
18.760... logprob:  0.485427, 0.132812 (1.462 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.626224517822266, 10.0]}, 128)
batch 872: ({'logprob': [66.10284423828125, 19.0]}, 128)
batch 873: ({'logprob': [41.45283889770508, 9.0]}, 128)
batch 874: ({'logprob': [45.881744384765625, 11.0]}, 128)
batch 875: ({'logprob': [51.13156509399414, 13.0]}, 128)
batch 876: ({'logprob': [63.70056915283203, 18.0]}, 128)
batch 877: ({'logprob': [46.29988098144531, 11.0]}, 128)
batch 878: ({'logprob': [61.67136764526367, 17.0]}, 128)
batch 879: ({'logprob': [72.58837890625, 21.0]}, 128)
batch 880: ({'logprob': [51.150146484375, 13.0]}, 128)
batch 881: ({'logprob': [30.503787994384766, 5.0]}, 128)
batch 882: ({'logprob': [54.80430221557617, 14.0]}, 128)
batch 883: ({'logprob': [61.652584075927734, 17.0]}, 128)
batch 884: ({'logprob': [51.54381561279297, 13.0]}, 128)
batch 885: ({'logprob': [52.366844177246094, 13.0]}, 128)
batch 886: ({'logprob': [62.075843811035156, 17.0]}, 128)

======================Test output======================
logprob:  0.417750, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.967434e-03 [2.410399e-09] 
Layer 'conv1' biases: 1.917869e-07 [4.077122e-11] 
Layer 'conv2' weights[0]: 7.954481e-03 [1.792240e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.165493e-10] 
Layer 'conv3' weights[0]: 7.952801e-03 [1.516482e-09] 
Layer 'conv3' biases: 1.657937e-06 [7.119848e-10] 
Layer 'conv4' weights[0]: 7.985394e-03 [1.562037e-09] 
Layer 'conv4' biases: 9.999995e-01 [6.055451e-09] 
Layer 'conv5' weights[0]: 7.984236e-03 [4.057530e-08] 
Layer 'conv5' biases: 9.999967e-01 [4.383681e-08] 
Layer 'fc6' weights[0]: 7.580982e-03 [3.493476e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.465970e-09] 
Layer 'fc7' weights[0]: 7.259831e-03 [2.309067e-07] 
Layer 'fc7' biases: 9.998625e-01 [2.200084e-07] 
Layer 'fc8' weights[0]: 1.288221e-03 [7.992106e-06] 
Layer 'fc8' biases: 4.375377e-02 [4.992091e-05] 
Train error last 870 batches: 0.435246
-------------------------------------------------------
Not saving because 0.417750 > 0.415685 (17.630: -0.01%)
======================================================= (12.074 sec)
18.761... logprob:  0.418370, 0.109375 (1.456 sec)
18.762... logprob:  0.515990, 0.148438 (1.442 sec)
18.763... logprob:  0.558802, 0.164062 (1.428 sec)
18.764... logprob:  0.503287, 0.140625 (1.425 sec)
18.765... logprob:  0.312213, 0.062500 (1.443 sec)
18.766... logprob:  0.482288, 0.132812 (1.457 sec)
18.767... logprob:  0.371165, 0.085938 (1.460 sec)
18.768... logprob:  0.432702, 0.117188 (1.464 sec)
18.769... logprob:  0.490890, 0.140625 (1.464 sec)
18.770... logprob:  0.402838, 0.101562 (1.480 sec)
18.771... logprob:  0.549650, 0.156250 (1.453 sec)
18.772... logprob:  0.414040, 0.109375 (1.443 sec)
18.773... logprob:  0.558114, 0.164062 (1.448 sec)
18.774... logprob:  0.361552, 0.085938 (1.461 sec)
18.775... logprob:  0.407328, 0.101562 (1.463 sec)
18.776... logprob:  0.433233, 0.117188 (1.486 sec)
18.777... logprob:  0.379925, 0.093750 (1.496 sec)
18.778... logprob:  0.433615, 0.117188 (1.468 sec)
18.779... logprob:  0.505464, 0.140625 (1.486 sec)
18.780... logprob:  0.385758, 0.101562 (1.460 sec)
18.781... logprob:  0.369716, 0.085938 (1.449 sec)
18.782... logprob:  0.351497, 0.085938 (1.447 sec)
18.783... logprob:  0.555473, 0.156250 (1.463 sec)
18.784... logprob:  0.440956, 0.117188 (1.458 sec)
18.785... logprob:  0.543540, 0.156250 (1.497 sec)
18.786... logprob:  0.477412, 0.132812 (1.470 sec)
18.787... logprob:  0.546211, 0.156250 (1.463 sec)
18.788... logprob:  0.562924, 0.164062 (1.495 sec)
18.789... logprob:  0.281386, 0.054688 (1.458 sec)
18.790... logprob:  0.408288, 0.101562 (1.442 sec)
18.791... logprob:  0.398133, 0.101562 (1.445 sec)
18.792... logprob:  0.361228, 0.085938 (1.462 sec)
18.793... logprob:  0.370270, 0.085938 (1.457 sec)
18.794... logprob:  0.387129, 0.093750 (1.496 sec)
18.795... logprob:  0.469817, 0.125000 (1.469 sec)
18.796... logprob:  0.423500, 0.109375 (1.460 sec)
18.797... logprob:  0.358719, 0.085938 (1.497 sec)
18.798... logprob:  0.393268, 0.101562 (1.450 sec)
18.799... logprob:  0.332197, 0.078125 (1.449 sec)
18.800... logprob:  0.371774, 0.093750 (1.452 sec)
18.801... logprob:  0.450306, 0.117188 (1.459 sec)
18.802... logprob:  0.423132, 0.109375 (1.454 sec)
18.803... logprob:  0.491968, 0.132812 (1.493 sec)
18.804... logprob:  0.349981, 0.085938 (1.465 sec)
18.805... logprob:  0.452297, 0.117188 (1.458 sec)
18.806... logprob:  0.424186, 0.109375 (1.500 sec)
18.807... logprob:  0.443456, 0.117188 (1.455 sec)
18.808... logprob:  0.462342, 0.125000 (1.455 sec)
18.809... logprob:  0.589485, 0.171875 (1.450 sec)
18.810... logprob:  0.442445, 0.117188 (1.454 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.554222106933594, 10.0]}, 128)
batch 872: ({'logprob': [66.62887573242188, 19.0]}, 128)
batch 873: ({'logprob': [40.76561737060547, 9.0]}, 128)
batch 874: ({'logprob': [45.62871170043945, 11.0]}, 128)
batch 875: ({'logprob': [50.99252700805664, 13.0]}, 128)
batch 876: ({'logprob': [64.09019470214844, 18.0]}, 128)
batch 877: ({'logprob': [45.88676452636719, 11.0]}, 128)
batch 878: ({'logprob': [61.76334762573242, 17.0]}, 128)
batch 879: ({'logprob': [72.75237274169922, 21.0]}, 128)
batch 880: ({'logprob': [51.01197052001953, 13.0]}, 128)
batch 881: ({'logprob': [29.74455451965332, 5.0]}, 128)
batch 882: ({'logprob': [54.325889587402344, 14.0]}, 128)
batch 883: ({'logprob': [61.744319915771484, 17.0]}, 128)
batch 884: ({'logprob': [51.2469482421875, 13.0]}, 128)
batch 885: ({'logprob': [51.751441955566406, 13.0]}, 128)
batch 886: ({'logprob': [62.00922775268555, 17.0]}, 128)

======================Test output======================
logprob:  0.416454, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.967397e-03 [3.815208e-09] 
Layer 'conv1' biases: 1.927359e-07 [1.264611e-10] 
Layer 'conv2' weights[0]: 7.954454e-03 [3.622904e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.665707e-10] 
Layer 'conv3' weights[0]: 7.952759e-03 [3.476129e-09] 
Layer 'conv3' biases: 1.666568e-06 [2.056089e-09] 
Layer 'conv4' weights[0]: 7.985353e-03 [3.581526e-09] 
Layer 'conv4' biases: 9.999995e-01 [1.755259e-08] 
Layer 'conv5' weights[0]: 7.984201e-03 [1.141479e-07] 
Layer 'conv5' biases: 9.999970e-01 [1.232477e-07] 
Layer 'fc6' weights[0]: 7.580941e-03 [9.752533e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.820067e-09] 
Layer 'fc7' weights[0]: 7.257968e-03 [4.281601e-07] 
Layer 'fc7' biases: 9.998626e-01 [4.156838e-07] 
Layer 'fc8' weights[0]: 1.299638e-03 [1.580106e-05] 
Layer 'fc8' biases: 4.402071e-02 [9.712135e-05] 
Train error last 870 batches: 0.435245
-------------------------------------------------------
Not saving because 0.416454 > 0.415685 (17.630: -0.01%)
======================================================= (12.065 sec)
18.811... logprob:  0.460419, 0.125000 (1.463 sec)
18.812... logprob:  0.462415, 0.125000 (1.505 sec)
18.813... logprob:  0.485983, 0.132812 (1.466 sec)
18.814... logprob:  0.478129, 0.132812 (1.456 sec)
18.815... logprob:  0.372277, 0.085938 (1.502 sec)
18.816... logprob:  0.408959, 0.101562 (1.453 sec)
18.817... logprob:  0.426113, 0.109375 (1.456 sec)
18.818... logprob:  0.559971, 0.164062 (1.450 sec)
18.819... logprob:  0.498213, 0.140625 (1.459 sec)
18.820... logprob:  0.421561, 0.109375 (1.453 sec)
18.821... logprob:  0.406455, 0.101562 (1.496 sec)
18.822... logprob:  0.441103, 0.117188 (1.463 sec)
18.823... logprob:  0.340513, 0.078125 (1.214 sec)
18.824... logprob:  0.489977, 0.132812 (0.716 sec)
18.825... logprob:  0.287581, 0.062500 (0.683 sec)
18.826... logprob:  0.375372, 0.093750 (0.689 sec)
18.827... logprob:  0.420630, 0.109375 (0.692 sec)
18.828... logprob:  0.443592, 0.117188 (0.686 sec)
18.829... logprob:  0.504602, 0.140625 (0.684 sec)
18.830... logprob:  0.442337, 0.117188 (1.513 sec)
18.831... logprob:  0.514118, 0.140625 (1.452 sec)
18.832... logprob:  0.330857, 0.078125 (1.466 sec)
18.833... logprob:  0.488962, 0.132812 (1.492 sec)
18.834... logprob:  0.433210, 0.117188 (1.445 sec)
18.835... logprob:  0.542514, 0.148438 (1.454 sec)
18.836... logprob:  0.376322, 0.093750 (1.449 sec)
18.837... logprob:  0.314740, 0.070312 (1.539 sec)
18.838... logprob:  0.437089, 0.117188 (1.450 sec)
18.839... logprob:  0.471723, 0.125000 (1.505 sec)
18.840... logprob:  0.555267, 0.156250 (1.457 sec)
18.841... logprob:  0.396263, 0.101562 (1.464 sec)
18.842... logprob:  0.497808, 0.140625 (1.493 sec)
18.843... logprob:  0.465547, 0.125000 (1.455 sec)
18.844... logprob:  0.497618, 0.140625 (1.459 sec)
18.845... logprob:  0.486823, 0.132812 (1.449 sec)
18.846... logprob:  0.468483, 0.125000 (1.454 sec)
18.847... logprob:  0.363187, 0.085938 (1.452 sec)
18.848... logprob:  0.397030, 0.101562 (1.494 sec)
18.849... logprob:  0.360272, 0.085938 (1.456 sec)
18.850... logprob:  0.479435, 0.132812 (1.470 sec)
18.851... logprob:  0.440152, 0.117188 (1.493 sec)
18.852... logprob:  0.545857, 0.156250 (1.453 sec)
18.853... logprob:  0.371796, 0.093750 (1.489 sec)
18.854... logprob:  0.307027, 0.070312 (1.447 sec)
18.855... logprob:  0.484966, 0.132812 (1.452 sec)
18.856... logprob:  0.443855, 0.117188 (1.451 sec)
18.857... logprob:  0.372239, 0.093750 (1.498 sec)
18.858... logprob:  0.396247, 0.101562 (1.459 sec)
18.859... logprob:  0.307952, 0.070312 (1.475 sec)
18.860... logprob:  0.565959, 0.156250 (1.486 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.28308868408203, 10.0]}, 128)
batch 872: ({'logprob': [67.6616439819336, 19.0]}, 128)
batch 873: ({'logprob': [39.71977233886719, 9.0]}, 128)
batch 874: ({'logprob': [44.83143615722656, 11.0]}, 128)
batch 875: ({'logprob': [50.72126007080078, 13.0]}, 128)
batch 876: ({'logprob': [64.93002319335938, 18.0]}, 128)
batch 877: ({'logprob': [45.22706604003906, 11.0]}, 128)
batch 878: ({'logprob': [62.54747772216797, 17.0]}, 128)
batch 879: ({'logprob': [74.72994995117188, 21.0]}, 128)
batch 880: ({'logprob': [50.74108123779297, 13.0]}, 128)
batch 881: ({'logprob': [27.502954483032227, 5.0]}, 128)
batch 882: ({'logprob': [54.66937255859375, 14.0]}, 128)
batch 883: ({'logprob': [62.528160095214844, 17.0]}, 128)
batch 884: ({'logprob': [51.11827087402344, 13.0]}, 128)
batch 885: ({'logprob': [51.90232467651367, 13.0]}, 128)
batch 886: ({'logprob': [62.9345817565918, 17.0]}, 128)

======================Test output======================
logprob:  0.416528, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.967350e-03 [4.328664e-09] 
Layer 'conv1' biases: 1.935285e-07 [1.055389e-10] 
Layer 'conv2' weights[0]: 7.954413e-03 [3.093771e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.959539e-10] 
Layer 'conv3' weights[0]: 7.952720e-03 [2.886262e-09] 
Layer 'conv3' biases: 1.672139e-06 [1.856375e-09] 
Layer 'conv4' weights[0]: 7.985312e-03 [3.041727e-09] 
Layer 'conv4' biases: 9.999995e-01 [1.675822e-08] 
Layer 'conv5' weights[0]: 7.984170e-03 [1.124572e-07] 
Layer 'conv5' biases: 9.999959e-01 [1.216085e-07] 
Layer 'fc6' weights[0]: 7.580900e-03 [9.628974e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.675553e-09] 
Layer 'fc7' weights[0]: 7.256093e-03 [4.896552e-08] 
Layer 'fc7' biases: 9.998636e-01 [2.857216e-08] 
Layer 'fc8' weights[0]: 1.339881e-03 [1.113946e-06] 
Layer 'fc8' biases: 4.453577e-02 [4.299466e-06] 
Train error last 870 batches: 0.435245
-------------------------------------------------------
Not saving because 0.416528 > 0.415685 (17.630: -0.01%)
======================================================= (12.071 sec)
18.861... logprob:  0.417817, 0.109375 (1.466 sec)
18.862... logprob:  0.328928, 0.078125 (1.469 sec)
18.863... logprob:  0.399521, 0.101562 (1.445 sec)
18.864... logprob:  0.451400, 0.117188 (1.442 sec)
18.865... logprob:  0.484413, 0.132812 (1.458 sec)
18.866... logprob:  0.507524, 0.140625 (1.487 sec)
18.867... logprob:  0.502857, 0.140625 (1.473 sec)
18.868... logprob:  0.405379, 0.101562 (1.475 sec)
18.869... logprob:  0.383324, 0.093750 (1.482 sec)
18.870... logprob:  0.551972, 0.156250 (1.397 sec)
19.1... logprob:  0.380166, 0.093750 (1.411 sec)
19.2... logprob:  0.448279, 0.117188 (1.450 sec)
19.3... logprob:  0.398409, 0.101562 (1.419 sec)
19.4... logprob:  0.443347, 0.117188 (1.410 sec)
19.5... logprob:  0.443428, 0.117188 (1.436 sec)
19.6... logprob:  0.499183, 0.140625 (1.396 sec)
19.7... logprob:  0.363075, 0.085938 (1.420 sec)
19.8... logprob:  0.419114, 0.109375 (1.395 sec)
19.9... logprob:  0.358688, 0.085938 (1.407 sec)
19.10... logprob:  0.377406, 0.093750 (1.412 sec)
19.11... logprob:  0.334595, 0.078125 (1.447 sec)
19.12... logprob:  0.466499, 0.125000 (1.392 sec)
19.13... logprob:  0.442357, 0.117188 (1.429 sec)
19.14... logprob:  0.444751, 0.117188 (1.401 sec)
19.15... logprob:  0.395626, 0.101562 (1.405 sec)
19.16... logprob:  0.421450, 0.109375 (1.428 sec)
19.17... logprob:  0.516082, 0.140625 (1.395 sec)
19.18... logprob:  0.262106, 0.054688 (1.406 sec)
19.19... logprob:  0.279604, 0.062500 (1.400 sec)
19.20... logprob:  0.421378, 0.109375 (1.404 sec)
19.21... logprob:  0.443957, 0.117188 (0.893 sec)
19.22... logprob:  0.536603, 0.148438 (1.326 sec)
19.23... logprob:  0.532845, 0.148438 (1.418 sec)
19.24... logprob:  0.310732, 0.070312 (0.986 sec)
19.25... logprob:  0.356296, 0.085938 (0.959 sec)
19.26... logprob:  0.463687, 0.125000 (1.449 sec)
19.27... logprob:  0.404594, 0.101562 (1.393 sec)
19.28... logprob:  0.421870, 0.109375 (1.416 sec)
19.29... logprob:  0.396039, 0.101562 (1.424 sec)
19.30... logprob:  0.374165, 0.093750 (1.416 sec)
19.31... logprob:  0.479915, 0.132812 (1.402 sec)
19.32... logprob:  0.457232, 0.125000 (1.391 sec)
19.33... logprob:  0.460678, 0.125000 (1.445 sec)
19.34... logprob:  0.464609, 0.125000 (1.396 sec)
19.35... logprob:  0.316220, 0.070312 (1.405 sec)
19.36... logprob:  0.475800, 0.132812 (1.405 sec)
19.37... logprob:  0.417595, 0.109375 (1.408 sec)
19.38... logprob:  0.392549, 0.101562 (1.400 sec)
19.39... logprob:  0.631815, 0.187500 (1.443 sec)
19.40... logprob:  0.445805, 0.117188 (1.414 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.26396179199219, 10.0]}, 128)
batch 872: ({'logprob': [66.38800811767578, 19.0]}, 128)
batch 873: ({'logprob': [40.898311614990234, 9.0]}, 128)
batch 874: ({'logprob': [45.537410736083984, 11.0]}, 128)
batch 875: ({'logprob': [50.92644500732422, 13.0]}, 128)
batch 876: ({'logprob': [63.89889907836914, 18.0]}, 128)
batch 877: ({'logprob': [45.919883728027344, 11.0]}, 128)
batch 878: ({'logprob': [61.7467041015625, 17.0]}, 128)
batch 879: ({'logprob': [72.9089126586914, 21.0]}, 128)
batch 880: ({'logprob': [50.94558334350586, 13.0]}, 128)
batch 881: ({'logprob': [29.70355987548828, 5.0]}, 128)
batch 882: ({'logprob': [54.582828521728516, 14.0]}, 128)
batch 883: ({'logprob': [61.727622985839844, 17.0]}, 128)
batch 884: ({'logprob': [51.305015563964844, 13.0]}, 128)
batch 885: ({'logprob': [52.05838394165039, 13.0]}, 128)
batch 886: ({'logprob': [62.11697006225586, 17.0]}, 128)

======================Test output======================
logprob:  0.416469, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.967308e-03 [4.097434e-09] 
Layer 'conv1' biases: 1.944278e-07 [9.673176e-11] 
Layer 'conv2' weights[0]: 7.954370e-03 [2.504050e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.199677e-10] 
Layer 'conv3' weights[0]: 7.952685e-03 [2.193203e-09] 
Layer 'conv3' biases: 1.680333e-06 [1.278909e-09] 
Layer 'conv4' weights[0]: 7.985272e-03 [2.249179e-09] 
Layer 'conv4' biases: 9.999995e-01 [1.028425e-08] 
Layer 'conv5' weights[0]: 7.984122e-03 [6.876369e-08] 
Layer 'conv5' biases: 9.999964e-01 [7.428691e-08] 
Layer 'fc6' weights[0]: 7.580870e-03 [5.790360e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.885010e-09] 
Layer 'fc7' weights[0]: 7.254268e-03 [1.132647e-07] 
Layer 'fc7' biases: 9.998627e-01 [9.938980e-08] 
Layer 'fc8' weights[0]: 1.293719e-03 [6.967675e-06] 
Layer 'fc8' biases: 4.435269e-02 [4.490514e-05] 
Train error last 870 batches: 0.435245
-------------------------------------------------------
Not saving because 0.416469 > 0.415685 (17.630: -0.01%)
======================================================= (12.050 sec)
19.41... logprob:  0.352815, 0.085938 (1.436 sec)
19.42... logprob:  0.391880, 0.101562 (1.424 sec)
19.43... logprob:  0.440110, 0.117188 (1.409 sec)
19.44... logprob:  0.518522, 0.148438 (1.443 sec)
19.45... logprob:  0.381768, 0.093750 (1.402 sec)
19.46... logprob:  0.486325, 0.132812 (1.396 sec)
19.47... logprob:  0.331753, 0.078125 (1.399 sec)
19.48... logprob:  0.498891, 0.140625 (1.423 sec)
19.49... logprob:  0.510701, 0.148438 (1.418 sec)
19.50... logprob:  0.393231, 0.101562 (1.423 sec)
19.51... logprob:  0.490072, 0.140625 (1.443 sec)
19.52... logprob:  0.525781, 0.148438 (1.403 sec)
19.53... logprob:  0.294986, 0.062500 (1.444 sec)
19.54... logprob:  0.403288, 0.109375 (1.394 sec)
19.55... logprob:  0.331771, 0.078125 (1.399 sec)
19.56... logprob:  0.421689, 0.109375 (1.402 sec)
19.57... logprob:  0.572489, 0.164062 (1.433 sec)
19.58... logprob:  0.407713, 0.101562 (1.413 sec)
19.59... logprob:  0.333858, 0.078125 (1.470 sec)
19.60... logprob:  0.618959, 0.179688 (1.430 sec)
19.61... logprob:  0.382850, 0.093750 (1.428 sec)
19.62... logprob:  0.474888, 0.132812 (1.465 sec)
19.63... logprob:  0.397305, 0.101562 (1.436 sec)
19.64... logprob:  0.450282, 0.125000 (1.417 sec)
19.65... logprob:  0.373335, 0.093750 (1.396 sec)
19.66... logprob:  0.354013, 0.085938 (1.449 sec)
19.67... logprob:  0.295394, 0.062500 (1.393 sec)
19.68... logprob:  0.396814, 0.101562 (1.398 sec)
19.69... logprob:  0.496792, 0.140625 (1.423 sec)
19.70... logprob:  0.325881, 0.078125 (1.432 sec)
19.71... logprob:  0.381829, 0.101562 (1.459 sec)
19.72... logprob:  0.493808, 0.132812 (1.403 sec)
19.73... logprob:  0.447753, 0.117188 (1.427 sec)
19.74... logprob:  0.442573, 0.117188 (1.420 sec)
19.75... logprob:  0.380645, 0.093750 (1.415 sec)
19.76... logprob:  0.412076, 0.109375 (1.436 sec)
19.77... logprob:  0.396343, 0.101562 (1.433 sec)
19.78... logprob:  0.493064, 0.140625 (1.456 sec)
19.79... logprob:  0.456449, 0.125000 (1.402 sec)
19.80... logprob:  0.507915, 0.132812 (1.423 sec)
19.81... logprob:  0.416724, 0.109375 (1.418 sec)
19.82... logprob:  0.231667, 0.039062 (1.426 sec)
19.83... logprob:  0.493745, 0.140625 (1.409 sec)
19.84... logprob:  0.468097, 0.125000 (1.471 sec)
19.85... logprob:  0.432005, 0.117188 (1.424 sec)
19.86... logprob:  0.416975, 0.109375 (1.433 sec)
19.87... logprob:  0.633212, 0.187500 (1.421 sec)
19.88... logprob:  0.535080, 0.156250 (1.409 sec)
19.89... logprob:  0.410610, 0.109375 (1.435 sec)
19.90... logprob:  0.577502, 0.171875 (1.395 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.11211395263672, 10.0]}, 128)
batch 872: ({'logprob': [65.8039779663086, 19.0]}, 128)
batch 873: ({'logprob': [42.334686279296875, 9.0]}, 128)
batch 874: ({'logprob': [46.419620513916016, 11.0]}, 128)
batch 875: ({'logprob': [51.50613021850586, 13.0]}, 128)
batch 876: ({'logprob': [63.52816390991211, 18.0]}, 128)
batch 877: ({'logprob': [46.928348541259766, 11.0]}, 128)
batch 878: ({'logprob': [61.71665573120117, 17.0]}, 128)
batch 879: ({'logprob': [72.39403533935547, 21.0]}, 128)
batch 880: ({'logprob': [51.52412033081055, 13.0]}, 128)
batch 881: ({'logprob': [31.625627517700195, 5.0]}, 128)
batch 882: ({'logprob': [55.31959533691406, 14.0]}, 128)
batch 883: ({'logprob': [61.698028564453125, 17.0]}, 128)
batch 884: ({'logprob': [52.0064697265625, 13.0]}, 128)
batch 885: ({'logprob': [53.00877380371094, 13.0]}, 128)
batch 886: ({'logprob': [62.210079193115234, 17.0]}, 128)

======================Test output======================
logprob:  0.420477, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.967272e-03 [3.735039e-09] 
Layer 'conv1' biases: 1.953884e-07 [1.014517e-10] 
Layer 'conv2' weights[0]: 7.954326e-03 [2.922760e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.245811e-10] 
Layer 'conv3' weights[0]: 7.952642e-03 [2.536964e-09] 
Layer 'conv3' biases: 1.687504e-06 [1.624988e-09] 
Layer 'conv4' weights[0]: 7.985233e-03 [2.667156e-09] 
Layer 'conv4' biases: 9.999995e-01 [1.372895e-08] 
Layer 'conv5' weights[0]: 7.984078e-03 [8.888309e-08] 
Layer 'conv5' biases: 9.999966e-01 [9.589206e-08] 
Layer 'fc6' weights[0]: 7.580825e-03 [7.475070e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.590192e-09] 
Layer 'fc7' weights[0]: 7.252475e-03 [2.529148e-07] 
Layer 'fc7' biases: 9.998623e-01 [2.425812e-07] 
Layer 'fc8' weights[0]: 1.266221e-03 [9.507489e-06] 
Layer 'fc8' biases: 4.419900e-02 [6.161379e-05] 
Train error last 870 batches: 0.435245
-------------------------------------------------------
Not saving because 0.420477 > 0.415685 (17.630: -0.01%)
======================================================= (12.070 sec)
19.91... logprob:  0.348519, 0.078125 (1.411 sec)
19.92... logprob:  0.464462, 0.125000 (1.411 sec)
19.93... logprob:  0.492263, 0.140625 (1.406 sec)
19.94... logprob:  0.428783, 0.109375 (1.400 sec)
19.95... logprob:  0.471851, 0.125000 (1.406 sec)
19.96... logprob:  0.576312, 0.171875 (1.418 sec)
19.97... logprob:  0.430763, 0.117188 (1.396 sec)
19.98... logprob:  0.391069, 0.093750 (1.443 sec)
19.99... logprob:  0.474291, 0.132812 (1.412 sec)
19.100... logprob:  0.310419, 0.070312 (1.407 sec)
19.101... logprob:  0.310618, 0.062500 (1.440 sec)
19.102... logprob:  0.546257, 0.156250 (1.391 sec)
19.103... logprob:  0.541245, 0.156250 (1.404 sec)
19.104... logprob:  0.388856, 0.101562 (1.403 sec)
19.105... logprob:  0.619685, 0.179688 (1.393 sec)
19.106... logprob:  0.344437, 0.085938 (1.398 sec)
19.107... logprob:  0.335721, 0.078125 (1.437 sec)
19.108... logprob:  0.586825, 0.171875 (1.397 sec)
19.109... logprob:  0.336186, 0.078125 (1.402 sec)
19.110... logprob:  0.564486, 0.164062 (1.404 sec)
19.111... logprob:  0.404718, 0.101562 (1.406 sec)
19.112... logprob:  0.366144, 0.093750 (1.405 sec)
19.113... logprob:  0.354619, 0.085938 (1.402 sec)
19.114... logprob:  0.440227, 0.117188 (1.429 sec)
19.115... logprob:  0.506733, 0.140625 (1.416 sec)
19.116... logprob:  0.393395, 0.101562 (1.401 sec)
19.117... logprob:  0.440395, 0.117188 (1.448 sec)
19.118... logprob:  0.409152, 0.101562 (1.395 sec)
19.119... logprob:  0.346125, 0.085938 (1.401 sec)
19.120... logprob:  0.547144, 0.156250 (1.407 sec)
19.121... logprob:  0.412657, 0.109375 (1.406 sec)
19.122... logprob:  0.519339, 0.148438 (1.443 sec)
19.123... logprob:  0.463730, 0.125000 (1.393 sec)
19.124... logprob:  0.447706, 0.125000 (1.402 sec)
19.125... logprob:  0.501985, 0.140625 (1.402 sec)
19.126... logprob:  0.475791, 0.125000 (1.395 sec)
19.127... logprob:  0.479600, 0.125000 (1.402 sec)
19.128... logprob:  0.422368, 0.109375 (1.422 sec)
19.129... logprob:  0.574893, 0.164062 (1.424 sec)
19.130... logprob:  0.382740, 0.093750 (1.415 sec)
19.131... logprob:  0.495500, 0.132812 (1.409 sec)
19.132... logprob:  0.506378, 0.140625 (1.436 sec)
19.133... logprob:  0.444683, 0.117188 (1.392 sec)
19.134... logprob:  0.401904, 0.101562 (1.396 sec)
19.135... logprob:  0.460228, 0.125000 (1.404 sec)
19.136... logprob:  0.562524, 0.164062 (1.404 sec)
19.137... logprob:  0.462572, 0.125000 (1.399 sec)
19.138... logprob:  0.319351, 0.070312 (1.441 sec)
19.139... logprob:  0.395775, 0.101562 (1.405 sec)
19.140... logprob:  0.560400, 0.164062 (1.412 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.47916030883789, 10.0]}, 128)
batch 872: ({'logprob': [66.68462371826172, 19.0]}, 128)
batch 873: ({'logprob': [40.67192077636719, 9.0]}, 128)
batch 874: ({'logprob': [45.566505432128906, 11.0]}, 128)
batch 875: ({'logprob': [50.95899200439453, 13.0]}, 128)
batch 876: ({'logprob': [64.13135528564453, 18.0]}, 128)
batch 877: ({'logprob': [45.823326110839844, 11.0]}, 128)
batch 878: ({'logprob': [61.78820037841797, 17.0]}, 128)
batch 879: ({'logprob': [72.83395385742188, 21.0]}, 128)
batch 880: ({'logprob': [50.978763580322266, 13.0]}, 128)
batch 881: ({'logprob': [29.593982696533203, 5.0]}, 128)
batch 882: ({'logprob': [54.304378509521484, 14.0]}, 128)
batch 883: ({'logprob': [61.768699645996094, 17.0]}, 128)
batch 884: ({'logprob': [51.2127799987793, 13.0]}, 128)
batch 885: ({'logprob': [51.71489715576172, 13.0]}, 128)
batch 886: ({'logprob': [62.033042907714844, 17.0]}, 128)

======================Test output======================
logprob:  0.416282, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.967238e-03 [3.018075e-09] 
Layer 'conv1' biases: 1.960501e-07 [5.390457e-11] 
Layer 'conv2' weights[0]: 7.954292e-03 [1.966337e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.022366e-10] 
Layer 'conv3' weights[0]: 7.952607e-03 [1.625401e-09] 
Layer 'conv3' biases: 1.691924e-06 [9.047031e-10] 
Layer 'conv4' weights[0]: 7.985191e-03 [1.559735e-09] 
Layer 'conv4' biases: 9.999995e-01 [6.408261e-09] 
Layer 'conv5' weights[0]: 7.984058e-03 [3.117172e-08] 
Layer 'conv5' biases: 9.999960e-01 [3.309180e-08] 
Layer 'fc6' weights[0]: 7.580784e-03 [2.751545e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.689461e-09] 
Layer 'fc7' weights[0]: 7.250627e-03 [1.120643e-07] 
Layer 'fc7' biases: 9.998626e-01 [9.750216e-08] 
Layer 'fc8' weights[0]: 1.298703e-03 [3.905442e-06] 
Layer 'fc8' biases: 4.454020e-02 [2.739433e-05] 
Train error last 870 batches: 0.435245
-------------------------------------------------------
Not saving because 0.416282 > 0.415685 (17.630: -0.01%)
======================================================= (12.076 sec)
19.141... logprob:  0.464547, 0.125000 (1.445 sec)
19.142... logprob:  0.464615, 0.125000 (1.406 sec)
19.143... logprob:  0.294296, 0.062500 (1.426 sec)
19.144... logprob:  0.457243, 0.125000 (1.417 sec)
19.145... logprob:  0.324838, 0.078125 (1.420 sec)
19.146... logprob:  0.483202, 0.132812 (1.419 sec)
19.147... logprob:  0.262472, 0.054688 (1.436 sec)
19.148... logprob:  0.458777, 0.125000 (1.395 sec)
19.149... logprob:  0.442549, 0.117188 (1.395 sec)
19.150... logprob:  0.347616, 0.085938 (1.404 sec)
19.151... logprob:  0.347151, 0.085938 (1.399 sec)
19.152... logprob:  0.785038, 0.234375 (1.395 sec)
19.153... logprob:  0.381661, 0.093750 (1.440 sec)
19.154... logprob:  0.524454, 0.148438 (1.412 sec)
19.155... logprob:  0.426008, 0.117188 (1.412 sec)
19.156... logprob:  0.295738, 0.062500 (1.436 sec)
19.157... logprob:  0.270650, 0.054688 (1.395 sec)
19.158... logprob:  0.455383, 0.125000 (1.401 sec)
19.159... logprob:  0.483115, 0.132812 (1.404 sec)
19.160... logprob:  0.444842, 0.117188 (1.411 sec)
19.161... logprob:  0.350050, 0.078125 (1.413 sec)
19.162... logprob:  0.611791, 0.179688 (1.414 sec)
19.163... logprob:  0.450437, 0.125000 (1.431 sec)
19.164... logprob:  0.468651, 0.125000 (1.421 sec)
19.165... logprob:  0.547910, 0.156250 (1.416 sec)
19.166... logprob:  0.446079, 0.125000 (1.458 sec)
19.167... logprob:  0.350456, 0.085938 (1.432 sec)
19.168... logprob:  0.363690, 0.085938 (1.424 sec)
19.169... logprob:  0.408669, 0.101562 (1.460 sec)
19.170... logprob:  0.459486, 0.125000 (1.409 sec)
19.171... logprob:  0.535412, 0.156250 (1.425 sec)
19.172... logprob:  0.434856, 0.109375 (1.417 sec)
19.173... logprob:  0.440491, 0.117188 (1.423 sec)
19.174... logprob:  0.601050, 0.171875 (1.407 sec)
19.175... logprob:  0.506078, 0.140625 (1.471 sec)
19.176... logprob:  0.478469, 0.132812 (1.424 sec)
19.177... logprob:  0.289756, 0.054688 (1.430 sec)
19.178... logprob:  0.383484, 0.093750 (1.463 sec)
19.179... logprob:  0.394710, 0.101562 (1.408 sec)
19.180... logprob:  0.466383, 0.125000 (1.421 sec)
19.181... logprob:  0.539372, 0.156250 (1.421 sec)
19.182... logprob:  0.371374, 0.093750 (1.417 sec)
19.183... logprob:  0.419953, 0.109375 (1.429 sec)
19.184... logprob:  0.483465, 0.132812 (1.425 sec)
19.185... logprob:  0.289843, 0.062500 (1.392 sec)
19.186... logprob:  0.370473, 0.093750 (1.398 sec)
19.187... logprob:  0.529625, 0.148438 (1.407 sec)
19.188... logprob:  0.458959, 0.125000 (1.403 sec)
19.189... logprob:  0.440909, 0.117188 (1.389 sec)
19.190... logprob:  0.375755, 0.093750 (1.438 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.678314208984375, 10.0]}, 128)
batch 872: ({'logprob': [67.02841186523438, 19.0]}, 128)
batch 873: ({'logprob': [40.128475189208984, 9.0]}, 128)
batch 874: ({'logprob': [45.06666564941406, 11.0]}, 128)
batch 875: ({'logprob': [50.72524642944336, 13.0]}, 128)
batch 876: ({'logprob': [64.3980712890625, 18.0]}, 128)
batch 877: ({'logprob': [45.43415069580078, 11.0]}, 128)
batch 878: ({'logprob': [62.0881233215332, 17.0]}, 128)
batch 879: ({'logprob': [73.77787780761719, 21.0]}, 128)
batch 880: ({'logprob': [50.74525451660156, 13.0]}, 128)
batch 881: ({'logprob': [28.404909133911133, 5.0]}, 128)
batch 882: ({'logprob': [54.483821868896484, 14.0]}, 128)
batch 883: ({'logprob': [62.06843185424805, 17.0]}, 128)
batch 884: ({'logprob': [51.09202194213867, 13.0]}, 128)
batch 885: ({'logprob': [51.81724166870117, 13.0]}, 128)
batch 886: ({'logprob': [62.44526290893555, 17.0]}, 128)

======================Test output======================
logprob:  0.415714, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.967197e-03 [2.479130e-09] 
Layer 'conv1' biases: 1.970260e-07 [4.506664e-11] 
Layer 'conv2' weights[0]: 7.954257e-03 [1.635318e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.290123e-10] 
Layer 'conv3' weights[0]: 7.952566e-03 [1.207962e-09] 
Layer 'conv3' biases: 1.700584e-06 [3.383411e-10] 
Layer 'conv4' weights[0]: 7.985154e-03 [1.156775e-09] 
Layer 'conv4' biases: 9.999994e-01 [5.775193e-10] 
Layer 'conv5' weights[0]: 7.984012e-03 [2.788431e-09] 
Layer 'conv5' biases: 9.999959e-01 [2.481320e-09] 
Layer 'fc6' weights[0]: 7.580745e-03 [7.839401e-10] 
Layer 'fc6' biases: 1.000000e+00 [1.984670e-10] 
Layer 'fc7' weights[0]: 7.248734e-03 [3.680211e-08] 
Layer 'fc7' biases: 9.998630e-01 [5.997761e-09] 
Layer 'fc8' weights[0]: 1.327339e-03 [8.811830e-07] 
Layer 'fc8' biases: 4.483471e-02 [4.771006e-06] 
Train error last 870 batches: 0.435244
-------------------------------------------------------
Not saving because 0.415714 > 0.415685 (17.630: -0.01%)
======================================================= (12.221 sec)
19.191... logprob:  0.485097, 0.132812 (1.418 sec)
19.192... logprob:  0.520131, 0.148438 (1.427 sec)
19.193... logprob:  0.312590, 0.070312 (1.420 sec)
19.194... logprob:  0.414099, 0.109375 (1.428 sec)
19.195... logprob:  0.287183, 0.062500 (1.401 sec)
19.196... logprob:  0.410530, 0.109375 (1.396 sec)
19.197... logprob:  0.478016, 0.132812 (1.406 sec)
19.198... logprob:  0.355794, 0.085938 (1.409 sec)
19.199... logprob:  0.437193, 0.117188 (1.394 sec)
19.200... logprob:  0.440762, 0.117188 (1.443 sec)
19.201... logprob:  0.437096, 0.117188 (1.403 sec)
19.202... logprob:  0.537937, 0.148438 (1.410 sec)
19.203... logprob:  0.420445, 0.109375 (1.447 sec)
19.204... logprob:  0.504124, 0.140625 (1.417 sec)
19.205... logprob:  0.334362, 0.078125 (1.402 sec)
19.206... logprob:  0.361631, 0.093750 (1.399 sec)
19.207... logprob:  0.381866, 0.093750 (1.489 sec)
19.208... logprob:  0.490536, 0.140625 (1.409 sec)
19.209... logprob:  0.334581, 0.078125 (1.419 sec)
19.210... logprob:  0.586242, 0.171875 (1.421 sec)
19.211... logprob:  0.488175, 0.132812 (1.411 sec)
19.212... logprob:  0.526144, 0.148438 (1.413 sec)
19.213... logprob:  0.514755, 0.140625 (1.463 sec)
19.214... logprob:  0.459426, 0.125000 (1.425 sec)
19.215... logprob:  0.396135, 0.101562 (1.417 sec)
19.216... logprob:  0.517058, 0.140625 (1.473 sec)
19.217... logprob:  0.325041, 0.070312 (1.407 sec)
19.218... logprob:  0.463670, 0.125000 (1.428 sec)
19.219... logprob:  0.500286, 0.140625 (1.414 sec)
19.220... logprob:  0.415005, 0.109375 (1.423 sec)
19.221... logprob:  0.399548, 0.101562 (1.403 sec)
19.222... logprob:  0.554533, 0.164062 (1.457 sec)
19.223... logprob:  0.569154, 0.164062 (1.427 sec)
19.224... logprob:  0.405902, 0.101562 (1.436 sec)
19.225... logprob:  0.391977, 0.101562 (1.447 sec)
19.226... logprob:  0.424664, 0.109375 (1.428 sec)
19.227... logprob:  0.452702, 0.125000 (1.412 sec)
19.228... logprob:  0.417188, 0.109375 (1.420 sec)
19.229... logprob:  0.489371, 0.132812 (1.416 sec)
19.230... logprob:  0.459885, 0.125000 (1.440 sec)
19.231... logprob:  0.453529, 0.125000 (1.411 sec)
19.232... logprob:  0.496210, 0.140625 (1.460 sec)
19.233... logprob:  0.466136, 0.132812 (1.430 sec)
19.234... logprob:  0.563819, 0.164062 (1.412 sec)
19.235... logprob:  0.482025, 0.132812 (1.473 sec)
19.236... logprob:  0.425756, 0.109375 (1.405 sec)
19.237... logprob:  0.341221, 0.078125 (1.423 sec)
19.238... logprob:  0.389306, 0.093750 (1.415 sec)
19.239... logprob:  0.478126, 0.132812 (1.424 sec)
19.240... logprob:  0.485803, 0.132812 (1.400 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.32295608520508, 10.0]}, 128)
batch 872: ({'logprob': [66.07523345947266, 19.0]}, 128)
batch 873: ({'logprob': [41.3679313659668, 9.0]}, 128)
batch 874: ({'logprob': [45.72159194946289, 11.0]}, 128)
batch 875: ({'logprob': [51.04058837890625, 13.0]}, 128)
batch 876: ({'logprob': [63.67497634887695, 18.0]}, 128)
batch 877: ({'logprob': [46.211978912353516, 11.0]}, 128)
batch 878: ({'logprob': [61.719417572021484, 17.0]}, 128)
batch 879: ({'logprob': [72.84648895263672, 21.0]}, 128)
batch 880: ({'logprob': [51.05952072143555, 13.0]}, 128)
batch 881: ({'logprob': [30.207904815673828, 5.0]}, 128)
batch 882: ({'logprob': [54.929039001464844, 14.0]}, 128)
batch 883: ({'logprob': [61.70009231567383, 17.0]}, 128)
batch 884: ({'logprob': [51.52554702758789, 13.0]}, 128)
batch 885: ({'logprob': [52.49301528930664, 13.0]}, 128)
batch 886: ({'logprob': [62.196311950683594, 17.0]}, 128)

======================Test output======================
logprob:  0.417526, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.967163e-03 [2.526425e-09] 
Layer 'conv1' biases: 1.978529e-07 [5.272687e-11] 
Layer 'conv2' weights[0]: 7.954222e-03 [1.575070e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.541061e-10] 
Layer 'conv3' weights[0]: 7.952522e-03 [1.240973e-09] 
Layer 'conv3' biases: 1.708053e-06 [4.531411e-10] 
Layer 'conv4' weights[0]: 7.985117e-03 [1.179598e-09] 
Layer 'conv4' biases: 9.999994e-01 [2.608447e-09] 
Layer 'conv5' weights[0]: 7.983974e-03 [1.235722e-08] 
Layer 'conv5' biases: 9.999962e-01 [1.288214e-08] 
Layer 'fc6' weights[0]: 7.580707e-03 [1.308549e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.047493e-09] 
Layer 'fc7' weights[0]: 7.246973e-03 [7.596178e-08] 
Layer 'fc7' biases: 9.998623e-01 [5.957436e-08] 
Layer 'fc8' weights[0]: 1.296181e-03 [2.468977e-06] 
Layer 'fc8' biases: 4.466815e-02 [1.767970e-05] 
Train error last 870 batches: 0.435244
-------------------------------------------------------
Not saving because 0.417526 > 0.415685 (17.630: -0.01%)
======================================================= (12.117 sec)
19.241... logprob:  0.493603, 0.132812 (1.473 sec)
19.242... logprob:  0.341650, 0.078125 (1.437 sec)
19.243... logprob:  0.386013, 0.093750 (1.435 sec)
19.244... logprob:  0.315281, 0.070312 (1.447 sec)
19.245... logprob:  0.494310, 0.132812 (1.429 sec)
19.246... logprob:  0.416888, 0.109375 (1.415 sec)
19.247... logprob:  0.357418, 0.085938 (1.419 sec)
19.248... logprob:  0.307835, 0.070312 (1.417 sec)
19.249... logprob:  0.555193, 0.156250 (1.420 sec)
19.250... logprob:  0.591591, 0.164062 (1.412 sec)
19.251... logprob:  0.352933, 0.085938 (1.457 sec)
19.252... logprob:  0.348472, 0.085938 (1.515 sec)
19.253... logprob:  0.379187, 0.093750 (1.414 sec)
19.254... logprob:  0.444175, 0.117188 (1.469 sec)
19.255... logprob:  0.351441, 0.085938 (1.403 sec)
19.256... logprob:  0.378778, 0.093750 (1.428 sec)
19.257... logprob:  0.332024, 0.078125 (1.416 sec)
19.258... logprob:  0.415695, 0.109375 (1.422 sec)
19.259... logprob:  0.442312, 0.117188 (1.403 sec)
19.260... logprob:  0.308333, 0.070312 (1.458 sec)
19.261... logprob:  0.392738, 0.101562 (1.429 sec)
19.262... logprob:  0.524625, 0.148438 (1.434 sec)
19.263... logprob:  0.425507, 0.109375 (1.445 sec)
19.264... logprob:  0.375116, 0.093750 (1.428 sec)
19.265... logprob:  0.439613, 0.117188 (1.416 sec)
19.266... logprob:  0.439027, 0.117188 (1.418 sec)
19.267... logprob:  0.422012, 0.109375 (1.414 sec)
19.268... logprob:  0.458941, 0.125000 (1.426 sec)
19.269... logprob:  0.567496, 0.164062 (1.412 sec)
19.270... logprob:  0.542244, 0.156250 (1.467 sec)
19.271... logprob:  0.445705, 0.117188 (1.422 sec)
19.272... logprob:  0.384706, 0.093750 (1.417 sec)
19.273... logprob:  0.500221, 0.140625 (1.474 sec)
19.274... logprob:  0.542519, 0.156250 (1.400 sec)
19.275... logprob:  0.487685, 0.132812 (1.426 sec)
19.276... logprob:  0.390129, 0.093750 (1.415 sec)
19.277... logprob:  0.428686, 0.109375 (1.428 sec)
19.278... logprob:  0.323461, 0.070312 (1.417 sec)
19.279... logprob:  0.325057, 0.070312 (1.470 sec)
19.280... logprob:  0.215404, 0.031250 (1.403 sec)
19.281... logprob:  0.417223, 0.109375 (1.423 sec)
19.282... logprob:  0.411419, 0.109375 (1.423 sec)
19.283... logprob:  0.393821, 0.101562 (1.416 sec)
19.284... logprob:  0.394603, 0.101562 (1.413 sec)
19.285... logprob:  0.451947, 0.117188 (1.441 sec)
19.286... logprob:  0.537160, 0.140625 (1.443 sec)
19.287... logprob:  0.346634, 0.085938 (1.428 sec)
19.288... logprob:  0.329967, 0.078125 (1.442 sec)
19.289... logprob:  0.445962, 0.117188 (1.441 sec)
19.290... logprob:  0.490657, 0.132812 (1.411 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.97746658325195, 10.0]}, 128)
batch 872: ({'logprob': [68.59359741210938, 19.0]}, 128)
batch 873: ({'logprob': [39.435367584228516, 9.0]}, 128)
batch 874: ({'logprob': [44.73526382446289, 11.0]}, 128)
batch 875: ({'logprob': [50.90420150756836, 13.0]}, 128)
batch 876: ({'logprob': [65.74596405029297, 18.0]}, 128)
batch 877: ({'logprob': [45.17609405517578, 11.0]}, 128)
batch 878: ({'logprob': [63.29133224487305, 17.0]}, 128)
batch 879: ({'logprob': [76.0793685913086, 21.0]}, 128)
batch 880: ({'logprob': [50.92473220825195, 13.0]}, 128)
batch 881: ({'logprob': [26.611522674560547, 5.0]}, 128)
batch 882: ({'logprob': [55.108673095703125, 14.0]}, 128)
batch 883: ({'logprob': [63.271366119384766, 17.0]}, 128)
batch 884: ({'logprob': [51.349117279052734, 13.0]}, 128)
batch 885: ({'logprob': [52.22483825683594, 13.0]}, 128)
batch 886: ({'logprob': [63.725284576416016, 17.0]}, 128)

======================Test output======================
logprob:  0.419021, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.967120e-03 [5.678901e-09] 
Layer 'conv1' biases: 1.987879e-07 [1.927694e-10] 
Layer 'conv2' weights[0]: 7.954184e-03 [4.735327e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.011830e-09] 
Layer 'conv3' weights[0]: 7.952479e-03 [4.659431e-09] 
Layer 'conv3' biases: 1.714468e-06 [3.074225e-09] 
Layer 'conv4' weights[0]: 7.985070e-03 [4.800187e-09] 
Layer 'conv4' biases: 9.999995e-01 [2.687361e-08] 
Layer 'conv5' weights[0]: 7.983931e-03 [1.755815e-07] 
Layer 'conv5' biases: 9.999961e-01 [1.892596e-07] 
Layer 'fc6' weights[0]: 7.580671e-03 [1.489932e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.521252e-08] 
Layer 'fc7' weights[0]: 7.245070e-03 [2.770796e-07] 
Layer 'fc7' biases: 9.998639e-01 [2.674053e-07] 
Layer 'fc8' weights[0]: 1.373956e-03 [1.095040e-05] 
Layer 'fc8' biases: 4.539291e-02 [5.809674e-05] 
Train error last 870 batches: 0.435243
-------------------------------------------------------
Not saving because 0.419021 > 0.415685 (17.630: -0.01%)
======================================================= (12.029 sec)
19.291... logprob:  0.439204, 0.117188 (1.424 sec)
19.292... logprob:  0.567228, 0.156250 (1.426 sec)
19.293... logprob:  0.427564, 0.117188 (1.432 sec)
19.294... logprob:  0.356060, 0.085938 (1.403 sec)
19.295... logprob:  0.334900, 0.078125 (1.463 sec)
19.296... logprob:  0.355996, 0.085938 (1.431 sec)
19.297... logprob:  0.394677, 0.101562 (1.423 sec)
19.298... logprob:  0.448146, 0.125000 (1.466 sec)
19.299... logprob:  0.342444, 0.078125 (1.407 sec)
19.300... logprob:  0.406597, 0.101562 (1.424 sec)
19.301... logprob:  0.397944, 0.101562 (1.421 sec)
19.302... logprob:  0.591552, 0.179688 (1.441 sec)
19.303... logprob:  0.459591, 0.125000 (1.420 sec)
19.304... logprob:  0.459681, 0.125000 (1.439 sec)
19.305... logprob:  0.455226, 0.125000 (1.434 sec)
19.306... logprob:  0.440600, 0.117188 (1.441 sec)
19.307... logprob:  0.421607, 0.109375 (1.446 sec)
19.308... logprob:  0.374636, 0.093750 (1.453 sec)
19.309... logprob:  0.450487, 0.125000 (1.421 sec)
19.310... logprob:  0.473710, 0.125000 (1.419 sec)
19.311... logprob:  0.502610, 0.140625 (1.436 sec)
19.312... logprob:  0.478763, 0.132812 (1.425 sec)
19.313... logprob:  0.454868, 0.125000 (1.427 sec)
19.314... logprob:  0.454467, 0.117188 (1.463 sec)
19.315... logprob:  0.314682, 0.070312 (1.435 sec)
19.316... logprob:  0.468561, 0.125000 (1.423 sec)
19.317... logprob:  0.355494, 0.085938 (1.480 sec)
19.318... logprob:  0.455414, 0.125000 (1.413 sec)
19.319... logprob:  0.423198, 0.117188 (1.431 sec)
19.320... logprob:  0.412255, 0.109375 (1.423 sec)
19.321... logprob:  0.348278, 0.085938 (1.430 sec)
19.322... logprob:  0.387499, 0.101562 (1.419 sec)
19.323... logprob:  0.416519, 0.109375 (1.478 sec)
19.324... logprob:  0.498621, 0.140625 (1.424 sec)
19.325... logprob:  0.350680, 0.085938 (1.439 sec)
19.326... logprob:  0.543186, 0.148438 (1.460 sec)
19.327... logprob:  0.554403, 0.164062 (1.508 sec)
19.328... logprob:  0.565044, 0.156250 (1.427 sec)
19.329... logprob:  0.401977, 0.101562 (1.428 sec)
19.330... logprob:  0.388622, 0.101562 (1.418 sec)
19.331... logprob:  0.352465, 0.085938 (1.420 sec)
19.332... logprob:  0.482785, 0.132812 (1.454 sec)
19.333... logprob:  0.339600, 0.085938 (1.444 sec)
19.334... logprob:  0.565153, 0.171875 (1.444 sec)
19.335... logprob:  0.358817, 0.085938 (1.443 sec)
19.336... logprob:  0.444839, 0.125000 (1.464 sec)
19.337... logprob:  0.566456, 0.164062 (1.423 sec)
19.338... logprob:  0.449515, 0.125000 (1.426 sec)
19.339... logprob:  0.488673, 0.132812 (1.422 sec)
19.340... logprob:  0.442074, 0.117188 (1.440 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.3189811706543, 10.0]}, 128)
batch 872: ({'logprob': [65.78245544433594, 19.0]}, 128)
batch 873: ({'logprob': [42.10639190673828, 9.0]}, 128)
batch 874: ({'logprob': [46.006065368652344, 11.0]}, 128)
batch 875: ({'logprob': [51.28504943847656, 13.0]}, 128)
batch 876: ({'logprob': [63.504974365234375, 18.0]}, 128)
batch 877: ({'logprob': [46.702999114990234, 11.0]}, 128)
batch 878: ({'logprob': [61.88043975830078, 17.0]}, 128)
batch 879: ({'logprob': [73.1300048828125, 21.0]}, 128)
batch 880: ({'logprob': [51.3028450012207, 13.0]}, 128)
batch 881: ({'logprob': [30.823650360107422, 5.0]}, 128)
batch 882: ({'logprob': [55.66702651977539, 14.0]}, 128)
batch 883: ({'logprob': [61.86160659790039, 17.0]}, 128)
batch 884: ({'logprob': [51.97489547729492, 13.0]}, 128)
batch 885: ({'logprob': [53.35481643676758, 13.0]}, 128)
batch 886: ({'logprob': [62.563114166259766, 17.0]}, 128)

======================Test output======================
logprob:  0.420051, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.967079e-03 [2.671432e-09] 
Layer 'conv1' biases: 1.996379e-07 [3.832415e-11] 
Layer 'conv2' weights[0]: 7.954144e-03 [1.785226e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.578924e-10] 
Layer 'conv3' weights[0]: 7.952438e-03 [1.354378e-09] 
Layer 'conv3' biases: 1.721965e-06 [4.914673e-10] 
Layer 'conv4' weights[0]: 7.985034e-03 [1.289998e-09] 
Layer 'conv4' biases: 9.999994e-01 [2.719967e-09] 
Layer 'conv5' weights[0]: 7.983882e-03 [1.343762e-08] 
Layer 'conv5' biases: 9.999962e-01 [1.421477e-08] 
Layer 'fc6' weights[0]: 7.580626e-03 [1.393728e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.157653e-09] 
Layer 'fc7' weights[0]: 7.243237e-03 [3.670398e-08] 
Layer 'fc7' biases: 9.998625e-01 [5.313311e-09] 
Layer 'fc8' weights[0]: 1.285560e-03 [1.375762e-06] 
Layer 'fc8' biases: 4.497205e-02 [8.180694e-06] 
Train error last 870 batches: 0.435243
-------------------------------------------------------
Not saving because 0.420051 > 0.415685 (17.630: -0.01%)
======================================================= (12.155 sec)
19.341... logprob:  0.530115, 0.148438 (1.425 sec)
19.342... logprob:  0.429658, 0.109375 (1.466 sec)
19.343... logprob:  0.434778, 0.109375 (1.439 sec)
19.344... logprob:  0.444450, 0.125000 (1.486 sec)
19.345... logprob:  0.488242, 0.132812 (1.438 sec)
19.346... logprob:  0.436233, 0.117188 (1.441 sec)
19.347... logprob:  0.372399, 0.085938 (1.484 sec)
19.348... logprob:  0.398448, 0.101562 (1.436 sec)
19.349... logprob:  0.497804, 0.140625 (1.430 sec)
19.350... logprob:  0.358589, 0.085938 (1.441 sec)
19.351... logprob:  0.508628, 0.140625 (1.429 sec)
19.352... logprob:  0.363648, 0.093750 (1.438 sec)
19.353... logprob:  0.512705, 0.148438 (1.487 sec)
19.354... logprob:  0.675053, 0.203125 (1.435 sec)
19.355... logprob:  0.357480, 0.085938 (1.443 sec)
19.356... logprob:  0.479246, 0.132812 (1.483 sec)
19.357... logprob:  0.346958, 0.085938 (1.432 sec)
19.358... logprob:  0.325957, 0.070312 (1.442 sec)
19.359... logprob:  0.555261, 0.164062 (1.431 sec)
19.360... logprob:  0.444516, 0.117188 (1.432 sec)
19.361... logprob:  0.410769, 0.101562 (1.430 sec)
19.362... logprob:  0.424084, 0.117188 (1.482 sec)
19.363... logprob:  0.486583, 0.132812 (1.441 sec)
19.364... logprob:  0.475559, 0.125000 (1.458 sec)
19.365... logprob:  0.425075, 0.109375 (1.465 sec)
19.366... logprob:  0.409664, 0.109375 (1.441 sec)
19.367... logprob:  0.324978, 0.078125 (1.436 sec)
19.368... logprob:  0.595654, 0.171875 (1.430 sec)
19.369... logprob:  0.381569, 0.093750 (1.432 sec)
19.370... logprob:  0.381197, 0.093750 (1.437 sec)
19.371... logprob:  0.400367, 0.101562 (1.461 sec)
19.372... logprob:  0.537504, 0.156250 (1.453 sec)
19.373... logprob:  0.463818, 0.125000 (1.460 sec)
19.374... logprob:  0.527011, 0.148438 (1.453 sec)
19.375... logprob:  0.393778, 0.101562 (1.463 sec)
19.376... logprob:  0.374306, 0.093750 (1.437 sec)
19.377... logprob:  0.295391, 0.062500 (1.431 sec)
19.378... logprob:  0.453742, 0.125000 (1.431 sec)
19.379... logprob:  0.420239, 0.109375 (1.436 sec)
19.380... logprob:  0.605739, 0.179688 (1.442 sec)
19.381... logprob:  0.463464, 0.125000 (1.471 sec)
19.382... logprob:  0.529524, 0.148438 (1.455 sec)
19.383... logprob:  0.358651, 0.085938 (1.438 sec)
19.384... logprob:  0.521089, 0.148438 (1.486 sec)
19.385... logprob:  0.523496, 0.148438 (1.432 sec)
19.386... logprob:  0.582397, 0.171875 (1.428 sec)
19.387... logprob:  0.428640, 0.117188 (1.437 sec)
19.388... logprob:  0.521325, 0.148438 (1.441 sec)
19.389... logprob:  0.425824, 0.109375 (1.430 sec)
19.390... logprob:  0.419867, 0.109375 (1.475 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.845542907714844, 10.0]}, 128)
batch 872: ({'logprob': [65.84571075439453, 19.0]}, 128)
batch 873: ({'logprob': [42.90993118286133, 9.0]}, 128)
batch 874: ({'logprob': [46.96986770629883, 11.0]}, 128)
batch 875: ({'logprob': [51.895423889160156, 13.0]}, 128)
batch 876: ({'logprob': [63.61660385131836, 18.0]}, 128)
batch 877: ({'logprob': [47.41131591796875, 11.0]}, 128)
batch 878: ({'logprob': [61.783905029296875, 17.0]}, 128)
batch 879: ({'logprob': [72.07073974609375, 21.0]}, 128)
batch 880: ({'logprob': [51.91392135620117, 13.0]}, 128)
batch 881: ({'logprob': [32.59196853637695, 5.0]}, 128)
batch 882: ({'logprob': [55.45757293701172, 14.0]}, 128)
batch 883: ({'logprob': [61.76472854614258, 17.0]}, 128)
batch 884: ({'logprob': [52.32686996459961, 13.0]}, 128)
batch 885: ({'logprob': [53.19252014160156, 13.0]}, 128)
batch 886: ({'logprob': [62.2085075378418, 17.0]}, 128)

======================Test output======================
logprob:  0.422756, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.967033e-03 [2.657984e-09] 
Layer 'conv1' biases: 2.006494e-07 [1.218924e-10] 
Layer 'conv2' weights[0]: 7.954108e-03 [2.828830e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.235923e-10] 
Layer 'conv3' weights[0]: 7.952394e-03 [3.000818e-09] 
Layer 'conv3' biases: 1.729858e-06 [1.865891e-09] 
Layer 'conv4' weights[0]: 7.985003e-03 [3.223055e-09] 
Layer 'conv4' biases: 9.999994e-01 [1.803945e-08] 
Layer 'conv5' weights[0]: 7.983855e-03 [1.205553e-07] 
Layer 'conv5' biases: 9.999964e-01 [1.304027e-07] 
Layer 'fc6' weights[0]: 7.580596e-03 [1.006459e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.020947e-08] 
Layer 'fc7' weights[0]: 7.241449e-03 [4.734682e-08] 
Layer 'fc7' biases: 9.998614e-01 [2.521174e-08] 
Layer 'fc8' weights[0]: 1.260484e-03 [2.572891e-06] 
Layer 'fc8' biases: 4.488957e-02 [1.871878e-05] 
Train error last 870 batches: 0.435243
-------------------------------------------------------
Not saving because 0.422756 > 0.415685 (17.630: -0.01%)
======================================================= (11.986 sec)
19.391... logprob:  0.318326, 0.070312 (1.451 sec)
19.392... logprob:  0.439434, 0.117188 (1.434 sec)
19.393... logprob:  0.368890, 0.093750 (1.488 sec)
19.394... logprob:  0.343533, 0.078125 (1.436 sec)
19.395... logprob:  0.331635, 0.078125 (1.431 sec)
19.396... logprob:  0.252018, 0.046875 (1.437 sec)
19.397... logprob:  0.484583, 0.132812 (1.435 sec)
19.398... logprob:  0.471263, 0.125000 (1.432 sec)
19.399... logprob:  0.433598, 0.117188 (1.493 sec)
19.400... logprob:  0.538327, 0.148438 (1.433 sec)
19.401... logprob:  0.466066, 0.125000 (1.445 sec)
19.402... logprob:  0.474176, 0.125000 (1.479 sec)
19.403... logprob:  0.462214, 0.125000 (1.433 sec)
19.404... logprob:  0.474829, 0.125000 (1.441 sec)
19.405... logprob:  0.543944, 0.156250 (1.435 sec)
19.406... logprob:  0.357825, 0.085938 (1.432 sec)
19.407... logprob:  0.492759, 0.140625 (1.432 sec)
19.408... logprob:  0.339548, 0.078125 (1.484 sec)
19.409... logprob:  0.400872, 0.101562 (1.475 sec)
19.410... logprob:  0.581857, 0.171875 (1.449 sec)
19.411... logprob:  0.398175, 0.101562 (1.474 sec)
19.412... logprob:  0.540229, 0.156250 (1.441 sec)
19.413... logprob:  0.544697, 0.156250 (1.437 sec)
19.414... logprob:  0.466577, 0.125000 (1.435 sec)
19.415... logprob:  0.401768, 0.101562 (1.424 sec)
19.416... logprob:  0.427556, 0.109375 (1.443 sec)
19.417... logprob:  0.405430, 0.093750 (1.462 sec)
19.418... logprob:  0.380159, 0.093750 (1.455 sec)
19.419... logprob:  0.417621, 0.101562 (1.455 sec)
19.420... logprob:  0.355995, 0.085938 (1.455 sec)
19.421... logprob:  0.376553, 0.101562 (1.461 sec)
19.422... logprob:  0.522915, 0.148438 (1.437 sec)
19.423... logprob:  0.420994, 0.109375 (1.427 sec)
19.424... logprob:  0.324657, 0.078125 (1.436 sec)
19.425... logprob:  0.306187, 0.070312 (1.436 sec)
19.426... logprob:  0.449363, 0.117188 (1.450 sec)
19.427... logprob:  0.554874, 0.156250 (1.462 sec)
19.428... logprob:  0.602210, 0.171875 (1.456 sec)
19.429... logprob:  0.426289, 0.109375 (1.446 sec)
19.430... logprob:  0.299934, 0.070312 (1.476 sec)
19.431... logprob:  0.599415, 0.171875 (1.438 sec)
19.432... logprob:  0.387587, 0.093750 (1.428 sec)
19.433... logprob:  0.330156, 0.078125 (1.435 sec)
19.434... logprob:  0.529178, 0.148438 (1.437 sec)
19.435... logprob:  0.532116, 0.156250 (1.439 sec)
19.436... logprob:  0.381492, 0.093750 (1.475 sec)
19.437... logprob:  0.500237, 0.140625 (1.449 sec)
19.438... logprob:  0.546801, 0.156250 (1.430 sec)
19.439... logprob:  0.379128, 0.093750 (1.492 sec)
19.440... logprob:  0.439856, 0.117188 (1.434 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.58171844482422, 10.0]}, 128)
batch 872: ({'logprob': [65.83279418945312, 19.0]}, 128)
batch 873: ({'logprob': [42.668697357177734, 9.0]}, 128)
batch 874: ({'logprob': [46.75679016113281, 11.0]}, 128)
batch 875: ({'logprob': [51.73967742919922, 13.0]}, 128)
batch 876: ({'logprob': [63.582183837890625, 18.0]}, 128)
batch 877: ({'logprob': [47.21257400512695, 11.0]}, 128)
batch 878: ({'logprob': [61.7426872253418, 17.0]}, 128)
batch 879: ({'logprob': [72.15889739990234, 21.0]}, 128)
batch 880: ({'logprob': [51.75794219970703, 13.0]}, 128)
batch 881: ({'logprob': [32.22125244140625, 5.0]}, 128)
batch 882: ({'logprob': [55.3672981262207, 14.0]}, 128)
batch 883: ({'logprob': [61.7237548828125, 17.0]}, 128)
batch 884: ({'logprob': [52.18611145019531, 13.0]}, 128)
batch 885: ({'logprob': [53.08112716674805, 13.0]}, 128)
batch 886: ({'logprob': [62.18216323852539, 17.0]}, 128)

======================Test output======================
logprob:  0.421775, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.966989e-03 [3.856664e-09] 
Layer 'conv1' biases: 2.014216e-07 [9.234716e-11] 
Layer 'conv2' weights[0]: 7.954065e-03 [2.905540e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.336497e-10] 
Layer 'conv3' weights[0]: 7.952352e-03 [2.789244e-09] 
Layer 'conv3' biases: 1.735850e-06 [1.680133e-09] 
Layer 'conv4' weights[0]: 7.984966e-03 [2.974042e-09] 
Layer 'conv4' biases: 9.999995e-01 [1.603950e-08] 
Layer 'conv5' weights[0]: 7.983815e-03 [1.072378e-07] 
Layer 'conv5' biases: 9.999963e-01 [1.158507e-07] 
Layer 'fc6' weights[0]: 7.580558e-03 [8.995131e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.065725e-09] 
Layer 'fc7' weights[0]: 7.239615e-03 [4.295267e-08] 
Layer 'fc7' biases: 9.998616e-01 [1.891570e-08] 
Layer 'fc8' weights[0]: 1.259187e-03 [5.285711e-07] 
Layer 'fc8' biases: 4.529702e-02 [9.610279e-06] 
Train error last 870 batches: 0.435242
-------------------------------------------------------
Not saving because 0.421775 > 0.415685 (17.630: -0.01%)
======================================================= (12.125 sec)
19.441... logprob:  0.468034, 0.125000 (1.445 sec)
19.442... logprob:  0.378930, 0.093750 (1.461 sec)
19.443... logprob:  0.496583, 0.140625 (1.430 sec)
19.444... logprob:  0.372139, 0.093750 (1.437 sec)
19.445... logprob:  0.362221, 0.085938 (1.484 sec)
19.446... logprob:  0.398134, 0.101562 (1.438 sec)
19.447... logprob:  0.570264, 0.164062 (1.439 sec)
19.448... logprob:  0.332555, 0.078125 (1.486 sec)
19.449... logprob:  0.400022, 0.101562 (1.432 sec)
19.450... logprob:  0.238928, 0.046875 (1.438 sec)
19.451... logprob:  0.452978, 0.125000 (1.434 sec)
19.452... logprob:  0.456339, 0.117188 (1.430 sec)
19.453... logprob:  0.455482, 0.125000 (1.440 sec)
19.454... logprob:  0.489218, 0.132812 (1.483 sec)
19.455... logprob:  0.506134, 0.140625 (1.441 sec)
19.456... logprob:  0.468813, 0.125000 (1.447 sec)
19.457... logprob:  0.375380, 0.093750 (1.477 sec)
19.458... logprob:  0.351186, 0.085938 (1.436 sec)
19.459... logprob:  0.513702, 0.140625 (1.443 sec)
19.460... logprob:  0.274490, 0.054688 (1.430 sec)
19.461... logprob:  0.459996, 0.125000 (1.428 sec)
19.462... logprob:  0.471904, 0.125000 (1.440 sec)
19.463... logprob:  0.420933, 0.109375 (1.466 sec)
19.464... logprob:  0.482691, 0.132812 (1.445 sec)
19.465... logprob:  0.421207, 0.109375 (1.455 sec)
19.466... logprob:  0.318612, 0.070312 (1.459 sec)
19.467... logprob:  0.413868, 0.109375 (1.455 sec)
19.468... logprob:  0.394277, 0.101562 (1.438 sec)
19.469... logprob:  0.334673, 0.078125 (1.433 sec)
19.470... logprob:  0.400059, 0.101562 (1.429 sec)
19.471... logprob:  0.529581, 0.148438 (1.440 sec)
19.472... logprob:  0.410067, 0.109375 (1.451 sec)
19.473... logprob:  0.375356, 0.093750 (1.461 sec)
19.474... logprob:  0.465772, 0.125000 (1.458 sec)
19.475... logprob:  0.504362, 0.140625 (1.451 sec)
19.476... logprob:  0.510455, 0.140625 (1.468 sec)
19.477... logprob:  0.334515, 0.078125 (1.445 sec)
19.478... logprob:  0.464285, 0.125000 (1.426 sec)
19.479... logprob:  0.305786, 0.070312 (1.435 sec)
19.480... logprob:  0.443517, 0.117188 (1.438 sec)
19.481... logprob:  0.547755, 0.156250 (1.439 sec)
19.482... logprob:  0.443177, 0.117188 (1.478 sec)
19.483... logprob:  0.502590, 0.140625 (1.447 sec)
19.484... logprob:  0.485291, 0.132812 (1.434 sec)
19.485... logprob:  0.409072, 0.109375 (1.481 sec)
19.486... logprob:  0.361580, 0.085938 (1.435 sec)
19.487... logprob:  0.522621, 0.148438 (1.432 sec)
19.488... logprob:  0.424868, 0.109375 (1.438 sec)
19.489... logprob:  0.415938, 0.109375 (1.433 sec)
19.490... logprob:  0.440701, 0.117188 (1.434 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.595252990722656, 10.0]}, 128)
batch 872: ({'logprob': [66.17027282714844, 19.0]}, 128)
batch 873: ({'logprob': [41.33399200439453, 9.0]}, 128)
batch 874: ({'logprob': [45.8271598815918, 11.0]}, 128)
batch 875: ({'logprob': [51.09611129760742, 13.0]}, 128)
batch 876: ({'logprob': [63.74769973754883, 18.0]}, 128)
batch 877: ({'logprob': [46.22296142578125, 11.0]}, 128)
batch 878: ({'logprob': [61.675331115722656, 17.0]}, 128)
batch 879: ({'logprob': [72.60883331298828, 21.0]}, 128)
batch 880: ({'logprob': [51.11528778076172, 13.0]}, 128)
batch 881: ({'logprob': [30.368356704711914, 5.0]}, 128)
batch 882: ({'logprob': [54.723426818847656, 14.0]}, 128)
batch 883: ({'logprob': [61.65599060058594, 17.0]}, 128)
batch 884: ({'logprob': [51.48677062988281, 13.0]}, 128)
batch 885: ({'logprob': [52.26511001586914, 13.0]}, 128)
batch 886: ({'logprob': [62.057708740234375, 17.0]}, 128)

======================Test output======================
logprob:  0.417456, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.966946e-03 [2.336177e-09] 
Layer 'conv1' biases: 2.021651e-07 [5.808188e-11] 
Layer 'conv2' weights[0]: 7.954024e-03 [1.923210e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.036214e-10] 
Layer 'conv3' weights[0]: 7.952316e-03 [1.811010e-09] 
Layer 'conv3' biases: 1.741827e-06 [9.392714e-10] 
Layer 'conv4' weights[0]: 7.984921e-03 [1.974641e-09] 
Layer 'conv4' biases: 9.999995e-01 [8.928797e-09] 
Layer 'conv5' weights[0]: 7.983781e-03 [5.967241e-08] 
Layer 'conv5' biases: 9.999960e-01 [6.443991e-08] 
Layer 'fc6' weights[0]: 7.580513e-03 [5.053491e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.068157e-09] 
Layer 'fc7' weights[0]: 7.237735e-03 [9.183061e-08] 
Layer 'fc7' biases: 9.998623e-01 [7.669932e-08] 
Layer 'fc8' weights[0]: 1.283076e-03 [2.780291e-06] 
Layer 'fc8' biases: 4.567105e-02 [2.000024e-05] 
Train error last 870 batches: 0.435242
-------------------------------------------------------
Not saving because 0.417456 > 0.415685 (17.630: -0.01%)
======================================================= (12.061 sec)
19.491... logprob:  0.313701, 0.070312 (1.483 sec)
19.492... logprob:  0.459597, 0.125000 (1.449 sec)
19.493... logprob:  0.521939, 0.148438 (1.439 sec)
19.494... logprob:  0.450375, 0.125000 (1.483 sec)
19.495... logprob:  0.380569, 0.093750 (1.438 sec)
19.496... logprob:  0.550486, 0.156250 (1.429 sec)
19.497... logprob:  0.467024, 0.125000 (1.432 sec)
19.498... logprob:  0.476325, 0.132812 (1.430 sec)
19.499... logprob:  0.456273, 0.125000 (1.440 sec)
19.500... logprob:  0.355085, 0.085938 (1.489 sec)
19.501... logprob:  0.339109, 0.078125 (1.431 sec)
19.502... logprob:  0.459656, 0.125000 (1.445 sec)
19.503... logprob:  0.400686, 0.101562 (1.481 sec)
19.504... logprob:  0.487335, 0.132812 (1.433 sec)
19.505... logprob:  0.570807, 0.164062 (1.442 sec)
19.506... logprob:  0.479682, 0.132812 (1.436 sec)
19.507... logprob:  0.385125, 0.093750 (1.428 sec)
19.508... logprob:  0.374745, 0.093750 (1.435 sec)
19.509... logprob:  0.323190, 0.070312 (1.478 sec)
19.510... logprob:  0.390483, 0.101562 (1.441 sec)
19.511... logprob:  0.410077, 0.109375 (1.450 sec)
19.512... logprob:  0.470741, 0.125000 (1.468 sec)
19.513... logprob:  0.324974, 0.078125 (1.446 sec)
19.514... logprob:  0.406276, 0.101562 (1.439 sec)
19.515... logprob:  0.455579, 0.125000 (1.440 sec)
19.516... logprob:  0.400394, 0.109375 (1.452 sec)
19.517... logprob:  0.628006, 0.179688 (1.441 sec)
19.518... logprob:  0.437706, 0.117188 (1.458 sec)
19.519... logprob:  0.516149, 0.140625 (1.457 sec)
19.520... logprob:  0.409654, 0.109375 (1.451 sec)
19.521... logprob:  0.427508, 0.109375 (1.457 sec)
19.522... logprob:  0.533082, 0.156250 (1.463 sec)
19.523... logprob:  0.331739, 0.078125 (1.438 sec)
19.524... logprob:  0.437225, 0.117188 (1.431 sec)
19.525... logprob:  0.426064, 0.109375 (1.430 sec)
19.526... logprob:  0.351922, 0.078125 (1.441 sec)
19.527... logprob:  0.504547, 0.140625 (1.439 sec)
19.528... logprob:  0.440506, 0.117188 (1.468 sec)
19.529... logprob:  0.353012, 0.085938 (1.449 sec)
19.530... logprob:  0.440248, 0.117188 (1.439 sec)
19.531... logprob:  0.440002, 0.117188 (1.484 sec)
19.532... logprob:  0.467390, 0.125000 (1.436 sec)
19.533... logprob:  0.560657, 0.164062 (1.427 sec)
19.534... logprob:  0.325803, 0.078125 (1.437 sec)
19.535... logprob:  0.551655, 0.156250 (1.438 sec)
19.536... logprob:  0.507389, 0.140625 (1.434 sec)
19.537... logprob:  0.510072, 0.140625 (1.480 sec)
19.538... logprob:  0.486109, 0.132812 (1.445 sec)
19.539... logprob:  0.296130, 0.062500 (1.435 sec)
19.540... logprob:  0.447179, 0.117188 (1.489 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.441463470458984, 10.0]}, 128)
batch 872: ({'logprob': [66.1631088256836, 19.0]}, 128)
batch 873: ({'logprob': [41.27119827270508, 9.0]}, 128)
batch 874: ({'logprob': [45.738162994384766, 11.0]}, 128)
batch 875: ({'logprob': [51.04304885864258, 13.0]}, 128)
batch 876: ({'logprob': [63.73826217651367, 18.0]}, 128)
batch 877: ({'logprob': [46.16503143310547, 11.0]}, 128)
batch 878: ({'logprob': [61.694541931152344, 17.0]}, 128)
batch 879: ({'logprob': [72.73102569580078, 21.0]}, 128)
batch 880: ({'logprob': [51.062339782714844, 13.0]}, 128)
batch 881: ({'logprob': [30.202320098876953, 5.0]}, 128)
batch 882: ({'logprob': [54.76643371582031, 14.0]}, 128)
batch 883: ({'logprob': [61.674922943115234, 17.0]}, 128)
batch 884: ({'logprob': [51.4650993347168, 13.0]}, 128)
batch 885: ({'logprob': [52.305782318115234, 13.0]}, 128)
batch 886: ({'logprob': [62.108158111572266, 17.0]}, 128)

======================Test output======================
logprob:  0.417271, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.966910e-03 [2.909429e-09] 
Layer 'conv1' biases: 2.030086e-07 [7.641901e-11] 
Layer 'conv2' weights[0]: 7.953988e-03 [1.874232e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.692234e-10] 
Layer 'conv3' weights[0]: 7.952278e-03 [1.893630e-09] 
Layer 'conv3' biases: 1.751038e-06 [1.081276e-09] 
Layer 'conv4' weights[0]: 7.984886e-03 [1.998579e-09] 
Layer 'conv4' biases: 9.999995e-01 [9.155941e-09] 
Layer 'conv5' weights[0]: 7.983737e-03 [5.589330e-08] 
Layer 'conv5' biases: 9.999961e-01 [6.040245e-08] 
Layer 'fc6' weights[0]: 7.580479e-03 [4.811088e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.794426e-09] 
Layer 'fc7' weights[0]: 7.235919e-03 [5.000841e-08] 
Layer 'fc7' biases: 9.998624e-01 [2.907143e-08] 
Layer 'fc8' weights[0]: 1.285455e-03 [4.222484e-06] 
Layer 'fc8' biases: 4.576993e-02 [2.766443e-05] 
Train error last 870 batches: 0.435241
-------------------------------------------------------
Not saving because 0.417271 > 0.415685 (17.630: -0.01%)
======================================================= (12.090 sec)
19.541... logprob:  0.388879, 0.101562 (1.435 sec)
19.542... logprob:  0.411306, 0.109375 (1.432 sec)
19.543... logprob:  0.233377, 0.039062 (1.437 sec)
19.544... logprob:  0.317945, 0.070312 (1.432 sec)
19.545... logprob:  0.348810, 0.085938 (1.436 sec)
19.546... logprob:  0.368286, 0.093750 (1.489 sec)
19.547... logprob:  0.440129, 0.117188 (1.434 sec)
19.548... logprob:  0.453155, 0.125000 (1.446 sec)
19.549... logprob:  0.490688, 0.132812 (1.501 sec)
19.550... logprob:  0.367682, 0.093750 (1.439 sec)
19.551... logprob:  0.441778, 0.117188 (1.433 sec)
19.552... logprob:  0.471329, 0.125000 (1.440 sec)
19.553... logprob:  0.349438, 0.085938 (1.426 sec)
19.554... logprob:  0.506863, 0.140625 (1.438 sec)
19.555... logprob:  0.421412, 0.109375 (1.480 sec)
19.556... logprob:  0.355914, 0.085938 (1.441 sec)
19.557... logprob:  0.396470, 0.101562 (1.449 sec)
19.558... logprob:  0.383057, 0.101562 (1.477 sec)
19.559... logprob:  0.441470, 0.125000 (1.436 sec)
19.560... logprob:  0.335308, 0.078125 (1.443 sec)
19.561... logprob:  0.411838, 0.109375 (1.432 sec)
19.562... logprob:  0.503120, 0.140625 (1.426 sec)
19.563... logprob:  0.373852, 0.093750 (1.436 sec)
19.564... logprob:  0.468430, 0.132812 (1.471 sec)
19.565... logprob:  0.611047, 0.187500 (1.451 sec)
19.566... logprob:  0.374913, 0.093750 (1.457 sec)
19.567... logprob:  0.423427, 0.109375 (1.459 sec)
19.568... logprob:  0.496372, 0.140625 (1.456 sec)
19.569... logprob:  0.507836, 0.140625 (1.440 sec)
19.570... logprob:  0.543733, 0.164062 (1.425 sec)
19.571... logprob:  0.454876, 0.125000 (1.433 sec)
19.572... logprob:  0.501469, 0.140625 (1.437 sec)
19.573... logprob:  0.512625, 0.148438 (1.451 sec)
19.574... logprob:  0.428137, 0.109375 (1.461 sec)
19.575... logprob:  0.343355, 0.078125 (1.461 sec)
19.576... logprob:  0.427403, 0.109375 (1.440 sec)
19.577... logprob:  0.460837, 0.125000 (1.477 sec)
19.578... logprob:  0.336603, 0.078125 (1.438 sec)
19.579... logprob:  0.442087, 0.117188 (1.426 sec)
19.580... logprob:  0.546919, 0.156250 (1.438 sec)
19.581... logprob:  0.530968, 0.156250 (1.439 sec)
19.582... logprob:  0.437889, 0.125000 (1.436 sec)
19.583... logprob:  0.592817, 0.171875 (1.482 sec)
19.584... logprob:  0.468123, 0.132812 (1.460 sec)
19.585... logprob:  0.349764, 0.085938 (1.432 sec)
19.586... logprob:  0.313144, 0.070312 (1.489 sec)
19.587... logprob:  0.404313, 0.101562 (1.431 sec)
19.588... logprob:  0.418671, 0.117188 (1.428 sec)
19.589... logprob:  0.361282, 0.093750 (1.435 sec)
19.590... logprob:  0.524708, 0.148438 (1.453 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.19614028930664, 10.0]}, 128)
batch 872: ({'logprob': [66.45097351074219, 19.0]}, 128)
batch 873: ({'logprob': [41.025596618652344, 9.0]}, 128)
batch 874: ({'logprob': [45.191734313964844, 11.0]}, 128)
batch 875: ({'logprob': [50.87507247924805, 13.0]}, 128)
batch 876: ({'logprob': [64.00672149658203, 18.0]}, 128)
batch 877: ({'logprob': [45.95693588256836, 11.0]}, 128)
batch 878: ({'logprob': [62.28282165527344, 17.0]}, 128)
batch 879: ({'logprob': [74.41350555419922, 21.0]}, 128)
batch 880: ({'logprob': [50.89347839355469, 13.0]}, 128)
batch 881: ({'logprob': [28.860179901123047, 5.0]}, 128)
batch 882: ({'logprob': [55.636722564697266, 14.0]}, 128)
batch 883: ({'logprob': [62.26350784301758, 17.0]}, 128)
batch 884: ({'logprob': [51.637840270996094, 13.0]}, 128)
batch 885: ({'logprob': [53.157752990722656, 13.0]}, 128)
batch 886: ({'logprob': [63.036808013916016, 17.0]}, 128)

======================Test output======================
logprob:  0.418401, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.966872e-03 [2.909282e-09] 
Layer 'conv1' biases: 2.039107e-07 [6.514758e-11] 
Layer 'conv2' weights[0]: 7.953954e-03 [2.249113e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.147362e-10] 
Layer 'conv3' weights[0]: 7.952229e-03 [1.809541e-09] 
Layer 'conv3' biases: 1.757094e-06 [9.008854e-10] 
Layer 'conv4' weights[0]: 7.984849e-03 [1.800936e-09] 
Layer 'conv4' biases: 9.999995e-01 [6.604305e-09] 
Layer 'conv5' weights[0]: 7.983707e-03 [4.253837e-08] 
Layer 'conv5' biases: 9.999955e-01 [4.588660e-08] 
Layer 'fc6' weights[0]: 7.580438e-03 [3.700784e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.682332e-09] 
Layer 'fc7' weights[0]: 7.234063e-03 [6.514642e-08] 
Layer 'fc7' biases: 9.998632e-01 [4.746303e-08] 
Layer 'fc8' weights[0]: 1.313579e-03 [2.470175e-06] 
Layer 'fc8' biases: 4.608147e-02 [1.617497e-05] 
Train error last 870 batches: 0.435241
-------------------------------------------------------
Not saving because 0.418401 > 0.415685 (17.630: -0.01%)
======================================================= (12.076 sec)
19.591... logprob:  0.397509, 0.101562 (1.443 sec)
19.592... logprob:  0.455649, 0.125000 (1.486 sec)
19.593... logprob:  0.467433, 0.125000 (1.434 sec)
19.594... logprob:  0.352870, 0.085938 (1.433 sec)
19.595... logprob:  0.428667, 0.109375 (1.484 sec)
19.596... logprob:  0.461585, 0.125000 (1.435 sec)
19.597... logprob:  0.397413, 0.101562 (1.433 sec)
19.598... logprob:  0.397228, 0.101562 (1.438 sec)
19.599... logprob:  0.313519, 0.070312 (1.430 sec)
19.600... logprob:  0.340897, 0.085938 (1.436 sec)
19.601... logprob:  0.402126, 0.101562 (1.485 sec)
19.602... logprob:  0.289711, 0.062500 (1.438 sec)
19.603... logprob:  0.266970, 0.054688 (1.449 sec)
19.604... logprob:  0.407514, 0.101562 (1.473 sec)
19.605... logprob:  0.563550, 0.148438 (1.439 sec)
19.606... logprob:  0.295945, 0.070312 (1.436 sec)
19.607... logprob:  0.504892, 0.132812 (1.431 sec)
19.608... logprob:  0.361705, 0.085938 (1.424 sec)
19.609... logprob:  0.356938, 0.085938 (1.439 sec)
19.610... logprob:  0.493415, 0.132812 (1.473 sec)
19.611... logprob:  0.510428, 0.140625 (1.450 sec)
19.612... logprob:  0.448409, 0.117188 (1.452 sec)
19.613... logprob:  0.279732, 0.062500 (1.465 sec)
19.614... logprob:  0.503526, 0.140625 (1.450 sec)
19.615... logprob:  0.351121, 0.085938 (1.438 sec)
19.616... logprob:  0.415305, 0.109375 (1.434 sec)
19.617... logprob:  0.417953, 0.109375 (1.425 sec)
19.618... logprob:  0.546740, 0.156250 (1.441 sec)
19.619... logprob:  0.505966, 0.140625 (1.454 sec)
19.620... logprob:  0.539631, 0.156250 (1.462 sec)
19.621... logprob:  0.363877, 0.085938 (1.450 sec)
19.622... logprob:  0.364909, 0.085938 (1.447 sec)
19.623... logprob:  0.423207, 0.109375 (1.493 sec)
19.624... logprob:  0.382551, 0.093750 (1.441 sec)
19.625... logprob:  0.441001, 0.117188 (1.423 sec)
19.626... logprob:  0.438388, 0.117188 (1.435 sec)
19.627... logprob:  0.435857, 0.117188 (1.439 sec)
19.628... logprob:  0.465085, 0.125000 (1.438 sec)
19.629... logprob:  0.372013, 0.093750 (1.476 sec)
19.630... logprob:  0.422374, 0.109375 (1.447 sec)
19.631... logprob:  0.639220, 0.187500 (1.441 sec)
19.632... logprob:  0.399102, 0.101562 (1.480 sec)
19.633... logprob:  0.376034, 0.093750 (1.436 sec)
19.634... logprob:  0.660418, 0.195312 (1.432 sec)
19.635... logprob:  0.374120, 0.093750 (1.436 sec)
19.636... logprob:  0.480236, 0.132812 (1.438 sec)
19.637... logprob:  0.330917, 0.078125 (1.430 sec)
19.638... logprob:  0.515676, 0.140625 (1.487 sec)
19.639... logprob:  0.418137, 0.109375 (1.438 sec)
19.640... logprob:  0.528748, 0.148438 (1.437 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.71846008300781, 10.0]}, 128)
batch 872: ({'logprob': [66.2319107055664, 19.0]}, 128)
batch 873: ({'logprob': [41.31538009643555, 9.0]}, 128)
batch 874: ({'logprob': [45.876399993896484, 11.0]}, 128)
batch 875: ({'logprob': [51.12661361694336, 13.0]}, 128)
batch 876: ({'logprob': [63.797401428222656, 18.0]}, 128)
batch 877: ({'logprob': [46.22919845581055, 11.0]}, 128)
batch 878: ({'logprob': [61.669307708740234, 17.0]}, 128)
batch 879: ({'logprob': [72.52281951904297, 21.0]}, 128)
batch 880: ({'logprob': [51.146183013916016, 13.0]}, 128)
batch 881: ({'logprob': [30.4296932220459, 5.0]}, 128)
batch 882: ({'logprob': [54.637081146240234, 14.0]}, 128)
batch 883: ({'logprob': [61.64952850341797, 17.0]}, 128)
batch 884: ({'logprob': [51.474281311035156, 13.0]}, 128)
batch 885: ({'logprob': [52.166175842285156, 13.0]}, 128)
batch 886: ({'logprob': [62.00844955444336, 17.0]}, 128)

======================Test output======================
logprob:  0.417480, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.966846e-03 [3.558334e-09] 
Layer 'conv1' biases: 2.047808e-07 [6.393068e-11] 
Layer 'conv2' weights[0]: 7.953912e-03 [2.315361e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.898649e-10] 
Layer 'conv3' weights[0]: 7.952198e-03 [1.716683e-09] 
Layer 'conv3' biases: 1.765414e-06 [9.374284e-10] 
Layer 'conv4' weights[0]: 7.984813e-03 [1.786193e-09] 
Layer 'conv4' biases: 9.999995e-01 [6.769124e-09] 
Layer 'conv5' weights[0]: 7.983661e-03 [4.537893e-08] 
Layer 'conv5' biases: 9.999961e-01 [4.903424e-08] 
Layer 'fc6' weights[0]: 7.580406e-03 [3.861777e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.846770e-09] 
Layer 'fc7' weights[0]: 7.232212e-03 [1.299307e-07] 
Layer 'fc7' biases: 9.998621e-01 [1.177184e-07] 
Layer 'fc8' weights[0]: 1.286086e-03 [4.218094e-06] 
Layer 'fc8' biases: 4.606626e-02 [2.584538e-05] 
Train error last 870 batches: 0.435241
-------------------------------------------------------
Not saving because 0.417480 > 0.415685 (17.630: -0.01%)
======================================================= (12.068 sec)
19.641... logprob:  0.410476, 0.109375 (1.488 sec)
19.642... logprob:  0.500827, 0.140625 (1.436 sec)
19.643... logprob:  0.622898, 0.187500 (1.429 sec)
19.644... logprob:  0.321352, 0.070312 (1.440 sec)
19.645... logprob:  0.414501, 0.109375 (1.432 sec)
19.646... logprob:  0.385733, 0.093750 (1.431 sec)
19.647... logprob:  0.456756, 0.125000 (1.492 sec)
19.648... logprob:  0.491233, 0.140625 (1.433 sec)
19.649... logprob:  0.370140, 0.093750 (1.448 sec)
19.650... logprob:  0.413947, 0.109375 (1.477 sec)
19.651... logprob:  0.397318, 0.101562 (1.431 sec)
19.652... logprob:  0.507352, 0.140625 (1.439 sec)
19.653... logprob:  0.548077, 0.156250 (1.439 sec)
19.654... logprob:  0.496127, 0.140625 (1.426 sec)
19.655... logprob:  0.436204, 0.117188 (1.434 sec)
19.656... logprob:  0.416680, 0.109375 (1.509 sec)
19.657... logprob:  0.449242, 0.117188 (1.445 sec)
19.658... logprob:  0.345778, 0.085938 (1.451 sec)
19.659... logprob:  0.464344, 0.125000 (1.470 sec)
19.660... logprob:  0.445925, 0.125000 (1.442 sec)
19.661... logprob:  0.378524, 0.093750 (1.442 sec)
19.662... logprob:  0.469356, 0.132812 (1.434 sec)
19.663... logprob:  0.311017, 0.070312 (1.422 sec)
19.664... logprob:  0.285483, 0.062500 (1.437 sec)
19.665... logprob:  0.401824, 0.101562 (1.460 sec)
19.666... logprob:  0.442061, 0.117188 (1.453 sec)
19.667... logprob:  0.564292, 0.164062 (1.455 sec)
19.668... logprob:  0.497901, 0.140625 (1.453 sec)
19.669... logprob:  0.433068, 0.109375 (1.458 sec)
19.670... logprob:  0.362468, 0.085938 (1.438 sec)
19.671... logprob:  0.360856, 0.093750 (1.430 sec)
19.672... logprob:  0.441815, 0.117188 (1.428 sec)
19.673... logprob:  0.436240, 0.117188 (1.444 sec)
19.674... logprob:  0.446661, 0.117188 (1.443 sec)
19.675... logprob:  0.356668, 0.093750 (1.466 sec)
19.676... logprob:  0.450154, 0.125000 (1.455 sec)
19.677... logprob:  0.471052, 0.125000 (1.440 sec)
19.678... logprob:  0.465647, 0.125000 (1.483 sec)
19.679... logprob:  0.454870, 0.125000 (1.433 sec)
19.680... logprob:  0.351725, 0.078125 (1.432 sec)
19.681... logprob:  0.373929, 0.093750 (1.441 sec)
19.682... logprob:  0.340496, 0.078125 (1.438 sec)
19.683... logprob:  0.411644, 0.109375 (1.437 sec)
19.684... logprob:  0.357615, 0.085938 (1.480 sec)
19.685... logprob:  0.285912, 0.054688 (1.443 sec)
19.686... logprob:  0.318563, 0.070312 (1.437 sec)
19.687... logprob:  0.281555, 0.062500 (1.486 sec)
19.688... logprob:  0.323089, 0.078125 (1.437 sec)
19.689... logprob:  0.471452, 0.125000 (1.428 sec)
19.690... logprob:  0.528005, 0.140625 (1.436 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.889957427978516, 10.0]}, 128)
batch 872: ({'logprob': [69.62179565429688, 19.0]}, 128)
batch 873: ({'logprob': [39.31748962402344, 9.0]}, 128)
batch 874: ({'logprob': [44.814334869384766, 11.0]}, 128)
batch 875: ({'logprob': [51.23332214355469, 13.0]}, 128)
batch 876: ({'logprob': [66.6631088256836, 18.0]}, 128)
batch 877: ({'logprob': [45.28151321411133, 11.0]}, 128)
batch 878: ({'logprob': [64.1230239868164, 17.0]}, 128)
batch 879: ({'logprob': [77.43976593017578, 21.0]}, 128)
batch 880: ({'logprob': [51.25443649291992, 13.0]}, 128)
batch 881: ({'logprob': [25.963939666748047, 5.0]}, 128)
batch 882: ({'logprob': [55.63230895996094, 14.0]}, 128)
batch 883: ({'logprob': [64.10247802734375, 17.0]}, 128)
batch 884: ({'logprob': [51.70714569091797, 13.0]}, 128)
batch 885: ({'logprob': [52.63700866699219, 13.0]}, 128)
batch 886: ({'logprob': [64.58478546142578, 17.0]}, 128)

======================Test output======================
logprob:  0.422493, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.966810e-03 [4.871407e-09] 
Layer 'conv1' biases: 2.053653e-07 [1.829128e-10] 
Layer 'conv2' weights[0]: 7.953873e-03 [4.144680e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.611822e-10] 
Layer 'conv3' weights[0]: 7.952163e-03 [4.449747e-09] 
Layer 'conv3' biases: 1.768930e-06 [2.956932e-09] 
Layer 'conv4' weights[0]: 7.984781e-03 [4.647654e-09] 
Layer 'conv4' biases: 9.999994e-01 [2.717627e-08] 
Layer 'conv5' weights[0]: 7.983613e-03 [1.800411e-07] 
Layer 'conv5' biases: 9.999952e-01 [1.942530e-07] 
Layer 'fc6' weights[0]: 7.580361e-03 [1.529405e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.559669e-08] 
Layer 'fc7' weights[0]: 7.230298e-03 [5.147861e-08] 
Layer 'fc7' biases: 9.998645e-01 [3.052419e-08] 
Layer 'fc8' weights[0]: 1.389432e-03 [7.418335e-06] 
Layer 'fc8' biases: 4.682374e-02 [4.943354e-05] 
Train error last 870 batches: 0.435240
-------------------------------------------------------
Not saving because 0.422493 > 0.415685 (17.630: -0.01%)
======================================================= (12.097 sec)
19.691... logprob:  0.516952, 0.140625 (1.440 sec)
19.692... logprob:  0.385246, 0.101562 (1.435 sec)
19.693... logprob:  0.455962, 0.125000 (1.485 sec)
19.694... logprob:  0.330898, 0.078125 (1.439 sec)
19.695... logprob:  0.356898, 0.085938 (1.438 sec)
19.696... logprob:  0.538855, 0.148438 (1.479 sec)
19.697... logprob:  0.465609, 0.125000 (1.432 sec)
19.698... logprob:  0.548599, 0.156250 (1.440 sec)
19.699... logprob:  0.459589, 0.125000 (1.434 sec)
19.700... logprob:  0.434007, 0.117188 (1.428 sec)
19.701... logprob:  0.423287, 0.109375 (1.440 sec)
19.702... logprob:  0.521466, 0.148438 (1.477 sec)
19.703... logprob:  0.405447, 0.101562 (1.434 sec)
19.704... logprob:  0.406281, 0.101562 (1.451 sec)
19.705... logprob:  0.420279, 0.109375 (1.474 sec)
19.706... logprob:  0.468077, 0.125000 (1.440 sec)
19.707... logprob:  0.485300, 0.132812 (1.437 sec)
19.708... logprob:  0.417074, 0.109375 (1.440 sec)
19.709... logprob:  0.422471, 0.109375 (1.419 sec)
19.710... logprob:  0.602674, 0.179688 (1.444 sec)
19.711... logprob:  0.469517, 0.125000 (1.463 sec)
19.712... logprob:  0.340429, 0.078125 (1.455 sec)
19.713... logprob:  0.587208, 0.179688 (1.452 sec)
19.714... logprob:  0.466319, 0.125000 (1.460 sec)
19.715... logprob:  0.417144, 0.109375 (1.455 sec)
19.716... logprob:  0.335280, 0.078125 (1.441 sec)
19.717... logprob:  0.429825, 0.117188 (1.427 sec)
19.718... logprob:  0.490373, 0.132812 (1.429 sec)
19.719... logprob:  0.406197, 0.109375 (1.442 sec)
19.720... logprob:  0.433237, 0.117188 (1.453 sec)
19.721... logprob:  0.451601, 0.117188 (1.459 sec)
19.722... logprob:  0.536870, 0.156250 (1.458 sec)
19.723... logprob:  0.416592, 0.109375 (1.442 sec)
19.724... logprob:  0.412776, 0.109375 (1.487 sec)
19.725... logprob:  0.494686, 0.140625 (1.436 sec)
19.726... logprob:  0.338639, 0.085938 (1.430 sec)
19.727... logprob:  0.393349, 0.101562 (1.430 sec)
19.728... logprob:  0.421340, 0.109375 (1.443 sec)
19.729... logprob:  0.387767, 0.093750 (1.435 sec)
19.730... logprob:  0.565839, 0.164062 (1.510 sec)
19.731... logprob:  0.450339, 0.125000 (1.446 sec)
19.732... logprob:  0.311473, 0.070312 (1.440 sec)
19.733... logprob:  0.556659, 0.156250 (1.486 sec)
19.734... logprob:  0.340234, 0.078125 (1.434 sec)
19.735... logprob:  0.527589, 0.148438 (1.429 sec)
19.736... logprob:  0.642960, 0.187500 (1.439 sec)
19.737... logprob:  0.516187, 0.148438 (1.432 sec)
19.738... logprob:  0.459423, 0.125000 (1.437 sec)
19.739... logprob:  0.477810, 0.132812 (1.482 sec)
19.740... logprob:  0.339657, 0.078125 (1.442 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.958988189697266, 10.0]}, 128)
batch 872: ({'logprob': [65.74673461914062, 19.0]}, 128)
batch 873: ({'logprob': [42.38777542114258, 9.0]}, 128)
batch 874: ({'logprob': [46.37504577636719, 11.0]}, 128)
batch 875: ({'logprob': [51.48996353149414, 13.0]}, 128)
batch 876: ({'logprob': [63.48863220214844, 18.0]}, 128)
batch 877: ({'logprob': [46.946876525878906, 11.0]}, 128)
batch 878: ({'logprob': [61.757511138916016, 17.0]}, 128)
batch 879: ({'logprob': [72.55367279052734, 21.0]}, 128)
batch 880: ({'logprob': [51.508140563964844, 13.0]}, 128)
batch 881: ({'logprob': [31.559249877929688, 5.0]}, 128)
batch 882: ({'logprob': [55.47523498535156, 14.0]}, 128)
batch 883: ({'logprob': [61.738365173339844, 17.0]}, 128)
batch 884: ({'logprob': [52.053504943847656, 13.0]}, 128)
batch 885: ({'logprob': [53.181556701660156, 13.0]}, 128)
batch 886: ({'logprob': [62.31380081176758, 17.0]}, 128)

======================Test output======================
logprob:  0.420671, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.966777e-03 [2.968908e-09] 
Layer 'conv1' biases: 2.064816e-07 [8.548700e-11] 
Layer 'conv2' weights[0]: 7.953835e-03 [3.165709e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.458416e-10] 
Layer 'conv3' weights[0]: 7.952127e-03 [2.986791e-09] 
Layer 'conv3' biases: 1.779697e-06 [1.744868e-09] 
Layer 'conv4' weights[0]: 7.984741e-03 [3.267397e-09] 
Layer 'conv4' biases: 9.999994e-01 [1.643065e-08] 
Layer 'conv5' weights[0]: 7.983582e-03 [1.087998e-07] 
Layer 'conv5' biases: 9.999961e-01 [1.173278e-07] 
Layer 'fc6' weights[0]: 7.580325e-03 [9.159601e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.218985e-09] 
Layer 'fc7' weights[0]: 7.228509e-03 [7.136030e-08] 
Layer 'fc7' biases: 9.998617e-01 [5.583993e-08] 
Layer 'fc8' weights[0]: 1.270320e-03 [2.790273e-06] 
Layer 'fc8' biases: 4.622832e-02 [1.695655e-05] 
Train error last 870 batches: 0.435240
-------------------------------------------------------
Not saving because 0.420671 > 0.415685 (17.630: -0.01%)
======================================================= (12.071 sec)
19.741... logprob:  0.393452, 0.101562 (1.444 sec)
19.742... logprob:  0.419730, 0.109375 (1.483 sec)
19.743... logprob:  0.364873, 0.085938 (1.435 sec)
19.744... logprob:  0.519232, 0.148438 (1.431 sec)
19.745... logprob:  0.478171, 0.132812 (1.439 sec)
19.746... logprob:  0.440556, 0.117188 (1.432 sec)
19.747... logprob:  0.425622, 0.109375 (1.433 sec)
19.748... logprob:  0.378067, 0.093750 (1.491 sec)
19.749... logprob:  0.420838, 0.109375 (1.434 sec)
19.750... logprob:  0.512894, 0.140625 (1.450 sec)
19.751... logprob:  0.263562, 0.054688 (1.476 sec)
19.752... logprob:  0.522516, 0.140625 (1.435 sec)
19.753... logprob:  0.441234, 0.117188 (1.438 sec)
19.754... logprob:  0.468521, 0.132812 (1.439 sec)
19.755... logprob:  0.507103, 0.140625 (1.424 sec)
19.756... logprob:  0.440825, 0.117188 (1.437 sec)
19.757... logprob:  0.552322, 0.156250 (1.472 sec)
19.758... logprob:  0.393683, 0.101562 (1.440 sec)
19.759... logprob:  0.459692, 0.125000 (1.460 sec)
19.760... logprob:  0.485439, 0.132812 (1.456 sec)
19.761... logprob:  0.418349, 0.109375 (1.442 sec)
19.762... logprob:  0.515997, 0.148438 (1.445 sec)
19.763... logprob:  0.558819, 0.164062 (1.460 sec)
19.764... logprob:  0.503285, 0.140625 (1.426 sec)
19.765... logprob:  0.312166, 0.062500 (1.436 sec)
19.766... logprob:  0.482280, 0.132812 (1.453 sec)
19.767... logprob:  0.371157, 0.085938 (1.464 sec)
19.768... logprob:  0.432698, 0.117188 (1.461 sec)
19.769... logprob:  0.490881, 0.140625 (1.471 sec)
19.770... logprob:  0.402852, 0.101562 (1.479 sec)
19.771... logprob:  0.549624, 0.156250 (1.463 sec)
19.772... logprob:  0.414046, 0.109375 (1.444 sec)
19.773... logprob:  0.558069, 0.164062 (1.451 sec)
19.774... logprob:  0.361575, 0.085938 (1.460 sec)
19.775... logprob:  0.407333, 0.101562 (1.462 sec)
19.776... logprob:  0.433225, 0.117188 (1.483 sec)
19.777... logprob:  0.379929, 0.093750 (1.473 sec)
19.778... logprob:  0.433608, 0.117188 (1.467 sec)
19.779... logprob:  0.505451, 0.140625 (1.488 sec)
19.780... logprob:  0.385758, 0.101562 (1.459 sec)
19.781... logprob:  0.369706, 0.085938 (1.448 sec)
19.782... logprob:  0.351486, 0.085938 (1.451 sec)
19.783... logprob:  0.555480, 0.156250 (1.458 sec)
19.784... logprob:  0.440956, 0.117188 (1.459 sec)
19.785... logprob:  0.543559, 0.156250 (1.490 sec)
19.786... logprob:  0.477427, 0.132812 (1.472 sec)
19.787... logprob:  0.546240, 0.156250 (1.461 sec)
19.788... logprob:  0.562958, 0.164062 (1.495 sec)
19.789... logprob:  0.281315, 0.054688 (1.457 sec)
19.790... logprob:  0.408252, 0.101562 (1.447 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.04944610595703, 10.0]}, 128)
batch 872: ({'logprob': [65.9062728881836, 19.0]}, 128)
batch 873: ({'logprob': [42.05924606323242, 9.0]}, 128)
batch 874: ({'logprob': [46.28765869140625, 11.0]}, 128)
batch 875: ({'logprob': [51.40400695800781, 13.0]}, 128)
batch 876: ({'logprob': [63.58793640136719, 18.0]}, 128)
batch 877: ({'logprob': [46.73991775512695, 11.0]}, 128)
batch 878: ({'logprob': [61.676326751708984, 17.0]}, 128)
batch 879: ({'logprob': [72.35807800292969, 21.0]}, 128)
batch 880: ({'logprob': [51.42289733886719, 13.0]}, 128)
batch 881: ({'logprob': [31.345508575439453, 5.0]}, 128)
batch 882: ({'logprob': [55.09260177612305, 14.0]}, 128)
batch 883: ({'logprob': [61.65681838989258, 17.0]}, 128)
batch 884: ({'logprob': [51.84893798828125, 13.0]}, 128)
batch 885: ({'logprob': [52.7381706237793, 13.0]}, 128)
batch 886: ({'logprob': [62.113494873046875, 17.0]}, 128)

======================Test output======================
logprob:  0.419574, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.966733e-03 [3.009842e-09] 
Layer 'conv1' biases: 2.073154e-07 [1.066941e-10] 
Layer 'conv2' weights[0]: 7.953798e-03 [3.087706e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.812745e-10] 
Layer 'conv3' weights[0]: 7.952091e-03 [2.985539e-09] 
Layer 'conv3' biases: 1.787266e-06 [1.835021e-09] 
Layer 'conv4' weights[0]: 7.984707e-03 [3.101060e-09] 
Layer 'conv4' biases: 9.999994e-01 [1.632775e-08] 
Layer 'conv5' weights[0]: 7.983542e-03 [1.056882e-07] 
Layer 'conv5' biases: 9.999962e-01 [1.138902e-07] 
Layer 'fc6' weights[0]: 7.580285e-03 [8.892536e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.981203e-09] 
Layer 'fc7' weights[0]: 7.226651e-03 [8.738985e-08] 
Layer 'fc7' biases: 9.998617e-01 [7.312143e-08] 
Layer 'fc8' weights[0]: 1.271363e-03 [2.757656e-06] 
Layer 'fc8' biases: 4.638305e-02 [1.431047e-05] 
Train error last 870 batches: 0.435240
-------------------------------------------------------
Not saving because 0.419574 > 0.415685 (17.630: -0.01%)
======================================================= (12.145 sec)
19.791... logprob:  0.398107, 0.101562 (1.456 sec)
19.792... logprob:  0.361198, 0.085938 (1.465 sec)
19.793... logprob:  0.370251, 0.085938 (1.448 sec)
19.794... logprob:  0.387130, 0.093750 (1.483 sec)
19.795... logprob:  0.469807, 0.125000 (1.473 sec)
19.796... logprob:  0.423501, 0.109375 (1.455 sec)
19.797... logprob:  0.358736, 0.085938 (1.504 sec)
19.798... logprob:  0.393270, 0.101562 (1.451 sec)
19.799... logprob:  0.332223, 0.078125 (1.452 sec)
19.800... logprob:  0.371765, 0.093750 (1.448 sec)
19.801... logprob:  0.450271, 0.117188 (1.464 sec)
19.802... logprob:  0.423106, 0.109375 (1.452 sec)
19.803... logprob:  0.491917, 0.132812 (1.493 sec)
19.804... logprob:  0.349978, 0.085938 (1.467 sec)
19.805... logprob:  0.452295, 0.117188 (1.453 sec)
19.806... logprob:  0.424185, 0.109375 (1.506 sec)
19.807... logprob:  0.443459, 0.117188 (1.457 sec)
19.808... logprob:  0.462346, 0.125000 (1.448 sec)
19.809... logprob:  0.589519, 0.171875 (1.452 sec)
19.810... logprob:  0.442449, 0.117188 (1.459 sec)
19.811... logprob:  0.460418, 0.125000 (1.451 sec)
19.812... logprob:  0.462405, 0.125000 (1.509 sec)
19.813... logprob:  0.485979, 0.132812 (1.460 sec)
19.814... logprob:  0.478108, 0.132812 (1.456 sec)
19.815... logprob:  0.372200, 0.085938 (1.503 sec)
19.816... logprob:  0.408915, 0.101562 (1.455 sec)
19.817... logprob:  0.426086, 0.109375 (1.451 sec)
19.818... logprob:  0.559973, 0.164062 (1.452 sec)
19.819... logprob:  0.498210, 0.140625 (1.457 sec)
19.820... logprob:  0.421573, 0.109375 (1.455 sec)
19.821... logprob:  0.406479, 0.101562 (1.497 sec)
19.822... logprob:  0.441118, 0.117188 (1.463 sec)
19.823... logprob:  0.340571, 0.078125 (1.225 sec)
19.824... logprob:  0.489945, 0.132812 (0.713 sec)
19.825... logprob:  0.287655, 0.062500 (0.683 sec)
19.826... logprob:  0.375391, 0.093750 (0.689 sec)
19.827... logprob:  0.420613, 0.109375 (0.692 sec)
19.828... logprob:  0.443551, 0.117188 (0.686 sec)
19.829... logprob:  0.504528, 0.140625 (0.684 sec)
19.830... logprob:  0.442311, 0.117188 (1.501 sec)
19.831... logprob:  0.514095, 0.140625 (1.459 sec)
19.832... logprob:  0.330854, 0.078125 (1.460 sec)
19.833... logprob:  0.488972, 0.132812 (1.498 sec)
19.834... logprob:  0.433226, 0.117188 (1.450 sec)
19.835... logprob:  0.542554, 0.148438 (1.463 sec)
19.836... logprob:  0.376298, 0.093750 (1.449 sec)
19.837... logprob:  0.314670, 0.070312 (1.452 sec)
19.838... logprob:  0.437086, 0.117188 (1.453 sec)
19.839... logprob:  0.471715, 0.125000 (1.502 sec)
19.840... logprob:  0.555294, 0.156250 (1.459 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.63200378417969, 10.0]}, 128)
batch 872: ({'logprob': [66.20523834228516, 19.0]}, 128)
batch 873: ({'logprob': [41.30348587036133, 9.0]}, 128)
batch 874: ({'logprob': [45.833255767822266, 11.0]}, 128)
batch 875: ({'logprob': [51.09946823120117, 13.0]}, 128)
batch 876: ({'logprob': [63.774559020996094, 18.0]}, 128)
batch 877: ({'logprob': [46.20947265625, 11.0]}, 128)
batch 878: ({'logprob': [61.673797607421875, 17.0]}, 128)
batch 879: ({'logprob': [72.58258056640625, 21.0]}, 128)
batch 880: ({'logprob': [51.11880874633789, 13.0]}, 128)
batch 881: ({'logprob': [30.362396240234375, 5.0]}, 128)
batch 882: ({'logprob': [54.67665481567383, 14.0]}, 128)
batch 883: ({'logprob': [61.65420150756836, 17.0]}, 128)
batch 884: ({'logprob': [51.470603942871094, 13.0]}, 128)
batch 885: ({'logprob': [52.20970153808594, 13.0]}, 128)
batch 886: ({'logprob': [62.03649139404297, 17.0]}, 128)

======================Test output======================
logprob:  0.417404, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.966687e-03 [4.227748e-09] 
Layer 'conv1' biases: 2.081950e-07 [8.652464e-11] 
Layer 'conv2' weights[0]: 7.953759e-03 [2.896421e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.739469e-10] 
Layer 'conv3' weights[0]: 7.952058e-03 [2.461025e-09] 
Layer 'conv3' biases: 1.794122e-06 [1.431167e-09] 
Layer 'conv4' weights[0]: 7.984670e-03 [2.607413e-09] 
Layer 'conv4' biases: 9.999994e-01 [1.258557e-08] 
Layer 'conv5' weights[0]: 7.983507e-03 [8.397322e-08] 
Layer 'conv5' biases: 9.999961e-01 [9.077703e-08] 
Layer 'fc6' weights[0]: 7.580240e-03 [7.003654e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.103488e-09] 
Layer 'fc7' weights[0]: 7.224845e-03 [2.127580e-07] 
Layer 'fc7' biases: 9.998620e-01 [2.020788e-07] 
Layer 'fc8' weights[0]: 1.282828e-03 [7.293582e-06] 
Layer 'fc8' biases: 4.675510e-02 [4.692979e-05] 
Train error last 870 batches: 0.435239
-------------------------------------------------------
Not saving because 0.417404 > 0.415685 (17.630: -0.01%)
======================================================= (12.035 sec)
19.841... logprob:  0.396237, 0.101562 (1.473 sec)
19.842... logprob:  0.497814, 0.140625 (1.495 sec)
19.843... logprob:  0.465543, 0.125000 (1.449 sec)
19.844... logprob:  0.497622, 0.140625 (1.461 sec)
19.845... logprob:  0.486815, 0.132812 (1.451 sec)
19.846... logprob:  0.468474, 0.125000 (1.450 sec)
19.847... logprob:  0.363212, 0.085938 (1.456 sec)
19.848... logprob:  0.397051, 0.101562 (1.498 sec)
19.849... logprob:  0.360306, 0.085938 (1.460 sec)
19.850... logprob:  0.479428, 0.132812 (1.468 sec)
19.851... logprob:  0.440149, 0.117188 (1.491 sec)
19.852... logprob:  0.545806, 0.156250 (1.454 sec)
19.853... logprob:  0.371816, 0.093750 (1.463 sec)
19.854... logprob:  0.307061, 0.070312 (1.448 sec)
19.855... logprob:  0.484941, 0.132812 (1.449 sec)
19.856... logprob:  0.443840, 0.117188 (1.455 sec)
19.857... logprob:  0.372236, 0.093750 (1.493 sec)
19.858... logprob:  0.396246, 0.101562 (1.467 sec)
19.859... logprob:  0.307954, 0.070312 (1.469 sec)
19.860... logprob:  0.565964, 0.156250 (1.487 sec)
19.861... logprob:  0.417815, 0.109375 (1.460 sec)
19.862... logprob:  0.328917, 0.078125 (1.462 sec)
19.863... logprob:  0.399527, 0.101562 (1.449 sec)
19.864... logprob:  0.451409, 0.117188 (1.445 sec)
19.865... logprob:  0.484433, 0.132812 (1.461 sec)
19.866... logprob:  0.507552, 0.140625 (1.493 sec)
19.867... logprob:  0.502887, 0.140625 (1.477 sec)
19.868... logprob:  0.405362, 0.101562 (1.475 sec)
19.869... logprob:  0.383299, 0.093750 (1.477 sec)
19.870... logprob:  0.551998, 0.156250 (1.399 sec)
20.1... logprob:  0.380141, 0.093750 (1.406 sec)
20.2... logprob:  0.448276, 0.117188 (1.477 sec)
20.3... logprob:  0.398394, 0.101562 (1.423 sec)
20.4... logprob:  0.443342, 0.117188 (1.405 sec)
20.5... logprob:  0.443434, 0.117188 (1.431 sec)
20.6... logprob:  0.499169, 0.140625 (1.395 sec)
20.7... logprob:  0.363099, 0.085938 (1.422 sec)
20.8... logprob:  0.419120, 0.109375 (1.393 sec)
20.9... logprob:  0.358712, 0.085938 (1.403 sec)
20.10... logprob:  0.377426, 0.093750 (1.411 sec)
20.11... logprob:  0.334628, 0.078125 (1.443 sec)
20.12... logprob:  0.466475, 0.125000 (1.398 sec)
20.13... logprob:  0.442337, 0.117188 (1.423 sec)
20.14... logprob:  0.444727, 0.117188 (1.407 sec)
20.15... logprob:  0.395613, 0.101562 (1.410 sec)
20.16... logprob:  0.421440, 0.109375 (1.404 sec)
20.17... logprob:  0.516069, 0.140625 (1.396 sec)
20.18... logprob:  0.262105, 0.054688 (1.402 sec)
20.19... logprob:  0.279590, 0.062500 (1.406 sec)
20.20... logprob:  0.421376, 0.109375 (1.400 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.60744094848633, 10.0]}, 128)
batch 872: ({'logprob': [68.33367156982422, 19.0]}, 128)
batch 873: ({'logprob': [39.3740348815918, 9.0]}, 128)
batch 874: ({'logprob': [44.90972900390625, 11.0]}, 128)
batch 875: ({'logprob': [50.85506820678711, 13.0]}, 128)
batch 876: ({'logprob': [65.48347473144531, 18.0]}, 128)
batch 877: ({'logprob': [45.1218147277832, 11.0]}, 128)
batch 878: ({'logprob': [62.796756744384766, 17.0]}, 128)
batch 879: ({'logprob': [74.9105224609375, 21.0]}, 128)
batch 880: ({'logprob': [50.8765983581543, 13.0]}, 128)
batch 881: ({'logprob': [27.22576141357422, 5.0]}, 128)
batch 882: ({'logprob': [54.375274658203125, 14.0]}, 128)
batch 883: ({'logprob': [62.77608108520508, 17.0]}, 128)
batch 884: ({'logprob': [51.0707893371582, 13.0]}, 128)
batch 885: ({'logprob': [51.487998962402344, 13.0]}, 128)
batch 886: ({'logprob': [63.00112533569336, 17.0]}, 128)

======================Test output======================
logprob:  0.417093, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.966642e-03 [3.036057e-09] 
Layer 'conv1' biases: 2.090118e-07 [4.509069e-11] 
Layer 'conv2' weights[0]: 7.953727e-03 [1.746554e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.430866e-10] 
Layer 'conv3' weights[0]: 7.952023e-03 [1.268550e-09] 
Layer 'conv3' biases: 1.799777e-06 [3.936736e-10] 
Layer 'conv4' weights[0]: 7.984630e-03 [1.251732e-09] 
Layer 'conv4' biases: 9.999994e-01 [1.468293e-09] 
Layer 'conv5' weights[0]: 7.983462e-03 [9.025342e-09] 
Layer 'conv5' biases: 9.999955e-01 [9.454516e-09] 
Layer 'fc6' weights[0]: 7.580197e-03 [1.101522e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.579544e-10] 
Layer 'fc7' weights[0]: 7.222916e-03 [6.306224e-08] 
Layer 'fc7' biases: 9.998633e-01 [4.506265e-08] 
Layer 'fc8' weights[0]: 1.343823e-03 [1.885073e-06] 
Layer 'fc8' biases: 4.732442e-02 [1.262266e-05] 
Train error last 870 batches: 0.435239
-------------------------------------------------------
Not saving because 0.417093 > 0.415685 (17.630: -0.01%)
======================================================= (12.129 sec)
20.21... logprob:  0.443961, 0.117188 (0.902 sec)
20.22... logprob:  0.536623, 0.148438 (1.331 sec)
20.23... logprob:  0.532878, 0.148438 (1.427 sec)
20.24... logprob:  0.310704, 0.070312 (0.984 sec)
20.25... logprob:  0.356277, 0.085938 (0.959 sec)
20.26... logprob:  0.463700, 0.125000 (1.448 sec)
20.27... logprob:  0.404583, 0.101562 (1.394 sec)
20.28... logprob:  0.421867, 0.109375 (1.413 sec)
20.29... logprob:  0.396026, 0.101562 (1.423 sec)
20.30... logprob:  0.374154, 0.093750 (1.422 sec)
20.31... logprob:  0.479920, 0.132812 (1.403 sec)
20.32... logprob:  0.457231, 0.125000 (1.389 sec)
20.33... logprob:  0.460677, 0.125000 (1.449 sec)
20.34... logprob:  0.464599, 0.125000 (1.391 sec)
20.35... logprob:  0.316232, 0.070312 (1.400 sec)
20.36... logprob:  0.475799, 0.132812 (1.404 sec)
20.37... logprob:  0.417594, 0.109375 (1.422 sec)
20.38... logprob:  0.392563, 0.101562 (1.400 sec)
20.39... logprob:  0.631775, 0.187500 (1.440 sec)
20.40... logprob:  0.445792, 0.117188 (1.415 sec)
20.41... logprob:  0.352832, 0.085938 (1.427 sec)
20.42... logprob:  0.391893, 0.101562 (1.420 sec)
20.43... logprob:  0.440105, 0.117188 (1.417 sec)
20.44... logprob:  0.518526, 0.148438 (1.443 sec)
20.45... logprob:  0.381763, 0.093750 (1.394 sec)
20.46... logprob:  0.486310, 0.132812 (1.397 sec)
20.47... logprob:  0.331748, 0.078125 (1.395 sec)
20.48... logprob:  0.498896, 0.140625 (1.423 sec)
20.49... logprob:  0.510719, 0.148438 (1.419 sec)
20.50... logprob:  0.393226, 0.101562 (1.424 sec)
20.51... logprob:  0.490090, 0.140625 (1.417 sec)
20.52... logprob:  0.525782, 0.148438 (1.404 sec)
20.53... logprob:  0.294966, 0.062500 (1.444 sec)
20.54... logprob:  0.403298, 0.109375 (1.393 sec)
20.55... logprob:  0.331763, 0.078125 (1.397 sec)
20.56... logprob:  0.421682, 0.109375 (1.403 sec)
20.57... logprob:  0.572473, 0.164062 (1.426 sec)
20.58... logprob:  0.407696, 0.101562 (1.402 sec)
20.59... logprob:  0.333860, 0.078125 (1.470 sec)
20.60... logprob:  0.618934, 0.179688 (1.429 sec)
20.61... logprob:  0.382846, 0.093750 (1.433 sec)
20.62... logprob:  0.474882, 0.132812 (1.463 sec)
20.63... logprob:  0.397303, 0.101562 (1.441 sec)
20.64... logprob:  0.450286, 0.125000 (1.416 sec)
20.65... logprob:  0.373339, 0.093750 (1.404 sec)
20.66... logprob:  0.354016, 0.085938 (1.450 sec)
20.67... logprob:  0.295397, 0.062500 (1.387 sec)
20.68... logprob:  0.396812, 0.101562 (1.405 sec)
20.69... logprob:  0.496779, 0.140625 (1.422 sec)
20.70... logprob:  0.325883, 0.078125 (1.434 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.007850646972656, 10.0]}, 128)
batch 872: ({'logprob': [67.07718658447266, 19.0]}, 128)
batch 873: ({'logprob': [40.27381134033203, 9.0]}, 128)
batch 874: ({'logprob': [44.88069534301758, 11.0]}, 128)
batch 875: ({'logprob': [50.72831344604492, 13.0]}, 128)
batch 876: ({'logprob': [64.48262786865234, 18.0]}, 128)
batch 877: ({'logprob': [45.50776672363281, 11.0]}, 128)
batch 878: ({'logprob': [62.46852111816406, 17.0]}, 128)
batch 879: ({'logprob': [74.7939224243164, 21.0]}, 128)
batch 880: ({'logprob': [50.74783706665039, 13.0]}, 128)
batch 881: ({'logprob': [27.913013458251953, 5.0]}, 128)
batch 882: ({'logprob': [55.231143951416016, 14.0]}, 128)
batch 883: ({'logprob': [62.44863510131836, 17.0]}, 128)
batch 884: ({'logprob': [51.35565185546875, 13.0]}, 128)
batch 885: ({'logprob': [52.60066604614258, 13.0]}, 128)
batch 886: ({'logprob': [63.0859260559082, 17.0]}, 128)

======================Test output======================
logprob:  0.417287, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.966601e-03 [2.363585e-09] 
Layer 'conv1' biases: 2.098161e-07 [6.258281e-11] 
Layer 'conv2' weights[0]: 7.953685e-03 [1.678108e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.409692e-10] 
Layer 'conv3' weights[0]: 7.951980e-03 [1.517102e-09] 
Layer 'conv3' biases: 1.806172e-06 [7.336548e-10] 
Layer 'conv4' weights[0]: 7.984589e-03 [1.584026e-09] 
Layer 'conv4' biases: 9.999994e-01 [6.479733e-09] 
Layer 'conv5' weights[0]: 7.983419e-03 [4.328996e-08] 
Layer 'conv5' biases: 9.999954e-01 [4.673101e-08] 
Layer 'fc6' weights[0]: 7.580163e-03 [3.728401e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.705695e-09] 
Layer 'fc7' weights[0]: 7.221082e-03 [1.606413e-07] 
Layer 'fc7' biases: 9.998631e-01 [1.487752e-07] 
Layer 'fc8' weights[0]: 1.331161e-03 [6.016725e-06] 
Layer 'fc8' biases: 4.726753e-02 [3.888061e-05] 
Train error last 870 batches: 0.435239
-------------------------------------------------------
Not saving because 0.417287 > 0.415685 (17.630: -0.01%)
======================================================= (12.052 sec)
20.71... logprob:  0.381825, 0.101562 (1.469 sec)
20.72... logprob:  0.493797, 0.132812 (1.417 sec)
20.73... logprob:  0.447745, 0.117188 (1.427 sec)
20.74... logprob:  0.442567, 0.117188 (1.422 sec)
20.75... logprob:  0.380646, 0.093750 (1.414 sec)
20.76... logprob:  0.412073, 0.109375 (1.434 sec)
20.77... logprob:  0.396343, 0.101562 (1.435 sec)
20.78... logprob:  0.493063, 0.140625 (1.454 sec)
20.79... logprob:  0.456451, 0.125000 (1.406 sec)
20.80... logprob:  0.507926, 0.132812 (1.422 sec)
20.81... logprob:  0.416725, 0.109375 (1.413 sec)
20.82... logprob:  0.231622, 0.039062 (1.429 sec)
20.83... logprob:  0.493753, 0.140625 (1.398 sec)
20.84... logprob:  0.468101, 0.125000 (1.472 sec)
20.85... logprob:  0.431996, 0.117188 (1.424 sec)
20.86... logprob:  0.416970, 0.109375 (1.422 sec)
20.87... logprob:  0.633220, 0.187500 (1.414 sec)
20.88... logprob:  0.535073, 0.156250 (1.413 sec)
20.89... logprob:  0.410604, 0.109375 (1.433 sec)
20.90... logprob:  0.577498, 0.171875 (1.394 sec)
20.91... logprob:  0.348509, 0.078125 (1.400 sec)
20.92... logprob:  0.464462, 0.125000 (1.409 sec)
20.93... logprob:  0.492257, 0.140625 (1.399 sec)
20.94... logprob:  0.428783, 0.109375 (1.401 sec)
20.95... logprob:  0.471848, 0.125000 (1.408 sec)
20.96... logprob:  0.576297, 0.171875 (1.407 sec)
20.97... logprob:  0.430765, 0.117188 (1.396 sec)
20.98... logprob:  0.391083, 0.093750 (1.440 sec)
20.99... logprob:  0.474283, 0.132812 (1.408 sec)
20.100... logprob:  0.310440, 0.070312 (1.402 sec)
20.101... logprob:  0.310648, 0.062500 (1.446 sec)
20.102... logprob:  0.546220, 0.156250 (1.393 sec)
20.103... logprob:  0.541210, 0.156250 (1.398 sec)
20.104... logprob:  0.388851, 0.101562 (1.404 sec)
20.105... logprob:  0.619642, 0.179688 (1.397 sec)
20.106... logprob:  0.344440, 0.085938 (1.391 sec)
20.107... logprob:  0.335728, 0.078125 (1.441 sec)
20.108... logprob:  0.586830, 0.171875 (1.400 sec)
20.109... logprob:  0.336178, 0.078125 (1.404 sec)
20.110... logprob:  0.564505, 0.164062 (1.396 sec)
20.111... logprob:  0.404712, 0.101562 (1.399 sec)
20.112... logprob:  0.366128, 0.093750 (1.410 sec)
20.113... logprob:  0.354598, 0.085938 (1.402 sec)
20.114... logprob:  0.440225, 0.117188 (1.438 sec)
20.115... logprob:  0.506737, 0.140625 (1.415 sec)
20.116... logprob:  0.393389, 0.101562 (1.398 sec)
20.117... logprob:  0.440394, 0.117188 (1.446 sec)
20.118... logprob:  0.409145, 0.101562 (1.388 sec)
20.119... logprob:  0.346121, 0.085938 (1.403 sec)
20.120... logprob:  0.547142, 0.156250 (1.400 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.69357681274414, 10.0]}, 128)
batch 872: ({'logprob': [66.47879791259766, 19.0]}, 128)
batch 873: ({'logprob': [40.68452453613281, 9.0]}, 128)
batch 874: ({'logprob': [45.23491287231445, 11.0]}, 128)
batch 875: ({'logprob': [50.784324645996094, 13.0]}, 128)
batch 876: ({'logprob': [63.97275161743164, 18.0]}, 128)
batch 877: ({'logprob': [45.74187469482422, 11.0]}, 128)
batch 878: ({'logprob': [61.926971435546875, 17.0]}, 128)
batch 879: ({'logprob': [73.53443908691406, 21.0]}, 128)
batch 880: ({'logprob': [50.8038444519043, 13.0]}, 128)
batch 881: ({'logprob': [29.043088912963867, 5.0]}, 128)
batch 882: ({'logprob': [54.83402633666992, 14.0]}, 128)
batch 883: ({'logprob': [61.90707015991211, 17.0]}, 128)
batch 884: ({'logprob': [51.28904342651367, 13.0]}, 128)
batch 885: ({'logprob': [52.291656494140625, 13.0]}, 128)
batch 886: ({'logprob': [62.42234802246094, 17.0]}, 128)

======================Test output======================
logprob:  0.416330, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.966556e-03 [2.589932e-09] 
Layer 'conv1' biases: 2.107283e-07 [4.972486e-11] 
Layer 'conv2' weights[0]: 7.953649e-03 [1.892478e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.898692e-10] 
Layer 'conv3' weights[0]: 7.951947e-03 [1.727890e-09] 
Layer 'conv3' biases: 1.813686e-06 [9.839297e-10] 
Layer 'conv4' weights[0]: 7.984550e-03 [1.783863e-09] 
Layer 'conv4' biases: 9.999994e-01 [8.165120e-09] 
Layer 'conv5' weights[0]: 7.983398e-03 [5.407922e-08] 
Layer 'conv5' biases: 9.999956e-01 [5.828397e-08] 
Layer 'fc6' weights[0]: 7.580120e-03 [4.648116e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.619418e-09] 
Layer 'fc7' weights[0]: 7.219258e-03 [3.985562e-08] 
Layer 'fc7' biases: 9.998625e-01 [1.477941e-08] 
Layer 'fc8' weights[0]: 1.305632e-03 [7.829306e-07] 
Layer 'fc8' biases: 4.720577e-02 [4.618910e-06] 
Train error last 870 batches: 0.435239
-------------------------------------------------------
Not saving because 0.416330 > 0.415685 (17.630: -0.01%)
======================================================= (12.100 sec)
20.121... logprob:  0.412650, 0.109375 (1.409 sec)
20.122... logprob:  0.519330, 0.148438 (1.449 sec)
20.123... logprob:  0.463723, 0.125000 (1.395 sec)
20.124... logprob:  0.447704, 0.125000 (1.405 sec)
20.125... logprob:  0.501978, 0.140625 (1.401 sec)
20.126... logprob:  0.475785, 0.125000 (1.389 sec)
20.127... logprob:  0.479589, 0.125000 (1.402 sec)
20.128... logprob:  0.422364, 0.109375 (1.418 sec)
20.129... logprob:  0.574893, 0.164062 (1.424 sec)
20.130... logprob:  0.382735, 0.093750 (1.423 sec)
20.131... logprob:  0.495499, 0.132812 (1.411 sec)
20.132... logprob:  0.506375, 0.140625 (1.438 sec)
20.133... logprob:  0.444683, 0.117188 (1.394 sec)
20.134... logprob:  0.401900, 0.101562 (1.400 sec)
20.135... logprob:  0.460223, 0.125000 (1.403 sec)
20.136... logprob:  0.562508, 0.164062 (1.399 sec)
20.137... logprob:  0.462573, 0.125000 (1.391 sec)
20.138... logprob:  0.319356, 0.070312 (1.448 sec)
20.139... logprob:  0.395772, 0.101562 (1.400 sec)
20.140... logprob:  0.560366, 0.164062 (1.412 sec)
20.141... logprob:  0.464550, 0.125000 (1.437 sec)
20.142... logprob:  0.464617, 0.125000 (1.395 sec)
20.143... logprob:  0.294308, 0.062500 (1.429 sec)
20.144... logprob:  0.457223, 0.125000 (1.419 sec)
20.145... logprob:  0.324827, 0.078125 (1.415 sec)
20.146... logprob:  0.483190, 0.132812 (1.438 sec)
20.147... logprob:  0.262473, 0.054688 (1.434 sec)
20.148... logprob:  0.458760, 0.125000 (1.392 sec)
20.149... logprob:  0.442544, 0.117188 (1.399 sec)
20.150... logprob:  0.347611, 0.085938 (1.403 sec)
20.151... logprob:  0.347149, 0.085938 (1.399 sec)
20.152... logprob:  0.785047, 0.234375 (1.390 sec)
20.153... logprob:  0.381659, 0.093750 (1.442 sec)
20.154... logprob:  0.524477, 0.148438 (1.401 sec)
20.155... logprob:  0.426017, 0.117188 (1.416 sec)
20.156... logprob:  0.295685, 0.062500 (1.444 sec)
20.157... logprob:  0.270597, 0.054688 (1.397 sec)
20.158... logprob:  0.455388, 0.125000 (1.412 sec)
20.159... logprob:  0.483115, 0.132812 (1.399 sec)
20.160... logprob:  0.444829, 0.117188 (1.390 sec)
20.161... logprob:  0.350017, 0.078125 (1.415 sec)
20.162... logprob:  0.611790, 0.179688 (1.405 sec)
20.163... logprob:  0.450441, 0.125000 (1.430 sec)
20.164... logprob:  0.468639, 0.125000 (1.427 sec)
20.165... logprob:  0.547895, 0.156250 (1.420 sec)
20.166... logprob:  0.446084, 0.125000 (1.452 sec)
20.167... logprob:  0.350471, 0.085938 (1.429 sec)
20.168... logprob:  0.363696, 0.085938 (1.425 sec)
20.169... logprob:  0.408666, 0.101562 (1.463 sec)
20.170... logprob:  0.459483, 0.125000 (1.401 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.970462799072266, 10.0]}, 128)
batch 872: ({'logprob': [66.10333251953125, 19.0]}, 128)
batch 873: ({'logprob': [41.26057052612305, 9.0]}, 128)
batch 874: ({'logprob': [45.5413818359375, 11.0]}, 128)
batch 875: ({'logprob': [50.95403289794922, 13.0]}, 128)
batch 876: ({'logprob': [63.69856262207031, 18.0]}, 128)
batch 877: ({'logprob': [46.1149787902832, 11.0]}, 128)
batch 878: ({'logprob': [61.821048736572266, 17.0]}, 128)
batch 879: ({'logprob': [73.218505859375, 21.0]}, 128)
batch 880: ({'logprob': [50.973167419433594, 13.0]}, 128)
batch 881: ({'logprob': [29.829299926757812, 5.0]}, 128)
batch 882: ({'logprob': [55.098514556884766, 14.0]}, 128)
batch 883: ({'logprob': [61.80120086669922, 17.0]}, 128)
batch 884: ({'logprob': [51.52323913574219, 13.0]}, 128)
batch 885: ({'logprob': [52.65739440917969, 13.0]}, 128)
batch 886: ({'logprob': [62.3816032409668, 17.0]}, 128)

======================Test output======================
logprob:  0.417455, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.966510e-03 [2.252253e-09] 
Layer 'conv1' biases: 2.116014e-07 [5.549588e-11] 
Layer 'conv2' weights[0]: 7.953606e-03 [2.000925e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.067686e-10] 
Layer 'conv3' weights[0]: 7.951906e-03 [2.020978e-09] 
Layer 'conv3' biases: 1.821938e-06 [9.982288e-10] 
Layer 'conv4' weights[0]: 7.984509e-03 [2.106259e-09] 
Layer 'conv4' biases: 9.999994e-01 [8.799150e-09] 
Layer 'conv5' weights[0]: 7.983357e-03 [5.604163e-08] 
Layer 'conv5' biases: 9.999955e-01 [6.045752e-08] 
Layer 'fc6' weights[0]: 7.580080e-03 [4.823276e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.793404e-09] 
Layer 'fc7' weights[0]: 7.217434e-03 [1.528064e-07] 
Layer 'fc7' biases: 9.998622e-01 [1.407793e-07] 
Layer 'fc8' weights[0]: 1.296993e-03 [5.872089e-06] 
Layer 'fc8' biases: 4.724244e-02 [4.071222e-05] 
Train error last 870 batches: 0.435239
-------------------------------------------------------
Not saving because 0.417455 > 0.415685 (17.630: -0.01%)
======================================================= (11.994 sec)
20.171... logprob:  0.535393, 0.156250 (1.427 sec)
20.172... logprob:  0.434852, 0.109375 (1.424 sec)
20.173... logprob:  0.440488, 0.117188 (1.421 sec)
20.174... logprob:  0.601016, 0.171875 (1.401 sec)
20.175... logprob:  0.506064, 0.140625 (1.471 sec)
20.176... logprob:  0.478462, 0.132812 (1.417 sec)
20.177... logprob:  0.289751, 0.054688 (1.431 sec)
20.178... logprob:  0.383482, 0.093750 (1.458 sec)
20.179... logprob:  0.394705, 0.101562 (1.414 sec)
20.180... logprob:  0.466383, 0.125000 (1.426 sec)
20.181... logprob:  0.539363, 0.156250 (1.419 sec)
20.182... logprob:  0.371364, 0.093750 (1.419 sec)
20.183... logprob:  0.419950, 0.109375 (1.424 sec)
20.184... logprob:  0.483461, 0.132812 (1.421 sec)
20.185... logprob:  0.289833, 0.062500 (1.390 sec)
20.186... logprob:  0.370461, 0.093750 (1.405 sec)
20.187... logprob:  0.529623, 0.148438 (1.406 sec)
20.188... logprob:  0.458950, 0.125000 (1.399 sec)
20.189... logprob:  0.440910, 0.117188 (1.388 sec)
20.190... logprob:  0.375759, 0.093750 (1.442 sec)
20.191... logprob:  0.485096, 0.132812 (1.404 sec)
20.192... logprob:  0.520121, 0.148438 (1.423 sec)
20.193... logprob:  0.312580, 0.070312 (1.418 sec)
20.194... logprob:  0.414095, 0.109375 (1.416 sec)
20.195... logprob:  0.287167, 0.062500 (1.404 sec)
20.196... logprob:  0.410523, 0.109375 (1.397 sec)
20.197... logprob:  0.478012, 0.132812 (1.398 sec)
20.198... logprob:  0.355794, 0.085938 (1.411 sec)
20.199... logprob:  0.437192, 0.117188 (1.389 sec)
20.200... logprob:  0.440759, 0.117188 (1.441 sec)
20.201... logprob:  0.437096, 0.117188 (1.404 sec)
20.202... logprob:  0.537926, 0.148438 (1.403 sec)
20.203... logprob:  0.420441, 0.109375 (1.446 sec)
20.204... logprob:  0.504124, 0.140625 (1.392 sec)
20.205... logprob:  0.334354, 0.078125 (1.400 sec)
20.206... logprob:  0.361631, 0.093750 (1.405 sec)
20.207... logprob:  0.381855, 0.093750 (1.392 sec)
20.208... logprob:  0.490540, 0.140625 (1.395 sec)
20.209... logprob:  0.334576, 0.078125 (1.426 sec)
20.210... logprob:  0.586240, 0.171875 (1.416 sec)
20.211... logprob:  0.488170, 0.132812 (1.418 sec)
20.212... logprob:  0.526141, 0.148438 (1.417 sec)
20.213... logprob:  0.514740, 0.140625 (1.463 sec)
20.214... logprob:  0.459423, 0.125000 (1.428 sec)
20.215... logprob:  0.396131, 0.101562 (1.420 sec)
20.216... logprob:  0.517044, 0.140625 (1.467 sec)
20.217... logprob:  0.325022, 0.070312 (1.406 sec)
20.218... logprob:  0.463661, 0.125000 (1.428 sec)
20.219... logprob:  0.500279, 0.140625 (1.420 sec)
20.220... logprob:  0.415008, 0.109375 (1.416 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.5406608581543, 10.0]}, 128)
batch 872: ({'logprob': [66.01133728027344, 19.0]}, 128)
batch 873: ({'logprob': [41.56239700317383, 9.0]}, 128)
batch 874: ({'logprob': [45.88344955444336, 11.0]}, 128)
batch 875: ({'logprob': [51.138099670410156, 13.0]}, 128)
batch 876: ({'logprob': [63.636016845703125, 18.0]}, 128)
batch 877: ({'logprob': [46.35845184326172, 11.0]}, 128)
batch 878: ({'logprob': [61.689048767089844, 17.0]}, 128)
batch 879: ({'logprob': [72.6714859008789, 21.0]}, 128)
batch 880: ({'logprob': [51.15762710571289, 13.0]}, 128)
batch 881: ({'logprob': [30.54686164855957, 5.0]}, 128)
batch 882: ({'logprob': [54.95520782470703, 14.0]}, 128)
batch 883: ({'logprob': [61.66893768310547, 17.0]}, 128)
batch 884: ({'logprob': [51.6074104309082, 13.0]}, 128)
batch 885: ({'logprob': [52.54298782348633, 13.0]}, 128)
batch 886: ({'logprob': [62.1499137878418, 17.0]}, 128)

======================Test output======================
logprob:  0.418027, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.966480e-03 [2.707340e-09] 
Layer 'conv1' biases: 2.125418e-07 [7.272521e-11] 
Layer 'conv2' weights[0]: 7.953573e-03 [2.129229e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.348901e-10] 
Layer 'conv3' weights[0]: 7.951863e-03 [1.951895e-09] 
Layer 'conv3' biases: 1.830565e-06 [9.936853e-10] 
Layer 'conv4' weights[0]: 7.984475e-03 [2.071341e-09] 
Layer 'conv4' biases: 9.999994e-01 [9.358636e-09] 
Layer 'conv5' weights[0]: 7.983324e-03 [6.237373e-08] 
Layer 'conv5' biases: 9.999958e-01 [6.723396e-08] 
Layer 'fc6' weights[0]: 7.580040e-03 [5.254172e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.290928e-09] 
Layer 'fc7' weights[0]: 7.215576e-03 [1.064505e-07] 
Layer 'fc7' biases: 9.998617e-01 [9.174517e-08] 
Layer 'fc8' weights[0]: 1.287746e-03 [5.811268e-06] 
Layer 'fc8' biases: 4.725487e-02 [3.982544e-05] 
Train error last 870 batches: 0.435238
-------------------------------------------------------
Not saving because 0.418027 > 0.415685 (17.630: -0.01%)
======================================================= (12.094 sec)
20.221... logprob:  0.399550, 0.101562 (1.416 sec)
20.222... logprob:  0.554520, 0.164062 (1.465 sec)
20.223... logprob:  0.569131, 0.164062 (1.423 sec)
20.224... logprob:  0.405909, 0.101562 (1.435 sec)
20.225... logprob:  0.391979, 0.101562 (1.448 sec)
20.226... logprob:  0.424672, 0.109375 (1.427 sec)
20.227... logprob:  0.452694, 0.125000 (1.414 sec)
20.228... logprob:  0.417186, 0.109375 (1.417 sec)
20.229... logprob:  0.489371, 0.132812 (1.416 sec)
20.230... logprob:  0.459881, 0.125000 (1.433 sec)
20.231... logprob:  0.453525, 0.125000 (1.409 sec)
20.232... logprob:  0.496206, 0.140625 (1.461 sec)
20.233... logprob:  0.466129, 0.132812 (1.429 sec)
20.234... logprob:  0.563823, 0.164062 (1.417 sec)
20.235... logprob:  0.482023, 0.132812 (1.471 sec)
20.236... logprob:  0.425745, 0.109375 (1.408 sec)
20.237... logprob:  0.341191, 0.078125 (1.427 sec)
20.238... logprob:  0.389286, 0.093750 (1.420 sec)
20.239... logprob:  0.478122, 0.132812 (1.425 sec)
20.240... logprob:  0.485802, 0.132812 (1.401 sec)
20.241... logprob:  0.493603, 0.132812 (1.462 sec)
20.242... logprob:  0.341649, 0.078125 (1.424 sec)
20.243... logprob:  0.386011, 0.093750 (1.439 sec)
20.244... logprob:  0.315296, 0.070312 (1.452 sec)
20.245... logprob:  0.494299, 0.132812 (1.422 sec)
20.246... logprob:  0.416884, 0.109375 (1.417 sec)
20.247... logprob:  0.357433, 0.085938 (1.419 sec)
20.248... logprob:  0.307857, 0.070312 (1.420 sec)
20.249... logprob:  0.555128, 0.156250 (1.431 sec)
20.250... logprob:  0.591548, 0.164062 (1.406 sec)
20.251... logprob:  0.352939, 0.085938 (1.464 sec)
20.252... logprob:  0.348468, 0.085938 (1.431 sec)
20.253... logprob:  0.379189, 0.093750 (1.422 sec)
20.254... logprob:  0.444173, 0.117188 (1.467 sec)
20.255... logprob:  0.351429, 0.085938 (1.431 sec)
20.256... logprob:  0.378786, 0.093750 (1.418 sec)
20.257... logprob:  0.332018, 0.078125 (1.422 sec)
20.258... logprob:  0.415678, 0.109375 (1.422 sec)
20.259... logprob:  0.442313, 0.117188 (1.402 sec)
20.260... logprob:  0.308318, 0.070312 (1.461 sec)
20.261... logprob:  0.392722, 0.101562 (1.437 sec)
20.262... logprob:  0.524617, 0.148438 (1.437 sec)
20.263... logprob:  0.425515, 0.109375 (1.451 sec)
20.264... logprob:  0.375106, 0.093750 (1.424 sec)
20.265... logprob:  0.439613, 0.117188 (1.416 sec)
20.266... logprob:  0.439025, 0.117188 (1.421 sec)
20.267... logprob:  0.422014, 0.109375 (1.428 sec)
20.268... logprob:  0.458940, 0.125000 (1.427 sec)
20.269... logprob:  0.567503, 0.164062 (1.408 sec)
20.270... logprob:  0.542253, 0.156250 (1.463 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.67536926269531, 10.0]}, 128)
batch 872: ({'logprob': [66.2900161743164, 19.0]}, 128)
batch 873: ({'logprob': [41.21332931518555, 9.0]}, 128)
batch 874: ({'logprob': [45.823062896728516, 11.0]}, 128)
batch 875: ({'logprob': [51.09382629394531, 13.0]}, 128)
batch 876: ({'logprob': [63.83894348144531, 18.0]}, 128)
batch 877: ({'logprob': [46.162071228027344, 11.0]}, 128)
batch 878: ({'logprob': [61.67911148071289, 17.0]}, 128)
batch 879: ({'logprob': [72.56039428710938, 21.0]}, 128)
batch 880: ({'logprob': [51.11402893066406, 13.0]}, 128)
batch 881: ({'logprob': [30.299219131469727, 5.0]}, 128)
batch 882: ({'logprob': [54.5806884765625, 14.0]}, 128)
batch 883: ({'logprob': [61.65874099731445, 17.0]}, 128)
batch 884: ({'logprob': [51.42817306518555, 13.0]}, 128)
batch 885: ({'logprob': [52.0920295715332, 13.0]}, 128)
batch 886: ({'logprob': [62.004432678222656, 17.0]}, 128)

======================Test output======================
logprob:  0.417243, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.966446e-03 [4.835889e-09] 
Layer 'conv1' biases: 2.135355e-07 [1.458731e-10] 
Layer 'conv2' weights[0]: 7.953537e-03 [4.087670e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.294684e-10] 
Layer 'conv3' weights[0]: 7.951821e-03 [3.878815e-09] 
Layer 'conv3' biases: 1.838737e-06 [2.570191e-09] 
Layer 'conv4' weights[0]: 7.984438e-03 [4.071858e-09] 
Layer 'conv4' biases: 9.999994e-01 [2.260631e-08] 
Layer 'conv5' weights[0]: 7.983281e-03 [1.467531e-07] 
Layer 'conv5' biases: 9.999961e-01 [1.582155e-07] 
Layer 'fc6' weights[0]: 7.579995e-03 [1.223962e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.252893e-08] 
Layer 'fc7' weights[0]: 7.213715e-03 [3.382235e-07] 
Layer 'fc7' biases: 9.998617e-01 [3.285213e-07] 
Layer 'fc8' weights[0]: 1.296636e-03 [1.351876e-05] 
Layer 'fc8' biases: 4.740144e-02 [8.792641e-05] 
Train error last 870 batches: 0.435238
-------------------------------------------------------
Not saving because 0.417243 > 0.415685 (17.630: -0.01%)
======================================================= (12.060 sec)
20.271... logprob:  0.445695, 0.117188 (1.435 sec)
20.272... logprob:  0.384692, 0.093750 (1.425 sec)
20.273... logprob:  0.500222, 0.140625 (1.475 sec)
20.274... logprob:  0.542516, 0.156250 (1.404 sec)
20.275... logprob:  0.487674, 0.132812 (1.425 sec)
20.276... logprob:  0.390117, 0.093750 (1.417 sec)
20.277... logprob:  0.428678, 0.109375 (1.430 sec)
20.278... logprob:  0.323477, 0.070312 (1.426 sec)
20.279... logprob:  0.325081, 0.070312 (1.463 sec)
20.280... logprob:  0.215466, 0.031250 (1.408 sec)
20.281... logprob:  0.417225, 0.109375 (1.430 sec)
20.282... logprob:  0.411407, 0.109375 (1.429 sec)
20.283... logprob:  0.393811, 0.101562 (1.416 sec)
20.284... logprob:  0.394579, 0.101562 (1.416 sec)
20.285... logprob:  0.451891, 0.117188 (1.438 sec)
20.286... logprob:  0.537072, 0.140625 (1.440 sec)
20.287... logprob:  0.346622, 0.085938 (1.432 sec)
20.288... logprob:  0.329965, 0.078125 (1.464 sec)
20.289... logprob:  0.445945, 0.117188 (1.442 sec)
20.290... logprob:  0.490657, 0.132812 (1.412 sec)
20.291... logprob:  0.439216, 0.117188 (1.418 sec)
20.292... logprob:  0.567279, 0.156250 (1.421 sec)
20.293... logprob:  0.427583, 0.117188 (1.428 sec)
20.294... logprob:  0.356025, 0.085938 (1.406 sec)
20.295... logprob:  0.334841, 0.078125 (1.464 sec)
20.296... logprob:  0.355940, 0.085938 (1.421 sec)
20.297... logprob:  0.394641, 0.101562 (1.422 sec)
20.298... logprob:  0.448155, 0.125000 (1.468 sec)
20.299... logprob:  0.342393, 0.078125 (1.401 sec)
20.300... logprob:  0.406574, 0.101562 (1.428 sec)
20.301... logprob:  0.397938, 0.101562 (1.415 sec)
20.302... logprob:  0.591551, 0.179688 (1.424 sec)
20.303... logprob:  0.459579, 0.125000 (1.405 sec)
20.304... logprob:  0.459674, 0.125000 (1.446 sec)
20.305... logprob:  0.455222, 0.125000 (1.433 sec)
20.306... logprob:  0.440597, 0.117188 (1.441 sec)
20.307... logprob:  0.421609, 0.109375 (1.439 sec)
20.308... logprob:  0.374657, 0.093750 (1.458 sec)
20.309... logprob:  0.450485, 0.125000 (1.417 sec)
20.310... logprob:  0.473697, 0.125000 (1.423 sec)
20.311... logprob:  0.502595, 0.140625 (1.426 sec)
20.312... logprob:  0.478754, 0.132812 (1.425 sec)
20.313... logprob:  0.454867, 0.125000 (1.426 sec)
20.314... logprob:  0.454455, 0.117188 (1.467 sec)
20.315... logprob:  0.314679, 0.070312 (1.432 sec)
20.316... logprob:  0.468556, 0.125000 (1.430 sec)
20.317... logprob:  0.355486, 0.085938 (1.475 sec)
20.318... logprob:  0.455413, 0.125000 (1.418 sec)
20.319... logprob:  0.423195, 0.117188 (1.430 sec)
20.320... logprob:  0.412252, 0.109375 (1.432 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.477989196777344, 10.0]}, 128)
batch 872: ({'logprob': [66.55294799804688, 19.0]}, 128)
batch 873: ({'logprob': [40.626739501953125, 9.0]}, 128)
batch 874: ({'logprob': [45.13724899291992, 11.0]}, 128)
batch 875: ({'logprob': [50.75709915161133, 13.0]}, 128)
batch 876: ({'logprob': [64.03935241699219, 18.0]}, 128)
batch 877: ({'logprob': [45.699256896972656, 11.0]}, 128)
batch 878: ({'logprob': [62.040863037109375, 17.0]}, 128)
batch 879: ({'logprob': [73.84390258789062, 21.0]}, 128)
batch 880: ({'logprob': [50.77682113647461, 13.0]}, 128)
batch 881: ({'logprob': [28.78913688659668, 5.0]}, 128)
batch 882: ({'logprob': [54.98009490966797, 14.0]}, 128)
batch 883: ({'logprob': [62.02072525024414, 17.0]}, 128)
batch 884: ({'logprob': [51.3172721862793, 13.0]}, 128)
batch 885: ({'logprob': [52.42997360229492, 13.0]}, 128)
batch 886: ({'logprob': [62.59156799316406, 17.0]}, 128)

======================Test output======================
logprob:  0.416543, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.966401e-03 [2.105342e-09] 
Layer 'conv1' biases: 2.143925e-07 [3.410134e-11] 
Layer 'conv2' weights[0]: 7.953491e-03 [1.678651e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.622638e-10] 
Layer 'conv3' weights[0]: 7.951788e-03 [1.306115e-09] 
Layer 'conv3' biases: 1.843991e-06 [4.781875e-10] 
Layer 'conv4' weights[0]: 7.984395e-03 [1.423121e-09] 
Layer 'conv4' biases: 9.999994e-01 [3.806838e-09] 
Layer 'conv5' weights[0]: 7.983222e-03 [2.438351e-08] 
Layer 'conv5' biases: 9.999955e-01 [2.618025e-08] 
Layer 'fc6' weights[0]: 7.579966e-03 [2.213322e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.064611e-09] 
Layer 'fc7' weights[0]: 7.211893e-03 [1.208006e-07] 
Layer 'fc7' biases: 9.998626e-01 [1.066302e-07] 
Layer 'fc8' weights[0]: 1.317961e-03 [3.832552e-06] 
Layer 'fc8' biases: 4.783774e-02 [2.629378e-05] 
Train error last 870 batches: 0.435238
-------------------------------------------------------
Not saving because 0.416543 > 0.415685 (17.630: -0.01%)
======================================================= (12.063 sec)
20.321... logprob:  0.348274, 0.085938 (1.435 sec)
20.322... logprob:  0.387493, 0.101562 (1.420 sec)
20.323... logprob:  0.416517, 0.109375 (1.479 sec)
20.324... logprob:  0.498618, 0.140625 (1.423 sec)
20.325... logprob:  0.350680, 0.085938 (1.441 sec)
20.326... logprob:  0.543184, 0.148438 (1.462 sec)
20.327... logprob:  0.554403, 0.164062 (1.425 sec)
20.328... logprob:  0.565052, 0.156250 (1.426 sec)
20.329... logprob:  0.401970, 0.101562 (1.425 sec)
20.330... logprob:  0.388610, 0.101562 (1.424 sec)
20.331... logprob:  0.352445, 0.085938 (1.426 sec)
20.332... logprob:  0.482784, 0.132812 (1.454 sec)
20.333... logprob:  0.339588, 0.085938 (1.443 sec)
20.334... logprob:  0.565166, 0.171875 (1.442 sec)
20.335... logprob:  0.358804, 0.085938 (1.444 sec)
20.336... logprob:  0.444840, 0.125000 (1.454 sec)
20.337... logprob:  0.566450, 0.164062 (1.420 sec)
20.338... logprob:  0.449515, 0.125000 (1.420 sec)
20.339... logprob:  0.488664, 0.132812 (1.430 sec)
20.340... logprob:  0.442073, 0.117188 (1.433 sec)
20.341... logprob:  0.530107, 0.148438 (1.424 sec)
20.342... logprob:  0.429652, 0.109375 (1.463 sec)
20.343... logprob:  0.434777, 0.109375 (1.443 sec)
20.344... logprob:  0.444457, 0.125000 (1.482 sec)
20.345... logprob:  0.488236, 0.132812 (1.442 sec)
20.346... logprob:  0.436230, 0.117188 (1.438 sec)
20.347... logprob:  0.372413, 0.085938 (1.484 sec)
20.348... logprob:  0.398451, 0.101562 (1.433 sec)
20.349... logprob:  0.497783, 0.140625 (1.433 sec)
20.350... logprob:  0.358600, 0.085938 (1.439 sec)
20.351... logprob:  0.508613, 0.140625 (1.431 sec)
20.352... logprob:  0.363644, 0.093750 (1.433 sec)
20.353... logprob:  0.512680, 0.148438 (1.493 sec)
20.354... logprob:  0.675028, 0.203125 (1.435 sec)
20.355... logprob:  0.357481, 0.085938 (1.441 sec)
20.356... logprob:  0.479245, 0.132812 (1.481 sec)
20.357... logprob:  0.346935, 0.085938 (1.431 sec)
20.358... logprob:  0.325935, 0.070312 (1.440 sec)
20.359... logprob:  0.555273, 0.164062 (1.432 sec)
20.360... logprob:  0.444516, 0.117188 (1.425 sec)
20.361... logprob:  0.410764, 0.101562 (1.438 sec)
20.362... logprob:  0.424071, 0.117188 (1.474 sec)
20.363... logprob:  0.486583, 0.132812 (1.476 sec)
20.364... logprob:  0.475563, 0.125000 (1.451 sec)
20.365... logprob:  0.425071, 0.109375 (1.468 sec)
20.366... logprob:  0.409654, 0.109375 (1.444 sec)
20.367... logprob:  0.324971, 0.078125 (1.443 sec)
20.368... logprob:  0.595643, 0.171875 (1.430 sec)
20.369... logprob:  0.381578, 0.093750 (1.427 sec)
20.370... logprob:  0.381207, 0.093750 (1.442 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.827362060546875, 10.0]}, 128)
batch 872: ({'logprob': [66.51101684570312, 19.0]}, 128)
batch 873: ({'logprob': [40.64626693725586, 9.0]}, 128)
batch 874: ({'logprob': [45.27461624145508, 11.0]}, 128)
batch 875: ({'logprob': [50.79530334472656, 13.0]}, 128)
batch 876: ({'logprob': [63.993011474609375, 18.0]}, 128)
batch 877: ({'logprob': [45.72858428955078, 11.0]}, 128)
batch 878: ({'logprob': [61.881553649902344, 17.0]}, 128)
batch 879: ({'logprob': [73.3788833618164, 21.0]}, 128)
batch 880: ({'logprob': [50.8155403137207, 13.0]}, 128)
batch 881: ({'logprob': [29.114917755126953, 5.0]}, 128)
batch 882: ({'logprob': [54.698177337646484, 14.0]}, 128)
batch 883: ({'logprob': [61.86106491088867, 17.0]}, 128)
batch 884: ({'logprob': [51.24709701538086, 13.0]}, 128)
batch 885: ({'logprob': [52.14308166503906, 13.0]}, 128)
batch 886: ({'logprob': [62.323692321777344, 17.0]}, 128)

======================Test output======================
logprob:  0.416133, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.966360e-03 [2.586761e-09] 
Layer 'conv1' biases: 2.152301e-07 [6.027023e-11] 
Layer 'conv2' weights[0]: 7.953447e-03 [2.137846e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.170563e-10] 
Layer 'conv3' weights[0]: 7.951744e-03 [1.981320e-09] 
Layer 'conv3' biases: 1.851513e-06 [1.015669e-09] 
Layer 'conv4' weights[0]: 7.984363e-03 [2.023356e-09] 
Layer 'conv4' biases: 9.999993e-01 [8.596366e-09] 
Layer 'conv5' weights[0]: 7.983191e-03 [5.299605e-08] 
Layer 'conv5' biases: 9.999955e-01 [5.721263e-08] 
Layer 'fc6' weights[0]: 7.579929e-03 [4.559724e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.540672e-09] 
Layer 'fc7' weights[0]: 7.210075e-03 [1.080512e-07] 
Layer 'fc7' biases: 9.998621e-01 [9.331003e-08] 
Layer 'fc8' weights[0]: 1.312646e-03 [6.710932e-06] 
Layer 'fc8' biases: 4.789728e-02 [4.462423e-05] 
Train error last 870 batches: 0.435237
-------------------------------------------------------
Not saving because 0.416133 > 0.415685 (17.630: -0.01%)
======================================================= (12.136 sec)
20.371... logprob:  0.400372, 0.101562 (1.484 sec)
20.372... logprob:  0.537476, 0.156250 (1.466 sec)
20.373... logprob:  0.463815, 0.125000 (1.459 sec)
20.374... logprob:  0.526991, 0.148438 (1.467 sec)
20.375... logprob:  0.393777, 0.101562 (1.475 sec)
20.376... logprob:  0.374304, 0.093750 (1.444 sec)
20.377... logprob:  0.295394, 0.062500 (1.443 sec)
20.378... logprob:  0.453735, 0.125000 (1.442 sec)
20.379... logprob:  0.420239, 0.109375 (1.444 sec)
20.380... logprob:  0.605733, 0.179688 (1.451 sec)
20.381... logprob:  0.463459, 0.125000 (1.473 sec)
20.382... logprob:  0.529530, 0.148438 (1.461 sec)
20.383... logprob:  0.358638, 0.085938 (1.445 sec)
20.384... logprob:  0.521102, 0.148438 (1.494 sec)
20.385... logprob:  0.523505, 0.148438 (1.437 sec)
20.386... logprob:  0.582415, 0.171875 (1.436 sec)
20.387... logprob:  0.428626, 0.117188 (1.441 sec)
20.388... logprob:  0.521330, 0.148438 (1.450 sec)
20.389... logprob:  0.425798, 0.109375 (1.438 sec)
20.390... logprob:  0.419847, 0.109375 (1.477 sec)
20.391... logprob:  0.318309, 0.070312 (1.456 sec)
20.392... logprob:  0.439436, 0.117188 (1.447 sec)
20.393... logprob:  0.368904, 0.093750 (1.496 sec)
20.394... logprob:  0.343552, 0.078125 (1.452 sec)
20.395... logprob:  0.331663, 0.078125 (1.451 sec)
20.396... logprob:  0.252078, 0.046875 (1.451 sec)
20.397... logprob:  0.484531, 0.132812 (1.450 sec)
20.398... logprob:  0.471201, 0.125000 (1.451 sec)
20.399... logprob:  0.433551, 0.117188 (1.501 sec)
20.400... logprob:  0.538234, 0.148438 (1.453 sec)
20.401... logprob:  0.466021, 0.125000 (1.460 sec)
20.402... logprob:  0.474140, 0.125000 (1.485 sec)
20.403... logprob:  0.462202, 0.125000 (1.443 sec)
20.404... logprob:  0.474828, 0.125000 (1.445 sec)
20.405... logprob:  0.543979, 0.156250 (1.436 sec)
20.406... logprob:  0.357794, 0.085938 (1.441 sec)
20.407... logprob:  0.492787, 0.140625 (1.440 sec)
20.408... logprob:  0.339474, 0.078125 (1.478 sec)
20.409... logprob:  0.400822, 0.101562 (1.452 sec)
20.410... logprob:  0.581903, 0.171875 (1.446 sec)
20.411... logprob:  0.398128, 0.101562 (1.490 sec)
20.412... logprob:  0.540237, 0.156250 (1.450 sec)
20.413... logprob:  0.544692, 0.156250 (1.447 sec)
20.414... logprob:  0.466556, 0.125000 (1.444 sec)
20.415... logprob:  0.401758, 0.101562 (1.434 sec)
20.416... logprob:  0.427551, 0.109375 (1.449 sec)
20.417... logprob:  0.405436, 0.093750 (1.471 sec)
20.418... logprob:  0.380192, 0.093750 (1.453 sec)
20.419... logprob:  0.417649, 0.101562 (1.461 sec)
20.420... logprob:  0.356046, 0.085938 (1.457 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.64868927001953, 10.0]}, 128)
batch 872: ({'logprob': [66.4780044555664, 19.0]}, 128)
batch 873: ({'logprob': [40.68925857543945, 9.0]}, 128)
batch 874: ({'logprob': [45.219512939453125, 11.0]}, 128)
batch 875: ({'logprob': [50.78048324584961, 13.0]}, 128)
batch 876: ({'logprob': [63.974246978759766, 18.0]}, 128)
batch 877: ({'logprob': [45.74245834350586, 11.0]}, 128)
batch 878: ({'logprob': [61.94655227661133, 17.0]}, 128)
batch 879: ({'logprob': [73.59268188476562, 21.0]}, 128)
batch 880: ({'logprob': [50.800392150878906, 13.0]}, 128)
batch 881: ({'logprob': [29.00898551940918, 5.0]}, 128)
batch 882: ({'logprob': [54.8758430480957, 14.0]}, 128)
batch 883: ({'logprob': [61.92630386352539, 17.0]}, 128)
batch 884: ({'logprob': [51.30131912231445, 13.0]}, 128)
batch 885: ({'logprob': [52.33543014526367, 13.0]}, 128)
batch 886: ({'logprob': [62.457828521728516, 17.0]}, 128)

======================Test output======================
logprob:  0.416396, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.966331e-03 [3.538048e-09] 
Layer 'conv1' biases: 2.161088e-07 [1.638329e-10] 
Layer 'conv2' weights[0]: 7.953409e-03 [4.070118e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.297885e-10] 
Layer 'conv3' weights[0]: 7.951706e-03 [4.144745e-09] 
Layer 'conv3' biases: 1.855722e-06 [2.520507e-09] 
Layer 'conv4' weights[0]: 7.984321e-03 [4.207880e-09] 
Layer 'conv4' biases: 9.999994e-01 [2.237400e-08] 
Layer 'conv5' weights[0]: 7.983145e-03 [1.435935e-07] 
Layer 'conv5' biases: 9.999949e-01 [1.549206e-07] 
Layer 'fc6' weights[0]: 7.579884e-03 [1.198666e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.226268e-08] 
Layer 'fc7' weights[0]: 7.208273e-03 [4.140530e-07] 
Layer 'fc7' biases: 9.998623e-01 [4.017854e-07] 
Layer 'fc8' weights[0]: 1.309279e-03 [1.843899e-05] 
Layer 'fc8' biases: 4.815187e-02 [1.271628e-04] 
Train error last 870 batches: 0.435237
-------------------------------------------------------
Not saving because 0.416396 > 0.415685 (17.630: -0.01%)
======================================================= (12.097 sec)
20.421... logprob:  0.376562, 0.101562 (1.470 sec)
20.422... logprob:  0.522825, 0.148438 (1.455 sec)
20.423... logprob:  0.420973, 0.109375 (1.437 sec)
20.424... logprob:  0.324682, 0.078125 (1.440 sec)
20.425... logprob:  0.306220, 0.070312 (1.445 sec)
20.426... logprob:  0.449328, 0.117188 (1.448 sec)
20.427... logprob:  0.554791, 0.156250 (1.466 sec)
20.428... logprob:  0.602148, 0.171875 (1.480 sec)
20.429... logprob:  0.426297, 0.109375 (1.445 sec)
20.430... logprob:  0.299915, 0.070312 (1.476 sec)
20.431... logprob:  0.599485, 0.171875 (1.436 sec)
20.432... logprob:  0.387578, 0.093750 (1.426 sec)
20.433... logprob:  0.330097, 0.078125 (1.439 sec)
20.434... logprob:  0.529226, 0.148438 (1.447 sec)
20.435... logprob:  0.532158, 0.156250 (1.433 sec)
20.436... logprob:  0.381433, 0.093750 (1.479 sec)
20.437... logprob:  0.500245, 0.140625 (1.446 sec)
20.438... logprob:  0.546819, 0.156250 (1.434 sec)
20.439... logprob:  0.379075, 0.093750 (1.487 sec)
20.440... logprob:  0.439836, 0.117188 (1.438 sec)
20.441... logprob:  0.468026, 0.125000 (1.431 sec)
20.442... logprob:  0.378933, 0.093750 (1.436 sec)
20.443... logprob:  0.496580, 0.140625 (1.436 sec)
20.444... logprob:  0.372170, 0.093750 (1.431 sec)
20.445... logprob:  0.362266, 0.085938 (1.488 sec)
20.446... logprob:  0.398161, 0.101562 (1.438 sec)
20.447... logprob:  0.570184, 0.164062 (1.442 sec)
20.448... logprob:  0.332602, 0.078125 (1.483 sec)
20.449... logprob:  0.400023, 0.101562 (1.435 sec)
20.450... logprob:  0.239009, 0.046875 (1.433 sec)
20.451... logprob:  0.452931, 0.125000 (1.437 sec)
20.452... logprob:  0.456305, 0.117188 (1.431 sec)
20.453... logprob:  0.455444, 0.125000 (1.435 sec)
20.454... logprob:  0.489186, 0.132812 (1.487 sec)
20.455... logprob:  0.506126, 0.140625 (1.441 sec)
20.456... logprob:  0.468818, 0.125000 (1.446 sec)
20.457... logprob:  0.375373, 0.093750 (1.472 sec)
20.458... logprob:  0.351162, 0.085938 (1.440 sec)
20.459... logprob:  0.513740, 0.140625 (1.439 sec)
20.460... logprob:  0.274405, 0.054688 (1.437 sec)
20.461... logprob:  0.460009, 0.125000 (1.423 sec)
20.462... logprob:  0.471912, 0.125000 (1.443 sec)
20.463... logprob:  0.420919, 0.109375 (1.477 sec)
20.464... logprob:  0.482701, 0.132812 (1.450 sec)
20.465... logprob:  0.421196, 0.109375 (1.453 sec)
20.466... logprob:  0.318580, 0.070312 (1.464 sec)
20.467... logprob:  0.413864, 0.109375 (1.450 sec)
20.468... logprob:  0.394276, 0.101562 (1.444 sec)
20.469... logprob:  0.334688, 0.078125 (1.426 sec)
20.470... logprob:  0.400063, 0.101562 (1.432 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.53475570678711, 10.0]}, 128)
batch 872: ({'logprob': [66.8952407836914, 19.0]}, 128)
batch 873: ({'logprob': [40.24216842651367, 9.0]}, 128)
batch 874: ({'logprob': [45.04106140136719, 11.0]}, 128)
batch 875: ({'logprob': [50.710453033447266, 13.0]}, 128)
batch 876: ({'logprob': [64.29755401611328, 18.0]}, 128)
batch 877: ({'logprob': [45.48379898071289, 11.0]}, 128)
batch 878: ({'logprob': [62.095191955566406, 17.0]}, 128)
batch 879: ({'logprob': [73.88057708740234, 21.0]}, 128)
batch 880: ({'logprob': [50.73078155517578, 13.0]}, 128)
batch 881: ({'logprob': [28.422504425048828, 5.0]}, 128)
batch 882: ({'logprob': [54.662235260009766, 14.0]}, 128)
batch 883: ({'logprob': [62.07484436035156, 17.0]}, 128)
batch 884: ({'logprob': [51.15278625488281, 13.0]}, 128)
batch 885: ({'logprob': [52.027740478515625, 13.0]}, 128)
batch 886: ({'logprob': [62.527366638183594, 17.0]}, 128)

======================Test output======================
logprob:  0.415908, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.966293e-03 [3.003589e-09] 
Layer 'conv1' biases: 2.169262e-07 [9.348974e-11] 
Layer 'conv2' weights[0]: 7.953379e-03 [2.663613e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.722470e-10] 
Layer 'conv3' weights[0]: 7.951667e-03 [2.559292e-09] 
Layer 'conv3' biases: 1.863317e-06 [1.397919e-09] 
Layer 'conv4' weights[0]: 7.984286e-03 [2.762132e-09] 
Layer 'conv4' biases: 9.999993e-01 [1.259120e-08] 
Layer 'conv5' weights[0]: 7.983107e-03 [8.245032e-08] 
Layer 'conv5' biases: 9.999950e-01 [8.887314e-08] 
Layer 'fc6' weights[0]: 7.579846e-03 [6.930433e-09] 
Layer 'fc6' biases: 9.999999e-01 [7.039247e-09] 
Layer 'fc7' weights[0]: 7.206417e-03 [2.408949e-07] 
Layer 'fc7' biases: 9.998624e-01 [2.293073e-07] 
Layer 'fc8' weights[0]: 1.317097e-03 [9.147800e-06] 
Layer 'fc8' biases: 4.852126e-02 [6.216559e-05] 
Train error last 870 batches: 0.435237
-------------------------------------------------------
Not saving because 0.415908 > 0.415685 (17.630: -0.01%)
======================================================= (12.039 sec)
20.471... logprob:  0.529541, 0.148438 (1.442 sec)
20.472... logprob:  0.410057, 0.109375 (1.461 sec)
20.473... logprob:  0.375368, 0.093750 (1.457 sec)
20.474... logprob:  0.465745, 0.125000 (1.456 sec)
20.475... logprob:  0.504315, 0.140625 (1.450 sec)
20.476... logprob:  0.510426, 0.140625 (1.471 sec)
20.477... logprob:  0.334527, 0.078125 (1.437 sec)
20.478... logprob:  0.464280, 0.125000 (1.432 sec)
20.479... logprob:  0.305782, 0.070312 (1.427 sec)
20.480... logprob:  0.443516, 0.117188 (1.443 sec)
20.481... logprob:  0.547763, 0.156250 (1.435 sec)
20.482... logprob:  0.443172, 0.117188 (1.480 sec)
20.483... logprob:  0.502602, 0.140625 (1.446 sec)
20.484... logprob:  0.485294, 0.132812 (1.439 sec)
20.485... logprob:  0.409056, 0.109375 (1.483 sec)
20.486... logprob:  0.361548, 0.085938 (1.439 sec)
20.487... logprob:  0.522629, 0.148438 (1.427 sec)
20.488... logprob:  0.424851, 0.109375 (1.441 sec)
20.489... logprob:  0.415927, 0.109375 (1.432 sec)
20.490... logprob:  0.440700, 0.117188 (1.438 sec)
20.491... logprob:  0.313693, 0.070312 (1.482 sec)
20.492... logprob:  0.459589, 0.125000 (1.438 sec)
20.493... logprob:  0.521923, 0.148438 (1.442 sec)
20.494... logprob:  0.450372, 0.125000 (1.478 sec)
20.495... logprob:  0.380582, 0.093750 (1.433 sec)
20.496... logprob:  0.550456, 0.156250 (1.430 sec)
20.497... logprob:  0.467010, 0.125000 (1.441 sec)
20.498... logprob:  0.476313, 0.132812 (1.429 sec)
20.499... logprob:  0.456267, 0.125000 (1.435 sec)
20.500... logprob:  0.355093, 0.085938 (1.491 sec)
20.501... logprob:  0.339110, 0.078125 (1.436 sec)
20.502... logprob:  0.459650, 0.125000 (1.480 sec)
20.503... logprob:  0.400683, 0.101562 (1.482 sec)
20.504... logprob:  0.487329, 0.132812 (1.429 sec)
20.505... logprob:  0.570804, 0.164062 (1.435 sec)
20.506... logprob:  0.479683, 0.132812 (1.433 sec)
20.507... logprob:  0.385115, 0.093750 (1.426 sec)
20.508... logprob:  0.374735, 0.093750 (1.437 sec)
20.509... logprob:  0.323168, 0.070312 (1.477 sec)
20.510... logprob:  0.390480, 0.101562 (1.448 sec)
20.511... logprob:  0.410073, 0.109375 (1.452 sec)
20.512... logprob:  0.470738, 0.125000 (1.469 sec)
20.513... logprob:  0.324973, 0.078125 (1.444 sec)
20.514... logprob:  0.406276, 0.101562 (1.437 sec)
20.515... logprob:  0.455567, 0.125000 (1.434 sec)
20.516... logprob:  0.400380, 0.109375 (1.425 sec)
20.517... logprob:  0.627976, 0.179688 (1.440 sec)
20.518... logprob:  0.437700, 0.117188 (1.463 sec)
20.519... logprob:  0.516146, 0.140625 (1.453 sec)
20.520... logprob:  0.409653, 0.109375 (1.460 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.95003128051758, 10.0]}, 128)
batch 872: ({'logprob': [66.38726043701172, 19.0]}, 128)
batch 873: ({'logprob': [40.81416320800781, 9.0]}, 128)
batch 874: ({'logprob': [45.377960205078125, 11.0]}, 128)
batch 875: ({'logprob': [50.84477615356445, 13.0]}, 128)
batch 876: ({'logprob': [63.8986930847168, 18.0]}, 128)
batch 877: ({'logprob': [45.83735275268555, 11.0]}, 128)
batch 878: ({'logprob': [61.822505950927734, 17.0]}, 128)
batch 879: ({'logprob': [73.21681213378906, 21.0]}, 128)
batch 880: ({'logprob': [50.86480712890625, 13.0]}, 128)
batch 881: ({'logprob': [29.386314392089844, 5.0]}, 128)
batch 882: ({'logprob': [54.733299255371094, 14.0]}, 128)
batch 883: ({'logprob': [61.8021240234375, 17.0]}, 128)
batch 884: ({'logprob': [51.30144500732422, 13.0]}, 128)
batch 885: ({'logprob': [52.20793914794922, 13.0]}, 128)
batch 886: ({'logprob': [62.26971435546875, 17.0]}, 128)

======================Test output======================
logprob:  0.416365, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.966255e-03 [3.143475e-09] 
Layer 'conv1' biases: 2.178229e-07 [7.114953e-11] 
Layer 'conv2' weights[0]: 7.953343e-03 [2.591996e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.909173e-10] 
Layer 'conv3' weights[0]: 7.951621e-03 [2.115523e-09] 
Layer 'conv3' biases: 1.874492e-06 [1.201537e-09] 
Layer 'conv4' weights[0]: 7.984255e-03 [2.133315e-09] 
Layer 'conv4' biases: 9.999994e-01 [9.450577e-09] 
Layer 'conv5' weights[0]: 7.983070e-03 [6.042988e-08] 
Layer 'conv5' biases: 9.999955e-01 [6.521878e-08] 
Layer 'fc6' weights[0]: 7.579797e-03 [5.167946e-09] 
Layer 'fc6' biases: 9.999999e-01 [5.203573e-09] 
Layer 'fc7' weights[0]: 7.204590e-03 [2.405932e-07] 
Layer 'fc7' biases: 9.998621e-01 [2.300254e-07] 
Layer 'fc8' weights[0]: 1.298250e-03 [9.234706e-06] 
Layer 'fc8' biases: 4.847516e-02 [5.743228e-05] 
Train error last 870 batches: 0.435236
-------------------------------------------------------
Not saving because 0.416365 > 0.415685 (17.630: -0.01%)
======================================================= (12.049 sec)
20.521... logprob:  0.427499, 0.109375 (1.463 sec)
20.522... logprob:  0.533091, 0.156250 (1.462 sec)
20.523... logprob:  0.331713, 0.078125 (1.442 sec)
20.524... logprob:  0.437217, 0.117188 (1.419 sec)
20.525... logprob:  0.426046, 0.109375 (1.440 sec)
20.526... logprob:  0.351893, 0.078125 (1.434 sec)
20.527... logprob:  0.504550, 0.140625 (1.445 sec)
20.528... logprob:  0.440501, 0.117188 (1.555 sec)
20.529... logprob:  0.353011, 0.085938 (1.449 sec)
20.530... logprob:  0.440249, 0.117188 (1.445 sec)
20.531... logprob:  0.439997, 0.117188 (1.481 sec)
20.532... logprob:  0.467382, 0.125000 (1.433 sec)
20.533... logprob:  0.560621, 0.164062 (1.425 sec)
20.534... logprob:  0.325818, 0.078125 (1.433 sec)
20.535... logprob:  0.551631, 0.156250 (1.463 sec)
20.536... logprob:  0.507376, 0.140625 (1.436 sec)
20.537... logprob:  0.510065, 0.140625 (1.475 sec)
20.538... logprob:  0.486106, 0.132812 (1.440 sec)
20.539... logprob:  0.296118, 0.062500 (1.434 sec)
20.540... logprob:  0.447179, 0.117188 (1.490 sec)
20.541... logprob:  0.388869, 0.101562 (1.432 sec)
20.542... logprob:  0.411298, 0.109375 (1.437 sec)
20.543... logprob:  0.233357, 0.039062 (1.439 sec)
20.544... logprob:  0.317941, 0.070312 (1.428 sec)
20.545... logprob:  0.348809, 0.085938 (1.438 sec)
20.546... logprob:  0.368285, 0.093750 (1.485 sec)
20.547... logprob:  0.440116, 0.117188 (1.438 sec)
20.548... logprob:  0.453125, 0.125000 (1.444 sec)
20.549... logprob:  0.490659, 0.132812 (1.480 sec)
20.550... logprob:  0.367674, 0.093750 (1.431 sec)
20.551... logprob:  0.441762, 0.117188 (1.432 sec)
20.552... logprob:  0.471321, 0.125000 (1.436 sec)
20.553... logprob:  0.349439, 0.085938 (1.431 sec)
20.554... logprob:  0.506876, 0.140625 (1.434 sec)
20.555... logprob:  0.421411, 0.109375 (1.481 sec)
20.556... logprob:  0.355900, 0.085938 (1.453 sec)
20.557... logprob:  0.396458, 0.101562 (1.450 sec)
20.558... logprob:  0.383051, 0.101562 (1.471 sec)
20.559... logprob:  0.441484, 0.125000 (1.440 sec)
20.560... logprob:  0.335279, 0.078125 (1.438 sec)
20.561... logprob:  0.411832, 0.109375 (1.433 sec)
20.562... logprob:  0.503123, 0.140625 (1.429 sec)
20.563... logprob:  0.373843, 0.093750 (1.440 sec)
20.564... logprob:  0.468436, 0.132812 (1.466 sec)
20.565... logprob:  0.611056, 0.187500 (1.456 sec)
20.566... logprob:  0.374908, 0.093750 (1.452 sec)
20.567... logprob:  0.423415, 0.109375 (1.469 sec)
20.568... logprob:  0.496367, 0.140625 (1.453 sec)
20.569... logprob:  0.507821, 0.140625 (1.443 sec)
20.570... logprob:  0.543738, 0.164062 (1.435 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.503963470458984, 10.0]}, 128)
batch 872: ({'logprob': [65.69673919677734, 19.0]}, 128)
batch 873: ({'logprob': [42.51397705078125, 9.0]}, 128)
batch 874: ({'logprob': [46.24799346923828, 11.0]}, 128)
batch 875: ({'logprob': [51.473323822021484, 13.0]}, 128)
batch 876: ({'logprob': [63.47483825683594, 18.0]}, 128)
batch 877: ({'logprob': [47.00147247314453, 11.0]}, 128)
batch 878: ({'logprob': [61.96164321899414, 17.0]}, 128)
batch 879: ({'logprob': [73.15860748291016, 21.0]}, 128)
batch 880: ({'logprob': [51.49156188964844, 13.0]}, 128)
batch 881: ({'logprob': [31.2835693359375, 5.0]}, 128)
batch 882: ({'logprob': [55.96842575073242, 14.0]}, 128)
batch 883: ({'logprob': [61.94194793701172, 17.0]}, 128)
batch 884: ({'logprob': [52.21926498413086, 13.0]}, 128)
batch 885: ({'logprob': [53.71089553833008, 13.0]}, 128)
batch 886: ({'logprob': [62.699947357177734, 17.0]}, 128)

======================Test output======================
logprob:  0.421557, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.966221e-03 [2.999020e-09] 
Layer 'conv1' biases: 2.187346e-07 [6.890667e-11] 
Layer 'conv2' weights[0]: 7.953307e-03 [2.732206e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.800999e-10] 
Layer 'conv3' weights[0]: 7.951574e-03 [2.539983e-09] 
Layer 'conv3' biases: 1.881896e-06 [1.515555e-09] 
Layer 'conv4' weights[0]: 7.984217e-03 [2.564701e-09] 
Layer 'conv4' biases: 9.999994e-01 [1.273024e-08] 
Layer 'conv5' weights[0]: 7.983039e-03 [8.287362e-08] 
Layer 'conv5' biases: 9.999954e-01 [8.918305e-08] 
Layer 'fc6' weights[0]: 7.579759e-03 [6.951239e-09] 
Layer 'fc6' biases: 9.999999e-01 [7.063687e-09] 
Layer 'fc7' weights[0]: 7.202729e-03 [1.816399e-07] 
Layer 'fc7' biases: 9.998619e-01 [1.711900e-07] 
Layer 'fc8' weights[0]: 1.269088e-03 [7.461798e-06] 
Layer 'fc8' biases: 4.838421e-02 [4.715954e-05] 
Train error last 870 batches: 0.435236
-------------------------------------------------------
Not saving because 0.421557 > 0.415685 (17.630: -0.01%)
======================================================= (12.021 sec)
20.571... logprob:  0.454876, 0.125000 (1.437 sec)
20.572... logprob:  0.501458, 0.140625 (1.439 sec)
20.573... logprob:  0.512622, 0.148438 (1.448 sec)
20.574... logprob:  0.428126, 0.109375 (1.463 sec)
20.575... logprob:  0.343352, 0.078125 (1.458 sec)
20.576... logprob:  0.427398, 0.109375 (1.442 sec)
20.577... logprob:  0.460832, 0.125000 (1.480 sec)
20.578... logprob:  0.336620, 0.078125 (1.433 sec)
20.579... logprob:  0.442086, 0.117188 (1.431 sec)
20.580... logprob:  0.546891, 0.156250 (1.430 sec)
20.581... logprob:  0.530935, 0.156250 (1.440 sec)
20.582... logprob:  0.437880, 0.125000 (1.436 sec)
20.583... logprob:  0.592779, 0.171875 (1.482 sec)
20.584... logprob:  0.468117, 0.132812 (1.442 sec)
20.585... logprob:  0.349764, 0.085938 (1.430 sec)
20.586... logprob:  0.313135, 0.070312 (1.489 sec)
20.587... logprob:  0.404311, 0.101562 (1.431 sec)
20.588... logprob:  0.418669, 0.117188 (1.435 sec)
20.589... logprob:  0.361270, 0.093750 (1.434 sec)
20.590... logprob:  0.524715, 0.148438 (1.436 sec)
20.591... logprob:  0.397504, 0.101562 (1.436 sec)
20.592... logprob:  0.455651, 0.125000 (1.485 sec)
20.593... logprob:  0.467432, 0.125000 (1.441 sec)
20.594... logprob:  0.352866, 0.085938 (1.441 sec)
20.595... logprob:  0.428666, 0.109375 (1.489 sec)
20.596... logprob:  0.461588, 0.125000 (1.437 sec)
20.597... logprob:  0.397413, 0.101562 (1.432 sec)
20.598... logprob:  0.397227, 0.101562 (1.441 sec)
20.599... logprob:  0.313525, 0.070312 (1.430 sec)
20.600... logprob:  0.340895, 0.085938 (1.437 sec)
20.601... logprob:  0.402128, 0.101562 (1.485 sec)
20.602... logprob:  0.289728, 0.062500 (1.437 sec)
20.603... logprob:  0.266992, 0.054688 (1.446 sec)
20.604... logprob:  0.407514, 0.101562 (1.479 sec)
20.605... logprob:  0.563523, 0.148438 (1.433 sec)
20.606... logprob:  0.295945, 0.070312 (1.443 sec)
20.607... logprob:  0.504872, 0.132812 (1.430 sec)
20.608... logprob:  0.361720, 0.085938 (1.431 sec)
20.609... logprob:  0.356948, 0.085938 (1.470 sec)
20.610... logprob:  0.493403, 0.132812 (1.472 sec)
20.611... logprob:  0.510420, 0.140625 (1.446 sec)
20.612... logprob:  0.448420, 0.117188 (1.452 sec)
20.613... logprob:  0.279695, 0.062500 (1.461 sec)
20.614... logprob:  0.503531, 0.140625 (1.451 sec)
20.615... logprob:  0.351091, 0.085938 (1.444 sec)
20.616... logprob:  0.415282, 0.109375 (1.435 sec)
20.617... logprob:  0.417942, 0.109375 (1.425 sec)
20.618... logprob:  0.546767, 0.156250 (1.440 sec)
20.619... logprob:  0.505979, 0.140625 (1.456 sec)
20.620... logprob:  0.539638, 0.156250 (1.461 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.3173713684082, 10.0]}, 128)
batch 872: ({'logprob': [66.22826385498047, 19.0]}, 128)
batch 873: ({'logprob': [41.74064636230469, 9.0]}, 128)
batch 874: ({'logprob': [46.299686431884766, 11.0]}, 128)
batch 875: ({'logprob': [51.40831756591797, 13.0]}, 128)
batch 876: ({'logprob': [63.83026123046875, 18.0]}, 128)
batch 877: ({'logprob': [46.58346176147461, 11.0]}, 128)
batch 878: ({'logprob': [61.668521881103516, 17.0]}, 128)
batch 879: ({'logprob': [72.16920471191406, 21.0]}, 128)
batch 880: ({'logprob': [51.428550720214844, 13.0]}, 128)
batch 881: ({'logprob': [31.208166122436523, 5.0]}, 128)
batch 882: ({'logprob': [54.673648834228516, 14.0]}, 128)
batch 883: ({'logprob': [61.64802932739258, 17.0]}, 128)
batch 884: ({'logprob': [51.686004638671875, 13.0]}, 128)
batch 885: ({'logprob': [52.23786926269531, 13.0]}, 128)
batch 886: ({'logprob': [61.93738555908203, 17.0]}, 128)

======================Test output======================
logprob:  0.418977, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.966182e-03 [4.975723e-09] 
Layer 'conv1' biases: 2.196465e-07 [8.594336e-11] 
Layer 'conv2' weights[0]: 7.953273e-03 [3.635494e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.371747e-10] 
Layer 'conv3' weights[0]: 7.951536e-03 [3.016877e-09] 
Layer 'conv3' biases: 1.890089e-06 [1.712299e-09] 
Layer 'conv4' weights[0]: 7.984175e-03 [3.107214e-09] 
Layer 'conv4' biases: 9.999994e-01 [1.416523e-08] 
Layer 'conv5' weights[0]: 7.983007e-03 [9.241498e-08] 
Layer 'conv5' biases: 9.999956e-01 [9.948761e-08] 
Layer 'fc6' weights[0]: 7.579718e-03 [7.737528e-09] 
Layer 'fc6' biases: 9.999999e-01 [7.847095e-09] 
Layer 'fc7' weights[0]: 7.200903e-03 [2.820171e-07] 
Layer 'fc7' biases: 9.998610e-01 [2.723504e-07] 
Layer 'fc8' weights[0]: 1.272826e-03 [9.903262e-06] 
Layer 'fc8' biases: 4.857645e-02 [6.367578e-05] 
Train error last 870 batches: 0.435235
-------------------------------------------------------
Not saving because 0.418977 > 0.415685 (17.630: -0.01%)
======================================================= (12.035 sec)
20.621... logprob:  0.363848, 0.085938 (1.453 sec)
20.622... logprob:  0.364886, 0.085938 (1.454 sec)
20.623... logprob:  0.423199, 0.109375 (1.464 sec)
20.624... logprob:  0.382547, 0.093750 (1.441 sec)
20.625... logprob:  0.440999, 0.117188 (1.425 sec)
20.626... logprob:  0.438384, 0.117188 (1.437 sec)
20.627... logprob:  0.435854, 0.117188 (1.438 sec)
20.628... logprob:  0.465078, 0.125000 (1.436 sec)
20.629... logprob:  0.372026, 0.093750 (1.475 sec)
20.630... logprob:  0.422374, 0.109375 (1.451 sec)
20.631... logprob:  0.639141, 0.187500 (1.436 sec)
20.632... logprob:  0.399104, 0.101562 (1.489 sec)
20.633... logprob:  0.376041, 0.093750 (1.432 sec)
20.634... logprob:  0.660386, 0.195312 (1.431 sec)
20.635... logprob:  0.374119, 0.093750 (1.434 sec)
20.636... logprob:  0.480239, 0.132812 (1.438 sec)
20.637... logprob:  0.330899, 0.078125 (1.436 sec)
20.638... logprob:  0.515679, 0.140625 (1.481 sec)
20.639... logprob:  0.418126, 0.109375 (1.444 sec)
20.640... logprob:  0.528749, 0.148438 (1.437 sec)
20.641... logprob:  0.410469, 0.109375 (1.484 sec)
20.642... logprob:  0.500834, 0.140625 (1.470 sec)
20.643... logprob:  0.622933, 0.187500 (1.433 sec)
20.644... logprob:  0.321313, 0.070312 (1.439 sec)
20.645... logprob:  0.414497, 0.109375 (1.428 sec)
20.646... logprob:  0.385718, 0.093750 (1.439 sec)
20.647... logprob:  0.456760, 0.125000 (1.486 sec)
20.648... logprob:  0.491236, 0.140625 (1.435 sec)
20.649... logprob:  0.370157, 0.093750 (1.447 sec)
20.650... logprob:  0.413955, 0.109375 (1.480 sec)
20.651... logprob:  0.397327, 0.101562 (1.435 sec)
20.652... logprob:  0.507325, 0.140625 (1.438 sec)
20.653... logprob:  0.548041, 0.156250 (1.436 sec)
20.654... logprob:  0.496114, 0.140625 (1.427 sec)
20.655... logprob:  0.436201, 0.117188 (1.439 sec)
20.656... logprob:  0.416683, 0.109375 (1.476 sec)
20.657... logprob:  0.449223, 0.117188 (1.447 sec)
20.658... logprob:  0.345787, 0.085938 (1.458 sec)
20.659... logprob:  0.464338, 0.125000 (1.476 sec)
20.660... logprob:  0.445936, 0.125000 (1.444 sec)
20.661... logprob:  0.378512, 0.093750 (1.441 sec)
20.662... logprob:  0.469365, 0.132812 (1.430 sec)
20.663... logprob:  0.311001, 0.070312 (1.429 sec)
20.664... logprob:  0.285469, 0.062500 (1.436 sec)
20.665... logprob:  0.401810, 0.101562 (1.465 sec)
20.666... logprob:  0.442057, 0.117188 (1.455 sec)
20.667... logprob:  0.564284, 0.164062 (1.452 sec)
20.668... logprob:  0.497894, 0.140625 (1.457 sec)
20.669... logprob:  0.433055, 0.109375 (1.463 sec)
20.670... logprob:  0.362458, 0.085938 (1.442 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.13896942138672, 10.0]}, 128)
batch 872: ({'logprob': [66.66503143310547, 19.0]}, 128)
batch 873: ({'logprob': [40.67595291137695, 9.0]}, 128)
batch 874: ({'logprob': [45.04644012451172, 11.0]}, 128)
batch 875: ({'logprob': [50.78067398071289, 13.0]}, 128)
batch 876: ({'logprob': [64.15811157226562, 18.0]}, 128)
batch 877: ({'logprob': [45.73543930053711, 11.0]}, 128)
batch 878: ({'logprob': [62.293277740478516, 17.0]}, 128)
batch 879: ({'logprob': [74.4513168334961, 21.0]}, 128)
batch 880: ({'logprob': [50.800331115722656, 13.0]}, 128)
batch 881: ({'logprob': [28.48243522644043, 5.0]}, 128)
batch 882: ({'logprob': [55.37908935546875, 14.0]}, 128)
batch 883: ({'logprob': [62.272918701171875, 17.0]}, 128)
batch 884: ({'logprob': [51.46862030029297, 13.0]}, 128)
batch 885: ({'logprob': [52.83561325073242, 13.0]}, 128)
batch 886: ({'logprob': [62.97137451171875, 17.0]}, 128)

======================Test output======================
logprob:  0.417556, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.966145e-03 [2.830332e-09] 
Layer 'conv1' biases: 2.204939e-07 [4.013984e-11] 
Layer 'conv2' weights[0]: 7.953236e-03 [1.732867e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.882323e-10] 
Layer 'conv3' weights[0]: 7.951501e-03 [1.334205e-09] 
Layer 'conv3' biases: 1.895891e-06 [5.660589e-10] 
Layer 'conv4' weights[0]: 7.984129e-03 [1.251825e-09] 
Layer 'conv4' biases: 9.999994e-01 [3.731480e-09] 
Layer 'conv5' weights[0]: 7.982959e-03 [2.161493e-08] 
Layer 'conv5' biases: 9.999951e-01 [2.306614e-08] 
Layer 'fc6' weights[0]: 7.579678e-03 [1.977849e-09] 
Layer 'fc6' biases: 9.999999e-01 [1.824469e-09] 
Layer 'fc7' weights[0]: 7.199029e-03 [8.652907e-08] 
Layer 'fc7' biases: 9.998627e-01 [7.239874e-08] 
Layer 'fc8' weights[0]: 1.321928e-03 [2.800279e-06] 
Layer 'fc8' biases: 4.899148e-02 [1.631093e-05] 
Train error last 870 batches: 0.435235
-------------------------------------------------------
Not saving because 0.417556 > 0.415685 (17.630: -0.01%)
======================================================= (12.113 sec)
20.671... logprob:  0.360857, 0.093750 (1.435 sec)
20.672... logprob:  0.441816, 0.117188 (1.438 sec)
20.673... logprob:  0.436239, 0.117188 (1.443 sec)
20.674... logprob:  0.446658, 0.117188 (1.445 sec)
20.675... logprob:  0.356670, 0.093750 (1.493 sec)
20.676... logprob:  0.450157, 0.125000 (1.454 sec)
20.677... logprob:  0.471048, 0.125000 (1.440 sec)
20.678... logprob:  0.465648, 0.125000 (1.481 sec)
20.679... logprob:  0.454869, 0.125000 (1.436 sec)
20.680... logprob:  0.351718, 0.078125 (1.428 sec)
20.681... logprob:  0.373922, 0.093750 (1.436 sec)
20.682... logprob:  0.340493, 0.078125 (1.439 sec)
20.683... logprob:  0.411643, 0.109375 (1.433 sec)
20.684... logprob:  0.357624, 0.085938 (1.481 sec)
20.685... logprob:  0.285941, 0.054688 (1.443 sec)
20.686... logprob:  0.318587, 0.070312 (1.432 sec)
20.687... logprob:  0.281579, 0.062500 (1.492 sec)
20.688... logprob:  0.323095, 0.078125 (1.432 sec)
20.689... logprob:  0.471402, 0.125000 (1.435 sec)
20.690... logprob:  0.527943, 0.140625 (1.437 sec)
20.691... logprob:  0.516877, 0.140625 (1.433 sec)
20.692... logprob:  0.385201, 0.101562 (1.435 sec)
20.693... logprob:  0.455918, 0.125000 (1.486 sec)
20.694... logprob:  0.330903, 0.078125 (1.436 sec)
20.695... logprob:  0.356903, 0.085938 (1.442 sec)
20.696... logprob:  0.538897, 0.148438 (1.482 sec)
20.697... logprob:  0.465626, 0.125000 (1.438 sec)
20.698... logprob:  0.548645, 0.156250 (1.434 sec)
20.699... logprob:  0.459593, 0.125000 (1.444 sec)
20.700... logprob:  0.433986, 0.117188 (1.427 sec)
20.701... logprob:  0.423250, 0.109375 (1.433 sec)
20.702... logprob:  0.521476, 0.148438 (1.484 sec)
20.703... logprob:  0.405398, 0.101562 (1.440 sec)
20.704... logprob:  0.406245, 0.101562 (1.448 sec)
20.705... logprob:  0.420261, 0.109375 (1.479 sec)
20.706... logprob:  0.468074, 0.125000 (1.435 sec)
20.707... logprob:  0.485300, 0.132812 (1.438 sec)
20.708... logprob:  0.417091, 0.109375 (1.437 sec)
20.709... logprob:  0.422492, 0.109375 (1.423 sec)
20.710... logprob:  0.602608, 0.179688 (1.448 sec)
20.711... logprob:  0.469510, 0.125000 (1.468 sec)
20.712... logprob:  0.340484, 0.078125 (1.455 sec)
20.713... logprob:  0.587125, 0.179688 (1.454 sec)
20.714... logprob:  0.466310, 0.125000 (1.459 sec)
20.715... logprob:  0.417149, 0.109375 (1.456 sec)
20.716... logprob:  0.335301, 0.078125 (1.458 sec)
20.717... logprob:  0.429820, 0.117188 (1.422 sec)
20.718... logprob:  0.490367, 0.132812 (1.434 sec)
20.719... logprob:  0.406195, 0.109375 (1.438 sec)
20.720... logprob:  0.433235, 0.117188 (1.443 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.6295166015625, 10.0]}, 128)
batch 872: ({'logprob': [66.63823699951172, 19.0]}, 128)
batch 873: ({'logprob': [40.49652862548828, 9.0]}, 128)
batch 874: ({'logprob': [45.15105438232422, 11.0]}, 128)
batch 875: ({'logprob': [50.7464485168457, 13.0]}, 128)
batch 876: ({'logprob': [64.09524536132812, 18.0]}, 128)
batch 877: ({'logprob': [45.6291618347168, 11.0]}, 128)
batch 878: ({'logprob': [61.98267364501953, 17.0]}, 128)
batch 879: ({'logprob': [73.65408325195312, 21.0]}, 128)
batch 880: ({'logprob': [50.76667022705078, 13.0]}, 128)
batch 881: ({'logprob': [28.790664672851562, 5.0]}, 128)
batch 882: ({'logprob': [54.74821090698242, 14.0]}, 128)
batch 883: ({'logprob': [61.96211624145508, 17.0]}, 128)
batch 884: ({'logprob': [51.22320556640625, 13.0]}, 128)
batch 885: ({'logprob': [52.16799545288086, 13.0]}, 128)
batch 886: ({'logprob': [62.44942855834961, 17.0]}, 128)

======================Test output======================
logprob:  0.416080, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.966098e-03 [1.973875e-09] 
Layer 'conv1' biases: 2.211585e-07 [4.704132e-11] 
Layer 'conv2' weights[0]: 7.953197e-03 [1.424607e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.956301e-10] 
Layer 'conv3' weights[0]: 7.951457e-03 [1.261017e-09] 
Layer 'conv3' biases: 1.901778e-06 [5.490203e-10] 
Layer 'conv4' weights[0]: 7.984093e-03 [1.177839e-09] 
Layer 'conv4' biases: 9.999994e-01 [3.256376e-09] 
Layer 'conv5' weights[0]: 7.982917e-03 [1.420889e-08] 
Layer 'conv5' biases: 9.999951e-01 [1.441329e-08] 
Layer 'fc6' weights[0]: 7.579636e-03 [1.323588e-09] 
Layer 'fc6' biases: 9.999999e-01 [1.065617e-09] 
Layer 'fc7' weights[0]: 7.197176e-03 [6.908225e-08] 
Layer 'fc7' biases: 9.998622e-01 [5.216704e-08] 
Layer 'fc8' weights[0]: 1.313304e-03 [5.045470e-06] 
Layer 'fc8' biases: 4.917118e-02 [3.367768e-05] 
Train error last 870 batches: 0.435235
-------------------------------------------------------
Not saving because 0.416080 > 0.415685 (17.630: -0.01%)
======================================================= (12.134 sec)
20.721... logprob:  0.451602, 0.117188 (1.469 sec)
20.722... logprob:  0.536887, 0.156250 (1.458 sec)
20.723... logprob:  0.416586, 0.109375 (1.444 sec)
20.724... logprob:  0.412774, 0.109375 (1.477 sec)
20.725... logprob:  0.494703, 0.140625 (1.432 sec)
20.726... logprob:  0.338613, 0.085938 (1.432 sec)
20.727... logprob:  0.393332, 0.101562 (1.431 sec)
20.728... logprob:  0.421326, 0.109375 (1.444 sec)
20.729... logprob:  0.387748, 0.093750 (1.437 sec)
20.730... logprob:  0.565847, 0.164062 (1.473 sec)
20.731... logprob:  0.450346, 0.125000 (1.445 sec)
20.732... logprob:  0.311466, 0.070312 (1.436 sec)
20.733... logprob:  0.556640, 0.156250 (1.493 sec)
20.734... logprob:  0.340239, 0.078125 (1.429 sec)
20.735... logprob:  0.527570, 0.148438 (1.427 sec)
20.736... logprob:  0.642917, 0.187500 (1.436 sec)
20.737... logprob:  0.516176, 0.148438 (1.437 sec)
20.738... logprob:  0.459419, 0.125000 (1.432 sec)
20.739... logprob:  0.477808, 0.132812 (1.487 sec)
20.740... logprob:  0.339654, 0.078125 (1.436 sec)
20.741... logprob:  0.393453, 0.101562 (1.444 sec)
20.742... logprob:  0.419724, 0.109375 (1.480 sec)
20.743... logprob:  0.364874, 0.085938 (1.433 sec)
20.744... logprob:  0.519223, 0.148438 (1.430 sec)
20.745... logprob:  0.478166, 0.132812 (1.441 sec)
20.746... logprob:  0.440554, 0.117188 (1.429 sec)
20.747... logprob:  0.425619, 0.109375 (1.432 sec)
20.748... logprob:  0.378074, 0.093750 (1.490 sec)
20.749... logprob:  0.420834, 0.109375 (1.459 sec)
20.750... logprob:  0.512881, 0.140625 (1.450 sec)
20.751... logprob:  0.263576, 0.054688 (1.474 sec)
20.752... logprob:  0.522515, 0.140625 (1.437 sec)
20.753... logprob:  0.441225, 0.117188 (1.448 sec)
20.754... logprob:  0.468499, 0.132812 (1.433 sec)
20.755... logprob:  0.507097, 0.140625 (1.429 sec)
20.756... logprob:  0.440825, 0.117188 (1.434 sec)
20.757... logprob:  0.552336, 0.156250 (1.477 sec)
20.758... logprob:  0.393670, 0.101562 (1.443 sec)
20.759... logprob:  0.459692, 0.125000 (1.458 sec)
20.760... logprob:  0.485451, 0.132812 (1.459 sec)
20.761... logprob:  0.418328, 0.109375 (1.446 sec)
20.762... logprob:  0.516004, 0.148438 (1.439 sec)
20.763... logprob:  0.558837, 0.164062 (1.433 sec)
20.764... logprob:  0.503283, 0.140625 (1.426 sec)
20.765... logprob:  0.312118, 0.062500 (1.437 sec)
20.766... logprob:  0.482272, 0.132812 (1.452 sec)
20.767... logprob:  0.371150, 0.085938 (1.459 sec)
20.768... logprob:  0.432694, 0.117188 (1.463 sec)
20.769... logprob:  0.490872, 0.140625 (1.467 sec)
20.770... logprob:  0.402866, 0.101562 (1.479 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.36172866821289, 10.0]}, 128)
batch 872: ({'logprob': [66.2125244140625, 19.0]}, 128)
batch 873: ({'logprob': [41.1648063659668, 9.0]}, 128)
batch 874: ({'logprob': [45.66739273071289, 11.0]}, 128)
batch 875: ({'logprob': [51.000125885009766, 13.0]}, 128)
batch 876: ({'logprob': [63.772857666015625, 18.0]}, 128)
batch 877: ({'logprob': [46.09077453613281, 11.0]}, 128)
batch 878: ({'logprob': [61.70919418334961, 17.0]}, 128)
batch 879: ({'logprob': [72.79828643798828, 21.0]}, 128)
batch 880: ({'logprob': [51.020145416259766, 13.0]}, 128)
batch 881: ({'logprob': [30.04253387451172, 5.0]}, 128)
batch 882: ({'logprob': [54.729576110839844, 14.0]}, 128)
batch 883: ({'logprob': [61.688697814941406, 17.0]}, 128)
batch 884: ({'logprob': [51.41945266723633, 13.0]}, 128)
batch 885: ({'logprob': [52.25251770019531, 13.0]}, 128)
batch 886: ({'logprob': [62.11928176879883, 17.0]}, 128)

======================Test output======================
logprob:  0.417017, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.966048e-03 [2.754434e-09] 
Layer 'conv1' biases: 2.220074e-07 [1.093444e-10] 
Layer 'conv2' weights[0]: 7.953161e-03 [2.271727e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.769885e-10] 
Layer 'conv3' weights[0]: 7.951412e-03 [2.395315e-09] 
Layer 'conv3' biases: 1.908222e-06 [1.411738e-09] 
Layer 'conv4' weights[0]: 7.984055e-03 [2.560490e-09] 
Layer 'conv4' biases: 9.999992e-01 [1.331306e-08] 
Layer 'conv5' weights[0]: 7.982880e-03 [8.859689e-08] 
Layer 'conv5' biases: 9.999949e-01 [9.571193e-08] 
Layer 'fc6' weights[0]: 7.579590e-03 [7.390035e-09] 
Layer 'fc6' biases: 9.999999e-01 [7.498504e-09] 
Layer 'fc7' weights[0]: 7.195333e-03 [2.617253e-07] 
Layer 'fc7' biases: 9.998616e-01 [2.507989e-07] 
Layer 'fc8' weights[0]: 1.290140e-03 [8.948694e-06] 
Layer 'fc8' biases: 4.912953e-02 [6.360193e-05] 
Train error last 870 batches: 0.435234
-------------------------------------------------------
Not saving because 0.417017 > 0.415685 (17.630: -0.01%)
======================================================= (12.053 sec)
20.771... logprob:  0.549597, 0.156250 (1.468 sec)
20.772... logprob:  0.414052, 0.109375 (1.454 sec)
20.773... logprob:  0.558025, 0.164062 (1.442 sec)
20.774... logprob:  0.361598, 0.085938 (1.466 sec)
20.775... logprob:  0.407339, 0.101562 (1.460 sec)
20.776... logprob:  0.433216, 0.117188 (1.484 sec)
20.777... logprob:  0.379934, 0.093750 (1.472 sec)
20.778... logprob:  0.433601, 0.117188 (1.469 sec)
20.779... logprob:  0.505438, 0.140625 (1.489 sec)
20.780... logprob:  0.385759, 0.101562 (1.457 sec)
20.781... logprob:  0.369697, 0.085938 (1.446 sec)
20.782... logprob:  0.351477, 0.085938 (1.460 sec)
20.783... logprob:  0.555486, 0.156250 (1.459 sec)
20.784... logprob:  0.440956, 0.117188 (1.459 sec)
20.785... logprob:  0.543577, 0.156250 (1.485 sec)
20.786... logprob:  0.477441, 0.132812 (1.472 sec)
20.787... logprob:  0.546269, 0.156250 (1.463 sec)
20.788... logprob:  0.562993, 0.164062 (1.492 sec)
20.789... logprob:  0.281243, 0.054688 (1.459 sec)
20.790... logprob:  0.408215, 0.101562 (1.450 sec)
20.791... logprob:  0.398080, 0.101562 (1.445 sec)
20.792... logprob:  0.361168, 0.085938 (1.466 sec)
20.793... logprob:  0.370232, 0.085938 (1.454 sec)
20.794... logprob:  0.387130, 0.093750 (1.489 sec)
20.795... logprob:  0.469797, 0.125000 (1.465 sec)
20.796... logprob:  0.423502, 0.109375 (1.456 sec)
20.797... logprob:  0.358753, 0.085938 (1.499 sec)
20.798... logprob:  0.393273, 0.101562 (1.452 sec)
20.799... logprob:  0.332250, 0.078125 (1.456 sec)
20.800... logprob:  0.371756, 0.093750 (1.451 sec)
20.801... logprob:  0.450235, 0.117188 (1.459 sec)
20.802... logprob:  0.423081, 0.109375 (1.452 sec)
20.803... logprob:  0.491867, 0.132812 (1.495 sec)
20.804... logprob:  0.349974, 0.085938 (1.463 sec)
20.805... logprob:  0.452293, 0.117188 (1.453 sec)
20.806... logprob:  0.424184, 0.109375 (1.500 sec)
20.807... logprob:  0.443462, 0.117188 (1.450 sec)
20.808... logprob:  0.462350, 0.125000 (1.454 sec)
20.809... logprob:  0.589552, 0.171875 (1.450 sec)
20.810... logprob:  0.442453, 0.117188 (1.460 sec)
20.811... logprob:  0.460418, 0.125000 (1.454 sec)
20.812... logprob:  0.462396, 0.125000 (1.493 sec)
20.813... logprob:  0.485974, 0.132812 (1.467 sec)
20.814... logprob:  0.478087, 0.132812 (1.454 sec)
20.815... logprob:  0.372124, 0.085938 (1.501 sec)
20.816... logprob:  0.408871, 0.101562 (1.459 sec)
20.817... logprob:  0.426059, 0.109375 (1.451 sec)
20.818... logprob:  0.559976, 0.164062 (1.452 sec)
20.819... logprob:  0.498207, 0.140625 (1.453 sec)
20.820... logprob:  0.421585, 0.109375 (1.450 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.33926010131836, 10.0]}, 128)
batch 872: ({'logprob': [66.18257904052734, 19.0]}, 128)
batch 873: ({'logprob': [41.8223991394043, 9.0]}, 128)
batch 874: ({'logprob': [46.337684631347656, 11.0]}, 128)
batch 875: ({'logprob': [51.43320083618164, 13.0]}, 128)
batch 876: ({'logprob': [63.7988166809082, 18.0]}, 128)
batch 877: ({'logprob': [46.63666915893555, 11.0]}, 128)
batch 878: ({'logprob': [61.66655349731445, 17.0]}, 128)
batch 879: ({'logprob': [72.15577697753906, 21.0]}, 128)
batch 880: ({'logprob': [51.453216552734375, 13.0]}, 128)
batch 881: ({'logprob': [31.30139923095703, 5.0]}, 128)
batch 882: ({'logprob': [54.729644775390625, 14.0]}, 128)
batch 883: ({'logprob': [61.646209716796875, 17.0]}, 128)
batch 884: ({'logprob': [51.72578811645508, 13.0]}, 128)
batch 885: ({'logprob': [52.30817794799805, 13.0]}, 128)
batch 886: ({'logprob': [61.95060348510742, 17.0]}, 128)

======================Test output======================
logprob:  0.419184, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.966007e-03 [3.234291e-09] 
Layer 'conv1' biases: 2.230065e-07 [1.156055e-10] 
Layer 'conv2' weights[0]: 7.953122e-03 [2.251903e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.454090e-10] 
Layer 'conv3' weights[0]: 7.951366e-03 [2.200029e-09] 
Layer 'conv3' biases: 1.917628e-06 [1.262487e-09] 
Layer 'conv4' weights[0]: 7.984011e-03 [2.358630e-09] 
Layer 'conv4' biases: 9.999994e-01 [1.212393e-08] 
Layer 'conv5' weights[0]: 7.982838e-03 [8.123931e-08] 
Layer 'conv5' biases: 9.999952e-01 [8.776932e-08] 
Layer 'fc6' weights[0]: 7.579547e-03 [6.752402e-09] 
Layer 'fc6' biases: 9.999999e-01 [6.854628e-09] 
Layer 'fc7' weights[0]: 7.193534e-03 [1.797185e-07] 
Layer 'fc7' biases: 9.998608e-01 [1.681705e-07] 
Layer 'fc8' weights[0]: 1.267961e-03 [5.694160e-06] 
Layer 'fc8' biases: 4.919711e-02 [4.462960e-05] 
Train error last 870 batches: 0.435234
-------------------------------------------------------
Not saving because 0.419184 > 0.415685 (17.630: -0.01%)
======================================================= (12.059 sec)
20.821... logprob:  0.406503, 0.101562 (1.501 sec)
20.822... logprob:  0.441134, 0.117188 (1.464 sec)
20.823... logprob:  0.340628, 0.078125 (1.226 sec)
20.824... logprob:  0.489913, 0.132812 (0.750 sec)
20.825... logprob:  0.287730, 0.062500 (0.681 sec)
20.826... logprob:  0.375410, 0.093750 (0.688 sec)
20.827... logprob:  0.420595, 0.109375 (0.686 sec)
20.828... logprob:  0.443512, 0.117188 (0.685 sec)
20.829... logprob:  0.504455, 0.140625 (0.682 sec)
20.830... logprob:  0.442285, 0.117188 (1.504 sec)
20.831... logprob:  0.514071, 0.140625 (1.457 sec)
20.832... logprob:  0.330852, 0.078125 (1.463 sec)
20.833... logprob:  0.488982, 0.132812 (1.496 sec)
20.834... logprob:  0.433242, 0.117188 (1.456 sec)
20.835... logprob:  0.542593, 0.148438 (1.458 sec)
20.836... logprob:  0.376274, 0.093750 (1.451 sec)
20.837... logprob:  0.314600, 0.070312 (1.454 sec)
20.838... logprob:  0.437083, 0.117188 (1.451 sec)
20.839... logprob:  0.471707, 0.125000 (1.507 sec)
20.840... logprob:  0.555320, 0.156250 (1.450 sec)
20.841... logprob:  0.396212, 0.101562 (1.470 sec)
20.842... logprob:  0.497821, 0.140625 (1.499 sec)
20.843... logprob:  0.465538, 0.125000 (1.458 sec)
20.844... logprob:  0.497627, 0.140625 (1.455 sec)
20.845... logprob:  0.486806, 0.132812 (1.454 sec)
20.846... logprob:  0.468466, 0.125000 (1.452 sec)
20.847... logprob:  0.363237, 0.085938 (1.452 sec)
20.848... logprob:  0.397072, 0.101562 (1.501 sec)
20.849... logprob:  0.360338, 0.085938 (1.456 sec)
20.850... logprob:  0.479421, 0.132812 (1.469 sec)
20.851... logprob:  0.440147, 0.117188 (1.498 sec)
20.852... logprob:  0.545756, 0.156250 (1.467 sec)
20.853... logprob:  0.371835, 0.093750 (1.462 sec)
20.854... logprob:  0.307096, 0.070312 (1.446 sec)
20.855... logprob:  0.484915, 0.132812 (1.453 sec)
20.856... logprob:  0.443825, 0.117188 (1.451 sec)
20.857... logprob:  0.372234, 0.093750 (1.497 sec)
20.858... logprob:  0.396246, 0.101562 (1.486 sec)
20.859... logprob:  0.307957, 0.070312 (1.475 sec)
20.860... logprob:  0.565969, 0.156250 (1.483 sec)
20.861... logprob:  0.417813, 0.109375 (1.465 sec)
20.862... logprob:  0.328907, 0.078125 (1.457 sec)
20.863... logprob:  0.399533, 0.101562 (1.453 sec)
20.864... logprob:  0.451419, 0.117188 (1.444 sec)
20.865... logprob:  0.484453, 0.132812 (1.458 sec)
20.866... logprob:  0.507578, 0.140625 (1.487 sec)
20.867... logprob:  0.502917, 0.140625 (1.474 sec)
20.868... logprob:  0.405345, 0.101562 (1.470 sec)
20.869... logprob:  0.383274, 0.093750 (1.479 sec)
20.870... logprob:  0.552023, 0.156250 (1.401 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.715362548828125, 10.0]}, 128)
batch 872: ({'logprob': [66.2840347290039, 19.0]}, 128)
batch 873: ({'logprob': [41.24345397949219, 9.0]}, 128)
batch 874: ({'logprob': [45.85136413574219, 11.0]}, 128)
batch 875: ({'logprob': [51.11144256591797, 13.0]}, 128)
batch 876: ({'logprob': [63.83638000488281, 18.0]}, 128)
batch 877: ({'logprob': [46.18604278564453, 11.0]}, 128)
batch 878: ({'logprob': [61.67556381225586, 17.0]}, 128)
batch 879: ({'logprob': [72.53126525878906, 21.0]}, 128)
batch 880: ({'logprob': [51.13180160522461, 13.0]}, 128)
batch 881: ({'logprob': [30.355127334594727, 5.0]}, 128)
batch 882: ({'logprob': [54.5823860168457, 14.0]}, 128)
batch 883: ({'logprob': [61.65494918823242, 17.0]}, 128)
batch 884: ({'logprob': [51.4416618347168, 13.0]}, 128)
batch 885: ({'logprob': [52.097049713134766, 13.0]}, 128)
batch 886: ({'logprob': [61.99668884277344, 17.0]}, 128)

======================Test output======================
logprob:  0.417331, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.965972e-03 [3.280330e-09] 
Layer 'conv1' biases: 2.240310e-07 [6.796510e-11] 
Layer 'conv2' weights[0]: 7.953084e-03 [2.051713e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.866625e-10] 
Layer 'conv3' weights[0]: 7.951329e-03 [1.965028e-09] 
Layer 'conv3' biases: 1.926434e-06 [1.219601e-09] 
Layer 'conv4' weights[0]: 7.983980e-03 [2.136375e-09] 
Layer 'conv4' biases: 9.999994e-01 [1.093184e-08] 
Layer 'conv5' weights[0]: 7.982809e-03 [7.333808e-08] 
Layer 'conv5' biases: 9.999957e-01 [7.918245e-08] 
Layer 'fc6' weights[0]: 7.579516e-03 [6.099149e-09] 
Layer 'fc6' biases: 9.999999e-01 [6.195878e-09] 
Layer 'fc7' weights[0]: 7.191637e-03 [2.700539e-07] 
Layer 'fc7' biases: 9.998612e-01 [2.602537e-07] 
Layer 'fc8' weights[0]: 1.279572e-03 [9.172730e-06] 
Layer 'fc8' biases: 4.948980e-02 [5.880292e-05] 
Train error last 870 batches: 0.435234
-------------------------------------------------------
Not saving because 0.417331 > 0.415685 (17.630: -0.01%)
======================================================= (12.072 sec)
21.1... logprob:  0.380115, 0.093750 (1.413 sec)
21.2... logprob:  0.448273, 0.117188 (1.456 sec)
21.3... logprob:  0.398379, 0.101562 (1.424 sec)
21.4... logprob:  0.443337, 0.117188 (1.531 sec)
21.5... logprob:  0.443441, 0.117188 (1.436 sec)
21.6... logprob:  0.499155, 0.140625 (1.396 sec)
21.7... logprob:  0.363122, 0.085938 (1.415 sec)
21.8... logprob:  0.419125, 0.109375 (1.400 sec)
21.9... logprob:  0.358736, 0.085938 (1.406 sec)
21.10... logprob:  0.377445, 0.093750 (1.406 sec)
21.11... logprob:  0.334660, 0.078125 (1.443 sec)
21.12... logprob:  0.466451, 0.125000 (1.396 sec)
21.13... logprob:  0.442316, 0.117188 (1.423 sec)
21.14... logprob:  0.444704, 0.117188 (1.402 sec)
21.15... logprob:  0.395600, 0.101562 (1.408 sec)
21.16... logprob:  0.421431, 0.109375 (1.402 sec)
21.17... logprob:  0.516055, 0.140625 (1.394 sec)
21.18... logprob:  0.262104, 0.054688 (1.405 sec)
21.19... logprob:  0.279576, 0.062500 (1.403 sec)
21.20... logprob:  0.421376, 0.109375 (1.404 sec)
21.21... logprob:  0.443965, 0.117188 (0.891 sec)
21.22... logprob:  0.536643, 0.148438 (1.339 sec)
21.23... logprob:  0.532912, 0.148438 (1.421 sec)
21.24... logprob:  0.310676, 0.070312 (0.989 sec)
21.25... logprob:  0.356258, 0.085938 (0.958 sec)
21.26... logprob:  0.463712, 0.125000 (1.452 sec)
21.27... logprob:  0.404572, 0.101562 (1.387 sec)
21.28... logprob:  0.421864, 0.109375 (1.410 sec)
21.29... logprob:  0.396013, 0.101562 (1.419 sec)
21.30... logprob:  0.374143, 0.093750 (1.423 sec)
21.31... logprob:  0.479926, 0.132812 (1.403 sec)
21.32... logprob:  0.457230, 0.125000 (1.396 sec)
21.33... logprob:  0.460677, 0.125000 (1.450 sec)
21.34... logprob:  0.464590, 0.125000 (1.390 sec)
21.35... logprob:  0.316244, 0.070312 (1.405 sec)
21.36... logprob:  0.475798, 0.132812 (1.398 sec)
21.37... logprob:  0.417593, 0.109375 (1.406 sec)
21.38... logprob:  0.392578, 0.101562 (1.399 sec)
21.39... logprob:  0.631734, 0.187500 (1.437 sec)
21.40... logprob:  0.445778, 0.117188 (1.411 sec)
21.41... logprob:  0.352849, 0.085938 (1.426 sec)
21.42... logprob:  0.391906, 0.101562 (1.420 sec)
21.43... logprob:  0.440102, 0.117188 (1.411 sec)
21.44... logprob:  0.518531, 0.148438 (1.435 sec)
21.45... logprob:  0.381757, 0.093750 (1.401 sec)
21.46... logprob:  0.486295, 0.132812 (1.397 sec)
21.47... logprob:  0.331743, 0.078125 (1.397 sec)
21.48... logprob:  0.498901, 0.140625 (1.427 sec)
21.49... logprob:  0.510738, 0.148438 (1.415 sec)
21.50... logprob:  0.393220, 0.101562 (1.429 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.84113311767578, 10.0]}, 128)
batch 872: ({'logprob': [66.26803588867188, 19.0]}, 128)
batch 873: ({'logprob': [40.97646713256836, 9.0]}, 128)
batch 874: ({'logprob': [45.38986587524414, 11.0]}, 128)
batch 875: ({'logprob': [50.863277435302734, 13.0]}, 128)
batch 876: ({'logprob': [63.815635681152344, 18.0]}, 128)
batch 877: ({'logprob': [45.927757263183594, 11.0]}, 128)
batch 878: ({'logprob': [61.85386657714844, 17.0]}, 128)
batch 879: ({'logprob': [73.33867645263672, 21.0]}, 128)
batch 880: ({'logprob': [50.88322830200195, 13.0]}, 128)
batch 881: ({'logprob': [29.457443237304688, 5.0]}, 128)
batch 882: ({'logprob': [54.95077133178711, 14.0]}, 128)
batch 883: ({'logprob': [61.83332824707031, 17.0]}, 128)
batch 884: ({'logprob': [51.39813995361328, 13.0]}, 128)
batch 885: ({'logprob': [52.46126937866211, 13.0]}, 128)
batch 886: ({'logprob': [62.379390716552734, 17.0]}, 128)

======================Test output======================
logprob:  0.416816, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.965932e-03 [2.619310e-09] 
Layer 'conv1' biases: 2.249445e-07 [4.162216e-11] 
Layer 'conv2' weights[0]: 7.953046e-03 [1.925131e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.788152e-10] 
Layer 'conv3' weights[0]: 7.951286e-03 [1.357892e-09] 
Layer 'conv3' biases: 1.932992e-06 [5.026888e-10] 
Layer 'conv4' weights[0]: 7.983944e-03 [1.315191e-09] 
Layer 'conv4' biases: 9.999993e-01 [2.267156e-09] 
Layer 'conv5' weights[0]: 7.982752e-03 [1.097041e-08] 
Layer 'conv5' biases: 9.999952e-01 [1.117124e-08] 
Layer 'fc6' weights[0]: 7.579473e-03 [1.155397e-09] 
Layer 'fc6' biases: 9.999999e-01 [8.287533e-10] 
Layer 'fc7' weights[0]: 7.189863e-03 [5.015474e-08] 
Layer 'fc7' biases: 9.998621e-01 [2.870191e-08] 
Layer 'fc8' weights[0]: 1.295472e-03 [6.437926e-06] 
Layer 'fc8' biases: 4.968554e-02 [4.178621e-05] 
Train error last 870 batches: 0.435234
-------------------------------------------------------
Not saving because 0.416816 > 0.415685 (17.630: -0.01%)
======================================================= (12.215 sec)
21.51... logprob:  0.490110, 0.140625 (1.419 sec)
21.52... logprob:  0.525783, 0.148438 (1.410 sec)
21.53... logprob:  0.294946, 0.062500 (1.450 sec)
21.54... logprob:  0.403310, 0.109375 (1.389 sec)
21.55... logprob:  0.331755, 0.078125 (1.403 sec)
21.56... logprob:  0.421674, 0.109375 (1.429 sec)
21.57... logprob:  0.572457, 0.164062 (1.430 sec)
21.58... logprob:  0.407679, 0.101562 (1.407 sec)
21.59... logprob:  0.333862, 0.078125 (1.468 sec)
21.60... logprob:  0.618909, 0.179688 (1.425 sec)
21.61... logprob:  0.382841, 0.093750 (1.436 sec)
21.62... logprob:  0.474877, 0.132812 (1.458 sec)
21.63... logprob:  0.397301, 0.101562 (1.438 sec)
21.64... logprob:  0.450290, 0.125000 (1.412 sec)
21.65... logprob:  0.373344, 0.093750 (1.396 sec)
21.66... logprob:  0.354019, 0.085938 (1.449 sec)
21.67... logprob:  0.295400, 0.062500 (1.393 sec)
21.68... logprob:  0.396810, 0.101562 (1.400 sec)
21.69... logprob:  0.496766, 0.140625 (1.424 sec)
21.70... logprob:  0.325885, 0.078125 (1.425 sec)
21.71... logprob:  0.381822, 0.101562 (1.464 sec)
21.72... logprob:  0.493786, 0.132812 (1.408 sec)
21.73... logprob:  0.447739, 0.117188 (1.430 sec)
21.74... logprob:  0.442560, 0.117188 (1.417 sec)
21.75... logprob:  0.380647, 0.093750 (1.414 sec)
21.76... logprob:  0.412069, 0.109375 (1.441 sec)
21.77... logprob:  0.396342, 0.101562 (1.431 sec)
21.78... logprob:  0.493062, 0.140625 (1.455 sec)
21.79... logprob:  0.456454, 0.125000 (1.408 sec)
21.80... logprob:  0.507938, 0.132812 (1.423 sec)
21.81... logprob:  0.416724, 0.109375 (1.421 sec)
21.82... logprob:  0.231577, 0.039062 (1.423 sec)
21.83... logprob:  0.493761, 0.140625 (1.406 sec)
21.84... logprob:  0.468107, 0.125000 (1.462 sec)
21.85... logprob:  0.431988, 0.117188 (1.424 sec)
21.86... logprob:  0.416964, 0.109375 (1.425 sec)
21.87... logprob:  0.633229, 0.187500 (1.415 sec)
21.88... logprob:  0.535066, 0.156250 (1.414 sec)
21.89... logprob:  0.410597, 0.109375 (1.436 sec)
21.90... logprob:  0.577496, 0.171875 (1.391 sec)
21.91... logprob:  0.348499, 0.078125 (1.398 sec)
21.92... logprob:  0.464462, 0.125000 (1.400 sec)
21.93... logprob:  0.492252, 0.140625 (1.405 sec)
21.94... logprob:  0.428783, 0.109375 (1.388 sec)
21.95... logprob:  0.471846, 0.125000 (1.403 sec)
21.96... logprob:  0.576283, 0.171875 (1.411 sec)
21.97... logprob:  0.430768, 0.117188 (1.393 sec)
21.98... logprob:  0.391098, 0.093750 (1.462 sec)
21.99... logprob:  0.474274, 0.132812 (1.412 sec)
21.100... logprob:  0.310461, 0.070312 (1.400 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.232513427734375, 10.0]}, 128)
batch 872: ({'logprob': [66.12662506103516, 19.0]}, 128)
batch 873: ({'logprob': [41.252471923828125, 9.0]}, 128)
batch 874: ({'logprob': [45.6430778503418, 11.0]}, 128)
batch 875: ({'logprob': [50.9927864074707, 13.0]}, 128)
batch 876: ({'logprob': [63.71083068847656, 18.0]}, 128)
batch 877: ({'logprob': [46.13089370727539, 11.0]}, 128)
batch 878: ({'logprob': [61.735382080078125, 17.0]}, 128)
batch 879: ({'logprob': [72.92194366455078, 21.0]}, 128)
batch 880: ({'logprob': [51.012691497802734, 13.0]}, 128)
batch 881: ({'logprob': [30.03236961364746, 5.0]}, 128)
batch 882: ({'logprob': [54.89137268066406, 14.0]}, 128)
batch 883: ({'logprob': [61.71482849121094, 17.0]}, 128)
batch 884: ({'logprob': [51.47639083862305, 13.0]}, 128)
batch 885: ({'logprob': [52.43811798095703, 13.0]}, 128)
batch 886: ({'logprob': [62.2098388671875, 17.0]}, 128)

======================Test output======================
logprob:  0.417247, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.965895e-03 [4.067416e-09] 
Layer 'conv1' biases: 2.257034e-07 [1.456520e-10] 
Layer 'conv2' weights[0]: 7.953013e-03 [4.128907e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.440685e-10] 
Layer 'conv3' weights[0]: 7.951245e-03 [4.068113e-09] 
Layer 'conv3' biases: 1.938708e-06 [2.567267e-09] 
Layer 'conv4' weights[0]: 7.983910e-03 [4.429036e-09] 
Layer 'conv4' biases: 9.999993e-01 [2.456460e-08] 
Layer 'conv5' weights[0]: 7.982728e-03 [1.634938e-07] 
Layer 'conv5' biases: 9.999950e-01 [1.764799e-07] 
Layer 'fc6' weights[0]: 7.579432e-03 [1.355759e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.384359e-08] 
Layer 'fc7' weights[0]: 7.188048e-03 [2.975503e-07] 
Layer 'fc7' biases: 9.998617e-01 [2.870316e-07] 
Layer 'fc8' weights[0]: 1.285975e-03 [1.068590e-05] 
Layer 'fc8' biases: 4.968825e-02 [7.309021e-05] 
Train error last 870 batches: 0.435234
-------------------------------------------------------
Not saving because 0.417247 > 0.415685 (17.630: -0.01%)
======================================================= (12.028 sec)
21.101... logprob:  0.310679, 0.062500 (1.453 sec)
21.102... logprob:  0.546183, 0.156250 (1.396 sec)
21.103... logprob:  0.541175, 0.156250 (1.402 sec)
21.104... logprob:  0.388846, 0.101562 (1.406 sec)
21.105... logprob:  0.619599, 0.179688 (1.401 sec)
21.106... logprob:  0.344443, 0.085938 (1.394 sec)
21.107... logprob:  0.335735, 0.078125 (1.445 sec)
21.108... logprob:  0.586834, 0.171875 (1.403 sec)
21.109... logprob:  0.336171, 0.078125 (1.413 sec)
21.110... logprob:  0.564525, 0.164062 (1.400 sec)
21.111... logprob:  0.404706, 0.101562 (1.400 sec)
21.112... logprob:  0.366111, 0.093750 (1.406 sec)
21.113... logprob:  0.354577, 0.085938 (1.399 sec)
21.114... logprob:  0.440223, 0.117188 (1.436 sec)
21.115... logprob:  0.506742, 0.140625 (1.414 sec)
21.116... logprob:  0.393384, 0.101562 (1.405 sec)
21.117... logprob:  0.440394, 0.117188 (1.447 sec)
21.118... logprob:  0.409138, 0.101562 (1.389 sec)
21.119... logprob:  0.346117, 0.085938 (1.401 sec)
21.120... logprob:  0.547139, 0.156250 (1.400 sec)
21.121... logprob:  0.412644, 0.109375 (1.398 sec)
21.122... logprob:  0.519320, 0.148438 (1.450 sec)
21.123... logprob:  0.463717, 0.125000 (1.385 sec)
21.124... logprob:  0.447702, 0.125000 (1.410 sec)
21.125... logprob:  0.501970, 0.140625 (1.408 sec)
21.126... logprob:  0.475779, 0.125000 (1.396 sec)
21.127... logprob:  0.479579, 0.125000 (1.403 sec)
21.128... logprob:  0.422360, 0.109375 (1.423 sec)
21.129... logprob:  0.574892, 0.164062 (1.415 sec)
21.130... logprob:  0.382731, 0.093750 (1.421 sec)
21.131... logprob:  0.495498, 0.132812 (1.418 sec)
21.132... logprob:  0.506373, 0.140625 (1.443 sec)
21.133... logprob:  0.444683, 0.117188 (1.393 sec)
21.134... logprob:  0.401896, 0.101562 (1.391 sec)
21.135... logprob:  0.460219, 0.125000 (1.411 sec)
21.136... logprob:  0.562492, 0.164062 (1.396 sec)
21.137... logprob:  0.462574, 0.125000 (1.391 sec)
21.138... logprob:  0.319361, 0.070312 (1.446 sec)
21.139... logprob:  0.395768, 0.101562 (1.398 sec)
21.140... logprob:  0.560331, 0.164062 (1.417 sec)
21.141... logprob:  0.464553, 0.125000 (1.439 sec)
21.142... logprob:  0.464619, 0.125000 (1.401 sec)
21.143... logprob:  0.294321, 0.062500 (1.427 sec)
21.144... logprob:  0.457202, 0.125000 (1.421 sec)
21.145... logprob:  0.324816, 0.078125 (1.414 sec)
21.146... logprob:  0.483177, 0.132812 (1.413 sec)
21.147... logprob:  0.262474, 0.054688 (1.434 sec)
21.148... logprob:  0.458743, 0.125000 (1.390 sec)
21.149... logprob:  0.442539, 0.117188 (1.397 sec)
21.150... logprob:  0.347607, 0.085938 (1.401 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.26275634765625, 10.0]}, 128)
batch 872: ({'logprob': [67.9063949584961, 19.0]}, 128)
batch 873: ({'logprob': [39.59328842163086, 9.0]}, 128)
batch 874: ({'logprob': [44.806461334228516, 11.0]}, 128)
batch 875: ({'logprob': [50.75156784057617, 13.0]}, 128)
batch 876: ({'logprob': [65.13770294189453, 18.0]}, 128)
batch 877: ({'logprob': [45.18002700805664, 11.0]}, 128)
batch 878: ({'logprob': [62.69283676147461, 17.0]}, 128)
batch 879: ({'logprob': [74.96533966064453, 21.0]}, 128)
batch 880: ({'logprob': [50.7733039855957, 13.0]}, 128)
batch 881: ({'logprob': [27.285207748413086, 5.0]}, 128)
batch 882: ({'logprob': [54.67411422729492, 14.0]}, 128)
batch 883: ({'logprob': [62.671321868896484, 17.0]}, 128)
batch 884: ({'logprob': [51.12857437133789, 13.0]}, 128)
batch 885: ({'logprob': [51.867130279541016, 13.0]}, 128)
batch 886: ({'logprob': [63.05802536010742, 17.0]}, 128)

======================Test output======================
logprob:  0.416872, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.965856e-03 [2.648842e-09] 
Layer 'conv1' biases: 2.264859e-07 [4.751816e-11] 
Layer 'conv2' weights[0]: 7.952970e-03 [1.561946e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.777794e-10] 
Layer 'conv3' weights[0]: 7.951206e-03 [1.207085e-09] 
Layer 'conv3' biases: 1.945469e-06 [4.531320e-10] 
Layer 'conv4' weights[0]: 7.983858e-03 [1.158754e-09] 
Layer 'conv4' biases: 9.999993e-01 [2.395673e-09] 
Layer 'conv5' weights[0]: 7.982679e-03 [1.076410e-08] 
Layer 'conv5' biases: 9.999949e-01 [1.087443e-08] 
Layer 'fc6' weights[0]: 7.579396e-03 [1.108739e-09] 
Layer 'fc6' biases: 9.999999e-01 [7.676277e-10] 
Layer 'fc7' weights[0]: 7.186172e-03 [1.281281e-07] 
Layer 'fc7' biases: 9.998627e-01 [1.150467e-07] 
Layer 'fc8' weights[0]: 1.343638e-03 [8.880476e-06] 
Layer 'fc8' biases: 5.018023e-02 [5.749905e-05] 
Train error last 870 batches: 0.435233
-------------------------------------------------------
Not saving because 0.416872 > 0.415685 (17.630: -0.01%)
======================================================= (12.094 sec)
21.151... logprob:  0.347148, 0.085938 (1.411 sec)
21.152... logprob:  0.785056, 0.234375 (1.402 sec)
21.153... logprob:  0.381657, 0.093750 (1.447 sec)
21.154... logprob:  0.524501, 0.148438 (1.407 sec)
21.155... logprob:  0.426027, 0.117188 (1.415 sec)
21.156... logprob:  0.295633, 0.062500 (1.433 sec)
21.157... logprob:  0.270543, 0.054688 (1.401 sec)
21.158... logprob:  0.455393, 0.125000 (1.404 sec)
21.159... logprob:  0.483116, 0.132812 (1.405 sec)
21.160... logprob:  0.444815, 0.117188 (1.396 sec)
21.161... logprob:  0.349983, 0.078125 (1.405 sec)
21.162... logprob:  0.611789, 0.179688 (1.411 sec)
21.163... logprob:  0.450445, 0.125000 (1.431 sec)
21.164... logprob:  0.468626, 0.125000 (1.426 sec)
21.165... logprob:  0.547880, 0.156250 (1.436 sec)
21.166... logprob:  0.446091, 0.125000 (1.455 sec)
21.167... logprob:  0.350487, 0.085938 (1.426 sec)
21.168... logprob:  0.363702, 0.085938 (1.428 sec)
21.169... logprob:  0.408662, 0.101562 (1.462 sec)
21.170... logprob:  0.459481, 0.125000 (1.400 sec)
21.171... logprob:  0.535374, 0.156250 (1.428 sec)
21.172... logprob:  0.434846, 0.109375 (1.413 sec)
21.173... logprob:  0.440485, 0.117188 (1.426 sec)
21.174... logprob:  0.600981, 0.171875 (1.409 sec)
21.175... logprob:  0.506051, 0.140625 (1.472 sec)
21.176... logprob:  0.478455, 0.132812 (1.415 sec)
21.177... logprob:  0.289746, 0.054688 (1.432 sec)
21.178... logprob:  0.383481, 0.093750 (1.461 sec)
21.179... logprob:  0.394699, 0.101562 (1.415 sec)
21.180... logprob:  0.466384, 0.125000 (1.422 sec)
21.181... logprob:  0.539354, 0.156250 (1.421 sec)
21.182... logprob:  0.371354, 0.093750 (1.417 sec)
21.183... logprob:  0.419949, 0.109375 (1.415 sec)
21.184... logprob:  0.483458, 0.132812 (1.423 sec)
21.185... logprob:  0.289823, 0.062500 (1.401 sec)
21.186... logprob:  0.370450, 0.093750 (1.400 sec)
21.187... logprob:  0.529622, 0.148438 (1.407 sec)
21.188... logprob:  0.458941, 0.125000 (1.400 sec)
21.189... logprob:  0.440912, 0.117188 (1.389 sec)
21.190... logprob:  0.375762, 0.093750 (1.436 sec)
21.191... logprob:  0.485096, 0.132812 (1.412 sec)
21.192... logprob:  0.520111, 0.148438 (1.414 sec)
21.193... logprob:  0.312570, 0.070312 (1.424 sec)
21.194... logprob:  0.414090, 0.109375 (1.416 sec)
21.195... logprob:  0.287151, 0.062500 (1.398 sec)
21.196... logprob:  0.410516, 0.109375 (1.395 sec)
21.197... logprob:  0.478009, 0.132812 (1.401 sec)
21.198... logprob:  0.355795, 0.085938 (1.409 sec)
21.199... logprob:  0.437193, 0.117188 (1.395 sec)
21.200... logprob:  0.440756, 0.117188 (1.443 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.39178466796875, 10.0]}, 128)
batch 872: ({'logprob': [66.89167785644531, 19.0]}, 128)
batch 873: ({'logprob': [40.266178131103516, 9.0]}, 128)
batch 874: ({'logprob': [44.99607849121094, 11.0]}, 128)
batch 875: ({'logprob': [50.7020149230957, 13.0]}, 128)
batch 876: ({'logprob': [64.30290222167969, 18.0]}, 128)
batch 877: ({'logprob': [45.49188232421875, 11.0]}, 128)
batch 878: ({'logprob': [62.161163330078125, 17.0]}, 128)
batch 879: ({'logprob': [74.07244873046875, 21.0]}, 128)
batch 880: ({'logprob': [50.72291564941406, 13.0]}, 128)
batch 881: ({'logprob': [28.319637298583984, 5.0]}, 128)
batch 882: ({'logprob': [54.80507278442383, 14.0]}, 128)
batch 883: ({'logprob': [62.14000701904297, 17.0]}, 128)
batch 884: ({'logprob': [51.19784927368164, 13.0]}, 128)
batch 885: ({'logprob': [52.178340911865234, 13.0]}, 128)
batch 886: ({'logprob': [62.6463508605957, 17.0]}, 128)

======================Test output======================
logprob:  0.416155, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.965824e-03 [3.646218e-09] 
Layer 'conv1' biases: 2.274818e-07 [1.045458e-10] 
Layer 'conv2' weights[0]: 7.952929e-03 [2.298394e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.950697e-10] 
Layer 'conv3' weights[0]: 7.951167e-03 [1.641650e-09] 
Layer 'conv3' biases: 1.954143e-06 [7.226132e-10] 
Layer 'conv4' weights[0]: 7.983821e-03 [1.602107e-09] 
Layer 'conv4' biases: 9.999993e-01 [4.108553e-09] 
Layer 'conv5' weights[0]: 7.982647e-03 [2.644052e-08] 
Layer 'conv5' biases: 9.999951e-01 [2.845160e-08] 
Layer 'fc6' weights[0]: 7.579355e-03 [2.391700e-09] 
Layer 'fc6' biases: 9.999999e-01 [2.260386e-09] 
Layer 'fc7' weights[0]: 7.184336e-03 [5.404386e-08] 
Layer 'fc7' biases: 9.998621e-01 [3.361124e-08] 
Layer 'fc8' weights[0]: 1.325395e-03 [4.834327e-06] 
Layer 'fc8' biases: 5.015161e-02 [3.169197e-05] 
Train error last 870 batches: 0.435233
-------------------------------------------------------
Not saving because 0.416155 > 0.415685 (17.630: -0.01%)
======================================================= (12.066 sec)
21.201... logprob:  0.437095, 0.117188 (1.415 sec)
21.202... logprob:  0.537916, 0.148438 (1.414 sec)
21.203... logprob:  0.420437, 0.109375 (1.445 sec)
21.204... logprob:  0.504124, 0.140625 (1.395 sec)
21.205... logprob:  0.334346, 0.078125 (1.406 sec)
21.206... logprob:  0.361631, 0.093750 (1.409 sec)
21.207... logprob:  0.381845, 0.093750 (1.400 sec)
21.208... logprob:  0.490545, 0.140625 (1.408 sec)
21.209... logprob:  0.334571, 0.078125 (1.419 sec)
21.210... logprob:  0.586238, 0.171875 (1.421 sec)
21.211... logprob:  0.488164, 0.132812 (1.416 sec)
21.212... logprob:  0.526139, 0.148438 (1.406 sec)
21.213... logprob:  0.514727, 0.140625 (1.466 sec)
21.214... logprob:  0.459419, 0.125000 (1.426 sec)
21.215... logprob:  0.396126, 0.101562 (1.420 sec)
21.216... logprob:  0.517030, 0.140625 (1.466 sec)
21.217... logprob:  0.325004, 0.070312 (1.413 sec)
21.218... logprob:  0.463652, 0.125000 (1.423 sec)
21.219... logprob:  0.500273, 0.140625 (1.420 sec)
21.220... logprob:  0.415010, 0.109375 (1.419 sec)
21.221... logprob:  0.399553, 0.101562 (1.415 sec)
21.222... logprob:  0.554506, 0.164062 (1.457 sec)
21.223... logprob:  0.569108, 0.164062 (1.428 sec)
21.224... logprob:  0.405917, 0.101562 (1.430 sec)
21.225... logprob:  0.391982, 0.101562 (1.453 sec)
21.226... logprob:  0.424681, 0.109375 (1.424 sec)
21.227... logprob:  0.452685, 0.125000 (1.417 sec)
21.228... logprob:  0.417184, 0.109375 (1.410 sec)
21.229... logprob:  0.489371, 0.132812 (1.422 sec)
21.230... logprob:  0.459877, 0.125000 (1.434 sec)
21.231... logprob:  0.453520, 0.125000 (1.405 sec)
21.232... logprob:  0.496200, 0.140625 (1.462 sec)
21.233... logprob:  0.466121, 0.132812 (1.431 sec)
21.234... logprob:  0.563829, 0.164062 (1.429 sec)
21.235... logprob:  0.482022, 0.132812 (1.475 sec)
21.236... logprob:  0.425733, 0.109375 (1.408 sec)
21.237... logprob:  0.341160, 0.078125 (1.429 sec)
21.238... logprob:  0.389265, 0.093750 (1.422 sec)
21.239... logprob:  0.478118, 0.132812 (1.422 sec)
21.240... logprob:  0.485801, 0.132812 (1.400 sec)
21.241... logprob:  0.493602, 0.132812 (1.474 sec)
21.242... logprob:  0.341647, 0.078125 (1.428 sec)
21.243... logprob:  0.386010, 0.093750 (1.437 sec)
21.244... logprob:  0.315310, 0.070312 (1.444 sec)
21.245... logprob:  0.494288, 0.132812 (1.430 sec)
21.246... logprob:  0.416879, 0.109375 (1.413 sec)
21.247... logprob:  0.357449, 0.085938 (1.421 sec)
21.248... logprob:  0.307880, 0.070312 (1.423 sec)
21.249... logprob:  0.555062, 0.156250 (1.424 sec)
21.250... logprob:  0.591505, 0.164062 (1.405 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.4268913269043, 10.0]}, 128)
batch 872: ({'logprob': [67.85459899902344, 19.0]}, 128)
batch 873: ({'logprob': [39.593387603759766, 9.0]}, 128)
batch 874: ({'logprob': [44.86163330078125, 11.0]}, 128)
batch 875: ({'logprob': [50.75261306762695, 13.0]}, 128)
batch 876: ({'logprob': [65.08588409423828, 18.0]}, 128)
batch 877: ({'logprob': [45.18085479736328, 11.0]}, 128)
batch 878: ({'logprob': [62.58613204956055, 17.0]}, 128)
batch 879: ({'logprob': [74.69602966308594, 21.0]}, 128)
batch 880: ({'logprob': [50.774723052978516, 13.0]}, 128)
batch 881: ({'logprob': [27.447887420654297, 5.0]}, 128)
batch 882: ({'logprob': [54.511844635009766, 14.0]}, 128)
batch 883: ({'logprob': [62.56428146362305, 17.0]}, 128)
batch 884: ({'logprob': [51.07499694824219, 13.0]}, 128)
batch 885: ({'logprob': [51.70430374145508, 13.0]}, 128)
batch 886: ({'logprob': [62.89655303955078, 17.0]}, 128)

======================Test output======================
logprob:  0.416510, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.965788e-03 [7.525512e-09] 
Layer 'conv1' biases: 2.283829e-07 [1.895847e-10] 
Layer 'conv2' weights[0]: 7.952891e-03 [5.658186e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.159261e-09] 
Layer 'conv3' weights[0]: 7.951127e-03 [5.240041e-09] 
Layer 'conv3' biases: 1.961053e-06 [3.632577e-09] 
Layer 'conv4' weights[0]: 7.983783e-03 [5.581191e-09] 
Layer 'conv4' biases: 9.999993e-01 [3.305584e-08] 
Layer 'conv5' weights[0]: 7.982616e-03 [2.195335e-07] 
Layer 'conv5' biases: 9.999951e-01 [2.366791e-07] 
Layer 'fc6' weights[0]: 7.579310e-03 [1.858018e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.876655e-08] 
Layer 'fc7' weights[0]: 7.182530e-03 [1.784052e-07] 
Layer 'fc7' biases: 9.998622e-01 [1.680940e-07] 
Layer 'fc8' weights[0]: 1.347192e-03 [9.253955e-06] 
Layer 'fc8' biases: 5.037957e-02 [5.870059e-05] 
Train error last 870 batches: 0.435233
-------------------------------------------------------
Not saving because 0.416510 > 0.415685 (17.630: -0.01%)
======================================================= (11.957 sec)
21.251... logprob:  0.352946, 0.085938 (1.465 sec)
21.252... logprob:  0.348464, 0.085938 (1.437 sec)
21.253... logprob:  0.379193, 0.093750 (1.416 sec)
21.254... logprob:  0.444171, 0.117188 (1.468 sec)
21.255... logprob:  0.351417, 0.085938 (1.408 sec)
21.256... logprob:  0.378794, 0.093750 (1.428 sec)
21.257... logprob:  0.332012, 0.078125 (1.419 sec)
21.258... logprob:  0.415660, 0.109375 (1.418 sec)
21.259... logprob:  0.442313, 0.117188 (1.406 sec)
21.260... logprob:  0.308302, 0.070312 (1.458 sec)
21.261... logprob:  0.392704, 0.101562 (1.428 sec)
21.262... logprob:  0.524606, 0.148438 (1.431 sec)
21.263... logprob:  0.425523, 0.109375 (1.452 sec)
21.264... logprob:  0.375097, 0.093750 (1.418 sec)
21.265... logprob:  0.439613, 0.117188 (1.423 sec)
21.266... logprob:  0.439023, 0.117188 (1.417 sec)
21.267... logprob:  0.422017, 0.109375 (1.425 sec)
21.268... logprob:  0.458940, 0.125000 (1.432 sec)
21.269... logprob:  0.567510, 0.164062 (1.405 sec)
21.270... logprob:  0.542261, 0.156250 (1.463 sec)
21.271... logprob:  0.445683, 0.117188 (1.426 sec)
21.272... logprob:  0.384677, 0.093750 (1.419 sec)
21.273... logprob:  0.500223, 0.140625 (1.467 sec)
21.274... logprob:  0.542514, 0.156250 (1.432 sec)
21.275... logprob:  0.487662, 0.132812 (1.421 sec)
21.276... logprob:  0.390105, 0.093750 (1.421 sec)
21.277... logprob:  0.428669, 0.109375 (1.422 sec)
21.278... logprob:  0.323494, 0.070312 (1.426 sec)
21.279... logprob:  0.325103, 0.070312 (1.460 sec)
21.280... logprob:  0.215529, 0.031250 (1.409 sec)
21.281... logprob:  0.417227, 0.109375 (1.426 sec)
21.282... logprob:  0.411395, 0.109375 (1.419 sec)
21.283... logprob:  0.393801, 0.101562 (1.416 sec)
21.284... logprob:  0.394555, 0.101562 (1.423 sec)
21.285... logprob:  0.451834, 0.117188 (1.446 sec)
21.286... logprob:  0.536983, 0.140625 (1.442 sec)
21.287... logprob:  0.346611, 0.085938 (1.430 sec)
21.288... logprob:  0.329962, 0.078125 (1.438 sec)
21.289... logprob:  0.445928, 0.117188 (1.443 sec)
21.290... logprob:  0.490657, 0.132812 (1.412 sec)
21.291... logprob:  0.439229, 0.117188 (1.428 sec)
21.292... logprob:  0.567330, 0.156250 (1.422 sec)
21.293... logprob:  0.427603, 0.117188 (1.426 sec)
21.294... logprob:  0.355990, 0.085938 (1.407 sec)
21.295... logprob:  0.334781, 0.078125 (1.461 sec)
21.296... logprob:  0.355885, 0.085938 (1.423 sec)
21.297... logprob:  0.394606, 0.101562 (1.426 sec)
21.298... logprob:  0.448165, 0.125000 (1.464 sec)
21.299... logprob:  0.342342, 0.078125 (1.402 sec)
21.300... logprob:  0.406550, 0.101562 (1.430 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.0065803527832, 10.0]}, 128)
batch 872: ({'logprob': [66.17774200439453, 19.0]}, 128)
batch 873: ({'logprob': [41.1268196105957, 9.0]}, 128)
batch 874: ({'logprob': [45.50715637207031, 11.0]}, 128)
batch 875: ({'logprob': [50.92243957519531, 13.0]}, 128)
batch 876: ({'logprob': [63.74829864501953, 18.0]}, 128)
batch 877: ({'logprob': [46.03276062011719, 11.0]}, 128)
batch 878: ({'logprob': [61.79678726196289, 17.0]}, 128)
batch 879: ({'logprob': [73.15238189697266, 21.0]}, 128)
batch 880: ({'logprob': [50.94257354736328, 13.0]}, 128)
batch 881: ({'logprob': [29.737062454223633, 5.0]}, 128)
batch 882: ({'logprob': [54.94917678833008, 14.0]}, 128)
batch 883: ({'logprob': [61.776023864746094, 17.0]}, 128)
batch 884: ({'logprob': [51.444454193115234, 13.0]}, 128)
batch 885: ({'logprob': [52.482078552246094, 13.0]}, 128)
batch 886: ({'logprob': [62.309417724609375, 17.0]}, 128)

======================Test output======================
logprob:  0.417047, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.965745e-03 [3.486600e-09] 
Layer 'conv1' biases: 2.293986e-07 [9.014080e-11] 
Layer 'conv2' weights[0]: 7.952855e-03 [3.677017e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.763934e-10] 
Layer 'conv3' weights[0]: 7.951082e-03 [3.309369e-09] 
Layer 'conv3' biases: 1.969040e-06 [1.843771e-09] 
Layer 'conv4' weights[0]: 7.983748e-03 [3.455853e-09] 
Layer 'conv4' biases: 9.999993e-01 [1.637443e-08] 
Layer 'conv5' weights[0]: 7.982574e-03 [1.052912e-07] 
Layer 'conv5' biases: 9.999951e-01 [1.134222e-07] 
Layer 'fc6' weights[0]: 7.579274e-03 [8.873723e-09] 
Layer 'fc6' biases: 9.999999e-01 [8.958403e-09] 
Layer 'fc7' weights[0]: 7.180754e-03 [1.550500e-07] 
Layer 'fc7' biases: 9.998615e-01 [1.430783e-07] 
Layer 'fc8' weights[0]: 1.298535e-03 [4.934333e-06] 
Layer 'fc8' biases: 5.030877e-02 [3.984024e-05] 
Train error last 870 batches: 0.435232
-------------------------------------------------------
Not saving because 0.417047 > 0.415685 (17.630: -0.01%)
======================================================= (12.079 sec)
21.301... logprob:  0.397933, 0.101562 (1.431 sec)
21.302... logprob:  0.591553, 0.179688 (1.428 sec)
21.303... logprob:  0.459568, 0.125000 (1.411 sec)
21.304... logprob:  0.459667, 0.125000 (1.445 sec)
21.305... logprob:  0.455218, 0.125000 (1.434 sec)
21.306... logprob:  0.440594, 0.117188 (1.441 sec)
21.307... logprob:  0.421611, 0.109375 (1.458 sec)
21.308... logprob:  0.374677, 0.093750 (1.458 sec)
21.309... logprob:  0.450484, 0.125000 (1.421 sec)
21.310... logprob:  0.473684, 0.125000 (1.427 sec)
21.311... logprob:  0.502580, 0.140625 (1.432 sec)
21.312... logprob:  0.478744, 0.132812 (1.427 sec)
21.313... logprob:  0.454866, 0.125000 (1.421 sec)
21.314... logprob:  0.454443, 0.117188 (1.469 sec)
21.315... logprob:  0.314677, 0.070312 (1.434 sec)
21.316... logprob:  0.468550, 0.125000 (1.423 sec)
21.317... logprob:  0.355478, 0.085938 (1.482 sec)
21.318... logprob:  0.455411, 0.125000 (1.412 sec)
21.319... logprob:  0.423191, 0.117188 (1.429 sec)
21.320... logprob:  0.412250, 0.109375 (1.425 sec)
21.321... logprob:  0.348269, 0.085938 (1.427 sec)
21.322... logprob:  0.387487, 0.101562 (1.413 sec)
21.323... logprob:  0.416515, 0.109375 (1.477 sec)
21.324... logprob:  0.498615, 0.140625 (1.424 sec)
21.325... logprob:  0.350679, 0.085938 (1.438 sec)
21.326... logprob:  0.543183, 0.148438 (1.468 sec)
21.327... logprob:  0.554402, 0.164062 (1.421 sec)
21.328... logprob:  0.565060, 0.156250 (1.423 sec)
21.329... logprob:  0.401964, 0.101562 (1.426 sec)
21.330... logprob:  0.388598, 0.101562 (1.423 sec)
21.331... logprob:  0.352424, 0.085938 (1.421 sec)
21.332... logprob:  0.482783, 0.132812 (1.453 sec)
21.333... logprob:  0.339575, 0.085938 (1.444 sec)
21.334... logprob:  0.565180, 0.171875 (1.444 sec)
21.335... logprob:  0.358791, 0.085938 (1.438 sec)
21.336... logprob:  0.444843, 0.125000 (1.465 sec)
21.337... logprob:  0.566444, 0.164062 (1.428 sec)
21.338... logprob:  0.449515, 0.125000 (1.426 sec)
21.339... logprob:  0.488655, 0.132812 (1.424 sec)
21.340... logprob:  0.442072, 0.117188 (1.432 sec)
21.341... logprob:  0.530097, 0.148438 (1.417 sec)
21.342... logprob:  0.429646, 0.109375 (1.470 sec)
21.343... logprob:  0.434775, 0.109375 (1.440 sec)
21.344... logprob:  0.444464, 0.125000 (1.479 sec)
21.345... logprob:  0.488230, 0.132812 (1.444 sec)
21.346... logprob:  0.436228, 0.117188 (1.435 sec)
21.347... logprob:  0.372427, 0.085938 (1.489 sec)
21.348... logprob:  0.398454, 0.101562 (1.432 sec)
21.349... logprob:  0.497761, 0.140625 (1.446 sec)
21.350... logprob:  0.358612, 0.085938 (1.438 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.50369644165039, 10.0]}, 128)
batch 872: ({'logprob': [66.47993469238281, 19.0]}, 128)
batch 873: ({'logprob': [40.717838287353516, 9.0]}, 128)
batch 874: ({'logprob': [45.176753997802734, 11.0]}, 128)
batch 875: ({'logprob': [50.77627182006836, 13.0]}, 128)
batch 876: ({'logprob': [63.9850959777832, 18.0]}, 128)
batch 877: ({'logprob': [45.75476837158203, 11.0]}, 128)
batch 878: ({'logprob': [62.02043533325195, 17.0]}, 128)
batch 879: ({'logprob': [73.79838562011719, 21.0]}, 128)
batch 880: ({'logprob': [50.796630859375, 13.0]}, 128)
batch 881: ({'logprob': [28.904794692993164, 5.0]}, 128)
batch 882: ({'logprob': [55.029090881347656, 14.0]}, 128)
batch 883: ({'logprob': [61.99946212768555, 17.0]}, 128)
batch 884: ({'logprob': [51.35271453857422, 13.0]}, 128)
batch 885: ({'logprob': [52.496665954589844, 13.0]}, 128)
batch 886: ({'logprob': [62.58682632446289, 17.0]}, 128)

======================Test output======================
logprob:  0.416689, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.965715e-03 [3.213435e-09] 
Layer 'conv1' biases: 2.301636e-07 [6.501478e-11] 
Layer 'conv2' weights[0]: 7.952817e-03 [2.197969e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.328684e-10] 
Layer 'conv3' weights[0]: 7.951040e-03 [2.066345e-09] 
Layer 'conv3' biases: 1.974901e-06 [1.068558e-09] 
Layer 'conv4' weights[0]: 7.983710e-03 [2.092458e-09] 
Layer 'conv4' biases: 9.999993e-01 [9.206940e-09] 
Layer 'conv5' weights[0]: 7.982524e-03 [5.831738e-08] 
Layer 'conv5' biases: 9.999949e-01 [6.290354e-08] 
Layer 'fc6' weights[0]: 7.579237e-03 [4.981358e-09] 
Layer 'fc6' biases: 9.999999e-01 [4.980950e-09] 
Layer 'fc7' weights[0]: 7.178918e-03 [1.750979e-07] 
Layer 'fc7' biases: 9.998620e-01 [1.635499e-07] 
Layer 'fc8' weights[0]: 1.313655e-03 [1.006055e-05] 
Layer 'fc8' biases: 5.052735e-02 [6.683592e-05] 
Train error last 870 batches: 0.435232
-------------------------------------------------------
Not saving because 0.416689 > 0.415685 (17.630: -0.01%)
======================================================= (12.033 sec)
21.351... logprob:  0.508599, 0.140625 (1.439 sec)
21.352... logprob:  0.363640, 0.093750 (1.442 sec)
21.353... logprob:  0.512655, 0.148438 (1.487 sec)
21.354... logprob:  0.675002, 0.203125 (1.435 sec)
21.355... logprob:  0.357482, 0.085938 (1.445 sec)
21.356... logprob:  0.479244, 0.132812 (1.481 sec)
21.357... logprob:  0.346912, 0.085938 (1.431 sec)
21.358... logprob:  0.325914, 0.070312 (1.444 sec)
21.359... logprob:  0.555285, 0.164062 (1.433 sec)
21.360... logprob:  0.444516, 0.117188 (1.429 sec)
21.361... logprob:  0.410761, 0.101562 (1.433 sec)
21.362... logprob:  0.424056, 0.117188 (1.483 sec)
21.363... logprob:  0.486584, 0.132812 (1.451 sec)
21.364... logprob:  0.475568, 0.125000 (1.451 sec)
21.365... logprob:  0.425067, 0.109375 (1.553 sec)
21.366... logprob:  0.409645, 0.109375 (1.446 sec)
21.367... logprob:  0.324964, 0.078125 (1.438 sec)
21.368... logprob:  0.595632, 0.171875 (1.431 sec)
21.369... logprob:  0.381588, 0.093750 (1.428 sec)
21.370... logprob:  0.381217, 0.093750 (1.438 sec)
21.371... logprob:  0.400378, 0.101562 (1.467 sec)
21.372... logprob:  0.537449, 0.156250 (1.461 sec)
21.373... logprob:  0.463812, 0.125000 (1.451 sec)
21.374... logprob:  0.526971, 0.148438 (1.452 sec)
21.375... logprob:  0.393776, 0.101562 (1.470 sec)
21.376... logprob:  0.374301, 0.093750 (1.438 sec)
21.377... logprob:  0.295399, 0.062500 (1.430 sec)
21.378... logprob:  0.453727, 0.125000 (1.430 sec)
21.379... logprob:  0.420240, 0.109375 (1.440 sec)
21.380... logprob:  0.605727, 0.179688 (1.439 sec)
21.381... logprob:  0.463453, 0.125000 (1.473 sec)
21.382... logprob:  0.529536, 0.148438 (1.451 sec)
21.383... logprob:  0.358625, 0.085938 (1.443 sec)
21.384... logprob:  0.521115, 0.148438 (1.479 sec)
21.385... logprob:  0.523514, 0.148438 (1.434 sec)
21.386... logprob:  0.582434, 0.171875 (1.435 sec)
21.387... logprob:  0.428613, 0.117188 (1.435 sec)
21.388... logprob:  0.521336, 0.148438 (1.436 sec)
21.389... logprob:  0.425772, 0.109375 (1.432 sec)
21.390... logprob:  0.419827, 0.109375 (1.485 sec)
21.391... logprob:  0.318292, 0.070312 (1.443 sec)
21.392... logprob:  0.439438, 0.117188 (1.437 sec)
21.393... logprob:  0.368920, 0.093750 (1.484 sec)
21.394... logprob:  0.343570, 0.078125 (1.439 sec)
21.395... logprob:  0.331691, 0.078125 (1.433 sec)
21.396... logprob:  0.252137, 0.046875 (1.436 sec)
21.397... logprob:  0.484480, 0.132812 (1.430 sec)
21.398... logprob:  0.471139, 0.125000 (1.440 sec)
21.399... logprob:  0.433505, 0.117188 (1.482 sec)
21.400... logprob:  0.538141, 0.148438 (1.441 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.64909744262695, 10.0]}, 128)
batch 872: ({'logprob': [68.79753875732422, 19.0]}, 128)
batch 873: ({'logprob': [39.644832611083984, 9.0]}, 128)
batch 874: ({'logprob': [44.73604202270508, 11.0]}, 128)
batch 875: ({'logprob': [51.042076110839844, 13.0]}, 128)
batch 876: ({'logprob': [65.96934509277344, 18.0]}, 128)
batch 877: ({'logprob': [45.35014724731445, 11.0]}, 128)
batch 878: ({'logprob': [63.7056884765625, 17.0]}, 128)
batch 879: ({'logprob': [76.9403305053711, 21.0]}, 128)
batch 880: ({'logprob': [51.06370544433594, 13.0]}, 128)
batch 881: ({'logprob': [26.372478485107422, 5.0]}, 128)
batch 882: ({'logprob': [55.749542236328125, 14.0]}, 128)
batch 883: ({'logprob': [63.68403244018555, 17.0]}, 128)
batch 884: ({'logprob': [51.662044525146484, 13.0]}, 128)
batch 885: ({'logprob': [52.88338088989258, 13.0]}, 128)
batch 886: ({'logprob': [64.31316375732422, 17.0]}, 128)

======================Test output======================
logprob:  0.421174, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.965685e-03 [5.144879e-09] 
Layer 'conv1' biases: 2.310805e-07 [1.863648e-10] 
Layer 'conv2' weights[0]: 7.952777e-03 [5.365647e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.112748e-09] 
Layer 'conv3' weights[0]: 7.950999e-03 [5.070390e-09] 
Layer 'conv3' biases: 1.981776e-06 [3.420778e-09] 
Layer 'conv4' weights[0]: 7.983680e-03 [5.357583e-09] 
Layer 'conv4' biases: 9.999993e-01 [3.081252e-08] 
Layer 'conv5' weights[0]: 7.982479e-03 [1.995247e-07] 
Layer 'conv5' biases: 9.999946e-01 [2.148571e-07] 
Layer 'fc6' weights[0]: 7.579194e-03 [1.693219e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.722802e-08] 
Layer 'fc7' weights[0]: 7.177090e-03 [4.347807e-08] 
Layer 'fc7' biases: 9.998636e-01 [1.973791e-08] 
Layer 'fc8' weights[0]: 1.374645e-03 [5.375494e-06] 
Layer 'fc8' biases: 5.105478e-02 [3.004948e-05] 
Train error last 870 batches: 0.435232
-------------------------------------------------------
Not saving because 0.421174 > 0.415685 (17.630: -0.01%)
======================================================= (12.067 sec)
21.401... logprob:  0.465975, 0.125000 (1.443 sec)
21.402... logprob:  0.474103, 0.125000 (1.484 sec)
21.403... logprob:  0.462190, 0.125000 (1.435 sec)
21.404... logprob:  0.474826, 0.125000 (1.441 sec)
21.405... logprob:  0.544014, 0.156250 (1.432 sec)
21.406... logprob:  0.357764, 0.085938 (1.435 sec)
21.407... logprob:  0.492815, 0.140625 (1.430 sec)
21.408... logprob:  0.339400, 0.078125 (1.496 sec)
21.409... logprob:  0.400772, 0.101562 (1.437 sec)
21.410... logprob:  0.581949, 0.171875 (1.454 sec)
21.411... logprob:  0.398081, 0.101562 (1.472 sec)
21.412... logprob:  0.540246, 0.156250 (1.440 sec)
21.413... logprob:  0.544687, 0.156250 (1.437 sec)
21.414... logprob:  0.466535, 0.125000 (1.434 sec)
21.415... logprob:  0.401747, 0.101562 (1.430 sec)
21.416... logprob:  0.427546, 0.109375 (1.436 sec)
21.417... logprob:  0.405442, 0.093750 (1.470 sec)
21.418... logprob:  0.380226, 0.093750 (1.447 sec)
21.419... logprob:  0.417677, 0.101562 (1.459 sec)
21.420... logprob:  0.356097, 0.085938 (1.456 sec)
21.421... logprob:  0.376571, 0.101562 (1.463 sec)
21.422... logprob:  0.522735, 0.148438 (1.434 sec)
21.423... logprob:  0.420952, 0.109375 (1.431 sec)
21.424... logprob:  0.324708, 0.078125 (1.428 sec)
21.425... logprob:  0.306252, 0.070312 (1.444 sec)
21.426... logprob:  0.449293, 0.117188 (1.443 sec)
21.427... logprob:  0.554706, 0.156250 (1.468 sec)
21.428... logprob:  0.602083, 0.171875 (1.452 sec)
21.429... logprob:  0.426304, 0.109375 (1.450 sec)
21.430... logprob:  0.299897, 0.070312 (1.475 sec)
21.431... logprob:  0.599555, 0.171875 (1.436 sec)
21.432... logprob:  0.387570, 0.093750 (1.429 sec)
21.433... logprob:  0.330039, 0.078125 (1.432 sec)
21.434... logprob:  0.529274, 0.148438 (1.439 sec)
21.435... logprob:  0.532200, 0.156250 (1.435 sec)
21.436... logprob:  0.381374, 0.093750 (1.479 sec)
21.437... logprob:  0.500254, 0.140625 (1.446 sec)
21.438... logprob:  0.546839, 0.156250 (1.439 sec)
21.439... logprob:  0.379020, 0.093750 (1.486 sec)
21.440... logprob:  0.439817, 0.117188 (1.433 sec)
21.441... logprob:  0.468018, 0.125000 (1.431 sec)
21.442... logprob:  0.378936, 0.093750 (1.439 sec)
21.443... logprob:  0.496578, 0.140625 (1.435 sec)
21.444... logprob:  0.372201, 0.093750 (1.433 sec)
21.445... logprob:  0.362310, 0.085938 (1.486 sec)
21.446... logprob:  0.398188, 0.101562 (1.441 sec)
21.447... logprob:  0.570103, 0.164062 (1.438 sec)
21.448... logprob:  0.332649, 0.078125 (1.486 sec)
21.449... logprob:  0.400024, 0.101562 (1.433 sec)
21.450... logprob:  0.239092, 0.046875 (1.437 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.0378532409668, 10.0]}, 128)
batch 872: ({'logprob': [67.66737365722656, 19.0]}, 128)
batch 873: ({'logprob': [39.79951477050781, 9.0]}, 128)
batch 874: ({'logprob': [44.773780822753906, 11.0]}, 128)
batch 875: ({'logprob': [50.73025131225586, 13.0]}, 128)
batch 876: ({'logprob': [64.95525360107422, 18.0]}, 128)
batch 877: ({'logprob': [45.272193908691406, 11.0]}, 128)
batch 878: ({'logprob': [62.69256591796875, 17.0]}, 128)
batch 879: ({'logprob': [75.11026000976562, 21.0]}, 128)
batch 880: ({'logprob': [50.751529693603516, 13.0]}, 128)
batch 881: ({'logprob': [27.345752716064453, 5.0]}, 128)
batch 882: ({'logprob': [54.96934509277344, 14.0]}, 128)
batch 883: ({'logprob': [62.671287536621094, 17.0]}, 128)
batch 884: ({'logprob': [51.231510162353516, 13.0]}, 128)
batch 885: ({'logprob': [52.219356536865234, 13.0]}, 128)
batch 886: ({'logprob': [63.182247161865234, 17.0]}, 128)

======================Test output======================
logprob:  0.417192, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.965648e-03 [4.080425e-09] 
Layer 'conv1' biases: 2.319111e-07 [1.328747e-10] 
Layer 'conv2' weights[0]: 7.952740e-03 [4.135234e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.418812e-10] 
Layer 'conv3' weights[0]: 7.950955e-03 [3.833110e-09] 
Layer 'conv3' biases: 1.988423e-06 [2.324632e-09] 
Layer 'conv4' weights[0]: 7.983640e-03 [4.027407e-09] 
Layer 'conv4' biases: 9.999993e-01 [2.056122e-08] 
Layer 'conv5' weights[0]: 7.982449e-03 [1.346467e-07] 
Layer 'conv5' biases: 9.999945e-01 [1.450184e-07] 
Layer 'fc6' weights[0]: 7.579155e-03 [1.126328e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.151654e-08] 
Layer 'fc7' weights[0]: 7.175289e-03 [3.755463e-07] 
Layer 'fc7' biases: 9.998625e-01 [3.638368e-07] 
Layer 'fc8' weights[0]: 1.341058e-03 [1.386185e-05] 
Layer 'fc8' biases: 5.124129e-02 [9.374312e-05] 
Train error last 870 batches: 0.435231
-------------------------------------------------------
Not saving because 0.417192 > 0.415685 (17.630: -0.01%)
======================================================= (12.030 sec)
21.451... logprob:  0.452883, 0.125000 (1.440 sec)
21.452... logprob:  0.456270, 0.117188 (1.438 sec)
21.453... logprob:  0.455406, 0.125000 (1.431 sec)
21.454... logprob:  0.489154, 0.132812 (1.490 sec)
21.455... logprob:  0.506117, 0.140625 (1.431 sec)
21.456... logprob:  0.468823, 0.125000 (1.456 sec)
21.457... logprob:  0.375367, 0.093750 (1.489 sec)
21.458... logprob:  0.351138, 0.085938 (1.441 sec)
21.459... logprob:  0.513780, 0.140625 (1.437 sec)
21.460... logprob:  0.274319, 0.054688 (1.432 sec)
21.461... logprob:  0.460023, 0.125000 (1.427 sec)
21.462... logprob:  0.471921, 0.125000 (1.440 sec)
21.463... logprob:  0.420906, 0.109375 (1.472 sec)
21.464... logprob:  0.482711, 0.132812 (1.445 sec)
21.465... logprob:  0.421185, 0.109375 (1.461 sec)
21.466... logprob:  0.318547, 0.070312 (1.457 sec)
21.467... logprob:  0.413860, 0.109375 (1.452 sec)
21.468... logprob:  0.394275, 0.101562 (1.442 sec)
21.469... logprob:  0.334702, 0.078125 (1.427 sec)
21.470... logprob:  0.400068, 0.101562 (1.430 sec)
21.471... logprob:  0.529501, 0.148438 (1.436 sec)
21.472... logprob:  0.410048, 0.109375 (1.455 sec)
21.473... logprob:  0.375380, 0.093750 (1.465 sec)
21.474... logprob:  0.465718, 0.125000 (1.449 sec)
21.475... logprob:  0.504267, 0.140625 (1.454 sec)
21.476... logprob:  0.510395, 0.140625 (1.468 sec)
21.477... logprob:  0.334539, 0.078125 (1.441 sec)
21.478... logprob:  0.464275, 0.125000 (1.427 sec)
21.479... logprob:  0.305780, 0.070312 (1.428 sec)
21.480... logprob:  0.443514, 0.117188 (1.438 sec)
21.481... logprob:  0.547771, 0.156250 (1.434 sec)
21.482... logprob:  0.443168, 0.117188 (1.478 sec)
21.483... logprob:  0.502614, 0.140625 (1.447 sec)
21.484... logprob:  0.485297, 0.132812 (1.441 sec)
21.485... logprob:  0.409040, 0.109375 (1.481 sec)
21.486... logprob:  0.361515, 0.085938 (1.435 sec)
21.487... logprob:  0.522637, 0.148438 (1.432 sec)
21.488... logprob:  0.424834, 0.109375 (1.440 sec)
21.489... logprob:  0.415914, 0.109375 (1.433 sec)
21.490... logprob:  0.440699, 0.117188 (1.435 sec)
21.491... logprob:  0.313685, 0.070312 (1.486 sec)
21.492... logprob:  0.459582, 0.125000 (1.440 sec)
21.493... logprob:  0.521907, 0.148438 (1.439 sec)
21.494... logprob:  0.450369, 0.125000 (1.482 sec)
21.495... logprob:  0.380594, 0.093750 (1.438 sec)
21.496... logprob:  0.550426, 0.156250 (1.432 sec)
21.497... logprob:  0.466996, 0.125000 (1.440 sec)
21.498... logprob:  0.476301, 0.132812 (1.428 sec)
21.499... logprob:  0.456262, 0.125000 (1.440 sec)
21.500... logprob:  0.355100, 0.085938 (1.486 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.02664566040039, 10.0]}, 128)
batch 872: ({'logprob': [66.30717468261719, 19.0]}, 128)
batch 873: ({'logprob': [40.933231353759766, 9.0]}, 128)
batch 874: ({'logprob': [45.44854736328125, 11.0]}, 128)
batch 875: ({'logprob': [50.88134002685547, 13.0]}, 128)
batch 876: ({'logprob': [63.83980941772461, 18.0]}, 128)
batch 877: ({'logprob': [45.91559600830078, 11.0]}, 128)
batch 878: ({'logprob': [61.791648864746094, 17.0]}, 128)
batch 879: ({'logprob': [73.12483215332031, 21.0]}, 128)
batch 880: ({'logprob': [50.90184020996094, 13.0]}, 128)
batch 881: ({'logprob': [29.566200256347656, 5.0]}, 128)
batch 882: ({'logprob': [54.7713623046875, 14.0]}, 128)
batch 883: ({'logprob': [61.77068328857422, 17.0]}, 128)
batch 884: ({'logprob': [51.345558166503906, 13.0]}, 128)
batch 885: ({'logprob': [52.266258239746094, 13.0]}, 128)
batch 886: ({'logprob': [62.24600601196289, 17.0]}, 128)

======================Test output======================
logprob:  0.416571, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.965609e-03 [2.578585e-09] 
Layer 'conv1' biases: 2.328201e-07 [4.369783e-11] 
Layer 'conv2' weights[0]: 7.952704e-03 [2.006989e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.215944e-10] 
Layer 'conv3' weights[0]: 7.950909e-03 [1.724565e-09] 
Layer 'conv3' biases: 1.997719e-06 [7.506514e-10] 
Layer 'conv4' weights[0]: 7.983600e-03 [1.906294e-09] 
Layer 'conv4' biases: 9.999993e-01 [7.083186e-09] 
Layer 'conv5' weights[0]: 7.982418e-03 [4.727510e-08] 
Layer 'conv5' biases: 9.999950e-01 [5.096858e-08] 
Layer 'fc6' weights[0]: 7.579114e-03 [4.023395e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.997260e-09] 
Layer 'fc7' weights[0]: 7.173515e-03 [3.861289e-08] 
Layer 'fc7' biases: 9.998616e-01 [1.122672e-08] 
Layer 'fc8' weights[0]: 1.292486e-03 [2.659679e-06] 
Layer 'fc8' biases: 5.107226e-02 [1.687052e-05] 
Train error last 870 batches: 0.435231
-------------------------------------------------------
Not saving because 0.416571 > 0.415685 (17.630: -0.01%)
======================================================= (12.122 sec)
21.501... logprob:  0.339112, 0.078125 (1.441 sec)
21.502... logprob:  0.459645, 0.125000 (1.455 sec)
21.503... logprob:  0.400680, 0.101562 (1.473 sec)
21.504... logprob:  0.487323, 0.132812 (1.438 sec)
21.505... logprob:  0.570802, 0.164062 (1.438 sec)
21.506... logprob:  0.479683, 0.132812 (1.435 sec)
21.507... logprob:  0.385104, 0.093750 (1.428 sec)
21.508... logprob:  0.374725, 0.093750 (1.436 sec)
21.509... logprob:  0.323147, 0.070312 (1.478 sec)
21.510... logprob:  0.390476, 0.101562 (1.444 sec)
21.511... logprob:  0.410070, 0.109375 (1.456 sec)
21.512... logprob:  0.470735, 0.125000 (1.468 sec)
21.513... logprob:  0.324972, 0.078125 (1.445 sec)
21.514... logprob:  0.406275, 0.101562 (1.439 sec)
21.515... logprob:  0.455555, 0.125000 (1.431 sec)
21.516... logprob:  0.400365, 0.109375 (1.428 sec)
21.517... logprob:  0.627947, 0.179688 (1.437 sec)
21.518... logprob:  0.437692, 0.117188 (1.464 sec)
21.519... logprob:  0.516143, 0.140625 (1.453 sec)
21.520... logprob:  0.409652, 0.109375 (1.457 sec)
21.521... logprob:  0.427491, 0.109375 (1.451 sec)
21.522... logprob:  0.533099, 0.156250 (1.466 sec)
21.523... logprob:  0.331687, 0.078125 (1.438 sec)
21.524... logprob:  0.437208, 0.117188 (1.427 sec)
21.525... logprob:  0.426029, 0.109375 (1.435 sec)
21.526... logprob:  0.351866, 0.078125 (1.438 sec)
21.527... logprob:  0.504553, 0.140625 (1.444 sec)
21.528... logprob:  0.440495, 0.117188 (1.468 sec)
21.529... logprob:  0.353009, 0.085938 (1.452 sec)
21.530... logprob:  0.440249, 0.117188 (1.440 sec)
21.531... logprob:  0.439991, 0.117188 (1.485 sec)
21.532... logprob:  0.467373, 0.125000 (1.433 sec)
21.533... logprob:  0.560586, 0.164062 (1.430 sec)
21.534... logprob:  0.325832, 0.078125 (1.433 sec)
21.535... logprob:  0.551607, 0.156250 (1.444 sec)
21.536... logprob:  0.507363, 0.140625 (1.433 sec)
21.537... logprob:  0.510057, 0.140625 (1.480 sec)
21.538... logprob:  0.486103, 0.132812 (1.448 sec)
21.539... logprob:  0.296107, 0.062500 (1.429 sec)
21.540... logprob:  0.447178, 0.117188 (1.492 sec)
21.541... logprob:  0.388860, 0.101562 (1.436 sec)
21.542... logprob:  0.411291, 0.109375 (1.428 sec)
21.543... logprob:  0.233339, 0.039062 (1.438 sec)
21.544... logprob:  0.317939, 0.070312 (1.435 sec)
21.545... logprob:  0.348807, 0.085938 (1.433 sec)
21.546... logprob:  0.368283, 0.093750 (1.489 sec)
21.547... logprob:  0.440104, 0.117188 (1.437 sec)
21.548... logprob:  0.453095, 0.125000 (1.440 sec)
21.549... logprob:  0.490632, 0.132812 (1.485 sec)
21.550... logprob:  0.367666, 0.093750 (1.430 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.84913635253906, 10.0]}, 128)
batch 872: ({'logprob': [68.40924835205078, 19.0]}, 128)
batch 873: ({'logprob': [39.57244873046875, 9.0]}, 128)
batch 874: ({'logprob': [44.71823501586914, 11.0]}, 128)
batch 875: ({'logprob': [50.8827018737793, 13.0]}, 128)
batch 876: ({'logprob': [65.6028823852539, 18.0]}, 128)
batch 877: ({'logprob': [45.2347412109375, 11.0]}, 128)
batch 878: ({'logprob': [63.263309478759766, 17.0]}, 128)
batch 879: ({'logprob': [76.11744689941406, 21.0]}, 128)
batch 880: ({'logprob': [50.9045295715332, 13.0]}, 128)
batch 881: ({'logprob': [26.68151092529297, 5.0]}, 128)
batch 882: ({'logprob': [55.27433776855469, 14.0]}, 128)
batch 883: ({'logprob': [63.24146270751953, 17.0]}, 128)
batch 884: ({'logprob': [51.404361724853516, 13.0]}, 128)
batch 885: ({'logprob': [52.42985916137695, 13.0]}, 128)
batch 886: ({'logprob': [63.772586822509766, 17.0]}, 128)

======================Test output======================
logprob:  0.419121, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.965559e-03 [3.538799e-09] 
Layer 'conv1' biases: 2.335805e-07 [7.979981e-11] 
Layer 'conv2' weights[0]: 7.952662e-03 [3.338361e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.315990e-10] 
Layer 'conv3' weights[0]: 7.950869e-03 [2.828819e-09] 
Layer 'conv3' biases: 2.004876e-06 [1.675799e-09] 
Layer 'conv4' weights[0]: 7.983558e-03 [2.980480e-09] 
Layer 'conv4' biases: 9.999993e-01 [1.389256e-08] 
Layer 'conv5' weights[0]: 7.982371e-03 [8.584192e-08] 
Layer 'conv5' biases: 9.999945e-01 [9.271052e-08] 
Layer 'fc6' weights[0]: 7.579072e-03 [7.297661e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.416985e-09] 
Layer 'fc7' weights[0]: 7.171641e-03 [4.950116e-08] 
Layer 'fc7' biases: 9.998631e-01 [2.799246e-08] 
Layer 'fc8' weights[0]: 1.355818e-03 [7.316935e-06] 
Layer 'fc8' biases: 5.159789e-02 [4.212125e-05] 
Train error last 870 batches: 0.435230
-------------------------------------------------------
Not saving because 0.419121 > 0.415685 (17.630: -0.01%)
======================================================= (12.093 sec)
21.551... logprob:  0.441746, 0.117188 (1.448 sec)
21.552... logprob:  0.471313, 0.125000 (1.446 sec)
21.553... logprob:  0.349440, 0.085938 (1.435 sec)
21.554... logprob:  0.506887, 0.140625 (1.448 sec)
21.555... logprob:  0.421411, 0.109375 (1.487 sec)
21.556... logprob:  0.355886, 0.085938 (1.445 sec)
21.557... logprob:  0.396447, 0.101562 (1.454 sec)
21.558... logprob:  0.383045, 0.101562 (1.476 sec)
21.559... logprob:  0.441498, 0.125000 (1.433 sec)
21.560... logprob:  0.335251, 0.078125 (1.440 sec)
21.561... logprob:  0.411827, 0.109375 (1.436 sec)
21.562... logprob:  0.503126, 0.140625 (1.428 sec)
21.563... logprob:  0.373833, 0.093750 (1.435 sec)
21.564... logprob:  0.468441, 0.132812 (1.464 sec)
21.565... logprob:  0.611066, 0.187500 (1.450 sec)
21.566... logprob:  0.374904, 0.093750 (1.454 sec)
21.567... logprob:  0.423403, 0.109375 (1.470 sec)
21.568... logprob:  0.496362, 0.140625 (1.455 sec)
21.569... logprob:  0.507806, 0.140625 (1.440 sec)
21.570... logprob:  0.543743, 0.164062 (1.427 sec)
21.571... logprob:  0.454877, 0.125000 (1.434 sec)
21.572... logprob:  0.501448, 0.140625 (1.438 sec)
21.573... logprob:  0.512618, 0.148438 (1.452 sec)
21.574... logprob:  0.428115, 0.109375 (1.460 sec)
21.575... logprob:  0.343348, 0.078125 (1.457 sec)
21.576... logprob:  0.427393, 0.109375 (1.444 sec)
21.577... logprob:  0.460826, 0.125000 (1.482 sec)
21.578... logprob:  0.336636, 0.078125 (1.432 sec)
21.579... logprob:  0.442085, 0.117188 (1.431 sec)
21.580... logprob:  0.546863, 0.156250 (1.432 sec)
21.581... logprob:  0.530901, 0.156250 (1.443 sec)
21.582... logprob:  0.437870, 0.125000 (1.438 sec)
21.583... logprob:  0.592740, 0.171875 (1.472 sec)
21.584... logprob:  0.468112, 0.132812 (1.451 sec)
21.585... logprob:  0.349763, 0.085938 (1.430 sec)
21.586... logprob:  0.313127, 0.070312 (1.499 sec)
21.587... logprob:  0.404309, 0.101562 (1.435 sec)
21.588... logprob:  0.418667, 0.117188 (1.431 sec)
21.589... logprob:  0.361257, 0.093750 (1.438 sec)
21.590... logprob:  0.524721, 0.148438 (1.438 sec)
21.591... logprob:  0.397499, 0.101562 (1.432 sec)
21.592... logprob:  0.455654, 0.125000 (1.486 sec)
21.593... logprob:  0.467430, 0.125000 (1.436 sec)
21.594... logprob:  0.352862, 0.085938 (1.443 sec)
21.595... logprob:  0.428666, 0.109375 (1.484 sec)
21.596... logprob:  0.461590, 0.125000 (1.432 sec)
21.597... logprob:  0.397413, 0.101562 (1.435 sec)
21.598... logprob:  0.397226, 0.101562 (1.435 sec)
21.599... logprob:  0.313531, 0.070312 (1.433 sec)
21.600... logprob:  0.340894, 0.085938 (1.437 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.992576599121094, 10.0]}, 128)
batch 872: ({'logprob': [66.87271881103516, 19.0]}, 128)
batch 873: ({'logprob': [40.528079986572266, 9.0]}, 128)
batch 874: ({'logprob': [44.956787109375, 11.0]}, 128)
batch 875: ({'logprob': [50.77040481567383, 13.0]}, 128)
batch 876: ({'logprob': [64.33226776123047, 18.0]}, 128)
batch 877: ({'logprob': [45.656578063964844, 11.0]}, 128)
batch 878: ({'logprob': [62.443626403808594, 17.0]}, 128)
batch 879: ({'logprob': [74.77215576171875, 21.0]}, 128)
batch 880: ({'logprob': [50.79072952270508, 13.0]}, 128)
batch 881: ({'logprob': [28.163467407226562, 5.0]}, 128)
batch 882: ({'logprob': [55.43709945678711, 14.0]}, 128)
batch 883: ({'logprob': [62.42246627807617, 17.0]}, 128)
batch 884: ({'logprob': [51.470516204833984, 13.0]}, 128)
batch 885: ({'logprob': [52.85931396484375, 13.0]}, 128)
batch 886: ({'logprob': [63.13300704956055, 17.0]}, 128)

======================Test output======================
logprob:  0.417774, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.965511e-03 [2.862130e-09] 
Layer 'conv1' biases: 2.345988e-07 [9.670714e-11] 
Layer 'conv2' weights[0]: 7.952633e-03 [2.551307e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.993997e-10] 
Layer 'conv3' weights[0]: 7.950834e-03 [2.530865e-09] 
Layer 'conv3' biases: 2.012742e-06 [1.557913e-09] 
Layer 'conv4' weights[0]: 7.983513e-03 [2.668977e-09] 
Layer 'conv4' biases: 9.999992e-01 [1.404115e-08] 
Layer 'conv5' weights[0]: 7.982338e-03 [9.211419e-08] 
Layer 'conv5' biases: 9.999946e-01 [9.932133e-08] 
Layer 'fc6' weights[0]: 7.579032e-03 [7.767763e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.884187e-09] 
Layer 'fc7' weights[0]: 7.169827e-03 [1.576636e-07] 
Layer 'fc7' biases: 9.998623e-01 [1.459214e-07] 
Layer 'fc8' weights[0]: 1.322650e-03 [7.158513e-06] 
Layer 'fc8' biases: 5.149157e-02 [4.579579e-05] 
Train error last 870 batches: 0.435230
-------------------------------------------------------
Not saving because 0.417774 > 0.415685 (17.630: -0.01%)
======================================================= (12.037 sec)
21.601... logprob:  0.402131, 0.101562 (1.500 sec)
21.602... logprob:  0.289746, 0.062500 (1.439 sec)
21.603... logprob:  0.267014, 0.054688 (1.451 sec)
21.604... logprob:  0.407516, 0.101562 (1.480 sec)
21.605... logprob:  0.563497, 0.148438 (1.432 sec)
21.606... logprob:  0.295944, 0.070312 (1.443 sec)
21.607... logprob:  0.504852, 0.132812 (1.433 sec)
21.608... logprob:  0.361735, 0.085938 (1.429 sec)
21.609... logprob:  0.356957, 0.085938 (1.434 sec)
21.610... logprob:  0.493391, 0.132812 (1.477 sec)
21.611... logprob:  0.510412, 0.140625 (1.442 sec)
21.612... logprob:  0.448432, 0.117188 (1.460 sec)
21.613... logprob:  0.279658, 0.062500 (1.457 sec)
21.614... logprob:  0.503536, 0.140625 (1.446 sec)
21.615... logprob:  0.351062, 0.085938 (1.442 sec)
21.616... logprob:  0.415258, 0.109375 (1.428 sec)
21.617... logprob:  0.417929, 0.109375 (1.433 sec)
21.618... logprob:  0.546793, 0.156250 (1.438 sec)
21.619... logprob:  0.505992, 0.140625 (1.453 sec)
21.620... logprob:  0.539644, 0.156250 (1.458 sec)
21.621... logprob:  0.363820, 0.085938 (1.459 sec)
21.622... logprob:  0.364864, 0.085938 (1.448 sec)
21.623... logprob:  0.423192, 0.109375 (1.470 sec)
21.624... logprob:  0.382544, 0.093750 (1.442 sec)
21.625... logprob:  0.440997, 0.117188 (1.425 sec)
21.626... logprob:  0.438380, 0.117188 (1.429 sec)
21.627... logprob:  0.435851, 0.117188 (1.443 sec)
21.628... logprob:  0.465071, 0.125000 (1.437 sec)
21.629... logprob:  0.372039, 0.093750 (1.477 sec)
21.630... logprob:  0.422375, 0.109375 (1.446 sec)
21.631... logprob:  0.639064, 0.187500 (1.442 sec)
21.632... logprob:  0.399105, 0.101562 (1.486 sec)
21.633... logprob:  0.376048, 0.093750 (1.431 sec)
21.634... logprob:  0.660354, 0.195312 (1.432 sec)
21.635... logprob:  0.374119, 0.093750 (1.437 sec)
21.636... logprob:  0.480242, 0.132812 (1.439 sec)
21.637... logprob:  0.330881, 0.078125 (1.430 sec)
21.638... logprob:  0.515683, 0.140625 (1.482 sec)
21.639... logprob:  0.418115, 0.109375 (1.443 sec)
21.640... logprob:  0.528749, 0.148438 (1.437 sec)
21.641... logprob:  0.410463, 0.109375 (1.489 sec)
21.642... logprob:  0.500841, 0.140625 (1.432 sec)
21.643... logprob:  0.622969, 0.187500 (1.436 sec)
21.644... logprob:  0.321274, 0.070312 (1.436 sec)
21.645... logprob:  0.414492, 0.109375 (1.434 sec)
21.646... logprob:  0.385703, 0.093750 (1.433 sec)
21.647... logprob:  0.456763, 0.125000 (1.490 sec)
21.648... logprob:  0.491239, 0.140625 (1.432 sec)
21.649... logprob:  0.370174, 0.093750 (1.449 sec)
21.650... logprob:  0.413963, 0.109375 (1.475 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.9693489074707, 10.0]}, 128)
batch 872: ({'logprob': [66.34504699707031, 19.0]}, 128)
batch 873: ({'logprob': [40.87167739868164, 9.0]}, 128)
batch 874: ({'logprob': [45.40471267700195, 11.0]}, 128)
batch 875: ({'logprob': [50.85859680175781, 13.0]}, 128)
batch 876: ({'logprob': [63.86827087402344, 18.0]}, 128)
batch 877: ({'logprob': [45.87355041503906, 11.0]}, 128)
batch 878: ({'logprob': [61.811912536621094, 17.0]}, 128)
batch 879: ({'logprob': [73.1894760131836, 21.0]}, 128)
batch 880: ({'logprob': [50.87932205200195, 13.0]}, 128)
batch 881: ({'logprob': [29.4599609375, 5.0]}, 128)
batch 882: ({'logprob': [54.76411437988281, 14.0]}, 128)
batch 883: ({'logprob': [61.79060363769531, 17.0]}, 128)
batch 884: ({'logprob': [51.32493209838867, 13.0]}, 128)
batch 885: ({'logprob': [52.249141693115234, 13.0]}, 128)
batch 886: ({'logprob': [62.26811981201172, 17.0]}, 128)

======================Test output======================
logprob:  0.416469, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.965472e-03 [2.353826e-09] 
Layer 'conv1' biases: 2.354678e-07 [6.504434e-11] 
Layer 'conv2' weights[0]: 7.952592e-03 [1.959988e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.785600e-10] 
Layer 'conv3' weights[0]: 7.950801e-03 [1.957637e-09] 
Layer 'conv3' biases: 2.020310e-06 [1.153570e-09] 
Layer 'conv4' weights[0]: 7.983473e-03 [2.198924e-09] 
Layer 'conv4' biases: 9.999992e-01 [1.159084e-08] 
Layer 'conv5' weights[0]: 7.982300e-03 [7.760617e-08] 
Layer 'conv5' biases: 9.999947e-01 [8.393556e-08] 
Layer 'fc6' weights[0]: 7.578990e-03 [6.452700e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.562123e-09] 
Layer 'fc7' weights[0]: 7.168035e-03 [2.372688e-07] 
Layer 'fc7' biases: 9.998614e-01 [2.254535e-07] 
Layer 'fc8' weights[0]: 1.297588e-03 [1.045933e-05] 
Layer 'fc8' biases: 5.148073e-02 [7.119666e-05] 
Train error last 870 batches: 0.435230
-------------------------------------------------------
Not saving because 0.416469 > 0.415685 (17.630: -0.01%)
======================================================= (12.048 sec)
21.651... logprob:  0.397335, 0.101562 (1.438 sec)
21.652... logprob:  0.507298, 0.140625 (1.439 sec)
21.653... logprob:  0.548005, 0.156250 (1.435 sec)
21.654... logprob:  0.496101, 0.140625 (1.432 sec)
21.655... logprob:  0.436198, 0.117188 (1.431 sec)
21.656... logprob:  0.416686, 0.109375 (1.484 sec)
21.657... logprob:  0.449205, 0.117188 (1.442 sec)
21.658... logprob:  0.345796, 0.085938 (1.452 sec)
21.659... logprob:  0.464333, 0.125000 (1.468 sec)
21.660... logprob:  0.445946, 0.125000 (1.443 sec)
21.661... logprob:  0.378501, 0.093750 (1.459 sec)
21.662... logprob:  0.469375, 0.132812 (1.430 sec)
21.663... logprob:  0.310985, 0.070312 (1.432 sec)
21.664... logprob:  0.285455, 0.062500 (1.437 sec)
21.665... logprob:  0.401796, 0.101562 (1.462 sec)
21.666... logprob:  0.442053, 0.117188 (1.453 sec)
21.667... logprob:  0.564274, 0.164062 (1.458 sec)
21.668... logprob:  0.497888, 0.140625 (1.452 sec)
21.669... logprob:  0.433040, 0.109375 (1.468 sec)
21.670... logprob:  0.362447, 0.085938 (1.432 sec)
21.671... logprob:  0.360858, 0.093750 (1.425 sec)
21.672... logprob:  0.441818, 0.117188 (1.428 sec)
21.673... logprob:  0.436237, 0.117188 (1.444 sec)
21.674... logprob:  0.446655, 0.117188 (1.439 sec)
21.675... logprob:  0.356671, 0.093750 (1.473 sec)
21.676... logprob:  0.450159, 0.125000 (1.449 sec)
21.677... logprob:  0.471045, 0.125000 (1.445 sec)
21.678... logprob:  0.465649, 0.125000 (1.481 sec)
21.679... logprob:  0.454868, 0.125000 (1.436 sec)
21.680... logprob:  0.351712, 0.078125 (1.424 sec)
21.681... logprob:  0.373915, 0.093750 (1.439 sec)
21.682... logprob:  0.340490, 0.078125 (1.439 sec)
21.683... logprob:  0.411642, 0.109375 (1.435 sec)
21.684... logprob:  0.357632, 0.085938 (1.477 sec)
21.685... logprob:  0.285969, 0.054688 (1.449 sec)
21.686... logprob:  0.318611, 0.070312 (1.430 sec)
21.687... logprob:  0.281602, 0.062500 (1.491 sec)
21.688... logprob:  0.323100, 0.078125 (1.435 sec)
21.689... logprob:  0.471353, 0.125000 (1.432 sec)
21.690... logprob:  0.527882, 0.140625 (1.435 sec)
21.691... logprob:  0.516804, 0.140625 (1.437 sec)
21.692... logprob:  0.385156, 0.101562 (1.434 sec)
21.693... logprob:  0.455874, 0.125000 (1.485 sec)
21.694... logprob:  0.330908, 0.078125 (1.438 sec)
21.695... logprob:  0.356907, 0.085938 (1.441 sec)
21.696... logprob:  0.538937, 0.148438 (1.491 sec)
21.697... logprob:  0.465642, 0.125000 (1.434 sec)
21.698... logprob:  0.548689, 0.156250 (1.435 sec)
21.699... logprob:  0.459597, 0.125000 (1.438 sec)
21.700... logprob:  0.433967, 0.117188 (1.433 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.04978942871094, 10.0]}, 128)
batch 872: ({'logprob': [65.9328842163086, 19.0]}, 128)
batch 873: ({'logprob': [42.00480651855469, 9.0]}, 128)
batch 874: ({'logprob': [46.26765823364258, 11.0]}, 128)
batch 875: ({'logprob': [51.38765335083008, 13.0]}, 128)
batch 876: ({'logprob': [63.60649871826172, 18.0]}, 128)
batch 877: ({'logprob': [46.705299377441406, 11.0]}, 128)
batch 878: ({'logprob': [61.66984176635742, 17.0]}, 128)
batch 879: ({'logprob': [72.3442153930664, 21.0]}, 128)
batch 880: ({'logprob': [51.40778350830078, 13.0]}, 128)
batch 881: ({'logprob': [31.29755210876465, 5.0]}, 128)
batch 882: ({'logprob': [55.041866302490234, 14.0]}, 128)
batch 883: ({'logprob': [61.64888000488281, 17.0]}, 128)
batch 884: ({'logprob': [51.81855010986328, 13.0]}, 128)
batch 885: ({'logprob': [52.67715072631836, 13.0]}, 128)
batch 886: ({'logprob': [62.091896057128906, 17.0]}, 128)

======================Test output======================
logprob:  0.419410, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.965436e-03 [2.988318e-09] 
Layer 'conv1' biases: 2.363637e-07 [5.061700e-11] 
Layer 'conv2' weights[0]: 7.952551e-03 [1.807032e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.855581e-10] 
Layer 'conv3' weights[0]: 7.950762e-03 [1.402613e-09] 
Layer 'conv3' biases: 2.029647e-06 [6.354917e-10] 
Layer 'conv4' weights[0]: 7.983431e-03 [1.324524e-09] 
Layer 'conv4' biases: 9.999993e-01 [3.557249e-09] 
Layer 'conv5' weights[0]: 7.982274e-03 [1.964700e-08] 
Layer 'conv5' biases: 9.999957e-01 [2.101458e-08] 
Layer 'fc6' weights[0]: 7.578955e-03 [1.853869e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.695564e-09] 
Layer 'fc7' weights[0]: 7.166206e-03 [3.657938e-07] 
Layer 'fc7' biases: 9.998604e-01 [3.555025e-07] 
Layer 'fc8' weights[0]: 1.271161e-03 [1.358390e-05] 
Layer 'fc8' biases: 5.142669e-02 [8.299485e-05] 
Train error last 870 batches: 0.435230
-------------------------------------------------------
Not saving because 0.419410 > 0.415685 (17.630: -0.01%)
======================================================= (12.062 sec)
21.701... logprob:  0.423214, 0.109375 (1.442 sec)
21.702... logprob:  0.521486, 0.148438 (1.493 sec)
21.703... logprob:  0.405349, 0.101562 (1.435 sec)
21.704... logprob:  0.406210, 0.101562 (1.449 sec)
21.705... logprob:  0.420243, 0.109375 (1.479 sec)
21.706... logprob:  0.468072, 0.125000 (1.435 sec)
21.707... logprob:  0.485300, 0.132812 (1.443 sec)
21.708... logprob:  0.417106, 0.109375 (1.431 sec)
21.709... logprob:  0.422512, 0.109375 (1.432 sec)
21.710... logprob:  0.602545, 0.179688 (1.442 sec)
21.711... logprob:  0.469504, 0.125000 (1.469 sec)
21.712... logprob:  0.340537, 0.078125 (1.449 sec)
21.713... logprob:  0.587044, 0.179688 (1.455 sec)
21.714... logprob:  0.466302, 0.125000 (1.458 sec)
21.715... logprob:  0.417154, 0.109375 (1.452 sec)
21.716... logprob:  0.335322, 0.078125 (1.436 sec)
21.717... logprob:  0.429814, 0.117188 (1.435 sec)
21.718... logprob:  0.490360, 0.132812 (1.430 sec)
21.719... logprob:  0.406193, 0.109375 (1.445 sec)
21.720... logprob:  0.433234, 0.117188 (1.452 sec)
21.721... logprob:  0.451602, 0.117188 (1.462 sec)
21.722... logprob:  0.536904, 0.156250 (1.457 sec)
21.723... logprob:  0.416581, 0.109375 (1.457 sec)
21.724... logprob:  0.412772, 0.109375 (1.474 sec)
21.725... logprob:  0.494721, 0.140625 (1.434 sec)
21.726... logprob:  0.338589, 0.085938 (1.424 sec)
21.727... logprob:  0.393316, 0.101562 (1.433 sec)
21.728... logprob:  0.421312, 0.109375 (1.437 sec)
21.729... logprob:  0.387727, 0.093750 (1.437 sec)
21.730... logprob:  0.565856, 0.164062 (1.472 sec)
21.731... logprob:  0.450354, 0.125000 (1.450 sec)
21.732... logprob:  0.311458, 0.070312 (1.438 sec)
21.733... logprob:  0.556622, 0.156250 (1.489 sec)
21.734... logprob:  0.340241, 0.078125 (1.432 sec)
21.735... logprob:  0.527552, 0.148438 (1.451 sec)
21.736... logprob:  0.642874, 0.187500 (1.435 sec)
21.737... logprob:  0.516166, 0.148438 (1.434 sec)
21.738... logprob:  0.459415, 0.125000 (1.435 sec)
21.739... logprob:  0.477805, 0.132812 (1.484 sec)
21.740... logprob:  0.339653, 0.078125 (1.436 sec)
21.741... logprob:  0.393455, 0.101562 (1.436 sec)
21.742... logprob:  0.419720, 0.109375 (1.482 sec)
21.743... logprob:  0.364875, 0.085938 (1.433 sec)
21.744... logprob:  0.519213, 0.148438 (1.441 sec)
21.745... logprob:  0.478162, 0.132812 (1.432 sec)
21.746... logprob:  0.440553, 0.117188 (1.435 sec)
21.747... logprob:  0.425617, 0.109375 (1.437 sec)
21.748... logprob:  0.378081, 0.093750 (1.485 sec)
21.749... logprob:  0.420830, 0.109375 (1.433 sec)
21.750... logprob:  0.512869, 0.140625 (1.445 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.458892822265625, 10.0]}, 128)
batch 872: ({'logprob': [66.6988296508789, 19.0]}, 128)
batch 873: ({'logprob': [40.451759338378906, 9.0]}, 128)
batch 874: ({'logprob': [45.07473373413086, 11.0]}, 128)
batch 875: ({'logprob': [50.72607421875, 13.0]}, 128)
batch 876: ({'logprob': [64.15058898925781, 18.0]}, 128)
batch 877: ({'logprob': [45.59686279296875, 11.0]}, 128)
batch 878: ({'logprob': [62.07563400268555, 17.0]}, 128)
batch 879: ({'logprob': [73.90293884277344, 21.0]}, 128)
batch 880: ({'logprob': [50.746910095214844, 13.0]}, 128)
batch 881: ({'logprob': [28.589191436767578, 5.0]}, 128)
batch 882: ({'logprob': [54.866580963134766, 14.0]}, 128)
batch 883: ({'logprob': [62.05422592163086, 17.0]}, 128)
batch 884: ({'logprob': [51.247711181640625, 13.0]}, 128)
batch 885: ({'logprob': [52.28009033203125, 13.0]}, 128)
batch 886: ({'logprob': [62.58655548095703, 17.0]}, 128)

======================Test output======================
logprob:  0.416263, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.965396e-03 [3.530632e-09] 
Layer 'conv1' biases: 2.371628e-07 [8.347667e-11] 
Layer 'conv2' weights[0]: 7.952512e-03 [2.335715e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.748156e-10] 
Layer 'conv3' weights[0]: 7.950726e-03 [1.939775e-09] 
Layer 'conv3' biases: 2.034832e-06 [1.132314e-09] 
Layer 'conv4' weights[0]: 7.983399e-03 [2.014245e-09] 
Layer 'conv4' biases: 9.999992e-01 [8.845138e-09] 
Layer 'conv5' weights[0]: 7.982221e-03 [5.902057e-08] 
Layer 'conv5' biases: 9.999947e-01 [6.373377e-08] 
Layer 'fc6' weights[0]: 7.578914e-03 [5.007514e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.012565e-09] 
Layer 'fc7' weights[0]: 7.164356e-03 [7.217110e-08] 
Layer 'fc7' biases: 9.998618e-01 [5.528202e-08] 
Layer 'fc8' weights[0]: 1.315666e-03 [6.772410e-06] 
Layer 'fc8' biases: 5.189996e-02 [4.526239e-05] 
Train error last 870 batches: 0.435229
-------------------------------------------------------
Not saving because 0.416263 > 0.415685 (17.630: -0.01%)
======================================================= (12.047 sec)
21.751... logprob:  0.263591, 0.054688 (1.482 sec)
21.752... logprob:  0.522514, 0.140625 (1.443 sec)
21.753... logprob:  0.441216, 0.117188 (1.432 sec)
21.754... logprob:  0.468474, 0.132812 (1.428 sec)
21.755... logprob:  0.507091, 0.140625 (1.432 sec)
21.756... logprob:  0.440826, 0.117188 (1.435 sec)
21.757... logprob:  0.552351, 0.156250 (1.473 sec)
21.758... logprob:  0.393657, 0.101562 (1.446 sec)
21.759... logprob:  0.459693, 0.125000 (1.459 sec)
21.760... logprob:  0.485463, 0.132812 (1.461 sec)
21.761... logprob:  0.418308, 0.109375 (1.447 sec)
21.762... logprob:  0.516011, 0.148438 (1.444 sec)
21.763... logprob:  0.558855, 0.164062 (1.427 sec)
21.764... logprob:  0.503281, 0.140625 (1.431 sec)
21.765... logprob:  0.312070, 0.062500 (1.439 sec)
21.766... logprob:  0.482265, 0.132812 (1.457 sec)
21.767... logprob:  0.371141, 0.085938 (1.460 sec)
21.768... logprob:  0.432689, 0.117188 (1.492 sec)
21.769... logprob:  0.490863, 0.140625 (1.475 sec)
21.770... logprob:  0.402880, 0.101562 (1.484 sec)
21.771... logprob:  0.549570, 0.156250 (1.454 sec)
21.772... logprob:  0.414057, 0.109375 (1.443 sec)
21.773... logprob:  0.557981, 0.164062 (1.446 sec)
21.774... logprob:  0.361621, 0.085938 (1.464 sec)
21.775... logprob:  0.407346, 0.101562 (1.461 sec)
21.776... logprob:  0.433208, 0.117188 (1.484 sec)
21.777... logprob:  0.379939, 0.093750 (1.474 sec)
21.778... logprob:  0.433594, 0.117188 (1.464 sec)
21.779... logprob:  0.505424, 0.140625 (1.492 sec)
21.780... logprob:  0.385759, 0.101562 (1.453 sec)
21.781... logprob:  0.369688, 0.085938 (1.453 sec)
21.782... logprob:  0.351468, 0.085938 (1.444 sec)
21.783... logprob:  0.555493, 0.156250 (1.465 sec)
21.784... logprob:  0.440956, 0.117188 (1.457 sec)
21.785... logprob:  0.543595, 0.156250 (1.497 sec)
21.786... logprob:  0.477455, 0.132812 (1.472 sec)
21.787... logprob:  0.546298, 0.156250 (1.461 sec)
21.788... logprob:  0.563028, 0.164062 (1.492 sec)
21.789... logprob:  0.281172, 0.054688 (1.458 sec)
21.790... logprob:  0.408179, 0.101562 (1.452 sec)
21.791... logprob:  0.398052, 0.101562 (1.447 sec)
21.792... logprob:  0.361137, 0.085938 (1.463 sec)
21.793... logprob:  0.370213, 0.085938 (1.458 sec)
21.794... logprob:  0.387130, 0.093750 (1.487 sec)
21.795... logprob:  0.469788, 0.125000 (1.471 sec)
21.796... logprob:  0.423503, 0.109375 (1.456 sec)
21.797... logprob:  0.358770, 0.085938 (1.503 sec)
21.798... logprob:  0.393276, 0.101562 (1.452 sec)
21.799... logprob:  0.332277, 0.078125 (1.450 sec)
21.800... logprob:  0.371748, 0.093750 (1.454 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.213104248046875, 10.0]}, 128)
batch 872: ({'logprob': [68.35952758789062, 19.0]}, 128)
batch 873: ({'logprob': [39.41366195678711, 9.0]}, 128)
batch 874: ({'logprob': [44.779388427734375, 11.0]}, 128)
batch 875: ({'logprob': [50.8332633972168, 13.0]}, 128)
batch 876: ({'logprob': [65.52623748779297, 18.0]}, 128)
batch 877: ({'logprob': [45.1311149597168, 11.0]}, 128)
batch 878: ({'logprob': [62.99396514892578, 17.0]}, 128)
batch 879: ({'logprob': [75.46337890625, 21.0]}, 128)
batch 880: ({'logprob': [50.85564041137695, 13.0]}, 128)
batch 881: ({'logprob': [26.90793228149414, 5.0]}, 128)
batch 882: ({'logprob': [54.75759506225586, 14.0]}, 128)
batch 883: ({'logprob': [62.97177505493164, 17.0]}, 128)
batch 884: ({'logprob': [51.19001388549805, 13.0]}, 128)
batch 885: ({'logprob': [51.885223388671875, 13.0]}, 128)
batch 886: ({'logprob': [63.33797073364258, 17.0]}, 128)

======================Test output======================
logprob:  0.417783, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.965358e-03 [2.726430e-09] 
Layer 'conv1' biases: 2.380289e-07 [7.011948e-11] 
Layer 'conv2' weights[0]: 7.952479e-03 [1.675993e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.277513e-10] 
Layer 'conv3' weights[0]: 7.950690e-03 [1.376677e-09] 
Layer 'conv3' biases: 2.041526e-06 [5.645254e-10] 
Layer 'conv4' weights[0]: 7.983362e-03 [1.442827e-09] 
Layer 'conv4' biases: 9.999992e-01 [5.018756e-09] 
Layer 'conv5' weights[0]: 7.982173e-03 [3.326544e-08] 
Layer 'conv5' biases: 9.999945e-01 [3.591323e-08] 
Layer 'fc6' weights[0]: 7.578883e-03 [2.889269e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.837822e-09] 
Layer 'fc7' weights[0]: 7.162534e-03 [2.585487e-07] 
Layer 'fc7' biases: 9.998625e-01 [2.478824e-07] 
Layer 'fc8' weights[0]: 1.352138e-03 [1.008524e-05] 
Layer 'fc8' biases: 5.230952e-02 [6.841800e-05] 
Train error last 870 batches: 0.435229
-------------------------------------------------------
Not saving because 0.417783 > 0.415685 (17.630: -0.01%)
======================================================= (12.088 sec)
21.801... logprob:  0.450200, 0.117188 (1.481 sec)
21.802... logprob:  0.423056, 0.109375 (1.462 sec)
21.803... logprob:  0.491817, 0.132812 (1.488 sec)
21.804... logprob:  0.349971, 0.085938 (1.469 sec)
21.805... logprob:  0.452291, 0.117188 (1.455 sec)
21.806... logprob:  0.424184, 0.109375 (1.502 sec)
21.807... logprob:  0.443465, 0.117188 (1.457 sec)
21.808... logprob:  0.462352, 0.125000 (1.450 sec)
21.809... logprob:  0.589583, 0.171875 (1.455 sec)
21.810... logprob:  0.442458, 0.117188 (1.453 sec)
21.811... logprob:  0.460418, 0.125000 (1.458 sec)
21.812... logprob:  0.462387, 0.125000 (1.498 sec)
21.813... logprob:  0.485971, 0.132812 (1.458 sec)
21.814... logprob:  0.478066, 0.132812 (1.458 sec)
21.815... logprob:  0.372049, 0.085938 (1.506 sec)
21.816... logprob:  0.408827, 0.101562 (1.450 sec)
21.817... logprob:  0.426032, 0.109375 (1.459 sec)
21.818... logprob:  0.559980, 0.164062 (1.445 sec)
21.819... logprob:  0.498204, 0.140625 (1.462 sec)
21.820... logprob:  0.421596, 0.109375 (1.451 sec)
21.821... logprob:  0.406525, 0.101562 (1.498 sec)
21.822... logprob:  0.441149, 0.117188 (1.462 sec)
21.823... logprob:  0.340684, 0.078125 (1.223 sec)
21.824... logprob:  0.489883, 0.132812 (0.754 sec)
21.825... logprob:  0.287804, 0.062500 (0.682 sec)
21.826... logprob:  0.375429, 0.093750 (0.685 sec)
21.827... logprob:  0.420578, 0.109375 (0.685 sec)
21.828... logprob:  0.443472, 0.117188 (0.684 sec)
21.829... logprob:  0.504383, 0.140625 (0.682 sec)
21.830... logprob:  0.442259, 0.117188 (1.505 sec)
21.831... logprob:  0.514046, 0.140625 (1.457 sec)
21.832... logprob:  0.330849, 0.078125 (1.462 sec)
21.833... logprob:  0.488992, 0.132812 (1.498 sec)
21.834... logprob:  0.433259, 0.117188 (1.451 sec)
21.835... logprob:  0.542630, 0.148438 (1.462 sec)
21.836... logprob:  0.376251, 0.093750 (1.451 sec)
21.837... logprob:  0.314531, 0.070312 (1.449 sec)
21.838... logprob:  0.437080, 0.117188 (1.463 sec)
21.839... logprob:  0.471698, 0.125000 (1.504 sec)
21.840... logprob:  0.555346, 0.156250 (1.452 sec)
21.841... logprob:  0.396188, 0.101562 (1.465 sec)
21.842... logprob:  0.497829, 0.140625 (1.499 sec)
21.843... logprob:  0.465533, 0.125000 (1.458 sec)
21.844... logprob:  0.497632, 0.140625 (1.455 sec)
21.845... logprob:  0.486797, 0.132812 (1.454 sec)
21.846... logprob:  0.468458, 0.125000 (1.449 sec)
21.847... logprob:  0.363260, 0.085938 (1.457 sec)
21.848... logprob:  0.397093, 0.101562 (1.496 sec)
21.849... logprob:  0.360371, 0.085938 (1.463 sec)
21.850... logprob:  0.479415, 0.132812 (1.467 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.42652893066406, 10.0]}, 128)
batch 872: ({'logprob': [66.47393035888672, 19.0]}, 128)
batch 873: ({'logprob': [40.863258361816406, 9.0]}, 128)
batch 874: ({'logprob': [45.598724365234375, 11.0]}, 128)
batch 875: ({'logprob': [50.96322250366211, 13.0]}, 128)
batch 876: ({'logprob': [63.96915817260742, 18.0]}, 128)
batch 877: ({'logprob': [45.9220085144043, 11.0]}, 128)
batch 878: ({'logprob': [61.73863983154297, 17.0]}, 128)
batch 879: ({'logprob': [72.79328155517578, 21.0]}, 128)
batch 880: ({'logprob': [50.984336853027344, 13.0]}, 128)
batch 881: ({'logprob': [29.77521324157715, 5.0]}, 128)
batch 882: ({'logprob': [54.460208892822266, 14.0]}, 128)
batch 883: ({'logprob': [61.71723175048828, 17.0]}, 128)
batch 884: ({'logprob': [51.28380584716797, 13.0]}, 128)
batch 885: ({'logprob': [51.91670227050781, 13.0]}, 128)
batch 886: ({'logprob': [62.0490837097168, 17.0]}, 128)

======================Test output======================
logprob:  0.416472, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.965321e-03 [2.602258e-09] 
Layer 'conv1' biases: 2.390108e-07 [7.162599e-11] 
Layer 'conv2' weights[0]: 7.952437e-03 [2.121134e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.667985e-10] 
Layer 'conv3' weights[0]: 7.950652e-03 [2.015755e-09] 
Layer 'conv3' biases: 2.049895e-06 [1.170279e-09] 
Layer 'conv4' weights[0]: 7.983323e-03 [2.304015e-09] 
Layer 'conv4' biases: 9.999992e-01 [1.133617e-08] 
Layer 'conv5' weights[0]: 7.982145e-03 [7.576831e-08] 
Layer 'conv5' biases: 9.999948e-01 [8.175868e-08] 
Layer 'fc6' weights[0]: 7.578844e-03 [6.277422e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.379584e-09] 
Layer 'fc7' weights[0]: 7.160779e-03 [2.509675e-07] 
Layer 'fc7' biases: 9.998610e-01 [2.398787e-07] 
Layer 'fc8' weights[0]: 1.287166e-03 [8.834781e-06] 
Layer 'fc8' biases: 5.214819e-02 [6.268646e-05] 
Train error last 870 batches: 0.435229
-------------------------------------------------------
Not saving because 0.416472 > 0.415685 (17.630: -0.01%)
======================================================= (12.076 sec)
21.851... logprob:  0.440145, 0.117188 (1.503 sec)
21.852... logprob:  0.545706, 0.156250 (1.464 sec)
21.853... logprob:  0.371856, 0.093750 (1.466 sec)
21.854... logprob:  0.307132, 0.070312 (1.447 sec)
21.855... logprob:  0.484889, 0.132812 (1.449 sec)
21.856... logprob:  0.443810, 0.117188 (1.453 sec)
21.857... logprob:  0.372233, 0.093750 (1.494 sec)
21.858... logprob:  0.396246, 0.101562 (1.457 sec)
21.859... logprob:  0.307960, 0.070312 (1.475 sec)
21.860... logprob:  0.565972, 0.156250 (1.483 sec)
21.861... logprob:  0.417812, 0.109375 (1.459 sec)
21.862... logprob:  0.328897, 0.078125 (1.464 sec)
21.863... logprob:  0.399538, 0.101562 (1.445 sec)
21.864... logprob:  0.451429, 0.117188 (1.452 sec)
21.865... logprob:  0.484474, 0.132812 (1.452 sec)
21.866... logprob:  0.507606, 0.140625 (1.491 sec)
21.867... logprob:  0.502948, 0.140625 (1.467 sec)
21.868... logprob:  0.405327, 0.101562 (1.477 sec)
21.869... logprob:  0.383248, 0.093750 (1.478 sec)
21.870... logprob:  0.552049, 0.156250 (1.406 sec)
22.1... logprob:  0.380090, 0.093750 (1.410 sec)
22.2... logprob:  0.448269, 0.117188 (1.448 sec)
22.3... logprob:  0.398365, 0.101562 (1.418 sec)
22.4... logprob:  0.443331, 0.117188 (1.415 sec)
22.5... logprob:  0.443446, 0.117188 (1.436 sec)
22.6... logprob:  0.499142, 0.140625 (1.394 sec)
22.7... logprob:  0.363147, 0.085938 (1.439 sec)
22.8... logprob:  0.419131, 0.109375 (1.399 sec)
22.9... logprob:  0.358761, 0.085938 (1.400 sec)
22.10... logprob:  0.377467, 0.093750 (1.412 sec)
22.11... logprob:  0.334695, 0.078125 (1.445 sec)
22.12... logprob:  0.466426, 0.125000 (1.400 sec)
22.13... logprob:  0.442294, 0.117188 (1.425 sec)
22.14... logprob:  0.444680, 0.117188 (1.408 sec)
22.15... logprob:  0.395587, 0.101562 (1.409 sec)
22.16... logprob:  0.421421, 0.109375 (1.411 sec)
22.17... logprob:  0.516042, 0.140625 (1.395 sec)
22.18... logprob:  0.262104, 0.054688 (1.404 sec)
22.19... logprob:  0.279562, 0.062500 (1.399 sec)
22.20... logprob:  0.421374, 0.109375 (1.410 sec)
22.21... logprob:  0.443969, 0.117188 (0.889 sec)
22.22... logprob:  0.536663, 0.148438 (1.329 sec)
22.23... logprob:  0.532946, 0.148438 (1.416 sec)
22.24... logprob:  0.310648, 0.070312 (0.986 sec)
22.25... logprob:  0.356239, 0.085938 (0.960 sec)
22.26... logprob:  0.463725, 0.125000 (1.456 sec)
22.27... logprob:  0.404562, 0.101562 (1.392 sec)
22.28... logprob:  0.421861, 0.109375 (1.418 sec)
22.29... logprob:  0.396000, 0.101562 (1.430 sec)
22.30... logprob:  0.374130, 0.093750 (1.417 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.38425827026367, 10.0]}, 128)
batch 872: ({'logprob': [66.88780975341797, 19.0]}, 128)
batch 873: ({'logprob': [40.439205169677734, 9.0]}, 128)
batch 874: ({'logprob': [45.457950592041016, 11.0]}, 128)
batch 875: ({'logprob': [50.91218566894531, 13.0]}, 128)
batch 876: ({'logprob': [64.29031372070312, 18.0]}, 128)
batch 877: ({'logprob': [45.68458938598633, 11.0]}, 128)
batch 878: ({'logprob': [61.8697395324707, 17.0]}, 128)
batch 879: ({'logprob': [73.01011657714844, 21.0]}, 128)
batch 880: ({'logprob': [50.93416213989258, 13.0]}, 128)
batch 881: ({'logprob': [29.265213012695312, 5.0]}, 128)
batch 882: ({'logprob': [54.21538543701172, 14.0]}, 128)
batch 883: ({'logprob': [61.847694396972656, 17.0]}, 128)
batch 884: ({'logprob': [51.13800048828125, 13.0]}, 128)
batch 885: ({'logprob': [51.57872772216797, 13.0]}, 128)
batch 886: ({'logprob': [62.084590911865234, 17.0]}, 128)

======================Test output======================
logprob:  0.416016, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.965278e-03 [2.429547e-09] 
Layer 'conv1' biases: 2.399362e-07 [6.952172e-11] 
Layer 'conv2' weights[0]: 7.952397e-03 [2.353458e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.731122e-10] 
Layer 'conv3' weights[0]: 7.950616e-03 [2.198311e-09] 
Layer 'conv3' biases: 2.058496e-06 [1.141338e-09] 
Layer 'conv4' weights[0]: 7.983284e-03 [2.417882e-09] 
Layer 'conv4' biases: 9.999992e-01 [1.090786e-08] 
Layer 'conv5' weights[0]: 7.982117e-03 [7.263898e-08] 
Layer 'conv5' biases: 9.999949e-01 [7.838781e-08] 
Layer 'fc6' weights[0]: 7.578805e-03 [6.055758e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.145156e-09] 
Layer 'fc7' weights[0]: 7.158948e-03 [4.615426e-08] 
Layer 'fc7' biases: 9.998612e-01 [2.436155e-08] 
Layer 'fc8' weights[0]: 1.294950e-03 [1.455911e-06] 
Layer 'fc8' biases: 5.235101e-02 [1.037739e-05] 
Train error last 870 batches: 0.435229
-------------------------------------------------------
Not saving because 0.416016 > 0.415685 (17.630: -0.01%)
======================================================= (12.104 sec)
22.31... logprob:  0.479932, 0.132812 (1.411 sec)
22.32... logprob:  0.457228, 0.125000 (1.398 sec)
22.33... logprob:  0.460677, 0.125000 (1.456 sec)
22.34... logprob:  0.464580, 0.125000 (1.388 sec)
22.35... logprob:  0.316256, 0.070312 (1.408 sec)
22.36... logprob:  0.475796, 0.132812 (1.410 sec)
22.37... logprob:  0.417593, 0.109375 (1.412 sec)
22.38... logprob:  0.392592, 0.101562 (1.398 sec)
22.39... logprob:  0.631693, 0.187500 (1.436 sec)
22.40... logprob:  0.445764, 0.117188 (1.411 sec)
22.41... logprob:  0.352866, 0.085938 (1.430 sec)
22.42... logprob:  0.391919, 0.101562 (1.449 sec)
22.43... logprob:  0.440098, 0.117188 (1.410 sec)
22.44... logprob:  0.518535, 0.148438 (1.439 sec)
22.45... logprob:  0.381752, 0.093750 (1.398 sec)
22.46... logprob:  0.486280, 0.132812 (1.398 sec)
22.47... logprob:  0.331738, 0.078125 (1.399 sec)
22.48... logprob:  0.498905, 0.140625 (1.429 sec)
22.49... logprob:  0.510757, 0.148438 (1.416 sec)
22.50... logprob:  0.393214, 0.101562 (1.426 sec)
22.51... logprob:  0.490130, 0.140625 (1.420 sec)
22.52... logprob:  0.525784, 0.148438 (1.399 sec)
22.53... logprob:  0.294926, 0.062500 (1.447 sec)
22.54... logprob:  0.403321, 0.109375 (1.391 sec)
22.55... logprob:  0.331747, 0.078125 (1.400 sec)
22.56... logprob:  0.421666, 0.109375 (1.402 sec)
22.57... logprob:  0.572443, 0.164062 (1.429 sec)
22.58... logprob:  0.407662, 0.101562 (1.406 sec)
22.59... logprob:  0.333863, 0.078125 (1.468 sec)
22.60... logprob:  0.618884, 0.179688 (1.427 sec)
22.61... logprob:  0.382836, 0.093750 (1.433 sec)
22.62... logprob:  0.474871, 0.132812 (1.461 sec)
22.63... logprob:  0.397300, 0.101562 (1.445 sec)
22.64... logprob:  0.450295, 0.125000 (1.412 sec)
22.65... logprob:  0.373349, 0.093750 (1.401 sec)
22.66... logprob:  0.354023, 0.085938 (1.447 sec)
22.67... logprob:  0.295403, 0.062500 (1.390 sec)
22.68... logprob:  0.396808, 0.101562 (1.394 sec)
22.69... logprob:  0.496753, 0.140625 (1.425 sec)
22.70... logprob:  0.325887, 0.078125 (1.438 sec)
22.71... logprob:  0.381818, 0.101562 (1.466 sec)
22.72... logprob:  0.493774, 0.132812 (1.405 sec)
22.73... logprob:  0.447731, 0.117188 (1.432 sec)
22.74... logprob:  0.442554, 0.117188 (1.417 sec)
22.75... logprob:  0.380648, 0.093750 (1.416 sec)
22.76... logprob:  0.412066, 0.109375 (1.440 sec)
22.77... logprob:  0.396343, 0.101562 (1.430 sec)
22.78... logprob:  0.493060, 0.140625 (1.455 sec)
22.79... logprob:  0.456456, 0.125000 (1.406 sec)
22.80... logprob:  0.507950, 0.132812 (1.418 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.66096878051758, 10.0]}, 128)
batch 872: ({'logprob': [66.32136535644531, 19.0]}, 128)
batch 873: ({'logprob': [40.91389465332031, 9.0]}, 128)
batch 874: ({'logprob': [45.30057144165039, 11.0]}, 128)
batch 875: ({'logprob': [50.83019256591797, 13.0]}, 128)
batch 876: ({'logprob': [63.862422943115234, 18.0]}, 128)
batch 877: ({'logprob': [45.880210876464844, 11.0]}, 128)
batch 878: ({'logprob': [61.93465042114258, 17.0]}, 128)
batch 879: ({'logprob': [73.57343292236328, 21.0]}, 128)
batch 880: ({'logprob': [50.8507194519043, 13.0]}, 128)
batch 881: ({'logprob': [29.239971160888672, 5.0]}, 128)
batch 882: ({'logprob': [55.050785064697266, 14.0]}, 128)
batch 883: ({'logprob': [61.91328811645508, 17.0]}, 128)
batch 884: ({'logprob': [51.40762710571289, 13.0]}, 128)
batch 885: ({'logprob': [52.55363464355469, 13.0]}, 128)
batch 886: ({'logprob': [62.50189208984375, 17.0]}, 128)

======================Test output======================
logprob:  0.416892, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.965243e-03 [3.799422e-09] 
Layer 'conv1' biases: 2.409366e-07 [9.696440e-11] 
Layer 'conv2' weights[0]: 7.952360e-03 [3.121209e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.603055e-10] 
Layer 'conv3' weights[0]: 7.950571e-03 [2.782482e-09] 
Layer 'conv3' biases: 2.066093e-06 [1.808562e-09] 
Layer 'conv4' weights[0]: 7.983247e-03 [3.086938e-09] 
Layer 'conv4' biases: 9.999992e-01 [1.670675e-08] 
Layer 'conv5' weights[0]: 7.982071e-03 [1.111110e-07] 
Layer 'conv5' biases: 9.999951e-01 [1.200296e-07] 
Layer 'fc6' weights[0]: 7.578769e-03 [9.384658e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.436325e-09] 
Layer 'fc7' weights[0]: 7.157071e-03 [2.651854e-07] 
Layer 'fc7' biases: 9.998615e-01 [2.554448e-07] 
Layer 'fc8' weights[0]: 1.299702e-03 [8.963147e-06] 
Layer 'fc8' biases: 5.239844e-02 [5.625976e-05] 
Train error last 870 batches: 0.435228
-------------------------------------------------------
Not saving because 0.416892 > 0.415685 (17.630: -0.01%)
======================================================= (12.118 sec)
22.81... logprob:  0.416725, 0.109375 (1.428 sec)
22.82... logprob:  0.231533, 0.039062 (1.434 sec)
22.83... logprob:  0.493769, 0.140625 (1.423 sec)
22.84... logprob:  0.468112, 0.125000 (1.470 sec)
22.85... logprob:  0.431979, 0.117188 (1.425 sec)
22.86... logprob:  0.416959, 0.109375 (1.421 sec)
22.87... logprob:  0.633237, 0.187500 (1.413 sec)
22.88... logprob:  0.535059, 0.156250 (1.415 sec)
22.89... logprob:  0.410591, 0.109375 (1.436 sec)
22.90... logprob:  0.577493, 0.171875 (1.390 sec)
22.91... logprob:  0.348489, 0.078125 (1.399 sec)
22.92... logprob:  0.464462, 0.125000 (1.407 sec)
22.93... logprob:  0.492245, 0.140625 (1.406 sec)
22.94... logprob:  0.428783, 0.109375 (1.390 sec)
22.95... logprob:  0.471844, 0.125000 (1.410 sec)
22.96... logprob:  0.576269, 0.171875 (1.411 sec)
22.97... logprob:  0.430771, 0.117188 (1.396 sec)
22.98... logprob:  0.391112, 0.093750 (1.435 sec)
22.99... logprob:  0.474267, 0.132812 (1.411 sec)
22.100... logprob:  0.310482, 0.070312 (1.401 sec)
22.101... logprob:  0.310709, 0.062500 (1.448 sec)
22.102... logprob:  0.546147, 0.156250 (1.389 sec)
22.103... logprob:  0.541141, 0.156250 (1.402 sec)
22.104... logprob:  0.388840, 0.101562 (1.402 sec)
22.105... logprob:  0.619556, 0.179688 (1.397 sec)
22.106... logprob:  0.344446, 0.085938 (1.394 sec)
22.107... logprob:  0.335743, 0.078125 (1.438 sec)
22.108... logprob:  0.586839, 0.171875 (1.397 sec)
22.109... logprob:  0.336165, 0.078125 (1.415 sec)
22.110... logprob:  0.564544, 0.164062 (1.393 sec)
22.111... logprob:  0.404700, 0.101562 (1.403 sec)
22.112... logprob:  0.366094, 0.093750 (1.406 sec)
22.113... logprob:  0.354556, 0.085938 (1.413 sec)
22.114... logprob:  0.440221, 0.117188 (1.430 sec)
22.115... logprob:  0.506746, 0.140625 (1.416 sec)
22.116... logprob:  0.393379, 0.101562 (1.397 sec)
22.117... logprob:  0.440393, 0.117188 (1.449 sec)
22.118... logprob:  0.409132, 0.101562 (1.388 sec)
22.119... logprob:  0.346112, 0.085938 (1.402 sec)
22.120... logprob:  0.547137, 0.156250 (1.402 sec)
22.121... logprob:  0.412636, 0.109375 (1.399 sec)
22.122... logprob:  0.519312, 0.148438 (1.444 sec)
22.123... logprob:  0.463711, 0.125000 (1.388 sec)
22.124... logprob:  0.447700, 0.125000 (1.410 sec)
22.125... logprob:  0.501962, 0.140625 (1.395 sec)
22.126... logprob:  0.475773, 0.125000 (1.400 sec)
22.127... logprob:  0.479569, 0.125000 (1.397 sec)
22.128... logprob:  0.422356, 0.109375 (1.418 sec)
22.129... logprob:  0.574891, 0.164062 (1.422 sec)
22.130... logprob:  0.382726, 0.093750 (1.423 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.0133056640625, 10.0]}, 128)
batch 872: ({'logprob': [65.92697143554688, 19.0]}, 128)
batch 873: ({'logprob': [41.989479064941406, 9.0]}, 128)
batch 874: ({'logprob': [46.2458381652832, 11.0]}, 128)
batch 875: ({'logprob': [51.3733024597168, 13.0]}, 128)
batch 876: ({'logprob': [63.60072326660156, 18.0]}, 128)
batch 877: ({'logprob': [46.69059371948242, 11.0]}, 128)
batch 878: ({'logprob': [61.671077728271484, 17.0]}, 128)
batch 879: ({'logprob': [72.36780548095703, 21.0]}, 128)
batch 880: ({'logprob': [51.393638610839844, 13.0]}, 128)
batch 881: ({'logprob': [31.259803771972656, 5.0]}, 128)
batch 882: ({'logprob': [55.04953384399414, 14.0]}, 128)
batch 883: ({'logprob': [61.64976119995117, 17.0]}, 128)
batch 884: ({'logprob': [51.81172180175781, 13.0]}, 128)
batch 885: ({'logprob': [52.6846809387207, 13.0]}, 128)
batch 886: ({'logprob': [62.100399017333984, 17.0]}, 128)

======================Test output======================
logprob:  0.419350, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.965201e-03 [1.937775e-09] 
Layer 'conv1' biases: 2.416869e-07 [6.567322e-11] 
Layer 'conv2' weights[0]: 7.952314e-03 [1.766865e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.249717e-10] 
Layer 'conv3' weights[0]: 7.950530e-03 [1.740022e-09] 
Layer 'conv3' biases: 2.072277e-06 [1.032238e-09] 
Layer 'conv4' weights[0]: 7.983210e-03 [1.758198e-09] 
Layer 'conv4' biases: 9.999993e-01 [8.761869e-09] 
Layer 'conv5' weights[0]: 7.982040e-03 [5.099939e-08] 
Layer 'conv5' biases: 9.999951e-01 [5.513063e-08] 
Layer 'fc6' weights[0]: 7.578740e-03 [4.374879e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.368708e-09] 
Layer 'fc7' weights[0]: 7.155281e-03 [8.321868e-08] 
Layer 'fc7' biases: 9.998603e-01 [6.858735e-08] 
Layer 'fc8' weights[0]: 1.263699e-03 [7.387169e-06] 
Layer 'fc8' biases: 5.225761e-02 [4.913797e-05] 
Train error last 870 batches: 0.435228
-------------------------------------------------------
Not saving because 0.419350 > 0.415685 (17.630: -0.01%)
======================================================= (12.091 sec)
22.131... logprob:  0.495498, 0.132812 (1.421 sec)
22.132... logprob:  0.506371, 0.140625 (1.441 sec)
22.133... logprob:  0.444683, 0.117188 (1.393 sec)
22.134... logprob:  0.401892, 0.101562 (1.401 sec)
22.135... logprob:  0.460214, 0.125000 (1.401 sec)
22.136... logprob:  0.562476, 0.164062 (1.399 sec)
22.137... logprob:  0.462576, 0.125000 (1.389 sec)
22.138... logprob:  0.319366, 0.070312 (1.450 sec)
22.139... logprob:  0.395764, 0.101562 (1.402 sec)
22.140... logprob:  0.560297, 0.164062 (1.418 sec)
22.141... logprob:  0.464556, 0.125000 (1.437 sec)
22.142... logprob:  0.464621, 0.125000 (1.402 sec)
22.143... logprob:  0.294334, 0.062500 (1.421 sec)
22.144... logprob:  0.457183, 0.125000 (1.423 sec)
22.145... logprob:  0.324805, 0.078125 (1.421 sec)
22.146... logprob:  0.483165, 0.132812 (1.415 sec)
22.147... logprob:  0.262475, 0.054688 (1.430 sec)
22.148... logprob:  0.458727, 0.125000 (1.396 sec)
22.149... logprob:  0.442533, 0.117188 (1.394 sec)
22.150... logprob:  0.347603, 0.085938 (1.408 sec)
22.151... logprob:  0.347147, 0.085938 (1.422 sec)
22.152... logprob:  0.785067, 0.234375 (1.396 sec)
22.153... logprob:  0.381655, 0.093750 (1.449 sec)
22.154... logprob:  0.524526, 0.148438 (1.398 sec)
22.155... logprob:  0.426038, 0.117188 (1.411 sec)
22.156... logprob:  0.295580, 0.062500 (1.441 sec)
22.157... logprob:  0.270489, 0.054688 (1.401 sec)
22.158... logprob:  0.455399, 0.125000 (1.405 sec)
22.159... logprob:  0.483117, 0.132812 (1.400 sec)
22.160... logprob:  0.444801, 0.117188 (1.392 sec)
22.161... logprob:  0.349948, 0.078125 (1.403 sec)
22.162... logprob:  0.611787, 0.179688 (1.407 sec)
22.163... logprob:  0.450450, 0.125000 (1.431 sec)
22.164... logprob:  0.468613, 0.125000 (1.423 sec)
22.165... logprob:  0.547865, 0.156250 (1.418 sec)
22.166... logprob:  0.446097, 0.125000 (1.456 sec)
22.167... logprob:  0.350502, 0.085938 (1.429 sec)
22.168... logprob:  0.363708, 0.085938 (1.427 sec)
22.169... logprob:  0.408657, 0.101562 (1.461 sec)
22.170... logprob:  0.459479, 0.125000 (1.398 sec)
22.171... logprob:  0.535355, 0.156250 (1.429 sec)
22.172... logprob:  0.434841, 0.109375 (1.415 sec)
22.173... logprob:  0.440483, 0.117188 (1.421 sec)
22.174... logprob:  0.600945, 0.171875 (1.414 sec)
22.175... logprob:  0.506037, 0.140625 (1.470 sec)
22.176... logprob:  0.478447, 0.132812 (1.415 sec)
22.177... logprob:  0.289743, 0.054688 (1.431 sec)
22.178... logprob:  0.383479, 0.093750 (1.457 sec)
22.179... logprob:  0.394695, 0.101562 (1.414 sec)
22.180... logprob:  0.466385, 0.125000 (1.430 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.003990173339844, 10.0]}, 128)
batch 872: ({'logprob': [66.5002212524414, 19.0]}, 128)
batch 873: ({'logprob': [40.684810638427734, 9.0]}, 128)
batch 874: ({'logprob': [45.35890579223633, 11.0]}, 128)
batch 875: ({'logprob': [50.83234405517578, 13.0]}, 128)
batch 876: ({'logprob': [63.984031677246094, 18.0]}, 128)
batch 877: ({'logprob': [45.767303466796875, 11.0]}, 128)
batch 878: ({'logprob': [61.82658767700195, 17.0]}, 128)
batch 879: ({'logprob': [73.18397521972656, 21.0]}, 128)
batch 880: ({'logprob': [50.85374450683594, 13.0]}, 128)
batch 881: ({'logprob': [29.292804718017578, 5.0]}, 128)
batch 882: ({'logprob': [54.597625732421875, 14.0]}, 128)
batch 883: ({'logprob': [61.80464553833008, 17.0]}, 128)
batch 884: ({'logprob': [51.23893737792969, 13.0]}, 128)
batch 885: ({'logprob': [52.04214096069336, 13.0]}, 128)
batch 886: ({'logprob': [62.22244644165039, 17.0]}, 128)

======================Test output======================
logprob:  0.416111, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.965168e-03 [2.510324e-09] 
Layer 'conv1' biases: 2.426039e-07 [5.959784e-11] 
Layer 'conv2' weights[0]: 7.952268e-03 [1.826205e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.502968e-10] 
Layer 'conv3' weights[0]: 7.950488e-03 [1.726556e-09] 
Layer 'conv3' biases: 2.079938e-06 [7.992866e-10] 
Layer 'conv4' weights[0]: 7.983166e-03 [1.738742e-09] 
Layer 'conv4' biases: 9.999992e-01 [5.896994e-09] 
Layer 'conv5' weights[0]: 7.982003e-03 [3.504273e-08] 
Layer 'conv5' biases: 9.999946e-01 [3.778122e-08] 
Layer 'fc6' weights[0]: 7.578700e-03 [3.037886e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.991086e-09] 
Layer 'fc7' weights[0]: 7.153470e-03 [1.218101e-07] 
Layer 'fc7' biases: 9.998611e-01 [1.078393e-07] 
Layer 'fc8' weights[0]: 1.302005e-03 [1.026595e-05] 
Layer 'fc8' biases: 5.263940e-02 [6.911426e-05] 
Train error last 870 batches: 0.435228
-------------------------------------------------------
Not saving because 0.416111 > 0.415685 (17.630: -0.01%)
======================================================= (12.063 sec)
22.181... logprob:  0.539344, 0.156250 (1.421 sec)
22.182... logprob:  0.371345, 0.093750 (1.420 sec)
22.183... logprob:  0.419946, 0.109375 (1.423 sec)
22.184... logprob:  0.483455, 0.132812 (1.420 sec)
22.185... logprob:  0.289814, 0.062500 (1.402 sec)
22.186... logprob:  0.370438, 0.093750 (1.397 sec)
22.187... logprob:  0.529621, 0.148438 (1.406 sec)
22.188... logprob:  0.458932, 0.125000 (1.392 sec)
22.189... logprob:  0.440913, 0.117188 (1.391 sec)
22.190... logprob:  0.375766, 0.093750 (1.442 sec)
22.191... logprob:  0.485095, 0.132812 (1.407 sec)
22.192... logprob:  0.520100, 0.148438 (1.419 sec)
22.193... logprob:  0.312560, 0.070312 (1.423 sec)
22.194... logprob:  0.414085, 0.109375 (1.421 sec)
22.195... logprob:  0.287136, 0.062500 (1.401 sec)
22.196... logprob:  0.410509, 0.109375 (1.392 sec)
22.197... logprob:  0.478005, 0.132812 (1.400 sec)
22.198... logprob:  0.355795, 0.085938 (1.405 sec)
22.199... logprob:  0.437193, 0.117188 (1.395 sec)
22.200... logprob:  0.440752, 0.117188 (1.438 sec)
22.201... logprob:  0.437094, 0.117188 (1.409 sec)
22.202... logprob:  0.537906, 0.148438 (1.403 sec)
22.203... logprob:  0.420433, 0.109375 (1.445 sec)
22.204... logprob:  0.504123, 0.140625 (1.387 sec)
22.205... logprob:  0.334338, 0.078125 (1.407 sec)
22.206... logprob:  0.361631, 0.093750 (1.400 sec)
22.207... logprob:  0.381834, 0.093750 (1.395 sec)
22.208... logprob:  0.490550, 0.140625 (1.393 sec)
22.209... logprob:  0.334567, 0.078125 (1.428 sec)
22.210... logprob:  0.586236, 0.171875 (1.488 sec)
22.211... logprob:  0.488159, 0.132812 (1.419 sec)
22.212... logprob:  0.526136, 0.148438 (1.410 sec)
22.213... logprob:  0.514712, 0.140625 (1.465 sec)
22.214... logprob:  0.459416, 0.125000 (1.433 sec)
22.215... logprob:  0.396122, 0.101562 (1.420 sec)
22.216... logprob:  0.517015, 0.140625 (1.465 sec)
22.217... logprob:  0.324986, 0.070312 (1.403 sec)
22.218... logprob:  0.463644, 0.125000 (1.426 sec)
22.219... logprob:  0.500267, 0.140625 (1.416 sec)
22.220... logprob:  0.415012, 0.109375 (1.421 sec)
22.221... logprob:  0.399555, 0.101562 (1.406 sec)
22.222... logprob:  0.554493, 0.164062 (1.457 sec)
22.223... logprob:  0.569085, 0.164062 (1.432 sec)
22.224... logprob:  0.405925, 0.101562 (1.438 sec)
22.225... logprob:  0.391985, 0.101562 (1.451 sec)
22.226... logprob:  0.424689, 0.109375 (1.423 sec)
22.227... logprob:  0.452677, 0.125000 (1.427 sec)
22.228... logprob:  0.417181, 0.109375 (1.411 sec)
22.229... logprob:  0.489370, 0.132812 (1.422 sec)
22.230... logprob:  0.459874, 0.125000 (1.430 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.994110107421875, 10.0]}, 128)
batch 872: ({'logprob': [66.4575424194336, 19.0]}, 128)
batch 873: ({'logprob': [40.73259735107422, 9.0]}, 128)
batch 874: ({'logprob': [45.3697509765625, 11.0]}, 128)
batch 875: ({'logprob': [50.8376350402832, 13.0]}, 128)
batch 876: ({'logprob': [63.952022552490234, 18.0]}, 128)
batch 877: ({'logprob': [45.793880462646484, 11.0]}, 128)
batch 878: ({'logprob': [61.82090759277344, 17.0]}, 128)
batch 879: ({'logprob': [73.1826400756836, 21.0]}, 128)
batch 880: ({'logprob': [50.85919189453125, 13.0]}, 128)
batch 881: ({'logprob': [29.336015701293945, 5.0]}, 128)
batch 882: ({'logprob': [54.639339447021484, 14.0]}, 128)
batch 883: ({'logprob': [61.79875946044922, 17.0]}, 128)
batch 884: ({'logprob': [51.259864807128906, 13.0]}, 128)
batch 885: ({'logprob': [52.09440231323242, 13.0]}, 128)
batch 886: ({'logprob': [62.23240661621094, 17.0]}, 128)

======================Test output======================
logprob:  0.416192, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.965133e-03 [2.220607e-09] 
Layer 'conv1' biases: 2.435525e-07 [5.120859e-11] 
Layer 'conv2' weights[0]: 7.952233e-03 [1.765658e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.118970e-10] 
Layer 'conv3' weights[0]: 7.950448e-03 [1.404165e-09] 
Layer 'conv3' biases: 2.088765e-06 [6.167812e-10] 
Layer 'conv4' weights[0]: 7.983125e-03 [1.397409e-09] 
Layer 'conv4' biases: 9.999993e-01 [4.098289e-09] 
Layer 'conv5' weights[0]: 7.981960e-03 [2.704125e-08] 
Layer 'conv5' biases: 9.999948e-01 [2.916575e-08] 
Layer 'fc6' weights[0]: 7.578653e-03 [2.432814e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.297714e-09] 
Layer 'fc7' weights[0]: 7.151641e-03 [4.295168e-08] 
Layer 'fc7' biases: 9.998609e-01 [1.922116e-08] 
Layer 'fc8' weights[0]: 1.304109e-03 [2.052503e-06] 
Layer 'fc8' biases: 5.271139e-02 [1.418266e-05] 
Train error last 870 batches: 0.435228
-------------------------------------------------------
Not saving because 0.416192 > 0.415685 (17.630: -0.01%)
======================================================= (12.201 sec)
22.231... logprob:  0.453516, 0.125000 (1.410 sec)
22.232... logprob:  0.496196, 0.140625 (1.468 sec)
22.233... logprob:  0.466113, 0.132812 (1.435 sec)
22.234... logprob:  0.563834, 0.164062 (1.423 sec)
22.235... logprob:  0.482020, 0.132812 (1.470 sec)
22.236... logprob:  0.425722, 0.109375 (1.400 sec)
22.237... logprob:  0.341130, 0.078125 (1.430 sec)
22.238... logprob:  0.389245, 0.093750 (1.414 sec)
22.239... logprob:  0.478113, 0.132812 (1.425 sec)
22.240... logprob:  0.485800, 0.132812 (1.399 sec)
22.241... logprob:  0.493602, 0.132812 (1.466 sec)
22.242... logprob:  0.341645, 0.078125 (1.441 sec)
22.243... logprob:  0.386008, 0.093750 (1.433 sec)
22.244... logprob:  0.315324, 0.070312 (1.448 sec)
22.245... logprob:  0.494277, 0.132812 (1.426 sec)
22.246... logprob:  0.416875, 0.109375 (1.413 sec)
22.247... logprob:  0.357465, 0.085938 (1.419 sec)
22.248... logprob:  0.307903, 0.070312 (1.421 sec)
22.249... logprob:  0.554996, 0.156250 (1.427 sec)
22.250... logprob:  0.591462, 0.164062 (1.413 sec)
22.251... logprob:  0.352951, 0.085938 (1.467 sec)
22.252... logprob:  0.348460, 0.085938 (1.428 sec)
22.253... logprob:  0.379196, 0.093750 (1.425 sec)
22.254... logprob:  0.444170, 0.117188 (1.475 sec)
22.255... logprob:  0.351404, 0.085938 (1.407 sec)
22.256... logprob:  0.378802, 0.093750 (1.424 sec)
22.257... logprob:  0.332006, 0.078125 (1.414 sec)
22.258... logprob:  0.415643, 0.109375 (1.422 sec)
22.259... logprob:  0.442314, 0.117188 (1.401 sec)
22.260... logprob:  0.308287, 0.070312 (1.499 sec)
22.261... logprob:  0.392686, 0.101562 (1.428 sec)
22.262... logprob:  0.524595, 0.148438 (1.430 sec)
22.263... logprob:  0.425531, 0.109375 (1.446 sec)
22.264... logprob:  0.375087, 0.093750 (1.431 sec)
22.265... logprob:  0.439613, 0.117188 (1.423 sec)
22.266... logprob:  0.439020, 0.117188 (1.414 sec)
22.267... logprob:  0.422019, 0.109375 (1.419 sec)
22.268... logprob:  0.458940, 0.125000 (1.435 sec)
22.269... logprob:  0.567518, 0.164062 (1.410 sec)
22.270... logprob:  0.542271, 0.156250 (1.466 sec)
22.271... logprob:  0.445672, 0.117188 (1.433 sec)
22.272... logprob:  0.384662, 0.093750 (1.420 sec)
22.273... logprob:  0.500224, 0.140625 (1.468 sec)
22.274... logprob:  0.542512, 0.156250 (1.399 sec)
22.275... logprob:  0.487650, 0.132812 (1.434 sec)
22.276... logprob:  0.390092, 0.093750 (1.418 sec)
22.277... logprob:  0.428660, 0.109375 (1.425 sec)
22.278... logprob:  0.323511, 0.070312 (1.428 sec)
22.279... logprob:  0.325127, 0.070312 (1.459 sec)
22.280... logprob:  0.215592, 0.031250 (1.414 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.961883544921875, 10.0]}, 128)
batch 872: ({'logprob': [66.65791320800781, 19.0]}, 128)
batch 873: ({'logprob': [40.50504684448242, 9.0]}, 128)
batch 874: ({'logprob': [45.28693771362305, 11.0]}, 128)
batch 875: ({'logprob': [50.80064392089844, 13.0]}, 128)
batch 876: ({'logprob': [64.10502624511719, 18.0]}, 128)
batch 877: ({'logprob': [45.661556243896484, 11.0]}, 128)
batch 878: ({'logprob': [61.87651443481445, 17.0]}, 128)
batch 879: ({'logprob': [73.28185272216797, 21.0]}, 128)
batch 880: ({'logprob': [50.8223991394043, 13.0]}, 128)
batch 881: ({'logprob': [29.064895629882812, 5.0]}, 128)
batch 882: ({'logprob': [54.50286102294922, 14.0]}, 128)
batch 883: ({'logprob': [61.85436248779297, 17.0]}, 128)
batch 884: ({'logprob': [51.17429733276367, 13.0]}, 128)
batch 885: ({'logprob': [51.91032028198242, 13.0]}, 128)
batch 886: ({'logprob': [62.2391357421875, 17.0]}, 128)

======================Test output======================
logprob:  0.415872, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.965091e-03 [8.781301e-09] 
Layer 'conv1' biases: 2.444691e-07 [3.594444e-10] 
Layer 'conv2' weights[0]: 7.952195e-03 [8.562539e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.874248e-09] 
Layer 'conv3' weights[0]: 7.950407e-03 [8.640397e-09] 
Layer 'conv3' biases: 2.093364e-06 [5.760271e-09] 
Layer 'conv4' weights[0]: 7.983091e-03 [8.941469e-09] 
Layer 'conv4' biases: 9.999992e-01 [5.238626e-08] 
Layer 'conv5' weights[0]: 7.981904e-03 [3.441360e-07] 
Layer 'conv5' biases: 9.999944e-01 [3.707450e-07] 
Layer 'fc6' weights[0]: 7.578603e-03 [2.842767e-08] 
Layer 'fc6' biases: 1.000000e+00 [2.906250e-08] 
Layer 'fc7' weights[0]: 7.149846e-03 [6.590349e-07] 
Layer 'fc7' biases: 9.998611e-01 [6.449371e-07] 
Layer 'fc8' weights[0]: 1.312047e-03 [2.356090e-05] 
Layer 'fc8' biases: 5.286893e-02 [1.655741e-04] 
Train error last 870 batches: 0.435227
-------------------------------------------------------
Not saving because 0.415872 > 0.415685 (17.630: -0.01%)
======================================================= (12.048 sec)
22.281... logprob:  0.417230, 0.109375 (2.002 sec)
22.282... logprob:  0.411384, 0.109375 (2.593 sec)
22.283... logprob:  0.393791, 0.101562 (2.797 sec)
22.284... logprob:  0.394531, 0.101562 (7.501 sec)
22.285... logprob:  0.451778, 0.117188 (1.963 sec)
22.286... logprob:  0.536893, 0.140625 (10.447 sec)
22.287... logprob:  0.346600, 0.085938 (5.197 sec)
22.288... logprob:  0.329959, 0.078125 (2.590 sec)
22.289... logprob:  0.445912, 0.117188 (2.344 sec)
22.290... logprob:  0.490656, 0.132812 (3.594 sec)
22.291... logprob:  0.439241, 0.117188 (1.730 sec)
22.292... logprob:  0.567380, 0.156250 (1.761 sec)
22.293... logprob:  0.427622, 0.117188 (1.744 sec)
22.294... logprob:  0.355955, 0.085938 (1.904 sec)
22.295... logprob:  0.334721, 0.078125 (1.680 sec)
22.296... logprob:  0.355829, 0.085938 (2.731 sec)
22.297... logprob:  0.394571, 0.101562 (8.392 sec)
22.298... logprob:  0.448175, 0.125000 (1.481 sec)
22.299... logprob:  0.342290, 0.078125 (1.411 sec)
22.300... logprob:  0.406526, 0.101562 (1.438 sec)
22.301... logprob:  0.397926, 0.101562 (1.418 sec)
22.302... logprob:  0.591555, 0.179688 (1.428 sec)
22.303... logprob:  0.459557, 0.125000 (1.421 sec)
22.304... logprob:  0.459660, 0.125000 (1.451 sec)
22.305... logprob:  0.455215, 0.125000 (1.450 sec)
22.306... logprob:  0.440591, 0.117188 (1.451 sec)
22.307... logprob:  0.421613, 0.109375 (1.452 sec)
22.308... logprob:  0.374698, 0.093750 (1.452 sec)
22.309... logprob:  0.450483, 0.125000 (1.424 sec)
22.310... logprob:  0.473671, 0.125000 (1.442 sec)
22.311... logprob:  0.502564, 0.140625 (1.431 sec)
22.312... logprob:  0.478735, 0.132812 (1.451 sec)
22.313... logprob:  0.454865, 0.125000 (1.425 sec)
22.314... logprob:  0.454431, 0.117188 (1.481 sec)
22.315... logprob:  0.314676, 0.070312 (1.454 sec)
22.316... logprob:  0.468545, 0.125000 (1.440 sec)
22.317... logprob:  0.355470, 0.085938 (1.495 sec)
22.318... logprob:  0.455410, 0.125000 (1.426 sec)
22.319... logprob:  0.423188, 0.117188 (1.432 sec)
22.320... logprob:  0.412248, 0.109375 (1.436 sec)
22.321... logprob:  0.348265, 0.085938 (1.432 sec)
22.322... logprob:  0.387479, 0.101562 (1.424 sec)
22.323... logprob:  0.416513, 0.109375 (1.497 sec)
22.324... logprob:  0.498612, 0.140625 (1.433 sec)
22.325... logprob:  0.350679, 0.085938 (1.439 sec)
22.326... logprob:  0.543182, 0.148438 (1.475 sec)
22.327... logprob:  0.554403, 0.164062 (1.431 sec)
22.328... logprob:  0.565068, 0.156250 (1.435 sec)
22.329... logprob:  0.401957, 0.101562 (1.435 sec)
22.330... logprob:  0.388586, 0.101562 (1.430 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.09447479248047, 10.0]}, 128)
batch 872: ({'logprob': [65.97236633300781, 19.0]}, 128)
batch 873: ({'logprob': [41.533836364746094, 9.0]}, 128)
batch 874: ({'logprob': [45.69174575805664, 11.0]}, 128)
batch 875: ({'logprob': [51.051536560058594, 13.0]}, 128)
batch 876: ({'logprob': [63.61286163330078, 18.0]}, 128)
batch 877: ({'logprob': [46.30118179321289, 11.0]}, 128)
batch 878: ({'logprob': [61.81464767456055, 17.0]}, 128)
batch 879: ({'logprob': [73.14055633544922, 21.0]}, 128)
batch 880: ({'logprob': [51.07195281982422, 13.0]}, 128)
batch 881: ({'logprob': [30.173025131225586, 5.0]}, 128)
batch 882: ({'logprob': [55.258243560791016, 14.0]}, 128)
batch 883: ({'logprob': [61.79314422607422, 17.0]}, 128)
batch 884: ({'logprob': [51.65652084350586, 13.0]}, 128)
batch 885: ({'logprob': [52.86026382446289, 13.0]}, 128)
batch 886: ({'logprob': [62.41004180908203, 17.0]}, 128)

======================Test output======================
logprob:  0.418182, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.965053e-03 [2.617611e-09] 
Layer 'conv1' biases: 2.455285e-07 [4.246387e-11] 
Layer 'conv2' weights[0]: 7.952165e-03 [1.818625e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.499704e-10] 
Layer 'conv3' weights[0]: 7.950375e-03 [1.265361e-09] 
Layer 'conv3' biases: 2.104441e-06 [3.637210e-10] 
Layer 'conv4' weights[0]: 7.983050e-03 [1.174691e-09] 
Layer 'conv4' biases: 9.999992e-01 [6.648750e-10] 
Layer 'conv5' weights[0]: 7.981868e-03 [4.495706e-09] 
Layer 'conv5' biases: 9.999952e-01 [4.795293e-09] 
Layer 'fc6' weights[0]: 7.578555e-03 [8.431948e-10] 
Layer 'fc6' biases: 1.000000e+00 [3.544402e-10] 
Layer 'fc7' weights[0]: 7.148036e-03 [2.156642e-07] 
Layer 'fc7' biases: 9.998608e-01 [2.052858e-07] 
Layer 'fc8' weights[0]: 1.289287e-03 [7.989979e-06] 
Layer 'fc8' biases: 5.297848e-02 [4.928896e-05] 
Train error last 870 batches: 0.435227
-------------------------------------------------------
Not saving because 0.418182 > 0.415685 (17.630: -0.01%)
======================================================= (12.314 sec)
22.331... logprob:  0.352403, 0.085938 (1.441 sec)
22.332... logprob:  0.482782, 0.132812 (1.458 sec)
22.333... logprob:  0.339563, 0.085938 (1.451 sec)
22.334... logprob:  0.565193, 0.171875 (1.450 sec)
22.335... logprob:  0.358778, 0.085938 (1.436 sec)
22.336... logprob:  0.444845, 0.125000 (1.461 sec)
22.337... logprob:  0.566439, 0.164062 (1.422 sec)
22.338... logprob:  0.449515, 0.125000 (1.432 sec)
22.339... logprob:  0.488647, 0.132812 (1.432 sec)
22.340... logprob:  0.442071, 0.117188 (1.442 sec)
22.341... logprob:  0.530089, 0.148438 (1.419 sec)
22.342... logprob:  0.429641, 0.109375 (1.497 sec)
22.343... logprob:  0.434774, 0.109375 (1.432 sec)
22.344... logprob:  0.444471, 0.125000 (1.484 sec)
22.345... logprob:  0.488225, 0.132812 (1.440 sec)
22.346... logprob:  0.436224, 0.117188 (1.442 sec)
22.347... logprob:  0.372441, 0.085938 (1.484 sec)
22.348... logprob:  0.398458, 0.101562 (1.436 sec)
22.349... logprob:  0.497740, 0.140625 (1.443 sec)
22.350... logprob:  0.358623, 0.085938 (1.446 sec)
22.351... logprob:  0.508585, 0.140625 (1.436 sec)
22.352... logprob:  0.363636, 0.093750 (1.434 sec)
22.353... logprob:  0.512630, 0.148438 (1.492 sec)
22.354... logprob:  0.674976, 0.203125 (1.439 sec)
22.355... logprob:  0.357484, 0.085938 (1.446 sec)
22.356... logprob:  0.479243, 0.132812 (1.479 sec)
22.357... logprob:  0.346890, 0.085938 (1.435 sec)
22.358... logprob:  0.325894, 0.070312 (1.443 sec)
22.359... logprob:  0.555296, 0.164062 (1.432 sec)
22.360... logprob:  0.444517, 0.117188 (1.430 sec)
22.361... logprob:  0.410757, 0.101562 (1.434 sec)
22.362... logprob:  0.424042, 0.117188 (1.480 sec)
22.363... logprob:  0.486584, 0.132812 (1.451 sec)
22.364... logprob:  0.475573, 0.125000 (1.460 sec)
22.365... logprob:  0.425064, 0.109375 (1.464 sec)
22.366... logprob:  0.409635, 0.109375 (1.447 sec)
22.367... logprob:  0.324956, 0.078125 (1.439 sec)
22.368... logprob:  0.595621, 0.171875 (1.431 sec)
22.369... logprob:  0.381597, 0.093750 (1.428 sec)
22.370... logprob:  0.381226, 0.093750 (1.442 sec)
22.371... logprob:  0.400383, 0.101562 (1.455 sec)
22.372... logprob:  0.537422, 0.156250 (1.464 sec)
22.373... logprob:  0.463808, 0.125000 (1.461 sec)
22.374... logprob:  0.526952, 0.148438 (1.449 sec)
22.375... logprob:  0.393774, 0.101562 (1.467 sec)
22.376... logprob:  0.374299, 0.093750 (1.440 sec)
22.377... logprob:  0.295402, 0.062500 (1.426 sec)
22.378... logprob:  0.453719, 0.125000 (1.433 sec)
22.379... logprob:  0.420240, 0.109375 (1.439 sec)
22.380... logprob:  0.605722, 0.179688 (1.442 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.80488967895508, 10.0]}, 128)
batch 872: ({'logprob': [66.6243896484375, 19.0]}, 128)
batch 873: ({'logprob': [40.51408386230469, 9.0]}, 128)
batch 874: ({'logprob': [45.22483444213867, 11.0]}, 128)
batch 875: ({'logprob': [50.77186584472656, 13.0]}, 128)
batch 876: ({'logprob': [64.08084106445312, 18.0]}, 128)
batch 877: ({'logprob': [45.65160369873047, 11.0]}, 128)
batch 878: ({'logprob': [61.91419219970703, 17.0]}, 128)
batch 879: ({'logprob': [73.43775939941406, 21.0]}, 128)
batch 880: ({'logprob': [50.793670654296875, 13.0]}, 128)
batch 881: ({'logprob': [28.955459594726562, 5.0]}, 128)
batch 882: ({'logprob': [54.62119674682617, 14.0]}, 128)
batch 883: ({'logprob': [61.891963958740234, 17.0]}, 128)
batch 884: ({'logprob': [51.19781494140625, 13.0]}, 128)
batch 885: ({'logprob': [52.038230895996094, 13.0]}, 128)
batch 886: ({'logprob': [62.32904052734375, 17.0]}, 128)

======================Test output======================
logprob:  0.415943, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.965016e-03 [4.060169e-09] 
Layer 'conv1' biases: 2.463460e-07 [1.602908e-10] 
Layer 'conv2' weights[0]: 7.952123e-03 [3.374844e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.104261e-10] 
Layer 'conv3' weights[0]: 7.950342e-03 [3.644942e-09] 
Layer 'conv3' biases: 2.110272e-06 [2.481162e-09] 
Layer 'conv4' weights[0]: 7.983017e-03 [3.530205e-09] 
Layer 'conv4' biases: 9.999992e-01 [2.079069e-08] 
Layer 'conv5' weights[0]: 7.981833e-03 [1.328280e-07] 
Layer 'conv5' biases: 9.999947e-01 [1.432858e-07] 
Layer 'fc6' weights[0]: 7.578515e-03 [1.108791e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.133681e-08] 
Layer 'fc7' weights[0]: 7.146228e-03 [1.092793e-07] 
Layer 'fc7' biases: 9.998611e-01 [9.580229e-08] 
Layer 'fc8' weights[0]: 1.311451e-03 [4.580046e-06] 
Layer 'fc8' biases: 5.322516e-02 [2.936565e-05] 
Train error last 870 batches: 0.435226
-------------------------------------------------------
Not saving because 0.415943 > 0.415685 (17.630: -0.01%)
======================================================= (12.078 sec)
22.381... logprob:  0.463448, 0.125000 (1.478 sec)
22.382... logprob:  0.529541, 0.148438 (1.460 sec)
22.383... logprob:  0.358612, 0.085938 (1.436 sec)
22.384... logprob:  0.521127, 0.148438 (1.469 sec)
22.385... logprob:  0.523523, 0.148438 (1.435 sec)
22.386... logprob:  0.582453, 0.171875 (1.417 sec)
22.387... logprob:  0.428600, 0.117188 (1.435 sec)
22.388... logprob:  0.521341, 0.148438 (1.437 sec)
22.389... logprob:  0.425746, 0.109375 (1.437 sec)
22.390... logprob:  0.419807, 0.109375 (1.477 sec)
22.391... logprob:  0.318275, 0.070312 (1.449 sec)
22.392... logprob:  0.439440, 0.117188 (1.435 sec)
22.393... logprob:  0.368934, 0.093750 (1.492 sec)
22.394... logprob:  0.343588, 0.078125 (1.429 sec)
22.395... logprob:  0.331718, 0.078125 (1.431 sec)
22.396... logprob:  0.252197, 0.046875 (1.438 sec)
22.397... logprob:  0.484429, 0.132812 (1.432 sec)
22.398... logprob:  0.471077, 0.125000 (1.431 sec)
22.399... logprob:  0.433459, 0.117188 (1.502 sec)
22.400... logprob:  0.538049, 0.148438 (1.440 sec)
22.401... logprob:  0.465931, 0.125000 (1.444 sec)
22.402... logprob:  0.474066, 0.125000 (1.484 sec)
22.403... logprob:  0.462178, 0.125000 (1.430 sec)
22.404... logprob:  0.474824, 0.125000 (1.455 sec)
22.405... logprob:  0.544048, 0.156250 (1.434 sec)
22.406... logprob:  0.357734, 0.085938 (1.434 sec)
22.407... logprob:  0.492843, 0.140625 (1.429 sec)
22.408... logprob:  0.339327, 0.078125 (1.485 sec)
22.409... logprob:  0.400722, 0.101562 (1.439 sec)
22.410... logprob:  0.581995, 0.171875 (1.455 sec)
22.411... logprob:  0.398034, 0.101562 (1.470 sec)
22.412... logprob:  0.540256, 0.156250 (1.445 sec)
22.413... logprob:  0.544683, 0.156250 (1.436 sec)
22.414... logprob:  0.466515, 0.125000 (1.434 sec)
22.415... logprob:  0.401736, 0.101562 (1.429 sec)
22.416... logprob:  0.427540, 0.109375 (1.471 sec)
22.417... logprob:  0.405446, 0.093750 (1.468 sec)
22.418... logprob:  0.380258, 0.093750 (1.453 sec)
22.419... logprob:  0.417705, 0.101562 (1.456 sec)
22.420... logprob:  0.356148, 0.085938 (1.455 sec)
22.421... logprob:  0.376581, 0.101562 (1.459 sec)
22.422... logprob:  0.522647, 0.148438 (1.438 sec)
22.423... logprob:  0.420931, 0.109375 (1.428 sec)
22.424... logprob:  0.324734, 0.078125 (1.429 sec)
22.425... logprob:  0.306285, 0.070312 (1.441 sec)
22.426... logprob:  0.449257, 0.117188 (1.445 sec)
22.427... logprob:  0.554620, 0.156250 (1.463 sec)
22.428... logprob:  0.602016, 0.171875 (1.446 sec)
22.429... logprob:  0.426311, 0.109375 (1.442 sec)
22.430... logprob:  0.299879, 0.070312 (1.474 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.20430374145508, 10.0]}, 128)
batch 872: ({'logprob': [67.23324584960938, 19.0]}, 128)
batch 873: ({'logprob': [40.02334213256836, 9.0]}, 128)
batch 874: ({'logprob': [44.86920928955078, 11.0]}, 128)
batch 875: ({'logprob': [50.692108154296875, 13.0]}, 128)
batch 876: ({'logprob': [64.58715057373047, 18.0]}, 128)
batch 877: ({'logprob': [45.3657112121582, 11.0]}, 128)
batch 878: ({'logprob': [62.38758087158203, 17.0]}, 128)
batch 879: ({'logprob': [74.53472137451172, 21.0]}, 128)
batch 880: ({'logprob': [50.71388626098633, 13.0]}, 128)
batch 881: ({'logprob': [27.840007781982422, 5.0]}, 128)
batch 882: ({'logprob': [54.85759735107422, 14.0]}, 128)
batch 883: ({'logprob': [62.36558151245117, 17.0]}, 128)
batch 884: ({'logprob': [51.19041442871094, 13.0]}, 128)
batch 885: ({'logprob': [52.1724739074707, 13.0]}, 128)
batch 886: ({'logprob': [62.87409973144531, 17.0]}, 128)

======================Test output======================
logprob:  0.416461, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.964991e-03 [2.228852e-09] 
Layer 'conv1' biases: 2.472766e-07 [4.227240e-11] 
Layer 'conv2' weights[0]: 7.952079e-03 [1.796146e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.379874e-10] 
Layer 'conv3' weights[0]: 7.950298e-03 [1.511766e-09] 
Layer 'conv3' biases: 2.116801e-06 [7.115959e-10] 
Layer 'conv4' weights[0]: 7.982981e-03 [1.487195e-09] 
Layer 'conv4' biases: 9.999993e-01 [5.181822e-09] 
Layer 'conv5' weights[0]: 7.981790e-03 [3.150176e-08] 
Layer 'conv5' biases: 9.999948e-01 [3.396163e-08] 
Layer 'fc6' weights[0]: 7.578473e-03 [2.793087e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.732467e-09] 
Layer 'fc7' weights[0]: 7.144379e-03 [2.174775e-07] 
Layer 'fc7' biases: 9.998620e-01 [2.070672e-07] 
Layer 'fc8' weights[0]: 1.330053e-03 [8.266069e-06] 
Layer 'fc8' biases: 5.370000e-02 [4.509608e-05] 
Train error last 870 batches: 0.435226
-------------------------------------------------------
Not saving because 0.416461 > 0.415685 (17.630: -0.01%)
======================================================= (11.983 sec)
22.431... logprob:  0.599623, 0.171875 (1.440 sec)
22.432... logprob:  0.387563, 0.093750 (1.429 sec)
22.433... logprob:  0.329981, 0.078125 (1.435 sec)
22.434... logprob:  0.529322, 0.148438 (1.437 sec)
22.435... logprob:  0.532242, 0.156250 (1.432 sec)
22.436... logprob:  0.381316, 0.093750 (1.474 sec)
22.437... logprob:  0.500263, 0.140625 (1.445 sec)
22.438... logprob:  0.546858, 0.156250 (1.436 sec)
22.439... logprob:  0.378964, 0.093750 (1.489 sec)
22.440... logprob:  0.439796, 0.117188 (1.437 sec)
22.441... logprob:  0.468010, 0.125000 (1.429 sec)
22.442... logprob:  0.378937, 0.093750 (1.440 sec)
22.443... logprob:  0.496575, 0.140625 (1.431 sec)
22.444... logprob:  0.372231, 0.093750 (1.431 sec)
22.445... logprob:  0.362354, 0.085938 (1.483 sec)
22.446... logprob:  0.398215, 0.101562 (1.441 sec)
22.447... logprob:  0.570023, 0.164062 (1.442 sec)
22.448... logprob:  0.332697, 0.078125 (1.482 sec)
22.449... logprob:  0.400026, 0.101562 (1.469 sec)
22.450... logprob:  0.239175, 0.046875 (1.435 sec)
22.451... logprob:  0.452835, 0.125000 (1.436 sec)
22.452... logprob:  0.456235, 0.117188 (1.422 sec)
22.453... logprob:  0.455367, 0.125000 (1.439 sec)
22.454... logprob:  0.489120, 0.132812 (1.487 sec)
22.455... logprob:  0.506107, 0.140625 (1.433 sec)
22.456... logprob:  0.468827, 0.125000 (1.447 sec)
22.457... logprob:  0.375361, 0.093750 (1.481 sec)
22.458... logprob:  0.351115, 0.085938 (1.440 sec)
22.459... logprob:  0.513817, 0.140625 (1.442 sec)
22.460... logprob:  0.274235, 0.054688 (1.433 sec)
22.461... logprob:  0.460037, 0.125000 (1.430 sec)
22.462... logprob:  0.471931, 0.125000 (1.438 sec)
22.463... logprob:  0.420892, 0.109375 (1.470 sec)
22.464... logprob:  0.482721, 0.132812 (1.451 sec)
22.465... logprob:  0.421175, 0.109375 (1.452 sec)
22.466... logprob:  0.318514, 0.070312 (1.459 sec)
22.467... logprob:  0.413856, 0.109375 (1.458 sec)
22.468... logprob:  0.394273, 0.101562 (1.446 sec)
22.469... logprob:  0.334715, 0.078125 (1.425 sec)
22.470... logprob:  0.400073, 0.101562 (1.432 sec)
22.471... logprob:  0.529463, 0.148438 (1.437 sec)
22.472... logprob:  0.410038, 0.109375 (1.455 sec)
22.473... logprob:  0.375392, 0.093750 (1.459 sec)
22.474... logprob:  0.465692, 0.125000 (1.448 sec)
22.475... logprob:  0.504220, 0.140625 (1.449 sec)
22.476... logprob:  0.510364, 0.140625 (1.463 sec)
22.477... logprob:  0.334552, 0.078125 (1.439 sec)
22.478... logprob:  0.464269, 0.125000 (1.430 sec)
22.479... logprob:  0.305777, 0.070312 (1.430 sec)
22.480... logprob:  0.443513, 0.117188 (1.442 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.765560150146484, 10.0]}, 128)
batch 872: ({'logprob': [66.7109375, 19.0]}, 128)
batch 873: ({'logprob': [40.42036437988281, 9.0]}, 128)
batch 874: ({'logprob': [45.18134689331055, 11.0]}, 128)
batch 875: ({'logprob': [50.75502014160156, 13.0]}, 128)
batch 876: ({'logprob': [64.1480484008789, 18.0]}, 128)
batch 877: ({'logprob': [45.59620666503906, 11.0]}, 128)
batch 878: ({'logprob': [61.95051956176758, 17.0]}, 128)
batch 879: ({'logprob': [73.515869140625, 21.0]}, 128)
batch 880: ({'logprob': [50.77659225463867, 13.0]}, 128)
batch 881: ({'logprob': [28.82011604309082, 5.0]}, 128)
batch 882: ({'logprob': [54.588375091552734, 14.0]}, 128)
batch 883: ({'logprob': [61.92854690551758, 17.0]}, 128)
batch 884: ({'logprob': [51.169376373291016, 13.0]}, 128)
batch 885: ({'logprob': [51.98645782470703, 13.0]}, 128)
batch 886: ({'logprob': [62.35374450683594, 17.0]}, 128)

======================Test output======================
logprob:  0.415853, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.964947e-03 [2.334697e-09] 
Layer 'conv1' biases: 2.480686e-07 [3.558779e-11] 
Layer 'conv2' weights[0]: 7.952037e-03 [1.527428e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.468087e-10] 
Layer 'conv3' weights[0]: 7.950265e-03 [1.176137e-09] 
Layer 'conv3' biases: 2.123347e-06 [4.351989e-10] 
Layer 'conv4' weights[0]: 7.982941e-03 [1.178101e-09] 
Layer 'conv4' biases: 9.999992e-01 [2.941227e-09] 
Layer 'conv5' weights[0]: 7.981755e-03 [1.863201e-08] 
Layer 'conv5' biases: 9.999947e-01 [2.007843e-08] 
Layer 'fc6' weights[0]: 7.578428e-03 [1.751353e-09] 
Layer 'fc6' biases: 9.999999e-01 [1.580165e-09] 
Layer 'fc7' weights[0]: 7.142556e-03 [4.513632e-08] 
Layer 'fc7' biases: 9.998612e-01 [2.393315e-08] 
Layer 'fc8' weights[0]: 1.304456e-03 [1.411827e-06] 
Layer 'fc8' biases: 5.378763e-02 [8.469867e-06] 
Train error last 870 batches: 0.435226
-------------------------------------------------------
Not saving because 0.415853 > 0.415685 (17.630: -0.01%)
======================================================= (12.114 sec)
22.481... logprob:  0.547778, 0.156250 (1.444 sec)
22.482... logprob:  0.443164, 0.117188 (1.506 sec)
22.483... logprob:  0.502625, 0.140625 (1.446 sec)
22.484... logprob:  0.485300, 0.132812 (1.441 sec)
22.485... logprob:  0.409024, 0.109375 (1.488 sec)
22.486... logprob:  0.361484, 0.085938 (1.430 sec)
22.487... logprob:  0.522645, 0.148438 (1.434 sec)
22.488... logprob:  0.424818, 0.109375 (1.435 sec)
22.489... logprob:  0.415902, 0.109375 (1.438 sec)
22.490... logprob:  0.440697, 0.117188 (1.433 sec)
22.491... logprob:  0.313676, 0.070312 (1.485 sec)
22.492... logprob:  0.459574, 0.125000 (1.440 sec)
22.493... logprob:  0.521892, 0.148438 (1.439 sec)
22.494... logprob:  0.450365, 0.125000 (1.485 sec)
22.495... logprob:  0.380606, 0.093750 (1.440 sec)
22.496... logprob:  0.550396, 0.156250 (1.431 sec)
22.497... logprob:  0.466983, 0.125000 (1.439 sec)
22.498... logprob:  0.476289, 0.132812 (1.432 sec)
22.499... logprob:  0.456257, 0.125000 (1.431 sec)
22.500... logprob:  0.355107, 0.085938 (1.493 sec)
22.501... logprob:  0.339114, 0.078125 (1.436 sec)
22.502... logprob:  0.459639, 0.125000 (1.447 sec)
22.503... logprob:  0.400678, 0.101562 (1.475 sec)
22.504... logprob:  0.487318, 0.132812 (1.434 sec)
22.505... logprob:  0.570799, 0.164062 (1.443 sec)
22.506... logprob:  0.479684, 0.132812 (1.433 sec)
22.507... logprob:  0.385093, 0.093750 (1.429 sec)
22.508... logprob:  0.374716, 0.093750 (1.438 sec)
22.509... logprob:  0.323126, 0.070312 (1.476 sec)
22.510... logprob:  0.390474, 0.101562 (1.446 sec)
22.511... logprob:  0.410067, 0.109375 (1.453 sec)
22.512... logprob:  0.470733, 0.125000 (1.466 sec)
22.513... logprob:  0.324970, 0.078125 (1.442 sec)
22.514... logprob:  0.406275, 0.101562 (1.443 sec)
22.515... logprob:  0.455542, 0.125000 (1.432 sec)
22.516... logprob:  0.400351, 0.109375 (1.428 sec)
22.517... logprob:  0.627918, 0.179688 (1.439 sec)
22.518... logprob:  0.437685, 0.117188 (1.459 sec)
22.519... logprob:  0.516141, 0.140625 (1.455 sec)
22.520... logprob:  0.409651, 0.109375 (1.450 sec)
22.521... logprob:  0.427482, 0.109375 (1.449 sec)
22.522... logprob:  0.533108, 0.156250 (1.462 sec)
22.523... logprob:  0.331661, 0.078125 (1.464 sec)
22.524... logprob:  0.437199, 0.117188 (1.426 sec)
22.525... logprob:  0.426011, 0.109375 (1.437 sec)
22.526... logprob:  0.351838, 0.078125 (1.435 sec)
22.527... logprob:  0.504557, 0.140625 (1.438 sec)
22.528... logprob:  0.440490, 0.117188 (1.470 sec)
22.529... logprob:  0.353008, 0.085938 (1.454 sec)
22.530... logprob:  0.440250, 0.117188 (1.442 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.88945007324219, 10.0]}, 128)
batch 872: ({'logprob': [66.38811492919922, 19.0]}, 128)
batch 873: ({'logprob': [40.80335235595703, 9.0]}, 128)
batch 874: ({'logprob': [45.35000991821289, 11.0]}, 128)
batch 875: ({'logprob': [50.83183288574219, 13.0]}, 128)
batch 876: ({'logprob': [63.90163803100586, 18.0]}, 128)
batch 877: ({'logprob': [45.82621765136719, 11.0]}, 128)
batch 878: ({'logprob': [61.8421745300293, 17.0]}, 128)
batch 879: ({'logprob': [73.28305053710938, 21.0]}, 128)
batch 880: ({'logprob': [50.85314178466797, 13.0]}, 128)
batch 881: ({'logprob': [29.327804565429688, 5.0]}, 128)
batch 882: ({'logprob': [54.77039337158203, 14.0]}, 128)
batch 883: ({'logprob': [61.8201789855957, 17.0]}, 128)
batch 884: ({'logprob': [51.3061637878418, 13.0]}, 128)
batch 885: ({'logprob': [52.24497604370117, 13.0]}, 128)
batch 886: ({'logprob': [62.30587387084961, 17.0]}, 128)

======================Test output======================
logprob:  0.416379, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.964904e-03 [2.172653e-09] 
Layer 'conv1' biases: 2.489264e-07 [7.923359e-11] 
Layer 'conv2' weights[0]: 7.951991e-03 [2.159705e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.363168e-10] 
Layer 'conv3' weights[0]: 7.950227e-03 [2.002015e-09] 
Layer 'conv3' biases: 2.132840e-06 [9.878448e-10] 
Layer 'conv4' weights[0]: 7.982905e-03 [2.129697e-09] 
Layer 'conv4' biases: 9.999992e-01 [8.782701e-09] 
Layer 'conv5' weights[0]: 7.981722e-03 [5.738783e-08] 
Layer 'conv5' biases: 9.999945e-01 [6.174395e-08] 
Layer 'fc6' weights[0]: 7.578385e-03 [4.892066e-09] 
Layer 'fc6' biases: 9.999999e-01 [4.871274e-09] 
Layer 'fc7' weights[0]: 7.140686e-03 [1.807803e-07] 
Layer 'fc7' biases: 9.998611e-01 [1.694785e-07] 
Layer 'fc8' weights[0]: 1.293857e-03 [6.621097e-06] 
Layer 'fc8' biases: 5.379017e-02 [4.591452e-05] 
Train error last 870 batches: 0.435225
-------------------------------------------------------
Not saving because 0.416379 > 0.415685 (17.630: -0.01%)
======================================================= (12.031 sec)
22.531... logprob:  0.439986, 0.117188 (1.484 sec)
22.532... logprob:  0.467365, 0.125000 (1.434 sec)
22.533... logprob:  0.560550, 0.164062 (1.429 sec)
22.534... logprob:  0.325846, 0.078125 (1.433 sec)
22.535... logprob:  0.551583, 0.156250 (1.433 sec)
22.536... logprob:  0.507349, 0.140625 (1.431 sec)
22.537... logprob:  0.510049, 0.140625 (1.479 sec)
22.538... logprob:  0.486100, 0.132812 (1.440 sec)
22.539... logprob:  0.296096, 0.062500 (1.562 sec)
22.540... logprob:  0.447178, 0.117188 (1.489 sec)
22.541... logprob:  0.388849, 0.101562 (1.437 sec)
22.542... logprob:  0.411283, 0.109375 (1.435 sec)
22.543... logprob:  0.233320, 0.039062 (1.446 sec)
22.544... logprob:  0.317936, 0.070312 (1.431 sec)
22.545... logprob:  0.348806, 0.085938 (1.433 sec)
22.546... logprob:  0.368281, 0.093750 (1.485 sec)
22.547... logprob:  0.440092, 0.117188 (1.439 sec)
22.548... logprob:  0.453065, 0.125000 (1.442 sec)
22.549... logprob:  0.490603, 0.132812 (1.483 sec)
22.550... logprob:  0.367658, 0.093750 (1.433 sec)
22.551... logprob:  0.441730, 0.117188 (1.442 sec)
22.552... logprob:  0.471305, 0.125000 (1.434 sec)
22.553... logprob:  0.349441, 0.085938 (1.429 sec)
22.554... logprob:  0.506901, 0.140625 (1.436 sec)
22.555... logprob:  0.421410, 0.109375 (1.569 sec)
22.556... logprob:  0.355872, 0.085938 (1.463 sec)
22.557... logprob:  0.396435, 0.101562 (1.450 sec)
22.558... logprob:  0.383039, 0.101562 (1.478 sec)
22.559... logprob:  0.441513, 0.125000 (1.433 sec)
22.560... logprob:  0.335223, 0.078125 (1.443 sec)
22.561... logprob:  0.411822, 0.109375 (1.430 sec)
22.562... logprob:  0.503130, 0.140625 (1.429 sec)
22.563... logprob:  0.373824, 0.093750 (1.436 sec)
22.564... logprob:  0.468447, 0.132812 (1.470 sec)
22.565... logprob:  0.611076, 0.187500 (1.449 sec)
22.566... logprob:  0.374900, 0.093750 (1.459 sec)
22.567... logprob:  0.423391, 0.109375 (1.455 sec)
22.568... logprob:  0.496357, 0.140625 (1.454 sec)
22.569... logprob:  0.507790, 0.140625 (1.438 sec)
22.570... logprob:  0.543748, 0.164062 (1.429 sec)
22.571... logprob:  0.454878, 0.125000 (1.432 sec)
22.572... logprob:  0.501438, 0.140625 (1.442 sec)
22.573... logprob:  0.512615, 0.148438 (1.448 sec)
22.574... logprob:  0.428104, 0.109375 (1.466 sec)
22.575... logprob:  0.343345, 0.078125 (1.451 sec)
22.576... logprob:  0.427388, 0.109375 (1.448 sec)
22.577... logprob:  0.460821, 0.125000 (1.473 sec)
22.578... logprob:  0.336653, 0.078125 (1.428 sec)
22.579... logprob:  0.442084, 0.117188 (1.424 sec)
22.580... logprob:  0.546835, 0.156250 (1.435 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.412017822265625, 10.0]}, 128)
batch 872: ({'logprob': [66.26017761230469, 19.0]}, 128)
batch 873: ({'logprob': [41.19837951660156, 9.0]}, 128)
batch 874: ({'logprob': [45.32282638549805, 11.0]}, 128)
batch 875: ({'logprob': [50.9124755859375, 13.0]}, 128)
batch 876: ({'logprob': [63.8519401550293, 18.0]}, 128)
batch 877: ({'logprob': [46.06337356567383, 11.0]}, 128)
batch 878: ({'logprob': [62.1361083984375, 17.0]}, 128)
batch 879: ({'logprob': [74.05379486083984, 21.0]}, 128)
batch 880: ({'logprob': [50.932762145996094, 13.0]}, 128)
batch 881: ({'logprob': [29.24481201171875, 5.0]}, 128)
batch 882: ({'logprob': [55.564903259277344, 14.0]}, 128)
batch 883: ({'logprob': [62.114505767822266, 17.0]}, 128)
batch 884: ({'logprob': [51.65082931518555, 13.0]}, 128)
batch 885: ({'logprob': [53.11860656738281, 13.0]}, 128)
batch 886: ({'logprob': [62.86421203613281, 17.0]}, 128)

======================Test output======================
logprob:  0.418311, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.964868e-03 [2.395708e-09] 
Layer 'conv1' biases: 2.498945e-07 [4.524546e-11] 
Layer 'conv2' weights[0]: 7.951950e-03 [1.738597e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.529393e-10] 
Layer 'conv3' weights[0]: 7.950188e-03 [1.538166e-09] 
Layer 'conv3' biases: 2.139572e-06 [8.198938e-10] 
Layer 'conv4' weights[0]: 7.982869e-03 [1.560411e-09] 
Layer 'conv4' biases: 9.999993e-01 [6.292561e-09] 
Layer 'conv5' weights[0]: 7.981676e-03 [4.184875e-08] 
Layer 'conv5' biases: 9.999942e-01 [4.518148e-08] 
Layer 'fc6' weights[0]: 7.578346e-03 [3.581600e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.560156e-09] 
Layer 'fc7' weights[0]: 7.138852e-03 [1.695351e-07] 
Layer 'fc7' biases: 9.998615e-01 [1.581665e-07] 
Layer 'fc8' weights[0]: 1.298475e-03 [8.401559e-06] 
Layer 'fc8' biases: 5.393959e-02 [5.743391e-05] 
Train error last 870 batches: 0.435225
-------------------------------------------------------
Not saving because 0.418311 > 0.415685 (17.630: -0.01%)
======================================================= (12.012 sec)
22.581... logprob:  0.530868, 0.156250 (1.444 sec)
22.582... logprob:  0.437861, 0.125000 (1.438 sec)
22.583... logprob:  0.592701, 0.171875 (1.473 sec)
22.584... logprob:  0.468107, 0.132812 (1.446 sec)
22.585... logprob:  0.349763, 0.085938 (1.440 sec)
22.586... logprob:  0.313119, 0.070312 (1.488 sec)
22.587... logprob:  0.404307, 0.101562 (1.437 sec)
22.588... logprob:  0.418666, 0.117188 (1.426 sec)
22.589... logprob:  0.361244, 0.093750 (1.464 sec)
22.590... logprob:  0.524728, 0.148438 (1.435 sec)
22.591... logprob:  0.397494, 0.101562 (1.435 sec)
22.592... logprob:  0.455657, 0.125000 (1.478 sec)
22.593... logprob:  0.467428, 0.125000 (1.437 sec)
22.594... logprob:  0.352858, 0.085938 (1.445 sec)
22.595... logprob:  0.428665, 0.109375 (1.476 sec)
22.596... logprob:  0.461594, 0.125000 (1.432 sec)
22.597... logprob:  0.397414, 0.101562 (1.433 sec)
22.598... logprob:  0.397225, 0.101562 (1.439 sec)
22.599... logprob:  0.313537, 0.070312 (1.428 sec)
22.600... logprob:  0.340893, 0.085938 (1.440 sec)
22.601... logprob:  0.402134, 0.101562 (1.483 sec)
22.602... logprob:  0.289763, 0.062500 (1.441 sec)
22.603... logprob:  0.267036, 0.054688 (1.447 sec)
22.604... logprob:  0.407516, 0.101562 (1.475 sec)
22.605... logprob:  0.563471, 0.148438 (1.437 sec)
22.606... logprob:  0.295944, 0.070312 (1.438 sec)
22.607... logprob:  0.504832, 0.132812 (1.436 sec)
22.608... logprob:  0.361751, 0.085938 (1.424 sec)
22.609... logprob:  0.356967, 0.085938 (1.432 sec)
22.610... logprob:  0.493379, 0.132812 (1.472 sec)
22.611... logprob:  0.510404, 0.140625 (1.442 sec)
22.612... logprob:  0.448444, 0.117188 (1.453 sec)
22.613... logprob:  0.279621, 0.062500 (1.472 sec)
22.614... logprob:  0.503541, 0.140625 (1.453 sec)
22.615... logprob:  0.351032, 0.085938 (1.438 sec)
22.616... logprob:  0.415234, 0.109375 (1.430 sec)
22.617... logprob:  0.417917, 0.109375 (1.427 sec)
22.618... logprob:  0.546821, 0.156250 (1.433 sec)
22.619... logprob:  0.506007, 0.140625 (1.453 sec)
22.620... logprob:  0.539651, 0.156250 (1.458 sec)
22.621... logprob:  0.363791, 0.085938 (1.456 sec)
22.622... logprob:  0.364841, 0.085938 (1.450 sec)
22.623... logprob:  0.423184, 0.109375 (1.470 sec)
22.624... logprob:  0.382540, 0.093750 (1.441 sec)
22.625... logprob:  0.440995, 0.117188 (1.425 sec)
22.626... logprob:  0.438376, 0.117188 (1.435 sec)
22.627... logprob:  0.435847, 0.117188 (1.438 sec)
22.628... logprob:  0.465064, 0.125000 (1.439 sec)
22.629... logprob:  0.372052, 0.093750 (1.474 sec)
22.630... logprob:  0.422376, 0.109375 (1.469 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.75892639160156, 10.0]}, 128)
batch 872: ({'logprob': [67.12920379638672, 19.0]}, 128)
batch 873: ({'logprob': [40.054630279541016, 9.0]}, 128)
batch 874: ({'logprob': [45.08134078979492, 11.0]}, 128)
batch 875: ({'logprob': [50.738380432128906, 13.0]}, 128)
batch 876: ({'logprob': [64.47979736328125, 18.0]}, 128)
batch 877: ({'logprob': [45.40521240234375, 11.0]}, 128)
batch 878: ({'logprob': [62.103450775146484, 17.0]}, 128)
batch 879: ({'logprob': [73.74738311767578, 21.0]}, 128)
batch 880: ({'logprob': [50.76082992553711, 13.0]}, 128)
batch 881: ({'logprob': [28.375524520874023, 5.0]}, 128)
batch 882: ({'logprob': [54.38862609863281, 14.0]}, 128)
batch 883: ({'logprob': [62.08080291748047, 17.0]}, 128)
batch 884: ({'logprob': [51.063533782958984, 13.0]}, 128)
batch 885: ({'logprob': [51.699283599853516, 13.0]}, 128)
batch 886: ({'logprob': [62.416534423828125, 17.0]}, 128)

======================Test output======================
logprob:  0.415666, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.964833e-03 [2.445620e-09] 
Layer 'conv1' biases: 2.507805e-07 [3.188018e-11] 
Layer 'conv2' weights[0]: 7.951910e-03 [1.723171e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.544873e-10] 
Layer 'conv3' weights[0]: 7.950147e-03 [1.288665e-09] 
Layer 'conv3' biases: 2.147454e-06 [4.767113e-10] 
Layer 'conv4' weights[0]: 7.982831e-03 [1.358748e-09] 
Layer 'conv4' biases: 9.999993e-01 [3.482330e-09] 
Layer 'conv5' weights[0]: 7.981643e-03 [2.303446e-08] 
Layer 'conv5' biases: 9.999943e-01 [2.476390e-08] 
Layer 'fc6' weights[0]: 7.578307e-03 [2.098999e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.949361e-09] 
Layer 'fc7' weights[0]: 7.137050e-03 [1.919192e-07] 
Layer 'fc7' biases: 9.998612e-01 [1.806435e-07] 
Layer 'fc8' weights[0]: 1.316550e-03 [6.409257e-06] 
Layer 'fc8' biases: 5.423548e-02 [4.541473e-05] 
Train error last 870 batches: 0.435225
-------------------------------------------------------
Saved checkpoint to /data2/ad6813/my-nets/saves/ConvNet__2014-06-17_23.05.49
======================================================= (12.772 sec)
22.631... logprob:  0.638985, 0.187500 (1.448 sec)
22.632... logprob:  0.399107, 0.101562 (1.495 sec)
22.633... logprob:  0.376056, 0.093750 (1.440 sec)
22.634... logprob:  0.660321, 0.195312 (2.579 sec)
22.635... logprob:  0.374119, 0.093750 (1.436 sec)
22.636... logprob:  0.480244, 0.132812 (1.436 sec)
22.637... logprob:  0.330863, 0.078125 (3.081 sec)
22.638... logprob:  0.515686, 0.140625 (1.484 sec)
22.639... logprob:  0.418104, 0.109375 (1.450 sec)
22.640... logprob:  0.528751, 0.148438 (1.456 sec)
22.641... logprob:  0.410456, 0.109375 (1.488 sec)
22.642... logprob:  0.500848, 0.140625 (1.439 sec)
22.643... logprob:  0.623006, 0.187500 (1.433 sec)
22.644... logprob:  0.321234, 0.070312 (1.437 sec)
22.645... logprob:  0.414488, 0.109375 (1.432 sec)
22.646... logprob:  0.385688, 0.093750 (1.432 sec)
22.647... logprob:  0.456767, 0.125000 (1.489 sec)
22.648... logprob:  0.491242, 0.140625 (1.439 sec)
22.649... logprob:  0.370191, 0.093750 (1.453 sec)
22.650... logprob:  0.413971, 0.109375 (1.477 sec)
22.651... logprob:  0.397344, 0.101562 (1.434 sec)
22.652... logprob:  0.507271, 0.140625 (1.437 sec)
22.653... logprob:  0.547969, 0.156250 (1.436 sec)
22.654... logprob:  0.496089, 0.140625 (1.430 sec)
22.655... logprob:  0.436195, 0.117188 (1.456 sec)
22.656... logprob:  0.416689, 0.109375 (1.484 sec)
22.657... logprob:  0.449186, 0.117188 (1.438 sec)
22.658... logprob:  0.345806, 0.085938 (1.472 sec)
22.659... logprob:  0.464326, 0.125000 (1.481 sec)
22.660... logprob:  0.445958, 0.125000 (1.440 sec)
22.661... logprob:  0.378489, 0.093750 (1.453 sec)
22.662... logprob:  0.469386, 0.132812 (1.427 sec)
22.663... logprob:  0.310969, 0.070312 (1.433 sec)
22.664... logprob:  0.285442, 0.062500 (1.435 sec)
22.665... logprob:  0.401783, 0.101562 (1.463 sec)
22.666... logprob:  0.442050, 0.117188 (1.454 sec)
22.667... logprob:  0.564266, 0.164062 (1.455 sec)
22.668... logprob:  0.497882, 0.140625 (1.453 sec)
22.669... logprob:  0.433026, 0.109375 (1.465 sec)
22.670... logprob:  0.362437, 0.085938 (1.441 sec)
22.671... logprob:  0.360860, 0.093750 (1.429 sec)
22.672... logprob:  0.441819, 0.117188 (1.428 sec)
22.673... logprob:  0.436235, 0.117188 (1.441 sec)
22.674... logprob:  0.446652, 0.117188 (1.442 sec)
22.675... logprob:  0.356672, 0.093750 (1.472 sec)
22.676... logprob:  0.450162, 0.125000 (1.449 sec)
22.677... logprob:  0.471042, 0.125000 (1.447 sec)
22.678... logprob:  0.465651, 0.125000 (1.479 sec)
22.679... logprob:  0.454867, 0.125000 (1.436 sec)
22.680... logprob:  0.351705, 0.078125 (1.426 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.73610305786133, 10.0]}, 128)
batch 872: ({'logprob': [66.12654876708984, 19.0]}, 128)
batch 873: ({'logprob': [41.26096725463867, 9.0]}, 128)
batch 874: ({'logprob': [45.45484924316406, 11.0]}, 128)
batch 875: ({'logprob': [50.93272399902344, 13.0]}, 128)
batch 876: ({'logprob': [63.729007720947266, 18.0]}, 128)
batch 877: ({'logprob': [46.10529327392578, 11.0]}, 128)
batch 878: ({'logprob': [61.93311309814453, 17.0]}, 128)
batch 879: ({'logprob': [73.53707122802734, 21.0]}, 128)
batch 880: ({'logprob': [50.953392028808594, 13.0]}, 128)
batch 881: ({'logprob': [29.621620178222656, 5.0]}, 128)
batch 882: ({'logprob': [55.302677154541016, 14.0]}, 128)
batch 883: ({'logprob': [61.91130447387695, 17.0]}, 128)
batch 884: ({'logprob': [51.580047607421875, 13.0]}, 128)
batch 885: ({'logprob': [52.866355895996094, 13.0]}, 128)
batch 886: ({'logprob': [62.570289611816406, 17.0]}, 128)

======================Test output======================
logprob:  0.417784, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.964795e-03 [4.106042e-09] 
Layer 'conv1' biases: 2.515741e-07 [1.107658e-10] 
Layer 'conv2' weights[0]: 7.951875e-03 [2.493223e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.517509e-10] 
Layer 'conv3' weights[0]: 7.950108e-03 [2.256453e-09] 
Layer 'conv3' biases: 2.155333e-06 [1.271269e-09] 
Layer 'conv4' weights[0]: 7.982792e-03 [2.246896e-09] 
Layer 'conv4' biases: 9.999993e-01 [9.313033e-09] 
Layer 'conv5' weights[0]: 7.981600e-03 [5.211026e-08] 
Layer 'conv5' biases: 9.999947e-01 [5.604010e-08] 
Layer 'fc6' weights[0]: 7.578270e-03 [4.503415e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.488872e-09] 
Layer 'fc7' weights[0]: 7.135275e-03 [5.142055e-08] 
Layer 'fc7' biases: 9.998609e-01 [3.145428e-08] 
Layer 'fc8' weights[0]: 1.294990e-03 [4.145527e-06] 
Layer 'fc8' biases: 5.414429e-02 [2.730127e-05] 
Train error last 870 batches: 0.435224
-------------------------------------------------------
Not saving because 0.417784 > 0.415666 (22.630: -0.00%)
======================================================= (12.075 sec)
22.681... logprob:  0.373909, 0.093750 (1.441 sec)
22.682... logprob:  0.340487, 0.078125 (1.439 sec)
22.683... logprob:  0.411640, 0.109375 (1.428 sec)
22.684... logprob:  0.357640, 0.085938 (1.482 sec)
22.685... logprob:  0.285998, 0.054688 (1.445 sec)
22.686... logprob:  0.318635, 0.070312 (1.435 sec)
22.687... logprob:  0.281626, 0.062500 (1.491 sec)
22.688... logprob:  0.323105, 0.078125 (1.461 sec)
22.689... logprob:  0.471303, 0.125000 (1.435 sec)
22.690... logprob:  0.527820, 0.140625 (1.437 sec)
22.691... logprob:  0.516729, 0.140625 (1.437 sec)
22.692... logprob:  0.385110, 0.101562 (1.435 sec)
22.693... logprob:  0.455829, 0.125000 (1.487 sec)
22.694... logprob:  0.330913, 0.078125 (1.440 sec)
22.695... logprob:  0.356912, 0.085938 (1.443 sec)
22.696... logprob:  0.538978, 0.148438 (1.475 sec)
22.697... logprob:  0.465659, 0.125000 (1.438 sec)
22.698... logprob:  0.548735, 0.156250 (1.434 sec)
22.699... logprob:  0.459600, 0.125000 (1.440 sec)
22.700... logprob:  0.433947, 0.117188 (1.427 sec)
22.701... logprob:  0.423177, 0.109375 (1.438 sec)
22.702... logprob:  0.521497, 0.148438 (1.484 sec)
22.703... logprob:  0.405299, 0.101562 (1.438 sec)
22.704... logprob:  0.406175, 0.101562 (1.450 sec)
22.705... logprob:  0.420224, 0.109375 (1.477 sec)
22.706... logprob:  0.468070, 0.125000 (1.436 sec)
22.707... logprob:  0.485300, 0.132812 (1.440 sec)
22.708... logprob:  0.417123, 0.109375 (1.446 sec)
22.709... logprob:  0.422532, 0.109375 (1.422 sec)
22.710... logprob:  0.602480, 0.179688 (1.446 sec)
22.711... logprob:  0.469499, 0.125000 (1.462 sec)
22.712... logprob:  0.340592, 0.078125 (1.446 sec)
22.713... logprob:  0.586963, 0.179688 (1.456 sec)
22.714... logprob:  0.466293, 0.125000 (1.458 sec)
22.715... logprob:  0.417160, 0.109375 (1.459 sec)
22.716... logprob:  0.335345, 0.078125 (1.434 sec)
22.717... logprob:  0.429809, 0.117188 (1.425 sec)
22.718... logprob:  0.490353, 0.132812 (1.427 sec)
22.719... logprob:  0.406191, 0.109375 (1.437 sec)
22.720... logprob:  0.433233, 0.117188 (1.445 sec)
22.721... logprob:  0.451602, 0.117188 (1.460 sec)
22.722... logprob:  0.536921, 0.156250 (1.454 sec)
22.723... logprob:  0.416576, 0.109375 (1.441 sec)
22.724... logprob:  0.412770, 0.109375 (1.482 sec)
22.725... logprob:  0.494740, 0.140625 (1.433 sec)
22.726... logprob:  0.338565, 0.085938 (1.425 sec)
22.727... logprob:  0.393299, 0.101562 (1.437 sec)
22.728... logprob:  0.421298, 0.109375 (1.438 sec)
22.729... logprob:  0.387707, 0.093750 (1.440 sec)
22.730... logprob:  0.565865, 0.164062 (1.476 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.64693832397461, 10.0]}, 128)
batch 872: ({'logprob': [66.25401306152344, 19.0]}, 128)
batch 873: ({'logprob': [41.034542083740234, 9.0]}, 128)
batch 874: ({'logprob': [45.338775634765625, 11.0]}, 128)
batch 875: ({'logprob': [50.86075973510742, 13.0]}, 128)
batch 876: ({'logprob': [63.817962646484375, 18.0]}, 128)
batch 877: ({'logprob': [45.95597839355469, 11.0]}, 128)
batch 878: ({'logprob': [61.95022201538086, 17.0]}, 128)
batch 879: ({'logprob': [73.61042022705078, 21.0]}, 128)
batch 880: ({'logprob': [50.88154602050781, 13.0]}, 128)
batch 881: ({'logprob': [29.338764190673828, 5.0]}, 128)
batch 882: ({'logprob': [55.171104431152344, 14.0]}, 128)
batch 883: ({'logprob': [61.92842483520508, 17.0]}, 128)
batch 884: ({'logprob': [51.4757194519043, 13.0]}, 128)
batch 885: ({'logprob': [52.696266174316406, 13.0]}, 128)
batch 886: ({'logprob': [62.55469512939453, 17.0]}, 128)

======================Test output======================
logprob:  0.417244, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.964762e-03 [3.378824e-09] 
Layer 'conv1' biases: 2.524310e-07 [8.921514e-11] 
Layer 'conv2' weights[0]: 7.951835e-03 [2.552088e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.390481e-10] 
Layer 'conv3' weights[0]: 7.950070e-03 [2.291772e-09] 
Layer 'conv3' biases: 2.162077e-06 [1.365308e-09] 
Layer 'conv4' weights[0]: 7.982758e-03 [2.320464e-09] 
Layer 'conv4' biases: 9.999993e-01 [1.125476e-08] 
Layer 'conv5' weights[0]: 7.981564e-03 [7.459013e-08] 
Layer 'conv5' biases: 9.999942e-01 [8.042266e-08] 
Layer 'fc6' weights[0]: 7.578235e-03 [6.217341e-09] 
Layer 'fc6' biases: 9.999999e-01 [6.321609e-09] 
Layer 'fc7' weights[0]: 7.133442e-03 [5.012204e-08] 
Layer 'fc7' biases: 9.998609e-01 [2.974994e-08] 
Layer 'fc8' weights[0]: 1.299599e-03 [3.518050e-06] 
Layer 'fc8' biases: 5.439796e-02 [2.233181e-05] 
Train error last 870 batches: 0.435224
-------------------------------------------------------
Not saving because 0.417244 > 0.415666 (22.630: -0.00%)
======================================================= (12.092 sec)
22.731... logprob:  0.450361, 0.125000 (1.452 sec)
22.732... logprob:  0.311450, 0.070312 (1.438 sec)
22.733... logprob:  0.556603, 0.156250 (1.486 sec)
22.734... logprob:  0.340244, 0.078125 (1.436 sec)
22.735... logprob:  0.527534, 0.148438 (1.432 sec)
22.736... logprob:  0.642832, 0.187500 (1.434 sec)
22.737... logprob:  0.516156, 0.148438 (1.438 sec)
22.738... logprob:  0.459411, 0.125000 (1.431 sec)
22.739... logprob:  0.477803, 0.132812 (1.489 sec)
22.740... logprob:  0.339651, 0.078125 (1.434 sec)
22.741... logprob:  0.393457, 0.101562 (1.445 sec)
22.742... logprob:  0.419715, 0.109375 (1.485 sec)
22.743... logprob:  0.364876, 0.085938 (1.435 sec)
22.744... logprob:  0.519204, 0.148438 (1.431 sec)
22.745... logprob:  0.478158, 0.132812 (1.438 sec)
22.746... logprob:  0.440552, 0.117188 (1.434 sec)
22.747... logprob:  0.425614, 0.109375 (1.436 sec)
22.748... logprob:  0.378089, 0.093750 (1.485 sec)
22.749... logprob:  0.420827, 0.109375 (1.441 sec)
22.750... logprob:  0.512856, 0.140625 (1.446 sec)
22.751... logprob:  0.263605, 0.054688 (1.484 sec)
22.752... logprob:  0.522513, 0.140625 (1.439 sec)
22.753... logprob:  0.441208, 0.117188 (1.438 sec)
22.754... logprob:  0.468450, 0.132812 (1.437 sec)
22.755... logprob:  0.507085, 0.140625 (1.424 sec)
22.756... logprob:  0.440827, 0.117188 (1.440 sec)
22.757... logprob:  0.552366, 0.156250 (1.474 sec)
22.758... logprob:  0.393644, 0.101562 (1.446 sec)
22.759... logprob:  0.459694, 0.125000 (1.455 sec)
22.760... logprob:  0.485475, 0.132812 (1.460 sec)
22.761... logprob:  0.418287, 0.109375 (1.453 sec)
22.762... logprob:  0.516018, 0.148438 (1.438 sec)
22.763... logprob:  0.558873, 0.164062 (1.433 sec)
22.764... logprob:  0.503278, 0.140625 (1.426 sec)
22.765... logprob:  0.312023, 0.062500 (1.441 sec)
22.766... logprob:  0.482257, 0.132812 (1.459 sec)
22.767... logprob:  0.371134, 0.085938 (1.456 sec)
22.768... logprob:  0.432683, 0.117188 (1.477 sec)
22.769... logprob:  0.490854, 0.140625 (1.469 sec)
22.770... logprob:  0.402895, 0.101562 (1.483 sec)
22.771... logprob:  0.549544, 0.156250 (1.459 sec)
22.772... logprob:  0.414063, 0.109375 (1.444 sec)
22.773... logprob:  0.557937, 0.164062 (1.448 sec)
22.774... logprob:  0.361644, 0.085938 (1.466 sec)
22.775... logprob:  0.407352, 0.101562 (1.460 sec)
22.776... logprob:  0.433200, 0.117188 (1.481 sec)
22.777... logprob:  0.379944, 0.093750 (1.477 sec)
22.778... logprob:  0.433587, 0.117188 (1.463 sec)
22.779... logprob:  0.505411, 0.140625 (1.487 sec)
22.780... logprob:  0.385760, 0.101562 (1.529 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.48854446411133, 10.0]}, 128)
batch 872: ({'logprob': [66.88033294677734, 19.0]}, 128)
batch 873: ({'logprob': [40.25825500488281, 9.0]}, 128)
batch 874: ({'logprob': [45.028411865234375, 11.0]}, 128)
batch 875: ({'logprob': [50.70612716674805, 13.0]}, 128)
batch 876: ({'logprob': [64.28974914550781, 18.0]}, 128)
batch 877: ({'logprob': [45.49064636230469, 11.0]}, 128)
batch 878: ({'logprob': [62.111087799072266, 17.0]}, 128)
batch 879: ({'logprob': [73.93266296386719, 21.0]}, 128)
batch 880: ({'logprob': [50.72804641723633, 13.0]}, 128)
batch 881: ({'logprob': [28.400951385498047, 5.0]}, 128)
batch 882: ({'logprob': [54.711666107177734, 14.0]}, 128)
batch 883: ({'logprob': [62.088626861572266, 17.0]}, 128)
batch 884: ({'logprob': [51.169132232666016, 13.0]}, 128)
batch 885: ({'logprob': [52.08146286010742, 13.0]}, 128)
batch 886: ({'logprob': [62.56233596801758, 17.0]}, 128)

======================Test output======================
logprob:  0.415980, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.964727e-03 [2.867548e-09] 
Layer 'conv1' biases: 2.532499e-07 [5.898715e-11] 
Layer 'conv2' weights[0]: 7.951800e-03 [2.206526e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.817985e-10] 
Layer 'conv3' weights[0]: 7.950029e-03 [1.692355e-09] 
Layer 'conv3' biases: 2.169220e-06 [7.648265e-10] 
Layer 'conv4' weights[0]: 7.982717e-03 [1.609084e-09] 
Layer 'conv4' biases: 9.999993e-01 [4.263388e-09] 
Layer 'conv5' weights[0]: 7.981523e-03 [1.962985e-08] 
Layer 'conv5' biases: 9.999943e-01 [2.027568e-08] 
Layer 'fc6' weights[0]: 7.578194e-03 [1.791429e-09] 
Layer 'fc6' biases: 9.999999e-01 [1.623367e-09] 
Layer 'fc7' weights[0]: 7.131625e-03 [5.213071e-08] 
Layer 'fc7' biases: 9.998613e-01 [3.189258e-08] 
Layer 'fc8' weights[0]: 1.315939e-03 [3.522418e-06] 
Layer 'fc8' biases: 5.465088e-02 [2.373864e-05] 
Train error last 870 batches: 0.435224
-------------------------------------------------------
Not saving because 0.415980 > 0.415666 (22.630: -0.00%)
======================================================= (12.103 sec)
22.781... logprob:  0.369679, 0.085938 (1.455 sec)
22.782... logprob:  0.351459, 0.085938 (1.454 sec)
22.783... logprob:  0.555499, 0.156250 (1.461 sec)
22.784... logprob:  0.440956, 0.117188 (1.461 sec)
22.785... logprob:  0.543613, 0.156250 (1.488 sec)
22.786... logprob:  0.477470, 0.132812 (1.470 sec)
22.787... logprob:  0.546327, 0.156250 (1.459 sec)
22.788... logprob:  0.563062, 0.164062 (1.497 sec)
22.789... logprob:  0.281101, 0.054688 (1.457 sec)
22.790... logprob:  0.408143, 0.101562 (1.446 sec)
22.791... logprob:  0.398025, 0.101562 (1.451 sec)
22.792... logprob:  0.361106, 0.085938 (1.460 sec)
22.793... logprob:  0.370194, 0.085938 (1.460 sec)
22.794... logprob:  0.387130, 0.093750 (1.496 sec)
22.795... logprob:  0.469778, 0.125000 (1.471 sec)
22.796... logprob:  0.423504, 0.109375 (1.458 sec)
22.797... logprob:  0.358787, 0.085938 (1.503 sec)
22.798... logprob:  0.393278, 0.101562 (1.451 sec)
22.799... logprob:  0.332304, 0.078125 (1.453 sec)
22.800... logprob:  0.371740, 0.093750 (1.496 sec)
22.801... logprob:  0.450165, 0.117188 (1.463 sec)
22.802... logprob:  0.423031, 0.109375 (1.452 sec)
22.803... logprob:  0.491767, 0.132812 (1.485 sec)
22.804... logprob:  0.349967, 0.085938 (1.463 sec)
22.805... logprob:  0.452289, 0.117188 (1.452 sec)
22.806... logprob:  0.424183, 0.109375 (1.516 sec)
22.807... logprob:  0.443467, 0.117188 (1.449 sec)
22.808... logprob:  0.462355, 0.125000 (1.456 sec)
22.809... logprob:  0.589615, 0.171875 (1.449 sec)
22.810... logprob:  0.442462, 0.117188 (1.459 sec)
22.811... logprob:  0.460418, 0.125000 (1.450 sec)
22.812... logprob:  0.462379, 0.125000 (1.493 sec)
22.813... logprob:  0.485967, 0.132812 (1.460 sec)
22.814... logprob:  0.478046, 0.132812 (1.459 sec)
22.815... logprob:  0.371973, 0.085938 (1.502 sec)
22.816... logprob:  0.408783, 0.101562 (1.451 sec)
22.817... logprob:  0.426005, 0.109375 (1.451 sec)
22.818... logprob:  0.559983, 0.164062 (1.445 sec)
22.819... logprob:  0.498201, 0.140625 (1.463 sec)
22.820... logprob:  0.421608, 0.109375 (1.449 sec)
22.821... logprob:  0.406548, 0.101562 (1.500 sec)
22.822... logprob:  0.441164, 0.117188 (1.461 sec)
22.823... logprob:  0.340741, 0.078125 (1.461 sec)
22.824... logprob:  0.489852, 0.132812 (1.496 sec)
22.825... logprob:  0.287879, 0.062500 (1.459 sec)
22.826... logprob:  0.375449, 0.093750 (1.454 sec)
22.827... logprob:  0.420562, 0.109375 (1.449 sec)
22.828... logprob:  0.443432, 0.117188 (1.455 sec)
22.829... logprob:  0.504309, 0.140625 (1.457 sec)
22.830... logprob:  0.442232, 0.117188 (1.509 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.254432678222656, 10.0]}, 128)
batch 872: ({'logprob': [68.31090545654297, 19.0]}, 128)
batch 873: ({'logprob': [39.420204162597656, 9.0]}, 128)
batch 874: ({'logprob': [44.7906379699707, 11.0]}, 128)
batch 875: ({'logprob': [50.822792053222656, 13.0]}, 128)
batch 876: ({'logprob': [65.48257446289062, 18.0]}, 128)
batch 877: ({'logprob': [45.1295280456543, 11.0]}, 128)
batch 878: ({'logprob': [62.94131851196289, 17.0]}, 128)
batch 879: ({'logprob': [75.35472106933594, 21.0]}, 128)
batch 880: ({'logprob': [50.84579849243164, 13.0]}, 128)
batch 881: ({'logprob': [26.970230102539062, 5.0]}, 128)
batch 882: ({'logprob': [54.704345703125, 14.0]}, 128)
batch 883: ({'logprob': [62.91849136352539, 17.0]}, 128)
batch 884: ({'logprob': [51.16701126098633, 13.0]}, 128)
batch 885: ({'logprob': [51.83588409423828, 13.0]}, 128)
batch 886: ({'logprob': [63.2723274230957, 17.0]}, 128)

======================Test output======================
logprob:  0.417588, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.964684e-03 [4.590702e-09] 
Layer 'conv1' biases: 2.542634e-07 [1.413544e-10] 
Layer 'conv2' weights[0]: 7.951765e-03 [3.994472e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.958331e-10] 
Layer 'conv3' weights[0]: 7.949991e-03 [3.780861e-09] 
Layer 'conv3' biases: 2.176893e-06 [2.421439e-09] 
Layer 'conv4' weights[0]: 7.982677e-03 [3.763311e-09] 
Layer 'conv4' biases: 9.999993e-01 [2.018201e-08] 
Layer 'conv5' weights[0]: 7.981485e-03 [1.271813e-07] 
Layer 'conv5' biases: 9.999942e-01 [1.372184e-07] 
Layer 'fc6' weights[0]: 7.578160e-03 [1.067208e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.088898e-08] 
Layer 'fc7' weights[0]: 7.129797e-03 [5.320594e-08] 
Layer 'fc7' biases: 9.998621e-01 [3.334286e-08] 
Layer 'fc8' weights[0]: 1.345924e-03 [5.686297e-06] 
Layer 'fc8' biases: 5.510983e-02 [3.176360e-05] 
Train error last 870 batches: 0.435223
-------------------------------------------------------
Not saving because 0.417588 > 0.415666 (22.630: -0.00%)
======================================================= (12.037 sec)
22.831... logprob:  0.514021, 0.140625 (1.457 sec)
22.832... logprob:  0.330848, 0.078125 (1.466 sec)
22.833... logprob:  0.489001, 0.132812 (1.503 sec)
22.834... logprob:  0.433275, 0.117188 (1.452 sec)
22.835... logprob:  0.542669, 0.148438 (1.459 sec)
22.836... logprob:  0.376229, 0.093750 (1.454 sec)
22.837... logprob:  0.314462, 0.070312 (1.448 sec)
22.838... logprob:  0.437077, 0.117188 (1.451 sec)
22.839... logprob:  0.471691, 0.125000 (1.501 sec)
22.840... logprob:  0.555373, 0.156250 (1.451 sec)
22.841... logprob:  0.396162, 0.101562 (1.463 sec)
22.842... logprob:  0.497836, 0.140625 (1.504 sec)
22.843... logprob:  0.465529, 0.125000 (1.452 sec)
22.844... logprob:  0.497636, 0.140625 (1.463 sec)
22.845... logprob:  0.486790, 0.132812 (1.445 sec)
22.846... logprob:  0.468449, 0.125000 (1.455 sec)
22.847... logprob:  0.363283, 0.085938 (1.450 sec)
22.848... logprob:  0.397113, 0.101562 (1.504 sec)
22.849... logprob:  0.360404, 0.085938 (1.458 sec)
22.850... logprob:  0.479408, 0.132812 (1.470 sec)
22.851... logprob:  0.440144, 0.117188 (1.498 sec)
22.852... logprob:  0.545655, 0.156250 (1.454 sec)
22.853... logprob:  0.371877, 0.093750 (1.465 sec)
22.854... logprob:  0.307168, 0.070312 (1.451 sec)
22.855... logprob:  0.484863, 0.132812 (1.443 sec)
22.856... logprob:  0.443795, 0.117188 (1.457 sec)
22.857... logprob:  0.372231, 0.093750 (1.498 sec)
22.858... logprob:  0.396246, 0.101562 (1.458 sec)
22.859... logprob:  0.307964, 0.070312 (1.472 sec)
22.860... logprob:  0.565975, 0.156250 (1.492 sec)
22.861... logprob:  0.417809, 0.109375 (1.459 sec)
22.862... logprob:  0.328888, 0.078125 (1.458 sec)
22.863... logprob:  0.399543, 0.101562 (1.450 sec)
22.864... logprob:  0.451438, 0.117188 (1.446 sec)
22.865... logprob:  0.484494, 0.132812 (1.462 sec)
22.866... logprob:  0.507633, 0.140625 (1.486 sec)
22.867... logprob:  0.502979, 0.140625 (1.468 sec)
22.868... logprob:  0.405311, 0.101562 (1.474 sec)
22.869... logprob:  0.383223, 0.093750 (1.480 sec)
22.870... logprob:  0.552075, 0.156250 (1.422 sec)
23.1... logprob:  0.380064, 0.093750 (1.408 sec)
23.2... logprob:  0.448266, 0.117188 (1.450 sec)
23.3... logprob:  0.398349, 0.101562 (1.430 sec)
23.4... logprob:  0.443325, 0.117188 (1.408 sec)
23.5... logprob:  0.443452, 0.117188 (1.429 sec)
23.6... logprob:  0.499128, 0.140625 (1.396 sec)
23.7... logprob:  0.363169, 0.085938 (1.416 sec)
23.8... logprob:  0.419136, 0.109375 (1.392 sec)
23.9... logprob:  0.358785, 0.085938 (1.404 sec)
23.10... logprob:  0.377486, 0.093750 (1.411 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.161312103271484, 10.0]}, 128)
batch 872: ({'logprob': [67.08329772949219, 19.0]}, 128)
batch 873: ({'logprob': [40.1894416809082, 9.0]}, 128)
batch 874: ({'logprob': [45.29066467285156, 11.0]}, 128)
batch 875: ({'logprob': [50.83787155151367, 13.0]}, 128)
batch 876: ({'logprob': [64.44287109375, 18.0]}, 128)
batch 877: ({'logprob': [45.522727966308594, 11.0]}, 128)
batch 878: ({'logprob': [61.98350524902344, 17.0]}, 128)
batch 879: ({'logprob': [73.31642150878906, 21.0]}, 128)
batch 880: ({'logprob': [50.86061096191406, 13.0]}, 128)
batch 881: ({'logprob': [28.822114944458008, 5.0]}, 128)
batch 882: ({'logprob': [54.20305633544922, 14.0]}, 128)
batch 883: ({'logprob': [61.96065902709961, 17.0]}, 128)
batch 884: ({'logprob': [51.07059097290039, 13.0]}, 128)
batch 885: ({'logprob': [51.52235794067383, 13.0]}, 128)
batch 886: ({'logprob': [62.204341888427734, 17.0]}, 128)

======================Test output======================
logprob:  0.415758, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.964648e-03 [3.274087e-09] 
Layer 'conv1' biases: 2.552885e-07 [1.185410e-10] 
Layer 'conv2' weights[0]: 7.951729e-03 [2.894057e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.966039e-10] 
Layer 'conv3' weights[0]: 7.949946e-03 [2.920344e-09] 
Layer 'conv3' biases: 2.184580e-06 [1.837981e-09] 
Layer 'conv4' weights[0]: 7.982636e-03 [3.095852e-09] 
Layer 'conv4' biases: 9.999993e-01 [1.707543e-08] 
Layer 'conv5' weights[0]: 7.981450e-03 [1.122864e-07] 
Layer 'conv5' biases: 9.999942e-01 [1.211033e-07] 
Layer 'fc6' weights[0]: 7.578114e-03 [9.409211e-09] 
Layer 'fc6' biases: 9.999999e-01 [9.488058e-09] 
Layer 'fc7' weights[0]: 7.128026e-03 [2.884910e-07] 
Layer 'fc7' biases: 9.998608e-01 [2.782064e-07] 
Layer 'fc8' weights[0]: 1.301161e-03 [1.055840e-05] 
Layer 'fc8' biases: 5.499430e-02 [7.269956e-05] 
Train error last 870 batches: 0.435223
-------------------------------------------------------
Not saving because 0.415758 > 0.415666 (22.630: -0.00%)
======================================================= (12.006 sec)
23.11... logprob:  0.334728, 0.078125 (1.444 sec)
23.12... logprob:  0.466402, 0.125000 (1.396 sec)
23.13... logprob:  0.442274, 0.117188 (1.425 sec)
23.14... logprob:  0.444657, 0.117188 (1.394 sec)
23.15... logprob:  0.395573, 0.101562 (1.408 sec)
23.16... logprob:  0.421411, 0.109375 (1.410 sec)
23.17... logprob:  0.516027, 0.140625 (1.394 sec)
23.18... logprob:  0.262104, 0.054688 (1.405 sec)
23.19... logprob:  0.279549, 0.062500 (1.408 sec)
23.20... logprob:  0.421373, 0.109375 (1.402 sec)
23.21... logprob:  0.443972, 0.117188 (1.408 sec)
23.22... logprob:  0.536683, 0.148438 (1.410 sec)
23.23... logprob:  0.532979, 0.148438 (1.418 sec)
23.24... logprob:  0.310620, 0.070312 (1.420 sec)
23.25... logprob:  0.356219, 0.085938 (1.400 sec)
23.26... logprob:  0.463737, 0.125000 (1.452 sec)
23.27... logprob:  0.404552, 0.101562 (1.392 sec)
23.28... logprob:  0.421859, 0.109375 (1.410 sec)
23.29... logprob:  0.395987, 0.101562 (1.426 sec)
23.30... logprob:  0.374118, 0.093750 (1.423 sec)
23.31... logprob:  0.479938, 0.132812 (1.402 sec)
23.32... logprob:  0.457227, 0.125000 (1.391 sec)
23.33... logprob:  0.460677, 0.125000 (1.470 sec)
23.34... logprob:  0.464571, 0.125000 (1.397 sec)
23.35... logprob:  0.316268, 0.070312 (1.397 sec)
23.36... logprob:  0.475795, 0.132812 (1.404 sec)
23.37... logprob:  0.417592, 0.109375 (1.435 sec)
23.38... logprob:  0.392607, 0.101562 (1.401 sec)
23.39... logprob:  0.631653, 0.187500 (1.439 sec)
23.40... logprob:  0.445751, 0.117188 (1.411 sec)
23.41... logprob:  0.352884, 0.085938 (1.428 sec)
23.42... logprob:  0.391933, 0.101562 (1.424 sec)
23.43... logprob:  0.440094, 0.117188 (1.410 sec)
23.44... logprob:  0.518540, 0.148438 (1.438 sec)
23.45... logprob:  0.381748, 0.093750 (1.396 sec)
23.46... logprob:  0.486265, 0.132812 (1.402 sec)
23.47... logprob:  0.331735, 0.078125 (1.394 sec)
23.48... logprob:  0.498911, 0.140625 (1.429 sec)
23.49... logprob:  0.510776, 0.148438 (1.419 sec)
23.50... logprob:  0.393209, 0.101562 (1.430 sec)
23.51... logprob:  0.490150, 0.140625 (1.416 sec)
23.52... logprob:  0.525784, 0.148438 (1.401 sec)
23.53... logprob:  0.294906, 0.062500 (1.445 sec)
23.54... logprob:  0.403333, 0.109375 (1.390 sec)
23.55... logprob:  0.331738, 0.078125 (1.397 sec)
23.56... logprob:  0.421658, 0.109375 (1.408 sec)
23.57... logprob:  0.572427, 0.164062 (1.428 sec)
23.58... logprob:  0.407644, 0.101562 (1.405 sec)
23.59... logprob:  0.333864, 0.078125 (1.466 sec)
23.60... logprob:  0.618859, 0.179688 (1.424 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.3577766418457, 10.0]}, 128)
batch 872: ({'logprob': [66.43572998046875, 19.0]}, 128)
batch 873: ({'logprob': [40.864322662353516, 9.0]}, 128)
batch 874: ({'logprob': [45.17947006225586, 11.0]}, 128)
batch 875: ({'logprob': [50.811275482177734, 13.0]}, 128)
batch 876: ({'logprob': [63.96986770629883, 18.0]}, 128)
batch 877: ({'logprob': [45.845970153808594, 11.0]}, 128)
batch 878: ({'logprob': [62.121219635009766, 17.0]}, 128)
batch 879: ({'logprob': [74.05107879638672, 21.0]}, 128)
batch 880: ({'logprob': [50.83224105834961, 13.0]}, 128)
batch 881: ({'logprob': [28.89824104309082, 5.0]}, 128)
batch 882: ({'logprob': [55.30135726928711, 14.0]}, 128)
batch 883: ({'logprob': [62.09920120239258, 17.0]}, 128)
batch 884: ({'logprob': [51.47662353515625, 13.0]}, 128)
batch 885: ({'logprob': [52.79653549194336, 13.0]}, 128)
batch 886: ({'logprob': [62.775794982910156, 17.0]}, 128)

======================Test output======================
logprob:  0.417391, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.964609e-03 [4.055243e-09] 
Layer 'conv1' biases: 2.562128e-07 [1.348156e-10] 
Layer 'conv2' weights[0]: 7.951690e-03 [3.227901e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.040269e-10] 
Layer 'conv3' weights[0]: 7.949911e-03 [3.355923e-09] 
Layer 'conv3' biases: 2.192914e-06 [2.197980e-09] 
Layer 'conv4' weights[0]: 7.982592e-03 [3.432897e-09] 
Layer 'conv4' biases: 9.999993e-01 [1.976594e-08] 
Layer 'conv5' weights[0]: 7.981403e-03 [1.309093e-07] 
Layer 'conv5' biases: 9.999943e-01 [1.411489e-07] 
Layer 'fc6' weights[0]: 7.578066e-03 [1.088204e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.111450e-08] 
Layer 'fc7' weights[0]: 7.126243e-03 [9.996702e-08] 
Layer 'fc7' biases: 9.998612e-01 [8.646306e-08] 
Layer 'fc8' weights[0]: 1.303859e-03 [2.846016e-06] 
Layer 'fc8' biases: 5.505306e-02 [1.723881e-05] 
Train error last 870 batches: 0.435223
-------------------------------------------------------
Not saving because 0.417391 > 0.415666 (22.630: -0.00%)
======================================================= (12.039 sec)
23.61... logprob:  0.382831, 0.093750 (1.440 sec)
23.62... logprob:  0.474866, 0.132812 (1.467 sec)
23.63... logprob:  0.397298, 0.101562 (1.442 sec)
23.64... logprob:  0.450299, 0.125000 (1.412 sec)
23.65... logprob:  0.373354, 0.093750 (1.399 sec)
23.66... logprob:  0.354025, 0.085938 (1.448 sec)
23.67... logprob:  0.295405, 0.062500 (1.388 sec)
23.68... logprob:  0.396807, 0.101562 (1.399 sec)
23.69... logprob:  0.496740, 0.140625 (1.420 sec)
23.70... logprob:  0.325889, 0.078125 (1.426 sec)
23.71... logprob:  0.381816, 0.101562 (1.473 sec)
23.72... logprob:  0.493762, 0.132812 (1.406 sec)
23.73... logprob:  0.447724, 0.117188 (1.420 sec)
23.74... logprob:  0.442548, 0.117188 (1.422 sec)
23.75... logprob:  0.380649, 0.093750 (1.414 sec)
23.76... logprob:  0.412063, 0.109375 (1.441 sec)
23.77... logprob:  0.396343, 0.101562 (1.424 sec)
23.78... logprob:  0.493059, 0.140625 (1.461 sec)
23.79... logprob:  0.456459, 0.125000 (1.404 sec)
23.80... logprob:  0.507963, 0.132812 (1.421 sec)
23.81... logprob:  0.416724, 0.109375 (1.417 sec)
23.82... logprob:  0.231488, 0.039062 (1.426 sec)
23.83... logprob:  0.493777, 0.140625 (1.401 sec)
23.84... logprob:  0.468117, 0.125000 (1.468 sec)
23.85... logprob:  0.431971, 0.117188 (1.422 sec)
23.86... logprob:  0.416954, 0.109375 (1.420 sec)
23.87... logprob:  0.633246, 0.187500 (1.412 sec)
23.88... logprob:  0.535053, 0.156250 (1.416 sec)
23.89... logprob:  0.410584, 0.109375 (1.441 sec)
23.90... logprob:  0.577492, 0.171875 (1.394 sec)
23.91... logprob:  0.348479, 0.078125 (1.396 sec)
23.92... logprob:  0.464461, 0.125000 (1.404 sec)
23.93... logprob:  0.492240, 0.140625 (1.398 sec)
23.94... logprob:  0.428783, 0.109375 (1.404 sec)
23.95... logprob:  0.471842, 0.125000 (1.404 sec)
23.96... logprob:  0.576256, 0.171875 (1.407 sec)
23.97... logprob:  0.430773, 0.117188 (1.395 sec)
23.98... logprob:  0.391127, 0.093750 (1.435 sec)
23.99... logprob:  0.474259, 0.132812 (1.411 sec)
23.100... logprob:  0.310503, 0.070312 (1.399 sec)
23.101... logprob:  0.310742, 0.062500 (1.449 sec)
23.102... logprob:  0.546110, 0.156250 (1.389 sec)
23.103... logprob:  0.541106, 0.156250 (1.398 sec)
23.104... logprob:  0.388836, 0.101562 (1.410 sec)
23.105... logprob:  0.619512, 0.179688 (1.403 sec)
23.106... logprob:  0.344449, 0.085938 (1.396 sec)
23.107... logprob:  0.335750, 0.078125 (1.439 sec)
23.108... logprob:  0.586842, 0.171875 (1.398 sec)
23.109... logprob:  0.336158, 0.078125 (1.404 sec)
23.110... logprob:  0.564563, 0.164062 (1.403 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.71672058105469, 10.0]}, 128)
batch 872: ({'logprob': [66.4718246459961, 19.0]}, 128)
batch 873: ({'logprob': [40.688934326171875, 9.0]}, 128)
batch 874: ({'logprob': [45.24510955810547, 11.0]}, 128)
batch 875: ({'logprob': [50.786346435546875, 13.0]}, 128)
batch 876: ({'logprob': [63.968666076660156, 18.0]}, 128)
batch 877: ({'logprob': [45.746341705322266, 11.0]}, 128)
batch 878: ({'logprob': [61.91661834716797, 17.0]}, 128)
batch 879: ({'logprob': [73.50186920166016, 21.0]}, 128)
batch 880: ({'logprob': [50.80793380737305, 13.0]}, 128)
batch 881: ({'logprob': [29.068344116210938, 5.0]}, 128)
batch 882: ({'logprob': [54.81819534301758, 14.0]}, 128)
batch 883: ({'logprob': [61.894264221191406, 17.0]}, 128)
batch 884: ({'logprob': [51.28644943237305, 13.0]}, 128)
batch 885: ({'logprob': [52.27537536621094, 13.0]}, 128)
batch 886: ({'logprob': [62.40562438964844, 17.0]}, 128)

======================Test output======================
logprob:  0.416308, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.964579e-03 [3.675899e-09] 
Layer 'conv1' biases: 2.570479e-07 [1.143384e-10] 
Layer 'conv2' weights[0]: 7.951649e-03 [3.590170e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.367451e-10] 
Layer 'conv3' weights[0]: 7.949874e-03 [3.312222e-09] 
Layer 'conv3' biases: 2.200402e-06 [1.968134e-09] 
Layer 'conv4' weights[0]: 7.982554e-03 [3.441647e-09] 
Layer 'conv4' biases: 9.999992e-01 [1.722039e-08] 
Layer 'conv5' weights[0]: 7.981355e-03 [1.118087e-07] 
Layer 'conv5' biases: 9.999945e-01 [1.202055e-07] 
Layer 'fc6' weights[0]: 7.578029e-03 [9.429516e-09] 
Layer 'fc6' biases: 9.999999e-01 [9.509611e-09] 
Layer 'fc7' weights[0]: 7.124438e-03 [1.737070e-07] 
Layer 'fc7' biases: 9.998609e-01 [1.633657e-07] 
Layer 'fc8' weights[0]: 1.298756e-03 [6.624057e-06] 
Layer 'fc8' biases: 5.512723e-02 [4.065298e-05] 
Train error last 870 batches: 0.435223
-------------------------------------------------------
Not saving because 0.416308 > 0.415666 (22.630: -0.00%)
======================================================= (12.017 sec)
23.111... logprob:  0.404694, 0.101562 (1.399 sec)
23.112... logprob:  0.366078, 0.093750 (1.413 sec)
23.113... logprob:  0.354535, 0.085938 (1.402 sec)
23.114... logprob:  0.440219, 0.117188 (1.440 sec)
23.115... logprob:  0.506752, 0.140625 (1.418 sec)
23.116... logprob:  0.393374, 0.101562 (1.400 sec)
23.117... logprob:  0.440393, 0.117188 (1.447 sec)
23.118... logprob:  0.409125, 0.101562 (1.395 sec)
23.119... logprob:  0.346107, 0.085938 (1.405 sec)
23.120... logprob:  0.547135, 0.156250 (1.399 sec)
23.121... logprob:  0.412631, 0.109375 (1.400 sec)
23.122... logprob:  0.519303, 0.148438 (1.444 sec)
23.123... logprob:  0.463704, 0.125000 (1.393 sec)
23.124... logprob:  0.447698, 0.125000 (1.403 sec)
23.125... logprob:  0.501954, 0.140625 (1.405 sec)
23.126... logprob:  0.475767, 0.125000 (1.397 sec)
23.127... logprob:  0.479558, 0.125000 (1.405 sec)
23.128... logprob:  0.422352, 0.109375 (1.424 sec)
23.129... logprob:  0.574890, 0.164062 (1.422 sec)
23.130... logprob:  0.382722, 0.093750 (1.416 sec)
23.131... logprob:  0.495497, 0.132812 (1.412 sec)
23.132... logprob:  0.506369, 0.140625 (1.441 sec)
23.133... logprob:  0.444684, 0.117188 (1.389 sec)
23.134... logprob:  0.401889, 0.101562 (1.405 sec)
23.135... logprob:  0.460210, 0.125000 (1.407 sec)
23.136... logprob:  0.562461, 0.164062 (1.402 sec)
23.137... logprob:  0.462578, 0.125000 (1.401 sec)
23.138... logprob:  0.319372, 0.070312 (1.453 sec)
23.139... logprob:  0.395761, 0.101562 (1.400 sec)
23.140... logprob:  0.560262, 0.164062 (1.416 sec)
23.141... logprob:  0.464560, 0.125000 (1.440 sec)
23.142... logprob:  0.464624, 0.125000 (1.404 sec)
23.143... logprob:  0.294347, 0.062500 (1.420 sec)
23.144... logprob:  0.457162, 0.125000 (1.417 sec)
23.145... logprob:  0.324793, 0.078125 (1.414 sec)
23.146... logprob:  0.483153, 0.132812 (1.430 sec)
23.147... logprob:  0.262476, 0.054688 (1.435 sec)
23.148... logprob:  0.458710, 0.125000 (1.392 sec)
23.149... logprob:  0.442528, 0.117188 (1.397 sec)
23.150... logprob:  0.347598, 0.085938 (1.422 sec)
23.151... logprob:  0.347145, 0.085938 (1.400 sec)
23.152... logprob:  0.785076, 0.234375 (1.400 sec)
23.153... logprob:  0.381653, 0.093750 (1.444 sec)
23.154... logprob:  0.524550, 0.148438 (1.402 sec)
23.155... logprob:  0.426048, 0.117188 (1.410 sec)
23.156... logprob:  0.295527, 0.062500 (1.436 sec)
23.157... logprob:  0.270436, 0.054688 (1.396 sec)
23.158... logprob:  0.455405, 0.125000 (1.405 sec)
23.159... logprob:  0.483118, 0.132812 (1.398 sec)
23.160... logprob:  0.444787, 0.117188 (1.403 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.91109085083008, 10.0]}, 128)
batch 872: ({'logprob': [66.12483978271484, 19.0]}, 128)
batch 873: ({'logprob': [41.21841812133789, 9.0]}, 128)
batch 874: ({'logprob': [45.50322341918945, 11.0]}, 128)
batch 875: ({'logprob': [50.93391418457031, 13.0]}, 128)
batch 876: ({'logprob': [63.716827392578125, 18.0]}, 128)
batch 877: ({'logprob': [46.0849723815918, 11.0]}, 128)
batch 878: ({'logprob': [61.840938568115234, 17.0]}, 128)
batch 879: ({'logprob': [73.28250885009766, 21.0]}, 128)
batch 880: ({'logprob': [50.955047607421875, 13.0]}, 128)
batch 881: ({'logprob': [29.741497039794922, 5.0]}, 128)
batch 882: ({'logprob': [55.10860061645508, 14.0]}, 128)
batch 883: ({'logprob': [61.818763732910156, 17.0]}, 128)
batch 884: ({'logprob': [51.51251220703125, 13.0]}, 128)
batch 885: ({'logprob': [52.66105270385742, 13.0]}, 128)
batch 886: ({'logprob': [62.409202575683594, 17.0]}, 128)

======================Test output======================
logprob:  0.417394, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.964536e-03 [2.177068e-09] 
Layer 'conv1' biases: 2.579104e-07 [3.962429e-11] 
Layer 'conv2' weights[0]: 7.951612e-03 [1.585428e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.352159e-10] 
Layer 'conv3' weights[0]: 7.949842e-03 [1.211367e-09] 
Layer 'conv3' biases: 2.208160e-06 [3.807222e-10] 
Layer 'conv4' weights[0]: 7.982518e-03 [1.139328e-09] 
Layer 'conv4' biases: 9.999993e-01 [1.613405e-09] 
Layer 'conv5' weights[0]: 7.981315e-03 [7.166789e-09] 
Layer 'conv5' biases: 9.999943e-01 [7.251331e-09] 
Layer 'fc6' weights[0]: 7.577984e-03 [9.552032e-10] 
Layer 'fc6' biases: 9.999999e-01 [5.557965e-10] 
Layer 'fc7' weights[0]: 7.122627e-03 [4.344858e-08] 
Layer 'fc7' biases: 9.998605e-01 [2.024946e-08] 
Layer 'fc8' weights[0]: 1.290849e-03 [4.476074e-06] 
Layer 'fc8' biases: 5.515955e-02 [2.687863e-05] 
Train error last 870 batches: 0.435223
-------------------------------------------------------
Not saving because 0.417394 > 0.415666 (22.630: -0.00%)
======================================================= (12.129 sec)
23.161... logprob:  0.349913, 0.078125 (1.419 sec)
23.162... logprob:  0.611786, 0.179688 (1.415 sec)
23.163... logprob:  0.450454, 0.125000 (1.424 sec)
23.164... logprob:  0.468601, 0.125000 (1.420 sec)
23.165... logprob:  0.547850, 0.156250 (1.418 sec)
23.166... logprob:  0.446105, 0.125000 (1.454 sec)
23.167... logprob:  0.350518, 0.085938 (1.431 sec)
23.168... logprob:  0.363714, 0.085938 (1.426 sec)
23.169... logprob:  0.408653, 0.101562 (1.467 sec)
23.170... logprob:  0.459476, 0.125000 (1.408 sec)
23.171... logprob:  0.535337, 0.156250 (1.419 sec)
23.172... logprob:  0.434835, 0.109375 (1.418 sec)
23.173... logprob:  0.440480, 0.117188 (1.424 sec)
23.174... logprob:  0.600910, 0.171875 (1.407 sec)
23.175... logprob:  0.506024, 0.140625 (1.474 sec)
23.176... logprob:  0.478440, 0.132812 (1.418 sec)
23.177... logprob:  0.289739, 0.054688 (1.429 sec)
23.178... logprob:  0.383478, 0.093750 (1.458 sec)
23.179... logprob:  0.394690, 0.101562 (1.413 sec)
23.180... logprob:  0.466386, 0.125000 (1.435 sec)
23.181... logprob:  0.539335, 0.156250 (1.422 sec)
23.182... logprob:  0.371335, 0.093750 (1.415 sec)
23.183... logprob:  0.419944, 0.109375 (1.421 sec)
23.184... logprob:  0.483452, 0.132812 (1.417 sec)
23.185... logprob:  0.289804, 0.062500 (1.401 sec)
23.186... logprob:  0.370426, 0.093750 (1.398 sec)
23.187... logprob:  0.529620, 0.148438 (1.406 sec)
23.188... logprob:  0.458922, 0.125000 (1.395 sec)
23.189... logprob:  0.440914, 0.117188 (1.392 sec)
23.190... logprob:  0.375769, 0.093750 (1.435 sec)
23.191... logprob:  0.485094, 0.132812 (1.414 sec)
23.192... logprob:  0.520090, 0.148438 (1.426 sec)
23.193... logprob:  0.312550, 0.070312 (1.418 sec)
23.194... logprob:  0.414081, 0.109375 (1.419 sec)
23.195... logprob:  0.287120, 0.062500 (1.396 sec)
23.196... logprob:  0.410502, 0.109375 (1.397 sec)
23.197... logprob:  0.478002, 0.132812 (1.398 sec)
23.198... logprob:  0.355795, 0.085938 (1.410 sec)
23.199... logprob:  0.437193, 0.117188 (1.384 sec)
23.200... logprob:  0.440749, 0.117188 (1.445 sec)
23.201... logprob:  0.437093, 0.117188 (1.404 sec)
23.202... logprob:  0.537896, 0.148438 (1.408 sec)
23.203... logprob:  0.420428, 0.109375 (1.442 sec)
23.204... logprob:  0.504123, 0.140625 (1.389 sec)
23.205... logprob:  0.334329, 0.078125 (1.402 sec)
23.206... logprob:  0.361632, 0.093750 (1.407 sec)
23.207... logprob:  0.381824, 0.093750 (1.399 sec)
23.208... logprob:  0.490555, 0.140625 (1.400 sec)
23.209... logprob:  0.334562, 0.078125 (1.422 sec)
23.210... logprob:  0.586235, 0.171875 (1.419 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.692935943603516, 10.0]}, 128)
batch 872: ({'logprob': [66.32420349121094, 19.0]}, 128)
batch 873: ({'logprob': [40.9007453918457, 9.0]}, 128)
batch 874: ({'logprob': [45.307586669921875, 11.0]}, 128)
batch 875: ({'logprob': [50.82881546020508, 13.0]}, 128)
batch 876: ({'logprob': [63.86338424682617, 18.0]}, 128)
batch 877: ({'logprob': [45.8735237121582, 11.0]}, 128)
batch 878: ({'logprob': [61.91836166381836, 17.0]}, 128)
batch 879: ({'logprob': [73.52655792236328, 21.0]}, 128)
batch 880: ({'logprob': [50.850364685058594, 13.0]}, 128)
batch 881: ({'logprob': [29.256711959838867, 5.0]}, 128)
batch 882: ({'logprob': [55.01111602783203, 14.0]}, 128)
batch 883: ({'logprob': [61.895843505859375, 17.0]}, 128)
batch 884: ({'logprob': [51.39289855957031, 13.0]}, 128)
batch 885: ({'logprob': [52.510406494140625, 13.0]}, 128)
batch 886: ({'logprob': [62.471519470214844, 17.0]}, 128)

======================Test output======================
logprob:  0.416809, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.964497e-03 [3.071792e-09] 
Layer 'conv1' biases: 2.588822e-07 [1.268497e-10] 
Layer 'conv2' weights[0]: 7.951576e-03 [2.252571e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.506042e-10] 
Layer 'conv3' weights[0]: 7.949800e-03 [2.417998e-09] 
Layer 'conv3' biases: 2.216510e-06 [1.613366e-09] 
Layer 'conv4' weights[0]: 7.982476e-03 [2.376588e-09] 
Layer 'conv4' biases: 9.999993e-01 [1.347756e-08] 
Layer 'conv5' weights[0]: 7.981276e-03 [8.702444e-08] 
Layer 'conv5' biases: 9.999943e-01 [9.361444e-08] 
Layer 'fc6' weights[0]: 7.577950e-03 [7.271254e-09] 
Layer 'fc6' biases: 9.999999e-01 [7.394680e-09] 
Layer 'fc7' weights[0]: 7.120824e-03 [7.987887e-08] 
Layer 'fc7' biases: 9.998606e-01 [6.489130e-08] 
Layer 'fc8' weights[0]: 1.303309e-03 [4.652481e-06] 
Layer 'fc8' biases: 5.532206e-02 [3.012673e-05] 
Train error last 870 batches: 0.435222
-------------------------------------------------------
Not saving because 0.416809 > 0.415666 (22.630: -0.00%)
======================================================= (12.061 sec)
23.211... logprob:  0.488154, 0.132812 (1.424 sec)
23.212... logprob:  0.526133, 0.148438 (1.420 sec)
23.213... logprob:  0.514698, 0.140625 (1.464 sec)
23.214... logprob:  0.459413, 0.125000 (1.429 sec)
23.215... logprob:  0.396117, 0.101562 (1.419 sec)
23.216... logprob:  0.517001, 0.140625 (1.466 sec)
23.217... logprob:  0.324967, 0.070312 (1.403 sec)
23.218... logprob:  0.463635, 0.125000 (1.423 sec)
23.219... logprob:  0.500262, 0.140625 (1.423 sec)
23.220... logprob:  0.415015, 0.109375 (1.430 sec)
23.221... logprob:  0.399557, 0.101562 (1.409 sec)
23.222... logprob:  0.554480, 0.164062 (1.459 sec)
23.223... logprob:  0.569063, 0.164062 (1.437 sec)
23.224... logprob:  0.405933, 0.101562 (1.430 sec)
23.225... logprob:  0.391988, 0.101562 (1.450 sec)
23.226... logprob:  0.424697, 0.109375 (1.423 sec)
23.227... logprob:  0.452669, 0.125000 (1.427 sec)
23.228... logprob:  0.417180, 0.109375 (1.420 sec)
23.229... logprob:  0.489370, 0.132812 (1.424 sec)
23.230... logprob:  0.459870, 0.125000 (1.429 sec)
23.231... logprob:  0.453512, 0.125000 (1.408 sec)
23.232... logprob:  0.496190, 0.140625 (1.460 sec)
23.233... logprob:  0.466105, 0.132812 (1.425 sec)
23.234... logprob:  0.563839, 0.164062 (1.422 sec)
23.235... logprob:  0.482019, 0.132812 (1.468 sec)
23.236... logprob:  0.425711, 0.109375 (1.404 sec)
23.237... logprob:  0.341099, 0.078125 (1.423 sec)
23.238... logprob:  0.389225, 0.093750 (1.414 sec)
23.239... logprob:  0.478109, 0.132812 (1.427 sec)
23.240... logprob:  0.485799, 0.132812 (1.401 sec)
23.241... logprob:  0.493601, 0.132812 (1.462 sec)
23.242... logprob:  0.341644, 0.078125 (1.430 sec)
23.243... logprob:  0.386006, 0.093750 (1.440 sec)
23.244... logprob:  0.315339, 0.070312 (1.445 sec)
23.245... logprob:  0.494267, 0.132812 (1.430 sec)
23.246... logprob:  0.416870, 0.109375 (1.420 sec)
23.247... logprob:  0.357481, 0.085938 (1.421 sec)
23.248... logprob:  0.307926, 0.070312 (1.417 sec)
23.249... logprob:  0.554931, 0.156250 (1.423 sec)
23.250... logprob:  0.591420, 0.164062 (1.410 sec)
23.251... logprob:  0.352958, 0.085938 (1.460 sec)
23.252... logprob:  0.348456, 0.085938 (1.425 sec)
23.253... logprob:  0.379200, 0.093750 (1.423 sec)
23.254... logprob:  0.444168, 0.117188 (1.473 sec)
23.255... logprob:  0.351393, 0.085938 (1.431 sec)
23.256... logprob:  0.378810, 0.093750 (1.423 sec)
23.257... logprob:  0.332000, 0.078125 (1.417 sec)
23.258... logprob:  0.415625, 0.109375 (1.416 sec)
23.259... logprob:  0.442315, 0.117188 (1.402 sec)
23.260... logprob:  0.308272, 0.070312 (1.456 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.83979797363281, 10.0]}, 128)
batch 872: ({'logprob': [67.85504150390625, 19.0]}, 128)
batch 873: ({'logprob': [39.61204147338867, 9.0]}, 128)
batch 874: ({'logprob': [45.030277252197266, 11.0]}, 128)
batch 875: ({'logprob': [50.814666748046875, 13.0]}, 128)
batch 876: ({'logprob': [65.07707977294922, 18.0]}, 128)
batch 877: ({'logprob': [45.22239303588867, 11.0]}, 128)
batch 878: ({'logprob': [62.43846130371094, 17.0]}, 128)
batch 879: ({'logprob': [74.20923614501953, 21.0]}, 128)
batch 880: ({'logprob': [50.838443756103516, 13.0]}, 128)
batch 881: ({'logprob': [27.80550765991211, 5.0]}, 128)
batch 882: ({'logprob': [54.20305633544922, 14.0]}, 128)
batch 883: ({'logprob': [62.41482162475586, 17.0]}, 128)
batch 884: ({'logprob': [51.010555267333984, 13.0]}, 128)
batch 885: ({'logprob': [51.38367462158203, 13.0]}, 128)
batch 886: ({'logprob': [62.62102508544922, 17.0]}, 128)

======================Test output======================
logprob:  0.416199, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.964452e-03 [2.145733e-09] 
Layer 'conv1' biases: 2.598253e-07 [6.804220e-11] 
Layer 'conv2' weights[0]: 7.951534e-03 [1.824926e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.888688e-10] 
Layer 'conv3' weights[0]: 7.949759e-03 [1.745254e-09] 
Layer 'conv3' biases: 2.222693e-06 [8.887694e-10] 
Layer 'conv4' weights[0]: 7.982435e-03 [1.878967e-09] 
Layer 'conv4' biases: 9.999993e-01 [8.334983e-09] 
Layer 'conv5' weights[0]: 7.981254e-03 [5.521083e-08] 
Layer 'conv5' biases: 9.999942e-01 [5.949671e-08] 
Layer 'fc6' weights[0]: 7.577911e-03 [4.701875e-09] 
Layer 'fc6' biases: 9.999999e-01 [4.674446e-09] 
Layer 'fc7' weights[0]: 7.118997e-03 [7.509181e-08] 
Layer 'fc7' biases: 9.998609e-01 [5.890061e-08] 
Layer 'fc8' weights[0]: 1.335496e-03 [2.453474e-06] 
Layer 'fc8' biases: 5.565013e-02 [1.704938e-05] 
Train error last 870 batches: 0.435222
-------------------------------------------------------
Not saving because 0.416199 > 0.415666 (22.630: -0.00%)
======================================================= (12.084 sec)
23.261... logprob:  0.392668, 0.101562 (1.442 sec)
23.262... logprob:  0.524584, 0.148438 (1.440 sec)
23.263... logprob:  0.425540, 0.109375 (1.453 sec)
23.264... logprob:  0.375078, 0.093750 (1.428 sec)
23.265... logprob:  0.439612, 0.117188 (1.415 sec)
23.266... logprob:  0.439019, 0.117188 (1.419 sec)
23.267... logprob:  0.422021, 0.109375 (1.414 sec)
23.268... logprob:  0.458940, 0.125000 (1.426 sec)
23.269... logprob:  0.567526, 0.164062 (1.411 sec)
23.270... logprob:  0.542280, 0.156250 (1.467 sec)
23.271... logprob:  0.445661, 0.117188 (1.432 sec)
23.272... logprob:  0.384648, 0.093750 (1.421 sec)
23.273... logprob:  0.500226, 0.140625 (1.472 sec)
23.274... logprob:  0.542510, 0.156250 (1.411 sec)
23.275... logprob:  0.487638, 0.132812 (1.428 sec)
23.276... logprob:  0.390080, 0.093750 (1.420 sec)
23.277... logprob:  0.428651, 0.109375 (1.417 sec)
23.278... logprob:  0.323527, 0.070312 (1.431 sec)
23.279... logprob:  0.325151, 0.070312 (1.461 sec)
23.280... logprob:  0.215656, 0.031250 (1.410 sec)
23.281... logprob:  0.417233, 0.109375 (1.427 sec)
23.282... logprob:  0.411374, 0.109375 (1.425 sec)
23.283... logprob:  0.393781, 0.101562 (1.415 sec)
23.284... logprob:  0.394507, 0.101562 (1.415 sec)
23.285... logprob:  0.451721, 0.117188 (1.442 sec)
23.286... logprob:  0.536803, 0.140625 (1.439 sec)
23.287... logprob:  0.346589, 0.085938 (1.432 sec)
23.288... logprob:  0.329957, 0.078125 (1.457 sec)
23.289... logprob:  0.445895, 0.117188 (1.442 sec)
23.290... logprob:  0.490656, 0.132812 (1.406 sec)
23.291... logprob:  0.439254, 0.117188 (1.412 sec)
23.292... logprob:  0.567429, 0.156250 (1.420 sec)
23.293... logprob:  0.427642, 0.117188 (1.421 sec)
23.294... logprob:  0.355921, 0.085938 (1.406 sec)
23.295... logprob:  0.334662, 0.078125 (1.464 sec)
23.296... logprob:  0.355774, 0.085938 (1.423 sec)
23.297... logprob:  0.394537, 0.101562 (1.427 sec)
23.298... logprob:  0.448185, 0.125000 (1.470 sec)
23.299... logprob:  0.342239, 0.078125 (1.405 sec)
23.300... logprob:  0.406502, 0.101562 (1.427 sec)
23.301... logprob:  0.397920, 0.101562 (1.417 sec)
23.302... logprob:  0.591558, 0.179688 (1.421 sec)
23.303... logprob:  0.459546, 0.125000 (1.410 sec)
23.304... logprob:  0.459653, 0.125000 (1.439 sec)
23.305... logprob:  0.455211, 0.125000 (1.441 sec)
23.306... logprob:  0.440589, 0.117188 (1.435 sec)
23.307... logprob:  0.421615, 0.109375 (1.443 sec)
23.308... logprob:  0.374719, 0.093750 (1.454 sec)
23.309... logprob:  0.450482, 0.125000 (1.421 sec)
23.310... logprob:  0.473658, 0.125000 (1.428 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.78574752807617, 10.0]}, 128)
batch 872: ({'logprob': [66.1744613647461, 19.0]}, 128)
batch 873: ({'logprob': [41.14263916015625, 9.0]}, 128)
batch 874: ({'logprob': [45.428462982177734, 11.0]}, 128)
batch 875: ({'logprob': [50.90018844604492, 13.0]}, 128)
batch 876: ({'logprob': [63.755943298339844, 18.0]}, 128)
batch 877: ({'logprob': [46.03009796142578, 11.0]}, 128)
batch 878: ({'logprob': [61.889495849609375, 17.0]}, 128)
batch 879: ({'logprob': [73.4331283569336, 21.0]}, 128)
batch 880: ({'logprob': [50.92140579223633, 13.0]}, 128)
batch 881: ({'logprob': [29.563444137573242, 5.0]}, 128)
batch 882: ({'logprob': [55.14570617675781, 14.0]}, 128)
batch 883: ({'logprob': [61.86721420288086, 17.0]}, 128)
batch 884: ({'logprob': [51.4991455078125, 13.0]}, 128)
batch 885: ({'logprob': [52.6876220703125, 13.0]}, 128)
batch 886: ({'logprob': [62.47795104980469, 17.0]}, 128)

======================Test output======================
logprob:  0.417335, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.964416e-03 [2.358796e-09] 
Layer 'conv1' biases: 2.609212e-07 [4.216351e-11] 
Layer 'conv2' weights[0]: 7.951500e-03 [1.442362e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.339389e-10] 
Layer 'conv3' weights[0]: 7.949729e-03 [1.143555e-09] 
Layer 'conv3' biases: 2.231619e-06 [3.940459e-10] 
Layer 'conv4' weights[0]: 7.982392e-03 [1.122630e-09] 
Layer 'conv4' biases: 9.999992e-01 [2.443409e-09] 
Layer 'conv5' weights[0]: 7.981209e-03 [1.403727e-08] 
Layer 'conv5' biases: 9.999941e-01 [1.483235e-08] 
Layer 'fc6' weights[0]: 7.577873e-03 [1.397150e-09] 
Layer 'fc6' biases: 9.999999e-01 [1.164212e-09] 
Layer 'fc7' weights[0]: 7.117195e-03 [4.377976e-08] 
Layer 'fc7' biases: 9.998604e-01 [2.089076e-08] 
Layer 'fc8' weights[0]: 1.296856e-03 [7.993855e-07] 
Layer 'fc8' biases: 5.565220e-02 [7.997728e-06] 
Train error last 870 batches: 0.435222
-------------------------------------------------------
Not saving because 0.417335 > 0.415666 (22.630: -0.00%)
======================================================= (12.110 sec)
23.311... logprob:  0.502549, 0.140625 (1.437 sec)
23.312... logprob:  0.478726, 0.132812 (1.441 sec)
23.313... logprob:  0.454863, 0.125000 (1.420 sec)
23.314... logprob:  0.454419, 0.117188 (1.467 sec)
23.315... logprob:  0.314675, 0.070312 (1.437 sec)
23.316... logprob:  0.468540, 0.125000 (1.423 sec)
23.317... logprob:  0.355463, 0.085938 (1.490 sec)
23.318... logprob:  0.455408, 0.125000 (1.411 sec)
23.319... logprob:  0.423185, 0.117188 (1.426 sec)
23.320... logprob:  0.412246, 0.109375 (1.431 sec)
23.321... logprob:  0.348261, 0.085938 (1.423 sec)
23.322... logprob:  0.387473, 0.101562 (1.429 sec)
23.323... logprob:  0.416512, 0.109375 (1.484 sec)
23.324... logprob:  0.498609, 0.140625 (1.426 sec)
23.325... logprob:  0.350678, 0.085938 (1.442 sec)
23.326... logprob:  0.543181, 0.148438 (1.459 sec)
23.327... logprob:  0.554403, 0.164062 (1.428 sec)
23.328... logprob:  0.565077, 0.156250 (1.424 sec)
23.329... logprob:  0.401951, 0.101562 (1.427 sec)
23.330... logprob:  0.388574, 0.101562 (1.420 sec)
23.331... logprob:  0.352382, 0.085938 (1.423 sec)
23.332... logprob:  0.482782, 0.132812 (1.450 sec)
23.333... logprob:  0.339550, 0.085938 (1.447 sec)
23.334... logprob:  0.565206, 0.171875 (1.443 sec)
23.335... logprob:  0.358765, 0.085938 (1.441 sec)
23.336... logprob:  0.444846, 0.125000 (1.454 sec)
23.337... logprob:  0.566433, 0.164062 (1.415 sec)
23.338... logprob:  0.449514, 0.125000 (1.425 sec)
23.339... logprob:  0.488638, 0.132812 (1.439 sec)
23.340... logprob:  0.442070, 0.117188 (1.427 sec)
23.341... logprob:  0.530080, 0.148438 (1.420 sec)
23.342... logprob:  0.429635, 0.109375 (1.466 sec)
23.343... logprob:  0.434773, 0.109375 (1.441 sec)
23.344... logprob:  0.444478, 0.125000 (1.480 sec)
23.345... logprob:  0.488219, 0.132812 (1.444 sec)
23.346... logprob:  0.436222, 0.117188 (1.438 sec)
23.347... logprob:  0.372455, 0.085938 (1.485 sec)
23.348... logprob:  0.398461, 0.101562 (1.437 sec)
23.349... logprob:  0.497720, 0.140625 (1.433 sec)
23.350... logprob:  0.358634, 0.085938 (1.436 sec)
23.351... logprob:  0.508571, 0.140625 (1.431 sec)
23.352... logprob:  0.363632, 0.093750 (1.437 sec)
23.353... logprob:  0.512605, 0.148438 (1.491 sec)
23.354... logprob:  0.674951, 0.203125 (1.431 sec)
23.355... logprob:  0.357486, 0.085938 (1.448 sec)
23.356... logprob:  0.479242, 0.132812 (1.487 sec)
23.357... logprob:  0.346867, 0.085938 (1.429 sec)
23.358... logprob:  0.325873, 0.070312 (1.444 sec)
23.359... logprob:  0.555307, 0.164062 (1.434 sec)
23.360... logprob:  0.444518, 0.117188 (1.428 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.055381774902344, 10.0]}, 128)
batch 872: ({'logprob': [66.12120819091797, 19.0]}, 128)
batch 873: ({'logprob': [41.225502014160156, 9.0]}, 128)
batch 874: ({'logprob': [45.56166458129883, 11.0]}, 128)
batch 875: ({'logprob': [50.95446014404297, 13.0]}, 128)
batch 876: ({'logprob': [63.709964752197266, 18.0]}, 128)
batch 877: ({'logprob': [46.099002838134766, 11.0]}, 128)
batch 878: ({'logprob': [61.78621292114258, 17.0]}, 128)
batch 879: ({'logprob': [73.1076889038086, 21.0]}, 128)
batch 880: ({'logprob': [50.97599411010742, 13.0]}, 128)
batch 881: ({'logprob': [29.868804931640625, 5.0]}, 128)
batch 882: ({'logprob': [54.998992919921875, 14.0]}, 128)
batch 883: ({'logprob': [61.7636833190918, 17.0]}, 128)
batch 884: ({'logprob': [51.488616943359375, 13.0]}, 128)
batch 885: ({'logprob': [52.547882080078125, 13.0]}, 128)
batch 886: ({'logprob': [62.30980682373047, 17.0]}, 128)

======================Test output======================
logprob:  0.417273, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.964380e-03 [3.257601e-09] 
Layer 'conv1' biases: 2.617646e-07 [5.230186e-11] 
Layer 'conv2' weights[0]: 7.951458e-03 [1.979279e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.697303e-10] 
Layer 'conv3' weights[0]: 7.949691e-03 [1.383266e-09] 
Layer 'conv3' biases: 2.238792e-06 [4.575212e-10] 
Layer 'conv4' weights[0]: 7.982357e-03 [1.314077e-09] 
Layer 'conv4' biases: 9.999993e-01 [1.826478e-09] 
Layer 'conv5' weights[0]: 7.981162e-03 [1.210742e-08] 
Layer 'conv5' biases: 9.999943e-01 [1.290169e-08] 
Layer 'fc6' weights[0]: 7.577839e-03 [1.288583e-09] 
Layer 'fc6' biases: 9.999999e-01 [1.018541e-09] 
Layer 'fc7' weights[0]: 7.115401e-03 [6.583272e-08] 
Layer 'fc7' biases: 9.998598e-01 [4.958098e-08] 
Layer 'fc8' weights[0]: 1.292196e-03 [1.618550e-06] 
Layer 'fc8' biases: 5.572011e-02 [9.240832e-06] 
Train error last 870 batches: 0.435221
-------------------------------------------------------
Not saving because 0.417273 > 0.415666 (22.630: -0.00%)
======================================================= (12.111 sec)
23.361... logprob:  0.410753, 0.101562 (1.440 sec)
23.362... logprob:  0.424028, 0.117188 (1.481 sec)
23.363... logprob:  0.486584, 0.132812 (1.438 sec)
23.364... logprob:  0.475578, 0.125000 (1.458 sec)
23.365... logprob:  0.425060, 0.109375 (1.468 sec)
23.366... logprob:  0.409626, 0.109375 (1.440 sec)
23.367... logprob:  0.324949, 0.078125 (1.434 sec)
23.368... logprob:  0.595611, 0.171875 (1.432 sec)
23.369... logprob:  0.381606, 0.093750 (1.432 sec)
23.370... logprob:  0.381236, 0.093750 (1.440 sec)
23.371... logprob:  0.400389, 0.101562 (1.453 sec)
23.372... logprob:  0.537395, 0.156250 (1.455 sec)
23.373... logprob:  0.463805, 0.125000 (1.453 sec)
23.374... logprob:  0.526933, 0.148438 (1.451 sec)
23.375... logprob:  0.393773, 0.101562 (1.469 sec)
23.376... logprob:  0.374297, 0.093750 (1.441 sec)
23.377... logprob:  0.295406, 0.062500 (1.423 sec)
23.378... logprob:  0.453712, 0.125000 (1.434 sec)
23.379... logprob:  0.420241, 0.109375 (1.517 sec)
23.380... logprob:  0.605715, 0.179688 (1.438 sec)
23.381... logprob:  0.463443, 0.125000 (1.474 sec)
23.382... logprob:  0.529547, 0.148438 (1.450 sec)
23.383... logprob:  0.358600, 0.085938 (1.442 sec)
23.384... logprob:  0.521140, 0.148438 (1.481 sec)
23.385... logprob:  0.523532, 0.148438 (1.434 sec)
23.386... logprob:  0.582471, 0.171875 (1.430 sec)
23.387... logprob:  0.428586, 0.117188 (1.440 sec)
23.388... logprob:  0.521347, 0.148438 (1.437 sec)
23.389... logprob:  0.425720, 0.109375 (1.433 sec)
23.390... logprob:  0.419787, 0.109375 (1.489 sec)
23.391... logprob:  0.318257, 0.070312 (1.446 sec)
23.392... logprob:  0.439442, 0.117188 (1.431 sec)
23.393... logprob:  0.368948, 0.093750 (1.491 sec)
23.394... logprob:  0.343606, 0.078125 (1.432 sec)
23.395... logprob:  0.331746, 0.078125 (1.434 sec)
23.396... logprob:  0.252256, 0.046875 (1.442 sec)
23.397... logprob:  0.484379, 0.132812 (1.440 sec)
23.398... logprob:  0.471015, 0.125000 (1.429 sec)
23.399... logprob:  0.433413, 0.117188 (1.493 sec)
23.400... logprob:  0.537957, 0.148438 (1.443 sec)
23.401... logprob:  0.465886, 0.125000 (1.446 sec)
23.402... logprob:  0.474030, 0.125000 (1.489 sec)
23.403... logprob:  0.462166, 0.125000 (1.445 sec)
23.404... logprob:  0.474822, 0.125000 (1.447 sec)
23.405... logprob:  0.544082, 0.156250 (1.442 sec)
23.406... logprob:  0.357705, 0.085938 (1.432 sec)
23.407... logprob:  0.492872, 0.140625 (1.441 sec)
23.408... logprob:  0.339254, 0.078125 (1.495 sec)
23.409... logprob:  0.400673, 0.101562 (1.443 sec)
23.410... logprob:  0.582041, 0.171875 (1.459 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.94318389892578, 10.0]}, 128)
batch 872: ({'logprob': [65.68394470214844, 19.0]}, 128)
batch 873: ({'logprob': [42.59562301635742, 9.0]}, 128)
batch 874: ({'logprob': [46.45301818847656, 11.0]}, 128)
batch 875: ({'logprob': [51.564117431640625, 13.0]}, 128)
batch 876: ({'logprob': [63.46189498901367, 18.0]}, 128)
batch 877: ({'logprob': [47.089271545410156, 11.0]}, 128)
batch 878: ({'logprob': [61.82778549194336, 17.0]}, 128)
batch 879: ({'logprob': [72.67884063720703, 21.0]}, 128)
batch 880: ({'logprob': [51.58457946777344, 13.0]}, 128)
batch 881: ({'logprob': [31.710433959960938, 5.0]}, 128)
batch 882: ({'logprob': [55.7082405090332, 14.0]}, 128)
batch 883: ({'logprob': [61.805824279785156, 17.0]}, 128)
batch 884: ({'logprob': [52.192771911621094, 13.0]}, 128)
batch 885: ({'logprob': [53.4468994140625, 13.0]}, 128)
batch 886: ({'logprob': [62.447418212890625, 17.0]}, 128)

======================Test output======================
logprob:  0.421481, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.964337e-03 [2.946366e-09] 
Layer 'conv1' biases: 2.627020e-07 [3.999320e-11] 
Layer 'conv2' weights[0]: 7.951423e-03 [1.896065e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.071928e-10] 
Layer 'conv3' weights[0]: 7.949651e-03 [1.520409e-09] 
Layer 'conv3' biases: 2.246324e-06 [6.871608e-10] 
Layer 'conv4' weights[0]: 7.982317e-03 [1.641560e-09] 
Layer 'conv4' biases: 9.999992e-01 [5.647149e-09] 
Layer 'conv5' weights[0]: 7.981135e-03 [3.746238e-08] 
Layer 'conv5' biases: 9.999945e-01 [4.029761e-08] 
Layer 'fc6' weights[0]: 7.577798e-03 [3.186157e-09] 
Layer 'fc6' biases: 9.999999e-01 [3.149374e-09] 
Layer 'fc7' weights[0]: 7.113607e-03 [2.239510e-07] 
Layer 'fc7' biases: 9.998593e-01 [2.135938e-07] 
Layer 'fc8' weights[0]: 1.260498e-03 [8.332656e-06] 
Layer 'fc8' biases: 5.569778e-02 [4.686297e-05] 
Train error last 870 batches: 0.435221
-------------------------------------------------------
Not saving because 0.421481 > 0.415666 (22.630: -0.00%)
======================================================= (12.253 sec)
23.411... logprob:  0.397987, 0.101562 (1.490 sec)
23.412... logprob:  0.540265, 0.156250 (1.440 sec)
23.413... logprob:  0.544678, 0.156250 (1.443 sec)
23.414... logprob:  0.466494, 0.125000 (1.442 sec)
23.415... logprob:  0.401724, 0.101562 (1.430 sec)
23.416... logprob:  0.427533, 0.109375 (1.451 sec)
23.417... logprob:  0.405451, 0.093750 (1.469 sec)
23.418... logprob:  0.380290, 0.093750 (1.463 sec)
23.419... logprob:  0.417732, 0.101562 (1.465 sec)
23.420... logprob:  0.356199, 0.085938 (1.466 sec)
23.421... logprob:  0.376591, 0.101562 (1.466 sec)
23.422... logprob:  0.522559, 0.148438 (1.444 sec)
23.423... logprob:  0.420910, 0.109375 (1.439 sec)
23.424... logprob:  0.324760, 0.078125 (1.438 sec)
23.425... logprob:  0.306318, 0.070312 (1.440 sec)
23.426... logprob:  0.449223, 0.117188 (1.459 sec)
23.427... logprob:  0.554534, 0.156250 (1.473 sec)
23.428... logprob:  0.601949, 0.171875 (1.488 sec)
23.429... logprob:  0.426318, 0.109375 (1.458 sec)
23.430... logprob:  0.299861, 0.070312 (1.476 sec)
23.431... logprob:  0.599690, 0.171875 (1.432 sec)
23.432... logprob:  0.387556, 0.093750 (1.422 sec)
23.433... logprob:  0.329924, 0.078125 (1.435 sec)
23.434... logprob:  0.529370, 0.148438 (1.449 sec)
23.435... logprob:  0.532284, 0.156250 (1.437 sec)
23.436... logprob:  0.381258, 0.093750 (1.481 sec)
23.437... logprob:  0.500272, 0.140625 (1.451 sec)
23.438... logprob:  0.546878, 0.156250 (1.435 sec)
23.439... logprob:  0.378909, 0.093750 (1.491 sec)
23.440... logprob:  0.439776, 0.117188 (1.431 sec)
23.441... logprob:  0.468002, 0.125000 (1.435 sec)
23.442... logprob:  0.378937, 0.093750 (1.435 sec)
23.443... logprob:  0.496573, 0.140625 (1.434 sec)
23.444... logprob:  0.372259, 0.093750 (1.439 sec)
23.445... logprob:  0.362397, 0.085938 (1.482 sec)
23.446... logprob:  0.398241, 0.101562 (1.442 sec)
23.447... logprob:  0.569945, 0.164062 (1.437 sec)
23.448... logprob:  0.332743, 0.078125 (1.489 sec)
23.449... logprob:  0.400028, 0.101562 (1.442 sec)
23.450... logprob:  0.239257, 0.046875 (1.432 sec)
23.451... logprob:  0.452788, 0.125000 (1.447 sec)
23.452... logprob:  0.456200, 0.117188 (1.433 sec)
23.453... logprob:  0.455329, 0.125000 (1.435 sec)
23.454... logprob:  0.489087, 0.132812 (1.483 sec)
23.455... logprob:  0.506096, 0.140625 (1.437 sec)
23.456... logprob:  0.468830, 0.125000 (1.450 sec)
23.457... logprob:  0.375354, 0.093750 (1.478 sec)
23.458... logprob:  0.351093, 0.085938 (1.437 sec)
23.459... logprob:  0.513855, 0.140625 (1.438 sec)
23.460... logprob:  0.274153, 0.054688 (1.435 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.67226028442383, 10.0]}, 128)
batch 872: ({'logprob': [66.42660522460938, 19.0]}, 128)
batch 873: ({'logprob': [40.75241470336914, 9.0]}, 128)
batch 874: ({'logprob': [45.249290466308594, 11.0]}, 128)
batch 875: ({'logprob': [50.79399108886719, 13.0]}, 128)
batch 876: ({'logprob': [63.93745040893555, 18.0]}, 128)
batch 877: ({'logprob': [45.78192138671875, 11.0]}, 128)
batch 878: ({'logprob': [61.93096160888672, 17.0]}, 128)
batch 879: ({'logprob': [73.5537338256836, 21.0]}, 128)
batch 880: ({'logprob': [50.8156852722168, 13.0]}, 128)
batch 881: ({'logprob': [29.094093322753906, 5.0]}, 128)
batch 882: ({'logprob': [54.905784606933594, 14.0]}, 128)
batch 883: ({'logprob': [61.90848159790039, 17.0]}, 128)
batch 884: ({'logprob': [51.32547378540039, 13.0]}, 128)
batch 885: ({'logprob': [52.376888275146484, 13.0]}, 128)
batch 886: ({'logprob': [62.451210021972656, 17.0]}, 128)

======================Test output======================
logprob:  0.416492, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.964287e-03 [2.666934e-09] 
Layer 'conv1' biases: 2.635457e-07 [9.171701e-11] 
Layer 'conv2' weights[0]: 7.951378e-03 [2.835271e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.945919e-10] 
Layer 'conv3' weights[0]: 7.949613e-03 [2.734036e-09] 
Layer 'conv3' biases: 2.253193e-06 [1.510292e-09] 
Layer 'conv4' weights[0]: 7.982277e-03 [2.786555e-09] 
Layer 'conv4' biases: 9.999993e-01 [1.306150e-08] 
Layer 'conv5' weights[0]: 7.981088e-03 [8.109894e-08] 
Layer 'conv5' biases: 9.999942e-01 [8.751663e-08] 
Layer 'fc6' weights[0]: 7.577762e-03 [6.771403e-09] 
Layer 'fc6' biases: 9.999999e-01 [6.879607e-09] 
Layer 'fc7' weights[0]: 7.111787e-03 [9.698050e-08] 
Layer 'fc7' biases: 9.998603e-01 [8.359932e-08] 
Layer 'fc8' weights[0]: 1.298297e-03 [2.986006e-06] 
Layer 'fc8' biases: 5.632969e-02 [1.665381e-05] 
Train error last 870 batches: 0.435220
-------------------------------------------------------
Not saving because 0.416492 > 0.415666 (22.630: -0.00%)
======================================================= (12.053 sec)
23.461... logprob:  0.460050, 0.125000 (1.459 sec)
23.462... logprob:  0.471940, 0.125000 (1.438 sec)
23.463... logprob:  0.420879, 0.109375 (1.468 sec)
23.464... logprob:  0.482731, 0.132812 (1.452 sec)
23.465... logprob:  0.421165, 0.109375 (1.452 sec)
23.466... logprob:  0.318480, 0.070312 (1.465 sec)
23.467... logprob:  0.413852, 0.109375 (1.450 sec)
23.468... logprob:  0.394271, 0.101562 (1.438 sec)
23.469... logprob:  0.334727, 0.078125 (1.434 sec)
23.470... logprob:  0.400077, 0.101562 (1.426 sec)
23.471... logprob:  0.529426, 0.148438 (1.442 sec)
23.472... logprob:  0.410030, 0.109375 (1.454 sec)
23.473... logprob:  0.375404, 0.093750 (1.459 sec)
23.474... logprob:  0.465666, 0.125000 (1.458 sec)
23.475... logprob:  0.504175, 0.140625 (1.447 sec)
23.476... logprob:  0.510335, 0.140625 (1.473 sec)
23.477... logprob:  0.334564, 0.078125 (1.437 sec)
23.478... logprob:  0.464264, 0.125000 (1.427 sec)
23.479... logprob:  0.305775, 0.070312 (1.433 sec)
23.480... logprob:  0.443512, 0.117188 (1.437 sec)
23.481... logprob:  0.547784, 0.156250 (1.439 sec)
23.482... logprob:  0.443159, 0.117188 (1.487 sec)
23.483... logprob:  0.502637, 0.140625 (1.445 sec)
23.484... logprob:  0.485303, 0.132812 (1.440 sec)
23.485... logprob:  0.409010, 0.109375 (1.485 sec)
23.486... logprob:  0.361453, 0.085938 (1.436 sec)
23.487... logprob:  0.522652, 0.148438 (1.429 sec)
23.488... logprob:  0.424802, 0.109375 (1.441 sec)
23.489... logprob:  0.415890, 0.109375 (1.432 sec)
23.490... logprob:  0.440696, 0.117188 (1.439 sec)
23.491... logprob:  0.313666, 0.070312 (1.479 sec)
23.492... logprob:  0.459566, 0.125000 (1.440 sec)
23.493... logprob:  0.521878, 0.148438 (1.442 sec)
23.494... logprob:  0.450362, 0.125000 (1.488 sec)
23.495... logprob:  0.380618, 0.093750 (1.438 sec)
23.496... logprob:  0.550368, 0.156250 (1.436 sec)
23.497... logprob:  0.466969, 0.125000 (1.433 sec)
23.498... logprob:  0.476277, 0.132812 (1.432 sec)
23.499... logprob:  0.456252, 0.125000 (1.438 sec)
23.500... logprob:  0.355115, 0.085938 (1.489 sec)
23.501... logprob:  0.339115, 0.078125 (1.432 sec)
23.502... logprob:  0.459634, 0.125000 (1.472 sec)
23.503... logprob:  0.400675, 0.101562 (1.478 sec)
23.504... logprob:  0.487312, 0.132812 (1.436 sec)
23.505... logprob:  0.570795, 0.164062 (1.441 sec)
23.506... logprob:  0.479684, 0.132812 (1.432 sec)
23.507... logprob:  0.385083, 0.093750 (1.432 sec)
23.508... logprob:  0.374706, 0.093750 (1.431 sec)
23.509... logprob:  0.323106, 0.070312 (1.483 sec)
23.510... logprob:  0.390470, 0.101562 (1.442 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.80635452270508, 10.0]}, 128)
batch 872: ({'logprob': [66.58650207519531, 19.0]}, 128)
batch 873: ({'logprob': [40.55450439453125, 9.0]}, 128)
batch 874: ({'logprob': [45.23777389526367, 11.0]}, 128)
batch 875: ({'logprob': [50.7770881652832, 13.0]}, 128)
batch 876: ({'logprob': [64.05242919921875, 18.0]}, 128)
batch 877: ({'logprob': [45.674781799316406, 11.0]}, 128)
batch 878: ({'logprob': [61.90481948852539, 17.0]}, 128)
batch 879: ({'logprob': [73.42298889160156, 21.0]}, 128)
batch 880: ({'logprob': [50.79937744140625, 13.0]}, 128)
batch 881: ({'logprob': [29.00118637084961, 5.0]}, 128)
batch 882: ({'logprob': [54.64823913574219, 14.0]}, 128)
batch 883: ({'logprob': [61.88197708129883, 17.0]}, 128)
batch 884: ({'logprob': [51.213645935058594, 13.0]}, 128)
batch 885: ({'logprob': [52.07408142089844, 13.0]}, 128)
batch 886: ({'logprob': [62.32976150512695, 17.0]}, 128)

======================Test output======================
logprob:  0.415999, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.964248e-03 [4.146337e-09] 
Layer 'conv1' biases: 2.642465e-07 [1.434932e-10] 
Layer 'conv2' weights[0]: 7.951334e-03 [3.056038e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.060308e-10] 
Layer 'conv3' weights[0]: 7.949575e-03 [2.937683e-09] 
Layer 'conv3' biases: 2.260167e-06 [1.711844e-09] 
Layer 'conv4' weights[0]: 7.982243e-03 [3.126061e-09] 
Layer 'conv4' biases: 9.999993e-01 [1.547469e-08] 
Layer 'conv5' weights[0]: 7.981065e-03 [1.017021e-07] 
Layer 'conv5' biases: 9.999940e-01 [1.094999e-07] 
Layer 'fc6' weights[0]: 7.577719e-03 [8.505541e-09] 
Layer 'fc6' biases: 9.999999e-01 [8.601386e-09] 
Layer 'fc7' weights[0]: 7.109975e-03 [1.643824e-07] 
Layer 'fc7' biases: 9.998602e-01 [1.529527e-07] 
Layer 'fc8' weights[0]: 1.297577e-03 [6.133516e-06] 
Layer 'fc8' biases: 5.643837e-02 [4.152362e-05] 
Train error last 870 batches: 0.435220
-------------------------------------------------------
Not saving because 0.415999 > 0.415666 (22.630: -0.00%)
======================================================= (12.033 sec)
23.511... logprob:  0.410063, 0.109375 (1.455 sec)
23.512... logprob:  0.470730, 0.125000 (1.468 sec)
23.513... logprob:  0.324968, 0.078125 (1.442 sec)
23.514... logprob:  0.406274, 0.101562 (1.444 sec)
23.515... logprob:  0.455530, 0.125000 (1.427 sec)
23.516... logprob:  0.400337, 0.109375 (1.429 sec)
23.517... logprob:  0.627890, 0.179688 (1.435 sec)
23.518... logprob:  0.437679, 0.117188 (1.459 sec)
23.519... logprob:  0.516139, 0.140625 (1.452 sec)
23.520... logprob:  0.409649, 0.109375 (1.455 sec)
23.521... logprob:  0.427474, 0.109375 (1.453 sec)
23.522... logprob:  0.533116, 0.156250 (1.467 sec)
23.523... logprob:  0.331636, 0.078125 (1.438 sec)
23.524... logprob:  0.437191, 0.117188 (1.429 sec)
23.525... logprob:  0.425994, 0.109375 (1.428 sec)
23.526... logprob:  0.351811, 0.078125 (1.444 sec)
23.527... logprob:  0.504560, 0.140625 (1.442 sec)
23.528... logprob:  0.440484, 0.117188 (1.470 sec)
23.529... logprob:  0.353006, 0.085938 (1.454 sec)
23.530... logprob:  0.440250, 0.117188 (1.440 sec)
23.531... logprob:  0.439980, 0.117188 (1.483 sec)
23.532... logprob:  0.467357, 0.125000 (1.434 sec)
23.533... logprob:  0.560515, 0.164062 (1.432 sec)
23.534... logprob:  0.325860, 0.078125 (1.434 sec)
23.535... logprob:  0.551560, 0.156250 (1.463 sec)
23.536... logprob:  0.507336, 0.140625 (1.435 sec)
23.537... logprob:  0.510042, 0.140625 (1.477 sec)
23.538... logprob:  0.486098, 0.132812 (1.449 sec)
23.539... logprob:  0.296085, 0.062500 (1.433 sec)
23.540... logprob:  0.447177, 0.117188 (1.488 sec)
23.541... logprob:  0.388840, 0.101562 (1.436 sec)
23.542... logprob:  0.411275, 0.109375 (1.432 sec)
23.543... logprob:  0.233302, 0.039062 (1.438 sec)
23.544... logprob:  0.317933, 0.070312 (1.430 sec)
23.545... logprob:  0.348804, 0.085938 (1.437 sec)
23.546... logprob:  0.368279, 0.093750 (1.488 sec)
23.547... logprob:  0.440080, 0.117188 (1.435 sec)
23.548... logprob:  0.453037, 0.125000 (1.444 sec)
23.549... logprob:  0.490576, 0.132812 (1.482 sec)
23.550... logprob:  0.367650, 0.093750 (1.434 sec)
23.551... logprob:  0.441714, 0.117188 (1.436 sec)
23.552... logprob:  0.471297, 0.125000 (1.438 sec)
23.553... logprob:  0.349442, 0.085938 (1.427 sec)
23.554... logprob:  0.506913, 0.140625 (1.432 sec)
23.555... logprob:  0.421410, 0.109375 (1.482 sec)
23.556... logprob:  0.355859, 0.085938 (1.440 sec)
23.557... logprob:  0.396424, 0.101562 (1.450 sec)
23.558... logprob:  0.383033, 0.101562 (1.472 sec)
23.559... logprob:  0.441528, 0.125000 (1.438 sec)
23.560... logprob:  0.335195, 0.078125 (1.440 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.652889251708984, 10.0]}, 128)
batch 872: ({'logprob': [66.21036529541016, 19.0]}, 128)
batch 873: ({'logprob': [41.11581039428711, 9.0]}, 128)
batch 874: ({'logprob': [45.37089157104492, 11.0]}, 128)
batch 875: ({'logprob': [50.88407897949219, 13.0]}, 128)
batch 876: ({'logprob': [63.78944396972656, 18.0]}, 128)
batch 877: ({'logprob': [46.00865173339844, 11.0]}, 128)
batch 878: ({'logprob': [61.95671463012695, 17.0]}, 128)
batch 879: ({'logprob': [73.61930847167969, 21.0]}, 128)
batch 880: ({'logprob': [50.905433654785156, 13.0]}, 128)
batch 881: ({'logprob': [29.417430877685547, 5.0]}, 128)
batch 882: ({'logprob': [55.24119567871094, 14.0]}, 128)
batch 883: ({'logprob': [61.93418502807617, 17.0]}, 128)
batch 884: ({'logprob': [51.51971435546875, 13.0]}, 128)
batch 885: ({'logprob': [52.78079605102539, 13.0]}, 128)
batch 886: ({'logprob': [62.581504821777344, 17.0]}, 128)

======================Test output======================
logprob:  0.417475, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.964204e-03 [3.535763e-09] 
Layer 'conv1' biases: 2.652921e-07 [1.206977e-10] 
Layer 'conv2' weights[0]: 7.951295e-03 [2.528827e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.936662e-10] 
Layer 'conv3' weights[0]: 7.949524e-03 [2.650470e-09] 
Layer 'conv3' biases: 2.269438e-06 [1.439112e-09] 
Layer 'conv4' weights[0]: 7.982206e-03 [2.767612e-09] 
Layer 'conv4' biases: 9.999993e-01 [1.295307e-08] 
Layer 'conv5' weights[0]: 7.981023e-03 [8.563359e-08] 
Layer 'conv5' biases: 9.999941e-01 [9.238497e-08] 
Layer 'fc6' weights[0]: 7.577678e-03 [7.159911e-09] 
Layer 'fc6' biases: 9.999999e-01 [7.263505e-09] 
Layer 'fc7' weights[0]: 7.108156e-03 [4.605472e-08] 
Layer 'fc7' biases: 9.998605e-01 [2.374858e-08] 
Layer 'fc8' weights[0]: 1.290581e-03 [5.467629e-06] 
Layer 'fc8' biases: 5.651057e-02 [3.282071e-05] 
Train error last 870 batches: 0.435220
-------------------------------------------------------
Not saving because 0.417475 > 0.415666 (22.630: -0.00%)
======================================================= (12.067 sec)
23.561... logprob:  0.411817, 0.109375 (1.437 sec)
23.562... logprob:  0.503134, 0.140625 (1.425 sec)
23.563... logprob:  0.373814, 0.093750 (1.439 sec)
23.564... logprob:  0.468452, 0.132812 (1.469 sec)
23.565... logprob:  0.611086, 0.187500 (1.451 sec)
23.566... logprob:  0.374895, 0.093750 (1.453 sec)
23.567... logprob:  0.423378, 0.109375 (1.459 sec)
23.568... logprob:  0.496352, 0.140625 (1.483 sec)
23.569... logprob:  0.507776, 0.140625 (1.441 sec)
23.570... logprob:  0.543753, 0.164062 (1.423 sec)
23.571... logprob:  0.454879, 0.125000 (1.434 sec)
23.572... logprob:  0.501427, 0.140625 (1.436 sec)
23.573... logprob:  0.512612, 0.148438 (1.445 sec)
23.574... logprob:  0.428094, 0.109375 (1.467 sec)
23.575... logprob:  0.343342, 0.078125 (1.451 sec)
23.576... logprob:  0.427383, 0.109375 (1.446 sec)
23.577... logprob:  0.460816, 0.125000 (1.479 sec)
23.578... logprob:  0.336669, 0.078125 (1.435 sec)
23.579... logprob:  0.442083, 0.117188 (1.429 sec)
23.580... logprob:  0.546808, 0.156250 (1.431 sec)
23.581... logprob:  0.530835, 0.156250 (1.444 sec)
23.582... logprob:  0.437852, 0.125000 (1.436 sec)
23.583... logprob:  0.592664, 0.171875 (1.476 sec)
23.584... logprob:  0.468102, 0.132812 (1.447 sec)
23.585... logprob:  0.349763, 0.085938 (1.435 sec)
23.586... logprob:  0.313111, 0.070312 (1.485 sec)
23.587... logprob:  0.404305, 0.101562 (1.438 sec)
23.588... logprob:  0.418664, 0.117188 (1.433 sec)
23.589... logprob:  0.361231, 0.093750 (1.437 sec)
23.590... logprob:  0.524734, 0.148438 (1.430 sec)
23.591... logprob:  0.397489, 0.101562 (1.435 sec)
23.592... logprob:  0.455659, 0.125000 (1.485 sec)
23.593... logprob:  0.467426, 0.125000 (1.441 sec)
23.594... logprob:  0.352854, 0.085938 (1.443 sec)
23.595... logprob:  0.428664, 0.109375 (1.482 sec)
23.596... logprob:  0.461596, 0.125000 (1.437 sec)
23.597... logprob:  0.397414, 0.101562 (1.432 sec)
23.598... logprob:  0.397224, 0.101562 (1.441 sec)
23.599... logprob:  0.313543, 0.070312 (1.431 sec)
23.600... logprob:  0.340891, 0.085938 (1.432 sec)
23.601... logprob:  0.402136, 0.101562 (1.487 sec)
23.602... logprob:  0.289779, 0.062500 (1.439 sec)
23.603... logprob:  0.267057, 0.054688 (1.445 sec)
23.604... logprob:  0.407517, 0.101562 (1.476 sec)
23.605... logprob:  0.563445, 0.148438 (1.440 sec)
23.606... logprob:  0.295944, 0.070312 (1.437 sec)
23.607... logprob:  0.504813, 0.132812 (1.438 sec)
23.608... logprob:  0.361766, 0.085938 (1.423 sec)
23.609... logprob:  0.356977, 0.085938 (1.446 sec)
23.610... logprob:  0.493368, 0.132812 (1.477 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.109432220458984, 10.0]}, 128)
batch 872: ({'logprob': [68.14208221435547, 19.0]}, 128)
batch 873: ({'logprob': [39.53116989135742, 9.0]}, 128)
batch 874: ({'logprob': [44.75746536254883, 11.0]}, 128)
batch 875: ({'logprob': [50.79254150390625, 13.0]}, 128)
batch 876: ({'logprob': [65.34957885742188, 18.0]}, 128)
batch 877: ({'logprob': [45.170166015625, 11.0]}, 128)
batch 878: ({'logprob': [62.9173469543457, 17.0]}, 128)
batch 879: ({'logprob': [75.40919494628906, 21.0]}, 128)
batch 880: ({'logprob': [50.815895080566406, 13.0]}, 128)
batch 881: ({'logprob': [27.002042770385742, 5.0]}, 128)
batch 882: ({'logprob': [54.85957717895508, 14.0]}, 128)
batch 883: ({'logprob': [62.8937873840332, 17.0]}, 128)
batch 884: ({'logprob': [51.21072769165039, 13.0]}, 128)
batch 885: ({'logprob': [52.0262336730957, 13.0]}, 128)
batch 886: ({'logprob': [63.32175064086914, 17.0]}, 128)

======================Test output======================
logprob:  0.417631, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.964158e-03 [3.861508e-09] 
Layer 'conv1' biases: 2.662485e-07 [1.485220e-10] 
Layer 'conv2' weights[0]: 7.951251e-03 [3.607533e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.340451e-10] 
Layer 'conv3' weights[0]: 7.949486e-03 [3.419665e-09] 
Layer 'conv3' biases: 2.276870e-06 [2.181347e-09] 
Layer 'conv4' weights[0]: 7.982166e-03 [3.658993e-09] 
Layer 'conv4' biases: 9.999992e-01 [1.959474e-08] 
Layer 'conv5' weights[0]: 7.980985e-03 [1.290097e-07] 
Layer 'conv5' biases: 9.999941e-01 [1.388689e-07] 
Layer 'fc6' weights[0]: 7.577641e-03 [1.077945e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.100366e-08] 
Layer 'fc7' weights[0]: 7.106350e-03 [2.473256e-07] 
Layer 'fc7' biases: 9.998615e-01 [2.373409e-07] 
Layer 'fc8' weights[0]: 1.345317e-03 [1.387534e-05] 
Layer 'fc8' biases: 5.700439e-02 [8.502466e-05] 
Train error last 870 batches: 0.435219
-------------------------------------------------------
Not saving because 0.417631 > 0.415666 (22.630: -0.00%)
======================================================= (12.044 sec)
23.611... logprob:  0.510395, 0.140625 (1.453 sec)
23.612... logprob:  0.448455, 0.117188 (1.452 sec)
23.613... logprob:  0.279585, 0.062500 (1.462 sec)
23.614... logprob:  0.503545, 0.140625 (1.456 sec)
23.615... logprob:  0.351003, 0.085938 (1.434 sec)
23.616... logprob:  0.415211, 0.109375 (1.433 sec)
23.617... logprob:  0.417906, 0.109375 (1.427 sec)
23.618... logprob:  0.546847, 0.156250 (1.437 sec)
23.619... logprob:  0.506020, 0.140625 (1.450 sec)
23.620... logprob:  0.539658, 0.156250 (1.460 sec)
23.621... logprob:  0.363763, 0.085938 (1.458 sec)
23.622... logprob:  0.364820, 0.085938 (1.447 sec)
23.623... logprob:  0.423176, 0.109375 (1.473 sec)
23.624... logprob:  0.382537, 0.093750 (1.435 sec)
23.625... logprob:  0.440993, 0.117188 (1.432 sec)
23.626... logprob:  0.438372, 0.117188 (1.429 sec)
23.627... logprob:  0.435844, 0.117188 (1.442 sec)
23.628... logprob:  0.465058, 0.125000 (1.438 sec)
23.629... logprob:  0.372064, 0.093750 (1.478 sec)
23.630... logprob:  0.422376, 0.109375 (1.447 sec)
23.631... logprob:  0.638909, 0.187500 (1.437 sec)
23.632... logprob:  0.399108, 0.101562 (1.488 sec)
23.633... logprob:  0.376063, 0.093750 (1.430 sec)
23.634... logprob:  0.660289, 0.195312 (1.425 sec)
23.635... logprob:  0.374119, 0.093750 (1.448 sec)
23.636... logprob:  0.480247, 0.132812 (1.433 sec)
23.637... logprob:  0.330846, 0.078125 (1.437 sec)
23.638... logprob:  0.515689, 0.140625 (1.481 sec)
23.639... logprob:  0.418094, 0.109375 (1.444 sec)
23.640... logprob:  0.528751, 0.148438 (1.438 sec)
23.641... logprob:  0.410449, 0.109375 (1.488 sec)
23.642... logprob:  0.500856, 0.140625 (1.450 sec)
23.643... logprob:  0.623041, 0.187500 (1.435 sec)
23.644... logprob:  0.321195, 0.070312 (1.434 sec)
23.645... logprob:  0.414483, 0.109375 (1.435 sec)
23.646... logprob:  0.385673, 0.093750 (1.432 sec)
23.647... logprob:  0.456770, 0.125000 (1.491 sec)
23.648... logprob:  0.491246, 0.140625 (1.435 sec)
23.649... logprob:  0.370208, 0.093750 (1.443 sec)
23.650... logprob:  0.413979, 0.109375 (1.485 sec)
23.651... logprob:  0.397353, 0.101562 (1.432 sec)
23.652... logprob:  0.507245, 0.140625 (1.439 sec)
23.653... logprob:  0.547934, 0.156250 (1.436 sec)
23.654... logprob:  0.496076, 0.140625 (1.427 sec)
23.655... logprob:  0.436192, 0.117188 (1.437 sec)
23.656... logprob:  0.416693, 0.109375 (1.477 sec)
23.657... logprob:  0.449167, 0.117188 (1.439 sec)
23.658... logprob:  0.345816, 0.085938 (1.453 sec)
23.659... logprob:  0.464320, 0.125000 (1.464 sec)
23.660... logprob:  0.445969, 0.125000 (1.446 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.721214294433594, 10.0]}, 128)
batch 872: ({'logprob': [66.21036529541016, 19.0]}, 128)
batch 873: ({'logprob': [41.090240478515625, 9.0]}, 128)
batch 874: ({'logprob': [45.38572311401367, 11.0]}, 128)
batch 875: ({'logprob': [50.880306243896484, 13.0]}, 128)
batch 876: ({'logprob': [63.784080505371094, 18.0]}, 128)
batch 877: ({'logprob': [45.9941520690918, 11.0]}, 128)
batch 878: ({'logprob': [61.91618347167969, 17.0]}, 128)
batch 879: ({'logprob': [73.51249694824219, 21.0]}, 128)
batch 880: ({'logprob': [50.901824951171875, 13.0]}, 128)
batch 881: ({'logprob': [29.458110809326172, 5.0]}, 128)
batch 882: ({'logprob': [55.154598236083984, 14.0]}, 128)
batch 883: ({'logprob': [61.8935432434082, 17.0]}, 128)
batch 884: ({'logprob': [51.48654556274414, 13.0]}, 128)
batch 885: ({'logprob': [52.68840789794922, 13.0]}, 128)
batch 886: ({'logprob': [62.511390686035156, 17.0]}, 128)

======================Test output======================
logprob:  0.417280, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.964122e-03 [2.279335e-09] 
Layer 'conv1' biases: 2.671322e-07 [3.370640e-11] 
Layer 'conv2' weights[0]: 7.951208e-03 [1.449326e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.409485e-10] 
Layer 'conv3' weights[0]: 7.949451e-03 [1.086195e-09] 
Layer 'conv3' biases: 2.284946e-06 [3.773744e-10] 
Layer 'conv4' weights[0]: 7.982123e-03 [1.060572e-09] 
Layer 'conv4' biases: 9.999992e-01 [2.058067e-09] 
Layer 'conv5' weights[0]: 7.980945e-03 [9.026293e-09] 
Layer 'conv5' biases: 9.999940e-01 [9.208342e-09] 
Layer 'fc6' weights[0]: 7.577604e-03 [1.019583e-09] 
Layer 'fc6' biases: 9.999999e-01 [6.477920e-10] 
Layer 'fc7' weights[0]: 7.104546e-03 [4.358584e-08] 
Layer 'fc7' biases: 9.998600e-01 [2.031287e-08] 
Layer 'fc8' weights[0]: 1.294517e-03 [4.651612e-06] 
Layer 'fc8' biases: 5.677706e-02 [3.040676e-05] 
Train error last 870 batches: 0.435219
-------------------------------------------------------
Not saving because 0.417280 > 0.415666 (22.630: -0.00%)
======================================================= (12.182 sec)
23.661... logprob:  0.378478, 0.093750 (1.444 sec)
23.662... logprob:  0.469396, 0.132812 (1.442 sec)
23.663... logprob:  0.310953, 0.070312 (1.420 sec)
23.664... logprob:  0.285429, 0.062500 (1.441 sec)
23.665... logprob:  0.401769, 0.101562 (1.460 sec)
23.666... logprob:  0.442046, 0.117188 (1.457 sec)
23.667... logprob:  0.564257, 0.164062 (1.454 sec)
23.668... logprob:  0.497876, 0.140625 (1.453 sec)
23.669... logprob:  0.433011, 0.109375 (1.461 sec)
23.670... logprob:  0.362426, 0.085938 (1.435 sec)
23.671... logprob:  0.360861, 0.093750 (1.428 sec)
23.672... logprob:  0.441820, 0.117188 (1.433 sec)
23.673... logprob:  0.436234, 0.117188 (1.442 sec)
23.674... logprob:  0.446649, 0.117188 (1.440 sec)
23.675... logprob:  0.356673, 0.093750 (1.497 sec)
23.676... logprob:  0.450166, 0.125000 (1.453 sec)
23.677... logprob:  0.471039, 0.125000 (1.439 sec)
23.678... logprob:  0.465653, 0.125000 (1.478 sec)
23.679... logprob:  0.454866, 0.125000 (1.430 sec)
23.680... logprob:  0.351699, 0.078125 (1.432 sec)
23.681... logprob:  0.373902, 0.093750 (1.433 sec)
23.682... logprob:  0.340483, 0.078125 (1.441 sec)
23.683... logprob:  0.411639, 0.109375 (1.433 sec)
23.684... logprob:  0.357648, 0.085938 (1.484 sec)
23.685... logprob:  0.286026, 0.054688 (1.444 sec)
23.686... logprob:  0.318659, 0.070312 (1.433 sec)
23.687... logprob:  0.281649, 0.062500 (1.492 sec)
23.688... logprob:  0.323110, 0.078125 (1.431 sec)
23.689... logprob:  0.471254, 0.125000 (1.435 sec)
23.690... logprob:  0.527760, 0.140625 (1.433 sec)
23.691... logprob:  0.516656, 0.140625 (1.427 sec)
23.692... logprob:  0.385065, 0.101562 (1.436 sec)
23.693... logprob:  0.455785, 0.125000 (1.486 sec)
23.694... logprob:  0.330919, 0.078125 (1.440 sec)
23.695... logprob:  0.356917, 0.085938 (1.443 sec)
23.696... logprob:  0.539018, 0.148438 (1.483 sec)
23.697... logprob:  0.465676, 0.125000 (1.432 sec)
23.698... logprob:  0.548779, 0.156250 (1.436 sec)
23.699... logprob:  0.459605, 0.125000 (1.439 sec)
23.700... logprob:  0.433928, 0.117188 (1.432 sec)
23.701... logprob:  0.423142, 0.109375 (1.429 sec)
23.702... logprob:  0.521507, 0.148438 (1.481 sec)
23.703... logprob:  0.405251, 0.101562 (1.438 sec)
23.704... logprob:  0.406139, 0.101562 (1.453 sec)
23.705... logprob:  0.420206, 0.109375 (1.470 sec)
23.706... logprob:  0.468067, 0.125000 (1.442 sec)
23.707... logprob:  0.485299, 0.132812 (1.438 sec)
23.708... logprob:  0.417138, 0.109375 (1.434 sec)
23.709... logprob:  0.422552, 0.109375 (1.424 sec)
23.710... logprob:  0.602418, 0.179688 (1.444 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.40260314941406, 10.0]}, 128)
batch 872: ({'logprob': [66.15372467041016, 19.0]}, 128)
batch 873: ({'logprob': [41.26446533203125, 9.0]}, 128)
batch 874: ({'logprob': [45.71896743774414, 11.0]}, 128)
batch 875: ({'logprob': [51.03060531616211, 13.0]}, 128)
batch 876: ({'logprob': [63.733436584472656, 18.0]}, 128)
batch 877: ({'logprob': [46.15694808959961, 11.0]}, 128)
batch 878: ({'logprob': [61.70071792602539, 17.0]}, 128)
batch 879: ({'logprob': [72.7613296508789, 21.0]}, 128)
batch 880: ({'logprob': [51.052364349365234, 13.0]}, 128)
batch 881: ({'logprob': [30.16930389404297, 5.0]}, 128)
batch 882: ({'logprob': [54.785911560058594, 14.0]}, 128)
batch 883: ({'logprob': [61.67805862426758, 17.0]}, 128)
batch 884: ({'logprob': [51.46516036987305, 13.0]}, 128)
batch 885: ({'logprob': [52.325172424316406, 13.0]}, 128)
batch 886: ({'logprob': [62.124488830566406, 17.0]}, 128)

======================Test output======================
logprob:  0.417248, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.964086e-03 [3.406780e-09] 
Layer 'conv1' biases: 2.678403e-07 [5.339706e-11] 
Layer 'conv2' weights[0]: 7.951164e-03 [2.371472e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.394274e-10] 
Layer 'conv3' weights[0]: 7.949410e-03 [2.005972e-09] 
Layer 'conv3' biases: 2.290514e-06 [1.181121e-09] 
Layer 'conv4' weights[0]: 7.982079e-03 [2.100313e-09] 
Layer 'conv4' biases: 9.999993e-01 [9.839471e-09] 
Layer 'conv5' weights[0]: 7.980906e-03 [6.413845e-08] 
Layer 'conv5' biases: 9.999940e-01 [6.900247e-08] 
Layer 'fc6' weights[0]: 7.577561e-03 [5.374382e-09] 
Layer 'fc6' biases: 9.999999e-01 [5.427969e-09] 
Layer 'fc7' weights[0]: 7.102726e-03 [1.129935e-07] 
Layer 'fc7' biases: 9.998595e-01 [9.878059e-08] 
Layer 'fc8' weights[0]: 1.281609e-03 [3.576952e-06] 
Layer 'fc8' biases: 5.689354e-02 [3.037320e-05] 
Train error last 870 batches: 0.435219
-------------------------------------------------------
Not saving because 0.417248 > 0.415666 (22.630: -0.00%)
======================================================= (12.050 sec)
23.711... logprob:  0.469493, 0.125000 (1.470 sec)
23.712... logprob:  0.340645, 0.078125 (1.449 sec)
23.713... logprob:  0.586882, 0.179688 (1.451 sec)
23.714... logprob:  0.466285, 0.125000 (1.463 sec)
23.715... logprob:  0.417165, 0.109375 (1.454 sec)
23.716... logprob:  0.335367, 0.078125 (1.441 sec)
23.717... logprob:  0.429804, 0.117188 (1.427 sec)
23.718... logprob:  0.490346, 0.132812 (1.434 sec)
23.719... logprob:  0.406189, 0.109375 (1.438 sec)
23.720... logprob:  0.433232, 0.117188 (1.448 sec)
23.721... logprob:  0.451602, 0.117188 (1.465 sec)
23.722... logprob:  0.536937, 0.156250 (1.451 sec)
23.723... logprob:  0.416571, 0.109375 (1.446 sec)
23.724... logprob:  0.412768, 0.109375 (1.473 sec)
23.725... logprob:  0.494758, 0.140625 (1.438 sec)
23.726... logprob:  0.338541, 0.085938 (1.427 sec)
23.727... logprob:  0.393283, 0.101562 (1.431 sec)
23.728... logprob:  0.421283, 0.109375 (1.441 sec)
23.729... logprob:  0.387686, 0.093750 (1.438 sec)
23.730... logprob:  0.565875, 0.164062 (1.477 sec)
23.731... logprob:  0.450369, 0.125000 (1.446 sec)
23.732... logprob:  0.311441, 0.070312 (1.569 sec)
23.733... logprob:  0.556585, 0.156250 (1.489 sec)
23.734... logprob:  0.340247, 0.078125 (1.436 sec)
23.735... logprob:  0.527516, 0.148438 (1.430 sec)
23.736... logprob:  0.642790, 0.187500 (1.441 sec)
23.737... logprob:  0.516146, 0.148438 (1.430 sec)
23.738... logprob:  0.459407, 0.125000 (1.435 sec)
23.739... logprob:  0.477801, 0.132812 (1.486 sec)
23.740... logprob:  0.339651, 0.078125 (1.441 sec)
23.741... logprob:  0.393459, 0.101562 (1.440 sec)
23.742... logprob:  0.419710, 0.109375 (1.479 sec)
23.743... logprob:  0.364878, 0.085938 (1.438 sec)
23.744... logprob:  0.519194, 0.148438 (1.433 sec)
23.745... logprob:  0.478154, 0.132812 (1.439 sec)
23.746... logprob:  0.440551, 0.117188 (1.432 sec)
23.747... logprob:  0.425612, 0.109375 (1.435 sec)
23.748... logprob:  0.378097, 0.093750 (1.487 sec)
23.749... logprob:  0.420823, 0.109375 (1.447 sec)
23.750... logprob:  0.512843, 0.140625 (1.445 sec)
23.751... logprob:  0.263620, 0.054688 (1.476 sec)
23.752... logprob:  0.522512, 0.140625 (1.437 sec)
23.753... logprob:  0.441199, 0.117188 (1.440 sec)
23.754... logprob:  0.468426, 0.132812 (1.434 sec)
23.755... logprob:  0.507079, 0.140625 (1.425 sec)
23.756... logprob:  0.440828, 0.117188 (1.440 sec)
23.757... logprob:  0.552382, 0.156250 (1.470 sec)
23.758... logprob:  0.393631, 0.101562 (1.440 sec)
23.759... logprob:  0.459695, 0.125000 (1.455 sec)
23.760... logprob:  0.485487, 0.132812 (1.466 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.59919738769531, 10.0]}, 128)
batch 872: ({'logprob': [66.10633850097656, 19.0]}, 128)
batch 873: ({'logprob': [41.4271354675293, 9.0]}, 128)
batch 874: ({'logprob': [45.8608512878418, 11.0]}, 128)
batch 875: ({'logprob': [51.11644744873047, 13.0]}, 128)
batch 876: ({'logprob': [63.705322265625, 18.0]}, 128)
batch 877: ({'logprob': [46.28143310546875, 11.0]}, 128)
batch 878: ({'logprob': [61.67432403564453, 17.0]}, 128)
batch 879: ({'logprob': [72.6049575805664, 21.0]}, 128)
batch 880: ({'logprob': [51.13828659057617, 13.0]}, 128)
batch 881: ({'logprob': [30.46214485168457, 5.0]}, 128)
batch 882: ({'logprob': [54.79927444458008, 14.0]}, 128)
batch 883: ({'logprob': [61.65153884887695, 17.0]}, 128)
batch 884: ({'logprob': [51.532997131347656, 13.0]}, 128)
batch 885: ({'logprob': [52.35759735107422, 13.0]}, 128)
batch 886: ({'logprob': [62.080204010009766, 17.0]}, 128)

======================Test output======================
logprob:  0.417675, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.964057e-03 [2.625408e-09] 
Layer 'conv1' biases: 2.688610e-07 [4.412765e-11] 
Layer 'conv2' weights[0]: 7.951131e-03 [1.898946e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.392547e-10] 
Layer 'conv3' weights[0]: 7.949371e-03 [1.592915e-09] 
Layer 'conv3' biases: 2.300409e-06 [7.707850e-10] 
Layer 'conv4' weights[0]: 7.982042e-03 [1.617054e-09] 
Layer 'conv4' biases: 9.999993e-01 [6.384973e-09] 
Layer 'conv5' weights[0]: 7.980861e-03 [4.218748e-08] 
Layer 'conv5' biases: 9.999945e-01 [4.548705e-08] 
Layer 'fc6' weights[0]: 7.577530e-03 [3.584835e-09] 
Layer 'fc6' biases: 9.999999e-01 [3.564012e-09] 
Layer 'fc7' weights[0]: 7.100919e-03 [2.291191e-07] 
Layer 'fc7' biases: 9.998593e-01 [2.187337e-07] 
Layer 'fc8' weights[0]: 1.277760e-03 [7.870734e-06] 
Layer 'fc8' biases: 5.698651e-02 [5.014678e-05] 
Train error last 870 batches: 0.435218
-------------------------------------------------------
Not saving because 0.417675 > 0.415666 (22.630: -0.00%)
======================================================= (12.044 sec)
23.761... logprob:  0.418267, 0.109375 (1.456 sec)
23.762... logprob:  0.516025, 0.148438 (1.443 sec)
23.763... logprob:  0.558891, 0.164062 (1.427 sec)
23.764... logprob:  0.503276, 0.140625 (1.426 sec)
23.765... logprob:  0.311975, 0.062500 (1.443 sec)
23.766... logprob:  0.482250, 0.132812 (1.453 sec)
23.767... logprob:  0.371125, 0.085938 (1.452 sec)
23.768... logprob:  0.432679, 0.117188 (1.468 sec)
23.769... logprob:  0.490844, 0.140625 (1.466 sec)
23.770... logprob:  0.402909, 0.101562 (1.481 sec)
23.771... logprob:  0.549519, 0.156250 (1.453 sec)
23.772... logprob:  0.414069, 0.109375 (1.447 sec)
23.773... logprob:  0.557893, 0.164062 (1.450 sec)
23.774... logprob:  0.361668, 0.085938 (1.456 sec)
23.775... logprob:  0.407359, 0.101562 (1.471 sec)
23.776... logprob:  0.433192, 0.117188 (1.487 sec)
23.777... logprob:  0.379950, 0.093750 (1.477 sec)
23.778... logprob:  0.433580, 0.117188 (1.463 sec)
23.779... logprob:  0.505397, 0.140625 (1.492 sec)
23.780... logprob:  0.385760, 0.101562 (1.454 sec)
23.781... logprob:  0.369671, 0.085938 (1.453 sec)
23.782... logprob:  0.351450, 0.085938 (1.473 sec)
23.783... logprob:  0.555505, 0.156250 (1.461 sec)
23.784... logprob:  0.440956, 0.117188 (1.460 sec)
23.785... logprob:  0.543631, 0.156250 (1.493 sec)
23.786... logprob:  0.477484, 0.132812 (1.475 sec)
23.787... logprob:  0.546356, 0.156250 (1.459 sec)
23.788... logprob:  0.563097, 0.164062 (1.499 sec)
23.789... logprob:  0.281029, 0.054688 (1.454 sec)
23.790... logprob:  0.408106, 0.101562 (1.450 sec)
23.791... logprob:  0.397998, 0.101562 (1.447 sec)
23.792... logprob:  0.361075, 0.085938 (1.465 sec)
23.793... logprob:  0.370173, 0.085938 (1.470 sec)
23.794... logprob:  0.387130, 0.093750 (1.500 sec)
23.795... logprob:  0.469769, 0.125000 (1.463 sec)
23.796... logprob:  0.423505, 0.109375 (1.457 sec)
23.797... logprob:  0.358804, 0.085938 (1.500 sec)
23.798... logprob:  0.393281, 0.101562 (1.451 sec)
23.799... logprob:  0.332331, 0.078125 (1.451 sec)
23.800... logprob:  0.371732, 0.093750 (1.448 sec)
23.801... logprob:  0.450130, 0.117188 (1.466 sec)
23.802... logprob:  0.423006, 0.109375 (1.452 sec)
23.803... logprob:  0.491715, 0.132812 (1.489 sec)
23.804... logprob:  0.349964, 0.085938 (1.462 sec)
23.805... logprob:  0.452286, 0.117188 (1.453 sec)
23.806... logprob:  0.424182, 0.109375 (1.502 sec)
23.807... logprob:  0.443469, 0.117188 (1.452 sec)
23.808... logprob:  0.462357, 0.125000 (1.449 sec)
23.809... logprob:  0.589644, 0.171875 (1.451 sec)
23.810... logprob:  0.442466, 0.117188 (1.460 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.51527404785156, 10.0]}, 128)
batch 872: ({'logprob': [66.6443099975586, 19.0]}, 128)
batch 873: ({'logprob': [40.72563552856445, 9.0]}, 128)
batch 874: ({'logprob': [45.59870147705078, 11.0]}, 128)
batch 875: ({'logprob': [50.9735107421875, 13.0]}, 128)
batch 876: ({'logprob': [64.10420989990234, 18.0]}, 128)
batch 877: ({'logprob': [45.85919189453125, 11.0]}, 128)
batch 878: ({'logprob': [61.77299880981445, 17.0]}, 128)
batch 879: ({'logprob': [72.7864761352539, 21.0]}, 128)
batch 880: ({'logprob': [50.99623107910156, 13.0]}, 128)
batch 881: ({'logprob': [29.677854537963867, 5.0]}, 128)
batch 882: ({'logprob': [54.319862365722656, 14.0]}, 128)
batch 883: ({'logprob': [61.749942779541016, 17.0]}, 128)
batch 884: ({'logprob': [51.23251724243164, 13.0]}, 128)
batch 885: ({'logprob': [51.738555908203125, 13.0]}, 128)
batch 886: ({'logprob': [62.020416259765625, 17.0]}, 128)

======================Test output======================
logprob:  0.416365, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.964020e-03 [4.227992e-09] 
Layer 'conv1' biases: 2.699090e-07 [1.413187e-10] 
Layer 'conv2' weights[0]: 7.951091e-03 [3.943301e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.314411e-10] 
Layer 'conv3' weights[0]: 7.949333e-03 [3.745431e-09] 
Layer 'conv3' biases: 2.309943e-06 [2.230413e-09] 
Layer 'conv4' weights[0]: 7.981999e-03 [3.743432e-09] 
Layer 'conv4' biases: 9.999992e-01 [1.826893e-08] 
Layer 'conv5' weights[0]: 7.980816e-03 [1.165547e-07] 
Layer 'conv5' biases: 9.999947e-01 [1.255827e-07] 
Layer 'fc6' weights[0]: 7.577487e-03 [9.799412e-09] 
Layer 'fc6' biases: 9.999999e-01 [9.901966e-09] 
Layer 'fc7' weights[0]: 7.099081e-03 [4.209998e-07] 
Layer 'fc7' biases: 9.998595e-01 [4.096756e-07] 
Layer 'fc8' weights[0]: 1.289529e-03 [1.546558e-05] 
Layer 'fc8' biases: 5.725777e-02 [9.698097e-05] 
Train error last 870 batches: 0.435218
-------------------------------------------------------
Not saving because 0.416365 > 0.415666 (22.630: -0.00%)
======================================================= (12.043 sec)
23.811... logprob:  0.460418, 0.125000 (1.455 sec)
23.812... logprob:  0.462371, 0.125000 (1.496 sec)
23.813... logprob:  0.485964, 0.132812 (1.462 sec)
23.814... logprob:  0.478026, 0.132812 (1.454 sec)
23.815... logprob:  0.371897, 0.085938 (1.507 sec)
23.816... logprob:  0.408739, 0.101562 (1.451 sec)
23.817... logprob:  0.425978, 0.109375 (1.455 sec)
23.818... logprob:  0.559987, 0.164062 (1.447 sec)
23.819... logprob:  0.498198, 0.140625 (1.453 sec)
23.820... logprob:  0.421618, 0.109375 (1.455 sec)
23.821... logprob:  0.406570, 0.101562 (1.502 sec)
23.822... logprob:  0.441180, 0.117188 (1.454 sec)
23.823... logprob:  0.340797, 0.078125 (1.457 sec)
23.824... logprob:  0.489822, 0.132812 (1.503 sec)
23.825... logprob:  0.287953, 0.062500 (1.453 sec)
23.826... logprob:  0.375468, 0.093750 (1.461 sec)
23.827... logprob:  0.420545, 0.109375 (1.445 sec)
23.828... logprob:  0.443393, 0.117188 (1.458 sec)
23.829... logprob:  0.504237, 0.140625 (1.452 sec)
23.830... logprob:  0.442206, 0.117188 (1.514 sec)
23.831... logprob:  0.513995, 0.140625 (1.455 sec)
23.832... logprob:  0.330846, 0.078125 (1.461 sec)
23.833... logprob:  0.489010, 0.132812 (1.497 sec)
23.834... logprob:  0.433292, 0.117188 (1.454 sec)
23.835... logprob:  0.542705, 0.148438 (1.460 sec)
23.836... logprob:  0.376206, 0.093750 (1.448 sec)
23.837... logprob:  0.314394, 0.070312 (1.454 sec)
23.838... logprob:  0.437076, 0.117188 (1.452 sec)
23.839... logprob:  0.471683, 0.125000 (1.506 sec)
23.840... logprob:  0.555400, 0.156250 (1.451 sec)
23.841... logprob:  0.396138, 0.101562 (1.470 sec)
23.842... logprob:  0.497844, 0.140625 (1.500 sec)
23.843... logprob:  0.465523, 0.125000 (1.457 sec)
23.844... logprob:  0.497642, 0.140625 (1.456 sec)
23.845... logprob:  0.486781, 0.132812 (1.454 sec)
23.846... logprob:  0.468441, 0.125000 (1.450 sec)
23.847... logprob:  0.363305, 0.085938 (1.457 sec)
23.848... logprob:  0.397134, 0.101562 (1.497 sec)
23.849... logprob:  0.360436, 0.085938 (1.462 sec)
23.850... logprob:  0.479402, 0.132812 (1.466 sec)
23.851... logprob:  0.440143, 0.117188 (1.492 sec)
23.852... logprob:  0.545606, 0.156250 (1.452 sec)
23.853... logprob:  0.371897, 0.093750 (1.467 sec)
23.854... logprob:  0.307205, 0.070312 (1.451 sec)
23.855... logprob:  0.484837, 0.132812 (1.479 sec)
23.856... logprob:  0.443780, 0.117188 (1.456 sec)
23.857... logprob:  0.372231, 0.093750 (1.491 sec)
23.858... logprob:  0.396246, 0.101562 (1.455 sec)
23.859... logprob:  0.307968, 0.070312 (1.475 sec)
23.860... logprob:  0.565977, 0.156250 (1.487 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.27873992919922, 10.0]}, 128)
batch 872: ({'logprob': [67.66698455810547, 19.0]}, 128)
batch 873: ({'logprob': [39.71388244628906, 9.0]}, 128)
batch 874: ({'logprob': [44.82872009277344, 11.0]}, 128)
batch 875: ({'logprob': [50.71918869018555, 13.0]}, 128)
batch 876: ({'logprob': [64.93838500976562, 18.0]}, 128)
batch 877: ({'logprob': [45.22509765625, 11.0]}, 128)
batch 878: ({'logprob': [62.55377960205078, 17.0]}, 128)
batch 879: ({'logprob': [74.73877716064453, 21.0]}, 128)
batch 880: ({'logprob': [50.74241638183594, 13.0]}, 128)
batch 881: ({'logprob': [27.492074966430664, 5.0]}, 128)
batch 882: ({'logprob': [54.67107009887695, 14.0]}, 128)
batch 883: ({'logprob': [62.53031921386719, 17.0]}, 128)
batch 884: ({'logprob': [51.119510650634766, 13.0]}, 128)
batch 885: ({'logprob': [51.90143585205078, 13.0]}, 128)
batch 886: ({'logprob': [62.94091033935547, 17.0]}, 128)

======================Test output======================
logprob:  0.416534, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.963975e-03 [4.559057e-09] 
Layer 'conv1' biases: 2.708045e-07 [1.175856e-10] 
Layer 'conv2' weights[0]: 7.951058e-03 [3.266505e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.384271e-10] 
Layer 'conv3' weights[0]: 7.949285e-03 [3.023451e-09] 
Layer 'conv3' biases: 2.315554e-06 [1.949334e-09] 
Layer 'conv4' weights[0]: 7.981963e-03 [3.123328e-09] 
Layer 'conv4' biases: 9.999993e-01 [1.711132e-08] 
Layer 'conv5' weights[0]: 7.980781e-03 [1.131734e-07] 
Layer 'conv5' biases: 9.999939e-01 [1.220032e-07] 
Layer 'fc6' weights[0]: 7.577453e-03 [9.542948e-09] 
Layer 'fc6' biases: 9.999999e-01 [9.615733e-09] 
Layer 'fc7' weights[0]: 7.097308e-03 [4.474161e-08] 
Layer 'fc7' biases: 9.998611e-01 [2.357786e-08] 
Layer 'fc8' weights[0]: 1.328343e-03 [9.158511e-07] 
Layer 'fc8' biases: 5.776838e-02 [3.093293e-06] 
Train error last 870 batches: 0.435218
-------------------------------------------------------
Not saving because 0.416534 > 0.415666 (22.630: -0.00%)
======================================================= (12.047 sec)
23.861... logprob:  0.417808, 0.109375 (1.463 sec)
23.862... logprob:  0.328878, 0.078125 (1.464 sec)
23.863... logprob:  0.399549, 0.101562 (1.445 sec)
23.864... logprob:  0.451449, 0.117188 (1.449 sec)
23.865... logprob:  0.484515, 0.132812 (1.454 sec)
23.866... logprob:  0.507661, 0.140625 (1.490 sec)
23.867... logprob:  0.503009, 0.140625 (1.478 sec)
23.868... logprob:  0.405294, 0.101562 (1.470 sec)
23.869... logprob:  0.383198, 0.093750 (1.480 sec)
23.870... logprob:  0.552102, 0.156250 (1.402 sec)
24.1... logprob:  0.380038, 0.093750 (1.406 sec)
24.2... logprob:  0.448263, 0.117188 (1.453 sec)
24.3... logprob:  0.398334, 0.101562 (1.419 sec)
24.4... logprob:  0.443320, 0.117188 (1.411 sec)
24.5... logprob:  0.443458, 0.117188 (1.434 sec)
24.6... logprob:  0.499115, 0.140625 (1.397 sec)
24.7... logprob:  0.363193, 0.085938 (1.420 sec)
24.8... logprob:  0.419141, 0.109375 (1.400 sec)
24.9... logprob:  0.358810, 0.085938 (1.401 sec)
24.10... logprob:  0.377507, 0.093750 (1.409 sec)
24.11... logprob:  0.334762, 0.078125 (1.441 sec)
24.12... logprob:  0.466378, 0.125000 (1.404 sec)
24.13... logprob:  0.442253, 0.117188 (1.419 sec)
24.14... logprob:  0.444633, 0.117188 (1.405 sec)
24.15... logprob:  0.395560, 0.101562 (1.415 sec)
24.16... logprob:  0.421401, 0.109375 (1.407 sec)
24.17... logprob:  0.516013, 0.140625 (1.398 sec)
24.18... logprob:  0.262105, 0.054688 (1.417 sec)
24.19... logprob:  0.279535, 0.062500 (1.404 sec)
24.20... logprob:  0.421372, 0.109375 (1.403 sec)
24.21... logprob:  0.443976, 0.117188 (1.407 sec)
24.22... logprob:  0.536702, 0.148438 (1.418 sec)
24.23... logprob:  0.533013, 0.148438 (1.422 sec)
24.24... logprob:  0.310592, 0.070312 (1.420 sec)
24.25... logprob:  0.356201, 0.085938 (1.407 sec)
24.26... logprob:  0.463751, 0.125000 (1.445 sec)
24.27... logprob:  0.404543, 0.101562 (1.393 sec)
24.28... logprob:  0.421856, 0.109375 (1.410 sec)
24.29... logprob:  0.395974, 0.101562 (1.428 sec)
24.30... logprob:  0.374106, 0.093750 (1.422 sec)
24.31... logprob:  0.479944, 0.132812 (1.404 sec)
24.32... logprob:  0.457226, 0.125000 (1.394 sec)
24.33... logprob:  0.460677, 0.125000 (1.445 sec)
24.34... logprob:  0.464561, 0.125000 (1.397 sec)
24.35... logprob:  0.316279, 0.070312 (1.402 sec)
24.36... logprob:  0.475794, 0.132812 (1.404 sec)
24.37... logprob:  0.417592, 0.109375 (1.410 sec)
24.38... logprob:  0.392621, 0.101562 (1.398 sec)
24.39... logprob:  0.631612, 0.187500 (1.435 sec)
24.40... logprob:  0.445738, 0.117188 (1.414 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.276668548583984, 10.0]}, 128)
batch 872: ({'logprob': [66.38436126708984, 19.0]}, 128)
batch 873: ({'logprob': [40.9022102355957, 9.0]}, 128)
batch 874: ({'logprob': [45.544158935546875, 11.0]}, 128)
batch 875: ({'logprob': [50.92795181274414, 13.0]}, 128)
batch 876: ({'logprob': [63.899688720703125, 18.0]}, 128)
batch 877: ({'logprob': [45.92458724975586, 11.0]}, 128)
batch 878: ({'logprob': [61.744468688964844, 17.0]}, 128)
batch 879: ({'logprob': [72.89411926269531, 21.0]}, 128)
batch 880: ({'logprob': [50.9504280090332, 13.0]}, 128)
batch 881: ({'logprob': [29.717857360839844, 5.0]}, 128)
batch 882: ({'logprob': [54.577850341796875, 14.0]}, 128)
batch 883: ({'logprob': [61.7213020324707, 17.0]}, 128)
batch 884: ({'logprob': [51.30648422241211, 13.0]}, 128)
batch 885: ({'logprob': [52.05238723754883, 13.0]}, 128)
batch 886: ({'logprob': [62.11167907714844, 17.0]}, 128)

======================Test output======================
logprob:  0.416473, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.963939e-03 [4.519725e-09] 
Layer 'conv1' biases: 2.718056e-07 [1.081223e-10] 
Layer 'conv2' weights[0]: 7.951028e-03 [2.727423e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.565602e-10] 
Layer 'conv3' weights[0]: 7.949247e-03 [2.317175e-09] 
Layer 'conv3' biases: 2.324615e-06 [1.358342e-09] 
Layer 'conv4' weights[0]: 7.981922e-03 [2.311791e-09] 
Layer 'conv4' biases: 9.999993e-01 [1.034629e-08] 
Layer 'conv5' weights[0]: 7.980749e-03 [6.817116e-08] 
Layer 'conv5' biases: 9.999943e-01 [7.337706e-08] 
Layer 'fc6' weights[0]: 7.577411e-03 [5.679854e-09] 
Layer 'fc6' biases: 9.999999e-01 [5.766337e-09] 
Layer 'fc7' weights[0]: 7.095518e-03 [1.104802e-07] 
Layer 'fc7' biases: 9.998595e-01 [9.696090e-08] 
Layer 'fc8' weights[0]: 1.282045e-03 [6.822476e-06] 
Layer 'fc8' biases: 5.757977e-02 [4.488989e-05] 
Train error last 870 batches: 0.435218
-------------------------------------------------------
Not saving because 0.416473 > 0.415666 (22.630: -0.00%)
======================================================= (12.076 sec)
24.41... logprob:  0.352901, 0.085938 (1.428 sec)
24.42... logprob:  0.391946, 0.101562 (1.428 sec)
24.43... logprob:  0.440091, 0.117188 (1.411 sec)
24.44... logprob:  0.518544, 0.148438 (1.441 sec)
24.45... logprob:  0.381743, 0.093750 (1.390 sec)
24.46... logprob:  0.486250, 0.132812 (1.398 sec)
24.47... logprob:  0.331731, 0.078125 (1.401 sec)
24.48... logprob:  0.498915, 0.140625 (1.425 sec)
24.49... logprob:  0.510795, 0.148438 (1.417 sec)
24.50... logprob:  0.393204, 0.101562 (1.423 sec)
24.51... logprob:  0.490171, 0.140625 (1.418 sec)
24.52... logprob:  0.525785, 0.148438 (1.429 sec)
24.53... logprob:  0.294886, 0.062500 (1.454 sec)
24.54... logprob:  0.403345, 0.109375 (1.395 sec)
24.55... logprob:  0.331730, 0.078125 (1.401 sec)
24.56... logprob:  0.421651, 0.109375 (1.405 sec)
24.57... logprob:  0.572413, 0.164062 (1.430 sec)
24.58... logprob:  0.407627, 0.101562 (1.411 sec)
24.59... logprob:  0.333865, 0.078125 (1.466 sec)
24.60... logprob:  0.618835, 0.179688 (1.429 sec)
24.61... logprob:  0.382826, 0.093750 (1.427 sec)
24.62... logprob:  0.474861, 0.132812 (1.461 sec)
24.63... logprob:  0.397296, 0.101562 (1.443 sec)
24.64... logprob:  0.450304, 0.125000 (1.410 sec)
24.65... logprob:  0.373359, 0.093750 (1.403 sec)
24.66... logprob:  0.354028, 0.085938 (1.445 sec)
24.67... logprob:  0.295408, 0.062500 (1.393 sec)
24.68... logprob:  0.396805, 0.101562 (1.405 sec)
24.69... logprob:  0.496727, 0.140625 (1.431 sec)
24.70... logprob:  0.325891, 0.078125 (1.427 sec)
24.71... logprob:  0.381813, 0.101562 (1.468 sec)
24.72... logprob:  0.493750, 0.132812 (1.409 sec)
24.73... logprob:  0.447717, 0.117188 (1.429 sec)
24.74... logprob:  0.442542, 0.117188 (1.421 sec)
24.75... logprob:  0.380650, 0.093750 (1.421 sec)
24.76... logprob:  0.412060, 0.109375 (1.436 sec)
24.77... logprob:  0.396343, 0.101562 (1.432 sec)
24.78... logprob:  0.493058, 0.140625 (1.457 sec)
24.79... logprob:  0.456462, 0.125000 (1.398 sec)
24.80... logprob:  0.507976, 0.132812 (1.426 sec)
24.81... logprob:  0.416724, 0.109375 (1.414 sec)
24.82... logprob:  0.231443, 0.039062 (1.429 sec)
24.83... logprob:  0.493785, 0.140625 (1.403 sec)
24.84... logprob:  0.468122, 0.125000 (1.466 sec)
24.85... logprob:  0.431963, 0.117188 (1.427 sec)
24.86... logprob:  0.416949, 0.109375 (1.418 sec)
24.87... logprob:  0.633256, 0.187500 (1.420 sec)
24.88... logprob:  0.535047, 0.156250 (1.406 sec)
24.89... logprob:  0.410578, 0.109375 (1.440 sec)
24.90... logprob:  0.577489, 0.171875 (1.391 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.10566329956055, 10.0]}, 128)
batch 872: ({'logprob': [65.80113220214844, 19.0]}, 128)
batch 873: ({'logprob': [42.328487396240234, 9.0]}, 128)
batch 874: ({'logprob': [46.41436767578125, 11.0]}, 128)
batch 875: ({'logprob': [51.50068283081055, 13.0]}, 128)
batch 876: ({'logprob': [63.52893829345703, 18.0]}, 128)
batch 877: ({'logprob': [46.92443084716797, 11.0]}, 128)
batch 878: ({'logprob': [61.717010498046875, 17.0]}, 128)
batch 879: ({'logprob': [72.39454650878906, 21.0]}, 128)
batch 880: ({'logprob': [51.521888732910156, 13.0]}, 128)
batch 881: ({'logprob': [31.617053985595703, 5.0]}, 128)
batch 882: ({'logprob': [55.31819534301758, 14.0]}, 128)
batch 883: ({'logprob': [61.69449996948242, 17.0]}, 128)
batch 884: ({'logprob': [52.00387954711914, 13.0]}, 128)
batch 885: ({'logprob': [53.0055046081543, 13.0]}, 128)
batch 886: ({'logprob': [62.2105827331543, 17.0]}, 128)

======================Test output======================
logprob:  0.420453, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.963887e-03 [4.033700e-09] 
Layer 'conv1' biases: 2.728428e-07 [1.089052e-10] 
Layer 'conv2' weights[0]: 7.950997e-03 [3.117703e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.614009e-10] 
Layer 'conv3' weights[0]: 7.949212e-03 [2.674204e-09] 
Layer 'conv3' biases: 2.332646e-06 [1.728025e-09] 
Layer 'conv4' weights[0]: 7.981888e-03 [2.756568e-09] 
Layer 'conv4' biases: 9.999992e-01 [1.409074e-08] 
Layer 'conv5' weights[0]: 7.980702e-03 [8.941201e-08] 
Layer 'conv5' biases: 9.999944e-01 [9.634049e-08] 
Layer 'fc6' weights[0]: 7.577369e-03 [7.436820e-09] 
Layer 'fc6' biases: 9.999999e-01 [7.557497e-09] 
Layer 'fc7' weights[0]: 7.093742e-03 [2.513682e-07] 
Layer 'fc7' biases: 9.998588e-01 [2.416366e-07] 
Layer 'fc8' weights[0]: 1.255332e-03 [9.402927e-06] 
Layer 'fc8' biases: 5.742450e-02 [6.213844e-05] 
Train error last 870 batches: 0.435218
-------------------------------------------------------
Not saving because 0.420453 > 0.415666 (22.630: -0.00%)
======================================================= (12.037 sec)
24.91... logprob:  0.348469, 0.078125 (1.403 sec)
24.92... logprob:  0.464461, 0.125000 (1.410 sec)
24.93... logprob:  0.492234, 0.140625 (1.401 sec)
24.94... logprob:  0.428784, 0.109375 (1.388 sec)
24.95... logprob:  0.471839, 0.125000 (1.402 sec)
24.96... logprob:  0.576241, 0.171875 (1.404 sec)
24.97... logprob:  0.430776, 0.117188 (1.393 sec)
24.98... logprob:  0.391141, 0.093750 (1.440 sec)
24.99... logprob:  0.474251, 0.132812 (1.415 sec)
24.100... logprob:  0.310524, 0.070312 (1.406 sec)
24.101... logprob:  0.310773, 0.062500 (1.451 sec)
24.102... logprob:  0.546073, 0.156250 (1.392 sec)
24.103... logprob:  0.541071, 0.156250 (1.402 sec)
24.104... logprob:  0.388831, 0.101562 (1.403 sec)
24.105... logprob:  0.619469, 0.179688 (1.393 sec)
24.106... logprob:  0.344452, 0.085938 (1.399 sec)
24.107... logprob:  0.335758, 0.078125 (1.438 sec)
24.108... logprob:  0.586845, 0.171875 (1.394 sec)
24.109... logprob:  0.336152, 0.078125 (1.415 sec)
24.110... logprob:  0.564581, 0.164062 (1.399 sec)
24.111... logprob:  0.404689, 0.101562 (1.396 sec)
24.112... logprob:  0.366062, 0.093750 (1.404 sec)
24.113... logprob:  0.354514, 0.085938 (1.399 sec)
24.114... logprob:  0.440218, 0.117188 (1.435 sec)
24.115... logprob:  0.506757, 0.140625 (1.409 sec)
24.116... logprob:  0.393368, 0.101562 (1.404 sec)
24.117... logprob:  0.440393, 0.117188 (1.445 sec)
24.118... logprob:  0.409119, 0.101562 (1.392 sec)
24.119... logprob:  0.346102, 0.085938 (1.402 sec)
24.120... logprob:  0.547134, 0.156250 (1.406 sec)
24.121... logprob:  0.412624, 0.109375 (1.400 sec)
24.122... logprob:  0.519294, 0.148438 (1.446 sec)
24.123... logprob:  0.463698, 0.125000 (1.394 sec)
24.124... logprob:  0.447696, 0.125000 (1.411 sec)
24.125... logprob:  0.501946, 0.140625 (1.402 sec)
24.126... logprob:  0.475761, 0.125000 (1.394 sec)
24.127... logprob:  0.479548, 0.125000 (1.398 sec)
24.128... logprob:  0.422348, 0.109375 (1.419 sec)
24.129... logprob:  0.574889, 0.164062 (1.418 sec)
24.130... logprob:  0.382718, 0.093750 (1.419 sec)
24.131... logprob:  0.495497, 0.132812 (1.412 sec)
24.132... logprob:  0.506367, 0.140625 (1.431 sec)
24.133... logprob:  0.444685, 0.117188 (1.402 sec)
24.134... logprob:  0.401885, 0.101562 (1.404 sec)
24.135... logprob:  0.460206, 0.125000 (1.402 sec)
24.136... logprob:  0.562445, 0.164062 (1.400 sec)
24.137... logprob:  0.462580, 0.125000 (1.398 sec)
24.138... logprob:  0.319377, 0.070312 (1.452 sec)
24.139... logprob:  0.395757, 0.101562 (1.395 sec)
24.140... logprob:  0.560228, 0.164062 (1.415 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.48123550415039, 10.0]}, 128)
batch 872: ({'logprob': [66.6681900024414, 19.0]}, 128)
batch 873: ({'logprob': [40.68439483642578, 9.0]}, 128)
batch 874: ({'logprob': [45.57095718383789, 11.0]}, 128)
batch 875: ({'logprob': [50.958351135253906, 13.0]}, 128)
batch 876: ({'logprob': [64.12206268310547, 18.0]}, 128)
batch 877: ({'logprob': [45.83124923706055, 11.0]}, 128)
batch 878: ({'logprob': [61.7840690612793, 17.0]}, 128)
batch 879: ({'logprob': [72.82317352294922, 21.0]}, 128)
batch 880: ({'logprob': [50.98141860961914, 13.0]}, 128)
batch 881: ({'logprob': [29.61099624633789, 5.0]}, 128)
batch 882: ({'logprob': [54.311092376708984, 14.0]}, 128)
batch 883: ({'logprob': [61.76051712036133, 17.0]}, 128)
batch 884: ({'logprob': [51.21767044067383, 13.0]}, 128)
batch 885: ({'logprob': [51.723289489746094, 13.0]}, 128)
batch 886: ({'logprob': [62.03144454956055, 17.0]}, 128)

======================Test output======================
logprob:  0.416289, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.963851e-03 [3.238399e-09] 
Layer 'conv1' biases: 2.736357e-07 [5.546954e-11] 
Layer 'conv2' weights[0]: 7.950960e-03 [2.099262e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.173895e-10] 
Layer 'conv3' weights[0]: 7.949171e-03 [1.668575e-09] 
Layer 'conv3' biases: 2.337617e-06 [9.258351e-10] 
Layer 'conv4' weights[0]: 7.981850e-03 [1.590358e-09] 
Layer 'conv4' biases: 9.999993e-01 [6.449975e-09] 
Layer 'conv5' weights[0]: 7.980676e-03 [3.063879e-08] 
Layer 'conv5' biases: 9.999940e-01 [3.224705e-08] 
Layer 'fc6' weights[0]: 7.577330e-03 [2.679202e-09] 
Layer 'fc6' biases: 9.999999e-01 [2.604385e-09] 
Layer 'fc7' weights[0]: 7.091925e-03 [1.122275e-07] 
Layer 'fc7' biases: 9.998594e-01 [9.809469e-08] 
Layer 'fc8' weights[0]: 1.286903e-03 [3.889729e-06] 
Layer 'fc8' biases: 5.776699e-02 [2.781573e-05] 
Train error last 870 batches: 0.435217
-------------------------------------------------------
Not saving because 0.416289 > 0.415666 (22.630: -0.00%)
======================================================= (12.045 sec)
24.141... logprob:  0.464564, 0.125000 (1.443 sec)
24.142... logprob:  0.464626, 0.125000 (1.405 sec)
24.143... logprob:  0.294360, 0.062500 (1.424 sec)
24.144... logprob:  0.457141, 0.125000 (1.421 sec)
24.145... logprob:  0.324781, 0.078125 (1.416 sec)
24.146... logprob:  0.483140, 0.132812 (1.415 sec)
24.147... logprob:  0.262478, 0.054688 (1.432 sec)
24.148... logprob:  0.458693, 0.125000 (1.395 sec)
24.149... logprob:  0.442523, 0.117188 (1.402 sec)
24.150... logprob:  0.347595, 0.085938 (1.404 sec)
24.151... logprob:  0.347145, 0.085938 (1.401 sec)
24.152... logprob:  0.785085, 0.234375 (1.385 sec)
24.153... logprob:  0.381651, 0.093750 (1.452 sec)
24.154... logprob:  0.524574, 0.148438 (1.398 sec)
24.155... logprob:  0.426058, 0.117188 (1.414 sec)
24.156... logprob:  0.295475, 0.062500 (1.442 sec)
24.157... logprob:  0.270383, 0.054688 (1.394 sec)
24.158... logprob:  0.455410, 0.125000 (1.408 sec)
24.159... logprob:  0.483118, 0.132812 (1.397 sec)
24.160... logprob:  0.444774, 0.117188 (1.399 sec)
24.161... logprob:  0.349878, 0.078125 (1.431 sec)
24.162... logprob:  0.611786, 0.179688 (1.408 sec)
24.163... logprob:  0.450459, 0.125000 (1.426 sec)
24.164... logprob:  0.468588, 0.125000 (1.423 sec)
24.165... logprob:  0.547835, 0.156250 (1.418 sec)
24.166... logprob:  0.446112, 0.125000 (1.454 sec)
24.167... logprob:  0.350533, 0.085938 (1.440 sec)
24.168... logprob:  0.363720, 0.085938 (1.421 sec)
24.169... logprob:  0.408650, 0.101562 (1.466 sec)
24.170... logprob:  0.459474, 0.125000 (1.400 sec)
24.171... logprob:  0.535318, 0.156250 (1.426 sec)
24.172... logprob:  0.434830, 0.109375 (1.416 sec)
24.173... logprob:  0.440478, 0.117188 (1.421 sec)
24.174... logprob:  0.600874, 0.171875 (1.409 sec)
24.175... logprob:  0.506010, 0.140625 (1.472 sec)
24.176... logprob:  0.478434, 0.132812 (1.421 sec)
24.177... logprob:  0.289736, 0.054688 (1.427 sec)
24.178... logprob:  0.383477, 0.093750 (1.462 sec)
24.179... logprob:  0.394685, 0.101562 (1.406 sec)
24.180... logprob:  0.466386, 0.125000 (1.421 sec)
24.181... logprob:  0.539326, 0.156250 (1.426 sec)
24.182... logprob:  0.371326, 0.093750 (1.420 sec)
24.183... logprob:  0.419942, 0.109375 (1.422 sec)
24.184... logprob:  0.483449, 0.132812 (1.426 sec)
24.185... logprob:  0.289794, 0.062500 (1.401 sec)
24.186... logprob:  0.370415, 0.093750 (1.397 sec)
24.187... logprob:  0.529618, 0.148438 (1.407 sec)
24.188... logprob:  0.458913, 0.125000 (1.396 sec)
24.189... logprob:  0.440915, 0.117188 (1.392 sec)
24.190... logprob:  0.375772, 0.093750 (1.437 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.671409606933594, 10.0]}, 128)
batch 872: ({'logprob': [67.02267456054688, 19.0]}, 128)
batch 873: ({'logprob': [40.12831497192383, 9.0]}, 128)
batch 874: ({'logprob': [45.063720703125, 11.0]}, 128)
batch 875: ({'logprob': [50.72140121459961, 13.0]}, 128)
batch 876: ({'logprob': [64.39720153808594, 18.0]}, 128)
batch 877: ({'logprob': [45.43414306640625, 11.0]}, 128)
batch 878: ({'logprob': [62.08946228027344, 17.0]}, 128)
batch 879: ({'logprob': [73.78059387207031, 21.0]}, 128)
batch 880: ({'logprob': [50.74480056762695, 13.0]}, 128)
batch 881: ({'logprob': [28.400981903076172, 5.0]}, 128)
batch 882: ({'logprob': [54.48835754394531, 14.0]}, 128)
batch 883: ({'logprob': [62.065574645996094, 17.0]}, 128)
batch 884: ({'logprob': [51.093467712402344, 13.0]}, 128)
batch 885: ({'logprob': [51.821083068847656, 13.0]}, 128)
batch 886: ({'logprob': [62.44871139526367, 17.0]}, 128)

======================Test output======================
logprob:  0.415709, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.963813e-03 [2.669515e-09] 
Layer 'conv1' biases: 2.746884e-07 [4.822669e-11] 
Layer 'conv2' weights[0]: 7.950928e-03 [1.709918e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.378670e-10] 
Layer 'conv3' weights[0]: 7.949134e-03 [1.236127e-09] 
Layer 'conv3' biases: 2.347024e-06 [3.482162e-10] 
Layer 'conv4' weights[0]: 7.981812e-03 [1.179466e-09] 
Layer 'conv4' biases: 9.999993e-01 [5.779313e-10] 
Layer 'conv5' weights[0]: 7.980639e-03 [2.791318e-09] 
Layer 'conv5' biases: 9.999941e-01 [2.472874e-09] 
Layer 'fc6' weights[0]: 7.577284e-03 [7.832344e-10] 
Layer 'fc6' biases: 9.999999e-01 [1.977054e-10] 
Layer 'fc7' weights[0]: 7.090076e-03 [3.600790e-08] 
Layer 'fc7' biases: 9.998600e-01 [5.685261e-09] 
Layer 'fc8' weights[0]: 1.315501e-03 [8.152314e-07] 
Layer 'fc8' biases: 5.806491e-02 [4.525549e-06] 
Train error last 870 batches: 0.435217
-------------------------------------------------------
Not saving because 0.415709 > 0.415666 (22.630: -0.00%)
======================================================= (12.225 sec)
24.191... logprob:  0.485094, 0.132812 (1.413 sec)
24.192... logprob:  0.520079, 0.148438 (1.425 sec)
24.193... logprob:  0.312541, 0.070312 (1.423 sec)
24.194... logprob:  0.414076, 0.109375 (1.417 sec)
24.195... logprob:  0.287104, 0.062500 (1.402 sec)
24.196... logprob:  0.410495, 0.109375 (1.389 sec)
24.197... logprob:  0.477999, 0.132812 (1.412 sec)
24.198... logprob:  0.355795, 0.085938 (1.407 sec)
24.199... logprob:  0.437193, 0.117188 (1.387 sec)
24.200... logprob:  0.440746, 0.117188 (1.446 sec)
24.201... logprob:  0.437092, 0.117188 (1.404 sec)
24.202... logprob:  0.537887, 0.148438 (1.407 sec)
24.203... logprob:  0.420424, 0.109375 (1.443 sec)
24.204... logprob:  0.504123, 0.140625 (1.389 sec)
24.205... logprob:  0.334322, 0.078125 (1.405 sec)
24.206... logprob:  0.361631, 0.093750 (1.401 sec)
24.207... logprob:  0.381814, 0.093750 (1.396 sec)
24.208... logprob:  0.490559, 0.140625 (1.403 sec)
24.209... logprob:  0.334557, 0.078125 (1.420 sec)
24.210... logprob:  0.586233, 0.171875 (1.423 sec)
24.211... logprob:  0.488149, 0.132812 (1.420 sec)
24.212... logprob:  0.526131, 0.148438 (1.417 sec)
24.213... logprob:  0.514684, 0.140625 (1.466 sec)
24.214... logprob:  0.459409, 0.125000 (1.428 sec)
24.215... logprob:  0.396113, 0.101562 (1.417 sec)
24.216... logprob:  0.516988, 0.140625 (1.472 sec)
24.217... logprob:  0.324949, 0.070312 (1.407 sec)
24.218... logprob:  0.463627, 0.125000 (1.429 sec)
24.219... logprob:  0.500255, 0.140625 (1.495 sec)
24.220... logprob:  0.415016, 0.109375 (1.425 sec)
24.221... logprob:  0.399559, 0.101562 (1.402 sec)
24.222... logprob:  0.554467, 0.164062 (1.460 sec)
24.223... logprob:  0.569041, 0.164062 (1.436 sec)
24.224... logprob:  0.405940, 0.101562 (1.434 sec)
24.225... logprob:  0.391991, 0.101562 (1.445 sec)
24.226... logprob:  0.424705, 0.109375 (1.428 sec)
24.227... logprob:  0.452661, 0.125000 (1.412 sec)
24.228... logprob:  0.417178, 0.109375 (1.419 sec)
24.229... logprob:  0.489371, 0.132812 (1.416 sec)
24.230... logprob:  0.459866, 0.125000 (1.447 sec)
24.231... logprob:  0.453508, 0.125000 (1.414 sec)
24.232... logprob:  0.496185, 0.140625 (1.462 sec)
24.233... logprob:  0.466098, 0.132812 (1.434 sec)
24.234... logprob:  0.563844, 0.164062 (1.422 sec)
24.235... logprob:  0.482017, 0.132812 (1.476 sec)
24.236... logprob:  0.425700, 0.109375 (1.407 sec)
24.237... logprob:  0.341071, 0.078125 (1.430 sec)
24.238... logprob:  0.389205, 0.093750 (1.420 sec)
24.239... logprob:  0.478105, 0.132812 (1.425 sec)
24.240... logprob:  0.485798, 0.132812 (1.402 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.318233489990234, 10.0]}, 128)
batch 872: ({'logprob': [66.07444763183594, 19.0]}, 128)
batch 873: ({'logprob': [41.360939025878906, 9.0]}, 128)
batch 874: ({'logprob': [45.71708297729492, 11.0]}, 128)
batch 875: ({'logprob': [51.03573226928711, 13.0]}, 128)
batch 876: ({'logprob': [63.677581787109375, 18.0]}, 128)
batch 877: ({'logprob': [46.20805358886719, 11.0]}, 128)
batch 878: ({'logprob': [61.72037887573242, 17.0]}, 128)
batch 879: ({'logprob': [72.84693145751953, 21.0]}, 128)
batch 880: ({'logprob': [51.05799865722656, 13.0]}, 128)
batch 881: ({'logprob': [30.199129104614258, 5.0]}, 128)
batch 882: ({'logprob': [54.92640686035156, 14.0]}, 128)
batch 883: ({'logprob': [61.697025299072266, 17.0]}, 128)
batch 884: ({'logprob': [51.523075103759766, 13.0]}, 128)
batch 885: ({'logprob': [52.488224029541016, 13.0]}, 128)
batch 886: ({'logprob': [62.1967658996582, 17.0]}, 128)

======================Test output======================
logprob:  0.417504, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.963781e-03 [2.764737e-09] 
Layer 'conv1' biases: 2.755786e-07 [5.659561e-11] 
Layer 'conv2' weights[0]: 7.950888e-03 [1.655112e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.682249e-10] 
Layer 'conv3' weights[0]: 7.949093e-03 [1.278750e-09] 
Layer 'conv3' biases: 2.355074e-06 [4.696395e-10] 
Layer 'conv4' weights[0]: 7.981769e-03 [1.194174e-09] 
Layer 'conv4' biases: 9.999993e-01 [2.576406e-09] 
Layer 'conv5' weights[0]: 7.980596e-03 [1.186180e-08] 
Layer 'conv5' biases: 9.999940e-01 [1.219872e-08] 
Layer 'fc6' weights[0]: 7.577244e-03 [1.262366e-09] 
Layer 'fc6' biases: 9.999999e-01 [9.813886e-10] 
Layer 'fc7' weights[0]: 7.088284e-03 [7.290891e-08] 
Layer 'fc7' biases: 9.998592e-01 [5.663889e-08] 
Layer 'fc8' weights[0]: 1.284846e-03 [2.342583e-06] 
Layer 'fc8' biases: 5.789459e-02 [1.710799e-05] 
Train error last 870 batches: 0.435217
-------------------------------------------------------
Not saving because 0.417504 > 0.415666 (22.630: -0.00%)
======================================================= (12.095 sec)
24.241... logprob:  0.493601, 0.132812 (1.465 sec)
24.242... logprob:  0.341642, 0.078125 (1.446 sec)
24.243... logprob:  0.386004, 0.093750 (1.435 sec)
24.244... logprob:  0.315352, 0.070312 (1.451 sec)
24.245... logprob:  0.494257, 0.132812 (1.422 sec)
24.246... logprob:  0.416866, 0.109375 (1.430 sec)
24.247... logprob:  0.357496, 0.085938 (1.413 sec)
24.248... logprob:  0.307948, 0.070312 (1.422 sec)
24.249... logprob:  0.554868, 0.156250 (1.421 sec)
24.250... logprob:  0.591379, 0.164062 (1.409 sec)
24.251... logprob:  0.352964, 0.085938 (1.463 sec)
24.252... logprob:  0.348452, 0.085938 (1.431 sec)
24.253... logprob:  0.379203, 0.093750 (1.421 sec)
24.254... logprob:  0.444166, 0.117188 (1.467 sec)
24.255... logprob:  0.351380, 0.085938 (1.406 sec)
24.256... logprob:  0.378818, 0.093750 (1.423 sec)
24.257... logprob:  0.331994, 0.078125 (1.420 sec)
24.258... logprob:  0.415608, 0.109375 (1.429 sec)
24.259... logprob:  0.442315, 0.117188 (1.400 sec)
24.260... logprob:  0.308258, 0.070312 (1.464 sec)
24.261... logprob:  0.392650, 0.101562 (1.432 sec)
24.262... logprob:  0.524573, 0.148438 (1.433 sec)
24.263... logprob:  0.425547, 0.109375 (1.451 sec)
24.264... logprob:  0.375068, 0.093750 (1.422 sec)
24.265... logprob:  0.439611, 0.117188 (1.419 sec)
24.266... logprob:  0.439016, 0.117188 (1.415 sec)
24.267... logprob:  0.422024, 0.109375 (1.422 sec)
24.268... logprob:  0.458938, 0.125000 (1.419 sec)
24.269... logprob:  0.567533, 0.164062 (1.412 sec)
24.270... logprob:  0.542288, 0.156250 (1.466 sec)
24.271... logprob:  0.445651, 0.117188 (1.429 sec)
24.272... logprob:  0.384634, 0.093750 (1.421 sec)
24.273... logprob:  0.500226, 0.140625 (1.470 sec)
24.274... logprob:  0.542507, 0.156250 (1.407 sec)
24.275... logprob:  0.487628, 0.132812 (1.425 sec)
24.276... logprob:  0.390069, 0.093750 (1.417 sec)
24.277... logprob:  0.428642, 0.109375 (1.425 sec)
24.278... logprob:  0.323542, 0.070312 (1.424 sec)
24.279... logprob:  0.325172, 0.070312 (1.466 sec)
24.280... logprob:  0.215714, 0.031250 (1.405 sec)
24.281... logprob:  0.417235, 0.109375 (1.424 sec)
24.282... logprob:  0.411363, 0.109375 (1.422 sec)
24.283... logprob:  0.393772, 0.101562 (1.418 sec)
24.284... logprob:  0.394485, 0.101562 (1.407 sec)
24.285... logprob:  0.451668, 0.117188 (1.445 sec)
24.286... logprob:  0.536716, 0.140625 (1.438 sec)
24.287... logprob:  0.346579, 0.085938 (1.434 sec)
24.288... logprob:  0.329954, 0.078125 (1.436 sec)
24.289... logprob:  0.445878, 0.117188 (1.445 sec)
24.290... logprob:  0.490654, 0.132812 (1.406 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.97547912597656, 10.0]}, 128)
batch 872: ({'logprob': [68.60856628417969, 19.0]}, 128)
batch 873: ({'logprob': [39.42875289916992, 9.0]}, 128)
batch 874: ({'logprob': [44.734806060791016, 11.0]}, 128)
batch 875: ({'logprob': [50.905765533447266, 13.0]}, 128)
batch 876: ({'logprob': [65.76296997070312, 18.0]}, 128)
batch 877: ({'logprob': [45.17567825317383, 11.0]}, 128)
batch 878: ({'logprob': [63.30450439453125, 17.0]}, 128)
batch 879: ({'logprob': [76.09745788574219, 21.0]}, 128)
batch 880: ({'logprob': [50.929908752441406, 13.0]}, 128)
batch 881: ({'logprob': [26.59738540649414, 5.0]}, 128)
batch 882: ({'logprob': [55.113243103027344, 14.0]}, 128)
batch 883: ({'logprob': [63.280189514160156, 17.0]}, 128)
batch 884: ({'logprob': [51.353702545166016, 13.0]}, 128)
batch 885: ({'logprob': [52.225746154785156, 13.0]}, 128)
batch 886: ({'logprob': [63.737850189208984, 17.0]}, 128)

======================Test output======================
logprob:  0.419059, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.963745e-03 [6.068912e-09] 
Layer 'conv1' biases: 2.766376e-07 [2.096391e-10] 
Layer 'conv2' weights[0]: 7.950845e-03 [5.093663e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.092753e-09] 
Layer 'conv3' weights[0]: 7.949056e-03 [4.924877e-09] 
Layer 'conv3' biases: 2.361889e-06 [3.250982e-09] 
Layer 'conv4' weights[0]: 7.981728e-03 [4.948056e-09] 
Layer 'conv4' biases: 9.999993e-01 [2.750112e-08] 
Layer 'conv5' weights[0]: 7.980559e-03 [1.760481e-07] 
Layer 'conv5' biases: 9.999940e-01 [1.894693e-07] 
Layer 'fc6' weights[0]: 7.577198e-03 [1.474320e-08] 
Layer 'fc6' biases: 9.999999e-01 [1.507134e-08] 
Layer 'fc7' weights[0]: 7.086465e-03 [2.670099e-07] 
Layer 'fc7' biases: 9.998612e-01 [2.578850e-07] 
Layer 'fc8' weights[0]: 1.361862e-03 [1.052394e-05] 
Layer 'fc8' biases: 5.862696e-02 [5.668482e-05] 
Train error last 870 batches: 0.435216
-------------------------------------------------------
Not saving because 0.419059 > 0.415666 (22.630: -0.00%)
======================================================= (12.024 sec)
24.291... logprob:  0.439265, 0.117188 (1.422 sec)
24.292... logprob:  0.567476, 0.156250 (1.428 sec)
24.293... logprob:  0.427661, 0.117188 (1.420 sec)
24.294... logprob:  0.355889, 0.085938 (1.409 sec)
24.295... logprob:  0.334607, 0.078125 (1.461 sec)
24.296... logprob:  0.355721, 0.085938 (1.427 sec)
24.297... logprob:  0.394503, 0.101562 (1.422 sec)
24.298... logprob:  0.448195, 0.125000 (1.463 sec)
24.299... logprob:  0.342189, 0.078125 (1.407 sec)
24.300... logprob:  0.406478, 0.101562 (1.425 sec)
24.301... logprob:  0.397914, 0.101562 (1.418 sec)
24.302... logprob:  0.591561, 0.179688 (1.416 sec)
24.303... logprob:  0.459535, 0.125000 (1.446 sec)
24.304... logprob:  0.459646, 0.125000 (1.438 sec)
24.305... logprob:  0.455208, 0.125000 (1.440 sec)
24.306... logprob:  0.440586, 0.117188 (1.437 sec)
24.307... logprob:  0.421616, 0.109375 (1.445 sec)
24.308... logprob:  0.374739, 0.093750 (1.451 sec)
24.309... logprob:  0.450482, 0.125000 (1.419 sec)
24.310... logprob:  0.473645, 0.125000 (1.426 sec)
24.311... logprob:  0.502534, 0.140625 (1.423 sec)
24.312... logprob:  0.478717, 0.132812 (1.438 sec)
24.313... logprob:  0.454862, 0.125000 (1.423 sec)
24.314... logprob:  0.454407, 0.117188 (1.466 sec)
24.315... logprob:  0.314675, 0.070312 (1.431 sec)
24.316... logprob:  0.468535, 0.125000 (1.430 sec)
24.317... logprob:  0.355456, 0.085938 (1.476 sec)
24.318... logprob:  0.455407, 0.125000 (1.418 sec)
24.319... logprob:  0.423181, 0.117188 (1.423 sec)
24.320... logprob:  0.412243, 0.109375 (1.432 sec)
24.321... logprob:  0.348257, 0.085938 (1.431 sec)
24.322... logprob:  0.387467, 0.101562 (1.412 sec)
24.323... logprob:  0.416510, 0.109375 (1.477 sec)
24.324... logprob:  0.498607, 0.140625 (1.430 sec)
24.325... logprob:  0.350677, 0.085938 (1.434 sec)
24.326... logprob:  0.543179, 0.148438 (1.466 sec)
24.327... logprob:  0.554405, 0.164062 (1.424 sec)
24.328... logprob:  0.565085, 0.156250 (1.435 sec)
24.329... logprob:  0.401944, 0.101562 (1.422 sec)
24.330... logprob:  0.388562, 0.101562 (1.426 sec)
24.331... logprob:  0.352362, 0.085938 (1.420 sec)
24.332... logprob:  0.482781, 0.132812 (1.452 sec)
24.333... logprob:  0.339537, 0.085938 (1.447 sec)
24.334... logprob:  0.565219, 0.171875 (1.448 sec)
24.335... logprob:  0.358752, 0.085938 (1.440 sec)
24.336... logprob:  0.444849, 0.125000 (1.459 sec)
24.337... logprob:  0.566428, 0.164062 (1.426 sec)
24.338... logprob:  0.449514, 0.125000 (1.422 sec)
24.339... logprob:  0.488630, 0.132812 (1.425 sec)
24.340... logprob:  0.442069, 0.117188 (1.433 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.32640838623047, 10.0]}, 128)
batch 872: ({'logprob': [65.77803039550781, 19.0]}, 128)
batch 873: ({'logprob': [42.10879898071289, 9.0]}, 128)
batch 874: ({'logprob': [46.00984191894531, 11.0]}, 128)
batch 875: ({'logprob': [51.284889221191406, 13.0]}, 128)
batch 876: ({'logprob': [63.50499725341797, 18.0]}, 128)
batch 877: ({'logprob': [46.70611572265625, 11.0]}, 128)
batch 878: ({'logprob': [61.87876510620117, 17.0]}, 128)
batch 879: ({'logprob': [73.11903381347656, 21.0]}, 128)
batch 880: ({'logprob': [51.30600357055664, 13.0]}, 128)
batch 881: ({'logprob': [30.832998275756836, 5.0]}, 128)
batch 882: ({'logprob': [55.66394805908203, 14.0]}, 128)
batch 883: ({'logprob': [61.85599899291992, 17.0]}, 128)
batch 884: ({'logprob': [51.975669860839844, 13.0]}, 128)
batch 885: ({'logprob': [53.350738525390625, 13.0]}, 128)
batch 886: ({'logprob': [62.55955123901367, 17.0]}, 128)

======================Test output======================
logprob:  0.420050, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.963705e-03 [2.778214e-09] 
Layer 'conv1' biases: 2.775094e-07 [4.092443e-11] 
Layer 'conv2' weights[0]: 7.950803e-03 [1.865900e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.664831e-10] 
Layer 'conv3' weights[0]: 7.949017e-03 [1.394853e-09] 
Layer 'conv3' biases: 2.369860e-06 [5.108146e-10] 
Layer 'conv4' weights[0]: 7.981690e-03 [1.311942e-09] 
Layer 'conv4' biases: 9.999992e-01 [2.817940e-09] 
Layer 'conv5' weights[0]: 7.980512e-03 [1.372591e-08] 
Layer 'conv5' biases: 9.999939e-01 [1.445622e-08] 
Layer 'fc6' weights[0]: 7.577165e-03 [1.397788e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.163366e-09] 
Layer 'fc7' weights[0]: 7.084667e-03 [3.610644e-08] 
Layer 'fc7' biases: 9.998592e-01 [6.019864e-09] 
Layer 'fc8' weights[0]: 1.273889e-03 [1.405366e-06] 
Layer 'fc8' biases: 5.819235e-02 [8.553687e-06] 
Train error last 870 batches: 0.435216
-------------------------------------------------------
Not saving because 0.420050 > 0.415666 (22.630: -0.00%)
======================================================= (12.167 sec)
24.341... logprob:  0.530071, 0.148438 (1.427 sec)
24.342... logprob:  0.429630, 0.109375 (1.473 sec)
24.343... logprob:  0.434772, 0.109375 (1.439 sec)
24.344... logprob:  0.444486, 0.125000 (1.484 sec)
24.345... logprob:  0.488214, 0.132812 (1.442 sec)
24.346... logprob:  0.436219, 0.117188 (1.440 sec)
24.347... logprob:  0.372469, 0.085938 (1.481 sec)
24.348... logprob:  0.398465, 0.101562 (1.436 sec)
24.349... logprob:  0.497699, 0.140625 (1.439 sec)
24.350... logprob:  0.358646, 0.085938 (1.434 sec)
24.351... logprob:  0.508557, 0.140625 (1.432 sec)
24.352... logprob:  0.363628, 0.093750 (1.438 sec)
24.353... logprob:  0.512580, 0.148438 (1.486 sec)
24.354... logprob:  0.674926, 0.203125 (1.435 sec)
24.355... logprob:  0.357488, 0.085938 (1.445 sec)
24.356... logprob:  0.479242, 0.132812 (1.481 sec)
24.357... logprob:  0.346845, 0.085938 (1.434 sec)
24.358... logprob:  0.325853, 0.070312 (1.439 sec)
24.359... logprob:  0.555318, 0.164062 (1.435 sec)
24.360... logprob:  0.444519, 0.117188 (1.429 sec)
24.361... logprob:  0.410750, 0.101562 (1.432 sec)
24.362... logprob:  0.424014, 0.117188 (1.483 sec)
24.363... logprob:  0.486585, 0.132812 (1.442 sec)
24.364... logprob:  0.475583, 0.125000 (1.457 sec)
24.365... logprob:  0.425057, 0.109375 (1.464 sec)
24.366... logprob:  0.409616, 0.109375 (1.447 sec)
24.367... logprob:  0.324941, 0.078125 (1.441 sec)
24.368... logprob:  0.595601, 0.171875 (1.431 sec)
24.369... logprob:  0.381615, 0.093750 (1.425 sec)
24.370... logprob:  0.381245, 0.093750 (1.440 sec)
24.371... logprob:  0.400394, 0.101562 (1.462 sec)
24.372... logprob:  0.537368, 0.156250 (1.455 sec)
24.373... logprob:  0.463802, 0.125000 (1.457 sec)
24.374... logprob:  0.526914, 0.148438 (1.449 sec)
24.375... logprob:  0.393772, 0.101562 (1.462 sec)
24.376... logprob:  0.374295, 0.093750 (1.438 sec)
24.377... logprob:  0.295410, 0.062500 (1.424 sec)
24.378... logprob:  0.453704, 0.125000 (1.433 sec)
24.379... logprob:  0.420241, 0.109375 (1.443 sec)
24.380... logprob:  0.605708, 0.179688 (1.439 sec)
24.381... logprob:  0.463438, 0.125000 (1.471 sec)
24.382... logprob:  0.529553, 0.148438 (1.455 sec)
24.383... logprob:  0.358588, 0.085938 (1.437 sec)
24.384... logprob:  0.521152, 0.148438 (1.488 sec)
24.385... logprob:  0.523541, 0.148438 (1.430 sec)
24.386... logprob:  0.582490, 0.171875 (1.432 sec)
24.387... logprob:  0.428573, 0.117188 (1.433 sec)
24.388... logprob:  0.521352, 0.148438 (1.436 sec)
24.389... logprob:  0.425695, 0.109375 (1.437 sec)
24.390... logprob:  0.419767, 0.109375 (1.481 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.832862854003906, 10.0]}, 128)
batch 872: ({'logprob': [65.84465026855469, 19.0]}, 128)
batch 873: ({'logprob': [42.890602111816406, 9.0]}, 128)
batch 874: ({'logprob': [46.95654296875, 11.0]}, 128)
batch 875: ({'logprob': [51.883544921875, 13.0]}, 128)
batch 876: ({'logprob': [63.617408752441406, 18.0]}, 128)
batch 877: ({'logprob': [47.397666931152344, 11.0]}, 128)
batch 878: ({'logprob': [61.78102493286133, 17.0]}, 128)
batch 879: ({'logprob': [72.06951904296875, 21.0]}, 128)
batch 880: ({'logprob': [51.905250549316406, 13.0]}, 128)
batch 881: ({'logprob': [32.56888961791992, 5.0]}, 128)
batch 882: ({'logprob': [55.44626998901367, 14.0]}, 128)
batch 883: ({'logprob': [61.75798034667969, 17.0]}, 128)
batch 884: ({'logprob': [52.31599044799805, 13.0]}, 128)
batch 885: ({'logprob': [53.17770004272461, 13.0]}, 128)
batch 886: ({'logprob': [62.204017639160156, 17.0]}, 128)

======================Test output======================
logprob:  0.422681, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.963672e-03 [2.852397e-09] 
Layer 'conv1' biases: 2.786279e-07 [1.330160e-10] 
Layer 'conv2' weights[0]: 7.950765e-03 [2.995047e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.610661e-10] 
Layer 'conv3' weights[0]: 7.948971e-03 [3.143053e-09] 
Layer 'conv3' biases: 2.378844e-06 [1.956560e-09] 
Layer 'conv4' weights[0]: 7.981648e-03 [3.277120e-09] 
Layer 'conv4' biases: 9.999992e-01 [1.823451e-08] 
Layer 'conv5' weights[0]: 7.980476e-03 [1.200428e-07] 
Layer 'conv5' biases: 9.999940e-01 [1.294473e-07] 
Layer 'fc6' weights[0]: 7.577124e-03 [9.905885e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.004726e-08] 
Layer 'fc7' weights[0]: 7.082864e-03 [4.440989e-08] 
Layer 'fc7' biases: 9.998580e-01 [2.191425e-08] 
Layer 'fc8' weights[0]: 1.249567e-03 [2.455468e-06] 
Layer 'fc8' biases: 5.811245e-02 [1.825718e-05] 
Train error last 870 batches: 0.435216
-------------------------------------------------------
Not saving because 0.422681 > 0.415666 (22.630: -0.00%)
======================================================= (12.070 sec)
24.391... logprob:  0.318238, 0.070312 (1.452 sec)
24.392... logprob:  0.439444, 0.117188 (1.443 sec)
24.393... logprob:  0.368962, 0.093750 (1.486 sec)
24.394... logprob:  0.343624, 0.078125 (1.432 sec)
24.395... logprob:  0.331773, 0.078125 (1.425 sec)
24.396... logprob:  0.252314, 0.046875 (1.441 sec)
24.397... logprob:  0.484329, 0.132812 (1.432 sec)
24.398... logprob:  0.470954, 0.125000 (1.437 sec)
24.399... logprob:  0.433369, 0.117188 (1.481 sec)
24.400... logprob:  0.537866, 0.148438 (1.434 sec)
24.401... logprob:  0.465841, 0.125000 (1.442 sec)
24.402... logprob:  0.473993, 0.125000 (1.483 sec)
24.403... logprob:  0.462153, 0.125000 (1.431 sec)
24.404... logprob:  0.474819, 0.125000 (1.439 sec)
24.405... logprob:  0.544115, 0.156250 (1.436 sec)
24.406... logprob:  0.357676, 0.085938 (1.432 sec)
24.407... logprob:  0.492900, 0.140625 (1.434 sec)
24.408... logprob:  0.339183, 0.078125 (1.479 sec)
24.409... logprob:  0.400625, 0.101562 (1.441 sec)
24.410... logprob:  0.582087, 0.171875 (1.478 sec)
24.411... logprob:  0.397942, 0.101562 (1.476 sec)
24.412... logprob:  0.540275, 0.156250 (1.436 sec)
24.413... logprob:  0.544675, 0.156250 (1.441 sec)
24.414... logprob:  0.466473, 0.125000 (1.432 sec)
24.415... logprob:  0.401712, 0.101562 (1.427 sec)
24.416... logprob:  0.427526, 0.109375 (1.437 sec)
24.417... logprob:  0.405455, 0.093750 (1.467 sec)
24.418... logprob:  0.380321, 0.093750 (1.455 sec)
24.419... logprob:  0.417758, 0.101562 (1.451 sec)
24.420... logprob:  0.356249, 0.085938 (1.461 sec)
24.421... logprob:  0.376602, 0.101562 (1.457 sec)
24.422... logprob:  0.522474, 0.148438 (1.441 sec)
24.423... logprob:  0.420890, 0.109375 (1.424 sec)
24.424... logprob:  0.324785, 0.078125 (1.436 sec)
24.425... logprob:  0.306350, 0.070312 (1.436 sec)
24.426... logprob:  0.449188, 0.117188 (1.449 sec)
24.427... logprob:  0.554451, 0.156250 (1.464 sec)
24.428... logprob:  0.601883, 0.171875 (1.457 sec)
24.429... logprob:  0.426324, 0.109375 (1.445 sec)
24.430... logprob:  0.299845, 0.070312 (1.476 sec)
24.431... logprob:  0.599754, 0.171875 (1.441 sec)
24.432... logprob:  0.387549, 0.093750 (1.429 sec)
24.433... logprob:  0.329869, 0.078125 (1.438 sec)
24.434... logprob:  0.529416, 0.148438 (1.436 sec)
24.435... logprob:  0.532326, 0.156250 (1.435 sec)
24.436... logprob:  0.381201, 0.093750 (1.481 sec)
24.437... logprob:  0.500282, 0.140625 (1.446 sec)
24.438... logprob:  0.546898, 0.156250 (1.434 sec)
24.439... logprob:  0.378854, 0.093750 (1.487 sec)
24.440... logprob:  0.439756, 0.117188 (1.432 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.56884002685547, 10.0]}, 128)
batch 872: ({'logprob': [65.83028411865234, 19.0]}, 128)
batch 873: ({'logprob': [42.65404510498047, 9.0]}, 128)
batch 874: ({'logprob': [46.745296478271484, 11.0]}, 128)
batch 875: ({'logprob': [51.72949981689453, 13.0]}, 128)
batch 876: ({'logprob': [63.582313537597656, 18.0]}, 128)
batch 877: ({'logprob': [47.20207595825195, 11.0]}, 128)
batch 878: ({'logprob': [61.741233825683594, 17.0]}, 128)
batch 879: ({'logprob': [72.1602554321289, 21.0]}, 128)
batch 880: ({'logprob': [51.7509765625, 13.0]}, 128)
batch 881: ({'logprob': [32.201698303222656, 5.0]}, 128)
batch 882: ({'logprob': [55.36100387573242, 14.0]}, 128)
batch 883: ({'logprob': [61.71847152709961, 17.0]}, 128)
batch 884: ({'logprob': [52.17833709716797, 13.0]}, 128)
batch 885: ({'logprob': [53.07213592529297, 13.0]}, 128)
batch 886: ({'logprob': [62.180519104003906, 17.0]}, 128)

======================Test output======================
logprob:  0.421717, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.963629e-03 [4.041799e-09] 
Layer 'conv1' biases: 2.794573e-07 [1.001526e-10] 
Layer 'conv2' weights[0]: 7.950724e-03 [3.025012e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.533150e-10] 
Layer 'conv3' weights[0]: 7.948927e-03 [2.869860e-09] 
Layer 'conv3' biases: 2.385422e-06 [1.722276e-09] 
Layer 'conv4' weights[0]: 7.981609e-03 [2.986024e-09] 
Layer 'conv4' biases: 9.999993e-01 [1.600547e-08] 
Layer 'conv5' weights[0]: 7.980443e-03 [1.053572e-07] 
Layer 'conv5' biases: 9.999940e-01 [1.135545e-07] 
Layer 'fc6' weights[0]: 7.577079e-03 [8.722870e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.817943e-09] 
Layer 'fc7' weights[0]: 7.081076e-03 [3.730424e-08] 
Layer 'fc7' biases: 9.998583e-01 [9.442227e-09] 
Layer 'fc8' weights[0]: 1.248032e-03 [1.951126e-07] 
Layer 'fc8' biases: 5.851719e-02 [7.202851e-06] 
Train error last 870 batches: 0.435215
-------------------------------------------------------
Not saving because 0.421717 > 0.415666 (22.630: -0.00%)
======================================================= (12.119 sec)
24.441... logprob:  0.467993, 0.125000 (1.437 sec)
24.442... logprob:  0.378937, 0.093750 (1.438 sec)
24.443... logprob:  0.496570, 0.140625 (1.455 sec)
24.444... logprob:  0.372288, 0.093750 (1.437 sec)
24.445... logprob:  0.362439, 0.085938 (1.483 sec)
24.446... logprob:  0.398268, 0.101562 (1.440 sec)
24.447... logprob:  0.569868, 0.164062 (1.440 sec)
24.448... logprob:  0.332790, 0.078125 (1.486 sec)
24.449... logprob:  0.400030, 0.101562 (1.430 sec)
24.450... logprob:  0.239340, 0.046875 (1.435 sec)
24.451... logprob:  0.452742, 0.125000 (1.442 sec)
24.452... logprob:  0.456165, 0.117188 (1.429 sec)
24.453... logprob:  0.455290, 0.125000 (1.436 sec)
24.454... logprob:  0.489053, 0.132812 (1.484 sec)
24.455... logprob:  0.506085, 0.140625 (1.448 sec)
24.456... logprob:  0.468833, 0.125000 (1.451 sec)
24.457... logprob:  0.375348, 0.093750 (1.473 sec)
24.458... logprob:  0.351071, 0.085938 (1.438 sec)
24.459... logprob:  0.513892, 0.140625 (1.438 sec)
24.460... logprob:  0.274070, 0.054688 (1.438 sec)
24.461... logprob:  0.460064, 0.125000 (1.424 sec)
24.462... logprob:  0.471949, 0.125000 (1.439 sec)
24.463... logprob:  0.420866, 0.109375 (1.470 sec)
24.464... logprob:  0.482742, 0.132812 (1.453 sec)
24.465... logprob:  0.421154, 0.109375 (1.451 sec)
24.466... logprob:  0.318446, 0.070312 (1.462 sec)
24.467... logprob:  0.413848, 0.109375 (1.453 sec)
24.468... logprob:  0.394269, 0.101562 (1.439 sec)
24.469... logprob:  0.334740, 0.078125 (1.428 sec)
24.470... logprob:  0.400081, 0.101562 (1.431 sec)
24.471... logprob:  0.529389, 0.148438 (1.440 sec)
24.472... logprob:  0.410021, 0.109375 (1.453 sec)
24.473... logprob:  0.375416, 0.093750 (1.461 sec)
24.474... logprob:  0.465640, 0.125000 (1.456 sec)
24.475... logprob:  0.504129, 0.140625 (1.457 sec)
24.476... logprob:  0.510304, 0.140625 (1.469 sec)
24.477... logprob:  0.334578, 0.078125 (1.450 sec)
24.478... logprob:  0.464259, 0.125000 (1.426 sec)
24.479... logprob:  0.305774, 0.070312 (1.431 sec)
24.480... logprob:  0.443510, 0.117188 (1.444 sec)
24.481... logprob:  0.547791, 0.156250 (1.442 sec)
24.482... logprob:  0.443155, 0.117188 (1.480 sec)
24.483... logprob:  0.502648, 0.140625 (1.445 sec)
24.484... logprob:  0.485306, 0.132812 (1.457 sec)
24.485... logprob:  0.408994, 0.109375 (1.484 sec)
24.486... logprob:  0.361422, 0.085938 (1.437 sec)
24.487... logprob:  0.522660, 0.148438 (1.427 sec)
24.488... logprob:  0.424786, 0.109375 (1.432 sec)
24.489... logprob:  0.415878, 0.109375 (1.438 sec)
24.490... logprob:  0.440695, 0.117188 (1.431 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.590843200683594, 10.0]}, 128)
batch 872: ({'logprob': [66.16887664794922, 19.0]}, 128)
batch 873: ({'logprob': [41.32804870605469, 9.0]}, 128)
batch 874: ({'logprob': [45.823116302490234, 11.0]}, 128)
batch 875: ({'logprob': [51.09156036376953, 13.0]}, 128)
batch 876: ({'logprob': [63.749698638916016, 18.0]}, 128)
batch 877: ({'logprob': [46.21969223022461, 11.0]}, 128)
batch 878: ({'logprob': [61.676204681396484, 17.0]}, 128)
batch 879: ({'logprob': [72.6090087890625, 21.0]}, 128)
batch 880: ({'logprob': [51.114009857177734, 13.0]}, 128)
batch 881: ({'logprob': [30.360904693603516, 5.0]}, 128)
batch 882: ({'logprob': [54.72148895263672, 14.0]}, 128)
batch 883: ({'logprob': [61.6528434753418, 17.0]}, 128)
batch 884: ({'logprob': [51.48475646972656, 13.0]}, 128)
batch 885: ({'logprob': [52.26118850708008, 13.0]}, 128)
batch 886: ({'logprob': [62.05823516845703, 17.0]}, 128)

======================Test output======================
logprob:  0.417437, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.963594e-03 [2.475867e-09] 
Layer 'conv1' biases: 2.802795e-07 [6.297046e-11] 
Layer 'conv2' weights[0]: 7.950685e-03 [2.011009e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.204664e-10] 
Layer 'conv3' weights[0]: 7.948887e-03 [1.864553e-09] 
Layer 'conv3' biases: 2.391828e-06 [9.650070e-10] 
Layer 'conv4' weights[0]: 7.981574e-03 [2.004277e-09] 
Layer 'conv4' biases: 9.999993e-01 [8.959020e-09] 
Layer 'conv5' weights[0]: 7.980396e-03 [5.895694e-08] 
Layer 'conv5' biases: 9.999939e-01 [6.347437e-08] 
Layer 'fc6' weights[0]: 7.577046e-03 [4.944748e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.949597e-09] 
Layer 'fc7' weights[0]: 7.079273e-03 [8.684604e-08] 
Layer 'fc7' biases: 9.998589e-01 [7.179517e-08] 
Layer 'fc8' weights[0]: 1.271469e-03 [2.578446e-06] 
Layer 'fc8' biases: 5.889117e-02 [1.895721e-05] 
Train error last 870 batches: 0.435215
-------------------------------------------------------
Not saving because 0.417437 > 0.415666 (22.630: -0.00%)
======================================================= (12.066 sec)
24.491... logprob:  0.313656, 0.070312 (1.496 sec)
24.492... logprob:  0.459559, 0.125000 (1.449 sec)
24.493... logprob:  0.521862, 0.148438 (1.433 sec)
24.494... logprob:  0.450358, 0.125000 (1.491 sec)
24.495... logprob:  0.380630, 0.093750 (1.434 sec)
24.496... logprob:  0.550339, 0.156250 (1.434 sec)
24.497... logprob:  0.466956, 0.125000 (1.436 sec)
24.498... logprob:  0.476265, 0.132812 (1.430 sec)
24.499... logprob:  0.456246, 0.125000 (1.439 sec)
24.500... logprob:  0.355123, 0.085938 (1.487 sec)
24.501... logprob:  0.339117, 0.078125 (1.434 sec)
24.502... logprob:  0.459628, 0.125000 (1.448 sec)
24.503... logprob:  0.400672, 0.101562 (1.479 sec)
24.504... logprob:  0.487307, 0.132812 (1.432 sec)
24.505... logprob:  0.570791, 0.164062 (1.441 sec)
24.506... logprob:  0.479684, 0.132812 (1.433 sec)
24.507... logprob:  0.385073, 0.093750 (1.432 sec)
24.508... logprob:  0.374697, 0.093750 (1.435 sec)
24.509... logprob:  0.323086, 0.070312 (1.478 sec)
24.510... logprob:  0.390467, 0.101562 (1.439 sec)
24.511... logprob:  0.410060, 0.109375 (1.458 sec)
24.512... logprob:  0.470727, 0.125000 (1.466 sec)
24.513... logprob:  0.324967, 0.078125 (1.446 sec)
24.514... logprob:  0.406274, 0.101562 (1.436 sec)
24.515... logprob:  0.455518, 0.125000 (1.436 sec)
24.516... logprob:  0.400324, 0.109375 (1.427 sec)
24.517... logprob:  0.627862, 0.179688 (1.464 sec)
24.518... logprob:  0.437672, 0.117188 (1.459 sec)
24.519... logprob:  0.516136, 0.140625 (1.456 sec)
24.520... logprob:  0.409648, 0.109375 (1.459 sec)
24.521... logprob:  0.427466, 0.109375 (1.449 sec)
24.522... logprob:  0.533124, 0.156250 (1.468 sec)
24.523... logprob:  0.331611, 0.078125 (1.439 sec)
24.524... logprob:  0.437182, 0.117188 (1.429 sec)
24.525... logprob:  0.425977, 0.109375 (1.430 sec)
24.526... logprob:  0.351784, 0.078125 (1.442 sec)
24.527... logprob:  0.504563, 0.140625 (1.439 sec)
24.528... logprob:  0.440479, 0.117188 (1.466 sec)
24.529... logprob:  0.353005, 0.085938 (1.450 sec)
24.530... logprob:  0.440251, 0.117188 (1.440 sec)
24.531... logprob:  0.439975, 0.117188 (1.483 sec)
24.532... logprob:  0.467349, 0.125000 (1.434 sec)
24.533... logprob:  0.560481, 0.164062 (1.430 sec)
24.534... logprob:  0.325874, 0.078125 (1.437 sec)
24.535... logprob:  0.551536, 0.156250 (1.435 sec)
24.536... logprob:  0.507324, 0.140625 (1.438 sec)
24.537... logprob:  0.510034, 0.140625 (1.480 sec)
24.538... logprob:  0.486095, 0.132812 (1.447 sec)
24.539... logprob:  0.296074, 0.062500 (1.437 sec)
24.540... logprob:  0.447177, 0.117188 (1.485 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.43238067626953, 10.0]}, 128)
batch 872: ({'logprob': [66.1634521484375, 19.0]}, 128)
batch 873: ({'logprob': [41.26084518432617, 9.0]}, 128)
batch 874: ({'logprob': [45.73061752319336, 11.0]}, 128)
batch 875: ({'logprob': [51.03646469116211, 13.0]}, 128)
batch 876: ({'logprob': [63.74146270751953, 18.0]}, 128)
batch 877: ({'logprob': [46.15852737426758, 11.0]}, 128)
batch 878: ({'logprob': [61.696250915527344, 17.0]}, 128)
batch 879: ({'logprob': [72.73528289794922, 21.0]}, 128)
batch 880: ({'logprob': [51.05900955200195, 13.0]}, 128)
batch 881: ({'logprob': [30.18723487854004, 5.0]}, 128)
batch 882: ({'logprob': [54.7639045715332, 14.0]}, 128)
batch 883: ({'logprob': [61.672706604003906, 17.0]}, 128)
batch 884: ({'logprob': [51.461341857910156, 13.0]}, 128)
batch 885: ({'logprob': [52.300697326660156, 13.0]}, 128)
batch 886: ({'logprob': [62.10985565185547, 17.0]}, 128)

======================Test output======================
logprob:  0.417241, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.963554e-03 [3.053304e-09] 
Layer 'conv1' biases: 2.812664e-07 [8.242795e-11] 
Layer 'conv2' weights[0]: 7.950641e-03 [1.944297e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.945931e-10] 
Layer 'conv3' weights[0]: 7.948846e-03 [1.967050e-09] 
Layer 'conv3' biases: 2.402249e-06 [1.142226e-09] 
Layer 'conv4' weights[0]: 7.981547e-03 [2.038349e-09] 
Layer 'conv4' biases: 9.999993e-01 [9.351202e-09] 
Layer 'conv5' weights[0]: 7.980357e-03 [5.587660e-08] 
Layer 'conv5' biases: 9.999939e-01 [6.025385e-08] 
Layer 'fc6' weights[0]: 7.577005e-03 [4.741663e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.730135e-09] 
Layer 'fc7' weights[0]: 7.077458e-03 [4.918759e-08] 
Layer 'fc7' biases: 9.998590e-01 [2.880662e-08] 
Layer 'fc8' weights[0]: 1.274118e-03 [4.115443e-06] 
Layer 'fc8' biases: 5.898881e-02 [2.778997e-05] 
Train error last 870 batches: 0.435215
-------------------------------------------------------
Not saving because 0.417241 > 0.415666 (22.630: -0.00%)
======================================================= (12.083 sec)
24.541... logprob:  0.388831, 0.101562 (1.436 sec)
24.542... logprob:  0.411268, 0.109375 (1.439 sec)
24.543... logprob:  0.233284, 0.039062 (1.437 sec)
24.544... logprob:  0.317931, 0.070312 (1.436 sec)
24.545... logprob:  0.348803, 0.085938 (1.431 sec)
24.546... logprob:  0.368277, 0.093750 (1.492 sec)
24.547... logprob:  0.440067, 0.117188 (1.433 sec)
24.548... logprob:  0.453008, 0.125000 (1.446 sec)
24.549... logprob:  0.490549, 0.132812 (1.479 sec)
24.550... logprob:  0.367643, 0.093750 (1.463 sec)
24.551... logprob:  0.441699, 0.117188 (1.435 sec)
24.552... logprob:  0.471288, 0.125000 (1.436 sec)
24.553... logprob:  0.349444, 0.085938 (1.419 sec)
24.554... logprob:  0.506925, 0.140625 (1.440 sec)
24.555... logprob:  0.421409, 0.109375 (1.482 sec)
24.556... logprob:  0.355846, 0.085938 (1.436 sec)
24.557... logprob:  0.396412, 0.101562 (1.455 sec)
24.558... logprob:  0.383027, 0.101562 (1.473 sec)
24.559... logprob:  0.441542, 0.125000 (1.438 sec)
24.560... logprob:  0.335168, 0.078125 (1.440 sec)
24.561... logprob:  0.411812, 0.109375 (1.433 sec)
24.562... logprob:  0.503137, 0.140625 (1.427 sec)
24.563... logprob:  0.373805, 0.093750 (1.439 sec)
24.564... logprob:  0.468457, 0.132812 (1.462 sec)
24.565... logprob:  0.611097, 0.187500 (1.448 sec)
24.566... logprob:  0.374891, 0.093750 (1.459 sec)
24.567... logprob:  0.423366, 0.109375 (1.455 sec)
24.568... logprob:  0.496348, 0.140625 (1.459 sec)
24.569... logprob:  0.507761, 0.140625 (1.437 sec)
24.570... logprob:  0.543758, 0.164062 (1.430 sec)
24.571... logprob:  0.454880, 0.125000 (1.432 sec)
24.572... logprob:  0.501417, 0.140625 (1.442 sec)
24.573... logprob:  0.512609, 0.148438 (1.445 sec)
24.574... logprob:  0.428083, 0.109375 (1.580 sec)
24.575... logprob:  0.343339, 0.078125 (1.454 sec)
24.576... logprob:  0.427378, 0.109375 (1.447 sec)
24.577... logprob:  0.460811, 0.125000 (1.475 sec)
24.578... logprob:  0.336686, 0.078125 (1.429 sec)
24.579... logprob:  0.442082, 0.117188 (1.438 sec)
24.580... logprob:  0.546781, 0.156250 (1.434 sec)
24.581... logprob:  0.530803, 0.156250 (1.443 sec)
24.582... logprob:  0.437843, 0.125000 (1.432 sec)
24.583... logprob:  0.592626, 0.171875 (1.479 sec)
24.584... logprob:  0.468096, 0.132812 (1.450 sec)
24.585... logprob:  0.349763, 0.085938 (1.433 sec)
24.586... logprob:  0.313103, 0.070312 (1.490 sec)
24.587... logprob:  0.404304, 0.101562 (1.434 sec)
24.588... logprob:  0.418663, 0.117188 (1.431 sec)
24.589... logprob:  0.361219, 0.093750 (1.437 sec)
24.590... logprob:  0.524740, 0.148438 (1.435 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.18891143798828, 10.0]}, 128)
batch 872: ({'logprob': [66.45420837402344, 19.0]}, 128)
batch 873: ({'logprob': [41.01918411254883, 9.0]}, 128)
batch 874: ({'logprob': [45.187225341796875, 11.0]}, 128)
batch 875: ({'logprob': [50.87165069580078, 13.0]}, 128)
batch 876: ({'logprob': [64.01311492919922, 18.0]}, 128)
batch 877: ({'logprob': [45.9539909362793, 11.0]}, 128)
batch 878: ({'logprob': [62.288230895996094, 17.0]}, 128)
batch 879: ({'logprob': [74.42243194580078, 21.0]}, 128)
batch 880: ({'logprob': [50.89341735839844, 13.0]}, 128)
batch 881: ({'logprob': [28.847705841064453, 5.0]}, 128)
batch 882: ({'logprob': [55.638919830322266, 14.0]}, 128)
batch 883: ({'logprob': [62.26498794555664, 17.0]}, 128)
batch 884: ({'logprob': [51.63808822631836, 13.0]}, 128)
batch 885: ({'logprob': [53.15752029418945, 13.0]}, 128)
batch 886: ({'logprob': [63.042850494384766, 17.0]}, 128)

======================Test output======================
logprob:  0.418400, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.963519e-03 [3.071496e-09] 
Layer 'conv1' biases: 2.822682e-07 [6.920190e-11] 
Layer 'conv2' weights[0]: 7.950601e-03 [2.379113e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.361187e-10] 
Layer 'conv3' weights[0]: 7.948807e-03 [1.895056e-09] 
Layer 'conv3' biases: 2.408725e-06 [9.598308e-10] 
Layer 'conv4' weights[0]: 7.981506e-03 [1.858784e-09] 
Layer 'conv4' biases: 9.999993e-01 [6.829338e-09] 
Layer 'conv5' weights[0]: 7.980284e-03 [4.328058e-08] 
Layer 'conv5' biases: 9.999936e-01 [4.663043e-08] 
Layer 'fc6' weights[0]: 7.576963e-03 [3.710108e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.694528e-09] 
Layer 'fc7' weights[0]: 7.075589e-03 [6.527399e-08] 
Layer 'fc7' biases: 9.998600e-01 [4.810802e-08] 
Layer 'fc8' weights[0]: 1.302033e-03 [2.445481e-06] 
Layer 'fc8' biases: 5.929918e-02 [1.631265e-05] 
Train error last 870 batches: 0.435214
-------------------------------------------------------
Not saving because 0.418400 > 0.415666 (22.630: -0.00%)
======================================================= (12.060 sec)
24.591... logprob:  0.397484, 0.101562 (1.434 sec)
24.592... logprob:  0.455662, 0.125000 (1.485 sec)
24.593... logprob:  0.467424, 0.125000 (1.437 sec)
24.594... logprob:  0.352850, 0.085938 (1.441 sec)
24.595... logprob:  0.428663, 0.109375 (1.482 sec)
24.596... logprob:  0.461599, 0.125000 (1.439 sec)
24.597... logprob:  0.397414, 0.101562 (1.432 sec)
24.598... logprob:  0.397223, 0.101562 (1.441 sec)
24.599... logprob:  0.313549, 0.070312 (1.427 sec)
24.600... logprob:  0.340889, 0.085938 (1.437 sec)
24.601... logprob:  0.402139, 0.101562 (1.487 sec)
24.602... logprob:  0.289796, 0.062500 (1.432 sec)
24.603... logprob:  0.267078, 0.054688 (1.450 sec)
24.604... logprob:  0.407518, 0.101562 (1.480 sec)
24.605... logprob:  0.563420, 0.148438 (1.433 sec)
24.606... logprob:  0.295943, 0.070312 (1.441 sec)
24.607... logprob:  0.504793, 0.132812 (1.433 sec)
24.608... logprob:  0.361781, 0.085938 (1.430 sec)
24.609... logprob:  0.356987, 0.085938 (1.439 sec)
24.610... logprob:  0.493356, 0.132812 (1.467 sec)
24.611... logprob:  0.510387, 0.140625 (1.444 sec)
24.612... logprob:  0.448466, 0.117188 (1.452 sec)
24.613... logprob:  0.279549, 0.062500 (1.467 sec)
24.614... logprob:  0.503549, 0.140625 (1.449 sec)
24.615... logprob:  0.350974, 0.085938 (1.441 sec)
24.616... logprob:  0.415187, 0.109375 (1.428 sec)
24.617... logprob:  0.417894, 0.109375 (1.438 sec)
24.618... logprob:  0.546874, 0.156250 (1.443 sec)
24.619... logprob:  0.506034, 0.140625 (1.452 sec)
24.620... logprob:  0.539664, 0.156250 (1.465 sec)
24.621... logprob:  0.363735, 0.085938 (1.451 sec)
24.622... logprob:  0.364798, 0.085938 (1.449 sec)
24.623... logprob:  0.423169, 0.109375 (1.471 sec)
24.624... logprob:  0.382532, 0.093750 (1.466 sec)
24.625... logprob:  0.440991, 0.117188 (1.424 sec)
24.626... logprob:  0.438369, 0.117188 (1.436 sec)
24.627... logprob:  0.435841, 0.117188 (1.437 sec)
24.628... logprob:  0.465051, 0.125000 (1.448 sec)
24.629... logprob:  0.372077, 0.093750 (1.473 sec)
24.630... logprob:  0.422377, 0.109375 (1.454 sec)
24.631... logprob:  0.638832, 0.187500 (1.439 sec)
24.632... logprob:  0.399109, 0.101562 (1.479 sec)
24.633... logprob:  0.376071, 0.093750 (1.441 sec)
24.634... logprob:  0.660256, 0.195312 (1.428 sec)
24.635... logprob:  0.374118, 0.093750 (1.438 sec)
24.636... logprob:  0.480250, 0.132812 (1.436 sec)
24.637... logprob:  0.330829, 0.078125 (1.435 sec)
24.638... logprob:  0.515691, 0.140625 (1.484 sec)
24.639... logprob:  0.418083, 0.109375 (1.440 sec)
24.640... logprob:  0.528752, 0.148438 (1.438 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.698486328125, 10.0]}, 128)
batch 872: ({'logprob': [66.24114990234375, 19.0]}, 128)
batch 873: ({'logprob': [41.285987854003906, 9.0]}, 128)
batch 874: ({'logprob': [45.85746383666992, 11.0]}, 128)
batch 875: ({'logprob': [51.11279296875, 13.0]}, 128)
batch 876: ({'logprob': [63.8065299987793, 18.0]}, 128)
batch 877: ({'logprob': [46.20957946777344, 11.0]}, 128)
batch 878: ({'logprob': [61.67226791381836, 17.0]}, 128)
batch 879: ({'logprob': [72.53498840332031, 21.0]}, 128)
batch 880: ({'logprob': [51.1356315612793, 13.0]}, 128)
batch 881: ({'logprob': [30.388843536376953, 5.0]}, 128)
batch 882: ({'logprob': [54.625160217285156, 14.0]}, 128)
batch 883: ({'logprob': [61.648502349853516, 17.0]}, 128)
batch 884: ({'logprob': [51.46166229248047, 13.0]}, 128)
batch 885: ({'logprob': [52.14873504638672, 13.0]}, 128)
batch 886: ({'logprob': [62.009605407714844, 17.0]}, 128)

======================Test output======================
logprob:  0.417401, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.963484e-03 [3.937429e-09] 
Layer 'conv1' biases: 2.832473e-07 [7.132868e-11] 
Layer 'conv2' weights[0]: 7.950564e-03 [2.517816e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.201411e-10] 
Layer 'conv3' weights[0]: 7.948769e-03 [1.818191e-09] 
Layer 'conv3' biases: 2.417856e-06 [1.015065e-09] 
Layer 'conv4' weights[0]: 7.981459e-03 [1.871916e-09] 
Layer 'conv4' biases: 9.999993e-01 [7.142693e-09] 
Layer 'conv5' weights[0]: 7.980282e-03 [4.714192e-08] 
Layer 'conv5' biases: 9.999939e-01 [5.071587e-08] 
Layer 'fc6' weights[0]: 7.576921e-03 [3.964424e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.954812e-09] 
Layer 'fc7' weights[0]: 7.073781e-03 [1.291138e-07] 
Layer 'fc7' biases: 9.998587e-01 [1.172542e-07] 
Layer 'fc8' weights[0]: 1.275041e-03 [4.156126e-06] 
Layer 'fc8' biases: 5.928657e-02 [2.604407e-05] 
Train error last 870 batches: 0.435214
-------------------------------------------------------
Not saving because 0.417401 > 0.415666 (22.630: -0.00%)
======================================================= (12.062 sec)
24.641... logprob:  0.410443, 0.109375 (1.490 sec)
24.642... logprob:  0.500863, 0.140625 (1.439 sec)
24.643... logprob:  0.623077, 0.187500 (1.433 sec)
24.644... logprob:  0.321156, 0.070312 (1.443 sec)
24.645... logprob:  0.414478, 0.109375 (1.429 sec)
24.646... logprob:  0.385658, 0.093750 (1.439 sec)
24.647... logprob:  0.456774, 0.125000 (1.487 sec)
24.648... logprob:  0.491249, 0.140625 (1.435 sec)
24.649... logprob:  0.370224, 0.093750 (1.445 sec)
24.650... logprob:  0.413988, 0.109375 (1.483 sec)
24.651... logprob:  0.397362, 0.101562 (1.438 sec)
24.652... logprob:  0.507219, 0.140625 (1.441 sec)
24.653... logprob:  0.547899, 0.156250 (1.433 sec)
24.654... logprob:  0.496064, 0.140625 (1.433 sec)
24.655... logprob:  0.436190, 0.117188 (1.431 sec)
24.656... logprob:  0.416696, 0.109375 (1.482 sec)
24.657... logprob:  0.449148, 0.117188 (1.477 sec)
24.658... logprob:  0.345826, 0.085938 (1.451 sec)
24.659... logprob:  0.464314, 0.125000 (1.469 sec)
24.660... logprob:  0.445979, 0.125000 (1.445 sec)
24.661... logprob:  0.378467, 0.093750 (1.440 sec)
24.662... logprob:  0.469406, 0.132812 (1.428 sec)
24.663... logprob:  0.310938, 0.070312 (1.422 sec)
24.664... logprob:  0.285416, 0.062500 (1.441 sec)
24.665... logprob:  0.401755, 0.101562 (1.460 sec)
24.666... logprob:  0.442043, 0.117188 (1.458 sec)
24.667... logprob:  0.564249, 0.164062 (1.452 sec)
24.668... logprob:  0.497871, 0.140625 (1.457 sec)
24.669... logprob:  0.432996, 0.109375 (1.461 sec)
24.670... logprob:  0.362415, 0.085938 (1.443 sec)
24.671... logprob:  0.360863, 0.093750 (1.425 sec)
24.672... logprob:  0.441821, 0.117188 (1.435 sec)
24.673... logprob:  0.436232, 0.117188 (1.438 sec)
24.674... logprob:  0.446646, 0.117188 (1.444 sec)
24.675... logprob:  0.356675, 0.093750 (1.466 sec)
24.676... logprob:  0.450169, 0.125000 (1.457 sec)
24.677... logprob:  0.471034, 0.125000 (1.437 sec)
24.678... logprob:  0.465654, 0.125000 (1.485 sec)
24.679... logprob:  0.454866, 0.125000 (1.433 sec)
24.680... logprob:  0.351692, 0.078125 (1.430 sec)
24.681... logprob:  0.373895, 0.093750 (1.432 sec)
24.682... logprob:  0.340479, 0.078125 (1.445 sec)
24.683... logprob:  0.411637, 0.109375 (1.429 sec)
24.684... logprob:  0.357656, 0.085938 (1.483 sec)
24.685... logprob:  0.286054, 0.054688 (1.441 sec)
24.686... logprob:  0.318683, 0.070312 (1.435 sec)
24.687... logprob:  0.281672, 0.062500 (1.489 sec)
24.688... logprob:  0.323116, 0.078125 (1.439 sec)
24.689... logprob:  0.471205, 0.125000 (1.429 sec)
24.690... logprob:  0.527699, 0.140625 (1.440 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.87999725341797, 10.0]}, 128)
batch 872: ({'logprob': [69.57119750976562, 19.0]}, 128)
batch 873: ({'logprob': [39.32551193237305, 9.0]}, 128)
batch 874: ({'logprob': [44.806846618652344, 11.0]}, 128)
batch 875: ({'logprob': [51.2155647277832, 13.0]}, 128)
batch 876: ({'logprob': [66.62297058105469, 18.0]}, 128)
batch 877: ({'logprob': [45.278751373291016, 11.0]}, 128)
batch 878: ({'logprob': [64.09217071533203, 17.0]}, 128)
batch 879: ({'logprob': [77.39385223388672, 21.0]}, 128)
batch 880: ({'logprob': [51.240177154541016, 13.0]}, 128)
batch 881: ({'logprob': [25.984285354614258, 5.0]}, 128)
batch 882: ({'logprob': [55.62298583984375, 14.0]}, 128)
batch 883: ({'logprob': [64.06735229492188, 17.0]}, 128)
batch 884: ({'logprob': [51.69706726074219, 13.0]}, 128)
batch 885: ({'logprob': [52.63246536254883, 13.0]}, 128)
batch 886: ({'logprob': [64.55792999267578, 17.0]}, 128)

======================Test output======================
logprob:  0.422358, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.963449e-03 [5.205825e-09] 
Layer 'conv1' biases: 2.839005e-07 [2.009274e-10] 
Layer 'conv2' weights[0]: 7.950526e-03 [4.387796e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.027025e-09] 
Layer 'conv3' weights[0]: 7.948726e-03 [4.671167e-09] 
Layer 'conv3' biases: 2.421225e-06 [3.108997e-09] 
Layer 'conv4' weights[0]: 7.981422e-03 [4.754188e-09] 
Layer 'conv4' biases: 9.999993e-01 [2.759974e-08] 
Layer 'conv5' weights[0]: 7.980204e-03 [1.794310e-07] 
Layer 'conv5' biases: 9.999934e-01 [1.931050e-07] 
Layer 'fc6' weights[0]: 7.576871e-03 [1.504384e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.536231e-08] 
Layer 'fc7' weights[0]: 7.071977e-03 [5.126820e-08] 
Layer 'fc7' biases: 9.998617e-01 [3.100599e-08] 
Layer 'fc8' weights[0]: 1.376052e-03 [7.392507e-06] 
Layer 'fc8' biases: 6.003990e-02 [5.014827e-05] 
Train error last 870 batches: 0.435214
-------------------------------------------------------
Not saving because 0.422358 > 0.415666 (22.630: -0.00%)
======================================================= (12.060 sec)
24.691... logprob:  0.516582, 0.140625 (1.442 sec)
24.692... logprob:  0.385019, 0.101562 (1.443 sec)
24.693... logprob:  0.455740, 0.125000 (1.481 sec)
24.694... logprob:  0.330924, 0.078125 (1.436 sec)
24.695... logprob:  0.356922, 0.085938 (1.448 sec)
24.696... logprob:  0.539059, 0.148438 (1.478 sec)
24.697... logprob:  0.465693, 0.125000 (1.434 sec)
24.698... logprob:  0.548824, 0.156250 (1.436 sec)
24.699... logprob:  0.459609, 0.125000 (1.441 sec)
24.700... logprob:  0.433908, 0.117188 (1.428 sec)
24.701... logprob:  0.423106, 0.109375 (1.436 sec)
24.702... logprob:  0.521518, 0.148438 (1.482 sec)
24.703... logprob:  0.405201, 0.101562 (1.441 sec)
24.704... logprob:  0.406103, 0.101562 (1.450 sec)
24.705... logprob:  0.420187, 0.109375 (1.479 sec)
24.706... logprob:  0.468065, 0.125000 (1.436 sec)
24.707... logprob:  0.485299, 0.132812 (1.439 sec)
24.708... logprob:  0.417154, 0.109375 (1.433 sec)
24.709... logprob:  0.422572, 0.109375 (1.428 sec)
24.710... logprob:  0.602356, 0.179688 (1.437 sec)
24.711... logprob:  0.469488, 0.125000 (1.468 sec)
24.712... logprob:  0.340700, 0.078125 (1.453 sec)
24.713... logprob:  0.586801, 0.179688 (1.455 sec)
24.714... logprob:  0.466276, 0.125000 (1.466 sec)
24.715... logprob:  0.417171, 0.109375 (1.456 sec)
24.716... logprob:  0.335390, 0.078125 (1.440 sec)
24.717... logprob:  0.429799, 0.117188 (1.429 sec)
24.718... logprob:  0.490338, 0.132812 (1.428 sec)
24.719... logprob:  0.406187, 0.109375 (1.444 sec)
24.720... logprob:  0.433230, 0.117188 (1.446 sec)
24.721... logprob:  0.451603, 0.117188 (1.463 sec)
24.722... logprob:  0.536954, 0.156250 (1.457 sec)
24.723... logprob:  0.416566, 0.109375 (1.448 sec)
24.724... logprob:  0.412766, 0.109375 (1.473 sec)
24.725... logprob:  0.494777, 0.140625 (1.433 sec)
24.726... logprob:  0.338518, 0.085938 (1.425 sec)
24.727... logprob:  0.393268, 0.101562 (1.432 sec)
24.728... logprob:  0.421270, 0.109375 (1.444 sec)
24.729... logprob:  0.387665, 0.093750 (1.429 sec)
24.730... logprob:  0.565885, 0.164062 (1.478 sec)
24.731... logprob:  0.450377, 0.125000 (1.484 sec)
24.732... logprob:  0.311432, 0.070312 (1.433 sec)
24.733... logprob:  0.556568, 0.156250 (1.487 sec)
24.734... logprob:  0.340248, 0.078125 (1.427 sec)
24.735... logprob:  0.527499, 0.148438 (1.433 sec)
24.736... logprob:  0.642748, 0.187500 (1.436 sec)
24.737... logprob:  0.516136, 0.148438 (1.436 sec)
24.738... logprob:  0.459403, 0.125000 (1.432 sec)
24.739... logprob:  0.477798, 0.132812 (1.486 sec)
24.740... logprob:  0.339649, 0.078125 (1.438 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.96010208129883, 10.0]}, 128)
batch 872: ({'logprob': [65.74498748779297, 19.0]}, 128)
batch 873: ({'logprob': [42.383583068847656, 9.0]}, 128)
batch 874: ({'logprob': [46.37382125854492, 11.0]}, 128)
batch 875: ({'logprob': [51.48689651489258, 13.0]}, 128)
batch 876: ({'logprob': [63.490394592285156, 18.0]}, 128)
batch 877: ({'logprob': [46.94525146484375, 11.0]}, 128)
batch 878: ({'logprob': [61.7569694519043, 17.0]}, 128)
batch 879: ({'logprob': [72.54817199707031, 21.0]}, 128)
batch 880: ({'logprob': [51.508338928222656, 13.0]}, 128)
batch 881: ({'logprob': [31.557830810546875, 5.0]}, 128)
batch 882: ({'logprob': [55.4708137512207, 14.0]}, 128)
batch 883: ({'logprob': [61.733970642089844, 17.0]}, 128)
batch 884: ({'logprob': [52.05149841308594, 13.0]}, 128)
batch 885: ({'logprob': [53.17521667480469, 13.0]}, 128)
batch 886: ({'logprob': [62.311553955078125, 17.0]}, 128)

======================Test output======================
logprob:  0.420654, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.963416e-03 [3.207076e-09] 
Layer 'conv1' biases: 2.850827e-07 [9.387260e-11] 
Layer 'conv2' weights[0]: 7.950487e-03 [3.377919e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.884794e-10] 
Layer 'conv3' weights[0]: 7.948686e-03 [3.144174e-09] 
Layer 'conv3' biases: 2.433494e-06 [1.841930e-09] 
Layer 'conv4' weights[0]: 7.981379e-03 [3.360620e-09] 
Layer 'conv4' biases: 9.999993e-01 [1.683622e-08] 
Layer 'conv5' weights[0]: 7.980209e-03 [1.094169e-07] 
Layer 'conv5' biases: 9.999939e-01 [1.177107e-07] 
Layer 'fc6' weights[0]: 7.576841e-03 [9.094233e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.180815e-09] 
Layer 'fc7' weights[0]: 7.070177e-03 [7.060562e-08] 
Layer 'fc7' biases: 9.998583e-01 [5.543863e-08] 
Layer 'fc8' weights[0]: 1.258841e-03 [2.695437e-06] 
Layer 'fc8' biases: 5.943823e-02 [1.669485e-05] 
Train error last 870 batches: 0.435213
-------------------------------------------------------
Not saving because 0.420654 > 0.415666 (22.630: -0.00%)
======================================================= (12.065 sec)
24.741... logprob:  0.393462, 0.101562 (1.445 sec)
24.742... logprob:  0.419705, 0.109375 (1.484 sec)
24.743... logprob:  0.364880, 0.085938 (1.433 sec)
24.744... logprob:  0.519185, 0.148438 (1.432 sec)
24.745... logprob:  0.478150, 0.132812 (1.432 sec)
24.746... logprob:  0.440549, 0.117188 (1.434 sec)
24.747... logprob:  0.425610, 0.109375 (1.436 sec)
24.748... logprob:  0.378105, 0.093750 (1.486 sec)
24.749... logprob:  0.420820, 0.109375 (1.435 sec)
24.750... logprob:  0.512830, 0.140625 (1.449 sec)
24.751... logprob:  0.263636, 0.054688 (1.480 sec)
24.752... logprob:  0.522511, 0.140625 (1.438 sec)
24.753... logprob:  0.441191, 0.117188 (1.443 sec)
24.754... logprob:  0.468402, 0.132812 (1.436 sec)
24.755... logprob:  0.507073, 0.140625 (1.424 sec)
24.756... logprob:  0.440829, 0.117188 (1.438 sec)
24.757... logprob:  0.552397, 0.156250 (1.474 sec)
24.758... logprob:  0.393618, 0.101562 (1.449 sec)
24.759... logprob:  0.459695, 0.125000 (1.457 sec)
24.760... logprob:  0.485499, 0.132812 (1.459 sec)
24.761... logprob:  0.418247, 0.109375 (1.450 sec)
24.762... logprob:  0.516032, 0.148438 (1.438 sec)
24.763... logprob:  0.558909, 0.164062 (1.426 sec)
24.764... logprob:  0.503274, 0.140625 (1.450 sec)
24.765... logprob:  0.311927, 0.062500 (1.446 sec)
24.766... logprob:  0.482242, 0.132812 (1.455 sec)
24.767... logprob:  0.371117, 0.085938 (1.456 sec)
24.768... logprob:  0.432673, 0.117188 (1.467 sec)
24.769... logprob:  0.490835, 0.140625 (1.466 sec)
24.770... logprob:  0.402923, 0.101562 (1.477 sec)
24.771... logprob:  0.549493, 0.156250 (1.460 sec)
24.772... logprob:  0.414076, 0.109375 (1.447 sec)
24.773... logprob:  0.557849, 0.164062 (1.451 sec)
24.774... logprob:  0.361691, 0.085938 (1.460 sec)
24.775... logprob:  0.407366, 0.101562 (1.463 sec)
24.776... logprob:  0.433184, 0.117188 (1.479 sec)
24.777... logprob:  0.379955, 0.093750 (1.477 sec)
24.778... logprob:  0.433573, 0.117188 (1.466 sec)
24.779... logprob:  0.505384, 0.140625 (1.487 sec)
24.780... logprob:  0.385760, 0.101562 (1.459 sec)
24.781... logprob:  0.369663, 0.085938 (1.445 sec)
24.782... logprob:  0.351442, 0.085938 (1.453 sec)
24.783... logprob:  0.555511, 0.156250 (1.457 sec)
24.784... logprob:  0.440957, 0.117188 (1.464 sec)
24.785... logprob:  0.543650, 0.156250 (1.481 sec)
24.786... logprob:  0.477498, 0.132812 (1.468 sec)
24.787... logprob:  0.546386, 0.156250 (1.460 sec)
24.788... logprob:  0.563133, 0.164062 (1.496 sec)
24.789... logprob:  0.280957, 0.054688 (1.453 sec)
24.790... logprob:  0.408070, 0.101562 (1.453 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.02345657348633, 10.0]}, 128)
batch 872: ({'logprob': [65.91044616699219, 19.0]}, 128)
batch 873: ({'logprob': [42.025352478027344, 9.0]}, 128)
batch 874: ({'logprob': [46.26349639892578, 11.0]}, 128)
batch 875: ({'logprob': [51.38534164428711, 13.0]}, 128)
batch 876: ({'logprob': [63.59209060668945, 18.0]}, 128)
batch 877: ({'logprob': [46.71561813354492, 11.0]}, 128)
batch 878: ({'logprob': [61.67491912841797, 17.0]}, 128)
batch 879: ({'logprob': [72.3668441772461, 21.0]}, 128)
batch 880: ({'logprob': [51.407466888427734, 13.0]}, 128)
batch 881: ({'logprob': [31.299240112304688, 5.0]}, 128)
batch 882: ({'logprob': [55.07712936401367, 14.0]}, 128)
batch 883: ({'logprob': [61.65152359008789, 17.0]}, 128)
batch 884: ({'logprob': [51.83170700073242, 13.0]}, 128)
batch 885: ({'logprob': [52.717254638671875, 13.0]}, 128)
batch 886: ({'logprob': [62.110748291015625, 17.0]}, 128)

======================Test output======================
logprob:  0.419459, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.963381e-03 [3.208174e-09] 
Layer 'conv1' biases: 2.859933e-07 [1.181409e-10] 
Layer 'conv2' weights[0]: 7.950453e-03 [3.214726e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.121284e-10] 
Layer 'conv3' weights[0]: 7.948646e-03 [3.080593e-09] 
Layer 'conv3' biases: 2.441700e-06 [1.895972e-09] 
Layer 'conv4' weights[0]: 7.981342e-03 [3.132072e-09] 
Layer 'conv4' biases: 9.999993e-01 [1.640251e-08] 
Layer 'conv5' weights[0]: 7.980165e-03 [1.041150e-07] 
Layer 'conv5' biases: 9.999941e-01 [1.121020e-07] 
Layer 'fc6' weights[0]: 7.576808e-03 [8.646502e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.746805e-09] 
Layer 'fc7' weights[0]: 7.068351e-03 [9.023145e-08] 
Layer 'fc7' biases: 9.998582e-01 [7.646690e-08] 
Layer 'fc8' weights[0]: 1.260589e-03 [2.860191e-06] 
Layer 'fc8' biases: 5.959859e-02 [1.536555e-05] 
Train error last 870 batches: 0.435213
-------------------------------------------------------
Not saving because 0.419459 > 0.415666 (22.630: -0.00%)
======================================================= (12.059 sec)
24.791... logprob:  0.397970, 0.101562 (1.458 sec)
24.792... logprob:  0.361045, 0.085938 (1.466 sec)
24.793... logprob:  0.370153, 0.085938 (1.455 sec)
24.794... logprob:  0.387129, 0.093750 (1.487 sec)
24.795... logprob:  0.469760, 0.125000 (1.467 sec)
24.796... logprob:  0.423506, 0.109375 (1.457 sec)
24.797... logprob:  0.358821, 0.085938 (1.504 sec)
24.798... logprob:  0.393284, 0.101562 (1.452 sec)
24.799... logprob:  0.332358, 0.078125 (1.453 sec)
24.800... logprob:  0.371724, 0.093750 (1.445 sec)
24.801... logprob:  0.450095, 0.117188 (1.464 sec)
24.802... logprob:  0.422981, 0.109375 (1.453 sec)
24.803... logprob:  0.491664, 0.132812 (1.495 sec)
24.804... logprob:  0.349961, 0.085938 (1.461 sec)
24.805... logprob:  0.452284, 0.117188 (1.452 sec)
24.806... logprob:  0.424181, 0.109375 (1.500 sec)
24.807... logprob:  0.443471, 0.117188 (1.456 sec)
24.808... logprob:  0.462359, 0.125000 (1.451 sec)
24.809... logprob:  0.589675, 0.171875 (1.449 sec)
24.810... logprob:  0.442471, 0.117188 (1.463 sec)
24.811... logprob:  0.460418, 0.125000 (1.450 sec)
24.812... logprob:  0.462364, 0.125000 (1.499 sec)
24.813... logprob:  0.485961, 0.132812 (1.459 sec)
24.814... logprob:  0.478006, 0.132812 (1.452 sec)
24.815... logprob:  0.371821, 0.085938 (1.502 sec)
24.816... logprob:  0.408694, 0.101562 (1.457 sec)
24.817... logprob:  0.425951, 0.109375 (1.450 sec)
24.818... logprob:  0.559991, 0.164062 (1.452 sec)
24.819... logprob:  0.498196, 0.140625 (1.456 sec)
24.820... logprob:  0.421630, 0.109375 (1.457 sec)
24.821... logprob:  0.406593, 0.101562 (1.497 sec)
24.822... logprob:  0.441196, 0.117188 (1.458 sec)
24.823... logprob:  0.340854, 0.078125 (1.457 sec)
24.824... logprob:  0.489793, 0.132812 (1.503 sec)
24.825... logprob:  0.288029, 0.062500 (1.450 sec)
24.826... logprob:  0.375488, 0.093750 (1.460 sec)
24.827... logprob:  0.420528, 0.109375 (1.448 sec)
24.828... logprob:  0.443353, 0.117188 (1.454 sec)
24.829... logprob:  0.504162, 0.140625 (1.458 sec)
24.830... logprob:  0.442179, 0.117188 (1.509 sec)
24.831... logprob:  0.513968, 0.140625 (1.454 sec)
24.832... logprob:  0.330845, 0.078125 (1.461 sec)
24.833... logprob:  0.489019, 0.132812 (1.500 sec)
24.834... logprob:  0.433307, 0.117188 (1.452 sec)
24.835... logprob:  0.542743, 0.148438 (1.461 sec)
24.836... logprob:  0.376184, 0.093750 (1.449 sec)
24.837... logprob:  0.314326, 0.070312 (1.477 sec)
24.838... logprob:  0.437073, 0.117188 (1.456 sec)
24.839... logprob:  0.471676, 0.125000 (1.505 sec)
24.840... logprob:  0.555429, 0.156250 (1.451 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.60210037231445, 10.0]}, 128)
batch 872: ({'logprob': [66.21876525878906, 19.0]}, 128)
batch 873: ({'logprob': [41.26325988769531, 9.0]}, 128)
batch 874: ({'logprob': [45.80630111694336, 11.0]}, 128)
batch 875: ({'logprob': [51.08079528808594, 13.0]}, 128)
batch 876: ({'logprob': [63.78644561767578, 18.0]}, 128)
batch 877: ({'logprob': [46.182010650634766, 11.0]}, 128)
batch 878: ({'logprob': [61.67818832397461, 17.0]}, 128)
batch 879: ({'logprob': [72.60275268554688, 21.0]}, 128)
batch 880: ({'logprob': [51.103355407714844, 13.0]}, 128)
batch 881: ({'logprob': [30.30414390563965, 5.0]}, 128)
batch 882: ({'logprob': [54.66197204589844, 14.0]}, 128)
batch 883: ({'logprob': [61.65474319458008, 17.0]}, 128)
batch 884: ({'logprob': [51.45329284667969, 13.0]}, 128)
batch 885: ({'logprob': [52.187923431396484, 13.0]}, 128)
batch 886: ({'logprob': [62.03933334350586, 17.0]}, 128)

======================Test output======================
logprob:  0.417298, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.963343e-03 [4.615495e-09] 
Layer 'conv1' biases: 2.870016e-07 [9.810218e-11] 
Layer 'conv2' weights[0]: 7.950416e-03 [3.144354e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.178560e-10] 
Layer 'conv3' weights[0]: 7.948603e-03 [2.636403e-09] 
Layer 'conv3' biases: 2.449118e-06 [1.543994e-09] 
Layer 'conv4' weights[0]: 7.981304e-03 [2.749916e-09] 
Layer 'conv4' biases: 9.999993e-01 [1.328766e-08] 
Layer 'conv5' weights[0]: 7.980118e-03 [8.756369e-08] 
Layer 'conv5' biases: 9.999938e-01 [9.431947e-08] 
Layer 'fc6' weights[0]: 7.576767e-03 [7.224068e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.334886e-09] 
Layer 'fc7' weights[0]: 7.066575e-03 [2.162159e-07] 
Layer 'fc7' biases: 9.998586e-01 [2.059957e-07] 
Layer 'fc8' weights[0]: 1.272048e-03 [7.226408e-06] 
Layer 'fc8' biases: 5.997248e-02 [4.741679e-05] 
Train error last 870 batches: 0.435213
-------------------------------------------------------
Not saving because 0.417298 > 0.415666 (22.630: -0.00%)
======================================================= (12.037 sec)
24.841... logprob:  0.396111, 0.101562 (1.466 sec)
24.842... logprob:  0.497852, 0.140625 (1.493 sec)
24.843... logprob:  0.465518, 0.125000 (1.455 sec)
24.844... logprob:  0.497646, 0.140625 (1.455 sec)
24.845... logprob:  0.486773, 0.132812 (1.453 sec)
24.846... logprob:  0.468433, 0.125000 (1.451 sec)
24.847... logprob:  0.363327, 0.085938 (1.453 sec)
24.848... logprob:  0.397153, 0.101562 (1.500 sec)
24.849... logprob:  0.360468, 0.085938 (1.457 sec)
24.850... logprob:  0.479396, 0.132812 (1.465 sec)
24.851... logprob:  0.440141, 0.117188 (1.487 sec)
24.852... logprob:  0.545556, 0.156250 (1.454 sec)
24.853... logprob:  0.371918, 0.093750 (1.462 sec)
24.854... logprob:  0.307242, 0.070312 (1.451 sec)
24.855... logprob:  0.484810, 0.132812 (1.452 sec)
24.856... logprob:  0.443766, 0.117188 (1.450 sec)
24.857... logprob:  0.372230, 0.093750 (1.500 sec)
24.858... logprob:  0.396246, 0.101562 (1.463 sec)
24.859... logprob:  0.307972, 0.070312 (1.469 sec)
24.860... logprob:  0.565978, 0.156250 (1.490 sec)
24.861... logprob:  0.417806, 0.109375 (1.454 sec)
24.862... logprob:  0.328869, 0.078125 (1.466 sec)
24.863... logprob:  0.399554, 0.101562 (1.448 sec)
24.864... logprob:  0.451458, 0.117188 (1.446 sec)
24.865... logprob:  0.484536, 0.132812 (1.456 sec)
24.866... logprob:  0.507689, 0.140625 (1.488 sec)
24.867... logprob:  0.503040, 0.140625 (1.480 sec)
24.868... logprob:  0.405278, 0.101562 (1.471 sec)
24.869... logprob:  0.383172, 0.093750 (1.484 sec)
24.870... logprob:  0.552130, 0.156250 (1.407 sec)
25.1... logprob:  0.380012, 0.093750 (1.408 sec)
25.2... logprob:  0.448259, 0.117188 (1.446 sec)
25.3... logprob:  0.398319, 0.101562 (1.414 sec)
25.4... logprob:  0.443314, 0.117188 (1.408 sec)
25.5... logprob:  0.443463, 0.117188 (1.431 sec)
25.6... logprob:  0.499103, 0.140625 (1.399 sec)
25.7... logprob:  0.363215, 0.085938 (1.423 sec)
25.8... logprob:  0.419147, 0.109375 (1.399 sec)
25.9... logprob:  0.358835, 0.085938 (1.402 sec)
25.10... logprob:  0.377528, 0.093750 (1.410 sec)
25.11... logprob:  0.334796, 0.078125 (1.447 sec)
25.12... logprob:  0.466354, 0.125000 (1.392 sec)
25.13... logprob:  0.442232, 0.117188 (1.423 sec)
25.14... logprob:  0.444609, 0.117188 (1.407 sec)
25.15... logprob:  0.395547, 0.101562 (1.411 sec)
25.16... logprob:  0.421391, 0.109375 (1.411 sec)
25.17... logprob:  0.515996, 0.140625 (1.396 sec)
25.18... logprob:  0.262107, 0.054688 (1.403 sec)
25.19... logprob:  0.279522, 0.062500 (1.406 sec)
25.20... logprob:  0.421370, 0.109375 (1.405 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.598663330078125, 10.0]}, 128)
batch 872: ({'logprob': [68.3416976928711, 19.0]}, 128)
batch 873: ({'logprob': [39.36774826049805, 9.0]}, 128)
batch 874: ({'logprob': [44.905574798583984, 11.0]}, 128)
batch 875: ({'logprob': [50.85330581665039, 13.0]}, 128)
batch 876: ({'logprob': [65.49430847167969, 18.0]}, 128)
batch 877: ({'logprob': [45.11982727050781, 11.0]}, 128)
batch 878: ({'logprob': [62.8068962097168, 17.0]}, 128)
batch 879: ({'logprob': [74.92813873291016, 21.0]}, 128)
batch 880: ({'logprob': [50.8781852722168, 13.0]}, 128)
batch 881: ({'logprob': [27.209575653076172, 5.0]}, 128)
batch 882: ({'logprob': [54.38172149658203, 14.0]}, 128)
batch 883: ({'logprob': [62.781978607177734, 17.0]}, 128)
batch 884: ({'logprob': [51.0738639831543, 13.0]}, 128)
batch 885: ({'logprob': [51.49166488647461, 13.0]}, 128)
batch 886: ({'logprob': [63.01264190673828, 17.0]}, 128)

======================Test output======================
logprob:  0.417112, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.963310e-03 [3.342533e-09] 
Layer 'conv1' biases: 2.879112e-07 [5.130444e-11] 
Layer 'conv2' weights[0]: 7.950383e-03 [1.850675e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.521590e-10] 
Layer 'conv3' weights[0]: 7.948569e-03 [1.303123e-09] 
Layer 'conv3' biases: 2.454832e-06 [4.040723e-10] 
Layer 'conv4' weights[0]: 7.981258e-03 [1.284068e-09] 
Layer 'conv4' biases: 9.999993e-01 [1.498676e-09] 
Layer 'conv5' weights[0]: 7.980050e-03 [9.122766e-09] 
Layer 'conv5' biases: 9.999936e-01 [9.596143e-09] 
Layer 'fc6' weights[0]: 7.576718e-03 [1.095096e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.503108e-10] 
Layer 'fc7' weights[0]: 7.064691e-03 [6.550400e-08] 
Layer 'fc7' biases: 9.998602e-01 [4.849185e-08] 
Layer 'fc8' weights[0]: 1.331752e-03 [1.873352e-06] 
Layer 'fc8' biases: 6.054449e-02 [1.285775e-05] 
Train error last 870 batches: 0.435213
-------------------------------------------------------
Not saving because 0.417112 > 0.415666 (22.630: -0.00%)
======================================================= (12.118 sec)
25.21... logprob:  0.443980, 0.117188 (1.409 sec)
25.22... logprob:  0.536722, 0.148438 (1.423 sec)
25.23... logprob:  0.533046, 0.148438 (1.421 sec)
25.24... logprob:  0.310565, 0.070312 (1.422 sec)
25.25... logprob:  0.356182, 0.085938 (1.401 sec)
25.26... logprob:  0.463764, 0.125000 (1.447 sec)
25.27... logprob:  0.404533, 0.101562 (1.392 sec)
25.28... logprob:  0.421854, 0.109375 (1.411 sec)
25.29... logprob:  0.395961, 0.101562 (1.428 sec)
25.30... logprob:  0.374093, 0.093750 (1.416 sec)
25.31... logprob:  0.479950, 0.132812 (1.405 sec)
25.32... logprob:  0.457225, 0.125000 (1.396 sec)
25.33... logprob:  0.460677, 0.125000 (1.474 sec)
25.34... logprob:  0.464553, 0.125000 (1.390 sec)
25.35... logprob:  0.316290, 0.070312 (1.408 sec)
25.36... logprob:  0.475793, 0.132812 (1.408 sec)
25.37... logprob:  0.417592, 0.109375 (1.404 sec)
25.38... logprob:  0.392636, 0.101562 (1.399 sec)
25.39... logprob:  0.631570, 0.187500 (1.439 sec)
25.40... logprob:  0.445725, 0.117188 (1.407 sec)
25.41... logprob:  0.352920, 0.085938 (1.425 sec)
25.42... logprob:  0.391960, 0.101562 (1.424 sec)
25.43... logprob:  0.440087, 0.117188 (1.408 sec)
25.44... logprob:  0.518547, 0.148438 (1.440 sec)
25.45... logprob:  0.381738, 0.093750 (1.389 sec)
25.46... logprob:  0.486234, 0.132812 (1.401 sec)
25.47... logprob:  0.331728, 0.078125 (1.397 sec)
25.48... logprob:  0.498920, 0.140625 (1.422 sec)
25.49... logprob:  0.510814, 0.148438 (1.419 sec)
25.50... logprob:  0.393199, 0.101562 (1.422 sec)
25.51... logprob:  0.490191, 0.140625 (1.420 sec)
25.52... logprob:  0.525787, 0.148438 (1.402 sec)
25.53... logprob:  0.294865, 0.062500 (1.445 sec)
25.54... logprob:  0.403357, 0.109375 (1.392 sec)
25.55... logprob:  0.331721, 0.078125 (1.399 sec)
25.56... logprob:  0.421642, 0.109375 (1.406 sec)
25.57... logprob:  0.572398, 0.164062 (1.430 sec)
25.58... logprob:  0.407609, 0.101562 (1.538 sec)
25.59... logprob:  0.333866, 0.078125 (1.472 sec)
25.60... logprob:  0.618811, 0.179688 (1.416 sec)
25.61... logprob:  0.382821, 0.093750 (1.443 sec)
25.62... logprob:  0.474856, 0.132812 (1.460 sec)
25.63... logprob:  0.397295, 0.101562 (1.440 sec)
25.64... logprob:  0.450308, 0.125000 (1.412 sec)
25.65... logprob:  0.373364, 0.093750 (1.399 sec)
25.66... logprob:  0.354031, 0.085938 (1.447 sec)
25.67... logprob:  0.295411, 0.062500 (1.395 sec)
25.68... logprob:  0.396804, 0.101562 (1.395 sec)
25.69... logprob:  0.496714, 0.140625 (1.420 sec)
25.70... logprob:  0.325894, 0.078125 (1.426 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.01048278808594, 10.0]}, 128)
batch 872: ({'logprob': [67.06524658203125, 19.0]}, 128)
batch 873: ({'logprob': [40.278404235839844, 9.0]}, 128)
batch 874: ({'logprob': [44.88256072998047, 11.0]}, 128)
batch 875: ({'logprob': [50.725563049316406, 13.0]}, 128)
batch 876: ({'logprob': [64.47640991210938, 18.0]}, 128)
batch 877: ({'logprob': [45.51069259643555, 11.0]}, 128)
batch 878: ({'logprob': [62.463321685791016, 17.0]}, 128)
batch 879: ({'logprob': [74.78059387207031, 21.0]}, 128)
batch 880: ({'logprob': [50.748477935791016, 13.0]}, 128)
batch 881: ({'logprob': [27.9232234954834, 5.0]}, 128)
batch 882: ({'logprob': [55.229923248291016, 14.0]}, 128)
batch 883: ({'logprob': [62.439449310302734, 17.0]}, 128)
batch 884: ({'logprob': [51.35619354248047, 13.0]}, 128)
batch 885: ({'logprob': [52.59960174560547, 13.0]}, 128)
batch 886: ({'logprob': [63.0809211730957, 17.0]}, 128)

======================Test output======================
logprob:  0.417271, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.963272e-03 [2.518568e-09] 
Layer 'conv1' biases: 2.887652e-07 [6.670011e-11] 
Layer 'conv2' weights[0]: 7.950342e-03 [1.780463e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.567880e-10] 
Layer 'conv3' weights[0]: 7.948527e-03 [1.579935e-09] 
Layer 'conv3' biases: 2.461957e-06 [7.805621e-10] 
Layer 'conv4' weights[0]: 7.981223e-03 [1.630167e-09] 
Layer 'conv4' biases: 9.999993e-01 [6.701357e-09] 
Layer 'conv5' weights[0]: 7.980010e-03 [4.399713e-08] 
Layer 'conv5' biases: 9.999934e-01 [4.738352e-08] 
Layer 'fc6' weights[0]: 7.576678e-03 [3.739735e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.724231e-09] 
Layer 'fc7' weights[0]: 7.062842e-03 [1.596596e-07] 
Layer 'fc7' biases: 9.998600e-01 [1.482696e-07] 
Layer 'fc8' weights[0]: 1.318723e-03 [5.949498e-06] 
Layer 'fc8' biases: 6.047972e-02 [3.918114e-05] 
Train error last 870 batches: 0.435213
-------------------------------------------------------
Not saving because 0.417271 > 0.415666 (22.630: -0.00%)
======================================================= (12.047 sec)
25.71... logprob:  0.381810, 0.101562 (1.468 sec)
25.72... logprob:  0.493739, 0.132812 (1.411 sec)
25.73... logprob:  0.447710, 0.117188 (1.423 sec)
25.74... logprob:  0.442536, 0.117188 (1.419 sec)
25.75... logprob:  0.380651, 0.093750 (1.415 sec)
25.76... logprob:  0.412057, 0.109375 (1.449 sec)
25.77... logprob:  0.396343, 0.101562 (1.428 sec)
25.78... logprob:  0.493057, 0.140625 (1.458 sec)
25.79... logprob:  0.456465, 0.125000 (1.409 sec)
25.80... logprob:  0.507989, 0.132812 (1.433 sec)
25.81... logprob:  0.416724, 0.109375 (1.419 sec)
25.82... logprob:  0.231398, 0.039062 (1.424 sec)
25.83... logprob:  0.493793, 0.140625 (1.401 sec)
25.84... logprob:  0.468128, 0.125000 (1.471 sec)
25.85... logprob:  0.431954, 0.117188 (1.424 sec)
25.86... logprob:  0.416944, 0.109375 (1.422 sec)
25.87... logprob:  0.633265, 0.187500 (1.415 sec)
25.88... logprob:  0.535041, 0.156250 (1.411 sec)
25.89... logprob:  0.410570, 0.109375 (1.438 sec)
25.90... logprob:  0.577487, 0.171875 (1.392 sec)
25.91... logprob:  0.348460, 0.078125 (1.396 sec)
25.92... logprob:  0.464461, 0.125000 (1.402 sec)
25.93... logprob:  0.492228, 0.140625 (1.399 sec)
25.94... logprob:  0.428784, 0.109375 (1.395 sec)
25.95... logprob:  0.471838, 0.125000 (1.407 sec)
25.96... logprob:  0.576228, 0.171875 (1.411 sec)
25.97... logprob:  0.430779, 0.117188 (1.399 sec)
25.98... logprob:  0.391156, 0.093750 (1.443 sec)
25.99... logprob:  0.474244, 0.132812 (1.407 sec)
25.100... logprob:  0.310546, 0.070312 (1.403 sec)
25.101... logprob:  0.310805, 0.062500 (1.444 sec)
25.102... logprob:  0.546037, 0.156250 (1.395 sec)
25.103... logprob:  0.541036, 0.156250 (1.400 sec)
25.104... logprob:  0.388827, 0.101562 (1.406 sec)
25.105... logprob:  0.619426, 0.179688 (1.401 sec)
25.106... logprob:  0.344455, 0.085938 (1.397 sec)
25.107... logprob:  0.335766, 0.078125 (1.437 sec)
25.108... logprob:  0.586849, 0.171875 (1.403 sec)
25.109... logprob:  0.336146, 0.078125 (1.417 sec)
25.110... logprob:  0.564600, 0.164062 (1.401 sec)
25.111... logprob:  0.404683, 0.101562 (1.398 sec)
25.112... logprob:  0.366046, 0.093750 (1.411 sec)
25.113... logprob:  0.354494, 0.085938 (1.406 sec)
25.114... logprob:  0.440216, 0.117188 (1.434 sec)
25.115... logprob:  0.506762, 0.140625 (1.411 sec)
25.116... logprob:  0.393363, 0.101562 (1.407 sec)
25.117... logprob:  0.440393, 0.117188 (1.450 sec)
25.118... logprob:  0.409112, 0.101562 (1.389 sec)
25.119... logprob:  0.346097, 0.085938 (1.399 sec)
25.120... logprob:  0.547132, 0.156250 (1.401 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.69603729248047, 10.0]}, 128)
batch 872: ({'logprob': [66.47330474853516, 19.0]}, 128)
batch 873: ({'logprob': [40.68581008911133, 9.0]}, 128)
batch 874: ({'logprob': [45.23622512817383, 11.0]}, 128)
batch 875: ({'logprob': [50.78253936767578, 13.0]}, 128)
batch 876: ({'logprob': [63.971885681152344, 18.0]}, 128)
batch 877: ({'logprob': [45.74364471435547, 11.0]}, 128)
batch 878: ({'logprob': [61.92557907104492, 17.0]}, 128)
batch 879: ({'logprob': [73.52715301513672, 21.0]}, 128)
batch 880: ({'logprob': [50.80537414550781, 13.0]}, 128)
batch 881: ({'logprob': [29.04796600341797, 5.0]}, 128)
batch 882: ({'logprob': [54.83285903930664, 14.0]}, 128)
batch 883: ({'logprob': [61.90169143676758, 17.0]}, 128)
batch 884: ({'logprob': [51.289676666259766, 13.0]}, 128)
batch 885: ({'logprob': [52.289588928222656, 13.0]}, 128)
batch 886: ({'logprob': [62.4204216003418, 17.0]}, 128)

======================Test output======================
logprob:  0.416323, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.963230e-03 [2.715135e-09] 
Layer 'conv1' biases: 2.898142e-07 [5.211713e-11] 
Layer 'conv2' weights[0]: 7.950300e-03 [1.971579e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.055754e-10] 
Layer 'conv3' weights[0]: 7.948490e-03 [1.797306e-09] 
Layer 'conv3' biases: 2.470423e-06 [1.031544e-09] 
Layer 'conv4' weights[0]: 7.981186e-03 [1.825823e-09] 
Layer 'conv4' biases: 9.999993e-01 [8.390587e-09] 
Layer 'conv5' weights[0]: 7.979996e-03 [5.447504e-08] 
Layer 'conv5' biases: 9.999937e-01 [5.855385e-08] 
Layer 'fc6' weights[0]: 7.576632e-03 [4.626831e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.606524e-09] 
Layer 'fc7' weights[0]: 7.061052e-03 [4.042983e-08] 
Layer 'fc7' biases: 9.998592e-01 [1.705986e-08] 
Layer 'fc8' weights[0]: 1.293589e-03 [8.079677e-07] 
Layer 'fc8' biases: 6.041776e-02 [4.880206e-06] 
Train error last 870 batches: 0.435212
-------------------------------------------------------
Not saving because 0.416323 > 0.415666 (22.630: -0.00%)
======================================================= (12.067 sec)
25.121... logprob:  0.412617, 0.109375 (1.400 sec)
25.122... logprob:  0.519286, 0.148438 (1.447 sec)
25.123... logprob:  0.463692, 0.125000 (1.387 sec)
25.124... logprob:  0.447694, 0.125000 (1.408 sec)
25.125... logprob:  0.501939, 0.140625 (1.399 sec)
25.126... logprob:  0.475755, 0.125000 (1.396 sec)
25.127... logprob:  0.479538, 0.125000 (1.398 sec)
25.128... logprob:  0.422345, 0.109375 (1.422 sec)
25.129... logprob:  0.574889, 0.164062 (1.420 sec)
25.130... logprob:  0.382714, 0.093750 (1.417 sec)
25.131... logprob:  0.495497, 0.132812 (1.406 sec)
25.132... logprob:  0.506366, 0.140625 (1.441 sec)
25.133... logprob:  0.444686, 0.117188 (1.395 sec)
25.134... logprob:  0.401881, 0.101562 (1.398 sec)
25.135... logprob:  0.460201, 0.125000 (1.402 sec)
25.136... logprob:  0.562430, 0.164062 (1.404 sec)
25.137... logprob:  0.462581, 0.125000 (1.398 sec)
25.138... logprob:  0.319382, 0.070312 (1.447 sec)
25.139... logprob:  0.395753, 0.101562 (1.401 sec)
25.140... logprob:  0.560194, 0.164062 (1.408 sec)
25.141... logprob:  0.464567, 0.125000 (1.439 sec)
25.142... logprob:  0.464629, 0.125000 (1.398 sec)
25.143... logprob:  0.294373, 0.062500 (1.427 sec)
25.144... logprob:  0.457121, 0.125000 (1.415 sec)
25.145... logprob:  0.324770, 0.078125 (1.419 sec)
25.146... logprob:  0.483128, 0.132812 (1.413 sec)
25.147... logprob:  0.262480, 0.054688 (1.437 sec)
25.148... logprob:  0.458676, 0.125000 (1.392 sec)
25.149... logprob:  0.442518, 0.117188 (1.392 sec)
25.150... logprob:  0.347590, 0.085938 (1.409 sec)
25.151... logprob:  0.347143, 0.085938 (1.397 sec)
25.152... logprob:  0.785092, 0.234375 (1.393 sec)
25.153... logprob:  0.381649, 0.093750 (1.446 sec)
25.154... logprob:  0.524597, 0.148438 (1.401 sec)
25.155... logprob:  0.426068, 0.117188 (1.414 sec)
25.156... logprob:  0.295424, 0.062500 (1.442 sec)
25.157... logprob:  0.270331, 0.054688 (1.394 sec)
25.158... logprob:  0.455416, 0.125000 (1.405 sec)
25.159... logprob:  0.483119, 0.132812 (1.397 sec)
25.160... logprob:  0.444761, 0.117188 (1.398 sec)
25.161... logprob:  0.349844, 0.078125 (1.398 sec)
25.162... logprob:  0.611786, 0.179688 (1.410 sec)
25.163... logprob:  0.450463, 0.125000 (1.425 sec)
25.164... logprob:  0.468576, 0.125000 (1.422 sec)
25.165... logprob:  0.547822, 0.156250 (1.418 sec)
25.166... logprob:  0.446119, 0.125000 (1.453 sec)
25.167... logprob:  0.350548, 0.085938 (1.428 sec)
25.168... logprob:  0.363726, 0.085938 (1.430 sec)
25.169... logprob:  0.408645, 0.101562 (1.463 sec)
25.170... logprob:  0.459471, 0.125000 (1.412 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.987701416015625, 10.0]}, 128)
batch 872: ({'logprob': [66.09318542480469, 19.0]}, 128)
batch 873: ({'logprob': [41.27241134643555, 9.0]}, 128)
batch 874: ({'logprob': [45.55233383178711, 11.0]}, 128)
batch 875: ({'logprob': [50.957454681396484, 13.0]}, 128)
batch 876: ({'logprob': [63.69428253173828, 18.0]}, 128)
batch 877: ({'logprob': [46.12465286254883, 11.0]}, 128)
batch 878: ({'logprob': [61.8158073425293, 17.0]}, 128)
batch 879: ({'logprob': [73.19641876220703, 21.0]}, 128)
batch 880: ({'logprob': [50.97990417480469, 13.0]}, 128)
batch 881: ({'logprob': [29.8557186126709, 5.0]}, 128)
batch 882: ({'logprob': [55.095619201660156, 14.0]}, 128)
batch 883: ({'logprob': [61.79209518432617, 17.0]}, 128)
batch 884: ({'logprob': [51.52705001831055, 13.0]}, 128)
batch 885: ({'logprob': [52.65487289428711, 13.0]}, 128)
batch 886: ({'logprob': [62.37394332885742, 17.0]}, 128)

======================Test output======================
logprob:  0.417468, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.963196e-03 [2.320344e-09] 
Layer 'conv1' biases: 2.907669e-07 [6.048160e-11] 
Layer 'conv2' weights[0]: 7.950255e-03 [2.118915e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.319521e-10] 
Layer 'conv3' weights[0]: 7.948446e-03 [2.123759e-09] 
Layer 'conv3' biases: 2.479304e-06 [1.067626e-09] 
Layer 'conv4' weights[0]: 7.981147e-03 [2.174145e-09] 
Layer 'conv4' biases: 9.999993e-01 [9.152823e-09] 
Layer 'conv5' weights[0]: 7.979950e-03 [5.728668e-08] 
Layer 'conv5' biases: 9.999936e-01 [6.179749e-08] 
Layer 'fc6' weights[0]: 7.576584e-03 [4.856079e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.831899e-09] 
Layer 'fc7' weights[0]: 7.059251e-03 [1.510064e-07] 
Layer 'fc7' biases: 9.998586e-01 [1.394331e-07] 
Layer 'fc8' weights[0]: 1.284512e-03 [5.759927e-06] 
Layer 'fc8' biases: 6.044999e-02 [4.075578e-05] 
Train error last 870 batches: 0.435212
-------------------------------------------------------
Not saving because 0.417468 > 0.415666 (22.630: -0.00%)
======================================================= (12.039 sec)
25.171... logprob:  0.535301, 0.156250 (1.424 sec)
25.172... logprob:  0.434825, 0.109375 (1.418 sec)
25.173... logprob:  0.440476, 0.117188 (1.422 sec)
25.174... logprob:  0.600839, 0.171875 (1.402 sec)
25.175... logprob:  0.505996, 0.140625 (1.472 sec)
25.176... logprob:  0.478427, 0.132812 (1.443 sec)
25.177... logprob:  0.289733, 0.054688 (1.431 sec)
25.178... logprob:  0.383476, 0.093750 (1.456 sec)
25.179... logprob:  0.394680, 0.101562 (1.413 sec)
25.180... logprob:  0.466387, 0.125000 (1.418 sec)
25.181... logprob:  0.539316, 0.156250 (1.424 sec)
25.182... logprob:  0.371316, 0.093750 (1.416 sec)
25.183... logprob:  0.419940, 0.109375 (1.420 sec)
25.184... logprob:  0.483447, 0.132812 (1.418 sec)
25.185... logprob:  0.289784, 0.062500 (1.400 sec)
25.186... logprob:  0.370403, 0.093750 (1.397 sec)
25.187... logprob:  0.529618, 0.148438 (1.407 sec)
25.188... logprob:  0.458904, 0.125000 (1.395 sec)
25.189... logprob:  0.440916, 0.117188 (1.393 sec)
25.190... logprob:  0.375776, 0.093750 (1.443 sec)
25.191... logprob:  0.485093, 0.132812 (1.408 sec)
25.192... logprob:  0.520069, 0.148438 (1.420 sec)
25.193... logprob:  0.312531, 0.070312 (1.422 sec)
25.194... logprob:  0.414071, 0.109375 (1.414 sec)
25.195... logprob:  0.287089, 0.062500 (1.405 sec)
25.196... logprob:  0.410488, 0.109375 (1.398 sec)
25.197... logprob:  0.477995, 0.132812 (1.401 sec)
25.198... logprob:  0.355796, 0.085938 (1.402 sec)
25.199... logprob:  0.437193, 0.117188 (1.396 sec)
25.200... logprob:  0.440742, 0.117188 (1.439 sec)
25.201... logprob:  0.437091, 0.117188 (1.406 sec)
25.202... logprob:  0.537877, 0.148438 (1.408 sec)
25.203... logprob:  0.420421, 0.109375 (1.446 sec)
25.204... logprob:  0.504123, 0.140625 (1.403 sec)
25.205... logprob:  0.334313, 0.078125 (1.404 sec)
25.206... logprob:  0.361632, 0.093750 (1.402 sec)
25.207... logprob:  0.381804, 0.093750 (1.399 sec)
25.208... logprob:  0.490564, 0.140625 (1.409 sec)
25.209... logprob:  0.334553, 0.078125 (1.420 sec)
25.210... logprob:  0.586232, 0.171875 (1.416 sec)
25.211... logprob:  0.488144, 0.132812 (1.419 sec)
25.212... logprob:  0.526128, 0.148438 (1.413 sec)
25.213... logprob:  0.514670, 0.140625 (1.465 sec)
25.214... logprob:  0.459406, 0.125000 (1.432 sec)
25.215... logprob:  0.396108, 0.101562 (1.417 sec)
25.216... logprob:  0.516973, 0.140625 (1.468 sec)
25.217... logprob:  0.324931, 0.070312 (1.402 sec)
25.218... logprob:  0.463619, 0.125000 (1.448 sec)
25.219... logprob:  0.500250, 0.140625 (1.421 sec)
25.220... logprob:  0.415018, 0.109375 (1.423 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.54718780517578, 10.0]}, 128)
batch 872: ({'logprob': [66.0061264038086, 19.0]}, 128)
batch 873: ({'logprob': [41.56802749633789, 9.0]}, 128)
batch 874: ({'logprob': [45.888240814208984, 11.0]}, 128)
batch 875: ({'logprob': [51.139095306396484, 13.0]}, 128)
batch 876: ({'logprob': [63.63572692871094, 18.0]}, 128)
batch 877: ({'logprob': [46.3637809753418, 11.0]}, 128)
batch 878: ({'logprob': [61.68879699707031, 17.0]}, 128)
batch 879: ({'logprob': [72.66363525390625, 21.0]}, 128)
batch 880: ({'logprob': [51.16189956665039, 13.0]}, 128)
batch 881: ({'logprob': [30.557920455932617, 5.0]}, 128)
batch 882: ({'logprob': [54.95637893676758, 14.0]}, 128)
batch 883: ({'logprob': [61.664794921875, 17.0]}, 128)
batch 884: ({'logprob': [51.610572814941406, 13.0]}, 128)
batch 885: ({'logprob': [52.54365539550781, 13.0]}, 128)
batch 886: ({'logprob': [62.149051666259766, 17.0]}, 128)

======================Test output======================
logprob:  0.418039, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.963155e-03 [2.940775e-09] 
Layer 'conv1' biases: 2.917841e-07 [7.840014e-11] 
Layer 'conv2' weights[0]: 7.950219e-03 [2.243945e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.530771e-10] 
Layer 'conv3' weights[0]: 7.948408e-03 [2.032784e-09] 
Layer 'conv3' biases: 2.488660e-06 [1.043610e-09] 
Layer 'conv4' weights[0]: 7.981106e-03 [2.122583e-09] 
Layer 'conv4' biases: 9.999993e-01 [9.594734e-09] 
Layer 'conv5' weights[0]: 7.979924e-03 [6.273006e-08] 
Layer 'conv5' biases: 9.999937e-01 [6.749297e-08] 
Layer 'fc6' weights[0]: 7.576544e-03 [5.224462e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.264245e-09] 
Layer 'fc7' weights[0]: 7.057462e-03 [1.038199e-07] 
Layer 'fc7' biases: 9.998583e-01 [8.951148e-08] 
Layer 'fc8' weights[0]: 1.275585e-03 [5.638437e-06] 
Layer 'fc8' biases: 6.046317e-02 [3.942284e-05] 
Train error last 870 batches: 0.435212
-------------------------------------------------------
Not saving because 0.418039 > 0.415666 (22.630: -0.00%)
======================================================= (12.084 sec)
25.221... logprob:  0.399562, 0.101562 (1.404 sec)
25.222... logprob:  0.554454, 0.164062 (1.467 sec)
25.223... logprob:  0.569019, 0.164062 (1.435 sec)
25.224... logprob:  0.405948, 0.101562 (1.442 sec)
25.225... logprob:  0.391994, 0.101562 (1.444 sec)
25.226... logprob:  0.424714, 0.109375 (1.429 sec)
25.227... logprob:  0.452653, 0.125000 (1.414 sec)
25.228... logprob:  0.417175, 0.109375 (1.420 sec)
25.229... logprob:  0.489371, 0.132812 (1.418 sec)
25.230... logprob:  0.459863, 0.125000 (1.424 sec)
25.231... logprob:  0.453503, 0.125000 (1.406 sec)
25.232... logprob:  0.496180, 0.140625 (1.463 sec)
25.233... logprob:  0.466090, 0.132812 (1.428 sec)
25.234... logprob:  0.563848, 0.164062 (1.423 sec)
25.235... logprob:  0.482016, 0.132812 (1.474 sec)
25.236... logprob:  0.425689, 0.109375 (1.410 sec)
25.237... logprob:  0.341041, 0.078125 (1.423 sec)
25.238... logprob:  0.389185, 0.093750 (1.413 sec)
25.239... logprob:  0.478101, 0.132812 (1.425 sec)
25.240... logprob:  0.485797, 0.132812 (1.405 sec)
25.241... logprob:  0.493601, 0.132812 (1.462 sec)
25.242... logprob:  0.341640, 0.078125 (1.431 sec)
25.243... logprob:  0.386002, 0.093750 (1.442 sec)
25.244... logprob:  0.315366, 0.070312 (1.448 sec)
25.245... logprob:  0.494247, 0.132812 (1.427 sec)
25.246... logprob:  0.416862, 0.109375 (1.424 sec)
25.247... logprob:  0.357512, 0.085938 (1.420 sec)
25.248... logprob:  0.307970, 0.070312 (1.425 sec)
25.249... logprob:  0.554804, 0.156250 (1.420 sec)
25.250... logprob:  0.591337, 0.164062 (1.405 sec)
25.251... logprob:  0.352970, 0.085938 (1.464 sec)
25.252... logprob:  0.348448, 0.085938 (1.424 sec)
25.253... logprob:  0.379207, 0.093750 (1.424 sec)
25.254... logprob:  0.444165, 0.117188 (1.468 sec)
25.255... logprob:  0.351369, 0.085938 (1.403 sec)
25.256... logprob:  0.378827, 0.093750 (1.424 sec)
25.257... logprob:  0.331989, 0.078125 (1.417 sec)
25.258... logprob:  0.415590, 0.109375 (1.424 sec)
25.259... logprob:  0.442315, 0.117188 (1.409 sec)
25.260... logprob:  0.308243, 0.070312 (1.461 sec)
25.261... logprob:  0.392632, 0.101562 (1.425 sec)
25.262... logprob:  0.524561, 0.148438 (1.433 sec)
25.263... logprob:  0.425556, 0.109375 (1.446 sec)
25.264... logprob:  0.375059, 0.093750 (1.428 sec)
25.265... logprob:  0.439612, 0.117188 (1.415 sec)
25.266... logprob:  0.439014, 0.117188 (1.417 sec)
25.267... logprob:  0.422026, 0.109375 (1.419 sec)
25.268... logprob:  0.458938, 0.125000 (1.422 sec)
25.269... logprob:  0.567541, 0.164062 (1.405 sec)
25.270... logprob:  0.542298, 0.156250 (1.464 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.66767120361328, 10.0]}, 128)
batch 872: ({'logprob': [66.29438781738281, 19.0]}, 128)
batch 873: ({'logprob': [41.19813537597656, 9.0]}, 128)
batch 874: ({'logprob': [45.81454849243164, 11.0]}, 128)
batch 875: ({'logprob': [51.086578369140625, 13.0]}, 128)
batch 876: ({'logprob': [63.84515380859375, 18.0]}, 128)
batch 877: ({'logprob': [46.15287780761719, 11.0]}, 128)
batch 878: ({'logprob': [61.68104934692383, 17.0]}, 128)
batch 879: ({'logprob': [72.5639877319336, 21.0]}, 128)
batch 880: ({'logprob': [51.11005401611328, 13.0]}, 128)
batch 881: ({'logprob': [30.280202865600586, 5.0]}, 128)
batch 882: ({'logprob': [54.57344055175781, 14.0]}, 128)
batch 883: ({'logprob': [61.65667724609375, 17.0]}, 128)
batch 884: ({'logprob': [51.42209243774414, 13.0]}, 128)
batch 885: ({'logprob': [52.08113479614258, 13.0]}, 128)
batch 886: ({'logprob': [62.004638671875, 17.0]}, 128)

======================Test output======================
logprob:  0.417203, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.963116e-03 [5.161618e-09] 
Layer 'conv1' biases: 2.928961e-07 [1.591206e-10] 
Layer 'conv2' weights[0]: 7.950184e-03 [4.367076e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.981591e-10] 
Layer 'conv3' weights[0]: 7.948372e-03 [4.111153e-09] 
Layer 'conv3' biases: 2.497597e-06 [2.732043e-09] 
Layer 'conv4' weights[0]: 7.981064e-03 [4.213884e-09] 
Layer 'conv4' biases: 9.999993e-01 [2.326915e-08] 
Layer 'conv5' weights[0]: 7.979888e-03 [1.479453e-07] 
Layer 'conv5' biases: 9.999939e-01 [1.593605e-07] 
Layer 'fc6' weights[0]: 7.576508e-03 [1.219818e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.249122e-08] 
Layer 'fc7' weights[0]: 7.055693e-03 [3.355258e-07] 
Layer 'fc7' biases: 9.998582e-01 [3.267319e-07] 
Layer 'fc8' weights[0]: 1.284692e-03 [1.326914e-05] 
Layer 'fc8' biases: 6.061374e-02 [8.806844e-05] 
Train error last 870 batches: 0.435211
-------------------------------------------------------
Not saving because 0.417203 > 0.415666 (22.630: -0.00%)
======================================================= (12.033 sec)
25.271... logprob:  0.445640, 0.117188 (1.429 sec)
25.272... logprob:  0.384618, 0.093750 (1.431 sec)
25.273... logprob:  0.500228, 0.140625 (1.472 sec)
25.274... logprob:  0.542506, 0.156250 (1.400 sec)
25.275... logprob:  0.487616, 0.132812 (1.426 sec)
25.276... logprob:  0.390056, 0.093750 (1.419 sec)
25.277... logprob:  0.428633, 0.109375 (1.420 sec)
25.278... logprob:  0.323558, 0.070312 (1.428 sec)
25.279... logprob:  0.325196, 0.070312 (1.461 sec)
25.280... logprob:  0.215778, 0.031250 (1.405 sec)
25.281... logprob:  0.417238, 0.109375 (1.428 sec)
25.282... logprob:  0.411353, 0.109375 (1.416 sec)
25.283... logprob:  0.393763, 0.101562 (1.422 sec)
25.284... logprob:  0.394461, 0.101562 (1.409 sec)
25.285... logprob:  0.451611, 0.117188 (1.457 sec)
25.286... logprob:  0.536624, 0.140625 (1.442 sec)
25.287... logprob:  0.346568, 0.085938 (1.431 sec)
25.288... logprob:  0.329952, 0.078125 (1.439 sec)
25.289... logprob:  0.445861, 0.117188 (1.434 sec)
25.290... logprob:  0.490654, 0.132812 (1.414 sec)
25.291... logprob:  0.439278, 0.117188 (1.418 sec)
25.292... logprob:  0.567526, 0.156250 (1.421 sec)
25.293... logprob:  0.427681, 0.117188 (1.428 sec)
25.294... logprob:  0.355854, 0.085938 (1.409 sec)
25.295... logprob:  0.334547, 0.078125 (1.461 sec)
25.296... logprob:  0.355666, 0.085938 (1.423 sec)
25.297... logprob:  0.394469, 0.101562 (1.425 sec)
25.298... logprob:  0.448206, 0.125000 (1.522 sec)
25.299... logprob:  0.342136, 0.078125 (1.407 sec)
25.300... logprob:  0.406453, 0.101562 (1.423 sec)
25.301... logprob:  0.397907, 0.101562 (1.421 sec)
25.302... logprob:  0.591566, 0.179688 (1.415 sec)
25.303... logprob:  0.459525, 0.125000 (1.421 sec)
25.304... logprob:  0.459639, 0.125000 (1.444 sec)
25.305... logprob:  0.455205, 0.125000 (1.437 sec)
25.306... logprob:  0.440583, 0.117188 (1.435 sec)
25.307... logprob:  0.421618, 0.109375 (1.445 sec)
25.308... logprob:  0.374759, 0.093750 (1.455 sec)
25.309... logprob:  0.450481, 0.125000 (1.417 sec)
25.310... logprob:  0.473632, 0.125000 (1.423 sec)
25.311... logprob:  0.502519, 0.140625 (1.425 sec)
25.312... logprob:  0.478708, 0.132812 (1.434 sec)
25.313... logprob:  0.454861, 0.125000 (1.424 sec)
25.314... logprob:  0.454395, 0.117188 (1.469 sec)
25.315... logprob:  0.314675, 0.070312 (1.432 sec)
25.316... logprob:  0.468529, 0.125000 (1.430 sec)
25.317... logprob:  0.355450, 0.085938 (1.473 sec)
25.318... logprob:  0.455406, 0.125000 (1.418 sec)
25.319... logprob:  0.423178, 0.117188 (1.435 sec)
25.320... logprob:  0.412241, 0.109375 (1.426 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.47347640991211, 10.0]}, 128)
batch 872: ({'logprob': [66.5528793334961, 19.0]}, 128)
batch 873: ({'logprob': [40.62229919433594, 9.0]}, 128)
batch 874: ({'logprob': [45.1341667175293, 11.0]}, 128)
batch 875: ({'logprob': [50.75368881225586, 13.0]}, 128)
batch 876: ({'logprob': [64.0428695678711, 18.0]}, 128)
batch 877: ({'logprob': [45.69730758666992, 11.0]}, 128)
batch 878: ({'logprob': [62.04353713989258, 17.0]}, 128)
batch 879: ({'logprob': [73.8470230102539, 21.0]}, 128)
batch 880: ({'logprob': [50.776798248291016, 13.0]}, 128)
batch 881: ({'logprob': [28.781816482543945, 5.0]}, 128)
batch 882: ({'logprob': [54.98060607910156, 14.0]}, 128)
batch 883: ({'logprob': [62.01942825317383, 17.0]}, 128)
batch 884: ({'logprob': [51.3171272277832, 13.0]}, 128)
batch 885: ({'logprob': [52.4285774230957, 13.0]}, 128)
batch 886: ({'logprob': [62.59450149536133, 17.0]}, 128)

======================Test output======================
logprob:  0.416536, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.963079e-03 [2.259395e-09] 
Layer 'conv1' biases: 2.938223e-07 [3.671332e-11] 
Layer 'conv2' weights[0]: 7.950143e-03 [1.745301e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.708253e-10] 
Layer 'conv3' weights[0]: 7.948340e-03 [1.343029e-09] 
Layer 'conv3' biases: 2.502861e-06 [4.997851e-10] 
Layer 'conv4' weights[0]: 7.981021e-03 [1.448929e-09] 
Layer 'conv4' biases: 9.999993e-01 [3.862234e-09] 
Layer 'conv5' weights[0]: 7.979820e-03 [2.453105e-08] 
Layer 'conv5' biases: 9.999934e-01 [2.637044e-08] 
Layer 'fc6' weights[0]: 7.576466e-03 [2.198327e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.052216e-09] 
Layer 'fc7' weights[0]: 7.053834e-03 [1.202879e-07] 
Layer 'fc7' biases: 9.998590e-01 [1.064711e-07] 
Layer 'fc8' weights[0]: 1.305707e-03 [3.793115e-06] 
Layer 'fc8' biases: 6.104843e-02 [2.650725e-05] 
Train error last 870 batches: 0.435211
-------------------------------------------------------
Not saving because 0.416536 > 0.415666 (22.630: -0.00%)
======================================================= (12.089 sec)
25.321... logprob:  0.348253, 0.085938 (1.448 sec)
25.322... logprob:  0.387460, 0.101562 (1.419 sec)
25.323... logprob:  0.416509, 0.109375 (1.478 sec)
25.324... logprob:  0.498605, 0.140625 (1.426 sec)
25.325... logprob:  0.350677, 0.085938 (1.438 sec)
25.326... logprob:  0.543180, 0.148438 (1.462 sec)
25.327... logprob:  0.554406, 0.164062 (1.427 sec)
25.328... logprob:  0.565095, 0.156250 (1.423 sec)
25.329... logprob:  0.401938, 0.101562 (1.429 sec)
25.330... logprob:  0.388550, 0.101562 (1.422 sec)
25.331... logprob:  0.352341, 0.085938 (1.418 sec)
25.332... logprob:  0.482781, 0.132812 (1.452 sec)
25.333... logprob:  0.339524, 0.085938 (1.446 sec)
25.334... logprob:  0.565234, 0.171875 (1.439 sec)
25.335... logprob:  0.358739, 0.085938 (1.442 sec)
25.336... logprob:  0.444851, 0.125000 (1.458 sec)
25.337... logprob:  0.566423, 0.164062 (1.428 sec)
25.338... logprob:  0.449514, 0.125000 (1.421 sec)
25.339... logprob:  0.488621, 0.132812 (1.429 sec)
25.340... logprob:  0.442068, 0.117188 (1.434 sec)
25.341... logprob:  0.530062, 0.148438 (1.421 sec)
25.342... logprob:  0.429624, 0.109375 (1.467 sec)
25.343... logprob:  0.434770, 0.109375 (1.443 sec)
25.344... logprob:  0.444493, 0.125000 (1.482 sec)
25.345... logprob:  0.488209, 0.132812 (1.438 sec)
25.346... logprob:  0.436216, 0.117188 (1.441 sec)
25.347... logprob:  0.372483, 0.085938 (1.485 sec)
25.348... logprob:  0.398469, 0.101562 (1.435 sec)
25.349... logprob:  0.497678, 0.140625 (1.433 sec)
25.350... logprob:  0.358658, 0.085938 (1.435 sec)
25.351... logprob:  0.508543, 0.140625 (1.427 sec)
25.352... logprob:  0.363625, 0.093750 (1.435 sec)
25.353... logprob:  0.512555, 0.148438 (1.492 sec)
25.354... logprob:  0.674900, 0.203125 (1.427 sec)
25.355... logprob:  0.357490, 0.085938 (1.445 sec)
25.356... logprob:  0.479241, 0.132812 (1.480 sec)
25.357... logprob:  0.346823, 0.085938 (1.431 sec)
25.358... logprob:  0.325833, 0.070312 (1.438 sec)
25.359... logprob:  0.555330, 0.164062 (1.454 sec)
25.360... logprob:  0.444519, 0.117188 (1.433 sec)
25.361... logprob:  0.410746, 0.101562 (1.440 sec)
25.362... logprob:  0.424001, 0.117188 (1.476 sec)
25.363... logprob:  0.486586, 0.132812 (1.443 sec)
25.364... logprob:  0.475589, 0.125000 (1.458 sec)
25.365... logprob:  0.425053, 0.109375 (1.465 sec)
25.366... logprob:  0.409607, 0.109375 (1.441 sec)
25.367... logprob:  0.324933, 0.078125 (1.438 sec)
25.368... logprob:  0.595591, 0.171875 (1.427 sec)
25.369... logprob:  0.381624, 0.093750 (1.430 sec)
25.370... logprob:  0.381255, 0.093750 (1.438 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.83359146118164, 10.0]}, 128)
batch 872: ({'logprob': [66.49657440185547, 19.0]}, 128)
batch 873: ({'logprob': [40.65876388549805, 9.0]}, 128)
batch 874: ({'logprob': [45.280975341796875, 11.0]}, 128)
batch 875: ({'logprob': [50.795936584472656, 13.0]}, 128)
batch 876: ({'logprob': [63.98532485961914, 18.0]}, 128)
batch 877: ({'logprob': [45.737178802490234, 11.0]}, 128)
batch 878: ({'logprob': [61.8773193359375, 17.0]}, 128)
batch 879: ({'logprob': [73.36520385742188, 21.0]}, 128)
batch 880: ({'logprob': [50.819549560546875, 13.0]}, 128)
batch 881: ({'logprob': [29.134544372558594, 5.0]}, 128)
batch 882: ({'logprob': [54.7025032043457, 14.0]}, 128)
batch 883: ({'logprob': [61.85282897949219, 17.0]}, 128)
batch 884: ({'logprob': [51.251930236816406, 13.0]}, 128)
batch 885: ({'logprob': [52.148719787597656, 13.0]}, 128)
batch 886: ({'logprob': [62.320701599121094, 17.0]}, 128)

======================Test output======================
logprob:  0.416143, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.963036e-03 [2.751476e-09] 
Layer 'conv1' biases: 2.947296e-07 [6.513304e-11] 
Layer 'conv2' weights[0]: 7.950102e-03 [2.233963e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.406289e-10] 
Layer 'conv3' weights[0]: 7.948301e-03 [2.072573e-09] 
Layer 'conv3' biases: 2.511054e-06 [1.076723e-09] 
Layer 'conv4' weights[0]: 7.980981e-03 [2.079303e-09] 
Layer 'conv4' biases: 9.999993e-01 [8.913830e-09] 
Layer 'conv5' weights[0]: 7.979787e-03 [5.363409e-08] 
Layer 'conv5' biases: 9.999935e-01 [5.782961e-08] 
Layer 'fc6' weights[0]: 7.576422e-03 [4.562051e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.546316e-09] 
Layer 'fc7' weights[0]: 7.052017e-03 [1.057717e-07] 
Layer 'fc7' biases: 9.998589e-01 [9.142707e-08] 
Layer 'fc8' weights[0]: 1.299950e-03 [6.605412e-06] 
Layer 'fc8' biases: 6.110433e-02 [4.479589e-05] 
Train error last 870 batches: 0.435211
-------------------------------------------------------
Not saving because 0.416143 > 0.415666 (22.630: -0.00%)
======================================================= (12.042 sec)
25.371... logprob:  0.400400, 0.101562 (1.463 sec)
25.372... logprob:  0.537341, 0.156250 (1.456 sec)
25.373... logprob:  0.463799, 0.125000 (1.458 sec)
25.374... logprob:  0.526895, 0.148438 (1.457 sec)
25.375... logprob:  0.393771, 0.101562 (1.468 sec)
25.376... logprob:  0.374294, 0.093750 (1.439 sec)
25.377... logprob:  0.295415, 0.062500 (1.429 sec)
25.378... logprob:  0.453696, 0.125000 (1.428 sec)
25.379... logprob:  0.420241, 0.109375 (1.444 sec)
25.380... logprob:  0.605702, 0.179688 (1.437 sec)
25.381... logprob:  0.463432, 0.125000 (1.476 sec)
25.382... logprob:  0.529558, 0.148438 (1.448 sec)
25.383... logprob:  0.358576, 0.085938 (1.446 sec)
25.384... logprob:  0.521165, 0.148438 (1.477 sec)
25.385... logprob:  0.523550, 0.148438 (1.435 sec)
25.386... logprob:  0.582508, 0.171875 (1.433 sec)
25.387... logprob:  0.428559, 0.117188 (1.434 sec)
25.388... logprob:  0.521357, 0.148438 (1.442 sec)
25.389... logprob:  0.425669, 0.109375 (1.431 sec)
25.390... logprob:  0.419747, 0.109375 (1.483 sec)
25.391... logprob:  0.318220, 0.070312 (1.440 sec)
25.392... logprob:  0.439445, 0.117188 (1.456 sec)
25.393... logprob:  0.368975, 0.093750 (1.496 sec)
25.394... logprob:  0.343641, 0.078125 (1.436 sec)
25.395... logprob:  0.331800, 0.078125 (1.433 sec)
25.396... logprob:  0.252371, 0.046875 (1.439 sec)
25.397... logprob:  0.484280, 0.132812 (1.429 sec)
25.398... logprob:  0.470894, 0.125000 (1.439 sec)
25.399... logprob:  0.433325, 0.117188 (1.483 sec)
25.400... logprob:  0.537776, 0.148438 (1.438 sec)
25.401... logprob:  0.465798, 0.125000 (1.441 sec)
25.402... logprob:  0.473957, 0.125000 (1.491 sec)
25.403... logprob:  0.462141, 0.125000 (1.436 sec)
25.404... logprob:  0.474817, 0.125000 (1.436 sec)
25.405... logprob:  0.544148, 0.156250 (1.435 sec)
25.406... logprob:  0.357648, 0.085938 (1.432 sec)
25.407... logprob:  0.492927, 0.140625 (1.433 sec)
25.408... logprob:  0.339113, 0.078125 (1.483 sec)
25.409... logprob:  0.400577, 0.101562 (1.443 sec)
25.410... logprob:  0.582133, 0.171875 (1.450 sec)
25.411... logprob:  0.397896, 0.101562 (1.476 sec)
25.412... logprob:  0.540284, 0.156250 (1.435 sec)
25.413... logprob:  0.544670, 0.156250 (1.444 sec)
25.414... logprob:  0.466453, 0.125000 (1.430 sec)
25.415... logprob:  0.401699, 0.101562 (1.429 sec)
25.416... logprob:  0.427520, 0.109375 (1.511 sec)
25.417... logprob:  0.405458, 0.093750 (1.470 sec)
25.418... logprob:  0.380351, 0.093750 (1.451 sec)
25.419... logprob:  0.417784, 0.101562 (1.453 sec)
25.420... logprob:  0.356298, 0.085938 (1.457 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.68427276611328, 10.0]}, 128)
batch 872: ({'logprob': [66.43563842773438, 19.0]}, 128)
batch 873: ({'logprob': [40.73622131347656, 9.0]}, 128)
batch 874: ({'logprob': [45.248268127441406, 11.0]}, 128)
batch 875: ({'logprob': [50.790855407714844, 13.0]}, 128)
batch 876: ({'logprob': [63.94480895996094, 18.0]}, 128)
batch 877: ({'logprob': [45.773155212402344, 11.0]}, 128)
batch 878: ({'logprob': [61.92644500732422, 17.0]}, 128)
batch 879: ({'logprob': [73.53721618652344, 21.0]}, 128)
batch 880: ({'logprob': [50.814029693603516, 13.0]}, 128)
batch 881: ({'logprob': [29.089019775390625, 5.0]}, 128)
batch 882: ({'logprob': [54.882476806640625, 14.0]}, 128)
batch 883: ({'logprob': [61.90223693847656, 17.0]}, 128)
batch 884: ({'logprob': [51.31538009643555, 13.0]}, 128)
batch 885: ({'logprob': [52.34957504272461, 13.0]}, 128)
batch 886: ({'logprob': [62.438499450683594, 17.0]}, 128)

======================Test output======================
logprob:  0.416440, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.962995e-03 [3.804433e-09] 
Layer 'conv1' biases: 2.956654e-07 [1.827801e-10] 
Layer 'conv2' weights[0]: 7.950056e-03 [4.378520e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.988837e-10] 
Layer 'conv3' weights[0]: 7.948263e-03 [4.417604e-09] 
Layer 'conv3' biases: 2.515316e-06 [2.688436e-09] 
Layer 'conv4' weights[0]: 7.980942e-03 [4.388459e-09] 
Layer 'conv4' biases: 9.999993e-01 [2.323551e-08] 
Layer 'conv5' weights[0]: 7.979716e-03 [1.466254e-07] 
Layer 'conv5' biases: 9.999931e-01 [1.581142e-07] 
Layer 'fc6' weights[0]: 7.576382e-03 [1.208247e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.237485e-08] 
Layer 'fc7' weights[0]: 7.050204e-03 [4.072603e-07] 
Layer 'fc7' biases: 9.998589e-01 [3.960226e-07] 
Layer 'fc8' weights[0]: 1.295429e-03 [1.802200e-05] 
Layer 'fc8' biases: 6.134843e-02 [1.268963e-04] 
Train error last 870 batches: 0.435210
-------------------------------------------------------
Not saving because 0.416440 > 0.415666 (22.630: -0.00%)
======================================================= (12.065 sec)
25.421... logprob:  0.376613, 0.101562 (1.466 sec)
25.422... logprob:  0.522389, 0.148438 (1.448 sec)
25.423... logprob:  0.420871, 0.109375 (1.432 sec)
25.424... logprob:  0.324811, 0.078125 (1.431 sec)
25.425... logprob:  0.306384, 0.070312 (1.465 sec)
25.426... logprob:  0.449153, 0.117188 (1.451 sec)
25.427... logprob:  0.554366, 0.156250 (1.461 sec)
25.428... logprob:  0.601816, 0.171875 (1.459 sec)
25.429... logprob:  0.426330, 0.109375 (1.442 sec)
25.430... logprob:  0.299829, 0.070312 (1.478 sec)
25.431... logprob:  0.599818, 0.171875 (1.433 sec)
25.432... logprob:  0.387542, 0.093750 (1.429 sec)
25.433... logprob:  0.329814, 0.078125 (1.440 sec)
25.434... logprob:  0.529463, 0.148438 (1.434 sec)
25.435... logprob:  0.532367, 0.156250 (1.440 sec)
25.436... logprob:  0.381145, 0.093750 (1.478 sec)
25.437... logprob:  0.500292, 0.140625 (1.442 sec)
25.438... logprob:  0.546918, 0.156250 (1.437 sec)
25.439... logprob:  0.378799, 0.093750 (1.488 sec)
25.440... logprob:  0.439735, 0.117188 (1.438 sec)
25.441... logprob:  0.467984, 0.125000 (1.428 sec)
25.442... logprob:  0.378937, 0.093750 (1.438 sec)
25.443... logprob:  0.496568, 0.140625 (1.432 sec)
25.444... logprob:  0.372315, 0.093750 (1.438 sec)
25.445... logprob:  0.362481, 0.085938 (1.484 sec)
25.446... logprob:  0.398294, 0.101562 (1.442 sec)
25.447... logprob:  0.569792, 0.164062 (1.440 sec)
25.448... logprob:  0.332837, 0.078125 (1.483 sec)
25.449... logprob:  0.400033, 0.101562 (1.432 sec)
25.450... logprob:  0.239422, 0.046875 (1.438 sec)
25.451... logprob:  0.452695, 0.125000 (1.436 sec)
25.452... logprob:  0.456130, 0.117188 (1.431 sec)
25.453... logprob:  0.455251, 0.125000 (1.436 sec)
25.454... logprob:  0.489018, 0.132812 (1.484 sec)
25.455... logprob:  0.506073, 0.140625 (1.447 sec)
25.456... logprob:  0.468836, 0.125000 (1.446 sec)
25.457... logprob:  0.375343, 0.093750 (1.479 sec)
25.458... logprob:  0.351049, 0.085938 (1.436 sec)
25.459... logprob:  0.513930, 0.140625 (1.448 sec)
25.460... logprob:  0.273989, 0.054688 (1.434 sec)
25.461... logprob:  0.460078, 0.125000 (1.425 sec)
25.462... logprob:  0.471959, 0.125000 (1.437 sec)
25.463... logprob:  0.420853, 0.109375 (1.473 sec)
25.464... logprob:  0.482753, 0.132812 (1.449 sec)
25.465... logprob:  0.421143, 0.109375 (1.455 sec)
25.466... logprob:  0.318412, 0.070312 (1.486 sec)
25.467... logprob:  0.413844, 0.109375 (1.449 sec)
25.468... logprob:  0.394267, 0.101562 (1.447 sec)
25.469... logprob:  0.334752, 0.078125 (1.425 sec)
25.470... logprob:  0.400086, 0.101562 (1.423 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.55038833618164, 10.0]}, 128)
batch 872: ({'logprob': [66.86676025390625, 19.0]}, 128)
batch 873: ({'logprob': [40.2629508972168, 9.0]}, 128)
batch 874: ({'logprob': [45.052547454833984, 11.0]}, 128)
batch 875: ({'logprob': [50.71092987060547, 13.0]}, 128)
batch 876: ({'logprob': [64.27796936035156, 18.0]}, 128)
batch 877: ({'logprob': [45.49644470214844, 11.0]}, 128)
batch 878: ({'logprob': [62.080108642578125, 17.0]}, 128)
batch 879: ({'logprob': [73.84430694580078, 21.0]}, 128)
batch 880: ({'logprob': [50.7345085144043, 13.0]}, 128)
batch 881: ({'logprob': [28.46209716796875, 5.0]}, 128)
batch 882: ({'logprob': [54.66095733642578, 14.0]}, 128)
batch 883: ({'logprob': [62.055755615234375, 17.0]}, 128)
batch 884: ({'logprob': [51.156368255615234, 13.0]}, 128)
batch 885: ({'logprob': [52.0298957824707, 13.0]}, 128)
batch 886: ({'logprob': [62.51237487792969, 17.0]}, 128)

======================Test output======================
logprob:  0.415896, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.962959e-03 [3.296628e-09] 
Layer 'conv1' biases: 2.965549e-07 [1.038890e-10] 
Layer 'conv2' weights[0]: 7.950017e-03 [2.870455e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.139905e-10] 
Layer 'conv3' weights[0]: 7.948221e-03 [2.710166e-09] 
Layer 'conv3' biases: 2.523730e-06 [1.495533e-09] 
Layer 'conv4' weights[0]: 7.980904e-03 [2.853324e-09] 
Layer 'conv4' biases: 9.999993e-01 [1.302918e-08] 
Layer 'conv5' weights[0]: 7.979681e-03 [8.354241e-08] 
Layer 'conv5' biases: 9.999932e-01 [8.989480e-08] 
Layer 'fc6' weights[0]: 7.576342e-03 [6.955799e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.059596e-09] 
Layer 'fc7' weights[0]: 7.048404e-03 [2.337613e-07] 
Layer 'fc7' biases: 9.998592e-01 [2.226212e-07] 
Layer 'fc8' weights[0]: 1.303643e-03 [8.837063e-06] 
Layer 'fc8' biases: 6.172292e-02 [6.131546e-05] 
Train error last 870 batches: 0.435210
-------------------------------------------------------
Not saving because 0.415896 > 0.415666 (22.630: -0.00%)
======================================================= (12.074 sec)
25.471... logprob:  0.529352, 0.148438 (1.453 sec)
25.472... logprob:  0.410012, 0.109375 (1.458 sec)
25.473... logprob:  0.375428, 0.093750 (1.459 sec)
25.474... logprob:  0.465614, 0.125000 (1.453 sec)
25.475... logprob:  0.504083, 0.140625 (1.452 sec)
25.476... logprob:  0.510273, 0.140625 (1.472 sec)
25.477... logprob:  0.334591, 0.078125 (1.436 sec)
25.478... logprob:  0.464253, 0.125000 (1.427 sec)
25.479... logprob:  0.305773, 0.070312 (1.433 sec)
25.480... logprob:  0.443509, 0.117188 (1.442 sec)
25.481... logprob:  0.547796, 0.156250 (1.438 sec)
25.482... logprob:  0.443151, 0.117188 (1.474 sec)
25.483... logprob:  0.502659, 0.140625 (1.450 sec)
25.484... logprob:  0.485309, 0.132812 (1.438 sec)
25.485... logprob:  0.408979, 0.109375 (1.484 sec)
25.486... logprob:  0.361391, 0.085938 (1.437 sec)
25.487... logprob:  0.522668, 0.148438 (1.428 sec)
25.488... logprob:  0.424770, 0.109375 (1.441 sec)
25.489... logprob:  0.415866, 0.109375 (1.433 sec)
25.490... logprob:  0.440693, 0.117188 (1.437 sec)
25.491... logprob:  0.313646, 0.070312 (1.477 sec)
25.492... logprob:  0.459552, 0.125000 (1.446 sec)
25.493... logprob:  0.521848, 0.148438 (1.438 sec)
25.494... logprob:  0.450355, 0.125000 (1.486 sec)
25.495... logprob:  0.380642, 0.093750 (1.433 sec)
25.496... logprob:  0.550310, 0.156250 (1.435 sec)
25.497... logprob:  0.466943, 0.125000 (1.438 sec)
25.498... logprob:  0.476254, 0.132812 (1.432 sec)
25.499... logprob:  0.456241, 0.125000 (1.454 sec)
25.500... logprob:  0.355130, 0.085938 (1.487 sec)
25.501... logprob:  0.339120, 0.078125 (1.434 sec)
25.502... logprob:  0.459622, 0.125000 (1.447 sec)
25.503... logprob:  0.400670, 0.101562 (1.478 sec)
25.504... logprob:  0.487301, 0.132812 (1.431 sec)
25.505... logprob:  0.570787, 0.164062 (1.444 sec)
25.506... logprob:  0.479685, 0.132812 (1.431 sec)
25.507... logprob:  0.385063, 0.093750 (1.433 sec)
25.508... logprob:  0.374688, 0.093750 (1.433 sec)
25.509... logprob:  0.323066, 0.070312 (1.476 sec)
25.510... logprob:  0.390465, 0.101562 (1.444 sec)
25.511... logprob:  0.410056, 0.109375 (1.457 sec)
25.512... logprob:  0.470724, 0.125000 (1.463 sec)
25.513... logprob:  0.324965, 0.078125 (1.449 sec)
25.514... logprob:  0.406273, 0.101562 (1.436 sec)
25.515... logprob:  0.455507, 0.125000 (1.438 sec)
25.516... logprob:  0.400310, 0.109375 (1.423 sec)
25.517... logprob:  0.627835, 0.179688 (1.437 sec)
25.518... logprob:  0.437666, 0.117188 (1.458 sec)
25.519... logprob:  0.516134, 0.140625 (1.453 sec)
25.520... logprob:  0.409647, 0.109375 (1.455 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.94217300415039, 10.0]}, 128)
batch 872: ({'logprob': [66.39088439941406, 19.0]}, 128)
batch 873: ({'logprob': [40.80270767211914, 9.0]}, 128)
batch 874: ({'logprob': [45.37098693847656, 11.0]}, 128)
batch 875: ({'logprob': [50.83903121948242, 13.0]}, 128)
batch 876: ({'logprob': [63.90471649169922, 18.0]}, 128)
batch 877: ({'logprob': [45.830772399902344, 11.0]}, 128)
batch 878: ({'logprob': [61.82582473754883, 17.0]}, 128)
batch 879: ({'logprob': [73.22274780273438, 21.0]}, 128)
batch 880: ({'logprob': [50.86238479614258, 13.0]}, 128)
batch 881: ({'logprob': [29.369916915893555, 5.0]}, 128)
batch 882: ({'logprob': [54.73023986816406, 14.0]}, 128)
batch 883: ({'logprob': [61.801517486572266, 17.0]}, 128)
batch 884: ({'logprob': [51.298095703125, 13.0]}, 128)
batch 885: ({'logprob': [52.201805114746094, 13.0]}, 128)
batch 886: ({'logprob': [62.272430419921875, 17.0]}, 128)

======================Test output======================
logprob:  0.416341, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.962920e-03 [3.315903e-09] 
Layer 'conv1' biases: 2.975837e-07 [7.490843e-11] 
Layer 'conv2' weights[0]: 7.949975e-03 [2.757818e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.233396e-10] 
Layer 'conv3' weights[0]: 7.948172e-03 [2.217874e-09] 
Layer 'conv3' biases: 2.536658e-06 [1.271312e-09] 
Layer 'conv4' weights[0]: 7.980859e-03 [2.195848e-09] 
Layer 'conv4' biases: 9.999993e-01 [9.677717e-09] 
Layer 'conv5' weights[0]: 7.979687e-03 [6.078942e-08] 
Layer 'conv5' biases: 9.999937e-01 [6.554652e-08] 
Layer 'fc6' weights[0]: 7.576293e-03 [5.130914e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.171303e-09] 
Layer 'fc7' weights[0]: 7.046667e-03 [2.365670e-07] 
Layer 'fc7' biases: 9.998587e-01 [2.264422e-07] 
Layer 'fc8' weights[0]: 1.286249e-03 [9.031506e-06] 
Layer 'fc8' biases: 6.168050e-02 [5.733761e-05] 
Train error last 870 batches: 0.435210
-------------------------------------------------------
Not saving because 0.416341 > 0.415666 (22.630: -0.00%)
======================================================= (12.075 sec)
25.521... logprob:  0.427458, 0.109375 (1.465 sec)
25.522... logprob:  0.533133, 0.156250 (1.465 sec)
25.523... logprob:  0.331585, 0.078125 (1.439 sec)
25.524... logprob:  0.437174, 0.117188 (1.424 sec)
25.525... logprob:  0.425960, 0.109375 (1.437 sec)
25.526... logprob:  0.351757, 0.078125 (1.438 sec)
25.527... logprob:  0.504567, 0.140625 (1.445 sec)
25.528... logprob:  0.440474, 0.117188 (1.467 sec)
25.529... logprob:  0.353004, 0.085938 (1.453 sec)
25.530... logprob:  0.440251, 0.117188 (1.442 sec)
25.531... logprob:  0.439970, 0.117188 (1.481 sec)
25.532... logprob:  0.467341, 0.125000 (1.460 sec)
25.533... logprob:  0.560446, 0.164062 (1.429 sec)
25.534... logprob:  0.325888, 0.078125 (1.436 sec)
25.535... logprob:  0.551513, 0.156250 (1.434 sec)
25.536... logprob:  0.507311, 0.140625 (1.427 sec)
25.537... logprob:  0.510026, 0.140625 (1.482 sec)
25.538... logprob:  0.486092, 0.132812 (1.445 sec)
25.539... logprob:  0.296064, 0.062500 (1.437 sec)
25.540... logprob:  0.447177, 0.117188 (1.488 sec)
25.541... logprob:  0.388821, 0.101562 (1.431 sec)
25.542... logprob:  0.411261, 0.109375 (1.433 sec)
25.543... logprob:  0.233266, 0.039062 (1.440 sec)
25.544... logprob:  0.317928, 0.070312 (1.434 sec)
25.545... logprob:  0.348802, 0.085938 (1.433 sec)
25.546... logprob:  0.368276, 0.093750 (1.488 sec)
25.547... logprob:  0.440056, 0.117188 (1.437 sec)
25.548... logprob:  0.452980, 0.125000 (1.441 sec)
25.549... logprob:  0.490521, 0.132812 (1.485 sec)
25.550... logprob:  0.367635, 0.093750 (1.439 sec)
25.551... logprob:  0.441683, 0.117188 (1.437 sec)
25.552... logprob:  0.471280, 0.125000 (1.436 sec)
25.553... logprob:  0.349445, 0.085938 (1.433 sec)
25.554... logprob:  0.506938, 0.140625 (1.432 sec)
25.555... logprob:  0.421409, 0.109375 (1.486 sec)
25.556... logprob:  0.355832, 0.085938 (1.442 sec)
25.557... logprob:  0.396401, 0.101562 (1.457 sec)
25.558... logprob:  0.383022, 0.101562 (1.471 sec)
25.559... logprob:  0.441557, 0.125000 (1.441 sec)
25.560... logprob:  0.335140, 0.078125 (1.437 sec)
25.561... logprob:  0.411807, 0.109375 (1.436 sec)
25.562... logprob:  0.503142, 0.140625 (1.424 sec)
25.563... logprob:  0.373795, 0.093750 (1.435 sec)
25.564... logprob:  0.468463, 0.132812 (1.463 sec)
25.565... logprob:  0.611107, 0.187500 (1.452 sec)
25.566... logprob:  0.374886, 0.093750 (1.456 sec)
25.567... logprob:  0.423354, 0.109375 (1.458 sec)
25.568... logprob:  0.496343, 0.140625 (1.456 sec)
25.569... logprob:  0.507747, 0.140625 (1.441 sec)
25.570... logprob:  0.543764, 0.164062 (1.428 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.510501861572266, 10.0]}, 128)
batch 872: ({'logprob': [65.69352722167969, 19.0]}, 128)
batch 873: ({'logprob': [42.509403228759766, 9.0]}, 128)
batch 874: ({'logprob': [46.24843215942383, 11.0]}, 128)
batch 875: ({'logprob': [51.47019958496094, 13.0]}, 128)
batch 876: ({'logprob': [63.4749641418457, 18.0]}, 128)
batch 877: ({'logprob': [46.99952697753906, 11.0]}, 128)
batch 878: ({'logprob': [61.957366943359375, 17.0]}, 128)
batch 879: ({'logprob': [73.14391326904297, 21.0]}, 128)
batch 880: ({'logprob': [51.49162292480469, 13.0]}, 128)
batch 881: ({'logprob': [31.287172317504883, 5.0]}, 128)
batch 882: ({'logprob': [55.95811462402344, 14.0]}, 128)
batch 883: ({'logprob': [61.9339714050293, 17.0]}, 128)
batch 884: ({'logprob': [52.215179443359375, 13.0]}, 128)
batch 885: ({'logprob': [53.6986198425293, 13.0]}, 128)
batch 886: ({'logprob': [62.69211959838867, 17.0]}, 128)

======================Test output======================
logprob:  0.421526, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.962878e-03 [3.144694e-09] 
Layer 'conv1' biases: 2.985769e-07 [7.460176e-11] 
Layer 'conv2' weights[0]: 7.949936e-03 [2.874447e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.090650e-10] 
Layer 'conv3' weights[0]: 7.948144e-03 [2.649623e-09] 
Layer 'conv3' biases: 2.545009e-06 [1.585329e-09] 
Layer 'conv4' weights[0]: 7.980817e-03 [2.625125e-09] 
Layer 'conv4' biases: 9.999993e-01 [1.297215e-08] 
Layer 'conv5' weights[0]: 7.979640e-03 [8.264256e-08] 
Layer 'conv5' biases: 9.999934e-01 [8.889640e-08] 
Layer 'fc6' weights[0]: 7.576253e-03 [6.865806e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.977988e-09] 
Layer 'fc7' weights[0]: 7.044891e-03 [1.798872e-07] 
Layer 'fc7' biases: 9.998582e-01 [1.699334e-07] 
Layer 'fc8' weights[0]: 1.256981e-03 [7.378776e-06] 
Layer 'fc8' biases: 6.158062e-02 [4.758536e-05] 
Train error last 870 batches: 0.435209
-------------------------------------------------------
Not saving because 0.421526 > 0.415666 (22.630: -0.00%)
======================================================= (12.069 sec)
25.571... logprob:  0.454881, 0.125000 (1.442 sec)
25.572... logprob:  0.501407, 0.140625 (1.448 sec)
25.573... logprob:  0.512606, 0.148438 (1.446 sec)
25.574... logprob:  0.428072, 0.109375 (1.463 sec)
25.575... logprob:  0.343336, 0.078125 (1.456 sec)
25.576... logprob:  0.427373, 0.109375 (1.444 sec)
25.577... logprob:  0.460806, 0.125000 (1.479 sec)
25.578... logprob:  0.336703, 0.078125 (1.433 sec)
25.579... logprob:  0.442081, 0.117188 (1.431 sec)
25.580... logprob:  0.546753, 0.156250 (1.430 sec)
25.581... logprob:  0.530770, 0.156250 (1.443 sec)
25.582... logprob:  0.437835, 0.125000 (1.435 sec)
25.583... logprob:  0.592588, 0.171875 (1.481 sec)
25.584... logprob:  0.468091, 0.132812 (1.444 sec)
25.585... logprob:  0.349764, 0.085938 (1.438 sec)
25.586... logprob:  0.313095, 0.070312 (1.485 sec)
25.587... logprob:  0.404302, 0.101562 (1.439 sec)
25.588... logprob:  0.418662, 0.117188 (1.429 sec)
25.589... logprob:  0.361207, 0.093750 (1.434 sec)
25.590... logprob:  0.524746, 0.148438 (1.440 sec)
25.591... logprob:  0.397479, 0.101562 (1.432 sec)
25.592... logprob:  0.455665, 0.125000 (1.487 sec)
25.593... logprob:  0.467423, 0.125000 (1.434 sec)
25.594... logprob:  0.352845, 0.085938 (1.447 sec)
25.595... logprob:  0.428662, 0.109375 (1.478 sec)
25.596... logprob:  0.461601, 0.125000 (1.438 sec)
25.597... logprob:  0.397415, 0.101562 (1.436 sec)
25.598... logprob:  0.397222, 0.101562 (1.433 sec)
25.599... logprob:  0.313554, 0.070312 (1.431 sec)
25.600... logprob:  0.340888, 0.085938 (1.437 sec)
25.601... logprob:  0.402141, 0.101562 (1.486 sec)
25.602... logprob:  0.289812, 0.062500 (1.435 sec)
25.603... logprob:  0.267100, 0.054688 (1.453 sec)
25.604... logprob:  0.407519, 0.101562 (1.474 sec)
25.605... logprob:  0.563394, 0.148438 (1.438 sec)
25.606... logprob:  0.295944, 0.070312 (1.453 sec)
25.607... logprob:  0.504774, 0.132812 (1.439 sec)
25.608... logprob:  0.361796, 0.085938 (1.425 sec)
25.609... logprob:  0.356997, 0.085938 (1.436 sec)
25.610... logprob:  0.493344, 0.132812 (1.475 sec)
25.611... logprob:  0.510378, 0.140625 (1.444 sec)
25.612... logprob:  0.448478, 0.117188 (1.457 sec)
25.613... logprob:  0.279513, 0.062500 (1.461 sec)
25.614... logprob:  0.503553, 0.140625 (1.455 sec)
25.615... logprob:  0.350944, 0.085938 (1.439 sec)
25.616... logprob:  0.415165, 0.109375 (1.431 sec)
25.617... logprob:  0.417882, 0.109375 (1.426 sec)
25.618... logprob:  0.546901, 0.156250 (1.444 sec)
25.619... logprob:  0.506048, 0.140625 (1.460 sec)
25.620... logprob:  0.539671, 0.156250 (1.456 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.29050064086914, 10.0]}, 128)
batch 872: ({'logprob': [66.22547149658203, 19.0]}, 128)
batch 873: ({'logprob': [41.71760940551758, 9.0]}, 128)
batch 874: ({'logprob': [46.2789421081543, 11.0]}, 128)
batch 875: ({'logprob': [51.39211654663086, 13.0]}, 128)
batch 876: ({'logprob': [63.82941818237305, 18.0]}, 128)
batch 877: ({'logprob': [46.56576919555664, 11.0]}, 128)
batch 878: ({'logprob': [61.667510986328125, 17.0]}, 128)
batch 879: ({'logprob': [72.17967987060547, 21.0]}, 128)
batch 880: ({'logprob': [51.41543960571289, 13.0]}, 128)
batch 881: ({'logprob': [31.17160987854004, 5.0]}, 128)
batch 882: ({'logprob': [54.668060302734375, 14.0]}, 128)
batch 883: ({'logprob': [61.64319610595703, 17.0]}, 128)
batch 884: ({'logprob': [51.67447280883789, 13.0]}, 128)
batch 885: ({'logprob': [52.22901916503906, 13.0]}, 128)
batch 886: ({'logprob': [61.938270568847656, 17.0]}, 128)

======================Test output======================
logprob:  0.418890, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.962838e-03 [5.320066e-09] 
Layer 'conv1' biases: 2.996182e-07 [9.244490e-11] 
Layer 'conv2' weights[0]: 7.949903e-03 [3.905920e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.762420e-10] 
Layer 'conv3' weights[0]: 7.948114e-03 [3.220984e-09] 
Layer 'conv3' biases: 2.553970e-06 [1.844466e-09] 
Layer 'conv4' weights[0]: 7.980774e-03 [3.241150e-09] 
Layer 'conv4' biases: 9.999993e-01 [1.471545e-08] 
Layer 'conv5' weights[0]: 7.979619e-03 [9.442910e-08] 
Layer 'conv5' biases: 9.999937e-01 [1.015683e-07] 
Layer 'fc6' weights[0]: 7.576214e-03 [7.828824e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.934506e-09] 
Layer 'fc7' weights[0]: 7.043110e-03 [2.824427e-07] 
Layer 'fc7' biases: 9.998576e-01 [2.733574e-07] 
Layer 'fc8' weights[0]: 1.261195e-03 [9.855152e-06] 
Layer 'fc8' biases: 6.178011e-02 [6.472885e-05] 
Train error last 870 batches: 0.435209
-------------------------------------------------------
Not saving because 0.418890 > 0.415666 (22.630: -0.00%)
======================================================= (12.030 sec)
25.621... logprob:  0.363707, 0.085938 (1.457 sec)
25.622... logprob:  0.364775, 0.085938 (1.456 sec)
25.623... logprob:  0.423161, 0.109375 (1.470 sec)
25.624... logprob:  0.382528, 0.093750 (1.435 sec)
25.625... logprob:  0.440989, 0.117188 (1.430 sec)
25.626... logprob:  0.438365, 0.117188 (1.430 sec)
25.627... logprob:  0.435838, 0.117188 (1.444 sec)
25.628... logprob:  0.465046, 0.125000 (1.435 sec)
25.629... logprob:  0.372090, 0.093750 (1.477 sec)
25.630... logprob:  0.422378, 0.109375 (1.450 sec)
25.631... logprob:  0.638755, 0.187500 (1.437 sec)
25.632... logprob:  0.399111, 0.101562 (1.487 sec)
25.633... logprob:  0.376078, 0.093750 (1.433 sec)
25.634... logprob:  0.660222, 0.195312 (1.434 sec)
25.635... logprob:  0.374119, 0.093750 (1.433 sec)
25.636... logprob:  0.480252, 0.132812 (1.441 sec)
25.637... logprob:  0.330813, 0.078125 (1.430 sec)
25.638... logprob:  0.515694, 0.140625 (1.484 sec)
25.639... logprob:  0.418073, 0.109375 (1.464 sec)
25.640... logprob:  0.528753, 0.148438 (1.430 sec)
25.641... logprob:  0.410436, 0.109375 (1.490 sec)
25.642... logprob:  0.500870, 0.140625 (1.432 sec)
25.643... logprob:  0.623113, 0.187500 (1.427 sec)
25.644... logprob:  0.321116, 0.070312 (1.440 sec)
25.645... logprob:  0.414474, 0.109375 (1.428 sec)
25.646... logprob:  0.385642, 0.093750 (1.438 sec)
25.647... logprob:  0.456777, 0.125000 (1.487 sec)
25.648... logprob:  0.491253, 0.140625 (1.450 sec)
25.649... logprob:  0.370241, 0.093750 (1.446 sec)
25.650... logprob:  0.413996, 0.109375 (1.481 sec)
25.651... logprob:  0.397370, 0.101562 (1.430 sec)
25.652... logprob:  0.507193, 0.140625 (1.437 sec)
25.653... logprob:  0.547864, 0.156250 (1.438 sec)
25.654... logprob:  0.496053, 0.140625 (1.435 sec)
25.655... logprob:  0.436188, 0.117188 (1.430 sec)
25.656... logprob:  0.416699, 0.109375 (1.483 sec)
25.657... logprob:  0.449130, 0.117188 (1.443 sec)
25.658... logprob:  0.345837, 0.085938 (1.453 sec)
25.659... logprob:  0.464308, 0.125000 (1.466 sec)
25.660... logprob:  0.445991, 0.125000 (1.448 sec)
25.661... logprob:  0.378456, 0.093750 (1.438 sec)
25.662... logprob:  0.469417, 0.132812 (1.432 sec)
25.663... logprob:  0.310923, 0.070312 (1.429 sec)
25.664... logprob:  0.285404, 0.062500 (1.440 sec)
25.665... logprob:  0.401741, 0.101562 (1.461 sec)
25.666... logprob:  0.442039, 0.117188 (1.452 sec)
25.667... logprob:  0.564241, 0.164062 (1.458 sec)
25.668... logprob:  0.497865, 0.140625 (1.452 sec)
25.669... logprob:  0.432982, 0.109375 (1.466 sec)
25.670... logprob:  0.362404, 0.085938 (1.436 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.1388053894043, 10.0]}, 128)
batch 872: ({'logprob': [66.66477966308594, 19.0]}, 128)
batch 873: ({'logprob': [40.66922378540039, 9.0]}, 128)
batch 874: ({'logprob': [45.04395294189453, 11.0]}, 128)
batch 875: ({'logprob': [50.77663803100586, 13.0]}, 128)
batch 876: ({'logprob': [64.16104888916016, 18.0]}, 128)
batch 877: ({'logprob': [45.7320442199707, 11.0]}, 128)
batch 878: ({'logprob': [62.29283905029297, 17.0]}, 128)
batch 879: ({'logprob': [74.4466781616211, 21.0]}, 128)
batch 880: ({'logprob': [50.79961013793945, 13.0]}, 128)
batch 881: ({'logprob': [28.47735595703125, 5.0]}, 128)
batch 882: ({'logprob': [55.37305450439453, 14.0]}, 128)
batch 883: ({'logprob': [62.26848220825195, 17.0]}, 128)
batch 884: ({'logprob': [51.46577835083008, 13.0]}, 128)
batch 885: ({'logprob': [52.82725524902344, 13.0]}, 128)
batch 886: ({'logprob': [62.9690055847168, 17.0]}, 128)

======================Test output======================
logprob:  0.417532, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.962794e-03 [2.989693e-09] 
Layer 'conv1' biases: 3.005454e-07 [4.299973e-11] 
Layer 'conv2' weights[0]: 7.949868e-03 [1.812617e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.937931e-10] 
Layer 'conv3' weights[0]: 7.948066e-03 [1.362144e-09] 
Layer 'conv3' biases: 2.560006e-06 [5.862893e-10] 
Layer 'conv4' weights[0]: 7.980732e-03 [1.273765e-09] 
Layer 'conv4' biases: 9.999993e-01 [3.823176e-09] 
Layer 'conv5' weights[0]: 7.979545e-03 [2.214926e-08] 
Layer 'conv5' biases: 9.999932e-01 [2.357937e-08] 
Layer 'fc6' weights[0]: 7.576175e-03 [1.990711e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.841235e-09] 
Layer 'fc7' weights[0]: 7.041316e-03 [8.553079e-08] 
Layer 'fc7' biases: 9.998593e-01 [7.170021e-08] 
Layer 'fc8' weights[0]: 1.309529e-03 [2.693859e-06] 
Layer 'fc8' biases: 6.219153e-02 [1.595036e-05] 
Train error last 870 batches: 0.435209
-------------------------------------------------------
Not saving because 0.417532 > 0.415666 (22.630: -0.00%)
======================================================= (12.112 sec)
25.671... logprob:  0.360864, 0.093750 (1.437 sec)
25.672... logprob:  0.441822, 0.117188 (1.473 sec)
25.673... logprob:  0.436231, 0.117188 (1.434 sec)
25.674... logprob:  0.446643, 0.117188 (1.445 sec)
25.675... logprob:  0.356677, 0.093750 (1.470 sec)
25.676... logprob:  0.450172, 0.125000 (1.452 sec)
25.677... logprob:  0.471032, 0.125000 (1.444 sec)
25.678... logprob:  0.465655, 0.125000 (1.479 sec)
25.679... logprob:  0.454864, 0.125000 (1.435 sec)
25.680... logprob:  0.351685, 0.078125 (1.427 sec)
25.681... logprob:  0.373888, 0.093750 (1.439 sec)
25.682... logprob:  0.340476, 0.078125 (1.437 sec)
25.683... logprob:  0.411636, 0.109375 (1.436 sec)
25.684... logprob:  0.357664, 0.085938 (1.476 sec)
25.685... logprob:  0.286083, 0.054688 (1.445 sec)
25.686... logprob:  0.318707, 0.070312 (1.438 sec)
25.687... logprob:  0.281695, 0.062500 (1.490 sec)
25.688... logprob:  0.323122, 0.078125 (1.434 sec)
25.689... logprob:  0.471155, 0.125000 (1.431 sec)
25.690... logprob:  0.527638, 0.140625 (1.435 sec)
25.691... logprob:  0.516509, 0.140625 (1.437 sec)
25.692... logprob:  0.384974, 0.101562 (1.436 sec)
25.693... logprob:  0.455695, 0.125000 (1.483 sec)
25.694... logprob:  0.330930, 0.078125 (1.438 sec)
25.695... logprob:  0.356927, 0.085938 (1.446 sec)
25.696... logprob:  0.539099, 0.148438 (1.478 sec)
25.697... logprob:  0.465710, 0.125000 (1.436 sec)
25.698... logprob:  0.548870, 0.156250 (1.436 sec)
25.699... logprob:  0.459613, 0.125000 (1.434 sec)
25.700... logprob:  0.433889, 0.117188 (1.434 sec)
25.701... logprob:  0.423071, 0.109375 (1.432 sec)
25.702... logprob:  0.521528, 0.148438 (1.486 sec)
25.703... logprob:  0.405152, 0.101562 (1.440 sec)
25.704... logprob:  0.406067, 0.101562 (1.452 sec)
25.705... logprob:  0.420168, 0.109375 (1.472 sec)
25.706... logprob:  0.468062, 0.125000 (1.440 sec)
25.707... logprob:  0.485299, 0.132812 (1.435 sec)
25.708... logprob:  0.417169, 0.109375 (1.438 sec)
25.709... logprob:  0.422592, 0.109375 (1.421 sec)
25.710... logprob:  0.602294, 0.179688 (1.443 sec)
25.711... logprob:  0.469483, 0.125000 (1.470 sec)
25.712... logprob:  0.340755, 0.078125 (1.446 sec)
25.713... logprob:  0.586720, 0.179688 (1.485 sec)
25.714... logprob:  0.466267, 0.125000 (1.457 sec)
25.715... logprob:  0.417177, 0.109375 (1.456 sec)
25.716... logprob:  0.335413, 0.078125 (1.441 sec)
25.717... logprob:  0.429794, 0.117188 (1.428 sec)
25.718... logprob:  0.490331, 0.132812 (1.430 sec)
25.719... logprob:  0.406186, 0.109375 (1.441 sec)
25.720... logprob:  0.433229, 0.117188 (1.447 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.621849060058594, 10.0]}, 128)
batch 872: ({'logprob': [66.64404296875, 19.0]}, 128)
batch 873: ({'logprob': [40.485443115234375, 9.0]}, 128)
batch 874: ({'logprob': [45.1446647644043, 11.0]}, 128)
batch 875: ({'logprob': [50.74170684814453, 13.0]}, 128)
batch 876: ({'logprob': [64.10322570800781, 18.0]}, 128)
batch 877: ({'logprob': [45.62318420410156, 11.0]}, 128)
batch 878: ({'logprob': [61.987823486328125, 17.0]}, 128)
batch 879: ({'logprob': [73.66291809082031, 21.0]}, 128)
batch 880: ({'logprob': [50.765167236328125, 13.0]}, 128)
batch 881: ({'logprob': [28.77353858947754, 5.0]}, 128)
batch 882: ({'logprob': [54.746524810791016, 14.0]}, 128)
batch 883: ({'logprob': [61.96333312988281, 17.0]}, 128)
batch 884: ({'logprob': [51.22102737426758, 13.0]}, 128)
batch 885: ({'logprob': [52.16310119628906, 13.0]}, 128)
batch 886: ({'logprob': [62.4540901184082, 17.0]}, 128)

======================Test output======================
logprob:  0.416065, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.962751e-03 [2.121282e-09] 
Layer 'conv1' biases: 3.012742e-07 [4.739870e-11] 
Layer 'conv2' weights[0]: 7.949838e-03 [1.477466e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.006986e-10] 
Layer 'conv3' weights[0]: 7.948022e-03 [1.280162e-09] 
Layer 'conv3' biases: 2.566037e-06 [5.527402e-10] 
Layer 'conv4' weights[0]: 7.980702e-03 [1.194803e-09] 
Layer 'conv4' biases: 9.999993e-01 [3.287922e-09] 
Layer 'conv5' weights[0]: 7.979498e-03 [1.424630e-08] 
Layer 'conv5' biases: 9.999930e-01 [1.441440e-08] 
Layer 'fc6' weights[0]: 7.576139e-03 [1.316962e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.056276e-09] 
Layer 'fc7' weights[0]: 7.039514e-03 [7.265363e-08] 
Layer 'fc7' biases: 9.998587e-01 [5.681487e-08] 
Layer 'fc8' weights[0]: 1.301194e-03 [4.998908e-06] 
Layer 'fc8' biases: 6.237254e-02 [3.405646e-05] 
Train error last 870 batches: 0.435208
-------------------------------------------------------
Not saving because 0.416065 > 0.415666 (22.630: -0.00%)
======================================================= (12.086 sec)
25.721... logprob:  0.451603, 0.117188 (1.472 sec)
25.722... logprob:  0.536969, 0.156250 (1.456 sec)
25.723... logprob:  0.416562, 0.109375 (1.442 sec)
25.724... logprob:  0.412764, 0.109375 (1.480 sec)
25.725... logprob:  0.494796, 0.140625 (1.432 sec)
25.726... logprob:  0.338494, 0.085938 (1.427 sec)
25.727... logprob:  0.393252, 0.101562 (1.434 sec)
25.728... logprob:  0.421256, 0.109375 (1.444 sec)
25.729... logprob:  0.387643, 0.093750 (1.432 sec)
25.730... logprob:  0.565896, 0.164062 (1.480 sec)
25.731... logprob:  0.450384, 0.125000 (1.447 sec)
25.732... logprob:  0.311422, 0.070312 (1.443 sec)
25.733... logprob:  0.556551, 0.156250 (1.486 sec)
25.734... logprob:  0.340250, 0.078125 (1.437 sec)
25.735... logprob:  0.527481, 0.148438 (1.428 sec)
25.736... logprob:  0.642708, 0.187500 (1.442 sec)
25.737... logprob:  0.516127, 0.148438 (1.433 sec)
25.738... logprob:  0.459399, 0.125000 (1.432 sec)
25.739... logprob:  0.477796, 0.132812 (1.488 sec)
25.740... logprob:  0.339649, 0.078125 (1.437 sec)
25.741... logprob:  0.393464, 0.101562 (1.442 sec)
25.742... logprob:  0.419702, 0.109375 (1.479 sec)
25.743... logprob:  0.364882, 0.085938 (1.431 sec)
25.744... logprob:  0.519175, 0.148438 (1.435 sec)
25.745... logprob:  0.478146, 0.132812 (1.438 sec)
25.746... logprob:  0.440548, 0.117188 (1.453 sec)
25.747... logprob:  0.425608, 0.109375 (1.440 sec)
25.748... logprob:  0.378113, 0.093750 (1.493 sec)
25.749... logprob:  0.420817, 0.109375 (1.429 sec)
25.750... logprob:  0.512818, 0.140625 (1.446 sec)
25.751... logprob:  0.263651, 0.054688 (1.481 sec)
25.752... logprob:  0.522510, 0.140625 (1.431 sec)
25.753... logprob:  0.441183, 0.117188 (1.440 sec)
25.754... logprob:  0.468378, 0.132812 (1.434 sec)
25.755... logprob:  0.507067, 0.140625 (1.428 sec)
25.756... logprob:  0.440830, 0.117188 (1.440 sec)
25.757... logprob:  0.552413, 0.156250 (1.470 sec)
25.758... logprob:  0.393606, 0.101562 (1.450 sec)
25.759... logprob:  0.459696, 0.125000 (1.457 sec)
25.760... logprob:  0.485511, 0.132812 (1.462 sec)
25.761... logprob:  0.418228, 0.109375 (1.444 sec)
25.762... logprob:  0.516039, 0.148438 (1.446 sec)
25.763... logprob:  0.558928, 0.164062 (1.428 sec)
25.764... logprob:  0.503273, 0.140625 (1.429 sec)
25.765... logprob:  0.311879, 0.062500 (1.443 sec)
25.766... logprob:  0.482234, 0.132812 (1.451 sec)
25.767... logprob:  0.371108, 0.085938 (1.457 sec)
25.768... logprob:  0.432668, 0.117188 (1.464 sec)
25.769... logprob:  0.490826, 0.140625 (1.466 sec)
25.770... logprob:  0.402937, 0.101562 (1.532 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.38188934326172, 10.0]}, 128)
batch 872: ({'logprob': [66.19703674316406, 19.0]}, 128)
batch 873: ({'logprob': [41.18947982788086, 9.0]}, 128)
batch 874: ({'logprob': [45.68437576293945, 11.0]}, 128)
batch 875: ({'logprob': [51.008140563964844, 13.0]}, 128)
batch 876: ({'logprob': [63.76524353027344, 18.0]}, 128)
batch 877: ({'logprob': [46.10907745361328, 11.0]}, 128)
batch 878: ({'logprob': [61.70547103881836, 17.0]}, 128)
batch 879: ({'logprob': [72.77728271484375, 21.0]}, 128)
batch 880: ({'logprob': [51.031307220458984, 13.0]}, 128)
batch 881: ({'logprob': [30.08222770690918, 5.0]}, 128)
batch 882: ({'logprob': [54.73702621459961, 14.0]}, 128)
batch 883: ({'logprob': [61.681095123291016, 17.0]}, 128)
batch 884: ({'logprob': [51.430416107177734, 13.0]}, 128)
batch 885: ({'logprob': [52.262474060058594, 13.0]}, 128)
batch 886: ({'logprob': [62.115631103515625, 17.0]}, 128)

======================Test output======================
logprob:  0.417069, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.962712e-03 [2.979758e-09] 
Layer 'conv1' biases: 3.022311e-07 [1.215473e-10] 
Layer 'conv2' weights[0]: 7.949792e-03 [2.419021e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.137289e-10] 
Layer 'conv3' weights[0]: 7.947976e-03 [2.526131e-09] 
Layer 'conv3' biases: 2.572881e-06 [1.500506e-09] 
Layer 'conv4' weights[0]: 7.980663e-03 [2.646614e-09] 
Layer 'conv4' biases: 9.999993e-01 [1.371452e-08] 
Layer 'conv5' weights[0]: 7.979455e-03 [8.990128e-08] 
Layer 'conv5' biases: 9.999930e-01 [9.682403e-08] 
Layer 'fc6' weights[0]: 7.576098e-03 [7.408562e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.529293e-09] 
Layer 'fc7' weights[0]: 7.037719e-03 [2.562882e-07] 
Layer 'fc7' biases: 9.998579e-01 [2.457466e-07] 
Layer 'fc8' weights[0]: 1.277256e-03 [8.692112e-06] 
Layer 'fc8' biases: 6.232181e-02 [6.311465e-05] 
Train error last 870 batches: 0.435208
-------------------------------------------------------
Not saving because 0.417069 > 0.415666 (22.630: -0.00%)
======================================================= (12.070 sec)
25.771... logprob:  0.549468, 0.156250 (1.470 sec)
25.772... logprob:  0.414082, 0.109375 (1.450 sec)
25.773... logprob:  0.557806, 0.164062 (1.445 sec)
25.774... logprob:  0.361715, 0.085938 (1.466 sec)
25.775... logprob:  0.407373, 0.101562 (1.462 sec)
25.776... logprob:  0.433177, 0.117188 (1.484 sec)
25.777... logprob:  0.379961, 0.093750 (1.474 sec)
25.778... logprob:  0.433565, 0.117188 (1.466 sec)
25.779... logprob:  0.505370, 0.140625 (1.496 sec)
25.780... logprob:  0.385761, 0.101562 (1.458 sec)
25.781... logprob:  0.369655, 0.085938 (1.449 sec)
25.782... logprob:  0.351434, 0.085938 (1.449 sec)
25.783... logprob:  0.555516, 0.156250 (1.459 sec)
25.784... logprob:  0.440958, 0.117188 (1.463 sec)
25.785... logprob:  0.543668, 0.156250 (1.492 sec)
25.786... logprob:  0.477512, 0.132812 (1.475 sec)
25.787... logprob:  0.546415, 0.156250 (1.458 sec)
25.788... logprob:  0.563168, 0.164062 (1.501 sec)
25.789... logprob:  0.280885, 0.054688 (1.454 sec)
25.790... logprob:  0.408033, 0.101562 (1.447 sec)
25.791... logprob:  0.397943, 0.101562 (1.451 sec)
25.792... logprob:  0.361013, 0.085938 (1.459 sec)
25.793... logprob:  0.370133, 0.085938 (1.459 sec)
25.794... logprob:  0.387128, 0.093750 (1.486 sec)
25.795... logprob:  0.469750, 0.125000 (1.472 sec)
25.796... logprob:  0.423507, 0.109375 (1.460 sec)
25.797... logprob:  0.358838, 0.085938 (1.497 sec)
25.798... logprob:  0.393287, 0.101562 (1.458 sec)
25.799... logprob:  0.332386, 0.078125 (1.447 sec)
25.800... logprob:  0.371717, 0.093750 (1.453 sec)
25.801... logprob:  0.450060, 0.117188 (1.459 sec)
25.802... logprob:  0.422955, 0.109375 (1.455 sec)
25.803... logprob:  0.491612, 0.132812 (1.492 sec)
25.804... logprob:  0.349957, 0.085938 (1.469 sec)
25.805... logprob:  0.452281, 0.117188 (1.451 sec)
25.806... logprob:  0.424180, 0.109375 (1.507 sec)
25.807... logprob:  0.443473, 0.117188 (1.455 sec)
25.808... logprob:  0.462361, 0.125000 (1.448 sec)
25.809... logprob:  0.589704, 0.171875 (1.452 sec)
25.810... logprob:  0.442475, 0.117188 (1.457 sec)
25.811... logprob:  0.460419, 0.125000 (1.455 sec)
25.812... logprob:  0.462356, 0.125000 (1.501 sec)
25.813... logprob:  0.485958, 0.132812 (1.459 sec)
25.814... logprob:  0.477987, 0.132812 (1.459 sec)
25.815... logprob:  0.371745, 0.085938 (1.498 sec)
25.816... logprob:  0.408649, 0.101562 (1.457 sec)
25.817... logprob:  0.425922, 0.109375 (1.451 sec)
25.818... logprob:  0.559996, 0.164062 (1.452 sec)
25.819... logprob:  0.498193, 0.140625 (1.484 sec)
25.820... logprob:  0.421640, 0.109375 (1.453 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.36635971069336, 10.0]}, 128)
batch 872: ({'logprob': [66.17512512207031, 19.0]}, 128)
batch 873: ({'logprob': [41.850303649902344, 9.0]}, 128)
batch 874: ({'logprob': [46.360103607177734, 11.0]}, 128)
batch 875: ({'logprob': [51.446834564208984, 13.0]}, 128)
batch 876: ({'logprob': [63.79853057861328, 18.0]}, 128)
batch 877: ({'logprob': [46.65934753417969, 11.0]}, 128)
batch 878: ({'logprob': [61.66872024536133, 17.0]}, 128)
batch 879: ({'logprob': [72.13993072509766, 21.0]}, 128)
batch 880: ({'logprob': [51.46991729736328, 13.0]}, 128)
batch 881: ({'logprob': [31.34526824951172, 5.0]}, 128)
batch 882: ({'logprob': [54.740257263183594, 14.0]}, 128)
batch 883: ({'logprob': [61.64459991455078, 17.0]}, 128)
batch 884: ({'logprob': [51.741153717041016, 13.0]}, 128)
batch 885: ({'logprob': [52.320674896240234, 13.0]}, 128)
batch 886: ({'logprob': [61.95179748535156, 17.0]}, 128)

======================Test output======================
logprob:  0.419277, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.962669e-03 [3.471013e-09] 
Layer 'conv1' biases: 3.033323e-07 [1.280954e-10] 
Layer 'conv2' weights[0]: 7.949755e-03 [2.384022e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.776988e-10] 
Layer 'conv3' weights[0]: 7.947938e-03 [2.297451e-09] 
Layer 'conv3' biases: 2.583387e-06 [1.323016e-09] 
Layer 'conv4' weights[0]: 7.980623e-03 [2.431666e-09] 
Layer 'conv4' biases: 9.999993e-01 [1.247090e-08] 
Layer 'conv5' weights[0]: 7.979427e-03 [8.232652e-08] 
Layer 'conv5' biases: 9.999932e-01 [8.866350e-08] 
Layer 'fc6' weights[0]: 7.576057e-03 [6.746220e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.855866e-09] 
Layer 'fc7' weights[0]: 7.035965e-03 [1.722116e-07] 
Layer 'fc7' biases: 9.998573e-01 [1.610647e-07] 
Layer 'fc8' weights[0]: 1.255185e-03 [5.375347e-06] 
Layer 'fc8' biases: 6.238711e-02 [4.321160e-05] 
Train error last 870 batches: 0.435208
-------------------------------------------------------
Not saving because 0.419277 > 0.415666 (22.630: -0.00%)
======================================================= (12.035 sec)
25.821... logprob:  0.406614, 0.101562 (1.502 sec)
25.822... logprob:  0.441212, 0.117188 (1.465 sec)
25.823... logprob:  0.340910, 0.078125 (1.450 sec)
25.824... logprob:  0.489763, 0.132812 (1.501 sec)
25.825... logprob:  0.288103, 0.062500 (1.454 sec)
25.826... logprob:  0.375508, 0.093750 (1.458 sec)
25.827... logprob:  0.420512, 0.109375 (1.446 sec)
25.828... logprob:  0.443313, 0.117188 (1.459 sec)
25.829... logprob:  0.504089, 0.140625 (1.452 sec)
25.830... logprob:  0.442152, 0.117188 (1.505 sec)
25.831... logprob:  0.513941, 0.140625 (1.454 sec)
25.832... logprob:  0.330844, 0.078125 (1.462 sec)
25.833... logprob:  0.489027, 0.132812 (1.499 sec)
25.834... logprob:  0.433323, 0.117188 (1.452 sec)
25.835... logprob:  0.542778, 0.148438 (1.460 sec)
25.836... logprob:  0.376162, 0.093750 (1.446 sec)
25.837... logprob:  0.314259, 0.070312 (1.454 sec)
25.838... logprob:  0.437072, 0.117188 (1.457 sec)
25.839... logprob:  0.471669, 0.125000 (1.507 sec)
25.840... logprob:  0.555456, 0.156250 (1.450 sec)
25.841... logprob:  0.396087, 0.101562 (1.466 sec)
25.842... logprob:  0.497861, 0.140625 (1.496 sec)
25.843... logprob:  0.465512, 0.125000 (1.455 sec)
25.844... logprob:  0.497652, 0.140625 (1.454 sec)
25.845... logprob:  0.486764, 0.132812 (1.447 sec)
25.846... logprob:  0.468424, 0.125000 (1.449 sec)
25.847... logprob:  0.363348, 0.085938 (1.457 sec)
25.848... logprob:  0.397173, 0.101562 (1.499 sec)
25.849... logprob:  0.360500, 0.085938 (1.460 sec)
25.850... logprob:  0.479390, 0.132812 (1.469 sec)
25.851... logprob:  0.440141, 0.117188 (1.486 sec)
25.852... logprob:  0.545506, 0.156250 (1.465 sec)
25.853... logprob:  0.371940, 0.093750 (1.463 sec)
25.854... logprob:  0.307280, 0.070312 (1.448 sec)
25.855... logprob:  0.484784, 0.132812 (1.453 sec)
25.856... logprob:  0.443751, 0.117188 (1.452 sec)
25.857... logprob:  0.372231, 0.093750 (1.494 sec)
25.858... logprob:  0.396245, 0.101562 (1.462 sec)
25.859... logprob:  0.307977, 0.070312 (1.471 sec)
25.860... logprob:  0.565979, 0.156250 (1.481 sec)
25.861... logprob:  0.417805, 0.109375 (1.460 sec)
25.862... logprob:  0.328860, 0.078125 (1.461 sec)
25.863... logprob:  0.399560, 0.101562 (1.447 sec)
25.864... logprob:  0.451468, 0.117188 (1.450 sec)
25.865... logprob:  0.484557, 0.132812 (1.455 sec)
25.866... logprob:  0.507717, 0.140625 (1.492 sec)
25.867... logprob:  0.503072, 0.140625 (1.466 sec)
25.868... logprob:  0.405261, 0.101562 (1.478 sec)
25.869... logprob:  0.383147, 0.093750 (1.479 sec)
25.870... logprob:  0.552158, 0.156250 (1.404 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.69279861450195, 10.0]}, 128)
batch 872: ({'logprob': [66.29074096679688, 19.0]}, 128)
batch 873: ({'logprob': [41.21677780151367, 9.0]}, 128)
batch 874: ({'logprob': [45.83219909667969, 11.0]}, 128)
batch 875: ({'logprob': [51.097625732421875, 13.0]}, 128)
batch 876: ({'logprob': [63.84353256225586, 18.0]}, 128)
batch 877: ({'logprob': [46.167724609375, 11.0]}, 128)
batch 878: ({'logprob': [61.67875671386719, 17.0]}, 128)
batch 879: ({'logprob': [72.54562377929688, 21.0]}, 128)
batch 880: ({'logprob': [51.12111282348633, 13.0]}, 128)
batch 881: ({'logprob': [30.315126419067383, 5.0]}, 128)
batch 882: ({'logprob': [54.57427978515625, 14.0]}, 128)
batch 883: ({'logprob': [61.65436935424805, 17.0]}, 128)
batch 884: ({'logprob': [51.43046569824219, 13.0]}, 128)
batch 885: ({'logprob': [52.08406448364258, 13.0]}, 128)
batch 886: ({'logprob': [61.999595642089844, 17.0]}, 128)

======================Test output======================
logprob:  0.417258, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.962638e-03 [3.636141e-09] 
Layer 'conv1' biases: 3.044567e-07 [7.684456e-11] 
Layer 'conv2' weights[0]: 7.949716e-03 [2.185392e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.190817e-10] 
Layer 'conv3' weights[0]: 7.947902e-03 [2.087409e-09] 
Layer 'conv3' biases: 2.593359e-06 [1.304542e-09] 
Layer 'conv4' weights[0]: 7.980593e-03 [2.233483e-09] 
Layer 'conv4' biases: 9.999993e-01 [1.146274e-08] 
Layer 'conv5' weights[0]: 7.979396e-03 [7.576754e-08] 
Layer 'conv5' biases: 9.999935e-01 [8.144757e-08] 
Layer 'fc6' weights[0]: 7.576020e-03 [6.235607e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.345917e-09] 
Layer 'fc7' weights[0]: 7.034153e-03 [2.715636e-07] 
Layer 'fc7' biases: 9.998578e-01 [2.623388e-07] 
Layer 'fc8' weights[0]: 1.267864e-03 [9.090618e-06] 
Layer 'fc8' biases: 6.269008e-02 [5.925892e-05] 
Train error last 870 batches: 0.435208
-------------------------------------------------------
Not saving because 0.417258 > 0.415666 (22.630: -0.00%)
======================================================= (11.973 sec)
26.1... logprob:  0.379986, 0.093750 (1.414 sec)
26.2... logprob:  0.448255, 0.117188 (1.458 sec)
26.3... logprob:  0.398303, 0.101562 (1.417 sec)
26.4... logprob:  0.443309, 0.117188 (1.402 sec)
26.5... logprob:  0.443468, 0.117188 (1.437 sec)
26.6... logprob:  0.499091, 0.140625 (1.398 sec)
26.7... logprob:  0.363239, 0.085938 (1.434 sec)
26.8... logprob:  0.419153, 0.109375 (1.399 sec)
26.9... logprob:  0.358860, 0.085938 (1.403 sec)
26.10... logprob:  0.377549, 0.093750 (1.411 sec)
26.11... logprob:  0.334831, 0.078125 (1.451 sec)
26.12... logprob:  0.466331, 0.125000 (1.397 sec)
26.13... logprob:  0.442211, 0.117188 (1.420 sec)
26.14... logprob:  0.444586, 0.117188 (1.407 sec)
26.15... logprob:  0.395534, 0.101562 (1.435 sec)
26.16... logprob:  0.421381, 0.109375 (1.412 sec)
26.17... logprob:  0.515981, 0.140625 (1.394 sec)
26.18... logprob:  0.262109, 0.054688 (1.405 sec)
26.19... logprob:  0.279509, 0.062500 (1.403 sec)
26.20... logprob:  0.421368, 0.109375 (1.403 sec)
26.21... logprob:  0.443984, 0.117188 (1.403 sec)
26.22... logprob:  0.536743, 0.148438 (1.419 sec)
26.23... logprob:  0.533080, 0.148438 (1.421 sec)
26.24... logprob:  0.310537, 0.070312 (1.416 sec)
26.25... logprob:  0.356162, 0.085938 (1.410 sec)
26.26... logprob:  0.463777, 0.125000 (1.446 sec)
26.27... logprob:  0.404523, 0.101562 (1.394 sec)
26.28... logprob:  0.421851, 0.109375 (1.412 sec)
26.29... logprob:  0.395948, 0.101562 (1.426 sec)
26.30... logprob:  0.374081, 0.093750 (1.415 sec)
26.31... logprob:  0.479956, 0.132812 (1.407 sec)
26.32... logprob:  0.457225, 0.125000 (1.387 sec)
26.33... logprob:  0.460677, 0.125000 (1.452 sec)
26.34... logprob:  0.464544, 0.125000 (1.393 sec)
26.35... logprob:  0.316301, 0.070312 (1.400 sec)
26.36... logprob:  0.475793, 0.132812 (1.401 sec)
26.37... logprob:  0.417593, 0.109375 (1.409 sec)
26.38... logprob:  0.392652, 0.101562 (1.395 sec)
26.39... logprob:  0.631530, 0.187500 (1.434 sec)
26.40... logprob:  0.445710, 0.117188 (1.415 sec)
26.41... logprob:  0.352938, 0.085938 (1.426 sec)
26.42... logprob:  0.391975, 0.101562 (1.421 sec)
26.43... logprob:  0.440085, 0.117188 (1.414 sec)
26.44... logprob:  0.518552, 0.148438 (1.439 sec)
26.45... logprob:  0.381733, 0.093750 (1.392 sec)
26.46... logprob:  0.486219, 0.132812 (1.395 sec)
26.47... logprob:  0.331725, 0.078125 (1.401 sec)
26.48... logprob:  0.498926, 0.140625 (1.422 sec)
26.49... logprob:  0.510835, 0.148438 (1.419 sec)
26.50... logprob:  0.393195, 0.101562 (1.423 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.840065002441406, 10.0]}, 128)
batch 872: ({'logprob': [66.27349853515625, 19.0]}, 128)
batch 873: ({'logprob': [40.96167755126953, 9.0]}, 128)
batch 874: ({'logprob': [45.384281158447266, 11.0]}, 128)
batch 875: ({'logprob': [50.85752487182617, 13.0]}, 128)
batch 876: ({'logprob': [63.82258987426758, 18.0]}, 128)
batch 877: ({'logprob': [45.919437408447266, 11.0]}, 128)
batch 878: ({'logprob': [61.85414123535156, 17.0]}, 128)
batch 879: ({'logprob': [73.33562469482422, 21.0]}, 128)
batch 880: ({'logprob': [50.880680084228516, 13.0]}, 128)
batch 881: ({'logprob': [29.443763732910156, 5.0]}, 128)
batch 882: ({'logprob': [54.93903732299805, 14.0]}, 128)
batch 883: ({'logprob': [61.82981872558594, 17.0]}, 128)
batch 884: ({'logprob': [51.39149856567383, 13.0]}, 128)
batch 885: ({'logprob': [52.44561767578125, 13.0]}, 128)
batch 886: ({'logprob': [62.37588119506836, 17.0]}, 128)

======================Test output======================
logprob:  0.416775, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.962601e-03 [2.861548e-09] 
Layer 'conv1' biases: 3.054439e-07 [4.325372e-11] 
Layer 'conv2' weights[0]: 7.949679e-03 [2.067646e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.837385e-10] 
Layer 'conv3' weights[0]: 7.947871e-03 [1.410300e-09] 
Layer 'conv3' biases: 2.600211e-06 [5.239962e-10] 
Layer 'conv4' weights[0]: 7.980552e-03 [1.356475e-09] 
Layer 'conv4' biases: 9.999993e-01 [2.314695e-09] 
Layer 'conv5' weights[0]: 7.979358e-03 [1.120770e-08] 
Layer 'conv5' biases: 9.999930e-01 [1.145105e-08] 
Layer 'fc6' weights[0]: 7.575978e-03 [1.157123e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.325828e-10] 
Layer 'fc7' weights[0]: 7.032346e-03 [5.052259e-08] 
Layer 'fc7' biases: 9.998581e-01 [2.996969e-08] 
Layer 'fc8' weights[0]: 1.283285e-03 [6.370245e-06] 
Layer 'fc8' biases: 6.288369e-02 [4.222348e-05] 
Train error last 870 batches: 0.435207
-------------------------------------------------------
Not saving because 0.416775 > 0.415666 (22.630: -0.00%)
======================================================= (12.133 sec)
26.51... logprob:  0.490213, 0.140625 (1.423 sec)
26.52... logprob:  0.525787, 0.148438 (1.408 sec)
26.53... logprob:  0.294845, 0.062500 (1.441 sec)
26.54... logprob:  0.403370, 0.109375 (1.391 sec)
26.55... logprob:  0.331713, 0.078125 (1.404 sec)
26.56... logprob:  0.421633, 0.109375 (1.401 sec)
26.57... logprob:  0.572383, 0.164062 (1.433 sec)
26.58... logprob:  0.407590, 0.101562 (1.401 sec)
26.59... logprob:  0.333867, 0.078125 (1.466 sec)
26.60... logprob:  0.618786, 0.179688 (1.421 sec)
26.61... logprob:  0.382815, 0.093750 (1.430 sec)
26.62... logprob:  0.474851, 0.132812 (1.458 sec)
26.63... logprob:  0.397293, 0.101562 (1.446 sec)
26.64... logprob:  0.450313, 0.125000 (1.418 sec)
26.65... logprob:  0.373368, 0.093750 (1.400 sec)
26.66... logprob:  0.354034, 0.085938 (1.449 sec)
26.67... logprob:  0.295414, 0.062500 (1.390 sec)
26.68... logprob:  0.396803, 0.101562 (1.400 sec)
26.69... logprob:  0.496700, 0.140625 (1.424 sec)
26.70... logprob:  0.325897, 0.078125 (1.437 sec)
26.71... logprob:  0.381807, 0.101562 (1.473 sec)
26.72... logprob:  0.493727, 0.132812 (1.408 sec)
26.73... logprob:  0.447703, 0.117188 (1.430 sec)
26.74... logprob:  0.442530, 0.117188 (1.415 sec)
26.75... logprob:  0.380653, 0.093750 (1.420 sec)
26.76... logprob:  0.412054, 0.109375 (1.432 sec)
26.77... logprob:  0.396343, 0.101562 (1.434 sec)
26.78... logprob:  0.493056, 0.140625 (1.454 sec)
26.79... logprob:  0.456468, 0.125000 (1.405 sec)
26.80... logprob:  0.508003, 0.132812 (1.428 sec)
26.81... logprob:  0.416724, 0.109375 (1.420 sec)
26.82... logprob:  0.231353, 0.039062 (1.425 sec)
26.83... logprob:  0.493802, 0.140625 (1.409 sec)
26.84... logprob:  0.468134, 0.125000 (1.467 sec)
26.85... logprob:  0.431946, 0.117188 (1.429 sec)
26.86... logprob:  0.416939, 0.109375 (1.416 sec)
26.87... logprob:  0.633275, 0.187500 (1.417 sec)
26.88... logprob:  0.535034, 0.156250 (1.410 sec)
26.89... logprob:  0.410563, 0.109375 (1.441 sec)
26.90... logprob:  0.577486, 0.171875 (1.403 sec)
26.91... logprob:  0.348449, 0.078125 (1.402 sec)
26.92... logprob:  0.464461, 0.125000 (1.406 sec)
26.93... logprob:  0.492222, 0.140625 (1.405 sec)
26.94... logprob:  0.428784, 0.109375 (1.396 sec)
26.95... logprob:  0.471836, 0.125000 (1.405 sec)
26.96... logprob:  0.576214, 0.171875 (1.400 sec)
26.97... logprob:  0.430782, 0.117188 (1.391 sec)
26.98... logprob:  0.391171, 0.093750 (1.445 sec)
26.99... logprob:  0.474237, 0.132812 (1.406 sec)
26.100... logprob:  0.310569, 0.070312 (1.403 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.24547576904297, 10.0]}, 128)
batch 872: ({'logprob': [66.11465454101562, 19.0]}, 128)
batch 873: ({'logprob': [41.269569396972656, 9.0]}, 128)
batch 874: ({'logprob': [45.65446853637695, 11.0]}, 128)
batch 875: ({'logprob': [50.99757385253906, 13.0]}, 128)
batch 876: ({'logprob': [63.70561218261719, 18.0]}, 128)
batch 877: ({'logprob': [46.143775939941406, 11.0]}, 128)
batch 878: ({'logprob': [61.73314666748047, 17.0]}, 128)
batch 879: ({'logprob': [72.90746307373047, 21.0]}, 128)
batch 880: ({'logprob': [51.020591735839844, 13.0]}, 128)
batch 881: ({'logprob': [30.059528350830078, 5.0]}, 128)
batch 882: ({'logprob': [54.89731216430664, 14.0]}, 128)
batch 883: ({'logprob': [61.708831787109375, 17.0]}, 128)
batch 884: ({'logprob': [51.48429870605469, 13.0]}, 128)
batch 885: ({'logprob': [52.44549560546875, 13.0]}, 128)
batch 886: ({'logprob': [62.20794677734375, 17.0]}, 128)

======================Test output======================
logprob:  0.417283, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.962565e-03 [4.314699e-09] 
Layer 'conv1' biases: 3.062811e-07 [1.613169e-10] 
Layer 'conv2' weights[0]: 7.949637e-03 [4.411117e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.006070e-10] 
Layer 'conv3' weights[0]: 7.947824e-03 [4.307878e-09] 
Layer 'conv3' biases: 2.606122e-06 [2.722123e-09] 
Layer 'conv4' weights[0]: 7.980514e-03 [4.576100e-09] 
Layer 'conv4' biases: 9.999993e-01 [2.522792e-08] 
Layer 'conv5' weights[0]: 7.979299e-03 [1.652570e-07] 
Layer 'conv5' biases: 9.999929e-01 [1.778894e-07] 
Layer 'fc6' weights[0]: 7.575941e-03 [1.354301e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.384422e-08] 
Layer 'fc7' weights[0]: 7.030599e-03 [2.943701e-07] 
Layer 'fc7' biases: 9.998580e-01 [2.844906e-07] 
Layer 'fc8' weights[0]: 1.273206e-03 [1.051675e-05] 
Layer 'fc8' biases: 6.288039e-02 [7.345652e-05] 
Train error last 870 batches: 0.435207
-------------------------------------------------------
Not saving because 0.417283 > 0.415666 (22.630: -0.00%)
======================================================= (11.961 sec)
26.101... logprob:  0.310839, 0.062500 (1.453 sec)
26.102... logprob:  0.545999, 0.156250 (1.397 sec)
26.103... logprob:  0.541000, 0.156250 (1.402 sec)
26.104... logprob:  0.388822, 0.101562 (1.404 sec)
26.105... logprob:  0.619382, 0.179688 (1.404 sec)
26.106... logprob:  0.344458, 0.085938 (1.395 sec)
26.107... logprob:  0.335774, 0.078125 (1.442 sec)
26.108... logprob:  0.586851, 0.171875 (1.402 sec)
26.109... logprob:  0.336140, 0.078125 (1.402 sec)
26.110... logprob:  0.564619, 0.164062 (1.401 sec)
26.111... logprob:  0.404678, 0.101562 (1.395 sec)
26.112... logprob:  0.366029, 0.093750 (1.405 sec)
26.113... logprob:  0.354472, 0.085938 (1.406 sec)
26.114... logprob:  0.440215, 0.117188 (1.433 sec)
26.115... logprob:  0.506770, 0.140625 (1.413 sec)
26.116... logprob:  0.393358, 0.101562 (1.406 sec)
26.117... logprob:  0.440393, 0.117188 (1.445 sec)
26.118... logprob:  0.409106, 0.101562 (1.397 sec)
26.119... logprob:  0.346093, 0.085938 (1.400 sec)
26.120... logprob:  0.547130, 0.156250 (1.402 sec)
26.121... logprob:  0.412612, 0.109375 (1.396 sec)
26.122... logprob:  0.519278, 0.148438 (1.448 sec)
26.123... logprob:  0.463686, 0.125000 (1.389 sec)
26.124... logprob:  0.447693, 0.125000 (1.424 sec)
26.125... logprob:  0.501931, 0.140625 (1.403 sec)
26.126... logprob:  0.475749, 0.125000 (1.399 sec)
26.127... logprob:  0.479526, 0.125000 (1.401 sec)
26.128... logprob:  0.422341, 0.109375 (1.419 sec)
26.129... logprob:  0.574887, 0.164062 (1.419 sec)
26.130... logprob:  0.382711, 0.093750 (1.412 sec)
26.131... logprob:  0.495497, 0.132812 (1.415 sec)
26.132... logprob:  0.506365, 0.140625 (1.437 sec)
26.133... logprob:  0.444688, 0.117188 (1.390 sec)
26.134... logprob:  0.401879, 0.101562 (1.397 sec)
26.135... logprob:  0.460197, 0.125000 (1.406 sec)
26.136... logprob:  0.562415, 0.164062 (1.404 sec)
26.137... logprob:  0.462584, 0.125000 (1.402 sec)
26.138... logprob:  0.319389, 0.070312 (1.448 sec)
26.139... logprob:  0.395748, 0.101562 (1.406 sec)
26.140... logprob:  0.560158, 0.164062 (1.410 sec)
26.141... logprob:  0.464571, 0.125000 (1.440 sec)
26.142... logprob:  0.464632, 0.125000 (1.402 sec)
26.143... logprob:  0.294387, 0.062500 (1.433 sec)
26.144... logprob:  0.457100, 0.125000 (1.425 sec)
26.145... logprob:  0.324756, 0.078125 (1.414 sec)
26.146... logprob:  0.483116, 0.132812 (1.416 sec)
26.147... logprob:  0.262480, 0.054688 (1.431 sec)
26.148... logprob:  0.458659, 0.125000 (1.393 sec)
26.149... logprob:  0.442513, 0.117188 (1.398 sec)
26.150... logprob:  0.347586, 0.085938 (1.401 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.26026153564453, 10.0]}, 128)
batch 872: ({'logprob': [67.90413665771484, 19.0]}, 128)
batch 873: ({'logprob': [39.591487884521484, 9.0]}, 128)
batch 874: ({'logprob': [44.80507278442383, 11.0]}, 128)
batch 875: ({'logprob': [50.748817443847656, 13.0]}, 128)
batch 876: ({'logprob': [65.13957977294922, 18.0]}, 128)
batch 877: ({'logprob': [45.179779052734375, 11.0]}, 128)
batch 878: ({'logprob': [62.69432067871094, 17.0]}, 128)
batch 879: ({'logprob': [74.96558380126953, 21.0]}, 128)
batch 880: ({'logprob': [50.77386474609375, 13.0]}, 128)
batch 881: ({'logprob': [27.282197952270508, 5.0]}, 128)
batch 882: ({'logprob': [54.67491912841797, 14.0]}, 128)
batch 883: ({'logprob': [62.66875457763672, 17.0]}, 128)
batch 884: ({'logprob': [51.12942886352539, 13.0]}, 128)
batch 885: ({'logprob': [51.86650466918945, 13.0]}, 128)
batch 886: ({'logprob': [63.05977249145508, 17.0]}, 128)

======================Test output======================
logprob:  0.416867, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.962522e-03 [2.814570e-09] 
Layer 'conv1' biases: 3.071510e-07 [4.977377e-11] 
Layer 'conv2' weights[0]: 7.949590e-03 [1.604652e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.788015e-10] 
Layer 'conv3' weights[0]: 7.947783e-03 [1.221119e-09] 
Layer 'conv3' biases: 2.613542e-06 [4.492563e-10] 
Layer 'conv4' weights[0]: 7.980476e-03 [1.174009e-09] 
Layer 'conv4' biases: 9.999993e-01 [2.413214e-09] 
Layer 'conv5' weights[0]: 7.979273e-03 [1.092672e-08] 
Layer 'conv5' biases: 9.999926e-01 [1.105911e-08] 
Layer 'fc6' weights[0]: 7.575907e-03 [1.112342e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.742124e-10] 
Layer 'fc7' weights[0]: 7.028793e-03 [1.295317e-07] 
Layer 'fc7' biases: 9.998593e-01 [1.170478e-07] 
Layer 'fc8' weights[0]: 1.330591e-03 [8.680464e-06] 
Layer 'fc8' biases: 6.338136e-02 [5.738963e-05] 
Train error last 870 batches: 0.435207
-------------------------------------------------------
Not saving because 0.416867 > 0.415666 (22.630: -0.00%)
======================================================= (12.111 sec)
26.151... logprob:  0.347142, 0.085938 (1.410 sec)
26.152... logprob:  0.785105, 0.234375 (1.401 sec)
26.153... logprob:  0.381647, 0.093750 (1.448 sec)
26.154... logprob:  0.524622, 0.148438 (1.401 sec)
26.155... logprob:  0.426080, 0.117188 (1.409 sec)
26.156... logprob:  0.295371, 0.062500 (1.441 sec)
26.157... logprob:  0.270276, 0.054688 (1.392 sec)
26.158... logprob:  0.455422, 0.125000 (1.432 sec)
26.159... logprob:  0.483121, 0.132812 (1.398 sec)
26.160... logprob:  0.444747, 0.117188 (1.399 sec)
26.161... logprob:  0.349807, 0.078125 (1.399 sec)
26.162... logprob:  0.611785, 0.179688 (1.402 sec)
26.163... logprob:  0.450470, 0.125000 (1.433 sec)
26.164... logprob:  0.468562, 0.125000 (1.429 sec)
26.165... logprob:  0.547806, 0.156250 (1.425 sec)
26.166... logprob:  0.446128, 0.125000 (1.456 sec)
26.167... logprob:  0.350566, 0.085938 (1.430 sec)
26.168... logprob:  0.363732, 0.085938 (1.423 sec)
26.169... logprob:  0.408640, 0.101562 (1.465 sec)
26.170... logprob:  0.459469, 0.125000 (1.401 sec)
26.171... logprob:  0.535283, 0.156250 (1.424 sec)
26.172... logprob:  0.434818, 0.109375 (1.416 sec)
26.173... logprob:  0.440473, 0.117188 (1.423 sec)
26.174... logprob:  0.600802, 0.171875 (1.413 sec)
26.175... logprob:  0.505982, 0.140625 (1.466 sec)
26.176... logprob:  0.478420, 0.132812 (1.422 sec)
26.177... logprob:  0.289731, 0.054688 (1.424 sec)
26.178... logprob:  0.383476, 0.093750 (1.458 sec)
26.179... logprob:  0.394676, 0.101562 (1.417 sec)
26.180... logprob:  0.466388, 0.125000 (1.428 sec)
26.181... logprob:  0.539307, 0.156250 (1.418 sec)
26.182... logprob:  0.371306, 0.093750 (1.419 sec)
26.183... logprob:  0.419939, 0.109375 (1.417 sec)
26.184... logprob:  0.483444, 0.132812 (1.422 sec)
26.185... logprob:  0.289775, 0.062500 (1.404 sec)
26.186... logprob:  0.370391, 0.093750 (1.405 sec)
26.187... logprob:  0.529618, 0.148438 (1.407 sec)
26.188... logprob:  0.458894, 0.125000 (1.400 sec)
26.189... logprob:  0.440917, 0.117188 (1.399 sec)
26.190... logprob:  0.375779, 0.093750 (1.436 sec)
26.191... logprob:  0.485094, 0.132812 (1.411 sec)
26.192... logprob:  0.520060, 0.148438 (1.415 sec)
26.193... logprob:  0.312520, 0.070312 (1.423 sec)
26.194... logprob:  0.414065, 0.109375 (1.415 sec)
26.195... logprob:  0.287072, 0.062500 (1.399 sec)
26.196... logprob:  0.410481, 0.109375 (1.394 sec)
26.197... logprob:  0.477992, 0.132812 (1.400 sec)
26.198... logprob:  0.355796, 0.085938 (1.408 sec)
26.199... logprob:  0.437193, 0.117188 (1.388 sec)
26.200... logprob:  0.440740, 0.117188 (1.467 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.39260482788086, 10.0]}, 128)
batch 872: ({'logprob': [66.88818359375, 19.0]}, 128)
batch 873: ({'logprob': [40.264469146728516, 9.0]}, 128)
batch 874: ({'logprob': [44.995750427246094, 11.0]}, 128)
batch 875: ({'logprob': [50.6993408203125, 13.0]}, 128)
batch 876: ({'logprob': [64.30352020263672, 18.0]}, 128)
batch 877: ({'logprob': [45.4917106628418, 11.0]}, 128)
batch 878: ({'logprob': [62.16044998168945, 17.0]}, 128)
batch 879: ({'logprob': [74.06709289550781, 21.0]}, 128)
batch 880: ({'logprob': [50.72350311279297, 13.0]}, 128)
batch 881: ({'logprob': [28.320161819458008, 5.0]}, 128)
batch 882: ({'logprob': [54.80265426635742, 14.0]}, 128)
batch 883: ({'logprob': [62.13530349731445, 17.0]}, 128)
batch 884: ({'logprob': [51.19744873046875, 13.0]}, 128)
batch 885: ({'logprob': [52.17448806762695, 13.0]}, 128)
batch 886: ({'logprob': [62.64476013183594, 17.0]}, 128)

======================Test output======================
logprob:  0.416143, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.962487e-03 [3.971593e-09] 
Layer 'conv1' biases: 3.082236e-07 [1.119766e-10] 
Layer 'conv2' weights[0]: 7.949558e-03 [2.420108e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.137383e-10] 
Layer 'conv3' weights[0]: 7.947745e-03 [1.706787e-09] 
Layer 'conv3' biases: 2.622799e-06 [7.610026e-10] 
Layer 'conv4' weights[0]: 7.980438e-03 [1.647690e-09] 
Layer 'conv4' biases: 9.999993e-01 [4.213801e-09] 
Layer 'conv5' weights[0]: 7.979234e-03 [2.656765e-08] 
Layer 'conv5' biases: 9.999929e-01 [2.858107e-08] 
Layer 'fc6' weights[0]: 7.575870e-03 [2.376462e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.246605e-09] 
Layer 'fc7' weights[0]: 7.027006e-03 [5.339359e-08] 
Layer 'fc7' biases: 9.998587e-01 [3.352667e-08] 
Layer 'fc8' weights[0]: 1.312503e-03 [4.698276e-06] 
Layer 'fc8' biases: 6.334909e-02 [3.142430e-05] 
Train error last 870 batches: 0.435207
-------------------------------------------------------
Not saving because 0.416143 > 0.415666 (22.630: -0.00%)
======================================================= (12.070 sec)
26.201... logprob:  0.437092, 0.117188 (1.413 sec)
26.202... logprob:  0.537868, 0.148438 (1.412 sec)
26.203... logprob:  0.420417, 0.109375 (1.441 sec)
26.204... logprob:  0.504123, 0.140625 (1.400 sec)
26.205... logprob:  0.334305, 0.078125 (1.402 sec)
26.206... logprob:  0.361634, 0.093750 (1.403 sec)
26.207... logprob:  0.381794, 0.093750 (1.395 sec)
26.208... logprob:  0.490570, 0.140625 (1.396 sec)
26.209... logprob:  0.334548, 0.078125 (1.423 sec)
26.210... logprob:  0.586230, 0.171875 (1.417 sec)
26.211... logprob:  0.488138, 0.132812 (1.417 sec)
26.212... logprob:  0.526125, 0.148438 (1.410 sec)
26.213... logprob:  0.514656, 0.140625 (1.464 sec)
26.214... logprob:  0.459403, 0.125000 (1.430 sec)
26.215... logprob:  0.396103, 0.101562 (1.423 sec)
26.216... logprob:  0.516957, 0.140625 (1.469 sec)
26.217... logprob:  0.324912, 0.070312 (1.412 sec)
26.218... logprob:  0.463610, 0.125000 (1.422 sec)
26.219... logprob:  0.500244, 0.140625 (1.417 sec)
26.220... logprob:  0.415021, 0.109375 (1.419 sec)
26.221... logprob:  0.399565, 0.101562 (1.408 sec)
26.222... logprob:  0.554441, 0.164062 (1.465 sec)
26.223... logprob:  0.568997, 0.164062 (1.427 sec)
26.224... logprob:  0.405957, 0.101562 (1.432 sec)
26.225... logprob:  0.391997, 0.101562 (1.448 sec)
26.226... logprob:  0.424722, 0.109375 (1.429 sec)
26.227... logprob:  0.452646, 0.125000 (1.414 sec)
26.228... logprob:  0.417174, 0.109375 (1.420 sec)
26.229... logprob:  0.489372, 0.132812 (1.417 sec)
26.230... logprob:  0.459860, 0.125000 (1.446 sec)
26.231... logprob:  0.453499, 0.125000 (1.408 sec)
26.232... logprob:  0.496174, 0.140625 (1.468 sec)
26.233... logprob:  0.466081, 0.132812 (1.446 sec)
26.234... logprob:  0.563855, 0.164062 (1.430 sec)
26.235... logprob:  0.482015, 0.132812 (1.471 sec)
26.236... logprob:  0.425678, 0.109375 (1.415 sec)
26.237... logprob:  0.341010, 0.078125 (1.422 sec)
26.238... logprob:  0.389164, 0.093750 (1.419 sec)
26.239... logprob:  0.478098, 0.132812 (1.421 sec)
26.240... logprob:  0.485797, 0.132812 (1.407 sec)
26.241... logprob:  0.493601, 0.132812 (1.465 sec)
26.242... logprob:  0.341638, 0.078125 (1.438 sec)
26.243... logprob:  0.386001, 0.093750 (1.427 sec)
26.244... logprob:  0.315380, 0.070312 (1.453 sec)
26.245... logprob:  0.494237, 0.132812 (1.420 sec)
26.246... logprob:  0.416857, 0.109375 (1.418 sec)
26.247... logprob:  0.357530, 0.085938 (1.421 sec)
26.248... logprob:  0.307994, 0.070312 (1.415 sec)
26.249... logprob:  0.554737, 0.156250 (1.434 sec)
26.250... logprob:  0.591294, 0.164062 (1.409 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.4260139465332, 10.0]}, 128)
batch 872: ({'logprob': [67.82630920410156, 19.0]}, 128)
batch 873: ({'logprob': [39.604393005371094, 9.0]}, 128)
batch 874: ({'logprob': [44.8624267578125, 11.0]}, 128)
batch 875: ({'logprob': [50.746219635009766, 13.0]}, 128)
batch 876: ({'logprob': [65.06581115722656, 18.0]}, 128)
batch 877: ({'logprob': [45.18520736694336, 11.0]}, 128)
batch 878: ({'logprob': [62.57221984863281, 17.0]}, 128)
batch 879: ({'logprob': [74.67159271240234, 21.0]}, 128)
batch 880: ({'logprob': [50.77162551879883, 13.0]}, 128)
batch 881: ({'logprob': [27.46709442138672, 5.0]}, 128)
batch 882: ({'logprob': [54.5119514465332, 14.0]}, 128)
batch 883: ({'logprob': [62.54629898071289, 17.0]}, 128)
batch 884: ({'logprob': [51.0745849609375, 13.0]}, 128)
batch 885: ({'logprob': [51.70710754394531, 13.0]}, 128)
batch 886: ({'logprob': [62.885284423828125, 17.0]}, 128)

======================Test output======================
logprob:  0.416467, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.962444e-03 [7.990722e-09] 
Layer 'conv1' biases: 3.092306e-07 [2.059971e-10] 
Layer 'conv2' weights[0]: 7.949521e-03 [5.979385e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.233028e-09] 
Layer 'conv3' weights[0]: 7.947700e-03 [5.497539e-09] 
Layer 'conv3' biases: 2.630159e-06 [3.812721e-09] 
Layer 'conv4' weights[0]: 7.980402e-03 [5.708895e-09] 
Layer 'conv4' biases: 9.999994e-01 [3.358862e-08] 
Layer 'conv5' weights[0]: 7.979179e-03 [2.190635e-07] 
Layer 'conv5' biases: 9.999930e-01 [2.355252e-07] 
Layer 'fc6' weights[0]: 7.575830e-03 [1.826877e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.852995e-08] 
Layer 'fc7' weights[0]: 7.025222e-03 [1.736669e-07] 
Layer 'fc7' biases: 9.998590e-01 [1.638129e-07] 
Layer 'fc8' weights[0]: 1.333441e-03 [9.030301e-06] 
Layer 'fc8' biases: 6.357543e-02 [5.849267e-05] 
Train error last 870 batches: 0.435206
-------------------------------------------------------
Not saving because 0.416467 > 0.415666 (22.630: -0.00%)
======================================================= (12.031 sec)
26.251... logprob:  0.352977, 0.085938 (1.464 sec)
26.252... logprob:  0.348444, 0.085938 (1.432 sec)
26.253... logprob:  0.379212, 0.093750 (1.417 sec)
26.254... logprob:  0.444163, 0.117188 (1.471 sec)
26.255... logprob:  0.351357, 0.085938 (1.401 sec)
26.256... logprob:  0.378837, 0.093750 (1.430 sec)
26.257... logprob:  0.331983, 0.078125 (1.412 sec)
26.258... logprob:  0.415571, 0.109375 (1.425 sec)
26.259... logprob:  0.442316, 0.117188 (1.400 sec)
26.260... logprob:  0.308227, 0.070312 (1.463 sec)
26.261... logprob:  0.392612, 0.101562 (1.427 sec)
26.262... logprob:  0.524548, 0.148438 (1.428 sec)
26.263... logprob:  0.425567, 0.109375 (1.453 sec)
26.264... logprob:  0.375049, 0.093750 (1.421 sec)
26.265... logprob:  0.439610, 0.117188 (1.418 sec)
26.266... logprob:  0.439012, 0.117188 (1.416 sec)
26.267... logprob:  0.422029, 0.109375 (1.430 sec)
26.268... logprob:  0.458939, 0.125000 (1.422 sec)
26.269... logprob:  0.567550, 0.164062 (1.404 sec)
26.270... logprob:  0.542307, 0.156250 (1.467 sec)
26.271... logprob:  0.445629, 0.117188 (1.432 sec)
26.272... logprob:  0.384604, 0.093750 (1.423 sec)
26.273... logprob:  0.500229, 0.140625 (1.470 sec)
26.274... logprob:  0.542504, 0.156250 (1.403 sec)
26.275... logprob:  0.487604, 0.132812 (1.429 sec)
26.276... logprob:  0.390044, 0.093750 (1.414 sec)
26.277... logprob:  0.428625, 0.109375 (1.424 sec)
26.278... logprob:  0.323576, 0.070312 (1.433 sec)
26.279... logprob:  0.325221, 0.070312 (1.464 sec)
26.280... logprob:  0.215842, 0.031250 (1.404 sec)
26.281... logprob:  0.417242, 0.109375 (1.428 sec)
26.282... logprob:  0.411343, 0.109375 (1.417 sec)
26.283... logprob:  0.393753, 0.101562 (1.422 sec)
26.284... logprob:  0.394439, 0.101562 (1.409 sec)
26.285... logprob:  0.451554, 0.117188 (1.442 sec)
26.286... logprob:  0.536535, 0.140625 (1.437 sec)
26.287... logprob:  0.346557, 0.085938 (1.435 sec)
26.288... logprob:  0.329950, 0.078125 (1.434 sec)
26.289... logprob:  0.445844, 0.117188 (1.444 sec)
26.290... logprob:  0.490653, 0.132812 (1.422 sec)
26.291... logprob:  0.439290, 0.117188 (1.416 sec)
26.292... logprob:  0.567575, 0.156250 (1.421 sec)
26.293... logprob:  0.427703, 0.117188 (1.423 sec)
26.294... logprob:  0.355821, 0.085938 (1.407 sec)
26.295... logprob:  0.334489, 0.078125 (1.461 sec)
26.296... logprob:  0.355612, 0.085938 (1.425 sec)
26.297... logprob:  0.394436, 0.101562 (1.420 sec)
26.298... logprob:  0.448217, 0.125000 (1.465 sec)
26.299... logprob:  0.342083, 0.078125 (1.405 sec)
26.300... logprob:  0.406428, 0.101562 (1.425 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.00082015991211, 10.0]}, 128)
batch 872: ({'logprob': [66.18234252929688, 19.0]}, 128)
batch 873: ({'logprob': [41.11220932006836, 9.0]}, 128)
batch 874: ({'logprob': [45.49962615966797, 11.0]}, 128)
batch 875: ({'logprob': [50.91587448120117, 13.0]}, 128)
batch 876: ({'logprob': [63.754638671875, 18.0]}, 128)
batch 877: ({'logprob': [46.02415084838867, 11.0]}, 128)
batch 878: ({'logprob': [61.79837417602539, 17.0]}, 128)
batch 879: ({'logprob': [73.154296875, 21.0]}, 128)
batch 880: ({'logprob': [50.939208984375, 13.0]}, 128)
batch 881: ({'logprob': [29.719953536987305, 5.0]}, 128)
batch 882: ({'logprob': [54.941078186035156, 14.0]}, 128)
batch 883: ({'logprob': [61.77375030517578, 17.0]}, 128)
batch 884: ({'logprob': [51.43856430053711, 13.0]}, 128)
batch 885: ({'logprob': [52.47029495239258, 13.0]}, 128)
batch 886: ({'logprob': [62.308780670166016, 17.0]}, 128)

======================Test output======================
logprob:  0.417009, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.962404e-03 [3.661952e-09] 
Layer 'conv1' biases: 3.103380e-07 [9.538981e-11] 
Layer 'conv2' weights[0]: 7.949490e-03 [3.854104e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.000457e-10] 
Layer 'conv3' weights[0]: 7.947658e-03 [3.417268e-09] 
Layer 'conv3' biases: 2.638870e-06 [1.902829e-09] 
Layer 'conv4' weights[0]: 7.980365e-03 [3.490729e-09] 
Layer 'conv4' biases: 9.999994e-01 [1.639415e-08] 
Layer 'conv5' weights[0]: 7.979157e-03 [1.036243e-07] 
Layer 'conv5' biases: 9.999927e-01 [1.116488e-07] 
Layer 'fc6' weights[0]: 7.575792e-03 [8.617274e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.715421e-09] 
Layer 'fc7' weights[0]: 7.023452e-03 [1.456698e-07] 
Layer 'fc7' biases: 9.998579e-01 [1.338351e-07] 
Layer 'fc8' weights[0]: 1.286057e-03 [4.541837e-06] 
Layer 'fc8' biases: 6.350473e-02 [3.779307e-05] 
Train error last 870 batches: 0.435206
-------------------------------------------------------
Not saving because 0.417009 > 0.415666 (22.630: -0.00%)
======================================================= (12.046 sec)
26.301... logprob:  0.397901, 0.101562 (1.432 sec)
26.302... logprob:  0.591573, 0.179688 (1.424 sec)
26.303... logprob:  0.459516, 0.125000 (1.413 sec)
26.304... logprob:  0.459633, 0.125000 (1.438 sec)
26.305... logprob:  0.455203, 0.125000 (1.442 sec)
26.306... logprob:  0.440581, 0.117188 (1.435 sec)
26.307... logprob:  0.421620, 0.109375 (1.443 sec)
26.308... logprob:  0.374780, 0.093750 (1.458 sec)
26.309... logprob:  0.450481, 0.125000 (1.414 sec)
26.310... logprob:  0.473617, 0.125000 (1.425 sec)
26.311... logprob:  0.502504, 0.140625 (1.427 sec)
26.312... logprob:  0.478699, 0.132812 (1.432 sec)
26.313... logprob:  0.454860, 0.125000 (1.427 sec)
26.314... logprob:  0.454382, 0.117188 (1.472 sec)
26.315... logprob:  0.314676, 0.070312 (1.436 sec)
26.316... logprob:  0.468524, 0.125000 (1.422 sec)
26.317... logprob:  0.355444, 0.085938 (1.483 sec)
26.318... logprob:  0.455405, 0.125000 (1.410 sec)
26.319... logprob:  0.423175, 0.117188 (1.426 sec)
26.320... logprob:  0.412239, 0.109375 (1.432 sec)
26.321... logprob:  0.348249, 0.085938 (1.423 sec)
26.322... logprob:  0.387454, 0.101562 (1.426 sec)
26.323... logprob:  0.416508, 0.109375 (1.474 sec)
26.324... logprob:  0.498603, 0.140625 (1.434 sec)
26.325... logprob:  0.350676, 0.085938 (1.438 sec)
26.326... logprob:  0.543180, 0.148438 (1.466 sec)
26.327... logprob:  0.554408, 0.164062 (1.423 sec)
26.328... logprob:  0.565106, 0.156250 (1.427 sec)
26.329... logprob:  0.401931, 0.101562 (1.428 sec)
26.330... logprob:  0.388538, 0.101562 (1.420 sec)
26.331... logprob:  0.352319, 0.085938 (1.419 sec)
26.332... logprob:  0.482781, 0.132812 (1.449 sec)
26.333... logprob:  0.339510, 0.085938 (1.445 sec)
26.334... logprob:  0.565248, 0.171875 (1.446 sec)
26.335... logprob:  0.358725, 0.085938 (1.444 sec)
26.336... logprob:  0.444853, 0.125000 (1.456 sec)
26.337... logprob:  0.566417, 0.164062 (1.415 sec)
26.338... logprob:  0.449515, 0.125000 (1.424 sec)
26.339... logprob:  0.488612, 0.132812 (1.429 sec)
26.340... logprob:  0.442068, 0.117188 (1.431 sec)
26.341... logprob:  0.530052, 0.148438 (1.422 sec)
26.342... logprob:  0.429618, 0.109375 (1.474 sec)
26.343... logprob:  0.434769, 0.109375 (1.437 sec)
26.344... logprob:  0.444500, 0.125000 (1.479 sec)
26.345... logprob:  0.488203, 0.132812 (1.444 sec)
26.346... logprob:  0.436215, 0.117188 (1.436 sec)
26.347... logprob:  0.372498, 0.085938 (1.489 sec)
26.348... logprob:  0.398474, 0.101562 (1.431 sec)
26.349... logprob:  0.497658, 0.140625 (1.433 sec)
26.350... logprob:  0.358671, 0.085938 (1.444 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.5103645324707, 10.0]}, 128)
batch 872: ({'logprob': [66.4650650024414, 19.0]}, 128)
batch 873: ({'logprob': [40.730812072753906, 9.0]}, 128)
batch 874: ({'logprob': [45.183387756347656, 11.0]}, 128)
batch 875: ({'logprob': [50.77712631225586, 13.0]}, 128)
batch 876: ({'logprob': [63.977046966552734, 18.0]}, 128)
batch 877: ({'logprob': [45.76368713378906, 11.0]}, 128)
batch 878: ({'logprob': [62.01597595214844, 17.0]}, 128)
batch 879: ({'logprob': [73.78404998779297, 21.0]}, 128)
batch 880: ({'logprob': [50.80069351196289, 13.0]}, 128)
batch 881: ({'logprob': [28.925308227539062, 5.0]}, 128)
batch 882: ({'logprob': [55.03339385986328, 14.0]}, 128)
batch 883: ({'logprob': [61.991111755371094, 17.0]}, 128)
batch 884: ({'logprob': [51.357643127441406, 13.0]}, 128)
batch 885: ({'logprob': [52.50232696533203, 13.0]}, 128)
batch 886: ({'logprob': [62.583499908447266, 17.0]}, 128)

======================Test output======================
logprob:  0.416700, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.962357e-03 [3.395605e-09] 
Layer 'conv1' biases: 3.111633e-07 [7.227887e-11] 
Layer 'conv2' weights[0]: 7.949452e-03 [2.317856e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.548679e-10] 
Layer 'conv3' weights[0]: 7.947618e-03 [2.148931e-09] 
Layer 'conv3' biases: 2.644858e-06 [1.115456e-09] 
Layer 'conv4' weights[0]: 7.980325e-03 [2.155532e-09] 
Layer 'conv4' biases: 9.999994e-01 [9.537847e-09] 
Layer 'conv5' weights[0]: 7.979106e-03 [5.946638e-08] 
Layer 'conv5' biases: 9.999925e-01 [6.409694e-08] 
Layer 'fc6' weights[0]: 7.575753e-03 [5.004603e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.015977e-09] 
Layer 'fc7' weights[0]: 7.021653e-03 [1.744367e-07] 
Layer 'fc7' biases: 9.998584e-01 [1.633767e-07] 
Layer 'fc8' weights[0]: 1.300399e-03 [9.914464e-06] 
Layer 'fc8' biases: 6.371835e-02 [6.722146e-05] 
Train error last 870 batches: 0.435206
-------------------------------------------------------
Not saving because 0.416700 > 0.415666 (22.630: -0.00%)
======================================================= (12.069 sec)
26.351... logprob:  0.508530, 0.140625 (1.436 sec)
26.352... logprob:  0.363621, 0.093750 (1.443 sec)
26.353... logprob:  0.512528, 0.148438 (1.485 sec)
26.354... logprob:  0.674873, 0.203125 (1.435 sec)
26.355... logprob:  0.357492, 0.085938 (1.448 sec)
26.356... logprob:  0.479240, 0.132812 (1.475 sec)
26.357... logprob:  0.346800, 0.085938 (1.435 sec)
26.358... logprob:  0.325813, 0.070312 (1.440 sec)
26.359... logprob:  0.555342, 0.164062 (1.433 sec)
26.360... logprob:  0.444520, 0.117188 (1.432 sec)
26.361... logprob:  0.410744, 0.101562 (1.435 sec)
26.362... logprob:  0.423986, 0.117188 (1.479 sec)
26.363... logprob:  0.486588, 0.132812 (1.444 sec)
26.364... logprob:  0.475595, 0.125000 (1.451 sec)
26.365... logprob:  0.425051, 0.109375 (1.470 sec)
26.366... logprob:  0.409597, 0.109375 (1.445 sec)
26.367... logprob:  0.324926, 0.078125 (1.437 sec)
26.368... logprob:  0.595582, 0.171875 (1.436 sec)
26.369... logprob:  0.381634, 0.093750 (1.428 sec)
26.370... logprob:  0.381266, 0.093750 (1.436 sec)
26.371... logprob:  0.400406, 0.101562 (1.459 sec)
26.372... logprob:  0.537312, 0.156250 (1.460 sec)
26.373... logprob:  0.463797, 0.125000 (1.451 sec)
26.374... logprob:  0.526876, 0.148438 (1.483 sec)
26.375... logprob:  0.393770, 0.101562 (1.465 sec)
26.376... logprob:  0.374292, 0.093750 (1.440 sec)
26.377... logprob:  0.295421, 0.062500 (1.427 sec)
26.378... logprob:  0.453687, 0.125000 (1.430 sec)
26.379... logprob:  0.420242, 0.109375 (1.441 sec)
26.380... logprob:  0.605694, 0.179688 (1.441 sec)
26.381... logprob:  0.463428, 0.125000 (1.470 sec)
26.382... logprob:  0.529565, 0.148438 (1.455 sec)
26.383... logprob:  0.358563, 0.085938 (1.440 sec)
26.384... logprob:  0.521177, 0.148438 (1.481 sec)
26.385... logprob:  0.523560, 0.148438 (1.436 sec)
26.386... logprob:  0.582527, 0.171875 (1.429 sec)
26.387... logprob:  0.428546, 0.117188 (1.438 sec)
26.388... logprob:  0.521363, 0.148438 (1.434 sec)
26.389... logprob:  0.425644, 0.109375 (1.438 sec)
26.390... logprob:  0.419727, 0.109375 (1.479 sec)
26.391... logprob:  0.318201, 0.070312 (1.443 sec)
26.392... logprob:  0.439447, 0.117188 (1.439 sec)
26.393... logprob:  0.368990, 0.093750 (1.484 sec)
26.394... logprob:  0.343658, 0.078125 (1.523 sec)
26.395... logprob:  0.331828, 0.078125 (1.430 sec)
26.396... logprob:  0.252431, 0.046875 (1.440 sec)
26.397... logprob:  0.484231, 0.132812 (1.431 sec)
26.398... logprob:  0.470833, 0.125000 (1.436 sec)
26.399... logprob:  0.433279, 0.117188 (1.488 sec)
26.400... logprob:  0.537682, 0.148438 (1.429 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.652706146240234, 10.0]}, 128)
batch 872: ({'logprob': [68.74887084960938, 19.0]}, 128)
batch 873: ({'logprob': [39.648502349853516, 9.0]}, 128)
batch 874: ({'logprob': [44.73200607299805, 11.0]}, 128)
batch 875: ({'logprob': [51.02472686767578, 13.0]}, 128)
batch 876: ({'logprob': [65.92985534667969, 18.0]}, 128)
batch 877: ({'logprob': [45.34540557861328, 11.0]}, 128)
batch 878: ({'logprob': [63.66876983642578, 17.0]}, 128)
batch 879: ({'logprob': [76.87635803222656, 21.0]}, 128)
batch 880: ({'logprob': [51.049827575683594, 13.0]}, 128)
batch 881: ({'logprob': [26.400527954101562, 5.0]}, 128)
batch 882: ({'logprob': [55.72498321533203, 14.0]}, 128)
batch 883: ({'logprob': [63.64299011230469, 17.0]}, 128)
batch 884: ({'logprob': [51.64658737182617, 13.0]}, 128)
batch 885: ({'logprob': [52.86240005493164, 13.0]}, 128)
batch 886: ({'logprob': [64.27469635009766, 17.0]}, 128)

======================Test output======================
logprob:  0.421010, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.962317e-03 [5.335259e-09] 
Layer 'conv1' biases: 3.121431e-07 [1.955876e-10] 
Layer 'conv2' weights[0]: 7.949413e-03 [5.676616e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.178750e-09] 
Layer 'conv3' weights[0]: 7.947577e-03 [5.295534e-09] 
Layer 'conv3' biases: 2.652253e-06 [3.565355e-09] 
Layer 'conv4' weights[0]: 7.980288e-03 [5.461149e-09] 
Layer 'conv4' biases: 9.999993e-01 [3.116861e-08] 
Layer 'conv5' weights[0]: 7.979062e-03 [1.980266e-07] 
Layer 'conv5' biases: 9.999922e-01 [2.130418e-07] 
Layer 'fc6' weights[0]: 7.575708e-03 [1.658836e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.688502e-08] 
Layer 'fc7' weights[0]: 7.019868e-03 [4.388779e-08] 
Layer 'fc7' biases: 9.998603e-01 [2.127281e-08] 
Layer 'fc8' weights[0]: 1.360306e-03 [5.147682e-06] 
Layer 'fc8' biases: 6.424657e-02 [3.066066e-05] 
Train error last 870 batches: 0.435205
-------------------------------------------------------
Not saving because 0.421010 > 0.415666 (22.630: -0.00%)
======================================================= (12.074 sec)
26.401... logprob:  0.465751, 0.125000 (1.453 sec)
26.402... logprob:  0.473920, 0.125000 (1.490 sec)
26.403... logprob:  0.462128, 0.125000 (1.438 sec)
26.404... logprob:  0.474813, 0.125000 (1.438 sec)
26.405... logprob:  0.544182, 0.156250 (1.437 sec)
26.406... logprob:  0.357619, 0.085938 (1.429 sec)
26.407... logprob:  0.492956, 0.140625 (1.456 sec)
26.408... logprob:  0.339040, 0.078125 (1.488 sec)
26.409... logprob:  0.400529, 0.101562 (1.439 sec)
26.410... logprob:  0.582180, 0.171875 (1.452 sec)
26.411... logprob:  0.397850, 0.101562 (1.473 sec)
26.412... logprob:  0.540295, 0.156250 (1.438 sec)
26.413... logprob:  0.544667, 0.156250 (1.440 sec)
26.414... logprob:  0.466431, 0.125000 (1.431 sec)
26.415... logprob:  0.401686, 0.101562 (1.431 sec)
26.416... logprob:  0.427513, 0.109375 (1.437 sec)
26.417... logprob:  0.405460, 0.093750 (1.465 sec)
26.418... logprob:  0.380383, 0.093750 (1.452 sec)
26.419... logprob:  0.417811, 0.101562 (1.458 sec)
26.420... logprob:  0.356350, 0.085938 (1.455 sec)
26.421... logprob:  0.376624, 0.101562 (1.461 sec)
26.422... logprob:  0.522301, 0.148438 (1.437 sec)
26.423... logprob:  0.420851, 0.109375 (1.429 sec)
26.424... logprob:  0.324838, 0.078125 (1.429 sec)
26.425... logprob:  0.306418, 0.070312 (1.445 sec)
26.426... logprob:  0.449117, 0.117188 (1.446 sec)
26.427... logprob:  0.554276, 0.156250 (1.463 sec)
26.428... logprob:  0.601745, 0.171875 (1.459 sec)
26.429... logprob:  0.426336, 0.109375 (1.439 sec)
26.430... logprob:  0.299811, 0.070312 (1.481 sec)
26.431... logprob:  0.599884, 0.171875 (1.435 sec)
26.432... logprob:  0.387537, 0.093750 (1.426 sec)
26.433... logprob:  0.329757, 0.078125 (1.436 sec)
26.434... logprob:  0.529514, 0.148438 (1.443 sec)
26.435... logprob:  0.532411, 0.156250 (1.431 sec)
26.436... logprob:  0.381087, 0.093750 (1.481 sec)
26.437... logprob:  0.500302, 0.140625 (1.444 sec)
26.438... logprob:  0.546941, 0.156250 (1.434 sec)
26.439... logprob:  0.378742, 0.093750 (1.490 sec)
26.440... logprob:  0.439714, 0.117188 (1.437 sec)
26.441... logprob:  0.467976, 0.125000 (1.430 sec)
26.442... logprob:  0.378935, 0.093750 (1.439 sec)
26.443... logprob:  0.496566, 0.140625 (1.431 sec)
26.444... logprob:  0.372343, 0.093750 (1.440 sec)
26.445... logprob:  0.362525, 0.085938 (1.482 sec)
26.446... logprob:  0.398322, 0.101562 (1.435 sec)
26.447... logprob:  0.569714, 0.164062 (1.440 sec)
26.448... logprob:  0.332886, 0.078125 (1.508 sec)
26.449... logprob:  0.400036, 0.101562 (1.432 sec)
26.450... logprob:  0.239508, 0.046875 (1.433 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.051395416259766, 10.0]}, 128)
batch 872: ({'logprob': [67.61437225341797, 19.0]}, 128)
batch 873: ({'logprob': [39.82067108154297, 9.0]}, 128)
batch 874: ({'logprob': [44.78070831298828, 11.0]}, 128)
batch 875: ({'logprob': [50.72114181518555, 13.0]}, 128)
batch 876: ({'logprob': [64.91366577148438, 18.0]}, 128)
batch 877: ({'logprob': [45.28022384643555, 11.0]}, 128)
batch 878: ({'logprob': [62.657894134521484, 17.0]}, 128)
batch 879: ({'logprob': [75.0444564819336, 21.0]}, 128)
batch 880: ({'logprob': [50.745731353759766, 13.0]}, 128)
batch 881: ({'logprob': [27.395566940307617, 5.0]}, 128)
batch 882: ({'logprob': [54.955848693847656, 14.0]}, 128)
batch 883: ({'logprob': [62.63254165649414, 17.0]}, 128)
batch 884: ({'logprob': [51.22567367553711, 13.0]}, 128)
batch 885: ({'logprob': [52.21174240112305, 13.0]}, 128)
batch 886: ({'logprob': [63.1477165222168, 17.0]}, 128)

======================Test output======================
logprob:  0.417090, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.962276e-03 [4.401761e-09] 
Layer 'conv1' biases: 3.130329e-07 [1.480453e-10] 
Layer 'conv2' weights[0]: 7.949377e-03 [4.479640e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.137446e-10] 
Layer 'conv3' weights[0]: 7.947543e-03 [4.106531e-09] 
Layer 'conv3' biases: 2.659348e-06 [2.503043e-09] 
Layer 'conv4' weights[0]: 7.980239e-03 [4.214930e-09] 
Layer 'conv4' biases: 9.999993e-01 [2.151716e-08] 
Layer 'conv5' weights[0]: 7.979025e-03 [1.381466e-07] 
Layer 'conv5' biases: 9.999922e-01 [1.485969e-07] 
Layer 'fc6' weights[0]: 7.575666e-03 [1.142391e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.169251e-08] 
Layer 'fc7' weights[0]: 7.018107e-03 [3.757022e-07] 
Layer 'fc7' biases: 9.998590e-01 [3.649438e-07] 
Layer 'fc8' weights[0]: 1.326539e-03 [1.381558e-05] 
Layer 'fc8' biases: 6.442674e-02 [9.537790e-05] 
Train error last 870 batches: 0.435205
-------------------------------------------------------
Not saving because 0.417090 > 0.415666 (22.630: -0.00%)
======================================================= (12.062 sec)
26.451... logprob:  0.452646, 0.125000 (1.448 sec)
26.452... logprob:  0.456094, 0.117188 (1.434 sec)
26.453... logprob:  0.455211, 0.125000 (1.435 sec)
26.454... logprob:  0.488982, 0.132812 (1.493 sec)
26.455... logprob:  0.506059, 0.140625 (1.454 sec)
26.456... logprob:  0.468838, 0.125000 (1.457 sec)
26.457... logprob:  0.375337, 0.093750 (1.492 sec)
26.458... logprob:  0.351028, 0.085938 (1.448 sec)
26.459... logprob:  0.513968, 0.140625 (1.444 sec)
26.460... logprob:  0.273907, 0.054688 (1.445 sec)
26.461... logprob:  0.460092, 0.125000 (1.431 sec)
26.462... logprob:  0.471969, 0.125000 (1.444 sec)
26.463... logprob:  0.420840, 0.109375 (1.482 sec)
26.464... logprob:  0.482764, 0.132812 (1.453 sec)
26.465... logprob:  0.421133, 0.109375 (1.455 sec)
26.466... logprob:  0.318376, 0.070312 (1.462 sec)
26.467... logprob:  0.413839, 0.109375 (1.459 sec)
26.468... logprob:  0.394265, 0.101562 (1.449 sec)
26.469... logprob:  0.334763, 0.078125 (1.432 sec)
26.470... logprob:  0.400090, 0.101562 (1.427 sec)
26.471... logprob:  0.529317, 0.148438 (1.454 sec)
26.472... logprob:  0.410004, 0.109375 (1.459 sec)
26.473... logprob:  0.375440, 0.093750 (1.462 sec)
26.474... logprob:  0.465588, 0.125000 (1.462 sec)
26.475... logprob:  0.504037, 0.140625 (1.466 sec)
26.476... logprob:  0.510243, 0.140625 (1.485 sec)
26.477... logprob:  0.334605, 0.078125 (1.454 sec)
26.478... logprob:  0.464247, 0.125000 (1.444 sec)
26.479... logprob:  0.305772, 0.070312 (1.450 sec)
26.480... logprob:  0.443507, 0.117188 (1.457 sec)
26.481... logprob:  0.547801, 0.156250 (1.485 sec)
26.482... logprob:  0.443148, 0.117188 (1.491 sec)
26.483... logprob:  0.502670, 0.140625 (1.465 sec)
26.484... logprob:  0.485312, 0.132812 (1.445 sec)
26.485... logprob:  0.408965, 0.109375 (1.490 sec)
26.486... logprob:  0.361361, 0.085938 (1.436 sec)
26.487... logprob:  0.522676, 0.148438 (1.440 sec)
26.488... logprob:  0.424754, 0.109375 (1.437 sec)
26.489... logprob:  0.415854, 0.109375 (1.443 sec)
26.490... logprob:  0.440692, 0.117188 (1.451 sec)
26.491... logprob:  0.313635, 0.070312 (1.490 sec)
26.492... logprob:  0.459544, 0.125000 (1.440 sec)
26.493... logprob:  0.521834, 0.148438 (1.434 sec)
26.494... logprob:  0.450353, 0.125000 (1.494 sec)
26.495... logprob:  0.380653, 0.093750 (1.442 sec)
26.496... logprob:  0.550283, 0.156250 (1.440 sec)
26.497... logprob:  0.466930, 0.125000 (1.448 sec)
26.498... logprob:  0.476242, 0.132812 (1.437 sec)
26.499... logprob:  0.456236, 0.125000 (1.441 sec)
26.500... logprob:  0.355138, 0.085938 (1.498 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.03138732910156, 10.0]}, 128)
batch 872: ({'logprob': [66.30278015136719, 19.0]}, 128)
batch 873: ({'logprob': [40.93447494506836, 9.0]}, 128)
batch 874: ({'logprob': [45.450828552246094, 11.0]}, 128)
batch 875: ({'logprob': [50.88029098510742, 13.0]}, 128)
batch 876: ({'logprob': [63.83974075317383, 18.0]}, 128)
batch 877: ({'logprob': [45.91767501831055, 11.0]}, 128)
batch 878: ({'logprob': [61.790374755859375, 17.0]}, 128)
batch 879: ({'logprob': [73.1163101196289, 21.0]}, 128)
batch 880: ({'logprob': [50.90406036376953, 13.0]}, 128)
batch 881: ({'logprob': [29.572397232055664, 5.0]}, 128)
batch 882: ({'logprob': [54.7690544128418, 14.0]}, 128)
batch 883: ({'logprob': [61.76541519165039, 17.0]}, 128)
batch 884: ({'logprob': [51.34611511230469, 13.0]}, 128)
batch 885: ({'logprob': [52.26290512084961, 13.0]}, 128)
batch 886: ({'logprob': [62.24347686767578, 17.0]}, 128)

======================Test output======================
logprob:  0.416566, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.962237e-03 [2.720555e-09] 
Layer 'conv1' biases: 3.140104e-07 [4.885228e-11] 
Layer 'conv2' weights[0]: 7.949340e-03 [2.136641e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.422245e-10] 
Layer 'conv3' weights[0]: 7.947511e-03 [1.823749e-09] 
Layer 'conv3' biases: 2.670106e-06 [8.151473e-10] 
Layer 'conv4' weights[0]: 7.980196e-03 [1.972546e-09] 
Layer 'conv4' biases: 9.999993e-01 [7.367813e-09] 
Layer 'conv5' weights[0]: 7.978998e-03 [4.830103e-08] 
Layer 'conv5' biases: 9.999927e-01 [5.194284e-08] 
Layer 'fc6' weights[0]: 7.575624e-03 [4.062792e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.043909e-09] 
Layer 'fc7' weights[0]: 7.016303e-03 [3.837317e-08] 
Layer 'fc7' biases: 9.998578e-01 [1.220571e-08] 
Layer 'fc8' weights[0]: 1.279608e-03 [2.560371e-06] 
Layer 'fc8' biases: 6.425965e-02 [1.660532e-05] 
Train error last 870 batches: 0.435205
-------------------------------------------------------
Not saving because 0.416566 > 0.415666 (22.630: -0.00%)
======================================================= (12.207 sec)
26.501... logprob:  0.339122, 0.078125 (1.439 sec)
26.502... logprob:  0.459617, 0.125000 (1.446 sec)
26.503... logprob:  0.400668, 0.101562 (1.477 sec)
26.504... logprob:  0.487295, 0.132812 (1.433 sec)
26.505... logprob:  0.570782, 0.164062 (1.440 sec)
26.506... logprob:  0.479685, 0.132812 (1.438 sec)
26.507... logprob:  0.385054, 0.093750 (1.427 sec)
26.508... logprob:  0.374679, 0.093750 (1.440 sec)
26.509... logprob:  0.323047, 0.070312 (1.495 sec)
26.510... logprob:  0.390462, 0.101562 (1.442 sec)
26.511... logprob:  0.410053, 0.109375 (1.451 sec)
26.512... logprob:  0.470722, 0.125000 (1.465 sec)
26.513... logprob:  0.324964, 0.078125 (1.451 sec)
26.514... logprob:  0.406273, 0.101562 (1.447 sec)
26.515... logprob:  0.455495, 0.125000 (1.429 sec)
26.516... logprob:  0.400295, 0.109375 (1.431 sec)
26.517... logprob:  0.627809, 0.179688 (1.436 sec)
26.518... logprob:  0.437659, 0.117188 (1.463 sec)
26.519... logprob:  0.516133, 0.140625 (1.455 sec)
26.520... logprob:  0.409645, 0.109375 (1.458 sec)
26.521... logprob:  0.427449, 0.109375 (1.450 sec)
26.522... logprob:  0.533142, 0.156250 (1.462 sec)
26.523... logprob:  0.331560, 0.078125 (1.443 sec)
26.524... logprob:  0.437166, 0.117188 (1.425 sec)
26.525... logprob:  0.425944, 0.109375 (1.434 sec)
26.526... logprob:  0.351730, 0.078125 (1.438 sec)
26.527... logprob:  0.504570, 0.140625 (1.445 sec)
26.528... logprob:  0.440469, 0.117188 (1.466 sec)
26.529... logprob:  0.353002, 0.085938 (1.450 sec)
26.530... logprob:  0.440252, 0.117188 (1.438 sec)
26.531... logprob:  0.439964, 0.117188 (1.484 sec)
26.532... logprob:  0.467333, 0.125000 (1.431 sec)
26.533... logprob:  0.560412, 0.164062 (1.434 sec)
26.534... logprob:  0.325901, 0.078125 (1.436 sec)
26.535... logprob:  0.551490, 0.156250 (1.437 sec)
26.536... logprob:  0.507298, 0.140625 (1.434 sec)
26.537... logprob:  0.510019, 0.140625 (1.482 sec)
26.538... logprob:  0.486088, 0.132812 (1.443 sec)
26.539... logprob:  0.296053, 0.062500 (1.435 sec)
26.540... logprob:  0.447177, 0.117188 (1.487 sec)
26.541... logprob:  0.388812, 0.101562 (1.438 sec)
26.542... logprob:  0.411254, 0.109375 (1.430 sec)
26.543... logprob:  0.233249, 0.039062 (1.440 sec)
26.544... logprob:  0.317926, 0.070312 (1.435 sec)
26.545... logprob:  0.348801, 0.085938 (1.430 sec)
26.546... logprob:  0.368274, 0.093750 (1.480 sec)
26.547... logprob:  0.440044, 0.117188 (1.438 sec)
26.548... logprob:  0.452951, 0.125000 (1.442 sec)
26.549... logprob:  0.490495, 0.132812 (1.483 sec)
26.550... logprob:  0.367627, 0.093750 (1.438 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.84949493408203, 10.0]}, 128)
batch 872: ({'logprob': [68.39276885986328, 19.0]}, 128)
batch 873: ({'logprob': [39.574337005615234, 9.0]}, 128)
batch 874: ({'logprob': [44.71732711791992, 11.0]}, 128)
batch 875: ({'logprob': [50.876564025878906, 13.0]}, 128)
batch 876: ({'logprob': [65.59229278564453, 18.0]}, 128)
batch 877: ({'logprob': [45.234642028808594, 11.0]}, 128)
batch 878: ({'logprob': [63.25374221801758, 17.0]}, 128)
batch 879: ({'logprob': [76.09857940673828, 21.0]}, 128)
batch 880: ({'logprob': [50.9018440246582, 13.0]}, 128)
batch 881: ({'logprob': [26.690086364746094, 5.0]}, 128)
batch 882: ({'logprob': [55.269039154052734, 14.0]}, 128)
batch 883: ({'logprob': [63.227725982666016, 17.0]}, 128)
batch 884: ({'logprob': [51.401676177978516, 13.0]}, 128)
batch 885: ({'logprob': [52.424896240234375, 13.0]}, 128)
batch 886: ({'logprob': [63.76310348510742, 17.0]}, 128)

======================Test output======================
logprob:  0.419076, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.962200e-03 [3.697754e-09] 
Layer 'conv1' biases: 3.148915e-07 [8.530474e-11] 
Layer 'conv2' weights[0]: 7.949299e-03 [3.521126e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.643346e-10] 
Layer 'conv3' weights[0]: 7.947471e-03 [2.943169e-09] 
Layer 'conv3' biases: 2.677739e-06 [1.754025e-09] 
Layer 'conv4' weights[0]: 7.980165e-03 [3.041347e-09] 
Layer 'conv4' biases: 9.999993e-01 [1.411214e-08] 
Layer 'conv5' weights[0]: 7.978940e-03 [8.537545e-08] 
Layer 'conv5' biases: 9.999923e-01 [9.199857e-08] 
Layer 'fc6' weights[0]: 7.575582e-03 [7.157359e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.277937e-09] 
Layer 'fc7' weights[0]: 7.014546e-03 [4.982476e-08] 
Layer 'fc7' biases: 9.998598e-01 [2.921629e-08] 
Layer 'fc8' weights[0]: 1.342274e-03 [7.108866e-06] 
Layer 'fc8' biases: 6.478729e-02 [4.174684e-05] 
Train error last 870 batches: 0.435204
-------------------------------------------------------
Not saving because 0.419076 > 0.415666 (22.630: -0.00%)
======================================================= (12.005 sec)
26.551... logprob:  0.441668, 0.117188 (1.438 sec)
26.552... logprob:  0.471272, 0.125000 (1.437 sec)
26.553... logprob:  0.349446, 0.085938 (1.427 sec)
26.554... logprob:  0.506950, 0.140625 (1.439 sec)
26.555... logprob:  0.421408, 0.109375 (1.479 sec)
26.556... logprob:  0.355819, 0.085938 (1.442 sec)
26.557... logprob:  0.396389, 0.101562 (1.450 sec)
26.558... logprob:  0.383017, 0.101562 (1.472 sec)
26.559... logprob:  0.441572, 0.125000 (1.442 sec)
26.560... logprob:  0.335113, 0.078125 (1.437 sec)
26.561... logprob:  0.411802, 0.109375 (1.436 sec)
26.562... logprob:  0.503145, 0.140625 (1.425 sec)
26.563... logprob:  0.373786, 0.093750 (1.443 sec)
26.564... logprob:  0.468469, 0.132812 (1.463 sec)
26.565... logprob:  0.611119, 0.187500 (1.451 sec)
26.566... logprob:  0.374881, 0.093750 (1.455 sec)
26.567... logprob:  0.423341, 0.109375 (1.459 sec)
26.568... logprob:  0.496339, 0.140625 (1.455 sec)
26.569... logprob:  0.507732, 0.140625 (1.445 sec)
26.570... logprob:  0.543770, 0.164062 (1.424 sec)
26.571... logprob:  0.454882, 0.125000 (1.437 sec)
26.572... logprob:  0.501396, 0.140625 (1.443 sec)
26.573... logprob:  0.512603, 0.148438 (1.452 sec)
26.574... logprob:  0.428061, 0.109375 (1.461 sec)
26.575... logprob:  0.343333, 0.078125 (1.458 sec)
26.576... logprob:  0.427368, 0.109375 (1.441 sec)
26.577... logprob:  0.460801, 0.125000 (1.476 sec)
26.578... logprob:  0.336720, 0.078125 (1.431 sec)
26.579... logprob:  0.442080, 0.117188 (1.429 sec)
26.580... logprob:  0.546726, 0.156250 (1.443 sec)
26.581... logprob:  0.530737, 0.156250 (1.439 sec)
26.582... logprob:  0.437826, 0.125000 (1.435 sec)
26.583... logprob:  0.592550, 0.171875 (1.479 sec)
26.584... logprob:  0.468086, 0.132812 (1.450 sec)
26.585... logprob:  0.349764, 0.085938 (1.430 sec)
26.586... logprob:  0.313087, 0.070312 (1.493 sec)
26.587... logprob:  0.404301, 0.101562 (1.434 sec)
26.588... logprob:  0.418659, 0.117188 (1.448 sec)
26.589... logprob:  0.361195, 0.093750 (1.434 sec)
26.590... logprob:  0.524753, 0.148438 (1.431 sec)
26.591... logprob:  0.397474, 0.101562 (1.429 sec)
26.592... logprob:  0.455668, 0.125000 (1.483 sec)
26.593... logprob:  0.467421, 0.125000 (1.434 sec)
26.594... logprob:  0.352841, 0.085938 (1.446 sec)
26.595... logprob:  0.428661, 0.109375 (1.483 sec)
26.596... logprob:  0.461604, 0.125000 (1.432 sec)
26.597... logprob:  0.397415, 0.101562 (1.437 sec)
26.598... logprob:  0.397220, 0.101562 (1.435 sec)
26.599... logprob:  0.313560, 0.070312 (1.434 sec)
26.600... logprob:  0.340886, 0.085938 (1.431 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.993186950683594, 10.0]}, 128)
batch 872: ({'logprob': [66.86256408691406, 19.0]}, 128)
batch 873: ({'logprob': [40.53464889526367, 9.0]}, 128)
batch 874: ({'logprob': [44.959007263183594, 11.0]}, 128)
batch 875: ({'logprob': [50.76911926269531, 13.0]}, 128)
batch 876: ({'logprob': [64.32794189453125, 18.0]}, 128)
batch 877: ({'logprob': [45.66119384765625, 11.0]}, 128)
batch 878: ({'logprob': [62.44187545776367, 17.0]}, 128)
batch 879: ({'logprob': [74.76551818847656, 21.0]}, 128)
batch 880: ({'logprob': [50.79276657104492, 13.0]}, 128)
batch 881: ({'logprob': [28.17237091064453, 5.0]}, 128)
batch 882: ({'logprob': [55.441017150878906, 14.0]}, 128)
batch 883: ({'logprob': [62.41672897338867, 17.0]}, 128)
batch 884: ({'logprob': [51.4737434387207, 13.0]}, 128)
batch 885: ({'logprob': [52.86353302001953, 13.0]}, 128)
batch 886: ({'logprob': [63.132720947265625, 17.0]}, 128)

======================Test output======================
logprob:  0.417777, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.962161e-03 [3.032624e-09] 
Layer 'conv1' biases: 3.160395e-07 [1.050994e-10] 
Layer 'conv2' weights[0]: 7.949256e-03 [2.726248e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.364517e-10] 
Layer 'conv3' weights[0]: 7.947429e-03 [2.661405e-09] 
Layer 'conv3' biases: 2.686422e-06 [1.645075e-09] 
Layer 'conv4' weights[0]: 7.980120e-03 [2.740931e-09] 
Layer 'conv4' biases: 9.999994e-01 [1.437877e-08] 
Layer 'conv5' weights[0]: 7.978902e-03 [9.237774e-08] 
Layer 'conv5' biases: 9.999923e-01 [9.942922e-08] 
Layer 'fc6' weights[0]: 7.575547e-03 [7.713419e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.834094e-09] 
Layer 'fc7' weights[0]: 7.012720e-03 [1.543750e-07] 
Layer 'fc7' biases: 9.998589e-01 [1.430521e-07] 
Layer 'fc8' weights[0]: 1.309499e-03 [7.020062e-06] 
Layer 'fc8' biases: 6.467672e-02 [4.577676e-05] 
Train error last 870 batches: 0.435204
-------------------------------------------------------
Not saving because 0.417777 > 0.415666 (22.630: -0.00%)
======================================================= (12.089 sec)
26.601... logprob:  0.402144, 0.101562 (1.497 sec)
26.602... logprob:  0.289829, 0.062500 (1.444 sec)
26.603... logprob:  0.267121, 0.054688 (1.584 sec)
26.604... logprob:  0.407520, 0.101562 (1.477 sec)
26.605... logprob:  0.563370, 0.148438 (1.435 sec)
26.606... logprob:  0.295943, 0.070312 (1.442 sec)
26.607... logprob:  0.504756, 0.132812 (1.434 sec)
26.608... logprob:  0.361812, 0.085938 (1.426 sec)
26.609... logprob:  0.357007, 0.085938 (1.440 sec)
26.610... logprob:  0.493333, 0.132812 (1.475 sec)
26.611... logprob:  0.510369, 0.140625 (1.450 sec)
26.612... logprob:  0.448490, 0.117188 (1.460 sec)
26.613... logprob:  0.279476, 0.062500 (1.459 sec)
26.614... logprob:  0.503557, 0.140625 (1.453 sec)
26.615... logprob:  0.350915, 0.085938 (1.438 sec)
26.616... logprob:  0.415141, 0.109375 (1.432 sec)
26.617... logprob:  0.417870, 0.109375 (1.426 sec)
26.618... logprob:  0.546928, 0.156250 (1.442 sec)
26.619... logprob:  0.506062, 0.140625 (1.454 sec)
26.620... logprob:  0.539677, 0.156250 (1.463 sec)
26.621... logprob:  0.363679, 0.085938 (1.459 sec)
26.622... logprob:  0.364753, 0.085938 (1.449 sec)
26.623... logprob:  0.423153, 0.109375 (1.471 sec)
26.624... logprob:  0.382524, 0.093750 (1.442 sec)
26.625... logprob:  0.440987, 0.117188 (1.426 sec)
26.626... logprob:  0.438361, 0.117188 (1.430 sec)
26.627... logprob:  0.435834, 0.117188 (1.438 sec)
26.628... logprob:  0.465040, 0.125000 (1.444 sec)
26.629... logprob:  0.372102, 0.093750 (1.470 sec)
26.630... logprob:  0.422379, 0.109375 (1.449 sec)
26.631... logprob:  0.638680, 0.187500 (1.439 sec)
26.632... logprob:  0.399113, 0.101562 (1.488 sec)
26.633... logprob:  0.376086, 0.093750 (1.435 sec)
26.634... logprob:  0.660189, 0.195312 (1.432 sec)
26.635... logprob:  0.374119, 0.093750 (1.433 sec)
26.636... logprob:  0.480254, 0.132812 (1.441 sec)
26.637... logprob:  0.330797, 0.078125 (1.431 sec)
26.638... logprob:  0.515697, 0.140625 (1.484 sec)
26.639... logprob:  0.418064, 0.109375 (1.439 sec)
26.640... logprob:  0.528754, 0.148438 (1.442 sec)
26.641... logprob:  0.410430, 0.109375 (1.493 sec)
26.642... logprob:  0.500878, 0.140625 (1.434 sec)
26.643... logprob:  0.623148, 0.187500 (1.433 sec)
26.644... logprob:  0.321077, 0.070312 (1.439 sec)
26.645... logprob:  0.414469, 0.109375 (1.433 sec)
26.646... logprob:  0.385626, 0.093750 (1.429 sec)
26.647... logprob:  0.456781, 0.125000 (1.485 sec)
26.648... logprob:  0.491257, 0.140625 (1.434 sec)
26.649... logprob:  0.370257, 0.093750 (1.447 sec)
26.650... logprob:  0.414004, 0.109375 (1.478 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.98765563964844, 10.0]}, 128)
batch 872: ({'logprob': [66.3346176147461, 19.0]}, 128)
batch 873: ({'logprob': [40.883026123046875, 9.0]}, 128)
batch 874: ({'logprob': [45.4157829284668, 11.0]}, 128)
batch 875: ({'logprob': [50.861854553222656, 13.0]}, 128)
batch 876: ({'logprob': [63.863609313964844, 18.0]}, 128)
batch 877: ({'logprob': [45.88282012939453, 11.0]}, 128)
batch 878: ({'logprob': [61.805843353271484, 17.0]}, 128)
batch 879: ({'logprob': [73.16543579101562, 21.0]}, 128)
batch 880: ({'logprob': [50.88579559326172, 13.0]}, 128)
batch 881: ({'logprob': [29.486957550048828, 5.0]}, 128)
batch 882: ({'logprob': [54.75965881347656, 14.0]}, 128)
batch 883: ({'logprob': [61.78059005737305, 17.0]}, 128)
batch 884: ({'logprob': [51.32813262939453, 13.0]}, 128)
batch 885: ({'logprob': [52.24506759643555, 13.0]}, 128)
batch 886: ({'logprob': [62.25910949707031, 17.0]}, 128)

======================Test output======================
logprob:  0.416478, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.962131e-03 [2.585745e-09] 
Layer 'conv1' biases: 3.170265e-07 [7.281685e-11] 
Layer 'conv2' weights[0]: 7.949216e-03 [2.076797e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.058816e-10] 
Layer 'conv3' weights[0]: 7.947386e-03 [2.046113e-09] 
Layer 'conv3' biases: 2.694769e-06 [1.219568e-09] 
Layer 'conv4' weights[0]: 7.980083e-03 [2.272740e-09] 
Layer 'conv4' biases: 9.999994e-01 [1.197600e-08] 
Layer 'conv5' weights[0]: 7.978865e-03 [7.883423e-08] 
Layer 'conv5' biases: 9.999923e-01 [8.491586e-08] 
Layer 'fc6' weights[0]: 7.575506e-03 [6.484314e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.599090e-09] 
Layer 'fc7' weights[0]: 7.010935e-03 [2.336161e-07] 
Layer 'fc7' biases: 9.998577e-01 [2.224612e-07] 
Layer 'fc8' weights[0]: 1.284414e-03 [1.025009e-05] 
Layer 'fc8' biases: 6.466209e-02 [7.126549e-05] 
Train error last 870 batches: 0.435204
-------------------------------------------------------
Not saving because 0.416478 > 0.415666 (22.630: -0.00%)
======================================================= (12.057 sec)
26.651... logprob:  0.397379, 0.101562 (1.438 sec)
26.652... logprob:  0.507168, 0.140625 (1.440 sec)
26.653... logprob:  0.547831, 0.156250 (1.442 sec)
26.654... logprob:  0.496041, 0.140625 (1.435 sec)
26.655... logprob:  0.436185, 0.117188 (1.437 sec)
26.656... logprob:  0.416703, 0.109375 (1.475 sec)
26.657... logprob:  0.449111, 0.117188 (1.441 sec)
26.658... logprob:  0.345848, 0.085938 (1.453 sec)
26.659... logprob:  0.464302, 0.125000 (1.472 sec)
26.660... logprob:  0.446002, 0.125000 (1.447 sec)
26.661... logprob:  0.378445, 0.093750 (1.438 sec)
26.662... logprob:  0.469427, 0.132812 (1.434 sec)
26.663... logprob:  0.310908, 0.070312 (1.424 sec)
26.664... logprob:  0.285392, 0.062500 (1.441 sec)
26.665... logprob:  0.401728, 0.101562 (1.463 sec)
26.666... logprob:  0.442036, 0.117188 (1.458 sec)
26.667... logprob:  0.564232, 0.164062 (1.452 sec)
26.668... logprob:  0.497860, 0.140625 (1.457 sec)
26.669... logprob:  0.432967, 0.109375 (1.462 sec)
26.670... logprob:  0.362393, 0.085938 (1.438 sec)
26.671... logprob:  0.360866, 0.093750 (1.429 sec)
26.672... logprob:  0.441823, 0.117188 (1.435 sec)
26.673... logprob:  0.436229, 0.117188 (1.435 sec)
26.674... logprob:  0.446640, 0.117188 (1.448 sec)
26.675... logprob:  0.356678, 0.093750 (1.466 sec)
26.676... logprob:  0.450175, 0.125000 (1.456 sec)
26.677... logprob:  0.471028, 0.125000 (1.441 sec)
26.678... logprob:  0.465657, 0.125000 (1.482 sec)
26.679... logprob:  0.454864, 0.125000 (1.437 sec)
26.680... logprob:  0.351679, 0.078125 (1.425 sec)
26.681... logprob:  0.373882, 0.093750 (1.435 sec)
26.682... logprob:  0.340473, 0.078125 (1.440 sec)
26.683... logprob:  0.411635, 0.109375 (1.435 sec)
26.684... logprob:  0.357673, 0.085938 (1.480 sec)
26.685... logprob:  0.286110, 0.054688 (1.447 sec)
26.686... logprob:  0.318730, 0.070312 (1.435 sec)
26.687... logprob:  0.281718, 0.062500 (1.484 sec)
26.688... logprob:  0.323127, 0.078125 (1.438 sec)
26.689... logprob:  0.471108, 0.125000 (1.429 sec)
26.690... logprob:  0.527579, 0.140625 (1.440 sec)
26.691... logprob:  0.516437, 0.140625 (1.431 sec)
26.692... logprob:  0.384930, 0.101562 (1.436 sec)
26.693... logprob:  0.455651, 0.125000 (1.485 sec)
26.694... logprob:  0.330935, 0.078125 (1.440 sec)
26.695... logprob:  0.356932, 0.085938 (1.451 sec)
26.696... logprob:  0.539138, 0.148438 (1.481 sec)
26.697... logprob:  0.465727, 0.125000 (1.433 sec)
26.698... logprob:  0.548913, 0.156250 (1.439 sec)
26.699... logprob:  0.459618, 0.125000 (1.439 sec)
26.700... logprob:  0.433870, 0.117188 (1.426 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.9998779296875, 10.0]}, 128)
batch 872: ({'logprob': [65.93859100341797, 19.0]}, 128)
batch 873: ({'logprob': [41.951927185058594, 9.0]}, 128)
batch 874: ({'logprob': [46.22589874267578, 11.0]}, 128)
batch 875: ({'logprob': [51.35732650756836, 13.0]}, 128)
batch 876: ({'logprob': [63.61029052734375, 18.0]}, 128)
batch 877: ({'logprob': [46.66559600830078, 11.0]}, 128)
batch 878: ({'logprob': [61.66854476928711, 17.0]}, 128)
batch 879: ({'logprob': [72.3671875, 21.0]}, 128)
batch 880: ({'logprob': [51.38057327270508, 13.0]}, 128)
batch 881: ({'logprob': [31.21820831298828, 5.0]}, 128)
batch 882: ({'logprob': [55.02326965332031, 14.0]}, 128)
batch 883: ({'logprob': [61.64377975463867, 17.0]}, 128)
batch 884: ({'logprob': [51.791900634765625, 13.0]}, 128)
batch 885: ({'logprob': [52.651275634765625, 13.0]}, 128)
batch 886: ({'logprob': [62.09156799316406, 17.0]}, 128)

======================Test output======================
logprob:  0.419231, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.962085e-03 [3.168436e-09] 
Layer 'conv1' biases: 3.179943e-07 [5.360284e-11] 
Layer 'conv2' weights[0]: 7.949178e-03 [1.904425e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.059730e-10] 
Layer 'conv3' weights[0]: 7.947346e-03 [1.472675e-09] 
Layer 'conv3' biases: 2.705602e-06 [6.988250e-10] 
Layer 'conv4' weights[0]: 7.980041e-03 [1.377106e-09] 
Layer 'conv4' biases: 9.999994e-01 [4.003037e-09] 
Layer 'conv5' weights[0]: 7.978848e-03 [2.214757e-08] 
Layer 'conv5' biases: 9.999933e-01 [2.367682e-08] 
Layer 'fc6' weights[0]: 7.575463e-03 [2.038138e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.892676e-09] 
Layer 'fc7' weights[0]: 7.009094e-03 [3.640445e-07] 
Layer 'fc7' biases: 9.998568e-01 [3.545904e-07] 
Layer 'fc8' weights[0]: 1.259908e-03 [1.344982e-05] 
Layer 'fc8' biases: 6.461602e-02 [8.392905e-05] 
Train error last 870 batches: 0.435203
-------------------------------------------------------
Not saving because 0.419231 > 0.415666 (22.630: -0.00%)
======================================================= (12.101 sec)
26.701... logprob:  0.423037, 0.109375 (1.447 sec)
26.702... logprob:  0.521539, 0.148438 (1.490 sec)
26.703... logprob:  0.405105, 0.101562 (1.438 sec)
26.704... logprob:  0.406032, 0.101562 (1.446 sec)
26.705... logprob:  0.420149, 0.109375 (1.473 sec)
26.706... logprob:  0.468060, 0.125000 (1.435 sec)
26.707... logprob:  0.485298, 0.132812 (1.443 sec)
26.708... logprob:  0.417184, 0.109375 (1.428 sec)
26.709... logprob:  0.422611, 0.109375 (1.429 sec)
26.710... logprob:  0.602234, 0.179688 (1.440 sec)
26.711... logprob:  0.469479, 0.125000 (1.467 sec)
26.712... logprob:  0.340808, 0.078125 (1.450 sec)
26.713... logprob:  0.586641, 0.179688 (1.458 sec)
26.714... logprob:  0.466260, 0.125000 (1.459 sec)
26.715... logprob:  0.417182, 0.109375 (1.466 sec)
26.716... logprob:  0.335436, 0.078125 (1.440 sec)
26.717... logprob:  0.429789, 0.117188 (1.425 sec)
26.718... logprob:  0.490323, 0.132812 (1.433 sec)
26.719... logprob:  0.406184, 0.109375 (1.436 sec)
26.720... logprob:  0.433228, 0.117188 (1.462 sec)
26.721... logprob:  0.451602, 0.117188 (1.461 sec)
26.722... logprob:  0.536984, 0.156250 (1.456 sec)
26.723... logprob:  0.416557, 0.109375 (1.444 sec)
26.724... logprob:  0.412763, 0.109375 (1.479 sec)
26.725... logprob:  0.494814, 0.140625 (1.434 sec)
26.726... logprob:  0.338471, 0.085938 (1.430 sec)
26.727... logprob:  0.393236, 0.101562 (1.434 sec)
26.728... logprob:  0.421243, 0.109375 (1.446 sec)
26.729... logprob:  0.387623, 0.093750 (1.440 sec)
26.730... logprob:  0.565906, 0.164062 (1.477 sec)
26.731... logprob:  0.450392, 0.125000 (1.452 sec)
26.732... logprob:  0.311413, 0.070312 (1.446 sec)
26.733... logprob:  0.556535, 0.156250 (1.484 sec)
26.734... logprob:  0.340251, 0.078125 (1.436 sec)
26.735... logprob:  0.527465, 0.148438 (1.434 sec)
26.736... logprob:  0.642669, 0.187500 (1.439 sec)
26.737... logprob:  0.516118, 0.148438 (1.429 sec)
26.738... logprob:  0.459395, 0.125000 (1.438 sec)
26.739... logprob:  0.477794, 0.132812 (1.482 sec)
26.740... logprob:  0.339647, 0.078125 (1.442 sec)
26.741... logprob:  0.393466, 0.101562 (1.440 sec)
26.742... logprob:  0.419697, 0.109375 (1.484 sec)
26.743... logprob:  0.364884, 0.085938 (1.434 sec)
26.744... logprob:  0.519166, 0.148438 (1.434 sec)
26.745... logprob:  0.478142, 0.132812 (1.437 sec)
26.746... logprob:  0.440547, 0.117188 (1.428 sec)
26.747... logprob:  0.425606, 0.109375 (1.436 sec)
26.748... logprob:  0.378121, 0.093750 (1.488 sec)
26.749... logprob:  0.420813, 0.109375 (1.441 sec)
26.750... logprob:  0.512804, 0.140625 (1.450 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.462432861328125, 10.0]}, 128)
batch 872: ({'logprob': [66.68548583984375, 19.0]}, 128)
batch 873: ({'logprob': [40.46083068847656, 9.0]}, 128)
batch 874: ({'logprob': [45.07863998413086, 11.0]}, 128)
batch 875: ({'logprob': [50.72514724731445, 13.0]}, 128)
batch 876: ({'logprob': [64.14352416992188, 18.0]}, 128)
batch 877: ({'logprob': [45.60287857055664, 11.0]}, 128)
batch 878: ({'logprob': [62.07148361206055, 17.0]}, 128)
batch 879: ({'logprob': [73.89087677001953, 21.0]}, 128)
batch 880: ({'logprob': [50.749244689941406, 13.0]}, 128)
batch 881: ({'logprob': [28.603723526000977, 5.0]}, 128)
batch 882: ({'logprob': [54.86946105957031, 14.0]}, 128)
batch 883: ({'logprob': [62.04609298706055, 17.0]}, 128)
batch 884: ({'logprob': [51.25089645385742, 13.0]}, 128)
batch 885: ({'logprob': [52.283790588378906, 13.0]}, 128)
batch 886: ({'logprob': [62.583499908447266, 17.0]}, 128)

======================Test output======================
logprob:  0.416264, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.962048e-03 [3.932992e-09] 
Layer 'conv1' biases: 3.188956e-07 [9.186914e-11] 
Layer 'conv2' weights[0]: 7.949139e-03 [2.529681e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.028815e-10] 
Layer 'conv3' weights[0]: 7.947299e-03 [2.024868e-09] 
Layer 'conv3' biases: 2.710457e-06 [1.183773e-09] 
Layer 'conv4' weights[0]: 7.979998e-03 [2.067858e-09] 
Layer 'conv4' biases: 9.999994e-01 [8.965705e-09] 
Layer 'conv5' weights[0]: 7.978792e-03 [5.865426e-08] 
Layer 'conv5' biases: 9.999923e-01 [6.308873e-08] 
Layer 'fc6' weights[0]: 7.575416e-03 [4.936159e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.938256e-09] 
Layer 'fc7' weights[0]: 7.007311e-03 [7.304205e-08] 
Layer 'fc7' biases: 9.998580e-01 [5.687339e-08] 
Layer 'fc8' weights[0]: 1.302475e-03 [6.678515e-06] 
Layer 'fc8' biases: 6.508121e-02 [4.555276e-05] 
Train error last 870 batches: 0.435203
-------------------------------------------------------
Not saving because 0.416264 > 0.415666 (22.630: -0.00%)
======================================================= (12.076 sec)
26.751... logprob:  0.263667, 0.054688 (1.498 sec)
26.752... logprob:  0.522508, 0.140625 (1.433 sec)
26.753... logprob:  0.441175, 0.117188 (1.441 sec)
26.754... logprob:  0.468355, 0.132812 (1.434 sec)
26.755... logprob:  0.507061, 0.140625 (1.430 sec)
26.756... logprob:  0.440831, 0.117188 (1.433 sec)
26.757... logprob:  0.552427, 0.156250 (1.479 sec)
26.758... logprob:  0.393593, 0.101562 (1.444 sec)
26.759... logprob:  0.459697, 0.125000 (1.455 sec)
26.760... logprob:  0.485524, 0.132812 (1.486 sec)
26.761... logprob:  0.418208, 0.109375 (1.455 sec)
26.762... logprob:  0.516047, 0.148438 (1.439 sec)
26.763... logprob:  0.558946, 0.164062 (1.429 sec)
26.764... logprob:  0.503271, 0.140625 (1.421 sec)
26.765... logprob:  0.311832, 0.062500 (1.438 sec)
26.766... logprob:  0.482227, 0.132812 (1.460 sec)
26.767... logprob:  0.371099, 0.085938 (1.457 sec)
26.768... logprob:  0.432662, 0.117188 (1.466 sec)
26.769... logprob:  0.490817, 0.140625 (1.465 sec)
26.770... logprob:  0.402951, 0.101562 (1.489 sec)
26.771... logprob:  0.549443, 0.156250 (1.456 sec)
26.772... logprob:  0.414088, 0.109375 (1.447 sec)
26.773... logprob:  0.557763, 0.164062 (1.448 sec)
26.774... logprob:  0.361738, 0.085938 (1.461 sec)
26.775... logprob:  0.407380, 0.101562 (1.467 sec)
26.776... logprob:  0.433168, 0.117188 (1.479 sec)
26.777... logprob:  0.379967, 0.093750 (1.476 sec)
26.778... logprob:  0.433559, 0.117188 (1.468 sec)
26.779... logprob:  0.505356, 0.140625 (1.485 sec)
26.780... logprob:  0.385761, 0.101562 (1.460 sec)
26.781... logprob:  0.369648, 0.085938 (1.447 sec)
26.782... logprob:  0.351425, 0.085938 (1.447 sec)
26.783... logprob:  0.555520, 0.156250 (1.464 sec)
26.784... logprob:  0.440957, 0.117188 (1.456 sec)
26.785... logprob:  0.543684, 0.156250 (1.492 sec)
26.786... logprob:  0.477526, 0.132812 (1.470 sec)
26.787... logprob:  0.546444, 0.156250 (1.457 sec)
26.788... logprob:  0.563202, 0.164062 (1.494 sec)
26.789... logprob:  0.280816, 0.054688 (1.452 sec)
26.790... logprob:  0.407999, 0.101562 (1.451 sec)
26.791... logprob:  0.397916, 0.101562 (1.448 sec)
26.792... logprob:  0.360982, 0.085938 (1.465 sec)
26.793... logprob:  0.370113, 0.085938 (1.453 sec)
26.794... logprob:  0.387127, 0.093750 (1.492 sec)
26.795... logprob:  0.469741, 0.125000 (1.466 sec)
26.796... logprob:  0.423508, 0.109375 (1.461 sec)
26.797... logprob:  0.358853, 0.085938 (1.500 sec)
26.798... logprob:  0.393290, 0.101562 (1.454 sec)
26.799... logprob:  0.332412, 0.078125 (1.449 sec)
26.800... logprob:  0.371710, 0.093750 (1.450 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.21696090698242, 10.0]}, 128)
batch 872: ({'logprob': [68.30328369140625, 19.0]}, 128)
batch 873: ({'logprob': [39.43023681640625, 9.0]}, 128)
batch 874: ({'logprob': [44.78004455566406, 11.0]}, 128)
batch 875: ({'logprob': [50.81935119628906, 13.0]}, 128)
batch 876: ({'logprob': [65.48146057128906, 18.0]}, 128)
batch 877: ({'logprob': [45.13446044921875, 11.0]}, 128)
batch 878: ({'logprob': [62.95772933959961, 17.0]}, 128)
batch 879: ({'logprob': [75.40105438232422, 21.0]}, 128)
batch 880: ({'logprob': [50.84505081176758, 13.0]}, 128)
batch 881: ({'logprob': [26.948217391967773, 5.0]}, 128)
batch 882: ({'logprob': [54.744380950927734, 14.0]}, 128)
batch 883: ({'logprob': [62.93149185180664, 17.0]}, 128)
batch 884: ({'logprob': [51.18119430541992, 13.0]}, 128)
batch 885: ({'logprob': [51.87796401977539, 13.0]}, 128)
batch 886: ({'logprob': [63.3036003112793, 17.0]}, 128)

======================Test output======================
logprob:  0.417655, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.962019e-03 [2.886057e-09] 
Layer 'conv1' biases: 3.198764e-07 [7.966102e-11] 
Layer 'conv2' weights[0]: 7.949107e-03 [1.756550e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.538124e-10] 
Layer 'conv3' weights[0]: 7.947268e-03 [1.461451e-09] 
Layer 'conv3' biases: 2.717212e-06 [6.296198e-10] 
Layer 'conv4' weights[0]: 7.979959e-03 [1.516818e-09] 
Layer 'conv4' biases: 9.999994e-01 [5.487239e-09] 
Layer 'conv5' weights[0]: 7.978746e-03 [3.571189e-08] 
Layer 'conv5' biases: 9.999921e-01 [3.843573e-08] 
Layer 'fc6' weights[0]: 7.575379e-03 [3.056625e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.015001e-09] 
Layer 'fc7' weights[0]: 7.005495e-03 [2.574631e-07] 
Layer 'fc7' biases: 9.998589e-01 [2.474491e-07] 
Layer 'fc8' weights[0]: 1.337614e-03 [9.999496e-06] 
Layer 'fc8' biases: 6.548886e-02 [6.920396e-05] 
Train error last 870 batches: 0.435203
-------------------------------------------------------
Not saving because 0.417655 > 0.415666 (22.630: -0.00%)
======================================================= (12.045 sec)
26.801... logprob:  0.450027, 0.117188 (1.459 sec)
26.802... logprob:  0.422932, 0.109375 (1.457 sec)
26.803... logprob:  0.491563, 0.132812 (1.493 sec)
26.804... logprob:  0.349955, 0.085938 (1.464 sec)
26.805... logprob:  0.452278, 0.117188 (1.457 sec)
26.806... logprob:  0.424178, 0.109375 (1.503 sec)
26.807... logprob:  0.443475, 0.117188 (1.454 sec)
26.808... logprob:  0.462363, 0.125000 (1.453 sec)
26.809... logprob:  0.589733, 0.171875 (1.452 sec)
26.810... logprob:  0.442480, 0.117188 (1.455 sec)
26.811... logprob:  0.460419, 0.125000 (1.453 sec)
26.812... logprob:  0.462349, 0.125000 (1.498 sec)
26.813... logprob:  0.485956, 0.132812 (1.463 sec)
26.814... logprob:  0.477968, 0.132812 (1.456 sec)
26.815... logprob:  0.371671, 0.085938 (1.503 sec)
26.816... logprob:  0.408606, 0.101562 (1.454 sec)
26.817... logprob:  0.425895, 0.109375 (1.456 sec)
26.818... logprob:  0.560000, 0.164062 (1.449 sec)
26.819... logprob:  0.498189, 0.140625 (1.454 sec)
26.820... logprob:  0.421650, 0.109375 (1.456 sec)
26.821... logprob:  0.406636, 0.101562 (1.499 sec)
26.822... logprob:  0.441226, 0.117188 (1.463 sec)
26.823... logprob:  0.340964, 0.078125 (1.456 sec)
26.824... logprob:  0.489735, 0.132812 (1.511 sec)
26.825... logprob:  0.288176, 0.062500 (1.454 sec)
26.826... logprob:  0.375528, 0.093750 (1.455 sec)
26.827... logprob:  0.420496, 0.109375 (1.452 sec)
26.828... logprob:  0.443275, 0.117188 (1.454 sec)
26.829... logprob:  0.504016, 0.140625 (1.452 sec)
26.830... logprob:  0.442125, 0.117188 (1.506 sec)
26.831... logprob:  0.513913, 0.140625 (1.452 sec)
26.832... logprob:  0.330843, 0.078125 (1.466 sec)
26.833... logprob:  0.489033, 0.132812 (1.494 sec)
26.834... logprob:  0.433338, 0.117188 (1.462 sec)
26.835... logprob:  0.542814, 0.148438 (1.457 sec)
26.836... logprob:  0.376141, 0.093750 (1.453 sec)
26.837... logprob:  0.314194, 0.070312 (1.454 sec)
26.838... logprob:  0.437070, 0.117188 (1.453 sec)
26.839... logprob:  0.471663, 0.125000 (1.506 sec)
26.840... logprob:  0.555485, 0.156250 (1.451 sec)
26.841... logprob:  0.396061, 0.101562 (1.470 sec)
26.842... logprob:  0.497869, 0.140625 (1.492 sec)
26.843... logprob:  0.465508, 0.125000 (1.452 sec)
26.844... logprob:  0.497657, 0.140625 (1.464 sec)
26.845... logprob:  0.486756, 0.132812 (1.449 sec)
26.846... logprob:  0.468416, 0.125000 (1.451 sec)
26.847... logprob:  0.363368, 0.085938 (1.456 sec)
26.848... logprob:  0.397191, 0.101562 (1.496 sec)
26.849... logprob:  0.360530, 0.085938 (1.463 sec)
26.850... logprob:  0.479385, 0.132812 (1.469 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.456668853759766, 10.0]}, 128)
batch 872: ({'logprob': [66.45155334472656, 19.0]}, 128)
batch 873: ({'logprob': [40.897979736328125, 9.0]}, 128)
batch 874: ({'logprob': [45.623016357421875, 11.0]}, 128)
batch 875: ({'logprob': [50.97471618652344, 13.0]}, 128)
batch 876: ({'logprob': [63.956207275390625, 18.0]}, 128)
batch 877: ({'logprob': [45.94709396362305, 11.0]}, 128)
batch 878: ({'logprob': [61.7307243347168, 17.0]}, 128)
batch 879: ({'logprob': [72.7601318359375, 21.0]}, 128)
batch 880: ({'logprob': [50.998966217041016, 13.0]}, 128)
batch 881: ({'logprob': [29.833114624023438, 5.0]}, 128)
batch 882: ({'logprob': [54.467952728271484, 14.0]}, 128)
batch 883: ({'logprob': [61.70551300048828, 17.0]}, 128)
batch 884: ({'logprob': [51.29768753051758, 13.0]}, 128)
batch 885: ({'logprob': [51.92854690551758, 13.0]}, 128)
batch 886: ({'logprob': [62.040748596191406, 17.0]}, 128)

======================Test output======================
logprob:  0.416538, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961975e-03 [2.808163e-09] 
Layer 'conv1' biases: 3.209362e-07 [7.839261e-11] 
Layer 'conv2' weights[0]: 7.949069e-03 [2.262113e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.006671e-10] 
Layer 'conv3' weights[0]: 7.947231e-03 [2.132134e-09] 
Layer 'conv3' biases: 2.726628e-06 [1.254664e-09] 
Layer 'conv4' weights[0]: 7.979920e-03 [2.408695e-09] 
Layer 'conv4' biases: 9.999994e-01 [1.189533e-08] 
Layer 'conv5' weights[0]: 7.978716e-03 [7.812480e-08] 
Layer 'conv5' biases: 9.999923e-01 [8.397867e-08] 
Layer 'fc6' weights[0]: 7.575339e-03 [6.393502e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.507694e-09] 
Layer 'fc7' weights[0]: 7.003804e-03 [2.469341e-07] 
Layer 'fc7' biases: 9.998571e-01 [2.363657e-07] 
Layer 'fc8' weights[0]: 1.273385e-03 [8.624933e-06] 
Layer 'fc8' biases: 6.532190e-02 [6.261605e-05] 
Train error last 870 batches: 0.435202
-------------------------------------------------------
Not saving because 0.416538 > 0.415666 (22.630: -0.00%)
======================================================= (12.039 sec)
26.851... logprob:  0.440140, 0.117188 (1.493 sec)
26.852... logprob:  0.545458, 0.156250 (1.455 sec)
26.853... logprob:  0.371961, 0.093750 (1.458 sec)
26.854... logprob:  0.307317, 0.070312 (1.454 sec)
26.855... logprob:  0.484758, 0.132812 (1.445 sec)
26.856... logprob:  0.443735, 0.117188 (1.460 sec)
26.857... logprob:  0.372229, 0.093750 (1.494 sec)
26.858... logprob:  0.396245, 0.101562 (1.460 sec)
26.859... logprob:  0.307983, 0.070312 (1.480 sec)
26.860... logprob:  0.565977, 0.156250 (1.491 sec)
26.861... logprob:  0.417802, 0.109375 (1.458 sec)
26.862... logprob:  0.328851, 0.078125 (1.459 sec)
26.863... logprob:  0.399566, 0.101562 (1.446 sec)
26.864... logprob:  0.451477, 0.117188 (1.452 sec)
26.865... logprob:  0.484576, 0.132812 (1.459 sec)
26.866... logprob:  0.507743, 0.140625 (1.507 sec)
26.867... logprob:  0.503102, 0.140625 (1.463 sec)
26.868... logprob:  0.405245, 0.101562 (1.477 sec)
26.869... logprob:  0.383122, 0.093750 (1.477 sec)
26.870... logprob:  0.552185, 0.156250 (1.397 sec)
27.1... logprob:  0.379960, 0.093750 (1.403 sec)
27.2... logprob:  0.448252, 0.117188 (1.447 sec)
27.3... logprob:  0.398287, 0.101562 (1.414 sec)
27.4... logprob:  0.443303, 0.117188 (1.409 sec)
27.5... logprob:  0.443473, 0.117188 (1.433 sec)
27.6... logprob:  0.499077, 0.140625 (1.392 sec)
27.7... logprob:  0.363260, 0.085938 (1.419 sec)
27.8... logprob:  0.419158, 0.109375 (1.398 sec)
27.9... logprob:  0.358883, 0.085938 (1.408 sec)
27.10... logprob:  0.377569, 0.093750 (1.414 sec)
27.11... logprob:  0.334865, 0.078125 (1.439 sec)
27.12... logprob:  0.466307, 0.125000 (1.397 sec)
27.13... logprob:  0.442190, 0.117188 (1.420 sec)
27.14... logprob:  0.444562, 0.117188 (1.405 sec)
27.15... logprob:  0.395521, 0.101562 (1.411 sec)
27.16... logprob:  0.421370, 0.109375 (1.405 sec)
27.17... logprob:  0.515964, 0.140625 (1.405 sec)
27.18... logprob:  0.262111, 0.054688 (1.401 sec)
27.19... logprob:  0.279498, 0.062500 (1.402 sec)
27.20... logprob:  0.421366, 0.109375 (1.407 sec)
27.21... logprob:  0.443986, 0.117188 (1.403 sec)
27.22... logprob:  0.536759, 0.148438 (1.422 sec)
27.23... logprob:  0.533111, 0.148438 (1.417 sec)
27.24... logprob:  0.310511, 0.070312 (1.419 sec)
27.25... logprob:  0.356145, 0.085938 (1.399 sec)
27.26... logprob:  0.463790, 0.125000 (1.450 sec)
27.27... logprob:  0.404514, 0.101562 (1.387 sec)
27.28... logprob:  0.421849, 0.109375 (1.418 sec)
27.29... logprob:  0.395934, 0.101562 (1.428 sec)
27.30... logprob:  0.374068, 0.093750 (1.423 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.37691116333008, 10.0]}, 128)
batch 872: ({'logprob': [66.8911361694336, 19.0]}, 128)
batch 873: ({'logprob': [40.42906951904297, 9.0]}, 128)
batch 874: ({'logprob': [45.451725006103516, 11.0]}, 128)
batch 875: ({'logprob': [50.90702438354492, 13.0]}, 128)
batch 876: ({'logprob': [64.29608917236328, 18.0]}, 128)
batch 877: ({'logprob': [45.67889404296875, 11.0]}, 128)
batch 878: ({'logprob': [61.873268127441406, 17.0]}, 128)
batch 879: ({'logprob': [73.01643371582031, 21.0]}, 128)
batch 880: ({'logprob': [50.932228088378906, 13.0]}, 128)
batch 881: ({'logprob': [29.250211715698242, 5.0]}, 128)
batch 882: ({'logprob': [54.213314056396484, 14.0]}, 128)
batch 883: ({'logprob': [61.84732437133789, 17.0]}, 128)
batch 884: ({'logprob': [51.13538360595703, 13.0]}, 128)
batch 885: ({'logprob': [51.57380294799805, 13.0]}, 128)
batch 886: ({'logprob': [62.087703704833984, 17.0]}, 128)

======================Test output======================
logprob:  0.415996, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961933e-03 [2.482969e-09] 
Layer 'conv1' biases: 3.219516e-07 [7.331532e-11] 
Layer 'conv2' weights[0]: 7.949027e-03 [2.455528e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.882648e-10] 
Layer 'conv3' weights[0]: 7.947196e-03 [2.250526e-09] 
Layer 'conv3' biases: 2.736253e-06 [1.169800e-09] 
Layer 'conv4' weights[0]: 7.979885e-03 [2.445164e-09] 
Layer 'conv4' biases: 9.999994e-01 [1.093555e-08] 
Layer 'conv5' weights[0]: 7.978678e-03 [7.178569e-08] 
Layer 'conv5' biases: 9.999925e-01 [7.723788e-08] 
Layer 'fc6' weights[0]: 7.575297e-03 [5.925563e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.009500e-09] 
Layer 'fc7' weights[0]: 7.001965e-03 [4.224662e-08] 
Layer 'fc7' biases: 9.998573e-01 [1.955399e-08] 
Layer 'fc8' weights[0]: 1.282204e-03 [1.324498e-06] 
Layer 'fc8' biases: 6.553636e-02 [9.712289e-06] 
Train error last 870 batches: 0.435202
-------------------------------------------------------
Not saving because 0.415996 > 0.415666 (22.630: -0.00%)
======================================================= (12.122 sec)
27.31... logprob:  0.479963, 0.132812 (1.417 sec)
27.32... logprob:  0.457223, 0.125000 (1.396 sec)
27.33... logprob:  0.460677, 0.125000 (1.445 sec)
27.34... logprob:  0.464535, 0.125000 (1.393 sec)
27.35... logprob:  0.316311, 0.070312 (1.405 sec)
27.36... logprob:  0.475791, 0.132812 (1.399 sec)
27.37... logprob:  0.417592, 0.109375 (1.409 sec)
27.38... logprob:  0.392665, 0.101562 (1.405 sec)
27.39... logprob:  0.631491, 0.187500 (1.435 sec)
27.40... logprob:  0.445698, 0.117188 (1.412 sec)
27.41... logprob:  0.352956, 0.085938 (1.429 sec)
27.42... logprob:  0.391988, 0.101562 (1.419 sec)
27.43... logprob:  0.440081, 0.117188 (1.405 sec)
27.44... logprob:  0.518555, 0.148438 (1.442 sec)
27.45... logprob:  0.381730, 0.093750 (1.395 sec)
27.46... logprob:  0.486204, 0.132812 (1.401 sec)
27.47... logprob:  0.331722, 0.078125 (1.394 sec)
27.48... logprob:  0.498930, 0.140625 (1.430 sec)
27.49... logprob:  0.510853, 0.148438 (1.412 sec)
27.50... logprob:  0.393190, 0.101562 (1.429 sec)
27.51... logprob:  0.490232, 0.140625 (1.418 sec)
27.52... logprob:  0.525789, 0.148438 (1.402 sec)
27.53... logprob:  0.294825, 0.062500 (1.442 sec)
27.54... logprob:  0.403381, 0.109375 (1.395 sec)
27.55... logprob:  0.331705, 0.078125 (1.396 sec)
27.56... logprob:  0.421626, 0.109375 (1.405 sec)
27.57... logprob:  0.572370, 0.164062 (1.433 sec)
27.58... logprob:  0.407573, 0.101562 (1.411 sec)
27.59... logprob:  0.333868, 0.078125 (1.468 sec)
27.60... logprob:  0.618764, 0.179688 (1.428 sec)
27.61... logprob:  0.382809, 0.093750 (1.433 sec)
27.62... logprob:  0.474847, 0.132812 (1.465 sec)
27.63... logprob:  0.397291, 0.101562 (1.441 sec)
27.64... logprob:  0.450318, 0.125000 (1.413 sec)
27.65... logprob:  0.373373, 0.093750 (1.398 sec)
27.66... logprob:  0.354037, 0.085938 (1.444 sec)
27.67... logprob:  0.295417, 0.062500 (1.393 sec)
27.68... logprob:  0.396802, 0.101562 (1.399 sec)
27.69... logprob:  0.496688, 0.140625 (1.431 sec)
27.70... logprob:  0.325899, 0.078125 (1.437 sec)
27.71... logprob:  0.381805, 0.101562 (1.469 sec)
27.72... logprob:  0.493715, 0.132812 (1.418 sec)
27.73... logprob:  0.447695, 0.117188 (1.426 sec)
27.74... logprob:  0.442524, 0.117188 (1.419 sec)
27.75... logprob:  0.380654, 0.093750 (1.418 sec)
27.76... logprob:  0.412051, 0.109375 (1.435 sec)
27.77... logprob:  0.396343, 0.101562 (1.427 sec)
27.78... logprob:  0.493055, 0.140625 (1.456 sec)
27.79... logprob:  0.456470, 0.125000 (1.418 sec)
27.80... logprob:  0.508015, 0.132812 (1.420 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.64643478393555, 10.0]}, 128)
batch 872: ({'logprob': [66.3282470703125, 19.0]}, 128)
batch 873: ({'logprob': [40.89985275268555, 9.0]}, 128)
batch 874: ({'logprob': [45.290313720703125, 11.0]}, 128)
batch 875: ({'logprob': [50.823585510253906, 13.0]}, 128)
batch 876: ({'logprob': [63.87118911743164, 18.0]}, 128)
batch 877: ({'logprob': [45.8718147277832, 11.0]}, 128)
batch 878: ({'logprob': [61.941680908203125, 17.0]}, 128)
batch 879: ({'logprob': [73.58935546875, 21.0]}, 128)
batch 880: ({'logprob': [50.84731674194336, 13.0]}, 128)
batch 881: ({'logprob': [29.2147159576416, 5.0]}, 128)
batch 882: ({'logprob': [55.051658630371094, 14.0]}, 128)
batch 883: ({'logprob': [61.91657257080078, 17.0]}, 128)
batch 884: ({'logprob': [51.40472412109375, 13.0]}, 128)
batch 885: ({'logprob': [52.55096435546875, 13.0]}, 128)
batch 886: ({'logprob': [62.50983810424805, 17.0]}, 128)

======================Test output======================
logprob:  0.416874, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961893e-03 [4.039617e-09] 
Layer 'conv1' biases: 3.230329e-07 [1.068866e-10] 
Layer 'conv2' weights[0]: 7.948989e-03 [3.347452e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.078016e-10] 
Layer 'conv3' weights[0]: 7.947146e-03 [2.942396e-09] 
Layer 'conv3' biases: 2.744774e-06 [1.916592e-09] 
Layer 'conv4' weights[0]: 7.979848e-03 [3.199490e-09] 
Layer 'conv4' biases: 9.999994e-01 [1.721936e-08] 
Layer 'conv5' weights[0]: 7.978621e-03 [1.126779e-07] 
Layer 'conv5' biases: 9.999926e-01 [1.212425e-07] 
Layer 'fc6' weights[0]: 7.575255e-03 [9.385562e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.475268e-09] 
Layer 'fc7' weights[0]: 7.000178e-03 [2.622251e-07] 
Layer 'fc7' biases: 9.998578e-01 [2.529854e-07] 
Layer 'fc8' weights[0]: 1.287302e-03 [8.799843e-06] 
Layer 'fc8' biases: 6.558243e-02 [5.634130e-05] 
Train error last 870 batches: 0.435202
-------------------------------------------------------
Not saving because 0.416874 > 0.415666 (22.630: -0.00%)
======================================================= (12.039 sec)
27.81... logprob:  0.416724, 0.109375 (1.420 sec)
27.82... logprob:  0.231310, 0.039062 (1.432 sec)
27.83... logprob:  0.493810, 0.140625 (1.400 sec)
27.84... logprob:  0.468140, 0.125000 (1.469 sec)
27.85... logprob:  0.431938, 0.117188 (1.418 sec)
27.86... logprob:  0.416933, 0.109375 (1.422 sec)
27.87... logprob:  0.633286, 0.187500 (1.411 sec)
27.88... logprob:  0.535029, 0.156250 (1.416 sec)
27.89... logprob:  0.410557, 0.109375 (1.436 sec)
27.90... logprob:  0.577484, 0.171875 (1.392 sec)
27.91... logprob:  0.348439, 0.078125 (1.398 sec)
27.92... logprob:  0.464461, 0.125000 (1.404 sec)
27.93... logprob:  0.492216, 0.140625 (1.398 sec)
27.94... logprob:  0.428785, 0.109375 (1.394 sec)
27.95... logprob:  0.471835, 0.125000 (1.406 sec)
27.96... logprob:  0.576200, 0.171875 (1.410 sec)
27.97... logprob:  0.430784, 0.117188 (1.394 sec)
27.98... logprob:  0.391186, 0.093750 (1.444 sec)
27.99... logprob:  0.474229, 0.132812 (1.406 sec)
27.100... logprob:  0.310589, 0.070312 (1.407 sec)
27.101... logprob:  0.310870, 0.062500 (1.452 sec)
27.102... logprob:  0.545964, 0.156250 (1.389 sec)
27.103... logprob:  0.540967, 0.156250 (1.399 sec)
27.104... logprob:  0.388818, 0.101562 (1.406 sec)
27.105... logprob:  0.619339, 0.179688 (1.417 sec)
27.106... logprob:  0.344462, 0.085938 (1.395 sec)
27.107... logprob:  0.335781, 0.078125 (1.439 sec)
27.108... logprob:  0.586854, 0.171875 (1.404 sec)
27.109... logprob:  0.336134, 0.078125 (1.398 sec)
27.110... logprob:  0.564637, 0.164062 (1.400 sec)
27.111... logprob:  0.404673, 0.101562 (1.400 sec)
27.112... logprob:  0.366013, 0.093750 (1.405 sec)
27.113... logprob:  0.354453, 0.085938 (1.407 sec)
27.114... logprob:  0.440213, 0.117188 (1.438 sec)
27.115... logprob:  0.506774, 0.140625 (1.415 sec)
27.116... logprob:  0.393352, 0.101562 (1.399 sec)
27.117... logprob:  0.440393, 0.117188 (1.447 sec)
27.118... logprob:  0.409099, 0.101562 (1.389 sec)
27.119... logprob:  0.346087, 0.085938 (1.400 sec)
27.120... logprob:  0.547130, 0.156250 (1.400 sec)
27.121... logprob:  0.412606, 0.109375 (1.401 sec)
27.122... logprob:  0.519270, 0.148438 (1.445 sec)
27.123... logprob:  0.463680, 0.125000 (1.393 sec)
27.124... logprob:  0.447691, 0.125000 (1.409 sec)
27.125... logprob:  0.501924, 0.140625 (1.405 sec)
27.126... logprob:  0.475743, 0.125000 (1.392 sec)
27.127... logprob:  0.479517, 0.125000 (1.396 sec)
27.128... logprob:  0.422338, 0.109375 (1.420 sec)
27.129... logprob:  0.574887, 0.164062 (1.418 sec)
27.130... logprob:  0.382707, 0.093750 (1.419 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.01038360595703, 10.0]}, 128)
batch 872: ({'logprob': [65.92462921142578, 19.0]}, 128)
batch 873: ({'logprob': [41.98527908325195, 9.0]}, 128)
batch 874: ({'logprob': [46.24293518066406, 11.0]}, 128)
batch 875: ({'logprob': [51.36952209472656, 13.0]}, 128)
batch 876: ({'logprob': [63.60194778442383, 18.0]}, 128)
batch 877: ({'logprob': [46.68852233886719, 11.0]}, 128)
batch 878: ({'logprob': [61.67142868041992, 17.0]}, 128)
batch 879: ({'logprob': [72.36654663085938, 21.0]}, 128)
batch 880: ({'logprob': [51.3929443359375, 13.0]}, 128)
batch 881: ({'logprob': [31.25522232055664, 5.0]}, 128)
batch 882: ({'logprob': [55.047977447509766, 14.0]}, 128)
batch 883: ({'logprob': [61.646453857421875, 17.0]}, 128)
batch 884: ({'logprob': [51.81013107299805, 13.0]}, 128)
batch 885: ({'logprob': [52.68129348754883, 13.0]}, 128)
batch 886: ({'logprob': [62.10039138793945, 17.0]}, 128)

======================Test output======================
logprob:  0.419334, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961856e-03 [2.059639e-09] 
Layer 'conv1' biases: 3.238980e-07 [7.130301e-11] 
Layer 'conv2' weights[0]: 7.948947e-03 [1.823043e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.405242e-10] 
Layer 'conv3' weights[0]: 7.947112e-03 [1.777780e-09] 
Layer 'conv3' biases: 2.751747e-06 [1.061442e-09] 
Layer 'conv4' weights[0]: 7.979809e-03 [1.788511e-09] 
Layer 'conv4' biases: 9.999994e-01 [8.952655e-09] 
Layer 'conv5' weights[0]: 7.978597e-03 [5.096973e-08] 
Layer 'conv5' biases: 9.999927e-01 [5.491486e-08] 
Layer 'fc6' weights[0]: 7.575221e-03 [4.318407e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.310614e-09] 
Layer 'fc7' weights[0]: 6.998420e-03 [8.380004e-08] 
Layer 'fc7' biases: 9.998567e-01 [6.979035e-08] 
Layer 'fc8' weights[0]: 1.251294e-03 [7.233485e-06] 
Layer 'fc8' biases: 6.543685e-02 [4.911924e-05] 
Train error last 870 batches: 0.435202
-------------------------------------------------------
Not saving because 0.419334 > 0.415666 (22.630: -0.00%)
======================================================= (12.090 sec)
27.131... logprob:  0.495497, 0.132812 (1.434 sec)
27.132... logprob:  0.506363, 0.140625 (1.444 sec)
27.133... logprob:  0.444688, 0.117188 (1.393 sec)
27.134... logprob:  0.401875, 0.101562 (1.399 sec)
27.135... logprob:  0.460192, 0.125000 (1.402 sec)
27.136... logprob:  0.562399, 0.164062 (1.404 sec)
27.137... logprob:  0.462585, 0.125000 (1.391 sec)
27.138... logprob:  0.319393, 0.070312 (1.452 sec)
27.139... logprob:  0.395745, 0.101562 (1.423 sec)
27.140... logprob:  0.560125, 0.164062 (1.417 sec)
27.141... logprob:  0.464574, 0.125000 (1.439 sec)
27.142... logprob:  0.464634, 0.125000 (1.400 sec)
27.143... logprob:  0.294400, 0.062500 (1.427 sec)
27.144... logprob:  0.457081, 0.125000 (1.421 sec)
27.145... logprob:  0.324747, 0.078125 (1.413 sec)
27.146... logprob:  0.483103, 0.132812 (1.416 sec)
27.147... logprob:  0.262483, 0.054688 (1.433 sec)
27.148... logprob:  0.458642, 0.125000 (1.393 sec)
27.149... logprob:  0.442508, 0.117188 (1.397 sec)
27.150... logprob:  0.347582, 0.085938 (1.403 sec)
27.151... logprob:  0.347141, 0.085938 (1.408 sec)
27.152... logprob:  0.785111, 0.234375 (1.390 sec)
27.153... logprob:  0.381644, 0.093750 (1.444 sec)
27.154... logprob:  0.524644, 0.148438 (1.400 sec)
27.155... logprob:  0.426089, 0.117188 (1.414 sec)
27.156... logprob:  0.295321, 0.062500 (1.438 sec)
27.157... logprob:  0.270225, 0.054688 (1.396 sec)
27.158... logprob:  0.455427, 0.125000 (1.401 sec)
27.159... logprob:  0.483121, 0.132812 (1.400 sec)
27.160... logprob:  0.444735, 0.117188 (1.394 sec)
27.161... logprob:  0.349774, 0.078125 (1.407 sec)
27.162... logprob:  0.611786, 0.179688 (1.410 sec)
27.163... logprob:  0.450474, 0.125000 (1.432 sec)
27.164... logprob:  0.468551, 0.125000 (1.424 sec)
27.165... logprob:  0.547793, 0.156250 (1.418 sec)
27.166... logprob:  0.446134, 0.125000 (1.457 sec)
27.167... logprob:  0.350578, 0.085938 (1.427 sec)
27.168... logprob:  0.363737, 0.085938 (1.427 sec)
27.169... logprob:  0.408636, 0.101562 (1.460 sec)
27.170... logprob:  0.459467, 0.125000 (1.408 sec)
27.171... logprob:  0.535265, 0.156250 (1.422 sec)
27.172... logprob:  0.434814, 0.109375 (1.415 sec)
27.173... logprob:  0.440471, 0.117188 (1.426 sec)
27.174... logprob:  0.600767, 0.171875 (1.410 sec)
27.175... logprob:  0.505969, 0.140625 (1.468 sec)
27.176... logprob:  0.478413, 0.132812 (1.418 sec)
27.177... logprob:  0.289728, 0.054688 (1.431 sec)
27.178... logprob:  0.383475, 0.093750 (1.458 sec)
27.179... logprob:  0.394671, 0.101562 (1.414 sec)
27.180... logprob:  0.466388, 0.125000 (1.429 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.9991340637207, 10.0]}, 128)
batch 872: ({'logprob': [66.494140625, 19.0]}, 128)
batch 873: ({'logprob': [40.68577194213867, 9.0]}, 128)
batch 874: ({'logprob': [45.35708999633789, 11.0]}, 128)
batch 875: ({'logprob': [50.82923126220703, 13.0]}, 128)
batch 876: ({'logprob': [63.98272705078125, 18.0]}, 128)
batch 877: ({'logprob': [45.768226623535156, 11.0]}, 128)
batch 878: ({'logprob': [61.82730484008789, 17.0]}, 128)
batch 879: ({'logprob': [73.18467712402344, 21.0]}, 128)
batch 880: ({'logprob': [50.85390090942383, 13.0]}, 128)
batch 881: ({'logprob': [29.29166603088379, 5.0]}, 128)
batch 882: ({'logprob': [54.601661682128906, 14.0]}, 128)
batch 883: ({'logprob': [61.801551818847656, 17.0]}, 128)
batch 884: ({'logprob': [51.24042510986328, 13.0]}, 128)
batch 885: ({'logprob': [52.0455436706543, 13.0]}, 128)
batch 886: ({'logprob': [62.224945068359375, 17.0]}, 128)

======================Test output======================
logprob:  0.416107, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961809e-03 [2.654006e-09] 
Layer 'conv1' biases: 3.248712e-07 [6.580940e-11] 
Layer 'conv2' weights[0]: 7.948909e-03 [1.902715e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.667582e-10] 
Layer 'conv3' weights[0]: 7.947066e-03 [1.787297e-09] 
Layer 'conv3' biases: 2.759278e-06 [8.279806e-10] 
Layer 'conv4' weights[0]: 7.979774e-03 [1.774595e-09] 
Layer 'conv4' biases: 9.999994e-01 [6.041743e-09] 
Layer 'conv5' weights[0]: 7.978554e-03 [3.501423e-08] 
Layer 'conv5' biases: 9.999923e-01 [3.762572e-08] 
Layer 'fc6' weights[0]: 7.575182e-03 [3.003730e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.955743e-09] 
Layer 'fc7' weights[0]: 6.996663e-03 [1.214738e-07] 
Layer 'fc7' biases: 9.998574e-01 [1.079850e-07] 
Layer 'fc8' weights[0]: 1.288956e-03 [1.007096e-05] 
Layer 'fc8' biases: 6.582102e-02 [6.920111e-05] 
Train error last 870 batches: 0.435202
-------------------------------------------------------
Not saving because 0.416107 > 0.415666 (22.630: -0.00%)
======================================================= (12.069 sec)
27.181... logprob:  0.539298, 0.156250 (1.426 sec)
27.182... logprob:  0.371298, 0.093750 (1.426 sec)
27.183... logprob:  0.419936, 0.109375 (1.422 sec)
27.184... logprob:  0.483441, 0.132812 (1.425 sec)
27.185... logprob:  0.289766, 0.062500 (1.398 sec)
27.186... logprob:  0.370380, 0.093750 (1.398 sec)
27.187... logprob:  0.529617, 0.148438 (1.403 sec)
27.188... logprob:  0.458886, 0.125000 (1.396 sec)
27.189... logprob:  0.440918, 0.117188 (1.392 sec)
27.190... logprob:  0.375782, 0.093750 (1.441 sec)
27.191... logprob:  0.485093, 0.132812 (1.407 sec)
27.192... logprob:  0.520051, 0.148438 (1.420 sec)
27.193... logprob:  0.312511, 0.070312 (1.419 sec)
27.194... logprob:  0.414061, 0.109375 (1.418 sec)
27.195... logprob:  0.287057, 0.062500 (1.398 sec)
27.196... logprob:  0.410474, 0.109375 (1.397 sec)
27.197... logprob:  0.477989, 0.132812 (1.397 sec)
27.198... logprob:  0.355796, 0.085938 (1.408 sec)
27.199... logprob:  0.437193, 0.117188 (1.389 sec)
27.200... logprob:  0.440736, 0.117188 (1.438 sec)
27.201... logprob:  0.437090, 0.117188 (1.412 sec)
27.202... logprob:  0.537858, 0.148438 (1.403 sec)
27.203... logprob:  0.420413, 0.109375 (1.444 sec)
27.204... logprob:  0.504123, 0.140625 (1.389 sec)
27.205... logprob:  0.334297, 0.078125 (1.407 sec)
27.206... logprob:  0.361634, 0.093750 (1.406 sec)
27.207... logprob:  0.381784, 0.093750 (1.398 sec)
27.208... logprob:  0.490574, 0.140625 (1.403 sec)
27.209... logprob:  0.334544, 0.078125 (1.420 sec)
27.210... logprob:  0.586229, 0.171875 (1.421 sec)
27.211... logprob:  0.488133, 0.132812 (1.415 sec)
27.212... logprob:  0.526122, 0.148438 (1.413 sec)
27.213... logprob:  0.514643, 0.140625 (1.456 sec)
27.214... logprob:  0.459399, 0.125000 (1.429 sec)
27.215... logprob:  0.396099, 0.101562 (1.426 sec)
27.216... logprob:  0.516945, 0.140625 (1.472 sec)
27.217... logprob:  0.324894, 0.070312 (1.401 sec)
27.218... logprob:  0.463602, 0.125000 (1.425 sec)
27.219... logprob:  0.500239, 0.140625 (1.415 sec)
27.220... logprob:  0.415023, 0.109375 (1.427 sec)
27.221... logprob:  0.399566, 0.101562 (1.410 sec)
27.222... logprob:  0.554429, 0.164062 (1.458 sec)
27.223... logprob:  0.568976, 0.164062 (1.429 sec)
27.224... logprob:  0.405964, 0.101562 (1.429 sec)
27.225... logprob:  0.392000, 0.101562 (1.450 sec)
27.226... logprob:  0.424730, 0.109375 (1.430 sec)
27.227... logprob:  0.452638, 0.125000 (1.420 sec)
27.228... logprob:  0.417172, 0.109375 (1.421 sec)
27.229... logprob:  0.489371, 0.132812 (1.427 sec)
27.230... logprob:  0.459856, 0.125000 (1.429 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.99352264404297, 10.0]}, 128)
batch 872: ({'logprob': [66.45022583007812, 19.0]}, 128)
batch 873: ({'logprob': [40.736148834228516, 9.0]}, 128)
batch 874: ({'logprob': [45.37055587768555, 11.0]}, 128)
batch 875: ({'logprob': [50.835872650146484, 13.0]}, 128)
batch 876: ({'logprob': [63.94974136352539, 18.0]}, 128)
batch 877: ({'logprob': [45.796775817871094, 11.0]}, 128)
batch 878: ({'logprob': [61.820396423339844, 17.0]}, 128)
batch 879: ({'logprob': [73.17882537841797, 21.0]}, 128)
batch 880: ({'logprob': [50.86070251464844, 13.0]}, 128)
batch 881: ({'logprob': [29.340740203857422, 5.0]}, 128)
batch 882: ({'logprob': [54.64240646362305, 14.0]}, 128)
batch 883: ({'logprob': [61.79444122314453, 17.0]}, 128)
batch 884: ({'logprob': [51.262027740478516, 13.0]}, 128)
batch 885: ({'logprob': [52.097129821777344, 13.0]}, 128)
batch 886: ({'logprob': [62.23296356201172, 17.0]}, 128)

======================Test output======================
logprob:  0.416193, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961772e-03 [2.258740e-09] 
Layer 'conv1' biases: 3.258965e-07 [5.397116e-11] 
Layer 'conv2' weights[0]: 7.948868e-03 [1.810435e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.199581e-10] 
Layer 'conv3' weights[0]: 7.947025e-03 [1.438663e-09] 
Layer 'conv3' biases: 2.769030e-06 [6.432382e-10] 
Layer 'conv4' weights[0]: 7.979735e-03 [1.415527e-09] 
Layer 'conv4' biases: 9.999994e-01 [4.112432e-09] 
Layer 'conv5' weights[0]: 7.978513e-03 [2.668352e-08] 
Layer 'conv5' biases: 9.999924e-01 [2.869385e-08] 
Layer 'fc6' weights[0]: 7.575144e-03 [2.380146e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.247148e-09] 
Layer 'fc7' weights[0]: 6.994839e-03 [4.339779e-08] 
Layer 'fc7' biases: 9.998573e-01 [2.086267e-08] 
Layer 'fc8' weights[0]: 1.290919e-03 [2.058690e-06] 
Layer 'fc8' biases: 6.589135e-02 [1.449601e-05] 
Train error last 870 batches: 0.435201
-------------------------------------------------------
Not saving because 0.416193 > 0.415666 (22.630: -0.00%)
======================================================= (12.116 sec)
27.231... logprob:  0.453494, 0.125000 (1.419 sec)
27.232... logprob:  0.496169, 0.140625 (1.469 sec)
27.233... logprob:  0.466074, 0.132812 (1.431 sec)
27.234... logprob:  0.563858, 0.164062 (1.419 sec)
27.235... logprob:  0.482014, 0.132812 (1.471 sec)
27.236... logprob:  0.425668, 0.109375 (1.400 sec)
27.237... logprob:  0.340982, 0.078125 (1.428 sec)
27.238... logprob:  0.389145, 0.093750 (1.417 sec)
27.239... logprob:  0.478093, 0.132812 (1.417 sec)
27.240... logprob:  0.485796, 0.132812 (1.406 sec)
27.241... logprob:  0.493601, 0.132812 (1.463 sec)
27.242... logprob:  0.341636, 0.078125 (1.435 sec)
27.243... logprob:  0.385998, 0.093750 (1.437 sec)
27.244... logprob:  0.315392, 0.070312 (1.447 sec)
27.245... logprob:  0.494227, 0.132812 (1.429 sec)
27.246... logprob:  0.416853, 0.109375 (1.415 sec)
27.247... logprob:  0.357544, 0.085938 (1.418 sec)
27.248... logprob:  0.308016, 0.070312 (1.446 sec)
27.249... logprob:  0.554677, 0.156250 (1.431 sec)
27.250... logprob:  0.591254, 0.164062 (1.405 sec)
27.251... logprob:  0.352982, 0.085938 (1.457 sec)
27.252... logprob:  0.348441, 0.085938 (1.430 sec)
27.253... logprob:  0.379215, 0.093750 (1.422 sec)
27.254... logprob:  0.444162, 0.117188 (1.464 sec)
27.255... logprob:  0.351346, 0.085938 (1.409 sec)
27.256... logprob:  0.378845, 0.093750 (1.424 sec)
27.257... logprob:  0.331978, 0.078125 (1.419 sec)
27.258... logprob:  0.415555, 0.109375 (1.429 sec)
27.259... logprob:  0.442316, 0.117188 (1.402 sec)
27.260... logprob:  0.308214, 0.070312 (1.461 sec)
27.261... logprob:  0.392596, 0.101562 (1.428 sec)
27.262... logprob:  0.524538, 0.148438 (1.433 sec)
27.263... logprob:  0.425575, 0.109375 (1.454 sec)
27.264... logprob:  0.375040, 0.093750 (1.429 sec)
27.265... logprob:  0.439610, 0.117188 (1.423 sec)
27.266... logprob:  0.439010, 0.117188 (1.414 sec)
27.267... logprob:  0.422031, 0.109375 (1.421 sec)
27.268... logprob:  0.458939, 0.125000 (1.422 sec)
27.269... logprob:  0.567559, 0.164062 (1.412 sec)
27.270... logprob:  0.542317, 0.156250 (1.464 sec)
27.271... logprob:  0.445619, 0.117188 (1.434 sec)
27.272... logprob:  0.384589, 0.093750 (1.422 sec)
27.273... logprob:  0.500231, 0.140625 (1.474 sec)
27.274... logprob:  0.542502, 0.156250 (1.398 sec)
27.275... logprob:  0.487592, 0.132812 (1.426 sec)
27.276... logprob:  0.390031, 0.093750 (1.419 sec)
27.277... logprob:  0.428616, 0.109375 (1.423 sec)
27.278... logprob:  0.323591, 0.070312 (1.425 sec)
27.279... logprob:  0.325243, 0.070312 (1.460 sec)
27.280... logprob:  0.215904, 0.031250 (1.411 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.987335205078125, 10.0]}, 128)
batch 872: ({'logprob': [66.63561248779297, 19.0]}, 128)
batch 873: ({'logprob': [40.52910614013672, 9.0]}, 128)
batch 874: ({'logprob': [45.30469512939453, 11.0]}, 128)
batch 875: ({'logprob': [50.80635070800781, 13.0]}, 128)
batch 876: ({'logprob': [64.09100341796875, 18.0]}, 128)
batch 877: ({'logprob': [45.6784782409668, 11.0]}, 128)
batch 878: ({'logprob': [61.86463928222656, 17.0]}, 128)
batch 879: ({'logprob': [73.24491882324219, 21.0]}, 128)
batch 880: ({'logprob': [50.831363677978516, 13.0]}, 128)
batch 881: ({'logprob': [29.111909866333008, 5.0]}, 128)
batch 882: ({'logprob': [54.50135040283203, 14.0]}, 128)
batch 883: ({'logprob': [61.838623046875, 17.0]}, 128)
batch 884: ({'logprob': [51.18101119995117, 13.0]}, 128)
batch 885: ({'logprob': [51.91168975830078, 13.0]}, 128)
batch 886: ({'logprob': [62.2253303527832, 17.0]}, 128)

======================Test output======================
logprob:  0.415890, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961734e-03 [9.401520e-09] 
Layer 'conv1' biases: 3.269273e-07 [3.916413e-10] 
Layer 'conv2' weights[0]: 7.948833e-03 [9.187503e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.013945e-09] 
Layer 'conv3' weights[0]: 7.946987e-03 [9.144367e-09] 
Layer 'conv3' biases: 2.773172e-06 [6.089072e-09] 
Layer 'conv4' weights[0]: 7.979692e-03 [9.234408e-09] 
Layer 'conv4' biases: 9.999994e-01 [5.379279e-08] 
Layer 'conv5' weights[0]: 7.978475e-03 [3.461379e-07] 
Layer 'conv5' biases: 9.999918e-01 [3.723718e-07] 
Layer 'fc6' weights[0]: 7.575097e-03 [2.832265e-08] 
Layer 'fc6' biases: 1.000000e+00 [2.896509e-08] 
Layer 'fc7' weights[0]: 6.993059e-03 [6.485579e-07] 
Layer 'fc7' biases: 9.998572e-01 [6.359375e-07] 
Layer 'fc8' weights[0]: 1.297865e-03 [2.302857e-05] 
Layer 'fc8' biases: 6.604378e-02 [1.654537e-04] 
Train error last 870 batches: 0.435201
-------------------------------------------------------
Not saving because 0.415890 > 0.415666 (22.630: -0.00%)
======================================================= (12.025 sec)
27.281... logprob:  0.417246, 0.109375 (1.448 sec)
27.282... logprob:  0.411333, 0.109375 (1.430 sec)
27.283... logprob:  0.393744, 0.101562 (1.420 sec)
27.284... logprob:  0.394416, 0.101562 (1.416 sec)
27.285... logprob:  0.451499, 0.117188 (1.446 sec)
27.286... logprob:  0.536444, 0.140625 (1.442 sec)
27.287... logprob:  0.346547, 0.085938 (1.429 sec)
27.288... logprob:  0.329947, 0.078125 (1.438 sec)
27.289... logprob:  0.445826, 0.117188 (1.445 sec)
27.290... logprob:  0.490651, 0.132812 (1.410 sec)
27.291... logprob:  0.439302, 0.117188 (1.421 sec)
27.292... logprob:  0.567622, 0.156250 (1.426 sec)
27.293... logprob:  0.427722, 0.117188 (1.421 sec)
27.294... logprob:  0.355788, 0.085938 (1.407 sec)
27.295... logprob:  0.334433, 0.078125 (1.463 sec)
27.296... logprob:  0.355559, 0.085938 (1.424 sec)
27.297... logprob:  0.394402, 0.101562 (1.425 sec)
27.298... logprob:  0.448227, 0.125000 (1.469 sec)
27.299... logprob:  0.342032, 0.078125 (1.409 sec)
27.300... logprob:  0.406405, 0.101562 (1.429 sec)
27.301... logprob:  0.397894, 0.101562 (1.422 sec)
27.302... logprob:  0.591577, 0.179688 (1.418 sec)
27.303... logprob:  0.459505, 0.125000 (1.412 sec)
27.304... logprob:  0.459626, 0.125000 (1.444 sec)
27.305... logprob:  0.455200, 0.125000 (1.445 sec)
27.306... logprob:  0.440578, 0.117188 (1.431 sec)
27.307... logprob:  0.421621, 0.109375 (1.447 sec)
27.308... logprob:  0.374801, 0.093750 (1.454 sec)
27.309... logprob:  0.450481, 0.125000 (1.419 sec)
27.310... logprob:  0.473605, 0.125000 (1.424 sec)
27.311... logprob:  0.502488, 0.140625 (1.423 sec)
27.312... logprob:  0.478690, 0.132812 (1.438 sec)
27.313... logprob:  0.454859, 0.125000 (1.418 sec)
27.314... logprob:  0.454371, 0.117188 (1.471 sec)
27.315... logprob:  0.314677, 0.070312 (1.435 sec)
27.316... logprob:  0.468519, 0.125000 (1.423 sec)
27.317... logprob:  0.355438, 0.085938 (1.482 sec)
27.318... logprob:  0.455403, 0.125000 (1.420 sec)
27.319... logprob:  0.423172, 0.117188 (1.428 sec)
27.320... logprob:  0.412237, 0.109375 (1.428 sec)
27.321... logprob:  0.348245, 0.085938 (1.426 sec)
27.322... logprob:  0.387448, 0.101562 (1.412 sec)
27.323... logprob:  0.416506, 0.109375 (1.520 sec)
27.324... logprob:  0.498600, 0.140625 (1.430 sec)
27.325... logprob:  0.350675, 0.085938 (1.440 sec)
27.326... logprob:  0.543179, 0.148438 (1.458 sec)
27.327... logprob:  0.554410, 0.164062 (1.422 sec)
27.328... logprob:  0.565114, 0.156250 (1.439 sec)
27.329... logprob:  0.401925, 0.101562 (1.428 sec)
27.330... logprob:  0.388526, 0.101562 (1.429 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.07862854003906, 10.0]}, 128)
batch 872: ({'logprob': [65.97761535644531, 19.0]}, 128)
batch 873: ({'logprob': [41.51385498046875, 9.0]}, 128)
batch 874: ({'logprob': [45.6779899597168, 11.0]}, 128)
batch 875: ({'logprob': [51.04133605957031, 13.0]}, 128)
batch 876: ({'logprob': [63.61935043334961, 18.0]}, 128)
batch 877: ({'logprob': [46.28801345825195, 11.0]}, 128)
batch 878: ({'logprob': [61.817588806152344, 17.0]}, 128)
batch 879: ({'logprob': [73.15068054199219, 21.0]}, 128)
batch 880: ({'logprob': [51.06495666503906, 13.0]}, 128)
batch 881: ({'logprob': [30.143768310546875, 5.0]}, 128)
batch 882: ({'logprob': [55.25200271606445, 14.0]}, 128)
batch 883: ({'logprob': [61.79237747192383, 17.0]}, 128)
batch 884: ({'logprob': [51.64852523803711, 13.0]}, 128)
batch 885: ({'logprob': [52.84991455078125, 13.0]}, 128)
batch 886: ({'logprob': [62.41252517700195, 17.0]}, 128)

======================Test output======================
logprob:  0.418129, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961703e-03 [2.768709e-09] 
Layer 'conv1' biases: 3.280248e-07 [4.414296e-11] 
Layer 'conv2' weights[0]: 7.948801e-03 [1.880777e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.491889e-10] 
Layer 'conv3' weights[0]: 7.946945e-03 [1.286334e-09] 
Layer 'conv3' biases: 2.786110e-06 [3.732498e-10] 
Layer 'conv4' weights[0]: 7.979655e-03 [1.188748e-09] 
Layer 'conv4' biases: 9.999994e-01 [5.258139e-10] 
Layer 'conv5' weights[0]: 7.978434e-03 [3.681895e-09] 
Layer 'conv5' biases: 9.999925e-01 [3.883212e-09] 
Layer 'fc6' weights[0]: 7.575064e-03 [8.127057e-10] 
Layer 'fc6' biases: 1.000000e+00 [2.837303e-10] 
Layer 'fc7' weights[0]: 6.991277e-03 [2.135071e-07] 
Layer 'fc7' biases: 9.998572e-01 [2.036833e-07] 
Layer 'fc8' weights[0]: 1.276603e-03 [7.880622e-06] 
Layer 'fc8' biases: 6.615842e-02 [4.961186e-05] 
Train error last 870 batches: 0.435201
-------------------------------------------------------
Not saving because 0.418129 > 0.415666 (22.630: -0.00%)
======================================================= (12.144 sec)
27.331... logprob:  0.352299, 0.085938 (1.431 sec)
27.332... logprob:  0.482781, 0.132812 (1.453 sec)
27.333... logprob:  0.339497, 0.085938 (1.442 sec)
27.334... logprob:  0.565262, 0.171875 (1.445 sec)
27.335... logprob:  0.358712, 0.085938 (1.439 sec)
27.336... logprob:  0.444855, 0.125000 (1.459 sec)
27.337... logprob:  0.566412, 0.164062 (1.427 sec)
27.338... logprob:  0.449515, 0.125000 (1.427 sec)
27.339... logprob:  0.488604, 0.132812 (1.430 sec)
27.340... logprob:  0.442066, 0.117188 (1.426 sec)
27.341... logprob:  0.530044, 0.148438 (1.425 sec)
27.342... logprob:  0.429614, 0.109375 (1.470 sec)
27.343... logprob:  0.434768, 0.109375 (1.442 sec)
27.344... logprob:  0.444507, 0.125000 (1.483 sec)
27.345... logprob:  0.488198, 0.132812 (1.442 sec)
27.346... logprob:  0.436212, 0.117188 (1.437 sec)
27.347... logprob:  0.372512, 0.085938 (1.488 sec)
27.348... logprob:  0.398478, 0.101562 (1.431 sec)
27.349... logprob:  0.497638, 0.140625 (1.434 sec)
27.350... logprob:  0.358682, 0.085938 (1.441 sec)
27.351... logprob:  0.508516, 0.140625 (1.429 sec)
27.352... logprob:  0.363618, 0.093750 (1.438 sec)
27.353... logprob:  0.512504, 0.148438 (1.489 sec)
27.354... logprob:  0.674848, 0.203125 (1.435 sec)
27.355... logprob:  0.357494, 0.085938 (1.443 sec)
27.356... logprob:  0.479240, 0.132812 (1.490 sec)
27.357... logprob:  0.346778, 0.085938 (1.436 sec)
27.358... logprob:  0.325792, 0.070312 (1.438 sec)
27.359... logprob:  0.555353, 0.164062 (1.440 sec)
27.360... logprob:  0.444521, 0.117188 (1.432 sec)
27.361... logprob:  0.410740, 0.101562 (1.434 sec)
27.362... logprob:  0.423973, 0.117188 (1.479 sec)
27.363... logprob:  0.486588, 0.132812 (1.443 sec)
27.364... logprob:  0.475600, 0.125000 (1.456 sec)
27.365... logprob:  0.425047, 0.109375 (1.463 sec)
27.366... logprob:  0.409588, 0.109375 (1.448 sec)
27.367... logprob:  0.324918, 0.078125 (1.442 sec)
27.368... logprob:  0.595573, 0.171875 (1.428 sec)
27.369... logprob:  0.381642, 0.093750 (1.438 sec)
27.370... logprob:  0.381275, 0.093750 (1.437 sec)
27.371... logprob:  0.400411, 0.101562 (1.464 sec)
27.372... logprob:  0.537287, 0.156250 (1.455 sec)
27.373... logprob:  0.463793, 0.125000 (1.456 sec)
27.374... logprob:  0.526858, 0.148438 (1.448 sec)
27.375... logprob:  0.393769, 0.101562 (1.465 sec)
27.376... logprob:  0.374291, 0.093750 (1.440 sec)
27.377... logprob:  0.295425, 0.062500 (1.429 sec)
27.378... logprob:  0.453681, 0.125000 (1.432 sec)
27.379... logprob:  0.420243, 0.109375 (1.441 sec)
27.380... logprob:  0.605688, 0.179688 (1.440 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.79989242553711, 10.0]}, 128)
batch 872: ({'logprob': [66.62254333496094, 19.0]}, 128)
batch 873: ({'logprob': [40.51079559326172, 9.0]}, 128)
batch 874: ({'logprob': [45.22175979614258, 11.0]}, 128)
batch 875: ({'logprob': [50.76831817626953, 13.0]}, 128)
batch 876: ({'logprob': [64.08283996582031, 18.0]}, 128)
batch 877: ({'logprob': [45.650146484375, 11.0]}, 128)
batch 878: ({'logprob': [61.91622543334961, 17.0]}, 128)
batch 879: ({'logprob': [73.44035339355469, 21.0]}, 128)
batch 880: ({'logprob': [50.793357849121094, 13.0]}, 128)
batch 881: ({'logprob': [28.949344635009766, 5.0]}, 128)
batch 882: ({'logprob': [54.62250518798828, 14.0]}, 128)
batch 883: ({'logprob': [61.89011764526367, 17.0]}, 128)
batch 884: ({'logprob': [51.197845458984375, 13.0]}, 128)
batch 885: ({'logprob': [52.03795623779297, 13.0]}, 128)
batch 886: ({'logprob': [62.33169937133789, 17.0]}, 128)

======================Test output======================
logprob:  0.415935, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961671e-03 [4.213248e-09] 
Layer 'conv1' biases: 3.289037e-07 [1.695134e-10] 
Layer 'conv2' weights[0]: 7.948763e-03 [3.546836e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.574537e-10] 
Layer 'conv3' weights[0]: 7.946910e-03 [3.803529e-09] 
Layer 'conv3' biases: 2.791969e-06 [2.589958e-09] 
Layer 'conv4' weights[0]: 7.979619e-03 [3.627694e-09] 
Layer 'conv4' biases: 9.999994e-01 [2.123628e-08] 
Layer 'conv5' weights[0]: 7.978398e-03 [1.332373e-07] 
Layer 'conv5' biases: 9.999923e-01 [1.435967e-07] 
Layer 'fc6' weights[0]: 7.575014e-03 [1.097922e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.124404e-08] 
Layer 'fc7' weights[0]: 6.989492e-03 [1.061947e-07] 
Layer 'fc7' biases: 9.998574e-01 [9.301642e-08] 
Layer 'fc8' weights[0]: 1.298322e-03 [4.415531e-06] 
Layer 'fc8' biases: 6.640515e-02 [2.890569e-05] 
Train error last 870 batches: 0.435200
-------------------------------------------------------
Not saving because 0.415935 > 0.415666 (22.630: -0.00%)
======================================================= (12.041 sec)
27.381... logprob:  0.463423, 0.125000 (1.476 sec)
27.382... logprob:  0.529570, 0.148438 (1.458 sec)
27.383... logprob:  0.358552, 0.085938 (1.441 sec)
27.384... logprob:  0.521190, 0.148438 (1.482 sec)
27.385... logprob:  0.523568, 0.148438 (1.431 sec)
27.386... logprob:  0.582546, 0.171875 (1.431 sec)
27.387... logprob:  0.428533, 0.117188 (1.437 sec)
27.388... logprob:  0.521369, 0.148438 (1.438 sec)
27.389... logprob:  0.425618, 0.109375 (1.445 sec)
27.390... logprob:  0.419707, 0.109375 (1.477 sec)
27.391... logprob:  0.318182, 0.070312 (1.446 sec)
27.392... logprob:  0.439448, 0.117188 (1.435 sec)
27.393... logprob:  0.369004, 0.093750 (1.491 sec)
27.394... logprob:  0.343675, 0.078125 (1.430 sec)
27.395... logprob:  0.331856, 0.078125 (1.433 sec)
27.396... logprob:  0.252489, 0.046875 (1.440 sec)
27.397... logprob:  0.484181, 0.132812 (1.433 sec)
27.398... logprob:  0.470772, 0.125000 (1.438 sec)
27.399... logprob:  0.433234, 0.117188 (1.484 sec)
27.400... logprob:  0.537590, 0.148438 (1.437 sec)
27.401... logprob:  0.465707, 0.125000 (1.442 sec)
27.402... logprob:  0.473883, 0.125000 (1.481 sec)
27.403... logprob:  0.462115, 0.125000 (1.434 sec)
27.404... logprob:  0.474810, 0.125000 (1.437 sec)
27.405... logprob:  0.544214, 0.156250 (1.441 sec)
27.406... logprob:  0.357590, 0.085938 (1.428 sec)
27.407... logprob:  0.492985, 0.140625 (1.433 sec)
27.408... logprob:  0.338970, 0.078125 (1.488 sec)
27.409... logprob:  0.400482, 0.101562 (1.438 sec)
27.410... logprob:  0.582227, 0.171875 (1.451 sec)
27.411... logprob:  0.397804, 0.101562 (1.472 sec)
27.412... logprob:  0.540305, 0.156250 (1.440 sec)
27.413... logprob:  0.544663, 0.156250 (1.441 sec)
27.414... logprob:  0.466410, 0.125000 (1.435 sec)
27.415... logprob:  0.401672, 0.101562 (1.429 sec)
27.416... logprob:  0.427505, 0.109375 (1.443 sec)
27.417... logprob:  0.405462, 0.093750 (1.468 sec)
27.418... logprob:  0.380413, 0.093750 (1.452 sec)
27.419... logprob:  0.417838, 0.101562 (1.450 sec)
27.420... logprob:  0.356401, 0.085938 (1.461 sec)
27.421... logprob:  0.376635, 0.101562 (1.456 sec)
27.422... logprob:  0.522216, 0.148438 (1.452 sec)
27.423... logprob:  0.420832, 0.109375 (1.424 sec)
27.424... logprob:  0.324866, 0.078125 (1.435 sec)
27.425... logprob:  0.306453, 0.070312 (1.437 sec)
27.426... logprob:  0.449081, 0.117188 (1.445 sec)
27.427... logprob:  0.554187, 0.156250 (1.473 sec)
27.428... logprob:  0.601674, 0.171875 (1.460 sec)
27.429... logprob:  0.426342, 0.109375 (1.441 sec)
27.430... logprob:  0.299795, 0.070312 (1.502 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.187007904052734, 10.0]}, 128)
batch 872: ({'logprob': [67.25332641601562, 19.0]}, 128)
batch 873: ({'logprob': [40.009891510009766, 9.0]}, 128)
batch 874: ({'logprob': [44.860355377197266, 11.0]}, 128)
batch 875: ({'logprob': [50.690494537353516, 13.0]}, 128)
batch 876: ({'logprob': [64.60808563232422, 18.0]}, 128)
batch 877: ({'logprob': [45.36012268066406, 11.0]}, 128)
batch 878: ({'logprob': [62.40708541870117, 17.0]}, 128)
batch 879: ({'logprob': [74.57203674316406, 21.0]}, 128)
batch 880: ({'logprob': [50.71554946899414, 13.0]}, 128)
batch 881: ({'logprob': [27.80635643005371, 5.0]}, 128)
batch 882: ({'logprob': [54.869049072265625, 14.0]}, 128)
batch 883: ({'logprob': [62.38114547729492, 17.0]}, 128)
batch 884: ({'logprob': [51.19440841674805, 13.0]}, 128)
batch 885: ({'logprob': [52.17927932739258, 13.0]}, 128)
batch 886: ({'logprob': [62.896018981933594, 17.0]}, 128)

======================Test output======================
logprob:  0.416499, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961632e-03 [2.375335e-09] 
Layer 'conv1' biases: 3.299161e-07 [4.541111e-11] 
Layer 'conv2' weights[0]: 7.948728e-03 [1.864682e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.503156e-10] 
Layer 'conv3' weights[0]: 7.946874e-03 [1.562334e-09] 
Layer 'conv3' biases: 2.799221e-06 [7.389730e-10] 
Layer 'conv4' weights[0]: 7.979577e-03 [1.512401e-09] 
Layer 'conv4' biases: 9.999994e-01 [5.278566e-09] 
Layer 'conv5' weights[0]: 7.978357e-03 [3.156554e-08] 
Layer 'conv5' biases: 9.999924e-01 [3.390160e-08] 
Layer 'fc6' weights[0]: 7.574975e-03 [2.764237e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.704253e-09] 
Layer 'fc7' weights[0]: 6.987720e-03 [2.068843e-07] 
Layer 'fc7' biases: 9.998582e-01 [1.970869e-07] 
Layer 'fc8' weights[0]: 1.317200e-03 [7.839901e-06] 
Layer 'fc8' biases: 6.688328e-02 [4.343205e-05] 
Train error last 870 batches: 0.435200
-------------------------------------------------------
Not saving because 0.416499 > 0.415666 (22.630: -0.00%)
======================================================= (12.050 sec)
27.431... logprob:  0.599947, 0.171875 (1.446 sec)
27.432... logprob:  0.387532, 0.093750 (1.432 sec)
27.433... logprob:  0.329703, 0.078125 (1.439 sec)
27.434... logprob:  0.529563, 0.148438 (1.439 sec)
27.435... logprob:  0.532454, 0.156250 (1.436 sec)
27.436... logprob:  0.381030, 0.093750 (1.476 sec)
27.437... logprob:  0.500313, 0.140625 (1.454 sec)
27.438... logprob:  0.546962, 0.156250 (1.436 sec)
27.439... logprob:  0.378685, 0.093750 (1.493 sec)
27.440... logprob:  0.439692, 0.117188 (1.430 sec)
27.441... logprob:  0.467966, 0.125000 (1.432 sec)
27.442... logprob:  0.378933, 0.093750 (1.440 sec)
27.443... logprob:  0.496563, 0.140625 (1.432 sec)
27.444... logprob:  0.372371, 0.093750 (1.435 sec)
27.445... logprob:  0.362567, 0.085938 (1.558 sec)
27.446... logprob:  0.398349, 0.101562 (1.440 sec)
27.447... logprob:  0.569637, 0.164062 (1.441 sec)
27.448... logprob:  0.332935, 0.078125 (1.483 sec)
27.449... logprob:  0.400039, 0.101562 (1.433 sec)
27.450... logprob:  0.239593, 0.046875 (1.438 sec)
27.451... logprob:  0.452598, 0.125000 (1.439 sec)
27.452... logprob:  0.456059, 0.117188 (1.430 sec)
27.453... logprob:  0.455170, 0.125000 (1.434 sec)
27.454... logprob:  0.488946, 0.132812 (1.486 sec)
27.455... logprob:  0.506044, 0.140625 (1.441 sec)
27.456... logprob:  0.468840, 0.125000 (1.445 sec)
27.457... logprob:  0.375331, 0.093750 (1.479 sec)
27.458... logprob:  0.351006, 0.085938 (1.433 sec)
27.459... logprob:  0.514005, 0.140625 (1.446 sec)
27.460... logprob:  0.273827, 0.054688 (1.435 sec)
27.461... logprob:  0.460106, 0.125000 (1.425 sec)
27.462... logprob:  0.471979, 0.125000 (1.437 sec)
27.463... logprob:  0.420828, 0.109375 (1.481 sec)
27.464... logprob:  0.482775, 0.132812 (1.446 sec)
27.465... logprob:  0.421122, 0.109375 (1.459 sec)
27.466... logprob:  0.318340, 0.070312 (1.458 sec)
27.467... logprob:  0.413834, 0.109375 (1.456 sec)
27.468... logprob:  0.394262, 0.101562 (1.440 sec)
27.469... logprob:  0.334774, 0.078125 (1.431 sec)
27.470... logprob:  0.400095, 0.101562 (1.424 sec)
27.471... logprob:  0.529281, 0.148438 (1.443 sec)
27.472... logprob:  0.409996, 0.109375 (1.461 sec)
27.473... logprob:  0.375452, 0.093750 (1.460 sec)
27.474... logprob:  0.465563, 0.125000 (1.453 sec)
27.475... logprob:  0.503991, 0.140625 (1.451 sec)
27.476... logprob:  0.510212, 0.140625 (1.469 sec)
27.477... logprob:  0.334619, 0.078125 (1.437 sec)
27.478... logprob:  0.464241, 0.125000 (1.432 sec)
27.479... logprob:  0.305772, 0.070312 (1.434 sec)
27.480... logprob:  0.443506, 0.117188 (1.437 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.758731842041016, 10.0]}, 128)
batch 872: ({'logprob': [66.71217346191406, 19.0]}, 128)
batch 873: ({'logprob': [40.413917541503906, 9.0]}, 128)
batch 874: ({'logprob': [45.176578521728516, 11.0]}, 128)
batch 875: ({'logprob': [50.750919342041016, 13.0]}, 128)
batch 876: ({'logprob': [64.1524658203125, 18.0]}, 128)
batch 877: ({'logprob': [45.5929069519043, 11.0]}, 128)
batch 878: ({'logprob': [61.954036712646484, 17.0]}, 128)
batch 879: ({'logprob': [73.52200317382812, 21.0]}, 128)
batch 880: ({'logprob': [50.77571487426758, 13.0]}, 128)
batch 881: ({'logprob': [28.80893325805664, 5.0]}, 128)
batch 882: ({'logprob': [54.58909606933594, 14.0]}, 128)
batch 883: ({'logprob': [61.928245544433594, 17.0]}, 128)
batch 884: ({'logprob': [51.16873550415039, 13.0]}, 128)
batch 885: ({'logprob': [51.984962463378906, 13.0]}, 128)
batch 886: ({'logprob': [62.35772705078125, 17.0]}, 128)

======================Test output======================
logprob:  0.415843, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961598e-03 [2.464238e-09] 
Layer 'conv1' biases: 3.307741e-07 [3.605477e-11] 
Layer 'conv2' weights[0]: 7.948689e-03 [1.605142e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.557601e-10] 
Layer 'conv3' weights[0]: 7.946830e-03 [1.210515e-09] 
Layer 'conv3' biases: 2.806329e-06 [4.586602e-10] 
Layer 'conv4' weights[0]: 7.979540e-03 [1.199153e-09] 
Layer 'conv4' biases: 9.999994e-01 [3.027621e-09] 
Layer 'conv5' weights[0]: 7.978319e-03 [1.887215e-08] 
Layer 'conv5' biases: 9.999923e-01 [2.032743e-08] 
Layer 'fc6' weights[0]: 7.574944e-03 [1.755027e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.585390e-09] 
Layer 'fc7' weights[0]: 6.985909e-03 [4.219922e-08] 
Layer 'fc7' biases: 9.998574e-01 [2.047258e-08] 
Layer 'fc8' weights[0]: 1.291271e-03 [1.339670e-06] 
Layer 'fc8' biases: 6.696442e-02 [8.193761e-06] 
Train error last 870 batches: 0.435199
-------------------------------------------------------
Not saving because 0.415843 > 0.415666 (22.630: -0.00%)
======================================================= (12.056 sec)
27.481... logprob:  0.547806, 0.156250 (1.439 sec)
27.482... logprob:  0.443144, 0.117188 (1.479 sec)
27.483... logprob:  0.502680, 0.140625 (1.451 sec)
27.484... logprob:  0.485316, 0.132812 (1.442 sec)
27.485... logprob:  0.408949, 0.109375 (1.485 sec)
27.486... logprob:  0.361330, 0.085938 (1.437 sec)
27.487... logprob:  0.522685, 0.148438 (1.426 sec)
27.488... logprob:  0.424739, 0.109375 (1.442 sec)
27.489... logprob:  0.415842, 0.109375 (1.432 sec)
27.490... logprob:  0.440690, 0.117188 (1.436 sec)
27.491... logprob:  0.313624, 0.070312 (1.482 sec)
27.492... logprob:  0.459538, 0.125000 (1.443 sec)
27.493... logprob:  0.521820, 0.148438 (1.436 sec)
27.494... logprob:  0.450350, 0.125000 (1.484 sec)
27.495... logprob:  0.380664, 0.093750 (1.438 sec)
27.496... logprob:  0.550256, 0.156250 (1.431 sec)
27.497... logprob:  0.466917, 0.125000 (1.440 sec)
27.498... logprob:  0.476231, 0.132812 (1.431 sec)
27.499... logprob:  0.456232, 0.125000 (1.431 sec)
27.500... logprob:  0.355146, 0.085938 (1.495 sec)
27.501... logprob:  0.339124, 0.078125 (1.430 sec)
27.502... logprob:  0.459612, 0.125000 (1.446 sec)
27.503... logprob:  0.400666, 0.101562 (1.479 sec)
27.504... logprob:  0.487289, 0.132812 (1.437 sec)
27.505... logprob:  0.570778, 0.164062 (1.437 sec)
27.506... logprob:  0.479685, 0.132812 (1.438 sec)
27.507... logprob:  0.385044, 0.093750 (1.427 sec)
27.508... logprob:  0.374670, 0.093750 (1.434 sec)
27.509... logprob:  0.323027, 0.070312 (1.484 sec)
27.510... logprob:  0.390459, 0.101562 (1.440 sec)
27.511... logprob:  0.410049, 0.109375 (1.457 sec)
27.512... logprob:  0.470720, 0.125000 (1.467 sec)
27.513... logprob:  0.324962, 0.078125 (1.442 sec)
27.514... logprob:  0.406272, 0.101562 (1.444 sec)
27.515... logprob:  0.455484, 0.125000 (1.428 sec)
27.516... logprob:  0.400283, 0.109375 (1.431 sec)
27.517... logprob:  0.627782, 0.179688 (1.440 sec)
27.518... logprob:  0.437653, 0.117188 (1.456 sec)
27.519... logprob:  0.516131, 0.140625 (1.462 sec)
27.520... logprob:  0.409644, 0.109375 (1.450 sec)
27.521... logprob:  0.427442, 0.109375 (1.461 sec)
27.522... logprob:  0.533151, 0.156250 (1.468 sec)
27.523... logprob:  0.331535, 0.078125 (1.440 sec)
27.524... logprob:  0.437158, 0.117188 (1.422 sec)
27.525... logprob:  0.425927, 0.109375 (1.435 sec)
27.526... logprob:  0.351703, 0.078125 (1.438 sec)
27.527... logprob:  0.504573, 0.140625 (1.445 sec)
27.528... logprob:  0.440464, 0.117188 (1.466 sec)
27.529... logprob:  0.353001, 0.085938 (1.454 sec)
27.530... logprob:  0.440253, 0.117188 (1.440 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.89921188354492, 10.0]}, 128)
batch 872: ({'logprob': [66.37767791748047, 19.0]}, 128)
batch 873: ({'logprob': [40.812644958496094, 9.0]}, 128)
batch 874: ({'logprob': [45.35692596435547, 11.0]}, 128)
batch 875: ({'logprob': [50.83300018310547, 13.0]}, 128)
batch 876: ({'logprob': [63.8969612121582, 18.0]}, 128)
batch 877: ({'logprob': [45.83341979980469, 11.0]}, 128)
batch 878: ({'logprob': [61.83815383911133, 17.0]}, 128)
batch 879: ({'logprob': [73.26754760742188, 21.0]}, 128)
batch 880: ({'logprob': [50.857505798339844, 13.0]}, 128)
batch 881: ({'logprob': [29.346454620361328, 5.0]}, 128)
batch 882: ({'logprob': [54.77025604248047, 14.0]}, 128)
batch 883: ({'logprob': [61.812355041503906, 17.0]}, 128)
batch 884: ({'logprob': [51.30946350097656, 13.0]}, 128)
batch 885: ({'logprob': [52.245201110839844, 13.0]}, 128)
batch 886: ({'logprob': [62.30110549926758, 17.0]}, 128)

======================Test output======================
logprob:  0.416386, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961548e-03 [2.255199e-09] 
Layer 'conv1' biases: 3.317810e-07 [8.672380e-11] 
Layer 'conv2' weights[0]: 7.948649e-03 [2.290195e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.637707e-10] 
Layer 'conv3' weights[0]: 7.946793e-03 [2.096835e-09] 
Layer 'conv3' biases: 2.816710e-06 [1.049555e-09] 
Layer 'conv4' weights[0]: 7.979504e-03 [2.189390e-09] 
Layer 'conv4' biases: 9.999994e-01 [9.019955e-09] 
Layer 'conv5' weights[0]: 7.978270e-03 [5.783237e-08] 
Layer 'conv5' biases: 9.999920e-01 [6.215814e-08] 
Layer 'fc6' weights[0]: 7.574900e-03 [4.875211e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.854315e-09] 
Layer 'fc7' weights[0]: 6.984128e-03 [1.763528e-07] 
Layer 'fc7' biases: 9.998573e-01 [1.655657e-07] 
Layer 'fc8' weights[0]: 1.280403e-03 [6.421009e-06] 
Layer 'fc8' biases: 6.695998e-02 [4.545007e-05] 
Train error last 870 batches: 0.435199
-------------------------------------------------------
Not saving because 0.416386 > 0.415666 (22.630: -0.00%)
======================================================= (12.050 sec)
27.531... logprob:  0.439960, 0.117188 (1.487 sec)
27.532... logprob:  0.467325, 0.125000 (1.436 sec)
27.533... logprob:  0.560378, 0.164062 (1.428 sec)
27.534... logprob:  0.325916, 0.078125 (1.431 sec)
27.535... logprob:  0.551466, 0.156250 (1.441 sec)
27.536... logprob:  0.507285, 0.140625 (1.432 sec)
27.537... logprob:  0.510011, 0.140625 (1.480 sec)
27.538... logprob:  0.486086, 0.132812 (1.449 sec)
27.539... logprob:  0.296043, 0.062500 (1.434 sec)
27.540... logprob:  0.447177, 0.117188 (1.484 sec)
27.541... logprob:  0.388803, 0.101562 (1.436 sec)
27.542... logprob:  0.411246, 0.109375 (1.433 sec)
27.543... logprob:  0.233231, 0.039062 (1.437 sec)
27.544... logprob:  0.317924, 0.070312 (1.435 sec)
27.545... logprob:  0.348800, 0.085938 (1.433 sec)
27.546... logprob:  0.368272, 0.093750 (1.489 sec)
27.547... logprob:  0.440031, 0.117188 (1.435 sec)
27.548... logprob:  0.452922, 0.125000 (1.446 sec)
27.549... logprob:  0.490467, 0.132812 (1.479 sec)
27.550... logprob:  0.367620, 0.093750 (1.436 sec)
27.551... logprob:  0.441653, 0.117188 (1.435 sec)
27.552... logprob:  0.471264, 0.125000 (1.440 sec)
27.553... logprob:  0.349446, 0.085938 (1.426 sec)
27.554... logprob:  0.506963, 0.140625 (1.437 sec)
27.555... logprob:  0.421408, 0.109375 (1.482 sec)
27.556... logprob:  0.355806, 0.085938 (1.443 sec)
27.557... logprob:  0.396378, 0.101562 (1.458 sec)
27.558... logprob:  0.383011, 0.101562 (1.471 sec)
27.559... logprob:  0.441586, 0.125000 (1.441 sec)
27.560... logprob:  0.335085, 0.078125 (1.438 sec)
27.561... logprob:  0.411798, 0.109375 (1.436 sec)
27.562... logprob:  0.503149, 0.140625 (1.432 sec)
27.563... logprob:  0.373776, 0.093750 (1.439 sec)
27.564... logprob:  0.468475, 0.132812 (1.466 sec)
27.565... logprob:  0.611130, 0.187500 (1.455 sec)
27.566... logprob:  0.374877, 0.093750 (1.453 sec)
27.567... logprob:  0.423329, 0.109375 (1.468 sec)
27.568... logprob:  0.496335, 0.140625 (1.454 sec)
27.569... logprob:  0.507718, 0.140625 (1.442 sec)
27.570... logprob:  0.543776, 0.164062 (1.435 sec)
27.571... logprob:  0.454883, 0.125000 (1.435 sec)
27.572... logprob:  0.501387, 0.140625 (1.437 sec)
27.573... logprob:  0.512601, 0.148438 (1.449 sec)
27.574... logprob:  0.428051, 0.109375 (1.465 sec)
27.575... logprob:  0.343331, 0.078125 (1.451 sec)
27.576... logprob:  0.427364, 0.109375 (1.449 sec)
27.577... logprob:  0.460796, 0.125000 (1.478 sec)
27.578... logprob:  0.336737, 0.078125 (1.434 sec)
27.579... logprob:  0.442080, 0.117188 (1.433 sec)
27.580... logprob:  0.546698, 0.156250 (1.437 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.42780303955078, 10.0]}, 128)
batch 872: ({'logprob': [66.2426986694336, 19.0]}, 128)
batch 873: ({'logprob': [41.21567153930664, 9.0]}, 128)
batch 874: ({'logprob': [45.334468841552734, 11.0]}, 128)
batch 875: ({'logprob': [50.915565490722656, 13.0]}, 128)
batch 876: ({'logprob': [63.84172439575195, 18.0]}, 128)
batch 877: ({'logprob': [46.07553482055664, 11.0]}, 128)
batch 878: ({'logprob': [62.128196716308594, 17.0]}, 128)
batch 879: ({'logprob': [74.02862548828125, 21.0]}, 128)
batch 880: ({'logprob': [50.939083099365234, 13.0]}, 128)
batch 881: ({'logprob': [29.277118682861328, 5.0]}, 128)
batch 882: ({'logprob': [55.5655632019043, 14.0]}, 128)
batch 883: ({'logprob': [62.10283660888672, 17.0]}, 128)
batch 884: ({'logprob': [51.656131744384766, 13.0]}, 128)
batch 885: ({'logprob': [53.12107849121094, 13.0]}, 128)
batch 886: ({'logprob': [62.855712890625, 17.0]}, 128)

======================Test output======================
logprob:  0.418324, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961513e-03 [2.478172e-09] 
Layer 'conv1' biases: 3.328522e-07 [4.958875e-11] 
Layer 'conv2' weights[0]: 7.948599e-03 [1.810073e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.650730e-10] 
Layer 'conv3' weights[0]: 7.946758e-03 [1.566444e-09] 
Layer 'conv3' biases: 2.824199e-06 [8.258573e-10] 
Layer 'conv4' weights[0]: 7.979465e-03 [1.576243e-09] 
Layer 'conv4' biases: 9.999994e-01 [6.254989e-09] 
Layer 'conv5' weights[0]: 7.978231e-03 [4.108140e-08] 
Layer 'conv5' biases: 9.999917e-01 [4.415178e-08] 
Layer 'fc6' weights[0]: 7.574860e-03 [3.475265e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.456354e-09] 
Layer 'fc7' weights[0]: 6.982323e-03 [1.688125e-07] 
Layer 'fc7' biases: 9.998577e-01 [1.579527e-07] 
Layer 'fc8' weights[0]: 1.284558e-03 [8.221009e-06] 
Layer 'fc8' biases: 6.710470e-02 [5.734693e-05] 
Train error last 870 batches: 0.435199
-------------------------------------------------------
Not saving because 0.418324 > 0.415666 (22.630: -0.00%)
======================================================= (12.084 sec)
27.581... logprob:  0.530705, 0.156250 (1.445 sec)
27.582... logprob:  0.437817, 0.125000 (1.439 sec)
27.583... logprob:  0.592511, 0.171875 (1.476 sec)
27.584... logprob:  0.468080, 0.132812 (1.448 sec)
27.585... logprob:  0.349765, 0.085938 (1.434 sec)
27.586... logprob:  0.313080, 0.070312 (1.492 sec)
27.587... logprob:  0.404300, 0.101562 (1.431 sec)
27.588... logprob:  0.418658, 0.117188 (1.431 sec)
27.589... logprob:  0.361183, 0.093750 (1.439 sec)
27.590... logprob:  0.524759, 0.148438 (1.437 sec)
27.591... logprob:  0.397469, 0.101562 (1.433 sec)
27.592... logprob:  0.455671, 0.125000 (1.486 sec)
27.593... logprob:  0.467420, 0.125000 (1.438 sec)
27.594... logprob:  0.352837, 0.085938 (1.443 sec)
27.595... logprob:  0.428661, 0.109375 (1.489 sec)
27.596... logprob:  0.461607, 0.125000 (1.435 sec)
27.597... logprob:  0.397415, 0.101562 (1.437 sec)
27.598... logprob:  0.397220, 0.101562 (1.436 sec)
27.599... logprob:  0.313565, 0.070312 (1.429 sec)
27.600... logprob:  0.340884, 0.085938 (1.439 sec)
27.601... logprob:  0.402147, 0.101562 (1.484 sec)
27.602... logprob:  0.289845, 0.062500 (1.438 sec)
27.603... logprob:  0.267143, 0.054688 (1.444 sec)
27.604... logprob:  0.407521, 0.101562 (1.483 sec)
27.605... logprob:  0.563345, 0.148438 (1.433 sec)
27.606... logprob:  0.295943, 0.070312 (1.441 sec)
27.607... logprob:  0.504736, 0.132812 (1.435 sec)
27.608... logprob:  0.361827, 0.085938 (1.428 sec)
27.609... logprob:  0.357017, 0.085938 (1.438 sec)
27.610... logprob:  0.493320, 0.132812 (1.469 sec)
27.611... logprob:  0.510360, 0.140625 (1.451 sec)
27.612... logprob:  0.448502, 0.117188 (1.450 sec)
27.613... logprob:  0.279441, 0.062500 (1.453 sec)
27.614... logprob:  0.503561, 0.140625 (1.446 sec)
27.615... logprob:  0.350886, 0.085938 (1.443 sec)
27.616... logprob:  0.415118, 0.109375 (1.431 sec)
27.617... logprob:  0.417859, 0.109375 (1.427 sec)
27.618... logprob:  0.546956, 0.156250 (1.442 sec)
27.619... logprob:  0.506077, 0.140625 (1.453 sec)
27.620... logprob:  0.539684, 0.156250 (1.461 sec)
27.621... logprob:  0.363650, 0.085938 (1.455 sec)
27.622... logprob:  0.364730, 0.085938 (1.449 sec)
27.623... logprob:  0.423145, 0.109375 (1.470 sec)
27.624... logprob:  0.382520, 0.093750 (1.438 sec)
27.625... logprob:  0.440985, 0.117188 (1.427 sec)
27.626... logprob:  0.438357, 0.117188 (1.435 sec)
27.627... logprob:  0.435831, 0.117188 (1.435 sec)
27.628... logprob:  0.465033, 0.125000 (1.444 sec)
27.629... logprob:  0.372115, 0.093750 (1.471 sec)
27.630... logprob:  0.422381, 0.109375 (1.453 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.77409362792969, 10.0]}, 128)
batch 872: ({'logprob': [67.10144805908203, 19.0]}, 128)
batch 873: ({'logprob': [40.07403564453125, 9.0]}, 128)
batch 874: ({'logprob': [45.09211349487305, 11.0]}, 128)
batch 875: ({'logprob': [50.7383918762207, 13.0]}, 128)
batch 876: ({'logprob': [64.46061706542969, 18.0]}, 128)
batch 877: ({'logprob': [45.416934967041016, 11.0]}, 128)
batch 878: ({'logprob': [62.08834457397461, 17.0]}, 128)
batch 879: ({'logprob': [73.71159362792969, 21.0]}, 128)
batch 880: ({'logprob': [50.7640495300293, 13.0]}, 128)
batch 881: ({'logprob': [28.41350746154785, 5.0]}, 128)
batch 882: ({'logprob': [54.386451721191406, 14.0]}, 128)
batch 883: ({'logprob': [62.06178665161133, 17.0]}, 128)
batch 884: ({'logprob': [51.06648254394531, 13.0]}, 128)
batch 885: ({'logprob': [51.70022964477539, 13.0]}, 128)
batch 886: ({'logprob': [62.40134048461914, 17.0]}, 128)

======================Test output======================
logprob:  0.415650, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961475e-03 [2.596742e-09] 
Layer 'conv1' biases: 3.338640e-07 [3.538930e-11] 
Layer 'conv2' weights[0]: 7.948562e-03 [1.824116e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.718335e-10] 
Layer 'conv3' weights[0]: 7.946717e-03 [1.349068e-09] 
Layer 'conv3' biases: 2.832710e-06 [5.243542e-10] 
Layer 'conv4' weights[0]: 7.979428e-03 [1.419044e-09] 
Layer 'conv4' biases: 9.999993e-01 [3.847248e-09] 
Layer 'conv5' weights[0]: 7.978185e-03 [2.492885e-08] 
Layer 'conv5' biases: 9.999918e-01 [2.673353e-08] 
Layer 'fc6' weights[0]: 7.574824e-03 [2.234089e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.092960e-09] 
Layer 'fc7' weights[0]: 6.980524e-03 [1.913974e-07] 
Layer 'fc7' biases: 9.998575e-01 [1.806603e-07] 
Layer 'fc8' weights[0]: 1.302297e-03 [6.356987e-06] 
Layer 'fc8' biases: 6.740295e-02 [4.598171e-05] 
Train error last 870 batches: 0.435199
-------------------------------------------------------
Saved checkpoint to /data2/ad6813/my-nets/saves/ConvNet__2014-06-17_23.05.49
======================================================= (12.753 sec)
27.631... logprob:  0.638602, 0.187500 (1.449 sec)
27.632... logprob:  0.399115, 0.101562 (1.490 sec)
27.633... logprob:  0.376095, 0.093750 (1.445 sec)
27.634... logprob:  0.660155, 0.195312 (2.635 sec)
27.635... logprob:  0.374119, 0.093750 (1.434 sec)
27.636... logprob:  0.480256, 0.132812 (1.436 sec)
27.637... logprob:  0.330780, 0.078125 (3.059 sec)
27.638... logprob:  0.515700, 0.140625 (1.486 sec)
27.639... logprob:  0.418053, 0.109375 (1.441 sec)
27.640... logprob:  0.528755, 0.148438 (1.468 sec)
27.641... logprob:  0.410424, 0.109375 (1.490 sec)
27.642... logprob:  0.500886, 0.140625 (1.441 sec)
27.643... logprob:  0.623185, 0.187500 (1.431 sec)
27.644... logprob:  0.321037, 0.070312 (1.442 sec)
27.645... logprob:  0.414463, 0.109375 (1.429 sec)
27.646... logprob:  0.385611, 0.093750 (1.434 sec)
27.647... logprob:  0.456784, 0.125000 (1.491 sec)
27.648... logprob:  0.491260, 0.140625 (1.433 sec)
27.649... logprob:  0.370273, 0.093750 (1.448 sec)
27.650... logprob:  0.414012, 0.109375 (1.478 sec)
27.651... logprob:  0.397388, 0.101562 (1.431 sec)
27.652... logprob:  0.507142, 0.140625 (1.443 sec)
27.653... logprob:  0.547796, 0.156250 (1.436 sec)
27.654... logprob:  0.496030, 0.140625 (1.428 sec)
27.655... logprob:  0.436183, 0.117188 (1.436 sec)
27.656... logprob:  0.416706, 0.109375 (1.480 sec)
27.657... logprob:  0.449093, 0.117188 (1.439 sec)
27.658... logprob:  0.345859, 0.085938 (1.457 sec)
27.659... logprob:  0.464296, 0.125000 (1.473 sec)
27.660... logprob:  0.446013, 0.125000 (1.444 sec)
27.661... logprob:  0.378435, 0.093750 (1.451 sec)
27.662... logprob:  0.469437, 0.132812 (1.440 sec)
27.663... logprob:  0.310894, 0.070312 (1.428 sec)
27.664... logprob:  0.285381, 0.062500 (1.437 sec)
27.665... logprob:  0.401715, 0.101562 (1.465 sec)
27.666... logprob:  0.442032, 0.117188 (1.454 sec)
27.667... logprob:  0.564226, 0.164062 (1.454 sec)
27.668... logprob:  0.497855, 0.140625 (1.453 sec)
27.669... logprob:  0.432953, 0.109375 (1.463 sec)
27.670... logprob:  0.362382, 0.085938 (1.442 sec)
27.671... logprob:  0.360868, 0.093750 (1.423 sec)
27.672... logprob:  0.441824, 0.117188 (1.435 sec)
27.673... logprob:  0.436228, 0.117188 (1.437 sec)
27.674... logprob:  0.446637, 0.117188 (1.472 sec)
27.675... logprob:  0.356679, 0.093750 (1.470 sec)
27.676... logprob:  0.450179, 0.125000 (1.453 sec)
27.677... logprob:  0.471025, 0.125000 (1.440 sec)
27.678... logprob:  0.465658, 0.125000 (1.483 sec)
27.679... logprob:  0.454863, 0.125000 (1.430 sec)
27.680... logprob:  0.351673, 0.078125 (1.432 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.733116149902344, 10.0]}, 128)
batch 872: ({'logprob': [66.12552642822266, 19.0]}, 128)
batch 873: ({'logprob': [41.256046295166016, 9.0]}, 128)
batch 874: ({'logprob': [45.451881408691406, 11.0]}, 128)
batch 875: ({'logprob': [50.928993225097656, 13.0]}, 128)
batch 876: ({'logprob': [63.73141860961914, 18.0]}, 128)
batch 877: ({'logprob': [46.10294723510742, 11.0]}, 128)
batch 878: ({'logprob': [61.93413162231445, 17.0]}, 128)
batch 879: ({'logprob': [73.53668975830078, 21.0]}, 128)
batch 880: ({'logprob': [50.952911376953125, 13.0]}, 128)
batch 881: ({'logprob': [29.6158390045166, 5.0]}, 128)
batch 882: ({'logprob': [55.300865173339844, 14.0]}, 128)
batch 883: ({'logprob': [61.90855407714844, 17.0]}, 128)
batch 884: ({'logprob': [51.57872009277344, 13.0]}, 128)
batch 885: ({'logprob': [52.8625373840332, 13.0]}, 128)
batch 886: ({'logprob': [62.57082748413086, 17.0]}, 128)

======================Test output======================
logprob:  0.417769, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961438e-03 [4.350117e-09] 
Layer 'conv1' biases: 3.347231e-07 [1.221419e-10] 
Layer 'conv2' weights[0]: 7.948527e-03 [2.623083e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.782077e-10] 
Layer 'conv3' weights[0]: 7.946677e-03 [2.318089e-09] 
Layer 'conv3' biases: 2.841794e-06 [1.305489e-09] 
Layer 'conv4' weights[0]: 7.979385e-03 [2.294381e-09] 
Layer 'conv4' biases: 9.999993e-01 [9.470204e-09] 
Layer 'conv5' weights[0]: 7.978161e-03 [5.179492e-08] 
Layer 'conv5' biases: 9.999923e-01 [5.548778e-08] 
Layer 'fc6' weights[0]: 7.574786e-03 [4.434409e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.416369e-09] 
Layer 'fc7' weights[0]: 6.978751e-03 [5.178587e-08] 
Layer 'fc7' biases: 9.998572e-01 [3.277644e-08] 
Layer 'fc8' weights[0]: 1.281869e-03 [4.011545e-06] 
Layer 'fc8' biases: 6.731194e-02 [2.688875e-05] 
Train error last 870 batches: 0.435198
-------------------------------------------------------
Not saving because 0.417769 > 0.415650 (27.630: -0.00%)
======================================================= (12.073 sec)
27.681... logprob:  0.373876, 0.093750 (1.446 sec)
27.682... logprob:  0.340469, 0.078125 (1.445 sec)
27.683... logprob:  0.411633, 0.109375 (1.430 sec)
27.684... logprob:  0.357681, 0.085938 (1.478 sec)
27.685... logprob:  0.286138, 0.054688 (1.442 sec)
27.686... logprob:  0.318754, 0.070312 (1.433 sec)
27.687... logprob:  0.281741, 0.062500 (1.493 sec)
27.688... logprob:  0.323133, 0.078125 (1.433 sec)
27.689... logprob:  0.471060, 0.125000 (1.431 sec)
27.690... logprob:  0.527519, 0.140625 (1.437 sec)
27.691... logprob:  0.516364, 0.140625 (1.434 sec)
27.692... logprob:  0.384886, 0.101562 (1.433 sec)
27.693... logprob:  0.455607, 0.125000 (1.490 sec)
27.694... logprob:  0.330941, 0.078125 (1.446 sec)
27.695... logprob:  0.356937, 0.085938 (1.440 sec)
27.696... logprob:  0.539178, 0.148438 (1.484 sec)
27.697... logprob:  0.465744, 0.125000 (1.434 sec)
27.698... logprob:  0.548959, 0.156250 (1.440 sec)
27.699... logprob:  0.459622, 0.125000 (1.448 sec)
27.700... logprob:  0.433852, 0.117188 (1.434 sec)
27.701... logprob:  0.423002, 0.109375 (1.432 sec)
27.702... logprob:  0.521551, 0.148438 (1.493 sec)
27.703... logprob:  0.405056, 0.101562 (1.440 sec)
27.704... logprob:  0.405995, 0.101562 (1.454 sec)
27.705... logprob:  0.420130, 0.109375 (1.470 sec)
27.706... logprob:  0.468057, 0.125000 (1.442 sec)
27.707... logprob:  0.485298, 0.132812 (1.460 sec)
27.708... logprob:  0.417200, 0.109375 (1.437 sec)
27.709... logprob:  0.422631, 0.109375 (1.423 sec)
27.710... logprob:  0.602174, 0.179688 (1.432 sec)
27.711... logprob:  0.469474, 0.125000 (1.468 sec)
27.712... logprob:  0.340863, 0.078125 (1.450 sec)
27.713... logprob:  0.586561, 0.179688 (1.457 sec)
27.714... logprob:  0.466252, 0.125000 (1.456 sec)
27.715... logprob:  0.417189, 0.109375 (1.462 sec)
27.716... logprob:  0.335460, 0.078125 (1.434 sec)
27.717... logprob:  0.429784, 0.117188 (1.431 sec)
27.718... logprob:  0.490315, 0.132812 (1.433 sec)
27.719... logprob:  0.406182, 0.109375 (1.436 sec)
27.720... logprob:  0.433227, 0.117188 (1.450 sec)
27.721... logprob:  0.451603, 0.117188 (1.467 sec)
27.722... logprob:  0.537000, 0.156250 (1.452 sec)
27.723... logprob:  0.416553, 0.109375 (1.448 sec)
27.724... logprob:  0.412761, 0.109375 (1.476 sec)
27.725... logprob:  0.494833, 0.140625 (1.430 sec)
27.726... logprob:  0.338447, 0.085938 (1.434 sec)
27.727... logprob:  0.393221, 0.101562 (1.430 sec)
27.728... logprob:  0.421230, 0.109375 (1.443 sec)
27.729... logprob:  0.387602, 0.093750 (1.436 sec)
27.730... logprob:  0.565918, 0.164062 (1.478 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.643333435058594, 10.0]}, 128)
batch 872: ({'logprob': [66.25785064697266, 19.0]}, 128)
batch 873: ({'logprob': [41.02155303955078, 9.0]}, 128)
batch 874: ({'logprob': [45.33266067504883, 11.0]}, 128)
batch 875: ({'logprob': [50.85493087768555, 13.0]}, 128)
batch 876: ({'logprob': [63.823768615722656, 18.0]}, 128)
batch 877: ({'logprob': [45.94849395751953, 11.0]}, 128)
batch 878: ({'logprob': [61.951072692871094, 17.0]}, 128)
batch 879: ({'logprob': [73.60992431640625, 21.0]}, 128)
batch 880: ({'logprob': [50.87887954711914, 13.0]}, 128)
batch 881: ({'logprob': [29.3248291015625, 5.0]}, 128)
batch 882: ({'logprob': [55.16263198852539, 14.0]}, 128)
batch 883: ({'logprob': [61.92550277709961, 17.0]}, 128)
batch 884: ({'logprob': [51.470211029052734, 13.0]}, 128)
batch 885: ({'logprob': [52.684303283691406, 13.0]}, 128)
batch 886: ({'logprob': [62.55307388305664, 17.0]}, 128)

======================Test output======================
logprob:  0.417209, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961411e-03 [3.602164e-09] 
Layer 'conv1' biases: 3.356422e-07 [9.808931e-11] 
Layer 'conv2' weights[0]: 7.948487e-03 [2.747682e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.763732e-10] 
Layer 'conv3' weights[0]: 7.946640e-03 [2.444053e-09] 
Layer 'conv3' biases: 2.849166e-06 [1.475634e-09] 
Layer 'conv4' weights[0]: 7.979348e-03 [2.418601e-09] 
Layer 'conv4' biases: 9.999993e-01 [1.169096e-08] 
Layer 'conv5' weights[0]: 7.978109e-03 [7.597290e-08] 
Layer 'conv5' biases: 9.999921e-01 [8.170405e-08] 
Layer 'fc6' weights[0]: 7.574748e-03 [6.276587e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.388377e-09] 
Layer 'fc7' weights[0]: 6.976954e-03 [5.216940e-08] 
Layer 'fc7' biases: 9.998574e-01 [3.304125e-08] 
Layer 'fc8' weights[0]: 1.286500e-03 [3.560953e-06] 
Layer 'fc8' biases: 6.756643e-02 [2.311199e-05] 
Train error last 870 batches: 0.435198
-------------------------------------------------------
Not saving because 0.417209 > 0.415650 (27.630: -0.00%)
======================================================= (12.053 sec)
27.731... logprob:  0.450400, 0.125000 (1.449 sec)
27.732... logprob:  0.311403, 0.070312 (1.447 sec)
27.733... logprob:  0.556518, 0.156250 (1.489 sec)
27.734... logprob:  0.340252, 0.078125 (1.439 sec)
27.735... logprob:  0.527448, 0.148438 (1.430 sec)
27.736... logprob:  0.642629, 0.187500 (1.437 sec)
27.737... logprob:  0.516108, 0.148438 (1.435 sec)
27.738... logprob:  0.459391, 0.125000 (1.436 sec)
27.739... logprob:  0.477792, 0.132812 (1.487 sec)
27.740... logprob:  0.339647, 0.078125 (1.469 sec)
27.741... logprob:  0.393469, 0.101562 (1.440 sec)
27.742... logprob:  0.419694, 0.109375 (1.485 sec)
27.743... logprob:  0.364887, 0.085938 (1.426 sec)
27.744... logprob:  0.519156, 0.148438 (1.435 sec)
27.745... logprob:  0.478138, 0.132812 (1.440 sec)
27.746... logprob:  0.440546, 0.117188 (1.428 sec)
27.747... logprob:  0.425604, 0.109375 (1.438 sec)
27.748... logprob:  0.378130, 0.093750 (1.484 sec)
27.749... logprob:  0.420810, 0.109375 (1.437 sec)
27.750... logprob:  0.512791, 0.140625 (1.449 sec)
27.751... logprob:  0.263682, 0.054688 (1.488 sec)
27.752... logprob:  0.522507, 0.140625 (1.431 sec)
27.753... logprob:  0.441167, 0.117188 (1.443 sec)
27.754... logprob:  0.468332, 0.132812 (1.428 sec)
27.755... logprob:  0.507055, 0.140625 (1.432 sec)
27.756... logprob:  0.440833, 0.117188 (1.435 sec)
27.757... logprob:  0.552443, 0.156250 (1.478 sec)
27.758... logprob:  0.393581, 0.101562 (1.448 sec)
27.759... logprob:  0.459698, 0.125000 (1.452 sec)
27.760... logprob:  0.485536, 0.132812 (1.464 sec)
27.761... logprob:  0.418188, 0.109375 (1.449 sec)
27.762... logprob:  0.516054, 0.148438 (1.444 sec)
27.763... logprob:  0.558965, 0.164062 (1.426 sec)
27.764... logprob:  0.503269, 0.140625 (1.431 sec)
27.765... logprob:  0.311783, 0.062500 (1.438 sec)
27.766... logprob:  0.482219, 0.132812 (1.458 sec)
27.767... logprob:  0.371090, 0.085938 (1.456 sec)
27.768... logprob:  0.432658, 0.117188 (1.465 sec)
27.769... logprob:  0.490809, 0.140625 (1.471 sec)
27.770... logprob:  0.402966, 0.101562 (1.482 sec)
27.771... logprob:  0.549419, 0.156250 (1.460 sec)
27.772... logprob:  0.414095, 0.109375 (1.446 sec)
27.773... logprob:  0.557719, 0.164062 (1.446 sec)
27.774... logprob:  0.361763, 0.085938 (1.461 sec)
27.775... logprob:  0.407387, 0.101562 (1.463 sec)
27.776... logprob:  0.433161, 0.117188 (1.478 sec)
27.777... logprob:  0.379973, 0.093750 (1.472 sec)
27.778... logprob:  0.433552, 0.117188 (1.473 sec)
27.779... logprob:  0.505342, 0.140625 (1.493 sec)
27.780... logprob:  0.385762, 0.101562 (1.453 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.48690414428711, 10.0]}, 128)
batch 872: ({'logprob': [66.87862396240234, 19.0]}, 128)
batch 873: ({'logprob': [40.25558853149414, 9.0]}, 128)
batch 874: ({'logprob': [45.02688217163086, 11.0]}, 128)
batch 875: ({'logprob': [50.70333480834961, 13.0]}, 128)
batch 876: ({'logprob': [64.2917709350586, 18.0]}, 128)
batch 877: ({'logprob': [45.489898681640625, 11.0]}, 128)
batch 878: ({'logprob': [62.11211395263672, 17.0]}, 128)
batch 879: ({'logprob': [73.93180084228516, 21.0]}, 128)
batch 880: ({'logprob': [50.728450775146484, 13.0]}, 128)
batch 881: ({'logprob': [28.39790153503418, 5.0]}, 128)
batch 882: ({'logprob': [54.710975646972656, 14.0]}, 128)
batch 883: ({'logprob': [62.08587646484375, 17.0]}, 128)
batch 884: ({'logprob': [51.169071197509766, 13.0]}, 128)
batch 885: ({'logprob': [52.079132080078125, 13.0]}, 128)
batch 886: ({'logprob': [62.563167572021484, 17.0]}, 128)

======================Test output======================
logprob:  0.415972, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961363e-03 [3.024512e-09] 
Layer 'conv1' biases: 3.365720e-07 [6.121855e-11] 
Layer 'conv2' weights[0]: 7.948449e-03 [2.298654e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.909273e-10] 
Layer 'conv3' weights[0]: 7.946601e-03 [1.737325e-09] 
Layer 'conv3' biases: 2.857000e-06 [7.891249e-10] 
Layer 'conv4' weights[0]: 7.979310e-03 [1.637127e-09] 
Layer 'conv4' biases: 9.999993e-01 [4.261526e-09] 
Layer 'conv5' weights[0]: 7.978070e-03 [1.922108e-08] 
Layer 'conv5' biases: 9.999921e-01 [1.970764e-08] 
Layer 'fc6' weights[0]: 7.574712e-03 [1.738368e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.565611e-09] 
Layer 'fc7' weights[0]: 6.975159e-03 [5.487037e-08] 
Layer 'fc7' biases: 9.998575e-01 [3.602254e-08] 
Layer 'fc8' weights[0]: 1.302595e-03 [3.493861e-06] 
Layer 'fc8' biases: 6.781978e-02 [2.403855e-05] 
Train error last 870 batches: 0.435198
-------------------------------------------------------
Not saving because 0.415972 > 0.415650 (27.630: -0.00%)
======================================================= (12.103 sec)
27.781... logprob:  0.369641, 0.085938 (1.456 sec)
27.782... logprob:  0.351418, 0.085938 (1.461 sec)
27.783... logprob:  0.555526, 0.156250 (1.464 sec)
27.784... logprob:  0.440958, 0.117188 (1.460 sec)
27.785... logprob:  0.543703, 0.156250 (1.485 sec)
27.786... logprob:  0.477541, 0.132812 (1.475 sec)
27.787... logprob:  0.546473, 0.156250 (1.457 sec)
27.788... logprob:  0.563238, 0.164062 (1.499 sec)
27.789... logprob:  0.280743, 0.054688 (1.455 sec)
27.790... logprob:  0.407962, 0.101562 (1.449 sec)
27.791... logprob:  0.397888, 0.101562 (1.449 sec)
27.792... logprob:  0.360951, 0.085938 (1.465 sec)
27.793... logprob:  0.370092, 0.085938 (1.453 sec)
27.794... logprob:  0.387126, 0.093750 (1.485 sec)
27.795... logprob:  0.469733, 0.125000 (1.475 sec)
27.796... logprob:  0.423510, 0.109375 (1.539 sec)
27.797... logprob:  0.358870, 0.085938 (1.503 sec)
27.798... logprob:  0.393293, 0.101562 (1.455 sec)
27.799... logprob:  0.332439, 0.078125 (1.449 sec)
27.800... logprob:  0.371703, 0.093750 (1.451 sec)
27.801... logprob:  0.449992, 0.117188 (1.460 sec)
27.802... logprob:  0.422906, 0.109375 (1.451 sec)
27.803... logprob:  0.491511, 0.132812 (1.492 sec)
27.804... logprob:  0.349952, 0.085938 (1.463 sec)
27.805... logprob:  0.452275, 0.117188 (1.458 sec)
27.806... logprob:  0.424177, 0.109375 (1.501 sec)
27.807... logprob:  0.443476, 0.117188 (1.453 sec)
27.808... logprob:  0.462364, 0.125000 (1.457 sec)
27.809... logprob:  0.589761, 0.171875 (1.448 sec)
27.810... logprob:  0.442485, 0.117188 (1.460 sec)
27.811... logprob:  0.460420, 0.125000 (1.452 sec)
27.812... logprob:  0.462343, 0.125000 (1.495 sec)
27.813... logprob:  0.485954, 0.132812 (1.490 sec)
27.814... logprob:  0.477949, 0.132812 (1.458 sec)
27.815... logprob:  0.371595, 0.085938 (1.497 sec)
27.816... logprob:  0.408561, 0.101562 (1.456 sec)
27.817... logprob:  0.425868, 0.109375 (1.449 sec)
27.818... logprob:  0.560005, 0.164062 (1.450 sec)
27.819... logprob:  0.498187, 0.140625 (1.458 sec)
27.820... logprob:  0.421660, 0.109375 (1.451 sec)
27.821... logprob:  0.406657, 0.101562 (1.505 sec)
27.822... logprob:  0.441243, 0.117188 (1.461 sec)
27.823... logprob:  0.341019, 0.078125 (1.458 sec)
27.824... logprob:  0.489706, 0.132812 (1.504 sec)
27.825... logprob:  0.288251, 0.062500 (1.450 sec)
27.826... logprob:  0.375548, 0.093750 (1.462 sec)
27.827... logprob:  0.420480, 0.109375 (1.450 sec)
27.828... logprob:  0.443235, 0.117188 (1.454 sec)
27.829... logprob:  0.503942, 0.140625 (1.452 sec)
27.830... logprob:  0.442098, 0.117188 (1.506 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.25715255737305, 10.0]}, 128)
batch 872: ({'logprob': [68.2891616821289, 19.0]}, 128)
batch 873: ({'logprob': [39.42481994628906, 9.0]}, 128)
batch 874: ({'logprob': [44.790985107421875, 11.0]}, 128)
batch 875: ({'logprob': [50.81629180908203, 13.0]}, 128)
batch 876: ({'logprob': [65.46733093261719, 18.0]}, 128)
batch 877: ({'logprob': [45.13056564331055, 11.0]}, 128)
batch 878: ({'logprob': [62.927833557128906, 17.0]}, 128)
batch 879: ({'logprob': [75.32854461669922, 21.0]}, 128)
batch 880: ({'logprob': [50.84251022338867, 13.0]}, 128)
batch 881: ({'logprob': [26.98514747619629, 5.0]}, 128)
batch 882: ({'logprob': [54.69737243652344, 14.0]}, 128)
batch 883: ({'logprob': [62.90107345581055, 17.0]}, 128)
batch 884: ({'logprob': [51.163551330566406, 13.0]}, 128)
batch 885: ({'logprob': [51.82999801635742, 13.0]}, 128)
batch 886: ({'logprob': [63.25863265991211, 17.0]}, 128)

======================Test output======================
logprob:  0.417535, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961319e-03 [4.770293e-09] 
Layer 'conv1' biases: 3.377078e-07 [1.521942e-10] 
Layer 'conv2' weights[0]: 7.948408e-03 [4.169265e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.340460e-10] 
Layer 'conv3' weights[0]: 7.946566e-03 [3.909279e-09] 
Layer 'conv3' biases: 2.865029e-06 [2.509162e-09] 
Layer 'conv4' weights[0]: 7.979277e-03 [3.817388e-09] 
Layer 'conv4' biases: 9.999993e-01 [2.027830e-08] 
Layer 'conv5' weights[0]: 7.978035e-03 [1.254905e-07] 
Layer 'conv5' biases: 9.999918e-01 [1.351881e-07] 
Layer 'fc6' weights[0]: 7.574670e-03 [1.040132e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.063041e-08] 
Layer 'fc7' weights[0]: 6.973340e-03 [4.789353e-08] 
Layer 'fc7' biases: 9.998585e-01 [2.730650e-08] 
Layer 'fc8' weights[0]: 1.331640e-03 [5.385041e-06] 
Layer 'fc8' biases: 6.827743e-02 [3.057892e-05] 
Train error last 870 batches: 0.435197
-------------------------------------------------------
Not saving because 0.417535 > 0.415650 (27.630: -0.00%)
======================================================= (12.072 sec)
27.831... logprob:  0.513885, 0.140625 (1.458 sec)
27.832... logprob:  0.330842, 0.078125 (1.464 sec)
27.833... logprob:  0.489041, 0.132812 (1.501 sec)
27.834... logprob:  0.433354, 0.117188 (1.456 sec)
27.835... logprob:  0.542849, 0.148438 (1.452 sec)
27.836... logprob:  0.376120, 0.093750 (1.448 sec)
27.837... logprob:  0.314127, 0.070312 (1.451 sec)
27.838... logprob:  0.437069, 0.117188 (1.466 sec)
27.839... logprob:  0.471656, 0.125000 (1.498 sec)
27.840... logprob:  0.555513, 0.156250 (1.452 sec)
27.841... logprob:  0.396036, 0.101562 (1.468 sec)
27.842... logprob:  0.497878, 0.140625 (1.498 sec)
27.843... logprob:  0.465502, 0.125000 (1.456 sec)
27.844... logprob:  0.497663, 0.140625 (1.459 sec)
27.845... logprob:  0.486748, 0.132812 (1.452 sec)
27.846... logprob:  0.468407, 0.125000 (1.461 sec)
27.847... logprob:  0.363387, 0.085938 (1.454 sec)
27.848... logprob:  0.397211, 0.101562 (1.498 sec)
27.849... logprob:  0.360562, 0.085938 (1.457 sec)
27.850... logprob:  0.479379, 0.132812 (1.473 sec)
27.851... logprob:  0.440140, 0.117188 (1.492 sec)
27.852... logprob:  0.545409, 0.156250 (1.451 sec)
27.853... logprob:  0.371983, 0.093750 (1.467 sec)
27.854... logprob:  0.307355, 0.070312 (1.445 sec)
27.855... logprob:  0.484732, 0.132812 (1.449 sec)
27.856... logprob:  0.443721, 0.117188 (1.456 sec)
27.857... logprob:  0.372230, 0.093750 (1.493 sec)
27.858... logprob:  0.396245, 0.101562 (1.466 sec)
27.859... logprob:  0.307988, 0.070312 (1.469 sec)
27.860... logprob:  0.565977, 0.156250 (1.487 sec)
27.861... logprob:  0.417800, 0.109375 (1.463 sec)
27.862... logprob:  0.328842, 0.078125 (1.458 sec)
27.863... logprob:  0.399571, 0.101562 (1.450 sec)
27.864... logprob:  0.451487, 0.117188 (1.444 sec)
27.865... logprob:  0.484597, 0.132812 (1.463 sec)
27.866... logprob:  0.507771, 0.140625 (1.486 sec)
27.867... logprob:  0.503133, 0.140625 (1.472 sec)
27.868... logprob:  0.405229, 0.101562 (1.479 sec)
27.869... logprob:  0.383096, 0.093750 (1.479 sec)
27.870... logprob:  0.552215, 0.156250 (1.394 sec)
28.1... logprob:  0.379933, 0.093750 (1.407 sec)
28.2... logprob:  0.448248, 0.117188 (1.445 sec)
28.3... logprob:  0.398270, 0.101562 (1.418 sec)
28.4... logprob:  0.443298, 0.117188 (1.407 sec)
28.5... logprob:  0.443478, 0.117188 (1.436 sec)
28.6... logprob:  0.499065, 0.140625 (1.398 sec)
28.7... logprob:  0.363282, 0.085938 (1.424 sec)
28.8... logprob:  0.419163, 0.109375 (1.398 sec)
28.9... logprob:  0.358908, 0.085938 (1.405 sec)
28.10... logprob:  0.377590, 0.093750 (1.410 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.178096771240234, 10.0]}, 128)
batch 872: ({'logprob': [67.05201721191406, 19.0]}, 128)
batch 873: ({'logprob': [40.21611785888672, 9.0]}, 128)
batch 874: ({'logprob': [45.30470275878906, 11.0]}, 128)
batch 875: ({'logprob': [50.84025573730469, 13.0]}, 128)
batch 876: ({'logprob': [64.42120361328125, 18.0]}, 128)
batch 877: ({'logprob': [45.539207458496094, 11.0]}, 128)
batch 878: ({'logprob': [61.968772888183594, 17.0]}, 128)
batch 879: ({'logprob': [73.28056335449219, 21.0]}, 128)
batch 880: ({'logprob': [50.866085052490234, 13.0]}, 128)
batch 881: ({'logprob': [28.867841720581055, 5.0]}, 128)
batch 882: ({'logprob': [54.20639419555664, 14.0]}, 128)
batch 883: ({'logprob': [61.9421501159668, 17.0]}, 128)
batch 884: ({'logprob': [51.07722854614258, 13.0]}, 128)
batch 885: ({'logprob': [51.53008270263672, 13.0]}, 128)
batch 886: ({'logprob': [62.19096374511719, 17.0]}, 128)

======================Test output======================
logprob:  0.415763, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961285e-03 [3.382268e-09] 
Layer 'conv1' biases: 3.388408e-07 [1.299119e-10] 
Layer 'conv2' weights[0]: 7.948368e-03 [3.072884e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.440840e-10] 
Layer 'conv3' weights[0]: 7.946530e-03 [3.098216e-09] 
Layer 'conv3' biases: 2.873422e-06 [1.961423e-09] 
Layer 'conv4' weights[0]: 7.979239e-03 [3.212440e-09] 
Layer 'conv4' biases: 9.999993e-01 [1.770749e-08] 
Layer 'conv5' weights[0]: 7.978003e-03 [1.143625e-07] 
Layer 'conv5' biases: 9.999918e-01 [1.230779e-07] 
Layer 'fc6' weights[0]: 7.574631e-03 [9.484559e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.584318e-09] 
Layer 'fc7' weights[0]: 6.971575e-03 [2.847552e-07] 
Layer 'fc7' biases: 9.998571e-01 [2.750656e-07] 
Layer 'fc8' weights[0]: 1.286742e-03 [1.036440e-05] 
Layer 'fc8' biases: 6.815637e-02 [7.300592e-05] 
Train error last 870 batches: 0.435197
-------------------------------------------------------
Not saving because 0.415763 > 0.415650 (27.630: -0.00%)
======================================================= (12.054 sec)
28.11... logprob:  0.334900, 0.078125 (1.448 sec)
28.12... logprob:  0.466284, 0.125000 (1.405 sec)
28.13... logprob:  0.442169, 0.117188 (1.422 sec)
28.14... logprob:  0.444539, 0.117188 (1.408 sec)
28.15... logprob:  0.395508, 0.101562 (1.408 sec)
28.16... logprob:  0.421360, 0.109375 (1.403 sec)
28.17... logprob:  0.515947, 0.140625 (1.399 sec)
28.18... logprob:  0.262115, 0.054688 (1.397 sec)
28.19... logprob:  0.279486, 0.062500 (1.407 sec)
28.20... logprob:  0.421365, 0.109375 (1.406 sec)
28.21... logprob:  0.443990, 0.117188 (1.399 sec)
28.22... logprob:  0.536780, 0.148438 (1.416 sec)
28.23... logprob:  0.533145, 0.148438 (1.414 sec)
28.24... logprob:  0.310483, 0.070312 (1.421 sec)
28.25... logprob:  0.356126, 0.085938 (1.401 sec)
28.26... logprob:  0.463804, 0.125000 (1.450 sec)
28.27... logprob:  0.404505, 0.101562 (1.387 sec)
28.28... logprob:  0.421847, 0.109375 (1.417 sec)
28.29... logprob:  0.395921, 0.101562 (1.424 sec)
28.30... logprob:  0.374055, 0.093750 (1.415 sec)
28.31... logprob:  0.479970, 0.132812 (1.402 sec)
28.32... logprob:  0.457222, 0.125000 (1.394 sec)
28.33... logprob:  0.460678, 0.125000 (1.448 sec)
28.34... logprob:  0.464528, 0.125000 (1.392 sec)
28.35... logprob:  0.316321, 0.070312 (1.406 sec)
28.36... logprob:  0.475792, 0.132812 (1.402 sec)
28.37... logprob:  0.417592, 0.109375 (1.411 sec)
28.38... logprob:  0.392681, 0.101562 (1.395 sec)
28.39... logprob:  0.631450, 0.187500 (1.441 sec)
28.40... logprob:  0.445685, 0.117188 (1.409 sec)
28.41... logprob:  0.352975, 0.085938 (1.430 sec)
28.42... logprob:  0.392003, 0.101562 (1.415 sec)
28.43... logprob:  0.440078, 0.117188 (1.413 sec)
28.44... logprob:  0.518559, 0.148438 (1.434 sec)
28.45... logprob:  0.381725, 0.093750 (1.394 sec)
28.46... logprob:  0.486189, 0.132812 (1.400 sec)
28.47... logprob:  0.331720, 0.078125 (1.394 sec)
28.48... logprob:  0.498935, 0.140625 (1.427 sec)
28.49... logprob:  0.510872, 0.148438 (1.413 sec)
28.50... logprob:  0.393186, 0.101562 (1.428 sec)
28.51... logprob:  0.490253, 0.140625 (1.429 sec)
28.52... logprob:  0.525790, 0.148438 (1.404 sec)
28.53... logprob:  0.294804, 0.062500 (1.449 sec)
28.54... logprob:  0.403394, 0.109375 (1.392 sec)
28.55... logprob:  0.331696, 0.078125 (1.397 sec)
28.56... logprob:  0.421618, 0.109375 (1.405 sec)
28.57... logprob:  0.572355, 0.164062 (1.429 sec)
28.58... logprob:  0.407555, 0.101562 (1.407 sec)
28.59... logprob:  0.333868, 0.078125 (1.464 sec)
28.60... logprob:  0.618741, 0.179688 (1.433 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.3646125793457, 10.0]}, 128)
batch 872: ({'logprob': [66.42985534667969, 19.0]}, 128)
batch 873: ({'logprob': [40.862281799316406, 9.0]}, 128)
batch 874: ({'logprob': [45.18080520629883, 11.0]}, 128)
batch 875: ({'logprob': [50.80833435058594, 13.0]}, 128)
batch 876: ({'logprob': [63.96791076660156, 18.0]}, 128)
batch 877: ({'logprob': [45.84538269042969, 11.0]}, 128)
batch 878: ({'logprob': [62.11583709716797, 17.0]}, 128)
batch 879: ({'logprob': [74.03473663330078, 21.0]}, 128)
batch 880: ({'logprob': [50.83248519897461, 13.0]}, 128)
batch 881: ({'logprob': [28.904850006103516, 5.0]}, 128)
batch 882: ({'logprob': [55.292118072509766, 14.0]}, 128)
batch 883: ({'logprob': [62.090110778808594, 17.0]}, 128)
batch 884: ({'logprob': [51.47349548339844, 13.0]}, 128)
batch 885: ({'logprob': [52.78582000732422, 13.0]}, 128)
batch 886: ({'logprob': [62.76744079589844, 17.0]}, 128)

======================Test output======================
logprob:  0.417361, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961254e-03 [4.291715e-09] 
Layer 'conv1' biases: 3.398494e-07 [1.450100e-10] 
Layer 'conv2' weights[0]: 7.948327e-03 [3.396165e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.445922e-10] 
Layer 'conv3' weights[0]: 7.946495e-03 [3.520876e-09] 
Layer 'conv3' biases: 2.882814e-06 [2.313175e-09] 
Layer 'conv4' weights[0]: 7.979203e-03 [3.518082e-09] 
Layer 'conv4' biases: 9.999993e-01 [2.016296e-08] 
Layer 'conv5' weights[0]: 7.977959e-03 [1.311907e-07] 
Layer 'conv5' biases: 9.999921e-01 [1.410632e-07] 
Layer 'fc6' weights[0]: 7.574588e-03 [1.079391e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.103799e-08] 
Layer 'fc7' weights[0]: 6.969796e-03 [9.882278e-08] 
Layer 'fc7' biases: 9.998575e-01 [8.562865e-08] 
Layer 'fc8' weights[0]: 1.290109e-03 [2.813110e-06] 
Layer 'fc8' biases: 6.821794e-02 [1.741776e-05] 
Train error last 870 batches: 0.435197
-------------------------------------------------------
Not saving because 0.417361 > 0.415650 (27.630: -0.00%)
======================================================= (12.078 sec)
28.61... logprob:  0.382804, 0.093750 (1.434 sec)
28.62... logprob:  0.474843, 0.132812 (1.471 sec)
28.63... logprob:  0.397290, 0.101562 (1.434 sec)
28.64... logprob:  0.450323, 0.125000 (1.416 sec)
28.65... logprob:  0.373378, 0.093750 (1.397 sec)
28.66... logprob:  0.354039, 0.085938 (1.450 sec)
28.67... logprob:  0.295420, 0.062500 (1.389 sec)
28.68... logprob:  0.396800, 0.101562 (1.399 sec)
28.69... logprob:  0.496675, 0.140625 (1.430 sec)
28.70... logprob:  0.325902, 0.078125 (1.424 sec)
28.71... logprob:  0.381802, 0.101562 (1.462 sec)
28.72... logprob:  0.493703, 0.132812 (1.406 sec)
28.73... logprob:  0.447688, 0.117188 (1.428 sec)
28.74... logprob:  0.442517, 0.117188 (1.423 sec)
28.75... logprob:  0.380655, 0.093750 (1.421 sec)
28.76... logprob:  0.412048, 0.109375 (1.434 sec)
28.77... logprob:  0.396343, 0.101562 (1.428 sec)
28.78... logprob:  0.493054, 0.140625 (1.459 sec)
28.79... logprob:  0.456473, 0.125000 (1.404 sec)
28.80... logprob:  0.508029, 0.132812 (1.417 sec)
28.81... logprob:  0.416724, 0.109375 (1.424 sec)
28.82... logprob:  0.231265, 0.039062 (1.423 sec)
28.83... logprob:  0.493818, 0.140625 (1.400 sec)
28.84... logprob:  0.468146, 0.125000 (1.506 sec)
28.85... logprob:  0.431930, 0.117188 (1.421 sec)
28.86... logprob:  0.416929, 0.109375 (1.425 sec)
28.87... logprob:  0.633297, 0.187500 (1.425 sec)
28.88... logprob:  0.535024, 0.156250 (1.407 sec)
28.89... logprob:  0.410549, 0.109375 (1.440 sec)
28.90... logprob:  0.577483, 0.171875 (1.394 sec)
28.91... logprob:  0.348429, 0.078125 (1.400 sec)
28.92... logprob:  0.464460, 0.125000 (1.406 sec)
28.93... logprob:  0.492211, 0.140625 (1.399 sec)
28.94... logprob:  0.428785, 0.109375 (1.396 sec)
28.95... logprob:  0.471834, 0.125000 (1.404 sec)
28.96... logprob:  0.576187, 0.171875 (1.404 sec)
28.97... logprob:  0.430787, 0.117188 (1.403 sec)
28.98... logprob:  0.391201, 0.093750 (1.441 sec)
28.99... logprob:  0.474222, 0.132812 (1.410 sec)
28.100... logprob:  0.310611, 0.070312 (1.404 sec)
28.101... logprob:  0.310904, 0.062500 (1.445 sec)
28.102... logprob:  0.545928, 0.156250 (1.389 sec)
28.103... logprob:  0.540930, 0.156250 (1.404 sec)
28.104... logprob:  0.388813, 0.101562 (1.402 sec)
28.105... logprob:  0.619295, 0.179688 (1.396 sec)
28.106... logprob:  0.344465, 0.085938 (1.398 sec)
28.107... logprob:  0.335790, 0.078125 (1.446 sec)
28.108... logprob:  0.586856, 0.171875 (1.399 sec)
28.109... logprob:  0.336128, 0.078125 (1.400 sec)
28.110... logprob:  0.564655, 0.164062 (1.399 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.70370864868164, 10.0]}, 128)
batch 872: ({'logprob': [66.47960662841797, 19.0]}, 128)
batch 873: ({'logprob': [40.67417526245117, 9.0]}, 128)
batch 874: ({'logprob': [45.23525619506836, 11.0]}, 128)
batch 875: ({'logprob': [50.77998733520508, 13.0]}, 128)
batch 876: ({'logprob': [63.97805404663086, 18.0]}, 128)
batch 877: ({'logprob': [45.7376823425293, 11.0]}, 128)
batch 878: ({'logprob': [61.923439025878906, 17.0]}, 128)
batch 879: ({'logprob': [73.51657104492188, 21.0]}, 128)
batch 880: ({'logprob': [50.804710388183594, 13.0]}, 128)
batch 881: ({'logprob': [29.043428421020508, 5.0]}, 128)
batch 882: ({'logprob': [54.8173942565918, 14.0]}, 128)
batch 883: ({'logprob': [61.897361755371094, 17.0]}, 128)
batch 884: ({'logprob': [51.283172607421875, 13.0]}, 128)
batch 885: ({'logprob': [52.27080535888672, 13.0]}, 128)
batch 886: ({'logprob': [62.41265106201172, 17.0]}, 128)

======================Test output======================
logprob:  0.416288, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961220e-03 [3.929236e-09] 
Layer 'conv1' biases: 3.407641e-07 [1.229206e-10] 
Layer 'conv2' weights[0]: 7.948283e-03 [3.828533e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.876014e-10] 
Layer 'conv3' weights[0]: 7.946462e-03 [3.490147e-09] 
Layer 'conv3' biases: 2.891215e-06 [2.075096e-09] 
Layer 'conv4' weights[0]: 7.979159e-03 [3.546962e-09] 
Layer 'conv4' biases: 9.999993e-01 [1.768109e-08] 
Layer 'conv5' weights[0]: 7.977923e-03 [1.127043e-07] 
Layer 'conv5' biases: 9.999921e-01 [1.210094e-07] 
Layer 'fc6' weights[0]: 7.574554e-03 [9.387623e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.484374e-09] 
Layer 'fc7' weights[0]: 6.968029e-03 [1.689906e-07] 
Layer 'fc7' biases: 9.998573e-01 [1.590817e-07] 
Layer 'fc8' weights[0]: 1.285851e-03 [6.412391e-06] 
Layer 'fc8' biases: 6.829700e-02 [4.012314e-05] 
Train error last 870 batches: 0.435197
-------------------------------------------------------
Not saving because 0.416288 > 0.415650 (27.630: -0.00%)
======================================================= (12.065 sec)
28.111... logprob:  0.404667, 0.101562 (1.402 sec)
28.112... logprob:  0.365998, 0.093750 (1.412 sec)
28.113... logprob:  0.354431, 0.085938 (1.405 sec)
28.114... logprob:  0.440212, 0.117188 (1.434 sec)
28.115... logprob:  0.506781, 0.140625 (1.410 sec)
28.116... logprob:  0.393346, 0.101562 (1.401 sec)
28.117... logprob:  0.440393, 0.117188 (1.445 sec)
28.118... logprob:  0.409092, 0.101562 (1.416 sec)
28.119... logprob:  0.346082, 0.085938 (1.400 sec)
28.120... logprob:  0.547129, 0.156250 (1.402 sec)
28.121... logprob:  0.412600, 0.109375 (1.393 sec)
28.122... logprob:  0.519262, 0.148438 (1.442 sec)
28.123... logprob:  0.463674, 0.125000 (1.393 sec)
28.124... logprob:  0.447690, 0.125000 (1.408 sec)
28.125... logprob:  0.501917, 0.140625 (1.407 sec)
28.126... logprob:  0.475737, 0.125000 (1.394 sec)
28.127... logprob:  0.479506, 0.125000 (1.397 sec)
28.128... logprob:  0.422334, 0.109375 (1.419 sec)
28.129... logprob:  0.574886, 0.164062 (1.424 sec)
28.130... logprob:  0.382703, 0.093750 (1.415 sec)
28.131... logprob:  0.495497, 0.132812 (1.408 sec)
28.132... logprob:  0.506361, 0.140625 (1.437 sec)
28.133... logprob:  0.444689, 0.117188 (1.392 sec)
28.134... logprob:  0.401872, 0.101562 (1.397 sec)
28.135... logprob:  0.460189, 0.125000 (1.406 sec)
28.136... logprob:  0.562384, 0.164062 (1.405 sec)
28.137... logprob:  0.462587, 0.125000 (1.401 sec)
28.138... logprob:  0.319400, 0.070312 (1.444 sec)
28.139... logprob:  0.395741, 0.101562 (1.403 sec)
28.140... logprob:  0.560090, 0.164062 (1.416 sec)
28.141... logprob:  0.464578, 0.125000 (1.440 sec)
28.142... logprob:  0.464637, 0.125000 (1.405 sec)
28.143... logprob:  0.294413, 0.062500 (1.428 sec)
28.144... logprob:  0.457060, 0.125000 (1.416 sec)
28.145... logprob:  0.324734, 0.078125 (1.421 sec)
28.146... logprob:  0.483091, 0.132812 (1.417 sec)
28.147... logprob:  0.262485, 0.054688 (1.434 sec)
28.148... logprob:  0.458625, 0.125000 (1.394 sec)
28.149... logprob:  0.442503, 0.117188 (1.394 sec)
28.150... logprob:  0.347578, 0.085938 (1.406 sec)
28.151... logprob:  0.347140, 0.085938 (1.399 sec)
28.152... logprob:  0.785120, 0.234375 (1.391 sec)
28.153... logprob:  0.381642, 0.093750 (1.443 sec)
28.154... logprob:  0.524669, 0.148438 (1.403 sec)
28.155... logprob:  0.426100, 0.117188 (1.411 sec)
28.156... logprob:  0.295269, 0.062500 (1.438 sec)
28.157... logprob:  0.270171, 0.054688 (1.393 sec)
28.158... logprob:  0.455434, 0.125000 (1.403 sec)
28.159... logprob:  0.483123, 0.132812 (1.402 sec)
28.160... logprob:  0.444722, 0.117188 (1.421 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.906028747558594, 10.0]}, 128)
batch 872: ({'logprob': [66.1315689086914, 19.0]}, 128)
batch 873: ({'logprob': [41.1987419128418, 9.0]}, 128)
batch 874: ({'logprob': [45.494022369384766, 11.0]}, 128)
batch 875: ({'logprob': [50.925804138183594, 13.0]}, 128)
batch 876: ({'logprob': [63.72438430786133, 18.0]}, 128)
batch 877: ({'logprob': [46.07300567626953, 11.0]}, 128)
batch 878: ({'logprob': [61.84115219116211, 17.0]}, 128)
batch 879: ({'logprob': [73.2817153930664, 21.0]}, 128)
batch 880: ({'logprob': [50.9500617980957, 13.0]}, 128)
batch 881: ({'logprob': [29.720701217651367, 5.0]}, 128)
batch 882: ({'logprob': [55.09484100341797, 14.0]}, 128)
batch 883: ({'logprob': [61.815269470214844, 17.0]}, 128)
batch 884: ({'logprob': [51.503360748291016, 13.0]}, 128)
batch 885: ({'logprob': [52.642704010009766, 13.0]}, 128)
batch 886: ({'logprob': [62.405601501464844, 17.0]}, 128)

======================Test output======================
logprob:  0.417338, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961177e-03 [2.343265e-09] 
Layer 'conv1' biases: 3.417094e-07 [4.333133e-11] 
Layer 'conv2' weights[0]: 7.948240e-03 [1.636253e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.374564e-10] 
Layer 'conv3' weights[0]: 7.946424e-03 [1.222951e-09] 
Layer 'conv3' biases: 2.899797e-06 [3.804982e-10] 
Layer 'conv4' weights[0]: 7.979121e-03 [1.153456e-09] 
Layer 'conv4' biases: 9.999993e-01 [1.524187e-09] 
Layer 'conv5' weights[0]: 7.977886e-03 [6.647119e-09] 
Layer 'conv5' biases: 9.999921e-01 [6.646691e-09] 
Layer 'fc6' weights[0]: 7.574513e-03 [9.124631e-10] 
Layer 'fc6' biases: 1.000000e+00 [4.861841e-10] 
Layer 'fc7' weights[0]: 6.966228e-03 [4.451848e-08] 
Layer 'fc7' biases: 9.998569e-01 [2.283600e-08] 
Layer 'fc8' weights[0]: 1.277670e-03 [4.504183e-06] 
Layer 'fc8' biases: 6.832715e-02 [2.769801e-05] 
Train error last 870 batches: 0.435197
-------------------------------------------------------
Not saving because 0.417338 > 0.415650 (27.630: -0.00%)
======================================================= (12.200 sec)
28.161... logprob:  0.349737, 0.078125 (1.413 sec)
28.162... logprob:  0.611787, 0.179688 (1.416 sec)
28.163... logprob:  0.450480, 0.125000 (1.434 sec)
28.164... logprob:  0.468538, 0.125000 (1.426 sec)
28.165... logprob:  0.547778, 0.156250 (1.421 sec)
28.166... logprob:  0.446143, 0.125000 (1.448 sec)
28.167... logprob:  0.350595, 0.085938 (1.435 sec)
28.168... logprob:  0.363743, 0.085938 (1.423 sec)
28.169... logprob:  0.408632, 0.101562 (1.462 sec)
28.170... logprob:  0.459465, 0.125000 (1.405 sec)
28.171... logprob:  0.535247, 0.156250 (1.422 sec)
28.172... logprob:  0.434808, 0.109375 (1.418 sec)
28.173... logprob:  0.440469, 0.117188 (1.420 sec)
28.174... logprob:  0.600731, 0.171875 (1.406 sec)
28.175... logprob:  0.505955, 0.140625 (1.465 sec)
28.176... logprob:  0.478407, 0.132812 (1.420 sec)
28.177... logprob:  0.289726, 0.054688 (1.428 sec)
28.178... logprob:  0.383474, 0.093750 (1.462 sec)
28.179... logprob:  0.394667, 0.101562 (1.410 sec)
28.180... logprob:  0.466390, 0.125000 (1.431 sec)
28.181... logprob:  0.539288, 0.156250 (1.416 sec)
28.182... logprob:  0.371288, 0.093750 (1.419 sec)
28.183... logprob:  0.419934, 0.109375 (1.424 sec)
28.184... logprob:  0.483439, 0.132812 (1.424 sec)
28.185... logprob:  0.289756, 0.062500 (1.397 sec)
28.186... logprob:  0.370368, 0.093750 (1.399 sec)
28.187... logprob:  0.529617, 0.148438 (1.406 sec)
28.188... logprob:  0.458877, 0.125000 (1.392 sec)
28.189... logprob:  0.440919, 0.117188 (1.396 sec)
28.190... logprob:  0.375785, 0.093750 (1.431 sec)
28.191... logprob:  0.485093, 0.132812 (1.413 sec)
28.192... logprob:  0.520041, 0.148438 (1.419 sec)
28.193... logprob:  0.312501, 0.070312 (1.419 sec)
28.194... logprob:  0.414056, 0.109375 (1.421 sec)
28.195... logprob:  0.287041, 0.062500 (1.404 sec)
28.196... logprob:  0.410467, 0.109375 (1.396 sec)
28.197... logprob:  0.477986, 0.132812 (1.407 sec)
28.198... logprob:  0.355796, 0.085938 (1.406 sec)
28.199... logprob:  0.437194, 0.117188 (1.390 sec)
28.200... logprob:  0.440734, 0.117188 (1.439 sec)
28.201... logprob:  0.437090, 0.117188 (1.412 sec)
28.202... logprob:  0.537848, 0.148438 (1.409 sec)
28.203... logprob:  0.420410, 0.109375 (1.440 sec)
28.204... logprob:  0.504123, 0.140625 (1.392 sec)
28.205... logprob:  0.334289, 0.078125 (1.404 sec)
28.206... logprob:  0.361635, 0.093750 (1.405 sec)
28.207... logprob:  0.381774, 0.093750 (1.392 sec)
28.208... logprob:  0.490580, 0.140625 (1.409 sec)
28.209... logprob:  0.334540, 0.078125 (1.419 sec)
28.210... logprob:  0.586228, 0.171875 (1.420 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.69498825073242, 10.0]}, 128)
batch 872: ({'logprob': [66.32345581054688, 19.0]}, 128)
batch 873: ({'logprob': [40.895206451416016, 9.0]}, 128)
batch 874: ({'logprob': [45.30636215209961, 11.0]}, 128)
batch 875: ({'logprob': [50.825557708740234, 13.0]}, 128)
batch 876: ({'logprob': [63.865760803222656, 18.0]}, 128)
batch 877: ({'logprob': [45.8710823059082, 11.0]}, 128)
batch 878: ({'logprob': [61.91727066040039, 17.0]}, 128)
batch 879: ({'logprob': [73.51988220214844, 21.0]}, 128)
batch 880: ({'logprob': [50.850318908691406, 13.0]}, 128)
batch 881: ({'logprob': [29.254594802856445, 5.0]}, 128)
batch 882: ({'logprob': [55.004554748535156, 14.0]}, 128)
batch 883: ({'logprob': [61.89102554321289, 17.0]}, 128)
batch 884: ({'logprob': [51.39022445678711, 13.0]}, 128)
batch 885: ({'logprob': [52.50163269042969, 13.0]}, 128)
batch 886: ({'logprob': [62.468196868896484, 17.0]}, 128)

======================Test output======================
logprob:  0.416787, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961132e-03 [3.253420e-09] 
Layer 'conv1' biases: 3.427654e-07 [1.370583e-10] 
Layer 'conv2' weights[0]: 7.948204e-03 [2.360112e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.892920e-10] 
Layer 'conv3' weights[0]: 7.946387e-03 [2.533987e-09] 
Layer 'conv3' biases: 2.908621e-06 [1.709417e-09] 
Layer 'conv4' weights[0]: 7.979085e-03 [2.434912e-09] 
Layer 'conv4' biases: 9.999993e-01 [1.378692e-08] 
Layer 'conv5' weights[0]: 7.977847e-03 [8.731652e-08] 
Layer 'conv5' biases: 9.999921e-01 [9.390570e-08] 
Layer 'fc6' weights[0]: 7.574474e-03 [7.220159e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.346782e-09] 
Layer 'fc7' weights[0]: 6.964423e-03 [7.924893e-08] 
Layer 'fc7' biases: 9.998569e-01 [6.466908e-08] 
Layer 'fc8' weights[0]: 1.289672e-03 [4.590205e-06] 
Layer 'fc8' biases: 6.848739e-02 [3.035428e-05] 
Train error last 870 batches: 0.435196
-------------------------------------------------------
Not saving because 0.416787 > 0.415650 (27.630: -0.00%)
======================================================= (12.078 sec)
28.211... logprob:  0.488128, 0.132812 (1.426 sec)
28.212... logprob:  0.526120, 0.148438 (1.415 sec)
28.213... logprob:  0.514629, 0.140625 (1.457 sec)
28.214... logprob:  0.459396, 0.125000 (1.431 sec)
28.215... logprob:  0.396095, 0.101562 (1.426 sec)
28.216... logprob:  0.516930, 0.140625 (1.469 sec)
28.217... logprob:  0.324876, 0.070312 (1.403 sec)
28.218... logprob:  0.463594, 0.125000 (1.426 sec)
28.219... logprob:  0.500233, 0.140625 (1.415 sec)
28.220... logprob:  0.415025, 0.109375 (1.420 sec)
28.221... logprob:  0.399569, 0.101562 (1.405 sec)
28.222... logprob:  0.554416, 0.164062 (1.463 sec)
28.223... logprob:  0.568955, 0.164062 (1.432 sec)
28.224... logprob:  0.405972, 0.101562 (1.431 sec)
28.225... logprob:  0.392004, 0.101562 (1.453 sec)
28.226... logprob:  0.424738, 0.109375 (1.424 sec)
28.227... logprob:  0.452630, 0.125000 (1.444 sec)
28.228... logprob:  0.417171, 0.109375 (1.413 sec)
28.229... logprob:  0.489371, 0.132812 (1.423 sec)
28.230... logprob:  0.459853, 0.125000 (1.428 sec)
28.231... logprob:  0.453490, 0.125000 (1.411 sec)
28.232... logprob:  0.496163, 0.140625 (1.456 sec)
28.233... logprob:  0.466066, 0.132812 (1.432 sec)
28.234... logprob:  0.563863, 0.164062 (1.416 sec)
28.235... logprob:  0.482013, 0.132812 (1.469 sec)
28.236... logprob:  0.425657, 0.109375 (1.403 sec)
28.237... logprob:  0.340952, 0.078125 (1.425 sec)
28.238... logprob:  0.389125, 0.093750 (1.415 sec)
28.239... logprob:  0.478090, 0.132812 (1.425 sec)
28.240... logprob:  0.485796, 0.132812 (1.399 sec)
28.241... logprob:  0.493601, 0.132812 (1.464 sec)
28.242... logprob:  0.341633, 0.078125 (1.424 sec)
28.243... logprob:  0.385997, 0.093750 (1.435 sec)
28.244... logprob:  0.315406, 0.070312 (1.455 sec)
28.245... logprob:  0.494218, 0.132812 (1.426 sec)
28.246... logprob:  0.416849, 0.109375 (1.423 sec)
28.247... logprob:  0.357561, 0.085938 (1.419 sec)
28.248... logprob:  0.308039, 0.070312 (1.417 sec)
28.249... logprob:  0.554612, 0.156250 (1.425 sec)
28.250... logprob:  0.591211, 0.164062 (1.405 sec)
28.251... logprob:  0.352989, 0.085938 (1.465 sec)
28.252... logprob:  0.348437, 0.085938 (1.431 sec)
28.253... logprob:  0.379220, 0.093750 (1.421 sec)
28.254... logprob:  0.444160, 0.117188 (1.465 sec)
28.255... logprob:  0.351334, 0.085938 (1.408 sec)
28.256... logprob:  0.378854, 0.093750 (1.420 sec)
28.257... logprob:  0.331973, 0.078125 (1.418 sec)
28.258... logprob:  0.415536, 0.109375 (1.426 sec)
28.259... logprob:  0.442317, 0.117188 (1.403 sec)
28.260... logprob:  0.308199, 0.070312 (1.461 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.825592041015625, 10.0]}, 128)
batch 872: ({'logprob': [67.8564682006836, 19.0]}, 128)
batch 873: ({'logprob': [39.60576248168945, 9.0]}, 128)
batch 874: ({'logprob': [45.02286148071289, 11.0]}, 128)
batch 875: ({'logprob': [50.809688568115234, 13.0]}, 128)
batch 876: ({'logprob': [65.08198547363281, 18.0]}, 128)
batch 877: ({'logprob': [45.21879959106445, 11.0]}, 128)
batch 878: ({'logprob': [62.44505310058594, 17.0]}, 128)
batch 879: ({'logprob': [74.2248764038086, 21.0]}, 128)
batch 880: ({'logprob': [50.836692810058594, 13.0]}, 128)
batch 881: ({'logprob': [27.788002014160156, 5.0]}, 128)
batch 882: ({'logprob': [54.210025787353516, 14.0]}, 128)
batch 883: ({'logprob': [62.41755676269531, 17.0]}, 128)
batch 884: ({'logprob': [51.01173782348633, 13.0]}, 128)
batch 885: ({'logprob': [51.38865661621094, 13.0]}, 128)
batch 886: ({'logprob': [62.63060760498047, 17.0]}, 128)

======================Test output======================
logprob:  0.416198, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961089e-03 [2.261579e-09] 
Layer 'conv1' biases: 3.438525e-07 [7.554312e-11] 
Layer 'conv2' weights[0]: 7.948161e-03 [1.907970e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.074865e-10] 
Layer 'conv3' weights[0]: 7.946344e-03 [1.801523e-09] 
Layer 'conv3' biases: 2.915061e-06 [9.239107e-10] 
Layer 'conv4' weights[0]: 7.979051e-03 [1.901730e-09] 
Layer 'conv4' biases: 9.999993e-01 [8.389407e-09] 
Layer 'conv5' weights[0]: 7.977809e-03 [5.456724e-08] 
Layer 'conv5' biases: 9.999919e-01 [5.864969e-08] 
Layer 'fc6' weights[0]: 7.574435e-03 [4.597182e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.581330e-09] 
Layer 'fc7' weights[0]: 6.962647e-03 [7.367203e-08] 
Layer 'fc7' biases: 9.998574e-01 [5.776996e-08] 
Layer 'fc8' weights[0]: 1.321766e-03 [2.402245e-06] 
Layer 'fc8' biases: 6.882126e-02 [1.699196e-05] 
Train error last 870 batches: 0.435196
-------------------------------------------------------
Not saving because 0.416198 > 0.415650 (27.630: -0.00%)
======================================================= (12.060 sec)
28.261... logprob:  0.392577, 0.101562 (1.434 sec)
28.262... logprob:  0.524525, 0.148438 (1.443 sec)
28.263... logprob:  0.425585, 0.109375 (1.456 sec)
28.264... logprob:  0.375031, 0.093750 (1.429 sec)
28.265... logprob:  0.439610, 0.117188 (1.419 sec)
28.266... logprob:  0.439009, 0.117188 (1.417 sec)
28.267... logprob:  0.422034, 0.109375 (1.417 sec)
28.268... logprob:  0.458939, 0.125000 (1.441 sec)
28.269... logprob:  0.567568, 0.164062 (1.410 sec)
28.270... logprob:  0.542327, 0.156250 (1.459 sec)
28.271... logprob:  0.445608, 0.117188 (1.429 sec)
28.272... logprob:  0.384573, 0.093750 (1.416 sec)
28.273... logprob:  0.500232, 0.140625 (1.471 sec)
28.274... logprob:  0.542501, 0.156250 (1.400 sec)
28.275... logprob:  0.487581, 0.132812 (1.430 sec)
28.276... logprob:  0.390018, 0.093750 (1.419 sec)
28.277... logprob:  0.428607, 0.109375 (1.428 sec)
28.278... logprob:  0.323608, 0.070312 (1.428 sec)
28.279... logprob:  0.325267, 0.070312 (1.470 sec)
28.280... logprob:  0.215968, 0.031250 (1.410 sec)
28.281... logprob:  0.417249, 0.109375 (1.429 sec)
28.282... logprob:  0.411323, 0.109375 (1.425 sec)
28.283... logprob:  0.393736, 0.101562 (1.418 sec)
28.284... logprob:  0.394393, 0.101562 (1.507 sec)
28.285... logprob:  0.451442, 0.117188 (1.448 sec)
28.286... logprob:  0.536353, 0.140625 (1.436 sec)
28.287... logprob:  0.346536, 0.085938 (1.437 sec)
28.288... logprob:  0.329945, 0.078125 (1.441 sec)
28.289... logprob:  0.445809, 0.117188 (1.448 sec)
28.290... logprob:  0.490649, 0.132812 (1.415 sec)
28.291... logprob:  0.439314, 0.117188 (1.418 sec)
28.292... logprob:  0.567671, 0.156250 (1.419 sec)
28.293... logprob:  0.427743, 0.117188 (1.429 sec)
28.294... logprob:  0.355755, 0.085938 (1.402 sec)
28.295... logprob:  0.334374, 0.078125 (1.467 sec)
28.296... logprob:  0.355505, 0.085938 (1.418 sec)
28.297... logprob:  0.394369, 0.101562 (1.424 sec)
28.298... logprob:  0.448239, 0.125000 (1.468 sec)
28.299... logprob:  0.341979, 0.078125 (1.408 sec)
28.300... logprob:  0.406379, 0.101562 (1.428 sec)
28.301... logprob:  0.397887, 0.101562 (1.416 sec)
28.302... logprob:  0.591586, 0.179688 (1.450 sec)
28.303... logprob:  0.459496, 0.125000 (1.415 sec)
28.304... logprob:  0.459620, 0.125000 (1.442 sec)
28.305... logprob:  0.455197, 0.125000 (1.435 sec)
28.306... logprob:  0.440576, 0.117188 (1.432 sec)
28.307... logprob:  0.421623, 0.109375 (1.440 sec)
28.308... logprob:  0.374821, 0.093750 (1.459 sec)
28.309... logprob:  0.450481, 0.125000 (1.413 sec)
28.310... logprob:  0.473591, 0.125000 (1.436 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.80370330810547, 10.0]}, 128)
batch 872: ({'logprob': [66.16150665283203, 19.0]}, 128)
batch 873: ({'logprob': [41.15652084350586, 9.0]}, 128)
batch 874: ({'logprob': [45.44013214111328, 11.0]}, 128)
batch 875: ({'logprob': [50.90365219116211, 13.0]}, 128)
batch 876: ({'logprob': [63.749237060546875, 18.0]}, 128)
batch 877: ({'logprob': [46.040706634521484, 11.0]}, 128)
batch 878: ({'logprob': [61.88261413574219, 17.0]}, 128)
batch 879: ({'logprob': [73.40827941894531, 21.0]}, 128)
batch 880: ({'logprob': [50.92802810668945, 13.0]}, 128)
batch 881: ({'logprob': [29.593177795410156, 5.0]}, 128)
batch 882: ({'logprob': [55.142982482910156, 14.0]}, 128)
batch 883: ({'logprob': [61.85676193237305, 17.0]}, 128)
batch 884: ({'logprob': [51.503135681152344, 13.0]}, 128)
batch 885: ({'logprob': [52.68574142456055, 13.0]}, 128)
batch 886: ({'logprob': [62.468868255615234, 17.0]}, 128)

======================Test output======================
logprob:  0.417346, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961046e-03 [2.478410e-09] 
Layer 'conv1' biases: 3.449906e-07 [4.534804e-11] 
Layer 'conv2' weights[0]: 7.948121e-03 [1.494230e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.390139e-10] 
Layer 'conv3' weights[0]: 7.946312e-03 [1.157700e-09] 
Layer 'conv3' biases: 2.924632e-06 [3.912315e-10] 
Layer 'conv4' weights[0]: 7.979011e-03 [1.138062e-09] 
Layer 'conv4' biases: 9.999993e-01 [2.380394e-09] 
Layer 'conv5' weights[0]: 7.977787e-03 [1.313461e-08] 
Layer 'conv5' biases: 9.999918e-01 [1.383115e-08] 
Layer 'fc6' weights[0]: 7.574396e-03 [1.318494e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.062400e-09] 
Layer 'fc7' weights[0]: 6.960846e-03 [4.472033e-08] 
Layer 'fc7' biases: 9.998568e-01 [2.304819e-08] 
Layer 'fc8' weights[0]: 1.282518e-03 [8.668721e-07] 
Layer 'fc8' biases: 6.881103e-02 [8.531879e-06] 
Train error last 870 batches: 0.435196
-------------------------------------------------------
Not saving because 0.417346 > 0.415650 (27.630: -0.00%)
======================================================= (12.113 sec)
28.311... logprob:  0.502472, 0.140625 (1.439 sec)
28.312... logprob:  0.478681, 0.132812 (1.442 sec)
28.313... logprob:  0.454858, 0.125000 (1.420 sec)
28.314... logprob:  0.454359, 0.117188 (1.471 sec)
28.315... logprob:  0.314679, 0.070312 (1.441 sec)
28.316... logprob:  0.468513, 0.125000 (1.427 sec)
28.317... logprob:  0.355433, 0.085938 (1.488 sec)
28.318... logprob:  0.455402, 0.125000 (1.412 sec)
28.319... logprob:  0.423169, 0.117188 (1.429 sec)
28.320... logprob:  0.412235, 0.109375 (1.424 sec)
28.321... logprob:  0.348241, 0.085938 (1.429 sec)
28.322... logprob:  0.387442, 0.101562 (1.421 sec)
28.323... logprob:  0.416504, 0.109375 (1.475 sec)
28.324... logprob:  0.498599, 0.140625 (1.429 sec)
28.325... logprob:  0.350674, 0.085938 (1.439 sec)
28.326... logprob:  0.543180, 0.148438 (1.463 sec)
28.327... logprob:  0.554413, 0.164062 (1.426 sec)
28.328... logprob:  0.565125, 0.156250 (1.431 sec)
28.329... logprob:  0.401919, 0.101562 (1.430 sec)
28.330... logprob:  0.388514, 0.101562 (1.419 sec)
28.331... logprob:  0.352277, 0.085938 (1.431 sec)
28.332... logprob:  0.482781, 0.132812 (1.446 sec)
28.333... logprob:  0.339483, 0.085938 (1.451 sec)
28.334... logprob:  0.565276, 0.171875 (1.440 sec)
28.335... logprob:  0.358699, 0.085938 (1.469 sec)
28.336... logprob:  0.444857, 0.125000 (1.456 sec)
28.337... logprob:  0.566407, 0.164062 (1.421 sec)
28.338... logprob:  0.449515, 0.125000 (1.428 sec)
28.339... logprob:  0.488596, 0.132812 (1.421 sec)
28.340... logprob:  0.442066, 0.117188 (1.431 sec)
28.341... logprob:  0.530035, 0.148438 (1.424 sec)
28.342... logprob:  0.429609, 0.109375 (1.463 sec)
28.343... logprob:  0.434767, 0.109375 (1.441 sec)
28.344... logprob:  0.444514, 0.125000 (1.486 sec)
28.345... logprob:  0.488193, 0.132812 (1.440 sec)
28.346... logprob:  0.436210, 0.117188 (1.439 sec)
28.347... logprob:  0.372527, 0.085938 (1.483 sec)
28.348... logprob:  0.398483, 0.101562 (1.437 sec)
28.349... logprob:  0.497617, 0.140625 (1.436 sec)
28.350... logprob:  0.358695, 0.085938 (1.437 sec)
28.351... logprob:  0.508503, 0.140625 (1.429 sec)
28.352... logprob:  0.363615, 0.093750 (1.439 sec)
28.353... logprob:  0.512478, 0.148438 (1.487 sec)
28.354... logprob:  0.674822, 0.203125 (1.429 sec)
28.355... logprob:  0.357496, 0.085938 (1.452 sec)
28.356... logprob:  0.479239, 0.132812 (1.478 sec)
28.357... logprob:  0.346756, 0.085938 (1.435 sec)
28.358... logprob:  0.325773, 0.070312 (1.439 sec)
28.359... logprob:  0.555365, 0.164062 (1.433 sec)
28.360... logprob:  0.444522, 0.117188 (1.432 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.03774642944336, 10.0]}, 128)
batch 872: ({'logprob': [66.12580871582031, 19.0]}, 128)
batch 873: ({'logprob': [41.20915985107422, 9.0]}, 128)
batch 874: ({'logprob': [45.54874038696289, 11.0]}, 128)
batch 875: ({'logprob': [50.945518493652344, 13.0]}, 128)
batch 876: ({'logprob': [63.71635437011719, 18.0]}, 128)
batch 877: ({'logprob': [46.0882682800293, 11.0]}, 128)
batch 878: ({'logprob': [61.79129409790039, 17.0]}, 128)
batch 879: ({'logprob': [73.12249755859375, 21.0]}, 128)
batch 880: ({'logprob': [50.97016906738281, 13.0]}, 128)
batch 881: ({'logprob': [29.840652465820312, 5.0]}, 128)
batch 882: ({'logprob': [54.99825668334961, 14.0]}, 128)
batch 883: ({'logprob': [61.765167236328125, 17.0]}, 128)
batch 884: ({'logprob': [51.48357009887695, 13.0]}, 128)
batch 885: ({'logprob': [52.54361343383789, 13.0]}, 128)
batch 886: ({'logprob': [62.31600570678711, 17.0]}, 128)

======================Test output======================
logprob:  0.417238, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.961001e-03 [3.485325e-09] 
Layer 'conv1' biases: 3.458995e-07 [5.637836e-11] 
Layer 'conv2' weights[0]: 7.948081e-03 [2.067599e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.800746e-10] 
Layer 'conv3' weights[0]: 7.946275e-03 [1.428898e-09] 
Layer 'conv3' biases: 2.932407e-06 [4.854833e-10] 
Layer 'conv4' weights[0]: 7.978975e-03 [1.351381e-09] 
Layer 'conv4' biases: 9.999993e-01 [2.035739e-09] 
Layer 'conv5' weights[0]: 7.977737e-03 [1.334738e-08] 
Layer 'conv5' biases: 9.999920e-01 [1.423182e-08] 
Layer 'fc6' weights[0]: 7.574350e-03 [1.357329e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.112425e-09] 
Layer 'fc7' weights[0]: 6.959054e-03 [6.587568e-08] 
Layer 'fc7' biases: 9.998567e-01 [5.002385e-08] 
Layer 'fc8' weights[0]: 1.279048e-03 [1.612656e-06] 
Layer 'fc8' biases: 6.888574e-02 [9.449982e-06] 
Train error last 870 batches: 0.435195
-------------------------------------------------------
Not saving because 0.417238 > 0.415650 (27.630: -0.00%)
======================================================= (12.138 sec)
28.361... logprob:  0.410737, 0.101562 (1.450 sec)
28.362... logprob:  0.423959, 0.117188 (1.481 sec)
28.363... logprob:  0.486590, 0.132812 (1.443 sec)
28.364... logprob:  0.475606, 0.125000 (1.457 sec)
28.365... logprob:  0.425044, 0.109375 (1.464 sec)
28.366... logprob:  0.409578, 0.109375 (1.447 sec)
28.367... logprob:  0.324910, 0.078125 (1.444 sec)
28.368... logprob:  0.595564, 0.171875 (1.462 sec)
28.369... logprob:  0.381652, 0.093750 (1.428 sec)
28.370... logprob:  0.381285, 0.093750 (1.441 sec)
28.371... logprob:  0.400417, 0.101562 (1.459 sec)
28.372... logprob:  0.537258, 0.156250 (1.455 sec)
28.373... logprob:  0.463791, 0.125000 (1.455 sec)
28.374... logprob:  0.526838, 0.148438 (1.455 sec)
28.375... logprob:  0.393768, 0.101562 (1.462 sec)
28.376... logprob:  0.374290, 0.093750 (1.444 sec)
28.377... logprob:  0.295431, 0.062500 (1.424 sec)
28.378... logprob:  0.453672, 0.125000 (1.436 sec)
28.379... logprob:  0.420243, 0.109375 (1.436 sec)
28.380... logprob:  0.605680, 0.179688 (1.438 sec)
28.381... logprob:  0.463418, 0.125000 (1.465 sec)
28.382... logprob:  0.529576, 0.148438 (1.455 sec)
28.383... logprob:  0.358540, 0.085938 (1.440 sec)
28.384... logprob:  0.521202, 0.148438 (1.483 sec)
28.385... logprob:  0.523578, 0.148438 (1.434 sec)
28.386... logprob:  0.582565, 0.171875 (1.432 sec)
28.387... logprob:  0.428519, 0.117188 (1.435 sec)
28.388... logprob:  0.521374, 0.148438 (1.436 sec)
28.389... logprob:  0.425593, 0.109375 (1.434 sec)
28.390... logprob:  0.419686, 0.109375 (1.481 sec)
28.391... logprob:  0.318161, 0.070312 (1.448 sec)
28.392... logprob:  0.439449, 0.117188 (1.435 sec)
28.393... logprob:  0.369017, 0.093750 (1.483 sec)
28.394... logprob:  0.343692, 0.078125 (1.440 sec)
28.395... logprob:  0.331883, 0.078125 (1.432 sec)
28.396... logprob:  0.252547, 0.046875 (1.434 sec)
28.397... logprob:  0.484133, 0.132812 (1.436 sec)
28.398... logprob:  0.470712, 0.125000 (1.437 sec)
28.399... logprob:  0.433190, 0.117188 (1.486 sec)
28.400... logprob:  0.537498, 0.148438 (1.437 sec)
28.401... logprob:  0.465662, 0.125000 (1.449 sec)
28.402... logprob:  0.473846, 0.125000 (1.484 sec)
28.403... logprob:  0.462102, 0.125000 (1.430 sec)
28.404... logprob:  0.474806, 0.125000 (1.441 sec)
28.405... logprob:  0.544246, 0.156250 (1.434 sec)
28.406... logprob:  0.357562, 0.085938 (1.431 sec)
28.407... logprob:  0.493013, 0.140625 (1.437 sec)
28.408... logprob:  0.338900, 0.078125 (1.478 sec)
28.409... logprob:  0.400434, 0.101562 (1.462 sec)
28.410... logprob:  0.582274, 0.171875 (1.448 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.896026611328125, 10.0]}, 128)
batch 872: ({'logprob': [65.69023895263672, 19.0]}, 128)
batch 873: ({'logprob': [42.53388977050781, 9.0]}, 128)
batch 874: ({'logprob': [46.40830612182617, 11.0]}, 128)
batch 875: ({'logprob': [51.53008270263672, 13.0]}, 128)
batch 876: ({'logprob': [63.46480941772461, 18.0]}, 128)
batch 877: ({'logprob': [47.04324722290039, 11.0]}, 128)
batch 878: ({'logprob': [61.820796966552734, 17.0]}, 128)
batch 879: ({'logprob': [72.69096374511719, 21.0]}, 128)
batch 880: ({'logprob': [51.55358123779297, 13.0]}, 128)
batch 881: ({'logprob': [31.627517700195312, 5.0]}, 128)
batch 882: ({'logprob': [55.67665100097656, 14.0]}, 128)
batch 883: ({'logprob': [61.79533767700195, 17.0]}, 128)
batch 884: ({'logprob': [52.15875244140625, 13.0]}, 128)
batch 885: ({'logprob': [53.40672302246094, 13.0]}, 128)
batch 886: ({'logprob': [62.43791961669922, 17.0]}, 128)

======================Test output======================
logprob:  0.421257, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960959e-03 [3.086080e-09] 
Layer 'conv1' biases: 3.468913e-07 [4.269243e-11] 
Layer 'conv2' weights[0]: 7.948042e-03 [2.042211e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.375166e-10] 
Layer 'conv3' weights[0]: 7.946236e-03 [1.634598e-09] 
Layer 'conv3' biases: 2.940898e-06 [7.761353e-10] 
Layer 'conv4' weights[0]: 7.978934e-03 [1.750279e-09] 
Layer 'conv4' biases: 9.999993e-01 [6.251837e-09] 
Layer 'conv5' weights[0]: 7.977699e-03 [4.085568e-08] 
Layer 'conv5' biases: 9.999921e-01 [4.380584e-08] 
Layer 'fc6' weights[0]: 7.574309e-03 [3.427329e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.401506e-09] 
Layer 'fc7' weights[0]: 6.957284e-03 [2.250245e-07] 
Layer 'fc7' biases: 9.998559e-01 [2.152152e-07] 
Layer 'fc8' weights[0]: 1.248229e-03 [8.355496e-06] 
Layer 'fc8' biases: 6.886386e-02 [4.824121e-05] 
Train error last 870 batches: 0.435195
-------------------------------------------------------
Not saving because 0.421257 > 0.415650 (27.630: -0.00%)
======================================================= (12.047 sec)
28.411... logprob:  0.397759, 0.101562 (1.480 sec)
28.412... logprob:  0.540315, 0.156250 (1.447 sec)
28.413... logprob:  0.544660, 0.156250 (1.439 sec)
28.414... logprob:  0.466389, 0.125000 (1.430 sec)
28.415... logprob:  0.401658, 0.101562 (1.428 sec)
28.416... logprob:  0.427497, 0.109375 (1.440 sec)
28.417... logprob:  0.405464, 0.093750 (1.462 sec)
28.418... logprob:  0.380443, 0.093750 (1.454 sec)
28.419... logprob:  0.417863, 0.101562 (1.458 sec)
28.420... logprob:  0.356451, 0.085938 (1.452 sec)
28.421... logprob:  0.376647, 0.101562 (1.464 sec)
28.422... logprob:  0.522131, 0.148438 (1.438 sec)
28.423... logprob:  0.420813, 0.109375 (1.426 sec)
28.424... logprob:  0.324894, 0.078125 (1.436 sec)
28.425... logprob:  0.306487, 0.070312 (1.437 sec)
28.426... logprob:  0.449046, 0.117188 (1.449 sec)
28.427... logprob:  0.554098, 0.156250 (1.463 sec)
28.428... logprob:  0.601602, 0.171875 (1.458 sec)
28.429... logprob:  0.426347, 0.109375 (1.442 sec)
28.430... logprob:  0.299780, 0.070312 (1.481 sec)
28.431... logprob:  0.600009, 0.171875 (1.432 sec)
28.432... logprob:  0.387527, 0.093750 (1.431 sec)
28.433... logprob:  0.329649, 0.078125 (1.433 sec)
28.434... logprob:  0.529611, 0.148438 (1.442 sec)
28.435... logprob:  0.532496, 0.156250 (1.434 sec)
28.436... logprob:  0.380974, 0.093750 (1.480 sec)
28.437... logprob:  0.500324, 0.140625 (1.444 sec)
28.438... logprob:  0.546985, 0.156250 (1.437 sec)
28.439... logprob:  0.378628, 0.093750 (1.487 sec)
28.440... logprob:  0.439670, 0.117188 (1.435 sec)
28.441... logprob:  0.467958, 0.125000 (1.434 sec)
28.442... logprob:  0.378930, 0.093750 (1.470 sec)
28.443... logprob:  0.496561, 0.140625 (1.436 sec)
28.444... logprob:  0.372396, 0.093750 (1.432 sec)
28.445... logprob:  0.362608, 0.085938 (1.488 sec)
28.446... logprob:  0.398375, 0.101562 (1.439 sec)
28.447... logprob:  0.569562, 0.164062 (1.437 sec)
28.448... logprob:  0.332982, 0.078125 (1.488 sec)
28.449... logprob:  0.400042, 0.101562 (1.432 sec)
28.450... logprob:  0.239677, 0.046875 (1.438 sec)
28.451... logprob:  0.452551, 0.125000 (1.434 sec)
28.452... logprob:  0.456023, 0.117188 (1.435 sec)
28.453... logprob:  0.455130, 0.125000 (1.433 sec)
28.454... logprob:  0.488910, 0.132812 (1.486 sec)
28.455... logprob:  0.506030, 0.140625 (1.437 sec)
28.456... logprob:  0.468841, 0.125000 (1.447 sec)
28.457... logprob:  0.375326, 0.093750 (1.478 sec)
28.458... logprob:  0.350986, 0.085938 (1.436 sec)
28.459... logprob:  0.514043, 0.140625 (1.436 sec)
28.460... logprob:  0.273747, 0.054688 (1.438 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.64078903198242, 10.0]}, 128)
batch 872: ({'logprob': [66.45543670654297, 19.0]}, 128)
batch 873: ({'logprob': [40.71145248413086, 9.0]}, 128)
batch 874: ({'logprob': [45.22383499145508, 11.0]}, 128)
batch 875: ({'logprob': [50.78068542480469, 13.0]}, 128)
batch 876: ({'logprob': [63.9631233215332, 18.0]}, 128)
batch 877: ({'logprob': [45.75665283203125, 11.0]}, 128)
batch 878: ({'logprob': [61.94821548461914, 17.0]}, 128)
batch 879: ({'logprob': [73.59528350830078, 21.0]}, 128)
batch 880: ({'logprob': [50.8055305480957, 13.0]}, 128)
batch 881: ({'logprob': [29.026569366455078, 5.0]}, 128)
batch 882: ({'logprob': [54.90004348754883, 14.0]}, 128)
batch 883: ({'logprob': [61.922019958496094, 17.0]}, 128)
batch 884: ({'logprob': [51.31432342529297, 13.0]}, 128)
batch 885: ({'logprob': [52.362571716308594, 13.0]}, 128)
batch 886: ({'logprob': [62.46773910522461, 17.0]}, 128)

======================Test output======================
logprob:  0.416443, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960915e-03 [2.764299e-09] 
Layer 'conv1' biases: 3.478276e-07 [9.499020e-11] 
Layer 'conv2' weights[0]: 7.948000e-03 [2.913800e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.074912e-10] 
Layer 'conv3' weights[0]: 7.946196e-03 [2.785520e-09] 
Layer 'conv3' biases: 2.948104e-06 [1.533618e-09] 
Layer 'conv4' weights[0]: 7.978899e-03 [2.785449e-09] 
Layer 'conv4' biases: 9.999994e-01 [1.293692e-08] 
Layer 'conv5' weights[0]: 7.977661e-03 [7.884479e-08] 
Layer 'conv5' biases: 9.999918e-01 [8.486948e-08] 
Layer 'fc6' weights[0]: 7.574272e-03 [6.517669e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.624576e-09] 
Layer 'fc7' weights[0]: 6.955472e-03 [9.602211e-08] 
Layer 'fc7' biases: 9.998571e-01 [8.296024e-08] 
Layer 'fc8' weights[0]: 1.285723e-03 [2.933807e-06] 
Layer 'fc8' biases: 6.949870e-02 [1.670422e-05] 
Train error last 870 batches: 0.435195
-------------------------------------------------------
Not saving because 0.416443 > 0.415650 (27.630: -0.00%)
======================================================= (12.062 sec)
28.461... logprob:  0.460121, 0.125000 (1.434 sec)
28.462... logprob:  0.471989, 0.125000 (1.444 sec)
28.463... logprob:  0.420816, 0.109375 (1.478 sec)
28.464... logprob:  0.482787, 0.132812 (1.448 sec)
28.465... logprob:  0.421112, 0.109375 (1.461 sec)
28.466... logprob:  0.318304, 0.070312 (1.459 sec)
28.467... logprob:  0.413830, 0.109375 (1.450 sec)
28.468... logprob:  0.394260, 0.101562 (1.443 sec)
28.469... logprob:  0.334783, 0.078125 (1.427 sec)
28.470... logprob:  0.400099, 0.101562 (1.433 sec)
28.471... logprob:  0.529247, 0.148438 (1.438 sec)
28.472... logprob:  0.409988, 0.109375 (1.456 sec)
28.473... logprob:  0.375465, 0.093750 (1.457 sec)
28.474... logprob:  0.465538, 0.125000 (1.457 sec)
28.475... logprob:  0.503946, 0.140625 (1.471 sec)
28.476... logprob:  0.510182, 0.140625 (1.475 sec)
28.477... logprob:  0.334633, 0.078125 (1.436 sec)
28.478... logprob:  0.464235, 0.125000 (1.417 sec)
28.479... logprob:  0.305773, 0.070312 (1.438 sec)
28.480... logprob:  0.443504, 0.117188 (1.439 sec)
28.481... logprob:  0.547811, 0.156250 (1.435 sec)
28.482... logprob:  0.443140, 0.117188 (1.475 sec)
28.483... logprob:  0.502691, 0.140625 (1.452 sec)
28.484... logprob:  0.485319, 0.132812 (1.439 sec)
28.485... logprob:  0.408935, 0.109375 (1.485 sec)
28.486... logprob:  0.361300, 0.085938 (1.433 sec)
28.487... logprob:  0.522694, 0.148438 (1.432 sec)
28.488... logprob:  0.424724, 0.109375 (1.440 sec)
28.489... logprob:  0.415830, 0.109375 (1.429 sec)
28.490... logprob:  0.440689, 0.117188 (1.442 sec)
28.491... logprob:  0.313613, 0.070312 (1.480 sec)
28.492... logprob:  0.459531, 0.125000 (1.444 sec)
28.493... logprob:  0.521808, 0.148438 (1.434 sec)
28.494... logprob:  0.450347, 0.125000 (1.487 sec)
28.495... logprob:  0.380675, 0.093750 (1.438 sec)
28.496... logprob:  0.550229, 0.156250 (1.432 sec)
28.497... logprob:  0.466905, 0.125000 (1.439 sec)
28.498... logprob:  0.476221, 0.132812 (1.433 sec)
28.499... logprob:  0.456227, 0.125000 (1.429 sec)
28.500... logprob:  0.355154, 0.085938 (1.494 sec)
28.501... logprob:  0.339126, 0.078125 (1.428 sec)
28.502... logprob:  0.459607, 0.125000 (1.453 sec)
28.503... logprob:  0.400664, 0.101562 (1.478 sec)
28.504... logprob:  0.487284, 0.132812 (1.432 sec)
28.505... logprob:  0.570773, 0.164062 (1.442 sec)
28.506... logprob:  0.479685, 0.132812 (1.433 sec)
28.507... logprob:  0.385035, 0.093750 (1.431 sec)
28.508... logprob:  0.374662, 0.093750 (1.434 sec)
28.509... logprob:  0.323008, 0.070312 (1.480 sec)
28.510... logprob:  0.390457, 0.101562 (1.443 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.80304718017578, 10.0]}, 128)
batch 872: ({'logprob': [66.58625793457031, 19.0]}, 128)
batch 873: ({'logprob': [40.54964065551758, 9.0]}, 128)
batch 874: ({'logprob': [45.23486328125, 11.0]}, 128)
batch 875: ({'logprob': [50.773651123046875, 13.0]}, 128)
batch 876: ({'logprob': [64.05550384521484, 18.0]}, 128)
batch 877: ({'logprob': [45.672569274902344, 11.0]}, 128)
batch 878: ({'logprob': [61.906681060791016, 17.0]}, 128)
batch 879: ({'logprob': [73.4242935180664, 21.0]}, 128)
batch 880: ({'logprob': [50.79908752441406, 13.0]}, 128)
batch 881: ({'logprob': [28.994688034057617, 5.0]}, 128)
batch 882: ({'logprob': [54.647193908691406, 14.0]}, 128)
batch 883: ({'logprob': [61.88005065917969, 17.0]}, 128)
batch 884: ({'logprob': [51.21282958984375, 13.0]}, 128)
batch 885: ({'logprob': [52.070987701416016, 13.0]}, 128)
batch 886: ({'logprob': [62.33133316040039, 17.0]}, 128)

======================Test output======================
logprob:  0.415988, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960869e-03 [4.524496e-09] 
Layer 'conv1' biases: 3.486153e-07 [1.540875e-10] 
Layer 'conv2' weights[0]: 7.947969e-03 [3.239105e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.430504e-10] 
Layer 'conv3' weights[0]: 7.946161e-03 [3.064891e-09] 
Layer 'conv3' biases: 2.955658e-06 [1.787567e-09] 
Layer 'conv4' weights[0]: 7.978856e-03 [3.204453e-09] 
Layer 'conv4' biases: 9.999993e-01 [1.575745e-08] 
Layer 'conv5' weights[0]: 7.977624e-03 [1.014759e-07] 
Layer 'conv5' biases: 9.999916e-01 [1.090317e-07] 
Layer 'fc6' weights[0]: 7.574239e-03 [8.396153e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.506737e-09] 
Layer 'fc7' weights[0]: 6.953716e-03 [1.613733e-07] 
Layer 'fc7' biases: 9.998571e-01 [1.502816e-07] 
Layer 'fc8' weights[0]: 1.284026e-03 [5.991495e-06] 
Layer 'fc8' biases: 6.959775e-02 [4.139356e-05] 
Train error last 870 batches: 0.435194
-------------------------------------------------------
Not saving because 0.415988 > 0.415650 (27.630: -0.00%)
======================================================= (12.092 sec)
28.511... logprob:  0.410046, 0.109375 (1.460 sec)
28.512... logprob:  0.470717, 0.125000 (1.469 sec)
28.513... logprob:  0.324962, 0.078125 (1.444 sec)
28.514... logprob:  0.406272, 0.101562 (1.437 sec)
28.515... logprob:  0.455473, 0.125000 (1.431 sec)
28.516... logprob:  0.400270, 0.109375 (1.429 sec)
28.517... logprob:  0.627756, 0.179688 (1.440 sec)
28.518... logprob:  0.437647, 0.117188 (1.462 sec)
28.519... logprob:  0.516129, 0.140625 (1.457 sec)
28.520... logprob:  0.409643, 0.109375 (1.455 sec)
28.521... logprob:  0.427434, 0.109375 (1.453 sec)
28.522... logprob:  0.533161, 0.156250 (1.461 sec)
28.523... logprob:  0.331509, 0.078125 (1.442 sec)
28.524... logprob:  0.437150, 0.117188 (1.426 sec)
28.525... logprob:  0.425910, 0.109375 (1.433 sec)
28.526... logprob:  0.351675, 0.078125 (1.441 sec)
28.527... logprob:  0.504577, 0.140625 (1.442 sec)
28.528... logprob:  0.440459, 0.117188 (1.470 sec)
28.529... logprob:  0.353000, 0.085938 (1.453 sec)
28.530... logprob:  0.440254, 0.117188 (1.441 sec)
28.531... logprob:  0.439955, 0.117188 (1.482 sec)
28.532... logprob:  0.467318, 0.125000 (1.434 sec)
28.533... logprob:  0.560344, 0.164062 (1.430 sec)
28.534... logprob:  0.325931, 0.078125 (1.437 sec)
28.535... logprob:  0.551443, 0.156250 (1.437 sec)
28.536... logprob:  0.507272, 0.140625 (1.435 sec)
28.537... logprob:  0.510003, 0.140625 (1.481 sec)
28.538... logprob:  0.486083, 0.132812 (1.444 sec)
28.539... logprob:  0.296034, 0.062500 (1.435 sec)
28.540... logprob:  0.447177, 0.117188 (1.489 sec)
28.541... logprob:  0.388794, 0.101562 (1.435 sec)
28.542... logprob:  0.411239, 0.109375 (1.432 sec)
28.543... logprob:  0.233213, 0.039062 (1.435 sec)
28.544... logprob:  0.317922, 0.070312 (1.434 sec)
28.545... logprob:  0.348798, 0.085938 (1.433 sec)
28.546... logprob:  0.368270, 0.093750 (1.479 sec)
28.547... logprob:  0.440019, 0.117188 (1.439 sec)
28.548... logprob:  0.452893, 0.125000 (1.442 sec)
28.549... logprob:  0.490440, 0.132812 (1.506 sec)
28.550... logprob:  0.367612, 0.093750 (1.435 sec)
28.551... logprob:  0.441637, 0.117188 (1.435 sec)
28.552... logprob:  0.471256, 0.125000 (1.431 sec)
28.553... logprob:  0.349447, 0.085938 (1.429 sec)
28.554... logprob:  0.506976, 0.140625 (1.436 sec)
28.555... logprob:  0.421408, 0.109375 (1.483 sec)
28.556... logprob:  0.355792, 0.085938 (1.441 sec)
28.557... logprob:  0.396368, 0.101562 (1.450 sec)
28.558... logprob:  0.383007, 0.101562 (1.475 sec)
28.559... logprob:  0.441602, 0.125000 (1.439 sec)
28.560... logprob:  0.335057, 0.078125 (1.439 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.6404914855957, 10.0]}, 128)
batch 872: ({'logprob': [66.22087097167969, 19.0]}, 128)
batch 873: ({'logprob': [41.092403411865234, 9.0]}, 128)
batch 874: ({'logprob': [45.35781478881836, 11.0]}, 128)
batch 875: ({'logprob': [50.87466812133789, 13.0]}, 128)
batch 876: ({'logprob': [63.8001594543457, 18.0]}, 128)
batch 877: ({'logprob': [45.994171142578125, 11.0]}, 128)
batch 878: ({'logprob': [61.96086502075195, 17.0]}, 128)
batch 879: ({'logprob': [73.6290512084961, 21.0]}, 128)
batch 880: ({'logprob': [50.89918899536133, 13.0]}, 128)
batch 881: ({'logprob': [29.386201858520508, 5.0]}, 128)
batch 882: ({'logprob': [55.230960845947266, 14.0]}, 128)
batch 883: ({'logprob': [61.93459701538086, 17.0]}, 128)
batch 884: ({'logprob': [51.5107307434082, 13.0]}, 128)
batch 885: ({'logprob': [52.76539993286133, 13.0]}, 128)
batch 886: ({'logprob': [62.583221435546875, 17.0]}, 128)

======================Test output======================
logprob:  0.417422, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960821e-03 [3.810026e-09] 
Layer 'conv1' biases: 3.497563e-07 [1.296251e-10] 
Layer 'conv2' weights[0]: 7.947934e-03 [2.667815e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.237006e-10] 
Layer 'conv3' weights[0]: 7.946127e-03 [2.751173e-09] 
Layer 'conv3' biases: 2.965819e-06 [1.495862e-09] 
Layer 'conv4' weights[0]: 7.978811e-03 [2.807911e-09] 
Layer 'conv4' biases: 9.999993e-01 [1.303946e-08] 
Layer 'conv5' weights[0]: 7.977581e-03 [8.458758e-08] 
Layer 'conv5' biases: 9.999917e-01 [9.094110e-08] 
Layer 'fc6' weights[0]: 7.574191e-03 [6.999747e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.106765e-09] 
Layer 'fc7' weights[0]: 6.951878e-03 [4.532163e-08] 
Layer 'fc7' biases: 9.998572e-01 [2.366495e-08] 
Layer 'fc8' weights[0]: 1.277374e-03 [5.454036e-06] 
Layer 'fc8' biases: 6.966950e-02 [3.347685e-05] 
Train error last 870 batches: 0.435194
-------------------------------------------------------
Not saving because 0.417422 > 0.415650 (27.630: -0.00%)
======================================================= (12.111 sec)
28.561... logprob:  0.411793, 0.109375 (1.437 sec)
28.562... logprob:  0.503154, 0.140625 (1.431 sec)
28.563... logprob:  0.373766, 0.093750 (1.440 sec)
28.564... logprob:  0.468482, 0.132812 (1.467 sec)
28.565... logprob:  0.611143, 0.187500 (1.451 sec)
28.566... logprob:  0.374872, 0.093750 (1.457 sec)
28.567... logprob:  0.423316, 0.109375 (1.455 sec)
28.568... logprob:  0.496331, 0.140625 (1.455 sec)
28.569... logprob:  0.507702, 0.140625 (1.443 sec)
28.570... logprob:  0.543782, 0.164062 (1.428 sec)
28.571... logprob:  0.454884, 0.125000 (1.433 sec)
28.572... logprob:  0.501376, 0.140625 (1.448 sec)
28.573... logprob:  0.512598, 0.148438 (1.445 sec)
28.574... logprob:  0.428040, 0.109375 (1.465 sec)
28.575... logprob:  0.343329, 0.078125 (1.454 sec)
28.576... logprob:  0.427359, 0.109375 (1.446 sec)
28.577... logprob:  0.460792, 0.125000 (1.483 sec)
28.578... logprob:  0.336755, 0.078125 (1.442 sec)
28.579... logprob:  0.442079, 0.117188 (1.426 sec)
28.580... logprob:  0.546670, 0.156250 (1.435 sec)
28.581... logprob:  0.530672, 0.156250 (1.444 sec)
28.582... logprob:  0.437809, 0.125000 (1.440 sec)
28.583... logprob:  0.592473, 0.171875 (1.480 sec)
28.584... logprob:  0.468075, 0.132812 (1.443 sec)
28.585... logprob:  0.349765, 0.085938 (1.439 sec)
28.586... logprob:  0.313072, 0.070312 (1.487 sec)
28.587... logprob:  0.404298, 0.101562 (1.436 sec)
28.588... logprob:  0.418656, 0.117188 (1.429 sec)
28.589... logprob:  0.361171, 0.093750 (1.438 sec)
28.590... logprob:  0.524766, 0.148438 (1.431 sec)
28.591... logprob:  0.397464, 0.101562 (1.441 sec)
28.592... logprob:  0.455673, 0.125000 (1.489 sec)
28.593... logprob:  0.467419, 0.125000 (1.438 sec)
28.594... logprob:  0.352833, 0.085938 (1.445 sec)
28.595... logprob:  0.428660, 0.109375 (1.483 sec)
28.596... logprob:  0.461610, 0.125000 (1.433 sec)
28.597... logprob:  0.397416, 0.101562 (1.440 sec)
28.598... logprob:  0.397219, 0.101562 (1.441 sec)
28.599... logprob:  0.313570, 0.070312 (1.428 sec)
28.600... logprob:  0.340883, 0.085938 (1.441 sec)
28.601... logprob:  0.402149, 0.101562 (1.496 sec)
28.602... logprob:  0.289862, 0.062500 (1.441 sec)
28.603... logprob:  0.267165, 0.054688 (1.450 sec)
28.604... logprob:  0.407523, 0.101562 (1.475 sec)
28.605... logprob:  0.563320, 0.148438 (1.436 sec)
28.606... logprob:  0.295944, 0.070312 (1.440 sec)
28.607... logprob:  0.504717, 0.132812 (1.433 sec)
28.608... logprob:  0.361844, 0.085938 (1.431 sec)
28.609... logprob:  0.357028, 0.085938 (1.435 sec)
28.610... logprob:  0.493308, 0.132812 (1.470 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.0997314453125, 10.0]}, 128)
batch 872: ({'logprob': [68.12879943847656, 19.0]}, 128)
batch 873: ({'logprob': [39.53715133666992, 9.0]}, 128)
batch 874: ({'logprob': [44.754981994628906, 11.0]}, 128)
batch 875: ({'logprob': [50.78839874267578, 13.0]}, 128)
batch 876: ({'logprob': [65.34262084960938, 18.0]}, 128)
batch 877: ({'logprob': [45.173065185546875, 11.0]}, 128)
batch 878: ({'logprob': [62.91658401489258, 17.0]}, 128)
batch 879: ({'logprob': [75.41073608398438, 21.0]}, 128)
batch 880: ({'logprob': [50.81497573852539, 13.0]}, 128)
batch 881: ({'logprob': [27.003360748291016, 5.0]}, 128)
batch 882: ({'logprob': [54.869232177734375, 14.0]}, 128)
batch 883: ({'logprob': [62.88908767700195, 17.0]}, 128)
batch 884: ({'logprob': [51.214393615722656, 13.0]}, 128)
batch 885: ({'logprob': [52.03678512573242, 13.0]}, 128)
batch 886: ({'logprob': [63.32550048828125, 17.0]}, 128)

======================Test output======================
logprob:  0.417630, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960781e-03 [4.113926e-09] 
Layer 'conv1' biases: 3.508574e-07 [1.607080e-10] 
Layer 'conv2' weights[0]: 7.947899e-03 [3.817522e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.814032e-10] 
Layer 'conv3' weights[0]: 7.946085e-03 [3.583449e-09] 
Layer 'conv3' biases: 2.973512e-06 [2.287545e-09] 
Layer 'conv4' weights[0]: 7.978773e-03 [3.755756e-09] 
Layer 'conv4' biases: 9.999993e-01 [1.998514e-08] 
Layer 'conv5' weights[0]: 7.977549e-03 [1.290634e-07] 
Layer 'conv5' biases: 9.999917e-01 [1.385322e-07] 
Layer 'fc6' weights[0]: 7.574148e-03 [1.067885e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.090488e-08] 
Layer 'fc7' weights[0]: 6.950106e-03 [2.434236e-07] 
Layer 'fc7' biases: 9.998580e-01 [2.338646e-07] 
Layer 'fc8' weights[0]: 1.331133e-03 [1.359988e-05] 
Layer 'fc8' biases: 7.016385e-02 [8.505935e-05] 
Train error last 870 batches: 0.435194
-------------------------------------------------------
Not saving because 0.417630 > 0.415650 (27.630: -0.00%)
======================================================= (12.028 sec)
28.611... logprob:  0.510350, 0.140625 (1.453 sec)
28.612... logprob:  0.448514, 0.117188 (1.458 sec)
28.613... logprob:  0.279404, 0.062500 (1.468 sec)
28.614... logprob:  0.503564, 0.140625 (1.449 sec)
28.615... logprob:  0.350857, 0.085938 (1.447 sec)
28.616... logprob:  0.415095, 0.109375 (1.433 sec)
28.617... logprob:  0.417847, 0.109375 (1.427 sec)
28.618... logprob:  0.546983, 0.156250 (1.443 sec)
28.619... logprob:  0.506092, 0.140625 (1.450 sec)
28.620... logprob:  0.539691, 0.156250 (1.464 sec)
28.621... logprob:  0.363622, 0.085938 (1.452 sec)
28.622... logprob:  0.364708, 0.085938 (1.452 sec)
28.623... logprob:  0.423137, 0.109375 (1.468 sec)
28.624... logprob:  0.382515, 0.093750 (1.441 sec)
28.625... logprob:  0.440983, 0.117188 (1.427 sec)
28.626... logprob:  0.438352, 0.117188 (1.441 sec)
28.627... logprob:  0.435827, 0.117188 (1.438 sec)
28.628... logprob:  0.465028, 0.125000 (1.440 sec)
28.629... logprob:  0.372127, 0.093750 (1.474 sec)
28.630... logprob:  0.422382, 0.109375 (1.452 sec)
28.631... logprob:  0.638526, 0.187500 (1.441 sec)
28.632... logprob:  0.399117, 0.101562 (1.491 sec)
28.633... logprob:  0.376102, 0.093750 (1.438 sec)
28.634... logprob:  0.660120, 0.195312 (1.435 sec)
28.635... logprob:  0.374120, 0.093750 (1.441 sec)
28.636... logprob:  0.480258, 0.132812 (1.440 sec)
28.637... logprob:  0.330765, 0.078125 (1.430 sec)
28.638... logprob:  0.515704, 0.140625 (1.601 sec)
28.639... logprob:  0.418044, 0.109375 (1.444 sec)
28.640... logprob:  0.528756, 0.148438 (1.437 sec)
28.641... logprob:  0.410417, 0.109375 (1.485 sec)
28.642... logprob:  0.500893, 0.140625 (1.432 sec)
28.643... logprob:  0.623220, 0.187500 (1.438 sec)
28.644... logprob:  0.320998, 0.070312 (1.435 sec)
28.645... logprob:  0.414458, 0.109375 (1.433 sec)
28.646... logprob:  0.385595, 0.093750 (1.432 sec)
28.647... logprob:  0.456787, 0.125000 (1.488 sec)
28.648... logprob:  0.491265, 0.140625 (1.438 sec)
28.649... logprob:  0.370288, 0.093750 (1.446 sec)
28.650... logprob:  0.414020, 0.109375 (1.480 sec)
28.651... logprob:  0.397396, 0.101562 (1.437 sec)
28.652... logprob:  0.507117, 0.140625 (1.445 sec)
28.653... logprob:  0.547763, 0.156250 (1.433 sec)
28.654... logprob:  0.496019, 0.140625 (1.432 sec)
28.655... logprob:  0.436180, 0.117188 (1.429 sec)
28.656... logprob:  0.416709, 0.109375 (1.492 sec)
28.657... logprob:  0.449074, 0.117188 (1.443 sec)
28.658... logprob:  0.345869, 0.085938 (1.452 sec)
28.659... logprob:  0.464290, 0.125000 (1.471 sec)
28.660... logprob:  0.446025, 0.125000 (1.442 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.718963623046875, 10.0]}, 128)
batch 872: ({'logprob': [66.21430206298828, 19.0]}, 128)
batch 873: ({'logprob': [41.076114654541016, 9.0]}, 128)
batch 874: ({'logprob': [45.37970733642578, 11.0]}, 128)
batch 875: ({'logprob': [50.874168395996094, 13.0]}, 128)
batch 876: ({'logprob': [63.789756774902344, 18.0]}, 128)
batch 877: ({'logprob': [45.98596954345703, 11.0]}, 128)
batch 878: ({'logprob': [61.91608810424805, 17.0]}, 128)
batch 879: ({'logprob': [73.50956726074219, 21.0]}, 128)
batch 880: ({'logprob': [50.89887237548828, 13.0]}, 128)
batch 881: ({'logprob': [29.44457244873047, 5.0]}, 128)
batch 882: ({'logprob': [55.14382553100586, 14.0]}, 128)
batch 883: ({'logprob': [61.88966369628906, 17.0]}, 128)
batch 884: ({'logprob': [51.480037689208984, 13.0]}, 128)
batch 885: ({'logprob': [52.673946380615234, 13.0]}, 128)
batch 886: ({'logprob': [62.50808334350586, 17.0]}, 128)

======================Test output======================
logprob:  0.417238, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960750e-03 [2.423225e-09] 
Layer 'conv1' biases: 3.518191e-07 [3.402958e-11] 
Layer 'conv2' weights[0]: 7.947863e-03 [1.488134e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.415516e-10] 
Layer 'conv3' weights[0]: 7.946045e-03 [1.100486e-09] 
Layer 'conv3' biases: 2.982324e-06 [3.777129e-10] 
Layer 'conv4' weights[0]: 7.978736e-03 [1.072593e-09] 
Layer 'conv4' biases: 9.999992e-01 [2.108154e-09] 
Layer 'conv5' weights[0]: 7.977503e-03 [9.278411e-09] 
Layer 'conv5' biases: 9.999916e-01 [9.511907e-09] 
Layer 'fc6' weights[0]: 7.574106e-03 [1.025083e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.561681e-10] 
Layer 'fc7' weights[0]: 6.948325e-03 [4.387946e-08] 
Layer 'fc7' biases: 9.998567e-01 [2.174833e-08] 
Layer 'fc8' weights[0]: 1.281003e-03 [4.579661e-06] 
Layer 'fc8' biases: 6.993180e-02 [3.060493e-05] 
Train error last 870 batches: 0.435193
-------------------------------------------------------
Not saving because 0.417238 > 0.415650 (27.630: -0.00%)
======================================================= (12.156 sec)
28.661... logprob:  0.378424, 0.093750 (1.451 sec)
28.662... logprob:  0.469447, 0.132812 (1.434 sec)
28.663... logprob:  0.310880, 0.070312 (1.422 sec)
28.664... logprob:  0.285369, 0.062500 (1.443 sec)
28.665... logprob:  0.401701, 0.101562 (1.545 sec)
28.666... logprob:  0.442029, 0.117188 (1.457 sec)
28.667... logprob:  0.564218, 0.164062 (1.451 sec)
28.668... logprob:  0.497850, 0.140625 (1.456 sec)
28.669... logprob:  0.432938, 0.109375 (1.466 sec)
28.670... logprob:  0.362371, 0.085938 (1.435 sec)
28.671... logprob:  0.360870, 0.093750 (1.429 sec)
28.672... logprob:  0.441825, 0.117188 (1.433 sec)
28.673... logprob:  0.436227, 0.117188 (1.438 sec)
28.674... logprob:  0.446634, 0.117188 (1.444 sec)
28.675... logprob:  0.356681, 0.093750 (1.465 sec)
28.676... logprob:  0.450182, 0.125000 (1.457 sec)
28.677... logprob:  0.471022, 0.125000 (1.439 sec)
28.678... logprob:  0.465659, 0.125000 (1.482 sec)
28.679... logprob:  0.454863, 0.125000 (1.435 sec)
28.680... logprob:  0.351665, 0.078125 (1.440 sec)
28.681... logprob:  0.373869, 0.093750 (1.431 sec)
28.682... logprob:  0.340466, 0.078125 (1.437 sec)
28.683... logprob:  0.411632, 0.109375 (1.435 sec)
28.684... logprob:  0.357689, 0.085938 (1.480 sec)
28.685... logprob:  0.286165, 0.054688 (1.448 sec)
28.686... logprob:  0.318777, 0.070312 (1.433 sec)
28.687... logprob:  0.281764, 0.062500 (1.491 sec)
28.688... logprob:  0.323138, 0.078125 (1.432 sec)
28.689... logprob:  0.471012, 0.125000 (1.435 sec)
28.690... logprob:  0.527460, 0.140625 (1.436 sec)
28.691... logprob:  0.516292, 0.140625 (1.432 sec)
28.692... logprob:  0.384842, 0.101562 (1.438 sec)
28.693... logprob:  0.455563, 0.125000 (1.484 sec)
28.694... logprob:  0.330946, 0.078125 (1.439 sec)
28.695... logprob:  0.356943, 0.085938 (1.443 sec)
28.696... logprob:  0.539217, 0.148438 (1.477 sec)
28.697... logprob:  0.465761, 0.125000 (1.435 sec)
28.698... logprob:  0.549002, 0.156250 (1.441 sec)
28.699... logprob:  0.459627, 0.125000 (1.442 sec)
28.700... logprob:  0.433833, 0.117188 (1.433 sec)
28.701... logprob:  0.422967, 0.109375 (1.432 sec)
28.702... logprob:  0.521562, 0.148438 (1.485 sec)
28.703... logprob:  0.405007, 0.101562 (1.456 sec)
28.704... logprob:  0.405959, 0.101562 (1.449 sec)
28.705... logprob:  0.420110, 0.109375 (1.479 sec)
28.706... logprob:  0.468054, 0.125000 (1.435 sec)
28.707... logprob:  0.485298, 0.132812 (1.438 sec)
28.708... logprob:  0.417214, 0.109375 (1.435 sec)
28.709... logprob:  0.422650, 0.109375 (1.431 sec)
28.710... logprob:  0.602115, 0.179688 (1.435 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.43791961669922, 10.0]}, 128)
batch 872: ({'logprob': [66.13312530517578, 19.0]}, 128)
batch 873: ({'logprob': [41.30485534667969, 9.0]}, 128)
batch 874: ({'logprob': [45.748069763183594, 11.0]}, 128)
batch 875: ({'logprob': [51.04624938964844, 13.0]}, 128)
batch 876: ({'logprob': [63.72256851196289, 18.0]}, 128)
batch 877: ({'logprob': [46.18693161010742, 11.0]}, 128)
batch 878: ({'logprob': [61.69540023803711, 17.0]}, 128)
batch 879: ({'logprob': [72.72928619384766, 21.0]}, 128)
batch 880: ({'logprob': [51.071067810058594, 13.0]}, 128)
batch 881: ({'logprob': [30.234453201293945, 5.0]}, 128)
batch 882: ({'logprob': [54.79743957519531, 14.0]}, 128)
batch 883: ({'logprob': [61.66903305053711, 17.0]}, 128)
batch 884: ({'logprob': [51.483116149902344, 13.0]}, 128)
batch 885: ({'logprob': [52.3411979675293, 13.0]}, 128)
batch 886: ({'logprob': [62.118778228759766, 17.0]}, 128)

======================Test output======================
logprob:  0.417344, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960707e-03 [3.641802e-09] 
Layer 'conv1' biases: 3.526159e-07 [5.423324e-11] 
Layer 'conv2' weights[0]: 7.947824e-03 [2.426440e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.451694e-10] 
Layer 'conv3' weights[0]: 7.946003e-03 [2.022868e-09] 
Layer 'conv3' biases: 2.988279e-06 [1.189407e-09] 
Layer 'conv4' weights[0]: 7.978696e-03 [2.102854e-09] 
Layer 'conv4' biases: 9.999992e-01 [9.735601e-09] 
Layer 'conv5' weights[0]: 7.977467e-03 [6.223999e-08] 
Layer 'conv5' biases: 9.999914e-01 [6.692364e-08] 
Layer 'fc6' weights[0]: 7.574067e-03 [5.168227e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.216939e-09] 
Layer 'fc7' weights[0]: 6.946557e-03 [1.102417e-07] 
Layer 'fc7' biases: 9.998559e-01 [9.643654e-08] 
Layer 'fc8' weights[0]: 1.267072e-03 [3.464087e-06] 
Layer 'fc8' biases: 7.003775e-02 [3.008005e-05] 
Train error last 870 batches: 0.435193
-------------------------------------------------------
Not saving because 0.417344 > 0.415650 (27.630: -0.00%)
======================================================= (12.120 sec)
28.711... logprob:  0.469470, 0.125000 (1.478 sec)
28.712... logprob:  0.340916, 0.078125 (1.458 sec)
28.713... logprob:  0.586483, 0.179688 (1.463 sec)
28.714... logprob:  0.466244, 0.125000 (1.463 sec)
28.715... logprob:  0.417195, 0.109375 (1.461 sec)
28.716... logprob:  0.335483, 0.078125 (1.439 sec)
28.717... logprob:  0.429779, 0.117188 (1.427 sec)
28.718... logprob:  0.490307, 0.132812 (1.427 sec)
28.719... logprob:  0.406180, 0.109375 (1.441 sec)
28.720... logprob:  0.433225, 0.117188 (1.451 sec)
28.721... logprob:  0.451603, 0.117188 (1.484 sec)
28.722... logprob:  0.537013, 0.156250 (1.459 sec)
28.723... logprob:  0.416548, 0.109375 (1.444 sec)
28.724... logprob:  0.412760, 0.109375 (1.478 sec)
28.725... logprob:  0.494851, 0.140625 (1.431 sec)
28.726... logprob:  0.338424, 0.085938 (1.431 sec)
28.727... logprob:  0.393205, 0.101562 (1.432 sec)
28.728... logprob:  0.421216, 0.109375 (1.444 sec)
28.729... logprob:  0.387581, 0.093750 (1.432 sec)
28.730... logprob:  0.565930, 0.164062 (1.478 sec)
28.731... logprob:  0.450408, 0.125000 (1.450 sec)
28.732... logprob:  0.311392, 0.070312 (1.433 sec)
28.733... logprob:  0.556503, 0.156250 (1.490 sec)
28.734... logprob:  0.340253, 0.078125 (1.432 sec)
28.735... logprob:  0.527432, 0.148438 (1.434 sec)
28.736... logprob:  0.642590, 0.187500 (1.439 sec)
28.737... logprob:  0.516100, 0.148438 (1.431 sec)
28.738... logprob:  0.459387, 0.125000 (1.432 sec)
28.739... logprob:  0.477789, 0.132812 (1.489 sec)
28.740... logprob:  0.339645, 0.078125 (1.435 sec)
28.741... logprob:  0.393472, 0.101562 (1.444 sec)
28.742... logprob:  0.419689, 0.109375 (1.481 sec)
28.743... logprob:  0.364890, 0.085938 (1.439 sec)
28.744... logprob:  0.519146, 0.148438 (1.431 sec)
28.745... logprob:  0.478134, 0.132812 (1.440 sec)
28.746... logprob:  0.440545, 0.117188 (1.426 sec)
28.747... logprob:  0.425603, 0.109375 (1.435 sec)
28.748... logprob:  0.378138, 0.093750 (1.491 sec)
28.749... logprob:  0.420807, 0.109375 (1.432 sec)
28.750... logprob:  0.512778, 0.140625 (1.446 sec)
28.751... logprob:  0.263698, 0.054688 (1.484 sec)
28.752... logprob:  0.522505, 0.140625 (1.430 sec)
28.753... logprob:  0.441158, 0.117188 (1.445 sec)
28.754... logprob:  0.468309, 0.132812 (1.430 sec)
28.755... logprob:  0.507049, 0.140625 (1.428 sec)
28.756... logprob:  0.440834, 0.117188 (1.440 sec)
28.757... logprob:  0.552458, 0.156250 (1.471 sec)
28.758... logprob:  0.393568, 0.101562 (1.447 sec)
28.759... logprob:  0.459698, 0.125000 (1.458 sec)
28.760... logprob:  0.485549, 0.132812 (1.458 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.5721549987793, 10.0]}, 128)
batch 872: ({'logprob': [66.11018371582031, 19.0]}, 128)
batch 873: ({'logprob': [41.401798248291016, 9.0]}, 128)
batch 874: ({'logprob': [45.840091705322266, 11.0]}, 128)
batch 875: ({'logprob': [51.1016731262207, 13.0]}, 128)
batch 876: ({'logprob': [63.71013641357422, 18.0]}, 128)
batch 877: ({'logprob': [46.263309478759766, 11.0]}, 128)
batch 878: ({'logprob': [61.6776008605957, 17.0]}, 128)
batch 879: ({'logprob': [72.622314453125, 21.0]}, 128)
batch 880: ({'logprob': [51.12662124633789, 13.0]}, 128)
batch 881: ({'logprob': [30.420717239379883, 5.0]}, 128)
batch 882: ({'logprob': [54.7947883605957, 14.0]}, 128)
batch 883: ({'logprob': [61.65108871459961, 17.0]}, 128)
batch 884: ({'logprob': [51.52250289916992, 13.0]}, 128)
batch 885: ({'logprob': [52.34880828857422, 13.0]}, 128)
batch 886: ({'logprob': [62.08500671386719, 17.0]}, 128)

======================Test output======================
logprob:  0.417602, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960666e-03 [2.816547e-09] 
Layer 'conv1' biases: 3.537020e-07 [4.807422e-11] 
Layer 'conv2' weights[0]: 7.947792e-03 [2.001392e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.584246e-10] 
Layer 'conv3' weights[0]: 7.945966e-03 [1.669820e-09] 
Layer 'conv3' biases: 2.999446e-06 [8.359882e-10] 
Layer 'conv4' weights[0]: 7.978660e-03 [1.672445e-09] 
Layer 'conv4' biases: 9.999992e-01 [6.738232e-09] 
Layer 'conv5' weights[0]: 7.977424e-03 [4.369418e-08] 
Layer 'conv5' biases: 9.999919e-01 [4.698219e-08] 
Layer 'fc6' weights[0]: 7.574034e-03 [3.667933e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.659593e-09] 
Layer 'fc7' weights[0]: 6.944789e-03 [2.268906e-07] 
Layer 'fc7' biases: 9.998558e-01 [2.170794e-07] 
Layer 'fc8' weights[0]: 1.264991e-03 [7.739212e-06] 
Layer 'fc8' biases: 7.014219e-02 [5.035882e-05] 
Train error last 870 batches: 0.435193
-------------------------------------------------------
Not saving because 0.417602 > 0.415650 (27.630: -0.00%)
======================================================= (12.051 sec)
28.761... logprob:  0.418169, 0.109375 (1.452 sec)
28.762... logprob:  0.516061, 0.148438 (1.450 sec)
28.763... logprob:  0.558983, 0.164062 (1.427 sec)
28.764... logprob:  0.503267, 0.140625 (1.427 sec)
28.765... logprob:  0.311736, 0.062500 (1.441 sec)
28.766... logprob:  0.482211, 0.132812 (1.454 sec)
28.767... logprob:  0.371081, 0.085938 (1.460 sec)
28.768... logprob:  0.432652, 0.117188 (1.465 sec)
28.769... logprob:  0.490800, 0.140625 (1.470 sec)
28.770... logprob:  0.402979, 0.101562 (1.483 sec)
28.771... logprob:  0.549394, 0.156250 (1.460 sec)
28.772... logprob:  0.414101, 0.109375 (1.448 sec)
28.773... logprob:  0.557677, 0.164062 (1.445 sec)
28.774... logprob:  0.361786, 0.085938 (1.462 sec)
28.775... logprob:  0.407394, 0.101562 (1.466 sec)
28.776... logprob:  0.433154, 0.117188 (1.560 sec)
28.777... logprob:  0.379979, 0.093750 (1.477 sec)
28.778... logprob:  0.433544, 0.117188 (1.464 sec)
28.779... logprob:  0.505328, 0.140625 (1.488 sec)
28.780... logprob:  0.385763, 0.101562 (1.461 sec)
28.781... logprob:  0.369633, 0.085938 (1.445 sec)
28.782... logprob:  0.351410, 0.085938 (1.448 sec)
28.783... logprob:  0.555530, 0.156250 (1.462 sec)
28.784... logprob:  0.440958, 0.117188 (1.458 sec)
28.785... logprob:  0.543719, 0.156250 (1.495 sec)
28.786... logprob:  0.477555, 0.132812 (1.476 sec)
28.787... logprob:  0.546502, 0.156250 (1.458 sec)
28.788... logprob:  0.563273, 0.164062 (1.497 sec)
28.789... logprob:  0.280674, 0.054688 (1.457 sec)
28.790... logprob:  0.407927, 0.101562 (1.447 sec)
28.791... logprob:  0.397861, 0.101562 (1.452 sec)
28.792... logprob:  0.360920, 0.085938 (1.461 sec)
28.793... logprob:  0.370072, 0.085938 (1.454 sec)
28.794... logprob:  0.387124, 0.093750 (1.491 sec)
28.795... logprob:  0.469724, 0.125000 (1.504 sec)
28.796... logprob:  0.423511, 0.109375 (1.463 sec)
28.797... logprob:  0.358886, 0.085938 (1.502 sec)
28.798... logprob:  0.393297, 0.101562 (1.447 sec)
28.799... logprob:  0.332466, 0.078125 (1.450 sec)
28.800... logprob:  0.371696, 0.093750 (1.451 sec)
28.801... logprob:  0.449960, 0.117188 (1.457 sec)
28.802... logprob:  0.422882, 0.109375 (1.459 sec)
28.803... logprob:  0.491462, 0.132812 (1.491 sec)
28.804... logprob:  0.349949, 0.085938 (1.469 sec)
28.805... logprob:  0.452272, 0.117188 (1.451 sec)
28.806... logprob:  0.424175, 0.109375 (1.506 sec)
28.807... logprob:  0.443477, 0.117188 (1.455 sec)
28.808... logprob:  0.462366, 0.125000 (1.446 sec)
28.809... logprob:  0.589788, 0.171875 (1.455 sec)
28.810... logprob:  0.442489, 0.117188 (1.456 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.477745056152344, 10.0]}, 128)
batch 872: ({'logprob': [66.65971374511719, 19.0]}, 128)
batch 873: ({'logprob': [40.687599182128906, 9.0]}, 128)
batch 874: ({'logprob': [45.57003402709961, 11.0]}, 128)
batch 875: ({'logprob': [50.95565414428711, 13.0]}, 128)
batch 876: ({'logprob': [64.1181411743164, 18.0]}, 128)
batch 877: ({'logprob': [45.83316421508789, 11.0]}, 128)
batch 878: ({'logprob': [61.78291702270508, 17.0]}, 128)
batch 879: ({'logprob': [72.82048797607422, 21.0]}, 128)
batch 880: ({'logprob': [50.98136901855469, 13.0]}, 128)
batch 881: ({'logprob': [29.6137638092041, 5.0]}, 128)
batch 882: ({'logprob': [54.314876556396484, 14.0]}, 128)
batch 883: ({'logprob': [61.75621032714844, 17.0]}, 128)
batch 884: ({'logprob': [51.21913146972656, 13.0]}, 128)
batch 885: ({'logprob': [51.726890563964844, 13.0]}, 128)
batch 886: ({'logprob': [62.03199005126953, 17.0]}, 128)

======================Test output======================
logprob:  0.416284, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960630e-03 [4.580278e-09] 
Layer 'conv1' biases: 3.548398e-07 [1.523163e-10] 
Layer 'conv2' weights[0]: 7.947753e-03 [4.234182e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.884832e-10] 
Layer 'conv3' weights[0]: 7.945932e-03 [3.966902e-09] 
Layer 'conv3' biases: 3.009656e-06 [2.368238e-09] 
Layer 'conv4' weights[0]: 7.978622e-03 [3.887261e-09] 
Layer 'conv4' biases: 9.999992e-01 [1.888222e-08] 
Layer 'conv5' weights[0]: 7.977389e-03 [1.185505e-07] 
Layer 'conv5' biases: 9.999920e-01 [1.276419e-07] 
Layer 'fc6' weights[0]: 7.573994e-03 [9.834720e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.968168e-09] 
Layer 'fc7' weights[0]: 6.943016e-03 [4.133514e-07] 
Layer 'fc7' biases: 9.998560e-01 [4.030180e-07] 
Layer 'fc8' weights[0]: 1.277006e-03 [1.510915e-05] 
Layer 'fc8' biases: 7.041760e-02 [9.678934e-05] 
Train error last 870 batches: 0.435192
-------------------------------------------------------
Not saving because 0.416284 > 0.415650 (27.630: -0.00%)
======================================================= (12.030 sec)
28.811... logprob:  0.460421, 0.125000 (1.460 sec)
28.812... logprob:  0.462336, 0.125000 (1.506 sec)
28.813... logprob:  0.485952, 0.132812 (1.456 sec)
28.814... logprob:  0.477931, 0.132812 (1.460 sec)
28.815... logprob:  0.371521, 0.085938 (1.501 sec)
28.816... logprob:  0.408517, 0.101562 (1.457 sec)
28.817... logprob:  0.425840, 0.109375 (1.455 sec)
28.818... logprob:  0.560009, 0.164062 (1.448 sec)
28.819... logprob:  0.498184, 0.140625 (1.457 sec)
28.820... logprob:  0.421670, 0.109375 (1.453 sec)
28.821... logprob:  0.406677, 0.101562 (1.498 sec)
28.822... logprob:  0.441257, 0.117188 (1.462 sec)
28.823... logprob:  0.341073, 0.078125 (1.454 sec)
28.824... logprob:  0.489678, 0.132812 (1.505 sec)
28.825... logprob:  0.288324, 0.062500 (1.455 sec)
28.826... logprob:  0.375569, 0.093750 (1.460 sec)
28.827... logprob:  0.420465, 0.109375 (1.456 sec)
28.828... logprob:  0.443197, 0.117188 (1.452 sec)
28.829... logprob:  0.503870, 0.140625 (1.454 sec)
28.830... logprob:  0.442071, 0.117188 (1.502 sec)
28.831... logprob:  0.513857, 0.140625 (1.458 sec)
28.832... logprob:  0.330842, 0.078125 (1.458 sec)
28.833... logprob:  0.489047, 0.132812 (1.498 sec)
28.834... logprob:  0.433369, 0.117188 (1.458 sec)
28.835... logprob:  0.542883, 0.148438 (1.455 sec)
28.836... logprob:  0.376100, 0.093750 (1.450 sec)
28.837... logprob:  0.314063, 0.070312 (1.452 sec)
28.838... logprob:  0.437068, 0.117188 (1.455 sec)
28.839... logprob:  0.471650, 0.125000 (1.502 sec)
28.840... logprob:  0.555541, 0.156250 (1.459 sec)
28.841... logprob:  0.396012, 0.101562 (1.462 sec)
28.842... logprob:  0.497886, 0.140625 (1.497 sec)
28.843... logprob:  0.465497, 0.125000 (1.455 sec)
28.844... logprob:  0.497668, 0.140625 (1.457 sec)
28.845... logprob:  0.486740, 0.132812 (1.454 sec)
28.846... logprob:  0.468397, 0.125000 (1.447 sec)
28.847... logprob:  0.363406, 0.085938 (1.458 sec)
28.848... logprob:  0.397229, 0.101562 (1.501 sec)
28.849... logprob:  0.360592, 0.085938 (1.460 sec)
28.850... logprob:  0.479373, 0.132812 (1.473 sec)
28.851... logprob:  0.440139, 0.117188 (1.488 sec)
28.852... logprob:  0.545362, 0.156250 (1.459 sec)
28.853... logprob:  0.372004, 0.093750 (1.464 sec)
28.854... logprob:  0.307394, 0.070312 (1.447 sec)
28.855... logprob:  0.484705, 0.132812 (1.446 sec)
28.856... logprob:  0.443705, 0.117188 (1.459 sec)
28.857... logprob:  0.372230, 0.093750 (1.492 sec)
28.858... logprob:  0.396245, 0.101562 (1.465 sec)
28.859... logprob:  0.307993, 0.070312 (1.472 sec)
28.860... logprob:  0.565974, 0.156250 (1.485 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.27533721923828, 10.0]}, 128)
batch 872: ({'logprob': [67.67066955566406, 19.0]}, 128)
batch 873: ({'logprob': [39.70903396606445, 9.0]}, 128)
batch 874: ({'logprob': [44.826515197753906, 11.0]}, 128)
batch 875: ({'logprob': [50.7171745300293, 13.0]}, 128)
batch 876: ({'logprob': [64.94499969482422, 18.0]}, 128)
batch 877: ({'logprob': [45.223697662353516, 11.0]}, 128)
batch 878: ({'logprob': [62.558746337890625, 17.0]}, 128)
batch 879: ({'logprob': [74.74527740478516, 21.0]}, 128)
batch 880: ({'logprob': [50.74361038208008, 13.0]}, 128)
batch 881: ({'logprob': [27.483543395996094, 5.0]}, 128)
batch 882: ({'logprob': [54.67222595214844, 14.0]}, 128)
batch 883: ({'logprob': [62.53145217895508, 17.0]}, 128)
batch 884: ({'logprob': [51.120548248291016, 13.0]}, 128)
batch 885: ({'logprob': [51.90026092529297, 13.0]}, 128)
batch 886: ({'logprob': [62.945858001708984, 17.0]}, 128)

======================Test output======================
logprob:  0.416538, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960597e-03 [4.743825e-09] 
Layer 'conv1' biases: 3.558450e-07 [1.260293e-10] 
Layer 'conv2' weights[0]: 7.947717e-03 [3.417622e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.743376e-10] 
Layer 'conv3' weights[0]: 7.945895e-03 [3.162029e-09] 
Layer 'conv3' biases: 3.015317e-06 [2.043436e-09] 
Layer 'conv4' weights[0]: 7.978580e-03 [3.198774e-09] 
Layer 'conv4' biases: 9.999992e-01 [1.744670e-08] 
Layer 'conv5' weights[0]: 7.977345e-03 [1.134270e-07] 
Layer 'conv5' biases: 9.999912e-01 [1.218945e-07] 
Layer 'fc6' weights[0]: 7.573962e-03 [9.435486e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.541509e-09] 
Layer 'fc7' weights[0]: 6.941217e-03 [4.076241e-08] 
Layer 'fc7' biases: 9.998574e-01 [1.845447e-08] 
Layer 'fc8' weights[0]: 1.314419e-03 [7.214070e-07] 
Layer 'fc8' biases: 7.092358e-02 [2.461737e-06] 
Train error last 870 batches: 0.435192
-------------------------------------------------------
Not saving because 0.416538 > 0.415650 (27.630: -0.00%)
======================================================= (12.109 sec)
28.861... logprob:  0.417799, 0.109375 (1.465 sec)
28.862... logprob:  0.328834, 0.078125 (1.468 sec)
28.863... logprob:  0.399576, 0.101562 (1.452 sec)
28.864... logprob:  0.451495, 0.117188 (1.449 sec)
28.865... logprob:  0.484617, 0.132812 (1.459 sec)
28.866... logprob:  0.507798, 0.140625 (1.488 sec)
28.867... logprob:  0.503164, 0.140625 (1.467 sec)
28.868... logprob:  0.405212, 0.101562 (1.473 sec)
28.869... logprob:  0.383071, 0.093750 (1.482 sec)
28.870... logprob:  0.552242, 0.156250 (1.406 sec)
29.1... logprob:  0.379907, 0.093750 (1.407 sec)
29.2... logprob:  0.448245, 0.117188 (1.451 sec)
29.3... logprob:  0.398254, 0.101562 (1.423 sec)
29.4... logprob:  0.443292, 0.117188 (1.405 sec)
29.5... logprob:  0.443482, 0.117188 (1.438 sec)
29.6... logprob:  0.499054, 0.140625 (1.395 sec)
29.7... logprob:  0.363304, 0.085938 (1.416 sec)
29.8... logprob:  0.419169, 0.109375 (1.400 sec)
29.9... logprob:  0.358932, 0.085938 (1.408 sec)
29.10... logprob:  0.377611, 0.093750 (1.416 sec)
29.11... logprob:  0.334934, 0.078125 (1.450 sec)
29.12... logprob:  0.466261, 0.125000 (1.392 sec)
29.13... logprob:  0.442149, 0.117188 (1.427 sec)
29.14... logprob:  0.444515, 0.117188 (1.406 sec)
29.15... logprob:  0.395495, 0.101562 (1.410 sec)
29.16... logprob:  0.421350, 0.109375 (1.407 sec)
29.17... logprob:  0.515930, 0.140625 (1.391 sec)
29.18... logprob:  0.262118, 0.054688 (1.407 sec)
29.19... logprob:  0.279474, 0.062500 (1.405 sec)
29.20... logprob:  0.421362, 0.109375 (1.410 sec)
29.21... logprob:  0.443994, 0.117188 (1.407 sec)
29.22... logprob:  0.536798, 0.148438 (1.415 sec)
29.23... logprob:  0.533177, 0.148438 (1.417 sec)
29.24... logprob:  0.310457, 0.070312 (1.421 sec)
29.25... logprob:  0.356108, 0.085938 (1.407 sec)
29.26... logprob:  0.463818, 0.125000 (1.446 sec)
29.27... logprob:  0.404495, 0.101562 (1.394 sec)
29.28... logprob:  0.421844, 0.109375 (1.411 sec)
29.29... logprob:  0.395909, 0.101562 (1.427 sec)
29.30... logprob:  0.374042, 0.093750 (1.423 sec)
29.31... logprob:  0.479976, 0.132812 (1.406 sec)
29.32... logprob:  0.457222, 0.125000 (1.403 sec)
29.33... logprob:  0.460678, 0.125000 (1.451 sec)
29.34... logprob:  0.464519, 0.125000 (1.394 sec)
29.35... logprob:  0.316330, 0.070312 (1.399 sec)
29.36... logprob:  0.475792, 0.132812 (1.402 sec)
29.37... logprob:  0.417592, 0.109375 (1.410 sec)
29.38... logprob:  0.392695, 0.101562 (1.403 sec)
29.39... logprob:  0.631411, 0.187500 (1.435 sec)
29.40... logprob:  0.445672, 0.117188 (1.411 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.29022979736328, 10.0]}, 128)
batch 872: ({'logprob': [66.38091278076172, 19.0]}, 128)
batch 873: ({'logprob': [40.90680694580078, 9.0]}, 128)
batch 874: ({'logprob': [45.55141067504883, 11.0]}, 128)
batch 875: ({'logprob': [50.930057525634766, 13.0]}, 128)
batch 876: ({'logprob': [63.90034103393555, 18.0]}, 128)
batch 877: ({'logprob': [45.929901123046875, 11.0]}, 128)
batch 878: ({'logprob': [61.74217987060547, 17.0]}, 128)
batch 879: ({'logprob': [72.8790512084961, 21.0]}, 128)
batch 880: ({'logprob': [50.95555114746094, 13.0]}, 128)
batch 881: ({'logprob': [29.733245849609375, 5.0]}, 128)
batch 882: ({'logprob': [54.57295608520508, 14.0]}, 128)
batch 883: ({'logprob': [61.71538543701172, 17.0]}, 128)
batch 884: ({'logprob': [51.30814743041992, 13.0]}, 128)
batch 885: ({'logprob': [52.04646301269531, 13.0]}, 128)
batch 886: ({'logprob': [62.10629653930664, 17.0]}, 128)

======================Test output======================
logprob:  0.416479, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960574e-03 [4.883832e-09] 
Layer 'conv1' biases: 3.569066e-07 [1.177447e-10] 
Layer 'conv2' weights[0]: 7.947683e-03 [2.935093e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.807117e-10] 
Layer 'conv3' weights[0]: 7.945850e-03 [2.412033e-09] 
Layer 'conv3' biases: 3.025531e-06 [1.422516e-09] 
Layer 'conv4' weights[0]: 7.978544e-03 [2.373618e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.042764e-08] 
Layer 'conv5' weights[0]: 7.977311e-03 [6.740912e-08] 
Layer 'conv5' biases: 9.999917e-01 [7.237833e-08] 
Layer 'fc6' weights[0]: 7.573920e-03 [5.562314e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.647567e-09] 
Layer 'fc7' weights[0]: 6.939519e-03 [1.078809e-07] 
Layer 'fc7' biases: 9.998561e-01 [9.476607e-08] 
Layer 'fc8' weights[0]: 1.268145e-03 [6.675386e-06] 
Layer 'fc8' biases: 7.072947e-02 [4.490637e-05] 
Train error last 870 batches: 0.435192
-------------------------------------------------------
Not saving because 0.416479 > 0.415650 (27.630: -0.00%)
======================================================= (12.048 sec)
29.41... logprob:  0.352994, 0.085938 (1.431 sec)
29.42... logprob:  0.392017, 0.101562 (1.429 sec)
29.43... logprob:  0.440075, 0.117188 (1.414 sec)
29.44... logprob:  0.518562, 0.148438 (1.445 sec)
29.45... logprob:  0.381721, 0.093750 (1.389 sec)
29.46... logprob:  0.486174, 0.132812 (1.398 sec)
29.47... logprob:  0.331719, 0.078125 (1.401 sec)
29.48... logprob:  0.498939, 0.140625 (1.431 sec)
29.49... logprob:  0.510892, 0.148438 (1.419 sec)
29.50... logprob:  0.393182, 0.101562 (1.433 sec)
29.51... logprob:  0.490274, 0.140625 (1.416 sec)
29.52... logprob:  0.525790, 0.148438 (1.402 sec)
29.53... logprob:  0.294784, 0.062500 (1.447 sec)
29.54... logprob:  0.403407, 0.109375 (1.389 sec)
29.55... logprob:  0.331687, 0.078125 (1.398 sec)
29.56... logprob:  0.421609, 0.109375 (1.404 sec)
29.57... logprob:  0.572341, 0.164062 (1.429 sec)
29.58... logprob:  0.407537, 0.101562 (1.404 sec)
29.59... logprob:  0.333868, 0.078125 (1.470 sec)
29.60... logprob:  0.618718, 0.179688 (1.416 sec)
29.61... logprob:  0.382797, 0.093750 (1.442 sec)
29.62... logprob:  0.474839, 0.132812 (1.462 sec)
29.63... logprob:  0.397288, 0.101562 (1.440 sec)
29.64... logprob:  0.450328, 0.125000 (1.411 sec)
29.65... logprob:  0.373383, 0.093750 (1.418 sec)
29.66... logprob:  0.354042, 0.085938 (1.447 sec)
29.67... logprob:  0.295422, 0.062500 (1.391 sec)
29.68... logprob:  0.396799, 0.101562 (1.398 sec)
29.69... logprob:  0.496662, 0.140625 (1.428 sec)
29.70... logprob:  0.325905, 0.078125 (1.430 sec)
29.71... logprob:  0.381800, 0.101562 (1.464 sec)
29.72... logprob:  0.493691, 0.132812 (1.409 sec)
29.73... logprob:  0.447681, 0.117188 (1.431 sec)
29.74... logprob:  0.442511, 0.117188 (1.416 sec)
29.75... logprob:  0.380656, 0.093750 (1.422 sec)
29.76... logprob:  0.412046, 0.109375 (1.434 sec)
29.77... logprob:  0.396343, 0.101562 (1.432 sec)
29.78... logprob:  0.493053, 0.140625 (1.454 sec)
29.79... logprob:  0.456476, 0.125000 (1.406 sec)
29.80... logprob:  0.508042, 0.132812 (1.420 sec)
29.81... logprob:  0.416724, 0.109375 (1.414 sec)
29.82... logprob:  0.231220, 0.039062 (1.427 sec)
29.83... logprob:  0.493827, 0.140625 (1.405 sec)
29.84... logprob:  0.468152, 0.125000 (1.473 sec)
29.85... logprob:  0.431922, 0.117188 (1.427 sec)
29.86... logprob:  0.416924, 0.109375 (1.418 sec)
29.87... logprob:  0.633307, 0.187500 (1.414 sec)
29.88... logprob:  0.535018, 0.156250 (1.414 sec)
29.89... logprob:  0.410543, 0.109375 (1.437 sec)
29.90... logprob:  0.577482, 0.171875 (1.387 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.09865951538086, 10.0]}, 128)
batch 872: ({'logprob': [65.79853057861328, 19.0]}, 128)
batch 873: ({'logprob': [42.3220100402832, 9.0]}, 128)
batch 874: ({'logprob': [46.40873718261719, 11.0]}, 128)
batch 875: ({'logprob': [51.495201110839844, 13.0]}, 128)
batch 876: ({'logprob': [63.529571533203125, 18.0]}, 128)
batch 877: ({'logprob': [46.920372009277344, 11.0]}, 128)
batch 878: ({'logprob': [61.7173957824707, 17.0]}, 128)
batch 879: ({'logprob': [72.395751953125, 21.0]}, 128)
batch 880: ({'logprob': [51.519344329833984, 13.0]}, 128)
batch 881: ({'logprob': [31.607826232910156, 5.0]}, 128)
batch 882: ({'logprob': [55.3169059753418, 14.0]}, 128)
batch 883: ({'logprob': [61.691375732421875, 17.0]}, 128)
batch 884: ({'logprob': [52.0010986328125, 13.0]}, 128)
batch 885: ({'logprob': [53.002315521240234, 13.0]}, 128)
batch 886: ({'logprob': [62.21126174926758, 17.0]}, 128)

======================Test output======================
logprob:  0.420428, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960536e-03 [4.210126e-09] 
Layer 'conv1' biases: 3.579826e-07 [1.151550e-10] 
Layer 'conv2' weights[0]: 7.947648e-03 [3.292468e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.965147e-10] 
Layer 'conv3' weights[0]: 7.945812e-03 [2.813945e-09] 
Layer 'conv3' biases: 3.034102e-06 [1.827020e-09] 
Layer 'conv4' weights[0]: 7.978503e-03 [2.837494e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.439025e-08] 
Layer 'conv5' weights[0]: 7.977280e-03 [8.987369e-08] 
Layer 'conv5' biases: 9.999918e-01 [9.674116e-08] 
Layer 'fc6' weights[0]: 7.573874e-03 [7.392108e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.517657e-09] 
Layer 'fc7' weights[0]: 6.937748e-03 [2.495709e-07] 
Layer 'fc7' biases: 9.998554e-01 [2.404885e-07] 
Layer 'fc8' weights[0]: 1.241977e-03 [9.287611e-06] 
Layer 'fc8' biases: 7.057278e-02 [6.268619e-05] 
Train error last 870 batches: 0.435192
-------------------------------------------------------
Not saving because 0.420428 > 0.415650 (27.630: -0.00%)
======================================================= (12.022 sec)
29.91... logprob:  0.348419, 0.078125 (1.405 sec)
29.92... logprob:  0.464460, 0.125000 (1.412 sec)
29.93... logprob:  0.492206, 0.140625 (1.404 sec)
29.94... logprob:  0.428785, 0.109375 (1.401 sec)
29.95... logprob:  0.471832, 0.125000 (1.412 sec)
29.96... logprob:  0.576174, 0.171875 (1.423 sec)
29.97... logprob:  0.430790, 0.117188 (1.395 sec)
29.98... logprob:  0.391216, 0.093750 (1.444 sec)
29.99... logprob:  0.474215, 0.132812 (1.440 sec)
29.100... logprob:  0.310634, 0.070312 (1.404 sec)
29.101... logprob:  0.310937, 0.062500 (1.443 sec)
29.102... logprob:  0.545892, 0.156250 (1.394 sec)
29.103... logprob:  0.540895, 0.156250 (1.406 sec)
29.104... logprob:  0.388809, 0.101562 (1.405 sec)
29.105... logprob:  0.619251, 0.179688 (1.405 sec)
29.106... logprob:  0.344468, 0.085938 (1.402 sec)
29.107... logprob:  0.335798, 0.078125 (1.435 sec)
29.108... logprob:  0.586857, 0.171875 (1.404 sec)
29.109... logprob:  0.336123, 0.078125 (1.408 sec)
29.110... logprob:  0.564673, 0.164062 (1.401 sec)
29.111... logprob:  0.404663, 0.101562 (1.394 sec)
29.112... logprob:  0.365981, 0.093750 (1.403 sec)
29.113... logprob:  0.354411, 0.085938 (1.402 sec)
29.114... logprob:  0.440210, 0.117188 (1.439 sec)
29.115... logprob:  0.506788, 0.140625 (1.411 sec)
29.116... logprob:  0.393341, 0.101562 (1.404 sec)
29.117... logprob:  0.440393, 0.117188 (1.446 sec)
29.118... logprob:  0.409086, 0.101562 (1.392 sec)
29.119... logprob:  0.346076, 0.085938 (1.401 sec)
29.120... logprob:  0.547128, 0.156250 (1.407 sec)
29.121... logprob:  0.412594, 0.109375 (1.397 sec)
29.122... logprob:  0.519255, 0.148438 (1.449 sec)
29.123... logprob:  0.463669, 0.125000 (1.529 sec)
29.124... logprob:  0.447688, 0.125000 (1.415 sec)
29.125... logprob:  0.501909, 0.140625 (1.400 sec)
29.126... logprob:  0.475731, 0.125000 (1.396 sec)
29.127... logprob:  0.479496, 0.125000 (1.397 sec)
29.128... logprob:  0.422331, 0.109375 (1.423 sec)
29.129... logprob:  0.574884, 0.164062 (1.423 sec)
29.130... logprob:  0.382700, 0.093750 (1.417 sec)
29.131... logprob:  0.495497, 0.132812 (1.414 sec)
29.132... logprob:  0.506360, 0.140625 (1.437 sec)
29.133... logprob:  0.444691, 0.117188 (1.388 sec)
29.134... logprob:  0.401869, 0.101562 (1.399 sec)
29.135... logprob:  0.460185, 0.125000 (1.412 sec)
29.136... logprob:  0.562370, 0.164062 (1.406 sec)
29.137... logprob:  0.462589, 0.125000 (1.392 sec)
29.138... logprob:  0.319406, 0.070312 (1.443 sec)
29.139... logprob:  0.395737, 0.101562 (1.405 sec)
29.140... logprob:  0.560056, 0.164062 (1.419 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.48312759399414, 10.0]}, 128)
batch 872: ({'logprob': [66.65181732177734, 19.0]}, 128)
batch 873: ({'logprob': [40.697288513183594, 9.0]}, 128)
batch 874: ({'logprob': [45.575401306152344, 11.0]}, 128)
batch 875: ({'logprob': [50.95795440673828, 13.0]}, 128)
batch 876: ({'logprob': [64.11253356933594, 18.0]}, 128)
batch 877: ({'logprob': [45.83945846557617, 11.0]}, 128)
batch 878: ({'logprob': [61.78008270263672, 17.0]}, 128)
batch 879: ({'logprob': [72.81288146972656, 21.0]}, 128)
batch 880: ({'logprob': [50.98408126831055, 13.0]}, 128)
batch 881: ({'logprob': [29.628217697143555, 5.0]}, 128)
batch 882: ({'logprob': [54.318321228027344, 14.0]}, 128)
batch 883: ({'logprob': [61.7528190612793, 17.0]}, 128)
batch 884: ({'logprob': [51.222660064697266, 13.0]}, 128)
batch 885: ({'logprob': [51.732181549072266, 13.0]}, 128)
batch 886: ({'logprob': [62.03003692626953, 17.0]}, 128)

======================Test output======================
logprob:  0.416298, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960502e-03 [3.442556e-09] 
Layer 'conv1' biases: 3.588376e-07 [5.804508e-11] 
Layer 'conv2' weights[0]: 7.947605e-03 [2.207494e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.272920e-10] 
Layer 'conv3' weights[0]: 7.945784e-03 [1.690669e-09] 
Layer 'conv3' biases: 3.039329e-06 [9.300392e-10] 
Layer 'conv4' weights[0]: 7.978461e-03 [1.609266e-09] 
Layer 'conv4' biases: 9.999991e-01 [6.384437e-09] 
Layer 'conv5' weights[0]: 7.977220e-03 [2.972886e-08] 
Layer 'conv5' biases: 9.999915e-01 [3.117095e-08] 
Layer 'fc6' weights[0]: 7.573840e-03 [2.589113e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.505037e-09] 
Layer 'fc7' weights[0]: 6.935989e-03 [1.122137e-07] 
Layer 'fc7' biases: 9.998559e-01 [9.850144e-08] 
Layer 'fc8' weights[0]: 1.272865e-03 [3.869193e-06] 
Layer 'fc8' biases: 7.091667e-02 [2.825096e-05] 
Train error last 870 batches: 0.435192
-------------------------------------------------------
Not saving because 0.416298 > 0.415650 (27.630: -0.00%)
======================================================= (12.053 sec)
29.141... logprob:  0.464582, 0.125000 (1.441 sec)
29.142... logprob:  0.464639, 0.125000 (1.408 sec)
29.143... logprob:  0.294427, 0.062500 (1.423 sec)
29.144... logprob:  0.457040, 0.125000 (1.420 sec)
29.145... logprob:  0.324723, 0.078125 (1.418 sec)
29.146... logprob:  0.483078, 0.132812 (1.410 sec)
29.147... logprob:  0.262486, 0.054688 (1.438 sec)
29.148... logprob:  0.458609, 0.125000 (1.393 sec)
29.149... logprob:  0.442498, 0.117188 (1.403 sec)
29.150... logprob:  0.347574, 0.085938 (1.407 sec)
29.151... logprob:  0.347138, 0.085938 (1.403 sec)
29.152... logprob:  0.785129, 0.234375 (1.385 sec)
29.153... logprob:  0.381641, 0.093750 (1.454 sec)
29.154... logprob:  0.524692, 0.148438 (1.406 sec)
29.155... logprob:  0.426110, 0.117188 (1.408 sec)
29.156... logprob:  0.295218, 0.062500 (1.438 sec)
29.157... logprob:  0.270118, 0.054688 (1.395 sec)
29.158... logprob:  0.455440, 0.125000 (1.407 sec)
29.159... logprob:  0.483125, 0.132812 (1.404 sec)
29.160... logprob:  0.444709, 0.117188 (1.398 sec)
29.161... logprob:  0.349701, 0.078125 (1.406 sec)
29.162... logprob:  0.611788, 0.179688 (1.410 sec)
29.163... logprob:  0.450485, 0.125000 (1.426 sec)
29.164... logprob:  0.468525, 0.125000 (1.421 sec)
29.165... logprob:  0.547765, 0.156250 (1.429 sec)
29.166... logprob:  0.446151, 0.125000 (1.448 sec)
29.167... logprob:  0.350610, 0.085938 (1.435 sec)
29.168... logprob:  0.363749, 0.085938 (1.432 sec)
29.169... logprob:  0.408628, 0.101562 (1.461 sec)
29.170... logprob:  0.459462, 0.125000 (1.405 sec)
29.171... logprob:  0.535229, 0.156250 (1.430 sec)
29.172... logprob:  0.434802, 0.109375 (1.413 sec)
29.173... logprob:  0.440467, 0.117188 (1.426 sec)
29.174... logprob:  0.600695, 0.171875 (1.410 sec)
29.175... logprob:  0.505941, 0.140625 (1.467 sec)
29.176... logprob:  0.478400, 0.132812 (1.419 sec)
29.177... logprob:  0.289725, 0.054688 (1.431 sec)
29.178... logprob:  0.383474, 0.093750 (1.467 sec)
29.179... logprob:  0.394664, 0.101562 (1.407 sec)
29.180... logprob:  0.466390, 0.125000 (1.436 sec)
29.181... logprob:  0.539278, 0.156250 (1.420 sec)
29.182... logprob:  0.371279, 0.093750 (1.423 sec)
29.183... logprob:  0.419933, 0.109375 (1.424 sec)
29.184... logprob:  0.483437, 0.132812 (1.422 sec)
29.185... logprob:  0.289747, 0.062500 (1.401 sec)
29.186... logprob:  0.370356, 0.093750 (1.405 sec)
29.187... logprob:  0.529616, 0.148438 (1.401 sec)
29.188... logprob:  0.458867, 0.125000 (1.397 sec)
29.189... logprob:  0.440921, 0.117188 (1.394 sec)
29.190... logprob:  0.375788, 0.093750 (1.437 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.664146423339844, 10.0]}, 128)
batch 872: ({'logprob': [67.01738739013672, 19.0]}, 128)
batch 873: ({'logprob': [40.12816619873047, 9.0]}, 128)
batch 874: ({'logprob': [45.060577392578125, 11.0]}, 128)
batch 875: ({'logprob': [50.71778106689453, 13.0]}, 128)
batch 876: ({'logprob': [64.39640045166016, 18.0]}, 128)
batch 877: ({'logprob': [45.43428039550781, 11.0]}, 128)
batch 878: ({'logprob': [62.091060638427734, 17.0]}, 128)
batch 879: ({'logprob': [73.78424072265625, 21.0]}, 128)
batch 880: ({'logprob': [50.74430847167969, 13.0]}, 128)
batch 881: ({'logprob': [28.396699905395508, 5.0]}, 128)
batch 882: ({'logprob': [54.49331283569336, 14.0]}, 128)
batch 883: ({'logprob': [62.06344985961914, 17.0]}, 128)
batch 884: ({'logprob': [51.09504318237305, 13.0]}, 128)
batch 885: ({'logprob': [51.825260162353516, 13.0]}, 128)
batch 886: ({'logprob': [62.45254898071289, 17.0]}, 128)

======================Test output======================
logprob:  0.415705, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960465e-03 [2.819893e-09] 
Layer 'conv1' biases: 3.599590e-07 [5.077042e-11] 
Layer 'conv2' weights[0]: 7.947567e-03 [1.779939e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.453203e-10] 
Layer 'conv3' weights[0]: 7.945738e-03 [1.265391e-09] 
Layer 'conv3' biases: 3.049259e-06 [3.577570e-10] 
Layer 'conv4' weights[0]: 7.978427e-03 [1.201485e-09] 
Layer 'conv4' biases: 9.999992e-01 [5.602670e-10] 
Layer 'conv5' weights[0]: 7.977186e-03 [2.738171e-09] 
Layer 'conv5' biases: 9.999914e-01 [2.401434e-09] 
Layer 'fc6' weights[0]: 7.573792e-03 [7.829240e-10] 
Layer 'fc6' biases: 1.000000e+00 [1.975548e-10] 
Layer 'fc7' weights[0]: 6.934229e-03 [3.517322e-08] 
Layer 'fc7' biases: 9.998568e-01 [5.306862e-09] 
Layer 'fc8' weights[0]: 1.301419e-03 [7.502842e-07] 
Layer 'fc8' biases: 7.121826e-02 [4.314905e-06] 
Train error last 870 batches: 0.435191
-------------------------------------------------------
Not saving because 0.415705 > 0.415650 (27.630: -0.00%)
======================================================= (12.251 sec)
29.191... logprob:  0.485094, 0.132812 (1.418 sec)
29.192... logprob:  0.520031, 0.148438 (1.428 sec)
29.193... logprob:  0.312491, 0.070312 (1.424 sec)
29.194... logprob:  0.414050, 0.109375 (1.415 sec)
29.195... logprob:  0.287025, 0.062500 (1.401 sec)
29.196... logprob:  0.410459, 0.109375 (1.394 sec)
29.197... logprob:  0.477983, 0.132812 (1.401 sec)
29.198... logprob:  0.355796, 0.085938 (1.404 sec)
29.199... logprob:  0.437194, 0.117188 (1.394 sec)
29.200... logprob:  0.440731, 0.117188 (1.439 sec)
29.201... logprob:  0.437089, 0.117188 (1.408 sec)
29.202... logprob:  0.537839, 0.148438 (1.403 sec)
29.203... logprob:  0.420406, 0.109375 (1.445 sec)
29.204... logprob:  0.504123, 0.140625 (1.399 sec)
29.205... logprob:  0.334282, 0.078125 (1.400 sec)
29.206... logprob:  0.361635, 0.093750 (1.404 sec)
29.207... logprob:  0.381765, 0.093750 (1.393 sec)
29.208... logprob:  0.490585, 0.140625 (1.425 sec)
29.209... logprob:  0.334536, 0.078125 (1.429 sec)
29.210... logprob:  0.586226, 0.171875 (1.416 sec)
29.211... logprob:  0.488123, 0.132812 (1.420 sec)
29.212... logprob:  0.526117, 0.148438 (1.415 sec)
29.213... logprob:  0.514616, 0.140625 (1.466 sec)
29.214... logprob:  0.459393, 0.125000 (1.430 sec)
29.215... logprob:  0.396090, 0.101562 (1.421 sec)
29.216... logprob:  0.516916, 0.140625 (1.469 sec)
29.217... logprob:  0.324858, 0.070312 (1.404 sec)
29.218... logprob:  0.463586, 0.125000 (1.424 sec)
29.219... logprob:  0.500228, 0.140625 (1.417 sec)
29.220... logprob:  0.415028, 0.109375 (1.419 sec)
29.221... logprob:  0.399571, 0.101562 (1.407 sec)
29.222... logprob:  0.554403, 0.164062 (1.457 sec)
29.223... logprob:  0.568933, 0.164062 (1.437 sec)
29.224... logprob:  0.405980, 0.101562 (1.434 sec)
29.225... logprob:  0.392007, 0.101562 (1.450 sec)
29.226... logprob:  0.424747, 0.109375 (1.423 sec)
29.227... logprob:  0.452623, 0.125000 (1.416 sec)
29.228... logprob:  0.417169, 0.109375 (1.417 sec)
29.229... logprob:  0.489371, 0.132812 (1.421 sec)
29.230... logprob:  0.459850, 0.125000 (1.431 sec)
29.231... logprob:  0.453485, 0.125000 (1.410 sec)
29.232... logprob:  0.496158, 0.140625 (1.456 sec)
29.233... logprob:  0.466057, 0.132812 (1.427 sec)
29.234... logprob:  0.563868, 0.164062 (1.422 sec)
29.235... logprob:  0.482012, 0.132812 (1.469 sec)
29.236... logprob:  0.425646, 0.109375 (1.400 sec)
29.237... logprob:  0.340923, 0.078125 (1.427 sec)
29.238... logprob:  0.389105, 0.093750 (1.416 sec)
29.239... logprob:  0.478086, 0.132812 (1.421 sec)
29.240... logprob:  0.485796, 0.132812 (1.406 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.31319046020508, 10.0]}, 128)
batch 872: ({'logprob': [66.07415008544922, 19.0]}, 128)
batch 873: ({'logprob': [41.35374450683594, 9.0]}, 128)
batch 874: ({'logprob': [45.71232986450195, 11.0]}, 128)
batch 875: ({'logprob': [51.03095245361328, 13.0]}, 128)
batch 876: ({'logprob': [63.680198669433594, 18.0]}, 128)
batch 877: ({'logprob': [46.20399475097656, 11.0]}, 128)
batch 878: ({'logprob': [61.721492767333984, 17.0]}, 128)
batch 879: ({'logprob': [72.84805297851562, 21.0]}, 128)
batch 880: ({'logprob': [51.05625915527344, 13.0]}, 128)
batch 881: ({'logprob': [30.189855575561523, 5.0]}, 128)
batch 882: ({'logprob': [54.92388153076172, 14.0]}, 128)
batch 883: ({'logprob': [61.69453048706055, 17.0]}, 128)
batch 884: ({'logprob': [51.52051544189453, 13.0]}, 128)
batch 885: ({'logprob': [52.4833984375, 13.0]}, 128)
batch 886: ({'logprob': [62.197452545166016, 17.0]}, 128)

======================Test output======================
logprob:  0.417482, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960418e-03 [2.947836e-09] 
Layer 'conv1' biases: 3.609281e-07 [5.848983e-11] 
Layer 'conv2' weights[0]: 7.947522e-03 [1.712988e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.722743e-10] 
Layer 'conv3' weights[0]: 7.945702e-03 [1.294849e-09] 
Layer 'conv3' biases: 3.058148e-06 [4.719051e-10] 
Layer 'conv4' weights[0]: 7.978389e-03 [1.203354e-09] 
Layer 'conv4' biases: 9.999992e-01 [2.482327e-09] 
Layer 'conv5' weights[0]: 7.977153e-03 [1.121903e-08] 
Layer 'conv5' biases: 9.999915e-01 [1.147201e-08] 
Layer 'fc6' weights[0]: 7.573751e-03 [1.218129e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.124749e-10] 
Layer 'fc7' weights[0]: 6.932511e-03 [6.993130e-08] 
Layer 'fc7' biases: 9.998557e-01 [5.370885e-08] 
Layer 'fc8' weights[0]: 1.271113e-03 [2.218590e-06] 
Layer 'fc8' biases: 7.104418e-02 [1.654835e-05] 
Train error last 870 batches: 0.435191
-------------------------------------------------------
Not saving because 0.417482 > 0.415650 (27.630: -0.00%)
======================================================= (12.133 sec)
29.241... logprob:  0.493601, 0.132812 (1.486 sec)
29.242... logprob:  0.341630, 0.078125 (1.439 sec)
29.243... logprob:  0.385995, 0.093750 (1.437 sec)
29.244... logprob:  0.315419, 0.070312 (1.452 sec)
29.245... logprob:  0.494208, 0.132812 (1.429 sec)
29.246... logprob:  0.416845, 0.109375 (1.412 sec)
29.247... logprob:  0.357577, 0.085938 (1.421 sec)
29.248... logprob:  0.308062, 0.070312 (1.414 sec)
29.249... logprob:  0.554550, 0.156250 (1.428 sec)
29.250... logprob:  0.591170, 0.164062 (1.408 sec)
29.251... logprob:  0.352996, 0.085938 (1.461 sec)
29.252... logprob:  0.348433, 0.085938 (1.434 sec)
29.253... logprob:  0.379224, 0.093750 (1.416 sec)
29.254... logprob:  0.444158, 0.117188 (1.472 sec)
29.255... logprob:  0.351323, 0.085938 (1.399 sec)
29.256... logprob:  0.378863, 0.093750 (1.429 sec)
29.257... logprob:  0.331969, 0.078125 (1.422 sec)
29.258... logprob:  0.415518, 0.109375 (1.420 sec)
29.259... logprob:  0.442317, 0.117188 (1.399 sec)
29.260... logprob:  0.308185, 0.070312 (1.465 sec)
29.261... logprob:  0.392558, 0.101562 (1.433 sec)
29.262... logprob:  0.524512, 0.148438 (1.435 sec)
29.263... logprob:  0.425595, 0.109375 (1.448 sec)
29.264... logprob:  0.375022, 0.093750 (1.427 sec)
29.265... logprob:  0.439609, 0.117188 (1.420 sec)
29.266... logprob:  0.439007, 0.117188 (1.420 sec)
29.267... logprob:  0.422036, 0.109375 (1.417 sec)
29.268... logprob:  0.458940, 0.125000 (1.423 sec)
29.269... logprob:  0.567577, 0.164062 (1.410 sec)
29.270... logprob:  0.542337, 0.156250 (1.465 sec)
29.271... logprob:  0.445598, 0.117188 (1.432 sec)
29.272... logprob:  0.384558, 0.093750 (1.425 sec)
29.273... logprob:  0.500234, 0.140625 (1.464 sec)
29.274... logprob:  0.542499, 0.156250 (1.405 sec)
29.275... logprob:  0.487570, 0.132812 (1.428 sec)
29.276... logprob:  0.390006, 0.093750 (1.421 sec)
29.277... logprob:  0.428599, 0.109375 (1.429 sec)
29.278... logprob:  0.323624, 0.070312 (1.431 sec)
29.279... logprob:  0.325290, 0.070312 (1.463 sec)
29.280... logprob:  0.216030, 0.031250 (1.407 sec)
29.281... logprob:  0.417253, 0.109375 (1.423 sec)
29.282... logprob:  0.411315, 0.109375 (1.422 sec)
29.283... logprob:  0.393727, 0.101562 (1.448 sec)
29.284... logprob:  0.394371, 0.101562 (1.413 sec)
29.285... logprob:  0.451387, 0.117188 (1.443 sec)
29.286... logprob:  0.536263, 0.140625 (1.438 sec)
29.287... logprob:  0.346526, 0.085938 (1.435 sec)
29.288... logprob:  0.329942, 0.078125 (1.437 sec)
29.289... logprob:  0.445791, 0.117188 (1.443 sec)
29.290... logprob:  0.490647, 0.132812 (1.411 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.97379684448242, 10.0]}, 128)
batch 872: ({'logprob': [68.62272644042969, 19.0]}, 128)
batch 873: ({'logprob': [39.422752380371094, 9.0]}, 128)
batch 874: ({'logprob': [44.734432220458984, 11.0]}, 128)
batch 875: ({'logprob': [50.90736389160156, 13.0]}, 128)
batch 876: ({'logprob': [65.77884674072266, 18.0]}, 128)
batch 877: ({'logprob': [45.17544174194336, 11.0]}, 128)
batch 878: ({'logprob': [63.31678009033203, 17.0]}, 128)
batch 879: ({'logprob': [76.11432647705078, 21.0]}, 128)
batch 880: ({'logprob': [50.93470764160156, 13.0]}, 128)
batch 881: ({'logprob': [26.584392547607422, 5.0]}, 128)
batch 882: ({'logprob': [55.117454528808594, 14.0]}, 128)
batch 883: ({'logprob': [63.288726806640625, 17.0]}, 128)
batch 884: ({'logprob': [51.35792922973633, 13.0]}, 128)
batch 885: ({'logprob': [52.226383209228516, 13.0]}, 128)
batch 886: ({'logprob': [63.74951171875, 17.0]}, 128)

======================Test output======================
logprob:  0.419095, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960375e-03 [6.443038e-09] 
Layer 'conv1' biases: 3.620670e-07 [2.215307e-10] 
Layer 'conv2' weights[0]: 7.947483e-03 [5.378329e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.159066e-09] 
Layer 'conv3' weights[0]: 7.945654e-03 [5.125434e-09] 
Layer 'conv3' biases: 3.065209e-06 [3.378763e-09] 
Layer 'conv4' weights[0]: 7.978354e-03 [5.079045e-09] 
Layer 'conv4' biases: 9.999992e-01 [2.801618e-08] 
Layer 'conv5' weights[0]: 7.977103e-03 [1.763102e-07] 
Layer 'conv5' biases: 9.999913e-01 [1.896220e-07] 
Layer 'fc6' weights[0]: 7.573704e-03 [1.460951e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.492240e-08] 
Layer 'fc7' weights[0]: 6.930657e-03 [2.565782e-07] 
Layer 'fc7' biases: 9.998580e-01 [2.477203e-07] 
Layer 'fc8' weights[0]: 1.347368e-03 [1.008751e-05] 
Layer 'fc8' biases: 7.178419e-02 [5.522222e-05] 
Train error last 870 batches: 0.435191
-------------------------------------------------------
Not saving because 0.419095 > 0.415650 (27.630: -0.00%)
======================================================= (12.064 sec)
29.291... logprob:  0.439325, 0.117188 (1.425 sec)
29.292... logprob:  0.567718, 0.156250 (1.423 sec)
29.293... logprob:  0.427764, 0.117188 (1.435 sec)
29.294... logprob:  0.355723, 0.085938 (1.410 sec)
29.295... logprob:  0.334318, 0.078125 (1.464 sec)
29.296... logprob:  0.355452, 0.085938 (1.420 sec)
29.297... logprob:  0.394337, 0.101562 (1.423 sec)
29.298... logprob:  0.448249, 0.125000 (1.469 sec)
29.299... logprob:  0.341926, 0.078125 (1.406 sec)
29.300... logprob:  0.406355, 0.101562 (1.430 sec)
29.301... logprob:  0.397879, 0.101562 (1.416 sec)
29.302... logprob:  0.591593, 0.179688 (1.425 sec)
29.303... logprob:  0.459487, 0.125000 (1.413 sec)
29.304... logprob:  0.459614, 0.125000 (1.439 sec)
29.305... logprob:  0.455195, 0.125000 (1.443 sec)
29.306... logprob:  0.440574, 0.117188 (1.433 sec)
29.307... logprob:  0.421625, 0.109375 (1.447 sec)
29.308... logprob:  0.374841, 0.093750 (1.458 sec)
29.309... logprob:  0.450481, 0.125000 (1.421 sec)
29.310... logprob:  0.473577, 0.125000 (1.424 sec)
29.311... logprob:  0.502457, 0.140625 (1.423 sec)
29.312... logprob:  0.478672, 0.132812 (1.432 sec)
29.313... logprob:  0.454857, 0.125000 (1.421 sec)
29.314... logprob:  0.454347, 0.117188 (1.467 sec)
29.315... logprob:  0.314681, 0.070312 (1.430 sec)
29.316... logprob:  0.468508, 0.125000 (1.457 sec)
29.317... logprob:  0.355428, 0.085938 (1.482 sec)
29.318... logprob:  0.455402, 0.125000 (1.416 sec)
29.319... logprob:  0.423166, 0.117188 (1.429 sec)
29.320... logprob:  0.412233, 0.109375 (1.421 sec)
29.321... logprob:  0.348237, 0.085938 (1.430 sec)
29.322... logprob:  0.387436, 0.101562 (1.418 sec)
29.323... logprob:  0.416503, 0.109375 (1.480 sec)
29.324... logprob:  0.498598, 0.140625 (1.427 sec)
29.325... logprob:  0.350673, 0.085938 (1.438 sec)
29.326... logprob:  0.543180, 0.148438 (1.464 sec)
29.327... logprob:  0.554416, 0.164062 (1.424 sec)
29.328... logprob:  0.565136, 0.156250 (1.423 sec)
29.329... logprob:  0.401912, 0.101562 (1.429 sec)
29.330... logprob:  0.388503, 0.101562 (1.423 sec)
29.331... logprob:  0.352255, 0.085938 (1.421 sec)
29.332... logprob:  0.482782, 0.132812 (1.448 sec)
29.333... logprob:  0.339468, 0.085938 (1.448 sec)
29.334... logprob:  0.565292, 0.171875 (1.441 sec)
29.335... logprob:  0.358685, 0.085938 (1.440 sec)
29.336... logprob:  0.444859, 0.125000 (1.456 sec)
29.337... logprob:  0.566403, 0.164062 (1.421 sec)
29.338... logprob:  0.449515, 0.125000 (1.420 sec)
29.339... logprob:  0.488587, 0.132812 (1.428 sec)
29.340... logprob:  0.442065, 0.117188 (1.440 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.33406066894531, 10.0]}, 128)
batch 872: ({'logprob': [65.77391052246094, 19.0]}, 128)
batch 873: ({'logprob': [42.111454010009766, 9.0]}, 128)
batch 874: ({'logprob': [46.01374816894531, 11.0]}, 128)
batch 875: ({'logprob': [51.28512954711914, 13.0]}, 128)
batch 876: ({'logprob': [63.504920959472656, 18.0]}, 128)
batch 877: ({'logprob': [46.70940399169922, 11.0]}, 128)
batch 878: ({'logprob': [61.8769645690918, 17.0]}, 128)
batch 879: ({'logprob': [73.10807800292969, 21.0]}, 128)
batch 880: ({'logprob': [51.30917739868164, 13.0]}, 128)
batch 881: ({'logprob': [30.842700958251953, 5.0]}, 128)
batch 882: ({'logprob': [55.66083908081055, 14.0]}, 128)
batch 883: ({'logprob': [61.85085678100586, 17.0]}, 128)
batch 884: ({'logprob': [51.976436614990234, 13.0]}, 128)
batch 885: ({'logprob': [53.34657287597656, 13.0]}, 128)
batch 886: ({'logprob': [62.555908203125, 17.0]}, 128)

======================Test output======================
logprob:  0.420049, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960346e-03 [2.933713e-09] 
Layer 'conv1' biases: 3.629975e-07 [4.372587e-11] 
Layer 'conv2' weights[0]: 7.947451e-03 [1.926388e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.736345e-10] 
Layer 'conv3' weights[0]: 7.945618e-03 [1.433933e-09] 
Layer 'conv3' biases: 3.073933e-06 [5.330186e-10] 
Layer 'conv4' weights[0]: 7.978313e-03 [1.330805e-09] 
Layer 'conv4' biases: 9.999991e-01 [2.847290e-09] 
Layer 'conv5' weights[0]: 7.977078e-03 [1.382066e-08] 
Layer 'conv5' biases: 9.999916e-01 [1.452772e-08] 
Layer 'fc6' weights[0]: 7.573656e-03 [1.395317e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.161655e-09] 
Layer 'fc7' weights[0]: 6.928951e-03 [3.559914e-08] 
Layer 'fc7' biases: 9.998558e-01 [6.854534e-09] 
Layer 'fc8' weights[0]: 1.259629e-03 [1.435316e-06] 
Layer 'fc8' biases: 7.133571e-02 [8.954690e-06] 
Train error last 870 batches: 0.435191
-------------------------------------------------------
Not saving because 0.420049 > 0.415650 (27.630: -0.00%)
======================================================= (12.140 sec)
29.341... logprob:  0.530025, 0.148438 (1.429 sec)
29.342... logprob:  0.429604, 0.109375 (1.473 sec)
29.343... logprob:  0.434766, 0.109375 (1.442 sec)
29.344... logprob:  0.444522, 0.125000 (1.482 sec)
29.345... logprob:  0.488188, 0.132812 (1.436 sec)
29.346... logprob:  0.436209, 0.117188 (1.440 sec)
29.347... logprob:  0.372542, 0.085938 (1.487 sec)
29.348... logprob:  0.398489, 0.101562 (1.436 sec)
29.349... logprob:  0.497598, 0.140625 (1.449 sec)
29.350... logprob:  0.358709, 0.085938 (1.436 sec)
29.351... logprob:  0.508489, 0.140625 (1.434 sec)
29.352... logprob:  0.363612, 0.093750 (1.434 sec)
29.353... logprob:  0.512451, 0.148438 (1.489 sec)
29.354... logprob:  0.674794, 0.203125 (1.432 sec)
29.355... logprob:  0.357499, 0.085938 (1.447 sec)
29.356... logprob:  0.479239, 0.132812 (1.510 sec)
29.357... logprob:  0.346734, 0.085938 (1.440 sec)
29.358... logprob:  0.325753, 0.070312 (1.444 sec)
29.359... logprob:  0.555378, 0.164062 (1.436 sec)
29.360... logprob:  0.444523, 0.117188 (1.426 sec)
29.361... logprob:  0.410733, 0.101562 (1.439 sec)
29.362... logprob:  0.423945, 0.117188 (1.478 sec)
29.363... logprob:  0.486593, 0.132812 (1.443 sec)
29.364... logprob:  0.475613, 0.125000 (1.455 sec)
29.365... logprob:  0.425042, 0.109375 (1.466 sec)
29.366... logprob:  0.409569, 0.109375 (1.443 sec)
29.367... logprob:  0.324902, 0.078125 (1.444 sec)
29.368... logprob:  0.595555, 0.171875 (1.428 sec)
29.369... logprob:  0.381661, 0.093750 (1.429 sec)
29.370... logprob:  0.381295, 0.093750 (1.439 sec)
29.371... logprob:  0.400423, 0.101562 (1.460 sec)
29.372... logprob:  0.537230, 0.156250 (1.459 sec)
29.373... logprob:  0.463787, 0.125000 (1.451 sec)
29.374... logprob:  0.526820, 0.148438 (1.455 sec)
29.375... logprob:  0.393766, 0.101562 (1.463 sec)
29.376... logprob:  0.374289, 0.093750 (1.443 sec)
29.377... logprob:  0.295436, 0.062500 (1.433 sec)
29.378... logprob:  0.453664, 0.125000 (1.433 sec)
29.379... logprob:  0.420244, 0.109375 (1.437 sec)
29.380... logprob:  0.605672, 0.179688 (1.445 sec)
29.381... logprob:  0.463414, 0.125000 (1.471 sec)
29.382... logprob:  0.529582, 0.148438 (1.461 sec)
29.383... logprob:  0.358528, 0.085938 (1.437 sec)
29.384... logprob:  0.521215, 0.148438 (1.485 sec)
29.385... logprob:  0.523588, 0.148438 (1.434 sec)
29.386... logprob:  0.582585, 0.171875 (1.430 sec)
29.387... logprob:  0.428506, 0.117188 (1.434 sec)
29.388... logprob:  0.521380, 0.148438 (1.442 sec)
29.389... logprob:  0.425567, 0.109375 (1.431 sec)
29.390... logprob:  0.419666, 0.109375 (1.481 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.819244384765625, 10.0]}, 128)
batch 872: ({'logprob': [65.8438949584961, 19.0]}, 128)
batch 873: ({'logprob': [42.87044906616211, 9.0]}, 128)
batch 874: ({'logprob': [46.9423828125, 11.0]}, 128)
batch 875: ({'logprob': [51.87131881713867, 13.0]}, 128)
batch 876: ({'logprob': [63.618080139160156, 18.0]}, 128)
batch 877: ({'logprob': [47.38331985473633, 11.0]}, 128)
batch 878: ({'logprob': [61.778076171875, 17.0]}, 128)
batch 879: ({'logprob': [72.06896209716797, 21.0]}, 128)
batch 880: ({'logprob': [51.89593505859375, 13.0]}, 128)
batch 881: ({'logprob': [32.544410705566406, 5.0]}, 128)
batch 882: ({'logprob': [55.43462371826172, 14.0]}, 128)
batch 883: ({'logprob': [61.751556396484375, 17.0]}, 128)
batch 884: ({'logprob': [52.304595947265625, 13.0]}, 128)
batch 885: ({'logprob': [53.16242980957031, 13.0]}, 128)
batch 886: ({'logprob': [62.19953155517578, 17.0]}, 128)

======================Test output======================
logprob:  0.422602, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960313e-03 [3.001937e-09] 
Layer 'conv1' biases: 3.641609e-07 [1.409237e-10] 
Layer 'conv2' weights[0]: 7.947414e-03 [3.114790e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.852391e-10] 
Layer 'conv3' weights[0]: 7.945579e-03 [3.247391e-09] 
Layer 'conv3' biases: 3.083749e-06 [2.021393e-09] 
Layer 'conv4' weights[0]: 7.978274e-03 [3.330072e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.843705e-08] 
Layer 'conv5' weights[0]: 7.977054e-03 [1.191663e-07] 
Layer 'conv5' biases: 9.999918e-01 [1.281873e-07] 
Layer 'fc6' weights[0]: 7.573619e-03 [9.771934e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.884861e-09] 
Layer 'fc7' weights[0]: 6.927202e-03 [4.175392e-08] 
Layer 'fc7' biases: 9.998548e-01 [1.882453e-08] 
Layer 'fc8' weights[0]: 1.236367e-03 [2.344763e-06] 
Layer 'fc8' biases: 7.125889e-02 [1.778127e-05] 
Train error last 870 batches: 0.435190
-------------------------------------------------------
Not saving because 0.422602 > 0.415650 (27.630: -0.00%)
======================================================= (12.087 sec)
29.391... logprob:  0.318141, 0.070312 (1.460 sec)
29.392... logprob:  0.439449, 0.117188 (1.443 sec)
29.393... logprob:  0.369030, 0.093750 (1.488 sec)
29.394... logprob:  0.343709, 0.078125 (1.432 sec)
29.395... logprob:  0.331911, 0.078125 (1.434 sec)
29.396... logprob:  0.252606, 0.046875 (1.435 sec)
29.397... logprob:  0.484084, 0.132812 (1.436 sec)
29.398... logprob:  0.470652, 0.125000 (1.429 sec)
29.399... logprob:  0.433145, 0.117188 (1.491 sec)
29.400... logprob:  0.537404, 0.148438 (1.436 sec)
29.401... logprob:  0.465615, 0.125000 (1.445 sec)
29.402... logprob:  0.473808, 0.125000 (1.477 sec)
29.403... logprob:  0.462088, 0.125000 (1.439 sec)
29.404... logprob:  0.474802, 0.125000 (1.432 sec)
29.405... logprob:  0.544278, 0.156250 (1.437 sec)
29.406... logprob:  0.357535, 0.085938 (1.430 sec)
29.407... logprob:  0.493043, 0.140625 (1.436 sec)
29.408... logprob:  0.338829, 0.078125 (1.482 sec)
29.409... logprob:  0.400387, 0.101562 (1.438 sec)
29.410... logprob:  0.582323, 0.171875 (1.454 sec)
29.411... logprob:  0.397712, 0.101562 (1.472 sec)
29.412... logprob:  0.540326, 0.156250 (1.438 sec)
29.413... logprob:  0.544659, 0.156250 (1.441 sec)
29.414... logprob:  0.466368, 0.125000 (1.432 sec)
29.415... logprob:  0.401643, 0.101562 (1.429 sec)
29.416... logprob:  0.427489, 0.109375 (1.436 sec)
29.417... logprob:  0.405464, 0.093750 (1.468 sec)
29.418... logprob:  0.380474, 0.093750 (1.449 sec)
29.419... logprob:  0.417890, 0.101562 (1.459 sec)
29.420... logprob:  0.356503, 0.085938 (1.455 sec)
29.421... logprob:  0.376660, 0.101562 (1.461 sec)
29.422... logprob:  0.522046, 0.148438 (1.437 sec)
29.423... logprob:  0.420795, 0.109375 (1.453 sec)
29.424... logprob:  0.324923, 0.078125 (1.427 sec)
29.425... logprob:  0.306523, 0.070312 (1.448 sec)
29.426... logprob:  0.449009, 0.117188 (1.449 sec)
29.427... logprob:  0.554007, 0.156250 (1.462 sec)
29.428... logprob:  0.601528, 0.171875 (1.459 sec)
29.429... logprob:  0.426352, 0.109375 (1.443 sec)
29.430... logprob:  0.299765, 0.070312 (1.477 sec)
29.431... logprob:  0.600070, 0.171875 (1.439 sec)
29.432... logprob:  0.387523, 0.093750 (1.428 sec)
29.433... logprob:  0.329595, 0.078125 (1.433 sec)
29.434... logprob:  0.529661, 0.148438 (1.443 sec)
29.435... logprob:  0.532539, 0.156250 (1.434 sec)
29.436... logprob:  0.380917, 0.093750 (1.477 sec)
29.437... logprob:  0.500335, 0.140625 (1.449 sec)
29.438... logprob:  0.547008, 0.156250 (1.439 sec)
29.439... logprob:  0.378570, 0.093750 (1.489 sec)
29.440... logprob:  0.439648, 0.117188 (1.436 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.552574157714844, 10.0]}, 128)
batch 872: ({'logprob': [65.82810974121094, 19.0]}, 128)
batch 873: ({'logprob': [42.63621520996094, 9.0]}, 128)
batch 874: ({'logprob': [46.73098373413086, 11.0]}, 128)
batch 875: ({'logprob': [51.71751022338867, 13.0]}, 128)
batch 876: ({'logprob': [63.58208465576172, 18.0]}, 128)
batch 877: ({'logprob': [47.18901062011719, 11.0]}, 128)
batch 878: ({'logprob': [61.739341735839844, 17.0]}, 128)
batch 879: ({'logprob': [72.16319274902344, 21.0]}, 128)
batch 880: ({'logprob': [51.74191665649414, 13.0]}, 128)
batch 881: ({'logprob': [32.177146911621094, 5.0]}, 128)
batch 882: ({'logprob': [55.353492736816406, 14.0]}, 128)
batch 883: ({'logprob': [61.71314239501953, 17.0]}, 128)
batch 884: ({'logprob': [52.1687126159668, 13.0]}, 128)
batch 885: ({'logprob': [53.061561584472656, 13.0]}, 128)
batch 886: ({'logprob': [62.1786003112793, 17.0]}, 128)

======================Test output======================
logprob:  0.421647, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960277e-03 [4.187937e-09] 
Layer 'conv1' biases: 3.650466e-07 [1.054042e-10] 
Layer 'conv2' weights[0]: 7.947377e-03 [3.124536e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.703072e-10] 
Layer 'conv3' weights[0]: 7.945542e-03 [2.931684e-09] 
Layer 'conv3' biases: 3.090747e-06 [1.759278e-09] 
Layer 'conv4' weights[0]: 7.978240e-03 [2.991675e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.594168e-08] 
Layer 'conv5' weights[0]: 7.977013e-03 [1.031230e-07] 
Layer 'conv5' biases: 9.999918e-01 [1.109106e-07] 
Layer 'fc6' weights[0]: 7.573583e-03 [8.452165e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.567785e-09] 
Layer 'fc7' weights[0]: 6.925425e-03 [3.461523e-08] 
Layer 'fc7' biases: 9.998549e-01 [1.168129e-09] 
Layer 'fc8' weights[0]: 1.234667e-03 [1.975114e-07] 
Layer 'fc8' biases: 7.166127e-02 [4.798417e-06] 
Train error last 870 batches: 0.435190
-------------------------------------------------------
Not saving because 0.421647 > 0.415650 (27.630: -0.00%)
======================================================= (12.135 sec)
29.441... logprob:  0.467948, 0.125000 (1.439 sec)
29.442... logprob:  0.378925, 0.093750 (1.445 sec)
29.443... logprob:  0.496559, 0.140625 (1.431 sec)
29.444... logprob:  0.372423, 0.093750 (1.437 sec)
29.445... logprob:  0.362648, 0.085938 (1.487 sec)
29.446... logprob:  0.398402, 0.101562 (1.436 sec)
29.447... logprob:  0.569488, 0.164062 (1.440 sec)
29.448... logprob:  0.333031, 0.078125 (1.483 sec)
29.449... logprob:  0.400047, 0.101562 (1.435 sec)
29.450... logprob:  0.239763, 0.046875 (1.435 sec)
29.451... logprob:  0.452504, 0.125000 (1.436 sec)
29.452... logprob:  0.455987, 0.117188 (1.433 sec)
29.453... logprob:  0.455089, 0.125000 (1.433 sec)
29.454... logprob:  0.488872, 0.132812 (1.489 sec)
29.455... logprob:  0.506014, 0.140625 (1.433 sec)
29.456... logprob:  0.468841, 0.125000 (1.481 sec)
29.457... logprob:  0.375320, 0.093750 (1.478 sec)
29.458... logprob:  0.350966, 0.085938 (1.442 sec)
29.459... logprob:  0.514080, 0.140625 (1.437 sec)
29.460... logprob:  0.273669, 0.054688 (1.434 sec)
29.461... logprob:  0.460135, 0.125000 (1.427 sec)
29.462... logprob:  0.472000, 0.125000 (1.439 sec)
29.463... logprob:  0.420804, 0.109375 (1.479 sec)
29.464... logprob:  0.482799, 0.132812 (1.450 sec)
29.465... logprob:  0.421101, 0.109375 (1.456 sec)
29.466... logprob:  0.318267, 0.070312 (1.459 sec)
29.467... logprob:  0.413825, 0.109375 (1.453 sec)
29.468... logprob:  0.394256, 0.101562 (1.444 sec)
29.469... logprob:  0.334792, 0.078125 (1.432 sec)
29.470... logprob:  0.400103, 0.101562 (1.433 sec)
29.471... logprob:  0.529213, 0.148438 (1.435 sec)
29.472... logprob:  0.409981, 0.109375 (1.457 sec)
29.473... logprob:  0.375476, 0.093750 (1.461 sec)
29.474... logprob:  0.465513, 0.125000 (1.454 sec)
29.475... logprob:  0.503901, 0.140625 (1.446 sec)
29.476... logprob:  0.510152, 0.140625 (1.478 sec)
29.477... logprob:  0.334647, 0.078125 (1.443 sec)
29.478... logprob:  0.464229, 0.125000 (1.430 sec)
29.479... logprob:  0.305774, 0.070312 (1.441 sec)
29.480... logprob:  0.443502, 0.117188 (1.441 sec)
29.481... logprob:  0.547815, 0.156250 (1.443 sec)
29.482... logprob:  0.443136, 0.117188 (1.474 sec)
29.483... logprob:  0.502701, 0.140625 (1.450 sec)
29.484... logprob:  0.485322, 0.132812 (1.437 sec)
29.485... logprob:  0.408921, 0.109375 (1.484 sec)
29.486... logprob:  0.361269, 0.085938 (1.433 sec)
29.487... logprob:  0.522703, 0.148438 (1.435 sec)
29.488... logprob:  0.424708, 0.109375 (1.438 sec)
29.489... logprob:  0.415818, 0.109375 (1.435 sec)
29.490... logprob:  0.440687, 0.117188 (1.435 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.585289001464844, 10.0]}, 128)
batch 872: ({'logprob': [66.16814422607422, 19.0]}, 128)
batch 873: ({'logprob': [41.32093811035156, 9.0]}, 128)
batch 874: ({'logprob': [45.81814193725586, 11.0]}, 128)
batch 875: ({'logprob': [51.08665466308594, 13.0]}, 128)
batch 876: ({'logprob': [63.75191879272461, 18.0]}, 128)
batch 877: ({'logprob': [46.21554946899414, 11.0]}, 128)
batch 878: ({'logprob': [61.67721176147461, 17.0]}, 128)
batch 879: ({'logprob': [72.61042785644531, 21.0]}, 128)
batch 880: ({'logprob': [51.11207580566406, 13.0]}, 128)
batch 881: ({'logprob': [30.351411819458008, 5.0]}, 128)
batch 882: ({'logprob': [54.71928405761719, 14.0]}, 128)
batch 883: ({'logprob': [61.650325775146484, 17.0]}, 128)
batch 884: ({'logprob': [51.48217010498047, 13.0]}, 128)
batch 885: ({'logprob': [52.256866455078125, 13.0]}, 128)
batch 886: ({'logprob': [62.058956146240234, 17.0]}, 128)

======================Test output======================
logprob:  0.417415, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960247e-03 [2.588362e-09] 
Layer 'conv1' biases: 3.659211e-07 [6.800570e-11] 
Layer 'conv2' weights[0]: 7.947344e-03 [2.088814e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.323100e-10] 
Layer 'conv3' weights[0]: 7.945503e-03 [1.908753e-09] 
Layer 'conv3' biases: 3.097508e-06 [9.839785e-10] 
Layer 'conv4' weights[0]: 7.978198e-03 [2.027184e-09] 
Layer 'conv4' biases: 9.999991e-01 [8.982250e-09] 
Layer 'conv5' weights[0]: 7.976956e-03 [5.798423e-08] 
Layer 'conv5' biases: 9.999914e-01 [6.231986e-08] 
Layer 'fc6' weights[0]: 7.573549e-03 [4.848175e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.832808e-09] 
Layer 'fc7' weights[0]: 6.923661e-03 [8.206126e-08] 
Layer 'fc7' biases: 9.998555e-01 [6.704634e-08] 
Layer 'fc8' weights[0]: 1.257778e-03 [2.386210e-06] 
Layer 'fc8' biases: 7.203488e-02 [1.795087e-05] 
Train error last 870 batches: 0.435189
-------------------------------------------------------
Not saving because 0.417415 > 0.415650 (27.630: -0.00%)
======================================================= (12.105 sec)
29.491... logprob:  0.313602, 0.070312 (1.493 sec)
29.492... logprob:  0.459525, 0.125000 (1.447 sec)
29.493... logprob:  0.521795, 0.148438 (1.445 sec)
29.494... logprob:  0.450345, 0.125000 (1.507 sec)
29.495... logprob:  0.380686, 0.093750 (1.443 sec)
29.496... logprob:  0.550202, 0.156250 (1.443 sec)
29.497... logprob:  0.466892, 0.125000 (1.443 sec)
29.498... logprob:  0.476211, 0.132812 (1.440 sec)
29.499... logprob:  0.456223, 0.125000 (1.441 sec)
29.500... logprob:  0.355162, 0.085938 (1.502 sec)
29.501... logprob:  0.339129, 0.078125 (1.441 sec)
29.502... logprob:  0.459602, 0.125000 (1.448 sec)
29.503... logprob:  0.400662, 0.101562 (1.490 sec)
29.504... logprob:  0.487278, 0.132812 (1.437 sec)
29.505... logprob:  0.570768, 0.164062 (1.453 sec)
29.506... logprob:  0.479685, 0.132812 (1.439 sec)
29.507... logprob:  0.385025, 0.093750 (1.449 sec)
29.508... logprob:  0.374654, 0.093750 (1.442 sec)
29.509... logprob:  0.322989, 0.070312 (1.484 sec)
29.510... logprob:  0.390454, 0.101562 (1.443 sec)
29.511... logprob:  0.410044, 0.109375 (1.465 sec)
29.512... logprob:  0.470715, 0.125000 (1.469 sec)
29.513... logprob:  0.324960, 0.078125 (1.445 sec)
29.514... logprob:  0.406272, 0.101562 (1.450 sec)
29.515... logprob:  0.455462, 0.125000 (1.441 sec)
29.516... logprob:  0.400257, 0.109375 (1.444 sec)
29.517... logprob:  0.627731, 0.179688 (1.456 sec)
29.518... logprob:  0.437641, 0.117188 (1.474 sec)
29.519... logprob:  0.516128, 0.140625 (1.466 sec)
29.520... logprob:  0.409642, 0.109375 (1.469 sec)
29.521... logprob:  0.427426, 0.109375 (1.462 sec)
29.522... logprob:  0.533170, 0.156250 (1.473 sec)
29.523... logprob:  0.331484, 0.078125 (1.456 sec)
29.524... logprob:  0.437143, 0.117188 (1.443 sec)
29.525... logprob:  0.425894, 0.109375 (1.440 sec)
29.526... logprob:  0.351648, 0.078125 (1.444 sec)
29.527... logprob:  0.504580, 0.140625 (1.456 sec)
29.528... logprob:  0.440455, 0.117188 (1.476 sec)
29.529... logprob:  0.352999, 0.085938 (1.463 sec)
29.530... logprob:  0.440255, 0.117188 (1.482 sec)
29.531... logprob:  0.439950, 0.117188 (1.479 sec)
29.532... logprob:  0.467310, 0.125000 (1.437 sec)
29.533... logprob:  0.560310, 0.164062 (1.426 sec)
29.534... logprob:  0.325946, 0.078125 (1.438 sec)
29.535... logprob:  0.551419, 0.156250 (1.451 sec)
29.536... logprob:  0.507259, 0.140625 (1.442 sec)
29.537... logprob:  0.509996, 0.140625 (1.497 sec)
29.538... logprob:  0.486081, 0.132812 (1.460 sec)
29.539... logprob:  0.296024, 0.062500 (1.442 sec)
29.540... logprob:  0.447176, 0.117188 (1.494 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.423702239990234, 10.0]}, 128)
batch 872: ({'logprob': [66.16383361816406, 19.0]}, 128)
batch 873: ({'logprob': [41.251197814941406, 9.0]}, 128)
batch 874: ({'logprob': [45.72347640991211, 11.0]}, 128)
batch 875: ({'logprob': [51.03030776977539, 13.0]}, 128)
batch 876: ({'logprob': [63.74447250366211, 18.0]}, 128)
batch 877: ({'logprob': [46.1524772644043, 11.0]}, 128)
batch 878: ({'logprob': [61.69797134399414, 17.0]}, 128)
batch 879: ({'logprob': [72.73957061767578, 21.0]}, 128)
batch 880: ({'logprob': [51.055824279785156, 13.0]}, 128)
batch 881: ({'logprob': [30.172941207885742, 5.0]}, 128)
batch 882: ({'logprob': [54.76163864135742, 14.0]}, 128)
batch 883: ({'logprob': [61.67081069946289, 17.0]}, 128)
batch 884: ({'logprob': [51.45784378051758, 13.0]}, 128)
batch 885: ({'logprob': [52.29594802856445, 13.0]}, 128)
batch 886: ({'logprob': [62.111610412597656, 17.0]}, 128)

======================Test output======================
logprob:  0.417214, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960216e-03 [3.273015e-09] 
Layer 'conv1' biases: 3.669738e-07 [8.681719e-11] 
Layer 'conv2' weights[0]: 7.947302e-03 [1.981700e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.117714e-10] 
Layer 'conv3' weights[0]: 7.945468e-03 [2.003343e-09] 
Layer 'conv3' biases: 3.108771e-06 [1.162829e-09] 
Layer 'conv4' weights[0]: 7.978162e-03 [2.069488e-09] 
Layer 'conv4' biases: 9.999991e-01 [9.472210e-09] 
Layer 'conv5' weights[0]: 7.976921e-03 [5.566881e-08] 
Layer 'conv5' biases: 9.999914e-01 [5.985274e-08] 
Layer 'fc6' weights[0]: 7.573509e-03 [4.678834e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.669229e-09] 
Layer 'fc7' weights[0]: 6.921872e-03 [4.829542e-08] 
Layer 'fc7' biases: 9.998555e-01 [2.845709e-08] 
Layer 'fc8' weights[0]: 1.260572e-03 [4.006384e-06] 
Layer 'fc8' biases: 7.213113e-02 [2.791907e-05] 
Train error last 870 batches: 0.435189
-------------------------------------------------------
Not saving because 0.417214 > 0.415650 (27.630: -0.00%)
======================================================= (12.134 sec)
29.541... logprob:  0.388785, 0.101562 (1.446 sec)
29.542... logprob:  0.411232, 0.109375 (1.436 sec)
29.543... logprob:  0.233196, 0.039062 (1.437 sec)
29.544... logprob:  0.317920, 0.070312 (1.442 sec)
29.545... logprob:  0.348797, 0.085938 (1.435 sec)
29.546... logprob:  0.368269, 0.093750 (1.488 sec)
29.547... logprob:  0.440007, 0.117188 (1.434 sec)
29.548... logprob:  0.452865, 0.125000 (1.441 sec)
29.549... logprob:  0.490412, 0.132812 (1.487 sec)
29.550... logprob:  0.367604, 0.093750 (1.439 sec)
29.551... logprob:  0.441622, 0.117188 (1.436 sec)
29.552... logprob:  0.471248, 0.125000 (1.442 sec)
29.553... logprob:  0.349448, 0.085938 (1.433 sec)
29.554... logprob:  0.506988, 0.140625 (1.439 sec)
29.555... logprob:  0.421408, 0.109375 (1.489 sec)
29.556... logprob:  0.355779, 0.085938 (1.441 sec)
29.557... logprob:  0.396357, 0.101562 (1.449 sec)
29.558... logprob:  0.383002, 0.101562 (1.475 sec)
29.559... logprob:  0.441617, 0.125000 (1.441 sec)
29.560... logprob:  0.335030, 0.078125 (1.443 sec)
29.561... logprob:  0.411789, 0.109375 (1.438 sec)
29.562... logprob:  0.503159, 0.140625 (1.422 sec)
29.563... logprob:  0.373757, 0.093750 (1.445 sec)
29.564... logprob:  0.468489, 0.132812 (1.474 sec)
29.565... logprob:  0.611155, 0.187500 (1.450 sec)
29.566... logprob:  0.374868, 0.093750 (1.459 sec)
29.567... logprob:  0.423305, 0.109375 (1.472 sec)
29.568... logprob:  0.496327, 0.140625 (1.454 sec)
29.569... logprob:  0.507688, 0.140625 (1.442 sec)
29.570... logprob:  0.543788, 0.164062 (1.424 sec)
29.571... logprob:  0.454885, 0.125000 (1.435 sec)
29.572... logprob:  0.501367, 0.140625 (1.439 sec)
29.573... logprob:  0.512596, 0.148438 (1.449 sec)
29.574... logprob:  0.428030, 0.109375 (1.460 sec)
29.575... logprob:  0.343327, 0.078125 (1.458 sec)
29.576... logprob:  0.427354, 0.109375 (1.447 sec)
29.577... logprob:  0.460788, 0.125000 (1.478 sec)
29.578... logprob:  0.336773, 0.078125 (1.431 sec)
29.579... logprob:  0.442079, 0.117188 (1.431 sec)
29.580... logprob:  0.546642, 0.156250 (1.434 sec)
29.581... logprob:  0.530639, 0.156250 (1.441 sec)
29.582... logprob:  0.437801, 0.125000 (1.430 sec)
29.583... logprob:  0.592434, 0.171875 (1.482 sec)
29.584... logprob:  0.468070, 0.132812 (1.445 sec)
29.585... logprob:  0.349767, 0.085938 (1.440 sec)
29.586... logprob:  0.313066, 0.070312 (1.487 sec)
29.587... logprob:  0.404297, 0.101562 (1.436 sec)
29.588... logprob:  0.418655, 0.117188 (1.426 sec)
29.589... logprob:  0.361159, 0.093750 (1.443 sec)
29.590... logprob:  0.524773, 0.148438 (1.430 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.18178176879883, 10.0]}, 128)
batch 872: ({'logprob': [66.45763397216797, 19.0]}, 128)
batch 873: ({'logprob': [41.0130500793457, 9.0]}, 128)
batch 874: ({'logprob': [45.18274688720703, 11.0]}, 128)
batch 875: ({'logprob': [50.8685417175293, 13.0]}, 128)
batch 876: ({'logprob': [64.01937866210938, 18.0]}, 128)
batch 877: ({'logprob': [45.951229095458984, 11.0]}, 128)
batch 878: ({'logprob': [62.29361343383789, 17.0]}, 128)
batch 879: ({'logprob': [74.43158721923828, 21.0]}, 128)
batch 880: ({'logprob': [50.89335632324219, 13.0]}, 128)
batch 881: ({'logprob': [28.83548355102539, 5.0]}, 128)
batch 882: ({'logprob': [55.641239166259766, 14.0]}, 128)
batch 883: ({'logprob': [62.26680374145508, 17.0]}, 128)
batch 884: ({'logprob': [51.63835525512695, 13.0]}, 128)
batch 885: ({'logprob': [53.15748977661133, 13.0]}, 128)
batch 886: ({'logprob': [63.048927307128906, 17.0]}, 128)

======================Test output======================
logprob:  0.418399, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960180e-03 [3.167775e-09] 
Layer 'conv1' biases: 3.680415e-07 [7.466972e-11] 
Layer 'conv2' weights[0]: 7.947266e-03 [2.501384e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.564940e-10] 
Layer 'conv3' weights[0]: 7.945428e-03 [1.973923e-09] 
Layer 'conv3' biases: 3.115589e-06 [1.008466e-09] 
Layer 'conv4' weights[0]: 7.978120e-03 [1.911787e-09] 
Layer 'conv4' biases: 9.999991e-01 [7.036573e-09] 
Layer 'conv5' weights[0]: 7.976877e-03 [4.384974e-08] 
Layer 'conv5' biases: 9.999909e-01 [4.718077e-08] 
Layer 'fc6' weights[0]: 7.573470e-03 [3.722040e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.707460e-09] 
Layer 'fc7' weights[0]: 6.920066e-03 [6.543054e-08] 
Layer 'fc7' biases: 9.998569e-01 [4.870988e-08] 
Layer 'fc8' weights[0]: 1.287935e-03 [2.420630e-06] 
Layer 'fc8' biases: 7.244048e-02 [1.647147e-05] 
Train error last 870 batches: 0.435189
-------------------------------------------------------
Not saving because 0.418399 > 0.415650 (27.630: -0.00%)
======================================================= (12.066 sec)
29.591... logprob:  0.397460, 0.101562 (1.439 sec)
29.592... logprob:  0.455677, 0.125000 (1.494 sec)
29.593... logprob:  0.467418, 0.125000 (1.441 sec)
29.594... logprob:  0.352828, 0.085938 (1.445 sec)
29.595... logprob:  0.428660, 0.109375 (1.478 sec)
29.596... logprob:  0.461613, 0.125000 (1.438 sec)
29.597... logprob:  0.397416, 0.101562 (1.432 sec)
29.598... logprob:  0.397218, 0.101562 (1.438 sec)
29.599... logprob:  0.313575, 0.070312 (1.430 sec)
29.600... logprob:  0.340880, 0.085938 (1.436 sec)
29.601... logprob:  0.402153, 0.101562 (1.485 sec)
29.602... logprob:  0.289878, 0.062500 (1.437 sec)
29.603... logprob:  0.267187, 0.054688 (1.450 sec)
29.604... logprob:  0.407524, 0.101562 (1.473 sec)
29.605... logprob:  0.563295, 0.148438 (1.442 sec)
29.606... logprob:  0.295944, 0.070312 (1.442 sec)
29.607... logprob:  0.504697, 0.132812 (1.440 sec)
29.608... logprob:  0.361860, 0.085938 (1.425 sec)
29.609... logprob:  0.357039, 0.085938 (1.437 sec)
29.610... logprob:  0.493296, 0.132812 (1.472 sec)
29.611... logprob:  0.510340, 0.140625 (1.449 sec)
29.612... logprob:  0.448527, 0.117188 (1.454 sec)
29.613... logprob:  0.279369, 0.062500 (1.467 sec)
29.614... logprob:  0.503568, 0.140625 (1.457 sec)
29.615... logprob:  0.350827, 0.085938 (1.441 sec)
29.616... logprob:  0.415072, 0.109375 (1.432 sec)
29.617... logprob:  0.417835, 0.109375 (1.432 sec)
29.618... logprob:  0.547011, 0.156250 (1.441 sec)
29.619... logprob:  0.506107, 0.140625 (1.448 sec)
29.620... logprob:  0.539699, 0.156250 (1.454 sec)
29.621... logprob:  0.363592, 0.085938 (1.457 sec)
29.622... logprob:  0.364684, 0.085938 (1.453 sec)
29.623... logprob:  0.423129, 0.109375 (1.468 sec)
29.624... logprob:  0.382510, 0.093750 (1.439 sec)
29.625... logprob:  0.440981, 0.117188 (1.424 sec)
29.626... logprob:  0.438349, 0.117188 (1.432 sec)
29.627... logprob:  0.435824, 0.117188 (1.442 sec)
29.628... logprob:  0.465023, 0.125000 (1.434 sec)
29.629... logprob:  0.372141, 0.093750 (1.491 sec)
29.630... logprob:  0.422383, 0.109375 (1.452 sec)
29.631... logprob:  0.638448, 0.187500 (1.440 sec)
29.632... logprob:  0.399119, 0.101562 (1.487 sec)
29.633... logprob:  0.376111, 0.093750 (1.436 sec)
29.634... logprob:  0.660085, 0.195312 (1.429 sec)
29.635... logprob:  0.374121, 0.093750 (1.436 sec)
29.636... logprob:  0.480260, 0.132812 (1.438 sec)
29.637... logprob:  0.330750, 0.078125 (1.439 sec)
29.638... logprob:  0.515706, 0.140625 (1.487 sec)
29.639... logprob:  0.418034, 0.109375 (1.440 sec)
29.640... logprob:  0.528759, 0.148438 (1.438 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.67908477783203, 10.0]}, 128)
batch 872: ({'logprob': [66.2503662109375, 19.0]}, 128)
batch 873: ({'logprob': [41.25761032104492, 9.0]}, 128)
batch 874: ({'logprob': [45.83919906616211, 11.0]}, 128)
batch 875: ({'logprob': [51.09964370727539, 13.0]}, 128)
batch 876: ({'logprob': [63.81549835205078, 18.0]}, 128)
batch 877: ({'logprob': [46.190677642822266, 11.0]}, 128)
batch 878: ({'logprob': [61.67534637451172, 17.0]}, 128)
batch 879: ({'logprob': [72.5473861694336, 21.0]}, 128)
batch 880: ({'logprob': [51.1254997253418, 13.0]}, 128)
batch 881: ({'logprob': [30.349225997924805, 5.0]}, 128)
batch 882: ({'logprob': [54.613861083984375, 14.0]}, 128)
batch 883: ({'logprob': [61.6479606628418, 17.0]}, 128)
batch 884: ({'logprob': [51.44955062866211, 13.0]}, 128)
batch 885: ({'logprob': [52.13200759887695, 13.0]}, 128)
batch 886: ({'logprob': [62.01110076904297, 17.0]}, 128)

======================Test output======================
logprob:  0.417326, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960142e-03 [4.133067e-09] 
Layer 'conv1' biases: 3.690739e-07 [7.774660e-11] 
Layer 'conv2' weights[0]: 7.947226e-03 [2.720955e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.545904e-10] 
Layer 'conv3' weights[0]: 7.945389e-03 [1.929058e-09] 
Layer 'conv3' biases: 3.125575e-06 [1.101656e-09] 
Layer 'conv4' weights[0]: 7.978078e-03 [1.959645e-09] 
Layer 'conv4' biases: 9.999991e-01 [7.516218e-09] 
Layer 'conv5' weights[0]: 7.976847e-03 [4.877461e-08] 
Layer 'conv5' biases: 9.999914e-01 [5.229915e-08] 
Layer 'fc6' weights[0]: 7.573432e-03 [4.058235e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.058661e-09] 
Layer 'fc7' weights[0]: 6.918321e-03 [1.278636e-07] 
Layer 'fc7' biases: 9.998552e-01 [1.162468e-07] 
Layer 'fc8' weights[0]: 1.261965e-03 [4.083135e-06] 
Layer 'fc8' biases: 7.243057e-02 [2.619386e-05] 
Train error last 870 batches: 0.435188
-------------------------------------------------------
Not saving because 0.417326 > 0.415650 (27.630: -0.00%)
======================================================= (12.050 sec)
29.641... logprob:  0.410412, 0.109375 (1.496 sec)
29.642... logprob:  0.500901, 0.140625 (1.442 sec)
29.643... logprob:  0.623257, 0.187500 (1.428 sec)
29.644... logprob:  0.320957, 0.070312 (1.440 sec)
29.645... logprob:  0.414453, 0.109375 (1.431 sec)
29.646... logprob:  0.385578, 0.093750 (1.436 sec)
29.647... logprob:  0.456791, 0.125000 (1.492 sec)
29.648... logprob:  0.491269, 0.140625 (1.439 sec)
29.649... logprob:  0.370304, 0.093750 (1.448 sec)
29.650... logprob:  0.414028, 0.109375 (1.475 sec)
29.651... logprob:  0.397405, 0.101562 (1.436 sec)
29.652... logprob:  0.507092, 0.140625 (1.437 sec)
29.653... logprob:  0.547728, 0.156250 (1.438 sec)
29.654... logprob:  0.496007, 0.140625 (1.424 sec)
29.655... logprob:  0.436178, 0.117188 (1.438 sec)
29.656... logprob:  0.416713, 0.109375 (1.479 sec)
29.657... logprob:  0.449056, 0.117188 (1.444 sec)
29.658... logprob:  0.345880, 0.085938 (1.453 sec)
29.659... logprob:  0.464283, 0.125000 (1.468 sec)
29.660... logprob:  0.446036, 0.125000 (1.441 sec)
29.661... logprob:  0.378414, 0.093750 (1.451 sec)
29.662... logprob:  0.469458, 0.132812 (1.432 sec)
29.663... logprob:  0.310866, 0.070312 (1.427 sec)
29.664... logprob:  0.285357, 0.062500 (1.439 sec)
29.665... logprob:  0.401688, 0.101562 (1.464 sec)
29.666... logprob:  0.442025, 0.117188 (1.455 sec)
29.667... logprob:  0.564210, 0.164062 (1.460 sec)
29.668... logprob:  0.497846, 0.140625 (1.459 sec)
29.669... logprob:  0.432923, 0.109375 (1.461 sec)
29.670... logprob:  0.362360, 0.085938 (1.442 sec)
29.671... logprob:  0.360871, 0.093750 (1.426 sec)
29.672... logprob:  0.441826, 0.117188 (1.435 sec)
29.673... logprob:  0.436226, 0.117188 (1.436 sec)
29.674... logprob:  0.446631, 0.117188 (1.448 sec)
29.675... logprob:  0.356683, 0.093750 (1.465 sec)
29.676... logprob:  0.450185, 0.125000 (1.457 sec)
29.677... logprob:  0.471018, 0.125000 (1.445 sec)
29.678... logprob:  0.465661, 0.125000 (1.486 sec)
29.679... logprob:  0.454863, 0.125000 (1.433 sec)
29.680... logprob:  0.351657, 0.078125 (1.426 sec)
29.681... logprob:  0.373863, 0.093750 (1.440 sec)
29.682... logprob:  0.340463, 0.078125 (1.435 sec)
29.683... logprob:  0.411632, 0.109375 (1.438 sec)
29.684... logprob:  0.357697, 0.085938 (1.477 sec)
29.685... logprob:  0.286194, 0.054688 (1.444 sec)
29.686... logprob:  0.318802, 0.070312 (1.437 sec)
29.687... logprob:  0.281789, 0.062500 (1.488 sec)
29.688... logprob:  0.323145, 0.078125 (1.433 sec)
29.689... logprob:  0.470961, 0.125000 (1.435 sec)
29.690... logprob:  0.527396, 0.140625 (1.436 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.87041091918945, 10.0]}, 128)
batch 872: ({'logprob': [69.52094268798828, 19.0]}, 128)
batch 873: ({'logprob': [39.33388900756836, 9.0]}, 128)
batch 874: ({'logprob': [44.79958724975586, 11.0]}, 128)
batch 875: ({'logprob': [51.198211669921875, 13.0]}, 128)
batch 876: ({'logprob': [66.58285522460938, 18.0]}, 128)
batch 877: ({'logprob': [45.27627182006836, 11.0]}, 128)
batch 878: ({'logprob': [64.06139373779297, 17.0]}, 128)
batch 879: ({'logprob': [77.3482894897461, 21.0]}, 128)
batch 880: ({'logprob': [51.22609329223633, 13.0]}, 128)
batch 881: ({'logprob': [26.005094528198242, 5.0]}, 128)
batch 882: ({'logprob': [55.61381530761719, 14.0]}, 128)
batch 883: ({'logprob': [64.0326919555664, 17.0]}, 128)
batch 884: ({'logprob': [51.687110900878906, 13.0]}, 128)
batch 885: ({'logprob': [52.62812423706055, 13.0]}, 128)
batch 886: ({'logprob': [64.5312728881836, 17.0]}, 128)

======================Test output======================
logprob:  0.422225, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960105e-03 [5.494861e-09] 
Layer 'conv1' biases: 3.698051e-07 [2.129424e-10] 
Layer 'conv2' weights[0]: 7.947187e-03 [4.611914e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.083533e-09] 
Layer 'conv3' weights[0]: 7.945353e-03 [4.862216e-09] 
Layer 'conv3' biases: 3.128755e-06 [3.232378e-09] 
Layer 'conv4' weights[0]: 7.978041e-03 [4.850774e-09] 
Layer 'conv4' biases: 9.999991e-01 [2.799293e-08] 
Layer 'conv5' weights[0]: 7.976795e-03 [1.786859e-07] 
Layer 'conv5' biases: 9.999905e-01 [1.919956e-07] 
Layer 'fc6' weights[0]: 7.573398e-03 [1.480021e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.514096e-08] 
Layer 'fc7' weights[0]: 6.916563e-03 [5.130890e-08] 
Layer 'fc7' biases: 9.998582e-01 [3.179656e-08] 
Layer 'fc8' weights[0]: 1.360423e-03 [7.354976e-06] 
Layer 'fc8' biases: 7.317973e-02 [5.085135e-05] 
Train error last 870 batches: 0.435188
-------------------------------------------------------
Not saving because 0.422225 > 0.415650 (27.630: -0.00%)
======================================================= (12.080 sec)
29.691... logprob:  0.516215, 0.140625 (1.440 sec)
29.692... logprob:  0.384796, 0.101562 (1.441 sec)
29.693... logprob:  0.455518, 0.125000 (1.484 sec)
29.694... logprob:  0.330953, 0.078125 (1.438 sec)
29.695... logprob:  0.356948, 0.085938 (1.444 sec)
29.696... logprob:  0.539257, 0.148438 (1.478 sec)
29.697... logprob:  0.465779, 0.125000 (1.439 sec)
29.698... logprob:  0.549049, 0.156250 (1.433 sec)
29.699... logprob:  0.459632, 0.125000 (1.435 sec)
29.700... logprob:  0.433814, 0.117188 (1.432 sec)
29.701... logprob:  0.422932, 0.109375 (1.435 sec)
29.702... logprob:  0.521573, 0.148438 (1.483 sec)
29.703... logprob:  0.404957, 0.101562 (1.444 sec)
29.704... logprob:  0.405921, 0.101562 (1.445 sec)
29.705... logprob:  0.420089, 0.109375 (1.477 sec)
29.706... logprob:  0.468051, 0.125000 (1.435 sec)
29.707... logprob:  0.485297, 0.132812 (1.444 sec)
29.708... logprob:  0.417229, 0.109375 (1.429 sec)
29.709... logprob:  0.422670, 0.109375 (1.428 sec)
29.710... logprob:  0.602055, 0.179688 (1.461 sec)
29.711... logprob:  0.469466, 0.125000 (1.473 sec)
29.712... logprob:  0.340972, 0.078125 (1.447 sec)
29.713... logprob:  0.586401, 0.179688 (1.459 sec)
29.714... logprob:  0.466236, 0.125000 (1.454 sec)
29.715... logprob:  0.417202, 0.109375 (1.457 sec)
29.716... logprob:  0.335509, 0.078125 (1.444 sec)
29.717... logprob:  0.429774, 0.117188 (1.433 sec)
29.718... logprob:  0.490299, 0.132812 (1.432 sec)
29.719... logprob:  0.406179, 0.109375 (1.437 sec)
29.720... logprob:  0.433224, 0.117188 (1.452 sec)
29.721... logprob:  0.451602, 0.117188 (1.463 sec)
29.722... logprob:  0.537029, 0.156250 (1.457 sec)
29.723... logprob:  0.416544, 0.109375 (1.452 sec)
29.724... logprob:  0.412758, 0.109375 (1.475 sec)
29.725... logprob:  0.494871, 0.140625 (1.438 sec)
29.726... logprob:  0.338400, 0.085938 (1.433 sec)
29.727... logprob:  0.393189, 0.101562 (1.436 sec)
29.728... logprob:  0.421203, 0.109375 (1.439 sec)
29.729... logprob:  0.387559, 0.093750 (1.436 sec)
29.730... logprob:  0.565944, 0.164062 (1.475 sec)
29.731... logprob:  0.450417, 0.125000 (1.451 sec)
29.732... logprob:  0.311381, 0.070312 (1.431 sec)
29.733... logprob:  0.556488, 0.156250 (1.492 sec)
29.734... logprob:  0.340253, 0.078125 (1.430 sec)
29.735... logprob:  0.527416, 0.148438 (1.437 sec)
29.736... logprob:  0.642551, 0.187500 (1.434 sec)
29.737... logprob:  0.516091, 0.148438 (1.438 sec)
29.738... logprob:  0.459384, 0.125000 (1.435 sec)
29.739... logprob:  0.477787, 0.132812 (1.478 sec)
29.740... logprob:  0.339645, 0.078125 (1.437 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.96174621582031, 10.0]}, 128)
batch 872: ({'logprob': [65.74344635009766, 19.0]}, 128)
batch 873: ({'logprob': [42.380027770996094, 9.0]}, 128)
batch 874: ({'logprob': [46.37306213378906, 11.0]}, 128)
batch 875: ({'logprob': [51.484375, 13.0]}, 128)
batch 876: ({'logprob': [63.492061614990234, 18.0]}, 128)
batch 877: ({'logprob': [46.94401931762695, 11.0]}, 128)
batch 878: ({'logprob': [61.75640106201172, 17.0]}, 128)
batch 879: ({'logprob': [72.54269409179688, 21.0]}, 128)
batch 880: ({'logprob': [51.508731842041016, 13.0]}, 128)
batch 881: ({'logprob': [31.557214736938477, 5.0]}, 128)
batch 882: ({'logprob': [55.46660614013672, 14.0]}, 128)
batch 883: ({'logprob': [61.72999572753906, 17.0]}, 128)
batch 884: ({'logprob': [52.04970932006836, 13.0]}, 128)
batch 885: ({'logprob': [53.169124603271484, 13.0]}, 128)
batch 886: ({'logprob': [62.30938720703125, 17.0]}, 128)

======================Test output======================
logprob:  0.420639, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960061e-03 [3.400459e-09] 
Layer 'conv1' biases: 3.710345e-07 [1.016090e-10] 
Layer 'conv2' weights[0]: 7.947152e-03 [3.551176e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.223975e-10] 
Layer 'conv3' weights[0]: 7.945318e-03 [3.278988e-09] 
Layer 'conv3' biases: 3.142598e-06 [1.923330e-09] 
Layer 'conv4' weights[0]: 7.978008e-03 [3.446655e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.722098e-08] 
Layer 'conv5' weights[0]: 7.976778e-03 [1.099404e-07] 
Layer 'conv5' biases: 9.999915e-01 [1.181028e-07] 
Layer 'fc6' weights[0]: 7.573361e-03 [9.039641e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.145111e-09] 
Layer 'fc7' weights[0]: 6.914844e-03 [6.992433e-08] 
Layer 'fc7' biases: 9.998550e-01 [5.505455e-08] 
Layer 'fc8' weights[0]: 1.244998e-03 [2.602876e-06] 
Layer 'fc8' biases: 7.257184e-02 [1.644868e-05] 
Train error last 870 batches: 0.435188
-------------------------------------------------------
Not saving because 0.420639 > 0.415650 (27.630: -0.00%)
======================================================= (12.079 sec)
29.741... logprob:  0.393475, 0.101562 (1.445 sec)
29.742... logprob:  0.419686, 0.109375 (1.493 sec)
29.743... logprob:  0.364893, 0.085938 (1.432 sec)
29.744... logprob:  0.519138, 0.148438 (1.434 sec)
29.745... logprob:  0.478130, 0.132812 (1.441 sec)
29.746... logprob:  0.440544, 0.117188 (1.426 sec)
29.747... logprob:  0.425602, 0.109375 (1.438 sec)
29.748... logprob:  0.378147, 0.093750 (1.485 sec)
29.749... logprob:  0.420804, 0.109375 (1.439 sec)
29.750... logprob:  0.512765, 0.140625 (1.445 sec)
29.751... logprob:  0.263716, 0.054688 (1.481 sec)
29.752... logprob:  0.522503, 0.140625 (1.430 sec)
29.753... logprob:  0.441151, 0.117188 (1.443 sec)
29.754... logprob:  0.468285, 0.132812 (1.438 sec)
29.755... logprob:  0.507044, 0.140625 (1.424 sec)
29.756... logprob:  0.440836, 0.117188 (1.440 sec)
29.757... logprob:  0.552474, 0.156250 (1.473 sec)
29.758... logprob:  0.393556, 0.101562 (1.448 sec)
29.759... logprob:  0.459700, 0.125000 (1.453 sec)
29.760... logprob:  0.485561, 0.132812 (1.465 sec)
29.761... logprob:  0.418149, 0.109375 (1.448 sec)
29.762... logprob:  0.516070, 0.148438 (1.444 sec)
29.763... logprob:  0.559003, 0.164062 (1.424 sec)
29.764... logprob:  0.503266, 0.140625 (1.433 sec)
29.765... logprob:  0.311684, 0.062500 (1.438 sec)
29.766... logprob:  0.482204, 0.132812 (1.454 sec)
29.767... logprob:  0.371071, 0.085938 (1.461 sec)
29.768... logprob:  0.432647, 0.117188 (1.464 sec)
29.769... logprob:  0.490792, 0.140625 (1.472 sec)
29.770... logprob:  0.402995, 0.101562 (1.479 sec)
29.771... logprob:  0.549369, 0.156250 (1.459 sec)
29.772... logprob:  0.414109, 0.109375 (1.445 sec)
29.773... logprob:  0.557633, 0.164062 (1.452 sec)
29.774... logprob:  0.361811, 0.085938 (1.457 sec)
29.775... logprob:  0.407403, 0.101562 (1.468 sec)
29.776... logprob:  0.433147, 0.117188 (1.495 sec)
29.777... logprob:  0.379986, 0.093750 (1.478 sec)
29.778... logprob:  0.433537, 0.117188 (1.466 sec)
29.779... logprob:  0.505313, 0.140625 (1.491 sec)
29.780... logprob:  0.385763, 0.101562 (1.455 sec)
29.781... logprob:  0.369627, 0.085938 (1.447 sec)
29.782... logprob:  0.351403, 0.085938 (1.453 sec)
29.783... logprob:  0.555536, 0.156250 (1.458 sec)
29.784... logprob:  0.440959, 0.117188 (1.461 sec)
29.785... logprob:  0.543739, 0.156250 (1.485 sec)
29.786... logprob:  0.477569, 0.132812 (1.471 sec)
29.787... logprob:  0.546533, 0.156250 (1.462 sec)
29.788... logprob:  0.563310, 0.164062 (1.496 sec)
29.789... logprob:  0.280599, 0.054688 (1.456 sec)
29.790... logprob:  0.407890, 0.101562 (1.449 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.996734619140625, 10.0]}, 128)
batch 872: ({'logprob': [65.91517639160156, 19.0]}, 128)
batch 873: ({'logprob': [41.9908561706543, 9.0]}, 128)
batch 874: ({'logprob': [46.23882293701172, 11.0]}, 128)
batch 875: ({'logprob': [51.366554260253906, 13.0]}, 128)
batch 876: ({'logprob': [63.59638595581055, 18.0]}, 128)
batch 877: ({'logprob': [46.6908073425293, 11.0]}, 128)
batch 878: ({'logprob': [61.67369079589844, 17.0]}, 128)
batch 879: ({'logprob': [72.37666320800781, 21.0]}, 128)
batch 880: ({'logprob': [51.39162826538086, 13.0]}, 128)
batch 881: ({'logprob': [31.251752853393555, 5.0]}, 128)
batch 882: ({'logprob': [55.06162643432617, 14.0]}, 128)
batch 883: ({'logprob': [61.64680862426758, 17.0]}, 128)
batch 884: ({'logprob': [51.8142204284668, 13.0]}, 128)
batch 885: ({'logprob': [52.69624710083008, 13.0]}, 128)
batch 886: ({'logprob': [62.10830307006836, 17.0]}, 128)

======================Test output======================
logprob:  0.419344, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.960018e-03 [3.288221e-09] 
Layer 'conv1' biases: 3.720139e-07 [1.257523e-10] 
Layer 'conv2' weights[0]: 7.947125e-03 [3.317703e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.371654e-10] 
Layer 'conv3' weights[0]: 7.945278e-03 [3.138103e-09] 
Layer 'conv3' biases: 3.151530e-06 [1.934326e-09] 
Layer 'conv4' weights[0]: 7.977965e-03 [3.144763e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.638585e-08] 
Layer 'conv5' weights[0]: 7.976730e-03 [1.022019e-07] 
Layer 'conv5' biases: 9.999915e-01 [1.099391e-07] 
Layer 'fc6' weights[0]: 7.573325e-03 [8.400747e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.513771e-09] 
Layer 'fc7' weights[0]: 6.913039e-03 [9.275330e-08] 
Layer 'fc7' biases: 9.998548e-01 [7.942995e-08] 
Layer 'fc8' weights[0]: 1.247604e-03 [2.950393e-06] 
Layer 'fc8' biases: 7.273830e-02 [1.639725e-05] 
Train error last 870 batches: 0.435188
-------------------------------------------------------
Not saving because 0.419344 > 0.415650 (27.630: -0.00%)
======================================================= (12.060 sec)
29.791... logprob:  0.397832, 0.101562 (1.458 sec)
29.792... logprob:  0.360887, 0.085938 (1.469 sec)
29.793... logprob:  0.370049, 0.085938 (1.451 sec)
29.794... logprob:  0.387122, 0.093750 (1.492 sec)
29.795... logprob:  0.469715, 0.125000 (1.470 sec)
29.796... logprob:  0.423512, 0.109375 (1.458 sec)
29.797... logprob:  0.358904, 0.085938 (1.498 sec)
29.798... logprob:  0.393301, 0.101562 (1.459 sec)
29.799... logprob:  0.332495, 0.078125 (1.451 sec)
29.800... logprob:  0.371690, 0.093750 (1.448 sec)
29.801... logprob:  0.449924, 0.117188 (1.457 sec)
29.802... logprob:  0.422856, 0.109375 (1.453 sec)
29.803... logprob:  0.491408, 0.132812 (1.497 sec)
29.804... logprob:  0.349946, 0.085938 (1.463 sec)
29.805... logprob:  0.452268, 0.117188 (1.458 sec)
29.806... logprob:  0.424174, 0.109375 (1.499 sec)
29.807... logprob:  0.443478, 0.117188 (1.458 sec)
29.808... logprob:  0.462367, 0.125000 (1.449 sec)
29.809... logprob:  0.589817, 0.171875 (1.485 sec)
29.810... logprob:  0.442495, 0.117188 (1.458 sec)
29.811... logprob:  0.460422, 0.125000 (1.457 sec)
29.812... logprob:  0.462330, 0.125000 (1.494 sec)
29.813... logprob:  0.485951, 0.132812 (1.465 sec)
29.814... logprob:  0.477911, 0.132812 (1.456 sec)
29.815... logprob:  0.371443, 0.085938 (1.501 sec)
29.816... logprob:  0.408470, 0.101562 (1.458 sec)
29.817... logprob:  0.425812, 0.109375 (1.453 sec)
29.818... logprob:  0.560014, 0.164062 (1.445 sec)
29.819... logprob:  0.498181, 0.140625 (1.463 sec)
29.820... logprob:  0.421680, 0.109375 (1.451 sec)
29.821... logprob:  0.406699, 0.101562 (1.501 sec)
29.822... logprob:  0.441273, 0.117188 (1.457 sec)
29.823... logprob:  0.341129, 0.078125 (1.457 sec)
29.824... logprob:  0.489651, 0.132812 (1.504 sec)
29.825... logprob:  0.288401, 0.062500 (1.451 sec)
29.826... logprob:  0.375590, 0.093750 (1.459 sec)
29.827... logprob:  0.420448, 0.109375 (1.447 sec)
29.828... logprob:  0.443157, 0.117188 (1.456 sec)
29.829... logprob:  0.503794, 0.140625 (1.454 sec)
29.830... logprob:  0.442043, 0.117188 (1.513 sec)
29.831... logprob:  0.513826, 0.140625 (1.454 sec)
29.832... logprob:  0.330842, 0.078125 (1.551 sec)
29.833... logprob:  0.489054, 0.132812 (1.491 sec)
29.834... logprob:  0.433384, 0.117188 (1.456 sec)
29.835... logprob:  0.542920, 0.148438 (1.457 sec)
29.836... logprob:  0.376079, 0.093750 (1.449 sec)
29.837... logprob:  0.313997, 0.070312 (1.456 sec)
29.838... logprob:  0.437068, 0.117188 (1.453 sec)
29.839... logprob:  0.471645, 0.125000 (1.502 sec)
29.840... logprob:  0.555572, 0.156250 (1.458 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.57171630859375, 10.0]}, 128)
batch 872: ({'logprob': [66.23330688476562, 19.0]}, 128)
batch 873: ({'logprob': [41.22259521484375, 9.0]}, 128)
batch 874: ({'logprob': [45.77902603149414, 11.0]}, 128)
batch 875: ({'logprob': [51.06229019165039, 13.0]}, 128)
batch 876: ({'logprob': [63.798954010009766, 18.0]}, 128)
batch 877: ({'logprob': [46.154266357421875, 11.0]}, 128)
batch 878: ({'logprob': [61.68312454223633, 17.0]}, 128)
batch 879: ({'logprob': [72.62445831298828, 21.0]}, 128)
batch 880: ({'logprob': [51.08780288696289, 13.0]}, 128)
batch 881: ({'logprob': [30.24479866027832, 5.0]}, 128)
batch 882: ({'logprob': [54.647403717041016, 14.0]}, 128)
batch 883: ({'logprob': [61.65617752075195, 17.0]}, 128)
batch 884: ({'logprob': [51.43592834472656, 13.0]}, 128)
batch 885: ({'logprob': [52.16624069213867, 13.0]}, 128)
batch 886: ({'logprob': [62.042850494384766, 17.0]}, 128)

======================Test output======================
logprob:  0.417193, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959981e-03 [4.811532e-09] 
Layer 'conv1' biases: 3.731152e-07 [1.083297e-10] 
Layer 'conv2' weights[0]: 7.947090e-03 [3.396434e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.689738e-10] 
Layer 'conv3' weights[0]: 7.945236e-03 [2.834896e-09] 
Layer 'conv3' biases: 3.159238e-06 [1.680976e-09] 
Layer 'conv4' weights[0]: 7.977927e-03 [2.901244e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.400065e-08] 
Layer 'conv5' weights[0]: 7.976693e-03 [9.098642e-08] 
Layer 'conv5' biases: 9.999914e-01 [9.767674e-08] 
Layer 'fc6' weights[0]: 7.573293e-03 [7.420830e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.562590e-09] 
Layer 'fc7' weights[0]: 6.911254e-03 [2.187481e-07] 
Layer 'fc7' biases: 9.998551e-01 [2.089468e-07] 
Layer 'fc8' weights[0]: 1.259284e-03 [7.147748e-06] 
Layer 'fc8' biases: 7.311407e-02 [4.787302e-05] 
Train error last 870 batches: 0.435187
-------------------------------------------------------
Not saving because 0.417193 > 0.415650 (27.630: -0.00%)
======================================================= (12.056 sec)
29.841... logprob:  0.395986, 0.101562 (1.494 sec)
29.842... logprob:  0.497897, 0.140625 (1.504 sec)
29.843... logprob:  0.465491, 0.125000 (1.459 sec)
29.844... logprob:  0.497674, 0.140625 (1.461 sec)
29.845... logprob:  0.486731, 0.132812 (1.451 sec)
29.846... logprob:  0.468389, 0.125000 (1.449 sec)
29.847... logprob:  0.363424, 0.085938 (1.457 sec)
29.848... logprob:  0.397248, 0.101562 (1.500 sec)
29.849... logprob:  0.360624, 0.085938 (1.455 sec)
29.850... logprob:  0.479368, 0.132812 (1.469 sec)
29.851... logprob:  0.440140, 0.117188 (1.490 sec)
29.852... logprob:  0.545312, 0.156250 (1.456 sec)
29.853... logprob:  0.372027, 0.093750 (1.462 sec)
29.854... logprob:  0.307435, 0.070312 (1.452 sec)
29.855... logprob:  0.484678, 0.132812 (1.446 sec)
29.856... logprob:  0.443691, 0.117188 (1.455 sec)
29.857... logprob:  0.372232, 0.093750 (1.494 sec)
29.858... logprob:  0.396245, 0.101562 (1.462 sec)
29.859... logprob:  0.308000, 0.070312 (1.474 sec)
29.860... logprob:  0.565971, 0.156250 (1.485 sec)
29.861... logprob:  0.417797, 0.109375 (1.461 sec)
29.862... logprob:  0.328826, 0.078125 (1.462 sec)
29.863... logprob:  0.399582, 0.101562 (1.445 sec)
29.864... logprob:  0.451506, 0.117188 (1.449 sec)
29.865... logprob:  0.484639, 0.132812 (1.455 sec)
29.866... logprob:  0.507828, 0.140625 (1.492 sec)
29.867... logprob:  0.503196, 0.140625 (1.467 sec)
29.868... logprob:  0.405197, 0.101562 (1.473 sec)
29.869... logprob:  0.383045, 0.093750 (1.482 sec)
29.870... logprob:  0.552273, 0.156250 (1.401 sec)
30.1... logprob:  0.379880, 0.093750 (1.405 sec)
30.2... logprob:  0.448240, 0.117188 (1.459 sec)
30.3... logprob:  0.398237, 0.101562 (1.421 sec)
30.4... logprob:  0.443286, 0.117188 (1.411 sec)
30.5... logprob:  0.443486, 0.117188 (1.434 sec)
30.6... logprob:  0.499042, 0.140625 (1.397 sec)
30.7... logprob:  0.363325, 0.085938 (1.429 sec)
30.8... logprob:  0.419175, 0.109375 (1.405 sec)
30.9... logprob:  0.358958, 0.085938 (1.404 sec)
30.10... logprob:  0.377632, 0.093750 (1.410 sec)
30.11... logprob:  0.334970, 0.078125 (1.448 sec)
30.12... logprob:  0.466237, 0.125000 (1.422 sec)
30.13... logprob:  0.442127, 0.117188 (1.424 sec)
30.14... logprob:  0.444491, 0.117188 (1.407 sec)
30.15... logprob:  0.395481, 0.101562 (1.410 sec)
30.16... logprob:  0.421339, 0.109375 (1.406 sec)
30.17... logprob:  0.515911, 0.140625 (1.401 sec)
30.18... logprob:  0.262122, 0.054688 (1.403 sec)
30.19... logprob:  0.279463, 0.062500 (1.408 sec)
30.20... logprob:  0.421361, 0.109375 (1.406 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.590179443359375, 10.0]}, 128)
batch 872: ({'logprob': [68.34834289550781, 19.0]}, 128)
batch 873: ({'logprob': [39.36237335205078, 9.0]}, 128)
batch 874: ({'logprob': [44.90169143676758, 11.0]}, 128)
batch 875: ({'logprob': [50.851524353027344, 13.0]}, 128)
batch 876: ({'logprob': [65.50366973876953, 18.0]}, 128)
batch 877: ({'logprob': [45.11817932128906, 11.0]}, 128)
batch 878: ({'logprob': [62.81597900390625, 17.0]}, 128)
batch 879: ({'logprob': [74.94435119628906, 21.0]}, 128)
batch 880: ({'logprob': [50.87952423095703, 13.0]}, 128)
batch 881: ({'logprob': [27.19491195678711, 5.0]}, 128)
batch 882: ({'logprob': [54.3880615234375, 14.0]}, 128)
batch 883: ({'logprob': [62.7873420715332, 17.0]}, 128)
batch 884: ({'logprob': [51.07675552368164, 13.0]}, 128)
batch 885: ({'logprob': [51.49549102783203, 13.0]}, 128)
batch 886: ({'logprob': [63.02332305908203, 17.0]}, 128)

======================Test output======================
logprob:  0.417130, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959939e-03 [3.578726e-09] 
Layer 'conv1' biases: 3.741181e-07 [5.411023e-11] 
Layer 'conv2' weights[0]: 7.947055e-03 [1.943976e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.602814e-10] 
Layer 'conv3' weights[0]: 7.945194e-03 [1.343695e-09] 
Layer 'conv3' biases: 3.165167e-06 [4.199509e-10] 
Layer 'conv4' weights[0]: 7.977890e-03 [1.313874e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.485653e-09] 
Layer 'conv5' weights[0]: 7.976638e-03 [9.059370e-09] 
Layer 'conv5' biases: 9.999909e-01 [9.500840e-09] 
Layer 'fc6' weights[0]: 7.573254e-03 [1.086923e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.426815e-10] 
Layer 'fc7' weights[0]: 6.909467e-03 [6.802911e-08] 
Layer 'fc7' biases: 9.998569e-01 [5.183788e-08] 
Layer 'fc8' weights[0]: 1.317472e-03 [1.862726e-06] 
Layer 'fc8' biases: 7.368829e-02 [1.384723e-05] 
Train error last 870 batches: 0.435187
-------------------------------------------------------
Not saving because 0.417130 > 0.415650 (27.630: -0.00%)
======================================================= (12.124 sec)
30.21... logprob:  0.443996, 0.117188 (1.412 sec)
30.22... logprob:  0.536818, 0.148438 (1.425 sec)
30.23... logprob:  0.533210, 0.148438 (1.420 sec)
30.24... logprob:  0.310430, 0.070312 (1.420 sec)
30.25... logprob:  0.356089, 0.085938 (1.403 sec)
30.26... logprob:  0.463832, 0.125000 (1.444 sec)
30.27... logprob:  0.404486, 0.101562 (1.395 sec)
30.28... logprob:  0.421842, 0.109375 (1.411 sec)
30.29... logprob:  0.395895, 0.101562 (1.422 sec)
30.30... logprob:  0.374029, 0.093750 (1.420 sec)
30.31... logprob:  0.479984, 0.132812 (1.408 sec)
30.32... logprob:  0.457222, 0.125000 (1.394 sec)
30.33... logprob:  0.460679, 0.125000 (1.451 sec)
30.34... logprob:  0.464511, 0.125000 (1.392 sec)
30.35... logprob:  0.316340, 0.070312 (1.408 sec)
30.36... logprob:  0.475792, 0.132812 (1.406 sec)
30.37... logprob:  0.417593, 0.109375 (1.410 sec)
30.38... logprob:  0.392710, 0.101562 (1.395 sec)
30.39... logprob:  0.631370, 0.187500 (1.438 sec)
30.40... logprob:  0.445659, 0.117188 (1.412 sec)
30.41... logprob:  0.353013, 0.085938 (1.432 sec)
30.42... logprob:  0.392032, 0.101562 (1.424 sec)
30.43... logprob:  0.440073, 0.117188 (1.404 sec)
30.44... logprob:  0.518565, 0.148438 (1.440 sec)
30.45... logprob:  0.381717, 0.093750 (1.395 sec)
30.46... logprob:  0.486159, 0.132812 (1.423 sec)
30.47... logprob:  0.331717, 0.078125 (1.401 sec)
30.48... logprob:  0.498944, 0.140625 (1.428 sec)
30.49... logprob:  0.510911, 0.148438 (1.416 sec)
30.50... logprob:  0.393178, 0.101562 (1.423 sec)
30.51... logprob:  0.490295, 0.140625 (1.420 sec)
30.52... logprob:  0.525792, 0.148438 (1.398 sec)
30.53... logprob:  0.294764, 0.062500 (1.447 sec)
30.54... logprob:  0.403420, 0.109375 (1.392 sec)
30.55... logprob:  0.331678, 0.078125 (1.396 sec)
30.56... logprob:  0.421601, 0.109375 (1.408 sec)
30.57... logprob:  0.572329, 0.164062 (1.430 sec)
30.58... logprob:  0.407519, 0.101562 (1.404 sec)
30.59... logprob:  0.333868, 0.078125 (1.467 sec)
30.60... logprob:  0.618695, 0.179688 (1.418 sec)
30.61... logprob:  0.382792, 0.093750 (1.429 sec)
30.62... logprob:  0.474835, 0.132812 (1.463 sec)
30.63... logprob:  0.397287, 0.101562 (1.443 sec)
30.64... logprob:  0.450333, 0.125000 (1.422 sec)
30.65... logprob:  0.373387, 0.093750 (1.404 sec)
30.66... logprob:  0.354045, 0.085938 (1.447 sec)
30.67... logprob:  0.295425, 0.062500 (1.393 sec)
30.68... logprob:  0.396798, 0.101562 (1.399 sec)
30.69... logprob:  0.496649, 0.140625 (1.423 sec)
30.70... logprob:  0.325908, 0.078125 (1.430 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.01356506347656, 10.0]}, 128)
batch 872: ({'logprob': [67.05301666259766, 19.0]}, 128)
batch 873: ({'logprob': [40.28333282470703, 9.0]}, 128)
batch 874: ({'logprob': [44.88463592529297, 11.0]}, 128)
batch 875: ({'logprob': [50.723045349121094, 13.0]}, 128)
batch 876: ({'logprob': [64.46965026855469, 18.0]}, 128)
batch 877: ({'logprob': [45.5138053894043, 11.0]}, 128)
batch 878: ({'logprob': [62.4577522277832, 17.0]}, 128)
batch 879: ({'logprob': [74.76670837402344, 21.0]}, 128)
batch 880: ({'logprob': [50.74907302856445, 13.0]}, 128)
batch 881: ({'logprob': [27.93421173095703, 5.0]}, 128)
batch 882: ({'logprob': [55.228572845458984, 14.0]}, 128)
batch 883: ({'logprob': [62.43028259277344, 17.0]}, 128)
batch 884: ({'logprob': [51.35665512084961, 13.0]}, 128)
batch 885: ({'logprob': [52.59844207763672, 13.0]}, 128)
batch 886: ({'logprob': [63.07549285888672, 17.0]}, 128)

======================Test output======================
logprob:  0.417255, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959900e-03 [2.662190e-09] 
Layer 'conv1' biases: 3.750160e-07 [7.350935e-11] 
Layer 'conv2' weights[0]: 7.947014e-03 [1.869512e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.722755e-10] 
Layer 'conv3' weights[0]: 7.945158e-03 [1.649222e-09] 
Layer 'conv3' biases: 3.172638e-06 [8.286437e-10] 
Layer 'conv4' weights[0]: 7.977857e-03 [1.674480e-09] 
Layer 'conv4' biases: 9.999991e-01 [6.925291e-09] 
Layer 'conv5' weights[0]: 7.976611e-03 [4.465751e-08] 
Layer 'conv5' biases: 9.999907e-01 [4.798768e-08] 
Layer 'fc6' weights[0]: 7.573220e-03 [3.757374e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.749637e-09] 
Layer 'fc7' weights[0]: 6.907660e-03 [1.585376e-07] 
Layer 'fc7' biases: 9.998567e-01 [1.475537e-07] 
Layer 'fc8' weights[0]: 1.303882e-03 [5.873730e-06] 
Layer 'fc8' biases: 7.361558e-02 [3.947854e-05] 
Train error last 870 batches: 0.435187
-------------------------------------------------------
Not saving because 0.417255 > 0.415650 (27.630: -0.00%)
======================================================= (12.065 sec)
30.71... logprob:  0.381797, 0.101562 (1.466 sec)
30.72... logprob:  0.493678, 0.132812 (1.414 sec)
30.73... logprob:  0.447673, 0.117188 (1.430 sec)
30.74... logprob:  0.442506, 0.117188 (1.415 sec)
30.75... logprob:  0.380658, 0.093750 (1.419 sec)
30.76... logprob:  0.412043, 0.109375 (1.437 sec)
30.77... logprob:  0.396344, 0.101562 (1.434 sec)
30.78... logprob:  0.493052, 0.140625 (1.453 sec)
30.79... logprob:  0.456479, 0.125000 (1.421 sec)
30.80... logprob:  0.508056, 0.132812 (1.428 sec)
30.81... logprob:  0.416724, 0.109375 (1.421 sec)
30.82... logprob:  0.231175, 0.039062 (1.428 sec)
30.83... logprob:  0.493835, 0.140625 (1.407 sec)
30.84... logprob:  0.468158, 0.125000 (1.464 sec)
30.85... logprob:  0.431914, 0.117188 (1.421 sec)
30.86... logprob:  0.416919, 0.109375 (1.418 sec)
30.87... logprob:  0.633319, 0.187500 (1.417 sec)
30.88... logprob:  0.535012, 0.156250 (1.414 sec)
30.89... logprob:  0.410536, 0.109375 (1.438 sec)
30.90... logprob:  0.577481, 0.171875 (1.390 sec)
30.91... logprob:  0.348408, 0.078125 (1.403 sec)
30.92... logprob:  0.464460, 0.125000 (1.407 sec)
30.93... logprob:  0.492200, 0.140625 (1.412 sec)
30.94... logprob:  0.428786, 0.109375 (1.403 sec)
30.95... logprob:  0.471832, 0.125000 (1.406 sec)
30.96... logprob:  0.576160, 0.171875 (1.408 sec)
30.97... logprob:  0.430793, 0.117188 (1.400 sec)
30.98... logprob:  0.391232, 0.093750 (1.436 sec)
30.99... logprob:  0.474208, 0.132812 (1.412 sec)
30.100... logprob:  0.310656, 0.070312 (1.411 sec)
30.101... logprob:  0.310971, 0.062500 (1.450 sec)
30.102... logprob:  0.545855, 0.156250 (1.394 sec)
30.103... logprob:  0.540860, 0.156250 (1.404 sec)
30.104... logprob:  0.388805, 0.101562 (1.403 sec)
30.105... logprob:  0.619207, 0.179688 (1.400 sec)
30.106... logprob:  0.344472, 0.085938 (1.392 sec)
30.107... logprob:  0.335806, 0.078125 (1.444 sec)
30.108... logprob:  0.586859, 0.171875 (1.400 sec)
30.109... logprob:  0.336117, 0.078125 (1.407 sec)
30.110... logprob:  0.564691, 0.164062 (1.397 sec)
30.111... logprob:  0.404658, 0.101562 (1.395 sec)
30.112... logprob:  0.365965, 0.093750 (1.400 sec)
30.113... logprob:  0.354390, 0.085938 (1.404 sec)
30.114... logprob:  0.440209, 0.117188 (1.438 sec)
30.115... logprob:  0.506795, 0.140625 (1.418 sec)
30.116... logprob:  0.393335, 0.101562 (1.401 sec)
30.117... logprob:  0.440393, 0.117188 (1.446 sec)
30.118... logprob:  0.409080, 0.101562 (1.392 sec)
30.119... logprob:  0.346070, 0.085938 (1.400 sec)
30.120... logprob:  0.547128, 0.156250 (1.409 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.69798278808594, 10.0]}, 128)
batch 872: ({'logprob': [66.4684829711914, 19.0]}, 128)
batch 873: ({'logprob': [40.686641693115234, 9.0]}, 128)
batch 874: ({'logprob': [45.237144470214844, 11.0]}, 128)
batch 875: ({'logprob': [50.780792236328125, 13.0]}, 128)
batch 876: ({'logprob': [63.971248626708984, 18.0]}, 128)
batch 877: ({'logprob': [45.745113372802734, 11.0]}, 128)
batch 878: ({'logprob': [61.92452621459961, 17.0]}, 128)
batch 879: ({'logprob': [73.52096557617188, 21.0]}, 128)
batch 880: ({'logprob': [50.80671310424805, 13.0]}, 128)
batch 881: ({'logprob': [29.051841735839844, 5.0]}, 128)
batch 882: ({'logprob': [54.83182907104492, 14.0]}, 128)
batch 883: ({'logprob': [61.897090911865234, 17.0]}, 128)
batch 884: ({'logprob': [51.29025650024414, 13.0]}, 128)
batch 885: ({'logprob': [52.28756332397461, 13.0]}, 128)
batch 886: ({'logprob': [62.418880462646484, 17.0]}, 128)

======================Test output======================
logprob:  0.416317, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959860e-03 [2.845057e-09] 
Layer 'conv1' biases: 3.761263e-07 [5.285102e-11] 
Layer 'conv2' weights[0]: 7.946973e-03 [2.050126e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.222307e-10] 
Layer 'conv3' weights[0]: 7.945116e-03 [1.865960e-09] 
Layer 'conv3' biases: 3.182007e-06 [1.083566e-09] 
Layer 'conv4' weights[0]: 7.977817e-03 [1.869540e-09] 
Layer 'conv4' biases: 9.999991e-01 [8.622839e-09] 
Layer 'conv5' weights[0]: 7.976583e-03 [5.494987e-08] 
Layer 'conv5' biases: 9.999911e-01 [5.900723e-08] 
Layer 'fc6' weights[0]: 7.573186e-03 [4.616403e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.603416e-09] 
Layer 'fc7' weights[0]: 6.905900e-03 [4.119103e-08] 
Layer 'fc7' biases: 9.998558e-01 [1.928880e-08] 
Layer 'fc8' weights[0]: 1.279326e-03 [8.329309e-07] 
Layer 'fc8' biases: 7.355379e-02 [5.155421e-06] 
Train error last 870 batches: 0.435187
-------------------------------------------------------
Not saving because 0.416317 > 0.415650 (27.630: -0.00%)
======================================================= (12.074 sec)
30.121... logprob:  0.412588, 0.109375 (1.409 sec)
30.122... logprob:  0.519247, 0.148438 (1.455 sec)
30.123... logprob:  0.463664, 0.125000 (1.393 sec)
30.124... logprob:  0.447687, 0.125000 (1.409 sec)
30.125... logprob:  0.501903, 0.140625 (1.407 sec)
30.126... logprob:  0.475725, 0.125000 (1.392 sec)
30.127... logprob:  0.479486, 0.125000 (1.398 sec)
30.128... logprob:  0.422328, 0.109375 (1.423 sec)
30.129... logprob:  0.574883, 0.164062 (1.417 sec)
30.130... logprob:  0.382696, 0.093750 (1.420 sec)
30.131... logprob:  0.495496, 0.132812 (1.407 sec)
30.132... logprob:  0.506358, 0.140625 (1.440 sec)
30.133... logprob:  0.444692, 0.117188 (1.396 sec)
30.134... logprob:  0.401867, 0.101562 (1.400 sec)
30.135... logprob:  0.460182, 0.125000 (1.409 sec)
30.136... logprob:  0.562355, 0.164062 (1.397 sec)
30.137... logprob:  0.462590, 0.125000 (1.391 sec)
30.138... logprob:  0.319412, 0.070312 (1.452 sec)
30.139... logprob:  0.395734, 0.101562 (1.404 sec)
30.140... logprob:  0.560021, 0.164062 (1.413 sec)
30.141... logprob:  0.464585, 0.125000 (1.434 sec)
30.142... logprob:  0.464642, 0.125000 (1.400 sec)
30.143... logprob:  0.294441, 0.062500 (1.427 sec)
30.144... logprob:  0.457020, 0.125000 (1.417 sec)
30.145... logprob:  0.324711, 0.078125 (1.419 sec)
30.146... logprob:  0.483066, 0.132812 (1.414 sec)
30.147... logprob:  0.262488, 0.054688 (1.436 sec)
30.148... logprob:  0.458592, 0.125000 (1.396 sec)
30.149... logprob:  0.442493, 0.117188 (1.404 sec)
30.150... logprob:  0.347570, 0.085938 (1.407 sec)
30.151... logprob:  0.347136, 0.085938 (1.402 sec)
30.152... logprob:  0.785136, 0.234375 (1.402 sec)
30.153... logprob:  0.381639, 0.093750 (1.445 sec)
30.154... logprob:  0.524716, 0.148438 (1.404 sec)
30.155... logprob:  0.426120, 0.117188 (1.449 sec)
30.156... logprob:  0.295166, 0.062500 (1.444 sec)
30.157... logprob:  0.270065, 0.054688 (1.399 sec)
30.158... logprob:  0.455446, 0.125000 (1.403 sec)
30.159... logprob:  0.483127, 0.132812 (1.400 sec)
30.160... logprob:  0.444697, 0.117188 (1.403 sec)
30.161... logprob:  0.349667, 0.078125 (1.420 sec)
30.162... logprob:  0.611790, 0.179688 (1.416 sec)
30.163... logprob:  0.450490, 0.125000 (1.436 sec)
30.164... logprob:  0.468513, 0.125000 (1.424 sec)
30.165... logprob:  0.547751, 0.156250 (1.419 sec)
30.166... logprob:  0.446159, 0.125000 (1.457 sec)
30.167... logprob:  0.350625, 0.085938 (1.437 sec)
30.168... logprob:  0.363754, 0.085938 (1.423 sec)
30.169... logprob:  0.408624, 0.101562 (1.465 sec)
30.170... logprob:  0.459460, 0.125000 (1.407 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.00543212890625, 10.0]}, 128)
batch 872: ({'logprob': [66.08326721191406, 19.0]}, 128)
batch 873: ({'logprob': [41.284584045410156, 9.0]}, 128)
batch 874: ({'logprob': [45.56361770629883, 11.0]}, 128)
batch 875: ({'logprob': [50.961334228515625, 13.0]}, 128)
batch 876: ({'logprob': [63.689964294433594, 18.0]}, 128)
batch 877: ({'logprob': [46.13457489013672, 11.0]}, 128)
batch 878: ({'logprob': [61.81064987182617, 17.0]}, 128)
batch 879: ({'logprob': [73.17436981201172, 21.0]}, 128)
batch 880: ({'logprob': [50.9868049621582, 13.0]}, 128)
batch 881: ({'logprob': [29.882701873779297, 5.0]}, 128)
batch 882: ({'logprob': [55.092830657958984, 14.0]}, 128)
batch 883: ({'logprob': [61.78338623046875, 17.0]}, 128)
batch 884: ({'logprob': [51.531036376953125, 13.0]}, 128)
batch 885: ({'logprob': [52.652530670166016, 13.0]}, 128)
batch 886: ({'logprob': [62.36623001098633, 17.0]}, 128)

======================Test output======================
logprob:  0.417482, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959821e-03 [2.399514e-09] 
Layer 'conv1' biases: 3.771234e-07 [6.616969e-11] 
Layer 'conv2' weights[0]: 7.946929e-03 [2.226879e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.575476e-10] 
Layer 'conv3' weights[0]: 7.945076e-03 [2.209840e-09] 
Layer 'conv3' biases: 3.191366e-06 [1.119979e-09] 
Layer 'conv4' weights[0]: 7.977781e-03 [2.235674e-09] 
Layer 'conv4' biases: 9.999991e-01 [9.445622e-09] 
Layer 'conv5' weights[0]: 7.976540e-03 [5.815437e-08] 
Layer 'conv5' biases: 9.999911e-01 [6.257329e-08] 
Layer 'fc6' weights[0]: 7.573142e-03 [4.884150e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.868942e-09] 
Layer 'fc7' weights[0]: 6.904180e-03 [1.488521e-07] 
Layer 'fc7' biases: 9.998554e-01 [1.376889e-07] 
Layer 'fc8' weights[0]: 1.269660e-03 [5.637003e-06] 
Layer 'fc8' biases: 7.358141e-02 [4.076831e-05] 
Train error last 870 batches: 0.435187
-------------------------------------------------------
Not saving because 0.417482 > 0.415650 (27.630: -0.00%)
======================================================= (12.054 sec)
30.171... logprob:  0.535211, 0.156250 (1.431 sec)
30.172... logprob:  0.434797, 0.109375 (1.423 sec)
30.173... logprob:  0.440465, 0.117188 (1.430 sec)
30.174... logprob:  0.600658, 0.171875 (1.401 sec)
30.175... logprob:  0.505928, 0.140625 (1.471 sec)
30.176... logprob:  0.478394, 0.132812 (1.420 sec)
30.177... logprob:  0.289723, 0.054688 (1.427 sec)
30.178... logprob:  0.383474, 0.093750 (1.458 sec)
30.179... logprob:  0.394659, 0.101562 (1.408 sec)
30.180... logprob:  0.466391, 0.125000 (1.435 sec)
30.181... logprob:  0.539269, 0.156250 (1.419 sec)
30.182... logprob:  0.371270, 0.093750 (1.422 sec)
30.183... logprob:  0.419931, 0.109375 (1.423 sec)
30.184... logprob:  0.483435, 0.132812 (1.426 sec)
30.185... logprob:  0.289738, 0.062500 (1.400 sec)
30.186... logprob:  0.370345, 0.093750 (1.396 sec)
30.187... logprob:  0.529616, 0.148438 (1.404 sec)
30.188... logprob:  0.458859, 0.125000 (1.401 sec)
30.189... logprob:  0.440922, 0.117188 (1.405 sec)
30.190... logprob:  0.375791, 0.093750 (1.436 sec)
30.191... logprob:  0.485094, 0.132812 (1.412 sec)
30.192... logprob:  0.520023, 0.148438 (1.414 sec)
30.193... logprob:  0.312481, 0.070312 (1.425 sec)
30.194... logprob:  0.414046, 0.109375 (1.422 sec)
30.195... logprob:  0.287009, 0.062500 (1.404 sec)
30.196... logprob:  0.410453, 0.109375 (1.397 sec)
30.197... logprob:  0.477981, 0.132812 (1.404 sec)
30.198... logprob:  0.355797, 0.085938 (1.412 sec)
30.199... logprob:  0.437194, 0.117188 (1.394 sec)
30.200... logprob:  0.440728, 0.117188 (1.447 sec)
30.201... logprob:  0.437088, 0.117188 (1.412 sec)
30.202... logprob:  0.537829, 0.148438 (1.410 sec)
30.203... logprob:  0.420403, 0.109375 (1.443 sec)
30.204... logprob:  0.504123, 0.140625 (1.403 sec)
30.205... logprob:  0.334274, 0.078125 (1.404 sec)
30.206... logprob:  0.361636, 0.093750 (1.412 sec)
30.207... logprob:  0.381755, 0.093750 (1.399 sec)
30.208... logprob:  0.490590, 0.140625 (1.400 sec)
30.209... logprob:  0.334532, 0.078125 (1.428 sec)
30.210... logprob:  0.586225, 0.171875 (1.415 sec)
30.211... logprob:  0.488118, 0.132812 (1.422 sec)
30.212... logprob:  0.526115, 0.148438 (1.408 sec)
30.213... logprob:  0.514603, 0.140625 (1.464 sec)
30.214... logprob:  0.459389, 0.125000 (1.426 sec)
30.215... logprob:  0.396085, 0.101562 (1.419 sec)
30.216... logprob:  0.516903, 0.140625 (1.476 sec)
30.217... logprob:  0.324839, 0.070312 (1.406 sec)
30.218... logprob:  0.463578, 0.125000 (1.429 sec)
30.219... logprob:  0.500223, 0.140625 (1.416 sec)
30.220... logprob:  0.415030, 0.109375 (1.425 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.5536003112793, 10.0]}, 128)
batch 872: ({'logprob': [66.00114440917969, 19.0]}, 128)
batch 873: ({'logprob': [41.57361602783203, 9.0]}, 128)
batch 874: ({'logprob': [45.892948150634766, 11.0]}, 128)
batch 875: ({'logprob': [51.1402473449707, 13.0]}, 128)
batch 876: ({'logprob': [63.63539123535156, 18.0]}, 128)
batch 877: ({'logprob': [46.36906814575195, 11.0]}, 128)
batch 878: ({'logprob': [61.68865203857422, 17.0]}, 128)
batch 879: ({'logprob': [72.65621185302734, 21.0]}, 128)
batch 880: ({'logprob': [51.166038513183594, 13.0]}, 128)
batch 881: ({'logprob': [30.56878662109375, 5.0]}, 128)
batch 882: ({'logprob': [54.9576301574707, 14.0]}, 128)
batch 883: ({'logprob': [61.66109085083008, 17.0]}, 128)
batch 884: ({'logprob': [51.61368179321289, 13.0]}, 128)
batch 885: ({'logprob': [52.54437255859375, 13.0]}, 128)
batch 886: ({'logprob': [62.148277282714844, 17.0]}, 128)

======================Test output======================
logprob:  0.418052, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959777e-03 [3.002647e-09] 
Layer 'conv1' biases: 3.781969e-07 [8.410282e-11] 
Layer 'conv2' weights[0]: 7.946887e-03 [2.352305e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.745335e-10] 
Layer 'conv3' weights[0]: 7.945040e-03 [2.119656e-09] 
Layer 'conv3' biases: 3.201439e-06 [1.100479e-09] 
Layer 'conv4' weights[0]: 7.977746e-03 [2.169733e-09] 
Layer 'conv4' biases: 9.999991e-01 [9.806956e-09] 
Layer 'conv5' weights[0]: 7.976501e-03 [6.297102e-08] 
Layer 'conv5' biases: 9.999912e-01 [6.762333e-08] 
Layer 'fc6' weights[0]: 7.573102e-03 [5.193242e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.245214e-09] 
Layer 'fc7' weights[0]: 6.902391e-03 [1.011540e-07] 
Layer 'fc7' biases: 9.998548e-01 [8.722457e-08] 
Layer 'fc8' weights[0]: 1.261251e-03 [5.461699e-06] 
Layer 'fc8' biases: 7.359560e-02 [3.901184e-05] 
Train error last 870 batches: 0.435186
-------------------------------------------------------
Not saving because 0.418052 > 0.415650 (27.630: -0.00%)
======================================================= (12.042 sec)
30.221... logprob:  0.399574, 0.101562 (1.411 sec)
30.222... logprob:  0.554390, 0.164062 (1.501 sec)
30.223... logprob:  0.568912, 0.164062 (1.440 sec)
30.224... logprob:  0.405988, 0.101562 (1.444 sec)
30.225... logprob:  0.392011, 0.101562 (1.443 sec)
30.226... logprob:  0.424755, 0.109375 (1.429 sec)
30.227... logprob:  0.452616, 0.125000 (1.419 sec)
30.228... logprob:  0.417168, 0.109375 (1.422 sec)
30.229... logprob:  0.489371, 0.132812 (1.416 sec)
30.230... logprob:  0.459846, 0.125000 (1.428 sec)
30.231... logprob:  0.453481, 0.125000 (1.409 sec)
30.232... logprob:  0.496153, 0.140625 (1.457 sec)
30.233... logprob:  0.466050, 0.132812 (1.431 sec)
30.234... logprob:  0.563872, 0.164062 (1.425 sec)
30.235... logprob:  0.482011, 0.132812 (1.472 sec)
30.236... logprob:  0.425635, 0.109375 (1.409 sec)
30.237... logprob:  0.340894, 0.078125 (1.427 sec)
30.238... logprob:  0.389085, 0.093750 (1.422 sec)
30.239... logprob:  0.478083, 0.132812 (1.424 sec)
30.240... logprob:  0.485795, 0.132812 (1.399 sec)
30.241... logprob:  0.493601, 0.132812 (1.462 sec)
30.242... logprob:  0.341628, 0.078125 (1.427 sec)
30.243... logprob:  0.385993, 0.093750 (1.431 sec)
30.244... logprob:  0.315432, 0.070312 (1.454 sec)
30.245... logprob:  0.494199, 0.132812 (1.429 sec)
30.246... logprob:  0.416841, 0.109375 (1.416 sec)
30.247... logprob:  0.357594, 0.085938 (1.416 sec)
30.248... logprob:  0.308085, 0.070312 (1.422 sec)
30.249... logprob:  0.554486, 0.156250 (1.428 sec)
30.250... logprob:  0.591127, 0.164062 (1.409 sec)
30.251... logprob:  0.353002, 0.085938 (1.459 sec)
30.252... logprob:  0.348430, 0.085938 (1.425 sec)
30.253... logprob:  0.379229, 0.093750 (1.426 sec)
30.254... logprob:  0.444156, 0.117188 (1.473 sec)
30.255... logprob:  0.351313, 0.085938 (1.405 sec)
30.256... logprob:  0.378872, 0.093750 (1.423 sec)
30.257... logprob:  0.331964, 0.078125 (1.421 sec)
30.258... logprob:  0.415501, 0.109375 (1.424 sec)
30.259... logprob:  0.442318, 0.117188 (1.405 sec)
30.260... logprob:  0.308170, 0.070312 (1.459 sec)
30.261... logprob:  0.392541, 0.101562 (1.432 sec)
30.262... logprob:  0.524502, 0.148438 (1.437 sec)
30.263... logprob:  0.425605, 0.109375 (1.448 sec)
30.264... logprob:  0.375013, 0.093750 (1.462 sec)
30.265... logprob:  0.439610, 0.117188 (1.420 sec)
30.266... logprob:  0.439006, 0.117188 (1.420 sec)
30.267... logprob:  0.422039, 0.109375 (1.416 sec)
30.268... logprob:  0.458940, 0.125000 (1.428 sec)
30.269... logprob:  0.567587, 0.164062 (1.415 sec)
30.270... logprob:  0.542347, 0.156250 (1.459 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.6594352722168, 10.0]}, 128)
batch 872: ({'logprob': [66.29923248291016, 19.0]}, 128)
batch 873: ({'logprob': [41.18247985839844, 9.0]}, 128)
batch 874: ({'logprob': [45.805580139160156, 11.0]}, 128)
batch 875: ({'logprob': [51.079341888427734, 13.0]}, 128)
batch 876: ({'logprob': [63.85140609741211, 18.0]}, 128)
batch 877: ({'logprob': [46.143341064453125, 11.0]}, 128)
batch 878: ({'logprob': [61.68310546875, 17.0]}, 128)
batch 879: ({'logprob': [72.56847381591797, 21.0]}, 128)
batch 880: ({'logprob': [51.1058235168457, 13.0]}, 128)
batch 881: ({'logprob': [30.2602481842041, 5.0]}, 128)
batch 882: ({'logprob': [54.566261291503906, 14.0]}, 128)
batch 883: ({'logprob': [61.65522003173828, 17.0]}, 128)
batch 884: ({'logprob': [51.41587448120117, 13.0]}, 128)
batch 885: ({'logprob': [52.0702018737793, 13.0]}, 128)
batch 886: ({'logprob': [62.00503921508789, 17.0]}, 128)

======================Test output======================
logprob:  0.417164, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959740e-03 [5.464583e-09] 
Layer 'conv1' biases: 3.793822e-07 [1.711324e-10] 
Layer 'conv2' weights[0]: 7.946846e-03 [4.648456e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.621646e-10] 
Layer 'conv3' weights[0]: 7.944995e-03 [4.316558e-09] 
Layer 'conv3' biases: 3.210888e-06 [2.867749e-09] 
Layer 'conv4' weights[0]: 7.977708e-03 [4.345200e-09] 
Layer 'conv4' biases: 9.999991e-01 [2.381296e-08] 
Layer 'conv5' weights[0]: 7.976478e-03 [1.488582e-07] 
Layer 'conv5' biases: 9.999915e-01 [1.601431e-07] 
Layer 'fc6' weights[0]: 7.573061e-03 [1.215383e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.246281e-08] 
Layer 'fc7' weights[0]: 6.900635e-03 [3.325501e-07] 
Layer 'fc7' biases: 9.998547e-01 [3.243214e-07] 
Layer 'fc8' weights[0]: 1.270923e-03 [1.300780e-05] 
Layer 'fc8' biases: 7.375048e-02 [8.821060e-05] 
Train error last 870 batches: 0.435186
-------------------------------------------------------
Not saving because 0.417164 > 0.415650 (27.630: -0.00%)
======================================================= (12.022 sec)
30.271... logprob:  0.445587, 0.117188 (1.433 sec)
30.272... logprob:  0.384543, 0.093750 (1.425 sec)
30.273... logprob:  0.500235, 0.140625 (1.471 sec)
30.274... logprob:  0.542498, 0.156250 (1.405 sec)
30.275... logprob:  0.487559, 0.132812 (1.430 sec)
30.276... logprob:  0.389993, 0.093750 (1.422 sec)
30.277... logprob:  0.428590, 0.109375 (1.422 sec)
30.278... logprob:  0.323640, 0.070312 (1.428 sec)
30.279... logprob:  0.325314, 0.070312 (1.472 sec)
30.280... logprob:  0.216095, 0.031250 (1.405 sec)
30.281... logprob:  0.417257, 0.109375 (1.424 sec)
30.282... logprob:  0.411305, 0.109375 (1.421 sec)
30.283... logprob:  0.393718, 0.101562 (1.418 sec)
30.284... logprob:  0.394347, 0.101562 (1.413 sec)
30.285... logprob:  0.451330, 0.117188 (1.448 sec)
30.286... logprob:  0.536170, 0.140625 (1.438 sec)
30.287... logprob:  0.346516, 0.085938 (1.431 sec)
30.288... logprob:  0.329940, 0.078125 (1.440 sec)
30.289... logprob:  0.445773, 0.117188 (1.443 sec)
30.290... logprob:  0.490644, 0.132812 (1.419 sec)
30.291... logprob:  0.439337, 0.117188 (1.418 sec)
30.292... logprob:  0.567766, 0.156250 (1.420 sec)
30.293... logprob:  0.427784, 0.117188 (1.430 sec)
30.294... logprob:  0.355691, 0.085938 (1.407 sec)
30.295... logprob:  0.334260, 0.078125 (1.479 sec)
30.296... logprob:  0.355399, 0.085938 (1.421 sec)
30.297... logprob:  0.394304, 0.101562 (1.459 sec)
30.298... logprob:  0.448261, 0.125000 (1.464 sec)
30.299... logprob:  0.341873, 0.078125 (1.401 sec)
30.300... logprob:  0.406331, 0.101562 (1.427 sec)
30.301... logprob:  0.397872, 0.101562 (1.417 sec)
30.302... logprob:  0.591602, 0.179688 (1.417 sec)
30.303... logprob:  0.459477, 0.125000 (1.413 sec)
30.304... logprob:  0.459608, 0.125000 (1.439 sec)
30.305... logprob:  0.455192, 0.125000 (1.442 sec)
30.306... logprob:  0.440571, 0.117188 (1.432 sec)
30.307... logprob:  0.421627, 0.109375 (1.449 sec)
30.308... logprob:  0.374862, 0.093750 (1.462 sec)
30.309... logprob:  0.450481, 0.125000 (1.415 sec)
30.310... logprob:  0.473564, 0.125000 (1.426 sec)
30.311... logprob:  0.502441, 0.140625 (1.423 sec)
30.312... logprob:  0.478663, 0.132812 (1.435 sec)
30.313... logprob:  0.454856, 0.125000 (1.423 sec)
30.314... logprob:  0.454336, 0.117188 (1.468 sec)
30.315... logprob:  0.314684, 0.070312 (1.435 sec)
30.316... logprob:  0.468502, 0.125000 (1.423 sec)
30.317... logprob:  0.355422, 0.085938 (1.481 sec)
30.318... logprob:  0.455400, 0.125000 (1.412 sec)
30.319... logprob:  0.423163, 0.117188 (1.428 sec)
30.320... logprob:  0.412232, 0.109375 (1.429 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.46936798095703, 10.0]}, 128)
batch 872: ({'logprob': [66.55268859863281, 19.0]}, 128)
batch 873: ({'logprob': [40.618404388427734, 9.0]}, 128)
batch 874: ({'logprob': [45.131343841552734, 11.0]}, 128)
batch 875: ({'logprob': [50.750694274902344, 13.0]}, 128)
batch 876: ({'logprob': [64.04598236083984, 18.0]}, 128)
batch 877: ({'logprob': [45.69572448730469, 11.0]}, 128)
batch 878: ({'logprob': [62.046043395996094, 17.0]}, 128)
batch 879: ({'logprob': [73.84999084472656, 21.0]}, 128)
batch 880: ({'logprob': [50.77682876586914, 13.0]}, 128)
batch 881: ({'logprob': [28.77531623840332, 5.0]}, 128)
batch 882: ({'logprob': [54.98127365112305, 14.0]}, 128)
batch 883: ({'logprob': [62.01841735839844, 17.0]}, 128)
batch 884: ({'logprob': [51.31709289550781, 13.0]}, 128)
batch 885: ({'logprob': [52.42736053466797, 13.0]}, 128)
batch 886: ({'logprob': [62.597232818603516, 17.0]}, 128)

======================Test output======================
logprob:  0.416530, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959696e-03 [2.379825e-09] 
Layer 'conv1' biases: 3.803929e-07 [3.938124e-11] 
Layer 'conv2' weights[0]: 7.946810e-03 [1.808928e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.813252e-10] 
Layer 'conv3' weights[0]: 7.944952e-03 [1.378678e-09] 
Layer 'conv3' biases: 3.216174e-06 [5.226937e-10] 
Layer 'conv4' weights[0]: 7.977663e-03 [1.474519e-09] 
Layer 'conv4' biases: 9.999991e-01 [3.914286e-09] 
Layer 'conv5' weights[0]: 7.976422e-03 [2.463783e-08] 
Layer 'conv5' biases: 9.999907e-01 [2.637721e-08] 
Layer 'fc6' weights[0]: 7.573020e-03 [2.187524e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.044433e-09] 
Layer 'fc7' weights[0]: 6.898883e-03 [1.199178e-07] 
Layer 'fc7' biases: 9.998558e-01 [1.063562e-07] 
Layer 'fc8' weights[0]: 1.291150e-03 [3.757910e-06] 
Layer 'fc8' biases: 7.418341e-02 [2.678711e-05] 
Train error last 870 batches: 0.435186
-------------------------------------------------------
Not saving because 0.416530 > 0.415650 (27.630: -0.00%)
======================================================= (12.103 sec)
30.321... logprob:  0.348233, 0.085938 (1.441 sec)
30.322... logprob:  0.387431, 0.101562 (1.426 sec)
30.323... logprob:  0.416501, 0.109375 (1.477 sec)
30.324... logprob:  0.498595, 0.140625 (1.425 sec)
30.325... logprob:  0.350672, 0.085938 (1.440 sec)
30.326... logprob:  0.543181, 0.148438 (1.464 sec)
30.327... logprob:  0.554419, 0.164062 (1.426 sec)
30.328... logprob:  0.565146, 0.156250 (1.440 sec)
30.329... logprob:  0.401906, 0.101562 (1.420 sec)
30.330... logprob:  0.388490, 0.101562 (1.460 sec)
30.331... logprob:  0.352234, 0.085938 (1.418 sec)
30.332... logprob:  0.482782, 0.132812 (1.455 sec)
30.333... logprob:  0.339455, 0.085938 (1.442 sec)
30.334... logprob:  0.565306, 0.171875 (1.442 sec)
30.335... logprob:  0.358672, 0.085938 (1.444 sec)
30.336... logprob:  0.444861, 0.125000 (1.457 sec)
30.337... logprob:  0.566398, 0.164062 (1.419 sec)
30.338... logprob:  0.449515, 0.125000 (1.429 sec)
30.339... logprob:  0.488579, 0.132812 (1.432 sec)
30.340... logprob:  0.442064, 0.117188 (1.432 sec)
30.341... logprob:  0.530017, 0.148438 (1.419 sec)
30.342... logprob:  0.429599, 0.109375 (1.465 sec)
30.343... logprob:  0.434765, 0.109375 (1.444 sec)
30.344... logprob:  0.444530, 0.125000 (1.479 sec)
30.345... logprob:  0.488182, 0.132812 (1.445 sec)
30.346... logprob:  0.436206, 0.117188 (1.435 sec)
30.347... logprob:  0.372557, 0.085938 (1.490 sec)
30.348... logprob:  0.398493, 0.101562 (1.439 sec)
30.349... logprob:  0.497578, 0.140625 (1.437 sec)
30.350... logprob:  0.358721, 0.085938 (1.438 sec)
30.351... logprob:  0.508475, 0.140625 (1.430 sec)
30.352... logprob:  0.363609, 0.093750 (1.431 sec)
30.353... logprob:  0.512426, 0.148438 (1.494 sec)
30.354... logprob:  0.674768, 0.203125 (1.433 sec)
30.355... logprob:  0.357501, 0.085938 (1.448 sec)
30.356... logprob:  0.479238, 0.132812 (1.475 sec)
30.357... logprob:  0.346712, 0.085938 (1.437 sec)
30.358... logprob:  0.325733, 0.070312 (1.437 sec)
30.359... logprob:  0.555390, 0.164062 (1.439 sec)
30.360... logprob:  0.444524, 0.117188 (1.434 sec)
30.361... logprob:  0.410730, 0.101562 (1.437 sec)
30.362... logprob:  0.423931, 0.117188 (1.476 sec)
30.363... logprob:  0.486594, 0.132812 (1.454 sec)
30.364... logprob:  0.475619, 0.125000 (1.450 sec)
30.365... logprob:  0.425038, 0.109375 (1.471 sec)
30.366... logprob:  0.409559, 0.109375 (1.441 sec)
30.367... logprob:  0.324893, 0.078125 (1.444 sec)
30.368... logprob:  0.595547, 0.171875 (1.431 sec)
30.369... logprob:  0.381670, 0.093750 (1.426 sec)
30.370... logprob:  0.381305, 0.093750 (1.442 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.83967971801758, 10.0]}, 128)
batch 872: ({'logprob': [66.48236083984375, 19.0]}, 128)
batch 873: ({'logprob': [40.67153549194336, 9.0]}, 128)
batch 874: ({'logprob': [45.28736114501953, 11.0]}, 128)
batch 875: ({'logprob': [50.79692077636719, 13.0]}, 128)
batch 876: ({'logprob': [63.97757339477539, 18.0]}, 128)
batch 877: ({'logprob': [45.74593734741211, 11.0]}, 128)
batch 878: ({'logprob': [61.873355865478516, 17.0]}, 128)
batch 879: ({'logprob': [73.35234832763672, 21.0]}, 128)
batch 880: ({'logprob': [50.823524475097656, 13.0]}, 128)
batch 881: ({'logprob': [29.15415382385254, 5.0]}, 128)
batch 882: ({'logprob': [54.70732498168945, 14.0]}, 128)
batch 883: ({'logprob': [61.84537124633789, 17.0]}, 128)
batch 884: ({'logprob': [51.25691604614258, 13.0]}, 128)
batch 885: ({'logprob': [52.15484619140625, 13.0]}, 128)
batch 886: ({'logprob': [62.318023681640625, 17.0]}, 128)

======================Test output======================
logprob:  0.416156, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959655e-03 [2.830268e-09] 
Layer 'conv1' biases: 3.813565e-07 [7.005451e-11] 
Layer 'conv2' weights[0]: 7.946776e-03 [2.321789e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.592021e-10] 
Layer 'conv3' weights[0]: 7.944912e-03 [2.144245e-09] 
Layer 'conv3' biases: 3.224991e-06 [1.125053e-09] 
Layer 'conv4' weights[0]: 7.977626e-03 [2.122708e-09] 
Layer 'conv4' biases: 9.999991e-01 [9.140814e-09] 
Layer 'conv5' weights[0]: 7.976386e-03 [5.400407e-08] 
Layer 'conv5' biases: 9.999910e-01 [5.808536e-08] 
Layer 'fc6' weights[0]: 7.572983e-03 [4.556601e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.543625e-09] 
Layer 'fc7' weights[0]: 6.897126e-03 [1.032901e-07] 
Layer 'fc7' biases: 9.998553e-01 [8.933640e-08] 
Layer 'fc8' weights[0]: 1.285181e-03 [6.493340e-06] 
Layer 'fc8' biases: 7.423588e-02 [4.496592e-05] 
Train error last 870 batches: 0.435185
-------------------------------------------------------
Not saving because 0.416156 > 0.415650 (27.630: -0.00%)
======================================================= (12.047 sec)
30.371... logprob:  0.400429, 0.101562 (1.463 sec)
30.372... logprob:  0.537204, 0.156250 (1.462 sec)
30.373... logprob:  0.463784, 0.125000 (1.453 sec)
30.374... logprob:  0.526802, 0.148438 (1.456 sec)
30.375... logprob:  0.393766, 0.101562 (1.462 sec)
30.376... logprob:  0.374287, 0.093750 (1.445 sec)
30.377... logprob:  0.295442, 0.062500 (1.429 sec)
30.378... logprob:  0.453656, 0.125000 (1.436 sec)
30.379... logprob:  0.420244, 0.109375 (1.439 sec)
30.380... logprob:  0.605663, 0.179688 (1.437 sec)
30.381... logprob:  0.463409, 0.125000 (1.475 sec)
30.382... logprob:  0.529587, 0.148438 (1.452 sec)
30.383... logprob:  0.358518, 0.085938 (1.440 sec)
30.384... logprob:  0.521227, 0.148438 (1.486 sec)
30.385... logprob:  0.523596, 0.148438 (1.432 sec)
30.386... logprob:  0.582603, 0.171875 (1.430 sec)
30.387... logprob:  0.428492, 0.117188 (1.436 sec)
30.388... logprob:  0.521386, 0.148438 (1.435 sec)
30.389... logprob:  0.425542, 0.109375 (1.439 sec)
30.390... logprob:  0.419645, 0.109375 (1.476 sec)
30.391... logprob:  0.318120, 0.070312 (1.444 sec)
30.392... logprob:  0.439451, 0.117188 (1.438 sec)
30.393... logprob:  0.369042, 0.093750 (1.484 sec)
30.394... logprob:  0.343725, 0.078125 (1.439 sec)
30.395... logprob:  0.331938, 0.078125 (1.434 sec)
30.396... logprob:  0.252662, 0.046875 (1.432 sec)
30.397... logprob:  0.484036, 0.132812 (1.438 sec)
30.398... logprob:  0.470593, 0.125000 (1.433 sec)
30.399... logprob:  0.433102, 0.117188 (1.483 sec)
30.400... logprob:  0.537315, 0.148438 (1.439 sec)
30.401... logprob:  0.465572, 0.125000 (1.443 sec)
30.402... logprob:  0.473771, 0.125000 (1.482 sec)
30.403... logprob:  0.462075, 0.125000 (1.435 sec)
30.404... logprob:  0.474798, 0.125000 (1.437 sec)
30.405... logprob:  0.544309, 0.156250 (1.432 sec)
30.406... logprob:  0.357507, 0.085938 (1.434 sec)
30.407... logprob:  0.493070, 0.140625 (1.433 sec)
30.408... logprob:  0.338762, 0.078125 (1.484 sec)
30.409... logprob:  0.400341, 0.101562 (1.438 sec)
30.410... logprob:  0.582368, 0.171875 (1.454 sec)
30.411... logprob:  0.397668, 0.101562 (1.484 sec)
30.412... logprob:  0.540336, 0.156250 (1.444 sec)
30.413... logprob:  0.544655, 0.156250 (1.437 sec)
30.414... logprob:  0.466347, 0.125000 (1.436 sec)
30.415... logprob:  0.401629, 0.101562 (1.422 sec)
30.416... logprob:  0.427479, 0.109375 (1.443 sec)
30.417... logprob:  0.405464, 0.093750 (1.465 sec)
30.418... logprob:  0.380502, 0.093750 (1.453 sec)
30.419... logprob:  0.417914, 0.101562 (1.457 sec)
30.420... logprob:  0.356551, 0.085938 (1.453 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.720542907714844, 10.0]}, 128)
batch 872: ({'logprob': [66.39491271972656, 19.0]}, 128)
batch 873: ({'logprob': [40.78367614746094, 9.0]}, 128)
batch 874: ({'logprob': [45.27769088745117, 11.0]}, 128)
batch 875: ({'logprob': [50.802276611328125, 13.0]}, 128)
batch 876: ({'logprob': [63.91657257080078, 18.0]}, 128)
batch 877: ({'logprob': [45.80448532104492, 11.0]}, 128)
batch 878: ({'logprob': [61.90753936767578, 17.0]}, 128)
batch 879: ({'logprob': [73.48355865478516, 21.0]}, 128)
batch 880: ({'logprob': [50.82843017578125, 13.0]}, 128)
batch 881: ({'logprob': [29.169198989868164, 5.0]}, 128)
batch 882: ({'logprob': [54.89004135131836, 14.0]}, 128)
batch 883: ({'logprob': [61.879886627197266, 17.0]}, 128)
batch 884: ({'logprob': [51.330196380615234, 13.0]}, 128)
batch 885: ({'logprob': [52.36444091796875, 13.0]}, 128)
batch 886: ({'logprob': [62.42036437988281, 17.0]}, 128)

======================Test output======================
logprob:  0.416491, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959614e-03 [4.091545e-09] 
Layer 'conv1' biases: 3.823497e-07 [2.002687e-10] 
Layer 'conv2' weights[0]: 7.946735e-03 [4.701476e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.726768e-10] 
Layer 'conv3' weights[0]: 7.944876e-03 [4.664145e-09] 
Layer 'conv3' biases: 3.229459e-06 [2.837940e-09] 
Layer 'conv4' weights[0]: 7.977584e-03 [4.554614e-09] 
Layer 'conv4' biases: 9.999991e-01 [2.401871e-08] 
Layer 'conv5' weights[0]: 7.976329e-03 [1.490607e-07] 
Layer 'conv5' biases: 9.999903e-01 [1.605136e-07] 
Layer 'fc6' weights[0]: 7.572944e-03 [1.216238e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.247536e-08] 
Layer 'fc7' weights[0]: 6.895384e-03 [3.996674e-07] 
Layer 'fc7' biases: 9.998554e-01 [3.891758e-07] 
Layer 'fc8' weights[0]: 1.279448e-03 [1.758034e-05] 
Layer 'fc8' biases: 7.446936e-02 [1.265598e-04] 
Train error last 870 batches: 0.435185
-------------------------------------------------------
Not saving because 0.416491 > 0.415650 (27.630: -0.00%)
======================================================= (12.035 sec)
30.421... logprob:  0.376673, 0.101562 (1.461 sec)
30.422... logprob:  0.521965, 0.148438 (1.451 sec)
30.423... logprob:  0.420777, 0.109375 (1.429 sec)
30.424... logprob:  0.324950, 0.078125 (1.437 sec)
30.425... logprob:  0.306557, 0.070312 (1.440 sec)
30.426... logprob:  0.448974, 0.117188 (1.452 sec)
30.427... logprob:  0.553919, 0.156250 (1.465 sec)
30.428... logprob:  0.601456, 0.171875 (1.451 sec)
30.429... logprob:  0.426357, 0.109375 (1.450 sec)
30.430... logprob:  0.299751, 0.070312 (1.471 sec)
30.431... logprob:  0.600130, 0.171875 (1.441 sec)
30.432... logprob:  0.387518, 0.093750 (1.424 sec)
30.433... logprob:  0.329543, 0.078125 (1.437 sec)
30.434... logprob:  0.529709, 0.148438 (1.443 sec)
30.435... logprob:  0.532582, 0.156250 (1.434 sec)
30.436... logprob:  0.380862, 0.093750 (1.475 sec)
30.437... logprob:  0.500346, 0.140625 (1.475 sec)
30.438... logprob:  0.547030, 0.156250 (1.430 sec)
30.439... logprob:  0.378513, 0.093750 (1.493 sec)
30.440... logprob:  0.439626, 0.117188 (1.436 sec)
30.441... logprob:  0.467938, 0.125000 (1.429 sec)
30.442... logprob:  0.378921, 0.093750 (1.439 sec)
30.443... logprob:  0.496557, 0.140625 (1.429 sec)
30.444... logprob:  0.372448, 0.093750 (1.440 sec)
30.445... logprob:  0.362689, 0.085938 (1.482 sec)
30.446... logprob:  0.398428, 0.101562 (1.442 sec)
30.447... logprob:  0.569415, 0.164062 (1.439 sec)
30.448... logprob:  0.333079, 0.078125 (1.487 sec)
30.449... logprob:  0.400050, 0.101562 (1.440 sec)
30.450... logprob:  0.239848, 0.046875 (1.436 sec)
30.451... logprob:  0.452456, 0.125000 (1.435 sec)
30.452... logprob:  0.455952, 0.117188 (1.431 sec)
30.453... logprob:  0.455048, 0.125000 (1.434 sec)
30.454... logprob:  0.488835, 0.132812 (1.488 sec)
30.455... logprob:  0.505997, 0.140625 (1.440 sec)
30.456... logprob:  0.468841, 0.125000 (1.448 sec)
30.457... logprob:  0.375315, 0.093750 (1.474 sec)
30.458... logprob:  0.350946, 0.085938 (1.436 sec)
30.459... logprob:  0.514116, 0.140625 (1.441 sec)
30.460... logprob:  0.273591, 0.054688 (1.432 sec)
30.461... logprob:  0.460150, 0.125000 (1.431 sec)
30.462... logprob:  0.472011, 0.125000 (1.433 sec)
30.463... logprob:  0.420792, 0.109375 (1.477 sec)
30.464... logprob:  0.482811, 0.132812 (1.444 sec)
30.465... logprob:  0.421090, 0.109375 (1.459 sec)
30.466... logprob:  0.318229, 0.070312 (1.459 sec)
30.467... logprob:  0.413819, 0.109375 (1.450 sec)
30.468... logprob:  0.394253, 0.101562 (1.444 sec)
30.469... logprob:  0.334801, 0.078125 (1.430 sec)
30.470... logprob:  0.400107, 0.101562 (1.427 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.56499099731445, 10.0]}, 128)
batch 872: ({'logprob': [66.84068298339844, 19.0]}, 128)
batch 873: ({'logprob': [40.282371520996094, 9.0]}, 128)
batch 874: ({'logprob': [45.063392639160156, 11.0]}, 128)
batch 875: ({'logprob': [50.711585998535156, 13.0]}, 128)
batch 876: ({'logprob': [64.26011657714844, 18.0]}, 128)
batch 877: ({'logprob': [45.508365631103516, 11.0]}, 128)
batch 878: ({'logprob': [62.06651306152344, 17.0]}, 128)
batch 879: ({'logprob': [73.81134796142578, 21.0]}, 128)
batch 880: ({'logprob': [50.738277435302734, 13.0]}, 128)
batch 881: ({'logprob': [28.49884605407715, 5.0]}, 128)
batch 882: ({'logprob': [54.66009521484375, 14.0]}, 128)
batch 883: ({'logprob': [62.038536071777344, 17.0]}, 128)
batch 884: ({'logprob': [51.160011291503906, 13.0]}, 128)
batch 885: ({'logprob': [52.032108306884766, 13.0]}, 128)
batch 886: ({'logprob': [62.49895095825195, 17.0]}, 128)

======================Test output======================
logprob:  0.415887, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959580e-03 [3.556468e-09] 
Layer 'conv1' biases: 3.832845e-07 [1.119727e-10] 
Layer 'conv2' weights[0]: 7.946695e-03 [3.041590e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.485505e-10] 
Layer 'conv3' weights[0]: 7.944841e-03 [2.845525e-09] 
Layer 'conv3' biases: 3.238418e-06 [1.579153e-09] 
Layer 'conv4' weights[0]: 7.977547e-03 [2.934848e-09] 
Layer 'conv4' biases: 9.999990e-01 [1.336591e-08] 
Layer 'conv5' weights[0]: 7.976291e-03 [8.428811e-08] 
Layer 'conv5' biases: 9.999906e-01 [9.063410e-08] 
Layer 'fc6' weights[0]: 7.572906e-03 [6.958234e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.063405e-09] 
Layer 'fc7' weights[0]: 6.893587e-03 [2.261771e-07] 
Layer 'fc7' biases: 9.998555e-01 [2.156506e-07] 
Layer 'fc8' weights[0]: 1.288323e-03 [8.515300e-06] 
Layer 'fc8' biases: 7.484942e-02 [6.038605e-05] 
Train error last 870 batches: 0.435185
-------------------------------------------------------
Not saving because 0.415887 > 0.415650 (27.630: -0.00%)
======================================================= (12.057 sec)
30.471... logprob:  0.529181, 0.148438 (1.442 sec)
30.472... logprob:  0.409974, 0.109375 (1.463 sec)
30.473... logprob:  0.375489, 0.093750 (1.459 sec)
30.474... logprob:  0.465488, 0.125000 (1.451 sec)
30.475... logprob:  0.503856, 0.140625 (1.455 sec)
30.476... logprob:  0.510121, 0.140625 (1.470 sec)
30.477... logprob:  0.334661, 0.078125 (1.439 sec)
30.478... logprob:  0.464223, 0.125000 (1.428 sec)
30.479... logprob:  0.305775, 0.070312 (1.436 sec)
30.480... logprob:  0.443500, 0.117188 (1.443 sec)
30.481... logprob:  0.547818, 0.156250 (1.437 sec)
30.482... logprob:  0.443132, 0.117188 (1.477 sec)
30.483... logprob:  0.502710, 0.140625 (1.450 sec)
30.484... logprob:  0.485326, 0.132812 (1.433 sec)
30.485... logprob:  0.408906, 0.109375 (1.490 sec)
30.486... logprob:  0.361241, 0.085938 (1.431 sec)
30.487... logprob:  0.522711, 0.148438 (1.434 sec)
30.488... logprob:  0.424694, 0.109375 (1.437 sec)
30.489... logprob:  0.415805, 0.109375 (1.433 sec)
30.490... logprob:  0.440686, 0.117188 (1.434 sec)
30.491... logprob:  0.313589, 0.070312 (1.482 sec)
30.492... logprob:  0.459518, 0.125000 (1.441 sec)
30.493... logprob:  0.521783, 0.148438 (1.440 sec)
30.494... logprob:  0.450342, 0.125000 (1.485 sec)
30.495... logprob:  0.380697, 0.093750 (1.436 sec)
30.496... logprob:  0.550176, 0.156250 (1.432 sec)
30.497... logprob:  0.466880, 0.125000 (1.440 sec)
30.498... logprob:  0.476200, 0.132812 (1.428 sec)
30.499... logprob:  0.456218, 0.125000 (1.439 sec)
30.500... logprob:  0.355169, 0.085938 (1.485 sec)
30.501... logprob:  0.339132, 0.078125 (1.437 sec)
30.502... logprob:  0.459597, 0.125000 (1.442 sec)
30.503... logprob:  0.400660, 0.101562 (1.483 sec)
30.504... logprob:  0.487272, 0.132812 (1.430 sec)
30.505... logprob:  0.570763, 0.164062 (1.443 sec)
30.506... logprob:  0.479686, 0.132812 (1.444 sec)
30.507... logprob:  0.385017, 0.093750 (1.429 sec)
30.508... logprob:  0.374646, 0.093750 (1.434 sec)
30.509... logprob:  0.322971, 0.070312 (1.477 sec)
30.510... logprob:  0.390452, 0.101562 (1.447 sec)
30.511... logprob:  0.410040, 0.109375 (1.466 sec)
30.512... logprob:  0.470713, 0.125000 (1.472 sec)
30.513... logprob:  0.324959, 0.078125 (1.448 sec)
30.514... logprob:  0.406271, 0.101562 (1.444 sec)
30.515... logprob:  0.455452, 0.125000 (1.431 sec)
30.516... logprob:  0.400244, 0.109375 (1.426 sec)
30.517... logprob:  0.627706, 0.179688 (1.440 sec)
30.518... logprob:  0.437636, 0.117188 (1.459 sec)
30.519... logprob:  0.516126, 0.140625 (1.457 sec)
30.520... logprob:  0.409641, 0.109375 (1.454 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.93428421020508, 10.0]}, 128)
batch 872: ({'logprob': [66.39495849609375, 19.0]}, 128)
batch 873: ({'logprob': [40.791259765625, 9.0]}, 128)
batch 874: ({'logprob': [45.363975524902344, 11.0]}, 128)
batch 875: ({'logprob': [50.83353042602539, 13.0]}, 128)
batch 876: ({'logprob': [63.91085433959961, 18.0]}, 128)
batch 877: ({'logprob': [45.82413864135742, 11.0]}, 128)
batch 878: ({'logprob': [61.82935333251953, 17.0]}, 128)
batch 879: ({'logprob': [73.2293930053711, 21.0]}, 128)
batch 880: ({'logprob': [50.85993957519531, 13.0]}, 128)
batch 881: ({'logprob': [29.353254318237305, 5.0]}, 128)
batch 882: ({'logprob': [54.7272834777832, 14.0]}, 128)
batch 883: ({'logprob': [61.80143356323242, 17.0]}, 128)
batch 884: ({'logprob': [51.29473114013672, 13.0]}, 128)
batch 885: ({'logprob': [52.19575119018555, 13.0]}, 128)
batch 886: ({'logprob': [62.275386810302734, 17.0]}, 128)

======================Test output======================
logprob:  0.416318, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959554e-03 [3.479925e-09] 
Layer 'conv1' biases: 3.843405e-07 [7.866633e-11] 
Layer 'conv2' weights[0]: 7.946665e-03 [2.888942e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.487153e-10] 
Layer 'conv3' weights[0]: 7.944797e-03 [2.319468e-09] 
Layer 'conv3' biases: 3.252188e-06 [1.342029e-09] 
Layer 'conv4' weights[0]: 7.977506e-03 [2.252397e-09] 
Layer 'conv4' biases: 9.999991e-01 [9.886449e-09] 
Layer 'conv5' weights[0]: 7.976286e-03 [6.103026e-08] 
Layer 'conv5' biases: 9.999912e-01 [6.568427e-08] 
Layer 'fc6' weights[0]: 7.572866e-03 [5.099881e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.140342e-09] 
Layer 'fc7' weights[0]: 6.891809e-03 [2.322700e-07] 
Layer 'fc7' biases: 9.998553e-01 [2.227623e-07] 
Layer 'fc8' weights[0]: 1.272245e-03 [8.823802e-06] 
Layer 'fc8' biases: 7.481049e-02 [5.725103e-05] 
Train error last 870 batches: 0.435184
-------------------------------------------------------
Not saving because 0.416318 > 0.415650 (27.630: -0.00%)
======================================================= (12.068 sec)
30.521... logprob:  0.427418, 0.109375 (1.455 sec)
30.522... logprob:  0.533179, 0.156250 (1.472 sec)
30.523... logprob:  0.331459, 0.078125 (1.440 sec)
30.524... logprob:  0.437135, 0.117188 (1.432 sec)
30.525... logprob:  0.425878, 0.109375 (1.431 sec)
30.526... logprob:  0.351622, 0.078125 (1.441 sec)
30.527... logprob:  0.504584, 0.140625 (1.440 sec)
30.528... logprob:  0.440449, 0.117188 (1.474 sec)
30.529... logprob:  0.352998, 0.085938 (1.450 sec)
30.530... logprob:  0.440255, 0.117188 (1.440 sec)
30.531... logprob:  0.439945, 0.117188 (1.488 sec)
30.532... logprob:  0.467303, 0.125000 (1.432 sec)
30.533... logprob:  0.560277, 0.164062 (1.427 sec)
30.534... logprob:  0.325960, 0.078125 (1.440 sec)
30.535... logprob:  0.551396, 0.156250 (1.435 sec)
30.536... logprob:  0.507247, 0.140625 (1.433 sec)
30.537... logprob:  0.509988, 0.140625 (1.486 sec)
30.538... logprob:  0.486077, 0.132812 (1.442 sec)
30.539... logprob:  0.296014, 0.062500 (1.435 sec)
30.540... logprob:  0.447177, 0.117188 (1.487 sec)
30.541... logprob:  0.388776, 0.101562 (1.439 sec)
30.542... logprob:  0.411225, 0.109375 (1.430 sec)
30.543... logprob:  0.233180, 0.039062 (1.438 sec)
30.544... logprob:  0.317918, 0.070312 (1.456 sec)
30.545... logprob:  0.348796, 0.085938 (1.438 sec)
30.546... logprob:  0.368267, 0.093750 (1.482 sec)
30.547... logprob:  0.439995, 0.117188 (1.434 sec)
30.548... logprob:  0.452837, 0.125000 (1.440 sec)
30.549... logprob:  0.490386, 0.132812 (1.482 sec)
30.550... logprob:  0.367598, 0.093750 (1.435 sec)
30.551... logprob:  0.441608, 0.117188 (1.434 sec)
30.552... logprob:  0.471240, 0.125000 (1.445 sec)
30.553... logprob:  0.349449, 0.085938 (1.433 sec)
30.554... logprob:  0.507000, 0.140625 (1.431 sec)
30.555... logprob:  0.421408, 0.109375 (1.488 sec)
30.556... logprob:  0.355766, 0.085938 (1.447 sec)
30.557... logprob:  0.396346, 0.101562 (1.449 sec)
30.558... logprob:  0.382997, 0.101562 (1.476 sec)
30.559... logprob:  0.441632, 0.125000 (1.439 sec)
30.560... logprob:  0.335002, 0.078125 (1.441 sec)
30.561... logprob:  0.411784, 0.109375 (1.431 sec)
30.562... logprob:  0.503164, 0.140625 (1.424 sec)
30.563... logprob:  0.373747, 0.093750 (1.440 sec)
30.564... logprob:  0.468495, 0.132812 (1.468 sec)
30.565... logprob:  0.611167, 0.187500 (1.452 sec)
30.566... logprob:  0.374863, 0.093750 (1.456 sec)
30.567... logprob:  0.423293, 0.109375 (1.463 sec)
30.568... logprob:  0.496323, 0.140625 (1.462 sec)
30.569... logprob:  0.507674, 0.140625 (1.434 sec)
30.570... logprob:  0.543795, 0.164062 (1.432 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.51695251464844, 10.0]}, 128)
batch 872: ({'logprob': [65.69058227539062, 19.0]}, 128)
batch 873: ({'logprob': [42.50444412231445, 9.0]}, 128)
batch 874: ({'logprob': [46.24864959716797, 11.0]}, 128)
batch 875: ({'logprob': [51.46705627441406, 13.0]}, 128)
batch 876: ({'logprob': [63.475067138671875, 18.0]}, 128)
batch 877: ({'logprob': [46.997291564941406, 11.0]}, 128)
batch 878: ({'logprob': [61.95304870605469, 17.0]}, 128)
batch 879: ({'logprob': [73.12934875488281, 21.0]}, 128)
batch 880: ({'logprob': [51.491485595703125, 13.0]}, 128)
batch 881: ({'logprob': [31.290283203125, 5.0]}, 128)
batch 882: ({'logprob': [55.94743728637695, 14.0]}, 128)
batch 883: ({'logprob': [61.926212310791016, 17.0]}, 128)
batch 884: ({'logprob': [52.21077346801758, 13.0]}, 128)
batch 885: ({'logprob': [53.68581771850586, 13.0]}, 128)
batch 886: ({'logprob': [62.68413162231445, 17.0]}, 128)

======================Test output======================
logprob:  0.421493, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959513e-03 [3.391118e-09] 
Layer 'conv1' biases: 3.853973e-07 [7.926599e-11] 
Layer 'conv2' weights[0]: 7.946628e-03 [2.996721e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.360103e-10] 
Layer 'conv3' weights[0]: 7.944756e-03 [2.745609e-09] 
Layer 'conv3' biases: 3.261114e-06 [1.642941e-09] 
Layer 'conv4' weights[0]: 7.977466e-03 [2.680875e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.317233e-08] 
Layer 'conv5' weights[0]: 7.976253e-03 [8.247204e-08] 
Layer 'conv5' biases: 9.999909e-01 [8.860673e-08] 
Layer 'fc6' weights[0]: 7.572825e-03 [6.783579e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.896136e-09] 
Layer 'fc7' weights[0]: 6.890083e-03 [1.781845e-07] 
Layer 'fc7' biases: 9.998549e-01 [1.686763e-07] 
Layer 'fc8' weights[0]: 1.242657e-03 [7.296486e-06] 
Layer 'fc8' biases: 7.470164e-02 [4.804278e-05] 
Train error last 870 batches: 0.435184
-------------------------------------------------------
Not saving because 0.421493 > 0.415650 (27.630: -0.00%)
======================================================= (12.073 sec)
30.571... logprob:  0.454886, 0.125000 (1.437 sec)
30.572... logprob:  0.501357, 0.140625 (1.446 sec)
30.573... logprob:  0.512593, 0.148438 (1.454 sec)
30.574... logprob:  0.428019, 0.109375 (1.463 sec)
30.575... logprob:  0.343324, 0.078125 (1.454 sec)
30.576... logprob:  0.427349, 0.109375 (1.442 sec)
30.577... logprob:  0.460783, 0.125000 (1.500 sec)
30.578... logprob:  0.336791, 0.078125 (1.434 sec)
30.579... logprob:  0.442079, 0.117188 (1.431 sec)
30.580... logprob:  0.546615, 0.156250 (1.430 sec)
30.581... logprob:  0.530607, 0.156250 (1.442 sec)
30.582... logprob:  0.437793, 0.125000 (1.438 sec)
30.583... logprob:  0.592396, 0.171875 (1.476 sec)
30.584... logprob:  0.468064, 0.132812 (1.445 sec)
30.585... logprob:  0.349767, 0.085938 (1.439 sec)
30.586... logprob:  0.313059, 0.070312 (1.484 sec)
30.587... logprob:  0.404296, 0.101562 (1.436 sec)
30.588... logprob:  0.418653, 0.117188 (1.431 sec)
30.589... logprob:  0.361148, 0.093750 (1.440 sec)
30.590... logprob:  0.524778, 0.148438 (1.436 sec)
30.591... logprob:  0.397455, 0.101562 (1.433 sec)
30.592... logprob:  0.455680, 0.125000 (1.481 sec)
30.593... logprob:  0.467417, 0.125000 (1.442 sec)
30.594... logprob:  0.352823, 0.085938 (1.439 sec)
30.595... logprob:  0.428660, 0.109375 (1.486 sec)
30.596... logprob:  0.461616, 0.125000 (1.434 sec)
30.597... logprob:  0.397417, 0.101562 (1.433 sec)
30.598... logprob:  0.397217, 0.101562 (1.440 sec)
30.599... logprob:  0.313580, 0.070312 (1.427 sec)
30.600... logprob:  0.340879, 0.085938 (1.440 sec)
30.601... logprob:  0.402155, 0.101562 (1.482 sec)
30.602... logprob:  0.289894, 0.062500 (1.440 sec)
30.603... logprob:  0.267209, 0.054688 (1.447 sec)
30.604... logprob:  0.407525, 0.101562 (1.482 sec)
30.605... logprob:  0.563271, 0.148438 (1.432 sec)
30.606... logprob:  0.295945, 0.070312 (1.443 sec)
30.607... logprob:  0.504679, 0.132812 (1.431 sec)
30.608... logprob:  0.361876, 0.085938 (1.430 sec)
30.609... logprob:  0.357049, 0.085938 (1.434 sec)
30.610... logprob:  0.493284, 0.132812 (1.476 sec)
30.611... logprob:  0.510330, 0.140625 (1.447 sec)
30.612... logprob:  0.448539, 0.117188 (1.455 sec)
30.613... logprob:  0.279334, 0.062500 (1.457 sec)
30.614... logprob:  0.503572, 0.140625 (1.447 sec)
30.615... logprob:  0.350798, 0.085938 (1.438 sec)
30.616... logprob:  0.415049, 0.109375 (1.431 sec)
30.617... logprob:  0.417823, 0.109375 (1.428 sec)
30.618... logprob:  0.547039, 0.156250 (1.477 sec)
30.619... logprob:  0.506122, 0.140625 (1.452 sec)
30.620... logprob:  0.539706, 0.156250 (1.465 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.26295852661133, 10.0]}, 128)
batch 872: ({'logprob': [66.22262573242188, 19.0]}, 128)
batch 873: ({'logprob': [41.69447708129883, 9.0]}, 128)
batch 874: ({'logprob': [46.25785827636719, 11.0]}, 128)
batch 875: ({'logprob': [51.375823974609375, 13.0]}, 128)
batch 876: ({'logprob': [63.82837677001953, 18.0]}, 128)
batch 877: ({'logprob': [46.54794692993164, 11.0]}, 128)
batch 878: ({'logprob': [61.66664505004883, 17.0]}, 128)
batch 879: ({'logprob': [72.19102478027344, 21.0]}, 128)
batch 880: ({'logprob': [51.40214157104492, 13.0]}, 128)
batch 881: ({'logprob': [31.134315490722656, 5.0]}, 128)
batch 882: ({'logprob': [54.66291809082031, 14.0]}, 128)
batch 883: ({'logprob': [61.63871765136719, 17.0]}, 128)
batch 884: ({'logprob': [51.662845611572266, 13.0]}, 128)
batch 885: ({'logprob': [52.22052001953125, 13.0]}, 128)
batch 886: ({'logprob': [61.939552307128906, 17.0]}, 128)

======================Test output======================
logprob:  0.418803, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959475e-03 [5.640365e-09] 
Layer 'conv1' biases: 3.865076e-07 [9.641750e-11] 
Layer 'conv2' weights[0]: 7.946589e-03 [4.145981e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.160115e-10] 
Layer 'conv3' weights[0]: 7.944720e-03 [3.392399e-09] 
Layer 'conv3' biases: 3.270771e-06 [1.950349e-09] 
Layer 'conv4' weights[0]: 7.977427e-03 [3.374748e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.528221e-08] 
Layer 'conv5' weights[0]: 7.976205e-03 [9.630552e-08] 
Layer 'conv5' biases: 9.999914e-01 [1.034472e-07] 
Layer 'fc6' weights[0]: 7.572783e-03 [7.908331e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.019720e-09] 
Layer 'fc7' weights[0]: 6.888316e-03 [2.824667e-07] 
Layer 'fc7' biases: 9.998543e-01 [2.740986e-07] 
Layer 'fc8' weights[0]: 1.247979e-03 [9.791457e-06] 
Layer 'fc8' biases: 7.490859e-02 [6.575945e-05] 
Train error last 870 batches: 0.435184
-------------------------------------------------------
Not saving because 0.418803 > 0.415650 (27.630: -0.00%)
======================================================= (12.070 sec)
30.621... logprob:  0.363564, 0.085938 (1.452 sec)
30.622... logprob:  0.364661, 0.085938 (1.457 sec)
30.623... logprob:  0.423120, 0.109375 (1.472 sec)
30.624... logprob:  0.382505, 0.093750 (1.442 sec)
30.625... logprob:  0.440979, 0.117188 (1.428 sec)
30.626... logprob:  0.438345, 0.117188 (1.435 sec)
30.627... logprob:  0.435821, 0.117188 (1.437 sec)
30.628... logprob:  0.465017, 0.125000 (1.443 sec)
30.629... logprob:  0.372153, 0.093750 (1.478 sec)
30.630... logprob:  0.422385, 0.109375 (1.453 sec)
30.631... logprob:  0.638372, 0.187500 (1.434 sec)
30.632... logprob:  0.399122, 0.101562 (1.489 sec)
30.633... logprob:  0.376119, 0.093750 (1.432 sec)
30.634... logprob:  0.660049, 0.195312 (1.431 sec)
30.635... logprob:  0.374122, 0.093750 (1.434 sec)
30.636... logprob:  0.480262, 0.132812 (1.439 sec)
30.637... logprob:  0.330734, 0.078125 (1.433 sec)
30.638... logprob:  0.515709, 0.140625 (1.481 sec)
30.639... logprob:  0.418025, 0.109375 (1.446 sec)
30.640... logprob:  0.528761, 0.148438 (1.435 sec)
30.641... logprob:  0.410405, 0.109375 (1.487 sec)
30.642... logprob:  0.500909, 0.140625 (1.438 sec)
30.643... logprob:  0.623294, 0.187500 (1.430 sec)
30.644... logprob:  0.320918, 0.070312 (1.440 sec)
30.645... logprob:  0.414447, 0.109375 (1.428 sec)
30.646... logprob:  0.385561, 0.093750 (1.437 sec)
30.647... logprob:  0.456794, 0.125000 (1.486 sec)
30.648... logprob:  0.491274, 0.140625 (1.436 sec)
30.649... logprob:  0.370319, 0.093750 (1.449 sec)
30.650... logprob:  0.414036, 0.109375 (1.475 sec)
30.651... logprob:  0.397414, 0.101562 (1.454 sec)
30.652... logprob:  0.507067, 0.140625 (1.440 sec)
30.653... logprob:  0.547696, 0.156250 (1.433 sec)
30.654... logprob:  0.495996, 0.140625 (1.430 sec)
30.655... logprob:  0.436176, 0.117188 (1.426 sec)
30.656... logprob:  0.416716, 0.109375 (1.477 sec)
30.657... logprob:  0.449037, 0.117188 (1.448 sec)
30.658... logprob:  0.345892, 0.085938 (1.451 sec)
30.659... logprob:  0.464277, 0.125000 (1.470 sec)
30.660... logprob:  0.446048, 0.125000 (1.442 sec)
30.661... logprob:  0.378404, 0.093750 (1.440 sec)
30.662... logprob:  0.469469, 0.132812 (1.435 sec)
30.663... logprob:  0.310852, 0.070312 (1.423 sec)
30.664... logprob:  0.285347, 0.062500 (1.444 sec)
30.665... logprob:  0.401675, 0.101562 (1.461 sec)
30.666... logprob:  0.442022, 0.117188 (1.458 sec)
30.667... logprob:  0.564203, 0.164062 (1.459 sec)
30.668... logprob:  0.497842, 0.140625 (1.456 sec)
30.669... logprob:  0.432908, 0.109375 (1.460 sec)
30.670... logprob:  0.362349, 0.085938 (1.443 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.138587951660156, 10.0]}, 128)
batch 872: ({'logprob': [66.66520690917969, 19.0]}, 128)
batch 873: ({'logprob': [40.66202163696289, 9.0]}, 128)
batch 874: ({'logprob': [45.04126739501953, 11.0]}, 128)
batch 875: ({'logprob': [50.772708892822266, 13.0]}, 128)
batch 876: ({'logprob': [64.16426086425781, 18.0]}, 128)
batch 877: ({'logprob': [45.7283935546875, 11.0]}, 128)
batch 878: ({'logprob': [62.292564392089844, 17.0]}, 128)
batch 879: ({'logprob': [74.4426498413086, 21.0]}, 128)
batch 880: ({'logprob': [50.798892974853516, 13.0]}, 128)
batch 881: ({'logprob': [28.47160530090332, 5.0]}, 128)
batch 882: ({'logprob': [55.36686706542969, 14.0]}, 128)
batch 883: ({'logprob': [62.26459503173828, 17.0]}, 128)
batch 884: ({'logprob': [51.462806701660156, 13.0]}, 128)
batch 885: ({'logprob': [52.818626403808594, 13.0]}, 128)
batch 886: ({'logprob': [62.96685028076172, 17.0]}, 128)

======================Test output======================
logprob:  0.417509, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959429e-03 [3.093482e-09] 
Layer 'conv1' biases: 3.875025e-07 [4.447473e-11] 
Layer 'conv2' weights[0]: 7.946550e-03 [1.891317e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.033962e-10] 
Layer 'conv3' weights[0]: 7.944685e-03 [1.388172e-09] 
Layer 'conv3' biases: 3.276997e-06 [6.017243e-10] 
Layer 'conv4' weights[0]: 7.977390e-03 [1.298000e-09] 
Layer 'conv4' biases: 9.999991e-01 [3.910152e-09] 
Layer 'conv5' weights[0]: 7.976166e-03 [2.269023e-08] 
Layer 'conv5' biases: 9.999907e-01 [2.409593e-08] 
Layer 'fc6' weights[0]: 7.572745e-03 [2.005898e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.860913e-09] 
Layer 'fc7' weights[0]: 6.886504e-03 [8.434620e-08] 
Layer 'fc7' biases: 9.998558e-01 [7.078335e-08] 
Layer 'fc8' weights[0]: 1.294951e-03 [2.585613e-06] 
Layer 'fc8' biases: 7.531656e-02 [1.557201e-05] 
Train error last 870 batches: 0.435183
-------------------------------------------------------
Not saving because 0.417509 > 0.415650 (27.630: -0.00%)
======================================================= (12.119 sec)
30.671... logprob:  0.360873, 0.093750 (1.432 sec)
30.672... logprob:  0.441827, 0.117188 (1.443 sec)
30.673... logprob:  0.436224, 0.117188 (1.442 sec)
30.674... logprob:  0.446628, 0.117188 (1.443 sec)
30.675... logprob:  0.356684, 0.093750 (1.474 sec)
30.676... logprob:  0.450189, 0.125000 (1.449 sec)
30.677... logprob:  0.471015, 0.125000 (1.443 sec)
30.678... logprob:  0.465662, 0.125000 (1.480 sec)
30.679... logprob:  0.454863, 0.125000 (1.436 sec)
30.680... logprob:  0.351650, 0.078125 (1.429 sec)
30.681... logprob:  0.373857, 0.093750 (1.437 sec)
30.682... logprob:  0.340459, 0.078125 (1.439 sec)
30.683... logprob:  0.411630, 0.109375 (1.434 sec)
30.684... logprob:  0.357705, 0.085938 (1.511 sec)
30.685... logprob:  0.286222, 0.054688 (1.444 sec)
30.686... logprob:  0.318825, 0.070312 (1.436 sec)
30.687... logprob:  0.281813, 0.062500 (1.485 sec)
30.688... logprob:  0.323151, 0.078125 (1.441 sec)
30.689... logprob:  0.470912, 0.125000 (1.429 sec)
30.690... logprob:  0.527335, 0.140625 (1.440 sec)
30.691... logprob:  0.516143, 0.140625 (1.433 sec)
30.692... logprob:  0.384752, 0.101562 (1.432 sec)
30.693... logprob:  0.455473, 0.125000 (1.485 sec)
30.694... logprob:  0.330959, 0.078125 (1.437 sec)
30.695... logprob:  0.356954, 0.085938 (1.445 sec)
30.696... logprob:  0.539296, 0.148438 (1.482 sec)
30.697... logprob:  0.465796, 0.125000 (1.432 sec)
30.698... logprob:  0.549093, 0.156250 (1.442 sec)
30.699... logprob:  0.459637, 0.125000 (1.431 sec)
30.700... logprob:  0.433796, 0.117188 (1.430 sec)
30.701... logprob:  0.422898, 0.109375 (1.438 sec)
30.702... logprob:  0.521585, 0.148438 (1.480 sec)
30.703... logprob:  0.404909, 0.101562 (1.442 sec)
30.704... logprob:  0.405884, 0.101562 (1.455 sec)
30.705... logprob:  0.420069, 0.109375 (1.472 sec)
30.706... logprob:  0.468048, 0.125000 (1.436 sec)
30.707... logprob:  0.485297, 0.132812 (1.444 sec)
30.708... logprob:  0.417244, 0.109375 (1.430 sec)
30.709... logprob:  0.422689, 0.109375 (1.430 sec)
30.710... logprob:  0.601997, 0.179688 (1.438 sec)
30.711... logprob:  0.469462, 0.125000 (1.471 sec)
30.712... logprob:  0.341026, 0.078125 (1.446 sec)
30.713... logprob:  0.586322, 0.179688 (1.461 sec)
30.714... logprob:  0.466229, 0.125000 (1.461 sec)
30.715... logprob:  0.417208, 0.109375 (1.460 sec)
30.716... logprob:  0.335534, 0.078125 (1.440 sec)
30.717... logprob:  0.429769, 0.117188 (1.424 sec)
30.718... logprob:  0.490291, 0.132812 (1.437 sec)
30.719... logprob:  0.406177, 0.109375 (1.436 sec)
30.720... logprob:  0.433222, 0.117188 (1.452 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.61531066894531, 10.0]}, 128)
batch 872: ({'logprob': [66.64868927001953, 19.0]}, 128)
batch 873: ({'logprob': [40.4759407043457, 9.0]}, 128)
batch 874: ({'logprob': [45.13918685913086, 11.0]}, 128)
batch 875: ({'logprob': [50.73749923706055, 13.0]}, 128)
batch 876: ({'logprob': [64.11011505126953, 18.0]}, 128)
batch 877: ({'logprob': [45.618247985839844, 11.0]}, 128)
batch 878: ({'logprob': [61.992347717285156, 17.0]}, 128)
batch 879: ({'logprob': [73.67035675048828, 21.0]}, 128)
batch 880: ({'logprob': [50.76411056518555, 13.0]}, 128)
batch 881: ({'logprob': [28.75901222229004, 5.0]}, 128)
batch 882: ({'logprob': [54.745140075683594, 14.0]}, 128)
batch 883: ({'logprob': [61.96418380737305, 17.0]}, 128)
batch 884: ({'logprob': [51.219200134277344, 13.0]}, 128)
batch 885: ({'logprob': [52.15879440307617, 13.0]}, 128)
batch 886: ({'logprob': [62.4582405090332, 17.0]}, 128)

======================Test output======================
logprob:  0.416053, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959389e-03 [2.229680e-09] 
Layer 'conv1' biases: 3.882862e-07 [4.953323e-11] 
Layer 'conv2' weights[0]: 7.946510e-03 [1.521172e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.069036e-10] 
Layer 'conv3' weights[0]: 7.944648e-03 [1.304996e-09] 
Layer 'conv3' biases: 3.283448e-06 [5.695534e-10] 
Layer 'conv4' weights[0]: 7.977347e-03 [1.209435e-09] 
Layer 'conv4' biases: 9.999990e-01 [3.301804e-09] 
Layer 'conv5' weights[0]: 7.976120e-03 [1.426997e-08] 
Layer 'conv5' biases: 9.999903e-01 [1.440643e-08] 
Layer 'fc6' weights[0]: 7.572708e-03 [1.305500e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.041187e-09] 
Layer 'fc7' weights[0]: 6.884749e-03 [7.637153e-08] 
Layer 'fc7' biases: 9.998552e-01 [6.147599e-08] 
Layer 'fc8' weights[0]: 1.287025e-03 [4.948572e-06] 
Layer 'fc8' biases: 7.549851e-02 [3.444677e-05] 
Train error last 870 batches: 0.435183
-------------------------------------------------------
Not saving because 0.416053 > 0.415650 (27.630: -0.00%)
======================================================= (12.136 sec)
30.721... logprob:  0.451602, 0.117188 (1.478 sec)
30.722... logprob:  0.537042, 0.156250 (1.465 sec)
30.723... logprob:  0.416541, 0.109375 (1.451 sec)
30.724... logprob:  0.412756, 0.109375 (1.475 sec)
30.725... logprob:  0.494890, 0.140625 (1.434 sec)
30.726... logprob:  0.338377, 0.085938 (1.432 sec)
30.727... logprob:  0.393174, 0.101562 (1.430 sec)
30.728... logprob:  0.421190, 0.109375 (1.443 sec)
30.729... logprob:  0.387537, 0.093750 (1.434 sec)
30.730... logprob:  0.565957, 0.164062 (1.480 sec)
30.731... logprob:  0.450425, 0.125000 (1.443 sec)
30.732... logprob:  0.311369, 0.070312 (1.440 sec)
30.733... logprob:  0.556474, 0.156250 (1.485 sec)
30.734... logprob:  0.340252, 0.078125 (1.436 sec)
30.735... logprob:  0.527401, 0.148438 (1.430 sec)
30.736... logprob:  0.642513, 0.187500 (1.440 sec)
30.737... logprob:  0.516082, 0.148438 (1.432 sec)
30.738... logprob:  0.459380, 0.125000 (1.432 sec)
30.739... logprob:  0.477785, 0.132812 (1.487 sec)
30.740... logprob:  0.339644, 0.078125 (1.438 sec)
30.741... logprob:  0.393479, 0.101562 (1.443 sec)
30.742... logprob:  0.419683, 0.109375 (1.481 sec)
30.743... logprob:  0.364897, 0.085938 (1.437 sec)
30.744... logprob:  0.519128, 0.148438 (1.433 sec)
30.745... logprob:  0.478126, 0.132812 (1.438 sec)
30.746... logprob:  0.440543, 0.117188 (1.433 sec)
30.747... logprob:  0.425600, 0.109375 (1.429 sec)
30.748... logprob:  0.378156, 0.093750 (1.487 sec)
30.749... logprob:  0.420801, 0.109375 (1.432 sec)
30.750... logprob:  0.512752, 0.140625 (1.446 sec)
30.751... logprob:  0.263732, 0.054688 (1.489 sec)
30.752... logprob:  0.522501, 0.140625 (1.432 sec)
30.753... logprob:  0.441143, 0.117188 (1.439 sec)
30.754... logprob:  0.468262, 0.132812 (1.438 sec)
30.755... logprob:  0.507038, 0.140625 (1.426 sec)
30.756... logprob:  0.440837, 0.117188 (1.439 sec)
30.757... logprob:  0.552489, 0.156250 (1.472 sec)
30.758... logprob:  0.393544, 0.101562 (1.472 sec)
30.759... logprob:  0.459701, 0.125000 (1.453 sec)
30.760... logprob:  0.485574, 0.132812 (1.463 sec)
30.761... logprob:  0.418130, 0.109375 (1.444 sec)
30.762... logprob:  0.516078, 0.148438 (1.440 sec)
30.763... logprob:  0.559023, 0.164062 (1.432 sec)
30.764... logprob:  0.503265, 0.140625 (1.426 sec)
30.765... logprob:  0.311637, 0.062500 (1.441 sec)
30.766... logprob:  0.482197, 0.132812 (1.455 sec)
30.767... logprob:  0.371062, 0.085938 (1.457 sec)
30.768... logprob:  0.432641, 0.117188 (1.469 sec)
30.769... logprob:  0.490784, 0.140625 (1.474 sec)
30.770... logprob:  0.403009, 0.101562 (1.485 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.401790618896484, 10.0]}, 128)
batch 872: ({'logprob': [66.1821517944336, 19.0]}, 128)
batch 873: ({'logprob': [41.21385192871094, 9.0]}, 128)
batch 874: ({'logprob': [45.701210021972656, 11.0]}, 128)
batch 875: ({'logprob': [51.01625061035156, 13.0]}, 128)
batch 876: ({'logprob': [63.7579231262207, 18.0]}, 128)
batch 877: ({'logprob': [46.12721633911133, 11.0]}, 128)
batch 878: ({'logprob': [61.7020263671875, 17.0]}, 128)
batch 879: ({'logprob': [72.75726318359375, 21.0]}, 128)
batch 880: ({'logprob': [51.04246139526367, 13.0]}, 128)
batch 881: ({'logprob': [30.121295928955078, 5.0]}, 128)
batch 882: ({'logprob': [54.7446174621582, 14.0]}, 128)
batch 883: ({'logprob': [61.674102783203125, 17.0]}, 128)
batch 884: ({'logprob': [51.441322326660156, 13.0]}, 128)
batch 885: ({'logprob': [52.27252960205078, 13.0]}, 128)
batch 886: ({'logprob': [62.11244583129883, 17.0]}, 128)

======================Test output======================
logprob:  0.417123, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959342e-03 [3.123013e-09] 
Layer 'conv1' biases: 3.893079e-07 [1.326035e-10] 
Layer 'conv2' weights[0]: 7.946468e-03 [2.557936e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.449562e-10] 
Layer 'conv3' weights[0]: 7.944608e-03 [2.649127e-09] 
Layer 'conv3' biases: 3.291120e-06 [1.587775e-09] 
Layer 'conv4' weights[0]: 7.977309e-03 [2.728130e-09] 
Layer 'conv4' biases: 9.999990e-01 [1.414520e-08] 
Layer 'conv5' weights[0]: 7.976078e-03 [9.098527e-08] 
Layer 'conv5' biases: 9.999903e-01 [9.774309e-08] 
Layer 'fc6' weights[0]: 7.572674e-03 [7.420789e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.558602e-09] 
Layer 'fc7' weights[0]: 6.883007e-03 [2.504424e-07] 
Layer 'fc7' biases: 9.998547e-01 [2.403956e-07] 
Layer 'fc8' weights[0]: 1.262519e-03 [8.429262e-06] 
Layer 'fc8' biases: 7.543906e-02 [6.259422e-05] 
Train error last 870 batches: 0.435183
-------------------------------------------------------
Not saving because 0.417123 > 0.415650 (27.630: -0.00%)
======================================================= (12.070 sec)
30.771... logprob:  0.549346, 0.156250 (1.467 sec)
30.772... logprob:  0.414116, 0.109375 (1.453 sec)
30.773... logprob:  0.557590, 0.164062 (1.452 sec)
30.774... logprob:  0.361835, 0.085938 (1.465 sec)
30.775... logprob:  0.407411, 0.101562 (1.459 sec)
30.776... logprob:  0.433139, 0.117188 (1.487 sec)
30.777... logprob:  0.379993, 0.093750 (1.471 sec)
30.778... logprob:  0.433530, 0.117188 (1.467 sec)
30.779... logprob:  0.505299, 0.140625 (1.486 sec)
30.780... logprob:  0.385764, 0.101562 (1.463 sec)
30.781... logprob:  0.369621, 0.085938 (1.445 sec)
30.782... logprob:  0.351395, 0.085938 (1.460 sec)
30.783... logprob:  0.555540, 0.156250 (1.459 sec)
30.784... logprob:  0.440960, 0.117188 (1.460 sec)
30.785... logprob:  0.543756, 0.156250 (1.497 sec)
30.786... logprob:  0.477583, 0.132812 (1.467 sec)
30.787... logprob:  0.546562, 0.156250 (1.455 sec)
30.788... logprob:  0.563344, 0.164062 (1.501 sec)
30.789... logprob:  0.280529, 0.054688 (1.459 sec)
30.790... logprob:  0.407855, 0.101562 (1.451 sec)
30.791... logprob:  0.397805, 0.101562 (1.458 sec)
30.792... logprob:  0.360855, 0.085938 (1.463 sec)
30.793... logprob:  0.370028, 0.085938 (1.454 sec)
30.794... logprob:  0.387120, 0.093750 (1.496 sec)
30.795... logprob:  0.469706, 0.125000 (1.469 sec)
30.796... logprob:  0.423514, 0.109375 (1.460 sec)
30.797... logprob:  0.358920, 0.085938 (1.499 sec)
30.798... logprob:  0.393304, 0.101562 (1.458 sec)
30.799... logprob:  0.332521, 0.078125 (1.448 sec)
30.800... logprob:  0.371683, 0.093750 (1.451 sec)
30.801... logprob:  0.449891, 0.117188 (1.460 sec)
30.802... logprob:  0.422833, 0.109375 (1.458 sec)
30.803... logprob:  0.491358, 0.132812 (1.489 sec)
30.804... logprob:  0.349944, 0.085938 (1.470 sec)
30.805... logprob:  0.452264, 0.117188 (1.458 sec)
30.806... logprob:  0.424172, 0.109375 (1.509 sec)
30.807... logprob:  0.443479, 0.117188 (1.452 sec)
30.808... logprob:  0.462368, 0.125000 (1.458 sec)
30.809... logprob:  0.589843, 0.171875 (1.455 sec)
30.810... logprob:  0.442500, 0.117188 (1.457 sec)
30.811... logprob:  0.460423, 0.125000 (1.454 sec)
30.812... logprob:  0.462324, 0.125000 (1.496 sec)
30.813... logprob:  0.485950, 0.132812 (1.466 sec)
30.814... logprob:  0.477893, 0.132812 (1.456 sec)
30.815... logprob:  0.371369, 0.085938 (1.508 sec)
30.816... logprob:  0.408426, 0.101562 (1.456 sec)
30.817... logprob:  0.425784, 0.109375 (1.450 sec)
30.818... logprob:  0.560020, 0.164062 (1.454 sec)
30.819... logprob:  0.498178, 0.140625 (1.455 sec)
30.820... logprob:  0.421688, 0.109375 (1.458 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.39156723022461, 10.0]}, 128)
batch 872: ({'logprob': [66.16831970214844, 19.0]}, 128)
batch 873: ({'logprob': [41.87611389160156, 9.0]}, 128)
batch 874: ({'logprob': [46.38087463378906, 11.0]}, 128)
batch 875: ({'logprob': [51.45952224731445, 13.0]}, 128)
batch 876: ({'logprob': [63.79844284057617, 18.0]}, 128)
batch 877: ({'logprob': [46.6805419921875, 11.0]}, 128)
batch 878: ({'logprob': [61.670928955078125, 17.0]}, 128)
batch 879: ({'logprob': [72.12561798095703, 21.0]}, 128)
batch 880: ({'logprob': [51.48557662963867, 13.0]}, 128)
batch 881: ({'logprob': [31.38584327697754, 5.0]}, 128)
batch 882: ({'logprob': [54.750213623046875, 14.0]}, 128)
batch 883: ({'logprob': [61.64330291748047, 17.0]}, 128)
batch 884: ({'logprob': [51.75542068481445, 13.0]}, 128)
batch 885: ({'logprob': [52.33226776123047, 13.0]}, 128)
batch 886: ({'logprob': [61.953094482421875, 17.0]}, 128)

======================Test output======================
logprob:  0.419364, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959302e-03 [3.661826e-09] 
Layer 'conv1' biases: 3.905120e-07 [1.401185e-10] 
Layer 'conv2' weights[0]: 7.946423e-03 [2.514313e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.056094e-10] 
Layer 'conv3' weights[0]: 7.944572e-03 [2.390139e-09] 
Layer 'conv3' biases: 3.302343e-06 [1.378206e-09] 
Layer 'conv4' weights[0]: 7.977273e-03 [2.496594e-09] 
Layer 'conv4' biases: 9.999990e-01 [1.276609e-08] 
Layer 'conv5' weights[0]: 7.976039e-03 [8.275738e-08] 
Layer 'conv5' biases: 9.999908e-01 [8.890066e-08] 
Layer 'fc6' weights[0]: 7.572642e-03 [6.723726e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.845290e-09] 
Layer 'fc7' weights[0]: 6.881253e-03 [1.645083e-07] 
Layer 'fc7' biases: 9.998540e-01 [1.536718e-07] 
Layer 'fc8' weights[0]: 1.240900e-03 [5.058089e-06] 
Layer 'fc8' biases: 7.550236e-02 [4.175417e-05] 
Train error last 870 batches: 0.435182
-------------------------------------------------------
Not saving because 0.419364 > 0.415650 (27.630: -0.00%)
======================================================= (12.058 sec)
30.821... logprob:  0.406719, 0.101562 (1.509 sec)
30.822... logprob:  0.441288, 0.117188 (1.467 sec)
30.823... logprob:  0.341182, 0.078125 (1.495 sec)
30.824... logprob:  0.489624, 0.132812 (1.500 sec)
30.825... logprob:  0.288474, 0.062500 (1.455 sec)
30.826... logprob:  0.375611, 0.093750 (1.447 sec)
30.827... logprob:  0.420433, 0.109375 (1.454 sec)
30.828... logprob:  0.443119, 0.117188 (1.453 sec)
30.829... logprob:  0.503721, 0.140625 (1.453 sec)
30.830... logprob:  0.442016, 0.117188 (1.511 sec)
30.831... logprob:  0.513797, 0.140625 (1.456 sec)
30.832... logprob:  0.330842, 0.078125 (1.466 sec)
30.833... logprob:  0.489060, 0.132812 (1.492 sec)
30.834... logprob:  0.433399, 0.117188 (1.458 sec)
30.835... logprob:  0.542953, 0.148438 (1.455 sec)
30.836... logprob:  0.376059, 0.093750 (1.454 sec)
30.837... logprob:  0.313933, 0.070312 (1.461 sec)
30.838... logprob:  0.437067, 0.117188 (1.450 sec)
30.839... logprob:  0.471639, 0.125000 (1.505 sec)
30.840... logprob:  0.555601, 0.156250 (1.455 sec)
30.841... logprob:  0.395961, 0.101562 (1.466 sec)
30.842... logprob:  0.497906, 0.140625 (1.492 sec)
30.843... logprob:  0.465487, 0.125000 (1.456 sec)
30.844... logprob:  0.497680, 0.140625 (1.462 sec)
30.845... logprob:  0.486723, 0.132812 (1.449 sec)
30.846... logprob:  0.468379, 0.125000 (1.450 sec)
30.847... logprob:  0.363441, 0.085938 (1.454 sec)
30.848... logprob:  0.397265, 0.101562 (1.501 sec)
30.849... logprob:  0.360653, 0.085938 (1.460 sec)
30.850... logprob:  0.479363, 0.132812 (1.466 sec)
30.851... logprob:  0.440139, 0.117188 (1.495 sec)
30.852... logprob:  0.545265, 0.156250 (1.448 sec)
30.853... logprob:  0.372049, 0.093750 (1.467 sec)
30.854... logprob:  0.307473, 0.070312 (1.448 sec)
30.855... logprob:  0.484652, 0.132812 (1.446 sec)
30.856... logprob:  0.443675, 0.117188 (1.461 sec)
30.857... logprob:  0.372232, 0.093750 (1.490 sec)
30.858... logprob:  0.396244, 0.101562 (1.468 sec)
30.859... logprob:  0.308007, 0.070312 (1.468 sec)
30.860... logprob:  0.565967, 0.156250 (1.491 sec)
30.861... logprob:  0.417794, 0.109375 (1.455 sec)
30.862... logprob:  0.328818, 0.078125 (1.464 sec)
30.863... logprob:  0.399587, 0.101562 (1.447 sec)
30.864... logprob:  0.451514, 0.117188 (1.455 sec)
30.865... logprob:  0.484659, 0.132812 (1.460 sec)
30.866... logprob:  0.507855, 0.140625 (1.496 sec)
30.867... logprob:  0.503227, 0.140625 (1.464 sec)
30.868... logprob:  0.405181, 0.101562 (1.479 sec)
30.869... logprob:  0.383020, 0.093750 (1.478 sec)
30.870... logprob:  0.552302, 0.156250 (1.399 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.66910934448242, 10.0]}, 128)
batch 872: ({'logprob': [66.29817962646484, 19.0]}, 128)
batch 873: ({'logprob': [41.18895721435547, 9.0]}, 128)
batch 874: ({'logprob': [45.812232971191406, 11.0]}, 128)
batch 875: ({'logprob': [51.08345413208008, 13.0]}, 128)
batch 876: ({'logprob': [63.85102844238281, 18.0]}, 128)
batch 877: ({'logprob': [46.148624420166016, 11.0]}, 128)
batch 878: ({'logprob': [61.68233108520508, 17.0]}, 128)
batch 879: ({'logprob': [72.56147766113281, 21.0]}, 128)
batch 880: ({'logprob': [51.11001968383789, 13.0]}, 128)
batch 881: ({'logprob': [30.273040771484375, 5.0]}, 128)
batch 882: ({'logprob': [54.566139221191406, 14.0]}, 128)
batch 883: ({'logprob': [61.65432357788086, 17.0]}, 128)
batch 884: ({'logprob': [51.41885757446289, 13.0]}, 128)
batch 885: ({'logprob': [52.07086181640625, 13.0]}, 128)
batch 886: ({'logprob': [62.00305938720703, 17.0]}, 128)

======================Test output======================
logprob:  0.417183, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959265e-03 [3.893733e-09] 
Layer 'conv1' biases: 3.916920e-07 [8.711667e-11] 
Layer 'conv2' weights[0]: 7.946394e-03 [2.328635e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.549032e-10] 
Layer 'conv3' weights[0]: 7.944534e-03 [2.208007e-09] 
Layer 'conv3' biases: 3.312946e-06 [1.386020e-09] 
Layer 'conv4' weights[0]: 7.977233e-03 [2.338236e-09] 
Layer 'conv4' biases: 9.999990e-01 [1.201104e-08] 
Layer 'conv5' weights[0]: 7.976010e-03 [7.829450e-08] 
Layer 'conv5' biases: 9.999910e-01 [8.389252e-08] 
Layer 'fc6' weights[0]: 7.572603e-03 [6.369841e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.497837e-09] 
Layer 'fc7' weights[0]: 6.879497e-03 [2.724301e-07] 
Layer 'fc7' biases: 9.998544e-01 [2.637502e-07] 
Layer 'fc8' weights[0]: 1.254574e-03 [9.054076e-06] 
Layer 'fc8' biases: 7.581576e-02 [5.970122e-05] 
Train error last 870 batches: 0.435182
-------------------------------------------------------
Not saving because 0.417183 > 0.415650 (27.630: -0.00%)
======================================================= (12.017 sec)
31.1... logprob:  0.379853, 0.093750 (1.410 sec)
31.2... logprob:  0.448237, 0.117188 (1.469 sec)
31.3... logprob:  0.398220, 0.101562 (1.415 sec)
31.4... logprob:  0.443280, 0.117188 (1.412 sec)
31.5... logprob:  0.443491, 0.117188 (1.434 sec)
31.6... logprob:  0.499031, 0.140625 (1.401 sec)
31.7... logprob:  0.363346, 0.085938 (1.423 sec)
31.8... logprob:  0.419180, 0.109375 (1.402 sec)
31.9... logprob:  0.358981, 0.085938 (1.403 sec)
31.10... logprob:  0.377653, 0.093750 (1.416 sec)
31.11... logprob:  0.335005, 0.078125 (1.451 sec)
31.12... logprob:  0.466214, 0.125000 (1.395 sec)
31.13... logprob:  0.442107, 0.117188 (1.424 sec)
31.14... logprob:  0.444467, 0.117188 (1.404 sec)
31.15... logprob:  0.395468, 0.101562 (1.416 sec)
31.16... logprob:  0.421328, 0.109375 (1.405 sec)
31.17... logprob:  0.515892, 0.140625 (1.398 sec)
31.18... logprob:  0.262127, 0.054688 (1.407 sec)
31.19... logprob:  0.279453, 0.062500 (1.406 sec)
31.20... logprob:  0.421359, 0.109375 (1.405 sec)
31.21... logprob:  0.443999, 0.117188 (1.403 sec)
31.22... logprob:  0.536836, 0.148438 (1.412 sec)
31.23... logprob:  0.533241, 0.148438 (1.419 sec)
31.24... logprob:  0.310403, 0.070312 (1.416 sec)
31.25... logprob:  0.356071, 0.085938 (1.405 sec)
31.26... logprob:  0.463846, 0.125000 (1.448 sec)
31.27... logprob:  0.404478, 0.101562 (1.413 sec)
31.28... logprob:  0.421840, 0.109375 (1.415 sec)
31.29... logprob:  0.395882, 0.101562 (1.432 sec)
31.30... logprob:  0.374015, 0.093750 (1.417 sec)
31.31... logprob:  0.479991, 0.132812 (1.404 sec)
31.32... logprob:  0.457221, 0.125000 (1.390 sec)
31.33... logprob:  0.460679, 0.125000 (1.446 sec)
31.34... logprob:  0.464504, 0.125000 (1.394 sec)
31.35... logprob:  0.316349, 0.070312 (1.401 sec)
31.36... logprob:  0.475791, 0.132812 (1.404 sec)
31.37... logprob:  0.417593, 0.109375 (1.433 sec)
31.38... logprob:  0.392725, 0.101562 (1.405 sec)
31.39... logprob:  0.631330, 0.187500 (1.441 sec)
31.40... logprob:  0.445646, 0.117188 (1.408 sec)
31.41... logprob:  0.353032, 0.085938 (1.426 sec)
31.42... logprob:  0.392047, 0.101562 (1.423 sec)
31.43... logprob:  0.440070, 0.117188 (1.406 sec)
31.44... logprob:  0.518567, 0.148438 (1.441 sec)
31.45... logprob:  0.381714, 0.093750 (1.391 sec)
31.46... logprob:  0.486144, 0.132812 (1.401 sec)
31.47... logprob:  0.331716, 0.078125 (1.393 sec)
31.48... logprob:  0.498949, 0.140625 (1.429 sec)
31.49... logprob:  0.510930, 0.148438 (1.413 sec)
31.50... logprob:  0.393174, 0.101562 (1.426 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.83945846557617, 10.0]}, 128)
batch 872: ({'logprob': [66.27887725830078, 19.0]}, 128)
batch 873: ({'logprob': [40.94742965698242, 9.0]}, 128)
batch 874: ({'logprob': [45.378997802734375, 11.0]}, 128)
batch 875: ({'logprob': [50.85207748413086, 13.0]}, 128)
batch 876: ({'logprob': [63.82933044433594, 18.0]}, 128)
batch 877: ({'logprob': [45.91147232055664, 11.0]}, 128)
batch 878: ({'logprob': [61.85443115234375, 17.0]}, 128)
batch 879: ({'logprob': [73.33251190185547, 21.0]}, 128)
batch 880: ({'logprob': [50.878326416015625, 13.0]}, 128)
batch 881: ({'logprob': [29.430757522583008, 5.0]}, 128)
batch 882: ({'logprob': [54.92753601074219, 14.0]}, 128)
batch 883: ({'logprob': [61.82651901245117, 17.0]}, 128)
batch 884: ({'logprob': [51.385128021240234, 13.0]}, 128)
batch 885: ({'logprob': [52.430274963378906, 13.0]}, 128)
batch 886: ({'logprob': [62.372474670410156, 17.0]}, 128)

======================Test output======================
logprob:  0.416736, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959234e-03 [2.963766e-09] 
Layer 'conv1' biases: 3.927460e-07 [4.437416e-11] 
Layer 'conv2' weights[0]: 7.946349e-03 [2.185446e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.916172e-10] 
Layer 'conv3' weights[0]: 7.944497e-03 [1.462146e-09] 
Layer 'conv3' biases: 3.320026e-06 [5.517544e-10] 
Layer 'conv4' weights[0]: 7.977197e-03 [1.395852e-09] 
Layer 'conv4' biases: 9.999990e-01 [2.361593e-09] 
Layer 'conv5' weights[0]: 7.975974e-03 [1.133868e-08] 
Layer 'conv5' biases: 9.999906e-01 [1.162081e-08] 
Layer 'fc6' weights[0]: 7.572555e-03 [1.158134e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.340778e-10] 
Layer 'fc7' weights[0]: 6.877723e-03 [5.093979e-08] 
Layer 'fc7' biases: 9.998550e-01 [3.129573e-08] 
Layer 'fc8' weights[0]: 1.269033e-03 [6.291762e-06] 
Layer 'fc8' biases: 7.600678e-02 [4.262603e-05] 
Train error last 870 batches: 0.435182
-------------------------------------------------------
Not saving because 0.416736 > 0.415650 (27.630: -0.00%)
======================================================= (12.128 sec)
31.51... logprob:  0.490315, 0.140625 (1.426 sec)
31.52... logprob:  0.525793, 0.148438 (1.417 sec)
31.53... logprob:  0.294743, 0.062500 (1.444 sec)
31.54... logprob:  0.403432, 0.109375 (1.390 sec)
31.55... logprob:  0.331670, 0.078125 (1.403 sec)
31.56... logprob:  0.421593, 0.109375 (1.406 sec)
31.57... logprob:  0.572316, 0.164062 (1.428 sec)
31.58... logprob:  0.407501, 0.101562 (1.407 sec)
31.59... logprob:  0.333867, 0.078125 (1.470 sec)
31.60... logprob:  0.618674, 0.179688 (1.417 sec)
31.61... logprob:  0.382786, 0.093750 (1.438 sec)
31.62... logprob:  0.474831, 0.132812 (1.464 sec)
31.63... logprob:  0.397285, 0.101562 (1.439 sec)
31.64... logprob:  0.450338, 0.125000 (1.412 sec)
31.65... logprob:  0.373392, 0.093750 (1.403 sec)
31.66... logprob:  0.354047, 0.085938 (1.456 sec)
31.67... logprob:  0.295428, 0.062500 (1.397 sec)
31.68... logprob:  0.396797, 0.101562 (1.398 sec)
31.69... logprob:  0.496636, 0.140625 (1.425 sec)
31.70... logprob:  0.325912, 0.078125 (1.429 sec)
31.71... logprob:  0.381796, 0.101562 (1.467 sec)
31.72... logprob:  0.493665, 0.132812 (1.409 sec)
31.73... logprob:  0.447666, 0.117188 (1.431 sec)
31.74... logprob:  0.442499, 0.117188 (1.420 sec)
31.75... logprob:  0.380659, 0.093750 (1.415 sec)
31.76... logprob:  0.412040, 0.109375 (1.440 sec)
31.77... logprob:  0.396344, 0.101562 (1.437 sec)
31.78... logprob:  0.493050, 0.140625 (1.453 sec)
31.79... logprob:  0.456482, 0.125000 (1.409 sec)
31.80... logprob:  0.508069, 0.132812 (1.425 sec)
31.81... logprob:  0.416724, 0.109375 (1.421 sec)
31.82... logprob:  0.231130, 0.039062 (1.420 sec)
31.83... logprob:  0.493843, 0.140625 (1.407 sec)
31.84... logprob:  0.468164, 0.125000 (1.472 sec)
31.85... logprob:  0.431906, 0.117188 (1.427 sec)
31.86... logprob:  0.416913, 0.109375 (1.424 sec)
31.87... logprob:  0.633331, 0.187500 (1.420 sec)
31.88... logprob:  0.535008, 0.156250 (1.413 sec)
31.89... logprob:  0.410529, 0.109375 (1.434 sec)
31.90... logprob:  0.577481, 0.171875 (1.394 sec)
31.91... logprob:  0.348397, 0.078125 (1.404 sec)
31.92... logprob:  0.464460, 0.125000 (1.406 sec)
31.93... logprob:  0.492195, 0.140625 (1.405 sec)
31.94... logprob:  0.428787, 0.109375 (1.391 sec)
31.95... logprob:  0.471831, 0.125000 (1.411 sec)
31.96... logprob:  0.576147, 0.171875 (1.410 sec)
31.97... logprob:  0.430796, 0.117188 (1.395 sec)
31.98... logprob:  0.391247, 0.093750 (1.437 sec)
31.99... logprob:  0.474201, 0.132812 (1.407 sec)
31.100... logprob:  0.310679, 0.070312 (1.406 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.2589225769043, 10.0]}, 128)
batch 872: ({'logprob': [66.1026840209961, 19.0]}, 128)
batch 873: ({'logprob': [41.28725814819336, 9.0]}, 128)
batch 874: ({'logprob': [45.66621398925781, 11.0]}, 128)
batch 875: ({'logprob': [51.00275802612305, 13.0]}, 128)
batch 876: ({'logprob': [63.700279235839844, 18.0]}, 128)
batch 877: ({'logprob': [46.157100677490234, 11.0]}, 128)
batch 878: ({'logprob': [61.73098373413086, 17.0]}, 128)
batch 879: ({'logprob': [72.8930892944336, 21.0]}, 128)
batch 880: ({'logprob': [51.02881622314453, 13.0]}, 128)
batch 881: ({'logprob': [30.08741569519043, 5.0]}, 128)
batch 882: ({'logprob': [54.90361404418945, 14.0]}, 128)
batch 883: ({'logprob': [61.703147888183594, 17.0]}, 128)
batch 884: ({'logprob': [51.492523193359375, 13.0]}, 128)
batch 885: ({'logprob': [52.45322799682617, 13.0]}, 128)
batch 886: ({'logprob': [62.20619583129883, 17.0]}, 128)

======================Test output======================
logprob:  0.417321, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959195e-03 [4.520013e-09] 
Layer 'conv1' biases: 3.936493e-07 [1.736232e-10] 
Layer 'conv2' weights[0]: 7.946316e-03 [4.689531e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.556451e-10] 
Layer 'conv3' weights[0]: 7.944460e-03 [4.534530e-09] 
Layer 'conv3' biases: 3.326351e-06 [2.869894e-09] 
Layer 'conv4' weights[0]: 7.977160e-03 [4.721248e-09] 
Layer 'conv4' biases: 9.999990e-01 [2.592112e-08] 
Layer 'conv5' weights[0]: 7.975927e-03 [1.667333e-07] 
Layer 'conv5' biases: 9.999904e-01 [1.790394e-07] 
Layer 'fc6' weights[0]: 7.572524e-03 [1.355685e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.386422e-08] 
Layer 'fc7' weights[0]: 6.875924e-03 [2.908476e-07] 
Layer 'fc7' biases: 9.998546e-01 [2.817134e-07] 
Layer 'fc8' weights[0]: 1.258478e-03 [1.034011e-05] 
Layer 'fc8' biases: 7.599734e-02 [7.381550e-05] 
Train error last 870 batches: 0.435182
-------------------------------------------------------
Not saving because 0.417321 > 0.415650 (27.630: -0.00%)
======================================================= (12.066 sec)
31.101... logprob:  0.311005, 0.062500 (1.453 sec)
31.102... logprob:  0.545819, 0.156250 (1.401 sec)
31.103... logprob:  0.540824, 0.156250 (1.403 sec)
31.104... logprob:  0.388801, 0.101562 (1.406 sec)
31.105... logprob:  0.619162, 0.179688 (1.410 sec)
31.106... logprob:  0.344475, 0.085938 (1.399 sec)
31.107... logprob:  0.335815, 0.078125 (1.436 sec)
31.108... logprob:  0.586860, 0.171875 (1.402 sec)
31.109... logprob:  0.336112, 0.078125 (1.407 sec)
31.110... logprob:  0.564708, 0.164062 (1.399 sec)
31.111... logprob:  0.404653, 0.101562 (1.397 sec)
31.112... logprob:  0.365950, 0.093750 (1.409 sec)
31.113... logprob:  0.354369, 0.085938 (1.403 sec)
31.114... logprob:  0.440208, 0.117188 (1.435 sec)
31.115... logprob:  0.506802, 0.140625 (1.419 sec)
31.116... logprob:  0.393329, 0.101562 (1.399 sec)
31.117... logprob:  0.440393, 0.117188 (1.449 sec)
31.118... logprob:  0.409073, 0.101562 (1.399 sec)
31.119... logprob:  0.346064, 0.085938 (1.396 sec)
31.120... logprob:  0.547128, 0.156250 (1.407 sec)
31.121... logprob:  0.412583, 0.109375 (1.404 sec)
31.122... logprob:  0.519240, 0.148438 (1.445 sec)
31.123... logprob:  0.463658, 0.125000 (1.391 sec)
31.124... logprob:  0.447686, 0.125000 (1.408 sec)
31.125... logprob:  0.501896, 0.140625 (1.403 sec)
31.126... logprob:  0.475720, 0.125000 (1.396 sec)
31.127... logprob:  0.479476, 0.125000 (1.399 sec)
31.128... logprob:  0.422324, 0.109375 (1.420 sec)
31.129... logprob:  0.574882, 0.164062 (1.423 sec)
31.130... logprob:  0.382693, 0.093750 (1.420 sec)
31.131... logprob:  0.495496, 0.132812 (1.415 sec)
31.132... logprob:  0.506357, 0.140625 (1.432 sec)
31.133... logprob:  0.444694, 0.117188 (1.391 sec)
31.134... logprob:  0.401864, 0.101562 (1.400 sec)
31.135... logprob:  0.460177, 0.125000 (1.402 sec)
31.136... logprob:  0.562340, 0.164062 (1.417 sec)
31.137... logprob:  0.462592, 0.125000 (1.391 sec)
31.138... logprob:  0.319418, 0.070312 (1.444 sec)
31.139... logprob:  0.395731, 0.101562 (1.404 sec)
31.140... logprob:  0.559988, 0.164062 (1.415 sec)
31.141... logprob:  0.464589, 0.125000 (1.441 sec)
31.142... logprob:  0.464644, 0.125000 (1.394 sec)
31.143... logprob:  0.294454, 0.062500 (1.424 sec)
31.144... logprob:  0.457000, 0.125000 (1.421 sec)
31.145... logprob:  0.324699, 0.078125 (1.416 sec)
31.146... logprob:  0.483054, 0.132812 (1.412 sec)
31.147... logprob:  0.262490, 0.054688 (1.442 sec)
31.148... logprob:  0.458575, 0.125000 (1.396 sec)
31.149... logprob:  0.442489, 0.117188 (1.401 sec)
31.150... logprob:  0.347567, 0.085938 (1.400 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.25794982910156, 10.0]}, 128)
batch 872: ({'logprob': [67.9014663696289, 19.0]}, 128)
batch 873: ({'logprob': [39.59007263183594, 9.0]}, 128)
batch 874: ({'logprob': [44.803802490234375, 11.0]}, 128)
batch 875: ({'logprob': [50.74616622924805, 13.0]}, 128)
batch 876: ({'logprob': [65.14090728759766, 18.0]}, 128)
batch 877: ({'logprob': [45.17970275878906, 11.0]}, 128)
batch 878: ({'logprob': [62.69544219970703, 17.0]}, 128)
batch 879: ({'logprob': [74.9655532836914, 21.0]}, 128)
batch 880: ({'logprob': [50.77445602416992, 13.0]}, 128)
batch 881: ({'logprob': [27.279794692993164, 5.0]}, 128)
batch 882: ({'logprob': [54.67576599121094, 14.0]}, 128)
batch 883: ({'logprob': [62.66612243652344, 17.0]}, 128)
batch 884: ({'logprob': [51.13024139404297, 13.0]}, 128)
batch 885: ({'logprob': [51.86602783203125, 13.0]}, 128)
batch 886: ({'logprob': [63.06134796142578, 17.0]}, 128)

======================Test output======================
logprob:  0.416863, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959159e-03 [2.917551e-09] 
Layer 'conv1' biases: 3.945698e-07 [5.207183e-11] 
Layer 'conv2' weights[0]: 7.946276e-03 [1.656019e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.824461e-10] 
Layer 'conv3' weights[0]: 7.944424e-03 [1.236940e-09] 
Layer 'conv3' biases: 3.334294e-06 [4.532654e-10] 
Layer 'conv4' weights[0]: 7.977118e-03 [1.190473e-09] 
Layer 'conv4' biases: 9.999990e-01 [2.428722e-09] 
Layer 'conv5' weights[0]: 7.975882e-03 [1.098374e-08] 
Layer 'conv5' biases: 9.999901e-01 [1.114464e-08] 
Layer 'fc6' weights[0]: 7.572482e-03 [1.115584e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.792277e-10] 
Layer 'fc7' weights[0]: 6.874151e-03 [1.308212e-07] 
Layer 'fc7' biases: 9.998559e-01 [1.189059e-07] 
Layer 'fc8' weights[0]: 1.315857e-03 [8.478727e-06] 
Layer 'fc8' biases: 7.650755e-02 [5.729220e-05] 
Train error last 870 batches: 0.435182
-------------------------------------------------------
Not saving because 0.416863 > 0.415650 (27.630: -0.00%)
======================================================= (12.092 sec)
31.151... logprob:  0.347135, 0.085938 (1.410 sec)
31.152... logprob:  0.785145, 0.234375 (1.401 sec)
31.153... logprob:  0.381637, 0.093750 (1.452 sec)
31.154... logprob:  0.524741, 0.148438 (1.400 sec)
31.155... logprob:  0.426131, 0.117188 (1.419 sec)
31.156... logprob:  0.295115, 0.062500 (1.444 sec)
31.157... logprob:  0.270012, 0.054688 (1.398 sec)
31.158... logprob:  0.455452, 0.125000 (1.411 sec)
31.159... logprob:  0.483129, 0.132812 (1.406 sec)
31.160... logprob:  0.444684, 0.117188 (1.397 sec)
31.161... logprob:  0.349631, 0.078125 (1.401 sec)
31.162... logprob:  0.611791, 0.179688 (1.405 sec)
31.163... logprob:  0.450496, 0.125000 (1.429 sec)
31.164... logprob:  0.468500, 0.125000 (1.428 sec)
31.165... logprob:  0.547738, 0.156250 (1.421 sec)
31.166... logprob:  0.446168, 0.125000 (1.451 sec)
31.167... logprob:  0.350640, 0.085938 (1.433 sec)
31.168... logprob:  0.363759, 0.085938 (1.429 sec)
31.169... logprob:  0.408620, 0.101562 (1.463 sec)
31.170... logprob:  0.459458, 0.125000 (1.432 sec)
31.171... logprob:  0.535194, 0.156250 (1.425 sec)
31.172... logprob:  0.434791, 0.109375 (1.418 sec)
31.173... logprob:  0.440462, 0.117188 (1.428 sec)
31.174... logprob:  0.600621, 0.171875 (1.410 sec)
31.175... logprob:  0.505914, 0.140625 (1.466 sec)
31.176... logprob:  0.478387, 0.132812 (1.424 sec)
31.177... logprob:  0.289722, 0.054688 (1.432 sec)
31.178... logprob:  0.383474, 0.093750 (1.463 sec)
31.179... logprob:  0.394656, 0.101562 (1.417 sec)
31.180... logprob:  0.466392, 0.125000 (1.420 sec)
31.181... logprob:  0.539259, 0.156250 (1.421 sec)
31.182... logprob:  0.371261, 0.093750 (1.427 sec)
31.183... logprob:  0.419929, 0.109375 (1.427 sec)
31.184... logprob:  0.483432, 0.132812 (1.423 sec)
31.185... logprob:  0.289729, 0.062500 (1.394 sec)
31.186... logprob:  0.370333, 0.093750 (1.398 sec)
31.187... logprob:  0.529615, 0.148438 (1.407 sec)
31.188... logprob:  0.458850, 0.125000 (1.402 sec)
31.189... logprob:  0.440923, 0.117188 (1.388 sec)
31.190... logprob:  0.375793, 0.093750 (1.442 sec)
31.191... logprob:  0.485095, 0.132812 (1.418 sec)
31.192... logprob:  0.520013, 0.148438 (1.425 sec)
31.193... logprob:  0.312471, 0.070312 (1.427 sec)
31.194... logprob:  0.414041, 0.109375 (1.415 sec)
31.195... logprob:  0.286993, 0.062500 (1.402 sec)
31.196... logprob:  0.410446, 0.109375 (1.395 sec)
31.197... logprob:  0.477978, 0.132812 (1.404 sec)
31.198... logprob:  0.355797, 0.085938 (1.410 sec)
31.199... logprob:  0.437194, 0.117188 (1.394 sec)
31.200... logprob:  0.440725, 0.117188 (1.443 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.393550872802734, 10.0]}, 128)
batch 872: ({'logprob': [66.88475799560547, 19.0]}, 128)
batch 873: ({'logprob': [40.26307678222656, 9.0]}, 128)
batch 874: ({'logprob': [44.99553680419922, 11.0]}, 128)
batch 875: ({'logprob': [50.69686508178711, 13.0]}, 128)
batch 876: ({'logprob': [64.3039779663086, 18.0]}, 128)
batch 877: ({'logprob': [45.49165344238281, 11.0]}, 128)
batch 878: ({'logprob': [62.15971755981445, 17.0]}, 128)
batch 879: ({'logprob': [74.06198120117188, 21.0]}, 128)
batch 880: ({'logprob': [50.724205017089844, 13.0]}, 128)
batch 881: ({'logprob': [28.32099151611328, 5.0]}, 128)
batch 882: ({'logprob': [54.80051040649414, 14.0]}, 128)
batch 883: ({'logprob': [62.130924224853516, 17.0]}, 128)
batch 884: ({'logprob': [51.197120666503906, 13.0]}, 128)
batch 885: ({'logprob': [52.170902252197266, 13.0]}, 128)
batch 886: ({'logprob': [62.643306732177734, 17.0]}, 128)

======================Test output======================
logprob:  0.416132, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959127e-03 [4.220497e-09] 
Layer 'conv1' biases: 3.957099e-07 [1.176673e-10] 
Layer 'conv2' weights[0]: 7.946242e-03 [2.536296e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.321292e-10] 
Layer 'conv3' weights[0]: 7.944386e-03 [1.764851e-09] 
Layer 'conv3' biases: 3.344097e-06 [7.924311e-10] 
Layer 'conv4' weights[0]: 7.977084e-03 [1.689822e-09] 
Layer 'conv4' biases: 9.999990e-01 [4.308577e-09] 
Layer 'conv5' weights[0]: 7.975847e-03 [2.659114e-08] 
Layer 'conv5' biases: 9.999904e-01 [2.853436e-08] 
Layer 'fc6' weights[0]: 7.572444e-03 [2.361883e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.233781e-09] 
Layer 'fc7' weights[0]: 6.872394e-03 [5.273212e-08] 
Layer 'fc7' biases: 9.998552e-01 [3.350191e-08] 
Layer 'fc8' weights[0]: 1.297672e-03 [4.562109e-06] 
Layer 'fc8' biases: 7.647176e-02 [3.115914e-05] 
Train error last 870 batches: 0.435181
-------------------------------------------------------
Not saving because 0.416132 > 0.415650 (27.630: -0.00%)
======================================================= (12.070 sec)
31.201... logprob:  0.437088, 0.117188 (1.414 sec)
31.202... logprob:  0.537820, 0.148438 (1.414 sec)
31.203... logprob:  0.420399, 0.109375 (1.447 sec)
31.204... logprob:  0.504123, 0.140625 (1.393 sec)
31.205... logprob:  0.334266, 0.078125 (1.409 sec)
31.206... logprob:  0.361637, 0.093750 (1.405 sec)
31.207... logprob:  0.381746, 0.093750 (1.399 sec)
31.208... logprob:  0.490595, 0.140625 (1.402 sec)
31.209... logprob:  0.334528, 0.078125 (1.426 sec)
31.210... logprob:  0.586224, 0.171875 (1.420 sec)
31.211... logprob:  0.488113, 0.132812 (1.421 sec)
31.212... logprob:  0.526112, 0.148438 (1.415 sec)
31.213... logprob:  0.514590, 0.140625 (1.466 sec)
31.214... logprob:  0.459387, 0.125000 (1.429 sec)
31.215... logprob:  0.396081, 0.101562 (1.424 sec)
31.216... logprob:  0.516889, 0.140625 (1.472 sec)
31.217... logprob:  0.324821, 0.070312 (1.408 sec)
31.218... logprob:  0.463571, 0.125000 (1.429 sec)
31.219... logprob:  0.500218, 0.140625 (1.422 sec)
31.220... logprob:  0.415031, 0.109375 (1.424 sec)
31.221... logprob:  0.399576, 0.101562 (1.411 sec)
31.222... logprob:  0.554378, 0.164062 (1.456 sec)
31.223... logprob:  0.568891, 0.164062 (1.439 sec)
31.224... logprob:  0.405995, 0.101562 (1.439 sec)
31.225... logprob:  0.392014, 0.101562 (1.449 sec)
31.226... logprob:  0.424763, 0.109375 (1.423 sec)
31.227... logprob:  0.452609, 0.125000 (1.419 sec)
31.228... logprob:  0.417167, 0.109375 (1.422 sec)
31.229... logprob:  0.489371, 0.132812 (1.422 sec)
31.230... logprob:  0.459843, 0.125000 (1.432 sec)
31.231... logprob:  0.453476, 0.125000 (1.412 sec)
31.232... logprob:  0.496147, 0.140625 (1.457 sec)
31.233... logprob:  0.466042, 0.132812 (1.427 sec)
31.234... logprob:  0.563877, 0.164062 (1.423 sec)
31.235... logprob:  0.482010, 0.132812 (1.470 sec)
31.236... logprob:  0.425625, 0.109375 (1.409 sec)
31.237... logprob:  0.340864, 0.078125 (1.422 sec)
31.238... logprob:  0.389066, 0.093750 (1.419 sec)
31.239... logprob:  0.478079, 0.132812 (1.422 sec)
31.240... logprob:  0.485794, 0.132812 (1.404 sec)
31.241... logprob:  0.493602, 0.132812 (1.456 sec)
31.242... logprob:  0.341625, 0.078125 (1.431 sec)
31.243... logprob:  0.385991, 0.093750 (1.446 sec)
31.244... logprob:  0.315445, 0.070312 (1.447 sec)
31.245... logprob:  0.494190, 0.132812 (1.452 sec)
31.246... logprob:  0.416837, 0.109375 (1.416 sec)
31.247... logprob:  0.357610, 0.085938 (1.420 sec)
31.248... logprob:  0.308108, 0.070312 (1.416 sec)
31.249... logprob:  0.554423, 0.156250 (1.427 sec)
31.250... logprob:  0.591086, 0.164062 (1.413 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.42549133300781, 10.0]}, 128)
batch 872: ({'logprob': [67.79853057861328, 19.0]}, 128)
batch 873: ({'logprob': [39.615577697753906, 9.0]}, 128)
batch 874: ({'logprob': [44.86349105834961, 11.0]}, 128)
batch 875: ({'logprob': [50.74020004272461, 13.0]}, 128)
batch 876: ({'logprob': [65.04592895507812, 18.0]}, 128)
batch 877: ({'logprob': [45.18973922729492, 11.0]}, 128)
batch 878: ({'logprob': [62.558509826660156, 17.0]}, 128)
batch 879: ({'logprob': [74.6474609375, 21.0]}, 128)
batch 880: ({'logprob': [50.76878356933594, 13.0]}, 128)
batch 881: ({'logprob': [27.48654556274414, 5.0]}, 128)
batch 882: ({'logprob': [54.512203216552734, 14.0]}, 128)
batch 883: ({'logprob': [62.52888107299805, 17.0]}, 128)
batch 884: ({'logprob': [51.074188232421875, 13.0]}, 128)
batch 885: ({'logprob': [51.709999084472656, 13.0]}, 128)
batch 886: ({'logprob': [62.87422561645508, 17.0]}, 128)

======================Test output======================
logprob:  0.416426, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959080e-03 [8.286783e-09] 
Layer 'conv1' biases: 3.967792e-07 [2.176471e-10] 
Layer 'conv2' weights[0]: 7.946197e-03 [6.269300e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.296894e-09] 
Layer 'conv3' weights[0]: 7.944353e-03 [5.721942e-09] 
Layer 'conv3' biases: 3.351900e-06 [3.964884e-09] 
Layer 'conv4' weights[0]: 7.977042e-03 [5.834656e-09] 
Layer 'conv4' biases: 9.999990e-01 [3.414767e-08] 
Layer 'conv5' weights[0]: 7.975803e-03 [2.185961e-07] 
Layer 'conv5' biases: 9.999905e-01 [2.345234e-07] 
Layer 'fc6' weights[0]: 7.572404e-03 [1.801811e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.832509e-08] 
Layer 'fc7' weights[0]: 6.870628e-03 [1.689184e-07] 
Layer 'fc7' biases: 9.998555e-01 [1.594857e-07] 
Layer 'fc8' weights[0]: 1.318043e-03 [8.805138e-06] 
Layer 'fc8' biases: 7.669645e-02 [5.829088e-05] 
Train error last 870 batches: 0.435181
-------------------------------------------------------
Not saving because 0.416426 > 0.415650 (27.630: -0.00%)
======================================================= (12.050 sec)
31.251... logprob:  0.353009, 0.085938 (1.464 sec)
31.252... logprob:  0.348426, 0.085938 (1.436 sec)
31.253... logprob:  0.379234, 0.093750 (1.421 sec)
31.254... logprob:  0.444155, 0.117188 (1.471 sec)
31.255... logprob:  0.351302, 0.085938 (1.402 sec)
31.256... logprob:  0.378881, 0.093750 (1.428 sec)
31.257... logprob:  0.331959, 0.078125 (1.420 sec)
31.258... logprob:  0.415483, 0.109375 (1.427 sec)
31.259... logprob:  0.442318, 0.117188 (1.407 sec)
31.260... logprob:  0.308156, 0.070312 (1.461 sec)
31.261... logprob:  0.392521, 0.101562 (1.438 sec)
31.262... logprob:  0.524488, 0.148438 (1.439 sec)
31.263... logprob:  0.425616, 0.109375 (1.447 sec)
31.264... logprob:  0.375004, 0.093750 (1.428 sec)
31.265... logprob:  0.439609, 0.117188 (1.423 sec)
31.266... logprob:  0.439004, 0.117188 (1.416 sec)
31.267... logprob:  0.422042, 0.109375 (1.420 sec)
31.268... logprob:  0.458941, 0.125000 (1.421 sec)
31.269... logprob:  0.567596, 0.164062 (1.407 sec)
31.270... logprob:  0.542357, 0.156250 (1.464 sec)
31.271... logprob:  0.445577, 0.117188 (1.441 sec)
31.272... logprob:  0.384527, 0.093750 (1.421 sec)
31.273... logprob:  0.500237, 0.140625 (1.474 sec)
31.274... logprob:  0.542498, 0.156250 (1.405 sec)
31.275... logprob:  0.487548, 0.132812 (1.422 sec)
31.276... logprob:  0.389980, 0.093750 (1.421 sec)
31.277... logprob:  0.428582, 0.109375 (1.430 sec)
31.278... logprob:  0.323656, 0.070312 (1.428 sec)
31.279... logprob:  0.325337, 0.070312 (1.468 sec)
31.280... logprob:  0.216158, 0.031250 (1.406 sec)
31.281... logprob:  0.417261, 0.109375 (1.428 sec)
31.282... logprob:  0.411297, 0.109375 (1.417 sec)
31.283... logprob:  0.393710, 0.101562 (1.421 sec)
31.284... logprob:  0.394326, 0.101562 (1.410 sec)
31.285... logprob:  0.451274, 0.117188 (1.441 sec)
31.286... logprob:  0.536079, 0.140625 (1.437 sec)
31.287... logprob:  0.346506, 0.085938 (1.433 sec)
31.288... logprob:  0.329938, 0.078125 (1.448 sec)
31.289... logprob:  0.445755, 0.117188 (1.442 sec)
31.290... logprob:  0.490641, 0.132812 (1.411 sec)
31.291... logprob:  0.439348, 0.117188 (1.423 sec)
31.292... logprob:  0.567812, 0.156250 (1.422 sec)
31.293... logprob:  0.427806, 0.117188 (1.429 sec)
31.294... logprob:  0.355659, 0.085938 (1.405 sec)
31.295... logprob:  0.334204, 0.078125 (1.469 sec)
31.296... logprob:  0.355347, 0.085938 (1.421 sec)
31.297... logprob:  0.394272, 0.101562 (1.429 sec)
31.298... logprob:  0.448273, 0.125000 (1.469 sec)
31.299... logprob:  0.341820, 0.078125 (1.402 sec)
31.300... logprob:  0.406305, 0.101562 (1.425 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.99375915527344, 10.0]}, 128)
batch 872: ({'logprob': [66.1881332397461, 19.0]}, 128)
batch 873: ({'logprob': [41.096187591552734, 9.0]}, 128)
batch 874: ({'logprob': [45.491111755371094, 11.0]}, 128)
batch 875: ({'logprob': [50.90890884399414, 13.0]}, 128)
batch 876: ({'logprob': [63.76167678833008, 18.0]}, 128)
batch 877: ({'logprob': [46.01455307006836, 11.0]}, 128)
batch 878: ({'logprob': [61.800418853759766, 17.0]}, 128)
batch 879: ({'logprob': [73.15795135498047, 21.0]}, 128)
batch 880: ({'logprob': [50.935298919677734, 13.0]}, 128)
batch 881: ({'logprob': [29.70028305053711, 5.0]}, 128)
batch 882: ({'logprob': [54.93281173706055, 14.0]}, 128)
batch 883: ({'logprob': [61.77240753173828, 17.0]}, 128)
batch 884: ({'logprob': [51.432098388671875, 13.0]}, 128)
batch 885: ({'logprob': [52.458099365234375, 13.0]}, 128)
batch 886: ({'logprob': [62.30866241455078, 17.0]}, 128)

======================Test output======================
logprob:  0.416969, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959040e-03 [3.744207e-09] 
Layer 'conv1' biases: 3.979526e-07 [9.765884e-11] 
Layer 'conv2' weights[0]: 7.946154e-03 [3.988851e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.167878e-10] 
Layer 'conv3' weights[0]: 7.944318e-03 [3.501681e-09] 
Layer 'conv3' biases: 3.361032e-06 [1.950913e-09] 
Layer 'conv4' weights[0]: 7.977010e-03 [3.518070e-09] 
Layer 'conv4' biases: 9.999990e-01 [1.637124e-08] 
Layer 'conv5' weights[0]: 7.975777e-03 [1.016043e-07] 
Layer 'conv5' biases: 9.999903e-01 [1.093105e-07] 
Layer 'fc6' weights[0]: 7.572357e-03 [8.366542e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.476337e-09] 
Layer 'fc7' weights[0]: 6.868852e-03 [1.365511e-07] 
Layer 'fc7' biases: 9.998546e-01 [1.246549e-07] 
Layer 'fc8' weights[0]: 1.271643e-03 [4.159888e-06] 
Layer 'fc8' biases: 7.662634e-02 [3.575157e-05] 
Train error last 870 batches: 0.435181
-------------------------------------------------------
Not saving because 0.416969 > 0.415650 (27.630: -0.00%)
======================================================= (12.072 sec)
31.301... logprob:  0.397864, 0.101562 (1.424 sec)
31.302... logprob:  0.591612, 0.179688 (1.427 sec)
31.303... logprob:  0.459469, 0.125000 (1.427 sec)
31.304... logprob:  0.459602, 0.125000 (1.448 sec)
31.305... logprob:  0.455190, 0.125000 (1.437 sec)
31.306... logprob:  0.440569, 0.117188 (1.436 sec)
31.307... logprob:  0.421629, 0.109375 (1.441 sec)
31.308... logprob:  0.374882, 0.093750 (1.458 sec)
31.309... logprob:  0.450482, 0.125000 (1.418 sec)
31.310... logprob:  0.473550, 0.125000 (1.421 sec)
31.311... logprob:  0.502426, 0.140625 (1.433 sec)
31.312... logprob:  0.478654, 0.132812 (1.440 sec)
31.313... logprob:  0.454855, 0.125000 (1.422 sec)
31.314... logprob:  0.454323, 0.117188 (1.465 sec)
31.315... logprob:  0.314687, 0.070312 (1.436 sec)
31.316... logprob:  0.468497, 0.125000 (1.426 sec)
31.317... logprob:  0.355418, 0.085938 (1.477 sec)
31.318... logprob:  0.455399, 0.125000 (1.415 sec)
31.319... logprob:  0.423160, 0.117188 (1.423 sec)
31.320... logprob:  0.412230, 0.109375 (1.429 sec)
31.321... logprob:  0.348230, 0.085938 (1.428 sec)
31.322... logprob:  0.387425, 0.101562 (1.417 sec)
31.323... logprob:  0.416500, 0.109375 (1.481 sec)
31.324... logprob:  0.498594, 0.140625 (1.425 sec)
31.325... logprob:  0.350671, 0.085938 (1.440 sec)
31.326... logprob:  0.543183, 0.148438 (1.468 sec)
31.327... logprob:  0.554423, 0.164062 (1.430 sec)
31.328... logprob:  0.565158, 0.156250 (1.431 sec)
31.329... logprob:  0.401899, 0.101562 (1.424 sec)
31.330... logprob:  0.388479, 0.101562 (1.426 sec)
31.331... logprob:  0.352212, 0.085938 (1.417 sec)
31.332... logprob:  0.482783, 0.132812 (1.454 sec)
31.333... logprob:  0.339440, 0.085938 (1.443 sec)
31.334... logprob:  0.565322, 0.171875 (1.442 sec)
31.335... logprob:  0.358659, 0.085938 (1.441 sec)
31.336... logprob:  0.444864, 0.125000 (1.458 sec)
31.337... logprob:  0.566393, 0.164062 (1.417 sec)
31.338... logprob:  0.449516, 0.125000 (1.423 sec)
31.339... logprob:  0.488571, 0.132812 (1.438 sec)
31.340... logprob:  0.442063, 0.117188 (1.427 sec)
31.341... logprob:  0.530007, 0.148438 (1.427 sec)
31.342... logprob:  0.429595, 0.109375 (1.469 sec)
31.343... logprob:  0.434764, 0.109375 (1.438 sec)
31.344... logprob:  0.444538, 0.125000 (1.493 sec)
31.345... logprob:  0.488177, 0.132812 (1.440 sec)
31.346... logprob:  0.436205, 0.117188 (1.440 sec)
31.347... logprob:  0.372573, 0.085938 (1.483 sec)
31.348... logprob:  0.398499, 0.101562 (1.436 sec)
31.349... logprob:  0.497557, 0.140625 (1.434 sec)
31.350... logprob:  0.358734, 0.085938 (1.434 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.51754379272461, 10.0]}, 128)
batch 872: ({'logprob': [66.45023345947266, 19.0]}, 128)
batch 873: ({'logprob': [40.74441909790039, 9.0]}, 128)
batch 874: ({'logprob': [45.19042205810547, 11.0]}, 128)
batch 875: ({'logprob': [50.778282165527344, 13.0]}, 128)
batch 876: ({'logprob': [63.96873474121094, 18.0]}, 128)
batch 877: ({'logprob': [45.772953033447266, 11.0]}, 128)
batch 878: ({'logprob': [62.0113410949707, 17.0]}, 128)
batch 879: ({'logprob': [73.76958465576172, 21.0]}, 128)
batch 880: ({'logprob': [50.804954528808594, 13.0]}, 128)
batch 881: ({'logprob': [28.946653366088867, 5.0]}, 128)
batch 882: ({'logprob': [55.03782653808594, 14.0]}, 128)
batch 883: ({'logprob': [61.983089447021484, 17.0]}, 128)
batch 884: ({'logprob': [51.362693786621094, 13.0]}, 128)
batch 885: ({'logprob': [52.50819396972656, 13.0]}, 128)
batch 886: ({'logprob': [62.580108642578125, 17.0]}, 128)

======================Test output======================
logprob:  0.416712, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958995e-03 [3.608639e-09] 
Layer 'conv1' biases: 3.988377e-07 [7.950388e-11] 
Layer 'conv2' weights[0]: 7.946116e-03 [2.448921e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.786025e-10] 
Layer 'conv3' weights[0]: 7.944270e-03 [2.238095e-09] 
Layer 'conv3' biases: 3.367420e-06 [1.165390e-09] 
Layer 'conv4' weights[0]: 7.976964e-03 [2.220259e-09] 
Layer 'conv4' biases: 9.999990e-01 [9.876339e-09] 
Layer 'conv5' weights[0]: 7.975726e-03 [6.038908e-08] 
Layer 'conv5' biases: 9.999901e-01 [6.495727e-08] 
Layer 'fc6' weights[0]: 7.572317e-03 [5.025838e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.053149e-09] 
Layer 'fc7' weights[0]: 6.867141e-03 [1.738883e-07] 
Layer 'fc7' biases: 9.998549e-01 [1.632796e-07] 
Layer 'fc8' weights[0]: 1.285106e-03 [9.761695e-06] 
Layer 'fc8' biases: 7.683456e-02 [6.761512e-05] 
Train error last 870 batches: 0.435181
-------------------------------------------------------
Not saving because 0.416712 > 0.415650 (27.630: -0.00%)
======================================================= (12.121 sec)
31.351... logprob:  0.508462, 0.140625 (1.443 sec)
31.352... logprob:  0.363606, 0.093750 (1.440 sec)
31.353... logprob:  0.512400, 0.148438 (1.496 sec)
31.354... logprob:  0.674741, 0.203125 (1.430 sec)
31.355... logprob:  0.357504, 0.085938 (1.449 sec)
31.356... logprob:  0.479238, 0.132812 (1.479 sec)
31.357... logprob:  0.346690, 0.085938 (1.435 sec)
31.358... logprob:  0.325714, 0.070312 (1.438 sec)
31.359... logprob:  0.555403, 0.164062 (1.437 sec)
31.360... logprob:  0.444526, 0.117188 (1.424 sec)
31.361... logprob:  0.410727, 0.101562 (1.436 sec)
31.362... logprob:  0.423917, 0.117188 (1.480 sec)
31.363... logprob:  0.486596, 0.132812 (1.445 sec)
31.364... logprob:  0.475625, 0.125000 (1.455 sec)
31.365... logprob:  0.425036, 0.109375 (1.471 sec)
31.366... logprob:  0.409550, 0.109375 (1.451 sec)
31.367... logprob:  0.324885, 0.078125 (1.438 sec)
31.368... logprob:  0.595539, 0.171875 (1.434 sec)
31.369... logprob:  0.381679, 0.093750 (1.426 sec)
31.370... logprob:  0.381315, 0.093750 (1.437 sec)
31.371... logprob:  0.400435, 0.101562 (1.463 sec)
31.372... logprob:  0.537175, 0.156250 (1.453 sec)
31.373... logprob:  0.463782, 0.125000 (1.460 sec)
31.374... logprob:  0.526783, 0.148438 (1.447 sec)
31.375... logprob:  0.393765, 0.101562 (1.468 sec)
31.376... logprob:  0.374287, 0.093750 (1.440 sec)
31.377... logprob:  0.295448, 0.062500 (1.435 sec)
31.378... logprob:  0.453648, 0.125000 (1.429 sec)
31.379... logprob:  0.420245, 0.109375 (1.439 sec)
31.380... logprob:  0.605655, 0.179688 (1.444 sec)
31.381... logprob:  0.463405, 0.125000 (1.475 sec)
31.382... logprob:  0.529593, 0.148438 (1.449 sec)
31.383... logprob:  0.358506, 0.085938 (1.444 sec)
31.384... logprob:  0.521240, 0.148438 (1.482 sec)
31.385... logprob:  0.523606, 0.148438 (1.437 sec)
31.386... logprob:  0.582624, 0.171875 (1.452 sec)
31.387... logprob:  0.428479, 0.117188 (1.437 sec)
31.388... logprob:  0.521392, 0.148438 (1.440 sec)
31.389... logprob:  0.425516, 0.109375 (1.433 sec)
31.390... logprob:  0.419625, 0.109375 (1.474 sec)
31.391... logprob:  0.318099, 0.070312 (1.440 sec)
31.392... logprob:  0.439451, 0.117188 (1.441 sec)
31.393... logprob:  0.369056, 0.093750 (1.482 sec)
31.394... logprob:  0.343742, 0.078125 (1.440 sec)
31.395... logprob:  0.331965, 0.078125 (1.430 sec)
31.396... logprob:  0.252721, 0.046875 (1.440 sec)
31.397... logprob:  0.483988, 0.132812 (1.431 sec)
31.398... logprob:  0.470533, 0.125000 (1.442 sec)
31.399... logprob:  0.433058, 0.117188 (1.488 sec)
31.400... logprob:  0.537222, 0.148438 (1.438 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.65685272216797, 10.0]}, 128)
batch 872: ({'logprob': [68.6998519897461, 19.0]}, 128)
batch 873: ({'logprob': [39.652679443359375, 9.0]}, 128)
batch 874: ({'logprob': [44.728271484375, 11.0]}, 128)
batch 875: ({'logprob': [51.00764846801758, 13.0]}, 128)
batch 876: ({'logprob': [65.88975524902344, 18.0]}, 128)
batch 877: ({'logprob': [45.3409309387207, 11.0]}, 128)
batch 878: ({'logprob': [63.63136672973633, 17.0]}, 128)
batch 879: ({'logprob': [76.81183624267578, 21.0]}, 128)
batch 880: ({'logprob': [51.03596115112305, 13.0]}, 128)
batch 881: ({'logprob': [26.42963409423828, 5.0]}, 128)
batch 882: ({'logprob': [55.70033264160156, 14.0]}, 128)
batch 883: ({'logprob': [63.60197067260742, 17.0]}, 128)
batch 884: ({'logprob': [51.63096618652344, 13.0]}, 128)
batch 885: ({'logprob': [52.84131622314453, 13.0]}, 128)
batch 886: ({'logprob': [64.23571014404297, 17.0]}, 128)

======================Test output======================
logprob:  0.420847, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958953e-03 [5.493579e-09] 
Layer 'conv1' biases: 3.998892e-07 [2.051584e-10] 
Layer 'conv2' weights[0]: 7.946070e-03 [5.944887e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.233757e-09] 
Layer 'conv3' weights[0]: 7.944234e-03 [5.481616e-09] 
Layer 'conv3' biases: 3.375369e-06 [3.674713e-09] 
Layer 'conv4' weights[0]: 7.976922e-03 [5.552707e-09] 
Layer 'conv4' biases: 9.999991e-01 [3.143438e-08] 
Layer 'conv5' weights[0]: 7.975675e-03 [1.960827e-07] 
Layer 'conv5' biases: 9.999898e-01 [2.105771e-07] 
Layer 'fc6' weights[0]: 7.572279e-03 [1.623406e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.655654e-08] 
Layer 'fc7' weights[0]: 6.865397e-03 [4.519178e-08] 
Layer 'fc7' biases: 9.998566e-01 [2.401370e-08] 
Layer 'fc8' weights[0]: 1.343939e-03 [4.922971e-06] 
Layer 'fc8' biases: 7.736364e-02 [3.126852e-05] 
Train error last 870 batches: 0.435180
-------------------------------------------------------
Not saving because 0.420847 > 0.415650 (27.630: -0.00%)
======================================================= (12.077 sec)
31.401... logprob:  0.465527, 0.125000 (1.452 sec)
31.402... logprob:  0.473734, 0.125000 (1.491 sec)
31.403... logprob:  0.462062, 0.125000 (1.435 sec)
31.404... logprob:  0.474793, 0.125000 (1.441 sec)
31.405... logprob:  0.544341, 0.156250 (1.434 sec)
31.406... logprob:  0.357480, 0.085938 (1.433 sec)
31.407... logprob:  0.493100, 0.140625 (1.430 sec)
31.408... logprob:  0.338692, 0.078125 (1.484 sec)
31.409... logprob:  0.400294, 0.101562 (1.439 sec)
31.410... logprob:  0.582417, 0.171875 (1.454 sec)
31.411... logprob:  0.397623, 0.101562 (1.479 sec)
31.412... logprob:  0.540348, 0.156250 (1.443 sec)
31.413... logprob:  0.544653, 0.156250 (1.437 sec)
31.414... logprob:  0.466325, 0.125000 (1.434 sec)
31.415... logprob:  0.401613, 0.101562 (1.427 sec)
31.416... logprob:  0.427470, 0.109375 (1.442 sec)
31.417... logprob:  0.405463, 0.093750 (1.465 sec)
31.418... logprob:  0.380532, 0.093750 (1.451 sec)
31.419... logprob:  0.417940, 0.101562 (1.463 sec)
31.420... logprob:  0.356603, 0.085938 (1.459 sec)
31.421... logprob:  0.376687, 0.101562 (1.459 sec)
31.422... logprob:  0.521880, 0.148438 (1.440 sec)
31.423... logprob:  0.420759, 0.109375 (1.435 sec)
31.424... logprob:  0.324979, 0.078125 (1.431 sec)
31.425... logprob:  0.306593, 0.070312 (1.438 sec)
31.426... logprob:  0.448937, 0.117188 (1.450 sec)
31.427... logprob:  0.553826, 0.156250 (1.463 sec)
31.428... logprob:  0.601381, 0.171875 (1.455 sec)
31.429... logprob:  0.426363, 0.109375 (1.443 sec)
31.430... logprob:  0.299736, 0.070312 (1.481 sec)
31.431... logprob:  0.600190, 0.171875 (1.431 sec)
31.432... logprob:  0.387515, 0.093750 (1.434 sec)
31.433... logprob:  0.329490, 0.078125 (1.441 sec)
31.434... logprob:  0.529759, 0.148438 (1.439 sec)
31.435... logprob:  0.532625, 0.156250 (1.430 sec)
31.436... logprob:  0.380806, 0.093750 (1.483 sec)
31.437... logprob:  0.500359, 0.140625 (1.445 sec)
31.438... logprob:  0.547054, 0.156250 (1.432 sec)
31.439... logprob:  0.378454, 0.093750 (1.493 sec)
31.440... logprob:  0.439603, 0.117188 (1.432 sec)
31.441... logprob:  0.467928, 0.125000 (1.433 sec)
31.442... logprob:  0.378915, 0.093750 (1.440 sec)
31.443... logprob:  0.496554, 0.140625 (1.435 sec)
31.444... logprob:  0.372473, 0.093750 (1.439 sec)
31.445... logprob:  0.362729, 0.085938 (1.487 sec)
31.446... logprob:  0.398455, 0.101562 (1.436 sec)
31.447... logprob:  0.569340, 0.164062 (1.444 sec)
31.448... logprob:  0.333128, 0.078125 (1.478 sec)
31.449... logprob:  0.400055, 0.101562 (1.439 sec)
31.450... logprob:  0.239935, 0.046875 (1.432 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.06599807739258, 10.0]}, 128)
batch 872: ({'logprob': [67.56077575683594, 19.0]}, 128)
batch 873: ({'logprob': [39.84323501586914, 9.0]}, 128)
batch 874: ({'logprob': [44.788536071777344, 11.0]}, 128)
batch 875: ({'logprob': [50.71259689331055, 13.0]}, 128)
batch 876: ({'logprob': [64.87130737304688, 18.0]}, 128)
batch 877: ({'logprob': [45.28923416137695, 11.0]}, 128)
batch 878: ({'logprob': [62.62278366088867, 17.0]}, 128)
batch 879: ({'logprob': [74.97769165039062, 21.0]}, 128)
batch 880: ({'logprob': [50.74031448364258, 13.0]}, 128)
batch 881: ({'logprob': [27.447736740112305, 5.0]}, 128)
batch 882: ({'logprob': [54.94271469116211, 14.0]}, 128)
batch 883: ({'logprob': [62.5938720703125, 17.0]}, 128)
batch 884: ({'logprob': [51.22019577026367, 13.0]}, 128)
batch 885: ({'logprob': [52.20475769042969, 13.0]}, 128)
batch 886: ({'logprob': [63.112762451171875, 17.0]}, 128)

======================Test output======================
logprob:  0.416990, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958917e-03 [4.709172e-09] 
Layer 'conv1' biases: 4.008266e-07 [1.619568e-10] 
Layer 'conv2' weights[0]: 7.946027e-03 [4.800420e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.810121e-10] 
Layer 'conv3' weights[0]: 7.944198e-03 [4.359206e-09] 
Layer 'conv3' biases: 3.382810e-06 [2.660265e-09] 
Layer 'conv4' weights[0]: 7.976882e-03 [4.398732e-09] 
Layer 'conv4' biases: 9.999992e-01 [2.244726e-08] 
Layer 'conv5' weights[0]: 7.975630e-03 [1.417183e-07] 
Layer 'conv5' biases: 9.999896e-01 [1.522659e-07] 
Layer 'fc6' weights[0]: 7.572239e-03 [1.157384e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.187059e-08] 
Layer 'fc7' weights[0]: 6.863665e-03 [3.751413e-07] 
Layer 'fc7' biases: 9.998556e-01 [3.651851e-07] 
Layer 'fc8' weights[0]: 1.310163e-03 [1.374189e-05] 
Layer 'fc8' biases: 7.753714e-02 [9.693784e-05] 
Train error last 870 batches: 0.435180
-------------------------------------------------------
Not saving because 0.416990 > 0.415650 (27.630: -0.00%)
======================================================= (12.055 sec)
31.451... logprob:  0.452408, 0.125000 (1.447 sec)
31.452... logprob:  0.455916, 0.117188 (1.444 sec)
31.453... logprob:  0.455005, 0.125000 (1.436 sec)
31.454... logprob:  0.488796, 0.132812 (1.483 sec)
31.455... logprob:  0.505979, 0.140625 (1.448 sec)
31.456... logprob:  0.468841, 0.125000 (1.448 sec)
31.457... logprob:  0.375310, 0.093750 (1.474 sec)
31.458... logprob:  0.350926, 0.085938 (1.437 sec)
31.459... logprob:  0.514153, 0.140625 (1.443 sec)
31.460... logprob:  0.273513, 0.054688 (1.431 sec)
31.461... logprob:  0.460165, 0.125000 (1.428 sec)
31.462... logprob:  0.472021, 0.125000 (1.435 sec)
31.463... logprob:  0.420780, 0.109375 (1.475 sec)
31.464... logprob:  0.482823, 0.132812 (1.446 sec)
31.465... logprob:  0.421079, 0.109375 (1.457 sec)
31.466... logprob:  0.318191, 0.070312 (1.463 sec)
31.467... logprob:  0.413814, 0.109375 (1.449 sec)
31.468... logprob:  0.394249, 0.101562 (1.442 sec)
31.469... logprob:  0.334810, 0.078125 (1.431 sec)
31.470... logprob:  0.400111, 0.101562 (1.425 sec)
31.471... logprob:  0.529148, 0.148438 (1.443 sec)
31.472... logprob:  0.409966, 0.109375 (1.451 sec)
31.473... logprob:  0.375501, 0.093750 (1.460 sec)
31.474... logprob:  0.465464, 0.125000 (1.458 sec)
31.475... logprob:  0.503812, 0.140625 (1.448 sec)
31.476... logprob:  0.510090, 0.140625 (1.469 sec)
31.477... logprob:  0.334677, 0.078125 (1.439 sec)
31.478... logprob:  0.464217, 0.125000 (1.426 sec)
31.479... logprob:  0.305777, 0.070312 (1.435 sec)
31.480... logprob:  0.443499, 0.117188 (1.436 sec)
31.481... logprob:  0.547821, 0.156250 (1.443 sec)
31.482... logprob:  0.443129, 0.117188 (1.474 sec)
31.483... logprob:  0.502721, 0.140625 (1.446 sec)
31.484... logprob:  0.485328, 0.132812 (1.451 sec)
31.485... logprob:  0.408892, 0.109375 (1.481 sec)
31.486... logprob:  0.361211, 0.085938 (1.437 sec)
31.487... logprob:  0.522720, 0.148438 (1.433 sec)
31.488... logprob:  0.424678, 0.109375 (1.434 sec)
31.489... logprob:  0.415794, 0.109375 (1.438 sec)
31.490... logprob:  0.440684, 0.117188 (1.432 sec)
31.491... logprob:  0.313577, 0.070312 (1.487 sec)
31.492... logprob:  0.459511, 0.125000 (1.446 sec)
31.493... logprob:  0.521771, 0.148438 (1.459 sec)
31.494... logprob:  0.450340, 0.125000 (1.484 sec)
31.495... logprob:  0.380708, 0.093750 (1.430 sec)
31.496... logprob:  0.550150, 0.156250 (1.437 sec)
31.497... logprob:  0.466868, 0.125000 (1.435 sec)
31.498... logprob:  0.476190, 0.132812 (1.437 sec)
31.499... logprob:  0.456214, 0.125000 (1.438 sec)
31.500... logprob:  0.355177, 0.085938 (1.492 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.036407470703125, 10.0]}, 128)
batch 872: ({'logprob': [66.2984848022461, 19.0]}, 128)
batch 873: ({'logprob': [40.936187744140625, 9.0]}, 128)
batch 874: ({'logprob': [45.45341110229492, 11.0]}, 128)
batch 875: ({'logprob': [50.87959671020508, 13.0]}, 128)
batch 876: ({'logprob': [63.83952713012695, 18.0]}, 128)
batch 877: ({'logprob': [45.92008590698242, 11.0]}, 128)
batch 878: ({'logprob': [61.78904342651367, 17.0]}, 128)
batch 879: ({'logprob': [73.10784149169922, 21.0]}, 128)
batch 880: ({'logprob': [50.90644073486328, 13.0]}, 128)
batch 881: ({'logprob': [29.579254150390625, 5.0]}, 128)
batch 882: ({'logprob': [54.76688766479492, 14.0]}, 128)
batch 883: ({'logprob': [61.76063919067383, 17.0]}, 128)
batch 884: ({'logprob': [51.34683609008789, 13.0]}, 128)
batch 885: ({'logprob': [52.25973129272461, 13.0]}, 128)
batch 886: ({'logprob': [62.24087142944336, 17.0]}, 128)

======================Test output======================
logprob:  0.416563, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958879e-03 [2.866186e-09] 
Layer 'conv1' biases: 4.018365e-07 [5.308855e-11] 
Layer 'conv2' weights[0]: 7.945992e-03 [2.264808e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.617684e-10] 
Layer 'conv3' weights[0]: 7.944163e-03 [1.914261e-09] 
Layer 'conv3' biases: 3.394444e-06 [8.750013e-10] 
Layer 'conv4' weights[0]: 7.976844e-03 [2.037512e-09] 
Layer 'conv4' biases: 9.999991e-01 [7.643618e-09] 
Layer 'conv5' weights[0]: 7.975615e-03 [4.921080e-08] 
Layer 'conv5' biases: 9.999905e-01 [5.279479e-08] 
Layer 'fc6' weights[0]: 7.572190e-03 [4.103482e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.090179e-09] 
Layer 'fc7' weights[0]: 6.861917e-03 [3.816920e-08] 
Layer 'fc7' biases: 9.998546e-01 [1.320122e-08] 
Layer 'fc8' weights[0]: 1.264907e-03 [2.465880e-06] 
Layer 'fc8' biases: 7.737225e-02 [1.637117e-05] 
Train error last 870 batches: 0.435179
-------------------------------------------------------
Not saving because 0.416563 > 0.415650 (27.630: -0.00%)
======================================================= (12.098 sec)
31.501... logprob:  0.339135, 0.078125 (1.437 sec)
31.502... logprob:  0.459591, 0.125000 (1.455 sec)
31.503... logprob:  0.400658, 0.101562 (1.482 sec)
31.504... logprob:  0.487265, 0.132812 (1.434 sec)
31.505... logprob:  0.570757, 0.164062 (1.444 sec)
31.506... logprob:  0.479685, 0.132812 (1.442 sec)
31.507... logprob:  0.385008, 0.093750 (1.428 sec)
31.508... logprob:  0.374638, 0.093750 (1.435 sec)
31.509... logprob:  0.322953, 0.070312 (1.480 sec)
31.510... logprob:  0.390450, 0.101562 (1.446 sec)
31.511... logprob:  0.410037, 0.109375 (1.457 sec)
31.512... logprob:  0.470711, 0.125000 (1.466 sec)
31.513... logprob:  0.324958, 0.078125 (1.450 sec)
31.514... logprob:  0.406271, 0.101562 (1.436 sec)
31.515... logprob:  0.455441, 0.125000 (1.436 sec)
31.516... logprob:  0.400231, 0.109375 (1.423 sec)
31.517... logprob:  0.627681, 0.179688 (1.442 sec)
31.518... logprob:  0.437630, 0.117188 (1.460 sec)
31.519... logprob:  0.516125, 0.140625 (1.453 sec)
31.520... logprob:  0.409640, 0.109375 (1.458 sec)
31.521... logprob:  0.427409, 0.109375 (1.453 sec)
31.522... logprob:  0.533189, 0.156250 (1.465 sec)
31.523... logprob:  0.331433, 0.078125 (1.435 sec)
31.524... logprob:  0.437127, 0.117188 (1.430 sec)
31.525... logprob:  0.425861, 0.109375 (1.432 sec)
31.526... logprob:  0.351594, 0.078125 (1.449 sec)
31.527... logprob:  0.504587, 0.140625 (1.439 sec)
31.528... logprob:  0.440445, 0.117188 (1.471 sec)
31.529... logprob:  0.352997, 0.085938 (1.453 sec)
31.530... logprob:  0.440257, 0.117188 (1.440 sec)
31.531... logprob:  0.439940, 0.117188 (1.485 sec)
31.532... logprob:  0.467295, 0.125000 (1.432 sec)
31.533... logprob:  0.560243, 0.164062 (1.432 sec)
31.534... logprob:  0.325975, 0.078125 (1.435 sec)
31.535... logprob:  0.551372, 0.156250 (1.438 sec)
31.536... logprob:  0.507234, 0.140625 (1.432 sec)
31.537... logprob:  0.509980, 0.140625 (1.483 sec)
31.538... logprob:  0.486075, 0.132812 (1.443 sec)
31.539... logprob:  0.296005, 0.062500 (1.436 sec)
31.540... logprob:  0.447177, 0.117188 (1.485 sec)
31.541... logprob:  0.388767, 0.101562 (1.439 sec)
31.542... logprob:  0.411218, 0.109375 (1.431 sec)
31.543... logprob:  0.233162, 0.039062 (1.437 sec)
31.544... logprob:  0.317916, 0.070312 (1.431 sec)
31.545... logprob:  0.348795, 0.085938 (1.438 sec)
31.546... logprob:  0.368266, 0.093750 (1.485 sec)
31.547... logprob:  0.439983, 0.117188 (1.438 sec)
31.548... logprob:  0.452808, 0.125000 (1.443 sec)
31.549... logprob:  0.490359, 0.132812 (1.482 sec)
31.550... logprob:  0.367590, 0.093750 (1.433 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.84981918334961, 10.0]}, 128)
batch 872: ({'logprob': [68.37667846679688, 19.0]}, 128)
batch 873: ({'logprob': [39.576480865478516, 9.0]}, 128)
batch 874: ({'logprob': [44.71652603149414, 11.0]}, 128)
batch 875: ({'logprob': [50.87076950073242, 13.0]}, 128)
batch 876: ({'logprob': [65.58180236816406, 18.0]}, 128)
batch 877: ({'logprob': [45.23476791381836, 11.0]}, 128)
batch 878: ({'logprob': [63.24439239501953, 17.0]}, 128)
batch 879: ({'logprob': [76.08040618896484, 21.0]}, 128)
batch 880: ({'logprob': [50.89923858642578, 13.0]}, 128)
batch 881: ({'logprob': [26.69877815246582, 5.0]}, 128)
batch 882: ({'logprob': [55.26407241821289, 14.0]}, 128)
batch 883: ({'logprob': [63.21472930908203, 17.0]}, 128)
batch 884: ({'logprob': [51.39902877807617, 13.0]}, 128)
batch 885: ({'logprob': [52.420326232910156, 13.0]}, 128)
batch 886: ({'logprob': [63.75381088256836, 17.0]}, 128)

======================Test output======================
logprob:  0.419034, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958840e-03 [3.890432e-09] 
Layer 'conv1' biases: 4.027673e-07 [9.079042e-11] 
Layer 'conv2' weights[0]: 7.945968e-03 [3.665208e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.910582e-10] 
Layer 'conv3' weights[0]: 7.944130e-03 [3.037099e-09] 
Layer 'conv3' biases: 3.402555e-06 [1.818031e-09] 
Layer 'conv4' weights[0]: 7.976796e-03 [3.088212e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.426841e-08] 
Layer 'conv5' weights[0]: 7.975558e-03 [8.463300e-08] 
Layer 'conv5' biases: 9.999899e-01 [9.089872e-08] 
Layer 'fc6' weights[0]: 7.572147e-03 [7.032587e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.143786e-09] 
Layer 'fc7' weights[0]: 6.860176e-03 [5.008954e-08] 
Layer 'fc7' biases: 9.998565e-01 [3.032290e-08] 
Layer 'fc8' weights[0]: 1.326885e-03 [6.898310e-06] 
Layer 'fc8' biases: 7.790213e-02 [4.136353e-05] 
Train error last 870 batches: 0.435179
-------------------------------------------------------
Not saving because 0.419034 > 0.415650 (27.630: -0.00%)
======================================================= (12.060 sec)
31.551... logprob:  0.441593, 0.117188 (1.438 sec)
31.552... logprob:  0.471232, 0.125000 (1.444 sec)
31.553... logprob:  0.349450, 0.085938 (1.429 sec)
31.554... logprob:  0.507013, 0.140625 (1.432 sec)
31.555... logprob:  0.421408, 0.109375 (1.487 sec)
31.556... logprob:  0.355752, 0.085938 (1.435 sec)
31.557... logprob:  0.396336, 0.101562 (1.454 sec)
31.558... logprob:  0.382993, 0.101562 (1.470 sec)
31.559... logprob:  0.441648, 0.125000 (1.442 sec)
31.560... logprob:  0.334974, 0.078125 (1.438 sec)
31.561... logprob:  0.411780, 0.109375 (1.434 sec)
31.562... logprob:  0.503169, 0.140625 (1.424 sec)
31.563... logprob:  0.373737, 0.093750 (1.440 sec)
31.564... logprob:  0.468502, 0.132812 (1.468 sec)
31.565... logprob:  0.611181, 0.187500 (1.450 sec)
31.566... logprob:  0.374858, 0.093750 (1.457 sec)
31.567... logprob:  0.423281, 0.109375 (1.454 sec)
31.568... logprob:  0.496320, 0.140625 (1.460 sec)
31.569... logprob:  0.507659, 0.140625 (1.439 sec)
31.570... logprob:  0.543802, 0.164062 (1.426 sec)
31.571... logprob:  0.454887, 0.125000 (1.437 sec)
31.572... logprob:  0.501347, 0.140625 (1.443 sec)
31.573... logprob:  0.512591, 0.148438 (1.453 sec)
31.574... logprob:  0.428008, 0.109375 (1.468 sec)
31.575... logprob:  0.343323, 0.078125 (1.451 sec)
31.576... logprob:  0.427344, 0.109375 (1.450 sec)
31.577... logprob:  0.460778, 0.125000 (1.474 sec)
31.578... logprob:  0.336809, 0.078125 (1.440 sec)
31.579... logprob:  0.442079, 0.117188 (1.425 sec)
31.580... logprob:  0.546586, 0.156250 (1.436 sec)
31.581... logprob:  0.530574, 0.156250 (1.439 sec)
31.582... logprob:  0.437785, 0.125000 (1.436 sec)
31.583... logprob:  0.592356, 0.171875 (1.476 sec)
31.584... logprob:  0.468059, 0.132812 (1.450 sec)
31.585... logprob:  0.349769, 0.085938 (1.431 sec)
31.586... logprob:  0.313053, 0.070312 (1.489 sec)
31.587... logprob:  0.404295, 0.101562 (1.437 sec)
31.588... logprob:  0.418652, 0.117188 (1.429 sec)
31.589... logprob:  0.361136, 0.093750 (1.441 sec)
31.590... logprob:  0.524785, 0.148438 (1.433 sec)
31.591... logprob:  0.397450, 0.101562 (1.436 sec)
31.592... logprob:  0.455683, 0.125000 (1.481 sec)
31.593... logprob:  0.467416, 0.125000 (1.440 sec)
31.594... logprob:  0.352819, 0.085938 (1.442 sec)
31.595... logprob:  0.428659, 0.109375 (1.485 sec)
31.596... logprob:  0.461619, 0.125000 (1.429 sec)
31.597... logprob:  0.397418, 0.101562 (1.439 sec)
31.598... logprob:  0.397216, 0.101562 (1.436 sec)
31.599... logprob:  0.313585, 0.070312 (1.429 sec)
31.600... logprob:  0.340877, 0.085938 (1.447 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.99360656738281, 10.0]}, 128)
batch 872: ({'logprob': [66.85299682617188, 19.0]}, 128)
batch 873: ({'logprob': [40.54132080078125, 9.0]}, 128)
batch 874: ({'logprob': [44.96120834350586, 11.0]}, 128)
batch 875: ({'logprob': [50.76814651489258, 13.0]}, 128)
batch 876: ({'logprob': [64.32380676269531, 18.0]}, 128)
batch 877: ({'logprob': [45.665916442871094, 11.0]}, 128)
batch 878: ({'logprob': [62.44047927856445, 17.0]}, 128)
batch 879: ({'logprob': [74.75982666015625, 21.0]}, 128)
batch 880: ({'logprob': [50.794891357421875, 13.0]}, 128)
batch 881: ({'logprob': [28.181049346923828, 5.0]}, 128)
batch 882: ({'logprob': [55.445316314697266, 14.0]}, 128)
batch 883: ({'logprob': [62.41181945800781, 17.0]}, 128)
batch 884: ({'logprob': [51.477046966552734, 13.0]}, 128)
batch 885: ({'logprob': [52.86812973022461, 13.0]}, 128)
batch 886: ({'logprob': [63.13279342651367, 17.0]}, 128)

======================Test output======================
logprob:  0.417782, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958800e-03 [3.175648e-09] 
Layer 'conv1' biases: 4.039874e-07 [1.130177e-10] 
Layer 'conv2' weights[0]: 7.945940e-03 [2.885575e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.705368e-10] 
Layer 'conv3' weights[0]: 7.944094e-03 [2.778462e-09] 
Layer 'conv3' biases: 3.411819e-06 [1.727533e-09] 
Layer 'conv4' weights[0]: 7.976761e-03 [2.808668e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.467760e-08] 
Layer 'conv5' weights[0]: 7.975528e-03 [9.286025e-08] 
Layer 'conv5' biases: 9.999899e-01 [9.976770e-08] 
Layer 'fc6' weights[0]: 7.572108e-03 [7.658029e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.787142e-09] 
Layer 'fc7' weights[0]: 6.858445e-03 [1.508954e-07] 
Layer 'fc7' biases: 9.998556e-01 [1.399437e-07] 
Layer 'fc8' weights[0]: 1.294391e-03 [6.875516e-06] 
Layer 'fc8' biases: 7.778731e-02 [4.574633e-05] 
Train error last 870 batches: 0.435179
-------------------------------------------------------
Not saving because 0.417782 > 0.415650 (27.630: -0.00%)
======================================================= (12.040 sec)
31.601... logprob:  0.402158, 0.101562 (1.489 sec)
31.602... logprob:  0.289911, 0.062500 (1.441 sec)
31.603... logprob:  0.267231, 0.054688 (1.451 sec)
31.604... logprob:  0.407527, 0.101562 (1.478 sec)
31.605... logprob:  0.563248, 0.148438 (1.434 sec)
31.606... logprob:  0.295946, 0.070312 (1.436 sec)
31.607... logprob:  0.504660, 0.132812 (1.442 sec)
31.608... logprob:  0.361893, 0.085938 (1.431 sec)
31.609... logprob:  0.357061, 0.085938 (1.439 sec)
31.610... logprob:  0.493271, 0.132812 (1.481 sec)
31.611... logprob:  0.510318, 0.140625 (1.445 sec)
31.612... logprob:  0.448552, 0.117188 (1.458 sec)
31.613... logprob:  0.279297, 0.062500 (1.462 sec)
31.614... logprob:  0.503575, 0.140625 (1.448 sec)
31.615... logprob:  0.350769, 0.085938 (1.443 sec)
31.616... logprob:  0.415027, 0.109375 (1.428 sec)
31.617... logprob:  0.417811, 0.109375 (1.432 sec)
31.618... logprob:  0.547068, 0.156250 (1.438 sec)
31.619... logprob:  0.506138, 0.140625 (1.451 sec)
31.620... logprob:  0.539713, 0.156250 (1.474 sec)
31.621... logprob:  0.363534, 0.085938 (1.450 sec)
31.622... logprob:  0.364638, 0.085938 (1.453 sec)
31.623... logprob:  0.423112, 0.109375 (1.470 sec)
31.624... logprob:  0.382500, 0.093750 (1.437 sec)
31.625... logprob:  0.440977, 0.117188 (1.428 sec)
31.626... logprob:  0.438341, 0.117188 (1.430 sec)
31.627... logprob:  0.435817, 0.117188 (1.440 sec)
31.628... logprob:  0.465012, 0.125000 (1.439 sec)
31.629... logprob:  0.372166, 0.093750 (1.478 sec)
31.630... logprob:  0.422387, 0.109375 (1.445 sec)
31.631... logprob:  0.638295, 0.187500 (1.442 sec)
31.632... logprob:  0.399125, 0.101562 (1.484 sec)
31.633... logprob:  0.376128, 0.093750 (1.436 sec)
31.634... logprob:  0.660013, 0.195312 (1.429 sec)
31.635... logprob:  0.374124, 0.093750 (1.435 sec)
31.636... logprob:  0.480264, 0.132812 (1.438 sec)
31.637... logprob:  0.330720, 0.078125 (1.436 sec)
31.638... logprob:  0.515712, 0.140625 (1.479 sec)
31.639... logprob:  0.418017, 0.109375 (1.442 sec)
31.640... logprob:  0.528763, 0.148438 (1.441 sec)
31.641... logprob:  0.410399, 0.109375 (1.482 sec)
31.642... logprob:  0.500917, 0.140625 (1.439 sec)
31.643... logprob:  0.623330, 0.187500 (1.430 sec)
31.644... logprob:  0.320878, 0.070312 (1.441 sec)
31.645... logprob:  0.414442, 0.109375 (1.428 sec)
31.646... logprob:  0.385545, 0.093750 (1.438 sec)
31.647... logprob:  0.456797, 0.125000 (1.487 sec)
31.648... logprob:  0.491279, 0.140625 (1.437 sec)
31.649... logprob:  0.370334, 0.093750 (1.443 sec)
31.650... logprob:  0.414044, 0.109375 (1.480 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.0053596496582, 10.0]}, 128)
batch 872: ({'logprob': [66.32514190673828, 19.0]}, 128)
batch 873: ({'logprob': [40.893733978271484, 9.0]}, 128)
batch 874: ({'logprob': [45.42648696899414, 11.0]}, 128)
batch 875: ({'logprob': [50.86509704589844, 13.0]}, 128)
batch 876: ({'logprob': [63.85948181152344, 18.0]}, 128)
batch 877: ({'logprob': [45.8917350769043, 11.0]}, 128)
batch 878: ({'logprob': [61.800201416015625, 17.0]}, 128)
batch 879: ({'logprob': [73.14276885986328, 21.0]}, 128)
batch 880: ({'logprob': [50.892173767089844, 13.0]}, 128)
batch 881: ({'logprob': [29.512733459472656, 5.0]}, 128)
batch 882: ({'logprob': [54.75525665283203, 14.0]}, 128)
batch 883: ({'logprob': [61.77142333984375, 17.0]}, 128)
batch 884: ({'logprob': [51.331153869628906, 13.0]}, 128)
batch 885: ({'logprob': [52.240867614746094, 13.0]}, 128)
batch 886: ({'logprob': [62.25053787231445, 17.0]}, 128)

======================Test output======================
logprob:  0.416486, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958762e-03 [2.724859e-09] 
Layer 'conv1' biases: 4.050221e-07 [8.029794e-11] 
Layer 'conv2' weights[0]: 7.945906e-03 [2.179188e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.327670e-10] 
Layer 'conv3' weights[0]: 7.944061e-03 [2.132216e-09] 
Layer 'conv3' biases: 3.420701e-06 [1.284068e-09] 
Layer 'conv4' weights[0]: 7.976727e-03 [2.338545e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.230942e-08] 
Layer 'conv5' weights[0]: 7.975491e-03 [7.995279e-08] 
Layer 'conv5' biases: 9.999899e-01 [8.586861e-08] 
Layer 'fc6' weights[0]: 7.572070e-03 [6.502497e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.630192e-09] 
Layer 'fc7' weights[0]: 6.856712e-03 [2.294660e-07] 
Layer 'fc7' biases: 9.998544e-01 [2.188723e-07] 
Layer 'fc8' weights[0]: 1.269507e-03 [1.003274e-05] 
Layer 'fc8' biases: 7.776914e-02 [7.130746e-05] 
Train error last 870 batches: 0.435178
-------------------------------------------------------
Not saving because 0.416486 > 0.415650 (27.630: -0.00%)
======================================================= (12.048 sec)
31.651... logprob:  0.397422, 0.101562 (1.437 sec)
31.652... logprob:  0.507043, 0.140625 (1.451 sec)
31.653... logprob:  0.547663, 0.156250 (1.440 sec)
31.654... logprob:  0.495986, 0.140625 (1.427 sec)
31.655... logprob:  0.436174, 0.117188 (1.436 sec)
31.656... logprob:  0.416720, 0.109375 (1.477 sec)
31.657... logprob:  0.449019, 0.117188 (1.446 sec)
31.658... logprob:  0.345904, 0.085938 (1.448 sec)
31.659... logprob:  0.464271, 0.125000 (1.475 sec)
31.660... logprob:  0.446059, 0.125000 (1.442 sec)
31.661... logprob:  0.378394, 0.093750 (1.442 sec)
31.662... logprob:  0.469479, 0.132812 (1.429 sec)
31.663... logprob:  0.310838, 0.070312 (1.429 sec)
31.664... logprob:  0.285336, 0.062500 (1.436 sec)
31.665... logprob:  0.401662, 0.101562 (1.464 sec)
31.666... logprob:  0.442019, 0.117188 (1.457 sec)
31.667... logprob:  0.564196, 0.164062 (1.452 sec)
31.668... logprob:  0.497838, 0.140625 (1.456 sec)
31.669... logprob:  0.432894, 0.109375 (1.462 sec)
31.670... logprob:  0.362338, 0.085938 (1.441 sec)
31.671... logprob:  0.360875, 0.093750 (1.426 sec)
31.672... logprob:  0.441828, 0.117188 (1.430 sec)
31.673... logprob:  0.436224, 0.117188 (1.444 sec)
31.674... logprob:  0.446625, 0.117188 (1.445 sec)
31.675... logprob:  0.356687, 0.093750 (1.472 sec)
31.676... logprob:  0.450192, 0.125000 (1.450 sec)
31.677... logprob:  0.471012, 0.125000 (1.444 sec)
31.678... logprob:  0.465663, 0.125000 (1.481 sec)
31.679... logprob:  0.454862, 0.125000 (1.433 sec)
31.680... logprob:  0.351643, 0.078125 (1.431 sec)
31.681... logprob:  0.373850, 0.093750 (1.433 sec)
31.682... logprob:  0.340456, 0.078125 (1.442 sec)
31.683... logprob:  0.411629, 0.109375 (1.433 sec)
31.684... logprob:  0.357714, 0.085938 (1.482 sec)
31.685... logprob:  0.286250, 0.054688 (1.443 sec)
31.686... logprob:  0.318850, 0.070312 (1.438 sec)
31.687... logprob:  0.281837, 0.062500 (1.484 sec)
31.688... logprob:  0.323157, 0.078125 (1.436 sec)
31.689... logprob:  0.470864, 0.125000 (1.434 sec)
31.690... logprob:  0.527274, 0.140625 (1.438 sec)
31.691... logprob:  0.516068, 0.140625 (1.433 sec)
31.692... logprob:  0.384706, 0.101562 (1.430 sec)
31.693... logprob:  0.455427, 0.125000 (1.492 sec)
31.694... logprob:  0.330965, 0.078125 (1.432 sec)
31.695... logprob:  0.356959, 0.085938 (1.448 sec)
31.696... logprob:  0.539336, 0.148438 (1.479 sec)
31.697... logprob:  0.465814, 0.125000 (1.436 sec)
31.698... logprob:  0.549139, 0.156250 (1.432 sec)
31.699... logprob:  0.459642, 0.125000 (1.437 sec)
31.700... logprob:  0.433778, 0.117188 (1.434 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.95008850097656, 10.0]}, 128)
batch 872: ({'logprob': [65.94505310058594, 19.0]}, 128)
batch 873: ({'logprob': [41.89970397949219, 9.0]}, 128)
batch 874: ({'logprob': [46.18455505371094, 11.0]}, 128)
batch 875: ({'logprob': [51.32762145996094, 13.0]}, 128)
batch 876: ({'logprob': [63.61457443237305, 18.0]}, 128)
batch 877: ({'logprob': [46.62646484375, 11.0]}, 128)
batch 878: ({'logprob': [61.667930603027344, 17.0]}, 128)
batch 879: ({'logprob': [72.39148712158203, 21.0]}, 128)
batch 880: ({'logprob': [51.353885650634766, 13.0]}, 128)
batch 881: ({'logprob': [31.13910675048828, 5.0]}, 128)
batch 882: ({'logprob': [55.00547790527344, 14.0]}, 128)
batch 883: ({'logprob': [61.63966369628906, 17.0]}, 128)
batch 884: ({'logprob': [51.765811920166016, 13.0]}, 128)
batch 885: ({'logprob': [52.626243591308594, 13.0]}, 128)
batch 886: ({'logprob': [62.09202575683594, 17.0]}, 128)

======================Test output======================
logprob:  0.419057, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958718e-03 [3.333856e-09] 
Layer 'conv1' biases: 4.060009e-07 [5.751943e-11] 
Layer 'conv2' weights[0]: 7.945865e-03 [1.989885e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.251298e-10] 
Layer 'conv3' weights[0]: 7.944025e-03 [1.533773e-09] 
Layer 'conv3' biases: 3.432731e-06 [7.468844e-10] 
Layer 'conv4' weights[0]: 7.976696e-03 [1.432370e-09] 
Layer 'conv4' biases: 9.999991e-01 [4.455731e-09] 
Layer 'conv5' weights[0]: 7.975476e-03 [2.473065e-08] 
Layer 'conv5' biases: 9.999908e-01 [2.634844e-08] 
Layer 'fc6' weights[0]: 7.572019e-03 [2.218805e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.082885e-09] 
Layer 'fc7' weights[0]: 6.855002e-03 [3.617413e-07] 
Layer 'fc7' biases: 9.998536e-01 [3.531432e-07] 
Layer 'fc8' weights[0]: 1.246886e-03 [1.329953e-05] 
Layer 'fc8' biases: 7.773108e-02 [8.482911e-05] 
Train error last 870 batches: 0.435178
-------------------------------------------------------
Not saving because 0.419057 > 0.415650 (27.630: -0.00%)
======================================================= (12.071 sec)
31.701... logprob:  0.422864, 0.109375 (1.439 sec)
31.702... logprob:  0.521597, 0.148438 (1.495 sec)
31.703... logprob:  0.404860, 0.101562 (1.442 sec)
31.704... logprob:  0.405847, 0.101562 (1.451 sec)
31.705... logprob:  0.420049, 0.109375 (1.477 sec)
31.706... logprob:  0.468045, 0.125000 (1.436 sec)
31.707... logprob:  0.485296, 0.132812 (1.439 sec)
31.708... logprob:  0.417258, 0.109375 (1.432 sec)
31.709... logprob:  0.422708, 0.109375 (1.429 sec)
31.710... logprob:  0.601939, 0.179688 (1.439 sec)
31.711... logprob:  0.469458, 0.125000 (1.469 sec)
31.712... logprob:  0.341081, 0.078125 (1.449 sec)
31.713... logprob:  0.586242, 0.179688 (1.456 sec)
31.714... logprob:  0.466221, 0.125000 (1.460 sec)
31.715... logprob:  0.417215, 0.109375 (1.457 sec)
31.716... logprob:  0.335559, 0.078125 (1.443 sec)
31.717... logprob:  0.429765, 0.117188 (1.432 sec)
31.718... logprob:  0.490282, 0.132812 (1.429 sec)
31.719... logprob:  0.406175, 0.109375 (1.443 sec)
31.720... logprob:  0.433221, 0.117188 (1.453 sec)
31.721... logprob:  0.451602, 0.117188 (1.467 sec)
31.722... logprob:  0.537057, 0.156250 (1.453 sec)
31.723... logprob:  0.416537, 0.109375 (1.448 sec)
31.724... logprob:  0.412756, 0.109375 (1.471 sec)
31.725... logprob:  0.494909, 0.140625 (1.438 sec)
31.726... logprob:  0.338354, 0.085938 (1.431 sec)
31.727... logprob:  0.393159, 0.101562 (1.431 sec)
31.728... logprob:  0.421177, 0.109375 (1.443 sec)
31.729... logprob:  0.387516, 0.093750 (1.434 sec)
31.730... logprob:  0.565971, 0.164062 (1.475 sec)
31.731... logprob:  0.450434, 0.125000 (1.449 sec)
31.732... logprob:  0.311357, 0.070312 (1.435 sec)
31.733... logprob:  0.556459, 0.156250 (1.490 sec)
31.734... logprob:  0.340252, 0.078125 (1.431 sec)
31.735... logprob:  0.527386, 0.148438 (1.433 sec)
31.736... logprob:  0.642476, 0.187500 (1.435 sec)
31.737... logprob:  0.516074, 0.148438 (1.436 sec)
31.738... logprob:  0.459376, 0.125000 (1.433 sec)
31.739... logprob:  0.477783, 0.132812 (1.490 sec)
31.740... logprob:  0.339644, 0.078125 (1.444 sec)
31.741... logprob:  0.393482, 0.101562 (1.441 sec)
31.742... logprob:  0.419680, 0.109375 (1.480 sec)
31.743... logprob:  0.364900, 0.085938 (1.439 sec)
31.744... logprob:  0.519118, 0.148438 (1.430 sec)
31.745... logprob:  0.478122, 0.132812 (1.442 sec)
31.746... logprob:  0.440542, 0.117188 (1.429 sec)
31.747... logprob:  0.425599, 0.109375 (1.437 sec)
31.748... logprob:  0.378165, 0.093750 (1.487 sec)
31.749... logprob:  0.420798, 0.109375 (1.436 sec)
31.750... logprob:  0.512738, 0.140625 (1.449 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.466468811035156, 10.0]}, 128)
batch 872: ({'logprob': [66.6719741821289, 19.0]}, 128)
batch 873: ({'logprob': [40.470481872558594, 9.0]}, 128)
batch 874: ({'logprob': [45.08299255371094, 11.0]}, 128)
batch 875: ({'logprob': [50.72454833984375, 13.0]}, 128)
batch 876: ({'logprob': [64.13609313964844, 18.0]}, 128)
batch 877: ({'logprob': [45.609371185302734, 11.0]}, 128)
batch 878: ({'logprob': [62.06711959838867, 17.0]}, 128)
batch 879: ({'logprob': [73.8785171508789, 21.0]}, 128)
batch 880: ({'logprob': [50.751773834228516, 13.0]}, 128)
batch 881: ({'logprob': [28.619260787963867, 5.0]}, 128)
batch 882: ({'logprob': [54.87236785888672, 14.0]}, 128)
batch 883: ({'logprob': [62.038211822509766, 17.0]}, 128)
batch 884: ({'logprob': [51.25416564941406, 13.0]}, 128)
batch 885: ({'logprob': [52.28760528564453, 13.0]}, 128)
batch 886: ({'logprob': [62.580230712890625, 17.0]}, 128)

======================Test output======================
logprob:  0.416265, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958681e-03 [4.261280e-09] 
Layer 'conv1' biases: 4.069766e-07 [9.949806e-11] 
Layer 'conv2' weights[0]: 7.945836e-03 [2.689285e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.245659e-10] 
Layer 'conv3' weights[0]: 7.943986e-03 [2.105688e-09] 
Layer 'conv3' biases: 3.437909e-06 [1.239726e-09] 
Layer 'conv4' weights[0]: 7.976662e-03 [2.122287e-09] 
Layer 'conv4' biases: 9.999990e-01 [9.033500e-09] 
Layer 'conv5' weights[0]: 7.975410e-03 [5.827901e-08] 
Layer 'conv5' biases: 9.999900e-01 [6.249800e-08] 
Layer 'fc6' weights[0]: 7.571976e-03 [4.868411e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.862434e-09] 
Layer 'fc7' weights[0]: 6.853258e-03 [7.400557e-08] 
Layer 'fc7' biases: 9.998547e-01 [5.855722e-08] 
Layer 'fc8' weights[0]: 1.287425e-03 [6.582090e-06] 
Layer 'fc8' biases: 7.818801e-02 [4.585870e-05] 
Train error last 870 batches: 0.435178
-------------------------------------------------------
Not saving because 0.416265 > 0.415650 (27.630: -0.00%)
======================================================= (12.057 sec)
31.751... logprob:  0.263749, 0.054688 (1.477 sec)
31.752... logprob:  0.522499, 0.140625 (1.436 sec)
31.753... logprob:  0.441134, 0.117188 (1.440 sec)
31.754... logprob:  0.468237, 0.132812 (1.432 sec)
31.755... logprob:  0.507032, 0.140625 (1.430 sec)
31.756... logprob:  0.440839, 0.117188 (1.438 sec)
31.757... logprob:  0.552504, 0.156250 (1.471 sec)
31.758... logprob:  0.393532, 0.101562 (1.451 sec)
31.759... logprob:  0.459702, 0.125000 (1.455 sec)
31.760... logprob:  0.485587, 0.132812 (1.461 sec)
31.761... logprob:  0.418111, 0.109375 (1.451 sec)
31.762... logprob:  0.516085, 0.148438 (1.438 sec)
31.763... logprob:  0.559042, 0.164062 (1.429 sec)
31.764... logprob:  0.503263, 0.140625 (1.431 sec)
31.765... logprob:  0.311587, 0.062500 (1.437 sec)
31.766... logprob:  0.482190, 0.132812 (1.456 sec)
31.767... logprob:  0.371052, 0.085938 (1.463 sec)
31.768... logprob:  0.432634, 0.117188 (1.471 sec)
31.769... logprob:  0.490774, 0.140625 (1.464 sec)
31.770... logprob:  0.403022, 0.101562 (1.497 sec)
31.771... logprob:  0.549322, 0.156250 (1.457 sec)
31.772... logprob:  0.414122, 0.109375 (1.446 sec)
31.773... logprob:  0.557548, 0.164062 (1.451 sec)
31.774... logprob:  0.361859, 0.085938 (1.458 sec)
31.775... logprob:  0.407419, 0.101562 (1.465 sec)
31.776... logprob:  0.433132, 0.117188 (1.481 sec)
31.777... logprob:  0.380000, 0.093750 (1.474 sec)
31.778... logprob:  0.433523, 0.117188 (1.464 sec)
31.779... logprob:  0.505284, 0.140625 (1.488 sec)
31.780... logprob:  0.385764, 0.101562 (1.460 sec)
31.781... logprob:  0.369615, 0.085938 (1.447 sec)
31.782... logprob:  0.351388, 0.085938 (1.450 sec)
31.783... logprob:  0.555544, 0.156250 (1.460 sec)
31.784... logprob:  0.440960, 0.117188 (1.461 sec)
31.785... logprob:  0.543772, 0.156250 (1.491 sec)
31.786... logprob:  0.477597, 0.132812 (1.476 sec)
31.787... logprob:  0.546591, 0.156250 (1.458 sec)
31.788... logprob:  0.563380, 0.164062 (1.501 sec)
31.789... logprob:  0.280459, 0.054688 (1.453 sec)
31.790... logprob:  0.407820, 0.101562 (1.447 sec)
31.791... logprob:  0.397777, 0.101562 (1.449 sec)
31.792... logprob:  0.360823, 0.085938 (1.464 sec)
31.793... logprob:  0.370006, 0.085938 (1.457 sec)
31.794... logprob:  0.387118, 0.093750 (1.498 sec)
31.795... logprob:  0.469697, 0.125000 (1.468 sec)
31.796... logprob:  0.423515, 0.109375 (1.456 sec)
31.797... logprob:  0.358936, 0.085938 (1.499 sec)
31.798... logprob:  0.393308, 0.101562 (1.454 sec)
31.799... logprob:  0.332549, 0.078125 (1.453 sec)
31.800... logprob:  0.371677, 0.093750 (1.450 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.221492767333984, 10.0]}, 128)
batch 872: ({'logprob': [68.24776458740234, 19.0]}, 128)
batch 873: ({'logprob': [39.44737243652344, 9.0]}, 128)
batch 874: ({'logprob': [44.78128433227539, 11.0]}, 128)
batch 875: ({'logprob': [50.806121826171875, 13.0]}, 128)
batch 876: ({'logprob': [65.43704986572266, 18.0]}, 128)
batch 877: ({'logprob': [45.1384162902832, 11.0]}, 128)
batch 878: ({'logprob': [62.92200469970703, 17.0]}, 128)
batch 879: ({'logprob': [75.33936309814453, 21.0]}, 128)
batch 880: ({'logprob': [50.8349723815918, 13.0]}, 128)
batch 881: ({'logprob': [26.989152908325195, 5.0]}, 128)
batch 882: ({'logprob': [54.73162841796875, 14.0]}, 128)
batch 883: ({'logprob': [62.89208221435547, 17.0]}, 128)
batch 884: ({'logprob': [51.17282485961914, 13.0]}, 128)
batch 885: ({'logprob': [51.87113571166992, 13.0]}, 128)
batch 886: ({'logprob': [63.269718170166016, 17.0]}, 128)

======================Test output======================
logprob:  0.417530, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958648e-03 [2.989890e-09] 
Layer 'conv1' biases: 4.080561e-07 [8.800454e-11] 
Layer 'conv2' weights[0]: 7.945791e-03 [1.826595e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.761216e-10] 
Layer 'conv3' weights[0]: 7.943945e-03 [1.551096e-09] 
Layer 'conv3' biases: 3.445066e-06 [6.946418e-10] 
Layer 'conv4' weights[0]: 7.976619e-03 [1.588436e-09] 
Layer 'conv4' biases: 9.999992e-01 [5.950523e-09] 
Layer 'conv5' weights[0]: 7.975362e-03 [3.803487e-08] 
Layer 'conv5' biases: 9.999896e-01 [4.082425e-08] 
Layer 'fc6' weights[0]: 7.571934e-03 [3.214780e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.188213e-09] 
Layer 'fc7' weights[0]: 6.851525e-03 [2.561437e-07] 
Layer 'fc7' biases: 9.998557e-01 [2.466925e-07] 
Layer 'fc8' weights[0]: 1.321615e-03 [9.898923e-06] 
Layer 'fc8' biases: 7.859389e-02 [6.994103e-05] 
Train error last 870 batches: 0.435178
-------------------------------------------------------
Not saving because 0.417530 > 0.415650 (27.630: -0.00%)
======================================================= (12.042 sec)
31.801... logprob:  0.449858, 0.117188 (1.470 sec)
31.802... logprob:  0.422809, 0.109375 (1.460 sec)
31.803... logprob:  0.491307, 0.132812 (1.495 sec)
31.804... logprob:  0.349941, 0.085938 (1.462 sec)
31.805... logprob:  0.452260, 0.117188 (1.491 sec)
31.806... logprob:  0.424170, 0.109375 (1.504 sec)
31.807... logprob:  0.443479, 0.117188 (1.450 sec)
31.808... logprob:  0.462369, 0.125000 (1.444 sec)
31.809... logprob:  0.589868, 0.171875 (1.455 sec)
31.810... logprob:  0.442505, 0.117188 (1.454 sec)
31.811... logprob:  0.460424, 0.125000 (1.456 sec)
31.812... logprob:  0.462318, 0.125000 (1.499 sec)
31.813... logprob:  0.485949, 0.132812 (1.458 sec)
31.814... logprob:  0.477874, 0.132812 (1.460 sec)
31.815... logprob:  0.371295, 0.085938 (1.500 sec)
31.816... logprob:  0.408382, 0.101562 (1.456 sec)
31.817... logprob:  0.425755, 0.109375 (1.456 sec)
31.818... logprob:  0.560025, 0.164062 (1.455 sec)
31.819... logprob:  0.498175, 0.140625 (1.454 sec)
31.820... logprob:  0.421697, 0.109375 (1.459 sec)
31.821... logprob:  0.406738, 0.101562 (1.497 sec)
31.822... logprob:  0.441303, 0.117188 (1.461 sec)
31.823... logprob:  0.341235, 0.078125 (1.456 sec)
31.824... logprob:  0.489597, 0.132812 (1.504 sec)
31.825... logprob:  0.288547, 0.062500 (1.450 sec)
31.826... logprob:  0.375631, 0.093750 (1.459 sec)
31.827... logprob:  0.420418, 0.109375 (1.448 sec)
31.828... logprob:  0.443080, 0.117188 (1.458 sec)
31.829... logprob:  0.503648, 0.140625 (1.452 sec)
31.830... logprob:  0.441988, 0.117188 (1.505 sec)
31.831... logprob:  0.513767, 0.140625 (1.452 sec)
31.832... logprob:  0.330843, 0.078125 (1.463 sec)
31.833... logprob:  0.489065, 0.132812 (1.500 sec)
31.834... logprob:  0.433413, 0.117188 (1.450 sec)
31.835... logprob:  0.542986, 0.148438 (1.459 sec)
31.836... logprob:  0.376039, 0.093750 (1.451 sec)
31.837... logprob:  0.313870, 0.070312 (1.454 sec)
31.838... logprob:  0.437067, 0.117188 (1.455 sec)
31.839... logprob:  0.471634, 0.125000 (1.508 sec)
31.840... logprob:  0.555631, 0.156250 (1.460 sec)
31.841... logprob:  0.395936, 0.101562 (1.463 sec)
31.842... logprob:  0.497915, 0.140625 (1.497 sec)
31.843... logprob:  0.465481, 0.125000 (1.453 sec)
31.844... logprob:  0.497686, 0.140625 (1.461 sec)
31.845... logprob:  0.486715, 0.132812 (1.446 sec)
31.846... logprob:  0.468370, 0.125000 (1.456 sec)
31.847... logprob:  0.363457, 0.085938 (1.451 sec)
31.848... logprob:  0.397283, 0.101562 (1.501 sec)
31.849... logprob:  0.360683, 0.085938 (1.460 sec)
31.850... logprob:  0.479358, 0.132812 (1.465 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.486934661865234, 10.0]}, 128)
batch 872: ({'logprob': [66.4303970336914, 19.0]}, 128)
batch 873: ({'logprob': [40.93254852294922, 9.0]}, 128)
batch 874: ({'logprob': [45.64741516113281, 11.0]}, 128)
batch 875: ({'logprob': [50.98670196533203, 13.0]}, 128)
batch 876: ({'logprob': [63.94407272338867, 18.0]}, 128)
batch 877: ({'logprob': [45.97222137451172, 11.0]}, 128)
batch 878: ({'logprob': [61.72344970703125, 17.0]}, 128)
batch 879: ({'logprob': [72.7282485961914, 21.0]}, 128)
batch 880: ({'logprob': [51.0137939453125, 13.0]}, 128)
batch 881: ({'logprob': [29.890472412109375, 5.0]}, 128)
batch 882: ({'logprob': [54.47593307495117, 14.0]}, 128)
batch 883: ({'logprob': [61.694862365722656, 17.0]}, 128)
batch 884: ({'logprob': [51.31174850463867, 13.0]}, 128)
batch 885: ({'logprob': [51.94050598144531, 13.0]}, 128)
batch 886: ({'logprob': [62.033050537109375, 17.0]}, 128)

======================Test output======================
logprob:  0.416608, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958605e-03 [2.952846e-09] 
Layer 'conv1' biases: 4.091977e-07 [8.691644e-11] 
Layer 'conv2' weights[0]: 7.945760e-03 [2.416960e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.358598e-10] 
Layer 'conv3' weights[0]: 7.943906e-03 [2.253052e-09] 
Layer 'conv3' biases: 3.455152e-06 [1.345528e-09] 
Layer 'conv4' weights[0]: 7.976586e-03 [2.512480e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.243175e-08] 
Layer 'conv5' weights[0]: 7.975323e-03 [8.015158e-08] 
Layer 'conv5' biases: 9.999900e-01 [8.595400e-08] 
Layer 'fc6' weights[0]: 7.571898e-03 [6.507759e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.633490e-09] 
Layer 'fc7' weights[0]: 6.849800e-03 [2.426193e-07] 
Layer 'fc7' biases: 9.998540e-01 [2.323438e-07] 
Layer 'fc8' weights[0]: 1.258240e-03 [8.399412e-06] 
Layer 'fc8' biases: 7.842122e-02 [6.244450e-05] 
Train error last 870 batches: 0.435177
-------------------------------------------------------
Not saving because 0.416608 > 0.415650 (27.630: -0.00%)
======================================================= (12.038 sec)
31.851... logprob:  0.440139, 0.117188 (1.496 sec)
31.852... logprob:  0.545217, 0.156250 (1.464 sec)
31.853... logprob:  0.372071, 0.093750 (1.458 sec)
31.854... logprob:  0.307513, 0.070312 (1.453 sec)
31.855... logprob:  0.484625, 0.132812 (1.447 sec)
31.856... logprob:  0.443661, 0.117188 (1.453 sec)
31.857... logprob:  0.372234, 0.093750 (1.496 sec)
31.858... logprob:  0.396244, 0.101562 (1.463 sec)
31.859... logprob:  0.308014, 0.070312 (1.476 sec)
31.860... logprob:  0.565963, 0.156250 (1.559 sec)
31.861... logprob:  0.417793, 0.109375 (1.460 sec)
31.862... logprob:  0.328810, 0.078125 (1.460 sec)
31.863... logprob:  0.399592, 0.101562 (1.450 sec)
31.864... logprob:  0.451524, 0.117188 (1.445 sec)
31.865... logprob:  0.484680, 0.132812 (1.461 sec)
31.866... logprob:  0.507882, 0.140625 (1.485 sec)
31.867... logprob:  0.503258, 0.140625 (1.469 sec)
31.868... logprob:  0.405166, 0.101562 (1.474 sec)
31.869... logprob:  0.382995, 0.093750 (1.478 sec)
31.870... logprob:  0.552331, 0.156250 (1.402 sec)
32.1... logprob:  0.379826, 0.093750 (1.405 sec)
32.2... logprob:  0.448232, 0.117188 (1.448 sec)
32.3... logprob:  0.398204, 0.101562 (1.423 sec)
32.4... logprob:  0.443274, 0.117188 (1.411 sec)
32.5... logprob:  0.443494, 0.117188 (1.430 sec)
32.6... logprob:  0.499020, 0.140625 (1.400 sec)
32.7... logprob:  0.363366, 0.085938 (1.417 sec)
32.8... logprob:  0.419186, 0.109375 (1.415 sec)
32.9... logprob:  0.359006, 0.085938 (1.404 sec)
32.10... logprob:  0.377674, 0.093750 (1.410 sec)
32.11... logprob:  0.335040, 0.078125 (1.444 sec)
32.12... logprob:  0.466191, 0.125000 (1.392 sec)
32.13... logprob:  0.442086, 0.117188 (1.427 sec)
32.14... logprob:  0.444444, 0.117188 (1.408 sec)
32.15... logprob:  0.395456, 0.101562 (1.410 sec)
32.16... logprob:  0.421317, 0.109375 (1.409 sec)
32.17... logprob:  0.515874, 0.140625 (1.399 sec)
32.18... logprob:  0.262132, 0.054688 (1.399 sec)
32.19... logprob:  0.279442, 0.062500 (1.402 sec)
32.20... logprob:  0.421356, 0.109375 (1.409 sec)
32.21... logprob:  0.444002, 0.117188 (1.409 sec)
32.22... logprob:  0.536854, 0.148438 (1.423 sec)
32.23... logprob:  0.533273, 0.148438 (1.423 sec)
32.24... logprob:  0.310378, 0.070312 (1.420 sec)
32.25... logprob:  0.356053, 0.085938 (1.407 sec)
32.26... logprob:  0.463860, 0.125000 (1.447 sec)
32.27... logprob:  0.404469, 0.101562 (1.390 sec)
32.28... logprob:  0.421838, 0.109375 (1.408 sec)
32.29... logprob:  0.395869, 0.101562 (1.426 sec)
32.30... logprob:  0.374002, 0.093750 (1.416 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.36848068237305, 10.0]}, 128)
batch 872: ({'logprob': [66.89558410644531, 19.0]}, 128)
batch 873: ({'logprob': [40.41785430908203, 9.0]}, 128)
batch 874: ({'logprob': [45.444671630859375, 11.0]}, 128)
batch 875: ({'logprob': [50.9017333984375, 13.0]}, 128)
batch 876: ({'logprob': [64.30254364013672, 18.0]}, 128)
batch 877: ({'logprob': [45.6724853515625, 11.0]}, 128)
batch 878: ({'logprob': [61.877418518066406, 17.0]}, 128)
batch 879: ({'logprob': [73.02458953857422, 21.0]}, 128)
batch 880: ({'logprob': [50.92989730834961, 13.0]}, 128)
batch 881: ({'logprob': [29.233041763305664, 5.0]}, 128)
batch 882: ({'logprob': [54.211334228515625, 14.0]}, 128)
batch 883: ({'logprob': [61.84798812866211, 17.0]}, 128)
batch 884: ({'logprob': [51.13251876831055, 13.0]}, 128)
batch 885: ({'logprob': [51.56869888305664, 13.0]}, 128)
batch 886: ({'logprob': [62.09156036376953, 17.0]}, 128)

======================Test output======================
logprob:  0.415977, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958571e-03 [2.556330e-09] 
Layer 'conv1' biases: 4.102659e-07 [7.699535e-11] 
Layer 'conv2' weights[0]: 7.945721e-03 [2.542350e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.992989e-10] 
Layer 'conv3' weights[0]: 7.943870e-03 [2.297859e-09] 
Layer 'conv3' biases: 3.465463e-06 [1.187800e-09] 
Layer 'conv4' weights[0]: 7.976548e-03 [2.468805e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.094121e-08] 
Layer 'conv5' weights[0]: 7.975295e-03 [7.070916e-08] 
Layer 'conv5' biases: 9.999905e-01 [7.581309e-08] 
Layer 'fc6' weights[0]: 7.571863e-03 [5.776734e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.869692e-09] 
Layer 'fc7' weights[0]: 6.848068e-03 [3.880907e-08] 
Layer 'fc7' biases: 9.998542e-01 [1.489493e-08] 
Layer 'fc8' weights[0]: 1.268194e-03 [1.195727e-06] 
Layer 'fc8' biases: 7.864765e-02 [9.035418e-06] 
Train error last 870 batches: 0.435177
-------------------------------------------------------
Not saving because 0.415977 > 0.415650 (27.630: -0.00%)
======================================================= (12.120 sec)
32.31... logprob:  0.479998, 0.132812 (1.414 sec)
32.32... logprob:  0.457221, 0.125000 (1.398 sec)
32.33... logprob:  0.460680, 0.125000 (1.459 sec)
32.34... logprob:  0.464496, 0.125000 (1.396 sec)
32.35... logprob:  0.316358, 0.070312 (1.405 sec)
32.36... logprob:  0.475792, 0.132812 (1.408 sec)
32.37... logprob:  0.417594, 0.109375 (1.412 sec)
32.38... logprob:  0.392739, 0.101562 (1.397 sec)
32.39... logprob:  0.631292, 0.187500 (1.445 sec)
32.40... logprob:  0.445633, 0.117188 (1.416 sec)
32.41... logprob:  0.353051, 0.085938 (1.432 sec)
32.42... logprob:  0.392061, 0.101562 (1.450 sec)
32.43... logprob:  0.440067, 0.117188 (1.407 sec)
32.44... logprob:  0.518571, 0.148438 (1.441 sec)
32.45... logprob:  0.381710, 0.093750 (1.398 sec)
32.46... logprob:  0.486129, 0.132812 (1.398 sec)
32.47... logprob:  0.331715, 0.078125 (1.395 sec)
32.48... logprob:  0.498954, 0.140625 (1.424 sec)
32.49... logprob:  0.510950, 0.148438 (1.418 sec)
32.50... logprob:  0.393171, 0.101562 (1.425 sec)
32.51... logprob:  0.490337, 0.140625 (1.418 sec)
32.52... logprob:  0.525794, 0.148438 (1.403 sec)
32.53... logprob:  0.294723, 0.062500 (1.445 sec)
32.54... logprob:  0.403446, 0.109375 (1.392 sec)
32.55... logprob:  0.331661, 0.078125 (1.400 sec)
32.56... logprob:  0.421584, 0.109375 (1.405 sec)
32.57... logprob:  0.572303, 0.164062 (1.429 sec)
32.58... logprob:  0.407482, 0.101562 (1.404 sec)
32.59... logprob:  0.333867, 0.078125 (1.464 sec)
32.60... logprob:  0.618652, 0.179688 (1.427 sec)
32.61... logprob:  0.382779, 0.093750 (1.428 sec)
32.62... logprob:  0.474828, 0.132812 (1.465 sec)
32.63... logprob:  0.397284, 0.101562 (1.440 sec)
32.64... logprob:  0.450343, 0.125000 (1.413 sec)
32.65... logprob:  0.373396, 0.093750 (1.399 sec)
32.66... logprob:  0.354050, 0.085938 (1.457 sec)
32.67... logprob:  0.295431, 0.062500 (1.398 sec)
32.68... logprob:  0.396796, 0.101562 (1.400 sec)
32.69... logprob:  0.496624, 0.140625 (1.428 sec)
32.70... logprob:  0.325915, 0.078125 (1.429 sec)
32.71... logprob:  0.381793, 0.101562 (1.468 sec)
32.72... logprob:  0.493653, 0.132812 (1.409 sec)
32.73... logprob:  0.447659, 0.117188 (1.437 sec)
32.74... logprob:  0.442493, 0.117188 (1.423 sec)
32.75... logprob:  0.380660, 0.093750 (1.414 sec)
32.76... logprob:  0.412037, 0.109375 (1.441 sec)
32.77... logprob:  0.396344, 0.101562 (1.428 sec)
32.78... logprob:  0.493049, 0.140625 (1.456 sec)
32.79... logprob:  0.456485, 0.125000 (1.407 sec)
32.80... logprob:  0.508083, 0.132812 (1.418 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.6319580078125, 10.0]}, 128)
batch 872: ({'logprob': [66.33533477783203, 19.0]}, 128)
batch 873: ({'logprob': [40.88608932495117, 9.0]}, 128)
batch 874: ({'logprob': [45.2801513671875, 11.0]}, 128)
batch 875: ({'logprob': [50.817317962646484, 13.0]}, 128)
batch 876: ({'logprob': [63.87991714477539, 18.0]}, 128)
batch 877: ({'logprob': [45.86362075805664, 11.0]}, 128)
batch 878: ({'logprob': [61.94891357421875, 17.0]}, 128)
batch 879: ({'logprob': [73.6057357788086, 21.0]}, 128)
batch 880: ({'logprob': [50.844032287597656, 13.0]}, 128)
batch 881: ({'logprob': [29.189668655395508, 5.0]}, 128)
batch 882: ({'logprob': [55.0527458190918, 14.0]}, 128)
batch 883: ({'logprob': [61.92033386230469, 17.0]}, 128)
batch 884: ({'logprob': [51.402034759521484, 13.0]}, 128)
batch 885: ({'logprob': [52.548519134521484, 13.0]}, 128)
batch 886: ({'logprob': [62.518001556396484, 17.0]}, 128)

======================Test output======================
logprob:  0.416858, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958536e-03 [4.216755e-09] 
Layer 'conv1' biases: 4.113907e-07 [1.173870e-10] 
Layer 'conv2' weights[0]: 7.945679e-03 [3.560612e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.527035e-10] 
Layer 'conv3' weights[0]: 7.943831e-03 [3.106478e-09] 
Layer 'conv3' biases: 3.474460e-06 [2.039649e-09] 
Layer 'conv4' weights[0]: 7.976508e-03 [3.312301e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.770810e-08] 
Layer 'conv5' weights[0]: 7.975257e-03 [1.142010e-07] 
Layer 'conv5' biases: 9.999906e-01 [1.225163e-07] 
Layer 'fc6' weights[0]: 7.571819e-03 [9.395921e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.516217e-09] 
Layer 'fc7' weights[0]: 6.846331e-03 [2.589237e-07] 
Layer 'fc7' biases: 9.998546e-01 [2.501813e-07] 
Layer 'fc8' weights[0]: 1.272995e-03 [8.627183e-06] 
Layer 'fc8' biases: 7.869201e-02 [5.639830e-05] 
Train error last 870 batches: 0.435177
-------------------------------------------------------
Not saving because 0.416858 > 0.415650 (27.630: -0.00%)
======================================================= (12.026 sec)
32.81... logprob:  0.416724, 0.109375 (1.429 sec)
32.82... logprob:  0.231086, 0.039062 (1.430 sec)
32.83... logprob:  0.493852, 0.140625 (1.401 sec)
32.84... logprob:  0.468170, 0.125000 (1.466 sec)
32.85... logprob:  0.431898, 0.117188 (1.427 sec)
32.86... logprob:  0.416909, 0.109375 (1.423 sec)
32.87... logprob:  0.633342, 0.187500 (1.420 sec)
32.88... logprob:  0.535003, 0.156250 (1.415 sec)
32.89... logprob:  0.410521, 0.109375 (1.444 sec)
32.90... logprob:  0.577480, 0.171875 (1.396 sec)
32.91... logprob:  0.348387, 0.078125 (1.400 sec)
32.92... logprob:  0.464459, 0.125000 (1.404 sec)
32.93... logprob:  0.492190, 0.140625 (1.407 sec)
32.94... logprob:  0.428787, 0.109375 (1.388 sec)
32.95... logprob:  0.471829, 0.125000 (1.404 sec)
32.96... logprob:  0.576134, 0.171875 (1.412 sec)
32.97... logprob:  0.430798, 0.117188 (1.395 sec)
32.98... logprob:  0.391263, 0.093750 (1.441 sec)
32.99... logprob:  0.474194, 0.132812 (1.413 sec)
32.100... logprob:  0.310701, 0.070312 (1.400 sec)
32.101... logprob:  0.311039, 0.062500 (1.444 sec)
32.102... logprob:  0.545783, 0.156250 (1.390 sec)
32.103... logprob:  0.540788, 0.156250 (1.406 sec)
32.104... logprob:  0.388797, 0.101562 (1.408 sec)
32.105... logprob:  0.619118, 0.179688 (1.398 sec)
32.106... logprob:  0.344478, 0.085938 (1.402 sec)
32.107... logprob:  0.335824, 0.078125 (1.440 sec)
32.108... logprob:  0.586861, 0.171875 (1.398 sec)
32.109... logprob:  0.336107, 0.078125 (1.405 sec)
32.110... logprob:  0.564726, 0.164062 (1.405 sec)
32.111... logprob:  0.404649, 0.101562 (1.400 sec)
32.112... logprob:  0.365933, 0.093750 (1.408 sec)
32.113... logprob:  0.354349, 0.085938 (1.405 sec)
32.114... logprob:  0.440207, 0.117188 (1.438 sec)
32.115... logprob:  0.506809, 0.140625 (1.422 sec)
32.116... logprob:  0.393324, 0.101562 (1.406 sec)
32.117... logprob:  0.440393, 0.117188 (1.448 sec)
32.118... logprob:  0.409067, 0.101562 (1.399 sec)
32.119... logprob:  0.346058, 0.085938 (1.409 sec)
32.120... logprob:  0.547128, 0.156250 (1.410 sec)
32.121... logprob:  0.412577, 0.109375 (1.406 sec)
32.122... logprob:  0.519233, 0.148438 (1.443 sec)
32.123... logprob:  0.463653, 0.125000 (1.392 sec)
32.124... logprob:  0.447685, 0.125000 (1.403 sec)
32.125... logprob:  0.501889, 0.140625 (1.402 sec)
32.126... logprob:  0.475713, 0.125000 (1.395 sec)
32.127... logprob:  0.479466, 0.125000 (1.410 sec)
32.128... logprob:  0.422321, 0.109375 (1.424 sec)
32.129... logprob:  0.574881, 0.164062 (1.417 sec)
32.130... logprob:  0.382689, 0.093750 (1.418 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.007991790771484, 10.0]}, 128)
batch 872: ({'logprob': [65.92227172851562, 19.0]}, 128)
batch 873: ({'logprob': [41.9818000793457, 9.0]}, 128)
batch 874: ({'logprob': [46.240509033203125, 11.0]}, 128)
batch 875: ({'logprob': [51.366233825683594, 13.0]}, 128)
batch 876: ({'logprob': [63.60301208496094, 18.0]}, 128)
batch 877: ({'logprob': [46.68696594238281, 11.0]}, 128)
batch 878: ({'logprob': [61.671905517578125, 17.0]}, 128)
batch 879: ({'logprob': [72.36529541015625, 21.0]}, 128)
batch 880: ({'logprob': [51.3925666809082, 13.0]}, 128)
batch 881: ({'logprob': [31.25163459777832, 5.0]}, 128)
batch 882: ({'logprob': [55.04671096801758, 14.0]}, 128)
batch 883: ({'logprob': [61.643524169921875, 17.0]}, 128)
batch 884: ({'logprob': [51.8089599609375, 13.0]}, 128)
batch 885: ({'logprob': [52.67837905883789, 13.0]}, 128)
batch 886: ({'logprob': [62.1005744934082, 17.0]}, 128)

======================Test output======================
logprob:  0.419320, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958501e-03 [2.092443e-09] 
Layer 'conv1' biases: 4.123184e-07 [7.628776e-11] 
Layer 'conv2' weights[0]: 7.945644e-03 [1.882197e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.551043e-10] 
Layer 'conv3' weights[0]: 7.943788e-03 [1.813245e-09] 
Layer 'conv3' biases: 3.482264e-06 [1.084338e-09] 
Layer 'conv4' weights[0]: 7.976466e-03 [1.811712e-09] 
Layer 'conv4' biases: 9.999991e-01 [9.052233e-09] 
Layer 'conv5' weights[0]: 7.975220e-03 [5.066757e-08] 
Layer 'conv5' biases: 9.999906e-01 [5.438397e-08] 
Layer 'fc6' weights[0]: 7.571779e-03 [4.261345e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.254292e-09] 
Layer 'fc7' weights[0]: 6.844588e-03 [8.420095e-08] 
Layer 'fc7' biases: 9.998536e-01 [7.077387e-08] 
Layer 'fc8' weights[0]: 1.237170e-03 [7.076752e-06] 
Layer 'fc8' biases: 7.854158e-02 [4.910779e-05] 
Train error last 870 batches: 0.435177
-------------------------------------------------------
Not saving because 0.419320 > 0.415650 (27.630: -0.00%)
======================================================= (12.087 sec)
32.131... logprob:  0.495497, 0.132812 (1.416 sec)
32.132... logprob:  0.506356, 0.140625 (1.446 sec)
32.133... logprob:  0.444696, 0.117188 (1.397 sec)
32.134... logprob:  0.401861, 0.101562 (1.393 sec)
32.135... logprob:  0.460174, 0.125000 (1.409 sec)
32.136... logprob:  0.562325, 0.164062 (1.405 sec)
32.137... logprob:  0.462595, 0.125000 (1.392 sec)
32.138... logprob:  0.319424, 0.070312 (1.447 sec)
32.139... logprob:  0.395727, 0.101562 (1.400 sec)
32.140... logprob:  0.559953, 0.164062 (1.410 sec)
32.141... logprob:  0.464593, 0.125000 (1.441 sec)
32.142... logprob:  0.464647, 0.125000 (1.400 sec)
32.143... logprob:  0.294468, 0.062500 (1.432 sec)
32.144... logprob:  0.456979, 0.125000 (1.419 sec)
32.145... logprob:  0.324687, 0.078125 (1.423 sec)
32.146... logprob:  0.483041, 0.132812 (1.416 sec)
32.147... logprob:  0.262492, 0.054688 (1.436 sec)
32.148... logprob:  0.458557, 0.125000 (1.398 sec)
32.149... logprob:  0.442483, 0.117188 (1.402 sec)
32.150... logprob:  0.347563, 0.085938 (1.403 sec)
32.151... logprob:  0.347134, 0.085938 (1.425 sec)
32.152... logprob:  0.785151, 0.234375 (1.392 sec)
32.153... logprob:  0.381635, 0.093750 (1.443 sec)
32.154... logprob:  0.524764, 0.148438 (1.403 sec)
32.155... logprob:  0.426141, 0.117188 (1.412 sec)
32.156... logprob:  0.295066, 0.062500 (1.446 sec)
32.157... logprob:  0.269961, 0.054688 (1.402 sec)
32.158... logprob:  0.455458, 0.125000 (1.412 sec)
32.159... logprob:  0.483131, 0.132812 (1.397 sec)
32.160... logprob:  0.444672, 0.117188 (1.396 sec)
32.161... logprob:  0.349596, 0.078125 (1.405 sec)
32.162... logprob:  0.611793, 0.179688 (1.410 sec)
32.163... logprob:  0.450502, 0.125000 (1.430 sec)
32.164... logprob:  0.468488, 0.125000 (1.425 sec)
32.165... logprob:  0.547725, 0.156250 (1.423 sec)
32.166... logprob:  0.446176, 0.125000 (1.449 sec)
32.167... logprob:  0.350654, 0.085938 (1.436 sec)
32.168... logprob:  0.363765, 0.085938 (1.424 sec)
32.169... logprob:  0.408615, 0.101562 (1.456 sec)
32.170... logprob:  0.459456, 0.125000 (1.409 sec)
32.171... logprob:  0.535177, 0.156250 (1.422 sec)
32.172... logprob:  0.434785, 0.109375 (1.422 sec)
32.173... logprob:  0.440460, 0.117188 (1.426 sec)
32.174... logprob:  0.600585, 0.171875 (1.401 sec)
32.175... logprob:  0.505900, 0.140625 (1.477 sec)
32.176... logprob:  0.478381, 0.132812 (1.417 sec)
32.177... logprob:  0.289722, 0.054688 (1.432 sec)
32.178... logprob:  0.383474, 0.093750 (1.462 sec)
32.179... logprob:  0.394652, 0.101562 (1.417 sec)
32.180... logprob:  0.466393, 0.125000 (1.431 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.99479675292969, 10.0]}, 128)
batch 872: ({'logprob': [66.48786926269531, 19.0]}, 128)
batch 873: ({'logprob': [40.68748092651367, 9.0]}, 128)
batch 874: ({'logprob': [45.355712890625, 11.0]}, 128)
batch 875: ({'logprob': [50.82657241821289, 13.0]}, 128)
batch 876: ({'logprob': [63.98101043701172, 18.0]}, 128)
batch 877: ({'logprob': [45.76959228515625, 11.0]}, 128)
batch 878: ({'logprob': [61.8280029296875, 17.0]}, 128)
batch 879: ({'logprob': [73.1851577758789, 21.0]}, 128)
batch 880: ({'logprob': [50.854270935058594, 13.0]}, 128)
batch 881: ({'logprob': [29.291522979736328, 5.0]}, 128)
batch 882: ({'logprob': [54.605892181396484, 14.0]}, 128)
batch 883: ({'logprob': [61.79865646362305, 17.0]}, 128)
batch 884: ({'logprob': [51.242244720458984, 13.0]}, 128)
batch 885: ({'logprob': [52.049278259277344, 13.0]}, 128)
batch 886: ({'logprob': [62.227352142333984, 17.0]}, 128)

======================Test output======================
logprob:  0.416106, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958460e-03 [2.753444e-09] 
Layer 'conv1' biases: 4.133618e-07 [6.904762e-11] 
Layer 'conv2' weights[0]: 7.945612e-03 [1.965946e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.766923e-10] 
Layer 'conv3' weights[0]: 7.943749e-03 [1.837800e-09] 
Layer 'conv3' biases: 3.490206e-06 [8.535542e-10] 
Layer 'conv4' weights[0]: 7.976419e-03 [1.803330e-09] 
Layer 'conv4' biases: 9.999991e-01 [6.130000e-09] 
Layer 'conv5' weights[0]: 7.975181e-03 [3.491050e-08] 
Layer 'conv5' biases: 9.999902e-01 [3.740156e-08] 
Layer 'fc6' weights[0]: 7.571733e-03 [2.970532e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.922315e-09] 
Layer 'fc7' weights[0]: 6.842811e-03 [1.211769e-07] 
Layer 'fc7' biases: 9.998542e-01 [1.081666e-07] 
Layer 'fc8' weights[0]: 1.274311e-03 [9.872307e-06] 
Layer 'fc8' biases: 7.892833e-02 [6.930246e-05] 
Train error last 870 batches: 0.435177
-------------------------------------------------------
Not saving because 0.416106 > 0.415650 (27.630: -0.00%)
======================================================= (12.086 sec)
32.181... logprob:  0.539249, 0.156250 (1.425 sec)
32.182... logprob:  0.371253, 0.093750 (1.510 sec)
32.183... logprob:  0.419927, 0.109375 (1.426 sec)
32.184... logprob:  0.483429, 0.132812 (1.422 sec)
32.185... logprob:  0.289719, 0.062500 (1.396 sec)
32.186... logprob:  0.370321, 0.093750 (1.398 sec)
32.187... logprob:  0.529615, 0.148438 (1.402 sec)
32.188... logprob:  0.458842, 0.125000 (1.398 sec)
32.189... logprob:  0.440924, 0.117188 (1.392 sec)
32.190... logprob:  0.375797, 0.093750 (1.435 sec)
32.191... logprob:  0.485095, 0.132812 (1.412 sec)
32.192... logprob:  0.520005, 0.148438 (1.415 sec)
32.193... logprob:  0.312461, 0.070312 (1.423 sec)
32.194... logprob:  0.414036, 0.109375 (1.414 sec)
32.195... logprob:  0.286977, 0.062500 (1.406 sec)
32.196... logprob:  0.410439, 0.109375 (1.401 sec)
32.197... logprob:  0.477975, 0.132812 (1.408 sec)
32.198... logprob:  0.355797, 0.085938 (1.411 sec)
32.199... logprob:  0.437194, 0.117188 (1.393 sec)
32.200... logprob:  0.440722, 0.117188 (1.439 sec)
32.201... logprob:  0.437087, 0.117188 (1.408 sec)
32.202... logprob:  0.537811, 0.148438 (1.402 sec)
32.203... logprob:  0.420396, 0.109375 (1.446 sec)
32.204... logprob:  0.504123, 0.140625 (1.390 sec)
32.205... logprob:  0.334259, 0.078125 (1.407 sec)
32.206... logprob:  0.361638, 0.093750 (1.409 sec)
32.207... logprob:  0.381736, 0.093750 (1.393 sec)
32.208... logprob:  0.490600, 0.140625 (1.396 sec)
32.209... logprob:  0.334524, 0.078125 (1.426 sec)
32.210... logprob:  0.586222, 0.171875 (1.416 sec)
32.211... logprob:  0.488108, 0.132812 (1.417 sec)
32.212... logprob:  0.526109, 0.148438 (1.407 sec)
32.213... logprob:  0.514577, 0.140625 (1.462 sec)
32.214... logprob:  0.459383, 0.125000 (1.430 sec)
32.215... logprob:  0.396077, 0.101562 (1.417 sec)
32.216... logprob:  0.516876, 0.140625 (1.470 sec)
32.217... logprob:  0.324803, 0.070312 (1.400 sec)
32.218... logprob:  0.463563, 0.125000 (1.430 sec)
32.219... logprob:  0.500213, 0.140625 (1.424 sec)
32.220... logprob:  0.415034, 0.109375 (1.420 sec)
32.221... logprob:  0.399578, 0.101562 (1.402 sec)
32.222... logprob:  0.554366, 0.164062 (1.456 sec)
32.223... logprob:  0.568870, 0.164062 (1.435 sec)
32.224... logprob:  0.406003, 0.101562 (1.439 sec)
32.225... logprob:  0.392017, 0.101562 (1.449 sec)
32.226... logprob:  0.424771, 0.109375 (1.425 sec)
32.227... logprob:  0.452601, 0.125000 (1.417 sec)
32.228... logprob:  0.417165, 0.109375 (1.422 sec)
32.229... logprob:  0.489371, 0.132812 (1.414 sec)
32.230... logprob:  0.459839, 0.125000 (1.439 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.99331283569336, 10.0]}, 128)
batch 872: ({'logprob': [66.4427261352539, 19.0]}, 128)
batch 873: ({'logprob': [40.740299224853516, 9.0]}, 128)
batch 874: ({'logprob': [45.37165451049805, 11.0]}, 128)
batch 875: ({'logprob': [50.83449172973633, 13.0]}, 128)
batch 876: ({'logprob': [63.94718933105469, 18.0]}, 128)
batch 877: ({'logprob': [45.8000373840332, 11.0]}, 128)
batch 878: ({'logprob': [61.819820404052734, 17.0]}, 128)
batch 879: ({'logprob': [73.17491149902344, 21.0]}, 128)
batch 880: ({'logprob': [50.86231231689453, 13.0]}, 128)
batch 881: ({'logprob': [29.346248626708984, 5.0]}, 128)
batch 882: ({'logprob': [54.64564514160156, 14.0]}, 128)
batch 883: ({'logprob': [61.79030227661133, 17.0]}, 128)
batch 884: ({'logprob': [51.26445007324219, 13.0]}, 128)
batch 885: ({'logprob': [52.10014724731445, 13.0]}, 128)
batch 886: ({'logprob': [62.23347854614258, 17.0]}, 128)

======================Test output======================
logprob:  0.416195, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958419e-03 [2.346495e-09] 
Layer 'conv1' biases: 4.144537e-07 [5.578086e-11] 
Layer 'conv2' weights[0]: 7.945564e-03 [1.867087e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.305185e-10] 
Layer 'conv3' weights[0]: 7.943711e-03 [1.468603e-09] 
Layer 'conv3' biases: 3.500587e-06 [6.594124e-10] 
Layer 'conv4' weights[0]: 7.976381e-03 [1.431114e-09] 
Layer 'conv4' biases: 9.999991e-01 [4.124020e-09] 
Layer 'conv5' weights[0]: 7.975136e-03 [2.632598e-08] 
Layer 'conv5' biases: 9.999903e-01 [2.825842e-08] 
Layer 'fc6' weights[0]: 7.571695e-03 [2.327253e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.195482e-09] 
Layer 'fc7' weights[0]: 6.841080e-03 [4.391369e-08] 
Layer 'fc7' biases: 9.998541e-01 [2.247876e-08] 
Layer 'fc8' weights[0]: 1.276120e-03 [2.062417e-06] 
Layer 'fc8' biases: 7.899710e-02 [1.481181e-05] 
Train error last 870 batches: 0.435176
-------------------------------------------------------
Not saving because 0.416195 > 0.415650 (27.630: -0.00%)
======================================================= (12.091 sec)
32.231... logprob:  0.453472, 0.125000 (1.416 sec)
32.232... logprob:  0.496141, 0.140625 (1.466 sec)
32.233... logprob:  0.466034, 0.132812 (1.426 sec)
32.234... logprob:  0.563881, 0.164062 (1.417 sec)
32.235... logprob:  0.482009, 0.132812 (1.473 sec)
32.236... logprob:  0.425615, 0.109375 (1.410 sec)
32.237... logprob:  0.340837, 0.078125 (1.423 sec)
32.238... logprob:  0.389047, 0.093750 (1.420 sec)
32.239... logprob:  0.478075, 0.132812 (1.427 sec)
32.240... logprob:  0.485794, 0.132812 (1.402 sec)
32.241... logprob:  0.493603, 0.132812 (1.463 sec)
32.242... logprob:  0.341623, 0.078125 (1.435 sec)
32.243... logprob:  0.385989, 0.093750 (1.431 sec)
32.244... logprob:  0.315457, 0.070312 (1.445 sec)
32.245... logprob:  0.494182, 0.132812 (1.430 sec)
32.246... logprob:  0.416833, 0.109375 (1.423 sec)
32.247... logprob:  0.357625, 0.085938 (1.417 sec)
32.248... logprob:  0.308130, 0.070312 (1.414 sec)
32.249... logprob:  0.554363, 0.156250 (1.429 sec)
32.250... logprob:  0.591047, 0.164062 (1.405 sec)
32.251... logprob:  0.353015, 0.085938 (1.460 sec)
32.252... logprob:  0.348422, 0.085938 (1.429 sec)
32.253... logprob:  0.379238, 0.093750 (1.416 sec)
32.254... logprob:  0.444153, 0.117188 (1.475 sec)
32.255... logprob:  0.351291, 0.085938 (1.403 sec)
32.256... logprob:  0.378890, 0.093750 (1.422 sec)
32.257... logprob:  0.331955, 0.078125 (1.419 sec)
32.258... logprob:  0.415465, 0.109375 (1.430 sec)
32.259... logprob:  0.442318, 0.117188 (1.405 sec)
32.260... logprob:  0.308143, 0.070312 (1.490 sec)
32.261... logprob:  0.392504, 0.101562 (1.429 sec)
32.262... logprob:  0.524475, 0.148438 (1.432 sec)
32.263... logprob:  0.425624, 0.109375 (1.446 sec)
32.264... logprob:  0.374994, 0.093750 (1.427 sec)
32.265... logprob:  0.439609, 0.117188 (1.416 sec)
32.266... logprob:  0.439003, 0.117188 (1.420 sec)
32.267... logprob:  0.422045, 0.109375 (1.426 sec)
32.268... logprob:  0.458942, 0.125000 (1.423 sec)
32.269... logprob:  0.567607, 0.164062 (1.412 sec)
32.270... logprob:  0.542368, 0.156250 (1.465 sec)
32.271... logprob:  0.445566, 0.117188 (1.431 sec)
32.272... logprob:  0.384511, 0.093750 (1.420 sec)
32.273... logprob:  0.500238, 0.140625 (1.470 sec)
32.274... logprob:  0.542496, 0.156250 (1.403 sec)
32.275... logprob:  0.487536, 0.132812 (1.426 sec)
32.276... logprob:  0.389967, 0.093750 (1.415 sec)
32.277... logprob:  0.428573, 0.109375 (1.425 sec)
32.278... logprob:  0.323672, 0.070312 (1.429 sec)
32.279... logprob:  0.325360, 0.070312 (1.463 sec)
32.280... logprob:  0.216219, 0.031250 (1.409 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.01341247558594, 10.0]}, 128)
batch 872: ({'logprob': [66.61371612548828, 19.0]}, 128)
batch 873: ({'logprob': [40.553802490234375, 9.0]}, 128)
batch 874: ({'logprob': [45.322879791259766, 11.0]}, 128)
batch 875: ({'logprob': [50.812713623046875, 13.0]}, 128)
batch 876: ({'logprob': [64.07721710205078, 18.0]}, 128)
batch 877: ({'logprob': [45.69593811035156, 11.0]}, 128)
batch 878: ({'logprob': [61.85304641723633, 17.0]}, 128)
batch 879: ({'logprob': [73.20835876464844, 21.0]}, 128)
batch 880: ({'logprob': [50.840694427490234, 13.0]}, 128)
batch 881: ({'logprob': [29.15970230102539, 5.0]}, 128)
batch 882: ({'logprob': [54.500213623046875, 14.0]}, 128)
batch 883: ({'logprob': [61.823509216308594, 17.0]}, 128)
batch 884: ({'logprob': [51.18815231323242, 13.0]}, 128)
batch 885: ({'logprob': [51.913455963134766, 13.0]}, 128)
batch 886: ({'logprob': [62.211856842041016, 17.0]}, 128)

======================Test output======================
logprob:  0.415912, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958385e-03 [1.007113e-08] 
Layer 'conv1' biases: 4.155722e-07 [4.203491e-10] 
Layer 'conv2' weights[0]: 7.945521e-03 [9.756003e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.136229e-09] 
Layer 'conv3' weights[0]: 7.943675e-03 [9.577748e-09] 
Layer 'conv3' biases: 3.504907e-06 [6.363076e-09] 
Layer 'conv4' weights[0]: 7.976346e-03 [9.506800e-09] 
Layer 'conv4' biases: 9.999990e-01 [5.497367e-08] 
Layer 'conv5' weights[0]: 7.975096e-03 [3.482129e-07] 
Layer 'conv5' biases: 9.999893e-01 [3.739593e-07] 
Layer 'fc6' weights[0]: 7.571659e-03 [2.825747e-08] 
Layer 'fc6' biases: 1.000000e+00 [2.889396e-08] 
Layer 'fc7' weights[0]: 6.839345e-03 [6.378703e-07] 
Layer 'fc7' biases: 9.998540e-01 [6.265736e-07] 
Layer 'fc8' weights[0]: 1.282301e-03 [2.248477e-05] 
Layer 'fc8' biases: 7.914453e-02 [1.653114e-04] 
Train error last 870 batches: 0.435176
-------------------------------------------------------
Not saving because 0.415912 > 0.415650 (27.630: -0.00%)
======================================================= (12.069 sec)
32.281... logprob:  0.417266, 0.109375 (1.434 sec)
32.282... logprob:  0.411288, 0.109375 (1.425 sec)
32.283... logprob:  0.393703, 0.101562 (1.414 sec)
32.284... logprob:  0.394305, 0.101562 (1.424 sec)
32.285... logprob:  0.451220, 0.117188 (1.439 sec)
32.286... logprob:  0.535990, 0.140625 (1.439 sec)
32.287... logprob:  0.346496, 0.085938 (1.433 sec)
32.288... logprob:  0.329936, 0.078125 (1.436 sec)
32.289... logprob:  0.445738, 0.117188 (1.452 sec)
32.290... logprob:  0.490639, 0.132812 (1.412 sec)
32.291... logprob:  0.439360, 0.117188 (1.424 sec)
32.292... logprob:  0.567858, 0.156250 (1.422 sec)
32.293... logprob:  0.427827, 0.117188 (1.460 sec)
32.294... logprob:  0.355628, 0.085938 (1.402 sec)
32.295... logprob:  0.334149, 0.078125 (1.469 sec)
32.296... logprob:  0.355295, 0.085938 (1.417 sec)
32.297... logprob:  0.394240, 0.101562 (1.432 sec)
32.298... logprob:  0.448285, 0.125000 (1.467 sec)
32.299... logprob:  0.341768, 0.078125 (1.405 sec)
32.300... logprob:  0.406280, 0.101562 (1.421 sec)
32.301... logprob:  0.397857, 0.101562 (1.424 sec)
32.302... logprob:  0.591622, 0.179688 (1.413 sec)
32.303... logprob:  0.459460, 0.125000 (1.423 sec)
32.304... logprob:  0.459596, 0.125000 (1.440 sec)
32.305... logprob:  0.455188, 0.125000 (1.439 sec)
32.306... logprob:  0.440567, 0.117188 (1.439 sec)
32.307... logprob:  0.421630, 0.109375 (1.443 sec)
32.308... logprob:  0.374902, 0.093750 (1.456 sec)
32.309... logprob:  0.450482, 0.125000 (1.418 sec)
32.310... logprob:  0.473536, 0.125000 (1.432 sec)
32.311... logprob:  0.502410, 0.140625 (1.440 sec)
32.312... logprob:  0.478645, 0.132812 (1.438 sec)
32.313... logprob:  0.454854, 0.125000 (1.424 sec)
32.314... logprob:  0.454312, 0.117188 (1.470 sec)
32.315... logprob:  0.314691, 0.070312 (1.439 sec)
32.316... logprob:  0.468491, 0.125000 (1.431 sec)
32.317... logprob:  0.355414, 0.085938 (1.480 sec)
32.318... logprob:  0.455398, 0.125000 (1.419 sec)
32.319... logprob:  0.423157, 0.117188 (1.429 sec)
32.320... logprob:  0.412228, 0.109375 (1.425 sec)
32.321... logprob:  0.348226, 0.085938 (1.427 sec)
32.322... logprob:  0.387419, 0.101562 (1.410 sec)
32.323... logprob:  0.416498, 0.109375 (1.481 sec)
32.324... logprob:  0.498593, 0.140625 (1.425 sec)
32.325... logprob:  0.350671, 0.085938 (1.439 sec)
32.326... logprob:  0.543184, 0.148438 (1.462 sec)
32.327... logprob:  0.554426, 0.164062 (1.427 sec)
32.328... logprob:  0.565169, 0.156250 (1.423 sec)
32.329... logprob:  0.401893, 0.101562 (1.427 sec)
32.330... logprob:  0.388467, 0.101562 (1.426 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.062095642089844, 10.0]}, 128)
batch 872: ({'logprob': [65.98353576660156, 19.0]}, 128)
batch 873: ({'logprob': [41.493289947509766, 9.0]}, 128)
batch 874: ({'logprob': [45.6636848449707, 11.0]}, 128)
batch 875: ({'logprob': [51.031036376953125, 13.0]}, 128)
batch 876: ({'logprob': [63.62608337402344, 18.0]}, 128)
batch 877: ({'logprob': [46.27438735961914, 11.0]}, 128)
batch 878: ({'logprob': [61.82083511352539, 17.0]}, 128)
batch 879: ({'logprob': [73.16183471679688, 21.0]}, 128)
batch 880: ({'logprob': [51.05756759643555, 13.0]}, 128)
batch 881: ({'logprob': [30.113229751586914, 5.0]}, 128)
batch 882: ({'logprob': [55.2457389831543, 14.0]}, 128)
batch 883: ({'logprob': [61.79229736328125, 17.0]}, 128)
batch 884: ({'logprob': [51.64033889770508, 13.0]}, 128)
batch 885: ({'logprob': [52.83943176269531, 13.0]}, 128)
batch 886: ({'logprob': [62.415409088134766, 17.0]}, 128)

======================Test output======================
logprob:  0.418077, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958343e-03 [2.827241e-09] 
Layer 'conv1' biases: 4.167194e-07 [4.500113e-11] 
Layer 'conv2' weights[0]: 7.945478e-03 [1.945194e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.546231e-10] 
Layer 'conv3' weights[0]: 7.943637e-03 [1.309950e-09] 
Layer 'conv3' biases: 3.518871e-06 [3.806393e-10] 
Layer 'conv4' weights[0]: 7.976318e-03 [1.203580e-09] 
Layer 'conv4' biases: 9.999991e-01 [4.085845e-10] 
Layer 'conv5' weights[0]: 7.975081e-03 [2.971316e-09] 
Layer 'conv5' biases: 9.999906e-01 [3.031659e-09] 
Layer 'fc6' weights[0]: 7.571622e-03 [7.885787e-10] 
Layer 'fc6' biases: 1.000000e+00 [2.156394e-10] 
Layer 'fc7' weights[0]: 6.837597e-03 [2.112501e-07] 
Layer 'fc7' biases: 9.998539e-01 [2.019080e-07] 
Layer 'fc8' weights[0]: 1.262264e-03 [7.767020e-06] 
Layer 'fc8' biases: 7.926462e-02 [4.994973e-05] 
Train error last 870 batches: 0.435176
-------------------------------------------------------
Not saving because 0.418077 > 0.415650 (27.630: -0.00%)
======================================================= (12.202 sec)
32.331... logprob:  0.352191, 0.085938 (1.431 sec)
32.332... logprob:  0.482783, 0.132812 (1.454 sec)
32.333... logprob:  0.339426, 0.085938 (1.446 sec)
32.334... logprob:  0.565337, 0.171875 (1.439 sec)
32.335... logprob:  0.358645, 0.085938 (1.439 sec)
32.336... logprob:  0.444866, 0.125000 (1.462 sec)
32.337... logprob:  0.566389, 0.164062 (1.417 sec)
32.338... logprob:  0.449516, 0.125000 (1.422 sec)
32.339... logprob:  0.488562, 0.132812 (1.430 sec)
32.340... logprob:  0.442062, 0.117188 (1.439 sec)
32.341... logprob:  0.529999, 0.148438 (1.424 sec)
32.342... logprob:  0.429589, 0.109375 (1.463 sec)
32.343... logprob:  0.434763, 0.109375 (1.444 sec)
32.344... logprob:  0.444544, 0.125000 (1.486 sec)
32.345... logprob:  0.488172, 0.132812 (1.446 sec)
32.346... logprob:  0.436203, 0.117188 (1.441 sec)
32.347... logprob:  0.372587, 0.085938 (1.484 sec)
32.348... logprob:  0.398504, 0.101562 (1.435 sec)
32.349... logprob:  0.497537, 0.140625 (1.437 sec)
32.350... logprob:  0.358747, 0.085938 (1.439 sec)
32.351... logprob:  0.508448, 0.140625 (1.435 sec)
32.352... logprob:  0.363603, 0.093750 (1.432 sec)
32.353... logprob:  0.512374, 0.148438 (1.491 sec)
32.354... logprob:  0.674714, 0.203125 (1.439 sec)
32.355... logprob:  0.357507, 0.085938 (1.452 sec)
32.356... logprob:  0.479237, 0.132812 (1.478 sec)
32.357... logprob:  0.346668, 0.085938 (1.434 sec)
32.358... logprob:  0.325695, 0.070312 (1.445 sec)
32.359... logprob:  0.555413, 0.164062 (1.437 sec)
32.360... logprob:  0.444527, 0.117188 (1.429 sec)
32.361... logprob:  0.410725, 0.101562 (1.432 sec)
32.362... logprob:  0.423903, 0.117188 (1.479 sec)
32.363... logprob:  0.486598, 0.132812 (1.446 sec)
32.364... logprob:  0.475632, 0.125000 (1.452 sec)
32.365... logprob:  0.425032, 0.109375 (1.466 sec)
32.366... logprob:  0.409539, 0.109375 (1.451 sec)
32.367... logprob:  0.324875, 0.078125 (1.437 sec)
32.368... logprob:  0.595531, 0.171875 (1.435 sec)
32.369... logprob:  0.381688, 0.093750 (1.425 sec)
32.370... logprob:  0.381324, 0.093750 (1.441 sec)
32.371... logprob:  0.400441, 0.101562 (1.459 sec)
32.372... logprob:  0.537148, 0.156250 (1.459 sec)
32.373... logprob:  0.463779, 0.125000 (1.453 sec)
32.374... logprob:  0.526764, 0.148438 (1.454 sec)
32.375... logprob:  0.393764, 0.101562 (1.463 sec)
32.376... logprob:  0.374285, 0.093750 (1.445 sec)
32.377... logprob:  0.295454, 0.062500 (1.426 sec)
32.378... logprob:  0.453640, 0.125000 (1.428 sec)
32.379... logprob:  0.420246, 0.109375 (1.444 sec)
32.380... logprob:  0.605646, 0.179688 (1.435 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.79514694213867, 10.0]}, 128)
batch 872: ({'logprob': [66.6202621459961, 19.0]}, 128)
batch 873: ({'logprob': [40.5083122253418, 9.0]}, 128)
batch 874: ({'logprob': [45.218971252441406, 11.0]}, 128)
batch 875: ({'logprob': [50.76512908935547, 13.0]}, 128)
batch 876: ({'logprob': [64.08419799804688, 18.0]}, 128)
batch 877: ({'logprob': [45.64921951293945, 11.0]}, 128)
batch 878: ({'logprob': [61.91801834106445, 17.0]}, 128)
batch 879: ({'logprob': [73.4427719116211, 21.0]}, 128)
batch 880: ({'logprob': [50.79313659667969, 13.0]}, 128)
batch 881: ({'logprob': [28.94428253173828, 5.0]}, 128)
batch 882: ({'logprob': [54.62421798706055, 14.0]}, 128)
batch 883: ({'logprob': [61.88836669921875, 17.0]}, 128)
batch 884: ({'logprob': [51.19816589355469, 13.0]}, 128)
batch 885: ({'logprob': [52.038185119628906, 13.0]}, 128)
batch 886: ({'logprob': [62.33428955078125, 17.0]}, 128)

======================Test output======================
logprob:  0.415929, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958297e-03 [4.450267e-09] 
Layer 'conv1' biases: 4.176582e-07 [1.781558e-10] 
Layer 'conv2' weights[0]: 7.945442e-03 [3.700968e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.973732e-10] 
Layer 'conv3' weights[0]: 7.943601e-03 [3.939173e-09] 
Layer 'conv3' biases: 3.525157e-06 [2.681972e-09] 
Layer 'conv4' weights[0]: 7.976278e-03 [3.711004e-09] 
Layer 'conv4' biases: 9.999990e-01 [2.159702e-08] 
Layer 'conv5' weights[0]: 7.975026e-03 [1.333155e-07] 
Layer 'conv5' biases: 9.999901e-01 [1.433530e-07] 
Layer 'fc6' weights[0]: 7.571585e-03 [1.087766e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.114832e-08] 
Layer 'fc7' weights[0]: 6.835779e-03 [1.031756e-07] 
Layer 'fc7' biases: 9.998542e-01 [9.030013e-08] 
Layer 'fc8' weights[0]: 1.283650e-03 [4.247964e-06] 
Layer 'fc8' biases: 7.951139e-02 [2.841164e-05] 
Train error last 870 batches: 0.435175
-------------------------------------------------------
Not saving because 0.415929 > 0.415650 (27.630: -0.00%)
======================================================= (12.049 sec)
32.381... logprob:  0.463400, 0.125000 (1.478 sec)
32.382... logprob:  0.529598, 0.148438 (1.460 sec)
32.383... logprob:  0.358495, 0.085938 (1.435 sec)
32.384... logprob:  0.521252, 0.148438 (1.483 sec)
32.385... logprob:  0.523615, 0.148438 (1.437 sec)
32.386... logprob:  0.582642, 0.171875 (1.429 sec)
32.387... logprob:  0.428466, 0.117188 (1.439 sec)
32.388... logprob:  0.521398, 0.148438 (1.434 sec)
32.389... logprob:  0.425491, 0.109375 (1.436 sec)
32.390... logprob:  0.419605, 0.109375 (1.483 sec)
32.391... logprob:  0.318079, 0.070312 (1.443 sec)
32.392... logprob:  0.439452, 0.117188 (1.436 sec)
32.393... logprob:  0.369068, 0.093750 (1.487 sec)
32.394... logprob:  0.343757, 0.078125 (1.432 sec)
32.395... logprob:  0.331991, 0.078125 (1.432 sec)
32.396... logprob:  0.252776, 0.046875 (1.444 sec)
32.397... logprob:  0.483943, 0.132812 (1.434 sec)
32.398... logprob:  0.470476, 0.125000 (1.440 sec)
32.399... logprob:  0.433016, 0.117188 (1.485 sec)
32.400... logprob:  0.537133, 0.148438 (1.437 sec)
32.401... logprob:  0.465483, 0.125000 (1.442 sec)
32.402... logprob:  0.473697, 0.125000 (1.483 sec)
32.403... logprob:  0.462049, 0.125000 (1.435 sec)
32.404... logprob:  0.474789, 0.125000 (1.436 sec)
32.405... logprob:  0.544371, 0.156250 (1.442 sec)
32.406... logprob:  0.357453, 0.085938 (1.437 sec)
32.407... logprob:  0.493127, 0.140625 (1.432 sec)
32.408... logprob:  0.338626, 0.078125 (1.487 sec)
32.409... logprob:  0.400250, 0.101562 (1.436 sec)
32.410... logprob:  0.582463, 0.171875 (1.455 sec)
32.411... logprob:  0.397579, 0.101562 (1.474 sec)
32.412... logprob:  0.540359, 0.156250 (1.437 sec)
32.413... logprob:  0.544650, 0.156250 (1.437 sec)
32.414... logprob:  0.466304, 0.125000 (1.438 sec)
32.415... logprob:  0.401598, 0.101562 (1.421 sec)
32.416... logprob:  0.427461, 0.109375 (1.444 sec)
32.417... logprob:  0.405462, 0.093750 (1.463 sec)
32.418... logprob:  0.380559, 0.093750 (1.452 sec)
32.419... logprob:  0.417963, 0.101562 (1.458 sec)
32.420... logprob:  0.356651, 0.085938 (1.454 sec)
32.421... logprob:  0.376700, 0.101562 (1.460 sec)
32.422... logprob:  0.521801, 0.148438 (1.439 sec)
32.423... logprob:  0.420742, 0.109375 (1.426 sec)
32.424... logprob:  0.325008, 0.078125 (1.438 sec)
32.425... logprob:  0.306628, 0.070312 (1.434 sec)
32.426... logprob:  0.448902, 0.117188 (1.453 sec)
32.427... logprob:  0.553737, 0.156250 (1.460 sec)
32.428... logprob:  0.601306, 0.171875 (1.456 sec)
32.429... logprob:  0.426367, 0.109375 (1.447 sec)
32.430... logprob:  0.299722, 0.070312 (1.473 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.17089080810547, 10.0]}, 128)
batch 872: ({'logprob': [67.27145385742188, 19.0]}, 128)
batch 873: ({'logprob': [39.99831008911133, 9.0]}, 128)
batch 874: ({'logprob': [44.852394104003906, 11.0]}, 128)
batch 875: ({'logprob': [50.68922805786133, 13.0]}, 128)
batch 876: ({'logprob': [64.6270980834961, 18.0]}, 128)
batch 877: ({'logprob': [45.3556022644043, 11.0]}, 128)
batch 878: ({'logprob': [62.425254821777344, 17.0]}, 128)
batch 879: ({'logprob': [74.60694122314453, 21.0]}, 128)
batch 880: ({'logprob': [50.71733093261719, 13.0]}, 128)
batch 881: ({'logprob': [27.77583122253418, 5.0]}, 128)
batch 882: ({'logprob': [54.88045120239258, 14.0]}, 128)
batch 883: ({'logprob': [62.395843505859375, 17.0]}, 128)
batch 884: ({'logprob': [51.19851303100586, 13.0]}, 128)
batch 885: ({'logprob': [52.18647003173828, 13.0]}, 128)
batch 886: ({'logprob': [62.916744232177734, 17.0]}, 128)

======================Test output======================
logprob:  0.416537, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958260e-03 [2.463544e-09] 
Layer 'conv1' biases: 4.187200e-07 [4.722126e-11] 
Layer 'conv2' weights[0]: 7.945406e-03 [1.926497e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.590658e-10] 
Layer 'conv3' weights[0]: 7.943566e-03 [1.603534e-09] 
Layer 'conv3' biases: 3.532988e-06 [7.580709e-10] 
Layer 'conv4' weights[0]: 7.976242e-03 [1.534185e-09] 
Layer 'conv4' biases: 9.999991e-01 [5.354989e-09] 
Layer 'conv5' weights[0]: 7.974994e-03 [3.146344e-08] 
Layer 'conv5' biases: 9.999901e-01 [3.373641e-08] 
Layer 'fc6' weights[0]: 7.571543e-03 [2.728493e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.664334e-09] 
Layer 'fc7' weights[0]: 6.834025e-03 [1.964735e-07] 
Layer 'fc7' biases: 9.998549e-01 [1.871629e-07] 
Layer 'fc8' weights[0]: 1.302689e-03 [7.413164e-06] 
Layer 'fc8' biases: 7.999260e-02 [4.171131e-05] 
Train error last 870 batches: 0.435175
-------------------------------------------------------
Not saving because 0.416537 > 0.415650 (27.630: -0.00%)
======================================================= (12.068 sec)
32.431... logprob:  0.600247, 0.171875 (1.437 sec)
32.432... logprob:  0.387511, 0.093750 (1.432 sec)
32.433... logprob:  0.329439, 0.078125 (1.453 sec)
32.434... logprob:  0.529808, 0.148438 (1.444 sec)
32.435... logprob:  0.532669, 0.156250 (1.436 sec)
32.436... logprob:  0.380751, 0.093750 (1.473 sec)
32.437... logprob:  0.500371, 0.140625 (1.447 sec)
32.438... logprob:  0.547077, 0.156250 (1.435 sec)
32.439... logprob:  0.378397, 0.093750 (1.486 sec)
32.440... logprob:  0.439582, 0.117188 (1.438 sec)
32.441... logprob:  0.467918, 0.125000 (1.430 sec)
32.442... logprob:  0.378910, 0.093750 (1.440 sec)
32.443... logprob:  0.496552, 0.140625 (1.433 sec)
32.444... logprob:  0.372498, 0.093750 (1.436 sec)
32.445... logprob:  0.362769, 0.085938 (1.484 sec)
32.446... logprob:  0.398481, 0.101562 (1.439 sec)
32.447... logprob:  0.569268, 0.164062 (1.439 sec)
32.448... logprob:  0.333177, 0.078125 (1.487 sec)
32.449... logprob:  0.400060, 0.101562 (1.432 sec)
32.450... logprob:  0.240021, 0.046875 (1.439 sec)
32.451... logprob:  0.452360, 0.125000 (1.441 sec)
32.452... logprob:  0.455880, 0.117188 (1.431 sec)
32.453... logprob:  0.454962, 0.125000 (1.437 sec)
32.454... logprob:  0.488757, 0.132812 (1.487 sec)
32.455... logprob:  0.505960, 0.140625 (1.436 sec)
32.456... logprob:  0.468841, 0.125000 (1.449 sec)
32.457... logprob:  0.375305, 0.093750 (1.475 sec)
32.458... logprob:  0.350907, 0.085938 (1.439 sec)
32.459... logprob:  0.514190, 0.140625 (1.437 sec)
32.460... logprob:  0.273436, 0.054688 (1.439 sec)
32.461... logprob:  0.460180, 0.125000 (1.435 sec)
32.462... logprob:  0.472033, 0.125000 (1.438 sec)
32.463... logprob:  0.420769, 0.109375 (1.469 sec)
32.464... logprob:  0.482836, 0.132812 (1.451 sec)
32.465... logprob:  0.421069, 0.109375 (1.454 sec)
32.466... logprob:  0.318153, 0.070312 (1.460 sec)
32.467... logprob:  0.413809, 0.109375 (1.454 sec)
32.468... logprob:  0.394246, 0.101562 (1.435 sec)
32.469... logprob:  0.334818, 0.078125 (1.435 sec)
32.470... logprob:  0.400115, 0.101562 (1.427 sec)
32.471... logprob:  0.529115, 0.148438 (1.441 sec)
32.472... logprob:  0.409959, 0.109375 (1.453 sec)
32.473... logprob:  0.375513, 0.093750 (1.459 sec)
32.474... logprob:  0.465440, 0.125000 (1.455 sec)
32.475... logprob:  0.503767, 0.140625 (1.451 sec)
32.476... logprob:  0.510060, 0.140625 (1.471 sec)
32.477... logprob:  0.334692, 0.078125 (1.438 sec)
32.478... logprob:  0.464211, 0.125000 (1.424 sec)
32.479... logprob:  0.305779, 0.070312 (1.433 sec)
32.480... logprob:  0.443497, 0.117188 (1.442 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.75325012207031, 10.0]}, 128)
batch 872: ({'logprob': [66.71224212646484, 19.0]}, 128)
batch 873: ({'logprob': [40.4091796875, 9.0]}, 128)
batch 874: ({'logprob': [45.17290496826172, 11.0]}, 128)
batch 875: ({'logprob': [50.7474250793457, 13.0]}, 128)
batch 876: ({'logprob': [64.15560150146484, 18.0]}, 128)
batch 877: ({'logprob': [45.590660095214844, 11.0]}, 128)
batch 878: ({'logprob': [61.956809997558594, 17.0]}, 128)
batch 879: ({'logprob': [73.52642059326172, 21.0]}, 128)
batch 880: ({'logprob': [50.77521514892578, 13.0]}, 128)
batch 881: ({'logprob': [28.800657272338867, 5.0]}, 128)
batch 882: ({'logprob': [54.59006118774414, 14.0]}, 128)
batch 883: ({'logprob': [61.927642822265625, 17.0]}, 128)
batch 884: ({'logprob': [51.16840744018555, 13.0]}, 128)
batch 885: ({'logprob': [51.983943939208984, 13.0]}, 128)
batch 886: ({'logprob': [62.36098098754883, 17.0]}, 128)

======================Test output======================
logprob:  0.415836, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958215e-03 [2.618925e-09] 
Layer 'conv1' biases: 4.196049e-07 [3.882738e-11] 
Layer 'conv2' weights[0]: 7.945371e-03 [1.675329e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.614496e-10] 
Layer 'conv3' weights[0]: 7.943524e-03 [1.239683e-09] 
Layer 'conv3' biases: 3.540452e-06 [4.797014e-10] 
Layer 'conv4' weights[0]: 7.976198e-03 [1.222274e-09] 
Layer 'conv4' biases: 9.999992e-01 [3.130666e-09] 
Layer 'conv5' weights[0]: 7.974951e-03 [1.919625e-08] 
Layer 'conv5' biases: 9.999899e-01 [2.063699e-08] 
Layer 'fc6' weights[0]: 7.571502e-03 [1.766617e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.600593e-09] 
Layer 'fc7' weights[0]: 6.832307e-03 [3.949967e-08] 
Layer 'fc7' biases: 9.998543e-01 [1.706953e-08] 
Layer 'fc8' weights[0]: 1.276565e-03 [1.268519e-06] 
Layer 'fc8' biases: 8.006710e-02 [7.916130e-06] 
Train error last 870 batches: 0.435175
-------------------------------------------------------
Not saving because 0.415836 > 0.415650 (27.630: -0.00%)
======================================================= (12.151 sec)
32.481... logprob:  0.547823, 0.156250 (1.448 sec)
32.482... logprob:  0.443126, 0.117188 (1.481 sec)
32.483... logprob:  0.502730, 0.140625 (1.449 sec)
32.484... logprob:  0.485332, 0.132812 (1.440 sec)
32.485... logprob:  0.408878, 0.109375 (1.484 sec)
32.486... logprob:  0.361182, 0.085938 (1.433 sec)
32.487... logprob:  0.522730, 0.148438 (1.431 sec)
32.488... logprob:  0.424664, 0.109375 (1.442 sec)
32.489... logprob:  0.415781, 0.109375 (1.431 sec)
32.490... logprob:  0.440682, 0.117188 (1.438 sec)
32.491... logprob:  0.313564, 0.070312 (1.483 sec)
32.492... logprob:  0.459505, 0.125000 (1.443 sec)
32.493... logprob:  0.521760, 0.148438 (1.434 sec)
32.494... logprob:  0.450337, 0.125000 (1.489 sec)
32.495... logprob:  0.380718, 0.093750 (1.431 sec)
32.496... logprob:  0.550125, 0.156250 (1.435 sec)
32.497... logprob:  0.466857, 0.125000 (1.440 sec)
32.498... logprob:  0.476180, 0.132812 (1.427 sec)
32.499... logprob:  0.456210, 0.125000 (1.438 sec)
32.500... logprob:  0.355185, 0.085938 (1.489 sec)
32.501... logprob:  0.339137, 0.078125 (1.432 sec)
32.502... logprob:  0.459587, 0.125000 (1.445 sec)
32.503... logprob:  0.400656, 0.101562 (1.491 sec)
32.504... logprob:  0.487260, 0.132812 (1.431 sec)
32.505... logprob:  0.570752, 0.164062 (1.443 sec)
32.506... logprob:  0.479686, 0.132812 (1.434 sec)
32.507... logprob:  0.384999, 0.093750 (1.444 sec)
32.508... logprob:  0.374630, 0.093750 (1.434 sec)
32.509... logprob:  0.322935, 0.070312 (1.478 sec)
32.510... logprob:  0.390447, 0.101562 (1.449 sec)
32.511... logprob:  0.410034, 0.109375 (1.449 sec)
32.512... logprob:  0.470709, 0.125000 (1.472 sec)
32.513... logprob:  0.324957, 0.078125 (1.440 sec)
32.514... logprob:  0.406271, 0.101562 (1.440 sec)
32.515... logprob:  0.455430, 0.125000 (1.434 sec)
32.516... logprob:  0.400219, 0.109375 (1.427 sec)
32.517... logprob:  0.627657, 0.179688 (1.444 sec)
32.518... logprob:  0.437625, 0.117188 (1.457 sec)
32.519... logprob:  0.516125, 0.140625 (1.458 sec)
32.520... logprob:  0.409638, 0.109375 (1.452 sec)
32.521... logprob:  0.427402, 0.109375 (1.453 sec)
32.522... logprob:  0.533199, 0.156250 (1.466 sec)
32.523... logprob:  0.331408, 0.078125 (1.437 sec)
32.524... logprob:  0.437119, 0.117188 (1.432 sec)
32.525... logprob:  0.425845, 0.109375 (1.428 sec)
32.526... logprob:  0.351567, 0.078125 (1.446 sec)
32.527... logprob:  0.504590, 0.140625 (1.450 sec)
32.528... logprob:  0.440440, 0.117188 (1.469 sec)
32.529... logprob:  0.352996, 0.085938 (1.453 sec)
32.530... logprob:  0.440257, 0.117188 (1.442 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.90916061401367, 10.0]}, 128)
batch 872: ({'logprob': [66.36761474609375, 19.0]}, 128)
batch 873: ({'logprob': [40.8220100402832, 9.0]}, 128)
batch 874: ({'logprob': [45.363929748535156, 11.0]}, 128)
batch 875: ({'logprob': [50.83445739746094, 13.0]}, 128)
batch 876: ({'logprob': [63.89226150512695, 18.0]}, 128)
batch 877: ({'logprob': [45.84075164794922, 11.0]}, 128)
batch 878: ({'logprob': [61.83428955078125, 17.0]}, 128)
batch 879: ({'logprob': [73.25239562988281, 21.0]}, 128)
batch 880: ({'logprob': [50.861942291259766, 13.0]}, 128)
batch 881: ({'logprob': [29.365169525146484, 5.0]}, 128)
batch 882: ({'logprob': [54.77019119262695, 14.0]}, 128)
batch 883: ({'logprob': [61.8050651550293, 17.0]}, 128)
batch 884: ({'logprob': [51.31272888183594, 13.0]}, 128)
batch 885: ({'logprob': [52.24553298950195, 13.0]}, 128)
batch 886: ({'logprob': [62.296424865722656, 17.0]}, 128)

======================Test output======================
logprob:  0.416394, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958175e-03 [2.329458e-09] 
Layer 'conv1' biases: 4.206741e-07 [9.314009e-11] 
Layer 'conv2' weights[0]: 7.945325e-03 [2.392103e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.826091e-10] 
Layer 'conv3' weights[0]: 7.943482e-03 [2.175888e-09] 
Layer 'conv3' biases: 3.551592e-06 [1.097522e-09] 
Layer 'conv4' weights[0]: 7.976154e-03 [2.240412e-09] 
Layer 'conv4' biases: 9.999992e-01 [9.203950e-09] 
Layer 'conv5' weights[0]: 7.974908e-03 [5.810748e-08] 
Layer 'conv5' biases: 9.999895e-01 [6.235808e-08] 
Layer 'fc6' weights[0]: 7.571466e-03 [4.855163e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.837743e-09] 
Layer 'fc7' weights[0]: 6.830582e-03 [1.717947e-07] 
Layer 'fc7' biases: 9.998542e-01 [1.613676e-07] 
Layer 'fc8' weights[0]: 1.265399e-03 [6.218496e-06] 
Layer 'fc8' biases: 8.005602e-02 [4.496928e-05] 
Train error last 870 batches: 0.435174
-------------------------------------------------------
Not saving because 0.416394 > 0.415650 (27.630: -0.00%)
======================================================= (12.030 sec)
32.531... logprob:  0.439936, 0.117188 (1.487 sec)
32.532... logprob:  0.467287, 0.125000 (1.439 sec)
32.533... logprob:  0.560209, 0.164062 (1.428 sec)
32.534... logprob:  0.325990, 0.078125 (1.435 sec)
32.535... logprob:  0.551349, 0.156250 (1.441 sec)
32.536... logprob:  0.507221, 0.140625 (1.433 sec)
32.537... logprob:  0.509972, 0.140625 (1.478 sec)
32.538... logprob:  0.486072, 0.132812 (1.450 sec)
32.539... logprob:  0.295997, 0.062500 (1.440 sec)
32.540... logprob:  0.447177, 0.117188 (1.516 sec)
32.541... logprob:  0.388759, 0.101562 (1.443 sec)
32.542... logprob:  0.411211, 0.109375 (1.436 sec)
32.543... logprob:  0.233146, 0.039062 (1.445 sec)
32.544... logprob:  0.317914, 0.070312 (1.437 sec)
32.545... logprob:  0.348794, 0.085938 (1.438 sec)
32.546... logprob:  0.368264, 0.093750 (1.491 sec)
32.547... logprob:  0.439972, 0.117188 (1.448 sec)
32.548... logprob:  0.452780, 0.125000 (1.452 sec)
32.549... logprob:  0.490332, 0.132812 (1.491 sec)
32.550... logprob:  0.367583, 0.093750 (1.442 sec)
32.551... logprob:  0.441578, 0.117188 (1.431 sec)
32.552... logprob:  0.471225, 0.125000 (1.448 sec)
32.553... logprob:  0.349451, 0.085938 (1.436 sec)
32.554... logprob:  0.507026, 0.140625 (1.447 sec)
32.555... logprob:  0.421408, 0.109375 (1.484 sec)
32.556... logprob:  0.355739, 0.085938 (1.444 sec)
32.557... logprob:  0.396325, 0.101562 (1.463 sec)
32.558... logprob:  0.382989, 0.101562 (1.487 sec)
32.559... logprob:  0.441664, 0.125000 (1.443 sec)
32.560... logprob:  0.334947, 0.078125 (1.443 sec)
32.561... logprob:  0.411776, 0.109375 (1.450 sec)
32.562... logprob:  0.503174, 0.140625 (1.440 sec)
32.563... logprob:  0.373728, 0.093750 (1.445 sec)
32.564... logprob:  0.468508, 0.132812 (1.471 sec)
32.565... logprob:  0.611194, 0.187500 (1.462 sec)
32.566... logprob:  0.374853, 0.093750 (1.472 sec)
32.567... logprob:  0.423268, 0.109375 (1.472 sec)
32.568... logprob:  0.496317, 0.140625 (1.473 sec)
32.569... logprob:  0.507645, 0.140625 (1.455 sec)
32.570... logprob:  0.543808, 0.164062 (1.444 sec)
32.571... logprob:  0.454888, 0.125000 (1.448 sec)
32.572... logprob:  0.501337, 0.140625 (1.456 sec)
32.573... logprob:  0.512589, 0.148438 (1.466 sec)
32.574... logprob:  0.427998, 0.109375 (1.479 sec)
32.575... logprob:  0.343321, 0.078125 (1.472 sec)
32.576... logprob:  0.427340, 0.109375 (1.452 sec)
32.577... logprob:  0.460774, 0.125000 (1.493 sec)
32.578... logprob:  0.336828, 0.078125 (1.446 sec)
32.579... logprob:  0.442078, 0.117188 (1.437 sec)
32.580... logprob:  0.546558, 0.156250 (1.447 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.444454193115234, 10.0]}, 128)
batch 872: ({'logprob': [66.22511291503906, 19.0]}, 128)
batch 873: ({'logprob': [41.23379135131836, 9.0]}, 128)
batch 874: ({'logprob': [45.3468132019043, 11.0]}, 128)
batch 875: ({'logprob': [50.91925048828125, 13.0]}, 128)
batch 876: ({'logprob': [63.83121109008789, 18.0]}, 128)
batch 877: ({'logprob': [46.08828353881836, 11.0]}, 128)
batch 878: ({'logprob': [62.120094299316406, 17.0]}, 128)
batch 879: ({'logprob': [74.0029067993164, 21.0]}, 128)
batch 880: ({'logprob': [50.945701599121094, 13.0]}, 128)
batch 881: ({'logprob': [29.31075096130371, 5.0]}, 128)
batch 882: ({'logprob': [55.56621551513672, 14.0]}, 128)
batch 883: ({'logprob': [62.09141540527344, 17.0]}, 128)
batch 884: ({'logprob': [51.66159439086914, 13.0]}, 128)
batch 885: ({'logprob': [53.123817443847656, 13.0]}, 128)
batch 886: ({'logprob': [62.84690475463867, 17.0]}, 128)

======================Test output======================
logprob:  0.418339, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958144e-03 [2.526397e-09] 
Layer 'conv1' biases: 4.218040e-07 [5.284451e-11] 
Layer 'conv2' weights[0]: 7.945293e-03 [1.860305e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.709170e-10] 
Layer 'conv3' weights[0]: 7.943441e-03 [1.590460e-09] 
Layer 'conv3' biases: 3.559531e-06 [8.422919e-10] 
Layer 'conv4' weights[0]: 7.976116e-03 [1.585465e-09] 
Layer 'conv4' biases: 9.999990e-01 [6.203143e-09] 
Layer 'conv5' weights[0]: 7.974861e-03 [4.012217e-08] 
Layer 'conv5' biases: 9.999892e-01 [4.303686e-08] 
Layer 'fc6' weights[0]: 7.571420e-03 [3.362802e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.348130e-09] 
Layer 'fc7' weights[0]: 6.828889e-03 [1.679122e-07] 
Layer 'fc7' biases: 9.998544e-01 [1.575631e-07] 
Layer 'fc8' weights[0]: 1.269063e-03 [8.031386e-06] 
Layer 'fc8' biases: 8.019580e-02 [5.723890e-05] 
Train error last 870 batches: 0.435174
-------------------------------------------------------
Not saving because 0.418339 > 0.415650 (27.630: -0.00%)
======================================================= (12.160 sec)
32.581... logprob:  0.530542, 0.156250 (1.452 sec)
32.582... logprob:  0.437777, 0.125000 (1.436 sec)
32.583... logprob:  0.592318, 0.171875 (1.490 sec)
32.584... logprob:  0.468054, 0.132812 (1.524 sec)
32.585... logprob:  0.349771, 0.085938 (1.432 sec)
32.586... logprob:  0.313046, 0.070312 (1.486 sec)
32.587... logprob:  0.404293, 0.101562 (1.433 sec)
32.588... logprob:  0.418650, 0.117188 (1.431 sec)
32.589... logprob:  0.361125, 0.093750 (1.438 sec)
32.590... logprob:  0.524791, 0.148438 (1.433 sec)
32.591... logprob:  0.397446, 0.101562 (1.434 sec)
32.592... logprob:  0.455686, 0.125000 (1.488 sec)
32.593... logprob:  0.467416, 0.125000 (1.440 sec)
32.594... logprob:  0.352815, 0.085938 (1.437 sec)
32.595... logprob:  0.428660, 0.109375 (1.486 sec)
32.596... logprob:  0.461622, 0.125000 (1.435 sec)
32.597... logprob:  0.397418, 0.101562 (1.437 sec)
32.598... logprob:  0.397215, 0.101562 (1.444 sec)
32.599... logprob:  0.313590, 0.070312 (1.431 sec)
32.600... logprob:  0.340875, 0.085938 (1.442 sec)
32.601... logprob:  0.402162, 0.101562 (1.488 sec)
32.602... logprob:  0.289927, 0.062500 (1.434 sec)
32.603... logprob:  0.267253, 0.054688 (1.452 sec)
32.604... logprob:  0.407529, 0.101562 (1.483 sec)
32.605... logprob:  0.563224, 0.148438 (1.435 sec)
32.606... logprob:  0.295946, 0.070312 (1.442 sec)
32.607... logprob:  0.504642, 0.132812 (1.430 sec)
32.608... logprob:  0.361910, 0.085938 (1.431 sec)
32.609... logprob:  0.357072, 0.085938 (1.434 sec)
32.610... logprob:  0.493258, 0.132812 (1.477 sec)
32.611... logprob:  0.510308, 0.140625 (1.446 sec)
32.612... logprob:  0.448564, 0.117188 (1.452 sec)
32.613... logprob:  0.279263, 0.062500 (1.466 sec)
32.614... logprob:  0.503579, 0.140625 (1.467 sec)
32.615... logprob:  0.350740, 0.085938 (1.437 sec)
32.616... logprob:  0.415005, 0.109375 (1.433 sec)
32.617... logprob:  0.417799, 0.109375 (1.427 sec)
32.618... logprob:  0.547096, 0.156250 (1.431 sec)
32.619... logprob:  0.506153, 0.140625 (1.455 sec)
32.620... logprob:  0.539721, 0.156250 (1.463 sec)
32.621... logprob:  0.363505, 0.085938 (1.452 sec)
32.622... logprob:  0.364615, 0.085938 (1.453 sec)
32.623... logprob:  0.423103, 0.109375 (1.468 sec)
32.624... logprob:  0.382495, 0.093750 (1.441 sec)
32.625... logprob:  0.440975, 0.117188 (1.425 sec)
32.626... logprob:  0.438338, 0.117188 (1.435 sec)
32.627... logprob:  0.435814, 0.117188 (1.435 sec)
32.628... logprob:  0.465007, 0.125000 (1.443 sec)
32.629... logprob:  0.372179, 0.093750 (1.475 sec)
32.630... logprob:  0.422388, 0.109375 (1.448 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.78954315185547, 10.0]}, 128)
batch 872: ({'logprob': [67.07363891601562, 19.0]}, 128)
batch 873: ({'logprob': [40.094242095947266, 9.0]}, 128)
batch 874: ({'logprob': [45.10334396362305, 11.0]}, 128)
batch 875: ({'logprob': [50.738956451416016, 13.0]}, 128)
batch 876: ({'logprob': [64.44114685058594, 18.0]}, 128)
batch 877: ({'logprob': [45.429203033447266, 11.0]}, 128)
batch 878: ({'logprob': [62.07334899902344, 17.0]}, 128)
batch 879: ({'logprob': [73.67609405517578, 21.0]}, 128)
batch 880: ({'logprob': [50.767539978027344, 13.0]}, 128)
batch 881: ({'logprob': [28.452316284179688, 5.0]}, 128)
batch 882: ({'logprob': [54.38493347167969, 14.0]}, 128)
batch 883: ({'logprob': [62.0433349609375, 17.0]}, 128)
batch 884: ({'logprob': [51.06972885131836, 13.0]}, 128)
batch 885: ({'logprob': [51.702022552490234, 13.0]}, 128)
batch 886: ({'logprob': [62.38636779785156, 17.0]}, 128)

======================Test output======================
logprob:  0.415638, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958107e-03 [2.687368e-09] 
Layer 'conv1' biases: 4.228899e-07 [3.753631e-11] 
Layer 'conv2' weights[0]: 7.945259e-03 [1.913154e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.854232e-10] 
Layer 'conv3' weights[0]: 7.943405e-03 [1.407953e-09] 
Layer 'conv3' biases: 3.568495e-06 [5.678152e-10] 
Layer 'conv4' weights[0]: 7.976079e-03 [1.478629e-09] 
Layer 'conv4' biases: 9.999992e-01 [4.201256e-09] 
Layer 'conv5' weights[0]: 7.974835e-03 [2.687976e-08] 
Layer 'conv5' biases: 9.999892e-01 [2.878794e-08] 
Layer 'fc6' weights[0]: 7.571386e-03 [2.369819e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.235365e-09] 
Layer 'fc7' weights[0]: 6.827178e-03 [1.905386e-07] 
Layer 'fc7' biases: 9.998541e-01 [1.801595e-07] 
Layer 'fc8' weights[0]: 1.286891e-03 [6.294789e-06] 
Layer 'fc8' biases: 8.049680e-02 [4.651325e-05] 
Train error last 870 batches: 0.435174
-------------------------------------------------------
Saved checkpoint to /data2/ad6813/my-nets/saves/ConvNet__2014-06-17_23.05.49
======================================================= (12.754 sec)
32.631... logprob:  0.638218, 0.187500 (1.447 sec)
32.632... logprob:  0.399128, 0.101562 (1.495 sec)
32.633... logprob:  0.376136, 0.093750 (1.439 sec)
32.634... logprob:  0.659977, 0.195312 (2.539 sec)
32.635... logprob:  0.374125, 0.093750 (1.442 sec)
32.636... logprob:  0.480266, 0.132812 (1.439 sec)
32.637... logprob:  0.330706, 0.078125 (3.032 sec)
32.638... logprob:  0.515715, 0.140625 (1.481 sec)
32.639... logprob:  0.418007, 0.109375 (1.443 sec)
32.640... logprob:  0.528765, 0.148438 (1.436 sec)
32.641... logprob:  0.410393, 0.109375 (1.488 sec)
32.642... logprob:  0.500925, 0.140625 (1.440 sec)
32.643... logprob:  0.623367, 0.187500 (1.436 sec)
32.644... logprob:  0.320838, 0.070312 (1.437 sec)
32.645... logprob:  0.414437, 0.109375 (1.439 sec)
32.646... logprob:  0.385527, 0.093750 (1.435 sec)
32.647... logprob:  0.456801, 0.125000 (1.493 sec)
32.648... logprob:  0.491284, 0.140625 (1.438 sec)
32.649... logprob:  0.370349, 0.093750 (1.451 sec)
32.650... logprob:  0.414053, 0.109375 (1.485 sec)
32.651... logprob:  0.397431, 0.101562 (1.436 sec)
32.652... logprob:  0.507018, 0.140625 (1.448 sec)
32.653... logprob:  0.547630, 0.156250 (1.443 sec)
32.654... logprob:  0.495975, 0.140625 (1.437 sec)
32.655... logprob:  0.436172, 0.117188 (1.442 sec)
32.656... logprob:  0.416724, 0.109375 (1.485 sec)
32.657... logprob:  0.449000, 0.117188 (1.444 sec)
32.658... logprob:  0.345916, 0.085938 (1.454 sec)
32.659... logprob:  0.464264, 0.125000 (1.469 sec)
32.660... logprob:  0.446072, 0.125000 (1.444 sec)
32.661... logprob:  0.378385, 0.093750 (1.438 sec)
32.662... logprob:  0.469490, 0.132812 (1.435 sec)
32.663... logprob:  0.310826, 0.070312 (1.427 sec)
32.664... logprob:  0.285326, 0.062500 (1.440 sec)
32.665... logprob:  0.401648, 0.101562 (1.464 sec)
32.666... logprob:  0.442015, 0.117188 (1.460 sec)
32.667... logprob:  0.564190, 0.164062 (1.452 sec)
32.668... logprob:  0.497834, 0.140625 (1.454 sec)
32.669... logprob:  0.432879, 0.109375 (1.464 sec)
32.670... logprob:  0.362326, 0.085938 (1.441 sec)
32.671... logprob:  0.360878, 0.093750 (1.425 sec)
32.672... logprob:  0.441829, 0.117188 (1.438 sec)
32.673... logprob:  0.436222, 0.117188 (1.438 sec)
32.674... logprob:  0.446622, 0.117188 (1.443 sec)
32.675... logprob:  0.356688, 0.093750 (1.468 sec)
32.676... logprob:  0.450196, 0.125000 (1.456 sec)
32.677... logprob:  0.471009, 0.125000 (1.438 sec)
32.678... logprob:  0.465664, 0.125000 (1.486 sec)
32.679... logprob:  0.454862, 0.125000 (1.432 sec)
32.680... logprob:  0.351634, 0.078125 (1.429 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.73017501831055, 10.0]}, 128)
batch 872: ({'logprob': [66.12492370605469, 19.0]}, 128)
batch 873: ({'logprob': [41.25104522705078, 9.0]}, 128)
batch 874: ({'logprob': [45.44892501831055, 11.0]}, 128)
batch 875: ({'logprob': [50.925479888916016, 13.0]}, 128)
batch 876: ({'logprob': [63.73388671875, 18.0]}, 128)
batch 877: ({'logprob': [46.10049819946289, 11.0]}, 128)
batch 878: ({'logprob': [61.9351692199707, 17.0]}, 128)
batch 879: ({'logprob': [73.53653717041016, 21.0]}, 128)
batch 880: ({'logprob': [50.95235061645508, 13.0]}, 128)
batch 881: ({'logprob': [29.60987663269043, 5.0]}, 128)
batch 882: ({'logprob': [55.29890060424805, 14.0]}, 128)
batch 883: ({'logprob': [61.90623092651367, 17.0]}, 128)
batch 884: ({'logprob': [51.57719039916992, 13.0]}, 128)
batch 885: ({'logprob': [52.85858154296875, 13.0]}, 128)
batch 886: ({'logprob': [62.571372985839844, 17.0]}, 128)

======================Test output======================
logprob:  0.417754, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958075e-03 [4.547959e-09] 
Layer 'conv1' biases: 4.237697e-07 [1.299880e-10] 
Layer 'conv2' weights[0]: 7.945219e-03 [2.726230e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.954840e-10] 
Layer 'conv3' weights[0]: 7.943369e-03 [2.364348e-09] 
Layer 'conv3' biases: 3.578542e-06 [1.331225e-09] 
Layer 'conv4' weights[0]: 7.976038e-03 [2.325970e-09] 
Layer 'conv4' biases: 9.999991e-01 [9.519860e-09] 
Layer 'conv5' weights[0]: 7.974803e-03 [5.132093e-08] 
Layer 'conv5' biases: 9.999898e-01 [5.481379e-08] 
Layer 'fc6' weights[0]: 7.571346e-03 [4.342792e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.327631e-09] 
Layer 'fc7' weights[0]: 6.825465e-03 [5.210599e-08] 
Layer 'fc7' biases: 9.998541e-01 [3.390412e-08] 
Layer 'fc8' weights[0]: 1.267314e-03 [3.886211e-06] 
Layer 'fc8' biases: 8.040609e-02 [2.644255e-05] 
Train error last 870 batches: 0.435173
-------------------------------------------------------
Not saving because 0.417754 > 0.415638 (32.630: -0.00%)
======================================================= (12.120 sec)
32.681... logprob:  0.373844, 0.093750 (1.444 sec)
32.682... logprob:  0.340453, 0.078125 (1.446 sec)
32.683... logprob:  0.411628, 0.109375 (1.434 sec)
32.684... logprob:  0.357722, 0.085938 (1.479 sec)
32.685... logprob:  0.286279, 0.054688 (1.446 sec)
32.686... logprob:  0.318874, 0.070312 (1.433 sec)
32.687... logprob:  0.281861, 0.062500 (1.488 sec)
32.688... logprob:  0.323164, 0.078125 (1.433 sec)
32.689... logprob:  0.470814, 0.125000 (1.437 sec)
32.690... logprob:  0.527213, 0.140625 (1.443 sec)
32.691... logprob:  0.515992, 0.140625 (1.432 sec)
32.692... logprob:  0.384660, 0.101562 (1.439 sec)
32.693... logprob:  0.455380, 0.125000 (1.490 sec)
32.694... logprob:  0.330971, 0.078125 (1.438 sec)
32.695... logprob:  0.356966, 0.085938 (1.443 sec)
32.696... logprob:  0.539376, 0.148438 (1.482 sec)
32.697... logprob:  0.465832, 0.125000 (1.454 sec)
32.698... logprob:  0.549185, 0.156250 (1.439 sec)
32.699... logprob:  0.459648, 0.125000 (1.437 sec)
32.700... logprob:  0.433760, 0.117188 (1.559 sec)
32.701... logprob:  0.422831, 0.109375 (1.433 sec)
32.702... logprob:  0.521609, 0.148438 (1.486 sec)
32.703... logprob:  0.404810, 0.101562 (1.438 sec)
32.704... logprob:  0.405809, 0.101562 (1.451 sec)
32.705... logprob:  0.420027, 0.109375 (1.475 sec)
32.706... logprob:  0.468041, 0.125000 (1.435 sec)
32.707... logprob:  0.485296, 0.132812 (1.443 sec)
32.708... logprob:  0.417272, 0.109375 (1.436 sec)
32.709... logprob:  0.422728, 0.109375 (1.423 sec)
32.710... logprob:  0.601881, 0.179688 (1.440 sec)
32.711... logprob:  0.469456, 0.125000 (1.466 sec)
32.712... logprob:  0.341136, 0.078125 (1.454 sec)
32.713... logprob:  0.586163, 0.179688 (1.456 sec)
32.714... logprob:  0.466215, 0.125000 (1.458 sec)
32.715... logprob:  0.417222, 0.109375 (1.456 sec)
32.716... logprob:  0.335586, 0.078125 (1.441 sec)
32.717... logprob:  0.429760, 0.117188 (1.427 sec)
32.718... logprob:  0.490274, 0.132812 (1.449 sec)
32.719... logprob:  0.406174, 0.109375 (1.446 sec)
32.720... logprob:  0.433220, 0.117188 (1.452 sec)
32.721... logprob:  0.451602, 0.117188 (1.460 sec)
32.722... logprob:  0.537071, 0.156250 (1.456 sec)
32.723... logprob:  0.416533, 0.109375 (1.446 sec)
32.724... logprob:  0.412754, 0.109375 (1.475 sec)
32.725... logprob:  0.494929, 0.140625 (1.440 sec)
32.726... logprob:  0.338331, 0.085938 (1.426 sec)
32.727... logprob:  0.393144, 0.101562 (1.434 sec)
32.728... logprob:  0.421164, 0.109375 (1.440 sec)
32.729... logprob:  0.387494, 0.093750 (1.433 sec)
32.730... logprob:  0.565986, 0.164062 (1.481 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.638675689697266, 10.0]}, 128)
batch 872: ({'logprob': [66.2629623413086, 19.0]}, 128)
batch 873: ({'logprob': [41.007266998291016, 9.0]}, 128)
batch 874: ({'logprob': [45.32579803466797, 11.0]}, 128)
batch 875: ({'logprob': [50.848907470703125, 13.0]}, 128)
batch 876: ({'logprob': [63.8302001953125, 18.0]}, 128)
batch 877: ({'logprob': [45.9401741027832, 11.0]}, 128)
batch 878: ({'logprob': [61.95246887207031, 17.0]}, 128)
batch 879: ({'logprob': [73.61109924316406, 21.0]}, 128)
batch 880: ({'logprob': [50.875823974609375, 13.0]}, 128)
batch 881: ({'logprob': [29.308712005615234, 5.0]}, 128)
batch 882: ({'logprob': [55.15402603149414, 14.0]}, 128)
batch 883: ({'logprob': [61.923519134521484, 17.0]}, 128)
batch 884: ({'logprob': [51.46437072753906, 13.0]}, 128)
batch 885: ({'logprob': [52.67203903198242, 13.0]}, 128)
batch 886: ({'logprob': [62.55201721191406, 17.0]}, 128)

======================Test output======================
logprob:  0.417172, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.958029e-03 [3.681492e-09] 
Layer 'conv1' biases: 4.247369e-07 [1.057088e-10] 
Layer 'conv2' weights[0]: 7.945179e-03 [2.907497e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.130832e-10] 
Layer 'conv3' weights[0]: 7.943333e-03 [2.568500e-09] 
Layer 'conv3' biases: 3.586392e-06 [1.564452e-09] 
Layer 'conv4' weights[0]: 7.975995e-03 [2.513691e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.210822e-08] 
Layer 'conv5' weights[0]: 7.974766e-03 [7.751464e-08] 
Layer 'conv5' biases: 9.999896e-01 [8.317721e-08] 
Layer 'fc6' weights[0]: 7.571308e-03 [6.331439e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.458940e-09] 
Layer 'fc7' weights[0]: 6.823731e-03 [5.418752e-08] 
Layer 'fc7' biases: 9.998538e-01 [3.608287e-08] 
Layer 'fc8' weights[0]: 1.271988e-03 [3.596515e-06] 
Layer 'fc8' biases: 8.066185e-02 [2.387995e-05] 
Train error last 870 batches: 0.435173
-------------------------------------------------------
Not saving because 0.417172 > 0.415638 (32.630: -0.00%)
======================================================= (12.120 sec)
32.731... logprob:  0.450443, 0.125000 (1.461 sec)
32.732... logprob:  0.311345, 0.070312 (1.446 sec)
32.733... logprob:  0.556445, 0.156250 (1.490 sec)
32.734... logprob:  0.340251, 0.078125 (1.434 sec)
32.735... logprob:  0.527370, 0.148438 (1.432 sec)
32.736... logprob:  0.642438, 0.187500 (1.434 sec)
32.737... logprob:  0.516066, 0.148438 (1.439 sec)
32.738... logprob:  0.459373, 0.125000 (1.431 sec)
32.739... logprob:  0.477782, 0.132812 (1.487 sec)
32.740... logprob:  0.339644, 0.078125 (1.437 sec)
32.741... logprob:  0.393486, 0.101562 (1.441 sec)
32.742... logprob:  0.419677, 0.109375 (1.495 sec)
32.743... logprob:  0.364905, 0.085938 (1.433 sec)
32.744... logprob:  0.519109, 0.148438 (1.432 sec)
32.745... logprob:  0.478118, 0.132812 (1.436 sec)
32.746... logprob:  0.440542, 0.117188 (1.429 sec)
32.747... logprob:  0.425598, 0.109375 (1.437 sec)
32.748... logprob:  0.378174, 0.093750 (1.484 sec)
32.749... logprob:  0.420796, 0.109375 (1.432 sec)
32.750... logprob:  0.512725, 0.140625 (1.451 sec)
32.751... logprob:  0.263767, 0.054688 (1.499 sec)
32.752... logprob:  0.522497, 0.140625 (1.436 sec)
32.753... logprob:  0.441127, 0.117188 (1.440 sec)
32.754... logprob:  0.468212, 0.132812 (1.431 sec)
32.755... logprob:  0.507026, 0.140625 (1.419 sec)
32.756... logprob:  0.440840, 0.117188 (1.441 sec)
32.757... logprob:  0.552521, 0.156250 (1.470 sec)
32.758... logprob:  0.393519, 0.101562 (1.449 sec)
32.759... logprob:  0.459704, 0.125000 (1.458 sec)
32.760... logprob:  0.485600, 0.132812 (1.459 sec)
32.761... logprob:  0.418092, 0.109375 (1.454 sec)
32.762... logprob:  0.516094, 0.148438 (1.439 sec)
32.763... logprob:  0.559062, 0.164062 (1.430 sec)
32.764... logprob:  0.503262, 0.140625 (1.427 sec)
32.765... logprob:  0.311537, 0.062500 (1.442 sec)
32.766... logprob:  0.482181, 0.132812 (1.456 sec)
32.767... logprob:  0.371041, 0.085938 (1.461 sec)
32.768... logprob:  0.432630, 0.117188 (1.470 sec)
32.769... logprob:  0.490767, 0.140625 (1.472 sec)
32.770... logprob:  0.403037, 0.101562 (1.479 sec)
32.771... logprob:  0.549298, 0.156250 (1.463 sec)
32.772... logprob:  0.414130, 0.109375 (1.441 sec)
32.773... logprob:  0.557504, 0.164062 (1.451 sec)
32.774... logprob:  0.361885, 0.085938 (1.460 sec)
32.775... logprob:  0.407428, 0.101562 (1.466 sec)
32.776... logprob:  0.433125, 0.117188 (1.480 sec)
32.777... logprob:  0.380008, 0.093750 (1.475 sec)
32.778... logprob:  0.433515, 0.117188 (1.476 sec)
32.779... logprob:  0.505270, 0.140625 (1.487 sec)
32.780... logprob:  0.385764, 0.101562 (1.455 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.4858283996582, 10.0]}, 128)
batch 872: ({'logprob': [66.87610626220703, 19.0]}, 128)
batch 873: ({'logprob': [40.25386047363281, 9.0]}, 128)
batch 874: ({'logprob': [45.02592468261719, 11.0]}, 128)
batch 875: ({'logprob': [50.70086669921875, 13.0]}, 128)
batch 876: ({'logprob': [64.29291534423828, 18.0]}, 128)
batch 877: ({'logprob': [45.48967361450195, 11.0]}, 128)
batch 878: ({'logprob': [62.112709045410156, 17.0]}, 128)
batch 879: ({'logprob': [73.93000030517578, 21.0]}, 128)
batch 880: ({'logprob': [50.72902297973633, 13.0]}, 128)
batch 881: ({'logprob': [28.39646339416504, 5.0]}, 128)
batch 882: ({'logprob': [54.710533142089844, 14.0]}, 128)
batch 883: ({'logprob': [62.08293914794922, 17.0]}, 128)
batch 884: ({'logprob': [51.16920852661133, 13.0]}, 128)
batch 885: ({'logprob': [52.07724380493164, 13.0]}, 128)
batch 886: ({'logprob': [62.56351852416992, 17.0]}, 128)

======================Test output======================
logprob:  0.415965, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957981e-03 [3.121970e-09] 
Layer 'conv1' biases: 4.257429e-07 [6.239717e-11] 
Layer 'conv2' weights[0]: 7.945144e-03 [2.354932e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.951239e-10] 
Layer 'conv3' weights[0]: 7.943295e-03 [1.752554e-09] 
Layer 'conv3' biases: 3.594744e-06 [7.920928e-10] 
Layer 'conv4' weights[0]: 7.975962e-03 [1.648791e-09] 
Layer 'conv4' biases: 9.999991e-01 [4.192979e-09] 
Layer 'conv5' weights[0]: 7.974719e-03 [1.870220e-08] 
Layer 'conv5' biases: 9.999894e-01 [1.910746e-08] 
Layer 'fc6' weights[0]: 7.571268e-03 [1.673215e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.493727e-09] 
Layer 'fc7' weights[0]: 6.821990e-03 [5.778786e-08] 
Layer 'fc7' biases: 9.998540e-01 [4.006719e-08] 
Layer 'fc8' weights[0]: 1.287832e-03 [3.463995e-06] 
Layer 'fc8' biases: 8.091529e-02 [2.434375e-05] 
Train error last 870 batches: 0.435173
-------------------------------------------------------
Not saving because 0.415965 > 0.415638 (32.630: -0.00%)
======================================================= (12.120 sec)
32.781... logprob:  0.369610, 0.085938 (1.449 sec)
32.782... logprob:  0.351382, 0.085938 (1.458 sec)
32.783... logprob:  0.555548, 0.156250 (1.458 sec)
32.784... logprob:  0.440962, 0.117188 (1.494 sec)
32.785... logprob:  0.543790, 0.156250 (1.494 sec)
32.786... logprob:  0.477611, 0.132812 (1.474 sec)
32.787... logprob:  0.546621, 0.156250 (1.459 sec)
32.788... logprob:  0.563416, 0.164062 (1.497 sec)
32.789... logprob:  0.280385, 0.054688 (1.456 sec)
32.790... logprob:  0.407783, 0.101562 (1.448 sec)
32.791... logprob:  0.397749, 0.101562 (1.451 sec)
32.792... logprob:  0.360791, 0.085938 (1.460 sec)
32.793... logprob:  0.369984, 0.085938 (1.455 sec)
32.794... logprob:  0.387115, 0.093750 (1.489 sec)
32.795... logprob:  0.469689, 0.125000 (1.471 sec)
32.796... logprob:  0.423517, 0.109375 (1.458 sec)
32.797... logprob:  0.358954, 0.085938 (1.500 sec)
32.798... logprob:  0.393311, 0.101562 (1.457 sec)
32.799... logprob:  0.332577, 0.078125 (1.447 sec)
32.800... logprob:  0.371672, 0.093750 (1.451 sec)
32.801... logprob:  0.449824, 0.117188 (1.454 sec)
32.802... logprob:  0.422784, 0.109375 (1.453 sec)
32.803... logprob:  0.491254, 0.132812 (1.494 sec)
32.804... logprob:  0.349938, 0.085938 (1.462 sec)
32.805... logprob:  0.452256, 0.117188 (1.467 sec)
32.806... logprob:  0.424168, 0.109375 (1.502 sec)
32.807... logprob:  0.443480, 0.117188 (1.456 sec)
32.808... logprob:  0.462369, 0.125000 (1.448 sec)
32.809... logprob:  0.589894, 0.171875 (1.456 sec)
32.810... logprob:  0.442511, 0.117188 (1.456 sec)
32.811... logprob:  0.460426, 0.125000 (1.453 sec)
32.812... logprob:  0.462313, 0.125000 (1.499 sec)
32.813... logprob:  0.485948, 0.132812 (1.459 sec)
32.814... logprob:  0.477857, 0.132812 (1.460 sec)
32.815... logprob:  0.371218, 0.085938 (1.500 sec)
32.816... logprob:  0.408335, 0.101562 (1.452 sec)
32.817... logprob:  0.425726, 0.109375 (1.457 sec)
32.818... logprob:  0.560031, 0.164062 (1.447 sec)
32.819... logprob:  0.498173, 0.140625 (1.460 sec)
32.820... logprob:  0.421706, 0.109375 (1.457 sec)
32.821... logprob:  0.406758, 0.101562 (1.502 sec)
32.822... logprob:  0.441319, 0.117188 (1.460 sec)
32.823... logprob:  0.341289, 0.078125 (1.463 sec)
32.824... logprob:  0.489571, 0.132812 (1.505 sec)
32.825... logprob:  0.288623, 0.062500 (1.465 sec)
32.826... logprob:  0.375653, 0.093750 (1.457 sec)
32.827... logprob:  0.420403, 0.109375 (1.447 sec)
32.828... logprob:  0.443041, 0.117188 (1.457 sec)
32.829... logprob:  0.503572, 0.140625 (1.452 sec)
32.830... logprob:  0.441960, 0.117188 (1.505 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.26042556762695, 10.0]}, 128)
batch 872: ({'logprob': [68.26539611816406, 19.0]}, 128)
batch 873: ({'logprob': [39.430355072021484, 9.0]}, 128)
batch 874: ({'logprob': [44.79160690307617, 11.0]}, 128)
batch 875: ({'logprob': [50.80958938598633, 13.0]}, 128)
batch 876: ({'logprob': [65.45011138916016, 18.0]}, 128)
batch 877: ({'logprob': [45.13193893432617, 11.0]}, 128)
batch 878: ({'logprob': [62.91267395019531, 17.0]}, 128)
batch 879: ({'logprob': [75.29987335205078, 21.0]}, 128)
batch 880: ({'logprob': [50.83884048461914, 13.0]}, 128)
batch 881: ({'logprob': [27.002220153808594, 5.0]}, 128)
batch 882: ({'logprob': [54.689849853515625, 14.0]}, 128)
batch 883: ({'logprob': [62.882484436035156, 17.0]}, 128)
batch 884: ({'logprob': [51.159732818603516, 13.0]}, 128)
batch 885: ({'logprob': [51.82389831542969, 13.0]}, 128)
batch 886: ({'logprob': [63.24342346191406, 17.0]}, 128)

======================Test output======================
logprob:  0.417477, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957939e-03 [4.913575e-09] 
Layer 'conv1' biases: 4.269691e-07 [1.597836e-10] 
Layer 'conv2' weights[0]: 7.945108e-03 [4.294147e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.610577e-10] 
Layer 'conv3' weights[0]: 7.943255e-03 [3.995061e-09] 
Layer 'conv3' biases: 3.603029e-06 [2.560572e-09] 
Layer 'conv4' weights[0]: 7.975923e-03 [3.849604e-09] 
Layer 'conv4' biases: 9.999991e-01 [2.024033e-08] 
Layer 'conv5' weights[0]: 7.974677e-03 [1.232829e-07] 
Layer 'conv5' biases: 9.999892e-01 [1.324965e-07] 
Layer 'fc6' weights[0]: 7.571223e-03 [1.016123e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.035939e-08] 
Layer 'fc7' weights[0]: 6.820271e-03 [4.403812e-08] 
Layer 'fc7' biases: 9.998549e-01 [2.280554e-08] 
Layer 'fc8' weights[0]: 1.316204e-03 [5.091604e-06] 
Layer 'fc8' biases: 8.137145e-02 [2.939713e-05] 
Train error last 870 batches: 0.435172
-------------------------------------------------------
Not saving because 0.417477 > 0.415638 (32.630: -0.00%)
======================================================= (12.137 sec)
32.831... logprob:  0.513735, 0.140625 (1.462 sec)
32.832... logprob:  0.330844, 0.078125 (1.471 sec)
32.833... logprob:  0.489071, 0.132812 (1.500 sec)
32.834... logprob:  0.433427, 0.117188 (1.456 sec)
32.835... logprob:  0.543020, 0.148438 (1.455 sec)
32.836... logprob:  0.376020, 0.093750 (1.455 sec)
32.837... logprob:  0.313806, 0.070312 (1.450 sec)
32.838... logprob:  0.437067, 0.117188 (1.456 sec)
32.839... logprob:  0.471629, 0.125000 (1.499 sec)
32.840... logprob:  0.555662, 0.156250 (1.459 sec)
32.841... logprob:  0.395911, 0.101562 (1.462 sec)
32.842... logprob:  0.497926, 0.140625 (1.497 sec)
32.843... logprob:  0.465476, 0.125000 (1.452 sec)
32.844... logprob:  0.497692, 0.140625 (1.461 sec)
32.845... logprob:  0.486707, 0.132812 (1.453 sec)
32.846... logprob:  0.468361, 0.125000 (1.453 sec)
32.847... logprob:  0.363474, 0.085938 (1.460 sec)
32.848... logprob:  0.397301, 0.101562 (1.496 sec)
32.849... logprob:  0.360713, 0.085938 (1.461 sec)
32.850... logprob:  0.479353, 0.132812 (1.466 sec)
32.851... logprob:  0.440140, 0.117188 (1.493 sec)
32.852... logprob:  0.545169, 0.156250 (1.452 sec)
32.853... logprob:  0.372095, 0.093750 (1.466 sec)
32.854... logprob:  0.307555, 0.070312 (1.449 sec)
32.855... logprob:  0.484598, 0.132812 (1.445 sec)
32.856... logprob:  0.443646, 0.117188 (1.456 sec)
32.857... logprob:  0.372235, 0.093750 (1.532 sec)
32.858... logprob:  0.396245, 0.101562 (1.462 sec)
32.859... logprob:  0.308021, 0.070312 (1.473 sec)
32.860... logprob:  0.565958, 0.156250 (1.487 sec)
32.861... logprob:  0.417791, 0.109375 (1.458 sec)
32.862... logprob:  0.328803, 0.078125 (1.461 sec)
32.863... logprob:  0.399598, 0.101562 (1.445 sec)
32.864... logprob:  0.451533, 0.117188 (1.452 sec)
32.865... logprob:  0.484701, 0.132812 (1.453 sec)
32.866... logprob:  0.507912, 0.140625 (1.488 sec)
32.867... logprob:  0.503291, 0.140625 (1.469 sec)
32.868... logprob:  0.405150, 0.101562 (1.473 sec)
32.869... logprob:  0.382969, 0.093750 (1.485 sec)
32.870... logprob:  0.552362, 0.156250 (1.403 sec)
33.1... logprob:  0.379799, 0.093750 (1.411 sec)
33.2... logprob:  0.448228, 0.117188 (1.449 sec)
33.3... logprob:  0.398187, 0.101562 (1.420 sec)
33.4... logprob:  0.443269, 0.117188 (1.412 sec)
33.5... logprob:  0.443498, 0.117188 (1.434 sec)
33.6... logprob:  0.499010, 0.140625 (1.400 sec)
33.7... logprob:  0.363387, 0.085938 (1.421 sec)
33.8... logprob:  0.419192, 0.109375 (1.404 sec)
33.9... logprob:  0.359032, 0.085938 (1.400 sec)
33.10... logprob:  0.377696, 0.093750 (1.406 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.195499420166016, 10.0]}, 128)
batch 872: ({'logprob': [67.02108764648438, 19.0]}, 128)
batch 873: ({'logprob': [40.24342346191406, 9.0]}, 128)
batch 874: ({'logprob': [45.3193473815918, 11.0]}, 128)
batch 875: ({'logprob': [50.843299865722656, 13.0]}, 128)
batch 876: ({'logprob': [64.39977264404297, 18.0]}, 128)
batch 877: ({'logprob': [45.556278228759766, 11.0]}, 128)
batch 878: ({'logprob': [61.954288482666016, 17.0]}, 128)
batch 879: ({'logprob': [73.2450180053711, 21.0]}, 128)
batch 880: ({'logprob': [50.87196731567383, 13.0]}, 128)
batch 881: ({'logprob': [28.914371490478516, 5.0]}, 128)
batch 882: ({'logprob': [54.210235595703125, 14.0]}, 128)
batch 883: ({'logprob': [61.92435836791992, 17.0]}, 128)
batch 884: ({'logprob': [51.08420181274414, 13.0]}, 128)
batch 885: ({'logprob': [51.538333892822266, 13.0]}, 128)
batch 886: ({'logprob': [62.1778564453125, 17.0]}, 128)

======================Test output======================
logprob:  0.415771, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957897e-03 [3.560699e-09] 
Layer 'conv1' biases: 4.281818e-07 [1.386773e-10] 
Layer 'conv2' weights[0]: 7.945065e-03 [3.254081e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.854065e-10] 
Layer 'conv3' weights[0]: 7.943221e-03 [3.256212e-09] 
Layer 'conv3' biases: 3.612042e-06 [2.069612e-09] 
Layer 'conv4' weights[0]: 7.975887e-03 [3.326081e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.832296e-08] 
Layer 'conv5' weights[0]: 7.974643e-03 [1.165039e-07] 
Layer 'conv5' biases: 9.999893e-01 [1.251372e-07] 
Layer 'fc6' weights[0]: 7.571182e-03 [9.555318e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.675040e-09] 
Layer 'fc7' weights[0]: 6.818575e-03 [2.805778e-07] 
Layer 'fc7' biases: 9.998536e-01 [2.713874e-07] 
Layer 'fc8' weights[0]: 1.271439e-03 [1.015900e-05] 
Layer 'fc8' biases: 8.124492e-02 [7.324412e-05] 
Train error last 870 batches: 0.435173
-------------------------------------------------------
Not saving because 0.415771 > 0.415638 (32.630: -0.00%)
======================================================= (12.083 sec)
33.11... logprob:  0.335076, 0.078125 (1.448 sec)
33.12... logprob:  0.466167, 0.125000 (1.412 sec)
33.13... logprob:  0.442065, 0.117188 (1.422 sec)
33.14... logprob:  0.444420, 0.117188 (1.403 sec)
33.15... logprob:  0.395442, 0.101562 (1.413 sec)
33.16... logprob:  0.421306, 0.109375 (1.411 sec)
33.17... logprob:  0.515854, 0.140625 (1.400 sec)
33.18... logprob:  0.262138, 0.054688 (1.408 sec)
33.19... logprob:  0.279431, 0.062500 (1.401 sec)
33.20... logprob:  0.421355, 0.109375 (1.424 sec)
33.21... logprob:  0.444005, 0.117188 (1.399 sec)
33.22... logprob:  0.536873, 0.148438 (1.415 sec)
33.23... logprob:  0.533306, 0.148438 (1.419 sec)
33.24... logprob:  0.310351, 0.070312 (1.423 sec)
33.25... logprob:  0.356035, 0.085938 (1.401 sec)
33.26... logprob:  0.463875, 0.125000 (1.451 sec)
33.27... logprob:  0.404461, 0.101562 (1.397 sec)
33.28... logprob:  0.421836, 0.109375 (1.414 sec)
33.29... logprob:  0.395855, 0.101562 (1.424 sec)
33.30... logprob:  0.373988, 0.093750 (1.421 sec)
33.31... logprob:  0.480005, 0.132812 (1.402 sec)
33.32... logprob:  0.457221, 0.125000 (1.400 sec)
33.33... logprob:  0.460681, 0.125000 (1.452 sec)
33.34... logprob:  0.464489, 0.125000 (1.393 sec)
33.35... logprob:  0.316366, 0.070312 (1.408 sec)
33.36... logprob:  0.475792, 0.132812 (1.409 sec)
33.37... logprob:  0.417594, 0.109375 (1.413 sec)
33.38... logprob:  0.392755, 0.101562 (1.395 sec)
33.39... logprob:  0.631252, 0.187500 (1.438 sec)
33.40... logprob:  0.445620, 0.117188 (1.411 sec)
33.41... logprob:  0.353070, 0.085938 (1.427 sec)
33.42... logprob:  0.392077, 0.101562 (1.416 sec)
33.43... logprob:  0.440065, 0.117188 (1.412 sec)
33.44... logprob:  0.518574, 0.148438 (1.438 sec)
33.45... logprob:  0.381707, 0.093750 (1.393 sec)
33.46... logprob:  0.486114, 0.132812 (1.395 sec)
33.47... logprob:  0.331715, 0.078125 (1.400 sec)
33.48... logprob:  0.498959, 0.140625 (1.431 sec)
33.49... logprob:  0.510970, 0.148438 (1.419 sec)
33.50... logprob:  0.393168, 0.101562 (1.429 sec)
33.51... logprob:  0.490358, 0.140625 (1.422 sec)
33.52... logprob:  0.525795, 0.148438 (1.399 sec)
33.53... logprob:  0.294701, 0.062500 (1.448 sec)
33.54... logprob:  0.403460, 0.109375 (1.396 sec)
33.55... logprob:  0.331652, 0.078125 (1.397 sec)
33.56... logprob:  0.421575, 0.109375 (1.406 sec)
33.57... logprob:  0.572290, 0.164062 (1.431 sec)
33.58... logprob:  0.407463, 0.101562 (1.404 sec)
33.59... logprob:  0.333866, 0.078125 (1.463 sec)
33.60... logprob:  0.618629, 0.179688 (1.428 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.37135314941406, 10.0]}, 128)
batch 872: ({'logprob': [66.42488098144531, 19.0]}, 128)
batch 873: ({'logprob': [40.85947799682617, 9.0]}, 128)
batch 874: ({'logprob': [45.18186950683594, 11.0]}, 128)
batch 875: ({'logprob': [50.80537414550781, 13.0]}, 128)
batch 876: ({'logprob': [63.96637725830078, 18.0]}, 128)
batch 877: ({'logprob': [45.84437561035156, 11.0]}, 128)
batch 878: ({'logprob': [62.11063766479492, 17.0]}, 128)
batch 879: ({'logprob': [74.0189208984375, 21.0]}, 128)
batch 880: ({'logprob': [50.83250045776367, 13.0]}, 128)
batch 881: ({'logprob': [28.91044807434082, 5.0]}, 128)
batch 882: ({'logprob': [55.28248596191406, 14.0]}, 128)
batch 883: ({'logprob': [62.081565856933594, 17.0]}, 128)
batch 884: ({'logprob': [51.470054626464844, 13.0]}, 128)
batch 885: ({'logprob': [52.77452087402344, 13.0]}, 128)
batch 886: ({'logprob': [62.75907897949219, 17.0]}, 128)

======================Test output======================
logprob:  0.417331, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957853e-03 [4.445993e-09] 
Layer 'conv1' biases: 4.292360e-07 [1.530584e-10] 
Layer 'conv2' weights[0]: 7.945031e-03 [3.550996e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.831932e-10] 
Layer 'conv3' weights[0]: 7.943183e-03 [3.665455e-09] 
Layer 'conv3' biases: 3.622051e-06 [2.417783e-09] 
Layer 'conv4' weights[0]: 7.975844e-03 [3.599784e-09] 
Layer 'conv4' biases: 9.999991e-01 [2.052981e-08] 
Layer 'conv5' weights[0]: 7.974608e-03 [1.314137e-07] 
Layer 'conv5' biases: 9.999894e-01 [1.409233e-07] 
Layer 'fc6' weights[0]: 7.571145e-03 [1.071204e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.096347e-08] 
Layer 'fc7' weights[0]: 6.816837e-03 [9.764232e-08] 
Layer 'fc7' biases: 9.998540e-01 [8.472887e-08] 
Layer 'fc8' weights[0]: 1.275087e-03 [2.781614e-06] 
Layer 'fc8' biases: 8.130953e-02 [1.762149e-05] 
Train error last 870 batches: 0.435172
-------------------------------------------------------
Not saving because 0.417331 > 0.415638 (32.630: -0.00%)
======================================================= (12.034 sec)
33.61... logprob:  0.382773, 0.093750 (1.432 sec)
33.62... logprob:  0.474824, 0.132812 (1.468 sec)
33.63... logprob:  0.397282, 0.101562 (1.443 sec)
33.64... logprob:  0.450348, 0.125000 (1.410 sec)
33.65... logprob:  0.373401, 0.093750 (1.403 sec)
33.66... logprob:  0.354052, 0.085938 (1.442 sec)
33.67... logprob:  0.295434, 0.062500 (1.393 sec)
33.68... logprob:  0.396796, 0.101562 (1.405 sec)
33.69... logprob:  0.496610, 0.140625 (1.431 sec)
33.70... logprob:  0.325920, 0.078125 (1.438 sec)
33.71... logprob:  0.381791, 0.101562 (1.468 sec)
33.72... logprob:  0.493641, 0.132812 (1.412 sec)
33.73... logprob:  0.447652, 0.117188 (1.425 sec)
33.74... logprob:  0.442487, 0.117188 (1.417 sec)
33.75... logprob:  0.380662, 0.093750 (1.421 sec)
33.76... logprob:  0.412035, 0.109375 (1.442 sec)
33.77... logprob:  0.396345, 0.101562 (1.432 sec)
33.78... logprob:  0.493048, 0.140625 (1.454 sec)
33.79... logprob:  0.456488, 0.125000 (1.412 sec)
33.80... logprob:  0.508097, 0.132812 (1.431 sec)
33.81... logprob:  0.416724, 0.109375 (1.419 sec)
33.82... logprob:  0.231040, 0.039062 (1.424 sec)
33.83... logprob:  0.493861, 0.140625 (1.401 sec)
33.84... logprob:  0.468177, 0.125000 (1.468 sec)
33.85... logprob:  0.431890, 0.117188 (1.427 sec)
33.86... logprob:  0.416905, 0.109375 (1.422 sec)
33.87... logprob:  0.633355, 0.187500 (1.425 sec)
33.88... logprob:  0.534999, 0.156250 (1.415 sec)
33.89... logprob:  0.410514, 0.109375 (1.441 sec)
33.90... logprob:  0.577480, 0.171875 (1.396 sec)
33.91... logprob:  0.348376, 0.078125 (1.401 sec)
33.92... logprob:  0.464459, 0.125000 (1.407 sec)
33.93... logprob:  0.492186, 0.140625 (1.403 sec)
33.94... logprob:  0.428788, 0.109375 (1.391 sec)
33.95... logprob:  0.471829, 0.125000 (1.408 sec)
33.96... logprob:  0.576121, 0.171875 (1.415 sec)
33.97... logprob:  0.430802, 0.117188 (1.401 sec)
33.98... logprob:  0.391279, 0.093750 (1.443 sec)
33.99... logprob:  0.474188, 0.132812 (1.408 sec)
33.100... logprob:  0.310725, 0.070312 (1.407 sec)
33.101... logprob:  0.311075, 0.062500 (1.453 sec)
33.102... logprob:  0.545747, 0.156250 (1.392 sec)
33.103... logprob:  0.540751, 0.156250 (1.404 sec)
33.104... logprob:  0.388793, 0.101562 (1.404 sec)
33.105... logprob:  0.619073, 0.179688 (1.397 sec)
33.106... logprob:  0.344482, 0.085938 (1.397 sec)
33.107... logprob:  0.335833, 0.078125 (1.440 sec)
33.108... logprob:  0.586860, 0.171875 (1.396 sec)
33.109... logprob:  0.336102, 0.078125 (1.404 sec)
33.110... logprob:  0.564743, 0.164062 (1.406 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.69089126586914, 10.0]}, 128)
batch 872: ({'logprob': [66.4875259399414, 19.0]}, 128)
batch 873: ({'logprob': [40.6599235534668, 9.0]}, 128)
batch 874: ({'logprob': [45.22567367553711, 11.0]}, 128)
batch 875: ({'logprob': [50.773948669433594, 13.0]}, 128)
batch 876: ({'logprob': [63.987300872802734, 18.0]}, 128)
batch 877: ({'logprob': [45.729427337646484, 11.0]}, 128)
batch 878: ({'logprob': [61.930381774902344, 17.0]}, 128)
batch 879: ({'logprob': [73.53158569335938, 21.0]}, 128)
batch 880: ({'logprob': [50.80160903930664, 13.0]}, 128)
batch 881: ({'logprob': [29.019012451171875, 5.0]}, 128)
batch 882: ({'logprob': [54.81707000732422, 14.0]}, 128)
batch 883: ({'logprob': [61.900917053222656, 17.0]}, 128)
batch 884: ({'logprob': [51.28007888793945, 13.0]}, 128)
batch 885: ({'logprob': [52.26677322387695, 13.0]}, 128)
batch 886: ({'logprob': [62.41985321044922, 17.0]}, 128)

======================Test output======================
logprob:  0.416270, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957819e-03 [4.079154e-09] 
Layer 'conv1' biases: 4.302026e-07 [1.301797e-10] 
Layer 'conv2' weights[0]: 7.944994e-03 [4.029585e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.297969e-10] 
Layer 'conv3' weights[0]: 7.943146e-03 [3.642418e-09] 
Layer 'conv3' biases: 3.631140e-06 [2.167491e-09] 
Layer 'conv4' weights[0]: 7.975806e-03 [3.643749e-09] 
Layer 'conv4' biases: 9.999990e-01 [1.808485e-08] 
Layer 'conv5' weights[0]: 7.974579e-03 [1.133205e-07] 
Layer 'conv5' biases: 9.999898e-01 [1.213759e-07] 
Layer 'fc6' weights[0]: 7.571110e-03 [9.348035e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.455059e-09] 
Layer 'fc7' weights[0]: 6.815137e-03 [1.641585e-07] 
Layer 'fc7' biases: 9.998539e-01 [1.546190e-07] 
Layer 'fc8' weights[0]: 1.271585e-03 [6.195675e-06] 
Layer 'fc8' biases: 8.139343e-02 [3.954959e-05] 
Train error last 870 batches: 0.435172
-------------------------------------------------------
Not saving because 0.416270 > 0.415638 (32.630: -0.00%)
======================================================= (12.029 sec)
33.111... logprob:  0.404644, 0.101562 (1.402 sec)
33.112... logprob:  0.365917, 0.093750 (1.412 sec)
33.113... logprob:  0.354327, 0.085938 (1.404 sec)
33.114... logprob:  0.440206, 0.117188 (1.434 sec)
33.115... logprob:  0.506817, 0.140625 (1.416 sec)
33.116... logprob:  0.393318, 0.101562 (1.396 sec)
33.117... logprob:  0.440393, 0.117188 (1.447 sec)
33.118... logprob:  0.409061, 0.101562 (1.389 sec)
33.119... logprob:  0.346052, 0.085938 (1.400 sec)
33.120... logprob:  0.547128, 0.156250 (1.409 sec)
33.121... logprob:  0.412573, 0.109375 (1.402 sec)
33.122... logprob:  0.519226, 0.148438 (1.446 sec)
33.123... logprob:  0.463648, 0.125000 (1.479 sec)
33.124... logprob:  0.447683, 0.125000 (1.416 sec)
33.125... logprob:  0.501882, 0.140625 (1.406 sec)
33.126... logprob:  0.475708, 0.125000 (1.396 sec)
33.127... logprob:  0.479456, 0.125000 (1.407 sec)
33.128... logprob:  0.422319, 0.109375 (1.421 sec)
33.129... logprob:  0.574879, 0.164062 (1.441 sec)
33.130... logprob:  0.382687, 0.093750 (1.419 sec)
33.131... logprob:  0.495497, 0.132812 (1.416 sec)
33.132... logprob:  0.506355, 0.140625 (1.441 sec)
33.133... logprob:  0.444698, 0.117188 (1.384 sec)
33.134... logprob:  0.401860, 0.101562 (1.396 sec)
33.135... logprob:  0.460170, 0.125000 (1.405 sec)
33.136... logprob:  0.562311, 0.164062 (1.404 sec)
33.137... logprob:  0.462597, 0.125000 (1.392 sec)
33.138... logprob:  0.319432, 0.070312 (1.449 sec)
33.139... logprob:  0.395723, 0.101562 (1.399 sec)
33.140... logprob:  0.559918, 0.164062 (1.415 sec)
33.141... logprob:  0.464596, 0.125000 (1.440 sec)
33.142... logprob:  0.464650, 0.125000 (1.394 sec)
33.143... logprob:  0.294483, 0.062500 (1.426 sec)
33.144... logprob:  0.456959, 0.125000 (1.415 sec)
33.145... logprob:  0.324674, 0.078125 (1.420 sec)
33.146... logprob:  0.483028, 0.132812 (1.412 sec)
33.147... logprob:  0.262494, 0.054688 (1.435 sec)
33.148... logprob:  0.458541, 0.125000 (1.392 sec)
33.149... logprob:  0.442479, 0.117188 (1.396 sec)
33.150... logprob:  0.347558, 0.085938 (1.402 sec)
33.151... logprob:  0.347132, 0.085938 (1.402 sec)
33.152... logprob:  0.785163, 0.234375 (1.387 sec)
33.153... logprob:  0.381634, 0.093750 (1.449 sec)
33.154... logprob:  0.524789, 0.148438 (1.408 sec)
33.155... logprob:  0.426153, 0.117188 (1.413 sec)
33.156... logprob:  0.295013, 0.062500 (1.441 sec)
33.157... logprob:  0.269905, 0.054688 (1.401 sec)
33.158... logprob:  0.455466, 0.125000 (1.408 sec)
33.159... logprob:  0.483134, 0.132812 (1.402 sec)
33.160... logprob:  0.444659, 0.117188 (1.395 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.900672912597656, 10.0]}, 128)
batch 872: ({'logprob': [66.13903045654297, 19.0]}, 128)
batch 873: ({'logprob': [41.178707122802734, 9.0]}, 128)
batch 874: ({'logprob': [45.48459243774414, 11.0]}, 128)
batch 875: ({'logprob': [50.91775894165039, 13.0]}, 128)
batch 876: ({'logprob': [63.732215881347656, 18.0]}, 128)
batch 877: ({'logprob': [46.060874938964844, 11.0]}, 128)
batch 878: ({'logprob': [61.84168243408203, 17.0]}, 128)
batch 879: ({'logprob': [73.28174591064453, 21.0]}, 128)
batch 880: ({'logprob': [50.94501495361328, 13.0]}, 128)
batch 881: ({'logprob': [29.699073791503906, 5.0]}, 128)
batch 882: ({'logprob': [55.08122253417969, 14.0]}, 128)
batch 883: ({'logprob': [61.81245803833008, 17.0]}, 128)
batch 884: ({'logprob': [51.49407958984375, 13.0]}, 128)
batch 885: ({'logprob': [52.62443923950195, 13.0]}, 128)
batch 886: ({'logprob': [62.402278900146484, 17.0]}, 128)

======================Test output======================
logprob:  0.417283, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957766e-03 [2.472327e-09] 
Layer 'conv1' biases: 4.312069e-07 [4.687375e-11] 
Layer 'conv2' weights[0]: 7.944953e-03 [1.683279e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.402839e-10] 
Layer 'conv3' weights[0]: 7.943108e-03 [1.235794e-09] 
Layer 'conv3' biases: 3.640350e-06 [3.867836e-10] 
Layer 'conv4' weights[0]: 7.975771e-03 [1.165983e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.415425e-09] 
Layer 'conv5' weights[0]: 7.974539e-03 [6.215436e-09] 
Layer 'conv5' biases: 9.999897e-01 [6.187686e-09] 
Layer 'fc6' weights[0]: 7.571068e-03 [8.807029e-10] 
Layer 'fc6' biases: 1.000000e+00 [4.304548e-10] 
Layer 'fc7' weights[0]: 6.813363e-03 [4.580271e-08] 
Layer 'fc7' biases: 9.998534e-01 [2.550456e-08] 
Layer 'fc8' weights[0]: 1.263257e-03 [4.526180e-06] 
Layer 'fc8' biases: 8.142167e-02 [2.850958e-05] 
Train error last 870 batches: 0.435172
-------------------------------------------------------
Not saving because 0.417283 > 0.415638 (32.630: -0.00%)
======================================================= (12.201 sec)
33.161... logprob:  0.349558, 0.078125 (1.412 sec)
33.162... logprob:  0.611794, 0.179688 (1.415 sec)
33.163... logprob:  0.450509, 0.125000 (1.459 sec)
33.164... logprob:  0.468475, 0.125000 (1.429 sec)
33.165... logprob:  0.547711, 0.156250 (1.423 sec)
33.166... logprob:  0.446186, 0.125000 (1.451 sec)
33.167... logprob:  0.350671, 0.085938 (1.434 sec)
33.168... logprob:  0.363770, 0.085938 (1.423 sec)
33.169... logprob:  0.408611, 0.101562 (1.464 sec)
33.170... logprob:  0.459454, 0.125000 (1.400 sec)
33.171... logprob:  0.535159, 0.156250 (1.428 sec)
33.172... logprob:  0.434779, 0.109375 (1.421 sec)
33.173... logprob:  0.440459, 0.117188 (1.428 sec)
33.174... logprob:  0.600547, 0.171875 (1.408 sec)
33.175... logprob:  0.505887, 0.140625 (1.467 sec)
33.176... logprob:  0.478375, 0.132812 (1.422 sec)
33.177... logprob:  0.289722, 0.054688 (1.426 sec)
33.178... logprob:  0.383474, 0.093750 (1.464 sec)
33.179... logprob:  0.394649, 0.101562 (1.407 sec)
33.180... logprob:  0.466394, 0.125000 (1.433 sec)
33.181... logprob:  0.539240, 0.156250 (1.419 sec)
33.182... logprob:  0.371244, 0.093750 (1.417 sec)
33.183... logprob:  0.419926, 0.109375 (1.419 sec)
33.184... logprob:  0.483428, 0.132812 (1.420 sec)
33.185... logprob:  0.289710, 0.062500 (1.400 sec)
33.186... logprob:  0.370310, 0.093750 (1.543 sec)
33.187... logprob:  0.529615, 0.148438 (1.407 sec)
33.188... logprob:  0.458833, 0.125000 (1.401 sec)
33.189... logprob:  0.440926, 0.117188 (1.394 sec)
33.190... logprob:  0.375799, 0.093750 (1.442 sec)
33.191... logprob:  0.485097, 0.132812 (1.406 sec)
33.192... logprob:  0.519996, 0.148438 (1.418 sec)
33.193... logprob:  0.312451, 0.070312 (1.419 sec)
33.194... logprob:  0.414030, 0.109375 (1.421 sec)
33.195... logprob:  0.286961, 0.062500 (1.397 sec)
33.196... logprob:  0.410431, 0.109375 (1.398 sec)
33.197... logprob:  0.477973, 0.132812 (1.405 sec)
33.198... logprob:  0.355797, 0.085938 (1.405 sec)
33.199... logprob:  0.437195, 0.117188 (1.395 sec)
33.200... logprob:  0.440720, 0.117188 (1.448 sec)
33.201... logprob:  0.437086, 0.117188 (1.413 sec)
33.202... logprob:  0.537802, 0.148438 (1.401 sec)
33.203... logprob:  0.420393, 0.109375 (1.448 sec)
33.204... logprob:  0.504123, 0.140625 (1.395 sec)
33.205... logprob:  0.334251, 0.078125 (1.415 sec)
33.206... logprob:  0.361639, 0.093750 (1.401 sec)
33.207... logprob:  0.381727, 0.093750 (1.395 sec)
33.208... logprob:  0.490606, 0.140625 (1.398 sec)
33.209... logprob:  0.334520, 0.078125 (1.418 sec)
33.210... logprob:  0.586221, 0.171875 (1.423 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.69717025756836, 10.0]}, 128)
batch 872: ({'logprob': [66.32295989990234, 19.0]}, 128)
batch 873: ({'logprob': [40.889854431152344, 9.0]}, 128)
batch 874: ({'logprob': [45.30518341064453, 11.0]}, 128)
batch 875: ({'logprob': [50.822513580322266, 13.0]}, 128)
batch 876: ({'logprob': [63.86811447143555, 18.0]}, 128)
batch 877: ({'logprob': [45.86874771118164, 11.0]}, 128)
batch 878: ({'logprob': [61.916259765625, 17.0]}, 128)
batch 879: ({'logprob': [73.51338195800781, 21.0]}, 128)
batch 880: ({'logprob': [50.85023880004883, 13.0]}, 128)
batch 881: ({'logprob': [29.252582550048828, 5.0]}, 128)
batch 882: ({'logprob': [54.998165130615234, 14.0]}, 128)
batch 883: ({'logprob': [61.8865966796875, 17.0]}, 128)
batch 884: ({'logprob': [51.38755798339844, 13.0]}, 128)
batch 885: ({'logprob': [52.49296188354492, 13.0]}, 128)
batch 886: ({'logprob': [62.46489334106445, 17.0]}, 128)

======================Test output======================
logprob:  0.416766, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957725e-03 [3.368984e-09] 
Layer 'conv1' biases: 4.323134e-07 [1.454198e-10] 
Layer 'conv2' weights[0]: 7.944924e-03 [2.436344e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.223174e-10] 
Layer 'conv3' weights[0]: 7.943073e-03 [2.619243e-09] 
Layer 'conv3' biases: 3.649632e-06 [1.775579e-09] 
Layer 'conv4' weights[0]: 7.975733e-03 [2.486534e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.406068e-08] 
Layer 'conv5' weights[0]: 7.974494e-03 [8.739295e-08] 
Layer 'conv5' biases: 9.999896e-01 [9.377004e-08] 
Layer 'fc6' weights[0]: 7.571026e-03 [7.173303e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.302475e-09] 
Layer 'fc7' weights[0]: 6.811635e-03 [7.854618e-08] 
Layer 'fc7' biases: 9.998534e-01 [6.439041e-08] 
Layer 'fc8' weights[0]: 1.274773e-03 [4.524807e-06] 
Layer 'fc8' biases: 8.157961e-02 [3.057668e-05] 
Train error last 870 batches: 0.435172
-------------------------------------------------------
Not saving because 0.416766 > 0.415638 (32.630: -0.00%)
======================================================= (12.070 sec)
33.211... logprob:  0.488102, 0.132812 (1.422 sec)
33.212... logprob:  0.526107, 0.148438 (1.418 sec)
33.213... logprob:  0.514564, 0.140625 (1.460 sec)
33.214... logprob:  0.459380, 0.125000 (1.434 sec)
33.215... logprob:  0.396072, 0.101562 (1.420 sec)
33.216... logprob:  0.516861, 0.140625 (1.465 sec)
33.217... logprob:  0.324784, 0.070312 (1.409 sec)
33.218... logprob:  0.463555, 0.125000 (1.424 sec)
33.219... logprob:  0.500208, 0.140625 (1.414 sec)
33.220... logprob:  0.415037, 0.109375 (1.427 sec)
33.221... logprob:  0.399581, 0.101562 (1.402 sec)
33.222... logprob:  0.554353, 0.164062 (1.460 sec)
33.223... logprob:  0.568850, 0.164062 (1.434 sec)
33.224... logprob:  0.406011, 0.101562 (1.435 sec)
33.225... logprob:  0.392021, 0.101562 (1.446 sec)
33.226... logprob:  0.424779, 0.109375 (1.425 sec)
33.227... logprob:  0.452595, 0.125000 (1.426 sec)
33.228... logprob:  0.417165, 0.109375 (1.418 sec)
33.229... logprob:  0.489371, 0.132812 (1.417 sec)
33.230... logprob:  0.459836, 0.125000 (1.438 sec)
33.231... logprob:  0.453467, 0.125000 (1.410 sec)
33.232... logprob:  0.496136, 0.140625 (1.463 sec)
33.233... logprob:  0.466025, 0.132812 (1.425 sec)
33.234... logprob:  0.563887, 0.164062 (1.428 sec)
33.235... logprob:  0.482009, 0.132812 (1.477 sec)
33.236... logprob:  0.425604, 0.109375 (1.403 sec)
33.237... logprob:  0.340807, 0.078125 (1.427 sec)
33.238... logprob:  0.389026, 0.093750 (1.439 sec)
33.239... logprob:  0.478073, 0.132812 (1.423 sec)
33.240... logprob:  0.485794, 0.132812 (1.403 sec)
33.241... logprob:  0.493603, 0.132812 (1.459 sec)
33.242... logprob:  0.341620, 0.078125 (1.438 sec)
33.243... logprob:  0.385988, 0.093750 (1.438 sec)
33.244... logprob:  0.315471, 0.070312 (1.450 sec)
33.245... logprob:  0.494173, 0.132812 (1.424 sec)
33.246... logprob:  0.416830, 0.109375 (1.419 sec)
33.247... logprob:  0.357643, 0.085938 (1.419 sec)
33.248... logprob:  0.308154, 0.070312 (1.427 sec)
33.249... logprob:  0.554298, 0.156250 (1.432 sec)
33.250... logprob:  0.591004, 0.164062 (1.411 sec)
33.251... logprob:  0.353022, 0.085938 (1.460 sec)
33.252... logprob:  0.348419, 0.085938 (1.431 sec)
33.253... logprob:  0.379244, 0.093750 (1.416 sec)
33.254... logprob:  0.444151, 0.117188 (1.468 sec)
33.255... logprob:  0.351280, 0.085938 (1.407 sec)
33.256... logprob:  0.378900, 0.093750 (1.422 sec)
33.257... logprob:  0.331951, 0.078125 (1.419 sec)
33.258... logprob:  0.415447, 0.109375 (1.418 sec)
33.259... logprob:  0.442320, 0.117188 (1.490 sec)
33.260... logprob:  0.308128, 0.070312 (1.461 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.81138610839844, 10.0]}, 128)
batch 872: ({'logprob': [67.85777282714844, 19.0]}, 128)
batch 873: ({'logprob': [39.59989929199219, 9.0]}, 128)
batch 874: ({'logprob': [45.015560150146484, 11.0]}, 128)
batch 875: ({'logprob': [50.80490493774414, 13.0]}, 128)
batch 876: ({'logprob': [65.08651733398438, 18.0]}, 128)
batch 877: ({'logprob': [45.21540069580078, 11.0]}, 128)
batch 878: ({'logprob': [62.451663970947266, 17.0]}, 128)
batch 879: ({'logprob': [74.24067687988281, 21.0]}, 128)
batch 880: ({'logprob': [50.8349723815918, 13.0]}, 128)
batch 881: ({'logprob': [27.77088737487793, 5.0]}, 128)
batch 882: ({'logprob': [54.217376708984375, 14.0]}, 128)
batch 883: ({'logprob': [62.420536041259766, 17.0]}, 128)
batch 884: ({'logprob': [51.012977600097656, 13.0]}, 128)
batch 885: ({'logprob': [51.394073486328125, 13.0]}, 128)
batch 886: ({'logprob': [62.64023971557617, 17.0]}, 128)

======================Test output======================
logprob:  0.416199, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957677e-03 [2.354635e-09] 
Layer 'conv1' biases: 4.334740e-07 [8.182544e-11] 
Layer 'conv2' weights[0]: 7.944886e-03 [1.972412e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.227094e-10] 
Layer 'conv3' weights[0]: 7.943034e-03 [1.845603e-09] 
Layer 'conv3' biases: 3.656582e-06 [9.546531e-10] 
Layer 'conv4' weights[0]: 7.975701e-03 [1.922437e-09] 
Layer 'conv4' biases: 9.999991e-01 [8.441056e-09] 
Layer 'conv5' weights[0]: 7.974453e-03 [5.400323e-08] 
Layer 'conv5' biases: 9.999893e-01 [5.788028e-08] 
Layer 'fc6' weights[0]: 7.570987e-03 [4.500115e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.494982e-09] 
Layer 'fc7' weights[0]: 6.809929e-03 [7.229155e-08] 
Layer 'fc7' biases: 9.998537e-01 [5.656126e-08] 
Layer 'fc8' weights[0]: 1.307204e-03 [2.362143e-06] 
Layer 'fc8' biases: 8.191948e-02 [1.697117e-05] 
Train error last 870 batches: 0.435171
-------------------------------------------------------
Not saving because 0.416199 > 0.415638 (32.630: -0.00%)
======================================================= (12.066 sec)
33.261... logprob:  0.392484, 0.101562 (1.444 sec)
33.262... logprob:  0.524462, 0.148438 (1.437 sec)
33.263... logprob:  0.425636, 0.109375 (1.451 sec)
33.264... logprob:  0.374985, 0.093750 (1.421 sec)
33.265... logprob:  0.439608, 0.117188 (1.416 sec)
33.266... logprob:  0.439001, 0.117188 (1.421 sec)
33.267... logprob:  0.422048, 0.109375 (1.417 sec)
33.268... logprob:  0.458942, 0.125000 (1.434 sec)
33.269... logprob:  0.567617, 0.164062 (1.412 sec)
33.270... logprob:  0.542379, 0.156250 (1.465 sec)
33.271... logprob:  0.445557, 0.117188 (1.451 sec)
33.272... logprob:  0.384496, 0.093750 (1.427 sec)
33.273... logprob:  0.500240, 0.140625 (1.470 sec)
33.274... logprob:  0.542496, 0.156250 (1.399 sec)
33.275... logprob:  0.487526, 0.132812 (1.430 sec)
33.276... logprob:  0.389954, 0.093750 (1.412 sec)
33.277... logprob:  0.428564, 0.109375 (1.429 sec)
33.278... logprob:  0.323688, 0.070312 (1.430 sec)
33.279... logprob:  0.325385, 0.070312 (1.466 sec)
33.280... logprob:  0.216285, 0.031250 (1.404 sec)
33.281... logprob:  0.417271, 0.109375 (1.427 sec)
33.282... logprob:  0.411280, 0.109375 (1.419 sec)
33.283... logprob:  0.393694, 0.101562 (1.417 sec)
33.284... logprob:  0.394282, 0.101562 (1.415 sec)
33.285... logprob:  0.451163, 0.117188 (1.445 sec)
33.286... logprob:  0.535896, 0.140625 (1.447 sec)
33.287... logprob:  0.346485, 0.085938 (1.432 sec)
33.288... logprob:  0.329934, 0.078125 (1.440 sec)
33.289... logprob:  0.445719, 0.117188 (1.445 sec)
33.290... logprob:  0.490636, 0.132812 (1.410 sec)
33.291... logprob:  0.439371, 0.117188 (1.425 sec)
33.292... logprob:  0.567906, 0.156250 (1.422 sec)
33.293... logprob:  0.427848, 0.117188 (1.428 sec)
33.294... logprob:  0.355596, 0.085938 (1.406 sec)
33.295... logprob:  0.334092, 0.078125 (1.467 sec)
33.296... logprob:  0.355243, 0.085938 (1.422 sec)
33.297... logprob:  0.394208, 0.101562 (1.423 sec)
33.298... logprob:  0.448297, 0.125000 (1.463 sec)
33.299... logprob:  0.341714, 0.078125 (1.402 sec)
33.300... logprob:  0.406256, 0.101562 (1.429 sec)
33.301... logprob:  0.397849, 0.101562 (1.415 sec)
33.302... logprob:  0.591633, 0.179688 (1.422 sec)
33.303... logprob:  0.459452, 0.125000 (1.405 sec)
33.304... logprob:  0.459591, 0.125000 (1.447 sec)
33.305... logprob:  0.455186, 0.125000 (1.440 sec)
33.306... logprob:  0.440565, 0.117188 (1.441 sec)
33.307... logprob:  0.421632, 0.109375 (1.446 sec)
33.308... logprob:  0.374923, 0.093750 (1.452 sec)
33.309... logprob:  0.450483, 0.125000 (1.420 sec)
33.310... logprob:  0.473522, 0.125000 (1.420 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.8226432800293, 10.0]}, 128)
batch 872: ({'logprob': [66.14859008789062, 19.0]}, 128)
batch 873: ({'logprob': [41.17119598388672, 9.0]}, 128)
batch 874: ({'logprob': [45.452449798583984, 11.0]}, 128)
batch 875: ({'logprob': [50.9077262878418, 13.0]}, 128)
batch 876: ({'logprob': [63.742305755615234, 18.0]}, 128)
batch 877: ({'logprob': [46.05192947387695, 11.0]}, 128)
batch 878: ({'logprob': [61.87565612792969, 17.0]}, 128)
batch 879: ({'logprob': [73.38285064697266, 21.0]}, 128)
batch 880: ({'logprob': [50.93498229980469, 13.0]}, 128)
batch 881: ({'logprob': [29.624237060546875, 5.0]}, 128)
batch 882: ({'logprob': [55.140377044677734, 14.0]}, 128)
batch 883: ({'logprob': [61.846439361572266, 17.0]}, 128)
batch 884: ({'logprob': [51.507423400878906, 13.0]}, 128)
batch 885: ({'logprob': [52.684173583984375, 13.0]}, 128)
batch 886: ({'logprob': [62.45958709716797, 17.0]}, 128)

======================Test output======================
logprob:  0.417360, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957652e-03 [2.523094e-09] 
Layer 'conv1' biases: 4.346859e-07 [4.567906e-11] 
Layer 'conv2' weights[0]: 7.944841e-03 [1.554214e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.468104e-10] 
Layer 'conv3' weights[0]: 7.942996e-03 [1.179150e-09] 
Layer 'conv3' biases: 3.666454e-06 [3.890228e-10] 
Layer 'conv4' weights[0]: 7.975665e-03 [1.153751e-09] 
Layer 'conv4' biases: 9.999991e-01 [2.287018e-09] 
Layer 'conv5' weights[0]: 7.974418e-03 [1.222377e-08] 
Layer 'conv5' biases: 9.999892e-01 [1.273911e-08] 
Layer 'fc6' weights[0]: 7.570947e-03 [1.249891e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.658797e-10] 
Layer 'fc7' weights[0]: 6.808199e-03 [4.555118e-08] 
Layer 'fc7' biases: 9.998533e-01 [2.488365e-08] 
Layer 'fc8' weights[0]: 1.267006e-03 [9.216581e-07] 
Layer 'fc8' biases: 8.189670e-02 [9.007254e-06] 
Train error last 870 batches: 0.435171
-------------------------------------------------------
Not saving because 0.417360 > 0.415638 (32.630: -0.00%)
======================================================= (12.118 sec)
33.311... logprob:  0.502394, 0.140625 (1.437 sec)
33.312... logprob:  0.478636, 0.132812 (1.446 sec)
33.313... logprob:  0.454853, 0.125000 (1.428 sec)
33.314... logprob:  0.454299, 0.117188 (1.463 sec)
33.315... logprob:  0.314695, 0.070312 (1.437 sec)
33.316... logprob:  0.468485, 0.125000 (1.426 sec)
33.317... logprob:  0.355410, 0.085938 (1.488 sec)
33.318... logprob:  0.455397, 0.125000 (1.419 sec)
33.319... logprob:  0.423155, 0.117188 (1.425 sec)
33.320... logprob:  0.412226, 0.109375 (1.431 sec)
33.321... logprob:  0.348222, 0.085938 (1.433 sec)
33.322... logprob:  0.387414, 0.101562 (1.427 sec)
33.323... logprob:  0.416497, 0.109375 (1.479 sec)
33.324... logprob:  0.498592, 0.140625 (1.428 sec)
33.325... logprob:  0.350669, 0.085938 (1.444 sec)
33.326... logprob:  0.543186, 0.148438 (1.465 sec)
33.327... logprob:  0.554431, 0.164062 (1.430 sec)
33.328... logprob:  0.565181, 0.156250 (1.428 sec)
33.329... logprob:  0.401886, 0.101562 (1.432 sec)
33.330... logprob:  0.388455, 0.101562 (1.423 sec)
33.331... logprob:  0.352169, 0.085938 (1.420 sec)
33.332... logprob:  0.482784, 0.132812 (1.449 sec)
33.333... logprob:  0.339411, 0.085938 (1.450 sec)
33.334... logprob:  0.565353, 0.171875 (1.439 sec)
33.335... logprob:  0.358631, 0.085938 (1.442 sec)
33.336... logprob:  0.444868, 0.125000 (1.460 sec)
33.337... logprob:  0.566384, 0.164062 (1.422 sec)
33.338... logprob:  0.449517, 0.125000 (1.426 sec)
33.339... logprob:  0.488554, 0.132812 (1.432 sec)
33.340... logprob:  0.442061, 0.117188 (1.430 sec)
33.341... logprob:  0.529989, 0.148438 (1.416 sec)
33.342... logprob:  0.429585, 0.109375 (1.469 sec)
33.343... logprob:  0.434762, 0.109375 (1.439 sec)
33.344... logprob:  0.444552, 0.125000 (1.488 sec)
33.345... logprob:  0.488167, 0.132812 (1.438 sec)
33.346... logprob:  0.436202, 0.117188 (1.463 sec)
33.347... logprob:  0.372603, 0.085938 (1.489 sec)
33.348... logprob:  0.398510, 0.101562 (1.429 sec)
33.349... logprob:  0.497518, 0.140625 (1.441 sec)
33.350... logprob:  0.358761, 0.085938 (1.432 sec)
33.351... logprob:  0.508435, 0.140625 (1.433 sec)
33.352... logprob:  0.363601, 0.093750 (1.434 sec)
33.353... logprob:  0.512348, 0.148438 (1.494 sec)
33.354... logprob:  0.674686, 0.203125 (1.437 sec)
33.355... logprob:  0.357509, 0.085938 (1.447 sec)
33.356... logprob:  0.479238, 0.132812 (1.482 sec)
33.357... logprob:  0.346647, 0.085938 (1.435 sec)
33.358... logprob:  0.325675, 0.070312 (1.439 sec)
33.359... logprob:  0.555427, 0.164062 (1.436 sec)
33.360... logprob:  0.444529, 0.117188 (1.425 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.019962310791016, 10.0]}, 128)
batch 872: ({'logprob': [66.1308364868164, 19.0]}, 128)
batch 873: ({'logprob': [41.192909240722656, 9.0]}, 128)
batch 874: ({'logprob': [45.535797119140625, 11.0]}, 128)
batch 875: ({'logprob': [50.93679428100586, 13.0]}, 128)
batch 876: ({'logprob': [63.7228889465332, 18.0]}, 128)
batch 877: ({'logprob': [46.07761001586914, 11.0]}, 128)
batch 878: ({'logprob': [61.79670715332031, 17.0]}, 128)
batch 879: ({'logprob': [73.13792419433594, 21.0]}, 128)
batch 880: ({'logprob': [50.96439743041992, 13.0]}, 128)
batch 881: ({'logprob': [29.812238693237305, 5.0]}, 128)
batch 882: ({'logprob': [54.997859954833984, 14.0]}, 128)
batch 883: ({'logprob': [61.76716613769531, 17.0]}, 128)
batch 884: ({'logprob': [51.478580474853516, 13.0]}, 128)
batch 885: ({'logprob': [52.53961944580078, 13.0]}, 128)
batch 886: ({'logprob': [62.322540283203125, 17.0]}, 128)

======================Test output======================
logprob:  0.417204, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957610e-03 [3.685587e-09] 
Layer 'conv1' biases: 4.356215e-07 [5.898658e-11] 
Layer 'conv2' weights[0]: 7.944798e-03 [2.164737e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.928930e-10] 
Layer 'conv3' weights[0]: 7.942957e-03 [1.470657e-09] 
Layer 'conv3' biases: 3.674806e-06 [5.043755e-10] 
Layer 'conv4' weights[0]: 7.975629e-03 [1.388375e-09] 
Layer 'conv4' biases: 9.999991e-01 [2.246259e-09] 
Layer 'conv5' weights[0]: 7.974381e-03 [1.460213e-08] 
Layer 'conv5' biases: 9.999896e-01 [1.556867e-08] 
Layer 'fc6' weights[0]: 7.570912e-03 [1.427526e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.208288e-09] 
Layer 'fc7' weights[0]: 6.806445e-03 [6.578935e-08] 
Layer 'fc7' biases: 9.998529e-01 [5.027328e-08] 
Layer 'fc8' weights[0]: 1.264697e-03 [1.601376e-06] 
Layer 'fc8' biases: 8.197863e-02 [9.631728e-06] 
Train error last 870 batches: 0.435171
-------------------------------------------------------
Not saving because 0.417204 > 0.415638 (32.630: -0.00%)
======================================================= (12.119 sec)
33.361... logprob:  0.410721, 0.101562 (1.443 sec)
33.362... logprob:  0.423890, 0.117188 (1.479 sec)
33.363... logprob:  0.486601, 0.132812 (1.442 sec)
33.364... logprob:  0.475639, 0.125000 (1.457 sec)
33.365... logprob:  0.425030, 0.109375 (1.464 sec)
33.366... logprob:  0.409530, 0.109375 (1.448 sec)
33.367... logprob:  0.324867, 0.078125 (1.440 sec)
33.368... logprob:  0.595524, 0.171875 (1.427 sec)
33.369... logprob:  0.381697, 0.093750 (1.432 sec)
33.370... logprob:  0.381334, 0.093750 (1.437 sec)
33.371... logprob:  0.400447, 0.101562 (1.461 sec)
33.372... logprob:  0.537120, 0.156250 (1.455 sec)
33.373... logprob:  0.463777, 0.125000 (1.458 sec)
33.374... logprob:  0.526746, 0.148438 (1.447 sec)
33.375... logprob:  0.393763, 0.101562 (1.465 sec)
33.376... logprob:  0.374285, 0.093750 (1.435 sec)
33.377... logprob:  0.295461, 0.062500 (1.431 sec)
33.378... logprob:  0.453632, 0.125000 (1.432 sec)
33.379... logprob:  0.420247, 0.109375 (1.471 sec)
33.380... logprob:  0.605637, 0.179688 (1.445 sec)
33.381... logprob:  0.463396, 0.125000 (1.467 sec)
33.382... logprob:  0.529604, 0.148438 (1.445 sec)
33.383... logprob:  0.358485, 0.085938 (1.438 sec)
33.384... logprob:  0.521264, 0.148438 (1.488 sec)
33.385... logprob:  0.523625, 0.148438 (1.432 sec)
33.386... logprob:  0.582663, 0.171875 (1.431 sec)
33.387... logprob:  0.428453, 0.117188 (1.435 sec)
33.388... logprob:  0.521404, 0.148438 (1.438 sec)
33.389... logprob:  0.425465, 0.109375 (1.433 sec)
33.390... logprob:  0.419584, 0.109375 (1.483 sec)
33.391... logprob:  0.318056, 0.070312 (1.439 sec)
33.392... logprob:  0.439452, 0.117188 (1.442 sec)
33.393... logprob:  0.369080, 0.093750 (1.491 sec)
33.394... logprob:  0.343773, 0.078125 (1.436 sec)
33.395... logprob:  0.332019, 0.078125 (1.432 sec)
33.396... logprob:  0.252835, 0.046875 (1.439 sec)
33.397... logprob:  0.483894, 0.132812 (1.433 sec)
33.398... logprob:  0.470416, 0.125000 (1.433 sec)
33.399... logprob:  0.432971, 0.117188 (1.488 sec)
33.400... logprob:  0.537040, 0.148438 (1.433 sec)
33.401... logprob:  0.465437, 0.125000 (1.446 sec)
33.402... logprob:  0.473658, 0.125000 (1.485 sec)
33.403... logprob:  0.462034, 0.125000 (1.439 sec)
33.404... logprob:  0.474784, 0.125000 (1.435 sec)
33.405... logprob:  0.544401, 0.156250 (1.441 sec)
33.406... logprob:  0.357427, 0.085938 (1.428 sec)
33.407... logprob:  0.493156, 0.140625 (1.437 sec)
33.408... logprob:  0.338557, 0.078125 (1.479 sec)
33.409... logprob:  0.400204, 0.101562 (1.442 sec)
33.410... logprob:  0.582512, 0.171875 (1.451 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.84920883178711, 10.0]}, 128)
batch 872: ({'logprob': [65.69740295410156, 19.0]}, 128)
batch 873: ({'logprob': [42.47246170043945, 9.0]}, 128)
batch 874: ({'logprob': [46.36396408081055, 11.0]}, 128)
batch 875: ({'logprob': [51.49660110473633, 13.0]}, 128)
batch 876: ({'logprob': [63.46831130981445, 18.0]}, 128)
batch 877: ({'logprob': [46.99752426147461, 11.0]}, 128)
batch 878: ({'logprob': [61.814453125, 17.0]}, 128)
batch 879: ({'logprob': [72.70396423339844, 21.0]}, 128)
batch 880: ({'logprob': [51.52295684814453, 13.0]}, 128)
batch 881: ({'logprob': [31.54461097717285, 5.0]}, 128)
batch 882: ({'logprob': [55.645530700683594, 14.0]}, 128)
batch 883: ({'logprob': [61.78570556640625, 17.0]}, 128)
batch 884: ({'logprob': [52.125057220458984, 13.0]}, 128)
batch 885: ({'logprob': [53.366939544677734, 13.0]}, 128)
batch 886: ({'logprob': [62.429019927978516, 17.0]}, 128)

======================Test output======================
logprob:  0.421037, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957578e-03 [3.267523e-09] 
Layer 'conv1' biases: 4.366621e-07 [4.553750e-11] 
Layer 'conv2' weights[0]: 7.944759e-03 [2.198702e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.664852e-10] 
Layer 'conv3' weights[0]: 7.942918e-03 [1.759064e-09] 
Layer 'conv3' biases: 3.684191e-06 [8.651149e-10] 
Layer 'conv4' weights[0]: 7.975592e-03 [1.859547e-09] 
Layer 'conv4' biases: 9.999992e-01 [6.873226e-09] 
Layer 'conv5' weights[0]: 7.974341e-03 [4.409153e-08] 
Layer 'conv5' biases: 9.999898e-01 [4.719920e-08] 
Layer 'fc6' weights[0]: 7.570876e-03 [3.655540e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.646957e-09] 
Layer 'fc7' weights[0]: 6.804712e-03 [2.256122e-07] 
Layer 'fc7' biases: 9.998527e-01 [2.163324e-07] 
Layer 'fc8' weights[0]: 1.234880e-03 [8.361434e-06] 
Layer 'fc8' biases: 8.195731e-02 [4.956653e-05] 
Train error last 870 batches: 0.435170
-------------------------------------------------------
Not saving because 0.421037 > 0.415638 (32.630: -0.00%)
======================================================= (12.081 sec)
33.411... logprob:  0.397533, 0.101562 (1.480 sec)
33.412... logprob:  0.540371, 0.156250 (1.456 sec)
33.413... logprob:  0.544649, 0.156250 (1.441 sec)
33.414... logprob:  0.466283, 0.125000 (1.437 sec)
33.415... logprob:  0.401581, 0.101562 (1.426 sec)
33.416... logprob:  0.427451, 0.109375 (1.442 sec)
33.417... logprob:  0.405461, 0.093750 (1.462 sec)
33.418... logprob:  0.380588, 0.093750 (1.458 sec)
33.419... logprob:  0.417988, 0.101562 (1.451 sec)
33.420... logprob:  0.356702, 0.085938 (1.457 sec)
33.421... logprob:  0.376715, 0.101562 (1.463 sec)
33.422... logprob:  0.521717, 0.148438 (1.435 sec)
33.423... logprob:  0.420725, 0.109375 (1.428 sec)
33.424... logprob:  0.325038, 0.078125 (1.433 sec)
33.425... logprob:  0.306665, 0.070312 (1.443 sec)
33.426... logprob:  0.448865, 0.117188 (1.446 sec)
33.427... logprob:  0.553644, 0.156250 (1.466 sec)
33.428... logprob:  0.601229, 0.171875 (1.456 sec)
33.429... logprob:  0.426371, 0.109375 (1.455 sec)
33.430... logprob:  0.299708, 0.070312 (1.472 sec)
33.431... logprob:  0.600305, 0.171875 (1.436 sec)
33.432... logprob:  0.387507, 0.093750 (1.431 sec)
33.433... logprob:  0.329387, 0.078125 (1.432 sec)
33.434... logprob:  0.529858, 0.148438 (1.443 sec)
33.435... logprob:  0.532714, 0.156250 (1.432 sec)
33.436... logprob:  0.380696, 0.093750 (1.479 sec)
33.437... logprob:  0.500383, 0.140625 (1.445 sec)
33.438... logprob:  0.547102, 0.156250 (1.436 sec)
33.439... logprob:  0.378338, 0.093750 (1.489 sec)
33.440... logprob:  0.439558, 0.117188 (1.433 sec)
33.441... logprob:  0.467908, 0.125000 (1.435 sec)
33.442... logprob:  0.378903, 0.093750 (1.439 sec)
33.443... logprob:  0.496550, 0.140625 (1.437 sec)
33.444... logprob:  0.372522, 0.093750 (1.440 sec)
33.445... logprob:  0.362808, 0.085938 (1.480 sec)
33.446... logprob:  0.398508, 0.101562 (1.442 sec)
33.447... logprob:  0.569194, 0.164062 (1.440 sec)
33.448... logprob:  0.333226, 0.078125 (1.484 sec)
33.449... logprob:  0.400065, 0.101562 (1.432 sec)
33.450... logprob:  0.240109, 0.046875 (1.436 sec)
33.451... logprob:  0.452314, 0.125000 (1.439 sec)
33.452... logprob:  0.455844, 0.117188 (1.427 sec)
33.453... logprob:  0.454920, 0.125000 (1.463 sec)
33.454... logprob:  0.488718, 0.132812 (1.484 sec)
33.455... logprob:  0.505942, 0.140625 (1.447 sec)
33.456... logprob:  0.468840, 0.125000 (1.440 sec)
33.457... logprob:  0.375301, 0.093750 (1.477 sec)
33.458... logprob:  0.350888, 0.085938 (1.437 sec)
33.459... logprob:  0.514226, 0.140625 (1.439 sec)
33.460... logprob:  0.273359, 0.054688 (1.435 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.610389709472656, 10.0]}, 128)
batch 872: ({'logprob': [66.48454284667969, 19.0]}, 128)
batch 873: ({'logprob': [40.67208480834961, 9.0]}, 128)
batch 874: ({'logprob': [45.19948196411133, 11.0]}, 128)
batch 875: ({'logprob': [50.76834487915039, 13.0]}, 128)
batch 876: ({'logprob': [63.98878479003906, 18.0]}, 128)
batch 877: ({'logprob': [45.732704162597656, 11.0]}, 128)
batch 878: ({'logprob': [61.96585464477539, 17.0]}, 128)
batch 879: ({'logprob': [73.63700866699219, 21.0]}, 128)
batch 880: ({'logprob': [50.796226501464844, 13.0]}, 128)
batch 881: ({'logprob': [28.960975646972656, 5.0]}, 128)
batch 882: ({'logprob': [54.89530944824219, 14.0]}, 128)
batch 883: ({'logprob': [61.936283111572266, 17.0]}, 128)
batch 884: ({'logprob': [51.30408477783203, 13.0]}, 128)
batch 885: ({'logprob': [52.34947967529297, 13.0]}, 128)
batch 886: ({'logprob': [62.48479080200195, 17.0]}, 128)

======================Test output======================
logprob:  0.416400, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957540e-03 [2.809589e-09] 
Layer 'conv1' biases: 4.376337e-07 [9.799875e-11] 
Layer 'conv2' weights[0]: 7.944709e-03 [2.975186e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.170963e-10] 
Layer 'conv3' weights[0]: 7.942874e-03 [2.823460e-09] 
Layer 'conv3' biases: 3.691666e-06 [1.547977e-09] 
Layer 'conv4' weights[0]: 7.975552e-03 [2.783676e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.284024e-08] 
Layer 'conv5' weights[0]: 7.974302e-03 [7.649302e-08] 
Layer 'conv5' biases: 9.999892e-01 [8.213966e-08] 
Layer 'fc6' weights[0]: 7.570842e-03 [6.266093e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.379986e-09] 
Layer 'fc7' weights[0]: 6.802987e-03 [9.453858e-08] 
Layer 'fc7' biases: 9.998533e-01 [8.174592e-08] 
Layer 'fc8' weights[0]: 1.271930e-03 [2.863827e-06] 
Layer 'fc8' biases: 8.259488e-02 [1.671938e-05] 
Train error last 870 batches: 0.435170
-------------------------------------------------------
Not saving because 0.416400 > 0.415638 (32.630: -0.00%)
======================================================= (12.061 sec)
33.461... logprob:  0.460195, 0.125000 (1.434 sec)
33.462... logprob:  0.472045, 0.125000 (1.445 sec)
33.463... logprob:  0.420758, 0.109375 (1.471 sec)
33.464... logprob:  0.482850, 0.132812 (1.448 sec)
33.465... logprob:  0.421058, 0.109375 (1.456 sec)
33.466... logprob:  0.318114, 0.070312 (1.459 sec)
33.467... logprob:  0.413804, 0.109375 (1.453 sec)
33.468... logprob:  0.394242, 0.101562 (1.440 sec)
33.469... logprob:  0.334825, 0.078125 (1.430 sec)
33.470... logprob:  0.400119, 0.101562 (1.427 sec)
33.471... logprob:  0.529084, 0.148438 (1.444 sec)
33.472... logprob:  0.409952, 0.109375 (1.457 sec)
33.473... logprob:  0.375525, 0.093750 (1.465 sec)
33.474... logprob:  0.465416, 0.125000 (1.452 sec)
33.475... logprob:  0.503723, 0.140625 (1.451 sec)
33.476... logprob:  0.510030, 0.140625 (1.471 sec)
33.477... logprob:  0.334707, 0.078125 (1.439 sec)
33.478... logprob:  0.464205, 0.125000 (1.426 sec)
33.479... logprob:  0.305782, 0.070312 (1.434 sec)
33.480... logprob:  0.443495, 0.117188 (1.439 sec)
33.481... logprob:  0.547826, 0.156250 (1.439 sec)
33.482... logprob:  0.443122, 0.117188 (1.475 sec)
33.483... logprob:  0.502739, 0.140625 (1.450 sec)
33.484... logprob:  0.485336, 0.132812 (1.437 sec)
33.485... logprob:  0.408864, 0.109375 (1.489 sec)
33.486... logprob:  0.361153, 0.085938 (1.440 sec)
33.487... logprob:  0.522739, 0.148438 (1.433 sec)
33.488... logprob:  0.424649, 0.109375 (1.434 sec)
33.489... logprob:  0.415769, 0.109375 (1.439 sec)
33.490... logprob:  0.440680, 0.117188 (1.432 sec)
33.491... logprob:  0.313551, 0.070312 (1.486 sec)
33.492... logprob:  0.459499, 0.125000 (1.447 sec)
33.493... logprob:  0.521749, 0.148438 (1.440 sec)
33.494... logprob:  0.450335, 0.125000 (1.487 sec)
33.495... logprob:  0.380728, 0.093750 (1.433 sec)
33.496... logprob:  0.550100, 0.156250 (1.432 sec)
33.497... logprob:  0.466845, 0.125000 (1.440 sec)
33.498... logprob:  0.476170, 0.132812 (1.430 sec)
33.499... logprob:  0.456206, 0.125000 (1.435 sec)
33.500... logprob:  0.355194, 0.085938 (1.489 sec)
33.501... logprob:  0.339141, 0.078125 (1.436 sec)
33.502... logprob:  0.459582, 0.125000 (1.443 sec)
33.503... logprob:  0.400655, 0.101562 (1.486 sec)
33.504... logprob:  0.487254, 0.132812 (1.436 sec)
33.505... logprob:  0.570746, 0.164062 (1.440 sec)
33.506... logprob:  0.479685, 0.132812 (1.433 sec)
33.507... logprob:  0.384991, 0.093750 (1.428 sec)
33.508... logprob:  0.374623, 0.093750 (1.434 sec)
33.509... logprob:  0.322917, 0.070312 (1.482 sec)
33.510... logprob:  0.390445, 0.101562 (1.446 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.800010681152344, 10.0]}, 128)
batch 872: ({'logprob': [66.5860824584961, 19.0]}, 128)
batch 873: ({'logprob': [40.54524612426758, 9.0]}, 128)
batch 874: ({'logprob': [45.23219299316406, 11.0]}, 128)
batch 875: ({'logprob': [50.77051544189453, 13.0]}, 128)
batch 876: ({'logprob': [64.05831146240234, 18.0]}, 128)
batch 877: ({'logprob': [45.67072677612305, 11.0]}, 128)
batch 878: ({'logprob': [61.908409118652344, 17.0]}, 128)
batch 879: ({'logprob': [73.42552947998047, 21.0]}, 128)
batch 880: ({'logprob': [50.79888916015625, 13.0]}, 128)
batch 881: ({'logprob': [28.988792419433594, 5.0]}, 128)
batch 882: ({'logprob': [54.64638137817383, 14.0]}, 128)
batch 883: ({'logprob': [61.87839126586914, 17.0]}, 128)
batch 884: ({'logprob': [51.21205520629883, 13.0]}, 128)
batch 885: ({'logprob': [52.06822967529297, 13.0]}, 128)
batch 886: ({'logprob': [62.332794189453125, 17.0]}, 128)

======================Test output======================
logprob:  0.415978, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957498e-03 [4.790609e-09] 
Layer 'conv1' biases: 4.384502e-07 [1.659907e-10] 
Layer 'conv2' weights[0]: 7.944666e-03 [3.400157e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.765287e-10] 
Layer 'conv3' weights[0]: 7.942837e-03 [3.178794e-09] 
Layer 'conv3' biases: 3.699770e-06 [1.851665e-09] 
Layer 'conv4' weights[0]: 7.975510e-03 [3.277760e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.601982e-08] 
Layer 'conv5' weights[0]: 7.974265e-03 [1.013345e-07] 
Layer 'conv5' biases: 9.999890e-01 [1.086610e-07] 
Layer 'fc6' weights[0]: 7.570803e-03 [8.299089e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.421012e-09] 
Layer 'fc7' weights[0]: 6.801256e-03 [1.584640e-07] 
Layer 'fc7' biases: 9.998531e-01 [1.477144e-07] 
Layer 'fc8' weights[0]: 1.269366e-03 [5.855965e-06] 
Layer 'fc8' biases: 8.268424e-02 [4.130377e-05] 
Train error last 870 batches: 0.435170
-------------------------------------------------------
Not saving because 0.415978 > 0.415638 (32.630: -0.00%)
======================================================= (12.065 sec)
33.511... logprob:  0.410032, 0.109375 (1.464 sec)
33.512... logprob:  0.470707, 0.125000 (1.476 sec)
33.513... logprob:  0.324956, 0.078125 (1.448 sec)
33.514... logprob:  0.406271, 0.101562 (1.443 sec)
33.515... logprob:  0.455419, 0.125000 (1.427 sec)
33.516... logprob:  0.400206, 0.109375 (1.433 sec)
33.517... logprob:  0.627633, 0.179688 (1.442 sec)
33.518... logprob:  0.437620, 0.117188 (1.466 sec)
33.519... logprob:  0.516124, 0.140625 (1.460 sec)
33.520... logprob:  0.409637, 0.109375 (1.460 sec)
33.521... logprob:  0.427395, 0.109375 (1.448 sec)
33.522... logprob:  0.533209, 0.156250 (1.466 sec)
33.523... logprob:  0.331382, 0.078125 (1.441 sec)
33.524... logprob:  0.437111, 0.117188 (1.427 sec)
33.525... logprob:  0.425829, 0.109375 (1.429 sec)
33.526... logprob:  0.351540, 0.078125 (1.442 sec)
33.527... logprob:  0.504594, 0.140625 (1.441 sec)
33.528... logprob:  0.440436, 0.117188 (1.470 sec)
33.529... logprob:  0.352996, 0.085938 (1.453 sec)
33.530... logprob:  0.440258, 0.117188 (1.444 sec)
33.531... logprob:  0.439931, 0.117188 (1.478 sec)
33.532... logprob:  0.467280, 0.125000 (1.436 sec)
33.533... logprob:  0.560176, 0.164062 (1.427 sec)
33.534... logprob:  0.326005, 0.078125 (1.440 sec)
33.535... logprob:  0.551326, 0.156250 (1.438 sec)
33.536... logprob:  0.507208, 0.140625 (1.431 sec)
33.537... logprob:  0.509964, 0.140625 (1.480 sec)
33.538... logprob:  0.486069, 0.132812 (1.447 sec)
33.539... logprob:  0.295987, 0.062500 (1.437 sec)
33.540... logprob:  0.447177, 0.117188 (1.484 sec)
33.541... logprob:  0.388750, 0.101562 (1.438 sec)
33.542... logprob:  0.411205, 0.109375 (1.430 sec)
33.543... logprob:  0.233129, 0.039062 (1.437 sec)
33.544... logprob:  0.317913, 0.070312 (1.435 sec)
33.545... logprob:  0.348793, 0.085938 (1.435 sec)
33.546... logprob:  0.368263, 0.093750 (1.489 sec)
33.547... logprob:  0.439959, 0.117188 (1.436 sec)
33.548... logprob:  0.452751, 0.125000 (1.438 sec)
33.549... logprob:  0.490305, 0.132812 (1.489 sec)
33.550... logprob:  0.367575, 0.093750 (1.430 sec)
33.551... logprob:  0.441563, 0.117188 (1.439 sec)
33.552... logprob:  0.471217, 0.125000 (1.436 sec)
33.553... logprob:  0.349452, 0.085938 (1.431 sec)
33.554... logprob:  0.507039, 0.140625 (1.434 sec)
33.555... logprob:  0.421408, 0.109375 (1.485 sec)
33.556... logprob:  0.355726, 0.085938 (1.440 sec)
33.557... logprob:  0.396315, 0.101562 (1.447 sec)
33.558... logprob:  0.382984, 0.101562 (1.478 sec)
33.559... logprob:  0.441680, 0.125000 (1.437 sec)
33.560... logprob:  0.334919, 0.078125 (1.446 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.6280403137207, 10.0]}, 128)
batch 872: ({'logprob': [66.23204803466797, 19.0]}, 128)
batch 873: ({'logprob': [41.069034576416016, 9.0]}, 128)
batch 874: ({'logprob': [45.34467697143555, 11.0]}, 128)
batch 875: ({'logprob': [50.86552047729492, 13.0]}, 128)
batch 876: ({'logprob': [63.811092376708984, 18.0]}, 128)
batch 877: ({'logprob': [45.97972869873047, 11.0]}, 128)
batch 878: ({'logprob': [61.96529006958008, 17.0]}, 128)
batch 879: ({'logprob': [73.63948059082031, 21.0]}, 128)
batch 880: ({'logprob': [50.89301300048828, 13.0]}, 128)
batch 881: ({'logprob': [29.35467529296875, 5.0]}, 128)
batch 882: ({'logprob': [55.2209358215332, 14.0]}, 128)
batch 883: ({'logprob': [61.93571472167969, 17.0]}, 128)
batch 884: ({'logprob': [51.5017204284668, 13.0]}, 128)
batch 885: ({'logprob': [52.750179290771484, 13.0]}, 128)
batch 886: ({'logprob': [62.58525848388672, 17.0]}, 128)

======================Test output======================
logprob:  0.417371, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957469e-03 [3.967765e-09] 
Layer 'conv1' biases: 4.396337e-07 [1.363845e-10] 
Layer 'conv2' weights[0]: 7.944627e-03 [2.791847e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.481338e-10] 
Layer 'conv3' weights[0]: 7.942795e-03 [2.828328e-09] 
Layer 'conv3' biases: 3.710533e-06 [1.540251e-09] 
Layer 'conv4' weights[0]: 7.975468e-03 [2.843542e-09] 
Layer 'conv4' biases: 9.999992e-01 [1.309535e-08] 
Layer 'conv5' weights[0]: 7.974228e-03 [8.350548e-08] 
Layer 'conv5' biases: 9.999891e-01 [8.958393e-08] 
Layer 'fc6' weights[0]: 7.570766e-03 [6.837000e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.955391e-09] 
Layer 'fc7' weights[0]: 6.799478e-03 [4.465818e-08] 
Layer 'fc7' biases: 9.998534e-01 [2.358615e-08] 
Layer 'fc8' weights[0]: 1.263176e-03 [5.435194e-06] 
Layer 'fc8' biases: 8.275579e-02 [3.413149e-05] 
Train error last 870 batches: 0.435169
-------------------------------------------------------
Not saving because 0.417371 > 0.415638 (32.630: -0.00%)
======================================================= (12.070 sec)
33.561... logprob:  0.411772, 0.109375 (1.442 sec)
33.562... logprob:  0.503180, 0.140625 (1.434 sec)
33.563... logprob:  0.373718, 0.093750 (1.437 sec)
33.564... logprob:  0.468516, 0.132812 (1.470 sec)
33.565... logprob:  0.611209, 0.187500 (1.451 sec)
33.566... logprob:  0.374848, 0.093750 (1.453 sec)
33.567... logprob:  0.423257, 0.109375 (1.457 sec)
33.568... logprob:  0.496313, 0.140625 (1.460 sec)
33.569... logprob:  0.507630, 0.140625 (1.437 sec)
33.570... logprob:  0.543815, 0.164062 (1.429 sec)
33.571... logprob:  0.454889, 0.125000 (1.430 sec)
33.572... logprob:  0.501328, 0.140625 (1.444 sec)
33.573... logprob:  0.512587, 0.148438 (1.448 sec)
33.574... logprob:  0.427988, 0.109375 (1.463 sec)
33.575... logprob:  0.343320, 0.078125 (1.453 sec)
33.576... logprob:  0.427336, 0.109375 (1.447 sec)
33.577... logprob:  0.460770, 0.125000 (1.475 sec)
33.578... logprob:  0.336847, 0.078125 (1.439 sec)
33.579... logprob:  0.442079, 0.117188 (1.424 sec)
33.580... logprob:  0.546530, 0.156250 (1.440 sec)
33.581... logprob:  0.530509, 0.156250 (1.435 sec)
33.582... logprob:  0.437769, 0.125000 (1.437 sec)
33.583... logprob:  0.592279, 0.171875 (1.485 sec)
33.584... logprob:  0.468048, 0.132812 (1.450 sec)
33.585... logprob:  0.349772, 0.085938 (1.432 sec)
33.586... logprob:  0.313040, 0.070312 (1.492 sec)
33.587... logprob:  0.404293, 0.101562 (1.434 sec)
33.588... logprob:  0.418649, 0.117188 (1.428 sec)
33.589... logprob:  0.361114, 0.093750 (1.440 sec)
33.590... logprob:  0.524798, 0.148438 (1.437 sec)
33.591... logprob:  0.397442, 0.101562 (1.431 sec)
33.592... logprob:  0.455690, 0.125000 (1.484 sec)
33.593... logprob:  0.467415, 0.125000 (1.451 sec)
33.594... logprob:  0.352809, 0.085938 (1.438 sec)
33.595... logprob:  0.428660, 0.109375 (1.488 sec)
33.596... logprob:  0.461625, 0.125000 (1.428 sec)
33.597... logprob:  0.397418, 0.101562 (1.439 sec)
33.598... logprob:  0.397214, 0.101562 (1.438 sec)
33.599... logprob:  0.313594, 0.070312 (1.427 sec)
33.600... logprob:  0.340873, 0.085938 (1.440 sec)
33.601... logprob:  0.402165, 0.101562 (1.485 sec)
33.602... logprob:  0.289944, 0.062500 (1.437 sec)
33.603... logprob:  0.267274, 0.054688 (1.445 sec)
33.604... logprob:  0.407531, 0.101562 (1.480 sec)
33.605... logprob:  0.563199, 0.148438 (1.438 sec)
33.606... logprob:  0.295947, 0.070312 (1.437 sec)
33.607... logprob:  0.504623, 0.132812 (1.437 sec)
33.608... logprob:  0.361926, 0.085938 (1.422 sec)
33.609... logprob:  0.357083, 0.085938 (1.442 sec)
33.610... logprob:  0.493245, 0.132812 (1.473 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.09015655517578, 10.0]}, 128)
batch 872: ({'logprob': [68.11485290527344, 19.0]}, 128)
batch 873: ({'logprob': [39.54385757446289, 9.0]}, 128)
batch 874: ({'logprob': [44.75271987915039, 11.0]}, 128)
batch 875: ({'logprob': [50.78436279296875, 13.0]}, 128)
batch 876: ({'logprob': [65.3348388671875, 18.0]}, 128)
batch 877: ({'logprob': [45.176334381103516, 11.0]}, 128)
batch 878: ({'logprob': [62.91527557373047, 17.0]}, 128)
batch 879: ({'logprob': [75.41161346435547, 21.0]}, 128)
batch 880: ({'logprob': [50.81403732299805, 13.0]}, 128)
batch 881: ({'logprob': [27.005659103393555, 5.0]}, 128)
batch 882: ({'logprob': [54.87910842895508, 14.0]}, 128)
batch 883: ({'logprob': [62.884212493896484, 17.0]}, 128)
batch 884: ({'logprob': [51.21799850463867, 13.0]}, 128)
batch 885: ({'logprob': [52.04771041870117, 13.0]}, 128)
batch 886: ({'logprob': [63.32887268066406, 17.0]}, 128)

======================Test output======================
logprob:  0.417628, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957433e-03 [4.367046e-09] 
Layer 'conv1' biases: 4.408156e-07 [1.694866e-10] 
Layer 'conv2' weights[0]: 7.944581e-03 [3.999742e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.189876e-10] 
Layer 'conv3' weights[0]: 7.942760e-03 [3.720725e-09] 
Layer 'conv3' biases: 3.718819e-06 [2.379327e-09] 
Layer 'conv4' weights[0]: 7.975426e-03 [3.842485e-09] 
Layer 'conv4' biases: 9.999991e-01 [2.028951e-08] 
Layer 'conv5' weights[0]: 7.974189e-03 [1.290657e-07] 
Layer 'conv5' biases: 9.999891e-01 [1.382492e-07] 
Layer 'fc6' weights[0]: 7.570725e-03 [1.055349e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.080652e-08] 
Layer 'fc7' weights[0]: 6.797720e-03 [2.392068e-07] 
Layer 'fc7' biases: 9.998543e-01 [2.298331e-07] 
Layer 'fc8' weights[0]: 1.316003e-03 [1.332266e-05] 
Layer 'fc8' biases: 8.325068e-02 [8.509496e-05] 
Train error last 870 batches: 0.435169
-------------------------------------------------------
Not saving because 0.417628 > 0.415638 (32.630: -0.00%)
======================================================= (12.056 sec)
33.611... logprob:  0.510297, 0.140625 (1.450 sec)
33.612... logprob:  0.448577, 0.117188 (1.455 sec)
33.613... logprob:  0.279228, 0.062500 (1.464 sec)
33.614... logprob:  0.503582, 0.140625 (1.449 sec)
33.615... logprob:  0.350712, 0.085938 (1.438 sec)
33.616... logprob:  0.414982, 0.109375 (1.432 sec)
33.617... logprob:  0.417788, 0.109375 (1.428 sec)
33.618... logprob:  0.547124, 0.156250 (1.445 sec)
33.619... logprob:  0.506169, 0.140625 (1.460 sec)
33.620... logprob:  0.539728, 0.156250 (1.457 sec)
33.621... logprob:  0.363476, 0.085938 (1.458 sec)
33.622... logprob:  0.364591, 0.085938 (1.449 sec)
33.623... logprob:  0.423095, 0.109375 (1.472 sec)
33.624... logprob:  0.382489, 0.093750 (1.436 sec)
33.625... logprob:  0.440973, 0.117188 (1.430 sec)
33.626... logprob:  0.438333, 0.117188 (1.442 sec)
33.627... logprob:  0.435811, 0.117188 (1.443 sec)
33.628... logprob:  0.465002, 0.125000 (1.441 sec)
33.629... logprob:  0.372192, 0.093750 (1.477 sec)
33.630... logprob:  0.422391, 0.109375 (1.453 sec)
33.631... logprob:  0.638143, 0.187500 (1.442 sec)
33.632... logprob:  0.399130, 0.101562 (1.484 sec)
33.633... logprob:  0.376145, 0.093750 (1.432 sec)
33.634... logprob:  0.659941, 0.195312 (1.435 sec)
33.635... logprob:  0.374126, 0.093750 (1.434 sec)
33.636... logprob:  0.480268, 0.132812 (1.437 sec)
33.637... logprob:  0.330691, 0.078125 (1.433 sec)
33.638... logprob:  0.515717, 0.140625 (1.485 sec)
33.639... logprob:  0.417999, 0.109375 (1.440 sec)
33.640... logprob:  0.528767, 0.148438 (1.440 sec)
33.641... logprob:  0.410387, 0.109375 (1.486 sec)
33.642... logprob:  0.500933, 0.140625 (1.434 sec)
33.643... logprob:  0.623404, 0.187500 (1.436 sec)
33.644... logprob:  0.320798, 0.070312 (1.433 sec)
33.645... logprob:  0.414431, 0.109375 (1.435 sec)
33.646... logprob:  0.385511, 0.093750 (1.434 sec)
33.647... logprob:  0.456804, 0.125000 (1.492 sec)
33.648... logprob:  0.491289, 0.140625 (1.437 sec)
33.649... logprob:  0.370364, 0.093750 (1.446 sec)
33.650... logprob:  0.414060, 0.109375 (1.482 sec)
33.651... logprob:  0.397439, 0.101562 (1.431 sec)
33.652... logprob:  0.506995, 0.140625 (1.443 sec)
33.653... logprob:  0.547597, 0.156250 (1.434 sec)
33.654... logprob:  0.495965, 0.140625 (1.428 sec)
33.655... logprob:  0.436171, 0.117188 (1.437 sec)
33.656... logprob:  0.416728, 0.109375 (1.480 sec)
33.657... logprob:  0.448982, 0.117188 (1.441 sec)
33.658... logprob:  0.345928, 0.085938 (1.456 sec)
33.659... logprob:  0.464258, 0.125000 (1.466 sec)
33.660... logprob:  0.446083, 0.125000 (1.449 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.71765899658203, 10.0]}, 128)
batch 872: ({'logprob': [66.21813201904297, 19.0]}, 128)
batch 873: ({'logprob': [41.06290817260742, 9.0]}, 128)
batch 874: ({'logprob': [45.37431716918945, 11.0]}, 128)
batch 875: ({'logprob': [50.86857223510742, 13.0]}, 128)
batch 876: ({'logprob': [63.79505920410156, 18.0]}, 128)
batch 877: ({'logprob': [45.97842025756836, 11.0]}, 128)
batch 878: ({'logprob': [61.91565704345703, 17.0]}, 128)
batch 879: ({'logprob': [73.50594329833984, 21.0]}, 128)
batch 880: ({'logprob': [50.89623260498047, 13.0]}, 128)
batch 881: ({'logprob': [29.432527542114258, 5.0]}, 128)
batch 882: ({'logprob': [55.13303756713867, 14.0]}, 128)
batch 883: ({'logprob': [61.88590621948242, 17.0]}, 128)
batch 884: ({'logprob': [51.47369384765625, 13.0]}, 128)
batch 885: ({'logprob': [52.65961837768555, 13.0]}, 128)
batch 886: ({'logprob': [62.50437927246094, 17.0]}, 128)

======================Test output======================
logprob:  0.417198, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957404e-03 [2.512497e-09] 
Layer 'conv1' biases: 4.418216e-07 [3.429011e-11] 
Layer 'conv2' weights[0]: 7.944537e-03 [1.526798e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.415440e-10] 
Layer 'conv3' weights[0]: 7.942727e-03 [1.119908e-09] 
Layer 'conv3' biases: 3.728166e-06 [3.834884e-10] 
Layer 'conv4' weights[0]: 7.975392e-03 [1.083226e-09] 
Layer 'conv4' biases: 9.999992e-01 [2.125814e-09] 
Layer 'conv5' weights[0]: 7.974145e-03 [9.387859e-09] 
Layer 'conv5' biases: 9.999891e-01 [9.621020e-09] 
Layer 'fc6' weights[0]: 7.570686e-03 [1.026998e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.604656e-10] 
Layer 'fc7' weights[0]: 6.795987e-03 [4.420171e-08] 
Layer 'fc7' biases: 9.998530e-01 [2.311822e-08] 
Layer 'fc8' weights[0]: 1.266483e-03 [4.505421e-06] 
Layer 'fc8' biases: 8.301380e-02 [3.080710e-05] 
Train error last 870 batches: 0.435169
-------------------------------------------------------
Not saving because 0.417198 > 0.415638 (32.630: -0.00%)
======================================================= (12.176 sec)
33.661... logprob:  0.378375, 0.093750 (1.454 sec)
33.662... logprob:  0.469500, 0.132812 (1.440 sec)
33.663... logprob:  0.310813, 0.070312 (1.426 sec)
33.664... logprob:  0.285315, 0.062500 (1.440 sec)
33.665... logprob:  0.401636, 0.101562 (1.458 sec)
33.666... logprob:  0.442012, 0.117188 (1.461 sec)
33.667... logprob:  0.564182, 0.164062 (1.450 sec)
33.668... logprob:  0.497830, 0.140625 (1.454 sec)
33.669... logprob:  0.432865, 0.109375 (1.464 sec)
33.670... logprob:  0.362315, 0.085938 (1.442 sec)
33.671... logprob:  0.360879, 0.093750 (1.427 sec)
33.672... logprob:  0.441830, 0.117188 (1.432 sec)
33.673... logprob:  0.436222, 0.117188 (1.442 sec)
33.674... logprob:  0.446619, 0.117188 (1.442 sec)
33.675... logprob:  0.356690, 0.093750 (1.466 sec)
33.676... logprob:  0.450200, 0.125000 (1.456 sec)
33.677... logprob:  0.471006, 0.125000 (1.440 sec)
33.678... logprob:  0.465665, 0.125000 (1.485 sec)
33.679... logprob:  0.454862, 0.125000 (1.433 sec)
33.680... logprob:  0.351627, 0.078125 (1.432 sec)
33.681... logprob:  0.373838, 0.093750 (1.433 sec)
33.682... logprob:  0.340450, 0.078125 (1.439 sec)
33.683... logprob:  0.411627, 0.109375 (1.430 sec)
33.684... logprob:  0.357730, 0.085938 (1.484 sec)
33.685... logprob:  0.286306, 0.054688 (1.444 sec)
33.686... logprob:  0.318898, 0.070312 (1.438 sec)
33.687... logprob:  0.281885, 0.062500 (1.484 sec)
33.688... logprob:  0.323170, 0.078125 (1.439 sec)
33.689... logprob:  0.470765, 0.125000 (1.427 sec)
33.690... logprob:  0.527152, 0.140625 (1.442 sec)
33.691... logprob:  0.515919, 0.140625 (1.431 sec)
33.692... logprob:  0.384617, 0.101562 (1.436 sec)
33.693... logprob:  0.455337, 0.125000 (1.484 sec)
33.694... logprob:  0.330977, 0.078125 (1.441 sec)
33.695... logprob:  0.356971, 0.085938 (1.441 sec)
33.696... logprob:  0.539414, 0.148438 (1.483 sec)
33.697... logprob:  0.465850, 0.125000 (1.433 sec)
33.698... logprob:  0.549231, 0.156250 (1.437 sec)
33.699... logprob:  0.459653, 0.125000 (1.438 sec)
33.700... logprob:  0.433743, 0.117188 (1.435 sec)
33.701... logprob:  0.422797, 0.109375 (1.437 sec)
33.702... logprob:  0.521621, 0.148438 (1.482 sec)
33.703... logprob:  0.404761, 0.101562 (1.442 sec)
33.704... logprob:  0.405772, 0.101562 (1.446 sec)
33.705... logprob:  0.420006, 0.109375 (1.478 sec)
33.706... logprob:  0.468038, 0.125000 (1.437 sec)
33.707... logprob:  0.485295, 0.132812 (1.443 sec)
33.708... logprob:  0.417286, 0.109375 (1.438 sec)
33.709... logprob:  0.422747, 0.109375 (1.428 sec)
33.710... logprob:  0.601825, 0.179688 (1.437 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.47338104248047, 10.0]}, 128)
batch 872: ({'logprob': [66.11343383789062, 19.0]}, 128)
batch 873: ({'logprob': [41.34543228149414, 9.0]}, 128)
batch 874: ({'logprob': [45.77741241455078, 11.0]}, 128)
batch 875: ({'logprob': [51.06245422363281, 13.0]}, 128)
batch 876: ({'logprob': [63.712303161621094, 18.0]}, 128)
batch 877: ({'logprob': [46.21715545654297, 11.0]}, 128)
batch 878: ({'logprob': [61.69070053100586, 17.0]}, 128)
batch 879: ({'logprob': [72.69837188720703, 21.0]}, 128)
batch 880: ({'logprob': [51.090126037597656, 13.0]}, 128)
batch 881: ({'logprob': [30.299413681030273, 5.0]}, 128)
batch 882: ({'logprob': [54.809444427490234, 14.0]}, 128)
batch 883: ({'logprob': [61.661014556884766, 17.0]}, 128)
batch 884: ({'logprob': [51.50136947631836, 13.0]}, 128)
batch 885: ({'logprob': [52.3576774597168, 13.0]}, 128)
batch 886: ({'logprob': [62.11375045776367, 17.0]}, 128)

======================Test output======================
logprob:  0.417443, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957372e-03 [3.666496e-09] 
Layer 'conv1' biases: 4.426661e-07 [5.494586e-11] 
Layer 'conv2' weights[0]: 7.944501e-03 [2.462542e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.473118e-10] 
Layer 'conv3' weights[0]: 7.942694e-03 [2.032911e-09] 
Layer 'conv3' biases: 3.734720e-06 [1.195650e-09] 
Layer 'conv4' weights[0]: 7.975349e-03 [2.097302e-09] 
Layer 'conv4' biases: 9.999991e-01 [9.611220e-09] 
Layer 'conv5' weights[0]: 7.974099e-03 [6.034587e-08] 
Layer 'conv5' biases: 9.999890e-01 [6.478177e-08] 
Layer 'fc6' weights[0]: 7.570648e-03 [4.995439e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.017323e-09] 
Layer 'fc7' weights[0]: 6.794241e-03 [1.070895e-07] 
Layer 'fc7' biases: 9.998525e-01 [9.357002e-08] 
Layer 'fc8' weights[0]: 1.251541e-03 [3.341073e-06] 
Layer 'fc8' biases: 8.310935e-02 [2.970941e-05] 
Train error last 870 batches: 0.435168
-------------------------------------------------------
Not saving because 0.417443 > 0.415638 (32.630: -0.00%)
======================================================= (12.053 sec)
33.711... logprob:  0.469453, 0.125000 (1.478 sec)
33.712... logprob:  0.341191, 0.078125 (1.460 sec)
33.713... logprob:  0.586084, 0.179688 (1.459 sec)
33.714... logprob:  0.466207, 0.125000 (1.461 sec)
33.715... logprob:  0.417229, 0.109375 (1.457 sec)
33.716... logprob:  0.335612, 0.078125 (1.435 sec)
33.717... logprob:  0.429756, 0.117188 (1.427 sec)
33.718... logprob:  0.490265, 0.132812 (1.435 sec)
33.719... logprob:  0.406172, 0.109375 (1.438 sec)
33.720... logprob:  0.433218, 0.117188 (1.453 sec)
33.721... logprob:  0.451602, 0.117188 (1.460 sec)
33.722... logprob:  0.537084, 0.156250 (1.458 sec)
33.723... logprob:  0.416529, 0.109375 (1.454 sec)
33.724... logprob:  0.412753, 0.109375 (1.479 sec)
33.725... logprob:  0.494948, 0.140625 (1.437 sec)
33.726... logprob:  0.338307, 0.085938 (1.424 sec)
33.727... logprob:  0.393128, 0.101562 (1.438 sec)
33.728... logprob:  0.421151, 0.109375 (1.444 sec)
33.729... logprob:  0.387473, 0.093750 (1.435 sec)
33.730... logprob:  0.566001, 0.164062 (1.477 sec)
33.731... logprob:  0.450451, 0.125000 (1.450 sec)
33.732... logprob:  0.311333, 0.070312 (1.443 sec)
33.733... logprob:  0.556432, 0.156250 (1.489 sec)
33.734... logprob:  0.340250, 0.078125 (1.436 sec)
33.735... logprob:  0.527356, 0.148438 (1.429 sec)
33.736... logprob:  0.642402, 0.187500 (1.441 sec)
33.737... logprob:  0.516057, 0.148438 (1.431 sec)
33.738... logprob:  0.459369, 0.125000 (1.438 sec)
33.739... logprob:  0.477780, 0.132812 (1.490 sec)
33.740... logprob:  0.339644, 0.078125 (1.439 sec)
33.741... logprob:  0.393489, 0.101562 (1.438 sec)
33.742... logprob:  0.419674, 0.109375 (1.488 sec)
33.743... logprob:  0.364909, 0.085938 (1.432 sec)
33.744... logprob:  0.519099, 0.148438 (1.435 sec)
33.745... logprob:  0.478114, 0.132812 (1.436 sec)
33.746... logprob:  0.440542, 0.117188 (1.435 sec)
33.747... logprob:  0.425598, 0.109375 (1.435 sec)
33.748... logprob:  0.378184, 0.093750 (1.489 sec)
33.749... logprob:  0.420793, 0.109375 (1.432 sec)
33.750... logprob:  0.512711, 0.140625 (1.449 sec)
33.751... logprob:  0.263784, 0.054688 (1.476 sec)
33.752... logprob:  0.522494, 0.140625 (1.434 sec)
33.753... logprob:  0.441119, 0.117188 (1.439 sec)
33.754... logprob:  0.468190, 0.132812 (1.439 sec)
33.755... logprob:  0.507021, 0.140625 (1.427 sec)
33.756... logprob:  0.440841, 0.117188 (1.435 sec)
33.757... logprob:  0.552536, 0.156250 (1.474 sec)
33.758... logprob:  0.393508, 0.101562 (1.448 sec)
33.759... logprob:  0.459705, 0.125000 (1.457 sec)
33.760... logprob:  0.485613, 0.132812 (1.463 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.54456329345703, 10.0]}, 128)
batch 872: ({'logprob': [66.11460876464844, 19.0]}, 128)
batch 873: ({'logprob': [41.37617111206055, 9.0]}, 128)
batch 874: ({'logprob': [45.81904220581055, 11.0]}, 128)
batch 875: ({'logprob': [51.08695602416992, 13.0]}, 128)
batch 876: ({'logprob': [63.71523666381836, 18.0]}, 128)
batch 877: ({'logprob': [46.244937896728516, 11.0]}, 128)
batch 878: ({'logprob': [61.68120574951172, 17.0]}, 128)
batch 879: ({'logprob': [72.64075469970703, 21.0]}, 128)
batch 880: ({'logprob': [51.11481857299805, 13.0]}, 128)
batch 881: ({'logprob': [30.378280639648438, 5.0]}, 128)
batch 882: ({'logprob': [54.79051208496094, 14.0]}, 128)
batch 883: ({'logprob': [61.65130615234375, 17.0]}, 128)
batch 884: ({'logprob': [51.51188659667969, 13.0]}, 128)
batch 885: ({'logprob': [52.340213775634766, 13.0]}, 128)
batch 886: ({'logprob': [62.090206146240234, 17.0]}, 128)

======================Test output======================
logprob:  0.417530, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957328e-03 [2.946214e-09] 
Layer 'conv1' biases: 4.437984e-07 [4.892228e-11] 
Layer 'conv2' weights[0]: 7.944463e-03 [2.082128e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.740473e-10] 
Layer 'conv3' weights[0]: 7.942653e-03 [1.740000e-09] 
Layer 'conv3' biases: 3.746630e-06 [8.868775e-10] 
Layer 'conv4' weights[0]: 7.975316e-03 [1.731515e-09] 
Layer 'conv4' biases: 9.999991e-01 [7.087654e-09] 
Layer 'conv5' weights[0]: 7.974069e-03 [4.526410e-08] 
Layer 'conv5' biases: 9.999896e-01 [4.851255e-08] 
Layer 'fc6' weights[0]: 7.570610e-03 [3.758771e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.756442e-09] 
Layer 'fc7' weights[0]: 6.792529e-03 [2.243651e-07] 
Layer 'fc7' biases: 9.998524e-01 [2.150348e-07] 
Layer 'fc8' weights[0]: 1.251229e-03 [7.602667e-06] 
Layer 'fc8' biases: 8.322569e-02 [5.055381e-05] 
Train error last 870 batches: 0.435168
-------------------------------------------------------
Not saving because 0.417530 > 0.415638 (32.630: -0.00%)
======================================================= (12.050 sec)
33.761... logprob:  0.418073, 0.109375 (1.451 sec)
33.762... logprob:  0.516102, 0.148438 (1.452 sec)
33.763... logprob:  0.559083, 0.164062 (1.431 sec)
33.764... logprob:  0.503261, 0.140625 (1.431 sec)
33.765... logprob:  0.311487, 0.062500 (1.436 sec)
33.766... logprob:  0.482174, 0.132812 (1.460 sec)
33.767... logprob:  0.371031, 0.085938 (1.456 sec)
33.768... logprob:  0.432625, 0.117188 (1.468 sec)
33.769... logprob:  0.490758, 0.140625 (1.477 sec)
33.770... logprob:  0.403051, 0.101562 (1.483 sec)
33.771... logprob:  0.549274, 0.156250 (1.457 sec)
33.772... logprob:  0.414136, 0.109375 (1.451 sec)
33.773... logprob:  0.557462, 0.164062 (1.446 sec)
33.774... logprob:  0.361910, 0.085938 (1.463 sec)
33.775... logprob:  0.407437, 0.101562 (1.466 sec)
33.776... logprob:  0.433117, 0.117188 (1.476 sec)
33.777... logprob:  0.380015, 0.093750 (1.487 sec)
33.778... logprob:  0.433508, 0.117188 (1.463 sec)
33.779... logprob:  0.505254, 0.140625 (1.492 sec)
33.780... logprob:  0.385764, 0.101562 (1.454 sec)
33.781... logprob:  0.369605, 0.085938 (1.452 sec)
33.782... logprob:  0.351375, 0.085938 (1.446 sec)
33.783... logprob:  0.555552, 0.156250 (1.463 sec)
33.784... logprob:  0.440961, 0.117188 (1.456 sec)
33.785... logprob:  0.543806, 0.156250 (1.493 sec)
33.786... logprob:  0.477624, 0.132812 (1.476 sec)
33.787... logprob:  0.546650, 0.156250 (1.461 sec)
33.788... logprob:  0.563452, 0.164062 (1.497 sec)
33.789... logprob:  0.280314, 0.054688 (1.457 sec)
33.790... logprob:  0.407748, 0.101562 (1.449 sec)
33.791... logprob:  0.397720, 0.101562 (1.443 sec)
33.792... logprob:  0.360757, 0.085938 (1.467 sec)
33.793... logprob:  0.369962, 0.085938 (1.455 sec)
33.794... logprob:  0.387113, 0.093750 (1.487 sec)
33.795... logprob:  0.469681, 0.125000 (1.473 sec)
33.796... logprob:  0.423518, 0.109375 (1.459 sec)
33.797... logprob:  0.358970, 0.085938 (1.497 sec)
33.798... logprob:  0.393315, 0.101562 (1.456 sec)
33.799... logprob:  0.332604, 0.078125 (1.448 sec)
33.800... logprob:  0.371666, 0.093750 (1.454 sec)
33.801... logprob:  0.449791, 0.117188 (1.456 sec)
33.802... logprob:  0.422760, 0.109375 (1.459 sec)
33.803... logprob:  0.491204, 0.132812 (1.492 sec)
33.804... logprob:  0.349936, 0.085938 (1.466 sec)
33.805... logprob:  0.452251, 0.117188 (1.453 sec)
33.806... logprob:  0.424166, 0.109375 (1.542 sec)
33.807... logprob:  0.443480, 0.117188 (1.452 sec)
33.808... logprob:  0.462370, 0.125000 (1.451 sec)
33.809... logprob:  0.589920, 0.171875 (1.442 sec)
33.810... logprob:  0.442516, 0.117188 (1.460 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.441097259521484, 10.0]}, 128)
batch 872: ({'logprob': [66.67514038085938, 19.0]}, 128)
batch 873: ({'logprob': [40.650909423828125, 9.0]}, 128)
batch 874: ({'logprob': [45.54230499267578, 11.0]}, 128)
batch 875: ({'logprob': [50.938636779785156, 13.0]}, 128)
batch 876: ({'logprob': [64.13207244873047, 18.0]}, 128)
batch 877: ({'logprob': [45.80817413330078, 11.0]}, 128)
batch 878: ({'logprob': [61.793190002441406, 17.0]}, 128)
batch 879: ({'logprob': [72.8547134399414, 21.0]}, 128)
batch 880: ({'logprob': [50.9672966003418, 13.0]}, 128)
batch 881: ({'logprob': [29.55118179321289, 5.0]}, 128)
batch 882: ({'logprob': [54.31083679199219, 14.0]}, 128)
batch 883: ({'logprob': [61.7630500793457, 17.0]}, 128)
batch 884: ({'logprob': [51.20649337768555, 13.0]}, 128)
batch 885: ({'logprob': [51.71625900268555, 13.0]}, 128)
batch 886: ({'logprob': [62.04402160644531, 17.0]}, 128)

======================Test output======================
logprob:  0.416209, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957301e-03 [4.788030e-09] 
Layer 'conv1' biases: 4.450015e-07 [1.639510e-10] 
Layer 'conv2' weights[0]: 7.944419e-03 [4.500610e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.386890e-10] 
Layer 'conv3' weights[0]: 7.942610e-03 [4.161635e-09] 
Layer 'conv3' biases: 3.757368e-06 [2.479334e-09] 
Layer 'conv4' weights[0]: 7.975275e-03 [4.028187e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.947102e-08] 
Layer 'conv5' weights[0]: 7.974025e-03 [1.202628e-07] 
Layer 'conv5' biases: 9.999896e-01 [1.291736e-07] 
Layer 'fc6' weights[0]: 7.570569e-03 [9.885018e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.003177e-08] 
Layer 'fc7' weights[0]: 6.790784e-03 [4.053824e-07] 
Layer 'fc7' biases: 9.998524e-01 [3.959697e-07] 
Layer 'fc8' weights[0]: 1.263816e-03 [1.474385e-05] 
Layer 'fc8' biases: 8.350526e-02 [9.653694e-05] 
Train error last 870 batches: 0.435168
-------------------------------------------------------
Not saving because 0.416209 > 0.415638 (32.630: -0.00%)
======================================================= (12.039 sec)
33.811... logprob:  0.460427, 0.125000 (1.460 sec)
33.812... logprob:  0.462308, 0.125000 (1.502 sec)
33.813... logprob:  0.485948, 0.132812 (1.464 sec)
33.814... logprob:  0.477839, 0.132812 (1.453 sec)
33.815... logprob:  0.371144, 0.085938 (1.505 sec)
33.816... logprob:  0.408290, 0.101562 (1.452 sec)
33.817... logprob:  0.425698, 0.109375 (1.459 sec)
33.818... logprob:  0.560037, 0.164062 (1.446 sec)
33.819... logprob:  0.498170, 0.140625 (1.459 sec)
33.820... logprob:  0.421714, 0.109375 (1.453 sec)
33.821... logprob:  0.406778, 0.101562 (1.502 sec)
33.822... logprob:  0.441333, 0.117188 (1.457 sec)
33.823... logprob:  0.341342, 0.078125 (1.461 sec)
33.824... logprob:  0.489545, 0.132812 (1.497 sec)
33.825... logprob:  0.288697, 0.062500 (1.457 sec)
33.826... logprob:  0.375674, 0.093750 (1.453 sec)
33.827... logprob:  0.420388, 0.109375 (1.454 sec)
33.828... logprob:  0.443003, 0.117188 (1.453 sec)
33.829... logprob:  0.503498, 0.140625 (1.455 sec)
33.830... logprob:  0.441932, 0.117188 (1.510 sec)
33.831... logprob:  0.513704, 0.140625 (1.453 sec)
33.832... logprob:  0.330845, 0.078125 (1.466 sec)
33.833... logprob:  0.489075, 0.132812 (1.503 sec)
33.834... logprob:  0.433441, 0.117188 (1.457 sec)
33.835... logprob:  0.543053, 0.148438 (1.453 sec)
33.836... logprob:  0.376001, 0.093750 (1.453 sec)
33.837... logprob:  0.313744, 0.070312 (1.456 sec)
33.838... logprob:  0.437066, 0.117188 (1.453 sec)
33.839... logprob:  0.471625, 0.125000 (1.507 sec)
33.840... logprob:  0.555692, 0.156250 (1.461 sec)
33.841... logprob:  0.395886, 0.101562 (1.463 sec)
33.842... logprob:  0.497935, 0.140625 (1.494 sec)
33.843... logprob:  0.465471, 0.125000 (1.452 sec)
33.844... logprob:  0.497698, 0.140625 (1.466 sec)
33.845... logprob:  0.486698, 0.132812 (1.446 sec)
33.846... logprob:  0.468352, 0.125000 (1.452 sec)
33.847... logprob:  0.363489, 0.085938 (1.456 sec)
33.848... logprob:  0.397318, 0.101562 (1.500 sec)
33.849... logprob:  0.360742, 0.085938 (1.459 sec)
33.850... logprob:  0.479349, 0.132812 (1.466 sec)
33.851... logprob:  0.440140, 0.117188 (1.499 sec)
33.852... logprob:  0.545122, 0.156250 (1.458 sec)
33.853... logprob:  0.372118, 0.093750 (1.461 sec)
33.854... logprob:  0.307594, 0.070312 (1.448 sec)
33.855... logprob:  0.484571, 0.132812 (1.450 sec)
33.856... logprob:  0.443630, 0.117188 (1.457 sec)
33.857... logprob:  0.372236, 0.093750 (1.492 sec)
33.858... logprob:  0.396244, 0.101562 (1.465 sec)
33.859... logprob:  0.308030, 0.070312 (1.471 sec)
33.860... logprob:  0.565951, 0.156250 (1.489 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.27278518676758, 10.0]}, 128)
batch 872: ({'logprob': [67.67247009277344, 19.0]}, 128)
batch 873: ({'logprob': [39.70534133911133, 9.0]}, 128)
batch 874: ({'logprob': [44.824771881103516, 11.0]}, 128)
batch 875: ({'logprob': [50.715145111083984, 13.0]}, 128)
batch 876: ({'logprob': [64.94989776611328, 18.0]}, 128)
batch 877: ({'logprob': [45.22272491455078, 11.0]}, 128)
batch 878: ({'logprob': [62.562381744384766, 17.0]}, 128)
batch 879: ({'logprob': [74.74928283691406, 21.0]}, 128)
batch 880: ({'logprob': [50.74467468261719, 13.0]}, 128)
batch 881: ({'logprob': [27.477325439453125, 5.0]}, 128)
batch 882: ({'logprob': [54.6729850769043, 14.0]}, 128)
batch 883: ({'logprob': [62.53156280517578, 17.0]}, 128)
batch 884: ({'logprob': [51.12133026123047, 13.0]}, 128)
batch 885: ({'logprob': [51.89893341064453, 13.0]}, 128)
batch 886: ({'logprob': [62.949378967285156, 17.0]}, 128)

======================Test output======================
logprob:  0.416539, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957266e-03 [4.922212e-09] 
Layer 'conv1' biases: 4.461137e-07 [1.319566e-10] 
Layer 'conv2' weights[0]: 7.944380e-03 [3.556899e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.031973e-10] 
Layer 'conv3' weights[0]: 7.942578e-03 [3.276872e-09] 
Layer 'conv3' biases: 3.763157e-06 [2.131976e-09] 
Layer 'conv4' weights[0]: 7.975231e-03 [3.259218e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.771472e-08] 
Layer 'conv5' weights[0]: 7.973981e-03 [1.133867e-07] 
Layer 'conv5' biases: 9.999887e-01 [1.214762e-07] 
Layer 'fc6' weights[0]: 7.570529e-03 [9.334917e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.463453e-09] 
Layer 'fc7' weights[0]: 6.789039e-03 [3.723061e-08] 
Layer 'fc7' biases: 9.998537e-01 [1.326019e-08] 
Layer 'fc8' weights[0]: 1.299665e-03 [5.835277e-07] 
Layer 'fc8' biases: 8.400620e-02 [1.859093e-06] 
Train error last 870 batches: 0.435168
-------------------------------------------------------
Not saving because 0.416539 > 0.415638 (32.630: -0.00%)
======================================================= (12.066 sec)
33.861... logprob:  0.417788, 0.109375 (1.466 sec)
33.862... logprob:  0.328796, 0.078125 (1.467 sec)
33.863... logprob:  0.399603, 0.101562 (1.446 sec)
33.864... logprob:  0.451541, 0.117188 (1.451 sec)
33.865... logprob:  0.484720, 0.132812 (1.460 sec)
33.866... logprob:  0.507938, 0.140625 (1.492 sec)
33.867... logprob:  0.503322, 0.140625 (1.469 sec)
33.868... logprob:  0.405135, 0.101562 (1.472 sec)
33.869... logprob:  0.382945, 0.093750 (1.484 sec)
33.870... logprob:  0.552392, 0.156250 (1.403 sec)
34.1... logprob:  0.379771, 0.093750 (1.435 sec)
34.2... logprob:  0.448225, 0.117188 (1.451 sec)
34.3... logprob:  0.398169, 0.101562 (1.422 sec)
34.4... logprob:  0.443262, 0.117188 (1.410 sec)
34.5... logprob:  0.443502, 0.117188 (1.436 sec)
34.6... logprob:  0.498998, 0.140625 (1.397 sec)
34.7... logprob:  0.363407, 0.085938 (1.424 sec)
34.8... logprob:  0.419197, 0.109375 (1.404 sec)
34.9... logprob:  0.359055, 0.085938 (1.407 sec)
34.10... logprob:  0.377716, 0.093750 (1.408 sec)
34.11... logprob:  0.335110, 0.078125 (1.444 sec)
34.12... logprob:  0.466145, 0.125000 (1.396 sec)
34.13... logprob:  0.442045, 0.117188 (1.421 sec)
34.14... logprob:  0.444397, 0.117188 (1.403 sec)
34.15... logprob:  0.395430, 0.101562 (1.409 sec)
34.16... logprob:  0.421295, 0.109375 (1.412 sec)
34.17... logprob:  0.515835, 0.140625 (1.393 sec)
34.18... logprob:  0.262143, 0.054688 (1.406 sec)
34.19... logprob:  0.279422, 0.062500 (1.402 sec)
34.20... logprob:  0.421352, 0.109375 (1.403 sec)
34.21... logprob:  0.444006, 0.117188 (1.406 sec)
34.22... logprob:  0.536888, 0.148438 (1.420 sec)
34.23... logprob:  0.533335, 0.148438 (1.418 sec)
34.24... logprob:  0.310326, 0.070312 (1.546 sec)
34.25... logprob:  0.356018, 0.085938 (1.409 sec)
34.26... logprob:  0.463889, 0.125000 (1.447 sec)
34.27... logprob:  0.404453, 0.101562 (1.392 sec)
34.28... logprob:  0.421834, 0.109375 (1.413 sec)
34.29... logprob:  0.395841, 0.101562 (1.418 sec)
34.30... logprob:  0.373973, 0.093750 (1.422 sec)
34.31... logprob:  0.480013, 0.132812 (1.405 sec)
34.32... logprob:  0.457219, 0.125000 (1.397 sec)
34.33... logprob:  0.460681, 0.125000 (1.451 sec)
34.34... logprob:  0.464481, 0.125000 (1.396 sec)
34.35... logprob:  0.316374, 0.070312 (1.406 sec)
34.36... logprob:  0.475790, 0.132812 (1.404 sec)
34.37... logprob:  0.417593, 0.109375 (1.410 sec)
34.38... logprob:  0.392768, 0.101562 (1.399 sec)
34.39... logprob:  0.631213, 0.187500 (1.435 sec)
34.40... logprob:  0.445608, 0.117188 (1.412 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.30428695678711, 10.0]}, 128)
batch 872: ({'logprob': [66.3770751953125, 19.0]}, 128)
batch 873: ({'logprob': [40.91227340698242, 9.0]}, 128)
batch 874: ({'logprob': [45.55929183959961, 11.0]}, 128)
batch 875: ({'logprob': [50.932559967041016, 13.0]}, 128)
batch 876: ({'logprob': [63.9007453918457, 18.0]}, 128)
batch 877: ({'logprob': [45.93578338623047, 11.0]}, 128)
batch 878: ({'logprob': [61.73991394042969, 17.0]}, 128)
batch 879: ({'logprob': [72.86380004882812, 21.0]}, 128)
batch 880: ({'logprob': [50.96110916137695, 13.0]}, 128)
batch 881: ({'logprob': [29.749792098999023, 5.0]}, 128)
batch 882: ({'logprob': [54.56853103637695, 14.0]}, 128)
batch 883: ({'logprob': [61.709625244140625, 17.0]}, 128)
batch 884: ({'logprob': [51.310264587402344, 13.0]}, 128)
batch 885: ({'logprob': [52.04106521606445, 13.0]}, 128)
batch 886: ({'logprob': [62.100948333740234, 17.0]}, 128)

======================Test output======================
logprob:  0.416488, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957225e-03 [5.220670e-09] 
Layer 'conv1' biases: 4.472193e-07 [1.239786e-10] 
Layer 'conv2' weights[0]: 7.944342e-03 [3.118725e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.069681e-10] 
Layer 'conv3' weights[0]: 7.942543e-03 [2.502492e-09] 
Layer 'conv3' biases: 3.774096e-06 [1.482615e-09] 
Layer 'conv4' weights[0]: 7.975199e-03 [2.432884e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.047501e-08] 
Layer 'conv5' weights[0]: 7.973936e-03 [6.650421e-08] 
Layer 'conv5' biases: 9.999891e-01 [7.128029e-08] 
Layer 'fc6' weights[0]: 7.570486e-03 [5.448394e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.527994e-09] 
Layer 'fc7' weights[0]: 6.787337e-03 [1.056253e-07] 
Layer 'fc7' biases: 9.998526e-01 [9.296436e-08] 
Layer 'fc8' weights[0]: 1.253441e-03 [6.531217e-06] 
Layer 'fc8' biases: 8.380684e-02 [4.493409e-05] 
Train error last 870 batches: 0.435168
-------------------------------------------------------
Not saving because 0.416488 > 0.415638 (32.630: -0.00%)
======================================================= (12.079 sec)
34.41... logprob:  0.353089, 0.085938 (1.436 sec)
34.42... logprob:  0.392091, 0.101562 (1.427 sec)
34.43... logprob:  0.440062, 0.117188 (1.412 sec)
34.44... logprob:  0.518576, 0.148438 (1.439 sec)
34.45... logprob:  0.381705, 0.093750 (1.398 sec)
34.46... logprob:  0.486098, 0.132812 (1.399 sec)
34.47... logprob:  0.331714, 0.078125 (1.397 sec)
34.48... logprob:  0.498962, 0.140625 (1.425 sec)
34.49... logprob:  0.510987, 0.148438 (1.417 sec)
34.50... logprob:  0.393163, 0.101562 (1.423 sec)
34.51... logprob:  0.490377, 0.140625 (1.418 sec)
34.52... logprob:  0.525796, 0.148438 (1.403 sec)
34.53... logprob:  0.294683, 0.062500 (1.447 sec)
34.54... logprob:  0.403471, 0.109375 (1.389 sec)
34.55... logprob:  0.331644, 0.078125 (1.400 sec)
34.56... logprob:  0.421569, 0.109375 (1.403 sec)
34.57... logprob:  0.572278, 0.164062 (1.431 sec)
34.58... logprob:  0.407446, 0.101562 (1.406 sec)
34.59... logprob:  0.333865, 0.078125 (1.476 sec)
34.60... logprob:  0.618610, 0.179688 (1.426 sec)
34.61... logprob:  0.382766, 0.093750 (1.429 sec)
34.62... logprob:  0.474821, 0.132812 (1.460 sec)
34.63... logprob:  0.397280, 0.101562 (1.445 sec)
34.64... logprob:  0.450354, 0.125000 (1.415 sec)
34.65... logprob:  0.373405, 0.093750 (1.405 sec)
34.66... logprob:  0.354055, 0.085938 (1.442 sec)
34.67... logprob:  0.295437, 0.062500 (1.395 sec)
34.68... logprob:  0.396794, 0.101562 (1.406 sec)
34.69... logprob:  0.496598, 0.140625 (1.427 sec)
34.70... logprob:  0.325922, 0.078125 (1.427 sec)
34.71... logprob:  0.381790, 0.101562 (1.467 sec)
34.72... logprob:  0.493628, 0.132812 (1.409 sec)
34.73... logprob:  0.447643, 0.117188 (1.431 sec)
34.74... logprob:  0.442480, 0.117188 (1.417 sec)
34.75... logprob:  0.380662, 0.093750 (1.417 sec)
34.76... logprob:  0.412032, 0.109375 (1.440 sec)
34.77... logprob:  0.396345, 0.101562 (1.438 sec)
34.78... logprob:  0.493047, 0.140625 (1.458 sec)
34.79... logprob:  0.456490, 0.125000 (1.410 sec)
34.80... logprob:  0.508108, 0.132812 (1.417 sec)
34.81... logprob:  0.416725, 0.109375 (1.421 sec)
34.82... logprob:  0.230999, 0.039062 (1.423 sec)
34.83... logprob:  0.493868, 0.140625 (1.413 sec)
34.84... logprob:  0.468182, 0.125000 (1.466 sec)
34.85... logprob:  0.431882, 0.117188 (1.427 sec)
34.86... logprob:  0.416899, 0.109375 (1.416 sec)
34.87... logprob:  0.633366, 0.187500 (1.420 sec)
34.88... logprob:  0.534993, 0.156250 (1.409 sec)
34.89... logprob:  0.410507, 0.109375 (1.438 sec)
34.90... logprob:  0.577479, 0.171875 (1.389 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.091156005859375, 10.0]}, 128)
batch 872: ({'logprob': [65.7960433959961, 19.0]}, 128)
batch 873: ({'logprob': [42.31509780883789, 9.0]}, 128)
batch 874: ({'logprob': [46.402774810791016, 11.0]}, 128)
batch 875: ({'logprob': [51.48954772949219, 13.0]}, 128)
batch 876: ({'logprob': [63.5301513671875, 18.0]}, 128)
batch 877: ({'logprob': [46.9159049987793, 11.0]}, 128)
batch 878: ({'logprob': [61.717872619628906, 17.0]}, 128)
batch 879: ({'logprob': [72.39741516113281, 21.0]}, 128)
batch 880: ({'logprob': [51.516639709472656, 13.0]}, 128)
batch 881: ({'logprob': [31.59777069091797, 5.0]}, 128)
batch 882: ({'logprob': [55.315521240234375, 14.0]}, 128)
batch 883: ({'logprob': [61.68844985961914, 17.0]}, 128)
batch 884: ({'logprob': [51.998146057128906, 13.0]}, 128)
batch 885: ({'logprob': [52.998966217041016, 13.0]}, 128)
batch 886: ({'logprob': [62.21199035644531, 17.0]}, 128)

======================Test output======================
logprob:  0.420402, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957183e-03 [4.427424e-09] 
Layer 'conv1' biases: 4.483409e-07 [1.211894e-10] 
Layer 'conv2' weights[0]: 7.944309e-03 [3.471582e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.322971e-10] 
Layer 'conv3' weights[0]: 7.942504e-03 [2.938494e-09] 
Layer 'conv3' biases: 3.783232e-06 [1.907033e-09] 
Layer 'conv4' weights[0]: 7.975155e-03 [2.915763e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.466965e-08] 
Layer 'conv5' weights[0]: 7.973908e-03 [8.996968e-08] 
Layer 'conv5' biases: 9.999895e-01 [9.653345e-08] 
Layer 'fc6' weights[0]: 7.570454e-03 [7.351983e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.483873e-09] 
Layer 'fc7' weights[0]: 6.785601e-03 [2.478831e-07] 
Layer 'fc7' biases: 9.998519e-01 [2.393611e-07] 
Layer 'fc8' weights[0]: 1.227903e-03 [9.174939e-06] 
Layer 'fc8' biases: 8.364895e-02 [6.325699e-05] 
Train error last 870 batches: 0.435167
-------------------------------------------------------
Not saving because 0.420402 > 0.415638 (32.630: -0.00%)
======================================================= (12.043 sec)
34.91... logprob:  0.348365, 0.078125 (1.407 sec)
34.92... logprob:  0.464459, 0.125000 (1.411 sec)
34.93... logprob:  0.492179, 0.140625 (1.407 sec)
34.94... logprob:  0.428789, 0.109375 (1.397 sec)
34.95... logprob:  0.471828, 0.125000 (1.405 sec)
34.96... logprob:  0.576108, 0.171875 (1.411 sec)
34.97... logprob:  0.430804, 0.117188 (1.391 sec)
34.98... logprob:  0.391293, 0.093750 (1.440 sec)
34.99... logprob:  0.474180, 0.132812 (1.412 sec)
34.100... logprob:  0.310746, 0.070312 (1.409 sec)
34.101... logprob:  0.311106, 0.062500 (1.445 sec)
34.102... logprob:  0.545711, 0.156250 (1.389 sec)
34.103... logprob:  0.540718, 0.156250 (1.400 sec)
34.104... logprob:  0.388789, 0.101562 (1.406 sec)
34.105... logprob:  0.619029, 0.179688 (1.401 sec)
34.106... logprob:  0.344486, 0.085938 (1.398 sec)
34.107... logprob:  0.335841, 0.078125 (1.438 sec)
34.108... logprob:  0.586862, 0.171875 (1.397 sec)
34.109... logprob:  0.336097, 0.078125 (1.406 sec)
34.110... logprob:  0.564759, 0.164062 (1.419 sec)
34.111... logprob:  0.404639, 0.101562 (1.403 sec)
34.112... logprob:  0.365902, 0.093750 (1.407 sec)
34.113... logprob:  0.354309, 0.085938 (1.402 sec)
34.114... logprob:  0.440205, 0.117188 (1.442 sec)
34.115... logprob:  0.506823, 0.140625 (1.409 sec)
34.116... logprob:  0.393312, 0.101562 (1.407 sec)
34.117... logprob:  0.440393, 0.117188 (1.450 sec)
34.118... logprob:  0.409055, 0.101562 (1.391 sec)
34.119... logprob:  0.346046, 0.085938 (1.403 sec)
34.120... logprob:  0.547130, 0.156250 (1.409 sec)
34.121... logprob:  0.412566, 0.109375 (1.399 sec)
34.122... logprob:  0.519220, 0.148438 (1.444 sec)
34.123... logprob:  0.463643, 0.125000 (1.393 sec)
34.124... logprob:  0.447682, 0.125000 (1.402 sec)
34.125... logprob:  0.501876, 0.140625 (1.404 sec)
34.126... logprob:  0.475702, 0.125000 (1.400 sec)
34.127... logprob:  0.479447, 0.125000 (1.405 sec)
34.128... logprob:  0.422315, 0.109375 (1.420 sec)
34.129... logprob:  0.574878, 0.164062 (1.424 sec)
34.130... logprob:  0.382683, 0.093750 (1.423 sec)
34.131... logprob:  0.495497, 0.132812 (1.412 sec)
34.132... logprob:  0.506353, 0.140625 (1.437 sec)
34.133... logprob:  0.444699, 0.117188 (1.390 sec)
34.134... logprob:  0.401856, 0.101562 (1.397 sec)
34.135... logprob:  0.460166, 0.125000 (1.403 sec)
34.136... logprob:  0.562295, 0.164062 (1.410 sec)
34.137... logprob:  0.462598, 0.125000 (1.399 sec)
34.138... logprob:  0.319437, 0.070312 (1.451 sec)
34.139... logprob:  0.395720, 0.101562 (1.401 sec)
34.140... logprob:  0.559886, 0.164062 (1.412 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.485260009765625, 10.0]}, 128)
batch 872: ({'logprob': [66.63565063476562, 19.0]}, 128)
batch 873: ({'logprob': [40.71040344238281, 9.0]}, 128)
batch 874: ({'logprob': [45.58012771606445, 11.0]}, 128)
batch 875: ({'logprob': [50.95785140991211, 13.0]}, 128)
batch 876: ({'logprob': [64.10307312011719, 18.0]}, 128)
batch 877: ({'logprob': [45.847862243652344, 11.0]}, 128)
batch 878: ({'logprob': [61.77623748779297, 17.0]}, 128)
batch 879: ({'logprob': [72.80280303955078, 21.0]}, 128)
batch 880: ({'logprob': [50.98695373535156, 13.0]}, 128)
batch 881: ({'logprob': [29.64573097229004, 5.0]}, 128)
batch 882: ({'logprob': [54.325721740722656, 14.0]}, 128)
batch 883: ({'logprob': [61.74549102783203, 17.0]}, 128)
batch 884: ({'logprob': [51.22781753540039, 13.0]}, 128)
batch 885: ({'logprob': [51.7412223815918, 13.0]}, 128)
batch 886: ({'logprob': [62.028812408447266, 17.0]}, 128)

======================Test output======================
logprob:  0.416309, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957143e-03 [3.681257e-09] 
Layer 'conv1' biases: 4.492582e-07 [5.924472e-11] 
Layer 'conv2' weights[0]: 7.944268e-03 [2.291758e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.332811e-10] 
Layer 'conv3' weights[0]: 7.942465e-03 [1.705818e-09] 
Layer 'conv3' biases: 3.788844e-06 [9.356810e-10] 
Layer 'conv4' weights[0]: 7.975116e-03 [1.627659e-09] 
Layer 'conv4' biases: 9.999991e-01 [6.301494e-09] 
Layer 'conv5' weights[0]: 7.973863e-03 [2.881897e-08] 
Layer 'conv5' biases: 9.999890e-01 [2.992397e-08] 
Layer 'fc6' weights[0]: 7.570407e-03 [2.509438e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.406995e-09] 
Layer 'fc7' weights[0]: 6.783855e-03 [1.121230e-07] 
Layer 'fc7' biases: 9.998522e-01 [9.879654e-08] 
Layer 'fc8' weights[0]: 1.258328e-03 [3.847314e-06] 
Layer 'fc8' biases: 8.399415e-02 [2.869545e-05] 
Train error last 870 batches: 0.435167
-------------------------------------------------------
Not saving because 0.416309 > 0.415638 (32.630: -0.00%)
======================================================= (12.064 sec)
34.141... logprob:  0.464600, 0.125000 (1.442 sec)
34.142... logprob:  0.464653, 0.125000 (1.403 sec)
34.143... logprob:  0.294496, 0.062500 (1.427 sec)
34.144... logprob:  0.456940, 0.125000 (1.443 sec)
34.145... logprob:  0.324665, 0.078125 (1.421 sec)
34.146... logprob:  0.483016, 0.132812 (1.409 sec)
34.147... logprob:  0.262497, 0.054688 (1.436 sec)
34.148... logprob:  0.458524, 0.125000 (1.388 sec)
34.149... logprob:  0.442473, 0.117188 (1.402 sec)
34.150... logprob:  0.347556, 0.085938 (1.402 sec)
34.151... logprob:  0.347132, 0.085938 (1.401 sec)
34.152... logprob:  0.785167, 0.234375 (1.399 sec)
34.153... logprob:  0.381631, 0.093750 (1.445 sec)
34.154... logprob:  0.524811, 0.148438 (1.406 sec)
34.155... logprob:  0.426163, 0.117188 (1.416 sec)
34.156... logprob:  0.294965, 0.062500 (1.441 sec)
34.157... logprob:  0.269856, 0.054688 (1.398 sec)
34.158... logprob:  0.455471, 0.125000 (1.408 sec)
34.159... logprob:  0.483136, 0.132812 (1.403 sec)
34.160... logprob:  0.444648, 0.117188 (1.405 sec)
34.161... logprob:  0.349525, 0.078125 (1.406 sec)
34.162... logprob:  0.611798, 0.179688 (1.409 sec)
34.163... logprob:  0.450513, 0.125000 (1.427 sec)
34.164... logprob:  0.468464, 0.125000 (1.427 sec)
34.165... logprob:  0.547699, 0.156250 (1.423 sec)
34.166... logprob:  0.446192, 0.125000 (1.456 sec)
34.167... logprob:  0.350683, 0.085938 (1.435 sec)
34.168... logprob:  0.363775, 0.085938 (1.424 sec)
34.169... logprob:  0.408607, 0.101562 (1.458 sec)
34.170... logprob:  0.459452, 0.125000 (1.406 sec)
34.171... logprob:  0.535142, 0.156250 (1.420 sec)
34.172... logprob:  0.434773, 0.109375 (1.422 sec)
34.173... logprob:  0.440457, 0.117188 (1.429 sec)
34.174... logprob:  0.600511, 0.171875 (1.413 sec)
34.175... logprob:  0.505872, 0.140625 (1.469 sec)
34.176... logprob:  0.478368, 0.132812 (1.421 sec)
34.177... logprob:  0.289720, 0.054688 (1.436 sec)
34.178... logprob:  0.383475, 0.093750 (1.460 sec)
34.179... logprob:  0.394646, 0.101562 (1.412 sec)
34.180... logprob:  0.466395, 0.125000 (1.426 sec)
34.181... logprob:  0.539231, 0.156250 (1.415 sec)
34.182... logprob:  0.371236, 0.093750 (1.420 sec)
34.183... logprob:  0.419924, 0.109375 (1.437 sec)
34.184... logprob:  0.483425, 0.132812 (1.424 sec)
34.185... logprob:  0.289701, 0.062500 (1.394 sec)
34.186... logprob:  0.370299, 0.093750 (1.405 sec)
34.187... logprob:  0.529615, 0.148438 (1.405 sec)
34.188... logprob:  0.458825, 0.125000 (1.398 sec)
34.189... logprob:  0.440927, 0.117188 (1.388 sec)
34.190... logprob:  0.375802, 0.093750 (1.522 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.65691375732422, 10.0]}, 128)
batch 872: ({'logprob': [67.01256561279297, 19.0]}, 128)
batch 873: ({'logprob': [40.12796401977539, 9.0]}, 128)
batch 874: ({'logprob': [45.05754470825195, 11.0]}, 128)
batch 875: ({'logprob': [50.71430587768555, 13.0]}, 128)
batch 876: ({'logprob': [64.39583587646484, 18.0]}, 128)
batch 877: ({'logprob': [45.43433380126953, 11.0]}, 128)
batch 878: ({'logprob': [62.09298324584961, 17.0]}, 128)
batch 879: ({'logprob': [73.78837585449219, 21.0]}, 128)
batch 880: ({'logprob': [50.74392318725586, 13.0]}, 128)
batch 881: ({'logprob': [28.392139434814453, 5.0]}, 128)
batch 882: ({'logprob': [54.49836730957031, 14.0]}, 128)
batch 883: ({'logprob': [62.06177520751953, 17.0]}, 128)
batch 884: ({'logprob': [51.09659194946289, 13.0]}, 128)
batch 885: ({'logprob': [51.829471588134766, 13.0]}, 128)
batch 886: ({'logprob': [62.45661926269531, 17.0]}, 128)

======================Test output======================
logprob:  0.415703, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957111e-03 [2.977833e-09] 
Layer 'conv1' biases: 4.504464e-07 [5.316088e-11] 
Layer 'conv2' weights[0]: 7.944221e-03 [1.828878e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.496024e-10] 
Layer 'conv3' weights[0]: 7.942428e-03 [1.290449e-09] 
Layer 'conv3' biases: 3.799420e-06 [3.656431e-10] 
Layer 'conv4' weights[0]: 7.975086e-03 [1.224029e-09] 
Layer 'conv4' biases: 9.999991e-01 [5.532775e-10] 
Layer 'conv5' weights[0]: 7.973822e-03 [2.722146e-09] 
Layer 'conv5' biases: 9.999890e-01 [2.366634e-09] 
Layer 'fc6' weights[0]: 7.570371e-03 [7.812932e-10] 
Layer 'fc6' biases: 1.000000e+00 [1.945115e-10] 
Layer 'fc7' weights[0]: 6.782083e-03 [3.436076e-08] 
Layer 'fc7' biases: 9.998527e-01 [4.893183e-09] 
Layer 'fc8' weights[0]: 1.286718e-03 [6.891182e-07] 
Layer 'fc8' biases: 8.429964e-02 [4.117481e-06] 
Train error last 870 batches: 0.435167
-------------------------------------------------------
Not saving because 0.415703 > 0.415638 (32.630: -0.00%)
======================================================= (12.240 sec)
34.191... logprob:  0.485096, 0.132812 (1.414 sec)
34.192... logprob:  0.519988, 0.148438 (1.429 sec)
34.193... logprob:  0.312441, 0.070312 (1.420 sec)
34.194... logprob:  0.414026, 0.109375 (1.419 sec)
34.195... logprob:  0.286945, 0.062500 (1.400 sec)
34.196... logprob:  0.410425, 0.109375 (1.395 sec)
34.197... logprob:  0.477970, 0.132812 (1.401 sec)
34.198... logprob:  0.355798, 0.085938 (1.404 sec)
34.199... logprob:  0.437195, 0.117188 (1.393 sec)
34.200... logprob:  0.440716, 0.117188 (1.438 sec)
34.201... logprob:  0.437086, 0.117188 (1.409 sec)
34.202... logprob:  0.537792, 0.148438 (1.403 sec)
34.203... logprob:  0.420389, 0.109375 (1.445 sec)
34.204... logprob:  0.504123, 0.140625 (1.400 sec)
34.205... logprob:  0.334243, 0.078125 (1.412 sec)
34.206... logprob:  0.361639, 0.093750 (1.406 sec)
34.207... logprob:  0.381718, 0.093750 (1.394 sec)
34.208... logprob:  0.490610, 0.140625 (1.409 sec)
34.209... logprob:  0.334516, 0.078125 (1.427 sec)
34.210... logprob:  0.586220, 0.171875 (1.421 sec)
34.211... logprob:  0.488098, 0.132812 (1.418 sec)
34.212... logprob:  0.526105, 0.148438 (1.415 sec)
34.213... logprob:  0.514551, 0.140625 (1.464 sec)
34.214... logprob:  0.459377, 0.125000 (1.425 sec)
34.215... logprob:  0.396067, 0.101562 (1.420 sec)
34.216... logprob:  0.516849, 0.140625 (1.469 sec)
34.217... logprob:  0.324766, 0.070312 (1.409 sec)
34.218... logprob:  0.463547, 0.125000 (1.425 sec)
34.219... logprob:  0.500203, 0.140625 (1.435 sec)
34.220... logprob:  0.415038, 0.109375 (1.424 sec)
34.221... logprob:  0.399583, 0.101562 (1.414 sec)
34.222... logprob:  0.554342, 0.164062 (1.460 sec)
34.223... logprob:  0.568830, 0.164062 (1.431 sec)
34.224... logprob:  0.406019, 0.101562 (1.440 sec)
34.225... logprob:  0.392024, 0.101562 (1.448 sec)
34.226... logprob:  0.424787, 0.109375 (1.420 sec)
34.227... logprob:  0.452588, 0.125000 (1.418 sec)
34.228... logprob:  0.417164, 0.109375 (1.422 sec)
34.229... logprob:  0.489371, 0.132812 (1.426 sec)
34.230... logprob:  0.459832, 0.125000 (1.430 sec)
34.231... logprob:  0.453463, 0.125000 (1.411 sec)
34.232... logprob:  0.496130, 0.140625 (1.457 sec)
34.233... logprob:  0.466018, 0.132812 (1.428 sec)
34.234... logprob:  0.563891, 0.164062 (1.419 sec)
34.235... logprob:  0.482008, 0.132812 (1.469 sec)
34.236... logprob:  0.425594, 0.109375 (1.404 sec)
34.237... logprob:  0.340780, 0.078125 (1.422 sec)
34.238... logprob:  0.389008, 0.093750 (1.419 sec)
34.239... logprob:  0.478069, 0.132812 (1.422 sec)
34.240... logprob:  0.485793, 0.132812 (1.414 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.30788040161133, 10.0]}, 128)
batch 872: ({'logprob': [66.0740966796875, 19.0]}, 128)
batch 873: ({'logprob': [41.346290588378906, 9.0]}, 128)
batch 874: ({'logprob': [45.707427978515625, 11.0]}, 128)
batch 875: ({'logprob': [51.026180267333984, 13.0]}, 128)
batch 876: ({'logprob': [63.682899475097656, 18.0]}, 128)
batch 877: ({'logprob': [46.1997184753418, 11.0]}, 128)
batch 878: ({'logprob': [61.722755432128906, 17.0]}, 128)
batch 879: ({'logprob': [72.84964752197266, 21.0]}, 128)
batch 880: ({'logprob': [51.05451965332031, 13.0]}, 128)
batch 881: ({'logprob': [30.18008041381836, 5.0]}, 128)
batch 882: ({'logprob': [54.92135238647461, 14.0]}, 128)
batch 883: ({'logprob': [61.69236373901367, 17.0]}, 128)
batch 884: ({'logprob': [51.51787185668945, 13.0]}, 128)
batch 885: ({'logprob': [52.478580474853516, 13.0]}, 128)
batch 886: ({'logprob': [62.19824981689453, 17.0]}, 128)

======================Test output======================
logprob:  0.417461, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957081e-03 [3.064353e-09] 
Layer 'conv1' biases: 4.514598e-07 [6.048544e-11] 
Layer 'conv2' weights[0]: 7.944179e-03 [1.768587e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.764184e-10] 
Layer 'conv3' weights[0]: 7.942393e-03 [1.318891e-09] 
Layer 'conv3' biases: 3.808936e-06 [4.846760e-10] 
Layer 'conv4' weights[0]: 7.975039e-03 [1.211482e-09] 
Layer 'conv4' biases: 9.999991e-01 [2.411288e-09] 
Layer 'conv5' weights[0]: 7.973786e-03 [1.064378e-08] 
Layer 'conv5' biases: 9.999889e-01 [1.086728e-08] 
Layer 'fc6' weights[0]: 7.570326e-03 [1.162737e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.451800e-10] 
Layer 'fc7' weights[0]: 6.780402e-03 [6.713836e-08] 
Layer 'fc7' biases: 9.998521e-01 [5.092309e-08] 
Layer 'fc8' weights[0]: 1.256656e-03 [2.100575e-06] 
Layer 'fc8' biases: 8.412184e-02 [1.600531e-05] 
Train error last 870 batches: 0.435167
-------------------------------------------------------
Not saving because 0.417461 > 0.415638 (32.630: -0.00%)
======================================================= (12.143 sec)
34.241... logprob:  0.493603, 0.132812 (1.476 sec)
34.242... logprob:  0.341616, 0.078125 (1.433 sec)
34.243... logprob:  0.385985, 0.093750 (1.431 sec)
34.244... logprob:  0.315482, 0.070312 (1.450 sec)
34.245... logprob:  0.494164, 0.132812 (1.424 sec)
34.246... logprob:  0.416826, 0.109375 (1.419 sec)
34.247... logprob:  0.357658, 0.085938 (1.414 sec)
34.248... logprob:  0.308176, 0.070312 (1.423 sec)
34.249... logprob:  0.554239, 0.156250 (1.427 sec)
34.250... logprob:  0.590965, 0.164062 (1.410 sec)
34.251... logprob:  0.353028, 0.085938 (1.456 sec)
34.252... logprob:  0.348416, 0.085938 (1.433 sec)
34.253... logprob:  0.379248, 0.093750 (1.413 sec)
34.254... logprob:  0.444149, 0.117188 (1.471 sec)
34.255... logprob:  0.351270, 0.085938 (1.406 sec)
34.256... logprob:  0.378909, 0.093750 (1.423 sec)
34.257... logprob:  0.331947, 0.078125 (1.421 sec)
34.258... logprob:  0.415429, 0.109375 (1.426 sec)
34.259... logprob:  0.442319, 0.117188 (1.402 sec)
34.260... logprob:  0.308115, 0.070312 (1.462 sec)
34.261... logprob:  0.392466, 0.101562 (1.442 sec)
34.262... logprob:  0.524449, 0.148438 (1.441 sec)
34.263... logprob:  0.425646, 0.109375 (1.451 sec)
34.264... logprob:  0.374976, 0.093750 (1.431 sec)
34.265... logprob:  0.439608, 0.117188 (1.418 sec)
34.266... logprob:  0.439000, 0.117188 (1.415 sec)
34.267... logprob:  0.422050, 0.109375 (1.419 sec)
34.268... logprob:  0.458942, 0.125000 (1.423 sec)
34.269... logprob:  0.567626, 0.164062 (1.417 sec)
34.270... logprob:  0.542389, 0.156250 (1.465 sec)
34.271... logprob:  0.445547, 0.117188 (1.432 sec)
34.272... logprob:  0.384480, 0.093750 (1.421 sec)
34.273... logprob:  0.500241, 0.140625 (1.473 sec)
34.274... logprob:  0.542495, 0.156250 (1.400 sec)
34.275... logprob:  0.487515, 0.132812 (1.428 sec)
34.276... logprob:  0.389942, 0.093750 (1.414 sec)
34.277... logprob:  0.428556, 0.109375 (1.426 sec)
34.278... logprob:  0.323702, 0.070312 (1.423 sec)
34.279... logprob:  0.325407, 0.070312 (1.463 sec)
34.280... logprob:  0.216345, 0.031250 (1.408 sec)
34.281... logprob:  0.417274, 0.109375 (1.432 sec)
34.282... logprob:  0.411272, 0.109375 (1.419 sec)
34.283... logprob:  0.393687, 0.101562 (1.417 sec)
34.284... logprob:  0.394261, 0.101562 (1.412 sec)
34.285... logprob:  0.451108, 0.117188 (1.445 sec)
34.286... logprob:  0.535805, 0.140625 (1.439 sec)
34.287... logprob:  0.346476, 0.085938 (1.431 sec)
34.288... logprob:  0.329931, 0.078125 (1.441 sec)
34.289... logprob:  0.445700, 0.117188 (1.442 sec)
34.290... logprob:  0.490632, 0.132812 (1.407 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.97245407104492, 10.0]}, 128)
batch 872: ({'logprob': [68.6356430053711, 19.0]}, 128)
batch 873: ({'logprob': [39.417083740234375, 9.0]}, 128)
batch 874: ({'logprob': [44.73413848876953, 11.0]}, 128)
batch 875: ({'logprob': [50.90877914428711, 13.0]}, 128)
batch 876: ({'logprob': [65.79352569580078, 18.0]}, 128)
batch 877: ({'logprob': [45.17527389526367, 11.0]}, 128)
batch 878: ({'logprob': [63.32807922363281, 17.0]}, 128)
batch 879: ({'logprob': [76.12960052490234, 21.0]}, 128)
batch 880: ({'logprob': [50.93929672241211, 13.0]}, 128)
batch 881: ({'logprob': [26.572551727294922, 5.0]}, 128)
batch 882: ({'logprob': [55.121116638183594, 14.0]}, 128)
batch 883: ({'logprob': [63.29641342163086, 17.0]}, 128)
batch 884: ({'logprob': [51.36173629760742, 13.0]}, 128)
batch 885: ({'logprob': [52.226600646972656, 13.0]}, 128)
batch 886: ({'logprob': [63.76017761230469, 17.0]}, 128)

======================Test output======================
logprob:  0.419127, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.957038e-03 [6.758654e-09] 
Layer 'conv1' biases: 4.526706e-07 [2.337294e-10] 
Layer 'conv2' weights[0]: 7.944142e-03 [5.638895e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.213944e-09] 
Layer 'conv3' weights[0]: 7.942356e-03 [5.308273e-09] 
Layer 'conv3' biases: 3.816266e-06 [3.495052e-09] 
Layer 'conv4' weights[0]: 7.975003e-03 [5.206430e-09] 
Layer 'conv4' biases: 9.999991e-01 [2.849142e-08] 
Layer 'conv5' weights[0]: 7.973747e-03 [1.759822e-07] 
Layer 'conv5' biases: 9.999889e-01 [1.887018e-07] 
Layer 'fc6' weights[0]: 7.570290e-03 [1.445764e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.477728e-08] 
Layer 'fc7' weights[0]: 6.778648e-03 [2.463142e-07] 
Layer 'fc7' biases: 9.998539e-01 [2.377083e-07] 
Layer 'fc8' weights[0]: 1.332265e-03 [9.655863e-06] 
Layer 'fc8' biases: 8.486947e-02 [5.373150e-05] 
Train error last 870 batches: 0.435166
-------------------------------------------------------
Not saving because 0.419127 > 0.415638 (32.630: -0.00%)
======================================================= (12.023 sec)
34.291... logprob:  0.439381, 0.117188 (1.426 sec)
34.292... logprob:  0.567950, 0.156250 (1.426 sec)
34.293... logprob:  0.427869, 0.117188 (1.432 sec)
34.294... logprob:  0.355566, 0.085938 (1.409 sec)
34.295... logprob:  0.334038, 0.078125 (1.464 sec)
34.296... logprob:  0.355192, 0.085938 (1.427 sec)
34.297... logprob:  0.394177, 0.101562 (1.432 sec)
34.298... logprob:  0.448310, 0.125000 (1.470 sec)
34.299... logprob:  0.341661, 0.078125 (1.402 sec)
34.300... logprob:  0.406231, 0.101562 (1.429 sec)
34.301... logprob:  0.397841, 0.101562 (1.426 sec)
34.302... logprob:  0.591644, 0.179688 (1.415 sec)
34.303... logprob:  0.459443, 0.125000 (1.411 sec)
34.304... logprob:  0.459586, 0.125000 (1.443 sec)
34.305... logprob:  0.455185, 0.125000 (1.441 sec)
34.306... logprob:  0.440563, 0.117188 (1.441 sec)
34.307... logprob:  0.421634, 0.109375 (1.443 sec)
34.308... logprob:  0.374942, 0.093750 (1.459 sec)
34.309... logprob:  0.450484, 0.125000 (1.427 sec)
34.310... logprob:  0.473509, 0.125000 (1.428 sec)
34.311... logprob:  0.502379, 0.140625 (1.430 sec)
34.312... logprob:  0.478627, 0.132812 (1.441 sec)
34.313... logprob:  0.454852, 0.125000 (1.424 sec)
34.314... logprob:  0.454288, 0.117188 (1.479 sec)
34.315... logprob:  0.314699, 0.070312 (1.437 sec)
34.316... logprob:  0.468480, 0.125000 (1.423 sec)
34.317... logprob:  0.355407, 0.085938 (1.484 sec)
34.318... logprob:  0.455396, 0.125000 (1.420 sec)
34.319... logprob:  0.423152, 0.117188 (1.424 sec)
34.320... logprob:  0.412225, 0.109375 (1.428 sec)
34.321... logprob:  0.348219, 0.085938 (1.425 sec)
34.322... logprob:  0.387408, 0.101562 (1.416 sec)
34.323... logprob:  0.416496, 0.109375 (1.476 sec)
34.324... logprob:  0.498590, 0.140625 (1.425 sec)
34.325... logprob:  0.350668, 0.085938 (1.441 sec)
34.326... logprob:  0.543187, 0.148438 (1.463 sec)
34.327... logprob:  0.554435, 0.164062 (1.444 sec)
34.328... logprob:  0.565191, 0.156250 (1.434 sec)
34.329... logprob:  0.401880, 0.101562 (1.429 sec)
34.330... logprob:  0.388443, 0.101562 (1.427 sec)
34.331... logprob:  0.352148, 0.085938 (1.418 sec)
34.332... logprob:  0.482785, 0.132812 (1.451 sec)
34.333... logprob:  0.339396, 0.085938 (1.447 sec)
34.334... logprob:  0.565367, 0.171875 (1.440 sec)
34.335... logprob:  0.358618, 0.085938 (1.445 sec)
34.336... logprob:  0.444870, 0.125000 (1.463 sec)
34.337... logprob:  0.566380, 0.164062 (1.416 sec)
34.338... logprob:  0.449517, 0.125000 (1.426 sec)
34.339... logprob:  0.488546, 0.132812 (1.424 sec)
34.340... logprob:  0.442060, 0.117188 (1.431 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.34174728393555, 10.0]}, 128)
batch 872: ({'logprob': [65.7697982788086, 19.0]}, 128)
batch 873: ({'logprob': [42.114295959472656, 9.0]}, 128)
batch 874: ({'logprob': [46.01777267456055, 11.0]}, 128)
batch 875: ({'logprob': [51.28545379638672, 13.0]}, 128)
batch 876: ({'logprob': [63.50480270385742, 18.0]}, 128)
batch 877: ({'logprob': [46.71278762817383, 11.0]}, 128)
batch 878: ({'logprob': [61.8753547668457, 17.0]}, 128)
batch 879: ({'logprob': [73.09754943847656, 21.0]}, 128)
batch 880: ({'logprob': [51.31242370605469, 13.0]}, 128)
batch 881: ({'logprob': [30.85248374938965, 5.0]}, 128)
batch 882: ({'logprob': [55.65791320800781, 14.0]}, 128)
batch 883: ({'logprob': [61.84593200683594, 17.0]}, 128)
batch 884: ({'logprob': [51.977294921875, 13.0]}, 128)
batch 885: ({'logprob': [53.34259796142578, 13.0]}, 128)
batch 886: ({'logprob': [62.552459716796875, 17.0]}, 128)

======================Test output======================
logprob:  0.420049, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956997e-03 [3.039671e-09] 
Layer 'conv1' biases: 4.536499e-07 [4.692165e-11] 
Layer 'conv2' weights[0]: 7.944098e-03 [1.981059e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.839137e-10] 
Layer 'conv3' weights[0]: 7.942314e-03 [1.476317e-09] 
Layer 'conv3' biases: 3.825442e-06 [5.606005e-10] 
Layer 'conv4' weights[0]: 7.974962e-03 [1.350850e-09] 
Layer 'conv4' biases: 9.999991e-01 [2.891380e-09] 
Layer 'conv5' weights[0]: 7.973699e-03 [1.380397e-08] 
Layer 'conv5' biases: 9.999890e-01 [1.447328e-08] 
Layer 'fc6' weights[0]: 7.570252e-03 [1.393543e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.160498e-09] 
Layer 'fc7' weights[0]: 6.776896e-03 [3.520903e-08] 
Layer 'fc7' biases: 9.998523e-01 [7.890329e-09] 
Layer 'fc8' weights[0]: 1.244799e-03 [1.464845e-06] 
Layer 'fc8' biases: 8.440730e-02 [9.364815e-06] 
Train error last 870 batches: 0.435166
-------------------------------------------------------
Not saving because 0.420049 > 0.415638 (32.630: -0.00%)
======================================================= (12.170 sec)
34.341... logprob:  0.529981, 0.148438 (1.435 sec)
34.342... logprob:  0.429581, 0.109375 (1.475 sec)
34.343... logprob:  0.434761, 0.109375 (1.437 sec)
34.344... logprob:  0.444560, 0.125000 (1.481 sec)
34.345... logprob:  0.488162, 0.132812 (1.444 sec)
34.346... logprob:  0.436200, 0.117188 (1.438 sec)
34.347... logprob:  0.372618, 0.085938 (1.486 sec)
34.348... logprob:  0.398514, 0.101562 (1.434 sec)
34.349... logprob:  0.497498, 0.140625 (1.435 sec)
34.350... logprob:  0.358773, 0.085938 (1.437 sec)
34.351... logprob:  0.508421, 0.140625 (1.432 sec)
34.352... logprob:  0.363598, 0.093750 (1.431 sec)
34.353... logprob:  0.512324, 0.148438 (1.494 sec)
34.354... logprob:  0.674659, 0.203125 (1.434 sec)
34.355... logprob:  0.357512, 0.085938 (1.448 sec)
34.356... logprob:  0.479237, 0.132812 (1.477 sec)
34.357... logprob:  0.346626, 0.085938 (1.432 sec)
34.358... logprob:  0.325657, 0.070312 (1.438 sec)
34.359... logprob:  0.555438, 0.164062 (1.437 sec)
34.360... logprob:  0.444530, 0.117188 (1.445 sec)
34.361... logprob:  0.410718, 0.101562 (1.437 sec)
34.362... logprob:  0.423876, 0.117188 (1.476 sec)
34.363... logprob:  0.486602, 0.132812 (1.448 sec)
34.364... logprob:  0.475645, 0.125000 (1.451 sec)
34.365... logprob:  0.425026, 0.109375 (1.470 sec)
34.366... logprob:  0.409520, 0.109375 (1.444 sec)
34.367... logprob:  0.324857, 0.078125 (1.442 sec)
34.368... logprob:  0.595517, 0.171875 (1.426 sec)
34.369... logprob:  0.381705, 0.093750 (1.435 sec)
34.370... logprob:  0.381343, 0.093750 (1.445 sec)
34.371... logprob:  0.400452, 0.101562 (1.460 sec)
34.372... logprob:  0.537095, 0.156250 (1.458 sec)
34.373... logprob:  0.463774, 0.125000 (1.450 sec)
34.374... logprob:  0.526728, 0.148438 (1.457 sec)
34.375... logprob:  0.393762, 0.101562 (1.463 sec)
34.376... logprob:  0.374284, 0.093750 (1.444 sec)
34.377... logprob:  0.295467, 0.062500 (1.431 sec)
34.378... logprob:  0.453624, 0.125000 (1.432 sec)
34.379... logprob:  0.420248, 0.109375 (1.439 sec)
34.380... logprob:  0.605627, 0.179688 (1.444 sec)
34.381... logprob:  0.463391, 0.125000 (1.470 sec)
34.382... logprob:  0.529608, 0.148438 (1.450 sec)
34.383... logprob:  0.358474, 0.085938 (1.523 sec)
34.384... logprob:  0.521276, 0.148438 (1.485 sec)
34.385... logprob:  0.523633, 0.148438 (1.432 sec)
34.386... logprob:  0.582681, 0.171875 (1.435 sec)
34.387... logprob:  0.428440, 0.117188 (1.432 sec)
34.388... logprob:  0.521410, 0.148438 (1.438 sec)
34.389... logprob:  0.425440, 0.109375 (1.435 sec)
34.390... logprob:  0.419564, 0.109375 (1.480 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.804813385009766, 10.0]}, 128)
batch 872: ({'logprob': [65.84307098388672, 19.0]}, 128)
batch 873: ({'logprob': [42.84971618652344, 9.0]}, 128)
batch 874: ({'logprob': [46.92776107788086, 11.0]}, 128)
batch 875: ({'logprob': [51.858741760253906, 13.0]}, 128)
batch 876: ({'logprob': [63.618621826171875, 18.0]}, 128)
batch 877: ({'logprob': [47.36849594116211, 11.0]}, 128)
batch 878: ({'logprob': [61.7750244140625, 17.0]}, 128)
batch 879: ({'logprob': [72.06900787353516, 21.0]}, 128)
batch 880: ({'logprob': [51.88624572753906, 13.0]}, 128)
batch 881: ({'logprob': [32.51893997192383, 5.0]}, 128)
batch 882: ({'logprob': [55.42290496826172, 14.0]}, 128)
batch 883: ({'logprob': [61.74518585205078, 17.0]}, 128)
batch 884: ({'logprob': [52.292869567871094, 13.0]}, 128)
batch 885: ({'logprob': [53.14700698852539, 13.0]}, 128)
batch 886: ({'logprob': [62.195068359375, 17.0]}, 128)

======================Test output======================
logprob:  0.422521, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956962e-03 [3.159294e-09] 
Layer 'conv1' biases: 4.548491e-07 [1.495838e-10] 
Layer 'conv2' weights[0]: 7.944054e-03 [3.209509e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.045028e-10] 
Layer 'conv3' weights[0]: 7.942278e-03 [3.333960e-09] 
Layer 'conv3' biases: 3.836203e-06 [2.077062e-09] 
Layer 'conv4' weights[0]: 7.974924e-03 [3.370346e-09] 
Layer 'conv4' biases: 9.999990e-01 [1.855146e-08] 
Layer 'conv5' weights[0]: 7.973648e-03 [1.179807e-07] 
Layer 'conv5' biases: 9.999893e-01 [1.266860e-07] 
Layer 'fc6' weights[0]: 7.570215e-03 [9.599186e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.719021e-09] 
Layer 'fc7' weights[0]: 6.775177e-03 [3.943120e-08] 
Layer 'fc7' biases: 9.998509e-01 [1.612261e-08] 
Layer 'fc8' weights[0]: 1.222563e-03 [2.329133e-06] 
Layer 'fc8' biases: 8.433381e-02 [1.730257e-05] 
Train error last 870 batches: 0.435166
-------------------------------------------------------
Not saving because 0.422521 > 0.415638 (32.630: -0.00%)
======================================================= (12.140 sec)
34.391... logprob:  0.318035, 0.070312 (1.460 sec)
34.392... logprob:  0.439452, 0.117188 (1.441 sec)
34.393... logprob:  0.369092, 0.093750 (1.514 sec)
34.394... logprob:  0.343789, 0.078125 (1.439 sec)
34.395... logprob:  0.332045, 0.078125 (1.435 sec)
34.396... logprob:  0.252890, 0.046875 (1.433 sec)
34.397... logprob:  0.483848, 0.132812 (1.434 sec)
34.398... logprob:  0.470359, 0.125000 (1.439 sec)
34.399... logprob:  0.432930, 0.117188 (1.486 sec)
34.400... logprob:  0.536951, 0.148438 (1.434 sec)
34.401... logprob:  0.465394, 0.125000 (1.447 sec)
34.402... logprob:  0.473621, 0.125000 (1.476 sec)
34.403... logprob:  0.462021, 0.125000 (1.440 sec)
34.404... logprob:  0.474779, 0.125000 (1.432 sec)
34.405... logprob:  0.544430, 0.156250 (1.441 sec)
34.406... logprob:  0.357401, 0.085938 (1.428 sec)
34.407... logprob:  0.493184, 0.140625 (1.436 sec)
34.408... logprob:  0.338492, 0.078125 (1.482 sec)
34.409... logprob:  0.400161, 0.101562 (1.443 sec)
34.410... logprob:  0.582559, 0.171875 (1.448 sec)
34.411... logprob:  0.397490, 0.101562 (1.476 sec)
34.412... logprob:  0.540383, 0.156250 (1.435 sec)
34.413... logprob:  0.544647, 0.156250 (1.445 sec)
34.414... logprob:  0.466261, 0.125000 (1.429 sec)
34.415... logprob:  0.401565, 0.101562 (1.429 sec)
34.416... logprob:  0.427440, 0.109375 (1.436 sec)
34.417... logprob:  0.405458, 0.093750 (1.468 sec)
34.418... logprob:  0.380614, 0.093750 (1.451 sec)
34.419... logprob:  0.418011, 0.101562 (1.455 sec)
34.420... logprob:  0.356750, 0.085938 (1.458 sec)
34.421... logprob:  0.376730, 0.101562 (1.458 sec)
34.422... logprob:  0.521639, 0.148438 (1.436 sec)
34.423... logprob:  0.420708, 0.109375 (1.432 sec)
34.424... logprob:  0.325067, 0.078125 (1.429 sec)
34.425... logprob:  0.306701, 0.070312 (1.446 sec)
34.426... logprob:  0.448829, 0.117188 (1.450 sec)
34.427... logprob:  0.553554, 0.156250 (1.470 sec)
34.428... logprob:  0.601152, 0.171875 (1.450 sec)
34.429... logprob:  0.426375, 0.109375 (1.448 sec)
34.430... logprob:  0.299696, 0.070312 (1.475 sec)
34.431... logprob:  0.600360, 0.171875 (1.436 sec)
34.432... logprob:  0.387505, 0.093750 (1.426 sec)
34.433... logprob:  0.329338, 0.078125 (1.441 sec)
34.434... logprob:  0.529906, 0.148438 (1.477 sec)
34.435... logprob:  0.532756, 0.156250 (1.434 sec)
34.436... logprob:  0.380643, 0.093750 (1.481 sec)
34.437... logprob:  0.500396, 0.140625 (1.443 sec)
34.438... logprob:  0.547126, 0.156250 (1.438 sec)
34.439... logprob:  0.378279, 0.093750 (1.488 sec)
34.440... logprob:  0.439535, 0.117188 (1.431 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.53351974487305, 10.0]}, 128)
batch 872: ({'logprob': [65.8262939453125, 19.0]}, 128)
batch 873: ({'logprob': [42.61539840698242, 9.0]}, 128)
batch 874: ({'logprob': [46.714298248291016, 11.0]}, 128)
batch 875: ({'logprob': [51.7038459777832, 13.0]}, 128)
batch 876: ({'logprob': [63.58175277709961, 18.0]}, 128)
batch 877: ({'logprob': [47.173587799072266, 11.0]}, 128)
batch 878: ({'logprob': [61.73707580566406, 17.0]}, 128)
batch 879: ({'logprob': [72.16729736328125, 21.0]}, 128)
batch 880: ({'logprob': [51.7310905456543, 13.0]}, 128)
batch 881: ({'logprob': [32.148197174072266, 5.0]}, 128)
batch 882: ({'logprob': [55.34470748901367, 14.0]}, 128)
batch 883: ({'logprob': [61.70764923095703, 17.0]}, 128)
batch 884: ({'logprob': [52.157283782958984, 13.0]}, 128)
batch 885: ({'logprob': [53.04928207397461, 13.0]}, 128)
batch 886: ({'logprob': [62.17633819580078, 17.0]}, 128)

======================Test output======================
logprob:  0.421566, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956914e-03 [4.267367e-09] 
Layer 'conv1' biases: 4.557880e-07 [1.102845e-10] 
Layer 'conv2' weights[0]: 7.944014e-03 [3.205990e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.835530e-10] 
Layer 'conv3' weights[0]: 7.942239e-03 [2.975063e-09] 
Layer 'conv3' biases: 3.843673e-06 [1.783379e-09] 
Layer 'conv4' weights[0]: 7.974891e-03 [2.992427e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.583611e-08] 
Layer 'conv5' weights[0]: 7.973616e-03 [1.007384e-07] 
Layer 'conv5' biases: 9.999891e-01 [1.081525e-07] 
Layer 'fc6' weights[0]: 7.570175e-03 [8.175788e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.310717e-09] 
Layer 'fc7' weights[0]: 6.773466e-03 [3.558852e-08] 
Layer 'fc7' biases: 9.998510e-01 [9.803357e-09] 
Layer 'fc8' weights[0]: 1.220709e-03 [5.096549e-07] 
Layer 'fc8' biases: 8.473399e-02 [2.414641e-06] 
Train error last 870 batches: 0.435165
-------------------------------------------------------
Not saving because 0.421566 > 0.415638 (32.630: -0.00%)
======================================================= (12.108 sec)
34.441... logprob:  0.467898, 0.125000 (1.438 sec)
34.442... logprob:  0.378895, 0.093750 (1.444 sec)
34.443... logprob:  0.496548, 0.140625 (1.441 sec)
34.444... logprob:  0.372545, 0.093750 (1.433 sec)
34.445... logprob:  0.362846, 0.085938 (1.487 sec)
34.446... logprob:  0.398535, 0.101562 (1.440 sec)
34.447... logprob:  0.569124, 0.164062 (1.442 sec)
34.448... logprob:  0.333274, 0.078125 (1.482 sec)
34.449... logprob:  0.400070, 0.101562 (1.433 sec)
34.450... logprob:  0.240194, 0.046875 (1.439 sec)
34.451... logprob:  0.452267, 0.125000 (1.433 sec)
34.452... logprob:  0.455808, 0.117188 (1.433 sec)
34.453... logprob:  0.454878, 0.125000 (1.434 sec)
34.454... logprob:  0.488678, 0.132812 (1.488 sec)
34.455... logprob:  0.505921, 0.140625 (1.433 sec)
34.456... logprob:  0.468838, 0.125000 (1.455 sec)
34.457... logprob:  0.375296, 0.093750 (1.481 sec)
34.458... logprob:  0.350870, 0.085938 (1.439 sec)
34.459... logprob:  0.514262, 0.140625 (1.435 sec)
34.460... logprob:  0.273285, 0.054688 (1.440 sec)
34.461... logprob:  0.460211, 0.125000 (1.434 sec)
34.462... logprob:  0.472057, 0.125000 (1.435 sec)
34.463... logprob:  0.420747, 0.109375 (1.472 sec)
34.464... logprob:  0.482863, 0.132812 (1.451 sec)
34.465... logprob:  0.421048, 0.109375 (1.453 sec)
34.466... logprob:  0.318074, 0.070312 (1.465 sec)
34.467... logprob:  0.413798, 0.109375 (1.476 sec)
34.468... logprob:  0.394238, 0.101562 (1.439 sec)
34.469... logprob:  0.334832, 0.078125 (1.439 sec)
34.470... logprob:  0.400123, 0.101562 (1.427 sec)
34.471... logprob:  0.529054, 0.148438 (1.442 sec)
34.472... logprob:  0.409946, 0.109375 (1.451 sec)
34.473... logprob:  0.375537, 0.093750 (1.462 sec)
34.474... logprob:  0.465393, 0.125000 (1.453 sec)
34.475... logprob:  0.503680, 0.140625 (1.452 sec)
34.476... logprob:  0.509999, 0.140625 (1.468 sec)
34.477... logprob:  0.334722, 0.078125 (1.440 sec)
34.478... logprob:  0.464198, 0.125000 (1.425 sec)
34.479... logprob:  0.305785, 0.070312 (1.433 sec)
34.480... logprob:  0.443493, 0.117188 (1.443 sec)
34.481... logprob:  0.547826, 0.156250 (1.438 sec)
34.482... logprob:  0.443118, 0.117188 (1.472 sec)
34.483... logprob:  0.502749, 0.140625 (1.453 sec)
34.484... logprob:  0.485339, 0.132812 (1.438 sec)
34.485... logprob:  0.408851, 0.109375 (1.482 sec)
34.486... logprob:  0.361125, 0.085938 (1.439 sec)
34.487... logprob:  0.522748, 0.148438 (1.426 sec)
34.488... logprob:  0.424634, 0.109375 (1.443 sec)
34.489... logprob:  0.415757, 0.109375 (1.438 sec)
34.490... logprob:  0.440678, 0.117188 (1.439 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.57856369018555, 10.0]}, 128)
batch 872: ({'logprob': [66.16793823242188, 19.0]}, 128)
batch 873: ({'logprob': [41.31283187866211, 9.0]}, 128)
batch 874: ({'logprob': [45.81231689453125, 11.0]}, 128)
batch 875: ({'logprob': [51.08127975463867, 13.0]}, 128)
batch 876: ({'logprob': [63.75435256958008, 18.0]}, 128)
batch 877: ({'logprob': [46.2107048034668, 11.0]}, 128)
batch 878: ({'logprob': [61.67850875854492, 17.0]}, 128)
batch 879: ({'logprob': [72.613037109375, 21.0]}, 128)
batch 880: ({'logprob': [51.10970687866211, 13.0]}, 128)
batch 881: ({'logprob': [30.340112686157227, 5.0]}, 128)
batch 882: ({'logprob': [54.716941833496094, 14.0]}, 128)
batch 883: ({'logprob': [61.64825439453125, 17.0]}, 128)
batch 884: ({'logprob': [51.47910690307617, 13.0]}, 128)
batch 885: ({'logprob': [52.25217056274414, 13.0]}, 128)
batch 886: ({'logprob': [62.06000900268555, 17.0]}, 128)

======================Test output======================
logprob:  0.417391, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956872e-03 [2.724287e-09] 
Layer 'conv1' biases: 4.566920e-07 [7.237500e-11] 
Layer 'conv2' weights[0]: 7.943974e-03 [2.157362e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.410937e-10] 
Layer 'conv3' weights[0]: 7.942203e-03 [1.951100e-09] 
Layer 'conv3' biases: 3.850714e-06 [1.006643e-09] 
Layer 'conv4' weights[0]: 7.974851e-03 [2.048061e-09] 
Layer 'conv4' biases: 9.999991e-01 [8.980050e-09] 
Layer 'conv5' weights[0]: 7.973585e-03 [5.702190e-08] 
Layer 'conv5' biases: 9.999888e-01 [6.116714e-08] 
Layer 'fc6' weights[0]: 7.570137e-03 [4.723610e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.714775e-09] 
Layer 'fc7' weights[0]: 6.771731e-03 [7.758300e-08] 
Layer 'fc7' biases: 9.998518e-01 [6.250948e-08] 
Layer 'fc8' weights[0]: 1.243488e-03 [2.207236e-06] 
Layer 'fc8' biases: 8.510701e-02 [1.699139e-05] 
Train error last 870 batches: 0.435165
-------------------------------------------------------
Not saving because 0.417391 > 0.415638 (32.630: -0.00%)
======================================================= (12.111 sec)
34.491... logprob:  0.313538, 0.070312 (1.490 sec)
34.492... logprob:  0.459493, 0.125000 (1.449 sec)
34.493... logprob:  0.521738, 0.148438 (1.435 sec)
34.494... logprob:  0.450333, 0.125000 (1.488 sec)
34.495... logprob:  0.380738, 0.093750 (1.433 sec)
34.496... logprob:  0.550075, 0.156250 (1.434 sec)
34.497... logprob:  0.466834, 0.125000 (1.438 sec)
34.498... logprob:  0.476160, 0.132812 (1.429 sec)
34.499... logprob:  0.456201, 0.125000 (1.439 sec)
34.500... logprob:  0.355201, 0.085938 (1.513 sec)
34.501... logprob:  0.339144, 0.078125 (1.434 sec)
34.502... logprob:  0.459577, 0.125000 (1.447 sec)
34.503... logprob:  0.400653, 0.101562 (1.477 sec)
34.504... logprob:  0.487247, 0.132812 (1.436 sec)
34.505... logprob:  0.570739, 0.164062 (1.439 sec)
34.506... logprob:  0.479685, 0.132812 (1.436 sec)
34.507... logprob:  0.384982, 0.093750 (1.426 sec)
34.508... logprob:  0.374615, 0.093750 (1.432 sec)
34.509... logprob:  0.322900, 0.070312 (1.483 sec)
34.510... logprob:  0.390444, 0.101562 (1.443 sec)
34.511... logprob:  0.410029, 0.109375 (1.451 sec)
34.512... logprob:  0.470705, 0.125000 (1.471 sec)
34.513... logprob:  0.324954, 0.078125 (1.442 sec)
34.514... logprob:  0.406271, 0.101562 (1.440 sec)
34.515... logprob:  0.455409, 0.125000 (1.432 sec)
34.516... logprob:  0.400193, 0.109375 (1.429 sec)
34.517... logprob:  0.627609, 0.179688 (1.439 sec)
34.518... logprob:  0.437614, 0.117188 (1.459 sec)
34.519... logprob:  0.516123, 0.140625 (1.459 sec)
34.520... logprob:  0.409636, 0.109375 (1.454 sec)
34.521... logprob:  0.427386, 0.109375 (1.464 sec)
34.522... logprob:  0.533219, 0.156250 (1.462 sec)
34.523... logprob:  0.331357, 0.078125 (1.443 sec)
34.524... logprob:  0.437103, 0.117188 (1.423 sec)
34.525... logprob:  0.425813, 0.109375 (1.435 sec)
34.526... logprob:  0.351514, 0.078125 (1.435 sec)
34.527... logprob:  0.504598, 0.140625 (1.447 sec)
34.528... logprob:  0.440431, 0.117188 (1.469 sec)
34.529... logprob:  0.352994, 0.085938 (1.454 sec)
34.530... logprob:  0.440259, 0.117188 (1.444 sec)
34.531... logprob:  0.439927, 0.117188 (1.487 sec)
34.532... logprob:  0.467273, 0.125000 (1.435 sec)
34.533... logprob:  0.560143, 0.164062 (1.429 sec)
34.534... logprob:  0.326020, 0.078125 (1.435 sec)
34.535... logprob:  0.551303, 0.156250 (1.436 sec)
34.536... logprob:  0.507196, 0.140625 (1.441 sec)
34.537... logprob:  0.509957, 0.140625 (1.478 sec)
34.538... logprob:  0.486067, 0.132812 (1.444 sec)
34.539... logprob:  0.295979, 0.062500 (1.435 sec)
34.540... logprob:  0.447178, 0.117188 (1.485 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.415443420410156, 10.0]}, 128)
batch 872: ({'logprob': [66.16410064697266, 19.0]}, 128)
batch 873: ({'logprob': [41.24219512939453, 9.0]}, 128)
batch 874: ({'logprob': [45.71674728393555, 11.0]}, 128)
batch 875: ({'logprob': [51.024471282958984, 13.0]}, 128)
batch 876: ({'logprob': [63.74729919433594, 18.0]}, 128)
batch 877: ({'logprob': [46.146968841552734, 11.0]}, 128)
batch 878: ({'logprob': [61.699737548828125, 17.0]}, 128)
batch 879: ({'logprob': [72.74381256103516, 21.0]}, 128)
batch 880: ({'logprob': [51.05301284790039, 13.0]}, 128)
batch 881: ({'logprob': [30.159564971923828, 5.0]}, 128)
batch 882: ({'logprob': [54.75971984863281, 14.0]}, 128)
batch 883: ({'logprob': [61.66923141479492, 17.0]}, 128)
batch 884: ({'logprob': [51.4546012878418, 13.0]}, 128)
batch 885: ({'logprob': [52.29154968261719, 13.0]}, 128)
batch 886: ({'logprob': [62.113407135009766, 17.0]}, 128)

======================Test output======================
logprob:  0.417188, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956831e-03 [3.330403e-09] 
Layer 'conv1' biases: 4.577907e-07 [9.330707e-11] 
Layer 'conv2' weights[0]: 7.943943e-03 [2.045074e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.334677e-10] 
Layer 'conv3' weights[0]: 7.942165e-03 [2.065072e-09] 
Layer 'conv3' biases: 3.862777e-06 [1.216558e-09] 
Layer 'conv4' weights[0]: 7.974821e-03 [2.101166e-09] 
Layer 'conv4' biases: 9.999991e-01 [9.599878e-09] 
Layer 'conv5' weights[0]: 7.973532e-03 [5.530871e-08] 
Layer 'conv5' biases: 9.999889e-01 [5.929942e-08] 
Layer 'fc6' weights[0]: 7.570108e-03 [4.615897e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.607376e-09] 
Layer 'fc7' weights[0]: 6.769958e-03 [4.728288e-08] 
Layer 'fc7' biases: 9.998519e-01 [2.791172e-08] 
Layer 'fc8' weights[0]: 1.246427e-03 [3.901645e-06] 
Layer 'fc8' biases: 8.520164e-02 [2.805268e-05] 
Train error last 870 batches: 0.435164
-------------------------------------------------------
Not saving because 0.417188 > 0.415638 (32.630: -0.00%)
======================================================= (12.084 sec)
34.541... logprob:  0.388741, 0.101562 (1.437 sec)
34.542... logprob:  0.411198, 0.109375 (1.442 sec)
34.543... logprob:  0.233112, 0.039062 (1.434 sec)
34.544... logprob:  0.317911, 0.070312 (1.435 sec)
34.545... logprob:  0.348792, 0.085938 (1.436 sec)
34.546... logprob:  0.368261, 0.093750 (1.483 sec)
34.547... logprob:  0.439947, 0.117188 (1.440 sec)
34.548... logprob:  0.452723, 0.125000 (1.441 sec)
34.549... logprob:  0.490278, 0.132812 (1.484 sec)
34.550... logprob:  0.367568, 0.093750 (1.432 sec)
34.551... logprob:  0.441548, 0.117188 (1.438 sec)
34.552... logprob:  0.471209, 0.125000 (1.434 sec)
34.553... logprob:  0.349452, 0.085938 (1.434 sec)
34.554... logprob:  0.507051, 0.140625 (1.435 sec)
34.555... logprob:  0.421408, 0.109375 (1.477 sec)
34.556... logprob:  0.355713, 0.085938 (1.443 sec)
34.557... logprob:  0.396305, 0.101562 (1.454 sec)
34.558... logprob:  0.382980, 0.101562 (1.472 sec)
34.559... logprob:  0.441695, 0.125000 (1.440 sec)
34.560... logprob:  0.334892, 0.078125 (1.437 sec)
34.561... logprob:  0.411767, 0.109375 (1.437 sec)
34.562... logprob:  0.503185, 0.140625 (1.423 sec)
34.563... logprob:  0.373708, 0.093750 (1.440 sec)
34.564... logprob:  0.468522, 0.132812 (1.475 sec)
34.565... logprob:  0.611222, 0.187500 (1.454 sec)
34.566... logprob:  0.374843, 0.093750 (1.455 sec)
34.567... logprob:  0.423245, 0.109375 (1.455 sec)
34.568... logprob:  0.496310, 0.140625 (1.459 sec)
34.569... logprob:  0.507616, 0.140625 (1.443 sec)
34.570... logprob:  0.543822, 0.164062 (1.425 sec)
34.571... logprob:  0.454890, 0.125000 (1.432 sec)
34.572... logprob:  0.501318, 0.140625 (1.444 sec)
34.573... logprob:  0.512585, 0.148438 (1.455 sec)
34.574... logprob:  0.427978, 0.109375 (1.499 sec)
34.575... logprob:  0.343318, 0.078125 (1.452 sec)
34.576... logprob:  0.427331, 0.109375 (1.448 sec)
34.577... logprob:  0.460766, 0.125000 (1.475 sec)
34.578... logprob:  0.336864, 0.078125 (1.434 sec)
34.579... logprob:  0.442078, 0.117188 (1.433 sec)
34.580... logprob:  0.546502, 0.156250 (1.438 sec)
34.581... logprob:  0.530477, 0.156250 (1.441 sec)
34.582... logprob:  0.437762, 0.125000 (1.434 sec)
34.583... logprob:  0.592240, 0.171875 (1.482 sec)
34.584... logprob:  0.468043, 0.132812 (1.443 sec)
34.585... logprob:  0.349774, 0.085938 (1.438 sec)
34.586... logprob:  0.313034, 0.070312 (1.487 sec)
34.587... logprob:  0.404291, 0.101562 (1.432 sec)
34.588... logprob:  0.418648, 0.117188 (1.434 sec)
34.589... logprob:  0.361103, 0.093750 (1.438 sec)
34.590... logprob:  0.524804, 0.148438 (1.434 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.17477035522461, 10.0]}, 128)
batch 872: ({'logprob': [66.46112823486328, 19.0]}, 128)
batch 873: ({'logprob': [41.00714111328125, 9.0]}, 128)
batch 874: ({'logprob': [45.178462982177734, 11.0]}, 128)
batch 875: ({'logprob': [50.865562438964844, 13.0]}, 128)
batch 876: ({'logprob': [64.02550506591797, 18.0]}, 128)
batch 877: ({'logprob': [45.94862747192383, 11.0]}, 128)
batch 878: ({'logprob': [62.2990608215332, 17.0]}, 128)
batch 879: ({'logprob': [74.44084930419922, 21.0]}, 128)
batch 880: ({'logprob': [50.8934211730957, 13.0]}, 128)
batch 881: ({'logprob': [28.82353401184082, 5.0]}, 128)
batch 882: ({'logprob': [55.64360809326172, 14.0]}, 128)
batch 883: ({'logprob': [62.268917083740234, 17.0]}, 128)
batch 884: ({'logprob': [51.638641357421875, 13.0]}, 128)
batch 885: ({'logprob': [53.15746307373047, 13.0]}, 128)
batch 886: ({'logprob': [63.0550422668457, 17.0]}, 128)

======================Test output======================
logprob:  0.418399, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956794e-03 [3.305717e-09] 
Layer 'conv1' biases: 4.589358e-07 [7.989642e-11] 
Layer 'conv2' weights[0]: 7.943907e-03 [2.614016e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.742973e-10] 
Layer 'conv3' weights[0]: 7.942128e-03 [2.049138e-09] 
Layer 'conv3' biases: 3.869889e-06 [1.054257e-09] 
Layer 'conv4' weights[0]: 7.974787e-03 [1.965125e-09] 
Layer 'conv4' biases: 9.999991e-01 [7.240310e-09] 
Layer 'conv5' weights[0]: 7.973509e-03 [4.431270e-08] 
Layer 'conv5' biases: 9.999884e-01 [4.753325e-08] 
Layer 'fc6' weights[0]: 7.570070e-03 [3.730499e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.718998e-09] 
Layer 'fc7' weights[0]: 6.768198e-03 [6.561153e-08] 
Layer 'fc7' biases: 9.998529e-01 [4.930948e-08] 
Layer 'fc8' weights[0]: 1.273322e-03 [2.397493e-06] 
Layer 'fc8' biases: 8.551008e-02 [1.665026e-05] 
Train error last 870 batches: 0.435164
-------------------------------------------------------
Not saving because 0.418399 > 0.415638 (32.630: -0.00%)
======================================================= (12.008 sec)
34.591... logprob:  0.397437, 0.101562 (1.438 sec)
34.592... logprob:  0.455693, 0.125000 (1.491 sec)
34.593... logprob:  0.467414, 0.125000 (1.445 sec)
34.594... logprob:  0.352805, 0.085938 (1.443 sec)
34.595... logprob:  0.428659, 0.109375 (1.479 sec)
34.596... logprob:  0.461628, 0.125000 (1.435 sec)
34.597... logprob:  0.397419, 0.101562 (1.434 sec)
34.598... logprob:  0.397213, 0.101562 (1.441 sec)
34.599... logprob:  0.313599, 0.070312 (1.430 sec)
34.600... logprob:  0.340870, 0.085938 (1.434 sec)
34.601... logprob:  0.402167, 0.101562 (1.488 sec)
34.602... logprob:  0.289959, 0.062500 (1.439 sec)
34.603... logprob:  0.267296, 0.054688 (1.447 sec)
34.604... logprob:  0.407532, 0.101562 (1.472 sec)
34.605... logprob:  0.563175, 0.148438 (1.438 sec)
34.606... logprob:  0.295948, 0.070312 (1.443 sec)
34.607... logprob:  0.504604, 0.132812 (1.450 sec)
34.608... logprob:  0.361942, 0.085938 (1.424 sec)
34.609... logprob:  0.357094, 0.085938 (1.440 sec)
34.610... logprob:  0.493233, 0.132812 (1.472 sec)
34.611... logprob:  0.510287, 0.140625 (1.448 sec)
34.612... logprob:  0.448590, 0.117188 (1.453 sec)
34.613... logprob:  0.279193, 0.062500 (1.467 sec)
34.614... logprob:  0.503586, 0.140625 (1.481 sec)
34.615... logprob:  0.350683, 0.085938 (1.441 sec)
34.616... logprob:  0.414960, 0.109375 (1.431 sec)
34.617... logprob:  0.417777, 0.109375 (1.425 sec)
34.618... logprob:  0.547152, 0.156250 (1.442 sec)
34.619... logprob:  0.506185, 0.140625 (1.450 sec)
34.620... logprob:  0.539736, 0.156250 (1.462 sec)
34.621... logprob:  0.363447, 0.085938 (1.458 sec)
34.622... logprob:  0.364568, 0.085938 (1.450 sec)
34.623... logprob:  0.423086, 0.109375 (1.468 sec)
34.624... logprob:  0.382483, 0.093750 (1.441 sec)
34.625... logprob:  0.440971, 0.117188 (1.424 sec)
34.626... logprob:  0.438330, 0.117188 (1.434 sec)
34.627... logprob:  0.435808, 0.117188 (1.440 sec)
34.628... logprob:  0.464997, 0.125000 (1.441 sec)
34.629... logprob:  0.372205, 0.093750 (1.480 sec)
34.630... logprob:  0.422392, 0.109375 (1.450 sec)
34.631... logprob:  0.638066, 0.187500 (1.437 sec)
34.632... logprob:  0.399133, 0.101562 (1.488 sec)
34.633... logprob:  0.376154, 0.093750 (1.433 sec)
34.634... logprob:  0.659903, 0.195312 (1.433 sec)
34.635... logprob:  0.374128, 0.093750 (1.434 sec)
34.636... logprob:  0.480270, 0.132812 (1.439 sec)
34.637... logprob:  0.330678, 0.078125 (1.431 sec)
34.638... logprob:  0.515720, 0.140625 (1.485 sec)
34.639... logprob:  0.417990, 0.109375 (1.445 sec)
34.640... logprob:  0.528769, 0.148438 (1.442 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.66025924682617, 10.0]}, 128)
batch 872: ({'logprob': [66.25960540771484, 19.0]}, 128)
batch 873: ({'logprob': [41.23020553588867, 9.0]}, 128)
batch 874: ({'logprob': [45.821502685546875, 11.0]}, 128)
batch 875: ({'logprob': [51.08699417114258, 13.0]}, 128)
batch 876: ({'logprob': [63.824440002441406, 18.0]}, 128)
batch 877: ({'logprob': [46.17255783081055, 11.0]}, 128)
batch 878: ({'logprob': [61.67862319946289, 17.0]}, 128)
batch 879: ({'logprob': [72.5599594116211, 21.0]}, 128)
batch 880: ({'logprob': [51.11579895019531, 13.0]}, 128)
batch 881: ({'logprob': [30.310697555541992, 5.0]}, 128)
batch 882: ({'logprob': [54.603172302246094, 14.0]}, 128)
batch 883: ({'logprob': [61.64790725708008, 17.0]}, 128)
batch 884: ({'logprob': [51.437835693359375, 13.0]}, 128)
batch 885: ({'logprob': [52.11591720581055, 13.0]}, 128)
batch 886: ({'logprob': [62.01276779174805, 17.0]}, 128)

======================Test output======================
logprob:  0.417255, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956753e-03 [4.371504e-09] 
Layer 'conv1' biases: 4.600275e-07 [8.285754e-11] 
Layer 'conv2' weights[0]: 7.943875e-03 [2.901251e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.845844e-10] 
Layer 'conv3' weights[0]: 7.942094e-03 [2.035927e-09] 
Layer 'conv3' biases: 3.880514e-06 [1.176739e-09] 
Layer 'conv4' weights[0]: 7.974740e-03 [2.044916e-09] 
Layer 'conv4' biases: 9.999991e-01 [7.858714e-09] 
Layer 'conv5' weights[0]: 7.973450e-03 [5.039412e-08] 
Layer 'conv5' biases: 9.999889e-01 [5.399184e-08] 
Layer 'fc6' weights[0]: 7.570033e-03 [4.153186e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.158014e-09] 
Layer 'fc7' weights[0]: 6.766470e-03 [1.263724e-07] 
Layer 'fc7' biases: 9.998517e-01 [1.149912e-07] 
Layer 'fc8' weights[0]: 1.248347e-03 [4.001207e-06] 
Layer 'fc8' biases: 8.550298e-02 [2.628879e-05] 
Train error last 870 batches: 0.435164
-------------------------------------------------------
Not saving because 0.417255 > 0.415638 (32.630: -0.00%)
======================================================= (12.058 sec)
34.641... logprob:  0.410381, 0.109375 (1.488 sec)
34.642... logprob:  0.500941, 0.140625 (1.442 sec)
34.643... logprob:  0.623441, 0.187500 (1.434 sec)
34.644... logprob:  0.320757, 0.070312 (1.436 sec)
34.645... logprob:  0.414425, 0.109375 (1.433 sec)
34.646... logprob:  0.385493, 0.093750 (1.436 sec)
34.647... logprob:  0.456808, 0.125000 (1.488 sec)
34.648... logprob:  0.491294, 0.140625 (1.435 sec)
34.649... logprob:  0.370378, 0.093750 (1.442 sec)
34.650... logprob:  0.414068, 0.109375 (1.487 sec)
34.651... logprob:  0.397448, 0.101562 (1.438 sec)
34.652... logprob:  0.506971, 0.140625 (1.442 sec)
34.653... logprob:  0.547565, 0.156250 (1.437 sec)
34.654... logprob:  0.495955, 0.140625 (1.431 sec)
34.655... logprob:  0.436169, 0.117188 (1.439 sec)
34.656... logprob:  0.416732, 0.109375 (1.477 sec)
34.657... logprob:  0.448964, 0.117188 (1.445 sec)
34.658... logprob:  0.345940, 0.085938 (1.455 sec)
34.659... logprob:  0.464252, 0.125000 (1.473 sec)
34.660... logprob:  0.446095, 0.125000 (1.448 sec)
34.661... logprob:  0.378366, 0.093750 (1.438 sec)
34.662... logprob:  0.469512, 0.132812 (1.432 sec)
34.663... logprob:  0.310800, 0.070312 (1.426 sec)
34.664... logprob:  0.285305, 0.062500 (1.443 sec)
34.665... logprob:  0.401623, 0.101562 (1.460 sec)
34.666... logprob:  0.442008, 0.117188 (1.457 sec)
34.667... logprob:  0.564175, 0.164062 (1.454 sec)
34.668... logprob:  0.497827, 0.140625 (1.454 sec)
34.669... logprob:  0.432850, 0.109375 (1.461 sec)
34.670... logprob:  0.362304, 0.085938 (1.441 sec)
34.671... logprob:  0.360882, 0.093750 (1.429 sec)
34.672... logprob:  0.441831, 0.117188 (1.431 sec)
34.673... logprob:  0.436221, 0.117188 (1.441 sec)
34.674... logprob:  0.446616, 0.117188 (1.449 sec)
34.675... logprob:  0.356693, 0.093750 (1.472 sec)
34.676... logprob:  0.450204, 0.125000 (1.453 sec)
34.677... logprob:  0.471002, 0.125000 (1.439 sec)
34.678... logprob:  0.465667, 0.125000 (1.482 sec)
34.679... logprob:  0.454861, 0.125000 (1.435 sec)
34.680... logprob:  0.351619, 0.078125 (1.429 sec)
34.681... logprob:  0.373832, 0.093750 (1.461 sec)
34.682... logprob:  0.340446, 0.078125 (1.438 sec)
34.683... logprob:  0.411627, 0.109375 (1.435 sec)
34.684... logprob:  0.357738, 0.085938 (1.480 sec)
34.685... logprob:  0.286334, 0.054688 (1.440 sec)
34.686... logprob:  0.318922, 0.070312 (1.440 sec)
34.687... logprob:  0.281910, 0.062500 (1.488 sec)
34.688... logprob:  0.323176, 0.078125 (1.435 sec)
34.689... logprob:  0.470717, 0.125000 (1.434 sec)
34.690... logprob:  0.527090, 0.140625 (1.433 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.861000061035156, 10.0]}, 128)
batch 872: ({'logprob': [69.47016906738281, 19.0]}, 128)
batch 873: ({'logprob': [39.342838287353516, 9.0]}, 128)
batch 874: ({'logprob': [44.792503356933594, 11.0]}, 128)
batch 875: ({'logprob': [51.18099594116211, 13.0]}, 128)
batch 876: ({'logprob': [66.54218292236328, 18.0]}, 128)
batch 877: ({'logprob': [45.274085998535156, 11.0]}, 128)
batch 878: ({'logprob': [64.03033447265625, 17.0]}, 128)
batch 879: ({'logprob': [77.30221557617188, 21.0]}, 128)
batch 880: ({'logprob': [51.212013244628906, 13.0]}, 128)
batch 881: ({'logprob': [26.0267333984375, 5.0]}, 128)
batch 882: ({'logprob': [55.60474395751953, 14.0]}, 128)
batch 883: ({'logprob': [63.998085021972656, 17.0]}, 128)
batch 884: ({'logprob': [51.677066802978516, 13.0]}, 128)
batch 885: ({'logprob': [52.62382507324219, 13.0]}, 128)
batch 886: ({'logprob': [64.50431060791016, 17.0]}, 128)

======================Test output======================
logprob:  0.422091, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956710e-03 [5.720777e-09] 
Layer 'conv1' biases: 4.608097e-07 [2.252773e-10] 
Layer 'conv2' weights[0]: 7.943839e-03 [4.815859e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.134557e-09] 
Layer 'conv3' weights[0]: 7.942052e-03 [5.019777e-09] 
Layer 'conv3' biases: 3.883956e-06 [3.328643e-09] 
Layer 'conv4' weights[0]: 7.974709e-03 [4.935167e-09] 
Layer 'conv4' biases: 9.999991e-01 [2.827241e-08] 
Layer 'conv5' weights[0]: 7.973417e-03 [1.776663e-07] 
Layer 'conv5' biases: 9.999883e-01 [1.903658e-07] 
Layer 'fc6' weights[0]: 7.569983e-03 [1.458412e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.491705e-08] 
Layer 'fc7' weights[0]: 6.764735e-03 [5.121666e-08] 
Layer 'fc7' biases: 9.998541e-01 [3.234780e-08] 
Layer 'fc8' weights[0]: 1.344383e-03 [7.310920e-06] 
Layer 'fc8' biases: 8.624783e-02 [5.155247e-05] 
Train error last 870 batches: 0.435164
-------------------------------------------------------
Not saving because 0.422091 > 0.415638 (32.630: -0.00%)
======================================================= (12.056 sec)
34.691... logprob:  0.515845, 0.140625 (1.440 sec)
34.692... logprob:  0.384571, 0.101562 (1.441 sec)
34.693... logprob:  0.455290, 0.125000 (1.487 sec)
34.694... logprob:  0.330984, 0.078125 (1.434 sec)
34.695... logprob:  0.356978, 0.085938 (1.442 sec)
34.696... logprob:  0.539453, 0.148438 (1.486 sec)
34.697... logprob:  0.465867, 0.125000 (1.431 sec)
34.698... logprob:  0.549276, 0.156250 (1.440 sec)
34.699... logprob:  0.459659, 0.125000 (1.435 sec)
34.700... logprob:  0.433725, 0.117188 (1.430 sec)
34.701... logprob:  0.422764, 0.109375 (1.436 sec)
34.702... logprob:  0.521634, 0.148438 (1.483 sec)
34.703... logprob:  0.404713, 0.101562 (1.442 sec)
34.704... logprob:  0.405734, 0.101562 (1.458 sec)
34.705... logprob:  0.419985, 0.109375 (1.477 sec)
34.706... logprob:  0.468034, 0.125000 (1.438 sec)
34.707... logprob:  0.485295, 0.132812 (1.438 sec)
34.708... logprob:  0.417299, 0.109375 (1.433 sec)
34.709... logprob:  0.422766, 0.109375 (1.424 sec)
34.710... logprob:  0.601769, 0.179688 (1.443 sec)
34.711... logprob:  0.469450, 0.125000 (1.464 sec)
34.712... logprob:  0.341246, 0.078125 (1.455 sec)
34.713... logprob:  0.586006, 0.179688 (1.455 sec)
34.714... logprob:  0.466201, 0.125000 (1.456 sec)
34.715... logprob:  0.417237, 0.109375 (1.460 sec)
34.716... logprob:  0.335638, 0.078125 (1.442 sec)
34.717... logprob:  0.429752, 0.117188 (1.430 sec)
34.718... logprob:  0.490256, 0.132812 (1.432 sec)
34.719... logprob:  0.406171, 0.109375 (1.444 sec)
34.720... logprob:  0.433217, 0.117188 (1.444 sec)
34.721... logprob:  0.451602, 0.117188 (1.470 sec)
34.722... logprob:  0.537096, 0.156250 (1.458 sec)
34.723... logprob:  0.416526, 0.109375 (1.452 sec)
34.724... logprob:  0.412751, 0.109375 (1.481 sec)
34.725... logprob:  0.494967, 0.140625 (1.436 sec)
34.726... logprob:  0.338285, 0.085938 (1.428 sec)
34.727... logprob:  0.393114, 0.101562 (1.433 sec)
34.728... logprob:  0.421138, 0.109375 (1.442 sec)
34.729... logprob:  0.387451, 0.093750 (1.443 sec)
34.730... logprob:  0.566016, 0.164062 (1.482 sec)
34.731... logprob:  0.450460, 0.125000 (1.450 sec)
34.732... logprob:  0.311319, 0.070312 (1.430 sec)
34.733... logprob:  0.556419, 0.156250 (1.483 sec)
34.734... logprob:  0.340248, 0.078125 (1.437 sec)
34.735... logprob:  0.527341, 0.148438 (1.432 sec)
34.736... logprob:  0.642366, 0.187500 (1.489 sec)
34.737... logprob:  0.516049, 0.148438 (1.432 sec)
34.738... logprob:  0.459366, 0.125000 (1.434 sec)
34.739... logprob:  0.477778, 0.132812 (1.487 sec)
34.740... logprob:  0.339643, 0.078125 (1.437 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.96396255493164, 10.0]}, 128)
batch 872: ({'logprob': [65.74203491210938, 19.0]}, 128)
batch 873: ({'logprob': [42.37697219848633, 9.0]}, 128)
batch 874: ({'logprob': [46.372676849365234, 11.0]}, 128)
batch 875: ({'logprob': [51.48219299316406, 13.0]}, 128)
batch 876: ({'logprob': [63.49374771118164, 18.0]}, 128)
batch 877: ({'logprob': [46.943260192871094, 11.0]}, 128)
batch 878: ({'logprob': [61.755958557128906, 17.0]}, 128)
batch 879: ({'logprob': [72.53712463378906, 21.0]}, 128)
batch 880: ({'logprob': [51.50941467285156, 13.0]}, 128)
batch 881: ({'logprob': [31.55735206604004, 5.0]}, 128)
batch 882: ({'logprob': [55.46255111694336, 14.0]}, 128)
batch 883: ({'logprob': [61.72630310058594, 17.0]}, 128)
batch 884: ({'logprob': [52.048099517822266, 13.0]}, 128)
batch 885: ({'logprob': [53.16313552856445, 13.0]}, 128)
batch 886: ({'logprob': [62.30719757080078, 17.0]}, 128)

======================Test output======================
logprob:  0.420626, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956665e-03 [3.600176e-09] 
Layer 'conv1' biases: 4.620712e-07 [1.103823e-10] 
Layer 'conv2' weights[0]: 7.943802e-03 [3.739217e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.588780e-10] 
Layer 'conv3' weights[0]: 7.942019e-03 [3.408185e-09] 
Layer 'conv3' biases: 3.898682e-06 [2.005640e-09] 
Layer 'conv4' weights[0]: 7.974672e-03 [3.523817e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.755422e-08] 
Layer 'conv5' weights[0]: 7.973373e-03 [1.104167e-07] 
Layer 'conv5' biases: 9.999890e-01 [1.183743e-07] 
Layer 'fc6' weights[0]: 7.569943e-03 [9.003489e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.111093e-09] 
Layer 'fc7' weights[0]: 6.763024e-03 [6.936076e-08] 
Layer 'fc7' biases: 9.998512e-01 [5.479347e-08] 
Layer 'fc8' weights[0]: 1.230729e-03 [2.513440e-06] 
Layer 'fc8' biases: 8.563371e-02 [1.621506e-05] 
Train error last 870 batches: 0.435163
-------------------------------------------------------
Not saving because 0.420626 > 0.415638 (32.630: -0.00%)
======================================================= (12.102 sec)
34.741... logprob:  0.393493, 0.101562 (1.451 sec)
34.742... logprob:  0.419671, 0.109375 (1.492 sec)
34.743... logprob:  0.364913, 0.085938 (1.441 sec)
34.744... logprob:  0.519090, 0.148438 (1.430 sec)
34.745... logprob:  0.478111, 0.132812 (1.444 sec)
34.746... logprob:  0.440541, 0.117188 (1.428 sec)
34.747... logprob:  0.425597, 0.109375 (1.436 sec)
34.748... logprob:  0.378193, 0.093750 (1.483 sec)
34.749... logprob:  0.420791, 0.109375 (1.439 sec)
34.750... logprob:  0.512697, 0.140625 (1.449 sec)
34.751... logprob:  0.263802, 0.054688 (1.477 sec)
34.752... logprob:  0.522491, 0.140625 (1.436 sec)
34.753... logprob:  0.441111, 0.117188 (1.440 sec)
34.754... logprob:  0.468166, 0.132812 (1.433 sec)
34.755... logprob:  0.507015, 0.140625 (1.429 sec)
34.756... logprob:  0.440843, 0.117188 (1.433 sec)
34.757... logprob:  0.552552, 0.156250 (1.479 sec)
34.758... logprob:  0.393496, 0.101562 (1.446 sec)
34.759... logprob:  0.459706, 0.125000 (1.454 sec)
34.760... logprob:  0.485625, 0.132812 (1.463 sec)
34.761... logprob:  0.418054, 0.109375 (1.450 sec)
34.762... logprob:  0.516111, 0.148438 (1.439 sec)
34.763... logprob:  0.559103, 0.164062 (1.433 sec)
34.764... logprob:  0.503260, 0.140625 (1.421 sec)
34.765... logprob:  0.311436, 0.062500 (1.446 sec)
34.766... logprob:  0.482167, 0.132812 (1.451 sec)
34.767... logprob:  0.371019, 0.085938 (1.465 sec)
34.768... logprob:  0.432620, 0.117188 (1.463 sec)
34.769... logprob:  0.490751, 0.140625 (1.470 sec)
34.770... logprob:  0.403065, 0.101562 (1.482 sec)
34.771... logprob:  0.549251, 0.156250 (1.458 sec)
34.772... logprob:  0.414144, 0.109375 (1.449 sec)
34.773... logprob:  0.557419, 0.164062 (1.447 sec)
34.774... logprob:  0.361935, 0.085938 (1.459 sec)
34.775... logprob:  0.407446, 0.101562 (1.466 sec)
34.776... logprob:  0.433111, 0.117188 (1.482 sec)
34.777... logprob:  0.380023, 0.093750 (1.476 sec)
34.778... logprob:  0.433501, 0.117188 (1.463 sec)
34.779... logprob:  0.505239, 0.140625 (1.491 sec)
34.780... logprob:  0.385765, 0.101562 (1.453 sec)
34.781... logprob:  0.369600, 0.085938 (1.451 sec)
34.782... logprob:  0.351369, 0.085938 (1.450 sec)
34.783... logprob:  0.555556, 0.156250 (1.461 sec)
34.784... logprob:  0.440963, 0.117188 (1.457 sec)
34.785... logprob:  0.543824, 0.156250 (1.489 sec)
34.786... logprob:  0.477638, 0.132812 (1.469 sec)
34.787... logprob:  0.546681, 0.156250 (1.467 sec)
34.788... logprob:  0.563489, 0.164062 (1.494 sec)
34.789... logprob:  0.280242, 0.054688 (1.455 sec)
34.790... logprob:  0.407712, 0.101562 (1.448 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.96923828125, 10.0]}, 128)
batch 872: ({'logprob': [65.92029571533203, 19.0]}, 128)
batch 873: ({'logprob': [41.95588684082031, 9.0]}, 128)
batch 874: ({'logprob': [46.21369552612305, 11.0]}, 128)
batch 875: ({'logprob': [51.347591400146484, 13.0]}, 128)
batch 876: ({'logprob': [63.600914001464844, 18.0]}, 128)
batch 877: ({'logprob': [46.66572189331055, 11.0]}, 128)
batch 878: ({'logprob': [61.67279815673828, 17.0]}, 128)
batch 879: ({'logprob': [72.38743591308594, 21.0]}, 128)
batch 880: ({'logprob': [51.37561798095703, 13.0]}, 128)
batch 881: ({'logprob': [31.203184127807617, 5.0]}, 128)
batch 882: ({'logprob': [55.046302795410156, 14.0]}, 128)
batch 883: ({'logprob': [61.642539978027344, 17.0]}, 128)
batch 884: ({'logprob': [51.796566009521484, 13.0]}, 128)
batch 885: ({'logprob': [52.675235748291016, 13.0]}, 128)
batch 886: ({'logprob': [62.10626220703125, 17.0]}, 128)

======================Test output======================
logprob:  0.419228, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956627e-03 [3.428097e-09] 
Layer 'conv1' biases: 4.631276e-07 [1.305894e-10] 
Layer 'conv2' weights[0]: 7.943752e-03 [3.398242e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.558839e-10] 
Layer 'conv3' weights[0]: 7.941982e-03 [3.188939e-09] 
Layer 'conv3' biases: 3.908247e-06 [1.963732e-09] 
Layer 'conv4' weights[0]: 7.974628e-03 [3.151749e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.632098e-08] 
Layer 'conv5' weights[0]: 7.973335e-03 [1.001056e-07] 
Layer 'conv5' biases: 9.999890e-01 [1.074108e-07] 
Layer 'fc6' weights[0]: 7.569896e-03 [8.160060e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.286789e-09] 
Layer 'fc7' weights[0]: 6.761311e-03 [9.514123e-08] 
Layer 'fc7' biases: 9.998511e-01 [8.223325e-08] 
Layer 'fc8' weights[0]: 1.234154e-03 [3.029175e-06] 
Layer 'fc8' biases: 8.580688e-02 [1.739499e-05] 
Train error last 870 batches: 0.435163
-------------------------------------------------------
Not saving because 0.419228 > 0.415638 (32.630: -0.00%)
======================================================= (11.972 sec)
34.791... logprob:  0.397692, 0.101562 (1.456 sec)
34.792... logprob:  0.360724, 0.085938 (1.468 sec)
34.793... logprob:  0.369939, 0.085938 (1.455 sec)
34.794... logprob:  0.387109, 0.093750 (1.493 sec)
34.795... logprob:  0.469673, 0.125000 (1.463 sec)
34.796... logprob:  0.423520, 0.109375 (1.461 sec)
34.797... logprob:  0.358987, 0.085938 (1.498 sec)
34.798... logprob:  0.393319, 0.101562 (1.458 sec)
34.799... logprob:  0.332632, 0.078125 (1.450 sec)
34.800... logprob:  0.371661, 0.093750 (1.449 sec)
34.801... logprob:  0.449758, 0.117188 (1.458 sec)
34.802... logprob:  0.422735, 0.109375 (1.460 sec)
34.803... logprob:  0.491151, 0.132812 (1.490 sec)
34.804... logprob:  0.349934, 0.085938 (1.468 sec)
34.805... logprob:  0.452247, 0.117188 (1.452 sec)
34.806... logprob:  0.424164, 0.109375 (1.505 sec)
34.807... logprob:  0.443479, 0.117188 (1.450 sec)
34.808... logprob:  0.462370, 0.125000 (1.456 sec)
34.809... logprob:  0.589944, 0.171875 (1.448 sec)
34.810... logprob:  0.442522, 0.117188 (1.461 sec)
34.811... logprob:  0.460429, 0.125000 (1.452 sec)
34.812... logprob:  0.462303, 0.125000 (1.496 sec)
34.813... logprob:  0.485948, 0.132812 (1.467 sec)
34.814... logprob:  0.477822, 0.132812 (1.453 sec)
34.815... logprob:  0.371067, 0.085938 (1.503 sec)
34.816... logprob:  0.408243, 0.101562 (1.454 sec)
34.817... logprob:  0.425669, 0.109375 (1.457 sec)
34.818... logprob:  0.560044, 0.164062 (1.448 sec)
34.819... logprob:  0.498168, 0.140625 (1.456 sec)
34.820... logprob:  0.421723, 0.109375 (1.481 sec)
34.821... logprob:  0.406796, 0.101562 (1.496 sec)
34.822... logprob:  0.441349, 0.117188 (1.462 sec)
34.823... logprob:  0.341396, 0.078125 (1.458 sec)
34.824... logprob:  0.489520, 0.132812 (1.499 sec)
34.825... logprob:  0.288773, 0.062500 (1.458 sec)
34.826... logprob:  0.375696, 0.093750 (1.451 sec)
34.827... logprob:  0.420373, 0.109375 (1.452 sec)
34.828... logprob:  0.442964, 0.117188 (1.457 sec)
34.829... logprob:  0.503422, 0.140625 (1.453 sec)
34.830... logprob:  0.441903, 0.117188 (1.511 sec)
34.831... logprob:  0.513671, 0.140625 (1.457 sec)
34.832... logprob:  0.330846, 0.078125 (1.464 sec)
34.833... logprob:  0.489080, 0.132812 (1.497 sec)
34.834... logprob:  0.433455, 0.117188 (1.451 sec)
34.835... logprob:  0.543086, 0.148438 (1.461 sec)
34.836... logprob:  0.375982, 0.093750 (1.445 sec)
34.837... logprob:  0.313681, 0.070312 (1.460 sec)
34.838... logprob:  0.437067, 0.117188 (1.457 sec)
34.839... logprob:  0.471621, 0.125000 (1.506 sec)
34.840... logprob:  0.555725, 0.156250 (1.455 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.54090118408203, 10.0]}, 128)
batch 872: ({'logprob': [66.24868774414062, 19.0]}, 128)
batch 873: ({'logprob': [41.18156814575195, 9.0]}, 128)
batch 874: ({'logprob': [45.75154113769531, 11.0]}, 128)
batch 875: ({'logprob': [51.04389953613281, 13.0]}, 128)
batch 876: ({'logprob': [63.81205368041992, 18.0]}, 128)
batch 877: ({'logprob': [46.12641525268555, 11.0]}, 128)
batch 878: ({'logprob': [61.688682556152344, 17.0]}, 128)
batch 879: ({'logprob': [72.64737701416016, 21.0]}, 128)
batch 880: ({'logprob': [51.07234191894531, 13.0]}, 128)
batch 881: ({'logprob': [30.184415817260742, 5.0]}, 128)
batch 882: ({'logprob': [54.633243560791016, 14.0]}, 128)
batch 883: ({'logprob': [61.65840148925781, 17.0]}, 128)
batch 884: ({'logprob': [51.41865158081055, 13.0]}, 128)
batch 885: ({'logprob': [52.144737243652344, 13.0]}, 128)
batch 886: ({'logprob': [62.046932220458984, 17.0]}, 128)

======================Test output======================
logprob:  0.417090, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956595e-03 [5.025232e-09] 
Layer 'conv1' biases: 4.643110e-07 [1.214388e-10] 
Layer 'conv2' weights[0]: 7.943710e-03 [3.639600e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.173185e-10] 
Layer 'conv3' weights[0]: 7.941943e-03 [3.021664e-09] 
Layer 'conv3' biases: 3.916269e-06 [1.810987e-09] 
Layer 'conv4' weights[0]: 7.974592e-03 [3.051168e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.470143e-08] 
Layer 'conv5' weights[0]: 7.973297e-03 [9.446315e-08] 
Layer 'conv5' biases: 9.999890e-01 [1.011380e-07] 
Layer 'fc6' weights[0]: 7.569854e-03 [7.623262e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.786730e-09] 
Layer 'fc7' weights[0]: 6.759576e-03 [2.207578e-07] 
Layer 'fc7' biases: 9.998515e-01 [2.114218e-07] 
Layer 'fc8' weights[0]: 1.246023e-03 [7.124823e-06] 
Layer 'fc8' biases: 8.618457e-02 [4.830422e-05] 
Train error last 870 batches: 0.435163
-------------------------------------------------------
Not saving because 0.417090 > 0.415638 (32.630: -0.00%)
======================================================= (12.040 sec)
34.841... logprob:  0.395861, 0.101562 (1.469 sec)
34.842... logprob:  0.497946, 0.140625 (1.502 sec)
34.843... logprob:  0.465465, 0.125000 (1.457 sec)
34.844... logprob:  0.497705, 0.140625 (1.465 sec)
34.845... logprob:  0.486690, 0.132812 (1.445 sec)
34.846... logprob:  0.468342, 0.125000 (1.457 sec)
34.847... logprob:  0.363504, 0.085938 (1.448 sec)
34.848... logprob:  0.397335, 0.101562 (1.503 sec)
34.849... logprob:  0.360771, 0.085938 (1.461 sec)
34.850... logprob:  0.479345, 0.132812 (1.467 sec)
34.851... logprob:  0.440142, 0.117188 (1.492 sec)
34.852... logprob:  0.545075, 0.156250 (1.454 sec)
34.853... logprob:  0.372142, 0.093750 (1.465 sec)
34.854... logprob:  0.307637, 0.070312 (1.445 sec)
34.855... logprob:  0.484544, 0.132812 (1.450 sec)
34.856... logprob:  0.443616, 0.117188 (1.456 sec)
34.857... logprob:  0.372239, 0.093750 (1.495 sec)
34.858... logprob:  0.396244, 0.101562 (1.464 sec)
34.859... logprob:  0.308038, 0.070312 (1.474 sec)
34.860... logprob:  0.565944, 0.156250 (1.491 sec)
34.861... logprob:  0.417786, 0.109375 (1.459 sec)
34.862... logprob:  0.328788, 0.078125 (1.465 sec)
34.863... logprob:  0.399608, 0.101562 (1.446 sec)
34.864... logprob:  0.451551, 0.117188 (1.450 sec)
34.865... logprob:  0.484742, 0.132812 (1.458 sec)
34.866... logprob:  0.507967, 0.140625 (1.484 sec)
34.867... logprob:  0.503354, 0.140625 (1.480 sec)
34.868... logprob:  0.405120, 0.101562 (1.473 sec)
34.869... logprob:  0.382919, 0.093750 (1.480 sec)
34.870... logprob:  0.552424, 0.156250 (1.399 sec)
35.1... logprob:  0.379743, 0.093750 (1.407 sec)
35.2... logprob:  0.448221, 0.117188 (1.461 sec)
35.3... logprob:  0.398151, 0.101562 (1.419 sec)
35.4... logprob:  0.443256, 0.117188 (1.414 sec)
35.5... logprob:  0.443506, 0.117188 (1.431 sec)
35.6... logprob:  0.498988, 0.140625 (1.401 sec)
35.7... logprob:  0.363427, 0.085938 (1.427 sec)
35.8... logprob:  0.419203, 0.109375 (1.396 sec)
35.9... logprob:  0.359081, 0.085938 (1.403 sec)
35.10... logprob:  0.377738, 0.093750 (1.414 sec)
35.11... logprob:  0.335147, 0.078125 (1.447 sec)
35.12... logprob:  0.466122, 0.125000 (1.393 sec)
35.13... logprob:  0.442024, 0.117188 (1.427 sec)
35.14... logprob:  0.444373, 0.117188 (1.402 sec)
35.15... logprob:  0.395417, 0.101562 (1.410 sec)
35.16... logprob:  0.421284, 0.109375 (1.406 sec)
35.17... logprob:  0.515814, 0.140625 (1.399 sec)
35.18... logprob:  0.262150, 0.054688 (1.403 sec)
35.19... logprob:  0.279412, 0.062500 (1.408 sec)
35.20... logprob:  0.421350, 0.109375 (1.408 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.58203887939453, 10.0]}, 128)
batch 872: ({'logprob': [68.35356903076172, 19.0]}, 128)
batch 873: ({'logprob': [39.357784271240234, 9.0]}, 128)
batch 874: ({'logprob': [44.897926330566406, 11.0]}, 128)
batch 875: ({'logprob': [50.849674224853516, 13.0]}, 128)
batch 876: ({'logprob': [65.51162719726562, 18.0]}, 128)
batch 877: ({'logprob': [45.11689376831055, 11.0]}, 128)
batch 878: ({'logprob': [62.824058532714844, 17.0]}, 128)
batch 879: ({'logprob': [74.95883178710938, 21.0]}, 128)
batch 880: ({'logprob': [50.880714416503906, 13.0]}, 128)
batch 881: ({'logprob': [27.181861877441406, 5.0]}, 128)
batch 882: ({'logprob': [54.394168853759766, 14.0]}, 128)
batch 883: ({'logprob': [62.7918815612793, 17.0]}, 128)
batch 884: ({'logprob': [51.07942199707031, 13.0]}, 128)
batch 885: ({'logprob': [51.49927520751953, 13.0]}, 128)
batch 886: ({'logprob': [63.03300094604492, 17.0]}, 128)

======================Test output======================
logprob:  0.417145, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956556e-03 [3.803845e-09] 
Layer 'conv1' biases: 4.653962e-07 [5.796144e-11] 
Layer 'conv2' weights[0]: 7.943676e-03 [2.040763e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.700292e-10] 
Layer 'conv3' weights[0]: 7.941901e-03 [1.386756e-09] 
Layer 'conv3' biases: 3.922390e-06 [4.414240e-10] 
Layer 'conv4' weights[0]: 7.974556e-03 [1.342771e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.513768e-09] 
Layer 'conv5' weights[0]: 7.973261e-03 [9.116985e-09] 
Layer 'conv5' biases: 9.999885e-01 [9.567922e-09] 
Layer 'fc6' weights[0]: 7.569820e-03 [1.090667e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.487718e-10] 
Layer 'fc7' weights[0]: 6.757796e-03 [7.079866e-08] 
Layer 'fc7' biases: 9.998531e-01 [5.539761e-08] 
Layer 'fc8' weights[0]: 1.302982e-03 [1.886066e-06] 
Layer 'fc8' biases: 8.676047e-02 [1.489313e-05] 
Train error last 870 batches: 0.435163
-------------------------------------------------------
Not saving because 0.417145 > 0.415638 (32.630: -0.00%)
======================================================= (12.026 sec)
35.21... logprob:  0.444009, 0.117188 (1.409 sec)
35.22... logprob:  0.536907, 0.148438 (1.426 sec)
35.23... logprob:  0.533368, 0.148438 (1.418 sec)
35.24... logprob:  0.310300, 0.070312 (1.422 sec)
35.25... logprob:  0.356000, 0.085938 (1.399 sec)
35.26... logprob:  0.463904, 0.125000 (1.452 sec)
35.27... logprob:  0.404445, 0.101562 (1.393 sec)
35.28... logprob:  0.421832, 0.109375 (1.411 sec)
35.29... logprob:  0.395828, 0.101562 (1.428 sec)
35.30... logprob:  0.373959, 0.093750 (1.422 sec)
35.31... logprob:  0.480020, 0.132812 (1.412 sec)
35.32... logprob:  0.457219, 0.125000 (1.395 sec)
35.33... logprob:  0.460682, 0.125000 (1.454 sec)
35.34... logprob:  0.464474, 0.125000 (1.394 sec)
35.35... logprob:  0.316381, 0.070312 (1.406 sec)
35.36... logprob:  0.475792, 0.132812 (1.415 sec)
35.37... logprob:  0.417594, 0.109375 (1.411 sec)
35.38... logprob:  0.392783, 0.101562 (1.402 sec)
35.39... logprob:  0.631173, 0.187500 (1.439 sec)
35.40... logprob:  0.445595, 0.117188 (1.410 sec)
35.41... logprob:  0.353110, 0.085938 (1.431 sec)
35.42... logprob:  0.392107, 0.101562 (1.425 sec)
35.43... logprob:  0.440060, 0.117188 (1.408 sec)
35.44... logprob:  0.518578, 0.148438 (1.439 sec)
35.45... logprob:  0.381702, 0.093750 (1.400 sec)
35.46... logprob:  0.486084, 0.132812 (1.407 sec)
35.47... logprob:  0.331715, 0.078125 (1.402 sec)
35.48... logprob:  0.498967, 0.140625 (1.428 sec)
35.49... logprob:  0.511007, 0.148438 (1.414 sec)
35.50... logprob:  0.393161, 0.101562 (1.431 sec)
35.51... logprob:  0.490399, 0.140625 (1.422 sec)
35.52... logprob:  0.525798, 0.148438 (1.406 sec)
35.53... logprob:  0.294661, 0.062500 (1.456 sec)
35.54... logprob:  0.403485, 0.109375 (1.393 sec)
35.55... logprob:  0.331634, 0.078125 (1.396 sec)
35.56... logprob:  0.421560, 0.109375 (1.410 sec)
35.57... logprob:  0.572266, 0.164062 (1.426 sec)
35.58... logprob:  0.407427, 0.101562 (1.407 sec)
35.59... logprob:  0.333864, 0.078125 (1.475 sec)
35.60... logprob:  0.618588, 0.179688 (1.433 sec)
35.61... logprob:  0.382759, 0.093750 (1.433 sec)
35.62... logprob:  0.474818, 0.132812 (1.467 sec)
35.63... logprob:  0.397279, 0.101562 (1.442 sec)
35.64... logprob:  0.450359, 0.125000 (1.413 sec)
35.65... logprob:  0.373410, 0.093750 (1.409 sec)
35.66... logprob:  0.354057, 0.085938 (1.451 sec)
35.67... logprob:  0.295440, 0.062500 (1.396 sec)
35.68... logprob:  0.396794, 0.101562 (1.406 sec)
35.69... logprob:  0.496585, 0.140625 (1.429 sec)
35.70... logprob:  0.325927, 0.078125 (1.432 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.017086029052734, 10.0]}, 128)
batch 872: ({'logprob': [67.04075622558594, 19.0]}, 128)
batch 873: ({'logprob': [40.2884635925293, 9.0]}, 128)
batch 874: ({'logprob': [44.88688278198242, 11.0]}, 128)
batch 875: ({'logprob': [50.720664978027344, 13.0]}, 128)
batch 876: ({'logprob': [64.46259307861328, 18.0]}, 128)
batch 877: ({'logprob': [45.51710510253906, 11.0]}, 128)
batch 878: ({'logprob': [62.451900482177734, 17.0]}, 128)
batch 879: ({'logprob': [74.752197265625, 21.0]}, 128)
batch 880: ({'logprob': [50.749698638916016, 13.0]}, 128)
batch 881: ({'logprob': [27.945810317993164, 5.0]}, 128)
batch 882: ({'logprob': [55.226844787597656, 14.0]}, 128)
batch 883: ({'logprob': [62.421024322509766, 17.0]}, 128)
batch 884: ({'logprob': [51.357017517089844, 13.0]}, 128)
batch 885: ({'logprob': [52.59694290161133, 13.0]}, 128)
batch 886: ({'logprob': [63.06965637207031, 17.0]}, 128)

======================Test output======================
logprob:  0.417239, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956521e-03 [2.752327e-09] 
Layer 'conv1' biases: 4.663307e-07 [7.869172e-11] 
Layer 'conv2' weights[0]: 7.943641e-03 [1.943524e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.872885e-10] 
Layer 'conv3' weights[0]: 7.941860e-03 [1.706564e-09] 
Layer 'conv3' biases: 3.930179e-06 [8.660687e-10] 
Layer 'conv4' weights[0]: 7.974516e-03 [1.717366e-09] 
Layer 'conv4' biases: 9.999991e-01 [7.141630e-09] 
Layer 'conv5' weights[0]: 7.973220e-03 [4.537017e-08] 
Layer 'conv5' biases: 9.999883e-01 [4.862962e-08] 
Layer 'fc6' weights[0]: 7.569782e-03 [3.775831e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.772047e-09] 
Layer 'fc7' weights[0]: 6.756113e-03 [1.573533e-07] 
Layer 'fc7' biases: 9.998527e-01 [1.467480e-07] 
Layer 'fc8' weights[0]: 1.288682e-03 [5.795066e-06] 
Layer 'fc8' biases: 8.667995e-02 [3.976465e-05] 
Train error last 870 batches: 0.435163
-------------------------------------------------------
Not saving because 0.417239 > 0.415638 (32.630: -0.00%)
======================================================= (12.057 sec)
35.71... logprob:  0.381788, 0.101562 (1.474 sec)
35.72... logprob:  0.493615, 0.132812 (1.414 sec)
35.73... logprob:  0.447637, 0.117188 (1.428 sec)
35.74... logprob:  0.442474, 0.117188 (1.421 sec)
35.75... logprob:  0.380664, 0.093750 (1.416 sec)
35.76... logprob:  0.412029, 0.109375 (1.438 sec)
35.77... logprob:  0.396345, 0.101562 (1.427 sec)
35.78... logprob:  0.493046, 0.140625 (1.462 sec)
35.79... logprob:  0.456493, 0.125000 (1.408 sec)
35.80... logprob:  0.508123, 0.132812 (1.423 sec)
35.81... logprob:  0.416724, 0.109375 (1.417 sec)
35.82... logprob:  0.230952, 0.039062 (1.425 sec)
35.83... logprob:  0.493878, 0.140625 (1.402 sec)
35.84... logprob:  0.468190, 0.125000 (1.469 sec)
35.85... logprob:  0.431875, 0.117188 (1.425 sec)
35.86... logprob:  0.416895, 0.109375 (1.423 sec)
35.87... logprob:  0.633379, 0.187500 (1.421 sec)
35.88... logprob:  0.534989, 0.156250 (1.413 sec)
35.89... logprob:  0.410499, 0.109375 (1.435 sec)
35.90... logprob:  0.577480, 0.171875 (1.394 sec)
35.91... logprob:  0.348354, 0.078125 (1.436 sec)
35.92... logprob:  0.464458, 0.125000 (1.406 sec)
35.93... logprob:  0.492174, 0.140625 (1.398 sec)
35.94... logprob:  0.428789, 0.109375 (1.392 sec)
35.95... logprob:  0.471827, 0.125000 (1.412 sec)
35.96... logprob:  0.576095, 0.171875 (1.411 sec)
35.97... logprob:  0.430808, 0.117188 (1.395 sec)
35.98... logprob:  0.391309, 0.093750 (1.435 sec)
35.99... logprob:  0.474174, 0.132812 (1.413 sec)
35.100... logprob:  0.310771, 0.070312 (1.401 sec)
35.101... logprob:  0.311144, 0.062500 (1.446 sec)
35.102... logprob:  0.545675, 0.156250 (1.395 sec)
35.103... logprob:  0.540680, 0.156250 (1.413 sec)
35.104... logprob:  0.388786, 0.101562 (1.401 sec)
35.105... logprob:  0.618983, 0.179688 (1.394 sec)
35.106... logprob:  0.344489, 0.085938 (1.401 sec)
35.107... logprob:  0.335850, 0.078125 (1.435 sec)
35.108... logprob:  0.586861, 0.171875 (1.399 sec)
35.109... logprob:  0.336093, 0.078125 (1.406 sec)
35.110... logprob:  0.564777, 0.164062 (1.404 sec)
35.111... logprob:  0.404636, 0.101562 (1.399 sec)
35.112... logprob:  0.365885, 0.093750 (1.398 sec)
35.113... logprob:  0.354287, 0.085938 (1.405 sec)
35.114... logprob:  0.440204, 0.117188 (1.435 sec)
35.115... logprob:  0.506832, 0.140625 (1.416 sec)
35.116... logprob:  0.393306, 0.101562 (1.402 sec)
35.117... logprob:  0.440394, 0.117188 (1.448 sec)
35.118... logprob:  0.409049, 0.101562 (1.398 sec)
35.119... logprob:  0.346039, 0.085938 (1.403 sec)
35.120... logprob:  0.547131, 0.156250 (1.408 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.69926071166992, 10.0]}, 128)
batch 872: ({'logprob': [66.4644546508789, 19.0]}, 128)
batch 873: ({'logprob': [40.686946868896484, 9.0]}, 128)
batch 874: ({'logprob': [45.23765182495117, 11.0]}, 128)
batch 875: ({'logprob': [50.779056549072266, 13.0]}, 128)
batch 876: ({'logprob': [63.971065521240234, 18.0]}, 128)
batch 877: ({'logprob': [45.746246337890625, 11.0]}, 128)
batch 878: ({'logprob': [61.92390441894531, 17.0]}, 128)
batch 879: ({'logprob': [73.5159683227539, 21.0]}, 128)
batch 880: ({'logprob': [50.80784606933594, 13.0]}, 128)
batch 881: ({'logprob': [29.05451011657715, 5.0]}, 128)
batch 882: ({'logprob': [54.83097839355469, 14.0]}, 128)
batch 883: ({'logprob': [61.893104553222656, 17.0]}, 128)
batch 884: ({'logprob': [51.290611267089844, 13.0]}, 128)
batch 885: ({'logprob': [52.285648345947266, 13.0]}, 128)
batch 886: ({'logprob': [62.417842864990234, 17.0]}, 128)

======================Test output======================
logprob:  0.416311, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956479e-03 [2.937772e-09] 
Layer 'conv1' biases: 4.674997e-07 [5.489219e-11] 
Layer 'conv2' weights[0]: 7.943598e-03 [2.128502e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.435608e-10] 
Layer 'conv3' weights[0]: 7.941818e-03 [1.944908e-09] 
Layer 'conv3' biases: 3.940192e-06 [1.143470e-09] 
Layer 'conv4' weights[0]: 7.974468e-03 [1.911333e-09] 
Layer 'conv4' biases: 9.999991e-01 [8.828048e-09] 
Layer 'conv5' weights[0]: 7.973176e-03 [5.540168e-08] 
Layer 'conv5' biases: 9.999887e-01 [5.937127e-08] 
Layer 'fc6' weights[0]: 7.569752e-03 [4.610048e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.599615e-09] 
Layer 'fc7' weights[0]: 6.754395e-03 [4.211924e-08] 
Layer 'fc7' biases: 9.998522e-01 [2.148318e-08] 
Layer 'fc8' weights[0]: 1.264728e-03 [8.588659e-07] 
Layer 'fc8' biases: 8.661860e-02 [5.446437e-06] 
Train error last 870 batches: 0.435162
-------------------------------------------------------
Not saving because 0.416311 > 0.415638 (32.630: -0.00%)
======================================================= (12.065 sec)
35.121... logprob:  0.412561, 0.109375 (1.403 sec)
35.122... logprob:  0.519213, 0.148438 (1.456 sec)
35.123... logprob:  0.463638, 0.125000 (1.392 sec)
35.124... logprob:  0.447681, 0.125000 (1.410 sec)
35.125... logprob:  0.501869, 0.140625 (1.397 sec)
35.126... logprob:  0.475697, 0.125000 (1.396 sec)
35.127... logprob:  0.479436, 0.125000 (1.409 sec)
35.128... logprob:  0.422312, 0.109375 (1.425 sec)
35.129... logprob:  0.574876, 0.164062 (1.422 sec)
35.130... logprob:  0.382680, 0.093750 (1.424 sec)
35.131... logprob:  0.495496, 0.132812 (1.411 sec)
35.132... logprob:  0.506352, 0.140625 (1.444 sec)
35.133... logprob:  0.444701, 0.117188 (1.396 sec)
35.134... logprob:  0.401855, 0.101562 (1.396 sec)
35.135... logprob:  0.460163, 0.125000 (1.409 sec)
35.136... logprob:  0.562281, 0.164062 (1.407 sec)
35.137... logprob:  0.462601, 0.125000 (1.396 sec)
35.138... logprob:  0.319445, 0.070312 (1.450 sec)
35.139... logprob:  0.395717, 0.101562 (1.403 sec)
35.140... logprob:  0.559851, 0.164062 (1.416 sec)
35.141... logprob:  0.464604, 0.125000 (1.442 sec)
35.142... logprob:  0.464656, 0.125000 (1.397 sec)
35.143... logprob:  0.294510, 0.062500 (1.429 sec)
35.144... logprob:  0.456920, 0.125000 (1.419 sec)
35.145... logprob:  0.324652, 0.078125 (1.414 sec)
35.146... logprob:  0.483004, 0.132812 (1.417 sec)
35.147... logprob:  0.262499, 0.054688 (1.430 sec)
35.148... logprob:  0.458508, 0.125000 (1.391 sec)
35.149... logprob:  0.442469, 0.117188 (1.403 sec)
35.150... logprob:  0.347551, 0.085938 (1.408 sec)
35.151... logprob:  0.347130, 0.085938 (1.401 sec)
35.152... logprob:  0.785176, 0.234375 (1.388 sec)
35.153... logprob:  0.381630, 0.093750 (1.449 sec)
35.154... logprob:  0.524836, 0.148438 (1.398 sec)
35.155... logprob:  0.426174, 0.117188 (1.413 sec)
35.156... logprob:  0.294913, 0.062500 (1.436 sec)
35.157... logprob:  0.269801, 0.054688 (1.399 sec)
35.158... logprob:  0.455479, 0.125000 (1.408 sec)
35.159... logprob:  0.483139, 0.132812 (1.397 sec)
35.160... logprob:  0.444636, 0.117188 (1.401 sec)
35.161... logprob:  0.349489, 0.078125 (1.410 sec)
35.162... logprob:  0.611801, 0.179688 (1.411 sec)
35.163... logprob:  0.450520, 0.125000 (1.431 sec)
35.164... logprob:  0.468452, 0.125000 (1.426 sec)
35.165... logprob:  0.547686, 0.156250 (1.430 sec)
35.166... logprob:  0.446202, 0.125000 (1.459 sec)
35.167... logprob:  0.350699, 0.085938 (1.441 sec)
35.168... logprob:  0.363781, 0.085938 (1.423 sec)
35.169... logprob:  0.408603, 0.101562 (1.460 sec)
35.170... logprob:  0.459450, 0.125000 (1.415 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.02338409423828, 10.0]}, 128)
batch 872: ({'logprob': [66.07379150390625, 19.0]}, 128)
batch 873: ({'logprob': [41.296783447265625, 9.0]}, 128)
batch 874: ({'logprob': [45.57506561279297, 11.0]}, 128)
batch 875: ({'logprob': [50.965415954589844, 13.0]}, 128)
batch 876: ({'logprob': [63.685829162597656, 18.0]}, 128)
batch 877: ({'logprob': [46.14452362060547, 11.0]}, 128)
batch 878: ({'logprob': [61.80561447143555, 17.0]}, 128)
batch 879: ({'logprob': [73.1525650024414, 21.0]}, 128)
batch 880: ({'logprob': [50.99380874633789, 13.0]}, 128)
batch 881: ({'logprob': [29.909713745117188, 5.0]}, 128)
batch 882: ({'logprob': [55.09001159667969, 14.0]}, 128)
batch 883: ({'logprob': [61.77503204345703, 17.0]}, 128)
batch 884: ({'logprob': [51.53496551513672, 13.0]}, 128)
batch 885: ({'logprob': [52.65009307861328, 13.0]}, 128)
batch 886: ({'logprob': [62.35865020751953, 17.0]}, 128)

======================Test output======================
logprob:  0.417498, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956437e-03 [2.487110e-09] 
Layer 'conv1' biases: 4.685480e-07 [7.244962e-11] 
Layer 'conv2' weights[0]: 7.943559e-03 [2.337999e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.823002e-10] 
Layer 'conv3' weights[0]: 7.941774e-03 [2.306893e-09] 
Layer 'conv3' biases: 3.950217e-06 [1.183254e-09] 
Layer 'conv4' weights[0]: 7.974435e-03 [2.293879e-09] 
Layer 'conv4' biases: 9.999991e-01 [9.731468e-09] 
Layer 'conv5' weights[0]: 7.973130e-03 [5.898492e-08] 
Layer 'conv5' biases: 9.999886e-01 [6.332689e-08] 
Layer 'fc6' weights[0]: 7.569708e-03 [4.904678e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.898324e-09] 
Layer 'fc7' weights[0]: 6.752667e-03 [1.467173e-07] 
Layer 'fc7' biases: 9.998519e-01 [1.358988e-07] 
Layer 'fc8' weights[0]: 1.254634e-03 [5.509753e-06] 
Layer 'fc8' biases: 8.664149e-02 [4.074567e-05] 
Train error last 870 batches: 0.435162
-------------------------------------------------------
Not saving because 0.417498 > 0.415638 (32.630: -0.00%)
======================================================= (12.086 sec)
35.171... logprob:  0.535125, 0.156250 (1.431 sec)
35.172... logprob:  0.434767, 0.109375 (1.422 sec)
35.173... logprob:  0.440455, 0.117188 (1.423 sec)
35.174... logprob:  0.600473, 0.171875 (1.407 sec)
35.175... logprob:  0.505859, 0.140625 (1.471 sec)
35.176... logprob:  0.478363, 0.132812 (1.419 sec)
35.177... logprob:  0.289721, 0.054688 (1.432 sec)
35.178... logprob:  0.383475, 0.093750 (1.467 sec)
35.179... logprob:  0.394642, 0.101562 (1.412 sec)
35.180... logprob:  0.466396, 0.125000 (1.436 sec)
35.181... logprob:  0.539221, 0.156250 (1.419 sec)
35.182... logprob:  0.371227, 0.093750 (1.414 sec)
35.183... logprob:  0.419922, 0.109375 (1.423 sec)
35.184... logprob:  0.483424, 0.132812 (1.427 sec)
35.185... logprob:  0.289692, 0.062500 (1.395 sec)
35.186... logprob:  0.370287, 0.093750 (1.407 sec)
35.187... logprob:  0.529615, 0.148438 (1.406 sec)
35.188... logprob:  0.458816, 0.125000 (1.400 sec)
35.189... logprob:  0.440928, 0.117188 (1.389 sec)
35.190... logprob:  0.375805, 0.093750 (1.438 sec)
35.191... logprob:  0.485098, 0.132812 (1.410 sec)
35.192... logprob:  0.519980, 0.148438 (1.425 sec)
35.193... logprob:  0.312430, 0.070312 (1.421 sec)
35.194... logprob:  0.414021, 0.109375 (1.415 sec)
35.195... logprob:  0.286929, 0.062500 (1.402 sec)
35.196... logprob:  0.410418, 0.109375 (1.401 sec)
35.197... logprob:  0.477967, 0.132812 (1.405 sec)
35.198... logprob:  0.355798, 0.085938 (1.415 sec)
35.199... logprob:  0.437195, 0.117188 (1.396 sec)
35.200... logprob:  0.440714, 0.117188 (1.474 sec)
35.201... logprob:  0.437085, 0.117188 (1.404 sec)
35.202... logprob:  0.537783, 0.148438 (1.409 sec)
35.203... logprob:  0.420386, 0.109375 (1.448 sec)
35.204... logprob:  0.504123, 0.140625 (1.393 sec)
35.205... logprob:  0.334236, 0.078125 (1.410 sec)
35.206... logprob:  0.361640, 0.093750 (1.404 sec)
35.207... logprob:  0.381709, 0.093750 (1.400 sec)
35.208... logprob:  0.490616, 0.140625 (1.408 sec)
35.209... logprob:  0.334512, 0.078125 (1.421 sec)
35.210... logprob:  0.586219, 0.171875 (1.421 sec)
35.211... logprob:  0.488093, 0.132812 (1.422 sec)
35.212... logprob:  0.526102, 0.148438 (1.414 sec)
35.213... logprob:  0.514539, 0.140625 (1.464 sec)
35.214... logprob:  0.459374, 0.125000 (1.430 sec)
35.215... logprob:  0.396063, 0.101562 (1.415 sec)
35.216... logprob:  0.516835, 0.140625 (1.467 sec)
35.217... logprob:  0.324747, 0.070312 (1.408 sec)
35.218... logprob:  0.463540, 0.125000 (1.421 sec)
35.219... logprob:  0.500198, 0.140625 (1.418 sec)
35.220... logprob:  0.415040, 0.109375 (1.421 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.559814453125, 10.0]}, 128)
batch 872: ({'logprob': [65.99658966064453, 19.0]}, 128)
batch 873: ({'logprob': [41.5789680480957, 9.0]}, 128)
batch 874: ({'logprob': [45.89751052856445, 11.0]}, 128)
batch 875: ({'logprob': [51.14145278930664, 13.0]}, 128)
batch 876: ({'logprob': [63.63513946533203, 18.0]}, 128)
batch 877: ({'logprob': [46.374183654785156, 11.0]}, 128)
batch 878: ({'logprob': [61.68854522705078, 17.0]}, 128)
batch 879: ({'logprob': [72.6491470336914, 21.0]}, 128)
batch 880: ({'logprob': [51.17014694213867, 13.0]}, 128)
batch 881: ({'logprob': [30.57923126220703, 5.0]}, 128)
batch 882: ({'logprob': [54.95879364013672, 14.0]}, 128)
batch 883: ({'logprob': [61.657711029052734, 17.0]}, 128)
batch 884: ({'logprob': [51.616676330566406, 13.0]}, 128)
batch 885: ({'logprob': [52.54499053955078, 13.0]}, 128)
batch 886: ({'logprob': [62.14759063720703, 17.0]}, 128)

======================Test output======================
logprob:  0.418065, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956400e-03 [3.162121e-09] 
Layer 'conv1' biases: 4.696629e-07 [8.800819e-11] 
Layer 'conv2' weights[0]: 7.943526e-03 [2.429848e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.881894e-10] 
Layer 'conv3' weights[0]: 7.941733e-03 [2.196449e-09] 
Layer 'conv3' biases: 3.960815e-06 [1.147893e-09] 
Layer 'conv4' weights[0]: 7.974398e-03 [2.215143e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.000249e-08] 
Layer 'conv5' weights[0]: 7.973099e-03 [6.319570e-08] 
Layer 'conv5' biases: 9.999887e-01 [6.769709e-08] 
Layer 'fc6' weights[0]: 7.569668e-03 [5.164870e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.217149e-09] 
Layer 'fc7' weights[0]: 6.750968e-03 [9.858621e-08] 
Layer 'fc7' biases: 9.998513e-01 [8.505493e-08] 
Layer 'fc8' weights[0]: 1.246674e-03 [5.288359e-06] 
Layer 'fc8' biases: 8.665682e-02 [3.860018e-05] 
Train error last 870 batches: 0.435162
-------------------------------------------------------
Not saving because 0.418065 > 0.415638 (32.630: -0.00%)
======================================================= (12.072 sec)
35.221... logprob:  0.399586, 0.101562 (1.409 sec)
35.222... logprob:  0.554330, 0.164062 (1.465 sec)
35.223... logprob:  0.568809, 0.164062 (1.432 sec)
35.224... logprob:  0.406027, 0.101562 (1.435 sec)
35.225... logprob:  0.392028, 0.101562 (1.451 sec)
35.226... logprob:  0.424796, 0.109375 (1.425 sec)
35.227... logprob:  0.452581, 0.125000 (1.429 sec)
35.228... logprob:  0.417163, 0.109375 (1.424 sec)
35.229... logprob:  0.489371, 0.132812 (1.414 sec)
35.230... logprob:  0.459829, 0.125000 (1.442 sec)
35.231... logprob:  0.453459, 0.125000 (1.408 sec)
35.232... logprob:  0.496124, 0.140625 (1.466 sec)
35.233... logprob:  0.466010, 0.132812 (1.430 sec)
35.234... logprob:  0.563896, 0.164062 (1.428 sec)
35.235... logprob:  0.482007, 0.132812 (1.467 sec)
35.236... logprob:  0.425583, 0.109375 (1.402 sec)
35.237... logprob:  0.340750, 0.078125 (1.426 sec)
35.238... logprob:  0.388988, 0.093750 (1.415 sec)
35.239... logprob:  0.478066, 0.132812 (1.425 sec)
35.240... logprob:  0.485793, 0.132812 (1.401 sec)
35.241... logprob:  0.493604, 0.132812 (1.459 sec)
35.242... logprob:  0.341613, 0.078125 (1.441 sec)
35.243... logprob:  0.385983, 0.093750 (1.439 sec)
35.244... logprob:  0.315495, 0.070312 (1.448 sec)
35.245... logprob:  0.494155, 0.132812 (1.424 sec)
35.246... logprob:  0.416823, 0.109375 (1.415 sec)
35.247... logprob:  0.357675, 0.085938 (1.419 sec)
35.248... logprob:  0.308199, 0.070312 (1.419 sec)
35.249... logprob:  0.554176, 0.156250 (1.424 sec)
35.250... logprob:  0.590923, 0.164062 (1.414 sec)
35.251... logprob:  0.353035, 0.085938 (1.462 sec)
35.252... logprob:  0.348412, 0.085938 (1.423 sec)
35.253... logprob:  0.379253, 0.093750 (1.422 sec)
35.254... logprob:  0.444147, 0.117188 (1.466 sec)
35.255... logprob:  0.351260, 0.085938 (1.407 sec)
35.256... logprob:  0.378918, 0.093750 (1.424 sec)
35.257... logprob:  0.331943, 0.078125 (1.415 sec)
35.258... logprob:  0.415411, 0.109375 (1.423 sec)
35.259... logprob:  0.442320, 0.117188 (1.402 sec)
35.260... logprob:  0.308101, 0.070312 (1.461 sec)
35.261... logprob:  0.392447, 0.101562 (1.425 sec)
35.262... logprob:  0.524436, 0.148438 (1.431 sec)
35.263... logprob:  0.425656, 0.109375 (1.449 sec)
35.264... logprob:  0.374967, 0.093750 (1.427 sec)
35.265... logprob:  0.439608, 0.117188 (1.413 sec)
35.266... logprob:  0.438999, 0.117188 (1.418 sec)
35.267... logprob:  0.422053, 0.109375 (1.422 sec)
35.268... logprob:  0.458943, 0.125000 (1.427 sec)
35.269... logprob:  0.567636, 0.164062 (1.411 sec)
35.270... logprob:  0.542400, 0.156250 (1.458 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.6505241394043, 10.0]}, 128)
batch 872: ({'logprob': [66.30416870117188, 19.0]}, 128)
batch 873: ({'logprob': [41.16676330566406, 9.0]}, 128)
batch 874: ({'logprob': [45.79636001586914, 11.0]}, 128)
batch 875: ({'logprob': [51.07200241088867, 13.0]}, 128)
batch 876: ({'logprob': [63.85761260986328, 18.0]}, 128)
batch 877: ({'logprob': [46.1336669921875, 11.0]}, 128)
batch 878: ({'logprob': [61.68539810180664, 17.0]}, 128)
batch 879: ({'logprob': [72.57361602783203, 21.0]}, 128)
batch 880: ({'logprob': [51.10144805908203, 13.0]}, 128)
batch 881: ({'logprob': [30.239696502685547, 5.0]}, 128)
batch 882: ({'logprob': [54.55936050415039, 14.0]}, 128)
batch 883: ({'logprob': [61.653987884521484, 17.0]}, 128)
batch 884: ({'logprob': [51.409576416015625, 13.0]}, 128)
batch 885: ({'logprob': [52.05952072143555, 13.0]}, 128)
batch 886: ({'logprob': [62.005767822265625, 17.0]}, 128)

======================Test output======================
logprob:  0.417124, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956361e-03 [5.790270e-09] 
Layer 'conv1' biases: 4.709014e-07 [1.796713e-10] 
Layer 'conv2' weights[0]: 7.943493e-03 [4.881252e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.014206e-09] 
Layer 'conv3' weights[0]: 7.941696e-03 [4.503907e-09] 
Layer 'conv3' biases: 3.971088e-06 [2.989215e-09] 
Layer 'conv4' weights[0]: 7.974365e-03 [4.475511e-09] 
Layer 'conv4' biases: 9.999991e-01 [2.438684e-08] 
Layer 'conv5' weights[0]: 7.973076e-03 [1.497626e-07] 
Layer 'conv5' biases: 9.999893e-01 [1.606720e-07] 
Layer 'fc6' weights[0]: 7.569633e-03 [1.210164e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.242945e-08] 
Layer 'fc7' weights[0]: 6.749222e-03 [3.298310e-07] 
Layer 'fc7' biases: 9.998510e-01 [3.223959e-07] 
Layer 'fc8' weights[0]: 1.256933e-03 [1.274994e-05] 
Layer 'fc8' biases: 8.681628e-02 [8.833956e-05] 
Train error last 870 batches: 0.435162
-------------------------------------------------------
Not saving because 0.417124 > 0.415638 (32.630: -0.00%)
======================================================= (12.019 sec)
35.271... logprob:  0.445537, 0.117188 (1.438 sec)
35.272... logprob:  0.384464, 0.093750 (1.434 sec)
35.273... logprob:  0.500243, 0.140625 (1.476 sec)
35.274... logprob:  0.542495, 0.156250 (1.410 sec)
35.275... logprob:  0.487504, 0.132812 (1.422 sec)
35.276... logprob:  0.389929, 0.093750 (1.418 sec)
35.277... logprob:  0.428548, 0.109375 (1.429 sec)
35.278... logprob:  0.323719, 0.070312 (1.430 sec)
35.279... logprob:  0.325431, 0.070312 (1.465 sec)
35.280... logprob:  0.216409, 0.031250 (1.413 sec)
35.281... logprob:  0.417280, 0.109375 (1.430 sec)
35.282... logprob:  0.411264, 0.109375 (1.423 sec)
35.283... logprob:  0.393680, 0.101562 (1.418 sec)
35.284... logprob:  0.394239, 0.101562 (1.409 sec)
35.285... logprob:  0.451053, 0.117188 (1.442 sec)
35.286... logprob:  0.535714, 0.140625 (1.443 sec)
35.287... logprob:  0.346466, 0.085938 (1.430 sec)
35.288... logprob:  0.329929, 0.078125 (1.439 sec)
35.289... logprob:  0.445682, 0.117188 (1.444 sec)
35.290... logprob:  0.490628, 0.132812 (1.412 sec)
35.291... logprob:  0.439392, 0.117188 (1.425 sec)
35.292... logprob:  0.567995, 0.156250 (1.425 sec)
35.293... logprob:  0.427889, 0.117188 (1.429 sec)
35.294... logprob:  0.355536, 0.085938 (1.408 sec)
35.295... logprob:  0.333984, 0.078125 (1.468 sec)
35.296... logprob:  0.355141, 0.085938 (1.426 sec)
35.297... logprob:  0.394146, 0.101562 (1.425 sec)
35.298... logprob:  0.448321, 0.125000 (1.464 sec)
35.299... logprob:  0.341609, 0.078125 (1.402 sec)
35.300... logprob:  0.406206, 0.101562 (1.427 sec)
35.301... logprob:  0.397833, 0.101562 (1.419 sec)
35.302... logprob:  0.591656, 0.179688 (1.419 sec)
35.303... logprob:  0.459434, 0.125000 (1.410 sec)
35.304... logprob:  0.459580, 0.125000 (1.440 sec)
35.305... logprob:  0.455183, 0.125000 (1.436 sec)
35.306... logprob:  0.440561, 0.117188 (1.438 sec)
35.307... logprob:  0.421636, 0.109375 (1.443 sec)
35.308... logprob:  0.374962, 0.093750 (1.458 sec)
35.309... logprob:  0.450485, 0.125000 (1.417 sec)
35.310... logprob:  0.473496, 0.125000 (1.432 sec)
35.311... logprob:  0.502363, 0.140625 (1.427 sec)
35.312... logprob:  0.478618, 0.132812 (1.433 sec)
35.313... logprob:  0.454851, 0.125000 (1.424 sec)
35.314... logprob:  0.454277, 0.117188 (1.473 sec)
35.315... logprob:  0.314705, 0.070312 (1.437 sec)
35.316... logprob:  0.468475, 0.125000 (1.424 sec)
35.317... logprob:  0.355403, 0.085938 (1.481 sec)
35.318... logprob:  0.455395, 0.125000 (1.417 sec)
35.319... logprob:  0.423149, 0.117188 (1.430 sec)
35.320... logprob:  0.412223, 0.109375 (1.427 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.465728759765625, 10.0]}, 128)
batch 872: ({'logprob': [66.55224609375, 19.0]}, 128)
batch 873: ({'logprob': [40.61495590209961, 9.0]}, 128)
batch 874: ({'logprob': [45.12883377075195, 11.0]}, 128)
batch 875: ({'logprob': [50.74784469604492, 13.0]}, 128)
batch 876: ({'logprob': [64.04882049560547, 18.0]}, 128)
batch 877: ({'logprob': [45.69445037841797, 11.0]}, 128)
batch 878: ({'logprob': [62.048370361328125, 17.0]}, 128)
batch 879: ({'logprob': [73.85237884521484, 21.0]}, 128)
batch 880: ({'logprob': [50.776954650878906, 13.0]}, 128)
batch 881: ({'logprob': [28.7696533203125, 5.0]}, 128)
batch 882: ({'logprob': [54.98185348510742, 14.0]}, 128)
batch 883: ({'logprob': [62.0172119140625, 17.0]}, 128)
batch 884: ({'logprob': [51.31711959838867, 13.0]}, 128)
batch 885: ({'logprob': [52.42616271972656, 13.0]}, 128)
batch 886: ({'logprob': [62.59971618652344, 17.0]}, 128)

======================Test output======================
logprob:  0.416525, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956316e-03 [2.474463e-09] 
Layer 'conv1' biases: 4.719877e-07 [4.276916e-11] 
Layer 'conv2' weights[0]: 7.943458e-03 [1.858238e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.878227e-10] 
Layer 'conv3' weights[0]: 7.941659e-03 [1.409997e-09] 
Layer 'conv3' biases: 3.976325e-06 [5.396483e-10] 
Layer 'conv4' weights[0]: 7.974332e-03 [1.498433e-09] 
Layer 'conv4' biases: 9.999990e-01 [3.964456e-09] 
Layer 'conv5' weights[0]: 7.973019e-03 [2.478923e-08] 
Layer 'conv5' biases: 9.999883e-01 [2.648317e-08] 
Layer 'fc6' weights[0]: 7.569587e-03 [2.181142e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.040208e-09] 
Layer 'fc7' weights[0]: 6.747500e-03 [1.196512e-07] 
Layer 'fc7' biases: 9.998521e-01 [1.064447e-07] 
Layer 'fc8' weights[0]: 1.276412e-03 [3.730280e-06] 
Layer 'fc8' biases: 8.724730e-02 [2.712443e-05] 
Train error last 870 batches: 0.435161
-------------------------------------------------------
Not saving because 0.416525 > 0.415638 (32.630: -0.00%)
======================================================= (12.059 sec)
35.321... logprob:  0.348216, 0.085938 (1.434 sec)
35.322... logprob:  0.387402, 0.101562 (1.431 sec)
35.323... logprob:  0.416494, 0.109375 (1.490 sec)
35.324... logprob:  0.498589, 0.140625 (1.430 sec)
35.325... logprob:  0.350667, 0.085938 (1.444 sec)
35.326... logprob:  0.543189, 0.148438 (1.461 sec)
35.327... logprob:  0.554440, 0.164062 (1.427 sec)
35.328... logprob:  0.565203, 0.156250 (1.425 sec)
35.329... logprob:  0.401873, 0.101562 (1.427 sec)
35.330... logprob:  0.388430, 0.101562 (1.420 sec)
35.331... logprob:  0.352126, 0.085938 (1.421 sec)
35.332... logprob:  0.482786, 0.132812 (1.449 sec)
35.333... logprob:  0.339381, 0.085938 (1.446 sec)
35.334... logprob:  0.565382, 0.171875 (1.442 sec)
35.335... logprob:  0.358604, 0.085938 (1.443 sec)
35.336... logprob:  0.444872, 0.125000 (1.457 sec)
35.337... logprob:  0.566376, 0.164062 (1.418 sec)
35.338... logprob:  0.449517, 0.125000 (1.422 sec)
35.339... logprob:  0.488539, 0.132812 (1.436 sec)
35.340... logprob:  0.442059, 0.117188 (1.433 sec)
35.341... logprob:  0.529973, 0.148438 (1.424 sec)
35.342... logprob:  0.429577, 0.109375 (1.478 sec)
35.343... logprob:  0.434761, 0.109375 (1.438 sec)
35.344... logprob:  0.444567, 0.125000 (1.481 sec)
35.345... logprob:  0.488157, 0.132812 (1.443 sec)
35.346... logprob:  0.436198, 0.117188 (1.436 sec)
35.347... logprob:  0.372632, 0.085938 (1.486 sec)
35.348... logprob:  0.398520, 0.101562 (1.434 sec)
35.349... logprob:  0.497479, 0.140625 (1.434 sec)
35.350... logprob:  0.358786, 0.085938 (1.438 sec)
35.351... logprob:  0.508407, 0.140625 (1.431 sec)
35.352... logprob:  0.363596, 0.093750 (1.436 sec)
35.353... logprob:  0.512298, 0.148438 (1.487 sec)
35.354... logprob:  0.674632, 0.203125 (1.436 sec)
35.355... logprob:  0.357515, 0.085938 (1.445 sec)
35.356... logprob:  0.479237, 0.132812 (1.478 sec)
35.357... logprob:  0.346605, 0.085938 (1.437 sec)
35.358... logprob:  0.325637, 0.070312 (1.437 sec)
35.359... logprob:  0.555451, 0.164062 (1.435 sec)
35.360... logprob:  0.444532, 0.117188 (1.430 sec)
35.361... logprob:  0.410714, 0.101562 (1.433 sec)
35.362... logprob:  0.423864, 0.117188 (1.482 sec)
35.363... logprob:  0.486605, 0.132812 (1.440 sec)
35.364... logprob:  0.475650, 0.125000 (1.455 sec)
35.365... logprob:  0.425023, 0.109375 (1.466 sec)
35.366... logprob:  0.409511, 0.109375 (1.448 sec)
35.367... logprob:  0.324849, 0.078125 (1.437 sec)
35.368... logprob:  0.595510, 0.171875 (1.434 sec)
35.369... logprob:  0.381713, 0.093750 (1.424 sec)
35.370... logprob:  0.381352, 0.093750 (1.445 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.84552001953125, 10.0]}, 128)
batch 872: ({'logprob': [66.4687271118164, 19.0]}, 128)
batch 873: ({'logprob': [40.68398666381836, 9.0]}, 128)
batch 874: ({'logprob': [45.29356384277344, 11.0]}, 128)
batch 875: ({'logprob': [50.797908782958984, 13.0]}, 128)
batch 876: ({'logprob': [63.970191955566406, 18.0]}, 128)
batch 877: ({'logprob': [45.75450134277344, 11.0]}, 128)
batch 878: ({'logprob': [61.869747161865234, 17.0]}, 128)
batch 879: ({'logprob': [73.34017944335938, 21.0]}, 128)
batch 880: ({'logprob': [50.827510833740234, 13.0]}, 128)
batch 881: ({'logprob': [29.173120498657227, 5.0]}, 128)
batch 882: ({'logprob': [54.712154388427734, 14.0]}, 128)
batch 883: ({'logprob': [61.83821487426758, 17.0]}, 128)
batch 884: ({'logprob': [51.26176834106445, 13.0]}, 128)
batch 885: ({'logprob': [52.160865783691406, 13.0]}, 128)
batch 886: ({'logprob': [62.3156623840332, 17.0]}, 128)

======================Test output======================
logprob:  0.416169, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956267e-03 [2.933398e-09] 
Layer 'conv1' biases: 4.729821e-07 [7.546218e-11] 
Layer 'conv2' weights[0]: 7.943418e-03 [2.420028e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.793204e-10] 
Layer 'conv3' weights[0]: 7.941622e-03 [2.213892e-09] 
Layer 'conv3' biases: 3.985935e-06 [1.174920e-09] 
Layer 'conv4' weights[0]: 7.974290e-03 [2.164638e-09] 
Layer 'conv4' biases: 9.999990e-01 [9.374477e-09] 
Layer 'conv5' weights[0]: 7.972988e-03 [5.448546e-08] 
Layer 'conv5' biases: 9.999886e-01 [5.840030e-08] 
Layer 'fc6' weights[0]: 7.569550e-03 [4.549842e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.536921e-09] 
Layer 'fc7' weights[0]: 6.745774e-03 [1.008887e-07] 
Layer 'fc7' biases: 9.998518e-01 [8.742237e-08] 
Layer 'fc8' weights[0]: 1.270215e-03 [6.379583e-06] 
Layer 'fc8' biases: 8.729653e-02 [4.511717e-05] 
Train error last 870 batches: 0.435161
-------------------------------------------------------
Not saving because 0.416169 > 0.415638 (32.630: -0.00%)
======================================================= (12.067 sec)
35.371... logprob:  0.400458, 0.101562 (1.465 sec)
35.372... logprob:  0.537070, 0.156250 (1.462 sec)
35.373... logprob:  0.463770, 0.125000 (1.457 sec)
35.374... logprob:  0.526710, 0.148438 (1.452 sec)
35.375... logprob:  0.393761, 0.101562 (1.468 sec)
35.376... logprob:  0.374283, 0.093750 (1.440 sec)
35.377... logprob:  0.295473, 0.062500 (1.423 sec)
35.378... logprob:  0.453616, 0.125000 (1.437 sec)
35.379... logprob:  0.420249, 0.109375 (1.435 sec)
35.380... logprob:  0.605618, 0.179688 (1.445 sec)
35.381... logprob:  0.463387, 0.125000 (1.471 sec)
35.382... logprob:  0.529613, 0.148438 (1.449 sec)
35.383... logprob:  0.358464, 0.085938 (1.444 sec)
35.384... logprob:  0.521288, 0.148438 (1.479 sec)
35.385... logprob:  0.523642, 0.148438 (1.439 sec)
35.386... logprob:  0.582700, 0.171875 (1.432 sec)
35.387... logprob:  0.428426, 0.117188 (1.436 sec)
35.388... logprob:  0.521415, 0.148438 (1.442 sec)
35.389... logprob:  0.425415, 0.109375 (1.431 sec)
35.390... logprob:  0.419543, 0.109375 (1.483 sec)
35.391... logprob:  0.318013, 0.070312 (1.443 sec)
35.392... logprob:  0.439452, 0.117188 (1.439 sec)
35.393... logprob:  0.369103, 0.093750 (1.489 sec)
35.394... logprob:  0.343804, 0.078125 (1.434 sec)
35.395... logprob:  0.332071, 0.078125 (1.433 sec)
35.396... logprob:  0.252947, 0.046875 (1.436 sec)
35.397... logprob:  0.483803, 0.132812 (1.431 sec)
35.398... logprob:  0.470301, 0.125000 (1.440 sec)
35.399... logprob:  0.432888, 0.117188 (1.485 sec)
35.400... logprob:  0.536861, 0.148438 (1.438 sec)
35.401... logprob:  0.465350, 0.125000 (1.440 sec)
35.402... logprob:  0.473585, 0.125000 (1.492 sec)
35.403... logprob:  0.462007, 0.125000 (1.432 sec)
35.404... logprob:  0.474774, 0.125000 (1.437 sec)
35.405... logprob:  0.544459, 0.156250 (1.437 sec)
35.406... logprob:  0.357376, 0.085938 (1.438 sec)
35.407... logprob:  0.493213, 0.140625 (1.432 sec)
35.408... logprob:  0.338426, 0.078125 (1.483 sec)
35.409... logprob:  0.400117, 0.101562 (1.444 sec)
35.410... logprob:  0.582607, 0.171875 (1.452 sec)
35.411... logprob:  0.397446, 0.101562 (1.471 sec)
35.412... logprob:  0.540395, 0.156250 (1.438 sec)
35.413... logprob:  0.544646, 0.156250 (1.441 sec)
35.414... logprob:  0.466240, 0.125000 (1.433 sec)
35.415... logprob:  0.401548, 0.101562 (1.425 sec)
35.416... logprob:  0.427430, 0.109375 (1.471 sec)
35.417... logprob:  0.405456, 0.093750 (1.468 sec)
35.418... logprob:  0.380641, 0.093750 (1.452 sec)
35.419... logprob:  0.418035, 0.101562 (1.447 sec)
35.420... logprob:  0.356800, 0.085938 (1.456 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.756858825683594, 10.0]}, 128)
batch 872: ({'logprob': [66.35655975341797, 19.0]}, 128)
batch 873: ({'logprob': [40.830501556396484, 9.0]}, 128)
batch 874: ({'logprob': [45.307193756103516, 11.0]}, 128)
batch 875: ({'logprob': [50.81428146362305, 13.0]}, 128)
batch 876: ({'logprob': [63.89012145996094, 18.0]}, 128)
batch 877: ({'logprob': [45.835777282714844, 11.0]}, 128)
batch 878: ({'logprob': [61.890159606933594, 17.0]}, 128)
batch 879: ({'logprob': [73.43216705322266, 21.0]}, 128)
batch 880: ({'logprob': [50.84336471557617, 13.0]}, 128)
batch 881: ({'logprob': [29.24798011779785, 5.0]}, 128)
batch 882: ({'logprob': [54.897926330566406, 14.0]}, 128)
batch 883: ({'logprob': [61.85908889770508, 17.0]}, 128)
batch 884: ({'logprob': [51.34519958496094, 13.0]}, 128)
batch 885: ({'logprob': [52.37934494018555, 13.0]}, 128)
batch 886: ({'logprob': [62.40345001220703, 17.0]}, 128)

======================Test output======================
logprob:  0.416548, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956232e-03 [4.323846e-09] 
Layer 'conv1' biases: 4.740259e-07 [2.164512e-10] 
Layer 'conv2' weights[0]: 7.943374e-03 [4.992213e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.033808e-09] 
Layer 'conv3' weights[0]: 7.941588e-03 [4.898360e-09] 
Layer 'conv3' biases: 3.990797e-06 [2.979343e-09] 
Layer 'conv4' weights[0]: 7.974256e-03 [4.724377e-09] 
Layer 'conv4' biases: 9.999990e-01 [2.482665e-08] 
Layer 'conv5' weights[0]: 7.972949e-03 [1.513329e-07] 
Layer 'conv5' biases: 9.999881e-01 [1.624145e-07] 
Layer 'fc6' weights[0]: 7.569510e-03 [1.223011e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.255916e-08] 
Layer 'fc7' weights[0]: 6.744067e-03 [3.922185e-07] 
Layer 'fc7' biases: 9.998518e-01 [3.828259e-07] 
Layer 'fc8' weights[0]: 1.263365e-03 [1.713866e-05] 
Layer 'fc8' biases: 8.751938e-02 [1.261635e-04] 
Train error last 870 batches: 0.435161
-------------------------------------------------------
Not saving because 0.416548 > 0.415638 (32.630: -0.00%)
======================================================= (12.036 sec)
35.421... logprob:  0.376745, 0.101562 (1.460 sec)
35.422... logprob:  0.521559, 0.148438 (1.448 sec)
35.423... logprob:  0.420692, 0.109375 (1.425 sec)
35.424... logprob:  0.325097, 0.078125 (1.434 sec)
35.425... logprob:  0.306737, 0.070312 (1.438 sec)
35.426... logprob:  0.448793, 0.117188 (1.449 sec)
35.427... logprob:  0.553462, 0.156250 (1.468 sec)
35.428... logprob:  0.601075, 0.171875 (1.458 sec)
35.429... logprob:  0.426379, 0.109375 (1.447 sec)
35.430... logprob:  0.299683, 0.070312 (1.476 sec)
35.431... logprob:  0.600415, 0.171875 (1.439 sec)
35.432... logprob:  0.387501, 0.093750 (1.425 sec)
35.433... logprob:  0.329288, 0.078125 (1.436 sec)
35.434... logprob:  0.529955, 0.148438 (1.440 sec)
35.435... logprob:  0.532800, 0.156250 (1.432 sec)
35.436... logprob:  0.380589, 0.093750 (1.479 sec)
35.437... logprob:  0.500409, 0.140625 (1.447 sec)
35.438... logprob:  0.547150, 0.156250 (1.434 sec)
35.439... logprob:  0.378221, 0.093750 (1.490 sec)
35.440... logprob:  0.439512, 0.117188 (1.433 sec)
35.441... logprob:  0.467887, 0.125000 (1.436 sec)
35.442... logprob:  0.378887, 0.093750 (1.444 sec)
35.443... logprob:  0.496546, 0.140625 (1.431 sec)
35.444... logprob:  0.372567, 0.093750 (1.439 sec)
35.445... logprob:  0.362884, 0.085938 (1.480 sec)
35.446... logprob:  0.398560, 0.101562 (1.442 sec)
35.447... logprob:  0.569054, 0.164062 (1.439 sec)
35.448... logprob:  0.333322, 0.078125 (1.484 sec)
35.449... logprob:  0.400075, 0.101562 (1.440 sec)
35.450... logprob:  0.240280, 0.046875 (1.438 sec)
35.451... logprob:  0.452221, 0.125000 (1.437 sec)
35.452... logprob:  0.455772, 0.117188 (1.430 sec)
35.453... logprob:  0.454836, 0.125000 (1.434 sec)
35.454... logprob:  0.488637, 0.132812 (1.490 sec)
35.455... logprob:  0.505902, 0.140625 (1.434 sec)
35.456... logprob:  0.468836, 0.125000 (1.451 sec)
35.457... logprob:  0.375292, 0.093750 (1.477 sec)
35.458... logprob:  0.350852, 0.085938 (1.442 sec)
35.459... logprob:  0.514296, 0.140625 (1.442 sec)
35.460... logprob:  0.273211, 0.054688 (1.434 sec)
35.461... logprob:  0.460225, 0.125000 (1.426 sec)
35.462... logprob:  0.472068, 0.125000 (1.435 sec)
35.463... logprob:  0.420736, 0.109375 (1.473 sec)
35.464... logprob:  0.482876, 0.132812 (1.452 sec)
35.465... logprob:  0.421037, 0.109375 (1.455 sec)
35.466... logprob:  0.318035, 0.070312 (1.457 sec)
35.467... logprob:  0.413792, 0.109375 (1.456 sec)
35.468... logprob:  0.394233, 0.101562 (1.437 sec)
35.469... logprob:  0.334838, 0.078125 (1.432 sec)
35.470... logprob:  0.400126, 0.101562 (1.426 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.57861328125, 10.0]}, 128)
batch 872: ({'logprob': [66.8167495727539, 19.0]}, 128)
batch 873: ({'logprob': [40.30064010620117, 9.0]}, 128)
batch 874: ({'logprob': [45.07358169555664, 11.0]}, 128)
batch 875: ({'logprob': [50.71240234375, 13.0]}, 128)
batch 876: ({'logprob': [64.24382019042969, 18.0]}, 128)
batch 877: ({'logprob': [45.51982498168945, 11.0]}, 128)
batch 878: ({'logprob': [62.05424118041992, 17.0]}, 128)
batch 879: ({'logprob': [73.78109741210938, 21.0]}, 128)
batch 880: ({'logprob': [50.74198913574219, 13.0]}, 128)
batch 881: ({'logprob': [28.533130645751953, 5.0]}, 128)
batch 882: ({'logprob': [54.65968704223633, 14.0]}, 128)
batch 883: ({'logprob': [62.02289581298828, 17.0]}, 128)
batch 884: ({'logprob': [51.16352081298828, 13.0]}, 128)
batch 885: ({'logprob': [52.03438949584961, 13.0]}, 128)
batch 886: ({'logprob': [62.48678207397461, 17.0]}, 128)

======================Test output======================
logprob:  0.415881, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956197e-03 [3.783901e-09] 
Layer 'conv1' biases: 4.749864e-07 [1.218096e-10] 
Layer 'conv2' weights[0]: 7.943332e-03 [3.193301e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.781109e-10] 
Layer 'conv3' weights[0]: 7.941552e-03 [2.952732e-09] 
Layer 'conv3' biases: 4.000115e-06 [1.640108e-09] 
Layer 'conv4' weights[0]: 7.974217e-03 [3.010628e-09] 
Layer 'conv4' biases: 9.999990e-01 [1.370526e-08] 
Layer 'conv5' weights[0]: 7.972905e-03 [8.498671e-08] 
Layer 'conv5' biases: 9.999882e-01 [9.114252e-08] 
Layer 'fc6' weights[0]: 7.569469e-03 [6.948961e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.053787e-09] 
Layer 'fc7' weights[0]: 6.742328e-03 [2.185635e-07] 
Layer 'fc7' biases: 9.998519e-01 [2.084920e-07] 
Layer 'fc8' weights[0]: 1.272868e-03 [8.192371e-06] 
Layer 'fc8' biases: 8.790509e-02 [5.939338e-05] 
Train error last 870 batches: 0.435160
-------------------------------------------------------
Not saving because 0.415881 > 0.415638 (32.630: -0.00%)
======================================================= (12.149 sec)
35.471... logprob:  0.529025, 0.148438 (1.456 sec)
35.472... logprob:  0.409939, 0.109375 (1.460 sec)
35.473... logprob:  0.375549, 0.093750 (1.459 sec)
35.474... logprob:  0.465369, 0.125000 (1.452 sec)
35.475... logprob:  0.503637, 0.140625 (1.452 sec)
35.476... logprob:  0.509969, 0.140625 (1.473 sec)
35.477... logprob:  0.334737, 0.078125 (1.436 sec)
35.478... logprob:  0.464192, 0.125000 (1.426 sec)
35.479... logprob:  0.305787, 0.070312 (1.437 sec)
35.480... logprob:  0.443491, 0.117188 (1.437 sec)
35.481... logprob:  0.547828, 0.156250 (1.439 sec)
35.482... logprob:  0.443114, 0.117188 (1.474 sec)
35.483... logprob:  0.502757, 0.140625 (1.453 sec)
35.484... logprob:  0.485342, 0.132812 (1.442 sec)
35.485... logprob:  0.408837, 0.109375 (1.489 sec)
35.486... logprob:  0.361098, 0.085938 (1.432 sec)
35.487... logprob:  0.522757, 0.148438 (1.434 sec)
35.488... logprob:  0.424620, 0.109375 (1.441 sec)
35.489... logprob:  0.415745, 0.109375 (1.440 sec)
35.490... logprob:  0.440676, 0.117188 (1.430 sec)
35.491... logprob:  0.313524, 0.070312 (1.487 sec)
35.492... logprob:  0.459487, 0.125000 (1.447 sec)
35.493... logprob:  0.521726, 0.148438 (1.436 sec)
35.494... logprob:  0.450330, 0.125000 (1.499 sec)
35.495... logprob:  0.380749, 0.093750 (1.434 sec)
35.496... logprob:  0.550051, 0.156250 (1.435 sec)
35.497... logprob:  0.466822, 0.125000 (1.439 sec)
35.498... logprob:  0.476150, 0.132812 (1.436 sec)
35.499... logprob:  0.456197, 0.125000 (1.432 sec)
35.500... logprob:  0.355209, 0.085938 (1.495 sec)
35.501... logprob:  0.339147, 0.078125 (1.438 sec)
35.502... logprob:  0.459572, 0.125000 (1.448 sec)
35.503... logprob:  0.400651, 0.101562 (1.476 sec)
35.504... logprob:  0.487241, 0.132812 (1.435 sec)
35.505... logprob:  0.570733, 0.164062 (1.441 sec)
35.506... logprob:  0.479684, 0.132812 (1.442 sec)
35.507... logprob:  0.384974, 0.093750 (1.429 sec)
35.508... logprob:  0.374608, 0.093750 (1.435 sec)
35.509... logprob:  0.322883, 0.070312 (1.479 sec)
35.510... logprob:  0.390442, 0.101562 (1.444 sec)
35.511... logprob:  0.410026, 0.109375 (1.453 sec)
35.512... logprob:  0.470703, 0.125000 (1.463 sec)
35.513... logprob:  0.324953, 0.078125 (1.450 sec)
35.514... logprob:  0.406270, 0.101562 (1.438 sec)
35.515... logprob:  0.455399, 0.125000 (1.433 sec)
35.516... logprob:  0.400182, 0.109375 (1.427 sec)
35.517... logprob:  0.627586, 0.179688 (1.436 sec)
35.518... logprob:  0.437609, 0.117188 (1.464 sec)
35.519... logprob:  0.516122, 0.140625 (1.456 sec)
35.520... logprob:  0.409635, 0.109375 (1.455 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.9261360168457, 10.0]}, 128)
batch 872: ({'logprob': [66.39952850341797, 19.0]}, 128)
batch 873: ({'logprob': [40.779693603515625, 9.0]}, 128)
batch 874: ({'logprob': [45.356834411621094, 11.0]}, 128)
batch 875: ({'logprob': [50.82810974121094, 13.0]}, 128)
batch 876: ({'logprob': [63.91714096069336, 18.0]}, 128)
batch 877: ({'logprob': [45.817527770996094, 11.0]}, 128)
batch 878: ({'logprob': [61.83311462402344, 17.0]}, 128)
batch 879: ({'logprob': [73.236572265625, 21.0]}, 128)
batch 880: ({'logprob': [50.85746383666992, 13.0]}, 128)
batch 881: ({'logprob': [29.336238861083984, 5.0]}, 128)
batch 882: ({'logprob': [54.724422454833984, 14.0]}, 128)
batch 883: ({'logprob': [61.8017578125, 17.0]}, 128)
batch 884: ({'logprob': [51.291263580322266, 13.0]}, 128)
batch 885: ({'logprob': [52.18976974487305, 13.0]}, 128)
batch 886: ({'logprob': [62.27853012084961, 17.0]}, 128)

======================Test output======================
logprob:  0.416296, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956155e-03 [3.620353e-09] 
Layer 'conv1' biases: 4.760806e-07 [8.294823e-11] 
Layer 'conv2' weights[0]: 7.943300e-03 [3.018154e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.740146e-10] 
Layer 'conv3' weights[0]: 7.941515e-03 [2.400597e-09] 
Layer 'conv3' biases: 4.014772e-06 [1.400193e-09] 
Layer 'conv4' weights[0]: 7.974180e-03 [2.307089e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.009830e-08] 
Layer 'conv5' weights[0]: 7.972871e-03 [6.119038e-08] 
Layer 'conv5' biases: 9.999888e-01 [6.564358e-08] 
Layer 'fc6' weights[0]: 7.569431e-03 [5.074704e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.110980e-09] 
Layer 'fc7' weights[0]: 6.740617e-03 [2.280131e-07] 
Layer 'fc7' biases: 9.998518e-01 [2.190045e-07] 
Layer 'fc8' weights[0]: 1.258060e-03 [8.619986e-06] 
Layer 'fc8' biases: 8.786955e-02 [5.717223e-05] 
Train error last 870 batches: 0.435160
-------------------------------------------------------
Not saving because 0.416296 > 0.415638 (32.630: -0.00%)
======================================================= (12.039 sec)
35.521... logprob:  0.427379, 0.109375 (1.457 sec)
35.522... logprob:  0.533229, 0.156250 (1.470 sec)
35.523... logprob:  0.331332, 0.078125 (1.441 sec)
35.524... logprob:  0.437096, 0.117188 (1.427 sec)
35.525... logprob:  0.425796, 0.109375 (1.430 sec)
35.526... logprob:  0.351486, 0.078125 (1.438 sec)
35.527... logprob:  0.504601, 0.140625 (1.447 sec)
35.528... logprob:  0.440426, 0.117188 (1.465 sec)
35.529... logprob:  0.352993, 0.085938 (1.456 sec)
35.530... logprob:  0.440260, 0.117188 (1.442 sec)
35.531... logprob:  0.439922, 0.117188 (1.480 sec)
35.532... logprob:  0.467265, 0.125000 (1.433 sec)
35.533... logprob:  0.560111, 0.164062 (1.433 sec)
35.534... logprob:  0.326035, 0.078125 (1.432 sec)
35.535... logprob:  0.551280, 0.156250 (1.441 sec)
35.536... logprob:  0.507183, 0.140625 (1.432 sec)
35.537... logprob:  0.509948, 0.140625 (1.484 sec)
35.538... logprob:  0.486064, 0.132812 (1.439 sec)
35.539... logprob:  0.295970, 0.062500 (1.438 sec)
35.540... logprob:  0.447177, 0.117188 (1.487 sec)
35.541... logprob:  0.388733, 0.101562 (1.438 sec)
35.542... logprob:  0.411192, 0.109375 (1.429 sec)
35.543... logprob:  0.233096, 0.039062 (1.440 sec)
35.544... logprob:  0.317910, 0.070312 (1.431 sec)
35.545... logprob:  0.348792, 0.085938 (1.438 sec)
35.546... logprob:  0.368260, 0.093750 (1.499 sec)
35.547... logprob:  0.439936, 0.117188 (1.438 sec)
35.548... logprob:  0.452697, 0.125000 (1.445 sec)
35.549... logprob:  0.490252, 0.132812 (1.480 sec)
35.550... logprob:  0.367561, 0.093750 (1.435 sec)
35.551... logprob:  0.441534, 0.117188 (1.438 sec)
35.552... logprob:  0.471201, 0.125000 (1.437 sec)
35.553... logprob:  0.349453, 0.085938 (1.431 sec)
35.554... logprob:  0.507063, 0.140625 (1.431 sec)
35.555... logprob:  0.421408, 0.109375 (1.486 sec)
35.556... logprob:  0.355700, 0.085938 (1.436 sec)
35.557... logprob:  0.396294, 0.101562 (1.454 sec)
35.558... logprob:  0.382976, 0.101562 (1.472 sec)
35.559... logprob:  0.441711, 0.125000 (1.440 sec)
35.560... logprob:  0.334865, 0.078125 (1.436 sec)
35.561... logprob:  0.411763, 0.109375 (1.438 sec)
35.562... logprob:  0.503190, 0.140625 (1.423 sec)
35.563... logprob:  0.373699, 0.093750 (1.436 sec)
35.564... logprob:  0.468529, 0.132812 (1.465 sec)
35.565... logprob:  0.611235, 0.187500 (1.450 sec)
35.566... logprob:  0.374838, 0.093750 (1.451 sec)
35.567... logprob:  0.423233, 0.109375 (1.463 sec)
35.568... logprob:  0.496306, 0.140625 (1.454 sec)
35.569... logprob:  0.507602, 0.140625 (1.443 sec)
35.570... logprob:  0.543828, 0.164062 (1.431 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.52323532104492, 10.0]}, 128)
batch 872: ({'logprob': [65.68801879882812, 19.0]}, 128)
batch 873: ({'logprob': [42.49925231933594, 9.0]}, 128)
batch 874: ({'logprob': [46.24869918823242, 11.0]}, 128)
batch 875: ({'logprob': [51.46392822265625, 13.0]}, 128)
batch 876: ({'logprob': [63.475196838378906, 18.0]}, 128)
batch 877: ({'logprob': [46.99496078491211, 11.0]}, 128)
batch 878: ({'logprob': [61.948726654052734, 17.0]}, 128)
batch 879: ({'logprob': [73.11509704589844, 21.0]}, 128)
batch 880: ({'logprob': [51.491180419921875, 13.0]}, 128)
batch 881: ({'logprob': [31.293066024780273, 5.0]}, 128)
batch 882: ({'logprob': [55.93662643432617, 14.0]}, 128)
batch 883: ({'logprob': [61.918678283691406, 17.0]}, 128)
batch 884: ({'logprob': [52.20615768432617, 13.0]}, 128)
batch 885: ({'logprob': [53.672855377197266, 13.0]}, 128)
batch 886: ({'logprob': [62.6761360168457, 17.0]}, 128)

======================Test output======================
logprob:  0.421461, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956126e-03 [3.613154e-09] 
Layer 'conv1' biases: 4.771820e-07 [8.368236e-11] 
Layer 'conv2' weights[0]: 7.943265e-03 [3.108598e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.596248e-10] 
Layer 'conv3' weights[0]: 7.941473e-03 [2.833119e-09] 
Layer 'conv3' biases: 4.024213e-06 [1.690336e-09] 
Layer 'conv4' weights[0]: 7.974144e-03 [2.730074e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.337775e-08] 
Layer 'conv5' weights[0]: 7.972835e-03 [8.219476e-08] 
Layer 'conv5' biases: 9.999887e-01 [8.800309e-08] 
Layer 'fc6' weights[0]: 7.569390e-03 [6.705225e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.817465e-09] 
Layer 'fc7' weights[0]: 6.738902e-03 [1.765904e-07] 
Layer 'fc7' biases: 9.998514e-01 [1.675315e-07] 
Layer 'fc8' weights[0]: 1.228323e-03 [7.230191e-06] 
Layer 'fc8' biases: 8.775165e-02 [4.872961e-05] 
Train error last 870 batches: 0.435159
-------------------------------------------------------
Not saving because 0.421461 > 0.415638 (32.630: -0.00%)
======================================================= (12.036 sec)
35.571... logprob:  0.454892, 0.125000 (1.435 sec)
35.572... logprob:  0.501309, 0.140625 (1.447 sec)
35.573... logprob:  0.512582, 0.148438 (1.447 sec)
35.574... logprob:  0.427968, 0.109375 (1.465 sec)
35.575... logprob:  0.343317, 0.078125 (1.450 sec)
35.576... logprob:  0.427327, 0.109375 (1.450 sec)
35.577... logprob:  0.460761, 0.125000 (1.475 sec)
35.578... logprob:  0.336883, 0.078125 (1.437 sec)
35.579... logprob:  0.442078, 0.117188 (1.427 sec)
35.580... logprob:  0.546474, 0.156250 (1.431 sec)
35.581... logprob:  0.530446, 0.156250 (1.447 sec)
35.582... logprob:  0.437754, 0.125000 (1.442 sec)
35.583... logprob:  0.592202, 0.171875 (1.474 sec)
35.584... logprob:  0.468038, 0.132812 (1.451 sec)
35.585... logprob:  0.349775, 0.085938 (1.434 sec)
35.586... logprob:  0.313028, 0.070312 (1.488 sec)
35.587... logprob:  0.404290, 0.101562 (1.435 sec)
35.588... logprob:  0.418647, 0.117188 (1.432 sec)
35.589... logprob:  0.361091, 0.093750 (1.441 sec)
35.590... logprob:  0.524810, 0.148438 (1.432 sec)
35.591... logprob:  0.397432, 0.101562 (1.435 sec)
35.592... logprob:  0.455696, 0.125000 (1.487 sec)
35.593... logprob:  0.467413, 0.125000 (1.447 sec)
35.594... logprob:  0.352801, 0.085938 (1.440 sec)
35.595... logprob:  0.428659, 0.109375 (1.479 sec)
35.596... logprob:  0.461631, 0.125000 (1.452 sec)
35.597... logprob:  0.397419, 0.101562 (1.443 sec)
35.598... logprob:  0.397212, 0.101562 (1.450 sec)
35.599... logprob:  0.313603, 0.070312 (1.438 sec)
35.600... logprob:  0.340868, 0.085938 (1.440 sec)
35.601... logprob:  0.402170, 0.101562 (1.496 sec)
35.602... logprob:  0.289975, 0.062500 (1.445 sec)
35.603... logprob:  0.267317, 0.054688 (1.458 sec)
35.604... logprob:  0.407533, 0.101562 (1.481 sec)
35.605... logprob:  0.563152, 0.148438 (1.438 sec)
35.606... logprob:  0.295949, 0.070312 (1.450 sec)
35.607... logprob:  0.504586, 0.132812 (1.440 sec)
35.608... logprob:  0.361959, 0.085938 (1.435 sec)
35.609... logprob:  0.357105, 0.085938 (1.455 sec)
35.610... logprob:  0.493221, 0.132812 (1.480 sec)
35.611... logprob:  0.510276, 0.140625 (1.451 sec)
35.612... logprob:  0.448602, 0.117188 (1.462 sec)
35.613... logprob:  0.279158, 0.062500 (1.476 sec)
35.614... logprob:  0.503589, 0.140625 (1.450 sec)
35.615... logprob:  0.350655, 0.085938 (1.451 sec)
35.616... logprob:  0.414938, 0.109375 (1.447 sec)
35.617... logprob:  0.417765, 0.109375 (1.441 sec)
35.618... logprob:  0.547180, 0.156250 (1.457 sec)
35.619... logprob:  0.506201, 0.140625 (1.472 sec)
35.620... logprob:  0.539744, 0.156250 (1.474 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.234737396240234, 10.0]}, 128)
batch 872: ({'logprob': [66.22016906738281, 19.0]}, 128)
batch 873: ({'logprob': [41.671119689941406, 9.0]}, 128)
batch 874: ({'logprob': [46.236392974853516, 11.0]}, 128)
batch 875: ({'logprob': [51.35946273803711, 13.0]}, 128)
batch 876: ({'logprob': [63.827388763427734, 18.0]}, 128)
batch 877: ({'logprob': [46.5299072265625, 11.0]}, 128)
batch 878: ({'logprob': [61.665950775146484, 17.0]}, 128)
batch 879: ({'logprob': [72.20317077636719, 21.0]}, 128)
batch 880: ({'logprob': [51.388572692871094, 13.0]}, 128)
batch 881: ({'logprob': [31.09630584716797, 5.0]}, 128)
batch 882: ({'logprob': [54.65795135498047, 14.0]}, 128)
batch 883: ({'logprob': [61.63465881347656, 17.0]}, 128)
batch 884: ({'logprob': [51.65106201171875, 13.0]}, 128)
batch 885: ({'logprob': [52.21215057373047, 13.0]}, 128)
batch 886: ({'logprob': [61.9410400390625, 17.0]}, 128)

======================Test output======================
logprob:  0.418716, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956081e-03 [5.871763e-09] 
Layer 'conv1' biases: 4.783599e-07 [1.034440e-10] 
Layer 'conv2' weights[0]: 7.943228e-03 [4.390940e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.602830e-10] 
Layer 'conv3' weights[0]: 7.941430e-03 [3.564676e-09] 
Layer 'conv3' biases: 4.034455e-06 [2.052216e-09] 
Layer 'conv4' weights[0]: 7.974108e-03 [3.499808e-09] 
Layer 'conv4' biases: 9.999991e-01 [1.581061e-08] 
Layer 'conv5' weights[0]: 7.972800e-03 [9.795858e-08] 
Layer 'conv5' biases: 9.999891e-01 [1.049678e-07] 
Layer 'fc6' weights[0]: 7.569357e-03 [7.990019e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.105621e-09] 
Layer 'fc7' weights[0]: 6.737249e-03 [2.822977e-07] 
Layer 'fc7' biases: 9.998504e-01 [2.745250e-07] 
Layer 'fc8' weights[0]: 1.234616e-03 [9.720707e-06] 
Layer 'fc8' biases: 8.796636e-02 [6.677146e-05] 
Train error last 870 batches: 0.435159
-------------------------------------------------------
Not saving because 0.418716 > 0.415638 (32.630: -0.00%)
======================================================= (12.344 sec)
35.621... logprob:  0.363418, 0.085938 (1.492 sec)
35.622... logprob:  0.364544, 0.085938 (1.466 sec)
35.623... logprob:  0.423077, 0.109375 (1.481 sec)
35.624... logprob:  0.382478, 0.093750 (1.441 sec)
35.625... logprob:  0.440969, 0.117188 (1.420 sec)
35.626... logprob:  0.438326, 0.117188 (1.438 sec)
35.627... logprob:  0.435804, 0.117188 (1.439 sec)
35.628... logprob:  0.464993, 0.125000 (1.447 sec)
35.629... logprob:  0.372217, 0.093750 (1.484 sec)
35.630... logprob:  0.422395, 0.109375 (1.458 sec)
35.631... logprob:  0.637991, 0.187500 (1.444 sec)
35.632... logprob:  0.399136, 0.101562 (1.493 sec)
35.633... logprob:  0.376163, 0.093750 (1.440 sec)
35.634... logprob:  0.659867, 0.195312 (1.429 sec)
35.635... logprob:  0.374130, 0.093750 (1.435 sec)
35.636... logprob:  0.480271, 0.132812 (1.437 sec)
35.637... logprob:  0.330664, 0.078125 (1.440 sec)
35.638... logprob:  0.515722, 0.140625 (1.476 sec)
35.639... logprob:  0.417982, 0.109375 (1.446 sec)
35.640... logprob:  0.528771, 0.148438 (1.433 sec)
35.641... logprob:  0.410375, 0.109375 (1.487 sec)
35.642... logprob:  0.500950, 0.140625 (1.440 sec)
35.643... logprob:  0.623477, 0.187500 (1.520 sec)
35.644... logprob:  0.320717, 0.070312 (1.439 sec)
35.645... logprob:  0.414419, 0.109375 (1.445 sec)
35.646... logprob:  0.385476, 0.093750 (1.439 sec)
35.647... logprob:  0.456811, 0.125000 (1.490 sec)
35.648... logprob:  0.491299, 0.140625 (1.432 sec)
35.649... logprob:  0.370393, 0.093750 (1.446 sec)
35.650... logprob:  0.414076, 0.109375 (1.478 sec)
35.651... logprob:  0.397456, 0.101562 (1.432 sec)
35.652... logprob:  0.506947, 0.140625 (1.445 sec)
35.653... logprob:  0.547533, 0.156250 (1.442 sec)
35.654... logprob:  0.495944, 0.140625 (1.430 sec)
35.655... logprob:  0.436167, 0.117188 (1.433 sec)
35.656... logprob:  0.416735, 0.109375 (1.477 sec)
35.657... logprob:  0.448945, 0.117188 (1.443 sec)
35.658... logprob:  0.345953, 0.085938 (1.457 sec)
35.659... logprob:  0.464245, 0.125000 (1.475 sec)
35.660... logprob:  0.446107, 0.125000 (1.441 sec)
35.661... logprob:  0.378356, 0.093750 (1.444 sec)
35.662... logprob:  0.469522, 0.132812 (1.458 sec)
35.663... logprob:  0.310787, 0.070312 (1.423 sec)
35.664... logprob:  0.285295, 0.062500 (1.440 sec)
35.665... logprob:  0.401610, 0.101562 (1.466 sec)
35.666... logprob:  0.442005, 0.117188 (1.452 sec)
35.667... logprob:  0.564168, 0.164062 (1.458 sec)
35.668... logprob:  0.497824, 0.140625 (1.449 sec)
35.669... logprob:  0.432835, 0.109375 (1.466 sec)
35.670... logprob:  0.362293, 0.085938 (1.439 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.13825607299805, 10.0]}, 128)
batch 872: ({'logprob': [66.66622161865234, 19.0]}, 128)
batch 873: ({'logprob': [40.654605865478516, 9.0]}, 128)
batch 874: ({'logprob': [45.0384521484375, 11.0]}, 128)
batch 875: ({'logprob': [50.7689094543457, 13.0]}, 128)
batch 876: ({'logprob': [64.16771697998047, 18.0]}, 128)
batch 877: ({'logprob': [45.72465133666992, 11.0]}, 128)
batch 878: ({'logprob': [62.292518615722656, 17.0]}, 128)
batch 879: ({'logprob': [74.43907928466797, 21.0]}, 128)
batch 880: ({'logprob': [50.798072814941406, 13.0]}, 128)
batch 881: ({'logprob': [28.465482711791992, 5.0]}, 128)
batch 882: ({'logprob': [55.36058044433594, 14.0]}, 128)
batch 883: ({'logprob': [62.2610969543457, 17.0]}, 128)
batch 884: ({'logprob': [51.45957565307617, 13.0]}, 128)
batch 885: ({'logprob': [52.80976486206055, 13.0]}, 128)
batch 886: ({'logprob': [62.96476745605469, 17.0]}, 128)

======================Test output======================
logprob:  0.417485, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956051e-03 [3.137965e-09] 
Layer 'conv1' biases: 4.794113e-07 [4.582250e-11] 
Layer 'conv2' weights[0]: 7.943188e-03 [1.947491e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.104072e-10] 
Layer 'conv3' weights[0]: 7.941395e-03 [1.406358e-09] 
Layer 'conv3' biases: 4.040894e-06 [6.164349e-10] 
Layer 'conv4' weights[0]: 7.974073e-03 [1.317015e-09] 
Layer 'conv4' biases: 9.999991e-01 [3.971762e-09] 
Layer 'conv5' weights[0]: 7.972758e-03 [2.305024e-08] 
Layer 'conv5' biases: 9.999885e-01 [2.441423e-08] 
Layer 'fc6' weights[0]: 7.569309e-03 [2.014161e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.873312e-09] 
Layer 'fc7' weights[0]: 6.735447e-03 [8.312080e-08] 
Layer 'fc7' biases: 9.998521e-01 [6.982082e-08] 
Layer 'fc8' weights[0]: 1.280341e-03 [2.477055e-06] 
Layer 'fc8' biases: 8.837081e-02 [1.517491e-05] 
Train error last 870 batches: 0.435159
-------------------------------------------------------
Not saving because 0.417485 > 0.415638 (32.630: -0.00%)
======================================================= (12.064 sec)
35.671... logprob:  0.360883, 0.093750 (1.432 sec)
35.672... logprob:  0.441832, 0.117188 (1.441 sec)
35.673... logprob:  0.436220, 0.117188 (1.445 sec)
35.674... logprob:  0.446613, 0.117188 (1.440 sec)
35.675... logprob:  0.356694, 0.093750 (1.473 sec)
35.676... logprob:  0.450207, 0.125000 (1.449 sec)
35.677... logprob:  0.470999, 0.125000 (1.444 sec)
35.678... logprob:  0.465668, 0.125000 (1.484 sec)
35.679... logprob:  0.454861, 0.125000 (1.433 sec)
35.680... logprob:  0.351611, 0.078125 (1.428 sec)
35.681... logprob:  0.373825, 0.093750 (1.438 sec)
35.682... logprob:  0.340443, 0.078125 (1.438 sec)
35.683... logprob:  0.411626, 0.109375 (1.431 sec)
35.684... logprob:  0.357746, 0.085938 (1.483 sec)
35.685... logprob:  0.286361, 0.054688 (1.451 sec)
35.686... logprob:  0.318945, 0.070312 (1.439 sec)
35.687... logprob:  0.281933, 0.062500 (1.486 sec)
35.688... logprob:  0.323183, 0.078125 (1.435 sec)
35.689... logprob:  0.470670, 0.125000 (1.429 sec)
35.690... logprob:  0.527030, 0.140625 (1.441 sec)
35.691... logprob:  0.515772, 0.140625 (1.430 sec)
35.692... logprob:  0.384528, 0.101562 (1.434 sec)
35.693... logprob:  0.455247, 0.125000 (1.488 sec)
35.694... logprob:  0.330990, 0.078125 (1.436 sec)
35.695... logprob:  0.356983, 0.085938 (1.481 sec)
35.696... logprob:  0.539491, 0.148438 (1.476 sec)
35.697... logprob:  0.465885, 0.125000 (1.440 sec)
35.698... logprob:  0.549320, 0.156250 (1.434 sec)
35.699... logprob:  0.459665, 0.125000 (1.439 sec)
35.700... logprob:  0.433708, 0.117188 (1.427 sec)
35.701... logprob:  0.422732, 0.109375 (1.435 sec)
35.702... logprob:  0.521646, 0.148438 (1.483 sec)
35.703... logprob:  0.404664, 0.101562 (1.443 sec)
35.704... logprob:  0.405696, 0.101562 (1.449 sec)
35.705... logprob:  0.419964, 0.109375 (1.473 sec)
35.706... logprob:  0.468030, 0.125000 (1.443 sec)
35.707... logprob:  0.485294, 0.132812 (1.442 sec)
35.708... logprob:  0.417313, 0.109375 (1.437 sec)
35.709... logprob:  0.422785, 0.109375 (1.424 sec)
35.710... logprob:  0.601713, 0.179688 (1.441 sec)
35.711... logprob:  0.469447, 0.125000 (1.473 sec)
35.712... logprob:  0.341300, 0.078125 (1.453 sec)
35.713... logprob:  0.585928, 0.179688 (1.456 sec)
35.714... logprob:  0.466194, 0.125000 (1.459 sec)
35.715... logprob:  0.417244, 0.109375 (1.453 sec)
35.716... logprob:  0.335665, 0.078125 (1.443 sec)
35.717... logprob:  0.429747, 0.117188 (1.427 sec)
35.718... logprob:  0.490247, 0.132812 (1.430 sec)
35.719... logprob:  0.406169, 0.109375 (1.443 sec)
35.720... logprob:  0.433215, 0.117188 (1.448 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.609771728515625, 10.0]}, 128)
batch 872: ({'logprob': [66.65229797363281, 19.0]}, 128)
batch 873: ({'logprob': [40.468021392822266, 9.0]}, 128)
batch 874: ({'logprob': [45.134559631347656, 11.0]}, 128)
batch 875: ({'logprob': [50.73379898071289, 13.0]}, 128)
batch 876: ({'logprob': [64.115966796875, 18.0]}, 128)
batch 877: ({'logprob': [45.61427307128906, 11.0]}, 128)
batch 878: ({'logprob': [61.99627685546875, 17.0]}, 128)
batch 879: ({'logprob': [73.6762466430664, 21.0]}, 128)
batch 880: ({'logprob': [50.76332473754883, 13.0]}, 128)
batch 881: ({'logprob': [28.746963500976562, 5.0]}, 128)
batch 882: ({'logprob': [54.744075775146484, 14.0]}, 128)
batch 883: ({'logprob': [61.96469497680664, 17.0]}, 128)
batch 884: ({'logprob': [51.21771240234375, 13.0]}, 128)
batch 885: ({'logprob': [52.15500259399414, 13.0]}, 128)
batch 886: ({'logprob': [62.461669921875, 17.0]}, 128)

======================Test output======================
logprob:  0.416042, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.956009e-03 [2.317827e-09] 
Layer 'conv1' biases: 4.802250e-07 [5.062414e-11] 
Layer 'conv2' weights[0]: 7.943149e-03 [1.540931e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.076078e-10] 
Layer 'conv3' weights[0]: 7.941349e-03 [1.312542e-09] 
Layer 'conv3' biases: 4.047704e-06 [5.694449e-10] 
Layer 'conv4' weights[0]: 7.974031e-03 [1.223730e-09] 
Layer 'conv4' biases: 9.999990e-01 [3.299983e-09] 
Layer 'conv5' weights[0]: 7.972724e-03 [1.419749e-08] 
Layer 'conv5' biases: 9.999883e-01 [1.431369e-08] 
Layer 'fc6' weights[0]: 7.569272e-03 [1.283858e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.011176e-09] 
Layer 'fc7' weights[0]: 6.733770e-03 [8.013385e-08] 
Layer 'fc7' biases: 9.998518e-01 [6.603716e-08] 
Layer 'fc8' weights[0]: 1.272686e-03 [4.898374e-06] 
Layer 'fc8' biases: 8.855339e-02 [3.485494e-05] 
Train error last 870 batches: 0.435159
-------------------------------------------------------
Not saving because 0.416042 > 0.415638 (32.630: -0.00%)
======================================================= (12.120 sec)
35.721... logprob:  0.451602, 0.117188 (1.467 sec)
35.722... logprob:  0.537108, 0.156250 (1.457 sec)
35.723... logprob:  0.416523, 0.109375 (1.451 sec)
35.724... logprob:  0.412750, 0.109375 (1.478 sec)
35.725... logprob:  0.494986, 0.140625 (1.434 sec)
35.726... logprob:  0.338263, 0.085938 (1.430 sec)
35.727... logprob:  0.393099, 0.101562 (1.431 sec)
35.728... logprob:  0.421126, 0.109375 (1.450 sec)
35.729... logprob:  0.387430, 0.093750 (1.437 sec)
35.730... logprob:  0.566032, 0.164062 (1.478 sec)
35.731... logprob:  0.450469, 0.125000 (1.444 sec)
35.732... logprob:  0.311306, 0.070312 (1.440 sec)
35.733... logprob:  0.556407, 0.156250 (1.483 sec)
35.734... logprob:  0.340246, 0.078125 (1.437 sec)
35.735... logprob:  0.527328, 0.148438 (1.431 sec)
35.736... logprob:  0.642331, 0.187500 (1.441 sec)
35.737... logprob:  0.516041, 0.148438 (1.434 sec)
35.738... logprob:  0.459362, 0.125000 (1.432 sec)
35.739... logprob:  0.477776, 0.132812 (1.485 sec)
35.740... logprob:  0.339643, 0.078125 (1.441 sec)
35.741... logprob:  0.393496, 0.101562 (1.437 sec)
35.742... logprob:  0.419668, 0.109375 (1.488 sec)
35.743... logprob:  0.364917, 0.085938 (1.431 sec)
35.744... logprob:  0.519080, 0.148438 (1.438 sec)
35.745... logprob:  0.478107, 0.132812 (1.441 sec)
35.746... logprob:  0.440540, 0.117188 (1.435 sec)
35.747... logprob:  0.425596, 0.109375 (1.434 sec)
35.748... logprob:  0.378203, 0.093750 (1.492 sec)
35.749... logprob:  0.420788, 0.109375 (1.432 sec)
35.750... logprob:  0.512683, 0.140625 (1.449 sec)
35.751... logprob:  0.263820, 0.054688 (1.476 sec)
35.752... logprob:  0.522489, 0.140625 (1.434 sec)
35.753... logprob:  0.441104, 0.117188 (1.444 sec)
35.754... logprob:  0.468143, 0.132812 (1.430 sec)
35.755... logprob:  0.507010, 0.140625 (1.432 sec)
35.756... logprob:  0.440844, 0.117188 (1.435 sec)
35.757... logprob:  0.552568, 0.156250 (1.475 sec)
35.758... logprob:  0.393484, 0.101562 (1.449 sec)
35.759... logprob:  0.459708, 0.125000 (1.459 sec)
35.760... logprob:  0.485638, 0.132812 (1.466 sec)
35.761... logprob:  0.418035, 0.109375 (1.448 sec)
35.762... logprob:  0.516119, 0.148438 (1.443 sec)
35.763... logprob:  0.559123, 0.164062 (1.426 sec)
35.764... logprob:  0.503259, 0.140625 (1.431 sec)
35.765... logprob:  0.311387, 0.062500 (1.438 sec)
35.766... logprob:  0.482159, 0.132812 (1.454 sec)
35.767... logprob:  0.371009, 0.085938 (1.464 sec)
35.768... logprob:  0.432613, 0.117188 (1.463 sec)
35.769... logprob:  0.490742, 0.140625 (1.505 sec)
35.770... logprob:  0.403079, 0.101562 (1.479 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.42141342163086, 10.0]}, 128)
batch 872: ({'logprob': [66.16786193847656, 19.0]}, 128)
batch 873: ({'logprob': [41.23817443847656, 9.0]}, 128)
batch 874: ({'logprob': [45.71793746948242, 11.0]}, 128)
batch 875: ({'logprob': [51.02459716796875, 13.0]}, 128)
batch 876: ({'logprob': [63.750850677490234, 18.0]}, 128)
batch 877: ({'logprob': [46.145416259765625, 11.0]}, 128)
batch 878: ({'logprob': [61.69898986816406, 17.0]}, 128)
batch 879: ({'logprob': [72.73798370361328, 21.0]}, 128)
batch 880: ({'logprob': [51.05364227294922, 13.0]}, 128)
batch 881: ({'logprob': [30.159908294677734, 5.0]}, 128)
batch 882: ({'logprob': [54.752532958984375, 14.0]}, 128)
batch 883: ({'logprob': [61.667728424072266, 17.0]}, 128)
batch 884: ({'logprob': [51.4522705078125, 13.0]}, 128)
batch 885: ({'logprob': [52.282752990722656, 13.0]}, 128)
batch 886: ({'logprob': [62.109554290771484, 17.0]}, 128)

======================Test output======================
logprob:  0.417179, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955970e-03 [3.365058e-09] 
Layer 'conv1' biases: 4.812953e-07 [1.443435e-10] 
Layer 'conv2' weights[0]: 7.943112e-03 [2.698299e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.797748e-10] 
Layer 'conv3' weights[0]: 7.941315e-03 [2.782816e-09] 
Layer 'conv3' biases: 4.055980e-06 [1.685283e-09] 
Layer 'conv4' weights[0]: 7.973989e-03 [2.802655e-09] 
Layer 'conv4' biases: 9.999990e-01 [1.450416e-08] 
Layer 'conv5' weights[0]: 7.972690e-03 [9.184888e-08] 
Layer 'conv5' biases: 9.999883e-01 [9.850449e-08] 
Layer 'fc6' weights[0]: 7.569238e-03 [7.431438e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.575877e-09] 
Layer 'fc7' weights[0]: 6.732063e-03 [2.446372e-07] 
Layer 'fc7' biases: 9.998507e-01 [2.349234e-07] 
Layer 'fc8' weights[0]: 1.247646e-03 [8.165873e-06] 
Layer 'fc8' biases: 8.848561e-02 [6.203057e-05] 
Train error last 870 batches: 0.435158
-------------------------------------------------------
Not saving because 0.417179 > 0.415638 (32.630: -0.00%)
======================================================= (12.059 sec)
35.771... logprob:  0.549227, 0.156250 (1.463 sec)
35.772... logprob:  0.414151, 0.109375 (1.448 sec)
35.773... logprob:  0.557378, 0.164062 (1.451 sec)
35.774... logprob:  0.361959, 0.085938 (1.462 sec)
35.775... logprob:  0.407454, 0.101562 (1.460 sec)
35.776... logprob:  0.433104, 0.117188 (1.480 sec)
35.777... logprob:  0.380030, 0.093750 (1.474 sec)
35.778... logprob:  0.433494, 0.117188 (1.475 sec)
35.779... logprob:  0.505224, 0.140625 (1.485 sec)
35.780... logprob:  0.385765, 0.101562 (1.461 sec)
35.781... logprob:  0.369595, 0.085938 (1.446 sec)
35.782... logprob:  0.351362, 0.085938 (1.452 sec)
35.783... logprob:  0.555558, 0.156250 (1.460 sec)
35.784... logprob:  0.440963, 0.117188 (1.462 sec)
35.785... logprob:  0.543840, 0.156250 (1.494 sec)
35.786... logprob:  0.477652, 0.132812 (1.470 sec)
35.787... logprob:  0.546709, 0.156250 (1.464 sec)
35.788... logprob:  0.563524, 0.164062 (1.494 sec)
35.789... logprob:  0.280172, 0.054688 (1.458 sec)
35.790... logprob:  0.407677, 0.101562 (1.447 sec)
35.791... logprob:  0.397664, 0.101562 (1.451 sec)
35.792... logprob:  0.360692, 0.085938 (1.460 sec)
35.793... logprob:  0.369917, 0.085938 (1.458 sec)
35.794... logprob:  0.387106, 0.093750 (1.489 sec)
35.795... logprob:  0.469665, 0.125000 (1.468 sec)
35.796... logprob:  0.423521, 0.109375 (1.459 sec)
35.797... logprob:  0.359002, 0.085938 (1.497 sec)
35.798... logprob:  0.393322, 0.101562 (1.458 sec)
35.799... logprob:  0.332659, 0.078125 (1.449 sec)
35.800... logprob:  0.371655, 0.093750 (1.451 sec)
35.801... logprob:  0.449726, 0.117188 (1.460 sec)
35.802... logprob:  0.422712, 0.109375 (1.456 sec)
35.803... logprob:  0.491100, 0.132812 (1.491 sec)
35.804... logprob:  0.349932, 0.085938 (1.470 sec)
35.805... logprob:  0.452242, 0.117188 (1.455 sec)
35.806... logprob:  0.424162, 0.109375 (1.501 sec)
35.807... logprob:  0.443479, 0.117188 (1.456 sec)
35.808... logprob:  0.462369, 0.125000 (1.450 sec)
35.809... logprob:  0.589967, 0.171875 (1.454 sec)
35.810... logprob:  0.442527, 0.117188 (1.455 sec)
35.811... logprob:  0.460430, 0.125000 (1.454 sec)
35.812... logprob:  0.462298, 0.125000 (1.501 sec)
35.813... logprob:  0.485948, 0.132812 (1.468 sec)
35.814... logprob:  0.477804, 0.132812 (1.453 sec)
35.815... logprob:  0.370994, 0.085938 (1.506 sec)
35.816... logprob:  0.408199, 0.101562 (1.454 sec)
35.817... logprob:  0.425640, 0.109375 (1.454 sec)
35.818... logprob:  0.560050, 0.164062 (1.450 sec)
35.819... logprob:  0.498165, 0.140625 (1.455 sec)
35.820... logprob:  0.421730, 0.109375 (1.457 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.414730072021484, 10.0]}, 128)
batch 872: ({'logprob': [66.1623306274414, 19.0]}, 128)
batch 873: ({'logprob': [41.899845123291016, 9.0]}, 128)
batch 874: ({'logprob': [46.39997863769531, 11.0]}, 128)
batch 875: ({'logprob': [51.47128677368164, 13.0]}, 128)
batch 876: ({'logprob': [63.798561096191406, 18.0]}, 128)
batch 877: ({'logprob': [46.70008087158203, 11.0]}, 128)
batch 878: ({'logprob': [61.67314529418945, 17.0]}, 128)
batch 879: ({'logprob': [72.11267852783203, 21.0]}, 128)
batch 880: ({'logprob': [51.50004196166992, 13.0]}, 128)
batch 881: ({'logprob': [31.42302131652832, 5.0]}, 128)
batch 882: ({'logprob': [54.759483337402344, 14.0]}, 128)
batch 883: ({'logprob': [61.6423225402832, 17.0]}, 128)
batch 884: ({'logprob': [51.768585205078125, 13.0]}, 128)
batch 885: ({'logprob': [52.342899322509766, 13.0]}, 128)
batch 886: ({'logprob': [61.9544792175293, 17.0]}, 128)

======================Test output======================
logprob:  0.419445, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955928e-03 [3.796094e-09] 
Layer 'conv1' biases: 4.825822e-07 [1.514890e-10] 
Layer 'conv2' weights[0]: 7.943072e-03 [2.623462e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.345672e-10] 
Layer 'conv3' weights[0]: 7.941282e-03 [2.491245e-09] 
Layer 'conv3' biases: 4.067661e-06 [1.454170e-09] 
Layer 'conv4' weights[0]: 7.973944e-03 [2.555805e-09] 
Layer 'conv4' biases: 9.999990e-01 [1.302432e-08] 
Layer 'conv5' weights[0]: 7.972654e-03 [8.310106e-08] 
Layer 'conv5' biases: 9.999886e-01 [8.903496e-08] 
Layer 'fc6' weights[0]: 7.569199e-03 [6.696612e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.821390e-09] 
Layer 'fc7' weights[0]: 6.730379e-03 [1.569537e-07] 
Layer 'fc7' biases: 9.998500e-01 [1.463674e-07] 
Layer 'fc8' weights[0]: 1.226565e-03 [4.745002e-06] 
Layer 'fc8' biases: 8.854726e-02 [4.024507e-05] 
Train error last 870 batches: 0.435158
-------------------------------------------------------
Not saving because 0.419445 > 0.415638 (32.630: -0.00%)
======================================================= (12.042 sec)
35.821... logprob:  0.406815, 0.101562 (1.501 sec)
35.822... logprob:  0.441363, 0.117188 (1.468 sec)
35.823... logprob:  0.341447, 0.078125 (1.455 sec)
35.824... logprob:  0.489495, 0.132812 (1.508 sec)
35.825... logprob:  0.288845, 0.062500 (1.457 sec)
35.826... logprob:  0.375717, 0.093750 (1.455 sec)
35.827... logprob:  0.420359, 0.109375 (1.448 sec)
35.828... logprob:  0.442927, 0.117188 (1.457 sec)
35.829... logprob:  0.503350, 0.140625 (1.455 sec)
35.830... logprob:  0.441875, 0.117188 (1.499 sec)
35.831... logprob:  0.513639, 0.140625 (1.460 sec)
35.832... logprob:  0.330847, 0.078125 (1.459 sec)
35.833... logprob:  0.489083, 0.132812 (1.502 sec)
35.834... logprob:  0.433468, 0.117188 (1.484 sec)
35.835... logprob:  0.543117, 0.148438 (1.458 sec)
35.836... logprob:  0.375964, 0.093750 (1.455 sec)
35.837... logprob:  0.313621, 0.070312 (1.447 sec)
35.838... logprob:  0.437067, 0.117188 (1.456 sec)
35.839... logprob:  0.471616, 0.125000 (1.499 sec)
35.840... logprob:  0.555755, 0.156250 (1.458 sec)
35.841... logprob:  0.395836, 0.101562 (1.468 sec)
35.842... logprob:  0.497957, 0.140625 (1.494 sec)
35.843... logprob:  0.465460, 0.125000 (1.452 sec)
35.844... logprob:  0.497710, 0.140625 (1.463 sec)
35.845... logprob:  0.486682, 0.132812 (1.448 sec)
35.846... logprob:  0.468333, 0.125000 (1.453 sec)
35.847... logprob:  0.363517, 0.085938 (1.452 sec)
35.848... logprob:  0.397352, 0.101562 (1.500 sec)
35.849... logprob:  0.360800, 0.085938 (1.461 sec)
35.850... logprob:  0.479341, 0.132812 (1.467 sec)
35.851... logprob:  0.440142, 0.117188 (1.494 sec)
35.852... logprob:  0.545028, 0.156250 (1.453 sec)
35.853... logprob:  0.372165, 0.093750 (1.462 sec)
35.854... logprob:  0.307678, 0.070312 (1.451 sec)
35.855... logprob:  0.484516, 0.132812 (1.447 sec)
35.856... logprob:  0.443600, 0.117188 (1.458 sec)
35.857... logprob:  0.372241, 0.093750 (1.489 sec)
35.858... logprob:  0.396245, 0.101562 (1.467 sec)
35.859... logprob:  0.308047, 0.070312 (1.470 sec)
35.860... logprob:  0.565936, 0.156250 (1.488 sec)
35.861... logprob:  0.417783, 0.109375 (1.458 sec)
35.862... logprob:  0.328782, 0.078125 (1.461 sec)
35.863... logprob:  0.399613, 0.101562 (1.449 sec)
35.864... logprob:  0.451560, 0.117188 (1.445 sec)
35.865... logprob:  0.484762, 0.132812 (1.459 sec)
35.866... logprob:  0.507995, 0.140625 (1.487 sec)
35.867... logprob:  0.503386, 0.140625 (1.555 sec)
35.868... logprob:  0.405105, 0.101562 (1.470 sec)
35.869... logprob:  0.382894, 0.093750 (1.483 sec)
35.870... logprob:  0.552456, 0.156250 (1.404 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.644256591796875, 10.0]}, 128)
batch 872: ({'logprob': [66.30674743652344, 19.0]}, 128)
batch 873: ({'logprob': [41.15997314453125, 9.0]}, 128)
batch 874: ({'logprob': [45.7913932800293, 11.0]}, 128)
batch 875: ({'logprob': [51.06910705566406, 13.0]}, 128)
batch 876: ({'logprob': [63.85917663574219, 18.0]}, 128)
batch 877: ({'logprob': [46.128761291503906, 11.0]}, 128)
batch 878: ({'logprob': [61.68629837036133, 17.0]}, 128)
batch 879: ({'logprob': [72.57878875732422, 21.0]}, 128)
batch 880: ({'logprob': [51.098419189453125, 13.0]}, 128)
batch 881: ({'logprob': [30.228857040405273, 5.0]}, 128)
batch 882: ({'logprob': [54.55781555175781, 14.0]}, 128)
batch 883: ({'logprob': [61.65509796142578, 17.0]}, 128)
batch 884: ({'logprob': [51.40674591064453, 13.0]}, 128)
batch 885: ({'logprob': [52.057315826416016, 13.0]}, 128)
batch 886: ({'logprob': [62.00697708129883, 17.0]}, 128)

======================Test output======================
logprob:  0.417107, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955897e-03 [4.114757e-09] 
Layer 'conv1' biases: 4.838288e-07 [9.630741e-11] 
Layer 'conv2' weights[0]: 7.943028e-03 [2.463386e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.871309e-10] 
Layer 'conv3' weights[0]: 7.941249e-03 [2.329596e-09] 
Layer 'conv3' biases: 4.079038e-06 [1.476122e-09] 
Layer 'conv4' weights[0]: 7.973909e-03 [2.444399e-09] 
Layer 'conv4' biases: 9.999990e-01 [1.257067e-08] 
Layer 'conv5' weights[0]: 7.972615e-03 [8.079773e-08] 
Layer 'conv5' biases: 9.999889e-01 [8.643291e-08] 
Layer 'fc6' weights[0]: 7.569154e-03 [6.514380e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.652455e-09] 
Layer 'fc7' weights[0]: 6.728659e-03 [2.731378e-07] 
Layer 'fc7' biases: 9.998508e-01 [2.650958e-07] 
Layer 'fc8' weights[0]: 1.241192e-03 [9.021349e-06] 
Layer 'fc8' biases: 8.887110e-02 [6.032216e-05] 
Train error last 870 batches: 0.435158
-------------------------------------------------------
Not saving because 0.417107 > 0.415638 (32.630: -0.00%)
======================================================= (12.033 sec)
36.1... logprob:  0.379716, 0.093750 (1.412 sec)
36.2... logprob:  0.448216, 0.117188 (1.457 sec)
36.3... logprob:  0.398133, 0.101562 (1.421 sec)
36.4... logprob:  0.443250, 0.117188 (1.404 sec)
36.5... logprob:  0.443509, 0.117188 (1.433 sec)
36.6... logprob:  0.498978, 0.140625 (1.394 sec)
36.7... logprob:  0.363446, 0.085938 (1.422 sec)
36.8... logprob:  0.419209, 0.109375 (1.397 sec)
36.9... logprob:  0.359104, 0.085938 (1.405 sec)
36.10... logprob:  0.377759, 0.093750 (1.415 sec)
36.11... logprob:  0.335182, 0.078125 (1.453 sec)
36.12... logprob:  0.466100, 0.125000 (1.391 sec)
36.13... logprob:  0.442004, 0.117188 (1.429 sec)
36.14... logprob:  0.444350, 0.117188 (1.402 sec)
36.15... logprob:  0.395404, 0.101562 (1.415 sec)
36.16... logprob:  0.421272, 0.109375 (1.406 sec)
36.17... logprob:  0.515793, 0.140625 (1.401 sec)
36.18... logprob:  0.262157, 0.054688 (1.398 sec)
36.19... logprob:  0.279403, 0.062500 (1.403 sec)
36.20... logprob:  0.421347, 0.109375 (1.406 sec)
36.21... logprob:  0.444011, 0.117188 (1.404 sec)
36.22... logprob:  0.536924, 0.148438 (1.419 sec)
36.23... logprob:  0.533399, 0.148438 (1.420 sec)
36.24... logprob:  0.310275, 0.070312 (1.426 sec)
36.25... logprob:  0.355983, 0.085938 (1.400 sec)
36.26... logprob:  0.463919, 0.125000 (1.449 sec)
36.27... logprob:  0.404437, 0.101562 (1.389 sec)
36.28... logprob:  0.421830, 0.109375 (1.414 sec)
36.29... logprob:  0.395815, 0.101562 (1.425 sec)
36.30... logprob:  0.373945, 0.093750 (1.422 sec)
36.31... logprob:  0.480028, 0.132812 (1.410 sec)
36.32... logprob:  0.457219, 0.125000 (1.391 sec)
36.33... logprob:  0.460683, 0.125000 (1.454 sec)
36.34... logprob:  0.464468, 0.125000 (1.396 sec)
36.35... logprob:  0.316389, 0.070312 (1.406 sec)
36.36... logprob:  0.475792, 0.132812 (1.407 sec)
36.37... logprob:  0.417595, 0.109375 (1.410 sec)
36.38... logprob:  0.392797, 0.101562 (1.423 sec)
36.39... logprob:  0.631134, 0.187500 (1.438 sec)
36.40... logprob:  0.445584, 0.117188 (1.411 sec)
36.41... logprob:  0.353129, 0.085938 (1.431 sec)
36.42... logprob:  0.392122, 0.101562 (1.422 sec)
36.43... logprob:  0.440059, 0.117188 (1.413 sec)
36.44... logprob:  0.518580, 0.148438 (1.437 sec)
36.45... logprob:  0.381699, 0.093750 (1.401 sec)
36.46... logprob:  0.486069, 0.132812 (1.397 sec)
36.47... logprob:  0.331715, 0.078125 (1.393 sec)
36.48... logprob:  0.498972, 0.140625 (1.431 sec)
36.49... logprob:  0.511025, 0.148438 (1.413 sec)
36.50... logprob:  0.393158, 0.101562 (1.426 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.83930206298828, 10.0]}, 128)
batch 872: ({'logprob': [66.2846908569336, 19.0]}, 128)
batch 873: ({'logprob': [40.93348693847656, 9.0]}, 128)
batch 874: ({'logprob': [45.37405776977539, 11.0]}, 128)
batch 875: ({'logprob': [50.847049713134766, 13.0]}, 128)
batch 876: ({'logprob': [63.83609390258789, 18.0]}, 128)
batch 877: ({'logprob': [45.9037971496582, 11.0]}, 128)
batch 878: ({'logprob': [61.854652404785156, 17.0]}, 128)
batch 879: ({'logprob': [73.32920837402344, 21.0]}, 128)
batch 880: ({'logprob': [50.876136779785156, 13.0]}, 128)
batch 881: ({'logprob': [29.4183292388916, 5.0]}, 128)
batch 882: ({'logprob': [54.915931701660156, 14.0]}, 128)
batch 883: ({'logprob': [61.823455810546875, 17.0]}, 128)
batch 884: ({'logprob': [51.37867736816406, 13.0]}, 128)
batch 885: ({'logprob': [52.414833068847656, 13.0]}, 128)
batch 886: ({'logprob': [62.368927001953125, 17.0]}, 128)

======================Test output======================
logprob:  0.416699, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955853e-03 [3.028714e-09] 
Layer 'conv1' biases: 4.849397e-07 [4.392244e-11] 
Layer 'conv2' weights[0]: 7.942991e-03 [2.275309e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.953590e-10] 
Layer 'conv3' weights[0]: 7.941202e-03 [1.490044e-09] 
Layer 'conv3' biases: 4.086393e-06 [5.514673e-10] 
Layer 'conv4' weights[0]: 7.973866e-03 [1.427850e-09] 
Layer 'conv4' biases: 9.999990e-01 [2.356911e-09] 
Layer 'conv5' weights[0]: 7.972573e-03 [1.139021e-08] 
Layer 'conv5' biases: 9.999884e-01 [1.165642e-08] 
Layer 'fc6' weights[0]: 7.569111e-03 [1.155626e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.333278e-10] 
Layer 'fc7' weights[0]: 6.726938e-03 [5.114903e-08] 
Layer 'fc7' biases: 9.998514e-01 [3.227910e-08] 
Layer 'fc8' weights[0]: 1.254816e-03 [6.209522e-06] 
Layer 'fc8' biases: 8.905915e-02 [4.301245e-05] 
Train error last 870 batches: 0.435158
-------------------------------------------------------
Not saving because 0.416699 > 0.415638 (32.630: -0.00%)
======================================================= (12.157 sec)
36.51... logprob:  0.490419, 0.140625 (1.424 sec)
36.52... logprob:  0.525799, 0.148438 (1.412 sec)
36.53... logprob:  0.294641, 0.062500 (1.576 sec)
36.54... logprob:  0.403498, 0.109375 (1.393 sec)
36.55... logprob:  0.331625, 0.078125 (1.399 sec)
36.56... logprob:  0.421551, 0.109375 (1.410 sec)
36.57... logprob:  0.572255, 0.164062 (1.428 sec)
36.58... logprob:  0.407409, 0.101562 (1.404 sec)
36.59... logprob:  0.333863, 0.078125 (1.483 sec)
36.60... logprob:  0.618568, 0.179688 (1.421 sec)
36.61... logprob:  0.382753, 0.093750 (1.425 sec)
36.62... logprob:  0.474815, 0.132812 (1.465 sec)
36.63... logprob:  0.397277, 0.101562 (1.442 sec)
36.64... logprob:  0.450365, 0.125000 (1.421 sec)
36.65... logprob:  0.373414, 0.093750 (1.405 sec)
36.66... logprob:  0.354059, 0.085938 (1.447 sec)
36.67... logprob:  0.295443, 0.062500 (1.393 sec)
36.68... logprob:  0.396793, 0.101562 (1.405 sec)
36.69... logprob:  0.496574, 0.140625 (1.429 sec)
36.70... logprob:  0.325931, 0.078125 (1.431 sec)
36.71... logprob:  0.381787, 0.101562 (1.466 sec)
36.72... logprob:  0.493602, 0.132812 (1.404 sec)
36.73... logprob:  0.447629, 0.117188 (1.425 sec)
36.74... logprob:  0.442468, 0.117188 (1.417 sec)
36.75... logprob:  0.380665, 0.093750 (1.420 sec)
36.76... logprob:  0.412027, 0.109375 (1.432 sec)
36.77... logprob:  0.396346, 0.101562 (1.433 sec)
36.78... logprob:  0.493045, 0.140625 (1.452 sec)
36.79... logprob:  0.456496, 0.125000 (1.405 sec)
36.80... logprob:  0.508137, 0.132812 (1.423 sec)
36.81... logprob:  0.416724, 0.109375 (1.415 sec)
36.82... logprob:  0.230908, 0.039062 (1.429 sec)
36.83... logprob:  0.493886, 0.140625 (1.407 sec)
36.84... logprob:  0.468196, 0.125000 (1.469 sec)
36.85... logprob:  0.431867, 0.117188 (1.426 sec)
36.86... logprob:  0.416890, 0.109375 (1.421 sec)
36.87... logprob:  0.633392, 0.187500 (1.412 sec)
36.88... logprob:  0.534986, 0.156250 (1.413 sec)
36.89... logprob:  0.410492, 0.109375 (1.439 sec)
36.90... logprob:  0.577481, 0.171875 (1.388 sec)
36.91... logprob:  0.348343, 0.078125 (1.399 sec)
36.92... logprob:  0.464457, 0.125000 (1.404 sec)
36.93... logprob:  0.492170, 0.140625 (1.405 sec)
36.94... logprob:  0.428790, 0.109375 (1.405 sec)
36.95... logprob:  0.471826, 0.125000 (1.403 sec)
36.96... logprob:  0.576082, 0.171875 (1.408 sec)
36.97... logprob:  0.430811, 0.117188 (1.393 sec)
36.98... logprob:  0.391325, 0.093750 (1.442 sec)
36.99... logprob:  0.474168, 0.132812 (1.416 sec)
36.100... logprob:  0.310794, 0.070312 (1.400 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.2728385925293, 10.0]}, 128)
batch 872: ({'logprob': [66.09088134765625, 19.0]}, 128)
batch 873: ({'logprob': [41.30586242675781, 9.0]}, 128)
batch 874: ({'logprob': [45.67853546142578, 11.0]}, 128)
batch 875: ({'logprob': [51.008544921875, 13.0]}, 128)
batch 876: ({'logprob': [63.694854736328125, 18.0]}, 128)
batch 877: ({'logprob': [46.17107391357422, 11.0]}, 128)
batch 878: ({'logprob': [61.72894287109375, 17.0]}, 128)
batch 879: ({'logprob': [72.87875366210938, 21.0]}, 128)
batch 880: ({'logprob': [51.03739929199219, 13.0]}, 128)
batch 881: ({'logprob': [30.11638641357422, 5.0]}, 128)
batch 882: ({'logprob': [54.91039276123047, 14.0]}, 128)
batch 883: ({'logprob': [61.69789123535156, 17.0]}, 128)
batch 884: ({'logprob': [51.501068115234375, 13.0]}, 128)
batch 885: ({'logprob': [52.46157455444336, 13.0]}, 128)
batch 886: ({'logprob': [62.20465087890625, 17.0]}, 128)

======================Test output======================
logprob:  0.417363, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955809e-03 [4.787409e-09] 
Layer 'conv1' biases: 4.858900e-07 [1.848937e-10] 
Layer 'conv2' weights[0]: 7.942952e-03 [4.921128e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.002641e-09] 
Layer 'conv3' weights[0]: 7.941158e-03 [4.729942e-09] 
Layer 'conv3' biases: 4.093088e-06 [2.995701e-09] 
Layer 'conv4' weights[0]: 7.973822e-03 [4.853750e-09] 
Layer 'conv4' biases: 9.999989e-01 [2.653956e-08] 
Layer 'conv5' weights[0]: 7.972539e-03 [1.680320e-07] 
Layer 'conv5' biases: 9.999882e-01 [1.800496e-07] 
Layer 'fc6' weights[0]: 7.569072e-03 [1.354514e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.385727e-08] 
Layer 'fc7' weights[0]: 6.725240e-03 [2.873445e-07] 
Layer 'fc7' biases: 9.998509e-01 [2.788693e-07] 
Layer 'fc8' weights[0]: 1.243767e-03 [1.016233e-05] 
Layer 'fc8' biases: 8.904334e-02 [7.417206e-05] 
Train error last 870 batches: 0.435158
-------------------------------------------------------
Not saving because 0.417363 > 0.415638 (32.630: -0.00%)
======================================================= (12.034 sec)
36.101... logprob:  0.311180, 0.062500 (1.453 sec)
36.102... logprob:  0.545639, 0.156250 (1.403 sec)
36.103... logprob:  0.540644, 0.156250 (1.405 sec)
36.104... logprob:  0.388782, 0.101562 (1.405 sec)
36.105... logprob:  0.618938, 0.179688 (1.417 sec)
36.106... logprob:  0.344493, 0.085938 (1.398 sec)
36.107... logprob:  0.335860, 0.078125 (1.437 sec)
36.108... logprob:  0.586860, 0.171875 (1.403 sec)
36.109... logprob:  0.336089, 0.078125 (1.401 sec)
36.110... logprob:  0.564794, 0.164062 (1.405 sec)
36.111... logprob:  0.404631, 0.101562 (1.398 sec)
36.112... logprob:  0.365870, 0.093750 (1.410 sec)
36.113... logprob:  0.354267, 0.085938 (1.402 sec)
36.114... logprob:  0.440203, 0.117188 (1.442 sec)
36.115... logprob:  0.506840, 0.140625 (1.416 sec)
36.116... logprob:  0.393300, 0.101562 (1.403 sec)
36.117... logprob:  0.440394, 0.117188 (1.445 sec)
36.118... logprob:  0.409043, 0.101562 (1.394 sec)
36.119... logprob:  0.346032, 0.085938 (1.398 sec)
36.120... logprob:  0.547132, 0.156250 (1.402 sec)
36.121... logprob:  0.412557, 0.109375 (1.399 sec)
36.122... logprob:  0.519207, 0.148438 (1.449 sec)
36.123... logprob:  0.463633, 0.125000 (1.393 sec)
36.124... logprob:  0.447680, 0.125000 (1.412 sec)
36.125... logprob:  0.501863, 0.140625 (1.406 sec)
36.126... logprob:  0.475691, 0.125000 (1.396 sec)
36.127... logprob:  0.479426, 0.125000 (1.405 sec)
36.128... logprob:  0.422310, 0.109375 (1.422 sec)
36.129... logprob:  0.574875, 0.164062 (1.420 sec)
36.130... logprob:  0.382678, 0.093750 (1.416 sec)
36.131... logprob:  0.495496, 0.132812 (1.409 sec)
36.132... logprob:  0.506351, 0.140625 (1.440 sec)
36.133... logprob:  0.444703, 0.117188 (1.397 sec)
36.134... logprob:  0.401853, 0.101562 (1.398 sec)
36.135... logprob:  0.460159, 0.125000 (1.403 sec)
36.136... logprob:  0.562267, 0.164062 (1.398 sec)
36.137... logprob:  0.462603, 0.125000 (1.392 sec)
36.138... logprob:  0.319452, 0.070312 (1.448 sec)
36.139... logprob:  0.395713, 0.101562 (1.401 sec)
36.140... logprob:  0.559817, 0.164062 (1.419 sec)
36.141... logprob:  0.464608, 0.125000 (1.444 sec)
36.142... logprob:  0.464658, 0.125000 (1.397 sec)
36.143... logprob:  0.294524, 0.062500 (1.431 sec)
36.144... logprob:  0.456900, 0.125000 (1.417 sec)
36.145... logprob:  0.324640, 0.078125 (1.417 sec)
36.146... logprob:  0.482991, 0.132812 (1.412 sec)
36.147... logprob:  0.262502, 0.054688 (1.436 sec)
36.148... logprob:  0.458491, 0.125000 (1.396 sec)
36.149... logprob:  0.442465, 0.117188 (1.410 sec)
36.150... logprob:  0.347548, 0.085938 (1.409 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.25544357299805, 10.0]}, 128)
batch 872: ({'logprob': [67.89892578125, 19.0]}, 128)
batch 873: ({'logprob': [39.58903121948242, 9.0]}, 128)
batch 874: ({'logprob': [44.802547454833984, 11.0]}, 128)
batch 875: ({'logprob': [50.743736267089844, 13.0]}, 128)
batch 876: ({'logprob': [65.14203643798828, 18.0]}, 128)
batch 877: ({'logprob': [45.1797981262207, 11.0]}, 128)
batch 878: ({'logprob': [62.696632385253906, 17.0]}, 128)
batch 879: ({'logprob': [74.96570587158203, 21.0]}, 128)
batch 880: ({'logprob': [50.77497100830078, 13.0]}, 128)
batch 881: ({'logprob': [27.27757453918457, 5.0]}, 128)
batch 882: ({'logprob': [54.67688751220703, 14.0]}, 128)
batch 883: ({'logprob': [62.66383743286133, 17.0]}, 128)
batch 884: ({'logprob': [51.131107330322266, 13.0]}, 128)
batch 885: ({'logprob': [51.865875244140625, 13.0]}, 128)
batch 886: ({'logprob': [63.06300354003906, 17.0]}, 128)

======================Test output======================
logprob:  0.416859, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955774e-03 [3.045808e-09] 
Layer 'conv1' biases: 4.868432e-07 [5.396216e-11] 
Layer 'conv2' weights[0]: 7.942917e-03 [1.679619e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.809195e-10] 
Layer 'conv3' weights[0]: 7.941117e-03 [1.246587e-09] 
Layer 'conv3' biases: 4.101392e-06 [4.470716e-10] 
Layer 'conv4' weights[0]: 7.973770e-03 [1.203674e-09] 
Layer 'conv4' biases: 9.999989e-01 [2.408019e-09] 
Layer 'conv5' weights[0]: 7.972502e-03 [1.099155e-08] 
Layer 'conv5' biases: 9.999881e-01 [1.120916e-08] 
Layer 'fc6' weights[0]: 7.569033e-03 [1.113291e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.760130e-10] 
Layer 'fc7' weights[0]: 6.723509e-03 [1.317782e-07] 
Layer 'fc7' biases: 9.998524e-01 [1.203341e-07] 
Layer 'fc8' weights[0]: 1.301195e-03 [8.279518e-06] 
Layer 'fc8' biases: 8.956325e-02 [5.718735e-05] 
Train error last 870 batches: 0.435158
-------------------------------------------------------
Not saving because 0.416859 > 0.415638 (32.630: -0.00%)
======================================================= (12.092 sec)
36.151... logprob:  0.347128, 0.085938 (1.414 sec)
36.152... logprob:  0.785184, 0.234375 (1.407 sec)
36.153... logprob:  0.381629, 0.093750 (1.451 sec)
36.154... logprob:  0.524859, 0.148438 (1.406 sec)
36.155... logprob:  0.426185, 0.117188 (1.413 sec)
36.156... logprob:  0.294863, 0.062500 (1.445 sec)
36.157... logprob:  0.269748, 0.054688 (1.400 sec)
36.158... logprob:  0.455485, 0.125000 (1.405 sec)
36.159... logprob:  0.483142, 0.132812 (1.401 sec)
36.160... logprob:  0.444624, 0.117188 (1.395 sec)
36.161... logprob:  0.349452, 0.078125 (1.404 sec)
36.162... logprob:  0.611804, 0.179688 (1.411 sec)
36.163... logprob:  0.450527, 0.125000 (1.428 sec)
36.164... logprob:  0.468439, 0.125000 (1.421 sec)
36.165... logprob:  0.547674, 0.156250 (1.428 sec)
36.166... logprob:  0.446212, 0.125000 (1.450 sec)
36.167... logprob:  0.350714, 0.085938 (1.433 sec)
36.168... logprob:  0.363785, 0.085938 (1.425 sec)
36.169... logprob:  0.408598, 0.101562 (1.463 sec)
36.170... logprob:  0.459448, 0.125000 (1.401 sec)
36.171... logprob:  0.535109, 0.156250 (1.419 sec)
36.172... logprob:  0.434761, 0.109375 (1.422 sec)
36.173... logprob:  0.440453, 0.117188 (1.427 sec)
36.174... logprob:  0.600435, 0.171875 (1.407 sec)
36.175... logprob:  0.505845, 0.140625 (1.469 sec)
36.176... logprob:  0.478357, 0.132812 (1.418 sec)
36.177... logprob:  0.289722, 0.054688 (1.427 sec)
36.178... logprob:  0.383476, 0.093750 (1.460 sec)
36.179... logprob:  0.394640, 0.101562 (1.410 sec)
36.180... logprob:  0.466397, 0.125000 (1.425 sec)
36.181... logprob:  0.539211, 0.156250 (1.457 sec)
36.182... logprob:  0.371219, 0.093750 (1.420 sec)
36.183... logprob:  0.419921, 0.109375 (1.431 sec)
36.184... logprob:  0.483422, 0.132812 (1.414 sec)
36.185... logprob:  0.289684, 0.062500 (1.398 sec)
36.186... logprob:  0.370276, 0.093750 (1.401 sec)
36.187... logprob:  0.529616, 0.148438 (1.406 sec)
36.188... logprob:  0.458808, 0.125000 (1.403 sec)
36.189... logprob:  0.440930, 0.117188 (1.392 sec)
36.190... logprob:  0.375807, 0.093750 (1.439 sec)
36.191... logprob:  0.485099, 0.132812 (1.414 sec)
36.192... logprob:  0.519972, 0.148438 (1.425 sec)
36.193... logprob:  0.312420, 0.070312 (1.422 sec)
36.194... logprob:  0.414015, 0.109375 (1.419 sec)
36.195... logprob:  0.286912, 0.062500 (1.406 sec)
36.196... logprob:  0.410411, 0.109375 (1.393 sec)
36.197... logprob:  0.477965, 0.132812 (1.401 sec)
36.198... logprob:  0.355798, 0.085938 (1.408 sec)
36.199... logprob:  0.437195, 0.117188 (1.389 sec)
36.200... logprob:  0.440711, 0.117188 (1.441 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.39434814453125, 10.0]}, 128)
batch 872: ({'logprob': [66.88154602050781, 19.0]}, 128)
batch 873: ({'logprob': [40.26197052001953, 9.0]}, 128)
batch 874: ({'logprob': [44.995338439941406, 11.0]}, 128)
batch 875: ({'logprob': [50.69464111328125, 13.0]}, 128)
batch 876: ({'logprob': [64.30435943603516, 18.0]}, 128)
batch 877: ({'logprob': [45.49183654785156, 11.0]}, 128)
batch 878: ({'logprob': [62.15904998779297, 17.0]}, 128)
batch 879: ({'logprob': [74.05718994140625, 21.0]}, 128)
batch 880: ({'logprob': [50.72489547729492, 13.0]}, 128)
batch 881: ({'logprob': [28.321910858154297, 5.0]}, 128)
batch 882: ({'logprob': [54.79853820800781, 14.0]}, 128)
batch 883: ({'logprob': [62.12687683105469, 17.0]}, 128)
batch 884: ({'logprob': [51.19685363769531, 13.0]}, 128)
batch 885: ({'logprob': [52.16758728027344, 13.0]}, 128)
batch 886: ({'logprob': [62.64201736450195, 17.0]}, 128)

======================Test output======================
logprob:  0.416123, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955733e-03 [4.483643e-09] 
Layer 'conv1' biases: 4.880324e-07 [1.228356e-10] 
Layer 'conv2' weights[0]: 7.942871e-03 [2.643685e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.508107e-10] 
Layer 'conv3' weights[0]: 7.941074e-03 [1.821251e-09] 
Layer 'conv3' biases: 4.111755e-06 [8.226461e-10] 
Layer 'conv4' weights[0]: 7.973726e-03 [1.729677e-09] 
Layer 'conv4' biases: 9.999990e-01 [4.395396e-09] 
Layer 'conv5' weights[0]: 7.972463e-03 [2.662966e-08] 
Layer 'conv5' biases: 9.999883e-01 [2.847947e-08] 
Layer 'fc6' weights[0]: 7.569000e-03 [2.345349e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.218179e-09] 
Layer 'fc7' weights[0]: 6.721782e-03 [5.189944e-08] 
Layer 'fc7' biases: 9.998515e-01 [3.323771e-08] 
Layer 'fc8' weights[0]: 1.282896e-03 [4.427795e-06] 
Layer 'fc8' biases: 8.952396e-02 [3.088462e-05] 
Train error last 870 batches: 0.435157
-------------------------------------------------------
Not saving because 0.416123 > 0.415638 (32.630: -0.00%)
======================================================= (11.996 sec)
36.201... logprob:  0.437084, 0.117188 (1.415 sec)
36.202... logprob:  0.537775, 0.148438 (1.413 sec)
36.203... logprob:  0.420383, 0.109375 (1.446 sec)
36.204... logprob:  0.504123, 0.140625 (1.403 sec)
36.205... logprob:  0.334228, 0.078125 (1.408 sec)
36.206... logprob:  0.361641, 0.093750 (1.404 sec)
36.207... logprob:  0.381700, 0.093750 (1.394 sec)
36.208... logprob:  0.490622, 0.140625 (1.399 sec)
36.209... logprob:  0.334509, 0.078125 (1.422 sec)
36.210... logprob:  0.586218, 0.171875 (1.418 sec)
36.211... logprob:  0.488088, 0.132812 (1.415 sec)
36.212... logprob:  0.526100, 0.148438 (1.412 sec)
36.213... logprob:  0.514526, 0.140625 (1.462 sec)
36.214... logprob:  0.459372, 0.125000 (1.425 sec)
36.215... logprob:  0.396058, 0.101562 (1.421 sec)
36.216... logprob:  0.516822, 0.140625 (1.477 sec)
36.217... logprob:  0.324729, 0.070312 (1.409 sec)
36.218... logprob:  0.463533, 0.125000 (1.427 sec)
36.219... logprob:  0.500194, 0.140625 (1.422 sec)
36.220... logprob:  0.415043, 0.109375 (1.426 sec)
36.221... logprob:  0.399588, 0.101562 (1.415 sec)
36.222... logprob:  0.554317, 0.164062 (1.463 sec)
36.223... logprob:  0.568789, 0.164062 (1.426 sec)
36.224... logprob:  0.406035, 0.101562 (1.433 sec)
36.225... logprob:  0.392033, 0.101562 (1.448 sec)
36.226... logprob:  0.424804, 0.109375 (1.426 sec)
36.227... logprob:  0.452574, 0.125000 (1.432 sec)
36.228... logprob:  0.417162, 0.109375 (1.417 sec)
36.229... logprob:  0.489371, 0.132812 (1.415 sec)
36.230... logprob:  0.459826, 0.125000 (1.445 sec)
36.231... logprob:  0.453455, 0.125000 (1.410 sec)
36.232... logprob:  0.496118, 0.140625 (1.462 sec)
36.233... logprob:  0.466002, 0.132812 (1.432 sec)
36.234... logprob:  0.563900, 0.164062 (1.415 sec)
36.235... logprob:  0.482007, 0.132812 (1.469 sec)
36.236... logprob:  0.425573, 0.109375 (1.406 sec)
36.237... logprob:  0.340721, 0.078125 (1.425 sec)
36.238... logprob:  0.388968, 0.093750 (1.422 sec)
36.239... logprob:  0.478064, 0.132812 (1.424 sec)
36.240... logprob:  0.485794, 0.132812 (1.401 sec)
36.241... logprob:  0.493605, 0.132812 (1.466 sec)
36.242... logprob:  0.341610, 0.078125 (1.438 sec)
36.243... logprob:  0.385982, 0.093750 (1.434 sec)
36.244... logprob:  0.315508, 0.070312 (1.454 sec)
36.245... logprob:  0.494147, 0.132812 (1.426 sec)
36.246... logprob:  0.416819, 0.109375 (1.425 sec)
36.247... logprob:  0.357692, 0.085938 (1.420 sec)
36.248... logprob:  0.308223, 0.070312 (1.424 sec)
36.249... logprob:  0.554115, 0.156250 (1.422 sec)
36.250... logprob:  0.590881, 0.164062 (1.416 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.42506408691406, 10.0]}, 128)
batch 872: ({'logprob': [67.77074432373047, 19.0]}, 128)
batch 873: ({'logprob': [39.62725830078125, 9.0]}, 128)
batch 874: ({'logprob': [44.86465835571289, 11.0]}, 128)
batch 875: ({'logprob': [50.734466552734375, 13.0]}, 128)
batch 876: ({'logprob': [65.02586364746094, 18.0]}, 128)
batch 877: ({'logprob': [45.194580078125, 11.0]}, 128)
batch 878: ({'logprob': [62.54479217529297, 17.0]}, 128)
batch 879: ({'logprob': [74.62334442138672, 21.0]}, 128)
batch 880: ({'logprob': [50.766014099121094, 13.0]}, 128)
batch 881: ({'logprob': [27.506513595581055, 5.0]}, 128)
batch 882: ({'logprob': [54.51271438598633, 14.0]}, 128)
batch 883: ({'logprob': [62.511634826660156, 17.0]}, 128)
batch 884: ({'logprob': [51.07386779785156, 13.0]}, 128)
batch 885: ({'logprob': [51.71317672729492, 13.0]}, 128)
batch 886: ({'logprob': [62.86320495605469, 17.0]}, 128)

======================Test output======================
logprob:  0.416386, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955700e-03 [8.539581e-09] 
Layer 'conv1' biases: 4.891536e-07 [2.280148e-10] 
Layer 'conv2' weights[0]: 7.942835e-03 [6.503496e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.349931e-09] 
Layer 'conv3' weights[0]: 7.941041e-03 [5.918263e-09] 
Layer 'conv3' biases: 4.120250e-06 [4.099554e-09] 
Layer 'conv4' weights[0]: 7.973690e-03 [5.934522e-09] 
Layer 'conv4' biases: 9.999990e-01 [3.452668e-08] 
Layer 'conv5' weights[0]: 7.972428e-03 [2.177710e-07] 
Layer 'conv5' biases: 9.999883e-01 [2.330056e-07] 
Layer 'fc6' weights[0]: 7.568963e-03 [1.776480e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.809070e-08] 
Layer 'fc7' weights[0]: 6.720057e-03 [1.641938e-07] 
Layer 'fc7' biases: 9.998519e-01 [1.550983e-07] 
Layer 'fc8' weights[0]: 1.302799e-03 [8.585125e-06] 
Layer 'fc8' biases: 8.974701e-02 [5.809613e-05] 
Train error last 870 batches: 0.435157
-------------------------------------------------------
Not saving because 0.416386 > 0.415638 (32.630: -0.00%)
======================================================= (12.069 sec)
36.251... logprob:  0.353042, 0.085938 (1.467 sec)
36.252... logprob:  0.348409, 0.085938 (1.427 sec)
36.253... logprob:  0.379258, 0.093750 (1.418 sec)
36.254... logprob:  0.444146, 0.117188 (1.468 sec)
36.255... logprob:  0.351249, 0.085938 (1.402 sec)
36.256... logprob:  0.378927, 0.093750 (1.425 sec)
36.257... logprob:  0.331939, 0.078125 (1.409 sec)
36.258... logprob:  0.415394, 0.109375 (1.428 sec)
36.259... logprob:  0.442320, 0.117188 (1.406 sec)
36.260... logprob:  0.308088, 0.070312 (1.458 sec)
36.261... logprob:  0.392428, 0.101562 (1.438 sec)
36.262... logprob:  0.524423, 0.148438 (1.440 sec)
36.263... logprob:  0.425668, 0.109375 (1.452 sec)
36.264... logprob:  0.374958, 0.093750 (1.429 sec)
36.265... logprob:  0.439608, 0.117188 (1.415 sec)
36.266... logprob:  0.438997, 0.117188 (1.419 sec)
36.267... logprob:  0.422056, 0.109375 (1.418 sec)
36.268... logprob:  0.458944, 0.125000 (1.430 sec)
36.269... logprob:  0.567648, 0.164062 (1.414 sec)
36.270... logprob:  0.542411, 0.156250 (1.464 sec)
36.271... logprob:  0.445527, 0.117188 (1.431 sec)
36.272... logprob:  0.384448, 0.093750 (1.425 sec)
36.273... logprob:  0.500245, 0.140625 (1.468 sec)
36.274... logprob:  0.542495, 0.156250 (1.402 sec)
36.275... logprob:  0.487494, 0.132812 (1.424 sec)
36.276... logprob:  0.389916, 0.093750 (1.423 sec)
36.277... logprob:  0.428539, 0.109375 (1.429 sec)
36.278... logprob:  0.323734, 0.070312 (1.423 sec)
36.279... logprob:  0.325455, 0.070312 (1.464 sec)
36.280... logprob:  0.216475, 0.031250 (1.407 sec)
36.281... logprob:  0.417285, 0.109375 (1.425 sec)
36.282... logprob:  0.411257, 0.109375 (1.417 sec)
36.283... logprob:  0.393672, 0.101562 (1.423 sec)
36.284... logprob:  0.394217, 0.101562 (1.413 sec)
36.285... logprob:  0.450996, 0.117188 (1.445 sec)
36.286... logprob:  0.535620, 0.140625 (1.438 sec)
36.287... logprob:  0.346456, 0.085938 (1.438 sec)
36.288... logprob:  0.329928, 0.078125 (1.444 sec)
36.289... logprob:  0.445662, 0.117188 (1.445 sec)
36.290... logprob:  0.490624, 0.132812 (1.410 sec)
36.291... logprob:  0.439402, 0.117188 (1.425 sec)
36.292... logprob:  0.568041, 0.156250 (1.421 sec)
36.293... logprob:  0.427911, 0.117188 (1.432 sec)
36.294... logprob:  0.355505, 0.085938 (1.403 sec)
36.295... logprob:  0.333928, 0.078125 (1.468 sec)
36.296... logprob:  0.355089, 0.085938 (1.420 sec)
36.297... logprob:  0.394115, 0.101562 (1.424 sec)
36.298... logprob:  0.448334, 0.125000 (1.466 sec)
36.299... logprob:  0.341554, 0.078125 (1.402 sec)
36.300... logprob:  0.406181, 0.101562 (1.424 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.98551559448242, 10.0]}, 128)
batch 872: ({'logprob': [66.19511413574219, 19.0]}, 128)
batch 873: ({'logprob': [41.07882308959961, 9.0]}, 128)
batch 874: ({'logprob': [45.48166275024414, 11.0]}, 128)
batch 875: ({'logprob': [50.90160369873047, 13.0]}, 128)
batch 876: ({'logprob': [63.76938247680664, 18.0]}, 128)
batch 877: ({'logprob': [46.00396728515625, 11.0]}, 128)
batch 878: ({'logprob': [61.802974700927734, 17.0]}, 128)
batch 879: ({'logprob': [73.16307067871094, 21.0]}, 128)
batch 880: ({'logprob': [50.93089294433594, 13.0]}, 128)
batch 881: ({'logprob': [29.678247451782227, 5.0]}, 128)
batch 882: ({'logprob': [54.92424392700195, 14.0]}, 128)
batch 883: ({'logprob': [61.77155685424805, 17.0]}, 128)
batch 884: ({'logprob': [51.42505645751953, 13.0]}, 128)
batch 885: ({'logprob': [52.44536590576172, 13.0]}, 128)
batch 886: ({'logprob': [62.309043884277344, 17.0]}, 128)

======================Test output======================
logprob:  0.416927, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955656e-03 [3.888308e-09] 
Layer 'conv1' biases: 4.904016e-07 [1.006459e-10] 
Layer 'conv2' weights[0]: 7.942796e-03 [4.087648e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.264823e-10] 
Layer 'conv3' weights[0]: 7.941008e-03 [3.544504e-09] 
Layer 'conv3' biases: 4.129664e-06 [1.964654e-09] 
Layer 'conv4' weights[0]: 7.973654e-03 [3.531393e-09] 
Layer 'conv4' biases: 9.999990e-01 [1.626546e-08] 
Layer 'conv5' weights[0]: 7.972380e-03 [9.930993e-08] 
Layer 'conv5' biases: 9.999882e-01 [1.064673e-07] 
Layer 'fc6' weights[0]: 7.568923e-03 [8.107471e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.226019e-09] 
Layer 'fc7' weights[0]: 6.718377e-03 [1.280068e-07] 
Layer 'fc7' biases: 9.998507e-01 [1.158549e-07] 
Layer 'fc8' weights[0]: 1.257426e-03 [3.794623e-06] 
Layer 'fc8' biases: 8.967805e-02 [3.372529e-05] 
Train error last 870 batches: 0.435157
-------------------------------------------------------
Not saving because 0.416927 > 0.415638 (32.630: -0.00%)
======================================================= (12.076 sec)
36.301... logprob:  0.397825, 0.101562 (1.431 sec)
36.302... logprob:  0.591670, 0.179688 (1.427 sec)
36.303... logprob:  0.459426, 0.125000 (1.415 sec)
36.304... logprob:  0.459575, 0.125000 (1.438 sec)
36.305... logprob:  0.455181, 0.125000 (1.444 sec)
36.306... logprob:  0.440559, 0.117188 (1.441 sec)
36.307... logprob:  0.421637, 0.109375 (1.446 sec)
36.308... logprob:  0.374983, 0.093750 (1.455 sec)
36.309... logprob:  0.450486, 0.125000 (1.416 sec)
36.310... logprob:  0.473482, 0.125000 (1.425 sec)
36.311... logprob:  0.502347, 0.140625 (1.432 sec)
36.312... logprob:  0.478610, 0.132812 (1.428 sec)
36.313... logprob:  0.454850, 0.125000 (1.421 sec)
36.314... logprob:  0.454264, 0.117188 (1.468 sec)
36.315... logprob:  0.314710, 0.070312 (1.440 sec)
36.316... logprob:  0.468468, 0.125000 (1.430 sec)
36.317... logprob:  0.355400, 0.085938 (1.484 sec)
36.318... logprob:  0.455393, 0.125000 (1.415 sec)
36.319... logprob:  0.423147, 0.117188 (1.426 sec)
36.320... logprob:  0.412222, 0.109375 (1.427 sec)
36.321... logprob:  0.348213, 0.085938 (1.425 sec)
36.322... logprob:  0.387398, 0.101562 (1.416 sec)
36.323... logprob:  0.416493, 0.109375 (1.482 sec)
36.324... logprob:  0.498589, 0.140625 (1.429 sec)
36.325... logprob:  0.350666, 0.085938 (1.438 sec)
36.326... logprob:  0.543191, 0.148438 (1.464 sec)
36.327... logprob:  0.554445, 0.164062 (1.428 sec)
36.328... logprob:  0.565216, 0.156250 (1.432 sec)
36.329... logprob:  0.401867, 0.101562 (1.433 sec)
36.330... logprob:  0.388419, 0.101562 (1.423 sec)
36.331... logprob:  0.352104, 0.085938 (1.429 sec)
36.332... logprob:  0.482787, 0.132812 (1.458 sec)
36.333... logprob:  0.339365, 0.085938 (1.445 sec)
36.334... logprob:  0.565399, 0.171875 (1.441 sec)
36.335... logprob:  0.358590, 0.085938 (1.440 sec)
36.336... logprob:  0.444874, 0.125000 (1.462 sec)
36.337... logprob:  0.566372, 0.164062 (1.422 sec)
36.338... logprob:  0.449518, 0.125000 (1.425 sec)
36.339... logprob:  0.488531, 0.132812 (1.435 sec)
36.340... logprob:  0.442058, 0.117188 (1.426 sec)
36.341... logprob:  0.529964, 0.148438 (1.420 sec)
36.342... logprob:  0.429573, 0.109375 (1.468 sec)
36.343... logprob:  0.434760, 0.109375 (1.443 sec)
36.344... logprob:  0.444575, 0.125000 (1.481 sec)
36.345... logprob:  0.488152, 0.132812 (1.440 sec)
36.346... logprob:  0.436197, 0.117188 (1.440 sec)
36.347... logprob:  0.372649, 0.085938 (1.486 sec)
36.348... logprob:  0.398526, 0.101562 (1.436 sec)
36.349... logprob:  0.497459, 0.140625 (1.431 sec)
36.350... logprob:  0.358800, 0.085938 (1.438 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.525028228759766, 10.0]}, 128)
batch 872: ({'logprob': [66.43546295166016, 19.0]}, 128)
batch 873: ({'logprob': [40.7584114074707, 9.0]}, 128)
batch 874: ({'logprob': [45.19774627685547, 11.0]}, 128)
batch 875: ({'logprob': [50.77983093261719, 13.0]}, 128)
batch 876: ({'logprob': [63.96034622192383, 18.0]}, 128)
batch 877: ({'logprob': [45.78253936767578, 11.0]}, 128)
batch 878: ({'logprob': [62.006778717041016, 17.0]}, 128)
batch 879: ({'logprob': [73.75495147705078, 21.0]}, 128)
batch 880: ({'logprob': [50.809391021728516, 13.0]}, 128)
batch 881: ({'logprob': [28.968603134155273, 5.0]}, 128)
batch 882: ({'logprob': [55.042388916015625, 14.0]}, 128)
batch 883: ({'logprob': [61.97511291503906, 17.0]}, 128)
batch 884: ({'logprob': [51.367855072021484, 13.0]}, 128)
batch 885: ({'logprob': [52.51421356201172, 13.0]}, 128)
batch 886: ({'logprob': [62.5766716003418, 17.0]}, 128)

======================Test output======================
logprob:  0.416726, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955616e-03 [3.762396e-09] 
Layer 'conv1' biases: 4.913280e-07 [8.477098e-11] 
Layer 'conv2' weights[0]: 7.942762e-03 [2.556506e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.955395e-10] 
Layer 'conv3' weights[0]: 7.940968e-03 [2.313725e-09] 
Layer 'conv3' biases: 4.136439e-06 [1.202643e-09] 
Layer 'conv4' weights[0]: 7.973620e-03 [2.281889e-09] 
Layer 'conv4' biases: 9.999990e-01 [1.020303e-08] 
Layer 'conv5' weights[0]: 7.972340e-03 [6.125782e-08] 
Layer 'conv5' biases: 9.999881e-01 [6.567697e-08] 
Layer 'fc6' weights[0]: 7.568884e-03 [5.048694e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.083654e-09] 
Layer 'fc7' weights[0]: 6.716625e-03 [1.734917e-07] 
Layer 'fc7' biases: 9.998512e-01 [1.634621e-07] 
Layer 'fc8' weights[0]: 1.270007e-03 [9.610626e-06] 
Layer 'fc8' biases: 8.988049e-02 [6.801391e-05] 
Train error last 870 batches: 0.435156
-------------------------------------------------------
Not saving because 0.416726 > 0.415638 (32.630: -0.00%)
======================================================= (12.048 sec)
36.351... logprob:  0.508394, 0.140625 (1.434 sec)
36.352... logprob:  0.363594, 0.093750 (1.442 sec)
36.353... logprob:  0.512271, 0.148438 (1.491 sec)
36.354... logprob:  0.674603, 0.203125 (1.431 sec)
36.355... logprob:  0.357518, 0.085938 (1.449 sec)
36.356... logprob:  0.479237, 0.132812 (1.486 sec)
36.357... logprob:  0.346584, 0.085938 (1.436 sec)
36.358... logprob:  0.325618, 0.070312 (1.444 sec)
36.359... logprob:  0.555464, 0.164062 (1.438 sec)
36.360... logprob:  0.444533, 0.117188 (1.431 sec)
36.361... logprob:  0.410711, 0.101562 (1.433 sec)
36.362... logprob:  0.423849, 0.117188 (1.477 sec)
36.363... logprob:  0.486608, 0.132812 (1.447 sec)
36.364... logprob:  0.475658, 0.125000 (1.451 sec)
36.365... logprob:  0.425021, 0.109375 (1.469 sec)
36.366... logprob:  0.409501, 0.109375 (1.446 sec)
36.367... logprob:  0.324839, 0.078125 (1.443 sec)
36.368... logprob:  0.595503, 0.171875 (1.431 sec)
36.369... logprob:  0.381722, 0.093750 (1.427 sec)
36.370... logprob:  0.381362, 0.093750 (1.436 sec)
36.371... logprob:  0.400464, 0.101562 (1.457 sec)
36.372... logprob:  0.537041, 0.156250 (1.452 sec)
36.373... logprob:  0.463768, 0.125000 (1.458 sec)
36.374... logprob:  0.526692, 0.148438 (1.452 sec)
36.375... logprob:  0.393760, 0.101562 (1.464 sec)
36.376... logprob:  0.374283, 0.093750 (1.440 sec)
36.377... logprob:  0.295481, 0.062500 (1.430 sec)
36.378... logprob:  0.453608, 0.125000 (1.433 sec)
36.379... logprob:  0.420250, 0.109375 (1.439 sec)
36.380... logprob:  0.605607, 0.179688 (1.443 sec)
36.381... logprob:  0.463383, 0.125000 (1.468 sec)
36.382... logprob:  0.529619, 0.148438 (1.455 sec)
36.383... logprob:  0.358453, 0.085938 (1.440 sec)
36.384... logprob:  0.521300, 0.148438 (1.482 sec)
36.385... logprob:  0.523651, 0.148438 (1.436 sec)
36.386... logprob:  0.582721, 0.171875 (1.427 sec)
36.387... logprob:  0.428412, 0.117188 (1.446 sec)
36.388... logprob:  0.521422, 0.148438 (1.436 sec)
36.389... logprob:  0.425390, 0.109375 (1.432 sec)
36.390... logprob:  0.419522, 0.109375 (1.486 sec)
36.391... logprob:  0.317989, 0.070312 (1.443 sec)
36.392... logprob:  0.439452, 0.117188 (1.433 sec)
36.393... logprob:  0.369114, 0.093750 (1.492 sec)
36.394... logprob:  0.343820, 0.078125 (1.433 sec)
36.395... logprob:  0.332099, 0.078125 (1.434 sec)
36.396... logprob:  0.253004, 0.046875 (1.437 sec)
36.397... logprob:  0.483756, 0.132812 (1.464 sec)
36.398... logprob:  0.470244, 0.125000 (1.438 sec)
36.399... logprob:  0.432845, 0.117188 (1.487 sec)
36.400... logprob:  0.536769, 0.148438 (1.435 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.66130065917969, 10.0]}, 128)
batch 872: ({'logprob': [68.65118408203125, 19.0]}, 128)
batch 873: ({'logprob': [39.65736389160156, 9.0]}, 128)
batch 874: ({'logprob': [44.72486877441406, 11.0]}, 128)
batch 875: ({'logprob': [50.99098205566406, 13.0]}, 128)
batch 876: ({'logprob': [65.84976959228516, 18.0]}, 128)
batch 877: ({'logprob': [45.33683395385742, 11.0]}, 128)
batch 878: ({'logprob': [63.59436798095703, 17.0]}, 128)
batch 879: ({'logprob': [76.74750518798828, 21.0]}, 128)
batch 880: ({'logprob': [51.02238464355469, 13.0]}, 128)
batch 881: ({'logprob': [26.45920753479004, 5.0]}, 128)
batch 882: ({'logprob': [55.6760368347168, 14.0]}, 128)
batch 883: ({'logprob': [63.561317443847656, 17.0]}, 128)
batch 884: ({'logprob': [51.61564636230469, 13.0]}, 128)
batch 885: ({'logprob': [52.8206787109375, 13.0]}, 128)
batch 886: ({'logprob': [64.19705963134766, 17.0]}, 128)

======================Test output======================
logprob:  0.420687, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955580e-03 [5.672142e-09] 
Layer 'conv1' biases: 4.924214e-07 [2.140838e-10] 
Layer 'conv2' weights[0]: 7.942727e-03 [6.170337e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.278579e-09] 
Layer 'conv3' weights[0]: 7.940930e-03 [5.618475e-09] 
Layer 'conv3' biases: 4.144771e-06 [3.760192e-09] 
Layer 'conv4' weights[0]: 7.973582e-03 [5.622768e-09] 
Layer 'conv4' biases: 9.999990e-01 [3.158630e-08] 
Layer 'conv5' weights[0]: 7.972301e-03 [1.937245e-07] 
Layer 'conv5' biases: 9.999877e-01 [2.072947e-07] 
Layer 'fc6' weights[0]: 7.568842e-03 [1.588373e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.622253e-08] 
Layer 'fc7' weights[0]: 6.714850e-03 [4.745856e-08] 
Layer 'fc7' biases: 9.998527e-01 [2.774116e-08] 
Layer 'fc8' weights[0]: 1.327766e-03 [4.708070e-06] 
Layer 'fc8' biases: 9.041057e-02 [3.185451e-05] 
Train error last 870 batches: 0.435156
-------------------------------------------------------
Not saving because 0.420687 > 0.415638 (32.630: -0.00%)
======================================================= (12.052 sec)
36.401... logprob:  0.465304, 0.125000 (1.444 sec)
36.402... logprob:  0.473547, 0.125000 (1.488 sec)
36.403... logprob:  0.461993, 0.125000 (1.434 sec)
36.404... logprob:  0.474769, 0.125000 (1.437 sec)
36.405... logprob:  0.544487, 0.156250 (1.437 sec)
36.406... logprob:  0.357350, 0.085938 (1.428 sec)
36.407... logprob:  0.493241, 0.140625 (1.435 sec)
36.408... logprob:  0.338360, 0.078125 (1.484 sec)
36.409... logprob:  0.400073, 0.101562 (1.438 sec)
36.410... logprob:  0.582655, 0.171875 (1.456 sec)
36.411... logprob:  0.397401, 0.101562 (1.613 sec)
36.412... logprob:  0.540407, 0.156250 (1.439 sec)
36.413... logprob:  0.544645, 0.156250 (1.437 sec)
36.414... logprob:  0.466219, 0.125000 (1.435 sec)
36.415... logprob:  0.401530, 0.101562 (1.423 sec)
36.416... logprob:  0.427418, 0.109375 (1.442 sec)
36.417... logprob:  0.405452, 0.093750 (1.463 sec)
36.418... logprob:  0.380667, 0.093750 (1.455 sec)
36.419... logprob:  0.418058, 0.101562 (1.457 sec)
36.420... logprob:  0.356849, 0.085938 (1.457 sec)
36.421... logprob:  0.376761, 0.101562 (1.457 sec)
36.422... logprob:  0.521480, 0.148438 (1.440 sec)
36.423... logprob:  0.420676, 0.109375 (1.429 sec)
36.424... logprob:  0.325127, 0.078125 (1.431 sec)
36.425... logprob:  0.306774, 0.070312 (1.438 sec)
36.426... logprob:  0.448756, 0.117188 (1.446 sec)
36.427... logprob:  0.553369, 0.156250 (1.466 sec)
36.428... logprob:  0.600996, 0.171875 (1.456 sec)
36.429... logprob:  0.426382, 0.109375 (1.443 sec)
36.430... logprob:  0.299671, 0.070312 (1.489 sec)
36.431... logprob:  0.600468, 0.171875 (1.433 sec)
36.432... logprob:  0.387499, 0.093750 (1.430 sec)
36.433... logprob:  0.329239, 0.078125 (1.436 sec)
36.434... logprob:  0.530003, 0.148438 (1.439 sec)
36.435... logprob:  0.532843, 0.156250 (1.433 sec)
36.436... logprob:  0.380536, 0.093750 (1.480 sec)
36.437... logprob:  0.500422, 0.140625 (1.445 sec)
36.438... logprob:  0.547176, 0.156250 (1.434 sec)
36.439... logprob:  0.378161, 0.093750 (1.491 sec)
36.440... logprob:  0.439489, 0.117188 (1.433 sec)
36.441... logprob:  0.467877, 0.125000 (1.434 sec)
36.442... logprob:  0.378877, 0.093750 (1.438 sec)
36.443... logprob:  0.496544, 0.140625 (1.431 sec)
36.444... logprob:  0.372589, 0.093750 (1.435 sec)
36.445... logprob:  0.362921, 0.085938 (1.487 sec)
36.446... logprob:  0.398586, 0.101562 (1.440 sec)
36.447... logprob:  0.568985, 0.164062 (1.441 sec)
36.448... logprob:  0.333371, 0.078125 (1.482 sec)
36.449... logprob:  0.400081, 0.101562 (1.435 sec)
36.450... logprob:  0.240367, 0.046875 (1.434 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.08160400390625, 10.0]}, 128)
batch 872: ({'logprob': [67.50714874267578, 19.0]}, 128)
batch 873: ({'logprob': [39.86687088012695, 9.0]}, 128)
batch 874: ({'logprob': [44.797183990478516, 11.0]}, 128)
batch 875: ({'logprob': [50.70471954345703, 13.0]}, 128)
batch 876: ({'logprob': [64.82887268066406, 18.0]}, 128)
batch 877: ({'logprob': [45.29899978637695, 11.0]}, 128)
batch 878: ({'logprob': [62.587791442871094, 17.0]}, 128)
batch 879: ({'logprob': [74.9105453491211, 21.0]}, 128)
batch 880: ({'logprob': [50.73543167114258, 13.0]}, 128)
batch 881: ({'logprob': [27.50139045715332, 5.0]}, 128)
batch 882: ({'logprob': [54.92997360229492, 14.0]}, 128)
batch 883: ({'logprob': [62.55543899536133, 17.0]}, 128)
batch 884: ({'logprob': [51.215152740478516, 13.0]}, 128)
batch 885: ({'logprob': [52.19818115234375, 13.0]}, 128)
batch 886: ({'logprob': [63.07783508300781, 17.0]}, 128)

======================Test output======================
logprob:  0.416893, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955534e-03 [4.947643e-09] 
Layer 'conv1' biases: 4.934039e-07 [1.747078e-10] 
Layer 'conv2' weights[0]: 7.942688e-03 [5.086605e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.384051e-10] 
Layer 'conv3' weights[0]: 7.940893e-03 [4.582819e-09] 
Layer 'conv3' biases: 4.152994e-06 [2.799721e-09] 
Layer 'conv4' weights[0]: 7.973548e-03 [4.577334e-09] 
Layer 'conv4' biases: 9.999990e-01 [2.333918e-08] 
Layer 'conv5' weights[0]: 7.972271e-03 [1.449615e-07] 
Layer 'conv5' biases: 9.999877e-01 [1.552054e-07] 
Layer 'fc6' weights[0]: 7.568805e-03 [1.173825e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.204455e-08] 
Layer 'fc7' weights[0]: 6.713140e-03 [3.742755e-07] 
Layer 'fc7' biases: 9.998520e-01 [3.651851e-07] 
Layer 'fc8' weights[0]: 1.293917e-03 [1.365078e-05] 
Layer 'fc8' biases: 9.057707e-02 [9.841035e-05] 
Train error last 870 batches: 0.435156
-------------------------------------------------------
Not saving because 0.416893 > 0.415638 (32.630: -0.00%)
======================================================= (12.069 sec)
36.451... logprob:  0.452175, 0.125000 (1.445 sec)
36.452... logprob:  0.455736, 0.117188 (1.440 sec)
36.453... logprob:  0.454793, 0.125000 (1.432 sec)
36.454... logprob:  0.488596, 0.132812 (1.488 sec)
36.455... logprob:  0.505880, 0.140625 (1.444 sec)
36.456... logprob:  0.468833, 0.125000 (1.451 sec)
36.457... logprob:  0.375288, 0.093750 (1.472 sec)
36.458... logprob:  0.350835, 0.085938 (1.440 sec)
36.459... logprob:  0.514331, 0.140625 (1.436 sec)
36.460... logprob:  0.273138, 0.054688 (1.438 sec)
36.461... logprob:  0.460241, 0.125000 (1.429 sec)
36.462... logprob:  0.472080, 0.125000 (1.434 sec)
36.463... logprob:  0.420726, 0.109375 (1.473 sec)
36.464... logprob:  0.482889, 0.132812 (1.448 sec)
36.465... logprob:  0.421027, 0.109375 (1.457 sec)
36.466... logprob:  0.317995, 0.070312 (1.460 sec)
36.467... logprob:  0.413786, 0.109375 (1.455 sec)
36.468... logprob:  0.394228, 0.101562 (1.439 sec)
36.469... logprob:  0.334844, 0.078125 (1.431 sec)
36.470... logprob:  0.400130, 0.101562 (1.427 sec)
36.471... logprob:  0.528996, 0.148438 (1.443 sec)
36.472... logprob:  0.409933, 0.109375 (1.450 sec)
36.473... logprob:  0.375561, 0.093750 (1.462 sec)
36.474... logprob:  0.465346, 0.125000 (1.454 sec)
36.475... logprob:  0.503594, 0.140625 (1.449 sec)
36.476... logprob:  0.509939, 0.140625 (1.471 sec)
36.477... logprob:  0.334753, 0.078125 (1.441 sec)
36.478... logprob:  0.464185, 0.125000 (1.427 sec)
36.479... logprob:  0.305791, 0.070312 (1.433 sec)
36.480... logprob:  0.443489, 0.117188 (1.438 sec)
36.481... logprob:  0.547827, 0.156250 (1.436 sec)
36.482... logprob:  0.443111, 0.117188 (1.475 sec)
36.483... logprob:  0.502765, 0.140625 (1.454 sec)
36.484... logprob:  0.485345, 0.132812 (1.433 sec)
36.485... logprob:  0.408825, 0.109375 (1.487 sec)
36.486... logprob:  0.361070, 0.085938 (1.437 sec)
36.487... logprob:  0.522766, 0.148438 (1.430 sec)
36.488... logprob:  0.424606, 0.109375 (1.437 sec)
36.489... logprob:  0.415733, 0.109375 (1.434 sec)
36.490... logprob:  0.440674, 0.117188 (1.438 sec)
36.491... logprob:  0.313510, 0.070312 (1.481 sec)
36.492... logprob:  0.459481, 0.125000 (1.441 sec)
36.493... logprob:  0.521716, 0.148438 (1.439 sec)
36.494... logprob:  0.450329, 0.125000 (1.488 sec)
36.495... logprob:  0.380758, 0.093750 (1.434 sec)
36.496... logprob:  0.550028, 0.156250 (1.434 sec)
36.497... logprob:  0.466811, 0.125000 (1.438 sec)
36.498... logprob:  0.476141, 0.132812 (1.431 sec)
36.499... logprob:  0.456193, 0.125000 (1.434 sec)
36.500... logprob:  0.355216, 0.085938 (1.490 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.04164123535156, 10.0]}, 128)
batch 872: ({'logprob': [66.29420471191406, 19.0]}, 128)
batch 873: ({'logprob': [40.938316345214844, 9.0]}, 128)
batch 874: ({'logprob': [45.4561882019043, 11.0]}, 128)
batch 875: ({'logprob': [50.879119873046875, 13.0]}, 128)
batch 876: ({'logprob': [63.839141845703125, 18.0]}, 128)
batch 877: ({'logprob': [45.92273712158203, 11.0]}, 128)
batch 878: ({'logprob': [61.78769302368164, 17.0]}, 128)
batch 879: ({'logprob': [73.0993423461914, 21.0]}, 128)
batch 880: ({'logprob': [50.908878326416016, 13.0]}, 128)
batch 881: ({'logprob': [29.58656883239746, 5.0]}, 128)
batch 882: ({'logprob': [54.76493453979492, 14.0]}, 128)
batch 883: ({'logprob': [61.75595474243164, 17.0]}, 128)
batch 884: ({'logprob': [51.34760665893555, 13.0]}, 128)
batch 885: ({'logprob': [52.25675964355469, 13.0]}, 128)
batch 886: ({'logprob': [62.23828887939453, 17.0]}, 128)

======================Test output======================
logprob:  0.416561, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955506e-03 [2.989653e-09] 
Layer 'conv1' biases: 4.944299e-07 [5.736188e-11] 
Layer 'conv2' weights[0]: 7.942642e-03 [2.384247e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.796763e-10] 
Layer 'conv3' weights[0]: 7.940856e-03 [2.002263e-09] 
Layer 'conv3' biases: 4.165480e-06 [9.307843e-10] 
Layer 'conv4' weights[0]: 7.973504e-03 [2.096608e-09] 
Layer 'conv4' biases: 9.999990e-01 [7.874530e-09] 
Layer 'conv5' weights[0]: 7.972219e-03 [5.002081e-08] 
Layer 'conv5' biases: 9.999883e-01 [5.353592e-08] 
Layer 'fc6' weights[0]: 7.568769e-03 [4.142948e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.131807e-09] 
Layer 'fc7' weights[0]: 6.711462e-03 [3.811339e-08] 
Layer 'fc7' biases: 9.998507e-01 [1.430542e-08] 
Layer 'fc8' weights[0]: 1.250323e-03 [2.378101e-06] 
Layer 'fc8' biases: 9.041461e-02 [1.616326e-05] 
Train error last 870 batches: 0.435155
-------------------------------------------------------
Not saving because 0.416561 > 0.415638 (32.630: -0.00%)
======================================================= (12.121 sec)
36.501... logprob:  0.339150, 0.078125 (1.444 sec)
36.502... logprob:  0.459567, 0.125000 (1.452 sec)
36.503... logprob:  0.400650, 0.101562 (1.477 sec)
36.504... logprob:  0.487235, 0.132812 (1.430 sec)
36.505... logprob:  0.570725, 0.164062 (1.440 sec)
36.506... logprob:  0.479683, 0.132812 (1.435 sec)
36.507... logprob:  0.384966, 0.093750 (1.433 sec)
36.508... logprob:  0.374601, 0.093750 (1.432 sec)
36.509... logprob:  0.322866, 0.070312 (1.484 sec)
36.510... logprob:  0.390440, 0.101562 (1.440 sec)
36.511... logprob:  0.410024, 0.109375 (1.455 sec)
36.512... logprob:  0.470701, 0.125000 (1.466 sec)
36.513... logprob:  0.324952, 0.078125 (1.447 sec)
36.514... logprob:  0.406271, 0.101562 (1.440 sec)
36.515... logprob:  0.455388, 0.125000 (1.430 sec)
36.516... logprob:  0.400169, 0.109375 (1.428 sec)
36.517... logprob:  0.627563, 0.179688 (1.443 sec)
36.518... logprob:  0.437604, 0.117188 (1.460 sec)
36.519... logprob:  0.516122, 0.140625 (1.452 sec)
36.520... logprob:  0.409634, 0.109375 (1.459 sec)
36.521... logprob:  0.427371, 0.109375 (1.450 sec)
36.522... logprob:  0.533238, 0.156250 (1.467 sec)
36.523... logprob:  0.331307, 0.078125 (1.440 sec)
36.524... logprob:  0.437088, 0.117188 (1.426 sec)
36.525... logprob:  0.425781, 0.109375 (1.433 sec)
36.526... logprob:  0.351461, 0.078125 (1.438 sec)
36.527... logprob:  0.504604, 0.140625 (1.442 sec)
36.528... logprob:  0.440422, 0.117188 (1.472 sec)
36.529... logprob:  0.352992, 0.085938 (1.452 sec)
36.530... logprob:  0.440261, 0.117188 (1.441 sec)
36.531... logprob:  0.439918, 0.117188 (1.483 sec)
36.532... logprob:  0.467258, 0.125000 (1.432 sec)
36.533... logprob:  0.560078, 0.164062 (1.432 sec)
36.534... logprob:  0.326049, 0.078125 (1.435 sec)
36.535... logprob:  0.551257, 0.156250 (1.435 sec)
36.536... logprob:  0.507170, 0.140625 (1.437 sec)
36.537... logprob:  0.509941, 0.140625 (1.487 sec)
36.538... logprob:  0.486061, 0.132812 (1.448 sec)
36.539... logprob:  0.295962, 0.062500 (1.431 sec)
36.540... logprob:  0.447178, 0.117188 (1.500 sec)
36.541... logprob:  0.388725, 0.101562 (1.434 sec)
36.542... logprob:  0.411185, 0.109375 (1.431 sec)
36.543... logprob:  0.233081, 0.039062 (1.438 sec)
36.544... logprob:  0.317908, 0.070312 (1.431 sec)
36.545... logprob:  0.348791, 0.085938 (1.437 sec)
36.546... logprob:  0.368259, 0.093750 (1.484 sec)
36.547... logprob:  0.439924, 0.117188 (1.439 sec)
36.548... logprob:  0.452670, 0.125000 (1.443 sec)
36.549... logprob:  0.490225, 0.132812 (1.484 sec)
36.550... logprob:  0.367554, 0.093750 (1.432 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.85028076171875, 10.0]}, 128)
batch 872: ({'logprob': [68.36093139648438, 19.0]}, 128)
batch 873: ({'logprob': [39.57862854003906, 9.0]}, 128)
batch 874: ({'logprob': [44.715789794921875, 11.0]}, 128)
batch 875: ({'logprob': [50.865108489990234, 13.0]}, 128)
batch 876: ({'logprob': [65.57138061523438, 18.0]}, 128)
batch 877: ({'logprob': [45.23495864868164, 11.0]}, 128)
batch 878: ({'logprob': [63.23517990112305, 17.0]}, 128)
batch 879: ({'logprob': [76.0624771118164, 21.0]}, 128)
batch 880: ({'logprob': [50.89668655395508, 13.0]}, 128)
batch 881: ({'logprob': [26.707433700561523, 5.0]}, 128)
batch 882: ({'logprob': [55.259185791015625, 14.0]}, 128)
batch 883: ({'logprob': [63.20195388793945, 17.0]}, 128)
batch 884: ({'logprob': [51.39639663696289, 13.0]}, 128)
batch 885: ({'logprob': [52.41572570800781, 13.0]}, 128)
batch 886: ({'logprob': [63.74465560913086, 17.0]}, 128)

======================Test output======================
logprob:  0.418993, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955464e-03 [4.039228e-09] 
Layer 'conv1' biases: 4.954011e-07 [9.556874e-11] 
Layer 'conv2' weights[0]: 7.942612e-03 [3.797905e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.147177e-10] 
Layer 'conv3' weights[0]: 7.940819e-03 [3.109497e-09] 
Layer 'conv3' biases: 4.173910e-06 [1.857507e-09] 
Layer 'conv4' weights[0]: 7.973474e-03 [3.133030e-09] 
Layer 'conv4' biases: 9.999990e-01 [1.438369e-08] 
Layer 'conv5' weights[0]: 7.972184e-03 [8.362270e-08] 
Layer 'conv5' biases: 9.999877e-01 [8.949901e-08] 
Layer 'fc6' weights[0]: 7.568725e-03 [6.890281e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.010541e-09] 
Layer 'fc7' weights[0]: 6.709763e-03 [5.053066e-08] 
Layer 'fc7' biases: 9.998524e-01 [3.164854e-08] 
Layer 'fc8' weights[0]: 1.311690e-03 [6.692623e-06] 
Layer 'fc8' biases: 9.094703e-02 [4.097946e-05] 
Train error last 870 batches: 0.435155
-------------------------------------------------------
Not saving because 0.418993 > 0.415638 (32.630: -0.00%)
======================================================= (12.064 sec)
36.551... logprob:  0.441519, 0.117188 (1.443 sec)
36.552... logprob:  0.471193, 0.125000 (1.444 sec)
36.553... logprob:  0.349453, 0.085938 (1.429 sec)
36.554... logprob:  0.507076, 0.140625 (1.433 sec)
36.555... logprob:  0.421409, 0.109375 (1.488 sec)
36.556... logprob:  0.355688, 0.085938 (1.436 sec)
36.557... logprob:  0.396284, 0.101562 (1.452 sec)
36.558... logprob:  0.382971, 0.101562 (1.476 sec)
36.559... logprob:  0.441726, 0.125000 (1.438 sec)
36.560... logprob:  0.334838, 0.078125 (1.437 sec)
36.561... logprob:  0.411759, 0.109375 (1.435 sec)
36.562... logprob:  0.503196, 0.140625 (1.426 sec)
36.563... logprob:  0.373689, 0.093750 (1.438 sec)
36.564... logprob:  0.468535, 0.132812 (1.467 sec)
36.565... logprob:  0.611249, 0.187500 (1.452 sec)
36.566... logprob:  0.374833, 0.093750 (1.457 sec)
36.567... logprob:  0.423221, 0.109375 (1.456 sec)
36.568... logprob:  0.496303, 0.140625 (1.457 sec)
36.569... logprob:  0.507589, 0.140625 (1.442 sec)
36.570... logprob:  0.543835, 0.164062 (1.427 sec)
36.571... logprob:  0.454893, 0.125000 (1.428 sec)
36.572... logprob:  0.501299, 0.140625 (1.442 sec)
36.573... logprob:  0.512580, 0.148438 (1.444 sec)
36.574... logprob:  0.427958, 0.109375 (1.470 sec)
36.575... logprob:  0.343316, 0.078125 (1.453 sec)
36.576... logprob:  0.427322, 0.109375 (1.447 sec)
36.577... logprob:  0.460757, 0.125000 (1.476 sec)
36.578... logprob:  0.336901, 0.078125 (1.438 sec)
36.579... logprob:  0.442078, 0.117188 (1.425 sec)
36.580... logprob:  0.546447, 0.156250 (1.437 sec)
36.581... logprob:  0.530415, 0.156250 (1.440 sec)
36.582... logprob:  0.437747, 0.125000 (1.437 sec)
36.583... logprob:  0.592164, 0.171875 (1.476 sec)
36.584... logprob:  0.468033, 0.132812 (1.450 sec)
36.585... logprob:  0.349777, 0.085938 (1.431 sec)
36.586... logprob:  0.313022, 0.070312 (1.490 sec)
36.587... logprob:  0.404289, 0.101562 (1.435 sec)
36.588... logprob:  0.418647, 0.117188 (1.433 sec)
36.589... logprob:  0.361081, 0.093750 (1.436 sec)
36.590... logprob:  0.524816, 0.148438 (1.436 sec)
36.591... logprob:  0.397428, 0.101562 (1.435 sec)
36.592... logprob:  0.455699, 0.125000 (1.482 sec)
36.593... logprob:  0.467412, 0.125000 (1.442 sec)
36.594... logprob:  0.352796, 0.085938 (1.441 sec)
36.595... logprob:  0.428658, 0.109375 (1.489 sec)
36.596... logprob:  0.461634, 0.125000 (1.439 sec)
36.597... logprob:  0.397420, 0.101562 (1.431 sec)
36.598... logprob:  0.397211, 0.101562 (1.438 sec)
36.599... logprob:  0.313607, 0.070312 (1.435 sec)
36.600... logprob:  0.340866, 0.085938 (1.432 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.993858337402344, 10.0]}, 128)
batch 872: ({'logprob': [66.84410858154297, 19.0]}, 128)
batch 873: ({'logprob': [40.5475959777832, 9.0]}, 128)
batch 874: ({'logprob': [44.963253021240234, 11.0]}, 128)
batch 875: ({'logprob': [50.76719665527344, 13.0]}, 128)
batch 876: ({'logprob': [64.32006072998047, 18.0]}, 128)
batch 877: ({'logprob': [45.670448303222656, 11.0]}, 128)
batch 878: ({'logprob': [62.43938446044922, 17.0]}, 128)
batch 879: ({'logprob': [74.75482177734375, 21.0]}, 128)
batch 880: ({'logprob': [50.796939849853516, 13.0]}, 128)
batch 881: ({'logprob': [28.189008712768555, 5.0]}, 128)
batch 882: ({'logprob': [55.44961929321289, 14.0]}, 128)
batch 883: ({'logprob': [62.40732192993164, 17.0]}, 128)
batch 884: ({'logprob': [51.48025894165039, 13.0]}, 128)
batch 885: ({'logprob': [52.87260818481445, 13.0]}, 128)
batch 886: ({'logprob': [63.133182525634766, 17.0]}, 128)

======================Test output======================
logprob:  0.417788, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955426e-03 [3.323988e-09] 
Layer 'conv1' biases: 4.966917e-07 [1.200035e-10] 
Layer 'conv2' weights[0]: 7.942570e-03 [3.026781e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.017564e-10] 
Layer 'conv3' weights[0]: 7.940782e-03 [2.878309e-09] 
Layer 'conv3' biases: 4.184031e-06 [1.790070e-09] 
Layer 'conv4' weights[0]: 7.973440e-03 [2.869118e-09] 
Layer 'conv4' biases: 9.999990e-01 [1.494010e-08] 
Layer 'conv5' weights[0]: 7.972147e-03 [9.293112e-08] 
Layer 'conv5' biases: 9.999878e-01 [9.945024e-08] 
Layer 'fc6' weights[0]: 7.568684e-03 [7.602387e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.738228e-09] 
Layer 'fc7' weights[0]: 6.708054e-03 [1.476013e-07] 
Layer 'fc7' biases: 9.998519e-01 [1.370920e-07] 
Layer 'fc8' weights[0]: 1.279556e-03 [6.731375e-06] 
Layer 'fc8' biases: 9.082816e-02 [4.570053e-05] 
Train error last 870 batches: 0.435155
-------------------------------------------------------
Not saving because 0.417788 > 0.415638 (32.630: -0.00%)
======================================================= (12.083 sec)
36.601... logprob:  0.402173, 0.101562 (1.492 sec)
36.602... logprob:  0.289990, 0.062500 (1.445 sec)
36.603... logprob:  0.267338, 0.054688 (1.453 sec)
36.604... logprob:  0.407535, 0.101562 (1.475 sec)
36.605... logprob:  0.563128, 0.148438 (1.436 sec)
36.606... logprob:  0.295950, 0.070312 (1.438 sec)
36.607... logprob:  0.504567, 0.132812 (1.439 sec)
36.608... logprob:  0.361974, 0.085938 (1.423 sec)
36.609... logprob:  0.357115, 0.085938 (1.441 sec)
36.610... logprob:  0.493207, 0.132812 (1.472 sec)
36.611... logprob:  0.510266, 0.140625 (1.445 sec)
36.612... logprob:  0.448613, 0.117188 (1.456 sec)
36.613... logprob:  0.279125, 0.062500 (1.463 sec)
36.614... logprob:  0.503592, 0.140625 (1.454 sec)
36.615... logprob:  0.350628, 0.085938 (1.435 sec)
36.616... logprob:  0.414916, 0.109375 (1.433 sec)
36.617... logprob:  0.417755, 0.109375 (1.429 sec)
36.618... logprob:  0.547207, 0.156250 (1.441 sec)
36.619... logprob:  0.506215, 0.140625 (1.452 sec)
36.620... logprob:  0.539751, 0.156250 (1.466 sec)
36.621... logprob:  0.363389, 0.085938 (1.451 sec)
36.622... logprob:  0.364521, 0.085938 (1.450 sec)
36.623... logprob:  0.423069, 0.109375 (1.472 sec)
36.624... logprob:  0.382472, 0.093750 (1.438 sec)
36.625... logprob:  0.440967, 0.117188 (1.430 sec)
36.626... logprob:  0.438322, 0.117188 (1.430 sec)
36.627... logprob:  0.435800, 0.117188 (1.439 sec)
36.628... logprob:  0.464988, 0.125000 (1.440 sec)
36.629... logprob:  0.372229, 0.093750 (1.485 sec)
36.630... logprob:  0.422397, 0.109375 (1.447 sec)
36.631... logprob:  0.637917, 0.187500 (1.440 sec)
36.632... logprob:  0.399139, 0.101562 (1.482 sec)
36.633... logprob:  0.376171, 0.093750 (1.437 sec)
36.634... logprob:  0.659831, 0.195312 (1.432 sec)
36.635... logprob:  0.374131, 0.093750 (1.434 sec)
36.636... logprob:  0.480272, 0.132812 (1.437 sec)
36.637... logprob:  0.330650, 0.078125 (1.433 sec)
36.638... logprob:  0.515726, 0.140625 (1.485 sec)
36.639... logprob:  0.417973, 0.109375 (1.441 sec)
36.640... logprob:  0.528773, 0.148438 (1.439 sec)
36.641... logprob:  0.410369, 0.109375 (1.484 sec)
36.642... logprob:  0.500957, 0.140625 (1.435 sec)
36.643... logprob:  0.623512, 0.187500 (1.432 sec)
36.644... logprob:  0.320678, 0.070312 (1.438 sec)
36.645... logprob:  0.414413, 0.109375 (1.429 sec)
36.646... logprob:  0.385460, 0.093750 (1.438 sec)
36.647... logprob:  0.456814, 0.125000 (1.490 sec)
36.648... logprob:  0.491303, 0.140625 (1.435 sec)
36.649... logprob:  0.370405, 0.093750 (1.443 sec)
36.650... logprob:  0.414083, 0.109375 (1.483 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.02230453491211, 10.0]}, 128)
batch 872: ({'logprob': [66.31658172607422, 19.0]}, 128)
batch 873: ({'logprob': [40.90357208251953, 9.0]}, 128)
batch 874: ({'logprob': [45.4366569519043, 11.0]}, 128)
batch 875: ({'logprob': [50.86827087402344, 13.0]}, 128)
batch 876: ({'logprob': [63.855892181396484, 18.0]}, 128)
batch 877: ({'logprob': [45.90008544921875, 11.0]}, 128)
batch 878: ({'logprob': [61.795040130615234, 17.0]}, 128)
batch 879: ({'logprob': [73.1213150024414, 21.0]}, 128)
batch 880: ({'logprob': [50.89820861816406, 13.0]}, 128)
batch 881: ({'logprob': [29.536956787109375, 5.0]}, 128)
batch 882: ({'logprob': [54.75095748901367, 14.0]}, 128)
batch 883: ({'logprob': [61.76290512084961, 17.0]}, 128)
batch 884: ({'logprob': [51.33391571044922, 13.0]}, 128)
batch 885: ({'logprob': [52.23655319213867, 13.0]}, 128)
batch 886: ({'logprob': [62.24248123168945, 17.0]}, 128)

======================Test output======================
logprob:  0.416495, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955392e-03 [2.924404e-09] 
Layer 'conv1' biases: 4.977809e-07 [8.821348e-11] 
Layer 'conv2' weights[0]: 7.942537e-03 [2.275689e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.570876e-10] 
Layer 'conv3' weights[0]: 7.940745e-03 [2.209845e-09] 
Layer 'conv3' biases: 4.193360e-06 [1.341774e-09] 
Layer 'conv4' weights[0]: 7.973406e-03 [2.402883e-09] 
Layer 'conv4' biases: 9.999990e-01 [1.261670e-08] 
Layer 'conv5' weights[0]: 7.972114e-03 [8.086163e-08] 
Layer 'conv5' biases: 9.999880e-01 [8.664291e-08] 
Layer 'fc6' weights[0]: 7.568642e-03 [6.515061e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.652839e-09] 
Layer 'fc7' weights[0]: 6.706341e-03 [2.254178e-07] 
Layer 'fc7' biases: 9.998507e-01 [2.154046e-07] 
Layer 'fc8' weights[0]: 1.254787e-03 [9.816812e-06] 
Layer 'fc8' biases: 9.080650e-02 [7.132904e-05] 
Train error last 870 batches: 0.435154
-------------------------------------------------------
Not saving because 0.416495 > 0.415638 (32.630: -0.00%)
======================================================= (12.069 sec)
36.651... logprob:  0.397464, 0.101562 (1.443 sec)
36.652... logprob:  0.506924, 0.140625 (1.445 sec)
36.653... logprob:  0.547502, 0.156250 (1.435 sec)
36.654... logprob:  0.495934, 0.140625 (1.426 sec)
36.655... logprob:  0.436166, 0.117188 (1.434 sec)
36.656... logprob:  0.416739, 0.109375 (1.482 sec)
36.657... logprob:  0.448928, 0.117188 (1.441 sec)
36.658... logprob:  0.345964, 0.085938 (1.455 sec)
36.659... logprob:  0.464239, 0.125000 (1.476 sec)
36.660... logprob:  0.446117, 0.125000 (1.444 sec)
36.661... logprob:  0.378348, 0.093750 (1.440 sec)
36.662... logprob:  0.469531, 0.132812 (1.432 sec)
36.663... logprob:  0.310775, 0.070312 (1.429 sec)
36.664... logprob:  0.285286, 0.062500 (1.439 sec)
36.665... logprob:  0.401598, 0.101562 (1.464 sec)
36.666... logprob:  0.442001, 0.117188 (1.453 sec)
36.667... logprob:  0.564161, 0.164062 (1.458 sec)
36.668... logprob:  0.497819, 0.140625 (1.450 sec)
36.669... logprob:  0.432820, 0.109375 (1.468 sec)
36.670... logprob:  0.362281, 0.085938 (1.438 sec)
36.671... logprob:  0.360885, 0.093750 (1.423 sec)
36.672... logprob:  0.441833, 0.117188 (1.433 sec)
36.673... logprob:  0.436219, 0.117188 (1.444 sec)
36.674... logprob:  0.446610, 0.117188 (1.441 sec)
36.675... logprob:  0.356696, 0.093750 (1.470 sec)
36.676... logprob:  0.450211, 0.125000 (1.451 sec)
36.677... logprob:  0.470996, 0.125000 (1.445 sec)
36.678... logprob:  0.465669, 0.125000 (1.479 sec)
36.679... logprob:  0.454861, 0.125000 (1.434 sec)
36.680... logprob:  0.351604, 0.078125 (1.428 sec)
36.681... logprob:  0.373819, 0.093750 (1.437 sec)
36.682... logprob:  0.340439, 0.078125 (1.440 sec)
36.683... logprob:  0.411625, 0.109375 (1.434 sec)
36.684... logprob:  0.357754, 0.085938 (1.481 sec)
36.685... logprob:  0.286387, 0.054688 (1.445 sec)
36.686... logprob:  0.318968, 0.070312 (1.437 sec)
36.687... logprob:  0.281957, 0.062500 (1.485 sec)
36.688... logprob:  0.323190, 0.078125 (1.438 sec)
36.689... logprob:  0.470622, 0.125000 (1.429 sec)
36.690... logprob:  0.526970, 0.140625 (1.439 sec)
36.691... logprob:  0.515700, 0.140625 (1.433 sec)
36.692... logprob:  0.384486, 0.101562 (1.434 sec)
36.693... logprob:  0.455203, 0.125000 (1.488 sec)
36.694... logprob:  0.330996, 0.078125 (1.436 sec)
36.695... logprob:  0.356988, 0.085938 (1.446 sec)
36.696... logprob:  0.539528, 0.148438 (1.477 sec)
36.697... logprob:  0.465902, 0.125000 (1.438 sec)
36.698... logprob:  0.549365, 0.156250 (1.436 sec)
36.699... logprob:  0.459670, 0.125000 (1.437 sec)
36.700... logprob:  0.433692, 0.117188 (1.426 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.90095901489258, 10.0]}, 128)
batch 872: ({'logprob': [65.9522476196289, 19.0]}, 128)
batch 873: ({'logprob': [41.848270416259766, 9.0]}, 128)
batch 874: ({'logprob': [46.14393615722656, 11.0]}, 128)
batch 875: ({'logprob': [51.2986946105957, 13.0]}, 128)
batch 876: ({'logprob': [63.619361877441406, 18.0]}, 128)
batch 877: ({'logprob': [46.588077545166016, 11.0]}, 128)
batch 878: ({'logprob': [61.66791915893555, 17.0]}, 128)
batch 879: ({'logprob': [72.41653442382812, 21.0]}, 128)
batch 880: ({'logprob': [51.327816009521484, 13.0]}, 128)
batch 881: ({'logprob': [31.060731887817383, 5.0]}, 128)
batch 882: ({'logprob': [54.98860168457031, 14.0]}, 128)
batch 883: ({'logprob': [61.636474609375, 17.0]}, 128)
batch 884: ({'logprob': [51.74043273925781, 13.0]}, 128)
batch 885: ({'logprob': [52.6021614074707, 13.0]}, 128)
batch 886: ({'logprob': [62.093223571777344, 17.0]}, 128)

======================Test output======================
logprob:  0.418889, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955348e-03 [3.468483e-09] 
Layer 'conv1' biases: 4.987744e-07 [6.051908e-11] 
Layer 'conv2' weights[0]: 7.942495e-03 [2.080733e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.467979e-10] 
Layer 'conv3' weights[0]: 7.940706e-03 [1.590948e-09] 
Layer 'conv3' biases: 4.206313e-06 [7.835679e-10] 
Layer 'conv4' weights[0]: 7.973371e-03 [1.485662e-09] 
Layer 'conv4' biases: 9.999990e-01 [4.872704e-09] 
Layer 'conv5' weights[0]: 7.972086e-03 [2.705077e-08] 
Layer 'conv5' biases: 9.999888e-01 [2.880782e-08] 
Layer 'fc6' weights[0]: 7.568608e-03 [2.398367e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.268134e-09] 
Layer 'fc7' weights[0]: 6.704669e-03 [3.594249e-07] 
Layer 'fc7' biases: 9.998497e-01 [3.516355e-07] 
Layer 'fc8' weights[0]: 1.233980e-03 [1.314300e-05] 
Layer 'fc8' biases: 9.077644e-02 [8.569040e-05] 
Train error last 870 batches: 0.435154
-------------------------------------------------------
Not saving because 0.418889 > 0.415638 (32.630: -0.00%)
======================================================= (12.093 sec)
36.701... logprob:  0.422699, 0.109375 (1.441 sec)
36.702... logprob:  0.521659, 0.148438 (1.495 sec)
36.703... logprob:  0.404616, 0.101562 (1.440 sec)
36.704... logprob:  0.405658, 0.101562 (1.453 sec)
36.705... logprob:  0.419942, 0.109375 (1.472 sec)
36.706... logprob:  0.468027, 0.125000 (1.438 sec)
36.707... logprob:  0.485293, 0.132812 (1.440 sec)
36.708... logprob:  0.417326, 0.109375 (1.437 sec)
36.709... logprob:  0.422803, 0.109375 (1.425 sec)
36.710... logprob:  0.601658, 0.179688 (1.440 sec)
36.711... logprob:  0.469445, 0.125000 (1.463 sec)
36.712... logprob:  0.341354, 0.078125 (1.455 sec)
36.713... logprob:  0.585852, 0.179688 (1.456 sec)
36.714... logprob:  0.466188, 0.125000 (1.458 sec)
36.715... logprob:  0.417252, 0.109375 (1.454 sec)
36.716... logprob:  0.335692, 0.078125 (1.443 sec)
36.717... logprob:  0.429743, 0.117188 (1.424 sec)
36.718... logprob:  0.490237, 0.132812 (1.432 sec)
36.719... logprob:  0.406168, 0.109375 (1.441 sec)
36.720... logprob:  0.433214, 0.117188 (1.448 sec)
36.721... logprob:  0.451603, 0.117188 (1.465 sec)
36.722... logprob:  0.537120, 0.156250 (1.451 sec)
36.723... logprob:  0.416519, 0.109375 (1.457 sec)
36.724... logprob:  0.412749, 0.109375 (1.480 sec)
36.725... logprob:  0.495004, 0.140625 (1.436 sec)
36.726... logprob:  0.338240, 0.085938 (1.427 sec)
36.727... logprob:  0.393084, 0.101562 (1.432 sec)
36.728... logprob:  0.421114, 0.109375 (1.441 sec)
36.729... logprob:  0.387409, 0.093750 (1.436 sec)
36.730... logprob:  0.566047, 0.164062 (1.476 sec)
36.731... logprob:  0.450478, 0.125000 (1.446 sec)
36.732... logprob:  0.311292, 0.070312 (1.448 sec)
36.733... logprob:  0.556395, 0.156250 (1.487 sec)
36.734... logprob:  0.340243, 0.078125 (1.432 sec)
36.735... logprob:  0.527315, 0.148438 (1.429 sec)
36.736... logprob:  0.642297, 0.187500 (1.443 sec)
36.737... logprob:  0.516034, 0.148438 (1.432 sec)
36.738... logprob:  0.459358, 0.125000 (1.435 sec)
36.739... logprob:  0.477774, 0.132812 (1.485 sec)
36.740... logprob:  0.339642, 0.078125 (1.441 sec)
36.741... logprob:  0.393499, 0.101562 (1.440 sec)
36.742... logprob:  0.419666, 0.109375 (1.483 sec)
36.743... logprob:  0.364922, 0.085938 (1.436 sec)
36.744... logprob:  0.519071, 0.148438 (1.435 sec)
36.745... logprob:  0.478103, 0.132812 (1.438 sec)
36.746... logprob:  0.440540, 0.117188 (1.431 sec)
36.747... logprob:  0.425596, 0.109375 (1.431 sec)
36.748... logprob:  0.378213, 0.093750 (1.488 sec)
36.749... logprob:  0.420786, 0.109375 (1.437 sec)
36.750... logprob:  0.512668, 0.140625 (1.449 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.471107482910156, 10.0]}, 128)
batch 872: ({'logprob': [66.65837097167969, 19.0]}, 128)
batch 873: ({'logprob': [40.480655670166016, 9.0]}, 128)
batch 874: ({'logprob': [45.08768844604492, 11.0]}, 128)
batch 875: ({'logprob': [50.72426986694336, 13.0]}, 128)
batch 876: ({'logprob': [64.12834930419922, 18.0]}, 128)
batch 877: ({'logprob': [45.61616134643555, 11.0]}, 128)
batch 878: ({'logprob': [62.0624885559082, 17.0]}, 128)
batch 879: ({'logprob': [73.86548614501953, 21.0]}, 128)
batch 880: ({'logprob': [50.75438690185547, 13.0]}, 128)
batch 881: ({'logprob': [28.635759353637695, 5.0]}, 128)
batch 882: ({'logprob': [54.875267028808594, 14.0]}, 128)
batch 883: ({'logprob': [62.030269622802734, 17.0]}, 128)
batch 884: ({'logprob': [51.257442474365234, 13.0]}, 128)
batch 885: ({'logprob': [52.29148864746094, 13.0]}, 128)
batch 886: ({'logprob': [62.576576232910156, 17.0]}, 128)

======================Test output======================
logprob:  0.416267, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955315e-03 [4.424268e-09] 
Layer 'conv1' biases: 4.998078e-07 [1.052465e-10] 
Layer 'conv2' weights[0]: 7.942451e-03 [2.806338e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.364586e-10] 
Layer 'conv3' weights[0]: 7.940664e-03 [2.170194e-09] 
Layer 'conv3' biases: 4.211526e-06 [1.284862e-09] 
Layer 'conv4' weights[0]: 7.973333e-03 [2.164941e-09] 
Layer 'conv4' biases: 9.999990e-01 [9.064715e-09] 
Layer 'conv5' weights[0]: 7.972041e-03 [5.783653e-08] 
Layer 'conv5' biases: 9.999880e-01 [6.193459e-08] 
Layer 'fc6' weights[0]: 7.568559e-03 [4.779429e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.782809e-09] 
Layer 'fc7' weights[0]: 6.702989e-03 [7.492550e-08] 
Layer 'fc7' biases: 9.998511e-01 [6.008715e-08] 
Layer 'fc8' weights[0]: 1.272579e-03 [6.486902e-06] 
Layer 'fc8' biases: 9.122485e-02 [4.617977e-05] 
Train error last 870 batches: 0.435154
-------------------------------------------------------
Not saving because 0.416267 > 0.415638 (32.630: -0.00%)
======================================================= (12.134 sec)
36.751... logprob:  0.263839, 0.054688 (1.487 sec)
36.752... logprob:  0.522485, 0.140625 (1.445 sec)
36.753... logprob:  0.441095, 0.117188 (1.444 sec)
36.754... logprob:  0.468121, 0.132812 (1.434 sec)
36.755... logprob:  0.507004, 0.140625 (1.429 sec)
36.756... logprob:  0.440846, 0.117188 (1.434 sec)
36.757... logprob:  0.552584, 0.156250 (1.477 sec)
36.758... logprob:  0.393473, 0.101562 (1.444 sec)
36.759... logprob:  0.459710, 0.125000 (1.460 sec)
36.760... logprob:  0.485651, 0.132812 (1.461 sec)
36.761... logprob:  0.418016, 0.109375 (1.447 sec)
36.762... logprob:  0.516128, 0.148438 (1.444 sec)
36.763... logprob:  0.559144, 0.164062 (1.428 sec)
36.764... logprob:  0.503258, 0.140625 (1.435 sec)
36.765... logprob:  0.311336, 0.062500 (1.467 sec)
36.766... logprob:  0.482152, 0.132812 (1.455 sec)
36.767... logprob:  0.370998, 0.085938 (1.460 sec)
36.768... logprob:  0.432608, 0.117188 (1.466 sec)
36.769... logprob:  0.490735, 0.140625 (1.469 sec)
36.770... logprob:  0.403093, 0.101562 (1.484 sec)
36.771... logprob:  0.549204, 0.156250 (1.457 sec)
36.772... logprob:  0.414158, 0.109375 (1.447 sec)
36.773... logprob:  0.557335, 0.164062 (1.450 sec)
36.774... logprob:  0.361985, 0.085938 (1.461 sec)
36.775... logprob:  0.407463, 0.101562 (1.467 sec)
36.776... logprob:  0.433097, 0.117188 (1.477 sec)
36.777... logprob:  0.380038, 0.093750 (1.479 sec)
36.778... logprob:  0.433487, 0.117188 (1.478 sec)
36.779... logprob:  0.505208, 0.140625 (1.490 sec)
36.780... logprob:  0.385766, 0.101562 (1.458 sec)
36.781... logprob:  0.369591, 0.085938 (1.447 sec)
36.782... logprob:  0.351356, 0.085938 (1.451 sec)
36.783... logprob:  0.555561, 0.156250 (1.495 sec)
36.784... logprob:  0.440964, 0.117188 (1.468 sec)
36.785... logprob:  0.543857, 0.156250 (1.501 sec)
36.786... logprob:  0.477666, 0.132812 (1.481 sec)
36.787... logprob:  0.546739, 0.156250 (1.467 sec)
36.788... logprob:  0.563560, 0.164062 (1.508 sec)
36.789... logprob:  0.280099, 0.054688 (1.463 sec)
36.790... logprob:  0.407641, 0.101562 (1.463 sec)
36.791... logprob:  0.397635, 0.101562 (1.453 sec)
36.792... logprob:  0.360658, 0.085938 (1.473 sec)
36.793... logprob:  0.369894, 0.085938 (1.464 sec)
36.794... logprob:  0.387103, 0.093750 (1.501 sec)
36.795... logprob:  0.469657, 0.125000 (1.475 sec)
36.796... logprob:  0.423523, 0.109375 (1.459 sec)
36.797... logprob:  0.359019, 0.085938 (1.499 sec)
36.798... logprob:  0.393327, 0.101562 (1.454 sec)
36.799... logprob:  0.332687, 0.078125 (1.447 sec)
36.800... logprob:  0.371651, 0.093750 (1.456 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.22660446166992, 10.0]}, 128)
batch 872: ({'logprob': [68.19293212890625, 19.0]}, 128)
batch 873: ({'logprob': [39.4650764465332, 9.0]}, 128)
batch 874: ({'logprob': [44.783023834228516, 11.0]}, 128)
batch 875: ({'logprob': [50.793514251708984, 13.0]}, 128)
batch 876: ({'logprob': [65.39309692382812, 18.0]}, 128)
batch 877: ({'logprob': [45.14289093017578, 11.0]}, 128)
batch 878: ({'logprob': [62.88676071166992, 17.0]}, 128)
batch 879: ({'logprob': [75.27809143066406, 21.0]}, 128)
batch 880: ({'logprob': [50.82533264160156, 13.0]}, 128)
batch 881: ({'logprob': [27.03072166442871, 5.0]}, 128)
batch 882: ({'logprob': [54.71938705444336, 14.0]}, 128)
batch 883: ({'logprob': [62.85337448120117, 17.0]}, 128)
batch 884: ({'logprob': [51.16475296020508, 13.0]}, 128)
batch 885: ({'logprob': [51.86482238769531, 13.0]}, 128)
batch 886: ({'logprob': [63.23616409301758, 17.0]}, 128)

======================Test output======================
logprob:  0.417410, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955281e-03 [3.127973e-09] 
Layer 'conv1' biases: 5.009509e-07 [9.489840e-11] 
Layer 'conv2' weights[0]: 7.942417e-03 [1.897305e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.041879e-10] 
Layer 'conv3' weights[0]: 7.940627e-03 [1.635930e-09] 
Layer 'conv3' biases: 4.219324e-06 [7.586668e-10] 
Layer 'conv4' weights[0]: 7.973293e-03 [1.661687e-09] 
Layer 'conv4' biases: 9.999990e-01 [6.412021e-09] 
Layer 'conv5' weights[0]: 7.972008e-03 [4.048038e-08] 
Layer 'conv5' biases: 9.999875e-01 [4.329553e-08] 
Layer 'fc6' weights[0]: 7.568521e-03 [3.374894e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.354548e-09] 
Layer 'fc7' weights[0]: 6.701245e-03 [2.545330e-07] 
Layer 'fc7' biases: 9.998519e-01 [2.456394e-07] 
Layer 'fc8' weights[0]: 1.305883e-03 [9.789184e-06] 
Layer 'fc8' biases: 9.162910e-02 [7.062942e-05] 
Train error last 870 batches: 0.435154
-------------------------------------------------------
Not saving because 0.417410 > 0.415638 (32.630: -0.00%)
======================================================= (12.117 sec)
36.801... logprob:  0.449693, 0.117188 (1.470 sec)
36.802... logprob:  0.422687, 0.109375 (1.462 sec)
36.803... logprob:  0.491048, 0.132812 (1.499 sec)
36.804... logprob:  0.349930, 0.085938 (1.468 sec)
36.805... logprob:  0.452236, 0.117188 (1.452 sec)
36.806... logprob:  0.424159, 0.109375 (1.502 sec)
36.807... logprob:  0.443478, 0.117188 (1.455 sec)
36.808... logprob:  0.462369, 0.125000 (1.453 sec)
36.809... logprob:  0.589992, 0.171875 (1.452 sec)
36.810... logprob:  0.442533, 0.117188 (1.456 sec)
36.811... logprob:  0.460433, 0.125000 (1.453 sec)
36.812... logprob:  0.462294, 0.125000 (1.496 sec)
36.813... logprob:  0.485948, 0.132812 (1.463 sec)
36.814... logprob:  0.477787, 0.132812 (1.453 sec)
36.815... logprob:  0.370918, 0.085938 (1.507 sec)
36.816... logprob:  0.408153, 0.101562 (1.452 sec)
36.817... logprob:  0.425611, 0.109375 (1.458 sec)
36.818... logprob:  0.560057, 0.164062 (1.447 sec)
36.819... logprob:  0.498162, 0.140625 (1.457 sec)
36.820... logprob:  0.421738, 0.109375 (1.455 sec)
36.821... logprob:  0.406834, 0.101562 (1.500 sec)
36.822... logprob:  0.441379, 0.117188 (1.460 sec)
36.823... logprob:  0.341500, 0.078125 (1.457 sec)
36.824... logprob:  0.489470, 0.132812 (1.503 sec)
36.825... logprob:  0.288920, 0.062500 (1.451 sec)
36.826... logprob:  0.375739, 0.093750 (1.460 sec)
36.827... logprob:  0.420345, 0.109375 (1.449 sec)
36.828... logprob:  0.442888, 0.117188 (1.454 sec)
36.829... logprob:  0.503274, 0.140625 (1.454 sec)
36.830... logprob:  0.441846, 0.117188 (1.505 sec)
36.831... logprob:  0.513605, 0.140625 (1.452 sec)
36.832... logprob:  0.330849, 0.078125 (1.464 sec)
36.833... logprob:  0.489087, 0.132812 (1.495 sec)
36.834... logprob:  0.433481, 0.117188 (1.457 sec)
36.835... logprob:  0.543151, 0.148438 (1.460 sec)
36.836... logprob:  0.375945, 0.093750 (1.452 sec)
36.837... logprob:  0.313560, 0.070312 (1.452 sec)
36.838... logprob:  0.437068, 0.117188 (1.457 sec)
36.839... logprob:  0.471614, 0.125000 (1.501 sec)
36.840... logprob:  0.555788, 0.156250 (1.453 sec)
36.841... logprob:  0.395809, 0.101562 (1.467 sec)
36.842... logprob:  0.497967, 0.140625 (1.493 sec)
36.843... logprob:  0.465455, 0.125000 (1.457 sec)
36.844... logprob:  0.497716, 0.140625 (1.455 sec)
36.845... logprob:  0.486674, 0.132812 (1.453 sec)
36.846... logprob:  0.468324, 0.125000 (1.450 sec)
36.847... logprob:  0.363530, 0.085938 (1.457 sec)
36.848... logprob:  0.397368, 0.101562 (1.497 sec)
36.849... logprob:  0.360828, 0.085938 (1.457 sec)
36.850... logprob:  0.479337, 0.132812 (1.474 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.51728820800781, 10.0]}, 128)
batch 872: ({'logprob': [66.41021728515625, 19.0]}, 128)
batch 873: ({'logprob': [40.9669303894043, 9.0]}, 128)
batch 874: ({'logprob': [45.671905517578125, 11.0]}, 128)
batch 875: ({'logprob': [50.99898147583008, 13.0]}, 128)
batch 876: ({'logprob': [63.93260955810547, 18.0]}, 128)
batch 877: ({'logprob': [45.99742889404297, 11.0]}, 128)
batch 878: ({'logprob': [61.716835021972656, 17.0]}, 128)
batch 879: ({'logprob': [72.69718170166016, 21.0]}, 128)
batch 880: ({'logprob': [51.02893829345703, 13.0]}, 128)
batch 881: ({'logprob': [29.947338104248047, 5.0]}, 128)
batch 882: ({'logprob': [54.484100341796875, 14.0]}, 128)
batch 883: ({'logprob': [61.684932708740234, 17.0]}, 128)
batch 884: ({'logprob': [51.32588577270508, 13.0]}, 128)
batch 885: ({'logprob': [51.952537536621094, 13.0]}, 128)
batch 886: ({'logprob': [62.025821685791016, 17.0]}, 128)

======================Test output======================
logprob:  0.416679, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955239e-03 [3.066253e-09] 
Layer 'conv1' biases: 5.021639e-07 [9.322102e-11] 
Layer 'conv2' weights[0]: 7.942379e-03 [2.556475e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.677609e-10] 
Layer 'conv3' weights[0]: 7.940596e-03 [2.362720e-09] 
Layer 'conv3' biases: 4.230124e-06 [1.421940e-09] 
Layer 'conv4' weights[0]: 7.973256e-03 [2.604146e-09] 
Layer 'conv4' biases: 9.999990e-01 [1.289242e-08] 
Layer 'conv5' weights[0]: 7.971974e-03 [8.206629e-08] 
Layer 'conv5' biases: 9.999878e-01 [8.788483e-08] 
Layer 'fc6' weights[0]: 7.568486e-03 [6.600628e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.735750e-09] 
Layer 'fc7' weights[0]: 6.699582e-03 [2.379332e-07] 
Layer 'fc7' biases: 9.998499e-01 [2.279562e-07] 
Layer 'fc8' weights[0]: 1.243225e-03 [8.165035e-06] 
Layer 'fc8' biases: 9.145076e-02 [6.217303e-05] 
Train error last 870 batches: 0.435153
-------------------------------------------------------
Not saving because 0.416679 > 0.415638 (32.630: -0.00%)
======================================================= (12.128 sec)
36.851... logprob:  0.440143, 0.117188 (1.504 sec)
36.852... logprob:  0.544981, 0.156250 (1.464 sec)
36.853... logprob:  0.372189, 0.093750 (1.465 sec)
36.854... logprob:  0.307720, 0.070312 (1.453 sec)
36.855... logprob:  0.484488, 0.132812 (1.445 sec)
36.856... logprob:  0.443585, 0.117188 (1.457 sec)
36.857... logprob:  0.372243, 0.093750 (1.494 sec)
36.858... logprob:  0.396244, 0.101562 (1.462 sec)
36.859... logprob:  0.308056, 0.070312 (1.473 sec)
36.860... logprob:  0.565927, 0.156250 (1.486 sec)
36.861... logprob:  0.417781, 0.109375 (1.459 sec)
36.862... logprob:  0.328775, 0.078125 (1.459 sec)
36.863... logprob:  0.399618, 0.101562 (1.452 sec)
36.864... logprob:  0.451568, 0.117188 (1.447 sec)
36.865... logprob:  0.484782, 0.132812 (1.456 sec)
36.866... logprob:  0.508023, 0.140625 (1.491 sec)
36.867... logprob:  0.503418, 0.140625 (1.464 sec)
36.868... logprob:  0.405090, 0.101562 (1.478 sec)
36.869... logprob:  0.382868, 0.093750 (1.477 sec)
36.870... logprob:  0.552488, 0.156250 (1.399 sec)
37.1... logprob:  0.379688, 0.093750 (1.408 sec)
37.2... logprob:  0.448211, 0.117188 (1.450 sec)
37.3... logprob:  0.398115, 0.101562 (1.426 sec)
37.4... logprob:  0.443243, 0.117188 (1.402 sec)
37.5... logprob:  0.443512, 0.117188 (1.430 sec)
37.6... logprob:  0.498967, 0.140625 (1.398 sec)
37.7... logprob:  0.363464, 0.085938 (1.420 sec)
37.8... logprob:  0.419214, 0.109375 (1.395 sec)
37.9... logprob:  0.359129, 0.085938 (1.407 sec)
37.10... logprob:  0.377780, 0.093750 (1.409 sec)
37.11... logprob:  0.335218, 0.078125 (1.450 sec)
37.12... logprob:  0.466077, 0.125000 (1.394 sec)
37.13... logprob:  0.441983, 0.117188 (1.427 sec)
37.14... logprob:  0.444326, 0.117188 (1.407 sec)
37.15... logprob:  0.395391, 0.101562 (1.411 sec)
37.16... logprob:  0.421261, 0.109375 (1.409 sec)
37.17... logprob:  0.515770, 0.140625 (1.398 sec)
37.18... logprob:  0.262165, 0.054688 (1.399 sec)
37.19... logprob:  0.279396, 0.062500 (1.401 sec)
37.20... logprob:  0.421344, 0.109375 (1.411 sec)
37.21... logprob:  0.444013, 0.117188 (1.412 sec)
37.22... logprob:  0.536941, 0.148438 (1.420 sec)
37.23... logprob:  0.533429, 0.148438 (1.412 sec)
37.24... logprob:  0.310249, 0.070312 (1.423 sec)
37.25... logprob:  0.355966, 0.085938 (1.399 sec)
37.26... logprob:  0.463934, 0.125000 (1.449 sec)
37.27... logprob:  0.404430, 0.101562 (1.389 sec)
37.28... logprob:  0.421828, 0.109375 (1.411 sec)
37.29... logprob:  0.395801, 0.101562 (1.429 sec)
37.30... logprob:  0.373930, 0.093750 (1.422 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.35874557495117, 10.0]}, 128)
batch 872: ({'logprob': [66.90109252929688, 19.0]}, 128)
batch 873: ({'logprob': [40.40547561645508, 9.0]}, 128)
batch 874: ({'logprob': [45.436763763427734, 11.0]}, 128)
batch 875: ({'logprob': [50.89602279663086, 13.0]}, 128)
batch 876: ({'logprob': [64.30958557128906, 18.0]}, 128)
batch 877: ({'logprob': [45.665367126464844, 11.0]}, 128)
batch 878: ({'logprob': [61.88215255737305, 17.0]}, 128)
batch 879: ({'logprob': [73.03438568115234, 21.0]}, 128)
batch 880: ({'logprob': [50.927162170410156, 13.0]}, 128)
batch 881: ({'logprob': [29.213571548461914, 5.0]}, 128)
batch 882: ({'logprob': [54.20943832397461, 14.0]}, 128)
batch 883: ({'logprob': [61.84928512573242, 17.0]}, 128)
batch 884: ({'logprob': [51.12919998168945, 13.0]}, 128)
batch 885: ({'logprob': [51.563568115234375, 13.0]}, 128)
batch 886: ({'logprob': [62.09599685668945, 17.0]}, 128)

======================Test output======================
logprob:  0.415956, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955194e-03 [2.621352e-09] 
Layer 'conv1' biases: 5.032920e-07 [7.926571e-11] 
Layer 'conv2' weights[0]: 7.942342e-03 [2.619738e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.094561e-10] 
Layer 'conv3' weights[0]: 7.940559e-03 [2.338959e-09] 
Layer 'conv3' biases: 4.241117e-06 [1.207812e-09] 
Layer 'conv4' weights[0]: 7.973226e-03 [2.482599e-09] 
Layer 'conv4' biases: 9.999990e-01 [1.089145e-08] 
Layer 'conv5' weights[0]: 7.971933e-03 [6.951023e-08] 
Layer 'conv5' biases: 9.999883e-01 [7.428751e-08] 
Layer 'fc6' weights[0]: 7.568438e-03 [5.626550e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.720913e-09] 
Layer 'fc7' weights[0]: 6.697838e-03 [3.599156e-08] 
Layer 'fc7' biases: 9.998502e-01 [1.047973e-08] 
Layer 'fc8' weights[0]: 1.254457e-03 [1.072968e-06] 
Layer 'fc8' biases: 9.168959e-02 [8.352095e-06] 
Train error last 870 batches: 0.435153
-------------------------------------------------------
Not saving because 0.415956 > 0.415638 (32.630: -0.00%)
======================================================= (12.084 sec)
37.31... logprob:  0.480037, 0.132812 (1.410 sec)
37.32... logprob:  0.457218, 0.125000 (1.400 sec)
37.33... logprob:  0.460684, 0.125000 (1.452 sec)
37.34... logprob:  0.464462, 0.125000 (1.392 sec)
37.35... logprob:  0.316396, 0.070312 (1.403 sec)
37.36... logprob:  0.475792, 0.132812 (1.402 sec)
37.37... logprob:  0.417595, 0.109375 (1.413 sec)
37.38... logprob:  0.392811, 0.101562 (1.396 sec)
37.39... logprob:  0.631095, 0.187500 (1.436 sec)
37.40... logprob:  0.445572, 0.117188 (1.413 sec)
37.41... logprob:  0.353147, 0.085938 (1.428 sec)
37.42... logprob:  0.392137, 0.101562 (1.423 sec)
37.43... logprob:  0.440056, 0.117188 (1.409 sec)
37.44... logprob:  0.518581, 0.148438 (1.439 sec)
37.45... logprob:  0.381697, 0.093750 (1.390 sec)
37.46... logprob:  0.486054, 0.132812 (1.399 sec)
37.47... logprob:  0.331716, 0.078125 (1.398 sec)
37.48... logprob:  0.498975, 0.140625 (1.423 sec)
37.49... logprob:  0.511043, 0.148438 (1.414 sec)
37.50... logprob:  0.393155, 0.101562 (1.438 sec)
37.51... logprob:  0.490439, 0.140625 (1.418 sec)
37.52... logprob:  0.525801, 0.148438 (1.400 sec)
37.53... logprob:  0.294621, 0.062500 (1.462 sec)
37.54... logprob:  0.403510, 0.109375 (1.391 sec)
37.55... logprob:  0.331616, 0.078125 (1.402 sec)
37.56... logprob:  0.421544, 0.109375 (1.402 sec)
37.57... logprob:  0.572245, 0.164062 (1.430 sec)
37.58... logprob:  0.407392, 0.101562 (1.403 sec)
37.59... logprob:  0.333862, 0.078125 (1.468 sec)
37.60... logprob:  0.618548, 0.179688 (1.422 sec)
37.61... logprob:  0.382747, 0.093750 (1.434 sec)
37.62... logprob:  0.474812, 0.132812 (1.464 sec)
37.63... logprob:  0.397276, 0.101562 (1.439 sec)
37.64... logprob:  0.450370, 0.125000 (1.413 sec)
37.65... logprob:  0.373418, 0.093750 (1.400 sec)
37.66... logprob:  0.354062, 0.085938 (1.447 sec)
37.67... logprob:  0.295445, 0.062500 (1.390 sec)
37.68... logprob:  0.396792, 0.101562 (1.398 sec)
37.69... logprob:  0.496561, 0.140625 (1.428 sec)
37.70... logprob:  0.325934, 0.078125 (1.425 sec)
37.71... logprob:  0.381786, 0.101562 (1.466 sec)
37.72... logprob:  0.493588, 0.132812 (1.414 sec)
37.73... logprob:  0.447621, 0.117188 (1.432 sec)
37.74... logprob:  0.442461, 0.117188 (1.422 sec)
37.75... logprob:  0.380666, 0.093750 (1.423 sec)
37.76... logprob:  0.412024, 0.109375 (1.438 sec)
37.77... logprob:  0.396347, 0.101562 (1.441 sec)
37.78... logprob:  0.493045, 0.140625 (1.454 sec)
37.79... logprob:  0.456498, 0.125000 (1.413 sec)
37.80... logprob:  0.508150, 0.132812 (1.420 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.6178092956543, 10.0]}, 128)
batch 872: ({'logprob': [66.34283447265625, 19.0]}, 128)
batch 873: ({'logprob': [40.8724365234375, 9.0]}, 128)
batch 874: ({'logprob': [45.27024459838867, 11.0]}, 128)
batch 875: ({'logprob': [50.811214447021484, 13.0]}, 128)
batch 876: ({'logprob': [63.88876724243164, 18.0]}, 128)
batch 877: ({'logprob': [45.85557556152344, 11.0]}, 128)
batch 878: ({'logprob': [61.95619201660156, 17.0]}, 128)
batch 879: ({'logprob': [73.62206268310547, 21.0]}, 128)
batch 880: ({'logprob': [50.84089279174805, 13.0]}, 128)
batch 881: ({'logprob': [29.16476058959961, 5.0]}, 128)
batch 882: ({'logprob': [55.05379867553711, 14.0]}, 128)
batch 883: ({'logprob': [61.92433166503906, 17.0]}, 128)
batch 884: ({'logprob': [51.3992919921875, 13.0]}, 128)
batch 885: ({'logprob': [52.54609298706055, 13.0]}, 128)
batch 886: ({'logprob': [62.5260124206543, 17.0]}, 128)

======================Test output======================
logprob:  0.416842, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955164e-03 [4.391739e-09] 
Layer 'conv1' biases: 5.044479e-07 [1.262190e-10] 
Layer 'conv2' weights[0]: 7.942305e-03 [3.738030e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.880955e-10] 
Layer 'conv3' weights[0]: 7.940524e-03 [3.259653e-09] 
Layer 'conv3' biases: 4.250480e-06 [2.146525e-09] 
Layer 'conv4' weights[0]: 7.973181e-03 [3.414607e-09] 
Layer 'conv4' biases: 9.999990e-01 [1.812115e-08] 
Layer 'conv5' weights[0]: 7.971898e-03 [1.153978e-07] 
Layer 'conv5' biases: 9.999884e-01 [1.234751e-07] 
Layer 'fc6' weights[0]: 7.568400e-03 [9.415472e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.547624e-09] 
Layer 'fc7' weights[0]: 6.696126e-03 [2.554233e-07] 
Layer 'fc7' biases: 9.998506e-01 [2.471572e-07] 
Layer 'fc8' weights[0]: 1.259027e-03 [8.453842e-06] 
Layer 'fc8' biases: 9.173197e-02 [5.643340e-05] 
Train error last 870 batches: 0.435153
-------------------------------------------------------
Not saving because 0.416842 > 0.415638 (32.630: -0.00%)
======================================================= (12.047 sec)
37.81... logprob:  0.416725, 0.109375 (1.427 sec)
37.82... logprob:  0.230863, 0.039062 (1.430 sec)
37.83... logprob:  0.493895, 0.140625 (1.403 sec)
37.84... logprob:  0.468202, 0.125000 (1.465 sec)
37.85... logprob:  0.431860, 0.117188 (1.425 sec)
37.86... logprob:  0.416885, 0.109375 (1.423 sec)
37.87... logprob:  0.633404, 0.187500 (1.415 sec)
37.88... logprob:  0.534983, 0.156250 (1.412 sec)
37.89... logprob:  0.410485, 0.109375 (1.434 sec)
37.90... logprob:  0.577482, 0.171875 (1.394 sec)
37.91... logprob:  0.348330, 0.078125 (1.395 sec)
37.92... logprob:  0.464457, 0.125000 (1.404 sec)
37.93... logprob:  0.492166, 0.140625 (1.400 sec)
37.94... logprob:  0.428790, 0.109375 (1.389 sec)
37.95... logprob:  0.471826, 0.125000 (1.402 sec)
37.96... logprob:  0.576070, 0.171875 (1.406 sec)
37.97... logprob:  0.430815, 0.117188 (1.394 sec)
37.98... logprob:  0.391340, 0.093750 (1.438 sec)
37.99... logprob:  0.474162, 0.132812 (1.407 sec)
37.100... logprob:  0.310819, 0.070312 (1.405 sec)
37.101... logprob:  0.311215, 0.062500 (1.443 sec)
37.102... logprob:  0.545603, 0.156250 (1.392 sec)
37.103... logprob:  0.540608, 0.156250 (1.403 sec)
37.104... logprob:  0.388779, 0.101562 (1.410 sec)
37.105... logprob:  0.618892, 0.179688 (1.394 sec)
37.106... logprob:  0.344497, 0.085938 (1.398 sec)
37.107... logprob:  0.335869, 0.078125 (1.437 sec)
37.108... logprob:  0.586859, 0.171875 (1.402 sec)
37.109... logprob:  0.336084, 0.078125 (1.409 sec)
37.110... logprob:  0.564810, 0.164062 (1.398 sec)
37.111... logprob:  0.404627, 0.101562 (1.397 sec)
37.112... logprob:  0.365854, 0.093750 (1.401 sec)
37.113... logprob:  0.354247, 0.085938 (1.403 sec)
37.114... logprob:  0.440203, 0.117188 (1.429 sec)
37.115... logprob:  0.506849, 0.140625 (1.415 sec)
37.116... logprob:  0.393294, 0.101562 (1.400 sec)
37.117... logprob:  0.440395, 0.117188 (1.447 sec)
37.118... logprob:  0.409036, 0.101562 (1.389 sec)
37.119... logprob:  0.346025, 0.085938 (1.403 sec)
37.120... logprob:  0.547134, 0.156250 (1.408 sec)
37.121... logprob:  0.412552, 0.109375 (1.400 sec)
37.122... logprob:  0.519202, 0.148438 (1.447 sec)
37.123... logprob:  0.463628, 0.125000 (1.396 sec)
37.124... logprob:  0.447679, 0.125000 (1.404 sec)
37.125... logprob:  0.501857, 0.140625 (1.407 sec)
37.126... logprob:  0.475686, 0.125000 (1.399 sec)
37.127... logprob:  0.479417, 0.125000 (1.399 sec)
37.128... logprob:  0.422307, 0.109375 (1.419 sec)
37.129... logprob:  0.574873, 0.164062 (1.425 sec)
37.130... logprob:  0.382674, 0.093750 (1.422 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.00605773925781, 10.0]}, 128)
batch 872: ({'logprob': [65.92021179199219, 19.0]}, 128)
batch 873: ({'logprob': [41.9789924621582, 9.0]}, 128)
batch 874: ({'logprob': [46.23855972290039, 11.0]}, 128)
batch 875: ({'logprob': [51.36333465576172, 13.0]}, 128)
batch 876: ({'logprob': [63.60407638549805, 18.0]}, 128)
batch 877: ({'logprob': [46.68592071533203, 11.0]}, 128)
batch 878: ({'logprob': [61.67246627807617, 17.0]}, 128)
batch 879: ({'logprob': [72.3638687133789, 21.0]}, 128)
batch 880: ({'logprob': [51.39248275756836, 13.0]}, 128)
batch 881: ({'logprob': [31.24873924255371, 5.0]}, 128)
batch 882: ({'logprob': [55.04572296142578, 14.0]}, 128)
batch 883: ({'logprob': [61.64089584350586, 17.0]}, 128)
batch 884: ({'logprob': [51.807891845703125, 13.0]}, 128)
batch 885: ({'logprob': [52.67583084106445, 13.0]}, 128)
batch 886: ({'logprob': [62.100685119628906, 17.0]}, 128)

======================Test output======================
logprob:  0.419309, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955133e-03 [2.134428e-09] 
Layer 'conv1' biases: 5.054180e-07 [8.010885e-11] 
Layer 'conv2' weights[0]: 7.942267e-03 [1.932630e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.666472e-10] 
Layer 'conv3' weights[0]: 7.940478e-03 [1.840306e-09] 
Layer 'conv3' biases: 4.258870e-06 [1.106542e-09] 
Layer 'conv4' weights[0]: 7.973143e-03 [1.831918e-09] 
Layer 'conv4' biases: 9.999990e-01 [9.152101e-09] 
Layer 'conv5' weights[0]: 7.971857e-03 [5.030498e-08] 
Layer 'conv5' biases: 9.999885e-01 [5.376999e-08] 
Layer 'fc6' weights[0]: 7.568362e-03 [4.204159e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.197531e-09] 
Layer 'fc7' weights[0]: 6.694418e-03 [8.461640e-08] 
Layer 'fc7' biases: 9.998496e-01 [7.174405e-08] 
Layer 'fc8' weights[0]: 1.223265e-03 [6.924511e-06] 
Layer 'fc8' biases: 9.157654e-02 [4.910655e-05] 
Train error last 870 batches: 0.435153
-------------------------------------------------------
Not saving because 0.419309 > 0.415638 (32.630: -0.00%)
======================================================= (12.053 sec)
37.131... logprob:  0.495496, 0.132812 (1.416 sec)
37.132... logprob:  0.506349, 0.140625 (1.445 sec)
37.133... logprob:  0.444704, 0.117188 (1.396 sec)
37.134... logprob:  0.401851, 0.101562 (1.395 sec)
37.135... logprob:  0.460156, 0.125000 (1.402 sec)
37.136... logprob:  0.562253, 0.164062 (1.400 sec)
37.137... logprob:  0.462604, 0.125000 (1.394 sec)
37.138... logprob:  0.319459, 0.070312 (1.447 sec)
37.139... logprob:  0.395712, 0.101562 (1.406 sec)
37.140... logprob:  0.559785, 0.164062 (1.411 sec)
37.141... logprob:  0.464610, 0.125000 (1.435 sec)
37.142... logprob:  0.464661, 0.125000 (1.398 sec)
37.143... logprob:  0.294539, 0.062500 (1.426 sec)
37.144... logprob:  0.456881, 0.125000 (1.422 sec)
37.145... logprob:  0.324630, 0.078125 (1.415 sec)
37.146... logprob:  0.482979, 0.132812 (1.412 sec)
37.147... logprob:  0.262505, 0.054688 (1.434 sec)
37.148... logprob:  0.458475, 0.125000 (1.392 sec)
37.149... logprob:  0.442460, 0.117188 (1.393 sec)
37.150... logprob:  0.347544, 0.085938 (1.404 sec)
37.151... logprob:  0.347127, 0.085938 (1.403 sec)
37.152... logprob:  0.785190, 0.234375 (1.391 sec)
37.153... logprob:  0.381627, 0.093750 (1.441 sec)
37.154... logprob:  0.524882, 0.148438 (1.406 sec)
37.155... logprob:  0.426195, 0.117188 (1.407 sec)
37.156... logprob:  0.294813, 0.062500 (1.440 sec)
37.157... logprob:  0.269696, 0.054688 (1.392 sec)
37.158... logprob:  0.455491, 0.125000 (1.407 sec)
37.159... logprob:  0.483145, 0.132812 (1.398 sec)
37.160... logprob:  0.444612, 0.117188 (1.397 sec)
37.161... logprob:  0.349418, 0.078125 (1.399 sec)
37.162... logprob:  0.611807, 0.179688 (1.408 sec)
37.163... logprob:  0.450532, 0.125000 (1.439 sec)
37.164... logprob:  0.468428, 0.125000 (1.426 sec)
37.165... logprob:  0.547661, 0.156250 (1.427 sec)
37.166... logprob:  0.446219, 0.125000 (1.452 sec)
37.167... logprob:  0.350727, 0.085938 (1.432 sec)
37.168... logprob:  0.363790, 0.085938 (1.434 sec)
37.169... logprob:  0.408595, 0.101562 (1.461 sec)
37.170... logprob:  0.459446, 0.125000 (1.403 sec)
37.171... logprob:  0.535091, 0.156250 (1.424 sec)
37.172... logprob:  0.434756, 0.109375 (1.413 sec)
37.173... logprob:  0.440452, 0.117188 (1.427 sec)
37.174... logprob:  0.600398, 0.171875 (1.410 sec)
37.175... logprob:  0.505831, 0.140625 (1.469 sec)
37.176... logprob:  0.478351, 0.132812 (1.417 sec)
37.177... logprob:  0.289722, 0.054688 (1.432 sec)
37.178... logprob:  0.383477, 0.093750 (1.462 sec)
37.179... logprob:  0.394637, 0.101562 (1.417 sec)
37.180... logprob:  0.466397, 0.125000 (1.430 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.991058349609375, 10.0]}, 128)
batch 872: ({'logprob': [66.48171997070312, 19.0]}, 128)
batch 873: ({'logprob': [40.68965148925781, 9.0]}, 128)
batch 874: ({'logprob': [45.354740142822266, 11.0]}, 128)
batch 875: ({'logprob': [50.82421112060547, 13.0]}, 128)
batch 876: ({'logprob': [63.979270935058594, 18.0]}, 128)
batch 877: ({'logprob': [45.771366119384766, 11.0]}, 128)
batch 878: ({'logprob': [61.82856750488281, 17.0]}, 128)
batch 879: ({'logprob': [73.1851577758789, 21.0]}, 128)
batch 880: ({'logprob': [50.85483169555664, 13.0]}, 128)
batch 881: ({'logprob': [29.292179107666016, 5.0]}, 128)
batch 882: ({'logprob': [54.61009216308594, 14.0]}, 128)
batch 883: ({'logprob': [61.79594039916992, 17.0]}, 128)
batch 884: ({'logprob': [51.24397277832031, 13.0]}, 128)
batch 885: ({'logprob': [52.052955627441406, 13.0]}, 128)
batch 886: ({'logprob': [62.229488372802734, 17.0]}, 128)

======================Test output======================
logprob:  0.416106, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955093e-03 [2.858333e-09] 
Layer 'conv1' biases: 5.065178e-07 [7.300542e-11] 
Layer 'conv2' weights[0]: 7.942226e-03 [2.030503e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.893458e-10] 
Layer 'conv3' weights[0]: 7.940439e-03 [1.878792e-09] 
Layer 'conv3' biases: 4.267387e-06 [8.718005e-10] 
Layer 'conv4' weights[0]: 7.973110e-03 [1.832723e-09] 
Layer 'conv4' biases: 9.999990e-01 [6.209447e-09] 
Layer 'conv5' weights[0]: 7.971818e-03 [3.473241e-08] 
Layer 'conv5' biases: 9.999881e-01 [3.704988e-08] 
Layer 'fc6' weights[0]: 7.568319e-03 [2.940106e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.892885e-09] 
Layer 'fc7' weights[0]: 6.692689e-03 [1.208635e-07] 
Layer 'fc7' biases: 9.998499e-01 [1.083725e-07] 
Layer 'fc8' weights[0]: 1.259871e-03 [9.675821e-06] 
Layer 'fc8' biases: 9.196590e-02 [6.941277e-05] 
Train error last 870 batches: 0.435153
-------------------------------------------------------
Not saving because 0.416106 > 0.415638 (32.630: -0.00%)
======================================================= (12.049 sec)
37.181... logprob:  0.539202, 0.156250 (1.427 sec)
37.182... logprob:  0.371212, 0.093750 (1.428 sec)
37.183... logprob:  0.419919, 0.109375 (1.431 sec)
37.184... logprob:  0.483420, 0.132812 (1.419 sec)
37.185... logprob:  0.289675, 0.062500 (1.400 sec)
37.186... logprob:  0.370265, 0.093750 (1.401 sec)
37.187... logprob:  0.529615, 0.148438 (1.404 sec)
37.188... logprob:  0.458800, 0.125000 (1.404 sec)
37.189... logprob:  0.440931, 0.117188 (1.397 sec)
37.190... logprob:  0.375810, 0.093750 (1.437 sec)
37.191... logprob:  0.485100, 0.132812 (1.409 sec)
37.192... logprob:  0.519964, 0.148438 (1.420 sec)
37.193... logprob:  0.312410, 0.070312 (1.419 sec)
37.194... logprob:  0.414011, 0.109375 (1.417 sec)
37.195... logprob:  0.286896, 0.062500 (1.397 sec)
37.196... logprob:  0.410404, 0.109375 (1.419 sec)
37.197... logprob:  0.477963, 0.132812 (1.401 sec)
37.198... logprob:  0.355799, 0.085938 (1.408 sec)
37.199... logprob:  0.437195, 0.117188 (1.396 sec)
37.200... logprob:  0.440708, 0.117188 (1.439 sec)
37.201... logprob:  0.437083, 0.117188 (1.408 sec)
37.202... logprob:  0.537765, 0.148438 (1.407 sec)
37.203... logprob:  0.420381, 0.109375 (1.439 sec)
37.204... logprob:  0.504123, 0.140625 (1.395 sec)
37.205... logprob:  0.334221, 0.078125 (1.409 sec)
37.206... logprob:  0.361641, 0.093750 (1.404 sec)
37.207... logprob:  0.381691, 0.093750 (1.393 sec)
37.208... logprob:  0.490625, 0.140625 (1.401 sec)
37.209... logprob:  0.334505, 0.078125 (1.423 sec)
37.210... logprob:  0.586216, 0.171875 (1.424 sec)
37.211... logprob:  0.488084, 0.132812 (1.420 sec)
37.212... logprob:  0.526098, 0.148438 (1.414 sec)
37.213... logprob:  0.514515, 0.140625 (1.465 sec)
37.214... logprob:  0.459369, 0.125000 (1.433 sec)
37.215... logprob:  0.396054, 0.101562 (1.423 sec)
37.216... logprob:  0.516810, 0.140625 (1.473 sec)
37.217... logprob:  0.324710, 0.070312 (1.410 sec)
37.218... logprob:  0.463526, 0.125000 (1.422 sec)
37.219... logprob:  0.500189, 0.140625 (1.413 sec)
37.220... logprob:  0.415044, 0.109375 (1.425 sec)
37.221... logprob:  0.399590, 0.101562 (1.406 sec)
37.222... logprob:  0.554306, 0.164062 (1.459 sec)
37.223... logprob:  0.568769, 0.164062 (1.439 sec)
37.224... logprob:  0.406042, 0.101562 (1.444 sec)
37.225... logprob:  0.392036, 0.101562 (1.450 sec)
37.226... logprob:  0.424812, 0.109375 (1.425 sec)
37.227... logprob:  0.452567, 0.125000 (1.415 sec)
37.228... logprob:  0.417161, 0.109375 (1.418 sec)
37.229... logprob:  0.489369, 0.132812 (1.420 sec)
37.230... logprob:  0.459823, 0.125000 (1.437 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.99361038208008, 10.0]}, 128)
batch 872: ({'logprob': [66.43544006347656, 19.0]}, 128)
batch 873: ({'logprob': [40.74493408203125, 9.0]}, 128)
batch 874: ({'logprob': [45.373199462890625, 11.0]}, 128)
batch 875: ({'logprob': [50.83338928222656, 13.0]}, 128)
batch 876: ({'logprob': [63.944557189941406, 18.0]}, 128)
batch 877: ({'logprob': [45.80364990234375, 11.0]}, 128)
batch 878: ({'logprob': [61.819217681884766, 17.0]}, 128)
batch 879: ({'logprob': [73.17056274414062, 21.0]}, 128)
batch 880: ({'logprob': [50.864166259765625, 13.0]}, 128)
batch 881: ({'logprob': [29.352436065673828, 5.0]}, 128)
batch 882: ({'logprob': [54.648929595947266, 14.0]}, 128)
batch 883: ({'logprob': [61.786354064941406, 17.0]}, 128)
batch 884: ({'logprob': [51.26681137084961, 13.0]}, 128)
batch 885: ({'logprob': [52.10318374633789, 13.0]}, 128)
batch 886: ({'logprob': [62.23378372192383, 17.0]}, 128)

======================Test output======================
logprob:  0.416198, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955055e-03 [2.484013e-09] 
Layer 'conv1' biases: 5.076654e-07 [5.733674e-11] 
Layer 'conv2' weights[0]: 7.942192e-03 [1.901260e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.370890e-10] 
Layer 'conv3' weights[0]: 7.940402e-03 [1.493522e-09] 
Layer 'conv3' biases: 4.278340e-06 [6.795044e-10] 
Layer 'conv4' weights[0]: 7.973070e-03 [1.443054e-09] 
Layer 'conv4' biases: 9.999990e-01 [4.100262e-09] 
Layer 'conv5' weights[0]: 7.971776e-03 [2.591001e-08] 
Layer 'conv5' biases: 9.999881e-01 [2.771864e-08] 
Layer 'fc6' weights[0]: 7.568276e-03 [2.273870e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.141805e-09] 
Layer 'fc7' weights[0]: 6.690952e-03 [4.447592e-08] 
Layer 'fc7' biases: 9.998499e-01 [2.404632e-08] 
Layer 'fc8' weights[0]: 1.261572e-03 [2.064830e-06] 
Layer 'fc8' biases: 9.203321e-02 [1.512702e-05] 
Train error last 870 batches: 0.435152
-------------------------------------------------------
Not saving because 0.416198 > 0.415638 (32.630: -0.00%)
======================================================= (12.093 sec)
37.231... logprob:  0.453451, 0.125000 (1.419 sec)
37.232... logprob:  0.496113, 0.140625 (1.467 sec)
37.233... logprob:  0.465995, 0.132812 (1.426 sec)
37.234... logprob:  0.563904, 0.164062 (1.416 sec)
37.235... logprob:  0.482006, 0.132812 (1.473 sec)
37.236... logprob:  0.425563, 0.109375 (1.403 sec)
37.237... logprob:  0.340694, 0.078125 (1.436 sec)
37.238... logprob:  0.388949, 0.093750 (1.423 sec)
37.239... logprob:  0.478061, 0.132812 (1.420 sec)
37.240... logprob:  0.485793, 0.132812 (1.405 sec)
37.241... logprob:  0.493606, 0.132812 (1.462 sec)
37.242... logprob:  0.341606, 0.078125 (1.428 sec)
37.243... logprob:  0.385980, 0.093750 (1.433 sec)
37.244... logprob:  0.315519, 0.070312 (1.455 sec)
37.245... logprob:  0.494138, 0.132812 (1.427 sec)
37.246... logprob:  0.416816, 0.109375 (1.433 sec)
37.247... logprob:  0.357708, 0.085938 (1.415 sec)
37.248... logprob:  0.308245, 0.070312 (1.420 sec)
37.249... logprob:  0.554056, 0.156250 (1.431 sec)
37.250... logprob:  0.590841, 0.164062 (1.407 sec)
37.251... logprob:  0.353048, 0.085938 (1.464 sec)
37.252... logprob:  0.348406, 0.085938 (1.516 sec)
37.253... logprob:  0.379262, 0.093750 (1.414 sec)
37.254... logprob:  0.444144, 0.117188 (1.472 sec)
37.255... logprob:  0.351240, 0.085938 (1.406 sec)
37.256... logprob:  0.378936, 0.093750 (1.419 sec)
37.257... logprob:  0.331935, 0.078125 (1.421 sec)
37.258... logprob:  0.415378, 0.109375 (1.424 sec)
37.259... logprob:  0.442322, 0.117188 (1.406 sec)
37.260... logprob:  0.308075, 0.070312 (1.464 sec)
37.261... logprob:  0.392412, 0.101562 (1.423 sec)
37.262... logprob:  0.524414, 0.148438 (1.435 sec)
37.263... logprob:  0.425677, 0.109375 (1.447 sec)
37.264... logprob:  0.374950, 0.093750 (1.424 sec)
37.265... logprob:  0.439608, 0.117188 (1.416 sec)
37.266... logprob:  0.438997, 0.117188 (1.421 sec)
37.267... logprob:  0.422059, 0.109375 (1.422 sec)
37.268... logprob:  0.458945, 0.125000 (1.426 sec)
37.269... logprob:  0.567659, 0.164062 (1.417 sec)
37.270... logprob:  0.542422, 0.156250 (1.457 sec)
37.271... logprob:  0.445517, 0.117188 (1.454 sec)
37.272... logprob:  0.384432, 0.093750 (1.420 sec)
37.273... logprob:  0.500247, 0.140625 (1.474 sec)
37.274... logprob:  0.542495, 0.156250 (1.404 sec)
37.275... logprob:  0.487483, 0.132812 (1.424 sec)
37.276... logprob:  0.389903, 0.093750 (1.415 sec)
37.277... logprob:  0.428531, 0.109375 (1.428 sec)
37.278... logprob:  0.323749, 0.070312 (1.429 sec)
37.279... logprob:  0.325478, 0.070312 (1.468 sec)
37.280... logprob:  0.216538, 0.031250 (1.405 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.039886474609375, 10.0]}, 128)
batch 872: ({'logprob': [66.59224700927734, 19.0]}, 128)
batch 873: ({'logprob': [40.579219818115234, 9.0]}, 128)
batch 874: ({'logprob': [45.34165573120117, 11.0]}, 128)
batch 875: ({'logprob': [50.8195915222168, 13.0]}, 128)
batch 876: ({'logprob': [64.06359100341797, 18.0]}, 128)
batch 877: ({'logprob': [45.71397018432617, 11.0]}, 128)
batch 878: ({'logprob': [61.84191131591797, 17.0]}, 128)
batch 879: ({'logprob': [73.17208099365234, 21.0]}, 128)
batch 880: ({'logprob': [50.850502014160156, 13.0]}, 128)
batch 881: ({'logprob': [29.208154678344727, 5.0]}, 128)
batch 882: ({'logprob': [54.499698638916016, 14.0]}, 128)
batch 883: ({'logprob': [61.808963775634766, 17.0]}, 128)
batch 884: ({'logprob': [51.19565200805664, 13.0]}, 128)
batch 885: ({'logprob': [51.915870666503906, 13.0]}, 128)
batch 886: ({'logprob': [62.198673248291016, 17.0]}, 128)

======================Test output======================
logprob:  0.415938, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.955017e-03 [1.059436e-08] 
Layer 'conv1' biases: 5.088493e-07 [4.440099e-10] 
Layer 'conv2' weights[0]: 7.942162e-03 [1.025877e-08] 
Layer 'conv2' biases: 1.000000e+00 [2.240393e-09] 
Layer 'conv3' weights[0]: 7.940364e-03 [9.963332e-09] 
Layer 'conv3' biases: 4.283096e-06 [6.609220e-09] 
Layer 'conv4' weights[0]: 7.973027e-03 [9.761248e-09] 
Layer 'conv4' biases: 9.999990e-01 [5.602128e-08] 
Layer 'conv5' weights[0]: 7.971743e-03 [3.497616e-07] 
Layer 'conv5' biases: 9.999874e-01 [3.744070e-07] 
Layer 'fc6' weights[0]: 7.568234e-03 [2.816737e-08] 
Layer 'fc6' biases: 1.000000e+00 [2.878723e-08] 
Layer 'fc7' weights[0]: 6.689226e-03 [6.265072e-07] 
Layer 'fc7' biases: 9.998498e-01 [6.169759e-07] 
Layer 'fc8' weights[0]: 1.267002e-03 [2.194988e-05] 
Layer 'fc8' biases: 9.217565e-02 [1.651441e-04] 
Train error last 870 batches: 0.435152
-------------------------------------------------------
Not saving because 0.415938 > 0.415638 (32.630: -0.00%)
======================================================= (12.021 sec)
37.281... logprob:  0.417290, 0.109375 (1.429 sec)
37.282... logprob:  0.411249, 0.109375 (1.429 sec)
37.283... logprob:  0.393665, 0.101562 (1.423 sec)
37.284... logprob:  0.394195, 0.101562 (1.414 sec)
37.285... logprob:  0.450940, 0.117188 (1.440 sec)
37.286... logprob:  0.535527, 0.140625 (1.441 sec)
37.287... logprob:  0.346446, 0.085938 (1.430 sec)
37.288... logprob:  0.329925, 0.078125 (1.439 sec)
37.289... logprob:  0.445642, 0.117188 (1.443 sec)
37.290... logprob:  0.490619, 0.132812 (1.409 sec)
37.291... logprob:  0.439413, 0.117188 (1.419 sec)
37.292... logprob:  0.568086, 0.156250 (1.417 sec)
37.293... logprob:  0.427932, 0.117188 (1.425 sec)
37.294... logprob:  0.355474, 0.085938 (1.405 sec)
37.295... logprob:  0.333873, 0.078125 (1.467 sec)
37.296... logprob:  0.355037, 0.085938 (1.420 sec)
37.297... logprob:  0.394084, 0.101562 (1.420 sec)
37.298... logprob:  0.448347, 0.125000 (1.468 sec)
37.299... logprob:  0.341500, 0.078125 (1.405 sec)
37.300... logprob:  0.406156, 0.101562 (1.429 sec)
37.301... logprob:  0.397816, 0.101562 (1.420 sec)
37.302... logprob:  0.591682, 0.179688 (1.418 sec)
37.303... logprob:  0.459418, 0.125000 (1.410 sec)
37.304... logprob:  0.459570, 0.125000 (1.439 sec)
37.305... logprob:  0.455180, 0.125000 (1.439 sec)
37.306... logprob:  0.440557, 0.117188 (1.436 sec)
37.307... logprob:  0.421640, 0.109375 (1.443 sec)
37.308... logprob:  0.375003, 0.093750 (1.460 sec)
37.309... logprob:  0.450488, 0.125000 (1.423 sec)
37.310... logprob:  0.473468, 0.125000 (1.420 sec)
37.311... logprob:  0.502330, 0.140625 (1.438 sec)
37.312... logprob:  0.478601, 0.132812 (1.428 sec)
37.313... logprob:  0.454849, 0.125000 (1.419 sec)
37.314... logprob:  0.454253, 0.117188 (1.468 sec)
37.315... logprob:  0.314716, 0.070312 (1.442 sec)
37.316... logprob:  0.468463, 0.125000 (1.429 sec)
37.317... logprob:  0.355398, 0.085938 (1.484 sec)
37.318... logprob:  0.455393, 0.125000 (1.414 sec)
37.319... logprob:  0.423144, 0.117188 (1.425 sec)
37.320... logprob:  0.412220, 0.109375 (1.426 sec)
37.321... logprob:  0.348209, 0.085938 (1.426 sec)
37.322... logprob:  0.387392, 0.101562 (1.415 sec)
37.323... logprob:  0.416491, 0.109375 (1.474 sec)
37.324... logprob:  0.498587, 0.140625 (1.427 sec)
37.325... logprob:  0.350664, 0.085938 (1.439 sec)
37.326... logprob:  0.543193, 0.148438 (1.464 sec)
37.327... logprob:  0.554451, 0.164062 (1.425 sec)
37.328... logprob:  0.565228, 0.156250 (1.425 sec)
37.329... logprob:  0.401860, 0.101562 (1.425 sec)
37.330... logprob:  0.388406, 0.101562 (1.423 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.0450439453125, 10.0]}, 128)
batch 872: ({'logprob': [65.99006652832031, 19.0]}, 128)
batch 873: ({'logprob': [41.47221755981445, 9.0]}, 128)
batch 874: ({'logprob': [45.649078369140625, 11.0]}, 128)
batch 875: ({'logprob': [51.02067184448242, 13.0]}, 128)
batch 876: ({'logprob': [63.63315200805664, 18.0]}, 128)
batch 877: ({'logprob': [46.260494232177734, 11.0]}, 128)
batch 878: ({'logprob': [61.824424743652344, 17.0]}, 128)
batch 879: ({'logprob': [73.17378997802734, 21.0]}, 128)
batch 880: ({'logprob': [51.05012893676758, 13.0]}, 128)
batch 881: ({'logprob': [30.081684112548828, 5.0]}, 128)
batch 882: ({'logprob': [55.23953628540039, 14.0]}, 128)
batch 883: ({'logprob': [61.79265213012695, 17.0]}, 128)
batch 884: ({'logprob': [51.631893157958984, 13.0]}, 128)
batch 885: ({'logprob': [52.82892608642578, 13.0]}, 128)
batch 886: ({'logprob': [62.4184455871582, 17.0]}, 128)

======================Test output======================
logprob:  0.418024, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954978e-03 [2.972250e-09] 
Layer 'conv1' biases: 5.100191e-07 [4.629258e-11] 
Layer 'conv2' weights[0]: 7.942128e-03 [1.995305e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.579888e-10] 
Layer 'conv3' weights[0]: 7.940322e-03 [1.337787e-09] 
Layer 'conv3' biases: 4.297924e-06 [4.003623e-10] 
Layer 'conv4' weights[0]: 7.972987e-03 [1.218672e-09] 
Layer 'conv4' biases: 9.999990e-01 [2.736436e-10] 
Layer 'conv5' weights[0]: 7.971710e-03 [2.177899e-09] 
Layer 'conv5' biases: 9.999885e-01 [2.030494e-09] 
Layer 'fc6' weights[0]: 7.568195e-03 [7.698098e-10] 
Layer 'fc6' biases: 1.000000e+00 [1.464969e-10] 
Layer 'fc7' weights[0]: 6.687543e-03 [2.089832e-07] 
Layer 'fc7' biases: 9.998498e-01 [2.001461e-07] 
Layer 'fc8' weights[0]: 1.248301e-03 [7.656546e-06] 
Layer 'fc8' biases: 9.230175e-02 [5.029431e-05] 
Train error last 870 batches: 0.435152
-------------------------------------------------------
Not saving because 0.418024 > 0.415638 (32.630: -0.00%)
======================================================= (12.150 sec)
37.331... logprob:  0.352082, 0.085938 (1.438 sec)
37.332... logprob:  0.482789, 0.132812 (1.461 sec)
37.333... logprob:  0.339348, 0.085938 (1.448 sec)
37.334... logprob:  0.565415, 0.171875 (1.440 sec)
37.335... logprob:  0.358576, 0.085938 (1.446 sec)
37.336... logprob:  0.444876, 0.125000 (1.455 sec)
37.337... logprob:  0.566368, 0.164062 (1.418 sec)
37.338... logprob:  0.449518, 0.125000 (1.425 sec)
37.339... logprob:  0.488523, 0.132812 (1.428 sec)
37.340... logprob:  0.442057, 0.117188 (1.434 sec)
37.341... logprob:  0.529954, 0.148438 (1.421 sec)
37.342... logprob:  0.429569, 0.109375 (1.465 sec)
37.343... logprob:  0.434759, 0.109375 (1.438 sec)
37.344... logprob:  0.444583, 0.125000 (1.485 sec)
37.345... logprob:  0.488147, 0.132812 (1.439 sec)
37.346... logprob:  0.436196, 0.117188 (1.439 sec)
37.347... logprob:  0.372664, 0.085938 (1.494 sec)
37.348... logprob:  0.398532, 0.101562 (1.437 sec)
37.349... logprob:  0.497440, 0.140625 (1.441 sec)
37.350... logprob:  0.358814, 0.085938 (1.436 sec)
37.351... logprob:  0.508379, 0.140625 (1.434 sec)
37.352... logprob:  0.363592, 0.093750 (1.441 sec)
37.353... logprob:  0.512246, 0.148438 (1.491 sec)
37.354... logprob:  0.674575, 0.203125 (1.431 sec)
37.355... logprob:  0.357521, 0.085938 (1.447 sec)
37.356... logprob:  0.479237, 0.132812 (1.480 sec)
37.357... logprob:  0.346563, 0.085938 (1.434 sec)
37.358... logprob:  0.325599, 0.070312 (1.438 sec)
37.359... logprob:  0.555477, 0.164062 (1.432 sec)
37.360... logprob:  0.444535, 0.117188 (1.432 sec)
37.361... logprob:  0.410708, 0.101562 (1.438 sec)
37.362... logprob:  0.423836, 0.117188 (1.474 sec)
37.363... logprob:  0.486611, 0.132812 (1.448 sec)
37.364... logprob:  0.475665, 0.125000 (1.452 sec)
37.365... logprob:  0.425018, 0.109375 (1.465 sec)
37.366... logprob:  0.409492, 0.109375 (1.445 sec)
37.367... logprob:  0.324830, 0.078125 (1.444 sec)
37.368... logprob:  0.595497, 0.171875 (1.430 sec)
37.369... logprob:  0.381730, 0.093750 (1.428 sec)
37.370... logprob:  0.381370, 0.093750 (1.438 sec)
37.371... logprob:  0.400470, 0.101562 (1.461 sec)
37.372... logprob:  0.537015, 0.156250 (1.454 sec)
37.373... logprob:  0.463765, 0.125000 (1.458 sec)
37.374... logprob:  0.526674, 0.148438 (1.451 sec)
37.375... logprob:  0.393760, 0.101562 (1.463 sec)
37.376... logprob:  0.374283, 0.093750 (1.442 sec)
37.377... logprob:  0.295488, 0.062500 (1.429 sec)
37.378... logprob:  0.453601, 0.125000 (1.431 sec)
37.379... logprob:  0.420251, 0.109375 (1.448 sec)
37.380... logprob:  0.605598, 0.179688 (1.440 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.791019439697266, 10.0]}, 128)
batch 872: ({'logprob': [66.61772918701172, 19.0]}, 128)
batch 873: ({'logprob': [40.506561279296875, 9.0]}, 128)
batch 874: ({'logprob': [45.2166862487793, 11.0]}, 128)
batch 875: ({'logprob': [50.762237548828125, 13.0]}, 128)
batch 876: ({'logprob': [64.08524322509766, 18.0]}, 128)
batch 877: ({'logprob': [45.64875411987305, 11.0]}, 128)
batch 878: ({'logprob': [61.919673919677734, 17.0]}, 128)
batch 879: ({'logprob': [73.44456481933594, 21.0]}, 128)
batch 880: ({'logprob': [50.793216705322266, 13.0]}, 128)
batch 881: ({'logprob': [28.9403133392334, 5.0]}, 128)
batch 882: ({'logprob': [54.62608337402344, 14.0]}, 128)
batch 883: ({'logprob': [61.88666915893555, 17.0]}, 128)
batch 884: ({'logprob': [51.19859313964844, 13.0]}, 128)
batch 885: ({'logprob': [52.038700103759766, 13.0]}, 128)
batch 886: ({'logprob': [62.336612701416016, 17.0]}, 128)

======================Test output======================
logprob:  0.415924, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954941e-03 [4.603058e-09] 
Layer 'conv1' biases: 5.109836e-07 [1.884751e-10] 
Layer 'conv2' weights[0]: 7.942092e-03 [3.852368e-09] 
Layer 'conv2' biases: 1.000000e+00 [9.377422e-10] 
Layer 'conv3' weights[0]: 7.940282e-03 [4.074078e-09] 
Layer 'conv3' biases: 4.304869e-06 [2.775372e-09] 
Layer 'conv4' weights[0]: 7.972945e-03 [3.788245e-09] 
Layer 'conv4' biases: 9.999990e-01 [2.193633e-08] 
Layer 'conv5' weights[0]: 7.971667e-03 [1.330899e-07] 
Layer 'conv5' biases: 9.999880e-01 [1.426886e-07] 
Layer 'fc6' weights[0]: 7.568162e-03 [1.077042e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.104485e-08] 
Layer 'fc7' weights[0]: 6.685840e-03 [1.001039e-07] 
Layer 'fc7' biases: 9.998499e-01 [8.754849e-08] 
Layer 'fc8' weights[0]: 1.269261e-03 [4.085253e-06] 
Layer 'fc8' biases: 9.254825e-02 [2.791989e-05] 
Train error last 870 batches: 0.435151
-------------------------------------------------------
Not saving because 0.415924 > 0.415638 (32.630: -0.00%)
======================================================= (12.033 sec)
37.381... logprob:  0.463378, 0.125000 (1.476 sec)
37.382... logprob:  0.529624, 0.148438 (1.459 sec)
37.383... logprob:  0.358443, 0.085938 (1.439 sec)
37.384... logprob:  0.521313, 0.148438 (1.484 sec)
37.385... logprob:  0.523660, 0.148438 (1.432 sec)
37.386... logprob:  0.582741, 0.171875 (1.432 sec)
37.387... logprob:  0.428401, 0.117188 (1.435 sec)
37.388... logprob:  0.521428, 0.148438 (1.437 sec)
37.389... logprob:  0.425364, 0.109375 (1.434 sec)
37.390... logprob:  0.419501, 0.109375 (1.477 sec)
37.391... logprob:  0.317967, 0.070312 (1.449 sec)
37.392... logprob:  0.439451, 0.117188 (1.434 sec)
37.393... logprob:  0.369127, 0.093750 (1.490 sec)
37.394... logprob:  0.343835, 0.078125 (1.433 sec)
37.395... logprob:  0.332126, 0.078125 (1.435 sec)
37.396... logprob:  0.253062, 0.046875 (1.434 sec)
37.397... logprob:  0.483710, 0.132812 (1.437 sec)
37.398... logprob:  0.470185, 0.125000 (1.440 sec)
37.399... logprob:  0.432801, 0.117188 (1.486 sec)
37.400... logprob:  0.536676, 0.148438 (1.436 sec)
37.401... logprob:  0.465258, 0.125000 (1.444 sec)
37.402... logprob:  0.473508, 0.125000 (1.481 sec)
37.403... logprob:  0.461978, 0.125000 (1.433 sec)
37.404... logprob:  0.474763, 0.125000 (1.439 sec)
37.405... logprob:  0.544516, 0.156250 (1.436 sec)
37.406... logprob:  0.357325, 0.085938 (1.432 sec)
37.407... logprob:  0.493270, 0.140625 (1.431 sec)
37.408... logprob:  0.338293, 0.078125 (1.484 sec)
37.409... logprob:  0.400028, 0.101562 (1.442 sec)
37.410... logprob:  0.582705, 0.171875 (1.451 sec)
37.411... logprob:  0.397356, 0.101562 (1.473 sec)
37.412... logprob:  0.540420, 0.156250 (1.439 sec)
37.413... logprob:  0.544645, 0.156250 (1.441 sec)
37.414... logprob:  0.466197, 0.125000 (1.429 sec)
37.415... logprob:  0.401512, 0.101562 (1.428 sec)
37.416... logprob:  0.427407, 0.109375 (1.443 sec)
37.417... logprob:  0.405448, 0.093750 (1.463 sec)
37.418... logprob:  0.380694, 0.093750 (1.454 sec)
37.419... logprob:  0.418082, 0.101562 (1.454 sec)
37.420... logprob:  0.356899, 0.085938 (1.459 sec)
37.421... logprob:  0.376777, 0.101562 (1.459 sec)
37.422... logprob:  0.521400, 0.148438 (1.440 sec)
37.423... logprob:  0.420660, 0.109375 (1.426 sec)
37.424... logprob:  0.325159, 0.078125 (1.433 sec)
37.425... logprob:  0.306812, 0.070312 (1.442 sec)
37.426... logprob:  0.448719, 0.117188 (1.445 sec)
37.427... logprob:  0.553273, 0.156250 (1.462 sec)
37.428... logprob:  0.600915, 0.171875 (1.458 sec)
37.429... logprob:  0.426385, 0.109375 (1.445 sec)
37.430... logprob:  0.299659, 0.070312 (1.477 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.156131744384766, 10.0]}, 128)
batch 872: ({'logprob': [67.2879409790039, 19.0]}, 128)
batch 873: ({'logprob': [39.98808288574219, 9.0]}, 128)
batch 874: ({'logprob': [44.845333099365234, 11.0]}, 128)
batch 875: ({'logprob': [50.68816375732422, 13.0]}, 128)
batch 876: ({'logprob': [64.64456176757812, 18.0]}, 128)
batch 877: ({'logprob': [45.351783752441406, 11.0]}, 128)
batch 878: ({'logprob': [62.442176818847656, 17.0]}, 128)
batch 879: ({'logprob': [74.63898468017578, 21.0]}, 128)
batch 880: ({'logprob': [50.719276428222656, 13.0]}, 128)
batch 881: ({'logprob': [27.748258590698242, 5.0]}, 128)
batch 882: ({'logprob': [54.891380310058594, 14.0]}, 128)
batch 883: ({'logprob': [62.409324645996094, 17.0]}, 128)
batch 884: ({'logprob': [51.20255661010742, 13.0]}, 128)
batch 885: ({'logprob': [52.19355010986328, 13.0]}, 128)
batch 886: ({'logprob': [62.935935974121094, 17.0]}, 128)

======================Test output======================
logprob:  0.416574, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954903e-03 [2.589255e-09] 
Layer 'conv1' biases: 5.120858e-07 [4.868555e-11] 
Layer 'conv2' weights[0]: 7.942056e-03 [1.973282e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.636453e-10] 
Layer 'conv3' weights[0]: 7.940246e-03 [1.628189e-09] 
Layer 'conv3' biases: 4.313213e-06 [7.681581e-10] 
Layer 'conv4' weights[0]: 7.972907e-03 [1.548736e-09] 
Layer 'conv4' biases: 9.999990e-01 [5.391949e-09] 
Layer 'conv5' weights[0]: 7.971633e-03 [3.108755e-08] 
Layer 'conv5' biases: 9.999882e-01 [3.322377e-08] 
Layer 'fc6' weights[0]: 7.568121e-03 [2.684644e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.615025e-09] 
Layer 'fc7' weights[0]: 6.684147e-03 [1.860553e-07] 
Layer 'fc7' biases: 9.998510e-01 [1.770955e-07] 
Layer 'fc8' weights[0]: 1.288471e-03 [6.990874e-06] 
Layer 'fc8' biases: 9.303226e-02 [3.994062e-05] 
Train error last 870 batches: 0.435151
-------------------------------------------------------
Not saving because 0.416574 > 0.415638 (32.630: -0.00%)
======================================================= (12.061 sec)
37.431... logprob:  0.600522, 0.171875 (1.443 sec)
37.432... logprob:  0.387497, 0.093750 (1.437 sec)
37.433... logprob:  0.329189, 0.078125 (1.431 sec)
37.434... logprob:  0.530055, 0.148438 (1.443 sec)
37.435... logprob:  0.532889, 0.156250 (1.430 sec)
37.436... logprob:  0.380482, 0.093750 (1.480 sec)
37.437... logprob:  0.500436, 0.140625 (1.447 sec)
37.438... logprob:  0.547202, 0.156250 (1.430 sec)
37.439... logprob:  0.378101, 0.093750 (1.495 sec)
37.440... logprob:  0.439464, 0.117188 (1.433 sec)
37.441... logprob:  0.467865, 0.125000 (1.432 sec)
37.442... logprob:  0.378868, 0.093750 (1.434 sec)
37.443... logprob:  0.496543, 0.140625 (1.437 sec)
37.444... logprob:  0.372612, 0.093750 (1.434 sec)
37.445... logprob:  0.362960, 0.085938 (1.485 sec)
37.446... logprob:  0.398613, 0.101562 (1.440 sec)
37.447... logprob:  0.568913, 0.164062 (1.439 sec)
37.448... logprob:  0.333422, 0.078125 (1.486 sec)
37.449... logprob:  0.400088, 0.101562 (1.434 sec)
37.450... logprob:  0.240459, 0.046875 (1.436 sec)
37.451... logprob:  0.452126, 0.125000 (1.437 sec)
37.452... logprob:  0.455699, 0.117188 (1.432 sec)
37.453... logprob:  0.454747, 0.125000 (1.431 sec)
37.454... logprob:  0.488553, 0.132812 (1.488 sec)
37.455... logprob:  0.505856, 0.140625 (1.439 sec)
37.456... logprob:  0.468831, 0.125000 (1.449 sec)
37.457... logprob:  0.375283, 0.093750 (1.477 sec)
37.458... logprob:  0.350818, 0.085938 (1.435 sec)
37.459... logprob:  0.514368, 0.140625 (1.440 sec)
37.460... logprob:  0.273063, 0.054688 (1.433 sec)
37.461... logprob:  0.460257, 0.125000 (1.430 sec)
37.462... logprob:  0.472093, 0.125000 (1.437 sec)
37.463... logprob:  0.420715, 0.109375 (1.471 sec)
37.464... logprob:  0.482904, 0.132812 (1.447 sec)
37.465... logprob:  0.421016, 0.109375 (1.458 sec)
37.466... logprob:  0.317954, 0.070312 (1.461 sec)
37.467... logprob:  0.413780, 0.109375 (1.453 sec)
37.468... logprob:  0.394224, 0.101562 (1.439 sec)
37.469... logprob:  0.334849, 0.078125 (1.432 sec)
37.470... logprob:  0.400133, 0.101562 (1.425 sec)
37.471... logprob:  0.528966, 0.148438 (1.441 sec)
37.472... logprob:  0.409927, 0.109375 (1.451 sec)
37.473... logprob:  0.375573, 0.093750 (1.463 sec)
37.474... logprob:  0.465323, 0.125000 (1.454 sec)
37.475... logprob:  0.503550, 0.140625 (1.452 sec)
37.476... logprob:  0.509908, 0.140625 (1.470 sec)
37.477... logprob:  0.334769, 0.078125 (1.440 sec)
37.478... logprob:  0.464178, 0.125000 (1.424 sec)
37.479... logprob:  0.305796, 0.070312 (1.436 sec)
37.480... logprob:  0.443487, 0.117188 (1.439 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.74906539916992, 10.0]}, 128)
batch 872: ({'logprob': [66.71112060546875, 19.0]}, 128)
batch 873: ({'logprob': [40.40608215332031, 9.0]}, 128)
batch 874: ({'logprob': [45.17023468017578, 11.0]}, 128)
batch 875: ({'logprob': [50.744388580322266, 13.0]}, 128)
batch 876: ({'logprob': [64.15770721435547, 18.0]}, 128)
batch 877: ({'logprob': [45.589420318603516, 11.0]}, 128)
batch 878: ({'logprob': [61.958866119384766, 17.0]}, 128)
batch 879: ({'logprob': [73.52874755859375, 21.0]}, 128)
batch 880: ({'logprob': [50.7751350402832, 13.0]}, 128)
batch 881: ({'logprob': [28.79511070251465, 5.0]}, 128)
batch 882: ({'logprob': [54.59102249145508, 14.0]}, 128)
batch 883: ({'logprob': [61.92629623413086, 17.0]}, 128)
batch 884: ({'logprob': [51.16838455200195, 13.0]}, 128)
batch 885: ({'logprob': [51.98332214355469, 13.0]}, 128)
batch 886: ({'logprob': [62.3633918762207, 17.0]}, 128)

======================Test output======================
logprob:  0.415829, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954864e-03 [2.681329e-09] 
Layer 'conv1' biases: 5.130001e-07 [4.118026e-11] 
Layer 'conv2' weights[0]: 7.942018e-03 [1.730518e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.718616e-10] 
Layer 'conv3' weights[0]: 7.940209e-03 [1.271167e-09] 
Layer 'conv3' biases: 4.321136e-06 [5.117390e-10] 
Layer 'conv4' weights[0]: 7.972876e-03 [1.246648e-09] 
Layer 'conv4' biases: 9.999989e-01 [3.248198e-09] 
Layer 'conv5' weights[0]: 7.971593e-03 [1.969016e-08] 
Layer 'conv5' biases: 9.999880e-01 [2.109264e-08] 
Layer 'fc6' weights[0]: 7.568088e-03 [1.786490e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.624152e-09] 
Layer 'fc7' weights[0]: 6.682522e-03 [3.713348e-08] 
Layer 'fc7' biases: 9.998499e-01 [1.385692e-08] 
Layer 'fc8' weights[0]: 1.262144e-03 [1.199564e-06] 
Layer 'fc8' biases: 9.309997e-02 [7.636942e-06] 
Train error last 870 batches: 0.435151
-------------------------------------------------------
Not saving because 0.415829 > 0.415638 (32.630: -0.00%)
======================================================= (12.128 sec)
37.481... logprob:  0.547828, 0.156250 (1.444 sec)
37.482... logprob:  0.443108, 0.117188 (1.484 sec)
37.483... logprob:  0.502774, 0.140625 (1.447 sec)
37.484... logprob:  0.485349, 0.132812 (1.437 sec)
37.485... logprob:  0.408811, 0.109375 (1.488 sec)
37.486... logprob:  0.361041, 0.085938 (1.431 sec)
37.487... logprob:  0.522776, 0.148438 (1.433 sec)
37.488... logprob:  0.424592, 0.109375 (1.496 sec)
37.489... logprob:  0.415721, 0.109375 (1.435 sec)
37.490... logprob:  0.440672, 0.117188 (1.434 sec)
37.491... logprob:  0.313496, 0.070312 (1.483 sec)
37.492... logprob:  0.459476, 0.125000 (1.443 sec)
37.493... logprob:  0.521707, 0.148438 (1.446 sec)
37.494... logprob:  0.450328, 0.125000 (1.493 sec)
37.495... logprob:  0.380768, 0.093750 (1.434 sec)
37.496... logprob:  0.550004, 0.156250 (1.438 sec)
37.497... logprob:  0.466801, 0.125000 (1.442 sec)
37.498... logprob:  0.476133, 0.132812 (1.429 sec)
37.499... logprob:  0.456190, 0.125000 (1.440 sec)
37.500... logprob:  0.355225, 0.085938 (1.487 sec)
37.501... logprob:  0.339154, 0.078125 (1.433 sec)
37.502... logprob:  0.459562, 0.125000 (1.444 sec)
37.503... logprob:  0.400648, 0.101562 (1.484 sec)
37.504... logprob:  0.487229, 0.132812 (1.431 sec)
37.505... logprob:  0.570719, 0.164062 (1.439 sec)
37.506... logprob:  0.479684, 0.132812 (1.438 sec)
37.507... logprob:  0.384958, 0.093750 (1.427 sec)
37.508... logprob:  0.374595, 0.093750 (1.445 sec)
37.509... logprob:  0.322850, 0.070312 (1.480 sec)
37.510... logprob:  0.390438, 0.101562 (1.442 sec)
37.511... logprob:  0.410021, 0.109375 (1.451 sec)
37.512... logprob:  0.470699, 0.125000 (1.470 sec)
37.513... logprob:  0.324952, 0.078125 (1.446 sec)
37.514... logprob:  0.406271, 0.101562 (1.437 sec)
37.515... logprob:  0.455379, 0.125000 (1.432 sec)
37.516... logprob:  0.400158, 0.109375 (1.428 sec)
37.517... logprob:  0.627541, 0.179688 (1.440 sec)
37.518... logprob:  0.437600, 0.117188 (1.461 sec)
37.519... logprob:  0.516122, 0.140625 (1.454 sec)
37.520... logprob:  0.409633, 0.109375 (1.457 sec)
37.521... logprob:  0.427364, 0.109375 (1.450 sec)
37.522... logprob:  0.533252, 0.156250 (1.468 sec)
37.523... logprob:  0.331281, 0.078125 (1.438 sec)
37.524... logprob:  0.437081, 0.117188 (1.428 sec)
37.525... logprob:  0.425765, 0.109375 (1.432 sec)
37.526... logprob:  0.351431, 0.078125 (1.438 sec)
37.527... logprob:  0.504608, 0.140625 (1.445 sec)
37.528... logprob:  0.440418, 0.117188 (1.469 sec)
37.529... logprob:  0.352992, 0.085938 (1.450 sec)
37.530... logprob:  0.440262, 0.117188 (1.446 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.9190673828125, 10.0]}, 128)
batch 872: ({'logprob': [66.35792541503906, 19.0]}, 128)
batch 873: ({'logprob': [40.831539154052734, 9.0]}, 128)
batch 874: ({'logprob': [45.37094497680664, 11.0]}, 128)
batch 875: ({'logprob': [50.83606719970703, 13.0]}, 128)
batch 876: ({'logprob': [63.88768768310547, 18.0]}, 128)
batch 877: ({'logprob': [45.84809494018555, 11.0]}, 128)
batch 878: ({'logprob': [61.83057403564453, 17.0]}, 128)
batch 879: ({'logprob': [73.23751831054688, 21.0]}, 128)
batch 880: ({'logprob': [50.866458892822266, 13.0]}, 128)
batch 881: ({'logprob': [29.383758544921875, 5.0]}, 128)
batch 882: ({'logprob': [54.770267486572266, 14.0]}, 128)
batch 883: ({'logprob': [61.79806900024414, 17.0]}, 128)
batch 884: ({'logprob': [51.31600570678711, 13.0]}, 128)
batch 885: ({'logprob': [52.245975494384766, 13.0]}, 128)
batch 886: ({'logprob': [62.29190444946289, 17.0]}, 128)

======================Test output======================
logprob:  0.416402, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954838e-03 [2.430800e-09] 
Layer 'conv1' biases: 5.141224e-07 [1.003357e-10] 
Layer 'conv2' weights[0]: 7.941984e-03 [2.510325e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.060447e-10] 
Layer 'conv3' weights[0]: 7.940168e-03 [2.254713e-09] 
Layer 'conv3' biases: 4.333181e-06 [1.145131e-09] 
Layer 'conv4' weights[0]: 7.972833e-03 [2.287589e-09] 
Layer 'conv4' biases: 9.999989e-01 [9.402883e-09] 
Layer 'conv5' weights[0]: 7.971551e-03 [5.833580e-08] 
Layer 'conv5' biases: 9.999874e-01 [6.240683e-08] 
Layer 'fc6' weights[0]: 7.568047e-03 [4.833007e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.818767e-09] 
Layer 'fc7' weights[0]: 6.680757e-03 [1.671879e-07] 
Layer 'fc7' biases: 9.998497e-01 [1.571951e-07] 
Layer 'fc8' weights[0]: 1.250785e-03 [6.019223e-06] 
Layer 'fc8' biases: 9.308262e-02 [4.447578e-05] 
Train error last 870 batches: 0.435150
-------------------------------------------------------
Not saving because 0.416402 > 0.415638 (32.630: -0.00%)
======================================================= (12.036 sec)
37.531... logprob:  0.439914, 0.117188 (1.484 sec)
37.532... logprob:  0.467251, 0.125000 (1.437 sec)
37.533... logprob:  0.560044, 0.164062 (1.435 sec)
37.534... logprob:  0.326066, 0.078125 (1.437 sec)
37.535... logprob:  0.551233, 0.156250 (1.441 sec)
37.536... logprob:  0.507157, 0.140625 (1.433 sec)
37.537... logprob:  0.509932, 0.140625 (1.479 sec)
37.538... logprob:  0.486058, 0.132812 (1.446 sec)
37.539... logprob:  0.295953, 0.062500 (1.432 sec)
37.540... logprob:  0.447178, 0.117188 (1.491 sec)
37.541... logprob:  0.388717, 0.101562 (1.436 sec)
37.542... logprob:  0.411179, 0.109375 (1.429 sec)
37.543... logprob:  0.233064, 0.039062 (1.437 sec)
37.544... logprob:  0.317908, 0.070312 (1.435 sec)
37.545... logprob:  0.348790, 0.085938 (1.438 sec)
37.546... logprob:  0.368257, 0.093750 (1.492 sec)
37.547... logprob:  0.439911, 0.117188 (1.434 sec)
37.548... logprob:  0.452640, 0.125000 (1.447 sec)
37.549... logprob:  0.490198, 0.132812 (1.479 sec)
37.550... logprob:  0.367547, 0.093750 (1.436 sec)
37.551... logprob:  0.441505, 0.117188 (1.450 sec)
37.552... logprob:  0.471186, 0.125000 (1.442 sec)
37.553... logprob:  0.349454, 0.085938 (1.435 sec)
37.554... logprob:  0.507089, 0.140625 (1.435 sec)
37.555... logprob:  0.421410, 0.109375 (1.484 sec)
37.556... logprob:  0.355674, 0.085938 (1.439 sec)
37.557... logprob:  0.396274, 0.101562 (1.453 sec)
37.558... logprob:  0.382968, 0.101562 (1.472 sec)
37.559... logprob:  0.441744, 0.125000 (1.435 sec)
37.560... logprob:  0.334809, 0.078125 (1.444 sec)
37.561... logprob:  0.411756, 0.109375 (1.431 sec)
37.562... logprob:  0.503203, 0.140625 (1.425 sec)
37.563... logprob:  0.373679, 0.093750 (1.442 sec)
37.564... logprob:  0.468544, 0.132812 (1.467 sec)
37.565... logprob:  0.611265, 0.187500 (1.450 sec)
37.566... logprob:  0.374828, 0.093750 (1.457 sec)
37.567... logprob:  0.423209, 0.109375 (1.468 sec)
37.568... logprob:  0.496300, 0.140625 (1.457 sec)
37.569... logprob:  0.507575, 0.140625 (1.440 sec)
37.570... logprob:  0.543842, 0.164062 (1.427 sec)
37.571... logprob:  0.454894, 0.125000 (1.428 sec)
37.572... logprob:  0.501290, 0.140625 (1.444 sec)
37.573... logprob:  0.512579, 0.148438 (1.454 sec)
37.574... logprob:  0.427947, 0.109375 (1.463 sec)
37.575... logprob:  0.343315, 0.078125 (1.457 sec)
37.576... logprob:  0.427318, 0.109375 (1.445 sec)
37.577... logprob:  0.460754, 0.125000 (1.476 sec)
37.578... logprob:  0.336922, 0.078125 (1.439 sec)
37.579... logprob:  0.442079, 0.117188 (1.422 sec)
37.580... logprob:  0.546416, 0.156250 (1.439 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.46174240112305, 10.0]}, 128)
batch 872: ({'logprob': [66.20771026611328, 19.0]}, 128)
batch 873: ({'logprob': [41.25245666503906, 9.0]}, 128)
batch 874: ({'logprob': [45.359500885009766, 11.0]}, 128)
batch 875: ({'logprob': [50.923255920410156, 13.0]}, 128)
batch 876: ({'logprob': [63.82061004638672, 18.0]}, 128)
batch 877: ({'logprob': [46.101383209228516, 11.0]}, 128)
batch 878: ({'logprob': [62.11197280883789, 17.0]}, 128)
batch 879: ({'logprob': [73.97679138183594, 21.0]}, 128)
batch 880: ({'logprob': [50.95259094238281, 13.0]}, 128)
batch 881: ({'logprob': [29.345190048217773, 5.0]}, 128)
batch 882: ({'logprob': [55.56690216064453, 14.0]}, 128)
batch 883: ({'logprob': [62.08013153076172, 17.0]}, 128)
batch 884: ({'logprob': [51.66722106933594, 13.0]}, 128)
batch 885: ({'logprob': [53.12653350830078, 13.0]}, 128)
batch 886: ({'logprob': [62.837974548339844, 17.0]}, 128)

======================Test output======================
logprob:  0.418355, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954809e-03 [2.593299e-09] 
Layer 'conv1' biases: 5.152949e-07 [5.579281e-11] 
Layer 'conv2' weights[0]: 7.941937e-03 [1.897298e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.726009e-10] 
Layer 'conv3' weights[0]: 7.940132e-03 [1.604943e-09] 
Layer 'conv3' biases: 4.341569e-06 [8.477641e-10] 
Layer 'conv4' weights[0]: 7.972791e-03 [1.590798e-09] 
Layer 'conv4' biases: 9.999990e-01 [6.128808e-09] 
Layer 'conv5' weights[0]: 7.971511e-03 [3.920967e-08] 
Layer 'conv5' biases: 9.999871e-01 [4.198245e-08] 
Layer 'fc6' weights[0]: 7.568010e-03 [3.251753e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.239078e-09] 
Layer 'fc7' weights[0]: 6.679054e-03 [1.669830e-07] 
Layer 'fc7' biases: 9.998506e-01 [1.571386e-07] 
Layer 'fc8' weights[0]: 1.254001e-03 [7.845162e-06] 
Layer 'fc8' biases: 9.321739e-02 [5.713316e-05] 
Train error last 870 batches: 0.435150
-------------------------------------------------------
Not saving because 0.418355 > 0.415638 (32.630: -0.00%)
======================================================= (12.056 sec)
37.581... logprob:  0.530380, 0.156250 (1.445 sec)
37.582... logprob:  0.437739, 0.125000 (1.444 sec)
37.583... logprob:  0.592123, 0.171875 (1.484 sec)
37.584... logprob:  0.468027, 0.132812 (1.470 sec)
37.585... logprob:  0.349780, 0.085938 (1.434 sec)
37.586... logprob:  0.313017, 0.070312 (1.490 sec)
37.587... logprob:  0.404288, 0.101562 (1.436 sec)
37.588... logprob:  0.418645, 0.117188 (1.430 sec)
37.589... logprob:  0.361070, 0.093750 (1.437 sec)
37.590... logprob:  0.524824, 0.148438 (1.436 sec)
37.591... logprob:  0.397424, 0.101562 (1.435 sec)
37.592... logprob:  0.455703, 0.125000 (1.485 sec)
37.593... logprob:  0.467414, 0.125000 (1.439 sec)
37.594... logprob:  0.352791, 0.085938 (1.441 sec)
37.595... logprob:  0.428660, 0.109375 (1.478 sec)
37.596... logprob:  0.461638, 0.125000 (1.439 sec)
37.597... logprob:  0.397420, 0.101562 (1.432 sec)
37.598... logprob:  0.397210, 0.101562 (1.442 sec)
37.599... logprob:  0.313610, 0.070312 (1.431 sec)
37.600... logprob:  0.340863, 0.085938 (1.432 sec)
37.601... logprob:  0.402176, 0.101562 (1.483 sec)
37.602... logprob:  0.290007, 0.062500 (1.443 sec)
37.603... logprob:  0.267362, 0.054688 (1.447 sec)
37.604... logprob:  0.407537, 0.101562 (1.476 sec)
37.605... logprob:  0.563103, 0.148438 (1.437 sec)
37.606... logprob:  0.295952, 0.070312 (1.440 sec)
37.607... logprob:  0.504547, 0.132812 (1.433 sec)
37.608... logprob:  0.361993, 0.085938 (1.427 sec)
37.609... logprob:  0.357127, 0.085938 (1.441 sec)
37.610... logprob:  0.493194, 0.132812 (1.473 sec)
37.611... logprob:  0.510252, 0.140625 (1.444 sec)
37.612... logprob:  0.448627, 0.117188 (1.456 sec)
37.613... logprob:  0.279090, 0.062500 (1.463 sec)
37.614... logprob:  0.503596, 0.140625 (1.452 sec)
37.615... logprob:  0.350598, 0.085938 (1.442 sec)
37.616... logprob:  0.414894, 0.109375 (1.430 sec)
37.617... logprob:  0.417742, 0.109375 (1.424 sec)
37.618... logprob:  0.547238, 0.156250 (1.443 sec)
37.619... logprob:  0.506233, 0.140625 (1.452 sec)
37.620... logprob:  0.539760, 0.156250 (1.463 sec)
37.621... logprob:  0.363359, 0.085938 (1.454 sec)
37.622... logprob:  0.364496, 0.085938 (1.451 sec)
37.623... logprob:  0.423059, 0.109375 (1.471 sec)
37.624... logprob:  0.382466, 0.093750 (1.444 sec)
37.625... logprob:  0.440965, 0.117188 (1.455 sec)
37.626... logprob:  0.438319, 0.117188 (1.431 sec)
37.627... logprob:  0.435797, 0.117188 (1.440 sec)
37.628... logprob:  0.464984, 0.125000 (1.438 sec)
37.629... logprob:  0.372243, 0.093750 (1.475 sec)
37.630... logprob:  0.422399, 0.109375 (1.451 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.80524826049805, 10.0]}, 128)
batch 872: ({'logprob': [67.0461654663086, 19.0]}, 128)
batch 873: ({'logprob': [40.114986419677734, 9.0]}, 128)
batch 874: ({'logprob': [45.1148567199707, 11.0]}, 128)
batch 875: ({'logprob': [50.739830017089844, 13.0]}, 128)
batch 876: ({'logprob': [64.42184448242188, 18.0]}, 128)
batch 877: ({'logprob': [45.441864013671875, 11.0]}, 128)
batch 878: ({'logprob': [62.05865478515625, 17.0]}, 128)
batch 879: ({'logprob': [73.64087677001953, 21.0]}, 128)
batch 880: ({'logprob': [50.77132034301758, 13.0]}, 128)
batch 881: ({'logprob': [28.49153709411621, 5.0]}, 128)
batch 882: ({'logprob': [54.383758544921875, 14.0]}, 128)
batch 883: ({'logprob': [62.025299072265625, 17.0]}, 128)
batch 884: ({'logprob': [51.07328796386719, 13.0]}, 128)
batch 885: ({'logprob': [51.70417404174805, 13.0]}, 128)
batch 886: ({'logprob': [62.37173080444336, 17.0]}, 128)

======================Test output======================
logprob:  0.415628, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954778e-03 [2.829541e-09] 
Layer 'conv1' biases: 5.164319e-07 [4.008816e-11] 
Layer 'conv2' weights[0]: 7.941895e-03 [2.004574e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.019421e-10] 
Layer 'conv3' weights[0]: 7.940090e-03 [1.475184e-09] 
Layer 'conv3' biases: 4.350949e-06 [6.276727e-10] 
Layer 'conv4' weights[0]: 7.972750e-03 [1.537381e-09] 
Layer 'conv4' biases: 9.999989e-01 [4.571813e-09] 
Layer 'conv5' weights[0]: 7.971465e-03 [2.887054e-08] 
Layer 'conv5' biases: 9.999872e-01 [3.084384e-08] 
Layer 'fc6' weights[0]: 7.567970e-03 [2.485658e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.372501e-09] 
Layer 'fc7' weights[0]: 6.677335e-03 [1.893474e-07] 
Layer 'fc7' biases: 9.998500e-01 [1.794272e-07] 
Layer 'fc8' weights[0]: 1.271811e-03 [6.227166e-06] 
Layer 'fc8' biases: 9.352125e-02 [4.701194e-05] 
Train error last 870 batches: 0.435150
-------------------------------------------------------
Saved checkpoint to /data2/ad6813/my-nets/saves/ConvNet__2014-06-17_23.05.49
======================================================= (12.768 sec)
37.631... logprob:  0.637838, 0.187500 (1.446 sec)
37.632... logprob:  0.399143, 0.101562 (1.495 sec)
37.633... logprob:  0.376181, 0.093750 (1.446 sec)
37.634... logprob:  0.659791, 0.195312 (2.558 sec)
37.635... logprob:  0.374134, 0.093750 (1.436 sec)
37.636... logprob:  0.480274, 0.132812 (1.446 sec)
37.637... logprob:  0.330637, 0.078125 (3.074 sec)
37.638... logprob:  0.515728, 0.140625 (1.479 sec)
37.639... logprob:  0.417965, 0.109375 (1.452 sec)
37.640... logprob:  0.528778, 0.148438 (1.442 sec)
37.641... logprob:  0.410363, 0.109375 (1.487 sec)
37.642... logprob:  0.500967, 0.140625 (1.435 sec)
37.643... logprob:  0.623551, 0.187500 (1.436 sec)
37.644... logprob:  0.320637, 0.070312 (1.442 sec)
37.645... logprob:  0.414407, 0.109375 (1.434 sec)
37.646... logprob:  0.385441, 0.093750 (1.441 sec)
37.647... logprob:  0.456817, 0.125000 (1.516 sec)
37.648... logprob:  0.491310, 0.140625 (1.443 sec)
37.649... logprob:  0.370420, 0.093750 (1.453 sec)
37.650... logprob:  0.414092, 0.109375 (1.480 sec)
37.651... logprob:  0.397473, 0.101562 (1.441 sec)
37.652... logprob:  0.506900, 0.140625 (1.437 sec)
37.653... logprob:  0.547470, 0.156250 (1.437 sec)
37.654... logprob:  0.495924, 0.140625 (1.429 sec)
37.655... logprob:  0.436165, 0.117188 (1.433 sec)
37.656... logprob:  0.416743, 0.109375 (1.501 sec)
37.657... logprob:  0.448910, 0.117188 (1.451 sec)
37.658... logprob:  0.345977, 0.085938 (1.459 sec)
37.659... logprob:  0.464233, 0.125000 (1.470 sec)
37.660... logprob:  0.446130, 0.125000 (1.444 sec)
37.661... logprob:  0.378339, 0.093750 (1.446 sec)
37.662... logprob:  0.469542, 0.132812 (1.435 sec)
37.663... logprob:  0.310763, 0.070312 (1.436 sec)
37.664... logprob:  0.285276, 0.062500 (1.445 sec)
37.665... logprob:  0.401585, 0.101562 (1.464 sec)
37.666... logprob:  0.441998, 0.117188 (1.464 sec)
37.667... logprob:  0.564154, 0.164062 (1.460 sec)
37.668... logprob:  0.497817, 0.140625 (1.480 sec)
37.669... logprob:  0.432806, 0.109375 (1.472 sec)
37.670... logprob:  0.362270, 0.085938 (1.438 sec)
37.671... logprob:  0.360887, 0.093750 (1.429 sec)
37.672... logprob:  0.441833, 0.117188 (1.433 sec)
37.673... logprob:  0.436219, 0.117188 (1.440 sec)
37.674... logprob:  0.446607, 0.117188 (1.441 sec)
37.675... logprob:  0.356698, 0.093750 (1.470 sec)
37.676... logprob:  0.450215, 0.125000 (1.455 sec)
37.677... logprob:  0.470993, 0.125000 (1.446 sec)
37.678... logprob:  0.465670, 0.125000 (1.484 sec)
37.679... logprob:  0.454862, 0.125000 (1.436 sec)
37.680... logprob:  0.351594, 0.078125 (1.429 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.72718811035156, 10.0]}, 128)
batch 872: ({'logprob': [66.12456512451172, 19.0]}, 128)
batch 873: ({'logprob': [41.24590301513672, 9.0]}, 128)
batch 874: ({'logprob': [45.445796966552734, 11.0]}, 128)
batch 875: ({'logprob': [50.92195510864258, 13.0]}, 128)
batch 876: ({'logprob': [63.73637771606445, 18.0]}, 128)
batch 877: ({'logprob': [46.09791564941406, 11.0]}, 128)
batch 878: ({'logprob': [61.936302185058594, 17.0]}, 128)
batch 879: ({'logprob': [73.53653717041016, 21.0]}, 128)
batch 880: ({'logprob': [50.95170593261719, 13.0]}, 128)
batch 881: ({'logprob': [29.60362434387207, 5.0]}, 128)
batch 882: ({'logprob': [55.29677200317383, 14.0]}, 128)
batch 883: ({'logprob': [61.90411376953125, 17.0]}, 128)
batch 884: ({'logprob': [51.57547378540039, 13.0]}, 128)
batch 885: ({'logprob': [52.854461669921875, 13.0]}, 128)
batch 886: ({'logprob': [62.57186508178711, 17.0]}, 128)

======================Test output======================
logprob:  0.417740, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954731e-03 [4.743783e-09] 
Layer 'conv1' biases: 5.173369e-07 [1.354484e-10] 
Layer 'conv2' weights[0]: 7.941849e-03 [2.818678e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.088039e-10] 
Layer 'conv3' weights[0]: 7.940051e-03 [2.412371e-09] 
Layer 'conv3' biases: 4.361484e-06 [1.363554e-09] 
Layer 'conv4' weights[0]: 7.972712e-03 [2.362121e-09] 
Layer 'conv4' biases: 9.999989e-01 [9.599113e-09] 
Layer 'conv5' weights[0]: 7.971450e-03 [5.061743e-08] 
Layer 'conv5' biases: 9.999878e-01 [5.391106e-08] 
Layer 'fc6' weights[0]: 7.567931e-03 [4.257961e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.248090e-09] 
Layer 'fc7' weights[0]: 6.675640e-03 [5.249259e-08] 
Layer 'fc7' biases: 9.998499e-01 [3.510743e-08] 
Layer 'fc8' weights[0]: 1.253102e-03 [3.777841e-06] 
Layer 'fc8' biases: 9.343107e-02 [2.597970e-05] 
Train error last 870 batches: 0.435149
-------------------------------------------------------
Not saving because 0.417740 > 0.415628 (37.630: -0.00%)
======================================================= (12.170 sec)
37.681... logprob:  0.373813, 0.093750 (1.440 sec)
37.682... logprob:  0.340436, 0.078125 (1.446 sec)
37.683... logprob:  0.411624, 0.109375 (1.437 sec)
37.684... logprob:  0.357762, 0.085938 (1.482 sec)
37.685... logprob:  0.286415, 0.054688 (1.446 sec)
37.686... logprob:  0.318993, 0.070312 (1.436 sec)
37.687... logprob:  0.281983, 0.062500 (1.491 sec)
37.688... logprob:  0.323197, 0.078125 (1.433 sec)
37.689... logprob:  0.470571, 0.125000 (1.430 sec)
37.690... logprob:  0.526905, 0.140625 (1.436 sec)
37.691... logprob:  0.515622, 0.140625 (1.436 sec)
37.692... logprob:  0.384440, 0.101562 (1.437 sec)
37.693... logprob:  0.455156, 0.125000 (1.484 sec)
37.694... logprob:  0.331003, 0.078125 (1.436 sec)
37.695... logprob:  0.356995, 0.085938 (1.445 sec)
37.696... logprob:  0.539567, 0.148438 (1.479 sec)
37.697... logprob:  0.465921, 0.125000 (1.436 sec)
37.698... logprob:  0.549411, 0.156250 (1.434 sec)
37.699... logprob:  0.459677, 0.125000 (1.440 sec)
37.700... logprob:  0.433674, 0.117188 (1.431 sec)
37.701... logprob:  0.422666, 0.109375 (1.434 sec)
37.702... logprob:  0.521673, 0.148438 (1.492 sec)
37.703... logprob:  0.404565, 0.101562 (1.440 sec)
37.704... logprob:  0.405618, 0.101562 (1.451 sec)
37.705... logprob:  0.419919, 0.109375 (1.472 sec)
37.706... logprob:  0.468022, 0.125000 (1.443 sec)
37.707... logprob:  0.485293, 0.132812 (1.439 sec)
37.708... logprob:  0.417339, 0.109375 (1.430 sec)
37.709... logprob:  0.422823, 0.109375 (1.424 sec)
37.710... logprob:  0.601603, 0.179688 (1.443 sec)
37.711... logprob:  0.469443, 0.125000 (1.467 sec)
37.712... logprob:  0.341411, 0.078125 (1.449 sec)
37.713... logprob:  0.585772, 0.179688 (1.458 sec)
37.714... logprob:  0.466181, 0.125000 (1.459 sec)
37.715... logprob:  0.417260, 0.109375 (1.455 sec)
37.716... logprob:  0.335720, 0.078125 (1.439 sec)
37.717... logprob:  0.429738, 0.117188 (1.428 sec)
37.718... logprob:  0.490228, 0.132812 (1.432 sec)
37.719... logprob:  0.406166, 0.109375 (1.440 sec)
37.720... logprob:  0.433212, 0.117188 (1.449 sec)
37.721... logprob:  0.451603, 0.117188 (1.467 sec)
37.722... logprob:  0.537132, 0.156250 (1.461 sec)
37.723... logprob:  0.416516, 0.109375 (1.445 sec)
37.724... logprob:  0.412748, 0.109375 (1.478 sec)
37.725... logprob:  0.495024, 0.140625 (1.435 sec)
37.726... logprob:  0.338217, 0.085938 (1.426 sec)
37.727... logprob:  0.393069, 0.101562 (1.432 sec)
37.728... logprob:  0.421102, 0.109375 (1.444 sec)
37.729... logprob:  0.387387, 0.093750 (1.436 sec)
37.730... logprob:  0.566066, 0.164062 (1.491 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.63288116455078, 10.0]}, 128)
batch 872: ({'logprob': [66.26903533935547, 19.0]}, 128)
batch 873: ({'logprob': [40.9921989440918, 9.0]}, 128)
batch 874: ({'logprob': [45.318172454833984, 11.0]}, 128)
batch 875: ({'logprob': [50.842674255371094, 13.0]}, 128)
batch 876: ({'logprob': [63.837364196777344, 18.0]}, 128)
batch 877: ({'logprob': [45.93132400512695, 11.0]}, 128)
batch 878: ({'logprob': [61.95454788208008, 17.0]}, 128)
batch 879: ({'logprob': [73.61408996582031, 21.0]}, 128)
batch 880: ({'logprob': [50.872474670410156, 13.0]}, 128)
batch 881: ({'logprob': [29.290613174438477, 5.0]}, 128)
batch 882: ({'logprob': [55.14573287963867, 14.0]}, 128)
batch 883: ({'logprob': [61.922340393066406, 17.0]}, 128)
batch 884: ({'logprob': [51.45824432373047, 13.0]}, 128)
batch 885: ({'logprob': [52.659912109375, 13.0]}, 128)
batch 886: ({'logprob': [62.551753997802734, 17.0]}, 128)

======================Test output======================
logprob:  0.417135, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954686e-03 [3.837201e-09] 
Layer 'conv1' biases: 5.183323e-07 [1.119541e-10] 
Layer 'conv2' weights[0]: 7.941813e-03 [3.054353e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.477810e-10] 
Layer 'conv3' weights[0]: 7.940012e-03 [2.698075e-09] 
Layer 'conv3' biases: 4.369531e-06 [1.654406e-09] 
Layer 'conv4' weights[0]: 7.972675e-03 [2.606639e-09] 
Layer 'conv4' biases: 9.999989e-01 [1.250540e-08] 
Layer 'conv5' weights[0]: 7.971404e-03 [7.907555e-08] 
Layer 'conv5' biases: 9.999875e-01 [8.456119e-08] 
Layer 'fc6' weights[0]: 7.567886e-03 [6.398617e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.529909e-09] 
Layer 'fc7' weights[0]: 6.673917e-03 [5.620088e-08] 
Layer 'fc7' biases: 9.998499e-01 [3.903151e-08] 
Layer 'fc8' weights[0]: 1.257905e-03 [3.624623e-06] 
Layer 'fc8' biases: 9.368845e-02 [2.461917e-05] 
Train error last 870 batches: 0.435149
-------------------------------------------------------
Not saving because 0.417135 > 0.415628 (37.630: -0.00%)
======================================================= (12.093 sec)
37.731... logprob:  0.450486, 0.125000 (1.460 sec)
37.732... logprob:  0.311278, 0.070312 (1.450 sec)
37.733... logprob:  0.556384, 0.156250 (1.491 sec)
37.734... logprob:  0.340240, 0.078125 (1.433 sec)
37.735... logprob:  0.527301, 0.148438 (1.437 sec)
37.736... logprob:  0.642263, 0.187500 (1.436 sec)
37.737... logprob:  0.516026, 0.148438 (1.433 sec)
37.738... logprob:  0.459355, 0.125000 (1.437 sec)
37.739... logprob:  0.477772, 0.132812 (1.483 sec)
37.740... logprob:  0.339643, 0.078125 (1.437 sec)
37.741... logprob:  0.393504, 0.101562 (1.443 sec)
37.742... logprob:  0.419664, 0.109375 (1.484 sec)
37.743... logprob:  0.364927, 0.085938 (1.435 sec)
37.744... logprob:  0.519062, 0.148438 (1.431 sec)
37.745... logprob:  0.478100, 0.132812 (1.439 sec)
37.746... logprob:  0.440540, 0.117188 (1.433 sec)
37.747... logprob:  0.425596, 0.109375 (1.436 sec)
37.748... logprob:  0.378223, 0.093750 (1.483 sec)
37.749... logprob:  0.420784, 0.109375 (1.437 sec)
37.750... logprob:  0.512654, 0.140625 (1.450 sec)
37.751... logprob:  0.263858, 0.054688 (1.475 sec)
37.752... logprob:  0.522482, 0.140625 (1.437 sec)
37.753... logprob:  0.441087, 0.117188 (1.440 sec)
37.754... logprob:  0.468097, 0.132812 (1.431 sec)
37.755... logprob:  0.506998, 0.140625 (1.432 sec)
37.756... logprob:  0.440847, 0.117188 (1.434 sec)
37.757... logprob:  0.552599, 0.156250 (1.473 sec)
37.758... logprob:  0.393461, 0.101562 (1.446 sec)
37.759... logprob:  0.459711, 0.125000 (1.462 sec)
37.760... logprob:  0.485665, 0.132812 (1.461 sec)
37.761... logprob:  0.417997, 0.109375 (1.450 sec)
37.762... logprob:  0.516136, 0.148438 (1.443 sec)
37.763... logprob:  0.559164, 0.164062 (1.426 sec)
37.764... logprob:  0.503258, 0.140625 (1.430 sec)
37.765... logprob:  0.311285, 0.062500 (1.439 sec)
37.766... logprob:  0.482145, 0.132812 (1.456 sec)
37.767... logprob:  0.370986, 0.085938 (1.461 sec)
37.768... logprob:  0.432601, 0.117188 (1.474 sec)
37.769... logprob:  0.490727, 0.140625 (1.475 sec)
37.770... logprob:  0.403107, 0.101562 (1.483 sec)
37.771... logprob:  0.549181, 0.156250 (1.456 sec)
37.772... logprob:  0.414165, 0.109375 (1.450 sec)
37.773... logprob:  0.557293, 0.164062 (1.444 sec)
37.774... logprob:  0.362011, 0.085938 (1.463 sec)
37.775... logprob:  0.407472, 0.101562 (1.462 sec)
37.776... logprob:  0.433090, 0.117188 (1.485 sec)
37.777... logprob:  0.380046, 0.093750 (1.472 sec)
37.778... logprob:  0.433480, 0.117188 (1.473 sec)
37.779... logprob:  0.505192, 0.140625 (1.490 sec)
37.780... logprob:  0.385766, 0.101562 (1.458 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.48539733886719, 10.0]}, 128)
batch 872: ({'logprob': [66.8726806640625, 19.0]}, 128)
batch 873: ({'logprob': [40.25322341918945, 9.0]}, 128)
batch 874: ({'logprob': [45.02543640136719, 11.0]}, 128)
batch 875: ({'logprob': [50.69862365722656, 13.0]}, 128)
batch 876: ({'logprob': [64.293212890625, 18.0]}, 128)
batch 877: ({'logprob': [45.49006271362305, 11.0]}, 128)
batch 878: ({'logprob': [62.11272048950195, 17.0]}, 128)
batch 879: ({'logprob': [73.92695617675781, 21.0]}, 128)
batch 880: ({'logprob': [50.729705810546875, 13.0]}, 128)
batch 881: ({'logprob': [28.396709442138672, 5.0]}, 128)
batch 882: ({'logprob': [54.71012878417969, 14.0]}, 128)
batch 883: ({'logprob': [62.07951354980469, 17.0]}, 128)
batch 884: ({'logprob': [51.1694450378418, 13.0]}, 128)
batch 885: ({'logprob': [52.075653076171875, 13.0]}, 128)
batch 886: ({'logprob': [62.563350677490234, 17.0]}, 128)

======================Test output======================
logprob:  0.415958, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954655e-03 [3.268300e-09] 
Layer 'conv1' biases: 5.193789e-07 [6.309533e-11] 
Layer 'conv2' weights[0]: 7.941771e-03 [2.421634e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.971343e-10] 
Layer 'conv3' weights[0]: 7.939979e-03 [1.759091e-09] 
Layer 'conv3' biases: 4.378482e-06 [7.866831e-10] 
Layer 'conv4' weights[0]: 7.972639e-03 [1.660714e-09] 
Layer 'conv4' biases: 9.999990e-01 [4.114813e-09] 
Layer 'conv5' weights[0]: 7.971363e-03 [1.810350e-08] 
Layer 'conv5' biases: 9.999873e-01 [1.844321e-08] 
Layer 'fc6' weights[0]: 7.567834e-03 [1.608594e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.421429e-09] 
Layer 'fc7' weights[0]: 6.672216e-03 [6.071915e-08] 
Layer 'fc7' biases: 9.998502e-01 [4.412592e-08] 
Layer 'fc8' weights[0]: 1.273450e-03 [3.435285e-06] 
Layer 'fc8' biases: 9.394153e-02 [2.465993e-05] 
Train error last 870 batches: 0.435149
-------------------------------------------------------
Not saving because 0.415958 > 0.415628 (37.630: -0.00%)
======================================================= (12.096 sec)
37.781... logprob:  0.369587, 0.085938 (1.455 sec)
37.782... logprob:  0.351350, 0.085938 (1.457 sec)
37.783... logprob:  0.555564, 0.156250 (1.459 sec)
37.784... logprob:  0.440964, 0.117188 (1.457 sec)
37.785... logprob:  0.543874, 0.156250 (1.508 sec)
37.786... logprob:  0.477680, 0.132812 (1.469 sec)
37.787... logprob:  0.546769, 0.156250 (1.464 sec)
37.788... logprob:  0.563597, 0.164062 (1.497 sec)
37.789... logprob:  0.280027, 0.054688 (1.452 sec)
37.790... logprob:  0.407606, 0.101562 (1.447 sec)
37.791... logprob:  0.397607, 0.101562 (1.453 sec)
37.792... logprob:  0.360624, 0.085938 (1.461 sec)
37.793... logprob:  0.369871, 0.085938 (1.452 sec)
37.794... logprob:  0.387099, 0.093750 (1.493 sec)
37.795... logprob:  0.469649, 0.125000 (1.502 sec)
37.796... logprob:  0.423524, 0.109375 (1.458 sec)
37.797... logprob:  0.359035, 0.085938 (1.500 sec)
37.798... logprob:  0.393331, 0.101562 (1.448 sec)
37.799... logprob:  0.332715, 0.078125 (1.450 sec)
37.800... logprob:  0.371646, 0.093750 (1.451 sec)
37.801... logprob:  0.449661, 0.117188 (1.460 sec)
37.802... logprob:  0.422664, 0.109375 (1.453 sec)
37.803... logprob:  0.490997, 0.132812 (1.493 sec)
37.804... logprob:  0.349928, 0.085938 (1.466 sec)
37.805... logprob:  0.452230, 0.117188 (1.454 sec)
37.806... logprob:  0.424156, 0.109375 (1.506 sec)
37.807... logprob:  0.443477, 0.117188 (1.455 sec)
37.808... logprob:  0.462370, 0.125000 (1.449 sec)
37.809... logprob:  0.590015, 0.171875 (1.453 sec)
37.810... logprob:  0.442538, 0.117188 (1.461 sec)
37.811... logprob:  0.460435, 0.125000 (1.453 sec)
37.812... logprob:  0.462290, 0.125000 (1.515 sec)
37.813... logprob:  0.485949, 0.132812 (1.459 sec)
37.814... logprob:  0.477772, 0.132812 (1.457 sec)
37.815... logprob:  0.370843, 0.085938 (1.501 sec)
37.816... logprob:  0.408107, 0.101562 (1.459 sec)
37.817... logprob:  0.425582, 0.109375 (1.452 sec)
37.818... logprob:  0.560064, 0.164062 (1.454 sec)
37.819... logprob:  0.498159, 0.140625 (1.461 sec)
37.820... logprob:  0.421745, 0.109375 (1.455 sec)
37.821... logprob:  0.406851, 0.101562 (1.496 sec)
37.822... logprob:  0.441394, 0.117188 (1.461 sec)
37.823... logprob:  0.341551, 0.078125 (1.460 sec)
37.824... logprob:  0.489446, 0.132812 (1.501 sec)
37.825... logprob:  0.288994, 0.062500 (1.452 sec)
37.826... logprob:  0.375761, 0.093750 (1.458 sec)
37.827... logprob:  0.420331, 0.109375 (1.450 sec)
37.828... logprob:  0.442850, 0.117188 (1.456 sec)
37.829... logprob:  0.503198, 0.140625 (1.454 sec)
37.830... logprob:  0.441817, 0.117188 (1.502 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.264259338378906, 10.0]}, 128)
batch 872: ({'logprob': [68.23968505859375, 19.0]}, 128)
batch 873: ({'logprob': [39.43695831298828, 9.0]}, 128)
batch 874: ({'logprob': [44.79252624511719, 11.0]}, 128)
batch 875: ({'logprob': [50.80271530151367, 13.0]}, 128)
batch 876: ({'logprob': [65.43101501464844, 18.0]}, 128)
batch 877: ({'logprob': [45.1336555480957, 11.0]}, 128)
batch 878: ({'logprob': [62.89623260498047, 17.0]}, 128)
batch 879: ({'logprob': [75.26853942871094, 21.0]}, 128)
batch 880: ({'logprob': [50.83489227294922, 13.0]}, 128)
batch 881: ({'logprob': [27.021379470825195, 5.0]}, 128)
batch 882: ({'logprob': [54.68181610107422, 14.0]}, 128)
batch 883: ({'logprob': [62.86248779296875, 17.0]}, 128)
batch 884: ({'logprob': [51.15550994873047, 13.0]}, 128)
batch 885: ({'logprob': [51.81754684448242, 13.0]}, 128)
batch 886: ({'logprob': [63.226810455322266, 17.0]}, 128)

======================Test output======================
logprob:  0.417415, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954613e-03 [5.027579e-09] 
Layer 'conv1' biases: 5.206900e-07 [1.671805e-10] 
Layer 'conv2' weights[0]: 7.941740e-03 [4.415252e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.838167e-10] 
Layer 'conv3' weights[0]: 7.939944e-03 [4.071739e-09] 
Layer 'conv3' biases: 4.387239e-06 [2.607411e-09] 
Layer 'conv4' weights[0]: 7.972598e-03 [3.878591e-09] 
Layer 'conv4' biases: 9.999989e-01 [2.025014e-08] 
Layer 'conv5' weights[0]: 7.971325e-03 [1.211520e-07] 
Layer 'conv5' biases: 9.999871e-01 [1.298324e-07] 
Layer 'fc6' weights[0]: 7.567796e-03 [9.926069e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.007919e-08] 
Layer 'fc7' weights[0]: 6.670529e-03 [4.199248e-08] 
Layer 'fc7' biases: 9.998510e-01 [2.073430e-08] 
Layer 'fc8' weights[0]: 1.301167e-03 [4.808505e-06] 
Layer 'fc8' biases: 9.439601e-02 [2.882092e-05] 
Train error last 870 batches: 0.435149
-------------------------------------------------------
Not saving because 0.417415 > 0.415628 (37.630: -0.00%)
======================================================= (12.105 sec)
37.831... logprob:  0.513572, 0.140625 (1.463 sec)
37.832... logprob:  0.330851, 0.078125 (1.468 sec)
37.833... logprob:  0.489090, 0.132812 (1.497 sec)
37.834... logprob:  0.433494, 0.117188 (1.450 sec)
37.835... logprob:  0.543182, 0.148438 (1.457 sec)
37.836... logprob:  0.375928, 0.093750 (1.452 sec)
37.837... logprob:  0.313499, 0.070312 (1.456 sec)
37.838... logprob:  0.437069, 0.117188 (1.455 sec)
37.839... logprob:  0.471611, 0.125000 (1.499 sec)
37.840... logprob:  0.555819, 0.156250 (1.458 sec)
37.841... logprob:  0.395785, 0.101562 (1.464 sec)
37.842... logprob:  0.497978, 0.140625 (1.493 sec)
37.843... logprob:  0.465450, 0.125000 (1.454 sec)
37.844... logprob:  0.497723, 0.140625 (1.457 sec)
37.845... logprob:  0.486666, 0.132812 (1.454 sec)
37.846... logprob:  0.468314, 0.125000 (1.451 sec)
37.847... logprob:  0.363543, 0.085938 (1.456 sec)
37.848... logprob:  0.397383, 0.101562 (1.498 sec)
37.849... logprob:  0.360855, 0.085938 (1.458 sec)
37.850... logprob:  0.479333, 0.132812 (1.473 sec)
37.851... logprob:  0.440144, 0.117188 (1.491 sec)
37.852... logprob:  0.544935, 0.156250 (1.452 sec)
37.853... logprob:  0.372212, 0.093750 (1.462 sec)
37.854... logprob:  0.307761, 0.070312 (1.451 sec)
37.855... logprob:  0.484462, 0.132812 (1.448 sec)
37.856... logprob:  0.443570, 0.117188 (1.455 sec)
37.857... logprob:  0.372245, 0.093750 (1.495 sec)
37.858... logprob:  0.396245, 0.101562 (1.462 sec)
37.859... logprob:  0.308066, 0.070312 (1.472 sec)
37.860... logprob:  0.565918, 0.156250 (1.486 sec)
37.861... logprob:  0.417778, 0.109375 (1.460 sec)
37.862... logprob:  0.328769, 0.078125 (1.457 sec)
37.863... logprob:  0.399622, 0.101562 (1.453 sec)
37.864... logprob:  0.451577, 0.117188 (1.445 sec)
37.865... logprob:  0.484802, 0.132812 (1.458 sec)
37.866... logprob:  0.508051, 0.140625 (1.487 sec)
37.867... logprob:  0.503449, 0.140625 (1.469 sec)
37.868... logprob:  0.405075, 0.101562 (1.498 sec)
37.869... logprob:  0.382844, 0.093750 (1.481 sec)
37.870... logprob:  0.552520, 0.156250 (1.397 sec)
38.1... logprob:  0.379660, 0.093750 (1.410 sec)
38.2... logprob:  0.448207, 0.117188 (1.451 sec)
38.3... logprob:  0.398096, 0.101562 (1.421 sec)
38.4... logprob:  0.443236, 0.117188 (1.407 sec)
38.5... logprob:  0.443515, 0.117188 (1.437 sec)
38.6... logprob:  0.498957, 0.140625 (1.396 sec)
38.7... logprob:  0.363482, 0.085938 (1.419 sec)
38.8... logprob:  0.419220, 0.109375 (1.400 sec)
38.9... logprob:  0.359152, 0.085938 (1.402 sec)
38.10... logprob:  0.377801, 0.093750 (1.407 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.21324920654297, 10.0]}, 128)
batch 872: ({'logprob': [66.99111938476562, 19.0]}, 128)
batch 873: ({'logprob': [40.270809173583984, 9.0]}, 128)
batch 874: ({'logprob': [45.33428192138672, 11.0]}, 128)
batch 875: ({'logprob': [50.84670639038086, 13.0]}, 128)
batch 876: ({'logprob': [64.37898254394531, 18.0]}, 128)
batch 877: ({'logprob': [45.573570251464844, 11.0]}, 128)
batch 878: ({'logprob': [61.940467834472656, 17.0]}, 128)
batch 879: ({'logprob': [73.2101058959961, 21.0]}, 128)
batch 880: ({'logprob': [50.878292083740234, 13.0]}, 128)
batch 881: ({'logprob': [28.96084213256836, 5.0]}, 128)
batch 882: ({'logprob': [54.2142333984375, 14.0]}, 128)
batch 883: ({'logprob': [61.90708541870117, 17.0]}, 128)
batch 884: ({'logprob': [51.09142303466797, 13.0]}, 128)
batch 885: ({'logprob': [51.54668426513672, 13.0]}, 128)
batch 886: ({'logprob': [62.16521453857422, 17.0]}, 128)

======================Test output======================
logprob:  0.415783, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954567e-03 [3.722749e-09] 
Layer 'conv1' biases: 5.219593e-07 [1.493123e-10] 
Layer 'conv2' weights[0]: 7.941695e-03 [3.433999e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.274287e-10] 
Layer 'conv3' weights[0]: 7.939903e-03 [3.403729e-09] 
Layer 'conv3' biases: 4.396974e-06 [2.165610e-09] 
Layer 'conv4' weights[0]: 7.972561e-03 [3.435548e-09] 
Layer 'conv4' biases: 9.999989e-01 [1.886955e-08] 
Layer 'conv5' weights[0]: 7.971293e-03 [1.183787e-07] 
Layer 'conv5' biases: 9.999872e-01 [1.267788e-07] 
Layer 'fc6' weights[0]: 7.567758e-03 [9.632469e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.749987e-09] 
Layer 'fc7' weights[0]: 6.668876e-03 [2.765164e-07] 
Layer 'fc7' biases: 9.998497e-01 [2.681331e-07] 
Layer 'fc8' weights[0]: 1.256494e-03 [9.946820e-06] 
Layer 'fc8' biases: 9.426418e-02 [7.339640e-05] 
Train error last 870 batches: 0.435149
-------------------------------------------------------
Not saving because 0.415783 > 0.415628 (37.630: -0.00%)
======================================================= (12.033 sec)
38.11... logprob:  0.335253, 0.078125 (1.448 sec)
38.12... logprob:  0.466055, 0.125000 (1.404 sec)
38.13... logprob:  0.441963, 0.117188 (1.417 sec)
38.14... logprob:  0.444302, 0.117188 (1.401 sec)
38.15... logprob:  0.395379, 0.101562 (1.412 sec)
38.16... logprob:  0.421249, 0.109375 (1.410 sec)
38.17... logprob:  0.515749, 0.140625 (1.398 sec)
38.18... logprob:  0.262173, 0.054688 (1.401 sec)
38.19... logprob:  0.279387, 0.062500 (1.405 sec)
38.20... logprob:  0.421342, 0.109375 (1.404 sec)
38.21... logprob:  0.444015, 0.117188 (1.401 sec)
38.22... logprob:  0.536957, 0.148438 (1.416 sec)
38.23... logprob:  0.533459, 0.148438 (1.490 sec)
38.24... logprob:  0.310225, 0.070312 (1.421 sec)
38.25... logprob:  0.355948, 0.085938 (1.408 sec)
38.26... logprob:  0.463949, 0.125000 (1.449 sec)
38.27... logprob:  0.404422, 0.101562 (1.404 sec)
38.28... logprob:  0.421827, 0.109375 (1.418 sec)
38.29... logprob:  0.395789, 0.101562 (1.429 sec)
38.30... logprob:  0.373915, 0.093750 (1.418 sec)
38.31... logprob:  0.480045, 0.132812 (1.407 sec)
38.32... logprob:  0.457219, 0.125000 (1.402 sec)
38.33... logprob:  0.460686, 0.125000 (1.456 sec)
38.34... logprob:  0.464455, 0.125000 (1.397 sec)
38.35... logprob:  0.316403, 0.070312 (1.409 sec)
38.36... logprob:  0.475792, 0.132812 (1.404 sec)
38.37... logprob:  0.417595, 0.109375 (1.415 sec)
38.38... logprob:  0.392825, 0.101562 (1.403 sec)
38.39... logprob:  0.631057, 0.187500 (1.438 sec)
38.40... logprob:  0.445560, 0.117188 (1.420 sec)
38.41... logprob:  0.353168, 0.085938 (1.427 sec)
38.42... logprob:  0.392152, 0.101562 (1.417 sec)
38.43... logprob:  0.440054, 0.117188 (1.410 sec)
38.44... logprob:  0.518582, 0.148438 (1.436 sec)
38.45... logprob:  0.381695, 0.093750 (1.403 sec)
38.46... logprob:  0.486039, 0.132812 (1.403 sec)
38.47... logprob:  0.331717, 0.078125 (1.397 sec)
38.48... logprob:  0.498978, 0.140625 (1.429 sec)
38.49... logprob:  0.511061, 0.148438 (1.420 sec)
38.50... logprob:  0.393152, 0.101562 (1.428 sec)
38.51... logprob:  0.490460, 0.140625 (1.412 sec)
38.52... logprob:  0.525802, 0.148438 (1.406 sec)
38.53... logprob:  0.294600, 0.062500 (1.443 sec)
38.54... logprob:  0.403523, 0.109375 (1.393 sec)
38.55... logprob:  0.331607, 0.078125 (1.400 sec)
38.56... logprob:  0.421536, 0.109375 (1.404 sec)
38.57... logprob:  0.572234, 0.164062 (1.432 sec)
38.58... logprob:  0.407373, 0.101562 (1.409 sec)
38.59... logprob:  0.333861, 0.078125 (1.465 sec)
38.60... logprob:  0.618529, 0.179688 (1.428 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.37742233276367, 10.0]}, 128)
batch 872: ({'logprob': [66.4207534790039, 19.0]}, 128)
batch 873: ({'logprob': [40.85610580444336, 9.0]}, 128)
batch 874: ({'logprob': [45.18251037597656, 11.0]}, 128)
batch 875: ({'logprob': [50.80239486694336, 13.0]}, 128)
batch 876: ({'logprob': [63.96542739868164, 18.0]}, 128)
batch 877: ({'logprob': [45.84300231933594, 11.0]}, 128)
batch 878: ({'logprob': [62.10594177246094, 17.0]}, 128)
batch 879: ({'logprob': [74.00432586669922, 21.0]}, 128)
batch 880: ({'logprob': [50.832454681396484, 13.0]}, 128)
batch 881: ({'logprob': [28.914827346801758, 5.0]}, 128)
batch 882: ({'logprob': [55.272987365722656, 14.0]}, 128)
batch 883: ({'logprob': [62.073585510253906, 17.0]}, 128)
batch 884: ({'logprob': [51.466468811035156, 13.0]}, 128)
batch 885: ({'logprob': [52.76333236694336, 13.0]}, 128)
batch 886: ({'logprob': [62.75135040283203, 17.0]}, 128)

======================Test output======================
logprob:  0.417301, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954528e-03 [4.559638e-09] 
Layer 'conv1' biases: 5.230647e-07 [1.623896e-10] 
Layer 'conv2' weights[0]: 7.941663e-03 [3.695739e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.176003e-10] 
Layer 'conv3' weights[0]: 7.939867e-03 [3.787215e-09] 
Layer 'conv3' biases: 4.407265e-06 [2.499279e-09] 
Layer 'conv4' weights[0]: 7.972522e-03 [3.674058e-09] 
Layer 'conv4' biases: 9.999990e-01 [2.084582e-08] 
Layer 'conv5' weights[0]: 7.971266e-03 [1.316782e-07] 
Layer 'conv5' biases: 9.999874e-01 [1.408425e-07] 
Layer 'fc6' weights[0]: 7.567720e-03 [1.063420e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.088660e-08] 
Layer 'fc7' weights[0]: 6.667215e-03 [9.650436e-08] 
Layer 'fc7' biases: 9.998503e-01 [8.388008e-08] 
Layer 'fc8' weights[0]: 1.260539e-03 [2.752792e-06] 
Layer 'fc8' biases: 9.433224e-02 [1.783541e-05] 
Train error last 870 batches: 0.435148
-------------------------------------------------------
Not saving because 0.417301 > 0.415628 (37.630: -0.00%)
======================================================= (12.030 sec)
38.61... logprob:  0.382740, 0.093750 (1.436 sec)
38.62... logprob:  0.474809, 0.132812 (1.466 sec)
38.63... logprob:  0.397275, 0.101562 (1.442 sec)
38.64... logprob:  0.450376, 0.125000 (1.413 sec)
38.65... logprob:  0.373422, 0.093750 (1.427 sec)
38.66... logprob:  0.354064, 0.085938 (1.453 sec)
38.67... logprob:  0.295448, 0.062500 (1.399 sec)
38.68... logprob:  0.396792, 0.101562 (1.408 sec)
38.69... logprob:  0.496548, 0.140625 (1.428 sec)
38.70... logprob:  0.325939, 0.078125 (1.441 sec)
38.71... logprob:  0.381784, 0.101562 (1.465 sec)
38.72... logprob:  0.493575, 0.132812 (1.409 sec)
38.73... logprob:  0.447613, 0.117188 (1.432 sec)
38.74... logprob:  0.442454, 0.117188 (1.419 sec)
38.75... logprob:  0.380667, 0.093750 (1.416 sec)
38.76... logprob:  0.412022, 0.109375 (1.438 sec)
38.77... logprob:  0.396347, 0.101562 (1.443 sec)
38.78... logprob:  0.493043, 0.140625 (1.461 sec)
38.79... logprob:  0.456501, 0.125000 (1.409 sec)
38.80... logprob:  0.508163, 0.132812 (1.432 sec)
38.81... logprob:  0.416724, 0.109375 (1.422 sec)
38.82... logprob:  0.230820, 0.039062 (1.426 sec)
38.83... logprob:  0.493904, 0.140625 (1.413 sec)
38.84... logprob:  0.468209, 0.125000 (1.474 sec)
38.85... logprob:  0.431853, 0.117188 (1.424 sec)
38.86... logprob:  0.416880, 0.109375 (1.424 sec)
38.87... logprob:  0.633418, 0.187500 (1.427 sec)
38.88... logprob:  0.534978, 0.156250 (1.549 sec)
38.89... logprob:  0.410478, 0.109375 (1.438 sec)
38.90... logprob:  0.577482, 0.171875 (1.391 sec)
38.91... logprob:  0.348319, 0.078125 (1.403 sec)
38.92... logprob:  0.464456, 0.125000 (1.402 sec)
38.93... logprob:  0.492160, 0.140625 (1.400 sec)
38.94... logprob:  0.428791, 0.109375 (1.399 sec)
38.95... logprob:  0.471825, 0.125000 (1.404 sec)
38.96... logprob:  0.576057, 0.171875 (1.423 sec)
38.97... logprob:  0.430818, 0.117188 (1.398 sec)
38.98... logprob:  0.391356, 0.093750 (1.439 sec)
38.99... logprob:  0.474156, 0.132812 (1.410 sec)
38.100... logprob:  0.310842, 0.070312 (1.410 sec)
38.101... logprob:  0.311250, 0.062500 (1.449 sec)
38.102... logprob:  0.545567, 0.156250 (1.394 sec)
38.103... logprob:  0.540572, 0.156250 (1.413 sec)
38.104... logprob:  0.388776, 0.101562 (1.406 sec)
38.105... logprob:  0.618846, 0.179688 (1.407 sec)
38.106... logprob:  0.344501, 0.085938 (1.401 sec)
38.107... logprob:  0.335878, 0.078125 (1.466 sec)
38.108... logprob:  0.586858, 0.171875 (1.398 sec)
38.109... logprob:  0.336080, 0.078125 (1.410 sec)
38.110... logprob:  0.564826, 0.164062 (1.402 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.678489685058594, 10.0]}, 128)
batch 872: ({'logprob': [66.49514770507812, 19.0]}, 128)
batch 873: ({'logprob': [40.6463508605957, 9.0]}, 128)
batch 874: ({'logprob': [45.216529846191406, 11.0]}, 128)
batch 875: ({'logprob': [50.76818084716797, 13.0]}, 128)
batch 876: ({'logprob': [63.996337890625, 18.0]}, 128)
batch 877: ({'logprob': [45.72157287597656, 11.0]}, 128)
batch 878: ({'logprob': [61.93720626831055, 17.0]}, 128)
batch 879: ({'logprob': [73.54619598388672, 21.0]}, 128)
batch 880: ({'logprob': [50.798858642578125, 13.0]}, 128)
batch 881: ({'logprob': [28.99558448791504, 5.0]}, 128)
batch 882: ({'logprob': [54.81690216064453, 14.0]}, 128)
batch 883: ({'logprob': [61.904396057128906, 17.0]}, 128)
batch 884: ({'logprob': [51.277244567871094, 13.0]}, 128)
batch 885: ({'logprob': [52.26310729980469, 13.0]}, 128)
batch 886: ({'logprob': [62.427024841308594, 17.0]}, 128)

======================Test output======================
logprob:  0.416254, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954490e-03 [4.135295e-09] 
Layer 'conv1' biases: 5.240745e-07 [1.334376e-10] 
Layer 'conv2' weights[0]: 7.941627e-03 [4.175990e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.606960e-10] 
Layer 'conv3' weights[0]: 7.939822e-03 [3.769974e-09] 
Layer 'conv3' biases: 4.416919e-06 [2.250913e-09] 
Layer 'conv4' weights[0]: 7.972477e-03 [3.727201e-09] 
Layer 'conv4' biases: 9.999989e-01 [1.843602e-08] 
Layer 'conv5' weights[0]: 7.971221e-03 [1.137146e-07] 
Layer 'conv5' biases: 9.999877e-01 [1.214431e-07] 
Layer 'fc6' weights[0]: 7.567687e-03 [9.307194e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.416644e-09] 
Layer 'fc7' weights[0]: 6.665517e-03 [1.595423e-07] 
Layer 'fc7' biases: 9.998498e-01 [1.502842e-07] 
Layer 'fc8' weights[0]: 1.257792e-03 [5.982243e-06] 
Layer 'fc8' biases: 9.442068e-02 [3.894526e-05] 
Train error last 870 batches: 0.435148
-------------------------------------------------------
Not saving because 0.416254 > 0.415628 (37.630: -0.00%)
======================================================= (12.050 sec)
38.111... logprob:  0.404623, 0.101562 (1.406 sec)
38.112... logprob:  0.365839, 0.093750 (1.406 sec)
38.113... logprob:  0.354227, 0.085938 (1.403 sec)
38.114... logprob:  0.440202, 0.117188 (1.433 sec)
38.115... logprob:  0.506857, 0.140625 (1.414 sec)
38.116... logprob:  0.393289, 0.101562 (1.406 sec)
38.117... logprob:  0.440395, 0.117188 (1.450 sec)
38.118... logprob:  0.409030, 0.101562 (1.394 sec)
38.119... logprob:  0.346018, 0.085938 (1.400 sec)
38.120... logprob:  0.547136, 0.156250 (1.405 sec)
38.121... logprob:  0.412546, 0.109375 (1.398 sec)
38.122... logprob:  0.519196, 0.148438 (1.445 sec)
38.123... logprob:  0.463623, 0.125000 (1.391 sec)
38.124... logprob:  0.447677, 0.125000 (1.405 sec)
38.125... logprob:  0.501851, 0.140625 (1.404 sec)
38.126... logprob:  0.475680, 0.125000 (1.397 sec)
38.127... logprob:  0.479408, 0.125000 (1.403 sec)
38.128... logprob:  0.422304, 0.109375 (1.424 sec)
38.129... logprob:  0.574872, 0.164062 (1.420 sec)
38.130... logprob:  0.382671, 0.093750 (1.417 sec)
38.131... logprob:  0.495496, 0.132812 (1.410 sec)
38.132... logprob:  0.506348, 0.140625 (1.434 sec)
38.133... logprob:  0.444706, 0.117188 (1.395 sec)
38.134... logprob:  0.401849, 0.101562 (1.405 sec)
38.135... logprob:  0.460153, 0.125000 (1.398 sec)
38.136... logprob:  0.562238, 0.164062 (1.405 sec)
38.137... logprob:  0.462606, 0.125000 (1.390 sec)
38.138... logprob:  0.319466, 0.070312 (1.446 sec)
38.139... logprob:  0.395709, 0.101562 (1.402 sec)
38.140... logprob:  0.559751, 0.164062 (1.419 sec)
38.141... logprob:  0.464614, 0.125000 (1.455 sec)
38.142... logprob:  0.464663, 0.125000 (1.403 sec)
38.143... logprob:  0.294553, 0.062500 (1.427 sec)
38.144... logprob:  0.456861, 0.125000 (1.422 sec)
38.145... logprob:  0.324619, 0.078125 (1.421 sec)
38.146... logprob:  0.482966, 0.132812 (1.415 sec)
38.147... logprob:  0.262508, 0.054688 (1.432 sec)
38.148... logprob:  0.458458, 0.125000 (1.390 sec)
38.149... logprob:  0.442454, 0.117188 (1.399 sec)
38.150... logprob:  0.347540, 0.085938 (1.402 sec)
38.151... logprob:  0.347125, 0.085938 (1.400 sec)
38.152... logprob:  0.785195, 0.234375 (1.393 sec)
38.153... logprob:  0.381626, 0.093750 (1.444 sec)
38.154... logprob:  0.524905, 0.148438 (1.397 sec)
38.155... logprob:  0.426204, 0.117188 (1.416 sec)
38.156... logprob:  0.294764, 0.062500 (1.443 sec)
38.157... logprob:  0.269644, 0.054688 (1.394 sec)
38.158... logprob:  0.455497, 0.125000 (1.407 sec)
38.159... logprob:  0.483148, 0.132812 (1.405 sec)
38.160... logprob:  0.444601, 0.117188 (1.395 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.89463424682617, 10.0]}, 128)
batch 872: ({'logprob': [66.1467056274414, 19.0]}, 128)
batch 873: ({'logprob': [41.158782958984375, 9.0]}, 128)
batch 874: ({'logprob': [45.474979400634766, 11.0]}, 128)
batch 875: ({'logprob': [50.9098014831543, 13.0]}, 128)
batch 876: ({'logprob': [63.740234375, 18.0]}, 128)
batch 877: ({'logprob': [46.048728942871094, 11.0]}, 128)
batch 878: ({'logprob': [61.8426628112793, 17.0]}, 128)
batch 879: ({'logprob': [73.28286743164062, 21.0]}, 128)
batch 880: ({'logprob': [50.940032958984375, 13.0]}, 128)
batch 881: ({'logprob': [29.67688751220703, 5.0]}, 128)
batch 882: ({'logprob': [55.068153381347656, 14.0]}, 128)
batch 883: ({'logprob': [61.810062408447266, 17.0]}, 128)
batch 884: ({'logprob': [51.485023498535156, 13.0]}, 128)
batch 885: ({'logprob': [52.6068229675293, 13.0]}, 128)
batch 886: ({'logprob': [62.399620056152344, 17.0]}, 128)

======================Test output======================
logprob:  0.417229, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954449e-03 [2.587419e-09] 
Layer 'conv1' biases: 5.251267e-07 [4.971995e-11] 
Layer 'conv2' weights[0]: 7.941590e-03 [1.741464e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.441657e-10] 
Layer 'conv3' weights[0]: 7.939779e-03 [1.258749e-09] 
Layer 'conv3' biases: 4.426643e-06 [3.990062e-10] 
Layer 'conv4' weights[0]: 7.972439e-03 [1.180585e-09] 
Layer 'conv4' biases: 9.999989e-01 [1.318134e-09] 
Layer 'conv5' weights[0]: 7.971181e-03 [6.081554e-09] 
Layer 'conv5' biases: 9.999875e-01 [6.023637e-09] 
Layer 'fc6' weights[0]: 7.567645e-03 [8.708200e-10] 
Layer 'fc6' biases: 1.000000e+00 [4.131614e-10] 
Layer 'fc7' weights[0]: 6.663803e-03 [4.734492e-08] 
Layer 'fc7' biases: 9.998496e-01 [2.835434e-08] 
Layer 'fc8' weights[0]: 1.249325e-03 [4.541917e-06] 
Layer 'fc8' biases: 9.444733e-02 [2.929423e-05] 
Train error last 870 batches: 0.435148
-------------------------------------------------------
Not saving because 0.417229 > 0.415628 (37.630: -0.00%)
======================================================= (12.167 sec)
38.161... logprob:  0.349384, 0.078125 (1.422 sec)
38.162... logprob:  0.611811, 0.179688 (1.414 sec)
38.163... logprob:  0.450537, 0.125000 (1.435 sec)
38.164... logprob:  0.468417, 0.125000 (1.425 sec)
38.165... logprob:  0.547650, 0.156250 (1.417 sec)
38.166... logprob:  0.446227, 0.125000 (1.454 sec)
38.167... logprob:  0.350740, 0.085938 (1.431 sec)
38.168... logprob:  0.363795, 0.085938 (1.427 sec)
38.169... logprob:  0.408591, 0.101562 (1.461 sec)
38.170... logprob:  0.459444, 0.125000 (1.403 sec)
38.171... logprob:  0.535075, 0.156250 (1.426 sec)
38.172... logprob:  0.434751, 0.109375 (1.423 sec)
38.173... logprob:  0.440450, 0.117188 (1.422 sec)
38.174... logprob:  0.600362, 0.171875 (1.430 sec)
38.175... logprob:  0.505818, 0.140625 (1.472 sec)
38.176... logprob:  0.478345, 0.132812 (1.423 sec)
38.177... logprob:  0.289723, 0.054688 (1.429 sec)
38.178... logprob:  0.383477, 0.093750 (1.465 sec)
38.179... logprob:  0.394634, 0.101562 (1.409 sec)
38.180... logprob:  0.466398, 0.125000 (1.425 sec)
38.181... logprob:  0.539192, 0.156250 (1.426 sec)
38.182... logprob:  0.371204, 0.093750 (1.416 sec)
38.183... logprob:  0.419917, 0.109375 (1.418 sec)
38.184... logprob:  0.483417, 0.132812 (1.421 sec)
38.185... logprob:  0.289667, 0.062500 (1.401 sec)
38.186... logprob:  0.370255, 0.093750 (1.408 sec)
38.187... logprob:  0.529615, 0.148438 (1.408 sec)
38.188... logprob:  0.458792, 0.125000 (1.407 sec)
38.189... logprob:  0.440932, 0.117188 (1.392 sec)
38.190... logprob:  0.375813, 0.093750 (1.434 sec)
38.191... logprob:  0.485101, 0.132812 (1.415 sec)
38.192... logprob:  0.519956, 0.148438 (1.421 sec)
38.193... logprob:  0.312399, 0.070312 (1.425 sec)
38.194... logprob:  0.414007, 0.109375 (1.424 sec)
38.195... logprob:  0.286880, 0.062500 (1.404 sec)
38.196... logprob:  0.410397, 0.109375 (1.398 sec)
38.197... logprob:  0.477960, 0.132812 (1.408 sec)
38.198... logprob:  0.355799, 0.085938 (1.412 sec)
38.199... logprob:  0.437195, 0.117188 (1.389 sec)
38.200... logprob:  0.440705, 0.117188 (1.442 sec)
38.201... logprob:  0.437082, 0.117188 (1.405 sec)
38.202... logprob:  0.537756, 0.148438 (1.408 sec)
38.203... logprob:  0.420377, 0.109375 (1.449 sec)
38.204... logprob:  0.504123, 0.140625 (1.402 sec)
38.205... logprob:  0.334214, 0.078125 (1.411 sec)
38.206... logprob:  0.361642, 0.093750 (1.407 sec)
38.207... logprob:  0.381682, 0.093750 (1.393 sec)
38.208... logprob:  0.490631, 0.140625 (1.400 sec)
38.209... logprob:  0.334501, 0.078125 (1.423 sec)
38.210... logprob:  0.586216, 0.171875 (1.423 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.69914245605469, 10.0]}, 128)
batch 872: ({'logprob': [66.3224868774414, 19.0]}, 128)
batch 873: ({'logprob': [40.884769439697266, 9.0]}, 128)
batch 874: ({'logprob': [45.3040885925293, 11.0]}, 128)
batch 875: ({'logprob': [50.819610595703125, 13.0]}, 128)
batch 876: ({'logprob': [63.87043380737305, 18.0]}, 128)
batch 877: ({'logprob': [45.8665885925293, 11.0]}, 128)
batch 878: ({'logprob': [61.91542434692383, 17.0]}, 128)
batch 879: ({'logprob': [73.50726318359375, 21.0]}, 128)
batch 880: ({'logprob': [50.85031509399414, 13.0]}, 128)
batch 881: ({'logprob': [29.2506160736084, 5.0]}, 128)
batch 882: ({'logprob': [54.99211120605469, 14.0]}, 128)
batch 883: ({'logprob': [61.88241195678711, 17.0]}, 128)
batch 884: ({'logprob': [51.38504409790039, 13.0]}, 128)
batch 885: ({'logprob': [52.48476791381836, 13.0]}, 128)
batch 886: ({'logprob': [62.461875915527344, 17.0]}, 128)

======================Test output======================
logprob:  0.416747, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954405e-03 [3.467945e-09] 
Layer 'conv1' biases: 5.262812e-07 [1.525145e-10] 
Layer 'conv2' weights[0]: 7.941542e-03 [2.514150e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.486269e-10] 
Layer 'conv3' weights[0]: 7.939738e-03 [2.708378e-09] 
Layer 'conv3' biases: 4.436500e-06 [1.833323e-09] 
Layer 'conv4' weights[0]: 7.972405e-03 [2.538653e-09] 
Layer 'conv4' biases: 9.999989e-01 [1.432052e-08] 
Layer 'conv5' weights[0]: 7.971146e-03 [8.759373e-08] 
Layer 'conv5' biases: 9.999875e-01 [9.363875e-08] 
Layer 'fc6' weights[0]: 7.567611e-03 [7.125895e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.251044e-09] 
Layer 'fc7' weights[0]: 6.662071e-03 [7.794414e-08] 
Layer 'fc7' biases: 9.998497e-01 [6.425480e-08] 
Layer 'fc8' weights[0]: 1.260391e-03 [4.459119e-06] 
Layer 'fc8' biases: 9.460283e-02 [3.078736e-05] 
Train error last 870 batches: 0.435148
-------------------------------------------------------
Not saving because 0.416747 > 0.415628 (37.630: -0.00%)
======================================================= (12.047 sec)
38.211... logprob:  0.488079, 0.132812 (1.423 sec)
38.212... logprob:  0.526095, 0.148438 (1.421 sec)
38.213... logprob:  0.514502, 0.140625 (1.464 sec)
38.214... logprob:  0.459366, 0.125000 (1.425 sec)
38.215... logprob:  0.396049, 0.101562 (1.423 sec)
38.216... logprob:  0.516797, 0.140625 (1.477 sec)
38.217... logprob:  0.324692, 0.070312 (1.412 sec)
38.218... logprob:  0.463518, 0.125000 (1.427 sec)
38.219... logprob:  0.500185, 0.140625 (1.423 sec)
38.220... logprob:  0.415047, 0.109375 (1.428 sec)
38.221... logprob:  0.399593, 0.101562 (1.413 sec)
38.222... logprob:  0.554295, 0.164062 (1.459 sec)
38.223... logprob:  0.568749, 0.164062 (1.434 sec)
38.224... logprob:  0.406049, 0.101562 (1.433 sec)
38.225... logprob:  0.392040, 0.101562 (1.449 sec)
38.226... logprob:  0.424820, 0.109375 (1.428 sec)
38.227... logprob:  0.452560, 0.125000 (1.420 sec)
38.228... logprob:  0.417160, 0.109375 (1.421 sec)
38.229... logprob:  0.489369, 0.132812 (1.426 sec)
38.230... logprob:  0.459820, 0.125000 (1.430 sec)
38.231... logprob:  0.453447, 0.125000 (1.410 sec)
38.232... logprob:  0.496107, 0.140625 (1.465 sec)
38.233... logprob:  0.465987, 0.132812 (1.515 sec)
38.234... logprob:  0.563908, 0.164062 (1.426 sec)
38.235... logprob:  0.482005, 0.132812 (1.468 sec)
38.236... logprob:  0.425553, 0.109375 (1.406 sec)
38.237... logprob:  0.340666, 0.078125 (1.422 sec)
38.238... logprob:  0.388930, 0.093750 (1.416 sec)
38.239... logprob:  0.478058, 0.132812 (1.422 sec)
38.240... logprob:  0.485793, 0.132812 (1.403 sec)
38.241... logprob:  0.493607, 0.132812 (1.461 sec)
38.242... logprob:  0.341602, 0.078125 (1.429 sec)
38.243... logprob:  0.385977, 0.093750 (1.436 sec)
38.244... logprob:  0.315530, 0.070312 (1.451 sec)
38.245... logprob:  0.494130, 0.132812 (1.425 sec)
38.246... logprob:  0.416813, 0.109375 (1.416 sec)
38.247... logprob:  0.357724, 0.085938 (1.418 sec)
38.248... logprob:  0.308267, 0.070312 (1.417 sec)
38.249... logprob:  0.553995, 0.156250 (1.424 sec)
38.250... logprob:  0.590800, 0.164062 (1.407 sec)
38.251... logprob:  0.353055, 0.085938 (1.461 sec)
38.252... logprob:  0.348403, 0.085938 (1.430 sec)
38.253... logprob:  0.379267, 0.093750 (1.424 sec)
38.254... logprob:  0.444141, 0.117188 (1.469 sec)
38.255... logprob:  0.351229, 0.085938 (1.405 sec)
38.256... logprob:  0.378945, 0.093750 (1.430 sec)
38.257... logprob:  0.331931, 0.078125 (1.417 sec)
38.258... logprob:  0.415360, 0.109375 (1.420 sec)
38.259... logprob:  0.442322, 0.117188 (1.402 sec)
38.260... logprob:  0.308061, 0.070312 (1.461 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.79759979248047, 10.0]}, 128)
batch 872: ({'logprob': [67.85895538330078, 19.0]}, 128)
batch 873: ({'logprob': [39.59447479248047, 9.0]}, 128)
batch 874: ({'logprob': [45.00860595703125, 11.0]}, 128)
batch 875: ({'logprob': [50.8004150390625, 13.0]}, 128)
batch 876: ({'logprob': [65.09088134765625, 18.0]}, 128)
batch 877: ({'logprob': [45.21233367919922, 11.0]}, 128)
batch 878: ({'logprob': [62.45811080932617, 17.0]}, 128)
batch 879: ({'logprob': [74.25597381591797, 21.0]}, 128)
batch 880: ({'logprob': [50.83340072631836, 13.0]}, 128)
batch 881: ({'logprob': [27.75450325012207, 5.0]}, 128)
batch 882: ({'logprob': [54.22462463378906, 14.0]}, 128)
batch 883: ({'logprob': [62.42348861694336, 17.0]}, 128)
batch 884: ({'logprob': [51.01420593261719, 13.0]}, 128)
batch 885: ({'logprob': [51.399478912353516, 13.0]}, 128)
batch 886: ({'logprob': [62.649681091308594, 17.0]}, 128)

======================Test output======================
logprob:  0.416200, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954358e-03 [2.390355e-09] 
Layer 'conv1' biases: 5.274867e-07 [8.797116e-11] 
Layer 'conv2' weights[0]: 7.941504e-03 [2.027866e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.351897e-10] 
Layer 'conv3' weights[0]: 7.939694e-03 [1.876083e-09] 
Layer 'conv3' biases: 4.443781e-06 [9.702824e-10] 
Layer 'conv4' weights[0]: 7.972356e-03 [1.940703e-09] 
Layer 'conv4' biases: 9.999990e-01 [8.450977e-09] 
Layer 'conv5' weights[0]: 7.971114e-03 [5.343017e-08] 
Layer 'conv5' biases: 9.999874e-01 [5.709789e-08] 
Layer 'fc6' weights[0]: 7.567572e-03 [4.413299e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.408617e-09] 
Layer 'fc7' weights[0]: 6.660339e-03 [7.112567e-08] 
Layer 'fc7' biases: 9.998501e-01 [5.571596e-08] 
Layer 'fc8' weights[0]: 1.293118e-03 [2.354686e-06] 
Layer 'fc8' biases: 9.494864e-02 [1.707398e-05] 
Train error last 870 batches: 0.435147
-------------------------------------------------------
Not saving because 0.416200 > 0.415628 (37.630: -0.00%)
======================================================= (12.079 sec)
38.261... logprob:  0.392393, 0.101562 (1.444 sec)
38.262... logprob:  0.524400, 0.148438 (1.450 sec)
38.263... logprob:  0.425688, 0.109375 (1.452 sec)
38.264... logprob:  0.374941, 0.093750 (1.422 sec)
38.265... logprob:  0.439608, 0.117188 (1.417 sec)
38.266... logprob:  0.438996, 0.117188 (1.416 sec)
38.267... logprob:  0.422062, 0.109375 (1.422 sec)
38.268... logprob:  0.458946, 0.125000 (1.429 sec)
38.269... logprob:  0.567670, 0.164062 (1.412 sec)
38.270... logprob:  0.542434, 0.156250 (1.464 sec)
38.271... logprob:  0.445507, 0.117188 (1.432 sec)
38.272... logprob:  0.384416, 0.093750 (1.425 sec)
38.273... logprob:  0.500249, 0.140625 (1.470 sec)
38.274... logprob:  0.542495, 0.156250 (1.400 sec)
38.275... logprob:  0.487472, 0.132812 (1.425 sec)
38.276... logprob:  0.389890, 0.093750 (1.418 sec)
38.277... logprob:  0.428523, 0.109375 (1.433 sec)
38.278... logprob:  0.323765, 0.070312 (1.426 sec)
38.279... logprob:  0.325501, 0.070312 (1.470 sec)
38.280... logprob:  0.216601, 0.031250 (1.416 sec)
38.281... logprob:  0.417295, 0.109375 (1.424 sec)
38.282... logprob:  0.411243, 0.109375 (1.418 sec)
38.283... logprob:  0.393658, 0.101562 (1.427 sec)
38.284... logprob:  0.394175, 0.101562 (1.415 sec)
38.285... logprob:  0.450886, 0.117188 (1.446 sec)
38.286... logprob:  0.535435, 0.140625 (1.440 sec)
38.287... logprob:  0.346436, 0.085938 (1.431 sec)
38.288... logprob:  0.329924, 0.078125 (1.441 sec)
38.289... logprob:  0.445624, 0.117188 (1.442 sec)
38.290... logprob:  0.490614, 0.132812 (1.407 sec)
38.291... logprob:  0.439423, 0.117188 (1.420 sec)
38.292... logprob:  0.568130, 0.156250 (1.423 sec)
38.293... logprob:  0.427953, 0.117188 (1.430 sec)
38.294... logprob:  0.355445, 0.085938 (1.402 sec)
38.295... logprob:  0.333820, 0.078125 (1.464 sec)
38.296... logprob:  0.354987, 0.085938 (1.425 sec)
38.297... logprob:  0.394054, 0.101562 (1.420 sec)
38.298... logprob:  0.448359, 0.125000 (1.468 sec)
38.299... logprob:  0.341447, 0.078125 (1.410 sec)
38.300... logprob:  0.406131, 0.101562 (1.428 sec)
38.301... logprob:  0.397808, 0.101562 (1.415 sec)
38.302... logprob:  0.591696, 0.179688 (1.421 sec)
38.303... logprob:  0.459410, 0.125000 (1.408 sec)
38.304... logprob:  0.459565, 0.125000 (1.444 sec)
38.305... logprob:  0.455178, 0.125000 (1.437 sec)
38.306... logprob:  0.440555, 0.117188 (1.437 sec)
38.307... logprob:  0.421642, 0.109375 (1.443 sec)
38.308... logprob:  0.375023, 0.093750 (1.453 sec)
38.309... logprob:  0.450489, 0.125000 (1.421 sec)
38.310... logprob:  0.473455, 0.125000 (1.416 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.842098236083984, 10.0]}, 128)
batch 872: ({'logprob': [66.1356201171875, 19.0]}, 128)
batch 873: ({'logprob': [41.186519622802734, 9.0]}, 128)
batch 874: ({'logprob': [45.46525573730469, 11.0]}, 128)
batch 875: ({'logprob': [50.912200927734375, 13.0]}, 128)
batch 876: ({'logprob': [63.73530578613281, 18.0]}, 128)
batch 877: ({'logprob': [46.06362533569336, 11.0]}, 128)
batch 878: ({'logprob': [61.86875534057617, 17.0]}, 128)
batch 879: ({'logprob': [73.35725402832031, 21.0]}, 128)
batch 880: ({'logprob': [50.942359924316406, 13.0]}, 128)
batch 881: ({'logprob': [29.656232833862305, 5.0]}, 128)
batch 882: ({'logprob': [55.138023376464844, 14.0]}, 128)
batch 883: ({'logprob': [61.83626174926758, 17.0]}, 128)
batch 884: ({'logprob': [51.511959075927734, 13.0]}, 128)
batch 885: ({'logprob': [52.68293762207031, 13.0]}, 128)
batch 886: ({'logprob': [62.45036315917969, 17.0]}, 128)

======================Test output======================
logprob:  0.417375, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954318e-03 [2.562010e-09] 
Layer 'conv1' biases: 5.287548e-07 [4.596939e-11] 
Layer 'conv2' weights[0]: 7.941466e-03 [1.595587e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.524470e-10] 
Layer 'conv3' weights[0]: 7.939657e-03 [1.188791e-09] 
Layer 'conv3' biases: 4.454442e-06 [3.879637e-10] 
Layer 'conv4' weights[0]: 7.972313e-03 [1.167170e-09] 
Layer 'conv4' biases: 9.999990e-01 [2.234957e-09] 
Layer 'conv5' weights[0]: 7.971074e-03 [1.140133e-08] 
Layer 'conv5' biases: 9.999872e-01 [1.183073e-08] 
Layer 'fc6' weights[0]: 7.567533e-03 [1.189240e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.792554e-10] 
Layer 'fc7' weights[0]: 6.658641e-03 [4.623490e-08] 
Layer 'fc7' biases: 9.998495e-01 [2.641366e-08] 
Layer 'fc8' weights[0]: 1.251962e-03 [9.653288e-07] 
Layer 'fc8' biases: 9.491322e-02 [9.422914e-06] 
Train error last 870 batches: 0.435147
-------------------------------------------------------
Not saving because 0.417375 > 0.415628 (37.630: -0.00%)
======================================================= (12.113 sec)
38.311... logprob:  0.502314, 0.140625 (1.439 sec)
38.312... logprob:  0.478592, 0.132812 (1.435 sec)
38.313... logprob:  0.454848, 0.125000 (1.427 sec)
38.314... logprob:  0.454242, 0.117188 (1.465 sec)
38.315... logprob:  0.314723, 0.070312 (1.436 sec)
38.316... logprob:  0.468457, 0.125000 (1.454 sec)
38.317... logprob:  0.355395, 0.085938 (1.490 sec)
38.318... logprob:  0.455391, 0.125000 (1.417 sec)
38.319... logprob:  0.423141, 0.117188 (1.423 sec)
38.320... logprob:  0.412218, 0.109375 (1.427 sec)
38.321... logprob:  0.348206, 0.085938 (1.426 sec)
38.322... logprob:  0.387387, 0.101562 (1.414 sec)
38.323... logprob:  0.416490, 0.109375 (1.474 sec)
38.324... logprob:  0.498586, 0.140625 (1.429 sec)
38.325... logprob:  0.350663, 0.085938 (1.440 sec)
38.326... logprob:  0.543195, 0.148438 (1.469 sec)
38.327... logprob:  0.554456, 0.164062 (1.427 sec)
38.328... logprob:  0.565241, 0.156250 (1.425 sec)
38.329... logprob:  0.401853, 0.101562 (1.423 sec)
38.330... logprob:  0.388394, 0.101562 (1.424 sec)
38.331... logprob:  0.352060, 0.085938 (1.420 sec)
38.332... logprob:  0.482790, 0.132812 (1.451 sec)
38.333... logprob:  0.339334, 0.085938 (1.443 sec)
38.334... logprob:  0.565431, 0.171875 (1.442 sec)
38.335... logprob:  0.358562, 0.085938 (1.442 sec)
38.336... logprob:  0.444879, 0.125000 (1.457 sec)
38.337... logprob:  0.566364, 0.164062 (1.416 sec)
38.338... logprob:  0.449519, 0.125000 (1.426 sec)
38.339... logprob:  0.488515, 0.132812 (1.423 sec)
38.340... logprob:  0.442056, 0.117188 (1.430 sec)
38.341... logprob:  0.529946, 0.148438 (1.420 sec)
38.342... logprob:  0.429564, 0.109375 (1.469 sec)
38.343... logprob:  0.434758, 0.109375 (1.442 sec)
38.344... logprob:  0.444591, 0.125000 (1.482 sec)
38.345... logprob:  0.488142, 0.132812 (1.438 sec)
38.346... logprob:  0.436195, 0.117188 (1.441 sec)
38.347... logprob:  0.372680, 0.085938 (1.491 sec)
38.348... logprob:  0.398538, 0.101562 (1.437 sec)
38.349... logprob:  0.497421, 0.140625 (1.435 sec)
38.350... logprob:  0.358827, 0.085938 (1.435 sec)
38.351... logprob:  0.508366, 0.140625 (1.431 sec)
38.352... logprob:  0.363590, 0.093750 (1.439 sec)
38.353... logprob:  0.512221, 0.148438 (1.491 sec)
38.354... logprob:  0.674547, 0.203125 (1.429 sec)
38.355... logprob:  0.357524, 0.085938 (1.451 sec)
38.356... logprob:  0.479237, 0.132812 (1.476 sec)
38.357... logprob:  0.346542, 0.085938 (1.452 sec)
38.358... logprob:  0.325581, 0.070312 (1.439 sec)
38.359... logprob:  0.555489, 0.164062 (1.439 sec)
38.360... logprob:  0.444537, 0.117188 (1.427 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.00248336791992, 10.0]}, 128)
batch 872: ({'logprob': [66.13599395751953, 19.0]}, 128)
batch 873: ({'logprob': [41.176944732666016, 9.0]}, 128)
batch 874: ({'logprob': [45.52314376831055, 11.0]}, 128)
batch 875: ({'logprob': [50.928306579589844, 13.0]}, 128)
batch 876: ({'logprob': [63.72944641113281, 18.0]}, 128)
batch 877: ({'logprob': [46.06719207763672, 11.0]}, 128)
batch 878: ({'logprob': [61.802120208740234, 17.0]}, 128)
batch 879: ({'logprob': [73.15327453613281, 21.0]}, 128)
batch 880: ({'logprob': [50.95888137817383, 13.0]}, 128)
batch 881: ({'logprob': [29.7842960357666, 5.0]}, 128)
batch 882: ({'logprob': [54.997493743896484, 14.0]}, 128)
batch 883: ({'logprob': [61.76924133300781, 17.0]}, 128)
batch 884: ({'logprob': [51.473758697509766, 13.0]}, 128)
batch 885: ({'logprob': [52.53582763671875, 13.0]}, 128)
batch 886: ({'logprob': [62.32916259765625, 17.0]}, 128)

======================Test output======================
logprob:  0.417172, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954266e-03 [3.754772e-09] 
Layer 'conv1' biases: 5.297254e-07 [6.184284e-11] 
Layer 'conv2' weights[0]: 7.941427e-03 [2.234102e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.040365e-10] 
Layer 'conv3' weights[0]: 7.939627e-03 [1.523953e-09] 
Layer 'conv3' biases: 4.463410e-06 [5.341161e-10] 
Layer 'conv4' weights[0]: 7.972272e-03 [1.423545e-09] 
Layer 'conv4' biases: 9.999990e-01 [2.461393e-09] 
Layer 'conv5' weights[0]: 7.971030e-03 [1.579917e-08] 
Layer 'conv5' biases: 9.999875e-01 [1.681425e-08] 
Layer 'fc6' weights[0]: 7.567495e-03 [1.503162e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.302444e-09] 
Layer 'fc7' weights[0]: 6.656974e-03 [6.562911e-08] 
Layer 'fc7' biases: 9.998492e-01 [5.049140e-08] 
Layer 'fc8' weights[0]: 1.250839e-03 [1.586466e-06] 
Layer 'fc8' biases: 9.500278e-02 [9.785872e-06] 
Train error last 870 batches: 0.435147
-------------------------------------------------------
Not saving because 0.417172 > 0.415628 (37.630: -0.00%)
======================================================= (12.123 sec)
38.361... logprob:  0.410704, 0.101562 (1.437 sec)
38.362... logprob:  0.423823, 0.117188 (1.488 sec)
38.363... logprob:  0.486613, 0.132812 (1.442 sec)
38.364... logprob:  0.475671, 0.125000 (1.452 sec)
38.365... logprob:  0.425015, 0.109375 (1.467 sec)
38.366... logprob:  0.409482, 0.109375 (1.449 sec)
38.367... logprob:  0.324821, 0.078125 (1.435 sec)
38.368... logprob:  0.595491, 0.171875 (1.434 sec)
38.369... logprob:  0.381739, 0.093750 (1.429 sec)
38.370... logprob:  0.381380, 0.093750 (1.439 sec)
38.371... logprob:  0.400475, 0.101562 (1.458 sec)
38.372... logprob:  0.536990, 0.156250 (1.457 sec)
38.373... logprob:  0.463763, 0.125000 (1.454 sec)
38.374... logprob:  0.526656, 0.148438 (1.454 sec)
38.375... logprob:  0.393759, 0.101562 (1.465 sec)
38.376... logprob:  0.374283, 0.093750 (1.442 sec)
38.377... logprob:  0.295495, 0.062500 (1.431 sec)
38.378... logprob:  0.453593, 0.125000 (1.433 sec)
38.379... logprob:  0.420252, 0.109375 (1.441 sec)
38.380... logprob:  0.605587, 0.179688 (1.437 sec)
38.381... logprob:  0.463374, 0.125000 (1.474 sec)
38.382... logprob:  0.529628, 0.148438 (1.452 sec)
38.383... logprob:  0.358434, 0.085938 (1.442 sec)
38.384... logprob:  0.521324, 0.148438 (1.478 sec)
38.385... logprob:  0.523669, 0.148438 (1.438 sec)
38.386... logprob:  0.582759, 0.171875 (1.428 sec)
38.387... logprob:  0.428387, 0.117188 (1.437 sec)
38.388... logprob:  0.521434, 0.148438 (1.437 sec)
38.389... logprob:  0.425339, 0.109375 (1.434 sec)
38.390... logprob:  0.419480, 0.109375 (1.513 sec)
38.391... logprob:  0.317943, 0.070312 (1.447 sec)
38.392... logprob:  0.439451, 0.117188 (1.434 sec)
38.393... logprob:  0.369136, 0.093750 (1.481 sec)
38.394... logprob:  0.343849, 0.078125 (1.434 sec)
38.395... logprob:  0.332151, 0.078125 (1.433 sec)
38.396... logprob:  0.253116, 0.046875 (1.437 sec)
38.397... logprob:  0.483666, 0.132812 (1.435 sec)
38.398... logprob:  0.470130, 0.125000 (1.430 sec)
38.399... logprob:  0.432761, 0.117188 (1.491 sec)
38.400... logprob:  0.536588, 0.148438 (1.433 sec)
38.401... logprob:  0.465216, 0.125000 (1.449 sec)
38.402... logprob:  0.473472, 0.125000 (1.480 sec)
38.403... logprob:  0.461964, 0.125000 (1.435 sec)
38.404... logprob:  0.474758, 0.125000 (1.435 sec)
38.405... logprob:  0.544543, 0.156250 (1.436 sec)
38.406... logprob:  0.357300, 0.085938 (1.427 sec)
38.407... logprob:  0.493297, 0.140625 (1.439 sec)
38.408... logprob:  0.338230, 0.078125 (1.481 sec)
38.409... logprob:  0.399986, 0.101562 (1.441 sec)
38.410... logprob:  0.582753, 0.171875 (1.452 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.80322265625, 10.0]}, 128)
batch 872: ({'logprob': [65.70521545410156, 19.0]}, 128)
batch 873: ({'logprob': [42.41222381591797, 9.0]}, 128)
batch 874: ({'logprob': [46.32069778442383, 11.0]}, 128)
batch 875: ({'logprob': [51.4641227722168, 13.0]}, 128)
batch 876: ({'logprob': [63.47245407104492, 18.0]}, 128)
batch 877: ({'logprob': [46.95293045043945, 11.0]}, 128)
batch 878: ({'logprob': [61.80888366699219, 17.0]}, 128)
batch 879: ({'logprob': [72.71778869628906, 21.0]}, 128)
batch 880: ({'logprob': [51.49335861206055, 13.0]}, 128)
batch 881: ({'logprob': [31.46303939819336, 5.0]}, 128)
batch 882: ({'logprob': [55.61545181274414, 14.0]}, 128)
batch 883: ({'logprob': [61.77692413330078, 17.0]}, 128)
batch 884: ({'logprob': [52.09244918823242, 13.0]}, 128)
batch 885: ({'logprob': [53.32841873168945, 13.0]}, 128)
batch 886: ({'logprob': [62.42100143432617, 17.0]}, 128)

======================Test output======================
logprob:  0.420824, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954224e-03 [3.526477e-09] 
Layer 'conv1' biases: 5.308052e-07 [4.682396e-11] 
Layer 'conv2' weights[0]: 7.941388e-03 [2.358052e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.990833e-10] 
Layer 'conv3' weights[0]: 7.939592e-03 [1.887163e-09] 
Layer 'conv3' biases: 4.473704e-06 [9.534160e-10] 
Layer 'conv4' weights[0]: 7.972235e-03 [1.965306e-09] 
Layer 'conv4' biases: 9.999990e-01 [7.441386e-09] 
Layer 'conv5' weights[0]: 7.970990e-03 [4.722117e-08] 
Layer 'conv5' biases: 9.999877e-01 [5.049604e-08] 
Layer 'fc6' weights[0]: 7.567460e-03 [3.886377e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.882024e-09] 
Layer 'fc7' weights[0]: 6.655268e-03 [2.260611e-07] 
Layer 'fc7' biases: 9.998490e-01 [2.173241e-07] 
Layer 'fc8' weights[0]: 1.221923e-03 [8.353411e-06] 
Layer 'fc8' biases: 9.498209e-02 [5.082253e-05] 
Train error last 870 batches: 0.435146
-------------------------------------------------------
Not saving because 0.420824 > 0.415628 (37.630: -0.00%)
======================================================= (12.034 sec)
38.411... logprob:  0.397314, 0.101562 (1.491 sec)
38.412... logprob:  0.540432, 0.156250 (1.449 sec)
38.413... logprob:  0.544644, 0.156250 (1.444 sec)
38.414... logprob:  0.466176, 0.125000 (1.434 sec)
38.415... logprob:  0.401494, 0.101562 (1.425 sec)
38.416... logprob:  0.427395, 0.109375 (1.440 sec)
38.417... logprob:  0.405443, 0.093750 (1.467 sec)
38.418... logprob:  0.380719, 0.093750 (1.450 sec)
38.419... logprob:  0.418103, 0.101562 (1.458 sec)
38.420... logprob:  0.356947, 0.085938 (1.457 sec)
38.421... logprob:  0.376794, 0.101562 (1.454 sec)
38.422... logprob:  0.521323, 0.148438 (1.443 sec)
38.423... logprob:  0.420645, 0.109375 (1.450 sec)
38.424... logprob:  0.325190, 0.078125 (1.436 sec)
38.425... logprob:  0.306849, 0.070312 (1.439 sec)
38.426... logprob:  0.448682, 0.117188 (1.437 sec)
38.427... logprob:  0.553180, 0.156250 (1.464 sec)
38.428... logprob:  0.600835, 0.171875 (1.456 sec)
38.429... logprob:  0.426387, 0.109375 (1.443 sec)
38.430... logprob:  0.299647, 0.070312 (1.481 sec)
38.431... logprob:  0.600574, 0.171875 (1.437 sec)
38.432... logprob:  0.387495, 0.093750 (1.425 sec)
38.433... logprob:  0.329142, 0.078125 (1.437 sec)
38.434... logprob:  0.530103, 0.148438 (1.440 sec)
38.435... logprob:  0.532933, 0.156250 (1.431 sec)
38.436... logprob:  0.380430, 0.093750 (1.480 sec)
38.437... logprob:  0.500450, 0.140625 (1.444 sec)
38.438... logprob:  0.547228, 0.156250 (1.436 sec)
38.439... logprob:  0.378042, 0.093750 (1.489 sec)
38.440... logprob:  0.439441, 0.117188 (1.437 sec)
38.441... logprob:  0.467854, 0.125000 (1.427 sec)
38.442... logprob:  0.378858, 0.093750 (1.440 sec)
38.443... logprob:  0.496541, 0.140625 (1.432 sec)
38.444... logprob:  0.372632, 0.093750 (1.438 sec)
38.445... logprob:  0.362996, 0.085938 (1.556 sec)
38.446... logprob:  0.398638, 0.101562 (1.443 sec)
38.447... logprob:  0.568846, 0.164062 (1.441 sec)
38.448... logprob:  0.333470, 0.078125 (1.482 sec)
38.449... logprob:  0.400094, 0.101562 (1.435 sec)
38.450... logprob:  0.240546, 0.046875 (1.435 sec)
38.451... logprob:  0.452079, 0.125000 (1.437 sec)
38.452... logprob:  0.455663, 0.117188 (1.432 sec)
38.453... logprob:  0.454704, 0.125000 (1.434 sec)
38.454... logprob:  0.488512, 0.132812 (1.486 sec)
38.455... logprob:  0.505834, 0.140625 (1.445 sec)
38.456... logprob:  0.468828, 0.125000 (1.449 sec)
38.457... logprob:  0.375279, 0.093750 (1.474 sec)
38.458... logprob:  0.350801, 0.085938 (1.440 sec)
38.459... logprob:  0.514402, 0.140625 (1.436 sec)
38.460... logprob:  0.272991, 0.054688 (1.435 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.581295013427734, 10.0]}, 128)
batch 872: ({'logprob': [66.51335906982422, 19.0]}, 128)
batch 873: ({'logprob': [40.63454818725586, 9.0]}, 128)
batch 874: ({'logprob': [45.176422119140625, 11.0]}, 128)
batch 875: ({'logprob': [50.757057189941406, 13.0]}, 128)
batch 876: ({'logprob': [64.01434326171875, 18.0]}, 128)
batch 877: ({'logprob': [45.710025787353516, 11.0]}, 128)
batch 878: ({'logprob': [61.98369598388672, 17.0]}, 128)
batch 879: ({'logprob': [73.67840576171875, 21.0]}, 128)
batch 880: ({'logprob': [50.78781509399414, 13.0]}, 128)
batch 881: ({'logprob': [28.89778709411621, 5.0]}, 128)
batch 882: ({'logprob': [54.89149856567383, 14.0]}, 128)
batch 883: ({'logprob': [61.95084762573242, 17.0]}, 128)
batch 884: ({'logprob': [51.294803619384766, 13.0]}, 128)
batch 885: ({'logprob': [52.33745193481445, 13.0]}, 128)
batch 886: ({'logprob': [62.50203323364258, 17.0]}, 128)

======================Test output======================
logprob:  0.416363, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954183e-03 [2.812142e-09] 
Layer 'conv1' biases: 5.318206e-07 [1.001182e-10] 
Layer 'conv2' weights[0]: 7.941351e-03 [3.006127e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.172919e-10] 
Layer 'conv3' weights[0]: 7.939552e-03 [2.834384e-09] 
Layer 'conv3' biases: 4.481607e-06 [1.540978e-09] 
Layer 'conv4' weights[0]: 7.972199e-03 [2.767690e-09] 
Layer 'conv4' biases: 9.999990e-01 [1.266153e-08] 
Layer 'conv5' weights[0]: 7.970949e-03 [7.420081e-08] 
Layer 'conv5' biases: 9.999874e-01 [7.945238e-08] 
Layer 'fc6' weights[0]: 7.567420e-03 [6.031952e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.139117e-09] 
Layer 'fc7' weights[0]: 6.653579e-03 [9.271223e-08] 
Layer 'fc7' biases: 9.998496e-01 [8.020963e-08] 
Layer 'fc8' weights[0]: 1.258625e-03 [2.780152e-06] 
Layer 'fc8' biases: 9.562211e-02 [1.669920e-05] 
Train error last 870 batches: 0.435146
-------------------------------------------------------
Not saving because 0.416363 > 0.415628 (37.630: -0.00%)
======================================================= (12.087 sec)
38.461... logprob:  0.460273, 0.125000 (1.436 sec)
38.462... logprob:  0.472105, 0.125000 (1.444 sec)
38.463... logprob:  0.420705, 0.109375 (1.478 sec)
38.464... logprob:  0.482918, 0.132812 (1.448 sec)
38.465... logprob:  0.421006, 0.109375 (1.454 sec)
38.466... logprob:  0.317913, 0.070312 (1.459 sec)
38.467... logprob:  0.413775, 0.109375 (1.454 sec)
38.468... logprob:  0.394219, 0.101562 (1.441 sec)
38.469... logprob:  0.334854, 0.078125 (1.429 sec)
38.470... logprob:  0.400137, 0.101562 (1.429 sec)
38.471... logprob:  0.528938, 0.148438 (1.441 sec)
38.472... logprob:  0.409921, 0.109375 (1.453 sec)
38.473... logprob:  0.375585, 0.093750 (1.460 sec)
38.474... logprob:  0.465300, 0.125000 (1.455 sec)
38.475... logprob:  0.503507, 0.140625 (1.445 sec)
38.476... logprob:  0.509879, 0.140625 (1.475 sec)
38.477... logprob:  0.334785, 0.078125 (1.435 sec)
38.478... logprob:  0.464172, 0.125000 (1.430 sec)
38.479... logprob:  0.305800, 0.070312 (1.431 sec)
38.480... logprob:  0.443485, 0.117188 (1.440 sec)
38.481... logprob:  0.547828, 0.156250 (1.437 sec)
38.482... logprob:  0.443105, 0.117188 (1.476 sec)
38.483... logprob:  0.502783, 0.140625 (1.447 sec)
38.484... logprob:  0.485352, 0.132812 (1.441 sec)
38.485... logprob:  0.408799, 0.109375 (1.487 sec)
38.486... logprob:  0.361014, 0.085938 (1.432 sec)
38.487... logprob:  0.522785, 0.148438 (1.432 sec)
38.488... logprob:  0.424578, 0.109375 (1.434 sec)
38.489... logprob:  0.415709, 0.109375 (1.439 sec)
38.490... logprob:  0.440671, 0.117188 (1.436 sec)
38.491... logprob:  0.313482, 0.070312 (1.482 sec)
38.492... logprob:  0.459469, 0.125000 (1.440 sec)
38.493... logprob:  0.521697, 0.148438 (1.437 sec)
38.494... logprob:  0.450325, 0.125000 (1.489 sec)
38.495... logprob:  0.380777, 0.093750 (1.436 sec)
38.496... logprob:  0.549981, 0.156250 (1.431 sec)
38.497... logprob:  0.466790, 0.125000 (1.472 sec)
38.498... logprob:  0.476123, 0.132812 (1.428 sec)
38.499... logprob:  0.456186, 0.125000 (1.438 sec)
38.500... logprob:  0.355233, 0.085938 (1.480 sec)
38.501... logprob:  0.339156, 0.078125 (1.433 sec)
38.502... logprob:  0.459558, 0.125000 (1.447 sec)
38.503... logprob:  0.400647, 0.101562 (1.483 sec)
38.504... logprob:  0.487222, 0.132812 (1.436 sec)
38.505... logprob:  0.570711, 0.164062 (1.444 sec)
38.506... logprob:  0.479683, 0.132812 (1.432 sec)
38.507... logprob:  0.384951, 0.093750 (1.431 sec)
38.508... logprob:  0.374588, 0.093750 (1.433 sec)
38.509... logprob:  0.322834, 0.070312 (1.479 sec)
38.510... logprob:  0.390436, 0.101562 (1.444 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.7972526550293, 10.0]}, 128)
batch 872: ({'logprob': [66.58558654785156, 19.0]}, 128)
batch 873: ({'logprob': [40.54142379760742, 9.0]}, 128)
batch 874: ({'logprob': [45.229827880859375, 11.0]}, 128)
batch 875: ({'logprob': [50.767578125, 13.0]}, 128)
batch 876: ({'logprob': [64.0608901977539, 18.0]}, 128)
batch 877: ({'logprob': [45.66910171508789, 11.0]}, 128)
batch 878: ({'logprob': [61.9100341796875, 17.0]}, 128)
batch 879: ({'logprob': [73.42639923095703, 21.0]}, 128)
batch 880: ({'logprob': [50.79891586303711, 13.0]}, 128)
batch 881: ({'logprob': [28.983623504638672, 5.0]}, 128)
batch 882: ({'logprob': [54.6456298828125, 14.0]}, 128)
batch 883: ({'logprob': [61.8766975402832, 17.0]}, 128)
batch 884: ({'logprob': [51.21144104003906, 13.0]}, 128)
batch 885: ({'logprob': [52.065670013427734, 13.0]}, 128)
batch 886: ({'logprob': [62.334144592285156, 17.0]}, 128)

======================Test output======================
logprob:  0.415969, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954158e-03 [5.066675e-09] 
Layer 'conv1' biases: 5.326747e-07 [1.735840e-10] 
Layer 'conv2' weights[0]: 7.941314e-03 [3.550545e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.037707e-10] 
Layer 'conv3' weights[0]: 7.939518e-03 [3.272942e-09] 
Layer 'conv3' biases: 4.490276e-06 [1.901503e-09] 
Layer 'conv4' weights[0]: 7.972161e-03 [3.337435e-09] 
Layer 'conv4' biases: 9.999990e-01 [1.617224e-08] 
Layer 'conv5' weights[0]: 7.970920e-03 [1.010977e-07] 
Layer 'conv5' biases: 9.999869e-01 [1.080538e-07] 
Layer 'fc6' weights[0]: 7.567382e-03 [8.198083e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.331576e-09] 
Layer 'fc7' weights[0]: 6.651885e-03 [1.557827e-07] 
Layer 'fc7' biases: 9.998494e-01 [1.454423e-07] 
Layer 'fc8' weights[0]: 1.255215e-03 [5.728212e-06] 
Layer 'fc8' biases: 9.570177e-02 [4.124960e-05] 
Train error last 870 batches: 0.435146
-------------------------------------------------------
Not saving because 0.415969 > 0.415628 (37.630: -0.00%)
======================================================= (12.038 sec)
38.511... logprob:  0.410018, 0.109375 (1.460 sec)
38.512... logprob:  0.470697, 0.125000 (1.479 sec)
38.513... logprob:  0.324950, 0.078125 (1.447 sec)
38.514... logprob:  0.406271, 0.101562 (1.450 sec)
38.515... logprob:  0.455369, 0.125000 (1.434 sec)
38.516... logprob:  0.400145, 0.109375 (1.425 sec)
38.517... logprob:  0.627518, 0.179688 (1.441 sec)
38.518... logprob:  0.437594, 0.117188 (1.462 sec)
38.519... logprob:  0.516122, 0.140625 (1.456 sec)
38.520... logprob:  0.409632, 0.109375 (1.454 sec)
38.521... logprob:  0.427356, 0.109375 (1.459 sec)
38.522... logprob:  0.533260, 0.156250 (1.466 sec)
38.523... logprob:  0.331256, 0.078125 (1.437 sec)
38.524... logprob:  0.437073, 0.117188 (1.430 sec)
38.525... logprob:  0.425749, 0.109375 (1.431 sec)
38.526... logprob:  0.351405, 0.078125 (1.442 sec)
38.527... logprob:  0.504612, 0.140625 (1.440 sec)
38.528... logprob:  0.440413, 0.117188 (1.469 sec)
38.529... logprob:  0.352991, 0.085938 (1.451 sec)
38.530... logprob:  0.440263, 0.117188 (1.468 sec)
38.531... logprob:  0.439909, 0.117188 (1.477 sec)
38.532... logprob:  0.467244, 0.125000 (1.440 sec)
38.533... logprob:  0.560012, 0.164062 (1.429 sec)
38.534... logprob:  0.326081, 0.078125 (1.435 sec)
38.535... logprob:  0.551210, 0.156250 (1.439 sec)
38.536... logprob:  0.507144, 0.140625 (1.432 sec)
38.537... logprob:  0.509925, 0.140625 (1.480 sec)
38.538... logprob:  0.486055, 0.132812 (1.445 sec)
38.539... logprob:  0.295946, 0.062500 (1.435 sec)
38.540... logprob:  0.447178, 0.117188 (1.489 sec)
38.541... logprob:  0.388709, 0.101562 (1.433 sec)
38.542... logprob:  0.411173, 0.109375 (1.431 sec)
38.543... logprob:  0.233049, 0.039062 (1.438 sec)
38.544... logprob:  0.317906, 0.070312 (1.437 sec)
38.545... logprob:  0.348790, 0.085938 (1.431 sec)
38.546... logprob:  0.368257, 0.093750 (1.488 sec)
38.547... logprob:  0.439899, 0.117188 (1.435 sec)
38.548... logprob:  0.452613, 0.125000 (1.445 sec)
38.549... logprob:  0.490172, 0.132812 (1.483 sec)
38.550... logprob:  0.367540, 0.093750 (1.431 sec)
38.551... logprob:  0.441491, 0.117188 (1.437 sec)
38.552... logprob:  0.471179, 0.125000 (1.435 sec)
38.553... logprob:  0.349455, 0.085938 (1.430 sec)
38.554... logprob:  0.507101, 0.140625 (1.435 sec)
38.555... logprob:  0.421410, 0.109375 (1.482 sec)
38.556... logprob:  0.355662, 0.085938 (1.444 sec)
38.557... logprob:  0.396264, 0.101562 (1.451 sec)
38.558... logprob:  0.382964, 0.101562 (1.473 sec)
38.559... logprob:  0.441759, 0.125000 (1.439 sec)
38.560... logprob:  0.334783, 0.078125 (1.441 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.61552429199219, 10.0]}, 128)
batch 872: ({'logprob': [66.24346923828125, 19.0]}, 128)
batch 873: ({'logprob': [41.04589080810547, 9.0]}, 128)
batch 874: ({'logprob': [45.33171844482422, 11.0]}, 128)
batch 875: ({'logprob': [50.85658264160156, 13.0]}, 128)
batch 876: ({'logprob': [63.822208404541016, 18.0]}, 128)
batch 877: ({'logprob': [45.96543884277344, 11.0]}, 128)
batch 878: ({'logprob': [61.969947814941406, 17.0]}, 128)
batch 879: ({'logprob': [73.65043640136719, 21.0]}, 128)
batch 880: ({'logprob': [50.886959075927734, 13.0]}, 128)
batch 881: ({'logprob': [29.32317352294922, 5.0]}, 128)
batch 882: ({'logprob': [55.21120834350586, 14.0]}, 128)
batch 883: ({'logprob': [61.937171936035156, 17.0]}, 128)
batch 884: ({'logprob': [51.49294662475586, 13.0]}, 128)
batch 885: ({'logprob': [52.735267639160156, 13.0]}, 128)
batch 886: ({'logprob': [62.587615966796875, 17.0]}, 128)

======================Test output======================
logprob:  0.417322, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954122e-03 [4.164343e-09] 
Layer 'conv1' biases: 5.339048e-07 [1.427414e-10] 
Layer 'conv2' weights[0]: 7.941278e-03 [2.900837e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.667217e-10] 
Layer 'conv3' weights[0]: 7.939479e-03 [2.893948e-09] 
Layer 'conv3' biases: 4.501670e-06 [1.574199e-09] 
Layer 'conv4' weights[0]: 7.972116e-03 [2.868122e-09] 
Layer 'conv4' biases: 9.999990e-01 [1.306768e-08] 
Layer 'conv5' weights[0]: 7.970876e-03 [8.244479e-08] 
Layer 'conv5' biases: 9.999872e-01 [8.817708e-08] 
Layer 'fc6' weights[0]: 7.567345e-03 [6.679759e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.799658e-09] 
Layer 'fc7' weights[0]: 6.650233e-03 [4.416527e-08] 
Layer 'fc7' biases: 9.998497e-01 [2.382693e-08] 
Layer 'fc8' weights[0]: 1.249428e-03 [5.413568e-06] 
Layer 'fc8' biases: 9.577339e-02 [3.477604e-05] 
Train error last 870 batches: 0.435145
-------------------------------------------------------
Not saving because 0.417322 > 0.415628 (37.630: -0.00%)
======================================================= (12.108 sec)
38.561... logprob:  0.411752, 0.109375 (1.446 sec)
38.562... logprob:  0.503209, 0.140625 (1.433 sec)
38.563... logprob:  0.373669, 0.093750 (1.467 sec)
38.564... logprob:  0.468551, 0.132812 (1.464 sec)
38.565... logprob:  0.611281, 0.187500 (1.454 sec)
38.566... logprob:  0.374823, 0.093750 (1.456 sec)
38.567... logprob:  0.423197, 0.109375 (1.467 sec)
38.568... logprob:  0.496297, 0.140625 (1.457 sec)
38.569... logprob:  0.507561, 0.140625 (1.440 sec)
38.570... logprob:  0.543850, 0.164062 (1.430 sec)
38.571... logprob:  0.454895, 0.125000 (1.426 sec)
38.572... logprob:  0.501281, 0.140625 (1.443 sec)
38.573... logprob:  0.512577, 0.148438 (1.447 sec)
38.574... logprob:  0.427936, 0.109375 (1.469 sec)
38.575... logprob:  0.343314, 0.078125 (1.452 sec)
38.576... logprob:  0.427313, 0.109375 (1.444 sec)
38.577... logprob:  0.460750, 0.125000 (1.476 sec)
38.578... logprob:  0.336941, 0.078125 (1.441 sec)
38.579... logprob:  0.442079, 0.117188 (1.422 sec)
38.580... logprob:  0.546389, 0.156250 (1.440 sec)
38.581... logprob:  0.530349, 0.156250 (1.437 sec)
38.582... logprob:  0.437732, 0.125000 (1.437 sec)
38.583... logprob:  0.592084, 0.171875 (1.476 sec)
38.584... logprob:  0.468023, 0.132812 (1.449 sec)
38.585... logprob:  0.349782, 0.085938 (1.435 sec)
38.586... logprob:  0.313011, 0.070312 (1.489 sec)
38.587... logprob:  0.404287, 0.101562 (1.432 sec)
38.588... logprob:  0.418644, 0.117188 (1.432 sec)
38.589... logprob:  0.361060, 0.093750 (1.439 sec)
38.590... logprob:  0.524829, 0.148438 (1.430 sec)
38.591... logprob:  0.397419, 0.101562 (1.441 sec)
38.592... logprob:  0.455705, 0.125000 (1.488 sec)
38.593... logprob:  0.467413, 0.125000 (1.442 sec)
38.594... logprob:  0.352786, 0.085938 (1.438 sec)
38.595... logprob:  0.428659, 0.109375 (1.485 sec)
38.596... logprob:  0.461642, 0.125000 (1.433 sec)
38.597... logprob:  0.397421, 0.101562 (1.437 sec)
38.598... logprob:  0.397209, 0.101562 (1.434 sec)
38.599... logprob:  0.313614, 0.070312 (1.434 sec)
38.600... logprob:  0.340861, 0.085938 (1.432 sec)
38.601... logprob:  0.402179, 0.101562 (1.490 sec)
38.602... logprob:  0.290023, 0.062500 (1.435 sec)
38.603... logprob:  0.267382, 0.054688 (1.445 sec)
38.604... logprob:  0.407539, 0.101562 (1.503 sec)
38.605... logprob:  0.563081, 0.148438 (1.437 sec)
38.606... logprob:  0.295953, 0.070312 (1.440 sec)
38.607... logprob:  0.504530, 0.132812 (1.428 sec)
38.608... logprob:  0.362009, 0.085938 (1.427 sec)
38.609... logprob:  0.357138, 0.085938 (1.434 sec)
38.610... logprob:  0.493180, 0.132812 (1.477 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.08078384399414, 10.0]}, 128)
batch 872: ({'logprob': [68.10047912597656, 19.0]}, 128)
batch 873: ({'logprob': [39.550926208496094, 9.0]}, 128)
batch 874: ({'logprob': [44.75055694580078, 11.0]}, 128)
batch 875: ({'logprob': [50.780433654785156, 13.0]}, 128)
batch 876: ({'logprob': [65.32661437988281, 18.0]}, 128)
batch 877: ({'logprob': [45.17973709106445, 11.0]}, 128)
batch 878: ({'logprob': [62.91373825073242, 17.0]}, 128)
batch 879: ({'logprob': [75.41193389892578, 21.0]}, 128)
batch 880: ({'logprob': [50.81303024291992, 13.0]}, 128)
batch 881: ({'logprob': [27.008569717407227, 5.0]}, 128)
batch 882: ({'logprob': [54.888877868652344, 14.0]}, 128)
batch 883: ({'logprob': [62.879234313964844, 17.0]}, 128)
batch 884: ({'logprob': [51.22148513793945, 13.0]}, 128)
batch 885: ({'logprob': [52.05854797363281, 13.0]}, 128)
batch 886: ({'logprob': [63.33190155029297, 17.0]}, 128)

======================Test output======================
logprob:  0.417625, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954092e-03 [4.623796e-09] 
Layer 'conv1' biases: 5.351306e-07 [1.753268e-10] 
Layer 'conv2' weights[0]: 7.941236e-03 [4.174155e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.536743e-10] 
Layer 'conv3' weights[0]: 7.939442e-03 [3.839933e-09] 
Layer 'conv3' biases: 4.510389e-06 [2.459060e-09] 
Layer 'conv4' weights[0]: 7.972077e-03 [3.917177e-09] 
Layer 'conv4' biases: 9.999990e-01 [2.051933e-08] 
Layer 'conv5' weights[0]: 7.970849e-03 [1.290159e-07] 
Layer 'conv5' biases: 9.999871e-01 [1.378543e-07] 
Layer 'fc6' weights[0]: 7.567304e-03 [1.045603e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.069678e-08] 
Layer 'fc7' weights[0]: 6.648539e-03 [2.348418e-07] 
Layer 'fc7' biases: 9.998508e-01 [2.259126e-07] 
Layer 'fc8' weights[0]: 1.301389e-03 [1.305089e-05] 
Layer 'fc8' biases: 9.626860e-02 [8.512724e-05] 
Train error last 870 batches: 0.435145
-------------------------------------------------------
Not saving because 0.417625 > 0.415628 (37.630: -0.00%)
======================================================= (12.028 sec)
38.611... logprob:  0.510240, 0.140625 (1.454 sec)
38.612... logprob:  0.448640, 0.117188 (1.464 sec)
38.613... logprob:  0.279056, 0.062500 (1.464 sec)
38.614... logprob:  0.503598, 0.140625 (1.453 sec)
38.615... logprob:  0.350570, 0.085938 (1.439 sec)
38.616... logprob:  0.414872, 0.109375 (1.432 sec)
38.617... logprob:  0.417732, 0.109375 (1.427 sec)
38.618... logprob:  0.547265, 0.156250 (1.440 sec)
38.619... logprob:  0.506249, 0.140625 (1.453 sec)
38.620... logprob:  0.539767, 0.156250 (1.461 sec)
38.621... logprob:  0.363330, 0.085938 (1.456 sec)
38.622... logprob:  0.364472, 0.085938 (1.452 sec)
38.623... logprob:  0.423050, 0.109375 (1.467 sec)
38.624... logprob:  0.382459, 0.093750 (1.434 sec)
38.625... logprob:  0.440963, 0.117188 (1.424 sec)
38.626... logprob:  0.438314, 0.117188 (1.433 sec)
38.627... logprob:  0.435793, 0.117188 (1.439 sec)
38.628... logprob:  0.464980, 0.125000 (1.438 sec)
38.629... logprob:  0.372255, 0.093750 (1.476 sec)
38.630... logprob:  0.422401, 0.109375 (1.448 sec)
38.631... logprob:  0.637764, 0.187500 (1.437 sec)
38.632... logprob:  0.399146, 0.101562 (1.486 sec)
38.633... logprob:  0.376190, 0.093750 (1.435 sec)
38.634... logprob:  0.659753, 0.195312 (1.428 sec)
38.635... logprob:  0.374136, 0.093750 (1.438 sec)
38.636... logprob:  0.480275, 0.132812 (1.439 sec)
38.637... logprob:  0.330625, 0.078125 (1.460 sec)
38.638... logprob:  0.515731, 0.140625 (1.482 sec)
38.639... logprob:  0.417957, 0.109375 (1.443 sec)
38.640... logprob:  0.528779, 0.148438 (1.435 sec)
38.641... logprob:  0.410357, 0.109375 (1.477 sec)
38.642... logprob:  0.500975, 0.140625 (1.437 sec)
38.643... logprob:  0.623587, 0.187500 (1.437 sec)
38.644... logprob:  0.320597, 0.070312 (1.436 sec)
38.645... logprob:  0.414401, 0.109375 (1.430 sec)
38.646... logprob:  0.385424, 0.093750 (1.434 sec)
38.647... logprob:  0.456820, 0.125000 (1.486 sec)
38.648... logprob:  0.491314, 0.140625 (1.438 sec)
38.649... logprob:  0.370433, 0.093750 (1.449 sec)
38.650... logprob:  0.414099, 0.109375 (1.481 sec)
38.651... logprob:  0.397481, 0.101562 (1.436 sec)
38.652... logprob:  0.506878, 0.140625 (1.449 sec)
38.653... logprob:  0.547439, 0.156250 (1.442 sec)
38.654... logprob:  0.495915, 0.140625 (1.438 sec)
38.655... logprob:  0.436163, 0.117188 (1.448 sec)
38.656... logprob:  0.416747, 0.109375 (1.486 sec)
38.657... logprob:  0.448892, 0.117188 (1.453 sec)
38.658... logprob:  0.345990, 0.085938 (1.461 sec)
38.659... logprob:  0.464226, 0.125000 (1.484 sec)
38.660... logprob:  0.446141, 0.125000 (1.454 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.71711349487305, 10.0]}, 128)
batch 872: ({'logprob': [66.22148895263672, 19.0]}, 128)
batch 873: ({'logprob': [41.050697326660156, 9.0]}, 128)
batch 874: ({'logprob': [45.36960983276367, 11.0]}, 128)
batch 875: ({'logprob': [50.863407135009766, 13.0]}, 128)
batch 876: ({'logprob': [63.79997253417969, 18.0]}, 128)
batch 877: ({'logprob': [45.97151184082031, 11.0]}, 128)
batch 878: ({'logprob': [61.9150390625, 17.0]}, 128)
batch 879: ({'logprob': [73.5014877319336, 21.0]}, 128)
batch 880: ({'logprob': [50.89395523071289, 13.0]}, 128)
batch 881: ({'logprob': [29.421993255615234, 5.0]}, 128)
batch 882: ({'logprob': [55.122459411621094, 14.0]}, 128)
batch 883: ({'logprob': [61.88204574584961, 17.0]}, 128)
batch 884: ({'logprob': [51.4676399230957, 13.0]}, 128)
batch 885: ({'logprob': [52.6456298828125, 13.0]}, 128)
batch 886: ({'logprob': [62.50040817260742, 17.0]}, 128)

======================Test output======================
logprob:  0.417160, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954053e-03 [2.645759e-09] 
Layer 'conv1' biases: 5.361850e-07 [3.678327e-11] 
Layer 'conv2' weights[0]: 7.941202e-03 [1.571500e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.484302e-10] 
Layer 'conv3' weights[0]: 7.939402e-03 [1.143825e-09] 
Layer 'conv3' biases: 4.520253e-06 [3.991127e-10] 
Layer 'conv4' weights[0]: 7.972037e-03 [1.095902e-09] 
Layer 'conv4' biases: 9.999989e-01 [2.162171e-09] 
Layer 'conv5' weights[0]: 7.970799e-03 [9.563902e-09] 
Layer 'conv5' biases: 9.999870e-01 [9.766750e-09] 
Layer 'fc6' weights[0]: 7.567263e-03 [1.028454e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.625943e-10] 
Layer 'fc7' weights[0]: 6.646860e-03 [4.468138e-08] 
Layer 'fc7' biases: 9.998493e-01 [2.464918e-08] 
Layer 'fc8' weights[0]: 1.252435e-03 [4.432289e-06] 
Layer 'fc8' biases: 9.602694e-02 [3.100404e-05] 
Train error last 870 batches: 0.435145
-------------------------------------------------------
Not saving because 0.417160 > 0.415628 (37.630: -0.00%)
======================================================= (12.324 sec)
38.661... logprob:  0.378330, 0.093750 (1.438 sec)
38.662... logprob:  0.469552, 0.132812 (1.440 sec)
38.663... logprob:  0.310752, 0.070312 (1.446 sec)
38.664... logprob:  0.285267, 0.062500 (1.454 sec)
38.665... logprob:  0.401572, 0.101562 (1.477 sec)
38.666... logprob:  0.441995, 0.117188 (1.474 sec)
38.667... logprob:  0.564148, 0.164062 (1.469 sec)
38.668... logprob:  0.497813, 0.140625 (1.470 sec)
38.669... logprob:  0.432791, 0.109375 (1.480 sec)
38.670... logprob:  0.362259, 0.085938 (1.454 sec)
38.671... logprob:  0.360889, 0.093750 (1.442 sec)
38.672... logprob:  0.441835, 0.117188 (1.449 sec)
38.673... logprob:  0.436218, 0.117188 (1.458 sec)
38.674... logprob:  0.446604, 0.117188 (1.448 sec)
38.675... logprob:  0.356700, 0.093750 (1.487 sec)
38.676... logprob:  0.450219, 0.125000 (1.464 sec)
38.677... logprob:  0.470989, 0.125000 (1.450 sec)
38.678... logprob:  0.465671, 0.125000 (1.496 sec)
38.679... logprob:  0.454862, 0.125000 (1.440 sec)
38.680... logprob:  0.351586, 0.078125 (1.500 sec)
38.681... logprob:  0.373807, 0.093750 (1.438 sec)
38.682... logprob:  0.340432, 0.078125 (1.438 sec)
38.683... logprob:  0.411624, 0.109375 (1.444 sec)
38.684... logprob:  0.357770, 0.085938 (1.487 sec)
38.685... logprob:  0.286441, 0.054688 (1.453 sec)
38.686... logprob:  0.319015, 0.070312 (1.438 sec)
38.687... logprob:  0.282007, 0.062500 (1.497 sec)
38.688... logprob:  0.323203, 0.078125 (1.443 sec)
38.689... logprob:  0.470525, 0.125000 (1.431 sec)
38.690... logprob:  0.526846, 0.140625 (1.432 sec)
38.691... logprob:  0.515552, 0.140625 (1.437 sec)
38.692... logprob:  0.384397, 0.101562 (1.435 sec)
38.693... logprob:  0.455112, 0.125000 (1.490 sec)
38.694... logprob:  0.331009, 0.078125 (1.434 sec)
38.695... logprob:  0.357000, 0.085938 (1.445 sec)
38.696... logprob:  0.539604, 0.148438 (1.479 sec)
38.697... logprob:  0.465938, 0.125000 (1.438 sec)
38.698... logprob:  0.549455, 0.156250 (1.436 sec)
38.699... logprob:  0.459682, 0.125000 (1.437 sec)
38.700... logprob:  0.433658, 0.117188 (1.429 sec)
38.701... logprob:  0.422634, 0.109375 (1.434 sec)
38.702... logprob:  0.521685, 0.148438 (1.485 sec)
38.703... logprob:  0.404518, 0.101562 (1.443 sec)
38.704... logprob:  0.405580, 0.101562 (1.459 sec)
38.705... logprob:  0.419897, 0.109375 (1.478 sec)
38.706... logprob:  0.468018, 0.125000 (1.447 sec)
38.707... logprob:  0.485292, 0.132812 (1.443 sec)
38.708... logprob:  0.417352, 0.109375 (1.441 sec)
38.709... logprob:  0.422841, 0.109375 (1.435 sec)
38.710... logprob:  0.601550, 0.179688 (1.444 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.50796890258789, 10.0]}, 128)
batch 872: ({'logprob': [66.09490966796875, 19.0]}, 128)
batch 873: ({'logprob': [41.385154724121094, 9.0]}, 128)
batch 874: ({'logprob': [45.80618667602539, 11.0]}, 128)
batch 875: ({'logprob': [51.07855224609375, 13.0]}, 128)
batch 876: ({'logprob': [63.702911376953125, 18.0]}, 128)
batch 877: ({'logprob': [46.246891021728516, 11.0]}, 128)
batch 878: ({'logprob': [61.68669891357422, 17.0]}, 128)
batch 879: ({'logprob': [72.66899871826172, 21.0]}, 128)
batch 880: ({'logprob': [51.109031677246094, 13.0]}, 128)
batch 881: ({'logprob': [30.362571716308594, 5.0]}, 128)
batch 882: ({'logprob': [54.82162857055664, 14.0]}, 128)
batch 883: ({'logprob': [61.65382766723633, 17.0]}, 128)
batch 884: ({'logprob': [51.51938247680664, 13.0]}, 128)
batch 885: ({'logprob': [52.37405014038086, 13.0]}, 128)
batch 886: ({'logprob': [62.109397888183594, 17.0]}, 128)

======================Test output======================
logprob:  0.417543, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954018e-03 [3.710247e-09] 
Layer 'conv1' biases: 5.370569e-07 [5.539636e-11] 
Layer 'conv2' weights[0]: 7.941175e-03 [2.489044e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.509763e-10] 
Layer 'conv3' weights[0]: 7.939358e-03 [2.033803e-09] 
Layer 'conv3' biases: 4.526878e-06 [1.191058e-09] 
Layer 'conv4' weights[0]: 7.971997e-03 [2.085627e-09] 
Layer 'conv4' biases: 9.999987e-01 [9.436475e-09] 
Layer 'conv5' weights[0]: 7.970765e-03 [5.849376e-08] 
Layer 'conv5' biases: 9.999868e-01 [6.262565e-08] 
Layer 'fc6' weights[0]: 7.567224e-03 [4.834263e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.826011e-09] 
Layer 'fc7' weights[0]: 6.645192e-03 [1.039005e-07] 
Layer 'fc7' biases: 9.998488e-01 [9.077999e-08] 
Layer 'fc8' weights[0]: 1.236627e-03 [3.213746e-06] 
Layer 'fc8' biases: 9.611224e-02 [2.927258e-05] 
Train error last 870 batches: 0.435144
-------------------------------------------------------
Not saving because 0.417543 > 0.415628 (37.630: -0.00%)
======================================================= (12.050 sec)
38.711... logprob:  0.469441, 0.125000 (1.473 sec)
38.712... logprob:  0.341464, 0.078125 (1.459 sec)
38.713... logprob:  0.585696, 0.179688 (1.460 sec)
38.714... logprob:  0.466174, 0.125000 (1.460 sec)
38.715... logprob:  0.417267, 0.109375 (1.454 sec)
38.716... logprob:  0.335748, 0.078125 (1.440 sec)
38.717... logprob:  0.429734, 0.117188 (1.432 sec)
38.718... logprob:  0.490218, 0.132812 (1.436 sec)
38.719... logprob:  0.406165, 0.109375 (1.444 sec)
38.720... logprob:  0.433210, 0.117188 (1.454 sec)
38.721... logprob:  0.451602, 0.117188 (1.465 sec)
38.722... logprob:  0.537142, 0.156250 (1.452 sec)
38.723... logprob:  0.416513, 0.109375 (1.449 sec)
38.724... logprob:  0.412747, 0.109375 (1.474 sec)
38.725... logprob:  0.495042, 0.140625 (1.437 sec)
38.726... logprob:  0.338195, 0.085938 (1.425 sec)
38.727... logprob:  0.393054, 0.101562 (1.441 sec)
38.728... logprob:  0.421089, 0.109375 (1.444 sec)
38.729... logprob:  0.387366, 0.093750 (1.435 sec)
38.730... logprob:  0.566082, 0.164062 (1.476 sec)
38.731... logprob:  0.450495, 0.125000 (1.448 sec)
38.732... logprob:  0.311263, 0.070312 (1.439 sec)
38.733... logprob:  0.556374, 0.156250 (1.489 sec)
38.734... logprob:  0.340237, 0.078125 (1.434 sec)
38.735... logprob:  0.527289, 0.148438 (1.431 sec)
38.736... logprob:  0.642231, 0.187500 (1.439 sec)
38.737... logprob:  0.516019, 0.148438 (1.432 sec)
38.738... logprob:  0.459351, 0.125000 (1.435 sec)
38.739... logprob:  0.477771, 0.132812 (1.484 sec)
38.740... logprob:  0.339642, 0.078125 (1.441 sec)
38.741... logprob:  0.393508, 0.101562 (1.444 sec)
38.742... logprob:  0.419661, 0.109375 (1.487 sec)
38.743... logprob:  0.364931, 0.085938 (1.448 sec)
38.744... logprob:  0.519052, 0.148438 (1.438 sec)
38.745... logprob:  0.478096, 0.132812 (1.435 sec)
38.746... logprob:  0.440539, 0.117188 (1.433 sec)
38.747... logprob:  0.425595, 0.109375 (1.423 sec)
38.748... logprob:  0.378233, 0.093750 (1.491 sec)
38.749... logprob:  0.420782, 0.109375 (1.435 sec)
38.750... logprob:  0.512640, 0.140625 (1.448 sec)
38.751... logprob:  0.263877, 0.054688 (1.475 sec)
38.752... logprob:  0.522478, 0.140625 (1.434 sec)
38.753... logprob:  0.441079, 0.117188 (1.442 sec)
38.754... logprob:  0.468074, 0.132812 (1.434 sec)
38.755... logprob:  0.506992, 0.140625 (1.427 sec)
38.756... logprob:  0.440849, 0.117188 (1.438 sec)
38.757... logprob:  0.552615, 0.156250 (1.475 sec)
38.758... logprob:  0.393449, 0.101562 (1.446 sec)
38.759... logprob:  0.459713, 0.125000 (1.454 sec)
38.760... logprob:  0.485677, 0.132812 (1.464 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.51705551147461, 10.0]}, 128)
batch 872: ({'logprob': [66.11952209472656, 19.0]}, 128)
batch 873: ({'logprob': [41.350711822509766, 9.0]}, 128)
batch 874: ({'logprob': [45.79817199707031, 11.0]}, 128)
batch 875: ({'logprob': [51.072471618652344, 13.0]}, 128)
batch 876: ({'logprob': [63.720603942871094, 18.0]}, 128)
batch 877: ({'logprob': [46.226776123046875, 11.0]}, 128)
batch 878: ({'logprob': [61.685028076171875, 17.0]}, 128)
batch 879: ({'logprob': [72.65946197509766, 21.0]}, 128)
batch 880: ({'logprob': [51.103179931640625, 13.0]}, 128)
batch 881: ({'logprob': [30.33590316772461, 5.0]}, 128)
batch 882: ({'logprob': [54.78649139404297, 14.0]}, 128)
batch 883: ({'logprob': [61.6519775390625, 17.0]}, 128)
batch 884: ({'logprob': [51.501373291015625, 13.0]}, 128)
batch 885: ({'logprob': [52.331722259521484, 13.0]}, 128)
batch 886: ({'logprob': [62.09565353393555, 17.0]}, 128)

======================Test output======================
logprob:  0.417459, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.953985e-03 [3.062546e-09] 
Layer 'conv1' biases: 5.382010e-07 [5.233301e-11] 
Layer 'conv2' weights[0]: 7.941135e-03 [2.150152e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.906270e-10] 
Layer 'conv3' weights[0]: 7.939322e-03 [1.808921e-09] 
Layer 'conv3' biases: 4.539605e-06 [9.377260e-10] 
Layer 'conv4' weights[0]: 7.971967e-03 [1.786885e-09] 
Layer 'conv4' biases: 9.999988e-01 [7.416713e-09] 
Layer 'conv5' weights[0]: 7.970722e-03 [4.682467e-08] 
Layer 'conv5' biases: 9.999875e-01 [5.006602e-08] 
Layer 'fc6' weights[0]: 7.567190e-03 [3.850924e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.850238e-09] 
Layer 'fc7' weights[0]: 6.643487e-03 [2.218538e-07] 
Layer 'fc7' biases: 9.998487e-01 [2.130537e-07] 
Layer 'fc8' weights[0]: 1.238003e-03 [7.467099e-06] 
Layer 'fc8' biases: 9.624062e-02 [5.072900e-05] 
Train error last 870 batches: 0.435144
-------------------------------------------------------
Not saving because 0.417459 > 0.415628 (37.630: -0.00%)
======================================================= (12.047 sec)
38.761... logprob:  0.417979, 0.109375 (1.453 sec)
38.762... logprob:  0.516145, 0.148438 (1.449 sec)
38.763... logprob:  0.559185, 0.164062 (1.426 sec)
38.764... logprob:  0.503257, 0.140625 (1.431 sec)
38.765... logprob:  0.311234, 0.062500 (1.436 sec)
38.766... logprob:  0.482137, 0.132812 (1.457 sec)
38.767... logprob:  0.370974, 0.085938 (1.463 sec)
38.768... logprob:  0.432595, 0.117188 (1.472 sec)
38.769... logprob:  0.490720, 0.140625 (1.467 sec)
38.770... logprob:  0.403120, 0.101562 (1.492 sec)
38.771... logprob:  0.549160, 0.156250 (1.460 sec)
38.772... logprob:  0.414173, 0.109375 (1.443 sec)
38.773... logprob:  0.557252, 0.164062 (1.450 sec)
38.774... logprob:  0.362036, 0.085938 (1.462 sec)
38.775... logprob:  0.407482, 0.101562 (1.463 sec)
38.776... logprob:  0.433084, 0.117188 (1.515 sec)
38.777... logprob:  0.380055, 0.093750 (1.474 sec)
38.778... logprob:  0.433472, 0.117188 (1.466 sec)
38.779... logprob:  0.505176, 0.140625 (1.488 sec)
38.780... logprob:  0.385766, 0.101562 (1.458 sec)
38.781... logprob:  0.369583, 0.085938 (1.452 sec)
38.782... logprob:  0.351345, 0.085938 (1.453 sec)
38.783... logprob:  0.555566, 0.156250 (1.465 sec)
38.784... logprob:  0.440965, 0.117188 (1.455 sec)
38.785... logprob:  0.543889, 0.156250 (1.489 sec)
38.786... logprob:  0.477693, 0.132812 (1.473 sec)
38.787... logprob:  0.546798, 0.156250 (1.459 sec)
38.788... logprob:  0.563633, 0.164062 (1.498 sec)
38.789... logprob:  0.279956, 0.054688 (1.454 sec)
38.790... logprob:  0.407571, 0.101562 (1.450 sec)
38.791... logprob:  0.397579, 0.101562 (1.449 sec)
38.792... logprob:  0.360591, 0.085938 (1.462 sec)
38.793... logprob:  0.369847, 0.085938 (1.456 sec)
38.794... logprob:  0.387095, 0.093750 (1.487 sec)
38.795... logprob:  0.469641, 0.125000 (1.473 sec)
38.796... logprob:  0.423526, 0.109375 (1.455 sec)
38.797... logprob:  0.359051, 0.085938 (1.502 sec)
38.798... logprob:  0.393335, 0.101562 (1.530 sec)
38.799... logprob:  0.332743, 0.078125 (1.451 sec)
38.800... logprob:  0.371641, 0.093750 (1.447 sec)
38.801... logprob:  0.449629, 0.117188 (1.464 sec)
38.802... logprob:  0.422639, 0.109375 (1.452 sec)
38.803... logprob:  0.490944, 0.132812 (1.494 sec)
38.804... logprob:  0.349926, 0.085938 (1.468 sec)
38.805... logprob:  0.452225, 0.117188 (1.453 sec)
38.806... logprob:  0.424154, 0.109375 (1.506 sec)
38.807... logprob:  0.443476, 0.117188 (1.451 sec)
38.808... logprob:  0.462369, 0.125000 (1.454 sec)
38.809... logprob:  0.590037, 0.171875 (1.450 sec)
38.810... logprob:  0.442544, 0.117188 (1.463 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.40570831298828, 10.0]}, 128)
batch 872: ({'logprob': [66.69068908691406, 19.0]}, 128)
batch 873: ({'logprob': [40.61595153808594, 9.0]}, 128)
batch 874: ({'logprob': [45.51585006713867, 11.0]}, 128)
batch 875: ({'logprob': [50.922607421875, 13.0]}, 128)
batch 876: ({'logprob': [64.14607238769531, 18.0]}, 128)
batch 877: ({'logprob': [45.78448486328125, 11.0]}, 128)
batch 878: ({'logprob': [61.80370330810547, 17.0]}, 128)
batch 879: ({'logprob': [72.88853454589844, 21.0]}, 128)
batch 880: ({'logprob': [50.95405578613281, 13.0]}, 128)
batch 881: ({'logprob': [29.49083709716797, 5.0]}, 128)
batch 882: ({'logprob': [54.307552337646484, 14.0]}, 128)
batch 883: ({'logprob': [61.770362854003906, 17.0]}, 128)
batch 884: ({'logprob': [51.1947135925293, 13.0]}, 128)
batch 885: ({'logprob': [51.70661544799805, 13.0]}, 128)
batch 886: ({'logprob': [62.05633544921875, 17.0]}, 128)

======================Test output======================
logprob:  0.416140, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.953942e-03 [5.049063e-09] 
Layer 'conv1' biases: 5.394666e-07 [1.747120e-10] 
Layer 'conv2' weights[0]: 7.941089e-03 [4.747109e-09] 
Layer 'conv2' biases: 1.000000e+00 [8.821239e-10] 
Layer 'conv3' weights[0]: 7.939284e-03 [4.338299e-09] 
Layer 'conv3' biases: 4.550901e-06 [2.582612e-09] 
Layer 'conv4' weights[0]: 7.971925e-03 [4.154922e-09] 
Layer 'conv4' biases: 9.999988e-01 [1.998753e-08] 
Layer 'conv5' weights[0]: 7.970685e-03 [1.217548e-07] 
Layer 'conv5' biases: 9.999875e-01 [1.304237e-07] 
Layer 'fc6' weights[0]: 7.567145e-03 [9.923567e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.007385e-08] 
Layer 'fc7' weights[0]: 6.641780e-03 [3.974384e-07] 
Layer 'fc7' biases: 9.998488e-01 [3.889664e-07] 
Layer 'fc8' weights[0]: 1.251015e-03 [1.438174e-05] 
Layer 'fc8' biases: 9.652412e-02 [9.623205e-05] 
Train error last 870 batches: 0.435144
-------------------------------------------------------
Not saving because 0.416140 > 0.415628 (37.630: -0.00%)
======================================================= (12.029 sec)
38.811... logprob:  0.460437, 0.125000 (1.456 sec)
38.812... logprob:  0.462286, 0.125000 (1.504 sec)
38.813... logprob:  0.485950, 0.132812 (1.461 sec)
38.814... logprob:  0.477755, 0.132812 (1.456 sec)
38.815... logprob:  0.370767, 0.085938 (1.500 sec)
38.816... logprob:  0.408061, 0.101562 (1.454 sec)
38.817... logprob:  0.425552, 0.109375 (1.459 sec)
38.818... logprob:  0.560072, 0.164062 (1.447 sec)
38.819... logprob:  0.498156, 0.140625 (1.458 sec)
38.820... logprob:  0.421752, 0.109375 (1.453 sec)
38.821... logprob:  0.406869, 0.101562 (1.501 sec)
38.822... logprob:  0.441409, 0.117188 (1.457 sec)
38.823... logprob:  0.341603, 0.078125 (1.461 sec)
38.824... logprob:  0.489422, 0.132812 (1.501 sec)
38.825... logprob:  0.289069, 0.062500 (1.454 sec)
38.826... logprob:  0.375783, 0.093750 (1.456 sec)
38.827... logprob:  0.420316, 0.109375 (1.452 sec)
38.828... logprob:  0.442812, 0.117188 (1.453 sec)
38.829... logprob:  0.503123, 0.140625 (1.456 sec)
38.830... logprob:  0.441788, 0.117188 (1.498 sec)
38.831... logprob:  0.513537, 0.140625 (1.456 sec)
38.832... logprob:  0.330854, 0.078125 (1.465 sec)
38.833... logprob:  0.489093, 0.132812 (1.495 sec)
38.834... logprob:  0.433507, 0.117188 (1.456 sec)
38.835... logprob:  0.543213, 0.148438 (1.456 sec)
38.836... logprob:  0.375910, 0.093750 (1.450 sec)
38.837... logprob:  0.313439, 0.070312 (1.454 sec)
38.838... logprob:  0.437070, 0.117188 (1.458 sec)
38.839... logprob:  0.471607, 0.125000 (1.502 sec)
38.840... logprob:  0.555853, 0.156250 (1.455 sec)
38.841... logprob:  0.395760, 0.101562 (1.467 sec)
38.842... logprob:  0.497990, 0.140625 (1.493 sec)
38.843... logprob:  0.465444, 0.125000 (1.455 sec)
38.844... logprob:  0.497730, 0.140625 (1.458 sec)
38.845... logprob:  0.486658, 0.132812 (1.452 sec)
38.846... logprob:  0.468304, 0.125000 (1.453 sec)
38.847... logprob:  0.363555, 0.085938 (1.455 sec)
38.848... logprob:  0.397399, 0.101562 (1.500 sec)
38.849... logprob:  0.360883, 0.085938 (1.490 sec)
38.850... logprob:  0.479330, 0.132812 (1.472 sec)
38.851... logprob:  0.440146, 0.117188 (1.488 sec)
38.852... logprob:  0.544889, 0.156250 (1.448 sec)
38.853... logprob:  0.372237, 0.093750 (1.464 sec)
38.854... logprob:  0.307806, 0.070312 (1.447 sec)
38.855... logprob:  0.484435, 0.132812 (1.449 sec)
38.856... logprob:  0.443556, 0.117188 (1.456 sec)
38.857... logprob:  0.372249, 0.093750 (1.495 sec)
38.858... logprob:  0.396245, 0.101562 (1.461 sec)
38.859... logprob:  0.308076, 0.070312 (1.474 sec)
38.860... logprob:  0.565908, 0.156250 (1.487 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.27092742919922, 10.0]}, 128)
batch 872: ({'logprob': [67.67262268066406, 19.0]}, 128)
batch 873: ({'logprob': [39.70280838012695, 9.0]}, 128)
batch 874: ({'logprob': [44.823509216308594, 11.0]}, 128)
batch 875: ({'logprob': [50.713191986083984, 13.0]}, 128)
batch 876: ({'logprob': [64.95316314697266, 18.0]}, 128)
batch 877: ({'logprob': [45.22227096557617, 11.0]}, 128)
batch 878: ({'logprob': [62.56468200683594, 17.0]}, 128)
batch 879: ({'logprob': [74.75072479248047, 21.0]}, 128)
batch 880: ({'logprob': [50.74552917480469, 13.0]}, 128)
batch 881: ({'logprob': [27.473413467407227, 5.0]}, 128)
batch 882: ({'logprob': [54.67329025268555, 14.0]}, 128)
batch 883: ({'logprob': [62.53065490722656, 17.0]}, 128)
batch 884: ({'logprob': [51.12186813354492, 13.0]}, 128)
batch 885: ({'logprob': [51.8974609375, 13.0]}, 128)
batch 886: ({'logprob': [62.951515197753906, 17.0]}, 128)

======================Test output======================
logprob:  0.416537, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.953911e-03 [5.091758e-09] 
Layer 'conv1' biases: 5.406602e-07 [1.398605e-10] 
Layer 'conv2' weights[0]: 7.941047e-03 [3.680606e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.305985e-10] 
Layer 'conv3' weights[0]: 7.939247e-03 [3.367665e-09] 
Layer 'conv3' biases: 4.556922e-06 [2.190740e-09] 
Layer 'conv4' weights[0]: 7.971894e-03 [3.310431e-09] 
Layer 'conv4' biases: 9.999989e-01 [1.790472e-08] 
Layer 'conv5' weights[0]: 7.970644e-03 [1.132408e-07] 
Layer 'conv5' biases: 9.999868e-01 [1.211012e-07] 
Layer 'fc6' weights[0]: 7.567098e-03 [9.239527e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.364260e-09] 
Layer 'fc7' weights[0]: 6.640018e-03 [3.441571e-08] 
Layer 'fc7' biases: 9.998502e-01 [7.920867e-09] 
Layer 'fc8' weights[0]: 1.285404e-03 [4.857432e-07] 
Layer 'fc8' biases: 9.701970e-02 [2.087010e-06] 
Train error last 870 batches: 0.435144
-------------------------------------------------------
Not saving because 0.416537 > 0.415628 (37.630: -0.00%)
======================================================= (12.107 sec)
38.861... logprob:  0.417776, 0.109375 (1.461 sec)
38.862... logprob:  0.328762, 0.078125 (1.467 sec)
38.863... logprob:  0.399628, 0.101562 (1.445 sec)
38.864... logprob:  0.451587, 0.117188 (1.449 sec)
38.865... logprob:  0.484823, 0.132812 (1.459 sec)
38.866... logprob:  0.508080, 0.140625 (1.487 sec)
38.867... logprob:  0.503481, 0.140625 (1.474 sec)
38.868... logprob:  0.405061, 0.101562 (1.478 sec)
38.869... logprob:  0.382819, 0.093750 (1.478 sec)
38.870... logprob:  0.552553, 0.156250 (1.400 sec)
39.1... logprob:  0.379632, 0.093750 (1.407 sec)
39.2... logprob:  0.448203, 0.117188 (1.447 sec)
39.3... logprob:  0.398077, 0.101562 (1.417 sec)
39.4... logprob:  0.443230, 0.117188 (1.407 sec)
39.5... logprob:  0.443518, 0.117188 (1.437 sec)
39.6... logprob:  0.498948, 0.140625 (1.398 sec)
39.7... logprob:  0.363501, 0.085938 (1.427 sec)
39.8... logprob:  0.419226, 0.109375 (1.400 sec)
39.9... logprob:  0.359177, 0.085938 (1.401 sec)
39.10... logprob:  0.377823, 0.093750 (1.408 sec)
39.11... logprob:  0.335291, 0.078125 (1.442 sec)
39.12... logprob:  0.466032, 0.125000 (1.422 sec)
39.13... logprob:  0.441942, 0.117188 (1.425 sec)
39.14... logprob:  0.444278, 0.117188 (1.404 sec)
39.15... logprob:  0.395366, 0.101562 (1.415 sec)
39.16... logprob:  0.421238, 0.109375 (1.405 sec)
39.17... logprob:  0.515726, 0.140625 (1.400 sec)
39.18... logprob:  0.262182, 0.054688 (1.402 sec)
39.19... logprob:  0.279379, 0.062500 (1.402 sec)
39.20... logprob:  0.421339, 0.109375 (1.404 sec)
39.21... logprob:  0.444017, 0.117188 (1.404 sec)
39.22... logprob:  0.536974, 0.148438 (1.415 sec)
39.23... logprob:  0.533490, 0.148438 (1.414 sec)
39.24... logprob:  0.310199, 0.070312 (1.423 sec)
39.25... logprob:  0.355931, 0.085938 (1.408 sec)
39.26... logprob:  0.463965, 0.125000 (1.450 sec)
39.27... logprob:  0.404415, 0.101562 (1.397 sec)
39.28... logprob:  0.421825, 0.109375 (1.416 sec)
39.29... logprob:  0.395775, 0.101562 (1.428 sec)
39.30... logprob:  0.373900, 0.093750 (1.424 sec)
39.31... logprob:  0.480053, 0.132812 (1.408 sec)
39.32... logprob:  0.457218, 0.125000 (1.392 sec)
39.33... logprob:  0.460686, 0.125000 (1.454 sec)
39.34... logprob:  0.464448, 0.125000 (1.392 sec)
39.35... logprob:  0.316409, 0.070312 (1.403 sec)
39.36... logprob:  0.475793, 0.132812 (1.406 sec)
39.37... logprob:  0.417596, 0.109375 (1.410 sec)
39.38... logprob:  0.392840, 0.101562 (1.396 sec)
39.39... logprob:  0.631018, 0.187500 (1.436 sec)
39.40... logprob:  0.445547, 0.117188 (1.416 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.3188362121582, 10.0]}, 128)
batch 872: ({'logprob': [66.37344360351562, 19.0]}, 128)
batch 873: ({'logprob': [40.91853332519531, 9.0]}, 128)
batch 874: ({'logprob': [45.56760025024414, 11.0]}, 128)
batch 875: ({'logprob': [50.935630798339844, 13.0]}, 128)
batch 876: ({'logprob': [63.90104293823242, 18.0]}, 128)
batch 877: ({'logprob': [45.94218063354492, 11.0]}, 128)
batch 878: ({'logprob': [61.737632751464844, 17.0]}, 128)
batch 879: ({'logprob': [72.84828186035156, 21.0]}, 128)
batch 880: ({'logprob': [50.966854095458984, 13.0]}, 128)
batch 881: ({'logprob': [29.767292022705078, 5.0]}, 128)
batch 882: ({'logprob': [54.56433868408203, 14.0]}, 128)
batch 883: ({'logprob': [61.704227447509766, 17.0]}, 128)
batch 884: ({'logprob': [51.31252670288086, 13.0]}, 128)
batch 885: ({'logprob': [52.03606414794922, 13.0]}, 128)
batch 886: ({'logprob': [62.095577239990234, 17.0]}, 128)

======================Test output======================
logprob:  0.416499, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.953871e-03 [5.529866e-09] 
Layer 'conv1' biases: 5.418160e-07 [1.311290e-10] 
Layer 'conv2' weights[0]: 7.941016e-03 [3.268906e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.311422e-10] 
Layer 'conv3' weights[0]: 7.939209e-03 [2.584117e-09] 
Layer 'conv3' biases: 4.568600e-06 [1.530141e-09] 
Layer 'conv4' weights[0]: 7.971855e-03 [2.481197e-09] 
Layer 'conv4' biases: 9.999988e-01 [1.048255e-08] 
Layer 'conv5' weights[0]: 7.970612e-03 [6.569426e-08] 
Layer 'conv5' biases: 9.999872e-01 [7.025434e-08] 
Layer 'fc6' weights[0]: 7.567060e-03 [5.334701e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.409351e-09] 
Layer 'fc7' weights[0]: 6.638370e-03 [1.033947e-07] 
Layer 'fc7' biases: 9.998489e-01 [9.102126e-08] 
Layer 'fc8' weights[0]: 1.239203e-03 [6.393055e-06] 
Layer 'fc8' biases: 9.681503e-02 [4.499115e-05] 
Train error last 870 batches: 0.435144
-------------------------------------------------------
Not saving because 0.416499 > 0.415628 (37.630: -0.00%)
======================================================= (12.062 sec)
39.41... logprob:  0.353188, 0.085938 (1.430 sec)
39.42... logprob:  0.392168, 0.101562 (1.431 sec)
39.43... logprob:  0.440053, 0.117188 (1.410 sec)
39.44... logprob:  0.518584, 0.148438 (1.438 sec)
39.45... logprob:  0.381693, 0.093750 (1.394 sec)
39.46... logprob:  0.486024, 0.132812 (1.397 sec)
39.47... logprob:  0.331718, 0.078125 (1.396 sec)
39.48... logprob:  0.498983, 0.140625 (1.423 sec)
39.49... logprob:  0.511080, 0.148438 (1.415 sec)
39.50... logprob:  0.393150, 0.101562 (1.430 sec)
39.51... logprob:  0.490481, 0.140625 (1.415 sec)
39.52... logprob:  0.525803, 0.148438 (1.404 sec)
39.53... logprob:  0.294580, 0.062500 (1.448 sec)
39.54... logprob:  0.403537, 0.109375 (1.395 sec)
39.55... logprob:  0.331598, 0.078125 (1.403 sec)
39.56... logprob:  0.421527, 0.109375 (1.410 sec)
39.57... logprob:  0.572223, 0.164062 (1.430 sec)
39.58... logprob:  0.407355, 0.101562 (1.403 sec)
39.59... logprob:  0.333859, 0.078125 (1.468 sec)
39.60... logprob:  0.618509, 0.179688 (1.425 sec)
39.61... logprob:  0.382732, 0.093750 (1.432 sec)
39.62... logprob:  0.474807, 0.132812 (1.459 sec)
39.63... logprob:  0.397273, 0.101562 (1.442 sec)
39.64... logprob:  0.450382, 0.125000 (1.411 sec)
39.65... logprob:  0.373426, 0.093750 (1.400 sec)
39.66... logprob:  0.354066, 0.085938 (1.447 sec)
39.67... logprob:  0.295451, 0.062500 (1.392 sec)
39.68... logprob:  0.396792, 0.101562 (1.400 sec)
39.69... logprob:  0.496536, 0.140625 (1.425 sec)
39.70... logprob:  0.325943, 0.078125 (1.428 sec)
39.71... logprob:  0.381784, 0.101562 (1.468 sec)
39.72... logprob:  0.493561, 0.132812 (1.407 sec)
39.73... logprob:  0.447606, 0.117188 (1.431 sec)
39.74... logprob:  0.442448, 0.117188 (1.418 sec)
39.75... logprob:  0.380669, 0.093750 (1.418 sec)
39.76... logprob:  0.412019, 0.109375 (1.431 sec)
39.77... logprob:  0.396347, 0.101562 (1.437 sec)
39.78... logprob:  0.493042, 0.140625 (1.455 sec)
39.79... logprob:  0.456504, 0.125000 (1.406 sec)
39.80... logprob:  0.508177, 0.132812 (1.427 sec)
39.81... logprob:  0.416724, 0.109375 (1.420 sec)
39.82... logprob:  0.230774, 0.039062 (1.423 sec)
39.83... logprob:  0.493912, 0.140625 (1.401 sec)
39.84... logprob:  0.468215, 0.125000 (1.474 sec)
39.85... logprob:  0.431845, 0.117188 (1.424 sec)
39.86... logprob:  0.416875, 0.109375 (1.419 sec)
39.87... logprob:  0.633432, 0.187500 (1.418 sec)
39.88... logprob:  0.534975, 0.156250 (1.409 sec)
39.89... logprob:  0.410470, 0.109375 (1.437 sec)
39.90... logprob:  0.577483, 0.171875 (1.393 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.08286666870117, 10.0]}, 128)
batch 872: ({'logprob': [65.7940673828125, 19.0]}, 128)
batch 873: ({'logprob': [42.30754852294922, 9.0]}, 128)
batch 874: ({'logprob': [46.396175384521484, 11.0]}, 128)
batch 875: ({'logprob': [51.483638763427734, 13.0]}, 128)
batch 876: ({'logprob': [63.530853271484375, 18.0]}, 128)
batch 877: ({'logprob': [46.910888671875, 11.0]}, 128)
batch 878: ({'logprob': [61.71824645996094, 17.0]}, 128)
batch 879: ({'logprob': [72.39954376220703, 21.0]}, 128)
batch 880: ({'logprob': [51.51338577270508, 13.0]}, 128)
batch 881: ({'logprob': [31.58654022216797, 5.0]}, 128)
batch 882: ({'logprob': [55.31378173828125, 14.0]}, 128)
batch 883: ({'logprob': [61.68586730957031, 17.0]}, 128)
batch 884: ({'logprob': [51.99461364746094, 13.0]}, 128)
batch 885: ({'logprob': [52.995182037353516, 13.0]}, 128)
batch 886: ({'logprob': [62.21263885498047, 17.0]}, 128)

======================Test output======================
logprob:  0.420374, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.953836e-03 [4.415150e-09] 
Layer 'conv1' biases: 5.429891e-07 [1.261917e-10] 
Layer 'conv2' weights[0]: 7.940979e-03 [3.617004e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.629028e-10] 
Layer 'conv3' weights[0]: 7.939174e-03 [3.043288e-09] 
Layer 'conv3' biases: 4.578224e-06 [1.976965e-09] 
Layer 'conv4' weights[0]: 7.971819e-03 [2.983948e-09] 
Layer 'conv4' biases: 9.999988e-01 [1.494004e-08] 
Layer 'conv5' weights[0]: 7.970588e-03 [9.031714e-08] 
Layer 'conv5' biases: 9.999875e-01 [9.666904e-08] 
Layer 'fc6' weights[0]: 7.567020e-03 [7.313552e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.442950e-09] 
Layer 'fc7' weights[0]: 6.636662e-03 [2.461701e-07] 
Layer 'fc7' biases: 9.998484e-01 [2.379895e-07] 
Layer 'fc8' weights[0]: 1.214220e-03 [9.063656e-06] 
Layer 'fc8' biases: 9.665604e-02 [6.386400e-05] 
Train error last 870 batches: 0.435144
-------------------------------------------------------
Not saving because 0.420374 > 0.415628 (37.630: -0.00%)
======================================================= (12.026 sec)
39.91... logprob:  0.348307, 0.078125 (1.408 sec)
39.92... logprob:  0.464456, 0.125000 (1.410 sec)
39.93... logprob:  0.492155, 0.140625 (1.406 sec)
39.94... logprob:  0.428791, 0.109375 (1.400 sec)
39.95... logprob:  0.471825, 0.125000 (1.410 sec)
39.96... logprob:  0.576044, 0.171875 (1.414 sec)
39.97... logprob:  0.430821, 0.117188 (1.403 sec)
39.98... logprob:  0.391372, 0.093750 (1.448 sec)
39.99... logprob:  0.474149, 0.132812 (1.415 sec)
39.100... logprob:  0.310866, 0.070312 (1.406 sec)
39.101... logprob:  0.311288, 0.062500 (1.449 sec)
39.102... logprob:  0.545530, 0.156250 (1.398 sec)
39.103... logprob:  0.540535, 0.156250 (1.400 sec)
39.104... logprob:  0.388773, 0.101562 (1.402 sec)
39.105... logprob:  0.618799, 0.179688 (1.399 sec)
39.106... logprob:  0.344505, 0.085938 (1.401 sec)
39.107... logprob:  0.335888, 0.078125 (1.440 sec)
39.108... logprob:  0.586856, 0.171875 (1.401 sec)
39.109... logprob:  0.336077, 0.078125 (1.413 sec)
39.110... logprob:  0.564842, 0.164062 (1.402 sec)
39.111... logprob:  0.404620, 0.101562 (1.396 sec)
39.112... logprob:  0.365823, 0.093750 (1.403 sec)
39.113... logprob:  0.354207, 0.085938 (1.404 sec)
39.114... logprob:  0.440202, 0.117188 (1.440 sec)
39.115... logprob:  0.506866, 0.140625 (1.420 sec)
39.116... logprob:  0.393282, 0.101562 (1.402 sec)
39.117... logprob:  0.440396, 0.117188 (1.443 sec)
39.118... logprob:  0.409025, 0.101562 (1.403 sec)
39.119... logprob:  0.346010, 0.085938 (1.408 sec)
39.120... logprob:  0.547138, 0.156250 (1.405 sec)
39.121... logprob:  0.412541, 0.109375 (1.422 sec)
39.122... logprob:  0.519190, 0.148438 (1.450 sec)
39.123... logprob:  0.463619, 0.125000 (1.397 sec)
39.124... logprob:  0.447676, 0.125000 (1.405 sec)
39.125... logprob:  0.501845, 0.140625 (1.402 sec)
39.126... logprob:  0.475675, 0.125000 (1.397 sec)
39.127... logprob:  0.479399, 0.125000 (1.405 sec)
39.128... logprob:  0.422301, 0.109375 (1.426 sec)
39.129... logprob:  0.574870, 0.164062 (1.424 sec)
39.130... logprob:  0.382669, 0.093750 (1.420 sec)
39.131... logprob:  0.495496, 0.132812 (1.410 sec)
39.132... logprob:  0.506347, 0.140625 (1.435 sec)
39.133... logprob:  0.444709, 0.117188 (1.394 sec)
39.134... logprob:  0.401848, 0.101562 (1.405 sec)
39.135... logprob:  0.460150, 0.125000 (1.409 sec)
39.136... logprob:  0.562224, 0.164062 (1.402 sec)
39.137... logprob:  0.462609, 0.125000 (1.400 sec)
39.138... logprob:  0.319474, 0.070312 (1.452 sec)
39.139... logprob:  0.395706, 0.101562 (1.402 sec)
39.140... logprob:  0.559718, 0.164062 (1.420 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.48762893676758, 10.0]}, 128)
batch 872: ({'logprob': [66.61971282958984, 19.0]}, 128)
batch 873: ({'logprob': [40.723995208740234, 9.0]}, 128)
batch 874: ({'logprob': [45.5850715637207, 11.0]}, 128)
batch 875: ({'logprob': [50.95811462402344, 13.0]}, 128)
batch 876: ({'logprob': [64.0936508178711, 18.0]}, 128)
batch 877: ({'logprob': [45.85658645629883, 11.0]}, 128)
batch 878: ({'logprob': [61.77244186401367, 17.0]}, 128)
batch 879: ({'logprob': [72.79268646240234, 21.0]}, 128)
batch 880: ({'logprob': [50.98997116088867, 13.0]}, 128)
batch 881: ({'logprob': [29.663679122924805, 5.0]}, 128)
batch 882: ({'logprob': [54.333248138427734, 14.0]}, 128)
batch 883: ({'logprob': [61.73849105834961, 17.0]}, 128)
batch 884: ({'logprob': [51.23306655883789, 13.0]}, 128)
batch 885: ({'logprob': [51.750492095947266, 13.0]}, 128)
batch 886: ({'logprob': [62.027610778808594, 17.0]}, 128)

======================Test output======================
logprob:  0.416322, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.953797e-03 [3.837968e-09] 
Layer 'conv1' biases: 5.439483e-07 [6.007120e-11] 
Layer 'conv2' weights[0]: 7.940938e-03 [2.363422e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.315558e-10] 
Layer 'conv3' weights[0]: 7.939130e-03 [1.729383e-09] 
Layer 'conv3' biases: 4.583809e-06 [9.358538e-10] 
Layer 'conv4' weights[0]: 7.971787e-03 [1.641511e-09] 
Layer 'conv4' biases: 9.999988e-01 [6.185489e-09] 
Layer 'conv5' weights[0]: 7.970538e-03 [2.796467e-08] 
Layer 'conv5' biases: 9.999870e-01 [2.897569e-08] 
Layer 'fc6' weights[0]: 7.566981e-03 [2.419205e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.295509e-09] 
Layer 'fc7' weights[0]: 6.634954e-03 [1.120370e-07] 
Layer 'fc7' biases: 9.998488e-01 [9.909684e-08] 
Layer 'fc8' weights[0]: 1.244191e-03 [3.828936e-06] 
Layer 'fc8' biases: 9.700270e-02 [2.916757e-05] 
Train error last 870 batches: 0.435143
-------------------------------------------------------
Not saving because 0.416322 > 0.415628 (37.630: -0.00%)
======================================================= (12.054 sec)
39.141... logprob:  0.464618, 0.125000 (1.442 sec)
39.142... logprob:  0.464667, 0.125000 (1.405 sec)
39.143... logprob:  0.294567, 0.062500 (1.426 sec)
39.144... logprob:  0.456841, 0.125000 (1.415 sec)
39.145... logprob:  0.324608, 0.078125 (1.419 sec)
39.146... logprob:  0.482954, 0.132812 (1.413 sec)
39.147... logprob:  0.262510, 0.054688 (1.432 sec)
39.148... logprob:  0.458442, 0.125000 (1.395 sec)
39.149... logprob:  0.442450, 0.117188 (1.405 sec)
39.150... logprob:  0.347537, 0.085938 (1.408 sec)
39.151... logprob:  0.347124, 0.085938 (1.401 sec)
39.152... logprob:  0.785202, 0.234375 (1.397 sec)
39.153... logprob:  0.381624, 0.093750 (1.451 sec)
39.154... logprob:  0.524928, 0.148438 (1.408 sec)
39.155... logprob:  0.426215, 0.117188 (1.451 sec)
39.156... logprob:  0.294715, 0.062500 (1.446 sec)
39.157... logprob:  0.269592, 0.054688 (1.405 sec)
39.158... logprob:  0.455504, 0.125000 (1.409 sec)
39.159... logprob:  0.483152, 0.132812 (1.399 sec)
39.160... logprob:  0.444590, 0.117188 (1.397 sec)
39.161... logprob:  0.349347, 0.078125 (1.409 sec)
39.162... logprob:  0.611815, 0.179688 (1.413 sec)
39.163... logprob:  0.450544, 0.125000 (1.432 sec)
39.164... logprob:  0.468405, 0.125000 (1.427 sec)
39.165... logprob:  0.547638, 0.156250 (1.424 sec)
39.166... logprob:  0.446236, 0.125000 (1.455 sec)
39.167... logprob:  0.350755, 0.085938 (1.439 sec)
39.168... logprob:  0.363800, 0.085938 (1.423 sec)
39.169... logprob:  0.408586, 0.101562 (1.463 sec)
39.170... logprob:  0.459442, 0.125000 (1.402 sec)
39.171... logprob:  0.535058, 0.156250 (1.421 sec)
39.172... logprob:  0.434744, 0.109375 (1.415 sec)
39.173... logprob:  0.440448, 0.117188 (1.428 sec)
39.174... logprob:  0.600324, 0.171875 (1.421 sec)
39.175... logprob:  0.505803, 0.140625 (1.475 sec)
39.176... logprob:  0.478339, 0.132812 (1.421 sec)
39.177... logprob:  0.289724, 0.054688 (1.434 sec)
39.178... logprob:  0.383479, 0.093750 (1.457 sec)
39.179... logprob:  0.394631, 0.101562 (1.414 sec)
39.180... logprob:  0.466399, 0.125000 (1.428 sec)
39.181... logprob:  0.539182, 0.156250 (1.417 sec)
39.182... logprob:  0.371196, 0.093750 (1.419 sec)
39.183... logprob:  0.419916, 0.109375 (1.419 sec)
39.184... logprob:  0.483416, 0.132812 (1.423 sec)
39.185... logprob:  0.289658, 0.062500 (1.396 sec)
39.186... logprob:  0.370244, 0.093750 (1.408 sec)
39.187... logprob:  0.529616, 0.148438 (1.404 sec)
39.188... logprob:  0.458784, 0.125000 (1.398 sec)
39.189... logprob:  0.440934, 0.117188 (1.389 sec)
39.190... logprob:  0.375815, 0.093750 (1.441 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.64942169189453, 10.0]}, 128)
batch 872: ({'logprob': [67.00834655761719, 19.0]}, 128)
batch 873: ({'logprob': [40.12767028808594, 9.0]}, 128)
batch 874: ({'logprob': [45.05435562133789, 11.0]}, 128)
batch 875: ({'logprob': [50.711029052734375, 13.0]}, 128)
batch 876: ({'logprob': [64.3956527709961, 18.0]}, 128)
batch 877: ({'logprob': [45.43434524536133, 11.0]}, 128)
batch 878: ({'logprob': [62.095149993896484, 17.0]}, 128)
batch 879: ({'logprob': [73.79316711425781, 21.0]}, 128)
batch 880: ({'logprob': [50.74349594116211, 13.0]}, 128)
batch 881: ({'logprob': [28.387109756469727, 5.0]}, 128)
batch 882: ({'logprob': [54.50352096557617, 14.0]}, 128)
batch 883: ({'logprob': [62.06062316894531, 17.0]}, 128)
batch 884: ({'logprob': [51.09806442260742, 13.0]}, 128)
batch 885: ({'logprob': [51.83376693725586, 13.0]}, 128)
batch 886: ({'logprob': [62.460914611816406, 17.0]}, 128)

======================Test output======================
logprob:  0.415701, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.953753e-03 [3.133085e-09] 
Layer 'conv1' biases: 5.451643e-07 [5.422091e-11] 
Layer 'conv2' weights[0]: 7.940907e-03 [1.885108e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.553883e-10] 
Layer 'conv3' weights[0]: 7.939089e-03 [1.318139e-09] 
Layer 'conv3' biases: 4.595050e-06 [3.805172e-10] 
Layer 'conv4' weights[0]: 7.971755e-03 [1.244453e-09] 
Layer 'conv4' biases: 9.999988e-01 [5.602470e-10] 
Layer 'conv5' weights[0]: 7.970493e-03 [2.733582e-09] 
Layer 'conv5' biases: 9.999870e-01 [2.363001e-09] 
Layer 'fc6' weights[0]: 7.566939e-03 [7.802287e-10] 
Layer 'fc6' biases: 1.000000e+00 [1.926383e-10] 
Layer 'fc7' weights[0]: 6.633270e-03 [3.356128e-08] 
Layer 'fc7' biases: 9.998494e-01 [4.460535e-09] 
Layer 'fc8' weights[0]: 1.272497e-03 [6.307206e-07] 
Layer 'fc8' biases: 9.731251e-02 [3.928276e-06] 
Train error last 870 batches: 0.435143
-------------------------------------------------------
Not saving because 0.415701 > 0.415628 (37.630: -0.00%)
======================================================= (12.223 sec)
39.191... logprob:  0.485103, 0.132812 (1.419 sec)
39.192... logprob:  0.519949, 0.148438 (1.427 sec)
39.193... logprob:  0.312388, 0.070312 (1.427 sec)
39.194... logprob:  0.414001, 0.109375 (1.419 sec)
39.195... logprob:  0.286863, 0.062500 (1.407 sec)
39.196... logprob:  0.410390, 0.109375 (1.398 sec)
39.197... logprob:  0.477958, 0.132812 (1.400 sec)
39.198... logprob:  0.355799, 0.085938 (1.410 sec)
39.199... logprob:  0.437195, 0.117188 (1.395 sec)
39.200... logprob:  0.440703, 0.117188 (1.443 sec)
39.201... logprob:  0.437082, 0.117188 (1.415 sec)
39.202... logprob:  0.537747, 0.148438 (1.412 sec)
39.203... logprob:  0.420374, 0.109375 (1.452 sec)
39.204... logprob:  0.504124, 0.140625 (1.398 sec)
39.205... logprob:  0.334206, 0.078125 (1.411 sec)
39.206... logprob:  0.361643, 0.093750 (1.412 sec)
39.207... logprob:  0.381673, 0.093750 (1.400 sec)
39.208... logprob:  0.490636, 0.140625 (1.399 sec)
39.209... logprob:  0.334498, 0.078125 (1.422 sec)
39.210... logprob:  0.586215, 0.171875 (1.418 sec)
39.211... logprob:  0.488074, 0.132812 (1.420 sec)
39.212... logprob:  0.526093, 0.148438 (1.416 sec)
39.213... logprob:  0.514490, 0.140625 (1.461 sec)
39.214... logprob:  0.459363, 0.125000 (1.430 sec)
39.215... logprob:  0.396045, 0.101562 (1.425 sec)
39.216... logprob:  0.516784, 0.140625 (1.465 sec)
39.217... logprob:  0.324673, 0.070312 (1.409 sec)
39.218... logprob:  0.463511, 0.125000 (1.431 sec)
39.219... logprob:  0.500180, 0.140625 (1.414 sec)
39.220... logprob:  0.415049, 0.109375 (1.425 sec)
39.221... logprob:  0.399595, 0.101562 (1.412 sec)
39.222... logprob:  0.554283, 0.164062 (1.456 sec)
39.223... logprob:  0.568729, 0.164062 (1.430 sec)
39.224... logprob:  0.406058, 0.101562 (1.449 sec)
39.225... logprob:  0.392044, 0.101562 (1.445 sec)
39.226... logprob:  0.424828, 0.109375 (1.424 sec)
39.227... logprob:  0.452554, 0.125000 (1.428 sec)
39.228... logprob:  0.417160, 0.109375 (1.417 sec)
39.229... logprob:  0.489369, 0.132812 (1.416 sec)
39.230... logprob:  0.459816, 0.125000 (1.453 sec)
39.231... logprob:  0.453442, 0.125000 (1.416 sec)
39.232... logprob:  0.496101, 0.140625 (1.466 sec)
39.233... logprob:  0.465979, 0.132812 (1.429 sec)
39.234... logprob:  0.563913, 0.164062 (1.418 sec)
39.235... logprob:  0.482005, 0.132812 (1.471 sec)
39.236... logprob:  0.425544, 0.109375 (1.412 sec)
39.237... logprob:  0.340638, 0.078125 (1.433 sec)
39.238... logprob:  0.388911, 0.093750 (1.421 sec)
39.239... logprob:  0.478055, 0.132812 (1.422 sec)
39.240... logprob:  0.485793, 0.132812 (1.407 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.30218505859375, 10.0]}, 128)
batch 872: ({'logprob': [66.07441711425781, 19.0]}, 128)
batch 873: ({'logprob': [41.338687896728516, 9.0]}, 128)
batch 874: ({'logprob': [45.70229721069336, 11.0]}, 128)
batch 875: ({'logprob': [51.02143859863281, 13.0]}, 128)
batch 876: ({'logprob': [63.68571853637695, 18.0]}, 128)
batch 877: ({'logprob': [46.19533920288086, 11.0]}, 128)
batch 878: ({'logprob': [61.72414016723633, 17.0]}, 128)
batch 879: ({'logprob': [72.85163879394531, 21.0]}, 128)
batch 880: ({'logprob': [51.052574157714844, 13.0]}, 128)
batch 881: ({'logprob': [30.169769287109375, 5.0]}, 128)
batch 882: ({'logprob': [54.91885757446289, 14.0]}, 128)
batch 883: ({'logprob': [61.69050979614258, 17.0]}, 128)
batch 884: ({'logprob': [51.51502990722656, 13.0]}, 128)
batch 885: ({'logprob': [52.473758697509766, 13.0]}, 128)
batch 886: ({'logprob': [62.19913101196289, 17.0]}, 128)

======================Test output======================
logprob:  0.417439, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.953716e-03 [3.124424e-09] 
Layer 'conv1' biases: 5.462199e-07 [6.279919e-11] 
Layer 'conv2' weights[0]: 7.940868e-03 [1.836218e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.827662e-10] 
Layer 'conv3' weights[0]: 7.939044e-03 [1.341847e-09] 
Layer 'conv3' biases: 4.605243e-06 [4.953693e-10] 
Layer 'conv4' weights[0]: 7.971721e-03 [1.220286e-09] 
Layer 'conv4' biases: 9.999988e-01 [2.317988e-09] 
Layer 'conv5' weights[0]: 7.970453e-03 [1.009137e-08] 
Layer 'conv5' biases: 9.999871e-01 [1.022267e-08] 
Layer 'fc6' weights[0]: 7.566898e-03 [1.109045e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.781667e-10] 
Layer 'fc7' weights[0]: 6.631552e-03 [6.450589e-08] 
Layer 'fc7' biases: 9.998485e-01 [4.824407e-08] 
Layer 'fc8' weights[0]: 1.242694e-03 [1.988968e-06] 
Layer 'fc8' biases: 9.713104e-02 [1.547529e-05] 
Train error last 870 batches: 0.435143
-------------------------------------------------------
Not saving because 0.417439 > 0.415628 (37.630: -0.00%)
======================================================= (12.144 sec)
39.241... logprob:  0.493608, 0.132812 (1.474 sec)
39.242... logprob:  0.341599, 0.078125 (1.438 sec)
39.243... logprob:  0.385976, 0.093750 (1.435 sec)
39.244... logprob:  0.315542, 0.070312 (1.453 sec)
39.245... logprob:  0.494123, 0.132812 (1.429 sec)
39.246... logprob:  0.416809, 0.109375 (1.427 sec)
39.247... logprob:  0.357741, 0.085938 (1.424 sec)
39.248... logprob:  0.308290, 0.070312 (1.423 sec)
39.249... logprob:  0.553935, 0.156250 (1.428 sec)
39.250... logprob:  0.590760, 0.164062 (1.413 sec)
39.251... logprob:  0.353062, 0.085938 (1.457 sec)
39.252... logprob:  0.348400, 0.085938 (1.431 sec)
39.253... logprob:  0.379273, 0.093750 (1.415 sec)
39.254... logprob:  0.444139, 0.117188 (1.468 sec)
39.255... logprob:  0.351220, 0.085938 (1.407 sec)
39.256... logprob:  0.378955, 0.093750 (1.423 sec)
39.257... logprob:  0.331928, 0.078125 (1.416 sec)
39.258... logprob:  0.415342, 0.109375 (1.422 sec)
39.259... logprob:  0.442322, 0.117188 (1.404 sec)
39.260... logprob:  0.308048, 0.070312 (1.459 sec)
39.261... logprob:  0.392374, 0.101562 (1.437 sec)
39.262... logprob:  0.524386, 0.148438 (1.432 sec)
39.263... logprob:  0.425700, 0.109375 (1.448 sec)
39.264... logprob:  0.374932, 0.093750 (1.425 sec)
39.265... logprob:  0.439608, 0.117188 (1.420 sec)
39.266... logprob:  0.438995, 0.117188 (1.423 sec)
39.267... logprob:  0.422065, 0.109375 (1.418 sec)
39.268... logprob:  0.458947, 0.125000 (1.424 sec)
39.269... logprob:  0.567681, 0.164062 (1.411 sec)
39.270... logprob:  0.542445, 0.156250 (1.466 sec)
39.271... logprob:  0.445497, 0.117188 (1.435 sec)
39.272... logprob:  0.384400, 0.093750 (1.417 sec)
39.273... logprob:  0.500250, 0.140625 (1.471 sec)
39.274... logprob:  0.542495, 0.156250 (1.409 sec)
39.275... logprob:  0.487462, 0.132812 (1.425 sec)
39.276... logprob:  0.389877, 0.093750 (1.419 sec)
39.277... logprob:  0.428514, 0.109375 (1.431 sec)
39.278... logprob:  0.323780, 0.070312 (1.422 sec)
39.279... logprob:  0.325524, 0.070312 (1.468 sec)
39.280... logprob:  0.216664, 0.031250 (1.414 sec)
39.281... logprob:  0.417301, 0.109375 (1.433 sec)
39.282... logprob:  0.411235, 0.109375 (1.426 sec)
39.283... logprob:  0.393652, 0.101562 (1.416 sec)
39.284... logprob:  0.394154, 0.101562 (1.415 sec)
39.285... logprob:  0.450830, 0.117188 (1.447 sec)
39.286... logprob:  0.535343, 0.140625 (1.512 sec)
39.287... logprob:  0.346426, 0.085938 (1.437 sec)
39.288... logprob:  0.329922, 0.078125 (1.447 sec)
39.289... logprob:  0.445604, 0.117188 (1.448 sec)
39.290... logprob:  0.490608, 0.132812 (1.409 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.971248626708984, 10.0]}, 128)
batch 872: ({'logprob': [68.64741516113281, 19.0]}, 128)
batch 873: ({'logprob': [39.41193389892578, 9.0]}, 128)
batch 874: ({'logprob': [44.73389434814453, 11.0]}, 128)
batch 875: ({'logprob': [50.91008377075195, 13.0]}, 128)
batch 876: ({'logprob': [65.80712127685547, 18.0]}, 128)
batch 877: ({'logprob': [45.17518997192383, 11.0]}, 128)
batch 878: ({'logprob': [63.33852005004883, 17.0]}, 128)
batch 879: ({'logprob': [76.14337158203125, 21.0]}, 128)
batch 880: ({'logprob': [50.943599700927734, 13.0]}, 128)
batch 881: ({'logprob': [26.561756134033203, 5.0]}, 128)
batch 882: ({'logprob': [55.124446868896484, 14.0]}, 128)
batch 883: ({'logprob': [63.30338668823242, 17.0]}, 128)
batch 884: ({'logprob': [51.36529541015625, 13.0]}, 128)
batch 885: ({'logprob': [52.22671890258789, 13.0]}, 128)
batch 886: ({'logprob': [63.769927978515625, 17.0]}, 128)

======================Test output======================
logprob:  0.419157, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.953674e-03 [7.055849e-09] 
Layer 'conv1' biases: 5.474698e-07 [2.463174e-10] 
Layer 'conv2' weights[0]: 7.940830e-03 [5.875247e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.261967e-09] 
Layer 'conv3' weights[0]: 7.939005e-03 [5.481027e-09] 
Layer 'conv3' biases: 4.612799e-06 [3.605376e-09] 
Layer 'conv4' weights[0]: 7.971681e-03 [5.313292e-09] 
Layer 'conv4' biases: 9.999987e-01 [2.885143e-08] 
Layer 'conv5' weights[0]: 7.970420e-03 [1.755744e-07] 
Layer 'conv5' biases: 9.999868e-01 [1.876963e-07] 
Layer 'fc6' weights[0]: 7.566858e-03 [1.430106e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.460886e-08] 
Layer 'fc7' weights[0]: 6.629902e-03 [2.363623e-07] 
Layer 'fc7' biases: 9.998506e-01 [2.278128e-07] 
Layer 'fc8' weights[0]: 1.317668e-03 [9.233094e-06] 
Layer 'fc8' biases: 9.788628e-02 [5.219774e-05] 
Train error last 870 batches: 0.435143
-------------------------------------------------------
Not saving because 0.419157 > 0.415628 (37.630: -0.00%)
======================================================= (12.048 sec)
39.291... logprob:  0.439433, 0.117188 (1.425 sec)
39.292... logprob:  0.568175, 0.156250 (1.428 sec)
39.293... logprob:  0.427974, 0.117188 (1.426 sec)
39.294... logprob:  0.355415, 0.085938 (1.404 sec)
39.295... logprob:  0.333766, 0.078125 (1.470 sec)
39.296... logprob:  0.354937, 0.085938 (1.428 sec)
39.297... logprob:  0.394024, 0.101562 (1.437 sec)
39.298... logprob:  0.448373, 0.125000 (1.469 sec)
39.299... logprob:  0.341393, 0.078125 (1.408 sec)
39.300... logprob:  0.406105, 0.101562 (1.426 sec)
39.301... logprob:  0.397799, 0.101562 (1.423 sec)
39.302... logprob:  0.591713, 0.179688 (1.425 sec)
39.303... logprob:  0.459402, 0.125000 (1.421 sec)
39.304... logprob:  0.459560, 0.125000 (1.445 sec)
39.305... logprob:  0.455178, 0.125000 (1.441 sec)
39.306... logprob:  0.440553, 0.117188 (1.436 sec)
39.307... logprob:  0.421643, 0.109375 (1.444 sec)
39.308... logprob:  0.375042, 0.093750 (1.454 sec)
39.309... logprob:  0.450490, 0.125000 (1.421 sec)
39.310... logprob:  0.473441, 0.125000 (1.427 sec)
39.311... logprob:  0.502299, 0.140625 (1.426 sec)
39.312... logprob:  0.478583, 0.132812 (1.439 sec)
39.313... logprob:  0.454847, 0.125000 (1.430 sec)
39.314... logprob:  0.454229, 0.117188 (1.472 sec)
39.315... logprob:  0.314730, 0.070312 (1.437 sec)
39.316... logprob:  0.468451, 0.125000 (1.431 sec)
39.317... logprob:  0.355394, 0.085938 (1.476 sec)
39.318... logprob:  0.455390, 0.125000 (1.420 sec)
39.319... logprob:  0.423139, 0.117188 (1.433 sec)
39.320... logprob:  0.412217, 0.109375 (1.427 sec)
39.321... logprob:  0.348204, 0.085938 (1.428 sec)
39.322... logprob:  0.387382, 0.101562 (1.427 sec)
39.323... logprob:  0.416489, 0.109375 (1.476 sec)
39.324... logprob:  0.498586, 0.140625 (1.429 sec)
39.325... logprob:  0.350662, 0.085938 (1.445 sec)
39.326... logprob:  0.543198, 0.148438 (1.464 sec)
39.327... logprob:  0.554461, 0.164062 (1.433 sec)
39.328... logprob:  0.565254, 0.156250 (1.442 sec)
39.329... logprob:  0.401846, 0.101562 (1.433 sec)
39.330... logprob:  0.388382, 0.101562 (1.424 sec)
39.331... logprob:  0.352038, 0.085938 (1.437 sec)
39.332... logprob:  0.482792, 0.132812 (1.458 sec)
39.333... logprob:  0.339318, 0.085938 (1.446 sec)
39.334... logprob:  0.565447, 0.171875 (1.440 sec)
39.335... logprob:  0.358548, 0.085938 (1.442 sec)
39.336... logprob:  0.444881, 0.125000 (1.458 sec)
39.337... logprob:  0.566360, 0.164062 (1.420 sec)
39.338... logprob:  0.449520, 0.125000 (1.465 sec)
39.339... logprob:  0.488507, 0.132812 (1.435 sec)
39.340... logprob:  0.442056, 0.117188 (1.436 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.34955596923828, 10.0]}, 128)
batch 872: ({'logprob': [65.76591491699219, 19.0]}, 128)
batch 873: ({'logprob': [42.117393493652344, 9.0]}, 128)
batch 874: ({'logprob': [46.021942138671875, 11.0]}, 128)
batch 875: ({'logprob': [51.286033630371094, 13.0]}, 128)
batch 876: ({'logprob': [63.50473403930664, 18.0]}, 128)
batch 877: ({'logprob': [46.71635818481445, 11.0]}, 128)
batch 878: ({'logprob': [61.87385177612305, 17.0]}, 128)
batch 879: ({'logprob': [73.08698272705078, 21.0]}, 128)
batch 880: ({'logprob': [51.31583786010742, 13.0]}, 128)
batch 881: ({'logprob': [30.862478256225586, 5.0]}, 128)
batch 882: ({'logprob': [55.6551628112793, 14.0]}, 128)
batch 883: ({'logprob': [61.841251373291016, 17.0]}, 128)
batch 884: ({'logprob': [51.97824478149414, 13.0]}, 128)
batch 885: ({'logprob': [53.33887481689453, 13.0]}, 128)
batch 886: ({'logprob': [62.5490608215332, 17.0]}, 128)

======================Test output======================
logprob:  0.420051, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.953638e-03 [3.184353e-09] 
Layer 'conv1' biases: 5.484882e-07 [4.777041e-11] 
Layer 'conv2' weights[0]: 7.940789e-03 [2.024405e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.872415e-10] 
Layer 'conv3' weights[0]: 7.938961e-03 [1.504006e-09] 
Layer 'conv3' biases: 4.622933e-06 [5.754673e-10] 
Layer 'conv4' weights[0]: 7.971646e-03 [1.368208e-09] 
Layer 'conv4' biases: 9.999988e-01 [2.933620e-09] 
Layer 'conv5' weights[0]: 7.970374e-03 [1.385658e-08] 
Layer 'conv5' biases: 9.999869e-01 [1.447587e-08] 
Layer 'fc6' weights[0]: 7.566813e-03 [1.388475e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.153387e-09] 
Layer 'fc7' weights[0]: 6.628246e-03 [3.493093e-08] 
Layer 'fc7' biases: 9.998486e-01 [9.044191e-09] 
Layer 'fc8' weights[0]: 1.230410e-03 [1.495727e-06] 
Layer 'fc8' biases: 9.741040e-02 [9.796113e-06] 
Train error last 870 batches: 0.435142
-------------------------------------------------------
Not saving because 0.420051 > 0.415628 (37.630: -0.00%)
======================================================= (12.128 sec)
39.341... logprob:  0.529937, 0.148438 (1.424 sec)
39.342... logprob:  0.429560, 0.109375 (1.478 sec)
39.343... logprob:  0.434757, 0.109375 (1.436 sec)
39.344... logprob:  0.444598, 0.125000 (1.484 sec)
39.345... logprob:  0.488137, 0.132812 (1.439 sec)
39.346... logprob:  0.436194, 0.117188 (1.443 sec)
39.347... logprob:  0.372696, 0.085938 (1.490 sec)
39.348... logprob:  0.398545, 0.101562 (1.433 sec)
39.349... logprob:  0.497401, 0.140625 (1.435 sec)
39.350... logprob:  0.358841, 0.085938 (1.438 sec)
39.351... logprob:  0.508352, 0.140625 (1.430 sec)
39.352... logprob:  0.363588, 0.093750 (1.436 sec)
39.353... logprob:  0.512195, 0.148438 (1.491 sec)
39.354... logprob:  0.674519, 0.203125 (1.430 sec)
39.355... logprob:  0.357528, 0.085938 (1.449 sec)
39.356... logprob:  0.479237, 0.132812 (1.479 sec)
39.357... logprob:  0.346521, 0.085938 (1.431 sec)
39.358... logprob:  0.325562, 0.070312 (1.444 sec)
39.359... logprob:  0.555501, 0.164062 (1.432 sec)
39.360... logprob:  0.444538, 0.117188 (1.431 sec)
39.361... logprob:  0.410702, 0.101562 (1.431 sec)
39.362... logprob:  0.423810, 0.117188 (1.480 sec)
39.363... logprob:  0.486616, 0.132812 (1.441 sec)
39.364... logprob:  0.475678, 0.125000 (1.460 sec)
39.365... logprob:  0.425012, 0.109375 (1.463 sec)
39.366... logprob:  0.409472, 0.109375 (1.447 sec)
39.367... logprob:  0.324811, 0.078125 (1.441 sec)
39.368... logprob:  0.595485, 0.171875 (1.431 sec)
39.369... logprob:  0.381747, 0.093750 (1.428 sec)
39.370... logprob:  0.381389, 0.093750 (1.438 sec)
39.371... logprob:  0.400482, 0.101562 (1.493 sec)
39.372... logprob:  0.536963, 0.156250 (1.458 sec)
39.373... logprob:  0.463760, 0.125000 (1.455 sec)
39.374... logprob:  0.526638, 0.148438 (1.451 sec)
39.375... logprob:  0.393758, 0.101562 (1.468 sec)
39.376... logprob:  0.374283, 0.093750 (1.436 sec)
39.377... logprob:  0.295503, 0.062500 (1.428 sec)
39.378... logprob:  0.453584, 0.125000 (1.433 sec)
39.379... logprob:  0.420254, 0.109375 (1.440 sec)
39.380... logprob:  0.605576, 0.179688 (1.440 sec)
39.381... logprob:  0.463369, 0.125000 (1.472 sec)
39.382... logprob:  0.529633, 0.148438 (1.452 sec)
39.383... logprob:  0.358423, 0.085938 (1.440 sec)
39.384... logprob:  0.521336, 0.148438 (1.482 sec)
39.385... logprob:  0.523678, 0.148438 (1.436 sec)
39.386... logprob:  0.582779, 0.171875 (1.427 sec)
39.387... logprob:  0.428374, 0.117188 (1.439 sec)
39.388... logprob:  0.521441, 0.148438 (1.435 sec)
39.389... logprob:  0.425314, 0.109375 (1.435 sec)
39.390... logprob:  0.419459, 0.109375 (1.479 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.78940200805664, 10.0]}, 128)
batch 872: ({'logprob': [65.84247589111328, 19.0]}, 128)
batch 873: ({'logprob': [42.82829666137695, 9.0]}, 128)
batch 874: ({'logprob': [46.912384033203125, 11.0]}, 128)
batch 875: ({'logprob': [51.84575653076172, 13.0]}, 128)
batch 876: ({'logprob': [63.61905288696289, 18.0]}, 128)
batch 877: ({'logprob': [47.3530158996582, 11.0]}, 128)
batch 878: ({'logprob': [61.77196502685547, 17.0]}, 128)
batch 879: ({'logprob': [72.0694580078125, 21.0]}, 128)
batch 880: ({'logprob': [51.87601089477539, 13.0]}, 128)
batch 881: ({'logprob': [32.4920654296875, 5.0]}, 128)
batch 882: ({'logprob': [55.41099548339844, 14.0]}, 128)
batch 883: ({'logprob': [61.73897171020508, 17.0]}, 128)
batch 884: ({'logprob': [52.28069305419922, 13.0]}, 128)
batch 885: ({'logprob': [53.13136672973633, 13.0]}, 128)
batch 886: ({'logprob': [62.19053649902344, 17.0]}, 128)

======================Test output======================
logprob:  0.422438, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.953602e-03 [3.352230e-09] 
Layer 'conv1' biases: 5.497343e-07 [1.565003e-10] 
Layer 'conv2' weights[0]: 7.940756e-03 [3.297148e-09] 
Layer 'conv2' biases: 1.000000e+00 [7.257210e-10] 
Layer 'conv3' weights[0]: 7.938924e-03 [3.413049e-09] 
Layer 'conv3' biases: 4.634516e-06 [2.125262e-09] 
Layer 'conv4' weights[0]: 7.971607e-03 [3.406243e-09] 
Layer 'conv4' biases: 9.999988e-01 [1.861405e-08] 
Layer 'conv5' weights[0]: 7.970347e-03 [1.169293e-07] 
Layer 'conv5' biases: 9.999875e-01 [1.251778e-07] 
Layer 'fc6' weights[0]: 7.566774e-03 [9.424117e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.546651e-09] 
Layer 'fc7' weights[0]: 6.626554e-03 [3.758090e-08] 
Layer 'fc7' biases: 9.998476e-01 [1.412608e-08] 
Layer 'fc8' weights[0]: 1.209183e-03 [2.348087e-06] 
Layer 'fc8' biases: 9.734057e-02 [1.681681e-05] 
Train error last 870 batches: 0.435142
-------------------------------------------------------
Not saving because 0.422438 > 0.415628 (37.630: -0.00%)
======================================================= (12.083 sec)
39.391... logprob:  0.317920, 0.070312 (1.447 sec)
39.392... logprob:  0.439451, 0.117188 (1.444 sec)
39.393... logprob:  0.369147, 0.093750 (1.483 sec)
39.394... logprob:  0.343864, 0.078125 (1.433 sec)
39.395... logprob:  0.332177, 0.078125 (1.438 sec)
39.396... logprob:  0.253172, 0.046875 (1.437 sec)
39.397... logprob:  0.483621, 0.132812 (1.430 sec)
39.398... logprob:  0.470073, 0.125000 (1.438 sec)
39.399... logprob:  0.432719, 0.117188 (1.489 sec)
39.400... logprob:  0.536498, 0.148438 (1.435 sec)
39.401... logprob:  0.465171, 0.125000 (1.446 sec)
39.402... logprob:  0.473434, 0.125000 (1.480 sec)
39.403... logprob:  0.461949, 0.125000 (1.433 sec)
39.404... logprob:  0.474751, 0.125000 (1.478 sec)
39.405... logprob:  0.544571, 0.156250 (1.437 sec)
39.406... logprob:  0.357275, 0.085938 (1.429 sec)
39.407... logprob:  0.493325, 0.140625 (1.432 sec)
39.408... logprob:  0.338167, 0.078125 (1.479 sec)
39.409... logprob:  0.399944, 0.101562 (1.437 sec)
39.410... logprob:  0.582801, 0.171875 (1.452 sec)
39.411... logprob:  0.397271, 0.101562 (1.474 sec)
39.412... logprob:  0.540445, 0.156250 (1.439 sec)
39.413... logprob:  0.544643, 0.156250 (1.438 sec)
39.414... logprob:  0.466154, 0.125000 (1.435 sec)
39.415... logprob:  0.401475, 0.101562 (1.427 sec)
39.416... logprob:  0.427383, 0.109375 (1.438 sec)
39.417... logprob:  0.405437, 0.093750 (1.464 sec)
39.418... logprob:  0.380743, 0.093750 (1.453 sec)
39.419... logprob:  0.418125, 0.101562 (1.454 sec)
39.420... logprob:  0.356995, 0.085938 (1.460 sec)
39.421... logprob:  0.376810, 0.101562 (1.459 sec)
39.422... logprob:  0.521246, 0.148438 (1.438 sec)
39.423... logprob:  0.420630, 0.109375 (1.430 sec)
39.424... logprob:  0.325220, 0.078125 (1.429 sec)
39.425... logprob:  0.306887, 0.070312 (1.443 sec)
39.426... logprob:  0.448646, 0.117188 (1.445 sec)
39.427... logprob:  0.553086, 0.156250 (1.466 sec)
39.428... logprob:  0.600753, 0.171875 (1.453 sec)
39.429... logprob:  0.426390, 0.109375 (1.444 sec)
39.430... logprob:  0.299636, 0.070312 (1.477 sec)
39.431... logprob:  0.600624, 0.171875 (1.436 sec)
39.432... logprob:  0.387493, 0.093750 (1.429 sec)
39.433... logprob:  0.329095, 0.078125 (1.436 sec)
39.434... logprob:  0.530152, 0.148438 (1.439 sec)
39.435... logprob:  0.532977, 0.156250 (1.434 sec)
39.436... logprob:  0.380377, 0.093750 (1.478 sec)
39.437... logprob:  0.500465, 0.140625 (1.449 sec)
39.438... logprob:  0.547254, 0.156250 (1.432 sec)
39.439... logprob:  0.377983, 0.093750 (1.492 sec)
39.440... logprob:  0.439417, 0.117188 (1.431 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.51160430908203, 10.0]}, 128)
batch 872: ({'logprob': [65.82490539550781, 19.0]}, 128)
batch 873: ({'logprob': [42.591575622558594, 9.0]}, 128)
batch 874: ({'logprob': [46.69525146484375, 11.0]}, 128)
batch 875: ({'logprob': [51.68855285644531, 13.0]}, 128)
batch 876: ({'logprob': [63.581424713134766, 18.0]}, 128)
batch 877: ({'logprob': [47.15574645996094, 11.0]}, 128)
batch 878: ({'logprob': [61.734493255615234, 17.0]}, 128)
batch 879: ({'logprob': [72.17239379882812, 21.0]}, 128)
batch 880: ({'logprob': [51.71855163574219, 13.0]}, 128)
batch 881: ({'logprob': [32.11473083496094, 5.0]}, 128)
batch 882: ({'logprob': [55.33454513549805, 14.0]}, 128)
batch 883: ({'logprob': [61.7018928527832, 17.0]}, 128)
batch 884: ({'logprob': [52.144168853759766, 13.0]}, 128)
batch 885: ({'logprob': [53.035396575927734, 13.0]}, 128)
batch 886: ({'logprob': [62.17366027832031, 17.0]}, 128)

======================Test output======================
logprob:  0.421474, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.953567e-03 [4.361197e-09] 
Layer 'conv1' biases: 5.507095e-07 [1.133476e-10] 
Layer 'conv2' weights[0]: 7.940723e-03 [3.243972e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.889410e-10] 
Layer 'conv3' weights[0]: 7.938883e-03 [2.985398e-09] 
Layer 'conv3' biases: 4.642542e-06 [1.783114e-09] 
Layer 'conv4' weights[0]: 7.971569e-03 [2.975063e-09] 
Layer 'conv4' biases: 9.999988e-01 [1.563665e-08] 
Layer 'conv5' weights[0]: 7.970304e-03 [9.829411e-08] 
Layer 'conv5' biases: 9.999874e-01 [1.051953e-07] 
Layer 'fc6' weights[0]: 7.566732e-03 [7.891607e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.032248e-09] 
Layer 'fc7' weights[0]: 6.624850e-03 [3.954447e-08] 
Layer 'fc7' biases: 9.998479e-01 [1.841878e-08] 
Layer 'fc8' weights[0]: 1.207242e-03 [8.179192e-07] 
Layer 'fc8' biases: 9.773886e-02 [7.820388e-08] 
Train error last 870 batches: 0.435142
-------------------------------------------------------
Not saving because 0.421474 > 0.415628 (37.630: -0.00%)
======================================================= (12.089 sec)
39.441... logprob:  0.467843, 0.125000 (1.439 sec)
39.442... logprob:  0.378847, 0.093750 (1.442 sec)
39.443... logprob:  0.496539, 0.140625 (1.435 sec)
39.444... logprob:  0.372653, 0.093750 (1.434 sec)
39.445... logprob:  0.363032, 0.085938 (1.485 sec)
39.446... logprob:  0.398665, 0.101562 (1.438 sec)
39.447... logprob:  0.568778, 0.164062 (1.441 sec)
39.448... logprob:  0.333520, 0.078125 (1.488 sec)
39.449... logprob:  0.400101, 0.101562 (1.441 sec)
39.450... logprob:  0.240634, 0.046875 (1.435 sec)
39.451... logprob:  0.452032, 0.125000 (1.437 sec)
39.452... logprob:  0.455627, 0.117188 (1.432 sec)
39.453... logprob:  0.454659, 0.125000 (1.438 sec)
39.454... logprob:  0.488469, 0.132812 (1.492 sec)
39.455... logprob:  0.505810, 0.140625 (1.442 sec)
39.456... logprob:  0.468824, 0.125000 (1.450 sec)
39.457... logprob:  0.375276, 0.093750 (1.476 sec)
39.458... logprob:  0.350784, 0.085938 (1.440 sec)
39.459... logprob:  0.514437, 0.140625 (1.441 sec)
39.460... logprob:  0.272920, 0.054688 (1.438 sec)
39.461... logprob:  0.460289, 0.125000 (1.432 sec)
39.462... logprob:  0.472117, 0.125000 (1.448 sec)
39.463... logprob:  0.420695, 0.109375 (1.468 sec)
39.464... logprob:  0.482932, 0.132812 (1.452 sec)
39.465... logprob:  0.420996, 0.109375 (1.457 sec)
39.466... logprob:  0.317872, 0.070312 (1.459 sec)
39.467... logprob:  0.413768, 0.109375 (1.459 sec)
39.468... logprob:  0.394214, 0.101562 (1.445 sec)
39.469... logprob:  0.334858, 0.078125 (1.436 sec)
39.470... logprob:  0.400140, 0.101562 (1.424 sec)
39.471... logprob:  0.528911, 0.148438 (1.443 sec)
39.472... logprob:  0.409916, 0.109375 (1.455 sec)
39.473... logprob:  0.375597, 0.093750 (1.459 sec)
39.474... logprob:  0.465278, 0.125000 (1.459 sec)
39.475... logprob:  0.503465, 0.140625 (1.453 sec)
39.476... logprob:  0.509848, 0.140625 (1.471 sec)
39.477... logprob:  0.334801, 0.078125 (1.441 sec)
39.478... logprob:  0.464166, 0.125000 (1.459 sec)
39.479... logprob:  0.305805, 0.070312 (1.430 sec)
39.480... logprob:  0.443484, 0.117188 (1.444 sec)
39.481... logprob:  0.547827, 0.156250 (1.439 sec)
39.482... logprob:  0.443101, 0.117188 (1.478 sec)
39.483... logprob:  0.502790, 0.140625 (1.454 sec)
39.484... logprob:  0.485355, 0.132812 (1.437 sec)
39.485... logprob:  0.408786, 0.109375 (1.484 sec)
39.486... logprob:  0.360988, 0.085938 (1.437 sec)
39.487... logprob:  0.522795, 0.148438 (1.430 sec)
39.488... logprob:  0.424564, 0.109375 (1.436 sec)
39.489... logprob:  0.415697, 0.109375 (1.433 sec)
39.490... logprob:  0.440669, 0.117188 (1.438 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.571006774902344, 10.0]}, 128)
batch 872: ({'logprob': [66.16841125488281, 19.0]}, 128)
batch 873: ({'logprob': [41.303890228271484, 9.0]}, 128)
batch 874: ({'logprob': [45.80588912963867, 11.0]}, 128)
batch 875: ({'logprob': [51.07568359375, 13.0]}, 128)
batch 876: ({'logprob': [63.75715637207031, 18.0]}, 128)
batch 877: ({'logprob': [46.205162048339844, 11.0]}, 128)
batch 878: ({'logprob': [61.67991256713867, 17.0]}, 128)
batch 879: ({'logprob': [72.61626434326172, 21.0]}, 128)
batch 880: ({'logprob': [51.106868743896484, 13.0]}, 128)
batch 881: ({'logprob': [30.327348709106445, 5.0]}, 128)
batch 882: ({'logprob': [54.71438980102539, 14.0]}, 128)
batch 883: ({'logprob': [61.64645004272461, 17.0]}, 128)
batch 884: ({'logprob': [51.47561264038086, 13.0]}, 128)
batch 885: ({'logprob': [52.24711227416992, 13.0]}, 128)
batch 886: ({'logprob': [62.06119155883789, 17.0]}, 128)

======================Test output======================
logprob:  0.417364, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.953533e-03 [2.826500e-09] 
Layer 'conv1' biases: 5.516511e-07 [7.517486e-11] 
Layer 'conv2' weights[0]: 7.940687e-03 [2.202446e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.468335e-10] 
Layer 'conv3' weights[0]: 7.938845e-03 [1.982961e-09] 
Layer 'conv3' biases: 4.649814e-06 [1.025991e-09] 
Layer 'conv4' weights[0]: 7.971532e-03 [2.060192e-09] 
Layer 'conv4' biases: 9.999988e-01 [8.925030e-09] 
Layer 'conv5' weights[0]: 7.970272e-03 [5.598589e-08] 
Layer 'conv5' biases: 9.999868e-01 [5.989502e-08] 
Layer 'fc6' weights[0]: 7.566697e-03 [4.597167e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.588872e-09] 
Layer 'fc7' weights[0]: 6.623138e-03 [7.342094e-08] 
Layer 'fc7' biases: 9.998484e-01 [5.834459e-08] 
Layer 'fc8' weights[0]: 1.229670e-03 [2.041580e-06] 
Layer 'fc8' biases: 9.811092e-02 [1.607244e-05] 
Train error last 870 batches: 0.435141
-------------------------------------------------------
Not saving because 0.417364 > 0.415628 (37.630: -0.00%)
======================================================= (12.081 sec)
39.491... logprob:  0.313467, 0.070312 (1.488 sec)
39.492... logprob:  0.459464, 0.125000 (1.446 sec)
39.493... logprob:  0.521687, 0.148438 (1.439 sec)
39.494... logprob:  0.450324, 0.125000 (1.483 sec)
39.495... logprob:  0.380787, 0.093750 (1.434 sec)
39.496... logprob:  0.549958, 0.156250 (1.434 sec)
39.497... logprob:  0.466779, 0.125000 (1.437 sec)
39.498... logprob:  0.476114, 0.132812 (1.434 sec)
39.499... logprob:  0.456182, 0.125000 (1.436 sec)
39.500... logprob:  0.355241, 0.085938 (1.487 sec)
39.501... logprob:  0.339160, 0.078125 (1.437 sec)
39.502... logprob:  0.459553, 0.125000 (1.451 sec)
39.503... logprob:  0.400646, 0.101562 (1.479 sec)
39.504... logprob:  0.487216, 0.132812 (1.435 sec)
39.505... logprob:  0.570704, 0.164062 (1.448 sec)
39.506... logprob:  0.479682, 0.132812 (1.433 sec)
39.507... logprob:  0.384943, 0.093750 (1.428 sec)
39.508... logprob:  0.374581, 0.093750 (1.436 sec)
39.509... logprob:  0.322818, 0.070312 (1.480 sec)
39.510... logprob:  0.390435, 0.101562 (1.442 sec)
39.511... logprob:  0.410016, 0.109375 (1.455 sec)
39.512... logprob:  0.470695, 0.125000 (1.465 sec)
39.513... logprob:  0.324949, 0.078125 (1.449 sec)
39.514... logprob:  0.406271, 0.101562 (1.456 sec)
39.515... logprob:  0.455358, 0.125000 (1.427 sec)
39.516... logprob:  0.400133, 0.109375 (1.432 sec)
39.517... logprob:  0.627496, 0.179688 (1.437 sec)
39.518... logprob:  0.437589, 0.117188 (1.462 sec)
39.519... logprob:  0.516122, 0.140625 (1.457 sec)
39.520... logprob:  0.409631, 0.109375 (1.456 sec)
39.521... logprob:  0.427349, 0.109375 (1.453 sec)
39.522... logprob:  0.533271, 0.156250 (1.463 sec)
39.523... logprob:  0.331230, 0.078125 (1.442 sec)
39.524... logprob:  0.437066, 0.117188 (1.424 sec)
39.525... logprob:  0.425733, 0.109375 (1.434 sec)
39.526... logprob:  0.351378, 0.078125 (1.440 sec)
39.527... logprob:  0.504615, 0.140625 (1.439 sec)
39.528... logprob:  0.440409, 0.117188 (1.468 sec)
39.529... logprob:  0.352990, 0.085938 (1.455 sec)
39.530... logprob:  0.440264, 0.117188 (1.441 sec)
39.531... logprob:  0.439905, 0.117188 (1.481 sec)
39.532... logprob:  0.467236, 0.125000 (1.438 sec)
39.533... logprob:  0.559980, 0.164062 (1.428 sec)
39.534... logprob:  0.326096, 0.078125 (1.436 sec)
39.535... logprob:  0.551187, 0.156250 (1.438 sec)
39.536... logprob:  0.507132, 0.140625 (1.433 sec)
39.537... logprob:  0.509916, 0.140625 (1.479 sec)
39.538... logprob:  0.486052, 0.132812 (1.447 sec)
39.539... logprob:  0.295938, 0.062500 (1.437 sec)
39.540... logprob:  0.447178, 0.117188 (1.491 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.407745361328125, 10.0]}, 128)
batch 872: ({'logprob': [66.16443634033203, 19.0]}, 128)
batch 873: ({'logprob': [41.233829498291016, 9.0]}, 128)
batch 874: ({'logprob': [45.71052551269531, 11.0]}, 128)
batch 875: ({'logprob': [51.01909637451172, 13.0]}, 128)
batch 876: ({'logprob': [63.7501335144043, 18.0]}, 128)
batch 877: ({'logprob': [46.14183044433594, 11.0]}, 128)
batch 878: ({'logprob': [61.70149612426758, 17.0]}, 128)
batch 879: ({'logprob': [72.74766540527344, 21.0]}, 128)
batch 880: ({'logprob': [51.050437927246094, 13.0]}, 128)
batch 881: ({'logprob': [30.14704704284668, 5.0]}, 128)
batch 882: ({'logprob': [54.757896423339844, 14.0]}, 128)
batch 883: ({'logprob': [61.667789459228516, 17.0]}, 128)
batch 884: ({'logprob': [51.451595306396484, 13.0]}, 128)
batch 885: ({'logprob': [52.28742599487305, 13.0]}, 128)
batch 886: ({'logprob': [62.11511993408203, 17.0]}, 128)

======================Test output======================
logprob:  0.417165, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.953497e-03 [3.500277e-09] 
Layer 'conv1' biases: 5.527900e-07 [9.776479e-11] 
Layer 'conv2' weights[0]: 7.940646e-03 [2.090608e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.440386e-10] 
Layer 'conv3' weights[0]: 7.938807e-03 [2.102682e-09] 
Layer 'conv3' biases: 4.662859e-06 [1.239191e-09] 
Layer 'conv4' weights[0]: 7.971496e-03 [2.131051e-09] 
Layer 'conv4' biases: 9.999988e-01 [9.719478e-09] 
Layer 'conv5' weights[0]: 7.970229e-03 [5.499597e-08] 
Layer 'conv5' biases: 9.999869e-01 [5.871832e-08] 
Layer 'fc6' weights[0]: 7.566660e-03 [4.548279e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.542672e-09] 
Layer 'fc7' weights[0]: 6.621473e-03 [4.631762e-08] 
Layer 'fc7' biases: 9.998484e-01 [2.743022e-08] 
Layer 'fc8' weights[0]: 1.232720e-03 [3.816865e-06] 
Layer 'fc8' biases: 9.820379e-02 [2.818874e-05] 
Train error last 870 batches: 0.435141
-------------------------------------------------------
Not saving because 0.417165 > 0.415628 (37.630: -0.00%)
======================================================= (12.111 sec)
39.541... logprob:  0.388701, 0.101562 (1.444 sec)
39.542... logprob:  0.411167, 0.109375 (1.441 sec)
39.543... logprob:  0.233033, 0.039062 (1.441 sec)
39.544... logprob:  0.317905, 0.070312 (1.438 sec)
39.545... logprob:  0.348790, 0.085938 (1.432 sec)
39.546... logprob:  0.368255, 0.093750 (1.490 sec)
39.547... logprob:  0.439888, 0.117188 (1.439 sec)
39.548... logprob:  0.452585, 0.125000 (1.448 sec)
39.549... logprob:  0.490145, 0.132812 (1.479 sec)
39.550... logprob:  0.367533, 0.093750 (1.434 sec)
39.551... logprob:  0.441477, 0.117188 (1.438 sec)
39.552... logprob:  0.471171, 0.125000 (1.434 sec)
39.553... logprob:  0.349455, 0.085938 (1.432 sec)
39.554... logprob:  0.507114, 0.140625 (1.436 sec)
39.555... logprob:  0.421411, 0.109375 (1.483 sec)
39.556... logprob:  0.355649, 0.085938 (1.440 sec)
39.557... logprob:  0.396254, 0.101562 (1.449 sec)
39.558... logprob:  0.382961, 0.101562 (1.477 sec)
39.559... logprob:  0.441775, 0.125000 (1.434 sec)
39.560... logprob:  0.334756, 0.078125 (1.442 sec)
39.561... logprob:  0.411748, 0.109375 (1.431 sec)
39.562... logprob:  0.503214, 0.140625 (1.427 sec)
39.563... logprob:  0.373660, 0.093750 (1.442 sec)
39.564... logprob:  0.468558, 0.132812 (1.466 sec)
39.565... logprob:  0.611295, 0.187500 (1.451 sec)
39.566... logprob:  0.374817, 0.093750 (1.458 sec)
39.567... logprob:  0.423185, 0.109375 (1.468 sec)
39.568... logprob:  0.496294, 0.140625 (1.455 sec)
39.569... logprob:  0.507548, 0.140625 (1.439 sec)
39.570... logprob:  0.543857, 0.164062 (1.426 sec)
39.571... logprob:  0.454897, 0.125000 (1.434 sec)
39.572... logprob:  0.501271, 0.140625 (1.438 sec)
39.573... logprob:  0.512575, 0.148438 (1.448 sec)
39.574... logprob:  0.427926, 0.109375 (1.468 sec)
39.575... logprob:  0.343313, 0.078125 (1.458 sec)
39.576... logprob:  0.427309, 0.109375 (1.445 sec)
39.577... logprob:  0.460746, 0.125000 (1.477 sec)
39.578... logprob:  0.336960, 0.078125 (1.437 sec)
39.579... logprob:  0.442079, 0.117188 (1.432 sec)
39.580... logprob:  0.546360, 0.156250 (1.430 sec)
39.581... logprob:  0.530317, 0.156250 (1.442 sec)
39.582... logprob:  0.437725, 0.125000 (1.443 sec)
39.583... logprob:  0.592045, 0.171875 (1.477 sec)
39.584... logprob:  0.468017, 0.132812 (1.448 sec)
39.585... logprob:  0.349785, 0.085938 (1.436 sec)
39.586... logprob:  0.313007, 0.070312 (1.485 sec)
39.587... logprob:  0.404286, 0.101562 (1.436 sec)
39.588... logprob:  0.418643, 0.117188 (1.434 sec)
39.589... logprob:  0.361050, 0.093750 (1.438 sec)
39.590... logprob:  0.524836, 0.148438 (1.432 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.16792678833008, 10.0]}, 128)
batch 872: ({'logprob': [66.46477508544922, 19.0]}, 128)
batch 873: ({'logprob': [41.001441955566406, 9.0]}, 128)
batch 874: ({'logprob': [45.17427444458008, 11.0]}, 128)
batch 875: ({'logprob': [50.86278533935547, 13.0]}, 128)
batch 876: ({'logprob': [64.03168487548828, 18.0]}, 128)
batch 877: ({'logprob': [45.946109771728516, 11.0]}, 128)
batch 878: ({'logprob': [62.30449295043945, 17.0]}, 128)
batch 879: ({'logprob': [74.44998168945312, 21.0]}, 128)
batch 880: ({'logprob': [50.89350509643555, 13.0]}, 128)
batch 881: ({'logprob': [28.81182861328125, 5.0]}, 128)
batch 882: ({'logprob': [55.645992279052734, 14.0]}, 128)
batch 883: ({'logprob': [62.271217346191406, 17.0]}, 128)
batch 884: ({'logprob': [51.63890838623047, 13.0]}, 128)
batch 885: ({'logprob': [53.15745544433594, 13.0]}, 128)
batch 886: ({'logprob': [63.06100845336914, 17.0]}, 128)

======================Test output======================
logprob:  0.418400, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.953458e-03 [3.398751e-09] 
Layer 'conv1' biases: 5.539872e-07 [8.508260e-11] 
Layer 'conv2' weights[0]: 7.940608e-03 [2.705524e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.897358e-10] 
Layer 'conv3' weights[0]: 7.938770e-03 [2.114796e-09] 
Layer 'conv3' biases: 4.670291e-06 [1.099447e-09] 
Layer 'conv4' weights[0]: 7.971467e-03 [2.011851e-09] 
Layer 'conv4' biases: 9.999988e-01 [7.449335e-09] 
Layer 'conv5' weights[0]: 7.970193e-03 [4.477677e-08] 
Layer 'conv5' biases: 9.999862e-01 [4.790701e-08] 
Layer 'fc6' weights[0]: 7.566624e-03 [3.728897e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.717959e-09] 
Layer 'fc7' weights[0]: 6.619759e-03 [6.589753e-08] 
Layer 'fc7' biases: 9.998497e-01 [5.006936e-08] 
Layer 'fc8' weights[0]: 1.259196e-03 [2.377611e-06] 
Layer 'fc8' biases: 9.851149e-02 [1.684936e-05] 
Train error last 870 batches: 0.435140
-------------------------------------------------------
Not saving because 0.418400 > 0.415628 (37.630: -0.00%)
======================================================= (12.079 sec)
39.591... logprob:  0.397415, 0.101562 (1.442 sec)
39.592... logprob:  0.455709, 0.125000 (1.493 sec)
39.593... logprob:  0.467413, 0.125000 (1.442 sec)
39.594... logprob:  0.352781, 0.085938 (1.444 sec)
39.595... logprob:  0.428659, 0.109375 (1.485 sec)
39.596... logprob:  0.461645, 0.125000 (1.431 sec)
39.597... logprob:  0.397421, 0.101562 (1.436 sec)
39.598... logprob:  0.397208, 0.101562 (1.439 sec)
39.599... logprob:  0.313618, 0.070312 (1.430 sec)
39.600... logprob:  0.340859, 0.085938 (1.433 sec)
39.601... logprob:  0.402182, 0.101562 (1.485 sec)
39.602... logprob:  0.290038, 0.062500 (1.441 sec)
39.603... logprob:  0.267404, 0.054688 (1.445 sec)
39.604... logprob:  0.407541, 0.101562 (1.478 sec)
39.605... logprob:  0.563057, 0.148438 (1.438 sec)
39.606... logprob:  0.295955, 0.070312 (1.435 sec)
39.607... logprob:  0.504511, 0.132812 (1.447 sec)
39.608... logprob:  0.362026, 0.085938 (1.427 sec)
39.609... logprob:  0.357150, 0.085938 (1.438 sec)
39.610... logprob:  0.493167, 0.132812 (1.478 sec)
39.611... logprob:  0.510229, 0.140625 (1.448 sec)
39.612... logprob:  0.448652, 0.117188 (1.458 sec)
39.613... logprob:  0.279023, 0.062500 (1.459 sec)
39.614... logprob:  0.503601, 0.140625 (1.452 sec)
39.615... logprob:  0.350542, 0.085938 (1.440 sec)
39.616... logprob:  0.414851, 0.109375 (1.430 sec)
39.617... logprob:  0.417720, 0.109375 (1.431 sec)
39.618... logprob:  0.547294, 0.156250 (1.446 sec)
39.619... logprob:  0.506266, 0.140625 (1.454 sec)
39.620... logprob:  0.539776, 0.156250 (1.459 sec)
39.621... logprob:  0.363300, 0.085938 (1.457 sec)
39.622... logprob:  0.364448, 0.085938 (1.450 sec)
39.623... logprob:  0.423041, 0.109375 (1.469 sec)
39.624... logprob:  0.382453, 0.093750 (1.438 sec)
39.625... logprob:  0.440961, 0.117188 (1.429 sec)
39.626... logprob:  0.438311, 0.117188 (1.438 sec)
39.627... logprob:  0.435790, 0.117188 (1.441 sec)
39.628... logprob:  0.464976, 0.125000 (1.439 sec)
39.629... logprob:  0.372268, 0.093750 (1.473 sec)
39.630... logprob:  0.422404, 0.109375 (1.451 sec)
39.631... logprob:  0.637688, 0.187500 (1.437 sec)
39.632... logprob:  0.399150, 0.101562 (1.481 sec)
39.633... logprob:  0.376200, 0.093750 (1.439 sec)
39.634... logprob:  0.659714, 0.195312 (1.430 sec)
39.635... logprob:  0.374138, 0.093750 (1.434 sec)
39.636... logprob:  0.480276, 0.132812 (1.439 sec)
39.637... logprob:  0.330612, 0.078125 (1.436 sec)
39.638... logprob:  0.515734, 0.140625 (1.480 sec)
39.639... logprob:  0.417949, 0.109375 (1.443 sec)
39.640... logprob:  0.528782, 0.148438 (1.436 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.641990661621094, 10.0]}, 128)
batch 872: ({'logprob': [66.2686538696289, 19.0]}, 128)
batch 873: ({'logprob': [41.20395278930664, 9.0]}, 128)
batch 874: ({'logprob': [45.80448532104492, 11.0]}, 128)
batch 875: ({'logprob': [51.07493209838867, 13.0]}, 128)
batch 876: ({'logprob': [63.83319854736328, 18.0]}, 128)
batch 877: ({'logprob': [46.15513610839844, 11.0]}, 128)
batch 878: ({'logprob': [61.68204879760742, 17.0]}, 128)
batch 879: ({'logprob': [72.5722427368164, 21.0]}, 128)
batch 880: ({'logprob': [51.10660934448242, 13.0]}, 128)
batch 881: ({'logprob': [30.273502349853516, 5.0]}, 128)
batch 882: ({'logprob': [54.59312438964844, 14.0]}, 128)
batch 883: ({'logprob': [61.64801788330078, 17.0]}, 128)
batch 884: ({'logprob': [51.426761627197266, 13.0]}, 128)
batch 885: ({'logprob': [52.100730895996094, 13.0]}, 128)
batch 886: ({'logprob': [62.01468276977539, 17.0]}, 128)

======================Test output======================
logprob:  0.417188, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.953418e-03 [4.545788e-09] 
Layer 'conv1' biases: 5.551279e-07 [8.818901e-11] 
Layer 'conv2' weights[0]: 7.940573e-03 [3.083575e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.123117e-10] 
Layer 'conv3' weights[0]: 7.938728e-03 [2.146376e-09] 
Layer 'conv3' biases: 4.681666e-06 [1.266259e-09] 
Layer 'conv4' weights[0]: 7.971437e-03 [2.132310e-09] 
Layer 'conv4' biases: 9.999988e-01 [8.183007e-09] 
Layer 'conv5' weights[0]: 7.970158e-03 [5.177515e-08] 
Layer 'conv5' biases: 9.999870e-01 [5.530451e-08] 
Layer 'fc6' weights[0]: 7.566588e-03 [4.233437e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.240817e-09] 
Layer 'fc7' weights[0]: 6.618115e-03 [1.248452e-07] 
Layer 'fc7' biases: 9.998483e-01 [1.137736e-07] 
Layer 'fc8' weights[0]: 1.235157e-03 [3.916157e-06] 
Layer 'fc8' biases: 9.850722e-02 [2.633850e-05] 
Train error last 870 batches: 0.435140
-------------------------------------------------------
Not saving because 0.417188 > 0.415628 (37.630: -0.00%)
======================================================= (12.047 sec)
39.641... logprob:  0.410351, 0.109375 (1.490 sec)
39.642... logprob:  0.500983, 0.140625 (1.442 sec)
39.643... logprob:  0.623624, 0.187500 (1.435 sec)
39.644... logprob:  0.320557, 0.070312 (1.441 sec)
39.645... logprob:  0.414394, 0.109375 (1.433 sec)
39.646... logprob:  0.385406, 0.093750 (1.436 sec)
39.647... logprob:  0.456823, 0.125000 (1.486 sec)
39.648... logprob:  0.491319, 0.140625 (1.435 sec)
39.649... logprob:  0.370446, 0.093750 (1.446 sec)
39.650... logprob:  0.414107, 0.109375 (1.480 sec)
39.651... logprob:  0.397489, 0.101562 (1.432 sec)
39.652... logprob:  0.506855, 0.140625 (1.442 sec)
39.653... logprob:  0.547409, 0.156250 (1.436 sec)
39.654... logprob:  0.495905, 0.140625 (1.429 sec)
39.655... logprob:  0.436162, 0.117188 (1.430 sec)
39.656... logprob:  0.416751, 0.109375 (1.484 sec)
39.657... logprob:  0.448874, 0.117188 (1.438 sec)
39.658... logprob:  0.346002, 0.085938 (1.456 sec)
39.659... logprob:  0.464220, 0.125000 (1.478 sec)
39.660... logprob:  0.446153, 0.125000 (1.443 sec)
39.661... logprob:  0.378321, 0.093750 (1.441 sec)
39.662... logprob:  0.469563, 0.132812 (1.431 sec)
39.663... logprob:  0.310741, 0.070312 (1.428 sec)
39.664... logprob:  0.285259, 0.062500 (1.438 sec)
39.665... logprob:  0.401561, 0.101562 (1.464 sec)
39.666... logprob:  0.441992, 0.117188 (1.455 sec)
39.667... logprob:  0.564141, 0.164062 (1.455 sec)
39.668... logprob:  0.497810, 0.140625 (1.454 sec)
39.669... logprob:  0.432777, 0.109375 (1.463 sec)
39.670... logprob:  0.362247, 0.085938 (1.439 sec)
39.671... logprob:  0.360891, 0.093750 (1.425 sec)
39.672... logprob:  0.441836, 0.117188 (1.432 sec)
39.673... logprob:  0.436217, 0.117188 (1.441 sec)
39.674... logprob:  0.446601, 0.117188 (1.441 sec)
39.675... logprob:  0.356702, 0.093750 (1.470 sec)
39.676... logprob:  0.450224, 0.125000 (1.457 sec)
39.677... logprob:  0.470986, 0.125000 (1.439 sec)
39.678... logprob:  0.465672, 0.125000 (1.486 sec)
39.679... logprob:  0.454862, 0.125000 (1.429 sec)
39.680... logprob:  0.351578, 0.078125 (1.429 sec)
39.681... logprob:  0.373801, 0.093750 (1.437 sec)
39.682... logprob:  0.340429, 0.078125 (1.439 sec)
39.683... logprob:  0.411623, 0.109375 (1.436 sec)
39.684... logprob:  0.357778, 0.085938 (1.480 sec)
39.685... logprob:  0.286468, 0.054688 (1.442 sec)
39.686... logprob:  0.319039, 0.070312 (1.436 sec)
39.687... logprob:  0.282031, 0.062500 (1.487 sec)
39.688... logprob:  0.323210, 0.078125 (1.439 sec)
39.689... logprob:  0.470476, 0.125000 (1.431 sec)
39.690... logprob:  0.526784, 0.140625 (1.437 sec)
=========================
Testing all batches
batch 871: ({'logprob': [40.85226058959961, 10.0]}, 128)
batch 872: ({'logprob': [69.41988372802734, 19.0]}, 128)
batch 873: ({'logprob': [39.35179901123047, 9.0]}, 128)
batch 874: ({'logprob': [44.785701751708984, 11.0]}, 128)
batch 875: ({'logprob': [51.16414260864258, 13.0]}, 128)
batch 876: ({'logprob': [66.50176239013672, 18.0]}, 128)
batch 877: ({'logprob': [45.27198028564453, 11.0]}, 128)
batch 878: ({'logprob': [63.999385833740234, 17.0]}, 128)
batch 879: ({'logprob': [77.2557601928711, 21.0]}, 128)
batch 880: ({'logprob': [51.19813919067383, 13.0]}, 128)
batch 881: ({'logprob': [26.048751831054688, 5.0]}, 128)
batch 882: ({'logprob': [55.5953483581543, 14.0]}, 128)
batch 883: ({'logprob': [63.96360778808594, 17.0]}, 128)
batch 884: ({'logprob': [51.66687774658203, 13.0]}, 128)
batch 885: ({'logprob': [52.619224548339844, 13.0]}, 128)
batch 886: ({'logprob': [64.47708129882812, 17.0]}, 128)

======================Test output======================
logprob:  0.421959, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.953379e-03 [5.995794e-09] 
Layer 'conv1' biases: 5.559491e-07 [2.354216e-10] 
Layer 'conv2' weights[0]: 7.940528e-03 [4.985478e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.173432e-09] 
Layer 'conv3' weights[0]: 7.938689e-03 [5.138671e-09] 
Layer 'conv3' biases: 4.684874e-06 [3.401881e-09] 
Layer 'conv4' weights[0]: 7.971403e-03 [5.005587e-09] 
Layer 'conv4' biases: 9.999988e-01 [2.845674e-08] 
Layer 'conv5' weights[0]: 7.970115e-03 [1.764756e-07] 
Layer 'conv5' biases: 9.999861e-01 [1.885863e-07] 
Layer 'fc6' weights[0]: 7.566543e-03 [1.435404e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.468194e-08] 
Layer 'fc7' weights[0]: 6.616377e-03 [5.159175e-08] 
Layer 'fc7' biases: 9.998507e-01 [3.352237e-08] 
Layer 'fc8' weights[0]: 1.328902e-03 [7.265600e-06] 
Layer 'fc8' biases: 9.924783e-02 [5.223388e-05] 
Train error last 870 batches: 0.435140
-------------------------------------------------------
Not saving because 0.421959 > 0.415628 (37.630: -0.00%)
======================================================= (12.059 sec)
39.691... logprob:  0.515478, 0.140625 (1.442 sec)
39.692... logprob:  0.384354, 0.101562 (1.443 sec)
39.693... logprob:  0.455068, 0.125000 (1.490 sec)
39.694... logprob:  0.331015, 0.078125 (1.437 sec)
39.695... logprob:  0.357006, 0.085938 (1.443 sec)
39.696... logprob:  0.539642, 0.148438 (1.483 sec)
39.697... logprob:  0.465956, 0.125000 (1.435 sec)
39.698... logprob:  0.549501, 0.156250 (1.438 sec)
39.699... logprob:  0.459689, 0.125000 (1.437 sec)
39.700... logprob:  0.433642, 0.117188 (1.428 sec)
39.701... logprob:  0.422602, 0.109375 (1.435 sec)
39.702... logprob:  0.521699, 0.148438 (1.485 sec)
39.703... logprob:  0.404469, 0.101562 (1.442 sec)
39.704... logprob:  0.405542, 0.101562 (1.455 sec)
39.705... logprob:  0.419875, 0.109375 (1.475 sec)
39.706... logprob:  0.468014, 0.125000 (1.435 sec)
39.707... logprob:  0.485291, 0.132812 (1.442 sec)
39.708... logprob:  0.417365, 0.109375 (1.433 sec)
39.709... logprob:  0.422859, 0.109375 (1.425 sec)
39.710... logprob:  0.601496, 0.179688 (1.442 sec)
39.711... logprob:  0.469439, 0.125000 (1.464 sec)
39.712... logprob:  0.341519, 0.078125 (1.451 sec)
39.713... logprob:  0.585619, 0.179688 (1.456 sec)
39.714... logprob:  0.466168, 0.125000 (1.457 sec)
39.715... logprob:  0.417275, 0.109375 (1.460 sec)
39.716... logprob:  0.335776, 0.078125 (1.441 sec)
39.717... logprob:  0.429730, 0.117188 (1.428 sec)
39.718... logprob:  0.490208, 0.132812 (1.432 sec)
39.719... logprob:  0.406164, 0.109375 (1.436 sec)
39.720... logprob:  0.433209, 0.117188 (1.450 sec)
39.721... logprob:  0.451602, 0.117188 (1.462 sec)
39.722... logprob:  0.537153, 0.156250 (1.454 sec)
39.723... logprob:  0.416509, 0.109375 (1.446 sec)
39.724... logprob:  0.412746, 0.109375 (1.478 sec)
39.725... logprob:  0.495061, 0.140625 (1.435 sec)
39.726... logprob:  0.338172, 0.085938 (1.426 sec)
39.727... logprob:  0.393040, 0.101562 (1.437 sec)
39.728... logprob:  0.421077, 0.109375 (1.442 sec)
39.729... logprob:  0.387344, 0.093750 (1.430 sec)
39.730... logprob:  0.566099, 0.164062 (1.479 sec)
39.731... logprob:  0.450505, 0.125000 (1.446 sec)
39.732... logprob:  0.311248, 0.070312 (1.439 sec)
39.733... logprob:  0.556363, 0.156250 (1.486 sec)
39.734... logprob:  0.340234, 0.078125 (1.436 sec)
39.735... logprob:  0.527276, 0.148438 (1.430 sec)
39.736... logprob:  0.642199, 0.187500 (1.440 sec)
39.737... logprob:  0.516012, 0.148438 (1.433 sec)
39.738... logprob:  0.459348, 0.125000 (1.436 sec)
39.739... logprob:  0.477769, 0.132812 (1.482 sec)
39.740... logprob:  0.339642, 0.078125 (1.442 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.96630096435547, 10.0]}, 128)
batch 872: ({'logprob': [65.74076080322266, 19.0]}, 128)
batch 873: ({'logprob': [42.37422561645508, 9.0]}, 128)
batch 874: ({'logprob': [46.3725471496582, 11.0]}, 128)
batch 875: ({'logprob': [51.480262756347656, 13.0]}, 128)
batch 876: ({'logprob': [63.49541091918945, 18.0]}, 128)
batch 877: ({'logprob': [46.94260787963867, 11.0]}, 128)
batch 878: ({'logprob': [61.75558090209961, 17.0]}, 128)
batch 879: ({'logprob': [72.53157043457031, 21.0]}, 128)
batch 880: ({'logprob': [51.51024627685547, 13.0]}, 128)
batch 881: ({'logprob': [31.557775497436523, 5.0]}, 128)
batch 882: ({'logprob': [55.45859909057617, 14.0]}, 128)
batch 883: ({'logprob': [61.722782135009766, 17.0]}, 128)
batch 884: ({'logprob': [52.04658126831055, 13.0]}, 128)
batch 885: ({'logprob': [53.157379150390625, 13.0]}, 128)
batch 886: ({'logprob': [62.305030822753906, 17.0]}, 128)

======================Test output======================
logprob:  0.420614, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.953343e-03 [3.750036e-09] 
Layer 'conv1' biases: 5.572177e-07 [1.171290e-10] 
Layer 'conv2' weights[0]: 7.940501e-03 [3.888636e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.889079e-10] 
Layer 'conv3' weights[0]: 7.938649e-03 [3.518431e-09] 
Layer 'conv3' biases: 4.700520e-06 [2.073904e-09] 
Layer 'conv4' weights[0]: 7.971368e-03 [3.594664e-09] 
Layer 'conv4' biases: 9.999989e-01 [1.786206e-08] 
Layer 'conv5' weights[0]: 7.970074e-03 [1.106441e-07] 
Layer 'conv5' biases: 9.999869e-01 [1.183059e-07] 
Layer 'fc6' weights[0]: 7.566507e-03 [8.941893e-09] 
Layer 'fc6' biases: 1.000000e+00 [9.055376e-09] 
Layer 'fc7' weights[0]: 6.614735e-03 [6.902602e-08] 
Layer 'fc7' biases: 9.998480e-01 [5.482879e-08] 
Layer 'fc8' weights[0]: 1.216881e-03 [2.432763e-06] 
Layer 'fc8' biases: 9.862759e-02 [1.601336e-05] 
Train error last 870 batches: 0.435140
-------------------------------------------------------
Not saving because 0.420614 > 0.415628 (37.630: -0.00%)
======================================================= (12.065 sec)
39.741... logprob:  0.393511, 0.101562 (1.443 sec)
39.742... logprob:  0.419659, 0.109375 (1.494 sec)
39.743... logprob:  0.364937, 0.085938 (1.438 sec)
39.744... logprob:  0.519043, 0.148438 (1.435 sec)
39.745... logprob:  0.478092, 0.132812 (1.437 sec)
39.746... logprob:  0.440539, 0.117188 (1.433 sec)
39.747... logprob:  0.425595, 0.109375 (1.433 sec)
39.748... logprob:  0.378243, 0.093750 (1.491 sec)
39.749... logprob:  0.420779, 0.109375 (1.434 sec)
39.750... logprob:  0.512625, 0.140625 (1.450 sec)
39.751... logprob:  0.263896, 0.054688 (1.478 sec)
39.752... logprob:  0.522475, 0.140625 (1.435 sec)
39.753... logprob:  0.441072, 0.117188 (1.439 sec)
39.754... logprob:  0.468051, 0.132812 (1.433 sec)
39.755... logprob:  0.506987, 0.140625 (1.427 sec)
39.756... logprob:  0.440850, 0.117188 (1.442 sec)
39.757... logprob:  0.552630, 0.156250 (1.471 sec)
39.758... logprob:  0.393438, 0.101562 (1.452 sec)
39.759... logprob:  0.459715, 0.125000 (1.461 sec)
39.760... logprob:  0.485691, 0.132812 (1.462 sec)
39.761... logprob:  0.417961, 0.109375 (1.447 sec)
39.762... logprob:  0.516154, 0.148438 (1.443 sec)
39.763... logprob:  0.559206, 0.164062 (1.429 sec)
39.764... logprob:  0.503256, 0.140625 (1.430 sec)
39.765... logprob:  0.311184, 0.062500 (1.438 sec)
39.766... logprob:  0.482130, 0.132812 (1.461 sec)
39.767... logprob:  0.370963, 0.085938 (1.454 sec)
39.768... logprob:  0.432589, 0.117188 (1.468 sec)
39.769... logprob:  0.490712, 0.140625 (1.466 sec)
39.770... logprob:  0.403134, 0.101562 (1.491 sec)
39.771... logprob:  0.549137, 0.156250 (1.460 sec)
39.772... logprob:  0.414180, 0.109375 (1.446 sec)
39.773... logprob:  0.557211, 0.164062 (1.452 sec)
39.774... logprob:  0.362061, 0.085938 (1.457 sec)
39.775... logprob:  0.407491, 0.101562 (1.467 sec)
39.776... logprob:  0.433077, 0.117188 (1.479 sec)
39.777... logprob:  0.380063, 0.093750 (1.477 sec)
39.778... logprob:  0.433465, 0.117188 (1.465 sec)
39.779... logprob:  0.505160, 0.140625 (1.491 sec)
39.780... logprob:  0.385767, 0.101562 (1.454 sec)
39.781... logprob:  0.369579, 0.085938 (1.453 sec)
39.782... logprob:  0.351339, 0.085938 (1.449 sec)
39.783... logprob:  0.555568, 0.156250 (1.460 sec)
39.784... logprob:  0.440965, 0.117188 (1.456 sec)
39.785... logprob:  0.543905, 0.156250 (1.490 sec)
39.786... logprob:  0.477707, 0.132812 (1.469 sec)
39.787... logprob:  0.546827, 0.156250 (1.463 sec)
39.788... logprob:  0.563669, 0.164062 (1.496 sec)
39.789... logprob:  0.279885, 0.054688 (1.453 sec)
39.790... logprob:  0.407536, 0.101562 (1.450 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.94106674194336, 10.0]}, 128)
batch 872: ({'logprob': [65.92593383789062, 19.0]}, 128)
batch 873: ({'logprob': [41.920597076416016, 9.0]}, 128)
batch 874: ({'logprob': [46.18820571899414, 11.0]}, 128)
batch 875: ({'logprob': [51.3286018371582, 13.0]}, 128)
batch 876: ({'logprob': [63.60561752319336, 18.0]}, 128)
batch 877: ({'logprob': [46.64025115966797, 11.0]}, 128)
batch 878: ({'logprob': [61.67213821411133, 17.0]}, 128)
batch 879: ({'logprob': [72.39910888671875, 21.0]}, 128)
batch 880: ({'logprob': [51.35942840576172, 13.0]}, 128)
batch 881: ({'logprob': [31.15355682373047, 5.0]}, 128)
batch 882: ({'logprob': [55.031070709228516, 14.0]}, 128)
batch 883: ({'logprob': [61.638710021972656, 17.0]}, 128)
batch 884: ({'logprob': [51.77874755859375, 13.0]}, 128)
batch 885: ({'logprob': [52.65434646606445, 13.0]}, 128)
batch 886: ({'logprob': [62.10447692871094, 17.0]}, 128)

======================Test output======================
logprob:  0.419112, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.953308e-03 [3.524285e-09] 
Layer 'conv1' biases: 5.583110e-07 [1.344918e-10] 
Layer 'conv2' weights[0]: 7.940459e-03 [3.447802e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.638626e-10] 
Layer 'conv3' weights[0]: 7.938604e-03 [3.207884e-09] 
Layer 'conv3' biases: 4.710894e-06 [1.968786e-09] 
Layer 'conv4' weights[0]: 7.971335e-03 [3.156837e-09] 
Layer 'conv4' biases: 9.999989e-01 [1.626297e-08] 
Layer 'conv5' weights[0]: 7.970036e-03 [9.801275e-08] 
Layer 'conv5' biases: 9.999870e-01 [1.048485e-07] 
Layer 'fc6' weights[0]: 7.566464e-03 [7.913115e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.038445e-09] 
Layer 'fc7' weights[0]: 6.613059e-03 [9.726064e-08] 
Layer 'fc7' biases: 9.998481e-01 [8.481259e-08] 
Layer 'fc8' weights[0]: 1.221174e-03 [3.100659e-06] 
Layer 'fc8' biases: 9.880779e-02 [1.836384e-05] 
Train error last 870 batches: 0.435140
-------------------------------------------------------
Not saving because 0.419112 > 0.415628 (37.630: -0.00%)
======================================================= (12.061 sec)
39.791... logprob:  0.397550, 0.101562 (1.458 sec)
39.792... logprob:  0.360557, 0.085938 (1.471 sec)
39.793... logprob:  0.369824, 0.085938 (1.461 sec)
39.794... logprob:  0.387091, 0.093750 (1.495 sec)
39.795... logprob:  0.469634, 0.125000 (1.474 sec)
39.796... logprob:  0.423527, 0.109375 (1.455 sec)
39.797... logprob:  0.359067, 0.085938 (1.501 sec)
39.798... logprob:  0.393340, 0.101562 (1.453 sec)
39.799... logprob:  0.332770, 0.078125 (1.451 sec)
39.800... logprob:  0.371637, 0.093750 (1.451 sec)
39.801... logprob:  0.449597, 0.117188 (1.460 sec)
39.802... logprob:  0.422616, 0.109375 (1.454 sec)
39.803... logprob:  0.490893, 0.132812 (1.496 sec)
39.804... logprob:  0.349925, 0.085938 (1.466 sec)
39.805... logprob:  0.452219, 0.117188 (1.453 sec)
39.806... logprob:  0.424151, 0.109375 (1.501 sec)
39.807... logprob:  0.443475, 0.117188 (1.458 sec)
39.808... logprob:  0.462368, 0.125000 (1.451 sec)
39.809... logprob:  0.590060, 0.171875 (1.450 sec)
39.810... logprob:  0.442550, 0.117188 (1.459 sec)
39.811... logprob:  0.460439, 0.125000 (1.456 sec)
39.812... logprob:  0.462283, 0.125000 (1.505 sec)
39.813... logprob:  0.485952, 0.132812 (1.461 sec)
39.814... logprob:  0.477739, 0.132812 (1.457 sec)
39.815... logprob:  0.370693, 0.085938 (1.503 sec)
39.816... logprob:  0.408015, 0.101562 (1.454 sec)
39.817... logprob:  0.425523, 0.109375 (1.458 sec)
39.818... logprob:  0.560079, 0.164062 (1.458 sec)
39.819... logprob:  0.498153, 0.140625 (1.455 sec)
39.820... logprob:  0.421759, 0.109375 (1.452 sec)
39.821... logprob:  0.406886, 0.101562 (1.506 sec)
39.822... logprob:  0.441423, 0.117188 (1.461 sec)
39.823... logprob:  0.341654, 0.078125 (1.462 sec)
39.824... logprob:  0.489398, 0.132812 (1.504 sec)
39.825... logprob:  0.289142, 0.062500 (1.458 sec)
39.826... logprob:  0.375805, 0.093750 (1.454 sec)
39.827... logprob:  0.420303, 0.109375 (1.451 sec)
39.828... logprob:  0.442774, 0.117188 (1.452 sec)
39.829... logprob:  0.503048, 0.140625 (1.457 sec)
39.830... logprob:  0.441759, 0.117188 (1.501 sec)
39.831... logprob:  0.513503, 0.140625 (1.540 sec)
39.832... logprob:  0.330856, 0.078125 (1.463 sec)
39.833... logprob:  0.489094, 0.132812 (1.497 sec)
39.834... logprob:  0.433519, 0.117188 (1.451 sec)
39.835... logprob:  0.543244, 0.148438 (1.463 sec)
39.836... logprob:  0.375893, 0.093750 (1.451 sec)
39.837... logprob:  0.313381, 0.070312 (1.449 sec)
39.838... logprob:  0.437071, 0.117188 (1.459 sec)
39.839... logprob:  0.471604, 0.125000 (1.503 sec)
39.840... logprob:  0.555885, 0.156250 (1.451 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.509639739990234, 10.0]}, 128)
batch 872: ({'logprob': [66.26472473144531, 19.0]}, 128)
batch 873: ({'logprob': [41.14051818847656, 9.0]}, 128)
batch 874: ({'logprob': [45.72401809692383, 11.0]}, 128)
batch 875: ({'logprob': [51.02570724487305, 13.0]}, 128)
batch 876: ({'logprob': [63.82558059692383, 18.0]}, 128)
batch 877: ({'logprob': [46.098514556884766, 11.0]}, 128)
batch 878: ({'logprob': [61.69481658935547, 17.0]}, 128)
batch 879: ({'logprob': [72.67142486572266, 21.0]}, 128)
batch 880: ({'logprob': [51.057003021240234, 13.0]}, 128)
batch 881: ({'logprob': [30.1234073638916, 5.0]}, 128)
batch 882: ({'logprob': [54.61952209472656, 14.0]}, 128)
batch 883: ({'logprob': [61.661251068115234, 17.0]}, 128)
batch 884: ({'logprob': [51.40150451660156, 13.0]}, 128)
batch 885: ({'logprob': [52.123722076416016, 13.0]}, 128)
batch 886: ({'logprob': [62.05160140991211, 17.0]}, 128)

======================Test output======================
logprob:  0.416989, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.953266e-03 [5.293923e-09] 
Layer 'conv1' biases: 5.595603e-07 [1.315319e-10] 
Layer 'conv2' weights[0]: 7.940423e-03 [3.877041e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.617982e-10] 
Layer 'conv3' weights[0]: 7.938567e-03 [3.199031e-09] 
Layer 'conv3' biases: 4.719301e-06 [1.936100e-09] 
Layer 'conv4' weights[0]: 7.971297e-03 [3.199447e-09] 
Layer 'conv4' biases: 9.999988e-01 [1.540962e-08] 
Layer 'conv5' weights[0]: 7.970003e-03 [9.775411e-08] 
Layer 'conv5' biases: 9.999869e-01 [1.044336e-07] 
Layer 'fc6' weights[0]: 7.566426e-03 [7.841422e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.000650e-09] 
Layer 'fc7' weights[0]: 6.611386e-03 [2.224468e-07] 
Layer 'fc7' biases: 9.998482e-01 [2.136362e-07] 
Layer 'fc8' weights[0]: 1.233263e-03 [7.143453e-06] 
Layer 'fc8' biases: 9.918736e-02 [4.871207e-05] 
Train error last 870 batches: 0.435139
-------------------------------------------------------
Not saving because 0.416989 > 0.415628 (37.630: -0.00%)
======================================================= (12.036 sec)
39.841... logprob:  0.395734, 0.101562 (1.474 sec)
39.842... logprob:  0.498000, 0.140625 (1.513 sec)
39.843... logprob:  0.465440, 0.125000 (1.456 sec)
39.844... logprob:  0.497736, 0.140625 (1.463 sec)
39.845... logprob:  0.486650, 0.132812 (1.450 sec)
39.846... logprob:  0.468294, 0.125000 (1.449 sec)
39.847... logprob:  0.363566, 0.085938 (1.451 sec)
39.848... logprob:  0.397413, 0.101562 (1.504 sec)
39.849... logprob:  0.360909, 0.085938 (1.460 sec)
39.850... logprob:  0.479326, 0.132812 (1.467 sec)
39.851... logprob:  0.440146, 0.117188 (1.501 sec)
39.852... logprob:  0.544843, 0.156250 (1.453 sec)
39.853... logprob:  0.372261, 0.093750 (1.461 sec)
39.854... logprob:  0.307846, 0.070312 (1.453 sec)
39.855... logprob:  0.484408, 0.132812 (1.448 sec)
39.856... logprob:  0.443540, 0.117188 (1.456 sec)
39.857... logprob:  0.372251, 0.093750 (1.502 sec)
39.858... logprob:  0.396245, 0.101562 (1.461 sec)
39.859... logprob:  0.308086, 0.070312 (1.469 sec)
39.860... logprob:  0.565896, 0.156250 (1.490 sec)
39.861... logprob:  0.417772, 0.109375 (1.459 sec)
39.862... logprob:  0.328757, 0.078125 (1.461 sec)
39.863... logprob:  0.399632, 0.101562 (1.482 sec)
39.864... logprob:  0.451594, 0.117188 (1.447 sec)
39.865... logprob:  0.484842, 0.132812 (1.458 sec)
39.866... logprob:  0.508107, 0.140625 (1.491 sec)
39.867... logprob:  0.503513, 0.140625 (1.466 sec)
39.868... logprob:  0.405046, 0.101562 (1.474 sec)
39.869... logprob:  0.382794, 0.093750 (1.482 sec)
39.870... logprob:  0.552585, 0.156250 (1.401 sec)
40.1... logprob:  0.379604, 0.093750 (1.402 sec)
40.2... logprob:  0.448198, 0.117188 (1.453 sec)
40.3... logprob:  0.398059, 0.101562 (1.428 sec)
40.4... logprob:  0.443223, 0.117188 (1.495 sec)
40.5... logprob:  0.443521, 0.117188 (1.436 sec)
40.6... logprob:  0.498938, 0.140625 (1.394 sec)
40.7... logprob:  0.363517, 0.085938 (1.430 sec)
40.8... logprob:  0.419231, 0.109375 (1.397 sec)
40.9... logprob:  0.359199, 0.085938 (1.403 sec)
40.10... logprob:  0.377843, 0.093750 (1.407 sec)
40.11... logprob:  0.335325, 0.078125 (1.447 sec)
40.12... logprob:  0.466010, 0.125000 (1.393 sec)
40.13... logprob:  0.441923, 0.117188 (1.426 sec)
40.14... logprob:  0.444255, 0.117188 (1.408 sec)
40.15... logprob:  0.395354, 0.101562 (1.409 sec)
40.16... logprob:  0.421226, 0.109375 (1.409 sec)
40.17... logprob:  0.515703, 0.140625 (1.399 sec)
40.18... logprob:  0.262191, 0.054688 (1.403 sec)
40.19... logprob:  0.279373, 0.062500 (1.408 sec)
40.20... logprob:  0.421335, 0.109375 (1.409 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.5744514465332, 10.0]}, 128)
batch 872: ({'logprob': [68.35710144042969, 19.0]}, 128)
batch 873: ({'logprob': [39.35407638549805, 9.0]}, 128)
batch 874: ({'logprob': [44.89458465576172, 11.0]}, 128)
batch 875: ({'logprob': [50.84763717651367, 13.0]}, 128)
batch 876: ({'logprob': [65.51814270019531, 18.0]}, 128)
batch 877: ({'logprob': [45.1158561706543, 11.0]}, 128)
batch 878: ({'logprob': [62.830936431884766, 17.0]}, 128)
batch 879: ({'logprob': [74.97103881835938, 21.0]}, 128)
batch 880: ({'logprob': [50.881656646728516, 13.0]}, 128)
batch 881: ({'logprob': [27.17058753967285, 5.0]}, 128)
batch 882: ({'logprob': [54.399776458740234, 14.0]}, 128)
batch 883: ({'logprob': [62.79530715942383, 17.0]}, 128)
batch 884: ({'logprob': [51.081764221191406, 13.0]}, 128)
batch 885: ({'logprob': [51.5028076171875, 13.0]}, 128)
batch 886: ({'logprob': [63.04133224487305, 17.0]}, 128)

======================Test output======================
logprob:  0.417157, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.953230e-03 [3.953092e-09] 
Layer 'conv1' biases: 5.607135e-07 [5.978045e-11] 
Layer 'conv2' weights[0]: 7.940383e-03 [2.106572e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.693809e-10] 
Layer 'conv3' weights[0]: 7.938529e-03 [1.412056e-09] 
Layer 'conv3' biases: 4.725393e-06 [4.474822e-10] 
Layer 'conv4' weights[0]: 7.971258e-03 [1.372474e-09] 
Layer 'conv4' biases: 9.999988e-01 [1.542075e-09] 
Layer 'conv5' weights[0]: 7.969958e-03 [9.330397e-09] 
Layer 'conv5' biases: 9.999863e-01 [9.793822e-09] 
Layer 'fc6' weights[0]: 7.566381e-03 [1.095397e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.569169e-10] 
Layer 'fc7' weights[0]: 6.609664e-03 [7.370443e-08] 
Layer 'fc7' biases: 9.998497e-01 [5.903541e-08] 
Layer 'fc8' weights[0]: 1.289000e-03 [1.997742e-06] 
Layer 'fc8' biases: 9.976437e-02 [1.598873e-05] 
Train error last 870 batches: 0.435139
-------------------------------------------------------
Not saving because 0.417157 > 0.415628 (37.630: -0.00%)
======================================================= (12.129 sec)
40.21... logprob:  0.444017, 0.117188 (1.406 sec)
40.22... logprob:  0.536987, 0.148438 (1.422 sec)
40.23... logprob:  0.533517, 0.148438 (1.424 sec)
40.24... logprob:  0.310176, 0.070312 (1.418 sec)
40.25... logprob:  0.355915, 0.085938 (1.401 sec)
40.26... logprob:  0.463978, 0.125000 (1.477 sec)
40.27... logprob:  0.404408, 0.101562 (1.398 sec)
40.28... logprob:  0.421824, 0.109375 (1.413 sec)
40.29... logprob:  0.395761, 0.101562 (1.420 sec)
40.30... logprob:  0.373886, 0.093750 (1.423 sec)
40.31... logprob:  0.480062, 0.132812 (1.402 sec)
40.32... logprob:  0.457218, 0.125000 (1.391 sec)
40.33... logprob:  0.460688, 0.125000 (1.447 sec)
40.34... logprob:  0.464442, 0.125000 (1.393 sec)
40.35... logprob:  0.316415, 0.070312 (1.405 sec)
40.36... logprob:  0.475792, 0.132812 (1.409 sec)
40.37... logprob:  0.417595, 0.109375 (1.410 sec)
40.38... logprob:  0.392853, 0.101562 (1.397 sec)
40.39... logprob:  0.630981, 0.187500 (1.441 sec)
40.40... logprob:  0.445536, 0.117188 (1.409 sec)
40.41... logprob:  0.353207, 0.085938 (1.430 sec)
40.42... logprob:  0.392183, 0.101562 (1.418 sec)
40.43... logprob:  0.440051, 0.117188 (1.409 sec)
40.44... logprob:  0.518584, 0.148438 (1.440 sec)
40.45... logprob:  0.381692, 0.093750 (1.396 sec)
40.46... logprob:  0.486009, 0.132812 (1.399 sec)
40.47... logprob:  0.331720, 0.078125 (1.399 sec)
40.48... logprob:  0.498986, 0.140625 (1.433 sec)
40.49... logprob:  0.511096, 0.148438 (1.414 sec)
40.50... logprob:  0.393146, 0.101562 (1.426 sec)
40.51... logprob:  0.490500, 0.140625 (1.422 sec)
40.52... logprob:  0.525804, 0.148438 (1.409 sec)
40.53... logprob:  0.294562, 0.062500 (1.445 sec)
40.54... logprob:  0.403548, 0.109375 (1.388 sec)
40.55... logprob:  0.331589, 0.078125 (1.400 sec)
40.56... logprob:  0.421519, 0.109375 (1.406 sec)
40.57... logprob:  0.572213, 0.164062 (1.427 sec)
40.58... logprob:  0.407337, 0.101562 (1.406 sec)
40.59... logprob:  0.333858, 0.078125 (1.468 sec)
40.60... logprob:  0.618492, 0.179688 (1.419 sec)
40.61... logprob:  0.382726, 0.093750 (1.437 sec)
40.62... logprob:  0.474804, 0.132812 (1.461 sec)
40.63... logprob:  0.397271, 0.101562 (1.444 sec)
40.64... logprob:  0.450388, 0.125000 (1.417 sec)
40.65... logprob:  0.373430, 0.093750 (1.402 sec)
40.66... logprob:  0.354068, 0.085938 (1.447 sec)
40.67... logprob:  0.295453, 0.062500 (1.388 sec)
40.68... logprob:  0.396790, 0.101562 (1.401 sec)
40.69... logprob:  0.496524, 0.140625 (1.430 sec)
40.70... logprob:  0.325946, 0.078125 (1.426 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.02096176147461, 10.0]}, 128)
batch 872: ({'logprob': [67.02822875976562, 19.0]}, 128)
batch 873: ({'logprob': [40.29376983642578, 9.0]}, 128)
batch 874: ({'logprob': [44.889339447021484, 11.0]}, 128)
batch 875: ({'logprob': [50.718353271484375, 13.0]}, 128)
batch 876: ({'logprob': [64.45535278320312, 18.0]}, 128)
batch 877: ({'logprob': [45.520362854003906, 11.0]}, 128)
batch 878: ({'logprob': [62.4458122253418, 17.0]}, 128)
batch 879: ({'logprob': [74.73706817626953, 21.0]}, 128)
batch 880: ({'logprob': [50.750308990478516, 13.0]}, 128)
batch 881: ({'logprob': [27.957870483398438, 5.0]}, 128)
batch 882: ({'logprob': [55.22480392456055, 14.0]}, 128)
batch 883: ({'logprob': [62.41163635253906, 17.0]}, 128)
batch 884: ({'logprob': [51.35711669921875, 13.0]}, 128)
batch 885: ({'logprob': [52.59516143798828, 13.0]}, 128)
batch 886: ({'logprob': [63.06332778930664, 17.0]}, 128)

======================Test output======================
logprob:  0.417221, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.953191e-03 [2.841617e-09] 
Layer 'conv1' biases: 5.616878e-07 [8.350492e-11] 
Layer 'conv2' weights[0]: 7.940336e-03 [2.012985e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.032480e-10] 
Layer 'conv3' weights[0]: 7.938492e-03 [1.757365e-09] 
Layer 'conv3' biases: 4.733522e-06 [8.995973e-10] 
Layer 'conv4' weights[0]: 7.971217e-03 [1.759958e-09] 
Layer 'conv4' biases: 9.999988e-01 [7.331690e-09] 
Layer 'conv5' weights[0]: 7.969910e-03 [4.603523e-08] 
Layer 'conv5' biases: 9.999861e-01 [4.919428e-08] 
Layer 'fc6' weights[0]: 7.566343e-03 [3.797962e-09] 
Layer 'fc6' biases: 1.000000e+00 [3.794369e-09] 
Layer 'fc7' weights[0]: 6.607978e-03 [1.561973e-07] 
Layer 'fc7' biases: 9.998496e-01 [1.460754e-07] 
Layer 'fc8' weights[0]: 1.274005e-03 [5.717812e-06] 
Layer 'fc8' biases: 9.967613e-02 [4.003311e-05] 
Train error last 870 batches: 0.435139
-------------------------------------------------------
Not saving because 0.417221 > 0.415628 (37.630: -0.00%)
======================================================= (12.050 sec)
40.71... logprob:  0.381783, 0.101562 (1.467 sec)
40.72... logprob:  0.493547, 0.132812 (1.413 sec)
40.73... logprob:  0.447598, 0.117188 (1.425 sec)
40.74... logprob:  0.442441, 0.117188 (1.418 sec)
40.75... logprob:  0.380670, 0.093750 (1.419 sec)
40.76... logprob:  0.412016, 0.109375 (1.437 sec)
40.77... logprob:  0.396348, 0.101562 (1.436 sec)
40.78... logprob:  0.493040, 0.140625 (1.458 sec)
40.79... logprob:  0.456507, 0.125000 (1.413 sec)
40.80... logprob:  0.508189, 0.132812 (1.435 sec)
40.81... logprob:  0.416725, 0.109375 (1.420 sec)
40.82... logprob:  0.230733, 0.039062 (1.428 sec)
40.83... logprob:  0.493920, 0.140625 (1.403 sec)
40.84... logprob:  0.468221, 0.125000 (1.471 sec)
40.85... logprob:  0.431838, 0.117188 (1.426 sec)
40.86... logprob:  0.416870, 0.109375 (1.416 sec)
40.87... logprob:  0.633444, 0.187500 (1.421 sec)
40.88... logprob:  0.534971, 0.156250 (1.416 sec)
40.89... logprob:  0.410463, 0.109375 (1.438 sec)
40.90... logprob:  0.577484, 0.171875 (1.390 sec)
40.91... logprob:  0.348295, 0.078125 (1.397 sec)
40.92... logprob:  0.464455, 0.125000 (1.405 sec)
40.93... logprob:  0.492150, 0.140625 (1.400 sec)
40.94... logprob:  0.428792, 0.109375 (1.407 sec)
40.95... logprob:  0.471824, 0.125000 (1.410 sec)
40.96... logprob:  0.576031, 0.171875 (1.404 sec)
40.97... logprob:  0.430824, 0.117188 (1.395 sec)
40.98... logprob:  0.391386, 0.093750 (1.446 sec)
40.99... logprob:  0.474143, 0.132812 (1.408 sec)
40.100... logprob:  0.310889, 0.070312 (1.402 sec)
40.101... logprob:  0.311321, 0.062500 (1.447 sec)
40.102... logprob:  0.545496, 0.156250 (1.420 sec)
40.103... logprob:  0.540501, 0.156250 (1.406 sec)
40.104... logprob:  0.388769, 0.101562 (1.413 sec)
40.105... logprob:  0.618755, 0.179688 (1.391 sec)
40.106... logprob:  0.344509, 0.085938 (1.398 sec)
40.107... logprob:  0.335897, 0.078125 (1.452 sec)
40.108... logprob:  0.586855, 0.171875 (1.396 sec)
40.109... logprob:  0.336073, 0.078125 (1.408 sec)
40.110... logprob:  0.564857, 0.164062 (1.405 sec)
40.111... logprob:  0.404616, 0.101562 (1.396 sec)
40.112... logprob:  0.365808, 0.093750 (1.406 sec)
40.113... logprob:  0.354188, 0.085938 (1.407 sec)
40.114... logprob:  0.440201, 0.117188 (1.435 sec)
40.115... logprob:  0.506873, 0.140625 (1.421 sec)
40.116... logprob:  0.393277, 0.101562 (1.396 sec)
40.117... logprob:  0.440396, 0.117188 (1.451 sec)
40.118... logprob:  0.409018, 0.101562 (1.395 sec)
40.119... logprob:  0.346004, 0.085938 (1.405 sec)
40.120... logprob:  0.547140, 0.156250 (1.408 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.69987106323242, 10.0]}, 128)
batch 872: ({'logprob': [66.46106719970703, 19.0]}, 128)
batch 873: ({'logprob': [40.686737060546875, 9.0]}, 128)
batch 874: ({'logprob': [45.23773956298828, 11.0]}, 128)
batch 875: ({'logprob': [50.77717208862305, 13.0]}, 128)
batch 876: ({'logprob': [63.97135925292969, 18.0]}, 128)
batch 877: ({'logprob': [45.74696731567383, 11.0]}, 128)
batch 878: ({'logprob': [61.923744201660156, 17.0]}, 128)
batch 879: ({'logprob': [73.51197814941406, 21.0]}, 128)
batch 880: ({'logprob': [50.80890655517578, 13.0]}, 128)
batch 881: ({'logprob': [29.055925369262695, 5.0]}, 128)
batch 882: ({'logprob': [54.83015823364258, 14.0]}, 128)
batch 883: ({'logprob': [61.889625549316406, 17.0]}, 128)
batch 884: ({'logprob': [51.2907600402832, 13.0]}, 128)
batch 885: ({'logprob': [52.2835693359375, 13.0]}, 128)
batch 886: ({'logprob': [62.41714859008789, 17.0]}, 128)

======================Test output======================
logprob:  0.416305, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.953157e-03 [3.040175e-09] 
Layer 'conv1' biases: 5.629025e-07 [5.704356e-11] 
Layer 'conv2' weights[0]: 7.940295e-03 [2.215689e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.607717e-10] 
Layer 'conv3' weights[0]: 7.938455e-03 [2.012109e-09] 
Layer 'conv3' biases: 4.744180e-06 [1.186615e-09] 
Layer 'conv4' weights[0]: 7.971177e-03 [1.956249e-09] 
Layer 'conv4' biases: 9.999989e-01 [9.020974e-09] 
Layer 'conv5' weights[0]: 7.969892e-03 [5.579288e-08] 
Layer 'conv5' biases: 9.999864e-01 [5.958011e-08] 
Layer 'fc6' weights[0]: 7.566298e-03 [4.608045e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.599732e-09] 
Layer 'fc7' weights[0]: 6.606293e-03 [4.318096e-08] 
Layer 'fc7' biases: 9.998487e-01 [2.367914e-08] 
Layer 'fc8' weights[0]: 1.250646e-03 [8.846648e-07] 
Layer 'fc8' biases: 9.961552e-02 [5.741347e-06] 
Train error last 870 batches: 0.435139
-------------------------------------------------------
Not saving because 0.416305 > 0.415628 (37.630: -0.00%)
======================================================= (12.097 sec)
40.121... logprob:  0.412536, 0.109375 (1.403 sec)
40.122... logprob:  0.519186, 0.148438 (1.454 sec)
40.123... logprob:  0.463614, 0.125000 (1.397 sec)
40.124... logprob:  0.447676, 0.125000 (1.411 sec)
40.125... logprob:  0.501839, 0.140625 (1.404 sec)
40.126... logprob:  0.475669, 0.125000 (1.393 sec)
40.127... logprob:  0.479389, 0.125000 (1.400 sec)
40.128... logprob:  0.422298, 0.109375 (1.421 sec)
40.129... logprob:  0.574869, 0.164062 (1.428 sec)
40.130... logprob:  0.382666, 0.093750 (1.424 sec)
40.131... logprob:  0.495496, 0.132812 (1.411 sec)
40.132... logprob:  0.506346, 0.140625 (1.436 sec)
40.133... logprob:  0.444711, 0.117188 (1.391 sec)
40.134... logprob:  0.401846, 0.101562 (1.397 sec)
40.135... logprob:  0.460146, 0.125000 (1.406 sec)
40.136... logprob:  0.562209, 0.164062 (1.408 sec)
40.137... logprob:  0.462611, 0.125000 (1.405 sec)
40.138... logprob:  0.319480, 0.070312 (1.449 sec)
40.139... logprob:  0.395704, 0.101562 (1.405 sec)
40.140... logprob:  0.559685, 0.164062 (1.411 sec)
40.141... logprob:  0.464621, 0.125000 (1.442 sec)
40.142... logprob:  0.464669, 0.125000 (1.405 sec)
40.143... logprob:  0.294581, 0.062500 (1.428 sec)
40.144... logprob:  0.456822, 0.125000 (1.434 sec)
40.145... logprob:  0.324598, 0.078125 (1.415 sec)
40.146... logprob:  0.482942, 0.132812 (1.415 sec)
40.147... logprob:  0.262513, 0.054688 (1.434 sec)
40.148... logprob:  0.458424, 0.125000 (1.396 sec)
40.149... logprob:  0.442445, 0.117188 (1.487 sec)
40.150... logprob:  0.347534, 0.085938 (1.407 sec)
40.151... logprob:  0.347123, 0.085938 (1.402 sec)
40.152... logprob:  0.785207, 0.234375 (1.388 sec)
40.153... logprob:  0.381623, 0.093750 (1.449 sec)
40.154... logprob:  0.524951, 0.148438 (1.408 sec)
40.155... logprob:  0.426225, 0.117188 (1.410 sec)
40.156... logprob:  0.294666, 0.062500 (1.438 sec)
40.157... logprob:  0.269541, 0.054688 (1.396 sec)
40.158... logprob:  0.455511, 0.125000 (1.405 sec)
40.159... logprob:  0.483155, 0.132812 (1.406 sec)
40.160... logprob:  0.444579, 0.117188 (1.398 sec)
40.161... logprob:  0.349313, 0.078125 (1.408 sec)
40.162... logprob:  0.611821, 0.179688 (1.406 sec)
40.163... logprob:  0.450549, 0.125000 (1.433 sec)
40.164... logprob:  0.468393, 0.125000 (1.426 sec)
40.165... logprob:  0.547627, 0.156250 (1.425 sec)
40.166... logprob:  0.446244, 0.125000 (1.456 sec)
40.167... logprob:  0.350767, 0.085938 (1.437 sec)
40.168... logprob:  0.363804, 0.085938 (1.422 sec)
40.169... logprob:  0.408582, 0.101562 (1.467 sec)
40.170... logprob:  0.459440, 0.125000 (1.408 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.041175842285156, 10.0]}, 128)
batch 872: ({'logprob': [66.06455993652344, 19.0]}, 128)
batch 873: ({'logprob': [41.30906295776367, 9.0]}, 128)
batch 874: ({'logprob': [45.58642578125, 11.0]}, 128)
batch 875: ({'logprob': [50.969635009765625, 13.0]}, 128)
batch 876: ({'logprob': [63.681880950927734, 18.0]}, 128)
batch 877: ({'logprob': [46.154579162597656, 11.0]}, 128)
batch 878: ({'logprob': [61.800846099853516, 17.0]}, 128)
batch 879: ({'logprob': [73.13117218017578, 21.0]}, 128)
batch 880: ({'logprob': [51.000877380371094, 13.0]}, 128)
batch 881: ({'logprob': [29.936534881591797, 5.0]}, 128)
batch 882: ({'logprob': [55.08732986450195, 14.0]}, 128)
batch 883: ({'logprob': [61.76701736450195, 17.0]}, 128)
batch 884: ({'logprob': [51.5389289855957, 13.0]}, 128)
batch 885: ({'logprob': [52.64778137207031, 13.0]}, 128)
batch 886: ({'logprob': [62.35116958618164, 17.0]}, 128)

======================Test output======================
logprob:  0.417514, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.953124e-03 [2.580853e-09] 
Layer 'conv1' biases: 5.640066e-07 [7.619693e-11] 
Layer 'conv2' weights[0]: 7.940261e-03 [2.421279e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.977617e-10] 
Layer 'conv3' weights[0]: 7.938413e-03 [2.378352e-09] 
Layer 'conv3' biases: 4.754894e-06 [1.223867e-09] 
Layer 'conv4' weights[0]: 7.971145e-03 [2.350521e-09] 
Layer 'conv4' biases: 9.999988e-01 [1.001174e-08] 
Layer 'conv5' weights[0]: 7.969844e-03 [5.982382e-08] 
Layer 'conv5' biases: 9.999864e-01 [6.395702e-08] 
Layer 'fc6' weights[0]: 7.566253e-03 [4.924455e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.929050e-09] 
Layer 'fc7' weights[0]: 6.604631e-03 [1.445742e-07] 
Layer 'fc7' biases: 9.998484e-01 [1.342525e-07] 
Layer 'fc8' weights[0]: 1.240027e-03 [5.382795e-06] 
Layer 'fc8' biases: 9.963358e-02 [4.068360e-05] 
Train error last 870 batches: 0.435139
-------------------------------------------------------
Not saving because 0.417514 > 0.415628 (37.630: -0.00%)
======================================================= (12.061 sec)
40.171... logprob:  0.535042, 0.156250 (1.438 sec)
40.172... logprob:  0.434739, 0.109375 (1.430 sec)
40.173... logprob:  0.440447, 0.117188 (1.425 sec)
40.174... logprob:  0.600286, 0.171875 (1.413 sec)
40.175... logprob:  0.505790, 0.140625 (1.470 sec)
40.176... logprob:  0.478333, 0.132812 (1.419 sec)
40.177... logprob:  0.289725, 0.054688 (1.425 sec)
40.178... logprob:  0.383480, 0.093750 (1.462 sec)
40.179... logprob:  0.394629, 0.101562 (1.410 sec)
40.180... logprob:  0.466400, 0.125000 (1.421 sec)
40.181... logprob:  0.539173, 0.156250 (1.422 sec)
40.182... logprob:  0.371189, 0.093750 (1.426 sec)
40.183... logprob:  0.419914, 0.109375 (1.421 sec)
40.184... logprob:  0.483413, 0.132812 (1.428 sec)
40.185... logprob:  0.289650, 0.062500 (1.397 sec)
40.186... logprob:  0.370233, 0.093750 (1.400 sec)
40.187... logprob:  0.529616, 0.148438 (1.412 sec)
40.188... logprob:  0.458775, 0.125000 (1.404 sec)
40.189... logprob:  0.440935, 0.117188 (1.391 sec)
40.190... logprob:  0.375818, 0.093750 (1.436 sec)
40.191... logprob:  0.485104, 0.132812 (1.411 sec)
40.192... logprob:  0.519941, 0.148438 (1.415 sec)
40.193... logprob:  0.312378, 0.070312 (1.425 sec)
40.194... logprob:  0.413996, 0.109375 (1.415 sec)
40.195... logprob:  0.286847, 0.062500 (1.410 sec)
40.196... logprob:  0.410383, 0.109375 (1.399 sec)
40.197... logprob:  0.477956, 0.132812 (1.403 sec)
40.198... logprob:  0.355800, 0.085938 (1.414 sec)
40.199... logprob:  0.437195, 0.117188 (1.390 sec)
40.200... logprob:  0.440699, 0.117188 (1.441 sec)
40.201... logprob:  0.437080, 0.117188 (1.406 sec)
40.202... logprob:  0.537739, 0.148438 (1.406 sec)
40.203... logprob:  0.420371, 0.109375 (1.449 sec)
40.204... logprob:  0.504123, 0.140625 (1.393 sec)
40.205... logprob:  0.334199, 0.078125 (1.409 sec)
40.206... logprob:  0.361643, 0.093750 (1.405 sec)
40.207... logprob:  0.381664, 0.093750 (1.392 sec)
40.208... logprob:  0.490640, 0.140625 (1.399 sec)
40.209... logprob:  0.334495, 0.078125 (1.423 sec)
40.210... logprob:  0.586213, 0.171875 (1.419 sec)
40.211... logprob:  0.488071, 0.132812 (1.442 sec)
40.212... logprob:  0.526091, 0.148438 (1.417 sec)
40.213... logprob:  0.514479, 0.140625 (1.460 sec)
40.214... logprob:  0.459360, 0.125000 (1.429 sec)
40.215... logprob:  0.396040, 0.101562 (1.416 sec)
40.216... logprob:  0.516772, 0.140625 (1.469 sec)
40.217... logprob:  0.324654, 0.070312 (1.404 sec)
40.218... logprob:  0.463503, 0.125000 (1.427 sec)
40.219... logprob:  0.500176, 0.140625 (1.423 sec)
40.220... logprob:  0.415050, 0.109375 (1.420 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.565765380859375, 10.0]}, 128)
batch 872: ({'logprob': [65.99219512939453, 19.0]}, 128)
batch 873: ({'logprob': [41.58420181274414, 9.0]}, 128)
batch 874: ({'logprob': [45.901885986328125, 11.0]}, 128)
batch 875: ({'logprob': [51.14258575439453, 13.0]}, 128)
batch 876: ({'logprob': [63.635009765625, 18.0]}, 128)
batch 877: ({'logprob': [46.37910842895508, 11.0]}, 128)
batch 878: ({'logprob': [61.6886100769043, 17.0]}, 128)
batch 879: ({'logprob': [72.64237976074219, 21.0]}, 128)
batch 880: ({'logprob': [51.174102783203125, 13.0]}, 128)
batch 881: ({'logprob': [30.589187622070312, 5.0]}, 128)
batch 882: ({'logprob': [54.95989227294922, 14.0]}, 128)
batch 883: ({'logprob': [61.65446853637695, 17.0]}, 128)
batch 884: ({'logprob': [51.61936950683594, 13.0]}, 128)
batch 885: ({'logprob': [52.54543685913086, 13.0]}, 128)
batch 886: ({'logprob': [62.146827697753906, 17.0]}, 128)

======================Test output======================
logprob:  0.418077, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.953091e-03 [3.316310e-09] 
Layer 'conv1' biases: 5.651600e-07 [9.420523e-11] 
Layer 'conv2' weights[0]: 7.940225e-03 [2.509827e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.006653e-10] 
Layer 'conv3' weights[0]: 7.938382e-03 [2.264712e-09] 
Layer 'conv3' biases: 4.766215e-06 [1.186271e-09] 
Layer 'conv4' weights[0]: 7.971108e-03 [2.256764e-09] 
Layer 'conv4' biases: 9.999989e-01 [1.014813e-08] 
Layer 'conv5' weights[0]: 7.969804e-03 [6.336192e-08] 
Layer 'conv5' biases: 9.999865e-01 [6.768659e-08] 
Layer 'fc6' weights[0]: 7.566220e-03 [5.132699e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.187160e-09] 
Layer 'fc7' weights[0]: 6.602980e-03 [9.607874e-08] 
Layer 'fc7' biases: 9.998481e-01 [8.294858e-08] 
Layer 'fc8' weights[0]: 1.232516e-03 [5.123392e-06] 
Layer 'fc8' biases: 9.965008e-02 [3.819291e-05] 
Train error last 870 batches: 0.435138
-------------------------------------------------------
Not saving because 0.418077 > 0.415628 (37.630: -0.00%)
======================================================= (12.061 sec)
40.221... logprob:  0.399598, 0.101562 (1.413 sec)
40.222... logprob:  0.554272, 0.164062 (1.463 sec)
40.223... logprob:  0.568709, 0.164062 (1.436 sec)
40.224... logprob:  0.406065, 0.101562 (1.440 sec)
40.225... logprob:  0.392047, 0.101562 (1.449 sec)
40.226... logprob:  0.424836, 0.109375 (1.426 sec)
40.227... logprob:  0.452548, 0.125000 (1.424 sec)
40.228... logprob:  0.417159, 0.109375 (1.418 sec)
40.229... logprob:  0.489368, 0.132812 (1.419 sec)
40.230... logprob:  0.459813, 0.125000 (1.434 sec)
40.231... logprob:  0.453438, 0.125000 (1.412 sec)
40.232... logprob:  0.496095, 0.140625 (1.463 sec)
40.233... logprob:  0.465972, 0.132812 (1.430 sec)
40.234... logprob:  0.563916, 0.164062 (1.420 sec)
40.235... logprob:  0.482003, 0.132812 (1.473 sec)
40.236... logprob:  0.425534, 0.109375 (1.400 sec)
40.237... logprob:  0.340611, 0.078125 (1.424 sec)
40.238... logprob:  0.388893, 0.093750 (1.419 sec)
40.239... logprob:  0.478052, 0.132812 (1.425 sec)
40.240... logprob:  0.485792, 0.132812 (1.405 sec)
40.241... logprob:  0.493609, 0.132812 (1.460 sec)
40.242... logprob:  0.341594, 0.078125 (1.431 sec)
40.243... logprob:  0.385973, 0.093750 (1.435 sec)
40.244... logprob:  0.315552, 0.070312 (1.448 sec)
40.245... logprob:  0.494115, 0.132812 (1.426 sec)
40.246... logprob:  0.416807, 0.109375 (1.420 sec)
40.247... logprob:  0.357757, 0.085938 (1.424 sec)
40.248... logprob:  0.308312, 0.070312 (1.425 sec)
40.249... logprob:  0.553876, 0.156250 (1.421 sec)
40.250... logprob:  0.590719, 0.164062 (1.407 sec)
40.251... logprob:  0.353068, 0.085938 (1.465 sec)
40.252... logprob:  0.348397, 0.085938 (1.426 sec)
40.253... logprob:  0.379277, 0.093750 (1.417 sec)
40.254... logprob:  0.444137, 0.117188 (1.474 sec)
40.255... logprob:  0.351210, 0.085938 (1.411 sec)
40.256... logprob:  0.378963, 0.093750 (1.430 sec)
40.257... logprob:  0.331924, 0.078125 (1.419 sec)
40.258... logprob:  0.415326, 0.109375 (1.426 sec)
40.259... logprob:  0.442323, 0.117188 (1.404 sec)
40.260... logprob:  0.308036, 0.070312 (1.460 sec)
40.261... logprob:  0.392358, 0.101562 (1.428 sec)
40.262... logprob:  0.524375, 0.148438 (1.432 sec)
40.263... logprob:  0.425710, 0.109375 (1.454 sec)
40.264... logprob:  0.374924, 0.093750 (1.430 sec)
40.265... logprob:  0.439608, 0.117188 (1.422 sec)
40.266... logprob:  0.438993, 0.117188 (1.420 sec)
40.267... logprob:  0.422068, 0.109375 (1.418 sec)
40.268... logprob:  0.458947, 0.125000 (1.430 sec)
40.269... logprob:  0.567691, 0.164062 (1.408 sec)
40.270... logprob:  0.542456, 0.156250 (1.463 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.640926361083984, 10.0]}, 128)
batch 872: ({'logprob': [66.309326171875, 19.0]}, 128)
batch 873: ({'logprob': [41.15077209472656, 9.0]}, 128)
batch 874: ({'logprob': [45.78670120239258, 11.0]}, 128)
batch 875: ({'logprob': [51.06450653076172, 13.0]}, 128)
batch 876: ({'logprob': [63.863914489746094, 18.0]}, 128)
batch 877: ({'logprob': [46.123756408691406, 11.0]}, 128)
batch 878: ({'logprob': [61.68783950805664, 17.0]}, 128)
batch 879: ({'logprob': [72.5794677734375, 21.0]}, 128)
batch 880: ({'logprob': [51.09680938720703, 13.0]}, 128)
batch 881: ({'logprob': [30.218265533447266, 5.0]}, 128)
batch 882: ({'logprob': [54.552677154541016, 14.0]}, 128)
batch 883: ({'logprob': [61.653141021728516, 17.0]}, 128)
batch 884: ({'logprob': [51.40304183959961, 13.0]}, 128)
batch 885: ({'logprob': [52.04906463623047, 13.0]}, 128)
batch 886: ({'logprob': [62.00664520263672, 17.0]}, 128)

======================Test output======================
logprob:  0.417083, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.953047e-03 [5.986254e-09] 
Layer 'conv1' biases: 5.664315e-07 [1.886468e-10] 
Layer 'conv2' weights[0]: 7.940183e-03 [5.113246e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.061847e-09] 
Layer 'conv3' weights[0]: 7.938341e-03 [4.679120e-09] 
Layer 'conv3' biases: 4.777309e-06 [3.104956e-09] 
Layer 'conv4' weights[0]: 7.971073e-03 [4.596801e-09] 
Layer 'conv4' biases: 9.999989e-01 [2.485380e-08] 
Layer 'conv5' weights[0]: 7.969780e-03 [1.504830e-07] 
Layer 'conv5' biases: 9.999870e-01 [1.609790e-07] 
Layer 'fc6' weights[0]: 7.566183e-03 [1.207739e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.239431e-08] 
Layer 'fc7' weights[0]: 6.601281e-03 [3.276215e-07] 
Layer 'fc7' biases: 9.998478e-01 [3.208941e-07] 
Layer 'fc8' weights[0]: 1.243350e-03 [1.250435e-05] 
Layer 'fc8' biases: 9.981426e-02 [8.847955e-05] 
Train error last 870 batches: 0.435138
-------------------------------------------------------
Not saving because 0.417083 > 0.415628 (37.630: -0.00%)
======================================================= (12.052 sec)
40.271... logprob:  0.445488, 0.117188 (1.436 sec)
40.272... logprob:  0.384385, 0.093750 (1.425 sec)
40.273... logprob:  0.500252, 0.140625 (1.472 sec)
40.274... logprob:  0.542495, 0.156250 (1.404 sec)
40.275... logprob:  0.487452, 0.132812 (1.428 sec)
40.276... logprob:  0.389864, 0.093750 (1.424 sec)
40.277... logprob:  0.428506, 0.109375 (1.431 sec)
40.278... logprob:  0.323794, 0.070312 (1.432 sec)
40.279... logprob:  0.325546, 0.070312 (1.466 sec)
40.280... logprob:  0.216724, 0.031250 (1.402 sec)
40.281... logprob:  0.417306, 0.109375 (1.428 sec)
40.282... logprob:  0.411228, 0.109375 (1.421 sec)
40.283... logprob:  0.393646, 0.101562 (1.418 sec)
40.284... logprob:  0.394133, 0.101562 (1.411 sec)
40.285... logprob:  0.450776, 0.117188 (1.440 sec)
40.286... logprob:  0.535251, 0.140625 (1.440 sec)
40.287... logprob:  0.346418, 0.085938 (1.432 sec)
40.288... logprob:  0.329919, 0.078125 (1.437 sec)
40.289... logprob:  0.445584, 0.117188 (1.450 sec)
40.290... logprob:  0.490603, 0.132812 (1.413 sec)
40.291... logprob:  0.439442, 0.117188 (1.418 sec)
40.292... logprob:  0.568216, 0.156250 (1.421 sec)
40.293... logprob:  0.427994, 0.117188 (1.425 sec)
40.294... logprob:  0.355387, 0.085938 (1.405 sec)
40.295... logprob:  0.333715, 0.078125 (1.465 sec)
40.296... logprob:  0.354889, 0.085938 (1.420 sec)
40.297... logprob:  0.393994, 0.101562 (1.428 sec)
40.298... logprob:  0.448385, 0.125000 (1.469 sec)
40.299... logprob:  0.341341, 0.078125 (1.403 sec)
40.300... logprob:  0.406081, 0.101562 (1.430 sec)
40.301... logprob:  0.397791, 0.101562 (1.423 sec)
40.302... logprob:  0.591727, 0.179688 (1.418 sec)
40.303... logprob:  0.459394, 0.125000 (1.416 sec)
40.304... logprob:  0.459556, 0.125000 (1.445 sec)
40.305... logprob:  0.455176, 0.125000 (1.439 sec)
40.306... logprob:  0.440551, 0.117188 (1.441 sec)
40.307... logprob:  0.421644, 0.109375 (1.447 sec)
40.308... logprob:  0.375061, 0.093750 (1.458 sec)
40.309... logprob:  0.450492, 0.125000 (1.418 sec)
40.310... logprob:  0.473428, 0.125000 (1.436 sec)
40.311... logprob:  0.502283, 0.140625 (1.428 sec)
40.312... logprob:  0.478575, 0.132812 (1.438 sec)
40.313... logprob:  0.454846, 0.125000 (1.428 sec)
40.314... logprob:  0.454218, 0.117188 (1.465 sec)
40.315... logprob:  0.314737, 0.070312 (1.435 sec)
40.316... logprob:  0.468446, 0.125000 (1.425 sec)
40.317... logprob:  0.355392, 0.085938 (1.481 sec)
40.318... logprob:  0.455389, 0.125000 (1.411 sec)
40.319... logprob:  0.423137, 0.117188 (1.454 sec)
40.320... logprob:  0.412216, 0.109375 (1.428 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.462554931640625, 10.0]}, 128)
batch 872: ({'logprob': [66.55157470703125, 19.0]}, 128)
batch 873: ({'logprob': [40.612117767333984, 9.0]}, 128)
batch 874: ({'logprob': [45.126731872558594, 11.0]}, 128)
batch 875: ({'logprob': [50.745243072509766, 13.0]}, 128)
batch 876: ({'logprob': [64.0512924194336, 18.0]}, 128)
batch 877: ({'logprob': [45.69349670410156, 11.0]}, 128)
batch 878: ({'logprob': [62.050392150878906, 17.0]}, 128)
batch 879: ({'logprob': [73.85409545898438, 21.0]}, 128)
batch 880: ({'logprob': [50.777278900146484, 13.0]}, 128)
batch 881: ({'logprob': [28.764892578125, 5.0]}, 128)
batch 882: ({'logprob': [54.98239517211914, 14.0]}, 128)
batch 883: ({'logprob': [62.01605987548828, 17.0]}, 128)
batch 884: ({'logprob': [51.3171272277832, 13.0]}, 128)
batch 885: ({'logprob': [52.424964904785156, 13.0]}, 128)
batch 886: ({'logprob': [62.60179901123047, 17.0]}, 128)

======================Test output======================
logprob:  0.416520, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.953012e-03 [2.564517e-09] 
Layer 'conv1' biases: 5.675737e-07 [4.447601e-11] 
Layer 'conv2' weights[0]: 7.940144e-03 [1.906101e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.949877e-10] 
Layer 'conv3' weights[0]: 7.938302e-03 [1.447406e-09] 
Layer 'conv3' biases: 4.782541e-06 [5.687169e-10] 
Layer 'conv4' weights[0]: 7.971033e-03 [1.521526e-09] 
Layer 'conv4' biases: 9.999989e-01 [4.036766e-09] 
Layer 'conv5' weights[0]: 7.969732e-03 [2.498867e-08] 
Layer 'conv5' biases: 9.999862e-01 [2.665026e-08] 
Layer 'fc6' weights[0]: 7.566144e-03 [2.179299e-09] 
Layer 'fc6' biases: 1.000000e+00 [2.041546e-09] 
Layer 'fc7' weights[0]: 6.599611e-03 [1.195470e-07] 
Layer 'fc7' biases: 9.998487e-01 [1.067204e-07] 
Layer 'fc8' weights[0]: 1.262062e-03 [3.711223e-06] 
Layer 'fc8' biases: 1.002432e-01 [2.752076e-05] 
Train error last 870 batches: 0.435138
-------------------------------------------------------
Not saving because 0.416520 > 0.415628 (37.630: -0.00%)
======================================================= (12.079 sec)
40.321... logprob:  0.348201, 0.085938 (1.431 sec)
40.322... logprob:  0.387377, 0.101562 (1.424 sec)
40.323... logprob:  0.416487, 0.109375 (1.470 sec)
40.324... logprob:  0.498585, 0.140625 (1.431 sec)
40.325... logprob:  0.350661, 0.085938 (1.436 sec)
40.326... logprob:  0.543199, 0.148438 (1.466 sec)
40.327... logprob:  0.554467, 0.164062 (1.424 sec)
40.328... logprob:  0.565266, 0.156250 (1.425 sec)
40.329... logprob:  0.401840, 0.101562 (1.426 sec)
40.330... logprob:  0.388370, 0.101562 (1.423 sec)
40.331... logprob:  0.352016, 0.085938 (1.417 sec)
40.332... logprob:  0.482793, 0.132812 (1.455 sec)
40.333... logprob:  0.339302, 0.085938 (1.446 sec)
40.334... logprob:  0.565464, 0.171875 (1.448 sec)
40.335... logprob:  0.358534, 0.085938 (1.442 sec)
40.336... logprob:  0.444883, 0.125000 (1.460 sec)
40.337... logprob:  0.566357, 0.164062 (1.422 sec)
40.338... logprob:  0.449520, 0.125000 (1.427 sec)
40.339... logprob:  0.488500, 0.132812 (1.436 sec)
40.340... logprob:  0.442055, 0.117188 (1.432 sec)
40.341... logprob:  0.529929, 0.148438 (1.422 sec)
40.342... logprob:  0.429557, 0.109375 (1.467 sec)
40.343... logprob:  0.434757, 0.109375 (1.444 sec)
40.344... logprob:  0.444606, 0.125000 (1.498 sec)
40.345... logprob:  0.488132, 0.132812 (1.438 sec)
40.346... logprob:  0.436192, 0.117188 (1.440 sec)
40.347... logprob:  0.372711, 0.085938 (1.485 sec)
40.348... logprob:  0.398550, 0.101562 (1.436 sec)
40.349... logprob:  0.497383, 0.140625 (1.437 sec)
40.350... logprob:  0.358854, 0.085938 (1.435 sec)
40.351... logprob:  0.508339, 0.140625 (1.431 sec)
40.352... logprob:  0.363587, 0.093750 (1.460 sec)
40.353... logprob:  0.512170, 0.148438 (1.489 sec)
40.354... logprob:  0.674491, 0.203125 (1.432 sec)
40.355... logprob:  0.357531, 0.085938 (1.449 sec)
40.356... logprob:  0.479237, 0.132812 (1.481 sec)
40.357... logprob:  0.346502, 0.085938 (1.433 sec)
40.358... logprob:  0.325544, 0.070312 (1.455 sec)
40.359... logprob:  0.555514, 0.164062 (1.436 sec)
40.360... logprob:  0.444540, 0.117188 (1.432 sec)
40.361... logprob:  0.410698, 0.101562 (1.440 sec)
40.362... logprob:  0.423797, 0.117188 (1.477 sec)
40.363... logprob:  0.486619, 0.132812 (1.445 sec)
40.364... logprob:  0.475684, 0.125000 (1.454 sec)
40.365... logprob:  0.425010, 0.109375 (1.465 sec)
40.366... logprob:  0.409463, 0.109375 (1.446 sec)
40.367... logprob:  0.324801, 0.078125 (1.444 sec)
40.368... logprob:  0.595479, 0.171875 (1.481 sec)
40.369... logprob:  0.381755, 0.093750 (1.423 sec)
40.370... logprob:  0.381397, 0.093750 (1.443 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.85116958618164, 10.0]}, 128)
batch 872: ({'logprob': [66.45563507080078, 19.0]}, 128)
batch 873: ({'logprob': [40.69632339477539, 9.0]}, 128)
batch 874: ({'logprob': [45.29970932006836, 11.0]}, 128)
batch 875: ({'logprob': [50.79903030395508, 13.0]}, 128)
batch 876: ({'logprob': [63.96308135986328, 18.0]}, 128)
batch 877: ({'logprob': [45.76307678222656, 11.0]}, 128)
batch 878: ({'logprob': [61.86631393432617, 17.0]}, 128)
batch 879: ({'logprob': [73.32848358154297, 21.0]}, 128)
batch 880: ({'logprob': [50.83149719238281, 13.0]}, 128)
batch 881: ({'logprob': [29.191608428955078, 5.0]}, 128)
batch 882: ({'logprob': [54.717124938964844, 14.0]}, 128)
batch 883: ({'logprob': [61.83161926269531, 17.0]}, 128)
batch 884: ({'logprob': [51.26662063598633, 13.0]}, 128)
batch 885: ({'logprob': [52.16694641113281, 13.0]}, 128)
batch 886: ({'logprob': [62.31344985961914, 17.0]}, 128)

======================Test output======================
logprob:  0.416182, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.952973e-03 [3.004850e-09] 
Layer 'conv1' biases: 5.686150e-07 [7.883093e-11] 
Layer 'conv2' weights[0]: 7.940113e-03 [2.482394e-09] 
Layer 'conv2' biases: 1.000000e+00 [3.938607e-10] 
Layer 'conv3' weights[0]: 7.938254e-03 [2.258007e-09] 
Layer 'conv3' biases: 4.793136e-06 [1.203872e-09] 
Layer 'conv4' weights[0]: 7.970999e-03 [2.200673e-09] 
Layer 'conv4' biases: 9.999989e-01 [9.560843e-09] 
Layer 'conv5' weights[0]: 7.969697e-03 [5.469928e-08] 
Layer 'conv5' biases: 9.999864e-01 [5.840155e-08] 
Layer 'fc6' weights[0]: 7.566105e-03 [4.534688e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.522247e-09] 
Layer 'fc7' weights[0]: 6.597925e-03 [9.849471e-08] 
Layer 'fc7' biases: 9.998481e-01 [8.540405e-08] 
Layer 'fc8' weights[0]: 1.255673e-03 [6.267367e-06] 
Layer 'fc8' biases: 1.002894e-01 [4.524926e-05] 
Train error last 870 batches: 0.435137
-------------------------------------------------------
Not saving because 0.416182 > 0.415628 (37.630: -0.00%)
======================================================= (12.079 sec)
40.371... logprob:  0.400486, 0.101562 (1.464 sec)
40.372... logprob:  0.536938, 0.156250 (1.458 sec)
40.373... logprob:  0.463758, 0.125000 (1.461 sec)
40.374... logprob:  0.526621, 0.148438 (1.449 sec)
40.375... logprob:  0.393757, 0.101562 (1.473 sec)
40.376... logprob:  0.374283, 0.093750 (1.441 sec)
40.377... logprob:  0.295510, 0.062500 (1.429 sec)
40.378... logprob:  0.453577, 0.125000 (1.431 sec)
40.379... logprob:  0.420255, 0.109375 (1.441 sec)
40.380... logprob:  0.605566, 0.179688 (1.440 sec)
40.381... logprob:  0.463365, 0.125000 (1.471 sec)
40.382... logprob:  0.529638, 0.148438 (1.450 sec)
40.383... logprob:  0.358414, 0.085938 (1.439 sec)
40.384... logprob:  0.521348, 0.148438 (1.485 sec)
40.385... logprob:  0.523686, 0.148438 (1.457 sec)
40.386... logprob:  0.582799, 0.171875 (1.432 sec)
40.387... logprob:  0.428360, 0.117188 (1.435 sec)
40.388... logprob:  0.521446, 0.148438 (1.429 sec)
40.389... logprob:  0.425289, 0.109375 (1.435 sec)
40.390... logprob:  0.419438, 0.109375 (1.480 sec)
40.391... logprob:  0.317896, 0.070312 (1.445 sec)
40.392... logprob:  0.439450, 0.117188 (1.437 sec)
40.393... logprob:  0.369157, 0.093750 (1.484 sec)
40.394... logprob:  0.343878, 0.078125 (1.438 sec)
40.395... logprob:  0.332204, 0.078125 (1.430 sec)
40.396... logprob:  0.253228, 0.046875 (1.439 sec)
40.397... logprob:  0.483576, 0.132812 (1.434 sec)
40.398... logprob:  0.470016, 0.125000 (1.434 sec)
40.399... logprob:  0.432678, 0.117188 (1.487 sec)
40.400... logprob:  0.536407, 0.148438 (1.435 sec)
40.401... logprob:  0.465127, 0.125000 (1.443 sec)
40.402... logprob:  0.473395, 0.125000 (1.486 sec)
40.403... logprob:  0.461934, 0.125000 (1.440 sec)
40.404... logprob:  0.474745, 0.125000 (1.434 sec)
40.405... logprob:  0.544597, 0.156250 (1.432 sec)
40.406... logprob:  0.357251, 0.085938 (1.445 sec)
40.407... logprob:  0.493353, 0.140625 (1.436 sec)
40.408... logprob:  0.338103, 0.078125 (1.484 sec)
40.409... logprob:  0.399902, 0.101562 (1.449 sec)
40.410... logprob:  0.582850, 0.171875 (1.459 sec)
40.411... logprob:  0.397228, 0.101562 (1.486 sec)
40.412... logprob:  0.540458, 0.156250 (1.438 sec)
40.413... logprob:  0.544644, 0.156250 (1.439 sec)
40.414... logprob:  0.466132, 0.125000 (1.433 sec)
40.415... logprob:  0.401455, 0.101562 (1.426 sec)
40.416... logprob:  0.427370, 0.109375 (1.444 sec)
40.417... logprob:  0.405432, 0.093750 (1.464 sec)
40.418... logprob:  0.380768, 0.093750 (1.455 sec)
40.419... logprob:  0.418147, 0.101562 (1.458 sec)
40.420... logprob:  0.357042, 0.085938 (1.458 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.793121337890625, 10.0]}, 128)
batch 872: ({'logprob': [66.32026672363281, 19.0]}, 128)
batch 873: ({'logprob': [40.876617431640625, 9.0]}, 128)
batch 874: ({'logprob': [45.33667755126953, 11.0]}, 128)
batch 875: ({'logprob': [50.826820373535156, 13.0]}, 128)
batch 876: ({'logprob': [63.86543655395508, 18.0]}, 128)
batch 877: ({'logprob': [45.866905212402344, 11.0]}, 128)
batch 878: ({'logprob': [61.87404251098633, 17.0]}, 128)
batch 879: ({'logprob': [73.38289642333984, 21.0]}, 128)
batch 880: ({'logprob': [50.85870361328125, 13.0]}, 128)
batch 881: ({'logprob': [29.325225830078125, 5.0]}, 128)
batch 882: ({'logprob': [54.906131744384766, 14.0]}, 128)
batch 883: ({'logprob': [61.839813232421875, 17.0]}, 128)
batch 884: ({'logprob': [51.36048126220703, 13.0]}, 128)
batch 885: ({'logprob': [52.39427185058594, 13.0]}, 128)
batch 886: ({'logprob': [62.3876838684082, 17.0]}, 128)

======================Test output======================
logprob:  0.416609, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.952929e-03 [4.542051e-09] 
Layer 'conv1' biases: 5.697052e-07 [2.312732e-10] 
Layer 'conv2' weights[0]: 7.940075e-03 [5.237238e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.084826e-09] 
Layer 'conv3' weights[0]: 7.938214e-03 [5.085389e-09] 
Layer 'conv3' biases: 4.798194e-06 [3.095887e-09] 
Layer 'conv4' weights[0]: 7.970962e-03 [4.871397e-09] 
Layer 'conv4' biases: 9.999988e-01 [2.551922e-08] 
Layer 'conv5' weights[0]: 7.969655e-03 [1.533093e-07] 
Layer 'conv5' biases: 9.999859e-01 [1.640806e-07] 
Layer 'fc6' weights[0]: 7.566065e-03 [1.227275e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.261578e-08] 
Layer 'fc7' weights[0]: 6.596236e-03 [3.852303e-07] 
Layer 'fc7' biases: 9.998482e-01 [3.767468e-07] 
Layer 'fc8' weights[0]: 1.247722e-03 [1.670819e-05] 
Layer 'fc8' biases: 1.005017e-01 [1.257067e-04] 
Train error last 870 batches: 0.435137
-------------------------------------------------------
Not saving because 0.416609 > 0.415628 (37.630: -0.00%)
======================================================= (12.037 sec)
40.421... logprob:  0.376827, 0.101562 (1.468 sec)
40.422... logprob:  0.521170, 0.148438 (1.448 sec)
40.423... logprob:  0.420614, 0.109375 (1.433 sec)
40.424... logprob:  0.325252, 0.078125 (1.431 sec)
40.425... logprob:  0.306924, 0.070312 (1.446 sec)
40.426... logprob:  0.448609, 0.117188 (1.450 sec)
40.427... logprob:  0.552993, 0.156250 (1.465 sec)
40.428... logprob:  0.600671, 0.171875 (1.453 sec)
40.429... logprob:  0.426392, 0.109375 (1.448 sec)
40.430... logprob:  0.299626, 0.070312 (1.480 sec)
40.431... logprob:  0.600672, 0.171875 (1.435 sec)
40.432... logprob:  0.387492, 0.093750 (1.427 sec)
40.433... logprob:  0.329049, 0.078125 (1.437 sec)
40.434... logprob:  0.530199, 0.148438 (1.438 sec)
40.435... logprob:  0.533020, 0.156250 (1.433 sec)
40.436... logprob:  0.380326, 0.093750 (1.480 sec)
40.437... logprob:  0.500478, 0.140625 (1.446 sec)
40.438... logprob:  0.547280, 0.156250 (1.433 sec)
40.439... logprob:  0.377923, 0.093750 (1.491 sec)
40.440... logprob:  0.439392, 0.117188 (1.437 sec)
40.441... logprob:  0.467832, 0.125000 (1.430 sec)
40.442... logprob:  0.378834, 0.093750 (1.438 sec)
40.443... logprob:  0.496538, 0.140625 (1.435 sec)
40.444... logprob:  0.372671, 0.093750 (1.433 sec)
40.445... logprob:  0.363065, 0.085938 (1.483 sec)
40.446... logprob:  0.398689, 0.101562 (1.441 sec)
40.447... logprob:  0.568712, 0.164062 (1.443 sec)
40.448... logprob:  0.333567, 0.078125 (1.491 sec)
40.449... logprob:  0.400107, 0.101562 (1.434 sec)
40.450... logprob:  0.240720, 0.046875 (1.432 sec)
40.451... logprob:  0.451988, 0.125000 (1.440 sec)
40.452... logprob:  0.455590, 0.117188 (1.429 sec)
40.453... logprob:  0.454617, 0.125000 (1.438 sec)
40.454... logprob:  0.488426, 0.132812 (1.486 sec)
40.455... logprob:  0.505786, 0.140625 (1.434 sec)
40.456... logprob:  0.468818, 0.125000 (1.452 sec)
40.457... logprob:  0.375272, 0.093750 (1.476 sec)
40.458... logprob:  0.350768, 0.085938 (1.437 sec)
40.459... logprob:  0.514468, 0.140625 (1.473 sec)
40.460... logprob:  0.272852, 0.054688 (1.435 sec)
40.461... logprob:  0.460303, 0.125000 (1.424 sec)
40.462... logprob:  0.472130, 0.125000 (1.432 sec)
40.463... logprob:  0.420685, 0.109375 (1.479 sec)
40.464... logprob:  0.482947, 0.132812 (1.450 sec)
40.465... logprob:  0.420985, 0.109375 (1.453 sec)
40.466... logprob:  0.317831, 0.070312 (1.462 sec)
40.467... logprob:  0.413762, 0.109375 (1.454 sec)
40.468... logprob:  0.394208, 0.101562 (1.434 sec)
40.469... logprob:  0.334860, 0.078125 (1.432 sec)
40.470... logprob:  0.400143, 0.101562 (1.439 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.591026306152344, 10.0]}, 128)
batch 872: ({'logprob': [66.79515075683594, 19.0]}, 128)
batch 873: ({'logprob': [40.3172607421875, 9.0]}, 128)
batch 874: ({'logprob': [45.08293151855469, 11.0]}, 128)
batch 875: ({'logprob': [50.713157653808594, 13.0]}, 128)
batch 876: ({'logprob': [64.2293930053711, 18.0]}, 128)
batch 877: ({'logprob': [45.530296325683594, 11.0]}, 128)
batch 878: ({'logprob': [62.04349136352539, 17.0]}, 128)
batch 879: ({'logprob': [73.7538070678711, 21.0]}, 128)
batch 880: ({'logprob': [50.74563217163086, 13.0]}, 128)
batch 881: ({'logprob': [28.56410789489746, 5.0]}, 128)
batch 882: ({'logprob': [54.65951156616211, 14.0]}, 128)
batch 883: ({'logprob': [62.00883102416992, 17.0]}, 128)
batch 884: ({'logprob': [51.166900634765625, 13.0]}, 128)
batch 885: ({'logprob': [52.0365104675293, 13.0]}, 128)
batch 886: ({'logprob': [62.47605514526367, 17.0]}, 128)

======================Test output======================
logprob:  0.415876, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.952889e-03 [4.037323e-09] 
Layer 'conv1' biases: 5.706967e-07 [1.288224e-10] 
Layer 'conv2' weights[0]: 7.940044e-03 [3.325078e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.022803e-10] 
Layer 'conv3' weights[0]: 7.938178e-03 [3.056292e-09] 
Layer 'conv3' biases: 4.808139e-06 [1.703680e-09] 
Layer 'conv4' weights[0]: 7.970924e-03 [3.075601e-09] 
Layer 'conv4' biases: 9.999988e-01 [1.395053e-08] 
Layer 'conv5' weights[0]: 7.969625e-03 [8.523356e-08] 
Layer 'conv5' biases: 9.999860e-01 [9.112227e-08] 
Layer 'fc6' weights[0]: 7.566027e-03 [6.916538e-09] 
Layer 'fc6' biases: 1.000000e+00 [7.024088e-09] 
Layer 'fc7' weights[0]: 6.594551e-03 [2.110782e-07] 
Layer 'fc7' biases: 9.998487e-01 [2.016389e-07] 
Layer 'fc8' weights[0]: 1.257924e-03 [7.875615e-06] 
Layer 'fc8' biases: 1.008933e-01 [5.833577e-05] 
Train error last 870 batches: 0.435137
-------------------------------------------------------
Not saving because 0.415876 > 0.415628 (37.630: -0.00%)
======================================================= (12.040 sec)
40.471... logprob:  0.528886, 0.148438 (1.443 sec)
40.472... logprob:  0.409910, 0.109375 (1.463 sec)
40.473... logprob:  0.375608, 0.093750 (1.574 sec)
40.474... logprob:  0.465257, 0.125000 (1.453 sec)
40.475... logprob:  0.503425, 0.140625 (1.454 sec)
40.476... logprob:  0.509819, 0.140625 (1.468 sec)
40.477... logprob:  0.334816, 0.078125 (1.435 sec)
40.478... logprob:  0.464158, 0.125000 (1.432 sec)
40.479... logprob:  0.305810, 0.070312 (1.431 sec)
40.480... logprob:  0.443481, 0.117188 (1.441 sec)
40.481... logprob:  0.547825, 0.156250 (1.438 sec)
40.482... logprob:  0.443096, 0.117188 (1.474 sec)
40.483... logprob:  0.502797, 0.140625 (1.448 sec)
40.484... logprob:  0.485357, 0.132812 (1.440 sec)
40.485... logprob:  0.408774, 0.109375 (1.485 sec)
40.486... logprob:  0.360964, 0.085938 (1.432 sec)
40.487... logprob:  0.522801, 0.148438 (1.431 sec)
40.488... logprob:  0.424551, 0.109375 (1.441 sec)
40.489... logprob:  0.415685, 0.109375 (1.437 sec)
40.490... logprob:  0.440667, 0.117188 (1.433 sec)
40.491... logprob:  0.313452, 0.070312 (1.483 sec)
40.492... logprob:  0.459458, 0.125000 (1.477 sec)
40.493... logprob:  0.521678, 0.148438 (1.437 sec)
40.494... logprob:  0.450321, 0.125000 (1.484 sec)
40.495... logprob:  0.380796, 0.093750 (1.430 sec)
40.496... logprob:  0.549936, 0.156250 (1.438 sec)
40.497... logprob:  0.466769, 0.125000 (1.437 sec)
40.498... logprob:  0.476104, 0.132812 (1.438 sec)
40.499... logprob:  0.456177, 0.125000 (1.441 sec)
40.500... logprob:  0.355248, 0.085938 (1.490 sec)
40.501... logprob:  0.339164, 0.078125 (1.432 sec)
40.502... logprob:  0.459547, 0.125000 (1.447 sec)
40.503... logprob:  0.400644, 0.101562 (1.487 sec)
40.504... logprob:  0.487209, 0.132812 (1.433 sec)
40.505... logprob:  0.570696, 0.164062 (1.441 sec)
40.506... logprob:  0.479681, 0.132812 (1.434 sec)
40.507... logprob:  0.384936, 0.093750 (1.428 sec)
40.508... logprob:  0.374575, 0.093750 (1.437 sec)
40.509... logprob:  0.322803, 0.070312 (1.479 sec)
40.510... logprob:  0.390434, 0.101562 (1.444 sec)
40.511... logprob:  0.410013, 0.109375 (1.456 sec)
40.512... logprob:  0.470693, 0.125000 (1.470 sec)
40.513... logprob:  0.324947, 0.078125 (1.450 sec)
40.514... logprob:  0.406270, 0.101562 (1.445 sec)
40.515... logprob:  0.455349, 0.125000 (1.429 sec)
40.516... logprob:  0.400122, 0.109375 (1.430 sec)
40.517... logprob:  0.627474, 0.179688 (1.441 sec)
40.518... logprob:  0.437584, 0.117188 (1.458 sec)
40.519... logprob:  0.516120, 0.140625 (1.461 sec)
40.520... logprob:  0.409630, 0.109375 (1.460 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.917823791503906, 10.0]}, 128)
batch 872: ({'logprob': [66.40414428710938, 19.0]}, 128)
batch 873: ({'logprob': [40.768131256103516, 9.0]}, 128)
batch 874: ({'logprob': [45.34967041015625, 11.0]}, 128)
batch 875: ({'logprob': [50.82272720336914, 13.0]}, 128)
batch 876: ({'logprob': [63.92351150512695, 18.0]}, 128)
batch 877: ({'logprob': [45.81080627441406, 11.0]}, 128)
batch 878: ({'logprob': [61.83695983886719, 17.0]}, 128)
batch 879: ({'logprob': [73.2440414428711, 21.0]}, 128)
batch 880: ({'logprob': [50.854984283447266, 13.0]}, 128)
batch 881: ({'logprob': [29.318986892700195, 5.0]}, 128)
batch 882: ({'logprob': [54.721744537353516, 14.0]}, 128)
batch 883: ({'logprob': [61.80231857299805, 17.0]}, 128)
batch 884: ({'logprob': [51.287879943847656, 13.0]}, 128)
batch 885: ({'logprob': [52.18387985229492, 13.0]}, 128)
batch 886: ({'logprob': [62.28178787231445, 17.0]}, 128)

======================Test output======================
logprob:  0.416274, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.952850e-03 [3.673090e-09] 
Layer 'conv1' biases: 5.718074e-07 [8.540327e-11] 
Layer 'conv2' weights[0]: 7.940004e-03 [3.126403e-09] 
Layer 'conv2' biases: 1.000000e+00 [4.932857e-10] 
Layer 'conv3' weights[0]: 7.938144e-03 [2.480779e-09] 
Layer 'conv3' biases: 4.824042e-06 [1.451261e-09] 
Layer 'conv4' weights[0]: 7.970894e-03 [2.358258e-09] 
Layer 'conv4' biases: 9.999989e-01 [1.029344e-08] 
Layer 'conv5' weights[0]: 7.969586e-03 [6.142027e-08] 
Layer 'conv5' biases: 9.999864e-01 [6.566073e-08] 
Layer 'fc6' weights[0]: 7.565988e-03 [5.043306e-09] 
Layer 'fc6' biases: 1.000000e+00 [5.081533e-09] 
Layer 'fc7' weights[0]: 6.592863e-03 [2.241950e-07] 
Layer 'fc7' biases: 9.998482e-01 [2.157342e-07] 
Layer 'fc8' weights[0]: 1.244288e-03 [8.426419e-06] 
Layer 'fc8' biases: 1.008609e-01 [5.709458e-05] 
Train error last 870 batches: 0.435136
-------------------------------------------------------
Not saving because 0.416274 > 0.415628 (37.630: -0.00%)
======================================================= (12.023 sec)
40.521... logprob:  0.427341, 0.109375 (1.455 sec)
40.522... logprob:  0.533280, 0.156250 (1.463 sec)
40.523... logprob:  0.331206, 0.078125 (1.441 sec)
40.524... logprob:  0.437058, 0.117188 (1.426 sec)
40.525... logprob:  0.425718, 0.109375 (1.453 sec)
40.526... logprob:  0.351353, 0.078125 (1.446 sec)
40.527... logprob:  0.504618, 0.140625 (1.446 sec)
40.528... logprob:  0.440404, 0.117188 (1.464 sec)
40.529... logprob:  0.352988, 0.085938 (1.450 sec)
40.530... logprob:  0.440264, 0.117188 (1.445 sec)
40.531... logprob:  0.439900, 0.117188 (1.480 sec)
40.532... logprob:  0.467229, 0.125000 (1.435 sec)
40.533... logprob:  0.559949, 0.164062 (1.429 sec)
40.534... logprob:  0.326110, 0.078125 (1.434 sec)
40.535... logprob:  0.551165, 0.156250 (1.442 sec)
40.536... logprob:  0.507119, 0.140625 (1.442 sec)
40.537... logprob:  0.509908, 0.140625 (1.478 sec)
40.538... logprob:  0.486050, 0.132812 (1.442 sec)
40.539... logprob:  0.295930, 0.062500 (1.440 sec)
40.540... logprob:  0.447178, 0.117188 (1.486 sec)
40.541... logprob:  0.388694, 0.101562 (1.431 sec)
40.542... logprob:  0.411161, 0.109375 (1.435 sec)
40.543... logprob:  0.233019, 0.039062 (1.439 sec)
40.544... logprob:  0.317905, 0.070312 (1.430 sec)
40.545... logprob:  0.348788, 0.085938 (1.434 sec)
40.546... logprob:  0.368254, 0.093750 (1.490 sec)
40.547... logprob:  0.439877, 0.117188 (1.437 sec)
40.548... logprob:  0.452561, 0.125000 (1.443 sec)
40.549... logprob:  0.490120, 0.132812 (1.483 sec)
40.550... logprob:  0.367527, 0.093750 (1.435 sec)
40.551... logprob:  0.441462, 0.117188 (1.433 sec)
40.552... logprob:  0.471164, 0.125000 (1.442 sec)
40.553... logprob:  0.349456, 0.085938 (1.436 sec)
40.554... logprob:  0.507126, 0.140625 (1.437 sec)
40.555... logprob:  0.421411, 0.109375 (1.480 sec)
40.556... logprob:  0.355637, 0.085938 (1.443 sec)
40.557... logprob:  0.396244, 0.101562 (1.457 sec)
40.558... logprob:  0.382956, 0.101562 (1.472 sec)
40.559... logprob:  0.441789, 0.125000 (1.439 sec)
40.560... logprob:  0.334731, 0.078125 (1.440 sec)
40.561... logprob:  0.411743, 0.109375 (1.436 sec)
40.562... logprob:  0.503220, 0.140625 (1.425 sec)
40.563... logprob:  0.373650, 0.093750 (1.441 sec)
40.564... logprob:  0.468564, 0.132812 (1.464 sec)
40.565... logprob:  0.611309, 0.187500 (1.452 sec)
40.566... logprob:  0.374812, 0.093750 (1.483 sec)
40.567... logprob:  0.423173, 0.109375 (1.458 sec)
40.568... logprob:  0.496291, 0.140625 (1.457 sec)
40.569... logprob:  0.507535, 0.140625 (1.439 sec)
40.570... logprob:  0.543864, 0.164062 (1.426 sec)
=========================
Testing all batches
batch 871: ({'logprob': [42.52900314331055, 10.0]}, 128)
batch 872: ({'logprob': [65.68560028076172, 19.0]}, 128)
batch 873: ({'logprob': [42.49385452270508, 9.0]}, 128)
batch 874: ({'logprob': [46.24850082397461, 11.0]}, 128)
batch 875: ({'logprob': [51.460723876953125, 13.0]}, 128)
batch 876: ({'logprob': [63.47541046142578, 18.0]}, 128)
batch 877: ({'logprob': [46.99233627319336, 11.0]}, 128)
batch 878: ({'logprob': [61.94453048706055, 17.0]}, 128)
batch 879: ({'logprob': [73.10132598876953, 21.0]}, 128)
batch 880: ({'logprob': [51.49075698852539, 13.0]}, 128)
batch 881: ({'logprob': [31.295236587524414, 5.0]}, 128)
batch 882: ({'logprob': [55.92594528198242, 14.0]}, 128)
batch 883: ({'logprob': [61.91145706176758, 17.0]}, 128)
batch 884: ({'logprob': [52.20151901245117, 13.0]}, 128)
batch 885: ({'logprob': [53.6600227355957, 13.0]}, 128)
batch 886: ({'logprob': [62.66828155517578, 17.0]}, 128)

======================Test output======================
logprob:  0.421428, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.952807e-03 [3.800055e-09] 
Layer 'conv1' biases: 5.729463e-07 [8.710143e-11] 
Layer 'conv2' weights[0]: 7.939968e-03 [3.209728e-09] 
Layer 'conv2' biases: 1.000000e+00 [5.811654e-10] 
Layer 'conv3' weights[0]: 7.938106e-03 [2.908111e-09] 
Layer 'conv3' biases: 4.834312e-06 [1.740478e-09] 
Layer 'conv4' weights[0]: 7.970855e-03 [2.771938e-09] 
Layer 'conv4' biases: 9.999989e-01 [1.351250e-08] 
Layer 'conv5' weights[0]: 7.969552e-03 [8.186849e-08] 
Layer 'conv5' biases: 9.999864e-01 [8.748427e-08] 
Layer 'fc6' weights[0]: 7.565947e-03 [6.620045e-09] 
Layer 'fc6' biases: 1.000000e+00 [6.738738e-09] 
Layer 'fc7' weights[0]: 6.591175e-03 [1.752620e-07] 
Layer 'fc7' biases: 9.998482e-01 [1.666839e-07] 
Layer 'fc8' weights[0]: 1.214313e-03 [7.179195e-06] 
Layer 'fc8' biases: 1.007340e-01 [4.944635e-05] 
Train error last 870 batches: 0.435136
-------------------------------------------------------
Not saving because 0.421428 > 0.415628 (37.630: -0.00%)
======================================================= (12.052 sec)
40.571... logprob:  0.454898, 0.125000 (1.441 sec)
40.572... logprob:  0.501263, 0.140625 (1.446 sec)
40.573... logprob:  0.512572, 0.148438 (1.448 sec)
40.574... logprob:  0.427917, 0.109375 (1.464 sec)
40.575... logprob:  0.343311, 0.078125 (1.454 sec)
40.576... logprob:  0.427306, 0.109375 (1.446 sec)
40.577... logprob:  0.460742, 0.125000 (1.479 sec)
40.578... logprob:  0.336976, 0.078125 (1.433 sec)
40.579... logprob:  0.442079, 0.117188 (1.429 sec)
40.580... logprob:  0.546334, 0.156250 (1.433 sec)
40.581... logprob:  0.530287, 0.156250 (1.444 sec)
40.582... logprob:  0.437719, 0.125000 (1.432 sec)
40.583... logprob:  0.592008, 0.171875 (1.478 sec)
40.584... logprob:  0.468012, 0.132812 (1.450 sec)
40.585... logprob:  0.349787, 0.085938 (1.433 sec)
40.586... logprob:  0.313001, 0.070312 (1.487 sec)
40.587... logprob:  0.404285, 0.101562 (1.438 sec)
40.588... logprob:  0.418643, 0.117188 (1.440 sec)
40.589... logprob:  0.361039, 0.093750 (1.436 sec)
40.590... logprob:  0.524841, 0.148438 (1.434 sec)
40.591... logprob:  0.397410, 0.101562 (1.437 sec)
40.592... logprob:  0.455712, 0.125000 (1.479 sec)
40.593... logprob:  0.467411, 0.125000 (1.442 sec)
40.594... logprob:  0.352776, 0.085938 (1.445 sec)
40.595... logprob:  0.428658, 0.109375 (1.483 sec)
40.596... logprob:  0.461648, 0.125000 (1.431 sec)
40.597... logprob:  0.397422, 0.101562 (1.438 sec)
40.598... logprob:  0.397206, 0.101562 (1.438 sec)
40.599... logprob:  0.313621, 0.070312 (1.452 sec)
40.600... logprob:  0.340857, 0.085938 (1.439 sec)
40.601... logprob:  0.402184, 0.101562 (1.485 sec)
40.602... logprob:  0.290051, 0.062500 (1.436 sec)
40.603... logprob:  0.267422, 0.054688 (1.449 sec)
40.604... logprob:  0.407542, 0.101562 (1.479 sec)
40.605... logprob:  0.563034, 0.148438 (1.431 sec)
40.606... logprob:  0.295955, 0.070312 (1.443 sec)
40.607... logprob:  0.504492, 0.132812 (1.433 sec)
40.608... logprob:  0.362040, 0.085938 (1.427 sec)
40.609... logprob:  0.357159, 0.085938 (1.440 sec)
40.610... logprob:  0.493155, 0.132812 (1.469 sec)
40.611... logprob:  0.510219, 0.140625 (1.451 sec)
40.612... logprob:  0.448663, 0.117188 (1.453 sec)
40.613... logprob:  0.278991, 0.062500 (1.474 sec)
40.614... logprob:  0.503604, 0.140625 (1.450 sec)
40.615... logprob:  0.350516, 0.085938 (1.441 sec)
40.616... logprob:  0.414830, 0.109375 (1.433 sec)
40.617... logprob:  0.417710, 0.109375 (1.435 sec)
40.618... logprob:  0.547321, 0.156250 (1.434 sec)
40.619... logprob:  0.506281, 0.140625 (1.461 sec)
40.620... logprob:  0.539784, 0.156250 (1.459 sec)
=========================
Testing all batches
batch 871: ({'logprob': [43.20627212524414, 10.0]}, 128)
batch 872: ({'logprob': [66.21794128417969, 19.0]}, 128)
batch 873: ({'logprob': [41.64760208129883, 9.0]}, 128)
batch 874: ({'logprob': [46.21495056152344, 11.0]}, 128)
batch 875: ({'logprob': [51.34309768676758, 13.0]}, 128)
batch 876: ({'logprob': [63.826656341552734, 18.0]}, 128)
batch 877: ({'logprob': [46.51173782348633, 11.0]}, 128)
batch 878: ({'logprob': [61.66534423828125, 17.0]}, 128)
batch 879: ({'logprob': [72.2156753540039, 21.0]}, 128)
batch 880: ({'logprob': [51.37504196166992, 13.0]}, 128)
batch 881: ({'logprob': [31.057872772216797, 5.0]}, 128)
batch 882: ({'logprob': [54.65305709838867, 14.0]}, 128)
batch 883: ({'logprob': [61.630943298339844, 17.0]}, 128)
batch 884: ({'logprob': [51.63932800292969, 13.0]}, 128)
batch 885: ({'logprob': [52.20378875732422, 13.0]}, 128)
batch 886: ({'logprob': [61.942691802978516, 17.0]}, 128)

======================Test output======================
logprob:  0.418629, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.952765e-03 [6.053532e-09] 
Layer 'conv1' biases: 5.741740e-07 [1.094776e-10] 
Layer 'conv2' weights[0]: 7.939928e-03 [4.604403e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.962427e-10] 
Layer 'conv3' weights[0]: 7.938064e-03 [3.730802e-09] 
Layer 'conv3' biases: 4.845085e-06 [2.154766e-09] 
Layer 'conv4' weights[0]: 7.970824e-03 [3.620369e-09] 
Layer 'conv4' biases: 9.999989e-01 [1.630161e-08] 
Layer 'conv5' weights[0]: 7.969511e-03 [9.964031e-08] 
Layer 'conv5' biases: 9.999868e-01 [1.064661e-07] 
Layer 'fc6' weights[0]: 7.565905e-03 [8.057893e-09] 
Layer 'fc6' biases: 1.000000e+00 [8.180607e-09] 
Layer 'fc7' weights[0]: 6.589502e-03 [2.821271e-07] 
Layer 'fc7' biases: 9.998475e-01 [2.750815e-07] 
Layer 'fc8' weights[0]: 1.221628e-03 [9.651902e-06] 
Layer 'fc8' biases: 1.009566e-01 [6.775791e-05] 
Train error last 870 batches: 0.435136
-------------------------------------------------------
Not saving because 0.418629 > 0.415628 (37.630: -0.00%)
======================================================= (12.013 sec)
40.621... logprob:  0.363272, 0.085938 (1.459 sec)
40.622... logprob:  0.364424, 0.085938 (1.460 sec)
40.623... logprob:  0.423032, 0.109375 (1.463 sec)
40.624... logprob:  0.382446, 0.093750 (1.441 sec)
40.625... logprob:  0.440959, 0.117188 (1.428 sec)
40.626... logprob:  0.438308, 0.117188 (1.435 sec)
40.627... logprob:  0.435787, 0.117188 (1.439 sec)
40.628... logprob:  0.464972, 0.125000 (1.439 sec)
40.629... logprob:  0.372280, 0.093750 (1.477 sec)
40.630... logprob:  0.422406, 0.109375 (1.455 sec)
40.631... logprob:  0.637616, 0.187500 (1.441 sec)
40.632... logprob:  0.399153, 0.101562 (1.498 sec)
40.633... logprob:  0.376209, 0.093750 (1.436 sec)
40.634... logprob:  0.659677, 0.195312 (1.429 sec)
40.635... logprob:  0.374140, 0.093750 (1.438 sec)
40.636... logprob:  0.480277, 0.132812 (1.436 sec)
40.637... logprob:  0.330600, 0.078125 (1.435 sec)
40.638... logprob:  0.515737, 0.140625 (1.484 sec)
40.639... logprob:  0.417941, 0.109375 (1.447 sec)
40.640... logprob:  0.528783, 0.148438 (1.439 sec)
40.641... logprob:  0.410345, 0.109375 (1.489 sec)
40.642... logprob:  0.500991, 0.140625 (1.435 sec)
40.643... logprob:  0.623660, 0.187500 (1.428 sec)
40.644... logprob:  0.320518, 0.070312 (1.442 sec)
40.645... logprob:  0.414387, 0.109375 (1.432 sec)
40.646... logprob:  0.385390, 0.093750 (1.432 sec)
40.647... logprob:  0.456825, 0.125000 (1.491 sec)
40.648... logprob:  0.491324, 0.140625 (1.436 sec)
40.649... logprob:  0.370458, 0.093750 (1.446 sec)
40.650... logprob:  0.414114, 0.109375 (1.476 sec)
40.651... logprob:  0.397496, 0.101562 (1.438 sec)
40.652... logprob:  0.506833, 0.140625 (1.436 sec)
40.653... logprob:  0.547378, 0.156250 (1.436 sec)
40.654... logprob:  0.495895, 0.140625 (1.430 sec)
40.655... logprob:  0.436160, 0.117188 (1.436 sec)
40.656... logprob:  0.416754, 0.109375 (1.479 sec)
40.657... logprob:  0.448856, 0.117188 (1.442 sec)
40.658... logprob:  0.346014, 0.085938 (1.454 sec)
40.659... logprob:  0.464214, 0.125000 (1.469 sec)
40.660... logprob:  0.446163, 0.125000 (1.442 sec)
40.661... logprob:  0.378313, 0.093750 (1.443 sec)
40.662... logprob:  0.469571, 0.132812 (1.438 sec)
40.663... logprob:  0.310730, 0.070312 (1.426 sec)
40.664... logprob:  0.285250, 0.062500 (1.441 sec)
40.665... logprob:  0.401548, 0.101562 (1.463 sec)
40.666... logprob:  0.441988, 0.117188 (1.455 sec)
40.667... logprob:  0.564133, 0.164062 (1.453 sec)
40.668... logprob:  0.497806, 0.140625 (1.456 sec)
40.669... logprob:  0.432762, 0.109375 (1.464 sec)
40.670... logprob:  0.362236, 0.085938 (1.441 sec)
=========================
Testing all batches
batch 871: ({'logprob': [41.1376953125, 10.0]}, 128)
batch 872: ({'logprob': [66.6675796508789, 19.0]}, 128)
batch 873: ({'logprob': [40.64694595336914, 9.0]}, 128)
batch 874: ({'logprob': [45.035552978515625, 11.0]}, 128)
batch 875: ({'logprob': [50.76511001586914, 13.0]}, 128)
batch 876: ({'logprob': [64.17144775390625, 18.0]}, 128)
batch 877: ({'logprob': [45.720706939697266, 11.0]}, 128)
batch 878: ({'logprob': [62.29263687133789, 17.0]}, 128)
batch 879: ({'logprob': [74.43605041503906, 21.0]}, 128)
batch 880: ({'logprob': [50.797218322753906, 13.0]}, 128)
batch 881: ({'logprob': [28.45881462097168, 5.0]}, 128)
batch 882: ({'logprob': [55.35435485839844, 14.0]}, 128)
batch 883: ({'logprob': [62.25803756713867, 17.0]}, 128)
batch 884: ({'logprob': [51.45635223388672, 13.0]}, 128)
batch 885: ({'logprob': [52.800926208496094, 13.0]}, 128)
batch 886: ({'logprob': [62.96287155151367, 17.0]}, 128)

======================Test output======================
logprob:  0.417462, 0.107910 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.952731e-03 [3.180429e-09] 
Layer 'conv1' biases: 5.752793e-07 [4.757713e-11] 
Layer 'conv2' weights[0]: 7.939898e-03 [2.008737e-09] 
Layer 'conv2' biases: 1.000000e+00 [2.139809e-10] 
Layer 'conv3' weights[0]: 7.938024e-03 [1.434746e-09] 
Layer 'conv3' biases: 4.851762e-06 [6.356636e-10] 
Layer 'conv4' weights[0]: 7.970782e-03 [1.340705e-09] 
Layer 'conv4' biases: 9.999989e-01 [4.035187e-09] 
Layer 'conv5' weights[0]: 7.969486e-03 [2.335923e-08] 
Layer 'conv5' biases: 9.999862e-01 [2.470033e-08] 
Layer 'fc6' weights[0]: 7.565869e-03 [2.026520e-09] 
Layer 'fc6' biases: 1.000000e+00 [1.888870e-09] 
Layer 'fc7' weights[0]: 6.587743e-03 [8.173222e-08] 
Layer 'fc7' biases: 9.998492e-01 [6.868413e-08] 
Layer 'fc8' weights[0]: 1.266149e-03 [2.374431e-06] 
Layer 'fc8' biases: 1.013576e-01 [1.478039e-05] 
Train error last 870 batches: 0.435135
-------------------------------------------------------
Not saving because 0.417462 > 0.415628 (37.630: -0.00%)
======================================================= (12.087 sec)
40.671... logprob:  0.360893, 0.093750 (1.433 sec)
40.672... logprob:  0.441836, 0.117188 (1.440 sec)
40.673... logprob:  0.436217, 0.117188 (1.445 sec)
40.674... logprob:  0.446598, 0.117188 (1.443 sec)
40.675... logprob:  0.356703, 0.093750 (1.468 sec)
40.676... logprob:  0.450227, 0.125000 (1.450 sec)
40.677... logprob:  0.470983, 0.125000 (1.447 sec)
40.678... logprob:  0.465673, 0.125000 (1.481 sec)
40.679... logprob:  0.454862, 0.125000 (1.434 sec)
40.680... logprob:  0.351570, 0.078125 (1.451 sec)
40.681... logprob:  0.373794, 0.093750 (1.461 sec)
40.682... logprob:  0.340425, 0.078125 (1.442 sec)
40.683... logprob:  0.411622, 0.109375 (1.455 sec)
40.684... logprob:  0.357785, 0.085938 (1.494 sec)
40.685... logprob:  0.286493, 0.054688 (1.446 sec)
40.686... logprob:  0.319061, 0.070312 (1.433 sec)
40.687... logprob:  0.282055, 0.062500 (1.487 sec)
40.688... logprob:  0.323217, 0.078125 (1.437 sec)
40.689... logprob:  0.470430, 0.125000 (1.430 sec)
40.690... logprob:  0.526724, 0.140625 (1.438 sec)
40.691...nohup: ignoring input
Option --layer-def (Layer definition file) cannot be changed
=========================
Importing _ConvNet C++ module
=========================
Training ConvNet
Always write savepoints, regardless of test err improvement: 0     [DEFAULT]
Check gradients and quit?                                  : 0     [DEFAULT]
Compress checkpoints?                                      : 0     [DEFAULT]
Conserve GPU memory (slower)?                              : 0     [DEFAULT]
Convert given conv layers to unshared local                :       
Cropped DP: crop border size                               : 4     [DEFAULT]
Cropped DP: logreg layer name (for --multiview-test)       :       [DEFAULT]
Cropped DP: test on multiple patches?                      : 0     [DEFAULT]
Cropped Step: crop border step                             : 1     [DEFAULT]
Data batch range: testing                                  : 851-886 
Data batch range: training                                 : 1-850 
Data path                                                  : /data2/ad6813/pipe-data/Redbox/batches/clamp_detection 
Data provider                                              : basic-leaf256 
GPU override                                               : -1    [DEFAULT]
Layer definition file                                      : /homes/ad6813/Git/pipe-classification/models/decaf-net/zero_init/10-06-2014/layers_decaf.cfg 
Layer parameter file                                       : /homes/ad6813/Git/pipe-classification/models/decaf-net/zero_init/10-06-2014/params_decaf.cfg 
Load file                                                  : /data2/ad6813/my-nets/saves/ConvNet__2014-06-17_23.05.49 
Maximum save file size (MB)                                : 0     [DEFAULT]
Minibatch size                                             : 128   [DEFAULT]
Number of GPUs                                             : 1     [DEFAULT]
Number of epochs                                           : 50000 [DEFAULT]
Save path                                                  : /data2/ad6813/my-nets/saves 
Test and quit?                                             : 0     [DEFAULT]
Test on more than one batch at a time?                     : -1    
Test on one batch at a time?                               : 0     
Testing frequency                                          : 50    
Unshare weight matrices in given layers                    :       
=========================
Running on CUDA device(s) -2
Current time: Wed Jun 18 20:39:40 2014
Saving checkpoints to /data2/ad6813/my-nets/saves/ConvNet__2014-06-17_23.05.49
=========================
37.631... logprob:  0.637838, 0.187500 (1.435 sec)
37.632... logprob:  0.399142, 0.101562 (1.493 sec)
37.633... logprob:  0.376187, 0.093750 (1.432 sec)
37.634... logprob:  0.659710, 0.195312 (1.433 sec)
37.635... logprob:  0.374163, 0.093750 (1.443 sec)
37.636... logprob:  0.480239, 0.132812 (1.440 sec)
37.637... logprob:  0.330780, 0.078125 (1.440 sec)
37.638... logprob:  0.515626, 0.140625 (1.487 sec)
37.639... logprob:  0.418027, 0.109375 (1.447 sec)
37.640... logprob:  0.528658, 0.148438 (1.444 sec)
37.641... logprob:  0.410457, 0.109375 (1.487 sec)
37.642... logprob:  0.500920, 0.140625 (1.439 sec)
37.643... logprob:  0.623362, 0.187500 (1.430 sec)
37.644... logprob:  0.320808, 0.070312 (1.440 sec)
37.645... logprob:  0.414487, 0.109375 (1.433 sec)
37.646... logprob:  0.385501, 0.093750 (1.436 sec)
37.647... logprob:  0.456832, 0.125000 (1.493 sec)
37.648... logprob:  0.491336, 0.140625 (1.439 sec)
37.649... logprob:  0.370368, 0.093750 (1.441 sec)
37.650... logprob:  0.414054, 0.109375 (1.492 sec)
=========================
Testing all batches
batch 851: ({'logprob': [56.310279846191406, 15.0]}, 128)
batch 852: ({'logprob': [69.74557495117188, 20.0]}, 128)
batch 853: ({'logprob': [47.45942306518555, 12.0]}, 128)
batch 854: ({'logprob': [39.47543716430664, 9.0]}, 128)
batch 855: ({'logprob': [61.78303909301758, 17.0]}, 128)
batch 856: ({'logprob': [56.77964782714844, 15.0]}, 128)
batch 857: ({'logprob': [47.903717041015625, 12.0]}, 128)
batch 858: ({'logprob': [50.881187438964844, 13.0]}, 128)
batch 859: ({'logprob': [40.431640625, 9.0]}, 128)
batch 860: ({'logprob': [71.12318420410156, 20.0]}, 128)
batch 861: ({'logprob': [53.36147689819336, 14.0]}, 128)
batch 862: ({'logprob': [42.9146728515625, 10.0]}, 128)
batch 863: ({'logprob': [51.359413146972656, 13.0]}, 128)
batch 864: ({'logprob': [57.70004653930664, 15.0]}, 128)
batch 865: ({'logprob': [61.320377349853516, 17.0]}, 128)
batch 866: ({'logprob': [64.29209899902344, 18.0]}, 128)
batch 867: ({'logprob': [63.856868743896484, 18.0]}, 128)
batch 868: ({'logprob': [52.208290100097656, 13.0]}, 128)
batch 869: ({'logprob': [49.2640380859375, 12.0]}, 128)
batch 870: ({'logprob': [71.12895965576172, 20.0]}, 128)
batch 871: ({'logprob': [42.00250244140625, 10.0]}, 128)
batch 872: ({'logprob': [66.33308410644531, 19.0]}, 128)
batch 873: ({'logprob': [40.87689208984375, 9.0]}, 128)
batch 874: ({'logprob': [45.41962432861328, 11.0]}, 128)
batch 875: ({'logprob': [50.85902404785156, 13.0]}, 128)
batch 876: ({'logprob': [63.86869812011719, 18.0]}, 128)
batch 877: ({'logprob': [45.8824577331543, 11.0]}, 128)
batch 878: ({'logprob': [61.80242919921875, 17.0]}, 128)
batch 879: ({'logprob': [73.14337921142578, 21.0]}, 128)
batch 880: ({'logprob': [50.8895378112793, 13.0]}, 128)
batch 881: ({'logprob': [29.494949340820312, 5.0]}, 128)
batch 882: ({'logprob': [54.74406051635742, 14.0]}, 128)
batch 883: ({'logprob': [61.76972198486328, 17.0]}, 128)
batch 884: ({'logprob': [51.32429122924805, 13.0]}, 128)
batch 885: ({'logprob': [52.22494125366211, 13.0]}, 128)
batch 886: ({'logprob': [62.248985290527344, 17.0]}, 128)

======================Test output======================
logprob:  0.425821, 0.111328 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954719e-03 [8.581860e-09] 
Layer 'conv1' biases: 5.176401e-07 [2.447105e-10] 
Layer 'conv2' weights[0]: 7.941836e-03 [6.776273e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.008537e-09] 
Layer 'conv3' weights[0]: 7.940036e-03 [6.282306e-09] 
Layer 'conv3' biases: 4.369543e-06 [2.933607e-09] 
Layer 'conv4' weights[0]: 7.972696e-03 [6.680881e-09] 
Layer 'conv4' biases: 9.999989e-01 [2.715879e-08] 
Layer 'conv5' weights[0]: 7.971455e-03 [8.044134e-08] 
Layer 'conv5' biases: 9.999873e-01 [8.616793e-08] 
Layer 'fc6' weights[0]: 7.567912e-03 [1.432247e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.419592e-08] 
Layer 'fc7' weights[0]: 6.676636e-03 [2.276094e-07] 
Layer 'fc7' biases: 9.998497e-01 [2.175157e-07] 
Layer 'fc8' weights[0]: 1.254200e-03 [9.809462e-06] 
Layer 'fc8' biases: 9.342360e-02 [7.175319e-05] 
Train error last 850 batches: 0.435211
-------------------------------------------------------
Not saving because 0.425821 > 0.415628 (37.630: -0.00%)
======================================================= (41.910 sec)
37.651... logprob:  0.397395, 0.101562 (1.439 sec)
37.652... logprob:  0.507054, 0.140625 (1.439 sec)
37.653... logprob:  0.547769, 0.156250 (1.443 sec)
37.654... logprob:  0.496119, 0.140625 (1.426 sec)
37.655... logprob:  0.436185, 0.117188 (1.437 sec)
37.656... logprob:  0.416710, 0.109375 (1.478 sec)
37.657... logprob:  0.448921, 0.117188 (1.448 sec)
37.658... logprob:  0.345894, 0.085938 (1.456 sec)
37.659... logprob:  0.464241, 0.125000 (1.472 sec)
37.660... logprob:  0.446123, 0.125000 (1.444 sec)
37.661... logprob:  0.378374, 0.093750 (1.441 sec)
37.662... logprob:  0.469502, 0.132812 (1.458 sec)
37.663... logprob:  0.310896, 0.070312 (1.432 sec)
37.664... logprob:  0.285441, 0.062500 (1.443 sec)
37.665... logprob:  0.401608, 0.101562 (1.457 sec)
37.666... logprob:  0.441971, 0.117188 (1.460 sec)
37.667... logprob:  0.564070, 0.164062 (1.459 sec)
37.668... logprob:  0.497803, 0.140625 (1.452 sec)
37.669... logprob:  0.432835, 0.109375 (1.467 sec)
37.670... logprob:  0.362278, 0.085938 (1.439 sec)
37.671... logprob:  0.360870, 0.093750 (1.433 sec)
37.672... logprob:  0.441838, 0.117188 (1.438 sec)
37.673... logprob:  0.436216, 0.117188 (1.440 sec)
37.674... logprob:  0.446612, 0.117188 (1.439 sec)
37.675... logprob:  0.356699, 0.093750 (1.472 sec)
37.676... logprob:  0.450198, 0.125000 (1.449 sec)
37.677... logprob:  0.470983, 0.125000 (1.446 sec)
37.678... logprob:  0.465659, 0.125000 (1.478 sec)
37.679... logprob:  0.454850, 0.125000 (1.434 sec)
37.680... logprob:  0.351652, 0.078125 (1.434 sec)
37.681... logprob:  0.373857, 0.093750 (1.445 sec)
37.682... logprob:  0.340499, 0.078125 (1.443 sec)
37.683... logprob:  0.411633, 0.109375 (1.470 sec)
37.684... logprob:  0.357775, 0.085938 (1.488 sec)
37.685... logprob:  0.286395, 0.054688 (1.449 sec)
37.686... logprob:  0.318950, 0.070312 (1.438 sec)
37.687... logprob:  0.281891, 0.062500 (1.494 sec)
37.688... logprob:  0.323151, 0.078125 (1.431 sec)
37.689... logprob:  0.470843, 0.125000 (1.438 sec)
37.690... logprob:  0.527402, 0.140625 (1.435 sec)
37.691... logprob:  0.516142, 0.140625 (1.435 sec)
37.692... logprob:  0.384579, 0.101562 (1.435 sec)
37.693... logprob:  0.455397, 0.125000 (1.484 sec)
37.694... logprob:  0.330971, 0.078125 (1.441 sec)
37.695... logprob:  0.356997, 0.085938 (1.443 sec)
37.696... logprob:  0.539542, 0.148438 (1.485 sec)
37.697... logprob:  0.465852, 0.125000 (1.437 sec)
37.698... logprob:  0.549157, 0.156250 (1.439 sec)
37.699... logprob:  0.459619, 0.125000 (1.434 sec)
37.700... logprob:  0.433767, 0.117188 (1.435 sec)
=========================
Testing all batches
batch 851: ({'logprob': [56.48350143432617, 15.0]}, 128)
batch 852: ({'logprob': [69.16423034667969, 20.0]}, 128)
batch 853: ({'logprob': [48.12020492553711, 12.0]}, 128)
batch 854: ({'logprob': [40.58469772338867, 9.0]}, 128)
batch 855: ({'logprob': [61.64875411987305, 17.0]}, 128)
batch 856: ({'logprob': [56.93042755126953, 15.0]}, 128)
batch 857: ({'logprob': [48.54439163208008, 12.0]}, 128)
batch 858: ({'logprob': [51.358192443847656, 13.0]}, 128)
batch 859: ({'logprob': [41.50119400024414, 9.0]}, 128)
batch 860: ({'logprob': [70.47869110107422, 20.0]}, 128)
batch 861: ({'logprob': [53.696475982666016, 14.0]}, 128)
batch 862: ({'logprob': [43.840335845947266, 10.0]}, 128)
batch 863: ({'logprob': [51.81497573852539, 13.0]}, 128)
batch 864: ({'logprob': [57.80937576293945, 15.0]}, 128)
batch 865: ({'logprob': [61.20801544189453, 17.0]}, 128)
batch 866: ({'logprob': [64.01730346679688, 18.0]}, 128)
batch 867: ({'logprob': [63.60115051269531, 18.0]}, 128)
batch 868: ({'logprob': [52.623573303222656, 13.0]}, 128)
batch 869: ({'logprob': [49.84206771850586, 12.0]}, 128)
batch 870: ({'logprob': [70.48410034179688, 20.0]}, 128)
batch 871: ({'logprob': [42.96993637084961, 10.0]}, 128)
batch 872: ({'logprob': [65.93553924560547, 19.0]}, 128)
batch 873: ({'logprob': [41.92426300048828, 9.0]}, 128)
batch 874: ({'logprob': [46.202308654785156, 11.0]}, 128)
batch 875: ({'logprob': [51.337860107421875, 13.0]}, 128)
batch 876: ({'logprob': [63.612525939941406, 18.0]}, 128)
batch 877: ({'logprob': [46.64607238769531, 11.0]}, 128)
batch 878: ({'logprob': [61.66954040527344, 17.0]}, 128)
batch 879: ({'logprob': [72.37867736816406, 21.0]}, 128)
batch 880: ({'logprob': [51.367515563964844, 13.0]}, 128)
batch 881: ({'logprob': [31.175701141357422, 5.0]}, 128)
batch 882: ({'logprob': [55.016761779785156, 14.0]}, 128)
batch 883: ({'logprob': [61.637481689453125, 17.0]}, 128)
batch 884: ({'logprob': [51.7790412902832, 13.0]}, 128)
batch 885: ({'logprob': [52.63904571533203, 13.0]}, 128)
batch 886: ({'logprob': [62.093929290771484, 17.0]}, 128)

======================Test output======================
logprob:  0.427981, 0.111328 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954516e-03 [1.336198e-08] 
Layer 'conv1' biases: 5.220576e-07 [3.692950e-10] 
Layer 'conv2' weights[0]: 7.941653e-03 [1.077417e-08] 
Layer 'conv2' biases: 1.000000e+00 [2.049343e-09] 
Layer 'conv3' weights[0]: 7.939853e-03 [1.013461e-08] 
Layer 'conv3' biases: 4.414430e-06 [6.080943e-09] 
Layer 'conv4' weights[0]: 7.972514e-03 [1.000453e-08] 
Layer 'conv4' biases: 9.999989e-01 [4.813833e-08] 
Layer 'conv5' weights[0]: 7.971429e-03 [2.419563e-08] 
Layer 'conv5' biases: 9.999885e-01 [2.572878e-08] 
Layer 'fc6' weights[0]: 7.567723e-03 [2.445601e-08] 
Layer 'fc6' biases: 1.000000e+00 [2.480677e-08] 
Layer 'fc7' weights[0]: 6.674975e-03 [3.564804e-07] 
Layer 'fc7' biases: 9.998490e-01 [3.488273e-07] 
Layer 'fc8' weights[0]: 1.230349e-03 [1.305279e-05] 
Layer 'fc8' biases: 9.337672e-02 [8.521847e-05] 
Train error last 850 batches: 0.434867
-------------------------------------------------------
Not saving because 0.427981 > 0.415628 (37.630: -0.00%)
======================================================= (41.947 sec)
37.701... logprob:  0.422928, 0.109375 (1.446 sec)
37.702... logprob:  0.521569, 0.148438 (1.494 sec)
37.703... logprob:  0.405081, 0.101562 (1.443 sec)
37.704... logprob:  0.406135, 0.101562 (1.454 sec)
37.705... logprob:  0.420310, 0.109375 (1.479 sec)
37.706... logprob:  0.468154, 0.125000 (1.442 sec)
37.707... logprob:  0.485322, 0.132812 (1.442 sec)
37.708... logprob:  0.417380, 0.109375 (1.435 sec)
37.709... logprob:  0.422766, 0.109375 (1.428 sec)
37.710... logprob:  0.601882, 0.179688 (1.437 sec)
37.711... logprob:  0.469440, 0.125000 (1.470 sec)
37.712... logprob:  0.340945, 0.078125 (1.446 sec)
37.713... logprob:  0.586407, 0.179688 (1.460 sec)
37.714... logprob:  0.466258, 0.125000 (1.458 sec)
37.715... logprob:  0.417139, 0.109375 (1.460 sec)
37.716... logprob:  0.335300, 0.078125 (1.436 sec)
37.717... logprob:  0.429726, 0.117188 (1.426 sec)
37.718... logprob:  0.490390, 0.132812 (1.435 sec)
37.719... logprob:  0.406121, 0.109375 (1.440 sec)
37.720... logprob:  0.433220, 0.117188 (1.447 sec)
37.721... logprob:  0.451641, 0.117188 (1.475 sec)
37.722... logprob:  0.537109, 0.156250 (1.457 sec)
37.723... logprob:  0.416518, 0.109375 (1.451 sec)
37.724... logprob:  0.412756, 0.109375 (1.501 sec)
37.725... logprob:  0.494886, 0.140625 (1.438 sec)
37.726... logprob:  0.338401, 0.085938 (1.430 sec)
37.727... logprob:  0.393185, 0.101562 (1.432 sec)
37.728... logprob:  0.421163, 0.109375 (1.435 sec)
37.729... logprob:  0.387549, 0.093750 (1.432 sec)
37.730... logprob:  0.565767, 0.164062 (1.481 sec)
37.731... logprob:  0.450439, 0.125000 (1.448 sec)
37.732... logprob:  0.311446, 0.070312 (1.432 sec)
37.733... logprob:  0.556293, 0.156250 (1.491 sec)
37.734... logprob:  0.340291, 0.078125 (1.434 sec)
37.735... logprob:  0.527305, 0.148438 (1.433 sec)
37.736... logprob:  0.642354, 0.187500 (1.446 sec)
37.737... logprob:  0.516071, 0.148438 (1.429 sec)
37.738... logprob:  0.459352, 0.125000 (1.437 sec)
37.739... logprob:  0.477772, 0.132812 (1.486 sec)
37.740... logprob:  0.339617, 0.078125 (1.436 sec)
37.741... logprob:  0.393523, 0.101562 (1.442 sec)
37.742... logprob:  0.419684, 0.109375 (1.486 sec)
37.743... logprob:  0.364952, 0.085938 (1.434 sec)
37.744... logprob:  0.519058, 0.148438 (1.434 sec)
37.745... logprob:  0.478106, 0.132812 (1.436 sec)
37.746... logprob:  0.440527, 0.117188 (1.433 sec)
37.747... logprob:  0.425565, 0.109375 (1.433 sec)
37.748... logprob:  0.378147, 0.093750 (1.489 sec)
37.749... logprob:  0.420768, 0.109375 (1.435 sec)
37.750... logprob:  0.512782, 0.140625 (1.445 sec)
=========================
Testing all batches
batch 851: ({'logprob': [56.376888275146484, 15.0]}, 128)
batch 852: ({'logprob': [70.29338073730469, 20.0]}, 128)
batch 853: ({'logprob': [47.11759948730469, 12.0]}, 128)
batch 854: ({'logprob': [38.85868453979492, 9.0]}, 128)
batch 855: ({'logprob': [62.05636215209961, 17.0]}, 128)
batch 856: ({'logprob': [56.9146614074707, 15.0]}, 128)
batch 857: ({'logprob': [47.62906265258789, 12.0]}, 128)
batch 858: ({'logprob': [50.74324035644531, 13.0]}, 128)
batch 859: ({'logprob': [39.94843292236328, 9.0]}, 128)
batch 860: ({'logprob': [71.87338256835938, 20.0]}, 128)
batch 861: ({'logprob': [53.29252243041992, 14.0]}, 128)
batch 862: ({'logprob': [42.50157165527344, 10.0]}, 128)
batch 863: ({'logprob': [51.289451599121094, 13.0]}, 128)
batch 864: ({'logprob': [57.9696044921875, 15.0]}, 128)
batch 865: ({'logprob': [61.525848388671875, 17.0]}, 128)
batch 866: ({'logprob': [64.63333892822266, 18.0]}, 128)
batch 867: ({'logprob': [64.13175201416016, 18.0]}, 128)
batch 868: ({'logprob': [52.271759033203125, 13.0]}, 128)
batch 869: ({'logprob': [49.19150161743164, 12.0]}, 128)
batch 870: ({'logprob': [71.87948608398438, 20.0]}, 128)
batch 871: ({'logprob': [41.45443344116211, 10.0]}, 128)
batch 872: ({'logprob': [66.6768798828125, 19.0]}, 128)
batch 873: ({'logprob': [40.46221923828125, 9.0]}, 128)
batch 874: ({'logprob': [45.075992584228516, 11.0]}, 128)
batch 875: ({'logprob': [50.72021484375, 13.0]}, 128)
batch 876: ({'logprob': [64.14410400390625, 18.0]}, 128)
batch 877: ({'logprob': [45.60527801513672, 11.0]}, 128)
batch 878: ({'logprob': [62.07501983642578, 17.0]}, 128)
batch 879: ({'logprob': [73.89397430419922, 21.0]}, 128)
batch 880: ({'logprob': [50.75099182128906, 13.0]}, 128)
batch 881: ({'logprob': [28.6007080078125, 5.0]}, 128)
batch 882: ({'logprob': [54.87723922729492, 14.0]}, 128)
batch 883: ({'logprob': [62.04209899902344, 17.0]}, 128)
batch 884: ({'logprob': [51.254615783691406, 13.0]}, 128)
batch 885: ({'logprob': [52.289459228515625, 13.0]}, 128)
batch 886: ({'logprob': [62.5897331237793, 17.0]}, 128)

======================Test output======================
logprob:  0.426001, 0.111328 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954296e-03 [1.037530e-08] 
Layer 'conv1' biases: 5.275568e-07 [1.624125e-10] 
Layer 'conv2' weights[0]: 7.941457e-03 [7.719414e-09] 
Layer 'conv2' biases: 1.000000e+00 [6.337463e-10] 
Layer 'conv3' weights[0]: 7.939644e-03 [6.017018e-09] 
Layer 'conv3' biases: 4.456308e-06 [1.945549e-09] 
Layer 'conv4' weights[0]: 7.972301e-03 [5.696061e-09] 
Layer 'conv4' biases: 9.999990e-01 [1.041493e-08] 
Layer 'conv5' weights[0]: 7.971382e-03 [5.937413e-08] 
Layer 'conv5' biases: 9.999872e-01 [6.353350e-08] 
Layer 'fc6' weights[0]: 7.567528e-03 [5.756472e-09] 
Layer 'fc6' biases: 1.000000e+00 [4.282783e-09] 
Layer 'fc7' weights[0]: 6.673244e-03 [7.305290e-08] 
Layer 'fc7' biases: 9.998503e-01 [5.808879e-08] 
Layer 'fc8' weights[0]: 1.270059e-03 [6.403836e-06] 
Layer 'fc8' biases: 9.384550e-02 [4.581045e-05] 
Train error last 850 batches: 0.434778
-------------------------------------------------------
Not saving because 0.426001 > 0.415628 (37.630: -0.00%)
======================================================= (42.030 sec)
37.751... logprob:  0.263622, 0.054688 (1.484 sec)
37.752... logprob:  0.522648, 0.140625 (1.440 sec)
37.753... logprob:  0.441147, 0.117188 (1.442 sec)
37.754... logprob:  0.468194, 0.132812 (1.432 sec)
37.755... logprob:  0.507109, 0.140625 (1.429 sec)
37.756... logprob:  0.440869, 0.117188 (1.434 sec)
37.757... logprob:  0.552619, 0.156250 (1.493 sec)
37.758... logprob:  0.393475, 0.101562 (1.445 sec)
37.759... logprob:  0.459690, 0.125000 (1.459 sec)
37.760... logprob:  0.485613, 0.132812 (1.462 sec)
37.761... logprob:  0.418103, 0.109375 (1.451 sec)
37.762... logprob:  0.516021, 0.148438 (1.450 sec)
37.763... logprob:  0.558951, 0.164062 (1.436 sec)
37.764... logprob:  0.503241, 0.140625 (1.429 sec)
37.765... logprob:  0.311847, 0.062500 (1.437 sec)
37.766... logprob:  0.482216, 0.132812 (1.456 sec)
37.767... logprob:  0.371282, 0.085938 (1.462 sec)
37.768... logprob:  0.432705, 0.117188 (1.471 sec)
37.769... logprob:  0.490733, 0.140625 (1.468 sec)
37.770... logprob:  0.403077, 0.101562 (1.493 sec)
37.771... logprob:  0.549285, 0.156250 (1.459 sec)
37.772... logprob:  0.414090, 0.109375 (1.447 sec)
37.773... logprob:  0.557615, 0.164062 (1.449 sec)
37.774... logprob:  0.361743, 0.085938 (1.460 sec)
37.775... logprob:  0.407357, 0.101562 (1.466 sec)
37.776... logprob:  0.433104, 0.117188 (1.481 sec)
37.777... logprob:  0.379905, 0.093750 (1.497 sec)
37.778... logprob:  0.433527, 0.117188 (1.475 sec)
37.779... logprob:  0.505413, 0.140625 (1.486 sec)
37.780... logprob:  0.385715, 0.101562 (1.454 sec)
37.781... logprob:  0.369545, 0.085938 (1.454 sec)
37.782... logprob:  0.351306, 0.085938 (1.450 sec)
37.783... logprob:  0.555604, 0.156250 (1.464 sec)
37.784... logprob:  0.440956, 0.117188 (1.456 sec)
37.785... logprob:  0.543761, 0.156250 (1.490 sec)
37.786... logprob:  0.477593, 0.132812 (1.471 sec)
37.787... logprob:  0.546568, 0.156250 (1.465 sec)
37.788... logprob:  0.563331, 0.164062 (1.492 sec)
37.789... logprob:  0.280578, 0.054688 (1.459 sec)
37.790... logprob:  0.407875, 0.101562 (1.457 sec)
37.791... logprob:  0.397921, 0.101562 (1.457 sec)
37.792... logprob:  0.361060, 0.085938 (1.465 sec)
37.793... logprob:  0.370212, 0.085938 (1.459 sec)
37.794... logprob:  0.387284, 0.093750 (1.492 sec)
37.795... logprob:  0.469626, 0.125000 (1.473 sec)
37.796... logprob:  0.423526, 0.109375 (1.459 sec)
37.797... logprob:  0.358977, 0.085938 (1.506 sec)
37.798... logprob:  0.393309, 0.101562 (1.451 sec)
37.799... logprob:  0.332555, 0.078125 (1.453 sec)
37.800... logprob:  0.371628, 0.093750 (1.458 sec)
=========================
Testing all batches
batch 851: ({'logprob': [56.85251235961914, 15.0]}, 128)
batch 852: ({'logprob': [71.82426452636719, 20.0]}, 128)
batch 853: ({'logprob': [47.2615966796875, 12.0]}, 128)
batch 854: ({'logprob': [38.33591842651367, 9.0]}, 128)
batch 855: ({'logprob': [62.92351531982422, 17.0]}, 128)
batch 856: ({'logprob': [57.22698974609375, 15.0]}, 128)
batch 857: ({'logprob': [47.6059455871582, 12.0]}, 128)
batch 858: ({'logprob': [50.8323860168457, 13.0]}, 128)
batch 859: ({'logprob': [39.0925178527832, 9.0]}, 128)
batch 860: ({'logprob': [72.90927124023438, 20.0]}, 128)
batch 861: ({'logprob': [53.65815734863281, 14.0]}, 128)
batch 862: ({'logprob': [41.92418670654297, 10.0]}, 128)
batch 863: ({'logprob': [51.214176177978516, 13.0]}, 128)
batch 864: ({'logprob': [57.951080322265625, 15.0]}, 128)
batch 865: ({'logprob': [62.556766510009766, 17.0]}, 128)
batch 866: ({'logprob': [65.77562713623047, 18.0]}, 128)
batch 867: ({'logprob': [65.44175720214844, 18.0]}, 128)
batch 868: ({'logprob': [51.863807678222656, 13.0]}, 128)
batch 869: ({'logprob': [48.672515869140625, 12.0]}, 128)
batch 870: ({'logprob': [72.91522979736328, 20.0]}, 128)
batch 871: ({'logprob': [41.208518981933594, 10.0]}, 128)
batch 872: ({'logprob': [68.26272583007812, 19.0]}, 128)
batch 873: ({'logprob': [39.4417839050293, 9.0]}, 128)
batch 874: ({'logprob': [44.776981353759766, 11.0]}, 128)
batch 875: ({'logprob': [50.80680465698242, 13.0]}, 128)
batch 876: ({'logprob': [65.45472717285156, 18.0]}, 128)
batch 877: ({'logprob': [45.13829040527344, 11.0]}, 128)
batch 878: ({'logprob': [62.94022750854492, 17.0]}, 128)
batch 879: ({'logprob': [75.37187957763672, 21.0]}, 128)
batch 880: ({'logprob': [50.8393669128418, 13.0]}, 128)
batch 881: ({'logprob': [26.966506958007812, 5.0]}, 128)
batch 882: ({'logprob': [54.74643325805664, 14.0]}, 128)
batch 883: ({'logprob': [62.906009674072266, 17.0]}, 128)
batch 884: ({'logprob': [51.180240631103516, 13.0]}, 128)
batch 885: ({'logprob': [51.882362365722656, 13.0]}, 128)
batch 886: ({'logprob': [63.29106521606445, 17.0]}, 128)

======================Test output======================
logprob:  0.427963, 0.111328 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.954117e-03 [1.045968e-08] 
Layer 'conv1' biases: 5.331725e-07 [3.777323e-10] 
Layer 'conv2' weights[0]: 7.941266e-03 [8.292888e-09] 
Layer 'conv2' biases: 1.000000e+00 [1.524362e-09] 
Layer 'conv3' weights[0]: 7.939462e-03 [8.431334e-09] 
Layer 'conv3' biases: 4.501367e-06 [4.212210e-09] 
Layer 'conv4' weights[0]: 7.972101e-03 [8.323091e-09] 
Layer 'conv4' biases: 9.999989e-01 [3.576081e-08] 
Layer 'conv5' weights[0]: 7.971349e-03 [3.802160e-08] 
Layer 'conv5' biases: 9.999868e-01 [4.063314e-08] 
Layer 'fc6' weights[0]: 7.567336e-03 [1.798255e-08] 
Layer 'fc6' biases: 1.000000e+00 [1.775656e-08] 
Layer 'fc7' weights[0]: 6.671533e-03 [2.548711e-07] 
Layer 'fc7' biases: 9.998511e-01 [2.460688e-07] 
Layer 'fc8' weights[0]: 1.303079e-03 [9.774453e-06] 
Layer 'fc8' biases: 9.425770e-02 [7.102033e-05] 
Train error last 850 batches: 0.434690
-------------------------------------------------------
Not saving because 0.427963 > 0.415628 (37.630: -0.00%)
======================================================= (41.940 sec)
37.801... logprob:  0.449974, 0.117188 (1.458 sec)
37.802... logprob:  0.422930, 0.109375 (1.483 sec)
37.803... logprob:  0.491556, 0.132812 (1.497 sec)
37.804... logprob:  0.349911, 0.085938 (1.467 sec)
37.805... logprob:  0.452532, 0.117188 (1.453 sec)
37.806... logprob:  0.424306, 0.109375 (1.506 sec)
37.807... logprob:  0.443589, 0.117188 (1.451 sec)
37.808... logprob:  0.462413, 0.125000 (1.456 sec)
37.809... logprob:  0.589920, 0.171875 (1.449 sec)
37.810... logprob:  0.442509, 0.117188 (1.460 sec)
37.811... logprob:  0.460389, 0.125000 (1.451 sec)
37.812... logprob:  0.462304, 0.125000 (1.500 sec)
37.813... logprob:  0.485953, 0.132812 (1.458 sec)
37.814... logprob:  0.477892, 0.132812 (1.460 sec)
37.815... logprob:  0.371626, 0.085938 (1.503 sec)
37.816... logprob:  0.408699, 0.101562 (1.456 sec)
37.817... logprob:  0.426009, 0.109375 (1.459 sec)
37.818... logprob:  0.559885, 0.164062 (1.446 sec)
37.819... logprob:  0.498177, 0.140625 (1.461 sec)
37.820... logprob:  0.421825, 0.109375 (1.451 sec)
37.821... logprob:  0.406821, 0.101562 (1.501 sec)
37.822... logprob:  0.441335, 0.117188 (1.462 sec)
37.823... logprob:  0.341214, 0.078125 (1.466 sec)
37.824...