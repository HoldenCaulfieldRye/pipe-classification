Initialized data layer 'data', producing 196608 outputs
Initialized data layer 'labels', producing 1 outputs
Initialized convolutional layer 'conv1', producing 63x63 48-channel output
Initialized max-pooling layer 'pool1', producing 31x31 48-channel output
Initialized cross-map response-normalization layer 'rnorm1', producing 31x31 48-channel output
Initialized convolutional layer 'conv2', producing 31x31 128-channel output
Initialized max-pooling layer 'pool2', producing 15x15 128-channel output
Initialized cross-map response-normalization layer 'rnorm2', producing 15x15 128-channel output
Initialized convolutional layer 'conv3', producing 15x15 192-channel output
Initialized convolutional layer 'conv4', producing 15x15 192-channel output
Initialized convolutional layer 'conv5', producing 15x15 128-channel output
Initialized max-pooling layer 'pool5', producing 7x7 128-channel output
Initialized fully-connected layer 'fc6', producing 4096 outputs
Initialized fully-connected layer 'fc7', producing 4096 outputs
Initialized fully-connected layer 'fc8', producing 3 outputs
Initialized softmax layer 'probs', producing 3 outputs
Initialized logistic regression cost 'logprob'
Initialized neuron layer 'conv1_neuron', producing 190512 outputs
Initialized neuron layer 'conv2_neuron', producing 123008 outputs
Initialized neuron layer 'conv3_neuron', producing 43200 outputs
Initialized neuron layer 'conv4_neuron', producing 43200 outputs
Initialized neuron layer 'conv5_neuron', producing 28800 outputs
Initialized neuron layer 'fc6_neuron', producing 4096 outputs
Initialized neuron layer 'fc7_neuron', producing 4096 outputs
=========================
Importing _ConvNet C++ module
=========================
Training ConvNet
Always write savepoints, regardless of test err improvement: 0     [DEFAULT]
Check gradients and quit?                                  : 0     [DEFAULT]
Compress checkpoints?                                      : 0     [DEFAULT]
Conserve GPU memory (slower)?                              : 0     [DEFAULT]
Convert given conv layers to unshared local                :       
Cropped DP: crop border size                               : 4     [DEFAULT]
Cropped DP: logreg layer name (for --multiview-test)       :       [DEFAULT]
Cropped DP: test on multiple patches?                      : 0     [DEFAULT]
Cropped Step: crop border step                             : 1     [DEFAULT]
Data batch range: testing                                  : 801-886 
Data batch range: training                                 : 1-800 
Data path                                                  : /data2/ad6813/pipe-data/Redbox/batches/clamp_detection 
Data provider                                              : basic-leaf256 
GPU override                                               : -1    [DEFAULT]
Layer definition file                                      : /homes/ad6813/Git/pipe-classification/models/decaf-net/zero_init/17-06-2014/layers_decaf.cfg 
Layer parameter file                                       : /homes/ad6813/Git/pipe-classification/models/decaf-net/zero_init/17-06-2014/params_decaf.cfg 
Load file                                                  :       [DEFAULT]
Maximum save file size (MB)                                : 0     [DEFAULT]
Minibatch size                                             : 128   [DEFAULT]
Number of GPUs                                             : 1     [DEFAULT]
Number of epochs                                           : 50000 [DEFAULT]
Save path                                                  : /data2/ad6813/my-nets/saves 
Test and quit?                                             : 0     [DEFAULT]
Test on more than one batch at a time?                     : 0     
Test on one batch at a time?                               : 0     
Testing frequency                                          : 5     
Unshare weight matrices in given layers                    :       
=========================
Running on CUDA device(s) -2
Current time: Tue Jun 17 21:08:42 2014
Saving checkpoints to /data2/ad6813/my-nets/saves/ConvNet__2014-06-17_21.08.37
=========================
1.1... logprob:  0.473121, 0.093750 (0.715 sec)
1.2... logprob:  0.502804, 0.117188 (0.699 sec)
1.3... logprob:  0.494462, 0.101562 (0.696 sec)
1.4... logprob:  0.512591, 0.117188 (0.700 sec)
1.5... logprob:  0.512701, 0.117188 (0.697 sec)
=========================
Testing all batches
batch 801: ({'logprob': [64.9854736328125, 15.0]}, 128)

======================Test output======================
logprob:  0.507699, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.499136
-------------------------------------------------------
Saved checkpoint to /data2/ad6813/my-nets/saves/ConvNet__2014-06-17_21.08.37
======================================================= (2.140 sec)
1.6... logprob:  0.566957, 0.140625 (0.714 sec)
1.7... logprob:  0.451750, 0.085938 (0.711 sec)
1.8... logprob:  0.506118, 0.109375 (0.711 sec)
1.9... logprob:  0.456628, 0.085938 (0.714 sec)
1.10... logprob:  0.473174, 0.093750 (0.715 sec)
=========================
Testing all batches
batch 802: ({'logprob': [64.14237213134766, 14.0]}, 128)

======================Test output======================
logprob:  0.501112, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.495031
-------------------------------------------------------
Saved checkpoint to /data2/ad6813/my-nets/saves/ConvNet__2014-06-17_21.08.37
======================================================= (3.403 sec)
1.11... logprob:  0.440221, 0.078125 (0.719 sec)
1.12... logprob:  0.524114, 0.125000 (0.722 sec)
1.13... logprob:  0.517593, 0.117188 (0.717 sec)
1.14... logprob:  0.512669, 0.117188 (0.721 sec)
1.15... logprob:  0.494551, 0.101562 (0.719 sec)
=========================
Testing all batches
batch 803: ({'logprob': [70.47981262207031, 17.0]}, 128)

======================Test output======================
logprob:  0.550624, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.495964
-------------------------------------------------------
Not saving because 0.550624 > 0.501112 (1.10: -1.30%)
======================================================= (1.704 sec)
1.16... logprob:  0.501173, 0.109375 (0.724 sec)
1.17... logprob:  0.552200, 0.140625 (0.719 sec)
1.18... logprob:  0.395684, 0.054688 (0.721 sec)
1.19... logprob:  0.427017, 0.062500 (0.719 sec)
1.20... logprob:  0.501138, 0.109375 (0.721 sec)
=========================
Testing all batches
batch 804: ({'logprob': [59.096134185791016, 11.0]}, 128)

======================Test output======================
logprob:  0.461689, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.490833
-------------------------------------------------------
Saved checkpoint to /data2/ad6813/my-nets/saves/ConvNet__2014-06-17_21.08.37
======================================================= (2.277 sec)
1.21... logprob:  0.517581, 0.117188 (0.721 sec)
1.22... logprob:  0.573623, 0.148438 (0.720 sec)
1.23... logprob:  0.578597, 0.148438 (0.721 sec)
1.24... logprob:  0.423672, 0.070312 (0.719 sec)
1.25... logprob:  0.451755, 0.085938 (0.721 sec)
=========================
Testing all batches
batch 805: ({'logprob': [64.3589859008789, 15.0]}, 128)

======================Test output======================
logprob:  0.502805, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.494476
-------------------------------------------------------
Not saving because 0.502805 > 0.461689 (1.20: -7.87%)
======================================================= (1.707 sec)
1.26... logprob:  0.529158, 0.125000 (0.721 sec)
1.27... logprob:  0.469870, 0.101562 (0.721 sec)
1.28... logprob:  0.496167, 0.109375 (0.720 sec)
1.29... logprob:  0.494504, 0.101562 (1.035 sec)
1.30... logprob:  0.483007, 0.093750 (1.450 sec)
=========================
Testing all batches
batch 806: ({'logprob': [63.49745559692383, 14.0]}, 128)

======================Test output======================
logprob:  0.496074, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.494487
-------------------------------------------------------
Not saving because 0.496074 > 0.461689 (1.20: -7.87%)
======================================================= (2.480 sec)
1.31... logprob:  0.555495, 0.132812 (1.436 sec)
1.32... logprob:  0.544039, 0.125000 (1.419 sec)
1.33... logprob:  0.534062, 0.125000 (1.490 sec)
1.34... logprob:  0.524127, 0.125000 (1.424 sec)
1.35... logprob:  0.428691, 0.070312 (1.432 sec)
=========================
Testing all batches
batch 807: ({'logprob': [66.25798034667969, 15.0]}, 128)

======================Test output======================
logprob:  0.517640, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.497743
-------------------------------------------------------
Not saving because 0.517640 > 0.461689 (1.20: -7.87%)
======================================================= (2.548 sec)
1.36... logprob:  0.560411, 0.132812 (1.438 sec)
1.37... logprob:  0.506135, 0.109375 (1.440 sec)
1.38... logprob:  0.499513, 0.101562 (1.429 sec)
1.39... logprob:  0.646134, 0.187500 (1.467 sec)
1.40... logprob:  0.507679, 0.117188 (1.446 sec)
=========================
Testing all batches
batch 808: ({'logprob': [69.0020523071289, 16.0]}, 128)

======================Test output======================
logprob:  0.539079, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.503522
-------------------------------------------------------
Not saving because 0.539079 > 0.461689 (1.20: -7.87%)
======================================================= (5.160 sec)
1.41... logprob:  0.466601, 0.085938 (1.456 sec)
1.42... logprob:  0.499485, 0.101562 (1.449 sec)
1.43... logprob:  0.517590, 0.117188 (1.436 sec)
1.44... logprob:  0.583558, 0.148438 (1.470 sec)
1.45... logprob:  0.468269, 0.093750 (1.417 sec)
=========================
Testing all batches
batch 809: ({'logprob': [81.64375305175781, 22.0]}, 128)

======================Test output======================
logprob:  0.637842, 0.171875 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.503920
-------------------------------------------------------
Not saving because 0.637842 > 0.461689 (1.20: -7.87%)
======================================================= (2.473 sec)
1.46... logprob:  0.540528, 0.132812 (1.427 sec)
1.47... logprob:  0.450078, 0.078125 (1.465 sec)
1.48... logprob:  0.566990, 0.140625 (1.450 sec)
1.49... logprob:  0.593451, 0.148438 (1.445 sec)
1.50... logprob:  0.494550, 0.101562 (1.457 sec)
=========================
Testing all batches
batch 810: ({'logprob': [65.61189270019531, 15.0]}, 128)

======================Test output======================
logprob:  0.512593, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.506440
-------------------------------------------------------
Not saving because 0.512593 > 0.461689 (1.20: -7.87%)
======================================================= (2.488 sec)
1.51... logprob:  0.576928, 0.140625 (1.455 sec)
1.52... logprob:  0.573586, 0.148438 (1.437 sec)
1.53... logprob:  0.417139, 0.062500 (1.476 sec)
1.54... logprob:  0.520969, 0.109375 (1.424 sec)
1.55... logprob:  0.450081, 0.078125 (1.438 sec)
=========================
Testing all batches
batch 811: ({'logprob': [68.35869598388672, 16.0]}, 128)

======================Test output======================
logprob:  0.534052, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.506558
-------------------------------------------------------
Not saving because 0.534052 > 0.461689 (1.20: -7.87%)
======================================================= (2.489 sec)
1.56... logprob:  0.501116, 0.109375 (1.466 sec)
1.57... logprob:  0.601506, 0.164062 (1.458 sec)
1.58... logprob:  0.479662, 0.101562 (1.432 sec)
1.59... logprob:  0.445117, 0.078125 (1.496 sec)
1.60... logprob:  0.629630, 0.179688 (1.451 sec)
=========================
Testing all batches
batch 812: ({'logprob': [67.72852325439453, 16.0]}, 128)

======================Test output======================
logprob:  0.529129, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.508629
-------------------------------------------------------
Not saving because 0.529129 > 0.461689 (1.20: -7.87%)
======================================================= (2.481 sec)
1.61... logprob:  0.468148, 0.093750 (1.465 sec)
1.62... logprob:  0.555488, 0.132812 (1.492 sec)
1.63... logprob:  0.489627, 0.101562 (1.470 sec)
1.64... logprob:  0.544097, 0.125000 (1.440 sec)
1.65... logprob:  0.478174, 0.093750 (1.435 sec)
=========================
Testing all batches
batch 813: ({'logprob': [68.57632446289062, 17.0]}, 128)

======================Test output======================
logprob:  0.535753, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.508512
-------------------------------------------------------
Not saving because 0.535753 > 0.461689 (1.20: -7.87%)
======================================================= (2.527 sec)
1.66... logprob:  0.461670, 0.085938 (1.482 sec)
1.67... logprob:  0.412191, 0.062500 (1.424 sec)
1.68... logprob:  0.489638, 0.101562 (1.431 sec)
1.69... logprob:  0.571997, 0.140625 (1.447 sec)
1.70... logprob:  0.450033, 0.078125 (1.456 sec)
=========================
Testing all batches
batch 814: ({'logprob': [71.11199951171875, 17.0]}, 128)

======================Test output======================
logprob:  0.555562, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.506268
-------------------------------------------------------
Not saving because 0.555562 > 0.461689 (1.20: -7.87%)
======================================================= (2.494 sec)
1.71... logprob:  0.504447, 0.101562 (1.498 sec)
1.72... logprob:  0.540692, 0.132812 (1.439 sec)
1.73... logprob:  0.512661, 0.117188 (1.456 sec)
1.74... logprob:  0.517665, 0.117188 (1.447 sec)
1.75... logprob:  0.468203, 0.093750 (1.450 sec)
=========================
Testing all batches
batch 815: ({'logprob': [57.81744384765625, 11.0]}, 128)

======================Test output======================
logprob:  0.451699, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.506433
-------------------------------------------------------
Saved checkpoint to /data2/ad6813/my-nets/saves/ConvNet__2014-06-17_21.08.37
======================================================= (3.012 sec)
1.76... logprob:  0.510964, 0.109375 (1.468 sec)
1.77... logprob:  0.489655, 0.101562 (1.462 sec)
1.78... logprob:  0.576943, 0.140625 (1.501 sec)
1.79... logprob:  0.539036, 0.125000 (2.925 sec)
1.80... logprob:  0.520832, 0.132812 (1.454 sec)
=========================
Testing all batches
batch 816: ({'logprob': [62.03542709350586, 13.0]}, 128)

======================Test output======================
logprob:  0.484652, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.507749
-------------------------------------------------------
Not saving because 0.484652 > 0.451699 (1.75: -2.16%)
======================================================= (2.535 sec)
1.81... logprob:  0.506081, 0.109375 (1.696 sec)
1.82... logprob:  0.372662, 0.039062 (1.461 sec)
1.83... logprob:  0.572057, 0.140625 (1.445 sec)
1.84... logprob:  0.524137, 0.125000 (1.499 sec)
1.85... logprob:  0.527469, 0.117188 (1.450 sec)
=========================
Testing all batches
batch 817: ({'logprob': [64.14230346679688, 14.0]}, 128)

======================Test output======================
logprob:  0.501112, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.507321
-------------------------------------------------------
Not saving because 0.501112 > 0.451699 (1.75: -2.16%)
======================================================= (2.494 sec)
1.86... logprob:  0.506146, 0.109375 (1.448 sec)
1.87... logprob:  0.641137, 0.187500 (1.456 sec)
1.88... logprob:  0.599899, 0.156250 (1.440 sec)
1.89... logprob:  0.515941, 0.109375 (1.467 sec)
1.90... logprob:  0.622940, 0.171875 (1.428 sec)
=========================
Testing all batches
batch 818: ({'logprob': [77.00069427490234, 21.0]}, 128)

======================Test output======================
logprob:  0.601568, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.511204
-------------------------------------------------------
Not saving because 0.601568 > 0.451699 (1.75: -2.16%)
======================================================= (2.486 sec)
1.91... logprob:  0.440142, 0.078125 (1.429 sec)
1.92... logprob:  0.529127, 0.125000 (1.465 sec)
1.93... logprob:  0.571916, 0.140625 (1.439 sec)
1.94... logprob:  0.496144, 0.109375 (1.420 sec)
1.95... logprob:  0.519166, 0.125000 (1.437 sec)
=========================
Testing all batches
batch 819: ({'logprob': [72.57974243164062, 18.0]}, 128)

======================Test output======================
logprob:  0.567029, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.511209
-------------------------------------------------------
Not saving because 0.567029 > 0.451699 (1.75: -2.16%)
======================================================= (2.478 sec)
1.96... logprob:  0.623099, 0.171875 (1.437 sec)
1.97... logprob:  0.532524, 0.117188 (1.516 sec)
1.98... logprob:  0.463226, 0.093750 (1.472 sec)
1.99... logprob:  0.555499, 0.132812 (1.435 sec)
1.100... logprob:  0.443542, 0.070312 (1.436 sec)
=========================
Testing all batches
batch 820: ({'logprob': [64.78218841552734, 14.0]}, 128)

======================Test output======================
logprob:  0.506111, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.511827
-------------------------------------------------------
Not saving because 0.506111 > 0.451699 (1.75: -2.16%)
======================================================= (2.494 sec)
1.101... logprob:  0.397330, 0.062500 (1.482 sec)
1.102... logprob:  0.589935, 0.156250 (1.422 sec)
1.103... logprob:  0.599950, 0.156250 (1.438 sec)
1.104... logprob:  0.499492, 0.101562 (1.434 sec)
1.105... logprob:  0.629635, 0.179688 (1.423 sec)
=========================
Testing all batches
batch 821: ({'logprob': [61.4152717590332, 13.0]}, 128)

======================Test output======================
logprob:  0.479807, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.513325
-------------------------------------------------------
Not saving because 0.479807 > 0.451699 (1.75: -2.16%)
======================================================= (2.486 sec)
1.106... logprob:  0.471628, 0.085938 (1.436 sec)
1.107... logprob:  0.440168, 0.078125 (1.474 sec)
1.108... logprob:  0.628070, 0.171875 (1.430 sec)
1.109... logprob:  0.440186, 0.078125 (1.431 sec)
1.110... logprob:  0.611572, 0.164062 (1.438 sec)
=========================
Testing all batches
batch 822: ({'logprob': [66.26049041748047, 15.0]}, 128)

======================Test output======================
logprob:  0.517660, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.513552
-------------------------------------------------------
Not saving because 0.517660 > 0.451699 (1.75: -2.16%)
======================================================= (2.529 sec)
1.111... logprob:  0.479726, 0.101562 (1.431 sec)
1.112... logprob:  0.488003, 0.093750 (1.441 sec)
1.113... logprob:  0.461608, 0.085938 (1.440 sec)
1.114... logprob:  0.517536, 0.117188 (1.460 sec)
1.115... logprob:  0.557071, 0.140625 (1.452 sec)
=========================
Testing all batches
batch 823: ({'logprob': [56.341068267822266, 10.0]}, 128)

======================Test output======================
logprob:  0.440165, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.512997
-------------------------------------------------------
Saved checkpoint to /data2/ad6813/my-nets/saves/ConvNet__2014-06-17_21.08.37
======================================================= (2.993 sec)
1.116... logprob:  0.494547, 0.101562 (1.474 sec)
1.117... logprob:  0.517621, 0.117188 (1.478 sec)
1.118... logprob:  0.474809, 0.101562 (1.424 sec)
1.119... logprob:  0.471525, 0.085938 (2.940 sec)
1.120... logprob:  0.590068, 0.156250 (1.440 sec)
=========================
Testing all batches
batch 824: ({'logprob': [67.93396759033203, 17.0]}, 128)

======================Test output======================
logprob:  0.530734, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.512860
-------------------------------------------------------
Not saving because 0.530734 > 0.440165 (1.115: -2.55%)
======================================================= (2.480 sec)
1.121... logprob:  0.510962, 0.109375 (1.993 sec)
1.122... logprob:  0.583498, 0.148438 (1.479 sec)
1.123... logprob:  0.529075, 0.125000 (1.422 sec)
1.124... logprob:  0.548938, 0.125000 (1.443 sec)
1.125... logprob:  0.562013, 0.140625 (1.429 sec)
=========================
Testing all batches
batch 825: ({'logprob': [54.02691650390625, 8.0]}, 128)

======================Test output======================
logprob:  0.422085, 0.062500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.514222
-------------------------------------------------------
Saved checkpoint to /data2/ad6813/my-nets/saves/ConvNet__2014-06-17_21.08.37
======================================================= (3.103 sec)
1.126... logprob:  0.514244, 0.125000 (1.427 sec)
1.127... logprob:  0.509332, 0.125000 (1.432 sec)
1.128... logprob:  0.501141, 0.109375 (1.449 sec)
1.129... logprob:  0.586724, 0.164062 (1.450 sec)
1.130... logprob:  0.473194, 0.093750 (1.447 sec)
=========================
Testing all batches
batch 826: ({'logprob': [60.57160568237305, 12.0]}, 128)

======================Test output======================
logprob:  0.473216, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.514326
-------------------------------------------------------
Not saving because 0.473216 > 0.422085 (1.125: -4.11%)
======================================================= (2.480 sec)
1.131... logprob:  0.525846, 0.132812 (1.449 sec)
1.132... logprob:  0.552187, 0.140625 (1.469 sec)
1.133... logprob:  0.512758, 0.117188 (1.427 sec)
1.134... logprob:  0.489572, 0.101562 (1.426 sec)
1.135... logprob:  0.534031, 0.125000 (1.440 sec)
=========================
Testing all batches
batch 827: ({'logprob': [64.13499450683594, 14.0]}, 128)

======================Test output======================
logprob:  0.501055, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.514642
-------------------------------------------------------
Not saving because 0.501055 > 0.422085 (1.125: -4.11%)
======================================================= (2.488 sec)
1.136... logprob:  0.601562, 0.164062 (1.436 sec)
1.137... logprob:  0.529136, 0.125000 (1.436 sec)
1.138... logprob:  0.433592, 0.070312 (1.484 sec)
1.139... logprob:  0.499408, 0.101562 (1.434 sec)
1.140... logprob:  0.616415, 0.164062 (1.443 sec)
=========================
Testing all batches
batch 828: ({'logprob': [66.24132537841797, 15.0]}, 128)

======================Test output======================
logprob:  0.517510, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.515406
-------------------------------------------------------
Not saving because 0.517510 > 0.422085 (1.125: -4.11%)
======================================================= (2.482 sec)
1.141... logprob:  0.524223, 0.125000 (4.362 sec)
1.142... logprob:  0.524198, 0.125000 (1.441 sec)
1.143... logprob:  0.412091, 0.062500 (1.455 sec)
1.144... logprob:  0.543946, 0.125000 (1.457 sec)
1.145... logprob:  0.464988, 0.078125 (1.455 sec)
=========================
Testing all batches
batch 829: ({'logprob': [74.47496795654297, 18.0]}, 128)

======================Test output======================
logprob:  0.581836, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.514664
-------------------------------------------------------
Not saving because 0.581836 > 0.422085 (1.125: -4.11%)
======================================================= (2.487 sec)
1.146... logprob:  0.550627, 0.132812 (1.453 sec)
1.147... logprob:  0.405647, 0.054688 (1.468 sec)
1.148... logprob:  0.543932, 0.125000 (1.420 sec)
1.149... logprob:  0.517604, 0.117188 (1.427 sec)
1.150... logprob:  0.466538, 0.085938 (1.430 sec)
=========================
Testing all batches
batch 830: ({'logprob': [66.89697265625, 15.0]}, 128)

======================Test output======================
logprob:  0.522633, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.514071
-------------------------------------------------------
Not saving because 0.522633 > 0.422085 (1.125: -4.11%)
======================================================= (2.488 sec)
1.151... logprob:  0.466612, 0.085938 (1.441 sec)
1.152... logprob:  0.745011, 0.234375 (1.424 sec)
1.153... logprob:  0.463268, 0.093750 (1.474 sec)
1.154... logprob:  0.583537, 0.148438 (1.430 sec)
1.155... logprob:  0.537455, 0.117188 (1.440 sec)
=========================
Testing all batches
batch 831: ({'logprob': [71.95584106445312, 18.0]}, 128)

======================Test output======================
logprob:  0.562155, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.515526
-------------------------------------------------------
Not saving because 0.562155 > 0.422085 (1.125: -4.11%)
======================================================= (2.529 sec)
1.156... logprob:  0.412197, 0.062500 (1.469 sec)
1.157... logprob:  0.405673, 0.054688 (1.427 sec)
1.158... logprob:  0.539050, 0.125000 (1.447 sec)
1.159... logprob:  0.545625, 0.132812 (1.428 sec)
1.160... logprob:  0.512690, 0.117188 (1.424 sec)
=========================
Testing all batches
batch 832: ({'logprob': [56.34614562988281, 10.0]}, 128)

======================Test output======================
logprob:  0.440204, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.514511
-------------------------------------------------------
Not saving because 0.440204 > 0.422085 (1.125: -4.11%)
======================================================= (2.483 sec)
1.161... logprob:  0.430275, 0.078125 (1.438 sec)
1.162... logprob:  0.629744, 0.179688 (1.442 sec)
1.163... logprob:  0.543988, 0.125000 (1.457 sec)
1.164... logprob:  0.524248, 0.125000 (1.461 sec)
1.165... logprob:  0.585129, 0.156250 (1.454 sec)
=========================
Testing all batches
batch 833: ({'logprob': [69.83384704589844, 17.0]}, 128)

======================Test output======================
logprob:  0.545577, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.515364
-------------------------------------------------------
Not saving because 0.545577 > 0.422085 (1.125: -4.11%)
======================================================= (2.501 sec)
1.166... logprob:  0.548835, 0.125000 (1.485 sec)
1.167... logprob:  0.471445, 0.085938 (1.467 sec)
1.168... logprob:  0.456672, 0.085938 (1.453 sec)
1.169... logprob:  0.479676, 0.101562 (1.491 sec)
1.170... logprob:  0.534097, 0.125000 (1.434 sec)
=========================
Testing all batches
batch 834: ({'logprob': [68.15666198730469, 15.0]}, 128)

======================Test output======================
logprob:  0.532474, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.514858
-------------------------------------------------------
Not saving because 0.532474 > 0.422085 (1.125: -4.11%)
======================================================= (2.534 sec)
1.171... logprob:  0.599993, 0.156250 (1.455 sec)
1.172... logprob:  0.486247, 0.109375 (1.447 sec)
1.173... logprob:  0.517617, 0.117188 (1.453 sec)
1.174... logprob:  0.603242, 0.171875 (1.434 sec)
1.175... logprob:  0.557101, 0.140625 (1.508 sec)
=========================
Testing all batches
batch 835: ({'logprob': [70.88435363769531, 19.0]}, 128)

======================Test output======================
logprob:  0.553784, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.515943
-------------------------------------------------------
Not saving because 0.553784 > 0.422085 (1.125: -4.11%)
======================================================= (2.477 sec)
1.176... logprob:  0.550532, 0.132812 (1.451 sec)
1.177... logprob:  0.385763, 0.054688 (1.466 sec)
1.178... logprob:  0.468185, 0.093750 (1.490 sec)
1.179... logprob:  0.494542, 0.101562 (1.439 sec)
1.180... logprob:  0.524226, 0.125000 (1.459 sec)
=========================
Testing all batches
batch 836: ({'logprob': [60.564945220947266, 12.0]}, 128)

======================Test output======================
logprob:  0.473164, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.515074
-------------------------------------------------------
Not saving because 0.473164 > 0.422085 (1.125: -4.11%)
======================================================= (2.494 sec)
1.181... logprob:  0.599961, 0.156250 (1.483 sec)
1.182... logprob:  0.482963, 0.093750 (1.451 sec)
1.183... logprob:  0.501145, 0.109375 (1.457 sec)
1.184... logprob:  0.545620, 0.132812 (1.452 sec)
1.185... logprob:  0.417171, 0.062500 (1.420 sec)
=========================
Testing all batches
batch 837: ({'logprob': [54.8602409362793, 9.0]}, 128)

======================Test output======================
logprob:  0.428596, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.514920
-------------------------------------------------------
Not saving because 0.428596 > 0.422085 (1.125: -4.11%)
======================================================= (2.488 sec)
1.186... logprob:  0.483018, 0.093750 (1.439 sec)
1.187... logprob:  0.573676, 0.148438 (1.439 sec)
1.188... logprob:  0.539032, 0.125000 (1.423 sec)
1.189... logprob:  0.517714, 0.117188 (1.420 sec)
1.190... logprob:  0.473219, 0.093750 (1.467 sec)
=========================
Testing all batches
batch 838: ({'logprob': [66.8767318725586, 15.0]}, 128)

======================Test output======================
logprob:  0.522474, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.514983
-------------------------------------------------------
Not saving because 0.522474 > 0.422085 (1.125: -4.11%)
======================================================= (2.490 sec)
1.191... logprob:  0.545620, 0.132812 (1.448 sec)
1.192... logprob:  0.588414, 0.148438 (1.451 sec)
1.193... logprob:  0.428629, 0.070312 (1.452 sec)
1.194... logprob:  0.511044, 0.109375 (1.448 sec)
1.195... logprob:  0.422047, 0.062500 (1.438 sec)
=========================
Testing all batches
batch 839: ({'logprob': [65.82894134521484, 16.0]}, 128)

======================Test output======================
logprob:  0.514289, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.514577
-------------------------------------------------------
Not saving because 0.514289 > 0.422085 (1.125: -4.11%)
======================================================= (2.562 sec)
1.196... logprob:  0.515957, 0.109375 (1.430 sec)
1.197... logprob:  0.555470, 0.132812 (1.436 sec)
1.198... logprob:  0.456714, 0.085938 (1.432 sec)
1.199... logprob:  0.522545, 0.117188 (1.420 sec)
1.200... logprob:  0.517662, 0.117188 (1.471 sec)
=========================
Testing all batches
batch 840: ({'logprob': [72.99861907958984, 20.0]}, 128)

======================Test output======================
logprob:  0.570302, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.514555
-------------------------------------------------------
Not saving because 0.570302 > 0.422085 (1.125: -4.11%)
======================================================= (2.533 sec)
1.201... logprob:  0.522643, 0.117188 (1.442 sec)
1.202... logprob:  0.563683, 0.148438 (1.439 sec)
1.203... logprob:  0.501128, 0.109375 (1.472 sec)
1.204... logprob:  0.562158, 0.140625 (1.425 sec)
1.205... logprob:  0.445092, 0.078125 (1.438 sec)
=========================
Testing all batches
batch 841: ({'logprob': [63.30925750732422, 13.0]}, 128)

======================Test output======================
logprob:  0.494604, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.514662
-------------------------------------------------------
Not saving because 0.494604 > 0.422085 (1.125: -4.11%)
======================================================= (2.476 sec)
1.206... logprob:  0.492918, 0.093750 (1.434 sec)
1.207... logprob:  0.468253, 0.093750 (1.427 sec)
1.208... logprob:  0.576915, 0.140625 (1.441 sec)
1.209... logprob:  0.445148, 0.078125 (1.455 sec)
1.210... logprob:  0.623157, 0.171875 (1.449 sec)
=========================
Testing all batches
batch 842: ({'logprob': [72.57878875732422, 18.0]}, 128)

======================Test output======================
logprob:  0.567022, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.514819
-------------------------------------------------------
Not saving because 0.567022 > 0.422085 (1.125: -4.11%)
======================================================= (2.489 sec)
1.211... logprob:  0.540731, 0.132812 (1.452 sec)
1.212... logprob:  0.573636, 0.148438 (1.446 sec)
1.213... logprob:  0.547255, 0.140625 (1.489 sec)
1.214... logprob:  0.534059, 0.125000 (1.461 sec)
1.215... logprob:  0.494625, 0.101562 (1.455 sec)
=========================
Testing all batches
batch 843: ({'logprob': [67.09676361083984, 16.0]}, 128)

======================Test output======================
logprob:  0.524193, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.515360
-------------------------------------------------------
Not saving because 0.524193 > 0.422085 (1.125: -4.11%)
======================================================= (2.532 sec)
1.216... logprob:  0.542265, 0.140625 (1.508 sec)
1.217... logprob:  0.428593, 0.070312 (1.442 sec)
1.218... logprob:  0.529071, 0.125000 (1.451 sec)
1.219... logprob:  0.562024, 0.140625 (1.455 sec)
1.220... logprob:  0.511024, 0.109375 (1.450 sec)
=========================
Testing all batches
batch 844: ({'logprob': [72.5876693725586, 18.0]}, 128)

======================Test output======================
logprob:  0.567091, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.515342
-------------------------------------------------------
Not saving because 0.567091 > 0.422085 (1.125: -4.11%)
======================================================= (2.491 sec)
1.221... logprob:  0.489636, 0.101562 (1.445 sec)
1.222... logprob:  0.616522, 0.164062 (1.488 sec)
1.223... logprob:  0.596563, 0.164062 (1.462 sec)
1.224... logprob:  0.479707, 0.101562 (1.464 sec)
1.225... logprob:  0.499521, 0.101562 (1.478 sec)
=========================
Testing all batches
batch 845: ({'logprob': [68.56705474853516, 17.0]}, 128)

======================Test output======================
logprob:  0.535680, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.515810
-------------------------------------------------------
Not saving because 0.535680 > 0.422085 (1.125: -4.11%)
======================================================= (2.486 sec)
1.226... logprob:  0.496247, 0.109375 (1.464 sec)
1.227... logprob:  0.543955, 0.125000 (1.451 sec)
1.228... logprob:  0.506032, 0.109375 (1.452 sec)
1.229... logprob:  0.535683, 0.132812 (1.455 sec)
1.230... logprob:  0.534092, 0.125000 (1.454 sec)
=========================
Testing all batches
batch 846: ({'logprob': [66.45528411865234, 16.0]}, 128)

======================Test output======================
logprob:  0.519182, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.515971
-------------------------------------------------------
Not saving because 0.519182 > 0.422085 (1.125: -4.11%)
======================================================= (2.485 sec)
1.231... logprob:  0.543903, 0.125000 (1.444 sec)
1.232... logprob:  0.572028, 0.140625 (1.495 sec)
1.233... logprob:  0.570389, 0.132812 (1.460 sec)
1.234... logprob:  0.606585, 0.164062 (1.457 sec)
1.235... logprob:  0.545536, 0.132812 (1.502 sec)
=========================
Testing all batches
batch 847: ({'logprob': [59.10850143432617, 11.0]}, 128)

======================Test output======================
logprob:  0.461785, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.517071
-------------------------------------------------------
Not saving because 0.461785 > 0.422085 (1.125: -4.11%)
======================================================= (2.490 sec)
1.236... logprob:  0.496114, 0.109375 (1.441 sec)
1.237... logprob:  0.445135, 0.078125 (1.461 sec)
1.238... logprob:  0.463222, 0.093750 (1.451 sec)
1.239... logprob:  0.550494, 0.132812 (1.455 sec)
1.240... logprob:  0.540718, 0.132812 (1.438 sec)
=========================
Testing all batches
batch 848: ({'logprob': [63.9375, 13.0]}, 128)

======================Test output======================
logprob:  0.499512, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.516697
-------------------------------------------------------
Not saving because 0.499512 > 0.422085 (1.125: -4.11%)
======================================================= (2.487 sec)
1.241... logprob:  0.530725, 0.132812 (1.499 sec)
1.242... logprob:  0.440130, 0.078125 (1.471 sec)
1.243... logprob:  0.463220, 0.093750 (1.460 sec)
1.244... logprob:  0.428576, 0.070312 (1.485 sec)
1.245... logprob:  0.530776, 0.132812 (1.456 sec)
=========================
Testing all batches
batch 849: ({'logprob': [59.08237838745117, 11.0]}, 128)

======================Test output======================
logprob:  0.461581, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.515922
-------------------------------------------------------
Not saving because 0.461581 > 0.422085 (1.125: -4.11%)
======================================================= (2.528 sec)
1.246... logprob:  0.506085, 0.109375 (1.449 sec)
1.247... logprob:  0.451724, 0.085938 (1.453 sec)
1.248... logprob:  0.428633, 0.070312 (1.446 sec)
1.249... logprob:  0.594997, 0.156250 (1.457 sec)
1.250... logprob:  0.586820, 0.164062 (1.443 sec)
=========================
Testing all batches
batch 850: ({'logprob': [70.47628021240234, 17.0]}, 128)

======================Test output======================
logprob:  0.550596, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.515876
-------------------------------------------------------
Not saving because 0.550596 > 0.422085 (1.125: -4.11%)
======================================================= (2.491 sec)
1.251... logprob:  0.456716, 0.085938 (1.494 sec)
1.252... logprob:  0.466625, 0.085938 (1.462 sec)
1.253... logprob:  0.463251, 0.093750 (1.451 sec)
1.254... logprob:  0.512629, 0.117188 (1.498 sec)
1.255... logprob:  0.461563, 0.085938 (1.431 sec)
=========================
Testing all batches
batch 851: ({'logprob': [66.25389862060547, 15.0]}, 128)

======================Test output======================
logprob:  0.517609, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.515019
-------------------------------------------------------
Not saving because 0.517609 > 0.422085 (1.125: -4.11%)
======================================================= (2.502 sec)
1.256... logprob:  0.463312, 0.093750 (1.456 sec)
1.257... logprob:  0.440256, 0.078125 (1.455 sec)
1.258... logprob:  0.515980, 0.109375 (1.452 sec)
1.259... logprob:  0.517565, 0.117188 (1.433 sec)
1.260... logprob:  0.428668, 0.070312 (1.497 sec)
=========================
Testing all batches
batch 852: ({'logprob': [75.53997039794922, 20.0]}, 128)

======================Test output======================
logprob:  0.590156, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.514214
-------------------------------------------------------
Not saving because 0.590156 > 0.422085 (1.125: -4.11%)
======================================================= (2.532 sec)
1.261... logprob:  0.504487, 0.101562 (1.467 sec)
1.262... logprob:  0.603297, 0.148438 (1.477 sec)
1.263... logprob:  0.486310, 0.109375 (1.480 sec)
1.264... logprob:  0.473096, 0.093750 (1.454 sec)
1.265... logprob:  0.522522, 0.117188 (1.444 sec)
=========================
Testing all batches
batch 853: ({'logprob': [61.830135345458984, 12.0]}, 128)

======================Test output======================
logprob:  0.483048, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.514284
-------------------------------------------------------
Not saving because 0.483048 > 0.422085 (1.125: -4.11%)
======================================================= (2.489 sec)
1.266... logprob:  0.522664, 0.117188 (1.484 sec)
1.267... logprob:  0.496206, 0.109375 (1.459 sec)
1.268... logprob:  0.538971, 0.125000 (1.450 sec)
1.269... logprob:  0.606523, 0.164062 (1.436 sec)
1.270... logprob:  0.595016, 0.156250 (1.493 sec)
=========================
Testing all batches
batch 854: ({'logprob': [56.14016342163086, 9.0]}, 128)

======================Test output======================
logprob:  0.438595, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.514981
-------------------------------------------------------
Not saving because 0.438595 > 0.422085 (1.125: -4.11%)
======================================================= (2.502 sec)
1.271... logprob:  0.507710, 0.117188 (1.461 sec)
1.272... logprob:  0.468237, 0.093750 (1.453 sec)
1.273... logprob:  0.562077, 0.140625 (1.494 sec)
1.274... logprob:  0.585110, 0.156250 (1.435 sec)
1.275... logprob:  0.535685, 0.132812 (1.453 sec)
=========================
Testing all batches
batch 855: ({'logprob': [69.84185791015625, 17.0]}, 128)

======================Test output======================
logprob:  0.545640, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.515286
-------------------------------------------------------
Not saving because 0.545640 > 0.422085 (1.125: -4.11%)
======================================================= (2.484 sec)
1.276... logprob:  0.468216, 0.093750 (1.454 sec)
1.277... logprob:  0.496240, 0.109375 (1.459 sec)
1.278... logprob:  0.438519, 0.070312 (1.454 sec)
1.279... logprob:  0.428646, 0.070312 (1.498 sec)
1.280... logprob:  0.361056, 0.031250 (1.437 sec)
=========================
Testing all batches
batch 856: ({'logprob': [65.61122131347656, 15.0]}, 128)

======================Test output======================
logprob:  0.512588, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.513915
-------------------------------------------------------
Not saving because 0.512588 > 0.422085 (1.125: -4.11%)
======================================================= (2.481 sec)
1.281... logprob:  0.506084, 0.109375 (1.456 sec)
1.282... logprob:  0.515907, 0.109375 (1.449 sec)
1.283... logprob:  0.494588, 0.101562 (1.453 sec)
1.284... logprob:  0.494586, 0.101562 (1.446 sec)
1.285... logprob:  0.512680, 0.117188 (1.473 sec)
=========================
Testing all batches
batch 857: ({'logprob': [61.18789291381836, 12.0]}, 128)

======================Test output======================
logprob:  0.478030, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.513755
-------------------------------------------------------
Not saving because 0.478030 > 0.422085 (1.125: -4.11%)
======================================================= (2.489 sec)
1.286... logprob:  0.542274, 0.140625 (1.471 sec)
1.287... logprob:  0.466545, 0.085938 (1.463 sec)
1.288... logprob:  0.440203, 0.078125 (1.471 sec)
1.289... logprob:  0.522588, 0.117188 (1.482 sec)
1.290... logprob:  0.555446, 0.132812 (1.441 sec)
=========================
Testing all batches
batch 858: ({'logprob': [62.67490768432617, 13.0]}, 128)

======================Test output======================
logprob:  0.489648, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.513611
-------------------------------------------------------
Not saving because 0.489648 > 0.422085 (1.125: -4.11%)
======================================================= (2.528 sec)
1.291... logprob:  0.527544, 0.117188 (1.458 sec)
1.292... logprob:  0.580197, 0.156250 (1.454 sec)
1.293... logprob:  0.537438, 0.117188 (1.453 sec)
1.294... logprob:  0.456672, 0.085938 (1.435 sec)
1.295... logprob:  0.445194, 0.078125 (1.495 sec)
=========================
Testing all batches
batch 859: ({'logprob': [54.87572479248047, 9.0]}, 128)

======================Test output======================
logprob:  0.428717, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.513540
-------------------------------------------------------
Not saving because 0.428717 > 0.422085 (1.125: -4.11%)
======================================================= (2.495 sec)
1.296... logprob:  0.461610, 0.085938 (1.464 sec)
1.297... logprob:  0.494616, 0.101562 (1.461 sec)
1.298... logprob:  0.549003, 0.125000 (1.493 sec)
1.299... logprob:  0.440173, 0.078125 (1.440 sec)
1.300... logprob:  0.479683, 0.101562 (1.455 sec)
=========================
Testing all batches
batch 860: ({'logprob': [73.63260650634766, 20.0]}, 128)

======================Test output======================
logprob:  0.575255, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.513064
-------------------------------------------------------
Not saving because 0.575255 > 0.422085 (1.125: -4.11%)
======================================================= (2.508 sec)
1.301... logprob:  0.489683, 0.101562 (1.457 sec)
1.302... logprob:  0.654319, 0.179688 (1.455 sec)
1.303... logprob:  0.533987, 0.125000 (1.437 sec)
1.304... logprob:  0.534085, 0.125000 (1.474 sec)
1.305... logprob:  0.539092, 0.125000 (1.466 sec)
=========================
Testing all batches
batch 861: ({'logprob': [64.76615142822266, 14.0]}, 128)

======================Test output======================
logprob:  0.505986, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.513674
-------------------------------------------------------
Not saving because 0.505986 > 0.422085 (1.125: -4.11%)
======================================================= (2.521 sec)
1.306... logprob:  0.517612, 0.117188 (1.468 sec)
1.307... logprob:  0.501135, 0.109375 (1.478 sec)
1.308... logprob:  0.478145, 0.093750 (1.486 sec)
1.309... logprob:  0.543905, 0.125000 (1.449 sec)
1.310... logprob:  0.519272, 0.125000 (1.449 sec)
=========================
Testing all batches
batch 862: ({'logprob': [56.9821662902832, 10.0]}, 128)

======================Test output======================
logprob:  0.445173, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.513647
-------------------------------------------------------
Not saving because 0.445173 > 0.422085 (1.125: -4.11%)
======================================================= (2.489 sec)
1.311... logprob:  0.562195, 0.140625 (1.455 sec)
1.312... logprob:  0.550576, 0.132812 (1.471 sec)
1.313... logprob:  0.539099, 0.125000 (1.451 sec)
1.314... logprob:  0.502744, 0.117188 (1.500 sec)
1.315... logprob:  0.433583, 0.070312 (1.469 sec)
=========================
Testing all batches
batch 863: ({'logprob': [62.04043197631836, 13.0]}, 128)

======================Test output======================
logprob:  0.484691, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.513710
-------------------------------------------------------
Not saving because 0.484691 > 0.422085 (1.125: -4.11%)
======================================================= (2.491 sec)
1.316... logprob:  0.524276, 0.125000 (1.460 sec)
1.317... logprob:  0.461648, 0.085938 (1.513 sec)
1.318... logprob:  0.539049, 0.125000 (1.446 sec)
1.319... logprob:  0.537327, 0.117188 (1.455 sec)
1.320... logprob:  0.511016, 0.109375 (1.457 sec)
=========================
Testing all batches
batch 864: ({'logprob': [64.35167694091797, 15.0]}, 128)

======================Test output======================
logprob:  0.502747, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.513725
-------------------------------------------------------
Not saving because 0.502747 > 0.422085 (1.125: -4.11%)
======================================================= (2.486 sec)
1.321... logprob:  0.466555, 0.085938 (1.455 sec)
1.322... logprob:  0.499526, 0.101562 (1.449 sec)
1.323... logprob:  0.506116, 0.109375 (1.509 sec)
1.324... logprob:  0.572066, 0.140625 (1.457 sec)
1.325... logprob:  0.461659, 0.085938 (1.463 sec)
=========================
Testing all batches
batch 865: ({'logprob': [70.4604263305664, 17.0]}, 128)

======================Test output======================
logprob:  0.550472, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.513532
-------------------------------------------------------
Not saving because 0.550472 > 0.422085 (1.125: -4.11%)
======================================================= (2.482 sec)
1.326... logprob:  0.563722, 0.148438 (1.502 sec)
1.327... logprob:  0.626340, 0.164062 (1.485 sec)
1.328... logprob:  0.575275, 0.156250 (1.457 sec)
1.329... logprob:  0.484623, 0.101562 (1.457 sec)
1.330... logprob:  0.499480, 0.101562 (1.455 sec)
=========================
Testing all batches
batch 866: ({'logprob': [71.94695281982422, 18.0]}, 128)

======================Test output======================
logprob:  0.562086, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.514083
-------------------------------------------------------
Not saving because 0.562086 > 0.422085 (1.125: -4.11%)
======================================================= (2.498 sec)
1.331... logprob:  0.466521, 0.085938 (1.458 sec)
1.332... logprob:  0.545590, 0.132812 (1.480 sec)
1.333... logprob:  0.481405, 0.085938 (1.481 sec)
1.334... logprob:  0.637971, 0.171875 (1.472 sec)
1.335... logprob:  0.461631, 0.085938 (1.472 sec)
=========================
Testing all batches
batch 867: ({'logprob': [72.5763931274414, 18.0]}, 128)

======================Test output======================
logprob:  0.567003, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.514151
-------------------------------------------------------
Not saving because 0.567003 > 0.422085 (1.125: -4.11%)
======================================================= (2.510 sec)
1.336... logprob:  0.548917, 0.125000 (1.491 sec)
1.337... logprob:  0.601706, 0.164062 (1.454 sec)
1.338... logprob:  0.543968, 0.125000 (1.452 sec)
1.339... logprob:  0.540603, 0.132812 (1.455 sec)
1.340... logprob:  0.517627, 0.117188 (1.463 sec)
=========================
Testing all batches
batch 868: ({'logprob': [60.76951217651367, 13.0]}, 128)

======================Test output======================
logprob:  0.474762, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.514686
-------------------------------------------------------
Not saving because 0.474762 > 0.422085 (1.125: -4.11%)
======================================================= (2.502 sec)
1.341... logprob:  0.568683, 0.148438 (1.454 sec)
1.342... logprob:  0.496131, 0.109375 (1.501 sec)
1.343... logprob:  0.491271, 0.109375 (1.466 sec)
1.344... logprob:  0.548984, 0.125000 (1.517 sec)
1.345... logprob:  0.540724, 0.132812 (1.474 sec)
=========================
Testing all batches
batch 869: ({'logprob': [59.297080993652344, 12.0]}, 128)

======================Test output======================
logprob:  0.463258, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.514896
-------------------------------------------------------
Not saving because 0.463258 > 0.422085 (1.125: -4.11%)
======================================================= (2.512 sec)
1.346... logprob:  0.522483, 0.117188 (1.472 sec)
1.347... logprob:  0.446784, 0.085938 (1.519 sec)
1.348... logprob:  0.489630, 0.101562 (1.465 sec)
1.349... logprob:  0.567036, 0.140625 (1.466 sec)
1.350... logprob:  0.456650, 0.085938 (1.473 sec)
=========================
Testing all batches
batch 870: ({'logprob': [73.62965393066406, 20.0]}, 128)

======================Test output======================
logprob:  0.575232, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.514633
-------------------------------------------------------
Not saving because 0.575232 > 0.422085 (1.125: -4.11%)
======================================================= (2.517 sec)
1.351... logprob:  0.557106, 0.140625 (1.474 sec)
1.352... logprob:  0.487966, 0.093750 (1.475 sec)
1.353... logprob:  0.593448, 0.148438 (1.521 sec)
1.354... logprob:  0.683954, 0.203125 (1.467 sec)
1.355... logprob:  0.456697, 0.085938 (1.481 sec)
=========================
Testing all batches
batch 871: ({'logprob': [58.24811935424805, 10.0]}, 128)

======================Test output======================
logprob:  0.455063, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.515214
-------------------------------------------------------
Not saving because 0.455063 > 0.422085 (1.125: -4.11%)
======================================================= (2.509 sec)
1.356... logprob:  0.550589, 0.132812 (1.513 sec)
1.357... logprob:  0.471575, 0.085938 (1.470 sec)
1.358... logprob:  0.418751, 0.070312 (1.480 sec)
1.359... logprob:  0.616461, 0.164062 (1.464 sec)
1.360... logprob:  0.512745, 0.117188 (1.464 sec)
=========================
Testing all batches
batch 872: ({'logprob': [74.6856460571289, 19.0]}, 128)

======================Test output======================
logprob:  0.583482, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.515197
-------------------------------------------------------
Not saving because 0.583482 > 0.422085 (1.125: -4.11%)
======================================================= (2.503 sec)
1.361... logprob:  0.474763, 0.101562 (1.480 sec)
1.362... logprob:  0.537446, 0.117188 (1.514 sec)
1.363... logprob:  0.540650, 0.132812 (1.478 sec)
1.364... logprob:  0.514204, 0.125000 (1.483 sec)
1.365... logprob:  0.496167, 0.109375 (1.496 sec)
=========================
Testing all batches
batch 873: ({'logprob': [54.23400115966797, 9.0]}, 128)

======================Test output======================
logprob:  0.423703, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.515162
-------------------------------------------------------
Not saving because 0.423703 > 0.422085 (1.125: -4.11%)
======================================================= (2.487 sec)
1.366... logprob:  0.515833, 0.109375 (1.485 sec)
1.367... logprob:  0.460028, 0.078125 (1.474 sec)
1.368... logprob:  0.608102, 0.171875 (1.460 sec)
1.369... logprob:  0.468160, 0.093750 (1.465 sec)
1.370... logprob:  0.468140, 0.093750 (1.468 sec)
=========================
Testing all batches
batch 874: ({'logprob': [59.079345703125, 11.0]}, 128)

======================Test output======================
logprob:  0.461557, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.515012
-------------------------------------------------------
Not saving because 0.461557 > 0.422085 (1.125: -4.11%)
======================================================= (2.481 sec)
1.371... logprob:  0.484594, 0.101562 (1.498 sec)
1.372... logprob:  0.605015, 0.156250 (1.492 sec)
1.373... logprob:  0.529177, 0.125000 (1.486 sec)
1.374... logprob:  0.573626, 0.148438 (1.487 sec)
1.375... logprob:  0.494500, 0.101562 (1.500 sec)
=========================
Testing all batches
batch 875: ({'logprob': [62.66839599609375, 13.0]}, 128)

======================Test output======================
logprob:  0.489597, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.515310
-------------------------------------------------------
Not saving because 0.489597 > 0.422085 (1.125: -4.11%)
======================================================= (2.494 sec)
1.376... logprob:  0.478081, 0.093750 (1.472 sec)
1.377... logprob:  0.412160, 0.062500 (1.461 sec)
1.378... logprob:  0.543960, 0.125000 (1.464 sec)
1.379... logprob:  0.501114, 0.109375 (1.472 sec)
1.380... logprob:  0.644456, 0.179688 (1.471 sec)
=========================
Testing all batches
batch 876: ({'logprob': [72.57776641845703, 18.0]}, 128)

======================Test output======================
logprob:  0.567014, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.515319
-------------------------------------------------------
Not saving because 0.567014 > 0.422085 (1.125: -4.11%)
======================================================= (2.513 sec)
1.381... logprob:  0.529079, 0.125000 (1.504 sec)
1.382... logprob:  0.568656, 0.148438 (1.489 sec)
1.383... logprob:  0.456587, 0.085938 (1.470 sec)
1.384... logprob:  0.578626, 0.148438 (1.515 sec)
1.385... logprob:  0.573663, 0.148438 (1.471 sec)
=========================
Testing all batches
batch 877: ({'logprob': [58.457889556884766, 11.0]}, 128)

======================Test output======================
logprob:  0.456702, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.515657
-------------------------------------------------------
Not saving because 0.456702 > 0.422085 (1.125: -4.11%)
======================================================= (2.507 sec)
1.386... logprob:  0.618093, 0.171875 (1.468 sec)
1.387... logprob:  0.537414, 0.117188 (1.473 sec)
1.388... logprob:  0.573611, 0.148438 (1.476 sec)
1.389... logprob:  0.501172, 0.109375 (1.470 sec)
1.390... logprob:  0.511028, 0.109375 (1.514 sec)
=========================
Testing all batches
batch 878: ({'logprob': [69.85212707519531, 17.0]}, 128)

======================Test output======================
logprob:  0.545720, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.516075
-------------------------------------------------------
Not saving because 0.545720 > 0.422085 (1.125: -4.11%)
======================================================= (2.512 sec)
1.391... logprob:  0.448427, 0.070312 (1.478 sec)
1.392... logprob:  0.522622, 0.117188 (1.474 sec)
1.393... logprob:  0.492964, 0.093750 (1.524 sec)
1.394... logprob:  0.440151, 0.078125 (1.466 sec)
1.395... logprob:  0.450008, 0.078125 (1.466 sec)
=========================
Testing all batches
batch 879: ({'logprob': [76.37348175048828, 21.0]}, 128)

======================Test output======================
logprob:  0.596668, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.515502
-------------------------------------------------------
Not saving because 0.596668 > 0.422085 (1.125: -4.11%)
======================================================= (2.503 sec)
1.396... logprob:  0.379277, 0.046875 (1.472 sec)
1.397... logprob:  0.550588, 0.132812 (1.464 sec)
1.398... logprob:  0.529105, 0.125000 (1.470 sec)
1.399... logprob:  0.532461, 0.117188 (1.517 sec)
1.400... logprob:  0.583509, 0.148438 (1.472 sec)
=========================
Testing all batches
batch 880: ({'logprob': [62.66399383544922, 13.0]}, 128)

======================Test output======================
logprob:  0.489562, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.515496
-------------------------------------------------------
Not saving because 0.489562 > 0.422085 (1.125: -4.11%)
======================================================= (2.505 sec)
1.401... logprob:  0.539041, 0.125000 (1.481 sec)
1.402... logprob:  0.529079, 0.125000 (1.516 sec)
1.403... logprob:  0.539033, 0.125000 (1.461 sec)
1.404... logprob:  0.524200, 0.125000 (1.476 sec)
1.405... logprob:  0.600075, 0.156250 (1.464 sec)
=========================
Testing all batches
batch 881: ({'logprob': [47.69685745239258, 5.0]}, 128)

======================Test output======================
logprob:  0.372632, 0.039062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.515876
-------------------------------------------------------
Saved checkpoint to /data2/ad6813/my-nets/saves/ConvNet__2014-06-17_21.08.37
======================================================= (2.988 sec)
1.406... logprob:  0.456651, 0.085938 (1.461 sec)
1.407... logprob:  0.571984, 0.140625 (1.467 sec)
1.408... logprob:  0.445159, 0.078125 (1.518 sec)
1.409... logprob:  0.489572, 0.101562 (2.984 sec)
1.410... logprob:  0.618121, 0.171875 (1.485 sec)
=========================
Testing all batches
batch 882: ({'logprob': [62.888160705566406, 14.0]}, 128)

======================Test output======================
logprob:  0.491314, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.515881
-------------------------------------------------------
Not saving because 0.491314 > 0.372632 (1.405: -11.72%)
======================================================= (2.478 sec)
1.411... logprob:  0.494524, 0.101562 (1.792 sec)
1.412... logprob:  0.590067, 0.156250 (1.472 sec)
1.413... logprob:  0.585061, 0.156250 (1.479 sec)
1.414... logprob:  0.529101, 0.125000 (1.467 sec)
1.415... logprob:  0.494574, 0.101562 (1.456 sec)
=========================
Testing all batches
batch 883: ({'logprob': [69.83807373046875, 17.0]}, 128)

======================Test output======================
logprob:  0.545610, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.516155
-------------------------------------------------------
Not saving because 0.545610 > 0.372632 (1.405: -11.72%)
======================================================= (2.483 sec)
1.416... logprob:  0.501124, 0.109375 (1.493 sec)
1.417... logprob:  0.453248, 0.093750 (1.499 sec)
1.418... logprob:  0.478052, 0.093750 (1.484 sec)
1.419... logprob:  0.469755, 0.101562 (1.489 sec)
1.420... logprob:  0.461601, 0.085938 (1.492 sec)
=========================
Testing all batches
batch 884: ({'logprob': [62.04248809814453, 13.0]}, 128)

======================Test output======================
logprob:  0.484707, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.515639
-------------------------------------------------------
Not saving because 0.484707 > 0.372632 (1.405: -11.72%)
======================================================= (2.494 sec)
1.421... logprob:  0.514384, 0.101562 (1.496 sec)
1.422... logprob:  0.583523, 0.148438 (1.471 sec)
1.423... logprob:  0.501057, 0.109375 (1.464 sec)
1.424... logprob:  0.450051, 0.078125 (1.487 sec)
1.425... logprob:  0.428646, 0.070312 (1.473 sec)
=========================
Testing all batches
batch 885: ({'logprob': [60.771915435791016, 13.0]}, 128)

======================Test output======================
logprob:  0.474781, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.515402
-------------------------------------------------------
Not saving because 0.474781 > 0.372632 (1.405: -11.72%)
======================================================= (2.505 sec)
1.426... logprob:  0.512752, 0.117188 (1.488 sec)
1.427... logprob:  0.604991, 0.156250 (1.492 sec)
1.428... logprob:  0.632946, 0.171875 (1.492 sec)
1.429... logprob:  0.496164, 0.109375 (1.476 sec)
1.430... logprob:  0.438600, 0.070312 (1.512 sec)
=========================
Testing all batches
batch 886: ({'logprob': [69.20498657226562, 17.0]}, 128)

======================Test output======================
logprob:  0.540664, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.515654
-------------------------------------------------------
Not saving because 0.540664 > 0.372632 (1.405: -11.72%)
======================================================= (2.510 sec)
1.431... logprob:  0.618132, 0.171875 (1.477 sec)
1.432... logprob:  0.458264, 0.093750 (1.456 sec)
1.433... logprob:  0.450103, 0.078125 (1.463 sec)
1.434... logprob:  0.568477, 0.148438 (1.476 sec)
1.435... logprob:  0.604988, 0.156250 (1.468 sec)
=========================
Testing all batches
batch 801: ({'logprob': [64.9854736328125, 15.0]}, 128)

======================Test output======================
logprob:  0.507699, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.515934
-------------------------------------------------------
Not saving because 0.507699 > 0.372632 (1.405: -11.72%)
======================================================= (1.898 sec)
1.436... logprob:  0.473117, 0.093750 (1.511 sec)
1.437... logprob:  0.562045, 0.140625 (1.479 sec)
1.438... logprob:  0.580205, 0.156250 (1.467 sec)
1.439... logprob:  0.482961, 0.093750 (1.519 sec)
1.440... logprob:  0.522612, 0.117188 (1.463 sec)
=========================
Testing all batches
batch 802: ({'logprob': [64.14237213134766, 14.0]}, 128)

======================Test output======================
logprob:  0.501112, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.516028
-------------------------------------------------------
Not saving because 0.501112 > 0.372632 (1.405: -11.72%)
======================================================= (1.696 sec)
1.441... logprob:  0.524125, 0.125000 (1.458 sec)
1.442... logprob:  0.483058, 0.093750 (1.466 sec)
1.443... logprob:  0.567102, 0.140625 (1.465 sec)
1.444... logprob:  0.487994, 0.093750 (1.459 sec)
1.445... logprob:  0.456628, 0.085938 (1.511 sec)
=========================
Testing all batches
batch 803: ({'logprob': [70.47981262207031, 17.0]}, 128)

======================Test output======================
logprob:  0.550624, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.515890
-------------------------------------------------------
Not saving because 0.550624 > 0.372632 (1.405: -11.72%)
======================================================= (1.709 sec)
1.446... logprob:  0.489626, 0.101562 (1.473 sec)
1.447... logprob:  0.601732, 0.164062 (1.474 sec)
1.448... logprob:  0.445087, 0.078125 (1.543 sec)
1.449... logprob:  0.484652, 0.101562 (1.468 sec)
1.450... logprob:  0.389164, 0.046875 (1.467 sec)
=========================
Testing all batches
batch 804: ({'logprob': [59.096134185791016, 11.0]}, 128)

======================Test output======================
logprob:  0.461689, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.515514
-------------------------------------------------------
Not saving because 0.461689 > 0.372632 (1.405: -11.72%)
======================================================= (1.708 sec)
1.451... logprob:  0.548914, 0.125000 (1.469 sec)
1.452... logprob:  0.502693, 0.117188 (1.463 sec)
1.453... logprob:  0.548986, 0.125000 (1.469 sec)
1.454... logprob:  0.550566, 0.132812 (1.523 sec)
1.455... logprob:  0.571970, 0.140625 (1.462 sec)
=========================
Testing all batches
batch 805: ({'logprob': [64.3589859008789, 15.0]}, 128)

======================Test output======================
logprob:  0.502805, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.515834
-------------------------------------------------------
Not saving because 0.502805 > 0.372632 (1.405: -11.72%)
======================================================= (1.702 sec)
1.456... logprob:  0.529117, 0.125000 (1.486 sec)
1.457... logprob:  0.473144, 0.093750 (1.503 sec)
1.458... logprob:  0.461530, 0.085938 (1.459 sec)
1.459... logprob:  0.552206, 0.140625 (1.471 sec)
1.460... logprob:  0.395668, 0.054688 (1.466 sec)
=========================
Testing all batches
batch 806: ({'logprob': [63.49745559692383, 14.0]}, 128)

======================Test output======================
logprob:  0.496074, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.979735e-03 [0.000000e+00] 
Layer 'conv1' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv2' weights[0]: 7.966643e-03 [0.000000e+00] 
Layer 'conv2' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv3' weights[0]: 7.965020e-03 [0.000000e+00] 
Layer 'conv3' biases: 0.000000e+00 [0.000000e+00] 
Layer 'conv4' weights[0]: 7.997512e-03 [0.000000e+00] 
Layer 'conv4' biases: 1.000000e+00 [0.000000e+00] 
Layer 'conv5' weights[0]: 7.996457e-03 [0.000000e+00] 
Layer 'conv5' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc6' weights[0]: 7.593280e-03 [0.000000e+00] 
Layer 'fc6' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc7' weights[0]: 7.854332e-03 [0.000000e+00] 
Layer 'fc7' biases: 1.000000e+00 [0.000000e+00] 
Layer 'fc8' weights[0]: 8.019939e-03 [0.000000e+00] 
Layer 'fc8' biases: 0.000000e+00 [0.000000e+00] 
Train error last 800 batches: 0.515470
-------------------------------------------------------
Not saving because 0.496074 > 0.372632 (1.405: -11.72%)
======================================================= (2.482 sec)
1.461... logprob:  0.534018, 0.125000 (1.465 sec)
1.462... logprob:  0.519267, 0.125000 (1.470 sec)
1.463...