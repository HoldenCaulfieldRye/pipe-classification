nohup: ignoring input
Option --layer-def (Layer definition file) cannot be changed
Option --crop-border (Cropped DP: crop border size) cannot be changed
=========================
Importing _ConvNet C++ module
=========================
Training ConvNet
Always write savepoints, regardless of test err improvement: 0     [DEFAULT]
Check gradients and quit?                                  : 0     [DEFAULT]
Compress checkpoints?                                      : 0     [DEFAULT]
Conserve GPU memory (slower)?                              : 0     [DEFAULT]
Convert given conv layers to unshared local                :       
Cropped DP: crop border size                               : 32    
Cropped DP: logreg layer name (for --multiview-test)       :       [DEFAULT]
Cropped DP: test on multiple patches?                      : 0     [DEFAULT]
Cropped Step: crop border step                             : 1     [DEFAULT]
Data batch range: testing                                  : 801-888 
Data batch range: training                                 : 1-800 
Data path                                                  : /data2/ad6813/pipe-data/Redbox/batches/clamp_detection 
Data provider                                              : basic-leaf256 
GPU override                                               : -1    [DEFAULT]
Layer definition file                                      : /homes/ad6813/Git/pipe-classification/models/decaf-net/layers_decaf.cfg 
Layer parameter file                                       : /homes/ad6813/Git/pipe-classification/models/decaf-net/params_decaf.cfg 
Load file                                                  : /data2/ad6813/my-nets/saves/ConvNet__2014-06-04_16.10.14 
Maximum save file size (MB)                                : 0     [DEFAULT]
Minibatch size                                             : 128   [DEFAULT]
Number of GPUs                                             : 1     [DEFAULT]
Number of epochs                                           : 50000 [DEFAULT]
Save path                                                  : /data2/ad6813/my-nets/saves 
Test and quit?                                             : 0     [DEFAULT]
Test on more than one batch at a time?                     : -1    [DEFAULT]
Test on one batch at a time?                               : 1     [DEFAULT]
Testing frequency                                          : 20    
Unshare weight matrices in given layers                    :       
=========================
Running on CUDA device(s) -2
Current time: Wed Jun  4 19:52:03 2014
Saving checkpoints to /data2/ad6813/my-nets/saves/ConvNet__2014-06-04_16.10.14
=========================
1.21... logprob:  0.737647, 0.316406 (1.417 sec)
1.22... logprob:  0.806754, 0.285156 (1.412 sec)
1.23... logprob:  0.788033, 0.313802 (1.418 sec)
1.24... logprob:  0.598435, 0.290365 (1.414 sec)
1.25... logprob:  0.634988, 0.266927 (1.394 sec)
1.26... logprob:  0.692669, 0.273437 (1.443 sec)
1.27... logprob:  0.687337, 0.273437 (1.383 sec)
1.28... logprob:  0.801551, 0.350260 (1.408 sec)
1.29... logprob:  0.594224, 0.283854 (1.412 sec)
1.30... logprob:  0.565279, 0.266927 (1.412 sec)
1.31... logprob:  0.777153, 0.312500 (1.392 sec)
1.32... logprob:  0.656008, 0.294271 (1.385 sec)
1.33... logprob:  0.725985, 0.311198 (1.446 sec)
1.34... logprob:  0.692710, 0.313802 (1.390 sec)
1.35... logprob:  0.522486, 0.253906 (1.389 sec)
1.36... logprob:  0.690676, 0.305990 (1.388 sec)
1.37... logprob:  0.623818, 0.287760 (1.398 sec)
1.38... logprob:  0.595717, 0.272135 (1.386 sec)
1.39... logprob:  0.691614, 0.322917 (1.423 sec)
1.40... logprob:  0.656308, 0.315104 (1.402 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.501671, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.967241e-03 [3.996171e-07] 
Layer 'conv1' biases: 7.343894e-08 [1.488071e-09] 
Layer 'conv2' weights[0]: 7.954179e-03 [3.982020e-07] 
Layer 'conv2' biases: 9.999999e-01 [1.141036e-08] 
Layer 'conv3' weights[0]: 7.952581e-03 [3.999662e-07] 
Layer 'conv3' biases: 2.074235e-06 [4.088048e-08] 
Layer 'conv4' weights[0]: 7.984965e-03 [4.091680e-07] 
Layer 'conv4' biases: 9.999973e-01 [4.293263e-07] 
Layer 'conv5' weights[0]: 7.984463e-03 [2.581222e-06] 
Layer 'conv5' biases: 9.998953e-01 [2.743187e-06] 
Layer 'fc6' weights[0]: 7.592062e-03 [5.606990e-08] 
Layer 'fc6' biases: 1.000000e+00 [4.056534e-08] 
Layer 'fc7' weights[0]: 7.945919e-03 [1.179728e-07] 
Layer 'fc7' biases: 9.999978e-01 [1.975754e-07] 
Layer 'fc8' weights[0]: 1.674873e-03 [2.300675e-05] 
Layer 'fc8' biases: 3.259962e-03 [3.305149e-05] 
Train error last 800 batches: 0.708008
-------------------------------------------------------
Not saving because 0.501671 > 0.456004 (1.20: -0.00%)
======================================================= (2.349 sec)
1.41... logprob:  0.629934, 0.269531 (1.427 sec)
1.42... logprob:  0.680732, 0.296875 (1.407 sec)
1.43... logprob:  0.718980, 0.292969 (1.402 sec)
1.44... logprob:  0.752699, 0.328125 (1.448 sec)
1.45... logprob:  0.617992, 0.273437 (1.386 sec)
1.46... logprob:  0.739861, 0.315104 (1.389 sec)
1.47... logprob:  0.586334, 0.243490 (1.454 sec)
1.48... logprob:  0.647207, 0.277344 (1.420 sec)
1.49... logprob:  0.723343, 0.307292 (1.406 sec)
1.50... logprob:  0.681847, 0.303385 (1.414 sec)
1.51... logprob:  0.726165, 0.296875 (1.400 sec)
1.52... logprob:  0.726778, 0.320312 (1.386 sec)
1.53... logprob:  0.553923, 0.265625 (1.433 sec)
1.54... logprob:  0.627737, 0.294271 (1.380 sec)
1.55... logprob:  0.586740, 0.227865 (1.396 sec)
1.56... logprob:  0.701053, 0.287760 (1.406 sec)
1.57... logprob:  0.786140, 0.316406 (1.429 sec)
1.58... logprob:  0.687695, 0.298177 (1.401 sec)
1.59... logprob:  0.646728, 0.273437 (1.457 sec)
1.60... logprob:  0.705659, 0.294271 (1.410 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.457380, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.959314e-03 [4.030483e-07] 
Layer 'conv1' biases: 8.081846e-08 [1.326471e-09] 
Layer 'conv2' weights[0]: 7.946271e-03 [4.011025e-07] 
Layer 'conv2' biases: 9.999999e-01 [8.485066e-09] 
Layer 'conv3' weights[0]: 7.944678e-03 [4.009908e-07] 
Layer 'conv3' biases: 2.339285e-06 [3.007896e-08] 
Layer 'conv4' weights[0]: 7.977026e-03 [4.052504e-07] 
Layer 'conv4' biases: 9.999966e-01 [2.667970e-07] 
Layer 'conv5' weights[0]: 7.976532e-03 [1.779106e-06] 
Layer 'conv5' biases: 9.998851e-01 [1.846905e-06] 
Layer 'fc6' weights[0]: 7.591267e-03 [4.894092e-08] 
Layer 'fc6' biases: 1.000000e+00 [3.097349e-08] 
Layer 'fc7' weights[0]: 7.945185e-03 [8.958845e-08] 
Layer 'fc7' biases: 9.999974e-01 [1.196938e-07] 
Layer 'fc8' weights[0]: 1.746799e-03 [2.320297e-05] 
Layer 'fc8' biases: 3.385542e-03 [2.966773e-05] 
Train error last 800 batches: 0.697465
-------------------------------------------------------
Not saving because 0.457380 > 0.456004 (1.20: -0.00%)
======================================================= (2.376 sec)
1.61... logprob:  0.626391, 0.274739 (1.419 sec)
1.62... logprob:  0.703574, 0.274740 (1.449 sec)
1.63... logprob:  0.584285, 0.269531 (1.434 sec)
1.64... logprob:  0.634362, 0.276042 (1.402 sec)
1.65... logprob:  0.610068, 0.247396 (1.385 sec)
1.66... logprob:  0.593078, 0.248698 (1.441 sec)
1.67... logprob:  0.568110, 0.255208 (1.383 sec)
1.68... logprob:  0.644237, 0.264323 (1.391 sec)
1.69... logprob:  0.739160, 0.308594 (1.416 sec)
1.70... logprob:  0.626202, 0.273437 (1.419 sec)
1.71... logprob:  0.601805, 0.251302 (1.457 sec)
1.72... logprob:  0.710699, 0.312500 (1.396 sec)
1.73... logprob:  0.659217, 0.260417 (1.417 sec)
1.74... logprob:  0.614254, 0.282552 (1.409 sec)
1.75... logprob:  0.570530, 0.252604 (1.402 sec)
1.76... logprob:  0.651788, 0.296875 (1.420 sec)
1.77... logprob:  0.592521, 0.268229 (1.418 sec)
1.78... logprob:  0.749983, 0.319010 (1.445 sec)
1.79... logprob:  0.641418, 0.274740 (1.386 sec)
1.80... logprob:  0.686184, 0.312500 (1.408 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.500704, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.951372e-03 [4.026085e-07] 
Layer 'conv1' biases: 8.407159e-08 [1.362703e-09] 
Layer 'conv2' weights[0]: 7.938331e-03 [3.993276e-07] 
Layer 'conv2' biases: 9.999999e-01 [6.327317e-09] 
Layer 'conv3' weights[0]: 7.936745e-03 [3.990621e-07] 
Layer 'conv3' biases: 2.500448e-06 [2.090748e-08] 
Layer 'conv4' weights[0]: 7.969053e-03 [4.021265e-07] 
Layer 'conv4' biases: 9.999960e-01 [1.888913e-07] 
Layer 'conv5' weights[0]: 7.968661e-03 [1.186695e-06] 
Layer 'conv5' biases: 9.998800e-01 [1.199710e-06] 
Layer 'fc6' weights[0]: 7.590453e-03 [4.438329e-08] 
Layer 'fc6' biases: 1.000000e+00 [2.307555e-08] 
Layer 'fc7' weights[0]: 7.944411e-03 [7.255593e-08] 
Layer 'fc7' biases: 9.999973e-01 [6.335919e-08] 
Layer 'fc8' weights[0]: 1.795622e-03 [2.412430e-05] 
Layer 'fc8' biases: 3.510377e-03 [3.458029e-05] 
Train error last 800 batches: 0.683197
-------------------------------------------------------
Not saving because 0.500704 > 0.456004 (1.20: -0.00%)
======================================================= (2.393 sec)
1.81... logprob:  0.694776, 0.322917 (1.412 sec)
1.82... logprob:  0.479196, 0.209635 (1.416 sec)
1.83... logprob:  0.841975, 0.373698 (1.420 sec)
1.84... logprob:  0.688431, 0.298177 (1.458 sec)
1.85... logprob:  0.641057, 0.309896 (1.408 sec)
1.86... logprob:  0.646495, 0.302083 (1.407 sec)
1.87... logprob:  0.838128, 0.332031 (1.407 sec)
1.88... logprob:  0.672217, 0.278646 (1.407 sec)
1.89... logprob:  0.685704, 0.316406 (1.428 sec)
1.90... logprob:  0.876440, 0.342448 (1.417 sec)
1.91... logprob:  0.657738, 0.290365 (1.393 sec)
1.92... logprob:  0.716595, 0.304687 (1.408 sec)
1.93... logprob:  0.691483, 0.296875 (1.394 sec)
1.94... logprob:  0.601248, 0.255208 (1.383 sec)
1.95... logprob:  0.674497, 0.296875 (1.397 sec)
1.96... logprob:  0.804290, 0.355469 (1.408 sec)
1.97... logprob:  0.612808, 0.264323 (1.377 sec)
1.98... logprob:  0.655421, 0.282552 (1.424 sec)
1.99... logprob:  0.629697, 0.268229 (1.395 sec)
1.100... logprob:  0.628875, 0.286458 (1.395 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.444120, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.943467e-03 [4.015189e-07] 
Layer 'conv1' biases: 8.738426e-08 [1.050932e-09] 
Layer 'conv2' weights[0]: 7.930372e-03 [3.984184e-07] 
Layer 'conv2' biases: 9.999999e-01 [5.876274e-09] 
Layer 'conv3' weights[0]: 7.928774e-03 [3.991021e-07] 
Layer 'conv3' biases: 2.684192e-06 [2.115076e-08] 
Layer 'conv4' weights[0]: 7.961073e-03 [4.026390e-07] 
Layer 'conv4' biases: 9.999969e-01 [2.215012e-07] 
Layer 'conv5' weights[0]: 7.960938e-03 [1.361926e-06] 
Layer 'conv5' biases: 9.998711e-01 [1.408377e-06] 
Layer 'fc6' weights[0]: 7.589675e-03 [4.593600e-08] 
Layer 'fc6' biases: 1.000000e+00 [2.611114e-08] 
Layer 'fc7' weights[0]: 7.943628e-03 [7.828662e-08] 
Layer 'fc7' biases: 9.999968e-01 [8.891424e-08] 
Layer 'fc8' weights[0]: 1.648561e-03 [2.845705e-05] 
Layer 'fc8' biases: 3.127122e-03 [5.254948e-05] 
Train error last 800 batches: 0.683928
-------------------------------------------------------
Saved checkpoint to /data2/ad6813/my-nets/saves/ConvNet__2014-06-04_16.10.14
======================================================= (2.840 sec)
1.101... logprob:  0.545562, 0.238281 (1.438 sec)
1.102... logprob:  0.713989, 0.294271 (1.378 sec)
1.103... logprob:  0.692123, 0.305989 (1.389 sec)
1.104... logprob:  0.592421, 0.276042 (2.319 sec)
1.105... logprob:  0.804444, 0.355469 (1.389 sec)
1.106... logprob:  0.595486, 0.264323 (1.381 sec)
1.107... logprob:  0.613992, 0.265625 (2.653 sec)
1.108... logprob:  0.707022, 0.312500 (1.425 sec)
1.109... logprob:  0.603578, 0.279948 (1.414 sec)
1.110... logprob:  0.717546, 0.295573 (1.392 sec)
1.111... logprob:  0.605659, 0.276042 (1.387 sec)
1.112... logprob:  0.602114, 0.247396 (1.397 sec)
1.113... logprob:  0.600421, 0.263021 (1.391 sec)
1.114... logprob:  0.667532, 0.285156 (1.418 sec)
1.115... logprob:  0.687579, 0.295573 (1.407 sec)
1.116... logprob:  0.583476, 0.248698 (1.396 sec)
1.117... logprob:  0.660444, 0.289062 (1.437 sec)
1.118... logprob:  0.561538, 0.257812 (1.382 sec)
1.119... logprob:  0.642871, 0.298177 (1.389 sec)
1.120... logprob:  0.691710, 0.282552 (1.396 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.461039, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.935498e-03 [4.008048e-07] 
Layer 'conv1' biases: 8.676065e-08 [1.088853e-09] 
Layer 'conv2' weights[0]: 7.922463e-03 [3.986952e-07] 
Layer 'conv2' biases: 9.999999e-01 [5.445678e-09] 
Layer 'conv3' weights[0]: 7.920841e-03 [3.982675e-07] 
Layer 'conv3' biases: 2.607550e-06 [1.985614e-08] 
Layer 'conv4' weights[0]: 7.953114e-03 [4.016568e-07] 
Layer 'conv4' biases: 9.999959e-01 [1.984319e-07] 
Layer 'conv5' weights[0]: 7.952738e-03 [1.224170e-06] 
Layer 'conv5' biases: 9.998785e-01 [1.216526e-06] 
Layer 'fc6' weights[0]: 7.588890e-03 [4.524127e-08] 
Layer 'fc6' biases: 1.000000e+00 [2.472831e-08] 
Layer 'fc7' weights[0]: 7.942821e-03 [7.491442e-08] 
Layer 'fc7' biases: 9.999973e-01 [6.506430e-08] 
Layer 'fc8' weights[0]: 1.953826e-03 [1.897417e-05] 
Layer 'fc8' biases: 3.851714e-03 [1.552856e-05] 
Train error last 800 batches: 0.677353
-------------------------------------------------------
Not saving because 0.461039 > 0.444120 (1.100: -2.61%)
======================================================= (2.399 sec)
1.121... logprob:  0.650729, 0.295573 (1.390 sec)
1.122... logprob:  0.746562, 0.325521 (1.437 sec)
1.123... logprob:  0.676057, 0.285156 (1.375 sec)
1.124... logprob:  0.676854, 0.296875 (1.397 sec)
1.125... logprob:  0.721373, 0.333333 (1.389 sec)
1.126... logprob:  0.666928, 0.287760 (1.383 sec)
1.127... logprob:  0.724725, 0.303385 (1.387 sec)
1.128... logprob:  0.699979, 0.300781 (1.416 sec)
1.129... logprob:  0.780190, 0.320312 (1.489 sec)
1.130... logprob:  0.578522, 0.248698 (1.413 sec)
1.131... logprob:  0.741289, 0.317708 (1.400 sec)
1.132... logprob:  0.642284, 0.281250 (1.426 sec)
1.133... logprob:  0.618266, 0.269531 (1.385 sec)
1.134... logprob:  0.627460, 0.273438 (1.390 sec)
1.135... logprob:  0.657215, 0.290365 (1.400 sec)
1.136... logprob:  0.801312, 0.328125 (1.393 sec)
1.137... logprob:  0.698264, 0.283854 (1.386 sec)
1.138... logprob:  0.617326, 0.282552 (1.440 sec)
1.139... logprob:  0.597721, 0.259115 (1.391 sec)
1.140... logprob:  0.725327, 0.305989 (1.405 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.475436, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.927556e-03 [4.013072e-07] 
Layer 'conv1' biases: 1.005285e-07 [1.156238e-09] 
Layer 'conv2' weights[0]: 7.914553e-03 [3.983290e-07] 
Layer 'conv2' biases: 9.999999e-01 [6.147191e-09] 
Layer 'conv3' weights[0]: 7.912966e-03 [3.982133e-07] 
Layer 'conv3' biases: 2.855320e-06 [2.148717e-08] 
Layer 'conv4' weights[0]: 7.945184e-03 [4.009353e-07] 
Layer 'conv4' biases: 9.999966e-01 [1.642260e-07] 
Layer 'conv5' weights[0]: 7.944992e-03 [1.088706e-06] 
Layer 'conv5' biases: 9.998643e-01 [1.053251e-06] 
Layer 'fc6' weights[0]: 7.588087e-03 [4.580906e-08] 
Layer 'fc6' biases: 9.999999e-01 [2.597979e-08] 
Layer 'fc7' weights[0]: 7.942057e-03 [7.680628e-08] 
Layer 'fc7' biases: 9.999965e-01 [7.323374e-08] 
Layer 'fc8' weights[0]: 1.734391e-03 [2.242350e-05] 
Layer 'fc8' biases: 3.300756e-03 [3.135248e-05] 
Train error last 800 batches: 0.678076
-------------------------------------------------------
Not saving because 0.475436 > 0.444120 (1.100: -2.61%)
======================================================= (2.388 sec)
1.141... logprob:  0.720713, 0.319010 (1.432 sec)
1.142... logprob:  0.642569, 0.281250 (1.392 sec)
1.143... logprob:  0.520443, 0.231771 (1.417 sec)
1.144... logprob:  0.663748, 0.295573 (1.413 sec)
1.145... logprob:  0.568902, 0.255208 (1.408 sec)
1.146... logprob:  0.697609, 0.302083 (1.404 sec)
1.147... logprob:  0.546193, 0.240885 (1.458 sec)
1.148... logprob:  0.652686, 0.263021 (1.394 sec)
1.149... logprob:  0.676706, 0.282552 (1.394 sec)
1.150... logprob:  0.670252, 0.299479 (1.392 sec)
1.151... logprob:  0.567092, 0.261719 (1.385 sec)
1.152... logprob:  0.843894, 0.360677 (1.386 sec)
1.153... logprob:  0.667516, 0.289062 (1.432 sec)
1.154... logprob:  0.765479, 0.332031 (1.386 sec)
1.155... logprob:  0.572973, 0.251302 (1.391 sec)
1.156... logprob:  0.535449, 0.236979 (1.425 sec)
1.157... logprob:  0.496277, 0.225260 (1.383 sec)
1.158... logprob:  0.655542, 0.292969 (1.394 sec)
1.159... logprob:  0.698187, 0.296875 (1.392 sec)
1.160... logprob:  0.691985, 0.307292 (1.389 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.468210, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.919642e-03 [3.991810e-07] 
Layer 'conv1' biases: 9.818493e-08 [1.154540e-09] 
Layer 'conv2' weights[0]: 7.906609e-03 [3.979932e-07] 
Layer 'conv2' biases: 9.999999e-01 [6.241924e-09] 
Layer 'conv3' weights[0]: 7.904956e-03 [3.975600e-07] 
Layer 'conv3' biases: 2.782885e-06 [2.129860e-08] 
Layer 'conv4' weights[0]: 7.937172e-03 [4.004350e-07] 
Layer 'conv4' biases: 9.999963e-01 [1.851256e-07] 
Layer 'conv5' weights[0]: 7.936917e-03 [1.170540e-06] 
Layer 'conv5' biases: 9.998659e-01 [1.115713e-06] 
Layer 'fc6' weights[0]: 7.587338e-03 [4.536778e-08] 
Layer 'fc6' biases: 9.999999e-01 [2.530554e-08] 
Layer 'fc7' weights[0]: 7.941247e-03 [7.477948e-08] 
Layer 'fc7' biases: 9.999967e-01 [6.576148e-08] 
Layer 'fc8' weights[0]: 1.901404e-03 [1.893444e-05] 
Layer 'fc8' biases: 3.641857e-03 [1.771490e-05] 
Train error last 800 batches: 0.673656
-------------------------------------------------------
Not saving because 0.468210 > 0.444120 (1.100: -2.61%)
======================================================= (2.453 sec)
1.161... logprob:  0.662230, 0.295573 (1.400 sec)
1.162... logprob:  0.823150, 0.350260 (1.401 sec)
1.163... logprob:  0.663818, 0.307292 (1.414 sec)
1.164... logprob:  0.600298, 0.250000 (1.411 sec)
1.165... logprob:  0.717321, 0.350260 (1.413 sec)
1.166... logprob:  0.619365, 0.250000 (1.446 sec)
1.167... logprob:  0.675932, 0.295573 (1.423 sec)
1.168... logprob:  0.589073, 0.266927 (1.415 sec)
1.169... logprob:  0.627450, 0.252604 (1.449 sec)
1.170... logprob:  0.680411, 0.266927 (1.391 sec)
1.171... logprob:  0.815872, 0.373698 (1.408 sec)
1.172... logprob:  0.721001, 0.299479 (1.409 sec)
1.173... logprob:  0.689345, 0.268229 (1.409 sec)
1.174... logprob:  0.824625, 0.332031 (1.397 sec)
1.175... logprob:  0.694558, 0.286458 (1.460 sec)
1.176... logprob:  0.664766, 0.296875 (1.410 sec)
1.177... logprob:  0.555065, 0.243490 (1.411 sec)
1.178... logprob:  0.554357, 0.233073 (1.441 sec)
1.179... logprob:  0.586660, 0.261719 (1.399 sec)
1.180... logprob:  0.685700, 0.303385 (1.416 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.499638, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.911722e-03 [3.984852e-07] 
Layer 'conv1' biases: 1.026043e-07 [1.067501e-09] 
Layer 'conv2' weights[0]: 7.898672e-03 [3.975326e-07] 
Layer 'conv2' biases: 9.999999e-01 [6.643117e-09] 
Layer 'conv3' weights[0]: 7.897134e-03 [3.973106e-07] 
Layer 'conv3' biases: 2.892515e-06 [2.130319e-08] 
Layer 'conv4' weights[0]: 7.929279e-03 [4.005481e-07] 
Layer 'conv4' biases: 9.999962e-01 [2.054170e-07] 
Layer 'conv5' weights[0]: 7.929100e-03 [1.317661e-06] 
Layer 'conv5' biases: 9.998608e-01 [1.302804e-06] 
Layer 'fc6' weights[0]: 7.586551e-03 [4.696349e-08] 
Layer 'fc6' biases: 9.999999e-01 [2.826786e-08] 
Layer 'fc7' weights[0]: 7.940481e-03 [8.040104e-08] 
Layer 'fc7' biases: 9.999962e-01 [8.820963e-08] 
Layer 'fc8' weights[0]: 1.829182e-03 [2.695937e-05] 
Layer 'fc8' biases: 3.431130e-03 [4.965205e-05] 
Train error last 800 batches: 0.673533
-------------------------------------------------------
Not saving because 0.499638 > 0.444120 (1.100: -2.61%)
======================================================= (2.377 sec)
1.181... logprob:  0.776699, 0.332031 (1.413 sec)
1.182... logprob:  0.614508, 0.264323 (1.412 sec)
1.183... logprob:  0.704181, 0.308594 (1.405 sec)
1.184... logprob:  0.668283, 0.291667 (1.408 sec)
1.185... logprob:  0.540983, 0.235677 (1.387 sec)
1.186... logprob:  0.539728, 0.244792 (1.390 sec)
1.187... logprob:  0.762957, 0.328125 (1.406 sec)
1.188... logprob:  0.637841, 0.291667 (1.389 sec)
1.189... logprob:  0.701443, 0.322917 (1.378 sec)
1.190... logprob:  0.624455, 0.277344 (1.425 sec)
1.191... logprob:  0.738964, 0.315104 (1.399 sec)
1.192... logprob:  0.667309, 0.289062 (1.411 sec)
1.193... logprob:  0.576005, 0.263021 (1.413 sec)
1.194... logprob:  0.635051, 0.270833 (1.410 sec)
1.195... logprob:  0.521195, 0.242188 (1.393 sec)
1.196... logprob:  0.642284, 0.281250 (1.387 sec)
1.197... logprob:  0.759342, 0.326823 (1.389 sec)
1.198... logprob:  0.629676, 0.286458 (1.392 sec)
1.199... logprob:  0.729947, 0.321615 (1.383 sec)
1.200... logprob:  0.564450, 0.239583 (1.441 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.565741, 0.171875 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.903800e-03 [3.997877e-07] 
Layer 'conv1' biases: 1.091020e-07 [1.325056e-09] 
Layer 'conv2' weights[0]: 7.890822e-03 [3.974434e-07] 
Layer 'conv2' biases: 9.999999e-01 [7.536256e-09] 
Layer 'conv3' weights[0]: 7.889179e-03 [3.974277e-07] 
Layer 'conv3' biases: 2.831647e-06 [2.432860e-08] 
Layer 'conv4' weights[0]: 7.921319e-03 [4.009440e-07] 
Layer 'conv4' biases: 9.999962e-01 [2.216293e-07] 
Layer 'conv5' weights[0]: 7.921094e-03 [1.395059e-06] 
Layer 'conv5' biases: 9.998600e-01 [1.396763e-06] 
Layer 'fc6' weights[0]: 7.585802e-03 [4.620405e-08] 
Layer 'fc6' biases: 1.000000e+00 [2.685288e-08] 
Layer 'fc7' weights[0]: 7.939672e-03 [7.688740e-08] 
Layer 'fc7' biases: 9.999962e-01 [6.986122e-08] 
Layer 'fc8' weights[0]: 1.942137e-03 [1.831554e-05] 
Layer 'fc8' biases: 3.669019e-03 [1.974051e-05] 
Train error last 800 batches: 0.671356
-------------------------------------------------------
Not saving because 0.565741 > 0.444120 (1.100: -2.61%)
======================================================= (2.392 sec)
1.201... logprob:  0.655886, 0.285156 (1.408 sec)
1.202... logprob:  0.726440, 0.337240 (1.397 sec)
1.203... logprob:  0.628540, 0.276042 (1.435 sec)
1.204... logprob:  0.674421, 0.322917 (1.384 sec)
1.205... logprob:  0.585840, 0.264323 (1.393 sec)
1.206... logprob:  0.605840, 0.274740 (1.391 sec)
1.207... logprob:  0.604215, 0.273437 (1.379 sec)
1.208... logprob:  0.663607, 0.307292 (1.382 sec)
1.209... logprob:  0.525176, 0.246094 (1.409 sec)
1.210... logprob:  0.774286, 0.321615 (1.408 sec)
1.211... logprob:  0.755197, 0.328125 (1.405 sec)
1.212... logprob:  0.804320, 0.355469 (1.402 sec)
1.213... logprob:  0.709597, 0.324219 (1.452 sec)
1.214... logprob:  0.698972, 0.290365 (1.420 sec)
1.215... logprob:  0.682187, 0.279948 (1.419 sec)
1.216... logprob:  0.695644, 0.308594 (1.459 sec)
1.217... logprob:  0.583595, 0.263021 (1.388 sec)
1.218... logprob:  0.687255, 0.274740 (1.411 sec)
1.219... logprob:  0.749009, 0.324219 (1.408 sec)
1.220... logprob:  0.639035, 0.304687 (1.414 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.490700, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.895893e-03 [4.017399e-07] 
Layer 'conv1' biases: 1.213385e-07 [1.388750e-09] 
Layer 'conv2' weights[0]: 7.882898e-03 [3.982237e-07] 
Layer 'conv2' biases: 9.999999e-01 [7.429756e-09] 
Layer 'conv3' weights[0]: 7.881277e-03 [3.973267e-07] 
Layer 'conv3' biases: 2.990824e-06 [2.470522e-08] 
Layer 'conv4' weights[0]: 7.913394e-03 [4.008700e-07] 
Layer 'conv4' biases: 9.999963e-01 [2.175961e-07] 
Layer 'conv5' weights[0]: 7.913367e-03 [1.464878e-06] 
Layer 'conv5' biases: 9.998517e-01 [1.480797e-06] 
Layer 'fc6' weights[0]: 7.585023e-03 [4.932420e-08] 
Layer 'fc6' biases: 1.000000e+00 [3.188347e-08] 
Layer 'fc7' weights[0]: 7.938934e-03 [8.894068e-08] 
Layer 'fc7' biases: 9.999959e-01 [1.092351e-07] 
Layer 'fc8' weights[0]: 1.849586e-03 [2.295034e-05] 
Layer 'fc8' biases: 3.385413e-03 [3.448161e-05] 
Train error last 800 batches: 0.671456
-------------------------------------------------------
Not saving because 0.490700 > 0.444120 (1.100: -2.61%)
======================================================= (2.375 sec)
1.221... logprob:  0.649035, 0.296875 (1.404 sec)
1.222... logprob:  0.675024, 0.319010 (1.454 sec)
1.223... logprob:  0.704512, 0.321615 (1.427 sec)
1.224... logprob:  0.620185, 0.285156 (1.426 sec)
1.225... logprob:  0.614682, 0.276042 (1.439 sec)
1.226... logprob:  0.618801, 0.286458 (1.414 sec)
1.227... logprob:  0.747628, 0.338542 (1.405 sec)
1.228... logprob:  0.626666, 0.270833 (1.407 sec)
1.229... logprob:  0.663074, 0.317708 (1.412 sec)
1.230... logprob:  0.672320, 0.277344 (1.414 sec)
1.231... logprob:  0.652347, 0.255208 (1.400 sec)
1.232... logprob:  0.748272, 0.338542 (1.456 sec)
1.233... logprob:  0.728532, 0.315104 (1.416 sec)
1.234... logprob:  0.820459, 0.333333 (1.406 sec)
1.235... logprob:  0.680768, 0.272135 (1.459 sec)
1.236... logprob:  0.652699, 0.257812 (1.387 sec)
1.237... logprob:  0.602481, 0.253906 (1.417 sec)
1.238... logprob:  0.698927, 0.277344 (1.411 sec)
1.239... logprob:  0.712378, 0.321615 (1.421 sec)
1.240... logprob:  0.659045, 0.296875 (1.396 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.499964, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.887994e-03 [3.988494e-07] 
Layer 'conv1' biases: 1.258476e-07 [1.042623e-09] 
Layer 'conv2' weights[0]: 7.875012e-03 [3.968435e-07] 
Layer 'conv2' biases: 9.999999e-01 [6.957025e-09] 
Layer 'conv3' weights[0]: 7.873452e-03 [3.966106e-07] 
Layer 'conv3' biases: 3.032480e-06 [2.368170e-08] 
Layer 'conv4' weights[0]: 7.905484e-03 [4.000618e-07] 
Layer 'conv4' biases: 9.999968e-01 [2.197849e-07] 
Layer 'conv5' weights[0]: 7.905664e-03 [1.266323e-06] 
Layer 'conv5' biases: 9.998510e-01 [1.263902e-06] 
Layer 'fc6' weights[0]: 7.584222e-03 [4.705464e-08] 
Layer 'fc6' biases: 1.000000e+00 [2.847146e-08] 
Layer 'fc7' weights[0]: 7.938124e-03 [7.988630e-08] 
Layer 'fc7' biases: 9.999958e-01 [7.368590e-08] 
Layer 'fc8' weights[0]: 1.871665e-03 [1.866474e-05] 
Layer 'fc8' biases: 3.380030e-03 [1.314978e-05] 
Train error last 800 batches: 0.671950
-------------------------------------------------------
Not saving because 0.499964 > 0.444120 (1.100: -2.61%)
======================================================= (2.396 sec)
1.241... logprob:  0.777180, 0.329427 (1.459 sec)
1.242... logprob:  0.594411, 0.279948 (1.430 sec)
1.243... logprob:  0.570691, 0.261719 (1.423 sec)
1.244... logprob:  0.556117, 0.252604 (1.441 sec)
1.245... logprob:  0.760677, 0.329427 (1.414 sec)
1.246... logprob:  0.625478, 0.276042 (1.411 sec)
1.247... logprob:  0.554887, 0.235677 (1.410 sec)
1.248... logprob:  0.561732, 0.251302 (1.404 sec)
1.249... logprob:  0.711712, 0.334635 (1.427 sec)
1.250... logprob:  0.847730, 0.352865 (1.398 sec)
1.251... logprob:  0.569813, 0.248698 (1.456 sec)
1.252... logprob:  0.570446, 0.247396 (1.417 sec)
1.253... logprob:  0.588499, 0.260417 (1.414 sec)
1.254... logprob:  0.622865, 0.257812 (1.458 sec)
1.255... logprob:  0.583165, 0.244792 (1.397 sec)
1.256... logprob:  0.633205, 0.268229 (1.417 sec)
1.257... logprob:  0.551502, 0.269531 (1.410 sec)
1.258... logprob:  0.587279, 0.268229 (1.414 sec)
1.259... logprob:  0.687351, 0.281250 (1.393 sec)
1.260... logprob:  0.565197, 0.278646 (1.451 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.473570, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.880127e-03 [4.000101e-07] 
Layer 'conv1' biases: 1.266694e-07 [1.005054e-09] 
Layer 'conv2' weights[0]: 7.867153e-03 [3.965646e-07] 
Layer 'conv2' biases: 9.999999e-01 [6.720476e-09] 
Layer 'conv3' weights[0]: 7.865572e-03 [3.963947e-07] 
Layer 'conv3' biases: 2.949592e-06 [2.424109e-08] 
Layer 'conv4' weights[0]: 7.897577e-03 [4.004912e-07] 
Layer 'conv4' biases: 9.999961e-01 [2.257622e-07] 
Layer 'conv5' weights[0]: 7.897341e-03 [1.402168e-06] 
Layer 'conv5' biases: 9.998548e-01 [1.348810e-06] 
Layer 'fc6' weights[0]: 7.583417e-03 [4.910508e-08] 
Layer 'fc6' biases: 1.000000e+00 [3.156732e-08] 
Layer 'fc7' weights[0]: 7.937348e-03 [8.681639e-08] 
Layer 'fc7' biases: 9.999964e-01 [1.064807e-07] 
Layer 'fc8' weights[0]: 2.114122e-03 [2.191821e-05] 
Layer 'fc8' biases: 4.062660e-03 [3.657180e-05] 
Train error last 800 batches: 0.668416
-------------------------------------------------------
Not saving because 0.473570 > 0.444120 (1.100: -2.61%)
======================================================= (2.368 sec)
1.261... logprob:  0.591360, 0.290365 (1.430 sec)
1.262... logprob:  0.702873, 0.281250 (1.432 sec)
1.263... logprob:  0.553116, 0.235677 (1.440 sec)
1.264... logprob:  0.613512, 0.276042 (1.413 sec)
1.265... logprob:  0.612117, 0.274740 (1.402 sec)
1.266... logprob:  0.681023, 0.311198 (1.402 sec)
1.267... logprob:  0.644034, 0.265625 (1.405 sec)
1.268... logprob:  0.660516, 0.287760 (1.418 sec)
1.269... logprob:  0.702683, 0.305989 (1.399 sec)
1.270... logprob:  0.737731, 0.313802 (1.455 sec)
1.271... logprob:  0.621922, 0.268229 (1.415 sec)
1.272... logprob:  0.563211, 0.248698 (1.405 sec)
1.273... logprob:  0.757104, 0.304687 (1.461 sec)
1.274... logprob:  0.743172, 0.312500 (1.397 sec)
1.275... logprob:  0.666121, 0.300781 (1.416 sec)
1.276... logprob:  0.563613, 0.242187 (1.413 sec)
1.277... logprob:  0.690876, 0.321615 (1.431 sec)
1.278... logprob:  0.567874, 0.246094 (1.416 sec)
1.279... logprob:  0.576648, 0.266927 (1.456 sec)
1.280... logprob:  0.501974, 0.238281 (1.396 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.510459, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.872234e-03 [3.981472e-07] 
Layer 'conv1' biases: 1.283164e-07 [1.213688e-09] 
Layer 'conv2' weights[0]: 7.859225e-03 [3.959372e-07] 
Layer 'conv2' biases: 9.999999e-01 [7.143879e-09] 
Layer 'conv3' weights[0]: 7.857758e-03 [3.959054e-07] 
Layer 'conv3' biases: 3.152114e-06 [2.386495e-08] 
Layer 'conv4' weights[0]: 7.889726e-03 [3.993322e-07] 
Layer 'conv4' biases: 9.999971e-01 [2.062074e-07] 
Layer 'conv5' weights[0]: 7.889930e-03 [1.389605e-06] 
Layer 'conv5' biases: 9.998398e-01 [1.399677e-06] 
Layer 'fc6' weights[0]: 7.582635e-03 [4.651962e-08] 
Layer 'fc6' biases: 9.999999e-01 [2.764058e-08] 
Layer 'fc7' weights[0]: 7.936573e-03 [7.825128e-08] 
Layer 'fc7' biases: 9.999958e-01 [8.152146e-08] 
Layer 'fc8' weights[0]: 1.969949e-03 [1.962330e-05] 
Layer 'fc8' biases: 3.584178e-03 [2.328139e-05] 
Train error last 800 batches: 0.666213
-------------------------------------------------------
Not saving because 0.510459 > 0.444120 (1.100: -2.61%)
======================================================= (2.420 sec)
1.281... logprob:  0.674392, 0.304687 (1.423 sec)
1.282... logprob:  0.616585, 0.273437 (1.412 sec)
1.283... logprob:  0.641982, 0.302083 (1.438 sec)
1.284... logprob:  0.628598, 0.278646 (1.408 sec)
1.285... logprob:  0.633681, 0.265625 (1.438 sec)
1.286... logprob:  0.597716, 0.259115 (1.429 sec)
1.287... logprob:  0.502700, 0.208333 (1.425 sec)
1.288... logprob:  0.551039, 0.239583 (1.430 sec)
1.289... logprob:  0.690213, 0.316406 (1.435 sec)
1.290... logprob:  0.799428, 0.326823 (1.401 sec)
1.291... logprob:  0.592959, 0.263021 (1.413 sec)
1.292... logprob:  0.783372, 0.329427 (1.409 sec)
1.293... logprob:  0.686563, 0.265625 (1.417 sec)
1.294... logprob:  0.576222, 0.252604 (1.395 sec)
1.295... logprob:  0.590837, 0.309896 (1.454 sec)
1.296... logprob:  0.566797, 0.252604 (1.411 sec)
1.297... logprob:  0.596124, 0.255208 (1.414 sec)
1.298... logprob:  0.753677, 0.326823 (1.461 sec)
1.299... logprob:  0.565251, 0.261719 (1.392 sec)
1.300... logprob:  0.687845, 0.281250 (1.419 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.497800, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.864377e-03 [3.990372e-07] 
Layer 'conv1' biases: 1.312386e-07 [1.405209e-09] 
Layer 'conv2' weights[0]: 7.851385e-03 [3.958846e-07] 
Layer 'conv2' biases: 9.999999e-01 [7.026102e-09] 
Layer 'conv3' weights[0]: 7.849841e-03 [3.954929e-07] 
Layer 'conv3' biases: 3.173586e-06 [2.381427e-08] 
Layer 'conv4' weights[0]: 7.881745e-03 [3.995038e-07] 
Layer 'conv4' biases: 9.999961e-01 [2.245878e-07] 
Layer 'conv5' weights[0]: 7.881947e-03 [1.407924e-06] 
Layer 'conv5' biases: 9.998379e-01 [1.443050e-06] 
Layer 'fc6' weights[0]: 7.581814e-03 [4.756450e-08] 
Layer 'fc6' biases: 1.000000e+00 [2.938528e-08] 
Layer 'fc7' weights[0]: 7.935800e-03 [8.286718e-08] 
Layer 'fc7' biases: 9.999956e-01 [8.307724e-08] 
Layer 'fc8' weights[0]: 2.033821e-03 [2.284317e-05] 
Layer 'fc8' biases: 3.755591e-03 [3.873341e-05] 
Train error last 800 batches: 0.664252
-------------------------------------------------------
Not saving because 0.497800 > 0.444120 (1.100: -2.61%)
======================================================= (2.394 sec)
1.301... logprob:  0.602769, 0.251302 (1.419 sec)
1.302... logprob:  0.756521, 0.324219 (1.413 sec)
1.303... logprob:  0.732237, 0.324219 (1.407 sec)
1.304... logprob:  0.660790, 0.274739 (1.433 sec)
1.305... logprob:  0.718597, 0.324219 (1.431 sec)
1.306... logprob:  0.630776, 0.274740 (1.426 sec)
1.307... logprob:  0.726086, 0.330729 (1.437 sec)
1.308... logprob:  0.579998, 0.250000 (1.447 sec)
1.309... logprob:  0.684895, 0.294271 (1.410 sec)
1.310... logprob:  0.669336, 0.296875 (1.424 sec)
1.311... logprob:  0.691742, 0.278646 (1.419 sec)
1.312... logprob:  0.680134, 0.302083 (1.427 sec)
1.313... logprob:  0.672776, 0.283854 (1.414 sec)
1.314... logprob:  0.629937, 0.274740 (1.453 sec)
1.315... logprob:  0.535753, 0.231771 (1.424 sec)
1.316... logprob:  0.718369, 0.320312 (1.426 sec)
1.317... logprob:  0.553224, 0.247396 (1.480 sec)
1.318... logprob:  0.629368, 0.269531 (1.415 sec)
1.319... logprob:  0.628323, 0.303385 (1.427 sec)
1.320... logprob:  0.577369, 0.277344 (1.417 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.408079, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.856493e-03 [3.976519e-07] 
Layer 'conv1' biases: 1.388646e-07 [1.402977e-09] 
Layer 'conv2' weights[0]: 7.843511e-03 [3.959983e-07] 
Layer 'conv2' biases: 9.999999e-01 [8.850499e-09] 
Layer 'conv3' weights[0]: 7.842008e-03 [3.974141e-07] 
Layer 'conv3' biases: 3.257734e-06 [3.109579e-08] 
Layer 'conv4' weights[0]: 7.873854e-03 [4.034344e-07] 
Layer 'conv4' biases: 9.999963e-01 [3.081834e-07] 
Layer 'conv5' weights[0]: 7.874105e-03 [1.899736e-06] 
Layer 'conv5' biases: 9.998317e-01 [1.929249e-06] 
Layer 'fc6' weights[0]: 7.581020e-03 [5.144076e-08] 
Layer 'fc6' biases: 9.999999e-01 [3.592588e-08] 
Layer 'fc7' weights[0]: 7.935061e-03 [9.705307e-08] 
Layer 'fc7' biases: 9.999955e-01 [1.384902e-07] 
Layer 'fc8' weights[0]: 2.070199e-03 [2.771011e-05] 
Layer 'fc8' biases: 3.805606e-03 [5.298337e-05] 
Train error last 800 batches: 0.663608
-------------------------------------------------------
Saved checkpoint to /data2/ad6813/my-nets/saves/ConvNet__2014-06-04_16.10.14
======================================================= (2.764 sec)
1.321... logprob:  0.549788, 0.223958 (1.422 sec)
1.322... logprob:  0.616129, 0.277344 (1.409 sec)
1.323... logprob:  0.637960, 0.273437 (1.466 sec)
1.324... logprob:  0.711043, 0.317708 (1.825 sec)
1.325... logprob:  0.655089, 0.261719 (1.433 sec)
1.326... logprob:  0.707029, 0.295573 (1.461 sec)
1.327... logprob:  0.761114, 0.325521 (3.042 sec)
1.328... logprob:  0.661136, 0.304688 (1.426 sec)
1.329... logprob:  0.558141, 0.231771 (1.416 sec)
1.330... logprob:  0.662234, 0.278646 (1.418 sec)
1.331... logprob:  0.556211, 0.253906 (1.413 sec)
1.332... logprob:  0.770913, 0.309896 (1.441 sec)
1.333... logprob:  0.595474, 0.264323 (1.438 sec)
1.334... logprob:  0.702763, 0.287760 (1.434 sec)
1.335... logprob:  0.612953, 0.272135 (1.432 sec)
1.336... logprob:  0.607182, 0.274740 (1.449 sec)
1.337... logprob:  0.779834, 0.309896 (1.414 sec)
1.338... logprob:  0.692219, 0.311198 (1.413 sec)
1.339... logprob:  0.712213, 0.322917 (1.424 sec)
1.340... logprob:  0.629061, 0.266927 (1.414 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.457201, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.848635e-03 [3.958671e-07] 
Layer 'conv1' biases: 1.482185e-07 [1.061397e-09] 
Layer 'conv2' weights[0]: 7.835730e-03 [3.954390e-07] 
Layer 'conv2' biases: 9.999999e-01 [7.836030e-09] 
Layer 'conv3' weights[0]: 7.834134e-03 [3.950173e-07] 
Layer 'conv3' biases: 3.335945e-06 [2.624998e-08] 
Layer 'conv4' weights[0]: 7.865963e-03 [3.994017e-07] 
Layer 'conv4' biases: 9.999971e-01 [2.706593e-07] 
Layer 'conv5' weights[0]: 7.866416e-03 [1.726835e-06] 
Layer 'conv5' biases: 9.998223e-01 [1.794594e-06] 
Layer 'fc6' weights[0]: 7.580191e-03 [5.004635e-08] 
Layer 'fc6' biases: 9.999999e-01 [3.367608e-08] 
Layer 'fc7' weights[0]: 7.934313e-03 [9.142889e-08] 
Layer 'fc7' biases: 9.999951e-01 [1.096905e-07] 
Layer 'fc8' weights[0]: 2.034077e-03 [2.153294e-05] 
Layer 'fc8' biases: 3.614811e-03 [2.985915e-05] 
Train error last 800 batches: 0.663332
-------------------------------------------------------
Not saving because 0.457201 > 0.408079 (1.320: -8.12%)
======================================================= (2.461 sec)
1.341... logprob:  0.738852, 0.305990 (1.426 sec)
1.342... logprob:  0.633810, 0.248698 (1.465 sec)
1.343... logprob:  0.738784, 0.303385 (1.438 sec)
1.344... logprob:  0.611542, 0.272135 (1.472 sec)
1.345... logprob:  0.701843, 0.296875 (1.434 sec)
1.346... logprob:  0.646527, 0.265625 (1.429 sec)
1.347... logprob:  0.632287, 0.283854 (1.479 sec)
1.348... logprob:  0.581219, 0.261719 (1.427 sec)
1.349... logprob:  0.666852, 0.303385 (1.428 sec)
1.350... logprob:  0.648251, 0.303385 (1.426 sec)
1.351... logprob:  0.724940, 0.311198 (1.425 sec)
1.352... logprob:  0.648746, 0.289062 (1.468 sec)
1.353... logprob:  0.744450, 0.304687 (1.482 sec)
1.354... logprob:  0.791836, 0.342448 (1.428 sec)
1.355... logprob:  0.619838, 0.279948 (1.437 sec)
1.356... logprob:  0.626531, 0.298177 (1.472 sec)
1.357... logprob:  0.576765, 0.250000 (1.428 sec)
1.358... logprob:  0.640607, 0.274740 (1.429 sec)
1.359... logprob:  0.721473, 0.317708 (1.429 sec)
1.360... logprob:  0.585157, 0.281250 (1.444 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.457486, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.840791e-03 [3.967148e-07] 
Layer 'conv1' biases: 1.548485e-07 [1.161980e-09] 
Layer 'conv2' weights[0]: 7.827835e-03 [3.947038e-07] 
Layer 'conv2' biases: 9.999999e-01 [7.031166e-09] 
Layer 'conv3' weights[0]: 7.826314e-03 [3.945195e-07] 
Layer 'conv3' biases: 3.436550e-06 [2.416361e-08] 
Layer 'conv4' weights[0]: 7.858146e-03 [3.989111e-07] 
Layer 'conv4' biases: 9.999971e-01 [2.386306e-07] 
Layer 'conv5' weights[0]: 7.858784e-03 [1.366109e-06] 
Layer 'conv5' biases: 9.998180e-01 [1.339269e-06] 
Layer 'fc6' weights[0]: 7.579362e-03 [4.885477e-08] 
Layer 'fc6' biases: 9.999999e-01 [3.192994e-08] 
Layer 'fc7' weights[0]: 7.933541e-03 [8.706368e-08] 
Layer 'fc7' biases: 9.999951e-01 [1.022083e-07] 
Layer 'fc8' weights[0]: 2.058333e-03 [2.214163e-05] 
Layer 'fc8' biases: 3.687858e-03 [2.932430e-05] 
Train error last 800 batches: 0.663370
-------------------------------------------------------
Not saving because 0.457486 > 0.408079 (1.320: -8.12%)
======================================================= (2.394 sec)
1.361... logprob:  0.605399, 0.268229 (1.439 sec)
1.362... logprob:  0.711887, 0.317708 (1.473 sec)
1.363... logprob:  0.660333, 0.278646 (1.438 sec)
1.364... logprob:  0.783901, 0.316406 (1.443 sec)
1.365... logprob:  0.695858, 0.328125 (1.461 sec)
1.366... logprob:  0.632140, 0.272135 (1.441 sec)
1.367... logprob:  0.601967, 0.285156 (1.430 sec)
1.368... logprob:  0.749874, 0.354167 (1.423 sec)
1.369... logprob:  0.637451, 0.253906 (1.421 sec)
1.370... logprob:  0.510184, 0.212240 (1.427 sec)
1.371... logprob:  0.665493, 0.285156 (1.457 sec)
1.372... logprob:  0.790589, 0.341146 (1.446 sec)
1.373... logprob:  0.685428, 0.260417 (1.448 sec)
1.374... logprob:  0.675147, 0.309896 (1.442 sec)
1.375... logprob:  0.623474, 0.274740 (1.454 sec)
1.376... logprob:  0.604828, 0.273437 (1.431 sec)
1.377... logprob:  0.544288, 0.231771 (1.420 sec)
1.378... logprob:  0.623026, 0.256510 (1.423 sec)
1.379... logprob:  0.603109, 0.261719 (1.455 sec)
1.380... logprob:  0.688929, 0.296875 (1.442 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.566998, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.832954e-03 [3.995171e-07] 
Layer 'conv1' biases: 1.594454e-07 [1.299438e-09] 
Layer 'conv2' weights[0]: 7.820027e-03 [3.949912e-07] 
Layer 'conv2' biases: 9.999999e-01 [7.224386e-09] 
Layer 'conv3' weights[0]: 7.818473e-03 [3.940982e-07] 
Layer 'conv3' biases: 3.573306e-06 [2.458770e-08] 
Layer 'conv4' weights[0]: 7.850284e-03 [3.982371e-07] 
Layer 'conv4' biases: 9.999974e-01 [2.369286e-07] 
Layer 'conv5' weights[0]: 7.850895e-03 [1.470494e-06] 
Layer 'conv5' biases: 9.998152e-01 [1.494087e-06] 
Layer 'fc6' weights[0]: 7.578585e-03 [4.786306e-08] 
Layer 'fc6' biases: 9.999999e-01 [3.039973e-08] 
Layer 'fc7' weights[0]: 7.932737e-03 [8.303664e-08] 
Layer 'fc7' biases: 9.999949e-01 [8.189531e-08] 
Layer 'fc8' weights[0]: 2.071647e-03 [2.213264e-05] 
Layer 'fc8' biases: 3.663843e-03 [2.978118e-05] 
Train error last 800 batches: 0.662912
-------------------------------------------------------
Not saving because 0.566998 > 0.408079 (1.320: -8.12%)
======================================================= (2.388 sec)
1.381... logprob:  0.651798, 0.247396 (1.468 sec)
1.382... logprob:  0.715657, 0.303385 (1.446 sec)
1.383... logprob:  0.592941, 0.299479 (1.427 sec)
1.384... logprob:  0.725985, 0.332031 (1.492 sec)
1.385... logprob:  0.653664, 0.315104 (1.422 sec)
1.386... logprob:  0.783849, 0.329427 (1.418 sec)
1.387... logprob:  0.664669, 0.285156 (1.424 sec)
1.388... logprob:  0.745046, 0.315104 (1.439 sec)
1.389... logprob:  0.718452, 0.269531 (1.425 sec)
1.390... logprob:  0.575304, 0.243490 (1.488 sec)
1.391... logprob:  0.519381, 0.246094 (1.432 sec)
1.392... logprob:  0.592735, 0.261719 (1.425 sec)
1.393... logprob:  0.586788, 0.272135 (1.481 sec)
1.394... logprob:  0.584795, 0.261719 (1.430 sec)
1.395... logprob:  0.543195, 0.240885 (1.421 sec)
1.396... logprob:  0.544569, 0.239583 (1.432 sec)
1.397... logprob:  0.658376, 0.302083 (1.426 sec)
1.398... logprob:  0.786381, 0.311198 (1.449 sec)
1.399... logprob:  0.652080, 0.291667 (1.489 sec)
1.400... logprob:  0.711239, 0.308594 (1.425 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.507411, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.825090e-03 [3.972735e-07] 
Layer 'conv1' biases: 1.600269e-07 [1.136305e-09] 
Layer 'conv2' weights[0]: 7.812209e-03 [3.944661e-07] 
Layer 'conv2' biases: 9.999999e-01 [8.123179e-09] 
Layer 'conv3' weights[0]: 7.810635e-03 [3.939697e-07] 
Layer 'conv3' biases: 3.636460e-06 [2.418781e-08] 
Layer 'conv4' weights[0]: 7.842401e-03 [3.982911e-07] 
Layer 'conv4' biases: 9.999973e-01 [2.299520e-07] 
Layer 'conv5' weights[0]: 7.842908e-03 [1.348633e-06] 
Layer 'conv5' biases: 9.998164e-01 [1.336916e-06] 
Layer 'fc6' weights[0]: 7.577775e-03 [4.801431e-08] 
Layer 'fc6' biases: 9.999999e-01 [3.058359e-08] 
Layer 'fc7' weights[0]: 7.931945e-03 [8.371586e-08] 
Layer 'fc7' biases: 9.999951e-01 [8.127441e-08] 
Layer 'fc8' weights[0]: 2.189516e-03 [1.960736e-05] 
Layer 'fc8' biases: 3.964737e-03 [2.347825e-05] 
Train error last 800 batches: 0.662284
-------------------------------------------------------
Not saving because 0.507411 > 0.408079 (1.320: -8.12%)
======================================================= (2.384 sec)
1.401... logprob:  0.673581, 0.305990 (1.438 sec)
1.402... logprob:  0.607202, 0.261719 (1.478 sec)
1.403... logprob:  0.699122, 0.294271 (1.421 sec)
1.404... logprob:  0.719953, 0.321615 (1.452 sec)
1.405... logprob:  0.722868, 0.311198 (1.420 sec)
1.406... logprob:  0.591958, 0.287760 (1.416 sec)
1.407... logprob:  0.708550, 0.315104 (1.429 sec)
1.408... logprob:  0.532882, 0.235677 (1.471 sec)
1.409... logprob:  0.642238, 0.282552 (1.427 sec)
1.410... logprob:  0.823970, 0.342448 (1.446 sec)
1.411... logprob:  0.603500, 0.242188 (1.463 sec)
1.412... logprob:  0.702910, 0.286458 (1.432 sec)
1.413... logprob:  0.727715, 0.303385 (1.430 sec)
1.414... logprob:  0.754098, 0.341146 (1.427 sec)
1.415... logprob:  0.623567, 0.283854 (1.418 sec)
1.416... logprob:  0.655472, 0.289062 (1.434 sec)
1.417... logprob:  0.689369, 0.304687 (1.488 sec)
1.418... logprob:  0.693734, 0.325521 (1.453 sec)
1.419... logprob:  0.675423, 0.285156 (1.437 sec)
1.420... logprob:  0.573595, 0.242187 (1.446 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.473081, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.817273e-03 [3.966383e-07] 
Layer 'conv1' biases: 1.674290e-07 [1.401168e-09] 
Layer 'conv2' weights[0]: 7.804361e-03 [3.930885e-07] 
Layer 'conv2' biases: 9.999999e-01 [6.856995e-09] 
Layer 'conv3' weights[0]: 7.802830e-03 [3.929270e-07] 
Layer 'conv3' biases: 3.821975e-06 [2.288781e-08] 
Layer 'conv4' weights[0]: 7.834572e-03 [3.973814e-07] 
Layer 'conv4' biases: 9.999978e-01 [2.334675e-07] 
Layer 'conv5' weights[0]: 7.835214e-03 [1.533689e-06] 
Layer 'conv5' biases: 9.998111e-01 [1.642750e-06] 
Layer 'fc6' weights[0]: 7.577013e-03 [4.972931e-08] 
Layer 'fc6' biases: 9.999999e-01 [3.353976e-08] 
Layer 'fc7' weights[0]: 7.931146e-03 [8.942871e-08] 
Layer 'fc7' biases: 9.999945e-01 [1.023618e-07] 
Layer 'fc8' weights[0]: 2.094619e-03 [2.440814e-05] 
Layer 'fc8' biases: 3.593437e-03 [3.975677e-05] 
Train error last 800 batches: 0.662703
-------------------------------------------------------
Not saving because 0.473081 > 0.408079 (1.320: -8.12%)
======================================================= (2.388 sec)
1.421... logprob:  0.644096, 0.286458 (1.454 sec)
1.422... logprob:  0.723598, 0.335937 (1.431 sec)
1.423... logprob:  0.676117, 0.303385 (1.418 sec)
1.424... logprob:  0.555129, 0.251302 (1.425 sec)
1.425... logprob:  0.546050, 0.252604 (1.433 sec)
1.426... logprob:  0.724340, 0.326823 (1.438 sec)
1.427... logprob:  0.702037, 0.312500 (1.457 sec)
1.428... logprob:  0.653323, 0.287760 (1.470 sec)
1.429... logprob:  0.609042, 0.274740 (1.440 sec)
1.430... logprob:  0.561917, 0.261719 (1.465 sec)
1.431... logprob:  0.840551, 0.348958 (1.432 sec)
1.432... logprob:  0.657704, 0.295573 (1.426 sec)
1.433... logprob:  0.568538, 0.259114 (1.429 sec)
1.434... logprob:  0.703016, 0.289062 (1.430 sec)
1.435... logprob:  0.856239, 0.337240 (1.429 sec)
1.436... logprob:  0.636057, 0.269531 (1.468 sec)
1.437... logprob:  0.803097, 0.363281 (1.451 sec)
1.438... logprob:  0.670115, 0.281250 (1.427 sec)
1.439... logprob:  0.529401, 0.238281 (1.478 sec)
1.440... logprob:  0.611048, 0.286458 (1.430 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.442328, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.809449e-03 [3.963029e-07] 
Layer 'conv1' biases: 1.740455e-07 [1.332727e-09] 
Layer 'conv2' weights[0]: 7.796552e-03 [3.942158e-07] 
Layer 'conv2' biases: 9.999999e-01 [8.480214e-09] 
Layer 'conv3' weights[0]: 7.795062e-03 [3.940048e-07] 
Layer 'conv3' biases: 3.974161e-06 [2.814653e-08] 
Layer 'conv4' weights[0]: 7.826727e-03 [3.979060e-07] 
Layer 'conv4' biases: 9.999967e-01 [2.624152e-07] 
Layer 'conv5' weights[0]: 7.827100e-03 [1.744380e-06] 
Layer 'conv5' biases: 9.998111e-01 [1.859786e-06] 
Layer 'fc6' weights[0]: 7.576202e-03 [4.872737e-08] 
Layer 'fc6' biases: 9.999999e-01 [3.164359e-08] 
Layer 'fc7' weights[0]: 7.930355e-03 [8.709242e-08] 
Layer 'fc7' biases: 9.999946e-01 [9.410676e-08] 
Layer 'fc8' weights[0]: 2.155269e-03 [2.110901e-05] 
Layer 'fc8' biases: 3.768210e-03 [2.932156e-05] 
Train error last 800 batches: 0.662742
-------------------------------------------------------
Not saving because 0.442328 > 0.408079 (1.320: -8.12%)
======================================================= (2.382 sec)
1.441... logprob:  0.627394, 0.265625 (1.426 sec)
1.442... logprob:  0.657974, 0.290365 (1.425 sec)
1.443... logprob:  0.759358, 0.361979 (1.424 sec)
1.444... logprob:  0.642504, 0.266927 (1.420 sec)
1.445... logprob:  0.522655, 0.233073 (1.470 sec)
1.446... logprob:  0.618477, 0.253906 (1.419 sec)
1.447... logprob:  0.878334, 0.376302 (1.433 sec)
1.448... logprob:  0.607237, 0.278646 (1.472 sec)
1.449... logprob:  0.693976, 0.300781 (1.428 sec)
1.450... logprob:  0.571596, 0.260417 (1.428 sec)
1.451... logprob:  0.688882, 0.298177 (1.427 sec)
1.452... logprob:  0.636015, 0.244792 (1.417 sec)
1.453... logprob:  0.673452, 0.277344 (1.425 sec)
1.454... logprob:  0.775677, 0.332031 (1.475 sec)
1.455... logprob:  0.674658, 0.304688 (1.424 sec)
1.456... logprob:  0.652499, 0.296875 (1.447 sec)
1.457... logprob:  0.662557, 0.300781 (1.464 sec)
1.458... logprob:  0.519523, 0.223958 (1.428 sec)
1.459... logprob:  0.613301, 0.255208 (1.425 sec)
1.460... logprob:  0.597814, 0.278646 (1.426 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.475852, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.801652e-03 [3.960314e-07] 
Layer 'conv1' biases: 1.797776e-07 [1.679149e-09] 
Layer 'conv2' weights[0]: 7.788731e-03 [3.944331e-07] 
Layer 'conv2' biases: 9.999999e-01 [8.733073e-09] 
Layer 'conv3' weights[0]: 7.787244e-03 [3.946126e-07] 
Layer 'conv3' biases: 4.117577e-06 [3.009817e-08] 
Layer 'conv4' weights[0]: 7.818875e-03 [3.998405e-07] 
Layer 'conv4' biases: 9.999965e-01 [2.834200e-07] 
Layer 'conv5' weights[0]: 7.819555e-03 [1.842357e-06] 
Layer 'conv5' biases: 9.998063e-01 [1.944353e-06] 
Layer 'fc6' weights[0]: 7.575396e-03 [5.263728e-08] 
Layer 'fc6' biases: 9.999999e-01 [3.785048e-08] 
Layer 'fc7' weights[0]: 7.929538e-03 [9.807488e-08] 
Layer 'fc7' biases: 9.999941e-01 [1.324957e-07] 
Layer 'fc8' weights[0]: 2.152046e-03 [2.778377e-05] 
Layer 'fc8' biases: 3.670949e-03 [4.971578e-05] 
Train error last 800 batches: 0.662349
-------------------------------------------------------
Not saving because 0.475852 > 0.408079 (1.320: -8.12%)
======================================================= (2.413 sec)
1.461... logprob:  0.718294, 0.315104 (1.426 sec)
1.462... logprob:  0.654250, 0.302083 (1.431 sec)
1.463... logprob:  0.629441, 0.265625 (1.462 sec)
1.464... logprob:  0.603567, 0.263021 (1.444 sec)
1.465... logprob:  0.667957, 0.287760 (1.444 sec)
1.466... logprob:  0.569225, 0.250000 (1.455 sec)
1.467... logprob:  0.564416, 0.247396 (1.452 sec)
1.468... logprob:  0.598597, 0.269531 (1.431 sec)
1.469... logprob:  0.609406, 0.308594 (1.421 sec)
1.470... logprob:  0.677163, 0.298177 (1.422 sec)
1.471... logprob:  0.747827, 0.317708 (1.431 sec)
1.472... logprob:  0.689785, 0.321614 (1.449 sec)
1.473... logprob:  0.746763, 0.328125 (1.453 sec)
1.474... logprob:  0.794284, 0.335937 (1.446 sec)
1.475... logprob:  0.638145, 0.268229 (1.448 sec)
1.476... logprob:  0.770971, 0.348958 (1.457 sec)
1.477... logprob:  0.665813, 0.289062 (1.431 sec)
1.478... logprob:  0.646662, 0.266927 (1.418 sec)
1.479... logprob:  0.583478, 0.277344 (1.421 sec)
1.480... logprob:  0.617142, 0.302083 (1.428 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.397422, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.793842e-03 [3.972244e-07] 
Layer 'conv1' biases: 1.856036e-07 [1.416090e-09] 
Layer 'conv2' weights[0]: 7.780920e-03 [3.926875e-07] 
Layer 'conv2' biases: 9.999999e-01 [6.568675e-09] 
Layer 'conv3' weights[0]: 7.779501e-03 [3.918462e-07] 
Layer 'conv3' biases: 4.230450e-06 [2.229743e-08] 
Layer 'conv4' weights[0]: 7.811018e-03 [3.962353e-07] 
Layer 'conv4' biases: 9.999972e-01 [2.209020e-07] 
Layer 'conv5' weights[0]: 7.811696e-03 [1.353096e-06] 
Layer 'conv5' biases: 9.998040e-01 [1.364235e-06] 
Layer 'fc6' weights[0]: 7.574640e-03 [4.764748e-08] 
Layer 'fc6' biases: 9.999999e-01 [2.989890e-08] 
Layer 'fc7' weights[0]: 7.928761e-03 [8.291820e-08] 
Layer 'fc7' biases: 9.999939e-01 [7.967874e-08] 
Layer 'fc8' weights[0]: 2.205187e-03 [1.672483e-05] 
Layer 'fc8' biases: 3.831682e-03 [1.300000e-05] 
Train error last 800 batches: 0.662237
-------------------------------------------------------
Saved checkpoint to /data2/ad6813/my-nets/saves/ConvNet__2014-06-04_16.10.14
======================================================= (2.788 sec)
1.481... logprob:  0.717831, 0.286458 (1.436 sec)
1.482... logprob:  0.688382, 0.276042 (1.473 sec)
1.483... logprob:  0.822845, 0.364583 (1.439 sec)
1.484... logprob:  0.623715, 0.274740 (2.207 sec)
1.485... logprob:  0.619195, 0.266927 (1.482 sec)
1.486... logprob:  0.636790, 0.294271 (1.431 sec)
1.487... logprob:  0.741530, 0.311198 (2.770 sec)
1.488... logprob:  0.704711, 0.299479 (1.437 sec)
1.489... logprob:  0.662464, 0.304687 (1.430 sec)
1.490... logprob:  0.608611, 0.276042 (1.425 sec)
1.491... logprob:  0.677433, 0.328125 (1.478 sec)
1.492... logprob:  0.670002, 0.251302 (1.475 sec)
1.493... logprob:  0.726038, 0.292969 (1.436 sec)
1.494... logprob:  0.643487, 0.279948 (1.478 sec)
1.495... logprob:  0.619628, 0.292969 (1.428 sec)
1.496... logprob:  0.744065, 0.312500 (1.423 sec)
1.497... logprob:  0.654325, 0.291667 (1.430 sec)
1.498... logprob:  0.666557, 0.292969 (1.429 sec)
1.499... logprob:  0.693807, 0.317708 (1.423 sec)
1.500... logprob:  0.589561, 0.256510 (1.481 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.516039, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.786047e-03 [3.948215e-07] 
Layer 'conv1' biases: 1.878782e-07 [1.515747e-09] 
Layer 'conv2' weights[0]: 7.773153e-03 [3.915660e-07] 
Layer 'conv2' biases: 9.999999e-01 [7.876895e-09] 
Layer 'conv3' weights[0]: 7.771720e-03 [3.925240e-07] 
Layer 'conv3' biases: 4.313928e-06 [2.920184e-08] 
Layer 'conv4' weights[0]: 7.803224e-03 [3.966743e-07] 
Layer 'conv4' biases: 9.999969e-01 [2.513834e-07] 
Layer 'conv5' weights[0]: 7.803953e-03 [1.558634e-06] 
Layer 'conv5' biases: 9.997970e-01 [1.576734e-06] 
Layer 'fc6' weights[0]: 7.573856e-03 [4.969573e-08] 
Layer 'fc6' biases: 9.999999e-01 [3.361346e-08] 
Layer 'fc7' weights[0]: 7.927977e-03 [8.902757e-08] 
Layer 'fc7' biases: 9.999936e-01 [9.810756e-08] 
Layer 'fc8' weights[0]: 2.205637e-03 [2.066922e-05] 
Layer 'fc8' biases: 3.729980e-03 [2.676022e-05] 
Train error last 800 batches: 0.662769
-------------------------------------------------------
Not saving because 0.516039 > 0.397422 (1.480: -2.61%)
======================================================= (2.380 sec)
1.501... logprob:  0.566491, 0.256510 (1.434 sec)
1.502... logprob:  0.682179, 0.304688 (1.434 sec)
1.503... logprob:  0.594129, 0.272135 (1.498 sec)
1.504... logprob:  0.750965, 0.322917 (1.425 sec)
1.505... logprob:  0.720701, 0.305990 (1.434 sec)
1.506... logprob:  0.730241, 0.303385 (1.423 sec)
1.507... logprob:  0.616144, 0.263021 (1.423 sec)
1.508... logprob:  0.575404, 0.269531 (1.425 sec)
1.509... logprob:  0.591785, 0.261719 (1.474 sec)
1.510... logprob:  0.628110, 0.291667 (1.436 sec)
1.511... logprob:  0.553454, 0.233073 (1.466 sec)
1.512... logprob:  0.628187, 0.281250 (1.465 sec)
1.513... logprob:  0.633762, 0.286458 (1.433 sec)
1.514... logprob:  0.630138, 0.285156 (1.429 sec)
1.515... logprob:  0.656107, 0.303385 (1.421 sec)
1.516... logprob:  0.680326, 0.305990 (1.420 sec)
1.517... logprob:  0.802104, 0.335937 (1.430 sec)
1.518... logprob:  0.708687, 0.312500 (1.451 sec)
1.519... logprob:  0.723768, 0.341146 (1.442 sec)
1.520... logprob:  0.711877, 0.326823 (1.441 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.354449, 0.062500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.778245e-03 [3.986995e-07] 
Layer 'conv1' biases: 1.858091e-07 [1.393813e-09] 
Layer 'conv2' weights[0]: 7.765403e-03 [3.934904e-07] 
Layer 'conv2' biases: 9.999999e-01 [9.397672e-09] 
Layer 'conv3' weights[0]: 7.763890e-03 [3.939325e-07] 
Layer 'conv3' biases: 4.326176e-06 [3.383703e-08] 
Layer 'conv4' weights[0]: 7.795441e-03 [3.991668e-07] 
Layer 'conv4' biases: 9.999966e-01 [3.512811e-07] 
Layer 'conv5' weights[0]: 7.796164e-03 [1.971208e-06] 
Layer 'conv5' biases: 9.997963e-01 [2.069268e-06] 
Layer 'fc6' weights[0]: 7.573073e-03 [5.267014e-08] 
Layer 'fc6' biases: 9.999999e-01 [3.807023e-08] 
Layer 'fc7' weights[0]: 7.927182e-03 [1.004339e-07] 
Layer 'fc7' biases: 9.999937e-01 [1.305787e-07] 
Layer 'fc8' weights[0]: 2.291644e-03 [2.334111e-05] 
Layer 'fc8' biases: 3.983787e-03 [3.736609e-05] 
Train error last 800 batches: 0.662633
-------------------------------------------------------
Saved checkpoint to /data2/ad6813/my-nets/saves/ConvNet__2014-06-04_16.10.14
======================================================= (2.860 sec)
1.521... logprob:  0.649355, 0.296875 (1.455 sec)
1.522... logprob:  0.646852, 0.296875 (1.460 sec)
1.523... logprob:  0.631054, 0.291667 (1.437 sec)
1.524... logprob:  0.683680, 0.299479 (2.213 sec)
1.525... logprob:  0.596753, 0.247396 (1.435 sec)
1.526... logprob:  0.601702, 0.266927 (1.430 sec)
1.527... logprob:  0.690439, 0.304687 (2.776 sec)
1.528... logprob:  0.625497, 0.263021 (1.464 sec)
1.529... logprob:  0.607654, 0.255208 (1.460 sec)
1.530... logprob:  0.676629, 0.286458 (1.430 sec)
1.531... logprob:  0.730403, 0.308594 (1.492 sec)
1.532... logprob:  0.685093, 0.334635 (1.426 sec)
1.533... logprob:  0.750411, 0.315104 (1.420 sec)
1.534... logprob:  0.668020, 0.309896 (1.429 sec)
1.535... logprob:  0.818167, 0.346354 (1.431 sec)
1.536... logprob:  0.825649, 0.365885 (1.428 sec)
1.537... logprob:  0.653769, 0.303385 (1.467 sec)
1.538... logprob:  0.703438, 0.289062 (1.438 sec)
1.539... logprob:  0.598791, 0.244792 (1.419 sec)
1.540... logprob:  0.673570, 0.289062 (1.475 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.448677, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.770468e-03 [3.956324e-07] 
Layer 'conv1' biases: 1.879494e-07 [1.456232e-09] 
Layer 'conv2' weights[0]: 7.757701e-03 [3.926059e-07] 
Layer 'conv2' biases: 9.999999e-01 [8.046555e-09] 
Layer 'conv3' weights[0]: 7.756158e-03 [3.929065e-07] 
Layer 'conv3' biases: 4.429282e-06 [2.973232e-08] 
Layer 'conv4' weights[0]: 7.787659e-03 [3.976748e-07] 
Layer 'conv4' biases: 9.999973e-01 [2.785735e-07] 
Layer 'conv5' weights[0]: 7.788499e-03 [1.657525e-06] 
Layer 'conv5' biases: 9.997935e-01 [1.691176e-06] 
Layer 'fc6' weights[0]: 7.572284e-03 [4.950584e-08] 
Layer 'fc6' biases: 9.999999e-01 [3.336636e-08] 
Layer 'fc7' weights[0]: 7.926376e-03 [8.926298e-08] 
Layer 'fc7' biases: 9.999933e-01 [9.027026e-08] 
Layer 'fc8' weights[0]: 2.230913e-03 [2.010509e-05] 
Layer 'fc8' biases: 3.674570e-03 [1.921496e-05] 
Train error last 800 batches: 0.663123
-------------------------------------------------------
Not saving because 0.448677 > 0.354449 (1.520: -10.81%)
======================================================= (2.386 sec)
1.541... logprob:  0.650251, 0.294271 (1.433 sec)
1.542... logprob:  0.689643, 0.325521 (1.427 sec)
1.543... logprob:  0.583332, 0.278646 (1.431 sec)
1.544... logprob:  0.614130, 0.298177 (1.421 sec)
1.545... logprob:  0.559061, 0.234375 (1.431 sec)
1.546... logprob:  0.599036, 0.305990 (1.475 sec)
1.547... logprob:  0.656660, 0.298177 (1.428 sec)
1.548... logprob:  0.704159, 0.341146 (1.444 sec)
1.549... logprob:  0.715448, 0.282552 (1.475 sec)
1.550... logprob:  0.532782, 0.260417 (1.425 sec)
1.551... logprob:  0.709154, 0.299479 (1.428 sec)
1.552... logprob:  0.681635, 0.296875 (1.430 sec)
1.553... logprob:  0.610820, 0.279948 (1.422 sec)
1.554... logprob:  0.630710, 0.300781 (1.430 sec)
1.555... logprob:  0.657468, 0.295573 (1.469 sec)
1.556... logprob:  0.549334, 0.231771 (1.426 sec)
1.557... logprob:  0.690203, 0.295573 (1.444 sec)
1.558... logprob:  0.680828, 0.286458 (1.466 sec)
1.559... logprob:  0.586998, 0.255208 (1.429 sec)
1.560... logprob:  0.619869, 0.269531 (1.427 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.443060, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.762725e-03 [3.967274e-07] 
Layer 'conv1' biases: 1.850123e-07 [1.280682e-09] 
Layer 'conv2' weights[0]: 7.749928e-03 [3.924532e-07] 
Layer 'conv2' biases: 9.999999e-01 [7.887087e-09] 
Layer 'conv3' weights[0]: 7.748388e-03 [3.915232e-07] 
Layer 'conv3' biases: 4.413482e-06 [2.842570e-08] 
Layer 'conv4' weights[0]: 7.779882e-03 [3.962794e-07] 
Layer 'conv4' biases: 9.999963e-01 [2.628743e-07] 
Layer 'conv5' weights[0]: 7.780427e-03 [1.625151e-06] 
Layer 'conv5' biases: 9.997963e-01 [1.655461e-06] 
Layer 'fc6' weights[0]: 7.571518e-03 [5.018894e-08] 
Layer 'fc6' biases: 9.999999e-01 [3.423597e-08] 
Layer 'fc7' weights[0]: 7.925642e-03 [9.051583e-08] 
Layer 'fc7' biases: 9.999939e-01 [9.452608e-08] 
Layer 'fc8' weights[0]: 2.402691e-03 [2.029895e-05] 
Layer 'fc8' biases: 4.229074e-03 [2.743403e-05] 
Train error last 800 batches: 0.662157
-------------------------------------------------------
Not saving because 0.443060 > 0.354449 (1.520: -10.81%)
======================================================= (2.393 sec)
1.561... logprob:  0.668386, 0.305990 (1.431 sec)
1.562... logprob:  0.693635, 0.302083 (1.417 sec)
1.563... logprob:  0.661875, 0.296875 (1.431 sec)
1.564... logprob:  0.670007, 0.326823 (1.461 sec)
1.565... logprob:  0.766671, 0.350260 (1.444 sec)
1.566... logprob:  0.587579, 0.270833 (1.447 sec)
1.567... logprob:  0.677485, 0.295573 (1.458 sec)
1.568... logprob:  0.636335, 0.265625 (1.449 sec)
1.569... logprob:  0.714734, 0.291667 (1.432 sec)
1.570... logprob:  0.756602, 0.329427 (1.422 sec)
1.571... logprob:  0.655780, 0.291667 (1.423 sec)
1.572... logprob:  0.692654, 0.287760 (1.434 sec)
1.573... logprob:  0.686642, 0.278646 (1.438 sec)
1.574... logprob:  0.606739, 0.268229 (1.461 sec)
1.575... logprob:  0.588076, 0.259115 (1.445 sec)
1.576... logprob:  0.662463, 0.289062 (1.441 sec)
1.577... logprob:  0.630262, 0.278646 (1.466 sec)
1.578... logprob:  0.623394, 0.283854 (1.425 sec)
1.579... logprob:  0.639298, 0.307292 (1.439 sec)
1.580... logprob:  0.743656, 0.317708 (1.425 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.479121, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.754942e-03 [3.933025e-07] 
Layer 'conv1' biases: 1.900320e-07 [1.529383e-09] 
Layer 'conv2' weights[0]: 7.742097e-03 [3.913196e-07] 
Layer 'conv2' biases: 9.999999e-01 [8.869610e-09] 
Layer 'conv3' weights[0]: 7.740633e-03 [3.915893e-07] 
Layer 'conv3' biases: 4.572830e-06 [2.976341e-08] 
Layer 'conv4' weights[0]: 7.772065e-03 [3.964409e-07] 
Layer 'conv4' biases: 9.999972e-01 [2.808989e-07] 
Layer 'conv5' weights[0]: 7.772946e-03 [1.762969e-06] 
Layer 'conv5' biases: 9.997857e-01 [1.807119e-06] 
Layer 'fc6' weights[0]: 7.570719e-03 [5.074069e-08] 
Layer 'fc6' biases: 9.999999e-01 [3.568896e-08] 
Layer 'fc7' weights[0]: 7.924850e-03 [9.175483e-08] 
Layer 'fc7' biases: 9.999930e-01 [1.031539e-07] 
Layer 'fc8' weights[0]: 2.296533e-03 [2.324612e-05] 
Layer 'fc8' biases: 3.763767e-03 [3.511032e-05] 
Train error last 800 batches: 0.662362
-------------------------------------------------------
Not saving because 0.479121 > 0.354449 (1.520: -10.81%)
======================================================= (2.361 sec)
1.581... logprob:  0.660408, 0.307292 (1.432 sec)
1.582... logprob:  0.609430, 0.265625 (1.429 sec)
1.583... logprob:  0.722275, 0.320312 (1.469 sec)
1.584... logprob:  0.690175, 0.295573 (1.440 sec)
1.585... logprob:  0.607450, 0.260417 (1.426 sec)
1.586... logprob:  0.533426, 0.251302 (1.487 sec)
1.587... logprob:  0.565293, 0.246094 (1.425 sec)
1.588... logprob:  0.640450, 0.286458 (1.420 sec)
1.589... logprob:  0.589505, 0.292969 (1.429 sec)
1.590... logprob:  0.645564, 0.279948 (1.427 sec)
1.591... logprob:  0.621630, 0.279948 (1.426 sec)
1.592... logprob:  0.700857, 0.286458 (1.473 sec)
1.593... logprob:  0.696442, 0.304688 (1.429 sec)
1.594... logprob:  0.471190, 0.216146 (1.431 sec)
1.595... logprob:  0.647417, 0.279948 (1.483 sec)
1.596... logprob:  0.617373, 0.252604 (1.426 sec)
1.597... logprob:  0.614845, 0.265625 (1.430 sec)
1.598... logprob:  0.614410, 0.265625 (1.423 sec)
1.599... logprob:  0.613933, 0.270833 (1.418 sec)
1.600... logprob:  0.639444, 0.303385 (1.428 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.502815, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.747178e-03 [3.917257e-07] 
Layer 'conv1' biases: 1.906151e-07 [1.449230e-09] 
Layer 'conv2' weights[0]: 7.734385e-03 [3.910131e-07] 
Layer 'conv2' biases: 9.999999e-01 [7.912921e-09] 
Layer 'conv3' weights[0]: 7.732976e-03 [3.907712e-07] 
Layer 'conv3' biases: 4.578985e-06 [2.618822e-08] 
Layer 'conv4' weights[0]: 7.764272e-03 [3.945173e-07] 
Layer 'conv4' biases: 9.999954e-01 [2.528760e-07] 
Layer 'conv5' weights[0]: 7.764918e-03 [1.571849e-06] 
Layer 'conv5' biases: 9.997888e-01 [1.616560e-06] 
Layer 'fc6' weights[0]: 7.569901e-03 [5.006968e-08] 
Layer 'fc6' biases: 9.999999e-01 [3.461015e-08] 
Layer 'fc7' weights[0]: 7.924057e-03 [9.059409e-08] 
Layer 'fc7' biases: 9.999934e-01 [1.008680e-07] 
Layer 'fc8' weights[0]: 2.423249e-03 [2.267706e-05] 
Layer 'fc8' biases: 4.233132e-03 [2.933168e-05] 
Train error last 800 batches: 0.661119
-------------------------------------------------------
Not saving because 0.502815 > 0.354449 (1.520: -10.81%)
======================================================= (2.387 sec)
1.601... logprob:  0.609164, 0.286458 (1.486 sec)
1.602... logprob:  0.487306, 0.244792 (1.430 sec)
1.603... logprob:  0.485468, 0.226562 (1.437 sec)
1.604... logprob:  0.786346, 0.343750 (1.478 sec)
1.605... logprob:  0.757589, 0.328125 (1.452 sec)
1.606... logprob:  0.547644, 0.226563 (1.438 sec)
1.607... logprob:  0.740266, 0.303385 (1.420 sec)
1.608... logprob:  0.556999, 0.243490 (1.417 sec)
1.609... logprob:  0.614429, 0.263021 (1.426 sec)
1.610... logprob:  0.644059, 0.281250 (1.466 sec)
1.611... logprob:  0.731515, 0.313802 (1.439 sec)
1.612... logprob:  0.727553, 0.294271 (1.446 sec)
1.613... logprob:  0.511682, 0.244792 (1.455 sec)
1.614... logprob:  0.604808, 0.283854 (1.443 sec)
1.615... logprob:  0.633508, 0.253906 (1.433 sec)
1.616... logprob:  0.599668, 0.246094 (1.422 sec)
1.617... logprob:  0.527482, 0.256510 (1.451 sec)
1.618... logprob:  0.744564, 0.337240 (1.436 sec)
1.619... logprob:  0.682369, 0.295573 (1.443 sec)
1.620... logprob:  0.738260, 0.317708 (1.449 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.471093, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.739445e-03 [3.961433e-07] 
Layer 'conv1' biases: 1.897923e-07 [1.455425e-09] 
Layer 'conv2' weights[0]: 7.726684e-03 [3.921783e-07] 
Layer 'conv2' biases: 9.999999e-01 [1.042927e-08] 
Layer 'conv3' weights[0]: 7.725243e-03 [3.926899e-07] 
Layer 'conv3' biases: 4.644886e-06 [3.543090e-08] 
Layer 'conv4' weights[0]: 7.756487e-03 [3.979419e-07] 
Layer 'conv4' biases: 9.999955e-01 [3.187466e-07] 
Layer 'conv5' weights[0]: 7.757148e-03 [1.989212e-06] 
Layer 'conv5' biases: 9.997859e-01 [2.140324e-06] 
Layer 'fc6' weights[0]: 7.569075e-03 [5.452572e-08] 
Layer 'fc6' biases: 9.999999e-01 [4.104336e-08] 
Layer 'fc7' weights[0]: 7.923264e-03 [1.029744e-07] 
Layer 'fc7' biases: 9.999927e-01 [1.329869e-07] 
Layer 'fc8' weights[0]: 2.393061e-03 [2.240523e-05] 
Layer 'fc8' biases: 4.056922e-03 [3.443878e-05] 
Train error last 800 batches: 0.660326
-------------------------------------------------------
Not saving because 0.471093 > 0.354449 (1.520: -10.81%)
======================================================= (2.364 sec)
1.621... logprob:  0.567188, 0.248698 (1.448 sec)
1.622... logprob:  0.561103, 0.257812 (1.442 sec)
1.623... logprob:  0.687261, 0.303385 (1.460 sec)
1.624... logprob:  0.679240, 0.308594 (1.457 sec)
1.625... logprob:  0.677440, 0.319010 (1.425 sec)
1.626... logprob:  0.661750, 0.317708 (1.426 sec)
1.627... logprob:  0.667256, 0.272135 (1.435 sec)
1.628... logprob:  0.662277, 0.290365 (1.429 sec)
1.629... logprob:  0.583975, 0.248698 (1.467 sec)
1.630... logprob:  0.615275, 0.289062 (1.444 sec)
1.631... logprob:  0.903944, 0.358073 (1.427 sec)
1.632... logprob:  0.671018, 0.289062 (1.473 sec)
1.633... logprob:  0.648239, 0.281250 (1.423 sec)
1.634... logprob:  0.768385, 0.337240 (1.425 sec)
1.635... logprob:  0.611886, 0.256510 (1.428 sec)
1.636... logprob:  0.726394, 0.311198 (1.428 sec)
1.637... logprob:  0.618392, 0.287760 (1.424 sec)
1.638... logprob:  0.731844, 0.303385 (1.468 sec)
1.639... logprob:  0.764844, 0.345052 (1.434 sec)
1.640... logprob:  0.762690, 0.324219 (1.427 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.529334, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.731735e-03 [3.938615e-07] 
Layer 'conv1' biases: 1.939537e-07 [1.451547e-09] 
Layer 'conv2' weights[0]: 7.718884e-03 [3.900935e-07] 
Layer 'conv2' biases: 9.999999e-01 [7.832867e-09] 
Layer 'conv3' weights[0]: 7.717531e-03 [3.903261e-07] 
Layer 'conv3' biases: 4.785815e-06 [3.205327e-08] 
Layer 'conv4' weights[0]: 7.748747e-03 [3.951945e-07] 
Layer 'conv4' biases: 9.999966e-01 [3.191692e-07] 
Layer 'conv5' weights[0]: 7.749829e-03 [1.797823e-06] 
Layer 'conv5' biases: 9.997776e-01 [1.812343e-06] 
Layer 'fc6' weights[0]: 7.568269e-03 [5.364976e-08] 
Layer 'fc6' biases: 9.999999e-01 [4.014535e-08] 
Layer 'fc7' weights[0]: 7.922453e-03 [1.014018e-07] 
Layer 'fc7' biases: 9.999922e-01 [1.202278e-07] 
Layer 'fc8' weights[0]: 2.323335e-03 [2.284918e-05] 
Layer 'fc8' biases: 3.703016e-03 [3.059540e-05] 
Train error last 800 batches: 0.660895
-------------------------------------------------------
Not saving because 0.529334 > 0.354449 (1.520: -10.81%)
======================================================= (2.425 sec)
1.641... logprob:  0.549641, 0.242187 (1.484 sec)
1.642... logprob:  0.706834, 0.322917 (1.430 sec)
1.643... logprob:  0.761408, 0.350260 (1.456 sec)
1.644... logprob:  0.587081, 0.272135 (1.438 sec)
1.645... logprob:  0.541536, 0.235677 (1.420 sec)
1.646... logprob:  0.638442, 0.291667 (1.428 sec)
1.647... logprob:  0.685340, 0.289062 (1.484 sec)
1.648... logprob:  0.664955, 0.305990 (1.424 sec)
1.649... logprob:  0.586555, 0.274740 (1.440 sec)
1.650... logprob:  0.684415, 0.309896 (1.471 sec)
1.651... logprob:  0.620002, 0.274740 (1.423 sec)
1.652... logprob:  0.772075, 0.343750 (1.424 sec)
1.653... logprob:  0.759858, 0.311198 (1.432 sec)
1.654... logprob:  0.598940, 0.269531 (1.421 sec)
1.655... logprob:  0.635395, 0.289062 (1.442 sec)
1.656... logprob:  0.628074, 0.277344 (1.473 sec)
1.657... logprob:  0.727677, 0.309896 (1.434 sec)
1.658... logprob:  0.581226, 0.261719 (1.469 sec)
1.659... logprob:  0.694500, 0.296875 (1.463 sec)
1.660... logprob:  0.685510, 0.320312 (1.436 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.396013, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.723987e-03 [3.949430e-07] 
Layer 'conv1' biases: 1.973816e-07 [1.351257e-09] 
Layer 'conv2' weights[0]: 7.711222e-03 [3.896929e-07] 
Layer 'conv2' biases: 9.999999e-01 [7.419515e-09] 
Layer 'conv3' weights[0]: 7.709825e-03 [3.893033e-07] 
Layer 'conv3' biases: 4.863566e-06 [2.758219e-08] 
Layer 'conv4' weights[0]: 7.740975e-03 [3.949255e-07] 
Layer 'conv4' biases: 9.999963e-01 [2.969882e-07] 
Layer 'conv5' weights[0]: 7.741822e-03 [1.667443e-06] 
Layer 'conv5' biases: 9.997780e-01 [1.727183e-06] 
Layer 'fc6' weights[0]: 7.567457e-03 [5.042737e-08] 
Layer 'fc6' biases: 9.999999e-01 [3.500537e-08] 
Layer 'fc7' weights[0]: 7.921668e-03 [9.313090e-08] 
Layer 'fc7' biases: 9.999923e-01 [1.015122e-07] 
Layer 'fc8' weights[0]: 2.423075e-03 [2.346167e-05] 
Layer 'fc8' biases: 4.000008e-03 [3.815244e-05] 
Train error last 800 batches: 0.660730
-------------------------------------------------------
Not saving because 0.396013 > 0.354449 (1.520: -10.81%)
======================================================= (2.374 sec)
1.661... logprob:  0.653350, 0.300781 (1.433 sec)
1.662... logprob:  0.696405, 0.317708 (1.454 sec)
1.663... logprob:  0.582329, 0.263021 (1.423 sec)
1.664... logprob:  0.537043, 0.265625 (1.434 sec)
1.665... logprob:  0.585809, 0.274740 (1.455 sec)
1.666... logprob:  0.686315, 0.292969 (1.442 sec)
1.667... logprob:  0.770736, 0.321615 (1.451 sec)
1.668... logprob:  0.718980, 0.287760 (1.448 sec)
1.669... logprob:  0.563839, 0.236979 (1.451 sec)
1.670... logprob:  0.552758, 0.243490 (1.432 sec)
1.671... logprob:  0.584716, 0.272135 (1.418 sec)
1.672... logprob:  0.667355, 0.269531 (1.451 sec)
1.673... logprob:  0.686366, 0.299479 (1.433 sec)
1.674... logprob:  0.636823, 0.309896 (1.433 sec)
1.675... logprob:  0.651121, 0.255208 (1.460 sec)
1.676... logprob:  0.641707, 0.299479 (1.447 sec)
1.677... logprob:  0.644926, 0.259115 (1.433 sec)
1.678... logprob:  0.643901, 0.285156 (1.474 sec)
1.679... logprob:  0.665582, 0.303385 (1.423 sec)
1.680... logprob:  0.596521, 0.256510 (1.426 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.496314, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.716271e-03 [3.923885e-07] 
Layer 'conv1' biases: 1.996447e-07 [1.288114e-09] 
Layer 'conv2' weights[0]: 7.703465e-03 [3.898927e-07] 
Layer 'conv2' biases: 9.999999e-01 [7.912774e-09] 
Layer 'conv3' weights[0]: 7.702012e-03 [3.890128e-07] 
Layer 'conv3' biases: 4.853671e-06 [2.710678e-08] 
Layer 'conv4' weights[0]: 7.733311e-03 [3.932444e-07] 
Layer 'conv4' biases: 9.999955e-01 [2.677345e-07] 
Layer 'conv5' weights[0]: 7.733843e-03 [1.700727e-06] 
Layer 'conv5' biases: 9.997802e-01 [1.767381e-06] 
Layer 'fc6' weights[0]: 7.566647e-03 [4.961194e-08] 
Layer 'fc6' biases: 9.999999e-01 [3.390298e-08] 
Layer 'fc7' weights[0]: 7.920908e-03 [8.975861e-08] 
Layer 'fc7' biases: 9.999924e-01 [9.177141e-08] 
Layer 'fc8' weights[0]: 2.475733e-03 [1.915515e-05] 
Layer 'fc8' biases: 4.144701e-03 [2.338227e-05] 
Train error last 800 batches: 0.660071
-------------------------------------------------------
Not saving because 0.496314 > 0.354449 (1.520: -10.81%)
======================================================= (2.392 sec)
1.681... logprob:  0.587572, 0.259114 (1.461 sec)
1.682... logprob:  0.533719, 0.233073 (1.438 sec)
1.683... logprob:  0.677704, 0.300781 (1.422 sec)
1.684... logprob:  0.610279, 0.269531 (1.474 sec)
1.685... logprob:  0.566889, 0.261719 (1.433 sec)
1.686... logprob:  0.562728, 0.256510 (1.423 sec)
1.687... logprob:  0.524103, 0.217448 (1.477 sec)
1.688... logprob:  0.530177, 0.265625 (1.428 sec)
1.689... logprob:  0.699254, 0.304687 (1.425 sec)
1.690... logprob:  0.653834, 0.298177 (1.429 sec)
1.691... logprob:  0.662370, 0.276042 (1.426 sec)
1.692... logprob:  0.738488, 0.351563 (1.432 sec)
1.693... logprob:  0.542468, 0.233073 (1.494 sec)
1.694... logprob:  0.652261, 0.299479 (1.426 sec)
1.695... logprob:  0.612391, 0.240885 (1.437 sec)
1.696... logprob:  0.780291, 0.342448 (1.474 sec)
1.697... logprob:  0.660059, 0.296875 (1.428 sec)
1.698... logprob:  0.732786, 0.295573 (1.424 sec)
1.699... logprob:  0.730530, 0.307292 (1.424 sec)
1.700... logprob:  0.665636, 0.316406 (1.422 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.459102, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.708555e-03 [3.997205e-07] 
Layer 'conv1' biases: 2.044856e-07 [2.102848e-09] 
Layer 'conv2' weights[0]: 7.695826e-03 [3.926016e-07] 
Layer 'conv2' biases: 9.999998e-01 [1.329563e-08] 
Layer 'conv3' weights[0]: 7.694319e-03 [3.952123e-07] 
Layer 'conv3' biases: 4.969092e-06 [4.641229e-08] 
Layer 'conv4' weights[0]: 7.725570e-03 [4.046950e-07] 
Layer 'conv4' biases: 9.999960e-01 [4.838002e-07] 
Layer 'conv5' weights[0]: 7.726456e-03 [2.986045e-06] 
Layer 'conv5' biases: 9.997734e-01 [3.148504e-06] 
Layer 'fc6' weights[0]: 7.565871e-03 [6.966181e-08] 
Layer 'fc6' biases: 9.999999e-01 [6.114125e-08] 
Layer 'fc7' weights[0]: 7.920098e-03 [1.460390e-07] 
Layer 'fc7' biases: 9.999920e-01 [2.450916e-07] 
Layer 'fc8' weights[0]: 2.442246e-03 [3.462498e-05] 
Layer 'fc8' biases: 4.011277e-03 [6.882765e-05] 
Train error last 800 batches: 0.659389
-------------------------------------------------------
Not saving because 0.459102 > 0.354449 (1.520: -10.81%)
======================================================= (2.379 sec)
1.701... logprob:  0.598524, 0.269531 (1.441 sec)
1.702... logprob:  0.694499, 0.307292 (1.478 sec)
1.703... logprob:  0.584463, 0.251302 (1.427 sec)
1.704... logprob:  0.526475, 0.200521 (1.460 sec)
1.705... logprob:  0.653761, 0.273437 (1.476 sec)
1.706... logprob:  0.644305, 0.281250 (1.429 sec)
1.707... logprob:  0.649670, 0.282552 (1.433 sec)
1.708... logprob:  0.621373, 0.289062 (1.421 sec)
1.709... logprob:  0.695035, 0.300781 (1.422 sec)
1.710... logprob:  0.787801, 0.360677 (1.427 sec)
1.711... logprob:  0.677263, 0.302083 (1.464 sec)
1.712... logprob:  0.514991, 0.257812 (1.442 sec)
1.713... logprob:  0.698918, 0.326823 (1.450 sec)
1.714... logprob:  0.740147, 0.304687 (1.445 sec)
1.715... logprob:  0.631456, 0.276042 (1.444 sec)
1.716... logprob:  0.601641, 0.257812 (1.430 sec)
1.717... logprob:  0.684197, 0.304687 (1.422 sec)
1.718... logprob:  0.695984, 0.305989 (1.423 sec)
1.719... logprob:  0.627041, 0.274740 (1.432 sec)
1.720... logprob:  0.705714, 0.290365 (1.440 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.544414, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.700854e-03 [3.922085e-07] 
Layer 'conv1' biases: 2.069490e-07 [1.710793e-09] 
Layer 'conv2' weights[0]: 7.688048e-03 [3.886483e-07] 
Layer 'conv2' biases: 9.999998e-01 [8.026047e-09] 
Layer 'conv3' weights[0]: 7.686620e-03 [3.885070e-07] 
Layer 'conv3' biases: 5.052950e-06 [2.879292e-08] 
Layer 'conv4' weights[0]: 7.717816e-03 [3.922997e-07] 
Layer 'conv4' biases: 9.999972e-01 [2.502635e-07] 
Layer 'conv5' weights[0]: 7.719013e-03 [1.647571e-06] 
Layer 'conv5' biases: 9.997662e-01 [1.658965e-06] 
Layer 'fc6' weights[0]: 7.565089e-03 [5.003794e-08] 
Layer 'fc6' biases: 9.999999e-01 [3.483529e-08] 
Layer 'fc7' weights[0]: 7.919322e-03 [9.253105e-08] 
Layer 'fc7' biases: 9.999914e-01 [9.544422e-08] 
Layer 'fc8' weights[0]: 2.397210e-03 [2.193704e-05] 
Layer 'fc8' biases: 3.817390e-03 [2.779763e-05] 
Train error last 800 batches: 0.659174
-------------------------------------------------------
Not saving because 0.544414 > 0.354449 (1.520: -10.81%)
======================================================= (2.399 sec)
1.721... logprob:  0.661495, 0.308594 (1.469 sec)
1.722... logprob:  0.680294, 0.325521 (1.446 sec)
1.723... logprob:  0.679466, 0.264323 (1.438 sec)
1.724... logprob:  0.648889, 0.308594 (1.464 sec)
1.725... logprob:  0.672519, 0.304688 (1.431 sec)
1.726... logprob:  0.538940, 0.253906 (1.425 sec)
1.727... logprob:  0.594207, 0.266927 (1.421 sec)
1.728... logprob:  0.661964, 0.281250 (1.434 sec)
1.729... logprob:  0.589348, 0.259115 (1.428 sec)
1.730... logprob:  0.747940, 0.325521 (1.468 sec)
1.731... logprob:  0.659830, 0.274740 (1.457 sec)
1.732... logprob:  0.559650, 0.257812 (1.435 sec)
1.733... logprob:  0.731165, 0.329427 (1.478 sec)
1.734... logprob:  0.620860, 0.266927 (1.432 sec)
1.735... logprob:  0.703652, 0.299479 (1.422 sec)
1.736... logprob:  0.804813, 0.346354 (1.454 sec)
1.737... logprob:  0.744976, 0.354167 (1.427 sec)
1.738... logprob:  0.661306, 0.279948 (1.423 sec)
1.739... logprob:  0.652054, 0.281250 (1.480 sec)
1.740... logprob:  0.563691, 0.268229 (1.454 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.432935, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.693144e-03 [3.898466e-07] 
Layer 'conv1' biases: 2.091501e-07 [1.225205e-09] 
Layer 'conv2' weights[0]: 7.680372e-03 [3.880541e-07] 
Layer 'conv2' biases: 9.999998e-01 [7.675525e-09] 
Layer 'conv3' weights[0]: 7.678944e-03 [3.877079e-07] 
Layer 'conv3' biases: 5.097475e-06 [2.481297e-08] 
Layer 'conv4' weights[0]: 7.710103e-03 [3.922422e-07] 
Layer 'conv4' biases: 9.999967e-01 [2.490741e-07] 
Layer 'conv5' weights[0]: 7.711178e-03 [1.623280e-06] 
Layer 'conv5' biases: 9.997633e-01 [1.718679e-06] 
Layer 'fc6' weights[0]: 7.564273e-03 [4.984038e-08] 
Layer 'fc6' biases: 9.999999e-01 [3.448994e-08] 
Layer 'fc7' weights[0]: 7.918539e-03 [9.018794e-08] 
Layer 'fc7' biases: 9.999914e-01 [9.076713e-08] 
Layer 'fc8' weights[0]: 2.447209e-03 [1.824344e-05] 
Layer 'fc8' biases: 3.924657e-03 [1.813465e-05] 
Train error last 800 batches: 0.659166
-------------------------------------------------------
Not saving because 0.432935 > 0.354449 (1.520: -10.81%)
======================================================= (2.395 sec)
1.741... logprob:  0.635610, 0.304688 (1.432 sec)
1.742... logprob:  0.596821, 0.269531 (1.479 sec)
1.743... logprob:  0.608375, 0.292969 (1.432 sec)
1.744... logprob:  0.740534, 0.333333 (1.424 sec)
1.745... logprob:  0.708259, 0.299479 (1.434 sec)
1.746... logprob:  0.670614, 0.296875 (1.420 sec)
1.747... logprob:  0.584640, 0.272135 (1.427 sec)
1.748... logprob:  0.592386, 0.290365 (1.477 sec)
1.749... logprob:  0.665315, 0.290365 (1.424 sec)
1.750... logprob:  0.642768, 0.260417 (1.438 sec)
1.751... logprob:  0.494388, 0.242187 (1.476 sec)
1.752... logprob:  0.693972, 0.285156 (1.431 sec)
1.753... logprob:  0.608539, 0.246094 (1.430 sec)
1.754... logprob:  0.592093, 0.266927 (1.427 sec)
1.755... logprob:  0.771955, 0.309896 (1.418 sec)
1.756... logprob:  0.711782, 0.332031 (1.432 sec)
1.757... logprob:  0.821092, 0.335937 (1.462 sec)
1.758... logprob:  0.720586, 0.300781 (1.434 sec)
1.759... logprob:  0.697243, 0.302083 (1.471 sec)
1.760... logprob:  0.713468, 0.303385 (1.465 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.376667, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.685435e-03 [3.938079e-07] 
Layer 'conv1' biases: 2.160623e-07 [1.787620e-09] 
Layer 'conv2' weights[0]: 7.672694e-03 [3.907951e-07] 
Layer 'conv2' biases: 9.999998e-01 [1.260371e-08] 
Layer 'conv3' weights[0]: 7.671193e-03 [3.938611e-07] 
Layer 'conv3' biases: 5.155311e-06 [5.048500e-08] 
Layer 'conv4' weights[0]: 7.702337e-03 [4.045616e-07] 
Layer 'conv4' biases: 9.999967e-01 [5.180832e-07] 
Layer 'conv5' weights[0]: 7.703571e-03 [2.990426e-06] 
Layer 'conv5' biases: 9.997624e-01 [3.099333e-06] 
Layer 'fc6' weights[0]: 7.563468e-03 [6.788472e-08] 
Layer 'fc6' biases: 9.999999e-01 [5.951846e-08] 
Layer 'fc7' weights[0]: 7.917777e-03 [1.445295e-07] 
Layer 'fc7' biases: 9.999913e-01 [2.394772e-07] 
Layer 'fc8' weights[0]: 2.469114e-03 [3.505705e-05] 
Layer 'fc8' biases: 4.022407e-03 [6.834973e-05] 
Train error last 800 batches: 0.659280
-------------------------------------------------------
Not saving because 0.376667 > 0.354449 (1.520: -10.81%)
======================================================= (2.355 sec)
1.761... logprob:  0.647856, 0.282552 (1.447 sec)
1.762... logprob:  0.774817, 0.330729 (1.437 sec)
1.763... logprob:  0.764715, 0.342448 (1.424 sec)
1.764... logprob:  0.709027, 0.292969 (1.419 sec)
1.765... logprob:  0.553719, 0.263021 (1.430 sec)
1.766... logprob:  0.618295, 0.244792 (1.452 sec)
1.767... logprob:  0.622047, 0.287760 (1.451 sec)
1.768... logprob:  0.679503, 0.311198 (1.473 sec)
1.769... logprob:  0.649757, 0.287760 (1.487 sec)
1.770... logprob:  0.648384, 0.259115 (1.474 sec)
1.771... logprob:  0.763765, 0.305990 (1.451 sec)
1.772... logprob:  0.630941, 0.277344 (1.438 sec)
1.773... logprob:  0.666915, 0.287760 (1.441 sec)
1.774... logprob:  0.634900, 0.315104 (1.454 sec)
1.775... logprob:  0.687129, 0.305990 (1.455 sec)
1.776... logprob:  0.667295, 0.295573 (1.483 sec)
1.777... logprob:  0.660364, 0.291667 (1.468 sec)
1.778... logprob:  0.617780, 0.276042 (1.473 sec)
1.779... logprob:  0.740899, 0.296875 (1.490 sec)
1.780... logprob:  0.683861, 0.289062 (1.447 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.475871, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.677775e-03 [3.940548e-07] 
Layer 'conv1' biases: 2.226895e-07 [1.348567e-09] 
Layer 'conv2' weights[0]: 7.665052e-03 [3.866628e-07] 
Layer 'conv2' biases: 9.999998e-01 [7.709716e-09] 
Layer 'conv3' weights[0]: 7.663505e-03 [3.867314e-07] 
Layer 'conv3' biases: 5.238030e-06 [2.744201e-08] 
Layer 'conv4' weights[0]: 7.694604e-03 [3.902391e-07] 
Layer 'conv4' biases: 9.999971e-01 [2.399474e-07] 
Layer 'conv5' weights[0]: 7.696138e-03 [1.685699e-06] 
Layer 'conv5' biases: 9.997603e-01 [1.779774e-06] 
Layer 'fc6' weights[0]: 7.562681e-03 [5.102723e-08] 
Layer 'fc6' biases: 9.999999e-01 [3.627432e-08] 
Layer 'fc7' weights[0]: 7.917002e-03 [9.517960e-08] 
Layer 'fc7' biases: 9.999908e-01 [9.628834e-08] 
Layer 'fc8' weights[0]: 2.457393e-03 [1.908811e-05] 
Layer 'fc8' biases: 3.898256e-03 [1.518049e-05] 
Train error last 800 batches: 0.659583
-------------------------------------------------------
Not saving because 0.475871 > 0.354449 (1.520: -10.81%)
======================================================= (2.374 sec)
1.781... logprob:  0.553228, 0.264323 (1.446 sec)
1.782... logprob:  0.546103, 0.246094 (1.450 sec)
1.783... logprob:  0.698341, 0.309896 (1.450 sec)
1.784... logprob:  0.649309, 0.277344 (1.448 sec)
1.785... logprob:  0.744548, 0.322917 (1.482 sec)
1.786... logprob:  0.666357, 0.269531 (1.462 sec)
1.787... logprob:  0.835526, 0.343750 (1.450 sec)
1.788... logprob:  0.856360, 0.346354 (1.486 sec)
1.789... logprob:  0.511921, 0.251302 (1.443 sec)
1.790... logprob:  0.707251, 0.346354 (1.445 sec)
1.791... logprob:  0.729342, 0.308594 (1.441 sec)
1.792... logprob:  0.617653, 0.259115 (1.454 sec)
1.793... logprob:  0.604694, 0.256510 (1.445 sec)
1.794... logprob:  0.652140, 0.289062 (1.483 sec)
1.795... logprob:  0.752125, 0.335938 (1.466 sec)
1.796... logprob:  0.710917, 0.312500 (1.446 sec)
1.797... logprob:  0.626768, 0.296875 (1.515 sec)
1.798... logprob:  0.696765, 0.308594 (1.457 sec)
1.799... logprob:  0.644153, 0.282552 (1.441 sec)
1.800... logprob:  0.567217, 0.263021 (1.412 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.496638, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.670096e-03 [3.894142e-07] 
Layer 'conv1' biases: 2.241488e-07 [1.289769e-09] 
Layer 'conv2' weights[0]: 7.657431e-03 [3.863602e-07] 
Layer 'conv2' biases: 9.999998e-01 [7.153552e-09] 
Layer 'conv3' weights[0]: 7.655878e-03 [3.868540e-07] 
Layer 'conv3' biases: 5.339847e-06 [2.684730e-08] 
Layer 'conv4' weights[0]: 7.686925e-03 [3.911432e-07] 
Layer 'conv4' biases: 9.999965e-01 [2.666108e-07] 
Layer 'conv5' weights[0]: 7.688413e-03 [1.748654e-06] 
Layer 'conv5' biases: 9.997625e-01 [1.723170e-06] 
Layer 'fc6' weights[0]: 7.561907e-03 [5.153454e-08] 
Layer 'fc6' biases: 9.999999e-01 [3.741270e-08] 
Layer 'fc7' weights[0]: 7.916212e-03 [9.590990e-08] 
Layer 'fc7' biases: 9.999907e-01 [1.106918e-07] 
Layer 'fc8' weights[0]: 2.480326e-03 [2.139737e-05] 
Layer 'fc8' biases: 3.939229e-03 [3.081904e-05] 
Train error last 800 batches: 0.659807
-------------------------------------------------------
Not saving because 0.496638 > 0.354449 (1.520: -10.81%)
======================================================= (2.375 sec)
2.1... logprob:  0.625290, 0.272135 (1.402 sec)
2.2... logprob:  0.717266, 0.317708 (1.454 sec)
2.3... logprob:  0.635693, 0.272135 (1.413 sec)
2.4... logprob:  0.692215, 0.307292 (1.401 sec)
2.5... logprob:  0.661701, 0.277344 (1.427 sec)
2.6... logprob:  0.630008, 0.274740 (1.389 sec)
2.7... logprob:  0.570014, 0.269531 (1.431 sec)
2.8... logprob:  0.613419, 0.273437 (1.387 sec)
2.9... logprob:  0.641314, 0.312500 (1.398 sec)
2.10... logprob:  0.536118, 0.246094 (1.395 sec)
2.11... logprob:  0.545256, 0.266927 (1.440 sec)
2.12... logprob:  0.704609, 0.289062 (1.385 sec)
2.13... logprob:  0.661720, 0.290365 (1.418 sec)
2.14... logprob:  0.678344, 0.292969 (1.395 sec)
2.15... logprob:  0.655038, 0.279948 (1.404 sec)
2.16... logprob:  0.719723, 0.334635 (1.396 sec)
2.17... logprob:  0.755475, 0.307292 (1.402 sec)
2.18... logprob:  0.466845, 0.234375 (1.399 sec)
2.19... logprob:  0.545487, 0.259115 (1.390 sec)
2.20... logprob:  0.657762, 0.287760 (0.672 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.544107, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.662408e-03 [3.901499e-07] 
Layer 'conv1' biases: 2.228442e-07 [1.363309e-09] 
Layer 'conv2' weights[0]: 7.649711e-03 [3.858073e-07] 
Layer 'conv2' biases: 9.999998e-01 [7.789121e-09] 
Layer 'conv3' weights[0]: 7.648270e-03 [3.857563e-07] 
Layer 'conv3' biases: 5.436045e-06 [2.672661e-08] 
Layer 'conv4' weights[0]: 7.679230e-03 [3.896902e-07] 
Layer 'conv4' biases: 9.999962e-01 [2.505534e-07] 
Layer 'conv5' weights[0]: 7.680591e-03 [1.598939e-06] 
Layer 'conv5' biases: 9.997657e-01 [1.684637e-06] 
Layer 'fc6' weights[0]: 7.561108e-03 [4.996365e-08] 
Layer 'fc6' biases: 9.999999e-01 [3.457663e-08] 
Layer 'fc7' weights[0]: 7.915417e-03 [9.137832e-08] 
Layer 'fc7' biases: 9.999911e-01 [9.547578e-08] 
Layer 'fc8' weights[0]: 2.573547e-03 [2.016464e-05] 
Layer 'fc8' biases: 4.278605e-03 [2.908942e-05] 
Train error last 800 batches: 0.657222
-------------------------------------------------------
Not saving because 0.544107 > 0.354449 (1.520: -10.81%)
======================================================= (2.430 sec)
2.21... logprob:  0.664821, 0.309896 (1.405 sec)
2.22... logprob:  0.705212, 0.282552 (1.410 sec)
2.23... logprob:  0.762337, 0.296875 (1.405 sec)
2.24... logprob:  0.531738, 0.255208 (1.413 sec)
2.25... logprob:  0.625960, 0.294271 (1.396 sec)
2.26... logprob:  0.696529, 0.330729 (1.437 sec)
2.27... logprob:  0.644765, 0.303385 (1.383 sec)
2.28... logprob:  0.631176, 0.290365 (1.408 sec)
2.29... logprob:  0.546937, 0.243490 (1.413 sec)
2.30... logprob:  0.635589, 0.269531 (1.410 sec)
2.31... logprob:  0.669780, 0.261719 (1.395 sec)
2.32... logprob:  0.616210, 0.286458 (1.380 sec)
2.33... logprob:  0.657314, 0.312500 (1.433 sec)
2.34... logprob:  0.718086, 0.316406 (1.388 sec)
2.35... logprob:  0.542618, 0.269531 (1.392 sec)
2.36... logprob:  0.768484, 0.334635 (1.394 sec)
2.37... logprob:  0.621747, 0.289062 (1.408 sec)
2.38... logprob:  0.624920, 0.282552 (1.388 sec)
2.39... logprob:  0.855593, 0.346354 (1.431 sec)
2.40... logprob:  0.700149, 0.298177 (1.399 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.437449, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.654782e-03 [3.901178e-07] 
Layer 'conv1' biases: 2.201586e-07 [1.156877e-09] 
Layer 'conv2' weights[0]: 7.642082e-03 [3.874144e-07] 
Layer 'conv2' biases: 9.999998e-01 [8.599121e-09] 
Layer 'conv3' weights[0]: 7.640605e-03 [3.875627e-07] 
Layer 'conv3' biases: 5.522243e-06 [3.166996e-08] 
Layer 'conv4' weights[0]: 7.671622e-03 [3.934800e-07] 
Layer 'conv4' biases: 9.999964e-01 [3.342733e-07] 
Layer 'conv5' weights[0]: 7.673127e-03 [2.095170e-06] 
Layer 'conv5' biases: 9.997616e-01 [2.168182e-06] 
Layer 'fc6' weights[0]: 7.560329e-03 [5.717941e-08] 
Layer 'fc6' biases: 9.999999e-01 [4.512475e-08] 
Layer 'fc7' weights[0]: 7.914598e-03 [1.106101e-07] 
Layer 'fc7' biases: 9.999906e-01 [1.460294e-07] 
Layer 'fc8' weights[0]: 2.527664e-03 [2.471289e-05] 
Layer 'fc8' biases: 4.021056e-03 [3.934096e-05] 
Train error last 800 batches: 0.656823
-------------------------------------------------------
Not saving because 0.437449 > 0.354449 (1.520: -10.81%)
======================================================= (2.376 sec)
2.41... logprob:  0.640688, 0.286458 (1.423 sec)
2.42... logprob:  0.621540, 0.285156 (1.413 sec)
2.43... logprob:  0.558574, 0.250000 (1.404 sec)
2.44... logprob:  0.748223, 0.320312 (1.430 sec)
2.45... logprob:  0.636451, 0.283854 (1.382 sec)
2.46... logprob:  0.659429, 0.255208 (1.391 sec)
2.47... logprob:  0.554988, 0.231771 (1.399 sec)
2.48... logprob:  0.616381, 0.290365 (1.415 sec)
2.49... logprob:  0.728152, 0.289062 (1.410 sec)
2.50... logprob:  0.681588, 0.279948 (1.418 sec)
2.51... logprob:  0.694139, 0.300781 (1.411 sec)
2.52... logprob:  0.639271, 0.291667 (1.396 sec)
2.53... logprob:  0.559666, 0.266927 (1.433 sec)
2.54... logprob:  0.648794, 0.278646 (1.384 sec)
2.55... logprob:  0.494235, 0.244792 (1.394 sec)
2.56... logprob:  0.645948, 0.311198 (1.419 sec)
2.57... logprob:  0.731969, 0.302083 (1.430 sec)
2.58... logprob:  0.671706, 0.319010 (1.396 sec)
2.59... logprob:  0.620722, 0.282552 (1.458 sec)
2.60... logprob:  0.737376, 0.305990 (1.410 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.514592, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.647114e-03 [3.888509e-07] 
Layer 'conv1' biases: 2.192996e-07 [1.208857e-09] 
Layer 'conv2' weights[0]: 7.634393e-03 [3.867142e-07] 
Layer 'conv2' biases: 9.999998e-01 [8.464380e-09] 
Layer 'conv3' weights[0]: 7.632959e-03 [3.859807e-07] 
Layer 'conv3' biases: 5.559158e-06 [2.661878e-08] 
Layer 'conv4' weights[0]: 7.663897e-03 [3.905740e-07] 
Layer 'conv4' biases: 9.999965e-01 [2.686475e-07] 
Layer 'conv5' weights[0]: 7.665333e-03 [1.768769e-06] 
Layer 'conv5' biases: 9.997571e-01 [1.764882e-06] 
Layer 'fc6' weights[0]: 7.559557e-03 [5.025297e-08] 
Layer 'fc6' biases: 9.999999e-01 [3.538682e-08] 
Layer 'fc7' weights[0]: 7.913817e-03 [9.213072e-08] 
Layer 'fc7' biases: 9.999905e-01 [9.339360e-08] 
Layer 'fc8' weights[0]: 2.540291e-03 [1.884161e-05] 
Layer 'fc8' biases: 4.069085e-03 [1.561236e-05] 
Train error last 800 batches: 0.656026
-------------------------------------------------------
Not saving because 0.514592 > 0.354449 (1.520: -10.81%)
======================================================= (2.387 sec)
2.61... logprob:  0.622463, 0.263021 (1.434 sec)
2.62... logprob:  0.673080, 0.298177 (1.458 sec)
2.63... logprob:  0.616470, 0.277344 (1.430 sec)
2.64... logprob:  0.600420, 0.269531 (1.405 sec)
2.65... logprob:  0.662402, 0.305990 (1.392 sec)
2.66... logprob:  0.639972, 0.290365 (1.439 sec)
2.67... logprob:  0.543479, 0.213542 (1.380 sec)
2.68... logprob:  0.629572, 0.283854 (1.390 sec)
2.69... logprob:  0.729519, 0.303385 (1.414 sec)
2.70... logprob:  0.566515, 0.269531 (1.419 sec)
2.71... logprob:  0.571021, 0.250000 (1.455 sec)
2.72... logprob:  0.715635, 0.298177 (1.396 sec)
2.73... logprob:  0.665652, 0.305990 (1.414 sec)
2.74... logprob:  0.656901, 0.283854 (1.404 sec)
2.75... logprob:  0.652326, 0.274740 (1.410 sec)
2.76... logprob:  0.723052, 0.320312 (1.435 sec)
2.77... logprob:  0.640667, 0.312500 (1.428 sec)
2.78... logprob:  0.717887, 0.312500 (1.444 sec)
2.79... logprob:  0.735645, 0.329427 (1.396 sec)
2.80... logprob:  0.640677, 0.268229 (1.414 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.487711, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.639497e-03 [3.903823e-07] 
Layer 'conv1' biases: 2.186650e-07 [1.195660e-09] 
Layer 'conv2' weights[0]: 7.626797e-03 [3.854812e-07] 
Layer 'conv2' biases: 9.999998e-01 [7.729000e-09] 
Layer 'conv3' weights[0]: 7.625351e-03 [3.856267e-07] 
Layer 'conv3' biases: 5.631207e-06 [3.276879e-08] 
Layer 'conv4' weights[0]: 7.656276e-03 [3.907531e-07] 
Layer 'conv4' biases: 9.999954e-01 [3.072259e-07] 
Layer 'conv5' weights[0]: 7.657570e-03 [1.964499e-06] 
Layer 'conv5' biases: 9.997558e-01 [2.015114e-06] 
Layer 'fc6' weights[0]: 7.558764e-03 [5.664648e-08] 
Layer 'fc6' biases: 9.999999e-01 [4.461344e-08] 
Layer 'fc7' weights[0]: 7.913070e-03 [1.110591e-07] 
Layer 'fc7' biases: 9.999906e-01 [1.467532e-07] 
Layer 'fc8' weights[0]: 2.594328e-03 [2.272122e-05] 
Layer 'fc8' biases: 4.228548e-03 [3.501022e-05] 
Train error last 800 batches: 0.656270
-------------------------------------------------------
Not saving because 0.487711 > 0.354449 (1.520: -10.81%)
======================================================= (2.406 sec)
2.81... logprob:  0.604242, 0.279948 (1.416 sec)
2.82... logprob:  0.497341, 0.231771 (1.417 sec)
2.83... logprob:  0.752846, 0.322917 (1.393 sec)
2.84... logprob:  0.779939, 0.332031 (1.456 sec)
2.85... logprob:  0.684287, 0.277344 (1.437 sec)
2.86... logprob:  0.553622, 0.248698 (1.412 sec)
2.87... logprob:  0.835872, 0.378906 (1.409 sec)
2.88... logprob:  0.706204, 0.312500 (1.401 sec)
2.89... logprob:  0.622159, 0.272135 (1.431 sec)
2.90... logprob:  0.795891, 0.322917 (1.382 sec)
2.91... logprob:  0.649716, 0.299479 (1.387 sec)
2.92... logprob:  0.740461, 0.319010 (1.397 sec)
2.93... logprob:  0.669239, 0.281250 (1.392 sec)
2.94... logprob:  0.645660, 0.268229 (1.464 sec)
2.95... logprob:  0.676084, 0.289062 (1.428 sec)
2.96... logprob:  0.768837, 0.345052 (1.413 sec)
2.97... logprob:  0.663021, 0.268229 (1.391 sec)
2.98... logprob:  0.594539, 0.250000 (1.426 sec)
2.99... logprob:  0.664097, 0.292969 (1.398 sec)
2.100... logprob:  0.515380, 0.214844 (1.391 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.529031, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.631836e-03 [3.886738e-07] 
Layer 'conv1' biases: 2.284496e-07 [1.332502e-09] 
Layer 'conv2' weights[0]: 7.619132e-03 [3.858374e-07] 
Layer 'conv2' biases: 9.999998e-01 [8.189699e-09] 
Layer 'conv3' weights[0]: 7.617732e-03 [3.852912e-07] 
Layer 'conv3' biases: 5.825793e-06 [2.865239e-08] 
Layer 'conv4' weights[0]: 7.648572e-03 [3.906075e-07] 
Layer 'conv4' biases: 9.999957e-01 [2.679524e-07] 
Layer 'conv5' weights[0]: 7.650188e-03 [1.805300e-06] 
Layer 'conv5' biases: 9.997484e-01 [1.894690e-06] 
Layer 'fc6' weights[0]: 7.557950e-03 [5.266828e-08] 
Layer 'fc6' biases: 9.999998e-01 [3.885250e-08] 
Layer 'fc7' weights[0]: 7.912305e-03 [9.940985e-08] 
Layer 'fc7' biases: 9.999898e-01 [1.165431e-07] 
Layer 'fc8' weights[0]: 2.517142e-03 [2.061358e-05] 
Layer 'fc8' biases: 3.849269e-03 [2.883194e-05] 
Train error last 800 batches: 0.655873
-------------------------------------------------------
Not saving because 0.529031 > 0.354449 (1.520: -10.81%)
======================================================= (2.375 sec)
2.101... logprob:  0.510143, 0.213542 (1.447 sec)
2.102... logprob:  0.805360, 0.356771 (1.389 sec)
2.103... logprob:  0.750385, 0.312500 (1.391 sec)
2.104... logprob:  0.632942, 0.291667 (1.393 sec)
2.105... logprob:  0.786838, 0.352865 (1.390 sec)
2.106... logprob:  0.580350, 0.266927 (1.383 sec)
2.107... logprob:  0.670023, 0.330729 (1.436 sec)
2.108... logprob:  0.702484, 0.322917 (1.392 sec)
2.109... logprob:  0.617220, 0.252604 (1.405 sec)
2.110... logprob:  0.757469, 0.312500 (1.392 sec)
2.111... logprob:  0.595144, 0.285156 (1.388 sec)
2.112... logprob:  0.637184, 0.278646 (1.396 sec)
2.113... logprob:  0.554640, 0.256510 (1.394 sec)
2.114... logprob:  0.618412, 0.256510 (1.426 sec)
2.115... logprob:  0.680196, 0.286458 (1.411 sec)
2.116... logprob:  0.614126, 0.259114 (1.393 sec)
2.117... logprob:  0.748153, 0.342448 (1.440 sec)
2.118... logprob:  0.645626, 0.309896 (1.389 sec)
2.119... logprob:  0.610174, 0.264323 (1.392 sec)
2.120... logprob:  0.821858, 0.335937 (1.394 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.504331, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.624217e-03 [3.868734e-07] 
Layer 'conv1' biases: 2.371757e-07 [1.525797e-09] 
Layer 'conv2' weights[0]: 7.611504e-03 [3.846713e-07] 
Layer 'conv2' biases: 9.999998e-01 [8.227321e-09] 
Layer 'conv3' weights[0]: 7.610095e-03 [3.841798e-07] 
Layer 'conv3' biases: 5.995265e-06 [2.861321e-08] 
Layer 'conv4' weights[0]: 7.640923e-03 [3.882193e-07] 
Layer 'conv4' biases: 9.999952e-01 [2.893780e-07] 
Layer 'conv5' weights[0]: 7.642572e-03 [1.694712e-06] 
Layer 'conv5' biases: 9.997434e-01 [1.755001e-06] 
Layer 'fc6' weights[0]: 7.557181e-03 [5.308887e-08] 
Layer 'fc6' biases: 9.999998e-01 [3.966203e-08] 
Layer 'fc7' weights[0]: 7.911481e-03 [1.004194e-07] 
Layer 'fc7' biases: 9.999900e-01 [1.132096e-07] 
Layer 'fc8' weights[0]: 2.583310e-03 [2.030422e-05] 
Layer 'fc8' biases: 4.129612e-03 [2.681707e-05] 
Train error last 800 batches: 0.656435
-------------------------------------------------------
Not saving because 0.504331 > 0.354449 (1.520: -10.81%)
======================================================= (2.374 sec)
2.121... logprob:  0.628040, 0.246094 (1.399 sec)
2.122... logprob:  0.741762, 0.325521 (1.440 sec)
2.123... logprob:  0.618967, 0.286458 (1.375 sec)
2.124... logprob:  0.664100, 0.305990 (1.404 sec)
2.125... logprob:  0.690360, 0.317708 (1.388 sec)
2.126... logprob:  0.684730, 0.307292 (1.385 sec)
2.127... logprob:  0.693112, 0.298177 (1.396 sec)
2.128... logprob:  0.599587, 0.270833 (1.410 sec)
2.129... logprob:  0.745215, 0.329427 (1.411 sec)
2.130... logprob:  0.582961, 0.273437 (1.407 sec)
2.131... logprob:  0.690269, 0.315104 (1.404 sec)
2.132... logprob:  0.654070, 0.265625 (1.429 sec)
2.133... logprob:  0.714300, 0.339844 (1.381 sec)
2.134... logprob:  0.630140, 0.287760 (1.421 sec)
2.135... logprob:  0.628037, 0.270833 (1.405 sec)
2.136... logprob:  0.719991, 0.319010 (1.392 sec)
2.137... logprob:  0.788878, 0.346354 (1.384 sec)
2.138... logprob:  0.525759, 0.240885 (1.437 sec)
2.139... logprob:  0.605845, 0.242188 (1.389 sec)
2.140... logprob:  0.664490, 0.277344 (1.398 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.492228, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.616559e-03 [3.873514e-07] 
Layer 'conv1' biases: 2.413230e-07 [1.105222e-09] 
Layer 'conv2' weights[0]: 7.603877e-03 [3.837292e-07] 
Layer 'conv2' biases: 9.999998e-01 [6.675589e-09] 
Layer 'conv3' weights[0]: 7.602463e-03 [3.831268e-07] 
Layer 'conv3' biases: 6.130629e-06 [2.482448e-08] 
Layer 'conv4' weights[0]: 7.633292e-03 [3.887660e-07] 
Layer 'conv4' biases: 9.999956e-01 [2.982691e-07] 
Layer 'conv5' weights[0]: 7.635127e-03 [1.744804e-06] 
Layer 'conv5' biases: 9.997418e-01 [1.795341e-06] 
Layer 'fc6' weights[0]: 7.556386e-03 [5.026759e-08] 
Layer 'fc6' biases: 9.999998e-01 [3.562600e-08] 
Layer 'fc7' weights[0]: 7.910747e-03 [9.262209e-08] 
Layer 'fc7' biases: 9.999897e-01 [8.873941e-08] 
Layer 'fc8' weights[0]: 2.560281e-03 [1.766991e-05] 
Layer 'fc8' biases: 4.055458e-03 [1.061309e-05] 
Train error last 800 batches: 0.655963
-------------------------------------------------------
Not saving because 0.492228 > 0.354449 (1.520: -10.81%)
======================================================= (2.379 sec)
2.141... logprob:  0.731240, 0.315104 (1.436 sec)
2.142... logprob:  0.694574, 0.304687 (1.388 sec)
2.143... logprob:  0.599498, 0.274739 (1.421 sec)
2.144... logprob:  0.735609, 0.337240 (1.409 sec)
2.145... logprob:  0.631328, 0.290365 (1.410 sec)
2.146... logprob:  0.687041, 0.317708 (1.403 sec)
2.147... logprob:  0.558444, 0.270833 (1.428 sec)
2.148... logprob:  0.657843, 0.255208 (1.380 sec)
2.149... logprob:  0.698742, 0.296875 (1.390 sec)
2.150... logprob:  0.615900, 0.257813 (1.395 sec)
2.151... logprob:  0.537447, 0.235677 (1.391 sec)
2.152... logprob:  0.880110, 0.342448 (1.393 sec)
2.153... logprob:  0.627610, 0.298177 (1.435 sec)
2.154... logprob:  0.733523, 0.307292 (1.400 sec)
2.155... logprob:  0.661218, 0.296875 (1.404 sec)
2.156... logprob:  0.483049, 0.216146 (1.427 sec)
2.157... logprob:  0.601273, 0.283854 (1.391 sec)
2.158... logprob:  0.689923, 0.303385 (1.393 sec)
2.159... logprob:  0.677245, 0.309896 (1.391 sec)
2.160... logprob:  0.639542, 0.272135 (1.389 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.410466, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.608956e-03 [3.860622e-07] 
Layer 'conv1' biases: 2.481315e-07 [1.290460e-09] 
Layer 'conv2' weights[0]: 7.596311e-03 [3.835911e-07] 
Layer 'conv2' biases: 9.999998e-01 [8.597991e-09] 
Layer 'conv3' weights[0]: 7.594862e-03 [3.842634e-07] 
Layer 'conv3' biases: 6.191993e-06 [2.944027e-08] 
Layer 'conv4' weights[0]: 7.625609e-03 [3.884194e-07] 
Layer 'conv4' biases: 9.999963e-01 [2.897556e-07] 
Layer 'conv5' weights[0]: 7.627582e-03 [1.713510e-06] 
Layer 'conv5' biases: 9.997407e-01 [1.710496e-06] 
Layer 'fc6' weights[0]: 7.555583e-03 [5.281398e-08] 
Layer 'fc6' biases: 9.999998e-01 [3.943753e-08] 
Layer 'fc7' weights[0]: 7.909972e-03 [9.909991e-08] 
Layer 'fc7' biases: 9.999893e-01 [1.148949e-07] 
Layer 'fc8' weights[0]: 2.591261e-03 [2.087050e-05] 
Layer 'fc8' biases: 4.105300e-03 [2.822107e-05] 
Train error last 800 batches: 0.656321
-------------------------------------------------------
Not saving because 0.410466 > 0.354449 (1.520: -10.81%)
======================================================= (2.376 sec)
2.161... logprob:  0.549778, 0.243490 (1.406 sec)
2.162... logprob:  0.875595, 0.367188 (1.405 sec)
2.163... logprob:  0.586471, 0.253906 (1.416 sec)
2.164... logprob:  0.705780, 0.292969 (1.424 sec)
2.165... logprob:  0.693995, 0.308594 (1.410 sec)
2.166... logprob:  0.653056, 0.290365 (1.443 sec)
2.167... logprob:  0.588378, 0.277344 (1.426 sec)
2.168... logprob:  0.563510, 0.239583 (1.415 sec)
2.169... logprob:  0.600117, 0.260417 (1.453 sec)
2.170... logprob:  0.627765, 0.285156 (1.402 sec)
2.171... logprob:  0.632441, 0.283854 (1.416 sec)
2.172... logprob:  0.701232, 0.292969 (1.411 sec)
2.173... logprob:  0.608141, 0.282552 (1.439 sec)
2.174... logprob:  0.771629, 0.305990 (1.403 sec)
2.175... logprob:  0.738245, 0.305990 (1.459 sec)
2.176... logprob:  0.639970, 0.286458 (1.410 sec)
2.177... logprob:  0.521423, 0.233073 (1.422 sec)
2.178... logprob:  0.620273, 0.259115 (1.451 sec)
2.179... logprob:  0.583046, 0.274740 (1.404 sec)
2.180... logprob:  0.664275, 0.290365 (1.412 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.433498, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.601382e-03 [3.893058e-07] 
Layer 'conv1' biases: 2.510448e-07 [1.440600e-09] 
Layer 'conv2' weights[0]: 7.588700e-03 [3.830669e-07] 
Layer 'conv2' biases: 9.999998e-01 [7.171187e-09] 
Layer 'conv3' weights[0]: 7.587310e-03 [3.829308e-07] 
Layer 'conv3' biases: 6.315089e-06 [2.536814e-08] 
Layer 'conv4' weights[0]: 7.618001e-03 [3.871038e-07] 
Layer 'conv4' biases: 9.999960e-01 [2.642665e-07] 
Layer 'conv5' weights[0]: 7.619929e-03 [1.575749e-06] 
Layer 'conv5' biases: 9.997365e-01 [1.605024e-06] 
Layer 'fc6' weights[0]: 7.554793e-03 [5.181239e-08] 
Layer 'fc6' biases: 9.999998e-01 [3.813217e-08] 
Layer 'fc7' weights[0]: 7.909192e-03 [9.864946e-08] 
Layer 'fc7' biases: 9.999895e-01 [1.147330e-07] 
Layer 'fc8' weights[0]: 2.611472e-03 [2.331947e-05] 
Layer 'fc8' biases: 4.200196e-03 [3.451642e-05] 
Train error last 800 batches: 0.655664
-------------------------------------------------------
Not saving because 0.433498 > 0.354449 (1.520: -10.81%)
======================================================= (2.367 sec)
2.181... logprob:  0.780601, 0.322917 (1.418 sec)
2.182... logprob:  0.562031, 0.272135 (1.416 sec)
2.183... logprob:  0.672968, 0.305990 (1.419 sec)
2.184... logprob:  0.788655, 0.324219 (1.417 sec)
2.185... logprob:  0.561329, 0.253906 (1.390 sec)
2.186... logprob:  0.581248, 0.261719 (1.394 sec)
2.187... logprob:  0.706474, 0.305990 (1.391 sec)
2.188... logprob:  0.641158, 0.281250 (1.392 sec)
2.189... logprob:  0.635872, 0.279948 (1.379 sec)
2.190... logprob:  0.603098, 0.296875 (1.430 sec)
2.191... logprob:  0.652615, 0.277344 (1.401 sec)
2.192... logprob:  0.850088, 0.328125 (1.411 sec)
2.193... logprob:  0.518327, 0.240885 (1.420 sec)
2.194... logprob:  0.596425, 0.243490 (1.407 sec)
2.195... logprob:  0.579228, 0.263021 (1.396 sec)
2.196... logprob:  0.654342, 0.265625 (1.388 sec)
2.197... logprob:  0.695040, 0.307292 (1.387 sec)
2.198... logprob:  0.594679, 0.265625 (1.398 sec)
2.199... logprob:  0.710316, 0.307292 (1.385 sec)
2.200... logprob:  0.651486, 0.253906 (1.431 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.409502, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.593728e-03 [3.868087e-07] 
Layer 'conv1' biases: 2.585905e-07 [1.498387e-09] 
Layer 'conv2' weights[0]: 7.581099e-03 [3.833638e-07] 
Layer 'conv2' biases: 9.999998e-01 [8.425080e-09] 
Layer 'conv3' weights[0]: 7.579716e-03 [3.832610e-07] 
Layer 'conv3' biases: 6.409182e-06 [3.161840e-08] 
Layer 'conv4' weights[0]: 7.610441e-03 [3.883147e-07] 
Layer 'conv4' biases: 9.999964e-01 [3.422945e-07] 
Layer 'conv5' weights[0]: 7.612223e-03 [2.119416e-06] 
Layer 'conv5' biases: 9.997343e-01 [2.206380e-06] 
Layer 'fc6' weights[0]: 7.553996e-03 [5.479563e-08] 
Layer 'fc6' biases: 9.999998e-01 [4.225635e-08] 
Layer 'fc7' weights[0]: 7.908424e-03 [1.054442e-07] 
Layer 'fc7' biases: 9.999892e-01 [1.236035e-07] 
Layer 'fc8' weights[0]: 2.629482e-03 [2.619358e-05] 
Layer 'fc8' biases: 4.188678e-03 [4.255873e-05] 
Train error last 800 batches: 0.655665
-------------------------------------------------------
Not saving because 0.409502 > 0.354449 (1.520: -10.81%)
======================================================= (2.426 sec)
2.201... logprob:  0.630515, 0.253906 (1.412 sec)
2.202... logprob:  0.692686, 0.268229 (1.411 sec)
2.203... logprob:  0.580837, 0.242187 (1.434 sec)
2.204... logprob:  0.677841, 0.308594 (1.383 sec)
2.205... logprob:  0.551657, 0.264323 (1.397 sec)
2.206... logprob:  0.519694, 0.238281 (1.391 sec)
2.207... logprob:  0.632141, 0.274740 (1.388 sec)
2.208... logprob:  0.734422, 0.316406 (1.399 sec)
2.209... logprob:  0.552974, 0.238281 (1.412 sec)
2.210... logprob:  0.692717, 0.313802 (1.412 sec)
2.211... logprob:  0.673493, 0.298177 (1.408 sec)
2.212... logprob:  0.733606, 0.300781 (1.439 sec)
2.213... logprob:  0.708652, 0.274740 (1.466 sec)
2.214... logprob:  0.670549, 0.294271 (1.422 sec)
2.215... logprob:  0.594926, 0.247396 (1.404 sec)
2.216... logprob:  0.747380, 0.305990 (1.458 sec)
2.217... logprob:  0.636022, 0.304687 (1.392 sec)
2.218... logprob:  0.724993, 0.309896 (1.422 sec)
2.219... logprob:  0.735549, 0.289062 (1.403 sec)
2.220... logprob:  0.590270, 0.256510 (1.415 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.505543, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.586165e-03 [3.856285e-07] 
Layer 'conv1' biases: 2.663682e-07 [1.660502e-09] 
Layer 'conv2' weights[0]: 7.573549e-03 [3.837214e-07] 
Layer 'conv2' biases: 9.999998e-01 [1.069724e-08] 
Layer 'conv3' weights[0]: 7.572116e-03 [3.850876e-07] 
Layer 'conv3' biases: 6.538083e-06 [3.670088e-08] 
Layer 'conv4' weights[0]: 7.602798e-03 [3.904694e-07] 
Layer 'conv4' biases: 9.999972e-01 [3.622481e-07] 
Layer 'conv5' weights[0]: 7.605236e-03 [1.986330e-06] 
Layer 'conv5' biases: 9.997306e-01 [2.114242e-06] 
Layer 'fc6' weights[0]: 7.553178e-03 [5.616507e-08] 
Layer 'fc6' biases: 9.999998e-01 [4.432188e-08] 
Layer 'fc7' weights[0]: 7.907656e-03 [1.122779e-07] 
Layer 'fc7' biases: 9.999886e-01 [1.457866e-07] 
Layer 'fc8' weights[0]: 2.624728e-03 [2.413646e-05] 
Layer 'fc8' biases: 4.095055e-03 [3.880604e-05] 
Train error last 800 batches: 0.655205
-------------------------------------------------------
Not saving because 0.505543 > 0.354449 (1.520: -10.81%)
======================================================= (2.373 sec)
2.221... logprob:  0.670818, 0.315104 (1.408 sec)
2.222... logprob:  0.695454, 0.315104 (1.453 sec)
2.223... logprob:  0.724639, 0.319010 (1.414 sec)
2.224... logprob:  0.638553, 0.248698 (1.428 sec)
2.225... logprob:  0.617260, 0.261719 (1.438 sec)
2.226... logprob:  0.659521, 0.270833 (1.418 sec)
2.227... logprob:  0.629095, 0.269531 (1.415 sec)
2.228... logprob:  0.600604, 0.240885 (1.409 sec)
2.229... logprob:  0.734072, 0.319010 (1.409 sec)
2.230... logprob:  0.718388, 0.311198 (1.417 sec)
2.231... logprob:  0.683998, 0.296875 (1.402 sec)
2.232... logprob:  0.694965, 0.285156 (1.458 sec)
2.233... logprob:  0.645995, 0.273437 (1.415 sec)
2.234... logprob:  0.695185, 0.313802 (1.403 sec)
2.235... logprob:  0.727668, 0.333333 (1.460 sec)
2.236... logprob:  0.642145, 0.248698 (1.394 sec)
2.237... logprob:  0.633835, 0.278646 (1.411 sec)
2.238... logprob:  0.557916, 0.263021 (1.410 sec)
2.239... logprob:  0.676649, 0.303385 (1.413 sec)
2.240... logprob:  0.711047, 0.299479 (1.398 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.481170, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.578612e-03 [3.861134e-07] 
Layer 'conv1' biases: 2.701795e-07 [1.512034e-09] 
Layer 'conv2' weights[0]: 7.565996e-03 [3.827746e-07] 
Layer 'conv2' biases: 9.999998e-01 [8.442035e-09] 
Layer 'conv3' weights[0]: 7.564549e-03 [3.830614e-07] 
Layer 'conv3' biases: 6.644639e-06 [3.043446e-08] 
Layer 'conv4' weights[0]: 7.595296e-03 [3.884089e-07] 
Layer 'conv4' biases: 9.999992e-01 [3.312579e-07] 
Layer 'conv5' weights[0]: 7.598417e-03 [2.001527e-06] 
Layer 'conv5' biases: 9.997233e-01 [2.080141e-06] 
Layer 'fc6' weights[0]: 7.552404e-03 [5.571704e-08] 
Layer 'fc6' biases: 9.999998e-01 [4.392139e-08] 
Layer 'fc7' weights[0]: 7.906877e-03 [1.088918e-07] 
Layer 'fc7' biases: 9.999881e-01 [1.394612e-07] 
Layer 'fc8' weights[0]: 2.620848e-03 [2.577636e-05] 
Layer 'fc8' biases: 4.002337e-03 [4.588604e-05] 
Train error last 800 batches: 0.654967
-------------------------------------------------------
Not saving because 0.481170 > 0.354449 (1.520: -10.81%)
======================================================= (2.384 sec)
2.241... logprob:  0.747461, 0.338542 (1.492 sec)
2.242... logprob:  0.526630, 0.230469 (1.421 sec)
2.243... logprob:  0.631305, 0.243489 (1.423 sec)
2.244... logprob:  0.556608, 0.270833 (1.440 sec)
2.245... logprob:  0.665976, 0.281250 (1.418 sec)
2.246... logprob:  0.669659, 0.308594 (1.408 sec)
2.247... logprob:  0.610246, 0.290365 (1.408 sec)
2.248... logprob:  0.511549, 0.242187 (1.408 sec)
2.249... logprob:  0.714936, 0.337240 (1.424 sec)
2.250... logprob:  0.741588, 0.305990 (1.405 sec)
2.251... logprob:  0.628614, 0.303385 (1.484 sec)
2.252... logprob:  0.569004, 0.239583 (1.428 sec)
2.253... logprob:  0.642709, 0.277344 (1.408 sec)
2.254... logprob:  0.742305, 0.317708 (1.463 sec)
2.255... logprob:  0.601063, 0.255208 (1.408 sec)
2.256... logprob:  0.617220, 0.272135 (1.414 sec)
2.257... logprob:  0.552532, 0.252604 (1.408 sec)
2.258... logprob:  0.562805, 0.243490 (1.413 sec)
2.259... logprob:  0.709873, 0.298177 (1.396 sec)
2.260... logprob:  0.586028, 0.277344 (1.450 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.544268, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.571031e-03 [3.861999e-07] 
Layer 'conv1' biases: 2.699230e-07 [1.389608e-09] 
Layer 'conv2' weights[0]: 7.558398e-03 [3.830798e-07] 
Layer 'conv2' biases: 9.999998e-01 [7.735747e-09] 
Layer 'conv3' weights[0]: 7.556954e-03 [3.819323e-07] 
Layer 'conv3' biases: 6.628231e-06 [2.818878e-08] 
Layer 'conv4' weights[0]: 7.587653e-03 [3.863146e-07] 
Layer 'conv4' biases: 9.999988e-01 [2.803249e-07] 
Layer 'conv5' weights[0]: 7.590743e-03 [1.683208e-06] 
Layer 'conv5' biases: 9.997243e-01 [1.822540e-06] 
Layer 'fc6' weights[0]: 7.551652e-03 [5.085245e-08] 
Layer 'fc6' biases: 9.999998e-01 [3.638399e-08] 
Layer 'fc7' weights[0]: 7.906084e-03 [9.458763e-08] 
Layer 'fc7' biases: 9.999886e-01 [9.758230e-08] 
Layer 'fc8' weights[0]: 2.724289e-03 [1.864439e-05] 
Layer 'fc8' biases: 4.416207e-03 [1.948323e-05] 
Train error last 800 batches: 0.655052
-------------------------------------------------------
Not saving because 0.544268 > 0.354449 (1.520: -10.81%)
======================================================= (2.415 sec)
2.261... logprob:  0.645205, 0.291667 (1.436 sec)
2.262... logprob:  0.675707, 0.325521 (1.423 sec)
2.263... logprob:  0.715002, 0.290365 (1.436 sec)
2.264... logprob:  0.622362, 0.248698 (1.429 sec)
2.265... logprob:  0.659856, 0.277344 (1.408 sec)
2.266... logprob:  0.664793, 0.299479 (1.409 sec)
2.267... logprob:  0.614498, 0.261719 (1.411 sec)
2.268... logprob:  0.662905, 0.305990 (1.413 sec)
2.269... logprob:  0.698179, 0.289063 (1.403 sec)
2.270... logprob:  0.730932, 0.317708 (1.485 sec)
2.271... logprob:  0.669046, 0.278646 (1.432 sec)
2.272... logprob:  0.571903, 0.274740 (1.407 sec)
2.273... logprob:  0.683340, 0.289062 (1.462 sec)
2.274... logprob:  0.768954, 0.321615 (1.393 sec)
2.275... logprob:  0.732340, 0.313802 (1.419 sec)
2.276... logprob:  0.657003, 0.300781 (1.407 sec)
2.277... logprob:  0.666205, 0.289062 (1.423 sec)
2.278... logprob:  0.511009, 0.230469 (1.416 sec)
2.279... logprob:  0.634824, 0.273437 (1.456 sec)
2.280... logprob:  0.574253, 0.281250 (1.398 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.425885, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.563471e-03 [3.829144e-07] 
Layer 'conv1' biases: 2.792576e-07 [1.227897e-09] 
Layer 'conv2' weights[0]: 7.550853e-03 [3.809311e-07] 
Layer 'conv2' biases: 9.999998e-01 [6.844163e-09] 
Layer 'conv3' weights[0]: 7.549457e-03 [3.812686e-07] 
Layer 'conv3' biases: 6.738609e-06 [2.618287e-08] 
Layer 'conv4' weights[0]: 7.580025e-03 [3.869146e-07] 
Layer 'conv4' biases: 9.999998e-01 [2.850182e-07] 
Layer 'conv5' weights[0]: 7.583601e-03 [1.869625e-06] 
Layer 'conv5' biases: 9.997171e-01 [1.926974e-06] 
Layer 'fc6' weights[0]: 7.550840e-03 [5.624863e-08] 
Layer 'fc6' biases: 9.999998e-01 [4.459070e-08] 
Layer 'fc7' weights[0]: 7.905269e-03 [1.118255e-07] 
Layer 'fc7' biases: 9.999877e-01 [1.553564e-07] 
Layer 'fc8' weights[0]: 2.660189e-03 [2.478486e-05] 
Layer 'fc8' biases: 4.107628e-03 [4.501535e-05] 
Train error last 800 batches: 0.655561
-------------------------------------------------------
Not saving because 0.425885 > 0.354449 (1.520: -10.81%)
======================================================= (2.393 sec)
2.281... logprob:  0.626869, 0.285156 (1.429 sec)
2.282... logprob:  0.653807, 0.298177 (1.413 sec)
2.283... logprob:  0.658750, 0.277344 (1.415 sec)
2.284... logprob:  0.635639, 0.253906 (1.414 sec)
2.285... logprob:  0.570226, 0.229167 (1.431 sec)
2.286... logprob:  0.706930, 0.296875 (1.430 sec)
2.287... logprob:  0.550015, 0.251302 (1.427 sec)
2.288... logprob:  0.584457, 0.263021 (1.425 sec)
2.289... logprob:  0.715333, 0.303385 (1.439 sec)
2.290... logprob:  0.733145, 0.322917 (1.412 sec)
2.291... logprob:  0.681946, 0.282552 (1.409 sec)
2.292... logprob:  0.724829, 0.303385 (1.408 sec)
2.293... logprob:  0.685040, 0.276042 (1.415 sec)
2.294... logprob:  0.674418, 0.292969 (1.399 sec)
2.295... logprob:  0.539121, 0.234375 (1.457 sec)
2.296... logprob:  0.589836, 0.236979 (1.415 sec)
2.297... logprob:  0.684970, 0.278646 (1.412 sec)
2.298... logprob:  0.649523, 0.287760 (1.460 sec)
2.299... logprob:  0.573341, 0.239583 (1.394 sec)
2.300... logprob:  0.625267, 0.272135 (1.417 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.382030, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.555894e-03 [3.879085e-07] 
Layer 'conv1' biases: 2.845381e-07 [1.587393e-09] 
Layer 'conv2' weights[0]: 7.543255e-03 [3.816939e-07] 
Layer 'conv2' biases: 9.999999e-01 [8.426236e-09] 
Layer 'conv3' weights[0]: 7.541925e-03 [3.823102e-07] 
Layer 'conv3' biases: 6.768387e-06 [3.174087e-08] 
Layer 'conv4' weights[0]: 7.572449e-03 [3.860353e-07] 
Layer 'conv4' biases: 9.999996e-01 [2.918403e-07] 
Layer 'conv5' weights[0]: 7.576032e-03 [1.914891e-06] 
Layer 'conv5' biases: 9.997176e-01 [1.971013e-06] 
Layer 'fc6' weights[0]: 7.550092e-03 [5.437703e-08] 
Layer 'fc6' biases: 9.999998e-01 [4.222537e-08] 
Layer 'fc7' weights[0]: 7.904506e-03 [1.051559e-07] 
Layer 'fc7' biases: 9.999874e-01 [1.276398e-07] 
Layer 'fc8' weights[0]: 2.675230e-03 [2.649050e-05] 
Layer 'fc8' biases: 4.132574e-03 [5.029775e-05] 
Train error last 800 batches: 0.655720
-------------------------------------------------------
Not saving because 0.382030 > 0.354449 (1.520: -10.81%)
======================================================= (2.381 sec)
2.301... logprob:  0.577346, 0.263021 (1.419 sec)
2.302... logprob:  0.741871, 0.328125 (1.411 sec)
2.303... logprob:  0.617630, 0.268229 (1.400 sec)
2.304... logprob:  0.734018, 0.303385 (1.432 sec)
2.305... logprob:  0.767442, 0.341146 (1.431 sec)
2.306... logprob:  0.735216, 0.296875 (1.429 sec)
2.307... logprob:  0.673855, 0.322917 (1.434 sec)
2.308... logprob:  0.597981, 0.244792 (1.449 sec)
2.309... logprob:  0.691762, 0.304687 (1.432 sec)
2.310... logprob:  0.702710, 0.304687 (1.424 sec)
2.311... logprob:  0.753622, 0.337240 (1.422 sec)
2.312... logprob:  0.645315, 0.296875 (1.420 sec)
2.313... logprob:  0.694212, 0.307292 (1.411 sec)
2.314... logprob:  0.674023, 0.272135 (1.464 sec)
2.315... logprob:  0.543347, 0.252604 (1.429 sec)
2.316... logprob:  0.657716, 0.294271 (1.422 sec)
2.317... logprob:  0.535899, 0.231771 (1.464 sec)
2.318... logprob:  0.717824, 0.326823 (1.410 sec)
2.319... logprob:  0.579961, 0.266927 (1.417 sec)
2.320... logprob:  0.579863, 0.257812 (1.430 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.500497, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.548365e-03 [3.849182e-07] 
Layer 'conv1' biases: 2.937571e-07 [1.390352e-09] 
Layer 'conv2' weights[0]: 7.535733e-03 [3.820537e-07] 
Layer 'conv2' biases: 9.999999e-01 [9.683336e-09] 
Layer 'conv3' weights[0]: 7.534417e-03 [3.826750e-07] 
Layer 'conv3' biases: 6.860800e-06 [3.558881e-08] 
Layer 'conv4' weights[0]: 7.564864e-03 [3.921498e-07] 
Layer 'conv4' biases: 9.999995e-01 [4.407509e-07] 
Layer 'conv5' weights[0]: 7.568493e-03 [2.616351e-06] 
Layer 'conv5' biases: 9.997154e-01 [2.814873e-06] 
Layer 'fc6' weights[0]: 7.549277e-03 [6.569715e-08] 
Layer 'fc6' biases: 9.999998e-01 [5.771451e-08] 
Layer 'fc7' weights[0]: 7.903770e-03 [1.374254e-07] 
Layer 'fc7' biases: 9.999877e-01 [2.261211e-07] 
Layer 'fc8' weights[0]: 2.743252e-03 [3.354523e-05] 
Layer 'fc8' biases: 4.350830e-03 [6.103471e-05] 
Train error last 800 batches: 0.655899
-------------------------------------------------------
Not saving because 0.500497 > 0.354449 (1.520: -10.81%)
======================================================= (2.343 sec)
2.321... logprob:  0.572572, 0.264323 (1.435 sec)
2.322... logprob:  0.613159, 0.266927 (1.406 sec)
2.323... logprob:  0.659520, 0.268229 (1.473 sec)
2.324... logprob:  0.746006, 0.325521 (1.419 sec)
2.325... logprob:  0.611235, 0.276042 (1.431 sec)
2.326... logprob:  0.748398, 0.308594 (1.453 sec)
2.327... logprob:  0.778889, 0.320312 (1.419 sec)
2.328... logprob:  0.852479, 0.339844 (1.441 sec)
2.329... logprob:  0.538175, 0.235677 (1.424 sec)
2.330... logprob:  0.623890, 0.294271 (1.409 sec)
2.331... logprob:  0.612348, 0.286458 (1.412 sec)
2.332... logprob:  0.716645, 0.298177 (1.439 sec)
2.333... logprob:  0.663604, 0.307292 (1.433 sec)
2.334... logprob:  0.741436, 0.322917 (1.435 sec)
2.335... logprob:  0.581456, 0.263021 (1.431 sec)
2.336... logprob:  0.723868, 0.313802 (1.445 sec)
2.337... logprob:  0.732205, 0.319010 (1.406 sec)
2.338... logprob:  0.747249, 0.304688 (1.422 sec)
2.339... logprob:  0.708052, 0.315104 (1.412 sec)
2.340... logprob:  0.610938, 0.246094 (1.422 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.491413, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.540811e-03 [3.875430e-07] 
Layer 'conv1' biases: 2.918070e-07 [1.696631e-09] 
Layer 'conv2' weights[0]: 7.528209e-03 [3.804330e-07] 
Layer 'conv2' biases: 9.999999e-01 [9.022668e-09] 
Layer 'conv3' weights[0]: 7.526846e-03 [3.806011e-07] 
Layer 'conv3' biases: 6.942605e-06 [3.307045e-08] 
Layer 'conv4' weights[0]: 7.557302e-03 [3.881409e-07] 
Layer 'conv4' biases: 1.000000e+00 [3.747587e-07] 
Layer 'conv5' weights[0]: 7.561196e-03 [2.326039e-06] 
Layer 'conv5' biases: 9.997116e-01 [2.403319e-06] 
Layer 'fc6' weights[0]: 7.548467e-03 [6.109069e-08] 
Layer 'fc6' biases: 9.999998e-01 [5.142621e-08] 
Layer 'fc7' weights[0]: 7.902980e-03 [1.241129e-07] 
Layer 'fc7' biases: 9.999869e-01 [1.740248e-07] 
Layer 'fc8' weights[0]: 2.690878e-03 [2.503789e-05] 
Layer 'fc8' biases: 4.006991e-03 [4.402855e-05] 
Train error last 800 batches: 0.656403
-------------------------------------------------------
Not saving because 0.491413 > 0.354449 (1.520: -10.81%)
======================================================= (2.356 sec)
2.341... logprob:  0.695903, 0.296875 (1.418 sec)
2.342... logprob:  0.686553, 0.303385 (1.461 sec)
2.343... logprob:  0.632078, 0.278646 (1.438 sec)
2.344... logprob:  0.667254, 0.308594 (1.476 sec)
2.345... logprob:  0.656834, 0.268229 (1.432 sec)
2.346... logprob:  0.718439, 0.307292 (1.432 sec)
2.347... logprob:  0.704180, 0.322917 (1.482 sec)
2.348... logprob:  0.587355, 0.246094 (1.434 sec)
2.349... logprob:  0.693890, 0.312500 (1.435 sec)
2.350... logprob:  0.665067, 0.263021 (1.433 sec)
2.351... logprob:  0.779529, 0.322917 (1.420 sec)
2.352... logprob:  0.653149, 0.261719 (1.422 sec)
2.353... logprob:  0.674494, 0.286458 (1.484 sec)
2.354... logprob:  0.935786, 0.386719 (1.422 sec)
2.355... logprob:  0.588113, 0.270833 (1.437 sec)
2.356... logprob:  0.691441, 0.308594 (1.474 sec)
2.357... logprob:  0.605382, 0.289062 (1.426 sec)
2.358... logprob:  0.609483, 0.264323 (1.458 sec)
2.359... logprob:  0.759623, 0.337240 (1.422 sec)
2.360... logprob:  0.660255, 0.295573 (1.423 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.444173, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.533277e-03 [3.817201e-07] 
Layer 'conv1' biases: 2.942324e-07 [1.482514e-09] 
Layer 'conv2' weights[0]: 7.520692e-03 [3.803884e-07] 
Layer 'conv2' biases: 9.999999e-01 [7.903084e-09] 
Layer 'conv3' weights[0]: 7.519358e-03 [3.795370e-07] 
Layer 'conv3' biases: 7.072232e-06 [2.541934e-08] 
Layer 'conv4' weights[0]: 7.549805e-03 [3.839384e-07] 
Layer 'conv4' biases: 1.000001e+00 [2.663251e-07] 
Layer 'conv5' weights[0]: 7.554007e-03 [1.677925e-06] 
Layer 'conv5' biases: 9.997090e-01 [1.763596e-06] 
Layer 'fc6' weights[0]: 7.547682e-03 [5.234118e-08] 
Layer 'fc6' biases: 9.999998e-01 [3.892070e-08] 
Layer 'fc7' weights[0]: 7.902176e-03 [1.003163e-07] 
Layer 'fc7' biases: 9.999866e-01 [1.035251e-07] 
Layer 'fc8' weights[0]: 2.694935e-03 [1.911791e-05] 
Layer 'fc8' biases: 4.048544e-03 [2.190755e-05] 
Train error last 800 batches: 0.656884
-------------------------------------------------------
Not saving because 0.444173 > 0.354449 (1.520: -10.81%)
======================================================= (2.379 sec)
2.361... logprob:  0.619620, 0.260417 (1.430 sec)
2.362... logprob:  0.722493, 0.337240 (1.471 sec)
2.363... logprob:  0.634264, 0.287760 (1.434 sec)
2.364... logprob:  0.627666, 0.305990 (1.453 sec)
2.365... logprob:  0.643983, 0.279948 (1.461 sec)
2.366... logprob:  0.729698, 0.321615 (1.440 sec)
2.367... logprob:  0.620735, 0.302083 (1.438 sec)
2.368... logprob:  0.820007, 0.345052 (1.429 sec)
2.369... logprob:  0.680561, 0.289062 (1.414 sec)
2.370... logprob:  0.552217, 0.234375 (1.434 sec)
2.371... logprob:  0.619498, 0.260417 (1.452 sec)
2.372... logprob:  0.680547, 0.274740 (1.444 sec)
2.373... logprob:  0.653112, 0.256510 (1.451 sec)
2.374... logprob:  0.707070, 0.303385 (1.445 sec)
2.375... logprob:  0.703716, 0.282552 (1.457 sec)
2.376... logprob:  0.684864, 0.308594 (1.433 sec)
2.377... logprob:  0.591395, 0.272135 (1.416 sec)
2.378... logprob:  0.683557, 0.282552 (1.424 sec)
2.379... logprob:  0.683756, 0.305990 (1.440 sec)
2.380... logprob:  0.800642, 0.345052 (1.433 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.437702, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.525762e-03 [3.814438e-07] 
Layer 'conv1' biases: 2.975930e-07 [1.628271e-09] 
Layer 'conv2' weights[0]: 7.513166e-03 [3.800661e-07] 
Layer 'conv2' biases: 9.999999e-01 [1.039985e-08] 
Layer 'conv3' weights[0]: 7.511812e-03 [3.821623e-07] 
Layer 'conv3' biases: 7.132584e-06 [3.759687e-08] 
Layer 'conv4' weights[0]: 7.542208e-03 [3.896801e-07] 
Layer 'conv4' biases: 1.000000e+00 [4.333965e-07] 
Layer 'conv5' weights[0]: 7.546367e-03 [2.538735e-06] 
Layer 'conv5' biases: 9.997064e-01 [2.645910e-06] 
Layer 'fc6' weights[0]: 7.546903e-03 [5.884539e-08] 
Layer 'fc6' biases: 9.999998e-01 [4.806834e-08] 
Layer 'fc7' weights[0]: 7.901402e-03 [1.171311e-07] 
Layer 'fc7' biases: 9.999868e-01 [1.531064e-07] 
Layer 'fc8' weights[0]: 2.764955e-03 [2.371232e-05] 
Layer 'fc8' biases: 4.267768e-03 [3.471476e-05] 
Train error last 800 batches: 0.657341
-------------------------------------------------------
Not saving because 0.437702 > 0.354449 (1.520: -10.81%)
======================================================= (2.409 sec)
2.381... logprob:  0.774498, 0.347656 (1.467 sec)
2.382... logprob:  0.773887, 0.333333 (1.448 sec)
2.383... logprob:  0.651066, 0.300781 (1.434 sec)
2.384... logprob:  0.775066, 0.321614 (1.475 sec)
2.385... logprob:  0.812010, 0.333333 (1.428 sec)
2.386... logprob:  0.732535, 0.325521 (1.428 sec)
2.387... logprob:  0.641287, 0.278646 (1.429 sec)
2.388... logprob:  0.763023, 0.350260 (1.430 sec)
2.389... logprob:  0.604505, 0.274740 (1.422 sec)
2.390... logprob:  0.585628, 0.256510 (1.465 sec)
2.391... logprob:  0.664093, 0.291667 (1.440 sec)
2.392... logprob:  0.625178, 0.298177 (1.422 sec)
2.393... logprob:  0.585049, 0.264323 (1.470 sec)
2.394... logprob:  0.633443, 0.277344 (1.426 sec)
2.395... logprob:  0.525449, 0.230469 (1.425 sec)
2.396... logprob:  0.526213, 0.231771 (1.451 sec)
2.397... logprob:  0.678583, 0.304687 (1.426 sec)
2.398... logprob:  0.688223, 0.282552 (1.429 sec)
2.399... logprob:  0.686389, 0.294271 (1.479 sec)
2.400... logprob:  0.766551, 0.346354 (1.437 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.370593, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.518249e-03 [3.846224e-07] 
Layer 'conv1' biases: 3.018241e-07 [1.652301e-09] 
Layer 'conv2' weights[0]: 7.505632e-03 [3.804169e-07] 
Layer 'conv2' biases: 9.999999e-01 [9.671329e-09] 
Layer 'conv3' weights[0]: 7.504363e-03 [3.807310e-07] 
Layer 'conv3' biases: 7.175874e-06 [3.381128e-08] 
Layer 'conv4' weights[0]: 7.534705e-03 [3.858323e-07] 
Layer 'conv4' biases: 1.000000e+00 [3.133981e-07] 
Layer 'conv5' weights[0]: 7.538965e-03 [1.848992e-06] 
Layer 'conv5' biases: 9.997022e-01 [1.897282e-06] 
Layer 'fc6' weights[0]: 7.546111e-03 [5.429643e-08] 
Layer 'fc6' biases: 9.999998e-01 [4.210755e-08] 
Layer 'fc7' weights[0]: 7.900658e-03 [1.051179e-07] 
Layer 'fc7' biases: 9.999864e-01 [1.179251e-07] 
Layer 'fc8' weights[0]: 2.795505e-03 [2.107047e-05] 
Layer 'fc8' biases: 4.339214e-03 [3.001092e-05] 
Train error last 800 batches: 0.657949
-------------------------------------------------------
Not saving because 0.370593 > 0.354449 (1.520: -10.81%)
======================================================= (2.383 sec)
2.401... logprob:  0.719673, 0.320312 (1.445 sec)
2.402... logprob:  0.625924, 0.256510 (1.477 sec)
2.403... logprob:  0.651894, 0.286458 (1.430 sec)
2.404... logprob:  0.675059, 0.286458 (1.429 sec)
2.405... logprob:  0.741590, 0.321615 (1.440 sec)
2.406... logprob:  0.671179, 0.290365 (1.419 sec)
2.407... logprob:  0.759697, 0.334635 (1.426 sec)
2.408... logprob:  0.557631, 0.240885 (1.478 sec)
2.409... logprob:  0.609492, 0.256510 (1.432 sec)
2.410... logprob:  0.662062, 0.299479 (1.443 sec)
2.411... logprob:  0.572873, 0.248698 (1.474 sec)
2.412... logprob:  0.659134, 0.298177 (1.430 sec)
2.413... logprob:  0.696056, 0.287760 (1.433 sec)
2.414... logprob:  0.622477, 0.278646 (1.425 sec)
2.415... logprob:  0.674110, 0.295573 (1.419 sec)
2.416... logprob:  0.664496, 0.266927 (1.432 sec)
2.417... logprob:  0.659804, 0.296875 (1.455 sec)
2.418... logprob:  0.558010, 0.236979 (1.446 sec)
2.419... logprob:  0.711679, 0.304687 (1.445 sec)
2.420... logprob:  0.664772, 0.303385 (1.453 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.556093, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.510703e-03 [3.833124e-07] 
Layer 'conv1' biases: 3.102074e-07 [1.339199e-09] 
Layer 'conv2' weights[0]: 7.498171e-03 [3.787501e-07] 
Layer 'conv2' biases: 9.999999e-01 [7.264123e-09] 
Layer 'conv3' weights[0]: 7.496743e-03 [3.785255e-07] 
Layer 'conv3' biases: 7.224495e-06 [2.642807e-08] 
Layer 'conv4' weights[0]: 7.527161e-03 [3.836167e-07] 
Layer 'conv4' biases: 1.000000e+00 [2.864246e-07] 
Layer 'conv5' weights[0]: 7.531510e-03 [1.986910e-06] 
Layer 'conv5' biases: 9.997013e-01 [2.175820e-06] 
Layer 'fc6' weights[0]: 7.545342e-03 [5.335137e-08] 
Layer 'fc6' biases: 9.999998e-01 [4.068469e-08] 
Layer 'fc7' weights[0]: 7.899882e-03 [1.012482e-07] 
Layer 'fc7' biases: 9.999857e-01 [1.092047e-07] 
Layer 'fc8' weights[0]: 2.787692e-03 [1.965323e-05] 
Layer 'fc8' biases: 4.285923e-03 [2.588204e-05] 
Train error last 800 batches: 0.657618
-------------------------------------------------------
Not saving because 0.556093 > 0.354449 (1.520: -10.81%)
======================================================= (2.387 sec)
2.421... logprob:  0.702778, 0.346354 (1.454 sec)
2.422... logprob:  0.660877, 0.272135 (1.435 sec)
2.423... logprob:  0.698663, 0.338542 (1.420 sec)
2.424... logprob:  0.654265, 0.307292 (1.448 sec)
2.425... logprob:  0.604946, 0.278646 (1.436 sec)
2.426... logprob:  0.661948, 0.272135 (1.441 sec)
2.427... logprob:  0.716587, 0.270833 (1.460 sec)
2.428... logprob:  0.726306, 0.319010 (1.442 sec)
2.429... logprob:  0.695990, 0.315104 (1.441 sec)
2.430... logprob:  0.544254, 0.250000 (1.468 sec)
2.431... logprob:  0.836409, 0.355469 (1.428 sec)
2.432... logprob:  0.628278, 0.266927 (1.419 sec)
2.433... logprob:  0.587482, 0.256510 (1.430 sec)
2.434... logprob:  0.774638, 0.347656 (1.453 sec)
2.435... logprob:  0.680100, 0.305990 (1.428 sec)
2.436... logprob:  0.593357, 0.222656 (1.471 sec)
2.437... logprob:  0.639249, 0.281250 (1.437 sec)
2.438... logprob:  0.829732, 0.325521 (1.426 sec)
2.439... logprob:  0.576734, 0.270833 (1.482 sec)
2.440... logprob:  0.617895, 0.274740 (1.428 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.468601, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.503176e-03 [3.869821e-07] 
Layer 'conv1' biases: 3.145172e-07 [1.547545e-09] 
Layer 'conv2' weights[0]: 7.490655e-03 [3.789707e-07] 
Layer 'conv2' biases: 9.999999e-01 [8.398348e-09] 
Layer 'conv3' weights[0]: 7.489330e-03 [3.793808e-07] 
Layer 'conv3' biases: 7.338602e-06 [3.062968e-08] 
Layer 'conv4' weights[0]: 7.519610e-03 [3.842661e-07] 
Layer 'conv4' biases: 1.000000e+00 [3.205778e-07] 
Layer 'conv5' weights[0]: 7.524135e-03 [2.009855e-06] 
Layer 'conv5' biases: 9.996948e-01 [2.127031e-06] 
Layer 'fc6' weights[0]: 7.544577e-03 [5.240649e-08] 
Layer 'fc6' biases: 9.999998e-01 [3.924562e-08] 
Layer 'fc7' weights[0]: 7.899152e-03 [9.838021e-08] 
Layer 'fc7' biases: 9.999849e-01 [9.604073e-08] 
Layer 'fc8' weights[0]: 2.758048e-03 [1.720500e-05] 
Layer 'fc8' biases: 4.099899e-03 [1.112833e-05] 
Train error last 800 batches: 0.657817
-------------------------------------------------------
Not saving because 0.468601 > 0.354449 (1.520: -10.81%)
======================================================= (2.415 sec)
2.441... logprob:  0.656101, 0.289062 (1.430 sec)
2.442... logprob:  0.627139, 0.257812 (1.437 sec)
2.443... logprob:  0.684582, 0.295573 (1.446 sec)
2.444... logprob:  0.657067, 0.282552 (1.437 sec)
2.445... logprob:  0.641024, 0.263021 (1.480 sec)
2.446... logprob:  0.581472, 0.242187 (1.430 sec)
2.447... logprob:  0.729931, 0.342448 (1.430 sec)
2.448... logprob:  0.619110, 0.274740 (1.477 sec)
2.449... logprob:  0.678145, 0.266927 (1.424 sec)
2.450... logprob:  0.605814, 0.294271 (1.427 sec)
2.451... logprob:  0.721816, 0.320312 (1.433 sec)
2.452... logprob:  0.782814, 0.352865 (1.421 sec)
2.453... logprob:  0.617615, 0.278646 (1.427 sec)
2.454... logprob:  0.713431, 0.311198 (1.481 sec)
2.455... logprob:  0.716583, 0.282552 (1.427 sec)
2.456... logprob:  0.663664, 0.302083 (1.444 sec)
2.457... logprob:  0.601953, 0.272135 (1.466 sec)
2.458... logprob:  0.624852, 0.303385 (1.432 sec)
2.459... logprob:  0.718859, 0.313802 (1.429 sec)
2.460... logprob:  0.564057, 0.256510 (1.430 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.399921, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.495707e-03 [3.824297e-07] 
Layer 'conv1' biases: 3.183139e-07 [1.313009e-09] 
Layer 'conv2' weights[0]: 7.483217e-03 [3.785326e-07] 
Layer 'conv2' biases: 9.999999e-01 [7.893938e-09] 
Layer 'conv3' weights[0]: 7.481820e-03 [3.783992e-07] 
Layer 'conv3' biases: 7.429602e-06 [2.668871e-08] 
Layer 'conv4' weights[0]: 7.512101e-03 [3.829822e-07] 
Layer 'conv4' biases: 9.999994e-01 [2.679531e-07] 
Layer 'conv5' weights[0]: 7.516498e-03 [1.753826e-06] 
Layer 'conv5' biases: 9.996943e-01 [1.811726e-06] 
Layer 'fc6' weights[0]: 7.543803e-03 [5.230068e-08] 
Layer 'fc6' biases: 9.999998e-01 [3.938171e-08] 
Layer 'fc7' weights[0]: 7.898386e-03 [9.909689e-08] 
Layer 'fc7' biases: 9.999849e-01 [1.071899e-07] 
Layer 'fc8' weights[0]: 2.794777e-03 [1.994732e-05] 
Layer 'fc8' biases: 4.206097e-03 [2.053106e-05] 
Train error last 800 batches: 0.657982
-------------------------------------------------------
Not saving because 0.399921 > 0.354449 (1.520: -10.81%)
======================================================= (2.377 sec)
2.461... logprob:  0.713666, 0.308594 (1.425 sec)
2.462... logprob:  0.690951, 0.283854 (1.453 sec)
2.463... logprob:  0.701789, 0.286458 (1.474 sec)
2.464... logprob:  0.670250, 0.282552 (1.440 sec)
2.465... logprob:  0.638932, 0.294271 (1.449 sec)
2.466... logprob:  0.573014, 0.274740 (1.451 sec)
2.467... logprob:  0.615868, 0.256510 (1.445 sec)
2.468... logprob:  0.602904, 0.259115 (1.431 sec)
2.469... logprob:  0.659646, 0.285156 (1.424 sec)
2.470... logprob:  0.603176, 0.268229 (1.421 sec)
2.471... logprob:  0.715861, 0.320312 (1.433 sec)
2.472... logprob:  0.694781, 0.328125 (1.469 sec)
2.473... logprob:  0.620723, 0.264323 (1.457 sec)
2.474... logprob:  0.708415, 0.315104 (1.440 sec)
2.475... logprob:  0.766460, 0.345052 (1.436 sec)
2.476... logprob:  0.669431, 0.303385 (1.464 sec)
2.477... logprob:  0.558840, 0.253906 (1.429 sec)
2.478... logprob:  0.735955, 0.307292 (1.418 sec)
2.479... logprob:  0.609675, 0.278646 (1.426 sec)
2.480... logprob:  0.635120, 0.298177 (1.433 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.437177, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.488196e-03 [3.825465e-07] 
Layer 'conv1' biases: 3.249874e-07 [1.160994e-09] 
Layer 'conv2' weights[0]: 7.475705e-03 [3.781378e-07] 
Layer 'conv2' biases: 9.999999e-01 [7.224199e-09] 
Layer 'conv3' weights[0]: 7.474329e-03 [3.783178e-07] 
Layer 'conv3' biases: 7.527338e-06 [2.952203e-08] 
Layer 'conv4' weights[0]: 7.504575e-03 [3.814478e-07] 
Layer 'conv4' biases: 9.999992e-01 [2.616491e-07] 
Layer 'conv5' weights[0]: 7.508794e-03 [1.717123e-06] 
Layer 'conv5' biases: 9.996954e-01 [1.834140e-06] 
Layer 'fc6' weights[0]: 7.542961e-03 [5.131652e-08] 
Layer 'fc6' biases: 9.999998e-01 [3.769254e-08] 
Layer 'fc7' weights[0]: 7.897628e-03 [9.838543e-08] 
Layer 'fc7' biases: 9.999850e-01 [9.911285e-08] 
Layer 'fc8' weights[0]: 2.836687e-03 [1.831685e-05] 
Layer 'fc8' biases: 4.352429e-03 [2.215695e-05] 
Train error last 800 batches: 0.657973
-------------------------------------------------------
Not saving because 0.437177 > 0.354449 (1.520: -10.81%)
======================================================= (2.387 sec)
2.481... logprob:  0.649914, 0.295573 (1.459 sec)
2.482... logprob:  0.709239, 0.313802 (1.478 sec)
2.483... logprob:  0.748854, 0.291667 (1.441 sec)
2.484... logprob:  0.626817, 0.270833 (1.431 sec)
2.485... logprob:  0.675134, 0.294271 (1.474 sec)
2.486... logprob:  0.587808, 0.278646 (1.430 sec)
2.487... logprob:  0.707820, 0.269531 (1.419 sec)
2.488... logprob:  0.616588, 0.243490 (1.425 sec)
2.489... logprob:  0.602169, 0.246094 (1.425 sec)
2.490... logprob:  0.677439, 0.292969 (1.423 sec)
2.491... logprob:  0.588635, 0.239583 (1.477 sec)
2.492... logprob:  0.612569, 0.290365 (1.435 sec)
2.493... logprob:  0.794540, 0.309896 (1.431 sec)
2.494... logprob:  0.679937, 0.302083 (1.480 sec)
2.495... logprob:  0.624830, 0.272135 (1.424 sec)
2.496... logprob:  0.767416, 0.302083 (1.423 sec)
2.497... logprob:  0.741764, 0.322917 (1.431 sec)
2.498... logprob:  0.619163, 0.252604 (1.422 sec)
2.499... logprob:  0.667919, 0.295573 (1.429 sec)
2.500... logprob:  0.542739, 0.251302 (1.478 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.490765, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.480714e-03 [3.797561e-07] 
Layer 'conv1' biases: 3.262702e-07 [1.322222e-09] 
Layer 'conv2' weights[0]: 7.468264e-03 [3.778314e-07] 
Layer 'conv2' biases: 9.999999e-01 [7.803439e-09] 
Layer 'conv3' weights[0]: 7.466789e-03 [3.771479e-07] 
Layer 'conv3' biases: 7.635297e-06 [2.728643e-08] 
Layer 'conv4' weights[0]: 7.497082e-03 [3.807337e-07] 
Layer 'conv4' biases: 9.999990e-01 [2.513688e-07] 
Layer 'conv5' weights[0]: 7.501559e-03 [1.614294e-06] 
Layer 'conv5' biases: 9.996916e-01 [1.619015e-06] 
Layer 'fc6' weights[0]: 7.542192e-03 [5.262051e-08] 
Layer 'fc6' biases: 9.999998e-01 [3.961401e-08] 
Layer 'fc7' weights[0]: 7.896805e-03 [9.983743e-08] 
Layer 'fc7' biases: 9.999842e-01 [1.003396e-07] 
Layer 'fc8' weights[0]: 2.775658e-03 [1.687906e-05] 
Layer 'fc8' biases: 3.984456e-03 [5.525736e-06] 
Train error last 800 batches: 0.657636
-------------------------------------------------------
Not saving because 0.490765 > 0.354449 (1.520: -10.81%)
======================================================= (2.375 sec)
2.501... logprob:  0.645035, 0.290365 (1.438 sec)
2.502... logprob:  0.680142, 0.307292 (1.442 sec)
2.503... logprob:  0.560338, 0.233073 (1.474 sec)
2.504... logprob:  0.653662, 0.295573 (1.426 sec)
2.505... logprob:  0.746656, 0.273438 (1.435 sec)
2.506... logprob:  0.739500, 0.350260 (1.425 sec)
2.507... logprob:  0.647060, 0.291667 (1.419 sec)
2.508... logprob:  0.652324, 0.287760 (1.431 sec)
2.509... logprob:  0.561612, 0.250000 (1.477 sec)
2.510... logprob:  0.591212, 0.257812 (1.449 sec)
2.511... logprob:  0.720425, 0.292969 (1.450 sec)
2.512... logprob:  0.730440, 0.294271 (1.456 sec)
2.513... logprob:  0.673461, 0.289062 (1.436 sec)
2.514... logprob:  0.703088, 0.315104 (1.435 sec)
2.515... logprob:  0.613947, 0.282552 (1.420 sec)
2.516... logprob:  0.659026, 0.305989 (1.422 sec)
2.517... logprob:  0.887134, 0.343750 (1.429 sec)
2.518... logprob:  0.592754, 0.247396 (1.454 sec)
2.519... logprob:  0.681373, 0.281250 (1.446 sec)
2.520... logprob:  0.630396, 0.276042 (1.451 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.508397, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.473228e-03 [3.855291e-07] 
Layer 'conv1' biases: 3.242224e-07 [1.761632e-09] 
Layer 'conv2' weights[0]: 7.460746e-03 [3.784806e-07] 
Layer 'conv2' biases: 9.999999e-01 [9.753781e-09] 
Layer 'conv3' weights[0]: 7.459340e-03 [3.798378e-07] 
Layer 'conv3' biases: 7.666769e-06 [3.760458e-08] 
Layer 'conv4' weights[0]: 7.489612e-03 [3.862290e-07] 
Layer 'conv4' biases: 9.999987e-01 [3.776766e-07] 
Layer 'conv5' weights[0]: 7.493985e-03 [2.111395e-06] 
Layer 'conv5' biases: 9.996908e-01 [2.233441e-06] 
Layer 'fc6' weights[0]: 7.541369e-03 [5.795303e-08] 
Layer 'fc6' biases: 9.999997e-01 [4.743264e-08] 
Layer 'fc7' weights[0]: 7.896043e-03 [1.145591e-07] 
Layer 'fc7' biases: 9.999844e-01 [1.385121e-07] 
Layer 'fc8' weights[0]: 2.838350e-03 [2.481657e-05] 
Layer 'fc8' biases: 4.220032e-03 [4.335491e-05] 
Train error last 800 batches: 0.657867
-------------------------------------------------------
Not saving because 0.508397 > 0.354449 (1.520: -10.81%)
======================================================= (2.390 sec)
2.521... logprob:  0.664450, 0.279948 (1.466 sec)
2.522... logprob:  0.732089, 0.333333 (1.464 sec)
2.523... logprob:  0.568301, 0.251302 (1.429 sec)
2.524... logprob:  0.649161, 0.264323 (1.419 sec)
2.525... logprob:  0.633939, 0.264323 (1.424 sec)
2.526... logprob:  0.574236, 0.270833 (1.431 sec)
2.527... logprob:  0.733185, 0.337240 (1.435 sec)
2.528... logprob:  0.625416, 0.257812 (1.461 sec)
2.529... logprob:  0.613175, 0.276042 (1.442 sec)
2.530... logprob:  0.611566, 0.248698 (1.436 sec)
2.531... logprob:  0.753876, 0.311198 (1.474 sec)
2.532... logprob:  0.731666, 0.295573 (1.429 sec)
2.533... logprob:  0.750447, 0.335937 (1.420 sec)
2.534... logprob:  0.641653, 0.281250 (1.427 sec)
2.535... logprob:  0.822792, 0.342448 (1.431 sec)
2.536... logprob:  0.764049, 0.296875 (1.423 sec)
2.537... logprob:  0.754738, 0.298177 (1.471 sec)
2.538... logprob:  0.734304, 0.325521 (1.439 sec)
2.539... logprob:  0.593206, 0.260417 (1.425 sec)
2.540... logprob:  0.697754, 0.319010 (1.505 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.533177, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.465786e-03 [3.798274e-07] 
Layer 'conv1' biases: 3.324503e-07 [1.836609e-09] 
Layer 'conv2' weights[0]: 7.453294e-03 [3.779381e-07] 
Layer 'conv2' biases: 9.999999e-01 [9.353252e-09] 
Layer 'conv3' weights[0]: 7.451920e-03 [3.786543e-07] 
Layer 'conv3' biases: 7.838228e-06 [3.502996e-08] 
Layer 'conv4' weights[0]: 7.482095e-03 [3.842990e-07] 
Layer 'conv4' biases: 1.000000e+00 [3.289204e-07] 
Layer 'conv5' weights[0]: 7.487128e-03 [2.007933e-06] 
Layer 'conv5' biases: 9.996814e-01 [2.072253e-06] 
Layer 'fc6' weights[0]: 7.540571e-03 [5.640870e-08] 
Layer 'fc6' biases: 9.999997e-01 [4.551075e-08] 
Layer 'fc7' weights[0]: 7.895295e-03 [1.121033e-07] 
Layer 'fc7' biases: 9.999837e-01 [1.343530e-07] 
Layer 'fc8' weights[0]: 2.804781e-03 [2.247079e-05] 
Layer 'fc8' biases: 4.033660e-03 [2.794108e-05] 
Train error last 800 batches: 0.658033
-------------------------------------------------------
Not saving because 0.533177 > 0.354449 (1.520: -10.81%)
======================================================= (2.376 sec)
2.541... logprob:  0.602716, 0.261719 (1.433 sec)
2.542... logprob:  0.650020, 0.281250 (1.432 sec)
2.543... logprob:  0.566736, 0.244792 (1.428 sec)
2.544... logprob:  0.609300, 0.281250 (1.423 sec)
2.545... logprob:  0.624497, 0.283854 (1.426 sec)
2.546... logprob:  0.670231, 0.287760 (1.477 sec)
2.547... logprob:  0.621574, 0.257812 (1.429 sec)
2.548... logprob:  0.617688, 0.281250 (1.436 sec)
2.549... logprob:  0.761887, 0.322917 (1.473 sec)
2.550... logprob:  0.521603, 0.233073 (1.428 sec)
2.551... logprob:  0.740864, 0.302083 (1.426 sec)
2.552... logprob:  0.573527, 0.252604 (1.429 sec)
2.553... logprob:  0.564503, 0.231771 (1.427 sec)
2.554... logprob:  0.716481, 0.319010 (1.431 sec)
2.555... logprob:  0.672587, 0.281250 (1.476 sec)
2.556... logprob:  0.625701, 0.304688 (1.432 sec)
2.557... logprob:  0.656964, 0.295573 (1.444 sec)
2.558... logprob:  0.768537, 0.372396 (1.463 sec)
2.559... logprob:  0.636952, 0.251302 (1.464 sec)
2.560... logprob:  0.582665, 0.236979 (1.441 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.510379, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.458275e-03 [3.792070e-07] 
Layer 'conv1' biases: 3.382452e-07 [1.321274e-09] 
Layer 'conv2' weights[0]: 7.445823e-03 [3.763779e-07] 
Layer 'conv2' biases: 9.999999e-01 [7.754906e-09] 
Layer 'conv3' weights[0]: 7.444461e-03 [3.764951e-07] 
Layer 'conv3' biases: 7.934146e-06 [2.891659e-08] 
Layer 'conv4' weights[0]: 7.474607e-03 [3.814549e-07] 
Layer 'conv4' biases: 9.999994e-01 [2.954679e-07] 
Layer 'conv5' weights[0]: 7.479647e-03 [1.824151e-06] 
Layer 'conv5' biases: 9.996763e-01 [1.921399e-06] 
Layer 'fc6' weights[0]: 7.539773e-03 [5.441654e-08] 
Layer 'fc6' biases: 9.999998e-01 [4.280099e-08] 
Layer 'fc7' weights[0]: 7.894509e-03 [1.059212e-07] 
Layer 'fc7' biases: 9.999843e-01 [1.165688e-07] 
Layer 'fc8' weights[0]: 2.915094e-03 [2.105593e-05] 
Layer 'fc8' biases: 4.513802e-03 [2.627508e-05] 
Train error last 800 batches: 0.658113
-------------------------------------------------------
Not saving because 0.510379 > 0.354449 (1.520: -10.81%)
======================================================= (2.409 sec)
2.561... logprob:  0.629556, 0.303385 (1.434 sec)
2.562... logprob:  0.692471, 0.321615 (1.417 sec)
2.563... logprob:  0.572784, 0.236979 (1.433 sec)
2.564... logprob:  0.704829, 0.329427 (1.458 sec)
2.565... logprob:  0.790428, 0.338542 (1.444 sec)
2.566... logprob:  0.617121, 0.279948 (1.446 sec)
2.567... logprob:  0.677212, 0.295573 (1.453 sec)
2.568... logprob:  0.660510, 0.309896 (1.445 sec)
2.569... logprob:  0.837149, 0.317708 (1.434 sec)
2.570... logprob:  0.846973, 0.337240 (1.417 sec)
2.571... logprob:  0.717298, 0.319010 (1.426 sec)
2.572... logprob:  0.801971, 0.351562 (1.432 sec)
2.573... logprob:  0.766847, 0.324219 (1.439 sec)
2.574... logprob:  0.618728, 0.274739 (1.458 sec)
2.575... logprob:  0.570255, 0.251302 (1.446 sec)
2.576... logprob:  0.698675, 0.317708 (1.439 sec)
2.577... logprob:  0.737507, 0.320312 (1.466 sec)
2.578... logprob:  0.597121, 0.260417 (1.452 sec)
2.579... logprob:  0.677955, 0.311198 (1.427 sec)
2.580... logprob:  0.668138, 0.281250 (1.432 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.476911, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.450848e-03 [3.827373e-07] 
Layer 'conv1' biases: 3.446748e-07 [1.301628e-09] 
Layer 'conv2' weights[0]: 7.438409e-03 [3.771563e-07] 
Layer 'conv2' biases: 9.999999e-01 [8.409597e-09] 
Layer 'conv3' weights[0]: 7.436965e-03 [3.774724e-07] 
Layer 'conv3' biases: 8.078366e-06 [3.144406e-08] 
Layer 'conv4' weights[0]: 7.467118e-03 [3.829277e-07] 
Layer 'conv4' biases: 1.000002e+00 [3.249435e-07] 
Layer 'conv5' weights[0]: 7.472706e-03 [2.250860e-06] 
Layer 'conv5' biases: 9.996651e-01 [2.368626e-06] 
Layer 'fc6' weights[0]: 7.538963e-03 [5.795905e-08] 
Layer 'fc6' biases: 9.999997e-01 [4.801984e-08] 
Layer 'fc7' weights[0]: 7.893734e-03 [1.169926e-07] 
Layer 'fc7' biases: 9.999831e-01 [1.539558e-07] 
Layer 'fc8' weights[0]: 2.838252e-03 [2.534530e-05] 
Layer 'fc8' biases: 4.081715e-03 [4.784152e-05] 
Train error last 800 batches: 0.658764
-------------------------------------------------------
Not saving because 0.476911 > 0.354449 (1.520: -10.81%)
======================================================= (2.382 sec)
2.581... logprob:  0.759281, 0.329427 (1.441 sec)
2.582... logprob:  0.674545, 0.305989 (1.428 sec)
2.583... logprob:  0.731396, 0.302083 (1.467 sec)
2.584... logprob:  0.704129, 0.298177 (1.442 sec)
2.585... logprob:  0.595365, 0.247396 (1.426 sec)
2.586... logprob:  0.605496, 0.287760 (1.476 sec)
2.587... logprob:  0.637016, 0.264323 (1.433 sec)
2.588... logprob:  0.630128, 0.279948 (1.419 sec)
2.589... logprob:  0.638932, 0.269531 (1.432 sec)
2.590... logprob:  0.655938, 0.291667 (1.429 sec)
2.591... logprob:  0.649982, 0.278646 (1.422 sec)
2.592... logprob:  0.637162, 0.282552 (1.476 sec)
2.593... logprob:  0.705392, 0.299479 (1.434 sec)
2.594... logprob:  0.641259, 0.300781 (1.432 sec)
2.595... logprob:  0.692180, 0.305990 (1.484 sec)
2.596... logprob:  0.641531, 0.291667 (1.429 sec)
2.597... logprob:  0.577640, 0.264323 (1.451 sec)
2.598... logprob:  0.695506, 0.303385 (1.441 sec)
2.599... logprob:  0.607729, 0.278646 (1.418 sec)
2.600... logprob:  0.590858, 0.261719 (1.429 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.412101, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.443374e-03 [3.823165e-07] 
Layer 'conv1' biases: 3.449045e-07 [1.550548e-09] 
Layer 'conv2' weights[0]: 7.430997e-03 [3.765196e-07] 
Layer 'conv2' biases: 9.999999e-01 [9.133865e-09] 
Layer 'conv3' weights[0]: 7.429585e-03 [3.765629e-07] 
Layer 'conv3' biases: 8.150499e-06 [3.336147e-08] 
Layer 'conv4' weights[0]: 7.459658e-03 [3.818362e-07] 
Layer 'conv4' biases: 1.000000e+00 [3.298002e-07] 
Layer 'conv5' weights[0]: 7.465120e-03 [2.193481e-06] 
Layer 'conv5' biases: 9.996612e-01 [2.311729e-06] 
Layer 'fc6' weights[0]: 7.538202e-03 [5.495890e-08] 
Layer 'fc6' biases: 9.999997e-01 [4.366872e-08] 
Layer 'fc7' weights[0]: 7.892959e-03 [1.093762e-07] 
Layer 'fc7' biases: 9.999834e-01 [1.363462e-07] 
Layer 'fc8' weights[0]: 2.930851e-03 [2.309591e-05] 
Layer 'fc8' biases: 4.593384e-03 [4.305335e-05] 
Train error last 800 batches: 0.659477
-------------------------------------------------------
Not saving because 0.412101 > 0.354449 (1.520: -10.81%)
======================================================= (2.394 sec)
2.601... logprob:  0.672821, 0.309896 (1.487 sec)
2.602... logprob:  0.578551, 0.281250 (1.429 sec)
2.603... logprob:  0.436370, 0.196615 (1.435 sec)
2.604... logprob:  0.558947, 0.238281 (1.468 sec)
2.605... logprob:  0.744788, 0.315104 (1.431 sec)
2.606... logprob:  0.620499, 0.268229 (1.433 sec)
2.607... logprob:  0.743533, 0.294271 (1.423 sec)
2.608... logprob:  0.651006, 0.266927 (1.418 sec)
2.609... logprob:  0.567286, 0.270833 (1.434 sec)
2.610... logprob:  0.695451, 0.261719 (1.461 sec)
2.611... logprob:  0.652266, 0.295573 (1.439 sec)
2.612... logprob:  0.634089, 0.302083 (1.453 sec)
2.613... logprob:  0.553703, 0.244792 (1.459 sec)
2.614... logprob:  0.736837, 0.319010 (1.453 sec)
2.615... logprob:  0.652399, 0.309896 (1.430 sec)
2.616... logprob:  0.680450, 0.285156 (1.450 sec)
2.617... logprob:  0.601231, 0.273437 (1.426 sec)
2.618... logprob:  0.904721, 0.371094 (1.432 sec)
2.619... logprob:  0.671557, 0.248698 (1.445 sec)
2.620... logprob:  0.730428, 0.289062 (1.445 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.556837, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.435940e-03 [3.845807e-07] 
Layer 'conv1' biases: 3.522923e-07 [1.968828e-09] 
Layer 'conv2' weights[0]: 7.423521e-03 [3.811751e-07] 
Layer 'conv2' biases: 9.999999e-01 [1.439008e-08] 
Layer 'conv3' weights[0]: 7.422184e-03 [3.837615e-07] 
Layer 'conv3' biases: 8.287615e-06 [5.295254e-08] 
Layer 'conv4' weights[0]: 7.452216e-03 [3.999884e-07] 
Layer 'conv4' biases: 1.000002e+00 [6.218151e-07] 
Layer 'conv5' weights[0]: 7.458308e-03 [3.703800e-06] 
Layer 'conv5' biases: 9.996528e-01 [3.924674e-06] 
Layer 'fc6' weights[0]: 7.537447e-03 [8.169628e-08] 
Layer 'fc6' biases: 9.999997e-01 [8.008128e-08] 
Layer 'fc7' weights[0]: 7.892195e-03 [1.853342e-07] 
Layer 'fc7' biases: 9.999822e-01 [3.273029e-07] 
Layer 'fc8' weights[0]: 2.876402e-03 [4.078363e-05] 
Layer 'fc8' biases: 4.330880e-03 [8.068638e-05] 
Train error last 800 batches: 0.659922
-------------------------------------------------------
Not saving because 0.556837 > 0.354449 (1.520: -10.81%)
======================================================= (2.356 sec)
2.621... logprob:  0.586782, 0.266927 (1.455 sec)
2.622... logprob:  0.591657, 0.266927 (1.443 sec)
2.623... logprob:  0.641017, 0.272135 (1.459 sec)
2.624... logprob:  0.602862, 0.259115 (1.431 sec)
2.625... logprob:  0.705066, 0.320313 (1.415 sec)
2.626... logprob:  0.681672, 0.277344 (1.426 sec)
2.627... logprob:  0.619624, 0.225260 (1.431 sec)
2.628... logprob:  0.665266, 0.255208 (1.432 sec)
2.629... logprob:  0.615181, 0.281250 (1.476 sec)
2.630... logprob:  0.688451, 0.274740 (1.441 sec)
2.631... logprob:  0.802809, 0.347656 (1.431 sec)
2.632... logprob:  0.677094, 0.283854 (1.473 sec)
2.633... logprob:  0.603174, 0.238281 (1.430 sec)
2.634... logprob:  0.900925, 0.350260 (1.419 sec)
2.635... logprob:  0.641116, 0.290364 (1.432 sec)
2.636... logprob:  0.693137, 0.326823 (1.435 sec)
2.637... logprob:  0.598166, 0.269531 (1.423 sec)
2.638... logprob:  0.710293, 0.309896 (1.471 sec)
2.639... logprob:  0.667971, 0.320312 (1.432 sec)
2.640... logprob:  0.649238, 0.277344 (1.431 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.416736, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.428527e-03 [3.793670e-07] 
Layer 'conv1' biases: 3.561588e-07 [9.727659e-10] 
Layer 'conv2' weights[0]: 7.416077e-03 [3.752702e-07] 
Layer 'conv2' biases: 9.999998e-01 [8.057603e-09] 
Layer 'conv3' weights[0]: 7.414758e-03 [3.756795e-07] 
Layer 'conv3' biases: 8.436021e-06 [3.159108e-08] 
Layer 'conv4' weights[0]: 7.444715e-03 [3.799904e-07] 
Layer 'conv4' biases: 1.000004e+00 [3.215577e-07] 
Layer 'conv5' weights[0]: 7.451642e-03 [2.000236e-06] 
Layer 'conv5' biases: 9.996424e-01 [2.106901e-06] 
Layer 'fc6' weights[0]: 7.536663e-03 [5.448272e-08] 
Layer 'fc6' biases: 9.999997e-01 [4.327342e-08] 
Layer 'fc7' weights[0]: 7.891415e-03 [1.056467e-07] 
Layer 'fc7' biases: 9.999816e-01 [1.184542e-07] 
Layer 'fc8' weights[0]: 2.834266e-03 [1.917213e-05] 
Layer 'fc8' biases: 4.066550e-03 [2.010482e-05] 
Train error last 800 batches: 0.659636
-------------------------------------------------------
Not saving because 0.416736 > 0.354449 (1.520: -10.81%)
======================================================= (2.398 sec)
2.641... logprob:  0.659627, 0.304687 (1.481 sec)
2.642... logprob:  0.688425, 0.316406 (1.430 sec)
2.643... logprob:  0.841106, 0.347656 (1.420 sec)
2.644... logprob:  0.564942, 0.261719 (1.427 sec)
2.645... logprob:  0.614384, 0.256510 (1.428 sec)
2.646... logprob:  0.675791, 0.286458 (1.425 sec)
2.647... logprob:  0.701807, 0.291667 (1.482 sec)
2.648... logprob:  0.561724, 0.255208 (1.426 sec)
2.649... logprob:  0.654327, 0.333333 (1.437 sec)
2.650... logprob:  0.711664, 0.298177 (1.471 sec)
2.651... logprob:  0.592488, 0.274739 (1.427 sec)
2.652... logprob:  0.721727, 0.295573 (1.433 sec)
2.653... logprob:  0.811229, 0.354167 (1.427 sec)
2.654... logprob:  0.708305, 0.286458 (1.421 sec)
2.655... logprob:  0.684914, 0.299479 (1.433 sec)
2.656... logprob:  0.677718, 0.309896 (1.470 sec)
2.657... logprob:  0.661309, 0.283854 (1.431 sec)
2.658... logprob:  0.565965, 0.244792 (1.445 sec)
2.659... logprob:  0.673380, 0.299479 (1.458 sec)
2.660... logprob:  0.735924, 0.341146 (1.437 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.533835, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.421101e-03 [3.783505e-07] 
Layer 'conv1' biases: 3.642591e-07 [1.295546e-09] 
Layer 'conv2' weights[0]: 7.408681e-03 [3.749133e-07] 
Layer 'conv2' biases: 9.999998e-01 [7.727907e-09] 
Layer 'conv3' weights[0]: 7.407367e-03 [3.747080e-07] 
Layer 'conv3' biases: 8.516978e-06 [2.916125e-08] 
Layer 'conv4' weights[0]: 7.437264e-03 [3.779637e-07] 
Layer 'conv4' biases: 1.000003e+00 [2.744420e-07] 
Layer 'conv5' weights[0]: 7.444066e-03 [1.795912e-06] 
Layer 'conv5' biases: 9.996414e-01 [1.838761e-06] 
Layer 'fc6' weights[0]: 7.535882e-03 [5.314853e-08] 
Layer 'fc6' biases: 9.999997e-01 [4.131194e-08] 
Layer 'fc7' weights[0]: 7.890666e-03 [1.019252e-07] 
Layer 'fc7' biases: 9.999818e-01 [1.031528e-07] 
Layer 'fc8' weights[0]: 2.897027e-03 [1.707810e-05] 
Layer 'fc8' biases: 4.294787e-03 [3.674363e-06] 
Train error last 800 batches: 0.660132
-------------------------------------------------------
Not saving because 0.533835 > 0.354449 (1.520: -10.81%)
======================================================= (2.387 sec)
2.661... logprob:  0.547434, 0.251302 (1.441 sec)
2.662... logprob:  0.564519, 0.234375 (1.435 sec)
2.663... logprob:  0.553787, 0.231771 (1.430 sec)
2.664... logprob:  0.440055, 0.204427 (1.432 sec)
2.665... logprob:  0.573547, 0.252604 (1.451 sec)
2.666... logprob:  0.638884, 0.282552 (1.451 sec)
2.667... logprob:  0.778394, 0.352865 (1.444 sec)
2.668... logprob:  0.692304, 0.299479 (1.447 sec)
2.669... logprob:  0.786489, 0.321615 (1.455 sec)
2.670... logprob:  0.615437, 0.286458 (1.434 sec)
2.671... logprob:  0.653352, 0.287760 (1.418 sec)
2.672... logprob:  0.530625, 0.229167 (1.425 sec)
2.673... logprob:  0.671277, 0.302083 (1.440 sec)
2.674... logprob:  0.543653, 0.251302 (1.443 sec)
2.675... logprob:  0.667429, 0.296875 (1.462 sec)
2.676... logprob:  0.659424, 0.307292 (1.445 sec)
2.677... logprob:  0.704887, 0.313802 (1.429 sec)
2.678... logprob:  0.672471, 0.302083 (1.476 sec)
2.679... logprob:  0.796567, 0.343750 (1.424 sec)
2.680... logprob:  0.598649, 0.266927 (1.417 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.373333, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.413649e-03 [3.795363e-07] 
Layer 'conv1' biases: 3.645763e-07 [1.333862e-09] 
Layer 'conv2' weights[0]: 7.401242e-03 [3.745322e-07] 
Layer 'conv2' biases: 9.999998e-01 [7.217919e-09] 
Layer 'conv3' weights[0]: 7.399874e-03 [3.743273e-07] 
Layer 'conv3' biases: 8.533504e-06 [2.987514e-08] 
Layer 'conv4' weights[0]: 7.429843e-03 [3.783423e-07] 
Layer 'conv4' biases: 1.000002e+00 [2.966794e-07] 
Layer 'conv5' weights[0]: 7.436775e-03 [1.942412e-06] 
Layer 'conv5' biases: 9.996414e-01 [2.012737e-06] 
Layer 'fc6' weights[0]: 7.535096e-03 [5.370041e-08] 
Layer 'fc6' biases: 9.999997e-01 [4.222034e-08] 
Layer 'fc7' weights[0]: 7.889900e-03 [1.021745e-07] 
Layer 'fc7' biases: 9.999823e-01 [1.089477e-07] 
Layer 'fc8' weights[0]: 2.969310e-03 [1.688076e-05] 
Layer 'fc8' biases: 4.612143e-03 [1.164377e-05] 
Train error last 800 batches: 0.660036
-------------------------------------------------------
Not saving because 0.373333 > 0.354449 (1.520: -10.81%)
======================================================= (2.373 sec)
2.681... logprob:  0.586256, 0.259115 (1.431 sec)
2.682... logprob:  0.504909, 0.222656 (1.428 sec)
2.683... logprob:  0.658488, 0.264323 (1.423 sec)
2.684... logprob:  0.647421, 0.304687 (1.470 sec)
2.685... logprob:  0.550343, 0.250000 (1.434 sec)
2.686... logprob:  0.666300, 0.295573 (1.424 sec)
2.687... logprob:  0.548924, 0.242187 (1.482 sec)
2.688... logprob:  0.594320, 0.277344 (1.426 sec)
2.689... logprob:  0.672512, 0.295573 (1.425 sec)
2.690... logprob:  0.714847, 0.308594 (1.433 sec)
2.691... logprob:  0.699597, 0.286458 (1.426 sec)
2.692... logprob:  0.595373, 0.260417 (1.422 sec)
2.693... logprob:  0.673375, 0.298177 (1.487 sec)
2.694... logprob:  0.580746, 0.242188 (1.439 sec)
2.695... logprob:  0.500943, 0.238281 (1.434 sec)
2.696... logprob:  0.684858, 0.273437 (1.469 sec)
2.697... logprob:  0.721866, 0.308594 (1.428 sec)
2.698... logprob:  0.705482, 0.304687 (1.430 sec)
2.699... logprob:  0.622457, 0.270833 (1.448 sec)
2.700... logprob:  0.689545, 0.299479 (1.432 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.403071, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.406238e-03 [3.781998e-07] 
Layer 'conv1' biases: 3.637717e-07 [1.445051e-09] 
Layer 'conv2' weights[0]: 7.393831e-03 [3.746548e-07] 
Layer 'conv2' biases: 9.999998e-01 [9.583780e-09] 
Layer 'conv3' weights[0]: 7.392533e-03 [3.759592e-07] 
Layer 'conv3' biases: 8.643731e-06 [3.938446e-08] 
Layer 'conv4' weights[0]: 7.422437e-03 [3.806346e-07] 
Layer 'conv4' biases: 1.000004e+00 [3.768356e-07] 
Layer 'conv5' weights[0]: 7.429620e-03 [2.220618e-06] 
Layer 'conv5' biases: 9.996392e-01 [2.269486e-06] 
Layer 'fc6' weights[0]: 7.534314e-03 [5.828279e-08] 
Layer 'fc6' biases: 9.999997e-01 [4.874592e-08] 
Layer 'fc7' weights[0]: 7.889110e-03 [1.172445e-07] 
Layer 'fc7' biases: 9.999818e-01 [1.539340e-07] 
Layer 'fc8' weights[0]: 2.959278e-03 [2.085626e-05] 
Layer 'fc8' biases: 4.566680e-03 [3.173855e-05] 
Train error last 800 batches: 0.659905
-------------------------------------------------------
Not saving because 0.403071 > 0.354449 (1.520: -10.81%)
======================================================= (2.367 sec)
2.701... logprob:  0.668571, 0.273437 (1.437 sec)
2.702... logprob:  0.683779, 0.313802 (1.486 sec)
2.703... logprob:  0.615205, 0.265625 (1.431 sec)
2.704... logprob:  0.655210, 0.272135 (1.453 sec)
2.705... logprob:  0.654240, 0.295573 (1.472 sec)
2.706... logprob:  0.770627, 0.341146 (1.436 sec)
2.707... logprob:  0.715371, 0.304687 (1.444 sec)
2.708... logprob:  0.672720, 0.291667 (1.432 sec)
2.709... logprob:  0.640469, 0.264323 (1.424 sec)
2.710... logprob:  0.820356, 0.339844 (1.444 sec)
2.711... logprob:  0.675007, 0.321615 (1.473 sec)
2.712... logprob:  0.616066, 0.290365 (1.449 sec)
2.713... logprob:  0.766740, 0.350260 (1.461 sec)
2.714... logprob:  0.736314, 0.346354 (1.466 sec)
2.715... logprob:  0.608887, 0.298177 (1.455 sec)
2.716... logprob:  0.607687, 0.266927 (1.428 sec)
2.717... logprob:  0.776256, 0.358073 (1.425 sec)
2.718... logprob:  0.676520, 0.321615 (1.437 sec)
2.719... logprob:  0.629503, 0.282552 (1.449 sec)
2.720... logprob:  0.719101, 0.321615 (1.456 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.456879, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.398830e-03 [3.771036e-07] 
Layer 'conv1' biases: 3.679456e-07 [1.374982e-09] 
Layer 'conv2' weights[0]: 7.386459e-03 [3.740376e-07] 
Layer 'conv2' biases: 9.999998e-01 [9.191655e-09] 
Layer 'conv3' weights[0]: 7.385120e-03 [3.752511e-07] 
Layer 'conv3' biases: 8.728135e-06 [3.543105e-08] 
Layer 'conv4' weights[0]: 7.415007e-03 [3.816407e-07] 
Layer 'conv4' biases: 1.000005e+00 [3.867534e-07] 
Layer 'conv5' weights[0]: 7.422784e-03 [2.205105e-06] 
Layer 'conv5' biases: 9.996372e-01 [2.285428e-06] 
Layer 'fc6' weights[0]: 7.533527e-03 [5.405781e-08] 
Layer 'fc6' biases: 9.999997e-01 [4.264006e-08] 
Layer 'fc7' weights[0]: 7.888320e-03 [1.052673e-07] 
Layer 'fc7' biases: 9.999807e-01 [1.184282e-07] 
Layer 'fc8' weights[0]: 2.899622e-03 [1.921918e-05] 
Layer 'fc8' biases: 4.235897e-03 [1.926469e-05] 
Train error last 800 batches: 0.660749
-------------------------------------------------------
Not saving because 0.456879 > 0.354449 (1.520: -10.81%)
======================================================= (2.417 sec)
2.721... logprob:  0.665059, 0.305990 (1.473 sec)
2.722... logprob:  0.755890, 0.312500 (1.459 sec)
2.723... logprob:  0.682847, 0.300781 (1.455 sec)
2.724... logprob:  0.633943, 0.268229 (1.483 sec)
2.725... logprob:  0.702260, 0.294271 (1.444 sec)
2.726... logprob:  0.559203, 0.247396 (1.435 sec)
2.727... logprob:  0.613729, 0.260417 (1.430 sec)
2.728... logprob:  0.598486, 0.226562 (1.447 sec)
2.729... logprob:  0.592939, 0.250000 (1.429 sec)
2.730... logprob:  0.700129, 0.292969 (1.486 sec)
2.731... logprob:  0.721125, 0.302083 (1.456 sec)
2.732... logprob:  0.559724, 0.257813 (1.437 sec)
2.733... logprob:  0.657171, 0.290365 (1.477 sec)
2.734... logprob:  0.597543, 0.263021 (1.425 sec)
2.735... logprob:  0.697530, 0.273437 (1.423 sec)
2.736... logprob:  0.784062, 0.350260 (1.445 sec)
2.737... logprob:  0.702986, 0.304687 (1.494 sec)
2.738... logprob:  0.711948, 0.311198 (1.435 sec)
2.739... logprob:  0.635027, 0.292969 (1.480 sec)
2.740... logprob:  0.597843, 0.270833 (1.457 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.517400, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.391415e-03 [3.758192e-07] 
Layer 'conv1' biases: 3.775448e-07 [1.760621e-09] 
Layer 'conv2' weights[0]: 7.379082e-03 [3.747970e-07] 
Layer 'conv2' biases: 9.999998e-01 [1.091309e-08] 
Layer 'conv3' weights[0]: 7.377744e-03 [3.754332e-07] 
Layer 'conv3' biases: 8.783378e-06 [3.552828e-08] 
Layer 'conv4' weights[0]: 7.407605e-03 [3.819334e-07] 
Layer 'conv4' biases: 1.000005e+00 [3.514881e-07] 
Layer 'conv5' weights[0]: 7.415395e-03 [2.138464e-06] 
Layer 'conv5' biases: 9.996336e-01 [2.258691e-06] 
Layer 'fc6' weights[0]: 7.532775e-03 [5.491501e-08] 
Layer 'fc6' biases: 9.999997e-01 [4.391855e-08] 
Layer 'fc7' weights[0]: 7.887585e-03 [1.086055e-07] 
Layer 'fc7' biases: 9.999810e-01 [1.228995e-07] 
Layer 'fc8' weights[0]: 2.969377e-03 [2.234371e-05] 
Layer 'fc8' biases: 4.543561e-03 [3.740713e-05] 
Train error last 800 batches: 0.660739
-------------------------------------------------------
Not saving because 0.517400 > 0.354449 (1.520: -10.81%)
======================================================= (2.387 sec)
2.741... logprob:  0.635561, 0.289062 (1.435 sec)
2.742... logprob:  0.641885, 0.289062 (1.485 sec)
2.743... logprob:  0.600909, 0.278646 (1.430 sec)
2.744... logprob:  0.664864, 0.298177 (1.427 sec)
2.745... logprob:  0.671044, 0.277344 (1.428 sec)
2.746... logprob:  0.638888, 0.291667 (1.425 sec)
2.747... logprob:  0.538348, 0.226562 (1.427 sec)
2.748... logprob:  0.640552, 0.299479 (1.480 sec)
2.749... logprob:  0.690280, 0.282552 (1.428 sec)
2.750... logprob:  0.723487, 0.281250 (1.446 sec)
2.751... logprob:  0.561066, 0.257812 (1.476 sec)
2.752... logprob:  0.675945, 0.277344 (1.427 sec)
2.753... logprob:  0.658155, 0.287760 (1.433 sec)
2.754... logprob:  0.714533, 0.322917 (1.426 sec)
2.755... logprob:  0.683699, 0.283854 (1.420 sec)
2.756... logprob:  0.694952, 0.277344 (1.430 sec)
2.757... logprob:  0.707291, 0.264323 (1.462 sec)
2.758... logprob:  0.649913, 0.273438 (1.438 sec)
2.759... logprob:  0.717073, 0.313802 (1.442 sec)
2.760... logprob:  0.752518, 0.335938 (1.456 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.411473, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.384043e-03 [3.786730e-07] 
Layer 'conv1' biases: 3.827150e-07 [1.385821e-09] 
Layer 'conv2' weights[0]: 7.371702e-03 [3.737894e-07] 
Layer 'conv2' biases: 9.999998e-01 [1.030224e-08] 
Layer 'conv3' weights[0]: 7.370406e-03 [3.754137e-07] 
Layer 'conv3' biases: 8.834940e-06 [4.251965e-08] 
Layer 'conv4' weights[0]: 7.400177e-03 [3.805427e-07] 
Layer 'conv4' biases: 1.000005e+00 [4.172510e-07] 
Layer 'conv5' weights[0]: 7.408021e-03 [2.518362e-06] 
Layer 'conv5' biases: 9.996318e-01 [2.798796e-06] 
Layer 'fc6' weights[0]: 7.531998e-03 [6.467011e-08] 
Layer 'fc6' biases: 9.999996e-01 [5.757560e-08] 
Layer 'fc7' weights[0]: 7.886822e-03 [1.364942e-07] 
Layer 'fc7' biases: 9.999807e-01 [1.998845e-07] 
Layer 'fc8' weights[0]: 2.986847e-03 [2.787350e-05] 
Layer 'fc8' biases: 4.621085e-03 [4.903571e-05] 
Train error last 800 batches: 0.660727
-------------------------------------------------------
Not saving because 0.411473 > 0.354449 (1.520: -10.81%)
======================================================= (2.374 sec)
2.761... logprob:  0.679779, 0.292969 (1.447 sec)
2.762... logprob:  0.707360, 0.311198 (1.439 sec)
2.763... logprob:  0.769663, 0.305990 (1.420 sec)
2.764... logprob:  0.782913, 0.343750 (1.421 sec)
2.765... logprob:  0.589026, 0.236979 (1.428 sec)
2.766... logprob:  0.680217, 0.287760 (1.457 sec)
2.767... logprob:  0.636487, 0.309896 (1.454 sec)
2.768... logprob:  0.637718, 0.270833 (1.463 sec)
2.769... logprob:  0.738810, 0.343750 (1.487 sec)
2.770... logprob:  0.631240, 0.272135 (1.481 sec)
2.771... logprob:  0.773229, 0.308594 (1.451 sec)
2.772... logprob:  0.620899, 0.269531 (1.442 sec)
2.773... logprob:  0.778140, 0.329427 (1.436 sec)
2.774... logprob:  0.621123, 0.265625 (1.455 sec)
2.775... logprob:  0.546973, 0.244792 (1.454 sec)
2.776... logprob:  0.690656, 0.320312 (1.477 sec)
2.777... logprob:  0.670869, 0.291667 (1.463 sec)
2.778... logprob:  0.663600, 0.308594 (1.488 sec)
2.779... logprob:  0.661291, 0.304687 (1.477 sec)
2.780... logprob:  0.696239, 0.302083 (1.450 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.510115, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.376690e-03 [3.754914e-07] 
Layer 'conv1' biases: 3.882675e-07 [1.281546e-09] 
Layer 'conv2' weights[0]: 7.364324e-03 [3.731008e-07] 
Layer 'conv2' biases: 9.999998e-01 [9.296366e-09] 
Layer 'conv3' weights[0]: 7.362955e-03 [3.737423e-07] 
Layer 'conv3' biases: 8.902584e-06 [3.453970e-08] 
Layer 'conv4' weights[0]: 7.392809e-03 [3.794601e-07] 
Layer 'conv4' biases: 1.000006e+00 [3.553494e-07] 
Layer 'conv5' weights[0]: 7.401025e-03 [2.002653e-06] 
Layer 'conv5' biases: 9.996252e-01 [2.019694e-06] 
Layer 'fc6' weights[0]: 7.531201e-03 [5.677612e-08] 
Layer 'fc6' biases: 9.999996e-01 [4.685715e-08] 
Layer 'fc7' weights[0]: 7.886073e-03 [1.134143e-07] 
Layer 'fc7' biases: 9.999794e-01 [1.419322e-07] 
Layer 'fc8' weights[0]: 2.937954e-03 [2.146835e-05] 
Layer 'fc8' biases: 4.390569e-03 [2.730221e-05] 
Train error last 800 batches: 0.660920
-------------------------------------------------------
Not saving because 0.510115 > 0.354449 (1.520: -10.81%)
======================================================= (2.379 sec)
2.781... logprob:  0.585075, 0.259114 (1.457 sec)
2.782... logprob:  0.582690, 0.268229 (1.447 sec)
2.783... logprob:  0.739680, 0.291667 (1.454 sec)
2.784... logprob:  0.646199, 0.295573 (1.447 sec)
2.785... logprob:  0.730779, 0.319010 (1.480 sec)
2.786... logprob:  0.791577, 0.289062 (1.460 sec)
2.787... logprob:  0.787181, 0.328125 (1.458 sec)
2.788... logprob:  0.758107, 0.320312 (1.494 sec)
2.789... logprob:  0.544822, 0.243489 (1.449 sec)
2.790... logprob:  0.630942, 0.289062 (1.440 sec)
2.791... logprob:  0.559778, 0.255208 (1.440 sec)
2.792... logprob:  0.570036, 0.255208 (1.454 sec)
2.793... logprob:  0.633307, 0.277344 (1.446 sec)
2.794... logprob:  0.644972, 0.302083 (1.486 sec)
2.795... logprob:  0.671439, 0.285156 (1.457 sec)
2.796... logprob:  0.643127, 0.269531 (1.450 sec)
2.797... logprob:  0.546219, 0.244792 (1.494 sec)
2.798... logprob:  0.565248, 0.238281 (1.443 sec)
2.799... logprob:  0.481282, 0.223958 (1.445 sec)
2.800... logprob:  0.661187, 0.278646 (1.391 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.562501, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.369313e-03 [3.763425e-07] 
Layer 'conv1' biases: 3.938125e-07 [1.538899e-09] 
Layer 'conv2' weights[0]: 7.356956e-03 [3.734307e-07] 
Layer 'conv2' biases: 9.999998e-01 [1.020678e-08] 
Layer 'conv3' weights[0]: 7.355641e-03 [3.742627e-07] 
Layer 'conv3' biases: 8.895059e-06 [3.688809e-08] 
Layer 'conv4' weights[0]: 7.385382e-03 [3.810972e-07] 
Layer 'conv4' biases: 1.000006e+00 [3.806589e-07] 
Layer 'conv5' weights[0]: 7.393776e-03 [2.442652e-06] 
Layer 'conv5' biases: 9.996182e-01 [2.558347e-06] 
Layer 'fc6' weights[0]: 7.530374e-03 [6.081211e-08] 
Layer 'fc6' biases: 9.999997e-01 [5.293682e-08] 
Layer 'fc7' weights[0]: 7.885256e-03 [1.257998e-07] 
Layer 'fc7' biases: 9.999800e-01 [1.897257e-07] 
Layer 'fc8' weights[0]: 3.011508e-03 [2.622184e-05] 
Layer 'fc8' biases: 4.728975e-03 [5.072568e-05] 
Train error last 800 batches: 0.660174
-------------------------------------------------------
Not saving because 0.562501 > 0.354449 (1.520: -10.81%)
======================================================= (2.378 sec)
3.1... logprob:  0.528976, 0.223958 (1.403 sec)
3.2... logprob:  0.625849, 0.278646 (1.448 sec)
3.3... logprob:  0.677313, 0.273437 (1.413 sec)
3.4... logprob:  0.538248, 0.236979 (1.401 sec)
3.5... logprob:  0.673366, 0.322917 (1.425 sec)
3.6... logprob:  0.708204, 0.302083 (1.384 sec)
3.7... logprob:  0.631487, 0.259115 (1.426 sec)
3.8... logprob:  0.586945, 0.270833 (1.395 sec)
3.9... logprob:  0.642888, 0.281250 (1.404 sec)
3.10... logprob:  0.662357, 0.286458 (1.406 sec)
3.11... logprob:  0.573291, 0.242188 (1.445 sec)
3.12... logprob:  0.665054, 0.294271 (1.392 sec)
3.13... logprob:  0.638301, 0.294271 (1.421 sec)
3.14... logprob:  0.695611, 0.299479 (1.397 sec)
3.15... logprob:  0.568748, 0.263021 (1.401 sec)
3.16... logprob:  0.677305, 0.304688 (1.422 sec)
3.17... logprob:  0.717865, 0.321615 (1.385 sec)
3.18... logprob:  0.499207, 0.235677 (1.395 sec)
3.19... logprob:  0.478288, 0.236979 (1.407 sec)
3.20... logprob:  0.657877, 0.292969 (0.673 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.426607, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.361919e-03 [3.733621e-07] 
Layer 'conv1' biases: 4.017882e-07 [1.382880e-09] 
Layer 'conv2' weights[0]: 7.349577e-03 [3.702596e-07] 
Layer 'conv2' biases: 9.999999e-01 [6.524043e-09] 
Layer 'conv3' weights[0]: 7.348259e-03 [3.707796e-07] 
Layer 'conv3' biases: 8.960234e-06 [2.589378e-08] 
Layer 'conv4' weights[0]: 7.378039e-03 [3.739788e-07] 
Layer 'conv4' biases: 1.000005e+00 [2.567865e-07] 
Layer 'conv5' weights[0]: 7.386417e-03 [1.694384e-06] 
Layer 'conv5' biases: 9.996160e-01 [1.781172e-06] 
Layer 'fc6' weights[0]: 7.529578e-03 [5.068340e-08] 
Layer 'fc6' biases: 9.999996e-01 [3.770625e-08] 
Layer 'fc7' weights[0]: 7.884481e-03 [9.687891e-08] 
Layer 'fc7' biases: 9.999802e-01 [1.032594e-07] 
Layer 'fc8' weights[0]: 3.043530e-03 [1.675750e-05] 
Layer 'fc8' biases: 4.842749e-03 [1.749449e-05] 
Train error last 800 batches: 0.659841
-------------------------------------------------------
Not saving because 0.426607 > 0.354449 (1.520: -10.81%)
======================================================= (2.402 sec)
3.21... logprob:  0.611397, 0.282552 (1.412 sec)
3.22... logprob:  0.744779, 0.317708 (1.411 sec)
3.23... logprob:  0.739971, 0.309896 (1.406 sec)
3.24... logprob:  0.539946, 0.253906 (1.408 sec)
3.25... logprob:  0.630105, 0.261719 (1.394 sec)
3.26... logprob:  0.714665, 0.335938 (1.443 sec)
3.27... logprob:  0.627477, 0.279948 (1.389 sec)
3.28... logprob:  0.706752, 0.335938 (1.414 sec)
3.29... logprob:  0.650853, 0.263021 (1.415 sec)
3.30... logprob:  0.598120, 0.264323 (1.409 sec)
3.31... logprob:  0.673633, 0.312500 (1.396 sec)
3.32... logprob:  0.686238, 0.294271 (1.381 sec)
3.33... logprob:  0.676507, 0.290365 (1.440 sec)
3.34... logprob:  0.700493, 0.292969 (1.386 sec)
3.35... logprob:  0.537885, 0.235677 (1.397 sec)
3.36... logprob:  0.714655, 0.308594 (1.392 sec)
3.37... logprob:  0.638989, 0.274740 (1.407 sec)
3.38... logprob:  0.617478, 0.261719 (1.385 sec)
3.39... logprob:  0.752647, 0.319010 (1.430 sec)
3.40... logprob:  0.637644, 0.273437 (1.406 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.323801, 0.039062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.354570e-03 [3.782486e-07] 
Layer 'conv1' biases: 4.113212e-07 [1.599986e-09] 
Layer 'conv2' weights[0]: 7.342262e-03 [3.718475e-07] 
Layer 'conv2' biases: 9.999999e-01 [8.707065e-09] 
Layer 'conv3' weights[0]: 7.340940e-03 [3.721836e-07] 
Layer 'conv3' biases: 9.112259e-06 [3.147539e-08] 
Layer 'conv4' weights[0]: 7.370640e-03 [3.774656e-07] 
Layer 'conv4' biases: 1.000006e+00 [3.162620e-07] 
Layer 'conv5' weights[0]: 7.379240e-03 [2.247408e-06] 
Layer 'conv5' biases: 9.996124e-01 [2.403452e-06] 
Layer 'fc6' weights[0]: 7.528789e-03 [5.718299e-08] 
Layer 'fc6' biases: 9.999996e-01 [4.793423e-08] 
Layer 'fc7' weights[0]: 7.883725e-03 [1.154885e-07] 
Layer 'fc7' biases: 9.999791e-01 [1.429462e-07] 
Layer 'fc8' weights[0]: 3.017208e-03 [2.354513e-05] 
Layer 'fc8' biases: 4.604404e-03 [3.497987e-05] 
Train error last 800 batches: 0.659817
-------------------------------------------------------
Saved checkpoint to /data2/ad6813/my-nets/saves/ConvNet__2014-06-04_16.10.14
======================================================= (2.776 sec)
3.41... logprob:  0.532884, 0.244792 (1.431 sec)
3.42... logprob:  0.616130, 0.268229 (1.415 sec)
3.43... logprob:  0.680348, 0.292969 (1.410 sec)
3.44... logprob:  0.767079, 0.317708 (2.211 sec)
3.45... logprob:  0.539404, 0.234375 (1.391 sec)
3.46... logprob:  0.614014, 0.243490 (1.405 sec)
3.47... logprob:  0.575906, 0.252604 (2.746 sec)
3.48... logprob:  0.682923, 0.285156 (1.426 sec)
3.49... logprob:  0.643418, 0.286458 (1.405 sec)
3.50... logprob:  0.649774, 0.289062 (1.421 sec)
3.51... logprob:  0.733269, 0.303385 (1.411 sec)
3.52... logprob:  0.735338, 0.325521 (1.391 sec)
3.53... logprob:  0.547196, 0.247396 (1.437 sec)
3.54... logprob:  0.633544, 0.260417 (1.407 sec)
3.55... logprob:  0.479726, 0.220052 (1.397 sec)
3.56... logprob:  0.672535, 0.274740 (1.402 sec)
3.57... logprob:  0.857544, 0.348958 (1.421 sec)
3.58... logprob:  0.616331, 0.269531 (1.396 sec)
3.59... logprob:  0.622654, 0.276042 (1.461 sec)
3.60... logprob:  0.724968, 0.295573 (1.409 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.460846, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.347224e-03 [3.743242e-07] 
Layer 'conv1' biases: 4.145963e-07 [1.675124e-09] 
Layer 'conv2' weights[0]: 7.334905e-03 [3.728843e-07] 
Layer 'conv2' biases: 9.999999e-01 [1.084288e-08] 
Layer 'conv3' weights[0]: 7.333572e-03 [3.737186e-07] 
Layer 'conv3' biases: 9.136042e-06 [3.873156e-08] 
Layer 'conv4' weights[0]: 7.363245e-03 [3.806367e-07] 
Layer 'conv4' biases: 1.000007e+00 [4.330284e-07] 
Layer 'conv5' weights[0]: 7.372278e-03 [2.339639e-06] 
Layer 'conv5' biases: 9.996051e-01 [2.482061e-06] 
Layer 'fc6' weights[0]: 7.528037e-03 [5.807309e-08] 
Layer 'fc6' biases: 9.999997e-01 [4.914486e-08] 
Layer 'fc7' weights[0]: 7.882992e-03 [1.188065e-07] 
Layer 'fc7' biases: 9.999786e-01 [1.504408e-07] 
Layer 'fc8' weights[0]: 3.017484e-03 [2.366758e-05] 
Layer 'fc8' biases: 4.571632e-03 [3.019863e-05] 
Train error last 800 batches: 0.659860
-------------------------------------------------------
Not saving because 0.460846 > 0.323801 (3.40: -8.65%)
======================================================= (2.359 sec)
3.61... logprob:  0.624417, 0.278646 (1.562 sec)
3.62... logprob:  0.568109, 0.260417 (1.453 sec)
3.63... logprob:  0.679848, 0.298177 (1.436 sec)
3.64... logprob:  0.732981, 0.282552 (1.431 sec)
3.65... logprob:  0.613053, 0.285156 (1.405 sec)
3.66... logprob:  0.620373, 0.273437 (1.437 sec)
3.67... logprob:  0.580941, 0.277344 (1.385 sec)
3.68... logprob:  0.599937, 0.226562 (1.391 sec)
3.69... logprob:  0.682444, 0.300781 (1.417 sec)
3.70... logprob:  0.535184, 0.233073 (1.415 sec)
3.71... logprob:  0.598994, 0.272135 (1.457 sec)
3.72... logprob:  0.676964, 0.309896 (1.401 sec)
3.73... logprob:  0.664631, 0.308594 (1.423 sec)
3.74... logprob:  0.662723, 0.294271 (1.413 sec)
3.75... logprob:  0.604976, 0.268229 (1.411 sec)
3.76... logprob:  0.632929, 0.300781 (1.431 sec)
3.77... logprob:  0.588707, 0.274740 (1.425 sec)
3.78... logprob:  0.790555, 0.328125 (1.447 sec)
3.79... logprob:  0.696441, 0.295573 (1.397 sec)
3.80... logprob:  0.565235, 0.238281 (1.413 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.497290, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.339903e-03 [3.762312e-07] 
Layer 'conv1' biases: 4.204492e-07 [1.429691e-09] 
Layer 'conv2' weights[0]: 7.327588e-03 [3.703539e-07] 
Layer 'conv2' biases: 9.999999e-01 [7.407566e-09] 
Layer 'conv3' weights[0]: 7.326284e-03 [3.698486e-07] 
Layer 'conv3' biases: 9.208703e-06 [2.793330e-08] 
Layer 'conv4' weights[0]: 7.355910e-03 [3.742071e-07] 
Layer 'conv4' biases: 1.000007e+00 [2.987229e-07] 
Layer 'conv5' weights[0]: 7.365157e-03 [1.824253e-06] 
Layer 'conv5' biases: 9.996003e-01 [1.874560e-06] 
Layer 'fc6' weights[0]: 7.527258e-03 [5.389242e-08] 
Layer 'fc6' biases: 9.999996e-01 [4.322352e-08] 
Layer 'fc7' weights[0]: 7.882236e-03 [1.048779e-07] 
Layer 'fc7' biases: 9.999787e-01 [1.118426e-07] 
Layer 'fc8' weights[0]: 3.052366e-03 [1.711757e-05] 
Layer 'fc8' biases: 4.779098e-03 [1.379265e-05] 
Train error last 800 batches: 0.659506
-------------------------------------------------------
Not saving because 0.497290 > 0.323801 (3.40: -8.65%)
======================================================= (2.369 sec)
3.81... logprob:  0.749636, 0.317708 (1.418 sec)
3.82... logprob:  0.514376, 0.227865 (1.422 sec)
3.83... logprob:  0.562247, 0.256510 (1.416 sec)
3.84... logprob:  0.745826, 0.322917 (1.469 sec)
3.85... logprob:  0.693445, 0.303385 (1.418 sec)
3.86... logprob:  0.604122, 0.278646 (1.409 sec)
3.87... logprob:  0.825993, 0.363281 (1.410 sec)
3.88... logprob:  0.762624, 0.296875 (1.402 sec)
3.89... logprob:  0.602586, 0.291667 (1.428 sec)
3.90... logprob:  0.779252, 0.345052 (1.384 sec)
3.91... logprob:  0.610794, 0.277344 (1.389 sec)
3.92... logprob:  0.678041, 0.291667 (1.392 sec)
3.93... logprob:  0.662891, 0.292969 (1.395 sec)
3.94... logprob:  0.582486, 0.253906 (1.389 sec)
3.95... logprob:  0.725906, 0.304688 (1.390 sec)
3.96... logprob:  0.776343, 0.343750 (1.405 sec)
3.97... logprob:  0.697242, 0.312500 (1.387 sec)
3.98... logprob:  0.636569, 0.261719 (1.433 sec)
3.99... logprob:  0.730686, 0.313802 (1.401 sec)
3.100... logprob:  0.535870, 0.260417 (1.396 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.456494, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.332566e-03 [3.720437e-07] 
Layer 'conv1' biases: 4.275195e-07 [1.045479e-09] 
Layer 'conv2' weights[0]: 7.320248e-03 [3.704609e-07] 
Layer 'conv2' biases: 9.999999e-01 [7.273353e-09] 
Layer 'conv3' weights[0]: 7.318986e-03 [3.699640e-07] 
Layer 'conv3' biases: 9.325617e-06 [2.704390e-08] 
Layer 'conv4' weights[0]: 7.348536e-03 [3.743240e-07] 
Layer 'conv4' biases: 1.000007e+00 [2.703448e-07] 
Layer 'conv5' weights[0]: 7.358022e-03 [1.837439e-06] 
Layer 'conv5' biases: 9.995928e-01 [1.940530e-06] 
Layer 'fc6' weights[0]: 7.526448e-03 [5.329324e-08] 
Layer 'fc6' biases: 9.999996e-01 [4.228259e-08] 
Layer 'fc7' weights[0]: 7.881462e-03 [1.048848e-07] 
Layer 'fc7' biases: 9.999778e-01 [1.148374e-07] 
Layer 'fc8' weights[0]: 3.018636e-03 [1.764506e-05] 
Layer 'fc8' biases: 4.544303e-03 [1.968424e-05] 
Train error last 800 batches: 0.659577
-------------------------------------------------------
Not saving because 0.456494 > 0.323801 (3.40: -8.65%)
======================================================= (2.381 sec)
3.101... logprob:  0.525797, 0.212240 (1.450 sec)
3.102... logprob:  0.712925, 0.317708 (1.391 sec)
3.103... logprob:  0.698471, 0.302083 (1.423 sec)
3.104... logprob:  0.593943, 0.276042 (1.405 sec)
3.105... logprob:  0.687658, 0.303385 (1.391 sec)
3.106... logprob:  0.583658, 0.261719 (1.388 sec)
3.107... logprob:  0.609715, 0.263021 (1.432 sec)
3.108... logprob:  0.701051, 0.313802 (1.390 sec)
3.109... logprob:  0.546302, 0.243490 (1.397 sec)
3.110... logprob:  0.728879, 0.308594 (1.386 sec)
3.111... logprob:  0.641064, 0.268229 (1.392 sec)
3.112... logprob:  0.699633, 0.312500 (1.391 sec)
3.113... logprob:  0.593652, 0.273438 (1.396 sec)
3.114... logprob:  0.701189, 0.268229 (1.425 sec)
3.115... logprob:  0.632403, 0.299479 (1.404 sec)
3.116... logprob:  0.676808, 0.321614 (1.393 sec)
3.117... logprob:  0.738961, 0.290365 (1.438 sec)
3.118... logprob:  0.626120, 0.307292 (1.380 sec)
3.119... logprob:  0.538854, 0.244792 (1.395 sec)
3.120... logprob:  0.785489, 0.332031 (1.395 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.443046, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.325213e-03 [3.737694e-07] 
Layer 'conv1' biases: 4.297480e-07 [1.316908e-09] 
Layer 'conv2' weights[0]: 7.312904e-03 [3.699408e-07] 
Layer 'conv2' biases: 9.999999e-01 [8.365786e-09] 
Layer 'conv3' weights[0]: 7.311638e-03 [3.695792e-07] 
Layer 'conv3' biases: 9.272779e-06 [2.831705e-08] 
Layer 'conv4' weights[0]: 7.341243e-03 [3.753728e-07] 
Layer 'conv4' biases: 1.000007e+00 [3.272621e-07] 
Layer 'conv5' weights[0]: 7.350768e-03 [2.075933e-06] 
Layer 'conv5' biases: 9.995931e-01 [2.210950e-06] 
Layer 'fc6' weights[0]: 7.525681e-03 [5.615744e-08] 
Layer 'fc6' biases: 9.999996e-01 [4.673882e-08] 
Layer 'fc7' weights[0]: 7.880672e-03 [1.124815e-07] 
Layer 'fc7' biases: 9.999784e-01 [1.366978e-07] 
Layer 'fc8' weights[0]: 3.069755e-03 [1.963822e-05] 
Layer 'fc8' biases: 4.807548e-03 [2.850861e-05] 
Train error last 800 batches: 0.659182
-------------------------------------------------------
Not saving because 0.443046 > 0.323801 (3.40: -8.65%)
======================================================= (2.404 sec)
3.121... logprob:  0.669097, 0.307292 (1.403 sec)
3.122... logprob:  0.714981, 0.299479 (1.446 sec)
3.123... logprob:  0.710054, 0.315104 (1.396 sec)
3.124... logprob:  0.750851, 0.341146 (1.400 sec)
3.125... logprob:  0.745282, 0.299479 (1.392 sec)
3.126... logprob:  0.821021, 0.343750 (1.387 sec)
3.127... logprob:  0.689862, 0.274740 (1.391 sec)
3.128... logprob:  0.630940, 0.285156 (1.409 sec)
3.129... logprob:  0.775661, 0.351562 (1.416 sec)
3.130... logprob:  0.618074, 0.274740 (1.413 sec)
3.131... logprob:  0.692924, 0.298177 (1.401 sec)
3.132... logprob:  0.699366, 0.303385 (1.440 sec)
3.133... logprob:  0.663944, 0.279948 (1.383 sec)
3.134... logprob:  0.643882, 0.272135 (1.391 sec)
3.135... logprob:  0.714445, 0.321615 (1.395 sec)
3.136... logprob:  0.721419, 0.296875 (1.388 sec)
3.137... logprob:  0.659104, 0.296875 (1.391 sec)
3.138... logprob:  0.548959, 0.252604 (1.440 sec)
3.139... logprob:  0.647953, 0.295573 (1.391 sec)
3.140... logprob:  0.752354, 0.319010 (1.406 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.513126, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.317916e-03 [3.754160e-07] 
Layer 'conv1' biases: 4.346872e-07 [1.271894e-09] 
Layer 'conv2' weights[0]: 7.305574e-03 [3.706071e-07] 
Layer 'conv2' biases: 9.999998e-01 [9.660873e-09] 
Layer 'conv3' weights[0]: 7.304314e-03 [3.713952e-07] 
Layer 'conv3' biases: 9.316271e-06 [3.582354e-08] 
Layer 'conv4' weights[0]: 7.333823e-03 [3.777920e-07] 
Layer 'conv4' biases: 1.000009e+00 [3.503786e-07] 
Layer 'conv5' weights[0]: 7.344160e-03 [2.090125e-06] 
Layer 'conv5' biases: 9.995845e-01 [2.235801e-06] 
Layer 'fc6' weights[0]: 7.524864e-03 [5.821645e-08] 
Layer 'fc6' biases: 9.999996e-01 [4.988105e-08] 
Layer 'fc7' weights[0]: 7.879884e-03 [1.185078e-07] 
Layer 'fc7' biases: 9.999769e-01 [1.552367e-07] 
Layer 'fc8' weights[0]: 3.000872e-03 [2.369741e-05] 
Layer 'fc8' biases: 4.480148e-03 [4.212915e-05] 
Train error last 800 batches: 0.659932
-------------------------------------------------------
Not saving because 0.513126 > 0.323801 (3.40: -8.65%)
======================================================= (2.379 sec)
3.141... logprob:  0.678295, 0.304687 (1.443 sec)
3.142... logprob:  0.732482, 0.307292 (1.428 sec)
3.143... logprob:  0.579688, 0.253906 (1.432 sec)
3.144... logprob:  0.710728, 0.309896 (1.408 sec)
3.145... logprob:  0.592456, 0.252604 (1.410 sec)
3.146... logprob:  0.651367, 0.277344 (1.403 sec)
3.147... logprob:  0.520733, 0.216146 (1.428 sec)
3.148... logprob:  0.689423, 0.333333 (1.381 sec)
3.149... logprob:  0.653822, 0.309896 (1.388 sec)
3.150... logprob:  0.548739, 0.240885 (1.395 sec)
3.151... logprob:  0.646446, 0.292969 (1.392 sec)
3.152... logprob:  0.872510, 0.371094 (1.389 sec)
3.153... logprob:  0.590225, 0.260417 (1.432 sec)
3.154... logprob:  0.675008, 0.291667 (1.394 sec)
3.155... logprob:  0.712053, 0.322917 (1.404 sec)
3.156... logprob:  0.546751, 0.261719 (1.433 sec)
3.157... logprob:  0.555504, 0.250000 (1.393 sec)
3.158... logprob:  0.672210, 0.316406 (1.396 sec)
3.159... logprob:  0.709447, 0.316406 (1.392 sec)
3.160... logprob:  0.624853, 0.285156 (1.384 sec)
Traceback (most recent call last):
  File "/homes/ad6813/.local/bin/ccn-train", line 9, in <module>
    load_entry_point('noccn==0.1-dev', 'console_scripts', 'ccn-train')()
  File "/homes/ad6813/.local/lib/python2.7/site-packages/noccn-0.1_dev-py2.7.egg/noccn/train.py", line 81, in console
    run_model(ConvNet, 'train')
  File "/homes/ad6813/.local/lib/python2.7/site-packages/noccn-0.1_dev-py2.7.egg/noccn/script.py", line 111, in run_model
    model.start()
  File "/homes/ad6813/.local/lib/python2.7/site-packages/noccn-0.1_dev-py2.7.egg/noccn/train.py", line 62, in start
    self.train()
  File "/homes/ad6813/Git/pipe-classification/cuda_convnet/gpumodel.py", line 157, in train
    self.test_outputs += [self.get_test_error()]
  File "/homes/ad6813/Git/pipe-classification/cuda_convnet/gpumodel.py", line 226, in get_test_error
    next_data = self.get_next_batch(train=False)
  File "/homes/ad6813/Git/pipe-classification/cuda_convnet/gpumodel.py", line 181, in get_next_batch
    return self.parse_batch_data(dp.get_next_batch(), train=train)
  File "/homes/ad6813/Git/pipe-classification/cuda_convnet/convdata.py", line 192, in get_next_batch
    self.data_dic = self.get_batch(self.curr_batchnum)
  File "/homes/ad6813/Git/pipe-classification/cuda_convnet/data.py", line 85, in get_batch
    dic = unpickle(self.get_data_file_name(batch_num))
  File "/homes/ad6813/Git/pipe-classification/cuda_convnet/util.py", line 71, in unpickle
    raise UnpickleError("Path '%s' does not exist." % filename)
util.UnpickleError: Path '/data2/ad6813/pipe-data/Redbox/batches/clamp_detection/data_batch_887' does not exist.
nohup: ignoring input
Option --layer-def (Layer definition file) cannot be changed
Option --crop-border (Cropped DP: crop border size) cannot be changed
=========================
Importing _ConvNet C++ module
=========================
Training ConvNet
Always write savepoints, regardless of test err improvement: 0     [DEFAULT]
Check gradients and quit?                                  : 0     [DEFAULT]
Compress checkpoints?                                      : 0     [DEFAULT]
Conserve GPU memory (slower)?                              : 0     [DEFAULT]
Convert given conv layers to unshared local                :       
Cropped DP: crop border size                               : 32    
Cropped DP: logreg layer name (for --multiview-test)       :       [DEFAULT]
Cropped DP: test on multiple patches?                      : 0     [DEFAULT]
Cropped Step: crop border step                             : 1     [DEFAULT]
Data batch range: testing                                  : 801-886 
Data batch range: training                                 : 1-800 
Data path                                                  : /data2/ad6813/pipe-data/Redbox/batches/clamp_detection 
Data provider                                              : basic-leaf256 
GPU override                                               : -1    [DEFAULT]
Layer definition file                                      : /homes/ad6813/Git/pipe-classification/models/decaf-net/layers_decaf.cfg 
Layer parameter file                                       : /homes/ad6813/Git/pipe-classification/models/decaf-net/params_decaf.cfg 
Load file                                                  : /data2/ad6813/my-nets/saves/ConvNet__2014-06-04_16.10.14 
Maximum save file size (MB)                                : 0     [DEFAULT]
Minibatch size                                             : 128   [DEFAULT]
Number of GPUs                                             : 1     [DEFAULT]
Number of epochs                                           : 50000 [DEFAULT]
Save path                                                  : /data2/ad6813/my-nets/saves 
Test and quit?                                             : 0     [DEFAULT]
Test on more than one batch at a time?                     : -1    [DEFAULT]
Test on one batch at a time?                               : 1     [DEFAULT]
Testing frequency                                          : 20    
Unshare weight matrices in given layers                    :       
=========================
Running on CUDA device(s) -2
Current time: Wed Jun  4 22:19:07 2014
Saving checkpoints to /data2/ad6813/my-nets/saves/ConvNet__2014-06-04_16.10.14
=========================
3.41... logprob:  0.660752, 0.316406 (1.434 sec)
3.42... logprob:  0.630370, 0.265625 (1.418 sec)
3.43... logprob:  0.614455, 0.278646 (1.407 sec)
3.44... logprob:  0.653869, 0.313802 (1.441 sec)
3.45... logprob:  0.609006, 0.270833 (1.389 sec)
3.46... logprob:  0.649370, 0.281250 (1.399 sec)
3.47... logprob:  0.560884, 0.238281 (1.397 sec)
3.48... logprob:  0.787256, 0.369792 (1.426 sec)
3.49... logprob:  0.752497, 0.326823 (1.417 sec)
3.50... logprob:  0.600636, 0.266927 (1.425 sec)
3.51... logprob:  0.711975, 0.296875 (1.417 sec)
3.52... logprob:  0.759832, 0.317708 (1.402 sec)
3.53... logprob:  0.571888, 0.264323 (1.444 sec)
3.54... logprob:  0.619791, 0.305990 (1.383 sec)
3.55... logprob:  0.561205, 0.273437 (1.397 sec)
3.56... logprob:  0.656645, 0.270833 (1.398 sec)
3.57... logprob:  0.719722, 0.315104 (1.433 sec)
3.58... logprob:  0.534320, 0.240885 (1.400 sec)
3.59... logprob:  0.556934, 0.256510 (1.457 sec)
3.60... logprob:  0.833730, 0.354167 (1.423 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.469135, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.347213e-03 [3.775567e-07] 
Layer 'conv1' biases: 4.140829e-07 [1.404298e-09] 
Layer 'conv2' weights[0]: 7.334882e-03 [3.716749e-07] 
Layer 'conv2' biases: 9.999999e-01 [8.783438e-09] 
Layer 'conv3' weights[0]: 7.333575e-03 [3.724705e-07] 
Layer 'conv3' biases: 9.127294e-06 [3.374241e-08] 
Layer 'conv4' weights[0]: 7.363259e-03 [3.767069e-07] 
Layer 'conv4' biases: 1.000004e+00 [3.300672e-07] 
Layer 'conv5' weights[0]: 7.371506e-03 [1.991161e-06] 
Layer 'conv5' biases: 9.996135e-01 [2.085655e-06] 
Layer 'fc6' weights[0]: 7.528036e-03 [5.542780e-08] 
Layer 'fc6' biases: 9.999997e-01 [4.544132e-08] 
Layer 'fc7' weights[0]: 7.882991e-03 [1.109678e-07] 
Layer 'fc7' biases: 9.999794e-01 [1.335044e-07] 
Layer 'fc8' weights[0]: 3.059993e-03 [2.291364e-05] 
Layer 'fc8' biases: 4.735248e-03 [3.803484e-05] 
Train error last 800 batches: 0.660011
-------------------------------------------------------
Not saving because 0.469135 > 0.323801 (3.40: -8.65%)
======================================================= (2.356 sec)
3.61... logprob:  0.654826, 0.292969 (1.451 sec)
3.62... logprob:  0.706304, 0.304687 (1.455 sec)
3.63... logprob:  0.556615, 0.261719 (1.468 sec)
3.64... logprob:  0.722160, 0.332031 (1.419 sec)
3.65... logprob:  0.557157, 0.253906 (1.395 sec)
3.66... logprob:  0.562371, 0.279948 (1.444 sec)
3.67... logprob:  0.533779, 0.239583 (1.385 sec)
3.68... logprob:  0.521509, 0.230469 (1.398 sec)
3.69... logprob:  0.636665, 0.272135 (1.417 sec)
3.70... logprob:  0.582008, 0.283854 (1.418 sec)
3.71... logprob:  0.687320, 0.292969 (1.454 sec)
3.72... logprob:  0.686466, 0.320312 (1.400 sec)
3.73... logprob:  0.662725, 0.312500 (1.443 sec)
3.74... logprob:  0.640660, 0.278646 (1.415 sec)
3.75... logprob:  0.541324, 0.220052 (1.411 sec)
3.76... logprob:  0.606635, 0.264323 (1.425 sec)
3.77... logprob:  0.612192, 0.269531 (1.424 sec)
3.78... logprob:  0.734168, 0.309896 (1.446 sec)
3.79... logprob:  0.649156, 0.292969 (1.398 sec)
3.80... logprob:  0.688553, 0.259115 (1.414 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.442432, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.339870e-03 [3.738628e-07] 
Layer 'conv1' biases: 4.117382e-07 [1.173433e-09] 
Layer 'conv2' weights[0]: 7.327551e-03 [3.718444e-07] 
Layer 'conv2' biases: 9.999999e-01 [8.930146e-09] 
Layer 'conv3' weights[0]: 7.326261e-03 [3.723802e-07] 
Layer 'conv3' biases: 9.172244e-06 [3.469592e-08] 
Layer 'conv4' weights[0]: 7.355929e-03 [3.778215e-07] 
Layer 'conv4' biases: 1.000003e+00 [3.450910e-07] 
Layer 'conv5' weights[0]: 7.363720e-03 [2.192477e-06] 
Layer 'conv5' biases: 9.996155e-01 [2.233989e-06] 
Layer 'fc6' weights[0]: 7.527255e-03 [5.879516e-08] 
Layer 'fc6' biases: 9.999996e-01 [5.007637e-08] 
Layer 'fc7' weights[0]: 7.882193e-03 [1.197988e-07] 
Layer 'fc7' biases: 9.999793e-01 [1.563858e-07] 
Layer 'fc8' weights[0]: 3.107841e-03 [2.100323e-05] 
Layer 'fc8' biases: 4.981612e-03 [3.250996e-05] 
Train error last 800 batches: 0.659435
-------------------------------------------------------
Not saving because 0.442432 > 0.323801 (3.40: -8.65%)
======================================================= (2.378 sec)
3.81... logprob:  0.623900, 0.286458 (1.421 sec)
3.82... logprob:  0.482652, 0.204427 (1.423 sec)
3.83... logprob:  0.746721, 0.324219 (1.404 sec)
3.84... logprob:  0.763581, 0.319010 (1.457 sec)
3.85... logprob:  0.631383, 0.259115 (1.420 sec)
3.86... logprob:  0.679639, 0.279948 (1.415 sec)
3.87... logprob:  0.714347, 0.313802 (1.413 sec)
3.88... logprob:  0.790232, 0.322917 (1.411 sec)
3.89... logprob:  0.672324, 0.285156 (1.431 sec)
3.90... logprob:  0.858406, 0.347656 (1.390 sec)
3.91... logprob:  0.570864, 0.247396 (1.394 sec)
3.92... logprob:  0.758024, 0.308594 (1.396 sec)
3.93... logprob:  0.674528, 0.276042 (1.393 sec)
3.94... logprob:  0.683881, 0.282552 (1.396 sec)
3.95... logprob:  0.645995, 0.276042 (1.395 sec)
3.96... logprob:  0.861044, 0.343750 (1.396 sec)
3.97... logprob:  0.630725, 0.268229 (1.387 sec)
3.98... logprob:  0.642358, 0.272135 (1.431 sec)
3.99... logprob:  0.707719, 0.282552 (1.400 sec)
3.100... logprob:  0.568431, 0.269531 (1.393 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.526887, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.332490e-03 [3.773163e-07] 
Layer 'conv1' biases: 4.114261e-07 [1.439506e-09] 
Layer 'conv2' weights[0]: 7.320214e-03 [3.747526e-07] 
Layer 'conv2' biases: 9.999998e-01 [1.159724e-08] 
Layer 'conv3' weights[0]: 7.318956e-03 [3.752996e-07] 
Layer 'conv3' biases: 9.335992e-06 [4.126392e-08] 
Layer 'conv4' weights[0]: 7.348558e-03 [3.829393e-07] 
Layer 'conv4' biases: 1.000004e+00 [4.234748e-07] 
Layer 'conv5' weights[0]: 7.356814e-03 [2.778835e-06] 
Layer 'conv5' biases: 9.996108e-01 [2.917592e-06] 
Layer 'fc6' weights[0]: 7.526447e-03 [6.438686e-08] 
Layer 'fc6' biases: 9.999996e-01 [5.809508e-08] 
Layer 'fc7' weights[0]: 7.881515e-03 [1.370475e-07] 
Layer 'fc7' biases: 9.999771e-01 [2.056745e-07] 
Layer 'fc8' weights[0]: 2.956831e-03 [3.041451e-05] 
Layer 'fc8' biases: 4.144521e-03 [5.872726e-05] 
Train error last 800 batches: 0.659794
-------------------------------------------------------
Not saving because 0.526887 > 0.323801 (3.40: -8.65%)
======================================================= (2.378 sec)
3.101... logprob:  0.633576, 0.291667 (1.448 sec)
3.102... logprob:  0.660779, 0.283854 (1.416 sec)
3.103... logprob:  0.812658, 0.369792 (1.398 sec)
3.104... logprob:  0.595710, 0.266927 (1.394 sec)
3.105... logprob:  0.703521, 0.329427 (1.387 sec)
3.106... logprob:  0.598366, 0.282552 (1.388 sec)
3.107... logprob:  0.576188, 0.253906 (1.438 sec)
3.108... logprob:  0.784137, 0.317708 (1.388 sec)
3.109... logprob:  0.664613, 0.300781 (1.398 sec)
3.110... logprob:  0.775385, 0.338542 (1.386 sec)
3.111... logprob:  0.733234, 0.305990 (1.390 sec)
3.112... logprob:  0.570787, 0.253906 (1.398 sec)
3.113... logprob:  0.537876, 0.242188 (1.399 sec)
3.114... logprob:  0.717412, 0.290365 (1.422 sec)
3.115... logprob:  0.678098, 0.300781 (1.403 sec)
3.116... logprob:  0.643812, 0.308594 (1.396 sec)
3.117... logprob:  0.623406, 0.256510 (1.437 sec)
3.118... logprob:  0.634788, 0.282552 (1.385 sec)
3.119... logprob:  0.511257, 0.221354 (1.387 sec)
3.120... logprob:  0.759755, 0.329427 (1.398 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.406263, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.325212e-03 [3.732738e-07] 
Layer 'conv1' biases: 4.159600e-07 [1.119734e-09] 
Layer 'conv2' weights[0]: 7.312891e-03 [3.701676e-07] 
Layer 'conv2' biases: 9.999998e-01 [7.551370e-09] 
Layer 'conv3' weights[0]: 7.311636e-03 [3.693147e-07] 
Layer 'conv3' biases: 9.341453e-06 [2.889339e-08] 
Layer 'conv4' weights[0]: 7.341230e-03 [3.739457e-07] 
Layer 'conv4' biases: 1.000004e+00 [2.813200e-07] 
Layer 'conv5' weights[0]: 7.349364e-03 [1.869827e-06] 
Layer 'conv5' biases: 9.996101e-01 [1.931442e-06] 
Layer 'fc6' weights[0]: 7.525678e-03 [5.278104e-08] 
Layer 'fc6' biases: 9.999996e-01 [4.139127e-08] 
Layer 'fc7' weights[0]: 7.880716e-03 [1.045074e-07] 
Layer 'fc7' biases: 9.999774e-01 [1.096173e-07] 
Layer 'fc8' weights[0]: 3.068877e-03 [1.883886e-05] 
Layer 'fc8' biases: 4.654491e-03 [2.004291e-05] 
Train error last 800 batches: 0.659640
-------------------------------------------------------
Not saving because 0.406263 > 0.323801 (3.40: -8.65%)
======================================================= (2.418 sec)
3.121... logprob:  0.624262, 0.281250 (1.406 sec)
3.122... logprob:  0.698919, 0.294271 (1.442 sec)
3.123... logprob:  0.673239, 0.294271 (1.382 sec)
3.124... logprob:  0.679718, 0.291667 (1.395 sec)
3.125... logprob:  0.676707, 0.289062 (1.399 sec)
3.126... logprob:  0.701398, 0.299479 (1.393 sec)
3.127... logprob:  0.769483, 0.316406 (1.397 sec)
3.128... logprob:  0.596520, 0.269531 (1.410 sec)
3.129... logprob:  0.727891, 0.322917 (1.411 sec)
3.130... logprob:  0.627903, 0.272135 (1.416 sec)
3.131... logprob:  0.641680, 0.279948 (1.404 sec)
3.132... logprob:  0.691458, 0.294271 (1.430 sec)
3.133... logprob:  0.656700, 0.282552 (1.379 sec)
3.134... logprob:  0.636010, 0.273438 (1.396 sec)
3.135... logprob:  0.630885, 0.276042 (1.397 sec)
3.136... logprob:  0.777353, 0.319010 (1.395 sec)
3.137... logprob:  0.594555, 0.269531 (1.377 sec)
3.138... logprob:  0.596178, 0.250000 (1.444 sec)
3.139... logprob:  0.652711, 0.305990 (1.392 sec)
3.140... logprob:  0.836942, 0.317708 (1.400 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.477354, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.317878e-03 [3.760858e-07] 
Layer 'conv1' biases: 4.195424e-07 [1.272293e-09] 
Layer 'conv2' weights[0]: 7.305532e-03 [3.708167e-07] 
Layer 'conv2' biases: 9.999998e-01 [9.300226e-09] 
Layer 'conv3' weights[0]: 7.304307e-03 [3.706256e-07] 
Layer 'conv3' biases: 9.475384e-06 [3.188822e-08] 
Layer 'conv4' weights[0]: 7.333871e-03 [3.753734e-07] 
Layer 'conv4' biases: 1.000004e+00 [3.221176e-07] 
Layer 'conv5' weights[0]: 7.342104e-03 [2.072482e-06] 
Layer 'conv5' biases: 9.996073e-01 [2.192409e-06] 
Layer 'fc6' weights[0]: 7.524859e-03 [5.659999e-08] 
Layer 'fc6' biases: 9.999996e-01 [4.728556e-08] 
Layer 'fc7' weights[0]: 7.879948e-03 [1.132023e-07] 
Layer 'fc7' biases: 9.999770e-01 [1.254956e-07] 
Layer 'fc8' weights[0]: 3.052045e-03 [1.879843e-05] 
Layer 'fc8' biases: 4.571504e-03 [1.841392e-05] 
Train error last 800 batches: 0.659915
-------------------------------------------------------
Not saving because 0.477354 > 0.323801 (3.40: -8.65%)
======================================================= (2.395 sec)
3.141... logprob:  0.713829, 0.303385 (1.439 sec)
3.142... logprob:  0.680661, 0.305990 (1.404 sec)
3.143... logprob:  0.532093, 0.253906 (1.419 sec)
3.144... logprob:  0.621663, 0.277344 (1.408 sec)
3.145... logprob:  0.583174, 0.286458 (1.410 sec)
3.146... logprob:  0.715160, 0.307292 (1.408 sec)
3.147... logprob:  0.542414, 0.260417 (1.430 sec)
3.148... logprob:  0.774763, 0.332031 (1.384 sec)
3.149... logprob:  0.711917, 0.308594 (1.392 sec)
3.150... logprob:  0.581376, 0.229167 (1.395 sec)
3.151... logprob:  0.558427, 0.270833 (1.390 sec)
3.152... logprob:  0.798708, 0.371094 (1.392 sec)
3.153... logprob:  0.606768, 0.261719 (1.439 sec)
3.154... logprob:  0.772684, 0.324219 (1.392 sec)
3.155... logprob:  0.619921, 0.278646 (1.402 sec)
3.156... logprob:  0.517012, 0.242187 (1.431 sec)
3.157... logprob:  0.482316, 0.221354 (1.388 sec)
3.158... logprob:  0.746156, 0.325521 (1.394 sec)
3.159... logprob:  0.632413, 0.305990 (1.394 sec)
3.160... logprob:  0.638897, 0.266927 (1.385 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.460595, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.310570e-03 [3.725492e-07] 
Layer 'conv1' biases: 4.212282e-07 [1.350108e-09] 
Layer 'conv2' weights[0]: 7.298245e-03 [3.697364e-07] 
Layer 'conv2' biases: 9.999998e-01 [8.795162e-09] 
Layer 'conv3' weights[0]: 7.297018e-03 [3.706397e-07] 
Layer 'conv3' biases: 9.558613e-06 [3.298069e-08] 
Layer 'conv4' weights[0]: 7.326579e-03 [3.753232e-07] 
Layer 'conv4' biases: 1.000003e+00 [3.442797e-07] 
Layer 'conv5' weights[0]: 7.334421e-03 [2.270810e-06] 
Layer 'conv5' biases: 9.996062e-01 [2.414801e-06] 
Layer 'fc6' weights[0]: 7.524088e-03 [5.585340e-08] 
Layer 'fc6' biases: 9.999996e-01 [4.610150e-08] 
Layer 'fc7' weights[0]: 7.879156e-03 [1.125527e-07] 
Layer 'fc7' biases: 9.999775e-01 [1.410927e-07] 
Layer 'fc8' weights[0]: 3.130192e-03 [2.203232e-05] 
Layer 'fc8' biases: 4.746235e-03 [3.501279e-05] 
Train error last 800 batches: 0.659526
-------------------------------------------------------
Not saving because 0.460595 > 0.323801 (3.40: -8.65%)
======================================================= (2.372 sec)
3.161... logprob:  0.591479, 0.276042 (1.407 sec)
3.162... logprob:  0.850417, 0.367188 (1.412 sec)
3.163... logprob:  0.695412, 0.278646 (1.424 sec)
3.164... logprob:  0.684713, 0.299479 (1.417 sec)
3.165... logprob:  0.748170, 0.317708 (1.413 sec)
3.166... logprob:  0.643393, 0.290365 (1.444 sec)
3.167... logprob:  0.600824, 0.248698 (1.430 sec)
3.168... logprob:  0.592128, 0.235677 (1.417 sec)
3.169... logprob:  0.611610, 0.266927 (1.452 sec)
3.170... logprob:  0.691601, 0.307292 (1.398 sec)
3.171... logprob:  0.723577, 0.316406 (1.410 sec)
3.172... logprob:  0.611618, 0.270833 (1.412 sec)
3.173... logprob:  0.686833, 0.296875 (1.416 sec)
3.174... logprob:  0.846162, 0.343750 (1.404 sec)
3.175... logprob:  0.677152, 0.290365 (1.457 sec)
3.176... logprob:  0.608867, 0.272135 (1.413 sec)
3.177... logprob:  0.461705, 0.213542 (1.420 sec)
3.178... logprob:  0.605693, 0.265625 (1.453 sec)
3.179... logprob:  0.552183, 0.238281 (1.420 sec)
3.180... logprob:  0.713499, 0.326823 (1.414 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.469101, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.303269e-03 [3.733323e-07] 
Layer 'conv1' biases: 4.307630e-07 [1.404833e-09] 
Layer 'conv2' weights[0]: 7.290950e-03 [3.692459e-07] 
Layer 'conv2' biases: 9.999998e-01 [8.307761e-09] 
Layer 'conv3' weights[0]: 7.289738e-03 [3.705335e-07] 
Layer 'conv3' biases: 9.737343e-06 [3.321921e-08] 
Layer 'conv4' weights[0]: 7.319188e-03 [3.752428e-07] 
Layer 'conv4' biases: 1.000003e+00 [3.326009e-07] 
Layer 'conv5' weights[0]: 7.327157e-03 [2.165844e-06] 
Layer 'conv5' biases: 9.996026e-01 [2.292937e-06] 
Layer 'fc6' weights[0]: 7.523298e-03 [5.614860e-08] 
Layer 'fc6' biases: 9.999996e-01 [4.664776e-08] 
Layer 'fc7' weights[0]: 7.878379e-03 [1.166573e-07] 
Layer 'fc7' biases: 9.999759e-01 [1.531931e-07] 
Layer 'fc8' weights[0]: 3.101924e-03 [2.456375e-05] 
Layer 'fc8' biases: 4.687243e-03 [4.714569e-05] 
Train error last 800 batches: 0.659866
-------------------------------------------------------
Not saving because 0.469101 > 0.323801 (3.40: -8.65%)
======================================================= (2.421 sec)
3.181... logprob:  0.831401, 0.350260 (1.421 sec)
3.182... logprob:  0.557531, 0.256510 (1.417 sec)
3.183... logprob:  0.579128, 0.287760 (1.410 sec)
3.184... logprob:  0.719145, 0.281250 (1.412 sec)
3.185... logprob:  0.591753, 0.287760 (1.394 sec)
3.186... logprob:  0.599324, 0.250000 (1.391 sec)
3.187... logprob:  0.641370, 0.295573 (1.398 sec)
3.188... logprob:  0.629362, 0.282552 (1.390 sec)
3.189... logprob:  0.659079, 0.268229 (1.385 sec)
3.190... logprob:  0.574375, 0.247396 (1.429 sec)
3.191... logprob:  0.700478, 0.334635 (1.402 sec)
3.192... logprob:  0.714601, 0.299479 (1.407 sec)
3.193... logprob:  0.503296, 0.221354 (1.414 sec)
3.194... logprob:  0.707977, 0.308594 (1.406 sec)
3.195... logprob:  0.508430, 0.220052 (1.393 sec)
3.196... logprob:  0.693245, 0.296875 (1.385 sec)
3.197... logprob:  0.737042, 0.305990 (1.394 sec)
3.198... logprob:  0.542199, 0.217448 (1.398 sec)
3.199... logprob:  0.559194, 0.250000 (1.382 sec)
3.200... logprob:  0.690729, 0.307292 (1.435 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.479012, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.295940e-03 [3.714649e-07] 
Layer 'conv1' biases: 4.360247e-07 [1.425787e-09] 
Layer 'conv2' weights[0]: 7.283705e-03 [3.679865e-07] 
Layer 'conv2' biases: 9.999998e-01 [7.023109e-09] 
Layer 'conv3' weights[0]: 7.282488e-03 [3.673724e-07] 
Layer 'conv3' biases: 9.900165e-06 [2.383973e-08] 
Layer 'conv4' weights[0]: 7.311891e-03 [3.719510e-07] 
Layer 'conv4' biases: 1.000003e+00 [2.517513e-07] 
Layer 'conv5' weights[0]: 7.319878e-03 [1.843209e-06] 
Layer 'conv5' biases: 9.995986e-01 [1.979417e-06] 
Layer 'fc6' weights[0]: 7.522532e-03 [5.540605e-08] 
Layer 'fc6' biases: 9.999995e-01 [4.578861e-08] 
Layer 'fc7' weights[0]: 7.877602e-03 [1.095394e-07] 
Layer 'fc7' biases: 9.999757e-01 [1.216503e-07] 
Layer 'fc8' weights[0]: 3.123287e-03 [1.958293e-05] 
Layer 'fc8' biases: 4.759562e-03 [2.829452e-05] 
Train error last 800 batches: 0.659496
-------------------------------------------------------
Not saving because 0.479012 > 0.323801 (3.40: -8.65%)
======================================================= (2.367 sec)
3.201... logprob:  0.687749, 0.292969 (1.408 sec)
3.202... logprob:  0.731423, 0.307292 (1.393 sec)
3.203... logprob:  0.584446, 0.273438 (1.433 sec)
3.204... logprob:  0.611089, 0.279948 (1.380 sec)
3.205... logprob:  0.546151, 0.239583 (1.395 sec)
3.206... logprob:  0.573906, 0.268229 (1.391 sec)
3.207... logprob:  0.580677, 0.257812 (1.392 sec)
3.208... logprob:  0.710070, 0.319010 (1.400 sec)
3.209... logprob:  0.526621, 0.260417 (1.415 sec)
3.210... logprob:  0.833593, 0.343750 (1.409 sec)
3.211... logprob:  0.698693, 0.303385 (1.413 sec)
3.212... logprob:  0.678192, 0.300781 (1.408 sec)
3.213... logprob:  0.739545, 0.317708 (1.457 sec)
3.214... logprob:  0.717310, 0.309896 (1.415 sec)
3.215... logprob:  0.634644, 0.277344 (1.410 sec)
3.216... logprob:  0.811625, 0.328125 (1.461 sec)
3.217... logprob:  0.578851, 0.264323 (1.402 sec)
3.218... logprob:  0.578869, 0.266927 (1.436 sec)
3.219... logprob:  0.769636, 0.352865 (1.408 sec)
3.220... logprob:  0.665410, 0.266927 (1.415 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.577888, 0.171875 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.288673e-03 [3.747294e-07] 
Layer 'conv1' biases: 4.421434e-07 [1.465157e-09] 
Layer 'conv2' weights[0]: 7.276420e-03 [3.687970e-07] 
Layer 'conv2' biases: 9.999998e-01 [1.072507e-08] 
Layer 'conv3' weights[0]: 7.275209e-03 [3.698615e-07] 
Layer 'conv3' biases: 1.001085e-05 [3.670668e-08] 
Layer 'conv4' weights[0]: 7.304570e-03 [3.754483e-07] 
Layer 'conv4' biases: 1.000003e+00 [3.699455e-07] 
Layer 'conv5' weights[0]: 7.312667e-03 [2.512255e-06] 
Layer 'conv5' biases: 9.995947e-01 [2.671557e-06] 
Layer 'fc6' weights[0]: 7.521773e-03 [6.170931e-08] 
Layer 'fc6' biases: 9.999996e-01 [5.460148e-08] 
Layer 'fc7' weights[0]: 7.876817e-03 [1.301148e-07] 
Layer 'fc7' biases: 9.999750e-01 [1.861984e-07] 
Layer 'fc8' weights[0]: 3.076691e-03 [2.403480e-05] 
Layer 'fc8' biases: 4.503338e-03 [3.834142e-05] 
Train error last 800 batches: 0.659717
-------------------------------------------------------
Not saving because 0.577888 > 0.323801 (3.40: -8.65%)
======================================================= (2.371 sec)
3.221... logprob:  0.601045, 0.269531 (1.399 sec)
3.222... logprob:  0.730716, 0.345052 (1.453 sec)
3.223... logprob:  0.822307, 0.342448 (1.426 sec)
3.224... logprob:  0.676378, 0.303385 (1.423 sec)
3.225... logprob:  0.621985, 0.260417 (1.442 sec)
3.226... logprob:  0.590492, 0.259115 (1.414 sec)
3.227... logprob:  0.666051, 0.300781 (1.407 sec)
3.228... logprob:  0.648989, 0.299479 (1.411 sec)
3.229... logprob:  0.569505, 0.246094 (1.408 sec)
3.230... logprob:  0.622993, 0.266927 (1.417 sec)
3.231... logprob:  0.676909, 0.296875 (1.400 sec)
3.232... logprob:  0.748800, 0.339844 (1.452 sec)
3.233... logprob:  0.734439, 0.324219 (1.429 sec)
3.234... logprob:  0.663750, 0.305990 (1.408 sec)
3.235... logprob:  0.648814, 0.272135 (1.460 sec)
3.236... logprob:  0.652022, 0.281250 (1.394 sec)
3.237... logprob:  0.547017, 0.251302 (1.420 sec)
3.238... logprob:  0.614763, 0.239583 (1.407 sec)
3.239... logprob:  0.639769, 0.296875 (1.418 sec)
3.240... logprob:  0.772097, 0.332031 (1.395 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.473323, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.281370e-03 [3.720725e-07] 
Layer 'conv1' biases: 4.425869e-07 [1.487893e-09] 
Layer 'conv2' weights[0]: 7.269135e-03 [3.679596e-07] 
Layer 'conv2' biases: 9.999998e-01 [7.060661e-09] 
Layer 'conv3' weights[0]: 7.267925e-03 [3.675174e-07] 
Layer 'conv3' biases: 1.007095e-05 [2.745924e-08] 
Layer 'conv4' weights[0]: 7.297255e-03 [3.709766e-07] 
Layer 'conv4' biases: 1.000003e+00 [2.780051e-07] 
Layer 'conv5' weights[0]: 7.305323e-03 [1.856297e-06] 
Layer 'conv5' biases: 9.995900e-01 [1.939114e-06] 
Layer 'fc6' weights[0]: 7.520977e-03 [5.490187e-08] 
Layer 'fc6' biases: 9.999996e-01 [4.520505e-08] 
Layer 'fc7' weights[0]: 7.876045e-03 [1.095203e-07] 
Layer 'fc7' biases: 9.999748e-01 [1.215283e-07] 
Layer 'fc8' weights[0]: 3.115970e-03 [2.015064e-05] 
Layer 'fc8' biases: 4.622088e-03 [2.532301e-05] 
Train error last 800 batches: 0.659581
-------------------------------------------------------
Not saving because 0.473323 > 0.323801 (3.40: -8.65%)
======================================================= (2.368 sec)
3.241... logprob:  0.760311, 0.335938 (1.457 sec)
3.242... logprob:  0.589788, 0.272135 (1.434 sec)
3.243... logprob:  0.630892, 0.270833 (1.427 sec)
3.244... logprob:  0.518732, 0.253906 (1.439 sec)
3.245... logprob:  0.745638, 0.315104 (1.419 sec)
3.246... logprob:  0.685452, 0.294271 (1.409 sec)
3.247... logprob:  0.656690, 0.307292 (1.408 sec)
3.248... logprob:  0.525781, 0.239583 (1.407 sec)
3.249... logprob:  0.739693, 0.341146 (1.425 sec)
3.250... logprob:  0.799430, 0.324219 (1.402 sec)
3.251... logprob:  0.604795, 0.247396 (1.450 sec)
3.252... logprob:  0.648209, 0.307292 (1.422 sec)
3.253... logprob:  0.635967, 0.295573 (1.409 sec)
3.254... logprob:  0.639953, 0.294271 (1.465 sec)
3.255... logprob:  0.549765, 0.225260 (1.393 sec)
3.256... logprob:  0.513248, 0.226562 (1.415 sec)
3.257... logprob:  0.559440, 0.261719 (1.437 sec)
3.258... logprob:  0.540834, 0.250000 (1.412 sec)
3.259... logprob:  0.639956, 0.302083 (1.393 sec)
3.260... logprob:  0.547469, 0.253906 (1.455 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.480107, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.274082e-03 [3.692952e-07] 
Layer 'conv1' biases: 4.429785e-07 [1.489469e-09] 
Layer 'conv2' weights[0]: 7.261868e-03 [3.685885e-07] 
Layer 'conv2' biases: 9.999998e-01 [1.195529e-08] 
Layer 'conv3' weights[0]: 7.260610e-03 [3.695881e-07] 
Layer 'conv3' biases: 1.016825e-05 [3.714663e-08] 
Layer 'conv4' weights[0]: 7.289981e-03 [3.773013e-07] 
Layer 'conv4' biases: 1.000003e+00 [4.148364e-07] 
Layer 'conv5' weights[0]: 7.298317e-03 [2.568486e-06] 
Layer 'conv5' biases: 9.995845e-01 [2.752762e-06] 
Layer 'fc6' weights[0]: 7.520193e-03 [6.150771e-08] 
Layer 'fc6' biases: 9.999995e-01 [5.479076e-08] 
Layer 'fc7' weights[0]: 7.875273e-03 [1.309656e-07] 
Layer 'fc7' biases: 9.999751e-01 [2.054221e-07] 
Layer 'fc8' weights[0]: 3.174366e-03 [2.673304e-05] 
Layer 'fc8' biases: 4.913844e-03 [5.497660e-05] 
Train error last 800 batches: 0.659511
-------------------------------------------------------
Not saving because 0.480107 > 0.323801 (3.40: -8.65%)
======================================================= (2.371 sec)
3.261... logprob:  0.671222, 0.298177 (1.432 sec)
3.262... logprob:  0.740171, 0.322917 (1.423 sec)
3.263... logprob:  0.651610, 0.289062 (1.440 sec)
3.264... logprob:  0.589206, 0.264323 (1.425 sec)
3.265... logprob:  0.672950, 0.302083 (1.409 sec)
3.266... logprob:  0.692557, 0.291667 (1.407 sec)
3.267... logprob:  0.597024, 0.251302 (1.411 sec)
3.268... logprob:  0.728450, 0.309896 (1.421 sec)
3.269... logprob:  0.781108, 0.338542 (1.399 sec)
3.270... logprob:  0.748899, 0.317708 (1.459 sec)
3.271... logprob:  0.585100, 0.248698 (1.422 sec)
3.272... logprob:  0.602718, 0.243490 (1.415 sec)
3.273... logprob:  0.803975, 0.315104 (1.461 sec)
3.274... logprob:  0.705277, 0.289062 (1.397 sec)
3.275... logprob:  0.763944, 0.307292 (1.414 sec)
3.276... logprob:  0.622089, 0.260417 (1.406 sec)
3.277... logprob:  0.631202, 0.281250 (1.414 sec)
3.278... logprob:  0.566429, 0.268229 (1.418 sec)
3.279... logprob:  0.518092, 0.234375 (1.456 sec)
3.280... logprob:  0.582499, 0.278646 (1.401 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.496818, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.266820e-03 [3.704852e-07] 
Layer 'conv1' biases: 4.445760e-07 [1.447584e-09] 
Layer 'conv2' weights[0]: 7.254595e-03 [3.687564e-07] 
Layer 'conv2' biases: 9.999998e-01 [1.091170e-08] 
Layer 'conv3' weights[0]: 7.253368e-03 [3.685456e-07] 
Layer 'conv3' biases: 1.028579e-05 [3.388882e-08] 
Layer 'conv4' weights[0]: 7.282654e-03 [3.746372e-07] 
Layer 'conv4' biases: 1.000003e+00 [3.629665e-07] 
Layer 'conv5' weights[0]: 7.291235e-03 [2.200681e-06] 
Layer 'conv5' biases: 9.995777e-01 [2.326726e-06] 
Layer 'fc6' weights[0]: 7.519460e-03 [5.629844e-08] 
Layer 'fc6' biases: 9.999995e-01 [4.735756e-08] 
Layer 'fc7' weights[0]: 7.874519e-03 [1.157304e-07] 
Layer 'fc7' biases: 9.999735e-01 [1.525316e-07] 
Layer 'fc8' weights[0]: 3.116303e-03 [2.334426e-05] 
Layer 'fc8' biases: 4.535425e-03 [4.395577e-05] 
Train error last 800 batches: 0.659631
-------------------------------------------------------
Not saving because 0.496818 > 0.323801 (3.40: -8.65%)
======================================================= (2.363 sec)
3.281... logprob:  0.637342, 0.282552 (1.427 sec)
3.282... logprob:  0.655596, 0.265625 (1.416 sec)
3.283... logprob:  0.647299, 0.255208 (1.418 sec)
3.284... logprob:  0.572480, 0.264323 (1.408 sec)
3.285... logprob:  0.688450, 0.290365 (1.433 sec)
3.286... logprob:  0.646717, 0.295573 (1.430 sec)
3.287... logprob:  0.552037, 0.246094 (1.427 sec)
3.288... logprob:  0.579204, 0.244792 (1.427 sec)
3.289... logprob:  0.732317, 0.309896 (1.439 sec)
3.290... logprob:  0.699051, 0.313802 (1.399 sec)
3.291... logprob:  0.743277, 0.283854 (1.409 sec)
3.292... logprob:  0.704665, 0.291667 (1.414 sec)
3.293... logprob:  0.683055, 0.289062 (1.416 sec)
3.294... logprob:  0.605215, 0.273437 (1.396 sec)
3.295... logprob:  0.597748, 0.292969 (1.451 sec)
3.296... logprob:  0.585962, 0.261719 (1.422 sec)
3.297... logprob:  0.567431, 0.274740 (1.420 sec)
3.298... logprob:  0.630431, 0.269531 (1.456 sec)
3.299... logprob:  0.544348, 0.266927 (1.394 sec)
3.300... logprob:  0.604798, 0.285156 (1.419 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.500663, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.259545e-03 [3.702667e-07] 
Layer 'conv1' biases: 4.563156e-07 [1.246286e-09] 
Layer 'conv2' weights[0]: 7.247349e-03 [3.669070e-07] 
Layer 'conv2' biases: 9.999998e-01 [8.574887e-09] 
Layer 'conv3' weights[0]: 7.246086e-03 [3.673849e-07] 
Layer 'conv3' biases: 1.034459e-05 [3.185887e-08] 
Layer 'conv4' weights[0]: 7.275417e-03 [3.734825e-07] 
Layer 'conv4' biases: 1.000003e+00 [3.620936e-07] 
Layer 'conv5' weights[0]: 7.284017e-03 [2.306070e-06] 
Layer 'conv5' biases: 9.995776e-01 [2.488336e-06] 
Layer 'fc6' weights[0]: 7.518699e-03 [5.776351e-08] 
Layer 'fc6' biases: 9.999996e-01 [4.966771e-08] 
Layer 'fc7' weights[0]: 7.873775e-03 [1.185828e-07] 
Layer 'fc7' biases: 9.999738e-01 [1.655131e-07] 
Layer 'fc8' weights[0]: 3.186580e-03 [2.497748e-05] 
Layer 'fc8' biases: 4.889472e-03 [4.318778e-05] 
Train error last 800 batches: 0.659399
-------------------------------------------------------
Not saving because 0.500663 > 0.323801 (3.40: -8.65%)
======================================================= (2.412 sec)
3.301... logprob:  0.681942, 0.320312 (1.415 sec)
3.302... logprob:  0.743589, 0.324219 (1.414 sec)
3.303... logprob:  0.747038, 0.337239 (1.400 sec)
3.304... logprob:  0.780052, 0.313802 (1.431 sec)
3.305... logprob:  0.677036, 0.281250 (1.430 sec)
3.306... logprob:  0.640470, 0.259115 (1.428 sec)
3.307... logprob:  0.633183, 0.239583 (1.438 sec)
3.308... logprob:  0.652960, 0.274740 (1.447 sec)
3.309... logprob:  0.637154, 0.304687 (1.405 sec)
3.310... logprob:  0.621498, 0.287760 (1.418 sec)
3.311... logprob:  0.745416, 0.305989 (1.427 sec)
3.312... logprob:  0.788567, 0.341146 (1.417 sec)
3.313... logprob:  0.569362, 0.230469 (1.419 sec)
3.314... logprob:  0.654253, 0.264323 (1.459 sec)
3.315... logprob:  0.672748, 0.329427 (1.431 sec)
3.316... logprob:  0.684328, 0.291667 (1.421 sec)
3.317... logprob:  0.576316, 0.255208 (1.469 sec)
3.318... logprob:  0.664148, 0.311198 (1.407 sec)
3.319... logprob:  0.622924, 0.281250 (1.416 sec)
3.320... logprob:  0.679529, 0.292969 (1.419 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.501760, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.252296e-03 [3.710897e-07] 
Layer 'conv1' biases: 4.663564e-07 [1.365277e-09] 
Layer 'conv2' weights[0]: 7.240041e-03 [3.665706e-07] 
Layer 'conv2' biases: 9.999998e-01 [7.724648e-09] 
Layer 'conv3' weights[0]: 7.238842e-03 [3.665885e-07] 
Layer 'conv3' biases: 1.045205e-05 [3.114693e-08] 
Layer 'conv4' weights[0]: 7.268171e-03 [3.716382e-07] 
Layer 'conv4' biases: 1.000004e+00 [3.260950e-07] 
Layer 'conv5' weights[0]: 7.277045e-03 [2.020048e-06] 
Layer 'conv5' biases: 9.995791e-01 [2.108872e-06] 
Layer 'fc6' weights[0]: 7.517905e-03 [5.531178e-08] 
Layer 'fc6' biases: 9.999995e-01 [4.564836e-08] 
Layer 'fc7' weights[0]: 7.872944e-03 [1.086588e-07] 
Layer 'fc7' biases: 9.999733e-01 [1.191181e-07] 
Layer 'fc8' weights[0]: 3.158960e-03 [1.772505e-05] 
Layer 'fc8' biases: 4.695661e-03 [1.805788e-05] 
Train error last 800 batches: 0.659713
-------------------------------------------------------
Not saving because 0.501760 > 0.323801 (3.40: -8.65%)
======================================================= (2.382 sec)
3.321... logprob:  0.634372, 0.263021 (1.423 sec)
3.322... logprob:  0.600522, 0.265625 (1.423 sec)
3.323... logprob:  0.597270, 0.281250 (1.466 sec)
3.324... logprob:  0.680900, 0.274740 (1.418 sec)
3.325... logprob:  0.631994, 0.300781 (1.430 sec)
3.326... logprob:  0.807015, 0.321615 (1.455 sec)
3.327... logprob:  0.728059, 0.322917 (1.418 sec)
3.328... logprob:  0.698809, 0.273438 (1.415 sec)
3.329... logprob:  0.665365, 0.263021 (1.419 sec)
3.330... logprob:  0.569848, 0.261719 (1.415 sec)
3.331... logprob:  0.622924, 0.259115 (1.411 sec)
3.332... logprob:  0.591378, 0.278646 (1.442 sec)
3.333... logprob:  0.559390, 0.256510 (1.439 sec)
3.334... logprob:  0.812083, 0.352865 (1.460 sec)
3.335... logprob:  0.587030, 0.255208 (1.433 sec)
3.336... logprob:  0.629444, 0.289062 (1.450 sec)
3.337... logprob:  0.751001, 0.309896 (1.410 sec)
3.338... logprob:  0.670079, 0.285156 (1.411 sec)
3.339... logprob:  0.747772, 0.330729 (1.429 sec)
3.340... logprob:  0.627071, 0.296875 (1.419 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.416462, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.245037e-03 [3.684981e-07] 
Layer 'conv1' biases: 4.760572e-07 [1.433021e-09] 
Layer 'conv2' weights[0]: 7.232854e-03 [3.660105e-07] 
Layer 'conv2' biases: 9.999998e-01 [9.633481e-09] 
Layer 'conv3' weights[0]: 7.231685e-03 [3.666406e-07] 
Layer 'conv3' biases: 1.055673e-05 [3.441839e-08] 
Layer 'conv4' weights[0]: 7.260823e-03 [3.713802e-07] 
Layer 'conv4' biases: 1.000005e+00 [3.348929e-07] 
Layer 'conv5' weights[0]: 7.270480e-03 [2.316788e-06] 
Layer 'conv5' biases: 9.995726e-01 [2.405546e-06] 
Layer 'fc6' weights[0]: 7.517110e-03 [5.767427e-08] 
Layer 'fc6' biases: 9.999996e-01 [4.942779e-08] 
Layer 'fc7' weights[0]: 7.872154e-03 [1.161984e-07] 
Layer 'fc7' biases: 9.999731e-01 [1.386103e-07] 
Layer 'fc8' weights[0]: 3.162442e-03 [2.014970e-05] 
Layer 'fc8' biases: 4.653730e-03 [2.947366e-05] 
Train error last 800 batches: 0.659250
-------------------------------------------------------
Not saving because 0.416462 > 0.323801 (3.40: -8.65%)
======================================================= (2.378 sec)
3.341... logprob:  0.664371, 0.274740 (1.422 sec)
3.342... logprob:  0.604640, 0.269531 (1.468 sec)
3.343... logprob:  0.651794, 0.261719 (1.438 sec)
3.344... logprob:  0.617048, 0.282552 (1.478 sec)
3.345... logprob:  0.654573, 0.265625 (1.439 sec)
3.346... logprob:  0.701070, 0.291667 (1.428 sec)
3.347... logprob:  0.634846, 0.278646 (1.474 sec)
3.348... logprob:  0.676611, 0.285156 (1.426 sec)
3.349... logprob:  0.663803, 0.263021 (1.430 sec)
3.350... logprob:  0.576823, 0.255208 (1.430 sec)
3.351... logprob:  0.672381, 0.289062 (1.421 sec)
3.352... logprob:  0.586447, 0.274740 (1.425 sec)
3.353... logprob:  0.677938, 0.303385 (1.487 sec)
3.354... logprob:  0.853226, 0.334635 (1.425 sec)
3.355... logprob:  0.636840, 0.295573 (1.444 sec)
3.356... logprob:  0.685883, 0.282552 (1.473 sec)
3.357... logprob:  0.532646, 0.227865 (1.423 sec)
3.358... logprob:  0.601346, 0.260417 (1.433 sec)
3.359... logprob:  0.746757, 0.361979 (1.426 sec)
3.360... logprob:  0.648018, 0.274740 (1.422 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.453790, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.237781e-03 [3.694662e-07] 
Layer 'conv1' biases: 4.738786e-07 [1.414065e-09] 
Layer 'conv2' weights[0]: 7.225630e-03 [3.666647e-07] 
Layer 'conv2' biases: 9.999998e-01 [9.012141e-09] 
Layer 'conv3' weights[0]: 7.224439e-03 [3.668506e-07] 
Layer 'conv3' biases: 1.070606e-05 [3.323679e-08] 
Layer 'conv4' weights[0]: 7.253629e-03 [3.706938e-07] 
Layer 'conv4' biases: 1.000005e+00 [3.125119e-07] 
Layer 'conv5' weights[0]: 7.263283e-03 [2.050278e-06] 
Layer 'conv5' biases: 9.995732e-01 [2.186536e-06] 
Layer 'fc6' weights[0]: 7.516304e-03 [5.412107e-08] 
Layer 'fc6' biases: 9.999996e-01 [4.400608e-08] 
Layer 'fc7' weights[0]: 7.871392e-03 [1.069217e-07] 
Layer 'fc7' biases: 9.999720e-01 [1.098060e-07] 
Layer 'fc8' weights[0]: 3.136896e-03 [1.760662e-05] 
Layer 'fc8' biases: 4.560151e-03 [1.635451e-05] 
Train error last 800 batches: 0.658528
-------------------------------------------------------
Not saving because 0.453790 > 0.323801 (3.40: -8.65%)
======================================================= (2.421 sec)
3.361... logprob:  0.605490, 0.263021 (1.434 sec)
3.362... logprob:  0.639417, 0.268229 (1.478 sec)
3.363... logprob:  0.659705, 0.303385 (1.431 sec)
3.364... logprob:  0.627408, 0.268229 (1.449 sec)
3.365... logprob:  0.687904, 0.289062 (1.458 sec)
3.366... logprob:  0.639796, 0.273437 (1.439 sec)
3.367... logprob:  0.605822, 0.279948 (1.440 sec)
3.368... logprob:  0.730405, 0.312500 (1.422 sec)
3.369... logprob:  0.593956, 0.268229 (1.418 sec)
3.370... logprob:  0.715408, 0.319010 (1.431 sec)
3.371... logprob:  0.637698, 0.283854 (1.454 sec)
3.372... logprob:  0.792646, 0.324219 (1.474 sec)
3.373... logprob:  0.558432, 0.250000 (1.445 sec)
3.374... logprob:  0.710390, 0.307292 (1.447 sec)
3.375... logprob:  0.688544, 0.295573 (1.456 sec)
3.376... logprob:  0.644570, 0.298177 (1.430 sec)
3.377... logprob:  0.556759, 0.226562 (1.419 sec)
3.378... logprob:  0.665081, 0.302083 (1.425 sec)
3.379... logprob:  0.650296, 0.266927 (1.428 sec)
3.380... logprob:  0.811666, 0.359375 (1.437 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.456074, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.230551e-03 [3.689778e-07] 
Layer 'conv1' biases: 4.781327e-07 [1.742100e-09] 
Layer 'conv2' weights[0]: 7.218337e-03 [3.656323e-07] 
Layer 'conv2' biases: 9.999998e-01 [9.198964e-09] 
Layer 'conv3' weights[0]: 7.217202e-03 [3.666183e-07] 
Layer 'conv3' biases: 1.083261e-05 [3.524825e-08] 
Layer 'conv4' weights[0]: 7.246365e-03 [3.708641e-07] 
Layer 'conv4' biases: 1.000005e+00 [3.344915e-07] 
Layer 'conv5' weights[0]: 7.255748e-03 [2.011907e-06] 
Layer 'conv5' biases: 9.995698e-01 [2.087709e-06] 
Layer 'fc6' weights[0]: 7.515531e-03 [5.548059e-08] 
Layer 'fc6' biases: 9.999995e-01 [4.606759e-08] 
Layer 'fc7' weights[0]: 7.870599e-03 [1.101785e-07] 
Layer 'fc7' biases: 9.999722e-01 [1.176162e-07] 
Layer 'fc8' weights[0]: 3.179213e-03 [1.829114e-05] 
Layer 'fc8' biases: 4.758833e-03 [1.643178e-05] 
Train error last 800 batches: 0.658231
-------------------------------------------------------
Not saving because 0.456074 > 0.323801 (3.40: -8.65%)
======================================================= (2.382 sec)
3.381... logprob:  0.674942, 0.291667 (1.467 sec)
3.382... logprob:  0.707264, 0.325521 (1.453 sec)
3.383... logprob:  0.635608, 0.270833 (1.438 sec)
3.384... logprob:  0.772560, 0.328125 (1.473 sec)
3.385... logprob:  0.750979, 0.343750 (1.428 sec)
3.386... logprob:  0.720788, 0.311198 (1.419 sec)
3.387... logprob:  0.622934, 0.304687 (1.428 sec)
3.388... logprob:  0.764340, 0.369792 (1.430 sec)
3.389... logprob:  0.610999, 0.261719 (1.429 sec)
3.390... logprob:  0.564993, 0.220052 (1.470 sec)
3.391... logprob:  0.551323, 0.246094 (1.438 sec)
3.392... logprob:  0.668456, 0.313802 (1.426 sec)
3.393... logprob:  0.602387, 0.217448 (1.479 sec)
3.394... logprob:  0.610428, 0.274740 (1.428 sec)
3.395... logprob:  0.582423, 0.266927 (1.427 sec)
3.396... logprob:  0.535167, 0.257812 (1.431 sec)
3.397... logprob:  0.681734, 0.270833 (1.420 sec)
3.398... logprob:  0.615483, 0.256510 (1.425 sec)
3.399... logprob:  0.691475, 0.285156 (1.483 sec)
3.400... logprob:  0.759899, 0.296875 (1.426 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.563758, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.223314e-03 [3.678253e-07] 
Layer 'conv1' biases: 4.870796e-07 [1.415662e-09] 
Layer 'conv2' weights[0]: 7.211145e-03 [3.648782e-07] 
Layer 'conv2' biases: 9.999998e-01 [8.540221e-09] 
Layer 'conv3' weights[0]: 7.209997e-03 [3.654124e-07] 
Layer 'conv3' biases: 1.093244e-05 [3.195570e-08] 
Layer 'conv4' weights[0]: 7.239096e-03 [3.692616e-07] 
Layer 'conv4' biases: 1.000004e+00 [2.990568e-07] 
Layer 'conv5' weights[0]: 7.248188e-03 [1.949349e-06] 
Layer 'conv5' biases: 9.995692e-01 [1.985838e-06] 
Layer 'fc6' weights[0]: 7.514757e-03 [5.628321e-08] 
Layer 'fc6' biases: 9.999995e-01 [4.746958e-08] 
Layer 'fc7' weights[0]: 7.869820e-03 [1.144490e-07] 
Layer 'fc7' biases: 9.999717e-01 [1.261335e-07] 
Layer 'fc8' weights[0]: 3.224459e-03 [2.021788e-05] 
Layer 'fc8' biases: 4.911125e-03 [2.155920e-05] 
Train error last 800 batches: 0.657770
-------------------------------------------------------
Not saving because 0.563758 > 0.323801 (3.40: -8.65%)
======================================================= (2.367 sec)
3.401... logprob:  0.625866, 0.263021 (1.439 sec)
3.402... logprob:  0.696494, 0.307292 (1.481 sec)
3.403... logprob:  0.721143, 0.322917 (1.433 sec)
3.404... logprob:  0.729975, 0.320312 (1.427 sec)
3.405... logprob:  0.788651, 0.350260 (1.432 sec)
3.406... logprob:  0.608521, 0.263021 (1.424 sec)
3.407... logprob:  0.684579, 0.300781 (1.429 sec)
3.408... logprob:  0.533112, 0.240885 (1.473 sec)
3.409... logprob:  0.623234, 0.250000 (1.432 sec)
3.410... logprob:  0.790301, 0.309896 (1.464 sec)
3.411... logprob:  0.640903, 0.289062 (1.463 sec)
3.412... logprob:  0.760972, 0.316406 (1.429 sec)
3.413... logprob:  0.731804, 0.319010 (1.434 sec)
3.414... logprob:  0.633335, 0.269531 (1.423 sec)
3.415... logprob:  0.616599, 0.276042 (1.417 sec)
3.416... logprob:  0.681091, 0.290365 (1.436 sec)
3.417... logprob:  0.657364, 0.294271 (1.453 sec)
3.418... logprob:  0.606040, 0.252604 (1.442 sec)
3.419... logprob:  0.596256, 0.260417 (1.444 sec)
3.420... logprob:  0.619033, 0.265625 (1.448 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.521795, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.216066e-03 [3.662718e-07] 
Layer 'conv1' biases: 4.925696e-07 [1.594779e-09] 
Layer 'conv2' weights[0]: 7.203922e-03 [3.648153e-07] 
Layer 'conv2' biases: 9.999998e-01 [9.089028e-09] 
Layer 'conv3' weights[0]: 7.202837e-03 [3.649955e-07] 
Layer 'conv3' biases: 1.105512e-05 [3.095702e-08] 
Layer 'conv4' weights[0]: 7.231879e-03 [3.701863e-07] 
Layer 'conv4' biases: 1.000003e+00 [3.636943e-07] 
Layer 'conv5' weights[0]: 7.241023e-03 [2.156266e-06] 
Layer 'conv5' biases: 9.995651e-01 [2.242398e-06] 
Layer 'fc6' weights[0]: 7.513963e-03 [6.168853e-08] 
Layer 'fc6' biases: 9.999996e-01 [5.533508e-08] 
Layer 'fc7' weights[0]: 7.869000e-03 [1.341072e-07] 
Layer 'fc7' biases: 9.999703e-01 [1.974978e-07] 
Layer 'fc8' weights[0]: 3.197301e-03 [2.777998e-05] 
Layer 'fc8' biases: 4.763055e-03 [5.194693e-05] 
Train error last 800 batches: 0.658005
-------------------------------------------------------
Not saving because 0.521795 > 0.323801 (3.40: -8.65%)
======================================================= (2.351 sec)
3.421... logprob:  0.602972, 0.294271 (1.455 sec)
3.422... logprob:  0.684379, 0.281250 (1.436 sec)
3.423... logprob:  0.644207, 0.278646 (1.421 sec)
3.424... logprob:  0.594985, 0.282552 (1.422 sec)
3.425... logprob:  0.556358, 0.236979 (1.432 sec)
3.426... logprob:  0.682797, 0.326823 (1.438 sec)
3.427... logprob:  0.751274, 0.311198 (1.458 sec)
3.428... logprob:  0.788925, 0.329427 (1.443 sec)
3.429... logprob:  0.678268, 0.302083 (1.440 sec)
3.430... logprob:  0.561756, 0.260417 (1.470 sec)
3.431... logprob:  0.754370, 0.289062 (1.425 sec)
3.432... logprob:  0.609186, 0.259115 (1.423 sec)
3.433... logprob:  0.509960, 0.233073 (1.426 sec)
3.434... logprob:  0.772847, 0.348958 (1.431 sec)
3.435... logprob:  0.798590, 0.330729 (1.424 sec)
3.436... logprob:  0.627021, 0.289062 (1.469 sec)
3.437... logprob:  0.704898, 0.328125 (1.443 sec)
3.438... logprob:  0.796673, 0.360677 (1.424 sec)
3.439... logprob:  0.627645, 0.273437 (1.483 sec)
3.440... logprob:  0.678216, 0.277344 (1.424 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.463790, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.208849e-03 [3.687764e-07] 
Layer 'conv1' biases: 4.963912e-07 [1.568204e-09] 
Layer 'conv2' weights[0]: 7.196773e-03 [3.651230e-07] 
Layer 'conv2' biases: 9.999998e-01 [9.904208e-09] 
Layer 'conv3' weights[0]: 7.195590e-03 [3.659093e-07] 
Layer 'conv3' biases: 1.122222e-05 [3.730790e-08] 
Layer 'conv4' weights[0]: 7.224611e-03 [3.731148e-07] 
Layer 'conv4' biases: 1.000003e+00 [4.119199e-07] 
Layer 'conv5' weights[0]: 7.233976e-03 [2.541874e-06] 
Layer 'conv5' biases: 9.995626e-01 [2.694695e-06] 
Layer 'fc6' weights[0]: 7.513172e-03 [5.904703e-08] 
Layer 'fc6' biases: 9.999995e-01 [5.152678e-08] 
Layer 'fc7' weights[0]: 7.868215e-03 [1.224581e-07] 
Layer 'fc7' biases: 9.999700e-01 [1.590683e-07] 
Layer 'fc8' weights[0]: 3.191905e-03 [2.127412e-05] 
Layer 'fc8' biases: 4.701087e-03 [2.945109e-05] 
Train error last 800 batches: 0.657998
-------------------------------------------------------
Not saving because 0.463790 > 0.323801 (3.40: -8.65%)
======================================================= (2.368 sec)
3.441... logprob:  0.658237, 0.286458 (1.429 sec)
3.442... logprob:  0.632976, 0.292969 (1.438 sec)
3.443... logprob:  0.665930, 0.299479 (1.433 sec)
3.444... logprob:  0.640498, 0.278646 (1.426 sec)
3.445... logprob:  0.616350, 0.276042 (1.474 sec)
3.446... logprob:  0.630605, 0.307292 (1.431 sec)
3.447... logprob:  0.788637, 0.351562 (1.436 sec)
3.448... logprob:  0.558271, 0.244792 (1.491 sec)
3.449... logprob:  0.620781, 0.274740 (1.424 sec)
3.450... logprob:  0.517914, 0.230469 (1.429 sec)
3.451... logprob:  0.681329, 0.325521 (1.428 sec)
3.452... logprob:  0.736642, 0.326823 (1.424 sec)
3.453... logprob:  0.657142, 0.290364 (1.426 sec)
3.454... logprob:  0.641716, 0.265625 (1.478 sec)
3.455... logprob:  0.686263, 0.305990 (1.428 sec)
3.456... logprob:  0.645177, 0.273437 (1.443 sec)
3.457... logprob:  0.635860, 0.312500 (1.470 sec)
3.458... logprob:  0.579778, 0.250000 (1.428 sec)
3.459... logprob:  0.689057, 0.273438 (1.434 sec)
3.460... logprob:  0.543347, 0.266927 (1.421 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.434315, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.201669e-03 [3.671532e-07] 
Layer 'conv1' biases: 5.040287e-07 [1.239792e-09] 
Layer 'conv2' weights[0]: 7.189553e-03 [3.626922e-07] 
Layer 'conv2' biases: 9.999998e-01 [6.699892e-09] 
Layer 'conv3' weights[0]: 7.188402e-03 [3.634276e-07] 
Layer 'conv3' biases: 1.131811e-05 [2.902528e-08] 
Layer 'conv4' weights[0]: 7.217403e-03 [3.681695e-07] 
Layer 'conv4' biases: 1.000003e+00 [2.886878e-07] 
Layer 'conv5' weights[0]: 7.226760e-03 [2.017290e-06] 
Layer 'conv5' biases: 9.995602e-01 [2.044293e-06] 
Layer 'fc6' weights[0]: 7.512377e-03 [5.572716e-08] 
Layer 'fc6' biases: 9.999996e-01 [4.636100e-08] 
Layer 'fc7' weights[0]: 7.867467e-03 [1.136818e-07] 
Layer 'fc7' biases: 9.999708e-01 [1.387836e-07] 
Layer 'fc8' weights[0]: 3.265119e-03 [1.927602e-05] 
Layer 'fc8' biases: 5.035133e-03 [3.118109e-05] 
Train error last 800 batches: 0.657524
-------------------------------------------------------
Not saving because 0.434315 > 0.323801 (3.40: -8.65%)
======================================================= (2.381 sec)
3.461... logprob:  0.638540, 0.273437 (1.426 sec)
3.462... logprob:  0.743168, 0.305990 (1.432 sec)
3.463... logprob:  0.706135, 0.350260 (1.470 sec)
3.464... logprob:  0.652170, 0.278646 (1.440 sec)
3.465... logprob:  0.639060, 0.264323 (1.448 sec)
3.466... logprob:  0.577823, 0.234375 (1.455 sec)
3.467... logprob:  0.578486, 0.282552 (1.445 sec)
3.468... logprob:  0.651708, 0.298177 (1.435 sec)
3.469... logprob:  0.663059, 0.285156 (1.422 sec)
3.470... logprob:  0.648311, 0.287760 (1.424 sec)
3.471... logprob:  0.735864, 0.294271 (1.434 sec)
3.472... logprob:  0.605810, 0.252604 (1.447 sec)
3.473... logprob:  0.571423, 0.253906 (1.454 sec)
3.474... logprob:  0.803187, 0.359375 (1.446 sec)
3.475... logprob:  0.713506, 0.308594 (1.439 sec)
3.476... logprob:  0.689940, 0.316406 (1.467 sec)
3.477... logprob:  0.657339, 0.300781 (1.427 sec)
3.478... logprob:  0.710124, 0.286458 (1.417 sec)
3.479... logprob:  0.525039, 0.235677 (1.428 sec)
3.480... logprob:  0.759691, 0.325521 (1.428 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.475872, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.194513e-03 [3.661301e-07] 
Layer 'conv1' biases: 5.022985e-07 [1.320200e-09] 
Layer 'conv2' weights[0]: 7.182388e-03 [3.641414e-07] 
Layer 'conv2' biases: 9.999998e-01 [9.325170e-09] 
Layer 'conv3' weights[0]: 7.181138e-03 [3.638473e-07] 
Layer 'conv3' biases: 1.134362e-05 [3.161641e-08] 
Layer 'conv4' weights[0]: 7.210215e-03 [3.697959e-07] 
Layer 'conv4' biases: 1.000005e+00 [3.658603e-07] 
Layer 'conv5' weights[0]: 7.220125e-03 [2.491597e-06] 
Layer 'conv5' biases: 9.995568e-01 [2.711727e-06] 
Layer 'fc6' weights[0]: 7.511624e-03 [5.893700e-08] 
Layer 'fc6' biases: 9.999995e-01 [5.151445e-08] 
Layer 'fc7' weights[0]: 7.866663e-03 [1.208676e-07] 
Layer 'fc7' biases: 9.999698e-01 [1.541213e-07] 
Layer 'fc8' weights[0]: 3.226808e-03 [2.087290e-05] 
Layer 'fc8' biases: 4.819801e-03 [2.890978e-05] 
Train error last 800 batches: 0.657630
-------------------------------------------------------
Not saving because 0.475872 > 0.323801 (3.40: -8.65%)
======================================================= (2.402 sec)
3.481... logprob:  0.849913, 0.354167 (1.434 sec)
3.482... logprob:  0.723657, 0.309896 (1.478 sec)
3.483... logprob:  0.637714, 0.265625 (1.446 sec)
3.484... logprob:  0.637915, 0.274740 (1.428 sec)
3.485... logprob:  0.631013, 0.283854 (1.478 sec)
3.486... logprob:  0.639056, 0.257812 (1.443 sec)
3.487... logprob:  0.723700, 0.302083 (1.419 sec)
3.488... logprob:  0.677287, 0.285156 (1.434 sec)
3.489... logprob:  0.658923, 0.320312 (1.423 sec)
3.490... logprob:  0.676352, 0.305990 (1.428 sec)
3.491... logprob:  0.551290, 0.259115 (1.475 sec)
3.492... logprob:  0.686807, 0.309896 (1.436 sec)
3.493... logprob:  0.625288, 0.289062 (1.428 sec)
3.494... logprob:  0.646970, 0.285156 (1.477 sec)
3.495... logprob:  0.545764, 0.225260 (1.425 sec)
3.496... logprob:  0.744614, 0.352865 (1.428 sec)
3.497... logprob:  0.607844, 0.289062 (1.426 sec)
3.498... logprob:  0.714057, 0.286458 (1.427 sec)
3.499... logprob:  0.741295, 0.316406 (1.424 sec)
3.500... logprob:  0.609672, 0.286458 (1.488 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.382822, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.187287e-03 [3.667591e-07] 
Layer 'conv1' biases: 5.066107e-07 [1.407404e-09] 
Layer 'conv2' weights[0]: 7.175237e-03 [3.640474e-07] 
Layer 'conv2' biases: 9.999998e-01 [9.056311e-09] 
Layer 'conv3' weights[0]: 7.173970e-03 [3.633083e-07] 
Layer 'conv3' biases: 1.147751e-05 [2.878872e-08] 
Layer 'conv4' weights[0]: 7.203042e-03 [3.689555e-07] 
Layer 'conv4' biases: 1.000004e+00 [3.172666e-07] 
Layer 'conv5' weights[0]: 7.213031e-03 [1.989308e-06] 
Layer 'conv5' biases: 9.995491e-01 [2.097335e-06] 
Layer 'fc6' weights[0]: 7.510872e-03 [5.531363e-08] 
Layer 'fc6' biases: 9.999995e-01 [4.609021e-08] 
Layer 'fc7' weights[0]: 7.865923e-03 [1.122682e-07] 
Layer 'fc7' biases: 9.999697e-01 [1.298932e-07] 
Layer 'fc8' weights[0]: 3.254656e-03 [1.872829e-05] 
Layer 'fc8' biases: 4.959411e-03 [2.437085e-05] 
Train error last 800 batches: 0.657740
-------------------------------------------------------
Not saving because 0.382822 > 0.323801 (3.40: -8.65%)
======================================================= (2.387 sec)
3.501... logprob:  0.542651, 0.223958 (1.430 sec)
3.502... logprob:  0.692059, 0.287760 (1.448 sec)
3.503... logprob:  0.708434, 0.329427 (1.483 sec)
3.504... logprob:  0.753188, 0.317708 (1.428 sec)
3.505... logprob:  0.716227, 0.313802 (1.429 sec)
3.506... logprob:  0.772103, 0.337240 (1.430 sec)
3.507... logprob:  0.669226, 0.272135 (1.419 sec)
3.508... logprob:  0.615893, 0.264323 (1.426 sec)
3.509... logprob:  0.630404, 0.277344 (1.472 sec)
3.510... logprob:  0.612645, 0.279948 (1.438 sec)
3.511... logprob:  0.717186, 0.347656 (1.443 sec)
3.512... logprob:  0.686864, 0.266927 (1.467 sec)
3.513... logprob:  0.576955, 0.246094 (1.440 sec)
3.514... logprob:  0.619536, 0.252604 (1.432 sec)
3.515... logprob:  0.690073, 0.320313 (1.423 sec)
3.516... logprob:  0.601729, 0.269531 (1.426 sec)
3.517... logprob:  0.815743, 0.322917 (1.430 sec)
3.518... logprob:  0.644733, 0.300781 (1.453 sec)
3.519... logprob:  0.810491, 0.321615 (1.449 sec)
3.520... logprob:  0.670175, 0.299479 (1.449 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.517984, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.180124e-03 [3.660417e-07] 
Layer 'conv1' biases: 5.094619e-07 [1.709147e-09] 
Layer 'conv2' weights[0]: 7.167997e-03 [3.630175e-07] 
Layer 'conv2' biases: 9.999998e-01 [9.210165e-09] 
Layer 'conv3' weights[0]: 7.166800e-03 [3.635388e-07] 
Layer 'conv3' biases: 1.160308e-05 [3.542359e-08] 
Layer 'conv4' weights[0]: 7.195871e-03 [3.672209e-07] 
Layer 'conv4' biases: 1.000005e+00 [3.234914e-07] 
Layer 'conv5' weights[0]: 7.206044e-03 [2.035282e-06] 
Layer 'conv5' biases: 9.995503e-01 [2.086336e-06] 
Layer 'fc6' weights[0]: 7.510138e-03 [5.769910e-08] 
Layer 'fc6' biases: 9.999995e-01 [4.990588e-08] 
Layer 'fc7' weights[0]: 7.865157e-03 [1.192270e-07] 
Layer 'fc7' biases: 9.999685e-01 [1.387791e-07] 
Layer 'fc8' weights[0]: 3.230109e-03 [1.930628e-05] 
Layer 'fc8' biases: 4.764784e-03 [1.815832e-05] 
Train error last 800 batches: 0.657961
-------------------------------------------------------
Not saving because 0.517984 > 0.323801 (3.40: -8.65%)
======================================================= (2.372 sec)
3.521... logprob:  0.657066, 0.272135 (1.460 sec)
3.522... logprob:  0.767951, 0.335938 (1.474 sec)
3.523... logprob:  0.565790, 0.260417 (1.433 sec)
3.524... logprob:  0.740513, 0.330729 (1.422 sec)
3.525... logprob:  0.589913, 0.259115 (1.433 sec)
3.526... logprob:  0.565583, 0.248698 (1.430 sec)
3.527... logprob:  0.697573, 0.286458 (1.431 sec)
3.528... logprob:  0.698889, 0.300781 (1.468 sec)
3.529... logprob:  0.601340, 0.265625 (1.445 sec)
3.530... logprob:  0.719972, 0.299479 (1.429 sec)
3.531... logprob:  0.592323, 0.248698 (1.474 sec)
3.532... logprob:  0.674558, 0.289062 (1.427 sec)
3.533... logprob:  0.795976, 0.337240 (1.421 sec)
3.534... logprob:  0.650972, 0.289062 (1.427 sec)
3.535... logprob:  0.797259, 0.346354 (1.431 sec)
3.536... logprob:  0.767630, 0.325521 (1.428 sec)
3.537... logprob:  0.766858, 0.332031 (1.469 sec)
3.538... logprob:  0.657302, 0.296875 (1.434 sec)
3.539... logprob:  0.556390, 0.274740 (1.421 sec)
3.540... logprob:  0.634614, 0.291667 (1.480 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.385010, 0.062500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.172952e-03 [3.648937e-07] 
Layer 'conv1' biases: 5.154654e-07 [1.289153e-09] 
Layer 'conv2' weights[0]: 7.160892e-03 [3.615644e-07] 
Layer 'conv2' biases: 9.999997e-01 [8.021281e-09] 
Layer 'conv3' weights[0]: 7.159667e-03 [3.619240e-07] 
Layer 'conv3' biases: 1.169779e-05 [2.633046e-08] 
Layer 'conv4' weights[0]: 7.188651e-03 [3.661024e-07] 
Layer 'conv4' biases: 1.000005e+00 [2.742205e-07] 
Layer 'conv5' weights[0]: 7.199223e-03 [1.799399e-06] 
Layer 'conv5' biases: 9.995450e-01 [1.821811e-06] 
Layer 'fc6' weights[0]: 7.509399e-03 [5.504378e-08] 
Layer 'fc6' biases: 9.999995e-01 [4.588189e-08] 
Layer 'fc7' weights[0]: 7.864406e-03 [1.122059e-07] 
Layer 'fc7' biases: 9.999678e-01 [1.325405e-07] 
Layer 'fc8' weights[0]: 3.202422e-03 [2.062742e-05] 
Layer 'fc8' biases: 4.597933e-03 [2.904506e-05] 
Train error last 800 batches: 0.657771
-------------------------------------------------------
Not saving because 0.385010 > 0.323801 (3.40: -8.65%)
======================================================= (2.435 sec)
3.541... logprob:  0.581943, 0.265625 (1.432 sec)
3.542... logprob:  0.697447, 0.285156 (1.432 sec)
3.543... logprob:  0.527722, 0.244792 (1.435 sec)
3.544... logprob:  0.538937, 0.240885 (1.423 sec)
3.545... logprob:  0.567404, 0.231771 (1.426 sec)
3.546... logprob:  0.661327, 0.302083 (1.481 sec)
3.547... logprob:  0.674470, 0.281250 (1.429 sec)
3.548... logprob:  0.642817, 0.270833 (1.434 sec)
3.549... logprob:  0.587101, 0.270833 (1.473 sec)
3.550... logprob:  0.594227, 0.266927 (1.425 sec)
3.551... logprob:  0.670760, 0.281250 (1.438 sec)
3.552... logprob:  0.641798, 0.322917 (1.428 sec)
3.553... logprob:  0.599708, 0.264323 (1.419 sec)
3.554... logprob:  0.703322, 0.325521 (1.428 sec)
3.555... logprob:  0.617377, 0.279948 (1.475 sec)
3.556... logprob:  0.650488, 0.315104 (1.434 sec)
3.557... logprob:  0.648321, 0.295573 (1.444 sec)
3.558... logprob:  0.693966, 0.273438 (1.466 sec)
3.559... logprob:  0.698961, 0.295573 (1.426 sec)
3.560... logprob:  0.563471, 0.246094 (1.436 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.407468, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.165777e-03 [3.649186e-07] 
Layer 'conv1' biases: 5.172254e-07 [1.390371e-09] 
Layer 'conv2' weights[0]: 7.153685e-03 [3.615253e-07] 
Layer 'conv2' biases: 9.999997e-01 [8.670026e-09] 
Layer 'conv3' weights[0]: 7.152486e-03 [3.618953e-07] 
Layer 'conv3' biases: 1.160166e-05 [2.972521e-08] 
Layer 'conv4' weights[0]: 7.181450e-03 [3.657127e-07] 
Layer 'conv4' biases: 1.000004e+00 [2.997634e-07] 
Layer 'conv5' weights[0]: 7.191549e-03 [2.091458e-06] 
Layer 'conv5' biases: 9.995438e-01 [2.186397e-06] 
Layer 'fc6' weights[0]: 7.508625e-03 [5.848555e-08] 
Layer 'fc6' biases: 9.999995e-01 [5.120451e-08] 
Layer 'fc7' weights[0]: 7.863622e-03 [1.252470e-07] 
Layer 'fc7' biases: 9.999691e-01 [1.669917e-07] 
Layer 'fc8' weights[0]: 3.340012e-03 [2.739587e-05] 
Layer 'fc8' biases: 5.248136e-03 [5.255175e-05] 
Train error last 800 batches: 0.657492
-------------------------------------------------------
Not saving because 0.407468 > 0.323801 (3.40: -8.65%)
======================================================= (2.360 sec)
3.561... logprob:  0.634049, 0.290364 (1.434 sec)
3.562... logprob:  0.749803, 0.352865 (1.430 sec)
3.563... logprob:  0.599852, 0.294271 (1.445 sec)
3.564... logprob:  0.713453, 0.345052 (1.457 sec)
3.565... logprob:  0.806553, 0.324219 (1.443 sec)
3.566... logprob:  0.635819, 0.313802 (1.448 sec)
3.567... logprob:  0.650541, 0.294271 (1.458 sec)
3.568... logprob:  0.795696, 0.368490 (1.445 sec)
3.569... logprob:  0.623053, 0.274740 (1.433 sec)
3.570... logprob:  0.859588, 0.361979 (1.420 sec)
3.571... logprob:  0.700910, 0.291667 (1.424 sec)
3.572... logprob:  0.681071, 0.312500 (1.426 sec)
3.573... logprob:  0.803573, 0.334635 (1.435 sec)
3.574... logprob:  0.649717, 0.296875 (1.457 sec)
3.575... logprob:  0.576474, 0.248698 (1.448 sec)
3.576... logprob:  0.566307, 0.231771 (1.436 sec)
3.577... logprob:  0.690938, 0.303385 (1.472 sec)
3.578... logprob:  0.550167, 0.243490 (1.427 sec)
3.579... logprob:  0.622932, 0.274740 (1.422 sec)
3.580... logprob:  0.735589, 0.324219 (1.420 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.472656, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.158631e-03 [3.673337e-07] 
Layer 'conv1' biases: 5.247881e-07 [1.180168e-09] 
Layer 'conv2' weights[0]: 7.146561e-03 [3.622895e-07] 
Layer 'conv2' biases: 9.999997e-01 [8.361362e-09] 
Layer 'conv3' weights[0]: 7.145329e-03 [3.621476e-07] 
Layer 'conv3' biases: 1.161165e-05 [2.951842e-08] 
Layer 'conv4' weights[0]: 7.174278e-03 [3.701343e-07] 
Layer 'conv4' biases: 1.000004e+00 [3.719224e-07] 
Layer 'conv5' weights[0]: 7.184574e-03 [2.408852e-06] 
Layer 'conv5' biases: 9.995428e-01 [2.516708e-06] 
Layer 'fc6' weights[0]: 7.507855e-03 [6.049189e-08] 
Layer 'fc6' biases: 9.999994e-01 [5.406382e-08] 
Layer 'fc7' weights[0]: 7.862838e-03 [1.271192e-07] 
Layer 'fc7' biases: 9.999673e-01 [1.765365e-07] 
Layer 'fc8' weights[0]: 3.276725e-03 [2.481501e-05] 
Layer 'fc8' biases: 4.773522e-03 [4.576796e-05] 
Train error last 800 batches: 0.657195
-------------------------------------------------------
Not saving because 0.472656 > 0.323801 (3.40: -8.65%)
======================================================= (2.362 sec)
3.581... logprob:  0.728984, 0.345052 (1.436 sec)
3.582... logprob:  0.714974, 0.325521 (1.434 sec)
3.583... logprob:  0.805858, 0.339844 (1.478 sec)
3.584... logprob:  0.781769, 0.350260 (1.440 sec)
3.585... logprob:  0.633648, 0.303385 (1.432 sec)
3.586... logprob:  0.551103, 0.247396 (1.481 sec)
3.587... logprob:  0.635425, 0.283854 (1.433 sec)
3.588... logprob:  0.565582, 0.238281 (1.425 sec)
3.589... logprob:  0.588704, 0.248698 (1.425 sec)
3.590... logprob:  0.673104, 0.290365 (1.428 sec)
3.591... logprob:  0.588753, 0.276042 (1.428 sec)
3.592... logprob:  0.676919, 0.291667 (1.475 sec)
3.593... logprob:  0.681892, 0.266927 (1.429 sec)
3.594... logprob:  0.555911, 0.268229 (1.437 sec)
3.595... logprob:  0.681370, 0.294271 (1.481 sec)
3.596... logprob:  0.582067, 0.273437 (1.428 sec)
3.597... logprob:  0.711581, 0.294271 (1.428 sec)
3.598... logprob:  0.635126, 0.303385 (1.428 sec)
3.599... logprob:  0.629291, 0.279948 (1.422 sec)
3.600... logprob:  0.573343, 0.278646 (1.429 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.458609, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.151427e-03 [3.620984e-07] 
Layer 'conv1' biases: 5.234975e-07 [1.278490e-09] 
Layer 'conv2' weights[0]: 7.139395e-03 [3.607163e-07] 
Layer 'conv2' biases: 9.999997e-01 [6.984499e-09] 
Layer 'conv3' weights[0]: 7.138196e-03 [3.614349e-07] 
Layer 'conv3' biases: 1.164989e-05 [2.949928e-08] 
Layer 'conv4' weights[0]: 7.167064e-03 [3.664718e-07] 
Layer 'conv4' biases: 1.000004e+00 [3.097145e-07] 
Layer 'conv5' weights[0]: 7.177610e-03 [2.059105e-06] 
Layer 'conv5' biases: 9.995368e-01 [2.084984e-06] 
Layer 'fc6' weights[0]: 7.507051e-03 [5.517257e-08] 
Layer 'fc6' biases: 9.999994e-01 [4.619359e-08] 
Layer 'fc7' weights[0]: 7.862071e-03 [1.131877e-07] 
Layer 'fc7' biases: 9.999685e-01 [1.396990e-07] 
Layer 'fc8' weights[0]: 3.352307e-03 [1.955928e-05] 
Layer 'fc8' biases: 5.235214e-03 [3.196848e-05] 
Train error last 800 batches: 0.657100
-------------------------------------------------------
Not saving because 0.458609 > 0.323801 (3.40: -8.65%)
======================================================= (2.357 sec)
3.601... logprob:  0.556191, 0.268229 (1.491 sec)
3.602... logprob:  0.512058, 0.230469 (1.437 sec)
3.603... logprob:  0.545224, 0.257812 (1.436 sec)
3.604... logprob:  0.631751, 0.279948 (1.471 sec)
3.605... logprob:  0.763879, 0.315104 (1.428 sec)
3.606... logprob:  0.495611, 0.243490 (1.432 sec)
3.607... logprob:  0.674036, 0.265625 (1.424 sec)
3.608... logprob:  0.629542, 0.278646 (1.421 sec)
3.609... logprob:  0.695839, 0.289062 (1.432 sec)
3.610... logprob:  0.733670, 0.295573 (1.473 sec)
3.611... logprob:  0.675369, 0.287760 (1.436 sec)
3.612... logprob:  0.724242, 0.305990 (1.449 sec)
3.613... logprob:  0.558588, 0.265625 (1.453 sec)
3.614... logprob:  0.697533, 0.286458 (1.442 sec)
3.615... logprob:  0.472805, 0.221354 (1.429 sec)
3.616... logprob:  0.632856, 0.279948 (1.425 sec)
3.617... logprob:  0.612161, 0.277344 (1.422 sec)
3.618... logprob:  0.714983, 0.285156 (1.430 sec)
3.619... logprob:  0.686294, 0.302083 (1.448 sec)
3.620... logprob:  0.767548, 0.346354 (1.452 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.517576, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.144291e-03 [3.654383e-07] 
Layer 'conv1' biases: 5.264412e-07 [1.776311e-09] 
Layer 'conv2' weights[0]: 7.132267e-03 [3.619689e-07] 
Layer 'conv2' biases: 9.999997e-01 [9.765390e-09] 
Layer 'conv3' weights[0]: 7.131078e-03 [3.640666e-07] 
Layer 'conv3' biases: 1.171407e-05 [4.031857e-08] 
Layer 'conv4' weights[0]: 7.159947e-03 [3.717908e-07] 
Layer 'conv4' biases: 1.000005e+00 [4.316152e-07] 
Layer 'conv5' weights[0]: 7.171135e-03 [2.859698e-06] 
Layer 'conv5' biases: 9.995270e-01 [2.999960e-06] 
Layer 'fc6' weights[0]: 7.506287e-03 [6.358422e-08] 
Layer 'fc6' biases: 9.999995e-01 [5.845747e-08] 
Layer 'fc7' weights[0]: 7.861311e-03 [1.358893e-07] 
Layer 'fc7' biases: 9.999675e-01 [2.004318e-07] 
Layer 'fc8' weights[0]: 3.315804e-03 [2.378208e-05] 
Layer 'fc8' biases: 5.115900e-03 [3.919680e-05] 
Train error last 800 batches: 0.656716
-------------------------------------------------------
Not saving because 0.517576 > 0.323801 (3.40: -8.65%)
======================================================= (2.360 sec)
3.621... logprob:  0.629271, 0.270833 (1.457 sec)
3.622... logprob:  0.565719, 0.264323 (1.442 sec)
3.623... logprob:  0.622525, 0.261719 (1.460 sec)
3.624... logprob:  0.757325, 0.328125 (1.431 sec)
3.625... logprob:  0.670343, 0.289062 (1.418 sec)
3.626... logprob:  0.639721, 0.250000 (1.426 sec)
3.627... logprob:  0.693464, 0.295573 (1.427 sec)
3.628... logprob:  0.645994, 0.266927 (1.435 sec)
3.629... logprob:  0.536611, 0.243490 (1.465 sec)
3.630... logprob:  0.683823, 0.300781 (1.443 sec)
3.631... logprob:  0.794009, 0.341146 (1.431 sec)
3.632... logprob:  0.595068, 0.255208 (1.474 sec)
3.633... logprob:  0.622288, 0.276042 (1.430 sec)
3.634... logprob:  0.863727, 0.338542 (1.419 sec)
3.635... logprob:  0.582304, 0.250000 (1.428 sec)
3.636... logprob:  0.679645, 0.281250 (1.427 sec)
3.637... logprob:  0.560795, 0.252604 (1.425 sec)
3.638... logprob:  0.674438, 0.305990 (1.475 sec)
3.639... logprob:  0.700141, 0.299479 (1.435 sec)
3.640... logprob:  0.683311, 0.305990 (1.428 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.478670, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.137160e-03 [3.630484e-07] 
Layer 'conv1' biases: 5.370836e-07 [1.566312e-09] 
Layer 'conv2' weights[0]: 7.125145e-03 [3.608572e-07] 
Layer 'conv2' biases: 9.999997e-01 [8.615986e-09] 
Layer 'conv3' weights[0]: 7.123989e-03 [3.606004e-07] 
Layer 'conv3' biases: 1.182315e-05 [3.066755e-08] 
Layer 'conv4' weights[0]: 7.152757e-03 [3.661533e-07] 
Layer 'conv4' biases: 1.000007e+00 [3.339754e-07] 
Layer 'conv5' weights[0]: 7.164921e-03 [2.132505e-06] 
Layer 'conv5' biases: 9.995186e-01 [2.322897e-06] 
Layer 'fc6' weights[0]: 7.505500e-03 [5.475100e-08] 
Layer 'fc6' biases: 9.999995e-01 [4.598461e-08] 
Layer 'fc7' weights[0]: 7.860492e-03 [1.110786e-07] 
Layer 'fc7' biases: 9.999655e-01 [1.168122e-07] 
Layer 'fc8' weights[0]: 3.268486e-03 [1.732265e-05] 
Layer 'fc8' biases: 4.814995e-03 [1.151602e-05] 
Train error last 800 batches: 0.656540
-------------------------------------------------------
Not saving because 0.478670 > 0.323801 (3.40: -8.65%)
======================================================= (2.373 sec)
3.641... logprob:  0.715182, 0.295573 (1.483 sec)
3.642... logprob:  0.744918, 0.324219 (1.427 sec)
3.643... logprob:  0.778898, 0.338542 (1.425 sec)
3.644... logprob:  0.588219, 0.281250 (1.430 sec)
3.645... logprob:  0.623745, 0.295573 (1.420 sec)
3.646... logprob:  0.656284, 0.305990 (1.431 sec)
3.647... logprob:  0.696519, 0.276042 (1.560 sec)
3.648... logprob:  0.773356, 0.337240 (1.429 sec)
3.649... logprob:  0.616724, 0.248698 (1.436 sec)
3.650... logprob:  0.625272, 0.289062 (1.473 sec)
3.651... logprob:  0.627419, 0.295573 (1.422 sec)
3.652... logprob:  0.665810, 0.281250 (1.436 sec)
3.653... logprob:  0.686422, 0.296875 (1.431 sec)
3.654... logprob:  0.629848, 0.282552 (1.420 sec)
3.655... logprob:  0.638510, 0.272135 (1.428 sec)
3.656... logprob:  0.638281, 0.291667 (1.473 sec)
3.657... logprob:  0.713374, 0.322917 (1.434 sec)
3.658... logprob:  0.563437, 0.260417 (1.445 sec)
3.659... logprob:  0.700583, 0.348958 (1.468 sec)
3.660... logprob:  0.646928, 0.292969 (1.437 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.516306, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.130032e-03 [3.637364e-07] 
Layer 'conv1' biases: 5.448638e-07 [1.221387e-09] 
Layer 'conv2' weights[0]: 7.118038e-03 [3.601989e-07] 
Layer 'conv2' biases: 9.999998e-01 [8.043624e-09] 
Layer 'conv3' weights[0]: 7.116844e-03 [3.609715e-07] 
Layer 'conv3' biases: 1.193595e-05 [3.145033e-08] 
Layer 'conv4' weights[0]: 7.145600e-03 [3.670037e-07] 
Layer 'conv4' biases: 1.000008e+00 [3.603685e-07] 
Layer 'conv5' weights[0]: 7.157992e-03 [2.377862e-06] 
Layer 'conv5' biases: 9.995118e-01 [2.533884e-06] 
Layer 'fc6' weights[0]: 7.504698e-03 [6.018554e-08] 
Layer 'fc6' biases: 9.999994e-01 [5.385946e-08] 
Layer 'fc7' weights[0]: 7.859732e-03 [1.285294e-07] 
Layer 'fc7' biases: 9.999666e-01 [1.845506e-07] 
Layer 'fc8' weights[0]: 3.320806e-03 [2.343038e-05] 
Layer 'fc8' biases: 5.077401e-03 [4.563681e-05] 
Train error last 800 batches: 0.656319
-------------------------------------------------------
Not saving because 0.516306 > 0.323801 (3.40: -8.65%)
======================================================= (2.413 sec)
3.661... logprob:  0.602284, 0.257812 (1.436 sec)
3.662... logprob:  0.792176, 0.338542 (1.432 sec)
3.663... logprob:  0.594724, 0.283854 (1.422 sec)
3.664... logprob:  0.584370, 0.276042 (1.434 sec)
3.665... logprob:  0.632174, 0.263021 (1.452 sec)
3.666... logprob:  0.716387, 0.326823 (1.447 sec)
3.667... logprob:  0.819107, 0.343750 (1.444 sec)
3.668... logprob:  0.671072, 0.302083 (1.444 sec)
3.669... logprob:  0.680627, 0.298177 (1.460 sec)
3.670... logprob:  0.596383, 0.266927 (1.431 sec)
3.671... logprob:  0.653267, 0.274740 (1.418 sec)
3.672... logprob:  0.712384, 0.328125 (1.426 sec)
3.673... logprob:  0.619972, 0.279948 (1.430 sec)
3.674... logprob:  0.738307, 0.308594 (1.434 sec)
3.675... logprob:  0.634471, 0.285156 (1.460 sec)
3.676... logprob:  0.635367, 0.289062 (1.447 sec)
3.677... logprob:  0.714942, 0.302083 (1.429 sec)
3.678... logprob:  0.664492, 0.273437 (1.471 sec)
3.679... logprob:  0.700479, 0.292969 (1.434 sec)
3.680... logprob:  0.573499, 0.277344 (1.418 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.397077, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.122890e-03 [3.629860e-07] 
Layer 'conv1' biases: 5.492727e-07 [1.223744e-09] 
Layer 'conv2' weights[0]: 7.110909e-03 [3.592266e-07] 
Layer 'conv2' biases: 9.999998e-01 [7.411573e-09] 
Layer 'conv3' weights[0]: 7.109781e-03 [3.597640e-07] 
Layer 'conv3' biases: 1.195807e-05 [2.850239e-08] 
Layer 'conv4' weights[0]: 7.138424e-03 [3.641077e-07] 
Layer 'conv4' biases: 1.000007e+00 [3.030619e-07] 
Layer 'conv5' weights[0]: 7.150809e-03 [2.069837e-06] 
Layer 'conv5' biases: 9.995109e-01 [2.245697e-06] 
Layer 'fc6' weights[0]: 7.503902e-03 [5.627324e-08] 
Layer 'fc6' biases: 9.999993e-01 [4.854276e-08] 
Layer 'fc7' weights[0]: 7.858953e-03 [1.156503e-07] 
Layer 'fc7' biases: 9.999661e-01 [1.371548e-07] 
Layer 'fc8' weights[0]: 3.317265e-03 [2.042135e-05] 
Layer 'fc8' biases: 5.004231e-03 [3.243175e-05] 
Train error last 800 batches: 0.657128
-------------------------------------------------------
Not saving because 0.397077 > 0.323801 (3.40: -8.65%)
======================================================= (2.365 sec)
3.681... logprob:  0.653610, 0.300781 (1.436 sec)
3.682... logprob:  0.531457, 0.251302 (1.439 sec)
3.683... logprob:  0.585455, 0.278646 (1.428 sec)
3.684... logprob:  0.628123, 0.292969 (1.477 sec)
3.685... logprob:  0.552595, 0.263021 (1.435 sec)
3.686... logprob:  0.479372, 0.218750 (1.427 sec)
3.687... logprob:  0.519874, 0.239583 (1.480 sec)
3.688... logprob:  0.592183, 0.252604 (1.427 sec)
3.689... logprob:  0.721761, 0.283854 (1.422 sec)
3.690... logprob:  0.701349, 0.302083 (1.429 sec)
3.691... logprob:  0.776027, 0.319010 (1.427 sec)
3.692... logprob:  0.593286, 0.273438 (1.429 sec)
3.693... logprob:  0.753154, 0.315104 (1.477 sec)
3.694... logprob:  0.611901, 0.294271 (1.427 sec)
3.695... logprob:  0.478533, 0.216146 (1.434 sec)
3.696... logprob:  0.911362, 0.361979 (1.475 sec)
3.697... logprob:  0.569261, 0.247396 (1.423 sec)
3.698... logprob:  0.658672, 0.289062 (1.430 sec)
3.699... logprob:  0.602929, 0.276042 (1.428 sec)
3.700... logprob:  0.634374, 0.279948 (1.422 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.499469, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.115794e-03 [3.629434e-07] 
Layer 'conv1' biases: 5.499048e-07 [1.402505e-09] 
Layer 'conv2' weights[0]: 7.103783e-03 [3.601441e-07] 
Layer 'conv2' biases: 9.999998e-01 [9.771249e-09] 
Layer 'conv3' weights[0]: 7.102656e-03 [3.607140e-07] 
Layer 'conv3' biases: 1.199345e-05 [3.497209e-08] 
Layer 'conv4' weights[0]: 7.131358e-03 [3.667002e-07] 
Layer 'conv4' biases: 1.000007e+00 [3.960678e-07] 
Layer 'conv5' weights[0]: 7.143656e-03 [2.719923e-06] 
Layer 'conv5' biases: 9.995112e-01 [2.856349e-06] 
Layer 'fc6' weights[0]: 7.503107e-03 [6.036899e-08] 
Layer 'fc6' biases: 9.999994e-01 [5.422637e-08] 
Layer 'fc7' weights[0]: 7.858193e-03 [1.285340e-07] 
Layer 'fc7' biases: 9.999655e-01 [1.783073e-07] 
Layer 'fc8' weights[0]: 3.348165e-03 [2.198331e-05] 
Layer 'fc8' biases: 5.183673e-03 [2.832079e-05] 
Train error last 800 batches: 0.657049
-------------------------------------------------------
Not saving because 0.499469 > 0.323801 (3.40: -8.65%)
======================================================= (2.367 sec)
3.701... logprob:  0.641583, 0.278646 (1.430 sec)
3.702... logprob:  0.649029, 0.272135 (1.478 sec)
3.703... logprob:  0.636686, 0.285156 (1.430 sec)
3.704... logprob:  0.581177, 0.257812 (1.438 sec)
3.705... logprob:  0.634256, 0.289062 (1.470 sec)
3.706... logprob:  0.635098, 0.283854 (1.426 sec)
3.707... logprob:  0.676446, 0.276042 (1.434 sec)
3.708... logprob:  0.704715, 0.304687 (1.427 sec)
3.709... logprob:  0.676039, 0.296875 (1.418 sec)
3.710... logprob:  0.840534, 0.345052 (1.429 sec)
3.711... logprob:  0.636584, 0.283854 (1.460 sec)
3.712... logprob:  0.662712, 0.320312 (1.441 sec)
3.713... logprob:  0.784049, 0.319010 (1.449 sec)
3.714... logprob:  0.673286, 0.307292 (1.460 sec)
3.715... logprob:  0.647423, 0.268229 (1.447 sec)
3.716... logprob:  0.613066, 0.287760 (1.432 sec)
3.717... logprob:  0.696406, 0.304687 (1.424 sec)
3.718... logprob:  0.725778, 0.287760 (1.425 sec)
3.719... logprob:  0.658491, 0.279948 (1.432 sec)
3.720... logprob:  0.633852, 0.285156 (1.443 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.478064, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.108701e-03 [3.617405e-07] 
Layer 'conv1' biases: 5.626878e-07 [1.867941e-09] 
Layer 'conv2' weights[0]: 7.096705e-03 [3.586885e-07] 
Layer 'conv2' biases: 9.999998e-01 [7.690118e-09] 
Layer 'conv3' weights[0]: 7.095520e-03 [3.594239e-07] 
Layer 'conv3' biases: 1.207297e-05 [3.084610e-08] 
Layer 'conv4' weights[0]: 7.124197e-03 [3.639651e-07] 
Layer 'conv4' biases: 1.000007e+00 [3.021161e-07] 
Layer 'conv5' weights[0]: 7.136708e-03 [2.094502e-06] 
Layer 'conv5' biases: 9.995080e-01 [2.215212e-06] 
Layer 'fc6' weights[0]: 7.502340e-03 [5.633003e-08] 
Layer 'fc6' biases: 9.999994e-01 [4.850463e-08] 
Layer 'fc7' weights[0]: 7.857399e-03 [1.192679e-07] 
Layer 'fc7' biases: 9.999644e-01 [1.375748e-07] 
Layer 'fc8' weights[0]: 3.302517e-03 [2.063526e-05] 
Layer 'fc8' biases: 4.889986e-03 [2.846760e-05] 
Train error last 800 batches: 0.656672
-------------------------------------------------------
Not saving because 0.478064 > 0.323801 (3.40: -8.65%)
======================================================= (2.400 sec)
3.721... logprob:  0.658904, 0.269531 (1.459 sec)
3.722... logprob:  0.800867, 0.330729 (1.456 sec)
3.723... logprob:  0.637843, 0.282552 (1.440 sec)
3.724... logprob:  0.607580, 0.223958 (1.471 sec)
3.725... logprob:  0.666867, 0.277344 (1.429 sec)
3.726... logprob:  0.584131, 0.265625 (1.420 sec)
3.727... logprob:  0.573280, 0.239583 (1.421 sec)
3.728... logprob:  0.655628, 0.304687 (1.435 sec)
3.729... logprob:  0.638311, 0.277344 (1.426 sec)
3.730... logprob:  0.747640, 0.345052 (1.471 sec)
3.731... logprob:  0.588908, 0.274740 (1.437 sec)
3.732... logprob:  0.620175, 0.277344 (1.425 sec)
3.733... logprob:  0.792545, 0.334635 (1.474 sec)
3.734... logprob:  0.601026, 0.253906 (1.430 sec)
3.735... logprob:  0.750536, 0.307292 (1.419 sec)
3.736... logprob:  0.740774, 0.308594 (1.430 sec)
3.737... logprob:  0.736063, 0.328125 (1.430 sec)
3.738... logprob:  0.723614, 0.309896 (1.425 sec)
3.739... logprob:  0.751844, 0.317708 (1.476 sec)
3.740... logprob:  0.579204, 0.259115 (1.431 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.547731, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.101590e-03 [3.641242e-07] 
Layer 'conv1' biases: 5.702727e-07 [1.552092e-09] 
Layer 'conv2' weights[0]: 7.089602e-03 [3.592130e-07] 
Layer 'conv2' biases: 9.999998e-01 [9.840885e-09] 
Layer 'conv3' weights[0]: 7.088414e-03 [3.600889e-07] 
Layer 'conv3' biases: 1.220403e-05 [3.366180e-08] 
Layer 'conv4' weights[0]: 7.117072e-03 [3.650305e-07] 
Layer 'conv4' biases: 1.000008e+00 [3.522526e-07] 
Layer 'conv5' weights[0]: 7.129754e-03 [2.461447e-06] 
Layer 'conv5' biases: 9.995025e-01 [2.493986e-06] 
Layer 'fc6' weights[0]: 7.501575e-03 [6.083313e-08] 
Layer 'fc6' biases: 9.999994e-01 [5.531537e-08] 
Layer 'fc7' weights[0]: 7.856554e-03 [1.298293e-07] 
Layer 'fc7' biases: 9.999642e-01 [1.723540e-07] 
Layer 'fc8' weights[0]: 3.313636e-03 [2.129110e-05] 
Layer 'fc8' biases: 4.958279e-03 [2.875183e-05] 
Train error last 800 batches: 0.657030
-------------------------------------------------------
Not saving because 0.547731 > 0.323801 (3.40: -8.65%)
======================================================= (2.366 sec)
3.741... logprob:  0.640085, 0.281250 (1.434 sec)
3.742... logprob:  0.624661, 0.278646 (1.479 sec)
3.743... logprob:  0.563716, 0.233073 (1.432 sec)
3.744... logprob:  0.757195, 0.316406 (1.426 sec)
3.745... logprob:  0.648751, 0.304688 (1.431 sec)
3.746... logprob:  0.597205, 0.273438 (1.422 sec)
3.747... logprob:  0.615339, 0.274740 (1.425 sec)
3.748... logprob:  0.618318, 0.273438 (1.477 sec)
3.749... logprob:  0.597373, 0.263021 (1.431 sec)
3.750... logprob:  0.753614, 0.317708 (1.440 sec)
3.751... logprob:  0.496297, 0.223958 (1.476 sec)
3.752... logprob:  0.737471, 0.316406 (1.426 sec)
3.753... logprob:  0.650145, 0.282552 (1.434 sec)
3.754... logprob:  0.654555, 0.294271 (1.425 sec)
3.755... logprob:  0.718172, 0.307292 (1.429 sec)
3.756... logprob:  0.593341, 0.276042 (1.429 sec)
3.757... logprob:  0.808801, 0.358073 (1.469 sec)
3.758... logprob:  0.599174, 0.260417 (1.435 sec)
3.759... logprob:  0.724180, 0.308594 (1.446 sec)
3.760... logprob:  0.744959, 0.311198 (1.461 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.424170, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.094516e-03 [3.649932e-07] 
Layer 'conv1' biases: 5.759468e-07 [1.535912e-09] 
Layer 'conv2' weights[0]: 7.082549e-03 [3.589392e-07] 
Layer 'conv2' biases: 9.999998e-01 [8.879319e-09] 
Layer 'conv3' weights[0]: 7.081363e-03 [3.593352e-07] 
Layer 'conv3' biases: 1.230462e-05 [3.319359e-08] 
Layer 'conv4' weights[0]: 7.109934e-03 [3.646839e-07] 
Layer 'conv4' biases: 1.000007e+00 [3.508492e-07] 
Layer 'conv5' weights[0]: 7.122517e-03 [2.310779e-06] 
Layer 'conv5' biases: 9.994986e-01 [2.403432e-06] 
Layer 'fc6' weights[0]: 7.500807e-03 [5.994568e-08] 
Layer 'fc6' biases: 9.999994e-01 [5.414833e-08] 
Layer 'fc7' weights[0]: 7.855806e-03 [1.256421e-07] 
Layer 'fc7' biases: 9.999642e-01 [1.611948e-07] 
Layer 'fc8' weights[0]: 3.333174e-03 [2.180150e-05] 
Layer 'fc8' biases: 5.089666e-03 [3.291631e-05] 
Train error last 800 batches: 0.656883
-------------------------------------------------------
Not saving because 0.424170 > 0.323801 (3.40: -8.65%)
======================================================= (2.364 sec)
3.761... logprob:  0.656188, 0.308594 (1.448 sec)
3.762... logprob:  0.732074, 0.320312 (1.439 sec)
3.763... logprob:  0.745886, 0.355469 (1.424 sec)
3.764... logprob:  0.774316, 0.337240 (1.418 sec)
3.765... logprob:  0.550439, 0.256510 (1.434 sec)
3.766... logprob:  0.738067, 0.320312 (1.448 sec)
3.767... logprob:  0.555332, 0.248698 (1.449 sec)
3.768... logprob:  0.662528, 0.309896 (1.460 sec)
3.769... logprob:  0.674351, 0.282552 (1.461 sec)
3.770... logprob:  0.597047, 0.248698 (1.474 sec)
3.771... logprob:  0.729781, 0.296875 (1.449 sec)
3.772... logprob:  0.604496, 0.246094 (1.445 sec)
3.773... logprob:  0.515614, 0.218750 (1.443 sec)
3.774... logprob:  0.514747, 0.231771 (1.454 sec)
3.775... logprob:  0.609947, 0.263021 (1.455 sec)
3.776... logprob:  0.738581, 0.347656 (1.472 sec)
3.777... logprob:  0.659445, 0.289062 (1.467 sec)
3.778... logprob:  0.611073, 0.281250 (1.465 sec)
3.779... logprob:  0.754917, 0.321615 (1.481 sec)
3.780... logprob:  0.572880, 0.264323 (1.449 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.366498, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.087416e-03 [3.610722e-07] 
Layer 'conv1' biases: 5.774443e-07 [1.267903e-09] 
Layer 'conv2' weights[0]: 7.075414e-03 [3.580220e-07] 
Layer 'conv2' biases: 9.999997e-01 [8.958164e-09] 
Layer 'conv3' weights[0]: 7.074234e-03 [3.593015e-07] 
Layer 'conv3' biases: 1.233981e-05 [3.385393e-08] 
Layer 'conv4' weights[0]: 7.102820e-03 [3.625589e-07] 
Layer 'conv4' biases: 1.000006e+00 [2.897423e-07] 
Layer 'conv5' weights[0]: 7.115260e-03 [1.945238e-06] 
Layer 'conv5' biases: 9.994963e-01 [2.067912e-06] 
Layer 'fc6' weights[0]: 7.500009e-03 [5.451402e-08] 
Layer 'fc6' biases: 9.999994e-01 [4.581385e-08] 
Layer 'fc7' weights[0]: 7.854999e-03 [1.112525e-07] 
Layer 'fc7' biases: 9.999646e-01 [1.220183e-07] 
Layer 'fc8' weights[0]: 3.369994e-03 [1.755911e-05] 
Layer 'fc8' biases: 5.228487e-03 [1.782138e-05] 
Train error last 800 batches: 0.656160
-------------------------------------------------------
Not saving because 0.366498 > 0.323801 (3.40: -8.65%)
======================================================= (2.370 sec)
3.781... logprob:  0.524076, 0.243490 (1.444 sec)
3.782... logprob:  0.590261, 0.260417 (1.451 sec)
3.783... logprob:  0.791322, 0.338542 (1.459 sec)
3.784... logprob:  0.694828, 0.281250 (1.451 sec)
3.785... logprob:  0.725206, 0.313802 (1.489 sec)
3.786... logprob:  0.635910, 0.264323 (1.462 sec)
3.787... logprob:  0.813325, 0.350260 (1.453 sec)
3.788... logprob:  0.821086, 0.338542 (1.488 sec)
3.789... logprob:  0.583338, 0.248698 (1.447 sec)
3.790... logprob:  0.613774, 0.243490 (1.439 sec)
3.791... logprob:  0.581467, 0.251302 (1.443 sec)
3.792... logprob:  0.592966, 0.257812 (1.455 sec)
3.793... logprob:  0.566227, 0.236979 (1.457 sec)
3.794... logprob:  0.660957, 0.319010 (1.481 sec)
3.795... logprob:  0.701015, 0.298177 (1.460 sec)
3.796... logprob:  0.693026, 0.307292 (1.451 sec)
3.797... logprob:  0.674980, 0.295573 (1.489 sec)
3.798... logprob:  0.621901, 0.276042 (1.450 sec)
3.799... logprob:  0.542202, 0.234375 (1.439 sec)
3.800... logprob:  0.603407, 0.250000 (1.395 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.471495, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.080323e-03 [3.627206e-07] 
Layer 'conv1' biases: 5.798400e-07 [1.672945e-09] 
Layer 'conv2' weights[0]: 7.068316e-03 [3.591995e-07] 
Layer 'conv2' biases: 9.999998e-01 [9.479606e-09] 
Layer 'conv3' weights[0]: 7.067150e-03 [3.601086e-07] 
Layer 'conv3' biases: 1.245466e-05 [3.712587e-08] 
Layer 'conv4' weights[0]: 7.095767e-03 [3.652469e-07] 
Layer 'conv4' biases: 1.000007e+00 [3.857858e-07] 
Layer 'conv5' weights[0]: 7.108641e-03 [2.551495e-06] 
Layer 'conv5' biases: 9.994921e-01 [2.790054e-06] 
Layer 'fc6' weights[0]: 7.499192e-03 [5.850993e-08] 
Layer 'fc6' biases: 9.999993e-01 [5.214475e-08] 
Layer 'fc7' weights[0]: 7.854240e-03 [1.255927e-07] 
Layer 'fc7' biases: 9.999636e-01 [1.733915e-07] 
Layer 'fc8' weights[0]: 3.347984e-03 [2.320646e-05] 
Layer 'fc8' biases: 5.096259e-03 [3.888442e-05] 
Train error last 800 batches: 0.656482
-------------------------------------------------------
Not saving because 0.471495 > 0.323801 (3.40: -8.65%)
======================================================= (2.359 sec)
4.1... logprob:  0.663959, 0.299479 (1.405 sec)
4.2... logprob:  0.658059, 0.292969 (1.449 sec)
4.3... logprob:  0.676442, 0.298177 (1.412 sec)
4.4... logprob:  0.723515, 0.285156 (1.400 sec)
4.5... logprob:  0.659943, 0.299479 (1.426 sec)
4.6... logprob:  0.662190, 0.269531 (1.395 sec)
4.7... logprob:  0.576139, 0.269531 (1.412 sec)
4.8... logprob:  0.691218, 0.303385 (1.393 sec)
4.9... logprob:  0.577499, 0.263021 (1.393 sec)
4.10... logprob:  0.653212, 0.315104 (1.401 sec)
4.11... logprob:  0.623334, 0.273437 (1.433 sec)
4.12... logprob:  0.696643, 0.278646 (1.392 sec)
4.13... logprob:  0.685254, 0.291667 (1.414 sec)
4.14... logprob:  0.656360, 0.296875 (1.398 sec)
4.15... logprob:  0.705889, 0.320312 (1.403 sec)
4.16... logprob:  0.668815, 0.292969 (1.402 sec)
4.17... logprob:  0.836069, 0.367187 (1.388 sec)
4.18... logprob:  0.539423, 0.273437 (1.395 sec)
4.19... logprob:  0.562873, 0.255208 (1.394 sec)
4.20... logprob:  0.652309, 0.282552 (0.670 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.487552, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.073253e-03 [3.613891e-07] 
Layer 'conv1' biases: 5.793952e-07 [1.489495e-09] 
Layer 'conv2' weights[0]: 7.061299e-03 [3.573334e-07] 
Layer 'conv2' biases: 9.999997e-01 [8.270495e-09] 
Layer 'conv3' weights[0]: 7.060153e-03 [3.579694e-07] 
Layer 'conv3' biases: 1.249091e-05 [2.920705e-08] 
Layer 'conv4' weights[0]: 7.088650e-03 [3.629779e-07] 
Layer 'conv4' biases: 1.000006e+00 [3.236398e-07] 
Layer 'conv5' weights[0]: 7.101424e-03 [2.236818e-06] 
Layer 'conv5' biases: 9.994944e-01 [2.319081e-06] 
Layer 'fc6' weights[0]: 7.498454e-03 [5.513227e-08] 
Layer 'fc6' biases: 9.999994e-01 [4.703252e-08] 
Layer 'fc7' weights[0]: 7.853519e-03 [1.112210e-07] 
Layer 'fc7' biases: 9.999633e-01 [1.242712e-07] 
Layer 'fc8' weights[0]: 3.369003e-03 [1.866493e-05] 
Layer 'fc8' biases: 5.205682e-03 [2.552092e-05] 
Train error last 800 batches: 0.657384
-------------------------------------------------------
Not saving because 0.487552 > 0.323801 (3.40: -8.65%)
======================================================= (2.383 sec)
4.21... logprob:  0.727760, 0.311198 (1.414 sec)
4.22... logprob:  0.746441, 0.341146 (1.409 sec)
4.23... logprob:  0.668469, 0.283854 (1.405 sec)
4.24... logprob:  0.604121, 0.287760 (1.416 sec)
4.25... logprob:  0.576243, 0.246094 (1.399 sec)
4.26... logprob:  0.738089, 0.325521 (1.440 sec)
4.27... logprob:  0.606754, 0.281250 (1.384 sec)
4.28... logprob:  0.600695, 0.273437 (1.406 sec)
4.29... logprob:  0.651924, 0.324219 (1.412 sec)
4.30... logprob:  0.567116, 0.250000 (1.412 sec)
4.31... logprob:  0.663947, 0.302083 (1.396 sec)
4.32... logprob:  0.608768, 0.273438 (1.388 sec)
4.33... logprob:  0.603737, 0.259115 (1.439 sec)
4.34... logprob:  0.673267, 0.300781 (1.389 sec)
4.35... logprob:  0.517772, 0.240885 (1.391 sec)
4.36... logprob:  0.698908, 0.330729 (1.392 sec)
4.37... logprob:  0.628775, 0.291667 (1.400 sec)
4.38... logprob:  0.691658, 0.304688 (1.388 sec)
4.39... logprob:  0.912040, 0.368490 (1.429 sec)
4.40... logprob:  0.740381, 0.291667 (1.403 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.555173, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.066170e-03 [3.605400e-07] 
Layer 'conv1' biases: 5.808138e-07 [1.198425e-09] 
Layer 'conv2' weights[0]: 7.054183e-03 [3.585232e-07] 
Layer 'conv2' biases: 9.999997e-01 [9.948305e-09] 
Layer 'conv3' weights[0]: 7.053025e-03 [3.602344e-07] 
Layer 'conv3' biases: 1.245024e-05 [4.102878e-08] 
Layer 'conv4' weights[0]: 7.081542e-03 [3.678593e-07] 
Layer 'conv4' biases: 1.000005e+00 [4.572636e-07] 
Layer 'conv5' weights[0]: 7.094087e-03 [2.678942e-06] 
Layer 'conv5' biases: 9.994944e-01 [2.878430e-06] 
Layer 'fc6' weights[0]: 7.497646e-03 [6.415623e-08] 
Layer 'fc6' biases: 9.999993e-01 [6.004630e-08] 
Layer 'fc7' weights[0]: 7.852715e-03 [1.379641e-07] 
Layer 'fc7' biases: 9.999640e-01 [1.917406e-07] 
Layer 'fc8' weights[0]: 3.417512e-03 [2.245524e-05] 
Layer 'fc8' biases: 5.348599e-03 [3.454712e-05] 
Train error last 800 batches: 0.657418
-------------------------------------------------------
Not saving because 0.555173 > 0.323801 (3.40: -8.65%)
======================================================= (2.416 sec)
4.41... logprob:  0.643349, 0.290364 (1.424 sec)
4.42... logprob:  0.557262, 0.231771 (1.417 sec)
4.43... logprob:  0.583628, 0.253906 (1.402 sec)
4.44... logprob:  0.677869, 0.309896 (1.429 sec)
4.45... logprob:  0.588103, 0.282552 (1.382 sec)
4.46... logprob:  0.724485, 0.330729 (1.390 sec)
4.47... logprob:  0.605896, 0.283854 (1.388 sec)
4.48... logprob:  0.791424, 0.325521 (1.418 sec)
4.49... logprob:  0.647148, 0.286458 (1.407 sec)
4.50... logprob:  0.659729, 0.281250 (1.420 sec)
4.51... logprob:  0.612415, 0.250000 (1.409 sec)
4.52... logprob:  0.808427, 0.329427 (1.393 sec)
4.53... logprob:  0.547477, 0.265625 (1.438 sec)
4.54... logprob:  0.702953, 0.312500 (1.384 sec)
4.55... logprob:  0.578742, 0.285156 (1.389 sec)
4.56... logprob:  0.690861, 0.322917 (1.397 sec)
4.57... logprob:  0.699956, 0.316406 (1.423 sec)
4.58... logprob:  0.630765, 0.282552 (1.392 sec)
4.59... logprob:  0.584731, 0.268229 (1.467 sec)
4.60... logprob:  0.760507, 0.317708 (1.411 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.435099, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.059102e-03 [3.568148e-07] 
Layer 'conv1' biases: 5.828612e-07 [1.287801e-09] 
Layer 'conv2' weights[0]: 7.047164e-03 [3.551781e-07] 
Layer 'conv2' biases: 9.999997e-01 [6.413369e-09] 
Layer 'conv3' weights[0]: 7.046021e-03 [3.560533e-07] 
Layer 'conv3' biases: 1.252255e-05 [2.799512e-08] 
Layer 'conv4' weights[0]: 7.074490e-03 [3.601489e-07] 
Layer 'conv4' biases: 1.000005e+00 [2.912066e-07] 
Layer 'conv5' weights[0]: 7.087166e-03 [2.082019e-06] 
Layer 'conv5' biases: 9.994983e-01 [2.219956e-06] 
Layer 'fc6' weights[0]: 7.496868e-03 [5.850264e-08] 
Layer 'fc6' biases: 9.999993e-01 [5.202359e-08] 
Layer 'fc7' weights[0]: 7.851944e-03 [1.257534e-07] 
Layer 'fc7' biases: 9.999634e-01 [1.646138e-07] 
Layer 'fc8' weights[0]: 3.407482e-03 [2.634707e-05] 
Layer 'fc8' biases: 5.207918e-03 [4.594303e-05] 
Train error last 800 batches: 0.657481
-------------------------------------------------------
Not saving because 0.435099 > 0.323801 (3.40: -8.65%)
======================================================= (2.384 sec)
4.61... logprob:  0.617838, 0.290365 (1.427 sec)
4.62... logprob:  0.692290, 0.312500 (1.451 sec)
4.63... logprob:  0.598336, 0.257812 (1.436 sec)
4.64... logprob:  0.775066, 0.339844 (1.409 sec)
4.65... logprob:  0.664102, 0.299479 (1.392 sec)
4.66... logprob:  0.526650, 0.212240 (1.441 sec)
4.67... logprob:  0.530984, 0.220052 (1.380 sec)
4.68... logprob:  0.594089, 0.274740 (1.393 sec)
4.69... logprob:  0.639437, 0.261719 (1.416 sec)
4.70... logprob:  0.539742, 0.256510 (1.419 sec)
4.71... logprob:  0.655579, 0.285156 (1.461 sec)
4.72... logprob:  0.685504, 0.287760 (1.397 sec)
4.73... logprob:  0.692304, 0.305990 (1.418 sec)
4.74... logprob:  0.767253, 0.298177 (1.411 sec)
4.75... logprob:  0.609875, 0.291667 (1.409 sec)
4.76... logprob:  0.654449, 0.299479 (1.429 sec)
4.77... logprob:  0.609586, 0.263021 (1.419 sec)
4.78... logprob:  0.752324, 0.334635 (1.443 sec)
4.79... logprob:  0.698522, 0.309896 (1.395 sec)
4.80... logprob:  0.658110, 0.263021 (1.424 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.517606, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.052061e-03 [3.608553e-07] 
Layer 'conv1' biases: 5.815848e-07 [1.175297e-09] 
Layer 'conv2' weights[0]: 7.040118e-03 [3.569410e-07] 
Layer 'conv2' biases: 9.999997e-01 [9.084740e-09] 
Layer 'conv3' weights[0]: 7.038978e-03 [3.570909e-07] 
Layer 'conv3' biases: 1.264107e-05 [3.299391e-08] 
Layer 'conv4' weights[0]: 7.067402e-03 [3.615232e-07] 
Layer 'conv4' biases: 1.000006e+00 [3.491330e-07] 
Layer 'conv5' weights[0]: 7.080409e-03 [2.337107e-06] 
Layer 'conv5' biases: 9.994971e-01 [2.493208e-06] 
Layer 'fc6' weights[0]: 7.496117e-03 [6.130726e-08] 
Layer 'fc6' biases: 9.999993e-01 [5.584984e-08] 
Layer 'fc7' weights[0]: 7.851182e-03 [1.314309e-07] 
Layer 'fc7' biases: 9.999628e-01 [1.766174e-07] 
Layer 'fc8' weights[0]: 3.400783e-03 [2.156036e-05] 
Layer 'fc8' biases: 5.141308e-03 [3.304554e-05] 
Train error last 800 batches: 0.658005
-------------------------------------------------------
Not saving because 0.517606 > 0.323801 (3.40: -8.65%)
======================================================= (2.372 sec)
4.81... logprob:  0.605112, 0.243489 (1.425 sec)
4.82... logprob:  0.525541, 0.259115 (1.422 sec)
4.83... logprob:  0.714385, 0.296875 (1.396 sec)
4.84... logprob:  0.604028, 0.265625 (1.459 sec)
4.85... logprob:  0.615728, 0.305990 (1.416 sec)
4.86... logprob:  0.660346, 0.294271 (1.416 sec)
4.87... logprob:  0.755596, 0.295573 (1.412 sec)
4.88... logprob:  0.742060, 0.330729 (1.401 sec)
4.89... logprob:  0.540924, 0.236979 (1.433 sec)
4.90... logprob:  0.812868, 0.351562 (1.390 sec)
4.91... logprob:  0.572774, 0.234375 (1.385 sec)
4.92... logprob:  0.653949, 0.286458 (1.395 sec)
4.93... logprob:  0.752890, 0.337240 (1.393 sec)
4.94... logprob:  0.571183, 0.264323 (1.384 sec)
4.95... logprob:  0.655889, 0.274740 (1.403 sec)
4.96... logprob:  0.759583, 0.335938 (1.395 sec)
4.97... logprob:  0.626435, 0.312500 (1.384 sec)
4.98... logprob:  0.552777, 0.265625 (1.430 sec)
4.99... logprob:  0.726294, 0.337240 (1.404 sec)
4.100... logprob:  0.444708, 0.201823 (1.394 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.490485, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.045027e-03 [3.589839e-07] 
Layer 'conv1' biases: 5.778358e-07 [1.384065e-09] 
Layer 'conv2' weights[0]: 7.033069e-03 [3.560094e-07] 
Layer 'conv2' biases: 9.999997e-01 [8.502025e-09] 
Layer 'conv3' weights[0]: 7.031979e-03 [3.567305e-07] 
Layer 'conv3' biases: 1.267209e-05 [3.325227e-08] 
Layer 'conv4' weights[0]: 7.060322e-03 [3.636117e-07] 
Layer 'conv4' biases: 1.000006e+00 [3.875742e-07] 
Layer 'conv5' weights[0]: 7.073484e-03 [2.506982e-06] 
Layer 'conv5' biases: 9.994888e-01 [2.601220e-06] 
Layer 'fc6' weights[0]: 7.495332e-03 [6.039811e-08] 
Layer 'fc6' biases: 9.999993e-01 [5.473439e-08] 
Layer 'fc7' weights[0]: 7.850371e-03 [1.307311e-07] 
Layer 'fc7' biases: 9.999628e-01 [1.937772e-07] 
Layer 'fc8' weights[0]: 3.436474e-03 [2.281483e-05] 
Layer 'fc8' biases: 5.309417e-03 [4.118536e-05] 
Train error last 800 batches: 0.656988
-------------------------------------------------------
Not saving because 0.490485 > 0.323801 (3.40: -8.65%)
======================================================= (2.403 sec)
4.101... logprob:  0.542135, 0.256510 (1.445 sec)
4.102... logprob:  0.751032, 0.317708 (1.390 sec)
4.103... logprob:  0.705410, 0.311198 (1.395 sec)
4.104... logprob:  0.611961, 0.300781 (1.401 sec)
4.105... logprob:  0.816617, 0.335937 (1.393 sec)
4.106... logprob:  0.511988, 0.240885 (1.387 sec)
4.107... logprob:  0.639595, 0.300781 (1.437 sec)
4.108... logprob:  0.760073, 0.332031 (1.388 sec)
4.109... logprob:  0.612817, 0.256510 (1.398 sec)
4.110... logprob:  0.865498, 0.334635 (1.399 sec)
4.111... logprob:  0.647369, 0.291667 (1.389 sec)
4.112... logprob:  0.642358, 0.279948 (1.392 sec)
4.113... logprob:  0.640892, 0.281250 (1.397 sec)
4.114... logprob:  0.632195, 0.276042 (1.424 sec)
4.115... logprob:  0.679551, 0.292969 (1.399 sec)
4.116... logprob:  0.713400, 0.298177 (1.395 sec)
4.117... logprob:  0.622828, 0.276042 (1.438 sec)
4.118... logprob:  0.608777, 0.257812 (1.380 sec)
4.119... logprob:  0.599450, 0.269531 (1.394 sec)
4.120... logprob:  0.640210, 0.257812 (1.393 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.518995, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.037977e-03 [3.599001e-07] 
Layer 'conv1' biases: 5.756165e-07 [1.670009e-09] 
Layer 'conv2' weights[0]: 7.026033e-03 [3.557969e-07] 
Layer 'conv2' biases: 9.999997e-01 [9.844146e-09] 
Layer 'conv3' weights[0]: 7.024921e-03 [3.555970e-07] 
Layer 'conv3' biases: 1.272742e-05 [3.072318e-08] 
Layer 'conv4' weights[0]: 7.053274e-03 [3.599032e-07] 
Layer 'conv4' biases: 1.000007e+00 [3.133369e-07] 
Layer 'conv5' weights[0]: 7.066873e-03 [2.235141e-06] 
Layer 'conv5' biases: 9.994823e-01 [2.369133e-06] 
Layer 'fc6' weights[0]: 7.494552e-03 [5.801496e-08] 
Layer 'fc6' biases: 9.999993e-01 [5.144497e-08] 
Layer 'fc7' weights[0]: 7.849596e-03 [1.210597e-07] 
Layer 'fc7' biases: 9.999614e-01 [1.461102e-07] 
Layer 'fc8' weights[0]: 3.400740e-03 [1.870981e-05] 
Layer 'fc8' biases: 5.133880e-03 [2.313320e-05] 
Train error last 800 batches: 0.657024
-------------------------------------------------------
Not saving because 0.518995 > 0.323801 (3.40: -8.65%)
======================================================= (2.375 sec)
4.121... logprob:  0.601896, 0.244792 (1.407 sec)
4.122... logprob:  0.699167, 0.309896 (1.444 sec)
4.123... logprob:  0.667119, 0.296875 (1.388 sec)
4.124... logprob:  0.582653, 0.291667 (1.398 sec)
4.125... logprob:  0.789594, 0.356771 (1.390 sec)
4.126... logprob:  0.688567, 0.298177 (1.386 sec)
4.127... logprob:  0.810158, 0.354167 (1.392 sec)
4.128... logprob:  0.616301, 0.283854 (1.413 sec)
4.129... logprob:  0.739649, 0.299479 (1.406 sec)
4.130... logprob:  0.642027, 0.269531 (1.411 sec)
4.131... logprob:  0.634101, 0.289062 (1.403 sec)
4.132... logprob:  0.717760, 0.305990 (1.430 sec)
4.133... logprob:  0.684400, 0.295573 (1.391 sec)
4.134... logprob:  0.646383, 0.264323 (1.390 sec)
4.135... logprob:  0.628412, 0.266927 (1.394 sec)
4.136... logprob:  0.707673, 0.298177 (1.385 sec)
4.137... logprob:  0.719435, 0.334635 (1.380 sec)
4.138... logprob:  0.595637, 0.302083 (1.438 sec)
4.139... logprob:  0.595380, 0.248698 (1.392 sec)
4.140... logprob:  0.812625, 0.363281 (1.403 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.514755, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.030969e-03 [3.584868e-07] 
Layer 'conv1' biases: 5.782582e-07 [1.290709e-09] 
Layer 'conv2' weights[0]: 7.019018e-03 [3.553340e-07] 
Layer 'conv2' biases: 9.999997e-01 [8.557529e-09] 
Layer 'conv3' weights[0]: 7.017888e-03 [3.553949e-07] 
Layer 'conv3' biases: 1.280465e-05 [3.239987e-08] 
Layer 'conv4' weights[0]: 7.046244e-03 [3.599459e-07] 
Layer 'conv4' biases: 1.000006e+00 [3.472221e-07] 
Layer 'conv5' weights[0]: 7.059605e-03 [2.176173e-06] 
Layer 'conv5' biases: 9.994828e-01 [2.352991e-06] 
Layer 'fc6' weights[0]: 7.493753e-03 [5.543690e-08] 
Layer 'fc6' biases: 9.999993e-01 [4.746505e-08] 
Layer 'fc7' weights[0]: 7.848803e-03 [1.156680e-07] 
Layer 'fc7' biases: 9.999606e-01 [1.280122e-07] 
Layer 'fc8' weights[0]: 3.373136e-03 [1.826218e-05] 
Layer 'fc8' biases: 4.970187e-03 [2.054596e-05] 
Train error last 800 batches: 0.657135
-------------------------------------------------------
Not saving because 0.514755 > 0.323801 (3.40: -8.65%)
======================================================= (2.391 sec)
4.141... logprob:  0.567849, 0.230469 (1.441 sec)
4.142... logprob:  0.655884, 0.294271 (1.401 sec)
4.143... logprob:  0.554779, 0.239583 (1.426 sec)
4.144... logprob:  0.631899, 0.298177 (1.409 sec)
4.145... logprob:  0.563429, 0.278646 (1.407 sec)
4.146... logprob:  0.687067, 0.319010 (1.403 sec)
4.147... logprob:  0.575745, 0.266927 (1.425 sec)
4.148... logprob:  0.629675, 0.302083 (1.385 sec)
4.149... logprob:  0.680402, 0.309896 (1.393 sec)
4.150... logprob:  0.614530, 0.281250 (1.398 sec)
4.151... logprob:  0.647466, 0.307292 (1.390 sec)
4.152... logprob:  0.954586, 0.359375 (1.383 sec)
4.153... logprob:  0.756861, 0.343750 (1.513 sec)
4.154... logprob:  0.798576, 0.322917 (1.395 sec)
4.155... logprob:  0.691069, 0.290365 (1.398 sec)
4.156... logprob:  0.540419, 0.248698 (1.430 sec)
4.157... logprob:  0.570930, 0.287760 (1.390 sec)
4.158... logprob:  0.595764, 0.272135 (1.391 sec)
4.159... logprob:  0.684737, 0.269531 (1.384 sec)
4.160... logprob:  0.699877, 0.277344 (1.391 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.495671, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.023924e-03 [3.594690e-07] 
Layer 'conv1' biases: 5.800111e-07 [1.430596e-09] 
Layer 'conv2' weights[0]: 7.012034e-03 [3.559711e-07] 
Layer 'conv2' biases: 9.999997e-01 [9.416178e-09] 
Layer 'conv3' weights[0]: 7.010871e-03 [3.568912e-07] 
Layer 'conv3' biases: 1.274397e-05 [3.885994e-08] 
Layer 'conv4' weights[0]: 7.039194e-03 [3.636899e-07] 
Layer 'conv4' biases: 1.000005e+00 [4.285840e-07] 
Layer 'conv5' weights[0]: 7.052452e-03 [2.668788e-06] 
Layer 'conv5' biases: 9.994836e-01 [2.893795e-06] 
Layer 'fc6' weights[0]: 7.492978e-03 [6.228769e-08] 
Layer 'fc6' biases: 9.999993e-01 [5.757806e-08] 
Layer 'fc7' weights[0]: 7.848005e-03 [1.348581e-07] 
Layer 'fc7' biases: 9.999607e-01 [1.883528e-07] 
Layer 'fc8' weights[0]: 3.427551e-03 [2.330627e-05] 
Layer 'fc8' biases: 5.151726e-03 [3.484341e-05] 
Train error last 800 batches: 0.657474
-------------------------------------------------------
Not saving because 0.495671 > 0.323801 (3.40: -8.65%)
======================================================= (2.360 sec)
4.161... logprob:  0.571534, 0.272135 (1.403 sec)
4.162... logprob:  0.779048, 0.343750 (1.408 sec)
4.163... logprob:  0.629041, 0.294271 (1.425 sec)
4.164... logprob:  0.720763, 0.333333 (1.418 sec)
4.165... logprob:  0.745109, 0.325521 (1.413 sec)
4.166... logprob:  0.701658, 0.309896 (1.444 sec)
4.167... logprob:  0.606907, 0.274740 (1.420 sec)
4.168... logprob:  0.542245, 0.235677 (1.428 sec)
4.169... logprob:  0.556300, 0.253906 (1.451 sec)
4.170... logprob:  0.619570, 0.285156 (1.397 sec)
4.171... logprob:  0.731928, 0.290365 (1.416 sec)
4.172... logprob:  0.598462, 0.244792 (1.406 sec)
4.173... logprob:  0.679155, 0.317708 (1.414 sec)
4.174... logprob:  0.711727, 0.303385 (1.405 sec)
4.175... logprob:  0.733633, 0.339844 (1.461 sec)
4.176... logprob:  0.608384, 0.255208 (1.408 sec)
4.177... logprob:  0.587932, 0.283854 (1.426 sec)
4.178... logprob:  0.626801, 0.279948 (1.447 sec)
4.179... logprob:  0.634694, 0.294271 (1.404 sec)
4.180... logprob:  0.579369, 0.264323 (1.413 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.406219, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.016904e-03 [3.579613e-07] 
Layer 'conv1' biases: 5.881078e-07 [1.337867e-09] 
Layer 'conv2' weights[0]: 7.004998e-03 [3.552974e-07] 
Layer 'conv2' biases: 9.999997e-01 [1.020208e-08] 
Layer 'conv3' weights[0]: 7.003909e-03 [3.569638e-07] 
Layer 'conv3' biases: 1.279567e-05 [3.670075e-08] 
Layer 'conv4' weights[0]: 7.032189e-03 [3.621178e-07] 
Layer 'conv4' biases: 1.000005e+00 [3.880958e-07] 
Layer 'conv5' weights[0]: 7.045486e-03 [2.616789e-06] 
Layer 'conv5' biases: 9.994810e-01 [2.746758e-06] 
Layer 'fc6' weights[0]: 7.492160e-03 [5.979573e-08] 
Layer 'fc6' biases: 9.999993e-01 [5.408416e-08] 
Layer 'fc7' weights[0]: 7.847244e-03 [1.262401e-07] 
Layer 'fc7' biases: 9.999602e-01 [1.766098e-07] 
Layer 'fc8' weights[0]: 3.450673e-03 [2.243841e-05] 
Layer 'fc8' biases: 5.250625e-03 [4.182973e-05] 
Train error last 800 batches: 0.657183
-------------------------------------------------------
Not saving because 0.406219 > 0.323801 (3.40: -8.65%)
======================================================= (2.362 sec)
4.181... logprob:  0.717497, 0.278646 (1.420 sec)
4.182... logprob:  0.638080, 0.300781 (1.420 sec)
4.183... logprob:  0.625196, 0.257812 (1.412 sec)
4.184... logprob:  0.624457, 0.277344 (1.412 sec)
4.185... logprob:  0.562452, 0.261719 (1.390 sec)
4.186... logprob:  0.583528, 0.270833 (1.394 sec)
4.187... logprob:  0.745190, 0.335938 (1.392 sec)
4.188... logprob:  0.666636, 0.290365 (1.399 sec)
4.189... logprob:  0.699367, 0.295573 (1.381 sec)
4.190... logprob:  0.612643, 0.277344 (1.429 sec)
4.191... logprob:  0.689929, 0.276042 (1.404 sec)
4.192... logprob:  0.743362, 0.312500 (1.407 sec)
4.193... logprob:  0.607880, 0.274739 (1.415 sec)
4.194... logprob:  0.620469, 0.270833 (1.406 sec)
4.195... logprob:  0.560255, 0.243490 (1.395 sec)
4.196... logprob:  0.571246, 0.235677 (1.384 sec)
4.197... logprob:  0.657572, 0.279948 (1.391 sec)
4.198... logprob:  0.617811, 0.266927 (1.398 sec)
4.199... logprob:  0.759120, 0.329427 (1.384 sec)
4.200... logprob:  0.674317, 0.294271 (1.428 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.429860, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.009917e-03 [3.551624e-07] 
Layer 'conv1' biases: 6.004907e-07 [1.332168e-09] 
Layer 'conv2' weights[0]: 6.998011e-03 [3.532381e-07] 
Layer 'conv2' biases: 9.999997e-01 [8.438620e-09] 
Layer 'conv3' weights[0]: 6.996900e-03 [3.542318e-07] 
Layer 'conv3' biases: 1.283396e-05 [3.271419e-08] 
Layer 'conv4' weights[0]: 7.025154e-03 [3.586776e-07] 
Layer 'conv4' biases: 1.000005e+00 [3.314066e-07] 
Layer 'conv5' weights[0]: 7.038746e-03 [2.315863e-06] 
Layer 'conv5' biases: 9.994780e-01 [2.363855e-06] 
Layer 'fc6' weights[0]: 7.491357e-03 [5.811967e-08] 
Layer 'fc6' biases: 9.999993e-01 [5.178608e-08] 
Layer 'fc7' weights[0]: 7.846454e-03 [1.217846e-07] 
Layer 'fc7' biases: 9.999599e-01 [1.491397e-07] 
Layer 'fc8' weights[0]: 3.470049e-03 [2.006588e-05] 
Layer 'fc8' biases: 5.361600e-03 [2.826712e-05] 
Train error last 800 batches: 0.657479
-------------------------------------------------------
Not saving because 0.429860 > 0.323801 (3.40: -8.65%)
======================================================= (2.363 sec)
4.201... logprob:  0.680612, 0.303385 (1.407 sec)
4.202... logprob:  0.710043, 0.303385 (1.398 sec)
4.203... logprob:  0.673704, 0.298177 (1.434 sec)
4.204... logprob:  0.754320, 0.335937 (1.383 sec)
4.205... logprob:  0.656849, 0.296875 (1.397 sec)
4.206... logprob:  0.597373, 0.273437 (1.399 sec)
4.207... logprob:  0.554123, 0.239583 (1.385 sec)
4.208... logprob:  0.692965, 0.292969 (1.397 sec)
4.209... logprob:  0.542483, 0.256510 (1.414 sec)
4.210... logprob:  0.710245, 0.332031 (1.412 sec)
4.211... logprob:  0.627364, 0.277344 (1.409 sec)
4.212... logprob:  0.731047, 0.316406 (1.411 sec)
4.213... logprob:  0.726048, 0.311198 (1.452 sec)
4.214... logprob:  0.608827, 0.243490 (1.417 sec)
4.215... logprob:  0.622709, 0.290365 (1.409 sec)
4.216... logprob:  0.698037, 0.281250 (1.462 sec)
4.217... logprob:  0.560933, 0.260417 (1.396 sec)
4.218... logprob:  0.714000, 0.304688 (1.418 sec)
4.219... logprob:  0.694464, 0.307292 (1.408 sec)
4.220... logprob:  0.550193, 0.230469 (1.416 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.415275, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.002942e-03 [3.548399e-07] 
Layer 'conv1' biases: 6.056374e-07 [1.421893e-09] 
Layer 'conv2' weights[0]: 6.991009e-03 [3.539980e-07] 
Layer 'conv2' biases: 9.999997e-01 [7.662767e-09] 
Layer 'conv3' weights[0]: 6.989903e-03 [3.542087e-07] 
Layer 'conv3' biases: 1.295107e-05 [2.916299e-08] 
Layer 'conv4' weights[0]: 7.018141e-03 [3.586265e-07] 
Layer 'conv4' biases: 1.000005e+00 [2.757198e-07] 
Layer 'conv5' weights[0]: 7.032000e-03 [1.841592e-06] 
Layer 'conv5' biases: 9.994759e-01 [1.897849e-06] 
Layer 'fc6' weights[0]: 7.490560e-03 [5.473710e-08] 
Layer 'fc6' biases: 9.999993e-01 [4.636945e-08] 
Layer 'fc7' weights[0]: 7.845710e-03 [1.119022e-07] 
Layer 'fc7' biases: 9.999585e-01 [1.172587e-07] 
Layer 'fc8' weights[0]: 3.440735e-03 [1.640153e-05] 
Layer 'fc8' biases: 5.216490e-03 [1.175029e-05] 
Train error last 800 batches: 0.657289
-------------------------------------------------------
Not saving because 0.415275 > 0.323801 (3.40: -8.65%)
======================================================= (2.435 sec)
4.221... logprob:  0.633594, 0.277344 (1.412 sec)
4.222... logprob:  0.715359, 0.295573 (1.457 sec)
4.223... logprob:  0.777624, 0.332031 (1.427 sec)
4.224... logprob:  0.605283, 0.289062 (1.424 sec)
4.225... logprob:  0.679596, 0.295573 (1.439 sec)
4.226... logprob:  0.648080, 0.277344 (1.415 sec)
4.227... logprob:  0.704012, 0.309896 (1.421 sec)
4.228... logprob:  0.528695, 0.265625 (1.406 sec)
4.229... logprob:  0.778945, 0.312500 (1.410 sec)
4.230... logprob:  0.753486, 0.321615 (1.414 sec)
4.231... logprob:  0.640942, 0.282552 (1.404 sec)
4.232... logprob:  0.726134, 0.308594 (1.450 sec)
4.233... logprob:  0.676753, 0.266927 (1.421 sec)
4.234... logprob:  0.798423, 0.341146 (1.411 sec)
4.235... logprob:  0.655176, 0.282552 (1.541 sec)
4.236... logprob:  0.701490, 0.290365 (1.398 sec)
4.237... logprob:  0.649559, 0.316406 (1.417 sec)
4.238... logprob:  0.648430, 0.298177 (1.403 sec)
4.239... logprob:  0.623998, 0.257812 (1.415 sec)
4.240... logprob:  0.675251, 0.283854 (1.396 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.517855, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.995952e-03 [3.580917e-07] 
Layer 'conv1' biases: 6.063112e-07 [1.506051e-09] 
Layer 'conv2' weights[0]: 6.984043e-03 [3.536154e-07] 
Layer 'conv2' biases: 9.999997e-01 [8.173801e-09] 
Layer 'conv3' weights[0]: 6.982924e-03 [3.536186e-07] 
Layer 'conv3' biases: 1.299747e-05 [2.923713e-08] 
Layer 'conv4' weights[0]: 7.011115e-03 [3.570444e-07] 
Layer 'conv4' biases: 1.000006e+00 [2.961833e-07] 
Layer 'conv5' weights[0]: 7.025407e-03 [2.077684e-06] 
Layer 'conv5' biases: 9.994751e-01 [2.143408e-06] 
Layer 'fc6' weights[0]: 7.489788e-03 [5.784497e-08] 
Layer 'fc6' biases: 9.999993e-01 [5.129653e-08] 
Layer 'fc7' weights[0]: 7.844951e-03 [1.199903e-07] 
Layer 'fc7' biases: 9.999584e-01 [1.374133e-07] 
Layer 'fc8' weights[0]: 3.407129e-03 [1.915763e-05] 
Layer 'fc8' biases: 4.943638e-03 [1.850970e-05] 
Train error last 800 batches: 0.657754
-------------------------------------------------------
Not saving because 0.517855 > 0.323801 (3.40: -8.65%)
======================================================= (2.368 sec)
4.241... logprob:  0.759106, 0.346354 (1.462 sec)
4.242... logprob:  0.586258, 0.260417 (1.428 sec)
4.243... logprob:  0.693964, 0.276042 (1.424 sec)
4.244... logprob:  0.533393, 0.221354 (1.439 sec)
4.245... logprob:  0.700565, 0.292969 (1.413 sec)
4.246... logprob:  0.581406, 0.263021 (1.411 sec)
4.247... logprob:  0.611933, 0.242187 (1.408 sec)
4.248... logprob:  0.468692, 0.205729 (1.409 sec)
4.249... logprob:  0.738551, 0.322917 (1.414 sec)
4.250... logprob:  0.781962, 0.311198 (1.403 sec)
4.251... logprob:  0.590888, 0.269531 (1.448 sec)
4.252... logprob:  0.581158, 0.257812 (1.426 sec)
4.253... logprob:  0.605123, 0.257812 (1.408 sec)
4.254... logprob:  0.642462, 0.282552 (1.463 sec)
4.255... logprob:  0.661296, 0.290365 (1.393 sec)
4.256... logprob:  0.578407, 0.248698 (1.416 sec)
4.257... logprob:  0.595944, 0.270833 (1.410 sec)
4.258... logprob:  0.576754, 0.278646 (1.412 sec)
4.259... logprob:  0.719807, 0.326823 (1.398 sec)
4.260... logprob:  0.591445, 0.276042 (1.450 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.457505, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.988978e-03 [3.557164e-07] 
Layer 'conv1' biases: 6.079259e-07 [1.090782e-09] 
Layer 'conv2' weights[0]: 6.977057e-03 [3.528478e-07] 
Layer 'conv2' biases: 9.999998e-01 [6.031663e-09] 
Layer 'conv3' weights[0]: 6.975915e-03 [3.521456e-07] 
Layer 'conv3' biases: 1.301005e-05 [2.455744e-08] 
Layer 'conv4' weights[0]: 7.004099e-03 [3.557220e-07] 
Layer 'conv4' biases: 1.000005e+00 [2.636032e-07] 
Layer 'conv5' weights[0]: 7.017752e-03 [1.892407e-06] 
Layer 'conv5' biases: 9.994681e-01 [2.025932e-06] 
Layer 'fc6' weights[0]: 7.489011e-03 [5.312046e-08] 
Layer 'fc6' biases: 9.999993e-01 [4.412353e-08] 
Layer 'fc7' weights[0]: 7.844121e-03 [1.081874e-07] 
Layer 'fc7' biases: 9.999594e-01 [1.169435e-07] 
Layer 'fc8' weights[0]: 3.515593e-03 [1.597018e-05] 
Layer 'fc8' biases: 5.620931e-03 [1.451896e-05] 
Train error last 800 batches: 0.657838
-------------------------------------------------------
Not saving because 0.457505 > 0.323801 (3.40: -8.65%)
======================================================= (2.410 sec)
4.261... logprob:  0.695827, 0.319010 (1.441 sec)
4.262... logprob:  0.761821, 0.296875 (1.433 sec)
4.263... logprob:  0.651883, 0.251302 (1.442 sec)
4.264... logprob:  0.610278, 0.286458 (1.418 sec)
4.265... logprob:  0.586428, 0.257812 (1.442 sec)
4.266... logprob:  0.526862, 0.257812 (1.408 sec)
4.267... logprob:  0.632756, 0.294271 (1.409 sec)
4.268... logprob:  0.628219, 0.277344 (1.414 sec)
4.269... logprob:  0.702448, 0.348958 (1.401 sec)
4.270... logprob:  0.810333, 0.309896 (1.452 sec)
4.271... logprob:  0.677819, 0.311198 (1.421 sec)
4.272... logprob:  0.615821, 0.251302 (1.407 sec)
4.273... logprob:  0.749457, 0.304688 (1.465 sec)
4.274... logprob:  0.782426, 0.352865 (1.394 sec)
4.275... logprob:  0.676941, 0.274740 (1.417 sec)
4.276... logprob:  0.577014, 0.268229 (1.405 sec)
4.277... logprob:  0.627654, 0.268229 (1.420 sec)
4.278... logprob:  0.570277, 0.243490 (1.417 sec)
4.279... logprob:  0.572384, 0.263021 (1.461 sec)
4.280... logprob:  0.503108, 0.238281 (1.398 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.555843, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.981954e-03 [3.561091e-07] 
Layer 'conv1' biases: 6.126309e-07 [1.490646e-09] 
Layer 'conv2' weights[0]: 6.970054e-03 [3.528349e-07] 
Layer 'conv2' biases: 9.999997e-01 [8.536039e-09] 
Layer 'conv3' weights[0]: 6.968943e-03 [3.525560e-07] 
Layer 'conv3' biases: 1.312443e-05 [2.849488e-08] 
Layer 'conv4' weights[0]: 6.997072e-03 [3.568197e-07] 
Layer 'conv4' biases: 1.000007e+00 [3.009854e-07] 
Layer 'conv5' weights[0]: 7.011637e-03 [2.036686e-06] 
Layer 'conv5' biases: 9.994656e-01 [2.120165e-06] 
Layer 'fc6' weights[0]: 7.488236e-03 [5.618425e-08] 
Layer 'fc6' biases: 9.999992e-01 [4.866655e-08] 
Layer 'fc7' weights[0]: 7.843370e-03 [1.180310e-07] 
Layer 'fc7' biases: 9.999571e-01 [1.530858e-07] 
Layer 'fc8' weights[0]: 3.435892e-03 [1.940159e-05] 
Layer 'fc8' biases: 5.163946e-03 [3.251766e-05] 
Train error last 800 batches: 0.657470
-------------------------------------------------------
Not saving because 0.555843 > 0.323801 (3.40: -8.65%)
======================================================= (2.403 sec)
4.281... logprob:  0.674166, 0.295573 (1.433 sec)
4.282... logprob:  0.686635, 0.313802 (1.418 sec)
4.283... logprob:  0.642154, 0.286458 (1.410 sec)
4.284... logprob:  0.589068, 0.264323 (1.405 sec)
4.285... logprob:  0.647165, 0.269531 (1.443 sec)
4.286... logprob:  0.698933, 0.330729 (1.434 sec)
4.287... logprob:  0.566663, 0.250000 (1.423 sec)
4.288... logprob:  0.607781, 0.278646 (1.431 sec)
4.289... logprob:  0.700989, 0.300781 (1.439 sec)
4.290... logprob:  0.710531, 0.302083 (1.406 sec)
4.291... logprob:  0.702101, 0.298177 (1.411 sec)
4.292... logprob:  0.776818, 0.317708 (1.410 sec)
4.293... logprob:  0.704026, 0.296875 (1.416 sec)
4.294... logprob:  0.594907, 0.274740 (1.405 sec)
4.295... logprob:  0.523307, 0.239583 (1.458 sec)
4.296... logprob:  0.659126, 0.304687 (1.413 sec)
4.297... logprob:  0.701712, 0.304687 (1.414 sec)
4.298... logprob:  0.720901, 0.289062 (1.454 sec)
4.299... logprob:  0.634087, 0.281250 (1.401 sec)
4.300... logprob:  0.656056, 0.308594 (1.419 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.416650, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.974983e-03 [3.547773e-07] 
Layer 'conv1' biases: 6.188396e-07 [9.592410e-10] 
Layer 'conv2' weights[0]: 6.963096e-03 [3.531413e-07] 
Layer 'conv2' biases: 9.999997e-01 [8.908952e-09] 
Layer 'conv3' weights[0]: 6.962003e-03 [3.535389e-07] 
Layer 'conv3' biases: 1.319592e-05 [3.473279e-08] 
Layer 'conv4' weights[0]: 6.990059e-03 [3.597492e-07] 
Layer 'conv4' biases: 1.000008e+00 [3.904774e-07] 
Layer 'conv5' weights[0]: 7.005466e-03 [2.248306e-06] 
Layer 'conv5' biases: 9.994609e-01 [2.426923e-06] 
Layer 'fc6' weights[0]: 7.487450e-03 [5.608735e-08] 
Layer 'fc6' biases: 9.999993e-01 [4.871068e-08] 
Layer 'fc7' weights[0]: 7.842612e-03 [1.172554e-07] 
Layer 'fc7' biases: 9.999574e-01 [1.351666e-07] 
Layer 'fc8' weights[0]: 3.493411e-03 [1.886775e-05] 
Layer 'fc8' biases: 5.398318e-03 [2.572580e-05] 
Train error last 800 batches: 0.658119
-------------------------------------------------------
Not saving because 0.416650 > 0.323801 (3.40: -8.65%)
======================================================= (2.375 sec)
4.301... logprob:  0.645198, 0.285156 (1.419 sec)
4.302... logprob:  0.816518, 0.333333 (1.421 sec)
4.303... logprob:  0.708310, 0.300781 (1.405 sec)
4.304... logprob:  0.662866, 0.269531 (1.442 sec)
4.305... logprob:  0.645656, 0.248698 (1.433 sec)
4.306... logprob:  0.648002, 0.296875 (1.431 sec)
4.307... logprob:  0.592619, 0.270833 (1.439 sec)
4.308... logprob:  0.573692, 0.255208 (1.447 sec)
4.309... logprob:  0.747585, 0.322917 (1.409 sec)
4.310... logprob:  0.664176, 0.299479 (1.412 sec)
4.311... logprob:  0.667368, 0.282552 (1.427 sec)
4.312... logprob:  0.593343, 0.268229 (1.426 sec)
4.313... logprob:  0.638212, 0.276042 (1.418 sec)
4.314... logprob:  0.694009, 0.312500 (1.454 sec)
4.315... logprob:  0.569876, 0.234375 (1.429 sec)
4.316... logprob:  0.689031, 0.276042 (1.420 sec)
4.317... logprob:  0.573409, 0.255208 (1.475 sec)
4.318... logprob:  0.636406, 0.276042 (1.409 sec)
4.319... logprob:  0.540528, 0.243490 (1.418 sec)
4.320... logprob:  0.612872, 0.268229 (1.420 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.371644, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.968031e-03 [3.542397e-07] 
Layer 'conv1' biases: 6.139805e-07 [1.432605e-09] 
Layer 'conv2' weights[0]: 6.956108e-03 [3.517948e-07] 
Layer 'conv2' biases: 9.999997e-01 [8.852549e-09] 
Layer 'conv3' weights[0]: 6.954994e-03 [3.531599e-07] 
Layer 'conv3' biases: 1.327303e-05 [3.130086e-08] 
Layer 'conv4' weights[0]: 6.983112e-03 [3.580936e-07] 
Layer 'conv4' biases: 1.000011e+00 [3.297527e-07] 
Layer 'conv5' weights[0]: 6.999665e-03 [2.449738e-06] 
Layer 'conv5' biases: 9.994521e-01 [2.591014e-06] 
Layer 'fc6' weights[0]: 7.486653e-03 [5.899823e-08] 
Layer 'fc6' biases: 9.999992e-01 [5.334478e-08] 
Layer 'fc7' weights[0]: 7.841830e-03 [1.245160e-07] 
Layer 'fc7' biases: 9.999571e-01 [1.643616e-07] 
Layer 'fc8' weights[0]: 3.482700e-03 [2.109872e-05] 
Layer 'fc8' biases: 5.348552e-03 [3.752027e-05] 
Train error last 800 batches: 0.657428
-------------------------------------------------------
Not saving because 0.371644 > 0.323801 (3.40: -8.65%)
======================================================= (2.370 sec)
4.321... logprob:  0.560868, 0.251302 (1.431 sec)
4.322... logprob:  0.530889, 0.261719 (1.418 sec)
4.323... logprob:  0.583135, 0.260417 (1.470 sec)
4.324... logprob:  0.612421, 0.272135 (1.423 sec)
4.325... logprob:  0.578914, 0.270833 (1.427 sec)
4.326... logprob:  0.692274, 0.300781 (1.459 sec)
4.327... logprob:  0.812834, 0.373698 (1.421 sec)
4.328... logprob:  0.709282, 0.268229 (1.420 sec)
4.329... logprob:  0.641154, 0.269531 (1.422 sec)
4.330... logprob:  0.663518, 0.292969 (1.416 sec)
4.331... logprob:  0.549902, 0.266927 (1.409 sec)
4.332... logprob:  0.735717, 0.304687 (1.444 sec)
4.333... logprob:  0.589977, 0.260417 (1.435 sec)
4.334... logprob:  0.756634, 0.315104 (1.438 sec)
4.335... logprob:  0.636441, 0.295573 (1.430 sec)
4.336... logprob:  0.688449, 0.298177 (1.453 sec)
4.337... logprob:  0.732296, 0.298177 (1.408 sec)
4.338... logprob:  0.611727, 0.295573 (1.417 sec)
4.339... logprob:  0.709410, 0.298177 (1.417 sec)
4.340... logprob:  0.657827, 0.277344 (1.422 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.505122, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.961024e-03 [3.564637e-07] 
Layer 'conv1' biases: 6.149124e-07 [1.247055e-09] 
Layer 'conv2' weights[0]: 6.949146e-03 [3.522010e-07] 
Layer 'conv2' biases: 9.999997e-01 [9.110108e-09] 
Layer 'conv3' weights[0]: 6.947989e-03 [3.536370e-07] 
Layer 'conv3' biases: 1.333384e-05 [3.636810e-08] 
Layer 'conv4' weights[0]: 6.976149e-03 [3.598370e-07] 
Layer 'conv4' biases: 1.000011e+00 [4.243853e-07] 
Layer 'conv5' weights[0]: 6.992813e-03 [2.734227e-06] 
Layer 'conv5' biases: 9.994490e-01 [2.989428e-06] 
Layer 'fc6' weights[0]: 7.485864e-03 [6.401063e-08] 
Layer 'fc6' biases: 9.999992e-01 [6.035784e-08] 
Layer 'fc7' weights[0]: 7.841086e-03 [1.388935e-07] 
Layer 'fc7' biases: 9.999566e-01 [1.969896e-07] 
Layer 'fc8' weights[0]: 3.482626e-03 [2.255479e-05] 
Layer 'fc8' biases: 5.360460e-03 [3.849307e-05] 
Train error last 800 batches: 0.657230
-------------------------------------------------------
Not saving because 0.505122 > 0.323801 (3.40: -8.65%)
======================================================= (2.353 sec)
4.341... logprob:  0.734444, 0.315104 (1.425 sec)
4.342... logprob:  0.637521, 0.270833 (1.485 sec)
4.343... logprob:  0.670195, 0.268229 (1.440 sec)
4.344... logprob:  0.645764, 0.298177 (1.474 sec)
4.345... logprob:  0.704210, 0.326823 (1.433 sec)
4.346... logprob:  0.625383, 0.281250 (1.429 sec)
4.347... logprob:  0.594555, 0.238281 (1.479 sec)
4.348... logprob:  0.584820, 0.269531 (1.425 sec)
4.349... logprob:  0.654750, 0.282552 (1.428 sec)
4.350... logprob:  0.628787, 0.282552 (1.435 sec)
4.351... logprob:  0.767425, 0.348958 (1.424 sec)
4.352... logprob:  0.584795, 0.274740 (1.424 sec)
4.353... logprob:  0.700177, 0.334635 (1.486 sec)
4.354... logprob:  0.802327, 0.338542 (1.424 sec)
4.355... logprob:  0.599709, 0.270833 (1.441 sec)
4.356... logprob:  0.755393, 0.325521 (1.468 sec)
4.357... logprob:  0.614985, 0.283854 (1.429 sec)
4.358... logprob:  0.563886, 0.246094 (1.431 sec)
4.359... logprob:  0.728820, 0.330729 (1.424 sec)
4.360... logprob:  0.568840, 0.246094 (1.424 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.475000, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.954059e-03 [3.537387e-07] 
Layer 'conv1' biases: 6.219783e-07 [1.081022e-09] 
Layer 'conv2' weights[0]: 6.942229e-03 [3.503800e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.521133e-09] 
Layer 'conv3' weights[0]: 6.941099e-03 [3.513238e-07] 
Layer 'conv3' biases: 1.341948e-05 [2.933870e-08] 
Layer 'conv4' weights[0]: 6.969214e-03 [3.558590e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.010854e-07] 
Layer 'conv5' weights[0]: 6.986549e-03 [2.073576e-06] 
Layer 'conv5' biases: 9.994408e-01 [2.143402e-06] 
Layer 'fc6' weights[0]: 7.485072e-03 [5.705458e-08] 
Layer 'fc6' biases: 9.999992e-01 [5.073384e-08] 
Layer 'fc7' weights[0]: 7.840286e-03 [1.192418e-07] 
Layer 'fc7' biases: 9.999560e-01 [1.437411e-07] 
Layer 'fc8' weights[0]: 3.476168e-03 [2.034116e-05] 
Layer 'fc8' biases: 5.337697e-03 [2.893342e-05] 
Train error last 800 batches: 0.657329
-------------------------------------------------------
Not saving because 0.475000 > 0.323801 (3.40: -8.65%)
======================================================= (2.357 sec)
4.361... logprob:  0.696588, 0.292969 (1.438 sec)
4.362... logprob:  0.630572, 0.303385 (1.481 sec)
4.363... logprob:  0.725741, 0.309896 (1.441 sec)
4.364... logprob:  0.679227, 0.316406 (1.444 sec)
4.365... logprob:  0.598227, 0.256510 (1.460 sec)
4.366... logprob:  0.706808, 0.311198 (1.438 sec)
4.367... logprob:  0.592703, 0.307292 (1.432 sec)
4.368... logprob:  0.866867, 0.312500 (1.423 sec)
4.369... logprob:  0.614082, 0.273438 (1.418 sec)
4.370... logprob:  0.618426, 0.270833 (1.428 sec)
4.371... logprob:  0.674907, 0.303385 (1.453 sec)
4.372... logprob:  0.742378, 0.308594 (1.450 sec)
4.373... logprob:  0.694732, 0.286458 (1.446 sec)
4.374... logprob:  0.692254, 0.304687 (1.445 sec)
4.375... logprob:  0.662008, 0.290365 (1.460 sec)
4.376... logprob:  0.551164, 0.257812 (1.429 sec)
4.377... logprob:  0.648555, 0.296875 (1.419 sec)
4.378... logprob:  0.593159, 0.264323 (1.425 sec)
4.379... logprob:  0.697209, 0.294271 (1.433 sec)
4.380... logprob:  0.811355, 0.346354 (1.431 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.435136, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.947134e-03 [3.533318e-07] 
Layer 'conv1' biases: 6.235740e-07 [1.633874e-09] 
Layer 'conv2' weights[0]: 6.935267e-03 [3.516356e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.068398e-09] 
Layer 'conv3' weights[0]: 6.934165e-03 [3.516673e-07] 
Layer 'conv3' biases: 1.351798e-05 [3.343443e-08] 
Layer 'conv4' weights[0]: 6.962191e-03 [3.552969e-07] 
Layer 'conv4' biases: 1.000014e+00 [3.305588e-07] 
Layer 'conv5' weights[0]: 6.979796e-03 [2.400237e-06] 
Layer 'conv5' biases: 9.994418e-01 [2.517087e-06] 
Layer 'fc6' weights[0]: 7.484308e-03 [5.656489e-08] 
Layer 'fc6' biases: 9.999992e-01 [4.972369e-08] 
Layer 'fc7' weights[0]: 7.839521e-03 [1.186225e-07] 
Layer 'fc7' biases: 9.999547e-01 [1.289768e-07] 
Layer 'fc8' weights[0]: 3.452575e-03 [1.746028e-05] 
Layer 'fc8' biases: 5.214655e-03 [9.250425e-06] 
Train error last 800 batches: 0.657674
-------------------------------------------------------
Not saving because 0.435136 > 0.323801 (3.40: -8.65%)
======================================================= (2.377 sec)
4.381... logprob:  0.673678, 0.283854 (1.472 sec)
4.382... logprob:  0.766862, 0.341146 (1.454 sec)
4.383... logprob:  0.603787, 0.276042 (1.439 sec)
4.384... logprob:  0.815952, 0.372396 (1.474 sec)
4.385... logprob:  0.635597, 0.276042 (1.424 sec)
4.386... logprob:  0.765987, 0.325521 (1.425 sec)
4.387... logprob:  0.636402, 0.302083 (1.435 sec)
4.388... logprob:  0.711911, 0.305990 (1.429 sec)
4.389... logprob:  0.703832, 0.320312 (1.427 sec)
4.390... logprob:  0.598955, 0.257812 (1.468 sec)
4.391... logprob:  0.558906, 0.252604 (1.440 sec)
4.392... logprob:  0.677487, 0.274740 (1.426 sec)
4.393... logprob:  0.592578, 0.225260 (1.482 sec)
4.394... logprob:  0.620208, 0.283854 (1.424 sec)
4.395... logprob:  0.518904, 0.235677 (1.424 sec)
4.396... logprob:  0.562130, 0.265625 (1.434 sec)
4.397... logprob:  0.563371, 0.272135 (1.420 sec)
4.398... logprob:  0.637626, 0.278646 (1.429 sec)
4.399... logprob:  0.643834, 0.294271 (1.476 sec)
4.400... logprob:  0.738683, 0.309896 (1.432 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.423856, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.940152e-03 [3.548945e-07] 
Layer 'conv1' biases: 6.267212e-07 [1.635141e-09] 
Layer 'conv2' weights[0]: 6.928364e-03 [3.514850e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.106978e-08] 
Layer 'conv3' weights[0]: 6.927216e-03 [3.546166e-07] 
Layer 'conv3' biases: 1.350354e-05 [4.109126e-08] 
Layer 'conv4' weights[0]: 6.955232e-03 [3.603698e-07] 
Layer 'conv4' biases: 1.000012e+00 [4.237565e-07] 
Layer 'conv5' weights[0]: 6.972252e-03 [2.824350e-06] 
Layer 'conv5' biases: 9.994360e-01 [3.035475e-06] 
Layer 'fc6' weights[0]: 7.483508e-03 [6.240760e-08] 
Layer 'fc6' biases: 9.999992e-01 [5.857795e-08] 
Layer 'fc7' weights[0]: 7.838761e-03 [1.391280e-07] 
Layer 'fc7' biases: 9.999565e-01 [2.089143e-07] 
Layer 'fc8' weights[0]: 3.552091e-03 [2.506058e-05] 
Layer 'fc8' biases: 5.654320e-03 [5.104775e-05] 
Train error last 800 batches: 0.657552
-------------------------------------------------------
Not saving because 0.423856 > 0.323801 (3.40: -8.65%)
======================================================= (2.388 sec)
4.401... logprob:  0.713797, 0.324219 (1.438 sec)
4.402... logprob:  0.643503, 0.294271 (1.475 sec)
4.403... logprob:  0.699349, 0.335937 (1.422 sec)
4.404... logprob:  0.675738, 0.294271 (1.440 sec)
4.405... logprob:  0.739982, 0.309896 (1.429 sec)
4.406... logprob:  0.643324, 0.286458 (1.418 sec)
4.407... logprob:  0.717184, 0.286458 (1.429 sec)
4.408... logprob:  0.634371, 0.303385 (1.473 sec)
4.409... logprob:  0.547908, 0.255208 (1.434 sec)
4.410... logprob:  0.789456, 0.322917 (1.443 sec)
4.411... logprob:  0.606770, 0.287760 (1.464 sec)
4.412... logprob:  0.762505, 0.329427 (1.431 sec)
4.413... logprob:  0.661898, 0.299479 (1.432 sec)
4.414... logprob:  0.715923, 0.320313 (1.424 sec)
4.415... logprob:  0.624263, 0.265625 (1.419 sec)
4.416... logprob:  0.605605, 0.270833 (1.428 sec)
4.417... logprob:  0.571119, 0.242187 (1.460 sec)
4.418... logprob:  0.661314, 0.263021 (1.445 sec)
4.419... logprob:  0.635086, 0.263021 (1.447 sec)
4.420... logprob:  0.642336, 0.303385 (1.459 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.380968, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.933239e-03 [3.529446e-07] 
Layer 'conv1' biases: 6.266037e-07 [1.539314e-09] 
Layer 'conv2' weights[0]: 6.921392e-03 [3.514319e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.028389e-08] 
Layer 'conv3' weights[0]: 6.920257e-03 [3.535095e-07] 
Layer 'conv3' biases: 1.364437e-05 [3.923476e-08] 
Layer 'conv4' weights[0]: 6.948257e-03 [3.596552e-07] 
Layer 'conv4' biases: 1.000013e+00 [4.412904e-07] 
Layer 'conv5' weights[0]: 6.965760e-03 [2.517695e-06] 
Layer 'conv5' biases: 9.994326e-01 [2.681267e-06] 
Layer 'fc6' weights[0]: 7.482732e-03 [5.860858e-08] 
Layer 'fc6' biases: 9.999992e-01 [5.322072e-08] 
Layer 'fc7' weights[0]: 7.838042e-03 [1.285407e-07] 
Layer 'fc7' biases: 9.999550e-01 [1.719208e-07] 
Layer 'fc8' weights[0]: 3.490484e-03 [2.555441e-05] 
Layer 'fc8' biases: 5.354657e-03 [4.445718e-05] 
Train error last 800 batches: 0.657485
-------------------------------------------------------
Not saving because 0.380968 > 0.323801 (3.40: -8.65%)
======================================================= (2.379 sec)
4.421... logprob:  0.613527, 0.281250 (1.455 sec)
4.422... logprob:  0.725221, 0.291667 (1.442 sec)
4.423... logprob:  0.624195, 0.282552 (1.425 sec)
4.424... logprob:  0.568937, 0.255208 (1.425 sec)
4.425... logprob:  0.517585, 0.247396 (1.429 sec)
4.426... logprob:  0.625255, 0.278646 (1.439 sec)
4.427... logprob:  0.681181, 0.303385 (1.456 sec)
4.428... logprob:  0.726766, 0.315104 (1.444 sec)
4.429... logprob:  0.622397, 0.283854 (1.439 sec)
4.430... logprob:  0.554623, 0.248698 (1.479 sec)
4.431... logprob:  0.706934, 0.291667 (1.424 sec)
4.432... logprob:  0.665547, 0.286458 (1.423 sec)
4.433... logprob:  0.583673, 0.248698 (1.430 sec)
4.434... logprob:  0.703136, 0.317708 (1.430 sec)
4.435... logprob:  0.709468, 0.311198 (1.426 sec)
4.436... logprob:  0.585814, 0.251302 (1.469 sec)
4.437... logprob:  0.668334, 0.312500 (1.439 sec)
4.438... logprob:  0.738490, 0.307292 (1.423 sec)
4.439... logprob:  0.600519, 0.273437 (1.484 sec)
4.440... logprob:  0.686887, 0.311198 (1.425 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.555626, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.926316e-03 [3.508992e-07] 
Layer 'conv1' biases: 6.285868e-07 [1.415334e-09] 
Layer 'conv2' weights[0]: 6.914509e-03 [3.494165e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.645033e-09] 
Layer 'conv3' weights[0]: 6.913343e-03 [3.492304e-07] 
Layer 'conv3' biases: 1.378962e-05 [2.968565e-08] 
Layer 'conv4' weights[0]: 6.941327e-03 [3.539820e-07] 
Layer 'conv4' biases: 1.000014e+00 [3.278794e-07] 
Layer 'conv5' weights[0]: 6.959080e-03 [2.143945e-06] 
Layer 'conv5' biases: 9.994310e-01 [2.361448e-06] 
Layer 'fc6' weights[0]: 7.481976e-03 [5.708443e-08] 
Layer 'fc6' biases: 9.999992e-01 [5.081085e-08] 
Layer 'fc7' weights[0]: 7.837209e-03 [1.209102e-07] 
Layer 'fc7' biases: 9.999545e-01 [1.474698e-07] 
Layer 'fc8' weights[0]: 3.493393e-03 [1.856281e-05] 
Layer 'fc8' biases: 5.338742e-03 [2.602047e-05] 
Train error last 800 batches: 0.656839
-------------------------------------------------------
Not saving because 0.555626 > 0.323801 (3.40: -8.65%)
======================================================= (2.386 sec)
4.441... logprob:  0.774313, 0.373698 (1.431 sec)
4.442... logprob:  0.569611, 0.240885 (1.435 sec)
4.443... logprob:  0.756453, 0.350260 (1.434 sec)
4.444... logprob:  0.715545, 0.322917 (1.433 sec)
4.445... logprob:  0.653981, 0.298177 (1.483 sec)
4.446... logprob:  0.620060, 0.272135 (1.430 sec)
4.447... logprob:  0.660986, 0.290365 (1.432 sec)
4.448... logprob:  0.568592, 0.244792 (1.473 sec)
4.449... logprob:  0.637912, 0.299479 (1.430 sec)
4.450... logprob:  0.480327, 0.214844 (1.428 sec)
4.451... logprob:  0.714187, 0.324219 (1.434 sec)
4.452... logprob:  0.653458, 0.282552 (1.426 sec)
4.453... logprob:  0.636826, 0.299479 (1.425 sec)
4.454... logprob:  0.730167, 0.332031 (1.477 sec)
4.455... logprob:  0.716341, 0.298177 (1.429 sec)
4.456... logprob:  0.658969, 0.261719 (1.439 sec)
4.457... logprob:  0.616723, 0.281250 (1.472 sec)
4.458... logprob:  0.621270, 0.266927 (1.461 sec)
4.459... logprob:  0.706958, 0.298177 (1.430 sec)
4.460... logprob:  0.542775, 0.247396 (1.428 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.450452, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.919379e-03 [3.526840e-07] 
Layer 'conv1' biases: 6.328748e-07 [1.561462e-09] 
Layer 'conv2' weights[0]: 6.907604e-03 [3.490423e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.074116e-09] 
Layer 'conv3' weights[0]: 6.906453e-03 [3.499911e-07] 
Layer 'conv3' biases: 1.382068e-05 [3.086001e-08] 
Layer 'conv4' weights[0]: 6.934394e-03 [3.554691e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.460589e-07] 
Layer 'conv5' weights[0]: 6.952067e-03 [2.344747e-06] 
Layer 'conv5' biases: 9.994299e-01 [2.562472e-06] 
Layer 'fc6' weights[0]: 7.481192e-03 [5.833452e-08] 
Layer 'fc6' biases: 9.999992e-01 [5.257889e-08] 
Layer 'fc7' weights[0]: 7.836459e-03 [1.242780e-07] 
Layer 'fc7' biases: 9.999545e-01 [1.623305e-07] 
Layer 'fc8' weights[0]: 3.537278e-03 [2.014020e-05] 
Layer 'fc8' biases: 5.510553e-03 [3.144698e-05] 
Train error last 800 batches: 0.657100
-------------------------------------------------------
Not saving because 0.450452 > 0.323801 (3.40: -8.65%)
======================================================= (2.406 sec)
4.461... logprob:  0.635808, 0.261719 (1.430 sec)
4.462... logprob:  0.660648, 0.292969 (1.435 sec)
4.463... logprob:  0.574047, 0.248698 (1.462 sec)
4.464... logprob:  0.677413, 0.298177 (1.444 sec)
4.465... logprob:  0.652053, 0.274740 (1.443 sec)
4.466... logprob:  0.534213, 0.234375 (1.454 sec)
4.467... logprob:  0.721735, 0.307292 (1.446 sec)
4.468... logprob:  0.686379, 0.302083 (1.441 sec)
4.469... logprob:  0.562258, 0.231771 (1.427 sec)
4.470... logprob:  0.683520, 0.321615 (1.423 sec)
4.471... logprob:  0.759129, 0.320312 (1.436 sec)
4.472... logprob:  0.664484, 0.325521 (1.448 sec)
4.473... logprob:  0.591075, 0.259115 (1.452 sec)
4.474... logprob:  0.619677, 0.283854 (1.446 sec)
4.475... logprob:  0.640166, 0.259115 (1.447 sec)
4.476... logprob:  0.748650, 0.321615 (1.465 sec)
4.477... logprob:  0.587719, 0.272135 (1.432 sec)
4.478... logprob:  0.655973, 0.311198 (1.414 sec)
4.479... logprob:  0.486703, 0.227865 (1.427 sec)
4.480... logprob:  0.701728, 0.303385 (1.432 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.383914, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.912469e-03 [3.508295e-07] 
Layer 'conv1' biases: 6.401409e-07 [1.276020e-09] 
Layer 'conv2' weights[0]: 6.900685e-03 [3.480136e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.382363e-09] 
Layer 'conv3' weights[0]: 6.899588e-03 [3.485500e-07] 
Layer 'conv3' biases: 1.398752e-05 [2.708854e-08] 
Layer 'conv4' weights[0]: 6.927458e-03 [3.515914e-07] 
Layer 'conv4' biases: 1.000014e+00 [2.824891e-07] 
Layer 'conv5' weights[0]: 6.945414e-03 [1.811397e-06] 
Layer 'conv5' biases: 9.994307e-01 [1.933728e-06] 
Layer 'fc6' weights[0]: 7.480386e-03 [5.307182e-08] 
Layer 'fc6' biases: 9.999991e-01 [4.436000e-08] 
Layer 'fc7' weights[0]: 7.835673e-03 [1.090375e-07] 
Layer 'fc7' biases: 9.999539e-01 [1.143951e-07] 
Layer 'fc8' weights[0]: 3.526712e-03 [1.554775e-05] 
Layer 'fc8' biases: 5.514410e-03 [9.627984e-06] 
Train error last 800 batches: 0.656566
-------------------------------------------------------
Not saving because 0.383914 > 0.323801 (3.40: -8.65%)
======================================================= (2.388 sec)
4.481... logprob:  0.649028, 0.300781 (1.439 sec)
4.482... logprob:  0.623797, 0.268229 (1.475 sec)
4.483... logprob:  0.778153, 0.302083 (1.447 sec)
4.484... logprob:  0.667551, 0.274740 (1.435 sec)
4.485... logprob:  0.673036, 0.294271 (1.479 sec)
4.486... logprob:  0.647921, 0.294271 (1.433 sec)
4.487... logprob:  0.692118, 0.283854 (1.424 sec)
4.488... logprob:  0.639006, 0.263021 (1.433 sec)
4.489... logprob:  0.671918, 0.300781 (1.434 sec)
4.490... logprob:  0.619322, 0.279948 (1.432 sec)
4.491... logprob:  0.634701, 0.285156 (1.471 sec)
4.492... logprob:  0.761234, 0.335937 (1.437 sec)
4.493... logprob:  0.738910, 0.291667 (1.427 sec)
4.494... logprob:  0.692935, 0.322917 (1.562 sec)
4.495... logprob:  0.612127, 0.286458 (1.427 sec)
4.496... logprob:  0.800808, 0.334635 (1.459 sec)
4.497... logprob:  0.658518, 0.281250 (1.430 sec)
4.498... logprob:  0.736800, 0.311198 (1.422 sec)
4.499... logprob:  0.637390, 0.305990 (1.426 sec)
4.500... logprob:  0.666707, 0.298177 (1.485 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.458972, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.905593e-03 [3.519302e-07] 
Layer 'conv1' biases: 6.458674e-07 [1.419295e-09] 
Layer 'conv2' weights[0]: 6.893824e-03 [3.486615e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.761427e-09] 
Layer 'conv3' weights[0]: 6.892682e-03 [3.496986e-07] 
Layer 'conv3' biases: 1.416527e-05 [3.241044e-08] 
Layer 'conv4' weights[0]: 6.920570e-03 [3.541601e-07] 
Layer 'conv4' biases: 1.000014e+00 [3.397381e-07] 
Layer 'conv5' weights[0]: 6.939043e-03 [2.403368e-06] 
Layer 'conv5' biases: 9.994327e-01 [2.537109e-06] 
Layer 'fc6' weights[0]: 7.479623e-03 [5.539587e-08] 
Layer 'fc6' biases: 9.999991e-01 [4.799424e-08] 
Layer 'fc7' weights[0]: 7.834896e-03 [1.159545e-07] 
Layer 'fc7' biases: 9.999523e-01 [1.224108e-07] 
Layer 'fc8' weights[0]: 3.467122e-03 [1.674558e-05] 
Layer 'fc8' biases: 5.104617e-03 [8.965699e-06] 
Train error last 800 batches: 0.656907
-------------------------------------------------------
Not saving because 0.458972 > 0.323801 (3.40: -8.65%)
======================================================= (2.385 sec)
4.501... logprob:  0.602843, 0.268229 (1.437 sec)
4.502... logprob:  0.662559, 0.309896 (1.444 sec)
4.503... logprob:  0.625604, 0.252604 (1.475 sec)
4.504... logprob:  0.609295, 0.243489 (1.423 sec)
4.505... logprob:  0.812694, 0.341146 (1.433 sec)
4.506... logprob:  0.672705, 0.313802 (1.428 sec)
4.507... logprob:  0.532316, 0.214844 (1.419 sec)
4.508... logprob:  0.551155, 0.220052 (1.429 sec)
4.509... logprob:  0.505980, 0.226562 (1.468 sec)
4.510... logprob:  0.590228, 0.273437 (1.437 sec)
4.511... logprob:  0.648530, 0.266927 (1.446 sec)
4.512... logprob:  0.689295, 0.302083 (1.466 sec)
4.513... logprob:  0.535184, 0.235677 (1.439 sec)
4.514... logprob:  0.673452, 0.298177 (1.430 sec)
4.515... logprob:  0.623144, 0.287760 (1.421 sec)
4.516... logprob:  0.646597, 0.294271 (1.421 sec)
4.517... logprob:  0.746642, 0.334635 (1.430 sec)
4.518... logprob:  0.563145, 0.244792 (1.452 sec)
4.519... logprob:  0.618864, 0.279948 (1.452 sec)
4.520... logprob:  0.625132, 0.286458 (1.447 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.468251, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.898689e-03 [3.508528e-07] 
Layer 'conv1' biases: 6.477119e-07 [1.201128e-09] 
Layer 'conv2' weights[0]: 6.886924e-03 [3.470790e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.449054e-09] 
Layer 'conv3' weights[0]: 6.885776e-03 [3.473562e-07] 
Layer 'conv3' biases: 1.418453e-05 [2.483570e-08] 
Layer 'conv4' weights[0]: 6.913621e-03 [3.511404e-07] 
Layer 'conv4' biases: 1.000014e+00 [2.735773e-07] 
Layer 'conv5' weights[0]: 6.932151e-03 [1.774583e-06] 
Layer 'conv5' biases: 9.994285e-01 [1.884304e-06] 
Layer 'fc6' weights[0]: 7.478872e-03 [5.368133e-08] 
Layer 'fc6' biases: 9.999991e-01 [4.542398e-08] 
Layer 'fc7' weights[0]: 7.834150e-03 [1.100049e-07] 
Layer 'fc7' biases: 9.999541e-01 [1.142681e-07] 
Layer 'fc8' weights[0]: 3.554127e-03 [1.595407e-05] 
Layer 'fc8' biases: 5.548216e-03 [8.863713e-06] 
Train error last 800 batches: 0.655643
-------------------------------------------------------
Not saving because 0.468251 > 0.323801 (3.40: -8.65%)
======================================================= (2.367 sec)
4.521... logprob:  0.678537, 0.298177 (1.465 sec)
4.522... logprob:  0.744549, 0.322917 (1.467 sec)
4.523... logprob:  0.480867, 0.209635 (1.434 sec)
4.524... logprob:  0.682030, 0.303385 (1.419 sec)
4.525... logprob:  0.703619, 0.273437 (1.424 sec)
4.526... logprob:  0.671052, 0.307292 (1.441 sec)
4.527... logprob:  0.714276, 0.322917 (1.437 sec)
4.528... logprob:  0.682813, 0.283854 (1.467 sec)
4.529... logprob:  0.601884, 0.265625 (1.441 sec)
4.530... logprob:  0.649948, 0.261719 (1.436 sec)
4.531... logprob:  0.660545, 0.277344 (1.474 sec)
4.532... logprob:  0.614754, 0.270833 (1.420 sec)
4.533... logprob:  0.790633, 0.324219 (1.425 sec)
4.534... logprob:  0.634349, 0.291667 (1.452 sec)
4.535... logprob:  0.832373, 0.329427 (1.430 sec)
4.536... logprob:  0.745605, 0.317708 (1.428 sec)
4.537... logprob:  0.769248, 0.308594 (1.470 sec)
4.538... logprob:  0.645589, 0.251302 (1.440 sec)
4.539... logprob:  0.581321, 0.234375 (1.435 sec)
4.540... logprob:  0.598461, 0.272135 (1.484 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.516876, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.891805e-03 [3.531668e-07] 
Layer 'conv1' biases: 6.466300e-07 [1.515690e-09] 
Layer 'conv2' weights[0]: 6.880031e-03 [3.494470e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.631823e-09] 
Layer 'conv3' weights[0]: 6.878981e-03 [3.506877e-07] 
Layer 'conv3' biases: 1.430423e-05 [3.605873e-08] 
Layer 'conv4' weights[0]: 6.906710e-03 [3.565507e-07] 
Layer 'conv4' biases: 1.000014e+00 [4.074182e-07] 
Layer 'conv5' weights[0]: 6.925439e-03 [2.533070e-06] 
Layer 'conv5' biases: 9.994316e-01 [2.706878e-06] 
Layer 'fc6' weights[0]: 7.478167e-03 [5.842189e-08] 
Layer 'fc6' biases: 9.999991e-01 [5.264632e-08] 
Layer 'fc7' weights[0]: 7.833365e-03 [1.256882e-07] 
Layer 'fc7' biases: 9.999520e-01 [1.475636e-07] 
Layer 'fc8' weights[0]: 3.484774e-03 [2.022168e-05] 
Layer 'fc8' biases: 5.137881e-03 [2.168434e-05] 
Train error last 800 batches: 0.655623
-------------------------------------------------------
Not saving because 0.516876 > 0.323801 (3.40: -8.65%)
======================================================= (2.372 sec)
4.541... logprob:  0.631373, 0.272135 (1.436 sec)
4.542... logprob:  0.695301, 0.305990 (1.433 sec)
4.543... logprob:  0.488673, 0.220052 (1.434 sec)
4.544... logprob:  0.589554, 0.240885 (1.426 sec)
4.545... logprob:  0.620624, 0.264323 (1.434 sec)
4.546... logprob:  0.538680, 0.263021 (1.475 sec)
4.547... logprob:  0.655869, 0.313802 (1.430 sec)
4.548... logprob:  0.600041, 0.261719 (1.438 sec)
4.549... logprob:  0.614365, 0.276042 (1.469 sec)
4.550... logprob:  0.618244, 0.248698 (1.425 sec)
4.551... logprob:  0.639009, 0.287760 (1.431 sec)
4.552... logprob:  0.575154, 0.248698 (1.425 sec)
4.553... logprob:  0.625854, 0.296875 (1.425 sec)
4.554... logprob:  0.801998, 0.328125 (1.427 sec)
4.555... logprob:  0.607984, 0.299479 (1.474 sec)
4.556... logprob:  0.631532, 0.277344 (1.433 sec)
4.557... logprob:  0.656907, 0.263021 (1.441 sec)
4.558... logprob:  0.637165, 0.294271 (1.469 sec)
4.559... logprob:  0.628974, 0.291667 (1.427 sec)
4.560... logprob:  0.624770, 0.279948 (1.434 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.507816, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.884899e-03 [3.498536e-07] 
Layer 'conv1' biases: 6.430159e-07 [1.240584e-09] 
Layer 'conv2' weights[0]: 6.873148e-03 [3.475310e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.234492e-09] 
Layer 'conv3' weights[0]: 6.872023e-03 [3.488036e-07] 
Layer 'conv3' biases: 1.428509e-05 [3.253713e-08] 
Layer 'conv4' weights[0]: 6.899772e-03 [3.526449e-07] 
Layer 'conv4' biases: 1.000012e+00 [3.195083e-07] 
Layer 'conv5' weights[0]: 6.917924e-03 [2.123245e-06] 
Layer 'conv5' biases: 9.994250e-01 [2.262736e-06] 
Layer 'fc6' weights[0]: 7.477392e-03 [5.522721e-08] 
Layer 'fc6' biases: 9.999991e-01 [4.777149e-08] 
Layer 'fc7' weights[0]: 7.832607e-03 [1.138729e-07] 
Layer 'fc7' biases: 9.999532e-01 [1.276218e-07] 
Layer 'fc8' weights[0]: 3.599953e-03 [1.746886e-05] 
Layer 'fc8' biases: 5.714487e-03 [2.042445e-05] 
Train error last 800 batches: 0.655524
-------------------------------------------------------
Not saving because 0.507816 > 0.323801 (3.40: -8.65%)
======================================================= (2.375 sec)
4.561... logprob:  0.606101, 0.261719 (1.437 sec)
4.562... logprob:  0.697699, 0.289062 (1.428 sec)
4.563... logprob:  0.602004, 0.268229 (1.435 sec)
4.564... logprob:  0.771713, 0.320312 (1.468 sec)
4.565... logprob:  0.911963, 0.361979 (1.441 sec)
4.566... logprob:  0.563795, 0.260417 (1.446 sec)
4.567... logprob:  0.675427, 0.281250 (1.456 sec)
4.568... logprob:  0.715104, 0.312500 (1.454 sec)
4.569... logprob:  0.657915, 0.295573 (1.436 sec)
4.570... logprob:  0.705784, 0.295573 (1.418 sec)
4.571... logprob:  0.675046, 0.294271 (1.426 sec)
4.572... logprob:  0.730096, 0.295573 (1.456 sec)
4.573... logprob:  0.700307, 0.282552 (1.440 sec)
4.574... logprob:  0.656075, 0.295573 (1.459 sec)
4.575... logprob:  0.523782, 0.242187 (1.444 sec)
4.576... logprob:  0.706407, 0.332031 (1.447 sec)
4.577... logprob:  0.700899, 0.319010 (1.467 sec)
4.578... logprob:  0.607223, 0.313802 (1.429 sec)
4.579... logprob:  0.573232, 0.235677 (1.423 sec)
4.580... logprob:  0.750107, 0.307292 (1.421 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.526857, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.877971e-03 [3.537657e-07] 
Layer 'conv1' biases: 6.460975e-07 [1.472677e-09] 
Layer 'conv2' weights[0]: 6.866268e-03 [3.491447e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.221578e-09] 
Layer 'conv3' weights[0]: 6.865127e-03 [3.512700e-07] 
Layer 'conv3' biases: 1.429280e-05 [3.880008e-08] 
Layer 'conv4' weights[0]: 6.892899e-03 [3.566125e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.969769e-07] 
Layer 'conv5' weights[0]: 6.911526e-03 [2.828851e-06] 
Layer 'conv5' biases: 9.994239e-01 [2.983454e-06] 
Layer 'fc6' weights[0]: 7.476586e-03 [6.122799e-08] 
Layer 'fc6' biases: 9.999992e-01 [5.675826e-08] 
Layer 'fc7' weights[0]: 7.831808e-03 [1.303662e-07] 
Layer 'fc7' biases: 9.999515e-01 [1.725889e-07] 
Layer 'fc8' weights[0]: 3.525275e-03 [2.092966e-05] 
Layer 'fc8' biases: 5.237072e-03 [3.497649e-05] 
Train error last 800 batches: 0.655380
-------------------------------------------------------
Not saving because 0.526857 > 0.323801 (3.40: -8.65%)
======================================================= (2.403 sec)
4.581... logprob:  0.750245, 0.326823 (1.447 sec)
4.582... logprob:  0.541537, 0.259115 (1.433 sec)
4.583... logprob:  0.772410, 0.295573 (1.475 sec)
4.584... logprob:  0.705781, 0.317708 (1.443 sec)
4.585... logprob:  0.609598, 0.264323 (1.430 sec)
4.586... logprob:  0.557058, 0.248698 (1.484 sec)
4.587... logprob:  0.648722, 0.283854 (1.432 sec)
4.588... logprob:  0.729313, 0.329427 (1.425 sec)
4.589... logprob:  0.580794, 0.255208 (1.437 sec)
4.590... logprob:  0.730538, 0.298177 (1.424 sec)
4.591... logprob:  0.623068, 0.283854 (1.430 sec)
4.592... logprob:  0.683312, 0.312500 (1.479 sec)
4.593... logprob:  0.583145, 0.265625 (1.429 sec)
4.594... logprob:  0.580571, 0.274739 (1.435 sec)
4.595... logprob:  0.663956, 0.282552 (1.475 sec)
4.596... logprob:  0.765172, 0.337240 (1.429 sec)
4.597... logprob:  0.570768, 0.277344 (1.424 sec)
4.598... logprob:  0.626959, 0.287760 (1.430 sec)
4.599... logprob:  0.567816, 0.272135 (1.424 sec)
4.600... logprob:  0.520626, 0.226562 (1.426 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.429894, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.871128e-03 [3.490758e-07] 
Layer 'conv1' biases: 6.506527e-07 [1.109721e-09] 
Layer 'conv2' weights[0]: 6.859439e-03 [3.466145e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.806565e-09] 
Layer 'conv3' weights[0]: 6.858311e-03 [3.471162e-07] 
Layer 'conv3' biases: 1.436307e-05 [2.713025e-08] 
Layer 'conv4' weights[0]: 6.886011e-03 [3.522279e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.114619e-07] 
Layer 'conv5' weights[0]: 6.904636e-03 [2.344695e-06] 
Layer 'conv5' biases: 9.994150e-01 [2.495508e-06] 
Layer 'fc6' weights[0]: 7.475807e-03 [5.716223e-08] 
Layer 'fc6' biases: 9.999991e-01 [5.085919e-08] 
Layer 'fc7' weights[0]: 7.831020e-03 [1.231130e-07] 
Layer 'fc7' biases: 9.999521e-01 [1.684909e-07] 
Layer 'fc8' weights[0]: 3.608508e-03 [2.037539e-05] 
Layer 'fc8' biases: 5.750507e-03 [3.707447e-05] 
Train error last 800 batches: 0.655150
-------------------------------------------------------
Not saving because 0.429894 > 0.323801 (3.40: -8.65%)
======================================================= (2.378 sec)
4.601... logprob:  0.643642, 0.278646 (1.489 sec)
4.602... logprob:  0.584759, 0.274740 (1.435 sec)
4.603... logprob:  0.595739, 0.243490 (1.440 sec)
4.604... logprob:  0.555138, 0.255208 (1.471 sec)
4.605... logprob:  0.810100, 0.329427 (1.433 sec)
4.606... logprob:  0.580104, 0.295573 (1.431 sec)
4.607... logprob:  0.718885, 0.283854 (1.427 sec)
4.608... logprob:  0.536399, 0.244792 (1.417 sec)
4.609... logprob:  0.583467, 0.253906 (1.431 sec)
4.610... logprob:  0.699593, 0.307292 (1.495 sec)
4.611... logprob:  0.731692, 0.294271 (1.440 sec)
4.612... logprob:  0.773651, 0.313802 (1.447 sec)
4.613... logprob:  0.550399, 0.244792 (1.454 sec)
4.614... logprob:  0.759369, 0.335937 (1.446 sec)
4.615... logprob:  0.593874, 0.270833 (1.433 sec)
4.616... logprob:  0.712999, 0.307292 (1.421 sec)
4.617... logprob:  0.580765, 0.252604 (1.423 sec)
4.618... logprob:  0.704969, 0.315104 (1.498 sec)
4.619... logprob:  0.707033, 0.317708 (1.442 sec)
4.620... logprob:  0.703076, 0.304687 (1.454 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.432821, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.864251e-03 [3.485670e-07] 
Layer 'conv1' biases: 6.524175e-07 [1.572522e-09] 
Layer 'conv2' weights[0]: 6.852578e-03 [3.472038e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.320519e-09] 
Layer 'conv3' weights[0]: 6.851439e-03 [3.492780e-07] 
Layer 'conv3' biases: 1.439264e-05 [3.760242e-08] 
Layer 'conv4' weights[0]: 6.879118e-03 [3.531779e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.569672e-07] 
Layer 'conv5' weights[0]: 6.897881e-03 [2.379805e-06] 
Layer 'conv5' biases: 9.994138e-01 [2.501229e-06] 
Layer 'fc6' weights[0]: 7.475019e-03 [6.362960e-08] 
Layer 'fc6' biases: 9.999992e-01 [6.059724e-08] 
Layer 'fc7' weights[0]: 7.830247e-03 [1.379716e-07] 
Layer 'fc7' biases: 9.999509e-01 [1.987452e-07] 
Layer 'fc8' weights[0]: 3.553606e-03 [2.276882e-05] 
Layer 'fc8' biases: 5.482399e-03 [3.504561e-05] 
Train error last 800 batches: 0.655582
-------------------------------------------------------
Not saving because 0.432821 > 0.323801 (3.40: -8.65%)
======================================================= (2.397 sec)
4.621... logprob:  0.587304, 0.278646 (1.455 sec)
4.622... logprob:  0.646975, 0.308594 (1.449 sec)
4.623... logprob:  0.526670, 0.227865 (1.468 sec)
4.624... logprob:  0.542937, 0.226562 (1.437 sec)
4.625... logprob:  0.632631, 0.279948 (1.417 sec)
4.626... logprob:  0.728386, 0.299479 (1.423 sec)
4.627... logprob:  0.604581, 0.251302 (1.435 sec)
4.628... logprob:  0.606165, 0.274740 (1.431 sec)
4.629... logprob:  0.630213, 0.290365 (1.465 sec)
4.630... logprob:  0.640088, 0.257812 (1.440 sec)
4.631... logprob:  0.832536, 0.334635 (1.433 sec)
4.632... logprob:  0.686965, 0.294271 (1.473 sec)
4.633... logprob:  0.618703, 0.260417 (1.430 sec)
4.634... logprob:  0.748270, 0.330729 (1.422 sec)
4.635... logprob:  0.653007, 0.313802 (1.427 sec)
4.636... logprob:  0.601811, 0.273437 (1.429 sec)
4.637... logprob:  0.631428, 0.281250 (1.426 sec)
4.638... logprob:  0.685641, 0.316406 (1.474 sec)
4.639... logprob:  0.599857, 0.213542 (1.436 sec)
4.640... logprob:  0.688128, 0.289062 (1.428 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.556079, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.857391e-03 [3.484259e-07] 
Layer 'conv1' biases: 6.591623e-07 [1.238621e-09] 
Layer 'conv2' weights[0]: 6.845695e-03 [3.468171e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.649386e-09] 
Layer 'conv3' weights[0]: 6.844579e-03 [3.475046e-07] 
Layer 'conv3' biases: 1.439962e-05 [3.313063e-08] 
Layer 'conv4' weights[0]: 6.872230e-03 [3.514791e-07] 
Layer 'conv4' biases: 1.000012e+00 [3.597193e-07] 
Layer 'conv5' weights[0]: 6.891194e-03 [2.133303e-06] 
Layer 'conv5' biases: 9.994096e-01 [2.265724e-06] 
Layer 'fc6' weights[0]: 7.474255e-03 [5.865194e-08] 
Layer 'fc6' biases: 9.999992e-01 [5.303041e-08] 
Layer 'fc7' weights[0]: 7.829525e-03 [1.261772e-07] 
Layer 'fc7' biases: 9.999509e-01 [1.563209e-07] 
Layer 'fc8' weights[0]: 3.547472e-03 [1.834503e-05] 
Layer 'fc8' biases: 5.456444e-03 [2.386527e-05] 
Train error last 800 batches: 0.655196
-------------------------------------------------------
Not saving because 0.556079 > 0.323801 (3.40: -8.65%)
======================================================= (2.395 sec)
4.641... logprob:  0.639079, 0.298177 (1.489 sec)
4.642... logprob:  0.703014, 0.302083 (1.432 sec)
4.643... logprob:  0.717202, 0.315104 (1.427 sec)
4.644... logprob:  0.477954, 0.212240 (1.434 sec)
4.645... logprob:  0.591486, 0.292969 (1.421 sec)
4.646... logprob:  0.563960, 0.242187 (1.429 sec)
4.647... logprob:  0.627352, 0.225260 (1.481 sec)
4.648... logprob:  0.751131, 0.290365 (1.450 sec)
4.649... logprob:  0.584677, 0.273438 (1.436 sec)
4.650... logprob:  0.627707, 0.266927 (1.471 sec)
4.651... logprob:  0.669356, 0.300781 (1.427 sec)
4.652... logprob:  0.689982, 0.311198 (1.437 sec)
4.653... logprob:  0.677655, 0.269531 (1.431 sec)
4.654... logprob:  0.732162, 0.307292 (1.418 sec)
4.655... logprob:  0.679246, 0.298177 (1.430 sec)
4.656... logprob:  0.714264, 0.330729 (1.466 sec)
4.657... logprob:  0.713352, 0.304687 (1.438 sec)
4.658... logprob:  0.594153, 0.282552 (1.446 sec)
4.659... logprob:  0.736181, 0.343750 (1.467 sec)
4.660... logprob:  0.685982, 0.285156 (1.439 sec)
=========================
Testing 1 batch

======================Test output======================
logprob:  0.404013, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.850522e-03 [3.478876e-07] 
Layer 'conv1' biases: 6.598921e-07 [1.405554e-09] 
Layer 'conv2' weights[0]: 6.838850e-03 [3.453980e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.066780e-09] 
Layer 'conv3' weights[0]: 6.837712e-03 [3.461819e-07] 
Layer 'conv3' biases: 1.438147e-05 [3.284628e-08] 
Layer 'conv4' weights[0]: 6.865381e-03 [3.503989e-07] 
Layer 'conv4' biases: 1.000012e+00 [3.722338e-07] 
Layer 'conv5' weights[0]: 6.884222e-03 [2.309972e-06] 
Layer 'conv5' biases: 9.994100e-01 [2.513972e-06] 
Layer 'fc6' weights[0]: 7.473444e-03 [5.947486e-08] 
Layer 'fc6' biases: 9.999992e-01 [5.462265e-08] 
Layer 'fc7' weights[0]: 7.828772e-03 [1.258101e-07] 
Layer 'fc7' biases: 9.999498e-01 [1.577182e-07] 
Layer 'fc8' weights[0]: 3.537575e-03 [2.020483e-05] 
Layer 'fc8' biases: 5.385562e-03 [2.849687e-05] 
Train error last 800 batches: 0.655004
-------------------------------------------------------
Not saving because 0.404013 > 0.323801 (3.40: -8.65%)
======================================================= (2.383 sec)
4.661... logprob:  0.588045, 0.269531 (1.439 sec)
4.662... logprob:  0.618183, 0.285156 (1.427 sec)
4.663...nohup: ignoring input
Option --layer-def (Layer definition file) cannot be changed
Option --crop-border (Cropped DP: crop border size) cannot be changed
=========================
Importing _ConvNet C++ module
=========================
Training ConvNet
Always write savepoints, regardless of test err improvement: 0     [DEFAULT]
Check gradients and quit?                                  : 0     [DEFAULT]
Compress checkpoints?                                      : 0     [DEFAULT]
Conserve GPU memory (slower)?                              : 0     [DEFAULT]
Convert given conv layers to unshared local                :       
Cropped DP: crop border size                               : 32    
Cropped DP: logreg layer name (for --multiview-test)       :       [DEFAULT]
Cropped DP: test on multiple patches?                      : 0     [DEFAULT]
Cropped Step: crop border step                             : 1     [DEFAULT]
Data batch range: testing                                  : 801-886 
Data batch range: training                                 : 1-800 
Data path                                                  : /data2/ad6813/pipe-data/Redbox/batches/clamp_detection 
Data provider                                              : basic-leaf256 
GPU override                                               : -1    [DEFAULT]
Layer definition file                                      : /homes/ad6813/Git/pipe-classification/models/decaf-net/layers_decaf.cfg 
Layer parameter file                                       : /homes/ad6813/Git/pipe-classification/models/decaf-net/params_decaf.cfg 
Load file                                                  : /data2/ad6813/my-nets/saves/ConvNet__2014-06-04_16.10.14 
Maximum save file size (MB)                                : 0     [DEFAULT]
Minibatch size                                             : 128   [DEFAULT]
Number of GPUs                                             : 1     [DEFAULT]
Number of epochs                                           : 50000 [DEFAULT]
Save path                                                  : /data2/ad6813/my-nets/saves 
Test and quit?                                             : 0     [DEFAULT]
Test on more than one batch at a time?                     : 10    
Test on one batch at a time?                               : 1     [DEFAULT]
Testing frequency                                          : 20    
Unshare weight matrices in given layers                    :       
=========================
Running on CUDA device(s) -2
Current time: Wed Jun  4 22:57:31 2014
Saving checkpoints to /data2/ad6813/my-nets/saves/ConvNet__2014-06-04_16.10.14
=========================
3.41... logprob:  0.660752, 0.316406 (1.431 sec)
3.42... logprob:  0.630370, 0.265625 (1.415 sec)
3.43... logprob:  0.614455, 0.278646 (1.405 sec)
3.44... logprob:  0.653869, 0.313802 (1.434 sec)
3.45... logprob:  0.609006, 0.270833 (1.385 sec)
3.46... logprob:  0.649370, 0.281250 (1.422 sec)
3.47... logprob:  0.560884, 0.238281 (1.392 sec)
3.48... logprob:  0.787256, 0.369792 (1.422 sec)
3.49... logprob:  0.752497, 0.326823 (1.410 sec)
3.50... logprob:  0.600636, 0.266927 (1.418 sec)
3.51... logprob:  0.711975, 0.296875 (1.412 sec)
3.52... logprob:  0.759832, 0.317708 (1.389 sec)
3.53... logprob:  0.571888, 0.264323 (1.441 sec)
3.54... logprob:  0.619791, 0.305990 (1.382 sec)
3.55... logprob:  0.561205, 0.273437 (1.390 sec)
3.56... logprob:  0.656645, 0.270833 (1.394 sec)
3.57... logprob:  0.719722, 0.315104 (1.428 sec)
3.58... logprob:  0.534320, 0.240885 (1.398 sec)
3.59... logprob:  0.556934, 0.256510 (1.459 sec)
3.60... logprob:  0.833730, 0.354167 (1.418 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.469135, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.347213e-03 [3.775567e-07] 
Layer 'conv1' biases: 4.140829e-07 [1.404298e-09] 
Layer 'conv2' weights[0]: 7.334882e-03 [3.716749e-07] 
Layer 'conv2' biases: 9.999999e-01 [8.783438e-09] 
Layer 'conv3' weights[0]: 7.333575e-03 [3.724705e-07] 
Layer 'conv3' biases: 9.127294e-06 [3.374241e-08] 
Layer 'conv4' weights[0]: 7.363259e-03 [3.767069e-07] 
Layer 'conv4' biases: 1.000004e+00 [3.300672e-07] 
Layer 'conv5' weights[0]: 7.371506e-03 [1.991161e-06] 
Layer 'conv5' biases: 9.996135e-01 [2.085655e-06] 
Layer 'fc6' weights[0]: 7.528036e-03 [5.542780e-08] 
Layer 'fc6' biases: 9.999997e-01 [4.544132e-08] 
Layer 'fc7' weights[0]: 7.882991e-03 [1.109678e-07] 
Layer 'fc7' biases: 9.999794e-01 [1.335044e-07] 
Layer 'fc8' weights[0]: 3.059993e-03 [2.291364e-05] 
Layer 'fc8' biases: 4.735248e-03 [3.803484e-05] 
Train error last 800 batches: 0.660011
-------------------------------------------------------
Not saving because 0.469135 > 0.323801 (3.40: -8.65%)
======================================================= (2.377 sec)
3.61... logprob:  0.654826, 0.292969 (1.435 sec)
3.62... logprob:  0.706304, 0.304687 (1.456 sec)
3.63... logprob:  0.556615, 0.261719 (1.440 sec)
3.64... logprob:  0.722160, 0.332031 (1.405 sec)
3.65... logprob:  0.557157, 0.253906 (1.391 sec)
3.66... logprob:  0.562371, 0.279948 (1.441 sec)
3.67... logprob:  0.533779, 0.239583 (1.387 sec)
3.68... logprob:  0.521509, 0.230469 (1.391 sec)
3.69... logprob:  0.636665, 0.272135 (1.419 sec)
3.70... logprob:  0.582008, 0.283854 (1.426 sec)
3.71... logprob:  0.687320, 0.292969 (1.451 sec)
3.72... logprob:  0.686466, 0.320312 (1.400 sec)
3.73... logprob:  0.662725, 0.312500 (1.416 sec)
3.74... logprob:  0.640660, 0.278646 (1.414 sec)
3.75... logprob:  0.541324, 0.220052 (1.415 sec)
3.76... logprob:  0.606635, 0.264323 (1.438 sec)
3.77... logprob:  0.612192, 0.269531 (1.426 sec)
3.78... logprob:  0.734168, 0.309896 (1.451 sec)
3.79... logprob:  0.649156, 0.292969 (1.404 sec)
3.80... logprob:  0.688553, 0.259115 (1.409 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.442432, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.339870e-03 [3.738628e-07] 
Layer 'conv1' biases: 4.117382e-07 [1.173433e-09] 
Layer 'conv2' weights[0]: 7.327551e-03 [3.718444e-07] 
Layer 'conv2' biases: 9.999999e-01 [8.930146e-09] 
Layer 'conv3' weights[0]: 7.326261e-03 [3.723802e-07] 
Layer 'conv3' biases: 9.172244e-06 [3.469592e-08] 
Layer 'conv4' weights[0]: 7.355929e-03 [3.778215e-07] 
Layer 'conv4' biases: 1.000003e+00 [3.450910e-07] 
Layer 'conv5' weights[0]: 7.363720e-03 [2.192477e-06] 
Layer 'conv5' biases: 9.996155e-01 [2.233989e-06] 
Layer 'fc6' weights[0]: 7.527255e-03 [5.879516e-08] 
Layer 'fc6' biases: 9.999996e-01 [5.007637e-08] 
Layer 'fc7' weights[0]: 7.882193e-03 [1.197988e-07] 
Layer 'fc7' biases: 9.999793e-01 [1.563858e-07] 
Layer 'fc8' weights[0]: 3.107841e-03 [2.100323e-05] 
Layer 'fc8' biases: 4.981612e-03 [3.250996e-05] 
Train error last 800 batches: 0.659435
-------------------------------------------------------
Not saving because 0.442432 > 0.323801 (3.40: -8.65%)
======================================================= (2.375 sec)
3.81... logprob:  0.623900, 0.286458 (1.419 sec)
3.82... logprob:  0.482652, 0.204427 (1.419 sec)
3.83... logprob:  0.746721, 0.324219 (1.391 sec)
3.84... logprob:  0.763581, 0.319010 (1.462 sec)
3.85... logprob:  0.631383, 0.259115 (1.422 sec)
3.86... logprob:  0.679639, 0.279948 (1.412 sec)
3.87... logprob:  0.714347, 0.313802 (1.414 sec)
3.88... logprob:  0.790232, 0.322917 (1.409 sec)
3.89... logprob:  0.672324, 0.285156 (1.426 sec)
3.90... logprob:  0.858406, 0.347656 (1.383 sec)
3.91... logprob:  0.570864, 0.247396 (1.391 sec)
3.92... logprob:  0.758024, 0.308594 (1.396 sec)
3.93... logprob:  0.674528, 0.276042 (1.387 sec)
3.94... logprob:  0.683881, 0.282552 (1.383 sec)
3.95... logprob:  0.645995, 0.276042 (1.404 sec)
3.96... logprob:  0.861044, 0.343750 (1.396 sec)
3.97... logprob:  0.630725, 0.268229 (1.381 sec)
3.98... logprob:  0.642358, 0.272135 (1.429 sec)
3.99... logprob:  0.707719, 0.282552 (1.405 sec)
3.100... logprob:  0.568431, 0.269531 (1.394 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.526887, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.332490e-03 [3.773163e-07] 
Layer 'conv1' biases: 4.114261e-07 [1.439506e-09] 
Layer 'conv2' weights[0]: 7.320214e-03 [3.747526e-07] 
Layer 'conv2' biases: 9.999998e-01 [1.159724e-08] 
Layer 'conv3' weights[0]: 7.318956e-03 [3.752996e-07] 
Layer 'conv3' biases: 9.335992e-06 [4.126392e-08] 
Layer 'conv4' weights[0]: 7.348558e-03 [3.829393e-07] 
Layer 'conv4' biases: 1.000004e+00 [4.234748e-07] 
Layer 'conv5' weights[0]: 7.356814e-03 [2.778835e-06] 
Layer 'conv5' biases: 9.996108e-01 [2.917592e-06] 
Layer 'fc6' weights[0]: 7.526447e-03 [6.438686e-08] 
Layer 'fc6' biases: 9.999996e-01 [5.809508e-08] 
Layer 'fc7' weights[0]: 7.881515e-03 [1.370475e-07] 
Layer 'fc7' biases: 9.999771e-01 [2.056745e-07] 
Layer 'fc8' weights[0]: 2.956831e-03 [3.041451e-05] 
Layer 'fc8' biases: 4.144521e-03 [5.872726e-05] 
Train error last 800 batches: 0.659794
-------------------------------------------------------
Not saving because 0.526887 > 0.323801 (3.40: -8.65%)
======================================================= (2.361 sec)
3.101... logprob:  0.633576, 0.291667 (1.441 sec)
3.102... logprob:  0.660779, 0.283854 (1.383 sec)
3.103... logprob:  0.812658, 0.369792 (1.392 sec)
3.104... logprob:  0.595710, 0.266927 (1.397 sec)
3.105... logprob:  0.703521, 0.329427 (1.388 sec)
3.106... logprob:  0.598366, 0.282552 (1.386 sec)
3.107... logprob:  0.576188, 0.253906 (1.437 sec)
3.108... logprob:  0.784137, 0.317708 (1.393 sec)
3.109... logprob:  0.664613, 0.300781 (1.393 sec)
3.110... logprob:  0.775385, 0.338542 (1.392 sec)
3.111... logprob:  0.733234, 0.305990 (1.390 sec)
3.112... logprob:  0.570787, 0.253906 (1.392 sec)
3.113... logprob:  0.537876, 0.242188 (1.394 sec)
3.114... logprob:  0.717412, 0.290365 (1.424 sec)
3.115... logprob:  0.678098, 0.300781 (1.407 sec)
3.116... logprob:  0.643812, 0.308594 (1.399 sec)
3.117... logprob:  0.623406, 0.256510 (1.435 sec)
3.118... logprob:  0.634788, 0.282552 (1.384 sec)
3.119... logprob:  0.511257, 0.221354 (1.390 sec)
3.120... logprob:  0.759755, 0.329427 (1.397 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.406263, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.325212e-03 [3.732738e-07] 
Layer 'conv1' biases: 4.159600e-07 [1.119734e-09] 
Layer 'conv2' weights[0]: 7.312891e-03 [3.701676e-07] 
Layer 'conv2' biases: 9.999998e-01 [7.551370e-09] 
Layer 'conv3' weights[0]: 7.311636e-03 [3.693147e-07] 
Layer 'conv3' biases: 9.341453e-06 [2.889339e-08] 
Layer 'conv4' weights[0]: 7.341230e-03 [3.739457e-07] 
Layer 'conv4' biases: 1.000004e+00 [2.813200e-07] 
Layer 'conv5' weights[0]: 7.349364e-03 [1.869827e-06] 
Layer 'conv5' biases: 9.996101e-01 [1.931442e-06] 
Layer 'fc6' weights[0]: 7.525678e-03 [5.278104e-08] 
Layer 'fc6' biases: 9.999996e-01 [4.139127e-08] 
Layer 'fc7' weights[0]: 7.880716e-03 [1.045074e-07] 
Layer 'fc7' biases: 9.999774e-01 [1.096173e-07] 
Layer 'fc8' weights[0]: 3.068877e-03 [1.883886e-05] 
Layer 'fc8' biases: 4.654491e-03 [2.004291e-05] 
Train error last 800 batches: 0.659640
-------------------------------------------------------
Not saving because 0.406263 > 0.323801 (3.40: -8.65%)
======================================================= (2.406 sec)
3.121... logprob:  0.624262, 0.281250 (1.401 sec)
3.122... logprob:  0.698919, 0.294271 (1.443 sec)
3.123... logprob:  0.673239, 0.294271 (1.382 sec)
3.124... logprob:  0.679718, 0.291667 (1.425 sec)
3.125... logprob:  0.676707, 0.289062 (1.391 sec)
3.126... logprob:  0.701398, 0.299479 (1.386 sec)
3.127... logprob:  0.769483, 0.316406 (1.390 sec)
3.128... logprob:  0.596520, 0.269531 (1.410 sec)
3.129... logprob:  0.727891, 0.322917 (1.413 sec)
3.130... logprob:  0.627903, 0.272135 (1.407 sec)
3.131... logprob:  0.641680, 0.279948 (1.405 sec)
3.132... logprob:  0.691458, 0.294271 (1.426 sec)
3.133... logprob:  0.656700, 0.282552 (1.386 sec)
3.134... logprob:  0.636010, 0.273438 (1.395 sec)
3.135... logprob:  0.630885, 0.276042 (1.393 sec)
3.136... logprob:  0.777353, 0.319010 (1.440 sec)
3.137... logprob:  0.594555, 0.269531 (1.395 sec)
3.138... logprob:  0.596178, 0.250000 (1.443 sec)
3.139... logprob:  0.652711, 0.305990 (1.394 sec)
3.140... logprob:  0.836942, 0.317708 (1.402 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.477354, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.317878e-03 [3.760858e-07] 
Layer 'conv1' biases: 4.195424e-07 [1.272293e-09] 
Layer 'conv2' weights[0]: 7.305532e-03 [3.708167e-07] 
Layer 'conv2' biases: 9.999998e-01 [9.300226e-09] 
Layer 'conv3' weights[0]: 7.304307e-03 [3.706256e-07] 
Layer 'conv3' biases: 9.475384e-06 [3.188822e-08] 
Layer 'conv4' weights[0]: 7.333871e-03 [3.753734e-07] 
Layer 'conv4' biases: 1.000004e+00 [3.221176e-07] 
Layer 'conv5' weights[0]: 7.342104e-03 [2.072482e-06] 
Layer 'conv5' biases: 9.996073e-01 [2.192409e-06] 
Layer 'fc6' weights[0]: 7.524859e-03 [5.659999e-08] 
Layer 'fc6' biases: 9.999996e-01 [4.728556e-08] 
Layer 'fc7' weights[0]: 7.879948e-03 [1.132023e-07] 
Layer 'fc7' biases: 9.999770e-01 [1.254956e-07] 
Layer 'fc8' weights[0]: 3.052045e-03 [1.879843e-05] 
Layer 'fc8' biases: 4.571504e-03 [1.841392e-05] 
Train error last 800 batches: 0.659915
-------------------------------------------------------
Not saving because 0.477354 > 0.323801 (3.40: -8.65%)
======================================================= (2.385 sec)
3.141... logprob:  0.713829, 0.303385 (1.437 sec)
3.142... logprob:  0.680661, 0.305990 (1.396 sec)
3.143... logprob:  0.532093, 0.253906 (1.419 sec)
3.144... logprob:  0.621663, 0.277344 (1.414 sec)
3.145... logprob:  0.583174, 0.286458 (1.410 sec)
3.146... logprob:  0.715160, 0.307292 (1.403 sec)
3.147... logprob:  0.542414, 0.260417 (1.431 sec)
3.148... logprob:  0.774763, 0.332031 (1.385 sec)
3.149... logprob:  0.711917, 0.308594 (1.397 sec)
3.150... logprob:  0.581376, 0.229167 (1.391 sec)
3.151... logprob:  0.558427, 0.270833 (1.405 sec)
3.152... logprob:  0.798708, 0.371094 (1.392 sec)
3.153... logprob:  0.606768, 0.261719 (1.453 sec)
3.154... logprob:  0.772684, 0.324219 (1.403 sec)
3.155... logprob:  0.619921, 0.278646 (1.415 sec)
3.156... logprob:  0.517012, 0.242187 (1.437 sec)
3.157... logprob:  0.482316, 0.221354 (1.393 sec)
3.158... logprob:  0.746156, 0.325521 (1.398 sec)
3.159... logprob:  0.632413, 0.305990 (1.393 sec)
3.160... logprob:  0.638897, 0.266927 (1.398 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.460595, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.310570e-03 [3.725492e-07] 
Layer 'conv1' biases: 4.212282e-07 [1.350108e-09] 
Layer 'conv2' weights[0]: 7.298245e-03 [3.697364e-07] 
Layer 'conv2' biases: 9.999998e-01 [8.795162e-09] 
Layer 'conv3' weights[0]: 7.297018e-03 [3.706397e-07] 
Layer 'conv3' biases: 9.558613e-06 [3.298069e-08] 
Layer 'conv4' weights[0]: 7.326579e-03 [3.753232e-07] 
Layer 'conv4' biases: 1.000003e+00 [3.442797e-07] 
Layer 'conv5' weights[0]: 7.334421e-03 [2.270810e-06] 
Layer 'conv5' biases: 9.996062e-01 [2.414801e-06] 
Layer 'fc6' weights[0]: 7.524088e-03 [5.585340e-08] 
Layer 'fc6' biases: 9.999996e-01 [4.610150e-08] 
Layer 'fc7' weights[0]: 7.879156e-03 [1.125527e-07] 
Layer 'fc7' biases: 9.999775e-01 [1.410927e-07] 
Layer 'fc8' weights[0]: 3.130192e-03 [2.203232e-05] 
Layer 'fc8' biases: 4.746235e-03 [3.501279e-05] 
Train error last 800 batches: 0.659526
-------------------------------------------------------
Not saving because 0.460595 > 0.323801 (3.40: -8.65%)
======================================================= (2.377 sec)
3.161... logprob:  0.591479, 0.276042 (1.403 sec)
3.162... logprob:  0.850417, 0.367188 (1.408 sec)
3.163... logprob:  0.695412, 0.278646 (1.459 sec)
3.164... logprob:  0.684713, 0.299479 (1.430 sec)
3.165... logprob:  0.748170, 0.317708 (1.417 sec)
3.166... logprob:  0.643393, 0.290365 (1.444 sec)
3.167... logprob:  0.600824, 0.248698 (1.441 sec)
3.168... logprob:  0.592128, 0.235677 (1.425 sec)
3.169... logprob:  0.611610, 0.266927 (1.453 sec)
3.170... logprob:  0.691601, 0.307292 (1.398 sec)
3.171... logprob:  0.723577, 0.316406 (1.431 sec)
3.172... logprob:  0.611618, 0.270833 (1.427 sec)
3.173... logprob:  0.686833, 0.296875 (1.428 sec)
3.174... logprob:  0.846162, 0.343750 (1.411 sec)
3.175... logprob:  0.677152, 0.290365 (1.474 sec)
3.176... logprob:  0.608867, 0.272135 (1.419 sec)
3.177... logprob:  0.461705, 0.213542 (1.431 sec)
3.178... logprob:  0.605693, 0.265625 (1.465 sec)
3.179... logprob:  0.552183, 0.238281 (1.409 sec)
3.180... logprob:  0.713499, 0.326823 (1.434 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.469101, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.303269e-03 [3.733323e-07] 
Layer 'conv1' biases: 4.307630e-07 [1.404833e-09] 
Layer 'conv2' weights[0]: 7.290950e-03 [3.692459e-07] 
Layer 'conv2' biases: 9.999998e-01 [8.307761e-09] 
Layer 'conv3' weights[0]: 7.289738e-03 [3.705335e-07] 
Layer 'conv3' biases: 9.737343e-06 [3.321921e-08] 
Layer 'conv4' weights[0]: 7.319188e-03 [3.752428e-07] 
Layer 'conv4' biases: 1.000003e+00 [3.326009e-07] 
Layer 'conv5' weights[0]: 7.327157e-03 [2.165844e-06] 
Layer 'conv5' biases: 9.996026e-01 [2.292937e-06] 
Layer 'fc6' weights[0]: 7.523298e-03 [5.614860e-08] 
Layer 'fc6' biases: 9.999996e-01 [4.664776e-08] 
Layer 'fc7' weights[0]: 7.878379e-03 [1.166573e-07] 
Layer 'fc7' biases: 9.999759e-01 [1.531931e-07] 
Layer 'fc8' weights[0]: 3.101924e-03 [2.456375e-05] 
Layer 'fc8' biases: 4.687243e-03 [4.714569e-05] 
Train error last 800 batches: 0.659866
-------------------------------------------------------
Not saving because 0.469101 > 0.323801 (3.40: -8.65%)
======================================================= (2.440 sec)
3.181... logprob:  0.831401, 0.350260 (1.422 sec)
3.182... logprob:  0.557531, 0.256510 (1.422 sec)
3.183... logprob:  0.579128, 0.287760 (1.413 sec)
3.184... logprob:  0.719145, 0.281250 (1.422 sec)
3.185... logprob:  0.591753, 0.287760 (1.397 sec)
3.186... logprob:  0.599324, 0.250000 (1.396 sec)
3.187... logprob:  0.641370, 0.295573 (1.400 sec)
3.188... logprob:  0.629362, 0.282552 (1.387 sec)
3.189... logprob:  0.659079, 0.268229 (1.385 sec)
3.190... logprob:  0.574375, 0.247396 (1.448 sec)
3.191... logprob:  0.700478, 0.334635 (1.413 sec)
3.192... logprob:  0.714601, 0.299479 (1.423 sec)
3.193... logprob:  0.503296, 0.221354 (1.428 sec)
3.194... logprob:  0.707977, 0.308594 (1.415 sec)
3.195... logprob:  0.508430, 0.220052 (1.395 sec)
3.196... logprob:  0.693245, 0.296875 (1.391 sec)
3.197... logprob:  0.737042, 0.305990 (1.391 sec)
3.198... logprob:  0.542199, 0.217448 (1.399 sec)
3.199... logprob:  0.559194, 0.250000 (1.380 sec)
3.200... logprob:  0.690729, 0.307292 (1.491 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.479012, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.295940e-03 [3.714649e-07] 
Layer 'conv1' biases: 4.360247e-07 [1.425787e-09] 
Layer 'conv2' weights[0]: 7.283705e-03 [3.679865e-07] 
Layer 'conv2' biases: 9.999998e-01 [7.023109e-09] 
Layer 'conv3' weights[0]: 7.282488e-03 [3.673724e-07] 
Layer 'conv3' biases: 9.900165e-06 [2.383973e-08] 
Layer 'conv4' weights[0]: 7.311891e-03 [3.719510e-07] 
Layer 'conv4' biases: 1.000003e+00 [2.517513e-07] 
Layer 'conv5' weights[0]: 7.319878e-03 [1.843209e-06] 
Layer 'conv5' biases: 9.995986e-01 [1.979417e-06] 
Layer 'fc6' weights[0]: 7.522532e-03 [5.540605e-08] 
Layer 'fc6' biases: 9.999995e-01 [4.578861e-08] 
Layer 'fc7' weights[0]: 7.877602e-03 [1.095394e-07] 
Layer 'fc7' biases: 9.999757e-01 [1.216503e-07] 
Layer 'fc8' weights[0]: 3.123287e-03 [1.958293e-05] 
Layer 'fc8' biases: 4.759562e-03 [2.829452e-05] 
Train error last 800 batches: 0.659496
-------------------------------------------------------
Not saving because 0.479012 > 0.323801 (3.40: -8.65%)
======================================================= (2.367 sec)
3.201... logprob:  0.687749, 0.292969 (1.409 sec)
3.202... logprob:  0.731423, 0.307292 (1.395 sec)
3.203... logprob:  0.584446, 0.273438 (1.430 sec)
3.204... logprob:  0.611089, 0.279948 (1.385 sec)
3.205... logprob:  0.546151, 0.239583 (1.394 sec)
3.206... logprob:  0.573906, 0.268229 (1.402 sec)
3.207... logprob:  0.580677, 0.257812 (1.391 sec)
3.208... logprob:  0.710070, 0.319010 (1.389 sec)
3.209... logprob:  0.526621, 0.260417 (1.415 sec)
3.210... logprob:  0.833593, 0.343750 (1.409 sec)
3.211... logprob:  0.698693, 0.303385 (1.406 sec)
3.212... logprob:  0.678192, 0.300781 (1.411 sec)
3.213... logprob:  0.739545, 0.317708 (1.453 sec)
3.214... logprob:  0.717310, 0.309896 (1.418 sec)
3.215... logprob:  0.634644, 0.277344 (1.409 sec)
3.216... logprob:  0.811625, 0.328125 (1.462 sec)
3.217... logprob:  0.578851, 0.264323 (1.399 sec)
3.218... logprob:  0.578869, 0.266927 (1.411 sec)
3.219... logprob:  0.769636, 0.352865 (1.412 sec)
3.220... logprob:  0.665410, 0.266927 (1.411 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.577888, 0.171875 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.288673e-03 [3.747294e-07] 
Layer 'conv1' biases: 4.421434e-07 [1.465157e-09] 
Layer 'conv2' weights[0]: 7.276420e-03 [3.687970e-07] 
Layer 'conv2' biases: 9.999998e-01 [1.072507e-08] 
Layer 'conv3' weights[0]: 7.275209e-03 [3.698615e-07] 
Layer 'conv3' biases: 1.001085e-05 [3.670668e-08] 
Layer 'conv4' weights[0]: 7.304570e-03 [3.754483e-07] 
Layer 'conv4' biases: 1.000003e+00 [3.699455e-07] 
Layer 'conv5' weights[0]: 7.312667e-03 [2.512255e-06] 
Layer 'conv5' biases: 9.995947e-01 [2.671557e-06] 
Layer 'fc6' weights[0]: 7.521773e-03 [6.170931e-08] 
Layer 'fc6' biases: 9.999996e-01 [5.460148e-08] 
Layer 'fc7' weights[0]: 7.876817e-03 [1.301148e-07] 
Layer 'fc7' biases: 9.999750e-01 [1.861984e-07] 
Layer 'fc8' weights[0]: 3.076691e-03 [2.403480e-05] 
Layer 'fc8' biases: 4.503338e-03 [3.834142e-05] 
Train error last 800 batches: 0.659717
-------------------------------------------------------
Not saving because 0.577888 > 0.323801 (3.40: -8.65%)
======================================================= (2.358 sec)
3.221... logprob:  0.601045, 0.269531 (1.414 sec)
3.222... logprob:  0.730716, 0.345052 (1.462 sec)
3.223... logprob:  0.822307, 0.342448 (1.441 sec)
3.224... logprob:  0.676378, 0.303385 (1.438 sec)
3.225... logprob:  0.621985, 0.260417 (1.448 sec)
3.226... logprob:  0.590492, 0.259115 (1.419 sec)
3.227... logprob:  0.666051, 0.300781 (1.416 sec)
3.228... logprob:  0.648989, 0.299479 (1.405 sec)
3.229... logprob:  0.569505, 0.246094 (1.410 sec)
3.230... logprob:  0.622993, 0.266927 (1.416 sec)
3.231... logprob:  0.676909, 0.296875 (1.400 sec)
3.232... logprob:  0.748800, 0.339844 (1.453 sec)
3.233... logprob:  0.734439, 0.324219 (1.420 sec)
3.234... logprob:  0.663750, 0.305990 (1.409 sec)
3.235... logprob:  0.648814, 0.272135 (1.459 sec)
3.236... logprob:  0.652022, 0.281250 (1.397 sec)
3.237... logprob:  0.547017, 0.251302 (1.413 sec)
3.238... logprob:  0.614763, 0.239583 (1.411 sec)
3.239... logprob:  0.639769, 0.296875 (1.411 sec)
3.240... logprob:  0.772097, 0.332031 (1.394 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.473323, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.281370e-03 [3.720725e-07] 
Layer 'conv1' biases: 4.425869e-07 [1.487893e-09] 
Layer 'conv2' weights[0]: 7.269135e-03 [3.679596e-07] 
Layer 'conv2' biases: 9.999998e-01 [7.060661e-09] 
Layer 'conv3' weights[0]: 7.267925e-03 [3.675174e-07] 
Layer 'conv3' biases: 1.007095e-05 [2.745924e-08] 
Layer 'conv4' weights[0]: 7.297255e-03 [3.709766e-07] 
Layer 'conv4' biases: 1.000003e+00 [2.780051e-07] 
Layer 'conv5' weights[0]: 7.305323e-03 [1.856297e-06] 
Layer 'conv5' biases: 9.995900e-01 [1.939114e-06] 
Layer 'fc6' weights[0]: 7.520977e-03 [5.490187e-08] 
Layer 'fc6' biases: 9.999996e-01 [4.520505e-08] 
Layer 'fc7' weights[0]: 7.876045e-03 [1.095203e-07] 
Layer 'fc7' biases: 9.999748e-01 [1.215283e-07] 
Layer 'fc8' weights[0]: 3.115970e-03 [2.015064e-05] 
Layer 'fc8' biases: 4.622088e-03 [2.532301e-05] 
Train error last 800 batches: 0.659581
-------------------------------------------------------
Not saving because 0.473323 > 0.323801 (3.40: -8.65%)
======================================================= (2.356 sec)
3.241... logprob:  0.760311, 0.335938 (1.455 sec)
3.242... logprob:  0.589788, 0.272135 (1.427 sec)
3.243... logprob:  0.630892, 0.270833 (1.422 sec)
3.244... logprob:  0.518732, 0.253906 (1.440 sec)
3.245... logprob:  0.745638, 0.315104 (1.428 sec)
3.246... logprob:  0.685452, 0.294271 (1.410 sec)
3.247... logprob:  0.656690, 0.307292 (1.409 sec)
3.248... logprob:  0.525781, 0.239583 (1.408 sec)
3.249... logprob:  0.739693, 0.341146 (1.417 sec)
3.250... logprob:  0.799430, 0.324219 (1.399 sec)
3.251... logprob:  0.604795, 0.247396 (1.450 sec)
3.252... logprob:  0.648209, 0.307292 (1.420 sec)
3.253... logprob:  0.635967, 0.295573 (1.412 sec)
3.254... logprob:  0.639953, 0.294271 (1.457 sec)
3.255... logprob:  0.549765, 0.225260 (1.395 sec)
3.256... logprob:  0.513248, 0.226562 (1.417 sec)
3.257... logprob:  0.559440, 0.261719 (1.409 sec)
3.258... logprob:  0.540834, 0.250000 (1.422 sec)
3.259... logprob:  0.639956, 0.302083 (1.403 sec)
3.260... logprob:  0.547469, 0.253906 (1.455 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.480107, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.274082e-03 [3.692952e-07] 
Layer 'conv1' biases: 4.429785e-07 [1.489469e-09] 
Layer 'conv2' weights[0]: 7.261868e-03 [3.685885e-07] 
Layer 'conv2' biases: 9.999998e-01 [1.195529e-08] 
Layer 'conv3' weights[0]: 7.260610e-03 [3.695881e-07] 
Layer 'conv3' biases: 1.016825e-05 [3.714663e-08] 
Layer 'conv4' weights[0]: 7.289981e-03 [3.773013e-07] 
Layer 'conv4' biases: 1.000003e+00 [4.148364e-07] 
Layer 'conv5' weights[0]: 7.298317e-03 [2.568486e-06] 
Layer 'conv5' biases: 9.995845e-01 [2.752762e-06] 
Layer 'fc6' weights[0]: 7.520193e-03 [6.150771e-08] 
Layer 'fc6' biases: 9.999995e-01 [5.479076e-08] 
Layer 'fc7' weights[0]: 7.875273e-03 [1.309656e-07] 
Layer 'fc7' biases: 9.999751e-01 [2.054221e-07] 
Layer 'fc8' weights[0]: 3.174366e-03 [2.673304e-05] 
Layer 'fc8' biases: 4.913844e-03 [5.497660e-05] 
Train error last 800 batches: 0.659511
-------------------------------------------------------
Not saving because 0.480107 > 0.323801 (3.40: -8.65%)
======================================================= (2.350 sec)
3.261... logprob:  0.671222, 0.298177 (1.424 sec)
3.262... logprob:  0.740171, 0.322917 (1.433 sec)
3.263... logprob:  0.651610, 0.289062 (1.441 sec)
3.264... logprob:  0.589206, 0.264323 (1.414 sec)
3.265... logprob:  0.672950, 0.302083 (1.409 sec)
3.266... logprob:  0.692557, 0.291667 (1.412 sec)
3.267... logprob:  0.597024, 0.251302 (1.410 sec)
3.268... logprob:  0.728450, 0.309896 (1.433 sec)
3.269... logprob:  0.781108, 0.338542 (1.397 sec)
3.270... logprob:  0.748899, 0.317708 (1.455 sec)
3.271... logprob:  0.585100, 0.248698 (1.416 sec)
3.272... logprob:  0.602718, 0.243490 (1.415 sec)
3.273... logprob:  0.803975, 0.315104 (1.458 sec)
3.274... logprob:  0.705277, 0.289062 (1.396 sec)
3.275... logprob:  0.763944, 0.307292 (1.419 sec)
3.276... logprob:  0.622089, 0.260417 (1.406 sec)
3.277... logprob:  0.631202, 0.281250 (1.425 sec)
3.278... logprob:  0.566429, 0.268229 (1.412 sec)
3.279... logprob:  0.518092, 0.234375 (1.458 sec)
3.280... logprob:  0.582499, 0.278646 (1.422 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.496818, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.266820e-03 [3.704852e-07] 
Layer 'conv1' biases: 4.445760e-07 [1.447584e-09] 
Layer 'conv2' weights[0]: 7.254595e-03 [3.687564e-07] 
Layer 'conv2' biases: 9.999998e-01 [1.091170e-08] 
Layer 'conv3' weights[0]: 7.253368e-03 [3.685456e-07] 
Layer 'conv3' biases: 1.028579e-05 [3.388882e-08] 
Layer 'conv4' weights[0]: 7.282654e-03 [3.746372e-07] 
Layer 'conv4' biases: 1.000003e+00 [3.629665e-07] 
Layer 'conv5' weights[0]: 7.291235e-03 [2.200681e-06] 
Layer 'conv5' biases: 9.995777e-01 [2.326726e-06] 
Layer 'fc6' weights[0]: 7.519460e-03 [5.629844e-08] 
Layer 'fc6' biases: 9.999995e-01 [4.735756e-08] 
Layer 'fc7' weights[0]: 7.874519e-03 [1.157304e-07] 
Layer 'fc7' biases: 9.999735e-01 [1.525316e-07] 
Layer 'fc8' weights[0]: 3.116303e-03 [2.334426e-05] 
Layer 'fc8' biases: 4.535425e-03 [4.395577e-05] 
Train error last 800 batches: 0.659631
-------------------------------------------------------
Not saving because 0.496818 > 0.323801 (3.40: -8.65%)
======================================================= (2.360 sec)
3.281... logprob:  0.637342, 0.282552 (1.430 sec)
3.282... logprob:  0.655596, 0.265625 (1.420 sec)
3.283... logprob:  0.647299, 0.255208 (1.411 sec)
3.284... logprob:  0.572480, 0.264323 (1.411 sec)
3.285... logprob:  0.688450, 0.290365 (1.433 sec)
3.286... logprob:  0.646717, 0.295573 (1.432 sec)
3.287... logprob:  0.552037, 0.246094 (1.425 sec)
3.288... logprob:  0.579204, 0.244792 (1.427 sec)
3.289... logprob:  0.732317, 0.309896 (1.438 sec)
3.290... logprob:  0.699051, 0.313802 (1.406 sec)
3.291... logprob:  0.743277, 0.283854 (1.411 sec)
3.292... logprob:  0.704665, 0.291667 (1.411 sec)
3.293... logprob:  0.683055, 0.289062 (1.416 sec)
3.294... logprob:  0.605215, 0.273437 (1.397 sec)
3.295... logprob:  0.597748, 0.292969 (1.454 sec)
3.296... logprob:  0.585962, 0.261719 (1.413 sec)
3.297... logprob:  0.567431, 0.274740 (1.416 sec)
3.298... logprob:  0.630431, 0.269531 (1.460 sec)
3.299... logprob:  0.544348, 0.266927 (1.398 sec)
3.300... logprob:  0.604798, 0.285156 (1.419 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.500663, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.259545e-03 [3.702667e-07] 
Layer 'conv1' biases: 4.563156e-07 [1.246286e-09] 
Layer 'conv2' weights[0]: 7.247349e-03 [3.669070e-07] 
Layer 'conv2' biases: 9.999998e-01 [8.574887e-09] 
Layer 'conv3' weights[0]: 7.246086e-03 [3.673849e-07] 
Layer 'conv3' biases: 1.034459e-05 [3.185887e-08] 
Layer 'conv4' weights[0]: 7.275417e-03 [3.734825e-07] 
Layer 'conv4' biases: 1.000003e+00 [3.620936e-07] 
Layer 'conv5' weights[0]: 7.284017e-03 [2.306070e-06] 
Layer 'conv5' biases: 9.995776e-01 [2.488336e-06] 
Layer 'fc6' weights[0]: 7.518699e-03 [5.776351e-08] 
Layer 'fc6' biases: 9.999996e-01 [4.966771e-08] 
Layer 'fc7' weights[0]: 7.873775e-03 [1.185828e-07] 
Layer 'fc7' biases: 9.999738e-01 [1.655131e-07] 
Layer 'fc8' weights[0]: 3.186580e-03 [2.497748e-05] 
Layer 'fc8' biases: 4.889472e-03 [4.318778e-05] 
Train error last 800 batches: 0.659399
-------------------------------------------------------
Not saving because 0.500663 > 0.323801 (3.40: -8.65%)
======================================================= (2.401 sec)
3.301... logprob:  0.681942, 0.320312 (1.415 sec)
3.302... logprob:  0.743589, 0.324219 (1.412 sec)
3.303... logprob:  0.747038, 0.337239 (1.400 sec)
3.304... logprob:  0.780052, 0.313802 (1.429 sec)
3.305... logprob:  0.677036, 0.281250 (1.443 sec)
3.306... logprob:  0.640470, 0.259115 (1.427 sec)
3.307... logprob:  0.633183, 0.239583 (1.434 sec)
3.308... logprob:  0.652960, 0.274740 (1.446 sec)
3.309... logprob:  0.637154, 0.304687 (1.418 sec)
3.310... logprob:  0.621498, 0.287760 (1.416 sec)
3.311... logprob:  0.745416, 0.305989 (1.429 sec)
3.312... logprob:  0.788567, 0.341146 (1.433 sec)
3.313... logprob:  0.569362, 0.230469 (1.414 sec)
3.314... logprob:  0.654253, 0.264323 (1.460 sec)
3.315... logprob:  0.672748, 0.329427 (1.425 sec)
3.316... logprob:  0.684328, 0.291667 (1.418 sec)
3.317... logprob:  0.576316, 0.255208 (1.470 sec)
3.318... logprob:  0.664148, 0.311198 (1.406 sec)
3.319... logprob:  0.622924, 0.281250 (1.419 sec)
3.320... logprob:  0.679529, 0.292969 (1.418 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.501760, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.252296e-03 [3.710897e-07] 
Layer 'conv1' biases: 4.663564e-07 [1.365277e-09] 
Layer 'conv2' weights[0]: 7.240041e-03 [3.665706e-07] 
Layer 'conv2' biases: 9.999998e-01 [7.724648e-09] 
Layer 'conv3' weights[0]: 7.238842e-03 [3.665885e-07] 
Layer 'conv3' biases: 1.045205e-05 [3.114693e-08] 
Layer 'conv4' weights[0]: 7.268171e-03 [3.716382e-07] 
Layer 'conv4' biases: 1.000004e+00 [3.260950e-07] 
Layer 'conv5' weights[0]: 7.277045e-03 [2.020048e-06] 
Layer 'conv5' biases: 9.995791e-01 [2.108872e-06] 
Layer 'fc6' weights[0]: 7.517905e-03 [5.531178e-08] 
Layer 'fc6' biases: 9.999995e-01 [4.564836e-08] 
Layer 'fc7' weights[0]: 7.872944e-03 [1.086588e-07] 
Layer 'fc7' biases: 9.999733e-01 [1.191181e-07] 
Layer 'fc8' weights[0]: 3.158960e-03 [1.772505e-05] 
Layer 'fc8' biases: 4.695661e-03 [1.805788e-05] 
Train error last 800 batches: 0.659713
-------------------------------------------------------
Not saving because 0.501760 > 0.323801 (3.40: -8.65%)
======================================================= (2.367 sec)
3.321... logprob:  0.634372, 0.263021 (1.422 sec)
3.322... logprob:  0.600522, 0.265625 (1.414 sec)
3.323... logprob:  0.597270, 0.281250 (1.468 sec)
3.324... logprob:  0.680900, 0.274740 (1.418 sec)
3.325... logprob:  0.631994, 0.300781 (1.513 sec)
3.326... logprob:  0.807015, 0.321615 (1.461 sec)
3.327... logprob:  0.728059, 0.322917 (1.423 sec)
3.328... logprob:  0.698809, 0.273438 (1.435 sec)
3.329... logprob:  0.665365, 0.263021 (1.432 sec)
3.330... logprob:  0.569848, 0.261719 (1.421 sec)
3.331... logprob:  0.622924, 0.259115 (1.417 sec)
3.332... logprob:  0.591378, 0.278646 (1.440 sec)
3.333... logprob:  0.559390, 0.256510 (1.437 sec)
3.334... logprob:  0.812083, 0.352865 (1.435 sec)
3.335... logprob:  0.587030, 0.255208 (1.434 sec)
3.336... logprob:  0.629444, 0.289062 (1.450 sec)
3.337... logprob:  0.751001, 0.309896 (1.411 sec)
3.338... logprob:  0.670079, 0.285156 (1.420 sec)
3.339... logprob:  0.747772, 0.330729 (1.419 sec)
3.340... logprob:  0.627071, 0.296875 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.416462, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.245037e-03 [3.684981e-07] 
Layer 'conv1' biases: 4.760572e-07 [1.433021e-09] 
Layer 'conv2' weights[0]: 7.232854e-03 [3.660105e-07] 
Layer 'conv2' biases: 9.999998e-01 [9.633481e-09] 
Layer 'conv3' weights[0]: 7.231685e-03 [3.666406e-07] 
Layer 'conv3' biases: 1.055673e-05 [3.441839e-08] 
Layer 'conv4' weights[0]: 7.260823e-03 [3.713802e-07] 
Layer 'conv4' biases: 1.000005e+00 [3.348929e-07] 
Layer 'conv5' weights[0]: 7.270480e-03 [2.316788e-06] 
Layer 'conv5' biases: 9.995726e-01 [2.405546e-06] 
Layer 'fc6' weights[0]: 7.517110e-03 [5.767427e-08] 
Layer 'fc6' biases: 9.999996e-01 [4.942779e-08] 
Layer 'fc7' weights[0]: 7.872154e-03 [1.161984e-07] 
Layer 'fc7' biases: 9.999731e-01 [1.386103e-07] 
Layer 'fc8' weights[0]: 3.162442e-03 [2.014970e-05] 
Layer 'fc8' biases: 4.653730e-03 [2.947366e-05] 
Train error last 800 batches: 0.659250
-------------------------------------------------------
Not saving because 0.416462 > 0.323801 (3.40: -8.65%)
======================================================= (2.360 sec)
3.341... logprob:  0.664371, 0.274740 (1.419 sec)
3.342... logprob:  0.604640, 0.269531 (1.454 sec)
3.343... logprob:  0.651794, 0.261719 (1.432 sec)
3.344... logprob:  0.617048, 0.282552 (1.477 sec)
3.345... logprob:  0.654573, 0.265625 (1.433 sec)
3.346... logprob:  0.701070, 0.291667 (1.430 sec)
3.347... logprob:  0.634846, 0.278646 (1.478 sec)
3.348... logprob:  0.676611, 0.285156 (1.426 sec)
3.349... logprob:  0.663803, 0.263021 (1.435 sec)
3.350... logprob:  0.576823, 0.255208 (1.431 sec)
3.351... logprob:  0.672381, 0.289062 (1.425 sec)
3.352... logprob:  0.586447, 0.274740 (1.429 sec)
3.353... logprob:  0.677938, 0.303385 (1.481 sec)
3.354... logprob:  0.853226, 0.334635 (1.421 sec)
3.355... logprob:  0.636840, 0.295573 (1.440 sec)
3.356... logprob:  0.685883, 0.282552 (1.472 sec)
3.357... logprob:  0.532646, 0.227865 (1.427 sec)
3.358... logprob:  0.601346, 0.260417 (1.437 sec)
3.359... logprob:  0.746757, 0.361979 (1.419 sec)
3.360... logprob:  0.648018, 0.274740 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.453790, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.237781e-03 [3.694662e-07] 
Layer 'conv1' biases: 4.738786e-07 [1.414065e-09] 
Layer 'conv2' weights[0]: 7.225630e-03 [3.666647e-07] 
Layer 'conv2' biases: 9.999998e-01 [9.012141e-09] 
Layer 'conv3' weights[0]: 7.224439e-03 [3.668506e-07] 
Layer 'conv3' biases: 1.070606e-05 [3.323679e-08] 
Layer 'conv4' weights[0]: 7.253629e-03 [3.706938e-07] 
Layer 'conv4' biases: 1.000005e+00 [3.125119e-07] 
Layer 'conv5' weights[0]: 7.263283e-03 [2.050278e-06] 
Layer 'conv5' biases: 9.995732e-01 [2.186536e-06] 
Layer 'fc6' weights[0]: 7.516304e-03 [5.412107e-08] 
Layer 'fc6' biases: 9.999996e-01 [4.400608e-08] 
Layer 'fc7' weights[0]: 7.871392e-03 [1.069217e-07] 
Layer 'fc7' biases: 9.999720e-01 [1.098060e-07] 
Layer 'fc8' weights[0]: 3.136896e-03 [1.760662e-05] 
Layer 'fc8' biases: 4.560151e-03 [1.635451e-05] 
Train error last 800 batches: 0.658528
-------------------------------------------------------
Not saving because 0.453790 > 0.323801 (3.40: -8.65%)
======================================================= (2.419 sec)
3.361... logprob:  0.605490, 0.263021 (1.437 sec)
3.362... logprob:  0.639417, 0.268229 (1.476 sec)
3.363... logprob:  0.659705, 0.303385 (1.438 sec)
3.364... logprob:  0.627408, 0.268229 (1.444 sec)
3.365... logprob:  0.687904, 0.289062 (1.458 sec)
3.366... logprob:  0.639796, 0.273437 (1.439 sec)
3.367... logprob:  0.605822, 0.279948 (1.431 sec)
3.368... logprob:  0.730405, 0.312500 (1.424 sec)
3.369... logprob:  0.593956, 0.268229 (1.418 sec)
3.370... logprob:  0.715408, 0.319010 (1.436 sec)
3.371... logprob:  0.637698, 0.283854 (1.459 sec)
3.372... logprob:  0.792646, 0.324219 (1.448 sec)
3.373... logprob:  0.558432, 0.250000 (1.449 sec)
3.374... logprob:  0.710390, 0.307292 (1.440 sec)
3.375... logprob:  0.688544, 0.295573 (1.458 sec)
3.376... logprob:  0.644570, 0.298177 (1.436 sec)
3.377... logprob:  0.556759, 0.226562 (1.418 sec)
3.378... logprob:  0.665081, 0.302083 (1.432 sec)
3.379... logprob:  0.650296, 0.266927 (1.433 sec)
3.380... logprob:  0.811666, 0.359375 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.456074, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.230551e-03 [3.689778e-07] 
Layer 'conv1' biases: 4.781327e-07 [1.742100e-09] 
Layer 'conv2' weights[0]: 7.218337e-03 [3.656323e-07] 
Layer 'conv2' biases: 9.999998e-01 [9.198964e-09] 
Layer 'conv3' weights[0]: 7.217202e-03 [3.666183e-07] 
Layer 'conv3' biases: 1.083261e-05 [3.524825e-08] 
Layer 'conv4' weights[0]: 7.246365e-03 [3.708641e-07] 
Layer 'conv4' biases: 1.000005e+00 [3.344915e-07] 
Layer 'conv5' weights[0]: 7.255748e-03 [2.011907e-06] 
Layer 'conv5' biases: 9.995698e-01 [2.087709e-06] 
Layer 'fc6' weights[0]: 7.515531e-03 [5.548059e-08] 
Layer 'fc6' biases: 9.999995e-01 [4.606759e-08] 
Layer 'fc7' weights[0]: 7.870599e-03 [1.101785e-07] 
Layer 'fc7' biases: 9.999722e-01 [1.176162e-07] 
Layer 'fc8' weights[0]: 3.179213e-03 [1.829114e-05] 
Layer 'fc8' biases: 4.758833e-03 [1.643178e-05] 
Train error last 800 batches: 0.658231
-------------------------------------------------------
Not saving because 0.456074 > 0.323801 (3.40: -8.65%)
======================================================= (2.386 sec)
3.381... logprob:  0.674942, 0.291667 (1.474 sec)
3.382... logprob:  0.707264, 0.325521 (1.450 sec)
3.383... logprob:  0.635608, 0.270833 (1.428 sec)
3.384... logprob:  0.772560, 0.328125 (1.479 sec)
3.385... logprob:  0.750979, 0.343750 (1.431 sec)
3.386... logprob:  0.720788, 0.311198 (1.417 sec)
3.387... logprob:  0.622934, 0.304687 (1.436 sec)
3.388... logprob:  0.764340, 0.369792 (1.436 sec)
3.389... logprob:  0.610999, 0.261719 (1.422 sec)
3.390... logprob:  0.564993, 0.220052 (1.476 sec)
3.391... logprob:  0.551323, 0.246094 (1.436 sec)
3.392... logprob:  0.668456, 0.313802 (1.424 sec)
3.393... logprob:  0.602387, 0.217448 (1.482 sec)
3.394... logprob:  0.610428, 0.274740 (1.426 sec)
3.395... logprob:  0.582423, 0.266927 (1.431 sec)
3.396... logprob:  0.535167, 0.257812 (1.429 sec)
3.397... logprob:  0.681734, 0.270833 (1.427 sec)
3.398... logprob:  0.615483, 0.256510 (1.427 sec)
3.399... logprob:  0.691475, 0.285156 (1.477 sec)
3.400... logprob:  0.759899, 0.296875 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.563758, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.223314e-03 [3.678253e-07] 
Layer 'conv1' biases: 4.870796e-07 [1.415662e-09] 
Layer 'conv2' weights[0]: 7.211145e-03 [3.648782e-07] 
Layer 'conv2' biases: 9.999998e-01 [8.540221e-09] 
Layer 'conv3' weights[0]: 7.209997e-03 [3.654124e-07] 
Layer 'conv3' biases: 1.093244e-05 [3.195570e-08] 
Layer 'conv4' weights[0]: 7.239096e-03 [3.692616e-07] 
Layer 'conv4' biases: 1.000004e+00 [2.990568e-07] 
Layer 'conv5' weights[0]: 7.248188e-03 [1.949349e-06] 
Layer 'conv5' biases: 9.995692e-01 [1.985838e-06] 
Layer 'fc6' weights[0]: 7.514757e-03 [5.628321e-08] 
Layer 'fc6' biases: 9.999995e-01 [4.746958e-08] 
Layer 'fc7' weights[0]: 7.869820e-03 [1.144490e-07] 
Layer 'fc7' biases: 9.999717e-01 [1.261335e-07] 
Layer 'fc8' weights[0]: 3.224459e-03 [2.021788e-05] 
Layer 'fc8' biases: 4.911125e-03 [2.155920e-05] 
Train error last 800 batches: 0.657770
-------------------------------------------------------
Not saving because 0.563758 > 0.323801 (3.40: -8.65%)
======================================================= (2.370 sec)
3.401... logprob:  0.625866, 0.263021 (1.443 sec)
3.402... logprob:  0.696494, 0.307292 (1.479 sec)
3.403... logprob:  0.721143, 0.322917 (1.428 sec)
3.404... logprob:  0.729975, 0.320312 (1.424 sec)
3.405... logprob:  0.788651, 0.350260 (1.431 sec)
3.406... logprob:  0.608521, 0.263021 (1.425 sec)
3.407... logprob:  0.684579, 0.300781 (1.425 sec)
3.408... logprob:  0.533112, 0.240885 (1.473 sec)
3.409... logprob:  0.623234, 0.250000 (1.431 sec)
3.410... logprob:  0.790301, 0.309896 (1.445 sec)
3.411... logprob:  0.640903, 0.289062 (1.465 sec)
3.412... logprob:  0.760972, 0.316406 (1.430 sec)
3.413... logprob:  0.731804, 0.319010 (1.434 sec)
3.414... logprob:  0.633335, 0.269531 (1.426 sec)
3.415... logprob:  0.616599, 0.276042 (1.417 sec)
3.416... logprob:  0.681091, 0.290365 (1.432 sec)
3.417... logprob:  0.657364, 0.294271 (1.459 sec)
3.418... logprob:  0.606040, 0.252604 (1.443 sec)
3.419... logprob:  0.596256, 0.260417 (1.449 sec)
3.420... logprob:  0.619033, 0.265625 (1.446 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.521795, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.216066e-03 [3.662718e-07] 
Layer 'conv1' biases: 4.925696e-07 [1.594779e-09] 
Layer 'conv2' weights[0]: 7.203922e-03 [3.648153e-07] 
Layer 'conv2' biases: 9.999998e-01 [9.089028e-09] 
Layer 'conv3' weights[0]: 7.202837e-03 [3.649955e-07] 
Layer 'conv3' biases: 1.105512e-05 [3.095702e-08] 
Layer 'conv4' weights[0]: 7.231879e-03 [3.701863e-07] 
Layer 'conv4' biases: 1.000003e+00 [3.636943e-07] 
Layer 'conv5' weights[0]: 7.241023e-03 [2.156266e-06] 
Layer 'conv5' biases: 9.995651e-01 [2.242398e-06] 
Layer 'fc6' weights[0]: 7.513963e-03 [6.168853e-08] 
Layer 'fc6' biases: 9.999996e-01 [5.533508e-08] 
Layer 'fc7' weights[0]: 7.869000e-03 [1.341072e-07] 
Layer 'fc7' biases: 9.999703e-01 [1.974978e-07] 
Layer 'fc8' weights[0]: 3.197301e-03 [2.777998e-05] 
Layer 'fc8' biases: 4.763055e-03 [5.194693e-05] 
Train error last 800 batches: 0.658005
-------------------------------------------------------
Not saving because 0.521795 > 0.323801 (3.40: -8.65%)
======================================================= (2.353 sec)
3.421... logprob:  0.602972, 0.294271 (1.459 sec)
3.422... logprob:  0.684379, 0.281250 (1.439 sec)
3.423... logprob:  0.644207, 0.278646 (1.424 sec)
3.424... logprob:  0.594985, 0.282552 (1.422 sec)
3.425... logprob:  0.556358, 0.236979 (1.435 sec)
3.426... logprob:  0.682797, 0.326823 (1.436 sec)
3.427... logprob:  0.751274, 0.311198 (1.460 sec)
3.428... logprob:  0.788925, 0.329427 (1.443 sec)
3.429... logprob:  0.678268, 0.302083 (1.439 sec)
3.430... logprob:  0.561756, 0.260417 (1.469 sec)
3.431... logprob:  0.754370, 0.289062 (1.425 sec)
3.432... logprob:  0.609186, 0.259115 (1.420 sec)
3.433... logprob:  0.509960, 0.233073 (1.438 sec)
3.434... logprob:  0.772847, 0.348958 (1.429 sec)
3.435... logprob:  0.798590, 0.330729 (1.428 sec)
3.436... logprob:  0.627021, 0.289062 (1.472 sec)
3.437... logprob:  0.704898, 0.328125 (1.439 sec)
3.438... logprob:  0.796673, 0.360677 (1.419 sec)
3.439... logprob:  0.627645, 0.273437 (1.487 sec)
3.440... logprob:  0.678216, 0.277344 (1.425 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.463790, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.208849e-03 [3.687764e-07] 
Layer 'conv1' biases: 4.963912e-07 [1.568204e-09] 
Layer 'conv2' weights[0]: 7.196773e-03 [3.651230e-07] 
Layer 'conv2' biases: 9.999998e-01 [9.904208e-09] 
Layer 'conv3' weights[0]: 7.195590e-03 [3.659093e-07] 
Layer 'conv3' biases: 1.122222e-05 [3.730790e-08] 
Layer 'conv4' weights[0]: 7.224611e-03 [3.731148e-07] 
Layer 'conv4' biases: 1.000003e+00 [4.119199e-07] 
Layer 'conv5' weights[0]: 7.233976e-03 [2.541874e-06] 
Layer 'conv5' biases: 9.995626e-01 [2.694695e-06] 
Layer 'fc6' weights[0]: 7.513172e-03 [5.904703e-08] 
Layer 'fc6' biases: 9.999995e-01 [5.152678e-08] 
Layer 'fc7' weights[0]: 7.868215e-03 [1.224581e-07] 
Layer 'fc7' biases: 9.999700e-01 [1.590683e-07] 
Layer 'fc8' weights[0]: 3.191905e-03 [2.127412e-05] 
Layer 'fc8' biases: 4.701087e-03 [2.945109e-05] 
Train error last 800 batches: 0.657998
-------------------------------------------------------
Not saving because 0.463790 > 0.323801 (3.40: -8.65%)
======================================================= (2.370 sec)
3.441... logprob:  0.658237, 0.286458 (1.432 sec)
3.442... logprob:  0.632976, 0.292969 (1.435 sec)
3.443... logprob:  0.665930, 0.299479 (1.421 sec)
3.444... logprob:  0.640498, 0.278646 (1.432 sec)
3.445... logprob:  0.616350, 0.276042 (1.476 sec)
3.446... logprob:  0.630605, 0.307292 (1.427 sec)
3.447... logprob:  0.788637, 0.351562 (1.436 sec)
3.448... logprob:  0.558271, 0.244792 (1.477 sec)
3.449... logprob:  0.620781, 0.274740 (1.427 sec)
3.450... logprob:  0.517914, 0.230469 (1.432 sec)
3.451... logprob:  0.681329, 0.325521 (1.429 sec)
3.452... logprob:  0.736642, 0.326823 (1.423 sec)
3.453... logprob:  0.657142, 0.290364 (1.424 sec)
3.454... logprob:  0.641716, 0.265625 (1.477 sec)
3.455... logprob:  0.686263, 0.305990 (1.433 sec)
3.456... logprob:  0.645177, 0.273437 (1.440 sec)
3.457... logprob:  0.635860, 0.312500 (1.468 sec)
3.458... logprob:  0.579778, 0.250000 (1.429 sec)
3.459... logprob:  0.689057, 0.273438 (1.444 sec)
3.460... logprob:  0.543347, 0.266927 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.434315, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.201669e-03 [3.671532e-07] 
Layer 'conv1' biases: 5.040287e-07 [1.239792e-09] 
Layer 'conv2' weights[0]: 7.189553e-03 [3.626922e-07] 
Layer 'conv2' biases: 9.999998e-01 [6.699892e-09] 
Layer 'conv3' weights[0]: 7.188402e-03 [3.634276e-07] 
Layer 'conv3' biases: 1.131811e-05 [2.902528e-08] 
Layer 'conv4' weights[0]: 7.217403e-03 [3.681695e-07] 
Layer 'conv4' biases: 1.000003e+00 [2.886878e-07] 
Layer 'conv5' weights[0]: 7.226760e-03 [2.017290e-06] 
Layer 'conv5' biases: 9.995602e-01 [2.044293e-06] 
Layer 'fc6' weights[0]: 7.512377e-03 [5.572716e-08] 
Layer 'fc6' biases: 9.999996e-01 [4.636100e-08] 
Layer 'fc7' weights[0]: 7.867467e-03 [1.136818e-07] 
Layer 'fc7' biases: 9.999708e-01 [1.387836e-07] 
Layer 'fc8' weights[0]: 3.265119e-03 [1.927602e-05] 
Layer 'fc8' biases: 5.035133e-03 [3.118109e-05] 
Train error last 800 batches: 0.657524
-------------------------------------------------------
Not saving because 0.434315 > 0.323801 (3.40: -8.65%)
======================================================= (2.373 sec)
3.461... logprob:  0.638540, 0.273437 (1.430 sec)
3.462... logprob:  0.743168, 0.305990 (1.429 sec)
3.463... logprob:  0.706135, 0.350260 (1.462 sec)
3.464... logprob:  0.652170, 0.278646 (1.444 sec)
3.465... logprob:  0.639060, 0.264323 (1.452 sec)
3.466... logprob:  0.577823, 0.234375 (1.454 sec)
3.467... logprob:  0.578486, 0.282552 (1.443 sec)
3.468... logprob:  0.651708, 0.298177 (1.432 sec)
3.469... logprob:  0.663059, 0.285156 (1.424 sec)
3.470... logprob:  0.648311, 0.287760 (1.427 sec)
3.471... logprob:  0.735864, 0.294271 (1.466 sec)
3.472... logprob:  0.605810, 0.252604 (1.448 sec)
3.473... logprob:  0.571423, 0.253906 (1.459 sec)
3.474... logprob:  0.803187, 0.359375 (1.449 sec)
3.475... logprob:  0.713506, 0.308594 (1.444 sec)
3.476... logprob:  0.689940, 0.316406 (1.461 sec)
3.477... logprob:  0.657339, 0.300781 (1.432 sec)
3.478... logprob:  0.710124, 0.286458 (1.419 sec)
3.479... logprob:  0.525039, 0.235677 (1.426 sec)
3.480... logprob:  0.759691, 0.325521 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.475872, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.194513e-03 [3.661301e-07] 
Layer 'conv1' biases: 5.022985e-07 [1.320200e-09] 
Layer 'conv2' weights[0]: 7.182388e-03 [3.641414e-07] 
Layer 'conv2' biases: 9.999998e-01 [9.325170e-09] 
Layer 'conv3' weights[0]: 7.181138e-03 [3.638473e-07] 
Layer 'conv3' biases: 1.134362e-05 [3.161641e-08] 
Layer 'conv4' weights[0]: 7.210215e-03 [3.697959e-07] 
Layer 'conv4' biases: 1.000005e+00 [3.658603e-07] 
Layer 'conv5' weights[0]: 7.220125e-03 [2.491597e-06] 
Layer 'conv5' biases: 9.995568e-01 [2.711727e-06] 
Layer 'fc6' weights[0]: 7.511624e-03 [5.893700e-08] 
Layer 'fc6' biases: 9.999995e-01 [5.151445e-08] 
Layer 'fc7' weights[0]: 7.866663e-03 [1.208676e-07] 
Layer 'fc7' biases: 9.999698e-01 [1.541213e-07] 
Layer 'fc8' weights[0]: 3.226808e-03 [2.087290e-05] 
Layer 'fc8' biases: 4.819801e-03 [2.890978e-05] 
Train error last 800 batches: 0.657630
-------------------------------------------------------
Not saving because 0.475872 > 0.323801 (3.40: -8.65%)
======================================================= (2.399 sec)
3.481... logprob:  0.849913, 0.354167 (1.441 sec)
3.482... logprob:  0.723657, 0.309896 (1.478 sec)
3.483... logprob:  0.637714, 0.265625 (1.446 sec)
3.484... logprob:  0.637915, 0.274740 (1.431 sec)
3.485... logprob:  0.631013, 0.283854 (1.472 sec)
3.486... logprob:  0.639056, 0.257812 (1.429 sec)
3.487... logprob:  0.723700, 0.302083 (1.424 sec)
3.488... logprob:  0.677287, 0.285156 (1.437 sec)
3.489... logprob:  0.658923, 0.320312 (1.426 sec)
3.490... logprob:  0.676352, 0.305990 (1.429 sec)
3.491... logprob:  0.551290, 0.259115 (1.470 sec)
3.492... logprob:  0.686807, 0.309896 (1.439 sec)
3.493... logprob:  0.625288, 0.289062 (1.435 sec)
3.494... logprob:  0.646970, 0.285156 (1.484 sec)
3.495... logprob:  0.545764, 0.225260 (1.427 sec)
3.496... logprob:  0.744614, 0.352865 (1.426 sec)
3.497... logprob:  0.607844, 0.289062 (1.428 sec)
3.498... logprob:  0.714057, 0.286458 (1.423 sec)
3.499... logprob:  0.741295, 0.316406 (1.428 sec)
3.500... logprob:  0.609672, 0.286458 (1.480 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.382822, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.187287e-03 [3.667591e-07] 
Layer 'conv1' biases: 5.066107e-07 [1.407404e-09] 
Layer 'conv2' weights[0]: 7.175237e-03 [3.640474e-07] 
Layer 'conv2' biases: 9.999998e-01 [9.056311e-09] 
Layer 'conv3' weights[0]: 7.173970e-03 [3.633083e-07] 
Layer 'conv3' biases: 1.147751e-05 [2.878872e-08] 
Layer 'conv4' weights[0]: 7.203042e-03 [3.689555e-07] 
Layer 'conv4' biases: 1.000004e+00 [3.172666e-07] 
Layer 'conv5' weights[0]: 7.213031e-03 [1.989308e-06] 
Layer 'conv5' biases: 9.995491e-01 [2.097335e-06] 
Layer 'fc6' weights[0]: 7.510872e-03 [5.531363e-08] 
Layer 'fc6' biases: 9.999995e-01 [4.609021e-08] 
Layer 'fc7' weights[0]: 7.865923e-03 [1.122682e-07] 
Layer 'fc7' biases: 9.999697e-01 [1.298932e-07] 
Layer 'fc8' weights[0]: 3.254656e-03 [1.872829e-05] 
Layer 'fc8' biases: 4.959411e-03 [2.437085e-05] 
Train error last 800 batches: 0.657740
-------------------------------------------------------
Not saving because 0.382822 > 0.323801 (3.40: -8.65%)
======================================================= (2.391 sec)
3.501... logprob:  0.542651, 0.223958 (1.435 sec)
3.502... logprob:  0.692059, 0.287760 (1.443 sec)
3.503... logprob:  0.708434, 0.329427 (1.479 sec)
3.504... logprob:  0.753188, 0.317708 (1.432 sec)
3.505... logprob:  0.716227, 0.313802 (1.431 sec)
3.506... logprob:  0.772103, 0.337240 (1.427 sec)
3.507... logprob:  0.669226, 0.272135 (1.419 sec)
3.508... logprob:  0.615893, 0.264323 (1.429 sec)
3.509... logprob:  0.630404, 0.277344 (1.504 sec)
3.510... logprob:  0.612645, 0.279948 (1.434 sec)
3.511... logprob:  0.717186, 0.347656 (1.448 sec)
3.512... logprob:  0.686864, 0.266927 (1.454 sec)
3.513... logprob:  0.576955, 0.246094 (1.439 sec)
3.514... logprob:  0.619536, 0.252604 (1.431 sec)
3.515... logprob:  0.690073, 0.320313 (1.427 sec)
3.516... logprob:  0.601729, 0.269531 (1.418 sec)
3.517... logprob:  0.815743, 0.322917 (1.433 sec)
3.518... logprob:  0.644733, 0.300781 (1.452 sec)
3.519... logprob:  0.810491, 0.321615 (1.448 sec)
3.520... logprob:  0.670175, 0.299479 (1.447 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.517984, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.180124e-03 [3.660417e-07] 
Layer 'conv1' biases: 5.094619e-07 [1.709147e-09] 
Layer 'conv2' weights[0]: 7.167997e-03 [3.630175e-07] 
Layer 'conv2' biases: 9.999998e-01 [9.210165e-09] 
Layer 'conv3' weights[0]: 7.166800e-03 [3.635388e-07] 
Layer 'conv3' biases: 1.160308e-05 [3.542359e-08] 
Layer 'conv4' weights[0]: 7.195871e-03 [3.672209e-07] 
Layer 'conv4' biases: 1.000005e+00 [3.234914e-07] 
Layer 'conv5' weights[0]: 7.206044e-03 [2.035282e-06] 
Layer 'conv5' biases: 9.995503e-01 [2.086336e-06] 
Layer 'fc6' weights[0]: 7.510138e-03 [5.769910e-08] 
Layer 'fc6' biases: 9.999995e-01 [4.990588e-08] 
Layer 'fc7' weights[0]: 7.865157e-03 [1.192270e-07] 
Layer 'fc7' biases: 9.999685e-01 [1.387791e-07] 
Layer 'fc8' weights[0]: 3.230109e-03 [1.930628e-05] 
Layer 'fc8' biases: 4.764784e-03 [1.815832e-05] 
Train error last 800 batches: 0.657961
-------------------------------------------------------
Not saving because 0.517984 > 0.323801 (3.40: -8.65%)
======================================================= (2.368 sec)
3.521... logprob:  0.657066, 0.272135 (1.452 sec)
3.522... logprob:  0.767951, 0.335938 (1.459 sec)
3.523... logprob:  0.565790, 0.260417 (1.439 sec)
3.524... logprob:  0.740513, 0.330729 (1.426 sec)
3.525... logprob:  0.589913, 0.259115 (1.425 sec)
3.526... logprob:  0.565583, 0.248698 (1.432 sec)
3.527... logprob:  0.697573, 0.286458 (1.433 sec)
3.528... logprob:  0.698889, 0.300781 (1.458 sec)
3.529... logprob:  0.601340, 0.265625 (1.450 sec)
3.530... logprob:  0.719972, 0.299479 (1.431 sec)
3.531... logprob:  0.592323, 0.248698 (1.473 sec)
3.532... logprob:  0.674558, 0.289062 (1.427 sec)
3.533... logprob:  0.795976, 0.337240 (1.423 sec)
3.534... logprob:  0.650972, 0.289062 (1.427 sec)
3.535... logprob:  0.797259, 0.346354 (1.431 sec)
3.536... logprob:  0.767630, 0.325521 (1.422 sec)
3.537... logprob:  0.766858, 0.332031 (1.476 sec)
3.538... logprob:  0.657302, 0.296875 (1.433 sec)
3.539... logprob:  0.556390, 0.274740 (1.430 sec)
3.540... logprob:  0.634614, 0.291667 (1.477 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.385010, 0.062500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.172952e-03 [3.648937e-07] 
Layer 'conv1' biases: 5.154654e-07 [1.289153e-09] 
Layer 'conv2' weights[0]: 7.160892e-03 [3.615644e-07] 
Layer 'conv2' biases: 9.999997e-01 [8.021281e-09] 
Layer 'conv3' weights[0]: 7.159667e-03 [3.619240e-07] 
Layer 'conv3' biases: 1.169779e-05 [2.633046e-08] 
Layer 'conv4' weights[0]: 7.188651e-03 [3.661024e-07] 
Layer 'conv4' biases: 1.000005e+00 [2.742205e-07] 
Layer 'conv5' weights[0]: 7.199223e-03 [1.799399e-06] 
Layer 'conv5' biases: 9.995450e-01 [1.821811e-06] 
Layer 'fc6' weights[0]: 7.509399e-03 [5.504378e-08] 
Layer 'fc6' biases: 9.999995e-01 [4.588189e-08] 
Layer 'fc7' weights[0]: 7.864406e-03 [1.122059e-07] 
Layer 'fc7' biases: 9.999678e-01 [1.325405e-07] 
Layer 'fc8' weights[0]: 3.202422e-03 [2.062742e-05] 
Layer 'fc8' biases: 4.597933e-03 [2.904506e-05] 
Train error last 800 batches: 0.657771
-------------------------------------------------------
Not saving because 0.385010 > 0.323801 (3.40: -8.65%)
======================================================= (2.424 sec)
3.541... logprob:  0.581943, 0.265625 (1.432 sec)
3.542... logprob:  0.697447, 0.285156 (1.433 sec)
3.543... logprob:  0.527722, 0.244792 (1.437 sec)
3.544... logprob:  0.538937, 0.240885 (1.429 sec)
3.545... logprob:  0.567404, 0.231771 (1.425 sec)
3.546... logprob:  0.661327, 0.302083 (1.483 sec)
3.547... logprob:  0.674470, 0.281250 (1.460 sec)
3.548... logprob:  0.642817, 0.270833 (1.435 sec)
3.549... logprob:  0.587101, 0.270833 (1.472 sec)
3.550... logprob:  0.594227, 0.266927 (1.426 sec)
3.551... logprob:  0.670760, 0.281250 (1.428 sec)
3.552... logprob:  0.641798, 0.322917 (1.431 sec)
3.553... logprob:  0.599708, 0.264323 (1.419 sec)
3.554... logprob:  0.703322, 0.325521 (1.425 sec)
3.555... logprob:  0.617377, 0.279948 (1.479 sec)
3.556... logprob:  0.650488, 0.315104 (1.434 sec)
3.557... logprob:  0.648321, 0.295573 (1.444 sec)
3.558... logprob:  0.693966, 0.273438 (1.461 sec)
3.559... logprob:  0.698961, 0.295573 (1.429 sec)
3.560... logprob:  0.563471, 0.246094 (1.436 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.407468, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.165777e-03 [3.649186e-07] 
Layer 'conv1' biases: 5.172254e-07 [1.390371e-09] 
Layer 'conv2' weights[0]: 7.153685e-03 [3.615253e-07] 
Layer 'conv2' biases: 9.999997e-01 [8.670026e-09] 
Layer 'conv3' weights[0]: 7.152486e-03 [3.618953e-07] 
Layer 'conv3' biases: 1.160166e-05 [2.972521e-08] 
Layer 'conv4' weights[0]: 7.181450e-03 [3.657127e-07] 
Layer 'conv4' biases: 1.000004e+00 [2.997634e-07] 
Layer 'conv5' weights[0]: 7.191549e-03 [2.091458e-06] 
Layer 'conv5' biases: 9.995438e-01 [2.186397e-06] 
Layer 'fc6' weights[0]: 7.508625e-03 [5.848555e-08] 
Layer 'fc6' biases: 9.999995e-01 [5.120451e-08] 
Layer 'fc7' weights[0]: 7.863622e-03 [1.252470e-07] 
Layer 'fc7' biases: 9.999691e-01 [1.669917e-07] 
Layer 'fc8' weights[0]: 3.340012e-03 [2.739587e-05] 
Layer 'fc8' biases: 5.248136e-03 [5.255175e-05] 
Train error last 800 batches: 0.657492
-------------------------------------------------------
Not saving because 0.407468 > 0.323801 (3.40: -8.65%)
======================================================= (2.355 sec)
3.561... logprob:  0.634049, 0.290364 (1.432 sec)
3.562... logprob:  0.749803, 0.352865 (1.424 sec)
3.563... logprob:  0.599852, 0.294271 (1.438 sec)
3.564... logprob:  0.713453, 0.345052 (1.459 sec)
3.565... logprob:  0.806553, 0.324219 (1.442 sec)
3.566... logprob:  0.635819, 0.313802 (1.449 sec)
3.567... logprob:  0.650541, 0.294271 (1.445 sec)
3.568... logprob:  0.795696, 0.368490 (1.451 sec)
3.569... logprob:  0.623053, 0.274740 (1.429 sec)
3.570... logprob:  0.859588, 0.361979 (1.424 sec)
3.571... logprob:  0.700910, 0.291667 (1.420 sec)
3.572... logprob:  0.681071, 0.312500 (1.433 sec)
3.573... logprob:  0.803573, 0.334635 (1.441 sec)
3.574... logprob:  0.649717, 0.296875 (1.454 sec)
3.575... logprob:  0.576474, 0.248698 (1.450 sec)
3.576... logprob:  0.566307, 0.231771 (1.433 sec)
3.577... logprob:  0.690938, 0.303385 (1.470 sec)
3.578... logprob:  0.550167, 0.243490 (1.429 sec)
3.579... logprob:  0.622932, 0.274740 (1.422 sec)
3.580... logprob:  0.735589, 0.324219 (1.424 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.472656, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.158631e-03 [3.673337e-07] 
Layer 'conv1' biases: 5.247881e-07 [1.180168e-09] 
Layer 'conv2' weights[0]: 7.146561e-03 [3.622895e-07] 
Layer 'conv2' biases: 9.999997e-01 [8.361362e-09] 
Layer 'conv3' weights[0]: 7.145329e-03 [3.621476e-07] 
Layer 'conv3' biases: 1.161165e-05 [2.951842e-08] 
Layer 'conv4' weights[0]: 7.174278e-03 [3.701343e-07] 
Layer 'conv4' biases: 1.000004e+00 [3.719224e-07] 
Layer 'conv5' weights[0]: 7.184574e-03 [2.408852e-06] 
Layer 'conv5' biases: 9.995428e-01 [2.516708e-06] 
Layer 'fc6' weights[0]: 7.507855e-03 [6.049189e-08] 
Layer 'fc6' biases: 9.999994e-01 [5.406382e-08] 
Layer 'fc7' weights[0]: 7.862838e-03 [1.271192e-07] 
Layer 'fc7' biases: 9.999673e-01 [1.765365e-07] 
Layer 'fc8' weights[0]: 3.276725e-03 [2.481501e-05] 
Layer 'fc8' biases: 4.773522e-03 [4.576796e-05] 
Train error last 800 batches: 0.657195
-------------------------------------------------------
Not saving because 0.472656 > 0.323801 (3.40: -8.65%)
======================================================= (2.375 sec)
3.581... logprob:  0.728984, 0.345052 (1.440 sec)
3.582... logprob:  0.714974, 0.325521 (1.430 sec)
3.583... logprob:  0.805858, 0.339844 (1.479 sec)
3.584... logprob:  0.781769, 0.350260 (1.437 sec)
3.585... logprob:  0.633648, 0.303385 (1.452 sec)
3.586... logprob:  0.551103, 0.247396 (1.478 sec)
3.587... logprob:  0.635425, 0.283854 (1.429 sec)
3.588... logprob:  0.565582, 0.238281 (1.420 sec)
3.589... logprob:  0.588704, 0.248698 (1.432 sec)
3.590... logprob:  0.673104, 0.290365 (1.425 sec)
3.591... logprob:  0.588753, 0.276042 (1.428 sec)
3.592... logprob:  0.676919, 0.291667 (1.476 sec)
3.593... logprob:  0.681892, 0.266927 (1.430 sec)
3.594... logprob:  0.555911, 0.268229 (1.433 sec)
3.595... logprob:  0.681370, 0.294271 (1.486 sec)
3.596... logprob:  0.582067, 0.273437 (1.426 sec)
3.597... logprob:  0.711581, 0.294271 (1.433 sec)
3.598... logprob:  0.635126, 0.303385 (1.430 sec)
3.599... logprob:  0.629291, 0.279948 (1.420 sec)
3.600... logprob:  0.573343, 0.278646 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.458609, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.151427e-03 [3.620984e-07] 
Layer 'conv1' biases: 5.234975e-07 [1.278490e-09] 
Layer 'conv2' weights[0]: 7.139395e-03 [3.607163e-07] 
Layer 'conv2' biases: 9.999997e-01 [6.984499e-09] 
Layer 'conv3' weights[0]: 7.138196e-03 [3.614349e-07] 
Layer 'conv3' biases: 1.164989e-05 [2.949928e-08] 
Layer 'conv4' weights[0]: 7.167064e-03 [3.664718e-07] 
Layer 'conv4' biases: 1.000004e+00 [3.097145e-07] 
Layer 'conv5' weights[0]: 7.177610e-03 [2.059105e-06] 
Layer 'conv5' biases: 9.995368e-01 [2.084984e-06] 
Layer 'fc6' weights[0]: 7.507051e-03 [5.517257e-08] 
Layer 'fc6' biases: 9.999994e-01 [4.619359e-08] 
Layer 'fc7' weights[0]: 7.862071e-03 [1.131877e-07] 
Layer 'fc7' biases: 9.999685e-01 [1.396990e-07] 
Layer 'fc8' weights[0]: 3.352307e-03 [1.955928e-05] 
Layer 'fc8' biases: 5.235214e-03 [3.196848e-05] 
Train error last 800 batches: 0.657100
-------------------------------------------------------
Not saving because 0.458609 > 0.323801 (3.40: -8.65%)
======================================================= (2.361 sec)
3.601... logprob:  0.556191, 0.268229 (1.487 sec)
3.602... logprob:  0.512058, 0.230469 (1.432 sec)
3.603... logprob:  0.545224, 0.257812 (1.442 sec)
3.604... logprob:  0.631751, 0.279948 (1.471 sec)
3.605... logprob:  0.763879, 0.315104 (1.427 sec)
3.606... logprob:  0.495611, 0.243490 (1.433 sec)
3.607... logprob:  0.674036, 0.265625 (1.424 sec)
3.608... logprob:  0.629542, 0.278646 (1.420 sec)
3.609... logprob:  0.695839, 0.289062 (1.425 sec)
3.610... logprob:  0.733670, 0.295573 (1.469 sec)
3.611... logprob:  0.675369, 0.287760 (1.438 sec)
3.612... logprob:  0.724242, 0.305990 (1.448 sec)
3.613... logprob:  0.558588, 0.265625 (1.455 sec)
3.614... logprob:  0.697533, 0.286458 (1.441 sec)
3.615... logprob:  0.472805, 0.221354 (1.432 sec)
3.616... logprob:  0.632856, 0.279948 (1.422 sec)
3.617... logprob:  0.612161, 0.277344 (1.415 sec)
3.618... logprob:  0.714983, 0.285156 (1.425 sec)
3.619... logprob:  0.686294, 0.302083 (1.454 sec)
3.620... logprob:  0.767548, 0.346354 (1.448 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.517576, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.144291e-03 [3.654383e-07] 
Layer 'conv1' biases: 5.264412e-07 [1.776311e-09] 
Layer 'conv2' weights[0]: 7.132267e-03 [3.619689e-07] 
Layer 'conv2' biases: 9.999997e-01 [9.765390e-09] 
Layer 'conv3' weights[0]: 7.131078e-03 [3.640666e-07] 
Layer 'conv3' biases: 1.171407e-05 [4.031857e-08] 
Layer 'conv4' weights[0]: 7.159947e-03 [3.717908e-07] 
Layer 'conv4' biases: 1.000005e+00 [4.316152e-07] 
Layer 'conv5' weights[0]: 7.171135e-03 [2.859698e-06] 
Layer 'conv5' biases: 9.995270e-01 [2.999960e-06] 
Layer 'fc6' weights[0]: 7.506287e-03 [6.358422e-08] 
Layer 'fc6' biases: 9.999995e-01 [5.845747e-08] 
Layer 'fc7' weights[0]: 7.861311e-03 [1.358893e-07] 
Layer 'fc7' biases: 9.999675e-01 [2.004318e-07] 
Layer 'fc8' weights[0]: 3.315804e-03 [2.378208e-05] 
Layer 'fc8' biases: 5.115900e-03 [3.919680e-05] 
Train error last 800 batches: 0.656716
-------------------------------------------------------
Not saving because 0.517576 > 0.323801 (3.40: -8.65%)
======================================================= (2.361 sec)
3.621... logprob:  0.629271, 0.270833 (1.457 sec)
3.622... logprob:  0.565719, 0.264323 (1.451 sec)
3.623... logprob:  0.622525, 0.261719 (1.491 sec)
3.624... logprob:  0.757325, 0.328125 (1.429 sec)
3.625... logprob:  0.670343, 0.289062 (1.420 sec)
3.626... logprob:  0.639721, 0.250000 (1.431 sec)
3.627... logprob:  0.693464, 0.295573 (1.428 sec)
3.628... logprob:  0.645994, 0.266927 (1.435 sec)
3.629... logprob:  0.536611, 0.243490 (1.476 sec)
3.630... logprob:  0.683823, 0.300781 (1.447 sec)
3.631... logprob:  0.794009, 0.341146 (1.431 sec)
3.632... logprob:  0.595068, 0.255208 (1.476 sec)
3.633... logprob:  0.622288, 0.276042 (1.429 sec)
3.634... logprob:  0.863727, 0.338542 (1.419 sec)
3.635... logprob:  0.582304, 0.250000 (1.428 sec)
3.636... logprob:  0.679645, 0.281250 (1.430 sec)
3.637... logprob:  0.560795, 0.252604 (1.427 sec)
3.638... logprob:  0.674438, 0.305990 (1.471 sec)
3.639... logprob:  0.700141, 0.299479 (1.433 sec)
3.640... logprob:  0.683311, 0.305990 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.478670, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.137160e-03 [3.630484e-07] 
Layer 'conv1' biases: 5.370836e-07 [1.566312e-09] 
Layer 'conv2' weights[0]: 7.125145e-03 [3.608572e-07] 
Layer 'conv2' biases: 9.999997e-01 [8.615986e-09] 
Layer 'conv3' weights[0]: 7.123989e-03 [3.606004e-07] 
Layer 'conv3' biases: 1.182315e-05 [3.066755e-08] 
Layer 'conv4' weights[0]: 7.152757e-03 [3.661533e-07] 
Layer 'conv4' biases: 1.000007e+00 [3.339754e-07] 
Layer 'conv5' weights[0]: 7.164921e-03 [2.132505e-06] 
Layer 'conv5' biases: 9.995186e-01 [2.322897e-06] 
Layer 'fc6' weights[0]: 7.505500e-03 [5.475100e-08] 
Layer 'fc6' biases: 9.999995e-01 [4.598461e-08] 
Layer 'fc7' weights[0]: 7.860492e-03 [1.110786e-07] 
Layer 'fc7' biases: 9.999655e-01 [1.168122e-07] 
Layer 'fc8' weights[0]: 3.268486e-03 [1.732265e-05] 
Layer 'fc8' biases: 4.814995e-03 [1.151602e-05] 
Train error last 800 batches: 0.656540
-------------------------------------------------------
Not saving because 0.478670 > 0.323801 (3.40: -8.65%)
======================================================= (2.370 sec)
3.641... logprob:  0.715182, 0.295573 (1.485 sec)
3.642... logprob:  0.744918, 0.324219 (1.436 sec)
3.643... logprob:  0.778898, 0.338542 (1.435 sec)
3.644... logprob:  0.588219, 0.281250 (1.434 sec)
3.645... logprob:  0.623745, 0.295573 (1.425 sec)
3.646... logprob:  0.656284, 0.305990 (1.424 sec)
3.647... logprob:  0.696519, 0.276042 (1.483 sec)
3.648... logprob:  0.773356, 0.337240 (1.426 sec)
3.649... logprob:  0.616724, 0.248698 (1.437 sec)
3.650... logprob:  0.625272, 0.289062 (1.469 sec)
3.651... logprob:  0.627419, 0.295573 (1.426 sec)
3.652... logprob:  0.665810, 0.281250 (1.428 sec)
3.653... logprob:  0.686422, 0.296875 (1.430 sec)
3.654... logprob:  0.629848, 0.282552 (1.422 sec)
3.655... logprob:  0.638510, 0.272135 (1.427 sec)
3.656... logprob:  0.638281, 0.291667 (1.474 sec)
3.657... logprob:  0.713374, 0.322917 (1.432 sec)
3.658... logprob:  0.563437, 0.260417 (1.444 sec)
3.659... logprob:  0.700583, 0.348958 (1.472 sec)
3.660... logprob:  0.646928, 0.292969 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.516306, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.130032e-03 [3.637364e-07] 
Layer 'conv1' biases: 5.448638e-07 [1.221387e-09] 
Layer 'conv2' weights[0]: 7.118038e-03 [3.601989e-07] 
Layer 'conv2' biases: 9.999998e-01 [8.043624e-09] 
Layer 'conv3' weights[0]: 7.116844e-03 [3.609715e-07] 
Layer 'conv3' biases: 1.193595e-05 [3.145033e-08] 
Layer 'conv4' weights[0]: 7.145600e-03 [3.670037e-07] 
Layer 'conv4' biases: 1.000008e+00 [3.603685e-07] 
Layer 'conv5' weights[0]: 7.157992e-03 [2.377862e-06] 
Layer 'conv5' biases: 9.995118e-01 [2.533884e-06] 
Layer 'fc6' weights[0]: 7.504698e-03 [6.018554e-08] 
Layer 'fc6' biases: 9.999994e-01 [5.385946e-08] 
Layer 'fc7' weights[0]: 7.859732e-03 [1.285294e-07] 
Layer 'fc7' biases: 9.999666e-01 [1.845506e-07] 
Layer 'fc8' weights[0]: 3.320806e-03 [2.343038e-05] 
Layer 'fc8' biases: 5.077401e-03 [4.563681e-05] 
Train error last 800 batches: 0.656319
-------------------------------------------------------
Not saving because 0.516306 > 0.323801 (3.40: -8.65%)
======================================================= (2.409 sec)
3.661... logprob:  0.602284, 0.257812 (1.469 sec)
3.662... logprob:  0.792176, 0.338542 (1.434 sec)
3.663... logprob:  0.594724, 0.283854 (1.423 sec)
3.664... logprob:  0.584370, 0.276042 (1.430 sec)
3.665... logprob:  0.632174, 0.263021 (1.452 sec)
3.666... logprob:  0.716387, 0.326823 (1.450 sec)
3.667... logprob:  0.819107, 0.343750 (1.452 sec)
3.668... logprob:  0.671072, 0.302083 (1.448 sec)
3.669... logprob:  0.680627, 0.298177 (1.453 sec)
3.670... logprob:  0.596383, 0.266927 (1.434 sec)
3.671... logprob:  0.653267, 0.274740 (1.417 sec)
3.672... logprob:  0.712384, 0.328125 (1.426 sec)
3.673... logprob:  0.619972, 0.279948 (1.430 sec)
3.674... logprob:  0.738307, 0.308594 (1.436 sec)
3.675... logprob:  0.634471, 0.285156 (1.462 sec)
3.676... logprob:  0.635367, 0.289062 (1.445 sec)
3.677... logprob:  0.714942, 0.302083 (1.435 sec)
3.678... logprob:  0.664492, 0.273437 (1.472 sec)
3.679... logprob:  0.700479, 0.292969 (1.428 sec)
3.680... logprob:  0.573499, 0.277344 (1.417 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.397077, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.122890e-03 [3.629860e-07] 
Layer 'conv1' biases: 5.492727e-07 [1.223744e-09] 
Layer 'conv2' weights[0]: 7.110909e-03 [3.592266e-07] 
Layer 'conv2' biases: 9.999998e-01 [7.411573e-09] 
Layer 'conv3' weights[0]: 7.109781e-03 [3.597640e-07] 
Layer 'conv3' biases: 1.195807e-05 [2.850239e-08] 
Layer 'conv4' weights[0]: 7.138424e-03 [3.641077e-07] 
Layer 'conv4' biases: 1.000007e+00 [3.030619e-07] 
Layer 'conv5' weights[0]: 7.150809e-03 [2.069837e-06] 
Layer 'conv5' biases: 9.995109e-01 [2.245697e-06] 
Layer 'fc6' weights[0]: 7.503902e-03 [5.627324e-08] 
Layer 'fc6' biases: 9.999993e-01 [4.854276e-08] 
Layer 'fc7' weights[0]: 7.858953e-03 [1.156503e-07] 
Layer 'fc7' biases: 9.999661e-01 [1.371548e-07] 
Layer 'fc8' weights[0]: 3.317265e-03 [2.042135e-05] 
Layer 'fc8' biases: 5.004231e-03 [3.243175e-05] 
Train error last 800 batches: 0.657128
-------------------------------------------------------
Not saving because 0.397077 > 0.323801 (3.40: -8.65%)
======================================================= (2.372 sec)
3.681... logprob:  0.653610, 0.300781 (1.436 sec)
3.682... logprob:  0.531457, 0.251302 (1.440 sec)
3.683... logprob:  0.585455, 0.278646 (1.431 sec)
3.684... logprob:  0.628123, 0.292969 (1.472 sec)
3.685... logprob:  0.552595, 0.263021 (1.442 sec)
3.686... logprob:  0.479372, 0.218750 (1.430 sec)
3.687... logprob:  0.519874, 0.239583 (1.485 sec)
3.688... logprob:  0.592183, 0.252604 (1.426 sec)
3.689... logprob:  0.721761, 0.283854 (1.427 sec)
3.690... logprob:  0.701349, 0.302083 (1.427 sec)
3.691... logprob:  0.776027, 0.319010 (1.424 sec)
3.692... logprob:  0.593286, 0.273438 (1.428 sec)
3.693... logprob:  0.753154, 0.315104 (1.481 sec)
3.694... logprob:  0.611901, 0.294271 (1.425 sec)
3.695... logprob:  0.478533, 0.216146 (1.438 sec)
3.696... logprob:  0.911362, 0.361979 (1.468 sec)
3.697... logprob:  0.569261, 0.247396 (1.434 sec)
3.698... logprob:  0.658672, 0.289062 (1.424 sec)
3.699... logprob:  0.602929, 0.276042 (1.430 sec)
3.700... logprob:  0.634374, 0.279948 (1.418 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.499469, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.115794e-03 [3.629434e-07] 
Layer 'conv1' biases: 5.499048e-07 [1.402505e-09] 
Layer 'conv2' weights[0]: 7.103783e-03 [3.601441e-07] 
Layer 'conv2' biases: 9.999998e-01 [9.771249e-09] 
Layer 'conv3' weights[0]: 7.102656e-03 [3.607140e-07] 
Layer 'conv3' biases: 1.199345e-05 [3.497209e-08] 
Layer 'conv4' weights[0]: 7.131358e-03 [3.667002e-07] 
Layer 'conv4' biases: 1.000007e+00 [3.960678e-07] 
Layer 'conv5' weights[0]: 7.143656e-03 [2.719923e-06] 
Layer 'conv5' biases: 9.995112e-01 [2.856349e-06] 
Layer 'fc6' weights[0]: 7.503107e-03 [6.036899e-08] 
Layer 'fc6' biases: 9.999994e-01 [5.422637e-08] 
Layer 'fc7' weights[0]: 7.858193e-03 [1.285340e-07] 
Layer 'fc7' biases: 9.999655e-01 [1.783073e-07] 
Layer 'fc8' weights[0]: 3.348165e-03 [2.198331e-05] 
Layer 'fc8' biases: 5.183673e-03 [2.832079e-05] 
Train error last 800 batches: 0.657049
-------------------------------------------------------
Not saving because 0.499469 > 0.323801 (3.40: -8.65%)
======================================================= (2.404 sec)
3.701... logprob:  0.641583, 0.278646 (1.438 sec)
3.702... logprob:  0.649029, 0.272135 (1.483 sec)
3.703... logprob:  0.636686, 0.285156 (1.439 sec)
3.704... logprob:  0.581177, 0.257812 (1.444 sec)
3.705... logprob:  0.634256, 0.289062 (1.471 sec)
3.706... logprob:  0.635098, 0.283854 (1.432 sec)
3.707... logprob:  0.676446, 0.276042 (1.429 sec)
3.708... logprob:  0.704715, 0.304687 (1.433 sec)
3.709... logprob:  0.676039, 0.296875 (1.419 sec)
3.710... logprob:  0.840534, 0.345052 (1.431 sec)
3.711... logprob:  0.636584, 0.283854 (1.461 sec)
3.712... logprob:  0.662712, 0.320312 (1.441 sec)
3.713... logprob:  0.784049, 0.319010 (1.450 sec)
3.714... logprob:  0.673286, 0.307292 (1.448 sec)
3.715... logprob:  0.647423, 0.268229 (1.451 sec)
3.716... logprob:  0.613066, 0.287760 (1.428 sec)
3.717... logprob:  0.696406, 0.304687 (1.423 sec)
3.718... logprob:  0.725778, 0.287760 (1.417 sec)
3.719... logprob:  0.658491, 0.279948 (1.435 sec)
3.720... logprob:  0.633852, 0.285156 (1.438 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.478064, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.108701e-03 [3.617405e-07] 
Layer 'conv1' biases: 5.626878e-07 [1.867941e-09] 
Layer 'conv2' weights[0]: 7.096705e-03 [3.586885e-07] 
Layer 'conv2' biases: 9.999998e-01 [7.690118e-09] 
Layer 'conv3' weights[0]: 7.095520e-03 [3.594239e-07] 
Layer 'conv3' biases: 1.207297e-05 [3.084610e-08] 
Layer 'conv4' weights[0]: 7.124197e-03 [3.639651e-07] 
Layer 'conv4' biases: 1.000007e+00 [3.021161e-07] 
Layer 'conv5' weights[0]: 7.136708e-03 [2.094502e-06] 
Layer 'conv5' biases: 9.995080e-01 [2.215212e-06] 
Layer 'fc6' weights[0]: 7.502340e-03 [5.633003e-08] 
Layer 'fc6' biases: 9.999994e-01 [4.850463e-08] 
Layer 'fc7' weights[0]: 7.857399e-03 [1.192679e-07] 
Layer 'fc7' biases: 9.999644e-01 [1.375748e-07] 
Layer 'fc8' weights[0]: 3.302517e-03 [2.063526e-05] 
Layer 'fc8' biases: 4.889986e-03 [2.846760e-05] 
Train error last 800 batches: 0.656672
-------------------------------------------------------
Not saving because 0.478064 > 0.323801 (3.40: -8.65%)
======================================================= (2.401 sec)
3.721... logprob:  0.658904, 0.269531 (1.463 sec)
3.722... logprob:  0.800867, 0.330729 (1.456 sec)
3.723... logprob:  0.637843, 0.282552 (1.444 sec)
3.724... logprob:  0.607580, 0.223958 (1.467 sec)
3.725... logprob:  0.666867, 0.277344 (1.437 sec)
3.726... logprob:  0.584131, 0.265625 (1.427 sec)
3.727... logprob:  0.573280, 0.239583 (1.425 sec)
3.728... logprob:  0.655628, 0.304687 (1.431 sec)
3.729... logprob:  0.638311, 0.277344 (1.430 sec)
3.730... logprob:  0.747640, 0.345052 (1.474 sec)
3.731... logprob:  0.588908, 0.274740 (1.441 sec)
3.732... logprob:  0.620175, 0.277344 (1.426 sec)
3.733... logprob:  0.792545, 0.334635 (1.480 sec)
3.734... logprob:  0.601026, 0.253906 (1.427 sec)
3.735... logprob:  0.750536, 0.307292 (1.425 sec)
3.736... logprob:  0.740774, 0.308594 (1.428 sec)
3.737... logprob:  0.736063, 0.328125 (1.422 sec)
3.738... logprob:  0.723614, 0.309896 (1.430 sec)
3.739... logprob:  0.751844, 0.317708 (1.507 sec)
3.740... logprob:  0.579204, 0.259115 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.547731, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.101590e-03 [3.641242e-07] 
Layer 'conv1' biases: 5.702727e-07 [1.552092e-09] 
Layer 'conv2' weights[0]: 7.089602e-03 [3.592130e-07] 
Layer 'conv2' biases: 9.999998e-01 [9.840885e-09] 
Layer 'conv3' weights[0]: 7.088414e-03 [3.600889e-07] 
Layer 'conv3' biases: 1.220403e-05 [3.366180e-08] 
Layer 'conv4' weights[0]: 7.117072e-03 [3.650305e-07] 
Layer 'conv4' biases: 1.000008e+00 [3.522526e-07] 
Layer 'conv5' weights[0]: 7.129754e-03 [2.461447e-06] 
Layer 'conv5' biases: 9.995025e-01 [2.493986e-06] 
Layer 'fc6' weights[0]: 7.501575e-03 [6.083313e-08] 
Layer 'fc6' biases: 9.999994e-01 [5.531537e-08] 
Layer 'fc7' weights[0]: 7.856554e-03 [1.298293e-07] 
Layer 'fc7' biases: 9.999642e-01 [1.723540e-07] 
Layer 'fc8' weights[0]: 3.313636e-03 [2.129110e-05] 
Layer 'fc8' biases: 4.958279e-03 [2.875183e-05] 
Train error last 800 batches: 0.657030
-------------------------------------------------------
Not saving because 0.547731 > 0.323801 (3.40: -8.65%)
======================================================= (2.367 sec)
3.741... logprob:  0.640085, 0.281250 (1.438 sec)
3.742... logprob:  0.624661, 0.278646 (1.484 sec)
3.743... logprob:  0.563716, 0.233073 (1.430 sec)
3.744... logprob:  0.757195, 0.316406 (1.430 sec)
3.745... logprob:  0.648751, 0.304688 (1.434 sec)
3.746... logprob:  0.597205, 0.273438 (1.426 sec)
3.747... logprob:  0.615339, 0.274740 (1.431 sec)
3.748... logprob:  0.618318, 0.273438 (1.480 sec)
3.749... logprob:  0.597373, 0.263021 (1.427 sec)
3.750... logprob:  0.753614, 0.317708 (1.440 sec)
3.751... logprob:  0.496297, 0.223958 (1.468 sec)
3.752... logprob:  0.737471, 0.316406 (1.428 sec)
3.753... logprob:  0.650145, 0.282552 (1.434 sec)
3.754... logprob:  0.654555, 0.294271 (1.422 sec)
3.755... logprob:  0.718172, 0.307292 (1.419 sec)
3.756... logprob:  0.593341, 0.276042 (1.429 sec)
3.757... logprob:  0.808801, 0.358073 (1.467 sec)
3.758... logprob:  0.599174, 0.260417 (1.440 sec)
3.759... logprob:  0.724180, 0.308594 (1.446 sec)
3.760... logprob:  0.744959, 0.311198 (1.463 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.424170, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.094516e-03 [3.649932e-07] 
Layer 'conv1' biases: 5.759468e-07 [1.535912e-09] 
Layer 'conv2' weights[0]: 7.082549e-03 [3.589392e-07] 
Layer 'conv2' biases: 9.999998e-01 [8.879319e-09] 
Layer 'conv3' weights[0]: 7.081363e-03 [3.593352e-07] 
Layer 'conv3' biases: 1.230462e-05 [3.319359e-08] 
Layer 'conv4' weights[0]: 7.109934e-03 [3.646839e-07] 
Layer 'conv4' biases: 1.000007e+00 [3.508492e-07] 
Layer 'conv5' weights[0]: 7.122517e-03 [2.310779e-06] 
Layer 'conv5' biases: 9.994986e-01 [2.403432e-06] 
Layer 'fc6' weights[0]: 7.500807e-03 [5.994568e-08] 
Layer 'fc6' biases: 9.999994e-01 [5.414833e-08] 
Layer 'fc7' weights[0]: 7.855806e-03 [1.256421e-07] 
Layer 'fc7' biases: 9.999642e-01 [1.611948e-07] 
Layer 'fc8' weights[0]: 3.333174e-03 [2.180150e-05] 
Layer 'fc8' biases: 5.089666e-03 [3.291631e-05] 
Train error last 800 batches: 0.656883
-------------------------------------------------------
Not saving because 0.424170 > 0.323801 (3.40: -8.65%)
======================================================= (2.363 sec)
3.761... logprob:  0.656188, 0.308594 (1.452 sec)
3.762... logprob:  0.732074, 0.320312 (1.439 sec)
3.763... logprob:  0.745886, 0.355469 (1.430 sec)
3.764... logprob:  0.774316, 0.337240 (1.424 sec)
3.765... logprob:  0.550439, 0.256510 (1.434 sec)
3.766... logprob:  0.738067, 0.320312 (1.447 sec)
3.767... logprob:  0.555332, 0.248698 (1.451 sec)
3.768... logprob:  0.662528, 0.309896 (1.458 sec)
3.769... logprob:  0.674351, 0.282552 (1.460 sec)
3.770... logprob:  0.597047, 0.248698 (1.475 sec)
3.771... logprob:  0.729781, 0.296875 (1.453 sec)
3.772... logprob:  0.604496, 0.246094 (1.434 sec)
3.773... logprob:  0.515614, 0.218750 (1.444 sec)
3.774... logprob:  0.514747, 0.231771 (1.450 sec)
3.775... logprob:  0.609947, 0.263021 (1.456 sec)
3.776... logprob:  0.738581, 0.347656 (1.470 sec)
3.777... logprob:  0.659445, 0.289062 (1.502 sec)
3.778... logprob:  0.611073, 0.281250 (1.468 sec)
3.779... logprob:  0.754917, 0.321615 (1.479 sec)
3.780... logprob:  0.572880, 0.264323 (1.449 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.366498, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.087416e-03 [3.610722e-07] 
Layer 'conv1' biases: 5.774443e-07 [1.267903e-09] 
Layer 'conv2' weights[0]: 7.075414e-03 [3.580220e-07] 
Layer 'conv2' biases: 9.999997e-01 [8.958164e-09] 
Layer 'conv3' weights[0]: 7.074234e-03 [3.593015e-07] 
Layer 'conv3' biases: 1.233981e-05 [3.385393e-08] 
Layer 'conv4' weights[0]: 7.102820e-03 [3.625589e-07] 
Layer 'conv4' biases: 1.000006e+00 [2.897423e-07] 
Layer 'conv5' weights[0]: 7.115260e-03 [1.945238e-06] 
Layer 'conv5' biases: 9.994963e-01 [2.067912e-06] 
Layer 'fc6' weights[0]: 7.500009e-03 [5.451402e-08] 
Layer 'fc6' biases: 9.999994e-01 [4.581385e-08] 
Layer 'fc7' weights[0]: 7.854999e-03 [1.112525e-07] 
Layer 'fc7' biases: 9.999646e-01 [1.220183e-07] 
Layer 'fc8' weights[0]: 3.369994e-03 [1.755911e-05] 
Layer 'fc8' biases: 5.228487e-03 [1.782138e-05] 
Train error last 800 batches: 0.656160
-------------------------------------------------------
Not saving because 0.366498 > 0.323801 (3.40: -8.65%)
======================================================= (2.373 sec)
3.781... logprob:  0.524076, 0.243490 (1.448 sec)
3.782... logprob:  0.590261, 0.260417 (1.450 sec)
3.783... logprob:  0.791322, 0.338542 (1.459 sec)
3.784... logprob:  0.694828, 0.281250 (1.459 sec)
3.785... logprob:  0.725206, 0.313802 (1.476 sec)
3.786... logprob:  0.635910, 0.264323 (1.466 sec)
3.787... logprob:  0.813325, 0.350260 (1.450 sec)
3.788... logprob:  0.821086, 0.338542 (1.489 sec)
3.789... logprob:  0.583338, 0.248698 (1.449 sec)
3.790... logprob:  0.613774, 0.243490 (1.447 sec)
3.791... logprob:  0.581467, 0.251302 (1.441 sec)
3.792... logprob:  0.592966, 0.257812 (1.454 sec)
3.793... logprob:  0.566227, 0.236979 (1.448 sec)
3.794... logprob:  0.660957, 0.319010 (1.484 sec)
3.795... logprob:  0.701015, 0.298177 (1.465 sec)
3.796... logprob:  0.693026, 0.307292 (1.448 sec)
3.797... logprob:  0.674980, 0.295573 (1.497 sec)
3.798... logprob:  0.621901, 0.276042 (1.440 sec)
3.799... logprob:  0.542202, 0.234375 (1.446 sec)
3.800... logprob:  0.603407, 0.250000 (1.396 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.471495, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.080323e-03 [3.627206e-07] 
Layer 'conv1' biases: 5.798400e-07 [1.672945e-09] 
Layer 'conv2' weights[0]: 7.068316e-03 [3.591995e-07] 
Layer 'conv2' biases: 9.999998e-01 [9.479606e-09] 
Layer 'conv3' weights[0]: 7.067150e-03 [3.601086e-07] 
Layer 'conv3' biases: 1.245466e-05 [3.712587e-08] 
Layer 'conv4' weights[0]: 7.095767e-03 [3.652469e-07] 
Layer 'conv4' biases: 1.000007e+00 [3.857858e-07] 
Layer 'conv5' weights[0]: 7.108641e-03 [2.551495e-06] 
Layer 'conv5' biases: 9.994921e-01 [2.790054e-06] 
Layer 'fc6' weights[0]: 7.499192e-03 [5.850993e-08] 
Layer 'fc6' biases: 9.999993e-01 [5.214475e-08] 
Layer 'fc7' weights[0]: 7.854240e-03 [1.255927e-07] 
Layer 'fc7' biases: 9.999636e-01 [1.733915e-07] 
Layer 'fc8' weights[0]: 3.347984e-03 [2.320646e-05] 
Layer 'fc8' biases: 5.096259e-03 [3.888442e-05] 
Train error last 800 batches: 0.656482
-------------------------------------------------------
Not saving because 0.471495 > 0.323801 (3.40: -8.65%)
======================================================= (2.367 sec)
4.1... logprob:  0.663959, 0.299479 (1.409 sec)
4.2... logprob:  0.658059, 0.292969 (1.454 sec)
4.3... logprob:  0.676442, 0.298177 (1.420 sec)
4.4... logprob:  0.723515, 0.285156 (1.407 sec)
4.5... logprob:  0.659943, 0.299479 (1.434 sec)
4.6... logprob:  0.662190, 0.269531 (1.392 sec)
4.7... logprob:  0.576139, 0.269531 (1.418 sec)
4.8... logprob:  0.691218, 0.303385 (1.397 sec)
4.9... logprob:  0.577499, 0.263021 (1.402 sec)
4.10... logprob:  0.653212, 0.315104 (1.403 sec)
4.11... logprob:  0.623334, 0.273437 (1.441 sec)
4.12... logprob:  0.696643, 0.278646 (1.395 sec)
4.13... logprob:  0.685254, 0.291667 (1.413 sec)
4.14... logprob:  0.656360, 0.296875 (1.401 sec)
4.15... logprob:  0.705889, 0.320312 (1.431 sec)
4.16... logprob:  0.668815, 0.292969 (1.399 sec)
4.17... logprob:  0.836069, 0.367187 (1.386 sec)
4.18... logprob:  0.539423, 0.273437 (1.393 sec)
4.19... logprob:  0.562873, 0.255208 (1.396 sec)
4.20... logprob:  0.652309, 0.282552 (0.674 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.487552, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.073253e-03 [3.613891e-07] 
Layer 'conv1' biases: 5.793952e-07 [1.489495e-09] 
Layer 'conv2' weights[0]: 7.061299e-03 [3.573334e-07] 
Layer 'conv2' biases: 9.999997e-01 [8.270495e-09] 
Layer 'conv3' weights[0]: 7.060153e-03 [3.579694e-07] 
Layer 'conv3' biases: 1.249091e-05 [2.920705e-08] 
Layer 'conv4' weights[0]: 7.088650e-03 [3.629779e-07] 
Layer 'conv4' biases: 1.000006e+00 [3.236398e-07] 
Layer 'conv5' weights[0]: 7.101424e-03 [2.236818e-06] 
Layer 'conv5' biases: 9.994944e-01 [2.319081e-06] 
Layer 'fc6' weights[0]: 7.498454e-03 [5.513227e-08] 
Layer 'fc6' biases: 9.999994e-01 [4.703252e-08] 
Layer 'fc7' weights[0]: 7.853519e-03 [1.112210e-07] 
Layer 'fc7' biases: 9.999633e-01 [1.242712e-07] 
Layer 'fc8' weights[0]: 3.369003e-03 [1.866493e-05] 
Layer 'fc8' biases: 5.205682e-03 [2.552092e-05] 
Train error last 800 batches: 0.657384
-------------------------------------------------------
Not saving because 0.487552 > 0.323801 (3.40: -8.65%)
======================================================= (2.380 sec)
4.21... logprob:  0.727760, 0.311198 (1.412 sec)
4.22... logprob:  0.746441, 0.341146 (1.409 sec)
4.23... logprob:  0.668469, 0.283854 (1.409 sec)
4.24... logprob:  0.604121, 0.287760 (1.416 sec)
4.25... logprob:  0.576243, 0.246094 (1.395 sec)
4.26... logprob:  0.738089, 0.325521 (1.437 sec)
4.27... logprob:  0.606754, 0.281250 (1.382 sec)
4.28... logprob:  0.600695, 0.273437 (1.410 sec)
4.29... logprob:  0.651924, 0.324219 (1.422 sec)
4.30... logprob:  0.567116, 0.250000 (1.409 sec)
4.31... logprob:  0.663947, 0.302083 (1.392 sec)
4.32... logprob:  0.608768, 0.273438 (1.386 sec)
4.33... logprob:  0.603737, 0.259115 (1.438 sec)
4.34... logprob:  0.673267, 0.300781 (1.382 sec)
4.35... logprob:  0.517772, 0.240885 (1.398 sec)
4.36... logprob:  0.698908, 0.330729 (1.394 sec)
4.37... logprob:  0.628775, 0.291667 (1.403 sec)
4.38... logprob:  0.691658, 0.304688 (1.387 sec)
4.39... logprob:  0.912040, 0.368490 (1.429 sec)
4.40... logprob:  0.740381, 0.291667 (1.404 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.555173, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.066170e-03 [3.605400e-07] 
Layer 'conv1' biases: 5.808138e-07 [1.198425e-09] 
Layer 'conv2' weights[0]: 7.054183e-03 [3.585232e-07] 
Layer 'conv2' biases: 9.999997e-01 [9.948305e-09] 
Layer 'conv3' weights[0]: 7.053025e-03 [3.602344e-07] 
Layer 'conv3' biases: 1.245024e-05 [4.102878e-08] 
Layer 'conv4' weights[0]: 7.081542e-03 [3.678593e-07] 
Layer 'conv4' biases: 1.000005e+00 [4.572636e-07] 
Layer 'conv5' weights[0]: 7.094087e-03 [2.678942e-06] 
Layer 'conv5' biases: 9.994944e-01 [2.878430e-06] 
Layer 'fc6' weights[0]: 7.497646e-03 [6.415623e-08] 
Layer 'fc6' biases: 9.999993e-01 [6.004630e-08] 
Layer 'fc7' weights[0]: 7.852715e-03 [1.379641e-07] 
Layer 'fc7' biases: 9.999640e-01 [1.917406e-07] 
Layer 'fc8' weights[0]: 3.417512e-03 [2.245524e-05] 
Layer 'fc8' biases: 5.348599e-03 [3.454712e-05] 
Train error last 800 batches: 0.657418
-------------------------------------------------------
Not saving because 0.555173 > 0.323801 (3.40: -8.65%)
======================================================= (2.399 sec)
4.41... logprob:  0.643349, 0.290364 (1.426 sec)
4.42... logprob:  0.557262, 0.231771 (1.418 sec)
4.43... logprob:  0.583628, 0.253906 (1.405 sec)
4.44... logprob:  0.677869, 0.309896 (1.429 sec)
4.45... logprob:  0.588103, 0.282552 (1.384 sec)
4.46... logprob:  0.724485, 0.330729 (1.399 sec)
4.47... logprob:  0.605896, 0.283854 (1.390 sec)
4.48... logprob:  0.791424, 0.325521 (1.420 sec)
4.49... logprob:  0.647148, 0.286458 (1.412 sec)
4.50... logprob:  0.659729, 0.281250 (1.416 sec)
4.51... logprob:  0.612415, 0.250000 (1.413 sec)
4.52... logprob:  0.808427, 0.329427 (1.390 sec)
4.53... logprob:  0.547477, 0.265625 (1.437 sec)
4.54... logprob:  0.702953, 0.312500 (1.382 sec)
4.55... logprob:  0.578742, 0.285156 (1.393 sec)
4.56... logprob:  0.690861, 0.322917 (1.395 sec)
4.57... logprob:  0.699956, 0.316406 (1.424 sec)
4.58... logprob:  0.630765, 0.282552 (1.395 sec)
4.59... logprob:  0.584731, 0.268229 (1.458 sec)
4.60... logprob:  0.760507, 0.317708 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.435099, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.059102e-03 [3.568148e-07] 
Layer 'conv1' biases: 5.828612e-07 [1.287801e-09] 
Layer 'conv2' weights[0]: 7.047164e-03 [3.551781e-07] 
Layer 'conv2' biases: 9.999997e-01 [6.413369e-09] 
Layer 'conv3' weights[0]: 7.046021e-03 [3.560533e-07] 
Layer 'conv3' biases: 1.252255e-05 [2.799512e-08] 
Layer 'conv4' weights[0]: 7.074490e-03 [3.601489e-07] 
Layer 'conv4' biases: 1.000005e+00 [2.912066e-07] 
Layer 'conv5' weights[0]: 7.087166e-03 [2.082019e-06] 
Layer 'conv5' biases: 9.994983e-01 [2.219956e-06] 
Layer 'fc6' weights[0]: 7.496868e-03 [5.850264e-08] 
Layer 'fc6' biases: 9.999993e-01 [5.202359e-08] 
Layer 'fc7' weights[0]: 7.851944e-03 [1.257534e-07] 
Layer 'fc7' biases: 9.999634e-01 [1.646138e-07] 
Layer 'fc8' weights[0]: 3.407482e-03 [2.634707e-05] 
Layer 'fc8' biases: 5.207918e-03 [4.594303e-05] 
Train error last 800 batches: 0.657481
-------------------------------------------------------
Not saving because 0.435099 > 0.323801 (3.40: -8.65%)
======================================================= (2.375 sec)
4.61... logprob:  0.617838, 0.290365 (1.431 sec)
4.62... logprob:  0.692290, 0.312500 (1.456 sec)
4.63... logprob:  0.598336, 0.257812 (1.440 sec)
4.64... logprob:  0.775066, 0.339844 (1.403 sec)
4.65... logprob:  0.664102, 0.299479 (1.391 sec)
4.66... logprob:  0.526650, 0.212240 (1.438 sec)
4.67... logprob:  0.530984, 0.220052 (1.381 sec)
4.68... logprob:  0.594089, 0.274740 (1.390 sec)
4.69... logprob:  0.639437, 0.261719 (1.421 sec)
4.70... logprob:  0.539742, 0.256510 (1.413 sec)
4.71... logprob:  0.655579, 0.285156 (1.455 sec)
4.72... logprob:  0.685504, 0.287760 (1.397 sec)
4.73... logprob:  0.692304, 0.305990 (1.417 sec)
4.74... logprob:  0.767253, 0.298177 (1.410 sec)
4.75... logprob:  0.609875, 0.291667 (1.411 sec)
4.76... logprob:  0.654449, 0.299479 (1.426 sec)
4.77... logprob:  0.609586, 0.263021 (1.425 sec)
4.78... logprob:  0.752324, 0.334635 (1.449 sec)
4.79... logprob:  0.698522, 0.309896 (1.391 sec)
4.80... logprob:  0.658110, 0.263021 (1.416 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.517606, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.052061e-03 [3.608553e-07] 
Layer 'conv1' biases: 5.815848e-07 [1.175297e-09] 
Layer 'conv2' weights[0]: 7.040118e-03 [3.569410e-07] 
Layer 'conv2' biases: 9.999997e-01 [9.084740e-09] 
Layer 'conv3' weights[0]: 7.038978e-03 [3.570909e-07] 
Layer 'conv3' biases: 1.264107e-05 [3.299391e-08] 
Layer 'conv4' weights[0]: 7.067402e-03 [3.615232e-07] 
Layer 'conv4' biases: 1.000006e+00 [3.491330e-07] 
Layer 'conv5' weights[0]: 7.080409e-03 [2.337107e-06] 
Layer 'conv5' biases: 9.994971e-01 [2.493208e-06] 
Layer 'fc6' weights[0]: 7.496117e-03 [6.130726e-08] 
Layer 'fc6' biases: 9.999993e-01 [5.584984e-08] 
Layer 'fc7' weights[0]: 7.851182e-03 [1.314309e-07] 
Layer 'fc7' biases: 9.999628e-01 [1.766174e-07] 
Layer 'fc8' weights[0]: 3.400783e-03 [2.156036e-05] 
Layer 'fc8' biases: 5.141308e-03 [3.304554e-05] 
Train error last 800 batches: 0.658005
-------------------------------------------------------
Not saving because 0.517606 > 0.323801 (3.40: -8.65%)
======================================================= (2.374 sec)
4.81... logprob:  0.605112, 0.243489 (1.422 sec)
4.82... logprob:  0.525541, 0.259115 (1.425 sec)
4.83... logprob:  0.714385, 0.296875 (1.401 sec)
4.84... logprob:  0.604028, 0.265625 (1.457 sec)
4.85... logprob:  0.615728, 0.305990 (1.419 sec)
4.86... logprob:  0.660346, 0.294271 (1.411 sec)
4.87... logprob:  0.755596, 0.295573 (1.412 sec)
4.88... logprob:  0.742060, 0.330729 (1.405 sec)
4.89... logprob:  0.540924, 0.236979 (1.433 sec)
4.90... logprob:  0.812868, 0.351562 (1.379 sec)
4.91... logprob:  0.572774, 0.234375 (1.389 sec)
4.92... logprob:  0.653949, 0.286458 (1.398 sec)
4.93... logprob:  0.752890, 0.337240 (1.391 sec)
4.94... logprob:  0.571183, 0.264323 (1.384 sec)
4.95... logprob:  0.655889, 0.274740 (1.401 sec)
4.96... logprob:  0.759583, 0.335938 (1.403 sec)
4.97... logprob:  0.626435, 0.312500 (1.383 sec)
4.98... logprob:  0.552777, 0.265625 (1.434 sec)
4.99... logprob:  0.726294, 0.337240 (1.399 sec)
4.100... logprob:  0.444708, 0.201823 (1.395 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.490485, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.045027e-03 [3.589839e-07] 
Layer 'conv1' biases: 5.778358e-07 [1.384065e-09] 
Layer 'conv2' weights[0]: 7.033069e-03 [3.560094e-07] 
Layer 'conv2' biases: 9.999997e-01 [8.502025e-09] 
Layer 'conv3' weights[0]: 7.031979e-03 [3.567305e-07] 
Layer 'conv3' biases: 1.267209e-05 [3.325227e-08] 
Layer 'conv4' weights[0]: 7.060322e-03 [3.636117e-07] 
Layer 'conv4' biases: 1.000006e+00 [3.875742e-07] 
Layer 'conv5' weights[0]: 7.073484e-03 [2.506982e-06] 
Layer 'conv5' biases: 9.994888e-01 [2.601220e-06] 
Layer 'fc6' weights[0]: 7.495332e-03 [6.039811e-08] 
Layer 'fc6' biases: 9.999993e-01 [5.473439e-08] 
Layer 'fc7' weights[0]: 7.850371e-03 [1.307311e-07] 
Layer 'fc7' biases: 9.999628e-01 [1.937772e-07] 
Layer 'fc8' weights[0]: 3.436474e-03 [2.281483e-05] 
Layer 'fc8' biases: 5.309417e-03 [4.118536e-05] 
Train error last 800 batches: 0.656988
-------------------------------------------------------
Not saving because 0.490485 > 0.323801 (3.40: -8.65%)
======================================================= (2.406 sec)
4.101... logprob:  0.542135, 0.256510 (1.451 sec)
4.102... logprob:  0.751032, 0.317708 (1.395 sec)
4.103... logprob:  0.705410, 0.311198 (1.397 sec)
4.104... logprob:  0.611961, 0.300781 (1.402 sec)
4.105... logprob:  0.816617, 0.335937 (1.430 sec)
4.106... logprob:  0.511988, 0.240885 (1.392 sec)
4.107... logprob:  0.639595, 0.300781 (1.434 sec)
4.108... logprob:  0.760073, 0.332031 (1.387 sec)
4.109... logprob:  0.612817, 0.256510 (1.396 sec)
4.110... logprob:  0.865498, 0.334635 (1.391 sec)
4.111... logprob:  0.647369, 0.291667 (1.388 sec)
4.112... logprob:  0.642358, 0.279948 (1.390 sec)
4.113... logprob:  0.640892, 0.281250 (1.397 sec)
4.114... logprob:  0.632195, 0.276042 (1.422 sec)
4.115... logprob:  0.679551, 0.292969 (1.406 sec)
4.116... logprob:  0.713400, 0.298177 (1.393 sec)
4.117... logprob:  0.622828, 0.276042 (1.438 sec)
4.118... logprob:  0.608777, 0.257812 (1.390 sec)
4.119... logprob:  0.599450, 0.269531 (1.394 sec)
4.120... logprob:  0.640210, 0.257812 (1.403 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.518995, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.037977e-03 [3.599001e-07] 
Layer 'conv1' biases: 5.756165e-07 [1.670009e-09] 
Layer 'conv2' weights[0]: 7.026033e-03 [3.557969e-07] 
Layer 'conv2' biases: 9.999997e-01 [9.844146e-09] 
Layer 'conv3' weights[0]: 7.024921e-03 [3.555970e-07] 
Layer 'conv3' biases: 1.272742e-05 [3.072318e-08] 
Layer 'conv4' weights[0]: 7.053274e-03 [3.599032e-07] 
Layer 'conv4' biases: 1.000007e+00 [3.133369e-07] 
Layer 'conv5' weights[0]: 7.066873e-03 [2.235141e-06] 
Layer 'conv5' biases: 9.994823e-01 [2.369133e-06] 
Layer 'fc6' weights[0]: 7.494552e-03 [5.801496e-08] 
Layer 'fc6' biases: 9.999993e-01 [5.144497e-08] 
Layer 'fc7' weights[0]: 7.849596e-03 [1.210597e-07] 
Layer 'fc7' biases: 9.999614e-01 [1.461102e-07] 
Layer 'fc8' weights[0]: 3.400740e-03 [1.870981e-05] 
Layer 'fc8' biases: 5.133880e-03 [2.313320e-05] 
Train error last 800 batches: 0.657024
-------------------------------------------------------
Not saving because 0.518995 > 0.323801 (3.40: -8.65%)
======================================================= (2.371 sec)
4.121... logprob:  0.601896, 0.244792 (1.405 sec)
4.122... logprob:  0.699167, 0.309896 (1.448 sec)
4.123... logprob:  0.667119, 0.296875 (1.386 sec)
4.124... logprob:  0.582653, 0.291667 (1.396 sec)
4.125... logprob:  0.789594, 0.356771 (1.392 sec)
4.126... logprob:  0.688567, 0.298177 (1.388 sec)
4.127... logprob:  0.810158, 0.354167 (1.398 sec)
4.128... logprob:  0.616301, 0.283854 (1.414 sec)
4.129... logprob:  0.739649, 0.299479 (1.418 sec)
4.130... logprob:  0.642027, 0.269531 (1.416 sec)
4.131... logprob:  0.634101, 0.289062 (1.399 sec)
4.132... logprob:  0.717760, 0.305990 (1.428 sec)
4.133... logprob:  0.684400, 0.295573 (1.384 sec)
4.134... logprob:  0.646383, 0.264323 (1.389 sec)
4.135... logprob:  0.628412, 0.266927 (1.396 sec)
4.136... logprob:  0.707673, 0.298177 (1.387 sec)
4.137... logprob:  0.719435, 0.334635 (1.385 sec)
4.138... logprob:  0.595637, 0.302083 (1.437 sec)
4.139... logprob:  0.595380, 0.248698 (1.392 sec)
4.140... logprob:  0.812625, 0.363281 (1.404 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.514755, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.030969e-03 [3.584868e-07] 
Layer 'conv1' biases: 5.782582e-07 [1.290709e-09] 
Layer 'conv2' weights[0]: 7.019018e-03 [3.553340e-07] 
Layer 'conv2' biases: 9.999997e-01 [8.557529e-09] 
Layer 'conv3' weights[0]: 7.017888e-03 [3.553949e-07] 
Layer 'conv3' biases: 1.280465e-05 [3.239987e-08] 
Layer 'conv4' weights[0]: 7.046244e-03 [3.599459e-07] 
Layer 'conv4' biases: 1.000006e+00 [3.472221e-07] 
Layer 'conv5' weights[0]: 7.059605e-03 [2.176173e-06] 
Layer 'conv5' biases: 9.994828e-01 [2.352991e-06] 
Layer 'fc6' weights[0]: 7.493753e-03 [5.543690e-08] 
Layer 'fc6' biases: 9.999993e-01 [4.746505e-08] 
Layer 'fc7' weights[0]: 7.848803e-03 [1.156680e-07] 
Layer 'fc7' biases: 9.999606e-01 [1.280122e-07] 
Layer 'fc8' weights[0]: 3.373136e-03 [1.826218e-05] 
Layer 'fc8' biases: 4.970187e-03 [2.054596e-05] 
Train error last 800 batches: 0.657135
-------------------------------------------------------
Not saving because 0.514755 > 0.323801 (3.40: -8.65%)
======================================================= (2.377 sec)
4.141... logprob:  0.567849, 0.230469 (1.439 sec)
4.142... logprob:  0.655884, 0.294271 (1.395 sec)
4.143... logprob:  0.554779, 0.239583 (1.422 sec)
4.144... logprob:  0.631899, 0.298177 (1.410 sec)
4.145... logprob:  0.563429, 0.278646 (1.412 sec)
4.146... logprob:  0.687067, 0.319010 (1.409 sec)
4.147... logprob:  0.575745, 0.266927 (1.425 sec)
4.148... logprob:  0.629675, 0.302083 (1.388 sec)
4.149... logprob:  0.680402, 0.309896 (1.392 sec)
4.150... logprob:  0.614530, 0.281250 (1.395 sec)
4.151... logprob:  0.647466, 0.307292 (1.389 sec)
4.152... logprob:  0.954586, 0.359375 (1.384 sec)
4.153... logprob:  0.756861, 0.343750 (1.438 sec)
4.154... logprob:  0.798576, 0.322917 (1.391 sec)
4.155... logprob:  0.691069, 0.290365 (1.406 sec)
4.156... logprob:  0.540419, 0.248698 (1.429 sec)
4.157... logprob:  0.570930, 0.287760 (1.388 sec)
4.158... logprob:  0.595764, 0.272135 (1.390 sec)
4.159... logprob:  0.684737, 0.269531 (1.397 sec)
4.160... logprob:  0.699877, 0.277344 (1.385 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.495671, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.023924e-03 [3.594690e-07] 
Layer 'conv1' biases: 5.800111e-07 [1.430596e-09] 
Layer 'conv2' weights[0]: 7.012034e-03 [3.559711e-07] 
Layer 'conv2' biases: 9.999997e-01 [9.416178e-09] 
Layer 'conv3' weights[0]: 7.010871e-03 [3.568912e-07] 
Layer 'conv3' biases: 1.274397e-05 [3.885994e-08] 
Layer 'conv4' weights[0]: 7.039194e-03 [3.636899e-07] 
Layer 'conv4' biases: 1.000005e+00 [4.285840e-07] 
Layer 'conv5' weights[0]: 7.052452e-03 [2.668788e-06] 
Layer 'conv5' biases: 9.994836e-01 [2.893795e-06] 
Layer 'fc6' weights[0]: 7.492978e-03 [6.228769e-08] 
Layer 'fc6' biases: 9.999993e-01 [5.757806e-08] 
Layer 'fc7' weights[0]: 7.848005e-03 [1.348581e-07] 
Layer 'fc7' biases: 9.999607e-01 [1.883528e-07] 
Layer 'fc8' weights[0]: 3.427551e-03 [2.330627e-05] 
Layer 'fc8' biases: 5.151726e-03 [3.484341e-05] 
Train error last 800 batches: 0.657474
-------------------------------------------------------
Not saving because 0.495671 > 0.323801 (3.40: -8.65%)
======================================================= (2.356 sec)
4.161... logprob:  0.571534, 0.272135 (1.418 sec)
4.162... logprob:  0.779048, 0.343750 (1.415 sec)
4.163... logprob:  0.629041, 0.294271 (1.424 sec)
4.164... logprob:  0.720763, 0.333333 (1.419 sec)
4.165... logprob:  0.745109, 0.325521 (1.419 sec)
4.166... logprob:  0.701658, 0.309896 (1.443 sec)
4.167... logprob:  0.606907, 0.274740 (1.423 sec)
4.168... logprob:  0.542245, 0.235677 (1.417 sec)
4.169... logprob:  0.556300, 0.253906 (1.454 sec)
4.170... logprob:  0.619570, 0.285156 (1.393 sec)
4.171... logprob:  0.731928, 0.290365 (1.416 sec)
4.172... logprob:  0.598462, 0.244792 (1.408 sec)
4.173... logprob:  0.679155, 0.317708 (1.417 sec)
4.174... logprob:  0.711727, 0.303385 (1.393 sec)
4.175... logprob:  0.733633, 0.339844 (1.466 sec)
4.176... logprob:  0.608384, 0.255208 (1.407 sec)
4.177... logprob:  0.587932, 0.283854 (1.418 sec)
4.178... logprob:  0.626801, 0.279948 (1.453 sec)
4.179... logprob:  0.634694, 0.294271 (1.402 sec)
4.180... logprob:  0.579369, 0.264323 (1.415 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.406219, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.016904e-03 [3.579613e-07] 
Layer 'conv1' biases: 5.881078e-07 [1.337867e-09] 
Layer 'conv2' weights[0]: 7.004998e-03 [3.552974e-07] 
Layer 'conv2' biases: 9.999997e-01 [1.020208e-08] 
Layer 'conv3' weights[0]: 7.003909e-03 [3.569638e-07] 
Layer 'conv3' biases: 1.279567e-05 [3.670075e-08] 
Layer 'conv4' weights[0]: 7.032189e-03 [3.621178e-07] 
Layer 'conv4' biases: 1.000005e+00 [3.880958e-07] 
Layer 'conv5' weights[0]: 7.045486e-03 [2.616789e-06] 
Layer 'conv5' biases: 9.994810e-01 [2.746758e-06] 
Layer 'fc6' weights[0]: 7.492160e-03 [5.979573e-08] 
Layer 'fc6' biases: 9.999993e-01 [5.408416e-08] 
Layer 'fc7' weights[0]: 7.847244e-03 [1.262401e-07] 
Layer 'fc7' biases: 9.999602e-01 [1.766098e-07] 
Layer 'fc8' weights[0]: 3.450673e-03 [2.243841e-05] 
Layer 'fc8' biases: 5.250625e-03 [4.182973e-05] 
Train error last 800 batches: 0.657183
-------------------------------------------------------
Not saving because 0.406219 > 0.323801 (3.40: -8.65%)
======================================================= (2.368 sec)
4.181... logprob:  0.717497, 0.278646 (1.423 sec)
4.182... logprob:  0.638080, 0.300781 (1.417 sec)
4.183... logprob:  0.625196, 0.257812 (1.412 sec)
4.184... logprob:  0.624457, 0.277344 (1.415 sec)
4.185... logprob:  0.562452, 0.261719 (1.391 sec)
4.186... logprob:  0.583528, 0.270833 (1.391 sec)
4.187... logprob:  0.745190, 0.335938 (1.394 sec)
4.188... logprob:  0.666636, 0.290365 (1.387 sec)
4.189... logprob:  0.699367, 0.295573 (1.379 sec)
4.190... logprob:  0.612643, 0.277344 (1.436 sec)
4.191... logprob:  0.689929, 0.276042 (1.401 sec)
4.192... logprob:  0.743362, 0.312500 (1.410 sec)
4.193... logprob:  0.607880, 0.274739 (1.407 sec)
4.194... logprob:  0.620469, 0.270833 (1.410 sec)
4.195... logprob:  0.560255, 0.243490 (1.396 sec)
4.196... logprob:  0.571246, 0.235677 (1.389 sec)
4.197... logprob:  0.657572, 0.279948 (1.393 sec)
4.198... logprob:  0.617811, 0.266927 (1.397 sec)
4.199... logprob:  0.759120, 0.329427 (1.383 sec)
4.200... logprob:  0.674317, 0.294271 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.429860, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.009917e-03 [3.551624e-07] 
Layer 'conv1' biases: 6.004907e-07 [1.332168e-09] 
Layer 'conv2' weights[0]: 6.998011e-03 [3.532381e-07] 
Layer 'conv2' biases: 9.999997e-01 [8.438620e-09] 
Layer 'conv3' weights[0]: 6.996900e-03 [3.542318e-07] 
Layer 'conv3' biases: 1.283396e-05 [3.271419e-08] 
Layer 'conv4' weights[0]: 7.025154e-03 [3.586776e-07] 
Layer 'conv4' biases: 1.000005e+00 [3.314066e-07] 
Layer 'conv5' weights[0]: 7.038746e-03 [2.315863e-06] 
Layer 'conv5' biases: 9.994780e-01 [2.363855e-06] 
Layer 'fc6' weights[0]: 7.491357e-03 [5.811967e-08] 
Layer 'fc6' biases: 9.999993e-01 [5.178608e-08] 
Layer 'fc7' weights[0]: 7.846454e-03 [1.217846e-07] 
Layer 'fc7' biases: 9.999599e-01 [1.491397e-07] 
Layer 'fc8' weights[0]: 3.470049e-03 [2.006588e-05] 
Layer 'fc8' biases: 5.361600e-03 [2.826712e-05] 
Train error last 800 batches: 0.657479
-------------------------------------------------------
Not saving because 0.429860 > 0.323801 (3.40: -8.65%)
======================================================= (2.369 sec)
4.201... logprob:  0.680612, 0.303385 (1.412 sec)
4.202... logprob:  0.710043, 0.303385 (1.403 sec)
4.203... logprob:  0.673704, 0.298177 (1.441 sec)
4.204... logprob:  0.754320, 0.335937 (1.390 sec)
4.205... logprob:  0.656849, 0.296875 (1.402 sec)
4.206... logprob:  0.597373, 0.273437 (1.392 sec)
4.207... logprob:  0.554123, 0.239583 (1.390 sec)
4.208... logprob:  0.692965, 0.292969 (1.395 sec)
4.209... logprob:  0.542483, 0.256510 (1.413 sec)
4.210... logprob:  0.710245, 0.332031 (1.412 sec)
4.211... logprob:  0.627364, 0.277344 (1.403 sec)
4.212... logprob:  0.731047, 0.316406 (1.407 sec)
4.213... logprob:  0.726048, 0.311198 (1.451 sec)
4.214... logprob:  0.608827, 0.243490 (1.422 sec)
4.215... logprob:  0.622709, 0.290365 (1.407 sec)
4.216... logprob:  0.698037, 0.281250 (1.519 sec)
4.217... logprob:  0.560933, 0.260417 (1.404 sec)
4.218... logprob:  0.714000, 0.304688 (1.412 sec)
4.219... logprob:  0.694464, 0.307292 (1.413 sec)
4.220... logprob:  0.550193, 0.230469 (1.413 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.415275, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 7.002942e-03 [3.548399e-07] 
Layer 'conv1' biases: 6.056374e-07 [1.421893e-09] 
Layer 'conv2' weights[0]: 6.991009e-03 [3.539980e-07] 
Layer 'conv2' biases: 9.999997e-01 [7.662767e-09] 
Layer 'conv3' weights[0]: 6.989903e-03 [3.542087e-07] 
Layer 'conv3' biases: 1.295107e-05 [2.916299e-08] 
Layer 'conv4' weights[0]: 7.018141e-03 [3.586265e-07] 
Layer 'conv4' biases: 1.000005e+00 [2.757198e-07] 
Layer 'conv5' weights[0]: 7.032000e-03 [1.841592e-06] 
Layer 'conv5' biases: 9.994759e-01 [1.897849e-06] 
Layer 'fc6' weights[0]: 7.490560e-03 [5.473710e-08] 
Layer 'fc6' biases: 9.999993e-01 [4.636945e-08] 
Layer 'fc7' weights[0]: 7.845710e-03 [1.119022e-07] 
Layer 'fc7' biases: 9.999585e-01 [1.172587e-07] 
Layer 'fc8' weights[0]: 3.440735e-03 [1.640153e-05] 
Layer 'fc8' biases: 5.216490e-03 [1.175029e-05] 
Train error last 800 batches: 0.657289
-------------------------------------------------------
Not saving because 0.415275 > 0.323801 (3.40: -8.65%)
======================================================= (2.422 sec)
4.221... logprob:  0.633594, 0.277344 (1.419 sec)
4.222... logprob:  0.715359, 0.295573 (1.461 sec)
4.223... logprob:  0.777624, 0.332031 (1.434 sec)
4.224... logprob:  0.605283, 0.289062 (1.431 sec)
4.225... logprob:  0.679596, 0.295573 (1.440 sec)
4.226... logprob:  0.648080, 0.277344 (1.416 sec)
4.227... logprob:  0.704012, 0.309896 (1.407 sec)
4.228... logprob:  0.528695, 0.265625 (1.410 sec)
4.229... logprob:  0.778945, 0.312500 (1.410 sec)
4.230... logprob:  0.753486, 0.321615 (1.415 sec)
4.231... logprob:  0.640942, 0.282552 (1.397 sec)
4.232... logprob:  0.726134, 0.308594 (1.455 sec)
4.233... logprob:  0.676753, 0.266927 (1.418 sec)
4.234... logprob:  0.798423, 0.341146 (1.412 sec)
4.235... logprob:  0.655176, 0.282552 (1.461 sec)
4.236... logprob:  0.701490, 0.290365 (1.394 sec)
4.237... logprob:  0.649559, 0.316406 (1.415 sec)
4.238... logprob:  0.648430, 0.298177 (1.409 sec)
4.239... logprob:  0.623998, 0.257812 (1.413 sec)
4.240... logprob:  0.675251, 0.283854 (1.395 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.517855, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.995952e-03 [3.580917e-07] 
Layer 'conv1' biases: 6.063112e-07 [1.506051e-09] 
Layer 'conv2' weights[0]: 6.984043e-03 [3.536154e-07] 
Layer 'conv2' biases: 9.999997e-01 [8.173801e-09] 
Layer 'conv3' weights[0]: 6.982924e-03 [3.536186e-07] 
Layer 'conv3' biases: 1.299747e-05 [2.923713e-08] 
Layer 'conv4' weights[0]: 7.011115e-03 [3.570444e-07] 
Layer 'conv4' biases: 1.000006e+00 [2.961833e-07] 
Layer 'conv5' weights[0]: 7.025407e-03 [2.077684e-06] 
Layer 'conv5' biases: 9.994751e-01 [2.143408e-06] 
Layer 'fc6' weights[0]: 7.489788e-03 [5.784497e-08] 
Layer 'fc6' biases: 9.999993e-01 [5.129653e-08] 
Layer 'fc7' weights[0]: 7.844951e-03 [1.199903e-07] 
Layer 'fc7' biases: 9.999584e-01 [1.374133e-07] 
Layer 'fc8' weights[0]: 3.407129e-03 [1.915763e-05] 
Layer 'fc8' biases: 4.943638e-03 [1.850970e-05] 
Train error last 800 batches: 0.657754
-------------------------------------------------------
Not saving because 0.517855 > 0.323801 (3.40: -8.65%)
======================================================= (2.374 sec)
4.241... logprob:  0.759106, 0.346354 (1.460 sec)
4.242... logprob:  0.586258, 0.260417 (1.428 sec)
4.243... logprob:  0.693964, 0.276042 (1.428 sec)
4.244... logprob:  0.533393, 0.221354 (1.450 sec)
4.245... logprob:  0.700565, 0.292969 (1.427 sec)
4.246... logprob:  0.581406, 0.263021 (1.413 sec)
4.247... logprob:  0.611933, 0.242187 (1.409 sec)
4.248... logprob:  0.468692, 0.205729 (1.414 sec)
4.249... logprob:  0.738551, 0.322917 (1.450 sec)
4.250... logprob:  0.781962, 0.311198 (1.401 sec)
4.251... logprob:  0.590888, 0.269531 (1.450 sec)
4.252... logprob:  0.581158, 0.257812 (1.421 sec)
4.253... logprob:  0.605123, 0.257812 (1.408 sec)
4.254... logprob:  0.642462, 0.282552 (1.461 sec)
4.255... logprob:  0.661296, 0.290365 (1.399 sec)
4.256... logprob:  0.578407, 0.248698 (1.415 sec)
4.257... logprob:  0.595944, 0.270833 (1.411 sec)
4.258... logprob:  0.576754, 0.278646 (1.419 sec)
4.259... logprob:  0.719807, 0.326823 (1.394 sec)
4.260... logprob:  0.591445, 0.276042 (1.453 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.457505, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.988978e-03 [3.557164e-07] 
Layer 'conv1' biases: 6.079259e-07 [1.090782e-09] 
Layer 'conv2' weights[0]: 6.977057e-03 [3.528478e-07] 
Layer 'conv2' biases: 9.999998e-01 [6.031663e-09] 
Layer 'conv3' weights[0]: 6.975915e-03 [3.521456e-07] 
Layer 'conv3' biases: 1.301005e-05 [2.455744e-08] 
Layer 'conv4' weights[0]: 7.004099e-03 [3.557220e-07] 
Layer 'conv4' biases: 1.000005e+00 [2.636032e-07] 
Layer 'conv5' weights[0]: 7.017752e-03 [1.892407e-06] 
Layer 'conv5' biases: 9.994681e-01 [2.025932e-06] 
Layer 'fc6' weights[0]: 7.489011e-03 [5.312046e-08] 
Layer 'fc6' biases: 9.999993e-01 [4.412353e-08] 
Layer 'fc7' weights[0]: 7.844121e-03 [1.081874e-07] 
Layer 'fc7' biases: 9.999594e-01 [1.169435e-07] 
Layer 'fc8' weights[0]: 3.515593e-03 [1.597018e-05] 
Layer 'fc8' biases: 5.620931e-03 [1.451896e-05] 
Train error last 800 batches: 0.657838
-------------------------------------------------------
Not saving because 0.457505 > 0.323801 (3.40: -8.65%)
======================================================= (2.403 sec)
4.261... logprob:  0.695827, 0.319010 (1.438 sec)
4.262... logprob:  0.761821, 0.296875 (1.429 sec)
4.263... logprob:  0.651883, 0.251302 (1.449 sec)
4.264... logprob:  0.610278, 0.286458 (1.422 sec)
4.265... logprob:  0.586428, 0.257812 (1.412 sec)
4.266... logprob:  0.526862, 0.257812 (1.414 sec)
4.267... logprob:  0.632756, 0.294271 (1.410 sec)
4.268... logprob:  0.628219, 0.277344 (1.418 sec)
4.269... logprob:  0.702448, 0.348958 (1.401 sec)
4.270... logprob:  0.810333, 0.309896 (1.457 sec)
4.271... logprob:  0.677819, 0.311198 (1.418 sec)
4.272... logprob:  0.615821, 0.251302 (1.409 sec)
4.273... logprob:  0.749457, 0.304688 (1.460 sec)
4.274... logprob:  0.782426, 0.352865 (1.397 sec)
4.275... logprob:  0.676941, 0.274740 (1.413 sec)
4.276... logprob:  0.577014, 0.268229 (1.412 sec)
4.277... logprob:  0.627654, 0.268229 (1.426 sec)
4.278... logprob:  0.570277, 0.243490 (1.421 sec)
4.279... logprob:  0.572384, 0.263021 (1.457 sec)
4.280... logprob:  0.503108, 0.238281 (1.395 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.555843, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.981954e-03 [3.561091e-07] 
Layer 'conv1' biases: 6.126309e-07 [1.490646e-09] 
Layer 'conv2' weights[0]: 6.970054e-03 [3.528349e-07] 
Layer 'conv2' biases: 9.999997e-01 [8.536039e-09] 
Layer 'conv3' weights[0]: 6.968943e-03 [3.525560e-07] 
Layer 'conv3' biases: 1.312443e-05 [2.849488e-08] 
Layer 'conv4' weights[0]: 6.997072e-03 [3.568197e-07] 
Layer 'conv4' biases: 1.000007e+00 [3.009854e-07] 
Layer 'conv5' weights[0]: 7.011637e-03 [2.036686e-06] 
Layer 'conv5' biases: 9.994656e-01 [2.120165e-06] 
Layer 'fc6' weights[0]: 7.488236e-03 [5.618425e-08] 
Layer 'fc6' biases: 9.999992e-01 [4.866655e-08] 
Layer 'fc7' weights[0]: 7.843370e-03 [1.180310e-07] 
Layer 'fc7' biases: 9.999571e-01 [1.530858e-07] 
Layer 'fc8' weights[0]: 3.435892e-03 [1.940159e-05] 
Layer 'fc8' biases: 5.163946e-03 [3.251766e-05] 
Train error last 800 batches: 0.657470
-------------------------------------------------------
Not saving because 0.555843 > 0.323801 (3.40: -8.65%)
======================================================= (2.394 sec)
4.281... logprob:  0.674166, 0.295573 (1.429 sec)
4.282... logprob:  0.686635, 0.313802 (1.419 sec)
4.283... logprob:  0.642154, 0.286458 (1.416 sec)
4.284... logprob:  0.589068, 0.264323 (1.410 sec)
4.285... logprob:  0.647165, 0.269531 (1.435 sec)
4.286... logprob:  0.698933, 0.330729 (1.427 sec)
4.287... logprob:  0.566663, 0.250000 (1.427 sec)
4.288... logprob:  0.607781, 0.278646 (1.436 sec)
4.289... logprob:  0.700989, 0.300781 (1.437 sec)
4.290... logprob:  0.710531, 0.302083 (1.398 sec)
4.291... logprob:  0.702101, 0.298177 (1.412 sec)
4.292... logprob:  0.776818, 0.317708 (1.411 sec)
4.293... logprob:  0.704026, 0.296875 (1.416 sec)
4.294... logprob:  0.594907, 0.274740 (1.397 sec)
4.295... logprob:  0.523307, 0.239583 (1.458 sec)
4.296... logprob:  0.659126, 0.304687 (1.484 sec)
4.297... logprob:  0.701712, 0.304687 (1.420 sec)
4.298... logprob:  0.720901, 0.289062 (1.457 sec)
4.299... logprob:  0.634087, 0.281250 (1.394 sec)
4.300... logprob:  0.656056, 0.308594 (1.414 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.416650, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.974983e-03 [3.547773e-07] 
Layer 'conv1' biases: 6.188396e-07 [9.592410e-10] 
Layer 'conv2' weights[0]: 6.963096e-03 [3.531413e-07] 
Layer 'conv2' biases: 9.999997e-01 [8.908952e-09] 
Layer 'conv3' weights[0]: 6.962003e-03 [3.535389e-07] 
Layer 'conv3' biases: 1.319592e-05 [3.473279e-08] 
Layer 'conv4' weights[0]: 6.990059e-03 [3.597492e-07] 
Layer 'conv4' biases: 1.000008e+00 [3.904774e-07] 
Layer 'conv5' weights[0]: 7.005466e-03 [2.248306e-06] 
Layer 'conv5' biases: 9.994609e-01 [2.426923e-06] 
Layer 'fc6' weights[0]: 7.487450e-03 [5.608735e-08] 
Layer 'fc6' biases: 9.999993e-01 [4.871068e-08] 
Layer 'fc7' weights[0]: 7.842612e-03 [1.172554e-07] 
Layer 'fc7' biases: 9.999574e-01 [1.351666e-07] 
Layer 'fc8' weights[0]: 3.493411e-03 [1.886775e-05] 
Layer 'fc8' biases: 5.398318e-03 [2.572580e-05] 
Train error last 800 batches: 0.658119
-------------------------------------------------------
Not saving because 0.416650 > 0.323801 (3.40: -8.65%)
======================================================= (2.376 sec)
4.301... logprob:  0.645198, 0.285156 (1.427 sec)
4.302... logprob:  0.816518, 0.333333 (1.416 sec)
4.303... logprob:  0.708310, 0.300781 (1.411 sec)
4.304... logprob:  0.662866, 0.269531 (1.437 sec)
4.305... logprob:  0.645656, 0.248698 (1.432 sec)
4.306... logprob:  0.648002, 0.296875 (1.426 sec)
4.307... logprob:  0.592619, 0.270833 (1.436 sec)
4.308... logprob:  0.573692, 0.255208 (1.444 sec)
4.309... logprob:  0.747585, 0.322917 (1.411 sec)
4.310... logprob:  0.664176, 0.299479 (1.420 sec)
4.311... logprob:  0.667368, 0.282552 (1.428 sec)
4.312... logprob:  0.593343, 0.268229 (1.427 sec)
4.313... logprob:  0.638212, 0.276042 (1.418 sec)
4.314... logprob:  0.694009, 0.312500 (1.456 sec)
4.315... logprob:  0.569876, 0.234375 (1.425 sec)
4.316... logprob:  0.689031, 0.276042 (1.419 sec)
4.317... logprob:  0.573409, 0.255208 (1.480 sec)
4.318... logprob:  0.636406, 0.276042 (1.407 sec)
4.319... logprob:  0.540528, 0.243490 (1.414 sec)
4.320... logprob:  0.612872, 0.268229 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.371644, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.968031e-03 [3.542397e-07] 
Layer 'conv1' biases: 6.139805e-07 [1.432605e-09] 
Layer 'conv2' weights[0]: 6.956108e-03 [3.517948e-07] 
Layer 'conv2' biases: 9.999997e-01 [8.852549e-09] 
Layer 'conv3' weights[0]: 6.954994e-03 [3.531599e-07] 
Layer 'conv3' biases: 1.327303e-05 [3.130086e-08] 
Layer 'conv4' weights[0]: 6.983112e-03 [3.580936e-07] 
Layer 'conv4' biases: 1.000011e+00 [3.297527e-07] 
Layer 'conv5' weights[0]: 6.999665e-03 [2.449738e-06] 
Layer 'conv5' biases: 9.994521e-01 [2.591014e-06] 
Layer 'fc6' weights[0]: 7.486653e-03 [5.899823e-08] 
Layer 'fc6' biases: 9.999992e-01 [5.334478e-08] 
Layer 'fc7' weights[0]: 7.841830e-03 [1.245160e-07] 
Layer 'fc7' biases: 9.999571e-01 [1.643616e-07] 
Layer 'fc8' weights[0]: 3.482700e-03 [2.109872e-05] 
Layer 'fc8' biases: 5.348552e-03 [3.752027e-05] 
Train error last 800 batches: 0.657428
-------------------------------------------------------
Not saving because 0.371644 > 0.323801 (3.40: -8.65%)
======================================================= (2.369 sec)
4.321... logprob:  0.560868, 0.251302 (1.425 sec)
4.322... logprob:  0.530889, 0.261719 (1.418 sec)
4.323... logprob:  0.583135, 0.260417 (1.479 sec)
4.324... logprob:  0.612421, 0.272135 (1.417 sec)
4.325... logprob:  0.578914, 0.270833 (1.429 sec)
4.326... logprob:  0.692274, 0.300781 (1.480 sec)
4.327... logprob:  0.812834, 0.373698 (1.419 sec)
4.328... logprob:  0.709282, 0.268229 (1.422 sec)
4.329... logprob:  0.641154, 0.269531 (1.420 sec)
4.330... logprob:  0.663518, 0.292969 (1.412 sec)
4.331... logprob:  0.549902, 0.266927 (1.414 sec)
4.332... logprob:  0.735717, 0.304687 (1.441 sec)
4.333... logprob:  0.589977, 0.260417 (1.439 sec)
4.334... logprob:  0.756634, 0.315104 (1.432 sec)
4.335... logprob:  0.636441, 0.295573 (1.434 sec)
4.336... logprob:  0.688449, 0.298177 (1.450 sec)
4.337... logprob:  0.732296, 0.298177 (1.410 sec)
4.338... logprob:  0.611727, 0.295573 (1.415 sec)
4.339... logprob:  0.709410, 0.298177 (1.417 sec)
4.340... logprob:  0.657827, 0.277344 (1.422 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.505122, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.961024e-03 [3.564637e-07] 
Layer 'conv1' biases: 6.149124e-07 [1.247055e-09] 
Layer 'conv2' weights[0]: 6.949146e-03 [3.522010e-07] 
Layer 'conv2' biases: 9.999997e-01 [9.110108e-09] 
Layer 'conv3' weights[0]: 6.947989e-03 [3.536370e-07] 
Layer 'conv3' biases: 1.333384e-05 [3.636810e-08] 
Layer 'conv4' weights[0]: 6.976149e-03 [3.598370e-07] 
Layer 'conv4' biases: 1.000011e+00 [4.243853e-07] 
Layer 'conv5' weights[0]: 6.992813e-03 [2.734227e-06] 
Layer 'conv5' biases: 9.994490e-01 [2.989428e-06] 
Layer 'fc6' weights[0]: 7.485864e-03 [6.401063e-08] 
Layer 'fc6' biases: 9.999992e-01 [6.035784e-08] 
Layer 'fc7' weights[0]: 7.841086e-03 [1.388935e-07] 
Layer 'fc7' biases: 9.999566e-01 [1.969896e-07] 
Layer 'fc8' weights[0]: 3.482626e-03 [2.255479e-05] 
Layer 'fc8' biases: 5.360460e-03 [3.849307e-05] 
Train error last 800 batches: 0.657230
-------------------------------------------------------
Not saving because 0.505122 > 0.323801 (3.40: -8.65%)
======================================================= (2.354 sec)
4.341... logprob:  0.734444, 0.315104 (1.428 sec)
4.342... logprob:  0.637521, 0.270833 (1.466 sec)
4.343... logprob:  0.670195, 0.268229 (1.437 sec)
4.344... logprob:  0.645764, 0.298177 (1.479 sec)
4.345... logprob:  0.704210, 0.326823 (1.439 sec)
4.346... logprob:  0.625383, 0.281250 (1.430 sec)
4.347... logprob:  0.594555, 0.238281 (1.475 sec)
4.348... logprob:  0.584820, 0.269531 (1.427 sec)
4.349... logprob:  0.654750, 0.282552 (1.426 sec)
4.350... logprob:  0.628787, 0.282552 (1.429 sec)
4.351... logprob:  0.767425, 0.348958 (1.423 sec)
4.352... logprob:  0.584795, 0.274740 (1.426 sec)
4.353... logprob:  0.700177, 0.334635 (1.484 sec)
4.354... logprob:  0.802327, 0.338542 (1.426 sec)
4.355... logprob:  0.599709, 0.270833 (1.439 sec)
4.356... logprob:  0.755393, 0.325521 (1.468 sec)
4.357... logprob:  0.614985, 0.283854 (1.426 sec)
4.358... logprob:  0.563886, 0.246094 (1.434 sec)
4.359... logprob:  0.728820, 0.330729 (1.427 sec)
4.360... logprob:  0.568840, 0.246094 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.475000, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.954059e-03 [3.537387e-07] 
Layer 'conv1' biases: 6.219783e-07 [1.081022e-09] 
Layer 'conv2' weights[0]: 6.942229e-03 [3.503800e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.521133e-09] 
Layer 'conv3' weights[0]: 6.941099e-03 [3.513238e-07] 
Layer 'conv3' biases: 1.341948e-05 [2.933870e-08] 
Layer 'conv4' weights[0]: 6.969214e-03 [3.558590e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.010854e-07] 
Layer 'conv5' weights[0]: 6.986549e-03 [2.073576e-06] 
Layer 'conv5' biases: 9.994408e-01 [2.143402e-06] 
Layer 'fc6' weights[0]: 7.485072e-03 [5.705458e-08] 
Layer 'fc6' biases: 9.999992e-01 [5.073384e-08] 
Layer 'fc7' weights[0]: 7.840286e-03 [1.192418e-07] 
Layer 'fc7' biases: 9.999560e-01 [1.437411e-07] 
Layer 'fc8' weights[0]: 3.476168e-03 [2.034116e-05] 
Layer 'fc8' biases: 5.337697e-03 [2.893342e-05] 
Train error last 800 batches: 0.657329
-------------------------------------------------------
Not saving because 0.475000 > 0.323801 (3.40: -8.65%)
======================================================= (2.370 sec)
4.361... logprob:  0.696588, 0.292969 (1.435 sec)
4.362... logprob:  0.630572, 0.303385 (1.478 sec)
4.363... logprob:  0.725741, 0.309896 (1.442 sec)
4.364... logprob:  0.679227, 0.316406 (1.486 sec)
4.365... logprob:  0.598227, 0.256510 (1.468 sec)
4.366... logprob:  0.706808, 0.311198 (1.444 sec)
4.367... logprob:  0.592703, 0.307292 (1.431 sec)
4.368... logprob:  0.866867, 0.312500 (1.423 sec)
4.369... logprob:  0.614082, 0.273438 (1.417 sec)
4.370... logprob:  0.618426, 0.270833 (1.431 sec)
4.371... logprob:  0.674907, 0.303385 (1.456 sec)
4.372... logprob:  0.742378, 0.308594 (1.443 sec)
4.373... logprob:  0.694732, 0.286458 (1.451 sec)
4.374... logprob:  0.692254, 0.304687 (1.443 sec)
4.375... logprob:  0.662008, 0.290365 (1.457 sec)
4.376... logprob:  0.551164, 0.257812 (1.434 sec)
4.377... logprob:  0.648555, 0.296875 (1.426 sec)
4.378... logprob:  0.593159, 0.264323 (1.424 sec)
4.379... logprob:  0.697209, 0.294271 (1.432 sec)
4.380... logprob:  0.811355, 0.346354 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.435136, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.947134e-03 [3.533318e-07] 
Layer 'conv1' biases: 6.235740e-07 [1.633874e-09] 
Layer 'conv2' weights[0]: 6.935267e-03 [3.516356e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.068398e-09] 
Layer 'conv3' weights[0]: 6.934165e-03 [3.516673e-07] 
Layer 'conv3' biases: 1.351798e-05 [3.343443e-08] 
Layer 'conv4' weights[0]: 6.962191e-03 [3.552969e-07] 
Layer 'conv4' biases: 1.000014e+00 [3.305588e-07] 
Layer 'conv5' weights[0]: 6.979796e-03 [2.400237e-06] 
Layer 'conv5' biases: 9.994418e-01 [2.517087e-06] 
Layer 'fc6' weights[0]: 7.484308e-03 [5.656489e-08] 
Layer 'fc6' biases: 9.999992e-01 [4.972369e-08] 
Layer 'fc7' weights[0]: 7.839521e-03 [1.186225e-07] 
Layer 'fc7' biases: 9.999547e-01 [1.289768e-07] 
Layer 'fc8' weights[0]: 3.452575e-03 [1.746028e-05] 
Layer 'fc8' biases: 5.214655e-03 [9.250425e-06] 
Train error last 800 batches: 0.657674
-------------------------------------------------------
Not saving because 0.435136 > 0.323801 (3.40: -8.65%)
======================================================= (2.382 sec)
4.381... logprob:  0.673678, 0.283854 (1.469 sec)
4.382... logprob:  0.766862, 0.341146 (1.457 sec)
4.383... logprob:  0.603787, 0.276042 (1.437 sec)
4.384... logprob:  0.815952, 0.372396 (1.481 sec)
4.385... logprob:  0.635597, 0.276042 (1.435 sec)
4.386... logprob:  0.765987, 0.325521 (1.430 sec)
4.387... logprob:  0.636402, 0.302083 (1.432 sec)
4.388... logprob:  0.711911, 0.305990 (1.429 sec)
4.389... logprob:  0.703832, 0.320312 (1.426 sec)
4.390... logprob:  0.598955, 0.257812 (1.475 sec)
4.391... logprob:  0.558906, 0.252604 (1.436 sec)
4.392... logprob:  0.677487, 0.274740 (1.429 sec)
4.393... logprob:  0.592578, 0.225260 (1.477 sec)
4.394... logprob:  0.620208, 0.283854 (1.430 sec)
4.395... logprob:  0.518904, 0.235677 (1.421 sec)
4.396... logprob:  0.562130, 0.265625 (1.431 sec)
4.397... logprob:  0.563371, 0.272135 (1.427 sec)
4.398... logprob:  0.637626, 0.278646 (1.423 sec)
4.399... logprob:  0.643834, 0.294271 (1.480 sec)
4.400... logprob:  0.738683, 0.309896 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.423856, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.940152e-03 [3.548945e-07] 
Layer 'conv1' biases: 6.267212e-07 [1.635141e-09] 
Layer 'conv2' weights[0]: 6.928364e-03 [3.514850e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.106978e-08] 
Layer 'conv3' weights[0]: 6.927216e-03 [3.546166e-07] 
Layer 'conv3' biases: 1.350354e-05 [4.109126e-08] 
Layer 'conv4' weights[0]: 6.955232e-03 [3.603698e-07] 
Layer 'conv4' biases: 1.000012e+00 [4.237565e-07] 
Layer 'conv5' weights[0]: 6.972252e-03 [2.824350e-06] 
Layer 'conv5' biases: 9.994360e-01 [3.035475e-06] 
Layer 'fc6' weights[0]: 7.483508e-03 [6.240760e-08] 
Layer 'fc6' biases: 9.999992e-01 [5.857795e-08] 
Layer 'fc7' weights[0]: 7.838761e-03 [1.391280e-07] 
Layer 'fc7' biases: 9.999565e-01 [2.089143e-07] 
Layer 'fc8' weights[0]: 3.552091e-03 [2.506058e-05] 
Layer 'fc8' biases: 5.654320e-03 [5.104775e-05] 
Train error last 800 batches: 0.657552
-------------------------------------------------------
Not saving because 0.423856 > 0.323801 (3.40: -8.65%)
======================================================= (2.399 sec)
4.401... logprob:  0.713797, 0.324219 (1.442 sec)
4.402... logprob:  0.643503, 0.294271 (1.519 sec)
4.403... logprob:  0.699349, 0.335937 (1.432 sec)
4.404... logprob:  0.675738, 0.294271 (1.434 sec)
4.405... logprob:  0.739982, 0.309896 (1.440 sec)
4.406... logprob:  0.643324, 0.286458 (1.425 sec)
4.407... logprob:  0.717184, 0.286458 (1.428 sec)
4.408... logprob:  0.634371, 0.303385 (1.472 sec)
4.409... logprob:  0.547908, 0.255208 (1.431 sec)
4.410... logprob:  0.789456, 0.322917 (1.443 sec)
4.411... logprob:  0.606770, 0.287760 (1.467 sec)
4.412... logprob:  0.762505, 0.329427 (1.431 sec)
4.413... logprob:  0.661898, 0.299479 (1.433 sec)
4.414... logprob:  0.715923, 0.320313 (1.425 sec)
4.415... logprob:  0.624263, 0.265625 (1.417 sec)
4.416... logprob:  0.605605, 0.270833 (1.432 sec)
4.417... logprob:  0.571119, 0.242187 (1.455 sec)
4.418... logprob:  0.661314, 0.263021 (1.444 sec)
4.419... logprob:  0.635086, 0.263021 (1.452 sec)
4.420... logprob:  0.642336, 0.303385 (1.446 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.380968, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.933239e-03 [3.529446e-07] 
Layer 'conv1' biases: 6.266037e-07 [1.539314e-09] 
Layer 'conv2' weights[0]: 6.921392e-03 [3.514319e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.028389e-08] 
Layer 'conv3' weights[0]: 6.920257e-03 [3.535095e-07] 
Layer 'conv3' biases: 1.364437e-05 [3.923476e-08] 
Layer 'conv4' weights[0]: 6.948257e-03 [3.596552e-07] 
Layer 'conv4' biases: 1.000013e+00 [4.412904e-07] 
Layer 'conv5' weights[0]: 6.965760e-03 [2.517695e-06] 
Layer 'conv5' biases: 9.994326e-01 [2.681267e-06] 
Layer 'fc6' weights[0]: 7.482732e-03 [5.860858e-08] 
Layer 'fc6' biases: 9.999992e-01 [5.322072e-08] 
Layer 'fc7' weights[0]: 7.838042e-03 [1.285407e-07] 
Layer 'fc7' biases: 9.999550e-01 [1.719208e-07] 
Layer 'fc8' weights[0]: 3.490484e-03 [2.555441e-05] 
Layer 'fc8' biases: 5.354657e-03 [4.445718e-05] 
Train error last 800 batches: 0.657485
-------------------------------------------------------
Not saving because 0.380968 > 0.323801 (3.40: -8.65%)
======================================================= (2.381 sec)
4.421... logprob:  0.613527, 0.281250 (1.460 sec)
4.422... logprob:  0.725221, 0.291667 (1.438 sec)
4.423... logprob:  0.624195, 0.282552 (1.427 sec)
4.424... logprob:  0.568937, 0.255208 (1.427 sec)
4.425... logprob:  0.517585, 0.247396 (1.433 sec)
4.426... logprob:  0.625255, 0.278646 (1.440 sec)
4.427... logprob:  0.681181, 0.303385 (1.465 sec)
4.428... logprob:  0.726766, 0.315104 (1.460 sec)
4.429... logprob:  0.622397, 0.283854 (1.437 sec)
4.430... logprob:  0.554623, 0.248698 (1.469 sec)
4.431... logprob:  0.706934, 0.291667 (1.427 sec)
4.432... logprob:  0.665547, 0.286458 (1.422 sec)
4.433... logprob:  0.583673, 0.248698 (1.423 sec)
4.434... logprob:  0.703136, 0.317708 (1.432 sec)
4.435... logprob:  0.709468, 0.311198 (1.428 sec)
4.436... logprob:  0.585814, 0.251302 (1.467 sec)
4.437... logprob:  0.668334, 0.312500 (1.442 sec)
4.438... logprob:  0.738490, 0.307292 (1.425 sec)
4.439... logprob:  0.600519, 0.273437 (1.481 sec)
4.440... logprob:  0.686887, 0.311198 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.555626, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.926316e-03 [3.508992e-07] 
Layer 'conv1' biases: 6.285868e-07 [1.415334e-09] 
Layer 'conv2' weights[0]: 6.914509e-03 [3.494165e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.645033e-09] 
Layer 'conv3' weights[0]: 6.913343e-03 [3.492304e-07] 
Layer 'conv3' biases: 1.378962e-05 [2.968565e-08] 
Layer 'conv4' weights[0]: 6.941327e-03 [3.539820e-07] 
Layer 'conv4' biases: 1.000014e+00 [3.278794e-07] 
Layer 'conv5' weights[0]: 6.959080e-03 [2.143945e-06] 
Layer 'conv5' biases: 9.994310e-01 [2.361448e-06] 
Layer 'fc6' weights[0]: 7.481976e-03 [5.708443e-08] 
Layer 'fc6' biases: 9.999992e-01 [5.081085e-08] 
Layer 'fc7' weights[0]: 7.837209e-03 [1.209102e-07] 
Layer 'fc7' biases: 9.999545e-01 [1.474698e-07] 
Layer 'fc8' weights[0]: 3.493393e-03 [1.856281e-05] 
Layer 'fc8' biases: 5.338742e-03 [2.602047e-05] 
Train error last 800 batches: 0.656839
-------------------------------------------------------
Not saving because 0.555626 > 0.323801 (3.40: -8.65%)
======================================================= (2.384 sec)
4.441... logprob:  0.774313, 0.373698 (1.432 sec)
4.442... logprob:  0.569611, 0.240885 (1.438 sec)
4.443... logprob:  0.756453, 0.350260 (1.431 sec)
4.444... logprob:  0.715545, 0.322917 (1.426 sec)
4.445... logprob:  0.653981, 0.298177 (1.480 sec)
4.446... logprob:  0.620060, 0.272135 (1.436 sec)
4.447... logprob:  0.660986, 0.290365 (1.436 sec)
4.448... logprob:  0.568592, 0.244792 (1.476 sec)
4.449... logprob:  0.637912, 0.299479 (1.432 sec)
4.450... logprob:  0.480327, 0.214844 (1.424 sec)
4.451... logprob:  0.714187, 0.324219 (1.434 sec)
4.452... logprob:  0.653458, 0.282552 (1.428 sec)
4.453... logprob:  0.636826, 0.299479 (1.426 sec)
4.454... logprob:  0.730167, 0.332031 (1.476 sec)
4.455... logprob:  0.716341, 0.298177 (1.430 sec)
4.456... logprob:  0.658969, 0.261719 (1.442 sec)
4.457... logprob:  0.616723, 0.281250 (1.471 sec)
4.458... logprob:  0.621270, 0.266927 (1.425 sec)
4.459... logprob:  0.706958, 0.298177 (1.434 sec)
4.460... logprob:  0.542775, 0.247396 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.450452, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.919379e-03 [3.526840e-07] 
Layer 'conv1' biases: 6.328748e-07 [1.561462e-09] 
Layer 'conv2' weights[0]: 6.907604e-03 [3.490423e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.074116e-09] 
Layer 'conv3' weights[0]: 6.906453e-03 [3.499911e-07] 
Layer 'conv3' biases: 1.382068e-05 [3.086001e-08] 
Layer 'conv4' weights[0]: 6.934394e-03 [3.554691e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.460589e-07] 
Layer 'conv5' weights[0]: 6.952067e-03 [2.344747e-06] 
Layer 'conv5' biases: 9.994299e-01 [2.562472e-06] 
Layer 'fc6' weights[0]: 7.481192e-03 [5.833452e-08] 
Layer 'fc6' biases: 9.999992e-01 [5.257889e-08] 
Layer 'fc7' weights[0]: 7.836459e-03 [1.242780e-07] 
Layer 'fc7' biases: 9.999545e-01 [1.623305e-07] 
Layer 'fc8' weights[0]: 3.537278e-03 [2.014020e-05] 
Layer 'fc8' biases: 5.510553e-03 [3.144698e-05] 
Train error last 800 batches: 0.657100
-------------------------------------------------------
Not saving because 0.450452 > 0.323801 (3.40: -8.65%)
======================================================= (2.400 sec)
4.461... logprob:  0.635808, 0.261719 (1.434 sec)
4.462... logprob:  0.660648, 0.292969 (1.435 sec)
4.463... logprob:  0.574047, 0.248698 (1.470 sec)
4.464... logprob:  0.677413, 0.298177 (1.442 sec)
4.465... logprob:  0.652053, 0.274740 (1.454 sec)
4.466... logprob:  0.534213, 0.234375 (1.460 sec)
4.467... logprob:  0.721735, 0.307292 (1.443 sec)
4.468... logprob:  0.686379, 0.302083 (1.439 sec)
4.469... logprob:  0.562258, 0.231771 (1.422 sec)
4.470... logprob:  0.683520, 0.321615 (1.415 sec)
4.471... logprob:  0.759129, 0.320312 (1.437 sec)
4.472... logprob:  0.664484, 0.325521 (1.446 sec)
4.473... logprob:  0.591075, 0.259115 (1.451 sec)
4.474... logprob:  0.619677, 0.283854 (1.449 sec)
4.475... logprob:  0.640166, 0.259115 (1.444 sec)
4.476... logprob:  0.748650, 0.321615 (1.460 sec)
4.477... logprob:  0.587719, 0.272135 (1.431 sec)
4.478... logprob:  0.655973, 0.311198 (1.418 sec)
4.479... logprob:  0.486703, 0.227865 (1.427 sec)
4.480... logprob:  0.701728, 0.303385 (1.455 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.383914, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.912469e-03 [3.508295e-07] 
Layer 'conv1' biases: 6.401409e-07 [1.276020e-09] 
Layer 'conv2' weights[0]: 6.900685e-03 [3.480136e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.382363e-09] 
Layer 'conv3' weights[0]: 6.899588e-03 [3.485500e-07] 
Layer 'conv3' biases: 1.398752e-05 [2.708854e-08] 
Layer 'conv4' weights[0]: 6.927458e-03 [3.515914e-07] 
Layer 'conv4' biases: 1.000014e+00 [2.824891e-07] 
Layer 'conv5' weights[0]: 6.945414e-03 [1.811397e-06] 
Layer 'conv5' biases: 9.994307e-01 [1.933728e-06] 
Layer 'fc6' weights[0]: 7.480386e-03 [5.307182e-08] 
Layer 'fc6' biases: 9.999991e-01 [4.436000e-08] 
Layer 'fc7' weights[0]: 7.835673e-03 [1.090375e-07] 
Layer 'fc7' biases: 9.999539e-01 [1.143951e-07] 
Layer 'fc8' weights[0]: 3.526712e-03 [1.554775e-05] 
Layer 'fc8' biases: 5.514410e-03 [9.627984e-06] 
Train error last 800 batches: 0.656566
-------------------------------------------------------
Not saving because 0.383914 > 0.323801 (3.40: -8.65%)
======================================================= (2.384 sec)
4.481... logprob:  0.649028, 0.300781 (1.444 sec)
4.482... logprob:  0.623797, 0.268229 (1.474 sec)
4.483... logprob:  0.778153, 0.302083 (1.448 sec)
4.484... logprob:  0.667551, 0.274740 (1.436 sec)
4.485... logprob:  0.673036, 0.294271 (1.480 sec)
4.486... logprob:  0.647921, 0.294271 (1.433 sec)
4.487... logprob:  0.692118, 0.283854 (1.419 sec)
4.488... logprob:  0.639006, 0.263021 (1.429 sec)
4.489... logprob:  0.671918, 0.300781 (1.427 sec)
4.490... logprob:  0.619322, 0.279948 (1.428 sec)
4.491... logprob:  0.634701, 0.285156 (1.476 sec)
4.492... logprob:  0.761234, 0.335937 (1.440 sec)
4.493... logprob:  0.738910, 0.291667 (1.433 sec)
4.494... logprob:  0.692935, 0.322917 (1.490 sec)
4.495... logprob:  0.612127, 0.286458 (1.424 sec)
4.496... logprob:  0.800808, 0.334635 (1.430 sec)
4.497... logprob:  0.658518, 0.281250 (1.425 sec)
4.498... logprob:  0.736800, 0.311198 (1.426 sec)
4.499... logprob:  0.637390, 0.305990 (1.427 sec)
4.500... logprob:  0.666707, 0.298177 (1.483 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.458972, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.905593e-03 [3.519302e-07] 
Layer 'conv1' biases: 6.458674e-07 [1.419295e-09] 
Layer 'conv2' weights[0]: 6.893824e-03 [3.486615e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.761427e-09] 
Layer 'conv3' weights[0]: 6.892682e-03 [3.496986e-07] 
Layer 'conv3' biases: 1.416527e-05 [3.241044e-08] 
Layer 'conv4' weights[0]: 6.920570e-03 [3.541601e-07] 
Layer 'conv4' biases: 1.000014e+00 [3.397381e-07] 
Layer 'conv5' weights[0]: 6.939043e-03 [2.403368e-06] 
Layer 'conv5' biases: 9.994327e-01 [2.537109e-06] 
Layer 'fc6' weights[0]: 7.479623e-03 [5.539587e-08] 
Layer 'fc6' biases: 9.999991e-01 [4.799424e-08] 
Layer 'fc7' weights[0]: 7.834896e-03 [1.159545e-07] 
Layer 'fc7' biases: 9.999523e-01 [1.224108e-07] 
Layer 'fc8' weights[0]: 3.467122e-03 [1.674558e-05] 
Layer 'fc8' biases: 5.104617e-03 [8.965699e-06] 
Train error last 800 batches: 0.656907
-------------------------------------------------------
Not saving because 0.458972 > 0.323801 (3.40: -8.65%)
======================================================= (2.383 sec)
4.501... logprob:  0.602843, 0.268229 (1.438 sec)
4.502... logprob:  0.662559, 0.309896 (1.445 sec)
4.503... logprob:  0.625604, 0.252604 (1.483 sec)
4.504... logprob:  0.609295, 0.243489 (1.434 sec)
4.505... logprob:  0.812694, 0.341146 (1.437 sec)
4.506... logprob:  0.672705, 0.313802 (1.429 sec)
4.507... logprob:  0.532316, 0.214844 (1.417 sec)
4.508... logprob:  0.551155, 0.220052 (1.429 sec)
4.509... logprob:  0.505980, 0.226562 (1.471 sec)
4.510... logprob:  0.590228, 0.273437 (1.435 sec)
4.511... logprob:  0.648530, 0.266927 (1.445 sec)
4.512... logprob:  0.689295, 0.302083 (1.460 sec)
4.513... logprob:  0.535184, 0.235677 (1.438 sec)
4.514... logprob:  0.673452, 0.298177 (1.430 sec)
4.515... logprob:  0.623144, 0.287760 (1.443 sec)
4.516... logprob:  0.646597, 0.294271 (1.421 sec)
4.517... logprob:  0.746642, 0.334635 (1.439 sec)
4.518... logprob:  0.563145, 0.244792 (1.478 sec)
4.519... logprob:  0.618864, 0.279948 (1.445 sec)
4.520... logprob:  0.625132, 0.286458 (1.449 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.468251, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.898689e-03 [3.508528e-07] 
Layer 'conv1' biases: 6.477119e-07 [1.201128e-09] 
Layer 'conv2' weights[0]: 6.886924e-03 [3.470790e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.449054e-09] 
Layer 'conv3' weights[0]: 6.885776e-03 [3.473562e-07] 
Layer 'conv3' biases: 1.418453e-05 [2.483570e-08] 
Layer 'conv4' weights[0]: 6.913621e-03 [3.511404e-07] 
Layer 'conv4' biases: 1.000014e+00 [2.735773e-07] 
Layer 'conv5' weights[0]: 6.932151e-03 [1.774583e-06] 
Layer 'conv5' biases: 9.994285e-01 [1.884304e-06] 
Layer 'fc6' weights[0]: 7.478872e-03 [5.368133e-08] 
Layer 'fc6' biases: 9.999991e-01 [4.542398e-08] 
Layer 'fc7' weights[0]: 7.834150e-03 [1.100049e-07] 
Layer 'fc7' biases: 9.999541e-01 [1.142681e-07] 
Layer 'fc8' weights[0]: 3.554127e-03 [1.595407e-05] 
Layer 'fc8' biases: 5.548216e-03 [8.863713e-06] 
Train error last 800 batches: 0.655643
-------------------------------------------------------
Not saving because 0.468251 > 0.323801 (3.40: -8.65%)
======================================================= (2.371 sec)
4.521... logprob:  0.678537, 0.298177 (1.458 sec)
4.522... logprob:  0.744549, 0.322917 (1.469 sec)
4.523... logprob:  0.480867, 0.209635 (1.433 sec)
4.524... logprob:  0.682030, 0.303385 (1.418 sec)
4.525... logprob:  0.703619, 0.273437 (1.425 sec)
4.526... logprob:  0.671052, 0.307292 (1.434 sec)
4.527... logprob:  0.714276, 0.322917 (1.438 sec)
4.528... logprob:  0.682813, 0.283854 (1.461 sec)
4.529... logprob:  0.601884, 0.265625 (1.445 sec)
4.530... logprob:  0.649948, 0.261719 (1.436 sec)
4.531... logprob:  0.660545, 0.277344 (1.471 sec)
4.532... logprob:  0.614754, 0.270833 (1.425 sec)
4.533... logprob:  0.790633, 0.324219 (1.423 sec)
4.534... logprob:  0.634349, 0.291667 (1.427 sec)
4.535... logprob:  0.832373, 0.329427 (1.432 sec)
4.536... logprob:  0.745605, 0.317708 (1.423 sec)
4.537... logprob:  0.769248, 0.308594 (1.474 sec)
4.538... logprob:  0.645589, 0.251302 (1.435 sec)
4.539... logprob:  0.581321, 0.234375 (1.430 sec)
4.540... logprob:  0.598461, 0.272135 (1.487 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.516876, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.891805e-03 [3.531668e-07] 
Layer 'conv1' biases: 6.466300e-07 [1.515690e-09] 
Layer 'conv2' weights[0]: 6.880031e-03 [3.494470e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.631823e-09] 
Layer 'conv3' weights[0]: 6.878981e-03 [3.506877e-07] 
Layer 'conv3' biases: 1.430423e-05 [3.605873e-08] 
Layer 'conv4' weights[0]: 6.906710e-03 [3.565507e-07] 
Layer 'conv4' biases: 1.000014e+00 [4.074182e-07] 
Layer 'conv5' weights[0]: 6.925439e-03 [2.533070e-06] 
Layer 'conv5' biases: 9.994316e-01 [2.706878e-06] 
Layer 'fc6' weights[0]: 7.478167e-03 [5.842189e-08] 
Layer 'fc6' biases: 9.999991e-01 [5.264632e-08] 
Layer 'fc7' weights[0]: 7.833365e-03 [1.256882e-07] 
Layer 'fc7' biases: 9.999520e-01 [1.475636e-07] 
Layer 'fc8' weights[0]: 3.484774e-03 [2.022168e-05] 
Layer 'fc8' biases: 5.137881e-03 [2.168434e-05] 
Train error last 800 batches: 0.655623
-------------------------------------------------------
Not saving because 0.516876 > 0.323801 (3.40: -8.65%)
======================================================= (2.367 sec)
4.541... logprob:  0.631373, 0.272135 (1.441 sec)
4.542... logprob:  0.695301, 0.305990 (1.432 sec)
4.543... logprob:  0.488673, 0.220052 (1.433 sec)
4.544... logprob:  0.589554, 0.240885 (1.426 sec)
4.545... logprob:  0.620624, 0.264323 (1.425 sec)
4.546... logprob:  0.538680, 0.263021 (1.478 sec)
4.547... logprob:  0.655869, 0.313802 (1.436 sec)
4.548... logprob:  0.600041, 0.261719 (1.436 sec)
4.549... logprob:  0.614365, 0.276042 (1.474 sec)
4.550... logprob:  0.618244, 0.248698 (1.424 sec)
4.551... logprob:  0.639009, 0.287760 (1.430 sec)
4.552... logprob:  0.575154, 0.248698 (1.427 sec)
4.553... logprob:  0.625854, 0.296875 (1.480 sec)
4.554... logprob:  0.801998, 0.328125 (1.427 sec)
4.555... logprob:  0.607984, 0.299479 (1.474 sec)
4.556... logprob:  0.631532, 0.277344 (1.451 sec)
4.557... logprob:  0.656907, 0.263021 (1.441 sec)
4.558... logprob:  0.637165, 0.294271 (1.466 sec)
4.559... logprob:  0.628974, 0.291667 (1.432 sec)
4.560... logprob:  0.624770, 0.279948 (1.432 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.507816, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.884899e-03 [3.498536e-07] 
Layer 'conv1' biases: 6.430159e-07 [1.240584e-09] 
Layer 'conv2' weights[0]: 6.873148e-03 [3.475310e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.234492e-09] 
Layer 'conv3' weights[0]: 6.872023e-03 [3.488036e-07] 
Layer 'conv3' biases: 1.428509e-05 [3.253713e-08] 
Layer 'conv4' weights[0]: 6.899772e-03 [3.526449e-07] 
Layer 'conv4' biases: 1.000012e+00 [3.195083e-07] 
Layer 'conv5' weights[0]: 6.917924e-03 [2.123245e-06] 
Layer 'conv5' biases: 9.994250e-01 [2.262736e-06] 
Layer 'fc6' weights[0]: 7.477392e-03 [5.522721e-08] 
Layer 'fc6' biases: 9.999991e-01 [4.777149e-08] 
Layer 'fc7' weights[0]: 7.832607e-03 [1.138729e-07] 
Layer 'fc7' biases: 9.999532e-01 [1.276218e-07] 
Layer 'fc8' weights[0]: 3.599953e-03 [1.746886e-05] 
Layer 'fc8' biases: 5.714487e-03 [2.042445e-05] 
Train error last 800 batches: 0.655524
-------------------------------------------------------
Not saving because 0.507816 > 0.323801 (3.40: -8.65%)
======================================================= (2.381 sec)
4.561... logprob:  0.606101, 0.261719 (1.439 sec)
4.562... logprob:  0.697699, 0.289062 (1.428 sec)
4.563... logprob:  0.602004, 0.268229 (1.435 sec)
4.564... logprob:  0.771713, 0.320312 (1.468 sec)
4.565... logprob:  0.911963, 0.361979 (1.451 sec)
4.566... logprob:  0.563795, 0.260417 (1.446 sec)
4.567... logprob:  0.675427, 0.281250 (1.456 sec)
4.568... logprob:  0.715104, 0.312500 (1.451 sec)
4.569... logprob:  0.657915, 0.295573 (1.432 sec)
4.570... logprob:  0.705784, 0.295573 (1.420 sec)
4.571... logprob:  0.675046, 0.294271 (1.420 sec)
4.572... logprob:  0.730096, 0.295573 (1.432 sec)
4.573... logprob:  0.700307, 0.282552 (1.438 sec)
4.574... logprob:  0.656075, 0.295573 (1.458 sec)
4.575... logprob:  0.523782, 0.242187 (1.448 sec)
4.576... logprob:  0.706407, 0.332031 (1.436 sec)
4.577... logprob:  0.700899, 0.319010 (1.470 sec)
4.578... logprob:  0.607223, 0.313802 (1.428 sec)
4.579... logprob:  0.573232, 0.235677 (1.421 sec)
4.580... logprob:  0.750107, 0.307292 (1.424 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.526857, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.877971e-03 [3.537657e-07] 
Layer 'conv1' biases: 6.460975e-07 [1.472677e-09] 
Layer 'conv2' weights[0]: 6.866268e-03 [3.491447e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.221578e-09] 
Layer 'conv3' weights[0]: 6.865127e-03 [3.512700e-07] 
Layer 'conv3' biases: 1.429280e-05 [3.880008e-08] 
Layer 'conv4' weights[0]: 6.892899e-03 [3.566125e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.969769e-07] 
Layer 'conv5' weights[0]: 6.911526e-03 [2.828851e-06] 
Layer 'conv5' biases: 9.994239e-01 [2.983454e-06] 
Layer 'fc6' weights[0]: 7.476586e-03 [6.122799e-08] 
Layer 'fc6' biases: 9.999992e-01 [5.675826e-08] 
Layer 'fc7' weights[0]: 7.831808e-03 [1.303662e-07] 
Layer 'fc7' biases: 9.999515e-01 [1.725889e-07] 
Layer 'fc8' weights[0]: 3.525275e-03 [2.092966e-05] 
Layer 'fc8' biases: 5.237072e-03 [3.497649e-05] 
Train error last 800 batches: 0.655380
-------------------------------------------------------
Not saving because 0.526857 > 0.323801 (3.40: -8.65%)
======================================================= (2.407 sec)
4.581... logprob:  0.750245, 0.326823 (1.441 sec)
4.582... logprob:  0.541537, 0.259115 (1.434 sec)
4.583... logprob:  0.772410, 0.295573 (1.477 sec)
4.584... logprob:  0.705781, 0.317708 (1.447 sec)
4.585... logprob:  0.609598, 0.264323 (1.431 sec)
4.586... logprob:  0.557058, 0.248698 (1.482 sec)
4.587... logprob:  0.648722, 0.283854 (1.439 sec)
4.588... logprob:  0.729313, 0.329427 (1.427 sec)
4.589... logprob:  0.580794, 0.255208 (1.430 sec)
4.590... logprob:  0.730538, 0.298177 (1.425 sec)
4.591... logprob:  0.623068, 0.283854 (1.424 sec)
4.592... logprob:  0.683312, 0.312500 (1.477 sec)
4.593... logprob:  0.583145, 0.265625 (1.435 sec)
4.594... logprob:  0.580571, 0.274739 (1.450 sec)
4.595... logprob:  0.663956, 0.282552 (1.479 sec)
4.596... logprob:  0.765172, 0.337240 (1.428 sec)
4.597... logprob:  0.570768, 0.277344 (1.429 sec)
4.598... logprob:  0.626959, 0.287760 (1.429 sec)
4.599... logprob:  0.567816, 0.272135 (1.422 sec)
4.600... logprob:  0.520626, 0.226562 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.429894, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.871128e-03 [3.490758e-07] 
Layer 'conv1' biases: 6.506527e-07 [1.109721e-09] 
Layer 'conv2' weights[0]: 6.859439e-03 [3.466145e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.806565e-09] 
Layer 'conv3' weights[0]: 6.858311e-03 [3.471162e-07] 
Layer 'conv3' biases: 1.436307e-05 [2.713025e-08] 
Layer 'conv4' weights[0]: 6.886011e-03 [3.522279e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.114619e-07] 
Layer 'conv5' weights[0]: 6.904636e-03 [2.344695e-06] 
Layer 'conv5' biases: 9.994150e-01 [2.495508e-06] 
Layer 'fc6' weights[0]: 7.475807e-03 [5.716223e-08] 
Layer 'fc6' biases: 9.999991e-01 [5.085919e-08] 
Layer 'fc7' weights[0]: 7.831020e-03 [1.231130e-07] 
Layer 'fc7' biases: 9.999521e-01 [1.684909e-07] 
Layer 'fc8' weights[0]: 3.608508e-03 [2.037539e-05] 
Layer 'fc8' biases: 5.750507e-03 [3.707447e-05] 
Train error last 800 batches: 0.655150
-------------------------------------------------------
Not saving because 0.429894 > 0.323801 (3.40: -8.65%)
======================================================= (2.373 sec)
4.601... logprob:  0.643642, 0.278646 (1.488 sec)
4.602... logprob:  0.584759, 0.274740 (1.444 sec)
4.603... logprob:  0.595739, 0.243490 (1.450 sec)
4.604... logprob:  0.555138, 0.255208 (1.476 sec)
4.605... logprob:  0.810100, 0.329427 (1.431 sec)
4.606... logprob:  0.580104, 0.295573 (1.437 sec)
4.607... logprob:  0.718885, 0.283854 (1.433 sec)
4.608... logprob:  0.536399, 0.244792 (1.431 sec)
4.609... logprob:  0.583467, 0.253906 (1.432 sec)
4.610... logprob:  0.699593, 0.307292 (1.463 sec)
4.611... logprob:  0.731692, 0.294271 (1.444 sec)
4.612... logprob:  0.773651, 0.313802 (1.446 sec)
4.613... logprob:  0.550399, 0.244792 (1.458 sec)
4.614... logprob:  0.759369, 0.335937 (1.447 sec)
4.615... logprob:  0.593874, 0.270833 (1.434 sec)
4.616... logprob:  0.712999, 0.307292 (1.429 sec)
4.617... logprob:  0.580765, 0.252604 (1.425 sec)
4.618... logprob:  0.704969, 0.315104 (1.432 sec)
4.619... logprob:  0.707033, 0.317708 (1.449 sec)
4.620... logprob:  0.703076, 0.304687 (1.452 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.432821, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.864251e-03 [3.485670e-07] 
Layer 'conv1' biases: 6.524175e-07 [1.572522e-09] 
Layer 'conv2' weights[0]: 6.852578e-03 [3.472038e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.320519e-09] 
Layer 'conv3' weights[0]: 6.851439e-03 [3.492780e-07] 
Layer 'conv3' biases: 1.439264e-05 [3.760242e-08] 
Layer 'conv4' weights[0]: 6.879118e-03 [3.531779e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.569672e-07] 
Layer 'conv5' weights[0]: 6.897881e-03 [2.379805e-06] 
Layer 'conv5' biases: 9.994138e-01 [2.501229e-06] 
Layer 'fc6' weights[0]: 7.475019e-03 [6.362960e-08] 
Layer 'fc6' biases: 9.999992e-01 [6.059724e-08] 
Layer 'fc7' weights[0]: 7.830247e-03 [1.379716e-07] 
Layer 'fc7' biases: 9.999509e-01 [1.987452e-07] 
Layer 'fc8' weights[0]: 3.553606e-03 [2.276882e-05] 
Layer 'fc8' biases: 5.482399e-03 [3.504561e-05] 
Train error last 800 batches: 0.655582
-------------------------------------------------------
Not saving because 0.432821 > 0.323801 (3.40: -8.65%)
======================================================= (2.390 sec)
4.621... logprob:  0.587304, 0.278646 (1.454 sec)
4.622... logprob:  0.646975, 0.308594 (1.448 sec)
4.623... logprob:  0.526670, 0.227865 (1.465 sec)
4.624... logprob:  0.542937, 0.226562 (1.432 sec)
4.625... logprob:  0.632631, 0.279948 (1.418 sec)
4.626... logprob:  0.728386, 0.299479 (1.423 sec)
4.627... logprob:  0.604581, 0.251302 (1.435 sec)
4.628... logprob:  0.606165, 0.274740 (1.437 sec)
4.629... logprob:  0.630213, 0.290365 (1.463 sec)
4.630... logprob:  0.640088, 0.257812 (1.444 sec)
4.631... logprob:  0.832536, 0.334635 (1.432 sec)
4.632... logprob:  0.686965, 0.294271 (1.499 sec)
4.633... logprob:  0.618703, 0.260417 (1.426 sec)
4.634... logprob:  0.748270, 0.330729 (1.424 sec)
4.635... logprob:  0.653007, 0.313802 (1.431 sec)
4.636... logprob:  0.601811, 0.273437 (1.423 sec)
4.637... logprob:  0.631428, 0.281250 (1.431 sec)
4.638... logprob:  0.685641, 0.316406 (1.472 sec)
4.639... logprob:  0.599857, 0.213542 (1.437 sec)
4.640... logprob:  0.688128, 0.289062 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.556079, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.857391e-03 [3.484259e-07] 
Layer 'conv1' biases: 6.591623e-07 [1.238621e-09] 
Layer 'conv2' weights[0]: 6.845695e-03 [3.468171e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.649386e-09] 
Layer 'conv3' weights[0]: 6.844579e-03 [3.475046e-07] 
Layer 'conv3' biases: 1.439962e-05 [3.313063e-08] 
Layer 'conv4' weights[0]: 6.872230e-03 [3.514791e-07] 
Layer 'conv4' biases: 1.000012e+00 [3.597193e-07] 
Layer 'conv5' weights[0]: 6.891194e-03 [2.133303e-06] 
Layer 'conv5' biases: 9.994096e-01 [2.265724e-06] 
Layer 'fc6' weights[0]: 7.474255e-03 [5.865194e-08] 
Layer 'fc6' biases: 9.999992e-01 [5.303041e-08] 
Layer 'fc7' weights[0]: 7.829525e-03 [1.261772e-07] 
Layer 'fc7' biases: 9.999509e-01 [1.563209e-07] 
Layer 'fc8' weights[0]: 3.547472e-03 [1.834503e-05] 
Layer 'fc8' biases: 5.456444e-03 [2.386527e-05] 
Train error last 800 batches: 0.655196
-------------------------------------------------------
Not saving because 0.556079 > 0.323801 (3.40: -8.65%)
======================================================= (2.395 sec)
4.641... logprob:  0.639079, 0.298177 (1.490 sec)
4.642... logprob:  0.703014, 0.302083 (1.435 sec)
4.643... logprob:  0.717202, 0.315104 (1.430 sec)
4.644... logprob:  0.477954, 0.212240 (1.430 sec)
4.645... logprob:  0.591486, 0.292969 (1.424 sec)
4.646... logprob:  0.563960, 0.242187 (1.434 sec)
4.647... logprob:  0.627352, 0.225260 (1.481 sec)
4.648... logprob:  0.751131, 0.290365 (1.434 sec)
4.649... logprob:  0.584677, 0.273438 (1.438 sec)
4.650... logprob:  0.627707, 0.266927 (1.470 sec)
4.651... logprob:  0.669356, 0.300781 (1.424 sec)
4.652... logprob:  0.689982, 0.311198 (1.432 sec)
4.653... logprob:  0.677655, 0.269531 (1.429 sec)
4.654... logprob:  0.732162, 0.307292 (1.421 sec)
4.655... logprob:  0.679246, 0.298177 (1.423 sec)
4.656... logprob:  0.714264, 0.330729 (1.474 sec)
4.657... logprob:  0.713352, 0.304687 (1.435 sec)
4.658... logprob:  0.594153, 0.282552 (1.445 sec)
4.659... logprob:  0.736181, 0.343750 (1.467 sec)
4.660... logprob:  0.685982, 0.285156 (1.438 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.404013, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.850522e-03 [3.478876e-07] 
Layer 'conv1' biases: 6.598921e-07 [1.405554e-09] 
Layer 'conv2' weights[0]: 6.838850e-03 [3.453980e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.066780e-09] 
Layer 'conv3' weights[0]: 6.837712e-03 [3.461819e-07] 
Layer 'conv3' biases: 1.438147e-05 [3.284628e-08] 
Layer 'conv4' weights[0]: 6.865381e-03 [3.503989e-07] 
Layer 'conv4' biases: 1.000012e+00 [3.722338e-07] 
Layer 'conv5' weights[0]: 6.884222e-03 [2.309972e-06] 
Layer 'conv5' biases: 9.994100e-01 [2.513972e-06] 
Layer 'fc6' weights[0]: 7.473444e-03 [5.947486e-08] 
Layer 'fc6' biases: 9.999992e-01 [5.462265e-08] 
Layer 'fc7' weights[0]: 7.828772e-03 [1.258101e-07] 
Layer 'fc7' biases: 9.999498e-01 [1.577182e-07] 
Layer 'fc8' weights[0]: 3.537575e-03 [2.020483e-05] 
Layer 'fc8' biases: 5.385562e-03 [2.849687e-05] 
Train error last 800 batches: 0.655004
-------------------------------------------------------
Not saving because 0.404013 > 0.323801 (3.40: -8.65%)
======================================================= (2.385 sec)
4.661... logprob:  0.588045, 0.269531 (1.440 sec)
4.662... logprob:  0.618183, 0.285156 (1.434 sec)
4.663... logprob:  0.572007, 0.265625 (1.425 sec)
4.664... logprob:  0.543915, 0.253906 (1.439 sec)
4.665... logprob:  0.614879, 0.268229 (1.463 sec)
4.666... logprob:  0.596421, 0.282552 (1.455 sec)
4.667... logprob:  0.712436, 0.299479 (1.452 sec)
4.668... logprob:  0.673246, 0.274740 (1.446 sec)
4.669... logprob:  0.706006, 0.337240 (1.457 sec)
4.670... logprob:  0.578002, 0.270833 (1.463 sec)
4.671... logprob:  0.584867, 0.278646 (1.417 sec)
4.672... logprob:  0.663783, 0.268229 (1.425 sec)
4.673... logprob:  0.650618, 0.307292 (1.433 sec)
4.674... logprob:  0.701486, 0.302083 (1.431 sec)
4.675... logprob:  0.596646, 0.268229 (1.464 sec)
4.676... logprob:  0.622530, 0.298177 (1.442 sec)
4.677... logprob:  0.688240, 0.283854 (1.437 sec)
4.678... logprob:  0.687609, 0.276042 (1.546 sec)
4.679... logprob:  0.658015, 0.303385 (1.430 sec)
4.680... logprob:  0.644538, 0.321615 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.522062, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.843702e-03 [3.481831e-07] 
Layer 'conv1' biases: 6.598452e-07 [1.175377e-09] 
Layer 'conv2' weights[0]: 6.832023e-03 [3.449422e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.483680e-09] 
Layer 'conv3' weights[0]: 6.830951e-03 [3.452631e-07] 
Layer 'conv3' biases: 1.436742e-05 [2.867912e-08] 
Layer 'conv4' weights[0]: 6.858508e-03 [3.489005e-07] 
Layer 'conv4' biases: 1.000012e+00 [3.103116e-07] 
Layer 'conv5' weights[0]: 6.877368e-03 [2.305530e-06] 
Layer 'conv5' biases: 9.994051e-01 [2.451531e-06] 
Layer 'fc6' weights[0]: 7.472637e-03 [5.632016e-08] 
Layer 'fc6' biases: 9.999992e-01 [4.982702e-08] 
Layer 'fc7' weights[0]: 7.828018e-03 [1.177538e-07] 
Layer 'fc7' biases: 9.999511e-01 [1.368318e-07] 
Layer 'fc8' weights[0]: 3.625464e-03 [1.813327e-05] 
Layer 'fc8' biases: 5.850056e-03 [2.594269e-05] 
Train error last 800 batches: 0.654210
-------------------------------------------------------
Not saving because 0.522062 > 0.323801 (3.40: -8.65%)
======================================================= (2.380 sec)
4.681... logprob:  0.650829, 0.270833 (1.436 sec)
4.682... logprob:  0.511663, 0.203125 (1.437 sec)
4.683... logprob:  0.533053, 0.227865 (1.435 sec)
4.684... logprob:  0.577333, 0.251302 (1.477 sec)
4.685... logprob:  0.545784, 0.248698 (1.444 sec)
4.686... logprob:  0.552191, 0.243490 (1.427 sec)
4.687... logprob:  0.571806, 0.278646 (1.478 sec)
4.688... logprob:  0.591735, 0.268229 (1.429 sec)
4.689... logprob:  0.703775, 0.325521 (1.421 sec)
4.690... logprob:  0.710295, 0.313802 (1.429 sec)
4.691... logprob:  0.590950, 0.276042 (1.428 sec)
4.692... logprob:  0.566689, 0.248698 (1.425 sec)
4.693... logprob:  0.703441, 0.294271 (1.480 sec)
4.694... logprob:  0.535953, 0.243490 (1.428 sec)
4.695... logprob:  0.608299, 0.277344 (1.439 sec)
4.696... logprob:  0.745833, 0.315104 (1.477 sec)
4.697... logprob:  0.757280, 0.321615 (1.425 sec)
4.698... logprob:  0.767649, 0.325521 (1.432 sec)
4.699... logprob:  0.799127, 0.339844 (1.426 sec)
4.700... logprob:  0.647745, 0.305990 (1.425 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.371192, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.836871e-03 [3.487113e-07] 
Layer 'conv1' biases: 6.570162e-07 [1.854530e-09] 
Layer 'conv2' weights[0]: 6.825184e-03 [3.474377e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.273210e-08] 
Layer 'conv3' weights[0]: 6.824171e-03 [3.506429e-07] 
Layer 'conv3' biases: 1.446171e-05 [4.661545e-08] 
Layer 'conv4' weights[0]: 6.851680e-03 [3.573410e-07] 
Layer 'conv4' biases: 1.000012e+00 [5.233755e-07] 
Layer 'conv5' weights[0]: 6.870568e-03 [3.387489e-06] 
Layer 'conv5' biases: 9.994105e-01 [3.743312e-06] 
Layer 'fc6' weights[0]: 7.471862e-03 [7.150198e-08] 
Layer 'fc6' biases: 9.999990e-01 [7.180217e-08] 
Layer 'fc7' weights[0]: 7.827247e-03 [1.595848e-07] 
Layer 'fc7' biases: 9.999505e-01 [2.654377e-07] 
Layer 'fc8' weights[0]: 3.620607e-03 [2.784547e-05] 
Layer 'fc8' biases: 5.810392e-03 [5.655359e-05] 
Train error last 800 batches: 0.654356
-------------------------------------------------------
Not saving because 0.371192 > 0.323801 (3.40: -8.65%)
======================================================= (2.347 sec)
4.701... logprob:  0.625734, 0.274740 (1.441 sec)
4.702... logprob:  0.627213, 0.242187 (1.483 sec)
4.703... logprob:  0.622360, 0.252604 (1.437 sec)
4.704... logprob:  0.684249, 0.308594 (1.449 sec)
4.705... logprob:  0.624448, 0.289062 (1.465 sec)
4.706... logprob:  0.731017, 0.326823 (1.431 sec)
4.707... logprob:  0.638266, 0.269531 (1.437 sec)
4.708... logprob:  0.628783, 0.285156 (1.447 sec)
4.709... logprob:  0.650823, 0.268229 (1.420 sec)
4.710... logprob:  0.869313, 0.355469 (1.432 sec)
4.711... logprob:  0.667177, 0.290365 (1.458 sec)
4.712... logprob:  0.610502, 0.256510 (1.444 sec)
4.713... logprob:  0.774716, 0.337240 (1.445 sec)
4.714... logprob:  0.687605, 0.281250 (1.450 sec)
4.715... logprob:  0.587092, 0.265625 (1.451 sec)
4.716... logprob:  0.567395, 0.234375 (1.430 sec)
4.717... logprob:  0.639064, 0.281250 (1.421 sec)
4.718... logprob:  0.652772, 0.281250 (1.421 sec)
4.719... logprob:  0.687038, 0.290365 (1.436 sec)
4.720... logprob:  0.696415, 0.295573 (1.439 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.421042, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.830004e-03 [3.500854e-07] 
Layer 'conv1' biases: 6.601942e-07 [1.567627e-09] 
Layer 'conv2' weights[0]: 6.818378e-03 [3.443919e-07] 
Layer 'conv2' biases: 9.999998e-01 [8.801092e-09] 
Layer 'conv3' weights[0]: 6.817301e-03 [3.455882e-07] 
Layer 'conv3' biases: 1.464834e-05 [3.267366e-08] 
Layer 'conv4' weights[0]: 6.844828e-03 [3.496613e-07] 
Layer 'conv4' biases: 1.000014e+00 [3.341584e-07] 
Layer 'conv5' weights[0]: 6.864786e-03 [2.213639e-06] 
Layer 'conv5' biases: 9.994135e-01 [2.322664e-06] 
Layer 'fc6' weights[0]: 7.471079e-03 [5.600721e-08] 
Layer 'fc6' biases: 9.999990e-01 [4.930189e-08] 
Layer 'fc7' weights[0]: 7.826471e-03 [1.180331e-07] 
Layer 'fc7' biases: 9.999479e-01 [1.223244e-07] 
Layer 'fc8' weights[0]: 3.537495e-03 [1.612342e-05] 
Layer 'fc8' biases: 5.304495e-03 [3.882376e-06] 
Train error last 800 batches: 0.654186
-------------------------------------------------------
Not saving because 0.421042 > 0.323801 (3.40: -8.65%)
======================================================= (2.361 sec)
4.721... logprob:  0.626875, 0.273437 (1.468 sec)
4.722... logprob:  0.715393, 0.305990 (1.453 sec)
4.723... logprob:  0.637417, 0.281250 (1.447 sec)
4.724... logprob:  0.651763, 0.268229 (1.473 sec)
4.725... logprob:  0.702547, 0.315104 (1.435 sec)
4.726... logprob:  0.672592, 0.305990 (1.429 sec)
4.727... logprob:  0.614914, 0.281250 (1.428 sec)
4.728... logprob:  0.719308, 0.307292 (1.433 sec)
4.729... logprob:  0.601654, 0.252604 (1.428 sec)
4.730... logprob:  0.793798, 0.339844 (1.467 sec)
4.731... logprob:  0.635181, 0.286458 (1.438 sec)
4.732... logprob:  0.629432, 0.298177 (1.437 sec)
4.733... logprob:  0.770930, 0.338542 (1.478 sec)
4.734... logprob:  0.651740, 0.299479 (1.436 sec)
4.735... logprob:  0.687561, 0.302083 (1.424 sec)
4.736... logprob:  0.737419, 0.325521 (1.430 sec)
4.737... logprob:  0.762272, 0.358073 (1.426 sec)
4.738... logprob:  0.772852, 0.329427 (1.427 sec)
4.739... logprob:  0.713437, 0.313802 (1.478 sec)
4.740... logprob:  0.609420, 0.294271 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.453684, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.823179e-03 [3.500778e-07] 
Layer 'conv1' biases: 6.620082e-07 [1.292142e-09] 
Layer 'conv2' weights[0]: 6.811550e-03 [3.448607e-07] 
Layer 'conv2' biases: 9.999998e-01 [6.846442e-09] 
Layer 'conv3' weights[0]: 6.810454e-03 [3.440357e-07] 
Layer 'conv3' biases: 1.465378e-05 [2.689675e-08] 
Layer 'conv4' weights[0]: 6.838016e-03 [3.485432e-07] 
Layer 'conv4' biases: 1.000014e+00 [2.878370e-07] 
Layer 'conv5' weights[0]: 6.857966e-03 [2.063710e-06] 
Layer 'conv5' biases: 9.994138e-01 [2.162642e-06] 
Layer 'fc6' weights[0]: 7.470284e-03 [5.589018e-08] 
Layer 'fc6' biases: 9.999990e-01 [4.878439e-08] 
Layer 'fc7' weights[0]: 7.825680e-03 [1.195013e-07] 
Layer 'fc7' biases: 9.999472e-01 [1.350474e-07] 
Layer 'fc8' weights[0]: 3.545121e-03 [1.774858e-05] 
Layer 'fc8' biases: 5.367562e-03 [1.856337e-05] 
Train error last 800 batches: 0.654500
-------------------------------------------------------
Not saving because 0.453684 > 0.323801 (3.40: -8.65%)
======================================================= (2.385 sec)
4.741... logprob:  0.715815, 0.337240 (1.444 sec)
4.742... logprob:  0.699402, 0.304687 (1.483 sec)
4.743... logprob:  0.587014, 0.250000 (1.434 sec)
4.744... logprob:  0.713073, 0.311198 (1.435 sec)
4.745... logprob:  0.701057, 0.298177 (1.435 sec)
4.746... logprob:  0.659634, 0.274740 (1.440 sec)
4.747... logprob:  0.614689, 0.264323 (1.427 sec)
4.748... logprob:  0.532517, 0.210937 (1.485 sec)
4.749... logprob:  0.601790, 0.265625 (1.431 sec)
4.750... logprob:  0.769170, 0.292969 (1.441 sec)
4.751... logprob:  0.549334, 0.247396 (1.482 sec)
4.752... logprob:  0.670068, 0.296875 (1.429 sec)
4.753... logprob:  0.684114, 0.282552 (1.433 sec)
4.754... logprob:  0.768168, 0.309896 (1.427 sec)
4.755... logprob:  0.656667, 0.257812 (1.423 sec)
4.756... logprob:  0.672976, 0.299479 (1.431 sec)
4.757... logprob:  0.727036, 0.308594 (1.465 sec)
4.758... logprob:  0.629841, 0.291667 (1.439 sec)
4.759... logprob:  0.693067, 0.273437 (1.446 sec)
4.760... logprob:  0.805607, 0.325521 (1.457 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.520376, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.816367e-03 [3.515235e-07] 
Layer 'conv1' biases: 6.700694e-07 [1.620609e-09] 
Layer 'conv2' weights[0]: 6.804753e-03 [3.451821e-07] 
Layer 'conv2' biases: 9.999998e-01 [9.110667e-09] 
Layer 'conv3' weights[0]: 6.803656e-03 [3.450907e-07] 
Layer 'conv3' biases: 1.463892e-05 [3.264353e-08] 
Layer 'conv4' weights[0]: 6.831133e-03 [3.500415e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.487655e-07] 
Layer 'conv5' weights[0]: 6.851051e-03 [2.770219e-06] 
Layer 'conv5' biases: 9.994102e-01 [2.982222e-06] 
Layer 'fc6' weights[0]: 7.469501e-03 [6.512998e-08] 
Layer 'fc6' biases: 9.999990e-01 [6.253335e-08] 
Layer 'fc7' weights[0]: 7.824918e-03 [1.433776e-07] 
Layer 'fc7' biases: 9.999472e-01 [1.989920e-07] 
Layer 'fc8' weights[0]: 3.563473e-03 [2.406104e-05] 
Layer 'fc8' biases: 5.483241e-03 [3.428816e-05] 
Train error last 800 batches: 0.654885
-------------------------------------------------------
Not saving because 0.520376 > 0.323801 (3.40: -8.65%)
======================================================= (2.392 sec)
4.761... logprob:  0.652819, 0.296875 (1.453 sec)
4.762... logprob:  0.660950, 0.292969 (1.441 sec)
4.763... logprob:  0.837963, 0.388021 (1.426 sec)
4.764... logprob:  0.642789, 0.270833 (1.418 sec)
4.765... logprob:  0.485505, 0.203125 (1.432 sec)
4.766... logprob:  0.710380, 0.315104 (1.449 sec)
4.767... logprob:  0.539640, 0.214844 (1.451 sec)
4.768... logprob:  0.715438, 0.334635 (1.464 sec)
4.769... logprob:  0.745900, 0.305990 (1.457 sec)
4.770... logprob:  0.641450, 0.273437 (1.477 sec)
4.771... logprob:  0.677142, 0.320312 (1.450 sec)
4.772... logprob:  0.649979, 0.246094 (1.438 sec)
4.773... logprob:  0.744752, 0.322917 (1.441 sec)
4.774... logprob:  0.699343, 0.295573 (1.455 sec)
4.775... logprob:  0.598698, 0.256510 (1.456 sec)
4.776... logprob:  0.634378, 0.269531 (1.475 sec)
4.777... logprob:  0.615826, 0.248698 (1.464 sec)
4.778... logprob:  0.662734, 0.277344 (1.463 sec)
4.779... logprob:  0.687671, 0.313802 (1.485 sec)
4.780... logprob:  0.609577, 0.296875 (1.445 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.421000, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.809576e-03 [3.464645e-07] 
Layer 'conv1' biases: 6.757883e-07 [1.036462e-09] 
Layer 'conv2' weights[0]: 6.797944e-03 [3.434579e-07] 
Layer 'conv2' biases: 9.999998e-01 [6.761002e-09] 
Layer 'conv3' weights[0]: 6.796841e-03 [3.436492e-07] 
Layer 'conv3' biases: 1.468601e-05 [2.708087e-08] 
Layer 'conv4' weights[0]: 6.824294e-03 [3.474325e-07] 
Layer 'conv4' biases: 1.000013e+00 [2.975835e-07] 
Layer 'conv5' weights[0]: 6.844349e-03 [1.957995e-06] 
Layer 'conv5' biases: 9.994069e-01 [2.089120e-06] 
Layer 'fc6' weights[0]: 7.468705e-03 [5.759294e-08] 
Layer 'fc6' biases: 9.999990e-01 [5.158546e-08] 
Layer 'fc7' weights[0]: 7.824158e-03 [1.203625e-07] 
Layer 'fc7' biases: 9.999468e-01 [1.357171e-07] 
Layer 'fc8' weights[0]: 3.553705e-03 [1.772725e-05] 
Layer 'fc8' biases: 5.384433e-03 [1.913004e-05] 
Train error last 800 batches: 0.655154
-------------------------------------------------------
Not saving because 0.421000 > 0.323801 (3.40: -8.65%)
======================================================= (2.393 sec)
4.781... logprob:  0.602240, 0.281250 (1.449 sec)
4.782... logprob:  0.639545, 0.283854 (1.453 sec)
4.783... logprob:  0.740262, 0.298177 (1.458 sec)
4.784... logprob:  0.684460, 0.320312 (1.469 sec)
4.785... logprob:  0.776270, 0.291667 (1.496 sec)
4.786... logprob:  0.679474, 0.291667 (1.470 sec)
4.787... logprob:  0.724369, 0.337240 (1.460 sec)
4.788... logprob:  0.722948, 0.298177 (1.491 sec)
4.789... logprob:  0.609654, 0.296875 (1.451 sec)
4.790... logprob:  0.602711, 0.252604 (1.442 sec)
4.791... logprob:  0.606324, 0.250000 (1.439 sec)
4.792... logprob:  0.568786, 0.246094 (1.455 sec)
4.793... logprob:  0.665398, 0.290364 (1.444 sec)
4.794... logprob:  0.674672, 0.285156 (1.485 sec)
4.795... logprob:  0.683597, 0.287760 (1.460 sec)
4.796... logprob:  0.651832, 0.296875 (1.456 sec)
4.797... logprob:  0.638622, 0.272135 (1.493 sec)
4.798... logprob:  0.661140, 0.296875 (1.448 sec)
4.799... logprob:  0.596782, 0.281250 (1.445 sec)
4.800... logprob:  0.648770, 0.278646 (1.399 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.502383, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.802760e-03 [3.459026e-07] 
Layer 'conv1' biases: 6.764750e-07 [1.096985e-09] 
Layer 'conv2' weights[0]: 6.791122e-03 [3.434875e-07] 
Layer 'conv2' biases: 9.999998e-01 [7.670857e-09] 
Layer 'conv3' weights[0]: 6.790007e-03 [3.441850e-07] 
Layer 'conv3' biases: 1.480981e-05 [3.170075e-08] 
Layer 'conv4' weights[0]: 6.817515e-03 [3.480996e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.251940e-07] 
Layer 'conv5' weights[0]: 6.837462e-03 [2.221476e-06] 
Layer 'conv5' biases: 9.994042e-01 [2.372005e-06] 
Layer 'fc6' weights[0]: 7.467924e-03 [5.824894e-08] 
Layer 'fc6' biases: 9.999990e-01 [5.278734e-08] 
Layer 'fc7' weights[0]: 7.823368e-03 [1.264867e-07] 
Layer 'fc7' biases: 9.999471e-01 [1.654648e-07] 
Layer 'fc8' weights[0]: 3.578803e-03 [2.084777e-05] 
Layer 'fc8' biases: 5.562595e-03 [2.988491e-05] 
Train error last 800 batches: 0.655337
-------------------------------------------------------
Not saving because 0.502383 > 0.323801 (3.40: -8.65%)
======================================================= (2.385 sec)
5.1... logprob:  0.601225, 0.259114 (1.406 sec)
5.2... logprob:  0.686579, 0.303385 (1.449 sec)
5.3... logprob:  0.598250, 0.256510 (1.419 sec)
5.4... logprob:  0.666727, 0.311198 (1.411 sec)
5.5... logprob:  0.652536, 0.279948 (1.431 sec)
5.6... logprob:  0.727421, 0.292969 (1.393 sec)
5.7... logprob:  0.591229, 0.273437 (1.414 sec)
5.8... logprob:  0.640844, 0.273437 (1.391 sec)
5.9... logprob:  0.606778, 0.266927 (1.396 sec)
5.10... logprob:  0.677045, 0.289062 (1.406 sec)
5.11... logprob:  0.602647, 0.274740 (1.434 sec)
5.12... logprob:  0.655863, 0.270833 (1.390 sec)
5.13... logprob:  0.677745, 0.308594 (1.415 sec)
5.14... logprob:  0.727292, 0.313802 (1.400 sec)
5.15... logprob:  0.598423, 0.257812 (1.401 sec)
5.16... logprob:  0.655573, 0.273437 (1.404 sec)
5.17... logprob:  0.641613, 0.276042 (1.389 sec)
5.18... logprob:  0.527183, 0.218750 (1.391 sec)
5.19... logprob:  0.575740, 0.251302 (1.398 sec)
5.20... logprob:  0.623988, 0.274740 (0.671 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.564078, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.795962e-03 [3.452147e-07] 
Layer 'conv1' biases: 6.794320e-07 [1.224793e-09] 
Layer 'conv2' weights[0]: 6.784352e-03 [3.422505e-07] 
Layer 'conv2' biases: 9.999998e-01 [7.986437e-09] 
Layer 'conv3' weights[0]: 6.783235e-03 [3.437270e-07] 
Layer 'conv3' biases: 1.489388e-05 [2.924394e-08] 
Layer 'conv4' weights[0]: 6.810743e-03 [3.491050e-07] 
Layer 'conv4' biases: 1.000014e+00 [3.583421e-07] 
Layer 'conv5' weights[0]: 6.831180e-03 [2.452102e-06] 
Layer 'conv5' biases: 9.994041e-01 [2.633238e-06] 
Layer 'fc6' weights[0]: 7.467160e-03 [5.751260e-08] 
Layer 'fc6' biases: 9.999990e-01 [5.160661e-08] 
Layer 'fc7' weights[0]: 7.822597e-03 [1.218939e-07] 
Layer 'fc7' biases: 9.999472e-01 [1.517322e-07] 
Layer 'fc8' weights[0]: 3.600727e-03 [1.977237e-05] 
Layer 'fc8' biases: 5.677640e-03 [3.356359e-05] 
Train error last 800 batches: 0.654794
-------------------------------------------------------
Not saving because 0.564078 > 0.323801 (3.40: -8.65%)
======================================================= (2.392 sec)
5.21... logprob:  0.574987, 0.231771 (1.407 sec)
5.22... logprob:  0.727892, 0.298177 (1.411 sec)
5.23... logprob:  0.638059, 0.273437 (1.428 sec)
5.24... logprob:  0.489836, 0.225260 (1.414 sec)
5.25... logprob:  0.608600, 0.299479 (1.401 sec)
5.26... logprob:  0.693303, 0.298177 (1.441 sec)
5.27... logprob:  0.565809, 0.239583 (1.378 sec)
5.28... logprob:  0.664260, 0.290364 (1.408 sec)
5.29... logprob:  0.647225, 0.289062 (1.418 sec)
5.30... logprob:  0.645119, 0.286458 (1.407 sec)
5.31... logprob:  0.716047, 0.289062 (1.396 sec)
5.32... logprob:  0.745413, 0.305990 (1.380 sec)
5.33... logprob:  0.684331, 0.309896 (1.445 sec)
5.34... logprob:  0.696077, 0.315104 (1.383 sec)
5.35... logprob:  0.537109, 0.239583 (1.393 sec)
5.36... logprob:  0.691574, 0.308594 (1.395 sec)
5.37... logprob:  0.685318, 0.309896 (1.404 sec)
5.38... logprob:  0.631651, 0.278646 (1.387 sec)
5.39... logprob:  0.678806, 0.291667 (1.432 sec)
5.40... logprob:  0.706362, 0.316406 (1.402 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.439736, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.789214e-03 [3.458969e-07] 
Layer 'conv1' biases: 6.828662e-07 [1.272020e-09] 
Layer 'conv2' weights[0]: 6.777555e-03 [3.427377e-07] 
Layer 'conv2' biases: 9.999998e-01 [8.271023e-09] 
Layer 'conv3' weights[0]: 6.776550e-03 [3.444509e-07] 
Layer 'conv3' biases: 1.485078e-05 [3.667818e-08] 
Layer 'conv4' weights[0]: 6.803902e-03 [3.477987e-07] 
Layer 'conv4' biases: 1.000016e+00 [3.652669e-07] 
Layer 'conv5' weights[0]: 6.825168e-03 [2.445622e-06] 
Layer 'conv5' biases: 9.993966e-01 [2.722473e-06] 
Layer 'fc6' weights[0]: 7.466394e-03 [5.776527e-08] 
Layer 'fc6' biases: 9.999990e-01 [5.161097e-08] 
Layer 'fc7' weights[0]: 7.821809e-03 [1.222464e-07] 
Layer 'fc7' biases: 9.999470e-01 [1.447511e-07] 
Layer 'fc8' weights[0]: 3.596144e-03 [1.760262e-05] 
Layer 'fc8' biases: 5.636529e-03 [1.950083e-05] 
Train error last 800 batches: 0.654545
-------------------------------------------------------
Not saving because 0.439736 > 0.323801 (3.40: -8.65%)
======================================================= (2.383 sec)
5.41... logprob:  0.602918, 0.259115 (1.426 sec)
5.42... logprob:  0.576930, 0.274740 (1.416 sec)
5.43... logprob:  0.653371, 0.270833 (1.404 sec)
5.44... logprob:  0.693657, 0.296875 (1.434 sec)
5.45... logprob:  0.555414, 0.246094 (1.387 sec)
5.46... logprob:  0.711882, 0.335938 (1.399 sec)
5.47... logprob:  0.587767, 0.264323 (1.387 sec)
5.48... logprob:  0.766555, 0.359375 (1.420 sec)
5.49... logprob:  0.706700, 0.294271 (1.412 sec)
5.50... logprob:  0.618837, 0.279948 (1.421 sec)
5.51... logprob:  0.761219, 0.351562 (1.406 sec)
5.52... logprob:  0.656364, 0.302083 (1.397 sec)
5.53... logprob:  0.529968, 0.251302 (1.434 sec)
5.54... logprob:  0.588256, 0.253906 (1.384 sec)
5.55... logprob:  0.565369, 0.235677 (1.393 sec)
5.56... logprob:  0.573375, 0.257812 (1.393 sec)
5.57... logprob:  0.742411, 0.317708 (1.425 sec)
5.58... logprob:  0.613027, 0.265625 (1.396 sec)
5.59... logprob:  0.599068, 0.272135 (1.462 sec)
5.60... logprob:  0.780599, 0.324219 (1.415 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.303240, 0.039062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.782407e-03 [3.463754e-07] 
Layer 'conv1' biases: 6.855508e-07 [1.152548e-09] 
Layer 'conv2' weights[0]: 6.770834e-03 [3.417537e-07] 
Layer 'conv2' biases: 9.999998e-01 [7.759598e-09] 
Layer 'conv3' weights[0]: 6.769719e-03 [3.431309e-07] 
Layer 'conv3' biases: 1.494102e-05 [3.194899e-08] 
Layer 'conv4' weights[0]: 6.797083e-03 [3.485510e-07] 
Layer 'conv4' biases: 1.000017e+00 [4.101139e-07] 
Layer 'conv5' weights[0]: 6.818978e-03 [2.535674e-06] 
Layer 'conv5' biases: 9.993972e-01 [2.805513e-06] 
Layer 'fc6' weights[0]: 7.465617e-03 [5.687578e-08] 
Layer 'fc6' biases: 9.999990e-01 [5.073998e-08] 
Layer 'fc7' weights[0]: 7.821034e-03 [1.179779e-07] 
Layer 'fc7' biases: 9.999474e-01 [1.258346e-07] 
Layer 'fc8' weights[0]: 3.620674e-03 [1.625628e-05] 
Layer 'fc8' biases: 5.808191e-03 [1.013548e-05] 
Train error last 800 batches: 0.654280
-------------------------------------------------------
Saved checkpoint to /data2/ad6813/my-nets/saves/ConvNet__2014-06-04_16.10.14
======================================================= (2.817 sec)
5.61... logprob:  0.628774, 0.276042 (1.435 sec)
5.62... logprob:  0.610225, 0.276042 (1.466 sec)
5.63... logprob:  0.686101, 0.277344 (1.443 sec)
5.64... logprob:  0.678942, 0.298177 (2.186 sec)
5.65... logprob:  0.578098, 0.242187 (1.397 sec)
5.66... logprob:  0.520902, 0.204427 (1.445 sec)
5.67... logprob:  0.553978, 0.248698 (2.723 sec)
5.68... logprob:  0.630195, 0.261719 (1.397 sec)
5.69... logprob:  0.699193, 0.286458 (1.422 sec)
5.70... logprob:  0.514093, 0.253906 (1.426 sec)
5.71... logprob:  0.658445, 0.268229 (1.495 sec)
5.72... logprob:  0.723450, 0.333333 (1.405 sec)
5.73... logprob:  0.683319, 0.302083 (1.416 sec)
5.74... logprob:  0.634935, 0.256510 (1.410 sec)
5.75... logprob:  0.575200, 0.239583 (1.410 sec)
5.76... logprob:  0.648887, 0.278646 (1.428 sec)
5.77... logprob:  0.670763, 0.290364 (1.421 sec)
5.78... logprob:  0.591221, 0.277344 (1.452 sec)
5.79... logprob:  0.674802, 0.299479 (1.405 sec)
5.80... logprob:  0.606047, 0.276042 (1.418 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.454898, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.775642e-03 [3.432934e-07] 
Layer 'conv1' biases: 6.852489e-07 [1.043109e-09] 
Layer 'conv2' weights[0]: 6.764055e-03 [3.416481e-07] 
Layer 'conv2' biases: 9.999998e-01 [8.107500e-09] 
Layer 'conv3' weights[0]: 6.763061e-03 [3.426124e-07] 
Layer 'conv3' biases: 1.500141e-05 [2.909314e-08] 
Layer 'conv4' weights[0]: 6.790344e-03 [3.465747e-07] 
Layer 'conv4' biases: 1.000018e+00 [3.158773e-07] 
Layer 'conv5' weights[0]: 6.812538e-03 [2.028499e-06] 
Layer 'conv5' biases: 9.993955e-01 [2.161590e-06] 
Layer 'fc6' weights[0]: 7.464858e-03 [5.457463e-08] 
Layer 'fc6' biases: 9.999990e-01 [4.705294e-08] 
Layer 'fc7' weights[0]: 7.820276e-03 [1.125720e-07] 
Layer 'fc7' biases: 9.999470e-01 [1.171963e-07] 
Layer 'fc8' weights[0]: 3.615782e-03 [1.612648e-05] 
Layer 'fc8' biases: 5.762609e-03 [1.377419e-05] 
Train error last 800 batches: 0.653787
-------------------------------------------------------
Not saving because 0.454898 > 0.303240 (5.60: -6.35%)
======================================================= (2.368 sec)
5.81... logprob:  0.667982, 0.286458 (1.417 sec)
5.82... logprob:  0.518405, 0.225260 (1.422 sec)
5.83... logprob:  0.690501, 0.313802 (1.397 sec)
5.84... logprob:  0.698643, 0.286458 (1.466 sec)
5.85... logprob:  0.610049, 0.292969 (1.419 sec)
5.86... logprob:  0.736670, 0.300781 (1.410 sec)
5.87... logprob:  0.920278, 0.382812 (1.408 sec)
5.88... logprob:  0.707330, 0.269531 (1.405 sec)
5.89... logprob:  0.592244, 0.277344 (1.427 sec)
5.90... logprob:  0.752380, 0.291667 (1.383 sec)
5.91... logprob:  0.628140, 0.272135 (1.401 sec)
5.92... logprob:  0.706705, 0.302083 (1.401 sec)
5.93... logprob:  0.662667, 0.312500 (1.391 sec)
5.94... logprob:  0.657684, 0.290365 (1.390 sec)
5.95... logprob:  0.689380, 0.303385 (1.394 sec)
5.96... logprob:  0.701224, 0.324219 (1.397 sec)
5.97... logprob:  0.701710, 0.302083 (1.385 sec)
5.98... logprob:  0.651790, 0.281250 (1.429 sec)
5.99... logprob:  0.708074, 0.303385 (1.403 sec)
5.100... logprob:  0.563336, 0.222656 (1.393 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.522334, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.768866e-03 [3.455379e-07] 
Layer 'conv1' biases: 6.813171e-07 [1.125975e-09] 
Layer 'conv2' weights[0]: 6.757301e-03 [3.418374e-07] 
Layer 'conv2' biases: 9.999998e-01 [7.115220e-09] 
Layer 'conv3' weights[0]: 6.756252e-03 [3.419274e-07] 
Layer 'conv3' biases: 1.506578e-05 [2.757643e-08] 
Layer 'conv4' weights[0]: 6.783548e-03 [3.482546e-07] 
Layer 'conv4' biases: 1.000018e+00 [3.530448e-07] 
Layer 'conv5' weights[0]: 6.806119e-03 [2.422642e-06] 
Layer 'conv5' biases: 9.993961e-01 [2.518731e-06] 
Layer 'fc6' weights[0]: 7.464090e-03 [5.681167e-08] 
Layer 'fc6' biases: 9.999990e-01 [5.030105e-08] 
Layer 'fc7' weights[0]: 7.819490e-03 [1.201213e-07] 
Layer 'fc7' biases: 9.999447e-01 [1.344572e-07] 
Layer 'fc8' weights[0]: 3.542278e-03 [1.757172e-05] 
Layer 'fc8' biases: 5.343641e-03 [1.549099e-05] 
Train error last 800 batches: 0.654627
-------------------------------------------------------
Not saving because 0.522334 > 0.303240 (5.60: -6.35%)
======================================================= (2.378 sec)
5.101... logprob:  0.585354, 0.282552 (1.449 sec)
5.102... logprob:  0.674507, 0.305990 (1.393 sec)
5.103... logprob:  0.740276, 0.319010 (1.398 sec)
5.104... logprob:  0.613761, 0.276042 (1.397 sec)
5.105... logprob:  0.806773, 0.342448 (1.395 sec)
5.106... logprob:  0.626474, 0.278646 (1.387 sec)
5.107... logprob:  0.658311, 0.300781 (1.438 sec)
5.108... logprob:  0.816838, 0.308594 (1.390 sec)
5.109... logprob:  0.622675, 0.291667 (1.397 sec)
5.110... logprob:  0.773834, 0.348958 (1.425 sec)
5.111... logprob:  0.649701, 0.289062 (1.394 sec)
5.112... logprob:  0.579891, 0.264323 (1.395 sec)
5.113... logprob:  0.670881, 0.300781 (1.391 sec)
5.114... logprob:  0.663555, 0.289062 (1.428 sec)
5.115... logprob:  0.735130, 0.339844 (1.405 sec)
5.116... logprob:  0.681732, 0.292969 (1.392 sec)
5.117... logprob:  0.613565, 0.296875 (1.440 sec)
5.118... logprob:  0.636395, 0.269531 (1.380 sec)
5.119... logprob:  0.657430, 0.290364 (1.391 sec)
5.120... logprob:  0.724431, 0.326823 (1.392 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.445658, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.762096e-03 [3.451285e-07] 
Layer 'conv1' biases: 6.819097e-07 [1.133885e-09] 
Layer 'conv2' weights[0]: 6.750552e-03 [3.418098e-07] 
Layer 'conv2' biases: 9.999998e-01 [8.293243e-09] 
Layer 'conv3' weights[0]: 6.749475e-03 [3.428594e-07] 
Layer 'conv3' biases: 1.503279e-05 [3.296583e-08] 
Layer 'conv4' weights[0]: 6.776742e-03 [3.468039e-07] 
Layer 'conv4' biases: 1.000017e+00 [3.320707e-07] 
Layer 'conv5' weights[0]: 6.799088e-03 [2.364588e-06] 
Layer 'conv5' biases: 9.993882e-01 [2.472314e-06] 
Layer 'fc6' weights[0]: 7.463312e-03 [5.748012e-08] 
Layer 'fc6' biases: 9.999990e-01 [5.178670e-08] 
Layer 'fc7' weights[0]: 7.818703e-03 [1.209947e-07] 
Layer 'fc7' biases: 9.999458e-01 [1.439592e-07] 
Layer 'fc8' weights[0]: 3.609440e-03 [1.993182e-05] 
Layer 'fc8' biases: 5.680684e-03 [3.101039e-05] 
Train error last 800 batches: 0.654986
-------------------------------------------------------
Not saving because 0.445658 > 0.303240 (5.60: -6.35%)
======================================================= (2.372 sec)
5.121... logprob:  0.629617, 0.259115 (1.401 sec)
5.122... logprob:  0.686008, 0.298177 (1.443 sec)
5.123... logprob:  0.680984, 0.286458 (1.380 sec)
5.124... logprob:  0.652639, 0.279948 (1.403 sec)
5.125... logprob:  0.652068, 0.287760 (1.398 sec)
5.126... logprob:  0.551763, 0.238281 (1.382 sec)
5.127... logprob:  0.726009, 0.294271 (1.393 sec)
5.128... logprob:  0.628555, 0.259115 (1.411 sec)
5.129... logprob:  0.744633, 0.302083 (1.407 sec)
5.130... logprob:  0.562646, 0.261719 (1.412 sec)
5.131... logprob:  0.669408, 0.291667 (1.411 sec)
5.132... logprob:  0.891534, 0.371094 (1.428 sec)
5.133... logprob:  0.681966, 0.296875 (1.380 sec)
5.134... logprob:  0.610374, 0.252604 (1.393 sec)
5.135... logprob:  0.611299, 0.283854 (1.396 sec)
5.136... logprob:  0.825989, 0.360677 (1.392 sec)
5.137... logprob:  0.741311, 0.278646 (1.380 sec)
5.138... logprob:  0.586674, 0.283854 (1.438 sec)
5.139... logprob:  0.581067, 0.252604 (1.389 sec)
5.140... logprob:  0.730630, 0.312500 (1.416 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.455604, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.755372e-03 [3.455659e-07] 
Layer 'conv1' biases: 6.868321e-07 [1.499012e-09] 
Layer 'conv2' weights[0]: 6.743814e-03 [3.414716e-07] 
Layer 'conv2' biases: 9.999998e-01 [8.692921e-09] 
Layer 'conv3' weights[0]: 6.742774e-03 [3.420430e-07] 
Layer 'conv3' biases: 1.509768e-05 [3.241277e-08] 
Layer 'conv4' weights[0]: 6.770047e-03 [3.473697e-07] 
Layer 'conv4' biases: 1.000018e+00 [3.589040e-07] 
Layer 'conv5' weights[0]: 6.792823e-03 [2.397295e-06] 
Layer 'conv5' biases: 9.993826e-01 [2.527247e-06] 
Layer 'fc6' weights[0]: 7.462520e-03 [5.827868e-08] 
Layer 'fc6' biases: 9.999989e-01 [5.306394e-08] 
Layer 'fc7' weights[0]: 7.817954e-03 [1.227693e-07] 
Layer 'fc7' biases: 9.999452e-01 [1.443704e-07] 
Layer 'fc8' weights[0]: 3.590335e-03 [1.881187e-05] 
Layer 'fc8' biases: 5.550725e-03 [2.618519e-05] 
Train error last 800 batches: 0.654819
-------------------------------------------------------
Not saving because 0.455604 > 0.303240 (5.60: -6.35%)
======================================================= (2.396 sec)
5.141... logprob:  0.682658, 0.307292 (1.442 sec)
5.142... logprob:  0.678011, 0.279948 (1.396 sec)
5.143... logprob:  0.557320, 0.252604 (1.421 sec)
5.144... logprob:  0.679646, 0.309896 (1.412 sec)
5.145... logprob:  0.572048, 0.248698 (1.412 sec)
5.146... logprob:  0.723028, 0.335938 (1.407 sec)
5.147... logprob:  0.510146, 0.231771 (1.423 sec)
5.148... logprob:  0.664937, 0.269531 (1.385 sec)
5.149... logprob:  0.675127, 0.324219 (1.389 sec)
5.150... logprob:  0.550820, 0.263021 (1.393 sec)
5.151... logprob:  0.614577, 0.263021 (1.395 sec)
5.152... logprob:  0.851411, 0.361979 (1.379 sec)
5.153... logprob:  0.630113, 0.256510 (1.448 sec)
5.154... logprob:  0.714727, 0.315104 (1.391 sec)
5.155... logprob:  0.658988, 0.309896 (1.402 sec)
5.156... logprob:  0.508479, 0.222656 (1.433 sec)
5.157... logprob:  0.512038, 0.250000 (1.395 sec)
5.158... logprob:  0.598569, 0.268229 (1.395 sec)
5.159... logprob:  0.683702, 0.303385 (1.392 sec)
5.160... logprob:  0.742070, 0.311198 (1.387 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.498289, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.748584e-03 [3.441638e-07] 
Layer 'conv1' biases: 6.860254e-07 [9.397895e-10] 
Layer 'conv2' weights[0]: 6.737029e-03 [3.399987e-07] 
Layer 'conv2' biases: 9.999998e-01 [7.172908e-09] 
Layer 'conv3' weights[0]: 6.735978e-03 [3.409519e-07] 
Layer 'conv3' biases: 1.505213e-05 [2.839312e-08] 
Layer 'conv4' weights[0]: 6.763208e-03 [3.446599e-07] 
Layer 'conv4' biases: 1.000017e+00 [3.007580e-07] 
Layer 'conv5' weights[0]: 6.786094e-03 [2.013542e-06] 
Layer 'conv5' biases: 9.993737e-01 [2.073779e-06] 
Layer 'fc6' weights[0]: 7.461729e-03 [5.577944e-08] 
Layer 'fc6' biases: 9.999990e-01 [4.936950e-08] 
Layer 'fc7' weights[0]: 7.817206e-03 [1.175340e-07] 
Layer 'fc7' biases: 9.999468e-01 [1.310231e-07] 
Layer 'fc8' weights[0]: 3.673994e-03 [1.787506e-05] 
Layer 'fc8' biases: 5.956207e-03 [1.677678e-05] 
Train error last 800 batches: 0.654452
-------------------------------------------------------
Not saving because 0.498289 > 0.303240 (5.60: -6.35%)
======================================================= (2.394 sec)
5.161... logprob:  0.569433, 0.253906 (1.399 sec)
5.162... logprob:  0.763292, 0.326823 (1.411 sec)
5.163... logprob:  0.670471, 0.285156 (1.427 sec)
5.164... logprob:  0.689213, 0.317708 (1.429 sec)
5.165... logprob:  0.747762, 0.299479 (1.423 sec)
5.166... logprob:  0.651003, 0.269531 (1.462 sec)
5.167... logprob:  0.590165, 0.243490 (1.436 sec)
5.168... logprob:  0.642057, 0.309896 (1.429 sec)
5.169... logprob:  0.640087, 0.305990 (1.459 sec)
5.170... logprob:  0.636522, 0.268229 (1.413 sec)
5.171... logprob:  0.729110, 0.332031 (1.537 sec)
5.172... logprob:  0.724950, 0.308594 (1.424 sec)
5.173... logprob:  0.648814, 0.279948 (1.483 sec)
5.174... logprob:  0.743302, 0.299479 (1.449 sec)
5.175... logprob:  0.695826, 0.319010 (1.518 sec)
5.176... logprob:  0.691788, 0.316406 (1.461 sec)
5.177... logprob:  0.490662, 0.226562 (1.455 sec)
5.178... logprob:  0.634280, 0.289062 (1.539 sec)
5.179... logprob:  0.657264, 0.316406 (2.544 sec)
5.180... logprob:  0.675606, 0.289062 (1.655 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.473311, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.741829e-03 [3.442251e-07] 
Layer 'conv1' biases: 6.851031e-07 [1.358894e-09] 
Layer 'conv2' weights[0]: 6.730250e-03 [3.407200e-07] 
Layer 'conv2' biases: 9.999998e-01 [8.917624e-09] 
Layer 'conv3' weights[0]: 6.729216e-03 [3.418367e-07] 
Layer 'conv3' biases: 1.510224e-05 [3.455039e-08] 
Layer 'conv4' weights[0]: 6.756477e-03 [3.467779e-07] 
Layer 'conv4' biases: 1.000018e+00 [3.878409e-07] 
Layer 'conv5' weights[0]: 6.779739e-03 [2.473991e-06] 
Layer 'conv5' biases: 9.993771e-01 [2.566770e-06] 
Layer 'fc6' weights[0]: 7.460932e-03 [5.963239e-08] 
Layer 'fc6' biases: 9.999990e-01 [5.512011e-08] 
Layer 'fc7' weights[0]: 7.816446e-03 [1.318644e-07] 
Layer 'fc7' biases: 9.999456e-01 [1.837184e-07] 
Layer 'fc8' weights[0]: 3.648071e-03 [2.572705e-05] 
Layer 'fc8' biases: 5.850096e-03 [5.305664e-05] 
Train error last 800 batches: 0.654862
-------------------------------------------------------
Not saving because 0.473311 > 0.303240 (5.60: -6.35%)
======================================================= (2.463 sec)
5.181... logprob:  0.655476, 0.266927 (1.487 sec)
5.182... logprob:  0.541055, 0.235677 (1.488 sec)
5.183... logprob:  0.623793, 0.305990 (1.415 sec)
5.184... logprob:  0.716153, 0.296875 (1.427 sec)
5.185... logprob:  0.622289, 0.263021 (1.400 sec)
5.186... logprob:  0.614601, 0.273437 (1.410 sec)
5.187... logprob:  0.688180, 0.296875 (1.399 sec)
5.188... logprob:  0.771558, 0.348958 (1.398 sec)
5.189... logprob:  0.684587, 0.290364 (1.465 sec)
5.190... logprob:  0.598846, 0.239583 (1.433 sec)
5.191... logprob:  0.660152, 0.278646 (1.422 sec)
5.192... logprob:  0.721883, 0.292969 (1.427 sec)
5.193... logprob:  0.517548, 0.260417 (1.436 sec)
5.194... logprob:  0.576119, 0.247396 (1.416 sec)
5.195... logprob:  0.520339, 0.255208 (1.400 sec)
5.196... logprob:  0.639684, 0.291667 (1.393 sec)
5.197... logprob:  0.720941, 0.302083 (1.401 sec)
5.198... logprob:  0.596395, 0.276042 (1.405 sec)
5.199... logprob:  0.562363, 0.230469 (1.408 sec)
5.200... logprob:  0.703583, 0.302083 (1.440 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.444517, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.735087e-03 [3.411309e-07] 
Layer 'conv1' biases: 6.847675e-07 [9.939723e-10] 
Layer 'conv2' weights[0]: 6.723592e-03 [3.390213e-07] 
Layer 'conv2' biases: 9.999998e-01 [6.806651e-09] 
Layer 'conv3' weights[0]: 6.722532e-03 [3.394443e-07] 
Layer 'conv3' biases: 1.519511e-05 [2.561826e-08] 
Layer 'conv4' weights[0]: 6.749701e-03 [3.437582e-07] 
Layer 'conv4' biases: 1.000019e+00 [3.032392e-07] 
Layer 'conv5' weights[0]: 6.773225e-03 [2.129277e-06] 
Layer 'conv5' biases: 9.993686e-01 [2.331663e-06] 
Layer 'fc6' weights[0]: 7.460147e-03 [5.454865e-08] 
Layer 'fc6' biases: 9.999989e-01 [4.722212e-08] 
Layer 'fc7' weights[0]: 7.815675e-03 [1.134232e-07] 
Layer 'fc7' biases: 9.999461e-01 [1.248043e-07] 
Layer 'fc8' weights[0]: 3.678422e-03 [1.563532e-05] 
Layer 'fc8' biases: 5.982616e-03 [1.347530e-05] 
Train error last 800 batches: 0.654560
-------------------------------------------------------
Not saving because 0.444517 > 0.303240 (5.60: -6.35%)
======================================================= (2.387 sec)
5.201... logprob:  0.608366, 0.282552 (1.413 sec)
5.202... logprob:  0.780486, 0.321615 (1.414 sec)
5.203... logprob:  0.586619, 0.273438 (1.439 sec)
5.204... logprob:  0.628106, 0.276042 (1.398 sec)
5.205... logprob:  0.541707, 0.234375 (1.406 sec)
5.206... logprob:  0.588000, 0.257812 (1.425 sec)
5.207... logprob:  0.653070, 0.274740 (1.401 sec)
5.208... logprob:  0.830808, 0.335937 (1.399 sec)
5.209... logprob:  0.611899, 0.292969 (1.422 sec)
5.210... logprob:  0.719162, 0.291667 (1.420 sec)
5.211... logprob:  0.682977, 0.300781 (1.426 sec)
5.212... logprob:  0.669121, 0.296875 (1.418 sec)
5.213... logprob:  0.752193, 0.338542 (1.460 sec)
5.214... logprob:  0.599634, 0.298177 (1.431 sec)
5.215... logprob:  0.531319, 0.246094 (1.416 sec)
5.216... logprob:  0.731469, 0.303385 (1.478 sec)
5.217... logprob:  0.491554, 0.230469 (1.421 sec)
5.218... logprob:  0.660020, 0.261719 (1.432 sec)
5.219... logprob:  0.642007, 0.279948 (1.417 sec)
5.220... logprob:  0.621266, 0.302083 (1.456 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.504844, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.728366e-03 [3.397351e-07] 
Layer 'conv1' biases: 6.854605e-07 [1.101031e-09] 
Layer 'conv2' weights[0]: 6.716847e-03 [3.383657e-07] 
Layer 'conv2' biases: 9.999998e-01 [7.161463e-09] 
Layer 'conv3' weights[0]: 6.715828e-03 [3.385340e-07] 
Layer 'conv3' biases: 1.519006e-05 [2.506223e-08] 
Layer 'conv4' weights[0]: 6.742939e-03 [3.422170e-07] 
Layer 'conv4' biases: 1.000019e+00 [2.779087e-07] 
Layer 'conv5' weights[0]: 6.766365e-03 [1.857819e-06] 
Layer 'conv5' biases: 9.993722e-01 [1.924090e-06] 
Layer 'fc6' weights[0]: 7.459389e-03 [5.438774e-08] 
Layer 'fc6' biases: 9.999990e-01 [4.711077e-08] 
Layer 'fc7' weights[0]: 7.814919e-03 [1.130244e-07] 
Layer 'fc7' biases: 9.999452e-01 [1.205985e-07] 
Layer 'fc8' weights[0]: 3.644781e-03 [1.547179e-05] 
Layer 'fc8' biases: 5.766357e-03 [1.331678e-05] 
Train error last 800 batches: 0.654339
-------------------------------------------------------
Not saving because 0.504844 > 0.303240 (5.60: -6.35%)
======================================================= (2.381 sec)
5.221... logprob:  0.587794, 0.264323 (1.405 sec)
5.222... logprob:  0.781787, 0.338542 (1.467 sec)
5.223... logprob:  0.787625, 0.354167 (1.451 sec)
5.224... logprob:  0.652649, 0.289063 (1.433 sec)
5.225... logprob:  0.598654, 0.244792 (1.480 sec)
5.226... logprob:  0.659242, 0.299479 (1.425 sec)
5.227... logprob:  0.655803, 0.286458 (1.416 sec)
5.228... logprob:  0.699011, 0.304688 (1.409 sec)
5.229... logprob:  0.731712, 0.315104 (1.428 sec)
5.230... logprob:  0.676120, 0.282552 (1.423 sec)
5.231... logprob:  0.562638, 0.257812 (1.409 sec)
5.232... logprob:  0.722933, 0.317708 (1.459 sec)
5.233... logprob:  0.723949, 0.325521 (1.438 sec)
5.234... logprob:  0.753828, 0.325521 (1.426 sec)
5.235... logprob:  0.662773, 0.289062 (1.496 sec)
5.236... logprob:  0.684301, 0.285156 (1.409 sec)
5.237... logprob:  0.552465, 0.250000 (1.425 sec)
5.238... logprob:  0.650931, 0.285156 (1.418 sec)
5.239... logprob:  0.681713, 0.305990 (1.430 sec)
5.240... logprob:  0.680350, 0.287760 (1.406 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.420146, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.721673e-03 [3.446113e-07] 
Layer 'conv1' biases: 6.872451e-07 [1.221424e-09] 
Layer 'conv2' weights[0]: 6.710179e-03 [3.388893e-07] 
Layer 'conv2' biases: 9.999998e-01 [7.570356e-09] 
Layer 'conv3' weights[0]: 6.709152e-03 [3.407468e-07] 
Layer 'conv3' biases: 1.524801e-05 [3.506599e-08] 
Layer 'conv4' weights[0]: 6.736195e-03 [3.449081e-07] 
Layer 'conv4' biases: 1.000018e+00 [3.602298e-07] 
Layer 'conv5' weights[0]: 6.759717e-03 [2.262676e-06] 
Layer 'conv5' biases: 9.993738e-01 [2.419879e-06] 
Layer 'fc6' weights[0]: 7.458625e-03 [5.701563e-08] 
Layer 'fc6' biases: 9.999989e-01 [5.129857e-08] 
Layer 'fc7' weights[0]: 7.814137e-03 [1.214537e-07] 
Layer 'fc7' biases: 9.999449e-01 [1.417818e-07] 
Layer 'fc8' weights[0]: 3.641061e-03 [1.822889e-05] 
Layer 'fc8' biases: 5.666653e-03 [2.515793e-05] 
Train error last 800 batches: 0.654196
-------------------------------------------------------
Not saving because 0.420146 > 0.303240 (5.60: -6.35%)
======================================================= (2.403 sec)
5.241... logprob:  0.608310, 0.259115 (1.462 sec)
5.242... logprob:  0.573321, 0.269531 (1.447 sec)
5.243... logprob:  0.597606, 0.250000 (1.433 sec)
5.244... logprob:  0.548472, 0.230469 (1.446 sec)
5.245... logprob:  0.667107, 0.294271 (1.431 sec)
5.246... logprob:  0.599793, 0.264323 (1.418 sec)
5.247... logprob:  0.570636, 0.287760 (1.419 sec)
5.248... logprob:  0.538529, 0.252604 (1.417 sec)
5.249... logprob:  0.732892, 0.315104 (1.424 sec)
5.250... logprob:  0.728593, 0.309896 (1.408 sec)
5.251... logprob:  0.559974, 0.259115 (1.463 sec)
5.252... logprob:  0.598599, 0.281250 (1.430 sec)
5.253... logprob:  0.518477, 0.242187 (1.425 sec)
5.254... logprob:  0.657600, 0.296875 (1.490 sec)
5.255... logprob:  0.579035, 0.242187 (1.404 sec)
5.256... logprob:  0.544533, 0.268229 (1.419 sec)
5.257... logprob:  0.591938, 0.292969 (1.408 sec)
5.258... logprob:  0.675442, 0.282552 (1.418 sec)
5.259... logprob:  0.557769, 0.234375 (1.397 sec)
5.260... logprob:  0.577984, 0.252604 (1.461 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.451278, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.714943e-03 [3.429362e-07] 
Layer 'conv1' biases: 6.907269e-07 [1.183941e-09] 
Layer 'conv2' weights[0]: 6.703431e-03 [3.390247e-07] 
Layer 'conv2' biases: 9.999998e-01 [7.403629e-09] 
Layer 'conv3' weights[0]: 6.702392e-03 [3.398733e-07] 
Layer 'conv3' biases: 1.530605e-05 [3.181648e-08] 
Layer 'conv4' weights[0]: 6.729466e-03 [3.439310e-07] 
Layer 'conv4' biases: 1.000019e+00 [3.242194e-07] 
Layer 'conv5' weights[0]: 6.752977e-03 [2.082998e-06] 
Layer 'conv5' biases: 9.993671e-01 [2.185607e-06] 
Layer 'fc6' weights[0]: 7.457820e-03 [5.371676e-08] 
Layer 'fc6' biases: 9.999990e-01 [4.598056e-08] 
Layer 'fc7' weights[0]: 7.813348e-03 [1.112488e-07] 
Layer 'fc7' biases: 9.999462e-01 [1.196545e-07] 
Layer 'fc8' weights[0]: 3.764935e-03 [1.536604e-05] 
Layer 'fc8' biases: 6.427079e-03 [1.146953e-05] 
Train error last 800 batches: 0.653480
-------------------------------------------------------
Not saving because 0.451278 > 0.303240 (5.60: -6.35%)
======================================================= (2.392 sec)
5.261... logprob:  0.581124, 0.240885 (1.435 sec)
5.262... logprob:  0.731294, 0.299479 (1.432 sec)
5.263... logprob:  0.642532, 0.259114 (1.451 sec)
5.264... logprob:  0.594019, 0.265625 (1.431 sec)
5.265... logprob:  0.728301, 0.308594 (1.424 sec)
5.266... logprob:  0.693782, 0.300781 (1.418 sec)
5.267... logprob:  0.640974, 0.303385 (1.420 sec)
5.268... logprob:  0.607453, 0.273438 (1.428 sec)
5.269... logprob:  0.785786, 0.343750 (1.420 sec)
5.270... logprob:  0.761116, 0.287760 (1.467 sec)
5.271... logprob:  0.626673, 0.282552 (1.439 sec)
5.272... logprob:  0.662769, 0.266927 (1.425 sec)
5.273... logprob:  0.791867, 0.317708 (1.477 sec)
5.274... logprob:  0.750062, 0.330729 (1.416 sec)
5.275... logprob:  0.744384, 0.305990 (1.431 sec)
5.276... logprob:  0.643414, 0.277344 (1.416 sec)
5.277... logprob:  0.675752, 0.295573 (1.423 sec)
5.278... logprob:  0.538723, 0.272135 (1.424 sec)
5.279... logprob:  0.553163, 0.229167 (1.464 sec)
5.280... logprob:  0.540547, 0.261719 (1.419 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.478608, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.708234e-03 [3.407745e-07] 
Layer 'conv1' biases: 6.967750e-07 [1.789429e-09] 
Layer 'conv2' weights[0]: 6.696748e-03 [3.399832e-07] 
Layer 'conv2' biases: 9.999998e-01 [1.091102e-08] 
Layer 'conv3' weights[0]: 6.695685e-03 [3.434655e-07] 
Layer 'conv3' biases: 1.534832e-05 [4.338720e-08] 
Layer 'conv4' weights[0]: 6.722774e-03 [3.499262e-07] 
Layer 'conv4' biases: 1.000019e+00 [4.650204e-07] 
Layer 'conv5' weights[0]: 6.747159e-03 [3.058262e-06] 
Layer 'conv5' biases: 9.993752e-01 [3.238058e-06] 
Layer 'fc6' weights[0]: 7.457072e-03 [6.814518e-08] 
Layer 'fc6' biases: 9.999989e-01 [6.703826e-08] 
Layer 'fc7' weights[0]: 7.812542e-03 [1.535729e-07] 
Layer 'fc7' biases: 9.999433e-01 [2.518152e-07] 
Layer 'fc8' weights[0]: 3.615073e-03 [2.615620e-05] 
Layer 'fc8' biases: 5.543920e-03 [5.026036e-05] 
Train error last 800 batches: 0.653898
-------------------------------------------------------
Not saving because 0.478608 > 0.303240 (5.60: -6.35%)
======================================================= (2.353 sec)
5.281... logprob:  0.670538, 0.291667 (1.434 sec)
5.282... logprob:  0.575279, 0.231771 (1.417 sec)
5.283... logprob:  0.654161, 0.274740 (1.486 sec)
5.284... logprob:  0.685644, 0.286458 (1.428 sec)
5.285... logprob:  0.691461, 0.300781 (1.438 sec)
5.286... logprob:  0.676615, 0.286458 (1.436 sec)
5.287... logprob:  0.619167, 0.276042 (1.429 sec)
5.288... logprob:  0.515673, 0.227865 (1.426 sec)
5.289... logprob:  0.667026, 0.300781 (1.440 sec)
5.290... logprob:  0.680643, 0.305990 (1.504 sec)
5.291... logprob:  0.629353, 0.298177 (1.420 sec)
5.292... logprob:  0.776573, 0.342448 (1.438 sec)
5.293... logprob:  0.670938, 0.305990 (1.420 sec)
5.294... logprob:  0.566312, 0.235677 (1.408 sec)
5.295... logprob:  0.663897, 0.312500 (1.463 sec)
5.296... logprob:  0.519735, 0.220052 (1.419 sec)
5.297... logprob:  0.579889, 0.234375 (1.423 sec)
5.298... logprob:  0.733328, 0.307292 (1.463 sec)
5.299... logprob:  0.520874, 0.235677 (1.400 sec)
5.300... logprob:  0.583547, 0.265625 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.458052, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.701552e-03 [3.415227e-07] 
Layer 'conv1' biases: 7.018554e-07 [1.414017e-09] 
Layer 'conv2' weights[0]: 6.690017e-03 [3.389498e-07] 
Layer 'conv2' biases: 9.999998e-01 [8.216346e-09] 
Layer 'conv3' weights[0]: 6.688953e-03 [3.389619e-07] 
Layer 'conv3' biases: 1.537778e-05 [2.966220e-08] 
Layer 'conv4' weights[0]: 6.716074e-03 [3.432091e-07] 
Layer 'conv4' biases: 1.000018e+00 [3.175717e-07] 
Layer 'conv5' weights[0]: 6.740227e-03 [2.311726e-06] 
Layer 'conv5' biases: 9.993709e-01 [2.439921e-06] 
Layer 'fc6' weights[0]: 7.456303e-03 [5.561431e-08] 
Layer 'fc6' biases: 9.999989e-01 [4.901326e-08] 
Layer 'fc7' weights[0]: 7.811757e-03 [1.175448e-07] 
Layer 'fc7' biases: 9.999443e-01 [1.387651e-07] 
Layer 'fc8' weights[0]: 3.718120e-03 [1.763204e-05] 
Layer 'fc8' biases: 6.141294e-03 [2.491021e-05] 
Train error last 800 batches: 0.653252
-------------------------------------------------------
Not saving because 0.458052 > 0.303240 (5.60: -6.35%)
======================================================= (2.427 sec)
5.301... logprob:  0.549215, 0.227865 (1.422 sec)
5.302... logprob:  0.815901, 0.358073 (1.440 sec)
5.303... logprob:  0.615931, 0.264323 (1.414 sec)
5.304... logprob:  0.629426, 0.285156 (1.438 sec)
5.305... logprob:  0.771373, 0.315104 (1.434 sec)
5.306... logprob:  0.579736, 0.272135 (1.438 sec)
5.307... logprob:  0.649455, 0.256510 (1.450 sec)
5.308... logprob:  0.628465, 0.270833 (1.458 sec)
5.309... logprob:  0.739486, 0.319010 (1.413 sec)
5.310... logprob:  0.661834, 0.298177 (1.424 sec)
5.311... logprob:  0.753594, 0.347656 (1.437 sec)
5.312... logprob:  0.660201, 0.279948 (1.433 sec)
5.313... logprob:  0.669869, 0.265625 (1.422 sec)
5.314... logprob:  0.688479, 0.308594 (1.471 sec)
5.315... logprob:  0.528728, 0.231771 (1.440 sec)
5.316... logprob:  0.657646, 0.302083 (1.423 sec)
5.317... logprob:  0.666776, 0.312500 (1.480 sec)
5.318... logprob:  0.653662, 0.289062 (1.412 sec)
5.319... logprob:  0.730974, 0.303385 (1.422 sec)
5.320... logprob:  0.643992, 0.287760 (1.434 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.491781, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.694815e-03 [3.424107e-07] 
Layer 'conv1' biases: 7.019655e-07 [1.333316e-09] 
Layer 'conv2' weights[0]: 6.683342e-03 [3.376458e-07] 
Layer 'conv2' biases: 9.999997e-01 [6.933815e-09] 
Layer 'conv3' weights[0]: 6.682256e-03 [3.382231e-07] 
Layer 'conv3' biases: 1.541535e-05 [2.620941e-08] 
Layer 'conv4' weights[0]: 6.709352e-03 [3.425110e-07] 
Layer 'conv4' biases: 1.000018e+00 [3.149553e-07] 
Layer 'conv5' weights[0]: 6.733916e-03 [2.118773e-06] 
Layer 'conv5' biases: 9.993725e-01 [2.175429e-06] 
Layer 'fc6' weights[0]: 7.455521e-03 [5.811412e-08] 
Layer 'fc6' biases: 9.999989e-01 [5.262300e-08] 
Layer 'fc7' weights[0]: 7.810943e-03 [1.248621e-07] 
Layer 'fc7' biases: 9.999430e-01 [1.478949e-07] 
Layer 'fc8' weights[0]: 3.665311e-03 [1.871639e-05] 
Layer 'fc8' biases: 5.818729e-03 [2.427351e-05] 
Train error last 800 batches: 0.653721
-------------------------------------------------------
Not saving because 0.491781 > 0.303240 (5.60: -6.35%)
======================================================= (2.347 sec)
5.321... logprob:  0.591435, 0.263021 (1.454 sec)
5.322... logprob:  0.578424, 0.261719 (1.416 sec)
5.323... logprob:  0.571407, 0.231771 (1.472 sec)
5.324... logprob:  0.678556, 0.291667 (1.428 sec)
5.325... logprob:  0.626914, 0.277344 (1.449 sec)
5.326... logprob:  0.735929, 0.354167 (1.466 sec)
5.327... logprob:  0.685135, 0.274740 (1.429 sec)
5.328... logprob:  0.654359, 0.269531 (1.421 sec)
5.329... logprob:  0.622936, 0.272135 (1.420 sec)
5.330... logprob:  0.646635, 0.274740 (1.454 sec)
5.331... logprob:  0.606890, 0.274740 (1.431 sec)
5.332... logprob:  0.740520, 0.332031 (1.448 sec)
5.333... logprob:  0.602656, 0.260417 (1.446 sec)
5.334... logprob:  0.743520, 0.317708 (1.444 sec)
5.335... logprob:  0.586990, 0.283854 (1.449 sec)
5.336... logprob:  0.719676, 0.302083 (1.455 sec)
5.337... logprob:  0.842455, 0.355469 (1.419 sec)
5.338... logprob:  0.748274, 0.307292 (1.420 sec)
5.339... logprob:  0.721352, 0.322917 (1.426 sec)
5.340... logprob:  0.642690, 0.286458 (1.425 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.570306, 0.171875 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.688147e-03 [3.410206e-07] 
Layer 'conv1' biases: 7.072282e-07 [1.490519e-09] 
Layer 'conv2' weights[0]: 6.676667e-03 [3.380073e-07] 
Layer 'conv2' biases: 9.999997e-01 [9.352637e-09] 
Layer 'conv3' weights[0]: 6.675608e-03 [3.397121e-07] 
Layer 'conv3' biases: 1.543901e-05 [3.546661e-08] 
Layer 'conv4' weights[0]: 6.702607e-03 [3.440616e-07] 
Layer 'conv4' biases: 1.000018e+00 [3.802985e-07] 
Layer 'conv5' weights[0]: 6.727360e-03 [2.681935e-06] 
Layer 'conv5' biases: 9.993716e-01 [2.752163e-06] 
Layer 'fc6' weights[0]: 7.454737e-03 [6.062941e-08] 
Layer 'fc6' biases: 9.999989e-01 [5.661601e-08] 
Layer 'fc7' weights[0]: 7.810206e-03 [1.309546e-07] 
Layer 'fc7' biases: 9.999435e-01 [1.655469e-07] 
Layer 'fc8' weights[0]: 3.683537e-03 [2.098019e-05] 
Layer 'fc8' biases: 5.875810e-03 [2.599894e-05] 
Train error last 800 batches: 0.654087
-------------------------------------------------------
Not saving because 0.570306 > 0.303240 (5.60: -6.35%)
======================================================= (2.372 sec)
5.341... logprob:  0.733698, 0.298177 (1.422 sec)
5.342... logprob:  0.654520, 0.285156 (1.472 sec)
5.343... logprob:  0.659549, 0.305989 (1.440 sec)
5.344... logprob:  0.663949, 0.276042 (1.488 sec)
5.345... logprob:  0.771278, 0.319010 (1.438 sec)
5.346... logprob:  0.653187, 0.291667 (1.429 sec)
5.347... logprob:  0.599825, 0.240885 (1.493 sec)
5.348... logprob:  0.676907, 0.296875 (1.433 sec)
5.349... logprob:  0.726569, 0.320312 (1.438 sec)
5.350... logprob:  0.553733, 0.269531 (1.446 sec)
5.351... logprob:  0.707572, 0.325521 (1.429 sec)
5.352... logprob:  0.552953, 0.244792 (1.435 sec)
5.353... logprob:  0.787693, 0.355469 (1.490 sec)
5.354... logprob:  0.750767, 0.296875 (1.433 sec)
5.355... logprob:  0.606139, 0.231771 (1.450 sec)
5.356... logprob:  0.757019, 0.309896 (1.479 sec)
5.357... logprob:  0.606248, 0.252604 (1.439 sec)
5.358... logprob:  0.494499, 0.204427 (1.440 sec)
5.359... logprob:  0.776060, 0.302083 (1.436 sec)
5.360... logprob:  0.597949, 0.247396 (1.425 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.483430, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.681467e-03 [3.412241e-07] 
Layer 'conv1' biases: 7.142104e-07 [1.554395e-09] 
Layer 'conv2' weights[0]: 6.670020e-03 [3.390295e-07] 
Layer 'conv2' biases: 9.999997e-01 [9.718288e-09] 
Layer 'conv3' weights[0]: 6.668969e-03 [3.391426e-07] 
Layer 'conv3' biases: 1.561725e-05 [3.426386e-08] 
Layer 'conv4' weights[0]: 6.695907e-03 [3.437987e-07] 
Layer 'conv4' biases: 1.000019e+00 [3.294172e-07] 
Layer 'conv5' weights[0]: 6.721299e-03 [2.269076e-06] 
Layer 'conv5' biases: 9.993683e-01 [2.333755e-06] 
Layer 'fc6' weights[0]: 7.453947e-03 [5.701119e-08] 
Layer 'fc6' biases: 9.999989e-01 [5.095271e-08] 
Layer 'fc7' weights[0]: 7.809389e-03 [1.223755e-07] 
Layer 'fc7' biases: 9.999419e-01 [1.313977e-07] 
Layer 'fc8' weights[0]: 3.644470e-03 [1.712221e-05] 
Layer 'fc8' biases: 5.696129e-03 [8.075565e-06] 
Train error last 800 batches: 0.654292
-------------------------------------------------------
Not saving because 0.483430 > 0.303240 (5.60: -6.35%)
======================================================= (2.396 sec)
5.361... logprob:  0.683071, 0.295573 (1.441 sec)
5.362... logprob:  0.657519, 0.291667 (1.480 sec)
5.363... logprob:  0.645270, 0.278646 (1.443 sec)
5.364... logprob:  0.766097, 0.328125 (1.459 sec)
5.365... logprob:  0.637196, 0.257812 (1.471 sec)
5.366... logprob:  0.669434, 0.324219 (1.451 sec)
5.367... logprob:  0.598994, 0.276042 (1.440 sec)
5.368... logprob:  0.781330, 0.287760 (1.443 sec)
5.369... logprob:  0.636001, 0.246094 (1.431 sec)
5.370... logprob:  0.595576, 0.270833 (1.444 sec)
5.371... logprob:  0.599360, 0.263021 (1.466 sec)
5.372... logprob:  0.704225, 0.283854 (1.457 sec)
5.373... logprob:  0.698091, 0.290365 (1.463 sec)
5.374... logprob:  0.659527, 0.302083 (1.452 sec)
5.375... logprob:  0.702954, 0.285156 (1.467 sec)
5.376... logprob:  0.567674, 0.265625 (1.449 sec)
5.377... logprob:  0.600388, 0.281250 (1.428 sec)
5.378... logprob:  0.707056, 0.302083 (1.428 sec)
5.379... logprob:  0.625659, 0.279948 (1.440 sec)
5.380... logprob:  0.790248, 0.330729 (1.474 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.492015, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.674799e-03 [3.397553e-07] 
Layer 'conv1' biases: 7.191088e-07 [1.519588e-09] 
Layer 'conv2' weights[0]: 6.663334e-03 [3.381260e-07] 
Layer 'conv2' biases: 9.999997e-01 [9.770951e-09] 
Layer 'conv3' weights[0]: 6.662266e-03 [3.393159e-07] 
Layer 'conv3' biases: 1.562383e-05 [3.470662e-08] 
Layer 'conv4' weights[0]: 6.689173e-03 [3.436861e-07] 
Layer 'conv4' biases: 1.000018e+00 [3.777925e-07] 
Layer 'conv5' weights[0]: 6.714577e-03 [2.422146e-06] 
Layer 'conv5' biases: 9.993594e-01 [2.578572e-06] 
Layer 'fc6' weights[0]: 7.453190e-03 [6.021844e-08] 
Layer 'fc6' biases: 9.999989e-01 [5.617641e-08] 
Layer 'fc7' weights[0]: 7.808554e-03 [1.287164e-07] 
Layer 'fc7' biases: 9.999421e-01 [1.570269e-07] 
Layer 'fc8' weights[0]: 3.662789e-03 [1.864908e-05] 
Layer 'fc8' biases: 5.849367e-03 [1.754524e-05] 
Train error last 800 batches: 0.654077
-------------------------------------------------------
Not saving because 0.492015 > 0.303240 (5.60: -6.35%)
======================================================= (2.377 sec)
5.381... logprob:  0.696910, 0.300781 (1.478 sec)
5.382... logprob:  0.704768, 0.321615 (1.452 sec)
5.383... logprob:  0.524201, 0.231771 (1.439 sec)
5.384... logprob:  0.727572, 0.319010 (1.483 sec)
5.385... logprob:  0.606367, 0.286458 (1.439 sec)
5.386... logprob:  0.807910, 0.345052 (1.437 sec)
5.387... logprob:  0.730704, 0.305990 (1.434 sec)
5.388... logprob:  0.749075, 0.316406 (1.444 sec)
5.389... logprob:  0.679766, 0.326823 (1.434 sec)
5.390... logprob:  0.675061, 0.307292 (1.482 sec)
5.391... logprob:  0.548408, 0.223958 (1.451 sec)
5.392... logprob:  0.664980, 0.295573 (1.437 sec)
5.393... logprob:  0.619487, 0.266927 (1.493 sec)
5.394... logprob:  0.558447, 0.242187 (1.478 sec)
5.395... logprob:  0.570491, 0.263021 (1.430 sec)
5.396... logprob:  0.528327, 0.257812 (1.443 sec)
5.397... logprob:  0.644572, 0.265625 (1.436 sec)
5.398... logprob:  0.610435, 0.266927 (1.439 sec)
5.399... logprob:  0.692957, 0.321615 (1.528 sec)
5.400... logprob:  0.680391, 0.322917 (1.449 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.481915, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.668119e-03 [3.392207e-07] 
Layer 'conv1' biases: 7.225538e-07 [1.413181e-09] 
Layer 'conv2' weights[0]: 6.656660e-03 [3.362651e-07] 
Layer 'conv2' biases: 9.999997e-01 [8.853594e-09] 
Layer 'conv3' weights[0]: 6.655610e-03 [3.374665e-07] 
Layer 'conv3' biases: 1.558330e-05 [3.212270e-08] 
Layer 'conv4' weights[0]: 6.682515e-03 [3.441428e-07] 
Layer 'conv4' biases: 1.000016e+00 [4.188260e-07] 
Layer 'conv5' weights[0]: 6.707466e-03 [2.687385e-06] 
Layer 'conv5' biases: 9.993573e-01 [2.841557e-06] 
Layer 'fc6' weights[0]: 7.452403e-03 [6.041151e-08] 
Layer 'fc6' biases: 9.999989e-01 [5.649700e-08] 
Layer 'fc7' weights[0]: 7.807764e-03 [1.338355e-07] 
Layer 'fc7' biases: 9.999429e-01 [1.896776e-07] 
Layer 'fc8' weights[0]: 3.727444e-03 [2.337178e-05] 
Layer 'fc8' biases: 6.129606e-03 [4.141149e-05] 
Train error last 800 batches: 0.654070
-------------------------------------------------------
Not saving because 0.481915 > 0.303240 (5.60: -6.35%)
======================================================= (2.354 sec)
5.401... logprob:  0.705445, 0.296875 (1.440 sec)
5.402... logprob:  0.673349, 0.274740 (1.477 sec)
5.403... logprob:  0.715497, 0.329427 (1.437 sec)
5.404... logprob:  0.599559, 0.248698 (1.431 sec)
5.405... logprob:  0.608480, 0.253906 (1.427 sec)
5.406... logprob:  0.639251, 0.292969 (1.458 sec)
5.407... logprob:  0.748631, 0.313802 (1.441 sec)
5.408... logprob:  0.529018, 0.217448 (1.475 sec)
5.409... logprob:  0.662458, 0.305990 (1.438 sec)
5.410... logprob:  0.757333, 0.292969 (1.451 sec)
5.411... logprob:  0.686477, 0.300781 (1.475 sec)
5.412... logprob:  0.690778, 0.305990 (1.437 sec)
5.413... logprob:  0.737107, 0.289062 (1.988 sec)
5.414... logprob:  0.705717, 0.294271 (1.433 sec)
5.415... logprob:  0.625195, 0.269531 (1.429 sec)
5.416... logprob:  0.692680, 0.289062 (1.436 sec)
5.417... logprob:  0.660121, 0.308594 (1.459 sec)
5.418... logprob:  0.524209, 0.230469 (1.461 sec)
5.419... logprob:  0.653636, 0.287760 (1.453 sec)
5.420... logprob:  0.573741, 0.261719 (1.461 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.510224, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.661458e-03 [3.377717e-07] 
Layer 'conv1' biases: 7.181852e-07 [1.217422e-09] 
Layer 'conv2' weights[0]: 6.650004e-03 [3.368085e-07] 
Layer 'conv2' biases: 9.999997e-01 [7.462781e-09] 
Layer 'conv3' weights[0]: 6.648976e-03 [3.377864e-07] 
Layer 'conv3' biases: 1.563075e-05 [3.276422e-08] 
Layer 'conv4' weights[0]: 6.675820e-03 [3.417564e-07] 
Layer 'conv4' biases: 1.000017e+00 [3.583696e-07] 
Layer 'conv5' weights[0]: 6.701020e-03 [2.558975e-06] 
Layer 'conv5' biases: 9.993584e-01 [2.758876e-06] 
Layer 'fc6' weights[0]: 7.451636e-03 [6.289671e-08] 
Layer 'fc6' biases: 9.999988e-01 [6.010499e-08] 
Layer 'fc7' weights[0]: 7.806984e-03 [1.447143e-07] 
Layer 'fc7' biases: 9.999410e-01 [2.157189e-07] 
Layer 'fc8' weights[0]: 3.681210e-03 [3.163504e-05] 
Layer 'fc8' biases: 5.837766e-03 [6.876791e-05] 
Train error last 800 batches: 0.653942
-------------------------------------------------------
Not saving because 0.510224 > 0.303240 (5.60: -6.35%)
======================================================= (2.395 sec)
5.421... logprob:  0.565584, 0.255208 (1.459 sec)
5.422... logprob:  0.641617, 0.281250 (1.446 sec)
5.423... logprob:  0.639792, 0.315104 (1.425 sec)
5.424... logprob:  0.591906, 0.263021 (1.430 sec)
5.425... logprob:  0.615446, 0.242187 (1.460 sec)
5.426... logprob:  0.637712, 0.302083 (1.455 sec)
5.427... logprob:  0.701324, 0.312500 (1.466 sec)
5.428... logprob:  0.730972, 0.346354 (1.463 sec)
5.429... logprob:  0.671343, 0.303385 (1.451 sec)
5.430... logprob:  0.555295, 0.240885 (1.475 sec)
5.431... logprob:  0.809479, 0.321615 (1.432 sec)
5.432... logprob:  0.655482, 0.263021 (1.434 sec)
5.433... logprob:  0.625453, 0.272135 (1.437 sec)
5.434... logprob:  0.784949, 0.338542 (1.435 sec)
5.435... logprob:  0.760570, 0.305990 (1.429 sec)
5.436... logprob:  0.630504, 0.303385 (1.479 sec)
5.437... logprob:  0.748779, 0.313802 (1.454 sec)
5.438... logprob:  0.679627, 0.296875 (1.430 sec)
5.439... logprob:  0.622386, 0.286458 (1.500 sec)
5.440... logprob:  0.695042, 0.304687 (1.432 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.513145, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.654793e-03 [3.375104e-07] 
Layer 'conv1' biases: 7.209309e-07 [1.467111e-09] 
Layer 'conv2' weights[0]: 6.643376e-03 [3.359374e-07] 
Layer 'conv2' biases: 9.999997e-01 [8.692926e-09] 
Layer 'conv3' weights[0]: 6.642327e-03 [3.377104e-07] 
Layer 'conv3' biases: 1.571376e-05 [3.506749e-08] 
Layer 'conv4' weights[0]: 6.669129e-03 [3.406644e-07] 
Layer 'conv4' biases: 1.000016e+00 [3.368218e-07] 
Layer 'conv5' weights[0]: 6.694007e-03 [2.335881e-06] 
Layer 'conv5' biases: 9.993633e-01 [2.410168e-06] 
Layer 'fc6' weights[0]: 7.450800e-03 [6.384563e-08] 
Layer 'fc6' biases: 9.999987e-01 [6.165050e-08] 
Layer 'fc7' weights[0]: 7.806203e-03 [1.445625e-07] 
Layer 'fc7' biases: 9.999403e-01 [2.108526e-07] 
Layer 'fc8' weights[0]: 3.657293e-03 [2.413775e-05] 
Layer 'fc8' biases: 5.667367e-03 [4.650993e-05] 
Train error last 800 batches: 0.654510
-------------------------------------------------------
Not saving because 0.513145 > 0.303240 (5.60: -6.35%)
======================================================= (2.359 sec)
5.441... logprob:  0.649219, 0.287760 (1.429 sec)
5.442... logprob:  0.585749, 0.240885 (1.443 sec)
5.443... logprob:  0.689954, 0.300781 (1.433 sec)
5.444... logprob:  0.571735, 0.261719 (1.441 sec)
5.445... logprob:  0.580162, 0.252604 (1.485 sec)
5.446... logprob:  0.665585, 0.302083 (1.438 sec)
5.447... logprob:  0.772934, 0.329427 (1.442 sec)
5.448... logprob:  0.551838, 0.217448 (1.485 sec)
5.449... logprob:  0.647994, 0.299479 (1.431 sec)
5.450... logprob:  0.558340, 0.257812 (1.460 sec)
5.451... logprob:  0.637185, 0.278646 (1.458 sec)
5.452... logprob:  0.686511, 0.309896 (1.499 sec)
5.453... logprob:  0.642154, 0.282552 (1.534 sec)
5.454... logprob:  0.680489, 0.292969 (1.592 sec)
5.455... logprob:  0.752742, 0.316406 (1.516 sec)
5.456... logprob:  0.668224, 0.285156 (1.455 sec)
5.457... logprob:  0.647823, 0.317708 (1.471 sec)
5.458... logprob:  0.608898, 0.304687 (1.449 sec)
5.459... logprob:  0.651297, 0.299479 (1.449 sec)
5.460... logprob:  0.525270, 0.250000 (1.434 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.395869, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.648148e-03 [3.356740e-07] 
Layer 'conv1' biases: 7.223683e-07 [8.199360e-10] 
Layer 'conv2' weights[0]: 6.636732e-03 [3.345711e-07] 
Layer 'conv2' biases: 9.999997e-01 [6.214192e-09] 
Layer 'conv3' weights[0]: 6.635688e-03 [3.345307e-07] 
Layer 'conv3' biases: 1.573270e-05 [2.332741e-08] 
Layer 'conv4' weights[0]: 6.662489e-03 [3.383999e-07] 
Layer 'conv4' biases: 1.000015e+00 [2.814388e-07] 
Layer 'conv5' weights[0]: 6.687300e-03 [2.097140e-06] 
Layer 'conv5' biases: 9.993608e-01 [2.240479e-06] 
Layer 'fc6' weights[0]: 7.450008e-03 [5.660903e-08] 
Layer 'fc6' biases: 9.999987e-01 [5.074553e-08] 
Layer 'fc7' weights[0]: 7.805414e-03 [1.207945e-07] 
Layer 'fc7' biases: 9.999421e-01 [1.568022e-07] 
Layer 'fc8' weights[0]: 3.740742e-03 [1.921771e-05] 
Layer 'fc8' biases: 6.185348e-03 [2.722066e-05] 
Train error last 800 batches: 0.654183
-------------------------------------------------------
Not saving because 0.395869 > 0.303240 (5.60: -6.35%)
======================================================= (2.370 sec)
5.461... logprob:  0.757714, 0.322917 (1.432 sec)
5.462... logprob:  0.689127, 0.291667 (1.434 sec)
5.463... logprob:  0.598114, 0.277344 (1.476 sec)
5.464... logprob:  0.672099, 0.287760 (1.453 sec)
5.465... logprob:  0.653578, 0.291667 (1.457 sec)
5.466... logprob:  0.559321, 0.277344 (1.458 sec)
5.467... logprob:  0.716128, 0.305990 (1.445 sec)
5.468... logprob:  0.721435, 0.317708 (1.438 sec)
5.469... logprob:  0.557924, 0.244792 (1.424 sec)
5.470... logprob:  0.608158, 0.242188 (1.433 sec)
5.471... logprob:  0.812278, 0.322917 (1.437 sec)
5.472... logprob:  0.617504, 0.282552 (1.458 sec)
5.473... logprob:  0.588832, 0.276042 (1.456 sec)
5.474... logprob:  0.676638, 0.299479 (1.476 sec)
5.475... logprob:  0.700708, 0.308594 (1.453 sec)
5.476... logprob:  0.667975, 0.303385 (1.480 sec)
5.477... logprob:  0.564557, 0.264323 (1.438 sec)
5.478... logprob:  0.663261, 0.289062 (1.419 sec)
5.479... logprob:  0.591515, 0.252604 (1.433 sec)
5.480... logprob:  0.718913, 0.328125 (1.435 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.439877, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.641519e-03 [3.359982e-07] 
Layer 'conv1' biases: 7.219667e-07 [9.671503e-10] 
Layer 'conv2' weights[0]: 6.630096e-03 [3.344341e-07] 
Layer 'conv2' biases: 9.999997e-01 [5.897281e-09] 
Layer 'conv3' weights[0]: 6.629106e-03 [3.340698e-07] 
Layer 'conv3' biases: 1.571603e-05 [2.121872e-08] 
Layer 'conv4' weights[0]: 6.655819e-03 [3.373026e-07] 
Layer 'conv4' biases: 1.000014e+00 [2.446280e-07] 
Layer 'conv5' weights[0]: 6.680510e-03 [1.944254e-06] 
Layer 'conv5' biases: 9.993607e-01 [1.916623e-06] 
Layer 'fc6' weights[0]: 7.449231e-03 [5.486746e-08] 
Layer 'fc6' biases: 9.999988e-01 [4.808182e-08] 
Layer 'fc7' weights[0]: 7.804622e-03 [1.141142e-07] 
Layer 'fc7' biases: 9.999412e-01 [1.196736e-07] 
Layer 'fc8' weights[0]: 3.723194e-03 [1.493154e-05] 
Layer 'fc8' biases: 6.072798e-03 [4.274441e-06] 
Train error last 800 batches: 0.654549
-------------------------------------------------------
Not saving because 0.439877 > 0.303240 (5.60: -6.35%)
======================================================= (2.424 sec)
5.481... logprob:  0.717914, 0.315104 (1.460 sec)
5.482... logprob:  0.705926, 0.313802 (1.482 sec)
5.483... logprob:  0.750348, 0.312500 (1.457 sec)
5.484... logprob:  0.733314, 0.296875 (1.441 sec)
5.485... logprob:  0.608453, 0.257812 (1.487 sec)
5.486... logprob:  0.574698, 0.292969 (1.447 sec)
5.487... logprob:  0.706942, 0.300781 (1.436 sec)
5.488... logprob:  0.603409, 0.242187 (1.443 sec)
5.489... logprob:  0.711876, 0.319010 (1.472 sec)
5.490... logprob:  0.726240, 0.335938 (1.435 sec)
5.491... logprob:  0.559937, 0.243489 (1.483 sec)
5.492... logprob:  0.665531, 0.305990 (1.448 sec)
5.493... logprob:  0.772695, 0.311198 (1.473 sec)
5.494... logprob:  0.682795, 0.276042 (1.493 sec)
5.495... logprob:  0.669769, 0.302083 (1.434 sec)
5.496... logprob:  0.692989, 0.311198 (1.435 sec)
5.497... logprob:  0.743889, 0.324219 (1.440 sec)
5.498... logprob:  0.711414, 0.319010 (1.436 sec)
5.499... logprob:  0.645871, 0.287760 (1.447 sec)
5.500... logprob:  0.631666, 0.261719 (1.487 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.472097, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.634877e-03 [3.373871e-07] 
Layer 'conv1' biases: 7.288228e-07 [9.523657e-10] 
Layer 'conv2' weights[0]: 6.623468e-03 [3.343776e-07] 
Layer 'conv2' biases: 9.999997e-01 [7.138511e-09] 
Layer 'conv3' weights[0]: 6.622484e-03 [3.347609e-07] 
Layer 'conv3' biases: 1.578004e-05 [2.835872e-08] 
Layer 'conv4' weights[0]: 6.649174e-03 [3.394062e-07] 
Layer 'conv4' biases: 1.000015e+00 [3.221858e-07] 
Layer 'conv5' weights[0]: 6.674301e-03 [2.123895e-06] 
Layer 'conv5' biases: 9.993584e-01 [2.224980e-06] 
Layer 'fc6' weights[0]: 7.448466e-03 [5.757750e-08] 
Layer 'fc6' biases: 9.999989e-01 [5.202478e-08] 
Layer 'fc7' weights[0]: 7.803844e-03 [1.232818e-07] 
Layer 'fc7' biases: 9.999397e-01 [1.407751e-07] 
Layer 'fc8' weights[0]: 3.673662e-03 [1.753254e-05] 
Layer 'fc8' biases: 5.737267e-03 [1.803195e-05] 
Train error last 800 batches: 0.654566
-------------------------------------------------------
Not saving because 0.472097 > 0.303240 (5.60: -6.35%)
======================================================= (2.375 sec)
5.501... logprob:  0.594321, 0.274740 (1.434 sec)
5.502... logprob:  0.713093, 0.329427 (1.450 sec)
5.503... logprob:  0.626312, 0.304687 (1.483 sec)
5.504... logprob:  0.564531, 0.242187 (1.476 sec)
5.505... logprob:  0.752865, 0.328125 (1.515 sec)
5.506... logprob:  0.652472, 0.308594 (1.446 sec)
5.507... logprob:  0.654870, 0.307292 (1.484 sec)
5.508... logprob:  0.602579, 0.276042 (1.443 sec)
5.509... logprob:  0.552657, 0.240885 (1.540 sec)
5.510... logprob:  0.660250, 0.292969 (1.451 sec)
5.511... logprob:  0.677515, 0.279948 (1.470 sec)
5.512... logprob:  0.743287, 0.299479 (1.494 sec)
5.513... logprob:  0.536792, 0.263021 (1.451 sec)
5.514... logprob:  0.695919, 0.315104 (1.453 sec)
5.515... logprob:  0.622799, 0.260417 (1.439 sec)
5.516... logprob:  0.668894, 0.303385 (1.433 sec)
5.517... logprob:  0.765360, 0.312500 (1.440 sec)
5.518... logprob:  0.595002, 0.243490 (1.464 sec)
5.519... logprob:  0.729024, 0.305989 (1.457 sec)
5.520... logprob:  0.579055, 0.261719 (1.458 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.564330, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.628264e-03 [3.387700e-07] 
Layer 'conv1' biases: 7.325625e-07 [1.158159e-09] 
Layer 'conv2' weights[0]: 6.616845e-03 [3.342989e-07] 
Layer 'conv2' biases: 9.999997e-01 [7.913354e-09] 
Layer 'conv3' weights[0]: 6.615849e-03 [3.355615e-07] 
Layer 'conv3' biases: 1.585599e-05 [3.262887e-08] 
Layer 'conv4' weights[0]: 6.642523e-03 [3.395520e-07] 
Layer 'conv4' biases: 1.000014e+00 [3.744490e-07] 
Layer 'conv5' weights[0]: 6.667456e-03 [2.397239e-06] 
Layer 'conv5' biases: 9.993541e-01 [2.557066e-06] 
Layer 'fc6' weights[0]: 7.447698e-03 [5.836582e-08] 
Layer 'fc6' biases: 9.999989e-01 [5.351528e-08] 
Layer 'fc7' weights[0]: 7.803068e-03 [1.256276e-07] 
Layer 'fc7' biases: 9.999405e-01 [1.493812e-07] 
Layer 'fc8' weights[0]: 3.721845e-03 [1.779055e-05] 
Layer 'fc8' biases: 6.062290e-03 [2.000549e-05] 
Train error last 800 batches: 0.655131
-------------------------------------------------------
Not saving because 0.564330 > 0.303240 (5.60: -6.35%)
======================================================= (2.369 sec)
5.521... logprob:  0.658291, 0.277344 (1.454 sec)
5.522... logprob:  0.757509, 0.330729 (1.468 sec)
5.523... logprob:  0.615813, 0.278646 (1.442 sec)
5.524... logprob:  0.636998, 0.283854 (1.431 sec)
5.525... logprob:  0.654390, 0.281250 (1.435 sec)
5.526... logprob:  0.624670, 0.276042 (1.438 sec)
5.527... logprob:  0.603031, 0.278646 (1.444 sec)
5.528... logprob:  0.712319, 0.291667 (1.467 sec)
5.529... logprob:  0.660505, 0.285156 (1.453 sec)
5.530... logprob:  0.589963, 0.266927 (1.441 sec)
5.531... logprob:  0.653686, 0.291667 (1.515 sec)
5.532... logprob:  0.597011, 0.257812 (1.442 sec)
5.533... logprob:  0.752560, 0.291667 (1.426 sec)
5.534... logprob:  0.579691, 0.266927 (1.433 sec)
5.535... logprob:  0.812021, 0.316406 (1.439 sec)
5.536... logprob:  0.748994, 0.354167 (1.440 sec)
5.537... logprob:  0.651086, 0.295573 (1.486 sec)
5.538... logprob:  0.777102, 0.316406 (1.440 sec)
5.539... logprob:  0.567017, 0.272135 (1.447 sec)
5.540... logprob:  0.741242, 0.312500 (1.496 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.523503, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.621645e-03 [3.387530e-07] 
Layer 'conv1' biases: 7.375907e-07 [1.239023e-09] 
Layer 'conv2' weights[0]: 6.610220e-03 [3.351488e-07] 
Layer 'conv2' biases: 9.999997e-01 [9.230429e-09] 
Layer 'conv3' weights[0]: 6.609164e-03 [3.369055e-07] 
Layer 'conv3' biases: 1.592004e-05 [3.763681e-08] 
Layer 'conv4' weights[0]: 6.635870e-03 [3.415764e-07] 
Layer 'conv4' biases: 1.000014e+00 [4.044436e-07] 
Layer 'conv5' weights[0]: 6.661087e-03 [2.549134e-06] 
Layer 'conv5' biases: 9.993579e-01 [2.715625e-06] 
Layer 'fc6' weights[0]: 7.446918e-03 [5.951359e-08] 
Layer 'fc6' biases: 9.999988e-01 [5.509095e-08] 
Layer 'fc7' weights[0]: 7.802289e-03 [1.297790e-07] 
Layer 'fc7' biases: 9.999391e-01 [1.596028e-07] 
Layer 'fc8' weights[0]: 3.697033e-03 [1.879651e-05] 
Layer 'fc8' biases: 5.835837e-03 [2.432154e-05] 
Train error last 800 batches: 0.655021
-------------------------------------------------------
Not saving because 0.523503 > 0.303240 (5.60: -6.35%)
======================================================= (2.361 sec)
5.541... logprob:  0.668464, 0.291667 (1.434 sec)
5.542... logprob:  0.655484, 0.303385 (1.430 sec)
5.543... logprob:  0.451569, 0.200521 (1.433 sec)
5.544... logprob:  0.544695, 0.247396 (1.432 sec)
5.545... logprob:  0.614922, 0.246094 (1.431 sec)
5.546... logprob:  0.659045, 0.296875 (1.535 sec)
5.547... logprob:  0.620311, 0.251302 (1.439 sec)
5.548... logprob:  0.661304, 0.312500 (1.440 sec)
5.549... logprob:  0.676061, 0.309896 (1.475 sec)
5.550... logprob:  0.619812, 0.294271 (1.453 sec)
5.551... logprob:  0.689539, 0.305990 (1.443 sec)
5.552... logprob:  0.704399, 0.305989 (1.431 sec)
5.553... logprob:  0.642852, 0.298177 (1.420 sec)
5.554... logprob:  0.715126, 0.302083 (1.436 sec)
5.555... logprob:  0.615955, 0.282552 (1.474 sec)
5.556... logprob:  0.522795, 0.248698 (1.432 sec)
5.557... logprob:  0.622193, 0.278646 (1.446 sec)
5.558... logprob:  0.531046, 0.244792 (1.489 sec)
5.559... logprob:  0.703014, 0.283854 (1.435 sec)
5.560... logprob:  0.589002, 0.281250 (1.442 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.436669, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.614997e-03 [3.350994e-07] 
Layer 'conv1' biases: 7.402445e-07 [1.137336e-09] 
Layer 'conv2' weights[0]: 6.603640e-03 [3.330872e-07] 
Layer 'conv2' biases: 9.999997e-01 [6.300605e-09] 
Layer 'conv3' weights[0]: 6.602543e-03 [3.337311e-07] 
Layer 'conv3' biases: 1.600698e-05 [2.575716e-08] 
Layer 'conv4' weights[0]: 6.629230e-03 [3.373485e-07] 
Layer 'conv4' biases: 1.000013e+00 [2.932867e-07] 
Layer 'conv5' weights[0]: 6.654358e-03 [2.084672e-06] 
Layer 'conv5' biases: 9.993476e-01 [2.261531e-06] 
Layer 'fc6' weights[0]: 7.446183e-03 [5.523129e-08] 
Layer 'fc6' biases: 9.999989e-01 [4.875931e-08] 
Layer 'fc7' weights[0]: 7.801535e-03 [1.166487e-07] 
Layer 'fc7' biases: 9.999412e-01 [1.335911e-07] 
Layer 'fc8' weights[0]: 3.787328e-03 [1.630411e-05] 
Layer 'fc8' biases: 6.412027e-03 [1.887925e-05] 
Train error last 800 batches: 0.655053
-------------------------------------------------------
Not saving because 0.436669 > 0.303240 (5.60: -6.35%)
======================================================= (2.360 sec)
5.561... logprob:  0.557168, 0.253906 (1.443 sec)
5.562... logprob:  0.759939, 0.315104 (1.424 sec)
5.563... logprob:  0.622899, 0.265625 (1.435 sec)
5.564... logprob:  0.670285, 0.260417 (1.468 sec)
5.565... logprob:  0.768728, 0.330729 (1.514 sec)
5.566... logprob:  0.579693, 0.238281 (1.452 sec)
5.567... logprob:  0.704760, 0.298177 (1.464 sec)
5.568... logprob:  0.647604, 0.292969 (1.453 sec)
5.569... logprob:  0.716010, 0.325521 (1.450 sec)
5.570... logprob:  0.739900, 0.319010 (1.471 sec)
5.571... logprob:  0.603745, 0.268229 (1.444 sec)
5.572... logprob:  0.719347, 0.324219 (1.437 sec)
5.573... logprob:  0.689987, 0.315104 (1.463 sec)
5.574... logprob:  0.686575, 0.312500 (1.467 sec)
5.575... logprob:  0.604040, 0.273437 (1.456 sec)
5.576... logprob:  0.631413, 0.269531 (1.441 sec)
5.577... logprob:  0.732203, 0.325521 (1.480 sec)
5.578... logprob:  0.587775, 0.266927 (1.440 sec)
5.579... logprob:  0.692989, 0.289062 (1.424 sec)
5.580... logprob:  0.677679, 0.299479 (1.441 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.451727, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.608420e-03 [3.362243e-07] 
Layer 'conv1' biases: 7.417883e-07 [1.305483e-09] 
Layer 'conv2' weights[0]: 6.597002e-03 [3.331605e-07] 
Layer 'conv2' biases: 9.999997e-01 [7.650267e-09] 
Layer 'conv3' weights[0]: 6.595918e-03 [3.333634e-07] 
Layer 'conv3' biases: 1.615778e-05 [2.735997e-08] 
Layer 'conv4' weights[0]: 6.622660e-03 [3.364279e-07] 
Layer 'conv4' biases: 1.000014e+00 [2.770628e-07] 
Layer 'conv5' weights[0]: 6.648394e-03 [2.126875e-06] 
Layer 'conv5' biases: 9.993457e-01 [2.311961e-06] 
Layer 'fc6' weights[0]: 7.445424e-03 [5.833752e-08] 
Layer 'fc6' biases: 9.999989e-01 [5.357212e-08] 
Layer 'fc7' weights[0]: 7.800723e-03 [1.281518e-07] 
Layer 'fc7' biases: 9.999384e-01 [1.630788e-07] 
Layer 'fc8' weights[0]: 3.700635e-03 [2.106624e-05] 
Layer 'fc8' biases: 5.889383e-03 [3.141506e-05] 
Train error last 800 batches: 0.654880
-------------------------------------------------------
Not saving because 0.451727 > 0.303240 (5.60: -6.35%)
======================================================= (2.367 sec)
5.581... logprob:  0.726824, 0.322917 (1.444 sec)
5.582... logprob:  0.685966, 0.302083 (1.445 sec)
5.583... logprob:  0.731976, 0.329427 (1.477 sec)
5.584... logprob:  0.631375, 0.291667 (1.446 sec)
5.585... logprob:  0.655102, 0.298177 (1.433 sec)
5.586... logprob:  0.592396, 0.274740 (1.483 sec)
5.587... logprob:  0.623298, 0.274739 (1.443 sec)
5.588... logprob:  0.642726, 0.307292 (1.509 sec)
5.589... logprob:  0.599890, 0.273437 (1.447 sec)
5.590... logprob:  0.717065, 0.313802 (1.430 sec)
5.591... logprob:  0.594807, 0.255208 (1.427 sec)
5.592... logprob:  0.669919, 0.320312 (1.477 sec)
5.593... logprob:  0.641614, 0.283854 (1.439 sec)
5.594... logprob:  0.552629, 0.246094 (1.434 sec)
5.595... logprob:  0.654389, 0.291667 (1.486 sec)
5.596... logprob:  0.686432, 0.292969 (1.493 sec)
5.597... logprob:  0.618846, 0.265625 (1.442 sec)
5.598... logprob:  0.604663, 0.274740 (1.439 sec)
5.599... logprob:  0.523003, 0.221354 (1.429 sec)
5.600... logprob:  0.664053, 0.319010 (1.436 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.459783, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.601788e-03 [3.366545e-07] 
Layer 'conv1' biases: 7.429887e-07 [1.151739e-09] 
Layer 'conv2' weights[0]: 6.590444e-03 [3.339750e-07] 
Layer 'conv2' biases: 9.999997e-01 [8.710228e-09] 
Layer 'conv3' weights[0]: 6.589340e-03 [3.351057e-07] 
Layer 'conv3' biases: 1.624227e-05 [3.205721e-08] 
Layer 'conv4' weights[0]: 6.616005e-03 [3.400936e-07] 
Layer 'conv4' biases: 1.000014e+00 [3.751457e-07] 
Layer 'conv5' weights[0]: 6.641943e-03 [2.591780e-06] 
Layer 'conv5' biases: 9.993408e-01 [2.750603e-06] 
Layer 'fc6' weights[0]: 7.444642e-03 [6.107843e-08] 
Layer 'fc6' biases: 9.999989e-01 [5.773186e-08] 
Layer 'fc7' weights[0]: 7.799936e-03 [1.359961e-07] 
Layer 'fc7' biases: 9.999399e-01 [1.997134e-07] 
Layer 'fc8' weights[0]: 3.772045e-03 [2.316736e-05] 
Layer 'fc8' biases: 6.298072e-03 [4.424250e-05] 
Train error last 800 batches: 0.654887
-------------------------------------------------------
Not saving because 0.459783 > 0.303240 (5.60: -6.35%)
======================================================= (2.405 sec)
5.601... logprob:  0.630238, 0.295573 (1.493 sec)
5.602... logprob:  0.576330, 0.272135 (1.441 sec)
5.603... logprob:  0.521863, 0.246094 (1.448 sec)
5.604... logprob:  0.642773, 0.266927 (1.478 sec)
5.605... logprob:  0.806473, 0.343750 (1.436 sec)
5.606... logprob:  0.494358, 0.233073 (1.443 sec)
5.607... logprob:  0.697144, 0.299479 (1.444 sec)
5.608... logprob:  0.552103, 0.244792 (1.429 sec)
5.609... logprob:  0.632810, 0.316406 (1.443 sec)
5.610... logprob:  0.649298, 0.303385 (1.480 sec)
5.611... logprob:  0.737606, 0.330729 (1.448 sec)
5.612... logprob:  0.641408, 0.286458 (1.455 sec)
5.613... logprob:  0.566958, 0.255208 (1.470 sec)
5.614... logprob:  0.783419, 0.352865 (1.455 sec)
5.615... logprob:  0.631220, 0.294271 (1.448 sec)
5.616... logprob:  0.560015, 0.225260 (1.436 sec)
5.617... logprob:  0.663422, 0.277344 (1.435 sec)
5.618... logprob:  0.707624, 0.320313 (1.434 sec)
5.619... logprob:  0.812302, 0.345052 (1.456 sec)
5.620... logprob:  0.802694, 0.319010 (1.469 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.385591, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.595192e-03 [3.381445e-07] 
Layer 'conv1' biases: 7.440739e-07 [2.021734e-09] 
Layer 'conv2' weights[0]: 6.583866e-03 [3.358926e-07] 
Layer 'conv2' biases: 9.999997e-01 [1.437433e-08] 
Layer 'conv3' weights[0]: 6.582798e-03 [3.416589e-07] 
Layer 'conv3' biases: 1.636734e-05 [5.043315e-08] 
Layer 'conv4' weights[0]: 6.609417e-03 [3.525956e-07] 
Layer 'conv4' biases: 1.000015e+00 [6.507313e-07] 
Layer 'conv5' weights[0]: 6.635619e-03 [4.398375e-06] 
Layer 'conv5' biases: 9.993413e-01 [4.757922e-06] 
Layer 'fc6' weights[0]: 7.443826e-03 [8.733441e-08] 
Layer 'fc6' biases: 9.999989e-01 [9.722688e-08] 
Layer 'fc7' weights[0]: 7.799122e-03 [2.212163e-07] 
Layer 'fc7' biases: 9.999395e-01 [4.132839e-07] 
Layer 'fc8' weights[0]: 3.770370e-03 [3.908390e-05] 
Layer 'fc8' biases: 6.279302e-03 [8.877454e-05] 
Train error last 800 batches: 0.654868
-------------------------------------------------------
Not saving because 0.385591 > 0.303240 (5.60: -6.35%)
======================================================= (2.343 sec)
5.621... logprob:  0.615203, 0.286458 (1.470 sec)
5.622... logprob:  0.631613, 0.266927 (1.461 sec)
5.623... logprob:  0.656160, 0.287760 (1.476 sec)
5.624... logprob:  0.691020, 0.299479 (1.438 sec)
5.625... logprob:  0.688928, 0.302083 (1.439 sec)
5.626... logprob:  0.635807, 0.256510 (1.444 sec)
5.627... logprob:  0.590279, 0.238281 (1.445 sec)
5.628... logprob:  0.763190, 0.352865 (1.435 sec)
5.629... logprob:  0.571325, 0.227865 (1.475 sec)
5.630... logprob:  0.712918, 0.300781 (1.443 sec)
5.631... logprob:  0.755162, 0.332031 (1.439 sec)
5.632... logprob:  0.663411, 0.279948 (1.484 sec)
5.633... logprob:  0.709647, 0.309896 (1.437 sec)
5.634... logprob:  0.694026, 0.287760 (1.455 sec)
5.635... logprob:  0.657097, 0.296875 (1.438 sec)
5.636... logprob:  0.723420, 0.328125 (1.438 sec)
5.637... logprob:  0.615753, 0.290365 (1.444 sec)
5.638... logprob:  0.717070, 0.322917 (1.483 sec)
5.639... logprob:  0.616945, 0.268229 (1.451 sec)
5.640... logprob:  0.691480, 0.296875 (1.435 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.519236, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.588647e-03 [3.344393e-07] 
Layer 'conv1' biases: 7.460403e-07 [1.184815e-09] 
Layer 'conv2' weights[0]: 6.577269e-03 [3.323604e-07] 
Layer 'conv2' biases: 9.999997e-01 [8.133106e-09] 
Layer 'conv3' weights[0]: 6.576302e-03 [3.339120e-07] 
Layer 'conv3' biases: 1.647235e-05 [3.314018e-08] 
Layer 'conv4' weights[0]: 6.602807e-03 [3.381447e-07] 
Layer 'conv4' biases: 1.000016e+00 [3.693506e-07] 
Layer 'conv5' weights[0]: 6.629620e-03 [2.385221e-06] 
Layer 'conv5' biases: 9.993471e-01 [2.618350e-06] 
Layer 'fc6' weights[0]: 7.443089e-03 [6.049674e-08] 
Layer 'fc6' biases: 9.999987e-01 [5.709802e-08] 
Layer 'fc7' weights[0]: 7.798346e-03 [1.360067e-07] 
Layer 'fc7' biases: 9.999371e-01 [1.821933e-07] 
Layer 'fc8' weights[0]: 3.699230e-03 [2.479614e-05] 
Layer 'fc8' biases: 5.776079e-03 [4.705533e-05] 
Train error last 800 batches: 0.655503
-------------------------------------------------------
Not saving because 0.519236 > 0.303240 (5.60: -6.35%)
======================================================= (2.359 sec)
5.641... logprob:  0.655955, 0.287760 (1.495 sec)
5.642... logprob:  0.702575, 0.279948 (1.431 sec)
5.643... logprob:  0.696917, 0.281250 (1.426 sec)
5.644... logprob:  0.648329, 0.291667 (1.437 sec)
5.645... logprob:  0.585471, 0.265625 (1.441 sec)
5.646... logprob:  0.616590, 0.248698 (1.435 sec)
5.647... logprob:  0.596352, 0.261719 (1.492 sec)
5.648... logprob:  0.685521, 0.290365 (1.436 sec)
5.649... logprob:  0.576458, 0.251302 (1.441 sec)
5.650... logprob:  0.651021, 0.294271 (1.472 sec)
5.651... logprob:  0.638887, 0.295573 (1.435 sec)
5.652... logprob:  0.653124, 0.272135 (1.442 sec)
5.653... logprob:  0.763036, 0.329427 (1.445 sec)
5.654... logprob:  0.674454, 0.294271 (1.430 sec)
5.655... logprob:  0.671697, 0.266927 (1.440 sec)
5.656... logprob:  0.627136, 0.279948 (1.480 sec)
5.657... logprob:  0.601073, 0.276042 (1.438 sec)
5.658... logprob:  0.622794, 0.289062 (1.452 sec)
5.659... logprob:  0.700606, 0.295573 (1.471 sec)
5.660... logprob:  0.660036, 0.291667 (1.448 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.356724, 0.062500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.582066e-03 [3.348521e-07] 
Layer 'conv1' biases: 7.490967e-07 [1.287945e-09] 
Layer 'conv2' weights[0]: 6.570688e-03 [3.318095e-07] 
Layer 'conv2' biases: 9.999997e-01 [7.920328e-09] 
Layer 'conv3' weights[0]: 6.569701e-03 [3.330587e-07] 
Layer 'conv3' biases: 1.643169e-05 [2.963158e-08] 
Layer 'conv4' weights[0]: 6.596221e-03 [3.384827e-07] 
Layer 'conv4' biases: 1.000015e+00 [3.863439e-07] 
Layer 'conv5' weights[0]: 6.622867e-03 [2.456496e-06] 
Layer 'conv5' biases: 9.993474e-01 [2.631874e-06] 
Layer 'fc6' weights[0]: 7.442308e-03 [5.979644e-08] 
Layer 'fc6' biases: 9.999987e-01 [5.583199e-08] 
Layer 'fc7' weights[0]: 7.797595e-03 [1.309549e-07] 
Layer 'fc7' biases: 9.999383e-01 [1.673421e-07] 
Layer 'fc8' weights[0]: 3.765973e-03 [2.242789e-05] 
Layer 'fc8' biases: 6.168446e-03 [3.774451e-05] 
Train error last 800 batches: 0.655318
-------------------------------------------------------
Not saving because 0.356724 > 0.303240 (5.60: -6.35%)
======================================================= (2.399 sec)
5.661... logprob:  0.700366, 0.324219 (1.438 sec)
5.662... logprob:  0.603821, 0.252604 (1.437 sec)
5.663... logprob:  0.631590, 0.311198 (1.430 sec)
5.664... logprob:  0.530852, 0.248698 (1.499 sec)
5.665... logprob:  0.561711, 0.243490 (1.466 sec)
5.666... logprob:  0.687507, 0.270833 (1.465 sec)
5.667... logprob:  0.785223, 0.309896 (1.451 sec)
5.668... logprob:  0.724792, 0.287760 (1.450 sec)
5.669... logprob:  0.649714, 0.269531 (1.461 sec)
5.670... logprob:  0.639228, 0.305990 (1.495 sec)
5.671... logprob:  0.510821, 0.227865 (1.431 sec)
5.672... logprob:  0.533886, 0.233073 (1.447 sec)
5.673... logprob:  0.670949, 0.319010 (1.438 sec)
5.674... logprob:  0.646747, 0.287760 (1.439 sec)
5.675... logprob:  0.685836, 0.295573 (1.469 sec)
5.676... logprob:  0.620186, 0.287760 (1.453 sec)
5.677... logprob:  0.655109, 0.272135 (1.449 sec)
5.678... logprob:  0.666914, 0.292969 (1.486 sec)
5.679... logprob:  0.578784, 0.253906 (1.438 sec)
5.680... logprob:  0.479278, 0.231771 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.413926, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.575480e-03 [3.339088e-07] 
Layer 'conv1' biases: 7.519611e-07 [9.617253e-10] 
Layer 'conv2' weights[0]: 6.564128e-03 [3.314499e-07] 
Layer 'conv2' biases: 9.999997e-01 [7.400234e-09] 
Layer 'conv3' weights[0]: 6.563115e-03 [3.325169e-07] 
Layer 'conv3' biases: 1.640723e-05 [2.827970e-08] 
Layer 'conv4' weights[0]: 6.589647e-03 [3.365556e-07] 
Layer 'conv4' biases: 1.000014e+00 [3.333742e-07] 
Layer 'conv5' weights[0]: 6.615802e-03 [2.147415e-06] 
Layer 'conv5' biases: 9.993511e-01 [2.304163e-06] 
Layer 'fc6' weights[0]: 7.441518e-03 [5.938002e-08] 
Layer 'fc6' biases: 9.999987e-01 [5.494387e-08] 
Layer 'fc7' weights[0]: 7.796781e-03 [1.293868e-07] 
Layer 'fc7' biases: 9.999391e-01 [1.785373e-07] 
Layer 'fc8' weights[0]: 3.803139e-03 [1.973219e-05] 
Layer 'fc8' biases: 6.327587e-03 [2.861426e-05] 
Train error last 800 batches: 0.655145
-------------------------------------------------------
Not saving because 0.413926 > 0.303240 (5.60: -6.35%)
======================================================= (2.347 sec)
5.681... logprob:  0.607238, 0.265625 (1.441 sec)
5.682... logprob:  0.573482, 0.235677 (1.434 sec)
5.683... logprob:  0.655751, 0.281250 (1.441 sec)
5.684... logprob:  0.598199, 0.277344 (1.491 sec)
5.685... logprob:  0.534460, 0.240885 (1.452 sec)
5.686... logprob:  0.544349, 0.223958 (1.433 sec)
5.687... logprob:  0.539729, 0.252604 (1.488 sec)
5.688... logprob:  0.573008, 0.220052 (1.434 sec)
5.689... logprob:  0.625412, 0.239583 (1.437 sec)
5.690... logprob:  0.667284, 0.283854 (1.447 sec)
5.691... logprob:  0.682230, 0.292969 (1.438 sec)
5.692... logprob:  0.691526, 0.321615 (1.443 sec)
5.693... logprob:  0.661446, 0.273438 (1.485 sec)
5.694... logprob:  0.466345, 0.199219 (1.437 sec)
5.695... logprob:  0.579926, 0.256510 (1.454 sec)
5.696... logprob:  0.849229, 0.347656 (1.487 sec)
5.697... logprob:  0.728829, 0.313802 (1.436 sec)
5.698... logprob:  0.679532, 0.295573 (1.445 sec)
5.699... logprob:  0.698669, 0.309896 (1.435 sec)
5.700... logprob:  0.699594, 0.315104 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.452791, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.568908e-03 [3.351536e-07] 
Layer 'conv1' biases: 7.565191e-07 [1.952767e-09] 
Layer 'conv2' weights[0]: 6.557581e-03 [3.334557e-07] 
Layer 'conv2' biases: 9.999997e-01 [1.439666e-08] 
Layer 'conv3' weights[0]: 6.556542e-03 [3.373970e-07] 
Layer 'conv3' biases: 1.650655e-05 [4.823942e-08] 
Layer 'conv4' weights[0]: 6.583005e-03 [3.441936e-07] 
Layer 'conv4' biases: 1.000015e+00 [5.681456e-07] 
Layer 'conv5' weights[0]: 6.609622e-03 [3.356910e-06] 
Layer 'conv5' biases: 9.993532e-01 [3.588483e-06] 
Layer 'fc6' weights[0]: 7.440701e-03 [7.820726e-08] 
Layer 'fc6' biases: 9.999987e-01 [8.167064e-08] 
Layer 'fc7' weights[0]: 7.795972e-03 [1.862264e-07] 
Layer 'fc7' biases: 9.999382e-01 [3.253011e-07] 
Layer 'fc8' weights[0]: 3.786000e-03 [3.098774e-05] 
Layer 'fc8' biases: 6.233550e-03 [6.598165e-05] 
Train error last 800 batches: 0.655126
-------------------------------------------------------
Not saving because 0.452791 > 0.303240 (5.60: -6.35%)
======================================================= (2.345 sec)
5.701... logprob:  0.687602, 0.312500 (1.430 sec)
5.702... logprob:  0.795444, 0.359375 (1.495 sec)
5.703... logprob:  0.638710, 0.286458 (1.444 sec)
5.704... logprob:  0.624880, 0.283854 (1.446 sec)
5.705... logprob:  0.646006, 0.256510 (1.474 sec)
5.706... logprob:  0.643927, 0.283854 (1.437 sec)
5.707... logprob:  0.704199, 0.316406 (1.435 sec)
5.708... logprob:  0.619330, 0.261719 (1.435 sec)
5.709... logprob:  0.667046, 0.312500 (1.426 sec)
5.710... logprob:  0.804109, 0.316406 (1.444 sec)
5.711... logprob:  0.743221, 0.300781 (1.466 sec)
5.712... logprob:  0.534111, 0.226562 (1.448 sec)
5.713... logprob:  0.770962, 0.345052 (1.467 sec)
5.714... logprob:  0.618875, 0.268229 (1.467 sec)
5.715... logprob:  0.678338, 0.313802 (1.457 sec)
5.716... logprob:  0.565037, 0.266927 (1.437 sec)
5.717... logprob:  0.688880, 0.313802 (1.429 sec)
5.718... logprob:  0.635396, 0.287760 (1.433 sec)
5.719... logprob:  0.631741, 0.277344 (1.442 sec)
5.720... logprob:  0.660134, 0.286458 (1.459 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.481490, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.562354e-03 [3.336480e-07] 
Layer 'conv1' biases: 7.631203e-07 [1.010525e-09] 
Layer 'conv2' weights[0]: 6.551020e-03 [3.307634e-07] 
Layer 'conv2' biases: 9.999997e-01 [8.400101e-09] 
Layer 'conv3' weights[0]: 6.549960e-03 [3.325101e-07] 
Layer 'conv3' biases: 1.658562e-05 [3.205847e-08] 
Layer 'conv4' weights[0]: 6.576430e-03 [3.377909e-07] 
Layer 'conv4' biases: 1.000015e+00 [3.619295e-07] 
Layer 'conv5' weights[0]: 6.603600e-03 [2.741153e-06] 
Layer 'conv5' biases: 9.993516e-01 [2.942347e-06] 
Layer 'fc6' weights[0]: 7.439914e-03 [6.220267e-08] 
Layer 'fc6' biases: 9.999987e-01 [5.905043e-08] 
Layer 'fc7' weights[0]: 7.795185e-03 [1.359702e-07] 
Layer 'fc7' biases: 9.999377e-01 [1.861952e-07] 
Layer 'fc8' weights[0]: 3.750679e-03 [2.122297e-05] 
Layer 'fc8' biases: 5.973990e-03 [3.526375e-05] 
Train error last 800 batches: 0.655234
-------------------------------------------------------
Not saving because 0.481490 > 0.303240 (5.60: -6.35%)
======================================================= (2.350 sec)
5.721... logprob:  0.605978, 0.285156 (1.470 sec)
5.722... logprob:  0.738020, 0.325521 (1.461 sec)
5.723... logprob:  0.610392, 0.242187 (1.451 sec)
5.724... logprob:  0.683430, 0.317708 (1.473 sec)
5.725... logprob:  0.668851, 0.300781 (1.438 sec)
5.726... logprob:  0.642395, 0.305990 (1.429 sec)
5.727... logprob:  0.632286, 0.295573 (1.444 sec)
5.728... logprob:  0.624380, 0.260417 (1.446 sec)
5.729... logprob:  0.573699, 0.239583 (1.436 sec)
5.730... logprob:  0.809846, 0.330729 (1.486 sec)
5.731... logprob:  0.667093, 0.295573 (1.447 sec)
5.732... logprob:  0.579811, 0.278646 (1.468 sec)
5.733... logprob:  0.799162, 0.356771 (1.513 sec)
5.734... logprob:  0.652974, 0.279948 (1.433 sec)
5.735... logprob:  0.759510, 0.317708 (1.430 sec)
5.736... logprob:  0.732982, 0.303385 (1.447 sec)
5.737... logprob:  0.849896, 0.348958 (1.435 sec)
5.738... logprob:  0.599222, 0.278646 (1.437 sec)
5.739... logprob:  0.666424, 0.279948 (1.487 sec)
5.740... logprob:  0.585905, 0.263021 (1.436 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.510908, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.555793e-03 [3.341951e-07] 
Layer 'conv1' biases: 7.705465e-07 [9.690661e-10] 
Layer 'conv2' weights[0]: 6.544491e-03 [3.310814e-07] 
Layer 'conv2' biases: 9.999997e-01 [9.189070e-09] 
Layer 'conv3' weights[0]: 6.543359e-03 [3.327412e-07] 
Layer 'conv3' biases: 1.665953e-05 [3.756104e-08] 
Layer 'conv4' weights[0]: 6.569875e-03 [3.381738e-07] 
Layer 'conv4' biases: 1.000015e+00 [4.125634e-07] 
Layer 'conv5' weights[0]: 6.597364e-03 [2.907354e-06] 
Layer 'conv5' biases: 9.993508e-01 [3.133473e-06] 
Layer 'fc6' weights[0]: 7.439155e-03 [6.551372e-08] 
Layer 'fc6' biases: 9.999987e-01 [6.411786e-08] 
Layer 'fc7' weights[0]: 7.794412e-03 [1.465484e-07] 
Layer 'fc7' biases: 9.999375e-01 [2.146416e-07] 
Layer 'fc8' weights[0]: 3.761651e-03 [2.171487e-05] 
Layer 'fc8' biases: 6.041052e-03 [3.797012e-05] 
Train error last 800 batches: 0.654953
-------------------------------------------------------
Not saving because 0.510908 > 0.303240 (5.60: -6.35%)
======================================================= (2.400 sec)
5.741... logprob:  0.643864, 0.281250 (1.450 sec)
5.742... logprob:  0.725955, 0.299479 (1.484 sec)
5.743... logprob:  0.650201, 0.277344 (1.441 sec)
5.744... logprob:  0.769980, 0.313802 (1.441 sec)
5.745... logprob:  0.695123, 0.329427 (1.437 sec)
5.746... logprob:  0.645170, 0.289062 (1.425 sec)
5.747... logprob:  0.651484, 0.272135 (1.446 sec)
5.748... logprob:  0.736199, 0.313802 (1.484 sec)
5.749... logprob:  0.626166, 0.263021 (1.437 sec)
5.750... logprob:  0.690808, 0.283854 (1.445 sec)
5.751... logprob:  0.513433, 0.222656 (1.490 sec)
5.752... logprob:  0.684833, 0.325521 (1.441 sec)
5.753... logprob:  0.678448, 0.303385 (1.442 sec)
5.754... logprob:  0.686880, 0.303385 (1.433 sec)
5.755... logprob:  0.637258, 0.298177 (1.430 sec)
5.756... logprob:  0.657147, 0.287760 (1.440 sec)
5.757... logprob:  0.683359, 0.291667 (1.482 sec)
5.758... logprob:  0.635213, 0.278646 (1.456 sec)
5.759... logprob:  0.693092, 0.308594 (1.451 sec)
5.760... logprob:  0.628494, 0.260417 (1.500 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.473581, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.549266e-03 [3.337111e-07] 
Layer 'conv1' biases: 7.763916e-07 [1.150139e-09] 
Layer 'conv2' weights[0]: 6.537947e-03 [3.310940e-07] 
Layer 'conv2' biases: 9.999997e-01 [7.555480e-09] 
Layer 'conv3' weights[0]: 6.536829e-03 [3.314016e-07] 
Layer 'conv3' biases: 1.671798e-05 [2.822193e-08] 
Layer 'conv4' weights[0]: 6.563346e-03 [3.348611e-07] 
Layer 'conv4' biases: 1.000016e+00 [2.988279e-07] 
Layer 'conv5' weights[0]: 6.591025e-03 [2.067209e-06] 
Layer 'conv5' biases: 9.993500e-01 [2.116651e-06] 
Layer 'fc6' weights[0]: 7.438338e-03 [5.828710e-08] 
Layer 'fc6' biases: 9.999987e-01 [5.322849e-08] 
Layer 'fc7' weights[0]: 7.793627e-03 [1.267344e-07] 
Layer 'fc7' biases: 9.999368e-01 [1.561739e-07] 
Layer 'fc8' weights[0]: 3.761552e-03 [1.832143e-05] 
Layer 'fc8' biases: 6.125328e-03 [2.518017e-05] 
Train error last 800 batches: 0.654806
-------------------------------------------------------
Not saving because 0.473581 > 0.303240 (5.60: -6.35%)
======================================================= (2.356 sec)
5.761... logprob:  0.673739, 0.274740 (1.455 sec)
5.762... logprob:  0.687315, 0.298177 (1.441 sec)
5.763... logprob:  0.775255, 0.315104 (1.430 sec)
5.764... logprob:  0.641605, 0.292969 (1.429 sec)
5.765... logprob:  0.514987, 0.256510 (1.440 sec)
5.766... logprob:  0.668963, 0.269531 (1.454 sec)
5.767... logprob:  0.622285, 0.285156 (1.463 sec)
5.768... logprob:  0.630332, 0.252604 (1.461 sec)
5.769... logprob:  0.721517, 0.311198 (1.460 sec)
5.770... logprob:  0.583510, 0.247396 (1.486 sec)
5.771... logprob:  0.791099, 0.321615 (1.460 sec)
5.772... logprob:  0.605111, 0.274740 (1.444 sec)
5.773... logprob:  0.766812, 0.333333 (1.452 sec)
5.774... logprob:  0.590024, 0.256510 (1.461 sec)
5.775... logprob:  0.641686, 0.315104 (1.462 sec)
5.776... logprob:  0.678539, 0.289062 (1.482 sec)
5.777... logprob:  0.603806, 0.252604 (1.475 sec)
5.778... logprob:  0.687472, 0.320312 (1.475 sec)
5.779... logprob:  0.733236, 0.316406 (1.512 sec)
5.780... logprob:  0.589930, 0.243490 (1.460 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.520135, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.542748e-03 [3.323675e-07] 
Layer 'conv1' biases: 7.831084e-07 [1.144834e-09] 
Layer 'conv2' weights[0]: 6.531440e-03 [3.302971e-07] 
Layer 'conv2' biases: 9.999997e-01 [7.973878e-09] 
Layer 'conv3' weights[0]: 6.530388e-03 [3.310787e-07] 
Layer 'conv3' biases: 1.670758e-05 [3.072696e-08] 
Layer 'conv4' weights[0]: 6.556764e-03 [3.348233e-07] 
Layer 'conv4' biases: 1.000017e+00 [3.297565e-07] 
Layer 'conv5' weights[0]: 6.585036e-03 [2.091789e-06] 
Layer 'conv5' biases: 9.993460e-01 [2.248594e-06] 
Layer 'fc6' weights[0]: 7.437525e-03 [5.690881e-08] 
Layer 'fc6' biases: 9.999986e-01 [5.097419e-08] 
Layer 'fc7' weights[0]: 7.792904e-03 [1.208864e-07] 
Layer 'fc7' biases: 9.999360e-01 [1.343838e-07] 
Layer 'fc8' weights[0]: 3.764678e-03 [1.724047e-05] 
Layer 'fc8' biases: 6.101795e-03 [2.261629e-05] 
Train error last 800 batches: 0.654799
-------------------------------------------------------
Not saving because 0.520135 > 0.303240 (5.60: -6.35%)
======================================================= (2.419 sec)
5.781... logprob:  0.618819, 0.279948 (1.452 sec)
5.782... logprob:  0.598448, 0.277344 (1.460 sec)
5.783... logprob:  0.604518, 0.247396 (1.460 sec)
5.784... logprob:  0.600768, 0.259114 (1.460 sec)
5.785... logprob:  0.668871, 0.291667 (1.682 sec)
5.786... logprob:  0.691719, 0.343750 (1.498 sec)
5.787... logprob:  0.612734, 0.281250 (1.471 sec)
5.788... logprob:  0.820165, 0.365885 (1.510 sec)
5.789... logprob:  0.537504, 0.259115 (1.466 sec)
5.790... logprob:  0.711186, 0.289062 (1.455 sec)
5.791... logprob:  0.595103, 0.247396 (1.457 sec)
5.792... logprob:  0.600068, 0.246094 (1.464 sec)
5.793... logprob:  0.646608, 0.294271 (1.461 sec)
5.794... logprob:  0.532819, 0.221354 (1.500 sec)
5.795... logprob:  0.700722, 0.312500 (1.477 sec)
5.796... logprob:  0.683037, 0.299479 (1.467 sec)
5.797... logprob:  0.576772, 0.247396 (1.497 sec)
5.798... logprob:  0.629933, 0.272135 (1.463 sec)
5.799... logprob:  0.660914, 0.304687 (1.453 sec)
5.800... logprob:  0.552717, 0.255208 (1.408 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.380083, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.536219e-03 [3.329889e-07] 
Layer 'conv1' biases: 7.913333e-07 [1.459924e-09] 
Layer 'conv2' weights[0]: 6.524915e-03 [3.296428e-07] 
Layer 'conv2' biases: 9.999997e-01 [8.180895e-09] 
Layer 'conv3' weights[0]: 6.523876e-03 [3.305435e-07] 
Layer 'conv3' biases: 1.671692e-05 [2.847755e-08] 
Layer 'conv4' weights[0]: 6.550187e-03 [3.349652e-07] 
Layer 'conv4' biases: 1.000017e+00 [3.300232e-07] 
Layer 'conv5' weights[0]: 6.578623e-03 [2.175176e-06] 
Layer 'conv5' biases: 9.993384e-01 [2.331978e-06] 
Layer 'fc6' weights[0]: 7.436729e-03 [5.886208e-08] 
Layer 'fc6' biases: 9.999986e-01 [5.455263e-08] 
Layer 'fc7' weights[0]: 7.792087e-03 [1.308289e-07] 
Layer 'fc7' biases: 9.999364e-01 [1.837907e-07] 
Layer 'fc8' weights[0]: 3.810713e-03 [1.976654e-05] 
Layer 'fc8' biases: 6.364321e-03 [3.288684e-05] 
Train error last 800 batches: 0.654131
-------------------------------------------------------
Not saving because 0.380083 > 0.303240 (5.60: -6.35%)
======================================================= (2.362 sec)
6.1... logprob:  0.649654, 0.259114 (1.414 sec)
6.2... logprob:  0.588925, 0.263021 (1.444 sec)
6.3... logprob:  0.650663, 0.274740 (1.421 sec)
6.4... logprob:  0.618865, 0.256510 (1.437 sec)
6.5... logprob:  0.661153, 0.317708 (1.474 sec)
6.6... logprob:  0.721034, 0.335937 (1.394 sec)
6.7... logprob:  0.590212, 0.266927 (1.420 sec)
6.8... logprob:  0.626841, 0.298177 (1.398 sec)
6.9... logprob:  0.605443, 0.273437 (1.412 sec)
6.10... logprob:  0.586181, 0.251302 (1.408 sec)
6.11... logprob:  0.625812, 0.291667 (1.447 sec)
6.12... logprob:  0.685906, 0.274740 (1.411 sec)
6.13... logprob:  0.759476, 0.307292 (1.423 sec)
6.14... logprob:  0.742499, 0.304687 (1.400 sec)
6.15... logprob:  0.613947, 0.274740 (1.409 sec)
6.16... logprob:  0.586241, 0.268229 (1.399 sec)
6.17... logprob:  0.756155, 0.315104 (1.426 sec)
6.18... logprob:  0.459950, 0.209635 (1.400 sec)
6.19... logprob:  0.570878, 0.260417 (1.397 sec)
6.20... logprob:  0.637064, 0.257812 (1.397 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.502137, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.529701e-03 [3.298872e-07] 
Layer 'conv1' biases: 7.911925e-07 [1.257438e-09] 
Layer 'conv2' weights[0]: 6.518400e-03 [3.286276e-07] 
Layer 'conv2' biases: 9.999997e-01 [6.594901e-09] 
Layer 'conv3' weights[0]: 6.517320e-03 [3.290866e-07] 
Layer 'conv3' biases: 1.680323e-05 [2.541027e-08] 
Layer 'conv4' weights[0]: 6.543677e-03 [3.326436e-07] 
Layer 'conv4' biases: 1.000018e+00 [3.041658e-07] 
Layer 'conv5' weights[0]: 6.572224e-03 [2.322997e-06] 
Layer 'conv5' biases: 9.993415e-01 [2.524479e-06] 
Layer 'fc6' weights[0]: 7.435974e-03 [5.546130e-08] 
Layer 'fc6' biases: 9.999986e-01 [4.903245e-08] 
Layer 'fc7' weights[0]: 7.791319e-03 [1.163081e-07] 
Layer 'fc7' biases: 9.999357e-01 [1.237470e-07] 
Layer 'fc8' weights[0]: 3.795657e-03 [1.521612e-05] 
Layer 'fc8' biases: 6.227837e-03 [1.007081e-05] 
Train error last 800 batches: 0.654134
-------------------------------------------------------
Not saving because 0.502137 > 0.303240 (5.60: -6.35%)
======================================================= (2.397 sec)
6.21... logprob:  0.689758, 0.322917 (1.416 sec)
6.22... logprob:  0.712033, 0.303385 (1.410 sec)
6.23... logprob:  0.647763, 0.285156 (1.455 sec)
6.24... logprob:  0.537079, 0.240885 (1.415 sec)
6.25... logprob:  0.670495, 0.261719 (1.404 sec)
6.26... logprob:  0.651330, 0.266927 (1.446 sec)
6.27... logprob:  0.691320, 0.294271 (1.394 sec)
6.28... logprob:  0.656219, 0.266927 (1.404 sec)
6.29... logprob:  0.551946, 0.240885 (1.427 sec)
6.30... logprob:  0.588489, 0.265625 (1.425 sec)
6.31... logprob:  0.594531, 0.286458 (1.404 sec)
6.32... logprob:  0.617433, 0.255208 (1.401 sec)
6.33... logprob:  0.596342, 0.265625 (1.445 sec)
6.34... logprob:  0.642554, 0.279948 (1.398 sec)
6.35... logprob:  0.604943, 0.272135 (1.404 sec)
6.36... logprob:  0.760182, 0.333333 (1.438 sec)
6.37... logprob:  0.627620, 0.287760 (1.414 sec)
6.38... logprob:  0.574664, 0.255208 (1.396 sec)
6.39... logprob:  0.831899, 0.372396 (1.438 sec)
6.40... logprob:  0.738468, 0.307292 (1.409 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.465265, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.523212e-03 [3.341037e-07] 
Layer 'conv1' biases: 7.973116e-07 [1.268472e-09] 
Layer 'conv2' weights[0]: 6.511870e-03 [3.302263e-07] 
Layer 'conv2' biases: 9.999997e-01 [1.019671e-08] 
Layer 'conv3' weights[0]: 6.510782e-03 [3.314211e-07] 
Layer 'conv3' biases: 1.683697e-05 [3.694505e-08] 
Layer 'conv4' weights[0]: 6.537144e-03 [3.353668e-07] 
Layer 'conv4' biases: 1.000018e+00 [4.023964e-07] 
Layer 'conv5' weights[0]: 6.565753e-03 [2.612715e-06] 
Layer 'conv5' biases: 9.993396e-01 [2.814142e-06] 
Layer 'fc6' weights[0]: 7.435207e-03 [6.435697e-08] 
Layer 'fc6' biases: 9.999986e-01 [6.209363e-08] 
Layer 'fc7' weights[0]: 7.790535e-03 [1.424037e-07] 
Layer 'fc7' biases: 9.999353e-01 [1.968248e-07] 
Layer 'fc8' weights[0]: 3.805411e-03 [2.149969e-05] 
Layer 'fc8' biases: 6.173304e-03 [3.559678e-05] 
Train error last 800 batches: 0.654080
-------------------------------------------------------
Not saving because 0.465265 > 0.303240 (5.60: -6.35%)
======================================================= (2.406 sec)
6.41... logprob:  0.607253, 0.283854 (1.425 sec)
6.42... logprob:  0.678919, 0.298177 (1.422 sec)
6.43... logprob:  0.718550, 0.315104 (1.416 sec)
6.44... logprob:  0.736238, 0.320312 (1.438 sec)
6.45... logprob:  0.643345, 0.251302 (1.380 sec)
6.46... logprob:  0.636301, 0.290365 (1.395 sec)
6.47... logprob:  0.564846, 0.269531 (1.400 sec)
6.48... logprob:  0.788320, 0.325521 (1.426 sec)
6.49... logprob:  0.674489, 0.305990 (1.422 sec)
6.50... logprob:  0.566810, 0.243490 (1.425 sec)
6.51... logprob:  0.756236, 0.325521 (1.419 sec)
6.52... logprob:  0.721870, 0.309896 (1.394 sec)
6.53... logprob:  0.519117, 0.235677 (1.449 sec)
6.54... logprob:  0.646022, 0.308594 (1.391 sec)
6.55... logprob:  0.581221, 0.265625 (1.402 sec)
6.56... logprob:  0.653006, 0.290365 (1.407 sec)
6.57... logprob:  0.771972, 0.332031 (1.435 sec)
6.58... logprob:  0.629411, 0.278646 (1.409 sec)
6.59... logprob:  0.688854, 0.326823 (1.466 sec)
6.60... logprob:  0.798014, 0.317708 (1.411 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.544509, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.516665e-03 [3.298536e-07] 
Layer 'conv1' biases: 8.060222e-07 [1.148918e-09] 
Layer 'conv2' weights[0]: 6.505396e-03 [3.279776e-07] 
Layer 'conv2' biases: 9.999997e-01 [6.257174e-09] 
Layer 'conv3' weights[0]: 6.504316e-03 [3.287667e-07] 
Layer 'conv3' biases: 1.681589e-05 [2.789274e-08] 
Layer 'conv4' weights[0]: 6.530595e-03 [3.320789e-07] 
Layer 'conv4' biases: 1.000016e+00 [3.145772e-07] 
Layer 'conv5' weights[0]: 6.558796e-03 [2.363899e-06] 
Layer 'conv5' biases: 9.993417e-01 [2.495660e-06] 
Layer 'fc6' weights[0]: 7.434439e-03 [5.947357e-08] 
Layer 'fc6' biases: 9.999986e-01 [5.497416e-08] 
Layer 'fc7' weights[0]: 7.789715e-03 [1.307926e-07] 
Layer 'fc7' biases: 9.999355e-01 [1.568000e-07] 
Layer 'fc8' weights[0]: 3.826068e-03 [1.976330e-05] 
Layer 'fc8' biases: 6.230659e-03 [2.909787e-05] 
Train error last 800 batches: 0.654702
-------------------------------------------------------
Not saving because 0.544509 > 0.303240 (5.60: -6.35%)
======================================================= (2.368 sec)
6.61... logprob:  0.628858, 0.286458 (1.431 sec)
6.62... logprob:  0.570348, 0.248698 (1.480 sec)
6.63... logprob:  0.663956, 0.289062 (1.442 sec)
6.64... logprob:  0.719715, 0.324219 (1.411 sec)
6.65... logprob:  0.591242, 0.277344 (1.400 sec)
6.66... logprob:  0.670006, 0.294271 (1.453 sec)
6.67... logprob:  0.518637, 0.229167 (1.390 sec)
6.68... logprob:  0.632422, 0.291667 (1.402 sec)
6.69... logprob:  0.727650, 0.303385 (1.428 sec)
6.70... logprob:  0.621451, 0.298177 (1.434 sec)
6.71... logprob:  0.572439, 0.277344 (1.470 sec)
6.72... logprob:  0.685989, 0.296875 (1.413 sec)
6.73... logprob:  0.571082, 0.251302 (1.426 sec)
6.74... logprob:  0.597975, 0.255208 (1.424 sec)
6.75... logprob:  0.644329, 0.295573 (1.436 sec)
6.76... logprob:  0.734488, 0.315104 (1.452 sec)
6.77... logprob:  0.518218, 0.223958 (1.434 sec)
6.78... logprob:  0.615972, 0.255208 (1.461 sec)
6.79... logprob:  0.692908, 0.304687 (1.421 sec)
6.80... logprob:  0.645395, 0.281250 (1.417 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.411722, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.510161e-03 [3.317835e-07] 
Layer 'conv1' biases: 8.039572e-07 [1.164131e-09] 
Layer 'conv2' weights[0]: 6.498826e-03 [3.284669e-07] 
Layer 'conv2' biases: 9.999997e-01 [7.512961e-09] 
Layer 'conv3' weights[0]: 6.497809e-03 [3.295251e-07] 
Layer 'conv3' biases: 1.680833e-05 [2.875600e-08] 
Layer 'conv4' weights[0]: 6.524076e-03 [3.332762e-07] 
Layer 'conv4' biases: 1.000015e+00 [3.317731e-07] 
Layer 'conv5' weights[0]: 6.552007e-03 [2.338164e-06] 
Layer 'conv5' biases: 9.993401e-01 [2.500766e-06] 
Layer 'fc6' weights[0]: 7.433700e-03 [5.705599e-08] 
Layer 'fc6' biases: 9.999985e-01 [5.138986e-08] 
Layer 'fc7' weights[0]: 7.788935e-03 [1.193830e-07] 
Layer 'fc7' biases: 9.999359e-01 [1.301351e-07] 
Layer 'fc8' weights[0]: 3.870318e-03 [1.561881e-05] 
Layer 'fc8' biases: 6.431896e-03 [1.326533e-05] 
Train error last 800 batches: 0.654771
-------------------------------------------------------
Not saving because 0.411722 > 0.303240 (5.60: -6.35%)
======================================================= (2.417 sec)
6.81... logprob:  0.704742, 0.295573 (1.434 sec)
6.82... logprob:  0.518860, 0.246094 (1.431 sec)
6.83... logprob:  0.606453, 0.260417 (1.403 sec)
6.84... logprob:  0.605518, 0.272135 (1.468 sec)
6.85... logprob:  0.634866, 0.269531 (1.428 sec)
6.86... logprob:  0.739987, 0.296875 (1.426 sec)
6.87... logprob:  0.723888, 0.313802 (1.416 sec)
6.88... logprob:  0.790082, 0.325521 (1.408 sec)
6.89... logprob:  0.572879, 0.265625 (1.437 sec)
6.90... logprob:  0.861932, 0.368490 (1.544 sec)
6.91... logprob:  0.581201, 0.255208 (1.414 sec)
6.92... logprob:  0.705769, 0.316406 (1.410 sec)
6.93... logprob:  0.765516, 0.325521 (1.400 sec)
6.94... logprob:  0.630805, 0.292969 (1.427 sec)
6.95... logprob:  0.685870, 0.287760 (1.410 sec)
6.96... logprob:  0.685260, 0.308594 (1.412 sec)
6.97... logprob:  0.611927, 0.260417 (1.399 sec)
6.98... logprob:  0.668964, 0.305990 (1.439 sec)
6.99... logprob:  0.638654, 0.283854 (1.421 sec)
6.100... logprob:  0.508782, 0.238281 (1.406 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.400910, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.503664e-03 [3.303525e-07] 
Layer 'conv1' biases: 8.015803e-07 [9.659809e-10] 
Layer 'conv2' weights[0]: 6.492360e-03 [3.276721e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.026760e-09] 
Layer 'conv3' weights[0]: 6.491309e-03 [3.280502e-07] 
Layer 'conv3' biases: 1.688966e-05 [2.707185e-08] 
Layer 'conv4' weights[0]: 6.517542e-03 [3.316752e-07] 
Layer 'conv4' biases: 1.000015e+00 [2.853327e-07] 
Layer 'conv5' weights[0]: 6.545726e-03 [2.106193e-06] 
Layer 'conv5' biases: 9.993472e-01 [2.256991e-06] 
Layer 'fc6' weights[0]: 7.432927e-03 [5.573530e-08] 
Layer 'fc6' biases: 9.999986e-01 [4.936032e-08] 
Layer 'fc7' weights[0]: 7.788154e-03 [1.194418e-07] 
Layer 'fc7' biases: 9.999344e-01 [1.384355e-07] 
Layer 'fc8' weights[0]: 3.794004e-03 [1.643336e-05] 
Layer 'fc8' biases: 5.982767e-03 [2.113997e-05] 
Train error last 800 batches: 0.654367
-------------------------------------------------------
Not saving because 0.400910 > 0.303240 (5.60: -6.35%)
======================================================= (2.364 sec)
6.101... logprob:  0.538208, 0.242187 (1.457 sec)
6.102... logprob:  0.747794, 0.292969 (1.392 sec)
6.103... logprob:  0.772062, 0.315104 (1.402 sec)
6.104... logprob:  0.615980, 0.265625 (1.405 sec)
6.105... logprob:  0.783974, 0.324219 (1.406 sec)
6.106... logprob:  0.619807, 0.261719 (1.398 sec)
6.107... logprob:  0.600823, 0.273438 (1.441 sec)
6.108... logprob:  0.798488, 0.330729 (1.395 sec)
6.109... logprob:  0.587519, 0.276042 (1.404 sec)
6.110... logprob:  0.795192, 0.363281 (1.397 sec)
6.111... logprob:  0.665073, 0.287760 (1.398 sec)
6.112... logprob:  0.634390, 0.300781 (1.398 sec)
6.113... logprob:  0.701426, 0.337240 (1.410 sec)
6.114... logprob:  0.683065, 0.321615 (1.440 sec)
6.115... logprob:  0.696185, 0.294271 (1.414 sec)
6.116... logprob:  0.564514, 0.263021 (1.412 sec)
6.117... logprob:  0.636817, 0.268229 (1.446 sec)
6.118... logprob:  0.602591, 0.251302 (1.396 sec)
6.119... logprob:  0.554046, 0.227865 (1.409 sec)
6.120... logprob:  0.780442, 0.322917 (1.400 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.467244, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.497168e-03 [3.292079e-07] 
Layer 'conv1' biases: 8.061365e-07 [1.069903e-09] 
Layer 'conv2' weights[0]: 6.485881e-03 [3.278439e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.994238e-09] 
Layer 'conv3' weights[0]: 6.484831e-03 [3.289130e-07] 
Layer 'conv3' biases: 1.692105e-05 [3.007233e-08] 
Layer 'conv4' weights[0]: 6.510999e-03 [3.328406e-07] 
Layer 'conv4' biases: 1.000014e+00 [3.159996e-07] 
Layer 'conv5' weights[0]: 6.539103e-03 [2.249382e-06] 
Layer 'conv5' biases: 9.993478e-01 [2.335561e-06] 
Layer 'fc6' weights[0]: 7.432175e-03 [5.825343e-08] 
Layer 'fc6' biases: 9.999986e-01 [5.295470e-08] 
Layer 'fc7' weights[0]: 7.787360e-03 [1.252808e-07] 
Layer 'fc7' biases: 9.999348e-01 [1.454729e-07] 
Layer 'fc8' weights[0]: 3.833223e-03 [1.801395e-05] 
Layer 'fc8' biases: 6.196150e-03 [2.084095e-05] 
Train error last 800 batches: 0.654176
-------------------------------------------------------
Not saving because 0.467244 > 0.303240 (5.60: -6.35%)
======================================================= (2.362 sec)
6.121... logprob:  0.684593, 0.332031 (1.402 sec)
6.122... logprob:  0.643195, 0.276042 (1.440 sec)
6.123... logprob:  0.653549, 0.294271 (1.389 sec)
6.124... logprob:  0.695793, 0.291667 (1.407 sec)
6.125... logprob:  0.738101, 0.319010 (1.404 sec)
6.126... logprob:  0.712096, 0.309896 (1.392 sec)
6.127... logprob:  0.684687, 0.279948 (1.404 sec)
6.128... logprob:  0.607938, 0.269531 (1.423 sec)
6.129... logprob:  0.734868, 0.341146 (1.417 sec)
6.130... logprob:  0.633831, 0.296875 (1.419 sec)
6.131... logprob:  0.762986, 0.343750 (1.411 sec)
6.132... logprob:  0.784173, 0.343750 (1.436 sec)
6.133... logprob:  0.713762, 0.319010 (1.421 sec)
6.134... logprob:  0.707449, 0.295573 (1.406 sec)
6.135... logprob:  0.708258, 0.283854 (1.411 sec)
6.136... logprob:  0.670510, 0.324219 (1.416 sec)
6.137... logprob:  0.667212, 0.291667 (1.388 sec)
6.138... logprob:  0.615247, 0.269531 (1.445 sec)
6.139... logprob:  0.631419, 0.274740 (1.408 sec)
6.140... logprob:  0.755416, 0.315104 (1.411 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.508461, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.490668e-03 [3.309748e-07] 
Layer 'conv1' biases: 8.067167e-07 [1.202957e-09] 
Layer 'conv2' weights[0]: 6.479381e-03 [3.286007e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.819529e-09] 
Layer 'conv3' weights[0]: 6.478299e-03 [3.293259e-07] 
Layer 'conv3' biases: 1.701302e-05 [3.232233e-08] 
Layer 'conv4' weights[0]: 6.504543e-03 [3.325275e-07] 
Layer 'conv4' biases: 1.000016e+00 [3.468555e-07] 
Layer 'conv5' weights[0]: 6.533330e-03 [2.404791e-06] 
Layer 'conv5' biases: 9.993458e-01 [2.568508e-06] 
Layer 'fc6' weights[0]: 7.431371e-03 [5.927019e-08] 
Layer 'fc6' biases: 9.999986e-01 [5.475524e-08] 
Layer 'fc7' weights[0]: 7.786581e-03 [1.279728e-07] 
Layer 'fc7' biases: 9.999336e-01 [1.503400e-07] 
Layer 'fc8' weights[0]: 3.771970e-03 [1.836586e-05] 
Layer 'fc8' biases: 5.833835e-03 [2.229100e-05] 
Train error last 800 batches: 0.654625
-------------------------------------------------------
Not saving because 0.508461 > 0.303240 (5.60: -6.35%)
======================================================= (2.381 sec)
6.141... logprob:  0.598286, 0.277344 (1.452 sec)
6.142... logprob:  0.669003, 0.309896 (1.401 sec)
6.143... logprob:  0.573169, 0.260417 (1.429 sec)
6.144... logprob:  0.640545, 0.266927 (1.418 sec)
6.145... logprob:  0.580653, 0.235677 (1.416 sec)
6.146... logprob:  0.717635, 0.304688 (1.416 sec)
6.147... logprob:  0.526039, 0.247396 (1.433 sec)
6.148... logprob:  0.669556, 0.313802 (1.399 sec)
6.149... logprob:  0.607743, 0.289062 (1.404 sec)
6.150... logprob:  0.560587, 0.247396 (1.403 sec)
6.151... logprob:  0.636987, 0.292969 (1.404 sec)
6.152... logprob:  0.969478, 0.373698 (1.399 sec)
6.153... logprob:  0.576274, 0.277344 (1.453 sec)
6.154... logprob:  0.695742, 0.298177 (1.396 sec)
6.155... logprob:  0.568308, 0.252604 (1.406 sec)
6.156... logprob:  0.557242, 0.259115 (1.448 sec)
6.157... logprob:  0.486998, 0.234375 (1.391 sec)
6.158... logprob:  0.714474, 0.343750 (1.403 sec)
6.159... logprob:  0.706308, 0.279948 (1.396 sec)
6.160... logprob:  0.700911, 0.299479 (1.399 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.553747, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.484179e-03 [3.283907e-07] 
Layer 'conv1' biases: 8.126018e-07 [1.159905e-09] 
Layer 'conv2' weights[0]: 6.472915e-03 [3.268241e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.982665e-09] 
Layer 'conv3' weights[0]: 6.471818e-03 [3.280980e-07] 
Layer 'conv3' biases: 1.698443e-05 [3.080474e-08] 
Layer 'conv4' weights[0]: 6.498024e-03 [3.323171e-07] 
Layer 'conv4' biases: 1.000015e+00 [3.451352e-07] 
Layer 'conv5' weights[0]: 6.526811e-03 [2.429906e-06] 
Layer 'conv5' biases: 9.993321e-01 [2.583118e-06] 
Layer 'fc6' weights[0]: 7.430603e-03 [6.223179e-08] 
Layer 'fc6' biases: 9.999985e-01 [5.971602e-08] 
Layer 'fc7' weights[0]: 7.785802e-03 [1.365777e-07] 
Layer 'fc7' biases: 9.999352e-01 [1.839639e-07] 
Layer 'fc8' weights[0]: 3.879908e-03 [2.167297e-05] 
Layer 'fc8' biases: 6.458248e-03 [3.297908e-05] 
Train error last 800 batches: 0.654560
-------------------------------------------------------
Not saving because 0.553747 > 0.303240 (5.60: -6.35%)
======================================================= (2.408 sec)
6.161... logprob:  0.599046, 0.270833 (1.403 sec)
6.162... logprob:  0.799483, 0.350260 (1.407 sec)
6.163... logprob:  0.671436, 0.289062 (1.430 sec)
6.164... logprob:  0.642259, 0.289062 (1.427 sec)
6.165... logprob:  0.741048, 0.300781 (1.417 sec)
6.166... logprob:  0.708485, 0.307292 (1.450 sec)
6.167... logprob:  0.630447, 0.273437 (1.434 sec)
6.168... logprob:  0.596757, 0.248698 (1.427 sec)
6.169... logprob:  0.663168, 0.273438 (1.466 sec)
6.170... logprob:  0.705230, 0.296875 (1.404 sec)
6.171... logprob:  0.729138, 0.316406 (1.424 sec)
6.172... logprob:  0.651748, 0.298177 (1.448 sec)
6.173... logprob:  0.605830, 0.260417 (1.432 sec)
6.174... logprob:  0.740294, 0.325521 (1.403 sec)
6.175... logprob:  0.612618, 0.252604 (1.471 sec)
6.176... logprob:  0.728331, 0.319010 (1.416 sec)
6.177... logprob:  0.506549, 0.203125 (1.430 sec)
6.178... logprob:  0.672862, 0.279948 (1.460 sec)
6.179... logprob:  0.578788, 0.257812 (1.457 sec)
6.180... logprob:  0.642119, 0.282552 (1.434 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.443930, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.477716e-03 [3.303600e-07] 
Layer 'conv1' biases: 8.218437e-07 [1.347136e-09] 
Layer 'conv2' weights[0]: 6.466450e-03 [3.272760e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.142384e-09] 
Layer 'conv3' weights[0]: 6.465342e-03 [3.285850e-07] 
Layer 'conv3' biases: 1.706604e-05 [3.257580e-08] 
Layer 'conv4' weights[0]: 6.491560e-03 [3.336375e-07] 
Layer 'conv4' biases: 1.000017e+00 [3.866027e-07] 
Layer 'conv5' weights[0]: 6.521419e-03 [2.845610e-06] 
Layer 'conv5' biases: 9.993298e-01 [3.006247e-06] 
Layer 'fc6' weights[0]: 7.429827e-03 [6.744813e-08] 
Layer 'fc6' biases: 9.999985e-01 [6.703532e-08] 
Layer 'fc7' weights[0]: 7.785062e-03 [1.560253e-07] 
Layer 'fc7' biases: 9.999332e-01 [2.424689e-07] 
Layer 'fc8' weights[0]: 3.828669e-03 [3.029043e-05] 
Layer 'fc8' biases: 6.145167e-03 [6.785621e-05] 
Train error last 800 batches: 0.654477
-------------------------------------------------------
Not saving because 0.443930 > 0.303240 (5.60: -6.35%)
======================================================= (2.343 sec)
6.181... logprob:  0.805134, 0.363281 (1.421 sec)
6.182... logprob:  0.574686, 0.246094 (1.417 sec)
6.183... logprob:  0.679885, 0.269531 (1.420 sec)
6.184... logprob:  0.753260, 0.326823 (1.414 sec)
6.185... logprob:  0.614212, 0.281250 (1.393 sec)
6.186... logprob:  0.584830, 0.272135 (1.411 sec)
6.187... logprob:  0.775298, 0.330729 (1.411 sec)
6.188... logprob:  0.686731, 0.295573 (1.408 sec)
6.189... logprob:  0.640186, 0.265625 (1.401 sec)
6.190... logprob:  0.591231, 0.274740 (1.445 sec)
6.191... logprob:  0.643014, 0.278646 (1.627 sec)
6.192... logprob:  0.803882, 0.330729 (1.432 sec)
6.193... logprob:  0.530823, 0.239583 (1.433 sec)
6.194... logprob:  0.650282, 0.270833 (1.426 sec)
6.195... logprob:  0.508703, 0.222656 (1.397 sec)
6.196... logprob:  0.686269, 0.313802 (1.627 sec)
6.197... logprob:  0.717096, 0.295573 (1.402 sec)
6.198... logprob:  0.523451, 0.225260 (1.405 sec)
6.199... logprob:  0.730269, 0.326823 (1.386 sec)
6.200... logprob:  0.662878, 0.278646 (1.435 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.514066, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.471241e-03 [3.279030e-07] 
Layer 'conv1' biases: 8.286745e-07 [1.093133e-09] 
Layer 'conv2' weights[0]: 6.459978e-03 [3.254847e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.110568e-09] 
Layer 'conv3' weights[0]: 6.458918e-03 [3.274380e-07] 
Layer 'conv3' biases: 1.717949e-05 [3.161137e-08] 
Layer 'conv4' weights[0]: 6.485061e-03 [3.307019e-07] 
Layer 'conv4' biases: 1.000017e+00 [3.516772e-07] 
Layer 'conv5' weights[0]: 6.515101e-03 [2.370826e-06] 
Layer 'conv5' biases: 9.993302e-01 [2.512913e-06] 
Layer 'fc6' weights[0]: 7.429066e-03 [5.843513e-08] 
Layer 'fc6' biases: 9.999985e-01 [5.401208e-08] 
Layer 'fc7' weights[0]: 7.784263e-03 [1.270632e-07] 
Layer 'fc7' biases: 9.999336e-01 [1.565057e-07] 
Layer 'fc8' weights[0]: 3.864460e-03 [2.011929e-05] 
Layer 'fc8' biases: 6.414523e-03 [2.941327e-05] 
Train error last 800 batches: 0.655011
-------------------------------------------------------
Not saving because 0.514066 > 0.303240 (5.60: -6.35%)
======================================================= (2.385 sec)
6.201... logprob:  0.590457, 0.268229 (1.415 sec)
6.202... logprob:  0.702508, 0.300781 (1.405 sec)
6.203... logprob:  0.641475, 0.278646 (1.442 sec)
6.204... logprob:  0.699396, 0.311198 (1.395 sec)
6.205... logprob:  0.649748, 0.287760 (1.401 sec)
6.206... logprob:  0.611730, 0.281250 (1.404 sec)
6.207... logprob:  0.674165, 0.285156 (1.392 sec)
6.208... logprob:  0.712116, 0.295573 (1.397 sec)
6.209... logprob:  0.565495, 0.246094 (1.423 sec)
6.210... logprob:  0.695819, 0.324219 (1.463 sec)
6.211... logprob:  0.695564, 0.324219 (1.422 sec)
6.212... logprob:  0.680529, 0.292969 (1.407 sec)
6.213... logprob:  0.666420, 0.296875 (1.456 sec)
6.214... logprob:  0.793226, 0.312500 (1.426 sec)
6.215... logprob:  0.706136, 0.276042 (1.427 sec)
6.216... logprob:  0.719199, 0.298177 (1.478 sec)
6.217... logprob:  0.566120, 0.244792 (1.400 sec)
6.218... logprob:  0.608240, 0.229167 (1.434 sec)
6.219... logprob:  0.705835, 0.295573 (1.420 sec)
6.220... logprob:  0.674878, 0.298177 (1.422 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.499892, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.464766e-03 [3.276372e-07] 
Layer 'conv1' biases: 8.333921e-07 [1.171490e-09] 
Layer 'conv2' weights[0]: 6.453540e-03 [3.264051e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.461816e-09] 
Layer 'conv3' weights[0]: 6.452472e-03 [3.271606e-07] 
Layer 'conv3' biases: 1.725639e-05 [3.187298e-08] 
Layer 'conv4' weights[0]: 6.478577e-03 [3.314785e-07] 
Layer 'conv4' biases: 1.000018e+00 [3.785189e-07] 
Layer 'conv5' weights[0]: 6.509077e-03 [2.674163e-06] 
Layer 'conv5' biases: 9.993319e-01 [2.829171e-06] 
Layer 'fc6' weights[0]: 7.428273e-03 [6.011517e-08] 
Layer 'fc6' biases: 9.999984e-01 [5.629514e-08] 
Layer 'fc7' weights[0]: 7.783441e-03 [1.330114e-07] 
Layer 'fc7' biases: 9.999320e-01 [1.677054e-07] 
Layer 'fc8' weights[0]: 3.815051e-03 [2.027709e-05] 
Layer 'fc8' biases: 6.114782e-03 [2.562251e-05] 
Train error last 800 batches: 0.655547
-------------------------------------------------------
Not saving because 0.499892 > 0.303240 (5.60: -6.35%)
======================================================= (2.412 sec)
6.221... logprob:  0.616204, 0.289062 (1.408 sec)
6.222... logprob:  0.637144, 0.292969 (1.451 sec)
6.223... logprob:  0.823379, 0.341146 (1.428 sec)
6.224... logprob:  0.735544, 0.317708 (1.533 sec)
6.225... logprob:  0.635067, 0.307292 (1.453 sec)
6.226... logprob:  0.553280, 0.236979 (1.423 sec)
6.227... logprob:  0.674671, 0.304688 (1.418 sec)
6.228... logprob:  0.536245, 0.243490 (1.423 sec)
6.229... logprob:  0.721104, 0.325521 (1.415 sec)
6.230... logprob:  0.636732, 0.278646 (1.432 sec)
6.231... logprob:  0.604296, 0.276042 (1.420 sec)
6.232... logprob:  0.731653, 0.328125 (1.469 sec)
6.233... logprob:  0.671759, 0.329427 (1.423 sec)
6.234... logprob:  0.775461, 0.302083 (1.413 sec)
6.235... logprob:  0.596829, 0.295573 (1.470 sec)
6.236... logprob:  0.630629, 0.251302 (1.404 sec)
6.237... logprob:  0.492250, 0.208333 (1.426 sec)
6.238... logprob:  0.673718, 0.286458 (1.415 sec)
6.239... logprob:  0.642426, 0.281250 (1.423 sec)
6.240... logprob:  0.713921, 0.326823 (1.405 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.512766, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.458310e-03 [3.276111e-07] 
Layer 'conv1' biases: 8.376335e-07 [9.835797e-10] 
Layer 'conv2' weights[0]: 6.447093e-03 [3.259792e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.426401e-09] 
Layer 'conv3' weights[0]: 6.446046e-03 [3.265590e-07] 
Layer 'conv3' biases: 1.734422e-05 [2.949908e-08] 
Layer 'conv4' weights[0]: 6.472112e-03 [3.300565e-07] 
Layer 'conv4' biases: 1.000018e+00 [3.325385e-07] 
Layer 'conv5' weights[0]: 6.502744e-03 [2.142805e-06] 
Layer 'conv5' biases: 9.993215e-01 [2.286421e-06] 
Layer 'fc6' weights[0]: 7.427489e-03 [5.664679e-08] 
Layer 'fc6' biases: 9.999983e-01 [5.112980e-08] 
Layer 'fc7' weights[0]: 7.782670e-03 [1.195856e-07] 
Layer 'fc7' biases: 9.999322e-01 [1.320931e-07] 
Layer 'fc8' weights[0]: 3.845128e-03 [1.601881e-05] 
Layer 'fc8' biases: 6.357195e-03 [1.117134e-05] 
Train error last 800 batches: 0.655042
-------------------------------------------------------
Not saving because 0.512766 > 0.303240 (5.60: -6.35%)
======================================================= (2.363 sec)
6.241... logprob:  0.764873, 0.311198 (1.463 sec)
6.242... logprob:  0.552621, 0.269531 (1.435 sec)
6.243... logprob:  0.701718, 0.320312 (1.452 sec)
6.244... logprob:  0.591484, 0.291667 (1.454 sec)
6.245... logprob:  0.727119, 0.282552 (1.442 sec)
6.246... logprob:  0.600414, 0.269531 (1.469 sec)
6.247... logprob:  0.625976, 0.283854 (1.448 sec)
6.248... logprob:  0.471789, 0.190104 (1.425 sec)
6.249... logprob:  0.682407, 0.309896 (1.438 sec)
6.250... logprob:  0.776257, 0.328125 (1.423 sec)
6.251... logprob:  0.536956, 0.221354 (1.478 sec)
6.252... logprob:  0.591417, 0.279948 (1.429 sec)
6.253... logprob:  0.546063, 0.253906 (1.423 sec)
6.254... logprob:  0.655559, 0.294271 (1.467 sec)
6.255... logprob:  0.564737, 0.239583 (1.405 sec)
6.256... logprob:  0.693226, 0.308594 (1.449 sec)
6.257... logprob:  0.499565, 0.242187 (1.426 sec)
6.258... logprob:  0.684009, 0.287760 (1.421 sec)
6.259... logprob:  0.619986, 0.281250 (1.403 sec)
6.260... logprob:  0.508392, 0.246094 (1.464 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.493138, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.451860e-03 [3.273142e-07] 
Layer 'conv1' biases: 8.428053e-07 [1.214943e-09] 
Layer 'conv2' weights[0]: 6.440631e-03 [3.251640e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.727638e-09] 
Layer 'conv3' weights[0]: 6.439586e-03 [3.266117e-07] 
Layer 'conv3' biases: 1.742982e-05 [3.065001e-08] 
Layer 'conv4' weights[0]: 6.465685e-03 [3.310112e-07] 
Layer 'conv4' biases: 1.000017e+00 [3.706171e-07] 
Layer 'conv5' weights[0]: 6.496088e-03 [2.637803e-06] 
Layer 'conv5' biases: 9.993200e-01 [2.764879e-06] 
Layer 'fc6' weights[0]: 7.426720e-03 [5.793248e-08] 
Layer 'fc6' biases: 9.999983e-01 [5.326722e-08] 
Layer 'fc7' weights[0]: 7.781887e-03 [1.263321e-07] 
Layer 'fc7' biases: 9.999329e-01 [1.733894e-07] 
Layer 'fc8' weights[0]: 3.886647e-03 [1.956566e-05] 
Layer 'fc8' biases: 6.649975e-03 [3.532816e-05] 
Train error last 800 batches: 0.655502
-------------------------------------------------------
Not saving because 0.493138 > 0.303240 (5.60: -6.35%)
======================================================= (2.373 sec)
6.261... logprob:  0.751818, 0.309896 (1.427 sec)
6.262... logprob:  0.645324, 0.283854 (1.437 sec)
6.263... logprob:  0.665093, 0.255208 (1.447 sec)
6.264... logprob:  0.587469, 0.250000 (1.427 sec)
6.265... logprob:  0.644301, 0.273437 (1.416 sec)
6.266... logprob:  0.625408, 0.277344 (1.418 sec)
6.267... logprob:  0.652523, 0.261719 (1.418 sec)
6.268... logprob:  0.645433, 0.281250 (1.459 sec)
6.269... logprob:  0.751771, 0.272135 (1.413 sec)
6.270... logprob:  0.829800, 0.365885 (1.466 sec)
6.271... logprob:  0.586437, 0.269531 (1.442 sec)
6.272... logprob:  0.522089, 0.238281 (1.441 sec)
6.273... logprob:  0.706555, 0.316406 (1.468 sec)
6.274... logprob:  0.724737, 0.303385 (1.412 sec)
6.275... logprob:  0.641816, 0.282552 (1.426 sec)
6.276... logprob:  0.583697, 0.270833 (1.417 sec)
6.277... logprob:  0.574648, 0.252604 (1.424 sec)
6.278... logprob:  0.615620, 0.250000 (1.423 sec)
6.279... logprob:  0.579611, 0.270833 (1.464 sec)
6.280... logprob:  0.487904, 0.217448 (1.411 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.489120, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.445395e-03 [3.272322e-07] 
Layer 'conv1' biases: 8.493901e-07 [1.096565e-09] 
Layer 'conv2' weights[0]: 6.434223e-03 [3.251773e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.582148e-09] 
Layer 'conv3' weights[0]: 6.433082e-03 [3.261929e-07] 
Layer 'conv3' biases: 1.747651e-05 [2.849396e-08] 
Layer 'conv4' weights[0]: 6.459199e-03 [3.315756e-07] 
Layer 'conv4' biases: 1.000019e+00 [3.729457e-07] 
Layer 'conv5' weights[0]: 6.490527e-03 [2.476962e-06] 
Layer 'conv5' biases: 9.993226e-01 [2.554493e-06] 
Layer 'fc6' weights[0]: 7.425954e-03 [6.058218e-08] 
Layer 'fc6' biases: 9.999983e-01 [5.712262e-08] 
Layer 'fc7' weights[0]: 7.781087e-03 [1.329820e-07] 
Layer 'fc7' biases: 9.999318e-01 [1.890932e-07] 
Layer 'fc8' weights[0]: 3.841932e-03 [2.025704e-05] 
Layer 'fc8' biases: 6.287570e-03 [3.708886e-05] 
Train error last 800 batches: 0.654913
-------------------------------------------------------
Not saving because 0.489120 > 0.303240 (5.60: -6.35%)
======================================================= (2.360 sec)
6.281... logprob:  0.607180, 0.248698 (1.431 sec)
6.282... logprob:  0.639896, 0.290365 (1.427 sec)
6.283... logprob:  0.625603, 0.296875 (1.418 sec)
6.284... logprob:  0.609954, 0.283854 (1.411 sec)
6.285... logprob:  0.597179, 0.248698 (1.449 sec)
6.286... logprob:  0.652176, 0.268229 (1.438 sec)
6.287... logprob:  0.609325, 0.269531 (1.589 sec)
6.288... logprob:  0.609141, 0.291667 (1.447 sec)
6.289... logprob:  0.737900, 0.313802 (1.450 sec)
6.290... logprob:  0.678797, 0.300781 (1.409 sec)
6.291... logprob:  0.709034, 0.303385 (1.431 sec)
6.292... logprob:  0.761540, 0.337240 (1.423 sec)
6.293... logprob:  0.681581, 0.295573 (1.426 sec)
6.294... logprob:  0.567338, 0.251302 (1.431 sec)
6.295... logprob:  0.511280, 0.248698 (1.481 sec)
6.296... logprob:  0.611111, 0.291667 (1.424 sec)
6.297... logprob:  0.594216, 0.260417 (1.425 sec)
6.298... logprob:  0.647876, 0.278646 (1.463 sec)
6.299... logprob:  0.518033, 0.208333 (1.428 sec)
6.300... logprob:  0.630567, 0.309896 (1.452 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.399386, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.438944e-03 [3.270615e-07] 
Layer 'conv1' biases: 8.544057e-07 [1.010807e-09] 
Layer 'conv2' weights[0]: 6.427766e-03 [3.245547e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.331380e-09] 
Layer 'conv3' weights[0]: 6.426682e-03 [3.256732e-07] 
Layer 'conv3' biases: 1.751212e-05 [2.961322e-08] 
Layer 'conv4' weights[0]: 6.452722e-03 [3.293784e-07] 
Layer 'conv4' biases: 1.000018e+00 [3.366057e-07] 
Layer 'conv5' weights[0]: 6.484145e-03 [2.203066e-06] 
Layer 'conv5' biases: 9.993202e-01 [2.233121e-06] 
Layer 'fc6' weights[0]: 7.425176e-03 [5.586553e-08] 
Layer 'fc6' biases: 9.999983e-01 [5.004069e-08] 
Layer 'fc7' weights[0]: 7.780324e-03 [1.185110e-07] 
Layer 'fc7' biases: 9.999318e-01 [1.461297e-07] 
Layer 'fc8' weights[0]: 3.867450e-03 [1.756693e-05] 
Layer 'fc8' biases: 6.508472e-03 [2.738146e-05] 
Train error last 800 batches: 0.654811
-------------------------------------------------------
Not saving because 0.399386 > 0.303240 (5.60: -6.35%)
======================================================= (2.391 sec)
6.301... logprob:  0.613192, 0.240885 (1.427 sec)
6.302... logprob:  0.723561, 0.294271 (1.422 sec)
6.303... logprob:  0.639551, 0.287760 (1.480 sec)
6.304... logprob:  0.726137, 0.309896 (1.447 sec)
6.305... logprob:  0.676219, 0.270833 (1.456 sec)
6.306... logprob:  0.559301, 0.247396 (1.477 sec)
6.307... logprob:  0.648695, 0.294271 (1.452 sec)
6.308... logprob:  0.656635, 0.290365 (1.465 sec)
6.309... logprob:  0.775288, 0.332031 (1.425 sec)
6.310... logprob:  0.618127, 0.269531 (1.438 sec)
6.311... logprob:  0.637389, 0.265625 (1.427 sec)
6.312... logprob:  0.653901, 0.277344 (1.429 sec)
6.313... logprob:  0.690270, 0.300781 (1.422 sec)
6.314... logprob:  0.614298, 0.253906 (1.463 sec)
6.315... logprob:  0.516434, 0.236979 (1.444 sec)
6.316... logprob:  0.644778, 0.283854 (1.429 sec)
6.317... logprob:  0.569247, 0.233073 (1.473 sec)
6.318... logprob:  0.672645, 0.282552 (1.410 sec)
6.319... logprob:  0.683850, 0.316406 (1.427 sec)
6.320... logprob:  0.654348, 0.326823 (1.422 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.431893, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.432528e-03 [3.273014e-07] 
Layer 'conv1' biases: 8.606255e-07 [1.173652e-09] 
Layer 'conv2' weights[0]: 6.421325e-03 [3.249689e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.575776e-09] 
Layer 'conv3' weights[0]: 6.420261e-03 [3.260938e-07] 
Layer 'conv3' biases: 1.756723e-05 [3.246856e-08] 
Layer 'conv4' weights[0]: 6.446295e-03 [3.313286e-07] 
Layer 'conv4' biases: 1.000018e+00 [3.677831e-07] 
Layer 'conv5' weights[0]: 6.477722e-03 [2.508468e-06] 
Layer 'conv5' biases: 9.993145e-01 [2.630811e-06] 
Layer 'fc6' weights[0]: 7.424384e-03 [5.932373e-08] 
Layer 'fc6' biases: 9.999983e-01 [5.543240e-08] 
Layer 'fc7' weights[0]: 7.779530e-03 [1.292382e-07] 
Layer 'fc7' biases: 9.999308e-01 [1.738634e-07] 
Layer 'fc8' weights[0]: 3.865512e-03 [1.938390e-05] 
Layer 'fc8' biases: 6.504246e-03 [2.855679e-05] 
Train error last 800 batches: 0.654410
-------------------------------------------------------
Not saving because 0.431893 > 0.303240 (5.60: -6.35%)
======================================================= (2.352 sec)
6.321... logprob:  0.535297, 0.250000 (1.430 sec)
6.322... logprob:  0.654481, 0.305990 (1.413 sec)
6.323... logprob:  0.622928, 0.279948 (1.471 sec)
6.324... logprob:  0.775463, 0.317708 (1.419 sec)
6.325... logprob:  0.579480, 0.265625 (1.493 sec)
6.326... logprob:  0.593008, 0.263021 (1.464 sec)
6.327... logprob:  0.790697, 0.317708 (1.420 sec)
6.328... logprob:  0.754726, 0.304688 (1.426 sec)
6.329... logprob:  0.764346, 0.361979 (1.438 sec)
6.330... logprob:  0.645025, 0.282552 (1.429 sec)
6.331... logprob:  0.521208, 0.244792 (1.419 sec)
6.332... logprob:  0.713736, 0.311198 (1.524 sec)
6.333... logprob:  0.506186, 0.252604 (1.453 sec)
6.334... logprob:  0.821521, 0.334635 (1.441 sec)
6.335... logprob:  0.593322, 0.286458 (1.451 sec)
6.336... logprob:  0.696494, 0.299479 (1.458 sec)
6.337... logprob:  0.645693, 0.291667 (1.420 sec)
6.338... logprob:  0.601224, 0.238281 (1.422 sec)
6.339... logprob:  0.686334, 0.295573 (1.429 sec)
6.340... logprob:  0.659424, 0.266927 (1.425 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.418594, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.426070e-03 [3.270135e-07] 
Layer 'conv1' biases: 8.628614e-07 [1.017262e-09] 
Layer 'conv2' weights[0]: 6.414909e-03 [3.242414e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.424680e-09] 
Layer 'conv3' weights[0]: 6.413878e-03 [3.246862e-07] 
Layer 'conv3' biases: 1.757584e-05 [2.785695e-08] 
Layer 'conv4' weights[0]: 6.439820e-03 [3.292013e-07] 
Layer 'conv4' biases: 1.000017e+00 [3.510801e-07] 
Layer 'conv5' weights[0]: 6.471271e-03 [2.565304e-06] 
Layer 'conv5' biases: 9.993152e-01 [2.755992e-06] 
Layer 'fc6' weights[0]: 7.423617e-03 [5.873685e-08] 
Layer 'fc6' biases: 9.999982e-01 [5.453822e-08] 
Layer 'fc7' weights[0]: 7.778778e-03 [1.256952e-07] 
Layer 'fc7' biases: 9.999303e-01 [1.485087e-07] 
Layer 'fc8' weights[0]: 3.847876e-03 [1.772560e-05] 
Layer 'fc8' biases: 6.318102e-03 [2.175927e-05] 
Train error last 800 batches: 0.654178
-------------------------------------------------------
Not saving because 0.418594 > 0.303240 (5.60: -6.35%)
======================================================= (2.403 sec)
6.341... logprob:  0.719323, 0.320312 (1.425 sec)
6.342... logprob:  0.690841, 0.315104 (1.464 sec)
6.343... logprob:  0.653471, 0.260417 (1.444 sec)
6.344... logprob:  0.645475, 0.295573 (1.674 sec)
6.345... logprob:  0.740331, 0.291667 (1.447 sec)
6.346... logprob:  0.643412, 0.289062 (1.428 sec)
6.347... logprob:  0.620851, 0.276042 (1.483 sec)
6.348... logprob:  0.618796, 0.264323 (1.445 sec)
6.349... logprob:  0.679699, 0.303385 (1.429 sec)
6.350... logprob:  0.582792, 0.264323 (1.437 sec)
6.351... logprob:  0.752001, 0.334635 (1.430 sec)
6.352... logprob:  0.643522, 0.296875 (1.439 sec)
6.353... logprob:  0.654412, 0.285156 (1.488 sec)
6.354... logprob:  0.833438, 0.355469 (1.428 sec)
6.355... logprob:  0.609659, 0.243490 (1.443 sec)
6.356... logprob:  0.757141, 0.290365 (1.477 sec)
6.357... logprob:  0.552118, 0.256510 (1.439 sec)
6.358... logprob:  0.583858, 0.236979 (1.448 sec)
6.359... logprob:  0.779539, 0.343750 (1.460 sec)
6.360... logprob:  0.601752, 0.279948 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.504114, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.419675e-03 [3.246072e-07] 
Layer 'conv1' biases: 8.673994e-07 [7.743998e-10] 
Layer 'conv2' weights[0]: 6.408488e-03 [3.236741e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.269523e-09] 
Layer 'conv3' weights[0]: 6.407426e-03 [3.245970e-07] 
Layer 'conv3' biases: 1.768905e-05 [2.956309e-08] 
Layer 'conv4' weights[0]: 6.433393e-03 [3.294766e-07] 
Layer 'conv4' biases: 1.000019e+00 [3.617711e-07] 
Layer 'conv5' weights[0]: 6.465675e-03 [2.501115e-06] 
Layer 'conv5' biases: 9.993102e-01 [2.684250e-06] 
Layer 'fc6' weights[0]: 7.422829e-03 [5.904927e-08] 
Layer 'fc6' biases: 9.999983e-01 [5.508077e-08] 
Layer 'fc7' weights[0]: 7.778037e-03 [1.287906e-07] 
Layer 'fc7' biases: 9.999301e-01 [1.542543e-07] 
Layer 'fc8' weights[0]: 3.830717e-03 [1.838776e-05] 
Layer 'fc8' biases: 6.143204e-03 [2.505028e-05] 
Train error last 800 batches: 0.654218
-------------------------------------------------------
Not saving because 0.504114 > 0.303240 (5.60: -6.35%)
======================================================= (2.379 sec)
6.361... logprob:  0.667918, 0.285156 (1.443 sec)
6.362... logprob:  0.622380, 0.291667 (1.474 sec)
6.363... logprob:  0.632878, 0.277344 (1.631 sec)
6.364... logprob:  0.638804, 0.265625 (1.458 sec)
6.365... logprob:  0.627846, 0.255208 (1.465 sec)
6.366... logprob:  0.601050, 0.279948 (1.443 sec)
6.367... logprob:  0.574865, 0.248698 (1.450 sec)
6.368... logprob:  0.783847, 0.334635 (1.423 sec)
6.369... logprob:  0.657240, 0.259115 (1.424 sec)
6.370... logprob:  0.563499, 0.265625 (1.444 sec)
6.371... logprob:  0.600849, 0.276042 (1.452 sec)
6.372... logprob:  0.702995, 0.334635 (1.452 sec)
6.373... logprob:  0.650218, 0.273437 (1.446 sec)
6.374... logprob:  0.756626, 0.285156 (1.456 sec)
6.375... logprob:  0.595198, 0.255208 (1.462 sec)
6.376... logprob:  0.564353, 0.266927 (1.442 sec)
6.377... logprob:  0.515478, 0.263021 (1.426 sec)
6.378... logprob:  0.772855, 0.352865 (1.421 sec)
6.379... logprob:  0.665839, 0.300781 (1.434 sec)
6.380... logprob:  0.848228, 0.333333 (1.436 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.468515, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.413256e-03 [3.259704e-07] 
Layer 'conv1' biases: 8.725316e-07 [1.317283e-09] 
Layer 'conv2' weights[0]: 6.402112e-03 [3.241096e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.038625e-09] 
Layer 'conv3' weights[0]: 6.401072e-03 [3.255090e-07] 
Layer 'conv3' biases: 1.780506e-05 [3.592436e-08] 
Layer 'conv4' weights[0]: 6.426998e-03 [3.305731e-07] 
Layer 'conv4' biases: 1.000020e+00 [4.234165e-07] 
Layer 'conv5' weights[0]: 6.459232e-03 [2.834538e-06] 
Layer 'conv5' biases: 9.993074e-01 [3.040198e-06] 
Layer 'fc6' weights[0]: 7.422029e-03 [6.397262e-08] 
Layer 'fc6' biases: 9.999982e-01 [6.247799e-08] 
Layer 'fc7' weights[0]: 7.777245e-03 [1.432815e-07] 
Layer 'fc7' biases: 9.999303e-01 [2.009027e-07] 
Layer 'fc8' weights[0]: 3.859695e-03 [2.479371e-05] 
Layer 'fc8' biases: 6.358037e-03 [4.953380e-05] 
Train error last 800 batches: 0.653865
-------------------------------------------------------
Not saving because 0.468515 > 0.303240 (5.60: -6.35%)
======================================================= (2.366 sec)
6.381... logprob:  0.718034, 0.311198 (1.472 sec)
6.382... logprob:  0.731639, 0.273438 (1.487 sec)
6.383... logprob:  0.599930, 0.295573 (1.450 sec)
6.384... logprob:  0.723083, 0.319010 (1.491 sec)
6.385... logprob:  0.682216, 0.315104 (1.435 sec)
6.386... logprob:  0.699402, 0.317708 (1.430 sec)
6.387... logprob:  0.724760, 0.345052 (1.435 sec)
6.388... logprob:  0.694670, 0.290365 (1.439 sec)
6.389... logprob:  0.706410, 0.321614 (1.434 sec)
6.390... logprob:  0.714481, 0.312500 (1.481 sec)
6.391... logprob:  0.525939, 0.233073 (1.448 sec)
6.392... logprob:  0.613075, 0.294271 (1.444 sec)
6.393... logprob:  0.559223, 0.251302 (1.493 sec)
6.394... logprob:  0.577097, 0.257812 (1.435 sec)
6.395... logprob:  0.606614, 0.274740 (1.433 sec)
6.396... logprob:  0.499153, 0.213542 (1.438 sec)
6.397... logprob:  0.631439, 0.290365 (1.432 sec)
6.398... logprob:  0.708225, 0.307292 (1.475 sec)
6.399... logprob:  0.582100, 0.272135 (1.478 sec)
6.400... logprob:  0.667414, 0.285156 (1.448 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.542987, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.406845e-03 [3.250848e-07] 
Layer 'conv1' biases: 8.821763e-07 [1.265584e-09] 
Layer 'conv2' weights[0]: 6.395717e-03 [3.234795e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.594208e-09] 
Layer 'conv3' weights[0]: 6.394645e-03 [3.255983e-07] 
Layer 'conv3' biases: 1.778789e-05 [3.539710e-08] 
Layer 'conv4' weights[0]: 6.420597e-03 [3.306454e-07] 
Layer 'conv4' biases: 1.000019e+00 [4.077155e-07] 
Layer 'conv5' weights[0]: 6.452391e-03 [2.869465e-06] 
Layer 'conv5' biases: 9.993006e-01 [2.909075e-06] 
Layer 'fc6' weights[0]: 7.421265e-03 [6.715923e-08] 
Layer 'fc6' biases: 9.999983e-01 [6.723941e-08] 
Layer 'fc7' weights[0]: 7.776435e-03 [1.556257e-07] 
Layer 'fc7' biases: 9.999311e-01 [2.501054e-07] 
Layer 'fc8' weights[0]: 3.912197e-03 [2.736844e-05] 
Layer 'fc8' biases: 6.715041e-03 [5.847034e-05] 
Train error last 800 batches: 0.653795
-------------------------------------------------------
Not saving because 0.542987 > 0.303240 (5.60: -6.35%)
======================================================= (2.390 sec)
6.401... logprob:  0.664049, 0.274739 (1.480 sec)
6.402... logprob:  0.703638, 0.338542 (1.498 sec)
6.403... logprob:  0.708951, 0.295573 (1.441 sec)
6.404... logprob:  0.658817, 0.247396 (1.446 sec)
6.405... logprob:  0.840920, 0.333333 (1.444 sec)
6.406... logprob:  0.602259, 0.283854 (1.429 sec)
6.407... logprob:  0.675287, 0.287760 (1.445 sec)
6.408... logprob:  0.499438, 0.238281 (1.490 sec)
6.409... logprob:  0.580155, 0.225260 (1.439 sec)
6.410... logprob:  0.718173, 0.322917 (1.456 sec)
6.411... logprob:  0.638718, 0.274740 (1.477 sec)
6.412... logprob:  0.655126, 0.313802 (1.440 sec)
6.413... logprob:  0.822798, 0.351563 (1.440 sec)
6.414... logprob:  0.594429, 0.291667 (1.438 sec)
6.415... logprob:  0.658650, 0.295573 (1.429 sec)
6.416... logprob:  0.636467, 0.299479 (1.439 sec)
6.417... logprob:  0.579626, 0.264323 (1.468 sec)
6.418... logprob:  0.596599, 0.242187 (1.452 sec)
6.419... logprob:  0.630284, 0.277344 (1.450 sec)
6.420... logprob:  0.559240, 0.270833 (1.500 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.417638, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.400425e-03 [3.243444e-07] 
Layer 'conv1' biases: 8.869034e-07 [8.268887e-10] 
Layer 'conv2' weights[0]: 6.389301e-03 [3.222237e-07] 
Layer 'conv2' biases: 9.999995e-01 [6.697676e-09] 
Layer 'conv3' weights[0]: 6.388237e-03 [3.232925e-07] 
Layer 'conv3' biases: 1.788204e-05 [2.705120e-08] 
Layer 'conv4' weights[0]: 6.414140e-03 [3.278720e-07] 
Layer 'conv4' biases: 1.000019e+00 [3.421507e-07] 
Layer 'conv5' weights[0]: 6.446444e-03 [2.381506e-06] 
Layer 'conv5' biases: 9.993010e-01 [2.571125e-06] 
Layer 'fc6' weights[0]: 7.420490e-03 [6.028893e-08] 
Layer 'fc6' biases: 9.999982e-01 [5.684596e-08] 
Layer 'fc7' weights[0]: 7.775636e-03 [1.331202e-07] 
Layer 'fc7' biases: 9.999297e-01 [1.919445e-07] 
Layer 'fc8' weights[0]: 3.879591e-03 [2.182587e-05] 
Layer 'fc8' biases: 6.458985e-03 [4.534973e-05] 
Train error last 800 batches: 0.653588
-------------------------------------------------------
Not saving because 0.417638 > 0.303240 (5.60: -6.35%)
======================================================= (2.367 sec)
6.421... logprob:  0.595187, 0.261719 (1.462 sec)
6.422... logprob:  0.655083, 0.276042 (1.433 sec)
6.423... logprob:  0.632990, 0.294271 (1.426 sec)
6.424... logprob:  0.537294, 0.247396 (1.443 sec)
6.425... logprob:  0.634938, 0.308594 (1.442 sec)
6.426... logprob:  0.708748, 0.276042 (1.456 sec)
6.427... logprob:  0.690857, 0.287760 (1.460 sec)
6.428... logprob:  0.796676, 0.354167 (1.456 sec)
6.429... logprob:  0.705101, 0.303385 (1.458 sec)
6.430... logprob:  0.564767, 0.263021 (1.486 sec)
6.431... logprob:  0.780784, 0.333333 (1.442 sec)
6.432... logprob:  0.609574, 0.270833 (1.429 sec)
6.433... logprob:  0.595221, 0.272135 (1.437 sec)
6.434... logprob:  0.823641, 0.345052 (1.446 sec)
6.435... logprob:  0.720109, 0.328125 (1.433 sec)
6.436... logprob:  0.546636, 0.264323 (1.478 sec)
6.437... logprob:  0.630794, 0.259115 (1.455 sec)
6.438... logprob:  0.776094, 0.302083 (1.436 sec)
6.439... logprob:  0.630399, 0.259115 (1.487 sec)
6.440... logprob:  0.697679, 0.276042 (1.435 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.386902, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.394062e-03 [3.262498e-07] 
Layer 'conv1' biases: 8.919310e-07 [1.548010e-09] 
Layer 'conv2' weights[0]: 6.382945e-03 [3.224087e-07] 
Layer 'conv2' biases: 9.999995e-01 [9.073845e-09] 
Layer 'conv3' weights[0]: 6.381827e-03 [3.250861e-07] 
Layer 'conv3' biases: 1.789407e-05 [3.805293e-08] 
Layer 'conv4' weights[0]: 6.407738e-03 [3.300629e-07] 
Layer 'conv4' biases: 1.000020e+00 [4.322278e-07] 
Layer 'conv5' weights[0]: 6.440417e-03 [3.028185e-06] 
Layer 'conv5' biases: 9.993047e-01 [3.257211e-06] 
Layer 'fc6' weights[0]: 7.419713e-03 [6.940949e-08] 
Layer 'fc6' biases: 9.999982e-01 [7.022839e-08] 
Layer 'fc7' weights[0]: 7.774808e-03 [1.610818e-07] 
Layer 'fc7' biases: 9.999293e-01 [2.540733e-07] 
Layer 'fc8' weights[0]: 3.841206e-03 [2.635421e-05] 
Layer 'fc8' biases: 6.184518e-03 [5.165876e-05] 
Train error last 800 batches: 0.653550
-------------------------------------------------------
Not saving because 0.386902 > 0.303240 (5.60: -6.35%)
======================================================= (2.363 sec)
6.441... logprob:  0.606316, 0.250000 (1.448 sec)
6.442... logprob:  0.601054, 0.291667 (1.446 sec)
6.443... logprob:  0.747473, 0.289063 (1.438 sec)
6.444... logprob:  0.601534, 0.243490 (1.435 sec)
6.445... logprob:  0.598149, 0.242187 (1.493 sec)
6.446... logprob:  0.561230, 0.223958 (1.436 sec)
6.447... logprob:  0.673580, 0.285156 (1.442 sec)
6.448... logprob:  0.578074, 0.261719 (1.489 sec)
6.449... logprob:  0.594102, 0.244792 (1.448 sec)
6.450... logprob:  0.556697, 0.259114 (1.434 sec)
6.451... logprob:  0.641408, 0.277344 (1.436 sec)
6.452... logprob:  0.583044, 0.253906 (1.422 sec)
6.453... logprob:  0.677221, 0.290365 (1.436 sec)
6.454... logprob:  0.670063, 0.283854 (1.484 sec)
6.455... logprob:  0.700664, 0.317708 (1.442 sec)
6.456... logprob:  0.631631, 0.282552 (1.456 sec)
6.457... logprob:  0.642189, 0.277344 (1.485 sec)
6.458... logprob:  0.541084, 0.238281 (1.447 sec)
6.459... logprob:  0.795906, 0.315104 (1.450 sec)
6.460... logprob:  0.587758, 0.282552 (1.448 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.497057, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.387648e-03 [3.249675e-07] 
Layer 'conv1' biases: 8.951463e-07 [1.162385e-09] 
Layer 'conv2' weights[0]: 6.376539e-03 [3.214782e-07] 
Layer 'conv2' biases: 9.999995e-01 [6.797259e-09] 
Layer 'conv3' weights[0]: 6.375506e-03 [3.219726e-07] 
Layer 'conv3' biases: 1.792276e-05 [2.727430e-08] 
Layer 'conv4' weights[0]: 6.401292e-03 [3.253257e-07] 
Layer 'conv4' biases: 1.000019e+00 [2.946398e-07] 
Layer 'conv5' weights[0]: 6.433917e-03 [2.332691e-06] 
Layer 'conv5' biases: 9.992982e-01 [2.483823e-06] 
Layer 'fc6' weights[0]: 7.418945e-03 [5.694127e-08] 
Layer 'fc6' biases: 9.999983e-01 [5.174319e-08] 
Layer 'fc7' weights[0]: 7.774004e-03 [1.234417e-07] 
Layer 'fc7' biases: 9.999295e-01 [1.441765e-07] 
Layer 'fc8' weights[0]: 3.885949e-03 [1.770236e-05] 
Layer 'fc8' biases: 6.496721e-03 [2.615483e-05] 
Train error last 800 batches: 0.653319
-------------------------------------------------------
Not saving because 0.497057 > 0.303240 (5.60: -6.35%)
======================================================= (2.376 sec)
6.461... logprob:  0.611273, 0.286458 (1.431 sec)
6.462... logprob:  0.667278, 0.290365 (1.437 sec)
6.463... logprob:  0.686279, 0.321615 (1.474 sec)
6.464... logprob:  0.634885, 0.285156 (1.444 sec)
6.465... logprob:  0.635916, 0.268229 (1.451 sec)
6.466... logprob:  0.500795, 0.233073 (1.457 sec)
6.467... logprob:  0.640563, 0.298177 (1.446 sec)
6.468... logprob:  0.700471, 0.321615 (1.429 sec)
6.469... logprob:  0.567047, 0.263021 (1.427 sec)
6.470... logprob:  0.580476, 0.273438 (1.427 sec)
6.471... logprob:  0.693244, 0.265625 (1.431 sec)
6.472... logprob:  0.660186, 0.316406 (1.451 sec)
6.473... logprob:  0.611839, 0.287760 (1.455 sec)
6.474... logprob:  0.700265, 0.305990 (1.446 sec)
6.475... logprob:  0.701180, 0.299479 (1.443 sec)
6.476... logprob:  0.693770, 0.283854 (1.461 sec)
6.477... logprob:  0.587507, 0.264323 (1.429 sec)
6.478... logprob:  0.761298, 0.325521 (1.430 sec)
6.479... logprob:  0.552299, 0.264323 (1.433 sec)
6.480... logprob:  0.628036, 0.272135 (1.438 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.469776, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.381279e-03 [3.228683e-07] 
Layer 'conv1' biases: 9.023354e-07 [8.681024e-10] 
Layer 'conv2' weights[0]: 6.370182e-03 [3.210169e-07] 
Layer 'conv2' biases: 9.999995e-01 [6.068005e-09] 
Layer 'conv3' weights[0]: 6.369110e-03 [3.211747e-07] 
Layer 'conv3' biases: 1.799235e-05 [2.466590e-08] 
Layer 'conv4' weights[0]: 6.394939e-03 [3.247307e-07] 
Layer 'conv4' biases: 1.000019e+00 [2.978456e-07] 
Layer 'conv5' weights[0]: 6.427630e-03 [2.118140e-06] 
Layer 'conv5' biases: 9.992995e-01 [2.234361e-06] 
Layer 'fc6' weights[0]: 7.418169e-03 [5.562782e-08] 
Layer 'fc6' biases: 9.999983e-01 [4.986753e-08] 
Layer 'fc7' weights[0]: 7.773273e-03 [1.184706e-07] 
Layer 'fc7' biases: 9.999289e-01 [1.305206e-07] 
Layer 'fc8' weights[0]: 3.886810e-03 [1.544919e-05] 
Layer 'fc8' biases: 6.508240e-03 [9.336917e-06] 
Train error last 800 batches: 0.652917
-------------------------------------------------------
Not saving because 0.469776 > 0.303240 (5.60: -6.35%)
======================================================= (2.373 sec)
6.481... logprob:  0.650777, 0.272135 (1.444 sec)
6.482... logprob:  0.628111, 0.278646 (1.483 sec)
6.483... logprob:  0.664616, 0.279948 (1.480 sec)
6.484... logprob:  0.692594, 0.309896 (1.436 sec)
6.485... logprob:  0.578954, 0.261719 (1.476 sec)
6.486... logprob:  0.637665, 0.277344 (1.426 sec)
6.487... logprob:  0.739399, 0.321615 (1.423 sec)
6.488... logprob:  0.654045, 0.281250 (1.428 sec)
6.489... logprob:  0.677718, 0.307292 (1.429 sec)
6.490... logprob:  0.677586, 0.285156 (1.434 sec)
6.491... logprob:  0.590286, 0.256510 (1.471 sec)
6.492... logprob:  0.609318, 0.269531 (1.436 sec)
6.493... logprob:  0.665288, 0.303385 (1.430 sec)
6.494... logprob:  0.651797, 0.304687 (1.478 sec)
6.495... logprob:  0.630163, 0.281250 (1.426 sec)
6.496... logprob:  0.710934, 0.292969 (1.426 sec)
6.497... logprob:  0.666522, 0.309896 (1.429 sec)
6.498... logprob:  0.688165, 0.313802 (1.428 sec)
6.499... logprob:  0.712218, 0.282552 (1.428 sec)
6.500... logprob:  0.536144, 0.259115 (1.484 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.429450, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.374887e-03 [3.232682e-07] 
Layer 'conv1' biases: 9.073985e-07 [1.158263e-09] 
Layer 'conv2' weights[0]: 6.363784e-03 [3.213853e-07] 
Layer 'conv2' biases: 9.999995e-01 [8.241590e-09] 
Layer 'conv3' weights[0]: 6.362747e-03 [3.220896e-07] 
Layer 'conv3' biases: 1.803205e-05 [2.809541e-08] 
Layer 'conv4' weights[0]: 6.388533e-03 [3.251719e-07] 
Layer 'conv4' biases: 1.000021e+00 [3.162098e-07] 
Layer 'conv5' weights[0]: 6.422032e-03 [2.392551e-06] 
Layer 'conv5' biases: 9.992928e-01 [2.561918e-06] 
Layer 'fc6' weights[0]: 7.417395e-03 [5.656619e-08] 
Layer 'fc6' biases: 9.999982e-01 [5.134009e-08] 
Layer 'fc7' weights[0]: 7.772504e-03 [1.209301e-07] 
Layer 'fc7' biases: 9.999286e-01 [1.391490e-07] 
Layer 'fc8' weights[0]: 3.871969e-03 [1.631901e-05] 
Layer 'fc8' biases: 6.412720e-03 [1.520917e-05] 
Train error last 800 batches: 0.652226
-------------------------------------------------------
Not saving because 0.429450 > 0.303240 (5.60: -6.35%)
======================================================= (2.374 sec)
6.501... logprob:  0.571786, 0.263021 (1.435 sec)
6.502... logprob:  0.716313, 0.303385 (1.447 sec)
6.503... logprob:  0.666777, 0.317708 (1.477 sec)
6.504... logprob:  0.774718, 0.341146 (1.426 sec)
6.505... logprob:  0.640580, 0.299479 (1.441 sec)
6.506... logprob:  0.660074, 0.282552 (1.432 sec)
6.507... logprob:  0.632919, 0.272135 (1.423 sec)
6.508... logprob:  0.650589, 0.295573 (1.427 sec)
6.509... logprob:  0.634767, 0.294271 (1.480 sec)
6.510... logprob:  0.669083, 0.295573 (1.434 sec)
6.511... logprob:  0.639263, 0.274739 (1.444 sec)
6.512... logprob:  0.627916, 0.277344 (1.460 sec)
6.513... logprob:  0.548345, 0.248698 (1.437 sec)
6.514... logprob:  0.620507, 0.274740 (1.432 sec)
6.515... logprob:  0.666496, 0.308594 (1.422 sec)
6.516... logprob:  0.603063, 0.240885 (1.420 sec)
6.517... logprob:  0.735282, 0.346354 (1.436 sec)
6.518... logprob:  0.732030, 0.295573 (1.455 sec)
6.519... logprob:  0.686116, 0.313802 (1.448 sec)
6.520... logprob:  0.649345, 0.274740 (1.445 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.427495, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.368495e-03 [3.228014e-07] 
Layer 'conv1' biases: 9.089232e-07 [1.209511e-09] 
Layer 'conv2' weights[0]: 6.357462e-03 [3.208521e-07] 
Layer 'conv2' biases: 9.999995e-01 [7.283166e-09] 
Layer 'conv3' weights[0]: 6.356423e-03 [3.218465e-07] 
Layer 'conv3' biases: 1.808050e-05 [3.085978e-08] 
Layer 'conv4' weights[0]: 6.382151e-03 [3.257567e-07] 
Layer 'conv4' biases: 1.000021e+00 [3.458709e-07] 
Layer 'conv5' weights[0]: 6.415881e-03 [2.413761e-06] 
Layer 'conv5' biases: 9.992839e-01 [2.609431e-06] 
Layer 'fc6' weights[0]: 7.416614e-03 [5.962724e-08] 
Layer 'fc6' biases: 9.999982e-01 [5.640957e-08] 
Layer 'fc7' weights[0]: 7.771724e-03 [1.295196e-07] 
Layer 'fc7' biases: 9.999292e-01 [1.640253e-07] 
Layer 'fc8' weights[0]: 3.917218e-03 [1.785932e-05] 
Layer 'fc8' biases: 6.691103e-03 [2.252578e-05] 
Train error last 800 batches: 0.652399
-------------------------------------------------------
Not saving because 0.427495 > 0.303240 (5.60: -6.35%)
======================================================= (2.406 sec)
6.521... logprob:  0.698645, 0.311198 (1.477 sec)
6.522... logprob:  0.748404, 0.342448 (1.463 sec)
6.523... logprob:  0.606162, 0.281250 (1.434 sec)
6.524... logprob:  0.631654, 0.276042 (1.422 sec)
6.525... logprob:  0.670633, 0.282552 (1.422 sec)
6.526... logprob:  0.613188, 0.277344 (1.431 sec)
6.527... logprob:  0.704457, 0.295573 (1.435 sec)
6.528... logprob:  0.667427, 0.308594 (1.461 sec)
6.529... logprob:  0.592805, 0.281250 (1.444 sec)
6.530... logprob:  0.660154, 0.274740 (1.433 sec)
6.531... logprob:  0.664506, 0.316406 (1.483 sec)
6.532... logprob:  0.622433, 0.250000 (1.425 sec)
6.533... logprob:  0.813753, 0.329427 (1.423 sec)
6.534... logprob:  0.536862, 0.259115 (1.430 sec)
6.535... logprob:  0.721189, 0.278646 (1.429 sec)
6.536... logprob:  0.765308, 0.347656 (1.433 sec)
6.537... logprob:  0.786312, 0.298177 (1.473 sec)
6.538... logprob:  0.678915, 0.303385 (1.434 sec)
6.539... logprob:  0.545637, 0.243489 (1.430 sec)
6.540... logprob:  0.680822, 0.270833 (1.477 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.396572, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.362151e-03 [3.241968e-07] 
Layer 'conv1' biases: 9.145402e-07 [1.256465e-09] 
Layer 'conv2' weights[0]: 6.351077e-03 [3.216860e-07] 
Layer 'conv2' biases: 9.999995e-01 [8.629477e-09] 
Layer 'conv3' weights[0]: 6.349998e-03 [3.233715e-07] 
Layer 'conv3' biases: 1.814736e-05 [3.421045e-08] 
Layer 'conv4' weights[0]: 6.375761e-03 [3.270391e-07] 
Layer 'conv4' biases: 1.000022e+00 [4.015614e-07] 
Layer 'conv5' weights[0]: 6.410023e-03 [2.801008e-06] 
Layer 'conv5' biases: 9.992874e-01 [2.878136e-06] 
Layer 'fc6' weights[0]: 7.415821e-03 [6.262430e-08] 
Layer 'fc6' biases: 9.999983e-01 [6.082016e-08] 
Layer 'fc7' weights[0]: 7.770983e-03 [1.404825e-07] 
Layer 'fc7' biases: 9.999269e-01 [1.900338e-07] 
Layer 'fc8' weights[0]: 3.845387e-03 [2.174137e-05] 
Layer 'fc8' biases: 6.235911e-03 [3.736264e-05] 
Train error last 800 batches: 0.652418
-------------------------------------------------------
Not saving because 0.396572 > 0.303240 (5.60: -6.35%)
======================================================= (2.374 sec)
6.541... logprob:  0.611220, 0.266927 (1.437 sec)
6.542... logprob:  0.669140, 0.294271 (1.434 sec)
6.543... logprob:  0.541385, 0.263021 (1.439 sec)
6.544... logprob:  0.645788, 0.294271 (1.429 sec)
6.545... logprob:  0.571431, 0.252604 (1.429 sec)
6.546... logprob:  0.663387, 0.283854 (1.477 sec)
6.547... logprob:  0.594760, 0.279948 (1.430 sec)
6.548... logprob:  0.701670, 0.313802 (1.436 sec)
6.549... logprob:  0.645122, 0.261719 (1.471 sec)
6.550... logprob:  0.601575, 0.274740 (1.430 sec)
6.551... logprob:  0.653751, 0.277344 (1.433 sec)
6.552... logprob:  0.645016, 0.264323 (1.426 sec)
6.553... logprob:  0.619952, 0.302083 (1.421 sec)
6.554... logprob:  0.654923, 0.291667 (1.433 sec)
6.555... logprob:  0.657918, 0.291667 (1.473 sec)
6.556... logprob:  0.530124, 0.264323 (1.432 sec)
6.557... logprob:  0.695721, 0.309896 (1.440 sec)
6.558... logprob:  0.523312, 0.240885 (1.468 sec)
6.559... logprob:  0.611414, 0.260417 (1.431 sec)
6.560... logprob:  0.586590, 0.272135 (1.434 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.548129, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.355810e-03 [3.227630e-07] 
Layer 'conv1' biases: 9.161239e-07 [1.016638e-09] 
Layer 'conv2' weights[0]: 6.344746e-03 [3.212011e-07] 
Layer 'conv2' biases: 9.999995e-01 [8.572511e-09] 
Layer 'conv3' weights[0]: 6.343662e-03 [3.224299e-07] 
Layer 'conv3' biases: 1.820601e-05 [3.254275e-08] 
Layer 'conv4' weights[0]: 6.369435e-03 [3.272968e-07] 
Layer 'conv4' biases: 1.000022e+00 [3.901591e-07] 
Layer 'conv5' weights[0]: 6.403539e-03 [2.443489e-06] 
Layer 'conv5' biases: 9.992763e-01 [2.607013e-06] 
Layer 'fc6' weights[0]: 7.415045e-03 [5.664032e-08] 
Layer 'fc6' biases: 9.999982e-01 [5.172302e-08] 
Layer 'fc7' weights[0]: 7.770184e-03 [1.228039e-07] 
Layer 'fc7' biases: 9.999280e-01 [1.575949e-07] 
Layer 'fc8' weights[0]: 3.932885e-03 [1.849555e-05] 
Layer 'fc8' biases: 6.778633e-03 [2.786235e-05] 
Train error last 800 batches: 0.652314
-------------------------------------------------------
Not saving because 0.548129 > 0.303240 (5.60: -6.35%)
======================================================= (2.416 sec)
6.561... logprob:  0.735267, 0.300781 (1.435 sec)
6.562... logprob:  0.663743, 0.290365 (1.426 sec)
6.563... logprob:  0.512986, 0.210938 (1.437 sec)
6.564... logprob:  0.710436, 0.300781 (1.460 sec)
6.565... logprob:  0.864856, 0.367188 (1.445 sec)
6.566... logprob:  0.630911, 0.277344 (1.455 sec)
6.567... logprob:  0.600371, 0.296875 (1.453 sec)
6.568... logprob:  0.764299, 0.321614 (1.454 sec)
6.569... logprob:  0.644738, 0.282552 (1.435 sec)
6.570... logprob:  0.730706, 0.315104 (1.421 sec)
6.571... logprob:  0.701891, 0.276042 (1.422 sec)
6.572... logprob:  0.739865, 0.312500 (1.435 sec)
6.573... logprob:  0.764154, 0.346354 (1.440 sec)
6.574... logprob:  0.661577, 0.281250 (1.454 sec)
6.575... logprob:  0.582586, 0.250000 (1.449 sec)
6.576... logprob:  0.620457, 0.253906 (1.445 sec)
6.577... logprob:  0.611807, 0.250000 (1.468 sec)
6.578... logprob:  0.611686, 0.290364 (1.425 sec)
6.579... logprob:  0.680291, 0.305989 (1.423 sec)
6.580... logprob:  0.660909, 0.273437 (1.423 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.472581, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.349439e-03 [3.229539e-07] 
Layer 'conv1' biases: 9.181720e-07 [9.402131e-10] 
Layer 'conv2' weights[0]: 6.338420e-03 [3.203689e-07] 
Layer 'conv2' biases: 9.999995e-01 [6.232876e-09] 
Layer 'conv3' weights[0]: 6.337366e-03 [3.212082e-07] 
Layer 'conv3' biases: 1.828562e-05 [2.803219e-08] 
Layer 'conv4' weights[0]: 6.363068e-03 [3.260576e-07] 
Layer 'conv4' biases: 1.000021e+00 [3.418164e-07] 
Layer 'conv5' weights[0]: 6.397157e-03 [2.638742e-06] 
Layer 'conv5' biases: 9.992875e-01 [2.894542e-06] 
Layer 'fc6' weights[0]: 7.414298e-03 [5.832100e-08] 
Layer 'fc6' biases: 9.999982e-01 [5.440576e-08] 
Layer 'fc7' weights[0]: 7.769401e-03 [1.246191e-07] 
Layer 'fc7' biases: 9.999270e-01 [1.400653e-07] 
Layer 'fc8' weights[0]: 3.851343e-03 [1.668599e-05] 
Layer 'fc8' biases: 6.232900e-03 [1.548132e-05] 
Train error last 800 batches: 0.652440
-------------------------------------------------------
Not saving because 0.472581 > 0.303240 (5.60: -6.35%)
======================================================= (2.400 sec)
6.581... logprob:  0.743574, 0.328125 (1.443 sec)
6.582... logprob:  0.697549, 0.282552 (1.437 sec)
6.583... logprob:  0.729661, 0.312500 (1.475 sec)
6.584... logprob:  0.608212, 0.291667 (1.440 sec)
6.585... logprob:  0.656928, 0.311198 (1.427 sec)
6.586... logprob:  0.578200, 0.264323 (1.487 sec)
6.587... logprob:  0.638297, 0.268229 (1.427 sec)
6.588... logprob:  0.695960, 0.313802 (1.424 sec)
6.589... logprob:  0.673836, 0.319010 (1.432 sec)
6.590... logprob:  0.694009, 0.316406 (1.431 sec)
6.591... logprob:  0.697788, 0.289062 (1.425 sec)
6.592... logprob:  0.618544, 0.265625 (1.478 sec)
6.593... logprob:  0.729579, 0.329427 (1.429 sec)
6.594... logprob:  0.596797, 0.265625 (1.433 sec)
6.595... logprob:  0.685512, 0.335937 (1.476 sec)
6.596... logprob:  0.694307, 0.289062 (1.426 sec)
6.597... logprob:  0.626850, 0.312500 (1.426 sec)
6.598... logprob:  0.608558, 0.277344 (1.427 sec)
6.599... logprob:  0.552380, 0.263021 (1.452 sec)
6.600... logprob:  0.588274, 0.274740 (1.424 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.379187, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.343120e-03 [3.201119e-07] 
Layer 'conv1' biases: 9.195389e-07 [1.065373e-09] 
Layer 'conv2' weights[0]: 6.332029e-03 [3.199606e-07] 
Layer 'conv2' biases: 9.999995e-01 [8.474903e-09] 
Layer 'conv3' weights[0]: 6.330995e-03 [3.215995e-07] 
Layer 'conv3' biases: 1.821259e-05 [3.142459e-08] 
Layer 'conv4' weights[0]: 6.356652e-03 [3.263238e-07] 
Layer 'conv4' biases: 1.000021e+00 [3.860963e-07] 
Layer 'conv5' weights[0]: 6.390174e-03 [2.709387e-06] 
Layer 'conv5' biases: 9.992816e-01 [2.906916e-06] 
Layer 'fc6' weights[0]: 7.413531e-03 [6.318657e-08] 
Layer 'fc6' biases: 9.999983e-01 [6.156486e-08] 
Layer 'fc7' weights[0]: 7.768589e-03 [1.418859e-07] 
Layer 'fc7' biases: 9.999271e-01 [2.218911e-07] 
Layer 'fc8' weights[0]: 3.924113e-03 [2.326080e-05] 
Layer 'fc8' biases: 6.742145e-03 [4.639487e-05] 
Train error last 800 batches: 0.652812
-------------------------------------------------------
Not saving because 0.379187 > 0.303240 (5.60: -6.35%)
======================================================= (2.358 sec)
6.601... logprob:  0.583822, 0.252604 (1.484 sec)
6.602... logprob:  0.587706, 0.268229 (1.437 sec)
6.603... logprob:  0.542633, 0.252604 (1.446 sec)
6.604... logprob:  0.579852, 0.253906 (1.471 sec)
6.605... logprob:  0.728821, 0.302083 (1.436 sec)
6.606... logprob:  0.484382, 0.233073 (1.439 sec)
6.607... logprob:  0.696637, 0.285156 (1.429 sec)
6.608... logprob:  0.542511, 0.260417 (1.422 sec)
6.609... logprob:  0.596602, 0.273437 (1.429 sec)
6.610... logprob:  0.569889, 0.272135 (1.464 sec)
6.611... logprob:  0.655895, 0.295573 (1.443 sec)
6.612... logprob:  0.675065, 0.290364 (1.450 sec)
6.613... logprob:  0.537913, 0.236979 (1.460 sec)
6.614... logprob:  0.735625, 0.324219 (1.448 sec)
6.615... logprob:  0.650819, 0.276042 (1.436 sec)
6.616... logprob:  0.672754, 0.282552 (1.427 sec)
6.617... logprob:  0.627489, 0.256510 (1.419 sec)
6.618... logprob:  0.740742, 0.305989 (1.430 sec)
6.619... logprob:  0.805086, 0.329427 (1.444 sec)
6.620... logprob:  0.732845, 0.321615 (1.457 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.424726, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.336760e-03 [3.250230e-07] 
Layer 'conv1' biases: 9.218030e-07 [2.094652e-09] 
Layer 'conv2' weights[0]: 6.325725e-03 [3.241034e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.438383e-08] 
Layer 'conv3' weights[0]: 6.324658e-03 [3.282797e-07] 
Layer 'conv3' biases: 1.825497e-05 [4.934221e-08] 
Layer 'conv4' weights[0]: 6.350330e-03 [3.375000e-07] 
Layer 'conv4' biases: 1.000020e+00 [6.206873e-07] 
Layer 'conv5' weights[0]: 6.383729e-03 [4.349808e-06] 
Layer 'conv5' biases: 9.992785e-01 [4.611972e-06] 
Layer 'fc6' weights[0]: 7.412767e-03 [8.841643e-08] 
Layer 'fc6' biases: 9.999983e-01 [1.005766e-07] 
Layer 'fc7' weights[0]: 7.767855e-03 [2.269452e-07] 
Layer 'fc7' biases: 9.999276e-01 [4.267156e-07] 
Layer 'fc8' weights[0]: 3.941713e-03 [3.646717e-05] 
Layer 'fc8' biases: 6.930877e-03 [8.023047e-05] 
Train error last 800 batches: 0.652358
-------------------------------------------------------
Not saving because 0.424726 > 0.303240 (5.60: -6.35%)
======================================================= (2.340 sec)
6.621... logprob:  0.646987, 0.299479 (1.461 sec)
6.622... logprob:  0.611563, 0.273438 (1.445 sec)
6.623... logprob:  0.650429, 0.283854 (1.462 sec)
6.624... logprob:  0.609328, 0.273437 (1.434 sec)
6.625... logprob:  0.599387, 0.260417 (1.422 sec)
6.626... logprob:  0.656476, 0.287760 (1.429 sec)
6.627... logprob:  0.646178, 0.274740 (1.438 sec)
6.628... logprob:  0.691198, 0.302083 (1.455 sec)
6.629... logprob:  0.581905, 0.266927 (1.492 sec)
6.630... logprob:  0.656467, 0.283854 (1.454 sec)
6.631... logprob:  0.748894, 0.333333 (1.441 sec)
6.632... logprob:  0.650481, 0.298177 (1.484 sec)
6.633... logprob:  0.656005, 0.294271 (1.436 sec)
6.634... logprob:  0.768659, 0.329427 (1.438 sec)
6.635... logprob:  0.680962, 0.307292 (1.435 sec)
6.636... logprob:  0.751097, 0.341146 (1.432 sec)
6.637... logprob:  0.600877, 0.255208 (1.465 sec)
6.638... logprob:  0.762973, 0.332031 (1.483 sec)
6.639... logprob:  0.650821, 0.266927 (1.443 sec)
6.640... logprob:  0.768242, 0.317708 (1.432 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.490347, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.330434e-03 [3.220055e-07] 
Layer 'conv1' biases: 9.293670e-07 [1.289779e-09] 
Layer 'conv2' weights[0]: 6.319398e-03 [3.197819e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.837836e-09] 
Layer 'conv3' weights[0]: 6.318358e-03 [3.208705e-07] 
Layer 'conv3' biases: 1.834114e-05 [3.247235e-08] 
Layer 'conv4' weights[0]: 6.344005e-03 [3.235672e-07] 
Layer 'conv4' biases: 1.000022e+00 [3.395649e-07] 
Layer 'conv5' weights[0]: 6.378277e-03 [2.416998e-06] 
Layer 'conv5' biases: 9.992819e-01 [2.553732e-06] 
Layer 'fc6' weights[0]: 7.412035e-03 [6.308601e-08] 
Layer 'fc6' biases: 9.999982e-01 [6.170389e-08] 
Layer 'fc7' weights[0]: 7.767052e-03 [1.441434e-07] 
Layer 'fc7' biases: 9.999247e-01 [1.972775e-07] 
Layer 'fc8' weights[0]: 3.849967e-03 [2.360504e-05] 
Layer 'fc8' biases: 6.317740e-03 [3.907411e-05] 
Train error last 800 batches: 0.652344
-------------------------------------------------------
Not saving because 0.490347 > 0.303240 (5.60: -6.35%)
======================================================= (2.383 sec)
6.641... logprob:  0.604507, 0.269531 (1.490 sec)
6.642... logprob:  0.758714, 0.305989 (1.439 sec)
6.643... logprob:  0.779617, 0.333333 (1.444 sec)
6.644... logprob:  0.631372, 0.283854 (1.439 sec)
6.645... logprob:  0.659312, 0.283854 (1.423 sec)
6.646... logprob:  0.666222, 0.287760 (1.430 sec)
6.647... logprob:  0.627779, 0.264323 (1.498 sec)
6.648... logprob:  0.734123, 0.313802 (1.442 sec)
6.649... logprob:  0.622914, 0.269531 (1.455 sec)
6.650... logprob:  0.627782, 0.296875 (1.490 sec)
6.651... logprob:  0.579589, 0.283854 (1.438 sec)
6.652... logprob:  0.695996, 0.311198 (1.451 sec)
6.653... logprob:  0.626086, 0.295573 (1.442 sec)
6.654... logprob:  0.668721, 0.287760 (1.436 sec)
6.655... logprob:  0.664087, 0.285156 (1.445 sec)
6.656... logprob:  0.624213, 0.283854 (1.486 sec)
6.657... logprob:  0.683847, 0.287760 (1.450 sec)
6.658... logprob:  0.614290, 0.291667 (1.450 sec)
6.659... logprob:  0.676533, 0.291667 (1.469 sec)
6.660... logprob:  0.647716, 0.317708 (1.441 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.496368, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.324124e-03 [3.195706e-07] 
Layer 'conv1' biases: 9.360331e-07 [9.000031e-10] 
Layer 'conv2' weights[0]: 6.313059e-03 [3.188501e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.374592e-09] 
Layer 'conv3' weights[0]: 6.312081e-03 [3.197749e-07] 
Layer 'conv3' biases: 1.836958e-05 [2.767728e-08] 
Layer 'conv4' weights[0]: 6.337674e-03 [3.238772e-07] 
Layer 'conv4' biases: 1.000021e+00 [3.384511e-07] 
Layer 'conv5' weights[0]: 6.371890e-03 [2.556281e-06] 
Layer 'conv5' biases: 9.992727e-01 [2.693292e-06] 
Layer 'fc6' weights[0]: 7.411242e-03 [6.315212e-08] 
Layer 'fc6' biases: 9.999983e-01 [6.156593e-08] 
Layer 'fc7' weights[0]: 7.766346e-03 [1.425882e-07] 
Layer 'fc7' biases: 9.999254e-01 [2.164063e-07] 
Layer 'fc8' weights[0]: 3.919288e-03 [2.444631e-05] 
Layer 'fc8' biases: 6.662374e-03 [4.738724e-05] 
Train error last 800 batches: 0.652551
-------------------------------------------------------
Not saving because 0.496368 > 0.303240 (5.60: -6.35%)
======================================================= (2.374 sec)
6.661... logprob:  0.596982, 0.236979 (1.460 sec)
6.662... logprob:  0.652256, 0.305990 (1.435 sec)
6.663... logprob:  0.617092, 0.282552 (1.426 sec)
6.664... logprob:  0.554616, 0.244792 (1.438 sec)
6.665... logprob:  0.630225, 0.239583 (1.465 sec)
6.666... logprob:  0.723968, 0.321615 (1.462 sec)
6.667... logprob:  0.798653, 0.352865 (1.461 sec)
6.668... logprob:  0.653733, 0.291667 (1.458 sec)
6.669... logprob:  0.680777, 0.285156 (1.463 sec)
6.670... logprob:  0.553515, 0.251302 (1.434 sec)
6.671... logprob:  0.562209, 0.252604 (1.421 sec)
6.672... logprob:  0.691301, 0.295573 (1.430 sec)
6.673... logprob:  0.691257, 0.283854 (1.438 sec)
6.674... logprob:  0.644657, 0.279948 (1.439 sec)
6.675... logprob:  0.679307, 0.302083 (1.494 sec)
6.676... logprob:  0.646424, 0.291667 (1.452 sec)
6.677... logprob:  0.640797, 0.268229 (1.430 sec)
6.678... logprob:  0.673674, 0.285156 (1.477 sec)
6.679... logprob:  0.716668, 0.317708 (1.426 sec)
6.680... logprob:  0.590835, 0.268229 (1.423 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.515288, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.317769e-03 [3.194967e-07] 
Layer 'conv1' biases: 9.350745e-07 [6.769990e-10] 
Layer 'conv2' weights[0]: 6.306802e-03 [3.181327e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.445148e-09] 
Layer 'conv3' weights[0]: 6.305709e-03 [3.181721e-07] 
Layer 'conv3' biases: 1.844397e-05 [2.271311e-08] 
Layer 'conv4' weights[0]: 6.331346e-03 [3.226243e-07] 
Layer 'conv4' biases: 1.000020e+00 [2.829034e-07] 
Layer 'conv5' weights[0]: 6.365312e-03 [2.096206e-06] 
Layer 'conv5' biases: 9.992731e-01 [2.194721e-06] 
Layer 'fc6' weights[0]: 7.410439e-03 [5.657977e-08] 
Layer 'fc6' biases: 9.999982e-01 [5.186449e-08] 
Layer 'fc7' weights[0]: 7.765506e-03 [1.223665e-07] 
Layer 'fc7' biases: 9.999251e-01 [1.426747e-07] 
Layer 'fc8' weights[0]: 3.932059e-03 [1.678299e-05] 
Layer 'fc8' biases: 6.810037e-03 [2.096318e-05] 
Train error last 800 batches: 0.653095
-------------------------------------------------------
Not saving because 0.515288 > 0.303240 (5.60: -6.35%)
======================================================= (2.377 sec)
6.681... logprob:  0.661313, 0.312500 (1.433 sec)
6.682... logprob:  0.622830, 0.266927 (1.439 sec)
6.683... logprob:  0.664482, 0.289062 (1.434 sec)
6.684... logprob:  0.669574, 0.303385 (1.479 sec)
6.685... logprob:  0.581723, 0.250000 (1.442 sec)
6.686... logprob:  0.574140, 0.251302 (1.426 sec)
6.687... logprob:  0.454713, 0.210937 (1.481 sec)
6.688... logprob:  0.557483, 0.248698 (1.427 sec)
6.689... logprob:  0.753066, 0.300781 (1.424 sec)
6.690... logprob:  0.712494, 0.319010 (1.432 sec)
6.691... logprob:  0.743359, 0.337240 (1.431 sec)
6.692... logprob:  0.650639, 0.276042 (1.424 sec)
6.693... logprob:  0.665070, 0.263021 (1.479 sec)
6.694... logprob:  0.511450, 0.234375 (1.429 sec)
6.695... logprob:  0.516322, 0.239583 (1.436 sec)
6.696... logprob:  0.765819, 0.321615 (1.470 sec)
6.697... logprob:  0.707397, 0.328125 (1.431 sec)
6.698... logprob:  0.846058, 0.321614 (1.427 sec)
6.699... logprob:  0.639865, 0.279948 (1.425 sec)
6.700... logprob:  0.549955, 0.250000 (1.423 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.513581, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.311472e-03 [3.197804e-07] 
Layer 'conv1' biases: 9.384066e-07 [1.556948e-09] 
Layer 'conv2' weights[0]: 6.300511e-03 [3.187200e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.135855e-09] 
Layer 'conv3' weights[0]: 6.299411e-03 [3.194838e-07] 
Layer 'conv3' biases: 1.849674e-05 [3.206553e-08] 
Layer 'conv4' weights[0]: 6.325016e-03 [3.235278e-07] 
Layer 'conv4' biases: 1.000020e+00 [3.974006e-07] 
Layer 'conv5' weights[0]: 6.359207e-03 [2.767611e-06] 
Layer 'conv5' biases: 9.992700e-01 [2.900849e-06] 
Layer 'fc6' weights[0]: 7.409663e-03 [6.526439e-08] 
Layer 'fc6' biases: 9.999982e-01 [6.480354e-08] 
Layer 'fc7' weights[0]: 7.764753e-03 [1.421916e-07] 
Layer 'fc7' biases: 9.999249e-01 [2.012950e-07] 
Layer 'fc8' weights[0]: 3.919838e-03 [2.005030e-05] 
Layer 'fc8' biases: 6.777546e-03 [3.524417e-05] 
Train error last 800 batches: 0.653335
-------------------------------------------------------
Not saving because 0.513581 > 0.303240 (5.60: -6.35%)
======================================================= (2.405 sec)
6.701... logprob:  0.641183, 0.299479 (1.434 sec)
6.702... logprob:  0.664125, 0.282552 (1.481 sec)
6.703... logprob:  0.619689, 0.278646 (1.433 sec)
6.704... logprob:  0.607850, 0.264323 (1.447 sec)
6.705... logprob:  0.661980, 0.300781 (1.468 sec)
6.706... logprob:  0.676973, 0.316406 (1.428 sec)
6.707... logprob:  0.739126, 0.304688 (1.435 sec)
6.708... logprob:  0.691692, 0.317708 (1.432 sec)
6.709... logprob:  0.741625, 0.319010 (1.424 sec)
6.710... logprob:  0.851288, 0.347656 (1.434 sec)
6.711... logprob:  0.692517, 0.299479 (1.467 sec)
6.712... logprob:  0.591136, 0.274740 (1.441 sec)
6.713... logprob:  0.738891, 0.315104 (1.477 sec)
6.714... logprob:  0.609216, 0.261719 (1.456 sec)
6.715... logprob:  0.646644, 0.255208 (1.447 sec)
6.716... logprob:  0.636594, 0.270833 (1.434 sec)
6.717... logprob:  0.643339, 0.294271 (1.427 sec)
6.718... logprob:  0.679002, 0.313802 (1.420 sec)
6.719... logprob:  0.692068, 0.299479 (1.436 sec)
6.720... logprob:  0.668954, 0.311198 (1.450 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.465387, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.305169e-03 [3.198628e-07] 
Layer 'conv1' biases: 9.472669e-07 [1.425340e-09] 
Layer 'conv2' weights[0]: 6.294205e-03 [3.183698e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.642620e-09] 
Layer 'conv3' weights[0]: 6.293126e-03 [3.227766e-07] 
Layer 'conv3' biases: 1.858926e-05 [4.055533e-08] 
Layer 'conv4' weights[0]: 6.318634e-03 [3.256972e-07] 
Layer 'conv4' biases: 1.000022e+00 [4.086301e-07] 
Layer 'conv5' weights[0]: 6.353767e-03 [2.677931e-06] 
Layer 'conv5' biases: 9.992717e-01 [2.713542e-06] 
Layer 'fc6' weights[0]: 7.408909e-03 [6.314360e-08] 
Layer 'fc6' biases: 9.999983e-01 [6.193869e-08] 
Layer 'fc7' weights[0]: 7.763968e-03 [1.417735e-07] 
Layer 'fc7' biases: 9.999233e-01 [1.996258e-07] 
Layer 'fc8' weights[0]: 3.866852e-03 [2.301027e-05] 
Layer 'fc8' biases: 6.344751e-03 [4.774905e-05] 
Train error last 800 batches: 0.653504
-------------------------------------------------------
Not saving because 0.465387 > 0.303240 (5.60: -6.35%)
======================================================= (2.367 sec)
6.721... logprob:  0.619069, 0.239583 (1.462 sec)
6.722... logprob:  0.719350, 0.298177 (1.453 sec)
6.723... logprob:  0.725606, 0.296875 (1.434 sec)
6.724... logprob:  0.683671, 0.303385 (1.471 sec)
6.725... logprob:  0.768724, 0.300781 (1.428 sec)
6.726... logprob:  0.607329, 0.282552 (1.417 sec)
6.727... logprob:  0.652936, 0.290364 (1.430 sec)
6.728... logprob:  0.643166, 0.294271 (1.437 sec)
6.729... logprob:  0.609665, 0.246094 (1.430 sec)
6.730... logprob:  0.754501, 0.321614 (1.471 sec)
6.731... logprob:  0.593838, 0.285156 (1.443 sec)
6.732... logprob:  0.520345, 0.253906 (1.431 sec)
6.733... logprob:  0.702089, 0.315104 (1.483 sec)
6.734... logprob:  0.512265, 0.233073 (1.431 sec)
6.735... logprob:  0.748852, 0.312500 (1.423 sec)
6.736... logprob:  0.798095, 0.352865 (1.431 sec)
6.737... logprob:  0.689743, 0.298177 (1.431 sec)
6.738... logprob:  0.653703, 0.281250 (1.428 sec)
6.739... logprob:  0.806628, 0.342448 (1.471 sec)
6.740... logprob:  0.469486, 0.195312 (1.434 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.423219, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.298886e-03 [3.184979e-07] 
Layer 'conv1' biases: 9.545808e-07 [1.000441e-09] 
Layer 'conv2' weights[0]: 6.287889e-03 [3.172310e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.121163e-09] 
Layer 'conv3' weights[0]: 6.286821e-03 [3.177233e-07] 
Layer 'conv3' biases: 1.871962e-05 [2.588702e-08] 
Layer 'conv4' weights[0]: 6.312384e-03 [3.222415e-07] 
Layer 'conv4' biases: 1.000023e+00 [3.294864e-07] 
Layer 'conv5' weights[0]: 6.347987e-03 [2.355139e-06] 
Layer 'conv5' biases: 9.992619e-01 [2.475641e-06] 
Layer 'fc6' weights[0]: 7.408098e-03 [5.765418e-08] 
Layer 'fc6' biases: 9.999982e-01 [5.371106e-08] 
Layer 'fc7' weights[0]: 7.763252e-03 [1.266196e-07] 
Layer 'fc7' biases: 9.999245e-01 [1.464871e-07] 
Layer 'fc8' weights[0]: 3.920997e-03 [1.692538e-05] 
Layer 'fc8' biases: 6.725046e-03 [1.713635e-05] 
Train error last 800 batches: 0.653250
-------------------------------------------------------
Not saving because 0.423219 > 0.303240 (5.60: -6.35%)
======================================================= (2.400 sec)
6.741... logprob:  0.536533, 0.240885 (1.439 sec)
6.742... logprob:  0.694191, 0.303385 (1.482 sec)
6.743... logprob:  0.573223, 0.268229 (1.436 sec)
6.744... logprob:  0.746069, 0.338542 (1.430 sec)
6.745... logprob:  0.679765, 0.309896 (1.434 sec)
6.746... logprob:  0.660239, 0.273437 (1.429 sec)
6.747... logprob:  0.621320, 0.283854 (1.429 sec)
6.748... logprob:  0.645111, 0.298177 (1.485 sec)
6.749... logprob:  0.723013, 0.329427 (1.428 sec)
6.750... logprob:  0.762924, 0.319010 (1.448 sec)
6.751... logprob:  0.572158, 0.274740 (1.500 sec)
6.752... logprob:  0.773831, 0.329427 (1.428 sec)
6.753... logprob:  0.644830, 0.244792 (1.448 sec)
6.754... logprob:  0.660523, 0.277344 (1.434 sec)
6.755... logprob:  0.721655, 0.303385 (1.417 sec)
6.756... logprob:  0.672675, 0.298177 (1.433 sec)
6.757... logprob:  0.805118, 0.351562 (1.471 sec)
6.758... logprob:  0.605295, 0.253906 (1.441 sec)
6.759... logprob:  0.642269, 0.283854 (1.445 sec)
6.760... logprob:  0.666990, 0.311198 (1.457 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.560684, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.292598e-03 [3.176752e-07] 
Layer 'conv1' biases: 9.641366e-07 [1.087605e-09] 
Layer 'conv2' weights[0]: 6.281645e-03 [3.166323e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.285959e-09] 
Layer 'conv3' weights[0]: 6.280577e-03 [3.176716e-07] 
Layer 'conv3' biases: 1.883706e-05 [2.817432e-08] 
Layer 'conv4' weights[0]: 6.306057e-03 [3.210351e-07] 
Layer 'conv4' biases: 1.000023e+00 [3.196983e-07] 
Layer 'conv5' weights[0]: 6.341927e-03 [2.389315e-06] 
Layer 'conv5' biases: 9.992691e-01 [2.552265e-06] 
Layer 'fc6' weights[0]: 7.407366e-03 [5.634158e-08] 
Layer 'fc6' biases: 9.999982e-01 [5.143794e-08] 
Layer 'fc7' weights[0]: 7.762455e-03 [1.235757e-07] 
Layer 'fc7' biases: 9.999233e-01 [1.407435e-07] 
Layer 'fc8' weights[0]: 3.877389e-03 [1.645250e-05] 
Layer 'fc8' biases: 6.444459e-03 [1.233214e-05] 
Train error last 800 batches: 0.653344
-------------------------------------------------------
Not saving because 0.560684 > 0.303240 (5.60: -6.35%)
======================================================= (2.401 sec)
6.761... logprob:  0.575151, 0.264323 (1.451 sec)
6.762... logprob:  0.734503, 0.345052 (1.440 sec)
6.763... logprob:  0.759000, 0.299479 (1.429 sec)
6.764... logprob:  0.766406, 0.341146 (1.425 sec)
6.765... logprob:  0.467905, 0.208333 (1.430 sec)
6.766... logprob:  0.672919, 0.292969 (1.447 sec)
6.767... logprob:  0.616641, 0.260417 (1.456 sec)
6.768... logprob:  0.630477, 0.291667 (1.464 sec)
6.769... logprob:  0.726852, 0.315104 (1.460 sec)
6.770... logprob:  0.612367, 0.281250 (1.476 sec)
6.771... logprob:  0.719218, 0.329427 (1.455 sec)
6.772... logprob:  0.678196, 0.287760 (1.443 sec)
6.773... logprob:  0.750937, 0.317708 (1.448 sec)
6.774... logprob:  0.709954, 0.313802 (1.459 sec)
6.775... logprob:  0.706931, 0.330729 (1.459 sec)
6.776... logprob:  0.660080, 0.279948 (1.478 sec)
6.777... logprob:  0.629056, 0.279948 (1.464 sec)
6.778... logprob:  0.636717, 0.256510 (1.461 sec)
6.779... logprob:  0.731287, 0.328125 (1.480 sec)
6.780... logprob:  0.687147, 0.317708 (1.447 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.403949, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.286326e-03 [3.214387e-07] 
Layer 'conv1' biases: 9.747646e-07 [1.046671e-09] 
Layer 'conv2' weights[0]: 6.275388e-03 [3.173521e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.954796e-09] 
Layer 'conv3' weights[0]: 6.274263e-03 [3.185425e-07] 
Layer 'conv3' biases: 1.897538e-05 [3.185057e-08] 
Layer 'conv4' weights[0]: 6.299758e-03 [3.225676e-07] 
Layer 'conv4' biases: 1.000024e+00 [3.576866e-07] 
Layer 'conv5' weights[0]: 6.336061e-03 [2.371265e-06] 
Layer 'conv5' biases: 9.992664e-01 [2.541530e-06] 
Layer 'fc6' weights[0]: 7.406587e-03 [5.990227e-08] 
Layer 'fc6' biases: 9.999981e-01 [5.687713e-08] 
Layer 'fc7' weights[0]: 7.761672e-03 [1.318161e-07] 
Layer 'fc7' biases: 9.999231e-01 [1.636804e-07] 
Layer 'fc8' weights[0]: 3.887509e-03 [1.998412e-05] 
Layer 'fc8' biases: 6.442265e-03 [3.103639e-05] 
Train error last 800 batches: 0.653674
-------------------------------------------------------
Not saving because 0.403949 > 0.303240 (5.60: -6.35%)
======================================================= (2.379 sec)
6.781... logprob:  0.647047, 0.279948 (1.448 sec)
6.782... logprob:  0.599570, 0.256510 (1.451 sec)
6.783... logprob:  0.795408, 0.330729 (1.459 sec)
6.784... logprob:  0.696147, 0.287760 (1.451 sec)
6.785... logprob:  0.745698, 0.319010 (1.486 sec)
6.786... logprob:  0.715901, 0.319010 (1.467 sec)
6.787... logprob:  0.740314, 0.300781 (1.459 sec)
6.788... logprob:  0.760052, 0.348958 (1.487 sec)
6.789... logprob:  0.505970, 0.208333 (1.459 sec)
6.790... logprob:  0.569337, 0.260417 (1.444 sec)
6.791... logprob:  0.704773, 0.322917 (1.443 sec)
6.792... logprob:  0.646759, 0.278646 (1.456 sec)
6.793... logprob:  0.674852, 0.291667 (1.448 sec)
6.794... logprob:  0.614142, 0.276042 (1.482 sec)
6.795... logprob:  0.688395, 0.281250 (1.459 sec)
6.796... logprob:  0.589042, 0.247396 (1.461 sec)
6.797... logprob:  0.558505, 0.260417 (1.498 sec)
6.798... logprob:  0.679071, 0.312500 (1.447 sec)
6.799... logprob:  0.618075, 0.276042 (1.442 sec)
6.800... logprob:  0.656598, 0.292969 (1.396 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.530819, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.280037e-03 [3.200903e-07] 
Layer 'conv1' biases: 9.784617e-07 [1.305169e-09] 
Layer 'conv2' weights[0]: 6.269107e-03 [3.177700e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.077477e-08] 
Layer 'conv3' weights[0]: 6.268045e-03 [3.203406e-07] 
Layer 'conv3' biases: 1.908761e-05 [3.907438e-08] 
Layer 'conv4' weights[0]: 6.293459e-03 [3.260418e-07] 
Layer 'conv4' biases: 1.000025e+00 [4.597050e-07] 
Layer 'conv5' weights[0]: 6.329862e-03 [3.291991e-06] 
Layer 'conv5' biases: 9.992609e-01 [3.505545e-06] 
Layer 'fc6' weights[0]: 7.405819e-03 [7.154763e-08] 
Layer 'fc6' biases: 9.999980e-01 [7.390533e-08] 
Layer 'fc7' weights[0]: 7.760896e-03 [1.652469e-07] 
Layer 'fc7' biases: 9.999241e-01 [2.791457e-07] 
Layer 'fc8' weights[0]: 3.932766e-03 [2.741305e-05] 
Layer 'fc8' biases: 6.734277e-03 [6.039674e-05] 
Train error last 800 batches: 0.654377
-------------------------------------------------------
Not saving because 0.530819 > 0.303240 (5.60: -6.35%)
======================================================= (2.350 sec)
7.1... logprob:  0.580738, 0.273437 (1.409 sec)
7.2... logprob:  0.744548, 0.316406 (1.451 sec)
7.3... logprob:  0.647265, 0.309896 (1.420 sec)
7.4... logprob:  0.720608, 0.307292 (1.398 sec)
7.5... logprob:  0.628062, 0.266927 (1.429 sec)
7.6... logprob:  0.772976, 0.313802 (1.391 sec)
7.7... logprob:  0.666265, 0.303385 (1.416 sec)
7.8... logprob:  0.812441, 0.333333 (1.390 sec)
7.9... logprob:  0.604115, 0.256510 (1.401 sec)
7.10... logprob:  0.588835, 0.256510 (1.403 sec)
7.11... logprob:  0.631388, 0.266927 (1.439 sec)
7.12... logprob:  0.673362, 0.282552 (1.390 sec)
7.13... logprob:  0.731058, 0.322917 (1.413 sec)
7.14... logprob:  0.696644, 0.304687 (1.400 sec)
7.15... logprob:  0.613207, 0.263021 (1.403 sec)
7.16... logprob:  0.699461, 0.269531 (1.402 sec)
7.17... logprob:  0.698344, 0.286458 (1.388 sec)
7.18... logprob:  0.543186, 0.257813 (1.394 sec)
7.19... logprob:  0.557102, 0.261719 (1.393 sec)
7.20... logprob:  0.644133, 0.257812 (1.401 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.383900, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.273744e-03 [3.195968e-07] 
Layer 'conv1' biases: 9.817782e-07 [1.008316e-09] 
Layer 'conv2' weights[0]: 6.262804e-03 [3.157003e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.495099e-09] 
Layer 'conv3' weights[0]: 6.261808e-03 [3.163286e-07] 
Layer 'conv3' biases: 1.914420e-05 [2.510919e-08] 
Layer 'conv4' weights[0]: 6.287201e-03 [3.199086e-07] 
Layer 'conv4' biases: 1.000025e+00 [2.952929e-07] 
Layer 'conv5' weights[0]: 6.323614e-03 [2.268533e-06] 
Layer 'conv5' biases: 9.992607e-01 [2.431992e-06] 
Layer 'fc6' weights[0]: 7.405040e-03 [5.608292e-08] 
Layer 'fc6' biases: 9.999982e-01 [5.091730e-08] 
Layer 'fc7' weights[0]: 7.760099e-03 [1.212665e-07] 
Layer 'fc7' biases: 9.999234e-01 [1.320072e-07] 
Layer 'fc8' weights[0]: 3.921820e-03 [1.524661e-05] 
Layer 'fc8' biases: 6.685946e-03 [6.465491e-06] 
Train error last 800 batches: 0.655023
-------------------------------------------------------
Not saving because 0.383900 > 0.303240 (5.60: -6.35%)
======================================================= (2.377 sec)
7.21... logprob:  0.603540, 0.244792 (1.411 sec)
7.22... logprob:  0.773644, 0.325521 (1.418 sec)
7.23... logprob:  0.790047, 0.384115 (1.414 sec)
7.24... logprob:  0.519135, 0.236979 (1.413 sec)
7.25... logprob:  0.637307, 0.266927 (1.402 sec)
7.26... logprob:  0.659393, 0.279948 (1.440 sec)
7.27... logprob:  0.652861, 0.270833 (1.404 sec)
7.28... logprob:  0.610714, 0.257812 (1.405 sec)
7.29... logprob:  0.613177, 0.236979 (1.419 sec)
7.30... logprob:  0.650036, 0.286458 (1.418 sec)
7.31... logprob:  0.690354, 0.294271 (1.403 sec)
7.32... logprob:  0.721926, 0.289062 (1.391 sec)
7.33... logprob:  0.752722, 0.313802 (1.449 sec)
7.34... logprob:  0.729190, 0.338542 (1.389 sec)
7.35... logprob:  0.541337, 0.242187 (1.397 sec)
7.36... logprob:  0.683117, 0.307292 (1.402 sec)
7.37... logprob:  0.646553, 0.290365 (1.404 sec)
7.38... logprob:  0.650950, 0.276042 (1.387 sec)
7.39... logprob:  0.788328, 0.339844 (1.430 sec)
7.40... logprob:  0.687068, 0.304687 (1.400 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.420408, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.267502e-03 [3.191595e-07] 
Layer 'conv1' biases: 9.875556e-07 [1.443595e-09] 
Layer 'conv2' weights[0]: 6.256562e-03 [3.163512e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.001807e-09] 
Layer 'conv3' weights[0]: 6.255528e-03 [3.179582e-07] 
Layer 'conv3' biases: 1.923761e-05 [3.353838e-08] 
Layer 'conv4' weights[0]: 6.280912e-03 [3.229280e-07] 
Layer 'conv4' biases: 1.000028e+00 [4.318471e-07] 
Layer 'conv5' weights[0]: 6.318723e-03 [2.617316e-06] 
Layer 'conv5' biases: 9.992527e-01 [2.762240e-06] 
Layer 'fc6' weights[0]: 7.404258e-03 [6.323083e-08] 
Layer 'fc6' biases: 9.999982e-01 [6.206719e-08] 
Layer 'fc7' weights[0]: 7.759338e-03 [1.436109e-07] 
Layer 'fc7' biases: 9.999225e-01 [1.983197e-07] 
Layer 'fc8' weights[0]: 3.913546e-03 [2.150889e-05] 
Layer 'fc8' biases: 6.585973e-03 [3.941544e-05] 
Train error last 800 batches: 0.655544
-------------------------------------------------------
Not saving because 0.420408 > 0.303240 (5.60: -6.35%)
======================================================= (2.347 sec)
7.41... logprob:  0.564656, 0.255208 (1.430 sec)
7.42... logprob:  0.600058, 0.235677 (1.416 sec)
7.43... logprob:  0.630871, 0.279948 (1.407 sec)
7.44... logprob:  0.746818, 0.343750 (1.437 sec)
7.45... logprob:  0.618657, 0.291667 (1.394 sec)
7.46... logprob:  0.730028, 0.304688 (1.395 sec)
7.47... logprob:  0.567030, 0.242187 (1.390 sec)
7.48... logprob:  0.698868, 0.295573 (1.422 sec)
7.49... logprob:  0.682004, 0.299479 (1.408 sec)
7.50... logprob:  0.612973, 0.268229 (1.417 sec)
7.51... logprob:  0.671246, 0.291667 (1.413 sec)
7.52... logprob:  0.719988, 0.324219 (1.391 sec)
7.53... logprob:  0.543065, 0.242187 (1.439 sec)
7.54... logprob:  0.504106, 0.222656 (1.382 sec)
7.55... logprob:  0.595911, 0.270833 (1.394 sec)
7.56... logprob:  0.552512, 0.256510 (1.394 sec)
7.57... logprob:  0.838676, 0.332031 (1.427 sec)
7.58... logprob:  0.633376, 0.283854 (1.400 sec)
7.59... logprob:  0.592014, 0.240885 (1.461 sec)
7.60... logprob:  0.775050, 0.335938 (1.411 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.433250, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.261238e-03 [3.180261e-07] 
Layer 'conv1' biases: 9.934225e-07 [1.207035e-09] 
Layer 'conv2' weights[0]: 6.250318e-03 [3.156433e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.713833e-09] 
Layer 'conv3' weights[0]: 6.249278e-03 [3.168040e-07] 
Layer 'conv3' biases: 1.929169e-05 [3.278938e-08] 
Layer 'conv4' weights[0]: 6.274629e-03 [3.209156e-07] 
Layer 'conv4' biases: 1.000027e+00 [3.725585e-07] 
Layer 'conv5' weights[0]: 6.312465e-03 [2.398895e-06] 
Layer 'conv5' biases: 9.992447e-01 [2.524220e-06] 
Layer 'fc6' weights[0]: 7.403494e-03 [5.881131e-08] 
Layer 'fc6' biases: 9.999981e-01 [5.582636e-08] 
Layer 'fc7' weights[0]: 7.758535e-03 [1.295238e-07] 
Layer 'fc7' biases: 9.999238e-01 [1.557444e-07] 
Layer 'fc8' weights[0]: 3.964103e-03 [1.835401e-05] 
Layer 'fc8' biases: 6.889069e-03 [2.440017e-05] 
Train error last 800 batches: 0.654915
-------------------------------------------------------
Not saving because 0.433250 > 0.303240 (5.60: -6.35%)
======================================================= (2.376 sec)
7.61... logprob:  0.664631, 0.291667 (1.431 sec)
7.62... logprob:  0.777306, 0.329427 (1.461 sec)
7.63... logprob:  0.601555, 0.289062 (1.439 sec)
7.64... logprob:  0.727265, 0.319010 (1.413 sec)
7.65... logprob:  0.529339, 0.238281 (1.397 sec)
7.66... logprob:  0.693952, 0.300781 (1.465 sec)
7.67... logprob:  0.559594, 0.265625 (1.382 sec)
7.68... logprob:  0.604121, 0.265625 (1.393 sec)
7.69... logprob:  0.746631, 0.324219 (1.417 sec)
7.70... logprob:  0.533099, 0.266927 (1.434 sec)
7.71... logprob:  0.623721, 0.289062 (1.453 sec)
7.72... logprob:  0.708008, 0.317708 (1.395 sec)
7.73... logprob:  0.694510, 0.278646 (1.420 sec)
7.74... logprob:  0.575637, 0.242187 (1.416 sec)
7.75... logprob:  0.574265, 0.260417 (1.411 sec)
7.76... logprob:  0.693860, 0.311198 (1.425 sec)
7.77... logprob:  0.713434, 0.307292 (1.423 sec)
7.78... logprob:  0.695998, 0.283854 (1.448 sec)
7.79... logprob:  0.662557, 0.291667 (1.397 sec)
7.80... logprob:  0.706617, 0.311198 (1.412 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.509975, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.254988e-03 [3.173713e-07] 
Layer 'conv1' biases: 9.976845e-07 [1.177663e-09] 
Layer 'conv2' weights[0]: 6.244035e-03 [3.151329e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.596064e-09] 
Layer 'conv3' weights[0]: 6.243023e-03 [3.170297e-07] 
Layer 'conv3' biases: 1.932109e-05 [3.214842e-08] 
Layer 'conv4' weights[0]: 6.268352e-03 [3.216858e-07] 
Layer 'conv4' biases: 1.000027e+00 [3.781043e-07] 
Layer 'conv5' weights[0]: 6.306320e-03 [3.072011e-06] 
Layer 'conv5' biases: 9.992422e-01 [3.364626e-06] 
Layer 'fc6' weights[0]: 7.402743e-03 [6.308278e-08] 
Layer 'fc6' biases: 9.999981e-01 [6.219986e-08] 
Layer 'fc7' weights[0]: 7.757726e-03 [1.392425e-07] 
Layer 'fc7' biases: 9.999235e-01 [1.891768e-07] 
Layer 'fc8' weights[0]: 3.967474e-03 [2.073009e-05] 
Layer 'fc8' biases: 6.948623e-03 [3.268420e-05] 
Train error last 800 batches: 0.655494
-------------------------------------------------------
Not saving because 0.509975 > 0.303240 (5.60: -6.35%)
======================================================= (2.383 sec)
7.81... logprob:  0.665085, 0.312500 (1.422 sec)
7.82... logprob:  0.490198, 0.242187 (1.427 sec)
7.83... logprob:  0.591803, 0.257812 (1.396 sec)
7.84... logprob:  0.690648, 0.294271 (1.462 sec)
7.85... logprob:  0.617605, 0.292969 (1.418 sec)
7.86... logprob:  0.715753, 0.335937 (1.416 sec)
7.87... logprob:  0.699556, 0.289062 (1.408 sec)
7.88... logprob:  0.696424, 0.289062 (1.405 sec)
7.89... logprob:  0.615809, 0.265625 (1.427 sec)
7.90... logprob:  0.760334, 0.326823 (1.381 sec)
7.91... logprob:  0.610372, 0.289062 (1.391 sec)
7.92... logprob:  0.672651, 0.287760 (1.404 sec)
7.93... logprob:  0.743976, 0.330729 (1.392 sec)
7.94... logprob:  0.605113, 0.278646 (1.391 sec)
7.95... logprob:  0.577893, 0.234375 (1.399 sec)
7.96... logprob:  0.782652, 0.348958 (1.397 sec)
7.97... logprob:  0.672593, 0.322917 (1.382 sec)
7.98... logprob:  0.633652, 0.260417 (1.430 sec)
7.99... logprob:  0.693957, 0.302083 (1.404 sec)
7.100... logprob:  0.624352, 0.283854 (1.394 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.422273, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.248720e-03 [3.166744e-07] 
Layer 'conv1' biases: 1.003805e-06 [9.954572e-10] 
Layer 'conv2' weights[0]: 6.237812e-03 [3.142284e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.714607e-09] 
Layer 'conv3' weights[0]: 6.236767e-03 [3.147415e-07] 
Layer 'conv3' biases: 1.928273e-05 [2.489649e-08] 
Layer 'conv4' weights[0]: 6.262084e-03 [3.184966e-07] 
Layer 'conv4' biases: 1.000028e+00 [3.047959e-07] 
Layer 'conv5' weights[0]: 6.300517e-03 [2.311518e-06] 
Layer 'conv5' biases: 9.992432e-01 [2.508444e-06] 
Layer 'fc6' weights[0]: 7.401971e-03 [5.620431e-08] 
Layer 'fc6' biases: 9.999980e-01 [5.133694e-08] 
Layer 'fc7' weights[0]: 7.756929e-03 [1.212960e-07] 
Layer 'fc7' biases: 9.999221e-01 [1.333541e-07] 
Layer 'fc8' weights[0]: 3.911052e-03 [1.547942e-05] 
Layer 'fc8' biases: 6.536819e-03 [1.215831e-05] 
Train error last 800 batches: 0.655392
-------------------------------------------------------
Not saving because 0.422273 > 0.303240 (5.60: -6.35%)
======================================================= (2.393 sec)
7.101... logprob:  0.616682, 0.264323 (1.444 sec)
7.102... logprob:  0.721758, 0.342448 (1.393 sec)
7.103... logprob:  0.666523, 0.283854 (1.399 sec)
7.104... logprob:  0.619891, 0.283854 (1.401 sec)
7.105... logprob:  0.760641, 0.322917 (1.415 sec)
7.106... logprob:  0.573809, 0.243490 (1.399 sec)
7.107... logprob:  0.487133, 0.209635 (1.433 sec)
7.108... logprob:  0.750574, 0.300781 (1.388 sec)
7.109... logprob:  0.526526, 0.235677 (1.398 sec)
7.110... logprob:  0.741517, 0.326823 (1.386 sec)
7.111... logprob:  0.678568, 0.304687 (1.393 sec)
7.112... logprob:  0.622696, 0.247396 (1.393 sec)
7.113... logprob:  0.566257, 0.264323 (1.393 sec)
7.114... logprob:  0.664209, 0.273437 (1.426 sec)
7.115... logprob:  0.642944, 0.290365 (1.410 sec)
7.116... logprob:  0.592317, 0.246094 (1.395 sec)
7.117... logprob:  0.667521, 0.263021 (1.437 sec)
7.118... logprob:  0.647101, 0.274739 (1.382 sec)
7.119... logprob:  0.654447, 0.324219 (1.394 sec)
7.120... logprob:  0.745161, 0.325521 (1.396 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.498284, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.242502e-03 [3.192667e-07] 
Layer 'conv1' biases: 1.008106e-06 [1.095253e-09] 
Layer 'conv2' weights[0]: 6.231597e-03 [3.146076e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.701427e-09] 
Layer 'conv3' weights[0]: 6.230519e-03 [3.155883e-07] 
Layer 'conv3' biases: 1.935918e-05 [2.811759e-08] 
Layer 'conv4' weights[0]: 6.255857e-03 [3.178779e-07] 
Layer 'conv4' biases: 1.000027e+00 [3.197716e-07] 
Layer 'conv5' weights[0]: 6.293726e-03 [2.387399e-06] 
Layer 'conv5' biases: 9.992391e-01 [2.599425e-06] 
Layer 'fc6' weights[0]: 7.401178e-03 [5.675672e-08] 
Layer 'fc6' biases: 9.999981e-01 [5.249367e-08] 
Layer 'fc7' weights[0]: 7.756152e-03 [1.232230e-07] 
Layer 'fc7' biases: 9.999228e-01 [1.351539e-07] 
Layer 'fc8' weights[0]: 3.958360e-03 [1.557882e-05] 
Layer 'fc8' biases: 6.862205e-03 [7.965524e-06] 
Train error last 800 batches: 0.654852
-------------------------------------------------------
Not saving because 0.498284 > 0.303240 (5.60: -6.35%)
======================================================= (2.387 sec)
7.121... logprob:  0.716008, 0.302083 (1.404 sec)
7.122... logprob:  0.604003, 0.235677 (1.444 sec)
7.123... logprob:  0.682484, 0.308594 (1.390 sec)
7.124... logprob:  0.672975, 0.311198 (1.398 sec)
7.125... logprob:  0.703930, 0.308594 (1.401 sec)
7.126... logprob:  0.705153, 0.295573 (1.391 sec)
7.127... logprob:  0.697490, 0.311198 (1.394 sec)
7.128... logprob:  0.683808, 0.311198 (1.416 sec)
7.129... logprob:  0.702159, 0.341146 (1.413 sec)
7.130... logprob:  0.663057, 0.289062 (1.410 sec)
7.131... logprob:  0.815866, 0.347656 (1.399 sec)
7.132... logprob:  0.727259, 0.311198 (1.430 sec)
7.133... logprob:  0.679126, 0.298177 (1.381 sec)
7.134... logprob:  0.635337, 0.290365 (1.391 sec)
7.135... logprob:  0.691636, 0.302083 (1.395 sec)
7.136... logprob:  0.714354, 0.308594 (1.390 sec)
7.137... logprob:  0.590012, 0.261719 (1.392 sec)
7.138... logprob:  0.522652, 0.226562 (1.435 sec)
7.139... logprob:  0.547829, 0.229167 (1.393 sec)
7.140... logprob:  0.714713, 0.328125 (1.405 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.574732, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.236240e-03 [3.167760e-07] 
Layer 'conv1' biases: 1.009965e-06 [1.033117e-09] 
Layer 'conv2' weights[0]: 6.225360e-03 [3.146341e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.590764e-09] 
Layer 'conv3' weights[0]: 6.224284e-03 [3.164561e-07] 
Layer 'conv3' biases: 1.946601e-05 [3.211350e-08] 
Layer 'conv4' weights[0]: 6.249620e-03 [3.197084e-07] 
Layer 'conv4' biases: 1.000026e+00 [3.600393e-07] 
Layer 'conv5' weights[0]: 6.287794e-03 [2.725999e-06] 
Layer 'conv5' biases: 9.992477e-01 [2.943559e-06] 
Layer 'fc6' weights[0]: 7.400427e-03 [5.909478e-08] 
Layer 'fc6' biases: 9.999982e-01 [5.579961e-08] 
Layer 'fc7' weights[0]: 7.755382e-03 [1.321860e-07] 
Layer 'fc7' biases: 9.999205e-01 [1.777906e-07] 
Layer 'fc8' weights[0]: 3.896810e-03 [1.894896e-05] 
Layer 'fc8' biases: 6.469523e-03 [2.972662e-05] 
Train error last 800 batches: 0.654433
-------------------------------------------------------
Not saving because 0.574732 > 0.303240 (5.60: -6.35%)
======================================================= (2.394 sec)
7.141... logprob:  0.681156, 0.269531 (1.439 sec)
7.142... logprob:  0.694915, 0.305990 (1.396 sec)
7.143... logprob:  0.574928, 0.247396 (1.419 sec)
7.144... logprob:  0.587970, 0.264323 (1.441 sec)
7.145... logprob:  0.657667, 0.320312 (1.413 sec)
7.146... logprob:  0.592188, 0.226562 (1.409 sec)
7.147... logprob:  0.481365, 0.213542 (1.425 sec)
7.148... logprob:  0.601849, 0.264323 (1.390 sec)
7.149... logprob:  0.647483, 0.291667 (1.389 sec)
7.150... logprob:  0.633714, 0.287760 (1.396 sec)
7.151... logprob:  0.683773, 0.305989 (1.391 sec)
7.152... logprob:  0.998124, 0.382812 (1.382 sec)
7.153... logprob:  0.591076, 0.295573 (1.440 sec)
7.154... logprob:  0.723535, 0.324219 (1.395 sec)
7.155... logprob:  0.667240, 0.299479 (1.406 sec)
7.156... logprob:  0.617406, 0.281250 (1.432 sec)
7.157... logprob:  0.528152, 0.244792 (1.387 sec)
7.158... logprob:  0.610019, 0.222656 (1.396 sec)
7.159... logprob:  0.738866, 0.300781 (1.386 sec)
7.160... logprob:  0.690021, 0.285156 (1.389 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.437052, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.230019e-03 [3.162020e-07] 
Layer 'conv1' biases: 1.014360e-06 [8.153847e-10] 
Layer 'conv2' weights[0]: 6.219164e-03 [3.140306e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.601834e-09] 
Layer 'conv3' weights[0]: 6.218091e-03 [3.148298e-07] 
Layer 'conv3' biases: 1.947102e-05 [2.854489e-08] 
Layer 'conv4' weights[0]: 6.243351e-03 [3.178433e-07] 
Layer 'conv4' biases: 1.000027e+00 [3.109023e-07] 
Layer 'conv5' weights[0]: 6.281561e-03 [2.282856e-06] 
Layer 'conv5' biases: 9.992417e-01 [2.407968e-06] 
Layer 'fc6' weights[0]: 7.399672e-03 [6.343476e-08] 
Layer 'fc6' biases: 9.999982e-01 [6.277052e-08] 
Layer 'fc7' weights[0]: 7.754579e-03 [1.430023e-07] 
Layer 'fc7' biases: 9.999217e-01 [1.977989e-07] 
Layer 'fc8' weights[0]: 3.960310e-03 [2.158164e-05] 
Layer 'fc8' biases: 6.849492e-03 [4.257130e-05] 
Train error last 800 batches: 0.654740
-------------------------------------------------------
Not saving because 0.437052 > 0.303240 (5.60: -6.35%)
======================================================= (2.384 sec)
7.161... logprob:  0.584374, 0.269531 (1.414 sec)
7.162... logprob:  0.782838, 0.346354 (1.408 sec)
7.163... logprob:  0.651443, 0.304687 (1.421 sec)
7.164... logprob:  0.660702, 0.287760 (1.425 sec)
7.165... logprob:  0.760902, 0.296875 (1.418 sec)
7.166... logprob:  0.679969, 0.305989 (1.442 sec)
7.167... logprob:  0.514397, 0.227865 (1.423 sec)
7.168... logprob:  0.580960, 0.246094 (1.416 sec)
7.169... logprob:  0.630515, 0.281250 (1.457 sec)
7.170... logprob:  0.694967, 0.316406 (1.405 sec)
7.171... logprob:  0.714000, 0.290365 (1.418 sec)
7.172... logprob:  0.635866, 0.273437 (1.410 sec)
7.173... logprob:  0.729149, 0.291667 (1.417 sec)
7.174... logprob:  0.819489, 0.322917 (1.394 sec)
7.175... logprob:  0.684398, 0.274740 (1.460 sec)
7.176... logprob:  0.741987, 0.326823 (1.410 sec)
7.177... logprob:  0.488668, 0.222656 (1.421 sec)
7.178... logprob:  0.643220, 0.277344 (1.455 sec)
7.179... logprob:  0.662127, 0.309896 (1.407 sec)
7.180... logprob:  0.653016, 0.279948 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.333091, 0.039062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.223805e-03 [3.158228e-07] 
Layer 'conv1' biases: 1.016952e-06 [1.106785e-09] 
Layer 'conv2' weights[0]: 6.212947e-03 [3.138017e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.124693e-09] 
Layer 'conv3' weights[0]: 6.211889e-03 [3.162017e-07] 
Layer 'conv3' biases: 1.957108e-05 [3.360436e-08] 
Layer 'conv4' weights[0]: 6.237119e-03 [3.203295e-07] 
Layer 'conv4' biases: 1.000027e+00 [3.763293e-07] 
Layer 'conv5' weights[0]: 6.275301e-03 [2.749217e-06] 
Layer 'conv5' biases: 9.992425e-01 [2.963281e-06] 
Layer 'fc6' weights[0]: 7.398885e-03 [5.989732e-08] 
Layer 'fc6' biases: 9.999982e-01 [5.727041e-08] 
Layer 'fc7' weights[0]: 7.753772e-03 [1.346291e-07] 
Layer 'fc7' biases: 9.999205e-01 [1.733936e-07] 
Layer 'fc8' weights[0]: 3.927670e-03 [2.029407e-05] 
Layer 'fc8' biases: 6.607575e-03 [3.626496e-05] 
Train error last 800 batches: 0.654849
-------------------------------------------------------
Not saving because 0.333091 > 0.303240 (5.60: -6.35%)
======================================================= (2.378 sec)
7.181... logprob:  0.710923, 0.311198 (1.422 sec)
7.182... logprob:  0.576865, 0.265625 (1.415 sec)
7.183... logprob:  0.640240, 0.305989 (1.443 sec)
7.184... logprob:  0.636432, 0.285156 (1.411 sec)
7.185... logprob:  0.531270, 0.240885 (1.390 sec)
7.186... logprob:  0.568113, 0.247396 (1.390 sec)
7.187... logprob:  0.684794, 0.300781 (1.397 sec)
7.188... logprob:  0.638630, 0.272135 (1.393 sec)
7.189... logprob:  0.692506, 0.300781 (1.385 sec)
7.190... logprob:  0.645415, 0.302083 (1.431 sec)
7.191... logprob:  0.669157, 0.290365 (1.476 sec)
7.192... logprob:  0.652157, 0.263021 (1.412 sec)
7.193... logprob:  0.515509, 0.221354 (1.417 sec)
7.194... logprob:  0.671533, 0.277344 (1.411 sec)
7.195... logprob:  0.566453, 0.270833 (1.400 sec)
7.196... logprob:  0.594212, 0.269531 (1.385 sec)
7.197... logprob:  0.678386, 0.308594 (1.394 sec)
7.198... logprob:  0.545248, 0.269531 (1.404 sec)
7.199... logprob:  0.674624, 0.304688 (1.381 sec)
7.200... logprob:  0.701205, 0.266927 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.448056, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.217576e-03 [3.141131e-07] 
Layer 'conv1' biases: 1.020919e-06 [9.467203e-10] 
Layer 'conv2' weights[0]: 6.206690e-03 [3.130564e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.452834e-09] 
Layer 'conv3' weights[0]: 6.205672e-03 [3.139065e-07] 
Layer 'conv3' biases: 1.957991e-05 [2.712540e-08] 
Layer 'conv4' weights[0]: 6.230888e-03 [3.166534e-07] 
Layer 'conv4' biases: 1.000023e+00 [3.008676e-07] 
Layer 'conv5' weights[0]: 6.268034e-03 [2.184694e-06] 
Layer 'conv5' biases: 9.992364e-01 [2.413545e-06] 
Layer 'fc6' weights[0]: 7.398122e-03 [5.665262e-08] 
Layer 'fc6' biases: 9.999983e-01 [5.239774e-08] 
Layer 'fc7' weights[0]: 7.752998e-03 [1.232813e-07] 
Layer 'fc7' biases: 9.999222e-01 [1.387834e-07] 
Layer 'fc8' weights[0]: 4.013075e-03 [1.687002e-05] 
Layer 'fc8' biases: 7.102458e-03 [2.104117e-05] 
Train error last 800 batches: 0.654138
-------------------------------------------------------
Not saving because 0.448056 > 0.303240 (5.60: -6.35%)
======================================================= (2.363 sec)
7.201... logprob:  0.671883, 0.292969 (1.410 sec)
7.202... logprob:  0.764153, 0.334635 (1.399 sec)
7.203... logprob:  0.612499, 0.269531 (1.433 sec)
7.204... logprob:  0.770257, 0.321615 (1.382 sec)
7.205... logprob:  0.561468, 0.281250 (1.396 sec)
7.206... logprob:  0.536999, 0.226562 (1.400 sec)
7.207... logprob:  0.531244, 0.247396 (1.386 sec)
7.208... logprob:  0.767291, 0.321615 (1.388 sec)
7.209... logprob:  0.559524, 0.259115 (1.416 sec)
7.210... logprob:  0.836738, 0.359375 (1.407 sec)
7.211... logprob:  0.701917, 0.328125 (1.412 sec)
7.212... logprob:  0.696798, 0.319010 (1.411 sec)
7.213... logprob:  0.770806, 0.335937 (1.451 sec)
7.214... logprob:  0.677973, 0.282552 (1.418 sec)
7.215... logprob:  0.593706, 0.263021 (1.411 sec)
7.216... logprob:  0.694574, 0.276042 (1.462 sec)
7.217... logprob:  0.490768, 0.236979 (1.400 sec)
7.218... logprob:  0.682431, 0.283854 (1.416 sec)
7.219... logprob:  0.755733, 0.320312 (1.408 sec)
7.220... logprob:  0.699257, 0.305990 (1.416 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.504416, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.211386e-03 [3.147654e-07] 
Layer 'conv1' biases: 1.025330e-06 [1.205904e-09] 
Layer 'conv2' weights[0]: 6.200482e-03 [3.133275e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.962805e-09] 
Layer 'conv3' weights[0]: 6.199493e-03 [3.149780e-07] 
Layer 'conv3' biases: 1.960037e-05 [3.370306e-08] 
Layer 'conv4' weights[0]: 6.224674e-03 [3.187437e-07] 
Layer 'conv4' biases: 1.000023e+00 [3.900844e-07] 
Layer 'conv5' weights[0]: 6.261949e-03 [2.757332e-06] 
Layer 'conv5' biases: 9.992437e-01 [2.981949e-06] 
Layer 'fc6' weights[0]: 7.397345e-03 [6.226989e-08] 
Layer 'fc6' biases: 9.999982e-01 [6.098455e-08] 
Layer 'fc7' weights[0]: 7.752209e-03 [1.393382e-07] 
Layer 'fc7' biases: 9.999208e-01 [1.850566e-07] 
Layer 'fc8' weights[0]: 3.971176e-03 [1.995359e-05] 
Layer 'fc8' biases: 6.745985e-03 [2.998083e-05] 
Train error last 800 batches: 0.654159
-------------------------------------------------------
Not saving because 0.504416 > 0.303240 (5.60: -6.35%)
======================================================= (2.363 sec)
7.221... logprob:  0.614931, 0.277344 (1.411 sec)
7.222... logprob:  0.770498, 0.330729 (1.491 sec)
7.223... logprob:  0.780167, 0.351563 (1.416 sec)
7.224... logprob:  0.649655, 0.295573 (1.428 sec)
7.225... logprob:  0.662116, 0.270833 (1.446 sec)
7.226... logprob:  0.636921, 0.274740 (1.418 sec)
7.227... logprob:  0.697876, 0.321615 (1.404 sec)
7.228... logprob:  0.642120, 0.282552 (1.411 sec)
7.229... logprob:  0.697479, 0.304687 (1.409 sec)
7.230... logprob:  0.627917, 0.287760 (1.414 sec)
7.231... logprob:  0.638968, 0.304688 (1.403 sec)
7.232... logprob:  0.665454, 0.282552 (1.452 sec)
7.233... logprob:  0.696440, 0.312500 (1.417 sec)
7.234... logprob:  0.706164, 0.309896 (1.420 sec)
7.235... logprob:  0.739263, 0.334635 (1.464 sec)
7.236... logprob:  0.572335, 0.260417 (1.409 sec)
7.237... logprob:  0.491508, 0.204427 (1.416 sec)
7.238... logprob:  0.641607, 0.308594 (1.405 sec)
7.239... logprob:  0.642818, 0.283854 (1.419 sec)
7.240... logprob:  0.654527, 0.277344 (1.397 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.442788, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.205157e-03 [3.143412e-07] 
Layer 'conv1' biases: 1.028437e-06 [1.051367e-09] 
Layer 'conv2' weights[0]: 6.194307e-03 [3.127125e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.564353e-09] 
Layer 'conv3' weights[0]: 6.193275e-03 [3.138781e-07] 
Layer 'conv3' biases: 1.963379e-05 [3.012322e-08] 
Layer 'conv4' weights[0]: 6.218452e-03 [3.196501e-07] 
Layer 'conv4' biases: 1.000023e+00 [3.795061e-07] 
Layer 'conv5' weights[0]: 6.255887e-03 [2.687774e-06] 
Layer 'conv5' biases: 9.992459e-01 [2.820737e-06] 
Layer 'fc6' weights[0]: 7.396579e-03 [6.398381e-08] 
Layer 'fc6' biases: 9.999982e-01 [6.330111e-08] 
Layer 'fc7' weights[0]: 7.751440e-03 [1.442114e-07] 
Layer 'fc7' biases: 9.999204e-01 [2.163077e-07] 
Layer 'fc8' weights[0]: 3.976858e-03 [2.174775e-05] 
Layer 'fc8' biases: 6.723761e-03 [4.274422e-05] 
Train error last 800 batches: 0.654317
-------------------------------------------------------
Not saving because 0.442788 > 0.303240 (5.60: -6.35%)
======================================================= (2.363 sec)
7.241... logprob:  0.724061, 0.319010 (1.460 sec)
7.242... logprob:  0.649604, 0.294271 (1.426 sec)
7.243... logprob:  0.627523, 0.289062 (1.433 sec)
7.244... logprob:  0.569708, 0.274740 (1.450 sec)
7.245... logprob:  0.769872, 0.299479 (1.424 sec)
7.246... logprob:  0.647215, 0.266927 (1.414 sec)
7.247... logprob:  0.558313, 0.234375 (1.414 sec)
7.248... logprob:  0.506772, 0.244792 (1.418 sec)
7.249... logprob:  0.679109, 0.309896 (1.430 sec)
7.250... logprob:  0.808951, 0.313802 (1.404 sec)
7.251... logprob:  0.535935, 0.251302 (1.454 sec)
7.252... logprob:  0.677250, 0.304687 (1.418 sec)
7.253... logprob:  0.605357, 0.266927 (1.413 sec)
7.254... logprob:  0.641259, 0.298177 (1.470 sec)
7.255... logprob:  0.657490, 0.308594 (1.400 sec)
7.256... logprob:  0.605346, 0.282552 (1.416 sec)
7.257... logprob:  0.572392, 0.263021 (1.411 sec)
7.258... logprob:  0.654770, 0.298177 (1.413 sec)
7.259... logprob:  0.648421, 0.279948 (1.395 sec)
7.260... logprob:  0.531642, 0.248698 (1.448 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.430041, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.198968e-03 [3.135695e-07] 
Layer 'conv1' biases: 1.028421e-06 [9.300586e-10] 
Layer 'conv2' weights[0]: 6.188115e-03 [3.118378e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.773816e-09] 
Layer 'conv3' weights[0]: 6.187089e-03 [3.128437e-07] 
Layer 'conv3' biases: 1.966108e-05 [2.528169e-08] 
Layer 'conv4' weights[0]: 6.212270e-03 [3.164360e-07] 
Layer 'conv4' biases: 1.000021e+00 [3.020977e-07] 
Layer 'conv5' weights[0]: 6.249312e-03 [2.302103e-06] 
Layer 'conv5' biases: 9.992379e-01 [2.492380e-06] 
Layer 'fc6' weights[0]: 7.395794e-03 [5.509658e-08] 
Layer 'fc6' biases: 9.999982e-01 [4.975734e-08] 
Layer 'fc7' weights[0]: 7.750646e-03 [1.184889e-07] 
Layer 'fc7' biases: 9.999214e-01 [1.400229e-07] 
Layer 'fc8' weights[0]: 4.017662e-03 [1.604768e-05] 
Layer 'fc8' biases: 7.033729e-03 [2.089500e-05] 
Train error last 800 batches: 0.654663
-------------------------------------------------------
Not saving because 0.430041 > 0.303240 (5.60: -6.35%)
======================================================= (2.393 sec)
7.261... logprob:  0.613059, 0.286458 (1.432 sec)
7.262... logprob:  0.774745, 0.307292 (1.430 sec)
7.263... logprob:  0.662860, 0.294271 (1.447 sec)
7.264... logprob:  0.679126, 0.308594 (1.412 sec)
7.265... logprob:  0.622379, 0.266927 (1.413 sec)
7.266... logprob:  0.704556, 0.308594 (1.411 sec)
7.267... logprob:  0.618550, 0.283854 (1.417 sec)
7.268... logprob:  0.663650, 0.291667 (1.421 sec)
7.269... logprob:  0.726513, 0.328125 (1.399 sec)
7.270... logprob:  0.785246, 0.315104 (1.456 sec)
7.271... logprob:  0.668826, 0.287760 (1.426 sec)
7.272... logprob:  0.659648, 0.307292 (1.408 sec)
7.273... logprob:  0.729973, 0.316406 (1.459 sec)
7.274... logprob:  0.801293, 0.348958 (1.399 sec)
7.275... logprob:  0.693599, 0.282552 (1.412 sec)
7.276... logprob:  0.637737, 0.308594 (1.413 sec)
7.277... logprob:  0.646761, 0.315104 (1.423 sec)
7.278... logprob:  0.589821, 0.261719 (1.415 sec)
7.279... logprob:  0.532428, 0.243490 (1.457 sec)
7.280... logprob:  0.543960, 0.266927 (1.395 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.516497, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.192772e-03 [3.138782e-07] 
Layer 'conv1' biases: 1.037649e-06 [1.252819e-09] 
Layer 'conv2' weights[0]: 6.181941e-03 [3.122228e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.096630e-09] 
Layer 'conv3' weights[0]: 6.180890e-03 [3.133921e-07] 
Layer 'conv3' biases: 1.966704e-05 [3.003598e-08] 
Layer 'conv4' weights[0]: 6.206007e-03 [3.188806e-07] 
Layer 'conv4' biases: 1.000022e+00 [3.993252e-07] 
Layer 'conv5' weights[0]: 6.243582e-03 [2.988899e-06] 
Layer 'conv5' biases: 9.992388e-01 [3.248568e-06] 
Layer 'fc6' weights[0]: 7.395059e-03 [6.544378e-08] 
Layer 'fc6' biases: 9.999980e-01 [6.568473e-08] 
Layer 'fc7' weights[0]: 7.749867e-03 [1.490134e-07] 
Layer 'fc7' biases: 9.999199e-01 [2.388649e-07] 
Layer 'fc8' weights[0]: 3.957421e-03 [2.419007e-05] 
Layer 'fc8' biases: 6.589530e-03 [5.237427e-05] 
Train error last 800 batches: 0.655329
-------------------------------------------------------
Not saving because 0.516497 > 0.303240 (5.60: -6.35%)
======================================================= (2.374 sec)
7.281... logprob:  0.639758, 0.291667 (1.431 sec)
7.282... logprob:  0.589275, 0.268229 (1.423 sec)
7.283... logprob:  0.649399, 0.291667 (1.413 sec)
7.284... logprob:  0.694369, 0.296875 (1.407 sec)
7.285... logprob:  0.659333, 0.281250 (1.436 sec)
7.286... logprob:  0.726860, 0.332031 (1.433 sec)
7.287... logprob:  0.598105, 0.276042 (1.422 sec)
7.288... logprob:  0.553647, 0.236979 (1.429 sec)
7.289... logprob:  0.606225, 0.273438 (1.439 sec)
7.290... logprob:  0.677556, 0.294271 (1.405 sec)
7.291... logprob:  0.609376, 0.270833 (1.414 sec)
7.292... logprob:  0.700854, 0.309896 (1.419 sec)
7.293... logprob:  0.728807, 0.315104 (1.422 sec)
7.294... logprob:  0.621354, 0.294271 (1.401 sec)
7.295... logprob:  0.606322, 0.286458 (1.463 sec)
7.296... logprob:  0.588357, 0.257812 (1.419 sec)
7.297... logprob:  0.618586, 0.266927 (1.413 sec)
7.298... logprob:  0.660595, 0.295573 (1.461 sec)
7.299... logprob:  0.575888, 0.283854 (1.409 sec)
7.300... logprob:  0.630730, 0.286458 (1.414 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.459600, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.186550e-03 [3.140385e-07] 
Layer 'conv1' biases: 1.042642e-06 [9.666076e-10] 
Layer 'conv2' weights[0]: 6.175741e-03 [3.109332e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.538160e-09] 
Layer 'conv3' weights[0]: 6.174694e-03 [3.121808e-07] 
Layer 'conv3' biases: 1.962216e-05 [2.531548e-08] 
Layer 'conv4' weights[0]: 6.199827e-03 [3.147073e-07] 
Layer 'conv4' biases: 1.000021e+00 [2.833734e-07] 
Layer 'conv5' weights[0]: 6.237079e-03 [2.151565e-06] 
Layer 'conv5' biases: 9.992273e-01 [2.362113e-06] 
Layer 'fc6' weights[0]: 7.394265e-03 [5.427453e-08] 
Layer 'fc6' biases: 9.999981e-01 [4.864381e-08] 
Layer 'fc7' weights[0]: 7.749060e-03 [1.167380e-07] 
Layer 'fc7' biases: 9.999216e-01 [1.330568e-07] 
Layer 'fc8' weights[0]: 4.061605e-03 [1.474719e-05] 
Layer 'fc8' biases: 7.323720e-03 [1.681457e-05] 
Train error last 800 batches: 0.655498
-------------------------------------------------------
Not saving because 0.459600 > 0.303240 (5.60: -6.35%)
======================================================= (2.389 sec)
7.301... logprob:  0.580019, 0.252604 (1.420 sec)
7.302... logprob:  0.758740, 0.338542 (1.417 sec)
7.303... logprob:  0.757605, 0.315104 (1.407 sec)
7.304... logprob:  0.670711, 0.281250 (1.435 sec)
7.305... logprob:  0.745220, 0.360677 (1.429 sec)
7.306... logprob:  0.690973, 0.286458 (1.430 sec)
7.307... logprob:  0.631310, 0.308594 (1.434 sec)
7.308... logprob:  0.629066, 0.274740 (1.446 sec)
7.309... logprob:  0.698332, 0.304687 (1.410 sec)
7.310... logprob:  0.625438, 0.305990 (1.416 sec)
7.311... logprob:  0.682044, 0.279948 (1.434 sec)
7.312... logprob:  0.701140, 0.307292 (1.416 sec)
7.313... logprob:  0.716347, 0.302083 (1.415 sec)
7.314... logprob:  0.623057, 0.264323 (1.460 sec)
7.315... logprob:  0.556693, 0.266927 (1.432 sec)
7.316... logprob:  0.559444, 0.221354 (1.421 sec)
7.317... logprob:  0.591481, 0.253906 (1.476 sec)
7.318... logprob:  0.596262, 0.274739 (1.404 sec)
7.319... logprob:  0.666477, 0.259115 (1.430 sec)
7.320... logprob:  0.657876, 0.302083 (1.425 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.457772, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.180345e-03 [3.157822e-07] 
Layer 'conv1' biases: 1.045914e-06 [1.195927e-09] 
Layer 'conv2' weights[0]: 6.169592e-03 [3.113619e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.478450e-09] 
Layer 'conv3' weights[0]: 6.168514e-03 [3.119063e-07] 
Layer 'conv3' biases: 1.973772e-05 [2.851465e-08] 
Layer 'conv4' weights[0]: 6.193600e-03 [3.157076e-07] 
Layer 'conv4' biases: 1.000023e+00 [3.171238e-07] 
Layer 'conv5' weights[0]: 6.231687e-03 [2.361832e-06] 
Layer 'conv5' biases: 9.992300e-01 [2.543979e-06] 
Layer 'fc6' weights[0]: 7.393486e-03 [5.872908e-08] 
Layer 'fc6' biases: 9.999980e-01 [5.578904e-08] 
Layer 'fc7' weights[0]: 7.748266e-03 [1.314117e-07] 
Layer 'fc7' biases: 9.999203e-01 [1.646638e-07] 
Layer 'fc8' weights[0]: 3.991305e-03 [1.845477e-05] 
Layer 'fc8' biases: 6.846753e-03 [2.932101e-05] 
Train error last 800 batches: 0.655704
-------------------------------------------------------
Not saving because 0.457772 > 0.303240 (5.60: -6.35%)
======================================================= (2.376 sec)
7.321... logprob:  0.628546, 0.281250 (1.428 sec)
7.322... logprob:  0.602329, 0.277344 (1.421 sec)
7.323... logprob:  0.665976, 0.296875 (1.483 sec)
7.324... logprob:  0.750902, 0.322917 (1.418 sec)
7.325... logprob:  0.643879, 0.307292 (1.432 sec)
7.326... logprob:  0.747011, 0.305990 (1.460 sec)
7.327... logprob:  0.721407, 0.313802 (1.419 sec)
7.328... logprob:  0.707816, 0.322917 (1.418 sec)
7.329... logprob:  0.591525, 0.260417 (1.426 sec)
7.330... logprob:  0.590685, 0.269531 (1.419 sec)
7.331... logprob:  0.666736, 0.286458 (1.414 sec)
7.332... logprob:  0.736375, 0.329427 (1.441 sec)
7.333... logprob:  0.607780, 0.295573 (1.438 sec)
7.334... logprob:  0.650819, 0.277344 (1.437 sec)
7.335... logprob:  0.621195, 0.266927 (1.440 sec)
7.336... logprob:  0.655594, 0.289062 (1.449 sec)
7.337... logprob:  0.749905, 0.321615 (1.410 sec)
7.338... logprob:  0.749308, 0.338542 (1.419 sec)
7.339... logprob:  0.679399, 0.298177 (1.451 sec)
7.340... logprob:  0.596210, 0.265625 (1.422 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.505524, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.174207e-03 [3.138793e-07] 
Layer 'conv1' biases: 1.047015e-06 [1.246358e-09] 
Layer 'conv2' weights[0]: 6.163441e-03 [3.106958e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.685270e-09] 
Layer 'conv3' weights[0]: 6.162354e-03 [3.122536e-07] 
Layer 'conv3' biases: 1.982753e-05 [3.032367e-08] 
Layer 'conv4' weights[0]: 6.187439e-03 [3.144882e-07] 
Layer 'conv4' biases: 1.000026e+00 [3.077007e-07] 
Layer 'conv5' weights[0]: 6.226764e-03 [2.205456e-06] 
Layer 'conv5' biases: 9.992241e-01 [2.471183e-06] 
Layer 'fc6' weights[0]: 7.392692e-03 [5.694717e-08] 
Layer 'fc6' biases: 9.999979e-01 [5.285100e-08] 
Layer 'fc7' weights[0]: 7.747501e-03 [1.225449e-07] 
Layer 'fc7' biases: 9.999205e-01 [1.328404e-07] 
Layer 'fc8' weights[0]: 3.995633e-03 [1.518266e-05] 
Layer 'fc8' biases: 6.830117e-03 [8.699438e-06] 
Train error last 800 batches: 0.655957
-------------------------------------------------------
Not saving because 0.505524 > 0.303240 (5.60: -6.35%)
======================================================= (2.382 sec)
7.341... logprob:  0.763581, 0.304688 (1.416 sec)
7.342... logprob:  0.657537, 0.285156 (1.467 sec)
7.343... logprob:  0.620532, 0.252604 (1.436 sec)
7.344... logprob:  0.669499, 0.294271 (1.479 sec)
7.345... logprob:  0.722266, 0.305990 (1.440 sec)
7.346... logprob:  0.672148, 0.312500 (1.426 sec)
7.347... logprob:  0.577647, 0.286458 (1.478 sec)
7.348... logprob:  0.622488, 0.291667 (1.424 sec)
7.349... logprob:  0.712407, 0.300781 (1.427 sec)
7.350... logprob:  0.632046, 0.272135 (1.433 sec)
7.351... logprob:  0.737866, 0.302083 (1.420 sec)
7.352... logprob:  0.593336, 0.243490 (1.429 sec)
7.353... logprob:  0.753665, 0.313802 (1.480 sec)
7.354... logprob:  0.858459, 0.347656 (1.427 sec)
7.355... logprob:  0.582335, 0.244792 (1.436 sec)
7.356... logprob:  0.684342, 0.282552 (1.471 sec)
7.357... logprob:  0.651318, 0.276042 (1.426 sec)
7.358... logprob:  0.574341, 0.281250 (1.431 sec)
7.359... logprob:  0.798962, 0.334635 (1.428 sec)
7.360... logprob:  0.658831, 0.302083 (1.419 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.429434, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.168024e-03 [3.135079e-07] 
Layer 'conv1' biases: 1.043454e-06 [9.398956e-10] 
Layer 'conv2' weights[0]: 6.157304e-03 [3.106822e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.995966e-09] 
Layer 'conv3' weights[0]: 6.156183e-03 [3.110824e-07] 
Layer 'conv3' biases: 1.991732e-05 [2.518985e-08] 
Layer 'conv4' weights[0]: 6.181214e-03 [3.153155e-07] 
Layer 'conv4' biases: 1.000026e+00 [3.272362e-07] 
Layer 'conv5' weights[0]: 6.221095e-03 [2.357935e-06] 
Layer 'conv5' biases: 9.992265e-01 [2.502605e-06] 
Layer 'fc6' weights[0]: 7.391932e-03 [6.010382e-08] 
Layer 'fc6' biases: 9.999979e-01 [5.789659e-08] 
Layer 'fc7' weights[0]: 7.746680e-03 [1.331815e-07] 
Layer 'fc7' biases: 9.999194e-01 [1.617092e-07] 
Layer 'fc8' weights[0]: 3.970918e-03 [1.786179e-05] 
Layer 'fc8' biases: 6.694822e-03 [2.145721e-05] 
Train error last 800 batches: 0.656184
-------------------------------------------------------
Not saving because 0.429434 > 0.303240 (5.60: -6.35%)
======================================================= (2.412 sec)
7.361... logprob:  0.615289, 0.277344 (1.435 sec)
7.362... logprob:  0.716612, 0.332031 (1.479 sec)
7.363... logprob:  0.730816, 0.307292 (1.431 sec)
7.364... logprob:  0.717397, 0.308594 (1.450 sec)
7.365... logprob:  0.633190, 0.305989 (1.464 sec)
7.366... logprob:  0.587249, 0.277344 (1.438 sec)
7.367... logprob:  0.591035, 0.277344 (1.431 sec)
7.368... logprob:  0.704494, 0.316406 (1.425 sec)
7.369... logprob:  0.588449, 0.270833 (1.419 sec)
7.370... logprob:  0.591039, 0.276042 (1.434 sec)
7.371... logprob:  0.696549, 0.291667 (1.456 sec)
7.372... logprob:  0.752693, 0.339844 (1.450 sec)
7.373... logprob:  0.741161, 0.302083 (1.446 sec)
7.374... logprob:  0.709890, 0.305990 (1.442 sec)
7.375... logprob:  0.580018, 0.252604 (1.459 sec)
7.376... logprob:  0.621246, 0.296875 (1.433 sec)
7.377... logprob:  0.546526, 0.260417 (1.446 sec)
7.378... logprob:  0.675971, 0.272135 (1.427 sec)
7.379... logprob:  0.650286, 0.296875 (1.430 sec)
7.380... logprob:  0.684257, 0.299479 (1.435 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.471381, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.161843e-03 [3.127561e-07] 
Layer 'conv1' biases: 1.046486e-06 [8.967383e-10] 
Layer 'conv2' weights[0]: 6.151111e-03 [3.106386e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.394373e-09] 
Layer 'conv3' weights[0]: 6.150049e-03 [3.122858e-07] 
Layer 'conv3' biases: 1.993814e-05 [3.086540e-08] 
Layer 'conv4' weights[0]: 6.175070e-03 [3.160754e-07] 
Layer 'conv4' biases: 1.000025e+00 [3.705352e-07] 
Layer 'conv5' weights[0]: 6.214450e-03 [2.690557e-06] 
Layer 'conv5' biases: 9.992190e-01 [2.908551e-06] 
Layer 'fc6' weights[0]: 7.391177e-03 [5.959943e-08] 
Layer 'fc6' biases: 9.999979e-01 [5.709279e-08] 
Layer 'fc7' weights[0]: 7.745934e-03 [1.298427e-07] 
Layer 'fc7' biases: 9.999198e-01 [1.571388e-07] 
Layer 'fc8' weights[0]: 4.016905e-03 [1.818108e-05] 
Layer 'fc8' biases: 7.049683e-03 [2.825484e-05] 
Train error last 800 batches: 0.656298
-------------------------------------------------------
Not saving because 0.471381 > 0.303240 (5.60: -6.35%)
======================================================= (2.381 sec)
7.381... logprob:  0.609427, 0.252604 (1.471 sec)
7.382... logprob:  0.771095, 0.324219 (1.447 sec)
7.383... logprob:  0.540553, 0.252604 (1.429 sec)
7.384... logprob:  0.793213, 0.320312 (1.477 sec)
7.385... logprob:  0.698029, 0.302083 (1.428 sec)
7.386... logprob:  0.700181, 0.287760 (1.420 sec)
7.387... logprob:  0.694222, 0.305990 (1.428 sec)
7.388... logprob:  0.728101, 0.332031 (1.431 sec)
7.389... logprob:  0.640597, 0.287760 (1.429 sec)
7.390... logprob:  0.581533, 0.247396 (1.479 sec)
7.391... logprob:  0.560397, 0.252604 (1.443 sec)
7.392... logprob:  0.687828, 0.302083 (1.423 sec)
7.393... logprob:  0.625144, 0.274739 (1.485 sec)
7.394... logprob:  0.578567, 0.277344 (1.434 sec)
7.395... logprob:  0.639331, 0.294271 (1.423 sec)
7.396... logprob:  0.555340, 0.244792 (1.432 sec)
7.397... logprob:  0.789328, 0.335937 (1.432 sec)
7.398... logprob:  0.648671, 0.282552 (1.425 sec)
7.399... logprob:  0.662911, 0.302083 (1.477 sec)
7.400... logprob:  0.745332, 0.324219 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.456654, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.155704e-03 [3.136243e-07] 
Layer 'conv1' biases: 1.055298e-06 [1.191785e-09] 
Layer 'conv2' weights[0]: 6.144939e-03 [3.103208e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.799185e-09] 
Layer 'conv3' weights[0]: 6.143869e-03 [3.115431e-07] 
Layer 'conv3' biases: 1.995877e-05 [2.999016e-08] 
Layer 'conv4' weights[0]: 6.168946e-03 [3.148964e-07] 
Layer 'conv4' biases: 1.000023e+00 [3.517303e-07] 
Layer 'conv5' weights[0]: 6.207490e-03 [2.520290e-06] 
Layer 'conv5' biases: 9.992216e-01 [2.626538e-06] 
Layer 'fc6' weights[0]: 7.390415e-03 [5.902045e-08] 
Layer 'fc6' biases: 9.999979e-01 [5.635075e-08] 
Layer 'fc7' weights[0]: 7.745165e-03 [1.284877e-07] 
Layer 'fc7' biases: 9.999200e-01 [1.517031e-07] 
Layer 'fc8' weights[0]: 4.025996e-03 [1.740436e-05] 
Layer 'fc8' biases: 7.023970e-03 [2.370697e-05] 
Train error last 800 batches: 0.656654
-------------------------------------------------------
Not saving because 0.456654 > 0.303240 (5.60: -6.35%)
======================================================= (2.364 sec)
7.401... logprob:  0.712912, 0.337240 (1.442 sec)
7.402... logprob:  0.708088, 0.304687 (1.482 sec)
7.403... logprob:  0.711944, 0.315104 (1.426 sec)
7.404... logprob:  0.856867, 0.345052 (1.431 sec)
7.405... logprob:  0.810800, 0.322917 (1.429 sec)
7.406... logprob:  0.595719, 0.278646 (1.423 sec)
7.407... logprob:  0.682605, 0.307292 (1.426 sec)
7.408... logprob:  0.525867, 0.239583 (1.470 sec)
7.409... logprob:  0.635155, 0.274740 (1.432 sec)
7.410... logprob:  0.854402, 0.354167 (1.446 sec)
7.411... logprob:  0.576988, 0.255208 (1.473 sec)
7.412... logprob:  0.762922, 0.311198 (1.428 sec)
7.413... logprob:  0.823766, 0.333333 (1.434 sec)
7.414... logprob:  0.719836, 0.307292 (1.424 sec)
7.415... logprob:  0.597428, 0.279948 (1.447 sec)
7.416... logprob:  0.587301, 0.233073 (1.427 sec)
7.417... logprob:  0.635227, 0.285156 (1.459 sec)
7.418... logprob:  0.611207, 0.252604 (1.452 sec)
7.419... logprob:  0.700656, 0.292969 (1.452 sec)
7.420... logprob:  0.618081, 0.279948 (1.445 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.485169, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.149526e-03 [3.130476e-07] 
Layer 'conv1' biases: 1.060734e-06 [1.285157e-09] 
Layer 'conv2' weights[0]: 6.138821e-03 [3.104574e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.971523e-09] 
Layer 'conv3' weights[0]: 6.137764e-03 [3.123238e-07] 
Layer 'conv3' biases: 1.997930e-05 [3.252462e-08] 
Layer 'conv4' weights[0]: 6.162768e-03 [3.182512e-07] 
Layer 'conv4' biases: 1.000022e+00 [4.198474e-07] 
Layer 'conv5' weights[0]: 6.201071e-03 [2.932079e-06] 
Layer 'conv5' biases: 9.992332e-01 [3.110958e-06] 
Layer 'fc6' weights[0]: 7.389635e-03 [6.786733e-08] 
Layer 'fc6' biases: 9.999979e-01 [6.919358e-08] 
Layer 'fc7' weights[0]: 7.744416e-03 [1.564482e-07] 
Layer 'fc7' biases: 9.999182e-01 [2.457799e-07] 
Layer 'fc8' weights[0]: 3.978599e-03 [2.703722e-05] 
Layer 'fc8' biases: 6.691047e-03 [5.800836e-05] 
Train error last 800 batches: 0.657534
-------------------------------------------------------
Not saving because 0.485169 > 0.303240 (5.60: -6.35%)
======================================================= (2.406 sec)
7.421... logprob:  0.628887, 0.296875 (1.454 sec)
7.422... logprob:  0.794887, 0.324219 (1.436 sec)
7.423... logprob:  0.677192, 0.315104 (1.423 sec)
7.424... logprob:  0.532389, 0.230469 (1.427 sec)
7.425... logprob:  0.561850, 0.248698 (1.441 sec)
7.426... logprob:  0.655984, 0.259115 (1.439 sec)
7.427... logprob:  0.652588, 0.286458 (1.460 sec)
7.428... logprob:  0.776951, 0.343750 (1.449 sec)
7.429... logprob:  0.642107, 0.291667 (1.434 sec)
7.430... logprob:  0.546960, 0.251302 (1.470 sec)
7.431... logprob:  0.810403, 0.338542 (1.430 sec)
7.432... logprob:  0.605001, 0.274740 (1.419 sec)
7.433... logprob:  0.558057, 0.252604 (1.426 sec)
7.434... logprob:  0.713884, 0.325521 (1.429 sec)
7.435... logprob:  0.736989, 0.307292 (1.431 sec)
7.436... logprob:  0.641638, 0.272135 (1.467 sec)
7.437... logprob:  0.674683, 0.283854 (1.439 sec)
7.438... logprob:  0.771221, 0.335937 (1.425 sec)
7.439... logprob:  0.705822, 0.324219 (1.481 sec)
7.440... logprob:  0.641170, 0.270833 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.484042, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.143424e-03 [3.109845e-07] 
Layer 'conv1' biases: 1.070016e-06 [1.408757e-09] 
Layer 'conv2' weights[0]: 6.132706e-03 [3.089958e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.909486e-09] 
Layer 'conv3' weights[0]: 6.131613e-03 [3.101711e-07] 
Layer 'conv3' biases: 2.000387e-05 [2.961047e-08] 
Layer 'conv4' weights[0]: 6.156575e-03 [3.147649e-07] 
Layer 'conv4' biases: 1.000020e+00 [3.701489e-07] 
Layer 'conv5' weights[0]: 6.194279e-03 [2.797018e-06] 
Layer 'conv5' biases: 9.992347e-01 [2.902146e-06] 
Layer 'fc6' weights[0]: 7.388875e-03 [6.475336e-08] 
Layer 'fc6' biases: 9.999978e-01 [6.483241e-08] 
Layer 'fc7' weights[0]: 7.743611e-03 [1.455356e-07] 
Layer 'fc7' biases: 9.999189e-01 [2.045159e-07] 
Layer 'fc8' weights[0]: 4.018360e-03 [2.162124e-05] 
Layer 'fc8' biases: 6.960879e-03 [4.198596e-05] 
Train error last 800 batches: 0.657529
-------------------------------------------------------
Not saving because 0.484042 > 0.303240 (5.60: -6.35%)
======================================================= (2.362 sec)
7.441... logprob:  0.702828, 0.308594 (1.431 sec)
7.442... logprob:  0.627672, 0.282552 (1.435 sec)
7.443... logprob:  0.812681, 0.334635 (1.424 sec)
7.444... logprob:  0.673094, 0.292969 (1.429 sec)
7.445... logprob:  0.663284, 0.292969 (1.478 sec)
7.446... logprob:  0.602314, 0.255208 (1.428 sec)
7.447... logprob:  0.801371, 0.346354 (1.443 sec)
7.448... logprob:  0.612612, 0.273438 (1.473 sec)
7.449... logprob:  0.654232, 0.302083 (1.428 sec)
7.450... logprob:  0.544630, 0.264323 (1.495 sec)
7.451... logprob:  0.674253, 0.289062 (1.435 sec)
7.452... logprob:  0.660711, 0.268229 (1.423 sec)
7.453... logprob:  0.702441, 0.337240 (1.442 sec)
7.454... logprob:  0.694936, 0.304688 (1.480 sec)
7.455... logprob:  0.665023, 0.304688 (1.426 sec)
7.456... logprob:  0.585923, 0.273437 (1.443 sec)
7.457... logprob:  0.610979, 0.283854 (1.468 sec)
7.458... logprob:  0.602926, 0.263021 (1.427 sec)
7.459... logprob:  0.697776, 0.282552 (1.434 sec)
7.460... logprob:  0.538826, 0.266927 (1.424 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.571242, 0.171875 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.137279e-03 [3.120778e-07] 
Layer 'conv1' biases: 1.076301e-06 [1.450970e-09] 
Layer 'conv2' weights[0]: 6.126550e-03 [3.117917e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.123828e-08] 
Layer 'conv3' weights[0]: 6.125506e-03 [3.138759e-07] 
Layer 'conv3' biases: 2.005555e-05 [3.816739e-08] 
Layer 'conv4' weights[0]: 6.150355e-03 [3.210865e-07] 
Layer 'conv4' biases: 1.000019e+00 [4.871641e-07] 
Layer 'conv5' weights[0]: 6.188197e-03 [3.507263e-06] 
Layer 'conv5' biases: 9.992355e-01 [3.668164e-06] 
Layer 'fc6' weights[0]: 7.388094e-03 [7.186104e-08] 
Layer 'fc6' biases: 9.999977e-01 [7.488247e-08] 
Layer 'fc7' weights[0]: 7.742852e-03 [1.694966e-07] 
Layer 'fc7' biases: 9.999189e-01 [2.897365e-07] 
Layer 'fc8' weights[0]: 4.035928e-03 [2.645381e-05] 
Layer 'fc8' biases: 7.065727e-03 [5.887405e-05] 
Train error last 800 batches: 0.658203
-------------------------------------------------------
Not saving because 0.571242 > 0.303240 (5.60: -6.35%)
======================================================= (2.350 sec)
7.461... logprob:  0.697481, 0.292969 (1.431 sec)
7.462... logprob:  0.654237, 0.291667 (1.435 sec)
7.463... logprob:  0.669379, 0.304688 (1.463 sec)
7.464... logprob:  0.671622, 0.296875 (1.442 sec)
7.465... logprob:  0.641763, 0.266927 (1.445 sec)
7.466... logprob:  0.609555, 0.281250 (1.455 sec)
7.467... logprob:  0.598431, 0.269531 (1.443 sec)
7.468... logprob:  0.543091, 0.246094 (1.430 sec)
7.469... logprob:  0.532071, 0.217448 (1.423 sec)
7.470... logprob:  0.560373, 0.236979 (1.417 sec)
7.471... logprob:  0.757193, 0.325521 (1.433 sec)
7.472... logprob:  0.687374, 0.294271 (1.445 sec)
7.473... logprob:  0.615300, 0.278646 (1.455 sec)
7.474... logprob:  0.699845, 0.282552 (1.442 sec)
7.475... logprob:  0.742745, 0.315104 (1.446 sec)
7.476... logprob:  0.715619, 0.286458 (1.457 sec)
7.477... logprob:  0.532826, 0.248698 (1.435 sec)
7.478... logprob:  0.657756, 0.292969 (1.416 sec)
7.479... logprob:  0.579247, 0.259115 (1.426 sec)
7.480... logprob:  0.747673, 0.313802 (1.432 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.465372, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.131126e-03 [3.120461e-07] 
Layer 'conv1' biases: 1.082572e-06 [9.795517e-10] 
Layer 'conv2' weights[0]: 6.120473e-03 [3.090088e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.548218e-09] 
Layer 'conv3' weights[0]: 6.119409e-03 [3.096589e-07] 
Layer 'conv3' biases: 2.008334e-05 [2.716808e-08] 
Layer 'conv4' weights[0]: 6.144268e-03 [3.138015e-07] 
Layer 'conv4' biases: 1.000018e+00 [3.557110e-07] 
Layer 'conv5' weights[0]: 6.181566e-03 [2.727021e-06] 
Layer 'conv5' biases: 9.992329e-01 [2.835712e-06] 
Layer 'fc6' weights[0]: 7.387336e-03 [6.396030e-08] 
Layer 'fc6' biases: 9.999978e-01 [6.350383e-08] 
Layer 'fc7' weights[0]: 7.742041e-03 [1.416804e-07] 
Layer 'fc7' biases: 9.999186e-01 [1.967057e-07] 
Layer 'fc8' weights[0]: 4.052757e-03 [2.007069e-05] 
Layer 'fc8' biases: 7.209806e-03 [3.577140e-05] 
Train error last 800 batches: 0.658327
-------------------------------------------------------
Not saving because 0.465372 > 0.303240 (5.60: -6.35%)
======================================================= (2.355 sec)
7.481... logprob:  0.761842, 0.329427 (1.438 sec)
7.482... logprob:  0.720670, 0.313802 (1.473 sec)
7.483... logprob:  0.693646, 0.350260 (1.440 sec)
7.484... logprob:  0.625318, 0.270833 (1.441 sec)
7.485... logprob:  0.618542, 0.268229 (1.476 sec)
7.486... logprob:  0.675571, 0.325521 (1.424 sec)
7.487... logprob:  0.750752, 0.332031 (1.425 sec)
7.488... logprob:  0.652939, 0.274740 (1.428 sec)
7.489... logprob:  0.591985, 0.281250 (1.428 sec)
7.490... logprob:  0.628834, 0.273437 (1.424 sec)
7.491... logprob:  0.542881, 0.248698 (1.504 sec)
7.492... logprob:  0.708146, 0.296875 (1.439 sec)
7.493... logprob:  0.731610, 0.278646 (1.432 sec)
7.494... logprob:  0.744488, 0.322917 (1.473 sec)
7.495... logprob:  0.591310, 0.244792 (1.431 sec)
7.496... logprob:  0.655796, 0.274740 (1.424 sec)
7.497... logprob:  0.692519, 0.291667 (1.431 sec)
7.498... logprob:  0.668138, 0.296875 (1.421 sec)
7.499... logprob:  0.608311, 0.270833 (1.430 sec)
7.500... logprob:  0.523653, 0.233073 (1.487 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.492059, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.125000e-03 [3.098096e-07] 
Layer 'conv1' biases: 1.087499e-06 [8.922879e-10] 
Layer 'conv2' weights[0]: 6.114316e-03 [3.086529e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.904811e-09] 
Layer 'conv3' weights[0]: 6.113274e-03 [3.094547e-07] 
Layer 'conv3' biases: 2.010542e-05 [2.708167e-08] 
Layer 'conv4' weights[0]: 6.138159e-03 [3.145668e-07] 
Layer 'conv4' biases: 1.000019e+00 [3.719142e-07] 
Layer 'conv5' weights[0]: 6.176487e-03 [2.779694e-06] 
Layer 'conv5' biases: 9.992273e-01 [2.933563e-06] 
Layer 'fc6' weights[0]: 7.386586e-03 [5.906047e-08] 
Layer 'fc6' biases: 9.999977e-01 [5.613571e-08] 
Layer 'fc7' weights[0]: 7.741322e-03 [1.327587e-07] 
Layer 'fc7' biases: 9.999178e-01 [1.739498e-07] 
Layer 'fc8' weights[0]: 4.011713e-03 [1.887580e-05] 
Layer 'fc8' biases: 6.935973e-03 [3.343793e-05] 
Train error last 800 batches: 0.658483
-------------------------------------------------------
Not saving because 0.492059 > 0.303240 (5.60: -6.35%)
======================================================= (2.386 sec)
7.501... logprob:  0.652252, 0.281250 (1.435 sec)
7.502... logprob:  0.749152, 0.294271 (1.445 sec)
7.503... logprob:  0.550664, 0.248698 (1.484 sec)
7.504... logprob:  0.666350, 0.286458 (1.423 sec)
7.505... logprob:  0.772205, 0.334635 (1.434 sec)
7.506... logprob:  0.729542, 0.333333 (1.430 sec)
7.507... logprob:  0.665996, 0.283854 (1.420 sec)
7.508... logprob:  0.592201, 0.255208 (1.429 sec)
7.509... logprob:  0.554689, 0.240885 (1.478 sec)
7.510... logprob:  0.604094, 0.278646 (1.433 sec)
7.511... logprob:  0.576661, 0.263021 (1.445 sec)
7.512... logprob:  0.614359, 0.266927 (1.460 sec)
7.513... logprob:  0.560355, 0.263021 (1.437 sec)
7.514... logprob:  0.640777, 0.263021 (1.431 sec)
7.515... logprob:  0.670942, 0.303385 (1.423 sec)
7.516... logprob:  0.692013, 0.330729 (1.419 sec)
7.517... logprob:  0.768771, 0.358073 (1.431 sec)
7.518... logprob:  0.617715, 0.277344 (1.453 sec)
7.519... logprob:  0.717893, 0.311198 (1.451 sec)
7.520... logprob:  0.648884, 0.290365 (1.443 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.484336, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.118894e-03 [3.094128e-07] 
Layer 'conv1' biases: 1.089008e-06 [1.111036e-09] 
Layer 'conv2' weights[0]: 6.108228e-03 [3.082024e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.520907e-09] 
Layer 'conv3' weights[0]: 6.107112e-03 [3.090013e-07] 
Layer 'conv3' biases: 2.012455e-05 [2.753681e-08] 
Layer 'conv4' weights[0]: 6.131986e-03 [3.142590e-07] 
Layer 'conv4' biases: 1.000018e+00 [3.837192e-07] 
Layer 'conv5' weights[0]: 6.170160e-03 [2.807808e-06] 
Layer 'conv5' biases: 9.992234e-01 [2.984682e-06] 
Layer 'fc6' weights[0]: 7.385783e-03 [6.024433e-08] 
Layer 'fc6' biases: 9.999977e-01 [5.868132e-08] 
Layer 'fc7' weights[0]: 7.740496e-03 [1.327100e-07] 
Layer 'fc7' biases: 9.999179e-01 [1.713058e-07] 
Layer 'fc8' weights[0]: 4.058183e-03 [1.915181e-05] 
Layer 'fc8' biases: 7.228671e-03 [3.293993e-05] 
Train error last 800 batches: 0.658382
-------------------------------------------------------
Not saving because 0.484336 > 0.303240 (5.60: -6.35%)
======================================================= (2.354 sec)
7.521... logprob:  0.634259, 0.278646 (1.455 sec)
7.522... logprob:  0.731008, 0.330729 (1.463 sec)
7.523... logprob:  0.521198, 0.242187 (1.435 sec)
7.524... logprob:  0.679525, 0.300781 (1.419 sec)
7.525... logprob:  0.653310, 0.272135 (1.426 sec)
7.526... logprob:  0.618949, 0.265625 (1.429 sec)
7.527... logprob:  0.660424, 0.305990 (1.436 sec)
7.528... logprob:  0.755652, 0.320312 (1.462 sec)
7.529... logprob:  0.596434, 0.230469 (1.467 sec)
7.530... logprob:  0.564822, 0.256510 (1.436 sec)
7.531... logprob:  0.679906, 0.285156 (1.470 sec)
7.532... logprob:  0.768214, 0.328125 (1.433 sec)
7.533... logprob:  0.735380, 0.348958 (1.427 sec)
7.534... logprob:  0.538014, 0.274740 (1.428 sec)
7.535... logprob:  0.674686, 0.296875 (1.428 sec)
7.536... logprob:  0.653201, 0.296875 (1.423 sec)
7.537... logprob:  0.687405, 0.313802 (1.485 sec)
7.538... logprob:  0.669644, 0.286458 (1.434 sec)
7.539... logprob:  0.573585, 0.240885 (1.427 sec)
7.540... logprob:  0.590356, 0.261719 (1.492 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.508339, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.112764e-03 [3.105558e-07] 
Layer 'conv1' biases: 1.097504e-06 [1.066956e-09] 
Layer 'conv2' weights[0]: 6.102110e-03 [3.082796e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.610173e-09] 
Layer 'conv3' weights[0]: 6.101045e-03 [3.090462e-07] 
Layer 'conv3' biases: 2.021240e-05 [2.816511e-08] 
Layer 'conv4' weights[0]: 6.125913e-03 [3.118805e-07] 
Layer 'conv4' biases: 1.000019e+00 [2.994428e-07] 
Layer 'conv5' weights[0]: 6.164418e-03 [2.333241e-06] 
Layer 'conv5' biases: 9.992249e-01 [2.507157e-06] 
Layer 'fc6' weights[0]: 7.385010e-03 [5.721103e-08] 
Layer 'fc6' biases: 9.999977e-01 [5.366200e-08] 
Layer 'fc7' weights[0]: 7.739732e-03 [1.257411e-07] 
Layer 'fc7' biases: 9.999174e-01 [1.533746e-07] 
Layer 'fc8' weights[0]: 4.040474e-03 [1.720074e-05] 
Layer 'fc8' biases: 7.084524e-03 [1.781930e-05] 
Train error last 800 batches: 0.657853
-------------------------------------------------------
Not saving because 0.508339 > 0.303240 (5.60: -6.35%)
======================================================= (2.413 sec)
7.541... logprob:  0.633693, 0.278646 (1.431 sec)
7.542... logprob:  0.641324, 0.268229 (1.429 sec)
7.543... logprob:  0.500762, 0.239583 (1.434 sec)
7.544... logprob:  0.506623, 0.242187 (1.431 sec)
7.545... logprob:  0.579359, 0.255208 (1.427 sec)
7.546... logprob:  0.622881, 0.276042 (1.477 sec)
7.547... logprob:  0.620686, 0.286458 (1.427 sec)
7.548... logprob:  0.688541, 0.311198 (1.436 sec)
7.549... logprob:  0.658949, 0.272135 (1.474 sec)
7.550... logprob:  0.588540, 0.260417 (1.427 sec)
7.551... logprob:  0.613740, 0.260417 (1.425 sec)
7.552... logprob:  0.671013, 0.291667 (1.429 sec)
7.553... logprob:  0.604087, 0.277344 (1.426 sec)
7.554... logprob:  0.664840, 0.268229 (1.432 sec)
7.555... logprob:  0.734361, 0.324219 (1.472 sec)
7.556... logprob:  0.562585, 0.260417 (1.437 sec)
7.557... logprob:  0.690849, 0.324219 (1.444 sec)
7.558... logprob:  0.662950, 0.292969 (1.468 sec)
7.559... logprob:  0.765397, 0.309896 (1.434 sec)
7.560... logprob:  0.584127, 0.279948 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.487732, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.106667e-03 [3.104843e-07] 
Layer 'conv1' biases: 1.101607e-06 [8.199842e-10] 
Layer 'conv2' weights[0]: 6.096009e-03 [3.074703e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.772873e-09] 
Layer 'conv3' weights[0]: 6.094925e-03 [3.084466e-07] 
Layer 'conv3' biases: 2.025365e-05 [2.958090e-08] 
Layer 'conv4' weights[0]: 6.119788e-03 [3.126318e-07] 
Layer 'conv4' biases: 1.000019e+00 [3.628313e-07] 
Layer 'conv5' weights[0]: 6.158237e-03 [2.608513e-06] 
Layer 'conv5' biases: 9.992201e-01 [2.796502e-06] 
Layer 'fc6' weights[0]: 7.384236e-03 [6.164099e-08] 
Layer 'fc6' biases: 9.999977e-01 [6.042000e-08] 
Layer 'fc7' weights[0]: 7.738946e-03 [1.381961e-07] 
Layer 'fc7' biases: 9.999183e-01 [1.891455e-07] 
Layer 'fc8' weights[0]: 4.097065e-03 [2.059629e-05] 
Layer 'fc8' biases: 7.462112e-03 [3.814846e-05] 
Train error last 800 batches: 0.658067
-------------------------------------------------------
Not saving because 0.487732 > 0.303240 (5.60: -6.35%)
======================================================= (2.374 sec)
7.561... logprob:  0.648973, 0.291667 (1.432 sec)
7.562... logprob:  0.728235, 0.303385 (1.424 sec)
7.563... logprob:  0.577794, 0.261719 (1.436 sec)
7.564... logprob:  0.705074, 0.317708 (1.461 sec)
7.565... logprob:  0.757374, 0.320312 (1.440 sec)
7.566... logprob:  0.628082, 0.282552 (1.447 sec)
7.567... logprob:  0.659841, 0.321615 (1.453 sec)
7.568... logprob:  0.677594, 0.265625 (1.454 sec)
7.569... logprob:  0.713574, 0.322917 (1.429 sec)
7.570... logprob:  0.733820, 0.311198 (1.421 sec)
7.571... logprob:  0.725408, 0.322917 (1.423 sec)
7.572... logprob:  0.673618, 0.311198 (1.432 sec)
7.573... logprob:  0.749286, 0.304688 (1.440 sec)
7.574... logprob:  0.656647, 0.304687 (1.459 sec)
7.575... logprob:  0.551742, 0.256510 (1.525 sec)
7.576... logprob:  0.674536, 0.270833 (1.440 sec)
7.577... logprob:  0.697298, 0.294271 (1.472 sec)
7.578... logprob:  0.546363, 0.239583 (1.433 sec)
7.579... logprob:  0.708280, 0.308594 (1.424 sec)
7.580... logprob:  0.727566, 0.291667 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.432054, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.100542e-03 [3.086317e-07] 
Layer 'conv1' biases: 1.106930e-06 [8.538867e-10] 
Layer 'conv2' weights[0]: 6.089967e-03 [3.068778e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.222649e-09] 
Layer 'conv3' weights[0]: 6.088868e-03 [3.073754e-07] 
Layer 'conv3' biases: 2.030608e-05 [2.405902e-08] 
Layer 'conv4' weights[0]: 6.113682e-03 [3.113922e-07] 
Layer 'conv4' biases: 1.000019e+00 [3.241350e-07] 
Layer 'conv5' weights[0]: 6.152563e-03 [2.423518e-06] 
Layer 'conv5' biases: 9.992335e-01 [2.484143e-06] 
Layer 'fc6' weights[0]: 7.383469e-03 [6.074315e-08] 
Layer 'fc6' biases: 9.999977e-01 [5.883264e-08] 
Layer 'fc7' weights[0]: 7.738165e-03 [1.390133e-07] 
Layer 'fc7' biases: 9.999161e-01 [1.768135e-07] 
Layer 'fc8' weights[0]: 4.026946e-03 [2.132477e-05] 
Layer 'fc8' biases: 6.889363e-03 [3.377608e-05] 
Train error last 800 batches: 0.658127
-------------------------------------------------------
Not saving because 0.432054 > 0.303240 (5.60: -6.35%)
======================================================= (2.365 sec)
7.581... logprob:  0.749621, 0.347656 (1.439 sec)
7.582... logprob:  0.610422, 0.278646 (1.435 sec)
7.583... logprob:  0.740045, 0.315104 (1.475 sec)
7.584... logprob:  0.682474, 0.276042 (1.436 sec)
7.585... logprob:  0.619865, 0.289062 (1.428 sec)
7.586... logprob:  0.533507, 0.242187 (1.480 sec)
7.587... logprob:  0.664461, 0.311198 (1.426 sec)
7.588... logprob:  0.657549, 0.279948 (1.421 sec)
7.589... logprob:  0.537278, 0.257812 (1.430 sec)
7.590... logprob:  0.716084, 0.309896 (1.430 sec)
7.591... logprob:  0.613519, 0.247396 (1.426 sec)
7.592... logprob:  0.626068, 0.274740 (1.475 sec)
7.593... logprob:  0.641677, 0.272135 (1.435 sec)
7.594... logprob:  0.589524, 0.268229 (1.439 sec)
7.595... logprob:  0.660843, 0.311198 (1.480 sec)
7.596... logprob:  0.685979, 0.289062 (1.426 sec)
7.597... logprob:  0.625302, 0.283854 (1.428 sec)
7.598... logprob:  0.600241, 0.265625 (1.428 sec)
7.599... logprob:  0.614986, 0.264323 (1.428 sec)
7.600... logprob:  0.539455, 0.226562 (1.424 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.426619, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.094455e-03 [3.080182e-07] 
Layer 'conv1' biases: 1.112979e-06 [1.008618e-09] 
Layer 'conv2' weights[0]: 6.083848e-03 [3.074896e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.299197e-09] 
Layer 'conv3' weights[0]: 6.082754e-03 [3.089849e-07] 
Layer 'conv3' biases: 2.032729e-05 [3.156394e-08] 
Layer 'conv4' weights[0]: 6.107505e-03 [3.130215e-07] 
Layer 'conv4' biases: 1.000017e+00 [3.840941e-07] 
Layer 'conv5' weights[0]: 6.145588e-03 [2.723211e-06] 
Layer 'conv5' biases: 9.992239e-01 [2.889723e-06] 
Layer 'fc6' weights[0]: 7.382704e-03 [5.963664e-08] 
Layer 'fc6' biases: 9.999978e-01 [5.710818e-08] 
Layer 'fc7' weights[0]: 7.737385e-03 [1.308098e-07] 
Layer 'fc7' biases: 9.999170e-01 [1.710166e-07] 
Layer 'fc8' weights[0]: 4.097647e-03 [1.770443e-05] 
Layer 'fc8' biases: 7.421382e-03 [3.095050e-05] 
Train error last 800 batches: 0.657619
-------------------------------------------------------
Not saving because 0.426619 > 0.303240 (5.60: -6.35%)
======================================================= (2.417 sec)
7.601... logprob:  0.595166, 0.289062 (1.487 sec)
7.602... logprob:  0.560257, 0.239583 (1.429 sec)
7.603... logprob:  0.506956, 0.252604 (1.438 sec)
7.604... logprob:  0.607058, 0.281250 (1.474 sec)
7.605... logprob:  0.747076, 0.309896 (1.432 sec)
7.606... logprob:  0.615123, 0.295573 (1.431 sec)
7.607... logprob:  0.676571, 0.321615 (1.429 sec)
7.608... logprob:  0.574054, 0.248698 (1.424 sec)
7.609... logprob:  0.659094, 0.307292 (1.428 sec)
7.610... logprob:  0.646775, 0.290365 (1.466 sec)
7.611... logprob:  0.784219, 0.300781 (1.441 sec)
7.612... logprob:  0.723816, 0.289062 (1.455 sec)
7.613... logprob:  0.468946, 0.203125 (1.453 sec)
7.614... logprob:  0.635751, 0.259115 (1.443 sec)
7.615... logprob:  0.571766, 0.250000 (1.433 sec)
7.616... logprob:  0.657049, 0.295573 (1.428 sec)
7.617... logprob:  0.623710, 0.281250 (1.419 sec)
7.618... logprob:  0.740362, 0.305990 (1.434 sec)
7.619... logprob:  0.672559, 0.274740 (1.449 sec)
7.620... logprob:  0.773491, 0.319010 (1.451 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.450665, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.088377e-03 [3.089232e-07] 
Layer 'conv1' biases: 1.119892e-06 [1.242892e-09] 
Layer 'conv2' weights[0]: 6.077749e-03 [3.086661e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.057010e-08] 
Layer 'conv3' weights[0]: 6.076675e-03 [3.120682e-07] 
Layer 'conv3' biases: 2.036451e-05 [4.073374e-08] 
Layer 'conv4' weights[0]: 6.101456e-03 [3.193995e-07] 
Layer 'conv4' biases: 1.000014e+00 [5.569213e-07] 
Layer 'conv5' weights[0]: 6.139203e-03 [4.161914e-06] 
Layer 'conv5' biases: 9.992263e-01 [4.446089e-06] 
Layer 'fc6' weights[0]: 7.381949e-03 [8.042283e-08] 
Layer 'fc6' biases: 9.999979e-01 [8.880074e-08] 
Layer 'fc7' weights[0]: 7.736625e-03 [1.962537e-07] 
Layer 'fc7' biases: 9.999169e-01 [3.484374e-07] 
Layer 'fc8' weights[0]: 4.080396e-03 [3.077785e-05] 
Layer 'fc8' biases: 7.283042e-03 [6.673263e-05] 
Train error last 800 batches: 0.657735
-------------------------------------------------------
Not saving because 0.450665 > 0.303240 (5.60: -6.35%)
======================================================= (2.340 sec)
7.621... logprob:  0.562149, 0.246094 (1.459 sec)
7.622... logprob:  0.548283, 0.274740 (1.447 sec)
7.623... logprob:  0.605295, 0.260417 (1.462 sec)
7.624... logprob:  0.587082, 0.282552 (1.436 sec)
7.625... logprob:  0.677655, 0.283854 (1.420 sec)
7.626... logprob:  0.643484, 0.283854 (1.422 sec)
7.627... logprob:  0.685063, 0.291667 (1.427 sec)
7.628... logprob:  0.605624, 0.265625 (1.426 sec)
7.629... logprob:  0.606909, 0.263021 (1.471 sec)
7.630... logprob:  0.651644, 0.290365 (1.450 sec)
7.631... logprob:  0.821476, 0.355469 (1.436 sec)
7.632... logprob:  0.590410, 0.233073 (1.478 sec)
7.633... logprob:  0.616718, 0.281250 (1.426 sec)
7.634... logprob:  0.766826, 0.304688 (1.420 sec)
7.635... logprob:  0.623069, 0.283854 (1.432 sec)
7.636... logprob:  0.776123, 0.326823 (1.425 sec)
7.637... logprob:  0.596275, 0.240885 (1.432 sec)
7.638... logprob:  0.700446, 0.273437 (1.475 sec)
7.639... logprob:  0.643347, 0.290365 (1.437 sec)
7.640... logprob:  0.627126, 0.261719 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.569800, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.082295e-03 [3.085394e-07] 
Layer 'conv1' biases: 1.126614e-06 [1.021752e-09] 
Layer 'conv2' weights[0]: 6.071681e-03 [3.065161e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.181661e-09] 
Layer 'conv3' weights[0]: 6.070603e-03 [3.072252e-07] 
Layer 'conv3' biases: 2.042924e-05 [2.869970e-08] 
Layer 'conv4' weights[0]: 6.095362e-03 [3.106803e-07] 
Layer 'conv4' biases: 1.000015e+00 [3.225878e-07] 
Layer 'conv5' weights[0]: 6.133574e-03 [2.411150e-06] 
Layer 'conv5' biases: 9.992281e-01 [2.533207e-06] 
Layer 'fc6' weights[0]: 7.381170e-03 [6.108913e-08] 
Layer 'fc6' biases: 9.999977e-01 [5.967850e-08] 
Layer 'fc7' weights[0]: 7.735814e-03 [1.382172e-07] 
Layer 'fc7' biases: 9.999151e-01 [1.753624e-07] 
Layer 'fc8' weights[0]: 4.040984e-03 [2.119751e-05] 
Layer 'fc8' biases: 6.965723e-03 [3.987911e-05] 
Train error last 800 batches: 0.657168
-------------------------------------------------------
Not saving because 0.569800 > 0.303240 (5.60: -6.35%)
======================================================= (2.360 sec)
7.641... logprob:  0.661941, 0.279948 (1.489 sec)
7.642... logprob:  0.642343, 0.283854 (1.433 sec)
7.643... logprob:  0.840092, 0.355469 (1.425 sec)
7.644... logprob:  0.570638, 0.272135 (1.427 sec)
7.645... logprob:  0.677413, 0.298177 (1.429 sec)
7.646... logprob:  0.574972, 0.248698 (1.432 sec)
7.647... logprob:  0.678650, 0.305990 (1.480 sec)
7.648... logprob:  0.761928, 0.358073 (1.429 sec)
7.649... logprob:  0.565553, 0.236979 (1.432 sec)
7.650... logprob:  0.690468, 0.303385 (1.475 sec)
7.651... logprob:  0.650699, 0.261719 (1.430 sec)
7.652... logprob:  0.678546, 0.285156 (1.434 sec)
7.653... logprob:  0.767875, 0.289062 (1.427 sec)
7.654... logprob:  0.686855, 0.295573 (1.419 sec)
7.655... logprob:  0.652235, 0.296875 (1.426 sec)
7.656... logprob:  0.655358, 0.296875 (1.472 sec)
7.657... logprob:  0.656101, 0.281250 (1.434 sec)
7.658... logprob:  0.543387, 0.244792 (1.444 sec)
7.659... logprob:  0.799053, 0.351562 (1.470 sec)
7.660... logprob:  0.712526, 0.324219 (1.437 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.523644, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.076224e-03 [3.104370e-07] 
Layer 'conv1' biases: 1.132048e-06 [1.084729e-09] 
Layer 'conv2' weights[0]: 6.065608e-03 [3.057106e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.388648e-09] 
Layer 'conv3' weights[0]: 6.064500e-03 [3.069253e-07] 
Layer 'conv3' biases: 2.044669e-05 [3.058293e-08] 
Layer 'conv4' weights[0]: 6.089243e-03 [3.109908e-07] 
Layer 'conv4' biases: 1.000015e+00 [3.815696e-07] 
Layer 'conv5' weights[0]: 6.127736e-03 [2.584922e-06] 
Layer 'conv5' biases: 9.992256e-01 [2.716771e-06] 
Layer 'fc6' weights[0]: 7.380406e-03 [5.823939e-08] 
Layer 'fc6' biases: 9.999977e-01 [5.496776e-08] 
Layer 'fc7' weights[0]: 7.735031e-03 [1.280677e-07] 
Layer 'fc7' biases: 9.999150e-01 [1.453594e-07] 
Layer 'fc8' weights[0]: 4.036385e-03 [1.600336e-05] 
Layer 'fc8' biases: 6.901313e-03 [1.353481e-05] 
Train error last 800 batches: 0.657509
-------------------------------------------------------
Not saving because 0.523644 > 0.303240 (5.60: -6.35%)
======================================================= (2.372 sec)
7.661... logprob:  0.662068, 0.291667 (1.439 sec)
7.662... logprob:  0.617597, 0.264323 (1.432 sec)
7.663... logprob:  0.662699, 0.332031 (1.426 sec)
7.664... logprob:  0.554960, 0.256510 (1.437 sec)
7.665... logprob:  0.671729, 0.299479 (1.455 sec)
7.666... logprob:  0.703704, 0.287760 (1.445 sec)
7.667... logprob:  0.717888, 0.332031 (1.449 sec)
7.668... logprob:  0.708449, 0.319010 (1.446 sec)
7.669... logprob:  0.576610, 0.263021 (1.455 sec)
7.670... logprob:  0.614030, 0.274740 (1.436 sec)
7.671... logprob:  0.606007, 0.259114 (1.420 sec)
7.672... logprob:  0.684799, 0.320312 (1.427 sec)
7.673... logprob:  0.720496, 0.320312 (1.428 sec)
7.674... logprob:  0.606965, 0.269531 (1.438 sec)
7.675... logprob:  0.635531, 0.295573 (1.459 sec)
7.676... logprob:  0.625550, 0.270833 (1.443 sec)
7.677... logprob:  0.709394, 0.294271 (1.435 sec)
7.678... logprob:  0.693167, 0.304687 (1.474 sec)
7.679... logprob:  0.681983, 0.299479 (1.424 sec)
7.680... logprob:  0.726616, 0.313802 (1.423 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.451045, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.070144e-03 [3.098691e-07] 
Layer 'conv1' biases: 1.134737e-06 [1.017932e-09] 
Layer 'conv2' weights[0]: 6.059574e-03 [3.066552e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.688674e-09] 
Layer 'conv3' weights[0]: 6.058489e-03 [3.080385e-07] 
Layer 'conv3' biases: 2.047795e-05 [3.328855e-08] 
Layer 'conv4' weights[0]: 6.083178e-03 [3.116506e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.922450e-07] 
Layer 'conv5' weights[0]: 6.121310e-03 [2.585865e-06] 
Layer 'conv5' biases: 9.992179e-01 [2.693941e-06] 
Layer 'fc6' weights[0]: 7.379642e-03 [6.206548e-08] 
Layer 'fc6' biases: 9.999977e-01 [6.149233e-08] 
Layer 'fc7' weights[0]: 7.734263e-03 [1.425230e-07] 
Layer 'fc7' biases: 9.999156e-01 [1.989406e-07] 
Layer 'fc8' weights[0]: 4.082452e-03 [2.218327e-05] 
Layer 'fc8' biases: 7.235454e-03 [4.476533e-05] 
Train error last 800 batches: 0.657736
-------------------------------------------------------
Not saving because 0.451045 > 0.303240 (5.60: -6.35%)
======================================================= (2.358 sec)
7.681... logprob:  0.665873, 0.272135 (1.439 sec)
7.682... logprob:  0.569899, 0.243490 (1.448 sec)
7.683... logprob:  0.640368, 0.298177 (1.431 sec)
7.684... logprob:  0.633945, 0.273438 (1.467 sec)
7.685... logprob:  0.546331, 0.260417 (1.441 sec)
7.686... logprob:  0.585542, 0.256510 (1.430 sec)
7.687... logprob:  0.531901, 0.253906 (1.483 sec)
7.688... logprob:  0.606243, 0.281250 (1.426 sec)
7.689... logprob:  0.738678, 0.347656 (1.429 sec)
7.690... logprob:  0.637714, 0.268229 (1.431 sec)
7.691... logprob:  0.617085, 0.273437 (1.431 sec)
7.692... logprob:  0.636356, 0.255208 (1.421 sec)
7.693... logprob:  0.663433, 0.296875 (1.485 sec)
7.694... logprob:  0.634562, 0.285156 (1.433 sec)
7.695... logprob:  0.595988, 0.259115 (1.439 sec)
7.696... logprob:  0.833771, 0.348958 (1.469 sec)
7.697... logprob:  0.659424, 0.281250 (1.431 sec)
7.698... logprob:  0.654814, 0.296875 (1.428 sec)
7.699... logprob:  0.699549, 0.329427 (1.428 sec)
7.700... logprob:  0.680831, 0.315104 (1.417 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.439634, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.064097e-03 [3.065771e-07] 
Layer 'conv1' biases: 1.135946e-06 [1.077690e-09] 
Layer 'conv2' weights[0]: 6.053512e-03 [3.050340e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.457846e-09] 
Layer 'conv3' weights[0]: 6.052431e-03 [3.068547e-07] 
Layer 'conv3' biases: 2.054424e-05 [3.062399e-08] 
Layer 'conv4' weights[0]: 6.077115e-03 [3.101141e-07] 
Layer 'conv4' biases: 1.000014e+00 [3.603955e-07] 
Layer 'conv5' weights[0]: 6.115261e-03 [2.525159e-06] 
Layer 'conv5' biases: 9.992170e-01 [2.591721e-06] 
Layer 'fc6' weights[0]: 7.378888e-03 [6.265328e-08] 
Layer 'fc6' biases: 9.999977e-01 [6.231952e-08] 
Layer 'fc7' weights[0]: 7.733556e-03 [1.387943e-07] 
Layer 'fc7' biases: 9.999160e-01 [1.906530e-07] 
Layer 'fc8' weights[0]: 4.099796e-03 [1.830925e-05] 
Layer 'fc8' biases: 7.385803e-03 [2.915813e-05] 
Train error last 800 batches: 0.657717
-------------------------------------------------------
Not saving because 0.439634 > 0.303240 (5.60: -6.35%)
======================================================= (2.366 sec)
7.701... logprob:  0.642599, 0.281250 (1.434 sec)
7.702... logprob:  0.703485, 0.302083 (1.479 sec)
7.703... logprob:  0.603576, 0.261719 (1.432 sec)
7.704... logprob:  0.596122, 0.283854 (1.441 sec)
7.705... logprob:  0.572750, 0.240885 (1.469 sec)
7.706... logprob:  0.707162, 0.266927 (1.428 sec)
7.707... logprob:  0.657528, 0.274739 (1.429 sec)
7.708... logprob:  0.713529, 0.303385 (1.428 sec)
7.709... logprob:  0.665385, 0.276042 (1.412 sec)
7.710... logprob:  0.859296, 0.361979 (1.435 sec)
7.711... logprob:  0.746430, 0.330729 (1.457 sec)
7.712... logprob:  0.646813, 0.255208 (1.445 sec)
7.713... logprob:  0.744066, 0.317708 (1.449 sec)
7.714... logprob:  0.682950, 0.291667 (1.451 sec)
7.715... logprob:  0.602278, 0.268229 (1.447 sec)
7.716... logprob:  0.592724, 0.279948 (1.431 sec)
7.717... logprob:  0.685366, 0.333333 (1.422 sec)
7.718... logprob:  0.637785, 0.283854 (1.422 sec)
7.719... logprob:  0.663346, 0.315104 (1.432 sec)
7.720... logprob:  0.664744, 0.308594 (1.438 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.483945, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.058059e-03 [3.071694e-07] 
Layer 'conv1' biases: 1.138446e-06 [9.807450e-10] 
Layer 'conv2' weights[0]: 6.047470e-03 [3.048358e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.649354e-09] 
Layer 'conv3' weights[0]: 6.046343e-03 [3.059235e-07] 
Layer 'conv3' biases: 2.059482e-05 [2.754893e-08] 
Layer 'conv4' weights[0]: 6.071062e-03 [3.091745e-07] 
Layer 'conv4' biases: 1.000016e+00 [3.231048e-07] 
Layer 'conv5' weights[0]: 6.110284e-03 [2.228254e-06] 
Layer 'conv5' biases: 9.992242e-01 [2.243245e-06] 
Layer 'fc6' weights[0]: 7.378160e-03 [5.800126e-08] 
Layer 'fc6' biases: 9.999976e-01 [5.455042e-08] 
Layer 'fc7' weights[0]: 7.732754e-03 [1.267596e-07] 
Layer 'fc7' biases: 9.999146e-01 [1.508798e-07] 
Layer 'fc8' weights[0]: 4.040388e-03 [1.697679e-05] 
Layer 'fc8' biases: 6.966905e-03 [2.394090e-05] 
Train error last 800 batches: 0.657584
-------------------------------------------------------
Not saving because 0.483945 > 0.303240 (5.60: -6.35%)
======================================================= (2.436 sec)
7.721... logprob:  0.631508, 0.272135 (1.466 sec)
7.722... logprob:  0.651502, 0.316406 (1.456 sec)
7.723... logprob:  0.649837, 0.274740 (1.443 sec)
7.724... logprob:  0.635823, 0.283854 (1.468 sec)
7.725... logprob:  0.672530, 0.287760 (1.428 sec)
7.726... logprob:  0.560117, 0.246094 (1.417 sec)
7.727... logprob:  0.642048, 0.291667 (1.427 sec)
7.728... logprob:  0.507627, 0.235677 (1.429 sec)
7.729... logprob:  0.598266, 0.272135 (1.427 sec)
7.730... logprob:  0.794499, 0.343750 (1.469 sec)
7.731... logprob:  0.646944, 0.281250 (1.441 sec)
7.732... logprob:  0.539943, 0.272135 (1.426 sec)
7.733... logprob:  0.685782, 0.289062 (1.481 sec)
7.734... logprob:  0.566127, 0.260417 (1.430 sec)
7.735... logprob:  0.676484, 0.304688 (1.419 sec)
7.736... logprob:  0.831644, 0.330729 (1.436 sec)
7.737... logprob:  0.775833, 0.304687 (1.427 sec)
7.738... logprob:  0.687464, 0.326823 (1.427 sec)
7.739... logprob:  0.685608, 0.300781 (1.477 sec)
7.740... logprob:  0.610718, 0.263021 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.393305, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.052002e-03 [3.087166e-07] 
Layer 'conv1' biases: 1.145557e-06 [1.283858e-09] 
Layer 'conv2' weights[0]: 6.041425e-03 [3.055040e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.454967e-09] 
Layer 'conv3' weights[0]: 6.040328e-03 [3.071228e-07] 
Layer 'conv3' biases: 2.066006e-05 [3.210860e-08] 
Layer 'conv4' weights[0]: 6.064969e-03 [3.113738e-07] 
Layer 'conv4' biases: 1.000014e+00 [4.109951e-07] 
Layer 'conv5' weights[0]: 6.104221e-03 [3.195336e-06] 
Layer 'conv5' biases: 9.992133e-01 [3.235411e-06] 
Layer 'fc6' weights[0]: 7.377388e-03 [7.199865e-08] 
Layer 'fc6' biases: 9.999977e-01 [7.570138e-08] 
Layer 'fc7' weights[0]: 7.731981e-03 [1.702442e-07] 
Layer 'fc7' biases: 9.999155e-01 [2.781541e-07] 
Layer 'fc8' weights[0]: 4.096520e-03 [2.698211e-05] 
Layer 'fc8' biases: 7.336818e-03 [5.743486e-05] 
Train error last 800 batches: 0.657298
-------------------------------------------------------
Not saving because 0.393305 > 0.303240 (5.60: -6.35%)
======================================================= (2.349 sec)
7.741... logprob:  0.666835, 0.302083 (1.439 sec)
7.742... logprob:  0.636389, 0.283854 (1.486 sec)
7.743... logprob:  0.609642, 0.274740 (1.430 sec)
7.744... logprob:  0.758962, 0.338542 (1.427 sec)
7.745... logprob:  0.627727, 0.244792 (1.427 sec)
7.746... logprob:  0.626276, 0.264323 (1.425 sec)
7.747... logprob:  0.582039, 0.252604 (1.426 sec)
7.748... logprob:  0.631575, 0.287760 (1.480 sec)
7.749... logprob:  0.771056, 0.338542 (1.427 sec)
7.750... logprob:  0.743798, 0.322917 (1.440 sec)
7.751... logprob:  0.488563, 0.220052 (1.470 sec)
7.752... logprob:  0.814921, 0.345052 (1.434 sec)
7.753... logprob:  0.602844, 0.274740 (1.431 sec)
7.754... logprob:  0.647367, 0.270833 (1.428 sec)
7.755... logprob:  0.684655, 0.322917 (1.418 sec)
7.756... logprob:  0.653570, 0.286458 (1.425 sec)
7.757... logprob:  0.689748, 0.305990 (1.469 sec)
7.758... logprob:  0.695598, 0.295573 (1.438 sec)
7.759... logprob:  0.677306, 0.285156 (1.447 sec)
7.760... logprob:  0.675060, 0.309896 (1.454 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.511245, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.045947e-03 [3.070445e-07] 
Layer 'conv1' biases: 1.153302e-06 [9.298260e-10] 
Layer 'conv2' weights[0]: 6.035416e-03 [3.045661e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.390499e-09] 
Layer 'conv3' weights[0]: 6.034295e-03 [3.059892e-07] 
Layer 'conv3' biases: 2.067296e-05 [2.934653e-08] 
Layer 'conv4' weights[0]: 6.058913e-03 [3.092793e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.481312e-07] 
Layer 'conv5' weights[0]: 6.098380e-03 [2.455056e-06] 
Layer 'conv5' biases: 9.992136e-01 [2.564798e-06] 
Layer 'fc6' weights[0]: 7.376621e-03 [5.968944e-08] 
Layer 'fc6' biases: 9.999977e-01 [5.773315e-08] 
Layer 'fc7' weights[0]: 7.731201e-03 [1.313761e-07] 
Layer 'fc7' biases: 9.999141e-01 [1.569461e-07] 
Layer 'fc8' weights[0]: 4.078305e-03 [1.797545e-05] 
Layer 'fc8' biases: 7.230864e-03 [2.117588e-05] 
Train error last 800 batches: 0.657143
-------------------------------------------------------
Not saving because 0.511245 > 0.303240 (5.60: -6.35%)
======================================================= (2.366 sec)
7.761... logprob:  0.600649, 0.270833 (1.445 sec)
7.762... logprob:  0.680501, 0.298177 (1.442 sec)
7.763... logprob:  0.740919, 0.320312 (1.427 sec)
7.764... logprob:  0.779169, 0.319010 (1.420 sec)
7.765... logprob:  0.524928, 0.250000 (1.431 sec)
7.766... logprob:  0.714538, 0.292969 (1.451 sec)
7.767... logprob:  0.561469, 0.244792 (1.457 sec)
7.768... logprob:  0.643647, 0.266927 (1.458 sec)
7.769... logprob:  0.811268, 0.341146 (1.468 sec)
7.770... logprob:  0.616627, 0.261719 (1.480 sec)
7.771... logprob:  0.648722, 0.281250 (1.453 sec)
7.772... logprob:  0.579089, 0.272135 (1.435 sec)
7.773... logprob:  0.813689, 0.361979 (1.443 sec)
7.774... logprob:  0.635134, 0.261719 (1.449 sec)
7.775... logprob:  0.635936, 0.272135 (1.460 sec)
7.776... logprob:  0.721435, 0.294271 (1.472 sec)
7.777... logprob:  0.650526, 0.290365 (1.466 sec)
7.778... logprob:  0.614080, 0.247396 (1.463 sec)
7.779... logprob:  0.691205, 0.259114 (1.482 sec)
7.780... logprob:  0.623186, 0.278646 (1.452 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.377877, 0.062500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.039918e-03 [3.060667e-07] 
Layer 'conv1' biases: 1.159766e-06 [7.544720e-10] 
Layer 'conv2' weights[0]: 6.029363e-03 [3.044569e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.362891e-09] 
Layer 'conv3' weights[0]: 6.028254e-03 [3.053838e-07] 
Layer 'conv3' biases: 2.064437e-05 [2.755671e-08] 
Layer 'conv4' weights[0]: 6.052824e-03 [3.094714e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.462993e-07] 
Layer 'conv5' weights[0]: 6.092314e-03 [2.651412e-06] 
Layer 'conv5' biases: 9.992179e-01 [2.872986e-06] 
Layer 'fc6' weights[0]: 7.375819e-03 [6.131361e-08] 
Layer 'fc6' biases: 9.999977e-01 [6.002134e-08] 
Layer 'fc7' weights[0]: 7.730426e-03 [1.342732e-07] 
Layer 'fc7' biases: 9.999133e-01 [1.623394e-07] 
Layer 'fc8' weights[0]: 4.054345e-03 [1.769976e-05] 
Layer 'fc8' biases: 7.062691e-03 [2.655939e-05] 
Train error last 800 batches: 0.656912
-------------------------------------------------------
Not saving because 0.377877 > 0.303240 (5.60: -6.35%)
======================================================= (2.416 sec)
7.781... logprob:  0.545373, 0.221354 (1.452 sec)
7.782... logprob:  0.681287, 0.312500 (1.447 sec)
7.783... logprob:  0.723769, 0.307292 (1.459 sec)
7.784... logprob:  0.677587, 0.303385 (1.450 sec)
7.785... logprob:  0.730152, 0.345052 (1.485 sec)
7.786... logprob:  0.669645, 0.296875 (1.468 sec)
7.787... logprob:  0.810258, 0.350260 (1.451 sec)
7.788... logprob:  0.711893, 0.311198 (1.490 sec)
7.789... logprob:  0.538626, 0.248698 (1.533 sec)
7.790... logprob:  0.637924, 0.291667 (1.446 sec)
7.791... logprob:  0.611735, 0.303385 (1.444 sec)
7.792... logprob:  0.556724, 0.233073 (1.453 sec)
7.793... logprob:  0.585373, 0.248698 (1.450 sec)
7.794... logprob:  0.599781, 0.274740 (1.482 sec)
7.795... logprob:  0.679231, 0.299479 (1.460 sec)
7.796... logprob:  0.609090, 0.248698 (1.448 sec)
7.797... logprob:  0.610192, 0.264323 (1.529 sec)
7.798... logprob:  0.650453, 0.299479 (1.444 sec)
7.799... logprob:  0.588699, 0.248698 (1.442 sec)
7.800... logprob:  0.616936, 0.281250 (1.394 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.413518, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.033878e-03 [3.056749e-07] 
Layer 'conv1' biases: 1.168490e-06 [1.064806e-09] 
Layer 'conv2' weights[0]: 6.023302e-03 [3.040114e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.873171e-09] 
Layer 'conv3' weights[0]: 6.022230e-03 [3.052796e-07] 
Layer 'conv3' biases: 2.064388e-05 [2.961847e-08] 
Layer 'conv4' weights[0]: 6.046802e-03 [3.105711e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.904866e-07] 
Layer 'conv5' weights[0]: 6.086177e-03 [2.725792e-06] 
Layer 'conv5' biases: 9.992073e-01 [2.833928e-06] 
Layer 'fc6' weights[0]: 7.375049e-03 [6.316356e-08] 
Layer 'fc6' biases: 9.999977e-01 [6.288718e-08] 
Layer 'fc7' weights[0]: 7.729700e-03 [1.418792e-07] 
Layer 'fc7' biases: 9.999146e-01 [2.077706e-07] 
Layer 'fc8' weights[0]: 4.119244e-03 [2.054323e-05] 
Layer 'fc8' biases: 7.565713e-03 [4.153907e-05] 
Train error last 800 batches: 0.656448
-------------------------------------------------------
Not saving because 0.413518 > 0.303240 (5.60: -6.35%)
======================================================= (2.351 sec)
8.1... logprob:  0.594277, 0.255208 (1.415 sec)
8.2... logprob:  0.694038, 0.292969 (1.446 sec)
8.3... logprob:  0.708093, 0.311198 (1.412 sec)
8.4... logprob:  0.658599, 0.250000 (1.401 sec)
8.5... logprob:  0.675109, 0.298177 (1.433 sec)
8.6... logprob:  0.631985, 0.286458 (1.389 sec)
8.7... logprob:  0.555679, 0.253906 (1.421 sec)
8.8... logprob:  0.652372, 0.290365 (1.390 sec)
8.9... logprob:  0.542552, 0.243490 (1.403 sec)
8.10... logprob:  0.534007, 0.230469 (1.406 sec)
8.11... logprob:  0.543869, 0.217448 (1.444 sec)
8.12... logprob:  0.661628, 0.278646 (1.392 sec)
8.13... logprob:  0.738097, 0.321614 (1.419 sec)
8.14... logprob:  0.739451, 0.347656 (1.399 sec)
8.15... logprob:  0.652848, 0.304687 (1.402 sec)
8.16... logprob:  0.618616, 0.265625 (1.404 sec)
8.17... logprob:  0.710088, 0.292969 (1.392 sec)
8.18... logprob:  0.461821, 0.230469 (1.399 sec)
8.19... logprob:  0.510736, 0.244792 (1.399 sec)
8.20... logprob:  0.656018, 0.263021 (1.396 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.447197, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.027888e-03 [3.045303e-07] 
Layer 'conv1' biases: 1.174040e-06 [9.736786e-10] 
Layer 'conv2' weights[0]: 6.017333e-03 [3.031583e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.114306e-09] 
Layer 'conv3' weights[0]: 6.016223e-03 [3.038734e-07] 
Layer 'conv3' biases: 2.067424e-05 [2.646237e-08] 
Layer 'conv4' weights[0]: 6.040777e-03 [3.065472e-07] 
Layer 'conv4' biases: 1.000011e+00 [3.097065e-07] 
Layer 'conv5' weights[0]: 6.079609e-03 [2.171587e-06] 
Layer 'conv5' biases: 9.992126e-01 [2.290908e-06] 
Layer 'fc6' weights[0]: 7.374298e-03 [5.486800e-08] 
Layer 'fc6' biases: 9.999977e-01 [4.981768e-08] 
Layer 'fc7' weights[0]: 7.728942e-03 [1.172945e-07] 
Layer 'fc7' biases: 9.999145e-01 [1.236688e-07] 
Layer 'fc8' weights[0]: 4.113752e-03 [1.383498e-05] 
Layer 'fc8' biases: 7.549169e-03 [4.576667e-06] 
Train error last 800 batches: 0.655556
-------------------------------------------------------
Not saving because 0.447197 > 0.303240 (5.60: -6.35%)
======================================================= (2.387 sec)
8.21... logprob:  0.557025, 0.244792 (1.404 sec)
8.22... logprob:  0.814868, 0.328125 (1.412 sec)
8.23... logprob:  0.712417, 0.312500 (1.406 sec)
8.24... logprob:  0.569126, 0.247396 (1.412 sec)
8.25... logprob:  0.634556, 0.296875 (1.401 sec)
8.26... logprob:  0.708849, 0.316406 (1.439 sec)
8.27... logprob:  0.671028, 0.321614 (1.384 sec)
8.28... logprob:  0.645739, 0.274740 (1.411 sec)
8.29... logprob:  0.654535, 0.315104 (1.414 sec)
8.30... logprob:  0.633179, 0.247396 (1.422 sec)
8.31... logprob:  0.707314, 0.315104 (1.402 sec)
8.32... logprob:  0.654850, 0.295573 (1.383 sec)
8.33... logprob:  0.746143, 0.305990 (1.438 sec)
8.34... logprob:  0.639997, 0.298177 (1.386 sec)
8.35... logprob:  0.603525, 0.294271 (1.395 sec)
8.36... logprob:  0.703532, 0.294271 (1.417 sec)
8.37... logprob:  0.603479, 0.273437 (1.415 sec)
8.38... logprob:  0.687597, 0.325521 (1.388 sec)
8.39... logprob:  0.875024, 0.352865 (1.427 sec)
8.40... logprob:  0.754974, 0.329427 (1.405 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.479382, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.021851e-03 [3.062869e-07] 
Layer 'conv1' biases: 1.178014e-06 [1.579077e-09] 
Layer 'conv2' weights[0]: 6.011311e-03 [3.051440e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.077737e-08] 
Layer 'conv3' weights[0]: 6.010215e-03 [3.073395e-07] 
Layer 'conv3' biases: 2.069135e-05 [3.847621e-08] 
Layer 'conv4' weights[0]: 6.034762e-03 [3.133785e-07] 
Layer 'conv4' biases: 1.000011e+00 [5.208880e-07] 
Layer 'conv5' weights[0]: 6.073517e-03 [3.566374e-06] 
Layer 'conv5' biases: 9.992282e-01 [3.789144e-06] 
Layer 'fc6' weights[0]: 7.373522e-03 [7.307782e-08] 
Layer 'fc6' biases: 9.999976e-01 [7.704016e-08] 
Layer 'fc7' weights[0]: 7.728153e-03 [1.733889e-07] 
Layer 'fc7' biases: 9.999133e-01 [2.835538e-07] 
Layer 'fc8' weights[0]: 4.070110e-03 [2.596861e-05] 
Layer 'fc8' biases: 7.152163e-03 [5.036074e-05] 
Train error last 800 batches: 0.655777
-------------------------------------------------------
Not saving because 0.479382 > 0.303240 (5.60: -6.35%)
======================================================= (2.349 sec)
8.41... logprob:  0.637483, 0.279948 (1.434 sec)
8.42... logprob:  0.565917, 0.278646 (1.413 sec)
8.43... logprob:  0.732415, 0.332031 (1.402 sec)
8.44... logprob:  0.790143, 0.312500 (1.428 sec)
8.45... logprob:  0.580892, 0.261719 (1.381 sec)
8.46... logprob:  0.783180, 0.311198 (1.392 sec)
8.47... logprob:  0.646176, 0.316406 (1.389 sec)
8.48... logprob:  0.613259, 0.244792 (1.417 sec)
8.49... logprob:  0.758369, 0.339844 (1.407 sec)
8.50... logprob:  0.566912, 0.225260 (1.417 sec)
8.51... logprob:  0.680055, 0.317708 (1.409 sec)
8.52... logprob:  0.746440, 0.308594 (1.395 sec)
8.53... logprob:  0.571528, 0.263021 (1.439 sec)
8.54... logprob:  0.655186, 0.285156 (1.384 sec)
8.55... logprob:  0.605314, 0.264323 (1.397 sec)
8.56... logprob:  0.637707, 0.303385 (1.392 sec)
8.57... logprob:  0.722402, 0.322917 (1.424 sec)
8.58... logprob:  0.632744, 0.296875 (1.399 sec)
8.59... logprob:  0.604221, 0.265625 (1.465 sec)
8.60... logprob:  0.795818, 0.359375 (1.410 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.510364, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.015865e-03 [3.050116e-07] 
Layer 'conv1' biases: 1.181550e-06 [8.957475e-10] 
Layer 'conv2' weights[0]: 6.005285e-03 [3.031537e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.822305e-09] 
Layer 'conv3' weights[0]: 6.004226e-03 [3.036087e-07] 
Layer 'conv3' biases: 2.070954e-05 [2.523469e-08] 
Layer 'conv4' weights[0]: 6.028707e-03 [3.079876e-07] 
Layer 'conv4' biases: 1.000011e+00 [3.503572e-07] 
Layer 'conv5' weights[0]: 6.067731e-03 [2.626913e-06] 
Layer 'conv5' biases: 9.992298e-01 [2.835292e-06] 
Layer 'fc6' weights[0]: 7.372747e-03 [6.170267e-08] 
Layer 'fc6' biases: 9.999976e-01 [6.021518e-08] 
Layer 'fc7' weights[0]: 7.727402e-03 [1.396360e-07] 
Layer 'fc7' biases: 9.999136e-01 [1.924411e-07] 
Layer 'fc8' weights[0]: 4.086234e-03 [2.011891e-05] 
Layer 'fc8' biases: 7.294898e-03 [2.877956e-05] 
Train error last 800 batches: 0.656337
-------------------------------------------------------
Not saving because 0.510364 > 0.303240 (5.60: -6.35%)
======================================================= (2.359 sec)
8.61... logprob:  0.593323, 0.287760 (1.434 sec)
8.62... logprob:  0.716152, 0.339844 (1.458 sec)
8.63... logprob:  0.626512, 0.285156 (1.431 sec)
8.64... logprob:  0.707036, 0.295573 (1.409 sec)
8.65... logprob:  0.517106, 0.240885 (1.394 sec)
8.66... logprob:  0.625419, 0.276042 (1.443 sec)
8.67... logprob:  0.604243, 0.272135 (1.391 sec)
8.68... logprob:  0.618477, 0.279948 (1.399 sec)
8.69... logprob:  0.772396, 0.315104 (1.426 sec)
8.70... logprob:  0.560948, 0.248698 (1.423 sec)
8.71... logprob:  0.550221, 0.261719 (1.457 sec)
8.72... logprob:  0.650502, 0.270833 (1.398 sec)
8.73... logprob:  0.579822, 0.257812 (1.423 sec)
8.74... logprob:  0.623658, 0.278646 (1.409 sec)
8.75... logprob:  0.586528, 0.259115 (1.447 sec)
8.76... logprob:  0.695470, 0.305990 (1.433 sec)
8.77... logprob:  0.625050, 0.226562 (1.423 sec)
8.78... logprob:  0.727161, 0.295573 (1.449 sec)
8.79... logprob:  0.647698, 0.286458 (1.403 sec)
8.80... logprob:  0.655203, 0.300781 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.462362, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.009867e-03 [3.042046e-07] 
Layer 'conv1' biases: 1.182506e-06 [9.396539e-10] 
Layer 'conv2' weights[0]: 5.999279e-03 [3.023183e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.764373e-09] 
Layer 'conv3' weights[0]: 5.998251e-03 [3.029592e-07] 
Layer 'conv3' biases: 2.078418e-05 [2.578779e-08] 
Layer 'conv4' weights[0]: 6.022688e-03 [3.058245e-07] 
Layer 'conv4' biases: 1.000010e+00 [3.037999e-07] 
Layer 'conv5' weights[0]: 6.061633e-03 [2.321719e-06] 
Layer 'conv5' biases: 9.992239e-01 [2.410142e-06] 
Layer 'fc6' weights[0]: 7.371980e-03 [5.936324e-08] 
Layer 'fc6' biases: 9.999977e-01 [5.678197e-08] 
Layer 'fc7' weights[0]: 7.726626e-03 [1.306986e-07] 
Layer 'fc7' biases: 9.999138e-01 [1.666280e-07] 
Layer 'fc8' weights[0]: 4.135605e-03 [1.787408e-05] 
Layer 'fc8' biases: 7.653110e-03 [2.369801e-05] 
Train error last 800 batches: 0.655833
-------------------------------------------------------
Not saving because 0.462362 > 0.303240 (5.60: -6.35%)
======================================================= (2.366 sec)
8.81... logprob:  0.603743, 0.274740 (1.422 sec)
8.82... logprob:  0.494153, 0.239583 (1.421 sec)
8.83... logprob:  0.743461, 0.317708 (1.398 sec)
8.84... logprob:  0.601726, 0.287760 (1.473 sec)
8.85... logprob:  0.527457, 0.251302 (1.417 sec)
8.86... logprob:  0.648355, 0.286458 (1.414 sec)
8.87... logprob:  0.836637, 0.358073 (1.417 sec)
8.88... logprob:  0.681209, 0.290365 (1.406 sec)
8.89... logprob:  0.621529, 0.289063 (1.429 sec)
8.90... logprob:  0.802124, 0.345052 (1.379 sec)
8.91... logprob:  0.548820, 0.268229 (1.396 sec)
8.92... logprob:  0.665260, 0.303385 (1.404 sec)
8.93... logprob:  0.713632, 0.296875 (1.398 sec)
8.94... logprob:  0.729924, 0.338542 (1.393 sec)
8.95... logprob:  0.749779, 0.335937 (1.400 sec)
8.96... logprob:  0.833295, 0.373698 (1.405 sec)
8.97... logprob:  0.671642, 0.308594 (1.390 sec)
8.98... logprob:  0.652034, 0.294271 (1.430 sec)
8.99... logprob:  0.681811, 0.298177 (1.403 sec)
8.100... logprob:  0.546651, 0.248698 (1.394 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.524667, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 6.003837e-03 [3.045581e-07] 
Layer 'conv1' biases: 1.185508e-06 [8.480000e-10] 
Layer 'conv2' weights[0]: 5.993294e-03 [3.027331e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.183265e-09] 
Layer 'conv3' weights[0]: 5.992281e-03 [3.033457e-07] 
Layer 'conv3' biases: 2.089546e-05 [2.684229e-08] 
Layer 'conv4' weights[0]: 6.016689e-03 [3.070872e-07] 
Layer 'conv4' biases: 1.000011e+00 [3.402607e-07] 
Layer 'conv5' weights[0]: 6.056106e-03 [2.375941e-06] 
Layer 'conv5' biases: 9.992275e-01 [2.457089e-06] 
Layer 'fc6' weights[0]: 7.371187e-03 [5.873819e-08] 
Layer 'fc6' biases: 9.999977e-01 [5.589316e-08] 
Layer 'fc7' weights[0]: 7.725834e-03 [1.280356e-07] 
Layer 'fc7' biases: 9.999126e-01 [1.568156e-07] 
Layer 'fc8' weights[0]: 4.082409e-03 [1.606705e-05] 
Layer 'fc8' biases: 7.259975e-03 [1.952839e-05] 
Train error last 800 batches: 0.656074
-------------------------------------------------------
Not saving because 0.524667 > 0.303240 (5.60: -6.35%)
======================================================= (2.409 sec)
8.101... logprob:  0.617071, 0.272135 (1.446 sec)
8.102... logprob:  0.752704, 0.322917 (1.387 sec)
8.103... logprob:  0.722579, 0.320312 (1.395 sec)
8.104... logprob:  0.672305, 0.300781 (1.394 sec)
8.105... logprob:  0.785667, 0.320312 (1.393 sec)
8.106... logprob:  0.579841, 0.213542 (1.388 sec)
8.107... logprob:  0.583427, 0.264323 (1.443 sec)
8.108... logprob:  0.730642, 0.311198 (1.396 sec)
8.109... logprob:  0.569725, 0.250000 (1.398 sec)
8.110... logprob:  0.799842, 0.365885 (1.394 sec)
8.111... logprob:  0.665621, 0.308594 (1.389 sec)
8.112... logprob:  0.631850, 0.290365 (1.397 sec)
8.113... logprob:  0.549317, 0.239583 (1.391 sec)
8.114... logprob:  0.737978, 0.332031 (1.432 sec)
8.115... logprob:  0.656271, 0.286458 (1.410 sec)
8.116... logprob:  0.654070, 0.286458 (1.402 sec)
8.117... logprob:  0.762937, 0.325521 (1.443 sec)
8.118... logprob:  0.633246, 0.287760 (1.382 sec)
8.119... logprob:  0.598401, 0.278646 (1.392 sec)
8.120... logprob:  0.801011, 0.332031 (1.393 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.397523, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.997857e-03 [3.034380e-07] 
Layer 'conv1' biases: 1.184668e-06 [7.147747e-10] 
Layer 'conv2' weights[0]: 5.987306e-03 [3.021507e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.339367e-09] 
Layer 'conv3' weights[0]: 5.986231e-03 [3.028470e-07] 
Layer 'conv3' biases: 2.100284e-05 [2.625602e-08] 
Layer 'conv4' weights[0]: 6.010640e-03 [3.057947e-07] 
Layer 'conv4' biases: 1.000012e+00 [2.991782e-07] 
Layer 'conv5' weights[0]: 6.050497e-03 [2.455557e-06] 
Layer 'conv5' biases: 9.992192e-01 [2.560044e-06] 
Layer 'fc6' weights[0]: 7.370445e-03 [5.913027e-08] 
Layer 'fc6' biases: 9.999977e-01 [5.648992e-08] 
Layer 'fc7' weights[0]: 7.725057e-03 [1.279539e-07] 
Layer 'fc7' biases: 9.999123e-01 [1.391784e-07] 
Layer 'fc8' weights[0]: 4.089618e-03 [1.521893e-05] 
Layer 'fc8' biases: 7.295097e-03 [5.414206e-06] 
Train error last 800 batches: 0.656772
-------------------------------------------------------
Not saving because 0.397523 > 0.303240 (5.60: -6.35%)
======================================================= (2.375 sec)
8.121... logprob:  0.606572, 0.260417 (1.402 sec)
8.122... logprob:  0.676102, 0.299479 (1.444 sec)
8.123... logprob:  0.648028, 0.277344 (1.383 sec)
8.124... logprob:  0.671898, 0.276042 (1.396 sec)
8.125... logprob:  0.710541, 0.315104 (1.391 sec)
8.126... logprob:  0.650418, 0.289062 (1.382 sec)
8.127... logprob:  0.717673, 0.311198 (1.397 sec)
8.128... logprob:  0.692797, 0.265625 (1.414 sec)
8.129... logprob:  0.746386, 0.309896 (1.414 sec)
8.130... logprob:  0.598477, 0.255208 (1.409 sec)
8.131... logprob:  0.699225, 0.304688 (1.405 sec)
8.132... logprob:  0.734412, 0.316406 (1.431 sec)
8.133... logprob:  0.701351, 0.291667 (1.381 sec)
8.134... logprob:  0.677441, 0.295573 (1.391 sec)
8.135... logprob:  0.670229, 0.287760 (1.396 sec)
8.136... logprob:  0.704892, 0.295573 (1.392 sec)
8.137... logprob:  0.667388, 0.285156 (1.383 sec)
8.138... logprob:  0.596402, 0.268229 (1.441 sec)
8.139... logprob:  0.645215, 0.287760 (1.399 sec)
8.140... logprob:  0.835895, 0.356771 (1.415 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.517848, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.991856e-03 [3.017161e-07] 
Layer 'conv1' biases: 1.185980e-06 [9.756695e-10] 
Layer 'conv2' weights[0]: 5.981348e-03 [3.017511e-07] 
Layer 'conv2' biases: 9.999995e-01 [7.047645e-09] 
Layer 'conv3' weights[0]: 5.980177e-03 [3.035974e-07] 
Layer 'conv3' biases: 2.108051e-05 [2.992293e-08] 
Layer 'conv4' weights[0]: 6.004660e-03 [3.065956e-07] 
Layer 'conv4' biases: 1.000012e+00 [3.740126e-07] 
Layer 'conv5' weights[0]: 6.045168e-03 [2.698276e-06] 
Layer 'conv5' biases: 9.992177e-01 [3.017880e-06] 
Layer 'fc6' weights[0]: 7.369739e-03 [6.184738e-08] 
Layer 'fc6' biases: 9.999977e-01 [6.074723e-08] 
Layer 'fc7' weights[0]: 7.724307e-03 [1.357954e-07] 
Layer 'fc7' biases: 9.999113e-01 [1.637886e-07] 
Layer 'fc8' weights[0]: 4.053413e-03 [1.730322e-05] 
Layer 'fc8' biases: 7.025444e-03 [2.205210e-05] 
Train error last 800 batches: 0.656999
-------------------------------------------------------
Not saving because 0.517848 > 0.303240 (5.60: -6.35%)
======================================================= (2.384 sec)
8.141... logprob:  0.610166, 0.279948 (1.442 sec)
8.142... logprob:  0.648908, 0.274740 (1.398 sec)
8.143... logprob:  0.551844, 0.222656 (1.428 sec)
8.144... logprob:  0.729925, 0.307292 (1.410 sec)
8.145... logprob:  0.532856, 0.226562 (1.418 sec)
8.146... logprob:  0.672827, 0.287760 (1.411 sec)
8.147... logprob:  0.577110, 0.263021 (1.425 sec)
8.148... logprob:  0.625760, 0.300781 (1.385 sec)
8.149... logprob:  0.692881, 0.270833 (1.396 sec)
8.150... logprob:  0.549786, 0.248698 (1.392 sec)
8.151... logprob:  0.591260, 0.282552 (1.394 sec)
8.152... logprob:  0.827126, 0.326823 (1.380 sec)
8.153... logprob:  0.610219, 0.285156 (1.446 sec)
8.154... logprob:  0.798674, 0.321615 (1.396 sec)
8.155... logprob:  0.680109, 0.292969 (1.407 sec)
8.156... logprob:  0.550660, 0.263021 (1.428 sec)
8.157... logprob:  0.529148, 0.247396 (1.392 sec)
8.158... logprob:  0.626107, 0.299479 (1.401 sec)
8.159... logprob:  0.657396, 0.304687 (1.389 sec)
8.160... logprob:  0.768797, 0.317708 (1.389 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.455628, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.985884e-03 [3.030186e-07] 
Layer 'conv1' biases: 1.188090e-06 [7.856806e-10] 
Layer 'conv2' weights[0]: 5.975346e-03 [3.014167e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.722330e-09] 
Layer 'conv3' weights[0]: 5.974280e-03 [3.026873e-07] 
Layer 'conv3' biases: 2.099182e-05 [2.973846e-08] 
Layer 'conv4' weights[0]: 5.998661e-03 [3.067513e-07] 
Layer 'conv4' biases: 1.000011e+00 [3.487598e-07] 
Layer 'conv5' weights[0]: 6.038959e-03 [2.731265e-06] 
Layer 'conv5' biases: 9.992021e-01 [2.945668e-06] 
Layer 'fc6' weights[0]: 7.368962e-03 [5.905275e-08] 
Layer 'fc6' biases: 9.999977e-01 [5.647060e-08] 
Layer 'fc7' weights[0]: 7.723571e-03 [1.335012e-07] 
Layer 'fc7' biases: 9.999134e-01 [1.666859e-07] 
Layer 'fc8' weights[0]: 4.151132e-03 [1.929212e-05] 
Layer 'fc8' biases: 7.642761e-03 [3.080581e-05] 
Train error last 800 batches: 0.656786
-------------------------------------------------------
Not saving because 0.455628 > 0.303240 (5.60: -6.35%)
======================================================= (2.486 sec)
8.161... logprob:  0.569570, 0.276042 (1.402 sec)
8.162... logprob:  0.806899, 0.343750 (1.401 sec)
8.163... logprob:  0.587959, 0.282552 (1.423 sec)
8.164... logprob:  0.682404, 0.298177 (1.420 sec)
8.165... logprob:  0.801699, 0.347656 (1.418 sec)
8.166... logprob:  0.638771, 0.264323 (1.444 sec)
8.167... logprob:  0.600196, 0.265625 (1.420 sec)
8.168... logprob:  0.648966, 0.290365 (1.420 sec)
8.169... logprob:  0.622297, 0.298177 (1.452 sec)
8.170... logprob:  0.706205, 0.329427 (1.394 sec)
8.171... logprob:  0.731565, 0.308594 (1.416 sec)
8.172... logprob:  0.704613, 0.299479 (1.407 sec)
8.173... logprob:  0.688847, 0.313802 (1.415 sec)
8.174... logprob:  0.829154, 0.348958 (1.396 sec)
8.175... logprob:  0.802276, 0.330729 (1.460 sec)
8.176... logprob:  0.651008, 0.285156 (1.411 sec)
8.177... logprob:  0.610247, 0.282552 (1.425 sec)
8.178... logprob:  0.559564, 0.248698 (1.457 sec)
8.179... logprob:  0.631568, 0.273437 (1.400 sec)
8.180... logprob:  0.684174, 0.287760 (1.413 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.548844, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.979886e-03 [3.038107e-07] 
Layer 'conv1' biases: 1.190832e-06 [1.038012e-09] 
Layer 'conv2' weights[0]: 5.969385e-03 [3.018779e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.190990e-09] 
Layer 'conv3' weights[0]: 5.968340e-03 [3.037686e-07] 
Layer 'conv3' biases: 2.111993e-05 [3.468892e-08] 
Layer 'conv4' weights[0]: 5.992675e-03 [3.066431e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.798026e-07] 
Layer 'conv5' weights[0]: 6.034249e-03 [2.737083e-06] 
Layer 'conv5' biases: 9.992059e-01 [2.896906e-06] 
Layer 'fc6' weights[0]: 7.368190e-03 [6.166108e-08] 
Layer 'fc6' biases: 9.999979e-01 [6.073482e-08] 
Layer 'fc7' weights[0]: 7.722755e-03 [1.383510e-07] 
Layer 'fc7' biases: 9.999118e-01 [1.841873e-07] 
Layer 'fc8' weights[0]: 4.090699e-03 [2.095513e-05] 
Layer 'fc8' biases: 7.236197e-03 [3.655552e-05] 
Train error last 800 batches: 0.657093
-------------------------------------------------------
Not saving because 0.548844 > 0.303240 (5.60: -6.35%)
======================================================= (2.368 sec)
8.181... logprob:  0.752522, 0.300781 (1.423 sec)
8.182... logprob:  0.622527, 0.289063 (1.417 sec)
8.183... logprob:  0.618925, 0.268229 (1.417 sec)
8.184... logprob:  0.701923, 0.307292 (1.414 sec)
8.185... logprob:  0.611600, 0.285156 (1.414 sec)
8.186... logprob:  0.643486, 0.304688 (1.390 sec)
8.187... logprob:  0.746251, 0.337240 (1.396 sec)
8.188... logprob:  0.662753, 0.286458 (1.389 sec)
8.189... logprob:  0.729091, 0.294271 (1.384 sec)
8.190... logprob:  0.601221, 0.257813 (1.429 sec)
8.191... logprob:  0.615688, 0.269531 (1.397 sec)
8.192... logprob:  0.707998, 0.337240 (1.415 sec)
8.193... logprob:  0.608391, 0.269531 (1.419 sec)
8.194... logprob:  0.733218, 0.338542 (1.411 sec)
8.195... logprob:  0.497044, 0.220052 (1.401 sec)
8.196... logprob:  0.636798, 0.283854 (1.397 sec)
8.197... logprob:  0.720669, 0.304687 (1.392 sec)
8.198... logprob:  0.604844, 0.260417 (1.399 sec)
8.199... logprob:  0.575729, 0.252604 (1.401 sec)
8.200... logprob:  0.664918, 0.291667 (1.440 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.417736, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.973930e-03 [3.021410e-07] 
Layer 'conv1' biases: 1.196132e-06 [7.370225e-10] 
Layer 'conv2' weights[0]: 5.963406e-03 [2.998514e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.356152e-09] 
Layer 'conv3' weights[0]: 5.962297e-03 [3.011144e-07] 
Layer 'conv3' biases: 2.114516e-05 [2.479333e-08] 
Layer 'conv4' weights[0]: 5.986686e-03 [3.046601e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.011139e-07] 
Layer 'conv5' weights[0]: 6.028433e-03 [2.060620e-06] 
Layer 'conv5' biases: 9.992040e-01 [2.226094e-06] 
Layer 'fc6' weights[0]: 7.367436e-03 [5.881026e-08] 
Layer 'fc6' biases: 9.999977e-01 [5.627744e-08] 
Layer 'fc7' weights[0]: 7.721934e-03 [1.288722e-07] 
Layer 'fc7' biases: 9.999124e-01 [1.570008e-07] 
Layer 'fc8' weights[0]: 4.139774e-03 [1.720341e-05] 
Layer 'fc8' biases: 7.542683e-03 [1.921811e-05] 
Train error last 800 batches: 0.657670
-------------------------------------------------------
Not saving because 0.417736 > 0.303240 (5.60: -6.35%)
======================================================= (2.362 sec)
8.201... logprob:  0.660037, 0.291667 (1.414 sec)
8.202... logprob:  0.762413, 0.325521 (1.407 sec)
8.203... logprob:  0.598849, 0.281250 (1.441 sec)
8.204... logprob:  0.645361, 0.294271 (1.387 sec)
8.205... logprob:  0.611005, 0.263021 (1.393 sec)
8.206... logprob:  0.582409, 0.279948 (1.397 sec)
8.207... logprob:  0.674490, 0.295573 (1.392 sec)
8.208... logprob:  0.700263, 0.317708 (1.388 sec)
8.209... logprob:  0.512435, 0.251302 (1.417 sec)
8.210... logprob:  0.814142, 0.319010 (1.415 sec)
8.211... logprob:  0.805666, 0.350260 (1.409 sec)
8.212... logprob:  0.688647, 0.304688 (1.413 sec)
8.213... logprob:  0.721590, 0.339844 (1.461 sec)
8.214... logprob:  0.684769, 0.304687 (1.416 sec)
8.215... logprob:  0.648031, 0.272135 (1.415 sec)
8.216... logprob:  0.714510, 0.303385 (1.464 sec)
8.217... logprob:  0.563328, 0.265625 (1.400 sec)
8.218... logprob:  0.656140, 0.282552 (1.423 sec)
8.219... logprob:  0.660178, 0.303385 (1.408 sec)
8.220... logprob:  0.587892, 0.263021 (1.416 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.384424, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.967965e-03 [3.010029e-07] 
Layer 'conv1' biases: 1.202972e-06 [9.089653e-10] 
Layer 'conv2' weights[0]: 5.957436e-03 [2.997071e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.479863e-09] 
Layer 'conv3' weights[0]: 5.956357e-03 [3.028556e-07] 
Layer 'conv3' biases: 2.130552e-05 [2.947248e-08] 
Layer 'conv4' weights[0]: 5.980694e-03 [3.059084e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.650109e-07] 
Layer 'conv5' weights[0]: 6.022887e-03 [2.468674e-06] 
Layer 'conv5' biases: 9.992105e-01 [2.609010e-06] 
Layer 'fc6' weights[0]: 7.366651e-03 [5.737305e-08] 
Layer 'fc6' biases: 9.999977e-01 [5.422040e-08] 
Layer 'fc7' weights[0]: 7.721144e-03 [1.276437e-07] 
Layer 'fc7' biases: 9.999112e-01 [1.552389e-07] 
Layer 'fc8' weights[0]: 4.109665e-03 [1.709402e-05] 
Layer 'fc8' biases: 7.301205e-03 [2.238893e-05] 
Train error last 800 batches: 0.657565
-------------------------------------------------------
Not saving because 0.384424 > 0.303240 (5.60: -6.35%)
======================================================= (2.380 sec)
8.221... logprob:  0.657494, 0.273437 (1.404 sec)
8.222... logprob:  0.780142, 0.332031 (1.451 sec)
8.223... logprob:  0.680218, 0.269531 (1.415 sec)
8.224... logprob:  0.639017, 0.263021 (1.437 sec)
8.225... logprob:  0.609789, 0.283854 (1.442 sec)
8.226... logprob:  0.619576, 0.268229 (1.417 sec)
8.227... logprob:  0.604663, 0.256510 (1.412 sec)
8.228... logprob:  0.680941, 0.283854 (1.413 sec)
8.229... logprob:  0.696571, 0.313802 (1.413 sec)
8.230... logprob:  0.688251, 0.304687 (1.442 sec)
8.231... logprob:  0.610890, 0.282552 (1.402 sec)
8.232... logprob:  0.756492, 0.352865 (1.452 sec)
8.233... logprob:  0.638382, 0.299479 (1.426 sec)
8.234... logprob:  0.768829, 0.320312 (1.413 sec)
8.235... logprob:  0.731681, 0.324219 (1.469 sec)
8.236... logprob:  0.734698, 0.339844 (1.403 sec)
8.237... logprob:  0.593220, 0.260417 (1.417 sec)
8.238... logprob:  0.654661, 0.268229 (1.414 sec)
8.239... logprob:  0.679762, 0.303385 (1.415 sec)
8.240... logprob:  0.740134, 0.332031 (1.394 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.481744, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.962001e-03 [3.005817e-07] 
Layer 'conv1' biases: 1.205556e-06 [8.003284e-10] 
Layer 'conv2' weights[0]: 5.951527e-03 [2.999894e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.969662e-09] 
Layer 'conv3' weights[0]: 5.950390e-03 [3.009007e-07] 
Layer 'conv3' biases: 2.133136e-05 [2.725043e-08] 
Layer 'conv4' weights[0]: 5.974732e-03 [3.043602e-07] 
Layer 'conv4' biases: 1.000014e+00 [3.309209e-07] 
Layer 'conv5' weights[0]: 6.017336e-03 [2.387113e-06] 
Layer 'conv5' biases: 9.992098e-01 [2.565034e-06] 
Layer 'fc6' weights[0]: 7.365850e-03 [5.838122e-08] 
Layer 'fc6' biases: 9.999978e-01 [5.531197e-08] 
Layer 'fc7' weights[0]: 7.720371e-03 [1.289141e-07] 
Layer 'fc7' biases: 9.999104e-01 [1.449130e-07] 
Layer 'fc8' weights[0]: 4.104026e-03 [1.611300e-05] 
Layer 'fc8' biases: 7.215830e-03 [1.411641e-05] 
Train error last 800 batches: 0.657986
-------------------------------------------------------
Not saving because 0.481744 > 0.303240 (5.60: -6.35%)
======================================================= (2.370 sec)
8.241... logprob:  0.719493, 0.324219 (1.468 sec)
8.242... logprob:  0.633432, 0.316406 (1.428 sec)
8.243... logprob:  0.596303, 0.260417 (1.429 sec)
8.244... logprob:  0.512325, 0.227864 (1.437 sec)
8.245... logprob:  0.796451, 0.319010 (1.422 sec)
8.246... logprob:  0.699964, 0.317708 (1.411 sec)
8.247... logprob:  0.554008, 0.263021 (1.413 sec)
8.248... logprob:  0.538340, 0.226562 (1.414 sec)
8.249... logprob:  0.838731, 0.346354 (1.423 sec)
8.250... logprob:  0.767438, 0.300781 (1.405 sec)
8.251... logprob:  0.573066, 0.230469 (1.459 sec)
8.252... logprob:  0.584750, 0.272135 (1.415 sec)
8.253... logprob:  0.543490, 0.230469 (1.412 sec)
8.254... logprob:  0.691687, 0.278646 (1.459 sec)
8.255... logprob:  0.609527, 0.253906 (1.399 sec)
8.256... logprob:  0.594764, 0.266927 (1.414 sec)
8.257... logprob:  0.628078, 0.253906 (1.408 sec)
8.258... logprob:  0.715423, 0.329427 (1.417 sec)
8.259... logprob:  0.736658, 0.312500 (1.396 sec)
8.260... logprob:  0.536146, 0.227865 (1.456 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.486018, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.956052e-03 [3.008132e-07] 
Layer 'conv1' biases: 1.209381e-06 [8.006414e-10] 
Layer 'conv2' weights[0]: 5.945563e-03 [2.997541e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.854071e-09] 
Layer 'conv3' weights[0]: 5.944432e-03 [3.003730e-07] 
Layer 'conv3' biases: 2.143346e-05 [2.456756e-08] 
Layer 'conv4' weights[0]: 5.968739e-03 [3.036489e-07] 
Layer 'conv4' biases: 1.000015e+00 [3.115175e-07] 
Layer 'conv5' weights[0]: 6.011623e-03 [2.385450e-06] 
Layer 'conv5' biases: 9.992024e-01 [2.572762e-06] 
Layer 'fc6' weights[0]: 7.365091e-03 [5.807246e-08] 
Layer 'fc6' biases: 9.999977e-01 [5.513760e-08] 
Layer 'fc7' weights[0]: 7.719611e-03 [1.268062e-07] 
Layer 'fc7' biases: 9.999111e-01 [1.413636e-07] 
Layer 'fc8' weights[0]: 4.149427e-03 [1.496792e-05] 
Layer 'fc8' biases: 7.552781e-03 [1.149045e-05] 
Train error last 800 batches: 0.658235
-------------------------------------------------------
Not saving because 0.486018 > 0.303240 (5.60: -6.35%)
======================================================= (2.377 sec)
8.261... logprob:  0.539155, 0.250000 (1.437 sec)
8.262... logprob:  0.750216, 0.316406 (1.433 sec)
8.263... logprob:  0.701936, 0.299479 (1.445 sec)
8.264... logprob:  0.567237, 0.268229 (1.420 sec)
8.265... logprob:  0.585223, 0.269531 (1.415 sec)
8.266... logprob:  0.671240, 0.316406 (1.417 sec)
8.267... logprob:  0.599161, 0.252604 (1.408 sec)
8.268... logprob:  0.700791, 0.305990 (1.420 sec)
8.269... logprob:  0.729201, 0.316406 (1.434 sec)
8.270... logprob:  0.686122, 0.290365 (1.456 sec)
8.271... logprob:  0.699200, 0.281250 (1.415 sec)
8.272... logprob:  0.590118, 0.273437 (1.417 sec)
8.273... logprob:  0.676854, 0.292969 (1.546 sec)
8.274... logprob:  0.641392, 0.282552 (1.396 sec)
8.275... logprob:  0.746401, 0.295573 (1.419 sec)
8.276... logprob:  0.612552, 0.273437 (1.416 sec)
8.277... logprob:  0.617455, 0.261719 (1.423 sec)
8.278... logprob:  0.543662, 0.221354 (1.417 sec)
8.279... logprob:  0.581493, 0.276042 (1.463 sec)
8.280... logprob:  0.521979, 0.247396 (1.394 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.555201, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.950095e-03 [3.003586e-07] 
Layer 'conv1' biases: 1.212999e-06 [9.390775e-10] 
Layer 'conv2' weights[0]: 5.939625e-03 [2.993479e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.057391e-09] 
Layer 'conv3' weights[0]: 5.938499e-03 [2.998085e-07] 
Layer 'conv3' biases: 2.147849e-05 [2.284139e-08] 
Layer 'conv4' weights[0]: 5.962748e-03 [3.033164e-07] 
Layer 'conv4' biases: 1.000017e+00 [3.122489e-07] 
Layer 'conv5' weights[0]: 6.006467e-03 [2.552141e-06] 
Layer 'conv5' biases: 9.992025e-01 [2.735417e-06] 
Layer 'fc6' weights[0]: 7.364307e-03 [6.126436e-08] 
Layer 'fc6' biases: 9.999977e-01 [5.987201e-08] 
Layer 'fc7' weights[0]: 7.718840e-03 [1.372809e-07] 
Layer 'fc7' biases: 9.999108e-01 [1.958967e-07] 
Layer 'fc8' weights[0]: 4.140641e-03 [1.915766e-05] 
Layer 'fc8' biases: 7.469251e-03 [3.493178e-05] 
Train error last 800 batches: 0.657493
-------------------------------------------------------
Not saving because 0.555201 > 0.303240 (5.60: -6.35%)
======================================================= (2.395 sec)
8.281... logprob:  0.668067, 0.305990 (1.428 sec)
8.282... logprob:  0.622142, 0.265625 (1.418 sec)
8.283... logprob:  0.639535, 0.261719 (1.416 sec)
8.284... logprob:  0.640774, 0.276042 (1.406 sec)
8.285... logprob:  0.675664, 0.273437 (1.442 sec)
8.286... logprob:  0.734029, 0.296875 (1.429 sec)
8.287... logprob:  0.571409, 0.264323 (1.426 sec)
8.288... logprob:  0.598382, 0.257812 (1.426 sec)
8.289... logprob:  0.554563, 0.250000 (1.434 sec)
8.290... logprob:  0.743409, 0.298177 (1.406 sec)
8.291... logprob:  0.712421, 0.322917 (1.419 sec)
8.292... logprob:  0.761584, 0.334635 (1.416 sec)
8.293... logprob:  0.696521, 0.325521 (1.419 sec)
8.294... logprob:  0.687327, 0.325521 (1.395 sec)
8.295... logprob:  0.545444, 0.243490 (1.455 sec)
8.296... logprob:  0.487656, 0.223958 (1.416 sec)
8.297... logprob:  0.641360, 0.283854 (1.414 sec)
8.298... logprob:  0.682483, 0.300781 (1.459 sec)
8.299... logprob:  0.540732, 0.244792 (1.401 sec)
8.300... logprob:  0.585406, 0.263021 (1.419 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.430094, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.944175e-03 [3.014103e-07] 
Layer 'conv1' biases: 1.209276e-06 [9.677572e-10] 
Layer 'conv2' weights[0]: 5.933672e-03 [2.992107e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.292900e-09] 
Layer 'conv3' weights[0]: 5.932582e-03 [3.007967e-07] 
Layer 'conv3' biases: 2.154774e-05 [2.891153e-08] 
Layer 'conv4' weights[0]: 5.956797e-03 [3.041664e-07] 
Layer 'conv4' biases: 1.000017e+00 [3.325085e-07] 
Layer 'conv5' weights[0]: 6.000952e-03 [2.690293e-06] 
Layer 'conv5' biases: 9.991997e-01 [2.782329e-06] 
Layer 'fc6' weights[0]: 7.363529e-03 [5.973893e-08] 
Layer 'fc6' biases: 9.999977e-01 [5.756136e-08] 
Layer 'fc7' weights[0]: 7.718054e-03 [1.337679e-07] 
Layer 'fc7' biases: 9.999109e-01 [1.867484e-07] 
Layer 'fc8' weights[0]: 4.170119e-03 [1.856588e-05] 
Layer 'fc8' biases: 7.656883e-03 [3.177613e-05] 
Train error last 800 batches: 0.657560
-------------------------------------------------------
Not saving because 0.430094 > 0.303240 (5.60: -6.35%)
======================================================= (2.375 sec)
8.301... logprob:  0.652249, 0.307292 (1.420 sec)
8.302... logprob:  0.799597, 0.315104 (1.414 sec)
8.303... logprob:  0.684329, 0.295573 (1.405 sec)
8.304... logprob:  0.622114, 0.291667 (1.437 sec)
8.305... logprob:  0.650188, 0.291667 (1.433 sec)
8.306... logprob:  0.690735, 0.292969 (1.430 sec)
8.307... logprob:  0.622981, 0.296875 (1.460 sec)
8.308... logprob:  0.509205, 0.230469 (1.446 sec)
8.309... logprob:  0.638919, 0.302083 (1.411 sec)
8.310... logprob:  0.586294, 0.255208 (1.420 sec)
8.311... logprob:  0.707249, 0.292969 (1.428 sec)
8.312... logprob:  0.744096, 0.352865 (1.421 sec)
8.313... logprob:  0.752736, 0.287760 (1.419 sec)
8.314... logprob:  0.661956, 0.282552 (1.454 sec)
8.315... logprob:  0.543803, 0.243489 (1.432 sec)
8.316... logprob:  0.684627, 0.321615 (1.416 sec)
8.317... logprob:  0.615992, 0.274740 (1.478 sec)
8.318... logprob:  0.659821, 0.290365 (1.406 sec)
8.319... logprob:  0.666091, 0.311198 (1.418 sec)
8.320... logprob:  0.574264, 0.253906 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.513685, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.938203e-03 [3.016232e-07] 
Layer 'conv1' biases: 1.211932e-06 [1.082985e-09] 
Layer 'conv2' weights[0]: 5.927758e-03 [2.987240e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.112670e-09] 
Layer 'conv3' weights[0]: 5.926619e-03 [2.996079e-07] 
Layer 'conv3' biases: 2.160309e-05 [2.596838e-08] 
Layer 'conv4' weights[0]: 5.950922e-03 [3.022270e-07] 
Layer 'conv4' biases: 1.000017e+00 [2.928924e-07] 
Layer 'conv5' weights[0]: 5.995249e-03 [2.125715e-06] 
Layer 'conv5' biases: 9.992023e-01 [2.229751e-06] 
Layer 'fc6' weights[0]: 7.362774e-03 [5.531661e-08] 
Layer 'fc6' biases: 9.999977e-01 [5.054465e-08] 
Layer 'fc7' weights[0]: 7.717288e-03 [1.206294e-07] 
Layer 'fc7' biases: 9.999108e-01 [1.268919e-07] 
Layer 'fc8' weights[0]: 4.159798e-03 [1.414443e-05] 
Layer 'fc8' biases: 7.502926e-03 [5.077031e-06] 
Train error last 800 batches: 0.657471
-------------------------------------------------------
Not saving because 0.513685 > 0.303240 (5.60: -6.35%)
======================================================= (2.386 sec)
8.321... logprob:  0.557745, 0.281250 (1.424 sec)
8.322... logprob:  0.644197, 0.287760 (1.416 sec)
8.323... logprob:  0.650945, 0.281250 (1.474 sec)
8.324... logprob:  0.694851, 0.303385 (1.426 sec)
8.325... logprob:  0.647567, 0.299479 (1.434 sec)
8.326... logprob:  0.615501, 0.279948 (1.458 sec)
8.327... logprob:  0.673592, 0.289062 (1.414 sec)
8.328... logprob:  0.711647, 0.281250 (1.419 sec)
8.329... logprob:  0.564502, 0.236979 (1.419 sec)
8.330... logprob:  0.642568, 0.281250 (1.418 sec)
8.331... logprob:  0.600832, 0.270833 (1.416 sec)
8.332... logprob:  0.628570, 0.255208 (1.450 sec)
8.333... logprob:  0.515124, 0.251302 (1.434 sec)
8.334... logprob:  0.795640, 0.364583 (1.439 sec)
8.335... logprob:  0.568283, 0.274740 (1.439 sec)
8.336... logprob:  0.720536, 0.300781 (1.448 sec)
8.337... logprob:  0.813465, 0.369792 (1.411 sec)
8.338... logprob:  0.679285, 0.324219 (1.411 sec)
8.339... logprob:  0.730974, 0.342448 (1.422 sec)
8.340... logprob:  0.633608, 0.282552 (1.417 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.488653, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.932274e-03 [2.992354e-07] 
Layer 'conv1' biases: 1.212881e-06 [1.281307e-09] 
Layer 'conv2' weights[0]: 5.921818e-03 [2.981293e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.183547e-09] 
Layer 'conv3' weights[0]: 5.920681e-03 [2.991205e-07] 
Layer 'conv3' biases: 2.168257e-05 [2.474859e-08] 
Layer 'conv4' weights[0]: 5.944918e-03 [3.021800e-07] 
Layer 'conv4' biases: 1.000017e+00 [3.034466e-07] 
Layer 'conv5' weights[0]: 5.989400e-03 [2.533010e-06] 
Layer 'conv5' biases: 9.992021e-01 [2.662826e-06] 
Layer 'fc6' weights[0]: 7.362031e-03 [6.213876e-08] 
Layer 'fc6' biases: 9.999976e-01 [6.118381e-08] 
Layer 'fc7' weights[0]: 7.716535e-03 [1.399050e-07] 
Layer 'fc7' biases: 9.999105e-01 [1.912677e-07] 
Layer 'fc8' weights[0]: 4.170297e-03 [1.943951e-05] 
Layer 'fc8' biases: 7.555964e-03 [3.672500e-05] 
Train error last 800 batches: 0.657129
-------------------------------------------------------
Not saving because 0.488653 > 0.303240 (5.60: -6.35%)
======================================================= (2.423 sec)
8.341... logprob:  0.811433, 0.359375 (1.426 sec)
8.342... logprob:  0.670367, 0.304687 (1.468 sec)
8.343... logprob:  0.642412, 0.274740 (1.436 sec)
8.344... logprob:  0.601542, 0.270833 (1.475 sec)
8.345... logprob:  0.685655, 0.299479 (1.431 sec)
8.346... logprob:  0.648498, 0.303385 (1.433 sec)
8.347... logprob:  0.660233, 0.315104 (1.477 sec)
8.348... logprob:  0.618089, 0.281250 (1.423 sec)
8.349... logprob:  0.724095, 0.311198 (1.429 sec)
8.350... logprob:  0.629631, 0.256510 (1.429 sec)
8.351... logprob:  0.673198, 0.257812 (1.422 sec)
8.352... logprob:  0.556834, 0.252604 (1.428 sec)
8.353... logprob:  0.755416, 0.325521 (1.483 sec)
8.354... logprob:  0.918625, 0.380208 (1.429 sec)
8.355... logprob:  0.636874, 0.268229 (1.442 sec)
8.356... logprob:  0.680860, 0.269531 (1.469 sec)
8.357... logprob:  0.573864, 0.263021 (1.425 sec)
8.358... logprob:  0.632181, 0.283854 (1.444 sec)
8.359... logprob:  0.694119, 0.325521 (1.433 sec)
8.360... logprob:  0.720493, 0.324219 (1.416 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.527587, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.926353e-03 [3.001188e-07] 
Layer 'conv1' biases: 1.216326e-06 [9.119192e-10] 
Layer 'conv2' weights[0]: 5.915930e-03 [2.978805e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.350270e-09] 
Layer 'conv3' weights[0]: 5.914823e-03 [2.990097e-07] 
Layer 'conv3' biases: 2.178010e-05 [2.522765e-08] 
Layer 'conv4' weights[0]: 5.938981e-03 [3.021897e-07] 
Layer 'conv4' biases: 1.000017e+00 [3.069212e-07] 
Layer 'conv5' weights[0]: 5.983573e-03 [2.232521e-06] 
Layer 'conv5' biases: 9.992069e-01 [2.309801e-06] 
Layer 'fc6' weights[0]: 7.361271e-03 [5.856794e-08] 
Layer 'fc6' biases: 9.999976e-01 [5.563738e-08] 
Layer 'fc7' weights[0]: 7.715798e-03 [1.283360e-07] 
Layer 'fc7' biases: 9.999093e-01 [1.444397e-07] 
Layer 'fc8' weights[0]: 4.124635e-03 [1.575233e-05] 
Layer 'fc8' biases: 7.278074e-03 [1.237795e-05] 
Train error last 800 batches: 0.657117
-------------------------------------------------------
Not saving because 0.527587 > 0.303240 (5.60: -6.35%)
======================================================= (2.369 sec)
8.361... logprob:  0.627682, 0.269531 (1.439 sec)
8.362... logprob:  0.586263, 0.266927 (1.478 sec)
8.363... logprob:  0.764355, 0.312500 (1.442 sec)
8.364... logprob:  0.617872, 0.277344 (1.444 sec)
8.365... logprob:  0.692929, 0.277344 (1.459 sec)
8.366... logprob:  0.611560, 0.294271 (1.440 sec)
8.367... logprob:  0.666292, 0.294271 (1.428 sec)
8.368... logprob:  0.799162, 0.360677 (1.427 sec)
8.369... logprob:  0.620681, 0.286458 (1.428 sec)
8.370... logprob:  0.578037, 0.252604 (1.435 sec)
8.371... logprob:  0.578095, 0.239583 (1.450 sec)
8.372... logprob:  0.677244, 0.290364 (1.454 sec)
8.373... logprob:  0.606504, 0.281250 (1.446 sec)
8.374... logprob:  0.696887, 0.332031 (1.443 sec)
8.375... logprob:  0.629942, 0.296875 (1.465 sec)
8.376... logprob:  0.601795, 0.246094 (1.436 sec)
8.377... logprob:  0.581044, 0.266927 (1.426 sec)
8.378... logprob:  0.693158, 0.302083 (1.421 sec)
8.379... logprob:  0.694152, 0.304688 (1.433 sec)
8.380... logprob:  0.741396, 0.308594 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.501198, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.920415e-03 [2.991619e-07] 
Layer 'conv1' biases: 1.221552e-06 [9.465323e-10] 
Layer 'conv2' weights[0]: 5.910021e-03 [2.982064e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.398910e-09] 
Layer 'conv3' weights[0]: 5.908893e-03 [2.995381e-07] 
Layer 'conv3' biases: 2.179694e-05 [2.970621e-08] 
Layer 'conv4' weights[0]: 5.933051e-03 [3.028512e-07] 
Layer 'conv4' biases: 1.000017e+00 [3.544759e-07] 
Layer 'conv5' weights[0]: 5.977653e-03 [2.528270e-06] 
Layer 'conv5' biases: 9.991957e-01 [2.669031e-06] 
Layer 'fc6' weights[0]: 7.360484e-03 [6.090535e-08] 
Layer 'fc6' biases: 9.999977e-01 [5.938024e-08] 
Layer 'fc7' weights[0]: 7.715010e-03 [1.389799e-07] 
Layer 'fc7' biases: 9.999103e-01 [1.838832e-07] 
Layer 'fc8' weights[0]: 4.180220e-03 [1.925803e-05] 
Layer 'fc8' biases: 7.697607e-03 [3.209844e-05] 
Train error last 800 batches: 0.657031
-------------------------------------------------------
Not saving because 0.501198 > 0.303240 (5.60: -6.35%)
======================================================= (2.370 sec)
8.381... logprob:  0.655747, 0.296875 (1.471 sec)
8.382... logprob:  0.752692, 0.294271 (1.448 sec)
8.383... logprob:  0.713657, 0.330729 (1.435 sec)
8.384... logprob:  0.743465, 0.329427 (1.485 sec)
8.385... logprob:  0.700105, 0.269531 (1.428 sec)
8.386... logprob:  0.813858, 0.332031 (1.425 sec)
8.387... logprob:  0.594594, 0.240885 (1.431 sec)
8.388... logprob:  0.666981, 0.259115 (1.425 sec)
8.389... logprob:  0.636823, 0.277344 (1.427 sec)
8.390... logprob:  0.568537, 0.210938 (1.476 sec)
8.391... logprob:  0.572720, 0.252604 (1.443 sec)
8.392... logprob:  0.673983, 0.308594 (1.430 sec)
8.393... logprob:  0.650716, 0.298177 (1.485 sec)
8.394... logprob:  0.574059, 0.223958 (1.427 sec)
8.395... logprob:  0.543737, 0.250000 (1.424 sec)
8.396... logprob:  0.549160, 0.244792 (1.432 sec)
8.397... logprob:  0.765303, 0.317708 (1.431 sec)
8.398... logprob:  0.679513, 0.311198 (1.427 sec)
8.399... logprob:  0.647249, 0.255208 (1.484 sec)
8.400... logprob:  0.735689, 0.341146 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.493314, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.914498e-03 [2.991864e-07] 
Layer 'conv1' biases: 1.225525e-06 [9.179785e-10] 
Layer 'conv2' weights[0]: 5.904114e-03 [2.975272e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.672694e-09] 
Layer 'conv3' weights[0]: 5.902975e-03 [2.987093e-07] 
Layer 'conv3' biases: 2.188091e-05 [2.633208e-08] 
Layer 'conv4' weights[0]: 5.927089e-03 [3.022766e-07] 
Layer 'conv4' biases: 1.000017e+00 [3.328186e-07] 
Layer 'conv5' weights[0]: 5.971947e-03 [2.286024e-06] 
Layer 'conv5' biases: 9.991987e-01 [2.394648e-06] 
Layer 'fc6' weights[0]: 7.359733e-03 [5.926592e-08] 
Layer 'fc6' biases: 9.999976e-01 [5.705140e-08] 
Layer 'fc7' weights[0]: 7.714184e-03 [1.339189e-07] 
Layer 'fc7' biases: 9.999092e-01 [1.613502e-07] 
Layer 'fc8' weights[0]: 4.155943e-03 [1.724491e-05] 
Layer 'fc8' biases: 7.490714e-03 [2.594050e-05] 
Train error last 800 batches: 0.657017
-------------------------------------------------------
Not saving because 0.493314 > 0.303240 (5.60: -6.35%)
======================================================= (2.368 sec)
8.401... logprob:  0.747818, 0.321615 (1.449 sec)
8.402... logprob:  0.602562, 0.295573 (1.487 sec)
8.403... logprob:  0.624254, 0.296875 (1.426 sec)
8.404... logprob:  0.677721, 0.281250 (1.429 sec)
8.405... logprob:  0.809949, 0.335937 (1.437 sec)
8.406... logprob:  0.570178, 0.273437 (1.420 sec)
8.407... logprob:  0.619363, 0.303385 (1.427 sec)
8.408... logprob:  0.574490, 0.248698 (1.473 sec)
8.409... logprob:  0.623894, 0.276042 (1.435 sec)
8.410... logprob:  0.696936, 0.320312 (1.440 sec)
8.411... logprob:  0.616566, 0.296875 (1.475 sec)
8.412... logprob:  0.833190, 0.348958 (1.429 sec)
8.413... logprob:  0.737087, 0.337240 (1.432 sec)
8.414... logprob:  0.738658, 0.330729 (1.425 sec)
8.415... logprob:  0.660544, 0.299479 (1.421 sec)
8.416... logprob:  0.607179, 0.272135 (1.438 sec)
8.417... logprob:  0.621148, 0.253906 (1.459 sec)
8.418... logprob:  0.563872, 0.247396 (1.452 sec)
8.419... logprob:  0.680671, 0.324219 (1.443 sec)
8.420... logprob:  0.615432, 0.261719 (1.453 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.408480, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.908587e-03 [2.991944e-07] 
Layer 'conv1' biases: 1.231566e-06 [9.628317e-10] 
Layer 'conv2' weights[0]: 5.898194e-03 [2.975501e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.989636e-09] 
Layer 'conv3' weights[0]: 5.897077e-03 [2.992190e-07] 
Layer 'conv3' biases: 2.201128e-05 [2.862626e-08] 
Layer 'conv4' weights[0]: 5.921210e-03 [3.028536e-07] 
Layer 'conv4' biases: 1.000017e+00 [3.404147e-07] 
Layer 'conv5' weights[0]: 5.965998e-03 [2.518419e-06] 
Layer 'conv5' biases: 9.991980e-01 [2.623895e-06] 
Layer 'fc6' weights[0]: 7.358948e-03 [6.225229e-08] 
Layer 'fc6' biases: 9.999977e-01 [6.189239e-08] 
Layer 'fc7' weights[0]: 7.713413e-03 [1.423888e-07] 
Layer 'fc7' biases: 9.999089e-01 [2.007474e-07] 
Layer 'fc8' weights[0]: 4.172655e-03 [2.128782e-05] 
Layer 'fc8' biases: 7.672319e-03 [3.174992e-05] 
Train error last 800 batches: 0.656384
-------------------------------------------------------
Not saving because 0.408480 > 0.303240 (5.60: -6.35%)
======================================================= (2.361 sec)
8.421... logprob:  0.677114, 0.302083 (1.456 sec)
8.422... logprob:  0.707179, 0.295573 (1.443 sec)
8.423... logprob:  0.597934, 0.260417 (1.422 sec)
8.424... logprob:  0.635788, 0.294271 (1.425 sec)
8.425... logprob:  0.561774, 0.251302 (1.430 sec)
8.426... logprob:  0.639906, 0.251302 (1.438 sec)
8.427... logprob:  0.800679, 0.346354 (1.461 sec)
8.428... logprob:  0.666244, 0.300781 (1.450 sec)
8.429... logprob:  0.529863, 0.259114 (1.442 sec)
8.430... logprob:  0.530876, 0.255208 (1.475 sec)
8.431... logprob:  0.754973, 0.320312 (1.424 sec)
8.432... logprob:  0.717002, 0.299479 (1.426 sec)
8.433... logprob:  0.580338, 0.246094 (1.429 sec)
8.434... logprob:  0.675270, 0.285156 (1.435 sec)
8.435... logprob:  0.695146, 0.309896 (1.428 sec)
8.436... logprob:  0.681980, 0.274740 (1.466 sec)
8.437... logprob:  0.736140, 0.316406 (1.438 sec)
8.438... logprob:  0.844242, 0.381510 (1.430 sec)
8.439... logprob:  0.699718, 0.303385 (1.482 sec)
8.440... logprob:  0.602151, 0.265625 (1.435 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.443899, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.902696e-03 [2.988858e-07] 
Layer 'conv1' biases: 1.235246e-06 [1.223346e-09] 
Layer 'conv2' weights[0]: 5.892313e-03 [2.974440e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.632531e-09] 
Layer 'conv3' weights[0]: 5.891219e-03 [3.000546e-07] 
Layer 'conv3' biases: 2.211767e-05 [3.455170e-08] 
Layer 'conv4' weights[0]: 5.915244e-03 [3.051576e-07] 
Layer 'conv4' biases: 1.000017e+00 [4.488224e-07] 
Layer 'conv5' weights[0]: 5.960602e-03 [3.302409e-06] 
Layer 'conv5' biases: 9.992012e-01 [3.570559e-06] 
Layer 'fc6' weights[0]: 7.358168e-03 [6.712111e-08] 
Layer 'fc6' biases: 9.999977e-01 [6.844251e-08] 
Layer 'fc7' weights[0]: 7.712643e-03 [1.579346e-07] 
Layer 'fc7' biases: 9.999083e-01 [2.389901e-07] 
Layer 'fc8' weights[0]: 4.160935e-03 [2.258761e-05] 
Layer 'fc8' biases: 7.576553e-03 [4.378436e-05] 
Train error last 800 batches: 0.656391
-------------------------------------------------------
Not saving because 0.443899 > 0.303240 (5.60: -6.35%)
======================================================= (2.351 sec)
8.441... logprob:  0.676730, 0.290365 (1.427 sec)
8.442... logprob:  0.679096, 0.317708 (1.430 sec)
8.443... logprob:  0.613167, 0.269531 (1.423 sec)
8.444... logprob:  0.604339, 0.277344 (1.427 sec)
8.445... logprob:  0.579014, 0.259115 (1.481 sec)
8.446... logprob:  0.606622, 0.246094 (1.434 sec)
8.447... logprob:  0.787622, 0.347656 (1.443 sec)
8.448... logprob:  0.610509, 0.289062 (1.478 sec)
8.449... logprob:  0.683973, 0.281250 (1.426 sec)
8.450... logprob:  0.537720, 0.247396 (1.422 sec)
8.451... logprob:  0.695938, 0.291667 (1.432 sec)
8.452... logprob:  0.671576, 0.289062 (1.423 sec)
8.453... logprob:  0.779840, 0.351562 (1.426 sec)
8.454... logprob:  0.733135, 0.292969 (1.477 sec)
8.455... logprob:  0.738588, 0.335937 (1.433 sec)
8.456... logprob:  0.649742, 0.279948 (1.438 sec)
8.457... logprob:  0.736913, 0.335937 (1.471 sec)
8.458... logprob:  0.552037, 0.265625 (1.426 sec)
8.459... logprob:  0.729159, 0.334635 (1.431 sec)
8.460... logprob:  0.489418, 0.212240 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.408126, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.896811e-03 [2.979289e-07] 
Layer 'conv1' biases: 1.237963e-06 [7.997242e-10] 
Layer 'conv2' weights[0]: 5.886437e-03 [2.961702e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.349279e-09] 
Layer 'conv3' weights[0]: 5.885336e-03 [2.972272e-07] 
Layer 'conv3' biases: 2.215714e-05 [2.387162e-08] 
Layer 'conv4' weights[0]: 5.909342e-03 [3.012519e-07] 
Layer 'conv4' biases: 1.000019e+00 [2.962387e-07] 
Layer 'conv5' weights[0]: 5.955198e-03 [2.437452e-06] 
Layer 'conv5' biases: 9.991979e-01 [2.482063e-06] 
Layer 'fc6' weights[0]: 7.357415e-03 [5.910300e-08] 
Layer 'fc6' biases: 9.999976e-01 [5.667954e-08] 
Layer 'fc7' weights[0]: 7.711882e-03 [1.309153e-07] 
Layer 'fc7' biases: 9.999077e-01 [1.649059e-07] 
Layer 'fc8' weights[0]: 4.167309e-03 [1.766545e-05] 
Layer 'fc8' biases: 7.570215e-03 [2.835708e-05] 
Train error last 800 batches: 0.656424
-------------------------------------------------------
Not saving because 0.408126 > 0.303240 (5.60: -6.35%)
======================================================= (2.409 sec)
8.461... logprob:  0.650570, 0.305989 (1.429 sec)
8.462... logprob:  0.728916, 0.307292 (1.441 sec)
8.463... logprob:  0.694151, 0.319010 (1.467 sec)
8.464... logprob:  0.733805, 0.305990 (1.440 sec)
8.465... logprob:  0.737830, 0.311198 (1.450 sec)
8.466... logprob:  0.579301, 0.263021 (1.452 sec)
8.467... logprob:  0.672912, 0.307292 (1.442 sec)
8.468... logprob:  0.680827, 0.272135 (1.438 sec)
8.469... logprob:  0.611583, 0.282552 (1.426 sec)
8.470... logprob:  0.641879, 0.300781 (1.418 sec)
8.471... logprob:  0.697693, 0.316406 (1.441 sec)
8.472... logprob:  0.615824, 0.255208 (1.445 sec)
8.473... logprob:  0.686755, 0.309896 (1.452 sec)
8.474... logprob:  0.681213, 0.281250 (1.451 sec)
8.475... logprob:  0.698355, 0.312500 (1.457 sec)
8.476... logprob:  0.668541, 0.302083 (1.457 sec)
8.477... logprob:  0.581565, 0.256510 (1.437 sec)
8.478... logprob:  0.677009, 0.321615 (1.424 sec)
8.479... logprob:  0.533521, 0.246094 (1.426 sec)
8.480... logprob:  0.680207, 0.329427 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.502688, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.890918e-03 [2.967188e-07] 
Layer 'conv1' biases: 1.238583e-06 [7.564900e-10] 
Layer 'conv2' weights[0]: 5.880533e-03 [2.958279e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.914814e-09] 
Layer 'conv3' weights[0]: 5.879426e-03 [2.964349e-07] 
Layer 'conv3' biases: 2.221772e-05 [2.130111e-08] 
Layer 'conv4' weights[0]: 5.903448e-03 [2.990786e-07] 
Layer 'conv4' biases: 1.000018e+00 [2.674683e-07] 
Layer 'conv5' weights[0]: 5.949329e-03 [2.137001e-06] 
Layer 'conv5' biases: 9.991936e-01 [2.277501e-06] 
Layer 'fc6' weights[0]: 7.356656e-03 [5.647354e-08] 
Layer 'fc6' biases: 9.999977e-01 [5.271224e-08] 
Layer 'fc7' weights[0]: 7.711094e-03 [1.226519e-07] 
Layer 'fc7' biases: 9.999078e-01 [1.390097e-07] 
Layer 'fc8' weights[0]: 4.166041e-03 [1.524205e-05] 
Layer 'fc8' biases: 7.583306e-03 [1.425361e-05] 
Train error last 800 batches: 0.656848
-------------------------------------------------------
Not saving because 0.502688 > 0.303240 (5.60: -6.35%)
======================================================= (2.371 sec)
8.481... logprob:  0.818301, 0.343750 (1.438 sec)
8.482... logprob:  0.648705, 0.283854 (1.473 sec)
8.483... logprob:  0.674558, 0.276042 (1.446 sec)
8.484... logprob:  0.693123, 0.313802 (1.441 sec)
8.485... logprob:  0.669279, 0.286458 (1.475 sec)
8.486... logprob:  0.576666, 0.260417 (1.425 sec)
8.487... logprob:  0.703861, 0.342448 (1.424 sec)
8.488... logprob:  0.635528, 0.274740 (1.427 sec)
8.489... logprob:  0.599368, 0.268229 (1.429 sec)
8.490... logprob:  0.611564, 0.295573 (1.426 sec)
8.491... logprob:  0.533133, 0.256510 (1.479 sec)
8.492... logprob:  0.636877, 0.270833 (1.441 sec)
8.493... logprob:  0.810746, 0.359375 (1.427 sec)
8.494... logprob:  0.609438, 0.265625 (1.481 sec)
8.495... logprob:  0.622407, 0.266927 (1.434 sec)
8.496... logprob:  0.754317, 0.286458 (1.427 sec)
8.497... logprob:  0.672486, 0.294271 (1.435 sec)
8.498... logprob:  0.694176, 0.289062 (1.421 sec)
8.499... logprob:  0.765069, 0.333333 (1.428 sec)
8.500... logprob:  0.669901, 0.286458 (1.482 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.473347, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.885024e-03 [2.970382e-07] 
Layer 'conv1' biases: 1.239928e-06 [1.238072e-09] 
Layer 'conv2' weights[0]: 5.874666e-03 [2.959834e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.159439e-09] 
Layer 'conv3' weights[0]: 5.873554e-03 [2.975838e-07] 
Layer 'conv3' biases: 2.221204e-05 [2.922158e-08] 
Layer 'conv4' weights[0]: 5.897528e-03 [3.019167e-07] 
Layer 'conv4' biases: 1.000020e+00 [3.809855e-07] 
Layer 'conv5' weights[0]: 5.944094e-03 [2.837908e-06] 
Layer 'conv5' biases: 9.991919e-01 [3.043040e-06] 
Layer 'fc6' weights[0]: 7.355905e-03 [6.492277e-08] 
Layer 'fc6' biases: 9.999976e-01 [6.547558e-08] 
Layer 'fc7' weights[0]: 7.710360e-03 [1.497623e-07] 
Layer 'fc7' biases: 9.999082e-01 [2.060886e-07] 
Layer 'fc8' weights[0]: 4.174902e-03 [1.985290e-05] 
Layer 'fc8' biases: 7.537792e-03 [3.218877e-05] 
Train error last 800 batches: 0.657114
-------------------------------------------------------
Not saving because 0.473347 > 0.303240 (5.60: -6.35%)
======================================================= (2.370 sec)
8.501... logprob:  0.576388, 0.251302 (1.432 sec)
8.502... logprob:  0.664024, 0.246094 (1.442 sec)
8.503... logprob:  0.673047, 0.295573 (1.473 sec)
8.504... logprob:  0.683318, 0.292969 (1.424 sec)
8.505... logprob:  0.744597, 0.298177 (1.434 sec)
8.506... logprob:  0.693912, 0.321615 (1.435 sec)
8.507... logprob:  0.564437, 0.226562 (1.419 sec)
8.508... logprob:  0.671126, 0.295573 (1.428 sec)
8.509... logprob:  0.583758, 0.251302 (1.478 sec)
8.510... logprob:  0.590800, 0.281250 (1.434 sec)
8.511... logprob:  0.718625, 0.298177 (1.446 sec)
8.512... logprob:  0.641753, 0.287760 (1.458 sec)
8.513... logprob:  0.580221, 0.256510 (1.439 sec)
8.514... logprob:  0.642186, 0.278646 (1.433 sec)
8.515... logprob:  0.698337, 0.315104 (1.431 sec)
8.516... logprob:  0.608927, 0.276042 (1.418 sec)
8.517... logprob:  0.702008, 0.290364 (1.434 sec)
8.518... logprob:  0.682868, 0.244792 (1.455 sec)
8.519... logprob:  0.775207, 0.342448 (1.452 sec)
8.520... logprob:  0.667876, 0.286458 (1.448 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.549536, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.879147e-03 [2.968061e-07] 
Layer 'conv1' biases: 1.239594e-06 [8.485171e-10] 
Layer 'conv2' weights[0]: 5.868788e-03 [2.960476e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.179290e-09] 
Layer 'conv3' weights[0]: 5.867647e-03 [2.975571e-07] 
Layer 'conv3' biases: 2.226470e-05 [2.890778e-08] 
Layer 'conv4' weights[0]: 5.891632e-03 [3.004538e-07] 
Layer 'conv4' biases: 1.000020e+00 [3.398045e-07] 
Layer 'conv5' weights[0]: 5.938698e-03 [2.702693e-06] 
Layer 'conv5' biases: 9.991924e-01 [2.931678e-06] 
Layer 'fc6' weights[0]: 7.355140e-03 [6.081883e-08] 
Layer 'fc6' biases: 9.999975e-01 [5.952421e-08] 
Layer 'fc7' weights[0]: 7.709555e-03 [1.364952e-07] 
Layer 'fc7' biases: 9.999078e-01 [1.640341e-07] 
Layer 'fc8' weights[0]: 4.169021e-03 [1.719598e-05] 
Layer 'fc8' biases: 7.598047e-03 [2.351299e-05] 
Train error last 800 batches: 0.657261
-------------------------------------------------------
Not saving because 0.549536 > 0.303240 (5.60: -6.35%)
======================================================= (2.405 sec)
8.521... logprob:  0.629812, 0.253906 (1.466 sec)
8.522... logprob:  0.776076, 0.325521 (1.465 sec)
8.523... logprob:  0.559171, 0.250000 (1.434 sec)
8.524... logprob:  0.696715, 0.308594 (1.421 sec)
8.525... logprob:  0.702141, 0.326823 (1.424 sec)
8.526... logprob:  0.641796, 0.266927 (1.428 sec)
8.527... logprob:  0.795788, 0.356771 (1.435 sec)
8.528... logprob:  0.684086, 0.286458 (1.464 sec)
8.529... logprob:  0.702591, 0.326823 (1.443 sec)
8.530... logprob:  0.663084, 0.256510 (1.433 sec)
8.531... logprob:  0.736859, 0.347656 (1.472 sec)
8.532... logprob:  0.658023, 0.313802 (1.430 sec)
8.533... logprob:  0.704950, 0.319010 (1.418 sec)
8.534... logprob:  0.551270, 0.240885 (1.428 sec)
8.535... logprob:  0.681088, 0.307292 (1.430 sec)
8.536... logprob:  0.689004, 0.259115 (1.425 sec)
8.537... logprob:  0.781145, 0.354167 (1.483 sec)
8.538... logprob:  0.691087, 0.256510 (1.432 sec)
8.539... logprob:  0.577800, 0.236979 (1.432 sec)
8.540... logprob:  0.667687, 0.287760 (1.475 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.438453, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.873279e-03 [2.965262e-07] 
Layer 'conv1' biases: 1.243889e-06 [7.593149e-10] 
Layer 'conv2' weights[0]: 5.862906e-03 [2.956302e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.318438e-09] 
Layer 'conv3' weights[0]: 5.861809e-03 [2.969459e-07] 
Layer 'conv3' biases: 2.226123e-05 [2.847433e-08] 
Layer 'conv4' weights[0]: 5.885794e-03 [2.996199e-07] 
Layer 'conv4' biases: 1.000020e+00 [3.051773e-07] 
Layer 'conv5' weights[0]: 5.933001e-03 [2.422178e-06] 
Layer 'conv5' biases: 9.991951e-01 [2.682573e-06] 
Layer 'fc6' weights[0]: 7.354386e-03 [5.889430e-08] 
Layer 'fc6' biases: 9.999976e-01 [5.609014e-08] 
Layer 'fc7' weights[0]: 7.708806e-03 [1.310872e-07] 
Layer 'fc7' biases: 9.999065e-01 [1.449099e-07] 
Layer 'fc8' weights[0]: 4.142649e-03 [1.566797e-05] 
Layer 'fc8' biases: 7.393890e-03 [7.249870e-06] 
Train error last 800 batches: 0.658016
-------------------------------------------------------
Not saving because 0.438453 > 0.303240 (5.60: -6.35%)
======================================================= (2.381 sec)
8.541... logprob:  0.605860, 0.274740 (1.431 sec)
8.542... logprob:  0.642716, 0.259115 (1.427 sec)
8.543... logprob:  0.542442, 0.236979 (1.437 sec)
8.544... logprob:  0.587775, 0.259114 (1.481 sec)
8.545... logprob:  0.610123, 0.277344 (1.430 sec)
8.546... logprob:  0.646295, 0.296875 (1.484 sec)
8.547... logprob:  0.664457, 0.282552 (1.427 sec)
8.548... logprob:  0.754294, 0.305989 (1.438 sec)
8.549... logprob:  0.650556, 0.274740 (1.469 sec)
8.550... logprob:  0.525854, 0.225260 (1.429 sec)
8.551... logprob:  0.666352, 0.276042 (1.430 sec)
8.552... logprob:  0.687028, 0.283854 (1.428 sec)
8.553... logprob:  0.582483, 0.243490 (1.419 sec)
8.554... logprob:  0.691962, 0.319010 (1.429 sec)
8.555... logprob:  0.638876, 0.282552 (1.480 sec)
8.556... logprob:  0.644334, 0.253906 (1.436 sec)
8.557... logprob:  0.690109, 0.298177 (1.444 sec)
8.558... logprob:  0.692457, 0.315104 (1.463 sec)
8.559... logprob:  0.680271, 0.295573 (1.433 sec)
8.560... logprob:  0.689992, 0.319010 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.369206, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.867427e-03 [2.972614e-07] 
Layer 'conv1' biases: 1.244173e-06 [9.584928e-10] 
Layer 'conv2' weights[0]: 5.857060e-03 [2.954848e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.845443e-09] 
Layer 'conv3' weights[0]: 5.855919e-03 [2.966751e-07] 
Layer 'conv3' biases: 2.219412e-05 [2.799786e-08] 
Layer 'conv4' weights[0]: 5.879856e-03 [2.993405e-07] 
Layer 'conv4' biases: 1.000019e+00 [3.257951e-07] 
Layer 'conv5' weights[0]: 5.927003e-03 [2.859412e-06] 
Layer 'conv5' biases: 9.991858e-01 [3.000016e-06] 
Layer 'fc6' weights[0]: 7.353601e-03 [6.090904e-08] 
Layer 'fc6' biases: 9.999976e-01 [5.974470e-08] 
Layer 'fc7' weights[0]: 7.708021e-03 [1.355877e-07] 
Layer 'fc7' biases: 9.999072e-01 [1.704985e-07] 
Layer 'fc8' weights[0]: 4.191236e-03 [1.772395e-05] 
Layer 'fc8' biases: 7.692297e-03 [2.994117e-05] 
Train error last 800 batches: 0.658390
-------------------------------------------------------
Not saving because 0.369206 > 0.303240 (5.60: -6.35%)
======================================================= (2.378 sec)
8.561... logprob:  0.603681, 0.266927 (1.439 sec)
8.562... logprob:  0.681565, 0.308594 (1.422 sec)
8.563... logprob:  0.559901, 0.263021 (1.438 sec)
8.564... logprob:  0.799040, 0.347656 (1.459 sec)
8.565... logprob:  0.819118, 0.350260 (1.444 sec)
8.566... logprob:  0.651277, 0.298177 (1.446 sec)
8.567... logprob:  0.658547, 0.287760 (1.453 sec)
8.568... logprob:  0.661937, 0.292969 (1.448 sec)
8.569... logprob:  0.668433, 0.290365 (1.430 sec)
8.570... logprob:  0.659052, 0.278646 (1.417 sec)
8.571... logprob:  0.754854, 0.330729 (1.428 sec)
8.572... logprob:  0.686259, 0.316406 (1.440 sec)
8.573... logprob:  0.652446, 0.296875 (1.445 sec)
8.574... logprob:  0.576135, 0.248698 (1.458 sec)
8.575... logprob:  0.579577, 0.261719 (1.447 sec)
8.576... logprob:  0.625971, 0.248698 (1.443 sec)
8.577... logprob:  0.769176, 0.337240 (1.469 sec)
8.578... logprob:  0.577616, 0.253906 (1.426 sec)
8.579... logprob:  0.648625, 0.291667 (1.422 sec)
8.580... logprob:  0.743276, 0.317708 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.509515, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.861561e-03 [2.956240e-07] 
Layer 'conv1' biases: 1.244309e-06 [8.293752e-10] 
Layer 'conv2' weights[0]: 5.851218e-03 [2.952122e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.119210e-09] 
Layer 'conv3' weights[0]: 5.850083e-03 [2.966396e-07] 
Layer 'conv3' biases: 2.221633e-05 [2.810986e-08] 
Layer 'conv4' weights[0]: 5.874006e-03 [3.019834e-07] 
Layer 'conv4' biases: 1.000018e+00 [4.104937e-07] 
Layer 'conv5' weights[0]: 5.921314e-03 [2.850907e-06] 
Layer 'conv5' biases: 9.991875e-01 [3.008971e-06] 
Layer 'fc6' weights[0]: 7.352824e-03 [6.144691e-08] 
Layer 'fc6' biases: 9.999976e-01 [6.058405e-08] 
Layer 'fc7' weights[0]: 7.707237e-03 [1.389742e-07] 
Layer 'fc7' biases: 9.999068e-01 [1.797306e-07] 
Layer 'fc8' weights[0]: 4.172793e-03 [1.904749e-05] 
Layer 'fc8' biases: 7.566534e-03 [2.797908e-05] 
Train error last 800 batches: 0.658184
-------------------------------------------------------
Not saving because 0.509515 > 0.303240 (5.60: -6.35%)
======================================================= (2.364 sec)
8.581... logprob:  0.689887, 0.291667 (1.439 sec)
8.582... logprob:  0.693720, 0.315104 (1.433 sec)
8.583... logprob:  0.720697, 0.292969 (1.477 sec)
8.584... logprob:  0.709055, 0.292969 (1.436 sec)
8.585... logprob:  0.613437, 0.259115 (1.430 sec)
8.586... logprob:  0.560108, 0.227865 (1.479 sec)
8.587... logprob:  0.662370, 0.283854 (1.428 sec)
8.588... logprob:  0.622563, 0.256510 (1.420 sec)
8.589... logprob:  0.660461, 0.286458 (1.431 sec)
8.590... logprob:  0.671832, 0.325521 (1.427 sec)
8.591... logprob:  0.607844, 0.264323 (1.428 sec)
8.592... logprob:  0.634387, 0.281250 (1.473 sec)
8.593... logprob:  0.654375, 0.308594 (1.429 sec)
8.594... logprob:  0.606569, 0.302083 (1.436 sec)
8.595... logprob:  0.675793, 0.285156 (1.473 sec)
8.596... logprob:  0.724624, 0.292969 (1.428 sec)
8.597... logprob:  0.642647, 0.287760 (1.424 sec)
8.598... logprob:  0.600962, 0.272135 (1.433 sec)
8.599... logprob:  0.579185, 0.287760 (1.420 sec)
8.600... logprob:  0.602593, 0.256510 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.467714, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.855695e-03 [2.966301e-07] 
Layer 'conv1' biases: 1.247993e-06 [8.480015e-10] 
Layer 'conv2' weights[0]: 5.845347e-03 [2.943209e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.683063e-09] 
Layer 'conv3' weights[0]: 5.844192e-03 [2.959988e-07] 
Layer 'conv3' biases: 2.223437e-05 [2.770868e-08] 
Layer 'conv4' weights[0]: 5.868153e-03 [2.996628e-07] 
Layer 'conv4' biases: 1.000017e+00 [3.488124e-07] 
Layer 'conv5' weights[0]: 5.915196e-03 [2.714057e-06] 
Layer 'conv5' biases: 9.991841e-01 [2.943724e-06] 
Layer 'fc6' weights[0]: 7.352072e-03 [6.380278e-08] 
Layer 'fc6' biases: 9.999974e-01 [6.416580e-08] 
Layer 'fc7' weights[0]: 7.706441e-03 [1.474548e-07] 
Layer 'fc7' biases: 9.999070e-01 [2.201237e-07] 
Layer 'fc8' weights[0]: 4.207948e-03 [2.050151e-05] 
Layer 'fc8' biases: 7.863487e-03 [3.858395e-05] 
Train error last 800 batches: 0.658464
-------------------------------------------------------
Not saving because 0.467714 > 0.303240 (5.60: -6.35%)
======================================================= (2.357 sec)
8.601... logprob:  0.670202, 0.285156 (1.491 sec)
8.602... logprob:  0.533024, 0.252604 (1.432 sec)
8.603... logprob:  0.538644, 0.268229 (1.440 sec)
8.604... logprob:  0.655874, 0.272135 (1.471 sec)
8.605... logprob:  0.712684, 0.292969 (1.426 sec)
8.606... logprob:  0.535303, 0.259114 (1.430 sec)
8.607... logprob:  0.759685, 0.330729 (1.429 sec)
8.608... logprob:  0.637858, 0.305990 (1.416 sec)
8.609... logprob:  0.534811, 0.242188 (1.431 sec)
8.610... logprob:  0.635334, 0.286458 (1.467 sec)
8.611... logprob:  0.616849, 0.261719 (1.437 sec)
8.612... logprob:  0.624876, 0.276042 (1.450 sec)
8.613... logprob:  0.552727, 0.296875 (1.449 sec)
8.614... logprob:  0.774384, 0.313802 (1.479 sec)
8.615... logprob:  0.590413, 0.273438 (1.431 sec)
8.616... logprob:  0.658797, 0.291667 (1.422 sec)
8.617... logprob:  0.604654, 0.274740 (1.419 sec)
8.618... logprob:  0.612575, 0.263021 (1.434 sec)
8.619... logprob:  0.778927, 0.333333 (1.448 sec)
8.620... logprob:  0.702473, 0.324219 (1.449 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.404450, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.849830e-03 [2.970039e-07] 
Layer 'conv1' biases: 1.251222e-06 [1.214486e-09] 
Layer 'conv2' weights[0]: 5.839532e-03 [2.950177e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.114459e-09] 
Layer 'conv3' weights[0]: 5.838422e-03 [2.980875e-07] 
Layer 'conv3' biases: 2.224205e-05 [3.659586e-08] 
Layer 'conv4' weights[0]: 5.862264e-03 [3.029426e-07] 
Layer 'conv4' biases: 1.000017e+00 [4.802452e-07] 
Layer 'conv5' weights[0]: 5.909470e-03 [3.316632e-06] 
Layer 'conv5' biases: 9.991848e-01 [3.465173e-06] 
Layer 'fc6' weights[0]: 7.351315e-03 [6.861001e-08] 
Layer 'fc6' biases: 9.999974e-01 [7.114226e-08] 
Layer 'fc7' weights[0]: 7.705659e-03 [1.612829e-07] 
Layer 'fc7' biases: 9.999072e-01 [2.589168e-07] 
Layer 'fc8' weights[0]: 4.230125e-03 [2.269921e-05] 
Layer 'fc8' biases: 8.078092e-03 [3.933031e-05] 
Train error last 800 batches: 0.658327
-------------------------------------------------------
Not saving because 0.404450 > 0.303240 (5.60: -6.35%)
======================================================= (2.362 sec)
8.621... logprob:  0.602328, 0.230469 (1.457 sec)
8.622... logprob:  0.645448, 0.298177 (1.445 sec)
8.623... logprob:  0.601817, 0.247396 (1.463 sec)
8.624... logprob:  0.593517, 0.265625 (1.428 sec)
8.625... logprob:  0.589066, 0.274740 (1.423 sec)
8.626... logprob:  0.687047, 0.268229 (1.427 sec)
8.627... logprob:  0.697478, 0.278646 (1.434 sec)
8.628... logprob:  0.632237, 0.287760 (1.429 sec)
8.629... logprob:  0.545107, 0.229167 (1.475 sec)
8.630... logprob:  0.642141, 0.299479 (1.444 sec)
8.631... logprob:  0.779026, 0.332031 (1.427 sec)
8.632... logprob:  0.607283, 0.274740 (1.480 sec)
8.633... logprob:  0.556666, 0.253906 (1.426 sec)
8.634... logprob:  0.873204, 0.384115 (1.421 sec)
8.635... logprob:  0.588304, 0.255208 (1.428 sec)
8.636... logprob:  0.676492, 0.291667 (1.430 sec)
8.637... logprob:  0.611139, 0.270833 (1.424 sec)
8.638... logprob:  0.692700, 0.305990 (1.477 sec)
8.639... logprob:  0.752259, 0.338542 (1.441 sec)
8.640... logprob:  0.740691, 0.337240 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.448573, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.844032e-03 [2.949433e-07] 
Layer 'conv1' biases: 1.254180e-06 [6.208950e-10] 
Layer 'conv2' weights[0]: 5.833730e-03 [2.940520e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.182436e-09] 
Layer 'conv3' weights[0]: 5.832622e-03 [2.946638e-07] 
Layer 'conv3' biases: 2.222652e-05 [2.405318e-08] 
Layer 'conv4' weights[0]: 5.856442e-03 [2.974788e-07] 
Layer 'conv4' biases: 1.000015e+00 [3.015526e-07] 
Layer 'conv5' weights[0]: 5.903489e-03 [2.359946e-06] 
Layer 'conv5' biases: 9.991996e-01 [2.541810e-06] 
Layer 'fc6' weights[0]: 7.350533e-03 [5.904520e-08] 
Layer 'fc6' biases: 9.999973e-01 [5.645706e-08] 
Layer 'fc7' weights[0]: 7.704879e-03 [1.346721e-07] 
Layer 'fc7' biases: 9.999057e-01 [1.645715e-07] 
Layer 'fc8' weights[0]: 4.165063e-03 [1.639852e-05] 
Layer 'fc8' biases: 7.630690e-03 [1.844875e-05] 
Train error last 800 batches: 0.658551
-------------------------------------------------------
Not saving because 0.448573 > 0.303240 (5.60: -6.35%)
======================================================= (2.408 sec)
8.641... logprob:  0.734664, 0.317708 (1.480 sec)
8.642... logprob:  0.671749, 0.290365 (1.437 sec)
8.643... logprob:  0.735020, 0.299479 (1.429 sec)
8.644... logprob:  0.562205, 0.257812 (1.433 sec)
8.645... logprob:  0.631628, 0.305989 (1.423 sec)
8.646... logprob:  0.643558, 0.273437 (1.425 sec)
8.647... logprob:  0.712781, 0.325521 (1.482 sec)
8.648... logprob:  0.688587, 0.276042 (1.427 sec)
8.649... logprob:  0.657965, 0.298177 (1.437 sec)
8.650... logprob:  0.622267, 0.277344 (1.469 sec)
8.651... logprob:  0.653662, 0.296875 (1.429 sec)
8.652... logprob:  0.651932, 0.264323 (1.469 sec)
8.653... logprob:  0.834338, 0.363281 (1.424 sec)
8.654... logprob:  0.677223, 0.302083 (1.426 sec)
8.655... logprob:  0.693245, 0.282552 (1.425 sec)
8.656... logprob:  0.668568, 0.273438 (1.471 sec)
8.657... logprob:  0.734061, 0.312500 (1.438 sec)
8.658... logprob:  0.551659, 0.246094 (1.450 sec)
8.659... logprob:  0.649036, 0.268229 (1.470 sec)
8.660... logprob:  0.713133, 0.321615 (1.437 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.391539, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.838167e-03 [2.955203e-07] 
Layer 'conv1' biases: 1.255650e-06 [9.377878e-10] 
Layer 'conv2' weights[0]: 5.827863e-03 [2.939465e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.271485e-09] 
Layer 'conv3' weights[0]: 5.826730e-03 [2.954014e-07] 
Layer 'conv3' biases: 2.226279e-05 [2.841817e-08] 
Layer 'conv4' weights[0]: 5.850578e-03 [2.989439e-07] 
Layer 'conv4' biases: 1.000014e+00 [3.646346e-07] 
Layer 'conv5' weights[0]: 5.897250e-03 [2.431179e-06] 
Layer 'conv5' biases: 9.992030e-01 [2.559862e-06] 
Layer 'fc6' weights[0]: 7.349769e-03 [5.985704e-08] 
Layer 'fc6' biases: 9.999974e-01 [5.772742e-08] 
Layer 'fc7' weights[0]: 7.704137e-03 [1.322124e-07] 
Layer 'fc7' biases: 9.999053e-01 [1.522442e-07] 
Layer 'fc8' weights[0]: 4.163690e-03 [1.600466e-05] 
Layer 'fc8' biases: 7.550169e-03 [1.186516e-05] 
Train error last 800 batches: 0.658577
-------------------------------------------------------
Not saving because 0.391539 > 0.303240 (5.60: -6.35%)
======================================================= (2.384 sec)
8.661... logprob:  0.622126, 0.263021 (1.442 sec)
8.662... logprob:  0.710168, 0.324219 (1.428 sec)
8.663... logprob:  0.606695, 0.255208 (1.420 sec)
8.664... logprob:  0.554932, 0.265625 (1.429 sec)
8.665... logprob:  0.606375, 0.274740 (1.458 sec)
8.666... logprob:  0.743577, 0.326823 (1.453 sec)
8.667... logprob:  0.731216, 0.304688 (1.443 sec)
8.668... logprob:  0.697544, 0.296875 (1.452 sec)
8.669... logprob:  0.594394, 0.302083 (1.461 sec)
8.670... logprob:  0.566505, 0.257812 (1.430 sec)
8.671... logprob:  0.621134, 0.292969 (1.422 sec)
8.672... logprob:  0.662650, 0.287760 (1.427 sec)
8.673... logprob:  0.611204, 0.252604 (1.435 sec)
8.674... logprob:  0.593246, 0.264323 (1.433 sec)
8.675... logprob:  0.594436, 0.279948 (1.460 sec)
8.676... logprob:  0.770022, 0.342448 (1.447 sec)
8.677... logprob:  0.630107, 0.253906 (1.444 sec)
8.678... logprob:  0.713387, 0.329427 (1.471 sec)
8.679... logprob:  0.672396, 0.272135 (1.429 sec)
8.680... logprob:  0.590858, 0.252604 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.552274, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.832341e-03 [2.965628e-07] 
Layer 'conv1' biases: 1.252124e-06 [7.982965e-10] 
Layer 'conv2' weights[0]: 5.822041e-03 [2.935545e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.662546e-09] 
Layer 'conv3' weights[0]: 5.820889e-03 [2.951594e-07] 
Layer 'conv3' biases: 2.225641e-05 [2.796927e-08] 
Layer 'conv4' weights[0]: 5.844712e-03 [2.979074e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.423132e-07] 
Layer 'conv5' weights[0]: 5.891199e-03 [2.424294e-06] 
Layer 'conv5' biases: 9.992023e-01 [2.550208e-06] 
Layer 'fc6' weights[0]: 7.348998e-03 [5.977550e-08] 
Layer 'fc6' biases: 9.999973e-01 [5.745308e-08] 
Layer 'fc7' weights[0]: 7.703361e-03 [1.317315e-07] 
Layer 'fc7' biases: 9.999056e-01 [1.588626e-07] 
Layer 'fc8' weights[0]: 4.204197e-03 [1.699316e-05] 
Layer 'fc8' biases: 7.871359e-03 [2.299874e-05] 
Train error last 800 batches: 0.658218
-------------------------------------------------------
Not saving because 0.552274 > 0.303240 (5.60: -6.35%)
======================================================= (2.381 sec)
8.681... logprob:  0.668835, 0.290365 (1.440 sec)
8.682... logprob:  0.562521, 0.253906 (1.439 sec)
8.683... logprob:  0.692395, 0.317708 (1.432 sec)
8.684... logprob:  0.634778, 0.312500 (1.470 sec)
8.685... logprob:  0.488833, 0.238281 (1.440 sec)
8.686... logprob:  0.581407, 0.235677 (1.431 sec)
8.687... logprob:  0.561646, 0.226562 (1.479 sec)
8.688... logprob:  0.543106, 0.244792 (1.426 sec)
8.689... logprob:  0.653049, 0.273437 (1.424 sec)
8.690... logprob:  0.761855, 0.335938 (1.467 sec)
8.691... logprob:  0.795671, 0.325521 (1.431 sec)
8.692... logprob:  0.614014, 0.273437 (1.425 sec)
8.693... logprob:  0.682220, 0.300781 (1.480 sec)
8.694... logprob:  0.504620, 0.210938 (1.428 sec)
8.695... logprob:  0.669194, 0.260417 (1.434 sec)
8.696... logprob:  0.770839, 0.330729 (1.473 sec)
8.697... logprob:  0.733519, 0.334635 (1.429 sec)
8.698... logprob:  0.701577, 0.296875 (1.428 sec)
8.699... logprob:  0.647224, 0.268229 (1.429 sec)
8.700... logprob:  0.603824, 0.279948 (1.417 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.452006, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.826507e-03 [2.940644e-07] 
Layer 'conv1' biases: 1.253268e-06 [9.950680e-10] 
Layer 'conv2' weights[0]: 5.816247e-03 [2.930078e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.976961e-09] 
Layer 'conv3' weights[0]: 5.815054e-03 [2.943290e-07] 
Layer 'conv3' biases: 2.226434e-05 [2.933061e-08] 
Layer 'conv4' weights[0]: 5.838891e-03 [2.979033e-07] 
Layer 'conv4' biases: 1.000011e+00 [3.754769e-07] 
Layer 'conv5' weights[0]: 5.884778e-03 [2.715362e-06] 
Layer 'conv5' biases: 9.992068e-01 [2.906804e-06] 
Layer 'fc6' weights[0]: 7.348254e-03 [6.599788e-08] 
Layer 'fc6' biases: 9.999973e-01 [6.670415e-08] 
Layer 'fc7' weights[0]: 7.702542e-03 [1.484127e-07] 
Layer 'fc7' biases: 9.999054e-01 [2.122250e-07] 
Layer 'fc8' weights[0]: 4.202879e-03 [1.932498e-05] 
Layer 'fc8' biases: 7.884100e-03 [3.156535e-05] 
Train error last 800 batches: 0.658266
-------------------------------------------------------
Not saving because 0.452006 > 0.303240 (5.60: -6.35%)
======================================================= (2.393 sec)
8.701... logprob:  0.664437, 0.260417 (1.434 sec)
8.702... logprob:  0.697177, 0.333333 (1.480 sec)
8.703... logprob:  0.548299, 0.259114 (1.441 sec)
8.704... logprob:  0.622156, 0.269531 (1.451 sec)
8.705... logprob:  0.577908, 0.253906 (1.471 sec)
8.706... logprob:  0.677118, 0.294271 (1.431 sec)
8.707... logprob:  0.661527, 0.272135 (1.430 sec)
8.708... logprob:  0.648823, 0.302083 (1.428 sec)
8.709... logprob:  0.604722, 0.300781 (1.422 sec)
8.710... logprob:  0.755615, 0.309896 (1.436 sec)
8.711... logprob:  0.599750, 0.261719 (1.467 sec)
8.712... logprob:  0.608982, 0.246094 (1.442 sec)
8.713... logprob:  0.755638, 0.300781 (1.445 sec)
8.714... logprob:  0.689722, 0.324219 (1.453 sec)
8.715... logprob:  0.655232, 0.279948 (1.441 sec)
8.716... logprob:  0.603634, 0.273437 (1.440 sec)
8.717... logprob:  0.614762, 0.279948 (1.428 sec)
8.718... logprob:  0.653169, 0.289062 (1.428 sec)
8.719... logprob:  0.634646, 0.282552 (1.433 sec)
8.720... logprob:  0.586493, 0.244792 (1.442 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.398593, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.820708e-03 [2.951537e-07] 
Layer 'conv1' biases: 1.261427e-06 [9.045797e-10] 
Layer 'conv2' weights[0]: 5.810446e-03 [2.927270e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.844038e-09] 
Layer 'conv3' weights[0]: 5.809267e-03 [2.938456e-07] 
Layer 'conv3' biases: 2.230835e-05 [2.607935e-08] 
Layer 'conv4' weights[0]: 5.833018e-03 [2.966448e-07] 
Layer 'conv4' biases: 1.000011e+00 [3.182695e-07] 
Layer 'conv5' weights[0]: 5.879095e-03 [2.328375e-06] 
Layer 'conv5' biases: 9.992110e-01 [2.353072e-06] 
Layer 'fc6' weights[0]: 7.347494e-03 [5.825436e-08] 
Layer 'fc6' biases: 9.999973e-01 [5.481376e-08] 
Layer 'fc7' weights[0]: 7.701738e-03 [1.275689e-07] 
Layer 'fc7' biases: 9.999044e-01 [1.461328e-07] 
Layer 'fc8' weights[0]: 4.174203e-03 [1.561904e-05] 
Layer 'fc8' biases: 7.665606e-03 [1.564283e-05] 
Train error last 800 batches: 0.657606
-------------------------------------------------------
Not saving because 0.398593 > 0.303240 (5.60: -6.35%)
======================================================= (2.373 sec)
8.721... logprob:  0.663372, 0.265625 (1.472 sec)
8.722... logprob:  0.677756, 0.307292 (1.458 sec)
8.723... logprob:  0.615884, 0.269531 (1.442 sec)
8.724... logprob:  0.610574, 0.264323 (1.464 sec)
8.725... logprob:  0.617591, 0.242187 (1.433 sec)
8.726... logprob:  0.635475, 0.304687 (1.419 sec)
8.727... logprob:  0.624067, 0.270833 (1.426 sec)
8.728... logprob:  0.679804, 0.277344 (1.465 sec)
8.729... logprob:  0.641603, 0.263021 (1.430 sec)
8.730... logprob:  0.771834, 0.342448 (1.475 sec)
8.731... logprob:  0.603568, 0.259115 (1.441 sec)
8.732... logprob:  0.516188, 0.213542 (1.428 sec)
8.733... logprob:  0.736367, 0.335938 (1.485 sec)
8.734... logprob:  0.533566, 0.233073 (1.426 sec)
8.735... logprob:  0.680646, 0.292969 (1.421 sec)
8.736... logprob:  0.856170, 0.377604 (1.432 sec)
8.737... logprob:  0.736934, 0.332031 (1.428 sec)
8.738... logprob:  0.650896, 0.295573 (1.423 sec)
8.739... logprob:  0.633141, 0.291667 (1.479 sec)
8.740... logprob:  0.584148, 0.259114 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.443873, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.814860e-03 [2.935585e-07] 
Layer 'conv1' biases: 1.266141e-06 [9.238651e-10] 
Layer 'conv2' weights[0]: 5.804566e-03 [2.928250e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.111697e-09] 
Layer 'conv3' weights[0]: 5.803425e-03 [2.944593e-07] 
Layer 'conv3' biases: 2.230478e-05 [2.982246e-08] 
Layer 'conv4' weights[0]: 5.827211e-03 [2.985631e-07] 
Layer 'conv4' biases: 1.000009e+00 [3.947189e-07] 
Layer 'conv5' weights[0]: 5.872766e-03 [2.549520e-06] 
Layer 'conv5' biases: 9.992139e-01 [2.737882e-06] 
Layer 'fc6' weights[0]: 7.346746e-03 [5.758485e-08] 
Layer 'fc6' biases: 9.999973e-01 [5.383224e-08] 
Layer 'fc7' weights[0]: 7.700941e-03 [1.259828e-07] 
Layer 'fc7' biases: 9.999048e-01 [1.402317e-07] 
Layer 'fc8' weights[0]: 4.192661e-03 [1.499320e-05] 
Layer 'fc8' biases: 7.802222e-03 [1.124848e-05] 
Train error last 800 batches: 0.657630
-------------------------------------------------------
Not saving because 0.443873 > 0.303240 (5.60: -6.35%)
======================================================= (2.381 sec)
8.741... logprob:  0.628561, 0.292969 (1.439 sec)
8.742... logprob:  0.625226, 0.274740 (1.482 sec)
8.743... logprob:  0.690302, 0.300781 (1.427 sec)
8.744... logprob:  0.759158, 0.304687 (1.426 sec)
8.745... logprob:  0.628601, 0.281250 (1.429 sec)
8.746... logprob:  0.746175, 0.329427 (1.422 sec)
8.747... logprob:  0.648044, 0.298177 (1.427 sec)
8.748... logprob:  0.459699, 0.201823 (1.479 sec)
8.749... logprob:  0.733616, 0.312500 (1.430 sec)
8.750... logprob:  0.747521, 0.317708 (1.437 sec)
8.751... logprob:  0.508765, 0.213542 (1.473 sec)
8.752... logprob:  0.638659, 0.251302 (1.427 sec)
8.753... logprob:  0.734346, 0.325521 (1.438 sec)
8.754... logprob:  0.631577, 0.285156 (1.427 sec)
8.755... logprob:  0.797502, 0.311198 (1.421 sec)
8.756... logprob:  0.631281, 0.289062 (1.426 sec)
8.757... logprob:  0.777621, 0.322917 (1.468 sec)
8.758... logprob:  0.589895, 0.251302 (1.439 sec)
8.759... logprob:  0.715641, 0.307292 (1.447 sec)
8.760... logprob:  0.633162, 0.274740 (1.453 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.480736, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.809083e-03 [2.949157e-07] 
Layer 'conv1' biases: 1.268821e-06 [9.629590e-10] 
Layer 'conv2' weights[0]: 5.798800e-03 [2.923302e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.700263e-09] 
Layer 'conv3' weights[0]: 5.797571e-03 [2.940911e-07] 
Layer 'conv3' biases: 2.235254e-05 [2.935682e-08] 
Layer 'conv4' weights[0]: 5.821373e-03 [2.968217e-07] 
Layer 'conv4' biases: 1.000012e+00 [3.489262e-07] 
Layer 'conv5' weights[0]: 5.867760e-03 [2.625911e-06] 
Layer 'conv5' biases: 9.992149e-01 [2.743343e-06] 
Layer 'fc6' weights[0]: 7.346006e-03 [6.143613e-08] 
Layer 'fc6' biases: 9.999973e-01 [5.948792e-08] 
Layer 'fc7' weights[0]: 7.700155e-03 [1.372235e-07] 
Layer 'fc7' biases: 9.999044e-01 [1.699702e-07] 
Layer 'fc8' weights[0]: 4.184994e-03 [1.691408e-05] 
Layer 'fc8' biases: 7.708810e-03 [1.795912e-05] 
Train error last 800 batches: 0.657682
-------------------------------------------------------
Not saving because 0.480736 > 0.303240 (5.60: -6.35%)
======================================================= (2.354 sec)
8.761... logprob:  0.659342, 0.287760 (1.453 sec)
8.762... logprob:  0.746265, 0.304688 (1.436 sec)
8.763... logprob:  0.721938, 0.324219 (1.425 sec)
8.764... logprob:  0.770172, 0.315104 (1.424 sec)
8.765... logprob:  0.494187, 0.220052 (1.431 sec)
8.766... logprob:  0.615588, 0.270833 (1.476 sec)
8.767... logprob:  0.579249, 0.253906 (1.456 sec)
8.768... logprob:  0.595480, 0.261719 (1.462 sec)
8.769... logprob:  0.695063, 0.298177 (1.467 sec)
8.770... logprob:  0.671917, 0.291667 (1.474 sec)
8.771... logprob:  0.688476, 0.289062 (1.454 sec)
8.772... logprob:  0.631120, 0.252604 (1.433 sec)
8.773... logprob:  0.767231, 0.325521 (1.439 sec)
8.774... logprob:  0.612470, 0.276042 (1.457 sec)
8.775... logprob:  0.542232, 0.240885 (1.452 sec)
8.776... logprob:  0.628684, 0.274740 (1.479 sec)
8.777... logprob:  0.526443, 0.251302 (1.463 sec)
8.778... logprob:  0.623210, 0.289062 (1.455 sec)
8.779... logprob:  0.696827, 0.312500 (1.486 sec)
8.780... logprob:  0.621071, 0.298177 (1.442 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.498962, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.803282e-03 [2.931989e-07] 
Layer 'conv1' biases: 1.273883e-06 [1.005605e-09] 
Layer 'conv2' weights[0]: 5.793013e-03 [2.920621e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.241046e-09] 
Layer 'conv3' weights[0]: 5.791863e-03 [2.939948e-07] 
Layer 'conv3' biases: 2.236827e-05 [3.096900e-08] 
Layer 'conv4' weights[0]: 5.815553e-03 [2.976430e-07] 
Layer 'conv4' biases: 1.000012e+00 [3.911993e-07] 
Layer 'conv5' weights[0]: 5.862324e-03 [2.829551e-06] 
Layer 'conv5' biases: 9.992082e-01 [2.965777e-06] 
Layer 'fc6' weights[0]: 7.345251e-03 [6.392064e-08] 
Layer 'fc6' biases: 9.999973e-01 [6.328991e-08] 
Layer 'fc7' weights[0]: 7.699421e-03 [1.459010e-07] 
Layer 'fc7' biases: 9.999045e-01 [2.208445e-07] 
Layer 'fc8' weights[0]: 4.213464e-03 [2.072093e-05] 
Layer 'fc8' biases: 7.927100e-03 [4.152292e-05] 
Train error last 800 batches: 0.657182
-------------------------------------------------------
Not saving because 0.498962 > 0.303240 (5.60: -6.35%)
======================================================= (2.350 sec)
8.781... logprob:  0.609706, 0.261719 (1.449 sec)
8.782... logprob:  0.676596, 0.319010 (1.450 sec)
8.783... logprob:  0.766089, 0.343750 (1.458 sec)
8.784... logprob:  0.632259, 0.289062 (1.448 sec)
8.785... logprob:  0.745974, 0.324219 (1.480 sec)
8.786... logprob:  0.713387, 0.287760 (1.466 sec)
8.787... logprob:  0.674758, 0.300781 (1.452 sec)
8.788... logprob:  0.765265, 0.345052 (1.487 sec)
8.789... logprob:  0.494023, 0.220052 (1.451 sec)
8.790... logprob:  0.650981, 0.268229 (1.445 sec)
8.791... logprob:  0.638723, 0.276042 (1.443 sec)
8.792... logprob:  0.656427, 0.320312 (1.452 sec)
8.793... logprob:  0.641285, 0.276042 (1.451 sec)
8.794... logprob:  0.610636, 0.256510 (1.487 sec)
8.795... logprob:  0.578525, 0.261719 (1.460 sec)
8.796... logprob:  0.619417, 0.259115 (1.454 sec)
8.797... logprob:  0.644759, 0.266927 (1.492 sec)
8.798... logprob:  0.596724, 0.259115 (1.442 sec)
8.799... logprob:  0.636934, 0.283854 (1.446 sec)
8.800... logprob:  0.619070, 0.264323 (1.401 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.513971, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.797490e-03 [2.933155e-07] 
Layer 'conv1' biases: 1.280212e-06 [7.835072e-10] 
Layer 'conv2' weights[0]: 5.787254e-03 [2.912237e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.282081e-09] 
Layer 'conv3' weights[0]: 5.786048e-03 [2.916643e-07] 
Layer 'conv3' biases: 2.244779e-05 [2.217219e-08] 
Layer 'conv4' weights[0]: 5.809715e-03 [2.939724e-07] 
Layer 'conv4' biases: 1.000014e+00 [2.657453e-07] 
Layer 'conv5' weights[0]: 5.857386e-03 [2.428197e-06] 
Layer 'conv5' biases: 9.992027e-01 [2.648927e-06] 
Layer 'fc6' weights[0]: 7.344505e-03 [5.714643e-08] 
Layer 'fc6' biases: 9.999971e-01 [5.321726e-08] 
Layer 'fc7' weights[0]: 7.698664e-03 [1.249750e-07] 
Layer 'fc7' biases: 9.999043e-01 [1.379641e-07] 
Layer 'fc8' weights[0]: 4.219392e-03 [1.438827e-05] 
Layer 'fc8' biases: 7.962804e-03 [1.179915e-05] 
Train error last 800 batches: 0.657353
-------------------------------------------------------
Not saving because 0.513971 > 0.303240 (5.60: -6.35%)
======================================================= (2.371 sec)
9.1... logprob:  0.613006, 0.283854 (1.415 sec)
9.2... logprob:  0.676641, 0.298177 (1.448 sec)
9.3... logprob:  0.648843, 0.277344 (1.415 sec)
9.4... logprob:  0.619929, 0.300781 (1.431 sec)
9.5... logprob:  0.623700, 0.252604 (1.426 sec)
9.6... logprob:  0.823548, 0.330729 (1.395 sec)
9.7... logprob:  0.661328, 0.291667 (1.414 sec)
9.8... logprob:  0.700709, 0.315104 (1.393 sec)
9.9... logprob:  0.633213, 0.266927 (1.402 sec)
9.10... logprob:  0.597799, 0.276042 (1.408 sec)
9.11... logprob:  0.644710, 0.261719 (1.446 sec)
9.12... logprob:  0.702638, 0.300781 (1.393 sec)
9.13... logprob:  0.587752, 0.266927 (1.415 sec)
9.14... logprob:  0.705296, 0.298177 (1.395 sec)
9.15... logprob:  0.640724, 0.243490 (1.408 sec)
9.16... logprob:  0.711870, 0.292969 (1.401 sec)
9.17... logprob:  0.668783, 0.261719 (1.394 sec)
9.18... logprob:  0.475077, 0.190104 (1.398 sec)
9.19... logprob:  0.485564, 0.221354 (1.400 sec)
9.20... logprob:  0.710769, 0.319010 (1.397 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.519711, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.791724e-03 [2.920971e-07] 
Layer 'conv1' biases: 1.282813e-06 [1.073275e-09] 
Layer 'conv2' weights[0]: 5.781439e-03 [2.906770e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.443570e-09] 
Layer 'conv3' weights[0]: 5.780282e-03 [2.926659e-07] 
Layer 'conv3' biases: 2.242391e-05 [2.670931e-08] 
Layer 'conv4' weights[0]: 5.803926e-03 [2.965402e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.721242e-07] 
Layer 'conv5' weights[0]: 5.851816e-03 [2.913378e-06] 
Layer 'conv5' biases: 9.992092e-01 [3.018062e-06] 
Layer 'fc6' weights[0]: 7.343733e-03 [6.070178e-08] 
Layer 'fc6' biases: 9.999971e-01 [5.849986e-08] 
Layer 'fc7' weights[0]: 7.697908e-03 [1.329779e-07] 
Layer 'fc7' biases: 9.999034e-01 [1.638326e-07] 
Layer 'fc8' weights[0]: 4.194614e-03 [1.652724e-05] 
Layer 'fc8' biases: 7.806280e-03 [2.227765e-05] 
Train error last 800 batches: 0.657843
-------------------------------------------------------
Not saving because 0.519711 > 0.303240 (5.60: -6.35%)
======================================================= (2.415 sec)
9.21... logprob:  0.651726, 0.268229 (1.406 sec)
9.22... logprob:  0.722434, 0.307292 (1.415 sec)
9.23... logprob:  0.638263, 0.277344 (1.412 sec)
9.24... logprob:  0.632280, 0.316406 (1.414 sec)
9.25... logprob:  0.593004, 0.269531 (1.402 sec)
9.26... logprob:  0.683442, 0.305990 (1.441 sec)
9.27... logprob:  0.636202, 0.276042 (1.386 sec)
9.28... logprob:  0.744825, 0.320312 (1.407 sec)
9.29... logprob:  0.655831, 0.289062 (1.415 sec)
9.30... logprob:  0.572317, 0.273438 (1.411 sec)
9.31... logprob:  0.772093, 0.322917 (1.396 sec)
9.32... logprob:  0.792025, 0.335938 (1.383 sec)
9.33... logprob:  0.665962, 0.281250 (1.444 sec)
9.34... logprob:  0.687306, 0.287760 (1.388 sec)
9.35... logprob:  0.654550, 0.295573 (1.393 sec)
9.36... logprob:  0.738104, 0.294271 (1.394 sec)
9.37... logprob:  0.603595, 0.257812 (1.404 sec)
9.38... logprob:  0.652827, 0.274740 (1.393 sec)
9.39... logprob:  0.893243, 0.369792 (1.432 sec)
9.40... logprob:  0.652897, 0.282552 (1.405 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.463907, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.785932e-03 [2.924446e-07] 
Layer 'conv1' biases: 1.288620e-06 [1.016813e-09] 
Layer 'conv2' weights[0]: 5.775694e-03 [2.914205e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.922927e-09] 
Layer 'conv3' weights[0]: 5.774491e-03 [2.937920e-07] 
Layer 'conv3' biases: 2.249610e-05 [3.400471e-08] 
Layer 'conv4' weights[0]: 5.798134e-03 [2.988133e-07] 
Layer 'conv4' biases: 1.000012e+00 [4.513742e-07] 
Layer 'conv5' weights[0]: 5.846174e-03 [3.553416e-06] 
Layer 'conv5' biases: 9.992136e-01 [3.735161e-06] 
Layer 'fc6' weights[0]: 7.342972e-03 [7.838474e-08] 
Layer 'fc6' biases: 9.999971e-01 [8.401348e-08] 
Layer 'fc7' weights[0]: 7.697133e-03 [1.886971e-07] 
Layer 'fc7' biases: 9.999026e-01 [3.165525e-07] 
Layer 'fc8' weights[0]: 4.167108e-03 [2.739579e-05] 
Layer 'fc8' biases: 7.598275e-03 [5.959416e-05] 
Train error last 800 batches: 0.657925
-------------------------------------------------------
Not saving because 0.463907 > 0.303240 (5.60: -6.35%)
======================================================= (2.356 sec)
9.41... logprob:  0.595390, 0.279948 (1.426 sec)
9.42... logprob:  0.649148, 0.261719 (1.416 sec)
9.43... logprob:  0.615675, 0.270833 (1.431 sec)
9.44... logprob:  0.723379, 0.308594 (1.433 sec)
9.45... logprob:  0.557278, 0.233073 (1.388 sec)
9.46... logprob:  0.663052, 0.291667 (1.392 sec)
9.47... logprob:  0.577212, 0.257812 (1.389 sec)
9.48... logprob:  0.692977, 0.322917 (1.413 sec)
9.49... logprob:  0.697724, 0.292969 (1.411 sec)
9.50... logprob:  0.647801, 0.298177 (1.416 sec)
9.51... logprob:  0.746057, 0.335938 (1.409 sec)
9.52... logprob:  0.705617, 0.287760 (1.395 sec)
9.53... logprob:  0.543371, 0.259114 (1.436 sec)
9.54... logprob:  0.564942, 0.279948 (1.394 sec)
9.55... logprob:  0.548609, 0.243489 (1.388 sec)
9.56... logprob:  0.647418, 0.266927 (1.395 sec)
9.57... logprob:  0.816016, 0.371094 (1.422 sec)
9.58... logprob:  0.589649, 0.281250 (1.396 sec)
9.59... logprob:  0.575963, 0.252604 (1.460 sec)
9.60... logprob:  0.821256, 0.333333 (1.411 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.423438, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.780146e-03 [2.920487e-07] 
Layer 'conv1' biases: 1.293794e-06 [8.015991e-10] 
Layer 'conv2' weights[0]: 5.769903e-03 [2.906413e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.200373e-09] 
Layer 'conv3' weights[0]: 5.768753e-03 [2.918583e-07] 
Layer 'conv3' biases: 2.250282e-05 [2.651187e-08] 
Layer 'conv4' weights[0]: 5.792357e-03 [2.951190e-07] 
Layer 'conv4' biases: 1.000010e+00 [3.285086e-07] 
Layer 'conv5' weights[0]: 5.839756e-03 [2.257678e-06] 
Layer 'conv5' biases: 9.992054e-01 [2.363364e-06] 
Layer 'fc6' weights[0]: 7.342207e-03 [5.947899e-08] 
Layer 'fc6' biases: 9.999971e-01 [5.669845e-08] 
Layer 'fc7' weights[0]: 7.696343e-03 [1.314043e-07] 
Layer 'fc7' biases: 9.999038e-01 [1.482134e-07] 
Layer 'fc8' weights[0]: 4.238937e-03 [1.562827e-05] 
Layer 'fc8' biases: 8.097028e-03 [1.526458e-05] 
Train error last 800 batches: 0.657490
-------------------------------------------------------
Not saving because 0.423438 > 0.303240 (5.60: -6.35%)
======================================================= (2.397 sec)
9.61... logprob:  0.575714, 0.269531 (1.434 sec)
9.62... logprob:  0.683592, 0.298177 (1.461 sec)
9.63... logprob:  0.595815, 0.265625 (1.438 sec)
9.64... logprob:  0.671939, 0.302083 (1.406 sec)
9.65... logprob:  0.660575, 0.285156 (1.390 sec)
9.66... logprob:  0.664374, 0.278646 (1.442 sec)
9.67... logprob:  0.550447, 0.256510 (1.381 sec)
9.68... logprob:  0.725543, 0.322917 (1.388 sec)
9.69... logprob:  0.774922, 0.345052 (1.423 sec)
9.70... logprob:  0.586693, 0.259115 (1.424 sec)
9.71... logprob:  0.659087, 0.283854 (1.452 sec)
9.72... logprob:  0.716656, 0.312500 (1.395 sec)
9.73... logprob:  0.577906, 0.251302 (1.421 sec)
9.74... logprob:  0.741618, 0.304688 (1.408 sec)
9.75... logprob:  0.562540, 0.265625 (1.409 sec)
9.76... logprob:  0.644234, 0.285156 (1.427 sec)
9.77... logprob:  0.597002, 0.261719 (1.428 sec)
9.78... logprob:  0.639263, 0.281250 (1.444 sec)
9.79... logprob:  0.654221, 0.289062 (1.398 sec)
9.80... logprob:  0.661892, 0.286458 (1.412 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.555946, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.774393e-03 [2.915537e-07] 
Layer 'conv1' biases: 1.295580e-06 [7.443136e-10] 
Layer 'conv2' weights[0]: 5.764128e-03 [2.902254e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.434084e-09] 
Layer 'conv3' weights[0]: 5.763000e-03 [2.912844e-07] 
Layer 'conv3' biases: 2.249757e-05 [2.399066e-08] 
Layer 'conv4' weights[0]: 5.786494e-03 [2.947820e-07] 
Layer 'conv4' biases: 1.000008e+00 [3.350754e-07] 
Layer 'conv5' weights[0]: 5.832970e-03 [2.450056e-06] 
Layer 'conv5' biases: 9.992088e-01 [2.613757e-06] 
Layer 'fc6' weights[0]: 7.341435e-03 [5.831263e-08] 
Layer 'fc6' biases: 9.999970e-01 [5.489537e-08] 
Layer 'fc7' weights[0]: 7.695538e-03 [1.271538e-07] 
Layer 'fc7' biases: 9.999034e-01 [1.446999e-07] 
Layer 'fc8' weights[0]: 4.233271e-03 [1.449038e-05] 
Layer 'fc8' biases: 8.053864e-03 [9.674282e-06] 
Train error last 800 batches: 0.657817
-------------------------------------------------------
Not saving because 0.555946 > 0.303240 (5.60: -6.35%)
======================================================= (2.394 sec)
9.81... logprob:  0.717294, 0.315104 (1.417 sec)
9.82... logprob:  0.483227, 0.213542 (1.424 sec)
9.83... logprob:  0.785388, 0.326823 (1.393 sec)
9.84... logprob:  0.677864, 0.250000 (1.460 sec)
9.85... logprob:  0.690853, 0.315104 (1.415 sec)
9.86... logprob:  0.610850, 0.261719 (1.411 sec)
9.87... logprob:  0.812479, 0.339844 (1.412 sec)
9.88... logprob:  0.712380, 0.298177 (1.399 sec)
9.89... logprob:  0.655019, 0.256510 (1.429 sec)
9.90... logprob:  0.756443, 0.311198 (1.383 sec)
9.91... logprob:  0.553850, 0.236979 (1.388 sec)
9.92... logprob:  0.655317, 0.277344 (1.399 sec)
9.93... logprob:  0.727172, 0.339844 (1.389 sec)
9.94... logprob:  0.682346, 0.286458 (1.387 sec)
9.95... logprob:  0.678923, 0.268229 (1.400 sec)
9.96... logprob:  0.749638, 0.299479 (1.401 sec)
9.97... logprob:  0.675777, 0.290364 (1.387 sec)
9.98... logprob:  0.672882, 0.268229 (1.432 sec)
9.99... logprob:  0.725792, 0.300781 (1.399 sec)
9.100... logprob:  0.548607, 0.261719 (1.395 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.420996, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.768614e-03 [2.938204e-07] 
Layer 'conv1' biases: 1.293610e-06 [9.112500e-10] 
Layer 'conv2' weights[0]: 5.758398e-03 [2.908683e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.818876e-09] 
Layer 'conv3' weights[0]: 5.757233e-03 [2.920451e-07] 
Layer 'conv3' biases: 2.264878e-05 [2.838226e-08] 
Layer 'conv4' weights[0]: 5.780740e-03 [2.945320e-07] 
Layer 'conv4' biases: 1.000008e+00 [3.290597e-07] 
Layer 'conv5' weights[0]: 5.827409e-03 [2.435196e-06] 
Layer 'conv5' biases: 9.992160e-01 [2.561056e-06] 
Layer 'fc6' weights[0]: 7.340653e-03 [6.118506e-08] 
Layer 'fc6' biases: 9.999970e-01 [5.914944e-08] 
Layer 'fc7' weights[0]: 7.694795e-03 [1.346407e-07] 
Layer 'fc7' biases: 9.999025e-01 [1.549543e-07] 
Layer 'fc8' weights[0]: 4.170031e-03 [1.669082e-05] 
Layer 'fc8' biases: 7.653990e-03 [1.862776e-05] 
Train error last 800 batches: 0.658090
-------------------------------------------------------
Not saving because 0.420996 > 0.303240 (5.60: -6.35%)
======================================================= (2.384 sec)
9.101... logprob:  0.520662, 0.255208 (1.446 sec)
9.102... logprob:  0.711106, 0.324219 (1.392 sec)
9.103... logprob:  0.677498, 0.290365 (1.396 sec)
9.104... logprob:  0.644658, 0.299479 (1.398 sec)
9.105... logprob:  0.786946, 0.348958 (1.394 sec)
9.106... logprob:  0.581946, 0.278646 (1.387 sec)
9.107... logprob:  0.608745, 0.269531 (1.442 sec)
9.108... logprob:  0.718420, 0.316406 (1.395 sec)
9.109... logprob:  0.639123, 0.304688 (1.393 sec)
9.110... logprob:  0.803960, 0.351562 (1.391 sec)
9.111... logprob:  0.618684, 0.261719 (1.389 sec)
9.112... logprob:  0.605233, 0.286458 (1.395 sec)
9.113... logprob:  0.595729, 0.270833 (1.389 sec)
9.114... logprob:  0.653115, 0.285156 (1.426 sec)
9.115... logprob:  0.752863, 0.307292 (1.408 sec)
9.116... logprob:  0.560257, 0.233073 (1.392 sec)
9.117... logprob:  0.608631, 0.263021 (1.437 sec)
9.118... logprob:  0.564106, 0.259115 (1.394 sec)
9.119... logprob:  0.548668, 0.235677 (1.398 sec)
9.120... logprob:  0.722263, 0.303385 (1.391 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.526670, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.762821e-03 [2.902935e-07] 
Layer 'conv1' biases: 1.294778e-06 [8.030473e-10] 
Layer 'conv2' weights[0]: 5.752629e-03 [2.894511e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.181693e-09] 
Layer 'conv3' weights[0]: 5.751468e-03 [2.902835e-07] 
Layer 'conv3' biases: 2.263882e-05 [2.350433e-08] 
Layer 'conv4' weights[0]: 5.774970e-03 [2.933478e-07] 
Layer 'conv4' biases: 1.000007e+00 [3.004599e-07] 
Layer 'conv5' weights[0]: 5.821496e-03 [2.535874e-06] 
Layer 'conv5' biases: 9.992006e-01 [2.607760e-06] 
Layer 'fc6' weights[0]: 7.339887e-03 [5.871696e-08] 
Layer 'fc6' biases: 9.999969e-01 [5.551063e-08] 
Layer 'fc7' weights[0]: 7.693978e-03 [1.290899e-07] 
Layer 'fc7' biases: 9.999036e-01 [1.513398e-07] 
Layer 'fc8' weights[0]: 4.249970e-03 [1.562445e-05] 
Layer 'fc8' biases: 8.261786e-03 [1.882634e-05] 
Train error last 800 batches: 0.657363
-------------------------------------------------------
Not saving because 0.526670 > 0.303240 (5.60: -6.35%)
======================================================= (2.380 sec)
9.121... logprob:  0.633514, 0.317708 (1.398 sec)
9.122... logprob:  0.687755, 0.291667 (1.446 sec)
9.123... logprob:  0.670837, 0.277344 (1.380 sec)
9.124... logprob:  0.708820, 0.292969 (1.398 sec)
9.125... logprob:  0.740398, 0.299479 (1.393 sec)
9.126... logprob:  0.735488, 0.311198 (1.387 sec)
9.127... logprob:  0.663407, 0.298177 (1.388 sec)
9.128... logprob:  0.613430, 0.265625 (1.411 sec)
9.129... logprob:  0.678676, 0.252604 (1.418 sec)
9.130... logprob:  0.556475, 0.256510 (1.414 sec)
9.131... logprob:  0.627192, 0.287760 (1.400 sec)
9.132... logprob:  0.713443, 0.316406 (1.430 sec)
9.133... logprob:  0.546189, 0.230469 (1.381 sec)
9.134... logprob:  0.626451, 0.263021 (1.390 sec)
9.135... logprob:  0.636817, 0.279948 (1.396 sec)
9.136... logprob:  0.722181, 0.309896 (1.392 sec)
9.137... logprob:  0.647912, 0.276042 (1.390 sec)
9.138... logprob:  0.628933, 0.287760 (1.437 sec)
9.139... logprob:  0.645571, 0.299479 (1.395 sec)
9.140... logprob:  0.720732, 0.304687 (1.401 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.383909, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.757093e-03 [2.903682e-07] 
Layer 'conv1' biases: 1.294536e-06 [6.410325e-10] 
Layer 'conv2' weights[0]: 5.746894e-03 [2.889274e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.585501e-09] 
Layer 'conv3' weights[0]: 5.745728e-03 [2.903007e-07] 
Layer 'conv3' biases: 2.272819e-05 [2.454500e-08] 
Layer 'conv4' weights[0]: 5.769185e-03 [2.940885e-07] 
Layer 'conv4' biases: 1.000008e+00 [3.497134e-07] 
Layer 'conv5' weights[0]: 5.815867e-03 [2.641339e-06] 
Layer 'conv5' biases: 9.992025e-01 [2.835470e-06] 
Layer 'fc6' weights[0]: 7.339148e-03 [6.038459e-08] 
Layer 'fc6' biases: 9.999970e-01 [5.807837e-08] 
Layer 'fc7' weights[0]: 7.693194e-03 [1.311139e-07] 
Layer 'fc7' biases: 9.999028e-01 [1.527859e-07] 
Layer 'fc8' weights[0]: 4.222355e-03 [1.568357e-05] 
Layer 'fc8' biases: 8.125292e-03 [1.533588e-05] 
Train error last 800 batches: 0.656804
-------------------------------------------------------
Not saving because 0.383909 > 0.303240 (5.60: -6.35%)
======================================================= (2.365 sec)
9.141... logprob:  0.711855, 0.298177 (1.443 sec)
9.142... logprob:  0.675764, 0.298177 (1.395 sec)
9.143... logprob:  0.567371, 0.250000 (1.420 sec)
9.144... logprob:  0.685236, 0.304687 (1.410 sec)
9.145... logprob:  0.583566, 0.251302 (1.406 sec)
9.146... logprob:  0.701539, 0.269531 (1.404 sec)
9.147... logprob:  0.548671, 0.220052 (1.427 sec)
9.148... logprob:  0.634906, 0.263021 (1.382 sec)
9.149... logprob:  0.590734, 0.268229 (1.389 sec)
9.150... logprob:  0.597952, 0.291667 (1.394 sec)
9.151... logprob:  0.536438, 0.238281 (1.394 sec)
9.152... logprob:  1.007137, 0.397135 (1.379 sec)
9.153... logprob:  0.680818, 0.265625 (1.440 sec)
9.154... logprob:  0.710610, 0.315104 (1.394 sec)
9.155... logprob:  0.631608, 0.282552 (1.399 sec)
9.156... logprob:  0.541561, 0.251302 (1.430 sec)
9.157... logprob:  0.560817, 0.268229 (1.389 sec)
9.158... logprob:  0.788076, 0.339844 (1.399 sec)
9.159... logprob:  0.629117, 0.257812 (1.396 sec)
9.160... logprob:  0.642402, 0.272135 (1.389 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.403654, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.751341e-03 [2.908522e-07] 
Layer 'conv1' biases: 1.297110e-06 [8.982629e-10] 
Layer 'conv2' weights[0]: 5.741170e-03 [2.885764e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.274845e-09] 
Layer 'conv3' weights[0]: 5.739969e-03 [2.901163e-07] 
Layer 'conv3' biases: 2.270693e-05 [2.577886e-08] 
Layer 'conv4' weights[0]: 5.763447e-03 [2.936222e-07] 
Layer 'conv4' biases: 1.000007e+00 [3.551924e-07] 
Layer 'conv5' weights[0]: 5.810254e-03 [2.714439e-06] 
Layer 'conv5' biases: 9.992034e-01 [2.940204e-06] 
Layer 'fc6' weights[0]: 7.338416e-03 [6.404673e-08] 
Layer 'fc6' biases: 9.999970e-01 [6.389715e-08] 
Layer 'fc7' weights[0]: 7.692405e-03 [1.438412e-07] 
Layer 'fc7' biases: 9.999025e-01 [1.956858e-07] 
Layer 'fc8' weights[0]: 4.222098e-03 [1.908549e-05] 
Layer 'fc8' biases: 8.131598e-03 [2.642846e-05] 
Train error last 800 batches: 0.657047
-------------------------------------------------------
Not saving because 0.403654 > 0.303240 (5.60: -6.35%)
======================================================= (2.377 sec)
9.161... logprob:  0.604423, 0.286458 (1.411 sec)
9.162... logprob:  0.797450, 0.352865 (1.405 sec)
9.163... logprob:  0.705469, 0.283854 (1.419 sec)
9.164... logprob:  0.691262, 0.329427 (1.417 sec)
9.165... logprob:  0.757935, 0.319010 (1.416 sec)
9.166... logprob:  0.684668, 0.315104 (1.447 sec)
9.167... logprob:  0.564427, 0.266927 (1.425 sec)
9.168... logprob:  0.626065, 0.281250 (1.415 sec)
9.169... logprob:  0.634978, 0.279948 (1.458 sec)
9.170... logprob:  0.585924, 0.268229 (1.400 sec)
9.171... logprob:  0.794420, 0.355469 (1.414 sec)
9.172... logprob:  0.621105, 0.255208 (1.410 sec)
9.173... logprob:  0.589103, 0.264323 (1.414 sec)
9.174... logprob:  0.754054, 0.322917 (1.396 sec)
9.175... logprob:  0.711571, 0.291667 (1.462 sec)
9.176... logprob:  0.760366, 0.332031 (1.409 sec)
9.177... logprob:  0.629943, 0.295573 (1.417 sec)
9.178... logprob:  0.598988, 0.292969 (1.457 sec)
9.179... logprob:  0.573390, 0.272135 (1.402 sec)
9.180... logprob:  0.597667, 0.256510 (1.417 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.445667, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.745579e-03 [2.909301e-07] 
Layer 'conv1' biases: 1.299724e-06 [9.890614e-10] 
Layer 'conv2' weights[0]: 5.735419e-03 [2.896375e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.371982e-09] 
Layer 'conv3' weights[0]: 5.734238e-03 [2.907985e-07] 
Layer 'conv3' biases: 2.282084e-05 [2.773257e-08] 
Layer 'conv4' weights[0]: 5.757686e-03 [2.957581e-07] 
Layer 'conv4' biases: 1.000007e+00 [3.928005e-07] 
Layer 'conv5' weights[0]: 5.804756e-03 [3.036542e-06] 
Layer 'conv5' biases: 9.992090e-01 [3.206357e-06] 
Layer 'fc6' weights[0]: 7.337603e-03 [6.637195e-08] 
Layer 'fc6' biases: 9.999969e-01 [6.667754e-08] 
Layer 'fc7' weights[0]: 7.691654e-03 [1.532046e-07] 
Layer 'fc7' biases: 9.999017e-01 [2.405904e-07] 
Layer 'fc8' weights[0]: 4.198546e-03 [2.141794e-05] 
Layer 'fc8' biases: 7.983223e-03 [4.729641e-05] 
Train error last 800 batches: 0.656704
-------------------------------------------------------
Not saving because 0.445667 > 0.303240 (5.60: -6.35%)
======================================================= (2.364 sec)
9.181... logprob:  0.728318, 0.303385 (1.428 sec)
9.182... logprob:  0.541588, 0.233073 (1.415 sec)
9.183... logprob:  0.580863, 0.257812 (1.407 sec)
9.184... logprob:  0.675822, 0.285156 (1.416 sec)
9.185... logprob:  0.523898, 0.233073 (1.391 sec)
9.186... logprob:  0.633078, 0.276042 (1.397 sec)
9.187... logprob:  0.636514, 0.270833 (1.396 sec)
9.188... logprob:  0.649547, 0.259115 (1.394 sec)
9.189... logprob:  0.614356, 0.257812 (1.383 sec)
9.190... logprob:  0.642149, 0.281250 (1.428 sec)
9.191... logprob:  0.752777, 0.343750 (1.403 sec)
9.192... logprob:  0.743545, 0.317708 (1.408 sec)
9.193... logprob:  0.536685, 0.255208 (1.415 sec)
9.194... logprob:  0.616259, 0.299479 (1.406 sec)
9.195... logprob:  0.550538, 0.255208 (1.392 sec)
9.196... logprob:  0.654608, 0.294271 (1.388 sec)
9.197... logprob:  0.752593, 0.321615 (1.401 sec)
9.198... logprob:  0.548256, 0.204427 (1.403 sec)
9.199... logprob:  0.670437, 0.281250 (1.381 sec)
9.200... logprob:  0.691366, 0.291667 (1.470 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.509244, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.739855e-03 [2.894355e-07] 
Layer 'conv1' biases: 1.300662e-06 [1.207972e-09] 
Layer 'conv2' weights[0]: 5.729694e-03 [2.883899e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.301529e-09] 
Layer 'conv3' weights[0]: 5.728495e-03 [2.898609e-07] 
Layer 'conv3' biases: 2.286350e-05 [2.586597e-08] 
Layer 'conv4' weights[0]: 5.751926e-03 [2.930172e-07] 
Layer 'conv4' biases: 1.000007e+00 [3.278820e-07] 
Layer 'conv5' weights[0]: 5.799096e-03 [2.585560e-06] 
Layer 'conv5' biases: 9.992040e-01 [2.697740e-06] 
Layer 'fc6' weights[0]: 7.336845e-03 [6.388292e-08] 
Layer 'fc6' biases: 9.999971e-01 [6.348835e-08] 
Layer 'fc7' weights[0]: 7.690897e-03 [1.456155e-07] 
Layer 'fc7' biases: 9.999025e-01 [2.007472e-07] 
Layer 'fc8' weights[0]: 4.257152e-03 [2.126547e-05] 
Layer 'fc8' biases: 8.377807e-03 [4.236291e-05] 
Train error last 800 batches: 0.656313
-------------------------------------------------------
Not saving because 0.509244 > 0.303240 (5.60: -6.35%)
======================================================= (2.386 sec)
9.201... logprob:  0.592339, 0.278646 (1.420 sec)
9.202... logprob:  0.714796, 0.307292 (1.404 sec)
9.203... logprob:  0.713744, 0.330729 (1.441 sec)
9.204... logprob:  0.694442, 0.307292 (1.385 sec)
9.205... logprob:  0.581852, 0.252604 (1.403 sec)
9.206... logprob:  0.536045, 0.223958 (1.403 sec)
9.207... logprob:  0.601844, 0.278646 (1.389 sec)
9.208... logprob:  0.654675, 0.302083 (1.391 sec)
9.209... logprob:  0.590408, 0.253906 (1.412 sec)
9.210... logprob:  0.784816, 0.300781 (1.413 sec)
9.211... logprob:  0.695473, 0.277344 (1.410 sec)
9.212... logprob:  0.749890, 0.292969 (1.410 sec)
9.213... logprob:  0.854426, 0.335937 (1.462 sec)
9.214... logprob:  0.732956, 0.300781 (1.423 sec)
9.215... logprob:  0.676888, 0.294271 (1.414 sec)
9.216... logprob:  0.832274, 0.341146 (1.457 sec)
9.217... logprob:  0.579784, 0.244792 (1.397 sec)
9.218... logprob:  0.805424, 0.315104 (1.414 sec)
9.219... logprob:  0.721927, 0.316406 (1.412 sec)
9.220... logprob:  0.617793, 0.252604 (1.414 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.438406, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.734136e-03 [2.913925e-07] 
Layer 'conv1' biases: 1.301537e-06 [1.074083e-09] 
Layer 'conv2' weights[0]: 5.723921e-03 [2.891072e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.118834e-09] 
Layer 'conv3' weights[0]: 5.722794e-03 [2.925172e-07] 
Layer 'conv3' biases: 2.289868e-05 [3.857758e-08] 
Layer 'conv4' weights[0]: 5.746187e-03 [2.986324e-07] 
Layer 'conv4' biases: 1.000008e+00 [5.046234e-07] 
Layer 'conv5' weights[0]: 5.794095e-03 [3.489759e-06] 
Layer 'conv5' biases: 9.992150e-01 [3.626126e-06] 
Layer 'fc6' weights[0]: 7.336115e-03 [7.603608e-08] 
Layer 'fc6' biases: 9.999970e-01 [8.067419e-08] 
Layer 'fc7' weights[0]: 7.690150e-03 [1.799074e-07] 
Layer 'fc7' biases: 9.999000e-01 [2.897157e-07] 
Layer 'fc8' weights[0]: 4.166674e-03 [2.657306e-05] 
Layer 'fc8' biases: 7.716834e-03 [4.998650e-05] 
Train error last 800 batches: 0.656863
-------------------------------------------------------
Not saving because 0.438406 > 0.303240 (5.60: -6.35%)
======================================================= (2.369 sec)
9.221... logprob:  0.549847, 0.239583 (1.413 sec)
9.222... logprob:  0.785681, 0.371094 (1.454 sec)
9.223... logprob:  0.669844, 0.289062 (1.430 sec)
9.224... logprob:  0.634315, 0.290365 (1.420 sec)
9.225... logprob:  0.660583, 0.294271 (1.444 sec)
9.226... logprob:  0.631426, 0.282552 (1.415 sec)
9.227... logprob:  0.741452, 0.303385 (1.409 sec)
9.228... logprob:  0.625140, 0.268229 (1.405 sec)
9.229... logprob:  0.708922, 0.286458 (1.415 sec)
9.230... logprob:  0.667064, 0.282552 (1.430 sec)
9.231... logprob:  0.681376, 0.305990 (1.401 sec)
9.232... logprob:  0.715960, 0.321615 (1.450 sec)
9.233... logprob:  0.681501, 0.308594 (1.418 sec)
9.234... logprob:  0.739524, 0.329427 (1.413 sec)
9.235... logprob:  0.653018, 0.300781 (1.461 sec)
9.236... logprob:  0.619957, 0.255208 (1.392 sec)
9.237... logprob:  0.599802, 0.253906 (1.419 sec)
9.238... logprob:  0.610124, 0.272135 (1.408 sec)
9.239... logprob:  0.706608, 0.283854 (1.437 sec)
9.240... logprob:  0.754585, 0.341146 (1.395 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.507733, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.728407e-03 [2.899655e-07] 
Layer 'conv1' biases: 1.305865e-06 [7.593595e-10] 
Layer 'conv2' weights[0]: 5.718213e-03 [2.881123e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.759549e-09] 
Layer 'conv3' weights[0]: 5.717030e-03 [2.894110e-07] 
Layer 'conv3' biases: 2.287357e-05 [2.789469e-08] 
Layer 'conv4' weights[0]: 5.740455e-03 [2.931305e-07] 
Layer 'conv4' biases: 1.000009e+00 [3.504086e-07] 
Layer 'conv5' weights[0]: 5.788917e-03 [2.745872e-06] 
Layer 'conv5' biases: 9.992075e-01 [2.894274e-06] 
Layer 'fc6' weights[0]: 7.335356e-03 [6.207679e-08] 
Layer 'fc6' biases: 9.999970e-01 [6.053447e-08] 
Layer 'fc7' weights[0]: 7.689387e-03 [1.374721e-07] 
Layer 'fc7' biases: 9.999011e-01 [1.680981e-07] 
Layer 'fc8' weights[0]: 4.206185e-03 [1.779142e-05] 
Layer 'fc8' biases: 7.992158e-03 [2.240281e-05] 
Train error last 800 batches: 0.656702
-------------------------------------------------------
Not saving because 0.507733 > 0.303240 (5.60: -6.35%)
======================================================= (2.386 sec)
9.241... logprob:  0.678318, 0.292969 (1.459 sec)
9.242... logprob:  0.549581, 0.238281 (1.428 sec)
9.243... logprob:  0.604461, 0.265625 (1.431 sec)
9.244... logprob:  0.645604, 0.303385 (1.438 sec)
9.245... logprob:  0.539606, 0.240885 (1.421 sec)
9.246... logprob:  0.673423, 0.315104 (1.416 sec)
9.247... logprob:  0.582674, 0.259115 (1.408 sec)
9.248... logprob:  0.591625, 0.259115 (1.419 sec)
9.249... logprob:  0.639924, 0.264323 (1.421 sec)
9.250... logprob:  0.864060, 0.358073 (1.399 sec)
9.251... logprob:  0.624219, 0.268229 (1.455 sec)
9.252... logprob:  0.583073, 0.222656 (1.418 sec)
9.253... logprob:  0.629723, 0.279948 (1.411 sec)
9.254... logprob:  0.694542, 0.290365 (1.466 sec)
9.255... logprob:  0.531336, 0.251302 (1.400 sec)
9.256... logprob:  0.605615, 0.286458 (1.421 sec)
9.257... logprob:  0.545597, 0.239583 (1.408 sec)
9.258... logprob:  0.652106, 0.296875 (1.415 sec)
9.259... logprob:  0.666019, 0.287760 (1.392 sec)
9.260... logprob:  0.534697, 0.265625 (1.453 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.562424, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.722684e-03 [2.884940e-07] 
Layer 'conv1' biases: 1.308155e-06 [7.767625e-10] 
Layer 'conv2' weights[0]: 5.712508e-03 [2.877048e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.702839e-09] 
Layer 'conv3' weights[0]: 5.711339e-03 [2.886503e-07] 
Layer 'conv3' biases: 2.285915e-05 [2.560832e-08] 
Layer 'conv4' weights[0]: 5.734693e-03 [2.922487e-07] 
Layer 'conv4' biases: 1.000010e+00 [3.431259e-07] 
Layer 'conv5' weights[0]: 5.783501e-03 [2.522857e-06] 
Layer 'conv5' biases: 9.992023e-01 [2.674634e-06] 
Layer 'fc6' weights[0]: 7.334567e-03 [6.259774e-08] 
Layer 'fc6' biases: 9.999970e-01 [6.118830e-08] 
Layer 'fc7' weights[0]: 7.688599e-03 [1.436640e-07] 
Layer 'fc7' biases: 9.999018e-01 [2.136238e-07] 
Layer 'fc8' weights[0]: 4.273213e-03 [2.055336e-05] 
Layer 'fc8' biases: 8.466384e-03 [3.810476e-05] 
Train error last 800 batches: 0.656160
-------------------------------------------------------
Not saving because 0.562424 > 0.303240 (5.60: -6.35%)
======================================================= (2.385 sec)
9.261... logprob:  0.572205, 0.234375 (1.438 sec)
9.262... logprob:  0.749203, 0.307292 (1.438 sec)
9.263... logprob:  0.753275, 0.332031 (1.449 sec)
9.264... logprob:  0.676438, 0.309896 (1.414 sec)
9.265... logprob:  0.594891, 0.260417 (1.409 sec)
9.266... logprob:  0.675150, 0.281250 (1.411 sec)
9.267... logprob:  0.650553, 0.305990 (1.410 sec)
9.268... logprob:  0.685010, 0.287760 (1.413 sec)
9.269... logprob:  0.725308, 0.298177 (1.399 sec)
9.270... logprob:  0.703375, 0.287760 (1.456 sec)
9.271... logprob:  0.654239, 0.281250 (1.418 sec)
9.272... logprob:  0.642153, 0.269531 (1.410 sec)
9.273... logprob:  0.784593, 0.372396 (1.462 sec)
9.274... logprob:  0.692900, 0.321615 (1.392 sec)
9.275... logprob:  0.695462, 0.291667 (1.420 sec)
9.276... logprob:  0.645351, 0.298177 (1.415 sec)
9.277... logprob:  0.615146, 0.272135 (1.424 sec)
9.278... logprob:  0.594264, 0.256510 (1.416 sec)
9.279... logprob:  0.528871, 0.226562 (1.459 sec)
9.280... logprob:  0.493588, 0.200521 (1.402 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.445249, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.716978e-03 [2.895476e-07] 
Layer 'conv1' biases: 1.311994e-06 [8.862347e-10] 
Layer 'conv2' weights[0]: 5.706818e-03 [2.873775e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.408138e-09] 
Layer 'conv3' weights[0]: 5.705568e-03 [2.882839e-07] 
Layer 'conv3' biases: 2.287042e-05 [2.537686e-08] 
Layer 'conv4' weights[0]: 5.728978e-03 [2.922728e-07] 
Layer 'conv4' biases: 1.000009e+00 [3.266977e-07] 
Layer 'conv5' weights[0]: 5.777668e-03 [2.627699e-06] 
Layer 'conv5' biases: 9.992179e-01 [2.804314e-06] 
Layer 'fc6' weights[0]: 7.333840e-03 [6.559781e-08] 
Layer 'fc6' biases: 9.999970e-01 [6.518653e-08] 
Layer 'fc7' weights[0]: 7.687834e-03 [1.500400e-07] 
Layer 'fc7' biases: 9.999005e-01 [2.276067e-07] 
Layer 'fc8' weights[0]: 4.238146e-03 [2.053705e-05] 
Layer 'fc8' biases: 8.192400e-03 [3.771577e-05] 
Train error last 800 batches: 0.656623
-------------------------------------------------------
Not saving because 0.445249 > 0.303240 (5.60: -6.35%)
======================================================= (2.377 sec)
9.281... logprob:  0.644982, 0.269531 (1.428 sec)
9.282... logprob:  0.733375, 0.298177 (1.416 sec)
9.283... logprob:  0.613247, 0.266927 (1.408 sec)
9.284... logprob:  0.613830, 0.289062 (1.408 sec)
9.285... logprob:  0.736767, 0.320312 (1.442 sec)
9.286... logprob:  0.725704, 0.317708 (1.436 sec)
9.287... logprob:  0.550706, 0.243490 (1.424 sec)
9.288... logprob:  0.622204, 0.289062 (1.431 sec)
9.289... logprob:  0.678388, 0.294271 (1.435 sec)
9.290... logprob:  0.697180, 0.305990 (1.402 sec)
9.291... logprob:  0.714365, 0.296875 (1.415 sec)
9.292... logprob:  0.772364, 0.325521 (1.410 sec)
9.293... logprob:  0.603741, 0.248698 (1.420 sec)
9.294... logprob:  0.668353, 0.305989 (1.394 sec)
9.295... logprob:  0.661355, 0.308594 (1.461 sec)
9.296... logprob:  0.540484, 0.256510 (1.416 sec)
9.297... logprob:  0.593834, 0.273437 (1.416 sec)
9.298... logprob:  0.626139, 0.285156 (1.459 sec)
9.299... logprob:  0.538365, 0.236979 (1.402 sec)
9.300... logprob:  0.662811, 0.299479 (1.415 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.299667, 0.039062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.711252e-03 [2.884813e-07] 
Layer 'conv1' biases: 1.315999e-06 [8.090414e-10] 
Layer 'conv2' weights[0]: 5.701107e-03 [2.872272e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.252333e-09] 
Layer 'conv3' weights[0]: 5.699871e-03 [2.881982e-07] 
Layer 'conv3' biases: 2.293675e-05 [2.469177e-08] 
Layer 'conv4' weights[0]: 5.723239e-03 [2.919693e-07] 
Layer 'conv4' biases: 1.000008e+00 [3.327641e-07] 
Layer 'conv5' weights[0]: 5.771821e-03 [2.727098e-06] 
Layer 'conv5' biases: 9.992133e-01 [2.954544e-06] 
Layer 'fc6' weights[0]: 7.333062e-03 [5.986231e-08] 
Layer 'fc6' biases: 9.999968e-01 [5.657016e-08] 
Layer 'fc7' weights[0]: 7.687010e-03 [1.329361e-07] 
Layer 'fc7' biases: 9.999010e-01 [1.736208e-07] 
Layer 'fc8' weights[0]: 4.276134e-03 [1.651816e-05] 
Layer 'fc8' biases: 8.431239e-03 [2.849658e-05] 
Train error last 800 batches: 0.656884
-------------------------------------------------------
Saved checkpoint to /data2/ad6813/my-nets/saves/ConvNet__2014-06-04_16.10.14
======================================================= (2.815 sec)
9.301... logprob:  0.626406, 0.291667 (1.422 sec)
9.302... logprob:  0.778544, 0.329427 (1.413 sec)
9.303... logprob:  0.757785, 0.345052 (1.409 sec)
9.304... logprob:  0.731951, 0.309896 (2.608 sec)
9.305... logprob:  0.612508, 0.281250 (1.438 sec)
9.306... logprob:  0.608460, 0.285156 (1.437 sec)
9.307... logprob:  0.643506, 0.272135 (2.410 sec)
9.308... logprob:  0.619584, 0.281250 (1.452 sec)
9.309... logprob:  0.673006, 0.294271 (1.410 sec)
9.310... logprob:  0.678019, 0.295573 (1.414 sec)
9.311... logprob:  0.771277, 0.343750 (1.418 sec)
9.312... logprob:  0.747954, 0.316406 (1.427 sec)
9.313... logprob:  0.655133, 0.282552 (1.412 sec)
9.314... logprob:  0.668409, 0.296875 (1.511 sec)
9.315... logprob:  0.519956, 0.242188 (1.433 sec)
9.316... logprob:  0.692291, 0.324219 (1.420 sec)
9.317... logprob:  0.576318, 0.272135 (1.475 sec)
9.318... logprob:  0.635190, 0.276042 (1.410 sec)
9.319... logprob:  0.659910, 0.295573 (1.414 sec)
9.320... logprob:  0.661143, 0.299479 (1.422 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.462507, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.705562e-03 [2.880523e-07] 
Layer 'conv1' biases: 1.317018e-06 [6.749636e-10] 
Layer 'conv2' weights[0]: 5.695397e-03 [2.868091e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.383425e-09] 
Layer 'conv3' weights[0]: 5.694179e-03 [2.876591e-07] 
Layer 'conv3' biases: 2.301415e-05 [2.366892e-08] 
Layer 'conv4' weights[0]: 5.717523e-03 [2.904428e-07] 
Layer 'conv4' biases: 1.000009e+00 [2.862656e-07] 
Layer 'conv5' weights[0]: 5.766342e-03 [2.273718e-06] 
Layer 'conv5' biases: 9.992097e-01 [2.385459e-06] 
Layer 'fc6' weights[0]: 7.332306e-03 [5.819167e-08] 
Layer 'fc6' biases: 9.999970e-01 [5.416825e-08] 
Layer 'fc7' weights[0]: 7.686259e-03 [1.283424e-07] 
Layer 'fc7' biases: 9.998996e-01 [1.544420e-07] 
Layer 'fc8' weights[0]: 4.237978e-03 [1.636478e-05] 
Layer 'fc8' biases: 8.244578e-03 [2.215220e-05] 
Train error last 800 batches: 0.657197
-------------------------------------------------------
Not saving because 0.462507 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
9.321... logprob:  0.556614, 0.264323 (1.430 sec)
9.322... logprob:  0.599894, 0.281250 (1.420 sec)
9.323... logprob:  0.659210, 0.286458 (1.473 sec)
9.324... logprob:  0.746200, 0.332031 (1.420 sec)
9.325... logprob:  0.567237, 0.261719 (1.429 sec)
9.326... logprob:  0.879981, 0.359375 (1.465 sec)
9.327... logprob:  0.817628, 0.322917 (1.422 sec)
9.328... logprob:  0.748033, 0.308594 (1.426 sec)
9.329... logprob:  0.556509, 0.248698 (1.421 sec)
9.330... logprob:  0.608869, 0.276042 (1.420 sec)
9.331... logprob:  0.584905, 0.250000 (1.421 sec)
9.332... logprob:  0.682182, 0.299479 (1.442 sec)
9.333... logprob:  0.580889, 0.270833 (1.461 sec)
9.334... logprob:  0.715630, 0.298177 (1.443 sec)
9.335... logprob:  0.565705, 0.265625 (1.430 sec)
9.336... logprob:  0.663595, 0.289062 (1.453 sec)
9.337... logprob:  0.799062, 0.324219 (1.414 sec)
9.338... logprob:  0.824291, 0.358073 (1.416 sec)
9.339... logprob:  0.712814, 0.307292 (1.415 sec)
9.340... logprob:  0.703047, 0.291667 (1.425 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.513326, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.699857e-03 [2.879769e-07] 
Layer 'conv1' biases: 1.322289e-06 [9.417561e-10] 
Layer 'conv2' weights[0]: 5.689727e-03 [2.867285e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.249690e-09] 
Layer 'conv3' weights[0]: 5.688529e-03 [2.887594e-07] 
Layer 'conv3' biases: 2.307843e-05 [3.097448e-08] 
Layer 'conv4' weights[0]: 5.711805e-03 [2.939363e-07] 
Layer 'conv4' biases: 1.000011e+00 [4.391533e-07] 
Layer 'conv5' weights[0]: 5.761369e-03 [3.539358e-06] 
Layer 'conv5' biases: 9.992149e-01 [3.831939e-06] 
Layer 'fc6' weights[0]: 7.331562e-03 [7.339351e-08] 
Layer 'fc6' biases: 9.999969e-01 [7.636375e-08] 
Layer 'fc7' weights[0]: 7.685498e-03 [1.700810e-07] 
Layer 'fc7' biases: 9.998987e-01 [2.660229e-07] 
Layer 'fc8' weights[0]: 4.200010e-03 [2.382936e-05] 
Layer 'fc8' biases: 7.953134e-03 [4.641349e-05] 
Train error last 800 batches: 0.657801
-------------------------------------------------------
Not saving because 0.513326 > 0.299667 (9.300: -1.18%)
======================================================= (2.347 sec)
9.341... logprob:  0.727931, 0.308594 (1.422 sec)
9.342... logprob:  0.622217, 0.273438 (1.459 sec)
9.343... logprob:  0.786277, 0.328125 (1.436 sec)
9.344... logprob:  0.737172, 0.320312 (1.480 sec)
9.345... logprob:  0.661734, 0.298177 (1.440 sec)
9.346... logprob:  0.702655, 0.289062 (1.429 sec)
9.347... logprob:  0.624007, 0.263021 (1.478 sec)
9.348... logprob:  0.627628, 0.294271 (1.427 sec)
9.349... logprob:  0.742755, 0.329427 (1.426 sec)
9.350... logprob:  0.655547, 0.305990 (1.429 sec)
9.351... logprob:  0.708571, 0.309896 (1.422 sec)
9.352... logprob:  0.642917, 0.289062 (1.452 sec)
9.353... logprob:  0.740694, 0.328125 (1.490 sec)
9.354... logprob:  0.855260, 0.361979 (1.423 sec)
9.355... logprob:  0.566787, 0.253906 (1.440 sec)
9.356... logprob:  0.708520, 0.319010 (1.470 sec)
9.357... logprob:  0.653545, 0.283854 (1.426 sec)
9.358... logprob:  0.577310, 0.266927 (1.435 sec)
9.359... logprob:  0.726047, 0.335937 (1.431 sec)
9.360... logprob:  0.641472, 0.289062 (1.418 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.458177, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.694139e-03 [2.876508e-07] 
Layer 'conv1' biases: 1.325713e-06 [8.374921e-10] 
Layer 'conv2' weights[0]: 5.684041e-03 [2.869788e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.109493e-09] 
Layer 'conv3' weights[0]: 5.682838e-03 [2.889614e-07] 
Layer 'conv3' biases: 2.319456e-05 [3.232355e-08] 
Layer 'conv4' weights[0]: 5.706072e-03 [2.933265e-07] 
Layer 'conv4' biases: 1.000010e+00 [4.218106e-07] 
Layer 'conv5' weights[0]: 5.755534e-03 [3.314118e-06] 
Layer 'conv5' biases: 9.992230e-01 [3.608501e-06] 
Layer 'fc6' weights[0]: 7.330795e-03 [7.210113e-08] 
Layer 'fc6' biases: 9.999969e-01 [7.410244e-08] 
Layer 'fc7' weights[0]: 7.684730e-03 [1.654603e-07] 
Layer 'fc7' biases: 9.998987e-01 [2.639310e-07] 
Layer 'fc8' weights[0]: 4.210594e-03 [2.558208e-05] 
Layer 'fc8' biases: 8.088900e-03 [5.428302e-05] 
Train error last 800 batches: 0.658019
-------------------------------------------------------
Not saving because 0.458177 > 0.299667 (9.300: -1.18%)
======================================================= (2.352 sec)
9.361... logprob:  0.649932, 0.268229 (1.437 sec)
9.362... logprob:  0.722403, 0.328125 (1.473 sec)
9.363... logprob:  0.604577, 0.278646 (1.431 sec)
9.364... logprob:  0.613676, 0.273437 (1.449 sec)
9.365... logprob:  0.671904, 0.309896 (1.455 sec)
9.366... logprob:  0.673391, 0.326823 (1.442 sec)
9.367... logprob:  0.577506, 0.239583 (1.429 sec)
9.368... logprob:  0.740035, 0.342448 (1.423 sec)
9.369... logprob:  0.635602, 0.243490 (1.419 sec)
9.370... logprob:  0.594051, 0.239583 (1.432 sec)
9.371... logprob:  0.672741, 0.270833 (1.476 sec)
9.372... logprob:  0.718234, 0.325521 (1.453 sec)
9.373... logprob:  0.679069, 0.265625 (1.453 sec)
9.374... logprob:  0.709778, 0.308594 (1.442 sec)
9.375... logprob:  0.551805, 0.229167 (1.458 sec)
9.376... logprob:  0.613660, 0.263021 (1.428 sec)
9.377... logprob:  0.521920, 0.246094 (1.421 sec)
9.378... logprob:  0.660914, 0.313802 (1.427 sec)
9.379... logprob:  0.607903, 0.278646 (1.429 sec)
9.380... logprob:  0.765858, 0.308594 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.440244, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.688429e-03 [2.867983e-07] 
Layer 'conv1' biases: 1.329458e-06 [9.199529e-10] 
Layer 'conv2' weights[0]: 5.678335e-03 [2.858601e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.434588e-09] 
Layer 'conv3' weights[0]: 5.677159e-03 [2.884973e-07] 
Layer 'conv3' biases: 2.322336e-05 [3.314675e-08] 
Layer 'conv4' weights[0]: 5.700371e-03 [2.922769e-07] 
Layer 'conv4' biases: 1.000009e+00 [4.240274e-07] 
Layer 'conv5' weights[0]: 5.749842e-03 [3.055823e-06] 
Layer 'conv5' biases: 9.992140e-01 [3.251094e-06] 
Layer 'fc6' weights[0]: 7.329999e-03 [6.574354e-08] 
Layer 'fc6' biases: 9.999969e-01 [6.545138e-08] 
Layer 'fc7' weights[0]: 7.683952e-03 [1.465843e-07] 
Layer 'fc7' biases: 9.998993e-01 [2.060855e-07] 
Layer 'fc8' weights[0]: 4.278672e-03 [2.032045e-05] 
Layer 'fc8' biases: 8.508604e-03 [3.647202e-05] 
Train error last 800 batches: 0.657919
-------------------------------------------------------
Not saving because 0.440244 > 0.299667 (9.300: -1.18%)
======================================================= (2.378 sec)
9.381... logprob:  0.661615, 0.269531 (1.475 sec)
9.382... logprob:  0.687708, 0.298177 (1.452 sec)
9.383... logprob:  0.714471, 0.321615 (1.438 sec)
9.384... logprob:  0.696044, 0.292969 (1.474 sec)
9.385... logprob:  0.721886, 0.319010 (1.437 sec)
9.386... logprob:  0.807028, 0.334635 (1.425 sec)
9.387... logprob:  0.538201, 0.248698 (1.429 sec)
9.388... logprob:  0.781346, 0.317708 (1.433 sec)
9.389... logprob:  0.606689, 0.269531 (1.434 sec)
9.390... logprob:  0.676207, 0.296875 (1.476 sec)
9.391... logprob:  0.587359, 0.299479 (1.439 sec)
9.392... logprob:  0.718912, 0.332031 (1.427 sec)
9.393... logprob:  0.631266, 0.291667 (1.476 sec)
9.394... logprob:  0.608819, 0.282552 (1.429 sec)
9.395... logprob:  0.575951, 0.244792 (1.425 sec)
9.396... logprob:  0.557944, 0.234375 (1.426 sec)
9.397... logprob:  0.658270, 0.282552 (1.428 sec)
9.398... logprob:  0.658798, 0.291667 (1.428 sec)
9.399... logprob:  0.670098, 0.303385 (1.477 sec)
9.400... logprob:  0.738292, 0.313802 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.505031, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.682785e-03 [2.866909e-07] 
Layer 'conv1' biases: 1.331353e-06 [6.648445e-10] 
Layer 'conv2' weights[0]: 5.672675e-03 [2.853790e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.133970e-09] 
Layer 'conv3' weights[0]: 5.671462e-03 [2.868801e-07] 
Layer 'conv3' biases: 2.322705e-05 [2.548173e-08] 
Layer 'conv4' weights[0]: 5.694700e-03 [2.908929e-07] 
Layer 'conv4' biases: 1.000009e+00 [3.503494e-07] 
Layer 'conv5' weights[0]: 5.744484e-03 [2.797300e-06] 
Layer 'conv5' biases: 9.992129e-01 [3.159610e-06] 
Layer 'fc6' weights[0]: 7.329238e-03 [6.167280e-08] 
Layer 'fc6' biases: 9.999968e-01 [5.937811e-08] 
Layer 'fc7' weights[0]: 7.683197e-03 [1.408208e-07] 
Layer 'fc7' biases: 9.998981e-01 [1.864379e-07] 
Layer 'fc8' weights[0]: 4.248387e-03 [1.881016e-05] 
Layer 'fc8' biases: 8.329126e-03 [2.823517e-05] 
Train error last 800 batches: 0.657992
-------------------------------------------------------
Not saving because 0.505031 > 0.299667 (9.300: -1.18%)
======================================================= (2.382 sec)
9.401... logprob:  0.705421, 0.319010 (1.441 sec)
9.402... logprob:  0.667060, 0.287760 (1.482 sec)
9.403... logprob:  0.632842, 0.277344 (1.431 sec)
9.404... logprob:  0.673505, 0.287760 (1.432 sec)
9.405... logprob:  0.675326, 0.296875 (1.431 sec)
9.406... logprob:  0.513519, 0.234375 (1.426 sec)
9.407... logprob:  0.748661, 0.304688 (1.431 sec)
9.408... logprob:  0.581062, 0.268229 (1.480 sec)
9.409... logprob:  0.681432, 0.300781 (1.438 sec)
9.410... logprob:  0.768749, 0.354167 (1.447 sec)
9.411... logprob:  0.551669, 0.231771 (1.470 sec)
9.412... logprob:  0.738183, 0.354167 (1.428 sec)
9.413... logprob:  0.699260, 0.279948 (1.432 sec)
9.414... logprob:  0.644741, 0.307292 (1.424 sec)
9.415... logprob:  0.643857, 0.321614 (1.421 sec)
9.416... logprob:  0.618554, 0.302083 (1.443 sec)
9.417... logprob:  0.634654, 0.265625 (1.464 sec)
9.418... logprob:  0.562822, 0.255208 (1.443 sec)
9.419... logprob:  0.584574, 0.268229 (1.452 sec)
9.420... logprob:  0.651701, 0.291667 (1.452 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.468244, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.677110e-03 [2.873364e-07] 
Layer 'conv1' biases: 1.334037e-06 [8.043286e-10] 
Layer 'conv2' weights[0]: 5.667005e-03 [2.854090e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.620074e-09] 
Layer 'conv3' weights[0]: 5.665797e-03 [2.868643e-07] 
Layer 'conv3' biases: 2.325049e-05 [2.687582e-08] 
Layer 'conv4' weights[0]: 5.689022e-03 [2.904593e-07] 
Layer 'conv4' biases: 1.000012e+00 [3.673916e-07] 
Layer 'conv5' weights[0]: 5.739809e-03 [2.827091e-06] 
Layer 'conv5' biases: 9.992073e-01 [3.140874e-06] 
Layer 'fc6' weights[0]: 7.328498e-03 [6.381764e-08] 
Layer 'fc6' biases: 9.999968e-01 [6.262471e-08] 
Layer 'fc7' weights[0]: 7.682468e-03 [1.468638e-07] 
Layer 'fc7' biases: 9.998985e-01 [2.205236e-07] 
Layer 'fc8' weights[0]: 4.262313e-03 [2.203279e-05] 
Layer 'fc8' biases: 8.479666e-03 [4.656489e-05] 
Train error last 800 batches: 0.657687
-------------------------------------------------------
Not saving because 0.468244 > 0.299667 (9.300: -1.18%)
======================================================= (2.355 sec)
9.421... logprob:  0.643194, 0.304687 (1.457 sec)
9.422... logprob:  0.723402, 0.320313 (1.446 sec)
9.423... logprob:  0.656410, 0.266927 (1.419 sec)
9.424... logprob:  0.578351, 0.257812 (1.423 sec)
9.425... logprob:  0.487663, 0.216146 (1.434 sec)
9.426... logprob:  0.656826, 0.307292 (1.448 sec)
9.427... logprob:  0.781379, 0.312500 (1.461 sec)
9.428... logprob:  0.701054, 0.268229 (1.450 sec)
9.429... logprob:  0.595341, 0.261719 (1.442 sec)
9.430... logprob:  0.590636, 0.270833 (1.464 sec)
9.431... logprob:  0.912160, 0.365885 (1.434 sec)
9.432... logprob:  0.585480, 0.234375 (1.427 sec)
9.433... logprob:  0.627440, 0.266927 (1.422 sec)
9.434... logprob:  0.690150, 0.311198 (1.438 sec)
9.435... logprob:  0.719992, 0.286458 (1.433 sec)
9.436... logprob:  0.601876, 0.261719 (1.466 sec)
9.437... logprob:  0.742672, 0.296875 (1.442 sec)
9.438... logprob:  0.669026, 0.300781 (1.424 sec)
9.439... logprob:  0.597033, 0.250000 (1.481 sec)
9.440... logprob:  0.691387, 0.303385 (1.435 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.467528, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.671442e-03 [2.868488e-07] 
Layer 'conv1' biases: 1.338339e-06 [9.371415e-10] 
Layer 'conv2' weights[0]: 5.661323e-03 [2.856109e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.133401e-09] 
Layer 'conv3' weights[0]: 5.660156e-03 [2.866672e-07] 
Layer 'conv3' biases: 2.339357e-05 [2.939270e-08] 
Layer 'conv4' weights[0]: 5.683316e-03 [2.894702e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.659513e-07] 
Layer 'conv5' weights[0]: 5.734818e-03 [2.562732e-06] 
Layer 'conv5' biases: 9.992178e-01 [2.725049e-06] 
Layer 'fc6' weights[0]: 7.327756e-03 [6.459795e-08] 
Layer 'fc6' biases: 9.999968e-01 [6.344970e-08] 
Layer 'fc7' weights[0]: 7.681697e-03 [1.451222e-07] 
Layer 'fc7' biases: 9.998972e-01 [1.938197e-07] 
Layer 'fc8' weights[0]: 4.212848e-03 [1.837395e-05] 
Layer 'fc8' biases: 8.140013e-03 [2.598994e-05] 
Train error last 800 batches: 0.657583
-------------------------------------------------------
Not saving because 0.467528 > 0.299667 (9.300: -1.18%)
======================================================= (2.354 sec)
9.441... logprob:  0.643171, 0.286458 (1.433 sec)
9.442... logprob:  0.591926, 0.243490 (1.437 sec)
9.443... logprob:  0.729282, 0.335938 (1.433 sec)
9.444... logprob:  0.583284, 0.235677 (1.422 sec)
9.445... logprob:  0.607966, 0.290365 (1.479 sec)
9.446... logprob:  0.700260, 0.317708 (1.434 sec)
9.447... logprob:  0.790148, 0.317708 (1.436 sec)
9.448... logprob:  0.694617, 0.294271 (1.476 sec)
9.449... logprob:  0.697640, 0.316406 (1.425 sec)
9.450... logprob:  0.556095, 0.253906 (1.429 sec)
9.451... logprob:  0.685265, 0.287760 (1.431 sec)
9.452... logprob:  0.672544, 0.308594 (1.431 sec)
9.453... logprob:  0.625795, 0.291667 (1.422 sec)
9.454... logprob:  0.689912, 0.295573 (1.481 sec)
9.455... logprob:  0.781162, 0.330729 (1.430 sec)
9.456... logprob:  0.683867, 0.299479 (1.439 sec)
9.457... logprob:  0.561932, 0.225260 (1.472 sec)
9.458... logprob:  0.602114, 0.274740 (1.432 sec)
9.459... logprob:  0.754709, 0.338542 (1.428 sec)
9.460... logprob:  0.532807, 0.264323 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.501426, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.665769e-03 [2.863296e-07] 
Layer 'conv1' biases: 1.342717e-06 [8.368623e-10] 
Layer 'conv2' weights[0]: 5.655711e-03 [2.853994e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.438731e-09] 
Layer 'conv3' weights[0]: 5.654533e-03 [2.874856e-07] 
Layer 'conv3' biases: 2.342075e-05 [2.938326e-08] 
Layer 'conv4' weights[0]: 5.677650e-03 [2.910060e-07] 
Layer 'conv4' biases: 1.000014e+00 [3.825234e-07] 
Layer 'conv5' weights[0]: 5.729739e-03 [2.537024e-06] 
Layer 'conv5' biases: 9.992135e-01 [2.709635e-06] 
Layer 'fc6' weights[0]: 7.327003e-03 [6.322117e-08] 
Layer 'fc6' biases: 9.999968e-01 [6.135492e-08] 
Layer 'fc7' weights[0]: 7.680966e-03 [1.435724e-07] 
Layer 'fc7' biases: 9.998974e-01 [2.074544e-07] 
Layer 'fc8' weights[0]: 4.234360e-03 [1.953437e-05] 
Layer 'fc8' biases: 8.294006e-03 [3.261473e-05] 
Train error last 800 batches: 0.657620
-------------------------------------------------------
Not saving because 0.501426 > 0.299667 (9.300: -1.18%)
======================================================= (2.363 sec)
9.461... logprob:  0.707768, 0.312500 (1.434 sec)
9.462... logprob:  0.627828, 0.256510 (1.434 sec)
9.463... logprob:  0.588376, 0.261719 (1.465 sec)
9.464... logprob:  0.681353, 0.270833 (1.440 sec)
9.465... logprob:  0.653386, 0.300781 (1.449 sec)
9.466... logprob:  0.570492, 0.260417 (1.457 sec)
9.467... logprob:  0.703988, 0.303385 (1.445 sec)
9.468... logprob:  0.625918, 0.274740 (1.431 sec)
9.469... logprob:  0.584114, 0.264323 (1.424 sec)
9.470... logprob:  0.588660, 0.261719 (1.419 sec)
9.471... logprob:  0.809873, 0.348958 (1.431 sec)
9.472... logprob:  0.674883, 0.295573 (1.444 sec)
9.473... logprob:  0.584044, 0.264323 (1.461 sec)
9.474... logprob:  0.631128, 0.289062 (1.448 sec)
9.475... logprob:  0.791772, 0.343750 (1.452 sec)
9.476... logprob:  0.699973, 0.305990 (1.463 sec)
9.477... logprob:  0.599055, 0.256510 (1.438 sec)
9.478... logprob:  0.685943, 0.269531 (1.415 sec)
9.479... logprob:  0.529453, 0.234375 (1.428 sec)
9.480... logprob:  0.678327, 0.289062 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.402555, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.660113e-03 [2.856018e-07] 
Layer 'conv1' biases: 1.347521e-06 [7.880171e-10] 
Layer 'conv2' weights[0]: 5.650021e-03 [2.838334e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.154677e-09] 
Layer 'conv3' weights[0]: 5.648896e-03 [2.849259e-07] 
Layer 'conv3' biases: 2.351736e-05 [2.135497e-08] 
Layer 'conv4' weights[0]: 5.671997e-03 [2.874923e-07] 
Layer 'conv4' biases: 1.000015e+00 [2.694693e-07] 
Layer 'conv5' weights[0]: 5.724492e-03 [2.330296e-06] 
Layer 'conv5' biases: 9.992093e-01 [2.439428e-06] 
Layer 'fc6' weights[0]: 7.326248e-03 [5.948927e-08] 
Layer 'fc6' biases: 9.999967e-01 [5.617786e-08] 
Layer 'fc7' weights[0]: 7.680164e-03 [1.297659e-07] 
Layer 'fc7' biases: 9.998981e-01 [1.504948e-07] 
Layer 'fc8' weights[0]: 4.254547e-03 [1.518453e-05] 
Layer 'fc8' biases: 8.493451e-03 [1.233850e-05] 
Train error last 800 batches: 0.657325
-------------------------------------------------------
Not saving because 0.402555 > 0.299667 (9.300: -1.18%)
======================================================= (2.405 sec)
9.481... logprob:  0.639057, 0.278646 (1.436 sec)
9.482... logprob:  0.586453, 0.250000 (1.471 sec)
9.483... logprob:  0.740549, 0.295573 (1.439 sec)
9.484... logprob:  0.620364, 0.287760 (1.430 sec)
9.485... logprob:  0.650335, 0.285156 (1.480 sec)
9.486... logprob:  0.558751, 0.268229 (1.429 sec)
9.487... logprob:  0.810921, 0.298177 (1.421 sec)
9.488... logprob:  0.691781, 0.316406 (1.427 sec)
9.489... logprob:  0.681754, 0.304687 (1.430 sec)
9.490... logprob:  0.668965, 0.290365 (1.434 sec)
9.491... logprob:  0.605224, 0.265625 (1.474 sec)
9.492... logprob:  0.720243, 0.325521 (1.439 sec)
9.493... logprob:  0.723447, 0.281250 (1.430 sec)
9.494... logprob:  0.605127, 0.268229 (1.487 sec)
9.495... logprob:  0.543734, 0.233073 (1.426 sec)
9.496... logprob:  0.761911, 0.329427 (1.423 sec)
9.497... logprob:  0.612504, 0.279948 (1.434 sec)
9.498... logprob:  0.680493, 0.302083 (1.421 sec)
9.499... logprob:  0.657875, 0.264323 (1.429 sec)
9.500... logprob:  0.574782, 0.236979 (1.480 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.486757, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.654470e-03 [2.852081e-07] 
Layer 'conv1' biases: 1.351777e-06 [8.834175e-10] 
Layer 'conv2' weights[0]: 5.644375e-03 [2.840953e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.529688e-09] 
Layer 'conv3' weights[0]: 5.643236e-03 [2.849346e-07] 
Layer 'conv3' biases: 2.354192e-05 [2.304836e-08] 
Layer 'conv4' weights[0]: 5.666331e-03 [2.876765e-07] 
Layer 'conv4' biases: 1.000016e+00 [2.913475e-07] 
Layer 'conv5' weights[0]: 5.718977e-03 [2.297827e-06] 
Layer 'conv5' biases: 9.992173e-01 [2.312747e-06] 
Layer 'fc6' weights[0]: 7.325518e-03 [6.038739e-08] 
Layer 'fc6' biases: 9.999967e-01 [5.706083e-08] 
Layer 'fc7' weights[0]: 7.679350e-03 [1.308234e-07] 
Layer 'fc7' biases: 9.998969e-01 [1.462214e-07] 
Layer 'fc8' weights[0]: 4.219587e-03 [1.496482e-05] 
Layer 'fc8' biases: 8.273388e-03 [6.705587e-06] 
Train error last 800 batches: 0.656993
-------------------------------------------------------
Not saving because 0.486757 > 0.299667 (9.300: -1.18%)
======================================================= (2.391 sec)
9.501... logprob:  0.620155, 0.270833 (1.439 sec)
9.502... logprob:  0.696914, 0.326823 (1.443 sec)
9.503... logprob:  0.625595, 0.283854 (1.471 sec)
9.504... logprob:  0.691446, 0.283854 (1.423 sec)
9.505... logprob:  0.691963, 0.291667 (1.431 sec)
9.506... logprob:  0.635255, 0.270833 (1.429 sec)
9.507... logprob:  0.572761, 0.265625 (1.423 sec)
9.508... logprob:  0.591865, 0.256510 (1.422 sec)
9.509... logprob:  0.524937, 0.208333 (1.473 sec)
9.510... logprob:  0.606790, 0.291667 (1.435 sec)
9.511... logprob:  0.677372, 0.294271 (1.444 sec)
9.512... logprob:  0.703357, 0.279948 (1.459 sec)
9.513... logprob:  0.562716, 0.251302 (1.450 sec)
9.514... logprob:  0.631346, 0.292969 (1.440 sec)
9.515... logprob:  0.671155, 0.309896 (1.432 sec)
9.516... logprob:  0.619767, 0.261719 (1.423 sec)
9.517... logprob:  0.762588, 0.339844 (1.436 sec)
9.518... logprob:  0.612076, 0.296875 (1.457 sec)
9.519... logprob:  0.769417, 0.339844 (1.450 sec)
9.520... logprob:  0.675275, 0.312500 (1.442 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.448040, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.648822e-03 [2.851536e-07] 
Layer 'conv1' biases: 1.354777e-06 [7.874937e-10] 
Layer 'conv2' weights[0]: 5.638743e-03 [2.840016e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.106444e-09] 
Layer 'conv3' weights[0]: 5.637514e-03 [2.850514e-07] 
Layer 'conv3' biases: 2.357633e-05 [2.428689e-08] 
Layer 'conv4' weights[0]: 5.660605e-03 [2.878025e-07] 
Layer 'conv4' biases: 1.000014e+00 [3.150289e-07] 
Layer 'conv5' weights[0]: 5.713021e-03 [2.382111e-06] 
Layer 'conv5' biases: 9.992061e-01 [2.478809e-06] 
Layer 'fc6' weights[0]: 7.324745e-03 [5.951642e-08] 
Layer 'fc6' biases: 9.999968e-01 [5.585793e-08] 
Layer 'fc7' weights[0]: 7.678560e-03 [1.304136e-07] 
Layer 'fc7' biases: 9.998985e-01 [1.542189e-07] 
Layer 'fc8' weights[0]: 4.290130e-03 [1.581993e-05] 
Layer 'fc8' biases: 8.757227e-03 [1.892695e-05] 
Train error last 800 batches: 0.656717
-------------------------------------------------------
Not saving because 0.448040 > 0.299667 (9.300: -1.18%)
======================================================= (2.358 sec)
9.521... logprob:  0.735573, 0.326823 (1.460 sec)
9.522... logprob:  0.709716, 0.309896 (1.462 sec)
9.523... logprob:  0.470344, 0.216146 (1.429 sec)
9.524... logprob:  0.684258, 0.304688 (1.417 sec)
9.525... logprob:  0.695100, 0.273438 (1.429 sec)
9.526... logprob:  0.566749, 0.248698 (1.431 sec)
9.527... logprob:  0.736693, 0.303385 (1.432 sec)
9.528... logprob:  0.744010, 0.317708 (1.460 sec)
9.529... logprob:  0.619373, 0.274740 (1.449 sec)
9.530... logprob:  0.695068, 0.305990 (1.440 sec)
9.531... logprob:  0.645900, 0.292969 (1.468 sec)
9.532... logprob:  0.786430, 0.359375 (1.427 sec)
9.533... logprob:  0.734630, 0.321615 (1.424 sec)
9.534... logprob:  0.566947, 0.255208 (1.428 sec)
9.535... logprob:  0.730708, 0.320312 (1.429 sec)
9.536... logprob:  0.712121, 0.307292 (1.429 sec)
9.537... logprob:  0.699254, 0.312500 (1.486 sec)
9.538... logprob:  0.717685, 0.294271 (1.437 sec)
9.539... logprob:  0.530007, 0.242187 (1.428 sec)
9.540... logprob:  0.688569, 0.315104 (1.478 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.485480, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.643189e-03 [2.851459e-07] 
Layer 'conv1' biases: 1.359227e-06 [7.312788e-10] 
Layer 'conv2' weights[0]: 5.633146e-03 [2.838646e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.620796e-09] 
Layer 'conv3' weights[0]: 5.631892e-03 [2.847548e-07] 
Layer 'conv3' biases: 2.358794e-05 [2.522514e-08] 
Layer 'conv4' weights[0]: 5.654986e-03 [2.879451e-07] 
Layer 'conv4' biases: 1.000014e+00 [3.227321e-07] 
Layer 'conv5' weights[0]: 5.707693e-03 [2.677274e-06] 
Layer 'conv5' biases: 9.992136e-01 [2.948339e-06] 
Layer 'fc6' weights[0]: 7.323978e-03 [6.128523e-08] 
Layer 'fc6' biases: 9.999967e-01 [5.862645e-08] 
Layer 'fc7' weights[0]: 7.677755e-03 [1.374084e-07] 
Layer 'fc7' biases: 9.998963e-01 [1.759589e-07] 
Layer 'fc8' weights[0]: 4.206971e-03 [1.868862e-05] 
Layer 'fc8' biases: 8.214954e-03 [3.300917e-05] 
Train error last 800 batches: 0.656566
-------------------------------------------------------
Not saving because 0.485480 > 0.299667 (9.300: -1.18%)
======================================================= (2.423 sec)
9.541... logprob:  0.614844, 0.277344 (1.433 sec)
9.542... logprob:  0.585550, 0.256510 (1.433 sec)
9.543... logprob:  0.440672, 0.199219 (1.451 sec)
9.544... logprob:  0.523323, 0.222656 (1.426 sec)
9.545... logprob:  0.618365, 0.285156 (1.426 sec)
9.546... logprob:  0.651622, 0.282552 (1.478 sec)
9.547... logprob:  0.744862, 0.315104 (1.424 sec)
9.548... logprob:  0.613179, 0.282552 (1.441 sec)
9.549... logprob:  0.644472, 0.263021 (1.469 sec)
9.550... logprob:  0.628521, 0.266927 (1.429 sec)
9.551... logprob:  0.595577, 0.279948 (1.424 sec)
9.552... logprob:  0.675040, 0.272135 (1.435 sec)
9.553... logprob:  0.642685, 0.268229 (1.427 sec)
9.554... logprob:  0.710681, 0.303385 (1.427 sec)
9.555... logprob:  0.677636, 0.287760 (1.475 sec)
9.556... logprob:  0.649383, 0.278646 (1.431 sec)
9.557... logprob:  0.652914, 0.261719 (1.445 sec)
9.558... logprob:  0.663113, 0.279948 (1.469 sec)
9.559... logprob:  0.673857, 0.298177 (1.432 sec)
9.560... logprob:  0.555498, 0.251302 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.480199, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.637537e-03 [2.846524e-07] 
Layer 'conv1' biases: 1.364214e-06 [7.423765e-10] 
Layer 'conv2' weights[0]: 5.627473e-03 [2.834102e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.190214e-09] 
Layer 'conv3' weights[0]: 5.626295e-03 [2.847438e-07] 
Layer 'conv3' biases: 2.360150e-05 [2.733541e-08] 
Layer 'conv4' weights[0]: 5.649345e-03 [2.881397e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.695788e-07] 
Layer 'conv5' weights[0]: 5.701548e-03 [2.997226e-06] 
Layer 'conv5' biases: 9.992048e-01 [3.198343e-06] 
Layer 'fc6' weights[0]: 7.323238e-03 [6.605579e-08] 
Layer 'fc6' biases: 9.999967e-01 [6.560872e-08] 
Layer 'fc7' weights[0]: 7.677015e-03 [1.514598e-07] 
Layer 'fc7' biases: 9.998972e-01 [2.207790e-07] 
Layer 'fc8' weights[0]: 4.261932e-03 [2.283039e-05] 
Layer 'fc8' biases: 8.602446e-03 [5.075539e-05] 
Train error last 800 batches: 0.656151
-------------------------------------------------------
Not saving because 0.480199 > 0.299667 (9.300: -1.18%)
======================================================= (2.356 sec)
9.561... logprob:  0.609139, 0.269531 (1.430 sec)
9.562... logprob:  0.738920, 0.326823 (1.424 sec)
9.563... logprob:  0.663570, 0.292969 (1.428 sec)
9.564... logprob:  0.707186, 0.307292 (1.461 sec)
9.565... logprob:  0.817942, 0.341146 (1.442 sec)
9.566... logprob:  0.588079, 0.270833 (1.448 sec)
9.567... logprob:  0.722588, 0.281250 (1.451 sec)
9.568... logprob:  0.670810, 0.298177 (1.459 sec)
9.569... logprob:  0.692428, 0.304688 (1.430 sec)
9.570... logprob:  0.715050, 0.303385 (1.421 sec)
9.571... logprob:  0.723894, 0.287760 (1.423 sec)
9.572... logprob:  0.717356, 0.290365 (1.437 sec)
9.573... logprob:  0.639174, 0.285156 (1.442 sec)
9.574... logprob:  0.683341, 0.287760 (1.452 sec)
9.575... logprob:  0.554953, 0.226562 (1.450 sec)
9.576... logprob:  0.630145, 0.292969 (1.436 sec)
9.577... logprob:  0.666556, 0.273437 (1.468 sec)
9.578... logprob:  0.599675, 0.277344 (1.425 sec)
9.579... logprob:  0.658804, 0.315104 (1.422 sec)
9.580... logprob:  0.720253, 0.287760 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.570613, 0.171875 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.631893e-03 [2.853036e-07] 
Layer 'conv1' biases: 1.368196e-06 [9.871190e-10] 
Layer 'conv2' weights[0]: 5.621870e-03 [2.836865e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.004177e-09] 
Layer 'conv3' weights[0]: 5.620682e-03 [2.865363e-07] 
Layer 'conv3' biases: 2.361635e-05 [3.437079e-08] 
Layer 'conv4' weights[0]: 5.643708e-03 [2.908806e-07] 
Layer 'conv4' biases: 1.000012e+00 [4.349816e-07] 
Layer 'conv5' weights[0]: 5.695918e-03 [3.321991e-06] 
Layer 'conv5' biases: 9.992144e-01 [3.459708e-06] 
Layer 'fc6' weights[0]: 7.322498e-03 [7.408813e-08] 
Layer 'fc6' biases: 9.999967e-01 [7.646032e-08] 
Layer 'fc7' weights[0]: 7.676245e-03 [1.772847e-07] 
Layer 'fc7' biases: 9.998960e-01 [2.957988e-07] 
Layer 'fc8' weights[0]: 4.227742e-03 [2.809191e-05] 
Layer 'fc8' biases: 8.374276e-03 [6.224397e-05] 
Train error last 800 batches: 0.656330
-------------------------------------------------------
Not saving because 0.570613 > 0.299667 (9.300: -1.18%)
======================================================= (2.343 sec)
9.581... logprob:  0.762819, 0.324219 (1.458 sec)
9.582... logprob:  0.659791, 0.295573 (1.436 sec)
9.583... logprob:  0.749505, 0.351562 (1.477 sec)
9.584... logprob:  0.671746, 0.298177 (1.447 sec)
9.585... logprob:  0.638796, 0.299479 (1.425 sec)
9.586... logprob:  0.558158, 0.251302 (1.479 sec)
9.587... logprob:  0.582746, 0.263021 (1.426 sec)
9.588... logprob:  0.659125, 0.298177 (1.420 sec)
9.589... logprob:  0.556060, 0.255208 (1.432 sec)
9.590... logprob:  0.674448, 0.289062 (1.428 sec)
9.591... logprob:  0.703684, 0.311198 (1.422 sec)
9.592... logprob:  0.825114, 0.334635 (1.482 sec)
9.593... logprob:  0.755646, 0.305990 (1.429 sec)
9.594... logprob:  0.584991, 0.263021 (1.431 sec)
9.595... logprob:  0.645232, 0.266927 (1.485 sec)
9.596... logprob:  0.760235, 0.329427 (1.425 sec)
9.597... logprob:  0.655934, 0.285156 (1.428 sec)
9.598... logprob:  0.636420, 0.291667 (1.428 sec)
9.599... logprob:  0.497985, 0.229167 (1.424 sec)
9.600... logprob:  0.500233, 0.222656 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.473163, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.626301e-03 [2.841477e-07] 
Layer 'conv1' biases: 1.372749e-06 [7.422494e-10] 
Layer 'conv2' weights[0]: 5.616228e-03 [2.825433e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.441483e-09] 
Layer 'conv3' weights[0]: 5.615090e-03 [2.843647e-07] 
Layer 'conv3' biases: 2.359796e-05 [2.383775e-08] 
Layer 'conv4' weights[0]: 5.638049e-03 [2.874586e-07] 
Layer 'conv4' biases: 1.000011e+00 [3.232634e-07] 
Layer 'conv5' weights[0]: 5.689905e-03 [2.670054e-06] 
Layer 'conv5' biases: 9.992135e-01 [2.884951e-06] 
Layer 'fc6' weights[0]: 7.321725e-03 [6.016284e-08] 
Layer 'fc6' biases: 9.999967e-01 [5.669559e-08] 
Layer 'fc7' weights[0]: 7.675479e-03 [1.327089e-07] 
Layer 'fc7' biases: 9.998958e-01 [1.702575e-07] 
Layer 'fc8' weights[0]: 4.244270e-03 [1.727127e-05] 
Layer 'fc8' biases: 8.589580e-03 [2.694937e-05] 
Train error last 800 batches: 0.656512
-------------------------------------------------------
Not saving because 0.473163 > 0.299667 (9.300: -1.18%)
======================================================= (2.439 sec)
9.601... logprob:  0.667485, 0.286458 (1.483 sec)
9.602... logprob:  0.491021, 0.225260 (1.436 sec)
9.603... logprob:  0.532686, 0.239583 (1.439 sec)
9.604... logprob:  0.632417, 0.291667 (1.471 sec)
9.605... logprob:  0.738238, 0.329427 (1.434 sec)
9.606... logprob:  0.634170, 0.302083 (1.428 sec)
9.607... logprob:  0.686890, 0.313802 (1.431 sec)
9.608... logprob:  0.553087, 0.250000 (1.424 sec)
9.609... logprob:  0.544753, 0.256510 (1.434 sec)
9.610... logprob:  0.771739, 0.302083 (1.468 sec)
9.611... logprob:  0.694149, 0.296875 (1.439 sec)
9.612... logprob:  0.681517, 0.294271 (1.450 sec)
9.613... logprob:  0.621862, 0.282552 (1.453 sec)
9.614... logprob:  0.677801, 0.305990 (1.444 sec)
9.615... logprob:  0.539063, 0.236979 (1.432 sec)
9.616... logprob:  0.691858, 0.294271 (1.416 sec)
9.617... logprob:  0.667716, 0.283854 (1.427 sec)
9.618... logprob:  0.826971, 0.341146 (1.438 sec)
9.619... logprob:  0.715817, 0.308594 (1.447 sec)
9.620... logprob:  0.711487, 0.332031 (1.450 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.479890, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.620661e-03 [2.839385e-07] 
Layer 'conv1' biases: 1.376958e-06 [1.027955e-09] 
Layer 'conv2' weights[0]: 5.610651e-03 [2.835122e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.523650e-09] 
Layer 'conv3' weights[0]: 5.609446e-03 [2.850247e-07] 
Layer 'conv3' biases: 2.358185e-05 [3.006042e-08] 
Layer 'conv4' weights[0]: 5.632410e-03 [2.903446e-07] 
Layer 'conv4' biases: 1.000010e+00 [4.255166e-07] 
Layer 'conv5' weights[0]: 5.683914e-03 [3.496610e-06] 
Layer 'conv5' biases: 9.992116e-01 [3.817343e-06] 
Layer 'fc6' weights[0]: 7.320946e-03 [7.660093e-08] 
Layer 'fc6' biases: 9.999967e-01 [8.015051e-08] 
Layer 'fc7' weights[0]: 7.674715e-03 [1.768719e-07] 
Layer 'fc7' biases: 9.998959e-01 [2.961189e-07] 
Layer 'fc8' weights[0]: 4.269623e-03 [2.450974e-05] 
Layer 'fc8' biases: 8.790738e-03 [5.211153e-05] 
Train error last 800 batches: 0.656950
-------------------------------------------------------
Not saving because 0.479890 > 0.299667 (9.300: -1.18%)
======================================================= (2.365 sec)
9.621... logprob:  0.563020, 0.225260 (1.451 sec)
9.622... logprob:  0.580767, 0.253906 (1.450 sec)
9.623... logprob:  0.580091, 0.243490 (1.467 sec)
9.624... logprob:  0.650337, 0.268229 (1.432 sec)
9.625... logprob:  0.706806, 0.298177 (1.421 sec)
9.626... logprob:  0.611693, 0.268229 (1.432 sec)
9.627... logprob:  0.634639, 0.269531 (1.433 sec)
9.628... logprob:  0.669527, 0.287760 (1.429 sec)
9.629... logprob:  0.586951, 0.265625 (1.474 sec)
9.630... logprob:  0.720694, 0.330729 (1.442 sec)
9.631... logprob:  0.788862, 0.317708 (1.432 sec)
9.632... logprob:  0.648459, 0.283854 (1.475 sec)
9.633... logprob:  0.522060, 0.240885 (1.424 sec)
9.634... logprob:  0.853372, 0.378906 (1.427 sec)
9.635... logprob:  0.630793, 0.282552 (1.435 sec)
9.636... logprob:  0.705644, 0.303385 (1.427 sec)
9.637... logprob:  0.548901, 0.234375 (1.429 sec)
9.638... logprob:  0.754321, 0.324219 (1.473 sec)
9.639... logprob:  0.597521, 0.273438 (1.430 sec)
9.640... logprob:  0.862997, 0.395833 (1.434 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.496166, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.615073e-03 [2.832638e-07] 
Layer 'conv1' biases: 1.382617e-06 [8.277664e-10] 
Layer 'conv2' weights[0]: 5.605020e-03 [2.823931e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.427205e-09] 
Layer 'conv3' weights[0]: 5.603807e-03 [2.839340e-07] 
Layer 'conv3' biases: 2.365224e-05 [2.639588e-08] 
Layer 'conv4' weights[0]: 5.626766e-03 [2.868602e-07] 
Layer 'conv4' biases: 1.000009e+00 [3.517290e-07] 
Layer 'conv5' weights[0]: 5.677952e-03 [2.984544e-06] 
Layer 'conv5' biases: 9.992219e-01 [3.116254e-06] 
Layer 'fc6' weights[0]: 7.320194e-03 [6.450714e-08] 
Layer 'fc6' biases: 9.999966e-01 [6.296540e-08] 
Layer 'fc7' weights[0]: 7.673969e-03 [1.478760e-07] 
Layer 'fc7' biases: 9.998951e-01 [2.027840e-07] 
Layer 'fc8' weights[0]: 4.222757e-03 [2.038468e-05] 
Layer 'fc8' biases: 8.436317e-03 [3.465799e-05] 
Train error last 800 batches: 0.657079
-------------------------------------------------------
Not saving because 0.496166 > 0.299667 (9.300: -1.18%)
======================================================= (2.344 sec)
9.641... logprob:  0.652829, 0.252604 (1.481 sec)
9.642... logprob:  0.720814, 0.317708 (1.427 sec)
9.643... logprob:  0.829646, 0.329427 (1.424 sec)
9.644... logprob:  0.550402, 0.251302 (1.426 sec)
9.645... logprob:  0.674289, 0.308594 (1.426 sec)
9.646... logprob:  0.570143, 0.242188 (1.428 sec)
9.647... logprob:  0.703372, 0.290365 (1.478 sec)
9.648... logprob:  0.762739, 0.329427 (1.429 sec)
9.649... logprob:  0.676526, 0.298177 (1.436 sec)
9.650... logprob:  0.609013, 0.272135 (1.475 sec)
9.651... logprob:  0.651079, 0.285156 (1.432 sec)
9.652... logprob:  0.808515, 0.347656 (1.432 sec)
9.653... logprob:  0.776179, 0.333333 (1.431 sec)
9.654... logprob:  0.719721, 0.295573 (1.422 sec)
9.655... logprob:  0.619887, 0.290364 (1.426 sec)
9.656... logprob:  0.622088, 0.289062 (1.473 sec)
9.657... logprob:  0.666961, 0.283854 (1.432 sec)
9.658... logprob:  0.626249, 0.287760 (1.447 sec)
9.659... logprob:  0.691281, 0.272135 (1.468 sec)
9.660... logprob:  0.641081, 0.283854 (1.435 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.519244, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.609482e-03 [2.827579e-07] 
Layer 'conv1' biases: 1.389783e-06 [8.562749e-10] 
Layer 'conv2' weights[0]: 5.599435e-03 [2.819159e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.017640e-09] 
Layer 'conv3' weights[0]: 5.598205e-03 [2.835265e-07] 
Layer 'conv3' biases: 2.368100e-05 [2.700217e-08] 
Layer 'conv4' weights[0]: 5.621160e-03 [2.856553e-07] 
Layer 'conv4' biases: 1.000008e+00 [3.154615e-07] 
Layer 'conv5' weights[0]: 5.672622e-03 [2.479397e-06] 
Layer 'conv5' biases: 9.992279e-01 [2.654905e-06] 
Layer 'fc6' weights[0]: 7.319404e-03 [6.111144e-08] 
Layer 'fc6' biases: 9.999967e-01 [5.805928e-08] 
Layer 'fc7' weights[0]: 7.673195e-03 [1.366389e-07] 
Layer 'fc7' biases: 9.998946e-01 [1.712206e-07] 
Layer 'fc8' weights[0]: 4.198942e-03 [1.861976e-05] 
Layer 'fc8' biases: 8.275537e-03 [1.872660e-05] 
Train error last 800 batches: 0.657186
-------------------------------------------------------
Not saving because 0.519244 > 0.299667 (9.300: -1.18%)
======================================================= (2.416 sec)
9.661... logprob:  0.646491, 0.292969 (1.448 sec)
9.662... logprob:  0.648190, 0.299479 (1.425 sec)
9.663... logprob:  0.551911, 0.221354 (1.418 sec)
9.664... logprob:  0.579651, 0.244792 (1.432 sec)
9.665... logprob:  0.632154, 0.277344 (1.453 sec)
9.666... logprob:  0.643240, 0.298177 (1.448 sec)
9.667... logprob:  0.691425, 0.291667 (1.447 sec)
9.668... logprob:  0.741298, 0.316406 (1.446 sec)
9.669... logprob:  0.706869, 0.298177 (1.453 sec)
9.670... logprob:  0.605755, 0.278646 (1.434 sec)
9.671... logprob:  0.604750, 0.270833 (1.417 sec)
9.672... logprob:  0.658884, 0.299479 (1.426 sec)
9.673... logprob:  0.597685, 0.264323 (1.428 sec)
9.674... logprob:  0.676516, 0.296875 (1.437 sec)
9.675... logprob:  0.496813, 0.203125 (1.459 sec)
9.676... logprob:  0.534391, 0.227865 (1.445 sec)
9.677... logprob:  0.625886, 0.256510 (1.441 sec)
9.678... logprob:  0.743588, 0.322917 (1.477 sec)
9.679... logprob:  0.721008, 0.328125 (1.425 sec)
9.680... logprob:  0.538249, 0.247396 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.489448, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.603868e-03 [2.831211e-07] 
Layer 'conv1' biases: 1.393667e-06 [7.702676e-10] 
Layer 'conv2' weights[0]: 5.593824e-03 [2.813780e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.705372e-09] 
Layer 'conv3' weights[0]: 5.592635e-03 [2.820510e-07] 
Layer 'conv3' biases: 2.372599e-05 [2.102485e-08] 
Layer 'conv4' weights[0]: 5.615515e-03 [2.852074e-07] 
Layer 'conv4' biases: 1.000009e+00 [3.170760e-07] 
Layer 'conv5' weights[0]: 5.667416e-03 [2.420976e-06] 
Layer 'conv5' biases: 9.992073e-01 [2.671933e-06] 
Layer 'fc6' weights[0]: 7.318632e-03 [5.837977e-08] 
Layer 'fc6' biases: 9.999967e-01 [5.413458e-08] 
Layer 'fc7' weights[0]: 7.672392e-03 [1.282200e-07] 
Layer 'fc7' biases: 9.998958e-01 [1.541928e-07] 
Layer 'fc8' weights[0]: 4.285864e-03 [1.563021e-05] 
Layer 'fc8' biases: 8.938714e-03 [1.994847e-05] 
Train error last 800 batches: 0.656876
-------------------------------------------------------
Not saving because 0.489448 > 0.299667 (9.300: -1.18%)
======================================================= (2.370 sec)
9.681... logprob:  0.571070, 0.269531 (1.433 sec)
9.682... logprob:  0.559919, 0.264323 (1.433 sec)
9.683... logprob:  0.647177, 0.279948 (1.431 sec)
9.684... logprob:  0.582500, 0.260417 (1.469 sec)
9.685... logprob:  0.507548, 0.216146 (1.440 sec)
9.686... logprob:  0.523146, 0.240885 (1.427 sec)
9.687... logprob:  0.578679, 0.268229 (1.479 sec)
9.688... logprob:  0.552962, 0.259115 (1.430 sec)
9.689... logprob:  0.744015, 0.329427 (1.430 sec)
9.690... logprob:  0.741301, 0.309896 (1.430 sec)
9.691... logprob:  0.670090, 0.289062 (1.421 sec)
9.692... logprob:  0.579615, 0.291667 (1.429 sec)
9.693... logprob:  0.747527, 0.371094 (1.481 sec)
9.694... logprob:  0.598658, 0.272135 (1.436 sec)
9.695... logprob:  0.557360, 0.242187 (1.432 sec)
9.696... logprob:  0.645592, 0.272135 (1.473 sec)
9.697... logprob:  0.601062, 0.269531 (1.442 sec)
9.698... logprob:  0.795198, 0.332031 (1.433 sec)
9.699... logprob:  0.714777, 0.285156 (1.429 sec)
9.700... logprob:  0.631394, 0.287760 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.393776, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.598264e-03 [2.824332e-07] 
Layer 'conv1' biases: 1.393812e-06 [9.126583e-10] 
Layer 'conv2' weights[0]: 5.588259e-03 [2.817788e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.288417e-09] 
Layer 'conv3' weights[0]: 5.586994e-03 [2.835071e-07] 
Layer 'conv3' biases: 2.381450e-05 [2.997582e-08] 
Layer 'conv4' weights[0]: 5.609910e-03 [2.876274e-07] 
Layer 'conv4' biases: 1.000010e+00 [4.269556e-07] 
Layer 'conv5' weights[0]: 5.662580e-03 [3.362818e-06] 
Layer 'conv5' biases: 9.992006e-01 [3.505442e-06] 
Layer 'fc6' weights[0]: 7.317893e-03 [7.133007e-08] 
Layer 'fc6' biases: 9.999966e-01 [7.318992e-08] 
Layer 'fc7' weights[0]: 7.671662e-03 [1.643330e-07] 
Layer 'fc7' biases: 9.998964e-01 [2.618428e-07] 
Layer 'fc8' weights[0]: 4.299560e-03 [2.174413e-05] 
Layer 'fc8' biases: 9.017083e-03 [4.270371e-05] 
Train error last 800 batches: 0.656474
-------------------------------------------------------
Not saving because 0.393776 > 0.299667 (9.300: -1.18%)
======================================================= (2.344 sec)
9.701... logprob:  0.578514, 0.282552 (1.434 sec)
9.702... logprob:  0.740004, 0.296875 (1.476 sec)
9.703... logprob:  0.617105, 0.274740 (1.432 sec)
9.704... logprob:  0.583363, 0.240885 (1.447 sec)
9.705... logprob:  0.666208, 0.299479 (1.469 sec)
9.706... logprob:  0.639901, 0.312500 (1.427 sec)
9.707... logprob:  0.763816, 0.345052 (1.434 sec)
9.708... logprob:  0.670425, 0.305990 (1.427 sec)
9.709... logprob:  0.670083, 0.263021 (1.423 sec)
9.710... logprob:  0.780313, 0.345052 (1.432 sec)
9.711... logprob:  0.633236, 0.295573 (1.460 sec)
9.712... logprob:  0.643111, 0.282552 (1.444 sec)
9.713... logprob:  0.810514, 0.342448 (1.446 sec)
9.714... logprob:  0.684923, 0.302083 (1.447 sec)
9.715... logprob:  0.688766, 0.305990 (1.454 sec)
9.716... logprob:  0.516145, 0.209635 (1.438 sec)
9.717... logprob:  0.621978, 0.298177 (1.419 sec)
9.718... logprob:  0.681172, 0.303385 (1.423 sec)
9.719... logprob:  0.613877, 0.279948 (1.432 sec)
9.720... logprob:  0.675332, 0.298177 (1.438 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.454229, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.592671e-03 [2.839223e-07] 
Layer 'conv1' biases: 1.391961e-06 [6.596196e-10] 
Layer 'conv2' weights[0]: 5.582678e-03 [2.809781e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.998702e-09] 
Layer 'conv3' weights[0]: 5.581419e-03 [2.817114e-07] 
Layer 'conv3' biases: 2.388003e-05 [2.177690e-08] 
Layer 'conv4' weights[0]: 5.604352e-03 [2.851235e-07] 
Layer 'conv4' biases: 1.000013e+00 [2.972115e-07] 
Layer 'conv5' weights[0]: 5.658143e-03 [2.380604e-06] 
Layer 'conv5' biases: 9.992121e-01 [2.521396e-06] 
Layer 'fc6' weights[0]: 7.317117e-03 [6.068012e-08] 
Layer 'fc6' biases: 9.999967e-01 [5.713753e-08] 
Layer 'fc7' weights[0]: 7.670875e-03 [1.344814e-07] 
Layer 'fc7' biases: 9.998943e-01 [1.743857e-07] 
Layer 'fc8' weights[0]: 4.227220e-03 [1.683214e-05] 
Layer 'fc8' biases: 8.473499e-03 [2.452281e-05] 
Train error last 800 batches: 0.656998
-------------------------------------------------------
Not saving because 0.454229 > 0.299667 (9.300: -1.18%)
======================================================= (2.406 sec)
9.721... logprob:  0.621582, 0.283854 (1.462 sec)
9.722... logprob:  0.797482, 0.358073 (1.455 sec)
9.723... logprob:  0.679604, 0.283854 (1.442 sec)
9.724... logprob:  0.678831, 0.315104 (1.468 sec)
9.725... logprob:  0.734739, 0.303385 (1.426 sec)
9.726... logprob:  0.626380, 0.269531 (1.422 sec)
9.727... logprob:  0.623401, 0.269531 (1.427 sec)
9.728... logprob:  0.674161, 0.298177 (1.432 sec)
9.729... logprob:  0.574057, 0.244792 (1.426 sec)
9.730... logprob:  0.765999, 0.317708 (1.472 sec)
9.731... logprob:  0.637203, 0.274740 (1.444 sec)
9.732... logprob:  0.493348, 0.220052 (1.437 sec)
9.733... logprob:  0.789477, 0.334635 (1.479 sec)
9.734... logprob:  0.628118, 0.236979 (1.426 sec)
9.735... logprob:  0.791053, 0.313802 (1.442 sec)
9.736... logprob:  0.811689, 0.341146 (1.429 sec)
9.737... logprob:  0.804038, 0.320312 (1.424 sec)
9.738... logprob:  0.644880, 0.287760 (1.428 sec)
9.739... logprob:  0.727346, 0.312500 (1.477 sec)
9.740... logprob:  0.664015, 0.269531 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.469378, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.587066e-03 [2.832902e-07] 
Layer 'conv1' biases: 1.392734e-06 [9.846650e-10] 
Layer 'conv2' weights[0]: 5.577095e-03 [2.808999e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.593343e-09] 
Layer 'conv3' weights[0]: 5.575911e-03 [2.823498e-07] 
Layer 'conv3' biases: 2.395884e-05 [2.771014e-08] 
Layer 'conv4' weights[0]: 5.598733e-03 [2.869596e-07] 
Layer 'conv4' biases: 1.000015e+00 [3.988801e-07] 
Layer 'conv5' weights[0]: 5.653333e-03 [3.415541e-06] 
Layer 'conv5' biases: 9.992142e-01 [3.653069e-06] 
Layer 'fc6' weights[0]: 7.316394e-03 [7.496785e-08] 
Layer 'fc6' biases: 9.999965e-01 [7.772703e-08] 
Layer 'fc7' weights[0]: 7.670120e-03 [1.736510e-07] 
Layer 'fc7' biases: 9.998937e-01 [2.712700e-07] 
Layer 'fc8' weights[0]: 4.210562e-03 [2.348129e-05] 
Layer 'fc8' biases: 8.387916e-03 [4.421702e-05] 
Train error last 800 batches: 0.657870
-------------------------------------------------------
Not saving because 0.469378 > 0.299667 (9.300: -1.18%)
======================================================= (2.355 sec)
9.741... logprob:  0.662474, 0.302083 (1.436 sec)
9.742... logprob:  0.693430, 0.291667 (1.483 sec)
9.743... logprob:  0.582250, 0.261719 (1.424 sec)
9.744... logprob:  0.752864, 0.292969 (1.430 sec)
9.745... logprob:  0.641953, 0.285156 (1.426 sec)
9.746... logprob:  0.738912, 0.329427 (1.424 sec)
9.747... logprob:  0.587871, 0.272135 (1.427 sec)
9.748... logprob:  0.673246, 0.308594 (1.477 sec)
9.749... logprob:  0.613134, 0.263021 (1.428 sec)
9.750... logprob:  0.633786, 0.253906 (1.443 sec)
9.751... logprob:  0.559087, 0.233073 (1.469 sec)
9.752... logprob:  0.766055, 0.332031 (1.425 sec)
9.753... logprob:  0.661103, 0.265625 (1.430 sec)
9.754... logprob:  0.669260, 0.305990 (1.429 sec)
9.755... logprob:  0.675348, 0.285156 (1.421 sec)
9.756... logprob:  0.598833, 0.259115 (1.429 sec)
9.757... logprob:  0.784336, 0.354167 (1.466 sec)
9.758... logprob:  0.618421, 0.282552 (1.436 sec)
9.759... logprob:  0.712450, 0.333333 (1.451 sec)
9.760... logprob:  0.784147, 0.322917 (1.458 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.569463, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.581523e-03 [2.822591e-07] 
Layer 'conv1' biases: 1.398002e-06 [7.961067e-10] 
Layer 'conv2' weights[0]: 5.571558e-03 [2.806616e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.926915e-09] 
Layer 'conv3' weights[0]: 5.570309e-03 [2.821962e-07] 
Layer 'conv3' biases: 2.393360e-05 [2.762038e-08] 
Layer 'conv4' weights[0]: 5.593153e-03 [2.852618e-07] 
Layer 'conv4' biases: 1.000014e+00 [3.531499e-07] 
Layer 'conv5' weights[0]: 5.647477e-03 [2.418701e-06] 
Layer 'conv5' biases: 9.992172e-01 [2.509217e-06] 
Layer 'fc6' weights[0]: 7.315638e-03 [6.099750e-08] 
Layer 'fc6' biases: 9.999965e-01 [5.775790e-08] 
Layer 'fc7' weights[0]: 7.669349e-03 [1.363779e-07] 
Layer 'fc7' biases: 9.998940e-01 [1.581033e-07] 
Layer 'fc8' weights[0]: 4.230053e-03 [1.615465e-05] 
Layer 'fc8' biases: 8.516211e-03 [1.701991e-05] 
Train error last 800 batches: 0.657975
-------------------------------------------------------
Not saving because 0.569463 > 0.299667 (9.300: -1.18%)
======================================================= (2.363 sec)
9.761... logprob:  0.646628, 0.272135 (1.450 sec)
9.762... logprob:  0.746195, 0.311198 (1.438 sec)
9.763... logprob:  0.695528, 0.312500 (1.424 sec)
9.764... logprob:  0.761345, 0.365885 (1.417 sec)
9.765... logprob:  0.512543, 0.229167 (1.433 sec)
9.766... logprob:  0.692505, 0.300781 (1.446 sec)
9.767... logprob:  0.560559, 0.265625 (1.453 sec)
9.768... logprob:  0.705017, 0.313802 (1.463 sec)
9.769... logprob:  0.758728, 0.312500 (1.465 sec)
9.770... logprob:  0.520764, 0.230469 (1.469 sec)
9.771... logprob:  0.711247, 0.296875 (1.453 sec)
9.772... logprob:  0.648584, 0.313802 (1.442 sec)
9.773... logprob:  0.717203, 0.319010 (1.462 sec)
9.774... logprob:  0.564975, 0.253906 (1.454 sec)
9.775... logprob:  0.699248, 0.289062 (1.457 sec)
9.776... logprob:  0.647382, 0.287760 (1.470 sec)
9.777... logprob:  0.626257, 0.274740 (1.467 sec)
9.778... logprob:  0.686390, 0.309896 (1.459 sec)
9.779... logprob:  0.682058, 0.300781 (1.480 sec)
9.780... logprob:  0.604642, 0.282552 (1.449 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.513725, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.575927e-03 [2.813671e-07] 
Layer 'conv1' biases: 1.402819e-06 [5.628329e-10] 
Layer 'conv2' weights[0]: 5.565960e-03 [2.800819e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.769199e-09] 
Layer 'conv3' weights[0]: 5.564765e-03 [2.812291e-07] 
Layer 'conv3' biases: 2.393804e-05 [2.276509e-08] 
Layer 'conv4' weights[0]: 5.587546e-03 [2.839966e-07] 
Layer 'conv4' biases: 1.000014e+00 [3.069255e-07] 
Layer 'conv5' weights[0]: 5.642147e-03 [2.416117e-06] 
Layer 'conv5' biases: 9.992057e-01 [2.632473e-06] 
Layer 'fc6' weights[0]: 7.314891e-03 [6.026779e-08] 
Layer 'fc6' biases: 9.999966e-01 [5.695588e-08] 
Layer 'fc7' weights[0]: 7.668546e-03 [1.321570e-07] 
Layer 'fc7' biases: 9.998947e-01 [1.558471e-07] 
Layer 'fc8' weights[0]: 4.260764e-03 [1.566922e-05] 
Layer 'fc8' biases: 8.758120e-03 [1.743023e-05] 
Train error last 800 batches: 0.658351
-------------------------------------------------------
Not saving because 0.513725 > 0.299667 (9.300: -1.18%)
======================================================= (2.362 sec)
9.781... logprob:  0.584798, 0.256510 (1.445 sec)
9.782... logprob:  0.563897, 0.243490 (1.456 sec)
9.783... logprob:  0.705334, 0.300781 (1.452 sec)
9.784... logprob:  0.650743, 0.266927 (1.451 sec)
9.785... logprob:  0.745546, 0.313802 (1.490 sec)
9.786... logprob:  0.697744, 0.290365 (1.463 sec)
9.787... logprob:  0.710309, 0.279948 (1.454 sec)
9.788... logprob:  0.694997, 0.290365 (1.486 sec)
9.789... logprob:  0.545495, 0.266927 (1.449 sec)
9.790... logprob:  0.600323, 0.277344 (1.441 sec)
9.791... logprob:  0.606745, 0.273438 (1.441 sec)
9.792... logprob:  0.567923, 0.268229 (1.455 sec)
9.793... logprob:  0.583606, 0.243490 (1.445 sec)
9.794... logprob:  0.667852, 0.296875 (1.481 sec)
9.795... logprob:  0.656894, 0.294271 (1.460 sec)
9.796... logprob:  0.671437, 0.281250 (1.460 sec)
9.797... logprob:  0.514103, 0.239583 (1.494 sec)
9.798... logprob:  0.555123, 0.239583 (1.446 sec)
9.799... logprob:  0.541732, 0.225260 (1.442 sec)
9.800... logprob:  0.570984, 0.222656 (1.400 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.445747, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.570356e-03 [2.813898e-07] 
Layer 'conv1' biases: 1.405793e-06 [6.866875e-10] 
Layer 'conv2' weights[0]: 5.560373e-03 [2.806106e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.166853e-09] 
Layer 'conv3' weights[0]: 5.559157e-03 [2.819535e-07] 
Layer 'conv3' biases: 2.397059e-05 [2.884013e-08] 
Layer 'conv4' weights[0]: 5.581985e-03 [2.862333e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.958732e-07] 
Layer 'conv5' weights[0]: 5.635930e-03 [2.803689e-06] 
Layer 'conv5' biases: 9.991966e-01 [2.932461e-06] 
Layer 'fc6' weights[0]: 7.314144e-03 [6.709440e-08] 
Layer 'fc6' biases: 9.999967e-01 [6.659246e-08] 
Layer 'fc7' weights[0]: 7.667706e-03 [1.546196e-07] 
Layer 'fc7' biases: 9.998947e-01 [2.451472e-07] 
Layer 'fc8' weights[0]: 4.297146e-03 [2.109833e-05] 
Layer 'fc8' biases: 9.054281e-03 [4.818532e-05] 
Train error last 800 batches: 0.657681
-------------------------------------------------------
Not saving because 0.445747 > 0.299667 (9.300: -1.18%)
======================================================= (2.349 sec)
10.1... logprob:  0.666612, 0.279948 (1.407 sec)
10.2... logprob:  0.633256, 0.291667 (1.449 sec)
10.3... logprob:  0.650016, 0.302083 (1.417 sec)
10.4... logprob:  0.665997, 0.309896 (1.404 sec)
10.5... logprob:  0.590547, 0.273437 (1.435 sec)
10.6... logprob:  0.652597, 0.295573 (1.389 sec)
10.7... logprob:  0.670676, 0.290365 (1.422 sec)
10.8... logprob:  0.588097, 0.233073 (1.393 sec)
10.9... logprob:  0.626245, 0.278646 (1.400 sec)
10.10... logprob:  0.569686, 0.244792 (1.407 sec)
10.11... logprob:  0.636523, 0.285156 (1.456 sec)
10.12... logprob:  0.668797, 0.279948 (1.398 sec)
10.13... logprob:  0.738802, 0.305990 (1.417 sec)
10.14... logprob:  0.708801, 0.302083 (1.394 sec)
10.15... logprob:  0.678154, 0.296875 (1.408 sec)
10.16... logprob:  0.679223, 0.299479 (1.394 sec)
10.17... logprob:  0.737651, 0.307292 (1.393 sec)
10.18... logprob:  0.576248, 0.257812 (1.393 sec)
10.19... logprob:  0.500991, 0.242187 (1.397 sec)
10.20... logprob:  0.733354, 0.320312 (1.396 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.435810, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.564796e-03 [2.803244e-07] 
Layer 'conv1' biases: 1.407299e-06 [7.205696e-10] 
Layer 'conv2' weights[0]: 5.554837e-03 [2.790457e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.563394e-09] 
Layer 'conv3' weights[0]: 5.553626e-03 [2.797421e-07] 
Layer 'conv3' biases: 2.400866e-05 [2.054975e-08] 
Layer 'conv4' weights[0]: 5.576399e-03 [2.828401e-07] 
Layer 'conv4' biases: 1.000014e+00 [3.080935e-07] 
Layer 'conv5' weights[0]: 5.631017e-03 [2.304336e-06] 
Layer 'conv5' biases: 9.991989e-01 [2.514430e-06] 
Layer 'fc6' weights[0]: 7.313376e-03 [5.929129e-08] 
Layer 'fc6' biases: 9.999967e-01 [5.562267e-08] 
Layer 'fc7' weights[0]: 7.666961e-03 [1.302272e-07] 
Layer 'fc7' biases: 9.998944e-01 [1.567951e-07] 
Layer 'fc8' weights[0]: 4.283886e-03 [1.556998e-05] 
Layer 'fc8' biases: 8.960323e-03 [1.771101e-05] 
Train error last 800 batches: 0.657731
-------------------------------------------------------
Not saving because 0.435810 > 0.299667 (9.300: -1.18%)
======================================================= (2.380 sec)
10.21... logprob:  0.688473, 0.311198 (1.410 sec)
10.22... logprob:  0.761240, 0.324219 (1.411 sec)
10.23... logprob:  0.704728, 0.307292 (1.409 sec)
10.24... logprob:  0.569690, 0.277344 (1.410 sec)
10.25... logprob:  0.531321, 0.247396 (1.403 sec)
10.26... logprob:  0.597786, 0.269531 (1.437 sec)
10.27... logprob:  0.685101, 0.298177 (1.382 sec)
10.28... logprob:  0.595694, 0.270833 (1.409 sec)
10.29... logprob:  0.591855, 0.255208 (1.414 sec)
10.30... logprob:  0.596872, 0.272135 (1.410 sec)
10.31... logprob:  0.660689, 0.300781 (1.395 sec)
10.32... logprob:  0.707001, 0.324219 (1.380 sec)
10.33... logprob:  0.732019, 0.337240 (1.444 sec)
10.34... logprob:  0.723436, 0.325521 (1.393 sec)
10.35... logprob:  0.487424, 0.226562 (1.398 sec)
10.36... logprob:  0.659593, 0.287760 (1.398 sec)
10.37... logprob:  0.682805, 0.305990 (1.406 sec)
10.38... logprob:  0.624977, 0.290365 (1.391 sec)
10.39... logprob:  0.856394, 0.345052 (1.430 sec)
10.40... logprob:  0.679561, 0.299479 (1.403 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.468763, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.559256e-03 [2.803790e-07] 
Layer 'conv1' biases: 1.412603e-06 [8.095979e-10] 
Layer 'conv2' weights[0]: 5.549321e-03 [2.796036e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.000380e-09] 
Layer 'conv3' weights[0]: 5.548062e-03 [2.813746e-07] 
Layer 'conv3' biases: 2.410189e-05 [2.899821e-08] 
Layer 'conv4' weights[0]: 5.570799e-03 [2.855095e-07] 
Layer 'conv4' biases: 1.000014e+00 [4.196874e-07] 
Layer 'conv5' weights[0]: 5.625739e-03 [2.987419e-06] 
Layer 'conv5' biases: 9.992030e-01 [3.204529e-06] 
Layer 'fc6' weights[0]: 7.312556e-03 [6.568990e-08] 
Layer 'fc6' biases: 9.999967e-01 [6.489589e-08] 
Layer 'fc7' weights[0]: 7.666176e-03 [1.492106e-07] 
Layer 'fc7' biases: 9.998940e-01 [2.109357e-07] 
Layer 'fc8' weights[0]: 4.286000e-03 [1.985934e-05] 
Layer 'fc8' biases: 8.943127e-03 [3.871110e-05] 
Train error last 800 batches: 0.657098
-------------------------------------------------------
Not saving because 0.468763 > 0.299667 (9.300: -1.18%)
======================================================= (2.404 sec)
10.41... logprob:  0.552268, 0.253906 (1.428 sec)
10.42... logprob:  0.571260, 0.222656 (1.418 sec)
10.43... logprob:  0.649386, 0.276042 (1.405 sec)
10.44... logprob:  0.681390, 0.316406 (1.434 sec)
10.45... logprob:  0.669631, 0.298177 (1.390 sec)
10.46... logprob:  0.766174, 0.332031 (1.397 sec)
10.47... logprob:  0.603141, 0.268229 (1.390 sec)
10.48... logprob:  0.736797, 0.347656 (1.417 sec)
10.49... logprob:  0.617483, 0.259115 (1.406 sec)
10.50... logprob:  0.637496, 0.265625 (1.433 sec)
10.51... logprob:  0.696412, 0.299479 (1.416 sec)
10.52... logprob:  0.699395, 0.294271 (1.396 sec)
10.53... logprob:  0.578003, 0.255208 (1.443 sec)
10.54... logprob:  0.591024, 0.273437 (1.389 sec)
10.55... logprob:  0.628738, 0.299479 (1.389 sec)
10.56... logprob:  0.604018, 0.266927 (1.396 sec)
10.57... logprob:  0.724347, 0.320312 (1.425 sec)
10.58... logprob:  0.635107, 0.292969 (1.399 sec)
10.59... logprob:  0.607324, 0.308594 (1.460 sec)
10.60... logprob:  0.704791, 0.295573 (1.410 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.397246, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.553674e-03 [2.801668e-07] 
Layer 'conv1' biases: 1.414194e-06 [6.638196e-10] 
Layer 'conv2' weights[0]: 5.543738e-03 [2.791287e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.971185e-09] 
Layer 'conv3' weights[0]: 5.542559e-03 [2.802412e-07] 
Layer 'conv3' biases: 2.416711e-05 [2.519588e-08] 
Layer 'conv4' weights[0]: 5.565232e-03 [2.831950e-07] 
Layer 'conv4' biases: 1.000014e+00 [3.274402e-07] 
Layer 'conv5' weights[0]: 5.620571e-03 [2.521074e-06] 
Layer 'conv5' biases: 9.992048e-01 [2.632317e-06] 
Layer 'fc6' weights[0]: 7.311823e-03 [5.991697e-08] 
Layer 'fc6' biases: 9.999966e-01 [5.633000e-08] 
Layer 'fc7' weights[0]: 7.665438e-03 [1.358687e-07] 
Layer 'fc7' biases: 9.998937e-01 [1.771844e-07] 
Layer 'fc8' weights[0]: 4.279980e-03 [1.732181e-05] 
Layer 'fc8' biases: 8.819788e-03 [2.818717e-05] 
Train error last 800 batches: 0.657068
-------------------------------------------------------
Not saving because 0.397246 > 0.299667 (9.300: -1.18%)
======================================================= (2.376 sec)
10.61... logprob:  0.600185, 0.278646 (1.431 sec)
10.62... logprob:  0.751399, 0.302083 (1.461 sec)
10.63... logprob:  0.612907, 0.292969 (1.432 sec)
10.64... logprob:  0.668910, 0.291667 (1.406 sec)
10.65... logprob:  0.734782, 0.335938 (1.397 sec)
10.66... logprob:  0.573598, 0.244792 (1.440 sec)
10.67... logprob:  0.514538, 0.242187 (1.382 sec)
10.68... logprob:  0.613176, 0.273438 (1.390 sec)
10.69... logprob:  0.735945, 0.309896 (1.425 sec)
10.70... logprob:  0.573448, 0.259115 (1.420 sec)
10.71... logprob:  0.568210, 0.247396 (1.455 sec)
10.72... logprob:  0.697786, 0.281250 (1.397 sec)
10.73... logprob:  0.673370, 0.289063 (1.418 sec)
10.74... logprob:  0.645261, 0.300781 (1.406 sec)
10.75... logprob:  0.545160, 0.250000 (1.413 sec)
10.76... logprob:  0.660819, 0.302083 (1.427 sec)
10.77... logprob:  0.588422, 0.264323 (1.424 sec)
10.78... logprob:  0.797175, 0.339844 (1.449 sec)
10.79... logprob:  0.715196, 0.339844 (1.403 sec)
10.80... logprob:  0.801600, 0.316406 (1.412 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.505468, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.548136e-03 [2.803125e-07] 
Layer 'conv1' biases: 1.411922e-06 [9.992201e-10] 
Layer 'conv2' weights[0]: 5.538218e-03 [2.793067e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.578876e-09] 
Layer 'conv3' weights[0]: 5.536958e-03 [2.814740e-07] 
Layer 'conv3' biases: 2.427263e-05 [3.351207e-08] 
Layer 'conv4' weights[0]: 5.559649e-03 [2.844449e-07] 
Layer 'conv4' biases: 1.000015e+00 [4.086844e-07] 
Layer 'conv5' weights[0]: 5.615319e-03 [3.288488e-06] 
Layer 'conv5' biases: 9.991958e-01 [3.465720e-06] 
Layer 'fc6' weights[0]: 7.311068e-03 [7.401629e-08] 
Layer 'fc6' biases: 9.999965e-01 [7.658760e-08] 
Layer 'fc7' weights[0]: 7.664710e-03 [1.721412e-07] 
Layer 'fc7' biases: 9.998939e-01 [2.794637e-07] 
Layer 'fc8' weights[0]: 4.310691e-03 [2.349888e-05] 
Layer 'fc8' biases: 9.056290e-03 [3.979422e-05] 
Train error last 800 batches: 0.657228
-------------------------------------------------------
Not saving because 0.505468 > 0.299667 (9.300: -1.18%)
======================================================= (2.350 sec)
10.81... logprob:  0.641833, 0.287760 (1.421 sec)
10.82... logprob:  0.544985, 0.269531 (1.422 sec)
10.83... logprob:  0.692793, 0.296875 (1.395 sec)
10.84... logprob:  0.690921, 0.285156 (1.458 sec)
10.85... logprob:  0.662453, 0.286458 (1.421 sec)
10.86... logprob:  0.695315, 0.300781 (1.408 sec)
10.87... logprob:  0.788451, 0.334635 (1.412 sec)
10.88... logprob:  0.771607, 0.321615 (1.400 sec)
10.89... logprob:  0.572838, 0.236979 (1.436 sec)
10.90... logprob:  0.784462, 0.335938 (1.386 sec)
10.91... logprob:  0.574458, 0.266927 (1.386 sec)
10.92... logprob:  0.662155, 0.289062 (1.401 sec)
10.93... logprob:  0.673990, 0.300781 (1.398 sec)
10.94... logprob:  0.640156, 0.282552 (1.378 sec)
10.95... logprob:  0.697036, 0.291667 (1.392 sec)
10.96... logprob:  0.787060, 0.304688 (1.401 sec)
10.97... logprob:  0.588552, 0.236979 (1.394 sec)
10.98... logprob:  0.611609, 0.283854 (1.428 sec)
10.99... logprob:  0.701772, 0.304688 (1.399 sec)
10.100... logprob:  0.577568, 0.257812 (1.399 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.388137, 0.062500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.542610e-03 [2.798619e-07] 
Layer 'conv1' biases: 1.412634e-06 [6.949112e-10] 
Layer 'conv2' weights[0]: 5.532694e-03 [2.782417e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.539929e-09] 
Layer 'conv3' weights[0]: 5.531440e-03 [2.790174e-07] 
Layer 'conv3' biases: 2.426198e-05 [2.155639e-08] 
Layer 'conv4' weights[0]: 5.554113e-03 [2.817540e-07] 
Layer 'conv4' biases: 1.000016e+00 [3.023941e-07] 
Layer 'conv5' weights[0]: 5.610474e-03 [2.751376e-06] 
Layer 'conv5' biases: 9.992120e-01 [3.036430e-06] 
Layer 'fc6' weights[0]: 7.310284e-03 [6.309271e-08] 
Layer 'fc6' biases: 9.999965e-01 [6.075361e-08] 
Layer 'fc7' weights[0]: 7.663899e-03 [1.399750e-07] 
Layer 'fc7' biases: 9.998923e-01 [1.801099e-07] 
Layer 'fc8' weights[0]: 4.230358e-03 [1.752944e-05] 
Layer 'fc8' biases: 8.523749e-03 [2.983742e-05] 
Train error last 800 batches: 0.656963
-------------------------------------------------------
Not saving because 0.388137 > 0.299667 (9.300: -1.18%)
======================================================= (2.411 sec)
10.101... logprob:  0.565652, 0.253906 (1.451 sec)
10.102... logprob:  0.703441, 0.319010 (1.388 sec)
10.103... logprob:  0.751330, 0.324219 (1.395 sec)
10.104... logprob:  0.633215, 0.278646 (1.403 sec)
10.105... logprob:  0.749468, 0.311198 (1.397 sec)
10.106... logprob:  0.659042, 0.279948 (1.393 sec)
10.107... logprob:  0.553134, 0.240885 (1.440 sec)
10.108... logprob:  0.796937, 0.332031 (1.389 sec)
10.109... logprob:  0.588922, 0.273437 (1.394 sec)
10.110... logprob:  0.672518, 0.313802 (1.391 sec)
10.111... logprob:  0.665700, 0.276042 (1.387 sec)
10.112... logprob:  0.640571, 0.282552 (1.395 sec)
10.113... logprob:  0.660602, 0.273437 (1.392 sec)
10.114... logprob:  0.631257, 0.268229 (1.428 sec)
10.115... logprob:  0.768974, 0.337240 (1.409 sec)
10.116... logprob:  0.620715, 0.274740 (1.396 sec)
10.117... logprob:  0.590939, 0.278646 (1.438 sec)
10.118... logprob:  0.598975, 0.268229 (1.380 sec)
10.119... logprob:  0.598844, 0.257812 (1.394 sec)
10.120... logprob:  0.761174, 0.311198 (1.393 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.425361, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.537038e-03 [2.798841e-07] 
Layer 'conv1' biases: 1.412067e-06 [6.408281e-10] 
Layer 'conv2' weights[0]: 5.527131e-03 [2.780885e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.921343e-09] 
Layer 'conv3' weights[0]: 5.525917e-03 [2.788296e-07] 
Layer 'conv3' biases: 2.428759e-05 [2.221600e-08] 
Layer 'conv4' weights[0]: 5.548545e-03 [2.814596e-07] 
Layer 'conv4' biases: 1.000017e+00 [2.913184e-07] 
Layer 'conv5' weights[0]: 5.605617e-03 [2.567036e-06] 
Layer 'conv5' biases: 9.992023e-01 [2.757948e-06] 
Layer 'fc6' weights[0]: 7.309514e-03 [6.083114e-08] 
Layer 'fc6' biases: 9.999965e-01 [5.760882e-08] 
Layer 'fc7' weights[0]: 7.663108e-03 [1.345642e-07] 
Layer 'fc7' biases: 9.998924e-01 [1.592912e-07] 
Layer 'fc8' weights[0]: 4.270771e-03 [1.614561e-05] 
Layer 'fc8' biases: 8.875646e-03 [1.834283e-05] 
Train error last 800 batches: 0.657324
-------------------------------------------------------
Not saving because 0.425361 > 0.299667 (9.300: -1.18%)
======================================================= (2.365 sec)
10.121... logprob:  0.635469, 0.291667 (1.402 sec)
10.122... logprob:  0.720044, 0.307292 (1.447 sec)
10.123... logprob:  0.637081, 0.302083 (1.387 sec)
10.124... logprob:  0.681792, 0.264323 (1.397 sec)
10.125... logprob:  0.670115, 0.322917 (1.394 sec)
10.126... logprob:  0.693487, 0.279948 (1.387 sec)
10.127... logprob:  0.690007, 0.296875 (1.397 sec)
10.128... logprob:  0.621507, 0.278646 (1.442 sec)
10.129... logprob:  0.767193, 0.309896 (1.413 sec)
10.130... logprob:  0.530358, 0.243490 (1.409 sec)
10.131... logprob:  0.730018, 0.321615 (1.404 sec)
10.132... logprob:  0.680365, 0.283854 (1.434 sec)
10.133... logprob:  0.635387, 0.272135 (1.380 sec)
10.134... logprob:  0.682777, 0.295573 (1.393 sec)
10.135... logprob:  0.706140, 0.304687 (1.401 sec)
10.136... logprob:  0.656153, 0.282552 (1.392 sec)
10.137... logprob:  0.696592, 0.292969 (1.380 sec)
10.138... logprob:  0.545555, 0.263021 (1.442 sec)
10.139... logprob:  0.629062, 0.308594 (1.391 sec)
10.140... logprob:  0.769645, 0.337240 (1.405 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.468108, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.531546e-03 [2.789067e-07] 
Layer 'conv1' biases: 1.414286e-06 [7.191564e-10] 
Layer 'conv2' weights[0]: 5.521641e-03 [2.775561e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.959712e-09] 
Layer 'conv3' weights[0]: 5.520402e-03 [2.783947e-07] 
Layer 'conv3' biases: 2.438630e-05 [2.245033e-08] 
Layer 'conv4' weights[0]: 5.543033e-03 [2.825051e-07] 
Layer 'conv4' biases: 1.000018e+00 [3.304533e-07] 
Layer 'conv5' weights[0]: 5.600805e-03 [2.494446e-06] 
Layer 'conv5' biases: 9.992102e-01 [2.705852e-06] 
Layer 'fc6' weights[0]: 7.308718e-03 [6.015242e-08] 
Layer 'fc6' biases: 9.999965e-01 [5.628615e-08] 
Layer 'fc7' weights[0]: 7.662327e-03 [1.336572e-07] 
Layer 'fc7' biases: 9.998910e-01 [1.617772e-07] 
Layer 'fc8' weights[0]: 4.238735e-03 [1.667278e-05] 
Layer 'fc8' biases: 8.636661e-03 [2.042151e-05] 
Train error last 800 batches: 0.657542
-------------------------------------------------------
Not saving because 0.468108 > 0.299667 (9.300: -1.18%)
======================================================= (2.382 sec)
10.141... logprob:  0.616992, 0.269531 (1.440 sec)
10.142... logprob:  0.739160, 0.350260 (1.393 sec)
10.143... logprob:  0.564468, 0.268229 (1.418 sec)
10.144... logprob:  0.675447, 0.278646 (1.414 sec)
10.145... logprob:  0.576473, 0.264323 (1.410 sec)
10.146... logprob:  0.667367, 0.291667 (1.411 sec)
10.147... logprob:  0.535125, 0.250000 (1.424 sec)
10.148... logprob:  0.699517, 0.332031 (1.384 sec)
10.149... logprob:  0.607719, 0.287760 (1.390 sec)
10.150... logprob:  0.596218, 0.259115 (1.391 sec)
10.151... logprob:  0.626006, 0.291667 (1.392 sec)
10.152... logprob:  0.914356, 0.361979 (1.392 sec)
10.153... logprob:  0.692241, 0.302083 (1.439 sec)
10.154... logprob:  0.715666, 0.313802 (1.395 sec)
10.155... logprob:  0.628870, 0.263021 (1.406 sec)
10.156... logprob:  0.591935, 0.272135 (1.433 sec)
10.157... logprob:  0.560784, 0.256510 (1.392 sec)
10.158... logprob:  0.741141, 0.324219 (1.396 sec)
10.159... logprob:  0.643430, 0.276042 (1.392 sec)
10.160... logprob:  0.666230, 0.295573 (1.386 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.469775, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.526009e-03 [2.794791e-07] 
Layer 'conv1' biases: 1.419192e-06 [6.703787e-10] 
Layer 'conv2' weights[0]: 5.516122e-03 [2.777504e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.487560e-09] 
Layer 'conv3' weights[0]: 5.514845e-03 [2.796646e-07] 
Layer 'conv3' biases: 2.448649e-05 [2.888183e-08] 
Layer 'conv4' weights[0]: 5.537484e-03 [2.830796e-07] 
Layer 'conv4' biases: 1.000014e+00 [3.778384e-07] 
Layer 'conv5' weights[0]: 5.593935e-03 [2.631650e-06] 
Layer 'conv5' biases: 9.992087e-01 [2.711544e-06] 
Layer 'fc6' weights[0]: 7.307975e-03 [6.092215e-08] 
Layer 'fc6' biases: 9.999964e-01 [5.768946e-08] 
Layer 'fc7' weights[0]: 7.661564e-03 [1.328036e-07] 
Layer 'fc7' biases: 9.998921e-01 [1.559017e-07] 
Layer 'fc8' weights[0]: 4.303288e-03 [1.661627e-05] 
Layer 'fc8' biases: 8.999368e-03 [2.340768e-05] 
Train error last 800 batches: 0.657583
-------------------------------------------------------
Not saving because 0.469775 > 0.299667 (9.300: -1.18%)
======================================================= (2.353 sec)
10.161... logprob:  0.563740, 0.260417 (1.403 sec)
10.162... logprob:  0.807803, 0.339844 (1.405 sec)
10.163... logprob:  0.687128, 0.308594 (1.419 sec)
10.164... logprob:  0.635521, 0.285156 (1.421 sec)
10.165... logprob:  0.791220, 0.320312 (1.417 sec)
10.166... logprob:  0.611027, 0.273437 (1.444 sec)
10.167... logprob:  0.632690, 0.291667 (1.446 sec)
10.168... logprob:  0.599513, 0.300781 (1.419 sec)
10.169... logprob:  0.638377, 0.260417 (1.453 sec)
10.170... logprob:  0.670841, 0.274739 (1.397 sec)
10.171... logprob:  0.802782, 0.333333 (1.418 sec)
10.172... logprob:  0.599719, 0.278646 (1.411 sec)
10.173... logprob:  0.680543, 0.290365 (1.415 sec)
10.174... logprob:  0.785566, 0.335938 (1.395 sec)
10.175... logprob:  0.674399, 0.273438 (1.459 sec)
10.176... logprob:  0.755881, 0.360677 (1.413 sec)
10.177... logprob:  0.501908, 0.226562 (1.419 sec)
10.178... logprob:  0.622297, 0.289062 (1.450 sec)
10.179... logprob:  0.622379, 0.279948 (1.404 sec)
10.180... logprob:  0.718899, 0.309896 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.517513, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.520506e-03 [2.787112e-07] 
Layer 'conv1' biases: 1.420890e-06 [7.605609e-10] 
Layer 'conv2' weights[0]: 5.510607e-03 [2.773897e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.204924e-09] 
Layer 'conv3' weights[0]: 5.509363e-03 [2.790560e-07] 
Layer 'conv3' biases: 2.455998e-05 [2.618538e-08] 
Layer 'conv4' weights[0]: 5.531923e-03 [2.824544e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.580788e-07] 
Layer 'conv5' weights[0]: 5.587885e-03 [2.794519e-06] 
Layer 'conv5' biases: 9.992143e-01 [3.000875e-06] 
Layer 'fc6' weights[0]: 7.307196e-03 [6.476715e-08] 
Layer 'fc6' biases: 9.999965e-01 [6.293592e-08] 
Layer 'fc7' weights[0]: 7.660819e-03 [1.501337e-07] 
Layer 'fc7' biases: 9.998909e-01 [2.142737e-07] 
Layer 'fc8' weights[0]: 4.283840e-03 [2.278256e-05] 
Layer 'fc8' biases: 8.896069e-03 [4.133188e-05] 
Train error last 800 batches: 0.657732
-------------------------------------------------------
Not saving because 0.517513 > 0.299667 (9.300: -1.18%)
======================================================= (2.370 sec)
10.181... logprob:  0.729116, 0.311198 (1.427 sec)
10.182... logprob:  0.578687, 0.281250 (1.416 sec)
10.183... logprob:  0.695734, 0.289062 (1.417 sec)
10.184... logprob:  0.736843, 0.330729 (1.410 sec)
10.185... logprob:  0.554512, 0.261719 (1.392 sec)
10.186... logprob:  0.513638, 0.233073 (1.392 sec)
10.187... logprob:  0.805640, 0.335937 (1.396 sec)
10.188... logprob:  0.666699, 0.282552 (1.396 sec)
10.189... logprob:  0.614270, 0.274740 (1.380 sec)
10.190... logprob:  0.682388, 0.321614 (1.433 sec)
10.191... logprob:  0.779926, 0.326823 (1.401 sec)
10.192... logprob:  0.660096, 0.320312 (1.410 sec)
10.193... logprob:  0.550970, 0.230469 (1.407 sec)
10.194... logprob:  0.606214, 0.242188 (1.414 sec)
10.195... logprob:  0.543115, 0.263021 (1.397 sec)
10.196... logprob:  0.649089, 0.295573 (1.386 sec)
10.197... logprob:  0.682376, 0.309896 (1.394 sec)
10.198... logprob:  0.633282, 0.289062 (1.393 sec)
10.199... logprob:  0.637880, 0.259115 (1.389 sec)
10.200... logprob:  0.603382, 0.259115 (1.435 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.458351, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.514965e-03 [2.781732e-07] 
Layer 'conv1' biases: 1.421967e-06 [6.900738e-10] 
Layer 'conv2' weights[0]: 5.505089e-03 [2.769225e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.036410e-09] 
Layer 'conv3' weights[0]: 5.503831e-03 [2.778002e-07] 
Layer 'conv3' biases: 2.458682e-05 [2.228359e-08] 
Layer 'conv4' weights[0]: 5.526417e-03 [2.808129e-07] 
Layer 'conv4' biases: 1.000013e+00 [2.904376e-07] 
Layer 'conv5' weights[0]: 5.582580e-03 [2.453487e-06] 
Layer 'conv5' biases: 9.992041e-01 [2.596359e-06] 
Layer 'fc6' weights[0]: 7.306412e-03 [5.910852e-08] 
Layer 'fc6' biases: 9.999965e-01 [5.488508e-08] 
Layer 'fc7' weights[0]: 7.660052e-03 [1.304820e-07] 
Layer 'fc7' biases: 9.998921e-01 [1.554097e-07] 
Layer 'fc8' weights[0]: 4.341426e-03 [1.560463e-05] 
Layer 'fc8' biases: 9.285488e-03 [1.916634e-05] 
Train error last 800 batches: 0.657958
-------------------------------------------------------
Not saving because 0.458351 > 0.299667 (9.300: -1.18%)
======================================================= (2.377 sec)
10.201... logprob:  0.738390, 0.333333 (1.409 sec)
10.202... logprob:  0.701115, 0.285156 (1.405 sec)
10.203... logprob:  0.672394, 0.276042 (1.441 sec)
10.204... logprob:  0.720116, 0.312500 (1.390 sec)
10.205... logprob:  0.576081, 0.257812 (1.397 sec)
10.206... logprob:  0.583759, 0.269531 (1.409 sec)
10.207... logprob:  0.665932, 0.274740 (1.385 sec)
10.208... logprob:  0.681278, 0.317708 (1.391 sec)
10.209... logprob:  0.596678, 0.250000 (1.413 sec)
10.210... logprob:  0.758002, 0.352865 (1.409 sec)
10.211... logprob:  0.747240, 0.296875 (1.409 sec)
10.212... logprob:  0.794234, 0.338542 (1.412 sec)
10.213... logprob:  0.659121, 0.300781 (1.454 sec)
10.214... logprob:  0.731435, 0.319010 (1.424 sec)
10.215... logprob:  0.738637, 0.329427 (1.408 sec)
10.216... logprob:  0.645765, 0.290365 (1.461 sec)
10.217... logprob:  0.605608, 0.299479 (1.393 sec)
10.218... logprob:  0.728626, 0.324219 (1.419 sec)
10.219... logprob:  0.668617, 0.287760 (1.410 sec)
10.220... logprob:  0.712514, 0.307292 (1.413 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.530831, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.509454e-03 [2.779550e-07] 
Layer 'conv1' biases: 1.424029e-06 [7.778733e-10] 
Layer 'conv2' weights[0]: 5.499578e-03 [2.764230e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.948920e-09] 
Layer 'conv3' weights[0]: 5.498333e-03 [2.776666e-07] 
Layer 'conv3' biases: 2.469775e-05 [2.218491e-08] 
Layer 'conv4' weights[0]: 5.520911e-03 [2.814460e-07] 
Layer 'conv4' biases: 1.000015e+00 [3.261834e-07] 
Layer 'conv5' weights[0]: 5.578061e-03 [2.908289e-06] 
Layer 'conv5' biases: 9.992157e-01 [3.045129e-06] 
Layer 'fc6' weights[0]: 7.305662e-03 [6.547022e-08] 
Layer 'fc6' biases: 9.999967e-01 [6.379999e-08] 
Layer 'fc7' weights[0]: 7.659272e-03 [1.445411e-07] 
Layer 'fc7' biases: 9.998896e-01 [1.953891e-07] 
Layer 'fc8' weights[0]: 4.243701e-03 [1.833237e-05] 
Layer 'fc8' biases: 8.688626e-03 [2.530252e-05] 
Train error last 800 batches: 0.657950
-------------------------------------------------------
Not saving because 0.530831 > 0.299667 (9.300: -1.18%)
======================================================= (2.419 sec)
10.221... logprob:  0.654826, 0.298177 (1.423 sec)
10.222... logprob:  0.729617, 0.316406 (1.453 sec)
10.223... logprob:  0.788191, 0.332031 (1.430 sec)
10.224... logprob:  0.680429, 0.298177 (1.428 sec)
10.225... logprob:  0.589240, 0.273437 (1.444 sec)
10.226... logprob:  0.608008, 0.269531 (1.423 sec)
10.227... logprob:  0.596332, 0.261719 (1.417 sec)
10.228... logprob:  0.643909, 0.294271 (1.406 sec)
10.229... logprob:  0.757528, 0.332031 (1.411 sec)
10.230... logprob:  0.703910, 0.322917 (1.422 sec)
10.231... logprob:  0.659051, 0.303385 (1.409 sec)
10.232... logprob:  0.808286, 0.341146 (1.454 sec)
10.233... logprob:  0.661611, 0.287760 (1.419 sec)
10.234... logprob:  0.694087, 0.298177 (1.418 sec)
10.235... logprob:  0.687683, 0.283854 (1.463 sec)
10.236... logprob:  0.615084, 0.277344 (1.393 sec)
10.237... logprob:  0.547301, 0.212240 (1.427 sec)
10.238... logprob:  0.580440, 0.257812 (1.407 sec)
10.239... logprob:  0.648900, 0.281250 (1.418 sec)
10.240... logprob:  0.763087, 0.312500 (1.397 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.399109, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.503955e-03 [2.780377e-07] 
Layer 'conv1' biases: 1.426642e-06 [7.146417e-10] 
Layer 'conv2' weights[0]: 5.494073e-03 [2.761001e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.697865e-09] 
Layer 'conv3' weights[0]: 5.492827e-03 [2.768795e-07] 
Layer 'conv3' biases: 2.474342e-05 [2.208718e-08] 
Layer 'conv4' weights[0]: 5.515362e-03 [2.798730e-07] 
Layer 'conv4' biases: 1.000014e+00 [2.992413e-07] 
Layer 'conv5' weights[0]: 5.572430e-03 [2.762327e-06] 
Layer 'conv5' biases: 9.992084e-01 [2.971724e-06] 
Layer 'fc6' weights[0]: 7.304921e-03 [6.154917e-08] 
Layer 'fc6' biases: 9.999967e-01 [5.828120e-08] 
Layer 'fc7' weights[0]: 7.658448e-03 [1.368149e-07] 
Layer 'fc7' biases: 9.998899e-01 [1.610987e-07] 
Layer 'fc8' weights[0]: 4.279066e-03 [1.604900e-05] 
Layer 'fc8' biases: 8.968757e-03 [2.271071e-05] 
Train error last 800 batches: 0.657926
-------------------------------------------------------
Not saving because 0.399109 > 0.299667 (9.300: -1.18%)
======================================================= (2.368 sec)
10.241... logprob:  0.717737, 0.292969 (1.464 sec)
10.242... logprob:  0.602020, 0.281250 (1.425 sec)
10.243... logprob:  0.680583, 0.283854 (1.422 sec)
10.244... logprob:  0.580347, 0.243490 (1.465 sec)
10.245... logprob:  0.637933, 0.272135 (1.419 sec)
10.246... logprob:  0.650518, 0.270833 (1.409 sec)
10.247... logprob:  0.595823, 0.259115 (1.407 sec)
10.248... logprob:  0.570144, 0.253906 (1.410 sec)
10.249... logprob:  0.678947, 0.290365 (1.414 sec)
10.250... logprob:  0.707827, 0.296875 (1.396 sec)
10.251... logprob:  0.618226, 0.285156 (1.456 sec)
10.252... logprob:  0.664601, 0.300781 (1.419 sec)
10.253... logprob:  0.595170, 0.298177 (1.409 sec)
10.254... logprob:  0.611733, 0.264323 (1.462 sec)
10.255... logprob:  0.509958, 0.221354 (1.397 sec)
10.256... logprob:  0.599465, 0.269531 (1.414 sec)
10.257... logprob:  0.565074, 0.236979 (1.405 sec)
10.258... logprob:  0.682163, 0.276042 (1.417 sec)
10.259... logprob:  0.800666, 0.350260 (1.395 sec)
10.260... logprob:  0.608684, 0.278646 (1.448 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.494923, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.498457e-03 [2.780987e-07] 
Layer 'conv1' biases: 1.428635e-06 [8.299172e-10] 
Layer 'conv2' weights[0]: 5.488597e-03 [2.763030e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.356289e-09] 
Layer 'conv3' weights[0]: 5.487337e-03 [2.770477e-07] 
Layer 'conv3' biases: 2.473843e-05 [2.395343e-08] 
Layer 'conv4' weights[0]: 5.509878e-03 [2.795008e-07] 
Layer 'conv4' biases: 1.000014e+00 [2.800066e-07] 
Layer 'conv5' weights[0]: 5.567055e-03 [2.495688e-06] 
Layer 'conv5' biases: 9.992017e-01 [2.589907e-06] 
Layer 'fc6' weights[0]: 7.304150e-03 [5.994665e-08] 
Layer 'fc6' biases: 9.999967e-01 [5.602212e-08] 
Layer 'fc7' weights[0]: 7.657704e-03 [1.325736e-07] 
Layer 'fc7' biases: 9.998903e-01 [1.582065e-07] 
Layer 'fc8' weights[0]: 4.322183e-03 [1.636560e-05] 
Layer 'fc8' biases: 9.335022e-03 [2.433586e-05] 
Train error last 800 batches: 0.658228
-------------------------------------------------------
Not saving because 0.494923 > 0.299667 (9.300: -1.18%)
======================================================= (2.380 sec)
10.261... logprob:  0.631821, 0.300781 (1.427 sec)
10.262... logprob:  0.747712, 0.311198 (1.431 sec)
10.263... logprob:  0.656400, 0.274740 (1.449 sec)
10.264... logprob:  0.565998, 0.266927 (1.414 sec)
10.265... logprob:  0.660805, 0.264323 (1.418 sec)
10.266... logprob:  0.564290, 0.238281 (1.410 sec)
10.267... logprob:  0.636579, 0.274740 (1.418 sec)
10.268... logprob:  0.748851, 0.326823 (1.412 sec)
10.269... logprob:  0.882962, 0.354167 (1.402 sec)
10.270... logprob:  0.749079, 0.302083 (1.452 sec)
10.271... logprob:  0.635852, 0.313802 (1.420 sec)
10.272... logprob:  0.557615, 0.279948 (1.407 sec)
10.273... logprob:  0.776146, 0.315104 (1.463 sec)
10.274... logprob:  0.698331, 0.278646 (1.397 sec)
10.275... logprob:  0.656313, 0.274740 (1.411 sec)
10.276... logprob:  0.544892, 0.229167 (1.413 sec)
10.277... logprob:  0.595728, 0.265625 (1.424 sec)
10.278... logprob:  0.591465, 0.282552 (1.414 sec)
10.279... logprob:  0.564557, 0.263021 (1.457 sec)
10.280... logprob:  0.568455, 0.273438 (1.400 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.474968, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.492967e-03 [2.775943e-07] 
Layer 'conv1' biases: 1.431817e-06 [7.838125e-10] 
Layer 'conv2' weights[0]: 5.483112e-03 [2.761169e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.359278e-09] 
Layer 'conv3' weights[0]: 5.481891e-03 [2.778294e-07] 
Layer 'conv3' biases: 2.473742e-05 [2.721458e-08] 
Layer 'conv4' weights[0]: 5.504374e-03 [2.814588e-07] 
Layer 'conv4' biases: 1.000015e+00 [3.636689e-07] 
Layer 'conv5' weights[0]: 5.561752e-03 [3.131510e-06] 
Layer 'conv5' biases: 9.992176e-01 [3.305564e-06] 
Layer 'fc6' weights[0]: 7.303380e-03 [6.712211e-08] 
Layer 'fc6' biases: 9.999967e-01 [6.584652e-08] 
Layer 'fc7' weights[0]: 7.656896e-03 [1.527113e-07] 
Layer 'fc7' biases: 9.998891e-01 [2.469082e-07] 
Layer 'fc8' weights[0]: 4.258506e-03 [2.119368e-05] 
Layer 'fc8' biases: 8.877690e-03 [4.984924e-05] 
Train error last 800 batches: 0.658105
-------------------------------------------------------
Not saving because 0.474968 > 0.299667 (9.300: -1.18%)
======================================================= (2.397 sec)
10.281... logprob:  0.611593, 0.290365 (1.428 sec)
10.282... logprob:  0.636379, 0.308594 (1.415 sec)
10.283... logprob:  0.584101, 0.264323 (1.426 sec)
10.284... logprob:  0.638141, 0.273438 (1.404 sec)
10.285... logprob:  0.580092, 0.256510 (1.436 sec)
10.286... logprob:  0.807368, 0.333333 (1.432 sec)
10.287... logprob:  0.466648, 0.194010 (1.431 sec)
10.288... logprob:  0.574634, 0.250000 (1.429 sec)
10.289... logprob:  0.624306, 0.255208 (1.436 sec)
10.290... logprob:  0.678276, 0.303385 (1.403 sec)
10.291... logprob:  0.677079, 0.298177 (1.421 sec)
10.292... logprob:  0.578282, 0.263021 (1.413 sec)
10.293... logprob:  0.623700, 0.282552 (1.418 sec)
10.294... logprob:  0.546436, 0.283854 (1.401 sec)
10.295... logprob:  0.545999, 0.247396 (1.458 sec)
10.296... logprob:  0.539758, 0.233073 (1.416 sec)
10.297... logprob:  0.681602, 0.277344 (1.422 sec)
10.298... logprob:  0.756345, 0.317708 (1.457 sec)
10.299... logprob:  0.577851, 0.252604 (1.397 sec)
10.300... logprob:  0.671747, 0.304688 (1.416 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.531466, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.487463e-03 [2.772300e-07] 
Layer 'conv1' biases: 1.431337e-06 [6.982823e-10] 
Layer 'conv2' weights[0]: 5.477629e-03 [2.751672e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.361679e-09] 
Layer 'conv3' weights[0]: 5.476427e-03 [2.765646e-07] 
Layer 'conv3' biases: 2.472780e-05 [2.373200e-08] 
Layer 'conv4' weights[0]: 5.498840e-03 [2.794023e-07] 
Layer 'conv4' biases: 1.000015e+00 [3.242484e-07] 
Layer 'conv5' weights[0]: 5.556542e-03 [2.350876e-06] 
Layer 'conv5' biases: 9.991938e-01 [2.578158e-06] 
Layer 'fc6' weights[0]: 7.302629e-03 [6.019735e-08] 
Layer 'fc6' biases: 9.999967e-01 [5.683947e-08] 
Layer 'fc7' weights[0]: 7.656098e-03 [1.373210e-07] 
Layer 'fc7' biases: 9.998911e-01 [1.832448e-07] 
Layer 'fc8' weights[0]: 4.368322e-03 [2.038430e-05] 
Layer 'fc8' biases: 9.627358e-03 [4.567224e-05] 
Train error last 800 batches: 0.657358
-------------------------------------------------------
Not saving because 0.531466 > 0.299667 (9.300: -1.18%)
======================================================= (2.367 sec)
10.301... logprob:  0.607769, 0.287760 (1.422 sec)
10.302... logprob:  0.746391, 0.281250 (1.419 sec)
10.303... logprob:  0.675838, 0.282552 (1.407 sec)
10.304... logprob:  0.681500, 0.283854 (1.430 sec)
10.305... logprob:  0.649354, 0.291666 (1.436 sec)
10.306... logprob:  0.657751, 0.320312 (1.441 sec)
10.307... logprob:  0.644227, 0.282552 (1.437 sec)
10.308... logprob:  0.520173, 0.226562 (1.467 sec)
10.309... logprob:  0.637935, 0.290365 (1.421 sec)
10.310... logprob:  0.660901, 0.309896 (1.414 sec)
10.311... logprob:  0.651846, 0.259115 (1.434 sec)
10.312... logprob:  0.756590, 0.304687 (1.433 sec)
10.313... logprob:  0.727515, 0.315104 (1.421 sec)
10.314... logprob:  0.708932, 0.311198 (1.462 sec)
10.315... logprob:  0.588219, 0.264323 (1.436 sec)
10.316... logprob:  0.676646, 0.282552 (1.423 sec)
10.317... logprob:  0.615116, 0.264323 (1.472 sec)
10.318... logprob:  0.608265, 0.266927 (1.413 sec)
10.319... logprob:  0.619493, 0.295573 (1.424 sec)
10.320... logprob:  0.591505, 0.256510 (1.418 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.426418, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.481977e-03 [2.762838e-07] 
Layer 'conv1' biases: 1.431914e-06 [6.388811e-10] 
Layer 'conv2' weights[0]: 5.472188e-03 [2.750988e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.471094e-09] 
Layer 'conv3' weights[0]: 5.470927e-03 [2.757145e-07] 
Layer 'conv3' biases: 2.475367e-05 [2.054579e-08] 
Layer 'conv4' weights[0]: 5.493340e-03 [2.782033e-07] 
Layer 'conv4' biases: 1.000017e+00 [2.759990e-07] 
Layer 'conv5' weights[0]: 5.552073e-03 [2.439238e-06] 
Layer 'conv5' biases: 9.992046e-01 [2.526472e-06] 
Layer 'fc6' weights[0]: 7.301877e-03 [5.925105e-08] 
Layer 'fc6' biases: 9.999967e-01 [5.504499e-08] 
Layer 'fc7' weights[0]: 7.655339e-03 [1.307677e-07] 
Layer 'fc7' biases: 9.998893e-01 [1.572566e-07] 
Layer 'fc8' weights[0]: 4.301048e-03 [1.614635e-05] 
Layer 'fc8' biases: 9.171868e-03 [2.215374e-05] 
Train error last 800 batches: 0.656993
-------------------------------------------------------
Not saving because 0.426418 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
10.321... logprob:  0.602431, 0.273437 (1.446 sec)
10.322... logprob:  0.670724, 0.316406 (1.434 sec)
10.323... logprob:  0.660300, 0.299479 (1.475 sec)
10.324... logprob:  0.755567, 0.334635 (1.433 sec)
10.325... logprob:  0.655605, 0.273438 (1.432 sec)
10.326... logprob:  0.795607, 0.348958 (1.455 sec)
10.327... logprob:  0.765701, 0.332031 (1.432 sec)
10.328... logprob:  0.728423, 0.304688 (1.431 sec)
10.329... logprob:  0.668392, 0.276042 (1.435 sec)
10.330... logprob:  0.588245, 0.277344 (1.430 sec)
10.331... logprob:  0.593831, 0.269531 (1.427 sec)
10.332... logprob:  0.680858, 0.300781 (1.458 sec)
10.333... logprob:  0.601163, 0.259115 (1.451 sec)
10.334... logprob:  0.816983, 0.345052 (1.453 sec)
10.335... logprob:  0.630941, 0.290364 (1.449 sec)
10.336... logprob:  0.683639, 0.290365 (1.464 sec)
10.337... logprob:  0.831403, 0.348958 (1.425 sec)
10.338... logprob:  0.689941, 0.296875 (1.422 sec)
10.339... logprob:  0.696651, 0.320312 (1.438 sec)
10.340... logprob:  0.644636, 0.304687 (1.432 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.411369, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.476487e-03 [2.756466e-07] 
Layer 'conv1' biases: 1.433270e-06 [7.640513e-10] 
Layer 'conv2' weights[0]: 5.466664e-03 [2.750674e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.473278e-09] 
Layer 'conv3' weights[0]: 5.465442e-03 [2.765356e-07] 
Layer 'conv3' biases: 2.485568e-05 [2.542037e-08] 
Layer 'conv4' weights[0]: 5.487871e-03 [2.797186e-07] 
Layer 'conv4' biases: 1.000015e+00 [3.640460e-07] 
Layer 'conv5' weights[0]: 5.546249e-03 [2.964177e-06] 
Layer 'conv5' biases: 9.992154e-01 [3.235874e-06] 
Layer 'fc6' weights[0]: 7.301119e-03 [6.283699e-08] 
Layer 'fc6' biases: 9.999967e-01 [6.003926e-08] 
Layer 'fc7' weights[0]: 7.654564e-03 [1.411165e-07] 
Layer 'fc7' biases: 9.998882e-01 [1.811712e-07] 
Layer 'fc8' weights[0]: 4.252275e-03 [1.793481e-05] 
Layer 'fc8' biases: 8.764994e-03 [2.806604e-05] 
Train error last 800 batches: 0.657229
-------------------------------------------------------
Not saving because 0.411369 > 0.299667 (9.300: -1.18%)
======================================================= (2.384 sec)
10.341... logprob:  0.662757, 0.289062 (1.434 sec)
10.342... logprob:  0.588836, 0.268229 (1.463 sec)
10.343... logprob:  0.645556, 0.256510 (1.440 sec)
10.344... logprob:  0.675490, 0.273438 (1.481 sec)
10.345... logprob:  0.719292, 0.341146 (1.442 sec)
10.346... logprob:  0.651521, 0.292969 (1.444 sec)
10.347... logprob:  0.577594, 0.242187 (1.489 sec)
10.348... logprob:  0.692938, 0.313802 (1.438 sec)
10.349... logprob:  0.661662, 0.286458 (1.431 sec)
10.350... logprob:  0.613873, 0.256510 (1.436 sec)
10.351... logprob:  0.705014, 0.290364 (1.428 sec)
10.352... logprob:  0.624579, 0.273438 (1.428 sec)
10.353... logprob:  0.745783, 0.337240 (1.482 sec)
10.354... logprob:  0.894495, 0.355469 (1.423 sec)
10.355... logprob:  0.536943, 0.231771 (1.444 sec)
10.356... logprob:  0.677765, 0.277344 (1.485 sec)
10.357... logprob:  0.626041, 0.247396 (1.501 sec)
10.358... logprob:  0.672728, 0.300781 (1.438 sec)
10.359... logprob:  0.735630, 0.300781 (1.427 sec)
10.360... logprob:  0.748488, 0.321614 (1.423 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.476446, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.471023e-03 [2.761031e-07] 
Layer 'conv1' biases: 1.435989e-06 [8.450527e-10] 
Layer 'conv2' weights[0]: 5.461220e-03 [2.750911e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.775547e-09] 
Layer 'conv3' weights[0]: 5.460022e-03 [2.762946e-07] 
Layer 'conv3' biases: 2.491929e-05 [2.684218e-08] 
Layer 'conv4' weights[0]: 5.482411e-03 [2.799585e-07] 
Layer 'conv4' biases: 1.000016e+00 [4.083485e-07] 
Layer 'conv5' weights[0]: 5.540921e-03 [3.154636e-06] 
Layer 'conv5' biases: 9.992071e-01 [3.415482e-06] 
Layer 'fc6' weights[0]: 7.300337e-03 [7.082051e-08] 
Layer 'fc6' biases: 9.999967e-01 [7.150235e-08] 
Layer 'fc7' weights[0]: 7.653798e-03 [1.617425e-07] 
Layer 'fc7' biases: 9.998880e-01 [2.375656e-07] 
Layer 'fc8' weights[0]: 4.278876e-03 [2.003612e-05] 
Layer 'fc8' biases: 9.004266e-03 [3.764913e-05] 
Train error last 800 batches: 0.656914
-------------------------------------------------------
Not saving because 0.476446 > 0.299667 (9.300: -1.18%)
======================================================= (2.384 sec)
10.361... logprob:  0.672616, 0.272135 (1.434 sec)
10.362... logprob:  0.686544, 0.277344 (1.477 sec)
10.363... logprob:  0.722143, 0.332031 (1.439 sec)
10.364... logprob:  0.628090, 0.257812 (1.448 sec)
10.365... logprob:  0.680320, 0.304688 (1.459 sec)
10.366... logprob:  0.671071, 0.309896 (1.442 sec)
10.367... logprob:  0.648135, 0.283854 (1.437 sec)
10.368... logprob:  0.846238, 0.341146 (1.430 sec)
10.369... logprob:  0.668494, 0.295573 (1.423 sec)
10.370... logprob:  0.599118, 0.283854 (1.436 sec)
10.371... logprob:  0.684174, 0.319010 (1.449 sec)
10.372... logprob:  0.752876, 0.307292 (1.454 sec)
10.373... logprob:  0.607823, 0.278646 (1.444 sec)
10.374... logprob:  0.729694, 0.304688 (1.447 sec)
10.375... logprob:  0.646069, 0.263021 (1.457 sec)
10.376... logprob:  0.623788, 0.287760 (1.428 sec)
10.377... logprob:  0.574938, 0.251302 (1.424 sec)
10.378... logprob:  0.664278, 0.302083 (1.430 sec)
10.379... logprob:  0.643603, 0.277344 (1.429 sec)
10.380... logprob:  0.747630, 0.342448 (1.436 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.497846, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.465566e-03 [2.763723e-07] 
Layer 'conv1' biases: 1.437201e-06 [9.429480e-10] 
Layer 'conv2' weights[0]: 5.455774e-03 [2.750283e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.941716e-09] 
Layer 'conv3' weights[0]: 5.454551e-03 [2.762800e-07] 
Layer 'conv3' biases: 2.500532e-05 [2.708952e-08] 
Layer 'conv4' weights[0]: 5.476904e-03 [2.803094e-07] 
Layer 'conv4' biases: 1.000016e+00 [3.599244e-07] 
Layer 'conv5' weights[0]: 5.535919e-03 [3.200949e-06] 
Layer 'conv5' biases: 9.992059e-01 [3.410035e-06] 
Layer 'fc6' weights[0]: 7.299575e-03 [6.764447e-08] 
Layer 'fc6' biases: 9.999967e-01 [6.671974e-08] 
Layer 'fc7' weights[0]: 7.653059e-03 [1.541575e-07] 
Layer 'fc7' biases: 9.998875e-01 [2.305086e-07] 
Layer 'fc8' weights[0]: 4.274302e-03 [1.999958e-05] 
Layer 'fc8' biases: 8.985470e-03 [4.157771e-05] 
Train error last 800 batches: 0.657555
-------------------------------------------------------
Not saving because 0.497846 > 0.299667 (9.300: -1.18%)
======================================================= (2.363 sec)
10.381... logprob:  0.703618, 0.281250 (1.469 sec)
10.382... logprob:  0.725049, 0.320312 (1.451 sec)
10.383... logprob:  0.564143, 0.261719 (1.440 sec)
10.384... logprob:  0.683291, 0.299479 (1.488 sec)
10.385... logprob:  0.682614, 0.305990 (1.431 sec)
10.386... logprob:  0.751869, 0.309896 (1.426 sec)
10.387... logprob:  0.716708, 0.320312 (1.428 sec)
10.388... logprob:  0.719446, 0.299479 (1.428 sec)
10.389... logprob:  0.570242, 0.244792 (1.425 sec)
10.390... logprob:  0.597359, 0.282552 (1.475 sec)
10.391... logprob:  0.573262, 0.270833 (1.445 sec)
10.392... logprob:  0.628106, 0.261719 (1.432 sec)
10.393... logprob:  0.595094, 0.253906 (1.481 sec)
10.394... logprob:  0.574945, 0.256510 (1.425 sec)
10.395... logprob:  0.660980, 0.289062 (1.431 sec)
10.396... logprob:  0.474064, 0.231771 (1.431 sec)
10.397... logprob:  0.710227, 0.298177 (1.428 sec)
10.398... logprob:  0.660585, 0.285156 (1.427 sec)
10.399... logprob:  0.652682, 0.277344 (1.502 sec)
10.400... logprob:  0.688833, 0.315104 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.553165, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.460103e-03 [2.749560e-07] 
Layer 'conv1' biases: 1.437307e-06 [7.374547e-10] 
Layer 'conv2' weights[0]: 5.450308e-03 [2.744077e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.282446e-09] 
Layer 'conv3' weights[0]: 5.449074e-03 [2.752493e-07] 
Layer 'conv3' biases: 2.503964e-05 [2.435558e-08] 
Layer 'conv4' weights[0]: 5.471439e-03 [2.793783e-07] 
Layer 'conv4' biases: 1.000015e+00 [3.699512e-07] 
Layer 'conv5' weights[0]: 5.530116e-03 [2.612566e-06] 
Layer 'conv5' biases: 9.991933e-01 [2.798353e-06] 
Layer 'fc6' weights[0]: 7.298826e-03 [6.198779e-08] 
Layer 'fc6' biases: 9.999968e-01 [5.896980e-08] 
Layer 'fc7' weights[0]: 7.652292e-03 [1.397838e-07] 
Layer 'fc7' biases: 9.998887e-01 [1.879933e-07] 
Layer 'fc8' weights[0]: 4.342233e-03 [1.875582e-05] 
Layer 'fc8' biases: 9.408946e-03 [2.897750e-05] 
Train error last 800 batches: 0.657100
-------------------------------------------------------
Not saving because 0.553165 > 0.299667 (9.300: -1.18%)
======================================================= (2.409 sec)
10.401... logprob:  0.746048, 0.333333 (1.448 sec)
10.402... logprob:  0.700353, 0.304688 (1.484 sec)
10.403... logprob:  0.653501, 0.283854 (1.428 sec)
10.404... logprob:  0.697152, 0.282552 (1.430 sec)
10.405... logprob:  0.773595, 0.315104 (1.429 sec)
10.406... logprob:  0.643086, 0.283854 (1.424 sec)
10.407... logprob:  0.668175, 0.278646 (1.433 sec)
10.408... logprob:  0.548036, 0.246094 (1.471 sec)
10.409... logprob:  0.633281, 0.287760 (1.446 sec)
10.410... logprob:  0.903858, 0.363281 (1.446 sec)
10.411... logprob:  0.673681, 0.333333 (1.467 sec)
10.412... logprob:  0.749138, 0.321614 (1.430 sec)
10.413... logprob:  0.695239, 0.316406 (1.432 sec)
10.414... logprob:  0.630973, 0.269531 (1.427 sec)
10.415... logprob:  0.662226, 0.303385 (1.417 sec)
10.416... logprob:  0.683583, 0.305989 (1.432 sec)
10.417... logprob:  0.569435, 0.266927 (1.461 sec)
10.418... logprob:  0.551718, 0.235677 (1.449 sec)
10.419... logprob:  0.634417, 0.256510 (1.448 sec)
10.420... logprob:  0.572784, 0.274739 (1.451 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.445481, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.454658e-03 [2.764123e-07] 
Layer 'conv1' biases: 1.440007e-06 [1.109197e-09] 
Layer 'conv2' weights[0]: 5.444835e-03 [2.751007e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.335167e-09] 
Layer 'conv3' weights[0]: 5.443593e-03 [2.773621e-07] 
Layer 'conv3' biases: 2.508261e-05 [3.265995e-08] 
Layer 'conv4' weights[0]: 5.465967e-03 [2.833001e-07] 
Layer 'conv4' biases: 1.000014e+00 [4.925836e-07] 
Layer 'conv5' weights[0]: 5.524396e-03 [3.630281e-06] 
Layer 'conv5' biases: 9.992035e-01 [3.856286e-06] 
Layer 'fc6' weights[0]: 7.298047e-03 [7.605875e-08] 
Layer 'fc6' biases: 9.999968e-01 [7.877369e-08] 
Layer 'fc7' weights[0]: 7.651544e-03 [1.857065e-07] 
Layer 'fc7' biases: 9.998879e-01 [3.267035e-07] 
Layer 'fc8' weights[0]: 4.302566e-03 [2.969703e-05] 
Layer 'fc8' biases: 9.123955e-03 [7.405980e-05] 
Train error last 800 batches: 0.657616
-------------------------------------------------------
Not saving because 0.445481 > 0.299667 (9.300: -1.18%)
======================================================= (2.353 sec)
10.421... logprob:  0.646243, 0.273437 (1.459 sec)
10.422... logprob:  0.711103, 0.317708 (1.439 sec)
10.423... logprob:  0.571448, 0.253906 (1.423 sec)
10.424... logprob:  0.484420, 0.231771 (1.428 sec)
10.425... logprob:  0.610060, 0.269531 (1.436 sec)
10.426... logprob:  0.691133, 0.316406 (1.437 sec)
10.427... logprob:  0.758342, 0.311198 (1.460 sec)
10.428... logprob:  0.778950, 0.356771 (1.445 sec)
10.429... logprob:  0.655099, 0.299479 (1.438 sec)
10.430... logprob:  0.634357, 0.286458 (1.465 sec)
10.431... logprob:  0.794545, 0.345052 (1.428 sec)
10.432... logprob:  0.573539, 0.253906 (1.419 sec)
10.433... logprob:  0.570740, 0.257812 (1.430 sec)
10.434... logprob:  0.629007, 0.277344 (1.436 sec)
10.435... logprob:  0.696845, 0.308594 (1.431 sec)
10.436... logprob:  0.507191, 0.238281 (1.476 sec)
10.437... logprob:  0.622481, 0.290365 (1.455 sec)
10.438... logprob:  0.799313, 0.330729 (1.425 sec)
10.439... logprob:  0.601579, 0.263021 (1.483 sec)
10.440... logprob:  0.737323, 0.302083 (1.422 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.510979, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.449235e-03 [2.742985e-07] 
Layer 'conv1' biases: 1.440953e-06 [1.090128e-09] 
Layer 'conv2' weights[0]: 5.439433e-03 [2.739828e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.258793e-09] 
Layer 'conv3' weights[0]: 5.438207e-03 [2.762569e-07] 
Layer 'conv3' biases: 2.511713e-05 [3.082597e-08] 
Layer 'conv4' weights[0]: 5.460551e-03 [2.810146e-07] 
Layer 'conv4' biases: 1.000012e+00 [4.517239e-07] 
Layer 'conv5' weights[0]: 5.518355e-03 [3.433087e-06] 
Layer 'conv5' biases: 9.991946e-01 [3.578182e-06] 
Layer 'fc6' weights[0]: 7.297270e-03 [7.189698e-08] 
Layer 'fc6' biases: 9.999966e-01 [7.344828e-08] 
Layer 'fc7' weights[0]: 7.650757e-03 [1.655756e-07] 
Layer 'fc7' biases: 9.998880e-01 [2.646781e-07] 
Layer 'fc8' weights[0]: 4.335608e-03 [2.254300e-05] 
Layer 'fc8' biases: 9.382634e-03 [4.636889e-05] 
Train error last 800 batches: 0.657394
-------------------------------------------------------
Not saving because 0.510979 > 0.299667 (9.300: -1.18%)
======================================================= (2.362 sec)
10.441... logprob:  0.762981, 0.320312 (1.434 sec)
10.442... logprob:  0.633029, 0.273438 (1.442 sec)
10.443... logprob:  0.805816, 0.337240 (1.427 sec)
10.444... logprob:  0.613030, 0.277344 (1.428 sec)
10.445... logprob:  0.536908, 0.252604 (1.484 sec)
10.446... logprob:  0.581559, 0.242187 (1.435 sec)
10.447... logprob:  0.737851, 0.302083 (1.438 sec)
10.448... logprob:  0.543191, 0.263021 (1.478 sec)
10.449... logprob:  0.594325, 0.253906 (1.427 sec)
10.450... logprob:  0.486046, 0.207031 (1.426 sec)
10.451... logprob:  0.590523, 0.261719 (1.434 sec)
10.452... logprob:  0.684919, 0.263021 (1.428 sec)
10.453... logprob:  0.695005, 0.302083 (1.429 sec)
10.454... logprob:  0.742660, 0.295573 (1.483 sec)
10.455... logprob:  0.739607, 0.352865 (1.428 sec)
10.456... logprob:  0.747608, 0.324219 (1.444 sec)
10.457... logprob:  0.647108, 0.266927 (1.475 sec)
10.458... logprob:  0.596409, 0.253906 (1.427 sec)
10.459... logprob:  0.738664, 0.319010 (1.432 sec)
10.460... logprob:  0.561886, 0.265625 (1.424 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.495235, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.443774e-03 [2.746787e-07] 
Layer 'conv1' biases: 1.440606e-06 [6.958017e-10] 
Layer 'conv2' weights[0]: 5.433983e-03 [2.732011e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.315119e-09] 
Layer 'conv3' weights[0]: 5.432752e-03 [2.745231e-07] 
Layer 'conv3' biases: 2.515325e-05 [2.352547e-08] 
Layer 'conv4' weights[0]: 5.455073e-03 [2.775969e-07] 
Layer 'conv4' biases: 1.000011e+00 [3.424547e-07] 
Layer 'conv5' weights[0]: 5.512682e-03 [2.718569e-06] 
Layer 'conv5' biases: 9.992028e-01 [2.969947e-06] 
Layer 'fc6' weights[0]: 7.296546e-03 [6.090099e-08] 
Layer 'fc6' biases: 9.999965e-01 [5.738860e-08] 
Layer 'fc7' weights[0]: 7.650007e-03 [1.364079e-07] 
Layer 'fc7' biases: 9.998870e-01 [1.686818e-07] 
Layer 'fc8' weights[0]: 4.309034e-03 [1.670157e-05] 
Layer 'fc8' biases: 9.192710e-03 [2.622946e-05] 
Train error last 800 batches: 0.657212
-------------------------------------------------------
Not saving because 0.495235 > 0.299667 (9.300: -1.18%)
======================================================= (2.407 sec)
10.461... logprob:  0.647615, 0.308594 (1.424 sec)
10.462... logprob:  0.708569, 0.311198 (1.437 sec)
10.463... logprob:  0.646128, 0.295573 (1.474 sec)
10.464... logprob:  0.692006, 0.295573 (1.448 sec)
10.465... logprob:  0.646034, 0.266927 (1.454 sec)
10.466... logprob:  0.598028, 0.264323 (1.458 sec)
10.467... logprob:  0.657270, 0.292969 (1.450 sec)
10.468... logprob:  0.550323, 0.255208 (1.436 sec)
10.469... logprob:  0.562365, 0.231771 (1.422 sec)
10.470... logprob:  0.614306, 0.290365 (1.422 sec)
10.471... logprob:  0.775484, 0.316406 (1.439 sec)
10.472... logprob:  0.632558, 0.274740 (1.442 sec)
10.473... logprob:  0.600059, 0.261719 (1.454 sec)
10.474... logprob:  0.757361, 0.300781 (1.449 sec)
10.475... logprob:  0.572024, 0.272135 (1.457 sec)
10.476... logprob:  0.666652, 0.289062 (1.464 sec)
10.477... logprob:  0.557170, 0.247396 (1.440 sec)
10.478... logprob:  0.675529, 0.294271 (1.423 sec)
10.479... logprob:  0.494575, 0.233073 (1.427 sec)
10.480... logprob:  0.715432, 0.328125 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.510464, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.438330e-03 [2.744951e-07] 
Layer 'conv1' biases: 1.443172e-06 [7.614963e-10] 
Layer 'conv2' weights[0]: 5.428555e-03 [2.726011e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.506524e-09] 
Layer 'conv3' weights[0]: 5.427316e-03 [2.735074e-07] 
Layer 'conv3' biases: 2.519133e-05 [2.195674e-08] 
Layer 'conv4' weights[0]: 5.449595e-03 [2.759454e-07] 
Layer 'conv4' biases: 1.000010e+00 [2.705538e-07] 
Layer 'conv5' weights[0]: 5.507312e-03 [2.494641e-06] 
Layer 'conv5' biases: 9.991906e-01 [2.672152e-06] 
Layer 'fc6' weights[0]: 7.295766e-03 [5.713889e-08] 
Layer 'fc6' biases: 9.999964e-01 [5.207094e-08] 
Layer 'fc7' weights[0]: 7.649227e-03 [1.252640e-07] 
Layer 'fc7' biases: 9.998877e-01 [1.432912e-07] 
Layer 'fc8' weights[0]: 4.344152e-03 [1.428652e-05] 
Layer 'fc8' biases: 9.509812e-03 [1.275395e-05] 
Train error last 800 batches: 0.656904
-------------------------------------------------------
Not saving because 0.510464 > 0.299667 (9.300: -1.18%)
======================================================= (2.367 sec)
10.481... logprob:  0.916850, 0.361979 (1.520 sec)
10.482... logprob:  0.599598, 0.261719 (1.477 sec)
10.483... logprob:  0.713205, 0.319010 (1.445 sec)
10.484... logprob:  0.677733, 0.268229 (1.426 sec)
10.485... logprob:  0.548410, 0.230469 (1.480 sec)
10.486... logprob:  0.592309, 0.244792 (1.428 sec)
10.487... logprob:  0.731405, 0.302083 (1.426 sec)
10.488... logprob:  0.620310, 0.302083 (1.434 sec)
10.489... logprob:  0.691845, 0.313802 (1.435 sec)
10.490... logprob:  0.621667, 0.266927 (1.431 sec)
10.491... logprob:  0.602113, 0.260417 (1.478 sec)
10.492... logprob:  0.714072, 0.290365 (1.441 sec)
10.493... logprob:  0.721133, 0.302083 (1.425 sec)
10.494... logprob:  0.599373, 0.266927 (1.490 sec)
10.495... logprob:  0.616100, 0.286458 (1.424 sec)
10.496... logprob:  0.689587, 0.307292 (1.426 sec)
10.497... logprob:  0.665199, 0.279948 (1.430 sec)
10.498... logprob:  0.628068, 0.259115 (1.426 sec)
10.499... logprob:  0.715558, 0.296875 (1.431 sec)
10.500... logprob:  0.594327, 0.278646 (1.485 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.514238, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.432914e-03 [2.746497e-07] 
Layer 'conv1' biases: 1.448243e-06 [7.751152e-10] 
Layer 'conv2' weights[0]: 5.423153e-03 [2.731561e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.500218e-09] 
Layer 'conv3' weights[0]: 5.421879e-03 [2.740554e-07] 
Layer 'conv3' biases: 2.514069e-05 [2.617826e-08] 
Layer 'conv4' weights[0]: 5.444155e-03 [2.776189e-07] 
Layer 'conv4' biases: 1.000009e+00 [3.550182e-07] 
Layer 'conv5' weights[0]: 5.501148e-03 [2.766839e-06] 
Layer 'conv5' biases: 9.991974e-01 [2.923483e-06] 
Layer 'fc6' weights[0]: 7.294992e-03 [5.973389e-08] 
Layer 'fc6' biases: 9.999963e-01 [5.580172e-08] 
Layer 'fc7' weights[0]: 7.648441e-03 [1.301392e-07] 
Layer 'fc7' biases: 9.998866e-01 [1.450626e-07] 
Layer 'fc8' weights[0]: 4.305367e-03 [1.469798e-05] 
Layer 'fc8' biases: 9.226419e-03 [5.852689e-06] 
Train error last 800 batches: 0.657059
-------------------------------------------------------
Not saving because 0.514238 > 0.299667 (9.300: -1.18%)
======================================================= (2.385 sec)
10.501... logprob:  0.543410, 0.260417 (1.433 sec)
10.502... logprob:  0.644426, 0.281250 (1.450 sec)
10.503... logprob:  0.677786, 0.283854 (1.473 sec)
10.504... logprob:  0.694938, 0.286458 (1.432 sec)
10.505... logprob:  0.740890, 0.334635 (1.436 sec)
10.506... logprob:  0.759393, 0.355469 (1.430 sec)
10.507... logprob:  0.603099, 0.269531 (1.422 sec)
10.508... logprob:  0.593429, 0.282552 (1.429 sec)
10.509... logprob:  0.579242, 0.250000 (1.478 sec)
10.510... logprob:  0.675895, 0.282552 (1.435 sec)
10.511... logprob:  0.675002, 0.286458 (1.449 sec)
10.512... logprob:  0.766719, 0.319010 (1.462 sec)
10.513... logprob:  0.613222, 0.266927 (1.452 sec)
10.514... logprob:  0.659741, 0.274740 (1.433 sec)
10.515... logprob:  0.673641, 0.302083 (1.424 sec)
10.516... logprob:  0.606582, 0.299479 (1.422 sec)
10.517... logprob:  0.780429, 0.324219 (1.437 sec)
10.518... logprob:  0.671177, 0.295573 (1.448 sec)
10.519... logprob:  0.662133, 0.285156 (1.453 sec)
10.520... logprob:  0.697622, 0.313802 (1.449 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.493734, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.427495e-03 [2.731280e-07] 
Layer 'conv1' biases: 1.454242e-06 [5.621923e-10] 
Layer 'conv2' weights[0]: 5.417731e-03 [2.730747e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.972960e-09] 
Layer 'conv3' weights[0]: 5.416512e-03 [2.737019e-07] 
Layer 'conv3' biases: 2.517385e-05 [2.249074e-08] 
Layer 'conv4' weights[0]: 5.438684e-03 [2.767281e-07] 
Layer 'conv4' biases: 1.000008e+00 [2.838253e-07] 
Layer 'conv5' weights[0]: 5.495945e-03 [2.169469e-06] 
Layer 'conv5' biases: 9.991925e-01 [2.208345e-06] 
Layer 'fc6' weights[0]: 7.294232e-03 [6.124569e-08] 
Layer 'fc6' biases: 9.999964e-01 [5.789037e-08] 
Layer 'fc7' weights[0]: 7.647675e-03 [1.352755e-07] 
Layer 'fc7' biases: 9.998866e-01 [1.638403e-07] 
Layer 'fc8' weights[0]: 4.311215e-03 [1.561032e-05] 
Layer 'fc8' biases: 9.334406e-03 [1.603180e-05] 
Train error last 800 batches: 0.657530
-------------------------------------------------------
Not saving because 0.493734 > 0.299667 (9.300: -1.18%)
======================================================= (2.363 sec)
10.521... logprob:  0.573781, 0.231771 (1.451 sec)
10.522... logprob:  0.799784, 0.341146 (1.464 sec)
10.523... logprob:  0.576997, 0.235677 (1.434 sec)
10.524... logprob:  0.666027, 0.307292 (1.422 sec)
10.525... logprob:  0.655812, 0.287760 (1.432 sec)
10.526... logprob:  0.703269, 0.307292 (1.429 sec)
10.527... logprob:  0.611340, 0.257812 (1.437 sec)
10.528... logprob:  0.610204, 0.270833 (1.469 sec)
10.529... logprob:  0.570362, 0.253906 (1.441 sec)
10.530... logprob:  0.598541, 0.259115 (1.438 sec)
10.531... logprob:  0.691851, 0.276042 (1.477 sec)
10.532... logprob:  0.734953, 0.350260 (1.427 sec)
10.533... logprob:  0.696556, 0.308594 (1.425 sec)
10.534... logprob:  0.603014, 0.264323 (1.429 sec)
10.535... logprob:  0.724852, 0.324219 (1.434 sec)
10.536... logprob:  0.664423, 0.286458 (1.427 sec)
10.537... logprob:  0.688809, 0.279948 (1.472 sec)
10.538... logprob:  0.734627, 0.279948 (1.443 sec)
10.539... logprob:  0.501704, 0.217448 (1.427 sec)
10.540... logprob:  0.748019, 0.320312 (1.484 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.412835, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.422107e-03 [2.740404e-07] 
Layer 'conv1' biases: 1.457593e-06 [8.869951e-10] 
Layer 'conv2' weights[0]: 5.412304e-03 [2.723517e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.324311e-09] 
Layer 'conv3' weights[0]: 5.411101e-03 [2.735287e-07] 
Layer 'conv3' biases: 2.516795e-05 [2.522750e-08] 
Layer 'conv4' weights[0]: 5.433269e-03 [2.760254e-07] 
Layer 'conv4' biases: 1.000009e+00 [3.075753e-07] 
Layer 'conv5' weights[0]: 5.490832e-03 [2.618985e-06] 
Layer 'conv5' biases: 9.991871e-01 [2.734154e-06] 
Layer 'fc6' weights[0]: 7.293451e-03 [6.120773e-08] 
Layer 'fc6' biases: 9.999963e-01 [5.797845e-08] 
Layer 'fc7' weights[0]: 7.646904e-03 [1.362422e-07] 
Layer 'fc7' biases: 9.998860e-01 [1.597329e-07] 
Layer 'fc8' weights[0]: 4.298075e-03 [1.556064e-05] 
Layer 'fc8' biases: 9.284169e-03 [1.496317e-05] 
Train error last 800 batches: 0.657137
-------------------------------------------------------
Not saving because 0.412835 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
10.541... logprob:  0.635885, 0.248698 (1.438 sec)
10.542... logprob:  0.680470, 0.276042 (1.436 sec)
10.543... logprob:  0.453878, 0.203125 (1.432 sec)
10.544... logprob:  0.538657, 0.240885 (1.424 sec)
10.545... logprob:  0.632318, 0.277344 (1.427 sec)
10.546... logprob:  0.627867, 0.285156 (1.477 sec)
10.547... logprob:  0.638431, 0.281250 (1.431 sec)
10.548... logprob:  0.632300, 0.261719 (1.440 sec)
10.549... logprob:  0.747716, 0.328125 (1.478 sec)
10.550... logprob:  0.539906, 0.243490 (1.432 sec)
10.551... logprob:  0.634138, 0.268229 (1.444 sec)
10.552... logprob:  0.690148, 0.302083 (1.430 sec)
10.553... logprob:  0.580711, 0.252604 (1.423 sec)
10.554... logprob:  0.651885, 0.287760 (1.432 sec)
10.555... logprob:  0.604848, 0.283854 (1.475 sec)
10.556... logprob:  0.647809, 0.274740 (1.433 sec)
10.557... logprob:  0.666618, 0.291667 (1.448 sec)
10.558... logprob:  0.617618, 0.285156 (1.468 sec)
10.559... logprob:  0.655656, 0.289062 (1.431 sec)
10.560... logprob:  0.514455, 0.250000 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.419477, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.416681e-03 [2.724601e-07] 
Layer 'conv1' biases: 1.461148e-06 [7.881385e-10] 
Layer 'conv2' weights[0]: 5.406898e-03 [2.715062e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.151051e-09] 
Layer 'conv3' weights[0]: 5.405655e-03 [2.729131e-07] 
Layer 'conv3' biases: 2.522126e-05 [2.341896e-08] 
Layer 'conv4' weights[0]: 5.427789e-03 [2.756533e-07] 
Layer 'conv4' biases: 1.000009e+00 [3.080881e-07] 
Layer 'conv5' weights[0]: 5.485440e-03 [2.436861e-06] 
Layer 'conv5' biases: 9.991701e-01 [2.604804e-06] 
Layer 'fc6' weights[0]: 7.292675e-03 [5.825551e-08] 
Layer 'fc6' biases: 9.999963e-01 [5.402682e-08] 
Layer 'fc7' weights[0]: 7.646130e-03 [1.293086e-07] 
Layer 'fc7' biases: 9.998875e-01 [1.641038e-07] 
Layer 'fc8' weights[0]: 4.354030e-03 [1.624660e-05] 
Layer 'fc8' biases: 9.609234e-03 [2.578922e-05] 
Train error last 800 batches: 0.656924
-------------------------------------------------------
Not saving because 0.419477 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
10.561... logprob:  0.653940, 0.289062 (1.433 sec)
10.562... logprob:  0.705653, 0.302083 (1.427 sec)
10.563... logprob:  0.567629, 0.265625 (1.439 sec)
10.564... logprob:  0.688715, 0.308594 (1.463 sec)
10.565... logprob:  0.718791, 0.292969 (1.447 sec)
10.566... logprob:  0.658547, 0.292969 (1.454 sec)
10.567... logprob:  0.664452, 0.287760 (1.454 sec)
10.568... logprob:  0.724586, 0.311198 (1.452 sec)
10.569... logprob:  0.707549, 0.315104 (1.429 sec)
10.570... logprob:  0.771421, 0.320312 (1.422 sec)
10.571... logprob:  0.692594, 0.311198 (1.422 sec)
10.572... logprob:  0.652412, 0.282552 (1.429 sec)
10.573... logprob:  0.674197, 0.289062 (1.444 sec)
10.574... logprob:  0.668374, 0.304687 (1.454 sec)
10.575... logprob:  0.615061, 0.255208 (1.445 sec)
10.576... logprob:  0.650644, 0.261719 (1.435 sec)
10.577... logprob:  0.684737, 0.278646 (1.469 sec)
10.578... logprob:  0.634190, 0.274740 (1.430 sec)
10.579... logprob:  0.640854, 0.270833 (1.417 sec)
10.580... logprob:  0.765721, 0.322917 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.434686, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.411271e-03 [2.727400e-07] 
Layer 'conv1' biases: 1.466810e-06 [8.595500e-10] 
Layer 'conv2' weights[0]: 5.401510e-03 [2.719055e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.762640e-09] 
Layer 'conv3' weights[0]: 5.400222e-03 [2.734761e-07] 
Layer 'conv3' biases: 2.529671e-05 [2.706530e-08] 
Layer 'conv4' weights[0]: 5.422427e-03 [2.781245e-07] 
Layer 'conv4' biases: 1.000009e+00 [3.985512e-07] 
Layer 'conv5' weights[0]: 5.480779e-03 [2.882561e-06] 
Layer 'conv5' biases: 9.991820e-01 [3.035952e-06] 
Layer 'fc6' weights[0]: 7.291878e-03 [6.818318e-08] 
Layer 'fc6' biases: 9.999963e-01 [6.843287e-08] 
Layer 'fc7' weights[0]: 7.645367e-03 [1.601032e-07] 
Layer 'fc7' biases: 9.998856e-01 [2.370021e-07] 
Layer 'fc8' weights[0]: 4.267429e-03 [2.350757e-05] 
Layer 'fc8' biases: 9.044700e-03 [5.254705e-05] 
Train error last 800 batches: 0.656949
-------------------------------------------------------
Not saving because 0.434686 > 0.299667 (9.300: -1.18%)
======================================================= (2.396 sec)
10.581... logprob:  0.778621, 0.324219 (1.439 sec)
10.582... logprob:  0.624809, 0.252604 (1.438 sec)
10.583... logprob:  0.783556, 0.339844 (1.473 sec)
10.584... logprob:  0.708129, 0.312500 (1.445 sec)
10.585... logprob:  0.537812, 0.210937 (1.427 sec)
10.586... logprob:  0.588536, 0.283854 (1.479 sec)
10.587... logprob:  0.627145, 0.274739 (1.426 sec)
10.588... logprob:  0.679594, 0.324219 (1.425 sec)
10.589... logprob:  0.545547, 0.244792 (1.463 sec)
10.590... logprob:  0.721875, 0.332031 (1.423 sec)
10.591... logprob:  0.604841, 0.246094 (1.428 sec)
10.592... logprob:  0.655464, 0.290365 (1.478 sec)
10.593... logprob:  0.726866, 0.320312 (1.434 sec)
10.594... logprob:  0.658000, 0.302083 (1.438 sec)
10.595... logprob:  0.667875, 0.265625 (1.489 sec)
10.596... logprob:  0.603163, 0.253906 (1.425 sec)
10.597... logprob:  0.563968, 0.269531 (1.428 sec)
10.598... logprob:  0.602995, 0.265625 (1.427 sec)
10.599... logprob:  0.577590, 0.269531 (1.423 sec)
10.600... logprob:  0.632833, 0.282552 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.492257, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.405868e-03 [2.734125e-07] 
Layer 'conv1' biases: 1.469125e-06 [7.587261e-10] 
Layer 'conv2' weights[0]: 5.396119e-03 [2.721063e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.384305e-09] 
Layer 'conv3' weights[0]: 5.394839e-03 [2.738590e-07] 
Layer 'conv3' biases: 2.528924e-05 [2.825536e-08] 
Layer 'conv4' weights[0]: 5.417017e-03 [2.781754e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.911889e-07] 
Layer 'conv5' weights[0]: 5.476801e-03 [3.151813e-06] 
Layer 'conv5' biases: 9.991544e-01 [3.370913e-06] 
Layer 'fc6' weights[0]: 7.291161e-03 [7.149356e-08] 
Layer 'fc6' biases: 9.999963e-01 [7.346980e-08] 
Layer 'fc7' weights[0]: 7.644613e-03 [1.730400e-07] 
Layer 'fc7' biases: 9.998869e-01 [2.992771e-07] 
Layer 'fc8' weights[0]: 4.341383e-03 [2.429597e-05] 
Layer 'fc8' biases: 9.675539e-03 [5.541905e-05] 
Train error last 800 batches: 0.656712
-------------------------------------------------------
Not saving because 0.492257 > 0.299667 (9.300: -1.18%)
======================================================= (2.342 sec)
10.601... logprob:  0.573346, 0.255208 (1.488 sec)
10.602... logprob:  0.513814, 0.250000 (1.436 sec)
10.603... logprob:  0.550313, 0.252604 (1.443 sec)
10.604... logprob:  0.626167, 0.246094 (1.473 sec)
10.605... logprob:  0.684426, 0.308594 (1.428 sec)
10.606... logprob:  0.583620, 0.257812 (1.438 sec)
10.607... logprob:  0.731594, 0.290365 (1.428 sec)
10.608... logprob:  0.592556, 0.256510 (1.419 sec)
10.609... logprob:  0.592020, 0.268229 (1.433 sec)
10.610... logprob:  0.656225, 0.265625 (1.468 sec)
10.611... logprob:  0.708941, 0.320312 (1.439 sec)
10.612... logprob:  0.672055, 0.291667 (1.448 sec)
10.613... logprob:  0.543947, 0.256510 (1.459 sec)
10.614... logprob:  0.730741, 0.291667 (1.444 sec)
10.615... logprob:  0.618476, 0.273437 (1.431 sec)
10.616... logprob:  0.646358, 0.285156 (1.426 sec)
10.617... logprob:  0.704148, 0.286458 (1.417 sec)
10.618... logprob:  0.773916, 0.317708 (1.434 sec)
10.619... logprob:  0.760463, 0.296875 (1.444 sec)
10.620... logprob:  0.730217, 0.321615 (1.456 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.465349, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.400458e-03 [2.732865e-07] 
Layer 'conv1' biases: 1.472651e-06 [1.195047e-09] 
Layer 'conv2' weights[0]: 5.390746e-03 [2.737722e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.006557e-08] 
Layer 'conv3' weights[0]: 5.389485e-03 [2.777575e-07] 
Layer 'conv3' biases: 2.538206e-05 [4.206035e-08] 
Layer 'conv4' weights[0]: 5.411564e-03 [2.873896e-07] 
Layer 'conv4' biases: 1.000015e+00 [6.511413e-07] 
Layer 'conv5' weights[0]: 5.472531e-03 [5.131782e-06] 
Layer 'conv5' biases: 9.991593e-01 [5.568470e-06] 
Layer 'fc6' weights[0]: 7.290422e-03 [9.562124e-08] 
Layer 'fc6' biases: 9.999962e-01 [1.111279e-07] 
Layer 'fc7' weights[0]: 7.643846e-03 [2.528139e-07] 
Layer 'fc7' biases: 9.998854e-01 [4.851406e-07] 
Layer 'fc8' weights[0]: 4.315336e-03 [3.660529e-05] 
Layer 'fc8' biases: 9.599561e-03 [9.025913e-05] 
Train error last 800 batches: 0.656603
-------------------------------------------------------
Not saving because 0.465349 > 0.299667 (9.300: -1.18%)
======================================================= (2.350 sec)
10.621... logprob:  0.609628, 0.250000 (1.458 sec)
10.622... logprob:  0.593864, 0.260417 (1.447 sec)
10.623... logprob:  0.720159, 0.305990 (1.465 sec)
10.624... logprob:  0.597258, 0.278646 (1.436 sec)
10.625... logprob:  0.666025, 0.261719 (1.417 sec)
10.626... logprob:  0.717395, 0.292969 (1.421 sec)
10.627... logprob:  0.588693, 0.253906 (1.460 sec)
10.628... logprob:  0.696934, 0.298177 (1.431 sec)
10.629... logprob:  0.645654, 0.320312 (1.473 sec)
10.630... logprob:  0.578290, 0.243490 (1.440 sec)
10.631... logprob:  0.850342, 0.350260 (1.433 sec)
10.632... logprob:  0.588850, 0.242187 (1.474 sec)
10.633... logprob:  0.661538, 0.313802 (1.428 sec)
10.634... logprob:  0.814231, 0.337240 (1.421 sec)
10.635... logprob:  0.644581, 0.295573 (1.430 sec)
10.636... logprob:  0.778599, 0.339844 (1.428 sec)
10.637... logprob:  0.579913, 0.244792 (1.425 sec)
10.638... logprob:  0.663439, 0.278646 (1.474 sec)
10.639... logprob:  0.691768, 0.276042 (1.433 sec)
10.640... logprob:  0.720319, 0.311198 (1.432 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.563170, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.395081e-03 [2.721219e-07] 
Layer 'conv1' biases: 1.478727e-06 [6.274401e-10] 
Layer 'conv2' weights[0]: 5.385318e-03 [2.707892e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.926139e-09] 
Layer 'conv3' weights[0]: 5.384112e-03 [2.719895e-07] 
Layer 'conv3' biases: 2.547822e-05 [2.474022e-08] 
Layer 'conv4' weights[0]: 5.406168e-03 [2.747939e-07] 
Layer 'conv4' biases: 1.000015e+00 [2.886975e-07] 
Layer 'conv5' weights[0]: 5.467365e-03 [2.623776e-06] 
Layer 'conv5' biases: 9.991826e-01 [2.727999e-06] 
Layer 'fc6' weights[0]: 7.289668e-03 [6.196157e-08] 
Layer 'fc6' biases: 9.999961e-01 [5.917946e-08] 
Layer 'fc7' weights[0]: 7.643116e-03 [1.365770e-07] 
Layer 'fc7' biases: 9.998831e-01 [1.561143e-07] 
Layer 'fc8' weights[0]: 4.232207e-03 [1.549097e-05] 
Layer 'fc8' biases: 8.996947e-03 [5.269975e-06] 
Train error last 800 batches: 0.656840
-------------------------------------------------------
Not saving because 0.563170 > 0.299667 (9.300: -1.18%)
======================================================= (2.396 sec)
10.641... logprob:  0.599421, 0.260417 (1.483 sec)
10.642... logprob:  0.740642, 0.304687 (1.437 sec)
10.643... logprob:  0.813732, 0.342448 (1.428 sec)
10.644... logprob:  0.539225, 0.230469 (1.427 sec)
10.645... logprob:  0.580699, 0.261719 (1.427 sec)
10.646... logprob:  0.667512, 0.281250 (1.425 sec)
10.647... logprob:  0.681387, 0.283854 (1.483 sec)
10.648... logprob:  0.639890, 0.273437 (1.427 sec)
10.649... logprob:  0.577730, 0.252604 (1.439 sec)
10.650... logprob:  0.577064, 0.230469 (1.474 sec)
10.651... logprob:  0.667895, 0.305989 (1.428 sec)
10.652... logprob:  0.628438, 0.279948 (1.432 sec)
10.653... logprob:  0.860421, 0.341146 (1.430 sec)
10.654... logprob:  0.723238, 0.322917 (1.425 sec)
10.655... logprob:  0.588439, 0.277344 (1.428 sec)
10.656... logprob:  0.593821, 0.259115 (1.471 sec)
10.657... logprob:  0.658607, 0.260417 (1.433 sec)
10.658... logprob:  0.569897, 0.265625 (1.447 sec)
10.659... logprob:  0.688592, 0.277344 (1.459 sec)
10.660... logprob:  0.645399, 0.285156 (1.434 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.420777, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.389678e-03 [2.717958e-07] 
Layer 'conv1' biases: 1.480284e-06 [6.473436e-10] 
Layer 'conv2' weights[0]: 5.379959e-03 [2.706243e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.393590e-09] 
Layer 'conv3' weights[0]: 5.378721e-03 [2.714352e-07] 
Layer 'conv3' biases: 2.552259e-05 [2.177142e-08] 
Layer 'conv4' weights[0]: 5.400783e-03 [2.742024e-07] 
Layer 'conv4' biases: 1.000014e+00 [2.938962e-07] 
Layer 'conv5' weights[0]: 5.461795e-03 [2.631057e-06] 
Layer 'conv5' biases: 9.991663e-01 [2.767902e-06] 
Layer 'fc6' weights[0]: 7.288926e-03 [6.054557e-08] 
Layer 'fc6' biases: 9.999961e-01 [5.711590e-08] 
Layer 'fc7' weights[0]: 7.642314e-03 [1.363303e-07] 
Layer 'fc7' biases: 9.998842e-01 [1.657457e-07] 
Layer 'fc8' weights[0]: 4.288161e-03 [1.636382e-05] 
Layer 'fc8' biases: 9.432909e-03 [2.481602e-05] 
Train error last 800 batches: 0.656177
-------------------------------------------------------
Not saving because 0.420777 > 0.299667 (9.300: -1.18%)
======================================================= (2.368 sec)
10.661... logprob:  0.661026, 0.302083 (1.436 sec)
10.662... logprob:  0.609954, 0.286458 (1.439 sec)
10.663... logprob:  0.551930, 0.243490 (1.421 sec)
10.664... logprob:  0.583932, 0.286458 (1.437 sec)
10.665... logprob:  0.572336, 0.260417 (1.451 sec)
10.666... logprob:  0.665020, 0.285156 (1.450 sec)
10.667... logprob:  0.753781, 0.348958 (1.455 sec)
10.668... logprob:  0.634124, 0.292969 (1.444 sec)
10.669... logprob:  0.631378, 0.290365 (1.453 sec)
10.670... logprob:  0.536035, 0.236979 (1.434 sec)
10.671... logprob:  0.609510, 0.286458 (1.418 sec)
10.672... logprob:  0.694544, 0.286458 (1.429 sec)
10.673... logprob:  0.538148, 0.231771 (1.435 sec)
10.674... logprob:  0.671307, 0.319010 (1.434 sec)
10.675... logprob:  0.604212, 0.264323 (1.460 sec)
10.676... logprob:  0.671452, 0.283854 (1.447 sec)
10.677... logprob:  0.673090, 0.295573 (1.479 sec)
10.678... logprob:  0.671843, 0.300781 (1.484 sec)
10.679... logprob:  0.695472, 0.290365 (1.425 sec)
10.680... logprob:  0.672195, 0.282552 (1.422 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.359540, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.384273e-03 [2.707829e-07] 
Layer 'conv1' biases: 1.480489e-06 [6.131871e-10] 
Layer 'conv2' weights[0]: 5.374613e-03 [2.703397e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.950915e-09] 
Layer 'conv3' weights[0]: 5.373322e-03 [2.710649e-07] 
Layer 'conv3' biases: 2.551890e-05 [2.227345e-08] 
Layer 'conv4' weights[0]: 5.395388e-03 [2.740246e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.025558e-07] 
Layer 'conv5' weights[0]: 5.456076e-03 [2.455897e-06] 
Layer 'conv5' biases: 9.991515e-01 [2.583507e-06] 
Layer 'fc6' weights[0]: 7.288142e-03 [6.446544e-08] 
Layer 'fc6' biases: 9.999962e-01 [6.359252e-08] 
Layer 'fc7' weights[0]: 7.641503e-03 [1.486534e-07] 
Layer 'fc7' biases: 9.998853e-01 [2.151724e-07] 
Layer 'fc8' weights[0]: 4.343145e-03 [2.050044e-05] 
Layer 'fc8' biases: 9.870767e-03 [4.356029e-05] 
Train error last 800 batches: 0.656248
-------------------------------------------------------
Not saving because 0.359540 > 0.299667 (9.300: -1.18%)
======================================================= (2.363 sec)
10.681... logprob:  0.609964, 0.272135 (1.436 sec)
10.682... logprob:  0.614231, 0.286458 (1.440 sec)
10.683... logprob:  0.682732, 0.290365 (1.427 sec)
10.684... logprob:  0.634158, 0.277344 (1.473 sec)
10.685... logprob:  0.575460, 0.256510 (1.436 sec)
10.686... logprob:  0.610045, 0.266927 (1.429 sec)
10.687... logprob:  0.506708, 0.234375 (1.486 sec)
10.688... logprob:  0.613707, 0.286458 (1.427 sec)
10.689... logprob:  0.680258, 0.312500 (1.422 sec)
10.690... logprob:  0.823672, 0.348958 (1.429 sec)
10.691... logprob:  0.737918, 0.308594 (1.423 sec)
10.692... logprob:  0.691242, 0.290365 (1.431 sec)
10.693... logprob:  0.658280, 0.264323 (1.475 sec)
10.694... logprob:  0.535922, 0.238281 (1.432 sec)
10.695... logprob:  0.518879, 0.210937 (1.435 sec)
10.696... logprob:  0.723136, 0.307292 (1.472 sec)
10.697... logprob:  0.720951, 0.307292 (1.426 sec)
10.698... logprob:  0.660377, 0.294271 (1.428 sec)
10.699... logprob:  0.609424, 0.283854 (1.427 sec)
10.700... logprob:  0.594747, 0.276042 (1.425 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.499423, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.378910e-03 [2.707170e-07] 
Layer 'conv1' biases: 1.481357e-06 [6.508731e-10] 
Layer 'conv2' weights[0]: 5.369217e-03 [2.696913e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.113036e-09] 
Layer 'conv3' weights[0]: 5.367908e-03 [2.704260e-07] 
Layer 'conv3' biases: 2.553568e-05 [2.021243e-08] 
Layer 'conv4' weights[0]: 5.390029e-03 [2.727685e-07] 
Layer 'conv4' biases: 1.000014e+00 [2.789067e-07] 
Layer 'conv5' weights[0]: 5.451538e-03 [2.292689e-06] 
Layer 'conv5' biases: 9.991503e-01 [2.496557e-06] 
Layer 'fc6' weights[0]: 7.287339e-03 [5.897234e-08] 
Layer 'fc6' biases: 9.999962e-01 [5.546638e-08] 
Layer 'fc7' weights[0]: 7.640697e-03 [1.340101e-07] 
Layer 'fc7' biases: 9.998839e-01 [1.715449e-07] 
Layer 'fc8' weights[0]: 4.308737e-03 [1.716745e-05] 
Layer 'fc8' biases: 9.650574e-03 [2.841282e-05] 
Train error last 800 batches: 0.656563
-------------------------------------------------------
Not saving because 0.499423 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
10.701... logprob:  0.694934, 0.309896 (1.436 sec)
10.702... logprob:  0.743629, 0.290365 (1.484 sec)
10.703... logprob:  0.584414, 0.261719 (1.435 sec)
10.704... logprob:  0.671580, 0.279948 (1.450 sec)
10.705... logprob:  0.639312, 0.289062 (1.465 sec)
10.706... logprob:  0.700236, 0.286458 (1.432 sec)
10.707... logprob:  0.702009, 0.313802 (1.428 sec)
10.708... logprob:  0.634054, 0.272135 (1.426 sec)
10.709... logprob:  0.654893, 0.274740 (1.418 sec)
10.710... logprob:  0.758363, 0.334635 (1.432 sec)
10.711... logprob:  0.645448, 0.253906 (1.459 sec)
10.712... logprob:  0.588276, 0.253906 (1.441 sec)
10.713... logprob:  0.743261, 0.316406 (1.445 sec)
10.714... logprob:  0.640646, 0.286458 (1.455 sec)
10.715... logprob:  0.628974, 0.298177 (1.443 sec)
10.716... logprob:  0.555092, 0.244792 (1.437 sec)
10.717... logprob:  0.607269, 0.269531 (1.417 sec)
10.718... logprob:  0.754250, 0.296875 (1.425 sec)
10.719... logprob:  0.580073, 0.265625 (1.426 sec)
10.720... logprob:  0.655088, 0.311198 (1.445 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.479744, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.373536e-03 [2.711589e-07] 
Layer 'conv1' biases: 1.485873e-06 [5.904186e-10] 
Layer 'conv2' weights[0]: 5.363864e-03 [2.695170e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.357472e-09] 
Layer 'conv3' weights[0]: 5.362513e-03 [2.701386e-07] 
Layer 'conv3' biases: 2.558265e-05 [2.033189e-08] 
Layer 'conv4' weights[0]: 5.384596e-03 [2.732508e-07] 
Layer 'conv4' biases: 1.000015e+00 [2.988951e-07] 
Layer 'conv5' weights[0]: 5.446909e-03 [2.655557e-06] 
Layer 'conv5' biases: 9.991527e-01 [2.734326e-06] 
Layer 'fc6' weights[0]: 7.286553e-03 [6.419328e-08] 
Layer 'fc6' biases: 9.999963e-01 [6.339523e-08] 
Layer 'fc7' weights[0]: 7.639972e-03 [1.468256e-07] 
Layer 'fc7' biases: 9.998822e-01 [2.086070e-07] 
Layer 'fc8' weights[0]: 4.276017e-03 [1.915082e-05] 
Layer 'fc8' biases: 9.386100e-03 [3.405535e-05] 
Train error last 800 batches: 0.656442
-------------------------------------------------------
Not saving because 0.479744 > 0.299667 (9.300: -1.18%)
======================================================= (2.351 sec)
10.721... logprob:  0.688897, 0.309896 (1.466 sec)
10.722... logprob:  0.779492, 0.303385 (1.458 sec)
10.723... logprob:  0.603324, 0.266927 (1.452 sec)
10.724... logprob:  0.593608, 0.276042 (1.474 sec)
10.725... logprob:  0.691442, 0.303385 (1.436 sec)
10.726... logprob:  0.589019, 0.270833 (1.425 sec)
10.727... logprob:  0.647536, 0.307292 (1.431 sec)
10.728... logprob:  0.579100, 0.259115 (1.431 sec)
10.729... logprob:  0.665257, 0.312500 (1.431 sec)
10.730... logprob:  0.750171, 0.325521 (1.472 sec)
10.731... logprob:  0.716638, 0.315104 (1.436 sec)
10.732... logprob:  0.565667, 0.253906 (1.426 sec)
10.733... logprob:  0.881302, 0.369792 (1.483 sec)
10.734... logprob:  0.599556, 0.268229 (1.425 sec)
10.735... logprob:  0.770656, 0.325521 (1.421 sec)
10.736... logprob:  0.842389, 0.365885 (1.433 sec)
10.737... logprob:  0.704292, 0.278646 (1.425 sec)
10.738... logprob:  0.693809, 0.291667 (1.433 sec)
10.739... logprob:  0.686697, 0.300781 (1.474 sec)
10.740... logprob:  0.626608, 0.268229 (1.436 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.437648, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.368178e-03 [2.712015e-07] 
Layer 'conv1' biases: 1.490621e-06 [9.667186e-10] 
Layer 'conv2' weights[0]: 5.358472e-03 [2.699874e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.629806e-09] 
Layer 'conv3' weights[0]: 5.357221e-03 [2.718187e-07] 
Layer 'conv3' biases: 2.560460e-05 [2.893156e-08] 
Layer 'conv4' weights[0]: 5.379208e-03 [2.765141e-07] 
Layer 'conv4' biases: 1.000015e+00 [4.432907e-07] 
Layer 'conv5' weights[0]: 5.441638e-03 [3.299606e-06] 
Layer 'conv5' biases: 9.991553e-01 [3.509536e-06] 
Layer 'fc6' weights[0]: 7.285813e-03 [7.119220e-08] 
Layer 'fc6' biases: 9.999964e-01 [7.306194e-08] 
Layer 'fc7' weights[0]: 7.639191e-03 [1.694099e-07] 
Layer 'fc7' biases: 9.998817e-01 [2.646903e-07] 
Layer 'fc8' weights[0]: 4.269508e-03 [2.271365e-05] 
Layer 'fc8' biases: 9.386367e-03 [4.037377e-05] 
Train error last 800 batches: 0.656327
-------------------------------------------------------
Not saving because 0.437648 > 0.299667 (9.300: -1.18%)
======================================================= (2.348 sec)
10.741... logprob:  0.666713, 0.308594 (1.435 sec)
10.742... logprob:  0.744543, 0.330729 (1.495 sec)
10.743... logprob:  0.628205, 0.308594 (1.435 sec)
10.744... logprob:  0.701296, 0.291667 (1.430 sec)
10.745... logprob:  0.675797, 0.281250 (1.429 sec)
10.746... logprob:  0.619997, 0.283854 (1.425 sec)
10.747... logprob:  0.579794, 0.257812 (1.431 sec)
10.748... logprob:  0.596081, 0.276042 (1.479 sec)
10.749... logprob:  0.607064, 0.300781 (1.427 sec)
10.750... logprob:  0.679310, 0.281250 (1.439 sec)
10.751... logprob:  0.527679, 0.250000 (1.475 sec)
10.752... logprob:  0.737474, 0.278646 (1.431 sec)
10.753... logprob:  0.687890, 0.285156 (1.436 sec)
10.754... logprob:  0.662235, 0.299479 (1.432 sec)
10.755... logprob:  0.637996, 0.286458 (1.417 sec)
10.756... logprob:  0.746423, 0.333333 (1.430 sec)
10.757... logprob:  0.617431, 0.268229 (1.464 sec)
10.758... logprob:  0.660423, 0.287760 (1.442 sec)
10.759... logprob:  0.620180, 0.250000 (1.447 sec)
10.760... logprob:  0.681560, 0.285156 (1.453 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.428624, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.362782e-03 [2.706030e-07] 
Layer 'conv1' biases: 1.496306e-06 [8.087649e-10] 
Layer 'conv2' weights[0]: 5.353140e-03 [2.693530e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.564297e-09] 
Layer 'conv3' weights[0]: 5.351913e-03 [2.708332e-07] 
Layer 'conv3' biases: 2.567730e-05 [2.430111e-08] 
Layer 'conv4' weights[0]: 5.373868e-03 [2.742378e-07] 
Layer 'conv4' biases: 1.000015e+00 [3.637837e-07] 
Layer 'conv5' weights[0]: 5.436466e-03 [2.704871e-06] 
Layer 'conv5' biases: 9.991397e-01 [2.880439e-06] 
Layer 'fc6' weights[0]: 7.285038e-03 [6.328609e-08] 
Layer 'fc6' biases: 9.999962e-01 [6.207008e-08] 
Layer 'fc7' weights[0]: 7.638454e-03 [1.470514e-07] 
Layer 'fc7' biases: 9.998837e-01 [2.017326e-07] 
Layer 'fc8' weights[0]: 4.338622e-03 [2.085339e-05] 
Layer 'fc8' biases: 9.886418e-03 [4.220400e-05] 
Train error last 800 batches: 0.655913
-------------------------------------------------------
Not saving because 0.428624 > 0.299667 (9.300: -1.18%)
======================================================= (2.396 sec)
10.761... logprob:  0.582846, 0.277344 (1.451 sec)
10.762... logprob:  0.672585, 0.289062 (1.439 sec)
10.763... logprob:  0.686266, 0.289062 (1.429 sec)
10.764... logprob:  0.685871, 0.292969 (1.426 sec)
10.765... logprob:  0.558275, 0.259115 (1.437 sec)
10.766... logprob:  0.636988, 0.277344 (1.443 sec)
10.767... logprob:  0.626833, 0.296875 (1.450 sec)
10.768... logprob:  0.623693, 0.274740 (1.465 sec)
10.769... logprob:  0.764600, 0.311198 (1.468 sec)
10.770... logprob:  0.611291, 0.252604 (1.472 sec)
10.771... logprob:  0.753569, 0.341146 (1.454 sec)
10.772... logprob:  0.677162, 0.299479 (1.439 sec)
10.773... logprob:  0.654063, 0.316406 (1.437 sec)
10.774... logprob:  0.656159, 0.294271 (1.455 sec)
10.775... logprob:  0.621375, 0.282552 (1.458 sec)
10.776... logprob:  0.692743, 0.289062 (1.473 sec)
10.777... logprob:  0.587847, 0.246094 (1.463 sec)
10.778... logprob:  0.621296, 0.260417 (1.469 sec)
10.779... logprob:  0.665677, 0.277344 (1.478 sec)
10.780... logprob:  0.674037, 0.302083 (1.453 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.382121, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.357470e-03 [2.695645e-07] 
Layer 'conv1' biases: 1.501361e-06 [8.959701e-10] 
Layer 'conv2' weights[0]: 5.347775e-03 [2.687167e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.591193e-09] 
Layer 'conv3' weights[0]: 5.346602e-03 [2.700949e-07] 
Layer 'conv3' biases: 2.575621e-05 [2.328047e-08] 
Layer 'conv4' weights[0]: 5.368493e-03 [2.722288e-07] 
Layer 'conv4' biases: 1.000014e+00 [3.066587e-07] 
Layer 'conv5' weights[0]: 5.430947e-03 [2.594194e-06] 
Layer 'conv5' biases: 9.991486e-01 [2.809610e-06] 
Layer 'fc6' weights[0]: 7.284291e-03 [6.339269e-08] 
Layer 'fc6' biases: 9.999962e-01 [6.207388e-08] 
Layer 'fc7' weights[0]: 7.637703e-03 [1.451403e-07] 
Layer 'fc7' biases: 9.998816e-01 [2.072303e-07] 
Layer 'fc8' weights[0]: 4.292428e-03 [1.814598e-05] 
Layer 'fc8' biases: 9.499406e-03 [3.326861e-05] 
Train error last 800 batches: 0.655745
-------------------------------------------------------
Not saving because 0.382121 > 0.299667 (9.300: -1.18%)
======================================================= (2.394 sec)
10.781... logprob:  0.544935, 0.265625 (1.449 sec)
10.782... logprob:  0.637704, 0.302083 (1.447 sec)
10.783... logprob:  0.799038, 0.337240 (1.455 sec)
10.784... logprob:  0.643803, 0.277344 (1.455 sec)
10.785... logprob:  0.780328, 0.350260 (1.482 sec)
10.786... logprob:  0.542231, 0.239583 (1.470 sec)
10.787... logprob:  0.713645, 0.317708 (1.453 sec)
10.788... logprob:  0.685672, 0.296875 (1.487 sec)
10.789... logprob:  0.509340, 0.231771 (1.446 sec)
10.790... logprob:  0.678629, 0.303385 (1.442 sec)
10.791... logprob:  0.611596, 0.279948 (1.451 sec)
10.792... logprob:  0.626804, 0.294271 (1.450 sec)
10.793... logprob:  0.527005, 0.229167 (1.448 sec)
10.794... logprob:  0.607742, 0.236979 (1.483 sec)
10.795... logprob:  0.653679, 0.289062 (1.462 sec)
10.796... logprob:  0.672289, 0.311198 (1.460 sec)
10.797... logprob:  0.585313, 0.259115 (1.497 sec)
10.798... logprob:  0.650168, 0.286458 (1.445 sec)
10.799... logprob:  0.572583, 0.227865 (1.441 sec)
10.800... logprob:  0.619065, 0.278646 (1.400 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.550599, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.352130e-03 [2.703335e-07] 
Layer 'conv1' biases: 1.504385e-06 [7.799266e-10] 
Layer 'conv2' weights[0]: 5.342430e-03 [2.689245e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.708300e-09] 
Layer 'conv3' weights[0]: 5.341211e-03 [2.703970e-07] 
Layer 'conv3' biases: 2.581284e-05 [2.568070e-08] 
Layer 'conv4' weights[0]: 5.363117e-03 [2.745298e-07] 
Layer 'conv4' biases: 1.000012e+00 [3.963316e-07] 
Layer 'conv5' weights[0]: 5.424992e-03 [3.142584e-06] 
Layer 'conv5' biases: 9.991425e-01 [3.394325e-06] 
Layer 'fc6' weights[0]: 7.283513e-03 [7.420449e-08] 
Layer 'fc6' biases: 9.999962e-01 [7.758057e-08] 
Layer 'fc7' weights[0]: 7.636910e-03 [1.811327e-07] 
Layer 'fc7' biases: 9.998823e-01 [3.100031e-07] 
Layer 'fc8' weights[0]: 4.326696e-03 [2.656645e-05] 
Layer 'fc8' biases: 9.805065e-03 [5.647590e-05] 
Train error last 800 batches: 0.656027
-------------------------------------------------------
Not saving because 0.550599 > 0.299667 (9.300: -1.18%)
======================================================= (2.369 sec)
11.1... logprob:  0.587397, 0.257812 (1.407 sec)
11.2... logprob:  0.615432, 0.286458 (1.448 sec)
11.3... logprob:  0.598699, 0.236979 (1.418 sec)
11.4... logprob:  0.669199, 0.300781 (1.405 sec)
11.5... logprob:  0.611802, 0.263021 (1.433 sec)
11.6... logprob:  0.611564, 0.274740 (1.393 sec)
11.7... logprob:  0.582989, 0.246094 (1.415 sec)
11.8... logprob:  0.614612, 0.276042 (1.390 sec)
11.9... logprob:  0.637180, 0.274740 (1.398 sec)
11.10... logprob:  0.626112, 0.263021 (1.405 sec)
11.11... logprob:  0.600359, 0.315104 (1.447 sec)
11.12... logprob:  0.618931, 0.265625 (1.393 sec)
11.13... logprob:  0.739627, 0.335938 (1.417 sec)
11.14... logprob:  0.699019, 0.305990 (1.399 sec)
11.15... logprob:  0.563883, 0.236979 (1.402 sec)
11.16... logprob:  0.635093, 0.291667 (1.401 sec)
11.17... logprob:  0.754074, 0.274740 (1.390 sec)
11.18... logprob:  0.557984, 0.268229 (1.393 sec)
11.19... logprob:  0.500922, 0.229167 (1.392 sec)
11.20... logprob:  0.666059, 0.295573 (1.403 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.441589, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.346773e-03 [2.689697e-07] 
Layer 'conv1' biases: 1.507663e-06 [6.505330e-10] 
Layer 'conv2' weights[0]: 5.337090e-03 [2.680514e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.898418e-09] 
Layer 'conv3' weights[0]: 5.335855e-03 [2.691510e-07] 
Layer 'conv3' biases: 2.580235e-05 [2.233990e-08] 
Layer 'conv4' weights[0]: 5.357775e-03 [2.718152e-07] 
Layer 'conv4' biases: 1.000011e+00 [2.878483e-07] 
Layer 'conv5' weights[0]: 5.419390e-03 [2.406908e-06] 
Layer 'conv5' biases: 9.991364e-01 [2.422082e-06] 
Layer 'fc6' weights[0]: 7.282739e-03 [5.681662e-08] 
Layer 'fc6' biases: 9.999962e-01 [5.253615e-08] 
Layer 'fc7' weights[0]: 7.636152e-03 [1.262070e-07] 
Layer 'fc7' biases: 9.998829e-01 [1.499640e-07] 
Layer 'fc8' weights[0]: 4.355324e-03 [1.415440e-05] 
Layer 'fc8' biases: 1.007519e-02 [1.381447e-05] 
Train error last 800 batches: 0.655426
-------------------------------------------------------
Not saving because 0.441589 > 0.299667 (9.300: -1.18%)
======================================================= (2.415 sec)
11.21... logprob:  0.681751, 0.279948 (1.405 sec)
11.22... logprob:  0.727925, 0.303385 (1.413 sec)
11.23... logprob:  0.765135, 0.316406 (1.418 sec)
11.24... logprob:  0.567585, 0.272135 (1.416 sec)
11.25... logprob:  0.469503, 0.223958 (1.397 sec)
11.26... logprob:  0.700316, 0.319010 (1.444 sec)
11.27... logprob:  0.644601, 0.278646 (1.391 sec)
11.28... logprob:  0.612745, 0.277344 (1.412 sec)
11.29... logprob:  0.579959, 0.270833 (1.416 sec)
11.30... logprob:  0.655487, 0.279948 (1.410 sec)
11.31... logprob:  0.679498, 0.282552 (1.404 sec)
11.32... logprob:  0.700296, 0.312500 (1.384 sec)
11.33... logprob:  0.729830, 0.324219 (1.447 sec)
11.34... logprob:  0.627646, 0.292969 (1.390 sec)
11.35... logprob:  0.502412, 0.242187 (1.392 sec)
11.36... logprob:  0.701151, 0.333333 (1.400 sec)
11.37... logprob:  0.647325, 0.287760 (1.405 sec)
11.38... logprob:  0.684344, 0.277344 (1.384 sec)
11.39... logprob:  0.899627, 0.345052 (1.432 sec)
11.40... logprob:  0.524126, 0.229167 (1.403 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.396897, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.341440e-03 [2.695707e-07] 
Layer 'conv1' biases: 1.513095e-06 [7.471234e-10] 
Layer 'conv2' weights[0]: 5.331778e-03 [2.685092e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.928380e-09] 
Layer 'conv3' weights[0]: 5.330476e-03 [2.706176e-07] 
Layer 'conv3' biases: 2.577081e-05 [2.836672e-08] 
Layer 'conv4' weights[0]: 5.352395e-03 [2.741080e-07] 
Layer 'conv4' biases: 1.000011e+00 [3.775612e-07] 
Layer 'conv5' weights[0]: 5.413978e-03 [3.127952e-06] 
Layer 'conv5' biases: 9.991477e-01 [3.377760e-06] 
Layer 'fc6' weights[0]: 7.281974e-03 [6.675110e-08] 
Layer 'fc6' biases: 9.999964e-01 [6.703058e-08] 
Layer 'fc7' weights[0]: 7.635386e-03 [1.589648e-07] 
Layer 'fc7' biases: 9.998809e-01 [2.356358e-07] 
Layer 'fc8' weights[0]: 4.303348e-03 [2.130572e-05] 
Layer 'fc8' biases: 9.676286e-03 [3.888088e-05] 
Train error last 800 batches: 0.655381
-------------------------------------------------------
Not saving because 0.396897 > 0.299667 (9.300: -1.18%)
======================================================= (2.360 sec)
11.41... logprob:  0.674561, 0.317708 (1.429 sec)
11.42... logprob:  0.655536, 0.290365 (1.420 sec)
11.43... logprob:  0.722917, 0.294271 (1.411 sec)
11.44... logprob:  0.620665, 0.260417 (1.432 sec)
11.45... logprob:  0.714291, 0.294271 (1.386 sec)
11.46... logprob:  0.757770, 0.311198 (1.395 sec)
11.47... logprob:  0.596115, 0.282552 (1.386 sec)
11.48... logprob:  0.671845, 0.298177 (1.418 sec)
11.49... logprob:  0.672227, 0.302083 (1.407 sec)
11.50... logprob:  0.705584, 0.300781 (1.416 sec)
11.51... logprob:  0.682173, 0.278646 (1.414 sec)
11.52... logprob:  0.686726, 0.308594 (1.400 sec)
11.53... logprob:  0.546896, 0.243490 (1.437 sec)
11.54... logprob:  0.659479, 0.308594 (1.384 sec)
11.55... logprob:  0.577015, 0.285156 (1.392 sec)
11.56... logprob:  0.618675, 0.263021 (1.394 sec)
11.57... logprob:  0.823746, 0.375000 (1.422 sec)
11.58... logprob:  0.654632, 0.304687 (1.411 sec)
11.59... logprob:  0.592885, 0.286458 (1.460 sec)
11.60... logprob:  0.839135, 0.329427 (1.411 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.446155, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.336096e-03 [2.691608e-07] 
Layer 'conv1' biases: 1.513000e-06 [6.696257e-10] 
Layer 'conv2' weights[0]: 5.326449e-03 [2.680462e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.068904e-09] 
Layer 'conv3' weights[0]: 5.325152e-03 [2.693233e-07] 
Layer 'conv3' biases: 2.582301e-05 [2.481368e-08] 
Layer 'conv4' weights[0]: 5.347068e-03 [2.722390e-07] 
Layer 'conv4' biases: 1.000011e+00 [3.637177e-07] 
Layer 'conv5' weights[0]: 5.409427e-03 [2.729611e-06] 
Layer 'conv5' biases: 9.991498e-01 [2.915301e-06] 
Layer 'fc6' weights[0]: 7.281211e-03 [6.456539e-08] 
Layer 'fc6' biases: 9.999962e-01 [6.365447e-08] 
Layer 'fc7' weights[0]: 7.634657e-03 [1.494167e-07] 
Layer 'fc7' biases: 9.998803e-01 [2.100928e-07] 
Layer 'fc8' weights[0]: 4.305589e-03 [2.111452e-05] 
Layer 'fc8' biases: 9.647074e-03 [3.860259e-05] 
Train error last 800 batches: 0.656030
-------------------------------------------------------
Not saving because 0.446155 > 0.299667 (9.300: -1.18%)
======================================================= (2.378 sec)
11.61... logprob:  0.511100, 0.225260 (1.432 sec)
11.62... logprob:  0.711125, 0.317708 (1.457 sec)
11.63... logprob:  0.634121, 0.270833 (1.436 sec)
11.64... logprob:  0.711330, 0.313802 (1.539 sec)
11.65... logprob:  0.573846, 0.257812 (1.394 sec)
11.66... logprob:  0.614974, 0.281250 (1.435 sec)
11.67... logprob:  0.558757, 0.264323 (1.385 sec)
11.68... logprob:  0.695588, 0.302083 (1.397 sec)
11.69... logprob:  0.686191, 0.286458 (1.423 sec)
11.70... logprob:  0.609969, 0.302083 (1.422 sec)
11.71... logprob:  0.557940, 0.266927 (1.453 sec)
11.72... logprob:  0.708213, 0.309896 (1.398 sec)
11.73... logprob:  0.625846, 0.276042 (1.418 sec)
11.74... logprob:  0.717798, 0.333333 (1.412 sec)
11.75... logprob:  0.564486, 0.250000 (1.405 sec)
11.76... logprob:  0.586286, 0.253906 (1.434 sec)
11.77... logprob:  0.624523, 0.269531 (1.431 sec)
11.78... logprob:  0.688847, 0.298177 (1.453 sec)
11.79... logprob:  0.649038, 0.303385 (1.407 sec)
11.80... logprob:  0.749984, 0.311198 (1.419 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.467056, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.330752e-03 [2.680049e-07] 
Layer 'conv1' biases: 1.512245e-06 [5.325648e-10] 
Layer 'conv2' weights[0]: 5.321145e-03 [2.669598e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.115121e-09] 
Layer 'conv3' weights[0]: 5.319840e-03 [2.681401e-07] 
Layer 'conv3' biases: 2.589762e-05 [2.148978e-08] 
Layer 'conv4' weights[0]: 5.341731e-03 [2.704186e-07] 
Layer 'conv4' biases: 1.000013e+00 [2.677605e-07] 
Layer 'conv5' weights[0]: 5.404949e-03 [2.270134e-06] 
Layer 'conv5' biases: 9.991356e-01 [2.457364e-06] 
Layer 'fc6' weights[0]: 7.280461e-03 [5.940110e-08] 
Layer 'fc6' biases: 9.999962e-01 [5.622515e-08] 
Layer 'fc7' weights[0]: 7.633891e-03 [1.321163e-07] 
Layer 'fc7' biases: 9.998812e-01 [1.625202e-07] 
Layer 'fc8' weights[0]: 4.353661e-03 [1.557406e-05] 
Layer 'fc8' biases: 1.004787e-02 [1.683221e-05] 
Train error last 800 batches: 0.655665
-------------------------------------------------------
Not saving because 0.467056 > 0.299667 (9.300: -1.18%)
======================================================= (2.367 sec)
11.81... logprob:  0.697582, 0.342448 (1.414 sec)
11.82... logprob:  0.483595, 0.196615 (1.424 sec)
11.83... logprob:  0.700983, 0.291667 (1.399 sec)
11.84... logprob:  0.721687, 0.281250 (1.467 sec)
11.85... logprob:  0.622000, 0.286458 (1.417 sec)
11.86... logprob:  0.719721, 0.325521 (1.412 sec)
11.87... logprob:  0.800300, 0.292969 (1.411 sec)
11.88... logprob:  0.740191, 0.329427 (1.406 sec)
11.89... logprob:  0.539557, 0.240885 (1.431 sec)
11.90... logprob:  0.758514, 0.351562 (1.389 sec)
11.91... logprob:  0.550016, 0.235677 (1.389 sec)
11.92... logprob:  0.674050, 0.294271 (1.396 sec)
11.93... logprob:  0.613759, 0.269531 (1.395 sec)
11.94... logprob:  0.602154, 0.299479 (1.394 sec)
11.95... logprob:  0.594942, 0.261719 (1.395 sec)
11.96... logprob:  0.719729, 0.328125 (1.399 sec)
11.97... logprob:  0.650484, 0.274740 (1.413 sec)
11.98... logprob:  0.595059, 0.257812 (1.432 sec)
11.99... logprob:  0.655122, 0.279948 (1.402 sec)
11.100... logprob:  0.571126, 0.272135 (1.397 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.504616, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.325452e-03 [2.681803e-07] 
Layer 'conv1' biases: 1.513701e-06 [5.698123e-10] 
Layer 'conv2' weights[0]: 5.315783e-03 [2.673590e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.470798e-09] 
Layer 'conv3' weights[0]: 5.314486e-03 [2.676992e-07] 
Layer 'conv3' biases: 2.596269e-05 [1.831573e-08] 
Layer 'conv4' weights[0]: 5.336410e-03 [2.707899e-07] 
Layer 'conv4' biases: 1.000015e+00 [2.845028e-07] 
Layer 'conv5' weights[0]: 5.400329e-03 [2.504809e-06] 
Layer 'conv5' biases: 9.991465e-01 [2.645128e-06] 
Layer 'fc6' weights[0]: 7.279712e-03 [5.895327e-08] 
Layer 'fc6' biases: 9.999961e-01 [5.538935e-08] 
Layer 'fc7' weights[0]: 7.633083e-03 [1.319943e-07] 
Layer 'fc7' biases: 9.998795e-01 [1.685930e-07] 
Layer 'fc8' weights[0]: 4.295762e-03 [1.668273e-05] 
Layer 'fc8' biases: 9.647850e-03 [2.354802e-05] 
Train error last 800 batches: 0.655228
-------------------------------------------------------
Not saving because 0.504616 > 0.299667 (9.300: -1.18%)
======================================================= (2.365 sec)
11.101... logprob:  0.631955, 0.287760 (1.444 sec)
11.102... logprob:  0.735137, 0.281250 (1.392 sec)
11.103... logprob:  0.743929, 0.313802 (1.396 sec)
11.104... logprob:  0.571382, 0.257812 (1.399 sec)
11.105... logprob:  0.901789, 0.385417 (1.396 sec)
11.106... logprob:  0.504390, 0.238281 (1.389 sec)
11.107... logprob:  0.585350, 0.266927 (1.435 sec)
11.108... logprob:  0.800334, 0.348958 (1.389 sec)
11.109... logprob:  0.564172, 0.236979 (1.395 sec)
11.110... logprob:  0.728941, 0.329427 (1.389 sec)
11.111... logprob:  0.672784, 0.289063 (1.396 sec)
11.112... logprob:  0.586007, 0.251302 (1.394 sec)
11.113... logprob:  0.632349, 0.292969 (1.397 sec)
11.114... logprob:  0.566826, 0.260417 (1.432 sec)
11.115... logprob:  0.641191, 0.273437 (1.402 sec)
11.116... logprob:  0.597697, 0.269531 (1.393 sec)
11.117... logprob:  0.698872, 0.315104 (1.434 sec)
11.118... logprob:  0.579435, 0.235677 (1.386 sec)
11.119... logprob:  0.592689, 0.268229 (1.389 sec)
11.120... logprob:  0.651430, 0.266927 (1.397 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.512989, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.320127e-03 [2.686348e-07] 
Layer 'conv1' biases: 1.516626e-06 [6.520208e-10] 
Layer 'conv2' weights[0]: 5.310502e-03 [2.674639e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.513126e-09] 
Layer 'conv3' weights[0]: 5.309216e-03 [2.689958e-07] 
Layer 'conv3' biases: 2.598291e-05 [2.505902e-08] 
Layer 'conv4' weights[0]: 5.331067e-03 [2.717833e-07] 
Layer 'conv4' biases: 1.000015e+00 [3.461183e-07] 
Layer 'conv5' weights[0]: 5.395201e-03 [2.811042e-06] 
Layer 'conv5' biases: 9.991332e-01 [3.023395e-06] 
Layer 'fc6' weights[0]: 7.278933e-03 [6.262898e-08] 
Layer 'fc6' biases: 9.999962e-01 [6.135264e-08] 
Layer 'fc7' weights[0]: 7.632302e-03 [1.437841e-07] 
Layer 'fc7' biases: 9.998801e-01 [1.997671e-07] 
Layer 'fc8' weights[0]: 4.330389e-03 [1.816206e-05] 
Layer 'fc8' biases: 9.830677e-03 [3.067763e-05] 
Train error last 800 batches: 0.654947
-------------------------------------------------------
Not saving because 0.512989 > 0.299667 (9.300: -1.18%)
======================================================= (2.370 sec)
11.121... logprob:  0.668424, 0.307292 (1.405 sec)
11.122... logprob:  0.667661, 0.309896 (1.447 sec)
11.123... logprob:  0.581208, 0.248698 (1.387 sec)
11.124... logprob:  0.651986, 0.282552 (1.394 sec)
11.125... logprob:  0.672838, 0.287760 (1.395 sec)
11.126... logprob:  0.683391, 0.290365 (1.389 sec)
11.127... logprob:  0.686131, 0.311198 (1.397 sec)
11.128... logprob:  0.656489, 0.274740 (1.416 sec)
11.129... logprob:  0.839621, 0.345052 (1.415 sec)
11.130... logprob:  0.657137, 0.294271 (1.418 sec)
11.131... logprob:  0.698083, 0.296875 (1.410 sec)
11.132... logprob:  0.710145, 0.313802 (1.435 sec)
11.133... logprob:  0.717850, 0.321615 (1.392 sec)
11.134... logprob:  0.681436, 0.313802 (1.395 sec)
11.135... logprob:  0.689478, 0.291667 (1.396 sec)
11.136... logprob:  0.722948, 0.329427 (1.406 sec)
11.137... logprob:  0.629630, 0.272135 (1.393 sec)
11.138... logprob:  0.546502, 0.248698 (1.446 sec)
11.139... logprob:  0.709051, 0.315104 (1.388 sec)
11.140... logprob:  0.732092, 0.326823 (1.407 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.522465, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.314841e-03 [2.679928e-07] 
Layer 'conv1' biases: 1.519795e-06 [6.063470e-10] 
Layer 'conv2' weights[0]: 5.305188e-03 [2.667961e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.608159e-09] 
Layer 'conv3' weights[0]: 5.303931e-03 [2.679384e-07] 
Layer 'conv3' biases: 2.601689e-05 [2.398716e-08] 
Layer 'conv4' weights[0]: 5.325727e-03 [2.703160e-07] 
Layer 'conv4' biases: 1.000016e+00 [3.237080e-07] 
Layer 'conv5' weights[0]: 5.390396e-03 [2.445859e-06] 
Layer 'conv5' biases: 9.991404e-01 [2.631210e-06] 
Layer 'fc6' weights[0]: 7.278168e-03 [6.340771e-08] 
Layer 'fc6' biases: 9.999961e-01 [6.213057e-08] 
Layer 'fc7' weights[0]: 7.631576e-03 [1.493584e-07] 
Layer 'fc7' biases: 9.998790e-01 [2.129269e-07] 
Layer 'fc8' weights[0]: 4.279009e-03 [1.910048e-05] 
Layer 'fc8' biases: 9.502014e-03 [2.729209e-05] 
Train error last 800 batches: 0.655226
-------------------------------------------------------
Not saving because 0.522465 > 0.299667 (9.300: -1.18%)
======================================================= (2.405 sec)
11.141... logprob:  0.642866, 0.290365 (1.442 sec)
11.142... logprob:  0.648171, 0.283854 (1.400 sec)
11.143... logprob:  0.567034, 0.257812 (1.424 sec)
11.144... logprob:  0.694597, 0.303385 (1.410 sec)
11.145... logprob:  0.605554, 0.290365 (1.407 sec)
11.146... logprob:  0.649326, 0.313802 (1.405 sec)
11.147... logprob:  0.566530, 0.257812 (1.423 sec)
11.148... logprob:  0.676738, 0.308594 (1.389 sec)
11.149... logprob:  0.613828, 0.256510 (1.392 sec)
11.150... logprob:  0.655130, 0.315104 (1.398 sec)
11.151... logprob:  0.510418, 0.221354 (1.398 sec)
11.152... logprob:  0.862404, 0.338542 (1.380 sec)
11.153... logprob:  0.640462, 0.285156 (1.442 sec)
11.154... logprob:  0.747092, 0.328125 (1.392 sec)
11.155... logprob:  0.723699, 0.319010 (1.399 sec)
11.156... logprob:  0.506799, 0.242187 (1.433 sec)
11.157... logprob:  0.517493, 0.257812 (1.392 sec)
11.158... logprob:  0.716753, 0.311198 (1.397 sec)
11.159... logprob:  0.665885, 0.261719 (1.389 sec)
11.160... logprob:  0.685072, 0.277344 (1.390 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.446574, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.309500e-03 [2.674486e-07] 
Layer 'conv1' biases: 1.522437e-06 [5.999021e-10] 
Layer 'conv2' weights[0]: 5.299859e-03 [2.660466e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.333212e-09] 
Layer 'conv3' weights[0]: 5.298622e-03 [2.676625e-07] 
Layer 'conv3' biases: 2.604761e-05 [2.357179e-08] 
Layer 'conv4' weights[0]: 5.320386e-03 [2.708103e-07] 
Layer 'conv4' biases: 1.000015e+00 [3.456767e-07] 
Layer 'conv5' weights[0]: 5.385040e-03 [2.674474e-06] 
Layer 'conv5' biases: 9.991315e-01 [2.850742e-06] 
Layer 'fc6' weights[0]: 7.277394e-03 [6.026694e-08] 
Layer 'fc6' biases: 9.999961e-01 [5.787944e-08] 
Layer 'fc7' weights[0]: 7.630795e-03 [1.381429e-07] 
Layer 'fc7' biases: 9.998793e-01 [1.731102e-07] 
Layer 'fc8' weights[0]: 4.313368e-03 [1.769849e-05] 
Layer 'fc8' biases: 9.783302e-03 [3.140700e-05] 
Train error last 800 batches: 0.655022
-------------------------------------------------------
Not saving because 0.446574 > 0.299667 (9.300: -1.18%)
======================================================= (2.383 sec)
11.161... logprob:  0.569654, 0.247396 (1.405 sec)
11.162... logprob:  0.824117, 0.334635 (1.404 sec)
11.163... logprob:  0.640792, 0.308594 (1.420 sec)
11.164... logprob:  0.712596, 0.330729 (1.420 sec)
11.165... logprob:  0.748844, 0.320312 (1.420 sec)
11.166... logprob:  0.686221, 0.292969 (1.443 sec)
11.167... logprob:  0.643362, 0.268229 (1.424 sec)
11.168... logprob:  0.601364, 0.242188 (1.423 sec)
11.169... logprob:  0.595435, 0.272135 (1.455 sec)
11.170... logprob:  0.672233, 0.299479 (1.394 sec)
11.171... logprob:  0.730378, 0.290365 (1.414 sec)
11.172... logprob:  0.577336, 0.248698 (1.407 sec)
11.173... logprob:  0.575761, 0.234375 (1.418 sec)
11.174... logprob:  0.650870, 0.292969 (1.402 sec)
11.175... logprob:  0.680874, 0.308594 (1.496 sec)
11.176... logprob:  0.632078, 0.283854 (1.409 sec)
11.177... logprob:  0.508006, 0.216146 (1.420 sec)
11.178... logprob:  0.582619, 0.252604 (1.449 sec)
11.179... logprob:  0.742683, 0.332031 (1.401 sec)
11.180... logprob:  0.722290, 0.302083 (1.415 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.424435, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.304206e-03 [2.672692e-07] 
Layer 'conv1' biases: 1.524280e-06 [6.806502e-10] 
Layer 'conv2' weights[0]: 5.294572e-03 [2.662908e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.494748e-09] 
Layer 'conv3' weights[0]: 5.293341e-03 [2.674729e-07] 
Layer 'conv3' biases: 2.611703e-05 [2.291879e-08] 
Layer 'conv4' weights[0]: 5.315046e-03 [2.704085e-07] 
Layer 'conv4' biases: 1.000016e+00 [3.480547e-07] 
Layer 'conv5' weights[0]: 5.379975e-03 [2.604020e-06] 
Layer 'conv5' biases: 9.991320e-01 [2.823011e-06] 
Layer 'fc6' weights[0]: 7.276672e-03 [6.632578e-08] 
Layer 'fc6' biases: 9.999961e-01 [6.673817e-08] 
Layer 'fc7' weights[0]: 7.630026e-03 [1.565376e-07] 
Layer 'fc7' biases: 9.998792e-01 [2.375770e-07] 
Layer 'fc8' weights[0]: 4.311670e-03 [2.417026e-05] 
Layer 'fc8' biases: 9.839519e-03 [5.638280e-05] 
Train error last 800 batches: 0.654641
-------------------------------------------------------
Not saving because 0.424435 > 0.299667 (9.300: -1.18%)
======================================================= (2.380 sec)
11.181... logprob:  0.717852, 0.328125 (1.419 sec)
11.182... logprob:  0.590151, 0.261719 (1.415 sec)
11.183... logprob:  0.632294, 0.242187 (1.408 sec)
11.184... logprob:  0.670160, 0.274740 (1.411 sec)
11.185... logprob:  0.559836, 0.264323 (1.392 sec)
11.186... logprob:  0.597304, 0.277344 (1.394 sec)
11.187... logprob:  0.633562, 0.283854 (1.392 sec)
11.188... logprob:  0.745122, 0.316406 (1.386 sec)
11.189... logprob:  0.665249, 0.255208 (1.393 sec)
11.190... logprob:  0.631812, 0.285156 (1.432 sec)
11.191... logprob:  0.715198, 0.304687 (1.400 sec)
11.192... logprob:  0.695851, 0.312500 (1.413 sec)
11.193... logprob:  0.593146, 0.268229 (1.417 sec)
11.194... logprob:  0.641567, 0.291667 (1.410 sec)
11.195... logprob:  0.558558, 0.247396 (1.389 sec)
11.196... logprob:  0.608629, 0.289062 (1.387 sec)
11.197... logprob:  0.622497, 0.261719 (1.393 sec)
11.198... logprob:  0.597482, 0.278646 (1.405 sec)
11.199... logprob:  0.638554, 0.279948 (1.382 sec)
11.200... logprob:  0.583479, 0.276042 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.550372, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.298908e-03 [2.666288e-07] 
Layer 'conv1' biases: 1.525549e-06 [5.194622e-10] 
Layer 'conv2' weights[0]: 5.289304e-03 [2.658742e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.544649e-09] 
Layer 'conv3' weights[0]: 5.287989e-03 [2.665552e-07] 
Layer 'conv3' biases: 2.616352e-05 [2.079124e-08] 
Layer 'conv4' weights[0]: 5.309775e-03 [2.696586e-07] 
Layer 'conv4' biases: 1.000017e+00 [2.969128e-07] 
Layer 'conv5' weights[0]: 5.375759e-03 [2.314885e-06] 
Layer 'conv5' biases: 9.991228e-01 [2.415532e-06] 
Layer 'fc6' weights[0]: 7.275906e-03 [5.880880e-08] 
Layer 'fc6' biases: 9.999961e-01 [5.530109e-08] 
Layer 'fc7' weights[0]: 7.629220e-03 [1.319356e-07] 
Layer 'fc7' biases: 9.998794e-01 [1.746705e-07] 
Layer 'fc8' weights[0]: 4.324094e-03 [1.640963e-05] 
Layer 'fc8' biases: 9.893467e-03 [2.680627e-05] 
Train error last 800 batches: 0.654359
-------------------------------------------------------
Not saving because 0.550372 > 0.299667 (9.300: -1.18%)
======================================================= (2.390 sec)
11.201... logprob:  0.652281, 0.281250 (1.413 sec)
11.202... logprob:  0.691063, 0.317708 (1.403 sec)
11.203... logprob:  0.715226, 0.324219 (1.440 sec)
11.204... logprob:  0.660404, 0.287760 (1.389 sec)
11.205... logprob:  0.501744, 0.222656 (1.403 sec)
11.206... logprob:  0.548265, 0.243490 (1.396 sec)
11.207... logprob:  0.659685, 0.282552 (1.387 sec)
11.208... logprob:  0.717589, 0.322917 (1.390 sec)
11.209... logprob:  0.708633, 0.326823 (1.422 sec)
11.210... logprob:  0.878150, 0.343750 (1.405 sec)
11.211... logprob:  0.776737, 0.342448 (1.410 sec)
11.212... logprob:  0.782867, 0.352865 (1.409 sec)
11.213... logprob:  0.738025, 0.322917 (1.459 sec)
11.214... logprob:  0.570282, 0.283854 (1.448 sec)
11.215... logprob:  0.645962, 0.285156 (1.409 sec)
11.216... logprob:  0.702882, 0.305990 (1.463 sec)
11.217... logprob:  0.599010, 0.298177 (1.395 sec)
11.218... logprob:  0.624832, 0.272135 (1.416 sec)
11.219... logprob:  0.661980, 0.305990 (1.406 sec)
11.220... logprob:  0.609930, 0.281250 (1.416 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.400919, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.293614e-03 [2.662606e-07] 
Layer 'conv1' biases: 1.528149e-06 [5.833921e-10] 
Layer 'conv2' weights[0]: 5.284016e-03 [2.650826e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.964396e-09] 
Layer 'conv3' weights[0]: 5.282739e-03 [2.659321e-07] 
Layer 'conv3' biases: 2.620976e-05 [1.839870e-08] 
Layer 'conv4' weights[0]: 5.304449e-03 [2.682115e-07] 
Layer 'conv4' biases: 1.000016e+00 [2.243213e-07] 
Layer 'conv5' weights[0]: 5.370576e-03 [1.935248e-06] 
Layer 'conv5' biases: 9.991332e-01 [2.053197e-06] 
Layer 'fc6' weights[0]: 7.275108e-03 [5.522313e-08] 
Layer 'fc6' biases: 9.999959e-01 [4.966283e-08] 
Layer 'fc7' weights[0]: 7.628463e-03 [1.222314e-07] 
Layer 'fc7' biases: 9.998783e-01 [1.374417e-07] 
Layer 'fc8' weights[0]: 4.287336e-03 [1.401618e-05] 
Layer 'fc8' biases: 9.650897e-03 [1.411664e-05] 
Train error last 800 batches: 0.654009
-------------------------------------------------------
Not saving because 0.400919 > 0.299667 (9.300: -1.18%)
======================================================= (2.396 sec)
11.221... logprob:  0.594722, 0.242188 (1.411 sec)
11.222... logprob:  0.683081, 0.315104 (1.458 sec)
11.223... logprob:  0.769390, 0.330729 (1.429 sec)
11.224... logprob:  0.683235, 0.294271 (1.430 sec)
11.225... logprob:  0.601951, 0.243490 (1.449 sec)
11.226... logprob:  0.644339, 0.278646 (1.424 sec)
11.227... logprob:  0.626157, 0.256510 (1.414 sec)
11.228... logprob:  0.714397, 0.307292 (1.409 sec)
11.229... logprob:  0.746093, 0.320312 (1.409 sec)
11.230... logprob:  0.668577, 0.287760 (1.433 sec)
11.231... logprob:  0.596372, 0.268229 (1.403 sec)
11.232... logprob:  0.628209, 0.292969 (1.461 sec)
11.233... logprob:  0.684046, 0.273438 (1.428 sec)
11.234... logprob:  0.706252, 0.298177 (1.416 sec)
11.235... logprob:  0.775075, 0.337240 (1.540 sec)
11.236... logprob:  0.611781, 0.270833 (1.401 sec)
11.237... logprob:  0.584644, 0.278646 (1.424 sec)
11.238... logprob:  0.578365, 0.273438 (1.413 sec)
11.239... logprob:  0.620027, 0.292969 (1.413 sec)
11.240... logprob:  0.619320, 0.286458 (1.401 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.530741, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.288347e-03 [2.670261e-07] 
Layer 'conv1' biases: 1.530691e-06 [6.569490e-10] 
Layer 'conv2' weights[0]: 5.278774e-03 [2.658392e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.850963e-09] 
Layer 'conv3' weights[0]: 5.277424e-03 [2.670183e-07] 
Layer 'conv3' biases: 2.618329e-05 [2.471347e-08] 
Layer 'conv4' weights[0]: 5.299169e-03 [2.708288e-07] 
Layer 'conv4' biases: 1.000017e+00 [3.736706e-07] 
Layer 'conv5' weights[0]: 5.365908e-03 [2.611815e-06] 
Layer 'conv5' biases: 9.991373e-01 [2.730408e-06] 
Layer 'fc6' weights[0]: 7.274323e-03 [6.263601e-08] 
Layer 'fc6' biases: 9.999960e-01 [6.090171e-08] 
Layer 'fc7' weights[0]: 7.627693e-03 [1.431284e-07] 
Layer 'fc7' biases: 9.998782e-01 [2.075877e-07] 
Layer 'fc8' weights[0]: 4.293159e-03 [1.820396e-05] 
Layer 'fc8' biases: 9.611186e-03 [3.238577e-05] 
Train error last 800 batches: 0.653658
-------------------------------------------------------
Not saving because 0.530741 > 0.299667 (9.300: -1.18%)
======================================================= (2.365 sec)
11.241... logprob:  0.693933, 0.274740 (1.462 sec)
11.242... logprob:  0.663592, 0.320312 (1.427 sec)
11.243... logprob:  0.639102, 0.273438 (1.427 sec)
11.244... logprob:  0.543584, 0.238281 (1.444 sec)
11.245... logprob:  0.644360, 0.278646 (1.421 sec)
11.246... logprob:  0.636711, 0.300781 (1.413 sec)
11.247... logprob:  0.463104, 0.208333 (1.417 sec)
11.248... logprob:  0.510780, 0.227865 (1.414 sec)
11.249... logprob:  0.741336, 0.319010 (1.412 sec)
11.250... logprob:  0.766989, 0.328125 (1.406 sec)
11.251... logprob:  0.575114, 0.274740 (1.454 sec)
11.252... logprob:  0.657550, 0.296875 (1.440 sec)
11.253... logprob:  0.616430, 0.264323 (1.411 sec)
11.254... logprob:  0.608095, 0.236979 (1.466 sec)
11.255... logprob:  0.621201, 0.294271 (1.396 sec)
11.256... logprob:  0.616702, 0.290364 (1.421 sec)
11.257... logprob:  0.594731, 0.263021 (1.412 sec)
11.258... logprob:  0.684753, 0.311198 (1.409 sec)
11.259... logprob:  0.601210, 0.268229 (1.400 sec)
11.260... logprob:  0.573615, 0.260417 (1.453 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.357735, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.283032e-03 [2.653849e-07] 
Layer 'conv1' biases: 1.534212e-06 [5.995046e-10] 
Layer 'conv2' weights[0]: 5.273455e-03 [2.646158e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.788600e-09] 
Layer 'conv3' weights[0]: 5.272180e-03 [2.655315e-07] 
Layer 'conv3' biases: 2.624898e-05 [2.144896e-08] 
Layer 'conv4' weights[0]: 5.293840e-03 [2.683425e-07] 
Layer 'conv4' biases: 1.000017e+00 [3.057605e-07] 
Layer 'conv5' weights[0]: 5.360550e-03 [2.541413e-06] 
Layer 'conv5' biases: 9.991207e-01 [2.783219e-06] 
Layer 'fc6' weights[0]: 7.273591e-03 [6.029207e-08] 
Layer 'fc6' biases: 9.999959e-01 [5.763660e-08] 
Layer 'fc7' weights[0]: 7.626932e-03 [1.388970e-07] 
Layer 'fc7' biases: 9.998797e-01 [1.953747e-07] 
Layer 'fc8' weights[0]: 4.366846e-03 [2.162332e-05] 
Layer 'fc8' biases: 1.020368e-02 [4.932546e-05] 
Train error last 800 batches: 0.653377
-------------------------------------------------------
Not saving because 0.357735 > 0.299667 (9.300: -1.18%)
======================================================= (2.360 sec)
11.261... logprob:  0.622382, 0.286458 (1.429 sec)
11.262... logprob:  0.719795, 0.277344 (1.433 sec)
11.263... logprob:  0.727737, 0.321615 (1.452 sec)
11.264... logprob:  0.612511, 0.252604 (1.419 sec)
11.265... logprob:  0.737602, 0.315104 (1.416 sec)
11.266... logprob:  0.613455, 0.286458 (1.405 sec)
11.267... logprob:  0.642498, 0.286458 (1.415 sec)
11.268... logprob:  0.630529, 0.260417 (1.420 sec)
11.269... logprob:  0.764949, 0.326823 (1.398 sec)
11.270... logprob:  0.728009, 0.304687 (1.451 sec)
11.271... logprob:  0.682860, 0.309896 (1.425 sec)
11.272... logprob:  0.654393, 0.305990 (1.418 sec)
11.273... logprob:  0.659762, 0.294271 (1.469 sec)
11.274... logprob:  0.767291, 0.350260 (1.403 sec)
11.275... logprob:  0.665648, 0.296875 (1.413 sec)
11.276... logprob:  0.643894, 0.283854 (1.408 sec)
11.277... logprob:  0.587581, 0.244792 (1.425 sec)
11.278... logprob:  0.546263, 0.252604 (1.414 sec)
11.279... logprob:  0.577278, 0.251302 (1.460 sec)
11.280... logprob:  0.521054, 0.250000 (1.398 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.420252, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.277772e-03 [2.663805e-07] 
Layer 'conv1' biases: 1.539917e-06 [7.201245e-10] 
Layer 'conv2' weights[0]: 5.268207e-03 [2.649270e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.783362e-09] 
Layer 'conv3' weights[0]: 5.266858e-03 [2.665109e-07] 
Layer 'conv3' biases: 2.631591e-05 [2.434279e-08] 
Layer 'conv4' weights[0]: 5.288594e-03 [2.697161e-07] 
Layer 'conv4' biases: 1.000017e+00 [3.451074e-07] 
Layer 'conv5' weights[0]: 5.355607e-03 [2.758708e-06] 
Layer 'conv5' biases: 9.991394e-01 [2.861204e-06] 
Layer 'fc6' weights[0]: 7.272852e-03 [6.783936e-08] 
Layer 'fc6' biases: 9.999959e-01 [6.817607e-08] 
Layer 'fc7' weights[0]: 7.626212e-03 [1.597896e-07] 
Layer 'fc7' biases: 9.998773e-01 [2.629633e-07] 
Layer 'fc8' weights[0]: 4.283350e-03 [2.156154e-05] 
Layer 'fc8' biases: 9.662919e-03 [4.817007e-05] 
Train error last 800 batches: 0.653466
-------------------------------------------------------
Not saving because 0.420252 > 0.299667 (9.300: -1.18%)
======================================================= (2.339 sec)
11.281... logprob:  0.631396, 0.278646 (1.431 sec)
11.282... logprob:  0.600992, 0.282552 (1.420 sec)
11.283... logprob:  0.600535, 0.240885 (1.416 sec)
11.284... logprob:  0.577211, 0.247396 (1.403 sec)
11.285... logprob:  0.691610, 0.295573 (1.440 sec)
11.286... logprob:  0.699455, 0.295573 (1.435 sec)
11.287... logprob:  0.614350, 0.274740 (1.428 sec)
11.288... logprob:  0.610046, 0.261719 (1.432 sec)
11.289... logprob:  0.593141, 0.266927 (1.438 sec)
11.290... logprob:  0.707324, 0.313802 (1.412 sec)
11.291... logprob:  0.602559, 0.260417 (1.436 sec)
11.292... logprob:  0.697116, 0.292969 (1.410 sec)
11.293... logprob:  0.585373, 0.261719 (1.419 sec)
11.294... logprob:  0.585966, 0.252604 (1.393 sec)
11.295... logprob:  0.691458, 0.342448 (1.460 sec)
11.296... logprob:  0.622634, 0.270833 (1.421 sec)
11.297... logprob:  0.597654, 0.256510 (1.413 sec)
11.298... logprob:  0.572514, 0.247396 (1.459 sec)
11.299... logprob:  0.524276, 0.231771 (1.403 sec)
11.300... logprob:  0.614409, 0.248698 (1.413 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.426650, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.272495e-03 [2.657161e-07] 
Layer 'conv1' biases: 1.541800e-06 [5.695208e-10] 
Layer 'conv2' weights[0]: 5.262925e-03 [2.645364e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.628226e-09] 
Layer 'conv3' weights[0]: 5.261643e-03 [2.653528e-07] 
Layer 'conv3' biases: 2.632960e-05 [2.197926e-08] 
Layer 'conv4' weights[0]: 5.283270e-03 [2.676172e-07] 
Layer 'conv4' biases: 1.000016e+00 [2.745519e-07] 
Layer 'conv5' weights[0]: 5.350226e-03 [2.223119e-06] 
Layer 'conv5' biases: 9.991254e-01 [2.425334e-06] 
Layer 'fc6' weights[0]: 7.272113e-03 [5.712662e-08] 
Layer 'fc6' biases: 9.999959e-01 [5.269821e-08] 
Layer 'fc7' weights[0]: 7.625464e-03 [1.268833e-07] 
Layer 'fc7' biases: 9.998785e-01 [1.467016e-07] 
Layer 'fc8' weights[0]: 4.349699e-03 [1.447330e-05] 
Layer 'fc8' biases: 1.011586e-02 [1.329136e-05] 
Train error last 800 batches: 0.653491
-------------------------------------------------------
Not saving because 0.426650 > 0.299667 (9.300: -1.18%)
======================================================= (2.383 sec)
11.301... logprob:  0.633273, 0.274739 (1.425 sec)
11.302... logprob:  0.757993, 0.355469 (1.421 sec)
11.303... logprob:  0.658140, 0.279948 (1.408 sec)
11.304... logprob:  0.708065, 0.316406 (1.437 sec)
11.305... logprob:  0.618291, 0.269531 (1.434 sec)
11.306... logprob:  0.682000, 0.307292 (1.437 sec)
11.307... logprob:  0.665901, 0.294271 (1.439 sec)
11.308... logprob:  0.617638, 0.273438 (1.453 sec)
11.309... logprob:  0.625875, 0.274740 (1.416 sec)
11.310... logprob:  0.705364, 0.298177 (1.421 sec)
11.311... logprob:  0.764406, 0.304687 (1.420 sec)
11.312... logprob:  0.751193, 0.307292 (1.433 sec)
11.313... logprob:  0.631985, 0.287760 (1.414 sec)
11.314... logprob:  0.655549, 0.289062 (1.459 sec)
11.315... logprob:  0.525503, 0.236979 (1.435 sec)
11.316... logprob:  0.642516, 0.260417 (1.413 sec)
11.317... logprob:  0.587979, 0.248698 (1.472 sec)
11.318... logprob:  0.640330, 0.303385 (1.407 sec)
11.319... logprob:  0.633003, 0.276042 (1.415 sec)
11.320... logprob:  0.627196, 0.257812 (1.424 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.519309, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.267240e-03 [2.647536e-07] 
Layer 'conv1' biases: 1.543089e-06 [4.452888e-10] 
Layer 'conv2' weights[0]: 5.257700e-03 [2.642553e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.131457e-09] 
Layer 'conv3' weights[0]: 5.256326e-03 [2.647178e-07] 
Layer 'conv3' biases: 2.634031e-05 [1.867597e-08] 
Layer 'conv4' weights[0]: 5.278001e-03 [2.676341e-07] 
Layer 'conv4' biases: 1.000017e+00 [2.785232e-07] 
Layer 'conv5' weights[0]: 5.345117e-03 [2.496312e-06] 
Layer 'conv5' biases: 9.991390e-01 [2.633380e-06] 
Layer 'fc6' weights[0]: 7.271342e-03 [5.905785e-08] 
Layer 'fc6' biases: 9.999958e-01 [5.526659e-08] 
Layer 'fc7' weights[0]: 7.624687e-03 [1.306420e-07] 
Layer 'fc7' biases: 9.998766e-01 [1.530345e-07] 
Layer 'fc8' weights[0]: 4.299909e-03 [1.500025e-05] 
Layer 'fc8' biases: 9.777830e-03 [1.858638e-05] 
Train error last 800 batches: 0.653624
-------------------------------------------------------
Not saving because 0.519309 > 0.299667 (9.300: -1.18%)
======================================================= (2.392 sec)
11.321... logprob:  0.655051, 0.283854 (1.425 sec)
11.322... logprob:  0.663087, 0.307292 (1.424 sec)
11.323... logprob:  0.658558, 0.305990 (1.474 sec)
11.324... logprob:  0.716186, 0.330729 (1.422 sec)
11.325... logprob:  0.632685, 0.282552 (1.432 sec)
11.326... logprob:  0.812280, 0.355469 (1.458 sec)
11.327... logprob:  0.776259, 0.345052 (1.419 sec)
11.328... logprob:  0.744873, 0.304687 (1.421 sec)
11.329... logprob:  0.601003, 0.279948 (1.442 sec)
11.330... logprob:  0.580197, 0.251302 (1.419 sec)
11.331... logprob:  0.592415, 0.264323 (1.411 sec)
11.332... logprob:  0.699806, 0.311198 (1.442 sec)
11.333... logprob:  0.571075, 0.263021 (1.437 sec)
11.334... logprob:  0.714445, 0.320312 (1.434 sec)
11.335... logprob:  0.513838, 0.223958 (1.432 sec)
11.336... logprob:  0.679639, 0.328125 (1.454 sec)
11.337... logprob:  0.739887, 0.292969 (1.414 sec)
11.338... logprob:  0.618349, 0.235677 (1.418 sec)
11.339... logprob:  0.675585, 0.279948 (1.418 sec)
11.340... logprob:  0.792458, 0.355469 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.415152, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.261981e-03 [2.657609e-07] 
Layer 'conv1' biases: 1.542903e-06 [7.095953e-10] 
Layer 'conv2' weights[0]: 5.252438e-03 [2.641629e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.600521e-09] 
Layer 'conv3' weights[0]: 5.251154e-03 [2.651978e-07] 
Layer 'conv3' biases: 2.634245e-05 [2.319522e-08] 
Layer 'conv4' weights[0]: 5.272734e-03 [2.675987e-07] 
Layer 'conv4' biases: 1.000017e+00 [3.030173e-07] 
Layer 'conv5' weights[0]: 5.340015e-03 [2.563469e-06] 
Layer 'conv5' biases: 9.991351e-01 [2.721792e-06] 
Layer 'fc6' weights[0]: 7.270581e-03 [6.164254e-08] 
Layer 'fc6' biases: 9.999960e-01 [5.929750e-08] 
Layer 'fc7' weights[0]: 7.623878e-03 [1.380964e-07] 
Layer 'fc7' biases: 9.998772e-01 [1.647677e-07] 
Layer 'fc8' weights[0]: 4.315568e-03 [1.580201e-05] 
Layer 'fc8' biases: 9.830994e-03 [1.413318e-05] 
Train error last 800 batches: 0.653219
-------------------------------------------------------
Not saving because 0.415152 > 0.299667 (9.300: -1.18%)
======================================================= (2.394 sec)
11.341... logprob:  0.707987, 0.274740 (1.427 sec)
11.342... logprob:  0.680852, 0.300781 (1.469 sec)
11.343... logprob:  0.602574, 0.266927 (1.438 sec)
11.344... logprob:  0.723721, 0.316406 (1.480 sec)
11.345... logprob:  0.635234, 0.268229 (1.430 sec)
11.346... logprob:  0.659317, 0.294271 (1.435 sec)
11.347... logprob:  0.588972, 0.247396 (1.485 sec)
11.348... logprob:  0.691020, 0.295573 (1.431 sec)
11.349... logprob:  0.676459, 0.300781 (1.427 sec)
11.350... logprob:  0.589123, 0.257812 (1.431 sec)
11.351... logprob:  0.739982, 0.328125 (1.422 sec)
11.352... logprob:  0.651245, 0.283854 (1.430 sec)
11.353... logprob:  0.669450, 0.291667 (1.489 sec)
11.354... logprob:  0.844934, 0.358073 (1.438 sec)
11.355... logprob:  0.593589, 0.282552 (1.443 sec)
11.356... logprob:  0.763087, 0.328125 (1.469 sec)
11.357... logprob:  0.534142, 0.243490 (1.423 sec)
11.358... logprob:  0.631193, 0.268229 (1.436 sec)
11.359... logprob:  0.765980, 0.321615 (1.423 sec)
11.360... logprob:  0.628000, 0.251302 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.509920, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.256709e-03 [2.649208e-07] 
Layer 'conv1' biases: 1.545614e-06 [6.950009e-10] 
Layer 'conv2' weights[0]: 5.247186e-03 [2.637330e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.851080e-09] 
Layer 'conv3' weights[0]: 5.245879e-03 [2.653713e-07] 
Layer 'conv3' biases: 2.635826e-05 [2.414239e-08] 
Layer 'conv4' weights[0]: 5.267457e-03 [2.677443e-07] 
Layer 'conv4' biases: 1.000018e+00 [3.191036e-07] 
Layer 'conv5' weights[0]: 5.335474e-03 [2.510810e-06] 
Layer 'conv5' biases: 9.991338e-01 [2.704122e-06] 
Layer 'fc6' weights[0]: 7.269836e-03 [6.191963e-08] 
Layer 'fc6' biases: 9.999960e-01 [5.973109e-08] 
Layer 'fc7' weights[0]: 7.623098e-03 [1.385331e-07] 
Layer 'fc7' biases: 9.998765e-01 [1.701054e-07] 
Layer 'fc8' weights[0]: 4.297010e-03 [1.644906e-05] 
Layer 'fc8' biases: 9.657358e-03 [2.298128e-05] 
Train error last 800 batches: 0.653119
-------------------------------------------------------
Not saving because 0.509920 > 0.299667 (9.300: -1.18%)
======================================================= (2.384 sec)
11.361... logprob:  0.622234, 0.266927 (1.439 sec)
11.362... logprob:  0.592894, 0.263021 (1.480 sec)
11.363... logprob:  0.688631, 0.300781 (1.444 sec)
11.364... logprob:  0.708774, 0.305990 (1.451 sec)
11.365... logprob:  0.672744, 0.268229 (1.460 sec)
11.366... logprob:  0.612045, 0.265625 (1.443 sec)
11.367... logprob:  0.545694, 0.239583 (1.458 sec)
11.368... logprob:  0.765112, 0.355469 (1.422 sec)
11.369... logprob:  0.622768, 0.255208 (1.421 sec)
11.370... logprob:  0.636254, 0.272135 (1.436 sec)
11.371... logprob:  0.648001, 0.299479 (1.454 sec)
11.372... logprob:  0.693922, 0.320312 (1.447 sec)
11.373... logprob:  0.705087, 0.307292 (1.447 sec)
11.374... logprob:  0.724194, 0.312500 (1.444 sec)
11.375... logprob:  0.651197, 0.276042 (1.455 sec)
11.376... logprob:  0.573815, 0.242188 (1.437 sec)
11.377... logprob:  0.535523, 0.239583 (1.423 sec)
11.378... logprob:  0.697210, 0.298177 (1.425 sec)
11.379... logprob:  0.596685, 0.283854 (1.440 sec)
11.380... logprob:  0.815801, 0.334635 (1.436 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.569459, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.251490e-03 [2.644285e-07] 
Layer 'conv1' biases: 1.549892e-06 [5.955166e-10] 
Layer 'conv2' weights[0]: 5.241945e-03 [2.634148e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.598268e-09] 
Layer 'conv3' weights[0]: 5.240652e-03 [2.648817e-07] 
Layer 'conv3' biases: 2.642376e-05 [2.417394e-08] 
Layer 'conv4' weights[0]: 5.262224e-03 [2.673897e-07] 
Layer 'conv4' biases: 1.000018e+00 [3.044476e-07] 
Layer 'conv5' weights[0]: 5.330350e-03 [2.636344e-06] 
Layer 'conv5' biases: 9.991195e-01 [2.771749e-06] 
Layer 'fc6' weights[0]: 7.269097e-03 [6.316542e-08] 
Layer 'fc6' biases: 9.999960e-01 [6.208274e-08] 
Layer 'fc7' weights[0]: 7.622367e-03 [1.421073e-07] 
Layer 'fc7' biases: 9.998769e-01 [1.812071e-07] 
Layer 'fc8' weights[0]: 4.326823e-03 [1.790487e-05] 
Layer 'fc8' biases: 9.866826e-03 [2.680135e-05] 
Train error last 800 batches: 0.652633
-------------------------------------------------------
Not saving because 0.569459 > 0.299667 (9.300: -1.18%)
======================================================= (2.385 sec)
11.381... logprob:  0.711393, 0.320312 (1.466 sec)
11.382... logprob:  0.793944, 0.341146 (1.448 sec)
11.383... logprob:  0.589160, 0.273438 (1.439 sec)
11.384... logprob:  0.619601, 0.261719 (1.469 sec)
11.385... logprob:  0.757227, 0.308594 (1.428 sec)
11.386... logprob:  0.684284, 0.294271 (1.425 sec)
11.387... logprob:  0.640187, 0.299479 (1.433 sec)
11.388... logprob:  0.729257, 0.305990 (1.428 sec)
11.389... logprob:  0.643517, 0.308594 (1.429 sec)
11.390... logprob:  0.650018, 0.289062 (1.471 sec)
11.391... logprob:  0.546561, 0.248698 (1.437 sec)
11.392... logprob:  0.663808, 0.289062 (1.428 sec)
11.393... logprob:  0.619102, 0.281250 (1.488 sec)
11.394... logprob:  0.552449, 0.264323 (1.428 sec)
11.395... logprob:  0.567105, 0.246094 (1.430 sec)
11.396... logprob:  0.590428, 0.283854 (1.432 sec)
11.397... logprob:  0.732946, 0.342448 (1.431 sec)
11.398... logprob:  0.685772, 0.307292 (1.427 sec)
11.399... logprob:  0.619619, 0.287760 (1.477 sec)
11.400... logprob:  0.691057, 0.311198 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.431265, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.246244e-03 [2.643758e-07] 
Layer 'conv1' biases: 1.551156e-06 [4.911865e-10] 
Layer 'conv2' weights[0]: 5.236722e-03 [2.630548e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.076464e-09] 
Layer 'conv3' weights[0]: 5.235384e-03 [2.638267e-07] 
Layer 'conv3' biases: 2.643848e-05 [1.941295e-08] 
Layer 'conv4' weights[0]: 5.256970e-03 [2.664659e-07] 
Layer 'conv4' biases: 1.000018e+00 [2.696664e-07] 
Layer 'conv5' weights[0]: 5.325410e-03 [2.500988e-06] 
Layer 'conv5' biases: 9.991080e-01 [2.675412e-06] 
Layer 'fc6' weights[0]: 7.268347e-03 [5.969404e-08] 
Layer 'fc6' biases: 9.999960e-01 [5.702238e-08] 
Layer 'fc7' weights[0]: 7.621602e-03 [1.325426e-07] 
Layer 'fc7' biases: 9.998771e-01 [1.702506e-07] 
Layer 'fc8' weights[0]: 4.350432e-03 [1.586500e-05] 
Layer 'fc8' biases: 1.006116e-02 [2.877645e-05] 
Train error last 800 batches: 0.652826
-------------------------------------------------------
Not saving because 0.431265 > 0.299667 (9.300: -1.18%)
======================================================= (2.391 sec)
11.401... logprob:  0.674946, 0.305989 (1.442 sec)
11.402... logprob:  0.713283, 0.287760 (1.479 sec)
11.403... logprob:  0.661441, 0.287760 (1.430 sec)
11.404... logprob:  0.656328, 0.278646 (1.430 sec)
11.405... logprob:  0.698146, 0.282552 (1.436 sec)
11.406... logprob:  0.603115, 0.305989 (1.425 sec)
11.407... logprob:  0.711062, 0.279948 (1.430 sec)
11.408... logprob:  0.557272, 0.278646 (1.476 sec)
11.409... logprob:  0.625974, 0.264323 (1.430 sec)
11.410... logprob:  0.745502, 0.333333 (1.442 sec)
11.411... logprob:  0.630752, 0.266927 (1.475 sec)
11.412... logprob:  0.681608, 0.316406 (1.431 sec)
11.413... logprob:  0.780035, 0.342448 (1.434 sec)
11.414... logprob:  0.658763, 0.273438 (1.431 sec)
11.415... logprob:  0.704952, 0.315104 (1.417 sec)
11.416... logprob:  0.605558, 0.259115 (1.433 sec)
11.417... logprob:  0.624915, 0.294271 (1.457 sec)
11.418... logprob:  0.662642, 0.316406 (1.441 sec)
11.419... logprob:  0.602773, 0.261719 (1.450 sec)
11.420... logprob:  0.695368, 0.325521 (1.448 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.320646, 0.039062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.240979e-03 [2.635557e-07] 
Layer 'conv1' biases: 1.551337e-06 [7.078712e-10] 
Layer 'conv2' weights[0]: 5.231482e-03 [2.631665e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.630768e-09] 
Layer 'conv3' weights[0]: 5.230159e-03 [2.645510e-07] 
Layer 'conv3' biases: 2.645626e-05 [2.338656e-08] 
Layer 'conv4' weights[0]: 5.251678e-03 [2.666567e-07] 
Layer 'conv4' biases: 1.000016e+00 [3.205553e-07] 
Layer 'conv5' weights[0]: 5.319811e-03 [2.314918e-06] 
Layer 'conv5' biases: 9.991137e-01 [2.480318e-06] 
Layer 'fc6' weights[0]: 7.267578e-03 [5.949824e-08] 
Layer 'fc6' biases: 9.999961e-01 [5.646482e-08] 
Layer 'fc7' weights[0]: 7.620832e-03 [1.352403e-07] 
Layer 'fc7' biases: 9.998766e-01 [1.794457e-07] 
Layer 'fc8' weights[0]: 4.328017e-03 [1.754772e-05] 
Layer 'fc8' biases: 9.934263e-03 [2.425082e-05] 
Train error last 800 batches: 0.652706
-------------------------------------------------------
Not saving because 0.320646 > 0.299667 (9.300: -1.18%)
======================================================= (2.387 sec)
11.421... logprob:  0.707224, 0.315104 (1.459 sec)
11.422... logprob:  0.678463, 0.309896 (1.441 sec)
11.423... logprob:  0.595294, 0.287760 (1.421 sec)
11.424... logprob:  0.533474, 0.236979 (1.429 sec)
11.425... logprob:  0.600190, 0.270833 (1.436 sec)
11.426... logprob:  0.610148, 0.264323 (1.438 sec)
11.427... logprob:  0.708862, 0.316406 (1.457 sec)
11.428... logprob:  0.664244, 0.294271 (1.449 sec)
11.429... logprob:  0.657713, 0.295573 (1.442 sec)
11.430... logprob:  0.696836, 0.341146 (1.468 sec)
11.431... logprob:  0.799982, 0.339844 (1.431 sec)
11.432... logprob:  0.673279, 0.304688 (1.417 sec)
11.433... logprob:  0.561931, 0.212240 (1.428 sec)
11.434... logprob:  0.776861, 0.347656 (1.430 sec)
11.435... logprob:  0.720939, 0.312500 (1.428 sec)
11.436... logprob:  0.584763, 0.269531 (1.472 sec)
11.437... logprob:  0.643969, 0.282552 (1.443 sec)
11.438... logprob:  0.753690, 0.294271 (1.427 sec)
11.439... logprob:  0.583788, 0.223958 (1.480 sec)
11.440... logprob:  0.614845, 0.261719 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.466102, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.235750e-03 [2.636354e-07] 
Layer 'conv1' biases: 1.552311e-06 [7.323161e-10] 
Layer 'conv2' weights[0]: 5.226230e-03 [2.630610e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.729235e-09] 
Layer 'conv3' weights[0]: 5.224959e-03 [2.647066e-07] 
Layer 'conv3' biases: 2.648402e-05 [2.607813e-08] 
Layer 'conv4' weights[0]: 5.246436e-03 [2.696475e-07] 
Layer 'conv4' biases: 1.000018e+00 [4.398433e-07] 
Layer 'conv5' weights[0]: 5.315358e-03 [2.701338e-06] 
Layer 'conv5' biases: 9.991169e-01 [2.875378e-06] 
Layer 'fc6' weights[0]: 7.266816e-03 [6.284959e-08] 
Layer 'fc6' biases: 9.999961e-01 [6.137652e-08] 
Layer 'fc7' weights[0]: 7.620043e-03 [1.410256e-07] 
Layer 'fc7' biases: 9.998767e-01 [1.830801e-07] 
Layer 'fc8' weights[0]: 4.330566e-03 [1.655815e-05] 
Layer 'fc8' biases: 9.936417e-03 [2.239824e-05] 
Train error last 800 batches: 0.652822
-------------------------------------------------------
Not saving because 0.466102 > 0.299667 (9.300: -1.18%)
======================================================= (2.358 sec)
11.441... logprob:  0.723471, 0.315104 (1.432 sec)
11.442... logprob:  0.635400, 0.286458 (1.439 sec)
11.443... logprob:  0.606927, 0.266927 (1.431 sec)
11.444... logprob:  0.539152, 0.239583 (1.424 sec)
11.445... logprob:  0.587330, 0.273437 (1.480 sec)
11.446... logprob:  0.559291, 0.256510 (1.438 sec)
11.447... logprob:  0.706729, 0.295573 (1.432 sec)
11.448... logprob:  0.552119, 0.248698 (1.474 sec)
11.449... logprob:  0.666699, 0.255208 (1.426 sec)
11.450... logprob:  0.561830, 0.246094 (1.428 sec)
11.451... logprob:  0.719975, 0.299479 (1.511 sec)
11.452... logprob:  0.670239, 0.277344 (1.423 sec)
11.453... logprob:  0.683549, 0.303385 (1.424 sec)
11.454... logprob:  0.640557, 0.281250 (1.477 sec)
11.455... logprob:  0.651287, 0.260417 (1.433 sec)
11.456... logprob:  0.706704, 0.324219 (1.439 sec)
11.457... logprob:  0.577393, 0.247396 (1.468 sec)
11.458... logprob:  0.552276, 0.225260 (1.426 sec)
11.459... logprob:  0.667095, 0.290365 (1.432 sec)
11.460... logprob:  0.564500, 0.264323 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.499234, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.230512e-03 [2.642703e-07] 
Layer 'conv1' biases: 1.555289e-06 [7.400197e-10] 
Layer 'conv2' weights[0]: 5.221018e-03 [2.627211e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.161490e-09] 
Layer 'conv3' weights[0]: 5.219717e-03 [2.642602e-07] 
Layer 'conv3' biases: 2.652101e-05 [2.247487e-08] 
Layer 'conv4' weights[0]: 5.241223e-03 [2.673667e-07] 
Layer 'conv4' biases: 1.000019e+00 [3.189190e-07] 
Layer 'conv5' weights[0]: 5.310917e-03 [2.617901e-06] 
Layer 'conv5' biases: 9.991068e-01 [2.782820e-06] 
Layer 'fc6' weights[0]: 7.266045e-03 [6.256306e-08] 
Layer 'fc6' biases: 9.999961e-01 [6.133892e-08] 
Layer 'fc7' weights[0]: 7.619287e-03 [1.469011e-07] 
Layer 'fc7' biases: 9.998767e-01 [2.131558e-07] 
Layer 'fc8' weights[0]: 4.354426e-03 [1.952145e-05] 
Layer 'fc8' biases: 1.010992e-02 [4.376027e-05] 
Train error last 800 batches: 0.652239
-------------------------------------------------------
Not saving because 0.499234 > 0.299667 (9.300: -1.18%)
======================================================= (2.359 sec)
11.461... logprob:  0.672269, 0.290365 (1.426 sec)
11.462... logprob:  0.658357, 0.259115 (1.438 sec)
11.463... logprob:  0.669750, 0.292969 (1.470 sec)
11.464... logprob:  0.691430, 0.292969 (1.440 sec)
11.465... logprob:  0.623245, 0.300781 (1.445 sec)
11.466... logprob:  0.611474, 0.286458 (1.453 sec)
11.467... logprob:  0.663382, 0.272135 (1.442 sec)
11.468... logprob:  0.550248, 0.250000 (1.435 sec)
11.469... logprob:  0.605744, 0.294271 (1.423 sec)
11.470... logprob:  0.685051, 0.278646 (1.419 sec)
11.471... logprob:  0.665476, 0.315104 (1.432 sec)
11.472... logprob:  0.619095, 0.269531 (1.443 sec)
11.473... logprob:  0.589705, 0.260417 (1.451 sec)
11.474... logprob:  0.602928, 0.268229 (1.447 sec)
11.475... logprob:  0.720915, 0.320312 (1.441 sec)
11.476... logprob:  0.714323, 0.291667 (1.467 sec)
11.477... logprob:  0.607433, 0.273437 (1.433 sec)
11.478... logprob:  0.648111, 0.264323 (1.422 sec)
11.479... logprob:  0.583748, 0.294271 (1.424 sec)
11.480... logprob:  0.569899, 0.246094 (1.432 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.435221, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.225302e-03 [2.624051e-07] 
Layer 'conv1' biases: 1.559329e-06 [6.167606e-10] 
Layer 'conv2' weights[0]: 5.215791e-03 [2.615479e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.660364e-09] 
Layer 'conv3' weights[0]: 5.214544e-03 [2.621937e-07] 
Layer 'conv3' biases: 2.658679e-05 [1.825759e-08] 
Layer 'conv4' weights[0]: 5.235993e-03 [2.645016e-07] 
Layer 'conv4' biases: 1.000019e+00 [2.618857e-07] 
Layer 'conv5' weights[0]: 5.305930e-03 [2.243008e-06] 
Layer 'conv5' biases: 9.991059e-01 [2.399639e-06] 
Layer 'fc6' weights[0]: 7.265315e-03 [5.742355e-08] 
Layer 'fc6' biases: 9.999960e-01 [5.353145e-08] 
Layer 'fc7' weights[0]: 7.618485e-03 [1.274731e-07] 
Layer 'fc7' biases: 9.998762e-01 [1.543710e-07] 
Layer 'fc8' weights[0]: 4.347904e-03 [1.480366e-05] 
Layer 'fc8' biases: 1.009770e-02 [2.362395e-05] 
Train error last 800 batches: 0.652218
-------------------------------------------------------
Not saving because 0.435221 > 0.299667 (9.300: -1.18%)
======================================================= (2.374 sec)
11.481... logprob:  0.755839, 0.298177 (1.442 sec)
11.482... logprob:  0.670628, 0.287760 (1.484 sec)
11.483... logprob:  0.762117, 0.343750 (1.449 sec)
11.484... logprob:  0.702995, 0.287760 (1.435 sec)
11.485... logprob:  0.722750, 0.309896 (1.480 sec)
11.486... logprob:  0.640781, 0.296875 (1.430 sec)
11.487... logprob:  0.765012, 0.334635 (1.424 sec)
11.488... logprob:  0.573679, 0.240885 (1.430 sec)
11.489... logprob:  0.658556, 0.287760 (1.424 sec)
11.490... logprob:  0.670242, 0.290365 (1.429 sec)
11.491... logprob:  0.576897, 0.259115 (1.474 sec)
11.492... logprob:  0.699018, 0.317708 (1.433 sec)
11.493... logprob:  0.661105, 0.292969 (1.430 sec)
11.494... logprob:  0.669584, 0.279948 (1.488 sec)
11.495... logprob:  0.616872, 0.266927 (1.433 sec)
11.496... logprob:  0.665045, 0.305989 (1.427 sec)
11.497... logprob:  0.723083, 0.324219 (1.430 sec)
11.498... logprob:  0.724703, 0.311198 (1.430 sec)
11.499... logprob:  0.747724, 0.341146 (1.422 sec)
11.500... logprob:  0.654314, 0.302083 (1.488 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.458188, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.220070e-03 [2.631279e-07] 
Layer 'conv1' biases: 1.563884e-06 [5.860947e-10] 
Layer 'conv2' weights[0]: 5.210558e-03 [2.621545e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.289254e-09] 
Layer 'conv3' weights[0]: 5.209326e-03 [2.640116e-07] 
Layer 'conv3' biases: 2.664308e-05 [2.749700e-08] 
Layer 'conv4' weights[0]: 5.230738e-03 [2.667466e-07] 
Layer 'conv4' biases: 1.000019e+00 [3.654275e-07] 
Layer 'conv5' weights[0]: 5.300495e-03 [2.777547e-06] 
Layer 'conv5' biases: 9.991142e-01 [3.062980e-06] 
Layer 'fc6' weights[0]: 7.264562e-03 [6.362055e-08] 
Layer 'fc6' biases: 9.999961e-01 [6.283162e-08] 
Layer 'fc7' weights[0]: 7.617693e-03 [1.490000e-07] 
Layer 'fc7' biases: 9.998745e-01 [2.085065e-07] 
Layer 'fc8' weights[0]: 4.307285e-03 [2.119024e-05] 
Layer 'fc8' biases: 9.818441e-03 [4.355704e-05] 
Train error last 800 batches: 0.652720
-------------------------------------------------------
Not saving because 0.458188 > 0.299667 (9.300: -1.18%)
======================================================= (2.383 sec)
11.501... logprob:  0.601747, 0.270833 (1.433 sec)
11.502... logprob:  0.668051, 0.312500 (1.446 sec)
11.503... logprob:  0.685914, 0.304688 (1.480 sec)
11.504... logprob:  0.724025, 0.341146 (1.430 sec)
11.505... logprob:  0.804521, 0.346354 (1.439 sec)
11.506... logprob:  0.680670, 0.308594 (1.428 sec)
11.507... logprob:  0.643647, 0.269531 (1.423 sec)
11.508... logprob:  0.601044, 0.283854 (1.428 sec)
11.509... logprob:  0.544366, 0.250000 (1.473 sec)
11.510... logprob:  0.602965, 0.257812 (1.434 sec)
11.511... logprob:  0.595796, 0.244792 (1.447 sec)
11.512... logprob:  0.618129, 0.250000 (1.457 sec)
11.513... logprob:  0.566640, 0.244792 (1.439 sec)
11.514... logprob:  0.654457, 0.281250 (1.428 sec)
11.515... logprob:  0.623108, 0.256510 (1.424 sec)
11.516... logprob:  0.570404, 0.257812 (1.420 sec)
11.517... logprob:  0.802076, 0.325521 (1.432 sec)
11.518... logprob:  0.659661, 0.261719 (1.450 sec)
11.519... logprob:  0.653417, 0.277344 (1.451 sec)
11.520... logprob:  0.697907, 0.302083 (1.444 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.499350, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.214876e-03 [2.623730e-07] 
Layer 'conv1' biases: 1.565473e-06 [6.898955e-10] 
Layer 'conv2' weights[0]: 5.205388e-03 [2.612315e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.631443e-09] 
Layer 'conv3' weights[0]: 5.204116e-03 [2.621937e-07] 
Layer 'conv3' biases: 2.668968e-05 [2.026963e-08] 
Layer 'conv4' weights[0]: 5.225530e-03 [2.645397e-07] 
Layer 'conv4' biases: 1.000019e+00 [2.724328e-07] 
Layer 'conv5' weights[0]: 5.295711e-03 [2.453993e-06] 
Layer 'conv5' biases: 9.990950e-01 [2.630149e-06] 
Layer 'fc6' weights[0]: 7.263789e-03 [6.049244e-08] 
Layer 'fc6' biases: 9.999960e-01 [5.852496e-08] 
Layer 'fc7' weights[0]: 7.616964e-03 [1.376433e-07] 
Layer 'fc7' biases: 9.998754e-01 [1.648017e-07] 
Layer 'fc8' weights[0]: 4.367912e-03 [1.561862e-05] 
Layer 'fc8' biases: 1.026603e-02 [1.332364e-05] 
Train error last 800 batches: 0.652320
-------------------------------------------------------
Not saving because 0.499350 > 0.299667 (9.300: -1.18%)
======================================================= (2.396 sec)
11.521... logprob:  0.612269, 0.261719 (1.457 sec)
11.522... logprob:  0.741744, 0.320312 (1.463 sec)
11.523... logprob:  0.593187, 0.286458 (1.435 sec)
11.524... logprob:  0.646863, 0.291667 (1.424 sec)
11.525... logprob:  0.678038, 0.313802 (1.428 sec)
11.526... logprob:  0.697516, 0.294271 (1.430 sec)
11.527... logprob:  0.651864, 0.291667 (1.437 sec)
11.528... logprob:  0.741959, 0.320312 (1.470 sec)
11.529... logprob:  0.623558, 0.299479 (1.449 sec)
11.530... logprob:  0.702239, 0.289062 (1.432 sec)
11.531... logprob:  0.744498, 0.319010 (1.478 sec)
11.532... logprob:  0.656766, 0.282552 (1.425 sec)
11.533... logprob:  0.728793, 0.322917 (1.422 sec)
11.534... logprob:  0.581735, 0.281250 (1.425 sec)
11.535... logprob:  0.716732, 0.295573 (1.437 sec)
11.536... logprob:  0.699127, 0.316406 (1.430 sec)
11.537... logprob:  0.701151, 0.311198 (1.475 sec)
11.538... logprob:  0.754214, 0.330729 (1.437 sec)
11.539... logprob:  0.487510, 0.209635 (1.427 sec)
11.540... logprob:  0.678571, 0.303385 (1.482 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.485747, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.209681e-03 [2.618849e-07] 
Layer 'conv1' biases: 1.570467e-06 [6.665809e-10] 
Layer 'conv2' weights[0]: 5.200177e-03 [2.611354e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.362104e-09] 
Layer 'conv3' weights[0]: 5.198878e-03 [2.621911e-07] 
Layer 'conv3' biases: 2.669549e-05 [1.998143e-08] 
Layer 'conv4' weights[0]: 5.220287e-03 [2.647517e-07] 
Layer 'conv4' biases: 1.000019e+00 [2.993810e-07] 
Layer 'conv5' weights[0]: 5.290418e-03 [2.605865e-06] 
Layer 'conv5' biases: 9.991126e-01 [2.856219e-06] 
Layer 'fc6' weights[0]: 7.263043e-03 [6.200660e-08] 
Layer 'fc6' biases: 9.999959e-01 [6.089887e-08] 
Layer 'fc7' weights[0]: 7.616223e-03 [1.408751e-07] 
Layer 'fc7' biases: 9.998744e-01 [1.877874e-07] 
Layer 'fc8' weights[0]: 4.314261e-03 [1.885542e-05] 
Layer 'fc8' biases: 9.850189e-03 [3.493594e-05] 
Train error last 800 batches: 0.652674
-------------------------------------------------------
Not saving because 0.485747 > 0.299667 (9.300: -1.18%)
======================================================= (2.369 sec)
11.541... logprob:  0.554902, 0.250000 (1.434 sec)
11.542... logprob:  0.605104, 0.243490 (1.431 sec)
11.543... logprob:  0.582290, 0.273438 (1.429 sec)
11.544... logprob:  0.552536, 0.276042 (1.425 sec)
11.545... logprob:  0.670163, 0.296875 (1.426 sec)
11.546... logprob:  0.631492, 0.287760 (1.476 sec)
11.547... logprob:  0.745231, 0.320312 (1.429 sec)
11.548... logprob:  0.697155, 0.286458 (1.432 sec)
11.549... logprob:  0.606821, 0.276042 (1.477 sec)
11.550... logprob:  0.621923, 0.282552 (1.426 sec)
11.551... logprob:  0.734365, 0.335937 (1.427 sec)
11.552... logprob:  0.774028, 0.333333 (1.438 sec)
11.553... logprob:  0.599279, 0.276042 (1.420 sec)
11.554... logprob:  0.698380, 0.300781 (1.428 sec)
11.555... logprob:  0.591792, 0.255208 (1.475 sec)
11.556... logprob:  0.595662, 0.283854 (1.433 sec)
11.557... logprob:  0.604795, 0.259115 (1.446 sec)
11.558... logprob:  0.675439, 0.294271 (1.471 sec)
11.559... logprob:  0.710500, 0.322917 (1.452 sec)
11.560... logprob:  0.564119, 0.282552 (1.434 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.448423, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.204461e-03 [2.624630e-07] 
Layer 'conv1' biases: 1.573656e-06 [5.833355e-10] 
Layer 'conv2' weights[0]: 5.194987e-03 [2.611388e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.792589e-09] 
Layer 'conv3' weights[0]: 5.193672e-03 [2.621212e-07] 
Layer 'conv3' biases: 2.669028e-05 [2.111938e-08] 
Layer 'conv4' weights[0]: 5.215066e-03 [2.652120e-07] 
Layer 'conv4' biases: 1.000017e+00 [3.061413e-07] 
Layer 'conv5' weights[0]: 5.284920e-03 [2.493058e-06] 
Layer 'conv5' biases: 9.990967e-01 [2.587392e-06] 
Layer 'fc6' weights[0]: 7.262279e-03 [5.710514e-08] 
Layer 'fc6' biases: 9.999961e-01 [5.300362e-08] 
Layer 'fc7' weights[0]: 7.615409e-03 [1.286688e-07] 
Layer 'fc7' biases: 9.998751e-01 [1.570632e-07] 
Layer 'fc8' weights[0]: 4.386513e-03 [1.629263e-05] 
Layer 'fc8' biases: 1.031515e-02 [2.042559e-05] 
Train error last 800 batches: 0.653205
-------------------------------------------------------
Not saving because 0.448423 > 0.299667 (9.300: -1.18%)
======================================================= (2.370 sec)
11.561... logprob:  0.748496, 0.315104 (1.431 sec)
11.562... logprob:  0.760218, 0.319010 (1.428 sec)
11.563... logprob:  0.504226, 0.240885 (1.436 sec)
11.564... logprob:  0.670825, 0.299479 (1.459 sec)
11.565... logprob:  0.832882, 0.355469 (1.443 sec)
11.566... logprob:  0.608407, 0.252604 (1.445 sec)
11.567... logprob:  0.638008, 0.273437 (1.450 sec)
11.568... logprob:  0.739149, 0.333333 (1.452 sec)
11.569... logprob:  0.678007, 0.290365 (1.429 sec)
11.570... logprob:  0.836344, 0.361979 (1.420 sec)
11.571... logprob:  0.679352, 0.272135 (1.425 sec)
11.572... logprob:  0.632824, 0.278646 (1.440 sec)
11.573... logprob:  0.618694, 0.287760 (1.438 sec)
11.574... logprob:  0.726490, 0.312500 (1.460 sec)
11.575... logprob:  0.596764, 0.269531 (1.452 sec)
11.576... logprob:  0.716652, 0.326823 (1.434 sec)
11.577... logprob:  0.622227, 0.273437 (1.471 sec)
11.578... logprob:  0.644974, 0.289062 (1.426 sec)
11.579... logprob:  0.690669, 0.283854 (1.422 sec)
11.580... logprob:  0.753720, 0.351562 (1.424 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.509783, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.199272e-03 [2.618957e-07] 
Layer 'conv1' biases: 1.580062e-06 [5.708768e-10] 
Layer 'conv2' weights[0]: 5.189807e-03 [2.607184e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.319130e-09] 
Layer 'conv3' weights[0]: 5.188495e-03 [2.617327e-07] 
Layer 'conv3' biases: 2.669763e-05 [2.040953e-08] 
Layer 'conv4' weights[0]: 5.209847e-03 [2.644942e-07] 
Layer 'conv4' biases: 1.000015e+00 [3.121442e-07] 
Layer 'conv5' weights[0]: 5.278976e-03 [2.713589e-06] 
Layer 'conv5' biases: 9.991118e-01 [3.013798e-06] 
Layer 'fc6' weights[0]: 7.261528e-03 [6.273069e-08] 
Layer 'fc6' biases: 9.999959e-01 [6.183424e-08] 
Layer 'fc7' weights[0]: 7.614642e-03 [1.412129e-07] 
Layer 'fc7' biases: 9.998737e-01 [1.845587e-07] 
Layer 'fc8' weights[0]: 4.329958e-03 [1.767449e-05] 
Layer 'fc8' biases: 9.886615e-03 [3.098541e-05] 
Train error last 800 batches: 0.653404
-------------------------------------------------------
Not saving because 0.509783 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
11.581... logprob:  0.643048, 0.300781 (1.438 sec)
11.582... logprob:  0.588048, 0.276042 (1.435 sec)
11.583... logprob:  0.708998, 0.337240 (1.474 sec)
11.584... logprob:  0.600286, 0.239583 (1.438 sec)
11.585... logprob:  0.603738, 0.276042 (1.430 sec)
11.586... logprob:  0.593252, 0.243490 (1.486 sec)
11.587... logprob:  0.624636, 0.279948 (1.427 sec)
11.588... logprob:  0.656303, 0.289062 (1.421 sec)
11.589... logprob:  0.571426, 0.265625 (1.431 sec)
11.590... logprob:  0.717397, 0.313802 (1.425 sec)
11.591... logprob:  0.612101, 0.279948 (1.429 sec)
11.592... logprob:  0.733987, 0.303385 (1.476 sec)
11.593... logprob:  0.656138, 0.273438 (1.427 sec)
11.594... logprob:  0.584512, 0.246094 (1.436 sec)
11.595... logprob:  0.712872, 0.316406 (1.472 sec)
11.596... logprob:  0.670551, 0.291667 (1.429 sec)
11.597... logprob:  0.626588, 0.268229 (1.424 sec)
11.598... logprob:  0.642105, 0.295573 (1.433 sec)
11.599... logprob:  0.521027, 0.244792 (1.427 sec)
11.600... logprob:  0.610530, 0.263021 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.402612, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.194069e-03 [2.617729e-07] 
Layer 'conv1' biases: 1.584212e-06 [5.577542e-10] 
Layer 'conv2' weights[0]: 5.184614e-03 [2.602797e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.857286e-09] 
Layer 'conv3' weights[0]: 5.183275e-03 [2.611801e-07] 
Layer 'conv3' biases: 2.673150e-05 [1.883640e-08] 
Layer 'conv4' weights[0]: 5.204651e-03 [2.638796e-07] 
Layer 'conv4' biases: 1.000012e+00 [2.808357e-07] 
Layer 'conv5' weights[0]: 5.272974e-03 [2.490307e-06] 
Layer 'conv5' biases: 9.990997e-01 [2.634377e-06] 
Layer 'fc6' weights[0]: 7.260765e-03 [5.943765e-08] 
Layer 'fc6' biases: 9.999959e-01 [5.639291e-08] 
Layer 'fc7' weights[0]: 7.613890e-03 [1.344873e-07] 
Layer 'fc7' biases: 9.998749e-01 [1.723298e-07] 
Layer 'fc8' weights[0]: 4.387253e-03 [1.560614e-05] 
Layer 'fc8' biases: 1.031108e-02 [2.353112e-05] 
Train error last 800 batches: 0.653139
-------------------------------------------------------
Not saving because 0.402612 > 0.299667 (9.300: -1.18%)
======================================================= (2.401 sec)
11.601... logprob:  0.598496, 0.274740 (1.490 sec)
11.602... logprob:  0.617737, 0.291667 (1.437 sec)
11.603... logprob:  0.499387, 0.243490 (1.447 sec)
11.604... logprob:  0.694809, 0.286458 (1.475 sec)
11.605... logprob:  0.709476, 0.285156 (1.429 sec)
11.606... logprob:  0.545198, 0.268229 (1.437 sec)
11.607... logprob:  0.688179, 0.278646 (1.426 sec)
11.608... logprob:  0.535811, 0.257812 (1.418 sec)
11.609... logprob:  0.628680, 0.319010 (1.429 sec)
11.610... logprob:  0.662386, 0.292969 (1.465 sec)
11.611... logprob:  0.766143, 0.330729 (1.441 sec)
11.612... logprob:  0.590560, 0.264323 (1.445 sec)
11.613... logprob:  0.574235, 0.269531 (1.455 sec)
11.614... logprob:  0.682512, 0.285156 (1.438 sec)
11.615... logprob:  0.606435, 0.263021 (1.437 sec)
11.616... logprob:  0.673241, 0.326823 (1.423 sec)
11.617... logprob:  0.643884, 0.274740 (1.417 sec)
11.618... logprob:  0.731102, 0.320312 (1.430 sec)
11.619... logprob:  0.786123, 0.339844 (1.451 sec)
11.620... logprob:  0.772421, 0.329427 (1.451 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.466695, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.188878e-03 [2.620620e-07] 
Layer 'conv1' biases: 1.588543e-06 [8.792304e-10] 
Layer 'conv2' weights[0]: 5.179405e-03 [2.612213e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.620754e-09] 
Layer 'conv3' weights[0]: 5.178125e-03 [2.631991e-07] 
Layer 'conv3' biases: 2.676051e-05 [2.797718e-08] 
Layer 'conv4' weights[0]: 5.199463e-03 [2.673485e-07] 
Layer 'conv4' biases: 1.000013e+00 [4.117962e-07] 
Layer 'conv5' weights[0]: 5.268301e-03 [3.344001e-06] 
Layer 'conv5' biases: 9.990911e-01 [3.507207e-06] 
Layer 'fc6' weights[0]: 7.259990e-03 [7.825883e-08] 
Layer 'fc6' biases: 9.999958e-01 [8.447881e-08] 
Layer 'fc7' weights[0]: 7.613142e-03 [1.923626e-07] 
Layer 'fc7' biases: 9.998754e-01 [3.383607e-07] 
Layer 'fc8' weights[0]: 4.398728e-03 [2.555172e-05] 
Layer 'fc8' biases: 1.047622e-02 [5.976576e-05] 
Train error last 800 batches: 0.653156
-------------------------------------------------------
Not saving because 0.466695 > 0.299667 (9.300: -1.18%)
======================================================= (2.362 sec)
11.621... logprob:  0.516989, 0.246094 (1.450 sec)
11.622... logprob:  0.529624, 0.242187 (1.447 sec)
11.623... logprob:  0.705516, 0.326823 (1.465 sec)
11.624... logprob:  0.592413, 0.269531 (1.429 sec)
11.625... logprob:  0.678617, 0.290365 (1.420 sec)
11.626... logprob:  0.654136, 0.286458 (1.429 sec)
11.627... logprob:  0.637502, 0.315104 (1.438 sec)
11.628... logprob:  0.629409, 0.282552 (1.432 sec)
11.629... logprob:  0.616048, 0.278646 (1.470 sec)
11.630... logprob:  0.710437, 0.330729 (1.440 sec)
11.631... logprob:  0.770035, 0.309896 (1.433 sec)
11.632... logprob:  0.558644, 0.236979 (1.474 sec)
11.633... logprob:  0.583079, 0.266927 (1.428 sec)
11.634... logprob:  0.922427, 0.355469 (1.420 sec)
11.635... logprob:  0.599757, 0.261719 (1.426 sec)
11.636... logprob:  0.710674, 0.285156 (1.433 sec)
11.637... logprob:  0.628360, 0.286458 (1.426 sec)
11.638... logprob:  0.655203, 0.296875 (1.471 sec)
11.639... logprob:  0.612015, 0.278646 (1.438 sec)
11.640... logprob:  0.831778, 0.333333 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.466365, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.183720e-03 [2.608597e-07] 
Layer 'conv1' biases: 1.593449e-06 [7.610255e-10] 
Layer 'conv2' weights[0]: 5.174233e-03 [2.602360e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.810430e-09] 
Layer 'conv3' weights[0]: 5.172924e-03 [2.620493e-07] 
Layer 'conv3' biases: 2.671701e-05 [2.688265e-08] 
Layer 'conv4' weights[0]: 5.194259e-03 [2.649583e-07] 
Layer 'conv4' biases: 1.000012e+00 [3.606560e-07] 
Layer 'conv5' weights[0]: 5.262862e-03 [2.981959e-06] 
Layer 'conv5' biases: 9.991066e-01 [3.045515e-06] 
Layer 'fc6' weights[0]: 7.259240e-03 [6.710899e-08] 
Layer 'fc6' biases: 9.999957e-01 [6.813413e-08] 
Layer 'fc7' weights[0]: 7.612365e-03 [1.582494e-07] 
Layer 'fc7' biases: 9.998737e-01 [2.350881e-07] 
Layer 'fc8' weights[0]: 4.322949e-03 [2.090927e-05] 
Layer 'fc8' biases: 9.961614e-03 [4.041460e-05] 
Train error last 800 batches: 0.652825
-------------------------------------------------------
Not saving because 0.466365 > 0.299667 (9.300: -1.18%)
======================================================= (2.355 sec)
11.641... logprob:  0.697118, 0.332031 (1.485 sec)
11.642... logprob:  0.665868, 0.300781 (1.433 sec)
11.643... logprob:  0.705410, 0.302083 (1.436 sec)
11.644... logprob:  0.593257, 0.247396 (1.431 sec)
11.645... logprob:  0.677651, 0.320312 (1.427 sec)
11.646... logprob:  0.655510, 0.266927 (1.433 sec)
11.647... logprob:  0.737633, 0.319010 (1.493 sec)
11.648... logprob:  0.643357, 0.294271 (1.431 sec)
11.649... logprob:  0.633615, 0.289062 (1.438 sec)
11.650... logprob:  0.743886, 0.330729 (1.473 sec)
11.651... logprob:  0.655035, 0.281250 (1.428 sec)
11.652... logprob:  0.733528, 0.320312 (1.435 sec)
11.653... logprob:  0.745714, 0.332031 (1.424 sec)
11.654... logprob:  0.801943, 0.324219 (1.423 sec)
11.655... logprob:  0.658301, 0.303385 (1.426 sec)
11.656... logprob:  0.610263, 0.265625 (1.474 sec)
11.657... logprob:  0.647511, 0.292969 (1.439 sec)
11.658... logprob:  0.595156, 0.253906 (1.447 sec)
11.659... logprob:  0.744265, 0.311198 (1.461 sec)
11.660... logprob:  0.672015, 0.286458 (1.442 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.486375, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.178550e-03 [2.606084e-07] 
Layer 'conv1' biases: 1.599654e-06 [5.762904e-10] 
Layer 'conv2' weights[0]: 5.169058e-03 [2.595442e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.403596e-09] 
Layer 'conv3' weights[0]: 5.167733e-03 [2.608104e-07] 
Layer 'conv3' biases: 2.668407e-05 [2.134374e-08] 
Layer 'conv4' weights[0]: 5.189051e-03 [2.632298e-07] 
Layer 'conv4' biases: 1.000011e+00 [3.066606e-07] 
Layer 'conv5' weights[0]: 5.257618e-03 [2.503675e-06] 
Layer 'conv5' biases: 9.991133e-01 [2.679456e-06] 
Layer 'fc6' weights[0]: 7.258509e-03 [6.215861e-08] 
Layer 'fc6' biases: 9.999958e-01 [6.056111e-08] 
Layer 'fc7' weights[0]: 7.611596e-03 [1.380458e-07] 
Layer 'fc7' biases: 9.998726e-01 [1.650533e-07] 
Layer 'fc8' weights[0]: 4.294518e-03 [1.598392e-05] 
Layer 'fc8' biases: 9.779993e-03 [1.750653e-05] 
Train error last 800 batches: 0.653543
-------------------------------------------------------
Not saving because 0.486375 > 0.299667 (9.300: -1.18%)
======================================================= (2.406 sec)
11.661... logprob:  0.650084, 0.263021 (1.440 sec)
11.662... logprob:  0.662668, 0.313802 (1.430 sec)
11.663... logprob:  0.594822, 0.274740 (1.428 sec)
11.664... logprob:  0.472923, 0.196614 (1.440 sec)
11.665... logprob:  0.683999, 0.291667 (1.462 sec)
11.666... logprob:  0.557418, 0.259115 (1.452 sec)
11.667... logprob:  0.779650, 0.315104 (1.464 sec)
11.668... logprob:  0.684183, 0.292969 (1.455 sec)
11.669... logprob:  0.658233, 0.265625 (1.463 sec)
11.670... logprob:  0.594206, 0.256510 (1.436 sec)
11.671... logprob:  0.590707, 0.281250 (1.417 sec)
11.672... logprob:  0.740218, 0.300781 (1.429 sec)
11.673... logprob:  0.720173, 0.324219 (1.439 sec)
11.674... logprob:  0.598387, 0.277344 (1.431 sec)
11.675... logprob:  0.586250, 0.270833 (1.466 sec)
11.676... logprob:  0.638866, 0.281250 (1.450 sec)
11.677... logprob:  0.606447, 0.248698 (1.436 sec)
11.678... logprob:  0.679456, 0.308594 (1.479 sec)
11.679... logprob:  0.617681, 0.279948 (1.429 sec)
11.680... logprob:  0.610732, 0.272135 (1.418 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.476865, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.173361e-03 [2.601609e-07] 
Layer 'conv1' biases: 1.601699e-06 [5.124589e-10] 
Layer 'conv2' weights[0]: 5.163891e-03 [2.594491e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.551175e-09] 
Layer 'conv3' weights[0]: 5.162565e-03 [2.599673e-07] 
Layer 'conv3' biases: 2.667396e-05 [2.057243e-08] 
Layer 'conv4' weights[0]: 5.183876e-03 [2.623879e-07] 
Layer 'conv4' biases: 1.000011e+00 [2.955153e-07] 
Layer 'conv5' weights[0]: 5.252447e-03 [2.331569e-06] 
Layer 'conv5' biases: 9.990908e-01 [2.535741e-06] 
Layer 'fc6' weights[0]: 7.257750e-03 [5.776248e-08] 
Layer 'fc6' biases: 9.999956e-01 [5.429603e-08] 
Layer 'fc7' weights[0]: 7.610817e-03 [1.278586e-07] 
Layer 'fc7' biases: 9.998745e-01 [1.448014e-07] 
Layer 'fc8' weights[0]: 4.375226e-03 [1.427305e-05] 
Layer 'fc8' biases: 1.040416e-02 [1.393074e-05] 
Train error last 800 batches: 0.653576
-------------------------------------------------------
Not saving because 0.476865 > 0.299667 (9.300: -1.18%)
======================================================= (2.365 sec)
11.681... logprob:  0.636263, 0.286458 (1.432 sec)
11.682... logprob:  0.689957, 0.326823 (1.438 sec)
11.683... logprob:  0.656366, 0.266927 (1.430 sec)
11.684... logprob:  0.624182, 0.286458 (1.477 sec)
11.685... logprob:  0.555288, 0.256510 (1.443 sec)
11.686... logprob:  0.532882, 0.239583 (1.424 sec)
11.687... logprob:  0.547690, 0.256510 (1.483 sec)
11.688... logprob:  0.577120, 0.247396 (1.434 sec)
11.689... logprob:  0.647719, 0.272135 (1.421 sec)
11.690... logprob:  0.728966, 0.291667 (1.428 sec)
11.691... logprob:  0.747197, 0.298177 (1.426 sec)
11.692... logprob:  0.589914, 0.256510 (1.431 sec)
11.693... logprob:  0.624984, 0.273438 (1.485 sec)
11.694... logprob:  0.565637, 0.250000 (1.427 sec)
11.695... logprob:  0.711903, 0.304688 (1.437 sec)
11.696... logprob:  0.716144, 0.269531 (1.471 sec)
11.697... logprob:  0.692534, 0.324219 (1.429 sec)
11.698... logprob:  0.776373, 0.309896 (1.428 sec)
11.699... logprob:  0.691961, 0.305990 (1.433 sec)
11.700... logprob:  0.598026, 0.264323 (1.425 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.569930, 0.171875 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.168193e-03 [2.597259e-07] 
Layer 'conv1' biases: 1.603388e-06 [7.467050e-10] 
Layer 'conv2' weights[0]: 5.158735e-03 [2.595970e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.130316e-09] 
Layer 'conv3' weights[0]: 5.157445e-03 [2.617645e-07] 
Layer 'conv3' biases: 2.664810e-05 [3.009528e-08] 
Layer 'conv4' weights[0]: 5.178713e-03 [2.649694e-07] 
Layer 'conv4' biases: 1.000010e+00 [4.225266e-07] 
Layer 'conv5' weights[0]: 5.246873e-03 [3.435334e-06] 
Layer 'conv5' biases: 9.990999e-01 [3.711824e-06] 
Layer 'fc6' weights[0]: 7.256985e-03 [7.067936e-08] 
Layer 'fc6' biases: 9.999956e-01 [7.345019e-08] 
Layer 'fc7' weights[0]: 7.610053e-03 [1.667562e-07] 
Layer 'fc7' biases: 9.998739e-01 [2.678925e-07] 
Layer 'fc8' weights[0]: 4.369391e-03 [2.101909e-05] 
Layer 'fc8' biases: 1.035466e-02 [4.185601e-05] 
Train error last 800 batches: 0.653712
-------------------------------------------------------
Not saving because 0.569930 > 0.299667 (9.300: -1.18%)
======================================================= (2.357 sec)
11.701... logprob:  0.640387, 0.276042 (1.440 sec)
11.702... logprob:  0.673600, 0.308594 (1.480 sec)
11.703... logprob:  0.536708, 0.235677 (1.430 sec)
11.704... logprob:  0.625175, 0.315104 (1.444 sec)
11.705... logprob:  0.673448, 0.296875 (1.474 sec)
11.706... logprob:  0.722678, 0.282552 (1.436 sec)
11.707... logprob:  0.639122, 0.266927 (1.442 sec)
11.708... logprob:  0.599957, 0.277344 (1.440 sec)
11.709... logprob:  0.634302, 0.296875 (1.423 sec)
11.710... logprob:  0.844214, 0.337240 (1.432 sec)
11.711... logprob:  0.622157, 0.230469 (1.461 sec)
11.712... logprob:  0.597402, 0.240885 (1.448 sec)
11.713... logprob:  0.788459, 0.354167 (1.451 sec)
11.714... logprob:  0.751718, 0.337240 (1.454 sec)
11.715... logprob:  0.604267, 0.276042 (1.451 sec)
11.716... logprob:  0.573188, 0.270833 (1.430 sec)
11.717... logprob:  0.723040, 0.313802 (1.419 sec)
11.718... logprob:  0.705964, 0.304688 (1.421 sec)
11.719... logprob:  0.649469, 0.298177 (1.434 sec)
11.720... logprob:  0.684667, 0.290365 (1.440 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.479289, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.163026e-03 [2.595396e-07] 
Layer 'conv1' biases: 1.604540e-06 [5.168429e-10] 
Layer 'conv2' weights[0]: 5.153617e-03 [2.586861e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.364546e-09] 
Layer 'conv3' weights[0]: 5.152258e-03 [2.596669e-07] 
Layer 'conv3' biases: 2.666079e-05 [2.112509e-08] 
Layer 'conv4' weights[0]: 5.173513e-03 [2.616881e-07] 
Layer 'conv4' biases: 1.000010e+00 [2.884402e-07] 
Layer 'conv5' weights[0]: 5.242454e-03 [2.551038e-06] 
Layer 'conv5' biases: 9.991130e-01 [2.716392e-06] 
Layer 'fc6' weights[0]: 7.256232e-03 [6.220967e-08] 
Layer 'fc6' biases: 9.999958e-01 [6.065200e-08] 
Layer 'fc7' weights[0]: 7.609338e-03 [1.401128e-07] 
Layer 'fc7' biases: 9.998728e-01 [1.782794e-07] 
Layer 'fc8' weights[0]: 4.332738e-03 [1.768707e-05] 
Layer 'fc8' biases: 1.010154e-02 [3.211741e-05] 
Train error last 800 batches: 0.653848
-------------------------------------------------------
Not saving because 0.479289 > 0.299667 (9.300: -1.18%)
======================================================= (2.363 sec)
11.721... logprob:  0.654976, 0.290365 (1.465 sec)
11.722... logprob:  0.754166, 0.319010 (1.454 sec)
11.723... logprob:  0.604535, 0.260417 (1.440 sec)
11.724... logprob:  0.554606, 0.269531 (1.471 sec)
11.725... logprob:  0.668205, 0.290365 (1.437 sec)
11.726... logprob:  0.640518, 0.305990 (1.427 sec)
11.727... logprob:  0.626329, 0.252604 (1.433 sec)
11.728... logprob:  0.630836, 0.270833 (1.441 sec)
11.729... logprob:  0.599474, 0.230469 (1.436 sec)
11.730... logprob:  0.739735, 0.321615 (1.475 sec)
11.731... logprob:  0.554111, 0.252604 (1.441 sec)
11.732... logprob:  0.547093, 0.252604 (1.427 sec)
11.733... logprob:  0.707348, 0.302083 (1.478 sec)
11.734... logprob:  0.588356, 0.248698 (1.425 sec)
11.735... logprob:  0.742633, 0.322917 (1.420 sec)
11.736... logprob:  0.766199, 0.330729 (1.437 sec)
11.737... logprob:  0.698012, 0.298177 (1.440 sec)
11.738... logprob:  0.695290, 0.312500 (1.425 sec)
11.739... logprob:  0.685542, 0.316406 (1.478 sec)
11.740... logprob:  0.537977, 0.234375 (1.432 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.487363, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.157894e-03 [2.591876e-07] 
Layer 'conv1' biases: 1.607041e-06 [5.348568e-10] 
Layer 'conv2' weights[0]: 5.148468e-03 [2.585310e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.200600e-09] 
Layer 'conv3' weights[0]: 5.147102e-03 [2.597730e-07] 
Layer 'conv3' biases: 2.666204e-05 [2.305216e-08] 
Layer 'conv4' weights[0]: 5.168344e-03 [2.622263e-07] 
Layer 'conv4' biases: 1.000011e+00 [3.065110e-07] 
Layer 'conv5' weights[0]: 5.237613e-03 [2.460543e-06] 
Layer 'conv5' biases: 9.991091e-01 [2.670305e-06] 
Layer 'fc6' weights[0]: 7.255521e-03 [5.795284e-08] 
Layer 'fc6' biases: 9.999959e-01 [5.406498e-08] 
Layer 'fc7' weights[0]: 7.608585e-03 [1.293286e-07] 
Layer 'fc7' biases: 9.998726e-01 [1.468835e-07] 
Layer 'fc8' weights[0]: 4.344565e-03 [1.467198e-05] 
Layer 'fc8' biases: 1.008174e-02 [1.097193e-05] 
Train error last 800 batches: 0.652998
-------------------------------------------------------
Not saving because 0.487363 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
11.741... logprob:  0.641624, 0.295573 (1.442 sec)
11.742... logprob:  0.642110, 0.251302 (1.484 sec)
11.743... logprob:  0.631718, 0.289063 (1.425 sec)
11.744... logprob:  0.836879, 0.367187 (1.428 sec)
11.745... logprob:  0.686989, 0.291667 (1.436 sec)
11.746... logprob:  0.588388, 0.266927 (1.424 sec)
11.747... logprob:  0.664178, 0.292969 (1.425 sec)
11.748... logprob:  0.645927, 0.300781 (1.478 sec)
11.749... logprob:  0.679701, 0.311198 (1.429 sec)
11.750... logprob:  0.768901, 0.315104 (1.445 sec)
11.751... logprob:  0.545929, 0.248698 (1.474 sec)
11.752... logprob:  0.676825, 0.302083 (1.429 sec)
11.753... logprob:  0.682054, 0.277344 (1.431 sec)
11.754... logprob:  0.746284, 0.317708 (1.429 sec)
11.755... logprob:  0.664689, 0.278646 (1.421 sec)
11.756... logprob:  0.629641, 0.269531 (1.429 sec)
11.757... logprob:  0.752681, 0.316406 (1.471 sec)
11.758... logprob:  0.567709, 0.239583 (1.439 sec)
11.759... logprob:  0.747893, 0.316406 (1.450 sec)
11.760... logprob:  0.668704, 0.328125 (1.462 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.497517, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.152735e-03 [2.590605e-07] 
Layer 'conv1' biases: 1.609029e-06 [4.640876e-10] 
Layer 'conv2' weights[0]: 5.143314e-03 [2.579656e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.528084e-09] 
Layer 'conv3' weights[0]: 5.141968e-03 [2.584691e-07] 
Layer 'conv3' biases: 2.673747e-05 [1.705877e-08] 
Layer 'conv4' weights[0]: 5.163205e-03 [2.608937e-07] 
Layer 'conv4' biases: 1.000011e+00 [2.696614e-07] 
Layer 'conv5' weights[0]: 5.232712e-03 [2.389656e-06] 
Layer 'conv5' biases: 9.991077e-01 [2.590919e-06] 
Layer 'fc6' weights[0]: 7.254762e-03 [5.929633e-08] 
Layer 'fc6' biases: 9.999958e-01 [5.630631e-08] 
Layer 'fc7' weights[0]: 7.607795e-03 [1.322311e-07] 
Layer 'fc7' biases: 9.998722e-01 [1.537132e-07] 
Layer 'fc8' weights[0]: 4.329068e-03 [1.480474e-05] 
Layer 'fc8' biases: 1.004268e-02 [1.066360e-05] 
Train error last 800 batches: 0.653487
-------------------------------------------------------
Not saving because 0.497517 > 0.299667 (9.300: -1.18%)
======================================================= (2.407 sec)
11.761... logprob:  0.635234, 0.247396 (1.444 sec)
11.762... logprob:  0.683140, 0.287760 (1.445 sec)
11.763... logprob:  0.756810, 0.312500 (1.427 sec)
11.764... logprob:  0.673051, 0.300781 (1.425 sec)
11.765... logprob:  0.577001, 0.270833 (1.432 sec)
11.766... logprob:  0.745027, 0.373698 (1.448 sec)
11.767... logprob:  0.589715, 0.259114 (1.452 sec)
11.768... logprob:  0.699294, 0.298177 (1.467 sec)
11.769... logprob:  0.593957, 0.238281 (1.468 sec)
11.770... logprob:  0.594975, 0.247396 (1.490 sec)
11.771... logprob:  0.767275, 0.324219 (1.448 sec)
11.772... logprob:  0.689153, 0.328125 (1.443 sec)
11.773... logprob:  0.694169, 0.317708 (1.443 sec)
11.774... logprob:  0.696378, 0.313802 (1.457 sec)
11.775... logprob:  0.655242, 0.300781 (1.462 sec)
11.776... logprob:  0.697437, 0.316406 (1.471 sec)
11.777... logprob:  0.714089, 0.309896 (1.466 sec)
11.778... logprob:  0.614824, 0.257812 (1.460 sec)
11.779... logprob:  0.713851, 0.289062 (1.481 sec)
11.780... logprob:  0.680571, 0.315104 (1.445 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.509589, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.147579e-03 [2.597501e-07] 
Layer 'conv1' biases: 1.608962e-06 [6.372332e-10] 
Layer 'conv2' weights[0]: 5.138201e-03 [2.582063e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.067899e-09] 
Layer 'conv3' weights[0]: 5.136826e-03 [2.590205e-07] 
Layer 'conv3' biases: 2.679344e-05 [2.095748e-08] 
Layer 'conv4' weights[0]: 5.158024e-03 [2.617300e-07] 
Layer 'conv4' biases: 1.000012e+00 [2.957101e-07] 
Layer 'conv5' weights[0]: 5.228087e-03 [2.576725e-06] 
Layer 'conv5' biases: 9.990999e-01 [2.809292e-06] 
Layer 'fc6' weights[0]: 7.254027e-03 [5.955619e-08] 
Layer 'fc6' biases: 9.999958e-01 [5.685472e-08] 
Layer 'fc7' weights[0]: 7.607040e-03 [1.368886e-07] 
Layer 'fc7' biases: 9.998723e-01 [1.690723e-07] 
Layer 'fc8' weights[0]: 4.352008e-03 [1.583512e-05] 
Layer 'fc8' biases: 1.013164e-02 [2.165493e-05] 
Train error last 800 batches: 0.654009
-------------------------------------------------------
Not saving because 0.509589 > 0.299667 (9.300: -1.18%)
======================================================= (2.413 sec)
11.781... logprob:  0.531408, 0.229167 (1.448 sec)
11.782... logprob:  0.680844, 0.325521 (1.449 sec)
11.783... logprob:  0.721809, 0.298177 (1.454 sec)
11.784... logprob:  0.653052, 0.277344 (1.457 sec)
11.785... logprob:  0.721829, 0.292969 (1.483 sec)
11.786... logprob:  0.719029, 0.302083 (1.469 sec)
11.787... logprob:  0.741162, 0.326823 (1.460 sec)
11.788... logprob:  0.674484, 0.278646 (1.485 sec)
11.789... logprob:  0.526869, 0.231771 (1.450 sec)
11.790... logprob:  0.653265, 0.270833 (1.448 sec)
11.791... logprob:  0.608486, 0.274740 (1.444 sec)
11.792... logprob:  0.636089, 0.325521 (1.458 sec)
11.793... logprob:  0.550701, 0.238281 (1.446 sec)
11.794... logprob:  0.563058, 0.243490 (1.485 sec)
11.795... logprob:  0.660558, 0.281250 (1.467 sec)
11.796... logprob:  0.703045, 0.299479 (1.458 sec)
11.797... logprob:  0.699238, 0.298177 (1.494 sec)
11.798... logprob:  0.685327, 0.307292 (1.445 sec)
11.799... logprob:  0.591730, 0.276042 (1.438 sec)
11.800... logprob:  0.612490, 0.277344 (1.401 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.497307, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.142443e-03 [2.591116e-07] 
Layer 'conv1' biases: 1.611224e-06 [6.104774e-10] 
Layer 'conv2' weights[0]: 5.133003e-03 [2.580880e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.512149e-09] 
Layer 'conv3' weights[0]: 5.131703e-03 [2.590141e-07] 
Layer 'conv3' biases: 2.687764e-05 [2.190749e-08] 
Layer 'conv4' weights[0]: 5.152854e-03 [2.622495e-07] 
Layer 'conv4' biases: 1.000014e+00 [3.485154e-07] 
Layer 'conv5' weights[0]: 5.224010e-03 [2.972121e-06] 
Layer 'conv5' biases: 9.990830e-01 [3.202746e-06] 
Layer 'fc6' weights[0]: 7.253272e-03 [6.175579e-08] 
Layer 'fc6' biases: 9.999955e-01 [6.053883e-08] 
Layer 'fc7' weights[0]: 7.606269e-03 [1.434672e-07] 
Layer 'fc7' biases: 9.998730e-01 [2.050019e-07] 
Layer 'fc8' weights[0]: 4.380384e-03 [1.784053e-05] 
Layer 'fc8' biases: 1.038147e-02 [3.769950e-05] 
Train error last 800 batches: 0.654350
-------------------------------------------------------
Not saving because 0.497307 > 0.299667 (9.300: -1.18%)
======================================================= (2.371 sec)
12.1... logprob:  0.580079, 0.273437 (1.401 sec)
12.2... logprob:  0.633724, 0.305989 (1.448 sec)
12.3... logprob:  0.573534, 0.269531 (1.419 sec)
12.4... logprob:  0.611559, 0.272135 (1.401 sec)
12.5... logprob:  0.611784, 0.286458 (1.435 sec)
12.6... logprob:  0.874177, 0.378906 (1.385 sec)
12.7... logprob:  0.711066, 0.309896 (1.417 sec)
12.8... logprob:  0.619393, 0.270833 (1.391 sec)
12.9... logprob:  0.591088, 0.282552 (1.407 sec)
12.10... logprob:  0.611266, 0.278646 (1.410 sec)
12.11... logprob:  0.614381, 0.296875 (1.440 sec)
12.12... logprob:  0.717416, 0.292969 (1.406 sec)
12.13... logprob:  0.681165, 0.305990 (1.425 sec)
12.14... logprob:  0.595359, 0.257812 (1.393 sec)
12.15... logprob:  0.622111, 0.270833 (1.405 sec)
12.16... logprob:  0.703109, 0.307292 (1.402 sec)
12.17... logprob:  0.683935, 0.309896 (1.392 sec)
12.18... logprob:  0.539862, 0.235677 (1.398 sec)
12.19... logprob:  0.491334, 0.233073 (1.393 sec)
12.20... logprob:  0.642869, 0.294271 (1.397 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.395421, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.137296e-03 [2.576985e-07] 
Layer 'conv1' biases: 1.614084e-06 [4.004191e-10] 
Layer 'conv2' weights[0]: 5.127879e-03 [2.571671e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.231489e-09] 
Layer 'conv3' weights[0]: 5.126612e-03 [2.578987e-07] 
Layer 'conv3' biases: 2.691627e-05 [1.873666e-08] 
Layer 'conv4' weights[0]: 5.147687e-03 [2.596752e-07] 
Layer 'conv4' biases: 1.000014e+00 [2.321999e-07] 
Layer 'conv5' weights[0]: 5.219433e-03 [2.187796e-06] 
Layer 'conv5' biases: 9.990700e-01 [2.378919e-06] 
Layer 'fc6' weights[0]: 7.252522e-03 [5.484028e-08] 
Layer 'fc6' biases: 9.999955e-01 [5.013909e-08] 
Layer 'fc7' weights[0]: 7.605493e-03 [1.202760e-07] 
Layer 'fc7' biases: 9.998735e-01 [1.356683e-07] 
Layer 'fc8' weights[0]: 4.404985e-03 [1.345212e-05] 
Layer 'fc8' biases: 1.059529e-02 [1.179420e-05] 
Train error last 800 batches: 0.654623
-------------------------------------------------------
Not saving because 0.395421 > 0.299667 (9.300: -1.18%)
======================================================= (2.384 sec)
12.21... logprob:  0.708255, 0.313802 (1.407 sec)
12.22... logprob:  0.822966, 0.356771 (1.412 sec)
12.23... logprob:  0.700974, 0.320313 (1.415 sec)
12.24... logprob:  0.612730, 0.279948 (1.415 sec)
12.25... logprob:  0.702767, 0.298177 (1.399 sec)
12.26... logprob:  0.656672, 0.302083 (1.463 sec)
12.27... logprob:  0.691368, 0.298177 (1.384 sec)
12.28... logprob:  0.634236, 0.278646 (1.410 sec)
12.29... logprob:  0.630225, 0.276042 (1.417 sec)
12.30... logprob:  0.573404, 0.279948 (1.411 sec)
12.31... logprob:  0.757295, 0.333333 (1.399 sec)
12.32... logprob:  0.655505, 0.295573 (1.386 sec)
12.33... logprob:  0.647637, 0.268229 (1.446 sec)
12.34... logprob:  0.644247, 0.291667 (1.395 sec)
12.35... logprob:  0.532503, 0.227865 (1.400 sec)
12.36... logprob:  0.707970, 0.263021 (1.393 sec)
12.37... logprob:  0.684130, 0.302083 (1.408 sec)
12.38... logprob:  0.648708, 0.294271 (1.395 sec)
12.39... logprob:  0.758465, 0.292969 (1.427 sec)
12.40... logprob:  0.694440, 0.276042 (1.403 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.447361, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.132194e-03 [2.582417e-07] 
Layer 'conv1' biases: 1.620935e-06 [8.585869e-10] 
Layer 'conv2' weights[0]: 5.122772e-03 [2.581084e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.452781e-09] 
Layer 'conv3' weights[0]: 5.121410e-03 [2.604608e-07] 
Layer 'conv3' biases: 2.695400e-05 [3.006738e-08] 
Layer 'conv4' weights[0]: 5.142600e-03 [2.633282e-07] 
Layer 'conv4' biases: 1.000015e+00 [3.743455e-07] 
Layer 'conv5' weights[0]: 5.214608e-03 [3.196690e-06] 
Layer 'conv5' biases: 9.990851e-01 [3.574058e-06] 
Layer 'fc6' weights[0]: 7.251791e-03 [6.955272e-08] 
Layer 'fc6' biases: 9.999956e-01 [7.238672e-08] 
Layer 'fc7' weights[0]: 7.604780e-03 [1.640229e-07] 
Layer 'fc7' biases: 9.998716e-01 [2.452631e-07] 
Layer 'fc8' weights[0]: 4.353605e-03 [1.991427e-05] 
Layer 'fc8' biases: 1.018594e-02 [3.750815e-05] 
Train error last 800 batches: 0.655077
-------------------------------------------------------
Not saving because 0.447361 > 0.299667 (9.300: -1.18%)
======================================================= (2.391 sec)
12.41... logprob:  0.723634, 0.335938 (1.423 sec)
12.42... logprob:  0.674436, 0.300781 (1.422 sec)
12.43... logprob:  0.649287, 0.260417 (1.402 sec)
12.44... logprob:  0.761812, 0.342448 (1.430 sec)
12.45... logprob:  0.690481, 0.283854 (1.387 sec)
12.46... logprob:  0.651899, 0.305989 (1.397 sec)
12.47... logprob:  0.628108, 0.268229 (1.387 sec)
12.48... logprob:  0.717968, 0.333333 (1.416 sec)
12.49... logprob:  0.684121, 0.308594 (1.411 sec)
12.50... logprob:  0.547978, 0.243490 (1.425 sec)
12.51... logprob:  0.687912, 0.313802 (1.419 sec)
12.52... logprob:  0.606126, 0.247396 (1.393 sec)
12.53... logprob:  0.578553, 0.251302 (1.440 sec)
12.54... logprob:  0.641290, 0.286458 (1.387 sec)
12.55... logprob:  0.599239, 0.264323 (1.389 sec)
12.56... logprob:  0.515965, 0.246094 (1.400 sec)
12.57... logprob:  0.706185, 0.291667 (1.430 sec)
12.58... logprob:  0.618130, 0.268229 (1.402 sec)
12.59... logprob:  0.623170, 0.286458 (1.459 sec)
12.60... logprob:  0.913912, 0.352865 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.452739, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.127060e-03 [2.583270e-07] 
Layer 'conv1' biases: 1.625682e-06 [5.463135e-10] 
Layer 'conv2' weights[0]: 5.117666e-03 [2.570889e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.872527e-09] 
Layer 'conv3' weights[0]: 5.116292e-03 [2.590789e-07] 
Layer 'conv3' biases: 2.698094e-05 [2.539394e-08] 
Layer 'conv4' weights[0]: 5.137440e-03 [2.611542e-07] 
Layer 'conv4' biases: 1.000012e+00 [3.448891e-07] 
Layer 'conv5' weights[0]: 5.208927e-03 [2.602787e-06] 
Layer 'conv5' biases: 9.990865e-01 [2.768384e-06] 
Layer 'fc6' weights[0]: 7.251021e-03 [6.321424e-08] 
Layer 'fc6' biases: 9.999955e-01 [6.287195e-08] 
Layer 'fc7' weights[0]: 7.604020e-03 [1.472108e-07] 
Layer 'fc7' biases: 9.998717e-01 [1.946201e-07] 
Layer 'fc8' weights[0]: 4.371958e-03 [1.866375e-05] 
Layer 'fc8' biases: 1.034756e-02 [3.356450e-05] 
Train error last 800 batches: 0.654761
-------------------------------------------------------
Not saving because 0.452739 > 0.299667 (9.300: -1.18%)
======================================================= (2.369 sec)
12.61... logprob:  0.607328, 0.256510 (1.429 sec)
12.62... logprob:  0.672621, 0.304687 (1.459 sec)
12.63... logprob:  0.668606, 0.279948 (1.444 sec)
12.64... logprob:  0.638357, 0.287760 (1.408 sec)
12.65... logprob:  0.646116, 0.285156 (1.400 sec)
12.66... logprob:  0.538293, 0.230469 (1.440 sec)
12.67... logprob:  0.506860, 0.235677 (1.391 sec)
12.68... logprob:  0.666118, 0.307292 (1.396 sec)
12.69... logprob:  0.614446, 0.236979 (1.424 sec)
12.70... logprob:  0.534886, 0.233073 (1.423 sec)
12.71... logprob:  0.618656, 0.276042 (1.453 sec)
12.72... logprob:  0.669674, 0.269531 (1.399 sec)
12.73... logprob:  0.649582, 0.294271 (1.422 sec)
12.74... logprob:  0.612345, 0.294271 (1.413 sec)
12.75... logprob:  0.599565, 0.257812 (1.408 sec)
12.76... logprob:  0.741620, 0.329427 (1.432 sec)
12.77... logprob:  0.658062, 0.289062 (1.428 sec)
12.78... logprob:  0.728153, 0.312500 (1.448 sec)
12.79... logprob:  0.631716, 0.264323 (1.406 sec)
12.80... logprob:  0.694912, 0.283854 (1.412 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.563419, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.121950e-03 [2.576220e-07] 
Layer 'conv1' biases: 1.629010e-06 [7.346432e-10] 
Layer 'conv2' weights[0]: 5.112542e-03 [2.572694e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.798588e-09] 
Layer 'conv3' weights[0]: 5.111170e-03 [2.592691e-07] 
Layer 'conv3' biases: 2.700047e-05 [2.703057e-08] 
Layer 'conv4' weights[0]: 5.132323e-03 [2.628334e-07] 
Layer 'conv4' biases: 1.000012e+00 [3.936423e-07] 
Layer 'conv5' weights[0]: 5.203559e-03 [3.192383e-06] 
Layer 'conv5' biases: 9.990868e-01 [3.520219e-06] 
Layer 'fc6' weights[0]: 7.250275e-03 [6.803306e-08] 
Layer 'fc6' biases: 9.999955e-01 [6.995251e-08] 
Layer 'fc7' weights[0]: 7.603238e-03 [1.604121e-07] 
Layer 'fc7' biases: 9.998712e-01 [2.500582e-07] 
Layer 'fc8' weights[0]: 4.380580e-03 [2.077069e-05] 
Layer 'fc8' biases: 1.043475e-02 [3.221988e-05] 
Train error last 800 batches: 0.654659
-------------------------------------------------------
Not saving because 0.563419 > 0.299667 (9.300: -1.18%)
======================================================= (2.346 sec)
12.81... logprob:  0.702437, 0.341146 (1.424 sec)
12.82... logprob:  0.466550, 0.209635 (1.430 sec)
12.83... logprob:  0.684861, 0.285156 (1.399 sec)
12.84... logprob:  0.821639, 0.359375 (1.465 sec)
12.85... logprob:  0.691877, 0.326823 (1.421 sec)
12.86... logprob:  0.697484, 0.324219 (1.419 sec)
12.87... logprob:  0.800376, 0.332031 (1.412 sec)
12.88... logprob:  0.751707, 0.311198 (1.405 sec)
12.89... logprob:  0.578932, 0.226562 (1.426 sec)
12.90... logprob:  0.737799, 0.294271 (1.382 sec)
12.91... logprob:  0.592112, 0.276042 (1.393 sec)
12.92... logprob:  0.646415, 0.277344 (1.403 sec)
12.93... logprob:  0.728729, 0.325521 (1.389 sec)
12.94... logprob:  0.588515, 0.269531 (1.384 sec)
12.95... logprob:  0.654176, 0.281250 (1.403 sec)
12.96... logprob:  0.762120, 0.329427 (1.394 sec)
12.97... logprob:  0.684400, 0.312500 (1.386 sec)
12.98... logprob:  0.645918, 0.299479 (1.432 sec)
12.99... logprob:  0.713191, 0.292969 (1.397 sec)
12.100... logprob:  0.595457, 0.255208 (1.399 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.528239, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.116823e-03 [2.576032e-07] 
Layer 'conv1' biases: 1.633381e-06 [5.133278e-10] 
Layer 'conv2' weights[0]: 5.107444e-03 [2.565830e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.082684e-09] 
Layer 'conv3' weights[0]: 5.106124e-03 [2.577373e-07] 
Layer 'conv3' biases: 2.699446e-05 [2.161477e-08] 
Layer 'conv4' weights[0]: 5.127176e-03 [2.605066e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.032721e-07] 
Layer 'conv5' weights[0]: 5.199270e-03 [2.616902e-06] 
Layer 'conv5' biases: 9.991031e-01 [2.819506e-06] 
Layer 'fc6' weights[0]: 7.249528e-03 [6.111493e-08] 
Layer 'fc6' biases: 9.999955e-01 [5.952761e-08] 
Layer 'fc7' weights[0]: 7.602485e-03 [1.412589e-07] 
Layer 'fc7' biases: 9.998698e-01 [1.814119e-07] 
Layer 'fc8' weights[0]: 4.327837e-03 [1.715265e-05] 
Layer 'fc8' biases: 1.000062e-02 [3.217385e-05] 
Train error last 800 batches: 0.655326
-------------------------------------------------------
Not saving because 0.528239 > 0.299667 (9.300: -1.18%)
======================================================= (2.371 sec)
12.101... logprob:  0.511658, 0.201823 (1.444 sec)
12.102... logprob:  0.774681, 0.338542 (1.384 sec)
12.103... logprob:  0.755668, 0.328125 (1.397 sec)
12.104... logprob:  0.627430, 0.272135 (1.409 sec)
12.105... logprob:  0.862782, 0.354167 (1.394 sec)
12.106... logprob:  0.662552, 0.291667 (1.384 sec)
12.107... logprob:  0.530066, 0.250000 (1.435 sec)
12.108... logprob:  0.735404, 0.338542 (1.395 sec)
12.109... logprob:  0.584063, 0.277344 (1.394 sec)
12.110... logprob:  0.708821, 0.309896 (1.392 sec)
12.111... logprob:  0.661417, 0.279948 (1.390 sec)
12.112... logprob:  0.581033, 0.266927 (1.398 sec)
12.113... logprob:  0.554385, 0.253906 (1.397 sec)
12.114... logprob:  0.689649, 0.312500 (1.422 sec)
12.115... logprob:  0.732433, 0.311198 (1.403 sec)
12.116... logprob:  0.628908, 0.289062 (1.399 sec)
12.117... logprob:  0.631521, 0.273437 (1.442 sec)
12.118... logprob:  0.662566, 0.319010 (1.381 sec)
12.119... logprob:  0.612158, 0.274740 (1.394 sec)
12.120... logprob:  0.750056, 0.291667 (1.395 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.451672, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.111732e-03 [2.565000e-07] 
Layer 'conv1' biases: 1.632967e-06 [4.536523e-10] 
Layer 'conv2' weights[0]: 5.102353e-03 [2.557078e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.211102e-09] 
Layer 'conv3' weights[0]: 5.101038e-03 [2.565459e-07] 
Layer 'conv3' biases: 2.696060e-05 [1.797686e-08] 
Layer 'conv4' weights[0]: 5.122062e-03 [2.587997e-07] 
Layer 'conv4' biases: 1.000014e+00 [2.744649e-07] 
Layer 'conv5' weights[0]: 5.194681e-03 [2.172763e-06] 
Layer 'conv5' biases: 9.990858e-01 [2.228222e-06] 
Layer 'fc6' weights[0]: 7.248737e-03 [5.826846e-08] 
Layer 'fc6' biases: 9.999954e-01 [5.508070e-08] 
Layer 'fc7' weights[0]: 7.601715e-03 [1.320905e-07] 
Layer 'fc7' biases: 9.998710e-01 [1.509443e-07] 
Layer 'fc8' weights[0]: 4.376146e-03 [1.447129e-05] 
Layer 'fc8' biases: 1.039794e-02 [1.222709e-05] 
Train error last 800 batches: 0.655665
-------------------------------------------------------
Not saving because 0.451672 > 0.299667 (9.300: -1.18%)
======================================================= (2.376 sec)
12.121... logprob:  0.593463, 0.283854 (1.398 sec)
12.122... logprob:  0.728495, 0.303385 (1.448 sec)
12.123... logprob:  0.766753, 0.309896 (1.385 sec)
12.124... logprob:  0.718988, 0.319010 (1.400 sec)
12.125... logprob:  0.693674, 0.299479 (1.400 sec)
12.126... logprob:  0.711942, 0.324219 (1.391 sec)
12.127... logprob:  0.660817, 0.298177 (1.394 sec)
12.128... logprob:  0.615717, 0.270833 (1.417 sec)
12.129... logprob:  0.774057, 0.305989 (1.417 sec)
12.130... logprob:  0.637470, 0.283854 (1.412 sec)
12.131... logprob:  0.737157, 0.299479 (1.409 sec)
12.132... logprob:  0.830158, 0.308594 (1.424 sec)
12.133... logprob:  0.630779, 0.287760 (1.387 sec)
12.134... logprob:  0.641873, 0.295573 (1.396 sec)
12.135... logprob:  0.663235, 0.276042 (1.393 sec)
12.136... logprob:  0.729591, 0.313802 (1.395 sec)
12.137... logprob:  0.665754, 0.281250 (1.404 sec)
12.138... logprob:  0.504646, 0.216146 (1.440 sec)
12.139... logprob:  0.691472, 0.322917 (1.390 sec)
12.140... logprob:  0.746845, 0.326823 (1.409 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.458765, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.106607e-03 [2.571795e-07] 
Layer 'conv1' biases: 1.633238e-06 [5.909471e-10] 
Layer 'conv2' weights[0]: 5.097248e-03 [2.562297e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.413290e-09] 
Layer 'conv3' weights[0]: 5.095913e-03 [2.568330e-07] 
Layer 'conv3' biases: 2.701475e-05 [1.965899e-08] 
Layer 'conv4' weights[0]: 5.116949e-03 [2.597267e-07] 
Layer 'conv4' biases: 1.000014e+00 [2.961301e-07] 
Layer 'conv5' weights[0]: 5.189686e-03 [2.386851e-06] 
Layer 'conv5' biases: 9.990985e-01 [2.575288e-06] 
Layer 'fc6' weights[0]: 7.247961e-03 [5.986476e-08] 
Layer 'fc6' biases: 9.999954e-01 [5.722322e-08] 
Layer 'fc7' weights[0]: 7.600920e-03 [1.345235e-07] 
Layer 'fc7' biases: 9.998694e-01 [1.585041e-07] 
Layer 'fc8' weights[0]: 4.312657e-03 [1.519178e-05] 
Layer 'fc8' biases: 9.951109e-03 [1.498786e-05] 
Train error last 800 batches: 0.655841
-------------------------------------------------------
Not saving because 0.458765 > 0.299667 (9.300: -1.18%)
======================================================= (2.376 sec)
12.141... logprob:  0.672614, 0.302083 (1.446 sec)
12.142... logprob:  0.735707, 0.300781 (1.397 sec)
12.143... logprob:  0.554740, 0.269531 (1.434 sec)
12.144... logprob:  0.645746, 0.281250 (1.410 sec)
12.145... logprob:  0.567290, 0.257812 (1.416 sec)
12.146... logprob:  0.655326, 0.289062 (1.406 sec)
12.147... logprob:  0.625241, 0.292969 (1.432 sec)
12.148... logprob:  0.662473, 0.296875 (1.391 sec)
12.149... logprob:  0.663931, 0.294271 (1.397 sec)
12.150... logprob:  0.626366, 0.289062 (1.403 sec)
12.151... logprob:  0.606051, 0.279948 (1.398 sec)
12.152... logprob:  0.892144, 0.382812 (1.385 sec)
12.153... logprob:  0.687265, 0.299479 (1.446 sec)
12.154... logprob:  0.705291, 0.289062 (1.398 sec)
12.155... logprob:  0.538008, 0.229167 (1.404 sec)
12.156... logprob:  0.503264, 0.240885 (1.431 sec)
12.157... logprob:  0.461180, 0.203125 (1.390 sec)
12.158... logprob:  0.644709, 0.285156 (1.399 sec)
12.159... logprob:  0.642029, 0.259115 (1.390 sec)
12.160... logprob:  0.683475, 0.324219 (1.386 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.463852, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.101500e-03 [2.576125e-07] 
Layer 'conv1' biases: 1.634699e-06 [7.599019e-10] 
Layer 'conv2' weights[0]: 5.092133e-03 [2.565023e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.360098e-09] 
Layer 'conv3' weights[0]: 5.090801e-03 [2.575356e-07] 
Layer 'conv3' biases: 2.704630e-05 [2.310495e-08] 
Layer 'conv4' weights[0]: 5.111822e-03 [2.616416e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.638600e-07] 
Layer 'conv5' weights[0]: 5.184680e-03 [2.914437e-06] 
Layer 'conv5' biases: 9.990764e-01 [3.089060e-06] 
Layer 'fc6' weights[0]: 7.247216e-03 [6.555838e-08] 
Layer 'fc6' biases: 9.999954e-01 [6.608121e-08] 
Layer 'fc7' weights[0]: 7.600152e-03 [1.541001e-07] 
Layer 'fc7' biases: 9.998707e-01 [2.372103e-07] 
Layer 'fc8' weights[0]: 4.397950e-03 [1.950484e-05] 
Layer 'fc8' biases: 1.055593e-02 [3.863886e-05] 
Train error last 800 batches: 0.655687
-------------------------------------------------------
Not saving because 0.463852 > 0.299667 (9.300: -1.18%)
======================================================= (2.400 sec)
12.161... logprob:  0.568930, 0.273437 (1.406 sec)
12.162... logprob:  0.753133, 0.291667 (1.409 sec)
12.163... logprob:  0.735298, 0.335938 (1.427 sec)
12.164... logprob:  0.767399, 0.317708 (1.421 sec)
12.165... logprob:  0.667456, 0.300781 (1.417 sec)
12.166... logprob:  0.650027, 0.266927 (1.449 sec)
12.167... logprob:  0.592659, 0.268229 (1.425 sec)
12.168... logprob:  0.642330, 0.285156 (1.437 sec)
12.169... logprob:  0.626584, 0.244792 (1.456 sec)
12.170... logprob:  0.694624, 0.303385 (1.395 sec)
12.171... logprob:  0.760198, 0.312500 (1.413 sec)
12.172... logprob:  0.606318, 0.240885 (1.408 sec)
12.173... logprob:  0.667297, 0.303385 (1.419 sec)
12.174... logprob:  0.707993, 0.313802 (1.409 sec)
12.175... logprob:  0.678792, 0.308594 (1.459 sec)
12.176... logprob:  0.675352, 0.294271 (1.415 sec)
12.177... logprob:  0.522508, 0.234375 (1.427 sec)
12.178... logprob:  0.536975, 0.263021 (1.452 sec)
12.179... logprob:  0.561975, 0.242188 (1.404 sec)
12.180... logprob:  0.747994, 0.299479 (1.417 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.398105, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.096400e-03 [2.563067e-07] 
Layer 'conv1' biases: 1.635135e-06 [5.450573e-10] 
Layer 'conv2' weights[0]: 5.087047e-03 [2.555340e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.002768e-09] 
Layer 'conv3' weights[0]: 5.085722e-03 [2.562358e-07] 
Layer 'conv3' biases: 2.708353e-05 [1.961430e-08] 
Layer 'conv4' weights[0]: 5.106689e-03 [2.583912e-07] 
Layer 'conv4' biases: 1.000013e+00 [2.614028e-07] 
Layer 'conv5' weights[0]: 5.180015e-03 [2.316305e-06] 
Layer 'conv5' biases: 9.990843e-01 [2.542419e-06] 
Layer 'fc6' weights[0]: 7.246430e-03 [5.857187e-08] 
Layer 'fc6' biases: 9.999954e-01 [5.593627e-08] 
Layer 'fc7' weights[0]: 7.599399e-03 [1.336114e-07] 
Layer 'fc7' biases: 9.998696e-01 [1.638754e-07] 
Layer 'fc8' weights[0]: 4.354548e-03 [1.591410e-05] 
Layer 'fc8' biases: 1.027442e-02 [2.654665e-05] 
Train error last 800 batches: 0.655770
-------------------------------------------------------
Not saving because 0.398105 > 0.299667 (9.300: -1.18%)
======================================================= (2.378 sec)
12.181... logprob:  0.663129, 0.282552 (1.420 sec)
12.182... logprob:  0.616200, 0.265625 (1.418 sec)
12.183... logprob:  0.696002, 0.330729 (1.426 sec)
12.184... logprob:  0.767458, 0.338542 (1.418 sec)
12.185... logprob:  0.521540, 0.221354 (1.388 sec)
12.186... logprob:  0.669012, 0.334635 (1.392 sec)
12.187... logprob:  0.699703, 0.320312 (1.397 sec)
12.188... logprob:  0.747841, 0.342448 (1.395 sec)
12.189... logprob:  0.623865, 0.266927 (1.380 sec)
12.190... logprob:  0.626236, 0.260417 (1.433 sec)
12.191... logprob:  0.678585, 0.291667 (1.402 sec)
12.192... logprob:  0.682788, 0.295573 (1.416 sec)
12.193... logprob:  0.536164, 0.238281 (1.408 sec)
12.194... logprob:  0.592811, 0.265625 (1.414 sec)
12.195... logprob:  0.547032, 0.255208 (1.399 sec)
12.196... logprob:  0.604477, 0.285156 (1.383 sec)
12.197... logprob:  0.682487, 0.305990 (1.393 sec)
12.198... logprob:  0.589403, 0.281250 (1.399 sec)
12.199... logprob:  0.678422, 0.264323 (1.380 sec)
12.200... logprob:  0.656566, 0.278646 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.501470, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.091299e-03 [2.560978e-07] 
Layer 'conv1' biases: 1.639476e-06 [6.087420e-10] 
Layer 'conv2' weights[0]: 5.081972e-03 [2.553002e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.302221e-09] 
Layer 'conv3' weights[0]: 5.080601e-03 [2.563156e-07] 
Layer 'conv3' biases: 2.713573e-05 [2.230012e-08] 
Layer 'conv4' weights[0]: 5.101602e-03 [2.589572e-07] 
Layer 'conv4' biases: 1.000014e+00 [2.971093e-07] 
Layer 'conv5' weights[0]: 5.175081e-03 [2.593510e-06] 
Layer 'conv5' biases: 9.990703e-01 [2.824561e-06] 
Layer 'fc6' weights[0]: 7.245675e-03 [6.105549e-08] 
Layer 'fc6' biases: 9.999956e-01 [5.984793e-08] 
Layer 'fc7' weights[0]: 7.598673e-03 [1.394466e-07] 
Layer 'fc7' biases: 9.998703e-01 [1.850778e-07] 
Layer 'fc8' weights[0]: 4.401308e-03 [1.713903e-05] 
Layer 'fc8' biases: 1.062973e-02 [3.129672e-05] 
Train error last 800 batches: 0.655996
-------------------------------------------------------
Not saving because 0.501470 > 0.299667 (9.300: -1.18%)
======================================================= (2.360 sec)
12.201... logprob:  0.630707, 0.274740 (1.411 sec)
12.202... logprob:  0.781755, 0.334635 (1.404 sec)
12.203... logprob:  0.619221, 0.283854 (1.443 sec)
12.204... logprob:  0.675831, 0.268229 (1.388 sec)
12.205... logprob:  0.492197, 0.233073 (1.395 sec)
12.206... logprob:  0.594714, 0.292969 (1.406 sec)
12.207... logprob:  0.545569, 0.235677 (1.390 sec)
12.208... logprob:  0.704234, 0.289062 (1.390 sec)
12.209... logprob:  0.610588, 0.242187 (1.422 sec)
12.210... logprob:  0.757180, 0.326823 (1.415 sec)
12.211... logprob:  0.670755, 0.291667 (1.412 sec)
12.212... logprob:  0.729040, 0.332031 (1.407 sec)
12.213... logprob:  0.657286, 0.290365 (1.451 sec)
12.214... logprob:  0.723294, 0.328125 (1.422 sec)
12.215... logprob:  0.564621, 0.270833 (1.417 sec)
12.216... logprob:  0.711369, 0.294271 (1.459 sec)
12.217... logprob:  0.602633, 0.273437 (1.394 sec)
12.218... logprob:  0.723814, 0.321615 (1.419 sec)
12.219... logprob:  0.699030, 0.300781 (1.405 sec)
12.220... logprob:  0.700754, 0.317708 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.359591, 0.062500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.086224e-03 [2.557633e-07] 
Layer 'conv1' biases: 1.641479e-06 [5.751756e-10] 
Layer 'conv2' weights[0]: 5.076882e-03 [2.549313e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.608833e-09] 
Layer 'conv3' weights[0]: 5.075554e-03 [2.560638e-07] 
Layer 'conv3' biases: 2.715650e-05 [2.202630e-08] 
Layer 'conv4' weights[0]: 5.096524e-03 [2.587033e-07] 
Layer 'conv4' biases: 1.000014e+00 [3.303136e-07] 
Layer 'conv5' weights[0]: 5.170226e-03 [2.802508e-06] 
Layer 'conv5' biases: 9.990775e-01 [3.011416e-06] 
Layer 'fc6' weights[0]: 7.244908e-03 [6.583067e-08] 
Layer 'fc6' biases: 9.999956e-01 [6.671014e-08] 
Layer 'fc7' weights[0]: 7.597916e-03 [1.530840e-07] 
Layer 'fc7' biases: 9.998693e-01 [2.233625e-07] 
Layer 'fc8' weights[0]: 4.380956e-03 [1.897659e-05] 
Layer 'fc8' biases: 1.047193e-02 [3.605503e-05] 
Train error last 800 batches: 0.655683
-------------------------------------------------------
Not saving because 0.359591 > 0.299667 (9.300: -1.18%)
======================================================= (2.402 sec)
12.221... logprob:  0.606630, 0.278646 (1.408 sec)
12.222... logprob:  0.617333, 0.268229 (1.459 sec)
12.223... logprob:  0.727074, 0.299479 (1.426 sec)
12.224... logprob:  0.655155, 0.281250 (1.434 sec)
12.225... logprob:  0.724055, 0.298177 (1.449 sec)
12.226... logprob:  0.651084, 0.278646 (1.420 sec)
12.227... logprob:  0.692128, 0.282552 (1.410 sec)
12.228... logprob:  0.623145, 0.259115 (1.413 sec)
12.229... logprob:  0.697182, 0.298177 (1.413 sec)
12.230... logprob:  0.713153, 0.326823 (1.432 sec)
12.231... logprob:  0.702975, 0.298177 (1.402 sec)
12.232... logprob:  0.737161, 0.312500 (1.459 sec)
12.233... logprob:  0.681193, 0.265625 (1.417 sec)
12.234... logprob:  0.752150, 0.300781 (1.422 sec)
12.235... logprob:  0.747550, 0.298177 (1.468 sec)
12.236... logprob:  0.678568, 0.263021 (1.392 sec)
12.237... logprob:  0.620215, 0.291667 (1.418 sec)
12.238... logprob:  0.598176, 0.243490 (1.407 sec)
12.239... logprob:  0.767347, 0.308594 (1.416 sec)
12.240... logprob:  0.698057, 0.302083 (1.394 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.451982, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.081172e-03 [2.551772e-07] 
Layer 'conv1' biases: 1.641493e-06 [4.948412e-10] 
Layer 'conv2' weights[0]: 5.071794e-03 [2.545822e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.735077e-09] 
Layer 'conv3' weights[0]: 5.070495e-03 [2.559638e-07] 
Layer 'conv3' biases: 2.721209e-05 [2.206689e-08] 
Layer 'conv4' weights[0]: 5.091404e-03 [2.583829e-07] 
Layer 'conv4' biases: 1.000014e+00 [3.218195e-07] 
Layer 'conv5' weights[0]: 5.165497e-03 [2.535158e-06] 
Layer 'conv5' biases: 9.990934e-01 [2.684135e-06] 
Layer 'fc6' weights[0]: 7.244159e-03 [6.477429e-08] 
Layer 'fc6' biases: 9.999955e-01 [6.506335e-08] 
Layer 'fc7' weights[0]: 7.597152e-03 [1.524168e-07] 
Layer 'fc7' biases: 9.998677e-01 [2.031819e-07] 
Layer 'fc8' weights[0]: 4.306390e-03 [2.028152e-05] 
Layer 'fc8' biases: 9.901234e-03 [3.750562e-05] 
Train error last 800 batches: 0.656376
-------------------------------------------------------
Not saving because 0.451982 > 0.299667 (9.300: -1.18%)
======================================================= (2.357 sec)
12.241... logprob:  0.724520, 0.300781 (1.465 sec)
12.242... logprob:  0.551005, 0.235677 (1.431 sec)
12.243... logprob:  0.632167, 0.260417 (1.425 sec)
12.244... logprob:  0.554678, 0.256510 (1.441 sec)
12.245... logprob:  0.771494, 0.332031 (1.420 sec)
12.246... logprob:  0.591227, 0.256510 (1.412 sec)
12.247... logprob:  0.588258, 0.264323 (1.411 sec)
12.248... logprob:  0.505929, 0.223958 (1.420 sec)
12.249... logprob:  0.730263, 0.311198 (1.418 sec)
12.250... logprob:  0.855653, 0.375000 (1.404 sec)
12.251... logprob:  0.584876, 0.274740 (1.459 sec)
12.252... logprob:  0.589199, 0.279948 (1.416 sec)
12.253... logprob:  0.622522, 0.252604 (1.415 sec)
12.254... logprob:  0.689331, 0.317708 (1.469 sec)
12.255... logprob:  0.574629, 0.250000 (1.402 sec)
12.256... logprob:  0.625782, 0.278646 (1.415 sec)
12.257... logprob:  0.546843, 0.240885 (1.409 sec)
12.258... logprob:  0.679748, 0.265625 (1.412 sec)
12.259... logprob:  0.669165, 0.292969 (1.392 sec)
12.260... logprob:  0.526541, 0.247396 (1.453 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.446833, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.076085e-03 [2.560867e-07] 
Layer 'conv1' biases: 1.641138e-06 [5.813938e-10] 
Layer 'conv2' weights[0]: 5.066729e-03 [2.547394e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.782911e-09] 
Layer 'conv3' weights[0]: 5.065382e-03 [2.559360e-07] 
Layer 'conv3' biases: 2.734499e-05 [2.158298e-08] 
Layer 'conv4' weights[0]: 5.086338e-03 [2.589292e-07] 
Layer 'conv4' biases: 1.000015e+00 [3.512897e-07] 
Layer 'conv5' weights[0]: 5.161446e-03 [2.914802e-06] 
Layer 'conv5' biases: 9.990684e-01 [3.060853e-06] 
Layer 'fc6' weights[0]: 7.243389e-03 [6.615554e-08] 
Layer 'fc6' biases: 9.999955e-01 [6.719149e-08] 
Layer 'fc7' weights[0]: 7.596360e-03 [1.579642e-07] 
Layer 'fc7' biases: 9.998690e-01 [2.500458e-07] 
Layer 'fc8' weights[0]: 4.393165e-03 [2.071636e-05] 
Layer 'fc8' biases: 1.066683e-02 [4.231354e-05] 
Train error last 800 batches: 0.656577
-------------------------------------------------------
Not saving because 0.446833 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
12.261... logprob:  0.620371, 0.261719 (1.434 sec)
12.262... logprob:  0.733026, 0.294271 (1.438 sec)
12.263... logprob:  0.668691, 0.283854 (1.447 sec)
12.264... logprob:  0.603128, 0.278646 (1.418 sec)
12.265... logprob:  0.651764, 0.268229 (1.417 sec)
12.266... logprob:  0.651764, 0.282552 (1.414 sec)
12.267... logprob:  0.680173, 0.322917 (1.413 sec)
12.268... logprob:  0.648226, 0.302083 (1.420 sec)
12.269... logprob:  0.801904, 0.334635 (1.398 sec)
12.270... logprob:  0.793869, 0.335938 (1.455 sec)
12.271... logprob:  0.600564, 0.231771 (1.429 sec)
12.272... logprob:  0.573626, 0.264323 (1.413 sec)
12.273... logprob:  0.818126, 0.334635 (1.466 sec)
12.274... logprob:  0.825168, 0.381510 (1.403 sec)
12.275... logprob:  0.667969, 0.286458 (1.422 sec)
12.276... logprob:  0.632375, 0.255208 (1.411 sec)
12.277... logprob:  0.627629, 0.252604 (1.425 sec)
12.278... logprob:  0.556877, 0.255208 (1.420 sec)
12.279... logprob:  0.625031, 0.285156 (1.458 sec)
12.280... logprob:  0.473947, 0.213542 (1.399 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.482409, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.071028e-03 [2.549171e-07] 
Layer 'conv1' biases: 1.644968e-06 [5.261368e-10] 
Layer 'conv2' weights[0]: 5.061702e-03 [2.539870e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.378616e-09] 
Layer 'conv3' weights[0]: 5.060325e-03 [2.549440e-07] 
Layer 'conv3' biases: 2.735276e-05 [1.822649e-08] 
Layer 'conv4' weights[0]: 5.081238e-03 [2.573849e-07] 
Layer 'conv4' biases: 1.000014e+00 [2.846649e-07] 
Layer 'conv5' weights[0]: 5.155872e-03 [2.270649e-06] 
Layer 'conv5' biases: 9.990939e-01 [2.398919e-06] 
Layer 'fc6' weights[0]: 7.242638e-03 [5.830968e-08] 
Layer 'fc6' biases: 9.999955e-01 [5.501679e-08] 
Layer 'fc7' weights[0]: 7.595635e-03 [1.307677e-07] 
Layer 'fc7' biases: 9.998668e-01 [1.686897e-07] 
Layer 'fc8' weights[0]: 4.325999e-03 [1.523308e-05] 
Layer 'fc8' biases: 1.015894e-02 [2.510837e-05] 
Train error last 800 batches: 0.656763
-------------------------------------------------------
Not saving because 0.482409 > 0.299667 (9.300: -1.18%)
======================================================= (2.362 sec)
12.281... logprob:  0.683236, 0.304688 (1.431 sec)
12.282... logprob:  0.702391, 0.328125 (1.420 sec)
12.283... logprob:  0.618478, 0.295573 (1.416 sec)
12.284... logprob:  0.703439, 0.311198 (1.404 sec)
12.285... logprob:  0.585016, 0.250000 (1.439 sec)
12.286... logprob:  0.713258, 0.315104 (1.429 sec)
12.287... logprob:  0.606024, 0.238281 (1.427 sec)
12.288... logprob:  0.557627, 0.251302 (1.438 sec)
12.289... logprob:  0.729026, 0.341146 (1.442 sec)
12.290... logprob:  0.771289, 0.338542 (1.402 sec)
12.291... logprob:  0.572908, 0.247396 (1.418 sec)
12.292... logprob:  0.707095, 0.299479 (1.420 sec)
12.293... logprob:  0.640501, 0.279948 (1.423 sec)
12.294... logprob:  0.490214, 0.221354 (1.398 sec)
12.295... logprob:  0.577592, 0.226562 (1.474 sec)
12.296... logprob:  0.635292, 0.264323 (1.419 sec)
12.297... logprob:  0.646247, 0.287760 (1.414 sec)
12.298... logprob:  0.776335, 0.342448 (1.460 sec)
12.299... logprob:  0.517227, 0.210937 (1.432 sec)
12.300... logprob:  0.613281, 0.252604 (1.423 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.502743, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.065960e-03 [2.548612e-07] 
Layer 'conv1' biases: 1.648392e-06 [5.207557e-10] 
Layer 'conv2' weights[0]: 5.056624e-03 [2.537807e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.943266e-09] 
Layer 'conv3' weights[0]: 5.055294e-03 [2.545657e-07] 
Layer 'conv3' biases: 2.739166e-05 [1.847123e-08] 
Layer 'conv4' weights[0]: 5.076168e-03 [2.569846e-07] 
Layer 'conv4' biases: 1.000012e+00 [2.751631e-07] 
Layer 'conv5' weights[0]: 5.150406e-03 [2.618000e-06] 
Layer 'conv5' biases: 9.990777e-01 [2.800303e-06] 
Layer 'fc6' weights[0]: 7.241873e-03 [6.002988e-08] 
Layer 'fc6' biases: 9.999954e-01 [5.788282e-08] 
Layer 'fc7' weights[0]: 7.594856e-03 [1.345837e-07] 
Layer 'fc7' biases: 9.998683e-01 [1.645976e-07] 
Layer 'fc8' weights[0]: 4.397436e-03 [1.520161e-05] 
Layer 'fc8' biases: 1.070304e-02 [2.340152e-05] 
Train error last 800 batches: 0.657296
-------------------------------------------------------
Not saving because 0.502743 > 0.299667 (9.300: -1.18%)
======================================================= (2.381 sec)
12.301... logprob:  0.653064, 0.269531 (1.422 sec)
12.302... logprob:  0.752127, 0.308594 (1.420 sec)
12.303... logprob:  0.609005, 0.277344 (1.404 sec)
12.304... logprob:  0.599427, 0.263021 (1.436 sec)
12.305... logprob:  0.746865, 0.346354 (1.437 sec)
12.306... logprob:  0.574727, 0.244792 (1.429 sec)
12.307... logprob:  0.607171, 0.274740 (1.434 sec)
12.308... logprob:  0.623596, 0.266927 (1.447 sec)
12.309... logprob:  0.678313, 0.298177 (1.411 sec)
12.310... logprob:  0.702708, 0.283854 (1.420 sec)
12.311... logprob:  0.738776, 0.308594 (1.417 sec)
12.312... logprob:  0.709732, 0.305990 (1.424 sec)
12.313... logprob:  0.652788, 0.277344 (1.418 sec)
12.314... logprob:  0.634523, 0.273437 (1.458 sec)
12.315... logprob:  0.557917, 0.234375 (1.429 sec)
12.316... logprob:  0.717371, 0.312500 (1.417 sec)
12.317... logprob:  0.573753, 0.259115 (1.468 sec)
12.318... logprob:  0.706426, 0.303385 (1.408 sec)
12.319... logprob:  0.641300, 0.274740 (1.416 sec)
12.320... logprob:  0.657771, 0.287760 (1.419 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.477040, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.060887e-03 [2.545216e-07] 
Layer 'conv1' biases: 1.648685e-06 [3.821223e-10] 
Layer 'conv2' weights[0]: 5.051593e-03 [2.534425e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.394670e-09] 
Layer 'conv3' weights[0]: 5.050239e-03 [2.542680e-07] 
Layer 'conv3' biases: 2.744353e-05 [1.929511e-08] 
Layer 'conv4' weights[0]: 5.071130e-03 [2.565923e-07] 
Layer 'conv4' biases: 1.000013e+00 [2.686830e-07] 
Layer 'conv5' weights[0]: 5.145866e-03 [2.266357e-06] 
Layer 'conv5' biases: 9.990842e-01 [2.407012e-06] 
Layer 'fc6' weights[0]: 7.241143e-03 [5.788360e-08] 
Layer 'fc6' biases: 9.999954e-01 [5.448003e-08] 
Layer 'fc7' weights[0]: 7.594099e-03 [1.336043e-07] 
Layer 'fc7' biases: 9.998670e-01 [1.580120e-07] 
Layer 'fc8' weights[0]: 4.346287e-03 [1.457148e-05] 
Layer 'fc8' biases: 1.043250e-02 [1.374131e-05] 
Train error last 800 batches: 0.657302
-------------------------------------------------------
Not saving because 0.477040 > 0.299667 (9.300: -1.18%)
======================================================= (2.371 sec)
12.321... logprob:  0.591968, 0.276042 (1.423 sec)
12.322... logprob:  0.619415, 0.264323 (1.424 sec)
12.323... logprob:  0.679267, 0.289062 (1.475 sec)
12.324... logprob:  0.709249, 0.322917 (1.421 sec)
12.325... logprob:  0.636695, 0.273437 (1.435 sec)
12.326... logprob:  0.658801, 0.269531 (1.464 sec)
12.327... logprob:  0.728197, 0.307292 (1.414 sec)
12.328... logprob:  0.706388, 0.266927 (1.431 sec)
12.329... logprob:  0.656676, 0.300781 (1.423 sec)
12.330... logprob:  0.637748, 0.299479 (1.419 sec)
12.331... logprob:  0.612498, 0.260417 (1.413 sec)
12.332... logprob:  0.679521, 0.279948 (1.442 sec)
12.333... logprob:  0.610725, 0.270833 (1.437 sec)
12.334... logprob:  0.690167, 0.277344 (1.432 sec)
12.335... logprob:  0.671613, 0.307292 (1.440 sec)
12.336... logprob:  0.622952, 0.282552 (1.457 sec)
12.337... logprob:  0.777724, 0.330729 (1.412 sec)
12.338... logprob:  0.696394, 0.304687 (1.415 sec)
12.339... logprob:  0.639676, 0.283854 (1.417 sec)
12.340... logprob:  0.583916, 0.252604 (1.425 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.522494, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.055848e-03 [2.545412e-07] 
Layer 'conv1' biases: 1.651052e-06 [4.603404e-10] 
Layer 'conv2' weights[0]: 5.046558e-03 [2.532820e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.395502e-09] 
Layer 'conv3' weights[0]: 5.045192e-03 [2.541328e-07] 
Layer 'conv3' biases: 2.742766e-05 [1.910156e-08] 
Layer 'conv4' weights[0]: 5.066051e-03 [2.560514e-07] 
Layer 'conv4' biases: 1.000012e+00 [2.406518e-07] 
Layer 'conv5' weights[0]: 5.140566e-03 [2.160858e-06] 
Layer 'conv5' biases: 9.990858e-01 [2.208187e-06] 
Layer 'fc6' weights[0]: 7.240403e-03 [5.964708e-08] 
Layer 'fc6' biases: 9.999954e-01 [5.732016e-08] 
Layer 'fc7' weights[0]: 7.593310e-03 [1.349287e-07] 
Layer 'fc7' biases: 9.998664e-01 [1.617963e-07] 
Layer 'fc8' weights[0]: 4.345175e-03 [1.533165e-05] 
Layer 'fc8' biases: 1.040435e-02 [2.323632e-05] 
Train error last 800 batches: 0.657017
-------------------------------------------------------
Not saving because 0.522494 > 0.299667 (9.300: -1.18%)
======================================================= (2.445 sec)
12.341... logprob:  0.763750, 0.312500 (1.426 sec)
12.342... logprob:  0.672521, 0.313802 (1.467 sec)
12.343... logprob:  0.657697, 0.277344 (1.440 sec)
12.344... logprob:  0.688527, 0.299479 (1.480 sec)
12.345... logprob:  0.800182, 0.354167 (1.437 sec)
12.346... logprob:  0.711484, 0.317708 (1.437 sec)
12.347... logprob:  0.595512, 0.255208 (1.481 sec)
12.348... logprob:  0.682667, 0.295573 (1.440 sec)
12.349... logprob:  0.690642, 0.298177 (1.433 sec)
12.350... logprob:  0.584381, 0.253906 (1.434 sec)
12.351... logprob:  0.660747, 0.276042 (1.423 sec)
12.352... logprob:  0.669119, 0.317708 (1.428 sec)
12.353... logprob:  0.668480, 0.300781 (1.481 sec)
12.354... logprob:  0.786157, 0.351562 (1.423 sec)
12.355... logprob:  0.623373, 0.292969 (1.444 sec)
12.356... logprob:  0.790893, 0.317708 (1.479 sec)
12.357... logprob:  0.634634, 0.291667 (1.429 sec)
12.358... logprob:  0.562973, 0.231771 (1.436 sec)
12.359... logprob:  0.727237, 0.313802 (1.440 sec)
12.360... logprob:  0.633605, 0.287760 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.409143, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.050763e-03 [2.536904e-07] 
Layer 'conv1' biases: 1.654356e-06 [5.315823e-10] 
Layer 'conv2' weights[0]: 5.041468e-03 [2.530287e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.973554e-09] 
Layer 'conv3' weights[0]: 5.040172e-03 [2.539844e-07] 
Layer 'conv3' biases: 2.747749e-05 [1.937292e-08] 
Layer 'conv4' weights[0]: 5.061013e-03 [2.564894e-07] 
Layer 'conv4' biases: 1.000011e+00 [2.791199e-07] 
Layer 'conv5' weights[0]: 5.135323e-03 [2.428584e-06] 
Layer 'conv5' biases: 9.990857e-01 [2.564270e-06] 
Layer 'fc6' weights[0]: 7.239656e-03 [5.951105e-08] 
Layer 'fc6' biases: 9.999955e-01 [5.709149e-08] 
Layer 'fc7' weights[0]: 7.592565e-03 [1.351146e-07] 
Layer 'fc7' biases: 9.998662e-01 [1.633539e-07] 
Layer 'fc8' weights[0]: 4.338730e-03 [1.506521e-05] 
Layer 'fc8' biases: 1.042525e-02 [2.005519e-05] 
Train error last 800 batches: 0.657302
-------------------------------------------------------
Not saving because 0.409143 > 0.299667 (9.300: -1.18%)
======================================================= (2.369 sec)
12.361... logprob:  0.636737, 0.273438 (1.439 sec)
12.362... logprob:  0.558175, 0.264323 (1.479 sec)
12.363... logprob:  0.794890, 0.360677 (1.438 sec)
12.364... logprob:  0.623078, 0.247396 (1.450 sec)
12.365... logprob:  0.738569, 0.312500 (1.467 sec)
12.366... logprob:  0.616238, 0.278646 (1.444 sec)
12.367... logprob:  0.562526, 0.227864 (1.431 sec)
12.368... logprob:  0.748718, 0.332031 (1.425 sec)
12.369... logprob:  0.633987, 0.279948 (1.427 sec)
12.370... logprob:  0.583732, 0.238281 (1.430 sec)
12.371... logprob:  0.609603, 0.270833 (1.453 sec)
12.372... logprob:  0.691603, 0.308594 (1.451 sec)
12.373... logprob:  0.631205, 0.299479 (1.451 sec)
12.374... logprob:  0.694524, 0.289062 (1.441 sec)
12.375... logprob:  0.691765, 0.325521 (1.460 sec)
12.376... logprob:  0.562263, 0.259115 (1.432 sec)
12.377... logprob:  0.596340, 0.282552 (1.420 sec)
12.378... logprob:  0.682751, 0.290365 (1.433 sec)
12.379... logprob:  0.669929, 0.279948 (1.429 sec)
12.380... logprob:  0.777843, 0.335937 (1.436 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.500605, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.045744e-03 [2.535794e-07] 
Layer 'conv1' biases: 1.656320e-06 [5.124051e-10] 
Layer 'conv2' weights[0]: 5.036465e-03 [2.530616e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.646467e-09] 
Layer 'conv3' weights[0]: 5.035133e-03 [2.539332e-07] 
Layer 'conv3' biases: 2.751628e-05 [1.938485e-08] 
Layer 'conv4' weights[0]: 5.055914e-03 [2.561393e-07] 
Layer 'conv4' biases: 1.000011e+00 [2.713196e-07] 
Layer 'conv5' weights[0]: 5.130261e-03 [2.288714e-06] 
Layer 'conv5' biases: 9.990762e-01 [2.418319e-06] 
Layer 'fc6' weights[0]: 7.238868e-03 [6.041010e-08] 
Layer 'fc6' biases: 9.999954e-01 [5.871374e-08] 
Layer 'fc7' weights[0]: 7.591806e-03 [1.385602e-07] 
Layer 'fc7' biases: 9.998670e-01 [1.742393e-07] 
Layer 'fc8' weights[0]: 4.380114e-03 [1.660415e-05] 
Layer 'fc8' biases: 1.074979e-02 [2.650664e-05] 
Train error last 800 batches: 0.657297
-------------------------------------------------------
Not saving because 0.500605 > 0.299667 (9.300: -1.18%)
======================================================= (2.379 sec)
12.381... logprob:  0.732747, 0.333333 (1.469 sec)
12.382... logprob:  0.691629, 0.307292 (1.451 sec)
12.383... logprob:  0.558095, 0.250000 (1.442 sec)
12.384... logprob:  0.785883, 0.308594 (1.480 sec)
12.385... logprob:  0.729513, 0.334635 (1.430 sec)
12.386... logprob:  0.760555, 0.321615 (1.427 sec)
12.387... logprob:  0.706316, 0.332031 (1.432 sec)
12.388... logprob:  0.844502, 0.345052 (1.428 sec)
12.389... logprob:  0.604792, 0.274740 (1.430 sec)
12.390... logprob:  0.602028, 0.276042 (1.479 sec)
12.391... logprob:  0.606892, 0.252604 (1.441 sec)
12.392... logprob:  0.650866, 0.270833 (1.431 sec)
12.393... logprob:  0.639501, 0.290364 (1.480 sec)
12.394... logprob:  0.678290, 0.290364 (1.435 sec)
12.395... logprob:  0.631828, 0.248698 (1.428 sec)
12.396... logprob:  0.523041, 0.235677 (1.434 sec)
12.397... logprob:  0.726611, 0.304687 (1.430 sec)
12.398... logprob:  0.695834, 0.319010 (1.424 sec)
12.399... logprob:  0.558730, 0.257812 (1.482 sec)
12.400... logprob:  0.643899, 0.281250 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.470317, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.040699e-03 [2.538026e-07] 
Layer 'conv1' biases: 1.657694e-06 [4.629087e-10] 
Layer 'conv2' weights[0]: 5.031418e-03 [2.528116e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.124816e-09] 
Layer 'conv3' weights[0]: 5.030102e-03 [2.538606e-07] 
Layer 'conv3' biases: 2.750897e-05 [2.020862e-08] 
Layer 'conv4' weights[0]: 5.050857e-03 [2.563978e-07] 
Layer 'conv4' biases: 1.000011e+00 [2.889222e-07] 
Layer 'conv5' weights[0]: 5.125450e-03 [2.533412e-06] 
Layer 'conv5' biases: 9.990870e-01 [2.676023e-06] 
Layer 'fc6' weights[0]: 7.238139e-03 [6.371208e-08] 
Layer 'fc6' biases: 9.999953e-01 [6.320104e-08] 
Layer 'fc7' weights[0]: 7.591052e-03 [1.468545e-07] 
Layer 'fc7' biases: 9.998661e-01 [2.104563e-07] 
Layer 'fc8' weights[0]: 4.346308e-03 [1.823847e-05] 
Layer 'fc8' biases: 1.049640e-02 [3.262781e-05] 
Train error last 800 batches: 0.657652
-------------------------------------------------------
Not saving because 0.470317 > 0.299667 (9.300: -1.18%)
======================================================= (2.397 sec)
12.401... logprob:  0.657085, 0.256510 (1.442 sec)
12.402... logprob:  0.617736, 0.274740 (1.483 sec)
12.403... logprob:  0.648919, 0.283854 (1.430 sec)
12.404... logprob:  0.635243, 0.294271 (1.433 sec)
12.405... logprob:  0.734947, 0.292969 (1.434 sec)
12.406... logprob:  0.594401, 0.273438 (1.427 sec)
12.407... logprob:  0.689915, 0.305990 (1.432 sec)
12.408... logprob:  0.576518, 0.268229 (1.474 sec)
12.409... logprob:  0.600823, 0.278646 (1.435 sec)
12.410... logprob:  0.819915, 0.322917 (1.445 sec)
12.411... logprob:  0.564413, 0.259115 (1.477 sec)
12.412... logprob:  0.697007, 0.300781 (1.434 sec)
12.413... logprob:  0.716839, 0.296875 (1.433 sec)
12.414... logprob:  0.745989, 0.332031 (1.433 sec)
12.415... logprob:  0.643550, 0.300781 (1.415 sec)
12.416... logprob:  0.711909, 0.316406 (1.435 sec)
12.417... logprob:  0.595321, 0.272135 (1.463 sec)
12.418... logprob:  0.638095, 0.263021 (1.444 sec)
12.419... logprob:  0.673317, 0.272135 (1.447 sec)
12.420... logprob:  0.614152, 0.285156 (1.450 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.546038, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.035660e-03 [2.535350e-07] 
Layer 'conv1' biases: 1.660600e-06 [5.154313e-10] 
Layer 'conv2' weights[0]: 5.026404e-03 [2.525487e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.173854e-09] 
Layer 'conv3' weights[0]: 5.025072e-03 [2.538009e-07] 
Layer 'conv3' biases: 2.749985e-05 [2.192719e-08] 
Layer 'conv4' weights[0]: 5.045811e-03 [2.559472e-07] 
Layer 'conv4' biases: 1.000010e+00 [2.834342e-07] 
Layer 'conv5' weights[0]: 5.120063e-03 [2.614569e-06] 
Layer 'conv5' biases: 9.990779e-01 [2.795249e-06] 
Layer 'fc6' weights[0]: 7.237383e-03 [5.919025e-08] 
Layer 'fc6' biases: 9.999954e-01 [5.686769e-08] 
Layer 'fc7' weights[0]: 7.590304e-03 [1.369885e-07] 
Layer 'fc7' biases: 9.998659e-01 [1.718189e-07] 
Layer 'fc8' weights[0]: 4.362625e-03 [1.628079e-05] 
Layer 'fc8' biases: 1.062634e-02 [2.688708e-05] 
Train error last 800 batches: 0.657504
-------------------------------------------------------
Not saving because 0.546038 > 0.299667 (9.300: -1.18%)
======================================================= (2.451 sec)
12.421... logprob:  0.623463, 0.298177 (1.463 sec)
12.422... logprob:  0.673371, 0.319010 (1.440 sec)
12.423... logprob:  0.653386, 0.295573 (1.421 sec)
12.424... logprob:  0.599136, 0.265625 (1.427 sec)
12.425... logprob:  0.607218, 0.307292 (1.439 sec)
12.426... logprob:  0.591330, 0.260417 (1.445 sec)
12.427... logprob:  0.755397, 0.359375 (1.457 sec)
12.428... logprob:  0.744466, 0.312500 (1.449 sec)
12.429... logprob:  0.697513, 0.305990 (1.440 sec)
12.430... logprob:  0.557336, 0.236979 (1.471 sec)
12.431... logprob:  0.783708, 0.304688 (1.426 sec)
12.432... logprob:  0.564775, 0.230469 (1.417 sec)
12.433... logprob:  0.620545, 0.287760 (1.431 sec)
12.434... logprob:  0.689853, 0.305989 (1.439 sec)
12.435... logprob:  0.705217, 0.334635 (1.428 sec)
12.436... logprob:  0.614156, 0.276042 (1.470 sec)
12.437... logprob:  0.717473, 0.316406 (1.443 sec)
12.438... logprob:  0.646369, 0.261719 (1.431 sec)
12.439... logprob:  0.572774, 0.247396 (1.488 sec)
12.440... logprob:  0.698627, 0.289062 (1.436 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.424514, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.030632e-03 [2.527065e-07] 
Layer 'conv1' biases: 1.663412e-06 [4.796773e-10] 
Layer 'conv2' weights[0]: 5.021355e-03 [2.519490e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.969989e-09] 
Layer 'conv3' weights[0]: 5.020020e-03 [2.525245e-07] 
Layer 'conv3' biases: 2.752733e-05 [1.709647e-08] 
Layer 'conv4' weights[0]: 5.040792e-03 [2.549385e-07] 
Layer 'conv4' biases: 1.000009e+00 [2.759536e-07] 
Layer 'conv5' weights[0]: 5.114820e-03 [2.470595e-06] 
Layer 'conv5' biases: 9.990705e-01 [2.725137e-06] 
Layer 'fc6' weights[0]: 7.236630e-03 [6.123829e-08] 
Layer 'fc6' biases: 9.999952e-01 [6.022694e-08] 
Layer 'fc7' weights[0]: 7.589565e-03 [1.419018e-07] 
Layer 'fc7' biases: 9.998663e-01 [1.881475e-07] 
Layer 'fc8' weights[0]: 4.372998e-03 [1.704037e-05] 
Layer 'fc8' biases: 1.077008e-02 [3.028860e-05] 
Train error last 800 batches: 0.657441
-------------------------------------------------------
Not saving because 0.424514 > 0.299667 (9.300: -1.18%)
======================================================= (2.369 sec)
12.441... logprob:  0.734612, 0.313802 (1.436 sec)
12.442... logprob:  0.584068, 0.270833 (1.437 sec)
12.443... logprob:  0.606186, 0.298177 (1.433 sec)
12.444... logprob:  0.582919, 0.247396 (1.434 sec)
12.445... logprob:  0.640984, 0.287760 (1.478 sec)
12.446... logprob:  0.655572, 0.266927 (1.439 sec)
12.447... logprob:  0.716070, 0.304687 (1.437 sec)
12.448... logprob:  0.641015, 0.279948 (1.477 sec)
12.449... logprob:  0.652853, 0.283854 (1.427 sec)
12.450... logprob:  0.528957, 0.253906 (1.427 sec)
12.451... logprob:  0.613766, 0.265625 (1.434 sec)
12.452... logprob:  0.677663, 0.263021 (1.425 sec)
12.453... logprob:  0.659338, 0.307292 (1.424 sec)
12.454... logprob:  0.673410, 0.287760 (1.481 sec)
12.455... logprob:  0.652895, 0.321615 (1.428 sec)
12.456... logprob:  0.714061, 0.311198 (1.443 sec)
12.457... logprob:  0.545799, 0.251302 (1.472 sec)
12.458... logprob:  0.659541, 0.298177 (1.429 sec)
12.459... logprob:  0.741608, 0.308594 (1.430 sec)
12.460... logprob:  0.539659, 0.242187 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.369454, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.025612e-03 [2.528459e-07] 
Layer 'conv1' biases: 1.665330e-06 [4.710610e-10] 
Layer 'conv2' weights[0]: 5.016355e-03 [2.517015e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.489843e-09] 
Layer 'conv3' weights[0]: 5.015021e-03 [2.526938e-07] 
Layer 'conv3' biases: 2.751501e-05 [2.018692e-08] 
Layer 'conv4' weights[0]: 5.035746e-03 [2.547352e-07] 
Layer 'conv4' biases: 1.000010e+00 [2.973675e-07] 
Layer 'conv5' weights[0]: 5.110382e-03 [2.449715e-06] 
Layer 'conv5' biases: 9.990680e-01 [2.656085e-06] 
Layer 'fc6' weights[0]: 7.235871e-03 [5.858684e-08] 
Layer 'fc6' biases: 9.999951e-01 [5.632236e-08] 
Layer 'fc7' weights[0]: 7.588779e-03 [1.332861e-07] 
Layer 'fc7' biases: 9.998667e-01 [1.694744e-07] 
Layer 'fc8' weights[0]: 4.391266e-03 [1.702958e-05] 
Layer 'fc8' biases: 1.094812e-02 [3.030718e-05] 
Train error last 800 batches: 0.657751
-------------------------------------------------------
Not saving because 0.369454 > 0.299667 (9.300: -1.18%)
======================================================= (2.367 sec)
12.461... logprob:  0.661578, 0.289062 (1.428 sec)
12.462... logprob:  0.704646, 0.291667 (1.436 sec)
12.463... logprob:  0.709183, 0.298177 (1.469 sec)
12.464... logprob:  0.707125, 0.317708 (1.442 sec)
12.465... logprob:  0.685505, 0.307292 (1.452 sec)
12.466... logprob:  0.557559, 0.256510 (1.456 sec)
12.467... logprob:  0.695012, 0.308594 (1.451 sec)
12.468... logprob:  0.682713, 0.305990 (1.435 sec)
12.469... logprob:  0.499556, 0.200521 (1.427 sec)
12.470... logprob:  0.553277, 0.225260 (1.428 sec)
12.471... logprob:  0.822555, 0.367187 (1.431 sec)
12.472... logprob:  0.655339, 0.289062 (1.445 sec)
12.473... logprob:  0.585946, 0.253906 (1.455 sec)
12.474... logprob:  0.661068, 0.281250 (1.451 sec)
12.475... logprob:  0.719631, 0.342448 (1.445 sec)
12.476... logprob:  0.668713, 0.278646 (1.478 sec)
12.477... logprob:  0.631980, 0.264323 (1.431 sec)
12.478... logprob:  0.593962, 0.261719 (1.414 sec)
12.479... logprob:  0.574381, 0.265625 (1.430 sec)
12.480... logprob:  0.772775, 0.328125 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.467311, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.020599e-03 [2.526243e-07] 
Layer 'conv1' biases: 1.666373e-06 [6.374360e-10] 
Layer 'conv2' weights[0]: 5.011338e-03 [2.516663e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.512670e-09] 
Layer 'conv3' weights[0]: 5.010012e-03 [2.531708e-07] 
Layer 'conv3' biases: 2.747158e-05 [2.342581e-08] 
Layer 'conv4' weights[0]: 5.030737e-03 [2.559346e-07] 
Layer 'conv4' biases: 1.000009e+00 [3.108923e-07] 
Layer 'conv5' weights[0]: 5.105324e-03 [2.566400e-06] 
Layer 'conv5' biases: 9.990736e-01 [2.800663e-06] 
Layer 'fc6' weights[0]: 7.235126e-03 [5.912872e-08] 
Layer 'fc6' biases: 9.999951e-01 [5.638861e-08] 
Layer 'fc7' weights[0]: 7.588062e-03 [1.345527e-07] 
Layer 'fc7' biases: 9.998658e-01 [1.587115e-07] 
Layer 'fc8' weights[0]: 4.369523e-03 [1.550618e-05] 
Layer 'fc8' biases: 1.078216e-02 [1.993166e-05] 
Train error last 800 batches: 0.658239
-------------------------------------------------------
Not saving because 0.467311 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
12.481... logprob:  0.750070, 0.303385 (1.437 sec)
12.482... logprob:  0.617369, 0.261719 (1.474 sec)
12.483... logprob:  0.653392, 0.298177 (1.450 sec)
12.484... logprob:  0.652028, 0.292969 (1.435 sec)
12.485... logprob:  0.582004, 0.247396 (1.478 sec)
12.486... logprob:  0.600191, 0.250000 (1.430 sec)
12.487... logprob:  0.745575, 0.307292 (1.423 sec)
12.488... logprob:  0.535899, 0.218750 (1.429 sec)
12.489... logprob:  0.696961, 0.316406 (1.431 sec)
12.490... logprob:  0.604848, 0.265625 (1.426 sec)
12.491... logprob:  0.577561, 0.248698 (1.476 sec)
12.492... logprob:  0.671113, 0.308594 (1.443 sec)
12.493... logprob:  0.676655, 0.283854 (1.435 sec)
12.494... logprob:  0.675181, 0.279948 (1.486 sec)
12.495... logprob:  0.625909, 0.308594 (1.427 sec)
12.496... logprob:  0.736880, 0.317708 (1.422 sec)
12.497... logprob:  0.623538, 0.281250 (1.432 sec)
12.498... logprob:  0.680394, 0.289062 (1.421 sec)
12.499... logprob:  0.673319, 0.283854 (1.429 sec)
12.500... logprob:  0.637857, 0.286458 (1.482 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.489282, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.015580e-03 [2.520916e-07] 
Layer 'conv1' biases: 1.667236e-06 [4.680375e-10] 
Layer 'conv2' weights[0]: 5.006333e-03 [2.513756e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.179141e-09] 
Layer 'conv3' weights[0]: 5.005011e-03 [2.520133e-07] 
Layer 'conv3' biases: 2.748014e-05 [1.797599e-08] 
Layer 'conv4' weights[0]: 5.025684e-03 [2.541383e-07] 
Layer 'conv4' biases: 1.000008e+00 [2.751460e-07] 
Layer 'conv5' weights[0]: 5.100135e-03 [2.397476e-06] 
Layer 'conv5' biases: 9.990721e-01 [2.644781e-06] 
Layer 'fc6' weights[0]: 7.234396e-03 [5.744335e-08] 
Layer 'fc6' biases: 9.999951e-01 [5.418952e-08] 
Layer 'fc7' weights[0]: 7.587315e-03 [1.298785e-07] 
Layer 'fc7' biases: 9.998653e-01 [1.466173e-07] 
Layer 'fc8' weights[0]: 4.376266e-03 [1.398344e-05] 
Layer 'fc8' biases: 1.082985e-02 [4.935285e-06] 
Train error last 800 batches: 0.657434
-------------------------------------------------------
Not saving because 0.489282 > 0.299667 (9.300: -1.18%)
======================================================= (2.375 sec)
12.501... logprob:  0.576698, 0.268229 (1.435 sec)
12.502... logprob:  0.704645, 0.302083 (1.449 sec)
12.503... logprob:  0.650379, 0.268229 (1.486 sec)
12.504... logprob:  0.704394, 0.317708 (1.430 sec)
12.505... logprob:  0.743310, 0.295573 (1.441 sec)
12.506... logprob:  0.668542, 0.273437 (1.438 sec)
12.507... logprob:  0.594058, 0.272135 (1.424 sec)
12.508... logprob:  0.608262, 0.290365 (1.426 sec)
12.509... logprob:  0.617781, 0.295573 (1.471 sec)
12.510... logprob:  0.697965, 0.315104 (1.437 sec)
12.511... logprob:  0.656927, 0.268229 (1.449 sec)
12.512... logprob:  0.668450, 0.308594 (1.461 sec)
12.513... logprob:  0.624150, 0.268229 (1.434 sec)
12.514... logprob:  0.603395, 0.251302 (1.434 sec)
12.515... logprob:  0.627040, 0.269531 (1.424 sec)
12.516... logprob:  0.604986, 0.266927 (1.417 sec)
12.517... logprob:  0.761679, 0.319010 (1.430 sec)
12.518... logprob:  0.708283, 0.300781 (1.454 sec)
12.519... logprob:  0.770052, 0.304687 (1.449 sec)
12.520... logprob:  0.653374, 0.268229 (1.445 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.560023, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.010571e-03 [2.522012e-07] 
Layer 'conv1' biases: 1.669563e-06 [6.076592e-10] 
Layer 'conv2' weights[0]: 5.001320e-03 [2.511044e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.020711e-09] 
Layer 'conv3' weights[0]: 4.999984e-03 [2.529517e-07] 
Layer 'conv3' biases: 2.747972e-05 [2.502768e-08] 
Layer 'conv4' weights[0]: 5.020650e-03 [2.560049e-07] 
Layer 'conv4' biases: 1.000008e+00 [3.861603e-07] 
Layer 'conv5' weights[0]: 5.094821e-03 [3.122578e-06] 
Layer 'conv5' biases: 9.990820e-01 [3.330090e-06] 
Layer 'fc6' weights[0]: 7.233651e-03 [7.068725e-08] 
Layer 'fc6' biases: 9.999950e-01 [7.384823e-08] 
Layer 'fc7' weights[0]: 7.586589e-03 [1.696643e-07] 
Layer 'fc7' biases: 9.998640e-01 [2.634843e-07] 
Layer 'fc8' weights[0]: 4.346543e-03 [2.176040e-05] 
Layer 'fc8' biases: 1.061237e-02 [4.435001e-05] 
Train error last 800 batches: 0.657741
-------------------------------------------------------
Not saving because 0.560023 > 0.299667 (9.300: -1.18%)
======================================================= (2.403 sec)
12.521... logprob:  0.633271, 0.285156 (1.456 sec)
12.522... logprob:  0.825469, 0.355469 (1.465 sec)
12.523... logprob:  0.563770, 0.244792 (1.436 sec)
12.524... logprob:  0.597832, 0.252604 (1.420 sec)
12.525... logprob:  0.717106, 0.309896 (1.431 sec)
12.526... logprob:  0.583607, 0.264323 (1.432 sec)
12.527... logprob:  0.791496, 0.308594 (1.433 sec)
12.528... logprob:  0.666577, 0.300781 (1.463 sec)
12.529... logprob:  0.648313, 0.292969 (1.443 sec)
12.530... logprob:  0.673178, 0.303385 (1.431 sec)
12.531... logprob:  0.654331, 0.285156 (1.476 sec)
12.532... logprob:  0.699309, 0.294271 (1.427 sec)
12.533... logprob:  0.791563, 0.326823 (1.420 sec)
12.534... logprob:  0.591570, 0.234375 (1.426 sec)
12.535... logprob:  0.691774, 0.302083 (1.433 sec)
12.536... logprob:  0.648006, 0.295573 (1.423 sec)
12.537... logprob:  0.704413, 0.296875 (1.471 sec)
12.538... logprob:  0.759948, 0.330729 (1.439 sec)
12.539... logprob:  0.610662, 0.298177 (1.427 sec)
12.540... logprob:  0.706239, 0.300781 (1.479 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.454404, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.005568e-03 [2.514915e-07] 
Layer 'conv1' biases: 1.672125e-06 [4.143142e-10] 
Layer 'conv2' weights[0]: 4.996347e-03 [2.508993e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.699395e-09] 
Layer 'conv3' weights[0]: 4.995014e-03 [2.517531e-07] 
Layer 'conv3' biases: 2.748356e-05 [1.971708e-08] 
Layer 'conv4' weights[0]: 5.015628e-03 [2.538194e-07] 
Layer 'conv4' biases: 1.000009e+00 [2.768621e-07] 
Layer 'conv5' weights[0]: 5.089984e-03 [2.747259e-06] 
Layer 'conv5' biases: 9.990860e-01 [3.008615e-06] 
Layer 'fc6' weights[0]: 7.232909e-03 [6.195991e-08] 
Layer 'fc6' biases: 9.999950e-01 [6.068773e-08] 
Layer 'fc7' weights[0]: 7.585839e-03 [1.398109e-07] 
Layer 'fc7' biases: 9.998628e-01 [1.754852e-07] 
Layer 'fc8' weights[0]: 4.319871e-03 [1.659068e-05] 
Layer 'fc8' biases: 1.041622e-02 [2.015773e-05] 
Train error last 800 batches: 0.657891
-------------------------------------------------------
Not saving because 0.454404 > 0.299667 (9.300: -1.18%)
======================================================= (2.363 sec)
12.541... logprob:  0.673156, 0.313802 (1.435 sec)
12.542... logprob:  0.689466, 0.313802 (1.432 sec)
12.543... logprob:  0.528866, 0.250000 (1.435 sec)
12.544... logprob:  0.629327, 0.304688 (1.423 sec)
12.545... logprob:  0.628769, 0.270833 (1.427 sec)
12.546... logprob:  0.613582, 0.286458 (1.482 sec)
12.547... logprob:  0.681997, 0.282552 (1.433 sec)
12.548... logprob:  0.747283, 0.298177 (1.436 sec)
12.549... logprob:  0.691131, 0.312500 (1.474 sec)
12.550... logprob:  0.632082, 0.287760 (1.429 sec)
12.551... logprob:  0.595210, 0.255208 (1.441 sec)
12.552... logprob:  0.686629, 0.304687 (1.425 sec)
12.553... logprob:  0.622992, 0.276042 (1.426 sec)
12.554... logprob:  0.671252, 0.287760 (1.435 sec)
12.555... logprob:  0.591226, 0.256510 (1.475 sec)
12.556... logprob:  0.644531, 0.290365 (1.429 sec)
12.557... logprob:  0.720890, 0.328125 (1.441 sec)
12.558... logprob:  0.671975, 0.295573 (1.470 sec)
12.559... logprob:  0.646606, 0.294271 (1.426 sec)
12.560... logprob:  0.573915, 0.261719 (1.436 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.509094, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 5.000562e-03 [2.514129e-07] 
Layer 'conv1' biases: 1.673782e-06 [5.180771e-10] 
Layer 'conv2' weights[0]: 4.991315e-03 [2.505474e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.905522e-09] 
Layer 'conv3' weights[0]: 4.990046e-03 [2.512687e-07] 
Layer 'conv3' biases: 2.744800e-05 [1.768748e-08] 
Layer 'conv4' weights[0]: 5.010643e-03 [2.537661e-07] 
Layer 'conv4' biases: 1.000010e+00 [2.761492e-07] 
Layer 'conv5' weights[0]: 5.085668e-03 [2.620529e-06] 
Layer 'conv5' biases: 9.990637e-01 [2.811211e-06] 
Layer 'fc6' weights[0]: 7.232134e-03 [5.960441e-08] 
Layer 'fc6' biases: 9.999950e-01 [5.766841e-08] 
Layer 'fc7' weights[0]: 7.585091e-03 [1.377167e-07] 
Layer 'fc7' biases: 9.998649e-01 [1.794975e-07] 
Layer 'fc8' weights[0]: 4.399880e-03 [1.760722e-05] 
Layer 'fc8' biases: 1.100884e-02 [3.389181e-05] 
Train error last 800 batches: 0.658047
-------------------------------------------------------
Not saving because 0.509094 > 0.299667 (9.300: -1.18%)
======================================================= (2.383 sec)
12.561... logprob:  0.601431, 0.260417 (1.433 sec)
12.562... logprob:  0.721873, 0.299479 (1.431 sec)
12.563... logprob:  0.581257, 0.247396 (1.433 sec)
12.564... logprob:  0.665037, 0.305990 (1.460 sec)
12.565... logprob:  0.809180, 0.352865 (1.442 sec)
12.566... logprob:  0.599913, 0.272135 (1.449 sec)
12.567... logprob:  0.737740, 0.339844 (1.456 sec)
12.568... logprob:  0.757971, 0.342448 (1.447 sec)
12.569... logprob:  0.687853, 0.287760 (1.434 sec)
12.570... logprob:  0.738104, 0.338542 (1.417 sec)
12.571... logprob:  0.690900, 0.299479 (1.424 sec)
12.572... logprob:  0.666312, 0.311198 (1.432 sec)
12.573... logprob:  0.862707, 0.354167 (1.440 sec)
12.574... logprob:  0.650338, 0.269531 (1.454 sec)
12.575... logprob:  0.540757, 0.240885 (1.449 sec)
12.576... logprob:  0.617829, 0.281250 (1.434 sec)
12.577... logprob:  0.645001, 0.291667 (1.470 sec)
12.578... logprob:  0.677550, 0.322917 (1.427 sec)
12.579... logprob:  0.680505, 0.287760 (1.419 sec)
12.580... logprob:  0.706915, 0.311198 (1.424 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.502470, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.995580e-03 [2.502317e-07] 
Layer 'conv1' biases: 1.676587e-06 [4.696233e-10] 
Layer 'conv2' weights[0]: 4.986339e-03 [2.500624e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.669886e-09] 
Layer 'conv3' weights[0]: 4.985063e-03 [2.507604e-07] 
Layer 'conv3' biases: 2.740322e-05 [1.836584e-08] 
Layer 'conv4' weights[0]: 5.005655e-03 [2.529582e-07] 
Layer 'conv4' biases: 1.000008e+00 [2.807500e-07] 
Layer 'conv5' weights[0]: 5.080274e-03 [2.195698e-06] 
Layer 'conv5' biases: 9.990751e-01 [2.383846e-06] 
Layer 'fc6' weights[0]: 7.231399e-03 [5.881054e-08] 
Layer 'fc6' biases: 9.999951e-01 [5.626628e-08] 
Layer 'fc7' weights[0]: 7.584294e-03 [1.341068e-07] 
Layer 'fc7' biases: 9.998634e-01 [1.635002e-07] 
Layer 'fc8' weights[0]: 4.347352e-03 [1.547487e-05] 
Layer 'fc8' biases: 1.055416e-02 [1.817106e-05] 
Train error last 800 batches: 0.657972
-------------------------------------------------------
Not saving because 0.502470 > 0.299667 (9.300: -1.18%)
======================================================= (2.419 sec)
12.581... logprob:  0.748052, 0.305990 (1.441 sec)
12.582... logprob:  0.654428, 0.300781 (1.441 sec)
12.583... logprob:  0.791457, 0.334635 (1.475 sec)
12.584... logprob:  0.651449, 0.291667 (1.444 sec)
12.585... logprob:  0.623164, 0.281250 (1.426 sec)
12.586... logprob:  0.562234, 0.257812 (1.481 sec)
12.587... logprob:  0.556255, 0.246094 (1.425 sec)
12.588... logprob:  0.671293, 0.300781 (1.430 sec)
12.589... logprob:  0.604641, 0.248698 (1.432 sec)
12.590... logprob:  0.832161, 0.369792 (1.426 sec)
12.591... logprob:  0.598136, 0.250000 (1.432 sec)
12.592... logprob:  0.746895, 0.328125 (1.476 sec)
12.593... logprob:  0.637066, 0.290365 (1.436 sec)
12.594... logprob:  0.615622, 0.287760 (1.440 sec)
12.595... logprob:  0.668859, 0.259114 (1.479 sec)
12.596... logprob:  0.648715, 0.303385 (1.427 sec)
12.597... logprob:  0.591161, 0.282552 (1.425 sec)
12.598... logprob:  0.631566, 0.268229 (1.435 sec)
12.599... logprob:  0.592661, 0.286458 (1.424 sec)
12.600... logprob:  0.602441, 0.256510 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.510711, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.990566e-03 [2.515394e-07] 
Layer 'conv1' biases: 1.679293e-06 [5.888007e-10] 
Layer 'conv2' weights[0]: 4.981378e-03 [2.502286e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.524038e-09] 
Layer 'conv3' weights[0]: 4.980095e-03 [2.514463e-07] 
Layer 'conv3' biases: 2.748447e-05 [2.131973e-08] 
Layer 'conv4' weights[0]: 5.000626e-03 [2.541640e-07] 
Layer 'conv4' biases: 1.000009e+00 [3.374098e-07] 
Layer 'conv5' weights[0]: 5.075909e-03 [2.935775e-06] 
Layer 'conv5' biases: 9.990635e-01 [3.143278e-06] 
Layer 'fc6' weights[0]: 7.230659e-03 [6.690217e-08] 
Layer 'fc6' biases: 9.999951e-01 [6.840695e-08] 
Layer 'fc7' weights[0]: 7.583553e-03 [1.603367e-07] 
Layer 'fc7' biases: 9.998643e-01 [2.581853e-07] 
Layer 'fc8' weights[0]: 4.387873e-03 [2.088604e-05] 
Layer 'fc8' biases: 1.091888e-02 [4.624851e-05] 
Train error last 800 batches: 0.658411
-------------------------------------------------------
Not saving because 0.510711 > 0.299667 (9.300: -1.18%)
======================================================= (2.351 sec)
12.601... logprob:  0.615650, 0.278646 (1.489 sec)
12.602... logprob:  0.524918, 0.235677 (1.434 sec)
12.603... logprob:  0.542741, 0.265625 (1.445 sec)
12.604... logprob:  0.556726, 0.265625 (1.481 sec)
12.605... logprob:  0.618105, 0.261719 (1.433 sec)
12.606... logprob:  0.532892, 0.217448 (1.432 sec)
12.607... logprob:  0.632734, 0.286458 (1.424 sec)
12.608... logprob:  0.526523, 0.244792 (1.421 sec)
12.609... logprob:  0.558487, 0.250000 (1.427 sec)
12.610... logprob:  0.673407, 0.276042 (1.465 sec)
12.611... logprob:  0.676485, 0.274740 (1.441 sec)
12.612... logprob:  0.668564, 0.291667 (1.454 sec)
12.613... logprob:  0.575379, 0.273437 (1.455 sec)
12.614... logprob:  0.734180, 0.295573 (1.439 sec)
12.615... logprob:  0.583160, 0.263021 (1.436 sec)
12.616... logprob:  0.641613, 0.300781 (1.419 sec)
12.617... logprob:  0.700302, 0.307292 (1.421 sec)
12.618... logprob:  0.782835, 0.313802 (1.439 sec)
12.619... logprob:  0.743757, 0.291667 (1.449 sec)
12.620... logprob:  0.768130, 0.341146 (1.452 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.494454, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.985586e-03 [2.512557e-07] 
Layer 'conv1' biases: 1.681341e-06 [9.036930e-10] 
Layer 'conv2' weights[0]: 4.976371e-03 [2.507422e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.604704e-09] 
Layer 'conv3' weights[0]: 4.975047e-03 [2.535158e-07] 
Layer 'conv3' biases: 2.756525e-05 [3.072188e-08] 
Layer 'conv4' weights[0]: 4.995625e-03 [2.571435e-07] 
Layer 'conv4' biases: 1.000009e+00 [4.611919e-07] 
Layer 'conv5' weights[0]: 5.071457e-03 [4.419066e-06] 
Layer 'conv5' biases: 9.990557e-01 [4.694544e-06] 
Layer 'fc6' weights[0]: 7.229930e-03 [8.922313e-08] 
Layer 'fc6' biases: 9.999949e-01 [1.041642e-07] 
Layer 'fc7' weights[0]: 7.582777e-03 [2.370278e-07] 
Layer 'fc7' biases: 9.998652e-01 [4.503766e-07] 
Layer 'fc8' weights[0]: 4.430536e-03 [3.294412e-05] 
Layer 'fc8' biases: 1.126508e-02 [8.401884e-05] 
Train error last 800 batches: 0.657973
-------------------------------------------------------
Not saving because 0.494454 > 0.299667 (9.300: -1.18%)
======================================================= (2.334 sec)
12.621... logprob:  0.634164, 0.246094 (1.457 sec)
12.622... logprob:  0.621103, 0.255208 (1.447 sec)
12.623... logprob:  0.717048, 0.305990 (1.461 sec)
12.624... logprob:  0.646891, 0.321615 (1.437 sec)
12.625... logprob:  0.647430, 0.281250 (1.421 sec)
12.626... logprob:  0.738386, 0.308594 (1.432 sec)
12.627... logprob:  0.607382, 0.276042 (1.430 sec)
12.628... logprob:  0.743254, 0.328125 (1.433 sec)
12.629... logprob:  0.647673, 0.315104 (1.473 sec)
12.630... logprob:  0.666948, 0.283854 (1.449 sec)
12.631... logprob:  0.833856, 0.358073 (1.432 sec)
12.632... logprob:  0.597497, 0.281250 (1.484 sec)
12.633... logprob:  0.606617, 0.247396 (1.433 sec)
12.634... logprob:  0.810354, 0.322917 (1.420 sec)
12.635... logprob:  0.553457, 0.214844 (1.430 sec)
12.636... logprob:  0.765032, 0.342448 (1.426 sec)
12.637... logprob:  0.545484, 0.231771 (1.428 sec)
12.638... logprob:  0.707873, 0.282552 (1.475 sec)
12.639... logprob:  0.594773, 0.252604 (1.430 sec)
12.640... logprob:  0.759584, 0.305989 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.507852, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.980606e-03 [2.505749e-07] 
Layer 'conv1' biases: 1.682623e-06 [5.419380e-10] 
Layer 'conv2' weights[0]: 4.971420e-03 [2.493230e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.162447e-09] 
Layer 'conv3' weights[0]: 4.970043e-03 [2.505854e-07] 
Layer 'conv3' biases: 2.758121e-05 [2.041236e-08] 
Layer 'conv4' weights[0]: 4.990632e-03 [2.535936e-07] 
Layer 'conv4' biases: 1.000009e+00 [3.365281e-07] 
Layer 'conv5' weights[0]: 5.066694e-03 [2.793597e-06] 
Layer 'conv5' biases: 9.990792e-01 [3.091832e-06] 
Layer 'fc6' weights[0]: 7.229157e-03 [6.224175e-08] 
Layer 'fc6' biases: 9.999949e-01 [6.128637e-08] 
Layer 'fc7' weights[0]: 7.581961e-03 [1.434034e-07] 
Layer 'fc7' biases: 9.998617e-01 [1.758591e-07] 
Layer 'fc8' weights[0]: 4.319421e-03 [1.687410e-05] 
Layer 'fc8' biases: 1.045884e-02 [2.889102e-05] 
Train error last 800 batches: 0.658351
-------------------------------------------------------
Not saving because 0.507852 > 0.299667 (9.300: -1.18%)
======================================================= (2.351 sec)
12.641... logprob:  0.575978, 0.242188 (1.489 sec)
12.642... logprob:  0.753527, 0.313802 (1.465 sec)
12.643... logprob:  0.800055, 0.341146 (1.430 sec)
12.644... logprob:  0.602272, 0.270833 (1.432 sec)
12.645... logprob:  0.608763, 0.269531 (1.424 sec)
12.646... logprob:  0.662456, 0.285156 (1.425 sec)
12.647... logprob:  0.727813, 0.307292 (1.490 sec)
12.648... logprob:  0.697252, 0.316406 (1.424 sec)
12.649... logprob:  0.672337, 0.282552 (1.441 sec)
12.650... logprob:  0.687957, 0.273437 (1.469 sec)
12.651... logprob:  0.613069, 0.253906 (1.425 sec)
12.652... logprob:  0.674987, 0.279948 (1.436 sec)
12.653... logprob:  0.702044, 0.319010 (1.433 sec)
12.654... logprob:  0.734963, 0.308594 (1.420 sec)
12.655... logprob:  0.684314, 0.295573 (1.422 sec)
12.656... logprob:  0.662744, 0.277344 (1.476 sec)
12.657... logprob:  0.594269, 0.276042 (1.435 sec)
12.658... logprob:  0.655413, 0.278646 (1.441 sec)
12.659... logprob:  0.701910, 0.299479 (1.471 sec)
12.660... logprob:  0.673655, 0.277344 (1.434 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.417714, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.975651e-03 [2.499537e-07] 
Layer 'conv1' biases: 1.684506e-06 [7.272322e-10] 
Layer 'conv2' weights[0]: 4.966473e-03 [2.493482e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.076295e-09] 
Layer 'conv3' weights[0]: 4.965106e-03 [2.508771e-07] 
Layer 'conv3' biases: 2.760846e-05 [2.243656e-08] 
Layer 'conv4' weights[0]: 4.985687e-03 [2.529707e-07] 
Layer 'conv4' biases: 1.000011e+00 [3.152089e-07] 
Layer 'conv5' weights[0]: 5.062593e-03 [2.498778e-06] 
Layer 'conv5' biases: 9.990715e-01 [2.682189e-06] 
Layer 'fc6' weights[0]: 7.228409e-03 [5.911430e-08] 
Layer 'fc6' biases: 9.999949e-01 [5.665475e-08] 
Layer 'fc7' weights[0]: 7.581183e-03 [1.390287e-07] 
Layer 'fc7' biases: 9.998622e-01 [1.659738e-07] 
Layer 'fc8' weights[0]: 4.333543e-03 [1.667031e-05] 
Layer 'fc8' biases: 1.054594e-02 [2.547754e-05] 
Train error last 800 batches: 0.658187
-------------------------------------------------------
Not saving because 0.417714 > 0.299667 (9.300: -1.18%)
======================================================= (2.360 sec)
12.661... logprob:  0.624208, 0.289062 (1.445 sec)
12.662... logprob:  0.728302, 0.325521 (1.432 sec)
12.663... logprob:  0.596418, 0.292969 (1.425 sec)
12.664... logprob:  0.573928, 0.255208 (1.438 sec)
12.665... logprob:  0.680850, 0.276042 (1.456 sec)
12.666... logprob:  0.701325, 0.312500 (1.455 sec)
12.667... logprob:  0.806089, 0.312500 (1.453 sec)
12.668... logprob:  0.663190, 0.289063 (1.442 sec)
12.669... logprob:  0.624318, 0.281250 (1.456 sec)
12.670... logprob:  0.638353, 0.242187 (1.431 sec)
12.671... logprob:  0.586360, 0.261719 (1.418 sec)
12.672... logprob:  0.659196, 0.279948 (1.425 sec)
12.673... logprob:  0.675323, 0.308594 (1.434 sec)
12.674... logprob:  0.651564, 0.307292 (1.437 sec)
12.675... logprob:  0.621780, 0.298177 (1.456 sec)
12.676... logprob:  0.637750, 0.265625 (1.449 sec)
12.677... logprob:  0.705041, 0.326823 (1.432 sec)
12.678... logprob:  0.786224, 0.335937 (1.483 sec)
12.679... logprob:  0.633301, 0.300781 (1.422 sec)
12.680... logprob:  0.629236, 0.303385 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.434672, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.970655e-03 [2.498324e-07] 
Layer 'conv1' biases: 1.688941e-06 [4.815471e-10] 
Layer 'conv2' weights[0]: 4.961519e-03 [2.486889e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.240730e-09] 
Layer 'conv3' weights[0]: 4.960142e-03 [2.497068e-07] 
Layer 'conv3' biases: 2.765273e-05 [1.999669e-08] 
Layer 'conv4' weights[0]: 4.980702e-03 [2.518585e-07] 
Layer 'conv4' biases: 1.000010e+00 [2.791356e-07] 
Layer 'conv5' weights[0]: 5.057284e-03 [2.520058e-06] 
Layer 'conv5' biases: 9.990609e-01 [2.811757e-06] 
Layer 'fc6' weights[0]: 7.227632e-03 [5.626771e-08] 
Layer 'fc6' biases: 9.999949e-01 [5.252852e-08] 
Layer 'fc7' weights[0]: 7.580410e-03 [1.271330e-07] 
Layer 'fc7' biases: 9.998630e-01 [1.443591e-07] 
Layer 'fc8' weights[0]: 4.362818e-03 [1.394837e-05] 
Layer 'fc8' biases: 1.082424e-02 [1.083193e-05] 
Train error last 800 batches: 0.658806
-------------------------------------------------------
Not saving because 0.434672 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
12.681... logprob:  0.583422, 0.256510 (1.521 sec)
12.682... logprob:  0.562624, 0.253906 (1.440 sec)
12.683... logprob:  0.738324, 0.294271 (1.430 sec)
12.684... logprob:  0.646728, 0.289062 (1.470 sec)
12.685... logprob:  0.485014, 0.207031 (1.437 sec)
12.686... logprob:  0.572069, 0.266927 (1.426 sec)
12.687... logprob:  0.607349, 0.265625 (1.484 sec)
12.688... logprob:  0.596538, 0.274740 (1.433 sec)
12.689... logprob:  0.608088, 0.266927 (1.429 sec)
12.690... logprob:  0.717971, 0.292969 (1.432 sec)
12.691... logprob:  0.677752, 0.291667 (1.430 sec)
12.692... logprob:  0.577651, 0.276042 (1.427 sec)
12.693... logprob:  0.695144, 0.308594 (1.479 sec)
12.694... logprob:  0.585689, 0.283854 (1.430 sec)
12.695... logprob:  0.533020, 0.210937 (1.434 sec)
12.696... logprob:  0.708863, 0.302083 (1.472 sec)
12.697... logprob:  0.596984, 0.256510 (1.427 sec)
12.698... logprob:  0.753026, 0.311198 (1.428 sec)
12.699... logprob:  0.650999, 0.269531 (1.428 sec)
12.700... logprob:  0.758181, 0.328125 (1.422 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.396453, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.965709e-03 [2.491950e-07] 
Layer 'conv1' biases: 1.692096e-06 [6.349749e-10] 
Layer 'conv2' weights[0]: 4.956544e-03 [2.488704e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.661408e-09] 
Layer 'conv3' weights[0]: 4.955163e-03 [2.504483e-07] 
Layer 'conv3' biases: 2.766466e-05 [2.322712e-08] 
Layer 'conv4' weights[0]: 4.975704e-03 [2.542351e-07] 
Layer 'conv4' biases: 1.000008e+00 [4.021533e-07] 
Layer 'conv5' weights[0]: 5.051621e-03 [3.335006e-06] 
Layer 'conv5' biases: 9.990517e-01 [3.499310e-06] 
Layer 'fc6' weights[0]: 7.226836e-03 [7.308272e-08] 
Layer 'fc6' biases: 9.999949e-01 [7.806823e-08] 
Layer 'fc7' weights[0]: 7.579674e-03 [1.766668e-07] 
Layer 'fc7' biases: 9.998636e-01 [2.921686e-07] 
Layer 'fc8' weights[0]: 4.401284e-03 [2.252238e-05] 
Layer 'fc8' biases: 1.107553e-02 [4.855480e-05] 
Train error last 800 batches: 0.658487
-------------------------------------------------------
Not saving because 0.396453 > 0.299667 (9.300: -1.18%)
======================================================= (2.388 sec)
12.701... logprob:  0.645031, 0.276042 (1.433 sec)
12.702... logprob:  0.624647, 0.277344 (1.488 sec)
12.703... logprob:  0.608504, 0.251302 (1.436 sec)
12.704... logprob:  0.645240, 0.295573 (1.447 sec)
12.705... logprob:  0.613657, 0.296875 (1.466 sec)
12.706... logprob:  0.625381, 0.244792 (1.432 sec)
12.707... logprob:  0.634658, 0.273437 (1.439 sec)
12.708... logprob:  0.626341, 0.283854 (1.430 sec)
12.709... logprob:  0.663866, 0.302083 (1.420 sec)
12.710... logprob:  0.724602, 0.315104 (1.438 sec)
12.711... logprob:  0.660523, 0.309896 (1.458 sec)
12.712... logprob:  0.527923, 0.217448 (1.444 sec)
12.713... logprob:  0.741936, 0.308594 (1.444 sec)
12.714... logprob:  0.681712, 0.324219 (1.459 sec)
12.715... logprob:  0.691946, 0.298177 (1.450 sec)
12.716... logprob:  0.627781, 0.259115 (1.432 sec)
12.717... logprob:  0.682488, 0.325521 (1.416 sec)
12.718... logprob:  0.704659, 0.298177 (1.427 sec)
12.719... logprob:  0.607406, 0.281250 (1.430 sec)
12.720... logprob:  0.686609, 0.302083 (1.444 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.503124, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.960788e-03 [2.492189e-07] 
Layer 'conv1' biases: 1.693812e-06 [5.097066e-10] 
Layer 'conv2' weights[0]: 4.951601e-03 [2.483672e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.552901e-09] 
Layer 'conv3' weights[0]: 4.950283e-03 [2.495379e-07] 
Layer 'conv3' biases: 2.767997e-05 [2.136877e-08] 
Layer 'conv4' weights[0]: 4.970758e-03 [2.517197e-07] 
Layer 'conv4' biases: 1.000007e+00 [3.091497e-07] 
Layer 'conv5' weights[0]: 5.046269e-03 [2.543160e-06] 
Layer 'conv5' biases: 9.990571e-01 [2.757362e-06] 
Layer 'fc6' weights[0]: 7.226084e-03 [5.834944e-08] 
Layer 'fc6' biases: 9.999949e-01 [5.608720e-08] 
Layer 'fc7' weights[0]: 7.578868e-03 [1.351627e-07] 
Layer 'fc7' biases: 9.998619e-01 [1.647772e-07] 
Layer 'fc8' weights[0]: 4.365992e-03 [1.518229e-05] 
Layer 'fc8' biases: 1.081209e-02 [2.180220e-05] 
Train error last 800 batches: 0.658155
-------------------------------------------------------
Not saving because 0.503124 > 0.299667 (9.300: -1.18%)
======================================================= (2.362 sec)
12.721... logprob:  0.576378, 0.256510 (1.461 sec)
12.722... logprob:  0.783882, 0.351562 (1.456 sec)
12.723... logprob:  0.631946, 0.268229 (1.441 sec)
12.724... logprob:  0.610832, 0.295573 (1.467 sec)
12.725... logprob:  0.772673, 0.351562 (1.427 sec)
12.726... logprob:  0.668330, 0.312500 (1.422 sec)
12.727... logprob:  0.651189, 0.315104 (1.424 sec)
12.728... logprob:  0.600434, 0.295573 (1.433 sec)
12.729... logprob:  0.635733, 0.292969 (1.427 sec)
12.730... logprob:  0.763006, 0.315104 (1.475 sec)
12.731... logprob:  0.692212, 0.312500 (1.442 sec)
12.732... logprob:  0.559901, 0.260417 (1.427 sec)
12.733... logprob:  0.721659, 0.290365 (1.478 sec)
12.734... logprob:  0.560683, 0.231771 (1.429 sec)
12.735... logprob:  0.735332, 0.300781 (1.423 sec)
12.736... logprob:  0.778281, 0.335937 (1.430 sec)
12.737... logprob:  0.752145, 0.316406 (1.421 sec)
12.738... logprob:  0.630329, 0.279948 (1.428 sec)
12.739... logprob:  0.762725, 0.350260 (1.477 sec)
12.740... logprob:  0.527844, 0.247396 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.478460, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.955795e-03 [2.489570e-07] 
Layer 'conv1' biases: 1.696476e-06 [4.396945e-10] 
Layer 'conv2' weights[0]: 4.946643e-03 [2.482845e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.127798e-09] 
Layer 'conv3' weights[0]: 4.945306e-03 [2.488124e-07] 
Layer 'conv3' biases: 2.773168e-05 [1.761380e-08] 
Layer 'conv4' weights[0]: 4.965771e-03 [2.507355e-07] 
Layer 'conv4' biases: 1.000006e+00 [2.584391e-07] 
Layer 'conv5' weights[0]: 5.041165e-03 [2.453369e-06] 
Layer 'conv5' biases: 9.990517e-01 [2.701470e-06] 
Layer 'fc6' weights[0]: 7.225328e-03 [6.112326e-08] 
Layer 'fc6' biases: 9.999949e-01 [6.051878e-08] 
Layer 'fc7' weights[0]: 7.578088e-03 [1.428826e-07] 
Layer 'fc7' biases: 9.998618e-01 [1.958567e-07] 
Layer 'fc8' weights[0]: 4.356765e-03 [1.907762e-05] 
Layer 'fc8' biases: 1.078832e-02 [3.683538e-05] 
Train error last 800 batches: 0.658680
-------------------------------------------------------
Not saving because 0.478460 > 0.299667 (9.300: -1.18%)
======================================================= (2.379 sec)
12.741... logprob:  0.677404, 0.317708 (1.441 sec)
12.742... logprob:  0.675598, 0.274740 (1.485 sec)
12.743... logprob:  0.605665, 0.264323 (1.428 sec)
12.744... logprob:  0.699597, 0.317708 (1.429 sec)
12.745... logprob:  0.675458, 0.276042 (1.438 sec)
12.746... logprob:  0.696908, 0.305990 (1.429 sec)
12.747... logprob:  0.695589, 0.296875 (1.427 sec)
12.748... logprob:  0.666482, 0.281250 (1.479 sec)
12.749... logprob:  0.564052, 0.268229 (1.427 sec)
12.750... logprob:  0.669778, 0.309896 (1.440 sec)
12.751... logprob:  0.451656, 0.209635 (1.468 sec)
12.752... logprob:  0.757283, 0.311198 (1.429 sec)
12.753... logprob:  0.592962, 0.265625 (1.429 sec)
12.754... logprob:  0.692715, 0.289062 (1.428 sec)
12.755... logprob:  0.692632, 0.313802 (1.422 sec)
12.756... logprob:  0.732924, 0.319010 (1.427 sec)
12.757... logprob:  0.879796, 0.358073 (1.466 sec)
12.758... logprob:  0.629646, 0.292969 (1.438 sec)
12.759... logprob:  0.659000, 0.292969 (1.444 sec)
12.760... logprob:  0.672285, 0.286458 (1.457 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.551232, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.950827e-03 [2.488232e-07] 
Layer 'conv1' biases: 1.695653e-06 [4.825242e-10] 
Layer 'conv2' weights[0]: 4.941692e-03 [2.479676e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.594185e-09] 
Layer 'conv3' weights[0]: 4.940320e-03 [2.486009e-07] 
Layer 'conv3' biases: 2.769830e-05 [1.679450e-08] 
Layer 'conv4' weights[0]: 4.960816e-03 [2.504373e-07] 
Layer 'conv4' biases: 1.000007e+00 [2.513880e-07] 
Layer 'conv5' weights[0]: 5.037195e-03 [2.565690e-06] 
Layer 'conv5' biases: 9.990476e-01 [2.693133e-06] 
Layer 'fc6' weights[0]: 7.224549e-03 [6.275378e-08] 
Layer 'fc6' biases: 9.999949e-01 [6.292925e-08] 
Layer 'fc7' weights[0]: 7.577334e-03 [1.481939e-07] 
Layer 'fc7' biases: 9.998617e-01 [2.008965e-07] 
Layer 'fc8' weights[0]: 4.356687e-03 [1.703098e-05] 
Layer 'fc8' biases: 1.079911e-02 [3.132857e-05] 
Train error last 800 batches: 0.658578
-------------------------------------------------------
Not saving because 0.551232 > 0.299667 (9.300: -1.18%)
======================================================= (2.404 sec)
12.761... logprob:  0.619551, 0.295573 (1.449 sec)
12.762... logprob:  0.706664, 0.308594 (1.439 sec)
12.763... logprob:  0.774022, 0.367187 (1.427 sec)
12.764... logprob:  0.673892, 0.276042 (1.421 sec)
12.765... logprob:  0.539317, 0.243490 (1.432 sec)
12.766... logprob:  0.627835, 0.281250 (1.446 sec)
12.767... logprob:  0.625577, 0.274740 (1.454 sec)
12.768... logprob:  0.656704, 0.285156 (1.462 sec)
12.769... logprob:  0.695421, 0.300781 (1.464 sec)
12.770... logprob:  0.590977, 0.248698 (1.478 sec)
12.771... logprob:  0.690526, 0.273438 (1.455 sec)
12.772... logprob:  0.653414, 0.281250 (1.433 sec)
12.773... logprob:  0.740634, 0.309896 (1.443 sec)
12.774... logprob:  0.564539, 0.252604 (1.454 sec)
12.775... logprob:  0.561056, 0.239583 (1.453 sec)
12.776... logprob:  0.676128, 0.302083 (1.477 sec)
12.777... logprob:  0.628150, 0.260417 (1.464 sec)
12.778... logprob:  0.700235, 0.281250 (1.466 sec)
12.779... logprob:  0.729775, 0.303385 (1.480 sec)
12.780... logprob:  0.627238, 0.308594 (1.452 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.427971, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.945910e-03 [2.490236e-07] 
Layer 'conv1' biases: 1.694971e-06 [4.602051e-10] 
Layer 'conv2' weights[0]: 4.936786e-03 [2.478182e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.429596e-09] 
Layer 'conv3' weights[0]: 4.935384e-03 [2.485196e-07] 
Layer 'conv3' biases: 2.776118e-05 [1.673376e-08] 
Layer 'conv4' weights[0]: 4.955834e-03 [2.508421e-07] 
Layer 'conv4' biases: 1.000006e+00 [2.354353e-07] 
Layer 'conv5' weights[0]: 5.031457e-03 [2.228769e-06] 
Layer 'conv5' biases: 9.990560e-01 [2.281602e-06] 
Layer 'fc6' weights[0]: 7.223773e-03 [6.082630e-08] 
Layer 'fc6' biases: 9.999949e-01 [5.978072e-08] 
Layer 'fc7' weights[0]: 7.576628e-03 [1.426609e-07] 
Layer 'fc7' biases: 9.998614e-01 [1.859034e-07] 
Layer 'fc8' weights[0]: 4.351788e-03 [1.813253e-05] 
Layer 'fc8' biases: 1.070036e-02 [2.728167e-05] 
Train error last 800 batches: 0.658091
-------------------------------------------------------
Not saving because 0.427971 > 0.299667 (9.300: -1.18%)
======================================================= (2.369 sec)
12.781... logprob:  0.559480, 0.214844 (1.445 sec)
12.782... logprob:  0.560807, 0.259115 (1.451 sec)
12.783... logprob:  0.857139, 0.352865 (1.458 sec)
12.784... logprob:  0.744357, 0.330729 (1.452 sec)
12.785... logprob:  0.728638, 0.333333 (1.495 sec)
12.786... logprob:  0.669136, 0.305990 (1.462 sec)
12.787... logprob:  0.678580, 0.302083 (1.458 sec)
12.788... logprob:  0.770665, 0.343750 (1.492 sec)
12.789... logprob:  0.547566, 0.256510 (1.445 sec)
12.790... logprob:  0.606120, 0.252604 (1.442 sec)
12.791... logprob:  0.670714, 0.313802 (1.443 sec)
12.792... logprob:  0.521011, 0.252604 (1.458 sec)
12.793... logprob:  0.572114, 0.242187 (1.448 sec)
12.794... logprob:  0.631413, 0.276042 (1.485 sec)
12.795... logprob:  0.713186, 0.335938 (1.492 sec)
12.796... logprob:  0.657084, 0.266927 (1.458 sec)
12.797... logprob:  0.657380, 0.298177 (1.489 sec)
12.798... logprob:  0.699590, 0.295573 (1.450 sec)
12.799... logprob:  0.563659, 0.250000 (1.441 sec)
12.800... logprob:  0.725810, 0.326823 (1.403 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.367660, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.940943e-03 [2.480564e-07] 
Layer 'conv1' biases: 1.695498e-06 [5.110187e-10] 
Layer 'conv2' weights[0]: 4.931835e-03 [2.472368e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.102521e-09] 
Layer 'conv3' weights[0]: 4.930481e-03 [2.478506e-07] 
Layer 'conv3' biases: 2.779905e-05 [1.635005e-08] 
Layer 'conv4' weights[0]: 4.950878e-03 [2.504276e-07] 
Layer 'conv4' biases: 1.000005e+00 [2.683260e-07] 
Layer 'conv5' weights[0]: 5.026428e-03 [2.584132e-06] 
Layer 'conv5' biases: 9.990472e-01 [2.873350e-06] 
Layer 'fc6' weights[0]: 7.223051e-03 [6.139257e-08] 
Layer 'fc6' biases: 9.999950e-01 [6.096241e-08] 
Layer 'fc7' weights[0]: 7.575839e-03 [1.391583e-07] 
Layer 'fc7' biases: 9.998621e-01 [1.809087e-07] 
Layer 'fc8' weights[0]: 4.397690e-03 [1.642388e-05] 
Layer 'fc8' biases: 1.109746e-02 [2.379043e-05] 
Train error last 800 batches: 0.658341
-------------------------------------------------------
Not saving because 0.367660 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
13.1... logprob:  0.616363, 0.276042 (1.529 sec)
13.2... logprob:  0.698543, 0.303385 (1.450 sec)
13.3... logprob:  0.633115, 0.278646 (1.420 sec)
13.4... logprob:  0.627509, 0.277344 (1.397 sec)
13.5... logprob:  0.561310, 0.247396 (1.429 sec)
13.6... logprob:  0.652914, 0.298177 (1.389 sec)
13.7... logprob:  0.595448, 0.289062 (1.421 sec)
13.8... logprob:  0.626977, 0.290365 (1.396 sec)
13.9... logprob:  0.608940, 0.281250 (1.405 sec)
13.10... logprob:  0.542736, 0.243490 (1.404 sec)
13.11... logprob:  0.573817, 0.281250 (1.437 sec)
13.12... logprob:  0.624721, 0.266927 (1.393 sec)
13.13... logprob:  0.654650, 0.287760 (1.419 sec)
13.14... logprob:  0.669756, 0.299479 (1.394 sec)
13.15... logprob:  0.678731, 0.308594 (1.409 sec)
13.16... logprob:  0.513955, 0.225260 (1.398 sec)
13.17... logprob:  0.774177, 0.315104 (1.391 sec)
13.18... logprob:  0.455845, 0.186198 (1.395 sec)
13.19... logprob:  0.570955, 0.250000 (1.398 sec)
13.20... logprob:  0.605879, 0.282552 (1.402 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.493403, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.936029e-03 [2.478536e-07] 
Layer 'conv1' biases: 1.698823e-06 [5.051538e-10] 
Layer 'conv2' weights[0]: 4.926920e-03 [2.471935e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.041142e-09] 
Layer 'conv3' weights[0]: 4.925532e-03 [2.481563e-07] 
Layer 'conv3' biases: 2.785355e-05 [1.985710e-08] 
Layer 'conv4' weights[0]: 4.945948e-03 [2.500885e-07] 
Layer 'conv4' biases: 1.000004e+00 [2.724356e-07] 
Layer 'conv5' weights[0]: 5.021588e-03 [2.321233e-06] 
Layer 'conv5' biases: 9.990428e-01 [2.543338e-06] 
Layer 'fc6' weights[0]: 7.222316e-03 [5.865936e-08] 
Layer 'fc6' biases: 9.999950e-01 [5.653752e-08] 
Layer 'fc7' weights[0]: 7.575058e-03 [1.347467e-07] 
Layer 'fc7' biases: 9.998631e-01 [1.787108e-07] 
Layer 'fc8' weights[0]: 4.439252e-03 [1.628624e-05] 
Layer 'fc8' biases: 1.141491e-02 [3.076509e-05] 
Train error last 800 batches: 0.657813
-------------------------------------------------------
Not saving because 0.493403 > 0.299667 (9.300: -1.18%)
======================================================= (2.376 sec)
13.21... logprob:  0.752378, 0.305990 (1.403 sec)
13.22... logprob:  0.784175, 0.320313 (1.411 sec)
13.23... logprob:  0.716954, 0.319010 (1.416 sec)
13.24... logprob:  0.548765, 0.260417 (1.408 sec)
13.25... logprob:  0.557248, 0.250000 (1.404 sec)
13.26... logprob:  0.688198, 0.281250 (1.442 sec)
13.27... logprob:  0.683656, 0.309896 (1.385 sec)
13.28... logprob:  0.699774, 0.290365 (1.407 sec)
13.29... logprob:  0.608851, 0.277344 (1.423 sec)
13.30... logprob:  0.605263, 0.255208 (1.408 sec)
13.31... logprob:  0.642653, 0.264323 (1.395 sec)
13.32... logprob:  0.776593, 0.329427 (1.384 sec)
13.33... logprob:  0.635298, 0.283854 (1.438 sec)
13.34... logprob:  0.625019, 0.264323 (1.412 sec)
13.35... logprob:  0.650208, 0.286458 (1.392 sec)
13.36... logprob:  0.791499, 0.335938 (1.396 sec)
13.37... logprob:  0.626803, 0.286458 (1.404 sec)
13.38... logprob:  0.563200, 0.247396 (1.389 sec)
13.39... logprob:  0.880674, 0.364583 (1.428 sec)
13.40... logprob:  0.712550, 0.308594 (1.403 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.480020, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.931099e-03 [2.473760e-07] 
Layer 'conv1' biases: 1.700503e-06 [5.081416e-10] 
Layer 'conv2' weights[0]: 4.921970e-03 [2.471344e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.614627e-09] 
Layer 'conv3' weights[0]: 4.920596e-03 [2.482398e-07] 
Layer 'conv3' biases: 2.788308e-05 [2.313894e-08] 
Layer 'conv4' weights[0]: 4.941023e-03 [2.509142e-07] 
Layer 'conv4' biases: 1.000004e+00 [3.460071e-07] 
Layer 'conv5' weights[0]: 5.016782e-03 [3.256712e-06] 
Layer 'conv5' biases: 9.990678e-01 [3.533642e-06] 
Layer 'fc6' weights[0]: 7.221522e-03 [7.057704e-08] 
Layer 'fc6' biases: 9.999950e-01 [7.389171e-08] 
Layer 'fc7' weights[0]: 7.574289e-03 [1.699734e-07] 
Layer 'fc7' biases: 9.998612e-01 [2.680001e-07] 
Layer 'fc8' weights[0]: 4.352458e-03 [2.210464e-05] 
Layer 'fc8' biases: 1.079899e-02 [4.893207e-05] 
Train error last 800 batches: 0.657919
-------------------------------------------------------
Not saving because 0.480020 > 0.299667 (9.300: -1.18%)
======================================================= (2.348 sec)
13.41... logprob:  0.530313, 0.214844 (1.426 sec)
13.42... logprob:  0.645603, 0.304688 (1.416 sec)
13.43... logprob:  0.714253, 0.321615 (1.407 sec)
13.44... logprob:  0.764057, 0.347656 (1.433 sec)
13.45... logprob:  0.650763, 0.255208 (1.394 sec)
13.46... logprob:  0.783432, 0.346354 (1.393 sec)
13.47... logprob:  0.574087, 0.263021 (1.387 sec)
13.48... logprob:  0.688631, 0.303385 (1.419 sec)
13.49... logprob:  0.752429, 0.330729 (1.405 sec)
13.50... logprob:  0.709954, 0.319010 (1.419 sec)
13.51... logprob:  0.698604, 0.313802 (1.411 sec)
13.52... logprob:  0.635119, 0.273437 (1.389 sec)
13.53... logprob:  0.531651, 0.231771 (1.440 sec)
13.54... logprob:  0.625431, 0.264323 (1.381 sec)
13.55... logprob:  0.608001, 0.281250 (1.396 sec)
13.56... logprob:  0.658973, 0.312500 (1.403 sec)
13.57... logprob:  0.848036, 0.342448 (1.432 sec)
13.58... logprob:  0.672198, 0.300781 (1.401 sec)
13.59... logprob:  0.590154, 0.285156 (1.459 sec)
13.60... logprob:  0.925074, 0.384115 (1.411 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.433851, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.926159e-03 [2.474843e-07] 
Layer 'conv1' biases: 1.701620e-06 [4.276367e-10] 
Layer 'conv2' weights[0]: 4.917049e-03 [2.463426e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.260100e-09] 
Layer 'conv3' weights[0]: 4.915700e-03 [2.471097e-07] 
Layer 'conv3' biases: 2.783076e-05 [1.624848e-08] 
Layer 'conv4' weights[0]: 4.936088e-03 [2.495640e-07] 
Layer 'conv4' biases: 1.000004e+00 [2.604200e-07] 
Layer 'conv5' weights[0]: 5.011970e-03 [2.505350e-06] 
Layer 'conv5' biases: 9.990745e-01 [2.755879e-06] 
Layer 'fc6' weights[0]: 7.220787e-03 [6.149393e-08] 
Layer 'fc6' biases: 9.999951e-01 [6.026649e-08] 
Layer 'fc7' weights[0]: 7.573532e-03 [1.430344e-07] 
Layer 'fc7' biases: 9.998610e-01 [1.757751e-07] 
Layer 'fc8' weights[0]: 4.346320e-03 [1.615127e-05] 
Layer 'fc8' biases: 1.071709e-02 [2.110692e-05] 
Train error last 800 batches: 0.658402
-------------------------------------------------------
Not saving because 0.433851 > 0.299667 (9.300: -1.18%)
======================================================= (2.369 sec)
13.61... logprob:  0.605317, 0.239583 (1.428 sec)
13.62... logprob:  0.748721, 0.335937 (1.463 sec)
13.63... logprob:  0.676885, 0.304688 (1.440 sec)
13.64... logprob:  0.657983, 0.305990 (1.413 sec)
13.65... logprob:  0.618934, 0.279948 (1.399 sec)
13.66... logprob:  0.594595, 0.278646 (1.446 sec)
13.67... logprob:  0.586736, 0.260417 (1.383 sec)
13.68... logprob:  0.686364, 0.308594 (1.392 sec)
13.69... logprob:  0.729164, 0.311198 (1.425 sec)
13.70... logprob:  0.617168, 0.281250 (1.419 sec)
13.71... logprob:  0.588169, 0.272135 (1.459 sec)
13.72... logprob:  0.693486, 0.294271 (1.399 sec)
13.73... logprob:  0.648555, 0.269531 (1.442 sec)
13.74... logprob:  0.736941, 0.299479 (1.406 sec)
13.75... logprob:  0.602296, 0.286458 (1.411 sec)
13.76... logprob:  0.693841, 0.299479 (1.430 sec)
13.77... logprob:  0.612172, 0.273437 (1.418 sec)
13.78... logprob:  0.588386, 0.273437 (1.454 sec)
13.79... logprob:  0.689582, 0.307292 (1.402 sec)
13.80... logprob:  0.769552, 0.311198 (1.423 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.434339, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.921251e-03 [2.473357e-07] 
Layer 'conv1' biases: 1.699430e-06 [5.161343e-10] 
Layer 'conv2' weights[0]: 4.912161e-03 [2.464475e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.520702e-09] 
Layer 'conv3' weights[0]: 4.910767e-03 [2.476525e-07] 
Layer 'conv3' biases: 2.781123e-05 [2.330963e-08] 
Layer 'conv4' weights[0]: 4.931166e-03 [2.500124e-07] 
Layer 'conv4' biases: 1.000005e+00 [3.317194e-07] 
Layer 'conv5' weights[0]: 5.007644e-03 [2.592787e-06] 
Layer 'conv5' biases: 9.990660e-01 [2.732078e-06] 
Layer 'fc6' weights[0]: 7.220024e-03 [6.083750e-08] 
Layer 'fc6' biases: 9.999949e-01 [5.940143e-08] 
Layer 'fc7' weights[0]: 7.572809e-03 [1.394429e-07] 
Layer 'fc7' biases: 9.998611e-01 [1.747591e-07] 
Layer 'fc8' weights[0]: 4.389651e-03 [1.684216e-05] 
Layer 'fc8' biases: 1.099955e-02 [2.823347e-05] 
Train error last 800 batches: 0.658961
-------------------------------------------------------
Not saving because 0.434339 > 0.299667 (9.300: -1.18%)
======================================================= (2.398 sec)
13.81... logprob:  0.645552, 0.304688 (1.424 sec)
13.82... logprob:  0.558285, 0.266927 (1.423 sec)
13.83... logprob:  0.770632, 0.320313 (1.401 sec)
13.84... logprob:  0.674106, 0.311198 (1.458 sec)
13.85... logprob:  0.669430, 0.290365 (1.421 sec)
13.86... logprob:  0.646146, 0.313802 (1.419 sec)
13.87... logprob:  0.858864, 0.341146 (1.413 sec)
13.88... logprob:  0.790858, 0.319010 (1.404 sec)
13.89... logprob:  0.597831, 0.270833 (1.425 sec)
13.90... logprob:  0.774003, 0.325521 (1.384 sec)
13.91... logprob:  0.575129, 0.255208 (1.390 sec)
13.92... logprob:  0.668573, 0.291667 (1.395 sec)
13.93... logprob:  0.679013, 0.299479 (1.391 sec)
13.94... logprob:  0.657773, 0.294271 (1.381 sec)
13.95... logprob:  0.689689, 0.317708 (1.401 sec)
13.96... logprob:  0.781515, 0.320312 (1.405 sec)
13.97... logprob:  0.588462, 0.266927 (1.384 sec)
13.98... logprob:  0.686020, 0.274739 (1.431 sec)
13.99... logprob:  0.743016, 0.319010 (1.400 sec)
13.100... logprob:  0.643221, 0.289063 (1.394 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.405142, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.916350e-03 [2.470922e-07] 
Layer 'conv1' biases: 1.702081e-06 [4.440960e-10] 
Layer 'conv2' weights[0]: 4.907256e-03 [2.461795e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.465540e-09] 
Layer 'conv3' weights[0]: 4.905898e-03 [2.468375e-07] 
Layer 'conv3' biases: 2.785063e-05 [1.651129e-08] 
Layer 'conv4' weights[0]: 4.926223e-03 [2.492670e-07] 
Layer 'conv4' biases: 1.000004e+00 [2.826001e-07] 
Layer 'conv5' weights[0]: 5.002579e-03 [2.211176e-06] 
Layer 'conv5' biases: 9.990858e-01 [2.335613e-06] 
Layer 'fc6' weights[0]: 7.219260e-03 [5.881918e-08] 
Layer 'fc6' biases: 9.999949e-01 [5.585065e-08] 
Layer 'fc7' weights[0]: 7.572022e-03 [1.342616e-07] 
Layer 'fc7' biases: 9.998586e-01 [1.547888e-07] 
Layer 'fc8' weights[0]: 4.327559e-03 [1.448793e-05] 
Layer 'fc8' biases: 1.067188e-02 [1.270638e-05] 
Train error last 800 batches: 0.659153
-------------------------------------------------------
Not saving because 0.405142 > 0.299667 (9.300: -1.18%)
======================================================= (2.384 sec)
13.101... logprob:  0.597481, 0.272135 (1.449 sec)
13.102... logprob:  0.706296, 0.312500 (1.388 sec)
13.103... logprob:  0.707741, 0.290365 (1.402 sec)
13.104... logprob:  0.556477, 0.233073 (1.401 sec)
13.105... logprob:  0.880010, 0.380208 (1.387 sec)
13.106... logprob:  0.601529, 0.278646 (1.390 sec)
13.107... logprob:  0.644190, 0.305990 (1.440 sec)
13.108... logprob:  0.741345, 0.270833 (1.394 sec)
13.109... logprob:  0.599379, 0.247396 (1.395 sec)
13.110... logprob:  0.745821, 0.330729 (1.389 sec)
13.111... logprob:  0.634421, 0.270833 (1.389 sec)
13.112... logprob:  0.611385, 0.274740 (1.419 sec)
13.113... logprob:  0.563869, 0.235677 (1.394 sec)
13.114... logprob:  0.574725, 0.265625 (1.424 sec)
13.115... logprob:  0.664058, 0.286458 (1.405 sec)
13.116... logprob:  0.586549, 0.263021 (1.394 sec)
13.117... logprob:  0.714755, 0.308594 (1.438 sec)
13.118... logprob:  0.643227, 0.255208 (1.379 sec)
13.119... logprob:  0.570513, 0.260417 (1.394 sec)
13.120... logprob:  0.797874, 0.358073 (1.393 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.552771, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.911422e-03 [2.469634e-07] 
Layer 'conv1' biases: 1.702793e-06 [4.402102e-10] 
Layer 'conv2' weights[0]: 4.902333e-03 [2.462785e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.987121e-09] 
Layer 'conv3' weights[0]: 4.901015e-03 [2.471790e-07] 
Layer 'conv3' biases: 2.785698e-05 [1.936363e-08] 
Layer 'conv4' weights[0]: 4.921334e-03 [2.498019e-07] 
Layer 'conv4' biases: 1.000003e+00 [2.875566e-07] 
Layer 'conv5' weights[0]: 4.997595e-03 [2.562172e-06] 
Layer 'conv5' biases: 9.990753e-01 [2.707856e-06] 
Layer 'fc6' weights[0]: 7.218489e-03 [6.178562e-08] 
Layer 'fc6' biases: 9.999948e-01 [6.060426e-08] 
Layer 'fc7' weights[0]: 7.571226e-03 [1.406196e-07] 
Layer 'fc7' biases: 9.998596e-01 [1.830482e-07] 
Layer 'fc8' weights[0]: 4.389893e-03 [1.639590e-05] 
Layer 'fc8' biases: 1.113805e-02 [2.542965e-05] 
Train error last 800 batches: 0.659008
-------------------------------------------------------
Not saving because 0.552771 > 0.299667 (9.300: -1.18%)
======================================================= (2.380 sec)
13.121... logprob:  0.633609, 0.276042 (1.399 sec)
13.122... logprob:  0.768101, 0.333333 (1.442 sec)
13.123... logprob:  0.696566, 0.285156 (1.388 sec)
13.124... logprob:  0.620742, 0.278646 (1.406 sec)
13.125... logprob:  0.746085, 0.328125 (1.396 sec)
13.126... logprob:  0.722397, 0.320312 (1.393 sec)
13.127... logprob:  0.611860, 0.277344 (1.396 sec)
13.128... logprob:  0.582569, 0.252604 (1.415 sec)
13.129... logprob:  0.817331, 0.332031 (1.414 sec)
13.130... logprob:  0.647270, 0.282552 (1.411 sec)
13.131... logprob:  0.639787, 0.294271 (1.408 sec)
13.132... logprob:  0.730254, 0.321615 (1.427 sec)
13.133... logprob:  0.680106, 0.305990 (1.382 sec)
13.134... logprob:  0.661374, 0.304687 (1.388 sec)
13.135... logprob:  0.652362, 0.282552 (1.394 sec)
13.136... logprob:  0.844377, 0.358073 (1.397 sec)
13.137... logprob:  0.674150, 0.299479 (1.396 sec)
13.138... logprob:  0.552457, 0.259115 (1.436 sec)
13.139... logprob:  0.588924, 0.260417 (1.392 sec)
13.140... logprob:  0.731340, 0.328125 (1.408 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.469097, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.906519e-03 [2.464930e-07] 
Layer 'conv1' biases: 1.705632e-06 [4.119825e-10] 
Layer 'conv2' weights[0]: 4.897426e-03 [2.454076e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.130317e-09] 
Layer 'conv3' weights[0]: 4.896078e-03 [2.463060e-07] 
Layer 'conv3' biases: 2.791953e-05 [1.827339e-08] 
Layer 'conv4' weights[0]: 4.916321e-03 [2.483265e-07] 
Layer 'conv4' biases: 1.000002e+00 [2.749561e-07] 
Layer 'conv5' weights[0]: 4.992308e-03 [2.263258e-06] 
Layer 'conv5' biases: 9.990932e-01 [2.404369e-06] 
Layer 'fc6' weights[0]: 7.217707e-03 [5.728960e-08] 
Layer 'fc6' biases: 9.999948e-01 [5.363876e-08] 
Layer 'fc7' weights[0]: 7.570477e-03 [1.283223e-07] 
Layer 'fc7' biases: 9.998580e-01 [1.444458e-07] 
Layer 'fc8' weights[0]: 4.345951e-03 [1.371524e-05] 
Layer 'fc8' biases: 1.083681e-02 [4.203930e-06] 
Train error last 800 batches: 0.658832
-------------------------------------------------------
Not saving because 0.469097 > 0.299667 (9.300: -1.18%)
======================================================= (2.404 sec)
13.141... logprob:  0.675111, 0.269531 (1.439 sec)
13.142... logprob:  0.713790, 0.320312 (1.399 sec)
13.143... logprob:  0.608122, 0.260417 (1.435 sec)
13.144... logprob:  0.688923, 0.287760 (1.418 sec)
13.145... logprob:  0.557989, 0.242188 (1.420 sec)
13.146... logprob:  0.708900, 0.319010 (1.410 sec)
13.147... logprob:  0.562027, 0.263021 (1.433 sec)
13.148... logprob:  0.573971, 0.246094 (1.393 sec)
13.149... logprob:  0.716788, 0.299479 (1.395 sec)
13.150... logprob:  0.560315, 0.253906 (1.396 sec)
13.151... logprob:  0.539386, 0.259115 (1.406 sec)
13.152... logprob:  0.748619, 0.335938 (1.386 sec)
13.153... logprob:  0.595617, 0.292969 (1.444 sec)
13.154... logprob:  0.625941, 0.276042 (1.392 sec)
13.155... logprob:  0.603330, 0.274740 (1.404 sec)
13.156... logprob:  0.554383, 0.239583 (1.437 sec)
13.157... logprob:  0.535798, 0.260417 (1.392 sec)
13.158... logprob:  0.676114, 0.316406 (1.395 sec)
13.159... logprob:  0.593308, 0.252604 (1.391 sec)
13.160... logprob:  0.717565, 0.309896 (1.391 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.371674, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.901631e-03 [2.466724e-07] 
Layer 'conv1' biases: 1.705583e-06 [4.639591e-10] 
Layer 'conv2' weights[0]: 4.892569e-03 [2.454591e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.785867e-09] 
Layer 'conv3' weights[0]: 4.891179e-03 [2.462265e-07] 
Layer 'conv3' biases: 2.791275e-05 [1.973377e-08] 
Layer 'conv4' weights[0]: 4.911436e-03 [2.486729e-07] 
Layer 'conv4' biases: 1.000004e+00 [3.090301e-07] 
Layer 'conv5' weights[0]: 4.988647e-03 [2.771646e-06] 
Layer 'conv5' biases: 9.990743e-01 [3.026008e-06] 
Layer 'fc6' weights[0]: 7.216952e-03 [6.116655e-08] 
Layer 'fc6' biases: 9.999948e-01 [5.943545e-08] 
Layer 'fc7' weights[0]: 7.569702e-03 [1.440174e-07] 
Layer 'fc7' biases: 9.998606e-01 [2.111669e-07] 
Layer 'fc8' weights[0]: 4.444819e-03 [1.836796e-05] 
Layer 'fc8' biases: 1.145587e-02 [3.031151e-05] 
Train error last 800 batches: 0.658561
-------------------------------------------------------
Not saving because 0.371674 > 0.299667 (9.300: -1.18%)
======================================================= (2.357 sec)
13.161... logprob:  0.570340, 0.264323 (1.404 sec)
13.162... logprob:  0.796253, 0.329427 (1.405 sec)
13.163... logprob:  0.738008, 0.317708 (1.429 sec)
13.164... logprob:  0.631074, 0.257812 (1.417 sec)
13.165... logprob:  0.746248, 0.328125 (1.418 sec)
13.166... logprob:  0.583310, 0.274740 (1.446 sec)
13.167... logprob:  0.664035, 0.307292 (1.423 sec)
13.168... logprob:  0.579688, 0.266927 (1.414 sec)
13.169... logprob:  0.618648, 0.278646 (1.457 sec)
13.170... logprob:  0.702938, 0.302083 (1.403 sec)
13.171... logprob:  0.743669, 0.307292 (1.410 sec)
13.172... logprob:  0.755254, 0.359375 (1.410 sec)
13.173... logprob:  0.625977, 0.276042 (1.415 sec)
13.174... logprob:  0.780212, 0.311198 (1.397 sec)
13.175... logprob:  0.651547, 0.295573 (1.462 sec)
13.176... logprob:  0.771445, 0.328125 (1.405 sec)
13.177... logprob:  0.581599, 0.269531 (1.424 sec)
13.178... logprob:  0.641304, 0.278646 (1.452 sec)
13.179... logprob:  0.621215, 0.299479 (1.400 sec)
13.180... logprob:  0.658345, 0.281250 (1.418 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.451155, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.896727e-03 [2.456807e-07] 
Layer 'conv1' biases: 1.708948e-06 [3.774046e-10] 
Layer 'conv2' weights[0]: 4.887664e-03 [2.450602e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.402486e-09] 
Layer 'conv3' weights[0]: 4.886348e-03 [2.458392e-07] 
Layer 'conv3' biases: 2.802377e-05 [1.694714e-08] 
Layer 'conv4' weights[0]: 4.906555e-03 [2.475832e-07] 
Layer 'conv4' biases: 1.000004e+00 [2.448273e-07] 
Layer 'conv5' weights[0]: 4.983687e-03 [2.290471e-06] 
Layer 'conv5' biases: 9.990980e-01 [2.386155e-06] 
Layer 'fc6' weights[0]: 7.216218e-03 [6.074299e-08] 
Layer 'fc6' biases: 9.999947e-01 [5.860915e-08] 
Layer 'fc7' weights[0]: 7.568949e-03 [1.389807e-07] 
Layer 'fc7' biases: 9.998578e-01 [1.824186e-07] 
Layer 'fc8' weights[0]: 4.367746e-03 [1.682694e-05] 
Layer 'fc8' biases: 1.096477e-02 [3.133769e-05] 
Train error last 800 batches: 0.658932
-------------------------------------------------------
Not saving because 0.451155 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
13.181... logprob:  0.806847, 0.356771 (1.420 sec)
13.182... logprob:  0.673274, 0.286458 (1.418 sec)
13.183... logprob:  0.622007, 0.243490 (1.416 sec)
13.184... logprob:  0.696595, 0.321615 (1.410 sec)
13.185... logprob:  0.572991, 0.242188 (1.392 sec)
13.186... logprob:  0.667302, 0.313802 (1.390 sec)
13.187... logprob:  0.709981, 0.292969 (1.395 sec)
13.188... logprob:  0.671237, 0.305990 (1.390 sec)
13.189... logprob:  0.705346, 0.321615 (1.383 sec)
13.190... logprob:  0.559748, 0.256510 (1.425 sec)
13.191... logprob:  0.672530, 0.307292 (1.405 sec)
13.192... logprob:  0.779756, 0.320312 (1.410 sec)
13.193... logprob:  0.601285, 0.242188 (1.411 sec)
13.194... logprob:  0.599974, 0.269531 (1.408 sec)
13.195... logprob:  0.567026, 0.255208 (1.389 sec)
13.196... logprob:  0.643531, 0.270833 (1.389 sec)
13.197... logprob:  0.664261, 0.279948 (1.393 sec)
13.198... logprob:  0.666646, 0.303385 (1.406 sec)
13.199... logprob:  0.765106, 0.351562 (1.381 sec)
13.200... logprob:  0.688850, 0.292969 (1.432 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.477866, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.891835e-03 [2.458568e-07] 
Layer 'conv1' biases: 1.711298e-06 [4.523114e-10] 
Layer 'conv2' weights[0]: 4.882805e-03 [2.449186e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.823848e-09] 
Layer 'conv3' weights[0]: 4.881455e-03 [2.456702e-07] 
Layer 'conv3' biases: 2.807656e-05 [1.741708e-08] 
Layer 'conv4' weights[0]: 4.901653e-03 [2.478296e-07] 
Layer 'conv4' biases: 1.000003e+00 [2.653202e-07] 
Layer 'conv5' weights[0]: 4.978497e-03 [2.292495e-06] 
Layer 'conv5' biases: 9.990957e-01 [2.436877e-06] 
Layer 'fc6' weights[0]: 7.215471e-03 [5.908444e-08] 
Layer 'fc6' biases: 9.999948e-01 [5.609417e-08] 
Layer 'fc7' weights[0]: 7.568173e-03 [1.339868e-07] 
Layer 'fc7' biases: 9.998584e-01 [1.557847e-07] 
Layer 'fc8' weights[0]: 4.391651e-03 [1.466405e-05] 
Layer 'fc8' biases: 1.113470e-02 [1.314528e-05] 
Train error last 800 batches: 0.659501
-------------------------------------------------------
Not saving because 0.477866 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
13.201... logprob:  0.578479, 0.253906 (1.413 sec)
13.202... logprob:  0.730196, 0.334635 (1.408 sec)
13.203... logprob:  0.638944, 0.281250 (1.446 sec)
13.204... logprob:  0.708921, 0.283854 (1.387 sec)
13.205... logprob:  0.591735, 0.279948 (1.396 sec)
13.206... logprob:  0.608661, 0.264323 (1.397 sec)
13.207... logprob:  0.607349, 0.252604 (1.393 sec)
13.208... logprob:  0.726272, 0.313802 (1.393 sec)
13.209... logprob:  0.571621, 0.282552 (1.416 sec)
13.210... logprob:  0.738236, 0.332031 (1.409 sec)
13.211... logprob:  0.746939, 0.313802 (1.411 sec)
13.212... logprob:  0.738805, 0.299479 (1.410 sec)
13.213... logprob:  0.730730, 0.311198 (1.455 sec)
13.214... logprob:  0.702972, 0.317708 (1.426 sec)
13.215... logprob:  0.600632, 0.270833 (1.411 sec)
13.216... logprob:  0.666013, 0.305990 (1.467 sec)
13.217... logprob:  0.540161, 0.242187 (1.396 sec)
13.218... logprob:  0.674099, 0.292969 (1.414 sec)
13.219... logprob:  0.629737, 0.256510 (1.408 sec)
13.220... logprob:  0.608473, 0.250000 (1.417 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.505656, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.886957e-03 [2.453337e-07] 
Layer 'conv1' biases: 1.713644e-06 [4.752162e-10] 
Layer 'conv2' weights[0]: 4.877912e-03 [2.446137e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.403545e-09] 
Layer 'conv3' weights[0]: 4.876531e-03 [2.454040e-07] 
Layer 'conv3' biases: 2.810980e-05 [1.778686e-08] 
Layer 'conv4' weights[0]: 4.896771e-03 [2.476680e-07] 
Layer 'conv4' biases: 1.000003e+00 [2.967326e-07] 
Layer 'conv5' weights[0]: 4.973795e-03 [2.501591e-06] 
Layer 'conv5' biases: 9.991020e-01 [2.638678e-06] 
Layer 'fc6' weights[0]: 7.214737e-03 [5.785485e-08] 
Layer 'fc6' biases: 9.999949e-01 [5.403857e-08] 
Layer 'fc7' weights[0]: 7.567414e-03 [1.322662e-07] 
Layer 'fc7' biases: 9.998576e-01 [1.560207e-07] 
Layer 'fc8' weights[0]: 4.370125e-03 [1.436769e-05] 
Layer 'fc8' biases: 1.097075e-02 [1.425861e-05] 
Train error last 800 batches: 0.659431
-------------------------------------------------------
Not saving because 0.505656 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
13.221... logprob:  0.587771, 0.264323 (1.405 sec)
13.222... logprob:  0.714216, 0.308594 (1.461 sec)
13.223... logprob:  0.684760, 0.285156 (1.432 sec)
13.224... logprob:  0.633868, 0.286458 (1.425 sec)
13.225... logprob:  0.612159, 0.252604 (1.446 sec)
13.226... logprob:  0.593453, 0.266927 (1.415 sec)
13.227... logprob:  0.605808, 0.253906 (1.421 sec)
13.228... logprob:  0.592673, 0.273438 (1.412 sec)
13.229... logprob:  0.782165, 0.317708 (1.412 sec)
13.230... logprob:  0.692290, 0.324219 (1.415 sec)
13.231... logprob:  0.672110, 0.295573 (1.400 sec)
13.232... logprob:  0.671362, 0.308594 (1.453 sec)
13.233... logprob:  0.704120, 0.299479 (1.420 sec)
13.234... logprob:  0.819471, 0.324219 (1.407 sec)
13.235... logprob:  0.701496, 0.296875 (1.462 sec)
13.236... logprob:  0.645157, 0.265625 (1.397 sec)
13.237... logprob:  0.645832, 0.287760 (1.412 sec)
13.238... logprob:  0.548392, 0.240885 (1.412 sec)
13.239... logprob:  0.631259, 0.285156 (1.412 sec)
13.240... logprob:  0.720946, 0.316406 (1.392 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.524780, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.882094e-03 [2.454249e-07] 
Layer 'conv1' biases: 1.714524e-06 [4.171696e-10] 
Layer 'conv2' weights[0]: 4.873043e-03 [2.443045e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.331583e-09] 
Layer 'conv3' weights[0]: 4.871677e-03 [2.451283e-07] 
Layer 'conv3' biases: 2.816268e-05 [1.679744e-08] 
Layer 'conv4' weights[0]: 4.891844e-03 [2.466690e-07] 
Layer 'conv4' biases: 1.000003e+00 [2.339105e-07] 
Layer 'conv5' weights[0]: 4.969446e-03 [2.324379e-06] 
Layer 'conv5' biases: 9.991034e-01 [2.423369e-06] 
Layer 'fc6' weights[0]: 7.213973e-03 [5.938487e-08] 
Layer 'fc6' biases: 9.999949e-01 [5.649546e-08] 
Layer 'fc7' weights[0]: 7.566681e-03 [1.329143e-07] 
Layer 'fc7' biases: 9.998567e-01 [1.536615e-07] 
Layer 'fc8' weights[0]: 4.370520e-03 [1.417261e-05] 
Layer 'fc8' biases: 1.096066e-02 [8.125778e-06] 
Train error last 800 batches: 0.658892
-------------------------------------------------------
Not saving because 0.524780 > 0.299667 (9.300: -1.18%)
======================================================= (2.376 sec)
13.241... logprob:  0.734019, 0.321615 (1.464 sec)
13.242... logprob:  0.611776, 0.286458 (1.429 sec)
13.243... logprob:  0.651162, 0.268229 (1.429 sec)
13.244... logprob:  0.514439, 0.222656 (1.447 sec)
13.245... logprob:  0.684573, 0.309896 (1.414 sec)
13.246... logprob:  0.655059, 0.307292 (1.410 sec)
13.247... logprob:  0.633611, 0.277344 (1.411 sec)
13.248... logprob:  0.592295, 0.263021 (1.416 sec)
13.249... logprob:  0.761523, 0.321615 (1.419 sec)
13.250... logprob:  0.680379, 0.290365 (1.403 sec)
13.251... logprob:  0.527384, 0.246094 (1.455 sec)
13.252... logprob:  0.522104, 0.225260 (1.423 sec)
13.253... logprob:  0.546007, 0.231771 (1.415 sec)
13.254... logprob:  0.571723, 0.250000 (1.468 sec)
13.255... logprob:  0.504195, 0.223958 (1.392 sec)
13.256... logprob:  0.521154, 0.222656 (1.420 sec)
13.257... logprob:  0.609139, 0.282552 (1.410 sec)
13.258... logprob:  0.689438, 0.324219 (1.419 sec)
13.259... logprob:  0.547966, 0.238281 (1.399 sec)
13.260... logprob:  0.526738, 0.257812 (1.454 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.505538, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.877210e-03 [2.454652e-07] 
Layer 'conv1' biases: 1.712877e-06 [5.747519e-10] 
Layer 'conv2' weights[0]: 4.868183e-03 [2.447105e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.124651e-09] 
Layer 'conv3' weights[0]: 4.866841e-03 [2.462013e-07] 
Layer 'conv3' biases: 2.814723e-05 [2.383218e-08] 
Layer 'conv4' weights[0]: 4.886929e-03 [2.497077e-07] 
Layer 'conv4' biases: 1.000006e+00 [4.012823e-07] 
Layer 'conv5' weights[0]: 4.966165e-03 [3.686243e-06] 
Layer 'conv5' biases: 9.990671e-01 [4.077045e-06] 
Layer 'fc6' weights[0]: 7.213243e-03 [7.791265e-08] 
Layer 'fc6' biases: 9.999946e-01 [8.347519e-08] 
Layer 'fc7' weights[0]: 7.565903e-03 [1.953430e-07] 
Layer 'fc7' biases: 9.998592e-01 [3.608115e-07] 
Layer 'fc8' weights[0]: 4.496085e-03 [2.673248e-05] 
Layer 'fc8' biases: 1.184712e-02 [6.348680e-05] 
Train error last 800 batches: 0.658231
-------------------------------------------------------
Not saving because 0.505538 > 0.299667 (9.300: -1.18%)
======================================================= (2.382 sec)
13.261... logprob:  0.616392, 0.253906 (1.430 sec)
13.262... logprob:  0.677774, 0.295573 (1.433 sec)
13.263... logprob:  0.671255, 0.261719 (1.504 sec)
13.264... logprob:  0.598582, 0.255208 (1.427 sec)
13.265... logprob:  0.640540, 0.305990 (1.416 sec)
13.266... logprob:  0.624880, 0.259115 (1.409 sec)
13.267... logprob:  0.693128, 0.291667 (1.436 sec)
13.268... logprob:  0.699052, 0.294271 (1.412 sec)
13.269... logprob:  0.756473, 0.335938 (1.401 sec)
13.270... logprob:  0.734645, 0.322917 (1.454 sec)
13.271... logprob:  0.619322, 0.251302 (1.419 sec)
13.272... logprob:  0.678310, 0.279948 (1.413 sec)
13.273... logprob:  0.704566, 0.292969 (1.467 sec)
13.274... logprob:  0.687506, 0.294271 (1.392 sec)
13.275... logprob:  0.711208, 0.299479 (1.414 sec)
13.276... logprob:  0.511621, 0.225260 (1.416 sec)
13.277... logprob:  0.675776, 0.279948 (1.417 sec)
13.278... logprob:  0.568704, 0.255208 (1.420 sec)
13.279... logprob:  0.554532, 0.255208 (1.451 sec)
13.280... logprob:  0.471986, 0.218750 (1.402 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.446216, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.872330e-03 [2.444750e-07] 
Layer 'conv1' biases: 1.714771e-06 [4.690947e-10] 
Layer 'conv2' weights[0]: 4.863298e-03 [2.436760e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.101321e-09] 
Layer 'conv3' weights[0]: 4.861961e-03 [2.441878e-07] 
Layer 'conv3' biases: 2.821155e-05 [1.499914e-08] 
Layer 'conv4' weights[0]: 4.882101e-03 [2.461515e-07] 
Layer 'conv4' biases: 1.000005e+00 [2.303348e-07] 
Layer 'conv5' weights[0]: 4.961035e-03 [1.941344e-06] 
Layer 'conv5' biases: 9.990901e-01 [2.020910e-06] 
Layer 'fc6' weights[0]: 7.212525e-03 [5.535576e-08] 
Layer 'fc6' biases: 9.999948e-01 [5.064076e-08] 
Layer 'fc7' weights[0]: 7.565197e-03 [1.214824e-07] 
Layer 'fc7' biases: 9.998571e-01 [1.368859e-07] 
Layer 'fc8' weights[0]: 4.411373e-03 [1.230919e-05] 
Layer 'fc8' biases: 1.119503e-02 [7.841856e-06] 
Train error last 800 batches: 0.657783
-------------------------------------------------------
Not saving because 0.446216 > 0.299667 (9.300: -1.18%)
======================================================= (2.400 sec)
13.281... logprob:  0.583240, 0.240885 (1.427 sec)
13.282... logprob:  0.571154, 0.247396 (1.422 sec)
13.283... logprob:  0.659257, 0.300781 (1.414 sec)
13.284... logprob:  0.634687, 0.302083 (1.405 sec)
13.285... logprob:  0.689975, 0.321615 (1.440 sec)
13.286... logprob:  0.750343, 0.361979 (1.430 sec)
13.287... logprob:  0.609880, 0.255208 (1.425 sec)
13.288... logprob:  0.598017, 0.257812 (1.427 sec)
13.289... logprob:  0.640658, 0.292969 (1.436 sec)
13.290... logprob:  0.701940, 0.272135 (1.406 sec)
13.291... logprob:  0.634698, 0.291667 (1.417 sec)
13.292... logprob:  0.716670, 0.315104 (1.424 sec)
13.293... logprob:  0.754436, 0.317708 (1.419 sec)
13.294... logprob:  0.674902, 0.302083 (1.403 sec)
13.295... logprob:  0.589852, 0.261719 (1.455 sec)
13.296... logprob:  0.573534, 0.260417 (1.419 sec)
13.297... logprob:  0.615491, 0.292969 (1.420 sec)
13.298... logprob:  0.617352, 0.276042 (1.458 sec)
13.299... logprob:  0.668842, 0.276042 (1.398 sec)
13.300... logprob:  0.672764, 0.302083 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.426978, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.867467e-03 [2.444235e-07] 
Layer 'conv1' biases: 1.717390e-06 [4.160834e-10] 
Layer 'conv2' weights[0]: 4.858458e-03 [2.435683e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.005068e-09] 
Layer 'conv3' weights[0]: 4.857066e-03 [2.441263e-07] 
Layer 'conv3' biases: 2.822020e-05 [1.577304e-08] 
Layer 'conv4' weights[0]: 4.877231e-03 [2.460930e-07] 
Layer 'conv4' biases: 1.000006e+00 [2.524710e-07] 
Layer 'conv5' weights[0]: 4.956716e-03 [2.175865e-06] 
Layer 'conv5' biases: 9.990858e-01 [2.435575e-06] 
Layer 'fc6' weights[0]: 7.211809e-03 [5.657503e-08] 
Layer 'fc6' biases: 9.999947e-01 [5.219785e-08] 
Layer 'fc7' weights[0]: 7.564427e-03 [1.269093e-07] 
Layer 'fc7' biases: 9.998569e-01 [1.422844e-07] 
Layer 'fc8' weights[0]: 4.425924e-03 [1.339443e-05] 
Layer 'fc8' biases: 1.130982e-02 [1.088127e-05] 
Train error last 800 batches: 0.657922
-------------------------------------------------------
Not saving because 0.426978 > 0.299667 (9.300: -1.18%)
======================================================= (2.403 sec)
13.301... logprob:  0.529307, 0.266927 (1.415 sec)
13.302... logprob:  0.751750, 0.319010 (1.422 sec)
13.303... logprob:  0.576408, 0.236979 (1.404 sec)
13.304... logprob:  0.656066, 0.261719 (1.437 sec)
13.305... logprob:  0.682777, 0.295573 (1.436 sec)
13.306... logprob:  0.625079, 0.279948 (1.427 sec)
13.307... logprob:  0.665266, 0.299479 (1.434 sec)
13.308... logprob:  0.597222, 0.264323 (1.452 sec)
13.309... logprob:  0.714679, 0.326823 (1.415 sec)
13.310... logprob:  0.774612, 0.330729 (1.424 sec)
13.311... logprob:  0.743423, 0.307292 (1.434 sec)
13.312... logprob:  0.616183, 0.264323 (1.416 sec)
13.313... logprob:  0.699397, 0.316406 (1.416 sec)
13.314... logprob:  0.642367, 0.302083 (1.457 sec)
13.315... logprob:  0.606312, 0.282552 (1.436 sec)
13.316... logprob:  0.657814, 0.266927 (1.418 sec)
13.317... logprob:  0.628641, 0.304687 (1.479 sec)
13.318... logprob:  0.606691, 0.255208 (1.421 sec)
13.319... logprob:  0.685978, 0.290365 (1.414 sec)
13.320... logprob:  0.633437, 0.300781 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.555828, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.862604e-03 [2.440574e-07] 
Layer 'conv1' biases: 1.717964e-06 [3.568311e-10] 
Layer 'conv2' weights[0]: 4.853582e-03 [2.431552e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.766495e-09] 
Layer 'conv3' weights[0]: 4.852210e-03 [2.440479e-07] 
Layer 'conv3' biases: 2.819989e-05 [1.674651e-08] 
Layer 'conv4' weights[0]: 4.872341e-03 [2.460085e-07] 
Layer 'conv4' biases: 1.000008e+00 [2.601224e-07] 
Layer 'conv5' weights[0]: 4.953166e-03 [2.298708e-06] 
Layer 'conv5' biases: 9.990869e-01 [2.554126e-06] 
Layer 'fc6' weights[0]: 7.211047e-03 [5.774622e-08] 
Layer 'fc6' biases: 9.999945e-01 [5.401664e-08] 
Layer 'fc7' weights[0]: 7.563709e-03 [1.292192e-07] 
Layer 'fc7' biases: 9.998564e-01 [1.504170e-07] 
Layer 'fc8' weights[0]: 4.402810e-03 [1.422834e-05] 
Layer 'fc8' biases: 1.117906e-02 [1.532262e-05] 
Train error last 800 batches: 0.657867
-------------------------------------------------------
Not saving because 0.555828 > 0.299667 (9.300: -1.18%)
======================================================= (2.394 sec)
13.321... logprob:  0.510502, 0.200521 (1.432 sec)
13.322... logprob:  0.690598, 0.282552 (1.423 sec)
13.323... logprob:  0.589547, 0.246094 (1.477 sec)
13.324... logprob:  0.750455, 0.312500 (1.422 sec)
13.325... logprob:  0.579612, 0.240885 (1.427 sec)
13.326... logprob:  0.651548, 0.294271 (1.456 sec)
13.327... logprob:  0.740442, 0.321615 (1.420 sec)
13.328... logprob:  0.714469, 0.291667 (1.426 sec)
13.329... logprob:  0.594416, 0.260417 (1.424 sec)
13.330... logprob:  0.652231, 0.290364 (1.416 sec)
13.331... logprob:  0.554475, 0.244792 (1.418 sec)
13.332... logprob:  0.646473, 0.268229 (1.440 sec)
13.333... logprob:  0.525886, 0.223958 (1.439 sec)
13.334... logprob:  0.682429, 0.304687 (1.433 sec)
13.335... logprob:  0.659965, 0.285156 (1.434 sec)
13.336... logprob:  0.710239, 0.313802 (1.451 sec)
13.337... logprob:  0.779733, 0.337240 (1.407 sec)
13.338... logprob:  0.621393, 0.286458 (1.414 sec)
13.339... logprob:  0.670300, 0.295573 (1.417 sec)
13.340... logprob:  0.564493, 0.252604 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.394103, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.857725e-03 [2.440485e-07] 
Layer 'conv1' biases: 1.717718e-06 [3.974125e-10] 
Layer 'conv2' weights[0]: 4.848747e-03 [2.432438e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.261231e-09] 
Layer 'conv3' weights[0]: 4.847367e-03 [2.439755e-07] 
Layer 'conv3' biases: 2.823623e-05 [1.720570e-08] 
Layer 'conv4' weights[0]: 4.867459e-03 [2.459411e-07] 
Layer 'conv4' biases: 1.000010e+00 [2.670511e-07] 
Layer 'conv5' weights[0]: 4.949028e-03 [2.428198e-06] 
Layer 'conv5' biases: 9.990915e-01 [2.647716e-06] 
Layer 'fc6' weights[0]: 7.210286e-03 [5.855574e-08] 
Layer 'fc6' biases: 9.999945e-01 [5.519211e-08] 
Layer 'fc7' weights[0]: 7.562876e-03 [1.325770e-07] 
Layer 'fc7' biases: 9.998564e-01 [1.617499e-07] 
Layer 'fc8' weights[0]: 4.406695e-03 [1.556832e-05] 
Layer 'fc8' biases: 1.116232e-02 [2.202397e-05] 
Train error last 800 batches: 0.657467
-------------------------------------------------------
Not saving because 0.394103 > 0.299667 (9.300: -1.18%)
======================================================= (2.391 sec)
13.341... logprob:  0.730041, 0.303385 (1.428 sec)
13.342... logprob:  0.708241, 0.287760 (1.467 sec)
13.343... logprob:  0.625664, 0.279948 (1.435 sec)
13.344... logprob:  0.587467, 0.255208 (1.503 sec)
13.345... logprob:  0.647387, 0.285156 (1.439 sec)
13.346... logprob:  0.674911, 0.283854 (1.428 sec)
13.347... logprob:  0.666017, 0.287760 (1.479 sec)
13.348... logprob:  0.653720, 0.304688 (1.437 sec)
13.349... logprob:  0.708460, 0.325521 (1.430 sec)
13.350... logprob:  0.591162, 0.250000 (1.431 sec)
13.351... logprob:  0.738438, 0.304687 (1.423 sec)
13.352... logprob:  0.574576, 0.265625 (1.427 sec)
13.353... logprob:  0.697165, 0.308594 (1.488 sec)
13.354... logprob:  0.787614, 0.320312 (1.429 sec)
13.355... logprob:  0.602731, 0.250000 (1.445 sec)
13.356... logprob:  0.655804, 0.264323 (1.468 sec)
13.357... logprob:  0.637735, 0.320312 (1.428 sec)
13.358... logprob:  0.552394, 0.244792 (1.429 sec)
13.359... logprob:  0.724949, 0.292969 (1.428 sec)
13.360... logprob:  0.709175, 0.274740 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.532772, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.852886e-03 [2.433796e-07] 
Layer 'conv1' biases: 1.720336e-06 [3.508017e-10] 
Layer 'conv2' weights[0]: 4.843912e-03 [2.430025e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.208243e-09] 
Layer 'conv3' weights[0]: 4.842514e-03 [2.436130e-07] 
Layer 'conv3' biases: 2.823822e-05 [1.820306e-08] 
Layer 'conv4' weights[0]: 4.862582e-03 [2.455021e-07] 
Layer 'conv4' biases: 1.000011e+00 [2.589325e-07] 
Layer 'conv5' weights[0]: 4.944992e-03 [2.492244e-06] 
Layer 'conv5' biases: 9.990933e-01 [2.638172e-06] 
Layer 'fc6' weights[0]: 7.209558e-03 [6.051709e-08] 
Layer 'fc6' biases: 9.999943e-01 [5.798875e-08] 
Layer 'fc7' weights[0]: 7.562143e-03 [1.364946e-07] 
Layer 'fc7' biases: 9.998565e-01 [1.560180e-07] 
Layer 'fc8' weights[0]: 4.416208e-03 [1.472454e-05] 
Layer 'fc8' biases: 1.125750e-02 [1.133098e-05] 
Train error last 800 batches: 0.657053
-------------------------------------------------------
Not saving because 0.532772 > 0.299667 (9.300: -1.18%)
======================================================= (2.362 sec)
13.361... logprob:  0.627065, 0.272135 (1.433 sec)
13.362... logprob:  0.688078, 0.309896 (1.478 sec)
13.363... logprob:  0.674471, 0.287760 (1.436 sec)
13.364... logprob:  0.677056, 0.311198 (1.450 sec)
13.365... logprob:  0.671618, 0.273438 (1.461 sec)
13.366... logprob:  0.668490, 0.292969 (1.437 sec)
13.367... logprob:  0.620647, 0.294271 (1.433 sec)
13.368... logprob:  0.785724, 0.342448 (1.429 sec)
13.369... logprob:  0.572665, 0.266927 (1.423 sec)
13.370... logprob:  0.646637, 0.285156 (1.436 sec)
13.371... logprob:  0.662098, 0.300781 (1.451 sec)
13.372... logprob:  0.797929, 0.338542 (1.448 sec)
13.373... logprob:  0.644276, 0.276042 (1.448 sec)
13.374... logprob:  0.701505, 0.286458 (1.444 sec)
13.375... logprob:  0.573081, 0.261719 (1.460 sec)
13.376... logprob:  0.578604, 0.268229 (1.441 sec)
13.377... logprob:  0.621310, 0.270833 (1.423 sec)
13.378... logprob:  0.648617, 0.270833 (1.423 sec)
13.379... logprob:  0.683271, 0.295573 (1.431 sec)
13.380... logprob:  0.717066, 0.325521 (1.435 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.384834, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.848033e-03 [2.431342e-07] 
Layer 'conv1' biases: 1.720798e-06 [3.942599e-10] 
Layer 'conv2' weights[0]: 4.839079e-03 [2.426580e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.552854e-09] 
Layer 'conv3' weights[0]: 4.837679e-03 [2.434544e-07] 
Layer 'conv3' biases: 2.823124e-05 [1.596101e-08] 
Layer 'conv4' weights[0]: 4.857759e-03 [2.460081e-07] 
Layer 'conv4' biases: 1.000012e+00 [2.638664e-07] 
Layer 'conv5' weights[0]: 4.940473e-03 [2.519946e-06] 
Layer 'conv5' biases: 9.990892e-01 [2.595013e-06] 
Layer 'fc6' weights[0]: 7.208822e-03 [6.115933e-08] 
Layer 'fc6' biases: 9.999943e-01 [5.885985e-08] 
Layer 'fc7' weights[0]: 7.561362e-03 [1.443331e-07] 
Layer 'fc7' biases: 9.998562e-01 [1.959253e-07] 
Layer 'fc8' weights[0]: 4.424881e-03 [1.769217e-05] 
Layer 'fc8' biases: 1.133763e-02 [3.451847e-05] 
Train error last 800 batches: 0.657248
-------------------------------------------------------
Not saving because 0.384834 > 0.299667 (9.300: -1.18%)
======================================================= (2.356 sec)
13.381... logprob:  0.764399, 0.337240 (1.472 sec)
13.382... logprob:  0.706044, 0.296875 (1.491 sec)
13.383... logprob:  0.573105, 0.268229 (1.436 sec)
13.384... logprob:  0.740947, 0.322917 (1.472 sec)
13.385... logprob:  0.696185, 0.321615 (1.431 sec)
13.386... logprob:  0.749183, 0.299479 (1.424 sec)
13.387... logprob:  0.605578, 0.264323 (1.429 sec)
13.388... logprob:  0.719826, 0.326823 (1.431 sec)
13.389... logprob:  0.682569, 0.321615 (1.431 sec)
13.390... logprob:  0.578487, 0.227865 (1.479 sec)
13.391... logprob:  0.551958, 0.236979 (1.441 sec)
13.392... logprob:  0.654190, 0.307292 (1.430 sec)
13.393... logprob:  0.670514, 0.260417 (1.481 sec)
13.394... logprob:  0.604885, 0.270833 (1.431 sec)
13.395... logprob:  0.611481, 0.302083 (1.432 sec)
13.396... logprob:  0.515163, 0.225260 (1.425 sec)
13.397... logprob:  0.665371, 0.303385 (1.429 sec)
13.398... logprob:  0.655308, 0.298177 (1.426 sec)
13.399... logprob:  0.546276, 0.251302 (1.477 sec)
13.400... logprob:  0.780310, 0.305990 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.403660, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.843175e-03 [2.436018e-07] 
Layer 'conv1' biases: 1.719756e-06 [3.307760e-10] 
Layer 'conv2' weights[0]: 4.834233e-03 [2.423477e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.033958e-09] 
Layer 'conv3' weights[0]: 4.832877e-03 [2.428602e-07] 
Layer 'conv3' biases: 2.818381e-05 [1.411500e-08] 
Layer 'conv4' weights[0]: 4.852840e-03 [2.451313e-07] 
Layer 'conv4' biases: 1.000013e+00 [2.485509e-07] 
Layer 'conv5' weights[0]: 4.935819e-03 [2.262329e-06] 
Layer 'conv5' biases: 9.990844e-01 [2.428524e-06] 
Layer 'fc6' weights[0]: 7.208053e-03 [5.824532e-08] 
Layer 'fc6' biases: 9.999944e-01 [5.448319e-08] 
Layer 'fc7' weights[0]: 7.560585e-03 [1.322433e-07] 
Layer 'fc7' biases: 9.998566e-01 [1.519763e-07] 
Layer 'fc8' weights[0]: 4.441504e-03 [1.415093e-05] 
Layer 'fc8' biases: 1.146201e-02 [1.488350e-05] 
Train error last 800 batches: 0.656873
-------------------------------------------------------
Not saving because 0.403660 > 0.299667 (9.300: -1.18%)
======================================================= (2.368 sec)
13.401... logprob:  0.616699, 0.276042 (1.447 sec)
13.402... logprob:  0.785416, 0.348958 (1.479 sec)
13.403... logprob:  0.702597, 0.322917 (1.428 sec)
13.404... logprob:  0.731700, 0.292969 (1.435 sec)
13.405... logprob:  0.797439, 0.338542 (1.432 sec)
13.406... logprob:  0.632662, 0.291667 (1.424 sec)
13.407... logprob:  0.696941, 0.322917 (1.426 sec)
13.408... logprob:  0.600599, 0.264323 (1.472 sec)
13.409... logprob:  0.575127, 0.252604 (1.436 sec)
13.410... logprob:  0.836673, 0.339844 (1.450 sec)
13.411... logprob:  0.591649, 0.278646 (1.463 sec)
13.412... logprob:  0.729237, 0.307292 (1.433 sec)
13.413... logprob:  0.765713, 0.328125 (1.430 sec)
13.414... logprob:  0.631975, 0.290365 (1.425 sec)
13.415... logprob:  0.577206, 0.256510 (1.424 sec)
13.416... logprob:  0.618389, 0.273437 (1.435 sec)
13.417... logprob:  0.645533, 0.277344 (1.462 sec)
13.418... logprob:  0.589833, 0.256510 (1.448 sec)
13.419... logprob:  0.589211, 0.290365 (1.440 sec)
13.420... logprob:  0.628548, 0.290365 (1.451 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.445340, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.838369e-03 [2.430313e-07] 
Layer 'conv1' biases: 1.721122e-06 [4.427991e-10] 
Layer 'conv2' weights[0]: 4.829387e-03 [2.425036e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.299581e-09] 
Layer 'conv3' weights[0]: 4.828034e-03 [2.439998e-07] 
Layer 'conv3' biases: 2.818629e-05 [2.315254e-08] 
Layer 'conv4' weights[0]: 4.848045e-03 [2.474417e-07] 
Layer 'conv4' biases: 1.000015e+00 [4.054968e-07] 
Layer 'conv5' weights[0]: 4.932155e-03 [3.151588e-06] 
Layer 'conv5' biases: 9.990931e-01 [3.573192e-06] 
Layer 'fc6' weights[0]: 7.207294e-03 [6.815554e-08] 
Layer 'fc6' biases: 9.999943e-01 [6.882935e-08] 
Layer 'fc7' weights[0]: 7.559840e-03 [1.661155e-07] 
Layer 'fc7' biases: 9.998553e-01 [2.766928e-07] 
Layer 'fc8' weights[0]: 4.415557e-03 [2.239123e-05] 
Layer 'fc8' biases: 1.121720e-02 [4.900474e-05] 
Train error last 800 batches: 0.657082
-------------------------------------------------------
Not saving because 0.445340 > 0.299667 (9.300: -1.18%)
======================================================= (2.367 sec)
13.421... logprob:  0.617760, 0.298177 (1.453 sec)
13.422... logprob:  0.719561, 0.295573 (1.442 sec)
13.423... logprob:  0.705697, 0.283854 (1.430 sec)
13.424... logprob:  0.490309, 0.217448 (1.428 sec)
13.425... logprob:  0.523412, 0.256510 (1.438 sec)
13.426... logprob:  0.650591, 0.260417 (1.442 sec)
13.427... logprob:  0.709751, 0.273438 (1.460 sec)
13.428... logprob:  0.804681, 0.361979 (1.450 sec)
13.429... logprob:  0.635834, 0.263021 (1.447 sec)
13.430... logprob:  0.536733, 0.240885 (1.469 sec)
13.431... logprob:  0.751638, 0.317708 (1.433 sec)
13.432... logprob:  0.671581, 0.282552 (1.416 sec)
13.433... logprob:  0.584255, 0.270833 (1.431 sec)
13.434... logprob:  0.801220, 0.355469 (1.438 sec)
13.435... logprob:  0.783590, 0.333333 (1.424 sec)
13.436... logprob:  0.596264, 0.252604 (1.473 sec)
13.437... logprob:  0.622008, 0.265625 (1.436 sec)
13.438... logprob:  0.774395, 0.311198 (1.423 sec)
13.439... logprob:  0.546184, 0.259115 (1.486 sec)
13.440... logprob:  0.588403, 0.250000 (1.425 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.518597, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.833525e-03 [2.428583e-07] 
Layer 'conv1' biases: 1.721428e-06 [4.757475e-10] 
Layer 'conv2' weights[0]: 4.824568e-03 [2.420025e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.483831e-09] 
Layer 'conv3' weights[0]: 4.823207e-03 [2.426973e-07] 
Layer 'conv3' biases: 2.825344e-05 [1.672570e-08] 
Layer 'conv4' weights[0]: 4.843174e-03 [2.448875e-07] 
Layer 'conv4' biases: 1.000016e+00 [2.539765e-07] 
Layer 'conv5' weights[0]: 4.927709e-03 [2.246637e-06] 
Layer 'conv5' biases: 9.990938e-01 [2.327630e-06] 
Layer 'fc6' weights[0]: 7.206550e-03 [6.206369e-08] 
Layer 'fc6' biases: 9.999943e-01 [6.021072e-08] 
Layer 'fc7' weights[0]: 7.559104e-03 [1.396839e-07] 
Layer 'fc7' biases: 9.998552e-01 [1.745653e-07] 
Layer 'fc8' weights[0]: 4.429969e-03 [1.536554e-05] 
Layer 'fc8' biases: 1.134033e-02 [2.377920e-05] 
Train error last 800 batches: 0.657079
-------------------------------------------------------
Not saving because 0.518597 > 0.299667 (9.300: -1.18%)
======================================================= (2.397 sec)
13.441... logprob:  0.757003, 0.334635 (1.430 sec)
13.442... logprob:  0.571684, 0.250000 (1.438 sec)
13.443... logprob:  0.673290, 0.299479 (1.433 sec)
13.444... logprob:  0.574403, 0.272135 (1.434 sec)
13.445... logprob:  0.586151, 0.234375 (1.486 sec)
13.446... logprob:  0.643528, 0.286458 (1.439 sec)
13.447... logprob:  0.691152, 0.299479 (1.441 sec)
13.448... logprob:  0.542047, 0.236979 (1.477 sec)
13.449... logprob:  0.596676, 0.255208 (1.431 sec)
13.450... logprob:  0.512959, 0.233073 (1.435 sec)
13.451... logprob:  0.627287, 0.286458 (1.433 sec)
13.452... logprob:  0.695713, 0.294271 (1.427 sec)
13.453... logprob:  0.679829, 0.326823 (1.433 sec)
13.454... logprob:  0.714373, 0.328125 (1.476 sec)
13.455... logprob:  0.652941, 0.272135 (1.432 sec)
13.456... logprob:  0.566510, 0.234375 (1.440 sec)
13.457... logprob:  0.583182, 0.238281 (1.474 sec)
13.458... logprob:  0.665312, 0.298177 (1.430 sec)
13.459... logprob:  0.738344, 0.315104 (1.430 sec)
13.460... logprob:  0.506618, 0.210937 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.398437, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.828693e-03 [2.429456e-07] 
Layer 'conv1' biases: 1.721886e-06 [5.362537e-10] 
Layer 'conv2' weights[0]: 4.819749e-03 [2.421690e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.279828e-09] 
Layer 'conv3' weights[0]: 4.818376e-03 [2.429810e-07] 
Layer 'conv3' biases: 2.827412e-05 [2.017354e-08] 
Layer 'conv4' weights[0]: 4.838376e-03 [2.451717e-07] 
Layer 'conv4' biases: 1.000016e+00 [2.914039e-07] 
Layer 'conv5' weights[0]: 4.923006e-03 [2.501298e-06] 
Layer 'conv5' biases: 9.990882e-01 [2.652188e-06] 
Layer 'fc6' weights[0]: 7.205768e-03 [6.264840e-08] 
Layer 'fc6' biases: 9.999944e-01 [6.084365e-08] 
Layer 'fc7' weights[0]: 7.558374e-03 [1.463955e-07] 
Layer 'fc7' biases: 9.998565e-01 [2.080229e-07] 
Layer 'fc8' weights[0]: 4.475902e-03 [1.781972e-05] 
Layer 'fc8' biases: 1.166392e-02 [3.709444e-05] 
Train error last 800 batches: 0.656777
-------------------------------------------------------
Not saving because 0.398437 > 0.299667 (9.300: -1.18%)
======================================================= (2.392 sec)
13.461... logprob:  0.600990, 0.278646 (1.429 sec)
13.462... logprob:  0.710491, 0.292969 (1.435 sec)
13.463... logprob:  0.619849, 0.263021 (1.467 sec)
13.464... logprob:  0.719039, 0.303385 (1.448 sec)
13.465... logprob:  0.674106, 0.308594 (1.456 sec)
13.466... logprob:  0.543907, 0.266927 (1.460 sec)
13.467... logprob:  0.627561, 0.257812 (1.440 sec)
13.468... logprob:  0.616046, 0.279948 (1.435 sec)
13.469... logprob:  0.577590, 0.251302 (1.428 sec)
13.470... logprob:  0.623331, 0.270833 (1.421 sec)
13.471... logprob:  0.666438, 0.304687 (1.435 sec)
13.472... logprob:  0.673031, 0.289062 (1.451 sec)
13.473... logprob:  0.610650, 0.261719 (1.449 sec)
13.474... logprob:  0.712195, 0.285156 (1.449 sec)
13.475... logprob:  0.690593, 0.291667 (1.444 sec)
13.476... logprob:  0.650314, 0.270833 (1.465 sec)
13.477... logprob:  0.558666, 0.252604 (1.432 sec)
13.478... logprob:  0.695354, 0.289062 (1.423 sec)
13.479... logprob:  0.612858, 0.274740 (1.424 sec)
13.480... logprob:  0.693821, 0.298177 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.496646, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.823904e-03 [2.420727e-07] 
Layer 'conv1' biases: 1.723819e-06 [4.737247e-10] 
Layer 'conv2' weights[0]: 4.814922e-03 [2.413088e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.862181e-09] 
Layer 'conv3' weights[0]: 4.813547e-03 [2.424474e-07] 
Layer 'conv3' biases: 2.835052e-05 [1.976810e-08] 
Layer 'conv4' weights[0]: 4.833525e-03 [2.442663e-07] 
Layer 'conv4' biases: 1.000015e+00 [2.945526e-07] 
Layer 'conv5' weights[0]: 4.917455e-03 [2.721129e-06] 
Layer 'conv5' biases: 9.990979e-01 [2.889816e-06] 
Layer 'fc6' weights[0]: 7.205009e-03 [6.442425e-08] 
Layer 'fc6' biases: 9.999944e-01 [6.355472e-08] 
Layer 'fc7' weights[0]: 7.557618e-03 [1.507931e-07] 
Layer 'fc7' biases: 9.998558e-01 [2.159310e-07] 
Layer 'fc8' weights[0]: 4.474770e-03 [1.750127e-05] 
Layer 'fc8' biases: 1.171225e-02 [2.899271e-05] 
Train error last 800 batches: 0.656445
-------------------------------------------------------
Not saving because 0.496646 > 0.299667 (9.300: -1.18%)
======================================================= (2.388 sec)
13.481... logprob:  0.709665, 0.312500 (1.439 sec)
13.482... logprob:  0.635362, 0.281250 (1.476 sec)
13.483... logprob:  0.766127, 0.316406 (1.447 sec)
13.484... logprob:  0.778326, 0.315104 (1.437 sec)
13.485... logprob:  0.618054, 0.252604 (1.473 sec)
13.486... logprob:  0.552531, 0.223958 (1.431 sec)
13.487... logprob:  0.838155, 0.352865 (1.421 sec)
13.488... logprob:  0.626833, 0.283854 (1.429 sec)
13.489... logprob:  0.579667, 0.248698 (1.425 sec)
13.490... logprob:  0.652536, 0.302083 (1.428 sec)
13.491... logprob:  0.537517, 0.252604 (1.474 sec)
13.492... logprob:  0.625513, 0.257812 (1.436 sec)
13.493... logprob:  0.673420, 0.285156 (1.436 sec)
13.494... logprob:  0.645797, 0.320312 (1.475 sec)
13.495... logprob:  0.580803, 0.242187 (1.429 sec)
13.496... logprob:  0.736563, 0.315104 (1.426 sec)
13.497... logprob:  0.738898, 0.320312 (1.427 sec)
13.498... logprob:  0.679441, 0.289062 (1.424 sec)
13.499... logprob:  0.663775, 0.276042 (1.426 sec)
13.500... logprob:  0.634216, 0.268229 (1.486 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.573716, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.819087e-03 [2.419460e-07] 
Layer 'conv1' biases: 1.729658e-06 [3.676910e-10] 
Layer 'conv2' weights[0]: 4.810142e-03 [2.412859e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.245005e-09] 
Layer 'conv3' weights[0]: 4.808744e-03 [2.418136e-07] 
Layer 'conv3' biases: 2.840822e-05 [1.698462e-08] 
Layer 'conv4' weights[0]: 4.828700e-03 [2.439390e-07] 
Layer 'conv4' biases: 1.000012e+00 [2.568055e-07] 
Layer 'conv5' weights[0]: 4.911825e-03 [2.293225e-06] 
Layer 'conv5' biases: 9.991205e-01 [2.485210e-06] 
Layer 'fc6' weights[0]: 7.204274e-03 [6.142072e-08] 
Layer 'fc6' biases: 9.999943e-01 [5.839496e-08] 
Layer 'fc7' weights[0]: 7.556824e-03 [1.355408e-07] 
Layer 'fc7' biases: 9.998542e-01 [1.574846e-07] 
Layer 'fc8' weights[0]: 4.413915e-03 [1.442270e-05] 
Layer 'fc8' biases: 1.120455e-02 [1.115626e-05] 
Train error last 800 batches: 0.656765
-------------------------------------------------------
Not saving because 0.573716 > 0.299667 (9.300: -1.18%)
======================================================= (2.394 sec)
13.501... logprob:  0.534656, 0.238281 (1.431 sec)
13.502... logprob:  0.665604, 0.276042 (1.450 sec)
13.503... logprob:  0.624926, 0.273438 (1.475 sec)
13.504... logprob:  0.700570, 0.317708 (1.431 sec)
13.505... logprob:  0.676911, 0.292969 (1.431 sec)
13.506... logprob:  0.635183, 0.255208 (1.433 sec)
13.507... logprob:  0.642422, 0.261719 (1.425 sec)
13.508... logprob:  0.638354, 0.292969 (1.427 sec)
13.509... logprob:  0.655502, 0.289062 (1.468 sec)
13.510... logprob:  0.686303, 0.308594 (1.436 sec)
13.511... logprob:  0.695860, 0.320312 (1.447 sec)
13.512... logprob:  0.709623, 0.282552 (1.457 sec)
13.513... logprob:  0.581370, 0.278646 (1.437 sec)
13.514... logprob:  0.667692, 0.305989 (1.431 sec)
13.515... logprob:  0.759635, 0.354167 (1.425 sec)
13.516... logprob:  0.690334, 0.283854 (1.417 sec)
13.517... logprob:  0.797490, 0.320312 (1.442 sec)
13.518... logprob:  0.685317, 0.283854 (1.451 sec)
13.519... logprob:  0.757053, 0.326823 (1.446 sec)
13.520... logprob:  0.638992, 0.278646 (1.452 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.444501, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.814264e-03 [2.415325e-07] 
Layer 'conv1' biases: 1.731159e-06 [3.479192e-10] 
Layer 'conv2' weights[0]: 4.805323e-03 [2.409441e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.803620e-09] 
Layer 'conv3' weights[0]: 4.803922e-03 [2.419677e-07] 
Layer 'conv3' biases: 2.838551e-05 [1.889742e-08] 
Layer 'conv4' weights[0]: 4.823885e-03 [2.442727e-07] 
Layer 'conv4' biases: 1.000014e+00 [2.791052e-07] 
Layer 'conv5' weights[0]: 4.907869e-03 [2.588280e-06] 
Layer 'conv5' biases: 9.991109e-01 [2.732188e-06] 
Layer 'fc6' weights[0]: 7.203507e-03 [6.555328e-08] 
Layer 'fc6' biases: 9.999942e-01 [6.437402e-08] 
Layer 'fc7' weights[0]: 7.556014e-03 [1.532920e-07] 
Layer 'fc7' biases: 9.998543e-01 [2.145739e-07] 
Layer 'fc8' weights[0]: 4.433913e-03 [1.784961e-05] 
Layer 'fc8' biases: 1.138326e-02 [2.896706e-05] 
Train error last 800 batches: 0.657015
-------------------------------------------------------
Not saving because 0.444501 > 0.299667 (9.300: -1.18%)
======================================================= (2.375 sec)
13.521... logprob:  0.648667, 0.281250 (1.450 sec)
13.522... logprob:  0.727496, 0.338542 (1.459 sec)
13.523... logprob:  0.605713, 0.246094 (1.437 sec)
13.524... logprob:  0.702024, 0.295573 (1.421 sec)
13.525... logprob:  0.650158, 0.282552 (1.430 sec)
13.526... logprob:  0.594551, 0.259115 (1.433 sec)
13.527... logprob:  0.666519, 0.300781 (1.434 sec)
13.528... logprob:  0.608564, 0.269531 (1.463 sec)
13.529... logprob:  0.635827, 0.278646 (1.451 sec)
13.530... logprob:  0.676243, 0.304688 (1.430 sec)
13.531... logprob:  0.681707, 0.312500 (1.476 sec)
13.532... logprob:  0.619398, 0.281250 (1.424 sec)
13.533... logprob:  0.725886, 0.316406 (1.420 sec)
13.534... logprob:  0.604685, 0.285156 (1.433 sec)
13.535... logprob:  0.763237, 0.334635 (1.434 sec)
13.536... logprob:  0.784275, 0.312500 (1.428 sec)
13.537... logprob:  0.612579, 0.274740 (1.478 sec)
13.538... logprob:  0.695744, 0.268229 (1.438 sec)
13.539... logprob:  0.467593, 0.196615 (1.423 sec)
13.540... logprob:  0.644269, 0.287760 (1.485 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.326477, 0.039062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.809473e-03 [2.417484e-07] 
Layer 'conv1' biases: 1.732844e-06 [3.371300e-10] 
Layer 'conv2' weights[0]: 4.800504e-03 [2.410410e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.681140e-09] 
Layer 'conv3' weights[0]: 4.799126e-03 [2.420663e-07] 
Layer 'conv3' biases: 2.836613e-05 [1.974478e-08] 
Layer 'conv4' weights[0]: 4.819077e-03 [2.448141e-07] 
Layer 'conv4' biases: 1.000015e+00 [3.196160e-07] 
Layer 'conv5' weights[0]: 4.903292e-03 [2.468385e-06] 
Layer 'conv5' biases: 9.991060e-01 [2.681145e-06] 
Layer 'fc6' weights[0]: 7.202748e-03 [6.182806e-08] 
Layer 'fc6' biases: 9.999942e-01 [5.923181e-08] 
Layer 'fc7' weights[0]: 7.555312e-03 [1.428163e-07] 
Layer 'fc7' biases: 9.998543e-01 [1.927872e-07] 
Layer 'fc8' weights[0]: 4.433827e-03 [1.781218e-05] 
Layer 'fc8' biases: 1.143266e-02 [3.587594e-05] 
Train error last 800 batches: 0.656460
-------------------------------------------------------
Not saving because 0.326477 > 0.299667 (9.300: -1.18%)
======================================================= (2.383 sec)
13.541... logprob:  0.609529, 0.292969 (1.437 sec)
13.542... logprob:  0.645633, 0.278646 (1.431 sec)
13.543... logprob:  0.549463, 0.242187 (1.436 sec)
13.544... logprob:  0.513727, 0.230469 (1.428 sec)
13.545... logprob:  0.618012, 0.308594 (1.434 sec)
13.546... logprob:  0.636362, 0.272135 (1.489 sec)
13.547... logprob:  0.609209, 0.247396 (1.433 sec)
13.548... logprob:  0.658311, 0.300781 (1.440 sec)
13.549... logprob:  0.752245, 0.361979 (1.476 sec)
13.550... logprob:  0.652305, 0.264323 (1.428 sec)
13.551... logprob:  0.708851, 0.321615 (1.434 sec)
13.552... logprob:  0.665995, 0.274740 (1.435 sec)
13.553... logprob:  0.619294, 0.274740 (1.420 sec)
13.554... logprob:  0.765713, 0.356771 (1.430 sec)
13.555... logprob:  0.655088, 0.292969 (1.479 sec)
13.556... logprob:  0.539489, 0.212240 (1.432 sec)
13.557... logprob:  0.662094, 0.268229 (1.442 sec)
13.558... logprob:  0.678282, 0.312500 (1.467 sec)
13.559... logprob:  0.658467, 0.272135 (1.431 sec)
13.560... logprob:  0.583342, 0.261719 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.456605, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.804646e-03 [2.412038e-07] 
Layer 'conv1' biases: 1.732995e-06 [3.983621e-10] 
Layer 'conv2' weights[0]: 4.795702e-03 [2.408020e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.783357e-09] 
Layer 'conv3' weights[0]: 4.794340e-03 [2.417972e-07] 
Layer 'conv3' biases: 2.834645e-05 [1.926762e-08] 
Layer 'conv4' weights[0]: 4.814203e-03 [2.440057e-07] 
Layer 'conv4' biases: 1.000014e+00 [3.013352e-07] 
Layer 'conv5' weights[0]: 4.898613e-03 [2.858326e-06] 
Layer 'conv5' biases: 9.990960e-01 [3.026537e-06] 
Layer 'fc6' weights[0]: 7.201988e-03 [6.472868e-08] 
Layer 'fc6' biases: 9.999942e-01 [6.392896e-08] 
Layer 'fc7' weights[0]: 7.554510e-03 [1.513228e-07] 
Layer 'fc7' biases: 9.998546e-01 [2.203341e-07] 
Layer 'fc8' weights[0]: 4.471934e-03 [2.013098e-05] 
Layer 'fc8' biases: 1.165211e-02 [4.079587e-05] 
Train error last 800 batches: 0.656261
-------------------------------------------------------
Not saving because 0.456605 > 0.299667 (9.300: -1.18%)
======================================================= (2.353 sec)
13.561... logprob:  0.651487, 0.294271 (1.431 sec)
13.562... logprob:  0.765656, 0.302083 (1.429 sec)
13.563... logprob:  0.635983, 0.281250 (1.433 sec)
13.564... logprob:  0.661718, 0.289062 (1.456 sec)
13.565... logprob:  0.732558, 0.303385 (1.449 sec)
13.566... logprob:  0.584291, 0.256510 (1.454 sec)
13.567... logprob:  0.611306, 0.253906 (1.458 sec)
13.568... logprob:  0.672734, 0.307292 (1.458 sec)
13.569... logprob:  0.680167, 0.264323 (1.436 sec)
13.570... logprob:  0.823693, 0.325521 (1.423 sec)
13.571... logprob:  0.611773, 0.260417 (1.433 sec)
13.572... logprob:  0.676834, 0.264323 (1.437 sec)
13.573... logprob:  0.697976, 0.320312 (1.437 sec)
13.574... logprob:  0.650091, 0.289062 (1.470 sec)
13.575... logprob:  0.630604, 0.292969 (1.452 sec)
13.576... logprob:  0.590277, 0.255208 (1.434 sec)
13.577... logprob:  0.617222, 0.265625 (1.471 sec)
13.578... logprob:  0.602597, 0.281250 (1.427 sec)
13.579... logprob:  0.682102, 0.298177 (1.419 sec)
13.580... logprob:  0.746610, 0.303385 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.513606, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.799859e-03 [2.417832e-07] 
Layer 'conv1' biases: 1.734992e-06 [4.920820e-10] 
Layer 'conv2' weights[0]: 4.790938e-03 [2.403139e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.738382e-09] 
Layer 'conv3' weights[0]: 4.789521e-03 [2.416402e-07] 
Layer 'conv3' biases: 2.833703e-05 [1.983224e-08] 
Layer 'conv4' weights[0]: 4.809415e-03 [2.441846e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.090177e-07] 
Layer 'conv5' weights[0]: 4.893297e-03 [2.732506e-06] 
Layer 'conv5' biases: 9.991162e-01 [2.873903e-06] 
Layer 'fc6' weights[0]: 7.201245e-03 [6.368898e-08] 
Layer 'fc6' biases: 9.999942e-01 [6.173618e-08] 
Layer 'fc7' weights[0]: 7.553735e-03 [1.504996e-07] 
Layer 'fc7' biases: 9.998527e-01 [2.102853e-07] 
Layer 'fc8' weights[0]: 4.423110e-03 [1.941829e-05] 
Layer 'fc8' biases: 1.126418e-02 [4.068076e-05] 
Train error last 800 batches: 0.655869
-------------------------------------------------------
Not saving because 0.513606 > 0.299667 (9.300: -1.18%)
======================================================= (2.353 sec)
13.581... logprob:  0.687289, 0.304687 (1.443 sec)
13.582... logprob:  0.682149, 0.317708 (1.433 sec)
13.583... logprob:  0.712314, 0.298177 (1.473 sec)
13.584... logprob:  0.776466, 0.307292 (1.452 sec)
13.585... logprob:  0.584633, 0.251302 (1.432 sec)
13.586... logprob:  0.563468, 0.256510 (1.479 sec)
13.587... logprob:  0.646557, 0.285156 (1.425 sec)
13.588... logprob:  0.682484, 0.296875 (1.425 sec)
13.589... logprob:  0.589051, 0.252604 (1.438 sec)
13.590... logprob:  0.658963, 0.294271 (1.422 sec)
13.591... logprob:  0.636691, 0.269531 (1.427 sec)
13.592... logprob:  0.645581, 0.283854 (1.479 sec)
13.593... logprob:  0.733658, 0.332031 (1.429 sec)
13.594... logprob:  0.661268, 0.294271 (1.434 sec)
13.595... logprob:  0.625194, 0.268229 (1.476 sec)
13.596... logprob:  0.666271, 0.285156 (1.428 sec)
13.597... logprob:  0.637336, 0.257812 (1.430 sec)
13.598... logprob:  0.589707, 0.264323 (1.429 sec)
13.599... logprob:  0.531616, 0.242187 (1.427 sec)
13.600... logprob:  0.657871, 0.281250 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.441017, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.795040e-03 [2.413207e-07] 
Layer 'conv1' biases: 1.733241e-06 [4.253962e-10] 
Layer 'conv2' weights[0]: 4.786147e-03 [2.401959e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.708137e-09] 
Layer 'conv3' weights[0]: 4.784740e-03 [2.411413e-07] 
Layer 'conv3' biases: 2.832588e-05 [1.957779e-08] 
Layer 'conv4' weights[0]: 4.804628e-03 [2.432538e-07] 
Layer 'conv4' biases: 1.000014e+00 [3.005575e-07] 
Layer 'conv5' weights[0]: 4.888980e-03 [2.689011e-06] 
Layer 'conv5' biases: 9.991083e-01 [2.940830e-06] 
Layer 'fc6' weights[0]: 7.200515e-03 [6.328468e-08] 
Layer 'fc6' biases: 9.999942e-01 [6.106652e-08] 
Layer 'fc7' weights[0]: 7.552981e-03 [1.473700e-07] 
Layer 'fc7' biases: 9.998534e-01 [2.128960e-07] 
Layer 'fc8' weights[0]: 4.458374e-03 [1.762162e-05] 
Layer 'fc8' biases: 1.147966e-02 [3.424643e-05] 
Train error last 800 batches: 0.655795
-------------------------------------------------------
Not saving because 0.441017 > 0.299667 (9.300: -1.18%)
======================================================= (2.362 sec)
13.601... logprob:  0.599291, 0.292969 (1.486 sec)
13.602... logprob:  0.617624, 0.292968 (1.440 sec)
13.603... logprob:  0.551323, 0.250000 (1.442 sec)
13.604... logprob:  0.641544, 0.269531 (1.468 sec)
13.605... logprob:  0.736971, 0.320312 (1.431 sec)
13.606... logprob:  0.619475, 0.295573 (1.440 sec)
13.607... logprob:  0.804105, 0.351562 (1.433 sec)
13.608... logprob:  0.625608, 0.283854 (1.425 sec)
13.609... logprob:  0.603366, 0.259115 (1.427 sec)
13.610... logprob:  0.735154, 0.316406 (1.468 sec)
13.611... logprob:  0.723153, 0.281250 (1.440 sec)
13.612... logprob:  0.589689, 0.257812 (1.477 sec)
13.613... logprob:  0.609955, 0.281250 (1.456 sec)
13.614... logprob:  0.688089, 0.300781 (1.443 sec)
13.615... logprob:  0.484316, 0.216146 (1.436 sec)
13.616... logprob:  0.641301, 0.290365 (1.423 sec)
13.617... logprob:  0.667226, 0.292969 (1.418 sec)
13.618... logprob:  0.751554, 0.313802 (1.434 sec)
13.619... logprob:  0.721377, 0.308594 (1.445 sec)
13.620... logprob:  0.678738, 0.278646 (1.454 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.440131, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.790232e-03 [2.403206e-07] 
Layer 'conv1' biases: 1.732278e-06 [6.051140e-10] 
Layer 'conv2' weights[0]: 4.781354e-03 [2.398168e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.710409e-09] 
Layer 'conv3' weights[0]: 4.779911e-03 [2.417918e-07] 
Layer 'conv3' biases: 2.840642e-05 [2.384813e-08] 
Layer 'conv4' weights[0]: 4.799814e-03 [2.443116e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.635314e-07] 
Layer 'conv5' weights[0]: 4.884186e-03 [3.194452e-06] 
Layer 'conv5' biases: 9.991087e-01 [3.381868e-06] 
Layer 'fc6' weights[0]: 7.199737e-03 [7.262007e-08] 
Layer 'fc6' biases: 9.999943e-01 [7.454042e-08] 
Layer 'fc7' weights[0]: 7.552227e-03 [1.732519e-07] 
Layer 'fc7' biases: 9.998533e-01 [2.791176e-07] 
Layer 'fc8' weights[0]: 4.471829e-03 [2.062651e-05] 
Layer 'fc8' biases: 1.165973e-02 [4.273816e-05] 
Train error last 800 batches: 0.656336
-------------------------------------------------------
Not saving because 0.440131 > 0.299667 (9.300: -1.18%)
======================================================= (2.382 sec)
13.621... logprob:  0.575784, 0.244792 (1.459 sec)
13.622... logprob:  0.628667, 0.292969 (1.451 sec)
13.623... logprob:  0.683435, 0.315104 (1.466 sec)
13.624... logprob:  0.697001, 0.299479 (1.432 sec)
13.625... logprob:  0.586725, 0.230469 (1.420 sec)
13.626... logprob:  0.593083, 0.285156 (1.429 sec)
13.627... logprob:  0.680770, 0.308594 (1.433 sec)
13.628... logprob:  0.667551, 0.246094 (1.438 sec)
13.629... logprob:  0.614634, 0.279948 (1.475 sec)
13.630... logprob:  0.662041, 0.269531 (1.451 sec)
13.631... logprob:  0.760034, 0.342448 (1.435 sec)
13.632... logprob:  0.681217, 0.285156 (1.477 sec)
13.633... logprob:  0.593577, 0.269531 (1.429 sec)
13.634... logprob:  0.837263, 0.343750 (1.433 sec)
13.635... logprob:  0.633562, 0.294271 (1.427 sec)
13.636... logprob:  0.673517, 0.276042 (1.436 sec)
13.637... logprob:  0.618523, 0.290365 (1.432 sec)
13.638... logprob:  0.747208, 0.312500 (1.476 sec)
13.639... logprob:  0.541000, 0.235677 (1.442 sec)
13.640... logprob:  0.729305, 0.322917 (1.425 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.511290, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.785474e-03 [2.399938e-07] 
Layer 'conv1' biases: 1.733180e-06 [3.770825e-10] 
Layer 'conv2' weights[0]: 4.776547e-03 [2.393751e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.115065e-09] 
Layer 'conv3' weights[0]: 4.775156e-03 [2.404148e-07] 
Layer 'conv3' biases: 2.842039e-05 [1.841269e-08] 
Layer 'conv4' weights[0]: 4.795002e-03 [2.428077e-07] 
Layer 'conv4' biases: 1.000012e+00 [2.997662e-07] 
Layer 'conv5' weights[0]: 4.879328e-03 [2.585918e-06] 
Layer 'conv5' biases: 9.991187e-01 [2.827357e-06] 
Layer 'fc6' weights[0]: 7.199001e-03 [6.491385e-08] 
Layer 'fc6' biases: 9.999943e-01 [6.352626e-08] 
Layer 'fc7' weights[0]: 7.551432e-03 [1.511865e-07] 
Layer 'fc7' biases: 9.998525e-01 [2.102311e-07] 
Layer 'fc8' weights[0]: 4.444509e-03 [1.979583e-05] 
Layer 'fc8' biases: 1.139025e-02 [4.293245e-05] 
Train error last 800 batches: 0.656036
-------------------------------------------------------
Not saving because 0.511290 > 0.299667 (9.300: -1.18%)
======================================================= (2.378 sec)
13.641... logprob:  0.633992, 0.277344 (1.490 sec)
13.642... logprob:  0.773255, 0.368490 (1.433 sec)
13.643... logprob:  0.732480, 0.305990 (1.431 sec)
13.644... logprob:  0.538988, 0.226562 (1.432 sec)
13.645... logprob:  0.581675, 0.260417 (1.429 sec)
13.646... logprob:  0.594803, 0.263021 (1.423 sec)
13.647... logprob:  0.726366, 0.332031 (1.494 sec)
13.648... logprob:  0.749293, 0.325521 (1.435 sec)
13.649... logprob:  0.675865, 0.311198 (1.445 sec)
13.650... logprob:  0.601692, 0.277344 (1.496 sec)
13.651... logprob:  0.621791, 0.268229 (1.431 sec)
13.652... logprob:  0.839764, 0.345052 (1.435 sec)
13.653... logprob:  0.601082, 0.266927 (1.432 sec)
13.654... logprob:  0.754174, 0.322917 (1.421 sec)
13.655... logprob:  0.591225, 0.240885 (1.427 sec)
13.656... logprob:  0.628381, 0.256510 (1.474 sec)
13.657... logprob:  0.705455, 0.294271 (1.440 sec)
13.658... logprob:  0.599928, 0.252604 (1.444 sec)
13.659... logprob:  0.726907, 0.308594 (1.460 sec)
13.660... logprob:  0.697427, 0.330729 (1.435 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.483974, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.780693e-03 [2.408130e-07] 
Layer 'conv1' biases: 1.734535e-06 [5.371792e-10] 
Layer 'conv2' weights[0]: 4.771796e-03 [2.397978e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.340999e-09] 
Layer 'conv3' weights[0]: 4.770423e-03 [2.408628e-07] 
Layer 'conv3' biases: 2.848104e-05 [2.192837e-08] 
Layer 'conv4' weights[0]: 4.790222e-03 [2.429597e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.440622e-07] 
Layer 'conv5' weights[0]: 4.874965e-03 [2.926140e-06] 
Layer 'conv5' biases: 9.991145e-01 [3.242160e-06] 
Layer 'fc6' weights[0]: 7.198239e-03 [6.377132e-08] 
Layer 'fc6' biases: 9.999943e-01 [6.186490e-08] 
Layer 'fc7' weights[0]: 7.550668e-03 [1.468165e-07] 
Layer 'fc7' biases: 9.998528e-01 [1.936000e-07] 
Layer 'fc8' weights[0]: 4.447731e-03 [1.677357e-05] 
Layer 'fc8' biases: 1.134165e-02 [3.124700e-05] 
Train error last 800 batches: 0.655897
-------------------------------------------------------
Not saving because 0.483974 > 0.299667 (9.300: -1.18%)
======================================================= (2.370 sec)
13.661... logprob:  0.616170, 0.256510 (1.441 sec)
13.662... logprob:  0.660312, 0.316406 (1.434 sec)
13.663... logprob:  0.556385, 0.233073 (1.422 sec)
13.664... logprob:  0.605005, 0.252604 (1.435 sec)
13.665... logprob:  0.582963, 0.255208 (1.461 sec)
13.666... logprob:  0.711516, 0.302083 (1.455 sec)
13.667... logprob:  0.732988, 0.302083 (1.455 sec)
13.668... logprob:  0.672803, 0.289062 (1.450 sec)
13.669... logprob:  0.593298, 0.233073 (1.459 sec)
13.670... logprob:  0.699592, 0.315104 (1.440 sec)
13.671... logprob:  0.564490, 0.253906 (1.423 sec)
13.672... logprob:  0.657152, 0.278646 (1.429 sec)
13.673... logprob:  0.638592, 0.278646 (1.437 sec)
13.674... logprob:  0.665583, 0.291667 (1.432 sec)
13.675... logprob:  0.683201, 0.316406 (1.466 sec)
13.676... logprob:  0.579390, 0.263021 (1.447 sec)
13.677... logprob:  0.628870, 0.285156 (1.436 sec)
13.678... logprob:  0.726665, 0.299479 (1.474 sec)
13.679... logprob:  0.625085, 0.269531 (1.426 sec)
13.680... logprob:  0.659251, 0.277344 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.456544, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.775921e-03 [2.397443e-07] 
Layer 'conv1' biases: 1.736963e-06 [3.191308e-10] 
Layer 'conv2' weights[0]: 4.767029e-03 [2.390791e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.429254e-09] 
Layer 'conv3' weights[0]: 4.765615e-03 [2.397726e-07] 
Layer 'conv3' biases: 2.852365e-05 [1.715258e-08] 
Layer 'conv4' weights[0]: 4.785448e-03 [2.415483e-07] 
Layer 'conv4' biases: 1.000013e+00 [2.572965e-07] 
Layer 'conv5' weights[0]: 4.870486e-03 [2.387411e-06] 
Layer 'conv5' biases: 9.991039e-01 [2.590018e-06] 
Layer 'fc6' weights[0]: 7.197477e-03 [5.975180e-08] 
Layer 'fc6' biases: 9.999944e-01 [5.583090e-08] 
Layer 'fc7' weights[0]: 7.549934e-03 [1.339744e-07] 
Layer 'fc7' biases: 9.998531e-01 [1.574202e-07] 
Layer 'fc8' weights[0]: 4.483959e-03 [1.451334e-05] 
Layer 'fc8' biases: 1.161510e-02 [1.482399e-05] 
Train error last 800 batches: 0.655443
-------------------------------------------------------
Not saving because 0.456544 > 0.299667 (9.300: -1.18%)
======================================================= (2.367 sec)
13.681... logprob:  0.595568, 0.225260 (1.437 sec)
13.682... logprob:  0.593008, 0.269531 (1.443 sec)
13.683... logprob:  0.674441, 0.313802 (1.431 sec)
13.684... logprob:  0.645372, 0.278646 (1.475 sec)
13.685... logprob:  0.545594, 0.236979 (1.441 sec)
13.686... logprob:  0.547984, 0.248698 (1.435 sec)
13.687... logprob:  0.490537, 0.207031 (1.485 sec)
13.688... logprob:  0.555202, 0.217448 (1.453 sec)
13.689... logprob:  0.721262, 0.290365 (1.433 sec)
13.690... logprob:  0.791074, 0.320312 (1.437 sec)
13.691... logprob:  0.661368, 0.265625 (1.426 sec)
13.692... logprob:  0.583155, 0.257812 (1.433 sec)
13.693... logprob:  0.665778, 0.263021 (1.480 sec)
13.694... logprob:  0.632826, 0.274740 (1.431 sec)
13.695... logprob:  0.590712, 0.282552 (1.440 sec)
13.696... logprob:  0.775817, 0.339844 (1.474 sec)
13.697... logprob:  0.729656, 0.296875 (1.422 sec)
13.698... logprob:  0.603166, 0.292969 (1.432 sec)
13.699... logprob:  0.689562, 0.273438 (1.429 sec)
13.700... logprob:  0.662180, 0.281250 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.499121, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.771137e-03 [2.390042e-07] 
Layer 'conv1' biases: 1.737699e-06 [4.844884e-10] 
Layer 'conv2' weights[0]: 4.762286e-03 [2.388188e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.528686e-09] 
Layer 'conv3' weights[0]: 4.760874e-03 [2.395558e-07] 
Layer 'conv3' biases: 2.855785e-05 [1.827557e-08] 
Layer 'conv4' weights[0]: 4.780656e-03 [2.424086e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.424680e-07] 
Layer 'conv5' weights[0]: 4.865666e-03 [3.394386e-06] 
Layer 'conv5' biases: 9.991106e-01 [3.736943e-06] 
Layer 'fc6' weights[0]: 7.196744e-03 [7.351998e-08] 
Layer 'fc6' biases: 9.999944e-01 [7.538802e-08] 
Layer 'fc7' weights[0]: 7.549196e-03 [1.782969e-07] 
Layer 'fc7' biases: 9.998528e-01 [2.937799e-07] 
Layer 'fc8' weights[0]: 4.473923e-03 [2.141869e-05] 
Layer 'fc8' biases: 1.163447e-02 [4.912908e-05] 
Train error last 800 batches: 0.655566
-------------------------------------------------------
Not saving because 0.499121 > 0.299667 (9.300: -1.18%)
======================================================= (2.355 sec)
13.701... logprob:  0.670829, 0.326823 (1.430 sec)
13.702... logprob:  0.721275, 0.311198 (1.487 sec)
13.703... logprob:  0.616839, 0.276042 (1.434 sec)
13.704... logprob:  0.584190, 0.270833 (1.443 sec)
13.705... logprob:  0.647906, 0.302083 (1.469 sec)
13.706... logprob:  0.719961, 0.308594 (1.435 sec)
13.707... logprob:  0.635797, 0.242188 (1.435 sec)
13.708... logprob:  0.591832, 0.266927 (1.432 sec)
13.709... logprob:  0.615685, 0.252604 (1.415 sec)
13.710... logprob:  0.771838, 0.313802 (1.435 sec)
13.711... logprob:  0.671826, 0.291667 (1.466 sec)
13.712... logprob:  0.542736, 0.256510 (1.442 sec)
13.713... logprob:  0.731107, 0.328125 (1.447 sec)
13.714... logprob:  0.709587, 0.295573 (1.452 sec)
13.715... logprob:  0.672238, 0.285156 (1.450 sec)
13.716... logprob:  0.554405, 0.244792 (1.436 sec)
13.717... logprob:  0.591397, 0.226562 (1.418 sec)
13.718... logprob:  0.745998, 0.316406 (1.426 sec)
13.719... logprob:  0.628632, 0.268229 (1.432 sec)
13.720... logprob:  0.686817, 0.302083 (1.440 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.417950, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.766378e-03 [2.395867e-07] 
Layer 'conv1' biases: 1.738124e-06 [4.317273e-10] 
Layer 'conv2' weights[0]: 4.757511e-03 [2.387868e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.425188e-09] 
Layer 'conv3' weights[0]: 4.756105e-03 [2.396275e-07] 
Layer 'conv3' biases: 2.856523e-05 [1.858943e-08] 
Layer 'conv4' weights[0]: 4.775862e-03 [2.428796e-07] 
Layer 'conv4' biases: 1.000016e+00 [3.243264e-07] 
Layer 'conv5' weights[0]: 4.862532e-03 [2.739021e-06] 
Layer 'conv5' biases: 9.991221e-01 [2.970505e-06] 
Layer 'fc6' weights[0]: 7.196006e-03 [6.132146e-08] 
Layer 'fc6' biases: 9.999945e-01 [5.781699e-08] 
Layer 'fc7' weights[0]: 7.548497e-03 [1.396007e-07] 
Layer 'fc7' biases: 9.998513e-01 [1.626077e-07] 
Layer 'fc8' weights[0]: 4.429864e-03 [1.519156e-05] 
Layer 'fc8' biases: 1.131511e-02 [1.532454e-05] 
Train error last 800 batches: 0.655674
-------------------------------------------------------
Not saving because 0.417950 > 0.299667 (9.300: -1.18%)
======================================================= (2.401 sec)
13.721... logprob:  0.633750, 0.269531 (1.465 sec)
13.722... logprob:  0.740595, 0.292969 (1.457 sec)
13.723... logprob:  0.600046, 0.253906 (1.450 sec)
13.724... logprob:  0.631309, 0.251302 (1.466 sec)
13.725... logprob:  0.682742, 0.326823 (1.431 sec)
13.726... logprob:  0.590328, 0.256510 (1.441 sec)
13.727... logprob:  0.508824, 0.247396 (1.428 sec)
13.728... logprob:  0.666009, 0.300781 (1.440 sec)
13.729... logprob:  0.722555, 0.300781 (1.431 sec)
13.730... logprob:  0.687302, 0.313802 (1.474 sec)
13.731... logprob:  0.670071, 0.298177 (1.446 sec)
13.732... logprob:  0.614793, 0.286458 (1.431 sec)
13.733... logprob:  0.770742, 0.315104 (1.482 sec)
13.734... logprob:  0.574790, 0.272135 (1.427 sec)
13.735... logprob:  0.687414, 0.292969 (1.423 sec)
13.736... logprob:  0.744750, 0.330729 (1.430 sec)
13.737... logprob:  0.719518, 0.322917 (1.424 sec)
13.738... logprob:  0.657627, 0.286458 (1.427 sec)
13.739... logprob:  0.702214, 0.317708 (1.474 sec)
13.740... logprob:  0.584456, 0.260417 (1.435 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.484997, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.761620e-03 [2.390255e-07] 
Layer 'conv1' biases: 1.740566e-06 [2.723302e-10] 
Layer 'conv2' weights[0]: 4.752746e-03 [2.382689e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.093290e-09] 
Layer 'conv3' weights[0]: 4.751317e-03 [2.385906e-07] 
Layer 'conv3' biases: 2.853997e-05 [1.312303e-08] 
Layer 'conv4' weights[0]: 4.771095e-03 [2.407705e-07] 
Layer 'conv4' biases: 1.000014e+00 [2.476392e-07] 
Layer 'conv5' weights[0]: 4.856765e-03 [2.423864e-06] 
Layer 'conv5' biases: 9.991240e-01 [2.587708e-06] 
Layer 'fc6' weights[0]: 7.195223e-03 [5.912895e-08] 
Layer 'fc6' biases: 9.999945e-01 [5.447053e-08] 
Layer 'fc7' weights[0]: 7.547770e-03 [1.339112e-07] 
Layer 'fc7' biases: 9.998518e-01 [1.563016e-07] 
Layer 'fc8' weights[0]: 4.447003e-03 [1.490993e-05] 
Layer 'fc8' biases: 1.140651e-02 [2.163046e-05] 
Train error last 800 batches: 0.655392
-------------------------------------------------------
Not saving because 0.484997 > 0.299667 (9.300: -1.18%)
======================================================= (2.378 sec)
13.741... logprob:  0.574846, 0.235677 (1.438 sec)
13.742... logprob:  0.689326, 0.304687 (1.483 sec)
13.743... logprob:  0.554210, 0.209635 (1.431 sec)
13.744... logprob:  0.663187, 0.307292 (1.430 sec)
13.745... logprob:  0.712441, 0.295573 (1.435 sec)
13.746... logprob:  0.670389, 0.289062 (1.424 sec)
13.747... logprob:  0.673001, 0.311198 (1.431 sec)
13.748... logprob:  0.622406, 0.252604 (1.484 sec)
13.749... logprob:  0.601684, 0.263021 (1.433 sec)
13.750... logprob:  0.697122, 0.255208 (1.438 sec)
13.751... logprob:  0.537711, 0.243490 (1.481 sec)
13.752... logprob:  0.692051, 0.308594 (1.436 sec)
13.753... logprob:  0.650432, 0.290365 (1.435 sec)
13.754... logprob:  0.631889, 0.296875 (1.430 sec)
13.755... logprob:  0.759187, 0.292969 (1.425 sec)
13.756... logprob:  0.685961, 0.295573 (1.427 sec)
13.757... logprob:  0.708200, 0.303385 (1.469 sec)
13.758... logprob:  0.745336, 0.338542 (1.434 sec)
13.759... logprob:  0.605674, 0.265625 (1.452 sec)
13.760... logprob:  0.662264, 0.274740 (1.453 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.460136, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.756870e-03 [2.391575e-07] 
Layer 'conv1' biases: 1.741405e-06 [4.941375e-10] 
Layer 'conv2' weights[0]: 4.748028e-03 [2.383256e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.673691e-09] 
Layer 'conv3' weights[0]: 4.746578e-03 [2.393383e-07] 
Layer 'conv3' biases: 2.858692e-05 [1.931232e-08] 
Layer 'conv4' weights[0]: 4.766340e-03 [2.418310e-07] 
Layer 'conv4' biases: 1.000016e+00 [2.983679e-07] 
Layer 'conv5' weights[0]: 4.853071e-03 [2.371490e-06] 
Layer 'conv5' biases: 9.991156e-01 [2.535945e-06] 
Layer 'fc6' weights[0]: 7.194490e-03 [6.116059e-08] 
Layer 'fc6' biases: 9.999946e-01 [5.768888e-08] 
Layer 'fc7' weights[0]: 7.547003e-03 [1.400591e-07] 
Layer 'fc7' biases: 9.998522e-01 [1.682428e-07] 
Layer 'fc8' weights[0]: 4.475840e-03 [1.514076e-05] 
Layer 'fc8' biases: 1.161637e-02 [1.511963e-05] 
Train error last 800 batches: 0.655079
-------------------------------------------------------
Not saving because 0.460136 > 0.299667 (9.300: -1.18%)
======================================================= (2.349 sec)
13.761... logprob:  0.732344, 0.304688 (1.442 sec)
13.762... logprob:  0.693730, 0.264323 (1.438 sec)
13.763... logprob:  0.793120, 0.305990 (1.429 sec)
13.764... logprob:  0.616183, 0.299479 (1.450 sec)
13.765... logprob:  0.559532, 0.272135 (1.430 sec)
13.766... logprob:  0.637280, 0.289062 (1.446 sec)
13.767... logprob:  0.583794, 0.279948 (1.455 sec)
13.768... logprob:  0.621175, 0.277344 (1.463 sec)
13.769... logprob:  0.713561, 0.303385 (1.457 sec)
13.770... logprob:  0.580968, 0.268229 (1.480 sec)
13.771... logprob:  0.746829, 0.300781 (1.460 sec)
13.772... logprob:  0.593531, 0.242188 (1.446 sec)
13.773... logprob:  0.717385, 0.325521 (1.450 sec)
13.774... logprob:  0.563964, 0.242187 (1.453 sec)
13.775... logprob:  0.714796, 0.276042 (1.461 sec)
13.776... logprob:  0.650580, 0.300781 (1.472 sec)
13.777... logprob:  0.674848, 0.311198 (1.468 sec)
13.778... logprob:  0.745702, 0.325521 (1.466 sec)
13.779... logprob:  0.699374, 0.326823 (1.482 sec)
13.780... logprob:  0.541653, 0.252604 (1.449 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.473184, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.752109e-03 [2.387485e-07] 
Layer 'conv1' biases: 1.742472e-06 [4.991642e-10] 
Layer 'conv2' weights[0]: 4.743263e-03 [2.378241e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.697129e-09] 
Layer 'conv3' weights[0]: 4.741881e-03 [2.386190e-07] 
Layer 'conv3' biases: 2.859316e-05 [1.552949e-08] 
Layer 'conv4' weights[0]: 4.761581e-03 [2.407763e-07] 
Layer 'conv4' biases: 1.000015e+00 [2.749649e-07] 
Layer 'conv5' weights[0]: 4.847852e-03 [2.384163e-06] 
Layer 'conv5' biases: 9.991167e-01 [2.627142e-06] 
Layer 'fc6' weights[0]: 7.193757e-03 [5.978706e-08] 
Layer 'fc6' biases: 9.999946e-01 [5.555055e-08] 
Layer 'fc7' weights[0]: 7.546228e-03 [1.358299e-07] 
Layer 'fc7' biases: 9.998519e-01 [1.694236e-07] 
Layer 'fc8' weights[0]: 4.476570e-03 [1.520507e-05] 
Layer 'fc8' biases: 1.161045e-02 [2.117470e-05] 
Train error last 800 batches: 0.655203
-------------------------------------------------------
Not saving because 0.473184 > 0.299667 (9.300: -1.18%)
======================================================= (2.412 sec)
13.781... logprob:  0.629492, 0.255208 (1.446 sec)
13.782... logprob:  0.643851, 0.307292 (1.445 sec)
13.783... logprob:  0.683322, 0.305990 (1.455 sec)
13.784... logprob:  0.694405, 0.287760 (1.452 sec)
13.785... logprob:  0.717288, 0.309896 (1.509 sec)
13.786... logprob:  0.664126, 0.289062 (1.464 sec)
13.787... logprob:  0.689427, 0.290365 (1.458 sec)
13.788... logprob:  0.705450, 0.294271 (1.496 sec)
13.789... logprob:  0.575294, 0.272135 (1.456 sec)
13.790... logprob:  0.557289, 0.255208 (1.445 sec)
13.791... logprob:  0.620709, 0.294271 (1.464 sec)
13.792... logprob:  0.572090, 0.253906 (1.464 sec)
13.793... logprob:  0.625687, 0.253906 (1.459 sec)
13.794... logprob:  0.698690, 0.289062 (1.494 sec)
13.795... logprob:  0.608425, 0.290365 (1.467 sec)
13.796... logprob:  0.642169, 0.265625 (1.465 sec)
13.797... logprob:  0.576981, 0.256510 (1.500 sec)
13.798... logprob:  0.602351, 0.274740 (1.452 sec)
13.799... logprob:  0.696542, 0.302083 (1.455 sec)
13.800... logprob:  0.578999, 0.250000 (1.395 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.476463, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.747381e-03 [2.385021e-07] 
Layer 'conv1' biases: 1.743841e-06 [4.042703e-10] 
Layer 'conv2' weights[0]: 4.738507e-03 [2.378318e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.195505e-09] 
Layer 'conv3' weights[0]: 4.737113e-03 [2.383047e-07] 
Layer 'conv3' biases: 2.862788e-05 [1.529040e-08] 
Layer 'conv4' weights[0]: 4.756806e-03 [2.408346e-07] 
Layer 'conv4' biases: 1.000013e+00 [2.528334e-07] 
Layer 'conv5' weights[0]: 4.842704e-03 [2.521921e-06] 
Layer 'conv5' biases: 9.991049e-01 [2.770668e-06] 
Layer 'fc6' weights[0]: 7.193017e-03 [6.209473e-08] 
Layer 'fc6' biases: 9.999945e-01 [5.916207e-08] 
Layer 'fc7' weights[0]: 7.545428e-03 [1.420140e-07] 
Layer 'fc7' biases: 9.998526e-01 [1.920792e-07] 
Layer 'fc8' weights[0]: 4.522642e-03 [1.553358e-05] 
Layer 'fc8' biases: 1.193553e-02 [2.754030e-05] 
Train error last 800 batches: 0.654763
-------------------------------------------------------
Not saving because 0.476463 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
14.1... logprob:  0.643149, 0.270833 (1.406 sec)
14.2... logprob:  0.644962, 0.283854 (1.462 sec)
14.3... logprob:  0.628219, 0.276042 (1.427 sec)
14.4... logprob:  0.655246, 0.312500 (1.406 sec)
14.5... logprob:  0.720208, 0.300781 (1.431 sec)
14.6... logprob:  0.619484, 0.272135 (1.398 sec)
14.7... logprob:  0.597906, 0.265625 (1.428 sec)
14.8... logprob:  0.633544, 0.283854 (1.394 sec)
14.9... logprob:  0.531731, 0.246094 (1.415 sec)
14.10... logprob:  0.607977, 0.244792 (1.418 sec)
14.11... logprob:  0.603648, 0.285156 (1.450 sec)
14.12... logprob:  0.626538, 0.269531 (1.403 sec)
14.13... logprob:  0.670256, 0.315104 (1.435 sec)
14.14... logprob:  0.704991, 0.309896 (1.414 sec)
14.15... logprob:  0.641991, 0.278646 (1.417 sec)
14.16... logprob:  0.630674, 0.294271 (1.419 sec)
14.17... logprob:  0.689873, 0.296875 (1.403 sec)
14.18... logprob:  0.454182, 0.205729 (1.408 sec)
14.19... logprob:  0.545327, 0.238281 (1.411 sec)
14.20... logprob:  0.604407, 0.251302 (1.408 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.569973, 0.171875 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.742638e-03 [2.378348e-07] 
Layer 'conv1' biases: 1.744578e-06 [3.445545e-10] 
Layer 'conv2' weights[0]: 4.733771e-03 [2.375069e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.580772e-09] 
Layer 'conv3' weights[0]: 4.732391e-03 [2.380938e-07] 
Layer 'conv3' biases: 2.861039e-05 [1.685328e-08] 
Layer 'conv4' weights[0]: 4.752070e-03 [2.400844e-07] 
Layer 'conv4' biases: 1.000014e+00 [2.783233e-07] 
Layer 'conv5' weights[0]: 4.838217e-03 [2.167309e-06] 
Layer 'conv5' biases: 9.991038e-01 [2.330704e-06] 
Layer 'fc6' weights[0]: 7.192258e-03 [5.836755e-08] 
Layer 'fc6' biases: 9.999943e-01 [5.381636e-08] 
Layer 'fc7' weights[0]: 7.544734e-03 [1.275307e-07] 
Layer 'fc7' biases: 9.998531e-01 [1.493049e-07] 
Layer 'fc8' weights[0]: 4.538901e-03 [1.308377e-05] 
Layer 'fc8' biases: 1.201176e-02 [1.245599e-05] 
Train error last 800 batches: 0.654973
-------------------------------------------------------
Not saving because 0.569973 > 0.299667 (9.300: -1.18%)
======================================================= (2.382 sec)
14.21... logprob:  0.650990, 0.311198 (1.420 sec)
14.22... logprob:  0.697227, 0.286458 (1.418 sec)
14.23... logprob:  0.746720, 0.328125 (1.425 sec)
14.24... logprob:  0.595483, 0.266927 (1.424 sec)
14.25... logprob:  0.595708, 0.276042 (1.406 sec)
14.26... logprob:  0.647973, 0.279948 (1.443 sec)
14.27... logprob:  0.674569, 0.315104 (1.387 sec)
14.28... logprob:  0.574086, 0.242187 (1.406 sec)
14.29... logprob:  0.600632, 0.247396 (1.428 sec)
14.30... logprob:  0.592953, 0.260417 (1.423 sec)
14.31... logprob:  0.649282, 0.270833 (1.410 sec)
14.32... logprob:  0.690024, 0.294271 (1.385 sec)
14.33... logprob:  0.634750, 0.281250 (1.442 sec)
14.34... logprob:  0.764016, 0.335937 (1.391 sec)
14.35... logprob:  0.529725, 0.243489 (1.396 sec)
14.36... logprob:  0.686601, 0.287760 (1.402 sec)
14.37... logprob:  0.690831, 0.305989 (1.407 sec)
14.38... logprob:  0.629883, 0.257812 (1.395 sec)
14.39... logprob:  0.802863, 0.360677 (1.432 sec)
14.40... logprob:  0.635772, 0.270833 (1.410 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.473726, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.737892e-03 [2.376858e-07] 
Layer 'conv1' biases: 1.745530e-06 [5.103012e-10] 
Layer 'conv2' weights[0]: 4.729062e-03 [2.373018e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.380325e-09] 
Layer 'conv3' weights[0]: 4.727676e-03 [2.387101e-07] 
Layer 'conv3' biases: 2.864678e-05 [2.171233e-08] 
Layer 'conv4' weights[0]: 4.747321e-03 [2.413462e-07] 
Layer 'conv4' biases: 1.000014e+00 [3.381831e-07] 
Layer 'conv5' weights[0]: 4.833662e-03 [3.480968e-06] 
Layer 'conv5' biases: 9.991190e-01 [3.759171e-06] 
Layer 'fc6' weights[0]: 7.191513e-03 [7.133967e-08] 
Layer 'fc6' biases: 9.999944e-01 [7.214508e-08] 
Layer 'fc7' weights[0]: 7.543959e-03 [1.663804e-07] 
Layer 'fc7' biases: 9.998517e-01 [2.622025e-07] 
Layer 'fc8' weights[0]: 4.491197e-03 [1.988655e-05] 
Layer 'fc8' biases: 1.165333e-02 [4.378197e-05] 
Train error last 800 batches: 0.654398
-------------------------------------------------------
Not saving because 0.473726 > 0.299667 (9.300: -1.18%)
======================================================= (2.335 sec)
14.41... logprob:  0.649272, 0.286458 (1.445 sec)
14.42... logprob:  0.578469, 0.238281 (1.413 sec)
14.43... logprob:  0.692140, 0.320312 (1.409 sec)
14.44... logprob:  0.758429, 0.317708 (1.432 sec)
14.45... logprob:  0.571525, 0.264323 (1.390 sec)
14.46... logprob:  0.702554, 0.312500 (1.397 sec)
14.47... logprob:  0.595384, 0.270833 (1.391 sec)
14.48... logprob:  0.668418, 0.274740 (1.425 sec)
14.49... logprob:  0.704265, 0.312500 (1.404 sec)
14.50... logprob:  0.667596, 0.270833 (1.421 sec)
14.51... logprob:  0.666163, 0.289062 (1.421 sec)
14.52... logprob:  0.672056, 0.317708 (1.396 sec)
14.53... logprob:  0.525377, 0.217448 (1.442 sec)
14.54... logprob:  0.655378, 0.298177 (1.386 sec)
14.55... logprob:  0.499203, 0.196615 (1.394 sec)
14.56... logprob:  0.623526, 0.246094 (1.393 sec)
14.57... logprob:  0.732473, 0.317708 (1.427 sec)
14.58... logprob:  0.609893, 0.259115 (1.402 sec)
14.59... logprob:  0.542452, 0.243490 (1.459 sec)
14.60... logprob:  0.758202, 0.321615 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.488480, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.733142e-03 [2.381065e-07] 
Layer 'conv1' biases: 1.745260e-06 [4.418682e-10] 
Layer 'conv2' weights[0]: 4.724342e-03 [2.371780e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.273634e-09] 
Layer 'conv3' weights[0]: 4.722926e-03 [2.379908e-07] 
Layer 'conv3' biases: 2.871376e-05 [1.824895e-08] 
Layer 'conv4' weights[0]: 4.742579e-03 [2.403357e-07] 
Layer 'conv4' biases: 1.000014e+00 [2.889539e-07] 
Layer 'conv5' weights[0]: 4.829200e-03 [2.573948e-06] 
Layer 'conv5' biases: 9.991176e-01 [2.667719e-06] 
Layer 'fc6' weights[0]: 7.190705e-03 [6.286353e-08] 
Layer 'fc6' biases: 9.999943e-01 [5.993878e-08] 
Layer 'fc7' weights[0]: 7.543232e-03 [1.425483e-07] 
Layer 'fc7' biases: 9.998520e-01 [1.832377e-07] 
Layer 'fc8' weights[0]: 4.493230e-03 [1.602508e-05] 
Layer 'fc8' biases: 1.167061e-02 [2.574382e-05] 
Train error last 800 batches: 0.653481
-------------------------------------------------------
Not saving because 0.488480 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
14.61... logprob:  0.585708, 0.251302 (1.434 sec)
14.62... logprob:  0.669885, 0.291667 (1.459 sec)
14.63... logprob:  0.597146, 0.247396 (1.437 sec)
14.64... logprob:  0.699703, 0.292969 (1.406 sec)
14.65... logprob:  0.646439, 0.292969 (1.403 sec)
14.66... logprob:  0.574846, 0.247396 (1.444 sec)
14.67... logprob:  0.536954, 0.268229 (1.384 sec)
14.68... logprob:  0.685051, 0.276042 (1.400 sec)
14.69... logprob:  0.717136, 0.291667 (1.422 sec)
14.70... logprob:  0.535554, 0.250000 (1.427 sec)
14.71... logprob:  0.680911, 0.302083 (1.458 sec)
14.72... logprob:  0.774248, 0.322917 (1.405 sec)
14.73... logprob:  0.656402, 0.291667 (1.424 sec)
14.74... logprob:  0.698227, 0.285156 (1.411 sec)
14.75... logprob:  0.608451, 0.253906 (1.409 sec)
14.76... logprob:  0.739878, 0.308594 (1.429 sec)
14.77... logprob:  0.714161, 0.302083 (1.427 sec)
14.78... logprob:  0.698140, 0.298177 (1.451 sec)
14.79... logprob:  0.643123, 0.244792 (1.395 sec)
14.80... logprob:  0.744708, 0.303385 (1.413 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.491243, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.728401e-03 [2.373761e-07] 
Layer 'conv1' biases: 1.744977e-06 [5.501316e-10] 
Layer 'conv2' weights[0]: 4.719590e-03 [2.367775e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.036300e-09] 
Layer 'conv3' weights[0]: 4.718228e-03 [2.387548e-07] 
Layer 'conv3' biases: 2.875346e-05 [2.488573e-08] 
Layer 'conv4' weights[0]: 4.737832e-03 [2.421153e-07] 
Layer 'conv4' biases: 1.000016e+00 [4.353016e-07] 
Layer 'conv5' weights[0]: 4.825618e-03 [3.755836e-06] 
Layer 'conv5' biases: 9.991199e-01 [4.166008e-06] 
Layer 'fc6' weights[0]: 7.189993e-03 [7.594023e-08] 
Layer 'fc6' biases: 9.999942e-01 [7.818478e-08] 
Layer 'fc7' weights[0]: 7.542510e-03 [1.849082e-07] 
Layer 'fc7' biases: 9.998510e-01 [3.096986e-07] 
Layer 'fc8' weights[0]: 4.478509e-03 [2.249540e-05] 
Layer 'fc8' biases: 1.161666e-02 [5.311587e-05] 
Train error last 800 batches: 0.653558
-------------------------------------------------------
Not saving because 0.491243 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
14.81... logprob:  0.607842, 0.251302 (1.419 sec)
14.82... logprob:  0.596559, 0.298177 (1.428 sec)
14.83... logprob:  0.634786, 0.278646 (1.396 sec)
14.84... logprob:  0.649348, 0.270833 (1.461 sec)
14.85... logprob:  0.664875, 0.276042 (1.417 sec)
14.86... logprob:  0.607879, 0.282552 (1.412 sec)
14.87... logprob:  0.800567, 0.348958 (1.406 sec)
14.88... logprob:  0.666272, 0.304688 (1.404 sec)
14.89... logprob:  0.688305, 0.311198 (1.427 sec)
14.90... logprob:  0.741841, 0.342448 (1.384 sec)
14.91... logprob:  0.569021, 0.260417 (1.390 sec)
14.92... logprob:  0.639147, 0.279948 (1.397 sec)
14.93... logprob:  0.774295, 0.335937 (1.397 sec)
14.94... logprob:  0.575727, 0.259114 (1.392 sec)
14.95... logprob:  0.630601, 0.281250 (1.414 sec)
14.96... logprob:  0.751541, 0.351562 (1.413 sec)
14.97... logprob:  0.710216, 0.303385 (2.279 sec)
14.98... logprob:  0.558895, 0.229167 (1.444 sec)
14.99... logprob:  0.721544, 0.321615 (1.919 sec)
14.100... logprob:  0.533839, 0.240885 (4.746 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.515260, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.723708e-03 [2.369127e-07] 
Layer 'conv1' biases: 1.744850e-06 [4.097681e-10] 
Layer 'conv2' weights[0]: 4.714899e-03 [2.363619e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.828487e-09] 
Layer 'conv3' weights[0]: 4.713530e-03 [2.371452e-07] 
Layer 'conv3' biases: 2.874434e-05 [1.608089e-08] 
Layer 'conv4' weights[0]: 4.733083e-03 [2.391301e-07] 
Layer 'conv4' biases: 1.000016e+00 [2.533534e-07] 
Layer 'conv5' weights[0]: 4.821617e-03 [2.495075e-06] 
Layer 'conv5' biases: 9.991175e-01 [2.603598e-06] 
Layer 'fc6' weights[0]: 7.189230e-03 [6.297080e-08] 
Layer 'fc6' biases: 9.999942e-01 [6.011748e-08] 
Layer 'fc7' weights[0]: 7.541783e-03 [1.463670e-07] 
Layer 'fc7' biases: 9.998505e-01 [2.033343e-07] 
Layer 'fc8' weights[0]: 4.474204e-03 [1.706758e-05] 
Layer 'fc8' biases: 1.157459e-02 [3.087948e-05] 
Train error last 800 batches: 0.652839
-------------------------------------------------------
Not saving because 0.515260 > 0.299667 (9.300: -1.18%)
======================================================= (4.433 sec)
14.101... logprob:  0.628453, 0.287760 (1.451 sec)
14.102... logprob:  0.716602, 0.294271 (1.405 sec)
14.103... logprob:  0.769666, 0.307292 (1.515 sec)
14.104... logprob:  0.654709, 0.319010 (24.840 sec)
14.105... logprob:  0.773403, 0.316406 (1.518 sec)
14.106... logprob:  0.616351, 0.287760 (1.407 sec)
14.107... logprob:  0.648715, 0.282552 (1.444 sec)
14.108... logprob:  0.775960, 0.328125 (1.407 sec)
14.109... logprob:  0.570569, 0.238281 (1.402 sec)
14.110... logprob:  0.723086, 0.321615 (19.107 sec)
14.111... logprob:  0.553069, 0.251302 (1.781 sec)
14.112... logprob:  0.660014, 0.315104 (1.422 sec)
14.113... logprob:  0.633845, 0.277344 (1.403 sec)
14.114... logprob:  0.655804, 0.259114 (2.519 sec)
14.115... logprob:  0.650840, 0.276042 (1.430 sec)
14.116... logprob:  0.567199, 0.257812 (1.426 sec)
14.117... logprob:  0.782831, 0.332031 (1.454 sec)
14.118... logprob:  0.665337, 0.302083 (1.395 sec)
14.119... logprob:  0.574457, 0.260417 (6.032 sec)
14.120... logprob:  0.794681, 0.319010 (16.732 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.500150, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.719000e-03 [2.368562e-07] 
Layer 'conv1' biases: 1.744049e-06 [4.370669e-10] 
Layer 'conv2' weights[0]: 4.710149e-03 [2.360591e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.710742e-09] 
Layer 'conv3' weights[0]: 4.708814e-03 [2.366782e-07] 
Layer 'conv3' biases: 2.875618e-05 [1.453340e-08] 
Layer 'conv4' weights[0]: 4.728382e-03 [2.389325e-07] 
Layer 'conv4' biases: 1.000017e+00 [2.481954e-07] 
Layer 'conv5' weights[0]: 4.817285e-03 [2.352767e-06] 
Layer 'conv5' biases: 9.991117e-01 [2.544996e-06] 
Layer 'fc6' weights[0]: 7.188471e-03 [6.276313e-08] 
Layer 'fc6' biases: 9.999939e-01 [5.990090e-08] 
Layer 'fc7' weights[0]: 7.541026e-03 [1.419414e-07] 
Layer 'fc7' biases: 9.998510e-01 [1.739652e-07] 
Layer 'fc8' weights[0]: 4.492396e-03 [1.506952e-05] 
Layer 'fc8' biases: 1.169325e-02 [1.428635e-05] 
Train error last 800 batches: 0.653182
-------------------------------------------------------
Not saving because 0.500150 > 0.299667 (9.300: -1.18%)
======================================================= (2.424 sec)
14.121... logprob:  0.601191, 0.261719 (5.523 sec)
14.122... logprob:  0.720484, 0.324219 (1.459 sec)
14.123... logprob:  0.581611, 0.265625 (1.411 sec)
14.124... logprob:  0.718917, 0.304687 (4.795 sec)
14.125... logprob:  0.654277, 0.278646 (1.410 sec)
14.126... logprob:  0.637917, 0.283854 (1.802 sec)
14.127... logprob:  0.687956, 0.299479 (1.486 sec)
14.128... logprob:  0.582717, 0.261719 (1.463 sec)
14.129... logprob:  0.793117, 0.339844 (1.510 sec)
14.130... logprob:  0.610617, 0.259115 (1.429 sec)
14.131... logprob:  0.726151, 0.304687 (2.459 sec)
14.132... logprob:  0.789680, 0.338542 (1.444 sec)
14.133... logprob:  0.624438, 0.260417 (1.542 sec)
14.134... logprob:  0.591214, 0.266927 (1.446 sec)
14.135... logprob:  0.710154, 0.291667 (1.421 sec)
14.136... logprob:  0.778187, 0.326823 (1.429 sec)
14.137... logprob:  0.614025, 0.277344 (1.401 sec)
14.138... logprob:  0.709663, 0.335937 (1.453 sec)
14.139... logprob:  0.599482, 0.240885 (2.824 sec)
14.140... logprob:  0.708644, 0.290365 (1.415 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.427391, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.714266e-03 [2.365386e-07] 
Layer 'conv1' biases: 1.745275e-06 [3.517463e-10] 
Layer 'conv2' weights[0]: 4.705472e-03 [2.360496e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.027043e-09] 
Layer 'conv3' weights[0]: 4.704092e-03 [2.370399e-07] 
Layer 'conv3' biases: 2.886906e-05 [1.834729e-08] 
Layer 'conv4' weights[0]: 4.723628e-03 [2.393927e-07] 
Layer 'conv4' biases: 1.000015e+00 [2.894527e-07] 
Layer 'conv5' weights[0]: 4.811861e-03 [2.346349e-06] 
Layer 'conv5' biases: 9.991263e-01 [2.520444e-06] 
Layer 'fc6' weights[0]: 7.187692e-03 [6.152009e-08] 
Layer 'fc6' biases: 9.999940e-01 [5.782582e-08] 
Layer 'fc7' weights[0]: 7.540254e-03 [1.388684e-07] 
Layer 'fc7' biases: 9.998498e-01 [1.635707e-07] 
Layer 'fc8' weights[0]: 4.447091e-03 [1.453828e-05] 
Layer 'fc8' biases: 1.143820e-02 [1.084694e-05] 
Train error last 800 batches: 0.652980
-------------------------------------------------------
Not saving because 0.427391 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
14.141... logprob:  0.660527, 0.282552 (1.516 sec)
14.142... logprob:  0.734644, 0.303385 (1.404 sec)
14.143... logprob:  0.553756, 0.246094 (1.419 sec)
14.144... logprob:  0.665495, 0.276042 (1.424 sec)
14.145... logprob:  0.522312, 0.227865 (1.409 sec)
14.146... logprob:  0.713009, 0.311198 (1.405 sec)
14.147... logprob:  0.502413, 0.227865 (1.424 sec)
14.148... logprob:  0.630169, 0.265625 (1.385 sec)
14.149... logprob:  0.689040, 0.339844 (1.388 sec)
14.150... logprob:  0.593581, 0.270833 (1.418 sec)
14.151... logprob:  0.603691, 0.265625 (1.397 sec)
14.152... logprob:  0.945299, 0.412760 (1.388 sec)
14.153... logprob:  0.584579, 0.261719 (1.441 sec)
14.154... logprob:  0.757001, 0.320312 (1.396 sec)
14.155... logprob:  0.571161, 0.278646 (1.410 sec)
14.156... logprob:  0.542940, 0.246094 (1.430 sec)
14.157... logprob:  0.560390, 0.234375 (1.395 sec)
14.158... logprob:  0.634997, 0.250000 (1.403 sec)
14.159... logprob:  0.662699, 0.311198 (1.389 sec)
14.160... logprob:  0.632875, 0.251302 (1.385 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.440809, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.709546e-03 [2.364106e-07] 
Layer 'conv1' biases: 1.746515e-06 [4.443191e-10] 
Layer 'conv2' weights[0]: 4.700778e-03 [2.357588e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.875449e-09] 
Layer 'conv3' weights[0]: 4.699361e-03 [2.368776e-07] 
Layer 'conv3' biases: 2.892204e-05 [1.989754e-08] 
Layer 'conv4' weights[0]: 4.718912e-03 [2.388847e-07] 
Layer 'conv4' biases: 1.000015e+00 [3.170516e-07] 
Layer 'conv5' weights[0]: 4.806815e-03 [2.560516e-06] 
Layer 'conv5' biases: 9.991179e-01 [2.799971e-06] 
Layer 'fc6' weights[0]: 7.186947e-03 [6.116732e-08] 
Layer 'fc6' biases: 9.999940e-01 [5.744419e-08] 
Layer 'fc7' weights[0]: 7.539507e-03 [1.380135e-07] 
Layer 'fc7' biases: 9.998507e-01 [1.725608e-07] 
Layer 'fc8' weights[0]: 4.504500e-03 [1.548536e-05] 
Layer 'fc8' biases: 1.181999e-02 [2.596774e-05] 
Train error last 800 batches: 0.653236
-------------------------------------------------------
Not saving because 0.440809 > 0.299667 (9.300: -1.18%)
======================================================= (2.420 sec)
14.161... logprob:  0.544406, 0.238281 (1.401 sec)
14.162... logprob:  0.871679, 0.330729 (1.399 sec)
14.163... logprob:  0.688846, 0.322917 (1.416 sec)
14.164... logprob:  0.629101, 0.277344 (1.415 sec)
14.165... logprob:  0.793874, 0.351563 (1.410 sec)
14.166... logprob:  0.683614, 0.311198 (1.443 sec)
14.167... logprob:  0.659468, 0.286458 (1.427 sec)
14.168... logprob:  0.670305, 0.308594 (1.421 sec)
14.169... logprob:  0.687864, 0.324219 (1.449 sec)
14.170... logprob:  0.766950, 0.304687 (1.394 sec)
14.171... logprob:  0.791394, 0.332031 (1.414 sec)
14.172... logprob:  0.649086, 0.300781 (1.406 sec)
14.173... logprob:  0.655846, 0.286458 (1.419 sec)
14.174... logprob:  0.757097, 0.337240 (1.394 sec)
14.175... logprob:  0.733233, 0.321615 (1.462 sec)
14.176... logprob:  0.668168, 0.313802 (1.406 sec)
14.177... logprob:  0.550603, 0.234375 (1.425 sec)
14.178... logprob:  0.689532, 0.329427 (1.456 sec)
14.179... logprob:  0.575078, 0.239583 (1.404 sec)
14.180... logprob:  0.646115, 0.286458 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.469307, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.704849e-03 [2.362826e-07] 
Layer 'conv1' biases: 1.749190e-06 [4.165742e-10] 
Layer 'conv2' weights[0]: 4.696089e-03 [2.355036e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.879951e-09] 
Layer 'conv3' weights[0]: 4.694684e-03 [2.367556e-07] 
Layer 'conv3' biases: 2.898101e-05 [1.960106e-08] 
Layer 'conv4' weights[0]: 4.714215e-03 [2.387679e-07] 
Layer 'conv4' biases: 1.000013e+00 [2.770006e-07] 
Layer 'conv5' weights[0]: 4.801509e-03 [2.426864e-06] 
Layer 'conv5' biases: 9.991361e-01 [2.552488e-06] 
Layer 'fc6' weights[0]: 7.186179e-03 [6.506879e-08] 
Layer 'fc6' biases: 9.999940e-01 [6.257776e-08] 
Layer 'fc7' weights[0]: 7.538734e-03 [1.534014e-07] 
Layer 'fc7' biases: 9.998497e-01 [2.271326e-07] 
Layer 'fc8' weights[0]: 4.464171e-03 [1.925319e-05] 
Layer 'fc8' biases: 1.153359e-02 [4.492095e-05] 
Train error last 800 batches: 0.653550
-------------------------------------------------------
Not saving because 0.469307 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
14.181... logprob:  0.750674, 0.329427 (1.421 sec)
14.182... logprob:  0.668292, 0.296875 (1.419 sec)
14.183... logprob:  0.648213, 0.316406 (1.425 sec)
14.184... logprob:  0.791997, 0.333333 (1.412 sec)
14.185... logprob:  0.558936, 0.253906 (1.389 sec)
14.186... logprob:  0.661633, 0.286458 (1.393 sec)
14.187... logprob:  0.753022, 0.333333 (1.395 sec)
14.188... logprob:  0.725239, 0.317708 (1.391 sec)
14.189... logprob:  0.682317, 0.285156 (1.380 sec)
14.190... logprob:  0.498788, 0.235677 (1.433 sec)
14.191... logprob:  0.706276, 0.339844 (1.408 sec)
14.192... logprob:  0.731098, 0.294271 (1.412 sec)
14.193... logprob:  0.520949, 0.223958 (1.418 sec)
14.194... logprob:  0.594739, 0.270833 (1.407 sec)
14.195... logprob:  0.614136, 0.292969 (1.394 sec)
14.196... logprob:  0.623631, 0.298177 (1.391 sec)
14.197... logprob:  0.654253, 0.303385 (1.394 sec)
14.198... logprob:  0.641754, 0.294271 (1.399 sec)
14.199... logprob:  0.636630, 0.282552 (1.388 sec)
14.200... logprob:  0.652075, 0.279948 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.563950, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.700137e-03 [2.357587e-07] 
Layer 'conv1' biases: 1.750464e-06 [3.673356e-10] 
Layer 'conv2' weights[0]: 4.691386e-03 [2.352788e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.731952e-09] 
Layer 'conv3' weights[0]: 4.689963e-03 [2.359738e-07] 
Layer 'conv3' biases: 2.897024e-05 [1.584860e-08] 
Layer 'conv4' weights[0]: 4.709498e-03 [2.381677e-07] 
Layer 'conv4' biases: 1.000014e+00 [2.670502e-07] 
Layer 'conv5' weights[0]: 4.797572e-03 [2.600290e-06] 
Layer 'conv5' biases: 9.991218e-01 [2.752305e-06] 
Layer 'fc6' weights[0]: 7.185437e-03 [6.224649e-08] 
Layer 'fc6' biases: 9.999942e-01 [5.865419e-08] 
Layer 'fc7' weights[0]: 7.537957e-03 [1.421982e-07] 
Layer 'fc7' biases: 9.998507e-01 [1.942050e-07] 
Layer 'fc8' weights[0]: 4.522875e-03 [1.700494e-05] 
Layer 'fc8' biases: 1.194875e-02 [3.454498e-05] 
Train error last 800 batches: 0.653275
-------------------------------------------------------
Not saving because 0.563950 > 0.299667 (9.300: -1.18%)
======================================================= (2.360 sec)
14.201... logprob:  0.616397, 0.274740 (1.406 sec)
14.202... logprob:  0.750589, 0.325521 (1.397 sec)
14.203... logprob:  0.628591, 0.285156 (1.431 sec)
14.204... logprob:  0.656090, 0.286458 (1.384 sec)
14.205... logprob:  0.669975, 0.290364 (1.397 sec)
14.206... logprob:  0.643480, 0.272135 (1.393 sec)
14.207... logprob:  0.694115, 0.322917 (1.385 sec)
14.208... logprob:  0.717007, 0.294271 (1.400 sec)
14.209... logprob:  0.635266, 0.309896 (1.416 sec)
14.210... logprob:  0.719783, 0.303385 (1.415 sec)
14.211... logprob:  0.681493, 0.274740 (1.411 sec)
14.212... logprob:  0.682922, 0.299479 (1.409 sec)
14.213... logprob:  0.773787, 0.322917 (1.456 sec)
14.214... logprob:  0.732601, 0.278646 (1.423 sec)
14.215... logprob:  0.710502, 0.316406 (1.411 sec)
14.216... logprob:  0.784370, 0.322917 (1.457 sec)
14.217... logprob:  0.591732, 0.263021 (1.398 sec)
14.218... logprob:  0.603967, 0.240885 (1.415 sec)
14.219... logprob:  0.720639, 0.316406 (1.409 sec)
14.220... logprob:  0.666814, 0.299479 (1.414 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.526982, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.695461e-03 [2.353926e-07] 
Layer 'conv1' biases: 1.752287e-06 [3.935963e-10] 
Layer 'conv2' weights[0]: 4.686695e-03 [2.349503e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.377640e-09] 
Layer 'conv3' weights[0]: 4.685274e-03 [2.359533e-07] 
Layer 'conv3' biases: 2.904128e-05 [1.771953e-08] 
Layer 'conv4' weights[0]: 4.704779e-03 [2.384074e-07] 
Layer 'conv4' biases: 1.000014e+00 [2.846219e-07] 
Layer 'conv5' weights[0]: 4.792681e-03 [2.542003e-06] 
Layer 'conv5' biases: 9.991361e-01 [2.741548e-06] 
Layer 'fc6' weights[0]: 7.184724e-03 [6.630336e-08] 
Layer 'fc6' biases: 9.999941e-01 [6.447354e-08] 
Layer 'fc7' weights[0]: 7.537249e-03 [1.559698e-07] 
Layer 'fc7' biases: 9.998490e-01 [2.218801e-07] 
Layer 'fc8' weights[0]: 4.473311e-03 [1.836150e-05] 
Layer 'fc8' biases: 1.166214e-02 [3.793051e-05] 
Train error last 800 batches: 0.653952
-------------------------------------------------------
Not saving because 0.526982 > 0.299667 (9.300: -1.18%)
======================================================= (2.359 sec)
14.221... logprob:  0.648807, 0.287760 (1.403 sec)
14.222... logprob:  0.744658, 0.324219 (1.482 sec)
14.223... logprob:  0.792778, 0.329427 (1.431 sec)
14.224... logprob:  0.604432, 0.277344 (1.427 sec)
14.225... logprob:  0.614675, 0.282552 (1.441 sec)
14.226... logprob:  0.650947, 0.277344 (1.422 sec)
14.227... logprob:  0.685172, 0.311198 (1.403 sec)
14.228... logprob:  0.617201, 0.253906 (1.410 sec)
14.229... logprob:  0.750471, 0.296875 (1.411 sec)
14.230... logprob:  0.694767, 0.313802 (1.417 sec)
14.231... logprob:  0.592735, 0.255208 (1.399 sec)
14.232... logprob:  0.769779, 0.334635 (1.457 sec)
14.233... logprob:  0.720041, 0.300781 (1.417 sec)
14.234... logprob:  0.691457, 0.281250 (1.411 sec)
14.235... logprob:  0.696338, 0.315104 (1.471 sec)
14.236... logprob:  0.660488, 0.240885 (1.392 sec)
14.237... logprob:  0.601030, 0.274739 (1.419 sec)
14.238... logprob:  0.573820, 0.240885 (1.408 sec)
14.239... logprob:  0.728037, 0.309896 (1.414 sec)
14.240... logprob:  0.640573, 0.255208 (1.397 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.464157, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.690747e-03 [2.356932e-07] 
Layer 'conv1' biases: 1.751517e-06 [4.013881e-10] 
Layer 'conv2' weights[0]: 4.681995e-03 [2.350014e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.721835e-09] 
Layer 'conv3' weights[0]: 4.680609e-03 [2.360362e-07] 
Layer 'conv3' biases: 2.905016e-05 [1.865738e-08] 
Layer 'conv4' weights[0]: 4.700099e-03 [2.375027e-07] 
Layer 'conv4' biases: 1.000015e+00 [2.659617e-07] 
Layer 'conv5' weights[0]: 4.788641e-03 [2.688782e-06] 
Layer 'conv5' biases: 9.991339e-01 [2.916537e-06] 
Layer 'fc6' weights[0]: 7.183990e-03 [6.418701e-08] 
Layer 'fc6' biases: 9.999942e-01 [6.132586e-08] 
Layer 'fc7' weights[0]: 7.536464e-03 [1.498580e-07] 
Layer 'fc7' biases: 9.998482e-01 [1.966103e-07] 
Layer 'fc8' weights[0]: 4.473928e-03 [1.845637e-05] 
Layer 'fc8' biases: 1.165695e-02 [3.847357e-05] 
Train error last 800 batches: 0.654225
-------------------------------------------------------
Not saving because 0.464157 > 0.299667 (9.300: -1.18%)
======================================================= (2.356 sec)
14.241... logprob:  0.695653, 0.283854 (1.461 sec)
14.242... logprob:  0.617790, 0.299479 (1.428 sec)
14.243... logprob:  0.533651, 0.226562 (1.421 sec)
14.244... logprob:  0.522217, 0.242187 (1.441 sec)
14.245... logprob:  0.701079, 0.296875 (1.418 sec)
14.246... logprob:  0.669081, 0.292969 (1.406 sec)
14.247... logprob:  0.643784, 0.277344 (1.411 sec)
14.248... logprob:  0.541202, 0.216146 (1.410 sec)
14.249... logprob:  0.727033, 0.317708 (1.415 sec)
14.250... logprob:  0.773548, 0.345052 (1.402 sec)
14.251... logprob:  0.580887, 0.242188 (1.457 sec)
14.252... logprob:  0.562247, 0.248698 (1.419 sec)
14.253... logprob:  0.603919, 0.263021 (1.410 sec)
14.254... logprob:  0.686076, 0.270833 (1.460 sec)
14.255... logprob:  0.647162, 0.295573 (1.394 sec)
14.256... logprob:  0.539866, 0.210938 (1.418 sec)
14.257... logprob:  0.596536, 0.279948 (1.409 sec)
14.258... logprob:  0.630931, 0.286458 (1.411 sec)
14.259... logprob:  0.669574, 0.264323 (1.397 sec)
14.260... logprob:  0.587291, 0.268229 (1.449 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.433426, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.686061e-03 [2.355949e-07] 
Layer 'conv1' biases: 1.752431e-06 [3.623268e-10] 
Layer 'conv2' weights[0]: 4.677316e-03 [2.345618e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.843666e-09] 
Layer 'conv3' weights[0]: 4.675922e-03 [2.350242e-07] 
Layer 'conv3' biases: 2.906237e-05 [1.448139e-08] 
Layer 'conv4' weights[0]: 4.695392e-03 [2.373922e-07] 
Layer 'conv4' biases: 1.000014e+00 [2.515806e-07] 
Layer 'conv5' weights[0]: 4.783273e-03 [2.295762e-06] 
Layer 'conv5' biases: 9.991244e-01 [2.528199e-06] 
Layer 'fc6' weights[0]: 7.183259e-03 [6.005582e-08] 
Layer 'fc6' biases: 9.999943e-01 [5.543298e-08] 
Layer 'fc7' weights[0]: 7.535747e-03 [1.348850e-07] 
Layer 'fc7' biases: 9.998497e-01 [1.656138e-07] 
Layer 'fc8' weights[0]: 4.533000e-03 [1.508624e-05] 
Layer 'fc8' biases: 1.208680e-02 [2.318464e-05] 
Train error last 800 batches: 0.654781
-------------------------------------------------------
Not saving because 0.433426 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
14.261... logprob:  0.644898, 0.276042 (1.442 sec)
14.262... logprob:  0.715542, 0.304688 (1.424 sec)
14.263... logprob:  0.668398, 0.292969 (1.438 sec)
14.264... logprob:  0.638730, 0.273437 (1.420 sec)
14.265... logprob:  0.687697, 0.309896 (1.407 sec)
14.266... logprob:  0.656359, 0.281250 (1.413 sec)
14.267... logprob:  0.637680, 0.302083 (1.407 sec)
14.268... logprob:  0.695579, 0.307292 (1.417 sec)
14.269... logprob:  0.762036, 0.317708 (1.398 sec)
14.270... logprob:  0.723975, 0.312500 (1.454 sec)
14.271... logprob:  0.643654, 0.304688 (1.422 sec)
14.272... logprob:  0.638186, 0.272135 (1.413 sec)
14.273... logprob:  0.641503, 0.250000 (1.465 sec)
14.274... logprob:  0.717109, 0.304687 (1.402 sec)
14.275... logprob:  0.652402, 0.265625 (1.415 sec)
14.276... logprob:  0.541824, 0.225260 (1.411 sec)
14.277... logprob:  0.694709, 0.302083 (1.422 sec)
14.278... logprob:  0.509844, 0.239583 (1.414 sec)
14.279... logprob:  0.598073, 0.274740 (1.458 sec)
14.280... logprob:  0.465773, 0.218750 (1.395 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.471254, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.681376e-03 [2.351019e-07] 
Layer 'conv1' biases: 1.754698e-06 [3.600158e-10] 
Layer 'conv2' weights[0]: 4.672635e-03 [2.344756e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.855060e-09] 
Layer 'conv3' weights[0]: 4.671222e-03 [2.357862e-07] 
Layer 'conv3' biases: 2.910490e-05 [2.009939e-08] 
Layer 'conv4' weights[0]: 4.690688e-03 [2.387125e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.352479e-07] 
Layer 'conv5' weights[0]: 4.778720e-03 [3.011191e-06] 
Layer 'conv5' biases: 9.991278e-01 [3.317874e-06] 
Layer 'fc6' weights[0]: 7.182508e-03 [7.074353e-08] 
Layer 'fc6' biases: 9.999944e-01 [7.028729e-08] 
Layer 'fc7' weights[0]: 7.534979e-03 [1.721928e-07] 
Layer 'fc7' biases: 9.998490e-01 [3.033688e-07] 
Layer 'fc8' weights[0]: 4.514886e-03 [2.154640e-05] 
Layer 'fc8' biases: 1.190714e-02 [5.337024e-05] 
Train error last 800 batches: 0.654828
-------------------------------------------------------
Not saving because 0.471254 > 0.299667 (9.300: -1.18%)
======================================================= (2.391 sec)
14.281... logprob:  0.670102, 0.294271 (1.429 sec)
14.282... logprob:  0.605539, 0.283854 (1.418 sec)
14.283... logprob:  0.574026, 0.252604 (1.409 sec)
14.284... logprob:  0.638992, 0.270833 (1.402 sec)
14.285... logprob:  0.677370, 0.303385 (1.435 sec)
14.286... logprob:  0.799236, 0.332031 (1.433 sec)
14.287... logprob:  0.592813, 0.287760 (1.419 sec)
14.288... logprob:  0.520674, 0.230469 (1.432 sec)
14.289... logprob:  0.684702, 0.298177 (1.437 sec)
14.290... logprob:  0.687322, 0.321615 (1.400 sec)
14.291... logprob:  0.671477, 0.266927 (1.413 sec)
14.292... logprob:  0.719202, 0.273437 (1.411 sec)
14.293... logprob:  0.618561, 0.270833 (1.418 sec)
14.294... logprob:  0.585390, 0.270833 (1.394 sec)
14.295... logprob:  0.615594, 0.290365 (1.460 sec)
14.296... logprob:  0.629490, 0.287760 (1.415 sec)
14.297... logprob:  0.586353, 0.276042 (1.413 sec)
14.298... logprob:  0.643244, 0.272135 (1.457 sec)
14.299... logprob:  0.663258, 0.320312 (1.393 sec)
14.300... logprob:  0.652367, 0.298177 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.386369, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.676683e-03 [2.349578e-07] 
Layer 'conv1' biases: 1.756604e-06 [3.810684e-10] 
Layer 'conv2' weights[0]: 4.668002e-03 [2.338828e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.714968e-09] 
Layer 'conv3' weights[0]: 4.666567e-03 [2.344034e-07] 
Layer 'conv3' biases: 2.911603e-05 [1.277354e-08] 
Layer 'conv4' weights[0]: 4.686017e-03 [2.366524e-07] 
Layer 'conv4' biases: 1.000012e+00 [2.374597e-07] 
Layer 'conv5' weights[0]: 4.773895e-03 [2.234629e-06] 
Layer 'conv5' biases: 9.991222e-01 [2.364912e-06] 
Layer 'fc6' weights[0]: 7.181759e-03 [5.651889e-08] 
Layer 'fc6' biases: 9.999943e-01 [5.019347e-08] 
Layer 'fc7' weights[0]: 7.534224e-03 [1.265712e-07] 
Layer 'fc7' biases: 9.998498e-01 [1.418859e-07] 
Layer 'fc8' weights[0]: 4.546741e-03 [1.289330e-05] 
Layer 'fc8' biases: 1.207779e-02 [4.686982e-06] 
Train error last 800 batches: 0.654676
-------------------------------------------------------
Not saving because 0.386369 > 0.299667 (9.300: -1.18%)
======================================================= (2.388 sec)
14.301... logprob:  0.670477, 0.285156 (1.422 sec)
14.302... logprob:  0.881910, 0.341146 (1.411 sec)
14.303... logprob:  0.614353, 0.283854 (1.404 sec)
14.304... logprob:  0.650850, 0.279948 (1.440 sec)
14.305... logprob:  0.702640, 0.300781 (1.429 sec)
14.306... logprob:  0.808416, 0.335938 (1.428 sec)
14.307... logprob:  0.657855, 0.287760 (1.445 sec)
14.308... logprob:  0.601621, 0.281250 (1.446 sec)
14.309... logprob:  0.704174, 0.289062 (1.412 sec)
14.310... logprob:  0.662621, 0.292969 (1.420 sec)
14.311... logprob:  0.790909, 0.332031 (1.426 sec)
14.312... logprob:  0.731283, 0.305990 (1.420 sec)
14.313... logprob:  0.589230, 0.260417 (1.421 sec)
14.314... logprob:  0.668438, 0.283854 (1.465 sec)
14.315... logprob:  0.566278, 0.282552 (1.437 sec)
14.316... logprob:  0.680491, 0.298177 (1.423 sec)
14.317... logprob:  0.546198, 0.255208 (1.467 sec)
14.318... logprob:  0.761914, 0.352865 (1.419 sec)
14.319... logprob:  0.677454, 0.287760 (1.426 sec)
14.320... logprob:  0.558853, 0.250000 (1.419 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.515564, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.672004e-03 [2.345187e-07] 
Layer 'conv1' biases: 1.758629e-06 [4.225560e-10] 
Layer 'conv2' weights[0]: 4.663337e-03 [2.341874e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.036418e-09] 
Layer 'conv3' weights[0]: 4.661907e-03 [2.350361e-07] 
Layer 'conv3' biases: 2.919012e-05 [1.908309e-08] 
Layer 'conv4' weights[0]: 4.681337e-03 [2.369536e-07] 
Layer 'conv4' biases: 1.000012e+00 [2.809899e-07] 
Layer 'conv5' weights[0]: 4.769164e-03 [2.691913e-06] 
Layer 'conv5' biases: 9.991404e-01 [2.844762e-06] 
Layer 'fc6' weights[0]: 7.181051e-03 [6.288257e-08] 
Layer 'fc6' biases: 9.999944e-01 [5.901587e-08] 
Layer 'fc7' weights[0]: 7.533446e-03 [1.419069e-07] 
Layer 'fc7' biases: 9.998481e-01 [1.859883e-07] 
Layer 'fc8' weights[0]: 4.484071e-03 [1.593656e-05] 
Layer 'fc8' biases: 1.169396e-02 [2.405149e-05] 
Train error last 800 batches: 0.655217
-------------------------------------------------------
Not saving because 0.515564 > 0.299667 (9.300: -1.18%)
======================================================= (2.360 sec)
14.321... logprob:  0.599737, 0.265625 (1.423 sec)
14.322... logprob:  0.639592, 0.309896 (1.412 sec)
14.323... logprob:  0.672045, 0.332031 (1.475 sec)
14.324... logprob:  0.655529, 0.285156 (1.422 sec)
14.325... logprob:  0.522689, 0.229167 (1.425 sec)
14.326... logprob:  0.815547, 0.346354 (1.460 sec)
14.327... logprob:  0.696806, 0.304687 (1.419 sec)
14.328... logprob:  0.697367, 0.290364 (1.421 sec)
14.329... logprob:  0.715138, 0.312500 (1.419 sec)
14.330... logprob:  0.601502, 0.239583 (1.415 sec)
14.331... logprob:  0.569845, 0.283854 (1.412 sec)
14.332... logprob:  0.738232, 0.319010 (1.441 sec)
14.333... logprob:  0.596458, 0.274740 (1.439 sec)
14.334... logprob:  0.778379, 0.355469 (1.434 sec)
14.335... logprob:  0.574440, 0.243490 (1.431 sec)
14.336... logprob:  0.702659, 0.299479 (1.451 sec)
14.337... logprob:  0.722401, 0.307292 (1.417 sec)
14.338... logprob:  0.665910, 0.313802 (1.426 sec)
14.339... logprob:  0.735158, 0.295573 (1.448 sec)
14.340... logprob:  0.673983, 0.303385 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.367453, 0.062500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.667375e-03 [2.340964e-07] 
Layer 'conv1' biases: 1.760005e-06 [4.445133e-10] 
Layer 'conv2' weights[0]: 4.658676e-03 [2.333778e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.398566e-09] 
Layer 'conv3' weights[0]: 4.657260e-03 [2.343039e-07] 
Layer 'conv3' biases: 2.923547e-05 [1.881570e-08] 
Layer 'conv4' weights[0]: 4.676629e-03 [2.364534e-07] 
Layer 'conv4' biases: 1.000012e+00 [3.126528e-07] 
Layer 'conv5' weights[0]: 4.764816e-03 [2.896489e-06] 
Layer 'conv5' biases: 9.991339e-01 [3.159152e-06] 
Layer 'fc6' weights[0]: 7.180309e-03 [6.918041e-08] 
Layer 'fc6' biases: 9.999943e-01 [6.819864e-08] 
Layer 'fc7' weights[0]: 7.532712e-03 [1.635042e-07] 
Layer 'fc7' biases: 9.998481e-01 [2.465787e-07] 
Layer 'fc8' weights[0]: 4.507761e-03 [2.112100e-05] 
Layer 'fc8' biases: 1.178338e-02 [5.040064e-05] 
Train error last 800 batches: 0.655822
-------------------------------------------------------
Not saving because 0.367453 > 0.299667 (9.300: -1.18%)
======================================================= (2.403 sec)
14.341... logprob:  0.700195, 0.307292 (1.417 sec)
14.342... logprob:  0.695695, 0.299479 (1.458 sec)
14.343... logprob:  0.609376, 0.270833 (1.430 sec)
14.344... logprob:  0.694175, 0.316406 (1.477 sec)
14.345... logprob:  0.690208, 0.276042 (1.431 sec)
14.346... logprob:  0.696781, 0.317708 (1.429 sec)
14.347... logprob:  0.605531, 0.255208 (1.482 sec)
14.348... logprob:  0.642062, 0.278646 (1.422 sec)
14.349... logprob:  0.798704, 0.347656 (1.430 sec)
14.350... logprob:  0.588693, 0.251302 (1.428 sec)
14.351... logprob:  0.719266, 0.309896 (1.424 sec)
14.352... logprob:  0.610825, 0.277344 (1.422 sec)
14.353... logprob:  0.756043, 0.343750 (1.478 sec)
14.354... logprob:  0.851564, 0.355469 (1.425 sec)
14.355... logprob:  0.699827, 0.312500 (1.439 sec)
14.356... logprob:  0.781087, 0.337240 (1.471 sec)
14.357... logprob:  0.600323, 0.277344 (1.425 sec)
14.358... logprob:  0.608517, 0.268229 (1.433 sec)
14.359... logprob:  0.705631, 0.338542 (1.426 sec)
14.360... logprob:  0.645047, 0.287760 (1.423 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.446331, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.662706e-03 [2.335031e-07] 
Layer 'conv1' biases: 1.762257e-06 [3.599026e-10] 
Layer 'conv2' weights[0]: 4.654008e-03 [2.332218e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.058996e-09] 
Layer 'conv3' weights[0]: 4.652585e-03 [2.340302e-07] 
Layer 'conv3' biases: 2.928319e-05 [1.654445e-08] 
Layer 'conv4' weights[0]: 4.671959e-03 [2.362422e-07] 
Layer 'conv4' biases: 1.000011e+00 [2.771814e-07] 
Layer 'conv5' weights[0]: 4.760176e-03 [2.386880e-06] 
Layer 'conv5' biases: 9.991444e-01 [2.519354e-06] 
Layer 'fc6' weights[0]: 7.179542e-03 [6.268931e-08] 
Layer 'fc6' biases: 9.999943e-01 [5.884510e-08] 
Layer 'fc7' weights[0]: 7.531977e-03 [1.394912e-07] 
Layer 'fc7' biases: 9.998471e-01 [1.746037e-07] 
Layer 'fc8' weights[0]: 4.473201e-03 [1.551001e-05] 
Layer 'fc8' biases: 1.149407e-02 [1.722872e-05] 
Train error last 800 batches: 0.656354
-------------------------------------------------------
Not saving because 0.446331 > 0.299667 (9.300: -1.18%)
======================================================= (2.356 sec)
14.361... logprob:  0.635457, 0.273437 (1.430 sec)
14.362... logprob:  0.642453, 0.261719 (1.488 sec)
14.363... logprob:  0.710567, 0.294271 (1.433 sec)
14.364... logprob:  0.663343, 0.269531 (1.451 sec)
14.365... logprob:  0.619551, 0.250000 (1.464 sec)
14.366... logprob:  0.681529, 0.317708 (1.438 sec)
14.367... logprob:  0.516218, 0.243490 (1.434 sec)
14.368... logprob:  0.771807, 0.324219 (1.423 sec)
14.369... logprob:  0.596091, 0.266927 (1.428 sec)
14.370... logprob:  0.648617, 0.279948 (1.438 sec)
14.371... logprob:  0.657077, 0.285156 (1.451 sec)
14.372... logprob:  0.688040, 0.298177 (1.448 sec)
14.373... logprob:  0.654731, 0.278646 (1.448 sec)
14.374... logprob:  0.712377, 0.325521 (1.460 sec)
14.375... logprob:  0.621413, 0.260417 (1.456 sec)
14.376... logprob:  0.554619, 0.244792 (1.427 sec)
14.377... logprob:  0.662622, 0.289062 (1.441 sec)
14.378... logprob:  0.733233, 0.319010 (1.432 sec)
14.379... logprob:  0.703806, 0.296875 (1.437 sec)
14.380... logprob:  0.830845, 0.338542 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.455373, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.658038e-03 [2.339276e-07] 
Layer 'conv1' biases: 1.764215e-06 [4.962156e-10] 
Layer 'conv2' weights[0]: 4.649347e-03 [2.328384e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.169225e-09] 
Layer 'conv3' weights[0]: 4.647964e-03 [2.338673e-07] 
Layer 'conv3' biases: 2.931395e-05 [1.688595e-08] 
Layer 'conv4' weights[0]: 4.667309e-03 [2.361026e-07] 
Layer 'conv4' biases: 1.000012e+00 [2.945691e-07] 
Layer 'conv5' weights[0]: 4.756123e-03 [2.920533e-06] 
Layer 'conv5' biases: 9.991360e-01 [3.191731e-06] 
Layer 'fc6' weights[0]: 7.178765e-03 [6.836373e-08] 
Layer 'fc6' biases: 9.999943e-01 [6.688206e-08] 
Layer 'fc7' weights[0]: 7.531228e-03 [1.599069e-07] 
Layer 'fc7' biases: 9.998479e-01 [2.294683e-07] 
Layer 'fc8' weights[0]: 4.521643e-03 [1.786175e-05] 
Layer 'fc8' biases: 1.196172e-02 [3.296101e-05] 
Train error last 800 batches: 0.656409
-------------------------------------------------------
Not saving because 0.455373 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
14.381... logprob:  0.588792, 0.270833 (1.469 sec)
14.382... logprob:  0.689725, 0.305990 (1.446 sec)
14.383... logprob:  0.599593, 0.281250 (1.430 sec)
14.384... logprob:  0.725639, 0.320312 (1.476 sec)
14.385... logprob:  0.759082, 0.346354 (1.426 sec)
14.386... logprob:  0.665131, 0.279948 (1.421 sec)
14.387... logprob:  0.614639, 0.273437 (1.426 sec)
14.388... logprob:  0.814296, 0.345052 (1.430 sec)
14.389... logprob:  0.609865, 0.257812 (1.428 sec)
14.390... logprob:  0.711543, 0.316406 (1.470 sec)
14.391... logprob:  0.515360, 0.233073 (1.439 sec)
14.392... logprob:  0.714088, 0.283854 (1.426 sec)
14.393... logprob:  0.607675, 0.270833 (1.479 sec)
14.394... logprob:  0.551463, 0.259115 (1.425 sec)
14.395... logprob:  0.639222, 0.287760 (1.426 sec)
14.396... logprob:  0.474862, 0.214844 (1.429 sec)
14.397... logprob:  0.659200, 0.304688 (1.425 sec)
14.398... logprob:  0.650558, 0.273438 (1.423 sec)
14.399... logprob:  0.649971, 0.298177 (1.481 sec)
14.400... logprob:  0.747938, 0.313802 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.470025, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.653414e-03 [2.338038e-07] 
Layer 'conv1' biases: 1.764506e-06 [3.846091e-10] 
Layer 'conv2' weights[0]: 4.644717e-03 [2.327924e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.246236e-09] 
Layer 'conv3' weights[0]: 4.643307e-03 [2.335880e-07] 
Layer 'conv3' biases: 2.936638e-05 [1.696009e-08] 
Layer 'conv4' weights[0]: 4.662651e-03 [2.356588e-07] 
Layer 'conv4' biases: 1.000014e+00 [2.610884e-07] 
Layer 'conv5' weights[0]: 4.752394e-03 [2.579721e-06] 
Layer 'conv5' biases: 9.991344e-01 [2.768951e-06] 
Layer 'fc6' weights[0]: 7.177983e-03 [6.251154e-08] 
Layer 'fc6' biases: 9.999943e-01 [5.852914e-08] 
Layer 'fc7' weights[0]: 7.530442e-03 [1.428619e-07] 
Layer 'fc7' biases: 9.998476e-01 [1.895621e-07] 
Layer 'fc8' weights[0]: 4.529087e-03 [1.631827e-05] 
Layer 'fc8' biases: 1.196591e-02 [2.270499e-05] 
Train error last 800 batches: 0.656306
-------------------------------------------------------
Not saving because 0.470025 > 0.299667 (9.300: -1.18%)
======================================================= (2.360 sec)
14.401... logprob:  0.695747, 0.307292 (1.441 sec)
14.402... logprob:  0.664446, 0.274740 (1.477 sec)
14.403... logprob:  0.703013, 0.326823 (1.422 sec)
14.404... logprob:  0.741183, 0.355469 (1.429 sec)
14.405... logprob:  0.757438, 0.351562 (1.433 sec)
14.406... logprob:  0.583066, 0.259114 (1.417 sec)
14.407... logprob:  0.707248, 0.312500 (1.428 sec)
14.408... logprob:  0.649610, 0.273437 (1.475 sec)
14.409... logprob:  0.639013, 0.277344 (1.435 sec)
14.410... logprob:  0.797504, 0.311198 (1.443 sec)
14.411... logprob:  0.590772, 0.243490 (1.467 sec)
14.412... logprob:  0.781246, 0.289062 (1.429 sec)
14.413... logprob:  0.733262, 0.303385 (1.428 sec)
14.414... logprob:  0.704327, 0.286458 (1.426 sec)
14.415... logprob:  0.651701, 0.316406 (1.436 sec)
14.416... logprob:  0.634401, 0.287760 (1.432 sec)
14.417... logprob:  0.565226, 0.252604 (1.457 sec)
14.418... logprob:  0.527346, 0.234375 (1.445 sec)
14.419... logprob:  0.680612, 0.300781 (1.447 sec)
14.420... logprob:  0.607383, 0.273437 (1.450 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.519632, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.648751e-03 [2.335225e-07] 
Layer 'conv1' biases: 1.766906e-06 [4.558920e-10] 
Layer 'conv2' weights[0]: 4.640058e-03 [2.327721e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.234125e-09] 
Layer 'conv3' weights[0]: 4.638671e-03 [2.337455e-07] 
Layer 'conv3' biases: 2.937897e-05 [1.781003e-08] 
Layer 'conv4' weights[0]: 4.657982e-03 [2.365432e-07] 
Layer 'conv4' biases: 1.000013e+00 [3.000832e-07] 
Layer 'conv5' weights[0]: 4.747801e-03 [2.816763e-06] 
Layer 'conv5' biases: 9.991534e-01 [2.993741e-06] 
Layer 'fc6' weights[0]: 7.177242e-03 [6.673969e-08] 
Layer 'fc6' biases: 9.999942e-01 [6.427921e-08] 
Layer 'fc7' weights[0]: 7.529763e-03 [1.591335e-07] 
Layer 'fc7' biases: 9.998467e-01 [2.495215e-07] 
Layer 'fc8' weights[0]: 4.489899e-03 [2.102667e-05] 
Layer 'fc8' biases: 1.172472e-02 [4.046546e-05] 
Train error last 800 batches: 0.656395
-------------------------------------------------------
Not saving because 0.519632 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
14.421... logprob:  0.563956, 0.239583 (1.453 sec)
14.422... logprob:  0.792390, 0.367188 (1.431 sec)
14.423... logprob:  0.649350, 0.283854 (1.418 sec)
14.424... logprob:  0.571914, 0.269531 (1.427 sec)
14.425... logprob:  0.628820, 0.279948 (1.431 sec)
14.426... logprob:  0.754581, 0.341146 (1.436 sec)
14.427... logprob:  0.692146, 0.305990 (1.463 sec)
14.428... logprob:  0.701521, 0.330729 (1.452 sec)
14.429... logprob:  0.607200, 0.263021 (1.436 sec)
14.430... logprob:  0.556523, 0.246094 (1.470 sec)
14.431... logprob:  0.729049, 0.289062 (1.428 sec)
14.432... logprob:  0.580649, 0.260417 (1.420 sec)
14.433... logprob:  0.610047, 0.277344 (1.438 sec)
14.434... logprob:  0.684503, 0.321615 (1.436 sec)
14.435... logprob:  0.749181, 0.337240 (1.427 sec)
14.436... logprob:  0.648931, 0.278646 (1.465 sec)
14.437... logprob:  0.726842, 0.319010 (1.442 sec)
14.438... logprob:  0.661224, 0.302083 (1.423 sec)
14.439... logprob:  0.607334, 0.266927 (1.481 sec)
14.440... logprob:  0.654705, 0.292969 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.469611, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.644097e-03 [2.330223e-07] 
Layer 'conv1' biases: 1.767474e-06 [3.727577e-10] 
Layer 'conv2' weights[0]: 4.635402e-03 [2.323731e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.619787e-09] 
Layer 'conv3' weights[0]: 4.634012e-03 [2.330822e-07] 
Layer 'conv3' biases: 2.939316e-05 [1.638456e-08] 
Layer 'conv4' weights[0]: 4.653352e-03 [2.350953e-07] 
Layer 'conv4' biases: 1.000011e+00 [2.640965e-07] 
Layer 'conv5' weights[0]: 4.742691e-03 [2.363013e-06] 
Layer 'conv5' biases: 9.991426e-01 [2.480383e-06] 
Layer 'fc6' weights[0]: 7.176504e-03 [5.966172e-08] 
Layer 'fc6' biases: 9.999939e-01 [5.403000e-08] 
Layer 'fc7' weights[0]: 7.529000e-03 [1.336734e-07] 
Layer 'fc7' biases: 9.998477e-01 [1.571999e-07] 
Layer 'fc8' weights[0]: 4.537227e-03 [1.419535e-05] 
Layer 'fc8' biases: 1.212106e-02 [1.611641e-05] 
Train error last 800 batches: 0.656466
-------------------------------------------------------
Not saving because 0.469611 > 0.299667 (9.300: -1.18%)
======================================================= (2.365 sec)
14.441... logprob:  0.677478, 0.303385 (1.432 sec)
14.442... logprob:  0.634778, 0.282552 (1.432 sec)
14.443... logprob:  0.771293, 0.335937 (1.431 sec)
14.444... logprob:  0.558597, 0.253906 (1.429 sec)
14.445... logprob:  0.655443, 0.292969 (1.479 sec)
14.446... logprob:  0.595890, 0.268229 (1.435 sec)
14.447... logprob:  0.739544, 0.343750 (1.430 sec)
14.448... logprob:  0.629480, 0.309896 (1.476 sec)
14.449... logprob:  0.574842, 0.253906 (1.429 sec)
14.450... logprob:  0.563417, 0.243489 (1.433 sec)
14.451... logprob:  0.671856, 0.308594 (1.427 sec)
14.452... logprob:  0.671107, 0.289062 (1.423 sec)
14.453... logprob:  0.673359, 0.278646 (1.429 sec)
14.454... logprob:  0.749685, 0.313802 (1.491 sec)
14.455... logprob:  0.617388, 0.266927 (1.440 sec)
14.456... logprob:  0.692960, 0.321615 (1.440 sec)
14.457... logprob:  0.657284, 0.283854 (1.469 sec)
14.458... logprob:  0.584209, 0.276042 (1.429 sec)
14.459... logprob:  0.659797, 0.283854 (1.438 sec)
14.460... logprob:  0.511887, 0.190104 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.514023, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.639469e-03 [2.327808e-07] 
Layer 'conv1' biases: 1.769772e-06 [3.985062e-10] 
Layer 'conv2' weights[0]: 4.630768e-03 [2.320412e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.989384e-09] 
Layer 'conv3' weights[0]: 4.629380e-03 [2.329481e-07] 
Layer 'conv3' biases: 2.937212e-05 [1.728048e-08] 
Layer 'conv4' weights[0]: 4.648665e-03 [2.353652e-07] 
Layer 'conv4' biases: 1.000012e+00 [3.115084e-07] 
Layer 'conv5' weights[0]: 4.738443e-03 [2.510087e-06] 
Layer 'conv5' biases: 9.991366e-01 [2.725516e-06] 
Layer 'fc6' weights[0]: 7.175729e-03 [6.187520e-08] 
Layer 'fc6' biases: 9.999940e-01 [5.748378e-08] 
Layer 'fc7' weights[0]: 7.528192e-03 [1.394501e-07] 
Layer 'fc7' biases: 9.998474e-01 [1.801061e-07] 
Layer 'fc8' weights[0]: 4.553362e-03 [1.583594e-05] 
Layer 'fc8' biases: 1.220639e-02 [2.982358e-05] 
Train error last 800 batches: 0.656855
-------------------------------------------------------
Not saving because 0.514023 > 0.299667 (9.300: -1.18%)
======================================================= (2.419 sec)
14.461... logprob:  0.660675, 0.278646 (1.422 sec)
14.462... logprob:  0.702795, 0.315104 (1.435 sec)
14.463... logprob:  0.678466, 0.322917 (1.465 sec)
14.464... logprob:  0.649719, 0.295573 (1.446 sec)
14.465... logprob:  0.671474, 0.298177 (1.443 sec)
14.466... logprob:  0.563885, 0.260417 (1.457 sec)
14.467... logprob:  0.621217, 0.260417 (1.443 sec)
14.468... logprob:  0.712373, 0.345052 (1.431 sec)
14.469... logprob:  0.530854, 0.247396 (1.422 sec)
14.470... logprob:  0.679556, 0.291667 (1.422 sec)
14.471... logprob:  0.739683, 0.292969 (1.431 sec)
14.472... logprob:  0.637693, 0.285156 (1.446 sec)
14.473... logprob:  0.644906, 0.305990 (1.450 sec)
14.474... logprob:  0.768774, 0.319010 (1.452 sec)
14.475... logprob:  0.707550, 0.326823 (1.444 sec)
14.476... logprob:  0.764047, 0.328125 (1.463 sec)
14.477... logprob:  0.633745, 0.291667 (1.434 sec)
14.478... logprob:  0.678623, 0.298177 (1.419 sec)
14.479... logprob:  0.547799, 0.247396 (1.422 sec)
14.480... logprob:  0.601403, 0.302083 (1.434 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.392792, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.634812e-03 [2.324077e-07] 
Layer 'conv1' biases: 1.771386e-06 [3.606776e-10] 
Layer 'conv2' weights[0]: 4.626158e-03 [2.316388e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.389676e-09] 
Layer 'conv3' weights[0]: 4.624799e-03 [2.320929e-07] 
Layer 'conv3' biases: 2.937590e-05 [1.348535e-08] 
Layer 'conv4' weights[0]: 4.644026e-03 [2.338090e-07] 
Layer 'conv4' biases: 1.000014e+00 [2.219036e-07] 
Layer 'conv5' weights[0]: 4.734507e-03 [2.062408e-06] 
Layer 'conv5' biases: 9.991379e-01 [2.202205e-06] 
Layer 'fc6' weights[0]: 7.174963e-03 [5.959253e-08] 
Layer 'fc6' biases: 9.999940e-01 [5.429631e-08] 
Layer 'fc7' weights[0]: 7.527408e-03 [1.330497e-07] 
Layer 'fc7' biases: 9.998469e-01 [1.672286e-07] 
Layer 'fc8' weights[0]: 4.532893e-03 [1.499610e-05] 
Layer 'fc8' biases: 1.209085e-02 [2.648665e-05] 
Train error last 800 batches: 0.657253
-------------------------------------------------------
Not saving because 0.392792 > 0.299667 (9.300: -1.18%)
======================================================= (2.358 sec)
14.481... logprob:  0.683388, 0.294271 (1.438 sec)
14.482... logprob:  0.655023, 0.315104 (1.475 sec)
14.483... logprob:  0.659422, 0.319010 (1.439 sec)
14.484... logprob:  0.656839, 0.299479 (1.429 sec)
14.485... logprob:  0.712131, 0.339844 (1.481 sec)
14.486... logprob:  0.597800, 0.277344 (1.428 sec)
14.487... logprob:  0.735519, 0.315104 (1.420 sec)
14.488... logprob:  0.591254, 0.260417 (1.431 sec)
14.489... logprob:  0.615231, 0.272135 (1.428 sec)
14.490... logprob:  0.601002, 0.266927 (1.432 sec)
14.491... logprob:  0.510102, 0.203125 (1.477 sec)
14.492... logprob:  0.627555, 0.252604 (1.450 sec)
14.493... logprob:  0.679489, 0.294271 (1.426 sec)
14.494... logprob:  0.595345, 0.256510 (1.479 sec)
14.495... logprob:  0.631395, 0.264323 (1.424 sec)
14.496... logprob:  0.740105, 0.351563 (1.424 sec)
14.497... logprob:  0.621874, 0.268229 (1.435 sec)
14.498... logprob:  0.720504, 0.343750 (1.429 sec)
14.499... logprob:  0.636345, 0.289062 (1.426 sec)
14.500... logprob:  0.612132, 0.304687 (1.481 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.500459, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.630173e-03 [2.322805e-07] 
Layer 'conv1' biases: 1.774479e-06 [3.796872e-10] 
Layer 'conv2' weights[0]: 4.621528e-03 [2.317601e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.110424e-09] 
Layer 'conv3' weights[0]: 4.620172e-03 [2.323290e-07] 
Layer 'conv3' biases: 2.936141e-05 [1.549612e-08] 
Layer 'conv4' weights[0]: 4.639395e-03 [2.339187e-07] 
Layer 'conv4' biases: 1.000013e+00 [2.244240e-07] 
Layer 'conv5' weights[0]: 4.729737e-03 [2.133689e-06] 
Layer 'conv5' biases: 9.991323e-01 [2.255733e-06] 
Layer 'fc6' weights[0]: 7.174235e-03 [5.816080e-08] 
Layer 'fc6' biases: 9.999940e-01 [5.207605e-08] 
Layer 'fc7' weights[0]: 7.526647e-03 [1.299500e-07] 
Layer 'fc7' biases: 9.998470e-01 [1.547408e-07] 
Layer 'fc8' weights[0]: 4.546387e-03 [1.390771e-05] 
Layer 'fc8' biases: 1.216257e-02 [1.761858e-05] 
Train error last 800 batches: 0.656765
-------------------------------------------------------
Not saving because 0.500459 > 0.299667 (9.300: -1.18%)
======================================================= (2.375 sec)
14.501... logprob:  0.562022, 0.244792 (1.431 sec)
14.502... logprob:  0.622013, 0.263021 (1.442 sec)
14.503... logprob:  0.598366, 0.292969 (1.468 sec)
14.504... logprob:  0.712065, 0.320312 (1.425 sec)
14.505... logprob:  0.759814, 0.324219 (1.431 sec)
14.506... logprob:  0.735811, 0.328125 (1.427 sec)
14.507... logprob:  0.541893, 0.240885 (1.421 sec)
14.508... logprob:  0.638217, 0.289062 (1.431 sec)
14.509... logprob:  0.598211, 0.269531 (1.472 sec)
14.510... logprob:  0.680181, 0.312500 (1.438 sec)
14.511... logprob:  0.608417, 0.246094 (1.451 sec)
14.512... logprob:  0.653452, 0.269531 (1.491 sec)
14.513... logprob:  0.553353, 0.260417 (1.436 sec)
14.514... logprob:  0.586377, 0.272135 (1.431 sec)
14.515... logprob:  0.638771, 0.290365 (1.423 sec)
14.516... logprob:  0.633980, 0.285156 (1.425 sec)
14.517... logprob:  0.828494, 0.371094 (1.435 sec)
14.518... logprob:  0.642389, 0.298177 (1.452 sec)
14.519... logprob:  0.712915, 0.315104 (1.446 sec)
14.520... logprob:  0.666496, 0.268229 (1.453 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.462544, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.625558e-03 [2.319398e-07] 
Layer 'conv1' biases: 1.775868e-06 [3.903346e-10] 
Layer 'conv2' weights[0]: 4.616913e-03 [2.314761e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.358005e-09] 
Layer 'conv3' weights[0]: 4.615549e-03 [2.323435e-07] 
Layer 'conv3' biases: 2.940722e-05 [1.935087e-08] 
Layer 'conv4' weights[0]: 4.634760e-03 [2.342694e-07] 
Layer 'conv4' biases: 1.000015e+00 [2.670602e-07] 
Layer 'conv5' weights[0]: 4.726046e-03 [2.527457e-06] 
Layer 'conv5' biases: 9.991313e-01 [2.598204e-06] 
Layer 'fc6' weights[0]: 7.173474e-03 [6.500265e-08] 
Layer 'fc6' biases: 9.999940e-01 [6.193507e-08] 
Layer 'fc7' weights[0]: 7.525907e-03 [1.487012e-07] 
Layer 'fc7' biases: 9.998469e-01 [2.056393e-07] 
Layer 'fc8' weights[0]: 4.552848e-03 [1.726185e-05] 
Layer 'fc8' biases: 1.216617e-02 [3.538503e-05] 
Train error last 800 batches: 0.656177
-------------------------------------------------------
Not saving because 0.462544 > 0.299667 (9.300: -1.18%)
======================================================= (2.396 sec)
14.521... logprob:  0.711920, 0.339844 (1.452 sec)
14.522... logprob:  0.732890, 0.290365 (1.458 sec)
14.523... logprob:  0.574312, 0.257812 (1.438 sec)
14.524... logprob:  0.660504, 0.285156 (1.416 sec)
14.525... logprob:  0.621107, 0.277344 (1.427 sec)
14.526... logprob:  0.506314, 0.210937 (1.432 sec)
14.527... logprob:  0.755011, 0.303385 (1.433 sec)
14.528... logprob:  0.628680, 0.270833 (1.465 sec)
14.529... logprob:  0.607412, 0.277344 (1.452 sec)
14.530... logprob:  0.618318, 0.286458 (1.441 sec)
14.531... logprob:  0.730623, 0.317708 (1.471 sec)
14.532... logprob:  0.705234, 0.308594 (1.430 sec)
14.533... logprob:  0.784761, 0.332031 (1.429 sec)
14.534... logprob:  0.576896, 0.234375 (1.436 sec)
14.535... logprob:  0.725086, 0.312500 (1.435 sec)
14.536... logprob:  0.749046, 0.312500 (1.426 sec)
14.537... logprob:  0.567538, 0.252604 (1.473 sec)
14.538... logprob:  0.606355, 0.277344 (1.437 sec)
14.539... logprob:  0.586475, 0.272135 (1.424 sec)
14.540... logprob:  0.591529, 0.270833 (1.484 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.548591, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.620953e-03 [2.316881e-07] 
Layer 'conv1' biases: 1.777259e-06 [3.688228e-10] 
Layer 'conv2' weights[0]: 4.612287e-03 [2.312690e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.957233e-09] 
Layer 'conv3' weights[0]: 4.610911e-03 [2.319563e-07] 
Layer 'conv3' biases: 2.940869e-05 [1.720735e-08] 
Layer 'conv4' weights[0]: 4.630120e-03 [2.335801e-07] 
Layer 'conv4' biases: 1.000015e+00 [2.440301e-07] 
Layer 'conv5' weights[0]: 4.721788e-03 [2.410341e-06] 
Layer 'conv5' biases: 9.991417e-01 [2.662926e-06] 
Layer 'fc6' weights[0]: 7.172742e-03 [6.403183e-08] 
Layer 'fc6' biases: 9.999941e-01 [6.024727e-08] 
Layer 'fc7' weights[0]: 7.525208e-03 [1.495106e-07] 
Layer 'fc7' biases: 9.998462e-01 [2.179012e-07] 
Layer 'fc8' weights[0]: 4.540411e-03 [1.693877e-05] 
Layer 'fc8' biases: 1.200419e-02 [3.618654e-05] 
Train error last 800 batches: 0.656083
-------------------------------------------------------
Not saving because 0.548591 > 0.299667 (9.300: -1.18%)
======================================================= (2.369 sec)
14.541... logprob:  0.658522, 0.307292 (1.431 sec)
14.542... logprob:  0.647679, 0.292969 (1.425 sec)
14.543... logprob:  0.533498, 0.231771 (1.427 sec)
14.544... logprob:  0.500048, 0.216146 (1.427 sec)
14.545... logprob:  0.575805, 0.252604 (1.427 sec)
14.546... logprob:  0.548406, 0.247396 (1.480 sec)
14.547... logprob:  0.607106, 0.276042 (1.435 sec)
14.548... logprob:  0.614583, 0.269531 (1.435 sec)
14.549... logprob:  0.722278, 0.309896 (1.478 sec)
14.550... logprob:  0.579847, 0.244792 (1.432 sec)
14.551... logprob:  0.702071, 0.295573 (1.435 sec)
14.552... logprob:  0.705006, 0.289062 (1.429 sec)
14.553... logprob:  0.550099, 0.278646 (1.418 sec)
14.554... logprob:  0.686938, 0.300781 (1.430 sec)
14.555... logprob:  0.677306, 0.273437 (1.473 sec)
14.556... logprob:  0.565912, 0.259115 (1.434 sec)
14.557... logprob:  0.696087, 0.308594 (1.441 sec)
14.558... logprob:  0.573093, 0.242187 (1.464 sec)
14.559... logprob:  0.679102, 0.292969 (1.431 sec)
14.560... logprob:  0.545774, 0.265625 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.409852, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.616326e-03 [2.317619e-07] 
Layer 'conv1' biases: 1.776334e-06 [3.736844e-10] 
Layer 'conv2' weights[0]: 4.607696e-03 [2.309836e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.494918e-09] 
Layer 'conv3' weights[0]: 4.606299e-03 [2.315791e-07] 
Layer 'conv3' biases: 2.940200e-05 [1.557170e-08] 
Layer 'conv4' weights[0]: 4.625505e-03 [2.330135e-07] 
Layer 'conv4' biases: 1.000014e+00 [2.285269e-07] 
Layer 'conv5' weights[0]: 4.717306e-03 [2.182055e-06] 
Layer 'conv5' biases: 9.991187e-01 [2.445634e-06] 
Layer 'fc6' weights[0]: 7.172029e-03 [5.922497e-08] 
Layer 'fc6' biases: 9.999940e-01 [5.384889e-08] 
Layer 'fc7' weights[0]: 7.524376e-03 [1.340855e-07] 
Layer 'fc7' biases: 9.998474e-01 [1.693322e-07] 
Layer 'fc8' weights[0]: 4.608961e-03 [1.476765e-05] 
Layer 'fc8' biases: 1.255468e-02 [2.425265e-05] 
Train error last 800 batches: 0.655567
-------------------------------------------------------
Not saving because 0.409852 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
14.561... logprob:  0.643212, 0.291667 (1.428 sec)
14.562... logprob:  0.763746, 0.332031 (1.419 sec)
14.563... logprob:  0.620423, 0.253906 (1.430 sec)
14.564... logprob:  0.755316, 0.338542 (1.468 sec)
14.565... logprob:  0.845341, 0.356771 (1.449 sec)
14.566... logprob:  0.616830, 0.290365 (1.452 sec)
14.567... logprob:  0.654233, 0.273437 (1.467 sec)
14.568... logprob:  0.831083, 0.358073 (1.460 sec)
14.569... logprob:  0.710618, 0.317708 (1.436 sec)
14.570... logprob:  0.742069, 0.330729 (1.420 sec)
14.571... logprob:  0.747176, 0.322917 (1.421 sec)
14.572... logprob:  0.633035, 0.285156 (1.432 sec)
14.573... logprob:  0.703795, 0.286458 (1.440 sec)
14.574... logprob:  0.601902, 0.243490 (1.457 sec)
14.575... logprob:  0.610722, 0.261719 (1.444 sec)
14.576... logprob:  0.630932, 0.276042 (1.463 sec)
14.577... logprob:  0.697153, 0.317708 (1.469 sec)
14.578... logprob:  0.611160, 0.261719 (1.430 sec)
14.579... logprob:  0.615128, 0.242188 (1.426 sec)
14.580... logprob:  0.705086, 0.289062 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.408245, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.611714e-03 [2.320169e-07] 
Layer 'conv1' biases: 1.777775e-06 [4.210190e-10] 
Layer 'conv2' weights[0]: 4.603097e-03 [2.310045e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.065670e-09] 
Layer 'conv3' weights[0]: 4.601681e-03 [2.313932e-07] 
Layer 'conv3' biases: 2.947132e-05 [1.626275e-08] 
Layer 'conv4' weights[0]: 4.620869e-03 [2.334040e-07] 
Layer 'conv4' biases: 1.000015e+00 [2.527836e-07] 
Layer 'conv5' weights[0]: 4.712918e-03 [2.331239e-06] 
Layer 'conv5' biases: 9.991461e-01 [2.454016e-06] 
Layer 'fc6' weights[0]: 7.171271e-03 [6.209798e-08] 
Layer 'fc6' biases: 9.999940e-01 [5.770066e-08] 
Layer 'fc7' weights[0]: 7.523653e-03 [1.398587e-07] 
Layer 'fc7' biases: 9.998441e-01 [1.662056e-07] 
Layer 'fc8' weights[0]: 4.505074e-03 [1.457485e-05] 
Layer 'fc8' biases: 1.174852e-02 [1.445802e-05] 
Train error last 800 batches: 0.656084
-------------------------------------------------------
Not saving because 0.408245 > 0.299667 (9.300: -1.18%)
======================================================= (2.370 sec)
14.581... logprob:  0.702467, 0.302083 (1.442 sec)
14.582... logprob:  0.701672, 0.321615 (1.430 sec)
14.583... logprob:  0.763738, 0.332031 (1.474 sec)
14.584... logprob:  0.737535, 0.312500 (1.441 sec)
14.585... logprob:  0.658607, 0.315104 (1.424 sec)
14.586... logprob:  0.600525, 0.283854 (1.483 sec)
14.587... logprob:  0.615060, 0.272135 (1.425 sec)
14.588... logprob:  0.672444, 0.313802 (1.425 sec)
14.589... logprob:  0.673295, 0.315104 (1.429 sec)
14.590... logprob:  0.793225, 0.313802 (1.425 sec)
14.591... logprob:  0.554409, 0.268229 (1.429 sec)
14.592... logprob:  0.705751, 0.296875 (1.475 sec)
14.593... logprob:  0.698568, 0.287760 (1.431 sec)
14.594... logprob:  0.545705, 0.238281 (1.434 sec)
14.595... logprob:  0.686288, 0.295573 (1.476 sec)
14.596... logprob:  0.689211, 0.337239 (1.427 sec)
14.597... logprob:  0.665330, 0.321614 (1.424 sec)
14.598... logprob:  0.603814, 0.261719 (1.428 sec)
14.599... logprob:  0.606294, 0.261719 (1.425 sec)
14.600... logprob:  0.595495, 0.274740 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.463779, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.607089e-03 [2.312060e-07] 
Layer 'conv1' biases: 1.778498e-06 [3.335073e-10] 
Layer 'conv2' weights[0]: 4.598476e-03 [2.308977e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.308017e-09] 
Layer 'conv3' weights[0]: 4.597093e-03 [2.318755e-07] 
Layer 'conv3' biases: 2.950689e-05 [1.909016e-08] 
Layer 'conv4' weights[0]: 4.616254e-03 [2.345332e-07] 
Layer 'conv4' biases: 1.000014e+00 [3.232715e-07] 
Layer 'conv5' weights[0]: 4.708119e-03 [2.937900e-06] 
Layer 'conv5' biases: 9.991203e-01 [3.128317e-06] 
Layer 'fc6' weights[0]: 7.170489e-03 [6.899703e-08] 
Layer 'fc6' biases: 9.999942e-01 [6.736910e-08] 
Layer 'fc7' weights[0]: 7.522845e-03 [1.664937e-07] 
Layer 'fc7' biases: 9.998458e-01 [2.719034e-07] 
Layer 'fc8' weights[0]: 4.572153e-03 [2.111599e-05] 
Layer 'fc8' biases: 1.240619e-02 [4.943334e-05] 
Train error last 800 batches: 0.656460
-------------------------------------------------------
Not saving because 0.463779 > 0.299667 (9.300: -1.18%)
======================================================= (2.351 sec)
14.601... logprob:  0.629368, 0.302083 (1.485 sec)
14.602... logprob:  0.486395, 0.218750 (1.431 sec)
14.603... logprob:  0.531965, 0.234375 (1.436 sec)
14.604... logprob:  0.625285, 0.279948 (1.472 sec)
14.605... logprob:  0.824816, 0.350260 (1.431 sec)
14.606... logprob:  0.572443, 0.235677 (1.450 sec)
14.607... logprob:  0.645212, 0.289062 (1.433 sec)
14.608... logprob:  0.550264, 0.239583 (1.424 sec)
14.609... logprob:  0.557871, 0.257812 (1.433 sec)
14.610... logprob:  0.672772, 0.292969 (1.469 sec)
14.611... logprob:  0.760840, 0.338542 (1.442 sec)
14.612... logprob:  0.697408, 0.313802 (1.443 sec)
14.613... logprob:  0.483632, 0.244792 (1.466 sec)
14.614... logprob:  0.726294, 0.317708 (1.440 sec)
14.615... logprob:  0.653727, 0.285156 (1.430 sec)
14.616... logprob:  0.578072, 0.268229 (1.425 sec)
14.617... logprob:  0.528475, 0.230469 (1.427 sec)
14.618... logprob:  0.798097, 0.298177 (1.431 sec)
14.619... logprob:  0.711083, 0.279948 (1.455 sec)
14.620... logprob:  0.762613, 0.345052 (1.452 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.477511, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.602485e-03 [2.313035e-07] 
Layer 'conv1' biases: 1.779532e-06 [6.191160e-10] 
Layer 'conv2' weights[0]: 4.593891e-03 [2.306073e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.377210e-09] 
Layer 'conv3' weights[0]: 4.592522e-03 [2.324606e-07] 
Layer 'conv3' biases: 2.952200e-05 [2.517547e-08] 
Layer 'conv4' weights[0]: 4.611620e-03 [2.363227e-07] 
Layer 'conv4' biases: 1.000013e+00 [4.249938e-07] 
Layer 'conv5' weights[0]: 4.703044e-03 [3.989260e-06] 
Layer 'conv5' biases: 9.991111e-01 [4.190185e-06] 
Layer 'fc6' weights[0]: 7.169734e-03 [8.080056e-08] 
Layer 'fc6' biases: 9.999940e-01 [8.543871e-08] 
Layer 'fc7' weights[0]: 7.522094e-03 [1.979500e-07] 
Layer 'fc7' biases: 9.998462e-01 [3.465932e-07] 
Layer 'fc8' weights[0]: 4.595359e-03 [2.407708e-05] 
Layer 'fc8' biases: 1.265477e-02 [6.182336e-05] 
Train error last 800 batches: 0.656093
-------------------------------------------------------
Not saving because 0.477511 > 0.299667 (9.300: -1.18%)
======================================================= (2.358 sec)
14.621... logprob:  0.648417, 0.313802 (1.458 sec)
14.622... logprob:  0.620781, 0.304687 (1.451 sec)
14.623... logprob:  0.633991, 0.281250 (1.469 sec)
14.624... logprob:  0.613998, 0.308594 (1.433 sec)
14.625... logprob:  0.585419, 0.247396 (1.422 sec)
14.626... logprob:  0.635526, 0.304688 (1.425 sec)
14.627... logprob:  0.601105, 0.240885 (1.432 sec)
14.628... logprob:  0.670219, 0.289062 (1.432 sec)
14.629... logprob:  0.619820, 0.285156 (1.473 sec)
14.630... logprob:  0.637969, 0.259115 (1.452 sec)
14.631... logprob:  0.836038, 0.351562 (1.436 sec)
14.632... logprob:  0.618318, 0.287760 (1.476 sec)
14.633... logprob:  0.605279, 0.274740 (1.428 sec)
14.634... logprob:  0.827796, 0.380208 (1.420 sec)
14.635... logprob:  0.640095, 0.256510 (1.431 sec)
14.636... logprob:  0.715237, 0.325521 (1.426 sec)
14.637... logprob:  0.551075, 0.230469 (1.426 sec)
14.638... logprob:  0.744321, 0.300781 (1.474 sec)
14.639... logprob:  0.645488, 0.278646 (1.432 sec)
14.640... logprob:  0.723645, 0.325521 (1.432 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.559494, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.597893e-03 [2.305394e-07] 
Layer 'conv1' biases: 1.782698e-06 [4.599284e-10] 
Layer 'conv2' weights[0]: 4.589296e-03 [2.299588e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.473366e-09] 
Layer 'conv3' weights[0]: 4.587924e-03 [2.310085e-07] 
Layer 'conv3' biases: 2.959896e-05 [1.855971e-08] 
Layer 'conv4' weights[0]: 4.607057e-03 [2.338248e-07] 
Layer 'conv4' biases: 1.000010e+00 [3.558489e-07] 
Layer 'conv5' weights[0]: 4.697446e-03 [3.323563e-06] 
Layer 'conv5' biases: 9.991441e-01 [3.571437e-06] 
Layer 'fc6' weights[0]: 7.168990e-03 [7.254906e-08] 
Layer 'fc6' biases: 9.999941e-01 [7.216170e-08] 
Layer 'fc7' weights[0]: 7.521318e-03 [1.746709e-07] 
Layer 'fc7' biases: 9.998436e-01 [2.840815e-07] 
Layer 'fc8' weights[0]: 4.509628e-03 [2.195432e-05] 
Layer 'fc8' biases: 1.201681e-02 [4.733004e-05] 
Train error last 800 batches: 0.656056
-------------------------------------------------------
Not saving because 0.559494 > 0.299667 (9.300: -1.18%)
======================================================= (2.396 sec)
14.641... logprob:  0.709442, 0.276042 (1.481 sec)
14.642... logprob:  0.702366, 0.285156 (1.428 sec)
14.643... logprob:  0.776117, 0.330729 (1.423 sec)
14.644... logprob:  0.642615, 0.283854 (1.438 sec)
14.645... logprob:  0.675634, 0.265625 (1.426 sec)
14.646... logprob:  0.602264, 0.259115 (1.426 sec)
14.647... logprob:  0.610054, 0.273437 (1.480 sec)
14.648... logprob:  0.728084, 0.309896 (1.426 sec)
14.649... logprob:  0.632154, 0.273437 (1.442 sec)
14.650... logprob:  0.681281, 0.321615 (1.478 sec)
14.651... logprob:  0.663466, 0.311198 (1.431 sec)
14.652... logprob:  0.751192, 0.335937 (1.430 sec)
14.653... logprob:  0.780736, 0.328125 (1.431 sec)
14.654... logprob:  0.669913, 0.303385 (1.420 sec)
14.655... logprob:  0.684882, 0.299479 (1.425 sec)
14.656... logprob:  0.677146, 0.313802 (1.470 sec)
14.657... logprob:  0.696645, 0.295573 (1.436 sec)
14.658... logprob:  0.559332, 0.226562 (1.445 sec)
14.659... logprob:  0.655208, 0.279948 (1.461 sec)
14.660... logprob:  0.597173, 0.294271 (1.436 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.448750, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.593323e-03 [2.306264e-07] 
Layer 'conv1' biases: 1.782855e-06 [5.777081e-10] 
Layer 'conv2' weights[0]: 4.584727e-03 [2.303023e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.748614e-09] 
Layer 'conv3' weights[0]: 4.583337e-03 [2.321452e-07] 
Layer 'conv3' biases: 2.963630e-05 [2.523640e-08] 
Layer 'conv4' weights[0]: 4.602427e-03 [2.353892e-07] 
Layer 'conv4' biases: 1.000011e+00 [4.363136e-07] 
Layer 'conv5' weights[0]: 4.693466e-03 [3.373259e-06] 
Layer 'conv5' biases: 9.991497e-01 [3.676147e-06] 
Layer 'fc6' weights[0]: 7.168256e-03 [7.189576e-08] 
Layer 'fc6' biases: 9.999941e-01 [7.079372e-08] 
Layer 'fc7' weights[0]: 7.520556e-03 [1.702292e-07] 
Layer 'fc7' biases: 9.998435e-01 [2.775756e-07] 
Layer 'fc8' weights[0]: 4.516429e-03 [2.106435e-05] 
Layer 'fc8' biases: 1.198401e-02 [4.936221e-05] 
Train error last 800 batches: 0.656207
-------------------------------------------------------
Not saving because 0.448750 > 0.299667 (9.300: -1.18%)
======================================================= (2.350 sec)
14.661... logprob:  0.607946, 0.279948 (1.442 sec)
14.662... logprob:  0.668155, 0.274740 (1.431 sec)
14.663... logprob:  0.540385, 0.243490 (1.417 sec)
14.664... logprob:  0.542831, 0.269531 (1.433 sec)
14.665... logprob:  0.632870, 0.272135 (1.450 sec)
14.666... logprob:  0.701735, 0.305989 (1.448 sec)
14.667... logprob:  0.736950, 0.322917 (1.449 sec)
14.668... logprob:  0.693852, 0.294271 (1.455 sec)
14.669... logprob:  0.714151, 0.300781 (1.453 sec)
14.670... logprob:  0.597499, 0.272135 (1.432 sec)
14.671... logprob:  0.582639, 0.272135 (1.421 sec)
14.672... logprob:  0.702111, 0.312500 (1.434 sec)
14.673... logprob:  0.691698, 0.300781 (1.437 sec)
14.674... logprob:  0.592065, 0.279948 (1.433 sec)
14.675... logprob:  0.587474, 0.269531 (1.463 sec)
14.676... logprob:  0.675690, 0.274740 (1.443 sec)
14.677... logprob:  0.653069, 0.299479 (1.433 sec)
14.678... logprob:  0.580772, 0.246094 (1.476 sec)
14.679... logprob:  0.653457, 0.281250 (1.422 sec)
14.680... logprob:  0.625366, 0.268229 (1.422 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.509028, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.588711e-03 [2.297914e-07] 
Layer 'conv1' biases: 1.782960e-06 [3.812916e-10] 
Layer 'conv2' weights[0]: 4.580133e-03 [2.296498e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.240014e-09] 
Layer 'conv3' weights[0]: 4.578721e-03 [2.306892e-07] 
Layer 'conv3' biases: 2.962177e-05 [1.741740e-08] 
Layer 'conv4' weights[0]: 4.597841e-03 [2.320552e-07] 
Layer 'conv4' biases: 1.000011e+00 [2.480245e-07] 
Layer 'conv5' weights[0]: 4.689533e-03 [2.463293e-06] 
Layer 'conv5' biases: 9.991299e-01 [2.612687e-06] 
Layer 'fc6' weights[0]: 7.167494e-03 [5.934980e-08] 
Layer 'fc6' biases: 9.999941e-01 [5.380125e-08] 
Layer 'fc7' weights[0]: 7.519810e-03 [1.320662e-07] 
Layer 'fc7' biases: 9.998445e-01 [1.494344e-07] 
Layer 'fc8' weights[0]: 4.576337e-03 [1.310690e-05] 
Layer 'fc8' biases: 1.245776e-02 [8.384069e-06] 
Train error last 800 batches: 0.656109
-------------------------------------------------------
Not saving because 0.509028 > 0.299667 (9.300: -1.18%)
======================================================= (2.375 sec)
14.681... logprob:  0.548719, 0.260417 (1.436 sec)
14.682... logprob:  0.542054, 0.257812 (1.464 sec)
14.683... logprob:  0.745921, 0.351562 (1.425 sec)
14.684... logprob:  0.695247, 0.329427 (1.470 sec)
14.685... logprob:  0.479203, 0.214844 (1.443 sec)
14.686... logprob:  0.495208, 0.212240 (1.432 sec)
14.687... logprob:  0.569277, 0.274740 (1.489 sec)
14.688... logprob:  0.470566, 0.188802 (1.428 sec)
14.689... logprob:  0.685387, 0.290365 (1.505 sec)
14.690... logprob:  0.709568, 0.286458 (1.432 sec)
14.691... logprob:  0.786982, 0.325521 (1.429 sec)
14.692... logprob:  0.674296, 0.296875 (1.430 sec)
14.693... logprob:  0.664994, 0.266927 (1.478 sec)
14.694... logprob:  0.543910, 0.257812 (1.428 sec)
14.695... logprob:  0.613096, 0.253906 (1.435 sec)
14.696... logprob:  0.787926, 0.337240 (1.474 sec)
14.697... logprob:  0.615787, 0.287760 (1.432 sec)
14.698... logprob:  0.767035, 0.292969 (1.431 sec)
14.699... logprob:  0.617092, 0.292969 (1.427 sec)
14.700... logprob:  0.671607, 0.287760 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.483638, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.584151e-03 [2.303858e-07] 
Layer 'conv1' biases: 1.785177e-06 [4.904092e-10] 
Layer 'conv2' weights[0]: 4.575560e-03 [2.294731e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.654506e-09] 
Layer 'conv3' weights[0]: 4.574151e-03 [2.306150e-07] 
Layer 'conv3' biases: 2.961598e-05 [1.939731e-08] 
Layer 'conv4' weights[0]: 4.593232e-03 [2.334062e-07] 
Layer 'conv4' biases: 1.000010e+00 [3.578698e-07] 
Layer 'conv5' weights[0]: 4.684666e-03 [3.290681e-06] 
Layer 'conv5' biases: 9.991269e-01 [3.493523e-06] 
Layer 'fc6' weights[0]: 7.166765e-03 [7.055393e-08] 
Layer 'fc6' biases: 9.999942e-01 [6.979069e-08] 
Layer 'fc7' weights[0]: 7.519056e-03 [1.691954e-07] 
Layer 'fc7' biases: 9.998446e-01 [2.686886e-07] 
Layer 'fc8' weights[0]: 4.577715e-03 [1.982786e-05] 
Layer 'fc8' biases: 1.253022e-02 [4.527532e-05] 
Train error last 800 batches: 0.656021
-------------------------------------------------------
Not saving because 0.483638 > 0.299667 (9.300: -1.18%)
======================================================= (2.402 sec)
14.701... logprob:  0.620095, 0.235677 (1.433 sec)
14.702... logprob:  0.742529, 0.285156 (1.475 sec)
14.703... logprob:  0.622084, 0.286458 (1.435 sec)
14.704... logprob:  0.659388, 0.307292 (1.448 sec)
14.705... logprob:  0.640726, 0.270833 (1.467 sec)
14.706... logprob:  0.675781, 0.303385 (1.432 sec)
14.707... logprob:  0.625012, 0.269531 (1.436 sec)
14.708... logprob:  0.656372, 0.287760 (1.423 sec)
14.709... logprob:  0.601505, 0.259115 (1.422 sec)
14.710... logprob:  0.777269, 0.285156 (1.436 sec)
14.711... logprob:  0.693490, 0.278646 (1.465 sec)
14.712... logprob:  0.643293, 0.283854 (1.448 sec)
14.713... logprob:  0.728065, 0.332031 (1.449 sec)
14.714... logprob:  0.602561, 0.256510 (1.467 sec)
14.715... logprob:  0.718722, 0.312500 (1.446 sec)
14.716... logprob:  0.592987, 0.250000 (1.433 sec)
14.717... logprob:  0.698897, 0.311198 (1.419 sec)
14.718... logprob:  0.776018, 0.315104 (1.420 sec)
14.719... logprob:  0.632068, 0.268229 (1.435 sec)
14.720... logprob:  0.624462, 0.257812 (1.441 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.526880, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.579566e-03 [2.298238e-07] 
Layer 'conv1' biases: 1.784981e-06 [3.329376e-10] 
Layer 'conv2' weights[0]: 4.570963e-03 [2.291741e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.063332e-09] 
Layer 'conv3' weights[0]: 4.569547e-03 [2.305968e-07] 
Layer 'conv3' biases: 2.962517e-05 [2.125829e-08] 
Layer 'conv4' weights[0]: 4.588641e-03 [2.329282e-07] 
Layer 'conv4' biases: 1.000012e+00 [3.342322e-07] 
Layer 'conv5' weights[0]: 4.680908e-03 [2.471582e-06] 
Layer 'conv5' biases: 9.991509e-01 [2.657430e-06] 
Layer 'fc6' weights[0]: 7.165997e-03 [6.439054e-08] 
Layer 'fc6' biases: 9.999942e-01 [6.065299e-08] 
Layer 'fc7' weights[0]: 7.518271e-03 [1.457732e-07] 
Layer 'fc7' biases: 9.998422e-01 [1.857605e-07] 
Layer 'fc8' weights[0]: 4.491165e-03 [1.591115e-05] 
Layer 'fc8' biases: 1.190678e-02 [2.226218e-05] 
Train error last 800 batches: 0.656296
-------------------------------------------------------
Not saving because 0.526880 > 0.299667 (9.300: -1.18%)
======================================================= (2.358 sec)
14.721... logprob:  0.586278, 0.256510 (1.465 sec)
14.722... logprob:  0.705024, 0.322917 (1.456 sec)
14.723... logprob:  0.697043, 0.302083 (1.444 sec)
14.724... logprob:  0.638746, 0.298177 (1.464 sec)
14.725... logprob:  0.650319, 0.263021 (1.430 sec)
14.726... logprob:  0.600202, 0.265625 (1.424 sec)
14.727... logprob:  0.601243, 0.261719 (1.430 sec)
14.728... logprob:  0.619760, 0.255208 (1.433 sec)
14.729... logprob:  0.638898, 0.311198 (1.427 sec)
14.730... logprob:  0.758423, 0.311198 (1.466 sec)
14.731... logprob:  0.652093, 0.281250 (1.442 sec)
14.732... logprob:  0.597305, 0.283854 (1.438 sec)
14.733... logprob:  0.751254, 0.332031 (1.482 sec)
14.734... logprob:  0.512448, 0.205729 (1.427 sec)
14.735... logprob:  0.675962, 0.303385 (1.423 sec)
14.736... logprob:  0.744551, 0.295573 (1.438 sec)
14.737... logprob:  0.663383, 0.278646 (1.440 sec)
14.738... logprob:  0.681376, 0.313802 (1.428 sec)
14.739... logprob:  0.695001, 0.304687 (1.474 sec)
14.740... logprob:  0.624095, 0.277344 (1.432 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.510808, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.574970e-03 [2.302185e-07] 
Layer 'conv1' biases: 1.783912e-06 [4.020285e-10] 
Layer 'conv2' weights[0]: 4.566414e-03 [2.292031e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.205929e-09] 
Layer 'conv3' weights[0]: 4.564999e-03 [2.305198e-07] 
Layer 'conv3' biases: 2.959601e-05 [2.057237e-08] 
Layer 'conv4' weights[0]: 4.584060e-03 [2.325258e-07] 
Layer 'conv4' biases: 1.000015e+00 [3.265366e-07] 
Layer 'conv5' weights[0]: 4.678463e-03 [2.290046e-06] 
Layer 'conv5' biases: 9.991430e-01 [2.357921e-06] 
Layer 'fc6' weights[0]: 7.165296e-03 [6.069351e-08] 
Layer 'fc6' biases: 9.999943e-01 [5.534901e-08] 
Layer 'fc7' weights[0]: 7.517559e-03 [1.376549e-07] 
Layer 'fc7' biases: 9.998423e-01 [1.609866e-07] 
Layer 'fc8' weights[0]: 4.515003e-03 [1.399198e-05] 
Layer 'fc8' biases: 1.203008e-02 [1.251805e-05] 
Train error last 800 batches: 0.656176
-------------------------------------------------------
Not saving because 0.510808 > 0.299667 (9.300: -1.18%)
======================================================= (2.383 sec)
14.741... logprob:  0.629703, 0.299479 (1.442 sec)
14.742... logprob:  0.696765, 0.317708 (1.483 sec)
14.743... logprob:  0.576895, 0.244792 (1.424 sec)
14.744... logprob:  0.672221, 0.281250 (1.426 sec)
14.745... logprob:  0.619487, 0.298177 (1.429 sec)
14.746... logprob:  0.735278, 0.346354 (1.427 sec)
14.747... logprob:  0.734904, 0.313802 (1.423 sec)
14.748... logprob:  0.621974, 0.260417 (1.480 sec)
14.749... logprob:  0.739706, 0.313802 (1.427 sec)
14.750... logprob:  0.726816, 0.321615 (1.440 sec)
14.751... logprob:  0.565694, 0.263021 (1.471 sec)
14.752... logprob:  0.666041, 0.285156 (1.433 sec)
14.753... logprob:  0.656779, 0.256510 (1.433 sec)
14.754... logprob:  0.674381, 0.305990 (1.426 sec)
14.755... logprob:  0.783939, 0.320312 (1.422 sec)
14.756... logprob:  0.699755, 0.316406 (1.431 sec)
14.757... logprob:  0.699191, 0.312500 (1.469 sec)
14.758... logprob:  0.655659, 0.279948 (1.437 sec)
14.759... logprob:  0.741357, 0.324219 (1.448 sec)
14.760... logprob:  0.640000, 0.265625 (1.461 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.497752, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.570391e-03 [2.298032e-07] 
Layer 'conv1' biases: 1.786448e-06 [3.879199e-10] 
Layer 'conv2' weights[0]: 4.561852e-03 [2.287910e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.497483e-09] 
Layer 'conv3' weights[0]: 4.560441e-03 [2.302399e-07] 
Layer 'conv3' biases: 2.960427e-05 [2.078410e-08] 
Layer 'conv4' weights[0]: 4.579465e-03 [2.327721e-07] 
Layer 'conv4' biases: 1.000015e+00 [3.381000e-07] 
Layer 'conv5' weights[0]: 4.673631e-03 [2.963685e-06] 
Layer 'conv5' biases: 9.991454e-01 [3.167246e-06] 
Layer 'fc6' weights[0]: 7.164531e-03 [6.684751e-08] 
Layer 'fc6' biases: 9.999943e-01 [6.407267e-08] 
Layer 'fc7' weights[0]: 7.516777e-03 [1.558510e-07] 
Layer 'fc7' biases: 9.998416e-01 [2.176730e-07] 
Layer 'fc8' weights[0]: 4.509925e-03 [1.717270e-05] 
Layer 'fc8' biases: 1.200404e-02 [3.027705e-05] 
Train error last 800 batches: 0.656675
-------------------------------------------------------
Not saving because 0.497752 > 0.299667 (9.300: -1.18%)
======================================================= (2.354 sec)
14.761... logprob:  0.674999, 0.285156 (1.448 sec)
14.762... logprob:  0.771136, 0.322917 (1.439 sec)
14.763... logprob:  0.713974, 0.300781 (1.422 sec)
14.764... logprob:  0.646179, 0.274740 (1.419 sec)
14.765... logprob:  0.592429, 0.277344 (1.435 sec)
14.766... logprob:  0.611211, 0.255208 (1.447 sec)
14.767... logprob:  0.620283, 0.263021 (1.450 sec)
14.768... logprob:  0.631414, 0.286458 (1.455 sec)
14.769... logprob:  0.723917, 0.313802 (1.466 sec)
14.770... logprob:  0.659831, 0.287760 (1.474 sec)
14.771... logprob:  0.662701, 0.265625 (1.448 sec)
14.772... logprob:  0.670318, 0.302083 (1.437 sec)
14.773... logprob:  0.666251, 0.276042 (1.443 sec)
14.774... logprob:  0.609440, 0.281250 (1.456 sec)
14.775... logprob:  0.617387, 0.250000 (1.459 sec)
14.776... logprob:  0.649555, 0.296875 (1.477 sec)
14.777... logprob:  0.690535, 0.307292 (1.465 sec)
14.778... logprob:  0.630680, 0.289062 (1.457 sec)
14.779... logprob:  0.657899, 0.274740 (1.487 sec)
14.780... logprob:  0.632382, 0.286458 (1.451 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.412340, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.565834e-03 [2.291111e-07] 
Layer 'conv1' biases: 1.787948e-06 [3.402270e-10] 
Layer 'conv2' weights[0]: 4.557305e-03 [2.285348e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.864112e-09] 
Layer 'conv3' weights[0]: 4.555857e-03 [2.291786e-07] 
Layer 'conv3' biases: 2.955677e-05 [1.570687e-08] 
Layer 'conv4' weights[0]: 4.574897e-03 [2.309830e-07] 
Layer 'conv4' biases: 1.000013e+00 [2.620549e-07] 
Layer 'conv5' weights[0]: 4.668251e-03 [2.545171e-06] 
Layer 'conv5' biases: 9.991442e-01 [2.749060e-06] 
Layer 'fc6' weights[0]: 7.163816e-03 [6.626960e-08] 
Layer 'fc6' biases: 9.999942e-01 [6.293539e-08] 
Layer 'fc7' weights[0]: 7.515944e-03 [1.521896e-07] 
Layer 'fc7' biases: 9.998417e-01 [2.179626e-07] 
Layer 'fc8' weights[0]: 4.528491e-03 [1.726444e-05] 
Layer 'fc8' biases: 1.216159e-02 [3.495258e-05] 
Train error last 800 batches: 0.656615
-------------------------------------------------------
Not saving because 0.412340 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
14.781... logprob:  0.654702, 0.295573 (1.446 sec)
14.782... logprob:  0.591996, 0.276042 (1.444 sec)
14.783... logprob:  0.767961, 0.303385 (1.456 sec)
14.784... logprob:  0.677356, 0.300781 (1.450 sec)
14.785... logprob:  0.735833, 0.317708 (1.490 sec)
14.786... logprob:  0.663280, 0.320312 (1.467 sec)
14.787... logprob:  0.753811, 0.283854 (1.451 sec)
14.788... logprob:  0.758888, 0.304688 (1.496 sec)
14.789... logprob:  0.496939, 0.247396 (1.448 sec)
14.790... logprob:  0.588921, 0.291667 (1.450 sec)
14.791... logprob:  0.588453, 0.298177 (1.439 sec)
14.792... logprob:  0.582453, 0.276042 (1.456 sec)
14.793... logprob:  0.534867, 0.235677 (1.444 sec)
14.794... logprob:  0.649680, 0.294271 (1.483 sec)
14.795... logprob:  0.692245, 0.291667 (1.459 sec)
14.796... logprob:  0.716320, 0.325521 (1.453 sec)
14.797... logprob:  0.567309, 0.251302 (1.524 sec)
14.798... logprob:  0.588480, 0.246094 (1.446 sec)
14.799... logprob:  0.592118, 0.257812 (1.441 sec)
14.800... logprob:  0.583813, 0.244792 (1.419 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.425408, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.561285e-03 [2.288076e-07] 
Layer 'conv1' biases: 1.788855e-06 [3.393485e-10] 
Layer 'conv2' weights[0]: 4.552732e-03 [2.281749e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.898682e-09] 
Layer 'conv3' weights[0]: 4.551356e-03 [2.286685e-07] 
Layer 'conv3' biases: 2.951611e-05 [1.388918e-08] 
Layer 'conv4' weights[0]: 4.570300e-03 [2.309045e-07] 
Layer 'conv4' biases: 1.000011e+00 [2.549240e-07] 
Layer 'conv5' weights[0]: 4.663216e-03 [2.373399e-06] 
Layer 'conv5' biases: 9.991326e-01 [2.559531e-06] 
Layer 'fc6' weights[0]: 7.163070e-03 [6.310421e-08] 
Layer 'fc6' biases: 9.999941e-01 [5.902831e-08] 
Layer 'fc7' weights[0]: 7.515184e-03 [1.437657e-07] 
Layer 'fc7' biases: 9.998432e-01 [1.981138e-07] 
Layer 'fc8' weights[0]: 4.581445e-03 [1.582322e-05] 
Layer 'fc8' biases: 1.259711e-02 [3.257606e-05] 
Train error last 800 batches: 0.656619
-------------------------------------------------------
Not saving because 0.425408 > 0.299667 (9.300: -1.18%)
======================================================= (2.359 sec)
15.1... logprob:  0.624644, 0.274740 (1.399 sec)
15.2... logprob:  0.714162, 0.303385 (1.445 sec)
15.3... logprob:  0.683020, 0.311198 (1.415 sec)
15.4... logprob:  0.687076, 0.291667 (1.399 sec)
15.5... logprob:  0.735818, 0.345052 (1.427 sec)
15.6... logprob:  0.711046, 0.307292 (1.389 sec)
15.7... logprob:  0.634107, 0.311198 (1.421 sec)
15.8... logprob:  0.678794, 0.278646 (1.391 sec)
15.9... logprob:  0.681740, 0.320313 (1.400 sec)
15.10... logprob:  0.631443, 0.286458 (1.404 sec)
15.11... logprob:  0.546001, 0.248698 (1.437 sec)
15.12... logprob:  0.639396, 0.272135 (1.396 sec)
15.13... logprob:  0.646401, 0.299479 (1.418 sec)
15.14... logprob:  0.675087, 0.304687 (1.398 sec)
15.15... logprob:  0.545961, 0.231771 (1.403 sec)
15.16... logprob:  0.682876, 0.269531 (1.400 sec)
15.17... logprob:  0.761589, 0.311198 (1.390 sec)
15.18... logprob:  0.485644, 0.214844 (1.395 sec)
15.19... logprob:  0.552497, 0.233073 (1.393 sec)
15.20... logprob:  0.626567, 0.279948 (1.396 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.400181, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.556746e-03 [2.284389e-07] 
Layer 'conv1' biases: 1.788993e-06 [3.050799e-10] 
Layer 'conv2' weights[0]: 4.548182e-03 [2.279500e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.486600e-09] 
Layer 'conv3' weights[0]: 4.546825e-03 [2.284485e-07] 
Layer 'conv3' biases: 2.954946e-05 [1.564263e-08] 
Layer 'conv4' weights[0]: 4.565740e-03 [2.299165e-07] 
Layer 'conv4' biases: 1.000011e+00 [2.369279e-07] 
Layer 'conv5' weights[0]: 4.658663e-03 [1.990151e-06] 
Layer 'conv5' biases: 9.991394e-01 [2.257211e-06] 
Layer 'fc6' weights[0]: 7.162320e-03 [5.858125e-08] 
Layer 'fc6' biases: 9.999940e-01 [5.232553e-08] 
Layer 'fc7' weights[0]: 7.514439e-03 [1.318273e-07] 
Layer 'fc7' biases: 9.998426e-01 [1.522111e-07] 
Layer 'fc8' weights[0]: 4.564504e-03 [1.342336e-05] 
Layer 'fc8' biases: 1.246246e-02 [1.357497e-05] 
Train error last 800 batches: 0.657230
-------------------------------------------------------
Not saving because 0.400181 > 0.299667 (9.300: -1.18%)
======================================================= (2.419 sec)
15.21... logprob:  0.727481, 0.300781 (1.401 sec)
15.22... logprob:  0.787702, 0.308594 (1.415 sec)
15.23... logprob:  0.637173, 0.285156 (1.413 sec)
15.24... logprob:  0.515769, 0.222656 (1.413 sec)
15.25... logprob:  0.721373, 0.329427 (1.394 sec)
15.26... logprob:  0.792681, 0.307292 (1.440 sec)
15.27... logprob:  0.610899, 0.261719 (1.392 sec)
15.28... logprob:  0.634400, 0.299479 (1.402 sec)
15.29... logprob:  0.647170, 0.316406 (1.416 sec)
15.30... logprob:  0.592917, 0.244792 (1.408 sec)
15.31... logprob:  0.658322, 0.290365 (1.395 sec)
15.32... logprob:  0.720967, 0.307292 (1.384 sec)
15.33... logprob:  0.580016, 0.247396 (1.473 sec)
15.34... logprob:  0.674327, 0.281250 (1.385 sec)
15.35... logprob:  0.581051, 0.240885 (1.392 sec)
15.36... logprob:  0.603235, 0.272135 (1.414 sec)
15.37... logprob:  0.624662, 0.260417 (1.403 sec)
15.38... logprob:  0.567948, 0.243490 (1.389 sec)
15.39... logprob:  0.794933, 0.338542 (1.429 sec)
15.40... logprob:  0.644593, 0.286458 (1.402 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.503973, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.552178e-03 [2.282699e-07] 
Layer 'conv1' biases: 1.790173e-06 [3.712710e-10] 
Layer 'conv2' weights[0]: 4.543638e-03 [2.277983e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.916042e-09] 
Layer 'conv3' weights[0]: 4.542249e-03 [2.284316e-07] 
Layer 'conv3' biases: 2.957147e-05 [1.510918e-08] 
Layer 'conv4' weights[0]: 4.561177e-03 [2.298595e-07] 
Layer 'conv4' biases: 1.000009e+00 [2.207178e-07] 
Layer 'conv5' weights[0]: 4.653180e-03 [2.233751e-06] 
Layer 'conv5' biases: 9.991468e-01 [2.302375e-06] 
Layer 'fc6' weights[0]: 7.161570e-03 [6.083395e-08] 
Layer 'fc6' biases: 9.999940e-01 [5.544245e-08] 
Layer 'fc7' weights[0]: 7.513679e-03 [1.364819e-07] 
Layer 'fc7' biases: 9.998416e-01 [1.611741e-07] 
Layer 'fc8' weights[0]: 4.537623e-03 [1.521207e-05] 
Layer 'fc8' biases: 1.227358e-02 [2.218146e-05] 
Train error last 800 batches: 0.657265
-------------------------------------------------------
Not saving because 0.503973 > 0.299667 (9.300: -1.18%)
======================================================= (2.372 sec)
15.41... logprob:  0.534560, 0.257812 (1.427 sec)
15.42... logprob:  0.511181, 0.208333 (1.415 sec)
15.43... logprob:  0.700439, 0.299479 (1.399 sec)
15.44... logprob:  0.698318, 0.291667 (1.431 sec)
15.45... logprob:  0.646379, 0.286458 (1.391 sec)
15.46... logprob:  0.719060, 0.343750 (1.398 sec)
15.47... logprob:  0.556546, 0.246094 (1.388 sec)
15.48... logprob:  0.684245, 0.273437 (1.426 sec)
15.49... logprob:  0.712739, 0.347656 (1.411 sec)
15.50... logprob:  0.658678, 0.299479 (1.421 sec)
15.51... logprob:  0.699877, 0.296875 (1.409 sec)
15.52... logprob:  0.672512, 0.304688 (1.393 sec)
15.53... logprob:  0.560662, 0.260417 (1.436 sec)
15.54... logprob:  0.688447, 0.294271 (1.382 sec)
15.55... logprob:  0.524925, 0.235677 (1.395 sec)
15.56... logprob:  0.612254, 0.272135 (1.398 sec)
15.57... logprob:  0.745210, 0.302083 (1.425 sec)
15.58... logprob:  0.534424, 0.246094 (1.395 sec)
15.59... logprob:  0.532699, 0.247396 (1.460 sec)
15.60... logprob:  0.754466, 0.316406 (1.418 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.464699, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.547628e-03 [2.280237e-07] 
Layer 'conv1' biases: 1.791169e-06 [3.404875e-10] 
Layer 'conv2' weights[0]: 4.539103e-03 [2.274094e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.527377e-09] 
Layer 'conv3' weights[0]: 4.537707e-03 [2.278852e-07] 
Layer 'conv3' biases: 2.956193e-05 [1.312159e-08] 
Layer 'conv4' weights[0]: 4.556619e-03 [2.295247e-07] 
Layer 'conv4' biases: 1.000008e+00 [2.105982e-07] 
Layer 'conv5' weights[0]: 4.648672e-03 [2.389382e-06] 
Layer 'conv5' biases: 9.991299e-01 [2.556395e-06] 
Layer 'fc6' weights[0]: 7.160823e-03 [6.075456e-08] 
Layer 'fc6' biases: 9.999940e-01 [5.586551e-08] 
Layer 'fc7' weights[0]: 7.512927e-03 [1.364264e-07] 
Layer 'fc7' biases: 9.998424e-01 [1.701012e-07] 
Layer 'fc8' weights[0]: 4.581111e-03 [1.463956e-05] 
Layer 'fc8' biases: 1.257997e-02 [2.040265e-05] 
Train error last 800 batches: 0.657108
-------------------------------------------------------
Not saving because 0.464699 > 0.299667 (9.300: -1.18%)
======================================================= (2.393 sec)
15.61... logprob:  0.653598, 0.269531 (1.430 sec)
15.62... logprob:  0.598081, 0.268229 (1.462 sec)
15.63... logprob:  0.566332, 0.252604 (1.432 sec)
15.64... logprob:  0.722729, 0.316406 (1.406 sec)
15.65... logprob:  0.533372, 0.256510 (1.396 sec)
15.66... logprob:  0.572384, 0.242187 (1.438 sec)
15.67... logprob:  0.603239, 0.283854 (1.383 sec)
15.68... logprob:  0.633239, 0.274740 (1.395 sec)
15.69... logprob:  0.620089, 0.263021 (1.417 sec)
15.70... logprob:  0.578503, 0.281250 (1.423 sec)
15.71... logprob:  0.592048, 0.282552 (1.454 sec)
15.72... logprob:  0.694021, 0.313802 (1.399 sec)
15.73... logprob:  0.770815, 0.333333 (1.424 sec)
15.74... logprob:  0.579904, 0.223958 (1.409 sec)
15.75... logprob:  0.712187, 0.342448 (1.425 sec)
15.76... logprob:  0.601486, 0.281250 (1.429 sec)
15.77... logprob:  0.609765, 0.255208 (1.424 sec)
15.78... logprob:  0.712235, 0.316406 (1.444 sec)
15.79... logprob:  0.671545, 0.272135 (1.400 sec)
15.80... logprob:  0.700790, 0.298177 (1.418 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.542726, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.543084e-03 [2.278979e-07] 
Layer 'conv1' biases: 1.790027e-06 [3.273976e-10] 
Layer 'conv2' weights[0]: 4.534575e-03 [2.274022e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.431744e-09] 
Layer 'conv3' weights[0]: 4.533145e-03 [2.287459e-07] 
Layer 'conv3' biases: 2.954168e-05 [1.964725e-08] 
Layer 'conv4' weights[0]: 4.552054e-03 [2.313495e-07] 
Layer 'conv4' biases: 1.000010e+00 [3.405033e-07] 
Layer 'conv5' weights[0]: 4.644907e-03 [2.882021e-06] 
Layer 'conv5' biases: 9.991186e-01 [3.093296e-06] 
Layer 'fc6' weights[0]: 7.160099e-03 [6.780470e-08] 
Layer 'fc6' biases: 9.999940e-01 [6.597308e-08] 
Layer 'fc7' weights[0]: 7.512156e-03 [1.551012e-07] 
Layer 'fc7' biases: 9.998430e-01 [2.290072e-07] 
Layer 'fc8' weights[0]: 4.604451e-03 [1.729092e-05] 
Layer 'fc8' biases: 1.273095e-02 [3.360382e-05] 
Train error last 800 batches: 0.656508
-------------------------------------------------------
Not saving because 0.542726 > 0.299667 (9.300: -1.18%)
======================================================= (2.395 sec)
15.81... logprob:  0.666503, 0.277344 (1.427 sec)
15.82... logprob:  0.517453, 0.242187 (1.423 sec)
15.83... logprob:  0.720720, 0.296875 (1.394 sec)
15.84... logprob:  0.666219, 0.303385 (1.457 sec)
15.85... logprob:  0.616266, 0.272135 (1.420 sec)
15.86... logprob:  0.635307, 0.272135 (1.412 sec)
15.87... logprob:  0.915018, 0.361979 (1.410 sec)
15.88... logprob:  0.736727, 0.291667 (1.400 sec)
15.89... logprob:  0.682693, 0.286458 (1.428 sec)
15.90... logprob:  0.781771, 0.317708 (1.384 sec)
15.91... logprob:  0.627736, 0.282552 (1.390 sec)
15.92... logprob:  0.730697, 0.339844 (1.396 sec)
15.93... logprob:  0.672320, 0.291667 (1.392 sec)
15.94... logprob:  0.601466, 0.281250 (1.389 sec)
15.95... logprob:  0.703749, 0.277344 (1.401 sec)
15.96... logprob:  0.816545, 0.343750 (1.405 sec)
15.97... logprob:  0.676740, 0.319010 (1.393 sec)
15.98... logprob:  0.648402, 0.307292 (1.438 sec)
15.99... logprob:  0.659963, 0.273438 (1.400 sec)
15.100... logprob:  0.614864, 0.257812 (1.391 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.448514, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.538545e-03 [2.279733e-07] 
Layer 'conv1' biases: 1.790247e-06 [3.820015e-10] 
Layer 'conv2' weights[0]: 4.530040e-03 [2.271799e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.798945e-09] 
Layer 'conv3' weights[0]: 4.528626e-03 [2.279943e-07] 
Layer 'conv3' biases: 2.955791e-05 [1.662216e-08] 
Layer 'conv4' weights[0]: 4.547524e-03 [2.301024e-07] 
Layer 'conv4' biases: 1.000007e+00 [2.868732e-07] 
Layer 'conv5' weights[0]: 4.639289e-03 [2.549196e-06] 
Layer 'conv5' biases: 9.991561e-01 [2.666914e-06] 
Layer 'fc6' weights[0]: 7.159343e-03 [6.061084e-08] 
Layer 'fc6' biases: 9.999943e-01 [5.523237e-08] 
Layer 'fc7' weights[0]: 7.511450e-03 [1.371001e-07] 
Layer 'fc7' biases: 9.998394e-01 [1.608774e-07] 
Layer 'fc8' weights[0]: 4.481272e-03 [1.410174e-05] 
Layer 'fc8' biases: 1.187415e-02 [1.316700e-05] 
Train error last 800 batches: 0.657218
-------------------------------------------------------
Not saving because 0.448514 > 0.299667 (9.300: -1.18%)
======================================================= (2.371 sec)
15.101... logprob:  0.542678, 0.236979 (1.453 sec)
15.102... logprob:  0.750843, 0.339844 (1.387 sec)
15.103... logprob:  0.644513, 0.290365 (1.392 sec)
15.104... logprob:  0.636459, 0.290365 (1.400 sec)
15.105... logprob:  0.749609, 0.316406 (1.402 sec)
15.106... logprob:  0.578320, 0.266927 (1.397 sec)
15.107... logprob:  0.523715, 0.234375 (1.435 sec)
15.108... logprob:  0.655949, 0.277344 (1.391 sec)
15.109... logprob:  0.596322, 0.283854 (1.403 sec)
15.110... logprob:  0.725652, 0.338542 (1.393 sec)
15.111... logprob:  0.600827, 0.263021 (1.394 sec)
15.112... logprob:  0.678746, 0.305989 (1.393 sec)
15.113... logprob:  0.546969, 0.244792 (1.395 sec)
15.114... logprob:  0.692974, 0.294271 (1.455 sec)
15.115... logprob:  0.710756, 0.317708 (1.407 sec)
15.116... logprob:  0.583336, 0.250000 (1.393 sec)
15.117... logprob:  0.623115, 0.272135 (1.441 sec)
15.118... logprob:  0.641206, 0.263021 (1.385 sec)
15.119... logprob:  0.492107, 0.238281 (1.391 sec)
15.120... logprob:  0.843813, 0.368490 (1.392 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.360848, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.534008e-03 [2.273055e-07] 
Layer 'conv1' biases: 1.791574e-06 [3.816136e-10] 
Layer 'conv2' weights[0]: 4.525516e-03 [2.268078e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.676884e-09] 
Layer 'conv3' weights[0]: 4.524089e-03 [2.275405e-07] 
Layer 'conv3' biases: 2.954185e-05 [1.560687e-08] 
Layer 'conv4' weights[0]: 4.542977e-03 [2.295490e-07] 
Layer 'conv4' biases: 1.000007e+00 [2.559985e-07] 
Layer 'conv5' weights[0]: 4.634860e-03 [2.513897e-06] 
Layer 'conv5' biases: 9.991251e-01 [2.713503e-06] 
Layer 'fc6' weights[0]: 7.158597e-03 [6.145710e-08] 
Layer 'fc6' biases: 9.999941e-01 [5.693192e-08] 
Layer 'fc7' weights[0]: 7.510665e-03 [1.387911e-07] 
Layer 'fc7' biases: 9.998412e-01 [1.708391e-07] 
Layer 'fc8' weights[0]: 4.580196e-03 [1.494855e-05] 
Layer 'fc8' biases: 1.260504e-02 [2.256293e-05] 
Train error last 800 batches: 0.656471
-------------------------------------------------------
Not saving because 0.360848 > 0.299667 (9.300: -1.18%)
======================================================= (2.380 sec)
15.121... logprob:  0.618422, 0.264323 (1.403 sec)
15.122... logprob:  0.731883, 0.311198 (1.445 sec)
15.123... logprob:  0.631709, 0.292969 (1.384 sec)
15.124... logprob:  0.633320, 0.289062 (1.396 sec)
15.125... logprob:  0.788699, 0.335937 (1.393 sec)
15.126... logprob:  0.694141, 0.312500 (1.384 sec)
15.127... logprob:  0.636414, 0.287760 (1.393 sec)
15.128... logprob:  0.616794, 0.285156 (1.410 sec)
15.129... logprob:  0.745197, 0.325521 (1.411 sec)
15.130... logprob:  0.563840, 0.246094 (1.408 sec)
15.131... logprob:  0.656444, 0.298177 (1.403 sec)
15.132... logprob:  0.710284, 0.276042 (1.431 sec)
15.133... logprob:  0.675963, 0.278646 (1.386 sec)
15.134... logprob:  0.592235, 0.257812 (1.390 sec)
15.135... logprob:  0.612076, 0.282552 (1.393 sec)
15.136... logprob:  0.820554, 0.352865 (1.393 sec)
15.137... logprob:  0.687970, 0.296875 (1.381 sec)
15.138... logprob:  0.557706, 0.248698 (1.440 sec)
15.139... logprob:  0.661910, 0.298177 (1.391 sec)
15.140... logprob:  0.732369, 0.317708 (1.406 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.513127, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.529484e-03 [2.269358e-07] 
Layer 'conv1' biases: 1.794398e-06 [3.741948e-10] 
Layer 'conv2' weights[0]: 4.520977e-03 [2.264953e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.359478e-09] 
Layer 'conv3' weights[0]: 4.519562e-03 [2.274154e-07] 
Layer 'conv3' biases: 2.956956e-05 [1.677164e-08] 
Layer 'conv4' weights[0]: 4.538423e-03 [2.296078e-07] 
Layer 'conv4' biases: 1.000005e+00 [2.867529e-07] 
Layer 'conv5' weights[0]: 4.629890e-03 [2.880466e-06] 
Layer 'conv5' biases: 9.991474e-01 [3.207614e-06] 
Layer 'fc6' weights[0]: 7.157826e-03 [6.579550e-08] 
Layer 'fc6' biases: 9.999941e-01 [6.262611e-08] 
Layer 'fc7' weights[0]: 7.509969e-03 [1.542015e-07] 
Layer 'fc7' biases: 9.998392e-01 [2.203861e-07] 
Layer 'fc8' weights[0]: 4.510251e-03 [1.770565e-05] 
Layer 'fc8' biases: 1.206277e-02 [3.345374e-05] 
Train error last 800 batches: 0.656380
-------------------------------------------------------
Not saving because 0.513127 > 0.299667 (9.300: -1.18%)
======================================================= (2.355 sec)
15.141... logprob:  0.725784, 0.330729 (1.440 sec)
15.142... logprob:  0.693003, 0.289062 (1.397 sec)
15.143... logprob:  0.620524, 0.304687 (1.419 sec)
15.144... logprob:  0.597253, 0.261719 (1.410 sec)
15.145... logprob:  0.576779, 0.246094 (1.409 sec)
15.146... logprob:  0.599508, 0.281250 (1.404 sec)
15.147... logprob:  0.592398, 0.276042 (1.425 sec)
15.148... logprob:  0.711449, 0.294271 (1.386 sec)
15.149... logprob:  0.597518, 0.268229 (1.386 sec)
15.150... logprob:  0.659231, 0.303385 (1.395 sec)
15.151... logprob:  0.562071, 0.251302 (1.402 sec)
15.152... logprob:  0.818198, 0.337240 (1.383 sec)
15.153... logprob:  0.644254, 0.292969 (1.460 sec)
15.154... logprob:  0.693601, 0.311198 (1.395 sec)
15.155... logprob:  0.597923, 0.269531 (1.402 sec)
15.156... logprob:  0.545721, 0.252604 (1.429 sec)
15.157... logprob:  0.575663, 0.261719 (1.388 sec)
15.158... logprob:  0.625091, 0.260417 (1.395 sec)
15.159... logprob:  0.652203, 0.263021 (1.389 sec)
15.160... logprob:  0.606844, 0.287760 (1.389 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.464182, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.524930e-03 [2.273099e-07] 
Layer 'conv1' biases: 1.796946e-06 [3.923227e-10] 
Layer 'conv2' weights[0]: 4.516463e-03 [2.264724e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.666977e-09] 
Layer 'conv3' weights[0]: 4.515040e-03 [2.273120e-07] 
Layer 'conv3' biases: 2.961568e-05 [1.684118e-08] 
Layer 'conv4' weights[0]: 4.533873e-03 [2.297990e-07] 
Layer 'conv4' biases: 1.000005e+00 [3.138327e-07] 
Layer 'conv5' weights[0]: 4.625465e-03 [2.659698e-06] 
Layer 'conv5' biases: 9.991187e-01 [2.916226e-06] 
Layer 'fc6' weights[0]: 7.157093e-03 [6.242295e-08] 
Layer 'fc6' biases: 9.999940e-01 [5.832321e-08] 
Layer 'fc7' weights[0]: 7.509230e-03 [1.460593e-07] 
Layer 'fc7' biases: 9.998413e-01 [2.118595e-07] 
Layer 'fc8' weights[0]: 4.601585e-03 [1.721552e-05] 
Layer 'fc8' biases: 1.276245e-02 [3.868112e-05] 
Train error last 800 batches: 0.656298
-------------------------------------------------------
Not saving because 0.464182 > 0.299667 (9.300: -1.18%)
======================================================= (2.348 sec)
15.161... logprob:  0.607188, 0.242188 (1.404 sec)
15.162... logprob:  0.778080, 0.343750 (1.403 sec)
15.163... logprob:  0.687044, 0.289062 (1.418 sec)
15.164... logprob:  0.688202, 0.290365 (1.412 sec)
15.165... logprob:  0.787752, 0.329427 (1.412 sec)
15.166... logprob:  0.637509, 0.261719 (1.451 sec)
15.167... logprob:  0.597512, 0.257812 (1.426 sec)
15.168... logprob:  0.584069, 0.250000 (1.419 sec)
15.169... logprob:  0.622519, 0.296875 (1.452 sec)
15.170... logprob:  0.691575, 0.299479 (1.402 sec)
15.171... logprob:  0.715533, 0.332031 (1.417 sec)
15.172... logprob:  0.709686, 0.320312 (1.404 sec)
15.173... logprob:  0.770975, 0.326823 (1.419 sec)
15.174... logprob:  0.785129, 0.325521 (1.393 sec)
15.175... logprob:  0.773672, 0.329427 (1.459 sec)
15.176... logprob:  0.768562, 0.337240 (1.411 sec)
15.177... logprob:  0.525444, 0.244792 (1.419 sec)
15.178... logprob:  0.667140, 0.302083 (1.454 sec)
15.179... logprob:  0.608631, 0.287760 (1.402 sec)
15.180... logprob:  0.702262, 0.317708 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.438501, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.520418e-03 [2.266821e-07] 
Layer 'conv1' biases: 1.800634e-06 [3.929103e-10] 
Layer 'conv2' weights[0]: 4.511946e-03 [2.259890e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.943116e-09] 
Layer 'conv3' weights[0]: 4.510567e-03 [2.271305e-07] 
Layer 'conv3' biases: 2.967352e-05 [1.799091e-08] 
Layer 'conv4' weights[0]: 4.529355e-03 [2.288590e-07] 
Layer 'conv4' biases: 1.000003e+00 [2.872673e-07] 
Layer 'conv5' weights[0]: 4.620316e-03 [2.583516e-06] 
Layer 'conv5' biases: 9.991470e-01 [2.815638e-06] 
Layer 'fc6' weights[0]: 7.156304e-03 [6.506783e-08] 
Layer 'fc6' biases: 9.999942e-01 [6.190641e-08] 
Layer 'fc7' weights[0]: 7.508501e-03 [1.481288e-07] 
Layer 'fc7' biases: 9.998392e-01 [2.049725e-07] 
Layer 'fc8' weights[0]: 4.528061e-03 [1.660128e-05] 
Layer 'fc8' biases: 1.228736e-02 [3.439142e-05] 
Train error last 800 batches: 0.656294
-------------------------------------------------------
Not saving because 0.438501 > 0.299667 (9.300: -1.18%)
======================================================= (2.368 sec)
15.181... logprob:  0.662763, 0.295573 (1.419 sec)
15.182... logprob:  0.670833, 0.285156 (1.416 sec)
15.183... logprob:  0.572427, 0.227865 (1.412 sec)
15.184... logprob:  0.647215, 0.265625 (1.418 sec)
15.185... logprob:  0.530419, 0.240885 (1.400 sec)
15.186... logprob:  0.651518, 0.307292 (1.390 sec)
15.187... logprob:  0.641128, 0.270833 (1.395 sec)
15.188... logprob:  0.700588, 0.303385 (1.389 sec)
15.189... logprob:  0.570107, 0.246094 (1.381 sec)
15.190... logprob:  0.605841, 0.261719 (1.432 sec)
15.191... logprob:  0.663611, 0.294271 (1.398 sec)
15.192... logprob:  0.653430, 0.268229 (1.437 sec)
15.193... logprob:  0.593178, 0.282552 (1.409 sec)
15.194... logprob:  0.588273, 0.253906 (1.411 sec)
15.195... logprob:  0.424931, 0.192708 (1.399 sec)
15.196... logprob:  0.636364, 0.272135 (1.387 sec)
15.197... logprob:  0.635710, 0.250000 (1.390 sec)
15.198... logprob:  0.568086, 0.250000 (1.401 sec)
15.199... logprob:  0.681905, 0.278646 (1.387 sec)
15.200... logprob:  0.637091, 0.259115 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.424781, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.515913e-03 [2.270967e-07] 
Layer 'conv1' biases: 1.802346e-06 [3.462505e-10] 
Layer 'conv2' weights[0]: 4.507447e-03 [2.262980e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.597092e-09] 
Layer 'conv3' weights[0]: 4.506074e-03 [2.271100e-07] 
Layer 'conv3' biases: 2.970689e-05 [1.791808e-08] 
Layer 'conv4' weights[0]: 4.524837e-03 [2.293152e-07] 
Layer 'conv4' biases: 1.000002e+00 [3.207547e-07] 
Layer 'conv5' weights[0]: 4.615768e-03 [2.492502e-06] 
Layer 'conv5' biases: 9.991210e-01 [2.696966e-06] 
Layer 'fc6' weights[0]: 7.155541e-03 [6.331465e-08] 
Layer 'fc6' biases: 9.999942e-01 [5.957958e-08] 
Layer 'fc7' weights[0]: 7.507759e-03 [1.456911e-07] 
Layer 'fc7' biases: 9.998414e-01 [1.950203e-07] 
Layer 'fc8' weights[0]: 4.617420e-03 [1.624862e-05] 
Layer 'fc8' biases: 1.295098e-02 [3.261871e-05] 
Train error last 800 batches: 0.655320
-------------------------------------------------------
Not saving because 0.424781 > 0.299667 (9.300: -1.18%)
======================================================= (2.395 sec)
15.201... logprob:  0.702956, 0.309896 (1.410 sec)
15.202... logprob:  0.687234, 0.309896 (1.405 sec)
15.203... logprob:  0.614420, 0.266927 (1.438 sec)
15.204... logprob:  0.692936, 0.287760 (1.390 sec)
15.205... logprob:  0.607957, 0.282552 (1.396 sec)
15.206... logprob:  0.610444, 0.251302 (1.394 sec)
15.207... logprob:  0.651709, 0.302083 (1.386 sec)
15.208... logprob:  0.711510, 0.313802 (1.392 sec)
15.209... logprob:  0.518894, 0.234375 (1.413 sec)
15.210... logprob:  0.837605, 0.319010 (1.407 sec)
15.211... logprob:  0.711278, 0.313802 (1.409 sec)
15.212... logprob:  0.603849, 0.286458 (1.414 sec)
15.213... logprob:  0.752013, 0.290364 (1.458 sec)
15.214... logprob:  0.771516, 0.312500 (1.421 sec)
15.215... logprob:  0.684849, 0.295573 (1.408 sec)
15.216... logprob:  0.734451, 0.292969 (1.461 sec)
15.217... logprob:  0.612020, 0.277344 (1.397 sec)
15.218... logprob:  0.704634, 0.295573 (1.414 sec)
15.219... logprob:  0.695200, 0.268229 (1.412 sec)
15.220... logprob:  0.614511, 0.274739 (1.415 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.400084, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.511374e-03 [2.262897e-07] 
Layer 'conv1' biases: 1.803403e-06 [5.255716e-10] 
Layer 'conv2' weights[0]: 4.502939e-03 [2.257113e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.898466e-09] 
Layer 'conv3' weights[0]: 4.501546e-03 [2.274011e-07] 
Layer 'conv3' biases: 2.975503e-05 [2.117365e-08] 
Layer 'conv4' weights[0]: 4.520294e-03 [2.308553e-07] 
Layer 'conv4' biases: 1.000002e+00 [4.055166e-07] 
Layer 'conv5' weights[0]: 4.611048e-03 [3.561933e-06] 
Layer 'conv5' biases: 9.991577e-01 [3.799242e-06] 
Layer 'fc6' weights[0]: 7.154821e-03 [7.688554e-08] 
Layer 'fc6' biases: 9.999941e-01 [7.767515e-08] 
Layer 'fc7' weights[0]: 7.507039e-03 [1.825615e-07] 
Layer 'fc7' biases: 9.998384e-01 [2.952346e-07] 
Layer 'fc8' weights[0]: 4.524553e-03 [2.125110e-05] 
Layer 'fc8' biases: 1.223482e-02 [5.300442e-05] 
Train error last 800 batches: 0.655120
-------------------------------------------------------
Not saving because 0.400084 > 0.299667 (9.300: -1.18%)
======================================================= (2.354 sec)
15.221... logprob:  0.637662, 0.276042 (1.411 sec)
15.222... logprob:  0.811484, 0.363281 (1.460 sec)
15.223... logprob:  0.733166, 0.325521 (1.420 sec)
15.224... logprob:  0.651470, 0.291667 (1.427 sec)
15.225... logprob:  0.682000, 0.308594 (1.442 sec)
15.226... logprob:  0.655067, 0.259115 (1.419 sec)
15.227... logprob:  0.742561, 0.321615 (1.416 sec)
15.228... logprob:  0.626893, 0.298177 (1.410 sec)
15.229... logprob:  0.627859, 0.299479 (1.415 sec)
15.230... logprob:  0.646611, 0.270833 (1.424 sec)
15.231... logprob:  0.685000, 0.315104 (1.407 sec)
15.232... logprob:  0.708221, 0.326823 (1.452 sec)
15.233... logprob:  0.665070, 0.279948 (1.419 sec)
15.234... logprob:  0.741996, 0.320312 (1.413 sec)
15.235... logprob:  0.652190, 0.291667 (1.465 sec)
15.236... logprob:  0.589683, 0.250000 (1.394 sec)
15.237... logprob:  0.630781, 0.268229 (1.417 sec)
15.238... logprob:  0.521984, 0.227865 (1.410 sec)
15.239... logprob:  0.703653, 0.303385 (1.413 sec)
15.240... logprob:  0.761666, 0.338542 (1.396 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.558101, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.506867e-03 [2.267263e-07] 
Layer 'conv1' biases: 1.803800e-06 [3.894929e-10] 
Layer 'conv2' weights[0]: 4.498440e-03 [2.259304e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.442983e-09] 
Layer 'conv3' weights[0]: 4.497058e-03 [2.266604e-07] 
Layer 'conv3' biases: 2.976980e-05 [1.745827e-08] 
Layer 'conv4' weights[0]: 4.515786e-03 [2.296399e-07] 
Layer 'conv4' biases: 1.000000e+00 [3.228385e-07] 
Layer 'conv5' weights[0]: 4.606125e-03 [3.142861e-06] 
Layer 'conv5' biases: 9.991538e-01 [3.360507e-06] 
Layer 'fc6' weights[0]: 7.154084e-03 [7.339663e-08] 
Layer 'fc6' biases: 9.999942e-01 [7.214730e-08] 
Layer 'fc7' weights[0]: 7.506293e-03 [1.763954e-07] 
Layer 'fc7' biases: 9.998388e-01 [2.872075e-07] 
Layer 'fc8' weights[0]: 4.543264e-03 [2.205120e-05] 
Layer 'fc8' biases: 1.241728e-02 [5.216067e-05] 
Train error last 800 batches: 0.655116
-------------------------------------------------------
Not saving because 0.558101 > 0.299667 (9.300: -1.18%)
======================================================= (2.367 sec)
15.241... logprob:  0.748437, 0.329427 (1.461 sec)
15.242... logprob:  0.524136, 0.239583 (1.425 sec)
15.243... logprob:  0.549347, 0.250000 (1.432 sec)
15.244... logprob:  0.549678, 0.259115 (1.443 sec)
15.245... logprob:  0.803118, 0.333333 (1.416 sec)
15.246... logprob:  0.720874, 0.308594 (1.405 sec)
15.247... logprob:  0.565748, 0.257812 (1.409 sec)
15.248... logprob:  0.524846, 0.252604 (1.412 sec)
15.249... logprob:  0.747253, 0.292969 (1.422 sec)
15.250... logprob:  0.839560, 0.324219 (1.402 sec)
15.251... logprob:  0.615837, 0.300781 (1.457 sec)
15.252... logprob:  0.720140, 0.330729 (1.420 sec)
15.253... logprob:  0.632750, 0.282552 (1.411 sec)
15.254... logprob:  0.640606, 0.272135 (1.460 sec)
15.255... logprob:  0.629533, 0.265625 (1.393 sec)
15.256... logprob:  0.573771, 0.282552 (1.418 sec)
15.257... logprob:  0.565827, 0.259115 (1.407 sec)
15.258... logprob:  0.722811, 0.328125 (1.414 sec)
15.259... logprob:  0.683011, 0.321615 (1.396 sec)
15.260... logprob:  0.550190, 0.250000 (1.449 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.445893, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.502342e-03 [2.257529e-07] 
Layer 'conv1' biases: 1.804926e-06 [2.536515e-10] 
Layer 'conv2' weights[0]: 4.493941e-03 [2.251922e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.230109e-09] 
Layer 'conv3' weights[0]: 4.492516e-03 [2.256741e-07] 
Layer 'conv3' biases: 2.974986e-05 [1.310297e-08] 
Layer 'conv4' weights[0]: 4.511257e-03 [2.270326e-07] 
Layer 'conv4' biases: 9.999998e-01 [1.780042e-07] 
Layer 'conv5' weights[0]: 4.601405e-03 [1.967860e-06] 
Layer 'conv5' biases: 9.991404e-01 [2.045685e-06] 
Layer 'fc6' weights[0]: 7.153337e-03 [5.734357e-08] 
Layer 'fc6' biases: 9.999941e-01 [5.091212e-08] 
Layer 'fc7' weights[0]: 7.505545e-03 [1.287178e-07] 
Layer 'fc7' biases: 9.998395e-01 [1.522003e-07] 
Layer 'fc8' weights[0]: 4.591469e-03 [1.314541e-05] 
Layer 'fc8' biases: 1.287874e-02 [1.514838e-05] 
Train error last 800 batches: 0.655588
-------------------------------------------------------
Not saving because 0.445893 > 0.299667 (9.300: -1.18%)
======================================================= (2.411 sec)
15.261... logprob:  0.573287, 0.256510 (1.437 sec)
15.262... logprob:  0.679963, 0.272135 (1.431 sec)
15.263... logprob:  0.719495, 0.316406 (1.441 sec)
15.264... logprob:  0.646499, 0.304688 (1.415 sec)
15.265... logprob:  0.732236, 0.299479 (1.408 sec)
15.266... logprob:  0.663449, 0.308594 (1.412 sec)
15.267... logprob:  0.613970, 0.263021 (1.415 sec)
15.268... logprob:  0.685687, 0.269531 (1.417 sec)
15.269... logprob:  0.726323, 0.333333 (1.422 sec)
15.270... logprob:  0.749351, 0.322917 (1.456 sec)
15.271... logprob:  0.651144, 0.289062 (1.418 sec)
15.272... logprob:  0.723658, 0.303385 (1.410 sec)
15.273... logprob:  0.698314, 0.300781 (1.458 sec)
15.274... logprob:  0.746834, 0.358073 (1.396 sec)
15.275... logprob:  0.669273, 0.289062 (1.418 sec)
15.276... logprob:  0.637325, 0.305990 (1.409 sec)
15.277... logprob:  0.658449, 0.285156 (1.450 sec)
15.278... logprob:  0.495780, 0.214844 (1.421 sec)
15.279... logprob:  0.541148, 0.231771 (1.459 sec)
15.280... logprob:  0.507152, 0.244792 (1.403 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.400257, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.497863e-03 [2.257387e-07] 
Layer 'conv1' biases: 1.806097e-06 [3.482004e-10] 
Layer 'conv2' weights[0]: 4.489431e-03 [2.250686e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.023441e-09] 
Layer 'conv3' weights[0]: 4.488046e-03 [2.258993e-07] 
Layer 'conv3' biases: 2.976756e-05 [1.662141e-08] 
Layer 'conv4' weights[0]: 4.506757e-03 [2.282951e-07] 
Layer 'conv4' biases: 9.999988e-01 [2.903009e-07] 
Layer 'conv5' weights[0]: 4.596881e-03 [3.075941e-06] 
Layer 'conv5' biases: 9.991567e-01 [3.372771e-06] 
Layer 'fc6' weights[0]: 7.152619e-03 [6.842161e-08] 
Layer 'fc6' biases: 9.999941e-01 [6.576813e-08] 
Layer 'fc7' weights[0]: 7.504813e-03 [1.628531e-07] 
Layer 'fc7' biases: 9.998375e-01 [2.708750e-07] 
Layer 'fc8' weights[0]: 4.533348e-03 [1.973384e-05] 
Layer 'fc8' biases: 1.244257e-02 [4.466705e-05] 
Train error last 800 batches: 0.655820
-------------------------------------------------------
Not saving because 0.400257 > 0.299667 (9.300: -1.18%)
======================================================= (2.350 sec)
15.281... logprob:  0.581065, 0.263021 (1.427 sec)
15.282... logprob:  0.632211, 0.253906 (1.417 sec)
15.283... logprob:  0.644319, 0.295573 (1.407 sec)
15.284... logprob:  0.697680, 0.294271 (1.404 sec)
15.285... logprob:  0.685526, 0.273437 (1.436 sec)
15.286... logprob:  0.788587, 0.326823 (1.435 sec)
15.287... logprob:  0.573455, 0.272135 (1.515 sec)
15.288... logprob:  0.538556, 0.221354 (1.431 sec)
15.289... logprob:  0.701132, 0.283854 (1.440 sec)
15.290... logprob:  0.688596, 0.320313 (1.404 sec)
15.291... logprob:  0.676880, 0.307292 (1.420 sec)
15.292... logprob:  0.744619, 0.337240 (1.413 sec)
15.293... logprob:  0.739140, 0.307292 (1.415 sec)
15.294... logprob:  0.587214, 0.273437 (1.399 sec)
15.295... logprob:  0.571153, 0.246094 (1.460 sec)
15.296... logprob:  0.516293, 0.255208 (1.421 sec)
15.297... logprob:  0.617681, 0.276042 (1.420 sec)
15.298... logprob:  0.607652, 0.247396 (1.457 sec)
15.299... logprob:  0.562347, 0.248698 (1.395 sec)
15.300... logprob:  0.595233, 0.266927 (1.417 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.431294, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.493362e-03 [2.255657e-07] 
Layer 'conv1' biases: 1.808042e-06 [3.055829e-10] 
Layer 'conv2' weights[0]: 4.484940e-03 [2.247110e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.336213e-09] 
Layer 'conv3' weights[0]: 4.483567e-03 [2.252027e-07] 
Layer 'conv3' biases: 2.979253e-05 [1.395840e-08] 
Layer 'conv4' weights[0]: 4.502251e-03 [2.274017e-07] 
Layer 'conv4' biases: 1.000000e+00 [2.746607e-07] 
Layer 'conv5' weights[0]: 4.593756e-03 [2.712763e-06] 
Layer 'conv5' biases: 9.991291e-01 [2.958074e-06] 
Layer 'fc6' weights[0]: 7.151872e-03 [6.523641e-08] 
Layer 'fc6' biases: 9.999941e-01 [6.189072e-08] 
Layer 'fc7' weights[0]: 7.504091e-03 [1.525453e-07] 
Layer 'fc7' biases: 9.998393e-01 [2.283734e-07] 
Layer 'fc8' weights[0]: 4.589296e-03 [1.791470e-05] 
Layer 'fc8' biases: 1.281454e-02 [3.569566e-05] 
Train error last 800 batches: 0.655712
-------------------------------------------------------
Not saving because 0.431294 > 0.299667 (9.300: -1.18%)
======================================================= (2.365 sec)
15.301... logprob:  0.665173, 0.309896 (1.419 sec)
15.302... logprob:  0.800515, 0.342448 (1.413 sec)
15.303... logprob:  0.641831, 0.266927 (1.403 sec)
15.304... logprob:  0.566683, 0.231771 (1.437 sec)
15.305... logprob:  0.646895, 0.285156 (1.436 sec)
15.306... logprob:  0.639622, 0.291667 (1.434 sec)
15.307... logprob:  0.639676, 0.273437 (1.441 sec)
15.308... logprob:  0.584732, 0.266927 (1.458 sec)
15.309... logprob:  0.653413, 0.311198 (1.427 sec)
15.310... logprob:  0.701523, 0.303385 (1.417 sec)
15.311... logprob:  0.711458, 0.295573 (1.421 sec)
15.312... logprob:  0.670742, 0.303385 (1.429 sec)
15.313... logprob:  0.633590, 0.261719 (1.413 sec)
15.314... logprob:  0.694505, 0.332031 (1.456 sec)
15.315... logprob:  0.583806, 0.302083 (1.431 sec)
15.316... logprob:  0.780027, 0.332031 (1.418 sec)
15.317... logprob:  0.617278, 0.295573 (1.470 sec)
15.318... logprob:  0.620673, 0.268229 (1.412 sec)
15.319... logprob:  0.715143, 0.317708 (1.419 sec)
15.320... logprob:  0.672797, 0.277344 (1.424 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.477225, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.488869e-03 [2.253440e-07] 
Layer 'conv1' biases: 1.810746e-06 [3.486604e-10] 
Layer 'conv2' weights[0]: 4.480478e-03 [2.245879e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.490834e-09] 
Layer 'conv3' weights[0]: 4.479024e-03 [2.249201e-07] 
Layer 'conv3' biases: 2.984582e-05 [1.270149e-08] 
Layer 'conv4' weights[0]: 4.497741e-03 [2.266657e-07] 
Layer 'conv4' biases: 1.000001e+00 [2.027112e-07] 
Layer 'conv5' weights[0]: 4.589662e-03 [2.080800e-06] 
Layer 'conv5' biases: 9.991304e-01 [2.286226e-06] 
Layer 'fc6' weights[0]: 7.151117e-03 [6.132677e-08] 
Layer 'fc6' biases: 9.999940e-01 [5.676053e-08] 
Layer 'fc7' weights[0]: 7.503327e-03 [1.383602e-07] 
Layer 'fc7' biases: 9.998389e-01 [1.723980e-07] 
Layer 'fc8' weights[0]: 4.578499e-03 [1.457633e-05] 
Layer 'fc8' biases: 1.270639e-02 [1.834514e-05] 
Train error last 800 batches: 0.655354
-------------------------------------------------------
Not saving because 0.477225 > 0.299667 (9.300: -1.18%)
======================================================= (2.367 sec)
15.321... logprob:  0.501833, 0.221354 (1.434 sec)
15.322... logprob:  0.553749, 0.252604 (1.410 sec)
15.323... logprob:  0.693066, 0.294271 (1.474 sec)
15.324... logprob:  0.656664, 0.276042 (1.420 sec)
15.325... logprob:  0.574665, 0.253906 (1.434 sec)
15.326... logprob:  0.725358, 0.311198 (1.458 sec)
15.327... logprob:  0.700470, 0.298177 (1.415 sec)
15.328... logprob:  0.818612, 0.298177 (1.418 sec)
15.329... logprob:  0.692823, 0.303385 (1.422 sec)
15.330... logprob:  0.622088, 0.294271 (1.417 sec)
15.331... logprob:  0.640896, 0.274740 (1.422 sec)
15.332... logprob:  0.597659, 0.300781 (1.449 sec)
15.333... logprob:  0.499151, 0.213542 (1.441 sec)
15.334... logprob:  0.741618, 0.316406 (1.431 sec)
15.335... logprob:  0.654426, 0.299479 (1.438 sec)
15.336... logprob:  0.697094, 0.305990 (1.449 sec)
15.337... logprob:  0.729362, 0.338542 (1.413 sec)
15.338... logprob:  0.580113, 0.239583 (1.415 sec)
15.339... logprob:  0.690889, 0.308594 (1.420 sec)
15.340... logprob:  0.653466, 0.312500 (1.422 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.503962, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.484386e-03 [2.249627e-07] 
Layer 'conv1' biases: 1.811790e-06 [2.389658e-10] 
Layer 'conv2' weights[0]: 4.475988e-03 [2.242750e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.312618e-09] 
Layer 'conv3' weights[0]: 4.474618e-03 [2.247615e-07] 
Layer 'conv3' biases: 2.987661e-05 [1.298005e-08] 
Layer 'conv4' weights[0]: 4.493238e-03 [2.264272e-07] 
Layer 'conv4' biases: 1.000002e+00 [2.078655e-07] 
Layer 'conv5' weights[0]: 4.586002e-03 [2.201935e-06] 
Layer 'conv5' biases: 9.991334e-01 [2.419145e-06] 
Layer 'fc6' weights[0]: 7.150368e-03 [5.796882e-08] 
Layer 'fc6' biases: 9.999939e-01 [5.165087e-08] 
Layer 'fc7' weights[0]: 7.502612e-03 [1.296300e-07] 
Layer 'fc7' biases: 9.998379e-01 [1.452208e-07] 
Layer 'fc8' weights[0]: 4.552936e-03 [1.284827e-05] 
Layer 'fc8' biases: 1.252143e-02 [9.571688e-06] 
Train error last 800 batches: 0.654918
-------------------------------------------------------
Not saving because 0.503962 > 0.299667 (9.300: -1.18%)
======================================================= (2.374 sec)
15.341... logprob:  0.702529, 0.302083 (1.419 sec)
15.342... logprob:  0.608137, 0.290365 (1.458 sec)
15.343... logprob:  0.688101, 0.298177 (1.442 sec)
15.344... logprob:  0.670850, 0.291667 (1.472 sec)
15.345... logprob:  0.691426, 0.295573 (1.434 sec)
15.346... logprob:  0.703829, 0.296875 (1.449 sec)
15.347... logprob:  0.604791, 0.230469 (1.485 sec)
15.348... logprob:  0.646539, 0.259115 (1.432 sec)
15.349... logprob:  0.699468, 0.289062 (1.425 sec)
15.350... logprob:  0.608428, 0.255208 (1.433 sec)
15.351... logprob:  0.674835, 0.276042 (1.429 sec)
15.352... logprob:  0.611832, 0.281250 (1.427 sec)
15.353... logprob:  0.736872, 0.302083 (1.480 sec)
15.354... logprob:  0.802569, 0.335937 (1.424 sec)
15.355... logprob:  0.563100, 0.243490 (1.439 sec)
15.356... logprob:  0.633474, 0.283854 (1.470 sec)
15.357... logprob:  0.573897, 0.257812 (1.427 sec)
15.358... logprob:  0.627837, 0.291667 (1.431 sec)
15.359... logprob:  0.777746, 0.326823 (1.426 sec)
15.360... logprob:  0.617450, 0.246094 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.524800, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.479904e-03 [2.250155e-07] 
Layer 'conv1' biases: 1.813232e-06 [3.422430e-10] 
Layer 'conv2' weights[0]: 4.471503e-03 [2.242939e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.870380e-09] 
Layer 'conv3' weights[0]: 4.470143e-03 [2.250325e-07] 
Layer 'conv3' biases: 2.989094e-05 [1.664002e-08] 
Layer 'conv4' weights[0]: 4.488752e-03 [2.272559e-07] 
Layer 'conv4' biases: 1.000000e+00 [2.836890e-07] 
Layer 'conv5' weights[0]: 4.580996e-03 [2.519631e-06] 
Layer 'conv5' biases: 9.991406e-01 [2.781207e-06] 
Layer 'fc6' weights[0]: 7.149655e-03 [6.083286e-08] 
Layer 'fc6' biases: 9.999940e-01 [5.591841e-08] 
Layer 'fc7' weights[0]: 7.501863e-03 [1.380842e-07] 
Layer 'fc7' biases: 9.998369e-01 [1.592412e-07] 
Layer 'fc8' weights[0]: 4.535305e-03 [1.380652e-05] 
Layer 'fc8' biases: 1.241179e-02 [7.481586e-06] 
Train error last 800 batches: 0.654348
-------------------------------------------------------
Not saving because 0.524800 > 0.299667 (9.300: -1.18%)
======================================================= (2.372 sec)
15.361... logprob:  0.663556, 0.300781 (1.431 sec)
15.362... logprob:  0.580399, 0.250000 (1.469 sec)
15.363... logprob:  0.664366, 0.286458 (1.436 sec)
15.364... logprob:  0.698737, 0.304687 (1.445 sec)
15.365... logprob:  0.608648, 0.269531 (1.459 sec)
15.366... logprob:  0.735371, 0.319010 (1.437 sec)
15.367... logprob:  0.623147, 0.291667 (1.432 sec)
15.368... logprob:  0.821832, 0.375000 (1.426 sec)
15.369... logprob:  0.622883, 0.308594 (1.416 sec)
15.370... logprob:  0.644196, 0.311198 (1.434 sec)
15.371... logprob:  0.628077, 0.287760 (1.451 sec)
15.372... logprob:  0.679673, 0.292969 (1.448 sec)
15.373... logprob:  0.672362, 0.289062 (1.449 sec)
15.374... logprob:  0.675829, 0.315104 (1.442 sec)
15.375... logprob:  0.619684, 0.292969 (1.456 sec)
15.376... logprob:  0.608382, 0.282552 (1.432 sec)
15.377... logprob:  0.505894, 0.225260 (1.417 sec)
15.378... logprob:  0.614924, 0.268229 (1.425 sec)
15.379... logprob:  0.606014, 0.260416 (1.429 sec)
15.380... logprob:  0.768090, 0.319010 (1.437 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.511777, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.475413e-03 [2.248743e-07] 
Layer 'conv1' biases: 1.814646e-06 [3.529262e-10] 
Layer 'conv2' weights[0]: 4.467047e-03 [2.239491e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.867485e-09] 
Layer 'conv3' weights[0]: 4.465609e-03 [2.246227e-07] 
Layer 'conv3' biases: 2.988632e-05 [1.499692e-08] 
Layer 'conv4' weights[0]: 4.484280e-03 [2.267764e-07] 
Layer 'conv4' biases: 9.999985e-01 [2.816753e-07] 
Layer 'conv5' weights[0]: 4.576075e-03 [2.771589e-06] 
Layer 'conv5' biases: 9.991189e-01 [2.986449e-06] 
Layer 'fc6' weights[0]: 7.148901e-03 [6.244456e-08] 
Layer 'fc6' biases: 9.999940e-01 [5.851659e-08] 
Layer 'fc7' weights[0]: 7.501072e-03 [1.427879e-07] 
Layer 'fc7' biases: 9.998381e-01 [1.838814e-07] 
Layer 'fc8' weights[0]: 4.600419e-03 [1.507778e-05] 
Layer 'fc8' biases: 1.288249e-02 [2.477132e-05] 
Train error last 800 batches: 0.654020
-------------------------------------------------------
Not saving because 0.511777 > 0.299667 (9.300: -1.18%)
======================================================= (2.394 sec)
15.381... logprob:  0.699770, 0.300781 (1.470 sec)
15.382... logprob:  0.689430, 0.270833 (1.449 sec)
15.383... logprob:  0.631007, 0.285156 (1.435 sec)
15.384... logprob:  0.620849, 0.305990 (1.499 sec)
15.385... logprob:  0.757222, 0.321615 (1.428 sec)
15.386... logprob:  0.778322, 0.290365 (1.419 sec)
15.387... logprob:  0.626692, 0.289062 (1.429 sec)
15.388... logprob:  0.789857, 0.339844 (1.438 sec)
15.389... logprob:  0.601311, 0.281250 (1.428 sec)
15.390... logprob:  0.681759, 0.324219 (1.477 sec)
15.391... logprob:  0.602513, 0.285156 (1.437 sec)
15.392... logprob:  0.708923, 0.302083 (1.430 sec)
15.393... logprob:  0.570162, 0.246094 (1.485 sec)
15.394... logprob:  0.564176, 0.253906 (1.424 sec)
15.395... logprob:  0.544647, 0.251302 (1.426 sec)
15.396... logprob:  0.512413, 0.220052 (1.428 sec)
15.397... logprob:  0.591706, 0.259115 (1.427 sec)
15.398... logprob:  0.629029, 0.269531 (1.427 sec)
15.399... logprob:  0.646980, 0.285156 (1.478 sec)
15.400... logprob:  0.729376, 0.339844 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.444644, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.470951e-03 [2.244399e-07] 
Layer 'conv1' biases: 1.816709e-06 [3.329037e-10] 
Layer 'conv2' weights[0]: 4.462598e-03 [2.236555e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.148788e-09] 
Layer 'conv3' weights[0]: 4.461170e-03 [2.243054e-07] 
Layer 'conv3' biases: 2.992468e-05 [1.608205e-08] 
Layer 'conv4' weights[0]: 4.479757e-03 [2.262764e-07] 
Layer 'conv4' biases: 9.999970e-01 [2.950170e-07] 
Layer 'conv5' weights[0]: 4.571235e-03 [2.731258e-06] 
Layer 'conv5' biases: 9.991167e-01 [2.987452e-06] 
Layer 'fc6' weights[0]: 7.148154e-03 [6.427167e-08] 
Layer 'fc6' biases: 9.999940e-01 [6.121186e-08] 
Layer 'fc7' weights[0]: 7.500299e-03 [1.489599e-07] 
Layer 'fc7' biases: 9.998382e-01 [2.148956e-07] 
Layer 'fc8' weights[0]: 4.611796e-03 [1.687029e-05] 
Layer 'fc8' biases: 1.282876e-02 [3.117901e-05] 
Train error last 800 batches: 0.654004
-------------------------------------------------------
Not saving because 0.444644 > 0.299667 (9.300: -1.18%)
======================================================= (2.370 sec)
15.401... logprob:  0.605467, 0.266927 (1.440 sec)
15.402... logprob:  0.715277, 0.332031 (1.482 sec)
15.403... logprob:  0.703604, 0.311198 (1.423 sec)
15.404... logprob:  0.755189, 0.317708 (1.431 sec)
15.405... logprob:  0.704981, 0.266927 (1.426 sec)
15.406... logprob:  0.668084, 0.281250 (1.424 sec)
15.407... logprob:  0.681594, 0.283854 (1.434 sec)
15.408... logprob:  0.605657, 0.283854 (1.475 sec)
15.409... logprob:  0.715676, 0.308594 (1.429 sec)
15.410... logprob:  0.764365, 0.320312 (1.442 sec)
15.411... logprob:  0.730512, 0.330729 (1.469 sec)
15.412... logprob:  0.752482, 0.272135 (1.430 sec)
15.413... logprob:  0.718064, 0.329427 (1.433 sec)
15.414... logprob:  0.698462, 0.328125 (1.424 sec)
15.415... logprob:  0.569800, 0.259115 (1.420 sec)
15.416... logprob:  0.745789, 0.337240 (1.430 sec)
15.417... logprob:  0.664515, 0.303385 (1.455 sec)
15.418... logprob:  0.623440, 0.256510 (1.449 sec)
15.419... logprob:  0.756442, 0.316406 (1.443 sec)
15.420... logprob:  0.618950, 0.282552 (1.450 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.442230, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.466484e-03 [2.241930e-07] 
Layer 'conv1' biases: 1.817686e-06 [2.852598e-10] 
Layer 'conv2' weights[0]: 4.458133e-03 [2.234327e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.754296e-09] 
Layer 'conv3' weights[0]: 4.456736e-03 [2.241732e-07] 
Layer 'conv3' biases: 2.994175e-05 [1.656245e-08] 
Layer 'conv4' weights[0]: 4.475333e-03 [2.263213e-07] 
Layer 'conv4' biases: 9.999967e-01 [2.837312e-07] 
Layer 'conv5' weights[0]: 4.566809e-03 [2.689361e-06] 
Layer 'conv5' biases: 9.991375e-01 [2.884011e-06] 
Layer 'fc6' weights[0]: 7.147431e-03 [6.788185e-08] 
Layer 'fc6' biases: 9.999940e-01 [6.607292e-08] 
Layer 'fc7' weights[0]: 7.499577e-03 [1.624924e-07] 
Layer 'fc7' biases: 9.998364e-01 [2.447854e-07] 
Layer 'fc8' weights[0]: 4.545693e-03 [2.150440e-05] 
Layer 'fc8' biases: 1.241595e-02 [4.562757e-05] 
Train error last 800 batches: 0.654484
-------------------------------------------------------
Not saving because 0.442230 > 0.299667 (9.300: -1.18%)
======================================================= (2.380 sec)
15.421... logprob:  0.570032, 0.226562 (1.454 sec)
15.422... logprob:  0.728835, 0.341146 (1.451 sec)
15.423... logprob:  0.687500, 0.289062 (1.426 sec)
15.424... logprob:  0.580528, 0.278646 (1.426 sec)
15.425... logprob:  0.590490, 0.263021 (1.434 sec)
15.426... logprob:  0.591378, 0.250000 (1.441 sec)
15.427... logprob:  0.766712, 0.343750 (1.457 sec)
15.428... logprob:  0.832421, 0.351562 (1.446 sec)
15.429... logprob:  0.630136, 0.268229 (1.435 sec)
15.430... logprob:  0.581737, 0.283854 (1.473 sec)
15.431... logprob:  0.748493, 0.317708 (1.423 sec)
15.432... logprob:  0.630134, 0.268229 (1.421 sec)
15.433... logprob:  0.554119, 0.251302 (1.430 sec)
15.434... logprob:  0.674788, 0.296875 (1.437 sec)
15.435... logprob:  0.697579, 0.326823 (1.427 sec)
15.436... logprob:  0.601200, 0.279948 (1.468 sec)
15.437... logprob:  0.752014, 0.307292 (1.441 sec)
15.438... logprob:  0.775111, 0.312500 (1.423 sec)
15.439... logprob:  0.600309, 0.283854 (1.481 sec)
15.440... logprob:  0.568484, 0.281250 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.558059, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.462018e-03 [2.236299e-07] 
Layer 'conv1' biases: 1.819941e-06 [3.675943e-10] 
Layer 'conv2' weights[0]: 4.453673e-03 [2.231115e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.862008e-09] 
Layer 'conv3' weights[0]: 4.452256e-03 [2.238808e-07] 
Layer 'conv3' biases: 2.994736e-05 [1.560512e-08] 
Layer 'conv4' weights[0]: 4.470828e-03 [2.257063e-07] 
Layer 'conv4' biases: 9.999982e-01 [2.651578e-07] 
Layer 'conv5' weights[0]: 4.563519e-03 [2.357526e-06] 
Layer 'conv5' biases: 9.991317e-01 [2.566386e-06] 
Layer 'fc6' weights[0]: 7.146714e-03 [6.012227e-08] 
Layer 'fc6' biases: 9.999939e-01 [5.511658e-08] 
Layer 'fc7' weights[0]: 7.498784e-03 [1.337921e-07] 
Layer 'fc7' biases: 9.998370e-01 [1.572681e-07] 
Layer 'fc8' weights[0]: 4.564385e-03 [1.406009e-05] 
Layer 'fc8' biases: 1.254599e-02 [1.341276e-05] 
Train error last 800 batches: 0.654473
-------------------------------------------------------
Not saving because 0.558059 > 0.299667 (9.300: -1.18%)
======================================================= (2.389 sec)
15.441... logprob:  0.684646, 0.274740 (1.431 sec)
15.442... logprob:  0.669265, 0.299479 (1.430 sec)
15.443... logprob:  0.691011, 0.316406 (1.428 sec)
15.444... logprob:  0.596692, 0.251302 (1.425 sec)
15.445... logprob:  0.551153, 0.244792 (1.479 sec)
15.446... logprob:  0.603100, 0.251302 (1.429 sec)
15.447... logprob:  0.746606, 0.329427 (1.433 sec)
15.448... logprob:  0.589129, 0.266927 (1.474 sec)
15.449... logprob:  0.719601, 0.315104 (1.427 sec)
15.450... logprob:  0.502786, 0.214844 (1.426 sec)
15.451... logprob:  0.705598, 0.287760 (1.430 sec)
15.452... logprob:  0.725934, 0.315104 (1.421 sec)
15.453... logprob:  0.636695, 0.278646 (1.425 sec)
15.454... logprob:  0.679531, 0.319010 (1.482 sec)
15.455... logprob:  0.594965, 0.272135 (1.434 sec)
15.456... logprob:  0.649097, 0.289062 (1.444 sec)
15.457... logprob:  0.488464, 0.231771 (1.474 sec)
15.458... logprob:  0.585668, 0.225260 (1.426 sec)
15.459... logprob:  0.789751, 0.343750 (1.432 sec)
15.460... logprob:  0.502022, 0.248698 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.381776, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.457567e-03 [2.239318e-07] 
Layer 'conv1' biases: 1.822936e-06 [3.159399e-10] 
Layer 'conv2' weights[0]: 4.449233e-03 [2.231833e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.772656e-09] 
Layer 'conv3' weights[0]: 4.447815e-03 [2.236366e-07] 
Layer 'conv3' biases: 2.997917e-05 [1.634655e-08] 
Layer 'conv4' weights[0]: 4.466381e-03 [2.256489e-07] 
Layer 'conv4' biases: 9.999971e-01 [2.955974e-07] 
Layer 'conv5' weights[0]: 4.558708e-03 [2.715090e-06] 
Layer 'conv5' biases: 9.991150e-01 [2.991423e-06] 
Layer 'fc6' weights[0]: 7.145937e-03 [6.567898e-08] 
Layer 'fc6' biases: 9.999938e-01 [6.286658e-08] 
Layer 'fc7' weights[0]: 7.498031e-03 [1.541926e-07] 
Layer 'fc7' biases: 9.998379e-01 [2.370566e-07] 
Layer 'fc8' weights[0]: 4.606294e-03 [1.789501e-05] 
Layer 'fc8' biases: 1.287079e-02 [3.874776e-05] 
Train error last 800 batches: 0.654250
-------------------------------------------------------
Not saving because 0.381776 > 0.299667 (9.300: -1.18%)
======================================================= (2.372 sec)
15.461... logprob:  0.624439, 0.281250 (1.425 sec)
15.462... logprob:  0.707237, 0.298177 (1.433 sec)
15.463... logprob:  0.733497, 0.313802 (1.465 sec)
15.464... logprob:  0.730881, 0.299479 (1.437 sec)
15.465... logprob:  0.561816, 0.239583 (1.454 sec)
15.466... logprob:  0.655477, 0.286458 (1.458 sec)
15.467... logprob:  0.616373, 0.263021 (1.444 sec)
15.468... logprob:  0.658857, 0.299479 (1.433 sec)
15.469... logprob:  0.611352, 0.290364 (1.417 sec)
15.470... logprob:  0.584484, 0.247396 (1.425 sec)
15.471... logprob:  0.790857, 0.338542 (1.429 sec)
15.472... logprob:  0.638097, 0.266927 (1.444 sec)
15.473... logprob:  0.583172, 0.244792 (1.454 sec)
15.474... logprob:  0.664704, 0.303385 (1.447 sec)
15.475... logprob:  0.674006, 0.295573 (1.444 sec)
15.476... logprob:  0.670034, 0.282552 (1.460 sec)
15.477... logprob:  0.665888, 0.283854 (1.427 sec)
15.478... logprob:  0.629937, 0.278646 (1.422 sec)
15.479... logprob:  0.536047, 0.244792 (1.427 sec)
15.480... logprob:  0.569693, 0.257812 (1.437 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.530129, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.453120e-03 [2.232322e-07] 
Layer 'conv1' biases: 1.823515e-06 [2.930020e-10] 
Layer 'conv2' weights[0]: 4.444773e-03 [2.226227e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.499796e-09] 
Layer 'conv3' weights[0]: 4.443377e-03 [2.235002e-07] 
Layer 'conv3' biases: 2.998473e-05 [1.611936e-08] 
Layer 'conv4' weights[0]: 4.461907e-03 [2.255158e-07] 
Layer 'conv4' biases: 9.999966e-01 [2.983076e-07] 
Layer 'conv5' weights[0]: 4.554223e-03 [2.488280e-06] 
Layer 'conv5' biases: 9.991221e-01 [2.692887e-06] 
Layer 'fc6' weights[0]: 7.145249e-03 [5.851678e-08] 
Layer 'fc6' biases: 9.999939e-01 [5.282267e-08] 
Layer 'fc7' weights[0]: 7.497274e-03 [1.281357e-07] 
Layer 'fc7' biases: 9.998367e-01 [1.408948e-07] 
Layer 'fc8' weights[0]: 4.589392e-03 [1.266782e-05] 
Layer 'fc8' biases: 1.275926e-02 [7.491356e-06] 
Train error last 800 batches: 0.653889
-------------------------------------------------------
Not saving because 0.530129 > 0.299667 (9.300: -1.18%)
======================================================= (2.377 sec)
15.481... logprob:  0.682947, 0.316406 (1.438 sec)
15.482... logprob:  0.737112, 0.295573 (1.475 sec)
15.483... logprob:  0.669167, 0.303385 (1.442 sec)
15.484... logprob:  0.723931, 0.303385 (1.434 sec)
15.485... logprob:  0.595882, 0.255208 (1.481 sec)
15.486... logprob:  0.611897, 0.248698 (1.425 sec)
15.487... logprob:  0.708122, 0.315104 (1.425 sec)
15.488... logprob:  0.666378, 0.316406 (1.432 sec)
15.489... logprob:  0.646087, 0.290365 (1.432 sec)
15.490... logprob:  0.669330, 0.287760 (1.425 sec)
15.491... logprob:  0.544439, 0.234375 (1.475 sec)
15.492... logprob:  0.693084, 0.312500 (1.432 sec)
15.493... logprob:  0.646297, 0.311198 (1.437 sec)
15.494... logprob:  0.728622, 0.303385 (1.480 sec)
15.495... logprob:  0.518881, 0.230469 (1.435 sec)
15.496... logprob:  0.698664, 0.320312 (1.422 sec)
15.497... logprob:  0.640694, 0.256510 (1.428 sec)
15.498... logprob:  0.620358, 0.273437 (1.426 sec)
15.499... logprob:  0.606299, 0.260417 (1.424 sec)
15.500... logprob:  0.652407, 0.289062 (1.502 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.382244, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.448649e-03 [2.231236e-07] 
Layer 'conv1' biases: 1.824568e-06 [3.309391e-10] 
Layer 'conv2' weights[0]: 4.440317e-03 [2.225119e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.710361e-09] 
Layer 'conv3' weights[0]: 4.438928e-03 [2.229812e-07] 
Layer 'conv3' biases: 3.001375e-05 [1.409711e-08] 
Layer 'conv4' weights[0]: 4.457448e-03 [2.246536e-07] 
Layer 'conv4' biases: 9.999966e-01 [2.312929e-07] 
Layer 'conv5' weights[0]: 4.549718e-03 [2.444126e-06] 
Layer 'conv5' biases: 9.991227e-01 [2.672193e-06] 
Layer 'fc6' weights[0]: 7.144530e-03 [5.897030e-08] 
Layer 'fc6' biases: 9.999938e-01 [5.343983e-08] 
Layer 'fc7' weights[0]: 7.496501e-03 [1.312202e-07] 
Layer 'fc7' biases: 9.998363e-01 [1.480047e-07] 
Layer 'fc8' weights[0]: 4.580511e-03 [1.300365e-05] 
Layer 'fc8' biases: 1.265841e-02 [6.437780e-06] 
Train error last 800 batches: 0.654112
-------------------------------------------------------
Not saving because 0.382244 > 0.299667 (9.300: -1.18%)
======================================================= (2.368 sec)
15.501... logprob:  0.546577, 0.253906 (1.429 sec)
15.502... logprob:  0.712621, 0.320312 (1.439 sec)
15.503... logprob:  0.629681, 0.281250 (1.479 sec)
15.504... logprob:  0.743330, 0.329427 (1.425 sec)
15.505... logprob:  0.814668, 0.311198 (1.431 sec)
15.506... logprob:  0.638979, 0.317708 (1.430 sec)
15.507... logprob:  0.604503, 0.255208 (1.423 sec)
15.508... logprob:  0.595896, 0.269531 (1.431 sec)
15.509... logprob:  0.593984, 0.253906 (1.469 sec)
15.510... logprob:  0.561779, 0.253906 (1.435 sec)
15.511... logprob:  0.667475, 0.287760 (1.445 sec)
15.512... logprob:  0.643915, 0.278646 (1.459 sec)
15.513... logprob:  0.514909, 0.233073 (1.440 sec)
15.514... logprob:  0.644011, 0.265625 (1.432 sec)
15.515... logprob:  0.671976, 0.282552 (1.430 sec)
15.516... logprob:  0.597003, 0.277344 (1.418 sec)
15.517... logprob:  0.654708, 0.264323 (1.435 sec)
15.518... logprob:  0.588946, 0.252604 (1.458 sec)
15.519... logprob:  0.709287, 0.292969 (1.447 sec)
15.520... logprob:  0.615672, 0.272135 (1.448 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.399659, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.444222e-03 [2.228501e-07] 
Layer 'conv1' biases: 1.825245e-06 [4.178166e-10] 
Layer 'conv2' weights[0]: 4.435887e-03 [2.221347e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.638433e-09] 
Layer 'conv3' weights[0]: 4.434469e-03 [2.228361e-07] 
Layer 'conv3' biases: 3.001475e-05 [1.498817e-08] 
Layer 'conv4' weights[0]: 4.452979e-03 [2.247493e-07] 
Layer 'conv4' biases: 9.999958e-01 [2.572918e-07] 
Layer 'conv5' weights[0]: 4.545230e-03 [2.319039e-06] 
Layer 'conv5' biases: 9.991043e-01 [2.561710e-06] 
Layer 'fc6' weights[0]: 7.143827e-03 [6.019677e-08] 
Layer 'fc6' biases: 9.999938e-01 [5.572383e-08] 
Layer 'fc7' weights[0]: 7.495760e-03 [1.374296e-07] 
Layer 'fc7' biases: 9.998372e-01 [1.660077e-07] 
Layer 'fc8' weights[0]: 4.614555e-03 [1.506463e-05] 
Layer 'fc8' biases: 1.291991e-02 [2.472017e-05] 
Train error last 800 batches: 0.653833
-------------------------------------------------------
Not saving because 0.399659 > 0.299667 (9.300: -1.18%)
======================================================= (2.358 sec)
15.521... logprob:  0.561901, 0.246094 (1.447 sec)
15.522... logprob:  0.695069, 0.352865 (1.457 sec)
15.523... logprob:  0.578593, 0.256510 (1.434 sec)
15.524... logprob:  0.678890, 0.287760 (1.422 sec)
15.525... logprob:  0.625122, 0.287760 (1.425 sec)
15.526... logprob:  0.639554, 0.266927 (1.431 sec)
15.527... logprob:  0.727170, 0.343750 (1.429 sec)
15.528... logprob:  0.679307, 0.265625 (1.467 sec)
15.529... logprob:  0.601561, 0.278646 (1.443 sec)
15.530... logprob:  0.629811, 0.256510 (1.434 sec)
15.531... logprob:  0.619559, 0.248698 (1.470 sec)
15.532... logprob:  0.683568, 0.291667 (1.430 sec)
15.533... logprob:  0.727667, 0.303385 (1.423 sec)
15.534... logprob:  0.529389, 0.253906 (1.433 sec)
15.535... logprob:  0.940146, 0.384115 (1.431 sec)
15.536... logprob:  0.772662, 0.329427 (1.432 sec)
15.537... logprob:  0.660429, 0.283854 (1.482 sec)
15.538... logprob:  0.670018, 0.286458 (1.461 sec)
15.539... logprob:  0.627059, 0.298177 (1.427 sec)
15.540... logprob:  0.699255, 0.309896 (1.488 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.446705, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.439789e-03 [2.223650e-07] 
Layer 'conv1' biases: 1.825364e-06 [4.805744e-10] 
Layer 'conv2' weights[0]: 4.431473e-03 [2.221327e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.366258e-09] 
Layer 'conv3' weights[0]: 4.430053e-03 [2.235724e-07] 
Layer 'conv3' biases: 3.003005e-05 [2.140260e-08] 
Layer 'conv4' weights[0]: 4.448529e-03 [2.268771e-07] 
Layer 'conv4' biases: 9.999955e-01 [4.062380e-07] 
Layer 'conv5' weights[0]: 4.540712e-03 [3.392087e-06] 
Layer 'conv5' biases: 9.991208e-01 [3.736518e-06] 
Layer 'fc6' weights[0]: 7.143052e-03 [7.081115e-08] 
Layer 'fc6' biases: 9.999939e-01 [7.028891e-08] 
Layer 'fc7' weights[0]: 7.495008e-03 [1.700291e-07] 
Layer 'fc7' biases: 9.998360e-01 [2.717520e-07] 
Layer 'fc8' weights[0]: 4.576972e-03 [1.985190e-05] 
Layer 'fc8' biases: 1.268378e-02 [4.461593e-05] 
Train error last 800 batches: 0.654216
-------------------------------------------------------
Not saving because 0.446705 > 0.299667 (9.300: -1.18%)
======================================================= (2.360 sec)
15.541... logprob:  0.677821, 0.296875 (1.433 sec)
15.542... logprob:  0.664658, 0.312500 (1.433 sec)
15.543... logprob:  0.456079, 0.208333 (1.431 sec)
15.544... logprob:  0.554385, 0.240885 (1.423 sec)
15.545... logprob:  0.631755, 0.268229 (1.426 sec)
15.546... logprob:  0.645818, 0.309896 (1.481 sec)
15.547... logprob:  0.678587, 0.285156 (1.432 sec)
15.548... logprob:  0.711144, 0.328125 (1.437 sec)
15.549... logprob:  0.720368, 0.298177 (1.472 sec)
15.550... logprob:  0.619594, 0.274740 (1.429 sec)
15.551... logprob:  0.661373, 0.278646 (1.426 sec)
15.552... logprob:  0.726752, 0.307292 (1.428 sec)
15.553... logprob:  0.592206, 0.282552 (1.423 sec)
15.554... logprob:  0.738468, 0.316406 (1.427 sec)
15.555... logprob:  0.624546, 0.286458 (1.475 sec)
15.556... logprob:  0.654359, 0.316406 (1.431 sec)
15.557... logprob:  0.559717, 0.274740 (1.444 sec)
15.558... logprob:  0.672331, 0.302083 (1.464 sec)
15.559... logprob:  0.585726, 0.263021 (1.430 sec)
15.560... logprob:  0.741162, 0.361979 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.511333, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.435354e-03 [2.225888e-07] 
Layer 'conv1' biases: 1.826792e-06 [4.194300e-10] 
Layer 'conv2' weights[0]: 4.427016e-03 [2.218829e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.265552e-09] 
Layer 'conv3' weights[0]: 4.425614e-03 [2.231335e-07] 
Layer 'conv3' biases: 3.005646e-05 [1.873391e-08] 
Layer 'conv4' weights[0]: 4.444092e-03 [2.256605e-07] 
Layer 'conv4' biases: 9.999950e-01 [3.448660e-07] 
Layer 'conv5' weights[0]: 4.536364e-03 [2.592111e-06] 
Layer 'conv5' biases: 9.991145e-01 [2.792266e-06] 
Layer 'fc6' weights[0]: 7.142278e-03 [6.252100e-08] 
Layer 'fc6' biases: 9.999937e-01 [5.840761e-08] 
Layer 'fc7' weights[0]: 7.494282e-03 [1.439826e-07] 
Layer 'fc7' biases: 9.998360e-01 [2.014281e-07] 
Layer 'fc8' weights[0]: 4.607959e-03 [1.576723e-05] 
Layer 'fc8' biases: 1.288656e-02 [2.806677e-05] 
Train error last 800 batches: 0.654901
-------------------------------------------------------
Not saving because 0.511333 > 0.299667 (9.300: -1.18%)
======================================================= (2.385 sec)
15.561... logprob:  0.670097, 0.295573 (1.438 sec)
15.562... logprob:  0.662678, 0.285156 (1.421 sec)
15.563... logprob:  0.589186, 0.256510 (1.438 sec)
15.564... logprob:  0.691311, 0.299479 (1.460 sec)
15.565... logprob:  0.748047, 0.351563 (1.443 sec)
15.566... logprob:  0.650912, 0.309896 (1.448 sec)
15.567... logprob:  0.664721, 0.302083 (1.465 sec)
15.568... logprob:  0.678885, 0.287760 (1.449 sec)
15.569... logprob:  0.717452, 0.303385 (1.434 sec)
15.570... logprob:  0.767676, 0.295573 (1.423 sec)
15.571... logprob:  0.671888, 0.264323 (1.425 sec)
15.572... logprob:  0.759799, 0.299479 (1.431 sec)
15.573... logprob:  0.721021, 0.285156 (1.441 sec)
15.574... logprob:  0.616288, 0.281250 (1.457 sec)
15.575... logprob:  0.605768, 0.269531 (1.447 sec)
15.576... logprob:  0.633684, 0.256510 (1.461 sec)
15.577... logprob:  0.584994, 0.278646 (1.472 sec)
15.578... logprob:  0.565980, 0.268229 (1.433 sec)
15.579... logprob:  0.710034, 0.299479 (1.417 sec)
15.580... logprob:  0.757141, 0.351562 (1.424 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.422328, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.430910e-03 [2.220983e-07] 
Layer 'conv1' biases: 1.830148e-06 [3.501337e-10] 
Layer 'conv2' weights[0]: 4.422626e-03 [2.215997e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.068720e-09] 
Layer 'conv3' weights[0]: 4.421186e-03 [2.226379e-07] 
Layer 'conv3' biases: 3.007948e-05 [1.737325e-08] 
Layer 'conv4' weights[0]: 4.439684e-03 [2.242066e-07] 
Layer 'conv4' biases: 9.999927e-01 [2.731260e-07] 
Layer 'conv5' weights[0]: 4.530950e-03 [2.433447e-06] 
Layer 'conv5' biases: 9.991321e-01 [2.561092e-06] 
Layer 'fc6' weights[0]: 7.141551e-03 [6.049382e-08] 
Layer 'fc6' biases: 9.999938e-01 [5.564350e-08] 
Layer 'fc7' weights[0]: 7.493551e-03 [1.389033e-07] 
Layer 'fc7' biases: 9.998341e-01 [1.688742e-07] 
Layer 'fc8' weights[0]: 4.564706e-03 [1.490355e-05] 
Layer 'fc8' biases: 1.251725e-02 [2.125299e-05] 
Train error last 800 batches: 0.654562
-------------------------------------------------------
Not saving because 0.422328 > 0.299667 (9.300: -1.18%)
======================================================= (2.381 sec)
15.581... logprob:  0.717038, 0.300781 (1.440 sec)
15.582... logprob:  0.707955, 0.313802 (1.439 sec)
15.583... logprob:  0.788782, 0.313802 (1.470 sec)
15.584... logprob:  0.696879, 0.315104 (1.442 sec)
15.585... logprob:  0.543778, 0.243490 (1.428 sec)
15.586... logprob:  0.536962, 0.221354 (1.481 sec)
15.587... logprob:  0.617934, 0.265625 (1.433 sec)
15.588... logprob:  0.605895, 0.273438 (1.430 sec)
15.589... logprob:  0.625776, 0.287760 (1.429 sec)
15.590... logprob:  0.708479, 0.308594 (1.429 sec)
15.591... logprob:  0.605988, 0.261719 (1.423 sec)
15.592... logprob:  0.594231, 0.274740 (1.479 sec)
15.593... logprob:  0.697283, 0.315104 (1.429 sec)
15.594... logprob:  0.631276, 0.277344 (1.436 sec)
15.595... logprob:  0.601909, 0.255208 (1.481 sec)
15.596... logprob:  0.719494, 0.282552 (1.429 sec)
15.597... logprob:  0.581425, 0.264323 (1.430 sec)
15.598... logprob:  0.571678, 0.248698 (1.433 sec)
15.599... logprob:  0.652219, 0.290365 (1.420 sec)
15.600... logprob:  0.559996, 0.265625 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.498825, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.426481e-03 [2.223118e-07] 
Layer 'conv1' biases: 1.831647e-06 [2.670074e-10] 
Layer 'conv2' weights[0]: 4.418204e-03 [2.215048e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.789664e-09] 
Layer 'conv3' weights[0]: 4.416789e-03 [2.222612e-07] 
Layer 'conv3' biases: 3.007721e-05 [1.537856e-08] 
Layer 'conv4' weights[0]: 4.435227e-03 [2.245916e-07] 
Layer 'conv4' biases: 9.999948e-01 [2.960822e-07] 
Layer 'conv5' weights[0]: 4.527745e-03 [2.857093e-06] 
Layer 'conv5' biases: 9.991213e-01 [3.195018e-06] 
Layer 'fc6' weights[0]: 7.140862e-03 [7.019886e-08] 
Layer 'fc6' biases: 9.999937e-01 [6.895512e-08] 
Layer 'fc7' weights[0]: 7.492802e-03 [1.678535e-07] 
Layer 'fc7' biases: 9.998353e-01 [2.745257e-07] 
Layer 'fc8' weights[0]: 4.609406e-03 [2.037476e-05] 
Layer 'fc8' biases: 1.291537e-02 [5.151203e-05] 
Train error last 800 batches: 0.653931
-------------------------------------------------------
Not saving because 0.498825 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
15.601... logprob:  0.608523, 0.268229 (1.490 sec)
15.602... logprob:  0.659252, 0.309896 (1.433 sec)
15.603... logprob:  0.523180, 0.248698 (1.439 sec)
15.604... logprob:  0.629763, 0.269531 (1.470 sec)
15.605... logprob:  0.727840, 0.321615 (1.427 sec)
15.606... logprob:  0.592409, 0.256510 (1.433 sec)
15.607... logprob:  0.707943, 0.264323 (1.426 sec)
15.608... logprob:  0.531831, 0.248698 (1.418 sec)
15.609... logprob:  0.548416, 0.236979 (1.430 sec)
15.610... logprob:  0.705091, 0.303385 (1.465 sec)
15.611... logprob:  0.797532, 0.334635 (1.440 sec)
15.612... logprob:  0.599706, 0.270833 (1.443 sec)
15.613... logprob:  0.646760, 0.286458 (1.466 sec)
15.614... logprob:  0.747872, 0.319010 (1.460 sec)
15.615... logprob:  0.553825, 0.270833 (1.439 sec)
15.616... logprob:  0.593643, 0.253906 (1.419 sec)
15.617... logprob:  0.639889, 0.291667 (1.425 sec)
15.618... logprob:  0.704713, 0.319010 (1.438 sec)
15.619... logprob:  0.691528, 0.290365 (1.443 sec)
15.620... logprob:  0.719894, 0.320312 (1.454 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.565227, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.422062e-03 [2.219423e-07] 
Layer 'conv1' biases: 1.833817e-06 [4.749942e-10] 
Layer 'conv2' weights[0]: 4.413797e-03 [2.213583e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.987517e-09] 
Layer 'conv3' weights[0]: 4.412391e-03 [2.233243e-07] 
Layer 'conv3' biases: 3.009020e-05 [2.178910e-08] 
Layer 'conv4' weights[0]: 4.430788e-03 [2.266606e-07] 
Layer 'conv4' biases: 9.999952e-01 [4.224188e-07] 
Layer 'conv5' weights[0]: 4.523764e-03 [3.399647e-06] 
Layer 'conv5' biases: 9.991211e-01 [3.612876e-06] 
Layer 'fc6' weights[0]: 7.140111e-03 [7.695596e-08] 
Layer 'fc6' biases: 9.999938e-01 [7.829735e-08] 
Layer 'fc7' weights[0]: 7.492058e-03 [1.878913e-07] 
Layer 'fc7' biases: 9.998351e-01 [3.233745e-07] 
Layer 'fc8' weights[0]: 4.608881e-03 [2.169195e-05] 
Layer 'fc8' biases: 1.296874e-02 [5.246116e-05] 
Train error last 800 batches: 0.654097
-------------------------------------------------------
Not saving because 0.565227 > 0.299667 (9.300: -1.18%)
======================================================= (2.360 sec)
15.621... logprob:  0.653023, 0.300781 (1.455 sec)
15.622... logprob:  0.567233, 0.244792 (1.441 sec)
15.623... logprob:  0.668160, 0.276042 (1.460 sec)
15.624... logprob:  0.683166, 0.292969 (1.431 sec)
15.625... logprob:  0.626018, 0.277344 (1.417 sec)
15.626... logprob:  0.629705, 0.290365 (1.427 sec)
15.627... logprob:  0.652250, 0.283854 (1.430 sec)
15.628... logprob:  0.675734, 0.283854 (1.428 sec)
15.629... logprob:  0.588205, 0.257812 (1.470 sec)
15.630... logprob:  0.647394, 0.259115 (1.442 sec)
15.631... logprob:  0.766365, 0.345052 (1.427 sec)
15.632... logprob:  0.684452, 0.305990 (1.480 sec)
15.633... logprob:  0.604580, 0.273438 (1.423 sec)
15.634... logprob:  0.735831, 0.312500 (1.424 sec)
15.635... logprob:  0.533813, 0.240885 (1.426 sec)
15.636... logprob:  0.648713, 0.313802 (1.427 sec)
15.637... logprob:  0.505117, 0.236979 (1.431 sec)
15.638... logprob:  0.730882, 0.332031 (1.471 sec)
15.639... logprob:  0.652306, 0.296875 (1.437 sec)
15.640... logprob:  0.735495, 0.347656 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.440417, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.417629e-03 [2.215715e-07] 
Layer 'conv1' biases: 1.834739e-06 [2.412264e-10] 
Layer 'conv2' weights[0]: 4.409367e-03 [2.209336e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.216169e-09] 
Layer 'conv3' weights[0]: 4.407978e-03 [2.215455e-07] 
Layer 'conv3' biases: 3.009507e-05 [1.314923e-08] 
Layer 'conv4' weights[0]: 4.426384e-03 [2.230080e-07] 
Layer 'conv4' biases: 9.999949e-01 [2.057981e-07] 
Layer 'conv5' weights[0]: 4.519513e-03 [2.199213e-06] 
Layer 'conv5' biases: 9.991230e-01 [2.373657e-06] 
Layer 'fc6' weights[0]: 7.139360e-03 [5.827125e-08] 
Layer 'fc6' biases: 9.999937e-01 [5.201913e-08] 
Layer 'fc7' weights[0]: 7.491337e-03 [1.340246e-07] 
Layer 'fc7' biases: 9.998347e-01 [1.646004e-07] 
Layer 'fc8' weights[0]: 4.583057e-03 [1.402671e-05] 
Layer 'fc8' biases: 1.282648e-02 [1.845340e-05] 
Train error last 800 batches: 0.653865
-------------------------------------------------------
Not saving because 0.440417 > 0.299667 (9.300: -1.18%)
======================================================= (2.381 sec)
15.641... logprob:  0.597128, 0.269531 (1.485 sec)
15.642... logprob:  0.732830, 0.347656 (1.436 sec)
15.643... logprob:  0.782973, 0.322917 (1.432 sec)
15.644... logprob:  0.564876, 0.266927 (1.427 sec)
15.645... logprob:  0.644051, 0.308594 (1.425 sec)
15.646... logprob:  0.585822, 0.269531 (1.427 sec)
15.647... logprob:  0.714211, 0.305990 (1.481 sec)
15.648... logprob:  0.708449, 0.307292 (1.431 sec)
15.649... logprob:  0.628159, 0.287760 (1.444 sec)
15.650... logprob:  0.625625, 0.260417 (1.476 sec)
15.651... logprob:  0.649612, 0.305990 (1.427 sec)
15.652... logprob:  0.637885, 0.287760 (1.431 sec)
15.653... logprob:  0.694784, 0.294271 (1.434 sec)
15.654... logprob:  0.641513, 0.273438 (1.418 sec)
15.655... logprob:  0.744323, 0.355469 (1.431 sec)
15.656... logprob:  0.720307, 0.312500 (1.477 sec)
15.657... logprob:  0.660309, 0.256510 (1.446 sec)
15.658... logprob:  0.602524, 0.270833 (1.453 sec)
15.659... logprob:  0.690195, 0.302083 (1.459 sec)
15.660... logprob:  0.670506, 0.308594 (1.483 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.324161, 0.039062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.413227e-03 [2.210800e-07] 
Layer 'conv1' biases: 1.836876e-06 [4.069661e-10] 
Layer 'conv2' weights[0]: 4.404961e-03 [2.206824e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.231398e-09] 
Layer 'conv3' weights[0]: 4.403553e-03 [2.218476e-07] 
Layer 'conv3' biases: 3.011308e-05 [1.758152e-08] 
Layer 'conv4' weights[0]: 4.421913e-03 [2.239272e-07] 
Layer 'conv4' biases: 9.999924e-01 [3.258585e-07] 
Layer 'conv5' weights[0]: 4.514061e-03 [2.761742e-06] 
Layer 'conv5' biases: 9.991279e-01 [2.920433e-06] 
Layer 'fc6' weights[0]: 7.138642e-03 [6.637763e-08] 
Layer 'fc6' biases: 9.999937e-01 [6.369635e-08] 
Layer 'fc7' weights[0]: 7.490599e-03 [1.525546e-07] 
Layer 'fc7' biases: 9.998342e-01 [2.175368e-07] 
Layer 'fc8' weights[0]: 4.586249e-03 [1.870518e-05] 
Layer 'fc8' biases: 1.281857e-02 [4.317986e-05] 
Train error last 800 batches: 0.653615
-------------------------------------------------------
Not saving because 0.324161 > 0.299667 (9.300: -1.18%)
======================================================= (2.379 sec)
15.661... logprob:  0.657706, 0.289062 (1.439 sec)
15.662... logprob:  0.619535, 0.279948 (1.431 sec)
15.663... logprob:  0.598294, 0.259115 (1.418 sec)
15.664... logprob:  0.569384, 0.259115 (1.431 sec)
15.665... logprob:  0.620929, 0.259115 (1.456 sec)
15.666... logprob:  0.714890, 0.303385 (1.446 sec)
15.667... logprob:  0.741079, 0.324219 (1.453 sec)
15.668... logprob:  0.688214, 0.326823 (1.445 sec)
15.669... logprob:  0.578905, 0.235677 (1.456 sec)
15.670... logprob:  0.602554, 0.251302 (1.432 sec)
15.671... logprob:  0.613475, 0.225260 (1.419 sec)
15.672... logprob:  0.654896, 0.313802 (1.426 sec)
15.673... logprob:  0.582132, 0.273437 (1.430 sec)
15.674... logprob:  0.679452, 0.300781 (1.436 sec)
15.675... logprob:  0.676223, 0.307292 (1.456 sec)
15.676... logprob:  0.758499, 0.338542 (1.446 sec)
15.677... logprob:  0.703239, 0.283854 (1.436 sec)
15.678... logprob:  0.639903, 0.282552 (1.474 sec)
15.679... logprob:  0.647841, 0.266927 (1.425 sec)
15.680... logprob:  0.594375, 0.235677 (1.419 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.463284, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.408813e-03 [2.208894e-07] 
Layer 'conv1' biases: 1.838437e-06 [3.064120e-10] 
Layer 'conv2' weights[0]: 4.400554e-03 [2.205323e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.193379e-09] 
Layer 'conv3' weights[0]: 4.399122e-03 [2.218993e-07] 
Layer 'conv3' biases: 3.010905e-05 [1.896800e-08] 
Layer 'conv4' weights[0]: 4.417512e-03 [2.238598e-07] 
Layer 'conv4' biases: 9.999912e-01 [3.193461e-07] 
Layer 'conv5' weights[0]: 4.509063e-03 [2.508565e-06] 
Layer 'conv5' biases: 9.991166e-01 [2.701401e-06] 
Layer 'fc6' weights[0]: 7.137919e-03 [6.299831e-08] 
Layer 'fc6' biases: 9.999937e-01 [5.943723e-08] 
Layer 'fc7' weights[0]: 7.489812e-03 [1.425834e-07] 
Layer 'fc7' biases: 9.998347e-01 [1.771653e-07] 
Layer 'fc8' weights[0]: 4.615572e-03 [1.546993e-05] 
Layer 'fc8' biases: 1.301113e-02 [2.635321e-05] 
Train error last 800 batches: 0.653816
-------------------------------------------------------
Not saving because 0.463284 > 0.299667 (9.300: -1.18%)
======================================================= (2.355 sec)
15.681... logprob:  0.619732, 0.286458 (1.432 sec)
15.682... logprob:  0.569342, 0.261719 (1.430 sec)
15.683... logprob:  0.720504, 0.315104 (1.425 sec)
15.684... logprob:  0.660407, 0.268229 (1.471 sec)
15.685... logprob:  0.578024, 0.256510 (1.437 sec)
15.686... logprob:  0.579742, 0.263021 (1.426 sec)
15.687... logprob:  0.511382, 0.222656 (1.478 sec)
15.688... logprob:  0.588670, 0.283854 (1.433 sec)
15.689... logprob:  0.593323, 0.276042 (1.430 sec)
15.690... logprob:  0.762260, 0.289063 (1.430 sec)
15.691... logprob:  0.734269, 0.299479 (1.432 sec)
15.692... logprob:  0.650590, 0.287760 (1.425 sec)
15.693... logprob:  0.589081, 0.257812 (1.482 sec)
15.694... logprob:  0.572034, 0.243490 (1.427 sec)
15.695... logprob:  0.556552, 0.269531 (1.435 sec)
15.696... logprob:  0.680067, 0.281250 (1.473 sec)
15.697... logprob:  0.673630, 0.315104 (1.425 sec)
15.698... logprob:  0.830097, 0.361979 (1.428 sec)
15.699... logprob:  0.649008, 0.261719 (1.425 sec)
15.700... logprob:  0.679550, 0.270833 (1.424 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.492540, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.404399e-03 [2.205701e-07] 
Layer 'conv1' biases: 1.839120e-06 [3.918234e-10] 
Layer 'conv2' weights[0]: 4.396151e-03 [2.201731e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.906060e-09] 
Layer 'conv3' weights[0]: 4.394749e-03 [2.214699e-07] 
Layer 'conv3' biases: 3.011850e-05 [1.982794e-08] 
Layer 'conv4' weights[0]: 4.413113e-03 [2.240849e-07] 
Layer 'conv4' biases: 9.999948e-01 [3.703137e-07] 
Layer 'conv5' weights[0]: 4.506904e-03 [3.499004e-06] 
Layer 'conv5' biases: 9.991035e-01 [3.803656e-06] 
Layer 'fc6' weights[0]: 7.137158e-03 [7.096655e-08] 
Layer 'fc6' biases: 9.999936e-01 [7.027548e-08] 
Layer 'fc7' weights[0]: 7.489052e-03 [1.738177e-07] 
Layer 'fc7' biases: 9.998352e-01 [2.758946e-07] 
Layer 'fc8' weights[0]: 4.637716e-03 [2.090566e-05] 
Layer 'fc8' biases: 1.328697e-02 [4.786869e-05] 
Train error last 800 batches: 0.653959
-------------------------------------------------------
Not saving because 0.492540 > 0.299667 (9.300: -1.18%)
======================================================= (2.350 sec)
15.701... logprob:  0.676639, 0.294271 (1.435 sec)
15.702... logprob:  0.662240, 0.292969 (1.478 sec)
15.703... logprob:  0.637443, 0.291667 (1.427 sec)
15.704... logprob:  0.584932, 0.251302 (1.442 sec)
15.705... logprob:  0.635715, 0.278646 (1.469 sec)
15.706... logprob:  0.687854, 0.304687 (1.429 sec)
15.707... logprob:  0.761868, 0.296875 (1.430 sec)
15.708... logprob:  0.647985, 0.296875 (1.425 sec)
15.709... logprob:  0.641913, 0.313802 (1.421 sec)
15.710... logprob:  0.784259, 0.351562 (1.440 sec)
15.711... logprob:  0.716485, 0.299479 (1.457 sec)
15.712... logprob:  0.651528, 0.264323 (1.448 sec)
15.713... logprob:  0.784110, 0.358073 (1.449 sec)
15.714... logprob:  0.614544, 0.277344 (1.453 sec)
15.715... logprob:  0.638688, 0.287760 (1.449 sec)
15.716... logprob:  0.592934, 0.260417 (1.433 sec)
15.717... logprob:  0.694655, 0.307292 (1.420 sec)
15.718... logprob:  0.675449, 0.298177 (1.427 sec)
15.719... logprob:  0.672843, 0.281250 (1.431 sec)
15.720... logprob:  0.652706, 0.303385 (1.443 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.456958, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.400034e-03 [2.204515e-07] 
Layer 'conv1' biases: 1.841031e-06 [3.361511e-10] 
Layer 'conv2' weights[0]: 4.391773e-03 [2.198499e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.746345e-09] 
Layer 'conv3' weights[0]: 4.390393e-03 [2.206713e-07] 
Layer 'conv3' biases: 3.014452e-05 [1.458406e-08] 
Layer 'conv4' weights[0]: 4.408708e-03 [2.224818e-07] 
Layer 'conv4' biases: 9.999941e-01 [2.515306e-07] 
Layer 'conv5' weights[0]: 4.502500e-03 [2.718001e-06] 
Layer 'conv5' biases: 9.991403e-01 [2.981573e-06] 
Layer 'fc6' weights[0]: 7.136423e-03 [6.212151e-08] 
Layer 'fc6' biases: 9.999937e-01 [5.746016e-08] 
Layer 'fc7' weights[0]: 7.488319e-03 [1.428736e-07] 
Layer 'fc7' biases: 9.998319e-01 [1.873644e-07] 
Layer 'fc8' weights[0]: 4.531696e-03 [1.613260e-05] 
Layer 'fc8' biases: 1.252331e-02 [3.249185e-05] 
Train error last 800 batches: 0.654063
-------------------------------------------------------
Not saving because 0.456958 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
15.721... logprob:  0.719611, 0.309896 (1.464 sec)
15.722... logprob:  0.707178, 0.300781 (1.455 sec)
15.723... logprob:  0.632482, 0.295573 (1.437 sec)
15.724... logprob:  0.650721, 0.304687 (1.470 sec)
15.725... logprob:  0.710885, 0.308594 (1.428 sec)
15.726... logprob:  0.621464, 0.270833 (1.422 sec)
15.727... logprob:  0.559684, 0.259115 (1.429 sec)
15.728... logprob:  0.675312, 0.303385 (1.429 sec)
15.729... logprob:  0.556251, 0.247396 (1.438 sec)
15.730... logprob:  0.795044, 0.351562 (1.467 sec)
15.731... logprob:  0.660493, 0.286458 (1.441 sec)
15.732... logprob:  0.616776, 0.283854 (1.427 sec)
15.733... logprob:  0.770132, 0.328125 (1.478 sec)
15.734... logprob:  0.595243, 0.259115 (1.429 sec)
15.735... logprob:  0.728626, 0.324219 (1.422 sec)
15.736... logprob:  0.836372, 0.333333 (1.431 sec)
15.737... logprob:  0.818931, 0.333333 (1.425 sec)
15.738... logprob:  0.638700, 0.291667 (1.424 sec)
15.739... logprob:  0.726504, 0.308594 (1.478 sec)
15.740... logprob:  0.561987, 0.265625 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.460260, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.395615e-03 [2.202599e-07] 
Layer 'conv1' biases: 1.842847e-06 [3.026741e-10] 
Layer 'conv2' weights[0]: 4.387370e-03 [2.198831e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.810644e-09] 
Layer 'conv3' weights[0]: 4.386010e-03 [2.205122e-07] 
Layer 'conv3' biases: 3.011248e-05 [1.555588e-08] 
Layer 'conv4' weights[0]: 4.404275e-03 [2.225740e-07] 
Layer 'conv4' biases: 9.999945e-01 [2.774439e-07] 
Layer 'conv5' weights[0]: 4.498572e-03 [2.461437e-06] 
Layer 'conv5' biases: 9.991354e-01 [2.789235e-06] 
Layer 'fc6' weights[0]: 7.135632e-03 [6.350918e-08] 
Layer 'fc6' biases: 9.999937e-01 [5.913442e-08] 
Layer 'fc7' weights[0]: 7.487584e-03 [1.456485e-07] 
Layer 'fc7' biases: 9.998322e-01 [1.865966e-07] 
Layer 'fc8' weights[0]: 4.544574e-03 [1.568274e-05] 
Layer 'fc8' biases: 1.258756e-02 [2.385510e-05] 
Train error last 800 batches: 0.654675
-------------------------------------------------------
Not saving because 0.460260 > 0.299667 (9.300: -1.18%)
======================================================= (2.391 sec)
15.741... logprob:  0.573108, 0.248698 (1.436 sec)
15.742... logprob:  0.748690, 0.309896 (1.474 sec)
15.743... logprob:  0.608757, 0.259115 (1.430 sec)
15.744... logprob:  0.698110, 0.352865 (1.432 sec)
15.745... logprob:  0.628350, 0.259115 (1.430 sec)
15.746... logprob:  0.634052, 0.291667 (1.422 sec)
15.747... logprob:  0.665432, 0.273437 (1.428 sec)
15.748... logprob:  0.617554, 0.289062 (1.476 sec)
15.749... logprob:  0.632569, 0.260417 (1.431 sec)
15.750... logprob:  0.678352, 0.305990 (1.441 sec)
15.751... logprob:  0.476370, 0.223958 (1.481 sec)
15.752... logprob:  0.594275, 0.268229 (1.427 sec)
15.753... logprob:  0.628163, 0.270833 (1.431 sec)
15.754... logprob:  0.716106, 0.315104 (1.431 sec)
15.755... logprob:  0.739896, 0.334635 (1.424 sec)
15.756... logprob:  0.739361, 0.322917 (1.430 sec)
15.757... logprob:  0.807114, 0.358073 (1.466 sec)
15.758... logprob:  0.601237, 0.260417 (1.438 sec)
15.759... logprob:  0.696817, 0.279948 (1.445 sec)
15.760... logprob:  0.679136, 0.273438 (1.459 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.506869, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.391224e-03 [2.201210e-07] 
Layer 'conv1' biases: 1.844245e-06 [2.711236e-10] 
Layer 'conv2' weights[0]: 4.382991e-03 [2.195741e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.565399e-09] 
Layer 'conv3' weights[0]: 4.381574e-03 [2.202243e-07] 
Layer 'conv3' biases: 3.012100e-05 [1.492246e-08] 
Layer 'conv4' weights[0]: 4.399869e-03 [2.218802e-07] 
Layer 'conv4' biases: 9.999944e-01 [2.544724e-07] 
Layer 'conv5' weights[0]: 4.494447e-03 [2.533046e-06] 
Layer 'conv5' biases: 9.991257e-01 [2.810988e-06] 
Layer 'fc6' weights[0]: 7.134908e-03 [6.805895e-08] 
Layer 'fc6' biases: 9.999937e-01 [6.576941e-08] 
Layer 'fc7' weights[0]: 7.486810e-03 [1.606959e-07] 
Layer 'fc7' biases: 9.998328e-01 [2.313377e-07] 
Layer 'fc8' weights[0]: 4.566476e-03 [1.972974e-05] 
Layer 'fc8' biases: 1.283956e-02 [4.644967e-05] 
Train error last 800 batches: 0.654208
-------------------------------------------------------
Not saving because 0.506869 > 0.299667 (9.300: -1.18%)
======================================================= (2.376 sec)
15.761... logprob:  0.596375, 0.259115 (1.448 sec)
15.762... logprob:  0.696546, 0.292969 (1.439 sec)
15.763... logprob:  0.865273, 0.339844 (1.424 sec)
15.764... logprob:  0.678128, 0.273437 (1.426 sec)
15.765... logprob:  0.538784, 0.233073 (1.433 sec)
15.766... logprob:  0.669516, 0.296875 (1.448 sec)
15.767... logprob:  0.569457, 0.256510 (1.463 sec)
15.768... logprob:  0.740111, 0.322917 (1.459 sec)
15.769... logprob:  0.733782, 0.313802 (1.461 sec)
15.770... logprob:  0.619333, 0.283854 (1.477 sec)
15.771... logprob:  0.682440, 0.311198 (1.456 sec)
15.772... logprob:  0.579545, 0.270833 (1.440 sec)
15.773... logprob:  0.780712, 0.352865 (1.442 sec)
15.774... logprob:  0.559532, 0.240885 (1.459 sec)
15.775... logprob:  0.542299, 0.250000 (1.459 sec)
15.776... logprob:  0.616972, 0.263021 (1.480 sec)
15.777... logprob:  0.596737, 0.263021 (1.468 sec)
15.778... logprob:  0.694038, 0.309896 (1.461 sec)
15.779... logprob:  0.716482, 0.342448 (1.484 sec)
15.780... logprob:  0.679754, 0.295573 (1.454 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.476465, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.386859e-03 [2.199847e-07] 
Layer 'conv1' biases: 1.844942e-06 [3.879056e-10] 
Layer 'conv2' weights[0]: 4.378617e-03 [2.197138e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.533587e-09] 
Layer 'conv3' weights[0]: 4.377206e-03 [2.209854e-07] 
Layer 'conv3' biases: 3.011576e-05 [1.995203e-08] 
Layer 'conv4' weights[0]: 4.395477e-03 [2.234037e-07] 
Layer 'conv4' biases: 9.999939e-01 [3.153817e-07] 
Layer 'conv5' weights[0]: 4.490010e-03 [2.778546e-06] 
Layer 'conv5' biases: 9.991288e-01 [2.904906e-06] 
Layer 'fc6' weights[0]: 7.134151e-03 [6.758250e-08] 
Layer 'fc6' biases: 9.999936e-01 [6.496396e-08] 
Layer 'fc7' weights[0]: 7.486057e-03 [1.566554e-07] 
Layer 'fc7' biases: 9.998325e-01 [2.322279e-07] 
Layer 'fc8' weights[0]: 4.576255e-03 [1.861050e-05] 
Layer 'fc8' biases: 1.286677e-02 [3.506669e-05] 
Train error last 800 batches: 0.654237
-------------------------------------------------------
Not saving because 0.476465 > 0.299667 (9.300: -1.18%)
======================================================= (2.349 sec)
15.781... logprob:  0.604195, 0.278646 (1.443 sec)
15.782... logprob:  0.619214, 0.276042 (1.448 sec)
15.783... logprob:  0.731094, 0.308594 (1.453 sec)
15.784... logprob:  0.663689, 0.294271 (1.450 sec)
15.785... logprob:  0.767497, 0.355469 (1.491 sec)
15.786... logprob:  0.658277, 0.295573 (1.458 sec)
15.787... logprob:  0.754232, 0.317708 (1.455 sec)
15.788... logprob:  0.765579, 0.332031 (1.488 sec)
15.789... logprob:  0.501381, 0.218750 (1.448 sec)
15.790... logprob:  0.704667, 0.299479 (1.439 sec)
15.791... logprob:  0.638874, 0.281250 (1.441 sec)
15.792... logprob:  0.646375, 0.289062 (1.455 sec)
15.793... logprob:  0.592852, 0.285156 (1.448 sec)
15.794... logprob:  0.588031, 0.263021 (1.478 sec)
15.795... logprob:  0.672791, 0.319010 (1.465 sec)
15.796... logprob:  0.645059, 0.270833 (1.451 sec)
15.797... logprob:  0.656758, 0.307292 (1.499 sec)
15.798... logprob:  0.572076, 0.257812 (1.455 sec)
15.799... logprob:  0.535810, 0.243490 (1.448 sec)
15.800... logprob:  0.578558, 0.252604 (1.400 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.450270, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.382458e-03 [2.201438e-07] 
Layer 'conv1' biases: 1.845087e-06 [4.463749e-10] 
Layer 'conv2' weights[0]: 4.374227e-03 [2.194315e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.545294e-09] 
Layer 'conv3' weights[0]: 4.372823e-03 [2.203967e-07] 
Layer 'conv3' biases: 3.009206e-05 [1.746188e-08] 
Layer 'conv4' weights[0]: 4.391101e-03 [2.231999e-07] 
Layer 'conv4' biases: 9.999907e-01 [3.321920e-07] 
Layer 'conv5' weights[0]: 4.484155e-03 [2.886427e-06] 
Layer 'conv5' biases: 9.991243e-01 [3.122012e-06] 
Layer 'fc6' weights[0]: 7.133419e-03 [7.135221e-08] 
Layer 'fc6' biases: 9.999936e-01 [7.017131e-08] 
Layer 'fc7' weights[0]: 7.485276e-03 [1.755503e-07] 
Layer 'fc7' biases: 9.998329e-01 [2.965538e-07] 
Layer 'fc8' weights[0]: 4.609720e-03 [2.149693e-05] 
Layer 'fc8' biases: 1.313379e-02 [5.527792e-05] 
Train error last 800 batches: 0.654377
-------------------------------------------------------
Not saving because 0.450270 > 0.299667 (9.300: -1.18%)
======================================================= (2.359 sec)
16.1... logprob:  0.538785, 0.247396 (1.403 sec)
16.2... logprob:  0.654800, 0.269531 (1.447 sec)
16.3... logprob:  0.611984, 0.256510 (1.413 sec)
16.4... logprob:  0.677524, 0.283854 (1.402 sec)
16.5... logprob:  0.661261, 0.265625 (1.436 sec)
16.6... logprob:  0.750387, 0.295573 (1.387 sec)
16.7... logprob:  0.641571, 0.257812 (1.426 sec)
16.8... logprob:  0.551496, 0.250000 (1.393 sec)
16.9... logprob:  0.604525, 0.283854 (1.406 sec)
16.10... logprob:  0.590740, 0.261719 (1.409 sec)
16.11... logprob:  0.656308, 0.296875 (1.439 sec)
16.12... logprob:  0.662387, 0.269531 (1.397 sec)
16.13... logprob:  0.763405, 0.343750 (1.423 sec)
16.14... logprob:  0.659763, 0.286458 (1.407 sec)
16.15... logprob:  0.634406, 0.276042 (1.402 sec)
16.16... logprob:  0.665312, 0.248698 (1.403 sec)
16.17... logprob:  0.727650, 0.334635 (1.393 sec)
16.18... logprob:  0.442032, 0.217448 (1.399 sec)
16.19... logprob:  0.589743, 0.263021 (1.399 sec)
16.20... logprob:  0.627481, 0.272135 (1.395 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.496591, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.378062e-03 [2.192329e-07] 
Layer 'conv1' biases: 1.846298e-06 [2.480438e-10] 
Layer 'conv2' weights[0]: 4.369906e-03 [2.188306e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.072713e-09] 
Layer 'conv3' weights[0]: 4.368454e-03 [2.192339e-07] 
Layer 'conv3' biases: 3.008592e-05 [1.249335e-08] 
Layer 'conv4' weights[0]: 4.386704e-03 [2.209415e-07] 
Layer 'conv4' biases: 9.999895e-01 [2.305843e-07] 
Layer 'conv5' weights[0]: 4.479252e-03 [2.615541e-06] 
Layer 'conv5' biases: 9.991219e-01 [2.758677e-06] 
Layer 'fc6' weights[0]: 7.132660e-03 [6.283512e-08] 
Layer 'fc6' biases: 9.999937e-01 [5.880580e-08] 
Layer 'fc7' weights[0]: 7.484494e-03 [1.432232e-07] 
Layer 'fc7' biases: 9.998326e-01 [1.939364e-07] 
Layer 'fc8' weights[0]: 4.614094e-03 [1.679653e-05] 
Layer 'fc8' biases: 1.322153e-02 [3.803163e-05] 
Train error last 800 batches: 0.654086
-------------------------------------------------------
Not saving because 0.496591 > 0.299667 (9.300: -1.18%)
======================================================= (2.375 sec)
16.21... logprob:  0.615314, 0.289062 (1.406 sec)
16.22... logprob:  0.739835, 0.300781 (1.414 sec)
16.23... logprob:  0.696348, 0.291667 (1.415 sec)
16.24... logprob:  0.534527, 0.227865 (1.411 sec)
16.25... logprob:  0.608952, 0.282552 (1.401 sec)
16.26... logprob:  0.653070, 0.286458 (1.439 sec)
16.27... logprob:  0.648897, 0.289062 (1.382 sec)
16.28... logprob:  0.598511, 0.230469 (1.405 sec)
16.29... logprob:  0.635612, 0.265625 (1.419 sec)
16.30... logprob:  0.650682, 0.307292 (1.417 sec)
16.31... logprob:  0.644222, 0.264323 (1.404 sec)
16.32... logprob:  0.605283, 0.286458 (1.379 sec)
16.33... logprob:  0.711798, 0.311198 (1.438 sec)
16.34... logprob:  0.767518, 0.321615 (1.387 sec)
16.35... logprob:  0.564328, 0.278646 (1.396 sec)
16.36... logprob:  0.698145, 0.285156 (1.401 sec)
16.37... logprob:  0.544159, 0.225260 (1.404 sec)
16.38... logprob:  0.634387, 0.290364 (1.387 sec)
16.39... logprob:  0.742787, 0.316406 (1.431 sec)
16.40... logprob:  0.703260, 0.298177 (1.408 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.409796, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.373709e-03 [2.191633e-07] 
Layer 'conv1' biases: 1.846544e-06 [3.445568e-10] 
Layer 'conv2' weights[0]: 4.365491e-03 [2.186768e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.019942e-09] 
Layer 'conv3' weights[0]: 4.364098e-03 [2.197978e-07] 
Layer 'conv3' biases: 3.012504e-05 [1.838071e-08] 
Layer 'conv4' weights[0]: 4.382322e-03 [2.216213e-07] 
Layer 'conv4' biases: 9.999881e-01 [2.979573e-07] 
Layer 'conv5' weights[0]: 4.474389e-03 [2.740702e-06] 
Layer 'conv5' biases: 9.991361e-01 [2.987231e-06] 
Layer 'fc6' weights[0]: 7.131919e-03 [6.533340e-08] 
Layer 'fc6' biases: 9.999936e-01 [6.219078e-08] 
Layer 'fc7' weights[0]: 7.483729e-03 [1.489183e-07] 
Layer 'fc7' biases: 9.998311e-01 [2.018381e-07] 
Layer 'fc8' weights[0]: 4.584232e-03 [1.574611e-05] 
Layer 'fc8' biases: 1.296134e-02 [2.707201e-05] 
Train error last 800 batches: 0.653936
-------------------------------------------------------
Not saving because 0.409796 > 0.299667 (9.300: -1.18%)
======================================================= (2.401 sec)
16.41... logprob:  0.593536, 0.292969 (1.432 sec)
16.42... logprob:  0.563656, 0.270833 (1.417 sec)
16.43... logprob:  0.667177, 0.290365 (1.396 sec)
16.44... logprob:  0.761596, 0.337240 (1.432 sec)
16.45... logprob:  0.589130, 0.242188 (1.383 sec)
16.46... logprob:  0.675831, 0.307292 (1.396 sec)
16.47... logprob:  0.532427, 0.246094 (1.392 sec)
16.48... logprob:  0.680636, 0.273437 (1.417 sec)
16.49... logprob:  0.748223, 0.313802 (1.408 sec)
16.50... logprob:  0.542353, 0.235677 (1.417 sec)
16.51... logprob:  0.745087, 0.322917 (1.412 sec)
16.52... logprob:  0.699902, 0.298177 (1.390 sec)
16.53... logprob:  0.569751, 0.257812 (1.441 sec)
16.54... logprob:  0.675671, 0.304687 (1.390 sec)
16.55... logprob:  0.544681, 0.261719 (1.393 sec)
16.56... logprob:  0.609815, 0.294271 (1.399 sec)
16.57... logprob:  0.789595, 0.341146 (1.425 sec)
16.58... logprob:  0.692971, 0.285156 (1.403 sec)
16.59... logprob:  0.578972, 0.256510 (1.456 sec)
16.60... logprob:  0.869134, 0.341146 (1.412 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.481470, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.369333e-03 [2.193117e-07] 
Layer 'conv1' biases: 1.847090e-06 [4.073994e-10] 
Layer 'conv2' weights[0]: 4.361144e-03 [2.184673e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.066443e-09] 
Layer 'conv3' weights[0]: 4.359722e-03 [2.192404e-07] 
Layer 'conv3' biases: 3.014320e-05 [1.512627e-08] 
Layer 'conv4' weights[0]: 4.377938e-03 [2.209793e-07] 
Layer 'conv4' biases: 9.999890e-01 [2.720940e-07] 
Layer 'conv5' weights[0]: 4.470665e-03 [2.989610e-06] 
Layer 'conv5' biases: 9.991387e-01 [3.191661e-06] 
Layer 'fc6' weights[0]: 7.131188e-03 [6.593954e-08] 
Layer 'fc6' biases: 9.999937e-01 [6.265216e-08] 
Layer 'fc7' weights[0]: 7.483018e-03 [1.531110e-07] 
Layer 'fc7' biases: 9.998309e-01 [2.089233e-07] 
Layer 'fc8' weights[0]: 4.577605e-03 [1.619196e-05] 
Layer 'fc8' biases: 1.286400e-02 [2.807490e-05] 
Train error last 800 batches: 0.654415
-------------------------------------------------------
Not saving because 0.481470 > 0.299667 (9.300: -1.18%)
======================================================= (2.380 sec)
16.61... logprob:  0.599682, 0.264323 (1.437 sec)
16.62... logprob:  0.665037, 0.286458 (1.454 sec)
16.63... logprob:  0.643069, 0.304687 (1.438 sec)
16.64... logprob:  0.613239, 0.257812 (1.402 sec)
16.65... logprob:  0.625582, 0.273437 (1.394 sec)
16.66... logprob:  0.654369, 0.294271 (1.434 sec)
16.67... logprob:  0.649149, 0.304688 (1.384 sec)
16.68... logprob:  0.667386, 0.312500 (1.394 sec)
16.69... logprob:  0.700081, 0.317708 (1.423 sec)
16.70... logprob:  0.517350, 0.221354 (1.418 sec)
16.71... logprob:  0.648375, 0.289062 (1.457 sec)
16.72... logprob:  0.722130, 0.350260 (1.399 sec)
16.73... logprob:  0.709428, 0.273437 (1.420 sec)
16.74... logprob:  0.710150, 0.324219 (1.413 sec)
16.75... logprob:  0.641775, 0.270833 (1.416 sec)
16.76... logprob:  0.609093, 0.287760 (1.425 sec)
16.77... logprob:  0.610181, 0.266927 (1.429 sec)
16.78... logprob:  0.783250, 0.312500 (1.452 sec)
16.79... logprob:  0.547453, 0.261719 (1.396 sec)
16.80... logprob:  0.722109, 0.300781 (1.416 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.455378, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.364970e-03 [2.189956e-07] 
Layer 'conv1' biases: 1.847908e-06 [2.707110e-10] 
Layer 'conv2' weights[0]: 4.356793e-03 [2.183436e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.671068e-09] 
Layer 'conv3' weights[0]: 4.355364e-03 [2.187618e-07] 
Layer 'conv3' biases: 3.016932e-05 [1.322149e-08] 
Layer 'conv4' weights[0]: 4.373562e-03 [2.202732e-07] 
Layer 'conv4' biases: 9.999892e-01 [2.204706e-07] 
Layer 'conv5' weights[0]: 4.466613e-03 [2.140048e-06] 
Layer 'conv5' biases: 9.991294e-01 [2.341406e-06] 
Layer 'fc6' weights[0]: 7.130418e-03 [6.063400e-08] 
Layer 'fc6' biases: 9.999937e-01 [5.533174e-08] 
Layer 'fc7' weights[0]: 7.482282e-03 [1.367266e-07] 
Layer 'fc7' biases: 9.998314e-01 [1.600929e-07] 
Layer 'fc8' weights[0]: 4.609295e-03 [1.354415e-05] 
Layer 'fc8' biases: 1.309161e-02 [1.292786e-05] 
Train error last 800 batches: 0.654805
-------------------------------------------------------
Not saving because 0.455378 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
16.81... logprob:  0.613638, 0.292969 (1.416 sec)
16.82... logprob:  0.408383, 0.195312 (1.434 sec)
16.83... logprob:  0.697055, 0.294271 (1.395 sec)
16.84... logprob:  0.672700, 0.286458 (1.459 sec)
16.85... logprob:  0.640779, 0.286458 (1.414 sec)
16.86... logprob:  0.658538, 0.279948 (1.414 sec)
16.87... logprob:  0.853018, 0.356771 (1.408 sec)
16.88... logprob:  0.737568, 0.338542 (1.402 sec)
16.89... logprob:  0.695423, 0.317708 (1.425 sec)
16.90... logprob:  0.775313, 0.316406 (1.385 sec)
16.91... logprob:  0.594306, 0.266927 (1.391 sec)
16.92... logprob:  0.710392, 0.322917 (1.404 sec)
16.93... logprob:  0.619068, 0.281250 (1.398 sec)
16.94... logprob:  0.657048, 0.276042 (1.382 sec)
16.95... logprob:  0.750134, 0.338542 (1.401 sec)
16.96... logprob:  0.797425, 0.328125 (1.397 sec)
16.97... logprob:  0.621275, 0.279948 (1.385 sec)
16.98... logprob:  0.667500, 0.273437 (1.436 sec)
16.99... logprob:  0.624106, 0.289063 (1.399 sec)
16.100... logprob:  0.575949, 0.226562 (1.395 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.486169, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.360621e-03 [2.184352e-07] 
Layer 'conv1' biases: 1.848724e-06 [2.881827e-10] 
Layer 'conv2' weights[0]: 4.352400e-03 [2.179748e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.544836e-09] 
Layer 'conv3' weights[0]: 4.351006e-03 [2.185713e-07] 
Layer 'conv3' biases: 3.020166e-05 [1.433380e-08] 
Layer 'conv4' weights[0]: 4.369197e-03 [2.198814e-07] 
Layer 'conv4' biases: 9.999898e-01 [2.213052e-07] 
Layer 'conv5' weights[0]: 4.462678e-03 [2.311429e-06] 
Layer 'conv5' biases: 9.991485e-01 [2.425357e-06] 
Layer 'fc6' weights[0]: 7.129636e-03 [6.259808e-08] 
Layer 'fc6' biases: 9.999939e-01 [5.811345e-08] 
Layer 'fc7' weights[0]: 7.481548e-03 [1.402546e-07] 
Layer 'fc7' biases: 9.998302e-01 [1.712906e-07] 
Layer 'fc8' weights[0]: 4.557251e-03 [1.402843e-05] 
Layer 'fc8' biases: 1.271793e-02 [1.338458e-05] 
Train error last 800 batches: 0.654403
-------------------------------------------------------
Not saving because 0.486169 > 0.299667 (9.300: -1.18%)
======================================================= (2.421 sec)
16.101... logprob:  0.537191, 0.259115 (1.445 sec)
16.102... logprob:  0.650614, 0.263021 (1.387 sec)
16.103... logprob:  0.742096, 0.322917 (1.395 sec)
16.104... logprob:  0.649436, 0.269531 (1.402 sec)
16.105... logprob:  0.719644, 0.316406 (1.393 sec)
16.106... logprob:  0.620426, 0.287760 (1.391 sec)
16.107... logprob:  0.608310, 0.283854 (1.439 sec)
16.108... logprob:  0.750247, 0.317708 (1.388 sec)
16.109... logprob:  0.590948, 0.252604 (1.393 sec)
16.110... logprob:  0.757187, 0.295573 (1.395 sec)
16.111... logprob:  0.702159, 0.286458 (1.394 sec)
16.112... logprob:  0.596114, 0.279948 (1.392 sec)
16.113... logprob:  0.624577, 0.277344 (1.394 sec)
16.114... logprob:  0.621640, 0.277344 (1.424 sec)
16.115... logprob:  0.719721, 0.319010 (1.404 sec)
16.116... logprob:  0.564610, 0.238281 (1.393 sec)
16.117... logprob:  0.618989, 0.281250 (1.436 sec)
16.118... logprob:  0.665084, 0.291667 (1.383 sec)
16.119... logprob:  0.627614, 0.265625 (1.407 sec)
16.120... logprob:  0.691836, 0.302083 (1.396 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.481483, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.356255e-03 [2.184230e-07] 
Layer 'conv1' biases: 1.848297e-06 [2.615662e-10] 
Layer 'conv2' weights[0]: 4.348089e-03 [2.178054e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.593939e-09] 
Layer 'conv3' weights[0]: 4.346661e-03 [2.184966e-07] 
Layer 'conv3' biases: 3.023405e-05 [1.462671e-08] 
Layer 'conv4' weights[0]: 4.364822e-03 [2.202038e-07] 
Layer 'conv4' biases: 9.999928e-01 [2.460033e-07] 
Layer 'conv5' weights[0]: 4.460197e-03 [2.663240e-06] 
Layer 'conv5' biases: 9.991285e-01 [2.808234e-06] 
Layer 'fc6' weights[0]: 7.128875e-03 [6.277958e-08] 
Layer 'fc6' biases: 9.999939e-01 [5.831766e-08] 
Layer 'fc7' weights[0]: 7.480779e-03 [1.467670e-07] 
Layer 'fc7' biases: 9.998313e-01 [1.939797e-07] 
Layer 'fc8' weights[0]: 4.603403e-03 [1.671568e-05] 
Layer 'fc8' biases: 1.300230e-02 [3.532995e-05] 
Train error last 800 batches: 0.654704
-------------------------------------------------------
Not saving because 0.481483 > 0.299667 (9.300: -1.18%)
======================================================= (2.358 sec)
16.121... logprob:  0.629567, 0.273437 (1.413 sec)
16.122... logprob:  0.734702, 0.316406 (1.439 sec)
16.123... logprob:  0.660418, 0.287760 (1.382 sec)
16.124... logprob:  0.661083, 0.290365 (1.396 sec)
16.125... logprob:  0.584689, 0.276042 (1.394 sec)
16.126... logprob:  0.679673, 0.283854 (1.384 sec)
16.127... logprob:  0.703257, 0.315104 (1.391 sec)
16.128... logprob:  0.707560, 0.321615 (1.412 sec)
16.129... logprob:  0.732471, 0.319010 (1.414 sec)
16.130... logprob:  0.647944, 0.263021 (1.414 sec)
16.131... logprob:  0.717061, 0.278646 (1.406 sec)
16.132... logprob:  0.709342, 0.302083 (1.434 sec)
16.133... logprob:  0.653964, 0.277344 (1.383 sec)
16.134... logprob:  0.556536, 0.259115 (1.388 sec)
16.135... logprob:  0.600493, 0.263021 (1.394 sec)
16.136... logprob:  0.737812, 0.305990 (1.390 sec)
16.137... logprob:  0.678916, 0.287760 (1.393 sec)
16.138... logprob:  0.563561, 0.240885 (1.441 sec)
16.139... logprob:  0.618912, 0.279948 (1.389 sec)
16.140... logprob:  0.765649, 0.338542 (1.407 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.576044, 0.171875 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.351931e-03 [2.184268e-07] 
Layer 'conv1' biases: 1.850169e-06 [3.752912e-10] 
Layer 'conv2' weights[0]: 4.343723e-03 [2.176515e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.157404e-09] 
Layer 'conv3' weights[0]: 4.342313e-03 [2.191722e-07] 
Layer 'conv3' biases: 3.026633e-05 [2.031544e-08] 
Layer 'conv4' weights[0]: 4.360445e-03 [2.207882e-07] 
Layer 'conv4' biases: 9.999932e-01 [3.282060e-07] 
Layer 'conv5' weights[0]: 4.456216e-03 [2.558116e-06] 
Layer 'conv5' biases: 9.991361e-01 [2.783634e-06] 
Layer 'fc6' weights[0]: 7.128136e-03 [6.387649e-08] 
Layer 'fc6' biases: 9.999940e-01 [5.954140e-08] 
Layer 'fc7' weights[0]: 7.480022e-03 [1.459313e-07] 
Layer 'fc7' biases: 9.998296e-01 [1.887839e-07] 
Layer 'fc8' weights[0]: 4.561521e-03 [1.568218e-05] 
Layer 'fc8' biases: 1.267174e-02 [2.868222e-05] 
Train error last 800 batches: 0.654674
-------------------------------------------------------
Not saving because 0.576044 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
16.141... logprob:  0.738624, 0.321615 (1.435 sec)
16.142... logprob:  0.667172, 0.270833 (1.389 sec)
16.143... logprob:  0.580732, 0.269531 (1.419 sec)
16.144... logprob:  0.727659, 0.281250 (1.410 sec)
16.145... logprob:  0.573215, 0.274740 (1.410 sec)
16.146... logprob:  0.681205, 0.287760 (1.411 sec)
16.147... logprob:  0.494502, 0.227865 (1.426 sec)
16.148... logprob:  0.731249, 0.295573 (1.383 sec)
16.149... logprob:  0.628614, 0.290364 (1.388 sec)
16.150... logprob:  0.600112, 0.259114 (1.397 sec)
16.151... logprob:  0.621735, 0.264323 (1.389 sec)
16.152... logprob:  0.891325, 0.367188 (1.384 sec)
16.153... logprob:  0.641458, 0.264323 (1.440 sec)
16.154... logprob:  0.743025, 0.317708 (1.398 sec)
16.155... logprob:  0.600151, 0.261719 (1.401 sec)
16.156... logprob:  0.566453, 0.261719 (1.433 sec)
16.157... logprob:  0.574694, 0.270833 (1.387 sec)
16.158... logprob:  0.724183, 0.321615 (1.401 sec)
16.159... logprob:  0.749558, 0.317708 (1.392 sec)
16.160... logprob:  0.608339, 0.265625 (1.384 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.480039, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.347542e-03 [2.187460e-07] 
Layer 'conv1' biases: 1.852710e-06 [4.213932e-10] 
Layer 'conv2' weights[0]: 4.339416e-03 [2.176684e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.894627e-09] 
Layer 'conv3' weights[0]: 4.337942e-03 [2.193500e-07] 
Layer 'conv3' biases: 3.031675e-05 [2.171494e-08] 
Layer 'conv4' weights[0]: 4.356097e-03 [2.220554e-07] 
Layer 'conv4' biases: 9.999901e-01 [3.541492e-07] 
Layer 'conv5' weights[0]: 4.450476e-03 [2.699351e-06] 
Layer 'conv5' biases: 9.991335e-01 [2.919110e-06] 
Layer 'fc6' weights[0]: 7.127376e-03 [6.349916e-08] 
Layer 'fc6' biases: 9.999938e-01 [5.906315e-08] 
Layer 'fc7' weights[0]: 7.479272e-03 [1.459773e-07] 
Layer 'fc7' biases: 9.998296e-01 [1.937626e-07] 
Layer 'fc8' weights[0]: 4.586321e-03 [1.559495e-05] 
Layer 'fc8' biases: 1.287704e-02 [2.786473e-05] 
Train error last 800 batches: 0.655235
-------------------------------------------------------
Not saving because 0.480039 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
16.161... logprob:  0.595913, 0.265625 (1.420 sec)
16.162... logprob:  0.736202, 0.311198 (1.405 sec)
16.163... logprob:  0.631764, 0.273437 (1.422 sec)
16.164... logprob:  0.633304, 0.247396 (1.417 sec)
16.165... logprob:  0.753516, 0.305990 (1.412 sec)
16.166... logprob:  0.640456, 0.307292 (1.447 sec)
16.167... logprob:  0.568726, 0.250000 (1.431 sec)
16.168... logprob:  0.614514, 0.286458 (1.423 sec)
16.169... logprob:  0.639595, 0.303385 (1.451 sec)
16.170... logprob:  0.690501, 0.296875 (1.398 sec)
16.171... logprob:  0.705654, 0.304687 (1.415 sec)
16.172... logprob:  0.707445, 0.303385 (1.406 sec)
16.173... logprob:  0.603038, 0.269531 (1.414 sec)
16.174... logprob:  0.809343, 0.333333 (1.406 sec)
16.175... logprob:  0.702307, 0.316406 (1.460 sec)
16.176... logprob:  0.642568, 0.265625 (1.408 sec)
16.177... logprob:  0.604243, 0.255208 (1.420 sec)
16.178... logprob:  0.585114, 0.238281 (1.453 sec)
16.179... logprob:  0.641676, 0.296875 (1.403 sec)
16.180... logprob:  0.655233, 0.321615 (1.413 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.485770, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.343208e-03 [2.176983e-07] 
Layer 'conv1' biases: 1.855199e-06 [3.372311e-10] 
Layer 'conv2' weights[0]: 4.335043e-03 [2.172053e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.995747e-09] 
Layer 'conv3' weights[0]: 4.333643e-03 [2.180921e-07] 
Layer 'conv3' biases: 3.034232e-05 [1.690912e-08] 
Layer 'conv4' weights[0]: 4.351734e-03 [2.199154e-07] 
Layer 'conv4' biases: 9.999903e-01 [2.668397e-07] 
Layer 'conv5' weights[0]: 4.446222e-03 [2.380138e-06] 
Layer 'conv5' biases: 9.991220e-01 [2.526368e-06] 
Layer 'fc6' weights[0]: 7.126646e-03 [6.047724e-08] 
Layer 'fc6' biases: 9.999938e-01 [5.512298e-08] 
Layer 'fc7' weights[0]: 7.478524e-03 [1.367062e-07] 
Layer 'fc7' biases: 9.998302e-01 [1.680173e-07] 
Layer 'fc8' weights[0]: 4.605830e-03 [1.476201e-05] 
Layer 'fc8' biases: 1.308073e-02 [2.338207e-05] 
Train error last 800 batches: 0.654551
-------------------------------------------------------
Not saving because 0.485770 > 0.299667 (9.300: -1.18%)
======================================================= (2.376 sec)
16.181... logprob:  0.820835, 0.381510 (1.421 sec)
16.182... logprob:  0.645870, 0.292969 (1.416 sec)
16.183... logprob:  0.671849, 0.319010 (1.408 sec)
16.184... logprob:  0.611943, 0.238281 (1.411 sec)
16.185... logprob:  0.574616, 0.276042 (1.396 sec)
16.186... logprob:  0.549266, 0.234375 (1.398 sec)
16.187... logprob:  0.707120, 0.307292 (1.404 sec)
16.188... logprob:  0.752703, 0.313802 (1.396 sec)
16.189... logprob:  0.656096, 0.257812 (1.387 sec)
16.190... logprob:  0.538818, 0.252604 (1.433 sec)
16.191... logprob:  0.623924, 0.272135 (1.407 sec)
16.192... logprob:  0.743834, 0.316406 (1.409 sec)
16.193... logprob:  0.578547, 0.261719 (1.412 sec)
16.194... logprob:  0.674774, 0.303385 (1.418 sec)
16.195... logprob:  0.517998, 0.242188 (1.398 sec)
16.196... logprob:  0.683280, 0.307292 (1.381 sec)
16.197... logprob:  0.711398, 0.320312 (1.395 sec)
16.198... logprob:  0.577515, 0.287760 (1.398 sec)
16.199... logprob:  0.624505, 0.246094 (1.383 sec)
16.200... logprob:  0.663756, 0.274740 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.483429, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.338861e-03 [2.174733e-07] 
Layer 'conv1' biases: 1.857057e-06 [3.191582e-10] 
Layer 'conv2' weights[0]: 4.330716e-03 [2.169913e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.535624e-09] 
Layer 'conv3' weights[0]: 4.329330e-03 [2.174953e-07] 
Layer 'conv3' biases: 3.033054e-05 [1.339901e-08] 
Layer 'conv4' weights[0]: 4.347361e-03 [2.194038e-07] 
Layer 'conv4' biases: 9.999901e-01 [2.504058e-07] 
Layer 'conv5' weights[0]: 4.442279e-03 [2.433988e-06] 
Layer 'conv5' biases: 9.991050e-01 [2.561416e-06] 
Layer 'fc6' weights[0]: 7.125879e-03 [6.126495e-08] 
Layer 'fc6' biases: 9.999937e-01 [5.642844e-08] 
Layer 'fc7' weights[0]: 7.477731e-03 [1.422504e-07] 
Layer 'fc7' biases: 9.998310e-01 [1.845747e-07] 
Layer 'fc8' weights[0]: 4.627408e-03 [1.547122e-05] 
Layer 'fc8' biases: 1.321114e-02 [3.161358e-05] 
Train error last 800 batches: 0.655292
-------------------------------------------------------
Not saving because 0.483429 > 0.299667 (9.300: -1.18%)
======================================================= (2.393 sec)
16.201... logprob:  0.637662, 0.304688 (1.408 sec)
16.202... logprob:  0.715616, 0.291667 (1.405 sec)
16.203... logprob:  0.665201, 0.279948 (1.441 sec)
16.204... logprob:  0.683249, 0.309896 (1.391 sec)
16.205... logprob:  0.589095, 0.286458 (1.395 sec)
16.206... logprob:  0.585985, 0.252604 (1.393 sec)
16.207... logprob:  0.656655, 0.296875 (1.388 sec)
16.208... logprob:  0.733458, 0.315104 (1.388 sec)
16.209... logprob:  0.511891, 0.243490 (1.412 sec)
16.210... logprob:  0.756758, 0.334635 (1.412 sec)
16.211... logprob:  0.725308, 0.332031 (1.410 sec)
16.212... logprob:  0.758276, 0.325521 (1.410 sec)
16.213... logprob:  0.702372, 0.303385 (1.461 sec)
16.214... logprob:  0.777412, 0.313802 (1.424 sec)
16.215... logprob:  0.554996, 0.236979 (1.409 sec)
16.216... logprob:  0.754177, 0.354167 (1.461 sec)
16.217... logprob:  0.525756, 0.250000 (1.398 sec)
16.218... logprob:  0.662643, 0.287760 (1.423 sec)
16.219... logprob:  0.737095, 0.317708 (1.407 sec)
16.220... logprob:  0.657395, 0.292969 (1.414 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.507907, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.334538e-03 [2.172076e-07] 
Layer 'conv1' biases: 1.860844e-06 [3.631789e-10] 
Layer 'conv2' weights[0]: 4.326380e-03 [2.167606e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.510670e-09] 
Layer 'conv3' weights[0]: 4.324992e-03 [2.177340e-07] 
Layer 'conv3' biases: 3.041415e-05 [1.838487e-08] 
Layer 'conv4' weights[0]: 4.343044e-03 [2.190215e-07] 
Layer 'conv4' biases: 9.999882e-01 [2.799017e-07] 
Layer 'conv5' weights[0]: 4.437217e-03 [2.796412e-06] 
Layer 'conv5' biases: 9.991111e-01 [3.019357e-06] 
Layer 'fc6' weights[0]: 7.125124e-03 [6.752723e-08] 
Layer 'fc6' biases: 9.999937e-01 [6.530049e-08] 
Layer 'fc7' weights[0]: 7.476974e-03 [1.593739e-07] 
Layer 'fc7' biases: 9.998300e-01 [2.329002e-07] 
Layer 'fc8' weights[0]: 4.599208e-03 [1.808569e-05] 
Layer 'fc8' biases: 1.307786e-02 [3.574345e-05] 
Train error last 800 batches: 0.655131
-------------------------------------------------------
Not saving because 0.507907 > 0.299667 (9.300: -1.18%)
======================================================= (2.407 sec)
16.221... logprob:  0.616229, 0.269531 (1.413 sec)
16.222... logprob:  0.796638, 0.316406 (1.453 sec)
16.223... logprob:  0.709022, 0.317708 (1.424 sec)
16.224... logprob:  0.615553, 0.265625 (1.427 sec)
16.225... logprob:  0.557741, 0.246094 (1.440 sec)
16.226... logprob:  0.718656, 0.294271 (1.418 sec)
16.227... logprob:  0.647534, 0.268229 (1.411 sec)
16.228... logprob:  0.711221, 0.329427 (1.409 sec)
16.229... logprob:  0.666475, 0.300781 (1.411 sec)
16.230... logprob:  0.728367, 0.289063 (1.418 sec)
16.231... logprob:  0.663745, 0.302083 (1.398 sec)
16.232... logprob:  0.689810, 0.303385 (1.454 sec)
16.233... logprob:  0.670405, 0.289063 (1.426 sec)
16.234... logprob:  0.805825, 0.311198 (1.418 sec)
16.235... logprob:  0.729027, 0.347656 (1.464 sec)
16.236... logprob:  0.618810, 0.251302 (1.401 sec)
16.237... logprob:  0.625215, 0.260417 (1.413 sec)
16.238... logprob:  0.669240, 0.305990 (1.412 sec)
16.239... logprob:  0.651888, 0.290365 (1.413 sec)
16.240... logprob:  0.738354, 0.292969 (1.403 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.512161, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.330201e-03 [2.171865e-07] 
Layer 'conv1' biases: 1.862587e-06 [2.601622e-10] 
Layer 'conv2' weights[0]: 4.322087e-03 [2.165225e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.384915e-09] 
Layer 'conv3' weights[0]: 4.320676e-03 [2.171483e-07] 
Layer 'conv3' biases: 3.049587e-05 [1.579405e-08] 
Layer 'conv4' weights[0]: 4.338692e-03 [2.190316e-07] 
Layer 'conv4' biases: 9.999910e-01 [2.882768e-07] 
Layer 'conv5' weights[0]: 4.434298e-03 [2.552366e-06] 
Layer 'conv5' biases: 9.991171e-01 [2.753797e-06] 
Layer 'fc6' weights[0]: 7.124369e-03 [6.196593e-08] 
Layer 'fc6' biases: 9.999937e-01 [5.749593e-08] 
Layer 'fc7' weights[0]: 7.476222e-03 [1.416525e-07] 
Layer 'fc7' biases: 9.998288e-01 [1.646391e-07] 
Layer 'fc8' weights[0]: 4.564477e-03 [1.415809e-05] 
Layer 'fc8' biases: 1.278405e-02 [1.427264e-05] 
Train error last 800 batches: 0.655324
-------------------------------------------------------
Not saving because 0.512161 > 0.299667 (9.300: -1.18%)
======================================================= (2.363 sec)
16.241... logprob:  0.615448, 0.250000 (1.455 sec)
16.242... logprob:  0.573839, 0.243490 (1.420 sec)
16.243... logprob:  0.571280, 0.257812 (1.422 sec)
16.244... logprob:  0.595445, 0.276042 (1.444 sec)
16.245... logprob:  0.763300, 0.311198 (1.551 sec)
16.246... logprob:  0.620729, 0.253906 (1.415 sec)
16.247... logprob:  0.560727, 0.236979 (1.407 sec)
16.248... logprob:  0.561237, 0.251302 (1.413 sec)
16.249... logprob:  0.821730, 0.352864 (1.420 sec)
16.250... logprob:  0.670581, 0.296875 (1.398 sec)
16.251... logprob:  0.607038, 0.256510 (1.455 sec)
16.252... logprob:  0.622660, 0.282552 (1.416 sec)
16.253... logprob:  0.552212, 0.253906 (1.416 sec)
16.254... logprob:  0.718855, 0.315104 (1.464 sec)
16.255... logprob:  0.562126, 0.255208 (1.397 sec)
16.256... logprob:  0.579884, 0.226562 (1.418 sec)
16.257... logprob:  0.584727, 0.264323 (1.418 sec)
16.258... logprob:  0.612816, 0.260417 (1.416 sec)
16.259... logprob:  0.692676, 0.283854 (1.398 sec)
16.260... logprob:  0.558606, 0.251302 (1.448 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.392729, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.325867e-03 [2.168277e-07] 
Layer 'conv1' biases: 1.864104e-06 [3.048433e-10] 
Layer 'conv2' weights[0]: 4.317752e-03 [2.163559e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.117682e-09] 
Layer 'conv3' weights[0]: 4.316339e-03 [2.168378e-07] 
Layer 'conv3' biases: 3.057389e-05 [1.370462e-08] 
Layer 'conv4' weights[0]: 4.334376e-03 [2.183496e-07] 
Layer 'conv4' biases: 9.999942e-01 [2.222836e-07] 
Layer 'conv5' weights[0]: 4.431780e-03 [2.479132e-06] 
Layer 'conv5' biases: 9.990820e-01 [2.826817e-06] 
Layer 'fc6' weights[0]: 7.123645e-03 [6.265956e-08] 
Layer 'fc6' biases: 9.999934e-01 [5.898897e-08] 
Layer 'fc7' weights[0]: 7.475484e-03 [1.456229e-07] 
Layer 'fc7' biases: 9.998304e-01 [2.002697e-07] 
Layer 'fc8' weights[0]: 4.664353e-03 [1.623216e-05] 
Layer 'fc8' biases: 1.358687e-02 [2.612369e-05] 
Train error last 800 batches: 0.654747
-------------------------------------------------------
Not saving because 0.392729 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
16.261... logprob:  0.588938, 0.264323 (1.434 sec)
16.262... logprob:  0.725631, 0.302083 (1.429 sec)
16.263... logprob:  0.612203, 0.264323 (1.440 sec)
16.264... logprob:  0.622367, 0.276042 (1.417 sec)
16.265... logprob:  0.623476, 0.263021 (1.409 sec)
16.266... logprob:  0.612419, 0.238281 (1.409 sec)
16.267... logprob:  0.622886, 0.270833 (1.410 sec)
16.268... logprob:  0.731793, 0.350260 (1.414 sec)
16.269... logprob:  0.888918, 0.388021 (1.400 sec)
16.270... logprob:  0.673879, 0.313802 (1.452 sec)
16.271... logprob:  0.619389, 0.250000 (1.420 sec)
16.272... logprob:  0.558441, 0.257812 (1.412 sec)
16.273... logprob:  0.751947, 0.313802 (1.466 sec)
16.274... logprob:  0.746031, 0.348958 (1.393 sec)
16.275... logprob:  0.658495, 0.311198 (1.417 sec)
16.276... logprob:  0.661821, 0.277344 (1.409 sec)
16.277... logprob:  0.651153, 0.268229 (1.424 sec)
16.278... logprob:  0.620635, 0.269531 (1.440 sec)
16.279... logprob:  0.569350, 0.277344 (1.456 sec)
16.280... logprob:  0.450645, 0.212240 (1.397 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.445756, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.321569e-03 [2.167385e-07] 
Layer 'conv1' biases: 1.865262e-06 [2.116346e-10] 
Layer 'conv2' weights[0]: 4.313440e-03 [2.162366e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.415528e-09] 
Layer 'conv3' weights[0]: 4.312062e-03 [2.166009e-07] 
Layer 'conv3' biases: 3.058076e-05 [1.381470e-08] 
Layer 'conv4' weights[0]: 4.330017e-03 [2.185074e-07] 
Layer 'conv4' biases: 9.999933e-01 [2.579691e-07] 
Layer 'conv5' weights[0]: 4.427157e-03 [2.466844e-06] 
Layer 'conv5' biases: 9.991015e-01 [2.678509e-06] 
Layer 'fc6' weights[0]: 7.122891e-03 [6.036155e-08] 
Layer 'fc6' biases: 9.999936e-01 [5.557427e-08] 
Layer 'fc7' weights[0]: 7.474750e-03 [1.362225e-07] 
Layer 'fc7' biases: 9.998289e-01 [1.798077e-07] 
Layer 'fc8' weights[0]: 4.600962e-03 [1.406497e-05] 
Layer 'fc8' biases: 1.313381e-02 [2.326411e-05] 
Train error last 800 batches: 0.654586
-------------------------------------------------------
Not saving because 0.445756 > 0.299667 (9.300: -1.18%)
======================================================= (2.413 sec)
16.281... logprob:  0.673259, 0.286458 (1.433 sec)
16.282... logprob:  0.593703, 0.252604 (1.416 sec)
16.283... logprob:  0.629886, 0.278646 (1.409 sec)
16.284... logprob:  0.636498, 0.289062 (1.407 sec)
16.285... logprob:  0.709008, 0.328125 (1.438 sec)
16.286... logprob:  0.734753, 0.302083 (1.433 sec)
16.287... logprob:  0.603212, 0.274739 (1.426 sec)
16.288... logprob:  0.594375, 0.274740 (1.430 sec)
16.289... logprob:  0.669695, 0.312500 (1.442 sec)
16.290... logprob:  0.722182, 0.299479 (1.399 sec)
16.291... logprob:  0.702753, 0.304687 (1.411 sec)
16.292... logprob:  0.738041, 0.316406 (1.409 sec)
16.293... logprob:  0.608104, 0.279948 (1.418 sec)
16.294... logprob:  0.583745, 0.273437 (1.394 sec)
16.295... logprob:  0.541649, 0.240885 (1.457 sec)
16.296... logprob:  0.617601, 0.253906 (1.412 sec)
16.297... logprob:  0.564996, 0.243490 (1.420 sec)
16.298... logprob:  0.733284, 0.355469 (1.463 sec)
16.299... logprob:  0.624207, 0.266927 (1.396 sec)
16.300... logprob:  0.677001, 0.283854 (1.416 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.451461, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.317228e-03 [2.165801e-07] 
Layer 'conv1' biases: 1.866003e-06 [3.194061e-10] 
Layer 'conv2' weights[0]: 4.309142e-03 [2.158701e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.749921e-09] 
Layer 'conv3' weights[0]: 4.307726e-03 [2.166010e-07] 
Layer 'conv3' biases: 3.060198e-05 [1.555013e-08] 
Layer 'conv4' weights[0]: 4.325714e-03 [2.188424e-07] 
Layer 'conv4' biases: 9.999944e-01 [3.004375e-07] 
Layer 'conv5' weights[0]: 4.423728e-03 [2.545723e-06] 
Layer 'conv5' biases: 9.990879e-01 [2.733133e-06] 
Layer 'fc6' weights[0]: 7.122156e-03 [5.896281e-08] 
Layer 'fc6' biases: 9.999936e-01 [5.347002e-08] 
Layer 'fc7' weights[0]: 7.474048e-03 [1.330010e-07] 
Layer 'fc7' biases: 9.998296e-01 [1.524002e-07] 
Layer 'fc8' weights[0]: 4.627917e-03 [1.292468e-05] 
Layer 'fc8' biases: 1.335963e-02 [9.387039e-06] 
Train error last 800 batches: 0.654847
-------------------------------------------------------
Not saving because 0.451461 > 0.299667 (9.300: -1.18%)
======================================================= (2.371 sec)
16.301... logprob:  0.653807, 0.308594 (1.427 sec)
16.302... logprob:  0.813495, 0.351562 (1.414 sec)
16.303... logprob:  0.712362, 0.328125 (1.401 sec)
16.304... logprob:  0.659052, 0.276042 (1.433 sec)
16.305... logprob:  0.720545, 0.294271 (1.436 sec)
16.306... logprob:  0.573048, 0.242187 (1.433 sec)
16.307... logprob:  0.678549, 0.287760 (1.433 sec)
16.308... logprob:  0.598672, 0.281250 (1.447 sec)
16.309... logprob:  0.684776, 0.292969 (1.410 sec)
16.310... logprob:  0.701785, 0.300781 (1.426 sec)
16.311... logprob:  0.629321, 0.298177 (1.424 sec)
16.312... logprob:  0.705395, 0.315104 (1.428 sec)
16.313... logprob:  0.660593, 0.303385 (1.414 sec)
16.314... logprob:  0.661563, 0.305990 (1.457 sec)
16.315... logprob:  0.674992, 0.295573 (1.428 sec)
16.316... logprob:  0.617843, 0.257812 (1.421 sec)
16.317... logprob:  0.613792, 0.281250 (1.480 sec)
16.318... logprob:  0.756000, 0.308594 (1.406 sec)
16.319... logprob:  0.651645, 0.296875 (1.416 sec)
16.320... logprob:  0.759816, 0.322917 (1.423 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.568278, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.312911e-03 [2.159587e-07] 
Layer 'conv1' biases: 1.867597e-06 [3.138088e-10] 
Layer 'conv2' weights[0]: 4.304822e-03 [2.157607e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.928966e-09] 
Layer 'conv3' weights[0]: 4.303389e-03 [2.164661e-07] 
Layer 'conv3' biases: 3.056567e-05 [1.646597e-08] 
Layer 'conv4' weights[0]: 4.321375e-03 [2.180264e-07] 
Layer 'conv4' biases: 9.999938e-01 [2.687561e-07] 
Layer 'conv5' weights[0]: 4.419513e-03 [2.720748e-06] 
Layer 'conv5' biases: 9.991029e-01 [2.879246e-06] 
Layer 'fc6' weights[0]: 7.121464e-03 [6.480739e-08] 
Layer 'fc6' biases: 9.999936e-01 [6.173729e-08] 
Layer 'fc7' weights[0]: 7.473253e-03 [1.486917e-07] 
Layer 'fc7' biases: 9.998280e-01 [1.970812e-07] 
Layer 'fc8' weights[0]: 4.581560e-03 [1.545975e-05] 
Layer 'fc8' biases: 1.301578e-02 [2.358941e-05] 
Train error last 800 batches: 0.655206
-------------------------------------------------------
Not saving because 0.568278 > 0.299667 (9.300: -1.18%)
======================================================= (2.357 sec)
16.321... logprob:  0.565750, 0.246094 (1.434 sec)
16.322... logprob:  0.696052, 0.287760 (1.414 sec)
16.323... logprob:  0.744083, 0.312500 (1.468 sec)
16.324... logprob:  0.709597, 0.300781 (1.416 sec)
16.325... logprob:  0.627470, 0.250000 (1.434 sec)
16.326... logprob:  0.704360, 0.302083 (1.461 sec)
16.327... logprob:  0.797884, 0.320312 (1.414 sec)
16.328... logprob:  0.695066, 0.286458 (1.422 sec)
16.329... logprob:  0.649912, 0.290365 (1.423 sec)
16.330... logprob:  0.582699, 0.253906 (1.414 sec)
16.331... logprob:  0.570243, 0.247396 (1.410 sec)
16.332... logprob:  0.740485, 0.321615 (1.443 sec)
16.333... logprob:  0.587576, 0.259115 (1.439 sec)
16.334... logprob:  0.774707, 0.342448 (1.430 sec)
16.335... logprob:  0.673813, 0.291667 (1.436 sec)
16.336... logprob:  0.602312, 0.256510 (1.449 sec)
16.337... logprob:  0.777322, 0.337240 (1.406 sec)
16.338... logprob:  0.624371, 0.291667 (1.418 sec)
16.339... logprob:  0.755791, 0.332031 (1.417 sec)
16.340... logprob:  0.631915, 0.274740 (1.417 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.525451, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.308613e-03 [2.165273e-07] 
Layer 'conv1' biases: 1.867850e-06 [2.431522e-10] 
Layer 'conv2' weights[0]: 4.300525e-03 [2.157887e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.535776e-09] 
Layer 'conv3' weights[0]: 4.299088e-03 [2.165596e-07] 
Layer 'conv3' biases: 3.055602e-05 [1.726820e-08] 
Layer 'conv4' weights[0]: 4.317073e-03 [2.190059e-07] 
Layer 'conv4' biases: 9.999947e-01 [3.056679e-07] 
Layer 'conv5' weights[0]: 4.415820e-03 [2.904315e-06] 
Layer 'conv5' biases: 9.991089e-01 [3.057891e-06] 
Layer 'fc6' weights[0]: 7.120703e-03 [6.612407e-08] 
Layer 'fc6' biases: 9.999936e-01 [6.315577e-08] 
Layer 'fc7' weights[0]: 7.472530e-03 [1.556128e-07] 
Layer 'fc7' biases: 9.998267e-01 [2.191013e-07] 
Layer 'fc8' weights[0]: 4.555184e-03 [1.860663e-05] 
Layer 'fc8' biases: 1.269343e-02 [3.867025e-05] 
Train error last 800 batches: 0.655815
-------------------------------------------------------
Not saving because 0.525451 > 0.299667 (9.300: -1.18%)
======================================================= (2.356 sec)
16.341... logprob:  0.769488, 0.339844 (1.419 sec)
16.342... logprob:  0.646371, 0.285156 (1.465 sec)
16.343... logprob:  0.761108, 0.341146 (1.442 sec)
16.344... logprob:  0.635580, 0.270833 (1.473 sec)
16.345... logprob:  0.692166, 0.303385 (1.431 sec)
16.346... logprob:  0.753095, 0.325521 (1.431 sec)
16.347... logprob:  0.655441, 0.282552 (1.477 sec)
16.348... logprob:  0.591993, 0.263021 (1.428 sec)
16.349... logprob:  0.665257, 0.268229 (1.426 sec)
16.350... logprob:  0.554901, 0.238281 (1.427 sec)
16.351... logprob:  0.630848, 0.268229 (1.424 sec)
16.352... logprob:  0.700964, 0.317708 (1.429 sec)
16.353... logprob:  0.725879, 0.343750 (1.490 sec)
16.354... logprob:  0.780980, 0.328125 (1.432 sec)
16.355... logprob:  0.604197, 0.277344 (1.462 sec)
16.356... logprob:  0.662039, 0.273438 (1.471 sec)
16.357... logprob:  0.537067, 0.229167 (1.424 sec)
16.358... logprob:  0.533676, 0.226562 (1.434 sec)
16.359... logprob:  0.698073, 0.315104 (1.423 sec)
16.360... logprob:  0.715095, 0.287760 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.457336, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.304308e-03 [2.159124e-07] 
Layer 'conv1' biases: 1.868470e-06 [3.173590e-10] 
Layer 'conv2' weights[0]: 4.296234e-03 [2.152923e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.225816e-09] 
Layer 'conv3' weights[0]: 4.294832e-03 [2.162963e-07] 
Layer 'conv3' biases: 3.062826e-05 [1.774770e-08] 
Layer 'conv4' weights[0]: 4.312748e-03 [2.186009e-07] 
Layer 'conv4' biases: 9.999965e-01 [3.234135e-07] 
Layer 'conv5' weights[0]: 4.412523e-03 [2.954521e-06] 
Layer 'conv5' biases: 9.990922e-01 [3.278351e-06] 
Layer 'fc6' weights[0]: 7.119959e-03 [6.620375e-08] 
Layer 'fc6' biases: 9.999934e-01 [6.338998e-08] 
Layer 'fc7' weights[0]: 7.471770e-03 [1.573658e-07] 
Layer 'fc7' biases: 9.998276e-01 [2.269158e-07] 
Layer 'fc8' weights[0]: 4.600506e-03 [1.858667e-05] 
Layer 'fc8' biases: 1.305991e-02 [4.337115e-05] 
Train error last 800 batches: 0.655903
-------------------------------------------------------
Not saving because 0.457336 > 0.299667 (9.300: -1.18%)
======================================================= (2.362 sec)
16.361... logprob:  0.696313, 0.270833 (1.434 sec)
16.362... logprob:  0.700844, 0.324219 (1.468 sec)
16.363... logprob:  0.673925, 0.308594 (1.437 sec)
16.364... logprob:  0.750561, 0.341146 (1.449 sec)
16.365... logprob:  0.627140, 0.308594 (1.466 sec)
16.366... logprob:  0.699877, 0.303385 (1.444 sec)
16.367... logprob:  0.537701, 0.246094 (1.433 sec)
16.368... logprob:  0.679582, 0.273438 (1.421 sec)
16.369... logprob:  0.625333, 0.307292 (1.420 sec)
16.370... logprob:  0.573403, 0.266927 (1.431 sec)
16.371... logprob:  0.568101, 0.273438 (1.452 sec)
16.372... logprob:  0.780967, 0.319010 (1.449 sec)
16.373... logprob:  0.722622, 0.312500 (1.446 sec)
16.374... logprob:  0.716523, 0.315104 (1.445 sec)
16.375... logprob:  0.607255, 0.282552 (1.456 sec)
16.376... logprob:  0.656491, 0.304687 (1.433 sec)
16.377... logprob:  0.626153, 0.295573 (1.420 sec)
16.378... logprob:  0.772994, 0.324219 (1.431 sec)
16.379... logprob:  0.717521, 0.305990 (1.436 sec)
16.380... logprob:  0.806020, 0.322917 (1.435 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.442016, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.299991e-03 [2.156505e-07] 
Layer 'conv1' biases: 1.869817e-06 [4.288739e-10] 
Layer 'conv2' weights[0]: 4.291944e-03 [2.151837e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.951961e-09] 
Layer 'conv3' weights[0]: 4.290520e-03 [2.168237e-07] 
Layer 'conv3' biases: 3.067655e-05 [2.209394e-08] 
Layer 'conv4' weights[0]: 4.308417e-03 [2.189078e-07] 
Layer 'conv4' biases: 9.999971e-01 [3.804785e-07] 
Layer 'conv5' weights[0]: 4.408851e-03 [3.759505e-06] 
Layer 'conv5' biases: 9.990896e-01 [4.272367e-06] 
Layer 'fc6' weights[0]: 7.119253e-03 [7.810166e-08] 
Layer 'fc6' biases: 9.999934e-01 [8.002662e-08] 
Layer 'fc7' weights[0]: 7.471048e-03 [1.904839e-07] 
Layer 'fc7' biases: 9.998279e-01 [3.250833e-07] 
Layer 'fc8' weights[0]: 4.607071e-03 [2.275845e-05] 
Layer 'fc8' biases: 1.317686e-02 [5.567913e-05] 
Train error last 800 batches: 0.656525
-------------------------------------------------------
Not saving because 0.442016 > 0.299667 (9.300: -1.18%)
======================================================= (2.355 sec)
16.381... logprob:  0.732502, 0.311198 (1.466 sec)
16.382... logprob:  0.767470, 0.309896 (1.446 sec)
16.383... logprob:  0.585392, 0.273437 (1.436 sec)
16.384... logprob:  0.728869, 0.289062 (1.476 sec)
16.385... logprob:  0.800702, 0.320312 (1.425 sec)
16.386... logprob:  0.837477, 0.326823 (1.423 sec)
16.387... logprob:  0.664952, 0.302083 (1.426 sec)
16.388... logprob:  0.827117, 0.345052 (1.432 sec)
16.389... logprob:  0.662677, 0.294271 (1.424 sec)
16.390... logprob:  0.595465, 0.250000 (1.472 sec)
16.391... logprob:  0.588157, 0.268229 (1.439 sec)
16.392... logprob:  0.666562, 0.287760 (1.434 sec)
16.393... logprob:  0.622871, 0.295573 (1.513 sec)
16.394... logprob:  0.644584, 0.285156 (1.424 sec)
16.395... logprob:  0.589182, 0.253906 (1.427 sec)
16.396... logprob:  0.477392, 0.190104 (1.428 sec)
16.397... logprob:  0.706620, 0.279948 (1.426 sec)
16.398... logprob:  0.676823, 0.312500 (1.425 sec)
16.399... logprob:  0.612784, 0.292969 (1.483 sec)
16.400... logprob:  0.747039, 0.308594 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.483940, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.295720e-03 [2.163546e-07] 
Layer 'conv1' biases: 1.869680e-06 [4.139158e-10] 
Layer 'conv2' weights[0]: 4.287629e-03 [2.152181e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.352741e-09] 
Layer 'conv3' weights[0]: 4.286241e-03 [2.159235e-07] 
Layer 'conv3' biases: 3.073887e-05 [1.745246e-08] 
Layer 'conv4' weights[0]: 4.304114e-03 [2.189236e-07] 
Layer 'conv4' biases: 9.999948e-01 [3.527622e-07] 
Layer 'conv5' weights[0]: 4.403764e-03 [3.196523e-06] 
Layer 'conv5' biases: 9.991120e-01 [3.512769e-06] 
Layer 'fc6' weights[0]: 7.118530e-03 [7.738578e-08] 
Layer 'fc6' biases: 9.999934e-01 [7.745763e-08] 
Layer 'fc7' weights[0]: 7.470298e-03 [1.858769e-07] 
Layer 'fc7' biases: 9.998258e-01 [3.128682e-07] 
Layer 'fc8' weights[0]: 4.563039e-03 [2.266429e-05] 
Layer 'fc8' biases: 1.287464e-02 [6.095845e-05] 
Train error last 800 batches: 0.657223
-------------------------------------------------------
Not saving because 0.483940 > 0.299667 (9.300: -1.18%)
======================================================= (2.388 sec)
16.401... logprob:  0.676618, 0.307292 (1.443 sec)
16.402... logprob:  0.748305, 0.316406 (1.482 sec)
16.403... logprob:  0.668049, 0.283854 (1.432 sec)
16.404... logprob:  0.650629, 0.289062 (1.430 sec)
16.405... logprob:  0.656273, 0.287760 (1.427 sec)
16.406... logprob:  0.617358, 0.256510 (1.420 sec)
16.407... logprob:  0.727466, 0.326823 (1.428 sec)
16.408... logprob:  0.642621, 0.286458 (1.476 sec)
16.409... logprob:  0.562517, 0.231771 (1.437 sec)
16.410... logprob:  0.866859, 0.339844 (1.445 sec)
16.411... logprob:  0.638614, 0.285156 (1.468 sec)
16.412... logprob:  0.835531, 0.347656 (1.430 sec)
16.413... logprob:  0.603805, 0.263021 (1.432 sec)
16.414... logprob:  0.642414, 0.300781 (1.427 sec)
16.415... logprob:  0.640856, 0.291667 (1.418 sec)
16.416... logprob:  0.635595, 0.269531 (1.432 sec)
16.417... logprob:  0.554604, 0.253906 (1.461 sec)
16.418... logprob:  0.645814, 0.300781 (1.448 sec)
16.419... logprob:  0.542409, 0.212240 (1.448 sec)
16.420... logprob:  0.558847, 0.233073 (1.445 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.392527, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.291408e-03 [2.151849e-07] 
Layer 'conv1' biases: 1.871380e-06 [3.394695e-10] 
Layer 'conv2' weights[0]: 4.283358e-03 [2.145875e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.002992e-09] 
Layer 'conv3' weights[0]: 4.281953e-03 [2.155227e-07] 
Layer 'conv3' biases: 3.077840e-05 [1.727667e-08] 
Layer 'conv4' weights[0]: 4.299830e-03 [2.175429e-07] 
Layer 'conv4' biases: 9.999941e-01 [2.955442e-07] 
Layer 'conv5' weights[0]: 4.399624e-03 [2.564661e-06] 
Layer 'conv5' biases: 9.990910e-01 [2.812016e-06] 
Layer 'fc6' weights[0]: 7.117807e-03 [6.388975e-08] 
Layer 'fc6' biases: 9.999933e-01 [6.025779e-08] 
Layer 'fc7' weights[0]: 7.469520e-03 [1.494390e-07] 
Layer 'fc7' biases: 9.998271e-01 [2.131645e-07] 
Layer 'fc8' weights[0]: 4.611300e-03 [1.720632e-05] 
Layer 'fc8' biases: 1.326177e-02 [3.841088e-05] 
Train error last 800 batches: 0.656369
-------------------------------------------------------
Not saving because 0.392527 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
16.421... logprob:  0.571447, 0.256510 (1.454 sec)
16.422... logprob:  0.707673, 0.285156 (1.435 sec)
16.423... logprob:  0.673156, 0.283854 (1.426 sec)
16.424... logprob:  0.543871, 0.244792 (1.422 sec)
16.425... logprob:  0.547364, 0.251302 (1.429 sec)
16.426... logprob:  0.677850, 0.294271 (1.437 sec)
16.427... logprob:  0.750384, 0.326823 (1.461 sec)
16.428... logprob:  0.750520, 0.322917 (1.453 sec)
16.429... logprob:  0.690470, 0.316406 (1.440 sec)
16.430... logprob:  0.588682, 0.281250 (1.474 sec)
16.431... logprob:  0.805029, 0.320312 (1.463 sec)
16.432... logprob:  0.659521, 0.311198 (1.417 sec)
16.433... logprob:  0.550223, 0.286458 (1.430 sec)
16.434... logprob:  0.638652, 0.300781 (1.434 sec)
16.435... logprob:  0.707797, 0.312500 (1.434 sec)
16.436... logprob:  0.577422, 0.261719 (1.476 sec)
16.437... logprob:  0.793834, 0.346354 (1.434 sec)
16.438... logprob:  0.728376, 0.309896 (1.425 sec)
16.439... logprob:  0.683887, 0.328125 (1.483 sec)
16.440... logprob:  0.619697, 0.273438 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.507252, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.287123e-03 [2.148949e-07] 
Layer 'conv1' biases: 1.874503e-06 [3.335617e-10] 
Layer 'conv2' weights[0]: 4.279066e-03 [2.142252e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.396547e-09] 
Layer 'conv3' weights[0]: 4.277621e-03 [2.149510e-07] 
Layer 'conv3' biases: 3.077395e-05 [1.475835e-08] 
Layer 'conv4' weights[0]: 4.295497e-03 [2.166955e-07] 
Layer 'conv4' biases: 9.999928e-01 [2.698949e-07] 
Layer 'conv5' weights[0]: 4.395201e-03 [2.696053e-06] 
Layer 'conv5' biases: 9.990876e-01 [2.841107e-06] 
Layer 'fc6' weights[0]: 7.117113e-03 [6.541838e-08] 
Layer 'fc6' biases: 9.999934e-01 [6.250894e-08] 
Layer 'fc7' weights[0]: 7.468751e-03 [1.541261e-07] 
Layer 'fc7' biases: 9.998273e-01 [2.218416e-07] 
Layer 'fc8' weights[0]: 4.621175e-03 [1.718526e-05] 
Layer 'fc8' biases: 1.337630e-02 [3.209170e-05] 
Train error last 800 batches: 0.656499
-------------------------------------------------------
Not saving because 0.507252 > 0.299667 (9.300: -1.18%)
======================================================= (2.357 sec)
16.441... logprob:  0.620407, 0.240885 (1.444 sec)
16.442... logprob:  0.576699, 0.279948 (1.437 sec)
16.443... logprob:  0.696046, 0.298177 (1.434 sec)
16.444... logprob:  0.559477, 0.253906 (1.426 sec)
16.445... logprob:  0.707562, 0.311198 (1.479 sec)
16.446... logprob:  0.713417, 0.302083 (1.435 sec)
16.447... logprob:  0.765839, 0.292969 (1.434 sec)
16.448... logprob:  0.628402, 0.286458 (1.474 sec)
16.449... logprob:  0.637527, 0.289062 (1.426 sec)
16.450... logprob:  0.574449, 0.251302 (1.427 sec)
16.451... logprob:  0.638161, 0.282552 (1.433 sec)
16.452... logprob:  0.624495, 0.283854 (1.426 sec)
16.453... logprob:  0.686739, 0.316406 (1.429 sec)
16.454... logprob:  0.749481, 0.321615 (1.476 sec)
16.455... logprob:  0.632617, 0.289062 (1.438 sec)
16.456... logprob:  0.661386, 0.285156 (1.438 sec)
16.457... logprob:  0.586542, 0.257812 (1.469 sec)
16.458... logprob:  0.641204, 0.295573 (1.430 sec)
16.459... logprob:  0.637761, 0.292969 (1.436 sec)
16.460... logprob:  0.535007, 0.247396 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.363481, 0.062500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.282844e-03 [2.147283e-07] 
Layer 'conv1' biases: 1.876447e-06 [3.071765e-10] 
Layer 'conv2' weights[0]: 4.274822e-03 [2.141948e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.517434e-09] 
Layer 'conv3' weights[0]: 4.273386e-03 [2.147522e-07] 
Layer 'conv3' biases: 3.076075e-05 [1.456851e-08] 
Layer 'conv4' weights[0]: 4.291229e-03 [2.168842e-07] 
Layer 'conv4' biases: 9.999917e-01 [2.670853e-07] 
Layer 'conv5' weights[0]: 4.390510e-03 [2.980266e-06] 
Layer 'conv5' biases: 9.990948e-01 [3.228970e-06] 
Layer 'fc6' weights[0]: 7.116368e-03 [6.672044e-08] 
Layer 'fc6' biases: 9.999934e-01 [6.411961e-08] 
Layer 'fc7' weights[0]: 7.468029e-03 [1.555143e-07] 
Layer 'fc7' biases: 9.998267e-01 [2.361208e-07] 
Layer 'fc8' weights[0]: 4.610139e-03 [1.844848e-05] 
Layer 'fc8' biases: 1.330510e-02 [4.645528e-05] 
Train error last 800 batches: 0.656701
-------------------------------------------------------
Not saving because 0.363481 > 0.299667 (9.300: -1.18%)
======================================================= (2.419 sec)
16.461... logprob:  0.694863, 0.305990 (1.422 sec)
16.462... logprob:  0.645482, 0.294271 (1.432 sec)
16.463... logprob:  0.608802, 0.256510 (1.470 sec)
16.464... logprob:  0.722641, 0.279948 (1.442 sec)
16.465... logprob:  0.683850, 0.269531 (1.451 sec)
16.466... logprob:  0.566272, 0.255208 (1.456 sec)
16.467... logprob:  0.589590, 0.248698 (1.442 sec)
16.468... logprob:  0.601804, 0.265625 (1.432 sec)
16.469... logprob:  0.586862, 0.282552 (1.452 sec)
16.470... logprob:  0.589789, 0.259114 (1.425 sec)
16.471... logprob:  0.791673, 0.322917 (1.433 sec)
16.472... logprob:  0.670234, 0.276042 (1.450 sec)
16.473... logprob:  0.565534, 0.295573 (1.453 sec)
16.474... logprob:  0.657939, 0.311198 (1.448 sec)
16.475... logprob:  0.599389, 0.273437 (1.439 sec)
16.476... logprob:  0.684644, 0.295573 (1.462 sec)
16.477... logprob:  0.615436, 0.268229 (1.431 sec)
16.478... logprob:  0.824968, 0.350260 (1.418 sec)
16.479... logprob:  0.514166, 0.208333 (1.424 sec)
16.480... logprob:  0.677266, 0.264323 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.420688, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.278557e-03 [2.140304e-07] 
Layer 'conv1' biases: 1.877094e-06 [2.052930e-10] 
Layer 'conv2' weights[0]: 4.270527e-03 [2.136865e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.136855e-09] 
Layer 'conv3' weights[0]: 4.269102e-03 [2.143262e-07] 
Layer 'conv3' biases: 3.076781e-05 [1.422741e-08] 
Layer 'conv4' weights[0]: 4.286960e-03 [2.160233e-07] 
Layer 'conv4' biases: 9.999922e-01 [2.502318e-07] 
Layer 'conv5' weights[0]: 4.386661e-03 [2.557616e-06] 
Layer 'conv5' biases: 9.990911e-01 [2.700055e-06] 
Layer 'fc6' weights[0]: 7.115665e-03 [6.191034e-08] 
Layer 'fc6' biases: 9.999933e-01 [5.777887e-08] 
Layer 'fc7' weights[0]: 7.467246e-03 [1.416078e-07] 
Layer 'fc7' biases: 9.998270e-01 [1.738237e-07] 
Layer 'fc8' weights[0]: 4.631838e-03 [1.437118e-05] 
Layer 'fc8' biases: 1.345576e-02 [1.930488e-05] 
Train error last 800 batches: 0.656681
-------------------------------------------------------
Not saving because 0.420688 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
16.481... logprob:  0.852156, 0.322917 (1.431 sec)
16.482... logprob:  0.630570, 0.276042 (1.469 sec)
16.483... logprob:  0.774067, 0.317708 (1.443 sec)
16.484... logprob:  0.735131, 0.294271 (1.436 sec)
16.485... logprob:  0.615828, 0.278646 (1.479 sec)
16.486... logprob:  0.632691, 0.261719 (1.434 sec)
16.487... logprob:  0.704028, 0.302083 (1.421 sec)
16.488... logprob:  0.718219, 0.308594 (1.433 sec)
16.489... logprob:  0.666078, 0.294271 (1.431 sec)
16.490... logprob:  0.719468, 0.311198 (1.428 sec)
16.491... logprob:  0.562079, 0.246094 (1.473 sec)
16.492... logprob:  0.712956, 0.329427 (1.439 sec)
16.493... logprob:  0.717132, 0.324219 (1.434 sec)
16.494... logprob:  0.697822, 0.304687 (1.488 sec)
16.495... logprob:  0.635711, 0.281250 (1.431 sec)
16.496... logprob:  0.778757, 0.335937 (1.429 sec)
16.497... logprob:  0.576877, 0.243489 (1.434 sec)
16.498... logprob:  0.704454, 0.304688 (1.425 sec)
16.499... logprob:  0.690291, 0.302083 (1.427 sec)
16.500... logprob:  0.579413, 0.251302 (1.484 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.475745, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.274304e-03 [2.143285e-07] 
Layer 'conv1' biases: 1.878178e-06 [2.735358e-10] 
Layer 'conv2' weights[0]: 4.266256e-03 [2.136782e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.746963e-09] 
Layer 'conv3' weights[0]: 4.264855e-03 [2.143522e-07] 
Layer 'conv3' biases: 3.082967e-05 [1.535556e-08] 
Layer 'conv4' weights[0]: 4.282671e-03 [2.155494e-07] 
Layer 'conv4' biases: 9.999924e-01 [2.142685e-07] 
Layer 'conv5' weights[0]: 4.382310e-03 [2.269693e-06] 
Layer 'conv5' biases: 9.991234e-01 [2.327467e-06] 
Layer 'fc6' weights[0]: 7.114949e-03 [6.035060e-08] 
Layer 'fc6' biases: 9.999935e-01 [5.476325e-08] 
Layer 'fc7' weights[0]: 7.466502e-03 [1.375817e-07] 
Layer 'fc7' biases: 9.998250e-01 [1.642824e-07] 
Layer 'fc8' weights[0]: 4.556801e-03 [1.350551e-05] 
Layer 'fc8' biases: 1.281526e-02 [1.501321e-05] 
Train error last 800 batches: 0.657485
-------------------------------------------------------
Not saving because 0.475745 > 0.299667 (9.300: -1.18%)
======================================================= (2.377 sec)
16.501... logprob:  0.548865, 0.239583 (1.431 sec)
16.502... logprob:  0.697471, 0.292969 (1.447 sec)
16.503... logprob:  0.626883, 0.277344 (1.484 sec)
16.504... logprob:  0.700660, 0.316406 (1.428 sec)
16.505... logprob:  0.698514, 0.299479 (1.439 sec)
16.506... logprob:  0.740129, 0.303385 (1.427 sec)
16.507... logprob:  0.597650, 0.269531 (1.446 sec)
16.508... logprob:  0.621730, 0.274740 (1.422 sec)
16.509... logprob:  0.635208, 0.287760 (1.477 sec)
16.510... logprob:  0.642600, 0.272135 (1.433 sec)
16.511... logprob:  0.661526, 0.296875 (1.447 sec)
16.512... logprob:  0.678992, 0.291667 (1.463 sec)
16.513... logprob:  0.578505, 0.257812 (1.439 sec)
16.514... logprob:  0.580816, 0.238281 (1.430 sec)
16.515... logprob:  0.625559, 0.270833 (1.425 sec)
16.516... logprob:  0.668928, 0.279948 (1.418 sec)
16.517... logprob:  0.909259, 0.359375 (1.429 sec)
16.518... logprob:  0.641714, 0.286458 (1.454 sec)
16.519... logprob:  0.754664, 0.316406 (1.455 sec)
16.520... logprob:  0.663719, 0.279948 (1.446 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.471799, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.270029e-03 [2.141403e-07] 
Layer 'conv1' biases: 1.878539e-06 [2.731734e-10] 
Layer 'conv2' weights[0]: 4.261998e-03 [2.134691e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.256105e-09] 
Layer 'conv3' weights[0]: 4.260599e-03 [2.138621e-07] 
Layer 'conv3' biases: 3.085232e-05 [1.320449e-08] 
Layer 'conv4' weights[0]: 4.278395e-03 [2.158360e-07] 
Layer 'conv4' biases: 9.999913e-01 [2.671522e-07] 
Layer 'conv5' weights[0]: 4.378009e-03 [2.868589e-06] 
Layer 'conv5' biases: 9.990994e-01 [3.056970e-06] 
Layer 'fc6' weights[0]: 7.114224e-03 [6.659925e-08] 
Layer 'fc6' biases: 9.999934e-01 [6.386148e-08] 
Layer 'fc7' weights[0]: 7.465741e-03 [1.532673e-07] 
Layer 'fc7' biases: 9.998263e-01 [2.035127e-07] 
Layer 'fc8' weights[0]: 4.605215e-03 [1.570048e-05] 
Layer 'fc8' biases: 1.331356e-02 [2.186891e-05] 
Train error last 800 batches: 0.658139
-------------------------------------------------------
Not saving because 0.471799 > 0.299667 (9.300: -1.18%)
======================================================= (2.348 sec)
16.521... logprob:  0.671429, 0.256510 (1.451 sec)
16.522... logprob:  0.763382, 0.330729 (1.457 sec)
16.523... logprob:  0.556293, 0.229167 (1.437 sec)
16.524... logprob:  0.672336, 0.292969 (1.417 sec)
16.525... logprob:  0.629528, 0.243489 (1.425 sec)
16.526... logprob:  0.605968, 0.272135 (1.433 sec)
16.527... logprob:  0.678947, 0.313802 (1.437 sec)
16.528... logprob:  0.720474, 0.307292 (1.471 sec)
16.529... logprob:  0.576642, 0.250000 (1.449 sec)
16.530... logprob:  0.687294, 0.287760 (1.436 sec)
16.531... logprob:  0.618617, 0.291667 (1.479 sec)
16.532... logprob:  0.763825, 0.304688 (1.425 sec)
16.533... logprob:  0.733406, 0.330729 (1.418 sec)
16.534... logprob:  0.604161, 0.269531 (1.432 sec)
16.535... logprob:  0.721043, 0.299479 (1.428 sec)
16.536... logprob:  0.688868, 0.295573 (1.430 sec)
16.537... logprob:  0.678813, 0.281250 (1.476 sec)
16.538... logprob:  0.671715, 0.302083 (1.436 sec)
16.539... logprob:  0.506115, 0.239583 (1.427 sec)
16.540... logprob:  0.733826, 0.342448 (1.480 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.519094, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.265753e-03 [2.141894e-07] 
Layer 'conv1' biases: 1.879134e-06 [2.803455e-10] 
Layer 'conv2' weights[0]: 4.257743e-03 [2.134515e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.677919e-09] 
Layer 'conv3' weights[0]: 4.256352e-03 [2.141594e-07] 
Layer 'conv3' biases: 3.087932e-05 [1.654032e-08] 
Layer 'conv4' weights[0]: 4.274103e-03 [2.157997e-07] 
Layer 'conv4' biases: 9.999911e-01 [2.688705e-07] 
Layer 'conv5' weights[0]: 4.373895e-03 [2.164477e-06] 
Layer 'conv5' biases: 9.991007e-01 [2.299743e-06] 
Layer 'fc6' weights[0]: 7.113481e-03 [6.109067e-08] 
Layer 'fc6' biases: 9.999933e-01 [5.628933e-08] 
Layer 'fc7' weights[0]: 7.465014e-03 [1.365204e-07] 
Layer 'fc7' biases: 9.998252e-01 [1.650299e-07] 
Layer 'fc8' weights[0]: 4.577359e-03 [1.396953e-05] 
Layer 'fc8' biases: 1.316886e-02 [1.874204e-05] 
Train error last 800 batches: 0.658059
-------------------------------------------------------
Not saving because 0.519094 > 0.299667 (9.300: -1.18%)
======================================================= (2.367 sec)
16.541... logprob:  0.638349, 0.276042 (1.436 sec)
16.542... logprob:  0.675891, 0.312500 (1.436 sec)
16.543... logprob:  0.535286, 0.230469 (1.432 sec)
16.544... logprob:  0.591341, 0.265625 (1.423 sec)
16.545... logprob:  0.640169, 0.294271 (1.452 sec)
16.546... logprob:  0.541867, 0.269531 (1.480 sec)
16.547... logprob:  0.704620, 0.330729 (1.428 sec)
16.548... logprob:  0.628827, 0.286458 (1.435 sec)
16.549... logprob:  0.715583, 0.292969 (1.474 sec)
16.550... logprob:  0.652869, 0.283854 (1.423 sec)
16.551... logprob:  0.716153, 0.342448 (1.429 sec)
16.552... logprob:  0.618361, 0.282552 (1.429 sec)
16.553... logprob:  0.645915, 0.302083 (1.420 sec)
16.554... logprob:  0.737812, 0.325521 (1.427 sec)
16.555... logprob:  0.634347, 0.276042 (1.476 sec)
16.556... logprob:  0.579715, 0.273437 (1.433 sec)
16.557... logprob:  0.673724, 0.316406 (1.441 sec)
16.558... logprob:  0.653660, 0.283854 (1.467 sec)
16.559... logprob:  0.715712, 0.278646 (1.438 sec)
16.560... logprob:  0.484647, 0.209635 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.460842, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.261484e-03 [2.141170e-07] 
Layer 'conv1' biases: 1.879414e-06 [2.959128e-10] 
Layer 'conv2' weights[0]: 4.253483e-03 [2.131147e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.268649e-09] 
Layer 'conv3' weights[0]: 4.252070e-03 [2.137581e-07] 
Layer 'conv3' biases: 3.085685e-05 [1.438349e-08] 
Layer 'conv4' weights[0]: 4.269843e-03 [2.154350e-07] 
Layer 'conv4' biases: 9.999917e-01 [2.663643e-07] 
Layer 'conv5' weights[0]: 4.370321e-03 [2.348057e-06] 
Layer 'conv5' biases: 9.990731e-01 [2.492967e-06] 
Layer 'fc6' weights[0]: 7.112741e-03 [6.103215e-08] 
Layer 'fc6' biases: 9.999934e-01 [5.671240e-08] 
Layer 'fc7' weights[0]: 7.464244e-03 [1.378671e-07] 
Layer 'fc7' biases: 9.998265e-01 [1.730663e-07] 
Layer 'fc8' weights[0]: 4.652290e-03 [1.526640e-05] 
Layer 'fc8' biases: 1.369857e-02 [2.289016e-05] 
Train error last 800 batches: 0.657894
-------------------------------------------------------
Not saving because 0.460842 > 0.299667 (9.300: -1.18%)
======================================================= (2.368 sec)
16.561... logprob:  0.616701, 0.279948 (1.434 sec)
16.562... logprob:  0.665509, 0.287760 (1.435 sec)
16.563... logprob:  0.657074, 0.285156 (1.439 sec)
16.564... logprob:  0.670199, 0.290365 (1.458 sec)
16.565... logprob:  0.750594, 0.324219 (1.440 sec)
16.566... logprob:  0.617792, 0.264323 (1.450 sec)
16.567... logprob:  0.654409, 0.283854 (1.449 sec)
16.568... logprob:  0.748132, 0.319010 (1.451 sec)
16.569... logprob:  0.669917, 0.285156 (1.432 sec)
16.570... logprob:  0.723994, 0.322917 (1.418 sec)
16.571... logprob:  0.621331, 0.289062 (1.425 sec)
16.572... logprob:  0.737168, 0.304687 (1.438 sec)
16.573... logprob:  0.633083, 0.266927 (1.438 sec)
16.574... logprob:  0.630914, 0.268229 (1.455 sec)
16.575... logprob:  0.574866, 0.259115 (1.446 sec)
16.576... logprob:  0.643693, 0.303385 (1.442 sec)
16.577... logprob:  0.683181, 0.294271 (1.467 sec)
16.578... logprob:  0.643490, 0.292969 (1.428 sec)
16.579... logprob:  0.664068, 0.291667 (1.416 sec)
16.580... logprob:  0.737788, 0.328125 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.523517, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.257238e-03 [2.134884e-07] 
Layer 'conv1' biases: 1.881240e-06 [3.720301e-10] 
Layer 'conv2' weights[0]: 4.249256e-03 [2.128306e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.998469e-09] 
Layer 'conv3' weights[0]: 4.247873e-03 [2.133313e-07] 
Layer 'conv3' biases: 3.086885e-05 [1.362178e-08] 
Layer 'conv4' weights[0]: 4.265580e-03 [2.148176e-07] 
Layer 'conv4' biases: 9.999909e-01 [2.245501e-07] 
Layer 'conv5' weights[0]: 4.365993e-03 [2.335466e-06] 
Layer 'conv5' biases: 9.990909e-01 [2.447359e-06] 
Layer 'fc6' weights[0]: 7.112016e-03 [6.109419e-08] 
Layer 'fc6' biases: 9.999933e-01 [5.670325e-08] 
Layer 'fc7' weights[0]: 7.463536e-03 [1.410718e-07] 
Layer 'fc7' biases: 9.998251e-01 [1.752680e-07] 
Layer 'fc8' weights[0]: 4.607390e-03 [1.461259e-05] 
Layer 'fc8' biases: 1.332732e-02 [2.015145e-05] 
Train error last 800 batches: 0.657740
-------------------------------------------------------
Not saving because 0.523517 > 0.299667 (9.300: -1.18%)
======================================================= (2.416 sec)
16.581... logprob:  0.731852, 0.321615 (1.440 sec)
16.582... logprob:  0.613431, 0.300781 (1.435 sec)
16.583... logprob:  0.794436, 0.348958 (1.503 sec)
16.584... logprob:  0.734692, 0.328125 (1.436 sec)
16.585... logprob:  0.630507, 0.272135 (1.428 sec)
16.586... logprob:  0.537897, 0.247396 (1.481 sec)
16.587... logprob:  0.624533, 0.294271 (1.426 sec)
16.588... logprob:  0.684929, 0.311198 (1.423 sec)
16.589... logprob:  0.535262, 0.233073 (1.430 sec)
16.590... logprob:  0.802805, 0.348958 (1.423 sec)
16.591... logprob:  0.560154, 0.247396 (1.429 sec)
16.592... logprob:  0.735042, 0.286458 (1.477 sec)
16.593... logprob:  0.660878, 0.298177 (1.427 sec)
16.594... logprob:  0.634702, 0.255208 (1.439 sec)
16.595... logprob:  0.656077, 0.300781 (1.476 sec)
16.596... logprob:  0.691161, 0.324219 (1.431 sec)
16.597... logprob:  0.616457, 0.289062 (1.431 sec)
16.598... logprob:  0.580736, 0.257812 (1.430 sec)
16.599... logprob:  0.601991, 0.270833 (1.423 sec)
16.600... logprob:  0.616714, 0.282552 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.391567, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.252964e-03 [2.132793e-07] 
Layer 'conv1' biases: 1.881445e-06 [3.428135e-10] 
Layer 'conv2' weights[0]: 4.244984e-03 [2.127032e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.972682e-09] 
Layer 'conv3' weights[0]: 4.243585e-03 [2.134777e-07] 
Layer 'conv3' biases: 3.083152e-05 [1.509563e-08] 
Layer 'conv4' weights[0]: 4.261322e-03 [2.150513e-07] 
Layer 'conv4' biases: 9.999912e-01 [2.671208e-07] 
Layer 'conv5' weights[0]: 4.362293e-03 [2.417433e-06] 
Layer 'conv5' biases: 9.990791e-01 [2.593088e-06] 
Layer 'fc6' weights[0]: 7.111237e-03 [6.290004e-08] 
Layer 'fc6' biases: 9.999935e-01 [5.900788e-08] 
Layer 'fc7' weights[0]: 7.462730e-03 [1.446937e-07] 
Layer 'fc7' biases: 9.998257e-01 [2.004450e-07] 
Layer 'fc8' weights[0]: 4.640615e-03 [1.577985e-05] 
Layer 'fc8' biases: 1.356000e-02 [2.567500e-05] 
Train error last 800 batches: 0.658089
-------------------------------------------------------
Not saving because 0.391567 > 0.299667 (9.300: -1.18%)
======================================================= (2.352 sec)
16.601... logprob:  0.620399, 0.286458 (1.487 sec)
16.602... logprob:  0.525896, 0.231771 (1.435 sec)
16.603... logprob:  0.529041, 0.252604 (1.440 sec)
16.604... logprob:  0.676182, 0.304688 (1.467 sec)
16.605... logprob:  0.739779, 0.300781 (1.431 sec)
16.606... logprob:  0.535190, 0.261719 (1.438 sec)
16.607... logprob:  0.675905, 0.272135 (1.433 sec)
16.608... logprob:  0.598468, 0.269531 (1.417 sec)
16.609... logprob:  0.632936, 0.290365 (1.432 sec)
16.610... logprob:  0.726449, 0.326823 (1.462 sec)
16.611... logprob:  0.707846, 0.285156 (1.442 sec)
16.612... logprob:  0.665352, 0.304687 (1.447 sec)
16.613... logprob:  0.503549, 0.242188 (1.463 sec)
16.614... logprob:  0.730105, 0.283854 (1.443 sec)
16.615... logprob:  0.583958, 0.279948 (1.438 sec)
16.616... logprob:  0.689002, 0.292969 (1.419 sec)
16.617... logprob:  0.687891, 0.290365 (1.422 sec)
16.618... logprob:  0.697873, 0.289062 (1.435 sec)
16.619... logprob:  0.776398, 0.332031 (1.452 sec)
16.620... logprob:  0.685904, 0.311198 (1.449 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.496350, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.248728e-03 [2.130932e-07] 
Layer 'conv1' biases: 1.882225e-06 [4.174644e-10] 
Layer 'conv2' weights[0]: 4.240733e-03 [2.125536e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.187154e-09] 
Layer 'conv3' weights[0]: 4.239352e-03 [2.149721e-07] 
Layer 'conv3' biases: 3.086297e-05 [2.462659e-08] 
Layer 'conv4' weights[0]: 4.257048e-03 [2.178742e-07] 
Layer 'conv4' biases: 9.999913e-01 [4.730105e-07] 
Layer 'conv5' weights[0]: 4.357999e-03 [3.815626e-06] 
Layer 'conv5' biases: 9.990726e-01 [4.169419e-06] 
Layer 'fc6' weights[0]: 7.110520e-03 [7.694560e-08] 
Layer 'fc6' biases: 9.999936e-01 [7.873054e-08] 
Layer 'fc7' weights[0]: 7.461958e-03 [1.928778e-07] 
Layer 'fc7' biases: 9.998261e-01 [3.358432e-07] 
Layer 'fc8' weights[0]: 4.644101e-03 [2.238319e-05] 
Layer 'fc8' biases: 1.367498e-02 [5.623521e-05] 
Train error last 800 batches: 0.658162
-------------------------------------------------------
Not saving because 0.496350 > 0.299667 (9.300: -1.18%)
======================================================= (2.365 sec)
16.621... logprob:  0.584681, 0.242187 (1.451 sec)
16.622... logprob:  0.548565, 0.239583 (1.446 sec)
16.623... logprob:  0.624581, 0.272135 (1.461 sec)
16.624... logprob:  0.585436, 0.273438 (1.433 sec)
16.625... logprob:  0.719327, 0.324219 (1.419 sec)
16.626... logprob:  0.651257, 0.278646 (1.428 sec)
16.627... logprob:  0.742861, 0.300781 (1.437 sec)
16.628... logprob:  0.623855, 0.266927 (1.433 sec)
16.629... logprob:  0.690161, 0.325521 (1.479 sec)
16.630... logprob:  0.617090, 0.276042 (1.445 sec)
16.631... logprob:  0.718443, 0.332031 (1.437 sec)
16.632... logprob:  0.714340, 0.274740 (1.480 sec)
16.633... logprob:  0.546541, 0.221354 (1.428 sec)
16.634... logprob:  0.753188, 0.333333 (1.421 sec)
16.635... logprob:  0.569243, 0.243489 (1.431 sec)
16.636... logprob:  0.791692, 0.341146 (1.425 sec)
16.637... logprob:  0.604421, 0.279948 (1.429 sec)
16.638... logprob:  0.735856, 0.313802 (1.471 sec)
16.639... logprob:  0.720877, 0.332031 (1.435 sec)
16.640... logprob:  0.647796, 0.295573 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.479134, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.244485e-03 [2.130152e-07] 
Layer 'conv1' biases: 1.884048e-06 [2.779854e-10] 
Layer 'conv2' weights[0]: 4.236491e-03 [2.123640e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.617287e-09] 
Layer 'conv3' weights[0]: 4.235100e-03 [2.131257e-07] 
Layer 'conv3' biases: 3.090381e-05 [1.544124e-08] 
Layer 'conv4' weights[0]: 4.252821e-03 [2.148987e-07] 
Layer 'conv4' biases: 9.999886e-01 [2.757380e-07] 
Layer 'conv5' weights[0]: 4.352559e-03 [2.220664e-06] 
Layer 'conv5' biases: 9.990955e-01 [2.380686e-06] 
Layer 'fc6' weights[0]: 7.109731e-03 [6.131713e-08] 
Layer 'fc6' biases: 9.999936e-01 [5.680365e-08] 
Layer 'fc7' weights[0]: 7.461221e-03 [1.384547e-07] 
Layer 'fc7' biases: 9.998237e-01 [1.677314e-07] 
Layer 'fc8' weights[0]: 4.569871e-03 [1.382347e-05] 
Layer 'fc8' biases: 1.314212e-02 [1.715477e-05] 
Train error last 800 batches: 0.658414
-------------------------------------------------------
Not saving because 0.479134 > 0.299667 (9.300: -1.18%)
======================================================= (2.394 sec)
16.641... logprob:  0.707733, 0.291667 (1.483 sec)
16.642... logprob:  0.685826, 0.305990 (1.436 sec)
16.643... logprob:  0.805762, 0.345052 (1.433 sec)
16.644... logprob:  0.600347, 0.261719 (1.436 sec)
16.645... logprob:  0.618178, 0.259115 (1.423 sec)
16.646... logprob:  0.602721, 0.276042 (1.423 sec)
16.647... logprob:  0.690456, 0.296875 (1.486 sec)
16.648... logprob:  0.661023, 0.281250 (1.437 sec)
16.649... logprob:  0.645815, 0.285156 (1.446 sec)
16.650... logprob:  0.676188, 0.263021 (1.473 sec)
16.651... logprob:  0.568197, 0.246094 (1.427 sec)
16.652... logprob:  0.665070, 0.295573 (1.434 sec)
16.653... logprob:  0.701551, 0.287760 (1.435 sec)
16.654... logprob:  0.680862, 0.283854 (1.421 sec)
16.655... logprob:  0.692287, 0.317708 (1.434 sec)
16.656... logprob:  0.680394, 0.302083 (1.479 sec)
16.657... logprob:  0.693797, 0.302083 (1.434 sec)
16.658... logprob:  0.669863, 0.289063 (1.447 sec)
16.659... logprob:  0.642894, 0.296875 (1.476 sec)
16.660... logprob:  0.734799, 0.311198 (1.443 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.554181, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.240237e-03 [2.125786e-07] 
Layer 'conv1' biases: 1.885295e-06 [3.254120e-10] 
Layer 'conv2' weights[0]: 4.232281e-03 [2.121345e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.760273e-09] 
Layer 'conv3' weights[0]: 4.230859e-03 [2.129128e-07] 
Layer 'conv3' biases: 3.090586e-05 [1.481026e-08] 
Layer 'conv4' weights[0]: 4.248542e-03 [2.146989e-07] 
Layer 'conv4' biases: 9.999858e-01 [2.432892e-07] 
Layer 'conv5' weights[0]: 4.347336e-03 [2.529080e-06] 
Layer 'conv5' biases: 9.990921e-01 [2.703027e-06] 
Layer 'fc6' weights[0]: 7.108988e-03 [6.194188e-08] 
Layer 'fc6' biases: 9.999937e-01 [5.735572e-08] 
Layer 'fc7' weights[0]: 7.460511e-03 [1.417096e-07] 
Layer 'fc7' biases: 9.998239e-01 [1.707614e-07] 
Layer 'fc8' weights[0]: 4.576777e-03 [1.437104e-05] 
Layer 'fc8' biases: 1.310213e-02 [1.632429e-05] 
Train error last 800 batches: 0.658574
-------------------------------------------------------
Not saving because 0.554181 > 0.299667 (9.300: -1.18%)
======================================================= (2.400 sec)
16.661... logprob:  0.605760, 0.246094 (1.437 sec)
16.662... logprob:  0.696449, 0.333333 (1.424 sec)
16.663... logprob:  0.572815, 0.255208 (1.417 sec)
16.664... logprob:  0.525327, 0.227865 (1.435 sec)
16.665... logprob:  0.702323, 0.324219 (1.451 sec)
16.666... logprob:  0.682155, 0.285156 (1.448 sec)
16.667... logprob:  0.680128, 0.316406 (1.450 sec)
16.668... logprob:  0.750709, 0.312500 (1.443 sec)
16.669... logprob:  0.711708, 0.307292 (1.458 sec)
16.670... logprob:  0.544602, 0.242187 (1.437 sec)
16.671... logprob:  0.520648, 0.223958 (1.421 sec)
16.672... logprob:  0.715589, 0.308594 (1.431 sec)
16.673... logprob:  0.641875, 0.278646 (1.433 sec)
16.674... logprob:  0.647742, 0.263021 (1.434 sec)
16.675... logprob:  0.583702, 0.250000 (1.461 sec)
16.676... logprob:  0.670894, 0.282552 (1.444 sec)
16.677... logprob:  0.700785, 0.286458 (1.437 sec)
16.678... logprob:  0.707736, 0.326823 (1.472 sec)
16.679... logprob:  0.707775, 0.321615 (1.425 sec)
16.680... logprob:  0.619380, 0.263021 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.419524, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.236001e-03 [2.121757e-07] 
Layer 'conv1' biases: 1.885710e-06 [2.564903e-10] 
Layer 'conv2' weights[0]: 4.228037e-03 [2.118978e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.257500e-09] 
Layer 'conv3' weights[0]: 4.226621e-03 [2.122357e-07] 
Layer 'conv3' biases: 3.087778e-05 [1.277494e-08] 
Layer 'conv4' weights[0]: 4.244294e-03 [2.136664e-07] 
Layer 'conv4' biases: 9.999833e-01 [2.070591e-07] 
Layer 'conv5' weights[0]: 4.342060e-03 [2.257140e-06] 
Layer 'conv5' biases: 9.990744e-01 [2.354949e-06] 
Layer 'fc6' weights[0]: 7.108257e-03 [6.158622e-08] 
Layer 'fc6' biases: 9.999937e-01 [5.778405e-08] 
Layer 'fc7' weights[0]: 7.459746e-03 [1.408119e-07] 
Layer 'fc7' biases: 9.998255e-01 [1.721941e-07] 
Layer 'fc8' weights[0]: 4.626012e-03 [1.502922e-05] 
Layer 'fc8' biases: 1.350701e-02 [1.743446e-05] 
Train error last 800 batches: 0.658632
-------------------------------------------------------
Not saving because 0.419524 > 0.299667 (9.300: -1.18%)
======================================================= (2.363 sec)
16.681... logprob:  0.613502, 0.294271 (1.431 sec)
16.682... logprob:  0.543239, 0.253906 (1.431 sec)
16.683... logprob:  0.667811, 0.239583 (1.425 sec)
16.684... logprob:  0.592964, 0.268229 (1.472 sec)
16.685... logprob:  0.503070, 0.218750 (1.438 sec)
16.686... logprob:  0.550666, 0.226562 (1.427 sec)
16.687... logprob:  0.535468, 0.261719 (1.486 sec)
16.688... logprob:  0.614414, 0.278646 (1.425 sec)
16.689... logprob:  0.669662, 0.294271 (1.425 sec)
16.690... logprob:  0.817993, 0.325521 (1.433 sec)
16.691... logprob:  0.765973, 0.334635 (1.431 sec)
16.692... logprob:  0.604358, 0.276042 (1.434 sec)
16.693... logprob:  0.591128, 0.282552 (1.477 sec)
16.694... logprob:  0.592058, 0.257812 (1.430 sec)
16.695... logprob:  0.665453, 0.308594 (1.435 sec)
16.696... logprob:  0.751471, 0.291667 (1.470 sec)
16.697... logprob:  0.694862, 0.292969 (1.430 sec)
16.698... logprob:  0.843650, 0.341146 (1.433 sec)
16.699... logprob:  0.627102, 0.283854 (1.454 sec)
16.700... logprob:  0.640494, 0.270833 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.370970, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.231756e-03 [2.120206e-07] 
Layer 'conv1' biases: 1.885919e-06 [3.910623e-10] 
Layer 'conv2' weights[0]: 4.223814e-03 [2.115897e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.584295e-09] 
Layer 'conv3' weights[0]: 4.222394e-03 [2.133748e-07] 
Layer 'conv3' biases: 3.087848e-05 [2.345907e-08] 
Layer 'conv4' weights[0]: 4.240056e-03 [2.155619e-07] 
Layer 'conv4' biases: 9.999830e-01 [4.040642e-07] 
Layer 'conv5' weights[0]: 4.337541e-03 [3.641808e-06] 
Layer 'conv5' biases: 9.990726e-01 [3.923768e-06] 
Layer 'fc6' weights[0]: 7.107512e-03 [7.798565e-08] 
Layer 'fc6' biases: 9.999936e-01 [8.065897e-08] 
Layer 'fc7' weights[0]: 7.458973e-03 [1.870516e-07] 
Layer 'fc7' biases: 9.998247e-01 [3.167570e-07] 
Layer 'fc8' weights[0]: 4.610525e-03 [2.123167e-05] 
Layer 'fc8' biases: 1.347393e-02 [4.741135e-05] 
Train error last 800 batches: 0.658741
-------------------------------------------------------
Not saving because 0.370970 > 0.299667 (9.300: -1.18%)
======================================================= (2.351 sec)
16.701... logprob:  0.672551, 0.302083 (1.438 sec)
16.702... logprob:  0.731228, 0.321615 (1.484 sec)
16.703... logprob:  0.503635, 0.229167 (1.435 sec)
16.704... logprob:  0.577654, 0.270833 (1.445 sec)
16.705... logprob:  0.624065, 0.279948 (1.473 sec)
16.706... logprob:  0.650974, 0.285156 (1.430 sec)
16.707... logprob:  0.658964, 0.263021 (1.429 sec)
16.708... logprob:  0.630070, 0.289062 (1.427 sec)
16.709... logprob:  0.663303, 0.273437 (1.417 sec)
16.710... logprob:  0.710620, 0.287760 (1.435 sec)
16.711... logprob:  0.568617, 0.238281 (1.463 sec)
16.712... logprob:  0.542132, 0.255208 (1.444 sec)
16.713... logprob:  0.819328, 0.350260 (1.447 sec)
16.714... logprob:  0.673482, 0.295573 (1.460 sec)
16.715... logprob:  0.629541, 0.252604 (1.446 sec)
16.716... logprob:  0.595946, 0.266927 (1.435 sec)
16.717... logprob:  0.694212, 0.326823 (1.423 sec)
16.718... logprob:  0.637277, 0.278646 (1.424 sec)
16.719... logprob:  0.663494, 0.283854 (1.434 sec)
16.720... logprob:  0.663693, 0.263021 (1.439 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.475459, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.227538e-03 [2.120482e-07] 
Layer 'conv1' biases: 1.887624e-06 [2.574002e-10] 
Layer 'conv2' weights[0]: 4.219592e-03 [2.112923e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.382185e-09] 
Layer 'conv3' weights[0]: 4.218170e-03 [2.118973e-07] 
Layer 'conv3' biases: 3.092774e-05 [1.441889e-08] 
Layer 'conv4' weights[0]: 4.235811e-03 [2.136974e-07] 
Layer 'conv4' biases: 9.999811e-01 [2.333817e-07] 
Layer 'conv5' weights[0]: 4.332479e-03 [2.575038e-06] 
Layer 'conv5' biases: 9.990882e-01 [2.680822e-06] 
Layer 'fc6' weights[0]: 7.106788e-03 [6.374208e-08] 
Layer 'fc6' biases: 9.999937e-01 [6.069513e-08] 
Layer 'fc7' weights[0]: 7.458247e-03 [1.461734e-07] 
Layer 'fc7' biases: 9.998233e-01 [1.899762e-07] 
Layer 'fc8' weights[0]: 4.584636e-03 [1.649371e-05] 
Layer 'fc8' biases: 1.330979e-02 [2.925429e-05] 
Train error last 800 batches: 0.658111
-------------------------------------------------------
Not saving because 0.475459 > 0.299667 (9.300: -1.18%)
======================================================= (2.353 sec)
16.721... logprob:  0.623810, 0.277344 (1.463 sec)
16.722... logprob:  0.653952, 0.281250 (1.456 sec)
16.723... logprob:  0.612039, 0.256510 (1.444 sec)
16.724... logprob:  0.605401, 0.268229 (1.466 sec)
16.725... logprob:  0.625192, 0.290365 (1.425 sec)
16.726... logprob:  0.624511, 0.281250 (1.422 sec)
16.727... logprob:  0.731784, 0.335938 (1.425 sec)
16.728... logprob:  0.659201, 0.298177 (1.433 sec)
16.729... logprob:  0.682241, 0.296875 (1.427 sec)
16.730... logprob:  0.836653, 0.363281 (1.469 sec)
16.731... logprob:  0.682979, 0.287760 (1.439 sec)
16.732... logprob:  0.541143, 0.229167 (1.437 sec)
16.733... logprob:  0.786973, 0.346354 (1.480 sec)
16.734... logprob:  0.616546, 0.295573 (1.426 sec)
16.735... logprob:  0.673281, 0.278646 (1.424 sec)
16.736... logprob:  0.786306, 0.330729 (1.432 sec)
16.737... logprob:  0.731409, 0.324219 (1.453 sec)
16.738... logprob:  0.696522, 0.305990 (1.424 sec)
16.739... logprob:  0.602809, 0.273437 (1.480 sec)
16.740... logprob:  0.600995, 0.281250 (1.434 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.506240, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.223313e-03 [2.117182e-07] 
Layer 'conv1' biases: 1.889671e-06 [2.911273e-10] 
Layer 'conv2' weights[0]: 4.215393e-03 [2.110187e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.517134e-09] 
Layer 'conv3' weights[0]: 4.213940e-03 [2.114988e-07] 
Layer 'conv3' biases: 3.098002e-05 [1.395824e-08] 
Layer 'conv4' weights[0]: 4.231577e-03 [2.131678e-07] 
Layer 'conv4' biases: 9.999799e-01 [2.589956e-07] 
Layer 'conv5' weights[0]: 4.327796e-03 [2.414251e-06] 
Layer 'conv5' biases: 9.990987e-01 [2.611309e-06] 
Layer 'fc6' weights[0]: 7.106059e-03 [5.874485e-08] 
Layer 'fc6' biases: 9.999934e-01 [5.314726e-08] 
Layer 'fc7' weights[0]: 7.457497e-03 [1.320561e-07] 
Layer 'fc7' biases: 9.998222e-01 [1.469216e-07] 
Layer 'fc8' weights[0]: 4.576171e-03 [1.280358e-05] 
Layer 'fc8' biases: 1.320375e-02 [7.191378e-06] 
Train error last 800 batches: 0.657850
-------------------------------------------------------
Not saving because 0.506240 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
16.741... logprob:  0.586118, 0.229167 (1.438 sec)
16.742... logprob:  0.752926, 0.308594 (1.483 sec)
16.743... logprob:  0.612987, 0.289062 (1.434 sec)
16.744... logprob:  0.722279, 0.304688 (1.434 sec)
16.745... logprob:  0.688794, 0.296875 (1.437 sec)
16.746... logprob:  0.608193, 0.260417 (1.424 sec)
16.747... logprob:  0.661213, 0.302083 (1.433 sec)
16.748... logprob:  0.641845, 0.282552 (1.480 sec)
16.749... logprob:  0.671316, 0.287760 (1.426 sec)
16.750... logprob:  0.790134, 0.346354 (1.441 sec)
16.751... logprob:  0.524240, 0.235677 (1.470 sec)
16.752... logprob:  0.674086, 0.311198 (1.433 sec)
16.753... logprob:  0.586766, 0.263021 (1.431 sec)
16.754... logprob:  0.704359, 0.285156 (1.426 sec)
16.755... logprob:  0.650719, 0.281250 (1.424 sec)
16.756... logprob:  0.664395, 0.286458 (1.434 sec)
16.757... logprob:  0.763546, 0.313802 (1.467 sec)
16.758... logprob:  0.662719, 0.277344 (1.438 sec)
16.759... logprob:  0.697296, 0.291667 (1.447 sec)
16.760... logprob:  0.659859, 0.300781 (1.453 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.560684, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.219081e-03 [2.113953e-07] 
Layer 'conv1' biases: 1.891946e-06 [2.566907e-10] 
Layer 'conv2' weights[0]: 4.211164e-03 [2.109726e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.204175e-09] 
Layer 'conv3' weights[0]: 4.209719e-03 [2.117004e-07] 
Layer 'conv3' biases: 3.104276e-05 [1.500607e-08] 
Layer 'conv4' weights[0]: 4.227352e-03 [2.131009e-07] 
Layer 'conv4' biases: 9.999793e-01 [2.514470e-07] 
Layer 'conv5' weights[0]: 4.323643e-03 [2.245188e-06] 
Layer 'conv5' biases: 9.990978e-01 [2.404777e-06] 
Layer 'fc6' weights[0]: 7.105318e-03 [6.150915e-08] 
Layer 'fc6' biases: 9.999934e-01 [5.704327e-08] 
Layer 'fc7' weights[0]: 7.456736e-03 [1.389015e-07] 
Layer 'fc7' biases: 9.998221e-01 [1.639526e-07] 
Layer 'fc8' weights[0]: 4.580004e-03 [1.399803e-05] 
Layer 'fc8' biases: 1.325598e-02 [1.321932e-05] 
Train error last 800 batches: 0.658050
-------------------------------------------------------
Not saving because 0.560684 > 0.299667 (9.300: -1.18%)
======================================================= (2.413 sec)
16.761... logprob:  0.606665, 0.256510 (1.450 sec)
16.762... logprob:  0.673878, 0.313802 (1.437 sec)
16.763... logprob:  0.667282, 0.294271 (1.424 sec)
16.764... logprob:  0.780891, 0.322917 (1.425 sec)
16.765... logprob:  0.551404, 0.253906 (1.433 sec)
16.766... logprob:  0.662914, 0.261719 (1.446 sec)
16.767... logprob:  0.581747, 0.261719 (1.451 sec)
16.768... logprob:  0.710397, 0.299479 (1.455 sec)
16.769... logprob:  0.726981, 0.360677 (1.474 sec)
16.770... logprob:  0.543372, 0.222656 (1.481 sec)
16.771... logprob:  0.727016, 0.304687 (1.457 sec)
16.772... logprob:  0.627288, 0.260417 (1.438 sec)
16.773... logprob:  0.698833, 0.290365 (1.443 sec)
16.774... logprob:  0.660212, 0.298177 (1.460 sec)
16.775... logprob:  0.633749, 0.278646 (1.493 sec)
16.776... logprob:  0.612280, 0.253906 (1.476 sec)
16.777... logprob:  0.558446, 0.255208 (1.466 sec)
16.778... logprob:  0.691343, 0.309896 (1.457 sec)
16.779... logprob:  0.705289, 0.316406 (1.481 sec)
16.780... logprob:  0.644061, 0.282552 (1.449 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.441146, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.214879e-03 [2.110424e-07] 
Layer 'conv1' biases: 1.891398e-06 [2.954832e-10] 
Layer 'conv2' weights[0]: 4.206948e-03 [2.106727e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.089195e-09] 
Layer 'conv3' weights[0]: 4.205502e-03 [2.110705e-07] 
Layer 'conv3' biases: 3.108718e-05 [1.141808e-08] 
Layer 'conv4' weights[0]: 4.223105e-03 [2.126715e-07] 
Layer 'conv4' biases: 9.999795e-01 [2.071399e-07] 
Layer 'conv5' weights[0]: 4.319315e-03 [2.292780e-06] 
Layer 'conv5' biases: 9.990923e-01 [2.447614e-06] 
Layer 'fc6' weights[0]: 7.104556e-03 [5.929852e-08] 
Layer 'fc6' biases: 9.999934e-01 [5.394357e-08] 
Layer 'fc7' weights[0]: 7.455943e-03 [1.351520e-07] 
Layer 'fc7' biases: 9.998224e-01 [1.595599e-07] 
Layer 'fc8' weights[0]: 4.593485e-03 [1.394566e-05] 
Layer 'fc8' biases: 1.335397e-02 [1.255535e-05] 
Train error last 800 batches: 0.657936
-------------------------------------------------------
Not saving because 0.441146 > 0.299667 (9.300: -1.18%)
======================================================= (2.385 sec)
16.781... logprob:  0.637483, 0.277344 (1.449 sec)
16.782... logprob:  0.638938, 0.321615 (1.448 sec)
16.783... logprob:  0.720960, 0.319010 (1.459 sec)
16.784... logprob:  0.664127, 0.282552 (1.451 sec)
16.785... logprob:  0.773048, 0.324219 (1.477 sec)
16.786... logprob:  0.661273, 0.282552 (1.465 sec)
16.787... logprob:  0.628464, 0.305990 (1.452 sec)
16.788... logprob:  0.679134, 0.298177 (1.488 sec)
16.789... logprob:  0.565269, 0.264323 (1.446 sec)
16.790... logprob:  0.602416, 0.278646 (1.441 sec)
16.791... logprob:  0.589669, 0.239583 (1.439 sec)
16.792... logprob:  0.643186, 0.260417 (1.459 sec)
16.793... logprob:  0.610403, 0.260417 (1.455 sec)
16.794... logprob:  0.675145, 0.292969 (1.480 sec)
16.795... logprob:  0.665462, 0.302083 (1.477 sec)
16.796... logprob:  0.661582, 0.295573 (1.452 sec)
16.797... logprob:  0.664241, 0.311198 (1.491 sec)
16.798... logprob:  0.579889, 0.256510 (1.446 sec)
16.799... logprob:  0.543720, 0.236979 (1.439 sec)
16.800... logprob:  0.623122, 0.286458 (1.396 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.512524, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.210652e-03 [2.112614e-07] 
Layer 'conv1' biases: 1.891763e-06 [3.830900e-10] 
Layer 'conv2' weights[0]: 4.202755e-03 [2.107648e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.316268e-09] 
Layer 'conv3' weights[0]: 4.201318e-03 [2.116144e-07] 
Layer 'conv3' biases: 3.112407e-05 [1.651103e-08] 
Layer 'conv4' weights[0]: 4.218917e-03 [2.138642e-07] 
Layer 'conv4' biases: 9.999787e-01 [3.019266e-07] 
Layer 'conv5' weights[0]: 4.315109e-03 [3.124544e-06] 
Layer 'conv5' biases: 9.990780e-01 [3.485677e-06] 
Layer 'fc6' weights[0]: 7.103813e-03 [6.857853e-08] 
Layer 'fc6' biases: 9.999934e-01 [6.689837e-08] 
Layer 'fc7' weights[0]: 7.455196e-03 [1.627886e-07] 
Layer 'fc7' biases: 9.998234e-01 [2.661102e-07] 
Layer 'fc8' weights[0]: 4.632674e-03 [1.842098e-05] 
Layer 'fc8' biases: 1.369592e-02 [4.760709e-05] 
Train error last 800 batches: 0.657849
-------------------------------------------------------
Not saving because 0.512524 > 0.299667 (9.300: -1.18%)
======================================================= (2.358 sec)
17.1... logprob:  0.688781, 0.307292 (1.411 sec)
17.2... logprob:  0.649702, 0.270833 (1.447 sec)
17.3... logprob:  0.664494, 0.279948 (1.412 sec)
17.4... logprob:  0.686627, 0.295573 (1.402 sec)
17.5... logprob:  0.689921, 0.274739 (1.425 sec)
17.6... logprob:  0.742077, 0.326823 (1.389 sec)
17.7... logprob:  0.606939, 0.277344 (1.420 sec)
17.8... logprob:  0.672678, 0.292969 (1.392 sec)
17.9... logprob:  0.640305, 0.298177 (1.399 sec)
17.10... logprob:  0.633646, 0.274740 (1.402 sec)
17.11... logprob:  0.543553, 0.244792 (1.444 sec)
17.12... logprob:  0.648965, 0.286458 (1.392 sec)
17.13... logprob:  0.623466, 0.294271 (1.442 sec)
17.14... logprob:  0.623845, 0.269531 (1.395 sec)
17.15... logprob:  0.533661, 0.225260 (1.407 sec)
17.16... logprob:  0.617602, 0.309896 (1.401 sec)
17.17... logprob:  0.733193, 0.296875 (1.387 sec)
17.18... logprob:  0.486029, 0.214844 (1.392 sec)
17.19... logprob:  0.522419, 0.238281 (1.398 sec)
17.20... logprob:  0.794775, 0.330729 (1.398 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.479462, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.206461e-03 [2.108745e-07] 
Layer 'conv1' biases: 1.893090e-06 [2.396287e-10] 
Layer 'conv2' weights[0]: 4.198529e-03 [2.104663e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.653615e-09] 
Layer 'conv3' weights[0]: 4.197160e-03 [2.110762e-07] 
Layer 'conv3' biases: 3.116021e-05 [1.454501e-08] 
Layer 'conv4' weights[0]: 4.214664e-03 [2.125080e-07] 
Layer 'conv4' biases: 9.999774e-01 [2.481445e-07] 
Layer 'conv5' weights[0]: 4.310326e-03 [2.376372e-06] 
Layer 'conv5' biases: 9.990712e-01 [2.496173e-06] 
Layer 'fc6' weights[0]: 7.103112e-03 [6.034800e-08] 
Layer 'fc6' biases: 9.999934e-01 [5.580011e-08] 
Layer 'fc7' weights[0]: 7.454431e-03 [1.377143e-07] 
Layer 'fc7' biases: 9.998237e-01 [1.704904e-07] 
Layer 'fc8' weights[0]: 4.661857e-03 [1.447359e-05] 
Layer 'fc8' biases: 1.390982e-02 [2.352257e-05] 
Train error last 800 batches: 0.657963
-------------------------------------------------------
Not saving because 0.479462 > 0.299667 (9.300: -1.18%)
======================================================= (2.421 sec)
17.21... logprob:  0.685504, 0.308594 (1.407 sec)
17.22... logprob:  0.637211, 0.283854 (1.414 sec)
17.23... logprob:  0.758260, 0.330729 (1.411 sec)
17.24... logprob:  0.534336, 0.247396 (1.425 sec)
17.25... logprob:  0.582459, 0.261719 (1.398 sec)
17.26... logprob:  0.716294, 0.299479 (1.445 sec)
17.27... logprob:  0.642101, 0.264323 (1.387 sec)
17.28... logprob:  0.610526, 0.292969 (1.409 sec)
17.29... logprob:  0.666376, 0.282552 (1.419 sec)
17.30... logprob:  0.543987, 0.246094 (1.410 sec)
17.31... logprob:  0.670821, 0.289062 (1.397 sec)
17.32... logprob:  0.702762, 0.325521 (1.385 sec)
17.33... logprob:  0.729408, 0.312500 (1.446 sec)
17.34... logprob:  0.714640, 0.287760 (1.391 sec)
17.35... logprob:  0.571388, 0.240885 (1.397 sec)
17.36... logprob:  0.783824, 0.332031 (1.400 sec)
17.37... logprob:  0.647052, 0.286458 (1.405 sec)
17.38... logprob:  0.591833, 0.251302 (1.387 sec)
17.39... logprob:  0.825621, 0.367187 (1.427 sec)
17.40... logprob:  0.605702, 0.244792 (1.402 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.518622, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.202246e-03 [2.104921e-07] 
Layer 'conv1' biases: 1.893557e-06 [3.741391e-10] 
Layer 'conv2' weights[0]: 4.194347e-03 [2.101394e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.489550e-09] 
Layer 'conv3' weights[0]: 4.192908e-03 [2.115312e-07] 
Layer 'conv3' biases: 3.116598e-05 [1.867500e-08] 
Layer 'conv4' weights[0]: 4.210466e-03 [2.136171e-07] 
Layer 'conv4' biases: 9.999783e-01 [3.387360e-07] 
Layer 'conv5' weights[0]: 4.306793e-03 [3.589035e-06] 
Layer 'conv5' biases: 9.990904e-01 [3.942833e-06] 
Layer 'fc6' weights[0]: 7.102370e-03 [7.847112e-08] 
Layer 'fc6' biases: 9.999935e-01 [8.056652e-08] 
Layer 'fc7' weights[0]: 7.453719e-03 [1.963239e-07] 
Layer 'fc7' biases: 9.998223e-01 [3.380233e-07] 
Layer 'fc8' weights[0]: 4.599162e-03 [2.227295e-05] 
Layer 'fc8' biases: 1.345814e-02 [5.770658e-05] 
Train error last 800 batches: 0.658241
-------------------------------------------------------
Not saving because 0.518622 > 0.299667 (9.300: -1.18%)
======================================================= (2.350 sec)
17.41... logprob:  0.623307, 0.302083 (1.424 sec)
17.42... logprob:  0.580366, 0.244792 (1.419 sec)
17.43... logprob:  0.614973, 0.291667 (1.406 sec)
17.44... logprob:  0.743239, 0.291667 (1.432 sec)
17.45... logprob:  0.501792, 0.216146 (1.388 sec)
17.46... logprob:  0.661752, 0.279948 (1.400 sec)
17.47... logprob:  0.645697, 0.303385 (1.387 sec)
17.48... logprob:  0.681885, 0.296875 (1.419 sec)
17.49... logprob:  0.643203, 0.277344 (1.403 sec)
17.50... logprob:  0.639014, 0.282552 (1.421 sec)
17.51... logprob:  0.639070, 0.265625 (1.407 sec)
17.52... logprob:  0.774624, 0.342448 (1.421 sec)
17.53... logprob:  0.549472, 0.244792 (1.446 sec)
17.54... logprob:  0.599399, 0.276042 (1.383 sec)
17.55... logprob:  0.713902, 0.319010 (1.398 sec)
17.56... logprob:  0.643622, 0.282552 (1.397 sec)
17.57... logprob:  0.757245, 0.322917 (1.419 sec)
17.58... logprob:  0.715055, 0.289062 (1.393 sec)
17.59... logprob:  0.606148, 0.274740 (1.461 sec)
17.60... logprob:  0.829582, 0.332031 (1.414 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.513988, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.198061e-03 [2.103904e-07] 
Layer 'conv1' biases: 1.894064e-06 [2.585479e-10] 
Layer 'conv2' weights[0]: 4.190159e-03 [2.098267e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.341805e-09] 
Layer 'conv3' weights[0]: 4.188757e-03 [2.105574e-07] 
Layer 'conv3' biases: 3.116206e-05 [1.490740e-08] 
Layer 'conv4' weights[0]: 4.206264e-03 [2.120076e-07] 
Layer 'conv4' biases: 9.999770e-01 [2.506332e-07] 
Layer 'conv5' weights[0]: 4.302360e-03 [2.437468e-06] 
Layer 'conv5' biases: 9.990917e-01 [2.484667e-06] 
Layer 'fc6' weights[0]: 7.101609e-03 [6.773288e-08] 
Layer 'fc6' biases: 9.999935e-01 [6.592433e-08] 
Layer 'fc7' weights[0]: 7.452994e-03 [1.547395e-07] 
Layer 'fc7' biases: 9.998218e-01 [2.105475e-07] 
Layer 'fc8' weights[0]: 4.593880e-03 [1.614916e-05] 
Layer 'fc8' biases: 1.339397e-02 [2.242439e-05] 
Train error last 800 batches: 0.658282
-------------------------------------------------------
Not saving because 0.513988 > 0.299667 (9.300: -1.18%)
======================================================= (2.375 sec)
17.61... logprob:  0.635697, 0.295573 (1.431 sec)
17.62... logprob:  0.726171, 0.325521 (1.459 sec)
17.63... logprob:  0.557544, 0.247396 (1.433 sec)
17.64... logprob:  0.718814, 0.304687 (1.400 sec)
17.65... logprob:  0.585484, 0.265625 (1.396 sec)
17.66... logprob:  0.610834, 0.285156 (1.437 sec)
17.67... logprob:  0.499222, 0.231771 (1.385 sec)
17.68... logprob:  0.621422, 0.261719 (1.391 sec)
17.69... logprob:  0.802603, 0.342448 (1.415 sec)
17.70... logprob:  0.550590, 0.229167 (1.426 sec)
17.71... logprob:  0.528786, 0.247396 (1.455 sec)
17.72... logprob:  0.711573, 0.309896 (1.398 sec)
17.73... logprob:  0.691413, 0.303385 (1.421 sec)
17.74... logprob:  0.609898, 0.269531 (1.415 sec)
17.75... logprob:  0.650733, 0.289062 (1.415 sec)
17.76... logprob:  0.671138, 0.316406 (1.427 sec)
17.77... logprob:  0.630194, 0.276042 (1.429 sec)
17.78... logprob:  0.712518, 0.273438 (1.451 sec)
17.79... logprob:  0.674845, 0.303385 (1.397 sec)
17.80... logprob:  0.662834, 0.313802 (1.410 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.491056, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.193848e-03 [2.102296e-07] 
Layer 'conv1' biases: 1.893985e-06 [3.253066e-10] 
Layer 'conv2' weights[0]: 4.185969e-03 [2.096064e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.731221e-09] 
Layer 'conv3' weights[0]: 4.184573e-03 [2.101656e-07] 
Layer 'conv3' biases: 3.118238e-05 [1.317359e-08] 
Layer 'conv4' weights[0]: 4.202081e-03 [2.118850e-07] 
Layer 'conv4' biases: 9.999761e-01 [2.609601e-07] 
Layer 'conv5' weights[0]: 4.298144e-03 [2.401864e-06] 
Layer 'conv5' biases: 9.990792e-01 [2.491209e-06] 
Layer 'fc6' weights[0]: 7.100867e-03 [6.039971e-08] 
Layer 'fc6' biases: 9.999934e-01 [5.602859e-08] 
Layer 'fc7' weights[0]: 7.452216e-03 [1.362919e-07] 
Layer 'fc7' biases: 9.998235e-01 [1.643752e-07] 
Layer 'fc8' weights[0]: 4.642469e-03 [1.330109e-05] 
Layer 'fc8' biases: 1.375377e-02 [1.411338e-05] 
Train error last 800 batches: 0.658049
-------------------------------------------------------
Not saving because 0.491056 > 0.299667 (9.300: -1.18%)
======================================================= (2.362 sec)
17.81... logprob:  0.582867, 0.240885 (1.423 sec)
17.82... logprob:  0.510142, 0.247396 (1.424 sec)
17.83... logprob:  0.636048, 0.266927 (1.393 sec)
17.84... logprob:  0.692981, 0.289062 (1.459 sec)
17.85... logprob:  0.668308, 0.261719 (1.423 sec)
17.86... logprob:  0.705052, 0.272135 (1.409 sec)
17.87... logprob:  0.824597, 0.356771 (1.405 sec)
17.88... logprob:  0.685554, 0.270833 (1.407 sec)
17.89... logprob:  0.630960, 0.257812 (1.436 sec)
17.90... logprob:  0.757884, 0.335937 (1.384 sec)
17.91... logprob:  0.498748, 0.209635 (1.414 sec)
17.92... logprob:  0.637694, 0.296875 (1.396 sec)
17.93... logprob:  0.652342, 0.278646 (1.389 sec)
17.94... logprob:  0.708023, 0.315104 (1.383 sec)
17.95... logprob:  0.698668, 0.317708 (1.401 sec)
17.96... logprob:  0.808588, 0.313802 (1.398 sec)
17.97... logprob:  0.621988, 0.279948 (1.382 sec)
17.98... logprob:  0.623514, 0.273437 (1.433 sec)
17.99... logprob:  0.785744, 0.350260 (1.401 sec)
17.100... logprob:  0.616583, 0.299479 (1.397 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.424577, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.189683e-03 [2.101561e-07] 
Layer 'conv1' biases: 1.894181e-06 [2.663289e-10] 
Layer 'conv2' weights[0]: 4.181791e-03 [2.094160e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.888799e-09] 
Layer 'conv3' weights[0]: 4.180404e-03 [2.105607e-07] 
Layer 'conv3' biases: 3.120410e-05 [1.730361e-08] 
Layer 'conv4' weights[0]: 4.197862e-03 [2.124313e-07] 
Layer 'conv4' biases: 9.999763e-01 [3.044254e-07] 
Layer 'conv5' weights[0]: 4.294166e-03 [2.421048e-06] 
Layer 'conv5' biases: 9.991078e-01 [2.603429e-06] 
Layer 'fc6' weights[0]: 7.100161e-03 [6.186261e-08] 
Layer 'fc6' biases: 9.999934e-01 [5.745924e-08] 
Layer 'fc7' weights[0]: 7.451499e-03 [1.393154e-07] 
Layer 'fc7' biases: 9.998214e-01 [1.723749e-07] 
Layer 'fc8' weights[0]: 4.577825e-03 [1.396782e-05] 
Layer 'fc8' biases: 1.334588e-02 [1.870836e-05] 
Train error last 800 batches: 0.658020
-------------------------------------------------------
Not saving because 0.424577 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
17.101... logprob:  0.597452, 0.259115 (1.443 sec)
17.102... logprob:  0.766297, 0.317708 (1.391 sec)
17.103... logprob:  0.772736, 0.322917 (1.393 sec)
17.104... logprob:  0.692154, 0.296875 (1.392 sec)
17.105... logprob:  0.758219, 0.332031 (1.389 sec)
17.106... logprob:  0.688897, 0.315104 (1.388 sec)
17.107... logprob:  0.620349, 0.265625 (1.433 sec)
17.108... logprob:  0.760552, 0.332031 (1.389 sec)
17.109... logprob:  0.544325, 0.238281 (1.400 sec)
17.110... logprob:  0.755601, 0.325521 (1.391 sec)
17.111... logprob:  0.605323, 0.287760 (1.388 sec)
17.112... logprob:  0.572153, 0.257812 (1.392 sec)
17.113... logprob:  0.584535, 0.240885 (1.395 sec)
17.114... logprob:  0.610930, 0.274740 (1.424 sec)
17.115... logprob:  0.629716, 0.268229 (1.406 sec)
17.116... logprob:  0.588890, 0.268229 (1.400 sec)
17.117... logprob:  0.675714, 0.295573 (1.437 sec)
17.118... logprob:  0.611401, 0.248698 (1.384 sec)
17.119... logprob:  0.624334, 0.299479 (1.387 sec)
17.120... logprob:  0.789323, 0.332031 (1.395 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.438303, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.185484e-03 [2.097711e-07] 
Layer 'conv1' biases: 1.895025e-06 [2.706877e-10] 
Layer 'conv2' weights[0]: 4.177613e-03 [2.092260e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.968969e-09] 
Layer 'conv3' weights[0]: 4.176228e-03 [2.096967e-07] 
Layer 'conv3' biases: 3.117127e-05 [1.205805e-08] 
Layer 'conv4' weights[0]: 4.193670e-03 [2.113398e-07] 
Layer 'conv4' biases: 9.999759e-01 [2.251238e-07] 
Layer 'conv5' weights[0]: 4.289807e-03 [2.545200e-06] 
Layer 'conv5' biases: 9.991035e-01 [2.702823e-06] 
Layer 'fc6' weights[0]: 7.099400e-03 [6.230533e-08] 
Layer 'fc6' biases: 9.999934e-01 [5.779743e-08] 
Layer 'fc7' weights[0]: 7.450749e-03 [1.422167e-07] 
Layer 'fc7' biases: 9.998217e-01 [1.795319e-07] 
Layer 'fc8' weights[0]: 4.608023e-03 [1.449400e-05] 
Layer 'fc8' biases: 1.358209e-02 [2.237116e-05] 
Train error last 800 batches: 0.658258
-------------------------------------------------------
Not saving because 0.438303 > 0.299667 (9.300: -1.18%)
======================================================= (2.365 sec)
17.121... logprob:  0.603140, 0.270833 (1.402 sec)
17.122... logprob:  0.721461, 0.325521 (1.445 sec)
17.123... logprob:  0.698575, 0.294271 (1.381 sec)
17.124... logprob:  0.681459, 0.286458 (1.400 sec)
17.125... logprob:  0.718994, 0.309896 (1.388 sec)
17.126... logprob:  0.658902, 0.268229 (1.384 sec)
17.127... logprob:  0.718740, 0.335938 (1.395 sec)
17.128... logprob:  0.596963, 0.255208 (1.412 sec)
17.129... logprob:  0.753247, 0.303385 (1.410 sec)
17.130... logprob:  0.655536, 0.286458 (1.443 sec)
17.131... logprob:  0.627695, 0.277344 (1.401 sec)
17.132... logprob:  0.695505, 0.295573 (1.427 sec)
17.133... logprob:  0.645475, 0.266927 (1.385 sec)
17.134... logprob:  0.605136, 0.278646 (1.385 sec)
17.135... logprob:  0.722950, 0.312500 (1.398 sec)
17.136... logprob:  0.724355, 0.304688 (1.390 sec)
17.137... logprob:  0.659775, 0.277344 (1.382 sec)
17.138... logprob:  0.545857, 0.235677 (1.440 sec)
17.139... logprob:  0.665098, 0.285156 (1.393 sec)
17.140... logprob:  0.851205, 0.343750 (1.409 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.419394, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.181306e-03 [2.097239e-07] 
Layer 'conv1' biases: 1.897382e-06 [2.677554e-10] 
Layer 'conv2' weights[0]: 4.173431e-03 [2.089781e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.346008e-09] 
Layer 'conv3' weights[0]: 4.172022e-03 [2.096401e-07] 
Layer 'conv3' biases: 3.120787e-05 [1.452713e-08] 
Layer 'conv4' weights[0]: 4.189471e-03 [2.108972e-07] 
Layer 'conv4' biases: 9.999770e-01 [2.356110e-07] 
Layer 'conv5' weights[0]: 4.286091e-03 [2.447679e-06] 
Layer 'conv5' biases: 9.991068e-01 [2.574976e-06] 
Layer 'fc6' weights[0]: 7.098673e-03 [6.382281e-08] 
Layer 'fc6' biases: 9.999933e-01 [5.992128e-08] 
Layer 'fc7' weights[0]: 7.449972e-03 [1.472977e-07] 
Layer 'fc7' biases: 9.998205e-01 [1.825290e-07] 
Layer 'fc8' weights[0]: 4.590372e-03 [1.434757e-05] 
Layer 'fc8' biases: 1.348008e-02 [1.763556e-05] 
Train error last 800 batches: 0.658516
-------------------------------------------------------
Not saving because 0.419394 > 0.299667 (9.300: -1.18%)
======================================================= (2.409 sec)
17.141... logprob:  0.728758, 0.308594 (1.438 sec)
17.142... logprob:  0.619338, 0.261719 (1.398 sec)
17.143... logprob:  0.543435, 0.251302 (1.435 sec)
17.144... logprob:  0.779963, 0.333333 (1.408 sec)
17.145... logprob:  0.540619, 0.243489 (1.415 sec)
17.146... logprob:  0.669028, 0.294271 (1.409 sec)
17.147... logprob:  0.452366, 0.196614 (1.427 sec)
17.148... logprob:  0.652535, 0.295573 (1.384 sec)
17.149... logprob:  0.675850, 0.309896 (1.396 sec)
17.150... logprob:  0.627411, 0.281250 (1.395 sec)
17.151... logprob:  0.637923, 0.283854 (1.391 sec)
17.152... logprob:  0.809056, 0.348958 (1.383 sec)
17.153... logprob:  0.596029, 0.253906 (1.437 sec)
17.154... logprob:  0.801605, 0.342448 (1.396 sec)
17.155... logprob:  0.654945, 0.308594 (1.404 sec)
17.156... logprob:  0.612803, 0.303385 (1.434 sec)
17.157... logprob:  0.467192, 0.197917 (1.393 sec)
17.158... logprob:  0.702026, 0.299479 (1.394 sec)
17.159... logprob:  0.663982, 0.278646 (1.390 sec)
17.160... logprob:  0.631801, 0.296875 (1.389 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.497230, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.177124e-03 [2.094527e-07] 
Layer 'conv1' biases: 1.896984e-06 [2.099197e-10] 
Layer 'conv2' weights[0]: 4.169267e-03 [2.088681e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.120524e-09] 
Layer 'conv3' weights[0]: 4.167852e-03 [2.093663e-07] 
Layer 'conv3' biases: 3.121514e-05 [1.297748e-08] 
Layer 'conv4' weights[0]: 4.185292e-03 [2.109611e-07] 
Layer 'conv4' biases: 9.999769e-01 [2.345317e-07] 
Layer 'conv5' weights[0]: 4.282214e-03 [2.259550e-06] 
Layer 'conv5' biases: 9.990922e-01 [2.372021e-06] 
Layer 'fc6' weights[0]: 7.097950e-03 [6.096676e-08] 
Layer 'fc6' biases: 9.999934e-01 [5.612606e-08] 
Layer 'fc7' weights[0]: 7.449285e-03 [1.405468e-07] 
Layer 'fc7' biases: 9.998219e-01 [1.897560e-07] 
Layer 'fc8' weights[0]: 4.635051e-03 [1.571173e-05] 
Layer 'fc8' biases: 1.373159e-02 [3.156918e-05] 
Train error last 800 batches: 0.658169
-------------------------------------------------------
Not saving because 0.497230 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
17.161... logprob:  0.613943, 0.256510 (1.417 sec)
17.162... logprob:  0.811862, 0.364583 (1.405 sec)
17.163... logprob:  0.684392, 0.299479 (1.424 sec)
17.164... logprob:  0.603767, 0.257812 (1.421 sec)
17.165... logprob:  0.707570, 0.285156 (1.420 sec)
17.166... logprob:  0.649455, 0.296875 (1.441 sec)
17.167... logprob:  0.637165, 0.292969 (1.427 sec)
17.168... logprob:  0.554643, 0.226562 (1.431 sec)
17.169... logprob:  0.666646, 0.281250 (1.479 sec)
17.170... logprob:  0.762840, 0.303385 (1.402 sec)
17.171... logprob:  0.732775, 0.320312 (1.413 sec)
17.172... logprob:  0.782122, 0.302083 (1.408 sec)
17.173... logprob:  0.653815, 0.303385 (1.417 sec)
17.174... logprob:  0.759530, 0.285156 (1.395 sec)
17.175... logprob:  0.694208, 0.300781 (1.466 sec)
17.176... logprob:  0.680563, 0.316406 (1.414 sec)
17.177... logprob:  0.578800, 0.256510 (1.422 sec)
17.178... logprob:  0.635879, 0.305990 (1.457 sec)
17.179... logprob:  0.619676, 0.257812 (1.412 sec)
17.180... logprob:  0.665998, 0.282552 (1.417 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.485556, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.172957e-03 [2.090595e-07] 
Layer 'conv1' biases: 1.897736e-06 [2.491886e-10] 
Layer 'conv2' weights[0]: 4.165099e-03 [2.086888e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.489257e-09] 
Layer 'conv3' weights[0]: 4.163685e-03 [2.091521e-07] 
Layer 'conv3' biases: 3.124607e-05 [1.338771e-08] 
Layer 'conv4' weights[0]: 4.181110e-03 [2.108221e-07] 
Layer 'conv4' biases: 9.999783e-01 [2.619307e-07] 
Layer 'conv5' weights[0]: 4.279080e-03 [2.599983e-06] 
Layer 'conv5' biases: 9.991067e-01 [2.743896e-06] 
Layer 'fc6' weights[0]: 7.097199e-03 [6.734563e-08] 
Layer 'fc6' biases: 9.999933e-01 [6.457098e-08] 
Layer 'fc7' weights[0]: 7.448523e-03 [1.625836e-07] 
Layer 'fc7' biases: 9.998198e-01 [2.447412e-07] 
Layer 'fc8' weights[0]: 4.582390e-03 [2.028251e-05] 
Layer 'fc8' biases: 1.335371e-02 [4.576846e-05] 
Train error last 800 batches: 0.658588
-------------------------------------------------------
Not saving because 0.485556 > 0.299667 (9.300: -1.18%)
======================================================= (2.370 sec)
17.181... logprob:  0.733047, 0.325521 (1.421 sec)
17.182... logprob:  0.671890, 0.334635 (1.413 sec)
17.183... logprob:  0.593624, 0.261719 (1.412 sec)
17.184... logprob:  0.680976, 0.276042 (1.417 sec)
17.185... logprob:  0.544597, 0.250000 (1.391 sec)
17.186... logprob:  0.618213, 0.286458 (1.393 sec)
17.187... logprob:  0.681942, 0.307292 (1.394 sec)
17.188... logprob:  0.740735, 0.315104 (1.390 sec)
17.189... logprob:  0.598223, 0.252604 (1.383 sec)
17.190... logprob:  0.686261, 0.282552 (1.433 sec)
17.191... logprob:  0.680707, 0.283854 (1.403 sec)
17.192... logprob:  0.685938, 0.268229 (1.409 sec)
17.193... logprob:  0.598170, 0.243490 (1.416 sec)
17.194... logprob:  0.603277, 0.257812 (1.414 sec)
17.195... logprob:  0.549718, 0.264323 (1.398 sec)
17.196... logprob:  0.648588, 0.277344 (1.384 sec)
17.197... logprob:  0.758710, 0.305990 (1.398 sec)
17.198... logprob:  0.634845, 0.276042 (1.400 sec)
17.199... logprob:  0.664165, 0.299479 (1.384 sec)
17.200... logprob:  0.598316, 0.260417 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.547325, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.168765e-03 [2.087929e-07] 
Layer 'conv1' biases: 1.899856e-06 [2.793161e-10] 
Layer 'conv2' weights[0]: 4.160912e-03 [2.083972e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.559991e-09] 
Layer 'conv3' weights[0]: 4.159545e-03 [2.089730e-07] 
Layer 'conv3' biases: 3.125309e-05 [1.443798e-08] 
Layer 'conv4' weights[0]: 4.176946e-03 [2.108028e-07] 
Layer 'conv4' biases: 9.999793e-01 [2.673036e-07] 
Layer 'conv5' weights[0]: 4.275920e-03 [2.159389e-06] 
Layer 'conv5' biases: 9.990793e-01 [2.279472e-06] 
Layer 'fc6' weights[0]: 7.096478e-03 [5.901024e-08] 
Layer 'fc6' biases: 9.999933e-01 [5.354444e-08] 
Layer 'fc7' weights[0]: 7.447781e-03 [1.326442e-07] 
Layer 'fc7' biases: 9.998214e-01 [1.487884e-07] 
Layer 'fc8' weights[0]: 4.641417e-03 [1.286173e-05] 
Layer 'fc8' biases: 1.385365e-02 [7.402368e-06] 
Train error last 800 batches: 0.658642
-------------------------------------------------------
Not saving because 0.547325 > 0.299667 (9.300: -1.18%)
======================================================= (2.402 sec)
17.201... logprob:  0.618532, 0.273437 (1.415 sec)
17.202... logprob:  0.677403, 0.268229 (1.402 sec)
17.203... logprob:  0.583651, 0.266927 (1.433 sec)
17.204... logprob:  0.693828, 0.304687 (1.383 sec)
17.205... logprob:  0.703959, 0.324219 (1.397 sec)
17.206... logprob:  0.621118, 0.272135 (1.394 sec)
17.207... logprob:  0.600704, 0.276042 (1.386 sec)
17.208... logprob:  0.699091, 0.305989 (1.421 sec)
17.209... logprob:  0.601604, 0.251302 (1.413 sec)
17.210... logprob:  0.769636, 0.305990 (1.412 sec)
17.211... logprob:  0.651724, 0.294271 (1.416 sec)
17.212... logprob:  0.667351, 0.299479 (1.410 sec)
17.213... logprob:  0.725914, 0.324219 (1.452 sec)
17.214... logprob:  0.647656, 0.276042 (1.428 sec)
17.215... logprob:  0.611977, 0.282552 (1.539 sec)
17.216... logprob:  0.706354, 0.304687 (1.459 sec)
17.217... logprob:  0.565203, 0.253906 (1.401 sec)
17.218... logprob:  0.629685, 0.283854 (1.416 sec)
17.219... logprob:  0.683524, 0.303385 (1.408 sec)
17.220... logprob:  0.627620, 0.277344 (1.414 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.429256, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.164625e-03 [2.084388e-07] 
Layer 'conv1' biases: 1.901833e-06 [2.433048e-10] 
Layer 'conv2' weights[0]: 4.156792e-03 [2.080627e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.904328e-09] 
Layer 'conv3' weights[0]: 4.155375e-03 [2.085277e-07] 
Layer 'conv3' biases: 3.125955e-05 [1.194867e-08] 
Layer 'conv4' weights[0]: 4.172740e-03 [2.097609e-07] 
Layer 'conv4' biases: 9.999792e-01 [2.091898e-07] 
Layer 'conv5' weights[0]: 4.271899e-03 [2.219717e-06] 
Layer 'conv5' biases: 9.990889e-01 [2.403926e-06] 
Layer 'fc6' weights[0]: 7.095772e-03 [5.877919e-08] 
Layer 'fc6' biases: 9.999934e-01 [5.330146e-08] 
Layer 'fc7' weights[0]: 7.446985e-03 [1.325032e-07] 
Layer 'fc7' biases: 9.998202e-01 [1.531292e-07] 
Layer 'fc8' weights[0]: 4.620200e-03 [1.273250e-05] 
Layer 'fc8' biases: 1.368198e-02 [1.292314e-05] 
Train error last 800 batches: 0.658261
-------------------------------------------------------
Not saving because 0.429256 > 0.299667 (9.300: -1.18%)
======================================================= (2.374 sec)
17.221... logprob:  0.656644, 0.291667 (1.403 sec)
17.222... logprob:  0.761939, 0.303385 (1.458 sec)
17.223... logprob:  0.676737, 0.291667 (1.428 sec)
17.224... logprob:  0.599543, 0.264323 (1.423 sec)
17.225... logprob:  0.643959, 0.305990 (1.441 sec)
17.226... logprob:  0.687534, 0.296875 (1.417 sec)
17.227... logprob:  0.678625, 0.311198 (1.409 sec)
17.228... logprob:  0.619171, 0.274740 (1.409 sec)
17.229... logprob:  0.751511, 0.273438 (1.411 sec)
17.230... logprob:  0.670596, 0.286458 (1.431 sec)
17.231... logprob:  0.700129, 0.329427 (1.408 sec)
17.232... logprob:  0.685890, 0.285156 (1.453 sec)
17.233... logprob:  0.724089, 0.300781 (1.425 sec)
17.234... logprob:  0.688003, 0.300781 (1.411 sec)
17.235... logprob:  0.741516, 0.319010 (1.459 sec)
17.236... logprob:  0.658173, 0.277344 (1.394 sec)
17.237... logprob:  0.635259, 0.286458 (1.419 sec)
17.238... logprob:  0.556520, 0.240885 (1.406 sec)
17.239... logprob:  0.753830, 0.332031 (1.416 sec)
17.240... logprob:  0.697251, 0.309896 (1.391 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.384202, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.160469e-03 [2.083710e-07] 
Layer 'conv1' biases: 1.902703e-06 [2.287627e-10] 
Layer 'conv2' weights[0]: 4.152612e-03 [2.080772e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.377356e-09] 
Layer 'conv3' weights[0]: 4.151207e-03 [2.085617e-07] 
Layer 'conv3' biases: 3.130670e-05 [1.461299e-08] 
Layer 'conv4' weights[0]: 4.168556e-03 [2.103318e-07] 
Layer 'conv4' biases: 9.999797e-01 [2.757978e-07] 
Layer 'conv5' weights[0]: 4.268311e-03 [2.779229e-06] 
Layer 'conv5' biases: 9.990963e-01 [3.033982e-06] 
Layer 'fc6' weights[0]: 7.095038e-03 [6.167789e-08] 
Layer 'fc6' biases: 9.999936e-01 [5.731329e-08] 
Layer 'fc7' weights[0]: 7.446220e-03 [1.438486e-07] 
Layer 'fc7' biases: 9.998196e-01 [1.784212e-07] 
Layer 'fc8' weights[0]: 4.602800e-03 [1.481189e-05] 
Layer 'fc8' biases: 1.351048e-02 [1.996932e-05] 
Train error last 800 batches: 0.658208
-------------------------------------------------------
Not saving because 0.384202 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
17.241... logprob:  0.643632, 0.277344 (1.464 sec)
17.242... logprob:  0.553137, 0.243490 (1.425 sec)
17.243... logprob:  0.608960, 0.286458 (1.423 sec)
17.244... logprob:  0.590729, 0.255208 (1.441 sec)
17.245... logprob:  0.763304, 0.338542 (1.419 sec)
17.246... logprob:  0.618467, 0.265625 (1.406 sec)
17.247... logprob:  0.528077, 0.222656 (1.411 sec)
17.248... logprob:  0.580017, 0.269531 (1.409 sec)
17.249... logprob:  0.763601, 0.332031 (1.418 sec)
17.250... logprob:  0.750647, 0.328125 (1.406 sec)
17.251... logprob:  0.574296, 0.270833 (1.450 sec)
17.252... logprob:  0.616603, 0.274739 (1.422 sec)
17.253... logprob:  0.637145, 0.304687 (1.410 sec)
17.254... logprob:  0.766846, 0.324219 (1.462 sec)
17.255... logprob:  0.575523, 0.246094 (1.401 sec)
17.256... logprob:  0.631342, 0.299479 (1.416 sec)
17.257... logprob:  0.561114, 0.210937 (1.410 sec)
17.258... logprob:  0.606678, 0.263021 (1.412 sec)
17.259... logprob:  0.592107, 0.257812 (1.395 sec)
17.260... logprob:  0.503040, 0.242187 (1.452 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.498905, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.156300e-03 [2.082358e-07] 
Layer 'conv1' biases: 1.904167e-06 [2.770896e-10] 
Layer 'conv2' weights[0]: 4.148481e-03 [2.078803e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.263084e-09] 
Layer 'conv3' weights[0]: 4.147053e-03 [2.085935e-07] 
Layer 'conv3' biases: 3.136720e-05 [1.470314e-08] 
Layer 'conv4' weights[0]: 4.164388e-03 [2.106110e-07] 
Layer 'conv4' biases: 9.999795e-01 [2.602860e-07] 
Layer 'conv5' weights[0]: 4.264244e-03 [2.966344e-06] 
Layer 'conv5' biases: 9.990806e-01 [3.158433e-06] 
Layer 'fc6' weights[0]: 7.094311e-03 [6.785958e-08] 
Layer 'fc6' biases: 9.999935e-01 [6.575786e-08] 
Layer 'fc7' weights[0]: 7.445472e-03 [1.599036e-07] 
Layer 'fc7' biases: 9.998208e-01 [2.591946e-07] 
Layer 'fc8' weights[0]: 4.644542e-03 [1.841060e-05] 
Layer 'fc8' biases: 1.394994e-02 [4.910020e-05] 
Train error last 800 batches: 0.658232
-------------------------------------------------------
Not saving because 0.498905 > 0.299667 (9.300: -1.18%)
======================================================= (2.352 sec)
17.261... logprob:  0.685230, 0.302083 (1.427 sec)
17.262... logprob:  0.720041, 0.315104 (1.439 sec)
17.263... logprob:  0.566382, 0.247396 (1.439 sec)
17.264... logprob:  0.619434, 0.269531 (1.419 sec)
17.265... logprob:  0.624843, 0.260417 (1.413 sec)
17.266... logprob:  0.635740, 0.274740 (1.412 sec)
17.267... logprob:  0.705615, 0.268229 (1.417 sec)
17.268... logprob:  0.640823, 0.290364 (1.417 sec)
17.269... logprob:  0.796389, 0.299479 (1.408 sec)
17.270... logprob:  0.747921, 0.326823 (1.457 sec)
17.271... logprob:  0.698009, 0.325521 (1.421 sec)
17.272... logprob:  0.616034, 0.268229 (1.411 sec)
17.273... logprob:  0.696701, 0.279948 (1.465 sec)
17.274... logprob:  0.719723, 0.320312 (1.398 sec)
17.275... logprob:  0.655903, 0.259114 (1.423 sec)
17.276... logprob:  0.546204, 0.253906 (1.409 sec)
17.277... logprob:  0.623011, 0.272135 (1.421 sec)
17.278... logprob:  0.596389, 0.253906 (1.419 sec)
17.279... logprob:  0.541349, 0.246094 (1.453 sec)
17.280... logprob:  0.464910, 0.227865 (1.397 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.473252, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.152161e-03 [2.081790e-07] 
Layer 'conv1' biases: 1.905982e-06 [2.328602e-10] 
Layer 'conv2' weights[0]: 4.144319e-03 [2.075781e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.840049e-09] 
Layer 'conv3' weights[0]: 4.142928e-03 [2.080532e-07] 
Layer 'conv3' biases: 3.138023e-05 [1.161833e-08] 
Layer 'conv4' weights[0]: 4.160237e-03 [2.098428e-07] 
Layer 'conv4' biases: 9.999777e-01 [2.166596e-07] 
Layer 'conv5' weights[0]: 4.259395e-03 [2.262581e-06] 
Layer 'conv5' biases: 9.990909e-01 [2.455195e-06] 
Layer 'fc6' weights[0]: 7.093555e-03 [6.073601e-08] 
Layer 'fc6' biases: 9.999934e-01 [5.580724e-08] 
Layer 'fc7' weights[0]: 7.444717e-03 [1.379604e-07] 
Layer 'fc7' biases: 9.998194e-01 [1.949494e-07] 
Layer 'fc8' weights[0]: 4.615767e-03 [1.462221e-05] 
Layer 'fc8' biases: 1.374981e-02 [3.287265e-05] 
Train error last 800 batches: 0.658120
-------------------------------------------------------
Not saving because 0.473252 > 0.299667 (9.300: -1.18%)
======================================================= (2.353 sec)
17.281... logprob:  0.633232, 0.303385 (1.423 sec)
17.282... logprob:  0.579078, 0.277344 (1.422 sec)
17.283... logprob:  0.623502, 0.278646 (1.418 sec)
17.284... logprob:  0.641729, 0.287760 (1.404 sec)
17.285... logprob:  0.667094, 0.287760 (1.465 sec)
17.286... logprob:  0.615488, 0.256510 (1.430 sec)
17.287... logprob:  0.586116, 0.263021 (1.423 sec)
17.288... logprob:  0.587231, 0.253906 (1.429 sec)
17.289... logprob:  0.653139, 0.291667 (1.440 sec)
17.290... logprob:  0.635270, 0.283854 (1.406 sec)
17.291... logprob:  0.601834, 0.269531 (1.412 sec)
17.292... logprob:  0.680931, 0.319010 (1.416 sec)
17.293... logprob:  0.655715, 0.307292 (1.415 sec)
17.294... logprob:  0.624995, 0.273438 (1.406 sec)
17.295... logprob:  0.577154, 0.270833 (1.457 sec)
17.296... logprob:  0.648198, 0.285156 (1.414 sec)
17.297... logprob:  0.637923, 0.307292 (1.418 sec)
17.298... logprob:  0.627613, 0.309896 (1.464 sec)
17.299... logprob:  0.564597, 0.256510 (1.399 sec)
17.300... logprob:  0.568850, 0.252604 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.405837, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.148009e-03 [2.078858e-07] 
Layer 'conv1' biases: 1.906870e-06 [2.099320e-10] 
Layer 'conv2' weights[0]: 4.140180e-03 [2.073198e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.890832e-09] 
Layer 'conv3' weights[0]: 4.138767e-03 [2.077265e-07] 
Layer 'conv3' biases: 3.139841e-05 [1.179781e-08] 
Layer 'conv4' weights[0]: 4.156084e-03 [2.094990e-07] 
Layer 'conv4' biases: 9.999762e-01 [2.317328e-07] 
Layer 'conv5' weights[0]: 4.254726e-03 [2.335103e-06] 
Layer 'conv5' biases: 9.990680e-01 [2.494797e-06] 
Layer 'fc6' weights[0]: 7.092806e-03 [5.966226e-08] 
Layer 'fc6' biases: 9.999932e-01 [5.450934e-08] 
Layer 'fc7' weights[0]: 7.444009e-03 [1.339598e-07] 
Layer 'fc7' biases: 9.998217e-01 [1.774684e-07] 
Layer 'fc8' weights[0]: 4.690313e-03 [1.359232e-05] 
Layer 'fc8' biases: 1.430625e-02 [2.706120e-05] 
Train error last 800 batches: 0.657434
-------------------------------------------------------
Not saving because 0.405837 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
17.301... logprob:  0.680668, 0.292969 (1.418 sec)
17.302... logprob:  0.760167, 0.328125 (1.417 sec)
17.303... logprob:  0.687680, 0.302083 (1.398 sec)
17.304... logprob:  0.703531, 0.302083 (1.434 sec)
17.305... logprob:  0.653308, 0.277344 (1.434 sec)
17.306... logprob:  0.696459, 0.276042 (1.426 sec)
17.307... logprob:  0.702697, 0.292969 (1.437 sec)
17.308... logprob:  0.637905, 0.281250 (1.447 sec)
17.309... logprob:  0.678603, 0.274740 (1.419 sec)
17.310... logprob:  0.744344, 0.321615 (1.413 sec)
17.311... logprob:  0.709573, 0.337240 (1.417 sec)
17.312... logprob:  0.656198, 0.287760 (1.428 sec)
17.313... logprob:  0.692406, 0.279948 (1.415 sec)
17.314... logprob:  0.703253, 0.286458 (1.457 sec)
17.315... logprob:  0.561683, 0.282552 (1.434 sec)
17.316... logprob:  0.727631, 0.303385 (1.420 sec)
17.317... logprob:  0.569064, 0.252604 (1.466 sec)
17.318... logprob:  0.653988, 0.273437 (1.411 sec)
17.319... logprob:  0.587461, 0.255208 (1.424 sec)
17.320... logprob:  0.686715, 0.283854 (1.416 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.450205, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.143849e-03 [2.077865e-07] 
Layer 'conv1' biases: 1.907982e-06 [2.197245e-10] 
Layer 'conv2' weights[0]: 4.136042e-03 [2.071416e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.800843e-09] 
Layer 'conv3' weights[0]: 4.134608e-03 [2.076570e-07] 
Layer 'conv3' biases: 3.141919e-05 [1.225904e-08] 
Layer 'conv4' weights[0]: 4.151920e-03 [2.091993e-07] 
Layer 'conv4' biases: 9.999740e-01 [2.114544e-07] 
Layer 'conv5' weights[0]: 4.249499e-03 [2.329292e-06] 
Layer 'conv5' biases: 9.991028e-01 [2.345033e-06] 
Layer 'fc6' weights[0]: 7.092050e-03 [6.231691e-08] 
Layer 'fc6' biases: 9.999931e-01 [5.818633e-08] 
Layer 'fc7' weights[0]: 7.443257e-03 [1.406927e-07] 
Layer 'fc7' biases: 9.998183e-01 [1.764717e-07] 
Layer 'fc8' weights[0]: 4.595737e-03 [1.477535e-05] 
Layer 'fc8' biases: 1.370315e-02 [2.501717e-05] 
Train error last 800 batches: 0.657392
-------------------------------------------------------
Not saving because 0.450205 > 0.299667 (9.300: -1.18%)
======================================================= (2.396 sec)
17.321... logprob:  0.615649, 0.283854 (1.426 sec)
17.322... logprob:  0.613777, 0.277344 (1.417 sec)
17.323... logprob:  0.679682, 0.289062 (1.470 sec)
17.324... logprob:  0.734505, 0.316406 (1.417 sec)
17.325... logprob:  0.631661, 0.282552 (1.427 sec)
17.326... logprob:  0.695727, 0.305990 (1.459 sec)
17.327... logprob:  0.705574, 0.332031 (1.415 sec)
17.328... logprob:  0.798256, 0.312500 (1.421 sec)
17.329... logprob:  0.559802, 0.238281 (1.424 sec)
17.330... logprob:  0.622513, 0.269531 (1.415 sec)
17.331... logprob:  0.705360, 0.320312 (1.418 sec)
17.332... logprob:  0.592866, 0.257812 (1.442 sec)
17.333... logprob:  0.585111, 0.239583 (1.438 sec)
17.334... logprob:  0.822807, 0.354167 (1.434 sec)
17.335... logprob:  0.630921, 0.285156 (1.432 sec)
17.336... logprob:  0.631619, 0.291667 (1.450 sec)
17.337... logprob:  0.804680, 0.378906 (1.409 sec)
17.338... logprob:  0.677115, 0.302083 (1.416 sec)
17.339... logprob:  0.786159, 0.339844 (1.424 sec)
17.340... logprob:  0.774188, 0.330729 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.393637, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.139720e-03 [2.076493e-07] 
Layer 'conv1' biases: 1.907838e-06 [2.969402e-10] 
Layer 'conv2' weights[0]: 4.131920e-03 [2.069376e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.758406e-09] 
Layer 'conv3' weights[0]: 4.130487e-03 [2.081281e-07] 
Layer 'conv3' biases: 3.141886e-05 [1.705419e-08] 
Layer 'conv4' weights[0]: 4.147774e-03 [2.098510e-07] 
Layer 'conv4' biases: 9.999743e-01 [3.140708e-07] 
Layer 'conv5' weights[0]: 4.245765e-03 [3.411144e-06] 
Layer 'conv5' biases: 9.991069e-01 [3.751246e-06] 
Layer 'fc6' weights[0]: 7.091319e-03 [7.590991e-08] 
Layer 'fc6' biases: 9.999933e-01 [7.619841e-08] 
Layer 'fc7' weights[0]: 7.442506e-03 [1.855464e-07] 
Layer 'fc7' biases: 9.998178e-01 [3.063526e-07] 
Layer 'fc8' weights[0]: 4.586052e-03 [2.271451e-05] 
Layer 'fc8' biases: 1.354228e-02 [5.107340e-05] 
Train error last 800 batches: 0.657588
-------------------------------------------------------
Not saving because 0.393637 > 0.299667 (9.300: -1.18%)
======================================================= (2.365 sec)
17.341... logprob:  0.701215, 0.298177 (1.423 sec)
17.342... logprob:  0.630784, 0.269531 (1.465 sec)
17.343... logprob:  0.563783, 0.251302 (1.441 sec)
17.344... logprob:  0.642276, 0.261719 (1.474 sec)
17.345... logprob:  0.650185, 0.272135 (1.437 sec)
17.346... logprob:  0.615450, 0.272135 (1.435 sec)
17.347... logprob:  0.674005, 0.264323 (1.472 sec)
17.348... logprob:  0.575752, 0.231771 (1.429 sec)
17.349... logprob:  0.808999, 0.326823 (1.430 sec)
17.350... logprob:  0.554569, 0.265625 (1.435 sec)
17.351... logprob:  0.745757, 0.321615 (1.421 sec)
17.352... logprob:  0.688756, 0.312500 (1.433 sec)
17.353... logprob:  0.729020, 0.324219 (1.488 sec)
17.354... logprob:  0.793028, 0.324219 (1.428 sec)
17.355... logprob:  0.638680, 0.296875 (1.439 sec)
17.356... logprob:  0.705702, 0.308594 (1.474 sec)
17.357... logprob:  0.541687, 0.242187 (1.421 sec)
17.358... logprob:  0.615729, 0.285156 (1.435 sec)
17.359... logprob:  0.702126, 0.305990 (1.425 sec)
17.360... logprob:  0.699429, 0.324219 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.565119, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.135576e-03 [2.073718e-07] 
Layer 'conv1' biases: 1.906954e-06 [1.955154e-10] 
Layer 'conv2' weights[0]: 4.127764e-03 [2.067013e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.941650e-09] 
Layer 'conv3' weights[0]: 4.126388e-03 [2.073395e-07] 
Layer 'conv3' biases: 3.141174e-05 [1.244921e-08] 
Layer 'conv4' weights[0]: 4.143618e-03 [2.089958e-07] 
Layer 'conv4' biases: 9.999750e-01 [2.311510e-07] 
Layer 'conv5' weights[0]: 4.242298e-03 [2.400561e-06] 
Layer 'conv5' biases: 9.991068e-01 [2.566954e-06] 
Layer 'fc6' weights[0]: 7.090551e-03 [6.102689e-08] 
Layer 'fc6' biases: 9.999934e-01 [5.595625e-08] 
Layer 'fc7' weights[0]: 7.441751e-03 [1.386385e-07] 
Layer 'fc7' biases: 9.998173e-01 [1.649530e-07] 
Layer 'fc8' weights[0]: 4.571195e-03 [1.394516e-05] 
Layer 'fc8' biases: 1.344536e-02 [1.886446e-05] 
Train error last 800 batches: 0.657541
-------------------------------------------------------
Not saving because 0.565119 > 0.299667 (9.300: -1.18%)
======================================================= (2.388 sec)
17.361... logprob:  0.731643, 0.307292 (1.431 sec)
17.362... logprob:  0.699396, 0.308594 (1.478 sec)
17.363... logprob:  0.611453, 0.278646 (1.435 sec)
17.364... logprob:  0.640766, 0.285156 (1.445 sec)
17.365... logprob:  0.695146, 0.289062 (1.462 sec)
17.366... logprob:  0.647063, 0.283854 (1.434 sec)
17.367... logprob:  0.609884, 0.276042 (1.435 sec)
17.368... logprob:  0.866378, 0.343750 (1.421 sec)
17.369... logprob:  0.634610, 0.263021 (1.423 sec)
17.370... logprob:  0.598734, 0.238281 (1.439 sec)
17.371... logprob:  0.597842, 0.285156 (1.455 sec)
17.372... logprob:  0.728537, 0.321615 (1.450 sec)
17.373... logprob:  0.689539, 0.287760 (1.445 sec)
17.374... logprob:  0.725693, 0.328125 (1.446 sec)
17.375... logprob:  0.540538, 0.227865 (1.455 sec)
17.376... logprob:  0.663619, 0.298177 (1.438 sec)
17.377... logprob:  0.611999, 0.273437 (1.422 sec)
17.378... logprob:  0.686405, 0.328125 (1.425 sec)
17.379... logprob:  0.666338, 0.296875 (1.431 sec)
17.380... logprob:  0.683915, 0.292969 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.462215, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.131431e-03 [2.071761e-07] 
Layer 'conv1' biases: 1.909166e-06 [2.254256e-10] 
Layer 'conv2' weights[0]: 4.123646e-03 [2.065936e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.310650e-09] 
Layer 'conv3' weights[0]: 4.122277e-03 [2.072102e-07] 
Layer 'conv3' biases: 3.141420e-05 [1.260106e-08] 
Layer 'conv4' weights[0]: 4.139460e-03 [2.090762e-07] 
Layer 'conv4' biases: 9.999750e-01 [2.464463e-07] 
Layer 'conv5' weights[0]: 4.238030e-03 [2.465617e-06] 
Layer 'conv5' biases: 9.990979e-01 [2.721196e-06] 
Layer 'fc6' weights[0]: 7.089828e-03 [6.367294e-08] 
Layer 'fc6' biases: 9.999933e-01 [5.952696e-08] 
Layer 'fc7' weights[0]: 7.441023e-03 [1.468523e-07] 
Layer 'fc7' biases: 9.998176e-01 [1.966369e-07] 
Layer 'fc8' weights[0]: 4.594036e-03 [1.599956e-05] 
Layer 'fc8' biases: 1.368554e-02 [3.263635e-05] 
Train error last 800 batches: 0.657279
-------------------------------------------------------
Not saving because 0.462215 > 0.299667 (9.300: -1.18%)
======================================================= (2.400 sec)
17.381... logprob:  0.633678, 0.290365 (1.468 sec)
17.382... logprob:  0.699498, 0.308594 (1.451 sec)
17.383... logprob:  0.586510, 0.252604 (1.430 sec)
17.384... logprob:  0.786037, 0.316406 (1.484 sec)
17.385... logprob:  0.663515, 0.296875 (1.426 sec)
17.386... logprob:  0.804843, 0.337240 (1.423 sec)
17.387... logprob:  0.669193, 0.290365 (1.424 sec)
17.388... logprob:  0.637768, 0.281250 (1.434 sec)
17.389... logprob:  0.652753, 0.279948 (1.432 sec)
17.390... logprob:  0.671918, 0.265625 (1.482 sec)
17.391... logprob:  0.564255, 0.257812 (1.445 sec)
17.392... logprob:  0.658726, 0.269531 (1.431 sec)
17.393... logprob:  0.658275, 0.311198 (1.483 sec)
17.394... logprob:  0.619506, 0.269531 (1.425 sec)
17.395... logprob:  0.500221, 0.230469 (1.422 sec)
17.396... logprob:  0.564446, 0.261719 (1.431 sec)
17.397... logprob:  0.744150, 0.325521 (1.425 sec)
17.398... logprob:  0.658920, 0.279948 (1.430 sec)
17.399... logprob:  0.591213, 0.251302 (1.482 sec)
17.400... logprob:  0.712944, 0.320312 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.390494, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.127293e-03 [2.068954e-07] 
Layer 'conv1' biases: 1.909538e-06 [1.969342e-10] 
Layer 'conv2' weights[0]: 4.119521e-03 [2.064067e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.762549e-09] 
Layer 'conv3' weights[0]: 4.118146e-03 [2.067579e-07] 
Layer 'conv3' biases: 3.142341e-05 [1.204595e-08] 
Layer 'conv4' weights[0]: 4.135322e-03 [2.084771e-07] 
Layer 'conv4' biases: 9.999755e-01 [2.245237e-07] 
Layer 'conv5' weights[0]: 4.234546e-03 [2.431285e-06] 
Layer 'conv5' biases: 9.990793e-01 [2.588795e-06] 
Layer 'fc6' weights[0]: 7.089085e-03 [6.091705e-08] 
Layer 'fc6' biases: 9.999933e-01 [5.628904e-08] 
Layer 'fc7' weights[0]: 7.440275e-03 [1.381210e-07] 
Layer 'fc7' biases: 9.998188e-01 [1.702032e-07] 
Layer 'fc8' weights[0]: 4.633780e-03 [1.430647e-05] 
Layer 'fc8' biases: 1.395769e-02 [1.929597e-05] 
Train error last 800 batches: 0.656709
-------------------------------------------------------
Not saving because 0.390494 > 0.299667 (9.300: -1.18%)
======================================================= (2.371 sec)
17.401... logprob:  0.710313, 0.303385 (1.441 sec)
17.402... logprob:  0.734973, 0.335937 (1.490 sec)
17.403... logprob:  0.689132, 0.260417 (1.430 sec)
17.404... logprob:  0.687376, 0.273437 (1.429 sec)
17.405... logprob:  0.772591, 0.347656 (1.430 sec)
17.406... logprob:  0.556867, 0.256510 (1.423 sec)
17.407... logprob:  0.750877, 0.332031 (1.427 sec)
17.408... logprob:  0.582400, 0.220052 (1.472 sec)
17.409... logprob:  0.719826, 0.313802 (1.433 sec)
17.410... logprob:  0.750338, 0.319010 (1.447 sec)
17.411... logprob:  0.620288, 0.292969 (1.471 sec)
17.412... logprob:  0.769418, 0.313802 (1.438 sec)
17.413... logprob:  0.708035, 0.292969 (1.434 sec)
17.414... logprob:  0.698098, 0.311198 (1.432 sec)
17.415... logprob:  0.690982, 0.298177 (1.424 sec)
17.416... logprob:  0.646738, 0.289062 (1.433 sec)
17.417... logprob:  0.565571, 0.227865 (1.457 sec)
17.418... logprob:  0.591877, 0.261719 (1.448 sec)
17.419... logprob:  0.626934, 0.272135 (1.451 sec)
17.420... logprob:  0.584121, 0.251302 (1.450 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.457392, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.123158e-03 [2.067403e-07] 
Layer 'conv1' biases: 1.909474e-06 [2.805046e-10] 
Layer 'conv2' weights[0]: 4.115414e-03 [2.061560e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.117349e-09] 
Layer 'conv3' weights[0]: 4.114011e-03 [2.068086e-07] 
Layer 'conv3' biases: 3.146638e-05 [1.358168e-08] 
Layer 'conv4' weights[0]: 4.131222e-03 [2.083485e-07] 
Layer 'conv4' biases: 9.999757e-01 [2.436945e-07] 
Layer 'conv5' weights[0]: 4.230799e-03 [2.882692e-06] 
Layer 'conv5' biases: 9.990939e-01 [3.086026e-06] 
Layer 'fc6' weights[0]: 7.088383e-03 [6.697197e-08] 
Layer 'fc6' biases: 9.999934e-01 [6.437815e-08] 
Layer 'fc7' weights[0]: 7.439543e-03 [1.579900e-07] 
Layer 'fc7' biases: 9.998172e-01 [2.436936e-07] 
Layer 'fc8' weights[0]: 4.581391e-03 [1.818028e-05] 
Layer 'fc8' biases: 1.360971e-02 [4.225083e-05] 
Train error last 800 batches: 0.657135
-------------------------------------------------------
Not saving because 0.457392 > 0.299667 (9.300: -1.18%)
======================================================= (2.367 sec)
17.421... logprob:  0.698514, 0.308594 (1.457 sec)
17.422... logprob:  0.691170, 0.313802 (1.439 sec)
17.423... logprob:  0.657524, 0.286458 (1.419 sec)
17.424... logprob:  0.570937, 0.246094 (1.426 sec)
17.425... logprob:  0.640553, 0.312500 (1.433 sec)
17.426... logprob:  0.727624, 0.313802 (1.446 sec)
17.427... logprob:  0.769775, 0.360677 (1.459 sec)
17.428... logprob:  0.745917, 0.303385 (1.454 sec)
17.429... logprob:  0.699125, 0.312500 (1.442 sec)
17.430... logprob:  0.630580, 0.289062 (1.479 sec)
17.431... logprob:  0.757616, 0.300781 (1.426 sec)
17.432... logprob:  0.549020, 0.246094 (1.422 sec)
17.433... logprob:  0.593716, 0.256510 (1.453 sec)
17.434... logprob:  0.704054, 0.309896 (1.448 sec)
17.435... logprob:  0.709233, 0.294271 (1.440 sec)
17.436... logprob:  0.670877, 0.295573 (1.487 sec)
17.437... logprob:  0.666433, 0.291667 (1.449 sec)
17.438... logprob:  0.723097, 0.311198 (1.436 sec)
17.439... logprob:  0.636936, 0.260417 (1.481 sec)
17.440... logprob:  0.690401, 0.324219 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.481783, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.119047e-03 [2.062734e-07] 
Layer 'conv1' biases: 1.909585e-06 [3.466496e-10] 
Layer 'conv2' weights[0]: 4.111286e-03 [2.058602e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.624123e-09] 
Layer 'conv3' weights[0]: 4.109903e-03 [2.066923e-07] 
Layer 'conv3' biases: 3.148644e-05 [1.495867e-08] 
Layer 'conv4' weights[0]: 4.127076e-03 [2.081799e-07] 
Layer 'conv4' biases: 9.999752e-01 [2.639647e-07] 
Layer 'conv5' weights[0]: 4.226901e-03 [2.607861e-06] 
Layer 'conv5' biases: 9.990836e-01 [2.725213e-06] 
Layer 'fc6' weights[0]: 7.087618e-03 [6.583167e-08] 
Layer 'fc6' biases: 9.999933e-01 [6.329703e-08] 
Layer 'fc7' weights[0]: 7.438776e-03 [1.560478e-07] 
Layer 'fc7' biases: 9.998173e-01 [2.220267e-07] 
Layer 'fc8' weights[0]: 4.613513e-03 [1.818097e-05] 
Layer 'fc8' biases: 1.385730e-02 [3.392052e-05] 
Train error last 800 batches: 0.657470
-------------------------------------------------------
Not saving because 0.481783 > 0.299667 (9.300: -1.18%)
======================================================= (2.363 sec)
17.441... logprob:  0.773173, 0.381510 (1.435 sec)
17.442... logprob:  0.645676, 0.294271 (1.438 sec)
17.443... logprob:  0.743654, 0.328125 (1.428 sec)
17.444... logprob:  0.682326, 0.295573 (1.442 sec)
17.445... logprob:  0.629958, 0.290365 (1.487 sec)
17.446... logprob:  0.629763, 0.281250 (1.435 sec)
17.447... logprob:  0.697786, 0.304687 (1.440 sec)
17.448... logprob:  0.605807, 0.263021 (1.491 sec)
17.449... logprob:  0.658079, 0.300781 (1.427 sec)
17.450... logprob:  0.471337, 0.209635 (1.429 sec)
17.451... logprob:  0.689599, 0.277344 (1.439 sec)
17.452... logprob:  0.753979, 0.335937 (1.434 sec)
17.453... logprob:  0.730846, 0.325521 (1.444 sec)
17.454... logprob:  0.721467, 0.313802 (1.495 sec)
17.455... logprob:  0.674785, 0.294271 (1.443 sec)
17.456... logprob:  0.676468, 0.289062 (1.458 sec)
17.457... logprob:  0.673282, 0.320312 (1.482 sec)
17.458... logprob:  0.626225, 0.292969 (1.442 sec)
17.459... logprob:  0.703338, 0.305990 (1.447 sec)
17.460... logprob:  0.551519, 0.255208 (1.444 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.504379, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.114950e-03 [2.061537e-07] 
Layer 'conv1' biases: 1.911130e-06 [2.411515e-10] 
Layer 'conv2' weights[0]: 4.107166e-03 [2.056717e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.305011e-09] 
Layer 'conv3' weights[0]: 4.105784e-03 [2.062152e-07] 
Layer 'conv3' biases: 3.151661e-05 [1.336701e-08] 
Layer 'conv4' weights[0]: 4.122952e-03 [2.077364e-07] 
Layer 'conv4' biases: 9.999768e-01 [2.505081e-07] 
Layer 'conv5' weights[0]: 4.223664e-03 [2.604140e-06] 
Layer 'conv5' biases: 9.990856e-01 [2.871833e-06] 
Layer 'fc6' weights[0]: 7.086889e-03 [6.252137e-08] 
Layer 'fc6' biases: 9.999933e-01 [5.828779e-08] 
Layer 'fc7' weights[0]: 7.438012e-03 [1.411223e-07] 
Layer 'fc7' biases: 9.998176e-01 [1.897307e-07] 
Layer 'fc8' weights[0]: 4.603564e-03 [1.500098e-05] 
Layer 'fc8' biases: 1.379817e-02 [2.824026e-05] 
Train error last 800 batches: 0.658052
-------------------------------------------------------
Not saving because 0.504379 > 0.299667 (9.300: -1.18%)
======================================================= (2.391 sec)
17.461... logprob:  0.713513, 0.311198 (1.434 sec)
17.462... logprob:  0.648475, 0.286458 (1.449 sec)
17.463... logprob:  0.631996, 0.257812 (1.464 sec)
17.464... logprob:  0.618853, 0.264323 (1.455 sec)
17.465... logprob:  0.749613, 0.324219 (1.464 sec)
17.466... logprob:  0.574896, 0.242188 (1.461 sec)
17.467... logprob:  0.652034, 0.300781 (1.450 sec)
17.468... logprob:  0.614996, 0.291667 (1.435 sec)
17.469... logprob:  0.668657, 0.309896 (1.425 sec)
17.470... logprob:  0.546548, 0.244792 (1.441 sec)
17.471... logprob:  0.751698, 0.311198 (1.446 sec)
17.472... logprob:  0.561242, 0.251302 (1.459 sec)
17.473... logprob:  0.694130, 0.299479 (1.521 sec)
17.474... logprob:  0.578668, 0.274739 (1.450 sec)
17.475... logprob:  0.733861, 0.303385 (1.445 sec)
17.476... logprob:  0.680724, 0.313802 (1.470 sec)
17.477... logprob:  0.538454, 0.225260 (1.464 sec)
17.478... logprob:  0.710229, 0.296875 (1.420 sec)
17.479... logprob:  0.554493, 0.257812 (1.423 sec)
17.480... logprob:  0.586833, 0.250000 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.513871, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.110818e-03 [2.059732e-07] 
Layer 'conv1' biases: 1.913584e-06 [2.422829e-10] 
Layer 'conv2' weights[0]: 4.103082e-03 [2.053908e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.028777e-09] 
Layer 'conv3' weights[0]: 4.101672e-03 [2.060800e-07] 
Layer 'conv3' biases: 3.152820e-05 [1.413093e-08] 
Layer 'conv4' weights[0]: 4.118814e-03 [2.075823e-07] 
Layer 'conv4' biases: 9.999785e-01 [2.557974e-07] 
Layer 'conv5' weights[0]: 4.220764e-03 [2.117569e-06] 
Layer 'conv5' biases: 9.990690e-01 [2.316184e-06] 
Layer 'fc6' weights[0]: 7.086162e-03 [5.882282e-08] 
Layer 'fc6' biases: 9.999933e-01 [5.344713e-08] 
Layer 'fc7' weights[0]: 7.437272e-03 [1.337618e-07] 
Layer 'fc7' biases: 9.998181e-01 [1.589144e-07] 
Layer 'fc8' weights[0]: 4.643862e-03 [1.375136e-05] 
Layer 'fc8' biases: 1.416777e-02 [1.928413e-05] 
Train error last 800 batches: 0.657950
-------------------------------------------------------
Not saving because 0.513871 > 0.299667 (9.300: -1.18%)
======================================================= (2.369 sec)
17.481... logprob:  0.804811, 0.332031 (1.436 sec)
17.482... logprob:  0.574155, 0.248698 (1.480 sec)
17.483... logprob:  0.696550, 0.292969 (1.443 sec)
17.484... logprob:  0.746477, 0.315104 (1.440 sec)
17.485... logprob:  0.622160, 0.261719 (1.479 sec)
17.486... logprob:  0.682841, 0.317708 (1.433 sec)
17.487... logprob:  0.713586, 0.335937 (1.419 sec)
17.488... logprob:  0.652862, 0.302083 (1.432 sec)
17.489... logprob:  0.716745, 0.290365 (1.424 sec)
17.490... logprob:  0.645202, 0.298177 (1.428 sec)
17.491... logprob:  0.496846, 0.218750 (1.473 sec)
17.492... logprob:  0.687031, 0.272135 (1.436 sec)
17.493... logprob:  0.731182, 0.294271 (1.428 sec)
17.494... logprob:  0.595876, 0.281250 (1.478 sec)
17.495... logprob:  0.717138, 0.294271 (1.425 sec)
17.496... logprob:  0.693689, 0.295573 (1.429 sec)
17.497... logprob:  0.679147, 0.265625 (1.429 sec)
17.498... logprob:  0.718690, 0.348958 (1.424 sec)
17.499... logprob:  0.633335, 0.269531 (1.423 sec)
17.500... logprob:  0.549066, 0.248698 (1.482 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.522558, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.106726e-03 [2.058407e-07] 
Layer 'conv1' biases: 1.915530e-06 [2.323741e-10] 
Layer 'conv2' weights[0]: 4.098977e-03 [2.053933e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.134504e-09] 
Layer 'conv3' weights[0]: 4.097587e-03 [2.059705e-07] 
Layer 'conv3' biases: 3.154857e-05 [1.347713e-08] 
Layer 'conv4' weights[0]: 4.114714e-03 [2.076225e-07] 
Layer 'conv4' biases: 9.999794e-01 [2.418200e-07] 
Layer 'conv5' weights[0]: 4.217419e-03 [2.529054e-06] 
Layer 'conv5' biases: 9.990849e-01 [2.691495e-06] 
Layer 'fc6' weights[0]: 7.085429e-03 [6.069091e-08] 
Layer 'fc6' biases: 9.999933e-01 [5.592659e-08] 
Layer 'fc7' weights[0]: 7.436550e-03 [1.381711e-07] 
Layer 'fc7' biases: 9.998158e-01 [1.681071e-07] 
Layer 'fc8' weights[0]: 4.583707e-03 [1.389677e-05] 
Layer 'fc8' biases: 1.365768e-02 [2.163952e-05] 
Train error last 800 batches: 0.657517
-------------------------------------------------------
Not saving because 0.522558 > 0.299667 (9.300: -1.18%)
======================================================= (2.404 sec)
17.501... logprob:  0.547954, 0.246094 (1.437 sec)
17.502... logprob:  0.646793, 0.272135 (1.449 sec)
17.503... logprob:  0.625504, 0.272135 (1.473 sec)
17.504... logprob:  0.733132, 0.298177 (1.426 sec)
17.505... logprob:  0.703146, 0.330729 (1.435 sec)
17.506... logprob:  0.750542, 0.279948 (1.436 sec)
17.507... logprob:  0.566963, 0.257812 (1.425 sec)
17.508... logprob:  0.580233, 0.272135 (1.427 sec)
17.509... logprob:  0.546561, 0.256510 (1.469 sec)
17.510... logprob:  0.624339, 0.285156 (1.439 sec)
17.511... logprob:  0.640336, 0.287760 (1.445 sec)
17.512... logprob:  0.740922, 0.291667 (1.465 sec)
17.513... logprob:  0.520271, 0.229167 (1.434 sec)
17.514... logprob:  0.696291, 0.308594 (1.435 sec)
17.515... logprob:  0.615353, 0.265625 (1.456 sec)
17.516... logprob:  0.568142, 0.250000 (1.422 sec)
17.517... logprob:  0.757506, 0.319010 (1.439 sec)
17.518... logprob:  0.754271, 0.296875 (1.457 sec)
17.519... logprob:  0.739136, 0.335937 (1.450 sec)
17.520... logprob:  0.695714, 0.338542 (1.448 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.448675, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.102618e-03 [2.055307e-07] 
Layer 'conv1' biases: 1.916400e-06 [2.910155e-10] 
Layer 'conv2' weights[0]: 4.094871e-03 [2.050373e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.767991e-09] 
Layer 'conv3' weights[0]: 4.093501e-03 [2.059427e-07] 
Layer 'conv3' biases: 3.158966e-05 [1.588091e-08] 
Layer 'conv4' weights[0]: 4.110589e-03 [2.072811e-07] 
Layer 'conv4' biases: 9.999780e-01 [2.923832e-07] 
Layer 'conv5' weights[0]: 4.212887e-03 [2.947924e-06] 
Layer 'conv5' biases: 9.990733e-01 [3.106253e-06] 
Layer 'fc6' weights[0]: 7.084706e-03 [6.785469e-08] 
Layer 'fc6' biases: 9.999934e-01 [6.570806e-08] 
Layer 'fc7' weights[0]: 7.435788e-03 [1.576009e-07] 
Layer 'fc7' biases: 9.998168e-01 [2.309587e-07] 
Layer 'fc8' weights[0]: 4.621795e-03 [1.707923e-05] 
Layer 'fc8' biases: 1.389484e-02 [3.377294e-05] 
Train error last 800 batches: 0.657242
-------------------------------------------------------
Not saving because 0.448675 > 0.299667 (9.300: -1.18%)
======================================================= (2.384 sec)
17.521... logprob:  0.697733, 0.277344 (1.450 sec)
17.522... logprob:  0.793041, 0.329427 (1.462 sec)
17.523... logprob:  0.522735, 0.260417 (1.436 sec)
17.524... logprob:  0.583572, 0.272135 (1.418 sec)
17.525... logprob:  0.653950, 0.289062 (1.432 sec)
17.526... logprob:  0.607745, 0.282552 (1.432 sec)
17.527... logprob:  0.715544, 0.341146 (1.440 sec)
17.528... logprob:  0.653096, 0.302083 (1.469 sec)
17.529... logprob:  0.549862, 0.256510 (1.443 sec)
17.530... logprob:  0.644959, 0.279948 (1.435 sec)
17.531... logprob:  0.689585, 0.290365 (1.474 sec)
17.532... logprob:  0.687719, 0.320312 (1.423 sec)
17.533... logprob:  0.784676, 0.345052 (1.423 sec)
17.534... logprob:  0.608324, 0.256510 (1.432 sec)
17.535... logprob:  0.754655, 0.322917 (1.435 sec)
17.536... logprob:  0.697681, 0.311198 (1.427 sec)
17.537... logprob:  0.660091, 0.309896 (1.477 sec)
17.538... logprob:  0.620165, 0.285156 (1.440 sec)
17.539... logprob:  0.564748, 0.260417 (1.424 sec)
17.540... logprob:  0.679470, 0.272135 (1.479 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.433535, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.098513e-03 [2.053320e-07] 
Layer 'conv1' biases: 1.917767e-06 [2.137731e-10] 
Layer 'conv2' weights[0]: 4.090804e-03 [2.049634e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.377651e-09] 
Layer 'conv3' weights[0]: 4.089408e-03 [2.053730e-07] 
Layer 'conv3' biases: 3.162632e-05 [1.338616e-08] 
Layer 'conv4' weights[0]: 4.106508e-03 [2.068549e-07] 
Layer 'conv4' biases: 9.999747e-01 [2.300077e-07] 
Layer 'conv5' weights[0]: 4.207275e-03 [2.427394e-06] 
Layer 'conv5' biases: 9.990824e-01 [2.546075e-06] 
Layer 'fc6' weights[0]: 7.083949e-03 [6.355903e-08] 
Layer 'fc6' biases: 9.999934e-01 [5.987656e-08] 
Layer 'fc7' weights[0]: 7.435044e-03 [1.453258e-07] 
Layer 'fc7' biases: 9.998165e-01 [1.972593e-07] 
Layer 'fc8' weights[0]: 4.620649e-03 [1.609495e-05] 
Layer 'fc8' biases: 1.391683e-02 [3.405678e-05] 
Train error last 800 batches: 0.657100
-------------------------------------------------------
Not saving because 0.433535 > 0.299667 (9.300: -1.18%)
======================================================= (2.391 sec)
17.541... logprob:  0.607957, 0.263021 (1.439 sec)
17.542... logprob:  0.620619, 0.278646 (1.431 sec)
17.543... logprob:  0.573053, 0.268229 (1.440 sec)
17.544... logprob:  0.580454, 0.273437 (1.430 sec)
17.545... logprob:  0.605526, 0.290365 (1.426 sec)
17.546... logprob:  0.576601, 0.250000 (1.478 sec)
17.547... logprob:  0.617607, 0.290365 (1.428 sec)
17.548... logprob:  0.668189, 0.289062 (1.438 sec)
17.549... logprob:  0.738769, 0.305990 (1.474 sec)
17.550... logprob:  0.557493, 0.243490 (1.431 sec)
17.551... logprob:  0.660817, 0.286458 (1.431 sec)
17.552... logprob:  0.659642, 0.313802 (1.433 sec)
17.553... logprob:  0.591951, 0.256510 (1.450 sec)
17.554... logprob:  0.728620, 0.292969 (1.435 sec)
17.555... logprob:  0.661688, 0.296875 (1.476 sec)
17.556... logprob:  0.597845, 0.299479 (1.437 sec)
17.557... logprob:  0.685611, 0.290365 (1.444 sec)
17.558... logprob:  0.622561, 0.251302 (1.464 sec)
17.559... logprob:  0.715953, 0.320313 (1.433 sec)
17.560... logprob:  0.642952, 0.302083 (1.437 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.551619, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.094433e-03 [2.048577e-07] 
Layer 'conv1' biases: 1.919529e-06 [2.174471e-10] 
Layer 'conv2' weights[0]: 4.086732e-03 [2.046751e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.402699e-09] 
Layer 'conv3' weights[0]: 4.085319e-03 [2.053340e-07] 
Layer 'conv3' biases: 3.164211e-05 [1.359610e-08] 
Layer 'conv4' weights[0]: 4.102401e-03 [2.065651e-07] 
Layer 'conv4' biases: 9.999727e-01 [2.503282e-07] 
Layer 'conv5' weights[0]: 4.202445e-03 [2.786608e-06] 
Layer 'conv5' biases: 9.990703e-01 [2.976987e-06] 
Layer 'fc6' weights[0]: 7.083248e-03 [6.932805e-08] 
Layer 'fc6' biases: 9.999934e-01 [6.811486e-08] 
Layer 'fc7' weights[0]: 7.434316e-03 [1.628859e-07] 
Layer 'fc7' biases: 9.998175e-01 [2.513290e-07] 
Layer 'fc8' weights[0]: 4.670557e-03 [2.034735e-05] 
Layer 'fc8' biases: 1.428510e-02 [5.218773e-05] 
Train error last 800 batches: 0.657012
-------------------------------------------------------
Not saving because 0.551619 > 0.299667 (9.300: -1.18%)
======================================================= (2.376 sec)
17.561... logprob:  0.630084, 0.260417 (1.442 sec)
17.562... logprob:  0.728170, 0.309896 (1.426 sec)
17.563... logprob:  0.552938, 0.226562 (1.438 sec)
17.564... logprob:  0.701680, 0.295573 (1.461 sec)
17.565... logprob:  0.812643, 0.335937 (1.442 sec)
17.566... logprob:  0.572203, 0.251302 (1.445 sec)
17.567... logprob:  0.603004, 0.281250 (1.453 sec)
17.568... logprob:  0.711926, 0.321615 (1.456 sec)
17.569... logprob:  0.672306, 0.269531 (1.433 sec)
17.570... logprob:  0.757075, 0.324219 (1.424 sec)
17.571... logprob:  0.726166, 0.298177 (1.423 sec)
17.572... logprob:  0.703612, 0.277344 (1.431 sec)
17.573... logprob:  0.660667, 0.308594 (1.440 sec)
17.574... logprob:  0.620133, 0.260417 (1.456 sec)
17.575... logprob:  0.622988, 0.270833 (1.447 sec)
17.576... logprob:  0.654386, 0.313802 (1.446 sec)
17.577... logprob:  0.647593, 0.291667 (1.477 sec)
17.578... logprob:  0.586564, 0.264323 (1.426 sec)
17.579... logprob:  0.650769, 0.285156 (1.420 sec)
17.580... logprob:  0.797026, 0.329427 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.405322, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.090352e-03 [2.048974e-07] 
Layer 'conv1' biases: 1.921651e-06 [1.981617e-10] 
Layer 'conv2' weights[0]: 4.082637e-03 [2.044153e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.927728e-09] 
Layer 'conv3' weights[0]: 4.081238e-03 [2.047747e-07] 
Layer 'conv3' biases: 3.166115e-05 [1.142917e-08] 
Layer 'conv4' weights[0]: 4.098288e-03 [2.059710e-07] 
Layer 'conv4' biases: 9.999718e-01 [1.932895e-07] 
Layer 'conv5' weights[0]: 4.198121e-03 [2.302555e-06] 
Layer 'conv5' biases: 9.990943e-01 [2.497415e-06] 
Layer 'fc6' weights[0]: 7.082543e-03 [6.482435e-08] 
Layer 'fc6' biases: 9.999933e-01 [6.155659e-08] 
Layer 'fc7' weights[0]: 7.433599e-03 [1.487643e-07] 
Layer 'fc7' biases: 9.998148e-01 [1.984375e-07] 
Layer 'fc8' weights[0]: 4.592834e-03 [1.665620e-05] 
Layer 'fc8' biases: 1.367284e-02 [3.374707e-05] 
Train error last 800 batches: 0.657097
-------------------------------------------------------
Not saving because 0.405322 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
17.581... logprob:  0.733056, 0.329427 (1.438 sec)
17.582... logprob:  0.635403, 0.278646 (1.436 sec)
17.583... logprob:  0.773195, 0.315104 (1.475 sec)
17.584... logprob:  0.655126, 0.302083 (1.439 sec)
17.585... logprob:  0.658839, 0.304688 (1.426 sec)
17.586... logprob:  0.537757, 0.243489 (1.483 sec)
17.587... logprob:  0.569804, 0.214844 (1.430 sec)
17.588... logprob:  0.598865, 0.292969 (1.426 sec)
17.589... logprob:  0.610998, 0.281250 (1.427 sec)
17.590... logprob:  0.698138, 0.290365 (1.426 sec)
17.591... logprob:  0.576194, 0.255208 (1.425 sec)
17.592... logprob:  0.748446, 0.337240 (1.478 sec)
17.593... logprob:  0.755426, 0.348958 (1.430 sec)
17.594... logprob:  0.607961, 0.266927 (1.433 sec)
17.595... logprob:  0.651929, 0.287760 (1.476 sec)
17.596... logprob:  0.694917, 0.307292 (1.426 sec)
17.597... logprob:  0.655410, 0.277344 (1.425 sec)
17.598... logprob:  0.692219, 0.299479 (1.432 sec)
17.599... logprob:  0.544599, 0.234375 (1.430 sec)
17.600... logprob:  0.637770, 0.281250 (1.425 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.525544, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.086255e-03 [2.048817e-07] 
Layer 'conv1' biases: 1.922462e-06 [2.241339e-10] 
Layer 'conv2' weights[0]: 4.078557e-03 [2.043306e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.169493e-09] 
Layer 'conv3' weights[0]: 4.077183e-03 [2.049519e-07] 
Layer 'conv3' biases: 3.167275e-05 [1.310412e-08] 
Layer 'conv4' weights[0]: 4.094210e-03 [2.067710e-07] 
Layer 'conv4' biases: 9.999709e-01 [2.736093e-07] 
Layer 'conv5' weights[0]: 4.194258e-03 [2.926992e-06] 
Layer 'conv5' biases: 9.990747e-01 [3.118687e-06] 
Layer 'fc6' weights[0]: 7.081790e-03 [6.491489e-08] 
Layer 'fc6' biases: 9.999933e-01 [6.196193e-08] 
Layer 'fc7' weights[0]: 7.432873e-03 [1.494443e-07] 
Layer 'fc7' biases: 9.998165e-01 [2.084454e-07] 
Layer 'fc8' weights[0]: 4.655980e-03 [1.658210e-05] 
Layer 'fc8' biases: 1.421801e-02 [3.058642e-05] 
Train error last 800 batches: 0.657086
-------------------------------------------------------
Not saving because 0.525544 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
17.601... logprob:  0.616887, 0.283854 (1.485 sec)
17.602... logprob:  0.567813, 0.255208 (1.434 sec)
17.603... logprob:  0.547996, 0.270833 (1.445 sec)
17.604... logprob:  0.617996, 0.303385 (1.474 sec)
17.605... logprob:  0.762031, 0.286458 (1.434 sec)
17.606... logprob:  0.592849, 0.296875 (1.436 sec)
17.607... logprob:  0.681935, 0.308594 (1.426 sec)
17.608... logprob:  0.524490, 0.218750 (1.418 sec)
17.609... logprob:  0.582514, 0.269531 (1.432 sec)
17.610... logprob:  0.643688, 0.270833 (1.472 sec)
17.611... logprob:  0.747981, 0.328125 (1.441 sec)
17.612... logprob:  0.654305, 0.276042 (1.453 sec)
17.613... logprob:  0.541707, 0.266927 (1.460 sec)
17.614... logprob:  0.852337, 0.329427 (1.446 sec)
17.615... logprob:  0.640007, 0.309896 (1.441 sec)
17.616... logprob:  0.612237, 0.283854 (1.431 sec)
17.617... logprob:  0.699555, 0.315104 (1.427 sec)
17.618... logprob:  0.776334, 0.291667 (1.440 sec)
17.619... logprob:  0.599691, 0.247396 (1.445 sec)
17.620... logprob:  0.752505, 0.317708 (1.453 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.371511, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.082168e-03 [2.043103e-07] 
Layer 'conv1' biases: 1.922286e-06 [3.091877e-10] 
Layer 'conv2' weights[0]: 4.074466e-03 [2.041431e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.480894e-09] 
Layer 'conv3' weights[0]: 4.073094e-03 [2.057001e-07] 
Layer 'conv3' biases: 3.171141e-05 [2.052444e-08] 
Layer 'conv4' weights[0]: 4.090097e-03 [2.077511e-07] 
Layer 'conv4' biases: 9.999705e-01 [3.899324e-07] 
Layer 'conv5' weights[0]: 4.189925e-03 [4.049585e-06] 
Layer 'conv5' biases: 9.990759e-01 [4.547964e-06] 
Layer 'fc6' weights[0]: 7.081038e-03 [7.997970e-08] 
Layer 'fc6' biases: 9.999931e-01 [8.345669e-08] 
Layer 'fc7' weights[0]: 7.432144e-03 [1.982604e-07] 
Layer 'fc7' biases: 9.998161e-01 [3.454157e-07] 
Layer 'fc8' weights[0]: 4.651723e-03 [2.240495e-05] 
Layer 'fc8' biases: 1.426443e-02 [5.697620e-05] 
Train error last 800 batches: 0.657120
-------------------------------------------------------
Not saving because 0.371511 > 0.299667 (9.300: -1.18%)
======================================================= (2.338 sec)
17.621... logprob:  0.579503, 0.255208 (1.453 sec)
17.622... logprob:  0.534462, 0.243490 (1.447 sec)
17.623... logprob:  0.676588, 0.303385 (1.463 sec)
17.624... logprob:  0.599178, 0.248698 (1.437 sec)
17.625... logprob:  0.710068, 0.299479 (1.420 sec)
17.626... logprob:  0.643785, 0.260417 (1.423 sec)
17.627... logprob:  0.676529, 0.269531 (1.435 sec)
17.628... logprob:  0.720926, 0.299479 (1.434 sec)
17.629... logprob:  0.647069, 0.277344 (1.470 sec)
17.630... logprob:  0.636746, 0.279948 (1.438 sec)
17.631... logprob:  0.849523, 0.328125 (1.431 sec)
17.632... logprob:  0.612224, 0.285156 (1.478 sec)
17.633... logprob:  0.632008, 0.289062 (1.427 sec)
17.634... logprob:  0.790918, 0.355469 (1.421 sec)
17.635... logprob:  0.617898, 0.276042 (1.429 sec)
17.636... logprob:  0.611576, 0.272135 (1.430 sec)
17.637... logprob:  0.573502, 0.256510 (1.423 sec)
17.638... logprob:  0.704443, 0.308594 (1.476 sec)
17.639... logprob:  0.682608, 0.283854 (1.432 sec)
17.640... logprob:  0.635617, 0.302083 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.422273, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.078098e-03 [2.041374e-07] 
Layer 'conv1' biases: 1.923073e-06 [2.265915e-10] 
Layer 'conv2' weights[0]: 4.070402e-03 [2.037793e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.033013e-09] 
Layer 'conv3' weights[0]: 4.068994e-03 [2.041476e-07] 
Layer 'conv3' biases: 3.173927e-05 [1.171197e-08] 
Layer 'conv4' weights[0]: 4.086030e-03 [2.052659e-07] 
Layer 'conv4' biases: 9.999708e-01 [2.066841e-07] 
Layer 'conv5' weights[0]: 4.186249e-03 [2.122217e-06] 
Layer 'conv5' biases: 9.990956e-01 [2.175228e-06] 
Layer 'fc6' weights[0]: 7.080287e-03 [5.947623e-08] 
Layer 'fc6' biases: 9.999932e-01 [5.397296e-08] 
Layer 'fc7' weights[0]: 7.431410e-03 [1.325047e-07] 
Layer 'fc7' biases: 9.998142e-01 [1.536775e-07] 
Layer 'fc8' weights[0]: 4.590124e-03 [1.322479e-05] 
Layer 'fc8' biases: 1.378649e-02 [1.529574e-05] 
Train error last 800 batches: 0.657051
-------------------------------------------------------
Not saving because 0.422273 > 0.299667 (9.300: -1.18%)
======================================================= (2.360 sec)
17.641... logprob:  0.658738, 0.282552 (1.487 sec)
17.642... logprob:  0.734616, 0.307292 (1.432 sec)
17.643... logprob:  0.776343, 0.354167 (1.427 sec)
17.644... logprob:  0.484454, 0.218750 (1.434 sec)
17.645... logprob:  0.625827, 0.289062 (1.426 sec)
17.646... logprob:  0.669387, 0.296875 (1.425 sec)
17.647... logprob:  0.631804, 0.255208 (1.482 sec)
17.648... logprob:  0.681087, 0.291667 (1.425 sec)
17.649... logprob:  0.632383, 0.278646 (1.439 sec)
17.650... logprob:  0.692550, 0.324219 (1.477 sec)
17.651... logprob:  0.633077, 0.273437 (1.427 sec)
17.652... logprob:  0.674872, 0.295573 (1.437 sec)
17.653... logprob:  0.726052, 0.304688 (1.426 sec)
17.654... logprob:  0.669912, 0.311198 (1.420 sec)
17.655... logprob:  0.716641, 0.315104 (1.426 sec)
17.656... logprob:  0.699360, 0.313802 (1.473 sec)
17.657... logprob:  0.663203, 0.290365 (1.436 sec)
17.658... logprob:  0.590623, 0.253906 (1.445 sec)
17.659... logprob:  0.687467, 0.299479 (1.465 sec)
17.660... logprob:  0.662612, 0.286458 (1.442 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.448089, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.074013e-03 [2.042605e-07] 
Layer 'conv1' biases: 1.925114e-06 [2.794756e-10] 
Layer 'conv2' weights[0]: 4.066339e-03 [2.036350e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.919483e-09] 
Layer 'conv3' weights[0]: 4.064891e-03 [2.041212e-07] 
Layer 'conv3' biases: 3.175200e-05 [1.250891e-08] 
Layer 'conv4' weights[0]: 4.081943e-03 [2.056987e-07] 
Layer 'conv4' biases: 9.999703e-01 [2.501039e-07] 
Layer 'conv5' weights[0]: 4.182224e-03 [2.533262e-06] 
Layer 'conv5' biases: 9.990906e-01 [2.629047e-06] 
Layer 'fc6' weights[0]: 7.079562e-03 [6.469836e-08] 
Layer 'fc6' biases: 9.999931e-01 [6.146166e-08] 
Layer 'fc7' weights[0]: 7.430641e-03 [1.509869e-07] 
Layer 'fc7' biases: 9.998146e-01 [2.074709e-07] 
Layer 'fc8' weights[0]: 4.607229e-03 [1.785320e-05] 
Layer 'fc8' biases: 1.388027e-02 [3.716734e-05] 
Train error last 800 batches: 0.656910
-------------------------------------------------------
Not saving because 0.448089 > 0.299667 (9.300: -1.18%)
======================================================= (2.381 sec)
17.661... logprob:  0.611095, 0.270833 (1.443 sec)
17.662... logprob:  0.693740, 0.303385 (1.433 sec)
17.663... logprob:  0.555737, 0.253906 (1.425 sec)
17.664... logprob:  0.604570, 0.274740 (1.428 sec)
17.665... logprob:  0.683116, 0.302083 (1.454 sec)
17.666... logprob:  0.678073, 0.278646 (1.449 sec)
17.667... logprob:  0.757388, 0.324219 (1.454 sec)
17.668... logprob:  0.719807, 0.317708 (1.447 sec)
17.669... logprob:  0.741766, 0.321615 (1.455 sec)
17.670... logprob:  0.531235, 0.236979 (1.429 sec)
17.671... logprob:  0.660712, 0.289062 (1.420 sec)
17.672... logprob:  0.615278, 0.265625 (1.426 sec)
17.673... logprob:  0.650793, 0.312500 (1.435 sec)
17.674... logprob:  0.676992, 0.303385 (1.438 sec)
17.675... logprob:  0.575596, 0.264323 (1.462 sec)
17.676... logprob:  0.664135, 0.302083 (1.451 sec)
17.677... logprob:  0.672538, 0.343750 (1.435 sec)
17.678... logprob:  0.665720, 0.252604 (1.471 sec)
17.679... logprob:  0.711188, 0.260417 (1.427 sec)
17.680... logprob:  0.571577, 0.253906 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.511703, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.069955e-03 [2.044072e-07] 
Layer 'conv1' biases: 1.925790e-06 [2.625059e-10] 
Layer 'conv2' weights[0]: 4.062269e-03 [2.037485e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.789415e-09] 
Layer 'conv3' weights[0]: 4.060832e-03 [2.045497e-07] 
Layer 'conv3' biases: 3.176892e-05 [1.616292e-08] 
Layer 'conv4' weights[0]: 4.077868e-03 [2.059090e-07] 
Layer 'conv4' biases: 9.999701e-01 [2.715888e-07] 
Layer 'conv5' weights[0]: 4.178290e-03 [2.562418e-06] 
Layer 'conv5' biases: 9.990786e-01 [2.720244e-06] 
Layer 'fc6' weights[0]: 7.078819e-03 [6.201211e-08] 
Layer 'fc6' biases: 9.999931e-01 [5.807712e-08] 
Layer 'fc7' weights[0]: 7.429897e-03 [1.440835e-07] 
Layer 'fc7' biases: 9.998159e-01 [1.863115e-07] 
Layer 'fc8' weights[0]: 4.652078e-03 [1.608995e-05] 
Layer 'fc8' biases: 1.422073e-02 [3.147743e-05] 
Train error last 800 batches: 0.656976
-------------------------------------------------------
Not saving because 0.511703 > 0.299667 (9.300: -1.18%)
======================================================= (2.389 sec)
17.681... logprob:  0.559551, 0.234375 (1.431 sec)
17.682... logprob:  0.540610, 0.220052 (1.431 sec)
17.683... logprob:  0.584035, 0.278646 (1.426 sec)
17.684... logprob:  0.639041, 0.298177 (1.471 sec)
17.685... logprob:  0.527336, 0.242187 (1.439 sec)
17.686... logprob:  0.661110, 0.279948 (1.431 sec)
17.687... logprob:  0.530671, 0.234375 (1.483 sec)
17.688... logprob:  0.668382, 0.300781 (1.426 sec)
17.689... logprob:  0.600869, 0.286458 (1.424 sec)
17.690... logprob:  0.773602, 0.325521 (1.433 sec)
17.691... logprob:  0.758140, 0.324219 (1.430 sec)
17.692... logprob:  0.629556, 0.273438 (1.427 sec)
17.693... logprob:  0.673815, 0.292969 (1.481 sec)
17.694... logprob:  0.621904, 0.274740 (1.434 sec)
17.695... logprob:  0.584366, 0.251302 (1.434 sec)
17.696... logprob:  0.715264, 0.300781 (1.474 sec)
17.697... logprob:  0.655404, 0.282552 (1.428 sec)
17.698... logprob:  0.734730, 0.348958 (1.430 sec)
17.699... logprob:  0.658419, 0.294271 (1.433 sec)
17.700... logprob:  0.693664, 0.300781 (1.422 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.401265, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.065891e-03 [2.036572e-07] 
Layer 'conv1' biases: 1.926086e-06 [2.929241e-10] 
Layer 'conv2' weights[0]: 4.058194e-03 [2.032101e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.827936e-09] 
Layer 'conv3' weights[0]: 4.056796e-03 [2.041874e-07] 
Layer 'conv3' biases: 3.180391e-05 [1.620113e-08] 
Layer 'conv4' weights[0]: 4.073771e-03 [2.068954e-07] 
Layer 'conv4' biases: 9.999708e-01 [3.528958e-07] 
Layer 'conv5' weights[0]: 4.174670e-03 [3.571001e-06] 
Layer 'conv5' biases: 9.990773e-01 [3.944296e-06] 
Layer 'fc6' weights[0]: 7.078100e-03 [7.296434e-08] 
Layer 'fc6' biases: 9.999933e-01 [7.280811e-08] 
Layer 'fc7' weights[0]: 7.429173e-03 [1.735607e-07] 
Layer 'fc7' biases: 9.998155e-01 [2.838743e-07] 
Layer 'fc8' weights[0]: 4.656515e-03 [1.873881e-05] 
Layer 'fc8' biases: 1.431231e-02 [4.537067e-05] 
Train error last 800 batches: 0.656883
-------------------------------------------------------
Not saving because 0.401265 > 0.299667 (9.300: -1.18%)
======================================================= (2.367 sec)
17.701... logprob:  0.700664, 0.320312 (1.439 sec)
17.702... logprob:  0.815878, 0.332031 (1.483 sec)
17.703... logprob:  0.683693, 0.296875 (1.437 sec)
17.704... logprob:  0.711003, 0.296875 (1.442 sec)
17.705... logprob:  0.597740, 0.276042 (1.466 sec)
17.706... logprob:  0.724920, 0.279948 (1.428 sec)
17.707... logprob:  0.759066, 0.309896 (1.431 sec)
17.708... logprob:  0.658788, 0.289062 (1.427 sec)
17.709... logprob:  0.624381, 0.259115 (1.421 sec)
17.710... logprob:  0.734623, 0.313802 (1.440 sec)
17.711... logprob:  0.714316, 0.333333 (1.465 sec)
17.712... logprob:  0.578130, 0.246094 (1.444 sec)
17.713... logprob:  0.729915, 0.320312 (1.447 sec)
17.714... logprob:  0.600212, 0.239583 (1.448 sec)
17.715... logprob:  0.583375, 0.248698 (1.449 sec)
17.716... logprob:  0.648795, 0.286458 (1.434 sec)
17.717... logprob:  0.668212, 0.269531 (1.427 sec)
17.718... logprob:  0.753564, 0.317708 (1.422 sec)
17.719... logprob:  0.706266, 0.326823 (1.428 sec)
17.720... logprob:  0.652532, 0.274740 (1.443 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.524248, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.061812e-03 [2.033450e-07] 
Layer 'conv1' biases: 1.925803e-06 [2.050206e-10] 
Layer 'conv2' weights[0]: 4.054181e-03 [2.029728e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.215049e-09] 
Layer 'conv3' weights[0]: 4.052763e-03 [2.036598e-07] 
Layer 'conv3' biases: 3.186372e-05 [1.414687e-08] 
Layer 'conv4' weights[0]: 4.069727e-03 [2.049660e-07] 
Layer 'conv4' biases: 9.999729e-01 [2.258193e-07] 
Layer 'conv5' weights[0]: 4.171795e-03 [2.414352e-06] 
Layer 'conv5' biases: 9.991179e-01 [2.483983e-06] 
Layer 'fc6' weights[0]: 7.077364e-03 [6.698367e-08] 
Layer 'fc6' biases: 9.999933e-01 [6.390587e-08] 
Layer 'fc7' weights[0]: 7.428441e-03 [1.570401e-07] 
Layer 'fc7' biases: 9.998115e-01 [2.226357e-07] 
Layer 'fc8' weights[0]: 4.546035e-03 [1.860576e-05] 
Layer 'fc8' biases: 1.344798e-02 [4.045229e-05] 
Train error last 800 batches: 0.657802
-------------------------------------------------------
Not saving because 0.524248 > 0.299667 (9.300: -1.18%)
======================================================= (2.383 sec)
17.721... logprob:  0.711442, 0.311198 (1.466 sec)
17.722... logprob:  0.733130, 0.299479 (1.456 sec)
17.723... logprob:  0.632790, 0.282552 (1.447 sec)
17.724... logprob:  0.596920, 0.257812 (1.475 sec)
17.725... logprob:  0.634675, 0.265625 (1.436 sec)
17.726... logprob:  0.683469, 0.307291 (1.426 sec)
17.727... logprob:  0.631854, 0.294271 (1.424 sec)
17.728... logprob:  0.672988, 0.291667 (1.438 sec)
17.729... logprob:  0.595644, 0.274740 (1.433 sec)
17.730... logprob:  0.747683, 0.322917 (1.467 sec)
17.731... logprob:  0.650558, 0.307292 (1.440 sec)
17.732... logprob:  0.598722, 0.296875 (1.428 sec)
17.733... logprob:  0.790704, 0.329427 (1.478 sec)
17.734... logprob:  0.486240, 0.238281 (1.424 sec)
17.735... logprob:  0.648143, 0.315104 (1.428 sec)
17.736... logprob:  0.798886, 0.346354 (1.432 sec)
17.737... logprob:  0.684796, 0.283854 (1.426 sec)
17.738... logprob:  0.674970, 0.287760 (1.432 sec)
17.739... logprob:  0.655411, 0.291667 (1.475 sec)
17.740... logprob:  0.578321, 0.260417 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.567539, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.057758e-03 [2.034397e-07] 
Layer 'conv1' biases: 1.926937e-06 [2.694171e-10] 
Layer 'conv2' weights[0]: 4.050088e-03 [2.029136e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.017695e-09] 
Layer 'conv3' weights[0]: 4.048695e-03 [2.035609e-07] 
Layer 'conv3' biases: 3.186625e-05 [1.373911e-08] 
Layer 'conv4' weights[0]: 4.065635e-03 [2.053646e-07] 
Layer 'conv4' biases: 9.999715e-01 [2.723694e-07] 
Layer 'conv5' weights[0]: 4.167454e-03 [2.562336e-06] 
Layer 'conv5' biases: 9.991001e-01 [2.811830e-06] 
Layer 'fc6' weights[0]: 7.076625e-03 [6.278556e-08] 
Layer 'fc6' biases: 9.999935e-01 [5.819712e-08] 
Layer 'fc7' weights[0]: 7.427725e-03 [1.434938e-07] 
Layer 'fc7' biases: 9.998136e-01 [1.910003e-07] 
Layer 'fc8' weights[0]: 4.643473e-03 [1.503139e-05] 
Layer 'fc8' biases: 1.408843e-02 [2.939175e-05] 
Train error last 800 batches: 0.657594
-------------------------------------------------------
Not saving because 0.567539 > 0.299667 (9.300: -1.18%)
======================================================= (2.388 sec)
17.741... logprob:  0.585605, 0.257812 (1.435 sec)
17.742... logprob:  0.631356, 0.287760 (1.480 sec)
17.743... logprob:  0.649811, 0.281250 (1.433 sec)
17.744... logprob:  0.664821, 0.296875 (1.426 sec)
17.745... logprob:  0.661588, 0.285156 (1.429 sec)
17.746... logprob:  0.744531, 0.303385 (1.425 sec)
17.747... logprob:  0.734240, 0.335937 (1.432 sec)
17.748... logprob:  0.621236, 0.294271 (1.482 sec)
17.749... logprob:  0.586388, 0.240885 (1.425 sec)
17.750... logprob:  0.633787, 0.290365 (1.441 sec)
17.751... logprob:  0.480361, 0.216146 (1.478 sec)
17.752... logprob:  0.733954, 0.319010 (1.430 sec)
17.753... logprob:  0.714012, 0.304687 (1.434 sec)
17.754... logprob:  0.670570, 0.302083 (1.426 sec)
17.755... logprob:  0.669403, 0.298177 (1.423 sec)
17.756... logprob:  0.619631, 0.268229 (1.432 sec)
17.757... logprob:  0.760246, 0.329427 (1.468 sec)
17.758... logprob:  0.607018, 0.295573 (1.441 sec)
17.759... logprob:  0.723940, 0.321615 (1.443 sec)
17.760... logprob:  0.655443, 0.278646 (1.457 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.439500, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.053709e-03 [2.029559e-07] 
Layer 'conv1' biases: 1.927533e-06 [3.079486e-10] 
Layer 'conv2' weights[0]: 4.046023e-03 [2.026536e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.965801e-09] 
Layer 'conv3' weights[0]: 4.044631e-03 [2.034937e-07] 
Layer 'conv3' biases: 3.185787e-05 [1.554096e-08] 
Layer 'conv4' weights[0]: 4.061576e-03 [2.049085e-07] 
Layer 'conv4' biases: 9.999727e-01 [2.750931e-07] 
Layer 'conv5' weights[0]: 4.164038e-03 [2.731756e-06] 
Layer 'conv5' biases: 9.990985e-01 [2.905918e-06] 
Layer 'fc6' weights[0]: 7.075887e-03 [6.849788e-08] 
Layer 'fc6' biases: 9.999934e-01 [6.612549e-08] 
Layer 'fc7' weights[0]: 7.426993e-03 [1.607823e-07] 
Layer 'fc7' biases: 9.998135e-01 [2.405541e-07] 
Layer 'fc8' weights[0]: 4.652686e-03 [1.816409e-05] 
Layer 'fc8' biases: 1.423049e-02 [4.409045e-05] 
Train error last 800 batches: 0.657374
-------------------------------------------------------
Not saving because 0.439500 > 0.299667 (9.300: -1.18%)
======================================================= (2.359 sec)
17.761... logprob:  0.664278, 0.285156 (1.447 sec)
17.762... logprob:  0.679396, 0.311198 (1.439 sec)
17.763... logprob:  0.784789, 0.320312 (1.425 sec)
17.764... logprob:  0.765677, 0.324219 (1.421 sec)
17.765... logprob:  0.516629, 0.248698 (1.431 sec)
17.766... logprob:  0.793906, 0.343750 (1.447 sec)
17.767... logprob:  0.625989, 0.287760 (1.454 sec)
17.768... logprob:  0.710494, 0.333333 (1.463 sec)
17.769... logprob:  0.724754, 0.307292 (1.463 sec)
17.770... logprob:  0.616908, 0.285156 (1.474 sec)
17.771... logprob:  0.842057, 0.393229 (1.447 sec)
17.772... logprob:  0.649715, 0.295573 (1.439 sec)
17.773... logprob:  0.778131, 0.338542 (1.444 sec)
17.774... logprob:  0.610322, 0.259115 (1.451 sec)
17.775... logprob:  0.636891, 0.283854 (1.458 sec)
17.776... logprob:  0.609747, 0.273438 (1.475 sec)
17.777... logprob:  0.680387, 0.296875 (1.470 sec)
17.778... logprob:  0.616873, 0.281250 (1.477 sec)
17.779... logprob:  0.671833, 0.279948 (1.477 sec)
17.780... logprob:  0.691039, 0.312500 (1.450 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.337382, 0.039062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.049658e-03 [2.029081e-07] 
Layer 'conv1' biases: 1.926796e-06 [2.315856e-10] 
Layer 'conv2' weights[0]: 4.041995e-03 [2.024100e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.160175e-09] 
Layer 'conv3' weights[0]: 4.040591e-03 [2.030493e-07] 
Layer 'conv3' biases: 3.181614e-05 [1.306279e-08] 
Layer 'conv4' weights[0]: 4.057515e-03 [2.046986e-07] 
Layer 'conv4' biases: 9.999733e-01 [2.563485e-07] 
Layer 'conv5' weights[0]: 4.160554e-03 [2.559883e-06] 
Layer 'conv5' biases: 9.991127e-01 [2.701292e-06] 
Layer 'fc6' weights[0]: 7.075155e-03 [6.975736e-08] 
Layer 'fc6' biases: 9.999932e-01 [6.727605e-08] 
Layer 'fc7' weights[0]: 7.426287e-03 [1.645644e-07] 
Layer 'fc7' biases: 9.998120e-01 [2.486619e-07] 
Layer 'fc8' weights[0]: 4.612853e-03 [1.956966e-05] 
Layer 'fc8' biases: 1.394501e-02 [4.507048e-05] 
Train error last 800 batches: 0.658131
-------------------------------------------------------
Not saving because 0.337382 > 0.299667 (9.300: -1.18%)
======================================================= (2.352 sec)
17.781... logprob:  0.659742, 0.294271 (1.450 sec)
17.782... logprob:  0.620638, 0.277344 (1.451 sec)
17.783... logprob:  0.701946, 0.303385 (1.456 sec)
17.784... logprob:  0.589955, 0.272135 (1.449 sec)
17.785... logprob:  0.677132, 0.328125 (1.483 sec)
17.786... logprob:  0.718497, 0.299479 (1.471 sec)
17.787... logprob:  0.769088, 0.337240 (1.453 sec)
17.788... logprob:  0.721021, 0.308594 (1.490 sec)
17.789... logprob:  0.531354, 0.217448 (1.454 sec)
17.790... logprob:  0.559053, 0.234375 (1.439 sec)
17.791... logprob:  0.567783, 0.239583 (1.441 sec)
17.792... logprob:  0.640808, 0.308594 (1.457 sec)
17.793... logprob:  0.683456, 0.316406 (1.455 sec)
17.794... logprob:  0.645009, 0.296875 (1.489 sec)
17.795... logprob:  0.688464, 0.299479 (1.460 sec)
17.796... logprob:  0.671130, 0.286458 (1.452 sec)
17.797... logprob:  0.504817, 0.217448 (1.492 sec)
17.798... logprob:  0.571465, 0.240885 (1.443 sec)
17.799... logprob:  0.544066, 0.230469 (1.446 sec)
17.800... logprob:  0.600141, 0.285156 (1.399 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.447196, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.045600e-03 [2.027443e-07] 
Layer 'conv1' biases: 1.928048e-06 [1.898692e-10] 
Layer 'conv2' weights[0]: 4.037965e-03 [2.022321e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.882184e-09] 
Layer 'conv3' weights[0]: 4.036566e-03 [2.027419e-07] 
Layer 'conv3' biases: 3.179598e-05 [1.262329e-08] 
Layer 'conv4' weights[0]: 4.053473e-03 [2.048151e-07] 
Layer 'conv4' biases: 9.999723e-01 [2.463610e-07] 
Layer 'conv5' weights[0]: 4.156481e-03 [2.763141e-06] 
Layer 'conv5' biases: 9.990927e-01 [3.068968e-06] 
Layer 'fc6' weights[0]: 7.074462e-03 [6.700482e-08] 
Layer 'fc6' biases: 9.999931e-01 [6.410405e-08] 
Layer 'fc7' weights[0]: 7.425504e-03 [1.557611e-07] 
Layer 'fc7' biases: 9.998135e-01 [2.410240e-07] 
Layer 'fc8' weights[0]: 4.677985e-03 [1.689023e-05] 
Layer 'fc8' biases: 1.447231e-02 [3.681113e-05] 
Train error last 800 batches: 0.657929
-------------------------------------------------------
Not saving because 0.447196 > 0.299667 (9.300: -1.18%)
======================================================= (2.348 sec)
18.1... logprob:  0.645454, 0.279948 (1.405 sec)
18.2... logprob:  0.663254, 0.307292 (1.450 sec)
18.3... logprob:  0.625840, 0.260417 (1.414 sec)
18.4... logprob:  0.639389, 0.270833 (1.410 sec)
18.5... logprob:  0.603820, 0.269531 (1.443 sec)
18.6... logprob:  0.780146, 0.360677 (1.389 sec)
18.7... logprob:  0.568383, 0.260417 (1.416 sec)
18.8... logprob:  0.656522, 0.319010 (1.394 sec)
18.9... logprob:  0.527782, 0.222656 (1.403 sec)
18.10... logprob:  0.648705, 0.313802 (1.408 sec)
18.11... logprob:  0.614892, 0.313802 (1.440 sec)
18.12... logprob:  0.794775, 0.333333 (1.406 sec)
18.13... logprob:  0.614578, 0.281250 (1.416 sec)
18.14... logprob:  0.646861, 0.266927 (1.398 sec)
18.15... logprob:  0.536075, 0.244792 (1.412 sec)
18.16... logprob:  0.630877, 0.246094 (1.402 sec)
18.17... logprob:  0.642210, 0.294271 (1.396 sec)
18.18... logprob:  0.535666, 0.243489 (1.392 sec)
18.19... logprob:  0.540224, 0.256510 (1.394 sec)
18.20... logprob:  0.642523, 0.283854 (1.390 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.494776, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.041563e-03 [2.028281e-07] 
Layer 'conv1' biases: 1.928480e-06 [1.816248e-10] 
Layer 'conv2' weights[0]: 4.033925e-03 [2.020577e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.138963e-09] 
Layer 'conv3' weights[0]: 4.032527e-03 [2.025831e-07] 
Layer 'conv3' biases: 3.181545e-05 [1.218095e-08] 
Layer 'conv4' weights[0]: 4.049413e-03 [2.040874e-07] 
Layer 'conv4' biases: 9.999721e-01 [2.239961e-07] 
Layer 'conv5' weights[0]: 4.152293e-03 [2.120577e-06] 
Layer 'conv5' biases: 9.990897e-01 [2.261385e-06] 
Layer 'fc6' weights[0]: 7.073729e-03 [5.819532e-08] 
Layer 'fc6' biases: 9.999931e-01 [5.231617e-08] 
Layer 'fc7' weights[0]: 7.424738e-03 [1.305980e-07] 
Layer 'fc7' biases: 9.998134e-01 [1.605038e-07] 
Layer 'fc8' weights[0]: 4.685145e-03 [1.311829e-05] 
Layer 'fc8' biases: 1.460155e-02 [1.814095e-05] 
Train error last 800 batches: 0.657623
-------------------------------------------------------
Not saving because 0.494776 > 0.299667 (9.300: -1.18%)
======================================================= (2.377 sec)
18.21... logprob:  0.676214, 0.289062 (1.401 sec)
18.22... logprob:  0.643865, 0.276042 (1.412 sec)
18.23... logprob:  0.761855, 0.330729 (1.409 sec)
18.24... logprob:  0.600538, 0.272135 (1.411 sec)
18.25... logprob:  0.569734, 0.252604 (1.399 sec)
18.26... logprob:  0.738671, 0.328125 (1.442 sec)
18.27... logprob:  0.649653, 0.292969 (1.391 sec)
18.28... logprob:  0.701728, 0.307292 (1.413 sec)
18.29... logprob:  0.553489, 0.235677 (1.416 sec)
18.30... logprob:  0.623763, 0.287760 (1.415 sec)
18.31... logprob:  0.741321, 0.325521 (1.399 sec)
18.32... logprob:  0.694546, 0.302083 (1.388 sec)
18.33... logprob:  0.709439, 0.303385 (1.439 sec)
18.34... logprob:  0.712383, 0.321615 (1.385 sec)
18.35... logprob:  0.531382, 0.226562 (1.398 sec)
18.36... logprob:  0.767647, 0.309896 (1.403 sec)
18.37... logprob:  0.630153, 0.264323 (1.404 sec)
18.38... logprob:  0.514156, 0.221354 (1.393 sec)
18.39... logprob:  0.857902, 0.337240 (1.431 sec)
18.40... logprob:  0.726350, 0.277344 (1.402 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.447810, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.037522e-03 [2.023120e-07] 
Layer 'conv1' biases: 1.929224e-06 [3.425168e-10] 
Layer 'conv2' weights[0]: 4.029875e-03 [2.018126e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.161054e-09] 
Layer 'conv3' weights[0]: 4.028502e-03 [2.030309e-07] 
Layer 'conv3' biases: 3.183434e-05 [1.865753e-08] 
Layer 'conv4' weights[0]: 4.045383e-03 [2.051211e-07] 
Layer 'conv4' biases: 9.999710e-01 [3.742196e-07] 
Layer 'conv5' weights[0]: 4.148140e-03 [4.040560e-06] 
Layer 'conv5' biases: 9.991110e-01 [4.380665e-06] 
Layer 'fc6' weights[0]: 7.073012e-03 [8.593468e-08] 
Layer 'fc6' biases: 9.999931e-01 [9.101422e-08] 
Layer 'fc7' weights[0]: 7.423996e-03 [2.120408e-07] 
Layer 'fc7' biases: 9.998118e-01 [3.803798e-07] 
Layer 'fc8' weights[0]: 4.629028e-03 [2.449737e-05] 
Layer 'fc8' biases: 1.414356e-02 [6.464719e-05] 
Train error last 800 batches: 0.657854
-------------------------------------------------------
Not saving because 0.447810 > 0.299667 (9.300: -1.18%)
======================================================= (2.336 sec)
18.41... logprob:  0.670394, 0.317708 (1.429 sec)
18.42... logprob:  0.640926, 0.295573 (1.418 sec)
18.43... logprob:  0.601440, 0.268229 (1.407 sec)
18.44... logprob:  0.718991, 0.326823 (1.433 sec)
18.45... logprob:  0.619460, 0.294271 (1.386 sec)
18.46... logprob:  0.717648, 0.320312 (1.392 sec)
18.47... logprob:  0.547357, 0.246094 (1.390 sec)
18.48... logprob:  0.660647, 0.270833 (1.415 sec)
18.49... logprob:  0.676021, 0.303385 (1.411 sec)
18.50... logprob:  0.618189, 0.246094 (1.421 sec)
18.51... logprob:  0.663703, 0.289062 (1.408 sec)
18.52... logprob:  0.684912, 0.294271 (1.397 sec)
18.53... logprob:  0.586473, 0.269531 (1.437 sec)
18.54... logprob:  0.716905, 0.317708 (1.380 sec)
18.55... logprob:  0.529563, 0.220052 (1.395 sec)
18.56... logprob:  0.682789, 0.283854 (1.392 sec)
18.57... logprob:  0.731996, 0.298177 (1.423 sec)
18.58... logprob:  0.621427, 0.291667 (1.398 sec)
18.59... logprob:  0.696562, 0.300781 (1.472 sec)
18.60... logprob:  0.845254, 0.346354 (1.419 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.454434, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.033490e-03 [2.018680e-07] 
Layer 'conv1' biases: 1.929885e-06 [3.975644e-10] 
Layer 'conv2' weights[0]: 4.025875e-03 [2.016212e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.369211e-09] 
Layer 'conv3' weights[0]: 4.024473e-03 [2.029766e-07] 
Layer 'conv3' biases: 3.182684e-05 [1.793944e-08] 
Layer 'conv4' weights[0]: 4.041325e-03 [2.043173e-07] 
Layer 'conv4' biases: 9.999707e-01 [3.043177e-07] 
Layer 'conv5' weights[0]: 4.144222e-03 [2.777355e-06] 
Layer 'conv5' biases: 9.991126e-01 [3.075086e-06] 
Layer 'fc6' weights[0]: 7.072230e-03 [6.303826e-08] 
Layer 'fc6' biases: 9.999931e-01 [5.840382e-08] 
Layer 'fc7' weights[0]: 7.423285e-03 [1.447421e-07] 
Layer 'fc7' biases: 9.998112e-01 [1.704253e-07] 
Layer 'fc8' weights[0]: 4.627453e-03 [1.384640e-05] 
Layer 'fc8' biases: 1.412249e-02 [1.053913e-05] 
Train error last 800 batches: 0.657938
-------------------------------------------------------
Not saving because 0.454434 > 0.299667 (9.300: -1.18%)
======================================================= (2.390 sec)
18.61... logprob:  0.613843, 0.291667 (1.436 sec)
18.62... logprob:  0.692134, 0.307292 (1.456 sec)
18.63... logprob:  0.590050, 0.287760 (1.437 sec)
18.64... logprob:  0.697600, 0.291667 (1.411 sec)
18.65... logprob:  0.567742, 0.223958 (1.397 sec)
18.66... logprob:  0.547645, 0.236979 (1.439 sec)
18.67... logprob:  0.618014, 0.292969 (1.384 sec)
18.68... logprob:  0.621193, 0.300781 (1.391 sec)
18.69... logprob:  0.718885, 0.296875 (1.414 sec)
18.70... logprob:  0.598416, 0.292969 (1.425 sec)
18.71... logprob:  0.707430, 0.296875 (1.461 sec)
18.72... logprob:  0.621609, 0.247396 (1.402 sec)
18.73... logprob:  0.625058, 0.259115 (1.415 sec)
18.74... logprob:  0.580873, 0.286458 (1.415 sec)
18.75... logprob:  0.629321, 0.286458 (1.414 sec)
18.76... logprob:  0.654777, 0.307292 (1.430 sec)
18.77... logprob:  0.737711, 0.305990 (1.423 sec)
18.78... logprob:  0.641711, 0.320312 (1.448 sec)
18.79... logprob:  0.707286, 0.305990 (1.411 sec)
18.80... logprob:  0.641029, 0.261719 (1.411 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.498540, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.029473e-03 [2.016786e-07] 
Layer 'conv1' biases: 1.929330e-06 [2.268568e-10] 
Layer 'conv2' weights[0]: 4.021869e-03 [2.013154e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.854423e-09] 
Layer 'conv3' weights[0]: 4.020450e-03 [2.019383e-07] 
Layer 'conv3' biases: 3.183589e-05 [1.267936e-08] 
Layer 'conv4' weights[0]: 4.037277e-03 [2.029265e-07] 
Layer 'conv4' biases: 9.999696e-01 [2.172236e-07] 
Layer 'conv5' weights[0]: 4.140035e-03 [2.285079e-06] 
Layer 'conv5' biases: 9.990967e-01 [2.413525e-06] 
Layer 'fc6' weights[0]: 7.071497e-03 [6.064928e-08] 
Layer 'fc6' biases: 9.999930e-01 [5.571360e-08] 
Layer 'fc7' weights[0]: 7.422552e-03 [1.381495e-07] 
Layer 'fc7' biases: 9.998127e-01 [1.672154e-07] 
Layer 'fc8' weights[0]: 4.687016e-03 [1.340727e-05] 
Layer 'fc8' biases: 1.459274e-02 [1.605033e-05] 
Train error last 800 batches: 0.657888
-------------------------------------------------------
Not saving because 0.498540 > 0.299667 (9.300: -1.18%)
======================================================= (2.385 sec)
18.81... logprob:  0.630343, 0.287760 (1.419 sec)
18.82... logprob:  0.536608, 0.274739 (1.421 sec)
18.83... logprob:  0.661965, 0.295573 (1.407 sec)
18.84... logprob:  0.585284, 0.233073 (1.458 sec)
18.85... logprob:  0.667532, 0.265625 (1.418 sec)
18.86... logprob:  0.563870, 0.240885 (1.415 sec)
18.87... logprob:  0.855854, 0.315104 (1.412 sec)
18.88... logprob:  0.859010, 0.386719 (1.403 sec)
18.89... logprob:  0.547048, 0.250000 (1.428 sec)
18.90... logprob:  0.789882, 0.326823 (1.381 sec)
18.91... logprob:  0.594696, 0.285156 (1.389 sec)
18.92... logprob:  0.724802, 0.324219 (1.397 sec)
18.93... logprob:  0.685787, 0.303385 (1.394 sec)
18.94... logprob:  0.602774, 0.266927 (1.399 sec)
18.95... logprob:  0.701383, 0.287760 (1.400 sec)
18.96... logprob:  0.711275, 0.302083 (1.400 sec)
18.97... logprob:  0.739686, 0.312500 (1.387 sec)
18.98... logprob:  0.635761, 0.278646 (1.430 sec)
18.99... logprob:  0.685433, 0.305990 (1.430 sec)
18.100... logprob:  0.568946, 0.268229 (1.401 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.486037, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.025461e-03 [2.017719e-07] 
Layer 'conv1' biases: 1.928791e-06 [2.726057e-10] 
Layer 'conv2' weights[0]: 4.017812e-03 [2.011369e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.261579e-09] 
Layer 'conv3' weights[0]: 4.016433e-03 [2.018580e-07] 
Layer 'conv3' biases: 3.190416e-05 [1.354513e-08] 
Layer 'conv4' weights[0]: 4.033236e-03 [2.033124e-07] 
Layer 'conv4' biases: 9.999697e-01 [2.420552e-07] 
Layer 'conv5' weights[0]: 4.136137e-03 [2.453440e-06] 
Layer 'conv5' biases: 9.991237e-01 [2.674361e-06] 
Layer 'fc6' weights[0]: 7.070757e-03 [6.365875e-08] 
Layer 'fc6' biases: 9.999930e-01 [5.923431e-08] 
Layer 'fc7' weights[0]: 7.421783e-03 [1.484824e-07] 
Layer 'fc7' biases: 9.998105e-01 [2.053630e-07] 
Layer 'fc8' weights[0]: 4.606588e-03 [1.680573e-05] 
Layer 'fc8' biases: 1.412311e-02 [4.007058e-05] 
Train error last 800 batches: 0.657890
-------------------------------------------------------
Not saving because 0.486037 > 0.299667 (9.300: -1.18%)
======================================================= (2.368 sec)
18.101... logprob:  0.593101, 0.250000 (1.440 sec)
18.102... logprob:  0.733110, 0.304687 (1.384 sec)
18.103... logprob:  0.744164, 0.308594 (1.392 sec)
18.104... logprob:  0.565399, 0.220052 (1.398 sec)
18.105... logprob:  0.794096, 0.348958 (1.394 sec)
18.106... logprob:  0.565347, 0.247396 (1.386 sec)
18.107... logprob:  0.598579, 0.252604 (1.433 sec)
18.108... logprob:  0.700286, 0.292969 (1.387 sec)
18.109... logprob:  0.583343, 0.270833 (1.395 sec)
18.110... logprob:  0.746524, 0.325521 (1.391 sec)
18.111... logprob:  0.630818, 0.287760 (1.388 sec)
18.112... logprob:  0.666594, 0.295573 (1.396 sec)
18.113... logprob:  0.636612, 0.264323 (1.396 sec)
18.114... logprob:  0.685625, 0.316406 (1.429 sec)
18.115... logprob:  0.676685, 0.290365 (1.401 sec)
18.116... logprob:  0.595126, 0.253906 (1.396 sec)
18.117... logprob:  0.736781, 0.307292 (1.438 sec)
18.118... logprob:  0.672515, 0.305990 (1.379 sec)
18.119... logprob:  0.621541, 0.285156 (1.394 sec)
18.120... logprob:  0.753643, 0.303385 (1.395 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.459031, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.021422e-03 [2.014750e-07] 
Layer 'conv1' biases: 1.930584e-06 [2.728330e-10] 
Layer 'conv2' weights[0]: 4.013832e-03 [2.009784e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.076443e-09] 
Layer 'conv3' weights[0]: 4.012420e-03 [2.015004e-07] 
Layer 'conv3' biases: 3.191189e-05 [1.269982e-08] 
Layer 'conv4' weights[0]: 4.029209e-03 [2.029544e-07] 
Layer 'conv4' biases: 9.999696e-01 [2.348857e-07] 
Layer 'conv5' weights[0]: 4.132550e-03 [2.397740e-06] 
Layer 'conv5' biases: 9.991088e-01 [2.584851e-06] 
Layer 'fc6' weights[0]: 7.070009e-03 [5.996306e-08] 
Layer 'fc6' biases: 9.999929e-01 [5.406086e-08] 
Layer 'fc7' weights[0]: 7.421051e-03 [1.362361e-07] 
Layer 'fc7' biases: 9.998107e-01 [1.527327e-07] 
Layer 'fc8' weights[0]: 4.619683e-03 [1.285357e-05] 
Layer 'fc8' biases: 1.431136e-02 [5.414767e-06] 
Train error last 800 batches: 0.657954
-------------------------------------------------------
Not saving because 0.459031 > 0.299667 (9.300: -1.18%)
======================================================= (2.375 sec)
18.121... logprob:  0.636614, 0.283854 (1.397 sec)
18.122... logprob:  0.692983, 0.300781 (1.447 sec)
18.123... logprob:  0.596653, 0.253906 (1.379 sec)
18.124... logprob:  0.683205, 0.287760 (1.397 sec)
18.125... logprob:  0.628656, 0.277344 (1.398 sec)
18.126... logprob:  0.673300, 0.278646 (1.388 sec)
18.127... logprob:  0.636218, 0.283854 (1.394 sec)
18.128... logprob:  0.555402, 0.242188 (1.412 sec)
18.129... logprob:  0.805751, 0.352865 (1.421 sec)
18.130... logprob:  0.576174, 0.270833 (1.411 sec)
18.131... logprob:  0.683011, 0.291667 (1.403 sec)
18.132... logprob:  0.781592, 0.320312 (1.429 sec)
18.133... logprob:  0.657443, 0.281250 (1.382 sec)
18.134... logprob:  0.621854, 0.273438 (1.387 sec)
18.135... logprob:  0.572002, 0.250000 (1.399 sec)
18.136... logprob:  0.706973, 0.290365 (1.393 sec)
18.137... logprob:  0.632023, 0.264323 (1.384 sec)
18.138... logprob:  0.551240, 0.257812 (1.446 sec)
18.139... logprob:  0.645243, 0.277344 (1.397 sec)
18.140... logprob:  0.767238, 0.356771 (1.404 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.506422, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.017402e-03 [2.011939e-07] 
Layer 'conv1' biases: 1.932282e-06 [2.306277e-10] 
Layer 'conv2' weights[0]: 4.009806e-03 [2.007003e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.890293e-09] 
Layer 'conv3' weights[0]: 4.008415e-03 [2.010966e-07] 
Layer 'conv3' biases: 3.194978e-05 [1.117428e-08] 
Layer 'conv4' weights[0]: 4.025200e-03 [2.023516e-07] 
Layer 'conv4' biases: 9.999703e-01 [2.202771e-07] 
Layer 'conv5' weights[0]: 4.128899e-03 [2.165087e-06] 
Layer 'conv5' biases: 9.991149e-01 [2.377255e-06] 
Layer 'fc6' weights[0]: 7.069266e-03 [6.095192e-08] 
Layer 'fc6' biases: 9.999931e-01 [5.536923e-08] 
Layer 'fc7' weights[0]: 7.420305e-03 [1.365311e-07] 
Layer 'fc7' biases: 9.998100e-01 [1.619862e-07] 
Layer 'fc8' weights[0]: 4.608913e-03 [1.293595e-05] 
Layer 'fc8' biases: 1.423113e-02 [1.226726e-05] 
Train error last 800 batches: 0.657396
-------------------------------------------------------
Not saving because 0.506422 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
18.141... logprob:  0.671704, 0.260417 (1.435 sec)
18.142... logprob:  0.696234, 0.291667 (1.397 sec)
18.143... logprob:  0.513202, 0.199219 (1.419 sec)
18.144... logprob:  0.698492, 0.305989 (1.413 sec)
18.145... logprob:  0.623762, 0.286458 (1.415 sec)
18.146... logprob:  0.671373, 0.311198 (1.402 sec)
18.147... logprob:  0.600643, 0.285156 (1.426 sec)
18.148... logprob:  0.672049, 0.303385 (1.382 sec)
18.149... logprob:  0.600283, 0.285156 (1.393 sec)
18.150... logprob:  0.618823, 0.289062 (1.399 sec)
18.151... logprob:  0.609770, 0.285156 (1.391 sec)
18.152... logprob:  0.823703, 0.343750 (1.387 sec)
18.153... logprob:  0.616209, 0.291667 (1.443 sec)
18.154... logprob:  0.682186, 0.283854 (1.396 sec)
18.155... logprob:  0.589127, 0.225260 (1.406 sec)
18.156... logprob:  0.530395, 0.221354 (1.431 sec)
18.157... logprob:  0.570274, 0.233073 (1.389 sec)
18.158... logprob:  0.554609, 0.242187 (1.398 sec)
18.159... logprob:  0.647549, 0.257812 (1.390 sec)
18.160... logprob:  0.688197, 0.303385 (1.390 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.400260, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.013377e-03 [2.013116e-07] 
Layer 'conv1' biases: 1.933737e-06 [2.322965e-10] 
Layer 'conv2' weights[0]: 4.005778e-03 [2.007620e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.272705e-09] 
Layer 'conv3' weights[0]: 4.004404e-03 [2.013860e-07] 
Layer 'conv3' biases: 3.195181e-05 [1.446238e-08] 
Layer 'conv4' weights[0]: 4.021189e-03 [2.031058e-07] 
Layer 'conv4' biases: 9.999695e-01 [2.669665e-07] 
Layer 'conv5' weights[0]: 4.124922e-03 [2.512672e-06] 
Layer 'conv5' biases: 9.990997e-01 [2.730060e-06] 
Layer 'fc6' weights[0]: 7.068569e-03 [6.472573e-08] 
Layer 'fc6' biases: 9.999930e-01 [6.076645e-08] 
Layer 'fc7' weights[0]: 7.419560e-03 [1.507435e-07] 
Layer 'fc7' biases: 9.998111e-01 [2.098221e-07] 
Layer 'fc8' weights[0]: 4.658182e-03 [1.741016e-05] 
Layer 'fc8' biases: 1.454056e-02 [4.181071e-05] 
Train error last 800 batches: 0.657160
-------------------------------------------------------
Not saving because 0.400260 > 0.299667 (9.300: -1.18%)
======================================================= (2.404 sec)
18.161... logprob:  0.617107, 0.278646 (1.397 sec)
18.162... logprob:  0.760478, 0.329427 (1.400 sec)
18.163... logprob:  0.680882, 0.302083 (1.421 sec)
18.164... logprob:  0.636204, 0.277344 (1.421 sec)
18.165... logprob:  0.788618, 0.325521 (1.417 sec)
18.166... logprob:  0.741428, 0.291667 (1.446 sec)
18.167... logprob:  0.641689, 0.303385 (1.429 sec)
18.168... logprob:  0.572183, 0.266927 (1.419 sec)
18.169... logprob:  0.572054, 0.250000 (1.460 sec)
18.170... logprob:  0.666831, 0.290365 (1.401 sec)
18.171... logprob:  0.746353, 0.328125 (1.413 sec)
18.172... logprob:  0.665492, 0.272135 (1.412 sec)
18.173... logprob:  0.711787, 0.285156 (1.416 sec)
18.174... logprob:  0.807991, 0.333333 (1.394 sec)
18.175... logprob:  0.725197, 0.324219 (1.461 sec)
18.176... logprob:  0.647426, 0.294271 (1.409 sec)
18.177... logprob:  0.525061, 0.234375 (1.445 sec)
18.178... logprob:  0.568424, 0.247396 (1.451 sec)
18.179... logprob:  0.632066, 0.269531 (1.402 sec)
18.180... logprob:  0.671947, 0.290365 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.485333, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.009376e-03 [2.009477e-07] 
Layer 'conv1' biases: 1.934699e-06 [2.217508e-10] 
Layer 'conv2' weights[0]: 4.001810e-03 [2.003600e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.112717e-09] 
Layer 'conv3' weights[0]: 4.000410e-03 [2.009206e-07] 
Layer 'conv3' biases: 3.198833e-05 [1.293850e-08] 
Layer 'conv4' weights[0]: 4.017169e-03 [2.022208e-07] 
Layer 'conv4' biases: 9.999685e-01 [2.321702e-07] 
Layer 'conv5' weights[0]: 4.120408e-03 [2.344193e-06] 
Layer 'conv5' biases: 9.991162e-01 [2.436183e-06] 
Layer 'fc6' weights[0]: 7.067823e-03 [6.128281e-08] 
Layer 'fc6' biases: 9.999929e-01 [5.602648e-08] 
Layer 'fc7' weights[0]: 7.418820e-03 [1.427094e-07] 
Layer 'fc7' biases: 9.998097e-01 [1.852392e-07] 
Layer 'fc8' weights[0]: 4.611251e-03 [1.553003e-05] 
Layer 'fc8' biases: 1.415330e-02 [3.012825e-05] 
Train error last 800 batches: 0.657015
-------------------------------------------------------
Not saving because 0.485333 > 0.299667 (9.300: -1.18%)
======================================================= (2.385 sec)
18.181... logprob:  0.793243, 0.352865 (1.420 sec)
18.182... logprob:  0.622424, 0.285156 (1.418 sec)
18.183... logprob:  0.606201, 0.252604 (1.544 sec)
18.184... logprob:  0.606796, 0.273437 (1.415 sec)
18.185... logprob:  0.550475, 0.240885 (1.397 sec)
18.186... logprob:  0.530613, 0.222656 (1.400 sec)
18.187... logprob:  0.740874, 0.325521 (1.400 sec)
18.188... logprob:  0.674285, 0.299479 (1.389 sec)
18.189... logprob:  0.630974, 0.277344 (1.384 sec)
18.190... logprob:  0.650609, 0.277344 (1.431 sec)
18.191... logprob:  0.788222, 0.329427 (1.407 sec)
18.192... logprob:  0.777669, 0.317708 (1.407 sec)
18.193... logprob:  0.609162, 0.259115 (1.414 sec)
18.194... logprob:  0.654269, 0.308594 (1.407 sec)
18.195... logprob:  0.491216, 0.229167 (1.395 sec)
18.196... logprob:  0.620854, 0.285156 (1.393 sec)
18.197... logprob:  0.638923, 0.246094 (1.396 sec)
18.198... logprob:  0.603748, 0.261719 (1.402 sec)
18.199... logprob:  0.665167, 0.295573 (1.474 sec)
18.200... logprob:  0.644441, 0.287760 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.461888, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.005368e-03 [2.010122e-07] 
Layer 'conv1' biases: 1.934346e-06 [1.659615e-10] 
Layer 'conv2' weights[0]: 3.997798e-03 [2.003277e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.651327e-09] 
Layer 'conv3' weights[0]: 3.996411e-03 [2.005048e-07] 
Layer 'conv3' biases: 3.202813e-05 [1.026242e-08] 
Layer 'conv4' weights[0]: 4.013110e-03 [2.020977e-07] 
Layer 'conv4' biases: 9.999657e-01 [2.028357e-07] 
Layer 'conv5' weights[0]: 4.114974e-03 [2.373180e-06] 
Layer 'conv5' biases: 9.991089e-01 [2.552452e-06] 
Layer 'fc6' weights[0]: 7.067109e-03 [6.129016e-08] 
Layer 'fc6' biases: 9.999929e-01 [5.594129e-08] 
Layer 'fc7' weights[0]: 7.418132e-03 [1.382589e-07] 
Layer 'fc7' biases: 9.998106e-01 [1.699340e-07] 
Layer 'fc8' weights[0]: 4.644689e-03 [1.348543e-05] 
Layer 'fc8' biases: 1.436237e-02 [2.133627e-05] 
Train error last 800 batches: 0.656925
-------------------------------------------------------
Not saving because 0.461888 > 0.299667 (9.300: -1.18%)
======================================================= (2.360 sec)
18.201... logprob:  0.616331, 0.259115 (1.405 sec)
18.202... logprob:  0.742777, 0.334635 (1.399 sec)
18.203... logprob:  0.583112, 0.257812 (1.439 sec)
18.204... logprob:  0.673845, 0.291667 (1.386 sec)
18.205... logprob:  0.595454, 0.282552 (1.400 sec)
18.206... logprob:  0.595860, 0.263021 (1.398 sec)
18.207... logprob:  0.566057, 0.256510 (1.391 sec)
18.208... logprob:  0.649587, 0.277344 (1.395 sec)
18.209... logprob:  0.520815, 0.236979 (1.416 sec)
18.210... logprob:  0.674288, 0.294271 (1.409 sec)
18.211... logprob:  0.749789, 0.356771 (1.411 sec)
18.212... logprob:  0.691822, 0.313802 (1.409 sec)
18.213... logprob:  0.769267, 0.333333 (1.453 sec)
18.214... logprob:  0.757255, 0.311198 (1.423 sec)
18.215... logprob:  0.739273, 0.335937 (1.415 sec)
18.216... logprob:  0.749580, 0.292969 (1.477 sec)
18.217... logprob:  0.519685, 0.231771 (1.397 sec)
18.218... logprob:  0.625583, 0.277344 (1.414 sec)
18.219... logprob:  0.716505, 0.287760 (1.407 sec)
18.220... logprob:  0.673920, 0.278646 (1.416 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.471621, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 4.001379e-03 [2.003120e-07] 
Layer 'conv1' biases: 1.934833e-06 [2.440435e-10] 
Layer 'conv2' weights[0]: 3.993797e-03 [1.999035e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.271064e-09] 
Layer 'conv3' weights[0]: 3.992403e-03 [2.006424e-07] 
Layer 'conv3' biases: 3.203072e-05 [1.385800e-08] 
Layer 'conv4' weights[0]: 4.009106e-03 [2.021277e-07] 
Layer 'conv4' biases: 9.999648e-01 [2.530265e-07] 
Layer 'conv5' weights[0]: 4.110511e-03 [2.898352e-06] 
Layer 'conv5' biases: 9.991037e-01 [3.147453e-06] 
Layer 'fc6' weights[0]: 7.066401e-03 [6.737509e-08] 
Layer 'fc6' biases: 9.999928e-01 [6.472459e-08] 
Layer 'fc7' weights[0]: 7.417369e-03 [1.575539e-07] 
Layer 'fc7' biases: 9.998113e-01 [2.202980e-07] 
Layer 'fc8' weights[0]: 4.657746e-03 [1.621501e-05] 
Layer 'fc8' biases: 1.453038e-02 [2.862564e-05] 
Train error last 800 batches: 0.657081
-------------------------------------------------------
Not saving because 0.471621 > 0.299667 (9.300: -1.18%)
======================================================= (2.414 sec)
18.221... logprob:  0.658530, 0.321615 (1.416 sec)
18.222... logprob:  0.721910, 0.315104 (1.460 sec)
18.223... logprob:  0.644658, 0.294271 (1.425 sec)
18.224... logprob:  0.626130, 0.290365 (1.432 sec)
18.225... logprob:  0.598786, 0.255208 (1.440 sec)
18.226... logprob:  0.628474, 0.285156 (1.416 sec)
18.227... logprob:  0.659331, 0.283854 (1.409 sec)
18.228... logprob:  0.650135, 0.282552 (1.410 sec)
18.229... logprob:  0.686102, 0.296875 (1.411 sec)
18.230... logprob:  0.698737, 0.300781 (1.429 sec)
18.231... logprob:  0.683869, 0.305990 (1.402 sec)
18.232... logprob:  0.665308, 0.270833 (1.456 sec)
18.233... logprob:  0.724002, 0.329427 (1.419 sec)
18.234... logprob:  0.800116, 0.332031 (1.412 sec)
18.235... logprob:  0.584352, 0.236979 (1.461 sec)
18.236... logprob:  0.649091, 0.250000 (1.395 sec)
18.237... logprob:  0.568190, 0.260417 (1.416 sec)
18.238... logprob:  0.601749, 0.282552 (1.411 sec)
18.239... logprob:  0.636117, 0.291667 (1.419 sec)
18.240... logprob:  0.673754, 0.298177 (1.406 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.489823, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.997370e-03 [2.002660e-07] 
Layer 'conv1' biases: 1.934099e-06 [2.015864e-10] 
Layer 'conv2' weights[0]: 3.989793e-03 [1.997836e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.012418e-09] 
Layer 'conv3' weights[0]: 3.988423e-03 [2.001098e-07] 
Layer 'conv3' biases: 3.202405e-05 [1.162730e-08] 
Layer 'conv4' weights[0]: 4.005132e-03 [2.015228e-07] 
Layer 'conv4' biases: 9.999659e-01 [2.079368e-07] 
Layer 'conv5' weights[0]: 4.107274e-03 [2.231619e-06] 
Layer 'conv5' biases: 9.991062e-01 [2.452635e-06] 
Layer 'fc6' weights[0]: 7.065646e-03 [6.017504e-08] 
Layer 'fc6' biases: 9.999930e-01 [5.476540e-08] 
Layer 'fc7' weights[0]: 7.416664e-03 [1.353061e-07] 
Layer 'fc7' biases: 9.998101e-01 [1.563693e-07] 
Layer 'fc8' weights[0]: 4.629907e-03 [1.294986e-05] 
Layer 'fc8' biases: 1.430181e-02 [1.360951e-05] 
Train error last 800 batches: 0.656546
-------------------------------------------------------
Not saving because 0.489823 > 0.299667 (9.300: -1.18%)
======================================================= (2.372 sec)
18.241... logprob:  0.591566, 0.242188 (1.465 sec)
18.242... logprob:  0.570969, 0.250000 (1.423 sec)
18.243... logprob:  0.648795, 0.304688 (1.437 sec)
18.244... logprob:  0.590511, 0.287760 (1.444 sec)
18.245... logprob:  0.751351, 0.330729 (1.418 sec)
18.246... logprob:  0.603891, 0.261719 (1.404 sec)
18.247... logprob:  0.628468, 0.282552 (1.416 sec)
18.248... logprob:  0.627355, 0.287760 (1.415 sec)
18.249... logprob:  0.818751, 0.348958 (1.416 sec)
18.250... logprob:  0.734429, 0.324219 (1.402 sec)
18.251... logprob:  0.697610, 0.305989 (1.458 sec)
18.252... logprob:  0.537851, 0.243490 (1.421 sec)
18.253... logprob:  0.625952, 0.286458 (1.417 sec)
18.254... logprob:  0.598367, 0.281250 (1.460 sec)
18.255... logprob:  0.561015, 0.259115 (1.412 sec)
18.256... logprob:  0.593678, 0.270833 (1.416 sec)
18.257... logprob:  0.606449, 0.296875 (1.409 sec)
18.258... logprob:  0.641876, 0.308594 (1.414 sec)
18.259... logprob:  0.659674, 0.292969 (1.391 sec)
18.260... logprob:  0.519219, 0.235677 (1.455 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.576617, 0.171875 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.993383e-03 [2.000617e-07] 
Layer 'conv1' biases: 1.934167e-06 [2.665588e-10] 
Layer 'conv2' weights[0]: 3.985801e-03 [1.995978e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.535214e-09] 
Layer 'conv3' weights[0]: 3.984443e-03 [2.002507e-07] 
Layer 'conv3' biases: 3.202288e-05 [1.408482e-08] 
Layer 'conv4' weights[0]: 4.001116e-03 [2.019210e-07] 
Layer 'conv4' biases: 9.999665e-01 [2.653528e-07] 
Layer 'conv5' weights[0]: 4.103837e-03 [2.818212e-06] 
Layer 'conv5' biases: 9.990824e-01 [3.020469e-06] 
Layer 'fc6' weights[0]: 7.064898e-03 [6.740472e-08] 
Layer 'fc6' biases: 9.999930e-01 [6.467939e-08] 
Layer 'fc7' weights[0]: 7.415908e-03 [1.560466e-07] 
Layer 'fc7' biases: 9.998119e-01 [2.463905e-07] 
Layer 'fc8' weights[0]: 4.695363e-03 [1.718267e-05] 
Layer 'fc8' biases: 1.483298e-02 [4.488502e-05] 
Train error last 800 batches: 0.656724
-------------------------------------------------------
Not saving because 0.576617 > 0.299667 (9.300: -1.18%)
======================================================= (2.367 sec)
18.261... logprob:  0.652450, 0.292969 (1.432 sec)
18.262... logprob:  0.703906, 0.303385 (1.440 sec)
18.263... logprob:  0.605997, 0.260417 (1.443 sec)
18.264... logprob:  0.502255, 0.252604 (1.418 sec)
18.265... logprob:  0.662412, 0.283854 (1.416 sec)
18.266... logprob:  0.675202, 0.300781 (1.410 sec)
18.267... logprob:  0.592708, 0.286458 (1.411 sec)
18.268... logprob:  0.701394, 0.302083 (1.421 sec)
18.269... logprob:  0.847752, 0.346354 (1.402 sec)
18.270... logprob:  0.799680, 0.345052 (1.453 sec)
18.271... logprob:  0.681791, 0.287760 (1.426 sec)
18.272... logprob:  0.653077, 0.279948 (1.413 sec)
18.273... logprob:  0.650990, 0.298177 (1.466 sec)
18.274... logprob:  0.735891, 0.309896 (1.394 sec)
18.275... logprob:  0.643161, 0.281250 (1.414 sec)
18.276... logprob:  0.487018, 0.225260 (1.413 sec)
18.277... logprob:  0.610369, 0.259114 (1.422 sec)
18.278... logprob:  0.541572, 0.243490 (1.418 sec)
18.279... logprob:  0.556275, 0.255208 (1.454 sec)
18.280... logprob:  0.490550, 0.246094 (1.402 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.468997, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.989375e-03 [1.999446e-07] 
Layer 'conv1' biases: 1.935710e-06 [2.529758e-10] 
Layer 'conv2' weights[0]: 3.981868e-03 [1.994392e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.077699e-09] 
Layer 'conv3' weights[0]: 3.980426e-03 [1.999222e-07] 
Layer 'conv3' biases: 3.199885e-05 [1.185656e-08] 
Layer 'conv4' weights[0]: 3.997099e-03 [2.016912e-07] 
Layer 'conv4' biases: 9.999661e-01 [2.442678e-07] 
Layer 'conv5' weights[0]: 4.099811e-03 [2.600162e-06] 
Layer 'conv5' biases: 9.990883e-01 [2.871173e-06] 
Layer 'fc6' weights[0]: 7.064143e-03 [6.207952e-08] 
Layer 'fc6' biases: 9.999928e-01 [5.727653e-08] 
Layer 'fc7' weights[0]: 7.415143e-03 [1.425412e-07] 
Layer 'fc7' biases: 9.998112e-01 [2.108228e-07] 
Layer 'fc8' weights[0]: 4.676398e-03 [1.480173e-05] 
Layer 'fc8' biases: 1.464607e-02 [3.491905e-05] 
Train error last 800 batches: 0.656591
-------------------------------------------------------
Not saving because 0.468997 > 0.299667 (9.300: -1.18%)
======================================================= (2.363 sec)
18.281... logprob:  0.654447, 0.276042 (1.425 sec)
18.282... logprob:  0.645736, 0.277344 (1.414 sec)
18.283... logprob:  0.606582, 0.264323 (1.417 sec)
18.284... logprob:  0.625980, 0.279948 (1.405 sec)
18.285... logprob:  0.765164, 0.345052 (1.439 sec)
18.286... logprob:  0.755584, 0.287760 (1.430 sec)
18.287... logprob:  0.621484, 0.300781 (1.424 sec)
18.288... logprob:  0.553923, 0.227865 (1.429 sec)
18.289... logprob:  0.649111, 0.303385 (1.440 sec)
18.290... logprob:  0.640229, 0.253906 (1.408 sec)
18.291... logprob:  0.712322, 0.319010 (1.421 sec)
18.292... logprob:  0.657859, 0.324219 (1.417 sec)
18.293... logprob:  0.600417, 0.242187 (1.436 sec)
18.294... logprob:  0.665008, 0.300781 (1.398 sec)
18.295... logprob:  0.567473, 0.277344 (1.460 sec)
18.296... logprob:  0.633289, 0.285156 (1.420 sec)
18.297... logprob:  0.614399, 0.281250 (1.416 sec)
18.298... logprob:  0.665174, 0.298177 (1.454 sec)
18.299... logprob:  0.592786, 0.256510 (1.394 sec)
18.300... logprob:  0.508681, 0.222656 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.480863, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.985400e-03 [1.997830e-07] 
Layer 'conv1' biases: 1.937201e-06 [2.312689e-10] 
Layer 'conv2' weights[0]: 3.977866e-03 [1.993036e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.296802e-09] 
Layer 'conv3' weights[0]: 3.976454e-03 [2.001255e-07] 
Layer 'conv3' biases: 3.197411e-05 [1.485977e-08] 
Layer 'conv4' weights[0]: 3.993095e-03 [2.017546e-07] 
Layer 'conv4' biases: 9.999660e-01 [2.864691e-07] 
Layer 'conv5' weights[0]: 4.096015e-03 [2.845281e-06] 
Layer 'conv5' biases: 9.990843e-01 [3.077052e-06] 
Layer 'fc6' weights[0]: 7.063374e-03 [6.457099e-08] 
Layer 'fc6' biases: 9.999930e-01 [6.112941e-08] 
Layer 'fc7' weights[0]: 7.414414e-03 [1.480836e-07] 
Layer 'fc7' biases: 9.998114e-01 [2.217513e-07] 
Layer 'fc8' weights[0]: 4.698234e-03 [1.541400e-05] 
Layer 'fc8' biases: 1.479092e-02 [3.857988e-05] 
Train error last 800 batches: 0.656999
-------------------------------------------------------
Not saving because 0.480863 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
18.301... logprob:  0.648856, 0.302083 (1.426 sec)
18.302... logprob:  0.718543, 0.298177 (1.419 sec)
18.303... logprob:  0.614377, 0.260417 (1.406 sec)
18.304... logprob:  0.645304, 0.295573 (1.432 sec)
18.305... logprob:  0.661739, 0.272135 (1.430 sec)
18.306... logprob:  0.588744, 0.256510 (1.433 sec)
18.307... logprob:  0.645775, 0.276042 (1.440 sec)
18.308... logprob:  0.567840, 0.242188 (1.449 sec)
18.309... logprob:  0.685128, 0.304688 (1.411 sec)
18.310... logprob:  0.651706, 0.244792 (1.421 sec)
18.311... logprob:  0.756925, 0.320312 (1.415 sec)
18.312... logprob:  0.677503, 0.296875 (1.423 sec)
18.313... logprob:  0.717688, 0.311198 (1.413 sec)
18.314... logprob:  0.598520, 0.265625 (1.455 sec)
18.315... logprob:  0.591594, 0.274740 (1.427 sec)
18.316... logprob:  0.661966, 0.307292 (1.421 sec)
18.317... logprob:  0.570700, 0.239583 (1.469 sec)
18.318... logprob:  0.660512, 0.265625 (1.406 sec)
18.319... logprob:  0.639978, 0.287760 (1.417 sec)
18.320... logprob:  0.652500, 0.273438 (1.417 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.483264, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.981409e-03 [1.997530e-07] 
Layer 'conv1' biases: 1.937637e-06 [2.260631e-10] 
Layer 'conv2' weights[0]: 3.973884e-03 [1.989988e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.204810e-09] 
Layer 'conv3' weights[0]: 3.972481e-03 [1.995706e-07] 
Layer 'conv3' biases: 3.200378e-05 [1.271158e-08] 
Layer 'conv4' weights[0]: 3.989091e-03 [2.006238e-07] 
Layer 'conv4' biases: 9.999657e-01 [2.235835e-07] 
Layer 'conv5' weights[0]: 4.091981e-03 [2.425133e-06] 
Layer 'conv5' biases: 9.990833e-01 [2.599013e-06] 
Layer 'fc6' weights[0]: 7.062647e-03 [6.306349e-08] 
Layer 'fc6' biases: 9.999930e-01 [5.901904e-08] 
Layer 'fc7' weights[0]: 7.413673e-03 [1.431164e-07] 
Layer 'fc7' biases: 9.998104e-01 [1.821407e-07] 
Layer 'fc8' weights[0]: 4.683689e-03 [1.370008e-05] 
Layer 'fc8' biases: 1.469606e-02 [2.130025e-05] 
Train error last 800 batches: 0.656327
-------------------------------------------------------
Not saving because 0.483264 > 0.299667 (9.300: -1.18%)
======================================================= (2.372 sec)
18.321... logprob:  0.591713, 0.263021 (1.425 sec)
18.322... logprob:  0.595115, 0.253906 (1.421 sec)
18.323... logprob:  0.681136, 0.279948 (1.467 sec)
18.324... logprob:  0.684732, 0.312500 (1.419 sec)
18.325... logprob:  0.562179, 0.274740 (1.432 sec)
18.326... logprob:  0.681780, 0.274740 (1.461 sec)
18.327... logprob:  0.770456, 0.347656 (1.412 sec)
18.328... logprob:  0.677065, 0.290365 (1.423 sec)
18.329... logprob:  0.569770, 0.261719 (1.423 sec)
18.330... logprob:  0.633311, 0.282552 (1.415 sec)
18.331... logprob:  0.544169, 0.227865 (1.408 sec)
18.332... logprob:  0.624828, 0.270833 (1.456 sec)
18.333... logprob:  0.629264, 0.285156 (1.435 sec)
18.334... logprob:  0.733876, 0.313802 (1.434 sec)
18.335... logprob:  0.578009, 0.259115 (1.435 sec)
18.336... logprob:  0.723731, 0.325521 (1.449 sec)
18.337... logprob:  0.684223, 0.265625 (1.408 sec)
18.338... logprob:  0.633998, 0.283854 (1.413 sec)
18.339... logprob:  0.710863, 0.290365 (1.418 sec)
18.340... logprob:  0.599283, 0.253906 (1.423 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.507874, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.977431e-03 [1.992948e-07] 
Layer 'conv1' biases: 1.936947e-06 [2.970472e-10] 
Layer 'conv2' weights[0]: 3.969905e-03 [1.988656e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.594962e-09] 
Layer 'conv3' weights[0]: 3.968474e-03 [1.998164e-07] 
Layer 'conv3' biases: 3.205793e-05 [1.673994e-08] 
Layer 'conv4' weights[0]: 3.985108e-03 [2.011434e-07] 
Layer 'conv4' biases: 9.999664e-01 [2.942844e-07] 
Layer 'conv5' weights[0]: 4.088820e-03 [2.839488e-06] 
Layer 'conv5' biases: 9.990935e-01 [3.016098e-06] 
Layer 'fc6' weights[0]: 7.061910e-03 [6.523588e-08] 
Layer 'fc6' biases: 9.999932e-01 [6.189635e-08] 
Layer 'fc7' weights[0]: 7.412915e-03 [1.480410e-07] 
Layer 'fc7' biases: 9.998094e-01 [1.951670e-07] 
Layer 'fc8' weights[0]: 4.643480e-03 [1.452777e-05] 
Layer 'fc8' biases: 1.439836e-02 [2.705634e-05] 
Train error last 800 batches: 0.655379
-------------------------------------------------------
Not saving because 0.507874 > 0.299667 (9.300: -1.18%)
======================================================= (2.409 sec)
18.341... logprob:  0.764180, 0.354167 (1.415 sec)
18.342... logprob:  0.676347, 0.302083 (1.464 sec)
18.343... logprob:  0.644580, 0.270833 (1.439 sec)
18.344... logprob:  0.679059, 0.299479 (1.476 sec)
18.345... logprob:  0.719669, 0.296875 (1.430 sec)
18.346... logprob:  0.674793, 0.294271 (1.433 sec)
18.347... logprob:  0.576563, 0.265625 (1.478 sec)
18.348... logprob:  0.695616, 0.320312 (1.432 sec)
18.349... logprob:  0.634593, 0.281250 (1.429 sec)
18.350... logprob:  0.544567, 0.246094 (1.432 sec)
18.351... logprob:  0.636240, 0.290365 (1.428 sec)
18.352... logprob:  0.664554, 0.325521 (1.432 sec)
18.353... logprob:  0.738827, 0.339844 (1.482 sec)
18.354... logprob:  0.782704, 0.311198 (1.433 sec)
18.355... logprob:  0.578691, 0.242188 (1.435 sec)
18.356... logprob:  0.672883, 0.315104 (1.472 sec)
18.357... logprob:  0.590164, 0.278646 (1.428 sec)
18.358... logprob:  0.641827, 0.291667 (1.434 sec)
18.359... logprob:  0.741205, 0.289062 (1.431 sec)
18.360... logprob:  0.694356, 0.302083 (1.423 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.502015, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.973447e-03 [1.987908e-07] 
Layer 'conv1' biases: 1.937250e-06 [2.882663e-10] 
Layer 'conv2' weights[0]: 3.965910e-03 [1.985163e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.280709e-09] 
Layer 'conv3' weights[0]: 3.964516e-03 [1.992386e-07] 
Layer 'conv3' biases: 3.205360e-05 [1.329219e-08] 
Layer 'conv4' weights[0]: 3.981136e-03 [2.003449e-07] 
Layer 'conv4' biases: 9.999667e-01 [2.087915e-07] 
Layer 'conv5' weights[0]: 4.085295e-03 [2.379596e-06] 
Layer 'conv5' biases: 9.990982e-01 [2.525615e-06] 
Layer 'fc6' weights[0]: 7.061122e-03 [6.092018e-08] 
Layer 'fc6' biases: 9.999930e-01 [5.575885e-08] 
Layer 'fc7' weights[0]: 7.412209e-03 [1.356683e-07] 
Layer 'fc7' biases: 9.998084e-01 [1.564115e-07] 
Layer 'fc8' weights[0]: 4.632733e-03 [1.299497e-05] 
Layer 'fc8' biases: 1.430309e-02 [9.574938e-06] 
Train error last 800 batches: 0.655472
-------------------------------------------------------
Not saving because 0.502015 > 0.299667 (9.300: -1.18%)
======================================================= (2.378 sec)
18.361... logprob:  0.594184, 0.282552 (1.431 sec)
18.362... logprob:  0.658348, 0.320312 (1.480 sec)
18.363... logprob:  0.694480, 0.317708 (1.432 sec)
18.364... logprob:  0.712257, 0.281250 (1.446 sec)
18.365... logprob:  0.644572, 0.290365 (1.459 sec)
18.366... logprob:  0.673415, 0.295573 (1.440 sec)
18.367... logprob:  0.606837, 0.270833 (1.429 sec)
18.368... logprob:  0.659920, 0.282552 (1.423 sec)
18.369... logprob:  0.657659, 0.278646 (1.423 sec)
18.370... logprob:  0.605232, 0.257812 (1.473 sec)
18.371... logprob:  0.670635, 0.287760 (1.450 sec)
18.372... logprob:  0.708523, 0.305990 (1.450 sec)
18.373... logprob:  0.637105, 0.279948 (1.454 sec)
18.374... logprob:  0.693736, 0.299479 (1.442 sec)
18.375... logprob:  0.683935, 0.307292 (1.459 sec)
18.376... logprob:  0.627608, 0.260417 (1.436 sec)
18.377... logprob:  0.549982, 0.236979 (1.423 sec)
18.378... logprob:  0.674894, 0.304687 (1.426 sec)
18.379... logprob:  0.624992, 0.268229 (1.436 sec)
18.380... logprob:  0.749098, 0.339844 (1.436 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.412125, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.969479e-03 [1.986309e-07] 
Layer 'conv1' biases: 1.938804e-06 [2.196987e-10] 
Layer 'conv2' weights[0]: 3.961955e-03 [1.983052e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.776908e-09] 
Layer 'conv3' weights[0]: 3.960561e-03 [1.986801e-07] 
Layer 'conv3' biases: 3.207015e-05 [1.137789e-08] 
Layer 'conv4' weights[0]: 3.977164e-03 [1.999991e-07] 
Layer 'conv4' biases: 9.999651e-01 [2.115219e-07] 
Layer 'conv5' weights[0]: 4.080998e-03 [2.369406e-06] 
Layer 'conv5' biases: 9.990903e-01 [2.530308e-06] 
Layer 'fc6' weights[0]: 7.060404e-03 [5.988800e-08] 
Layer 'fc6' biases: 9.999928e-01 [5.440783e-08] 
Layer 'fc7' weights[0]: 7.411426e-03 [1.349600e-07] 
Layer 'fc7' biases: 9.998085e-01 [1.495866e-07] 
Layer 'fc8' weights[0]: 4.644647e-03 [1.254002e-05] 
Layer 'fc8' biases: 1.448599e-02 [5.584382e-06] 
Train error last 800 batches: 0.655220
-------------------------------------------------------
Not saving because 0.412125 > 0.299667 (9.300: -1.18%)
======================================================= (2.379 sec)
18.381... logprob:  0.677871, 0.296875 (1.477 sec)
18.382... logprob:  0.784216, 0.342448 (1.449 sec)
18.383... logprob:  0.559770, 0.244792 (1.442 sec)
18.384... logprob:  0.798043, 0.328125 (1.474 sec)
18.385... logprob:  0.794790, 0.345052 (1.435 sec)
18.386... logprob:  0.767129, 0.342448 (1.422 sec)
18.387... logprob:  0.629910, 0.283854 (1.435 sec)
18.388... logprob:  0.680611, 0.298177 (1.430 sec)
18.389... logprob:  0.711035, 0.298177 (1.425 sec)
18.390... logprob:  0.659603, 0.296875 (1.470 sec)
18.391... logprob:  0.589108, 0.279948 (1.436 sec)
18.392... logprob:  0.645721, 0.299479 (1.431 sec)
18.393... logprob:  0.560820, 0.234375 (1.480 sec)
18.394... logprob:  0.604488, 0.269531 (1.425 sec)
18.395... logprob:  0.531119, 0.240885 (1.427 sec)
18.396... logprob:  0.504612, 0.227865 (1.434 sec)
18.397... logprob:  0.693190, 0.319010 (1.429 sec)
18.398... logprob:  0.674602, 0.299479 (1.426 sec)
18.399... logprob:  0.669838, 0.290365 (1.485 sec)
18.400... logprob:  0.727197, 0.311198 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.442137, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.965523e-03 [1.986306e-07] 
Layer 'conv1' biases: 1.940428e-06 [1.930811e-10] 
Layer 'conv2' weights[0]: 3.958011e-03 [1.980789e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.035973e-09] 
Layer 'conv3' weights[0]: 3.956633e-03 [1.987898e-07] 
Layer 'conv3' biases: 3.208624e-05 [1.277431e-08] 
Layer 'conv4' weights[0]: 3.973182e-03 [2.001087e-07] 
Layer 'conv4' biases: 9.999650e-01 [2.217384e-07] 
Layer 'conv5' weights[0]: 4.076874e-03 [2.333656e-06] 
Layer 'conv5' biases: 9.990901e-01 [2.486828e-06] 
Layer 'fc6' weights[0]: 7.059662e-03 [6.310746e-08] 
Layer 'fc6' biases: 9.999929e-01 [5.881664e-08] 
Layer 'fc7' weights[0]: 7.410672e-03 [1.459172e-07] 
Layer 'fc7' biases: 9.998081e-01 [1.944732e-07] 
Layer 'fc8' weights[0]: 4.631557e-03 [1.521243e-05] 
Layer 'fc8' biases: 1.445680e-02 [2.698220e-05] 
Train error last 800 batches: 0.655451
-------------------------------------------------------
Not saving because 0.442137 > 0.299667 (9.300: -1.18%)
======================================================= (2.405 sec)
18.401... logprob:  0.774309, 0.343750 (1.443 sec)
18.402... logprob:  0.619099, 0.278646 (1.481 sec)
18.403... logprob:  0.675117, 0.329427 (1.430 sec)
18.404... logprob:  0.678422, 0.277344 (1.429 sec)
18.405... logprob:  0.746627, 0.304687 (1.423 sec)
18.406... logprob:  0.669680, 0.279948 (1.428 sec)
18.407... logprob:  0.694190, 0.312500 (1.425 sec)
18.408... logprob:  0.616428, 0.260417 (1.509 sec)
18.409... logprob:  0.674531, 0.292969 (1.429 sec)
18.410... logprob:  0.742005, 0.328125 (1.446 sec)
18.411... logprob:  0.636056, 0.253906 (1.464 sec)
18.412... logprob:  0.726644, 0.300781 (1.431 sec)
18.413... logprob:  0.804206, 0.343750 (1.433 sec)
18.414... logprob:  0.650816, 0.296875 (1.426 sec)
18.415... logprob:  0.658286, 0.259115 (1.417 sec)
18.416... logprob:  0.692327, 0.316406 (1.429 sec)
18.417... logprob:  0.596382, 0.242187 (1.459 sec)
18.418... logprob:  0.625264, 0.276042 (1.444 sec)
18.419... logprob:  0.701545, 0.295573 (1.444 sec)
18.420... logprob:  0.552853, 0.261719 (1.450 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.467265, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.961548e-03 [1.985906e-07] 
Layer 'conv1' biases: 1.942312e-06 [2.284979e-10] 
Layer 'conv2' weights[0]: 3.954047e-03 [1.980406e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.932667e-09] 
Layer 'conv3' weights[0]: 3.952684e-03 [1.985807e-07] 
Layer 'conv3' biases: 3.208664e-05 [1.223552e-08] 
Layer 'conv4' weights[0]: 3.969235e-03 [2.002428e-07] 
Layer 'conv4' biases: 9.999635e-01 [2.386648e-07] 
Layer 'conv5' weights[0]: 4.072554e-03 [2.456694e-06] 
Layer 'conv5' biases: 9.991030e-01 [2.606549e-06] 
Layer 'fc6' weights[0]: 7.058927e-03 [6.299172e-08] 
Layer 'fc6' biases: 9.999928e-01 [5.866270e-08] 
Layer 'fc7' weights[0]: 7.409966e-03 [1.463328e-07] 
Layer 'fc7' biases: 9.998068e-01 [1.966909e-07] 
Layer 'fc8' weights[0]: 4.586544e-03 [1.589371e-05] 
Layer 'fc8' biases: 1.421243e-02 [3.332637e-05] 
Train error last 800 batches: 0.655549
-------------------------------------------------------
Not saving because 0.467265 > 0.299667 (9.300: -1.18%)
======================================================= (2.367 sec)
18.421... logprob:  0.699415, 0.303385 (1.456 sec)
18.422... logprob:  0.736970, 0.302083 (1.441 sec)
18.423... logprob:  0.706470, 0.299479 (1.423 sec)
18.424... logprob:  0.617155, 0.278646 (1.425 sec)
18.425... logprob:  0.483426, 0.216146 (1.435 sec)
18.426... logprob:  0.620295, 0.287760 (1.441 sec)
18.427... logprob:  0.702145, 0.321615 (1.458 sec)
18.428... logprob:  0.767052, 0.296875 (1.447 sec)
18.429... logprob:  0.659216, 0.261719 (1.437 sec)
18.430... logprob:  0.629528, 0.309896 (1.471 sec)
18.431... logprob:  0.665375, 0.313802 (1.430 sec)
18.432... logprob:  0.637487, 0.274740 (1.423 sec)
18.433... logprob:  0.519628, 0.227865 (1.428 sec)
18.434... logprob:  0.654560, 0.276042 (1.430 sec)
18.435... logprob:  0.744816, 0.303385 (1.427 sec)
18.436... logprob:  0.620464, 0.296875 (1.471 sec)
18.437... logprob:  0.740488, 0.294271 (1.440 sec)
18.438... logprob:  0.794369, 0.316406 (1.432 sec)
18.439... logprob:  0.669056, 0.291667 (1.476 sec)
18.440... logprob:  0.641479, 0.279948 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.567511, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.957597e-03 [1.984813e-07] 
Layer 'conv1' biases: 1.943287e-06 [2.914951e-10] 
Layer 'conv2' weights[0]: 3.950129e-03 [1.979372e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.544950e-09] 
Layer 'conv3' weights[0]: 3.948718e-03 [1.985366e-07] 
Layer 'conv3' biases: 3.208459e-05 [1.435203e-08] 
Layer 'conv4' weights[0]: 3.965246e-03 [1.998074e-07] 
Layer 'conv4' biases: 9.999645e-01 [2.272922e-07] 
Layer 'conv5' weights[0]: 4.069204e-03 [2.244976e-06] 
Layer 'conv5' biases: 9.990916e-01 [2.370103e-06] 
Layer 'fc6' weights[0]: 7.058181e-03 [6.137635e-08] 
Layer 'fc6' biases: 9.999927e-01 [5.656067e-08] 
Layer 'fc7' weights[0]: 7.409223e-03 [1.415563e-07] 
Layer 'fc7' biases: 9.998074e-01 [1.665839e-07] 
Layer 'fc8' weights[0]: 4.616108e-03 [1.353436e-05] 
Layer 'fc8' biases: 1.447115e-02 [9.335340e-06] 
Train error last 800 batches: 0.655269
-------------------------------------------------------
Not saving because 0.567511 > 0.299667 (9.300: -1.18%)
======================================================= (2.360 sec)
18.441... logprob:  0.582739, 0.259115 (1.429 sec)
18.442... logprob:  0.660308, 0.277344 (1.429 sec)
18.443... logprob:  0.757757, 0.296875 (1.424 sec)
18.444... logprob:  0.658104, 0.312500 (1.429 sec)
18.445... logprob:  0.595255, 0.259115 (1.485 sec)
18.446... logprob:  0.649529, 0.279948 (1.456 sec)
18.447... logprob:  0.781453, 0.326823 (1.432 sec)
18.448... logprob:  0.655809, 0.285156 (1.475 sec)
18.449... logprob:  0.658391, 0.295573 (1.434 sec)
18.450... logprob:  0.550522, 0.266927 (1.425 sec)
18.451... logprob:  0.657922, 0.307292 (1.429 sec)
18.452... logprob:  0.611197, 0.244792 (1.422 sec)
18.453... logprob:  0.594644, 0.273437 (1.430 sec)
18.454... logprob:  0.666967, 0.296875 (1.474 sec)
18.455... logprob:  0.673878, 0.276042 (1.432 sec)
18.456... logprob:  0.726352, 0.322917 (1.439 sec)
18.457... logprob:  0.546614, 0.230469 (1.470 sec)
18.458... logprob:  0.554890, 0.270833 (1.425 sec)
18.459... logprob:  0.769039, 0.315104 (1.434 sec)
18.460... logprob:  0.528664, 0.248698 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.515461, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.953644e-03 [1.982609e-07] 
Layer 'conv1' biases: 1.943935e-06 [1.745347e-10] 
Layer 'conv2' weights[0]: 3.946159e-03 [1.975563e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.836058e-09] 
Layer 'conv3' weights[0]: 3.944766e-03 [1.979871e-07] 
Layer 'conv3' biases: 3.208602e-05 [1.180977e-08] 
Layer 'conv4' weights[0]: 3.961278e-03 [1.994959e-07] 
Layer 'conv4' biases: 9.999657e-01 [2.300004e-07] 
Layer 'conv5' weights[0]: 4.066260e-03 [2.500230e-06] 
Layer 'conv5' biases: 9.990789e-01 [2.741542e-06] 
Layer 'fc6' weights[0]: 7.057492e-03 [6.049301e-08] 
Layer 'fc6' biases: 9.999925e-01 [5.559650e-08] 
Layer 'fc7' weights[0]: 7.408482e-03 [1.378460e-07] 
Layer 'fc7' biases: 9.998080e-01 [1.740816e-07] 
Layer 'fc8' weights[0]: 4.628408e-03 [1.385940e-05] 
Layer 'fc8' biases: 1.459690e-02 [2.491293e-05] 
Train error last 800 batches: 0.654695
-------------------------------------------------------
Not saving because 0.515461 > 0.299667 (9.300: -1.18%)
======================================================= (2.380 sec)
18.461... logprob:  0.725224, 0.341146 (1.430 sec)
18.462... logprob:  0.762269, 0.338542 (1.437 sec)
18.463... logprob:  0.638892, 0.315104 (1.462 sec)
18.464... logprob:  0.658826, 0.296875 (1.452 sec)
18.465... logprob:  0.649170, 0.296875 (1.453 sec)
18.466... logprob:  0.491094, 0.196615 (1.454 sec)
18.467... logprob:  0.627442, 0.281250 (1.446 sec)
18.468... logprob:  0.664554, 0.291667 (1.437 sec)
18.469... logprob:  0.640522, 0.304687 (1.423 sec)
18.470... logprob:  0.614277, 0.268229 (1.428 sec)
18.471... logprob:  0.674767, 0.276042 (1.435 sec)
18.472... logprob:  0.661864, 0.313802 (1.455 sec)
18.473... logprob:  0.585805, 0.248698 (1.462 sec)
18.474... logprob:  0.682438, 0.298177 (1.449 sec)
18.475... logprob:  0.696306, 0.287760 (1.442 sec)
18.476... logprob:  0.693355, 0.296875 (1.463 sec)
18.477... logprob:  0.573018, 0.279948 (1.430 sec)
18.478... logprob:  0.689070, 0.285156 (1.419 sec)
18.479... logprob:  0.634135, 0.291667 (1.425 sec)
18.480... logprob:  0.638676, 0.295573 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.447099, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.949695e-03 [1.977587e-07] 
Layer 'conv1' biases: 1.943972e-06 [2.359526e-10] 
Layer 'conv2' weights[0]: 3.942207e-03 [1.973542e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.065006e-09] 
Layer 'conv3' weights[0]: 3.940850e-03 [1.981050e-07] 
Layer 'conv3' biases: 3.205662e-05 [1.378598e-08] 
Layer 'conv4' weights[0]: 3.957321e-03 [1.996419e-07] 
Layer 'conv4' biases: 9.999665e-01 [2.632730e-07] 
Layer 'conv5' weights[0]: 4.062866e-03 [2.393801e-06] 
Layer 'conv5' biases: 9.990674e-01 [2.593454e-06] 
Layer 'fc6' weights[0]: 7.056764e-03 [5.948094e-08] 
Layer 'fc6' biases: 9.999925e-01 [5.470082e-08] 
Layer 'fc7' weights[0]: 7.407755e-03 [1.360179e-07] 
Layer 'fc7' biases: 9.998084e-01 [1.669093e-07] 
Layer 'fc8' weights[0]: 4.655922e-03 [1.410467e-05] 
Layer 'fc8' biases: 1.485466e-02 [2.034878e-05] 
Train error last 800 batches: 0.654935
-------------------------------------------------------
Not saving because 0.447099 > 0.299667 (9.300: -1.18%)
======================================================= (2.372 sec)
18.481... logprob:  0.714518, 0.325521 (1.434 sec)
18.482... logprob:  0.767757, 0.343750 (1.475 sec)
18.483... logprob:  0.759836, 0.333333 (1.448 sec)
18.484... logprob:  0.686081, 0.283854 (1.461 sec)
18.485... logprob:  0.697355, 0.304687 (1.478 sec)
18.486... logprob:  0.530300, 0.248698 (1.427 sec)
18.487... logprob:  0.749734, 0.316406 (1.427 sec)
18.488... logprob:  0.612890, 0.239583 (1.433 sec)
18.489... logprob:  0.624217, 0.302083 (1.430 sec)
18.490... logprob:  0.607629, 0.272135 (1.433 sec)
18.491... logprob:  0.549835, 0.235677 (1.474 sec)
18.492... logprob:  0.582871, 0.255208 (1.435 sec)
18.493... logprob:  0.734233, 0.300781 (1.429 sec)
18.494... logprob:  0.667931, 0.312500 (1.477 sec)
18.495... logprob:  0.585203, 0.244792 (1.427 sec)
18.496... logprob:  0.688685, 0.330729 (1.425 sec)
18.497... logprob:  0.673141, 0.286458 (1.429 sec)
18.498... logprob:  0.670274, 0.304687 (1.424 sec)
18.499... logprob:  0.629598, 0.292969 (1.433 sec)
18.500... logprob:  0.587920, 0.256510 (1.479 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.443521, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.945744e-03 [1.975911e-07] 
Layer 'conv1' biases: 1.945468e-06 [2.070013e-10] 
Layer 'conv2' weights[0]: 3.938275e-03 [1.971094e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.778097e-09] 
Layer 'conv3' weights[0]: 3.936873e-03 [1.976302e-07] 
Layer 'conv3' biases: 3.207578e-05 [1.191024e-08] 
Layer 'conv4' weights[0]: 3.953361e-03 [1.991475e-07] 
Layer 'conv4' biases: 9.999653e-01 [2.355733e-07] 
Layer 'conv5' weights[0]: 4.058689e-03 [2.719067e-06] 
Layer 'conv5' biases: 9.990775e-01 [2.979931e-06] 
Layer 'fc6' weights[0]: 7.056036e-03 [6.136053e-08] 
Layer 'fc6' biases: 9.999925e-01 [5.663967e-08] 
Layer 'fc7' weights[0]: 7.407023e-03 [1.430710e-07] 
Layer 'fc7' biases: 9.998075e-01 [1.930369e-07] 
Layer 'fc8' weights[0]: 4.628387e-03 [1.595423e-05] 
Layer 'fc8' biases: 1.460910e-02 [3.693035e-05] 
Train error last 800 batches: 0.654638
-------------------------------------------------------
Not saving because 0.443521 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
18.501... logprob:  0.602521, 0.268229 (1.437 sec)
18.502... logprob:  0.670717, 0.274740 (1.445 sec)
18.503... logprob:  0.530459, 0.235677 (1.470 sec)
18.504... logprob:  0.614380, 0.263021 (1.426 sec)
18.505... logprob:  0.761514, 0.317708 (1.443 sec)
18.506... logprob:  0.622167, 0.292969 (1.431 sec)
18.507... logprob:  0.675389, 0.270833 (1.419 sec)
18.508... logprob:  0.681618, 0.305990 (1.424 sec)
18.509... logprob:  0.586741, 0.274739 (1.474 sec)
18.510... logprob:  0.606794, 0.259115 (1.435 sec)
18.511... logprob:  0.550944, 0.234375 (1.448 sec)
18.512... logprob:  0.641565, 0.279948 (1.457 sec)
18.513... logprob:  0.573259, 0.276042 (1.439 sec)
18.514... logprob:  0.700812, 0.328125 (1.430 sec)
18.515... logprob:  0.717855, 0.319010 (1.425 sec)
18.516... logprob:  0.689184, 0.296875 (1.419 sec)
18.517... logprob:  0.741731, 0.295573 (1.428 sec)
18.518... logprob:  0.545052, 0.230469 (1.454 sec)
18.519... logprob:  0.853969, 0.348958 (1.448 sec)
18.520... logprob:  0.639692, 0.279948 (1.446 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.466230, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.941790e-03 [1.974547e-07] 
Layer 'conv1' biases: 1.945205e-06 [3.124446e-10] 
Layer 'conv2' weights[0]: 3.934371e-03 [1.968742e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.521338e-09] 
Layer 'conv3' weights[0]: 3.932937e-03 [1.977807e-07] 
Layer 'conv3' biases: 3.206147e-05 [1.581408e-08] 
Layer 'conv4' weights[0]: 3.949402e-03 [1.995989e-07] 
Layer 'conv4' biases: 9.999660e-01 [3.152473e-07] 
Layer 'conv5' weights[0]: 4.055774e-03 [3.498949e-06] 
Layer 'conv5' biases: 9.990640e-01 [3.923503e-06] 
Layer 'fc6' weights[0]: 7.055325e-03 [7.584679e-08] 
Layer 'fc6' biases: 9.999925e-01 [7.690205e-08] 
Layer 'fc7' weights[0]: 7.406257e-03 [1.854554e-07] 
Layer 'fc7' biases: 9.998078e-01 [3.096267e-07] 
Layer 'fc8' weights[0]: 4.647555e-03 [2.125866e-05] 
Layer 'fc8' biases: 1.470062e-02 [5.317053e-05] 
Train error last 800 batches: 0.654580
-------------------------------------------------------
Not saving because 0.466230 > 0.299667 (9.300: -1.18%)
======================================================= (2.393 sec)
18.521... logprob:  0.725473, 0.304687 (1.456 sec)
18.522... logprob:  0.734025, 0.317708 (1.488 sec)
18.523... logprob:  0.578330, 0.247396 (1.439 sec)
18.524... logprob:  0.622606, 0.269531 (1.417 sec)
18.525... logprob:  0.666351, 0.282552 (1.422 sec)
18.526... logprob:  0.565625, 0.272135 (1.430 sec)
18.527... logprob:  0.690923, 0.311198 (1.435 sec)
18.528... logprob:  0.750803, 0.321615 (1.465 sec)
18.529... logprob:  0.629758, 0.292969 (1.444 sec)
18.530... logprob:  0.627111, 0.292969 (1.432 sec)
18.531... logprob:  0.634934, 0.266927 (1.474 sec)
18.532... logprob:  0.678860, 0.308594 (1.427 sec)
18.533... logprob:  0.801042, 0.367188 (1.421 sec)
18.534... logprob:  0.569696, 0.265625 (1.430 sec)
18.535... logprob:  0.624385, 0.270833 (1.427 sec)
18.536... logprob:  0.761347, 0.326823 (1.426 sec)
18.537... logprob:  0.773726, 0.343750 (1.472 sec)
18.538... logprob:  0.609966, 0.244792 (1.438 sec)
18.539... logprob:  0.498007, 0.200521 (1.422 sec)
18.540... logprob:  0.655526, 0.298177 (1.481 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.405705, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.937865e-03 [1.973273e-07] 
Layer 'conv1' biases: 1.945997e-06 [1.691037e-10] 
Layer 'conv2' weights[0]: 3.930424e-03 [1.968855e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.210917e-09] 
Layer 'conv3' weights[0]: 3.929000e-03 [1.975621e-07] 
Layer 'conv3' biases: 3.212982e-05 [1.386111e-08] 
Layer 'conv4' weights[0]: 3.945484e-03 [1.989991e-07] 
Layer 'conv4' biases: 9.999656e-01 [2.763902e-07] 
Layer 'conv5' weights[0]: 4.051836e-03 [2.771050e-06] 
Layer 'conv5' biases: 9.990823e-01 [3.032689e-06] 
Layer 'fc6' weights[0]: 7.054588e-03 [6.614468e-08] 
Layer 'fc6' biases: 9.999923e-01 [6.329356e-08] 
Layer 'fc7' weights[0]: 7.405553e-03 [1.564425e-07] 
Layer 'fc7' biases: 9.998064e-01 [2.327175e-07] 
Layer 'fc8' weights[0]: 4.602133e-03 [1.894634e-05] 
Layer 'fc8' biases: 1.441003e-02 [5.019957e-05] 
Train error last 800 batches: 0.654616
-------------------------------------------------------
Not saving because 0.405705 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
18.541... logprob:  0.580618, 0.272135 (1.430 sec)
18.542... logprob:  0.690233, 0.308594 (1.427 sec)
18.543... logprob:  0.464991, 0.214844 (1.436 sec)
18.544... logprob:  0.641135, 0.285156 (1.422 sec)
18.545... logprob:  0.588930, 0.281250 (1.427 sec)
18.546... logprob:  0.566844, 0.235677 (1.478 sec)
18.547... logprob:  0.692533, 0.319010 (1.433 sec)
18.548... logprob:  0.645079, 0.298177 (1.443 sec)
18.549... logprob:  0.668651, 0.304687 (1.481 sec)
18.550... logprob:  0.622555, 0.300781 (1.433 sec)
18.551... logprob:  0.582859, 0.272135 (1.434 sec)
18.552... logprob:  0.723160, 0.296875 (1.431 sec)
18.553... logprob:  0.626187, 0.292969 (1.421 sec)
18.554... logprob:  0.616529, 0.248698 (1.430 sec)
18.555... logprob:  0.649160, 0.304687 (1.480 sec)
18.556... logprob:  0.630030, 0.268229 (1.433 sec)
18.557... logprob:  0.537692, 0.234375 (1.442 sec)
18.558... logprob:  0.671775, 0.291667 (1.464 sec)
18.559... logprob:  0.640462, 0.302083 (1.433 sec)
18.560... logprob:  0.607250, 0.272135 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.498668, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.933923e-03 [1.968928e-07] 
Layer 'conv1' biases: 1.946593e-06 [2.555177e-10] 
Layer 'conv2' weights[0]: 3.926469e-03 [1.965215e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.968243e-09] 
Layer 'conv3' weights[0]: 3.925089e-03 [1.971418e-07] 
Layer 'conv3' biases: 3.212311e-05 [1.255376e-08] 
Layer 'conv4' weights[0]: 3.941521e-03 [1.983433e-07] 
Layer 'conv4' biases: 9.999654e-01 [2.190346e-07] 
Layer 'conv5' weights[0]: 4.048038e-03 [2.304182e-06] 
Layer 'conv5' biases: 9.990489e-01 [2.551634e-06] 
Layer 'fc6' weights[0]: 7.053852e-03 [6.164398e-08] 
Layer 'fc6' biases: 9.999925e-01 [5.792899e-08] 
Layer 'fc7' weights[0]: 7.404721e-03 [1.413185e-07] 
Layer 'fc7' biases: 9.998090e-01 [1.909955e-07] 
Layer 'fc8' weights[0]: 4.697463e-03 [1.665545e-05] 
Layer 'fc8' biases: 1.511287e-02 [3.545907e-05] 
Train error last 800 batches: 0.654282
-------------------------------------------------------
Not saving because 0.498668 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
18.561... logprob:  0.632007, 0.279948 (1.436 sec)
18.562... logprob:  0.654852, 0.274740 (1.423 sec)
18.563... logprob:  0.670326, 0.300781 (1.431 sec)
18.564... logprob:  0.708765, 0.307292 (1.458 sec)
18.565... logprob:  0.799492, 0.333333 (1.445 sec)
18.566... logprob:  0.686350, 0.295573 (1.450 sec)
18.567... logprob:  0.685051, 0.311198 (1.576 sec)
18.568... logprob:  0.759223, 0.303385 (1.454 sec)
18.569... logprob:  0.782471, 0.339844 (1.429 sec)
18.570... logprob:  0.774813, 0.308594 (1.421 sec)
18.571... logprob:  0.710214, 0.308594 (1.423 sec)
18.572... logprob:  0.763806, 0.328125 (1.433 sec)
18.573... logprob:  0.738187, 0.324219 (1.446 sec)
18.574... logprob:  0.644123, 0.281250 (1.453 sec)
18.575... logprob:  0.647320, 0.278646 (1.452 sec)
18.576... logprob:  0.738353, 0.317708 (1.435 sec)
18.577... logprob:  0.632694, 0.278646 (1.471 sec)
18.578... logprob:  0.623636, 0.299479 (1.437 sec)
18.579... logprob:  0.694098, 0.290365 (1.425 sec)
18.580... logprob:  0.710328, 0.295573 (1.423 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.399586, 0.062500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.930002e-03 [1.965605e-07] 
Layer 'conv1' biases: 1.947544e-06 [1.985143e-10] 
Layer 'conv2' weights[0]: 3.922559e-03 [1.963072e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.693556e-09] 
Layer 'conv3' weights[0]: 3.921181e-03 [1.966288e-07] 
Layer 'conv3' biases: 3.215446e-05 [1.074826e-08] 
Layer 'conv4' weights[0]: 3.937582e-03 [1.979178e-07] 
Layer 'conv4' biases: 9.999648e-01 [2.048907e-07] 
Layer 'conv5' weights[0]: 4.044107e-03 [2.545372e-06] 
Layer 'conv5' biases: 9.990978e-01 [2.796594e-06] 
Layer 'fc6' weights[0]: 7.053092e-03 [6.385733e-08] 
Layer 'fc6' biases: 9.999925e-01 [6.019758e-08] 
Layer 'fc7' weights[0]: 7.404006e-03 [1.449137e-07] 
Layer 'fc7' biases: 9.998047e-01 [1.767075e-07] 
Layer 'fc8' weights[0]: 4.581514e-03 [1.406058e-05] 
Layer 'fc8' biases: 1.413040e-02 [1.924533e-05] 
Train error last 800 batches: 0.655087
-------------------------------------------------------
Not saving because 0.399586 > 0.299667 (9.300: -1.18%)
======================================================= (2.421 sec)
18.581... logprob:  0.744851, 0.346354 (1.443 sec)
18.582... logprob:  0.601694, 0.256510 (1.435 sec)
18.583... logprob:  0.683862, 0.303385 (1.474 sec)
18.584... logprob:  0.672871, 0.274740 (1.436 sec)
18.585... logprob:  0.671348, 0.304688 (1.425 sec)
18.586... logprob:  0.506019, 0.226562 (1.483 sec)
18.587... logprob:  0.619300, 0.240885 (1.427 sec)
18.588... logprob:  0.648240, 0.294271 (1.423 sec)
18.589... logprob:  0.597654, 0.279948 (1.432 sec)
18.590... logprob:  0.720507, 0.312500 (1.432 sec)
18.591... logprob:  0.654911, 0.253906 (1.428 sec)
18.592... logprob:  0.704042, 0.289062 (1.476 sec)
18.593... logprob:  0.628175, 0.243490 (1.434 sec)
18.594... logprob:  0.630225, 0.272135 (1.438 sec)
18.595... logprob:  0.698616, 0.290365 (1.475 sec)
18.596... logprob:  0.603488, 0.263021 (1.426 sec)
18.597... logprob:  0.626079, 0.307292 (1.427 sec)
18.598... logprob:  0.548620, 0.250000 (1.429 sec)
18.599... logprob:  0.541686, 0.223958 (1.423 sec)
18.600... logprob:  0.589559, 0.247396 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.420713, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.926069e-03 [1.969474e-07] 
Layer 'conv1' biases: 1.948356e-06 [2.622975e-10] 
Layer 'conv2' weights[0]: 3.918628e-03 [1.964255e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.137789e-09] 
Layer 'conv3' weights[0]: 3.917224e-03 [1.969392e-07] 
Layer 'conv3' biases: 3.215242e-05 [1.317544e-08] 
Layer 'conv4' weights[0]: 3.933633e-03 [1.988297e-07] 
Layer 'conv4' biases: 9.999650e-01 [2.641591e-07] 
Layer 'conv5' weights[0]: 4.040715e-03 [3.410498e-06] 
Layer 'conv5' biases: 9.990680e-01 [3.716304e-06] 
Layer 'fc6' weights[0]: 7.052350e-03 [7.795208e-08] 
Layer 'fc6' biases: 9.999926e-01 [7.887791e-08] 
Layer 'fc7' weights[0]: 7.403258e-03 [1.958774e-07] 
Layer 'fc7' biases: 9.998077e-01 [3.507814e-07] 
Layer 'fc8' weights[0]: 4.670488e-03 [2.353177e-05] 
Layer 'fc8' biases: 1.489546e-02 [6.318223e-05] 
Train error last 800 batches: 0.654657
-------------------------------------------------------
Not saving because 0.420713 > 0.299667 (9.300: -1.18%)
======================================================= (2.339 sec)
18.601... logprob:  0.595215, 0.214844 (1.484 sec)
18.602... logprob:  0.547989, 0.243490 (1.425 sec)
18.603... logprob:  0.512307, 0.256510 (1.442 sec)
18.604... logprob:  0.593971, 0.244792 (1.467 sec)
18.605... logprob:  0.716970, 0.348958 (1.428 sec)
18.606... logprob:  0.537254, 0.255208 (1.433 sec)
18.607... logprob:  0.704202, 0.263021 (1.425 sec)
18.608... logprob:  0.561768, 0.282552 (1.421 sec)
18.609... logprob:  0.621086, 0.285156 (1.439 sec)
18.610... logprob:  0.768340, 0.324219 (1.470 sec)
18.611... logprob:  0.729840, 0.277344 (1.438 sec)
18.612... logprob:  0.791119, 0.342448 (1.445 sec)
18.613... logprob:  0.528102, 0.230469 (1.456 sec)
18.614... logprob:  0.737940, 0.302083 (1.446 sec)
18.615... logprob:  0.613816, 0.266927 (1.438 sec)
18.616... logprob:  0.656467, 0.298177 (1.420 sec)
18.617... logprob:  0.724307, 0.333333 (1.424 sec)
18.618... logprob:  0.707157, 0.295573 (1.438 sec)
18.619... logprob:  0.637012, 0.269531 (1.446 sec)
18.620... logprob:  0.871175, 0.328125 (1.452 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.447914, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.922133e-03 [1.964711e-07] 
Layer 'conv1' biases: 1.949476e-06 [3.845535e-10] 
Layer 'conv2' weights[0]: 3.914713e-03 [1.961941e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.269715e-09] 
Layer 'conv3' weights[0]: 3.913325e-03 [1.990860e-07] 
Layer 'conv3' biases: 3.221831e-05 [2.726701e-08] 
Layer 'conv4' weights[0]: 3.929733e-03 [2.017358e-07] 
Layer 'conv4' biases: 9.999646e-01 [5.238145e-07] 
Layer 'conv5' weights[0]: 4.036597e-03 [5.863433e-06] 
Layer 'conv5' biases: 9.990724e-01 [6.396355e-06] 
Layer 'fc6' weights[0]: 7.051627e-03 [1.021269e-07] 
Layer 'fc6' biases: 9.999927e-01 [1.159903e-07] 
Layer 'fc7' weights[0]: 7.402520e-03 [2.746973e-07] 
Layer 'fc7' biases: 9.998072e-01 [5.416737e-07] 
Layer 'fc8' weights[0]: 4.671616e-03 [3.186508e-05] 
Layer 'fc8' biases: 1.502996e-02 [9.263899e-05] 
Train error last 800 batches: 0.654834
-------------------------------------------------------
Not saving because 0.447914 > 0.299667 (9.300: -1.18%)
======================================================= (2.322 sec)
18.621... logprob:  0.628064, 0.246094 (1.451 sec)
18.622... logprob:  0.552406, 0.244792 (1.443 sec)
18.623... logprob:  0.598750, 0.259115 (1.461 sec)
18.624... logprob:  0.521817, 0.236979 (1.435 sec)
18.625... logprob:  0.579119, 0.234375 (1.421 sec)
18.626... logprob:  0.666033, 0.300781 (1.423 sec)
18.627... logprob:  0.658220, 0.270833 (1.432 sec)
18.628... logprob:  0.738225, 0.360677 (1.430 sec)
18.629... logprob:  0.622199, 0.287760 (1.468 sec)
18.630... logprob:  0.578987, 0.253906 (1.439 sec)
18.631... logprob:  0.866054, 0.350260 (1.432 sec)
18.632... logprob:  0.676913, 0.274740 (1.475 sec)
18.633... logprob:  0.665395, 0.304687 (1.427 sec)
18.634... logprob:  0.815710, 0.312500 (1.426 sec)
18.635... logprob:  0.674419, 0.307292 (1.433 sec)
18.636... logprob:  0.711367, 0.304688 (1.432 sec)
18.637... logprob:  0.545549, 0.242187 (1.421 sec)
18.638... logprob:  0.730609, 0.303385 (1.504 sec)
18.639... logprob:  0.661869, 0.291667 (1.438 sec)
18.640... logprob:  0.745509, 0.300781 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.492109, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.918235e-03 [1.961896e-07] 
Layer 'conv1' biases: 1.950968e-06 [1.876536e-10] 
Layer 'conv2' weights[0]: 3.910809e-03 [1.957068e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.766702e-09] 
Layer 'conv3' weights[0]: 3.909424e-03 [1.963004e-07] 
Layer 'conv3' biases: 3.227969e-05 [1.257154e-08] 
Layer 'conv4' weights[0]: 3.925801e-03 [1.976963e-07] 
Layer 'conv4' biases: 9.999634e-01 [2.450138e-07] 
Layer 'conv5' weights[0]: 4.032257e-03 [2.476166e-06] 
Layer 'conv5' biases: 9.991131e-01 [2.681714e-06] 
Layer 'fc6' weights[0]: 7.050872e-03 [6.606449e-08] 
Layer 'fc6' biases: 9.999927e-01 [6.291899e-08] 
Layer 'fc7' weights[0]: 7.401847e-03 [1.507631e-07] 
Layer 'fc7' biases: 9.998037e-01 [1.932305e-07] 
Layer 'fc8' weights[0]: 4.583083e-03 [1.470602e-05] 
Layer 'fc8' biases: 1.432388e-02 [1.922338e-05] 
Train error last 800 batches: 0.654961
-------------------------------------------------------
Not saving because 0.492109 > 0.299667 (9.300: -1.18%)
======================================================= (2.356 sec)
18.641... logprob:  0.707343, 0.321615 (1.489 sec)
18.642... logprob:  0.708620, 0.308594 (1.436 sec)
18.643... logprob:  0.816093, 0.359375 (1.433 sec)
18.644... logprob:  0.612894, 0.285156 (1.433 sec)
18.645... logprob:  0.688437, 0.299479 (1.427 sec)
18.646... logprob:  0.578524, 0.230469 (1.426 sec)
18.647... logprob:  0.693024, 0.283854 (1.490 sec)
18.648... logprob:  0.673442, 0.278646 (1.431 sec)
18.649... logprob:  0.596899, 0.269531 (1.438 sec)
18.650... logprob:  0.603306, 0.252604 (1.472 sec)
18.651... logprob:  0.612092, 0.256510 (1.422 sec)
18.652... logprob:  0.669344, 0.283854 (1.430 sec)
18.653... logprob:  0.721527, 0.309896 (1.432 sec)
18.654... logprob:  0.729946, 0.342448 (1.427 sec)
18.655... logprob:  0.706153, 0.303385 (1.424 sec)
18.656... logprob:  0.628613, 0.285156 (1.474 sec)
18.657... logprob:  0.640814, 0.289062 (1.434 sec)
18.658... logprob:  0.583179, 0.264323 (1.445 sec)
18.659... logprob:  0.719141, 0.315104 (1.468 sec)
18.660... logprob:  0.708560, 0.320312 (1.437 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.512395, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.914329e-03 [1.962061e-07] 
Layer 'conv1' biases: 1.953139e-06 [2.235202e-10] 
Layer 'conv2' weights[0]: 3.906897e-03 [1.958457e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.287377e-09] 
Layer 'conv3' weights[0]: 3.905529e-03 [1.966916e-07] 
Layer 'conv3' biases: 3.230434e-05 [1.509535e-08] 
Layer 'conv4' weights[0]: 3.921873e-03 [1.986415e-07] 
Layer 'conv4' biases: 9.999601e-01 [3.024850e-07] 
Layer 'conv5' weights[0]: 4.027335e-03 [3.418613e-06] 
Layer 'conv5' biases: 9.990976e-01 [3.781767e-06] 
Layer 'fc6' weights[0]: 7.050149e-03 [7.102137e-08] 
Layer 'fc6' biases: 9.999927e-01 [6.910397e-08] 
Layer 'fc7' weights[0]: 7.401104e-03 [1.690402e-07] 
Layer 'fc7' biases: 9.998046e-01 [2.638998e-07] 
Layer 'fc8' weights[0]: 4.627064e-03 [1.917993e-05] 
Layer 'fc8' biases: 1.469344e-02 [4.754923e-05] 
Train error last 800 batches: 0.655070
-------------------------------------------------------
Not saving because 0.512395 > 0.299667 (9.300: -1.18%)
======================================================= (2.360 sec)
18.661... logprob:  0.581996, 0.259115 (1.441 sec)
18.662... logprob:  0.709824, 0.338542 (1.432 sec)
18.663... logprob:  0.588205, 0.273437 (1.427 sec)
18.664... logprob:  0.564489, 0.285156 (1.438 sec)
18.665... logprob:  0.612679, 0.268229 (1.449 sec)
18.666... logprob:  0.719572, 0.312500 (1.455 sec)
18.667... logprob:  0.700380, 0.303385 (1.450 sec)
18.668... logprob:  0.698738, 0.272135 (1.445 sec)
18.669... logprob:  0.682890, 0.272135 (1.458 sec)
18.670... logprob:  0.537577, 0.225260 (1.429 sec)
18.671... logprob:  0.606707, 0.270833 (1.420 sec)
18.672... logprob:  0.572411, 0.273437 (1.426 sec)
18.673... logprob:  0.618923, 0.266927 (1.432 sec)
18.674... logprob:  0.762181, 0.299479 (1.453 sec)
18.675... logprob:  0.604251, 0.282552 (1.466 sec)
18.676... logprob:  0.706878, 0.313802 (1.478 sec)
18.677... logprob:  0.731082, 0.295573 (1.433 sec)
18.678... logprob:  0.692470, 0.302083 (1.473 sec)
18.679... logprob:  0.774287, 0.312500 (1.427 sec)
18.680... logprob:  0.533262, 0.257812 (1.419 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.463913, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.910400e-03 [1.958301e-07] 
Layer 'conv1' biases: 1.954768e-06 [2.289687e-10] 
Layer 'conv2' weights[0]: 3.903000e-03 [1.953553e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.956558e-09] 
Layer 'conv3' weights[0]: 3.901617e-03 [1.960360e-07] 
Layer 'conv3' biases: 3.228849e-05 [1.251310e-08] 
Layer 'conv4' weights[0]: 3.917956e-03 [1.972248e-07] 
Layer 'conv4' biases: 9.999587e-01 [2.364181e-07] 
Layer 'conv5' weights[0]: 4.023253e-03 [2.605335e-06] 
Layer 'conv5' biases: 9.990814e-01 [2.777899e-06] 
Layer 'fc6' weights[0]: 7.049398e-03 [6.255166e-08] 
Layer 'fc6' biases: 9.999925e-01 [5.869230e-08] 
Layer 'fc7' weights[0]: 7.400309e-03 [1.436198e-07] 
Layer 'fc7' biases: 9.998058e-01 [1.804433e-07] 
Layer 'fc8' weights[0]: 4.673574e-03 [1.418370e-05] 
Layer 'fc8' biases: 1.503651e-02 [2.072941e-05] 
Train error last 800 batches: 0.655017
-------------------------------------------------------
Not saving because 0.463913 > 0.299667 (9.300: -1.18%)
======================================================= (2.356 sec)
18.681... logprob:  0.545504, 0.260417 (1.433 sec)
18.682... logprob:  0.523368, 0.240885 (1.436 sec)
18.683... logprob:  0.713552, 0.321615 (1.428 sec)
18.684... logprob:  0.578426, 0.222656 (1.474 sec)
18.685... logprob:  0.585450, 0.265625 (1.441 sec)
18.686... logprob:  0.579632, 0.252604 (1.427 sec)
18.687... logprob:  0.688430, 0.311198 (1.478 sec)
18.688... logprob:  0.653020, 0.307292 (1.428 sec)
18.689... logprob:  0.616516, 0.272135 (1.424 sec)
18.690... logprob:  0.798106, 0.335938 (1.430 sec)
18.691... logprob:  0.662654, 0.274740 (1.424 sec)
18.692... logprob:  0.671826, 0.291667 (1.424 sec)
18.693... logprob:  0.638391, 0.303385 (1.480 sec)
18.694... logprob:  0.640774, 0.299479 (1.429 sec)
18.695... logprob:  0.590515, 0.246094 (1.435 sec)
18.696... logprob:  0.715904, 0.309896 (1.475 sec)
18.697... logprob:  0.789203, 0.348958 (1.430 sec)
18.698... logprob:  0.734352, 0.300781 (1.432 sec)
18.699... logprob:  0.609399, 0.263021 (1.430 sec)
18.700... logprob:  0.647431, 0.295573 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.517583, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.906500e-03 [1.954390e-07] 
Layer 'conv1' biases: 1.954670e-06 [2.033487e-10] 
Layer 'conv2' weights[0]: 3.899090e-03 [1.950790e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.124328e-09] 
Layer 'conv3' weights[0]: 3.897649e-03 [1.959759e-07] 
Layer 'conv3' biases: 3.232047e-05 [1.466463e-08] 
Layer 'conv4' weights[0]: 3.914050e-03 [1.971523e-07] 
Layer 'conv4' biases: 9.999589e-01 [2.593211e-07] 
Layer 'conv5' weights[0]: 4.019956e-03 [2.719140e-06] 
Layer 'conv5' biases: 9.990904e-01 [2.767351e-06] 
Layer 'fc6' weights[0]: 7.048687e-03 [6.550593e-08] 
Layer 'fc6' biases: 9.999925e-01 [6.256441e-08] 
Layer 'fc7' weights[0]: 7.399572e-03 [1.548867e-07] 
Layer 'fc7' biases: 9.998046e-01 [2.260196e-07] 
Layer 'fc8' weights[0]: 4.649560e-03 [1.722761e-05] 
Layer 'fc8' biases: 1.496238e-02 [4.112943e-05] 
Train error last 800 batches: 0.655232
-------------------------------------------------------
Not saving because 0.517583 > 0.299667 (9.300: -1.18%)
======================================================= (2.425 sec)
18.701... logprob:  0.664586, 0.270833 (1.438 sec)
18.702... logprob:  0.714505, 0.291667 (1.481 sec)
18.703... logprob:  0.631816, 0.291667 (1.433 sec)
18.704... logprob:  0.578772, 0.265625 (1.440 sec)
18.705... logprob:  0.650616, 0.289062 (1.470 sec)
18.706... logprob:  0.660127, 0.304688 (1.427 sec)
18.707... logprob:  0.697133, 0.303385 (1.431 sec)
18.708... logprob:  0.721993, 0.316406 (1.426 sec)
18.709... logprob:  0.643275, 0.292969 (1.419 sec)
18.710... logprob:  0.822567, 0.364583 (1.438 sec)
18.711... logprob:  0.675320, 0.294271 (1.462 sec)
18.712... logprob:  0.529721, 0.246094 (1.439 sec)
18.713... logprob:  0.719329, 0.305990 (1.452 sec)
18.714... logprob:  0.723267, 0.302083 (1.485 sec)
18.715... logprob:  0.614923, 0.279948 (1.452 sec)
18.716... logprob:  0.635022, 0.268229 (1.432 sec)
18.717... logprob:  0.644910, 0.281250 (1.420 sec)
18.718... logprob:  0.650590, 0.281250 (1.435 sec)
18.719... logprob:  0.671295, 0.290365 (1.431 sec)
18.720... logprob:  0.730358, 0.330729 (1.446 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.411418, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.902604e-03 [1.956107e-07] 
Layer 'conv1' biases: 1.954653e-06 [2.015148e-10] 
Layer 'conv2' weights[0]: 3.895221e-03 [1.950734e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.313838e-09] 
Layer 'conv3' weights[0]: 3.893784e-03 [1.958825e-07] 
Layer 'conv3' biases: 3.233638e-05 [1.500128e-08] 
Layer 'conv4' weights[0]: 3.910135e-03 [1.974915e-07] 
Layer 'conv4' biases: 9.999608e-01 [2.991337e-07] 
Layer 'conv5' weights[0]: 4.016946e-03 [2.637051e-06] 
Layer 'conv5' biases: 9.991130e-01 [2.827411e-06] 
Layer 'fc6' weights[0]: 7.047983e-03 [6.426854e-08] 
Layer 'fc6' biases: 9.999925e-01 [5.997101e-08] 
Layer 'fc7' weights[0]: 7.398862e-03 [1.492128e-07] 
Layer 'fc7' biases: 9.998028e-01 [1.980460e-07] 
Layer 'fc8' weights[0]: 4.595725e-03 [1.699331e-05] 
Layer 'fc8' biases: 1.455327e-02 [3.627411e-05] 
Train error last 800 batches: 0.654900
-------------------------------------------------------
Not saving because 0.411418 > 0.299667 (9.300: -1.18%)
======================================================= (2.359 sec)
18.721... logprob:  0.637693, 0.264323 (1.462 sec)
18.722... logprob:  0.744204, 0.346354 (1.455 sec)
18.723... logprob:  0.637034, 0.304688 (1.435 sec)
18.724... logprob:  0.646059, 0.316406 (1.469 sec)
18.725... logprob:  0.717906, 0.283854 (1.428 sec)
18.726... logprob:  0.651511, 0.312500 (1.421 sec)
18.727... logprob:  0.671166, 0.277344 (1.424 sec)
18.728... logprob:  0.587769, 0.248698 (1.431 sec)
18.729... logprob:  0.583007, 0.263021 (1.428 sec)
18.730... logprob:  0.756121, 0.326823 (1.468 sec)
18.731... logprob:  0.660451, 0.305990 (1.441 sec)
18.732... logprob:  0.580740, 0.252604 (1.432 sec)
18.733... logprob:  0.688240, 0.290365 (1.480 sec)
18.734... logprob:  0.572414, 0.268229 (1.426 sec)
18.735... logprob:  0.657928, 0.291667 (1.425 sec)
18.736... logprob:  0.768403, 0.337240 (1.429 sec)
18.737... logprob:  0.840867, 0.342448 (1.424 sec)
18.738... logprob:  0.677908, 0.292969 (1.428 sec)
18.739... logprob:  0.704165, 0.322917 (1.477 sec)
18.740... logprob:  0.568696, 0.257812 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.505770, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.898707e-03 [1.952366e-07] 
Layer 'conv1' biases: 1.955484e-06 [2.018763e-10] 
Layer 'conv2' weights[0]: 3.891322e-03 [1.947589e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.124020e-09] 
Layer 'conv3' weights[0]: 3.889919e-03 [1.953103e-07] 
Layer 'conv3' biases: 3.233761e-05 [1.334010e-08] 
Layer 'conv4' weights[0]: 3.906210e-03 [1.967051e-07] 
Layer 'conv4' biases: 9.999623e-01 [2.350794e-07] 
Layer 'conv5' weights[0]: 4.014104e-03 [2.432245e-06] 
Layer 'conv5' biases: 9.991026e-01 [2.555349e-06] 
Layer 'fc6' weights[0]: 7.047213e-03 [6.084796e-08] 
Layer 'fc6' biases: 9.999926e-01 [5.552615e-08] 
Layer 'fc7' weights[0]: 7.398100e-03 [1.362767e-07] 
Layer 'fc7' biases: 9.998035e-01 [1.580730e-07] 
Layer 'fc8' weights[0]: 4.633888e-03 [1.296621e-05] 
Layer 'fc8' biases: 1.481054e-02 [1.203696e-05] 
Train error last 800 batches: 0.655081
-------------------------------------------------------
Not saving because 0.505770 > 0.299667 (9.300: -1.18%)
======================================================= (2.381 sec)
18.741... logprob:  0.649083, 0.300781 (1.440 sec)
18.742... logprob:  0.656266, 0.283854 (1.484 sec)
18.743... logprob:  0.589335, 0.289062 (1.425 sec)
18.744... logprob:  0.774069, 0.312500 (1.424 sec)
18.745... logprob:  0.581576, 0.261719 (1.431 sec)
18.746... logprob:  0.667370, 0.304687 (1.425 sec)
18.747... logprob:  0.637951, 0.292969 (1.432 sec)
18.748... logprob:  0.590454, 0.256510 (1.484 sec)
18.749... logprob:  0.654283, 0.287760 (1.432 sec)
18.750... logprob:  0.654601, 0.273438 (1.437 sec)
18.751... logprob:  0.506162, 0.231771 (1.473 sec)
18.752... logprob:  0.698366, 0.304687 (1.456 sec)
18.753... logprob:  0.706515, 0.326823 (1.434 sec)
18.754... logprob:  0.653110, 0.286458 (1.427 sec)
18.755... logprob:  0.724200, 0.291667 (1.418 sec)
18.756... logprob:  0.642544, 0.294271 (1.426 sec)
18.757... logprob:  0.732480, 0.320312 (1.469 sec)
18.758... logprob:  0.636318, 0.300781 (1.439 sec)
18.759... logprob:  0.630010, 0.264323 (1.447 sec)
18.760... logprob:  0.637178, 0.278646 (1.454 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.463894, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.894797e-03 [1.950540e-07] 
Layer 'conv1' biases: 1.955680e-06 [1.913432e-10] 
Layer 'conv2' weights[0]: 3.887416e-03 [1.945763e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.137835e-09] 
Layer 'conv3' weights[0]: 3.885995e-03 [1.950209e-07] 
Layer 'conv3' biases: 3.233665e-05 [1.160470e-08] 
Layer 'conv4' weights[0]: 3.902308e-03 [1.962539e-07] 
Layer 'conv4' biases: 9.999640e-01 [2.148579e-07] 
Layer 'conv5' weights[0]: 4.011345e-03 [2.417691e-06] 
Layer 'conv5' biases: 9.990944e-01 [2.582918e-06] 
Layer 'fc6' weights[0]: 7.046479e-03 [5.974181e-08] 
Layer 'fc6' biases: 9.999926e-01 [5.404582e-08] 
Layer 'fc7' weights[0]: 7.397408e-03 [1.347485e-07] 
Layer 'fc7' biases: 9.998038e-01 [1.544228e-07] 
Layer 'fc8' weights[0]: 4.654206e-03 [1.314912e-05] 
Layer 'fc8' biases: 1.498190e-02 [1.410363e-05] 
Train error last 800 batches: 0.654923
-------------------------------------------------------
Not saving because 0.463894 > 0.299667 (9.300: -1.18%)
======================================================= (2.407 sec)
18.761... logprob:  0.614812, 0.292969 (1.446 sec)
18.762... logprob:  0.802420, 0.325521 (1.439 sec)
18.763... logprob:  0.729618, 0.305990 (1.442 sec)
18.764... logprob:  0.804956, 0.352865 (1.431 sec)
18.765... logprob:  0.644407, 0.283854 (1.431 sec)
18.766... logprob:  0.690013, 0.307292 (1.451 sec)
18.767... logprob:  0.550429, 0.244792 (1.446 sec)
18.768... logprob:  0.695111, 0.308594 (1.463 sec)
18.769... logprob:  0.688558, 0.309896 (1.461 sec)
18.770... logprob:  0.547709, 0.233073 (1.480 sec)
18.771... logprob:  0.712622, 0.326823 (1.453 sec)
18.772... logprob:  0.667676, 0.296875 (1.447 sec)
18.773... logprob:  0.750619, 0.319010 (1.445 sec)
18.774... logprob:  0.554694, 0.255208 (1.457 sec)
18.775... logprob:  0.637842, 0.279948 (1.460 sec)
18.776... logprob:  0.662085, 0.303385 (1.475 sec)
18.777... logprob:  0.608700, 0.290365 (1.465 sec)
18.778... logprob:  0.617278, 0.253906 (1.459 sec)
18.779... logprob:  0.807784, 0.351562 (1.478 sec)
18.780... logprob:  0.571109, 0.259115 (1.450 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.545903, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.890919e-03 [1.947789e-07] 
Layer 'conv1' biases: 1.955453e-06 [1.929007e-10] 
Layer 'conv2' weights[0]: 3.883536e-03 [1.943801e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.612547e-09] 
Layer 'conv3' weights[0]: 3.882126e-03 [1.946516e-07] 
Layer 'conv3' biases: 3.235908e-05 [1.092649e-08] 
Layer 'conv4' weights[0]: 3.898428e-03 [1.960561e-07] 
Layer 'conv4' biases: 9.999653e-01 [2.091497e-07] 
Layer 'conv5' weights[0]: 4.007864e-03 [2.213009e-06] 
Layer 'conv5' biases: 9.991044e-01 [2.340953e-06] 
Layer 'fc6' weights[0]: 7.045736e-03 [6.047671e-08] 
Layer 'fc6' biases: 9.999927e-01 [5.466105e-08] 
Layer 'fc7' weights[0]: 7.396623e-03 [1.369812e-07] 
Layer 'fc7' biases: 9.998031e-01 [1.657749e-07] 
Layer 'fc8' weights[0]: 4.634816e-03 [1.309235e-05] 
Layer 'fc8' biases: 1.483562e-02 [1.793838e-05] 
Train error last 800 batches: 0.654534
-------------------------------------------------------
Not saving because 0.545903 > 0.299667 (9.300: -1.18%)
======================================================= (2.362 sec)
18.781... logprob:  0.601666, 0.260417 (1.445 sec)
18.782... logprob:  0.598097, 0.257812 (1.451 sec)
18.783... logprob:  0.629264, 0.281250 (1.460 sec)
18.784... logprob:  0.596359, 0.286458 (1.459 sec)
18.785... logprob:  0.771390, 0.328125 (1.482 sec)
18.786... logprob:  0.722259, 0.329427 (1.468 sec)
18.787... logprob:  0.743752, 0.309896 (1.456 sec)
18.788... logprob:  0.731336, 0.341146 (1.492 sec)
18.789... logprob:  0.534749, 0.265625 (1.457 sec)
18.790... logprob:  0.591192, 0.264323 (1.483 sec)
18.791... logprob:  0.702278, 0.303385 (1.446 sec)
18.792... logprob:  0.608109, 0.260417 (1.454 sec)
18.793... logprob:  0.598577, 0.246094 (1.468 sec)
18.794... logprob:  0.522147, 0.242187 (1.485 sec)
18.795... logprob:  0.746012, 0.329427 (1.461 sec)
18.796... logprob:  0.703092, 0.307292 (1.448 sec)
18.797... logprob:  0.658009, 0.308594 (1.492 sec)
18.798... logprob:  0.713024, 0.333333 (1.444 sec)
18.799... logprob:  0.620444, 0.286458 (1.446 sec)
18.800... logprob:  0.613433, 0.289062 (1.395 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.417818, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.887011e-03 [1.945323e-07] 
Layer 'conv1' biases: 1.956075e-06 [1.957997e-10] 
Layer 'conv2' weights[0]: 3.879673e-03 [1.941193e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.870544e-09] 
Layer 'conv3' weights[0]: 3.878264e-03 [1.945490e-07] 
Layer 'conv3' biases: 3.237111e-05 [1.085312e-08] 
Layer 'conv4' weights[0]: 3.894522e-03 [1.959495e-07] 
Layer 'conv4' biases: 9.999650e-01 [2.154370e-07] 
Layer 'conv5' weights[0]: 4.003903e-03 [2.317046e-06] 
Layer 'conv5' biases: 9.990916e-01 [2.561478e-06] 
Layer 'fc6' weights[0]: 7.044981e-03 [5.970902e-08] 
Layer 'fc6' biases: 9.999927e-01 [5.382579e-08] 
Layer 'fc7' weights[0]: 7.395891e-03 [1.349599e-07] 
Layer 'fc7' biases: 9.998045e-01 [1.676068e-07] 
Layer 'fc8' weights[0]: 4.672835e-03 [1.409840e-05] 
Layer 'fc8' biases: 1.520235e-02 [2.174219e-05] 
Train error last 800 batches: 0.654958
-------------------------------------------------------
Not saving because 0.417818 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
19.1... logprob:  0.623535, 0.283854 (1.411 sec)
19.2... logprob:  0.640558, 0.283854 (1.450 sec)
19.3... logprob:  0.569468, 0.248698 (1.412 sec)
19.4... logprob:  0.666507, 0.274740 (1.399 sec)
19.5... logprob:  0.581980, 0.248698 (1.431 sec)
19.6... logprob:  0.728755, 0.313802 (1.386 sec)
19.7... logprob:  0.554940, 0.255208 (1.419 sec)
19.8... logprob:  0.533762, 0.240885 (1.390 sec)
19.9... logprob:  0.600940, 0.255208 (1.404 sec)
19.10... logprob:  0.638900, 0.286458 (1.407 sec)
19.11... logprob:  0.589145, 0.274740 (1.443 sec)
19.12... logprob:  0.645806, 0.291667 (1.396 sec)
19.13... logprob:  0.584664, 0.277344 (1.414 sec)
19.14... logprob:  0.619870, 0.265625 (1.400 sec)
19.15... logprob:  0.688691, 0.289062 (1.403 sec)
19.16... logprob:  0.631279, 0.303385 (1.400 sec)
19.17... logprob:  0.733750, 0.300781 (1.389 sec)
19.18... logprob:  0.462939, 0.203125 (1.393 sec)
19.19... logprob:  0.550271, 0.272135 (1.393 sec)
19.20... logprob:  0.703359, 0.303385 (1.400 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.361009, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.883142e-03 [1.946365e-07] 
Layer 'conv1' biases: 1.957746e-06 [2.625315e-10] 
Layer 'conv2' weights[0]: 3.875762e-03 [1.941491e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.362279e-09] 
Layer 'conv3' weights[0]: 3.874384e-03 [1.948196e-07] 
Layer 'conv3' biases: 3.237124e-05 [1.316336e-08] 
Layer 'conv4' weights[0]: 3.890645e-03 [1.961384e-07] 
Layer 'conv4' biases: 9.999634e-01 [2.321635e-07] 
Layer 'conv5' weights[0]: 3.999500e-03 [2.282045e-06] 
Layer 'conv5' biases: 9.990824e-01 [2.419983e-06] 
Layer 'fc6' weights[0]: 7.044267e-03 [5.751956e-08] 
Layer 'fc6' biases: 9.999925e-01 [5.114726e-08] 
Layer 'fc7' weights[0]: 7.395150e-03 [1.277346e-07] 
Layer 'fc7' biases: 9.998051e-01 [1.441108e-07] 
Layer 'fc8' weights[0]: 4.700256e-03 [1.182539e-05] 
Layer 'fc8' biases: 1.547583e-02 [9.096366e-06] 
Train error last 800 batches: 0.654697
-------------------------------------------------------
Not saving because 0.361009 > 0.299667 (9.300: -1.18%)
======================================================= (2.372 sec)
19.21... logprob:  0.579503, 0.263021 (1.408 sec)
19.22... logprob:  0.778627, 0.302083 (1.411 sec)
19.23... logprob:  0.733151, 0.298177 (1.417 sec)
19.24... logprob:  0.508449, 0.231771 (1.493 sec)
19.25... logprob:  0.530686, 0.252604 (1.401 sec)
19.26... logprob:  0.640265, 0.251302 (1.442 sec)
19.27... logprob:  0.566461, 0.242187 (1.379 sec)
19.28... logprob:  0.635626, 0.276042 (1.419 sec)
19.29... logprob:  0.639696, 0.279948 (1.422 sec)
19.30... logprob:  0.704819, 0.312500 (1.410 sec)
19.31... logprob:  0.722661, 0.296875 (1.406 sec)
19.32... logprob:  0.675615, 0.309896 (1.388 sec)
19.33... logprob:  0.698691, 0.274740 (1.441 sec)
19.34... logprob:  0.629939, 0.302083 (1.392 sec)
19.35... logprob:  0.517873, 0.205729 (1.395 sec)
19.36... logprob:  0.792961, 0.337240 (1.394 sec)
19.37... logprob:  0.694034, 0.291667 (1.403 sec)
19.38... logprob:  0.608948, 0.289062 (1.390 sec)
19.39... logprob:  0.849693, 0.347656 (1.426 sec)
19.40... logprob:  0.637795, 0.287760 (1.402 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.472448, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.879269e-03 [1.939172e-07] 
Layer 'conv1' biases: 1.958690e-06 [2.728656e-10] 
Layer 'conv2' weights[0]: 3.871901e-03 [1.938085e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.925040e-09] 
Layer 'conv3' weights[0]: 3.870500e-03 [1.950147e-07] 
Layer 'conv3' biases: 3.233380e-05 [1.810902e-08] 
Layer 'conv4' weights[0]: 3.886721e-03 [1.972097e-07] 
Layer 'conv4' biases: 9.999638e-01 [3.856127e-07] 
Layer 'conv5' weights[0]: 3.996247e-03 [4.392928e-06] 
Layer 'conv5' biases: 9.991053e-01 [4.932877e-06] 
Layer 'fc6' weights[0]: 7.043555e-03 [8.596858e-08] 
Layer 'fc6' biases: 9.999925e-01 [9.136218e-08] 
Layer 'fc7' weights[0]: 7.394425e-03 [2.196163e-07] 
Layer 'fc7' biases: 9.998033e-01 [4.021141e-07] 
Layer 'fc8' weights[0]: 4.626844e-03 [2.554322e-05] 
Layer 'fc8' biases: 1.493721e-02 [6.825541e-05] 
Train error last 800 batches: 0.654373
-------------------------------------------------------
Not saving because 0.472448 > 0.299667 (9.300: -1.18%)
======================================================= (2.335 sec)
19.41... logprob:  0.548838, 0.236979 (1.424 sec)
19.42... logprob:  0.630577, 0.266927 (1.417 sec)
19.43... logprob:  0.637183, 0.276042 (1.406 sec)
19.44... logprob:  0.764093, 0.305990 (1.434 sec)
19.45... logprob:  0.638950, 0.269531 (1.390 sec)
19.46... logprob:  0.636833, 0.268229 (1.397 sec)
19.47... logprob:  0.521562, 0.243490 (1.389 sec)
19.48... logprob:  0.720286, 0.296875 (1.423 sec)
19.49... logprob:  0.693905, 0.311198 (1.408 sec)
19.50... logprob:  0.630071, 0.295573 (1.418 sec)
19.51... logprob:  0.757336, 0.365885 (1.413 sec)
19.52... logprob:  0.765369, 0.330729 (1.399 sec)
19.53... logprob:  0.520822, 0.227865 (1.436 sec)
19.54... logprob:  0.616511, 0.279948 (1.384 sec)
19.55... logprob:  0.596748, 0.268229 (1.388 sec)
19.56... logprob:  0.598459, 0.236979 (1.399 sec)
19.57... logprob:  0.761702, 0.335938 (1.429 sec)
19.58... logprob:  0.680522, 0.317708 (1.399 sec)
19.59... logprob:  0.615547, 0.269531 (1.460 sec)
19.60... logprob:  0.727749, 0.325521 (1.425 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.506074, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.875398e-03 [1.941590e-07] 
Layer 'conv1' biases: 1.961035e-06 [2.282787e-10] 
Layer 'conv2' weights[0]: 3.868036e-03 [1.936988e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.238084e-09] 
Layer 'conv3' weights[0]: 3.866630e-03 [1.947397e-07] 
Layer 'conv3' biases: 3.233046e-05 [1.501935e-08] 
Layer 'conv4' weights[0]: 3.882855e-03 [1.964825e-07] 
Layer 'conv4' biases: 9.999623e-01 [2.960553e-07] 
Layer 'conv5' weights[0]: 3.991635e-03 [2.792413e-06] 
Layer 'conv5' biases: 9.991053e-01 [2.959813e-06] 
Layer 'fc6' weights[0]: 7.042840e-03 [6.437982e-08] 
Layer 'fc6' biases: 9.999925e-01 [6.014142e-08] 
Layer 'fc7' weights[0]: 7.393639e-03 [1.463376e-07] 
Layer 'fc7' biases: 9.998026e-01 [1.923277e-07] 
Layer 'fc8' weights[0]: 4.623535e-03 [1.549553e-05] 
Layer 'fc8' biases: 1.484010e-02 [3.046430e-05] 
Train error last 800 batches: 0.654164
-------------------------------------------------------
Not saving because 0.506074 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
19.61... logprob:  0.691394, 0.328125 (1.436 sec)
19.62... logprob:  0.734018, 0.311198 (1.457 sec)
19.63... logprob:  0.751120, 0.343750 (1.438 sec)
19.64... logprob:  0.643130, 0.278646 (1.402 sec)
19.65... logprob:  0.636654, 0.308594 (1.394 sec)
19.66... logprob:  0.673041, 0.272135 (1.438 sec)
19.67... logprob:  0.534251, 0.239583 (1.402 sec)
19.68... logprob:  0.606788, 0.278646 (1.396 sec)
19.69... logprob:  0.757655, 0.316406 (1.419 sec)
19.70... logprob:  0.598548, 0.257812 (1.426 sec)
19.71... logprob:  0.577413, 0.255208 (1.454 sec)
19.72... logprob:  0.671435, 0.291667 (1.396 sec)
19.73... logprob:  0.754897, 0.302083 (1.418 sec)
19.74... logprob:  0.564952, 0.238281 (1.407 sec)
19.75... logprob:  0.676235, 0.285156 (1.409 sec)
19.76... logprob:  0.672176, 0.279948 (1.432 sec)
19.77... logprob:  0.689212, 0.309896 (1.429 sec)
19.78... logprob:  0.675208, 0.305990 (1.449 sec)
19.79... logprob:  0.651972, 0.298177 (1.393 sec)
19.80... logprob:  0.639098, 0.281250 (1.415 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.559214, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.871523e-03 [1.935447e-07] 
Layer 'conv1' biases: 1.961629e-06 [1.832696e-10] 
Layer 'conv2' weights[0]: 3.864168e-03 [1.933756e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.648127e-09] 
Layer 'conv3' weights[0]: 3.862771e-03 [1.938273e-07] 
Layer 'conv3' biases: 3.229636e-05 [1.091178e-08] 
Layer 'conv4' weights[0]: 3.878983e-03 [1.951467e-07] 
Layer 'conv4' biases: 9.999618e-01 [1.993455e-07] 
Layer 'conv5' weights[0]: 3.987574e-03 [2.087207e-06] 
Layer 'conv5' biases: 9.990895e-01 [2.270350e-06] 
Layer 'fc6' weights[0]: 7.042115e-03 [6.070764e-08] 
Layer 'fc6' biases: 9.999925e-01 [5.552057e-08] 
Layer 'fc7' weights[0]: 7.392873e-03 [1.364467e-07] 
Layer 'fc7' biases: 9.998035e-01 [1.584311e-07] 
Layer 'fc8' weights[0]: 4.668699e-03 [1.321241e-05] 
Layer 'fc8' biases: 1.520214e-02 [1.646521e-05] 
Train error last 800 batches: 0.654647
-------------------------------------------------------
Not saving because 0.559214 > 0.299667 (9.300: -1.18%)
======================================================= (2.419 sec)
19.81... logprob:  0.652332, 0.302083 (1.428 sec)
19.82... logprob:  0.547285, 0.257812 (1.421 sec)
19.83... logprob:  0.726308, 0.302083 (1.396 sec)
19.84... logprob:  0.692609, 0.272135 (1.457 sec)
19.85... logprob:  0.606979, 0.264323 (1.417 sec)
19.86... logprob:  0.728986, 0.345052 (1.413 sec)
19.87... logprob:  0.697590, 0.299479 (1.410 sec)
19.88... logprob:  0.762145, 0.333333 (1.399 sec)
19.89... logprob:  0.636564, 0.264323 (1.432 sec)
19.90... logprob:  0.740195, 0.313802 (1.393 sec)
19.91... logprob:  0.475075, 0.217448 (1.391 sec)
19.92... logprob:  0.638944, 0.296875 (1.400 sec)
19.93... logprob:  0.700321, 0.335938 (1.388 sec)
19.94... logprob:  0.626072, 0.264323 (1.391 sec)
19.95... logprob:  0.685300, 0.273437 (1.396 sec)
19.96... logprob:  0.731187, 0.320312 (1.396 sec)
19.97... logprob:  0.651655, 0.268229 (1.384 sec)
19.98... logprob:  0.626032, 0.285156 (1.432 sec)
19.99... logprob:  0.676090, 0.291667 (1.399 sec)
19.100... logprob:  0.506911, 0.208333 (1.395 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.442716, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.867642e-03 [1.937331e-07] 
Layer 'conv1' biases: 1.962819e-06 [1.878012e-10] 
Layer 'conv2' weights[0]: 3.860288e-03 [1.933275e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.797403e-09] 
Layer 'conv3' weights[0]: 3.858899e-03 [1.937493e-07] 
Layer 'conv3' biases: 3.228365e-05 [1.132087e-08] 
Layer 'conv4' weights[0]: 3.875076e-03 [1.950730e-07] 
Layer 'conv4' biases: 9.999616e-01 [2.146457e-07] 
Layer 'conv5' weights[0]: 3.984124e-03 [2.505855e-06] 
Layer 'conv5' biases: 9.991032e-01 [2.642972e-06] 
Layer 'fc6' weights[0]: 7.041421e-03 [6.104106e-08] 
Layer 'fc6' biases: 9.999925e-01 [5.576847e-08] 
Layer 'fc7' weights[0]: 7.392124e-03 [1.379857e-07] 
Layer 'fc7' biases: 9.998025e-01 [1.624611e-07] 
Layer 'fc8' weights[0]: 4.638443e-03 [1.318741e-05] 
Layer 'fc8' biases: 1.500146e-02 [1.192620e-05] 
Train error last 800 batches: 0.654348
-------------------------------------------------------
Not saving because 0.442716 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
19.101... logprob:  0.529648, 0.227865 (1.449 sec)
19.102... logprob:  0.679582, 0.286458 (1.399 sec)
19.103... logprob:  0.698212, 0.315104 (1.402 sec)
19.104... logprob:  0.611850, 0.268229 (1.401 sec)
19.105... logprob:  0.782620, 0.347656 (1.389 sec)
19.106... logprob:  0.587385, 0.272135 (1.418 sec)
19.107... logprob:  0.586358, 0.257812 (1.441 sec)
19.108... logprob:  0.693780, 0.286458 (1.397 sec)
19.109... logprob:  0.525703, 0.239583 (1.394 sec)
19.110... logprob:  0.699079, 0.295573 (1.392 sec)
19.111... logprob:  0.672400, 0.291667 (1.385 sec)
19.112... logprob:  0.554192, 0.235677 (1.398 sec)
19.113... logprob:  0.651531, 0.299479 (1.394 sec)
19.114... logprob:  0.681202, 0.315104 (1.423 sec)
19.115... logprob:  0.694244, 0.308594 (1.405 sec)
19.116... logprob:  0.628767, 0.287760 (1.490 sec)
19.117... logprob:  0.639505, 0.295573 (1.440 sec)
19.118... logprob:  0.645921, 0.294271 (1.384 sec)
19.119... logprob:  0.553813, 0.247396 (1.387 sec)
19.120... logprob:  0.746823, 0.300781 (1.396 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.511480, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.863782e-03 [1.936662e-07] 
Layer 'conv1' biases: 1.962926e-06 [1.900455e-10] 
Layer 'conv2' weights[0]: 3.856440e-03 [1.931704e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.805700e-09] 
Layer 'conv3' weights[0]: 3.855032e-03 [1.935347e-07] 
Layer 'conv3' biases: 3.224438e-05 [1.159505e-08] 
Layer 'conv4' weights[0]: 3.871247e-03 [1.947560e-07] 
Layer 'conv4' biases: 9.999628e-01 [1.949108e-07] 
Layer 'conv5' weights[0]: 3.981219e-03 [2.231098e-06] 
Layer 'conv5' biases: 9.990883e-01 [2.404768e-06] 
Layer 'fc6' weights[0]: 7.040699e-03 [5.931751e-08] 
Layer 'fc6' biases: 9.999925e-01 [5.340597e-08] 
Layer 'fc7' weights[0]: 7.391387e-03 [1.337838e-07] 
Layer 'fc7' biases: 9.998030e-01 [1.551713e-07] 
Layer 'fc8' weights[0]: 4.667693e-03 [1.222471e-05] 
Layer 'fc8' biases: 1.527625e-02 [1.182667e-05] 
Train error last 800 batches: 0.653802
-------------------------------------------------------
Not saving because 0.511480 > 0.299667 (9.300: -1.18%)
======================================================= (2.379 sec)
19.121... logprob:  0.697123, 0.311198 (1.400 sec)
19.122... logprob:  0.748019, 0.351562 (1.445 sec)
19.123... logprob:  0.638950, 0.305990 (1.385 sec)
19.124... logprob:  0.659908, 0.277344 (1.399 sec)
19.125... logprob:  0.706928, 0.304687 (1.395 sec)
19.126... logprob:  0.685218, 0.282552 (1.385 sec)
19.127... logprob:  0.664436, 0.285156 (1.390 sec)
19.128... logprob:  0.632094, 0.292969 (1.409 sec)
19.129... logprob:  0.790092, 0.358073 (1.412 sec)
19.130... logprob:  0.592915, 0.251302 (1.412 sec)
19.131... logprob:  0.756202, 0.315104 (1.406 sec)
19.132... logprob:  0.676506, 0.303385 (1.432 sec)
19.133... logprob:  0.662431, 0.269531 (1.387 sec)
19.134... logprob:  0.602107, 0.273437 (1.390 sec)
19.135... logprob:  0.729915, 0.305990 (1.395 sec)
19.136... logprob:  0.720450, 0.308594 (1.391 sec)
19.137... logprob:  0.645021, 0.281250 (1.383 sec)
19.138... logprob:  0.576630, 0.265625 (1.440 sec)
19.139... logprob:  0.705138, 0.332031 (1.389 sec)
19.140... logprob:  0.752144, 0.312500 (1.406 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.496665, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.859917e-03 [1.931752e-07] 
Layer 'conv1' biases: 1.963796e-06 [1.700770e-10] 
Layer 'conv2' weights[0]: 3.852594e-03 [1.928061e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.919856e-09] 
Layer 'conv3' weights[0]: 3.851193e-03 [1.933005e-07] 
Layer 'conv3' biases: 3.226062e-05 [1.222334e-08] 
Layer 'conv4' weights[0]: 3.867363e-03 [1.946726e-07] 
Layer 'conv4' biases: 9.999627e-01 [2.369417e-07] 
Layer 'conv5' weights[0]: 3.977588e-03 [2.856673e-06] 
Layer 'conv5' biases: 9.991139e-01 [3.147956e-06] 
Layer 'fc6' weights[0]: 7.039978e-03 [6.959969e-08] 
Layer 'fc6' biases: 9.999925e-01 [6.698585e-08] 
Layer 'fc7' weights[0]: 7.390598e-03 [1.638338e-07] 
Layer 'fc7' biases: 9.998010e-01 [2.440201e-07] 
Layer 'fc8' weights[0]: 4.598887e-03 [1.752725e-05] 
Layer 'fc8' biases: 1.477193e-02 [3.414358e-05] 
Train error last 800 batches: 0.654475
-------------------------------------------------------
Not saving because 0.496665 > 0.299667 (9.300: -1.18%)
======================================================= (2.408 sec)
19.141... logprob:  0.718826, 0.346354 (1.439 sec)
19.142... logprob:  0.685259, 0.298177 (1.395 sec)
19.143... logprob:  0.574118, 0.239583 (1.429 sec)
19.144... logprob:  0.742318, 0.312500 (1.409 sec)
19.145... logprob:  0.663395, 0.302083 (1.432 sec)
19.146... logprob:  0.751972, 0.315104 (1.403 sec)
19.147... logprob:  0.492744, 0.205729 (1.428 sec)
19.148... logprob:  0.615517, 0.268229 (1.389 sec)
19.149... logprob:  0.663939, 0.298177 (1.391 sec)
19.150... logprob:  0.582276, 0.222656 (1.402 sec)
19.151... logprob:  0.574462, 0.252604 (1.394 sec)
19.152... logprob:  0.869313, 0.359375 (1.389 sec)
19.153... logprob:  0.610036, 0.264323 (1.446 sec)
19.154... logprob:  0.678728, 0.298177 (1.393 sec)
19.155... logprob:  0.652205, 0.299479 (1.400 sec)
19.156... logprob:  0.601602, 0.251302 (1.430 sec)
19.157... logprob:  0.534307, 0.247396 (1.388 sec)
19.158... logprob:  0.629495, 0.298177 (1.394 sec)
19.159... logprob:  0.634389, 0.269531 (1.392 sec)
19.160... logprob:  0.659799, 0.298177 (1.388 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.517215, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.856076e-03 [1.935733e-07] 
Layer 'conv1' biases: 1.964841e-06 [2.448231e-10] 
Layer 'conv2' weights[0]: 3.848761e-03 [1.928734e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.452532e-09] 
Layer 'conv3' weights[0]: 3.847344e-03 [1.935233e-07] 
Layer 'conv3' biases: 3.227847e-05 [1.363515e-08] 
Layer 'conv4' weights[0]: 3.863492e-03 [1.949671e-07] 
Layer 'conv4' biases: 9.999619e-01 [2.513626e-07] 
Layer 'conv5' weights[0]: 3.973724e-03 [2.805215e-06] 
Layer 'conv5' biases: 9.991024e-01 [2.953085e-06] 
Layer 'fc6' weights[0]: 7.039278e-03 [6.722761e-08] 
Layer 'fc6' biases: 9.999924e-01 [6.380473e-08] 
Layer 'fc7' weights[0]: 7.389881e-03 [1.558798e-07] 
Layer 'fc7' biases: 9.998010e-01 [2.382158e-07] 
Layer 'fc8' weights[0]: 4.632444e-03 [1.677863e-05] 
Layer 'fc8' biases: 1.500239e-02 [4.404374e-05] 
Train error last 800 batches: 0.654795
-------------------------------------------------------
Not saving because 0.517215 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
19.161... logprob:  0.603424, 0.268229 (1.407 sec)
19.162... logprob:  0.757131, 0.368490 (1.405 sec)
19.163... logprob:  0.640423, 0.278646 (1.427 sec)
19.164... logprob:  0.666670, 0.313802 (1.420 sec)
19.165... logprob:  0.691549, 0.303385 (1.418 sec)
19.166... logprob:  0.672944, 0.300781 (1.443 sec)
19.167... logprob:  0.558928, 0.246094 (1.423 sec)
19.168... logprob:  0.536518, 0.242187 (1.414 sec)
19.169... logprob:  0.660540, 0.283854 (1.457 sec)
19.170... logprob:  0.608845, 0.277344 (1.397 sec)
19.171... logprob:  0.744735, 0.298177 (1.413 sec)
19.172... logprob:  0.701681, 0.270833 (1.410 sec)
19.173... logprob:  0.598645, 0.268229 (1.411 sec)
19.174... logprob:  0.718848, 0.315104 (1.398 sec)
19.175... logprob:  0.699238, 0.308594 (1.460 sec)
19.176... logprob:  0.779785, 0.335938 (1.412 sec)
19.177... logprob:  0.548881, 0.235677 (1.426 sec)
19.178... logprob:  0.578130, 0.231771 (1.455 sec)
19.179... logprob:  0.612017, 0.295573 (1.405 sec)
19.180... logprob:  0.759617, 0.319010 (1.423 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.505832, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.852194e-03 [1.929617e-07] 
Layer 'conv1' biases: 1.967427e-06 [3.210221e-10] 
Layer 'conv2' weights[0]: 3.844909e-03 [1.924208e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.573083e-09] 
Layer 'conv3' weights[0]: 3.843497e-03 [1.934118e-07] 
Layer 'conv3' biases: 3.229332e-05 [1.594789e-08] 
Layer 'conv4' weights[0]: 3.859626e-03 [1.949243e-07] 
Layer 'conv4' biases: 9.999586e-01 [3.243823e-07] 
Layer 'conv5' weights[0]: 3.967955e-03 [2.723057e-06] 
Layer 'conv5' biases: 9.991043e-01 [3.043894e-06] 
Layer 'fc6' weights[0]: 7.038557e-03 [6.479761e-08] 
Layer 'fc6' biases: 9.999924e-01 [6.123363e-08] 
Layer 'fc7' weights[0]: 7.389115e-03 [1.502804e-07] 
Layer 'fc7' biases: 9.998024e-01 [2.000497e-07] 
Layer 'fc8' weights[0]: 4.661422e-03 [1.526151e-05] 
Layer 'fc8' biases: 1.527752e-02 [3.078760e-05] 
Train error last 800 batches: 0.654494
-------------------------------------------------------
Not saving because 0.505832 > 0.299667 (9.300: -1.18%)
======================================================= (2.381 sec)
19.181... logprob:  0.722331, 0.287760 (1.422 sec)
19.182... logprob:  0.625013, 0.270833 (1.411 sec)
19.183... logprob:  0.671604, 0.290365 (1.419 sec)
19.184... logprob:  0.700218, 0.311198 (1.442 sec)
19.185... logprob:  0.560704, 0.231771 (1.392 sec)
19.186... logprob:  0.496998, 0.222656 (1.393 sec)
19.187... logprob:  0.737715, 0.325521 (1.394 sec)
19.188... logprob:  0.646077, 0.313802 (1.385 sec)
19.189... logprob:  0.661701, 0.276042 (1.389 sec)
19.190... logprob:  0.649476, 0.296875 (1.431 sec)
19.191... logprob:  0.626212, 0.285156 (1.405 sec)
19.192... logprob:  0.712891, 0.332031 (1.408 sec)
19.193... logprob:  0.567365, 0.244792 (1.417 sec)
19.194... logprob:  0.605285, 0.252604 (1.411 sec)
19.195... logprob:  0.500403, 0.227864 (1.394 sec)
19.196... logprob:  0.597485, 0.270833 (1.384 sec)
19.197... logprob:  0.609528, 0.268229 (1.392 sec)
19.198... logprob:  0.604219, 0.289062 (1.401 sec)
19.199... logprob:  0.676257, 0.308594 (1.389 sec)
19.200... logprob:  0.709038, 0.298177 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.485641, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.848354e-03 [1.932287e-07] 
Layer 'conv1' biases: 1.968055e-06 [2.191869e-10] 
Layer 'conv2' weights[0]: 3.841041e-03 [1.926171e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.022130e-09] 
Layer 'conv3' weights[0]: 3.839643e-03 [1.930914e-07] 
Layer 'conv3' biases: 3.230000e-05 [1.309657e-08] 
Layer 'conv4' weights[0]: 3.855750e-03 [1.946688e-07] 
Layer 'conv4' biases: 9.999575e-01 [2.466723e-07] 
Layer 'conv5' weights[0]: 3.963709e-03 [3.013258e-06] 
Layer 'conv5' biases: 9.990968e-01 [3.225391e-06] 
Layer 'fc6' weights[0]: 7.037797e-03 [6.602514e-08] 
Layer 'fc6' biases: 9.999925e-01 [6.247129e-08] 
Layer 'fc7' weights[0]: 7.388305e-03 [1.532805e-07] 
Layer 'fc7' biases: 9.998037e-01 [2.297139e-07] 
Layer 'fc8' weights[0]: 4.707874e-03 [1.713014e-05] 
Layer 'fc8' biases: 1.558709e-02 [3.717439e-05] 
Train error last 800 batches: 0.654220
-------------------------------------------------------
Not saving because 0.485641 > 0.299667 (9.300: -1.18%)
======================================================= (2.353 sec)
19.201... logprob:  0.757531, 0.322917 (1.414 sec)
19.202... logprob:  0.734223, 0.304687 (1.404 sec)
19.203... logprob:  0.683977, 0.273438 (1.441 sec)
19.204... logprob:  0.726005, 0.295573 (1.389 sec)
19.205... logprob:  0.544890, 0.251302 (1.399 sec)
19.206... logprob:  0.593815, 0.286458 (1.397 sec)
19.207... logprob:  0.654564, 0.299479 (1.389 sec)
19.208... logprob:  0.712275, 0.290365 (1.399 sec)
19.209... logprob:  0.590741, 0.278646 (1.420 sec)
19.210... logprob:  0.722894, 0.315104 (1.413 sec)
19.211... logprob:  0.716760, 0.308594 (1.413 sec)
19.212... logprob:  0.743384, 0.335937 (1.411 sec)
19.213... logprob:  0.704739, 0.290365 (1.452 sec)
19.214... logprob:  0.745568, 0.290364 (1.421 sec)
19.215... logprob:  0.603592, 0.277344 (1.411 sec)
19.216... logprob:  0.699592, 0.294271 (1.459 sec)
19.217... logprob:  0.564355, 0.265625 (1.391 sec)
19.218... logprob:  0.700908, 0.300781 (1.420 sec)
19.219... logprob:  0.776604, 0.325521 (1.405 sec)
19.220... logprob:  0.737183, 0.332031 (1.418 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.416365, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.844517e-03 [1.923363e-07] 
Layer 'conv1' biases: 1.968641e-06 [1.862591e-10] 
Layer 'conv2' weights[0]: 3.837214e-03 [1.919572e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.242516e-09] 
Layer 'conv3' weights[0]: 3.835818e-03 [1.927472e-07] 
Layer 'conv3' biases: 3.232291e-05 [1.401745e-08] 
Layer 'conv4' weights[0]: 3.851904e-03 [1.944282e-07] 
Layer 'conv4' biases: 9.999581e-01 [2.804752e-07] 
Layer 'conv5' weights[0]: 3.960212e-03 [3.317189e-06] 
Layer 'conv5' biases: 9.991158e-01 [3.626353e-06] 
Layer 'fc6' weights[0]: 7.037066e-03 [7.483224e-08] 
Layer 'fc6' biases: 9.999926e-01 [7.403187e-08] 
Layer 'fc7' weights[0]: 7.387576e-03 [1.809589e-07] 
Layer 'fc7' biases: 9.998010e-01 [2.940565e-07] 
Layer 'fc8' weights[0]: 4.644227e-03 [1.927929e-05] 
Layer 'fc8' biases: 1.512923e-02 [4.937878e-05] 
Train error last 800 batches: 0.654848
-------------------------------------------------------
Not saving because 0.416365 > 0.299667 (9.300: -1.18%)
======================================================= (2.347 sec)
19.221... logprob:  0.630442, 0.276042 (1.407 sec)
19.222... logprob:  0.833833, 0.338542 (1.459 sec)
19.223... logprob:  0.766006, 0.345052 (1.460 sec)
19.224... logprob:  0.650200, 0.290365 (1.424 sec)
19.225... logprob:  0.559358, 0.250000 (1.439 sec)
19.226... logprob:  0.621030, 0.283854 (1.415 sec)
19.227... logprob:  0.649557, 0.252604 (1.408 sec)
19.228... logprob:  0.635223, 0.256510 (1.409 sec)
19.229... logprob:  0.735585, 0.316406 (1.410 sec)
19.230... logprob:  0.714798, 0.325521 (1.434 sec)
19.231... logprob:  0.689556, 0.307292 (1.401 sec)
19.232... logprob:  0.653451, 0.278646 (1.459 sec)
19.233... logprob:  0.544071, 0.250000 (1.421 sec)
19.234... logprob:  0.680764, 0.282552 (1.415 sec)
19.235... logprob:  0.715090, 0.311198 (1.460 sec)
19.236... logprob:  0.729237, 0.308594 (1.398 sec)
19.237... logprob:  0.567162, 0.277344 (1.429 sec)
19.238... logprob:  0.612084, 0.255208 (1.409 sec)
19.239... logprob:  0.725653, 0.295573 (1.415 sec)
19.240... logprob:  0.718951, 0.315104 (1.393 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.445775, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.840668e-03 [1.923430e-07] 
Layer 'conv1' biases: 1.969059e-06 [2.186055e-10] 
Layer 'conv2' weights[0]: 3.833380e-03 [1.919566e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.292472e-09] 
Layer 'conv3' weights[0]: 3.831981e-03 [1.927697e-07] 
Layer 'conv3' biases: 3.235106e-05 [1.506864e-08] 
Layer 'conv4' weights[0]: 3.848056e-03 [1.938410e-07] 
Layer 'conv4' biases: 9.999600e-01 [2.826042e-07] 
Layer 'conv5' weights[0]: 3.958187e-03 [2.781419e-06] 
Layer 'conv5' biases: 9.991251e-01 [2.980209e-06] 
Layer 'fc6' weights[0]: 7.036389e-03 [6.712751e-08] 
Layer 'fc6' biases: 9.999925e-01 [6.350151e-08] 
Layer 'fc7' weights[0]: 7.386869e-03 [1.579487e-07] 
Layer 'fc7' biases: 9.998001e-01 [2.167919e-07] 
Layer 'fc8' weights[0]: 4.607759e-03 [1.861560e-05] 
Layer 'fc8' biases: 1.485428e-02 [4.287023e-05] 
Train error last 800 batches: 0.655189
-------------------------------------------------------
Not saving because 0.445775 > 0.299667 (9.300: -1.18%)
======================================================= (2.357 sec)
19.241... logprob:  0.704683, 0.290365 (1.466 sec)
19.242... logprob:  0.606847, 0.251302 (1.427 sec)
19.243... logprob:  0.606703, 0.270833 (1.431 sec)
19.244... logprob:  0.521490, 0.257813 (1.448 sec)
19.245... logprob:  0.741574, 0.313802 (1.416 sec)
19.246... logprob:  0.652739, 0.268229 (1.416 sec)
19.247... logprob:  0.557667, 0.259114 (1.409 sec)
19.248... logprob:  0.621033, 0.290365 (1.418 sec)
19.249... logprob:  0.674437, 0.307292 (1.422 sec)
19.250... logprob:  0.812400, 0.332031 (1.401 sec)
19.251... logprob:  0.619923, 0.290365 (1.453 sec)
19.252... logprob:  0.623144, 0.279948 (1.421 sec)
19.253... logprob:  0.536009, 0.248698 (1.416 sec)
19.254... logprob:  0.674685, 0.287760 (1.458 sec)
19.255... logprob:  0.539317, 0.248698 (1.399 sec)
19.256... logprob:  0.545235, 0.247396 (1.416 sec)
19.257... logprob:  0.648083, 0.295573 (1.416 sec)
19.258... logprob:  0.622547, 0.292969 (1.415 sec)
19.259... logprob:  0.702353, 0.300781 (1.401 sec)
19.260... logprob:  0.552390, 0.291667 (1.450 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.396173, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.836833e-03 [1.922319e-07] 
Layer 'conv1' biases: 1.970158e-06 [2.688244e-10] 
Layer 'conv2' weights[0]: 3.829558e-03 [1.918538e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.951491e-09] 
Layer 'conv3' weights[0]: 3.828183e-03 [1.923359e-07] 
Layer 'conv3' biases: 3.237660e-05 [1.209849e-08] 
Layer 'conv4' weights[0]: 3.844226e-03 [1.936263e-07] 
Layer 'conv4' biases: 9.999604e-01 [2.339141e-07] 
Layer 'conv5' weights[0]: 3.955034e-03 [2.823678e-06] 
Layer 'conv5' biases: 9.990974e-01 [3.150505e-06] 
Layer 'fc6' weights[0]: 7.035635e-03 [6.665192e-08] 
Layer 'fc6' biases: 9.999922e-01 [6.317428e-08] 
Layer 'fc7' weights[0]: 7.386140e-03 [1.541888e-07] 
Layer 'fc7' biases: 9.998014e-01 [2.413165e-07] 
Layer 'fc8' weights[0]: 4.666639e-03 [1.676268e-05] 
Layer 'fc8' biases: 1.539869e-02 [4.439524e-05] 
Train error last 800 batches: 0.655133
-------------------------------------------------------
Not saving because 0.396173 > 0.299667 (9.300: -1.18%)
======================================================= (2.407 sec)
19.261... logprob:  0.590494, 0.255208 (1.436 sec)
19.262... logprob:  0.700113, 0.296875 (1.428 sec)
19.263... logprob:  0.631689, 0.290365 (1.448 sec)
19.264... logprob:  0.611916, 0.305990 (1.413 sec)
19.265... logprob:  0.650796, 0.279948 (1.412 sec)
19.266... logprob:  0.600347, 0.252604 (1.407 sec)
19.267... logprob:  0.634461, 0.282552 (1.410 sec)
19.268... logprob:  0.636738, 0.294271 (1.413 sec)
19.269... logprob:  0.726103, 0.305990 (1.408 sec)
19.270... logprob:  0.737448, 0.334635 (1.456 sec)
19.271... logprob:  0.585869, 0.251302 (1.421 sec)
19.272... logprob:  0.663438, 0.325521 (1.418 sec)
19.273... logprob:  0.734521, 0.295573 (1.471 sec)
19.274... logprob:  0.817350, 0.352865 (1.403 sec)
19.275... logprob:  0.635104, 0.282552 (1.421 sec)
19.276... logprob:  0.626916, 0.279948 (1.412 sec)
19.277... logprob:  0.679511, 0.290365 (1.421 sec)
19.278... logprob:  0.585107, 0.282552 (1.417 sec)
19.279... logprob:  0.518767, 0.243489 (1.464 sec)
19.280... logprob:  0.510951, 0.236979 (1.397 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.499341, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.833017e-03 [1.919388e-07] 
Layer 'conv1' biases: 1.971616e-06 [1.723310e-10] 
Layer 'conv2' weights[0]: 3.825721e-03 [1.915011e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.558801e-09] 
Layer 'conv3' weights[0]: 3.824325e-03 [1.918599e-07] 
Layer 'conv3' biases: 3.240851e-05 [1.059252e-08] 
Layer 'conv4' weights[0]: 3.840404e-03 [1.930542e-07] 
Layer 'conv4' biases: 9.999595e-01 [2.111589e-07] 
Layer 'conv5' weights[0]: 3.950949e-03 [2.398831e-06] 
Layer 'conv5' biases: 9.991061e-01 [2.559254e-06] 
Layer 'fc6' weights[0]: 7.034891e-03 [6.167629e-08] 
Layer 'fc6' biases: 9.999923e-01 [5.676248e-08] 
Layer 'fc7' weights[0]: 7.385415e-03 [1.415025e-07] 
Layer 'fc7' biases: 9.998012e-01 [2.020893e-07] 
Layer 'fc8' weights[0]: 4.653124e-03 [1.779347e-05] 
Layer 'fc8' biases: 1.538982e-02 [4.568334e-05] 
Train error last 800 batches: 0.655237
-------------------------------------------------------
Not saving because 0.499341 > 0.299667 (9.300: -1.18%)
======================================================= (2.369 sec)
19.281... logprob:  0.642894, 0.264323 (1.423 sec)
19.282... logprob:  0.666340, 0.308594 (1.420 sec)
19.283... logprob:  0.649233, 0.274739 (1.418 sec)
19.284... logprob:  0.602064, 0.260417 (1.404 sec)
19.285... logprob:  0.673574, 0.282552 (1.440 sec)
19.286... logprob:  0.666978, 0.286458 (1.431 sec)
19.287... logprob:  0.554970, 0.272135 (1.423 sec)
19.288... logprob:  0.589120, 0.273437 (1.445 sec)
19.289... logprob:  0.667754, 0.296875 (1.437 sec)
19.290... logprob:  0.667723, 0.309896 (1.401 sec)
19.291... logprob:  0.662526, 0.328125 (1.412 sec)
19.292... logprob:  0.717876, 0.278646 (1.421 sec)
19.293... logprob:  0.629758, 0.279948 (1.421 sec)
19.294... logprob:  0.596312, 0.261719 (1.394 sec)
19.295... logprob:  0.601630, 0.274740 (1.459 sec)
19.296... logprob:  0.608277, 0.269531 (1.413 sec)
19.297... logprob:  0.689570, 0.294271 (1.429 sec)
19.298... logprob:  0.628950, 0.281250 (1.460 sec)
19.299... logprob:  0.642969, 0.294271 (1.401 sec)
19.300... logprob:  0.604209, 0.265625 (1.416 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.464369, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.829164e-03 [1.916604e-07] 
Layer 'conv1' biases: 1.974580e-06 [2.488000e-10] 
Layer 'conv2' weights[0]: 3.821896e-03 [1.912428e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.548621e-09] 
Layer 'conv3' weights[0]: 3.820512e-03 [1.916589e-07] 
Layer 'conv3' biases: 3.244781e-05 [1.065272e-08] 
Layer 'conv4' weights[0]: 3.836549e-03 [1.929020e-07] 
Layer 'conv4' biases: 9.999573e-01 [2.090648e-07] 
Layer 'conv5' weights[0]: 3.946167e-03 [2.453726e-06] 
Layer 'conv5' biases: 9.990981e-01 [2.650378e-06] 
Layer 'fc6' weights[0]: 7.034178e-03 [6.437282e-08] 
Layer 'fc6' biases: 9.999923e-01 [6.069592e-08] 
Layer 'fc7' weights[0]: 7.384651e-03 [1.459906e-07] 
Layer 'fc7' biases: 9.998020e-01 [2.056308e-07] 
Layer 'fc8' weights[0]: 4.693989e-03 [1.652672e-05] 
Layer 'fc8' biases: 1.572251e-02 [4.144173e-05] 
Train error last 800 batches: 0.655271
-------------------------------------------------------
Not saving because 0.464369 > 0.299667 (9.300: -1.18%)
======================================================= (2.382 sec)
19.301... logprob:  0.630606, 0.277344 (1.421 sec)
19.302... logprob:  0.889303, 0.364583 (1.415 sec)
19.303... logprob:  0.627807, 0.244792 (1.407 sec)
19.304... logprob:  0.586166, 0.244792 (1.434 sec)
19.305... logprob:  0.638579, 0.260417 (1.428 sec)
19.306... logprob:  0.682633, 0.285156 (1.430 sec)
19.307... logprob:  0.635089, 0.277344 (1.436 sec)
19.308... logprob:  0.631163, 0.286458 (1.454 sec)
19.309... logprob:  0.652999, 0.285156 (1.411 sec)
19.310... logprob:  0.661251, 0.283854 (1.428 sec)
19.311... logprob:  0.655263, 0.298177 (1.420 sec)
19.312... logprob:  0.753135, 0.320312 (1.426 sec)
19.313... logprob:  0.752444, 0.320312 (1.414 sec)
19.314... logprob:  0.696346, 0.320312 (1.457 sec)
19.315... logprob:  0.594540, 0.303385 (1.424 sec)
19.316... logprob:  0.660890, 0.296875 (1.421 sec)
19.317... logprob:  0.546269, 0.238281 (1.470 sec)
19.318... logprob:  0.707254, 0.307292 (1.406 sec)
19.319... logprob:  0.705847, 0.296875 (1.423 sec)
19.320... logprob:  0.678685, 0.286458 (1.419 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.551754, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.825362e-03 [1.914827e-07] 
Layer 'conv1' biases: 1.975520e-06 [2.827332e-10] 
Layer 'conv2' weights[0]: 3.818098e-03 [1.910854e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.389001e-09] 
Layer 'conv3' weights[0]: 3.816674e-03 [1.920062e-07] 
Layer 'conv3' biases: 3.249042e-05 [1.467365e-08] 
Layer 'conv4' weights[0]: 3.832713e-03 [1.932823e-07] 
Layer 'conv4' biases: 9.999563e-01 [2.495189e-07] 
Layer 'conv5' weights[0]: 3.941902e-03 [2.501169e-06] 
Layer 'conv5' biases: 9.991211e-01 [2.697619e-06] 
Layer 'fc6' weights[0]: 7.033439e-03 [6.149224e-08] 
Layer 'fc6' biases: 9.999924e-01 [5.592585e-08] 
Layer 'fc7' weights[0]: 7.383915e-03 [1.420374e-07] 
Layer 'fc7' biases: 9.997999e-01 [1.777928e-07] 
Layer 'fc8' weights[0]: 4.643316e-03 [1.459754e-05] 
Layer 'fc8' biases: 1.527411e-02 [2.839658e-05] 
Train error last 800 batches: 0.655809
-------------------------------------------------------
Not saving because 0.551754 > 0.299667 (9.300: -1.18%)
======================================================= (2.400 sec)
19.321... logprob:  0.679971, 0.311198 (1.430 sec)
19.322... logprob:  0.588739, 0.257812 (1.421 sec)
19.323... logprob:  0.612145, 0.287760 (1.477 sec)
19.324... logprob:  0.682765, 0.303385 (1.415 sec)
19.325... logprob:  0.570965, 0.251302 (1.432 sec)
19.326... logprob:  0.775841, 0.345052 (1.453 sec)
19.327... logprob:  0.757163, 0.338542 (1.420 sec)
19.328... logprob:  0.744941, 0.317708 (1.423 sec)
19.329... logprob:  0.613102, 0.298177 (1.419 sec)
19.330... logprob:  0.603525, 0.270833 (1.412 sec)
19.331... logprob:  0.626466, 0.308594 (1.414 sec)
19.332... logprob:  0.721571, 0.321615 (1.450 sec)
19.333... logprob:  0.579276, 0.253906 (1.437 sec)
19.334... logprob:  0.726112, 0.343750 (1.431 sec)
19.335... logprob:  0.648879, 0.289062 (1.435 sec)
19.336... logprob:  0.743493, 0.281250 (1.451 sec)
19.337... logprob:  0.722670, 0.346354 (1.416 sec)
19.338... logprob:  0.710299, 0.305990 (1.415 sec)
19.339... logprob:  0.747159, 0.294271 (1.424 sec)
19.340... logprob:  0.706128, 0.311198 (1.453 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.427888, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.821521e-03 [1.914606e-07] 
Layer 'conv1' biases: 1.975697e-06 [2.516135e-10] 
Layer 'conv2' weights[0]: 3.814238e-03 [1.909441e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.256688e-09] 
Layer 'conv3' weights[0]: 3.812878e-03 [1.916285e-07] 
Layer 'conv3' biases: 3.247997e-05 [1.346720e-08] 
Layer 'conv4' weights[0]: 3.828875e-03 [1.933231e-07] 
Layer 'conv4' biases: 9.999554e-01 [2.803041e-07] 
Layer 'conv5' weights[0]: 3.937958e-03 [3.759018e-06] 
Layer 'conv5' biases: 9.991230e-01 [4.134074e-06] 
Layer 'fc6' weights[0]: 7.032684e-03 [7.350635e-08] 
Layer 'fc6' biases: 9.999924e-01 [7.196064e-08] 
Layer 'fc7' weights[0]: 7.383192e-03 [1.726348e-07] 
Layer 'fc7' biases: 9.997995e-01 [2.743753e-07] 
Layer 'fc8' weights[0]: 4.627419e-03 [1.854668e-05] 
Layer 'fc8' biases: 1.516350e-02 [4.556492e-05] 
Train error last 800 batches: 0.656624
-------------------------------------------------------
Not saving because 0.427888 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
19.341... logprob:  0.668154, 0.295573 (1.421 sec)
19.342... logprob:  0.606104, 0.282552 (1.471 sec)
19.343... logprob:  0.730589, 0.276042 (1.438 sec)
19.344... logprob:  0.706114, 0.315104 (1.482 sec)
19.345... logprob:  0.598772, 0.274740 (1.429 sec)
19.346... logprob:  0.617903, 0.277344 (1.442 sec)
19.347... logprob:  0.577981, 0.229167 (1.476 sec)
19.348... logprob:  0.599869, 0.279948 (1.427 sec)
19.349... logprob:  0.735993, 0.298177 (1.424 sec)
19.350... logprob:  0.624460, 0.282552 (1.440 sec)
19.351... logprob:  0.712604, 0.290365 (1.424 sec)
19.352... logprob:  0.532911, 0.240885 (1.424 sec)
19.353... logprob:  0.703647, 0.326823 (1.486 sec)
19.354... logprob:  0.782919, 0.352865 (1.432 sec)
19.355... logprob:  0.654696, 0.283854 (1.437 sec)
19.356... logprob:  0.596674, 0.290365 (1.471 sec)
19.357... logprob:  0.610636, 0.277344 (1.425 sec)
19.358... logprob:  0.569997, 0.265625 (1.436 sec)
19.359... logprob:  0.814296, 0.343750 (1.430 sec)
19.360... logprob:  0.642264, 0.277344 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.377951, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.817695e-03 [1.913572e-07] 
Layer 'conv1' biases: 1.975043e-06 [1.948521e-10] 
Layer 'conv2' weights[0]: 3.810470e-03 [1.908595e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.041899e-09] 
Layer 'conv3' weights[0]: 3.809075e-03 [1.913711e-07] 
Layer 'conv3' biases: 3.247076e-05 [1.324062e-08] 
Layer 'conv4' weights[0]: 3.825057e-03 [1.930770e-07] 
Layer 'conv4' biases: 9.999561e-01 [2.611091e-07] 
Layer 'conv5' weights[0]: 3.934645e-03 [2.538133e-06] 
Layer 'conv5' biases: 9.991201e-01 [2.695545e-06] 
Layer 'fc6' weights[0]: 7.031964e-03 [6.186667e-08] 
Layer 'fc6' biases: 9.999924e-01 [5.630852e-08] 
Layer 'fc7' weights[0]: 7.382454e-03 [1.387173e-07] 
Layer 'fc7' biases: 9.997990e-01 [1.667923e-07] 
Layer 'fc8' weights[0]: 4.617325e-03 [1.345293e-05] 
Layer 'fc8' biases: 1.521924e-02 [2.016303e-05] 
Train error last 800 batches: 0.656293
-------------------------------------------------------
Not saving because 0.377951 > 0.299667 (9.300: -1.18%)
======================================================= (2.374 sec)
19.361... logprob:  0.565502, 0.244792 (1.431 sec)
19.362... logprob:  0.667797, 0.296875 (1.489 sec)
19.363... logprob:  0.728965, 0.320312 (1.440 sec)
19.364... logprob:  0.693824, 0.312500 (1.446 sec)
19.365... logprob:  0.682607, 0.303385 (1.460 sec)
19.366... logprob:  0.650974, 0.329427 (1.443 sec)
19.367... logprob:  0.538834, 0.236979 (1.433 sec)
19.368... logprob:  0.752180, 0.364583 (1.422 sec)
19.369... logprob:  0.516680, 0.243489 (1.420 sec)
19.370... logprob:  0.638463, 0.276042 (1.431 sec)
19.371... logprob:  0.676299, 0.295573 (1.454 sec)
19.372... logprob:  0.809350, 0.358073 (1.448 sec)
19.373... logprob:  0.670113, 0.294271 (1.445 sec)
19.374... logprob:  0.644218, 0.286458 (1.446 sec)
19.375... logprob:  0.668074, 0.312500 (1.457 sec)
19.376... logprob:  0.593865, 0.298177 (1.434 sec)
19.377... logprob:  0.581875, 0.248698 (1.421 sec)
19.378... logprob:  0.664920, 0.281250 (1.457 sec)
19.379... logprob:  0.623774, 0.272135 (1.431 sec)
19.380... logprob:  0.777138, 0.345052 (1.435 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.500636, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.813896e-03 [1.908413e-07] 
Layer 'conv1' biases: 1.975219e-06 [2.565657e-10] 
Layer 'conv2' weights[0]: 3.806649e-03 [1.904946e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.068425e-09] 
Layer 'conv3' weights[0]: 3.805248e-03 [1.911008e-07] 
Layer 'conv3' biases: 3.246679e-05 [1.249885e-08] 
Layer 'conv4' weights[0]: 3.821237e-03 [1.923584e-07] 
Layer 'conv4' biases: 9.999575e-01 [2.364976e-07] 
Layer 'conv5' weights[0]: 3.931615e-03 [2.421161e-06] 
Layer 'conv5' biases: 9.991077e-01 [2.516218e-06] 
Layer 'fc6' weights[0]: 7.031235e-03 [6.453368e-08] 
Layer 'fc6' biases: 9.999925e-01 [6.035673e-08] 
Layer 'fc7' weights[0]: 7.381761e-03 [1.469132e-07] 
Layer 'fc7' biases: 9.997993e-01 [1.958577e-07] 
Layer 'fc8' weights[0]: 4.634064e-03 [1.561798e-05] 
Layer 'fc8' biases: 1.539297e-02 [3.460648e-05] 
Train error last 800 batches: 0.656315
-------------------------------------------------------
Not saving because 0.500636 > 0.299667 (9.300: -1.18%)
======================================================= (2.357 sec)
19.381... logprob:  0.703113, 0.290365 (1.473 sec)
19.382... logprob:  0.660409, 0.283854 (1.454 sec)
19.383... logprob:  0.590622, 0.264323 (1.436 sec)
19.384... logprob:  0.665367, 0.300781 (1.477 sec)
19.385... logprob:  0.759536, 0.328125 (1.423 sec)
19.386... logprob:  0.754250, 0.356771 (1.423 sec)
19.387... logprob:  0.714617, 0.295573 (1.428 sec)
19.388... logprob:  0.801366, 0.346354 (1.430 sec)
19.389... logprob:  0.748382, 0.333333 (1.426 sec)
19.390... logprob:  0.691223, 0.317708 (1.472 sec)
19.391... logprob:  0.543564, 0.242187 (1.435 sec)
19.392... logprob:  0.683104, 0.329427 (1.429 sec)
19.393... logprob:  0.662488, 0.281250 (1.480 sec)
19.394... logprob:  0.554385, 0.239583 (1.433 sec)
19.395... logprob:  0.605448, 0.268229 (1.429 sec)
19.396... logprob:  0.445299, 0.204427 (1.434 sec)
19.397... logprob:  0.721791, 0.300781 (1.430 sec)
19.398... logprob:  0.611929, 0.285156 (1.425 sec)
19.399... logprob:  0.651282, 0.279948 (1.482 sec)
19.400... logprob:  0.745096, 0.351562 (1.425 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.477482, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.810086e-03 [1.907276e-07] 
Layer 'conv1' biases: 1.976915e-06 [2.506687e-10] 
Layer 'conv2' weights[0]: 3.802830e-03 [1.903548e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.759659e-09] 
Layer 'conv3' weights[0]: 3.801464e-03 [1.907224e-07] 
Layer 'conv3' biases: 3.248516e-05 [1.120224e-08] 
Layer 'conv4' weights[0]: 3.817405e-03 [1.920685e-07] 
Layer 'conv4' biases: 9.999560e-01 [2.164273e-07] 
Layer 'conv5' weights[0]: 3.927347e-03 [2.712658e-06] 
Layer 'conv5' biases: 9.991183e-01 [3.023860e-06] 
Layer 'fc6' weights[0]: 7.030519e-03 [6.558733e-08] 
Layer 'fc6' biases: 9.999924e-01 [6.132627e-08] 
Layer 'fc7' weights[0]: 7.381075e-03 [1.518096e-07] 
Layer 'fc7' biases: 9.997989e-01 [2.181951e-07] 
Layer 'fc8' weights[0]: 4.612672e-03 [1.687324e-05] 
Layer 'fc8' biases: 1.526623e-02 [4.055719e-05] 
Train error last 800 batches: 0.656377
-------------------------------------------------------
Not saving because 0.477482 > 0.299667 (9.300: -1.18%)
======================================================= (2.350 sec)
19.401... logprob:  0.742016, 0.328125 (1.441 sec)
19.402... logprob:  0.634407, 0.266927 (1.478 sec)
19.403... logprob:  0.667471, 0.290365 (1.436 sec)
19.404... logprob:  0.717414, 0.321615 (1.431 sec)
19.405... logprob:  0.729365, 0.313802 (1.433 sec)
19.406... logprob:  0.595859, 0.270833 (1.422 sec)
19.407... logprob:  0.651518, 0.265625 (1.428 sec)
19.408... logprob:  0.682058, 0.266927 (1.484 sec)
19.409... logprob:  0.682852, 0.274740 (1.435 sec)
19.410... logprob:  0.802472, 0.325521 (1.446 sec)
19.411... logprob:  0.634128, 0.307292 (1.467 sec)
19.412... logprob:  0.773817, 0.316406 (1.435 sec)
19.413... logprob:  0.725913, 0.322917 (1.435 sec)
19.414... logprob:  0.732185, 0.304687 (1.434 sec)
19.415... logprob:  0.610233, 0.290365 (1.429 sec)
19.416... logprob:  0.628540, 0.281250 (1.470 sec)
19.417... logprob:  0.588180, 0.242187 (1.463 sec)
19.418... logprob:  0.663250, 0.282552 (1.445 sec)
19.419... logprob:  0.576184, 0.244792 (1.449 sec)
19.420... logprob:  0.615615, 0.270833 (1.456 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.433987, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.806256e-03 [1.906590e-07] 
Layer 'conv1' biases: 1.977355e-06 [1.687532e-10] 
Layer 'conv2' weights[0]: 3.799060e-03 [1.902045e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.721552e-09] 
Layer 'conv3' weights[0]: 3.797643e-03 [1.906356e-07] 
Layer 'conv3' biases: 3.251731e-05 [1.155990e-08] 
Layer 'conv4' weights[0]: 3.813595e-03 [1.920727e-07] 
Layer 'conv4' biases: 9.999568e-01 [2.352841e-07] 
Layer 'conv5' weights[0]: 3.924066e-03 [2.545871e-06] 
Layer 'conv5' biases: 9.991224e-01 [2.739147e-06] 
Layer 'fc6' weights[0]: 7.029775e-03 [6.630763e-08] 
Layer 'fc6' biases: 9.999924e-01 [6.217110e-08] 
Layer 'fc7' weights[0]: 7.380258e-03 [1.521273e-07] 
Layer 'fc7' biases: 9.997985e-01 [2.158217e-07] 
Layer 'fc8' weights[0]: 4.593279e-03 [1.644814e-05] 
Layer 'fc8' biases: 1.515426e-02 [3.621969e-05] 
Train error last 800 batches: 0.656276
-------------------------------------------------------
Not saving because 0.433987 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
19.421... logprob:  0.648285, 0.274740 (1.459 sec)
19.422... logprob:  0.784567, 0.319010 (1.444 sec)
19.423... logprob:  0.741014, 0.287760 (1.425 sec)
19.424... logprob:  0.618373, 0.265625 (1.430 sec)
19.425... logprob:  0.535049, 0.238281 (1.429 sec)
19.426... logprob:  0.614774, 0.253906 (1.443 sec)
19.427... logprob:  0.673060, 0.299479 (1.457 sec)
19.428... logprob:  0.899648, 0.401042 (1.454 sec)
19.429... logprob:  0.642644, 0.276042 (1.436 sec)
19.430... logprob:  0.560806, 0.235677 (1.471 sec)
19.431... logprob:  0.671719, 0.317708 (1.436 sec)
19.432... logprob:  0.594093, 0.240885 (1.426 sec)
19.433... logprob:  0.560886, 0.239583 (1.429 sec)
19.434... logprob:  0.682601, 0.285156 (1.438 sec)
19.435... logprob:  0.656606, 0.298177 (1.423 sec)
19.436... logprob:  0.596003, 0.255208 (1.473 sec)
19.437... logprob:  0.641281, 0.270833 (1.444 sec)
19.438... logprob:  0.786526, 0.333333 (1.428 sec)
19.439... logprob:  0.664892, 0.277344 (1.477 sec)
19.440... logprob:  0.697049, 0.313802 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.442915, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.802473e-03 [1.906417e-07] 
Layer 'conv1' biases: 1.977871e-06 [2.526751e-10] 
Layer 'conv2' weights[0]: 3.795240e-03 [1.900327e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.240204e-09] 
Layer 'conv3' weights[0]: 3.793844e-03 [1.907600e-07] 
Layer 'conv3' biases: 3.256903e-05 [1.449942e-08] 
Layer 'conv4' weights[0]: 3.809793e-03 [1.921247e-07] 
Layer 'conv4' biases: 9.999574e-01 [2.601909e-07] 
Layer 'conv5' weights[0]: 3.920752e-03 [2.656771e-06] 
Layer 'conv5' biases: 9.991133e-01 [2.857529e-06] 
Layer 'fc6' weights[0]: 7.029054e-03 [6.527159e-08] 
Layer 'fc6' biases: 9.999923e-01 [6.118147e-08] 
Layer 'fc7' weights[0]: 7.379551e-03 [1.482315e-07] 
Layer 'fc7' biases: 9.997985e-01 [1.883810e-07] 
Layer 'fc8' weights[0]: 4.612096e-03 [1.434888e-05] 
Layer 'fc8' biases: 1.534952e-02 [2.449153e-05] 
Train error last 800 batches: 0.656226
-------------------------------------------------------
Not saving because 0.442915 > 0.299667 (9.300: -1.18%)
======================================================= (2.399 sec)
19.441... logprob:  0.628238, 0.283854 (1.437 sec)
19.442... logprob:  0.625976, 0.253906 (1.438 sec)
19.443... logprob:  0.662016, 0.289062 (1.429 sec)
19.444... logprob:  0.625652, 0.274740 (1.426 sec)
19.445... logprob:  0.565270, 0.274740 (1.477 sec)
19.446... logprob:  0.603872, 0.259115 (1.430 sec)
19.447... logprob:  0.836828, 0.386719 (1.435 sec)
19.448... logprob:  0.573048, 0.278646 (1.480 sec)
19.449... logprob:  0.621501, 0.248698 (1.430 sec)
19.450... logprob:  0.480109, 0.209635 (1.430 sec)
19.451... logprob:  0.649906, 0.287760 (1.435 sec)
19.452... logprob:  0.693349, 0.286458 (1.418 sec)
19.453... logprob:  0.628901, 0.270833 (1.431 sec)
19.454... logprob:  0.690264, 0.305990 (1.511 sec)
19.455... logprob:  0.720915, 0.302083 (1.428 sec)
19.456... logprob:  0.720832, 0.281250 (1.443 sec)
19.457... logprob:  0.617545, 0.261719 (1.475 sec)
19.458... logprob:  0.611062, 0.278646 (1.428 sec)
19.459... logprob:  0.696869, 0.270833 (1.433 sec)
19.460... logprob:  0.527104, 0.240885 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.379251, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.798668e-03 [1.904621e-07] 
Layer 'conv1' biases: 1.977901e-06 [2.594220e-10] 
Layer 'conv2' weights[0]: 3.791449e-03 [1.898311e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.651276e-09] 
Layer 'conv3' weights[0]: 3.790050e-03 [1.908305e-07] 
Layer 'conv3' biases: 3.260196e-05 [1.657926e-08] 
Layer 'conv4' weights[0]: 3.805976e-03 [1.920172e-07] 
Layer 'conv4' biases: 9.999603e-01 [3.187075e-07] 
Layer 'conv5' weights[0]: 3.918450e-03 [2.497900e-06] 
Layer 'conv5' biases: 9.991068e-01 [2.752660e-06] 
Layer 'fc6' weights[0]: 7.028344e-03 [6.092820e-08] 
Layer 'fc6' biases: 9.999923e-01 [5.547546e-08] 
Layer 'fc7' weights[0]: 7.378826e-03 [1.372415e-07] 
Layer 'fc7' biases: 9.997984e-01 [1.617859e-07] 
Layer 'fc8' weights[0]: 4.618096e-03 [1.306266e-05] 
Layer 'fc8' biases: 1.547843e-02 [1.069392e-05] 
Train error last 800 batches: 0.656100
-------------------------------------------------------
Not saving because 0.379251 > 0.299667 (9.300: -1.18%)
======================================================= (2.383 sec)
19.461... logprob:  0.695149, 0.305990 (1.422 sec)
19.462... logprob:  0.668626, 0.295573 (1.430 sec)
19.463... logprob:  0.582612, 0.244792 (1.473 sec)
19.464... logprob:  0.763894, 0.339844 (1.447 sec)
19.465... logprob:  0.611468, 0.264323 (1.447 sec)
19.466... logprob:  0.585123, 0.246094 (1.452 sec)
19.467... logprob:  0.606004, 0.257812 (1.443 sec)
19.468... logprob:  0.681207, 0.303385 (1.442 sec)
19.469... logprob:  0.652276, 0.250000 (1.429 sec)
19.470... logprob:  0.690067, 0.302083 (1.421 sec)
19.471... logprob:  0.708900, 0.303385 (1.440 sec)
19.472... logprob:  0.623688, 0.276042 (1.456 sec)
19.473... logprob:  0.662535, 0.276042 (1.456 sec)
19.474... logprob:  0.623108, 0.261719 (1.451 sec)
19.475... logprob:  0.699610, 0.282552 (1.437 sec)
19.476... logprob:  0.727544, 0.277344 (1.466 sec)
19.477... logprob:  0.476422, 0.222656 (1.435 sec)
19.478... logprob:  0.702812, 0.313802 (1.421 sec)
19.479... logprob:  0.509646, 0.216146 (1.422 sec)
19.480... logprob:  0.678656, 0.269531 (1.434 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.555910, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.794868e-03 [1.900032e-07] 
Layer 'conv1' biases: 1.978487e-06 [1.875199e-10] 
Layer 'conv2' weights[0]: 3.787658e-03 [1.895619e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.486693e-09] 
Layer 'conv3' weights[0]: 3.786290e-03 [1.900014e-07] 
Layer 'conv3' biases: 3.264239e-05 [1.016585e-08] 
Layer 'conv4' weights[0]: 3.802179e-03 [1.910796e-07] 
Layer 'conv4' biases: 9.999619e-01 [1.828959e-07] 
Layer 'conv5' weights[0]: 3.916010e-03 [2.317351e-06] 
Layer 'conv5' biases: 9.991060e-01 [2.618639e-06] 
Layer 'fc6' weights[0]: 7.027607e-03 [6.086508e-08] 
Layer 'fc6' biases: 9.999921e-01 [5.526629e-08] 
Layer 'fc7' weights[0]: 7.378033e-03 [1.392823e-07] 
Layer 'fc7' biases: 9.997981e-01 [1.661297e-07] 
Layer 'fc8' weights[0]: 4.605066e-03 [1.314168e-05] 
Layer 'fc8' biases: 1.544056e-02 [1.495951e-05] 
Train error last 800 batches: 0.656035
-------------------------------------------------------
Not saving because 0.555910 > 0.299667 (9.300: -1.18%)
======================================================= (2.386 sec)
19.481... logprob:  0.792984, 0.332031 (1.436 sec)
19.482... logprob:  0.686671, 0.287760 (1.478 sec)
19.483... logprob:  0.725602, 0.312500 (1.446 sec)
19.484... logprob:  0.677177, 0.307292 (1.432 sec)
19.485... logprob:  0.575962, 0.266927 (1.476 sec)
19.486... logprob:  0.619598, 0.263021 (1.426 sec)
19.487... logprob:  0.687335, 0.274740 (1.432 sec)
19.488... logprob:  0.665790, 0.290365 (1.428 sec)
19.489... logprob:  0.679690, 0.296875 (1.428 sec)
19.490... logprob:  0.747112, 0.313802 (1.424 sec)
19.491... logprob:  0.575188, 0.257812 (1.478 sec)
19.492... logprob:  0.746254, 0.299479 (1.475 sec)
19.493... logprob:  0.730687, 0.342448 (1.427 sec)
19.494... logprob:  0.672518, 0.294271 (1.486 sec)
19.495... logprob:  0.607090, 0.274740 (1.427 sec)
19.496... logprob:  0.742625, 0.328125 (1.427 sec)
19.497... logprob:  0.740407, 0.319010 (1.427 sec)
19.498... logprob:  0.707244, 0.304687 (1.427 sec)
19.499... logprob:  0.721863, 0.300781 (1.426 sec)
19.500... logprob:  0.544325, 0.234375 (1.479 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.466332, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.791069e-03 [1.899719e-07] 
Layer 'conv1' biases: 1.979984e-06 [2.359202e-10] 
Layer 'conv2' weights[0]: 3.783875e-03 [1.894252e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.946745e-09] 
Layer 'conv3' weights[0]: 3.782476e-03 [1.899519e-07] 
Layer 'conv3' biases: 3.266063e-05 [1.275950e-08] 
Layer 'conv4' weights[0]: 3.798364e-03 [1.913077e-07] 
Layer 'conv4' biases: 9.999616e-01 [2.411058e-07] 
Layer 'conv5' weights[0]: 3.912061e-03 [2.463590e-06] 
Layer 'conv5' biases: 9.991167e-01 [2.700116e-06] 
Layer 'fc6' weights[0]: 7.026908e-03 [6.300428e-08] 
Layer 'fc6' biases: 9.999922e-01 [5.785865e-08] 
Layer 'fc7' weights[0]: 7.377297e-03 [1.446320e-07] 
Layer 'fc7' biases: 9.997970e-01 [1.790918e-07] 
Layer 'fc8' weights[0]: 4.583195e-03 [1.416979e-05] 
Layer 'fc8' biases: 1.528898e-02 [2.099128e-05] 
Train error last 800 batches: 0.656692
-------------------------------------------------------
Not saving because 0.466332 > 0.299667 (9.300: -1.18%)
======================================================= (2.411 sec)
19.501... logprob:  0.520713, 0.242188 (1.433 sec)
19.502... logprob:  0.780462, 0.339844 (1.442 sec)
19.503... logprob:  0.638028, 0.259115 (1.475 sec)
19.504... logprob:  0.720046, 0.337240 (1.424 sec)
19.505... logprob:  0.740935, 0.312500 (1.434 sec)
19.506... logprob:  0.651113, 0.302083 (1.434 sec)
19.507... logprob:  0.520144, 0.233073 (1.418 sec)
19.508... logprob:  0.677009, 0.294271 (1.429 sec)
19.509... logprob:  0.573784, 0.252604 (1.476 sec)
19.510... logprob:  0.630106, 0.272135 (1.441 sec)
19.511... logprob:  0.594297, 0.279948 (1.448 sec)
19.512... logprob:  0.698870, 0.303385 (1.460 sec)
19.513... logprob:  0.581339, 0.265625 (1.437 sec)
19.514... logprob:  0.600099, 0.256510 (1.433 sec)
19.515... logprob:  0.657118, 0.277344 (1.422 sec)
19.516... logprob:  0.625655, 0.283854 (1.420 sec)
19.517... logprob:  0.729716, 0.309896 (1.442 sec)
19.518... logprob:  0.662255, 0.315104 (1.458 sec)
19.519... logprob:  0.692744, 0.334635 (1.446 sec)
19.520... logprob:  0.574634, 0.265625 (1.450 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.387538, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.787285e-03 [1.895377e-07] 
Layer 'conv1' biases: 1.980442e-06 [1.635745e-10] 
Layer 'conv2' weights[0]: 3.780099e-03 [1.892041e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.659687e-09] 
Layer 'conv3' weights[0]: 3.778680e-03 [1.895443e-07] 
Layer 'conv3' biases: 3.267127e-05 [1.062557e-08] 
Layer 'conv4' weights[0]: 3.794557e-03 [1.906804e-07] 
Layer 'conv4' biases: 9.999619e-01 [2.031125e-07] 
Layer 'conv5' weights[0]: 3.909032e-03 [2.462117e-06] 
Layer 'conv5' biases: 9.990996e-01 [2.719006e-06] 
Layer 'fc6' weights[0]: 7.026180e-03 [6.252326e-08] 
Layer 'fc6' biases: 9.999923e-01 [5.721487e-08] 
Layer 'fc7' weights[0]: 7.376540e-03 [1.413282e-07] 
Layer 'fc7' biases: 9.997977e-01 [1.969347e-07] 
Layer 'fc8' weights[0]: 4.638961e-03 [1.445140e-05] 
Layer 'fc8' biases: 1.565221e-02 [3.231625e-05] 
Train error last 800 batches: 0.656521
-------------------------------------------------------
Not saving because 0.387538 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
19.521... logprob:  0.642177, 0.264323 (1.448 sec)
19.522... logprob:  0.825916, 0.365885 (1.465 sec)
19.523... logprob:  0.613832, 0.290365 (1.437 sec)
19.524... logprob:  0.748869, 0.341146 (1.421 sec)
19.525... logprob:  0.663475, 0.276042 (1.426 sec)
19.526... logprob:  0.618216, 0.287760 (1.428 sec)
19.527... logprob:  0.649429, 0.298177 (1.434 sec)
19.528... logprob:  0.637582, 0.269531 (1.463 sec)
19.529... logprob:  0.564762, 0.257812 (1.443 sec)
19.530... logprob:  0.575845, 0.270833 (1.459 sec)
19.531... logprob:  0.667583, 0.298177 (1.475 sec)
19.532... logprob:  0.756107, 0.299479 (1.424 sec)
19.533... logprob:  0.724588, 0.285156 (1.424 sec)
19.534... logprob:  0.583967, 0.287760 (1.424 sec)
19.535... logprob:  0.733587, 0.283854 (1.432 sec)
19.536... logprob:  0.731613, 0.294271 (1.428 sec)
19.537... logprob:  0.617647, 0.274740 (1.594 sec)
19.538... logprob:  0.628323, 0.298177 (1.439 sec)
19.539... logprob:  0.576669, 0.290364 (1.425 sec)
19.540... logprob:  0.658163, 0.283854 (1.487 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.442593, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.783501e-03 [1.894434e-07] 
Layer 'conv1' biases: 1.980589e-06 [1.651433e-10] 
Layer 'conv2' weights[0]: 3.776304e-03 [1.890244e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.847558e-09] 
Layer 'conv3' weights[0]: 3.774917e-03 [1.894417e-07] 
Layer 'conv3' biases: 3.268832e-05 [1.042222e-08] 
Layer 'conv4' weights[0]: 3.790796e-03 [1.903988e-07] 
Layer 'conv4' biases: 9.999654e-01 [1.920124e-07] 
Layer 'conv5' weights[0]: 3.907227e-03 [2.171531e-06] 
Layer 'conv5' biases: 9.991089e-01 [2.346449e-06] 
Layer 'fc6' weights[0]: 7.025462e-03 [5.879403e-08] 
Layer 'fc6' biases: 9.999922e-01 [5.229690e-08] 
Layer 'fc7' weights[0]: 7.375821e-03 [1.319118e-07] 
Layer 'fc7' biases: 9.997972e-01 [1.533896e-07] 
Layer 'fc8' weights[0]: 4.627102e-03 [1.235298e-05] 
Layer 'fc8' biases: 1.552803e-02 [1.190655e-05] 
Train error last 800 batches: 0.656546
-------------------------------------------------------
Not saving because 0.442593 > 0.299667 (9.300: -1.18%)
======================================================= (2.379 sec)
19.541... logprob:  0.617054, 0.277344 (1.433 sec)
19.542... logprob:  0.580622, 0.263021 (1.429 sec)
19.543... logprob:  0.517142, 0.251302 (1.437 sec)
19.544... logprob:  0.626837, 0.281250 (1.433 sec)
19.545... logprob:  0.631712, 0.268229 (1.432 sec)
19.546... logprob:  0.545399, 0.226562 (1.480 sec)
19.547... logprob:  0.665003, 0.281250 (1.429 sec)
19.548... logprob:  0.586312, 0.268229 (1.442 sec)
19.549... logprob:  0.681456, 0.296875 (1.474 sec)
19.550... logprob:  0.633170, 0.294271 (1.424 sec)
19.551... logprob:  0.613507, 0.291667 (1.432 sec)
19.552... logprob:  0.668327, 0.276042 (1.434 sec)
19.553... logprob:  0.546954, 0.239583 (1.420 sec)
19.554... logprob:  0.698903, 0.303385 (1.427 sec)
19.555... logprob:  0.721461, 0.317708 (1.477 sec)
19.556... logprob:  0.591475, 0.229167 (1.431 sec)
19.557... logprob:  0.608405, 0.265625 (1.445 sec)
19.558... logprob:  0.559579, 0.255208 (1.468 sec)
19.559... logprob:  0.617121, 0.260417 (1.435 sec)
19.560... logprob:  0.579452, 0.240885 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.469036, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.779726e-03 [1.892864e-07] 
Layer 'conv1' biases: 1.979910e-06 [1.611539e-10] 
Layer 'conv2' weights[0]: 3.772541e-03 [1.889410e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.954738e-09] 
Layer 'conv3' weights[0]: 3.771138e-03 [1.893558e-07] 
Layer 'conv3' biases: 3.264904e-05 [1.157837e-08] 
Layer 'conv4' weights[0]: 3.786986e-03 [1.906935e-07] 
Layer 'conv4' biases: 9.999666e-01 [2.360848e-07] 
Layer 'conv5' weights[0]: 3.904678e-03 [2.424046e-06] 
Layer 'conv5' biases: 9.990886e-01 [2.650823e-06] 
Layer 'fc6' weights[0]: 7.024754e-03 [6.322075e-08] 
Layer 'fc6' biases: 9.999922e-01 [5.865621e-08] 
Layer 'fc7' weights[0]: 7.375082e-03 [1.517424e-07] 
Layer 'fc7' biases: 9.997993e-01 [2.165478e-07] 
Layer 'fc8' weights[0]: 4.692456e-03 [1.767128e-05] 
Layer 'fc8' biases: 1.592367e-02 [3.754171e-05] 
Train error last 800 batches: 0.656350
-------------------------------------------------------
Not saving because 0.469036 > 0.299667 (9.300: -1.18%)
======================================================= (2.354 sec)
19.561... logprob:  0.620017, 0.272135 (1.433 sec)
19.562... logprob:  0.709697, 0.287760 (1.428 sec)
19.563... logprob:  0.641312, 0.285156 (1.438 sec)
19.564... logprob:  0.688457, 0.308594 (1.463 sec)
19.565... logprob:  0.868298, 0.338542 (1.446 sec)
19.566... logprob:  0.552107, 0.251302 (1.453 sec)
19.567... logprob:  0.681581, 0.292969 (1.448 sec)
19.568... logprob:  0.671105, 0.305990 (1.477 sec)
19.569... logprob:  0.708705, 0.302083 (1.439 sec)
19.570... logprob:  0.604444, 0.282552 (1.419 sec)
19.571... logprob:  0.683928, 0.298177 (1.425 sec)
19.572... logprob:  0.697795, 0.305990 (1.440 sec)
19.573... logprob:  0.722531, 0.296875 (1.444 sec)
19.574... logprob:  0.591157, 0.274739 (1.458 sec)
19.575... logprob:  0.580745, 0.252604 (1.447 sec)
19.576... logprob:  0.627004, 0.289063 (1.440 sec)
19.577... logprob:  0.663938, 0.285156 (1.472 sec)
19.578... logprob:  0.571060, 0.279948 (1.429 sec)
19.579... logprob:  0.692154, 0.295573 (1.419 sec)
19.580... logprob:  0.669940, 0.289062 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.500083, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.775943e-03 [1.890572e-07] 
Layer 'conv1' biases: 1.980470e-06 [2.189810e-10] 
Layer 'conv2' weights[0]: 3.768783e-03 [1.886643e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.745774e-09] 
Layer 'conv3' weights[0]: 3.767381e-03 [1.890829e-07] 
Layer 'conv3' biases: 3.265866e-05 [1.037359e-08] 
Layer 'conv4' weights[0]: 3.783201e-03 [1.902371e-07] 
Layer 'conv4' biases: 9.999677e-01 [1.927151e-07] 
Layer 'conv5' weights[0]: 3.901561e-03 [2.369286e-06] 
Layer 'conv5' biases: 9.991089e-01 [2.603494e-06] 
Layer 'fc6' weights[0]: 7.023996e-03 [6.420312e-08] 
Layer 'fc6' biases: 9.999921e-01 [5.952286e-08] 
Layer 'fc7' weights[0]: 7.374314e-03 [1.499762e-07] 
Layer 'fc7' biases: 9.997973e-01 [2.132650e-07] 
Layer 'fc8' weights[0]: 4.640838e-03 [1.712227e-05] 
Layer 'fc8' biases: 1.561785e-02 [3.644035e-05] 
Train error last 800 batches: 0.655337
-------------------------------------------------------
Not saving because 0.500083 > 0.299667 (9.300: -1.18%)
======================================================= (2.354 sec)
19.581... logprob:  0.766514, 0.322917 (1.434 sec)
19.582... logprob:  0.629718, 0.279948 (1.429 sec)
19.583... logprob:  0.870004, 0.337240 (1.479 sec)
19.584... logprob:  0.631469, 0.285156 (1.443 sec)
19.585... logprob:  0.554993, 0.246094 (1.427 sec)
19.586... logprob:  0.591756, 0.289062 (1.484 sec)
19.587... logprob:  0.709073, 0.333333 (1.425 sec)
19.588... logprob:  0.661636, 0.296875 (1.422 sec)
19.589... logprob:  0.637651, 0.277344 (1.431 sec)
19.590... logprob:  0.655703, 0.278646 (1.426 sec)
19.591... logprob:  0.558121, 0.242187 (1.425 sec)
19.592... logprob:  0.712025, 0.326823 (1.475 sec)
19.593... logprob:  0.688067, 0.300781 (1.434 sec)
19.594... logprob:  0.635274, 0.296875 (1.430 sec)
19.595... logprob:  0.662663, 0.279948 (1.477 sec)
19.596... logprob:  0.729842, 0.333333 (1.427 sec)
19.597... logprob:  0.673540, 0.287760 (1.428 sec)
19.598... logprob:  0.592115, 0.279948 (1.433 sec)
19.599... logprob:  0.574338, 0.268229 (1.424 sec)
19.600... logprob:  0.653644, 0.304687 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.518241, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.772171e-03 [1.890661e-07] 
Layer 'conv1' biases: 1.981336e-06 [1.769772e-10] 
Layer 'conv2' weights[0]: 3.765004e-03 [1.886047e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.024541e-09] 
Layer 'conv3' weights[0]: 3.763628e-03 [1.891656e-07] 
Layer 'conv3' biases: 3.266154e-05 [1.312590e-08] 
Layer 'conv4' weights[0]: 3.779419e-03 [1.907504e-07] 
Layer 'conv4' biases: 9.999681e-01 [2.627175e-07] 
Layer 'conv5' weights[0]: 3.898196e-03 [2.829398e-06] 
Layer 'conv5' biases: 9.991079e-01 [3.201808e-06] 
Layer 'fc6' weights[0]: 7.023280e-03 [6.816331e-08] 
Layer 'fc6' biases: 9.999923e-01 [6.479622e-08] 
Layer 'fc7' weights[0]: 7.373588e-03 [1.543288e-07] 
Layer 'fc7' biases: 9.997970e-01 [2.357250e-07] 
Layer 'fc8' weights[0]: 4.638119e-03 [1.624515e-05] 
Layer 'fc8' biases: 1.568953e-02 [3.881610e-05] 
Train error last 800 batches: 0.655957
-------------------------------------------------------
Not saving because 0.518241 > 0.299667 (9.300: -1.18%)
======================================================= (2.347 sec)
19.601... logprob:  0.668726, 0.295573 (1.487 sec)
19.602... logprob:  0.493255, 0.221354 (1.435 sec)
19.603... logprob:  0.559916, 0.235677 (1.444 sec)
19.604... logprob:  0.667214, 0.299479 (1.471 sec)
19.605... logprob:  0.674265, 0.294271 (1.429 sec)
19.606... logprob:  0.581848, 0.270833 (1.472 sec)
19.607... logprob:  0.729146, 0.302083 (1.427 sec)
19.608... logprob:  0.618512, 0.263021 (1.425 sec)
19.609... logprob:  0.608957, 0.274740 (1.428 sec)
19.610... logprob:  0.705713, 0.319010 (1.467 sec)
19.611... logprob:  0.683317, 0.283854 (1.438 sec)
19.612... logprob:  0.615648, 0.251302 (1.449 sec)
19.613... logprob:  0.530142, 0.234375 (1.452 sec)
19.614... logprob:  0.725491, 0.270833 (1.444 sec)
19.615... logprob:  0.556351, 0.247396 (1.431 sec)
19.616... logprob:  0.586738, 0.272135 (1.422 sec)
19.617... logprob:  0.665406, 0.278646 (1.420 sec)
19.618... logprob:  0.730835, 0.307292 (1.430 sec)
19.619... logprob:  0.662076, 0.299479 (1.447 sec)
19.620... logprob:  0.771603, 0.313802 (1.452 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.512134, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.768402e-03 [1.884753e-07] 
Layer 'conv1' biases: 1.981387e-06 [2.160080e-10] 
Layer 'conv2' weights[0]: 3.761227e-03 [1.882474e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.089104e-09] 
Layer 'conv3' weights[0]: 3.759848e-03 [1.890882e-07] 
Layer 'conv3' biases: 3.263362e-05 [1.401436e-08] 
Layer 'conv4' weights[0]: 3.775635e-03 [1.904705e-07] 
Layer 'conv4' biases: 9.999688e-01 [2.666477e-07] 
Layer 'conv5' weights[0]: 3.894904e-03 [3.207301e-06] 
Layer 'conv5' biases: 9.990867e-01 [3.418837e-06] 
Layer 'fc6' weights[0]: 7.022532e-03 [7.269509e-08] 
Layer 'fc6' biases: 9.999923e-01 [7.133884e-08] 
Layer 'fc7' weights[0]: 7.372889e-03 [1.709687e-07] 
Layer 'fc7' biases: 9.997977e-01 [2.669685e-07] 
Layer 'fc8' weights[0]: 4.664484e-03 [1.781154e-05] 
Layer 'fc8' biases: 1.599768e-02 [4.176830e-05] 
Train error last 800 batches: 0.655556
-------------------------------------------------------
Not saving because 0.512134 > 0.299667 (9.300: -1.18%)
======================================================= (2.387 sec)
19.621... logprob:  0.620643, 0.277344 (1.454 sec)
19.622... logprob:  0.601187, 0.279948 (1.450 sec)
19.623... logprob:  0.643579, 0.285156 (1.470 sec)
19.624... logprob:  0.616850, 0.279948 (1.436 sec)
19.625... logprob:  0.749439, 0.309896 (1.421 sec)
19.626... logprob:  0.650113, 0.285156 (1.441 sec)
19.627... logprob:  0.691950, 0.305990 (1.431 sec)
19.628... logprob:  0.625898, 0.256510 (1.437 sec)
19.629... logprob:  0.617067, 0.298177 (1.469 sec)
19.630... logprob:  0.602329, 0.255208 (1.449 sec)
19.631... logprob:  0.800990, 0.330729 (1.435 sec)
19.632... logprob:  0.678001, 0.303385 (1.478 sec)
19.633... logprob:  0.572959, 0.257812 (1.427 sec)
19.634... logprob:  0.792226, 0.319010 (1.419 sec)
19.635... logprob:  0.600684, 0.286458 (1.430 sec)
19.636... logprob:  0.753643, 0.334635 (1.431 sec)
19.637... logprob:  0.603970, 0.282552 (1.431 sec)
19.638... logprob:  0.745987, 0.328125 (1.475 sec)
19.639... logprob:  0.670388, 0.300781 (1.433 sec)
19.640... logprob:  0.672898, 0.295573 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.451568, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.764639e-03 [1.886797e-07] 
Layer 'conv1' biases: 1.981408e-06 [1.960160e-10] 
Layer 'conv2' weights[0]: 3.757481e-03 [1.881021e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.002611e-09] 
Layer 'conv3' weights[0]: 3.756104e-03 [1.885495e-07] 
Layer 'conv3' biases: 3.264733e-05 [1.245232e-08] 
Layer 'conv4' weights[0]: 3.771838e-03 [1.897836e-07] 
Layer 'conv4' biases: 9.999691e-01 [2.424953e-07] 
Layer 'conv5' weights[0]: 3.891883e-03 [2.410646e-06] 
Layer 'conv5' biases: 9.991033e-01 [2.532359e-06] 
Layer 'fc6' weights[0]: 7.021777e-03 [6.338048e-08] 
Layer 'fc6' biases: 9.999924e-01 [5.842312e-08] 
Layer 'fc7' weights[0]: 7.372130e-03 [1.445382e-07] 
Layer 'fc7' biases: 9.997962e-01 [1.937708e-07] 
Layer 'fc8' weights[0]: 4.596425e-03 [1.483859e-05] 
Layer 'fc8' biases: 1.551772e-02 [2.365102e-05] 
Train error last 800 batches: 0.655648
-------------------------------------------------------
Not saving because 0.451568 > 0.299667 (9.300: -1.18%)
======================================================= (2.365 sec)
19.641... logprob:  0.646416, 0.278646 (1.482 sec)
19.642... logprob:  0.677347, 0.296875 (1.431 sec)
19.643... logprob:  0.800823, 0.326823 (1.428 sec)
19.644... logprob:  0.618987, 0.274740 (1.429 sec)
19.645... logprob:  0.697386, 0.312500 (1.423 sec)
19.646... logprob:  0.580662, 0.266927 (1.424 sec)
19.647... logprob:  0.689674, 0.290365 (1.485 sec)
19.648... logprob:  0.578554, 0.261719 (1.434 sec)
19.649... logprob:  0.566934, 0.221354 (1.436 sec)
19.650... logprob:  0.716550, 0.285156 (1.473 sec)
19.651... logprob:  0.572167, 0.260416 (1.426 sec)
19.652... logprob:  0.649978, 0.265625 (1.437 sec)
19.653... logprob:  0.762399, 0.328125 (1.430 sec)
19.654... logprob:  0.604611, 0.266927 (1.426 sec)
19.655... logprob:  0.644516, 0.278646 (1.426 sec)
19.656... logprob:  0.583414, 0.273437 (1.476 sec)
19.657... logprob:  0.718021, 0.341146 (1.438 sec)
19.658... logprob:  0.580529, 0.248698 (1.449 sec)
19.659... logprob:  0.698461, 0.281250 (1.455 sec)
19.660... logprob:  0.699796, 0.339844 (1.437 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.437528, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.760872e-03 [1.884354e-07] 
Layer 'conv1' biases: 1.982192e-06 [1.781407e-10] 
Layer 'conv2' weights[0]: 3.753737e-03 [1.879948e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.636414e-09] 
Layer 'conv3' weights[0]: 3.752343e-03 [1.883250e-07] 
Layer 'conv3' biases: 3.266768e-05 [1.044911e-08] 
Layer 'conv4' weights[0]: 3.768100e-03 [1.898630e-07] 
Layer 'conv4' biases: 9.999690e-01 [2.269630e-07] 
Layer 'conv5' weights[0]: 3.887994e-03 [2.899311e-06] 
Layer 'conv5' biases: 9.990990e-01 [3.059336e-06] 
Layer 'fc6' weights[0]: 7.021053e-03 [6.450758e-08] 
Layer 'fc6' biases: 9.999924e-01 [6.010023e-08] 
Layer 'fc7' weights[0]: 7.371372e-03 [1.501790e-07] 
Layer 'fc7' biases: 9.997961e-01 [2.074218e-07] 
Layer 'fc8' weights[0]: 4.602944e-03 [1.601970e-05] 
Layer 'fc8' biases: 1.553418e-02 [3.616033e-05] 
Train error last 800 batches: 0.655260
-------------------------------------------------------
Not saving because 0.437528 > 0.299667 (9.300: -1.18%)
======================================================= (2.387 sec)
19.661... logprob:  0.618922, 0.274740 (1.439 sec)
19.662... logprob:  0.687061, 0.299479 (1.432 sec)
19.663... logprob:  0.587315, 0.273437 (1.425 sec)
19.664... logprob:  0.527822, 0.246094 (1.431 sec)
19.665... logprob:  0.634965, 0.266927 (1.454 sec)
19.666... logprob:  0.712915, 0.319010 (1.445 sec)
19.667... logprob:  0.878506, 0.341146 (1.449 sec)
19.668... logprob:  0.667934, 0.272135 (1.453 sec)
19.669... logprob:  0.680611, 0.311198 (1.457 sec)
19.670... logprob:  0.642876, 0.300781 (1.430 sec)
19.671... logprob:  0.691963, 0.334635 (1.420 sec)
19.672... logprob:  0.660049, 0.285156 (1.424 sec)
19.673... logprob:  0.639192, 0.273438 (1.433 sec)
19.674... logprob:  0.688340, 0.274740 (1.433 sec)
19.675... logprob:  0.563121, 0.248698 (1.463 sec)
19.676... logprob:  0.706152, 0.282552 (1.443 sec)
19.677... logprob:  0.660551, 0.283854 (1.437 sec)
19.678... logprob:  0.642391, 0.259115 (1.481 sec)
19.679... logprob:  0.666229, 0.309896 (1.424 sec)
19.680... logprob:  0.589900, 0.266927 (1.419 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.556858, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.757113e-03 [1.879656e-07] 
Layer 'conv1' biases: 1.983224e-06 [2.230879e-10] 
Layer 'conv2' weights[0]: 3.749975e-03 [1.877250e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.854320e-09] 
Layer 'conv3' weights[0]: 3.748571e-03 [1.882802e-07] 
Layer 'conv3' biases: 3.268984e-05 [1.207031e-08] 
Layer 'conv4' weights[0]: 3.764332e-03 [1.892864e-07] 
Layer 'conv4' biases: 9.999681e-01 [2.175626e-07] 
Layer 'conv5' weights[0]: 3.883772e-03 [2.462461e-06] 
Layer 'conv5' biases: 9.990922e-01 [2.668144e-06] 
Layer 'fc6' weights[0]: 7.020354e-03 [6.107964e-08] 
Layer 'fc6' biases: 9.999925e-01 [5.576422e-08] 
Layer 'fc7' weights[0]: 7.370634e-03 [1.375859e-07] 
Layer 'fc7' biases: 9.997962e-01 [1.653129e-07] 
Layer 'fc8' weights[0]: 4.625906e-03 [1.341061e-05] 
Layer 'fc8' biases: 1.574219e-02 [1.625345e-05] 
Train error last 800 batches: 0.655445
-------------------------------------------------------
Not saving because 0.556858 > 0.299667 (9.300: -1.18%)
======================================================= (2.389 sec)
19.681... logprob:  0.571386, 0.272135 (1.434 sec)
19.682... logprob:  0.536069, 0.233073 (1.438 sec)
19.683... logprob:  0.684831, 0.272135 (1.427 sec)
19.684... logprob:  0.565043, 0.246094 (1.468 sec)
19.685... logprob:  0.565708, 0.253906 (1.441 sec)
19.686... logprob:  0.564962, 0.231771 (1.434 sec)
19.687... logprob:  0.569022, 0.261719 (1.481 sec)
19.688... logprob:  0.543636, 0.259115 (1.431 sec)
19.689... logprob:  0.626090, 0.263021 (1.425 sec)
19.690... logprob:  0.673798, 0.270833 (1.429 sec)
19.691... logprob:  0.593928, 0.239583 (1.429 sec)
19.692... logprob:  0.621228, 0.263021 (1.429 sec)
19.693... logprob:  0.705736, 0.285156 (1.479 sec)
19.694... logprob:  0.702277, 0.289062 (1.430 sec)
19.695... logprob:  0.619013, 0.278646 (1.435 sec)
19.696... logprob:  0.650972, 0.261719 (1.475 sec)
19.697... logprob:  0.670127, 0.302083 (1.436 sec)
19.698... logprob:  0.778999, 0.326823 (1.433 sec)
19.699... logprob:  0.673298, 0.276042 (1.431 sec)
19.700... logprob:  0.605633, 0.263021 (1.416 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.382436, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.753359e-03 [1.878146e-07] 
Layer 'conv1' biases: 1.983801e-06 [2.857401e-10] 
Layer 'conv2' weights[0]: 3.746222e-03 [1.874414e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.701524e-09] 
Layer 'conv3' weights[0]: 3.744851e-03 [1.884763e-07] 
Layer 'conv3' biases: 3.270913e-05 [1.568855e-08] 
Layer 'conv4' weights[0]: 3.760553e-03 [1.896946e-07] 
Layer 'conv4' biases: 9.999655e-01 [3.034037e-07] 
Layer 'conv5' weights[0]: 3.879217e-03 [3.366704e-06] 
Layer 'conv5' biases: 9.990844e-01 [3.718551e-06] 
Layer 'fc6' weights[0]: 7.019651e-03 [7.379884e-08] 
Layer 'fc6' biases: 9.999924e-01 [7.305050e-08] 
Layer 'fc7' weights[0]: 7.369878e-03 [1.764924e-07] 
Layer 'fc7' biases: 9.997973e-01 [2.847447e-07] 
Layer 'fc8' weights[0]: 4.659387e-03 [1.855384e-05] 
Layer 'fc8' biases: 1.600149e-02 [4.309404e-05] 
Train error last 800 batches: 0.654869
-------------------------------------------------------
Not saving because 0.382436 > 0.299667 (9.300: -1.18%)
======================================================= (2.363 sec)
19.701... logprob:  0.699632, 0.330729 (1.435 sec)
19.702... logprob:  0.814559, 0.326823 (1.476 sec)
19.703... logprob:  0.676164, 0.286458 (1.432 sec)
19.704... logprob:  0.660166, 0.261719 (1.440 sec)
19.705... logprob:  0.705001, 0.311198 (1.469 sec)
19.706... logprob:  0.702142, 0.296875 (1.437 sec)
19.707... logprob:  0.751905, 0.360677 (1.435 sec)
19.708... logprob:  0.713356, 0.296875 (1.429 sec)
19.709... logprob:  0.626328, 0.272135 (1.414 sec)
19.710... logprob:  0.730407, 0.329427 (1.434 sec)
19.711... logprob:  0.725526, 0.334635 (1.459 sec)
19.712... logprob:  0.594228, 0.279948 (1.447 sec)
19.713... logprob:  0.779547, 0.354167 (1.452 sec)
19.714... logprob:  0.685536, 0.316406 (1.452 sec)
19.715... logprob:  0.741578, 0.309896 (1.446 sec)
19.716... logprob:  0.597184, 0.287760 (1.434 sec)
19.717... logprob:  0.693151, 0.317708 (1.428 sec)
19.718... logprob:  0.776752, 0.329427 (1.419 sec)
19.719... logprob:  0.640449, 0.298177 (1.435 sec)
19.720... logprob:  0.619719, 0.265625 (1.443 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.543922, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.749617e-03 [1.877916e-07] 
Layer 'conv1' biases: 1.984259e-06 [1.622642e-10] 
Layer 'conv2' weights[0]: 3.742487e-03 [1.873800e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.616384e-09] 
Layer 'conv3' weights[0]: 3.741070e-03 [1.878045e-07] 
Layer 'conv3' biases: 3.276411e-05 [1.086442e-08] 
Layer 'conv4' weights[0]: 3.756780e-03 [1.892291e-07] 
Layer 'conv4' biases: 9.999647e-01 [2.383254e-07] 
Layer 'conv5' weights[0]: 3.875073e-03 [2.370565e-06] 
Layer 'conv5' biases: 9.991186e-01 [2.558813e-06] 
Layer 'fc6' weights[0]: 7.018916e-03 [6.249003e-08] 
Layer 'fc6' biases: 9.999925e-01 [5.711453e-08] 
Layer 'fc7' weights[0]: 7.369157e-03 [1.422188e-07] 
Layer 'fc7' biases: 9.997942e-01 [1.808068e-07] 
Layer 'fc8' weights[0]: 4.575810e-03 [1.371586e-05] 
Layer 'fc8' biases: 1.532263e-02 [1.925571e-05] 
Train error last 800 batches: 0.655561
-------------------------------------------------------
Not saving because 0.543922 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
19.721... logprob:  0.593467, 0.253906 (1.466 sec)
19.722... logprob:  0.746642, 0.338542 (1.458 sec)
19.723... logprob:  0.658151, 0.313802 (1.443 sec)
19.724... logprob:  0.600555, 0.264323 (1.466 sec)
19.725... logprob:  0.697055, 0.298177 (1.427 sec)
19.726... logprob:  0.583404, 0.244792 (1.420 sec)
19.727... logprob:  0.573572, 0.256510 (1.423 sec)
19.728... logprob:  0.729543, 0.307292 (1.434 sec)
19.729... logprob:  0.714155, 0.304688 (1.427 sec)
19.730... logprob:  0.788305, 0.326823 (1.467 sec)
19.731... logprob:  0.675652, 0.305990 (1.444 sec)
19.732... logprob:  0.567644, 0.253906 (1.435 sec)
19.733... logprob:  0.722039, 0.324219 (1.484 sec)
19.734... logprob:  0.587644, 0.253906 (1.430 sec)
19.735... logprob:  0.693993, 0.296875 (1.425 sec)
19.736... logprob:  0.788020, 0.348958 (1.436 sec)
19.737... logprob:  0.671198, 0.294271 (1.422 sec)
19.738... logprob:  0.705028, 0.304688 (1.427 sec)
19.739... logprob:  0.715137, 0.305989 (1.476 sec)
19.740... logprob:  0.529194, 0.230469 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.389903, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.745869e-03 [1.875500e-07] 
Layer 'conv1' biases: 1.985415e-06 [1.890148e-10] 
Layer 'conv2' weights[0]: 3.738761e-03 [1.870864e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.545014e-09] 
Layer 'conv3' weights[0]: 3.737367e-03 [1.875868e-07] 
Layer 'conv3' biases: 3.279598e-05 [1.213605e-08] 
Layer 'conv4' weights[0]: 3.753049e-03 [1.888977e-07] 
Layer 'conv4' biases: 9.999626e-01 [2.242559e-07] 
Layer 'conv5' weights[0]: 3.870428e-03 [2.629458e-06] 
Layer 'conv5' biases: 9.991008e-01 [2.718231e-06] 
Layer 'fc6' weights[0]: 7.018159e-03 [6.138356e-08] 
Layer 'fc6' biases: 9.999926e-01 [5.594008e-08] 
Layer 'fc7' weights[0]: 7.368371e-03 [1.396512e-07] 
Layer 'fc7' biases: 9.997950e-01 [1.706767e-07] 
Layer 'fc8' weights[0]: 4.616692e-03 [1.356706e-05] 
Layer 'fc8' biases: 1.565392e-02 [2.058914e-05] 
Train error last 800 batches: 0.655546
-------------------------------------------------------
Not saving because 0.389903 > 0.299667 (9.300: -1.18%)
======================================================= (2.374 sec)
19.741... logprob:  0.624120, 0.291667 (1.437 sec)
19.742... logprob:  0.637125, 0.298177 (1.482 sec)
19.743... logprob:  0.652475, 0.282552 (1.425 sec)
19.744... logprob:  0.717906, 0.326823 (1.432 sec)
19.745... logprob:  0.738728, 0.309896 (1.434 sec)
19.746... logprob:  0.650446, 0.281250 (1.423 sec)
19.747... logprob:  0.614225, 0.260417 (1.427 sec)
19.748... logprob:  0.598515, 0.274740 (1.486 sec)
19.749... logprob:  0.692659, 0.290365 (1.426 sec)
19.750... logprob:  0.656330, 0.313802 (1.442 sec)
19.751... logprob:  0.523993, 0.260417 (1.481 sec)
19.752... logprob:  0.684591, 0.302083 (1.431 sec)
19.753... logprob:  0.596770, 0.274740 (1.434 sec)
19.754... logprob:  0.670851, 0.285156 (1.424 sec)
19.755... logprob:  0.665417, 0.279948 (1.422 sec)
19.756... logprob:  0.622934, 0.242187 (1.425 sec)
19.757... logprob:  0.772064, 0.320312 (1.465 sec)
19.758... logprob:  0.671955, 0.313802 (1.439 sec)
19.759... logprob:  0.666332, 0.294271 (1.447 sec)
19.760... logprob:  0.703247, 0.316406 (1.487 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.408488, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.742127e-03 [1.872225e-07] 
Layer 'conv1' biases: 1.986513e-06 [2.308814e-10] 
Layer 'conv2' weights[0]: 3.735006e-03 [1.869526e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.112578e-09] 
Layer 'conv3' weights[0]: 3.733629e-03 [1.875146e-07] 
Layer 'conv3' biases: 3.280490e-05 [1.319368e-08] 
Layer 'conv4' weights[0]: 3.749286e-03 [1.886598e-07] 
Layer 'conv4' biases: 9.999624e-01 [2.377037e-07] 
Layer 'conv5' weights[0]: 3.866867e-03 [2.886375e-06] 
Layer 'conv5' biases: 9.990915e-01 [3.157173e-06] 
Layer 'fc6' weights[0]: 7.017452e-03 [6.582875e-08] 
Layer 'fc6' biases: 9.999925e-01 [6.245721e-08] 
Layer 'fc7' weights[0]: 7.367640e-03 [1.536211e-07] 
Layer 'fc7' biases: 9.997952e-01 [2.216257e-07] 
Layer 'fc8' weights[0]: 4.633225e-03 [1.725983e-05] 
Layer 'fc8' biases: 1.585877e-02 [4.262586e-05] 
Train error last 800 batches: 0.655719
-------------------------------------------------------
Not saving because 0.408488 > 0.299667 (9.300: -1.18%)
======================================================= (2.341 sec)
19.761... logprob:  0.699276, 0.321614 (1.448 sec)
19.762... logprob:  0.772758, 0.335938 (1.441 sec)
19.763... logprob:  0.791915, 0.363281 (1.425 sec)
19.764... logprob:  0.683436, 0.299479 (1.422 sec)
19.765... logprob:  0.531483, 0.230469 (1.429 sec)
19.766... logprob:  0.658164, 0.276042 (1.452 sec)
19.767... logprob:  0.592042, 0.278646 (1.448 sec)
19.768... logprob:  0.720943, 0.333333 (1.456 sec)
19.769... logprob:  0.653356, 0.309896 (1.464 sec)
19.770... logprob:  0.652896, 0.303385 (1.474 sec)
19.771... logprob:  0.806227, 0.343750 (1.447 sec)
19.772... logprob:  0.609564, 0.286458 (1.442 sec)
19.773... logprob:  0.749300, 0.337240 (1.438 sec)
19.774... logprob:  0.585920, 0.255208 (1.454 sec)
19.775... logprob:  0.688738, 0.319010 (1.454 sec)
19.776... logprob:  0.732555, 0.292969 (1.475 sec)
19.777... logprob:  0.673491, 0.282552 (1.465 sec)
19.778... logprob:  0.615987, 0.282552 (1.459 sec)
19.779... logprob:  0.686379, 0.303385 (1.480 sec)
19.780... logprob:  0.681396, 0.321615 (1.448 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.451680, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.738382e-03 [1.873582e-07] 
Layer 'conv1' biases: 1.987390e-06 [1.722913e-10] 
Layer 'conv2' weights[0]: 3.731277e-03 [1.867891e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.902348e-09] 
Layer 'conv3' weights[0]: 3.729902e-03 [1.873741e-07] 
Layer 'conv3' biases: 3.284174e-05 [1.261408e-08] 
Layer 'conv4' weights[0]: 3.745560e-03 [1.885886e-07] 
Layer 'conv4' biases: 9.999627e-01 [2.333168e-07] 
Layer 'conv5' weights[0]: 3.863226e-03 [2.178758e-06] 
Layer 'conv5' biases: 9.991086e-01 [2.331844e-06] 
Layer 'fc6' weights[0]: 7.016705e-03 [6.054693e-08] 
Layer 'fc6' biases: 9.999924e-01 [5.473975e-08] 
Layer 'fc7' weights[0]: 7.366920e-03 [1.336542e-07] 
Layer 'fc7' biases: 9.997943e-01 [1.560138e-07] 
Layer 'fc8' weights[0]: 4.602639e-03 [1.241874e-05] 
Layer 'fc8' biases: 1.563340e-02 [7.328622e-06] 
Train error last 800 batches: 0.656004
-------------------------------------------------------
Not saving because 0.451680 > 0.299667 (9.300: -1.18%)
======================================================= (2.371 sec)
19.781... logprob:  0.668137, 0.282552 (1.447 sec)
19.782... logprob:  0.590061, 0.269531 (1.450 sec)
19.783... logprob:  0.741188, 0.321615 (1.457 sec)
19.784... logprob:  0.674778, 0.281250 (1.453 sec)
19.785... logprob:  0.591086, 0.259115 (1.481 sec)
19.786... logprob:  0.762215, 0.330729 (1.471 sec)
19.787... logprob:  0.787985, 0.317708 (1.460 sec)
19.788... logprob:  0.670052, 0.283854 (1.491 sec)
19.789... logprob:  0.524133, 0.238281 (1.452 sec)
19.790... logprob:  0.687374, 0.312500 (1.442 sec)
19.791... logprob:  0.641804, 0.268229 (1.440 sec)
19.792... logprob:  0.679201, 0.317708 (1.454 sec)
19.793... logprob:  0.611126, 0.270833 (1.447 sec)
19.794... logprob:  0.643562, 0.303385 (1.484 sec)
19.795... logprob:  0.659981, 0.268229 (1.467 sec)
19.796... logprob:  0.601989, 0.257812 (1.455 sec)
19.797... logprob:  0.630435, 0.276042 (1.493 sec)
19.798... logprob:  0.653713, 0.299479 (1.480 sec)
19.799... logprob:  0.669968, 0.274739 (1.443 sec)
19.800... logprob:  0.551964, 0.231771 (1.402 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.515841, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.734656e-03 [1.871914e-07] 
Layer 'conv1' biases: 1.987801e-06 [1.845510e-10] 
Layer 'conv2' weights[0]: 3.727544e-03 [1.866737e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.722076e-09] 
Layer 'conv3' weights[0]: 3.726163e-03 [1.870590e-07] 
Layer 'conv3' biases: 3.288572e-05 [1.083572e-08] 
Layer 'conv4' weights[0]: 3.741817e-03 [1.883045e-07] 
Layer 'conv4' biases: 9.999616e-01 [2.230233e-07] 
Layer 'conv5' weights[0]: 3.859139e-03 [2.643734e-06] 
Layer 'conv5' biases: 9.990977e-01 [2.796306e-06] 
Layer 'fc6' weights[0]: 7.015964e-03 [6.591897e-08] 
Layer 'fc6' biases: 9.999925e-01 [6.212066e-08] 
Layer 'fc7' weights[0]: 7.366162e-03 [1.539556e-07] 
Layer 'fc7' biases: 9.997951e-01 [2.255708e-07] 
Layer 'fc8' weights[0]: 4.641766e-03 [1.654875e-05] 
Layer 'fc8' biases: 1.594264e-02 [3.295063e-05] 
Train error last 800 batches: 0.656048
-------------------------------------------------------
Not saving because 0.515841 > 0.299667 (9.300: -1.18%)
======================================================= (2.390 sec)
20.1... logprob:  0.567982, 0.247396 (1.407 sec)
20.2... logprob:  0.681410, 0.274740 (1.447 sec)
20.3... logprob:  0.513997, 0.223958 (1.413 sec)
20.4... logprob:  0.667403, 0.291667 (1.402 sec)
20.5... logprob:  0.663056, 0.298177 (1.427 sec)
20.6... logprob:  0.742734, 0.321615 (1.389 sec)
20.7... logprob:  0.528941, 0.229167 (1.418 sec)
20.8... logprob:  0.617564, 0.257812 (1.390 sec)
20.9... logprob:  0.564609, 0.255208 (1.405 sec)
20.10... logprob:  0.564699, 0.231771 (1.410 sec)
20.11... logprob:  0.539485, 0.235677 (1.441 sec)
20.12... logprob:  0.680081, 0.294271 (1.397 sec)
20.13... logprob:  0.696531, 0.282552 (1.416 sec)
20.14... logprob:  0.635956, 0.272135 (1.396 sec)
20.15... logprob:  0.667348, 0.295573 (1.407 sec)
20.16... logprob:  0.657025, 0.276042 (1.398 sec)
20.17... logprob:  0.664827, 0.279948 (1.397 sec)
20.18... logprob:  0.459885, 0.208333 (1.396 sec)
20.19... logprob:  0.506469, 0.233073 (1.390 sec)
20.20... logprob:  0.711101, 0.307292 (1.400 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.397931, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.730906e-03 [1.867816e-07] 
Layer 'conv1' biases: 1.987857e-06 [1.563546e-10] 
Layer 'conv2' weights[0]: 3.723822e-03 [1.864639e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.791309e-09] 
Layer 'conv3' weights[0]: 3.722418e-03 [1.870286e-07] 
Layer 'conv3' biases: 3.290866e-05 [1.227007e-08] 
Layer 'conv4' weights[0]: 3.738085e-03 [1.885854e-07] 
Layer 'conv4' biases: 9.999606e-01 [2.764076e-07] 
Layer 'conv5' weights[0]: 3.855034e-03 [2.390594e-06] 
Layer 'conv5' biases: 9.990908e-01 [2.553519e-06] 
Layer 'fc6' weights[0]: 7.015218e-03 [6.083058e-08] 
Layer 'fc6' biases: 9.999925e-01 [5.550283e-08] 
Layer 'fc7' weights[0]: 7.365454e-03 [1.377027e-07] 
Layer 'fc7' biases: 9.997955e-01 [1.745307e-07] 
Layer 'fc8' weights[0]: 4.667669e-03 [1.519334e-05] 
Layer 'fc8' biases: 1.615047e-02 [3.256689e-05] 
Train error last 800 batches: 0.656025
-------------------------------------------------------
Not saving because 0.397931 > 0.299667 (9.300: -1.18%)
======================================================= (2.391 sec)
20.21... logprob:  0.734375, 0.324219 (1.407 sec)
20.22... logprob:  0.767242, 0.326823 (1.412 sec)
20.23... logprob:  0.726571, 0.290365 (1.414 sec)
20.24... logprob:  0.535992, 0.239583 (1.414 sec)
20.25... logprob:  0.622779, 0.286458 (1.398 sec)
20.26... logprob:  0.742277, 0.311198 (1.444 sec)
20.27... logprob:  0.642461, 0.285156 (1.390 sec)
20.28... logprob:  0.611151, 0.265625 (1.416 sec)
20.29... logprob:  0.664108, 0.321615 (1.420 sec)
20.30... logprob:  0.645896, 0.273437 (1.410 sec)
20.31... logprob:  0.664150, 0.282552 (1.395 sec)
20.32... logprob:  0.735128, 0.309896 (1.381 sec)
20.33... logprob:  0.691890, 0.299479 (1.441 sec)
20.34... logprob:  0.648518, 0.279948 (1.383 sec)
20.35... logprob:  0.586143, 0.270833 (1.395 sec)
20.36... logprob:  0.666355, 0.324219 (1.395 sec)
20.37... logprob:  0.631683, 0.235677 (1.431 sec)
20.38... logprob:  0.599129, 0.244792 (1.396 sec)
20.39... logprob:  0.895237, 0.352864 (1.428 sec)
20.40... logprob:  0.687593, 0.296875 (1.403 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.508415, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.727195e-03 [1.864223e-07] 
Layer 'conv1' biases: 1.989776e-06 [1.750298e-10] 
Layer 'conv2' weights[0]: 3.720087e-03 [1.861819e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.460841e-09] 
Layer 'conv3' weights[0]: 3.718708e-03 [1.864195e-07] 
Layer 'conv3' biases: 3.295957e-05 [9.841237e-09] 
Layer 'conv4' weights[0]: 3.734320e-03 [1.874092e-07] 
Layer 'conv4' biases: 9.999579e-01 [1.898467e-07] 
Layer 'conv5' weights[0]: 3.850048e-03 [2.306088e-06] 
Layer 'conv5' biases: 9.991071e-01 [2.509506e-06] 
Layer 'fc6' weights[0]: 7.014507e-03 [6.690790e-08] 
Layer 'fc6' biases: 9.999925e-01 [6.341945e-08] 
Layer 'fc7' weights[0]: 7.364719e-03 [1.576362e-07] 
Layer 'fc7' biases: 9.997938e-01 [2.196445e-07] 
Layer 'fc8' weights[0]: 4.621780e-03 [1.587334e-05] 
Layer 'fc8' biases: 1.585991e-02 [2.985355e-05] 
Train error last 800 batches: 0.656467
-------------------------------------------------------
Not saving because 0.508415 > 0.299667 (9.300: -1.18%)
======================================================= (2.388 sec)
20.41... logprob:  0.618959, 0.264323 (1.428 sec)
20.42... logprob:  0.691565, 0.300781 (1.415 sec)
20.43... logprob:  0.747267, 0.321615 (1.408 sec)
20.44... logprob:  0.641129, 0.283854 (1.436 sec)
20.45... logprob:  0.641496, 0.260417 (1.390 sec)
20.46... logprob:  0.771021, 0.309896 (1.394 sec)
20.47... logprob:  0.616421, 0.277344 (1.388 sec)
20.48... logprob:  0.657285, 0.274740 (1.423 sec)
20.49... logprob:  0.755743, 0.315104 (1.408 sec)
20.50... logprob:  0.545684, 0.226562 (1.416 sec)
20.51... logprob:  0.670036, 0.281250 (1.415 sec)
20.52... logprob:  0.799634, 0.332031 (1.407 sec)
20.53... logprob:  0.598338, 0.281250 (1.436 sec)
20.54... logprob:  0.648218, 0.276042 (1.381 sec)
20.55... logprob:  0.544091, 0.242188 (1.396 sec)
20.56... logprob:  0.717388, 0.286458 (1.403 sec)
20.57... logprob:  0.801403, 0.343750 (1.428 sec)
20.58... logprob:  0.592135, 0.261719 (1.396 sec)
20.59... logprob:  0.645252, 0.308594 (1.457 sec)
20.60... logprob:  0.739858, 0.337240 (1.422 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.571711, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.723465e-03 [1.865506e-07] 
Layer 'conv1' biases: 1.990137e-06 [1.888456e-10] 
Layer 'conv2' weights[0]: 3.716360e-03 [1.861250e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.324955e-09] 
Layer 'conv3' weights[0]: 3.714964e-03 [1.867756e-07] 
Layer 'conv3' biases: 3.295321e-05 [1.354754e-08] 
Layer 'conv4' weights[0]: 3.730614e-03 [1.882170e-07] 
Layer 'conv4' biases: 9.999583e-01 [2.712112e-07] 
Layer 'conv5' weights[0]: 3.847005e-03 [2.831933e-06] 
Layer 'conv5' biases: 9.990962e-01 [3.094952e-06] 
Layer 'fc6' weights[0]: 7.013770e-03 [6.698602e-08] 
Layer 'fc6' biases: 9.999925e-01 [6.372836e-08] 
Layer 'fc7' weights[0]: 7.364011e-03 [1.615107e-07] 
Layer 'fc7' biases: 9.997934e-01 [2.401075e-07] 
Layer 'fc8' weights[0]: 4.616199e-03 [2.069654e-05] 
Layer 'fc8' biases: 1.574923e-02 [5.620457e-05] 
Train error last 800 batches: 0.656942
-------------------------------------------------------
Not saving because 0.571711 > 0.299667 (9.300: -1.18%)
======================================================= (2.383 sec)
20.61... logprob:  0.567679, 0.273437 (1.432 sec)
20.62... logprob:  0.742093, 0.317708 (1.461 sec)
20.63... logprob:  0.632856, 0.292969 (1.443 sec)
20.64... logprob:  0.600231, 0.269531 (1.408 sec)
20.65... logprob:  0.546666, 0.239583 (1.395 sec)
20.66... logprob:  0.613283, 0.278646 (1.444 sec)
20.67... logprob:  0.566669, 0.242188 (1.382 sec)
20.68... logprob:  0.570732, 0.263021 (1.391 sec)
20.69... logprob:  0.735614, 0.332031 (1.421 sec)
20.70... logprob:  0.577046, 0.242187 (1.433 sec)
20.71... logprob:  0.581706, 0.268229 (1.454 sec)
20.72... logprob:  0.664335, 0.304687 (1.399 sec)
20.73... logprob:  0.629718, 0.255208 (1.421 sec)
20.74... logprob:  0.676027, 0.305990 (1.411 sec)
20.75... logprob:  0.634945, 0.281250 (1.409 sec)
20.76... logprob:  0.587279, 0.242187 (1.433 sec)
20.77... logprob:  0.594374, 0.272135 (1.425 sec)
20.78... logprob:  0.676063, 0.278646 (1.449 sec)
20.79... logprob:  0.608093, 0.264323 (1.396 sec)
20.80... logprob:  0.753884, 0.329427 (1.415 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.427031, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.719734e-03 [1.859935e-07] 
Layer 'conv1' biases: 1.990158e-06 [2.726707e-10] 
Layer 'conv2' weights[0]: 3.712667e-03 [1.857057e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.888853e-09] 
Layer 'conv3' weights[0]: 3.711285e-03 [1.864753e-07] 
Layer 'conv3' biases: 3.294906e-05 [1.322708e-08] 
Layer 'conv4' weights[0]: 3.726848e-03 [1.877166e-07] 
Layer 'conv4' biases: 9.999585e-01 [2.474189e-07] 
Layer 'conv5' weights[0]: 3.843683e-03 [2.364849e-06] 
Layer 'conv5' biases: 9.990666e-01 [2.604116e-06] 
Layer 'fc6' weights[0]: 7.013030e-03 [6.087277e-08] 
Layer 'fc6' biases: 9.999925e-01 [5.610191e-08] 
Layer 'fc7' weights[0]: 7.363230e-03 [1.408984e-07] 
Layer 'fc7' biases: 9.997950e-01 [1.742542e-07] 
Layer 'fc8' weights[0]: 4.679179e-03 [1.379065e-05] 
Layer 'fc8' biases: 1.624880e-02 [1.612910e-05] 
Train error last 800 batches: 0.656142
-------------------------------------------------------
Not saving because 0.427031 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
20.81... logprob:  0.644154, 0.296875 (1.422 sec)
20.82... logprob:  0.521215, 0.263021 (1.421 sec)
20.83... logprob:  0.550702, 0.261719 (1.402 sec)
20.84... logprob:  0.726197, 0.294271 (1.460 sec)
20.85... logprob:  0.655042, 0.277344 (1.416 sec)
20.86... logprob:  0.587873, 0.286458 (1.415 sec)
20.87... logprob:  0.681221, 0.305990 (1.416 sec)
20.88... logprob:  0.738047, 0.305990 (1.406 sec)
20.89... logprob:  0.697546, 0.300781 (1.431 sec)
20.90... logprob:  0.704357, 0.330729 (1.391 sec)
20.91... logprob:  0.582488, 0.257812 (1.387 sec)
20.92... logprob:  0.701929, 0.285156 (1.396 sec)
20.93... logprob:  0.692624, 0.311198 (1.393 sec)
20.94... logprob:  0.682702, 0.274740 (1.391 sec)
20.95... logprob:  0.637792, 0.303385 (1.404 sec)
20.96... logprob:  0.717469, 0.320312 (1.399 sec)
20.97... logprob:  0.654689, 0.302083 (1.386 sec)
20.98... logprob:  0.649827, 0.289063 (1.431 sec)
20.99... logprob:  0.718255, 0.317708 (1.409 sec)
20.100... logprob:  0.497161, 0.235677 (1.394 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.320886, 0.039062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.716024e-03 [1.859115e-07] 
Layer 'conv1' biases: 1.991390e-06 [1.783616e-10] 
Layer 'conv2' weights[0]: 3.708965e-03 [1.855239e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.631105e-09] 
Layer 'conv3' weights[0]: 3.707589e-03 [1.861085e-07] 
Layer 'conv3' biases: 3.297079e-05 [1.141566e-08] 
Layer 'conv4' weights[0]: 3.723122e-03 [1.873464e-07] 
Layer 'conv4' biases: 9.999571e-01 [2.331284e-07] 
Layer 'conv5' weights[0]: 3.839231e-03 [2.274389e-06] 
Layer 'conv5' biases: 9.990885e-01 [2.523627e-06] 
Layer 'fc6' weights[0]: 7.012305e-03 [5.936099e-08] 
Layer 'fc6' biases: 9.999925e-01 [5.376188e-08] 
Layer 'fc7' weights[0]: 7.362473e-03 [1.343006e-07] 
Layer 'fc7' biases: 9.997933e-01 [1.681927e-07] 
Layer 'fc8' weights[0]: 4.623451e-03 [1.339420e-05] 
Layer 'fc8' biases: 1.583180e-02 [2.420755e-05] 
Train error last 800 batches: 0.656058
-------------------------------------------------------
Not saving because 0.320886 > 0.299667 (9.300: -1.18%)
======================================================= (2.379 sec)
20.101... logprob:  0.590221, 0.286458 (1.449 sec)
20.102... logprob:  0.733732, 0.329427 (1.385 sec)
20.103... logprob:  0.715752, 0.321614 (1.400 sec)
20.104... logprob:  0.666827, 0.282552 (1.391 sec)
20.105... logprob:  0.752490, 0.313802 (1.390 sec)
20.106... logprob:  0.561564, 0.255208 (1.384 sec)
20.107... logprob:  0.659738, 0.278646 (1.436 sec)
20.108... logprob:  0.769368, 0.305990 (1.396 sec)
20.109... logprob:  0.591222, 0.233073 (1.397 sec)
20.110... logprob:  0.889721, 0.382813 (1.397 sec)
20.111... logprob:  0.703843, 0.302083 (1.390 sec)
20.112... logprob:  0.640978, 0.282552 (1.399 sec)
20.113... logprob:  0.665089, 0.311198 (1.396 sec)
20.114... logprob:  0.714647, 0.316406 (1.425 sec)
20.115... logprob:  0.697948, 0.302083 (1.405 sec)
20.116... logprob:  0.608659, 0.278646 (1.391 sec)
20.117... logprob:  0.675457, 0.308594 (1.436 sec)
20.118... logprob:  0.716742, 0.342448 (1.382 sec)
20.119... logprob:  0.579409, 0.251302 (1.393 sec)
20.120... logprob:  0.689845, 0.305989 (1.393 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.473479, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.712321e-03 [1.862197e-07] 
Layer 'conv1' biases: 1.992339e-06 [2.236912e-10] 
Layer 'conv2' weights[0]: 3.705215e-03 [1.856238e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.029432e-09] 
Layer 'conv3' weights[0]: 3.703861e-03 [1.864156e-07] 
Layer 'conv3' biases: 3.298657e-05 [1.380915e-08] 
Layer 'conv4' weights[0]: 3.719413e-03 [1.877960e-07] 
Layer 'conv4' biases: 9.999534e-01 [2.575554e-07] 
Layer 'conv5' weights[0]: 3.833819e-03 [2.417676e-06] 
Layer 'conv5' biases: 9.990997e-01 [2.581550e-06] 
Layer 'fc6' weights[0]: 7.011527e-03 [6.153926e-08] 
Layer 'fc6' biases: 9.999925e-01 [5.644123e-08] 
Layer 'fc7' weights[0]: 7.361735e-03 [1.419854e-07] 
Layer 'fc7' biases: 9.997923e-01 [1.805538e-07] 
Layer 'fc8' weights[0]: 4.599030e-03 [1.425529e-05] 
Layer 'fc8' biases: 1.568610e-02 [2.838691e-05] 
Train error last 800 batches: 0.657009
-------------------------------------------------------
Not saving because 0.473479 > 0.299667 (9.300: -1.18%)
======================================================= (2.349 sec)
20.121... logprob:  0.644360, 0.263021 (1.404 sec)
20.122... logprob:  0.758848, 0.300781 (1.445 sec)
20.123... logprob:  0.731685, 0.321615 (1.390 sec)
20.124... logprob:  0.590773, 0.250000 (1.396 sec)
20.125... logprob:  0.776153, 0.339844 (1.392 sec)
20.126... logprob:  0.765846, 0.313802 (1.387 sec)
20.127... logprob:  0.744638, 0.329427 (1.393 sec)
20.128... logprob:  0.632974, 0.308594 (1.416 sec)
20.129... logprob:  0.769761, 0.322917 (1.414 sec)
20.130... logprob:  0.579909, 0.225260 (1.407 sec)
20.131... logprob:  0.737638, 0.304687 (1.405 sec)
20.132... logprob:  0.731093, 0.321615 (1.427 sec)
20.133... logprob:  0.632497, 0.277344 (1.385 sec)
20.134... logprob:  0.629807, 0.296875 (1.393 sec)
20.135... logprob:  0.648299, 0.290365 (1.400 sec)
20.136... logprob:  0.846286, 0.351562 (1.398 sec)
20.137... logprob:  0.662417, 0.291667 (1.391 sec)
20.138... logprob:  0.625289, 0.281250 (1.447 sec)
20.139... logprob:  0.598645, 0.231771 (1.398 sec)
20.140... logprob:  0.676684, 0.313802 (1.403 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.519792, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.708606e-03 [1.857337e-07] 
Layer 'conv1' biases: 1.992729e-06 [1.308208e-10] 
Layer 'conv2' weights[0]: 3.701540e-03 [1.853213e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.667686e-09] 
Layer 'conv3' weights[0]: 3.700159e-03 [1.859916e-07] 
Layer 'conv3' biases: 3.300664e-05 [1.271515e-08] 
Layer 'conv4' weights[0]: 3.715701e-03 [1.872871e-07] 
Layer 'conv4' biases: 9.999540e-01 [2.474740e-07] 
Layer 'conv5' weights[0]: 3.830147e-03 [2.286618e-06] 
Layer 'conv5' biases: 9.991215e-01 [2.399648e-06] 
Layer 'fc6' weights[0]: 7.010853e-03 [6.137162e-08] 
Layer 'fc6' biases: 9.999926e-01 [5.557137e-08] 
Layer 'fc7' weights[0]: 7.361036e-03 [1.374530e-07] 
Layer 'fc7' biases: 9.997903e-01 [1.613655e-07] 
Layer 'fc8' weights[0]: 4.548591e-03 [1.292977e-05] 
Layer 'fc8' biases: 1.541700e-02 [1.433685e-05] 
Train error last 800 batches: 0.657185
-------------------------------------------------------
Not saving because 0.519792 > 0.299667 (9.300: -1.18%)
======================================================= (2.371 sec)
20.141... logprob:  0.666762, 0.312500 (1.444 sec)
20.142... logprob:  0.659362, 0.289062 (1.396 sec)
20.143... logprob:  0.609500, 0.286458 (1.513 sec)
20.144... logprob:  0.666453, 0.278646 (1.414 sec)
20.145... logprob:  0.568927, 0.242187 (1.408 sec)
20.146... logprob:  0.706595, 0.317708 (1.404 sec)
20.147... logprob:  0.545153, 0.243490 (1.426 sec)
20.148... logprob:  0.700949, 0.322917 (1.393 sec)
20.149... logprob:  0.633020, 0.265625 (1.389 sec)
20.150... logprob:  0.622640, 0.285156 (1.394 sec)
20.151... logprob:  0.552667, 0.236979 (1.393 sec)
20.152... logprob:  0.915900, 0.375000 (1.384 sec)
20.153... logprob:  0.617769, 0.281250 (1.442 sec)
20.154... logprob:  0.624525, 0.260417 (1.395 sec)
20.155... logprob:  0.622902, 0.276042 (1.403 sec)
20.156... logprob:  0.559350, 0.248698 (1.437 sec)
20.157... logprob:  0.610600, 0.279948 (1.395 sec)
20.158... logprob:  0.636850, 0.266927 (1.405 sec)
20.159... logprob:  0.740269, 0.319010 (1.397 sec)
20.160... logprob:  0.653195, 0.272135 (1.382 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.435709, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.704904e-03 [1.858636e-07] 
Layer 'conv1' biases: 1.993029e-06 [2.163540e-10] 
Layer 'conv2' weights[0]: 3.697836e-03 [1.852833e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.175443e-09] 
Layer 'conv3' weights[0]: 3.696461e-03 [1.859911e-07] 
Layer 'conv3' biases: 3.301741e-05 [1.387579e-08] 
Layer 'conv4' weights[0]: 3.711985e-03 [1.873571e-07] 
Layer 'conv4' biases: 9.999545e-01 [2.631036e-07] 
Layer 'conv5' weights[0]: 3.827267e-03 [2.793631e-06] 
Layer 'conv5' biases: 9.990868e-01 [2.983615e-06] 
Layer 'fc6' weights[0]: 7.010114e-03 [6.349566e-08] 
Layer 'fc6' biases: 9.999925e-01 [5.898608e-08] 
Layer 'fc7' weights[0]: 7.360283e-03 [1.462430e-07] 
Layer 'fc7' biases: 9.997928e-01 [1.912840e-07] 
Layer 'fc8' weights[0]: 4.641347e-03 [1.610415e-05] 
Layer 'fc8' biases: 1.612100e-02 [3.036865e-05] 
Train error last 800 batches: 0.657159
-------------------------------------------------------
Not saving because 0.435709 > 0.299667 (9.300: -1.18%)
======================================================= (2.370 sec)
20.161... logprob:  0.535494, 0.270833 (1.406 sec)
20.162... logprob:  0.814424, 0.329427 (1.404 sec)
20.163... logprob:  0.633082, 0.281250 (1.419 sec)
20.164... logprob:  0.635839, 0.277344 (1.419 sec)
20.165... logprob:  0.739196, 0.283854 (1.412 sec)
20.166... logprob:  0.716061, 0.330729 (1.446 sec)
20.167... logprob:  0.587339, 0.259114 (1.429 sec)
20.168... logprob:  0.598707, 0.246094 (1.419 sec)
20.169... logprob:  0.640964, 0.304687 (1.452 sec)
20.170... logprob:  0.698156, 0.317708 (1.396 sec)
20.171... logprob:  0.711999, 0.305990 (1.421 sec)
20.172... logprob:  0.618572, 0.252604 (1.412 sec)
20.173... logprob:  0.660102, 0.281250 (1.420 sec)
20.174... logprob:  0.815587, 0.326823 (1.394 sec)
20.175... logprob:  0.733988, 0.313802 (1.463 sec)
20.176... logprob:  0.689949, 0.303385 (1.409 sec)
20.177... logprob:  0.569723, 0.253906 (1.420 sec)
20.178... logprob:  0.578803, 0.253906 (1.454 sec)
20.179... logprob:  0.526101, 0.246094 (1.403 sec)
20.180... logprob:  0.720090, 0.281250 (1.419 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.456988, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.701197e-03 [1.854655e-07] 
Layer 'conv1' biases: 1.993762e-06 [1.939408e-10] 
Layer 'conv2' weights[0]: 3.694131e-03 [1.849315e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.743426e-09] 
Layer 'conv3' weights[0]: 3.692752e-03 [1.853839e-07] 
Layer 'conv3' biases: 3.305661e-05 [1.130857e-08] 
Layer 'conv4' weights[0]: 3.708272e-03 [1.866926e-07] 
Layer 'conv4' biases: 9.999539e-01 [2.180660e-07] 
Layer 'conv5' weights[0]: 3.823416e-03 [2.332299e-06] 
Layer 'conv5' biases: 9.991085e-01 [2.556604e-06] 
Layer 'fc6' weights[0]: 7.009372e-03 [6.394451e-08] 
Layer 'fc6' biases: 9.999927e-01 [5.955889e-08] 
Layer 'fc7' weights[0]: 7.359548e-03 [1.495042e-07] 
Layer 'fc7' biases: 9.997911e-01 [2.019820e-07] 
Layer 'fc8' weights[0]: 4.586970e-03 [1.578904e-05] 
Layer 'fc8' biases: 1.572781e-02 [2.923133e-05] 
Train error last 800 batches: 0.657266
-------------------------------------------------------
Not saving because 0.456988 > 0.299667 (9.300: -1.18%)
======================================================= (2.377 sec)
20.181... logprob:  0.753091, 0.352865 (1.420 sec)
20.182... logprob:  0.602314, 0.283854 (1.419 sec)
20.183... logprob:  0.646773, 0.279948 (1.417 sec)
20.184... logprob:  0.663448, 0.253906 (1.417 sec)
20.185... logprob:  0.580575, 0.255208 (1.394 sec)
20.186... logprob:  0.645663, 0.290365 (1.390 sec)
20.187... logprob:  0.677892, 0.294271 (1.395 sec)
20.188... logprob:  0.598197, 0.259115 (1.397 sec)
20.189... logprob:  0.741499, 0.300781 (1.382 sec)
20.190... logprob:  0.619660, 0.291667 (1.429 sec)
20.191... logprob:  0.780945, 0.335938 (1.402 sec)
20.192... logprob:  0.789139, 0.352865 (1.411 sec)
20.193... logprob:  0.600258, 0.272135 (1.410 sec)
20.194... logprob:  0.632132, 0.269531 (1.407 sec)
20.195... logprob:  0.567751, 0.264323 (1.395 sec)
20.196... logprob:  0.680601, 0.289062 (1.387 sec)
20.197... logprob:  0.761836, 0.335938 (1.400 sec)
20.198... logprob:  0.599258, 0.229167 (1.403 sec)
20.199... logprob:  0.599341, 0.256510 (1.384 sec)
20.200... logprob:  0.652000, 0.292969 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.511075, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.697502e-03 [1.853966e-07] 
Layer 'conv1' biases: 1.994814e-06 [1.748019e-10] 
Layer 'conv2' weights[0]: 3.690449e-03 [1.847871e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.661376e-09] 
Layer 'conv3' weights[0]: 3.689049e-03 [1.852154e-07] 
Layer 'conv3' biases: 3.304980e-05 [1.174472e-08] 
Layer 'conv4' weights[0]: 3.704559e-03 [1.865821e-07] 
Layer 'conv4' biases: 9.999544e-01 [2.344617e-07] 
Layer 'conv5' weights[0]: 3.820132e-03 [2.232313e-06] 
Layer 'conv5' biases: 9.991040e-01 [2.374742e-06] 
Layer 'fc6' weights[0]: 7.008601e-03 [6.506043e-08] 
Layer 'fc6' biases: 9.999925e-01 [6.097361e-08] 
Layer 'fc7' weights[0]: 7.358808e-03 [1.530029e-07] 
Layer 'fc7' biases: 9.997913e-01 [2.119422e-07] 
Layer 'fc8' weights[0]: 4.604741e-03 [1.696467e-05] 
Layer 'fc8' biases: 1.582019e-02 [4.188243e-05] 
Train error last 800 batches: 0.657905
-------------------------------------------------------
Not saving because 0.511075 > 0.299667 (9.300: -1.18%)
======================================================= (2.381 sec)
20.201... logprob:  0.680568, 0.294271 (1.410 sec)
20.202... logprob:  0.717513, 0.305990 (1.406 sec)
20.203... logprob:  0.614566, 0.270833 (1.438 sec)
20.204... logprob:  0.747705, 0.360677 (1.393 sec)
20.205... logprob:  0.624459, 0.270833 (1.402 sec)
20.206... logprob:  0.636065, 0.277344 (1.393 sec)
20.207... logprob:  0.585647, 0.281250 (1.389 sec)
20.208... logprob:  0.711533, 0.316406 (1.396 sec)
20.209... logprob:  0.579825, 0.266927 (1.419 sec)
20.210... logprob:  0.833150, 0.355469 (1.412 sec)
20.211... logprob:  0.612561, 0.252604 (1.406 sec)
20.212... logprob:  0.681701, 0.305990 (1.407 sec)
20.213... logprob:  0.716633, 0.307292 (1.461 sec)
20.214... logprob:  0.660300, 0.295573 (1.424 sec)
20.215... logprob:  0.618600, 0.263021 (1.412 sec)
20.216... logprob:  0.696616, 0.296875 (1.464 sec)
20.217... logprob:  0.598063, 0.239583 (1.396 sec)
20.218... logprob:  0.598460, 0.265625 (1.418 sec)
20.219... logprob:  0.684806, 0.273437 (1.407 sec)
20.220... logprob:  0.627813, 0.278646 (1.416 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.480311, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.693787e-03 [1.849390e-07] 
Layer 'conv1' biases: 1.994899e-06 [1.654270e-10] 
Layer 'conv2' weights[0]: 3.686768e-03 [1.844911e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.505439e-09] 
Layer 'conv3' weights[0]: 3.685366e-03 [1.846660e-07] 
Layer 'conv3' biases: 3.304241e-05 [9.440091e-09] 
Layer 'conv4' weights[0]: 3.700872e-03 [1.857164e-07] 
Layer 'conv4' biases: 9.999564e-01 [1.738307e-07] 
Layer 'conv5' weights[0]: 3.817927e-03 [2.205504e-06] 
Layer 'conv5' biases: 9.990976e-01 [2.361724e-06] 
Layer 'fc6' weights[0]: 7.007888e-03 [6.050188e-08] 
Layer 'fc6' biases: 9.999925e-01 [5.474380e-08] 
Layer 'fc7' weights[0]: 7.358071e-03 [1.357079e-07] 
Layer 'fc7' biases: 9.997916e-01 [1.561262e-07] 
Layer 'fc8' weights[0]: 4.614026e-03 [1.258572e-05] 
Layer 'fc8' biases: 1.585811e-02 [1.186009e-05] 
Train error last 800 batches: 0.657297
-------------------------------------------------------
Not saving because 0.480311 > 0.299667 (9.300: -1.18%)
======================================================= (2.378 sec)
20.221... logprob:  0.643851, 0.299479 (1.409 sec)
20.222... logprob:  0.764813, 0.342448 (1.453 sec)
20.223... logprob:  0.795483, 0.333333 (1.432 sec)
20.224... logprob:  0.771773, 0.313802 (1.425 sec)
20.225... logprob:  0.610503, 0.261719 (1.439 sec)
20.226... logprob:  0.682256, 0.308594 (1.422 sec)
20.227... logprob:  0.727847, 0.285156 (1.411 sec)
20.228... logprob:  0.604257, 0.261719 (1.412 sec)
20.229... logprob:  0.655529, 0.292969 (1.415 sec)
20.230... logprob:  0.707439, 0.330729 (1.427 sec)
20.231... logprob:  0.628822, 0.283854 (1.422 sec)
20.232... logprob:  0.642207, 0.282552 (1.455 sec)
20.233... logprob:  0.658407, 0.289062 (1.416 sec)
20.234... logprob:  0.731453, 0.335938 (1.411 sec)
20.235... logprob:  0.674969, 0.304688 (1.462 sec)
20.236... logprob:  0.671161, 0.292969 (1.397 sec)
20.237... logprob:  0.584106, 0.259115 (1.421 sec)
20.238... logprob:  0.601097, 0.274740 (1.410 sec)
20.239... logprob:  0.650039, 0.286458 (1.413 sec)
20.240... logprob:  0.740155, 0.335937 (1.394 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.467952, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.690112e-03 [1.846568e-07] 
Layer 'conv1' biases: 1.995661e-06 [1.609706e-10] 
Layer 'conv2' weights[0]: 3.683089e-03 [1.843740e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.770414e-09] 
Layer 'conv3' weights[0]: 3.681681e-03 [1.848615e-07] 
Layer 'conv3' biases: 3.302478e-05 [1.254059e-08] 
Layer 'conv4' weights[0]: 3.697152e-03 [1.860093e-07] 
Layer 'conv4' biases: 9.999590e-01 [2.245778e-07] 
Layer 'conv5' weights[0]: 3.815828e-03 [2.478012e-06] 
Layer 'conv5' biases: 9.991031e-01 [2.551307e-06] 
Layer 'fc6' weights[0]: 7.007157e-03 [6.218313e-08] 
Layer 'fc6' biases: 9.999925e-01 [5.676431e-08] 
Layer 'fc7' weights[0]: 7.357311e-03 [1.458917e-07] 
Layer 'fc7' biases: 9.997907e-01 [1.983087e-07] 
Layer 'fc8' weights[0]: 4.592488e-03 [1.479025e-05] 
Layer 'fc8' biases: 1.576632e-02 [2.734327e-05] 
Train error last 800 batches: 0.657439
-------------------------------------------------------
Not saving because 0.467952 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
20.241... logprob:  0.709480, 0.300781 (1.468 sec)
20.242... logprob:  0.692531, 0.292969 (1.424 sec)
20.243... logprob:  0.589377, 0.256510 (1.433 sec)
20.244... logprob:  0.603166, 0.260417 (1.449 sec)
20.245... logprob:  0.691960, 0.300781 (1.424 sec)
20.246... logprob:  0.592713, 0.265625 (1.414 sec)
20.247... logprob:  0.561934, 0.260417 (1.413 sec)
20.248... logprob:  0.523617, 0.240885 (1.417 sec)
20.249... logprob:  0.890315, 0.376302 (1.428 sec)
20.250... logprob:  0.736302, 0.315104 (1.404 sec)
20.251... logprob:  0.565453, 0.260417 (1.461 sec)
20.252... logprob:  0.593808, 0.265625 (1.426 sec)
20.253... logprob:  0.548712, 0.230469 (1.410 sec)
20.254... logprob:  0.655423, 0.299479 (1.459 sec)
20.255... logprob:  0.600365, 0.268229 (1.397 sec)
20.256... logprob:  0.544788, 0.222656 (1.416 sec)
20.257... logprob:  0.616239, 0.269531 (1.413 sec)
20.258... logprob:  0.635478, 0.278646 (1.416 sec)
20.259... logprob:  0.653892, 0.287760 (1.395 sec)
20.260... logprob:  0.467488, 0.212240 (1.449 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.492915, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.686407e-03 [1.847945e-07] 
Layer 'conv1' biases: 1.996480e-06 [2.190045e-10] 
Layer 'conv2' weights[0]: 3.679407e-03 [1.843607e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.011588e-09] 
Layer 'conv3' weights[0]: 3.678014e-03 [1.850337e-07] 
Layer 'conv3' biases: 3.302309e-05 [1.270293e-08] 
Layer 'conv4' weights[0]: 3.693478e-03 [1.866340e-07] 
Layer 'conv4' biases: 9.999591e-01 [2.617301e-07] 
Layer 'conv5' weights[0]: 3.812776e-03 [3.336905e-06] 
Layer 'conv5' biases: 9.990699e-01 [3.670626e-06] 
Layer 'fc6' weights[0]: 7.006433e-03 [6.965070e-08] 
Layer 'fc6' biases: 9.999924e-01 [6.726645e-08] 
Layer 'fc7' weights[0]: 7.356560e-03 [1.693334e-07] 
Layer 'fc7' biases: 9.997930e-01 [2.838626e-07] 
Layer 'fc8' weights[0]: 4.682782e-03 [1.829628e-05] 
Layer 'fc8' biases: 1.654387e-02 [4.874880e-05] 
Train error last 800 batches: 0.657327
-------------------------------------------------------
Not saving because 0.492915 > 0.299667 (9.300: -1.18%)
======================================================= (2.354 sec)
20.261... logprob:  0.647214, 0.256510 (1.427 sec)
20.262... logprob:  0.684109, 0.311198 (1.432 sec)
20.263... logprob:  0.663171, 0.283854 (1.446 sec)
20.264... logprob:  0.600973, 0.274740 (1.417 sec)
20.265... logprob:  0.587544, 0.252604 (1.419 sec)
20.266... logprob:  0.601100, 0.266927 (1.416 sec)
20.267... logprob:  0.621616, 0.285156 (1.409 sec)
20.268... logprob:  0.676231, 0.278646 (1.415 sec)
20.269... logprob:  0.722008, 0.328125 (1.398 sec)
20.270... logprob:  0.799315, 0.304688 (1.465 sec)
20.271... logprob:  0.696661, 0.260417 (1.427 sec)
20.272... logprob:  0.576027, 0.251302 (1.418 sec)
20.273... logprob:  0.655290, 0.298177 (1.458 sec)
20.274... logprob:  0.668000, 0.295573 (1.395 sec)
20.275... logprob:  0.632680, 0.282552 (1.416 sec)
20.276... logprob:  0.621164, 0.269531 (1.408 sec)
20.277... logprob:  0.666729, 0.303385 (1.425 sec)
20.278... logprob:  0.538778, 0.236979 (1.414 sec)
20.279... logprob:  0.512282, 0.244792 (1.457 sec)
20.280... logprob:  0.525035, 0.257812 (1.405 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.407209, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.682736e-03 [1.845853e-07] 
Layer 'conv1' biases: 1.997596e-06 [1.469560e-10] 
Layer 'conv2' weights[0]: 3.675710e-03 [1.840575e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.210257e-09] 
Layer 'conv3' weights[0]: 3.674316e-03 [1.842916e-07] 
Layer 'conv3' biases: 3.307812e-05 [8.049215e-09] 
Layer 'conv4' weights[0]: 3.689784e-03 [1.854853e-07] 
Layer 'conv4' biases: 9.999578e-01 [1.721683e-07] 
Layer 'conv5' weights[0]: 3.808354e-03 [2.312043e-06] 
Layer 'conv5' biases: 9.990914e-01 [2.464205e-06] 
Layer 'fc6' weights[0]: 7.005718e-03 [5.811675e-08] 
Layer 'fc6' biases: 9.999924e-01 [5.143074e-08] 
Layer 'fc7' weights[0]: 7.355831e-03 [1.331083e-07] 
Layer 'fc7' biases: 9.997910e-01 [1.757757e-07] 
Layer 'fc8' weights[0]: 4.630702e-03 [1.338902e-05] 
Layer 'fc8' biases: 1.612458e-02 [2.245339e-05] 
Train error last 800 batches: 0.657099
-------------------------------------------------------
Not saving because 0.407209 > 0.299667 (9.300: -1.18%)
======================================================= (2.406 sec)
20.281... logprob:  0.575635, 0.250000 (1.428 sec)
20.282... logprob:  0.617107, 0.287760 (1.412 sec)
20.283... logprob:  0.654073, 0.300781 (1.419 sec)
20.284... logprob:  0.587533, 0.290365 (1.405 sec)
20.285... logprob:  0.577373, 0.240885 (1.442 sec)
20.286... logprob:  0.799904, 0.317708 (1.439 sec)
20.287... logprob:  0.634440, 0.283854 (1.428 sec)
20.288... logprob:  0.547894, 0.236979 (1.433 sec)
20.289... logprob:  0.682032, 0.319010 (1.434 sec)
20.290... logprob:  0.657292, 0.282552 (1.403 sec)
20.291... logprob:  0.675400, 0.274740 (1.419 sec)
20.292... logprob:  0.695810, 0.299479 (1.416 sec)
20.293... logprob:  0.572841, 0.274740 (1.418 sec)
20.294... logprob:  0.588093, 0.235677 (1.394 sec)
20.295... logprob:  0.653220, 0.285156 (1.460 sec)
20.296... logprob:  0.622983, 0.302083 (1.412 sec)
20.297... logprob:  0.644340, 0.308594 (1.412 sec)
20.298... logprob:  0.676775, 0.289062 (1.460 sec)
20.299... logprob:  0.547794, 0.247396 (1.391 sec)
20.300... logprob:  0.629558, 0.286458 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.469227, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.679036e-03 [1.841726e-07] 
Layer 'conv1' biases: 1.998261e-06 [1.374452e-10] 
Layer 'conv2' weights[0]: 3.672044e-03 [1.837816e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.448175e-09] 
Layer 'conv3' weights[0]: 3.670657e-03 [1.840362e-07] 
Layer 'conv3' biases: 3.310577e-05 [9.631370e-09] 
Layer 'conv4' weights[0]: 3.686082e-03 [1.850167e-07] 
Layer 'conv4' biases: 9.999574e-01 [1.806320e-07] 
Layer 'conv5' weights[0]: 3.804617e-03 [2.267172e-06] 
Layer 'conv5' biases: 9.990829e-01 [2.420267e-06] 
Layer 'fc6' weights[0]: 7.004987e-03 [5.851637e-08] 
Layer 'fc6' biases: 9.999925e-01 [5.216662e-08] 
Layer 'fc7' weights[0]: 7.355137e-03 [1.328197e-07] 
Layer 'fc7' biases: 9.997915e-01 [1.677177e-07] 
Layer 'fc8' weights[0]: 4.662854e-03 [1.307386e-05] 
Layer 'fc8' biases: 1.629222e-02 [1.852535e-05] 
Train error last 800 batches: 0.656946
-------------------------------------------------------
Not saving because 0.469227 > 0.299667 (9.300: -1.18%)
======================================================= (2.394 sec)
20.301... logprob:  0.606603, 0.265625 (1.413 sec)
20.302... logprob:  0.816550, 0.333333 (1.420 sec)
20.303... logprob:  0.719844, 0.307292 (1.405 sec)
20.304... logprob:  0.644226, 0.285156 (1.430 sec)
20.305... logprob:  0.590094, 0.242188 (1.433 sec)
20.306... logprob:  0.591773, 0.247396 (1.426 sec)
20.307... logprob:  0.641662, 0.281250 (1.441 sec)
20.308... logprob:  0.582140, 0.239583 (1.476 sec)
20.309... logprob:  0.761263, 0.311198 (1.412 sec)
20.310... logprob:  0.664318, 0.283854 (1.419 sec)
20.311... logprob:  0.705198, 0.282552 (1.420 sec)
20.312... logprob:  0.717202, 0.332031 (1.419 sec)
20.313... logprob:  0.671294, 0.305990 (1.414 sec)
20.314... logprob:  0.654333, 0.282552 (1.458 sec)
20.315... logprob:  0.627436, 0.272135 (1.427 sec)
20.316... logprob:  0.720777, 0.333333 (1.418 sec)
20.317... logprob:  0.553559, 0.265625 (1.479 sec)
20.318... logprob:  0.658767, 0.282552 (1.412 sec)
20.319... logprob:  0.630354, 0.291667 (1.425 sec)
20.320... logprob:  0.700290, 0.305990 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.465088, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.675374e-03 [1.841407e-07] 
Layer 'conv1' biases: 1.999105e-06 [1.601659e-10] 
Layer 'conv2' weights[0]: 3.668396e-03 [1.837408e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.546101e-09] 
Layer 'conv3' weights[0]: 3.666992e-03 [1.840753e-07] 
Layer 'conv3' biases: 3.312041e-05 [1.116915e-08] 
Layer 'conv4' weights[0]: 3.682396e-03 [1.851824e-07] 
Layer 'conv4' biases: 9.999560e-01 [2.335120e-07] 
Layer 'conv5' weights[0]: 3.799906e-03 [2.504991e-06] 
Layer 'conv5' biases: 9.991023e-01 [2.717355e-06] 
Layer 'fc6' weights[0]: 7.004235e-03 [6.044108e-08] 
Layer 'fc6' biases: 9.999926e-01 [5.470351e-08] 
Layer 'fc7' weights[0]: 7.354415e-03 [1.364674e-07] 
Layer 'fc7' biases: 9.997900e-01 [1.628344e-07] 
Layer 'fc8' weights[0]: 4.612036e-03 [1.354380e-05] 
Layer 'fc8' biases: 1.590898e-02 [2.382564e-05] 
Train error last 800 batches: 0.656785
-------------------------------------------------------
Not saving because 0.465088 > 0.299667 (9.300: -1.18%)
======================================================= (2.362 sec)
20.321... logprob:  0.635182, 0.287760 (1.423 sec)
20.322... logprob:  0.547834, 0.266927 (1.409 sec)
20.323... logprob:  0.601477, 0.272135 (1.469 sec)
20.324... logprob:  0.770482, 0.320312 (1.422 sec)
20.325... logprob:  0.584525, 0.255208 (1.428 sec)
20.326... logprob:  0.740507, 0.326823 (1.458 sec)
20.327... logprob:  0.695209, 0.311198 (1.422 sec)
20.328... logprob:  0.781006, 0.333333 (1.424 sec)
20.329... logprob:  0.635664, 0.289062 (1.421 sec)
20.330... logprob:  0.606539, 0.274740 (1.419 sec)
20.331... logprob:  0.557021, 0.216146 (1.417 sec)
20.332... logprob:  0.650984, 0.296875 (1.455 sec)
20.333... logprob:  0.516811, 0.231771 (1.434 sec)
20.334... logprob:  0.832702, 0.343750 (1.438 sec)
20.335... logprob:  0.594777, 0.257812 (1.429 sec)
20.336... logprob:  0.612396, 0.277344 (1.454 sec)
20.337... logprob:  0.883262, 0.352865 (1.415 sec)
20.338... logprob:  0.664261, 0.290365 (1.413 sec)
20.339... logprob:  0.729067, 0.322917 (1.429 sec)
20.340... logprob:  0.732571, 0.342448 (1.419 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.481076, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.671706e-03 [1.837956e-07] 
Layer 'conv1' biases: 1.999367e-06 [2.113495e-10] 
Layer 'conv2' weights[0]: 3.664703e-03 [1.834875e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.987224e-09] 
Layer 'conv3' weights[0]: 3.663378e-03 [1.841138e-07] 
Layer 'conv3' biases: 3.313608e-05 [1.288538e-08] 
Layer 'conv4' weights[0]: 3.678711e-03 [1.853770e-07] 
Layer 'conv4' biases: 9.999548e-01 [2.736144e-07] 
Layer 'conv5' weights[0]: 3.796260e-03 [2.902893e-06] 
Layer 'conv5' biases: 9.990978e-01 [3.276598e-06] 
Layer 'fc6' weights[0]: 7.003475e-03 [7.033819e-08] 
Layer 'fc6' biases: 9.999925e-01 [6.799560e-08] 
Layer 'fc7' weights[0]: 7.353642e-03 [1.652213e-07] 
Layer 'fc7' biases: 9.997895e-01 [2.548070e-07] 
Layer 'fc8' weights[0]: 4.623363e-03 [1.795348e-05] 
Layer 'fc8' biases: 1.598171e-02 [4.545382e-05] 
Train error last 800 batches: 0.656549
-------------------------------------------------------
Not saving because 0.481076 > 0.299667 (9.300: -1.18%)
======================================================= (2.412 sec)
20.341... logprob:  0.746777, 0.291667 (1.424 sec)
20.342... logprob:  0.592167, 0.268229 (1.459 sec)
20.343... logprob:  0.654271, 0.266927 (1.438 sec)
20.344... logprob:  0.660839, 0.285156 (1.480 sec)
20.345... logprob:  0.679021, 0.261719 (1.440 sec)
20.346... logprob:  0.709054, 0.290365 (1.437 sec)
20.347... logprob:  0.641621, 0.290364 (1.483 sec)
20.348... logprob:  0.636860, 0.291667 (1.430 sec)
20.349... logprob:  0.602047, 0.256510 (1.432 sec)
20.350... logprob:  0.573928, 0.225260 (1.424 sec)
20.351... logprob:  0.705972, 0.272135 (1.429 sec)
20.352... logprob:  0.533538, 0.229167 (1.434 sec)
20.353... logprob:  0.693339, 0.343750 (1.484 sec)
20.354... logprob:  0.832659, 0.356771 (1.430 sec)
20.355... logprob:  0.615618, 0.285156 (1.438 sec)
20.356... logprob:  0.715039, 0.305990 (1.471 sec)
20.357... logprob:  0.604031, 0.246094 (1.427 sec)
20.358... logprob:  0.520192, 0.233073 (1.438 sec)
20.359... logprob:  0.813519, 0.332031 (1.428 sec)
20.360... logprob:  0.628860, 0.281250 (1.419 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.488769, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.668039e-03 [1.837173e-07] 
Layer 'conv1' biases: 1.999374e-06 [1.824905e-10] 
Layer 'conv2' weights[0]: 3.661032e-03 [1.832246e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.498839e-09] 
Layer 'conv3' weights[0]: 3.659680e-03 [1.836556e-07] 
Layer 'conv3' biases: 3.309784e-05 [1.091799e-08] 
Layer 'conv4' weights[0]: 3.675028e-03 [1.847321e-07] 
Layer 'conv4' biases: 9.999572e-01 [1.896005e-07] 
Layer 'conv5' weights[0]: 3.793695e-03 [2.393620e-06] 
Layer 'conv5' biases: 9.990931e-01 [2.514419e-06] 
Layer 'fc6' weights[0]: 7.002756e-03 [6.199815e-08] 
Layer 'fc6' biases: 9.999924e-01 [5.680167e-08] 
Layer 'fc7' weights[0]: 7.352899e-03 [1.396500e-07] 
Layer 'fc7' biases: 9.997897e-01 [1.655982e-07] 
Layer 'fc8' weights[0]: 4.620916e-03 [1.319147e-05] 
Layer 'fc8' biases: 1.603656e-02 [1.657990e-05] 
Train error last 800 batches: 0.656640
-------------------------------------------------------
Not saving because 0.488769 > 0.299667 (9.300: -1.18%)
======================================================= (2.368 sec)
20.361... logprob:  0.692010, 0.313802 (1.435 sec)
20.362... logprob:  0.629324, 0.302083 (1.478 sec)
20.363... logprob:  0.661465, 0.278646 (1.439 sec)
20.364... logprob:  0.659619, 0.294271 (1.456 sec)
20.365... logprob:  0.637999, 0.287760 (1.461 sec)
20.366... logprob:  0.686690, 0.328125 (1.438 sec)
20.367... logprob:  0.530634, 0.230469 (1.434 sec)
20.368... logprob:  0.744839, 0.319010 (1.430 sec)
20.369... logprob:  0.584778, 0.252604 (1.417 sec)
20.370... logprob:  0.617939, 0.278646 (1.433 sec)
20.371... logprob:  0.606635, 0.278646 (1.449 sec)
20.372... logprob:  0.798371, 0.328125 (1.449 sec)
20.373... logprob:  0.638099, 0.295573 (1.448 sec)
20.374... logprob:  0.649415, 0.295573 (1.445 sec)
20.375... logprob:  0.623501, 0.312500 (1.455 sec)
20.376... logprob:  0.623540, 0.274740 (1.433 sec)
20.377... logprob:  0.522335, 0.261719 (1.428 sec)
20.378... logprob:  0.690408, 0.316406 (1.430 sec)
20.379... logprob:  0.704527, 0.307292 (1.432 sec)
20.380... logprob:  0.767887, 0.322917 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.573165, 0.171875 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.664378e-03 [1.833902e-07] 
Layer 'conv1' biases: 2.001270e-06 [2.604899e-10] 
Layer 'conv2' weights[0]: 3.657386e-03 [1.830933e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.141910e-09] 
Layer 'conv3' weights[0]: 3.656010e-03 [1.837211e-07] 
Layer 'conv3' biases: 3.308920e-05 [1.174019e-08] 
Layer 'conv4' weights[0]: 3.671354e-03 [1.848345e-07] 
Layer 'conv4' biases: 9.999555e-01 [2.188900e-07] 
Layer 'conv5' weights[0]: 3.789595e-03 [2.147447e-06] 
Layer 'conv5' biases: 9.990762e-01 [2.243676e-06] 
Layer 'fc6' weights[0]: 7.002045e-03 [5.918569e-08] 
Layer 'fc6' biases: 9.999925e-01 [5.328411e-08] 
Layer 'fc7' weights[0]: 7.352142e-03 [1.340519e-07] 
Layer 'fc7' biases: 9.997908e-01 [1.524100e-07] 
Layer 'fc8' weights[0]: 4.658372e-03 [1.231959e-05] 
Layer 'fc8' biases: 1.633119e-02 [7.586973e-06] 
Train error last 800 batches: 0.656546
-------------------------------------------------------
Not saving because 0.573165 > 0.299667 (9.300: -1.18%)
======================================================= (2.370 sec)
20.381... logprob:  0.714987, 0.321615 (1.481 sec)
20.382... logprob:  0.726436, 0.309896 (1.454 sec)
20.383... logprob:  0.617649, 0.294271 (1.432 sec)
20.384... logprob:  0.629076, 0.283854 (1.476 sec)
20.385... logprob:  0.797115, 0.342448 (1.435 sec)
20.386... logprob:  0.772384, 0.312500 (1.424 sec)
20.387... logprob:  0.646605, 0.296875 (1.431 sec)
20.388... logprob:  0.636573, 0.266927 (1.434 sec)
20.389... logprob:  0.728670, 0.300781 (1.434 sec)
20.390... logprob:  0.641725, 0.282552 (1.469 sec)
20.391... logprob:  0.561702, 0.252604 (1.438 sec)
20.392... logprob:  0.727439, 0.322917 (1.425 sec)
20.393... logprob:  0.624185, 0.264323 (1.485 sec)
20.394... logprob:  0.528147, 0.261719 (1.430 sec)
20.395... logprob:  0.593655, 0.266927 (1.431 sec)
20.396... logprob:  0.512926, 0.246094 (1.435 sec)
20.397... logprob:  0.701450, 0.302083 (1.429 sec)
20.398... logprob:  0.625929, 0.246094 (1.428 sec)
20.399... logprob:  0.638610, 0.281250 (1.478 sec)
20.400... logprob:  0.711272, 0.311198 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.473837, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.660713e-03 [1.833456e-07] 
Layer 'conv1' biases: 2.003317e-06 [1.647719e-10] 
Layer 'conv2' weights[0]: 3.653738e-03 [1.829111e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.614883e-09] 
Layer 'conv3' weights[0]: 3.652359e-03 [1.834961e-07] 
Layer 'conv3' biases: 3.309068e-05 [1.228153e-08] 
Layer 'conv4' weights[0]: 3.667684e-03 [1.848156e-07] 
Layer 'conv4' biases: 9.999553e-01 [2.463977e-07] 
Layer 'conv5' weights[0]: 3.785731e-03 [2.742734e-06] 
Layer 'conv5' biases: 9.990827e-01 [2.970205e-06] 
Layer 'fc6' weights[0]: 7.001320e-03 [6.691817e-08] 
Layer 'fc6' biases: 9.999925e-01 [6.359424e-08] 
Layer 'fc7' weights[0]: 7.351442e-03 [1.579466e-07] 
Layer 'fc7' biases: 9.997908e-01 [2.294350e-07] 
Layer 'fc8' weights[0]: 4.640638e-03 [1.863213e-05] 
Layer 'fc8' biases: 1.614236e-02 [5.044934e-05] 
Train error last 800 batches: 0.656325
-------------------------------------------------------
Not saving because 0.473837 > 0.299667 (9.300: -1.18%)
======================================================= (2.359 sec)
20.401... logprob:  0.598390, 0.285156 (1.450 sec)
20.402... logprob:  0.701686, 0.303385 (1.478 sec)
20.403... logprob:  0.646765, 0.278646 (1.431 sec)
20.404... logprob:  0.716792, 0.316406 (1.428 sec)
20.405... logprob:  0.719567, 0.317708 (1.430 sec)
20.406... logprob:  0.600496, 0.268229 (1.420 sec)
20.407... logprob:  0.719349, 0.317708 (1.427 sec)
20.408... logprob:  0.565265, 0.253906 (1.473 sec)
20.409... logprob:  0.609371, 0.276042 (1.433 sec)
20.410... logprob:  0.665655, 0.303385 (1.446 sec)
20.411... logprob:  0.612569, 0.283854 (1.469 sec)
20.412... logprob:  0.798250, 0.324219 (1.435 sec)
20.413... logprob:  0.824626, 0.369792 (1.436 sec)
20.414... logprob:  0.691732, 0.282552 (1.428 sec)
20.415... logprob:  0.636159, 0.279948 (1.417 sec)
20.416... logprob:  0.665085, 0.283854 (1.432 sec)
20.417... logprob:  0.596274, 0.277344 (1.462 sec)
20.418... logprob:  0.621598, 0.289062 (1.450 sec)
20.419... logprob:  0.672745, 0.272135 (1.446 sec)
20.420... logprob:  0.584862, 0.253906 (1.447 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.491651, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.657047e-03 [1.831701e-07] 
Layer 'conv1' biases: 2.004100e-06 [1.648662e-10] 
Layer 'conv2' weights[0]: 3.650087e-03 [1.827130e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.274163e-09] 
Layer 'conv3' weights[0]: 3.648739e-03 [1.829910e-07] 
Layer 'conv3' biases: 3.310056e-05 [9.314174e-09] 
Layer 'conv4' weights[0]: 3.664020e-03 [1.843698e-07] 
Layer 'conv4' biases: 9.999557e-01 [2.065905e-07] 
Layer 'conv5' weights[0]: 3.782537e-03 [2.441600e-06] 
Layer 'conv5' biases: 9.990872e-01 [2.618067e-06] 
Layer 'fc6' weights[0]: 7.000625e-03 [6.558373e-08] 
Layer 'fc6' biases: 9.999927e-01 [6.206047e-08] 
Layer 'fc7' weights[0]: 7.350650e-03 [1.573163e-07] 
Layer 'fc7' biases: 9.997901e-01 [2.353708e-07] 
Layer 'fc8' weights[0]: 4.627643e-03 [1.829257e-05] 
Layer 'fc8' biases: 1.608428e-02 [3.920327e-05] 
Train error last 800 batches: 0.656067
-------------------------------------------------------
Not saving because 0.491651 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
20.421... logprob:  0.674035, 0.319010 (1.456 sec)
20.422... logprob:  0.707762, 0.298177 (1.440 sec)
20.423... logprob:  0.622814, 0.282552 (1.431 sec)
20.424... logprob:  0.591501, 0.260417 (1.429 sec)
20.425... logprob:  0.525331, 0.242188 (1.438 sec)
20.426... logprob:  0.676880, 0.303385 (1.440 sec)
20.427... logprob:  0.692948, 0.303385 (1.459 sec)
20.428... logprob:  0.739062, 0.324219 (1.448 sec)
20.429... logprob:  0.684979, 0.312500 (1.440 sec)
20.430... logprob:  0.556760, 0.260417 (1.467 sec)
20.431... logprob:  0.652204, 0.296875 (1.432 sec)
20.432... logprob:  0.609494, 0.255208 (1.428 sec)
20.433... logprob:  0.534571, 0.247396 (1.431 sec)
20.434... logprob:  0.686142, 0.305990 (1.431 sec)
20.435... logprob:  0.812834, 0.358073 (1.428 sec)
20.436... logprob:  0.576409, 0.264323 (1.471 sec)
20.437... logprob:  0.726954, 0.303385 (1.444 sec)
20.438... logprob:  0.676252, 0.294271 (1.427 sec)
20.439... logprob:  0.668649, 0.294271 (1.487 sec)
20.440... logprob:  0.669481, 0.315104 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.484252, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.653393e-03 [1.827630e-07] 
Layer 'conv1' biases: 2.004626e-06 [1.412690e-10] 
Layer 'conv2' weights[0]: 3.646426e-03 [1.824371e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.363194e-09] 
Layer 'conv3' weights[0]: 3.645070e-03 [1.827045e-07] 
Layer 'conv3' biases: 3.313783e-05 [8.312057e-09] 
Layer 'conv4' weights[0]: 3.660358e-03 [1.837397e-07] 
Layer 'conv4' biases: 9.999552e-01 [1.828305e-07] 
Layer 'conv5' weights[0]: 3.778891e-03 [2.215702e-06] 
Layer 'conv5' biases: 9.990670e-01 [2.429573e-06] 
Layer 'fc6' weights[0]: 6.999871e-03 [6.051439e-08] 
Layer 'fc6' biases: 9.999925e-01 [5.550756e-08] 
Layer 'fc7' weights[0]: 7.349928e-03 [1.373815e-07] 
Layer 'fc7' biases: 9.997911e-01 [1.695409e-07] 
Layer 'fc8' weights[0]: 4.671771e-03 [1.359415e-05] 
Layer 'fc8' biases: 1.655302e-02 [2.277830e-05] 
Train error last 800 batches: 0.655836
-------------------------------------------------------
Not saving because 0.484252 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
20.441... logprob:  0.690251, 0.303385 (1.429 sec)
20.442... logprob:  0.643331, 0.286458 (1.434 sec)
20.443... logprob:  0.679698, 0.279948 (1.424 sec)
20.444... logprob:  0.621073, 0.296875 (1.426 sec)
20.445... logprob:  0.611498, 0.265625 (1.477 sec)
20.446... logprob:  0.585111, 0.255208 (1.430 sec)
20.447... logprob:  0.823745, 0.339844 (1.436 sec)
20.448... logprob:  0.581882, 0.260417 (1.480 sec)
20.449... logprob:  0.684886, 0.296875 (1.429 sec)
20.450... logprob:  0.537372, 0.238281 (1.425 sec)
20.451... logprob:  0.636545, 0.278646 (1.430 sec)
20.452... logprob:  0.711900, 0.337240 (1.423 sec)
20.453... logprob:  0.705944, 0.317708 (1.433 sec)
20.454... logprob:  0.734082, 0.321615 (1.479 sec)
20.455... logprob:  0.696633, 0.317708 (1.429 sec)
20.456... logprob:  0.767359, 0.329427 (1.442 sec)
20.457... logprob:  0.608940, 0.274740 (1.466 sec)
20.458... logprob:  0.628963, 0.278646 (1.432 sec)
20.459... logprob:  0.742001, 0.326823 (1.427 sec)
20.460... logprob:  0.510465, 0.217448 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.507128, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.649759e-03 [1.825932e-07] 
Layer 'conv1' biases: 2.004900e-06 [1.300049e-10] 
Layer 'conv2' weights[0]: 3.642810e-03 [1.822551e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.416529e-09] 
Layer 'conv3' weights[0]: 3.641436e-03 [1.826437e-07] 
Layer 'conv3' biases: 3.310314e-05 [9.724044e-09] 
Layer 'conv4' weights[0]: 3.656733e-03 [1.836320e-07] 
Layer 'conv4' biases: 9.999563e-01 [1.795413e-07] 
Layer 'conv5' weights[0]: 3.776193e-03 [2.272055e-06] 
Layer 'conv5' biases: 9.990734e-01 [2.413280e-06] 
Layer 'fc6' weights[0]: 6.999116e-03 [5.983239e-08] 
Layer 'fc6' biases: 9.999924e-01 [5.445138e-08] 
Layer 'fc7' weights[0]: 7.349210e-03 [1.385217e-07] 
Layer 'fc7' biases: 9.997897e-01 [1.695319e-07] 
Layer 'fc8' weights[0]: 4.632079e-03 [1.440787e-05] 
Layer 'fc8' biases: 1.633470e-02 [3.009457e-05] 
Train error last 800 batches: 0.656364
-------------------------------------------------------
Not saving because 0.507128 > 0.299667 (9.300: -1.18%)
======================================================= (2.414 sec)
20.461... logprob:  0.668625, 0.300781 (1.439 sec)
20.462... logprob:  0.710833, 0.286458 (1.436 sec)
20.463... logprob:  0.702246, 0.277344 (1.467 sec)
20.464... logprob:  0.711055, 0.296875 (1.447 sec)
20.465... logprob:  0.673363, 0.316406 (1.452 sec)
20.466... logprob:  0.459094, 0.205729 (1.455 sec)
20.467... logprob:  0.616650, 0.272135 (1.449 sec)
20.468... logprob:  0.673869, 0.303385 (1.440 sec)
20.469... logprob:  0.536315, 0.246094 (1.421 sec)
20.470... logprob:  0.611862, 0.302083 (1.421 sec)
20.471... logprob:  0.659862, 0.285156 (1.434 sec)
20.472... logprob:  0.672887, 0.312500 (1.450 sec)
20.473... logprob:  0.600309, 0.264323 (1.455 sec)
20.474... logprob:  0.708716, 0.312500 (1.444 sec)
20.475... logprob:  0.706330, 0.303385 (1.443 sec)
20.476... logprob:  0.720213, 0.295573 (1.464 sec)
20.477... logprob:  0.594367, 0.281250 (1.437 sec)
20.478... logprob:  0.692710, 0.273437 (1.420 sec)
20.479... logprob:  0.564777, 0.259114 (1.422 sec)
20.480... logprob:  0.739561, 0.324219 (1.439 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.496554, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.646094e-03 [1.826651e-07] 
Layer 'conv1' biases: 2.004799e-06 [1.648975e-10] 
Layer 'conv2' weights[0]: 3.639149e-03 [1.822324e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.559539e-09] 
Layer 'conv3' weights[0]: 3.637787e-03 [1.825672e-07] 
Layer 'conv3' biases: 3.311030e-05 [1.046972e-08] 
Layer 'conv4' weights[0]: 3.653054e-03 [1.838853e-07] 
Layer 'conv4' biases: 9.999558e-01 [2.040246e-07] 
Layer 'conv5' weights[0]: 3.772184e-03 [2.325070e-06] 
Layer 'conv5' biases: 9.990802e-01 [2.522207e-06] 
Layer 'fc6' weights[0]: 6.998394e-03 [6.049195e-08] 
Layer 'fc6' biases: 9.999924e-01 [5.512448e-08] 
Layer 'fc7' weights[0]: 7.348476e-03 [1.371206e-07] 
Layer 'fc7' biases: 9.997894e-01 [1.612121e-07] 
Layer 'fc8' weights[0]: 4.623561e-03 [1.264476e-05] 
Layer 'fc8' biases: 1.622893e-02 [9.699446e-06] 
Train error last 800 batches: 0.656457
-------------------------------------------------------
Not saving because 0.496554 > 0.299667 (9.300: -1.18%)
======================================================= (2.375 sec)
20.481... logprob:  0.745351, 0.321614 (1.436 sec)
20.482... logprob:  0.698134, 0.302083 (1.471 sec)
20.483... logprob:  0.668361, 0.317708 (1.439 sec)
20.484... logprob:  0.724804, 0.313802 (1.441 sec)
20.485... logprob:  0.678419, 0.287760 (1.476 sec)
20.486... logprob:  0.588407, 0.263021 (1.431 sec)
20.487... logprob:  0.705866, 0.312500 (1.427 sec)
20.488... logprob:  0.709698, 0.291667 (1.434 sec)
20.489... logprob:  0.732980, 0.364583 (1.432 sec)
20.490... logprob:  0.639746, 0.269531 (1.433 sec)
20.491... logprob:  0.550169, 0.261719 (1.472 sec)
20.492... logprob:  0.693002, 0.298177 (1.434 sec)
20.493... logprob:  0.740327, 0.320312 (1.430 sec)
20.494... logprob:  0.708186, 0.286458 (1.479 sec)
20.495... logprob:  0.626566, 0.285156 (1.425 sec)
20.496... logprob:  0.777359, 0.302083 (1.429 sec)
20.497... logprob:  0.711629, 0.300781 (1.434 sec)
20.498... logprob:  0.735051, 0.289062 (1.424 sec)
20.499... logprob:  0.685332, 0.277344 (1.425 sec)
20.500... logprob:  0.635182, 0.270833 (1.481 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.432465, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.642433e-03 [1.825885e-07] 
Layer 'conv1' biases: 2.004158e-06 [2.015978e-10] 
Layer 'conv2' weights[0]: 3.635508e-03 [1.821065e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.028772e-09] 
Layer 'conv3' weights[0]: 3.634124e-03 [1.826508e-07] 
Layer 'conv3' biases: 3.313117e-05 [1.296309e-08] 
Layer 'conv4' weights[0]: 3.649411e-03 [1.839656e-07] 
Layer 'conv4' biases: 9.999548e-01 [2.680294e-07] 
Layer 'conv5' weights[0]: 3.768180e-03 [2.801989e-06] 
Layer 'conv5' biases: 9.991079e-01 [2.977368e-06] 
Layer 'fc6' weights[0]: 6.997660e-03 [6.710069e-08] 
Layer 'fc6' biases: 9.999924e-01 [6.360548e-08] 
Layer 'fc7' weights[0]: 7.347752e-03 [1.565037e-07] 
Layer 'fc7' biases: 9.997879e-01 [2.163971e-07] 
Layer 'fc8' weights[0]: 4.560115e-03 [1.614180e-05] 
Layer 'fc8' biases: 1.583563e-02 [3.024544e-05] 
Train error last 800 batches: 0.656593
-------------------------------------------------------
Not saving because 0.432465 > 0.299667 (9.300: -1.18%)
======================================================= (2.368 sec)
20.501... logprob:  0.603454, 0.264323 (1.433 sec)
20.502... logprob:  0.690573, 0.309896 (1.443 sec)
20.503... logprob:  0.656479, 0.303385 (1.485 sec)
20.504... logprob:  0.711724, 0.296875 (1.432 sec)
20.505... logprob:  0.739435, 0.326823 (1.432 sec)
20.506... logprob:  0.627599, 0.252604 (1.519 sec)
20.507... logprob:  0.556098, 0.230469 (1.419 sec)
20.508... logprob:  0.628710, 0.285156 (1.427 sec)
20.509... logprob:  0.608897, 0.263021 (1.471 sec)
20.510... logprob:  0.639929, 0.294271 (1.438 sec)
20.511... logprob:  0.667015, 0.282552 (1.451 sec)
20.512... logprob:  0.613186, 0.257812 (1.460 sec)
20.513... logprob:  0.573884, 0.264323 (1.436 sec)
20.514... logprob:  0.697122, 0.321615 (1.433 sec)
20.515... logprob:  0.660998, 0.285156 (1.422 sec)
20.516... logprob:  0.582706, 0.273438 (1.419 sec)
20.517... logprob:  0.754855, 0.320313 (1.431 sec)
20.518... logprob:  0.704166, 0.309896 (1.456 sec)
20.519... logprob:  0.733889, 0.317708 (1.454 sec)
20.520... logprob:  0.589278, 0.236979 (1.455 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.444481, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.638820e-03 [1.819289e-07] 
Layer 'conv1' biases: 2.004313e-06 [1.911258e-10] 
Layer 'conv2' weights[0]: 3.631873e-03 [1.817501e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.436627e-09] 
Layer 'conv3' weights[0]: 3.630521e-03 [1.821570e-07] 
Layer 'conv3' biases: 3.312728e-05 [1.029191e-08] 
Layer 'conv4' weights[0]: 3.645761e-03 [1.834679e-07] 
Layer 'conv4' biases: 9.999564e-01 [2.278171e-07] 
Layer 'conv5' weights[0]: 3.765816e-03 [2.426988e-06] 
Layer 'conv5' biases: 9.990864e-01 [2.549007e-06] 
Layer 'fc6' weights[0]: 6.996966e-03 [6.064570e-08] 
Layer 'fc6' biases: 9.999923e-01 [5.505864e-08] 
Layer 'fc7' weights[0]: 7.346964e-03 [1.375668e-07] 
Layer 'fc7' biases: 9.997888e-01 [1.594028e-07] 
Layer 'fc8' weights[0]: 4.609086e-03 [1.278653e-05] 
Layer 'fc8' biases: 1.621062e-02 [1.254462e-05] 
Train error last 800 batches: 0.656806
-------------------------------------------------------
Not saving because 0.444481 > 0.299667 (9.300: -1.18%)
======================================================= (2.426 sec)
20.521... logprob:  0.691917, 0.294271 (1.462 sec)
20.522... logprob:  0.751775, 0.348958 (1.463 sec)
20.523... logprob:  0.578143, 0.276042 (1.439 sec)
20.524... logprob:  0.693773, 0.294271 (1.424 sec)
20.525... logprob:  0.658445, 0.303385 (1.429 sec)
20.526... logprob:  0.647541, 0.265625 (1.436 sec)
20.527... logprob:  0.680467, 0.292969 (1.433 sec)
20.528... logprob:  0.649857, 0.272135 (1.462 sec)
20.529... logprob:  0.615217, 0.281250 (1.444 sec)
20.530... logprob:  0.658937, 0.291667 (1.434 sec)
20.531... logprob:  0.605931, 0.251302 (1.474 sec)
20.532... logprob:  0.669014, 0.289062 (1.426 sec)
20.533... logprob:  0.778174, 0.342448 (1.424 sec)
20.534... logprob:  0.571513, 0.256510 (1.434 sec)
20.535... logprob:  0.687761, 0.299479 (1.431 sec)
20.536... logprob:  0.703871, 0.311198 (1.424 sec)
20.537... logprob:  0.781186, 0.351563 (1.473 sec)
20.538... logprob:  0.754844, 0.319010 (1.437 sec)
20.539... logprob:  0.549990, 0.244792 (1.425 sec)
20.540... logprob:  0.648819, 0.276042 (1.478 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.466973, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.635171e-03 [1.817309e-07] 
Layer 'conv1' biases: 2.005704e-06 [1.784520e-10] 
Layer 'conv2' weights[0]: 3.628240e-03 [1.814984e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.789711e-09] 
Layer 'conv3' weights[0]: 3.626868e-03 [1.821444e-07] 
Layer 'conv3' biases: 3.314326e-05 [1.214414e-08] 
Layer 'conv4' weights[0]: 3.642103e-03 [1.832756e-07] 
Layer 'conv4' biases: 9.999559e-01 [2.294313e-07] 
Layer 'conv5' weights[0]: 3.761942e-03 [2.383240e-06] 
Layer 'conv5' biases: 9.990864e-01 [2.536961e-06] 
Layer 'fc6' weights[0]: 6.996273e-03 [6.222215e-08] 
Layer 'fc6' biases: 9.999923e-01 [5.753160e-08] 
Layer 'fc7' weights[0]: 7.346249e-03 [1.401946e-07] 
Layer 'fc7' biases: 9.997887e-01 [1.733020e-07] 
Layer 'fc8' weights[0]: 4.596459e-03 [1.339483e-05] 
Layer 'fc8' biases: 1.611130e-02 [1.754172e-05] 
Train error last 800 batches: 0.657005
-------------------------------------------------------
Not saving because 0.466973 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
20.541... logprob:  0.653917, 0.277344 (1.438 sec)
20.542... logprob:  0.602195, 0.285156 (1.429 sec)
20.543... logprob:  0.550871, 0.276042 (1.431 sec)
20.544... logprob:  0.581097, 0.265625 (1.421 sec)
20.545... logprob:  0.658491, 0.291667 (1.430 sec)
20.546... logprob:  0.647347, 0.317708 (1.480 sec)
20.547... logprob:  0.602303, 0.282552 (1.434 sec)
20.548... logprob:  0.728972, 0.319010 (1.436 sec)
20.549... logprob:  0.598652, 0.264323 (1.471 sec)
20.550... logprob:  0.622344, 0.305990 (1.429 sec)
20.551... logprob:  0.646717, 0.308594 (1.429 sec)
20.552... logprob:  0.713385, 0.352865 (1.435 sec)
20.553... logprob:  0.627530, 0.281250 (1.422 sec)
20.554... logprob:  0.825801, 0.360677 (1.427 sec)
20.555... logprob:  0.652214, 0.279948 (1.477 sec)
20.556... logprob:  0.664103, 0.311198 (1.427 sec)
20.557... logprob:  0.679080, 0.311198 (1.441 sec)
20.558... logprob:  0.578950, 0.259115 (1.468 sec)
20.559... logprob:  0.727470, 0.312500 (1.429 sec)
20.560... logprob:  0.573508, 0.256510 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.563322, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.631544e-03 [1.817455e-07] 
Layer 'conv1' biases: 2.006870e-06 [1.856114e-10] 
Layer 'conv2' weights[0]: 3.624596e-03 [1.814247e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.824987e-09] 
Layer 'conv3' weights[0]: 3.623263e-03 [1.818929e-07] 
Layer 'conv3' biases: 3.313310e-05 [1.114984e-08] 
Layer 'conv4' weights[0]: 3.638477e-03 [1.832887e-07] 
Layer 'conv4' biases: 9.999546e-01 [2.536221e-07] 
Layer 'conv5' weights[0]: 3.757774e-03 [2.556173e-06] 
Layer 'conv5' biases: 9.990604e-01 [2.740054e-06] 
Layer 'fc6' weights[0]: 6.995540e-03 [6.114942e-08] 
Layer 'fc6' biases: 9.999921e-01 [5.655466e-08] 
Layer 'fc7' weights[0]: 7.345492e-03 [1.397925e-07] 
Layer 'fc7' biases: 9.997903e-01 [1.810735e-07] 
Layer 'fc8' weights[0]: 4.663716e-03 [1.478094e-05] 
Layer 'fc8' biases: 1.662933e-02 [3.144100e-05] 
Train error last 800 batches: 0.657811
-------------------------------------------------------
Not saving because 0.563322 > 0.299667 (9.300: -1.18%)
======================================================= (2.360 sec)
20.561... logprob:  0.571293, 0.269531 (1.434 sec)
20.562... logprob:  0.704623, 0.317708 (1.428 sec)
20.563... logprob:  0.642770, 0.276042 (1.438 sec)
20.564... logprob:  0.710318, 0.320312 (1.457 sec)
20.565... logprob:  0.858704, 0.350260 (1.445 sec)
20.566... logprob:  0.634684, 0.277344 (1.455 sec)
20.567... logprob:  0.650227, 0.289062 (1.448 sec)
20.568... logprob:  0.726509, 0.343750 (1.449 sec)
20.569... logprob:  0.782489, 0.341146 (1.431 sec)
20.570... logprob:  0.669316, 0.270833 (1.421 sec)
20.571... logprob:  0.709688, 0.286458 (1.425 sec)
20.572... logprob:  0.752913, 0.315104 (1.439 sec)
20.573... logprob:  0.721436, 0.304687 (1.440 sec)
20.574... logprob:  0.615457, 0.272135 (1.454 sec)
20.575... logprob:  0.633594, 0.317708 (1.447 sec)
20.576... logprob:  0.707590, 0.319010 (1.438 sec)
20.577... logprob:  0.625177, 0.263021 (1.469 sec)
20.578... logprob:  0.581065, 0.265625 (1.429 sec)
20.579... logprob:  0.683378, 0.300781 (1.419 sec)
20.580... logprob:  0.761623, 0.332031 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.523872, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.627932e-03 [1.815709e-07] 
Layer 'conv1' biases: 2.007674e-06 [1.812575e-10] 
Layer 'conv2' weights[0]: 3.620993e-03 [1.811830e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.608315e-09] 
Layer 'conv3' weights[0]: 3.619601e-03 [1.817152e-07] 
Layer 'conv3' biases: 3.314558e-05 [1.095202e-08] 
Layer 'conv4' weights[0]: 3.634840e-03 [1.825783e-07] 
Layer 'conv4' biases: 9.999541e-01 [2.088020e-07] 
Layer 'conv5' weights[0]: 3.754346e-03 [2.266020e-06] 
Layer 'conv5' biases: 9.990843e-01 [2.326287e-06] 
Layer 'fc6' weights[0]: 6.994815e-03 [6.214103e-08] 
Layer 'fc6' biases: 9.999921e-01 [5.768910e-08] 
Layer 'fc7' weights[0]: 7.344697e-03 [1.429781e-07] 
Layer 'fc7' biases: 9.997876e-01 [1.808953e-07] 
Layer 'fc8' weights[0]: 4.598166e-03 [1.419699e-05] 
Layer 'fc8' biases: 1.604896e-02 [1.926369e-05] 
Train error last 800 batches: 0.658432
-------------------------------------------------------
Not saving because 0.523872 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
20.581... logprob:  0.735023, 0.338542 (1.441 sec)
20.582... logprob:  0.720090, 0.302083 (1.431 sec)
20.583... logprob:  0.831071, 0.351562 (1.468 sec)
20.584... logprob:  0.732734, 0.328125 (1.439 sec)
20.585... logprob:  0.636075, 0.305990 (1.429 sec)
20.586... logprob:  0.612210, 0.272135 (1.477 sec)
20.587... logprob:  0.721149, 0.294271 (1.428 sec)
20.588... logprob:  0.660887, 0.282552 (1.420 sec)
20.589... logprob:  0.617914, 0.286458 (1.430 sec)
20.590... logprob:  0.733779, 0.325521 (1.424 sec)
20.591... logprob:  0.566641, 0.242187 (1.428 sec)
20.592... logprob:  0.655595, 0.268229 (1.479 sec)
20.593... logprob:  0.644030, 0.300781 (1.429 sec)
20.594... logprob:  0.633287, 0.296875 (1.438 sec)
20.595... logprob:  0.673950, 0.281250 (1.481 sec)
20.596... logprob:  0.626327, 0.282552 (1.426 sec)
20.597... logprob:  0.686217, 0.295573 (1.426 sec)
20.598... logprob:  0.575185, 0.239583 (1.428 sec)
20.599... logprob:  0.557192, 0.255208 (1.422 sec)
20.600... logprob:  0.570226, 0.263021 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.455858, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.624298e-03 [1.816448e-07] 
Layer 'conv1' biases: 2.008162e-06 [2.194989e-10] 
Layer 'conv2' weights[0]: 3.617381e-03 [1.812823e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.603829e-09] 
Layer 'conv3' weights[0]: 3.616006e-03 [1.823218e-07] 
Layer 'conv3' biases: 3.312631e-05 [1.653299e-08] 
Layer 'conv4' weights[0]: 3.631212e-03 [1.842007e-07] 
Layer 'conv4' biases: 9.999550e-01 [3.777017e-07] 
Layer 'conv5' weights[0]: 3.751360e-03 [4.455026e-06] 
Layer 'conv5' biases: 9.990695e-01 [5.012102e-06] 
Layer 'fc6' weights[0]: 6.994089e-03 [8.439538e-08] 
Layer 'fc6' biases: 9.999921e-01 [8.820536e-08] 
Layer 'fc7' weights[0]: 7.343985e-03 [2.140262e-07] 
Layer 'fc7' biases: 9.997879e-01 [4.008503e-07] 
Layer 'fc8' weights[0]: 4.625961e-03 [2.478700e-05] 
Layer 'fc8' biases: 1.632067e-02 [7.163537e-05] 
Train error last 800 batches: 0.658434
-------------------------------------------------------
Not saving because 0.455858 > 0.299667 (9.300: -1.18%)
======================================================= (2.334 sec)
20.601... logprob:  0.702470, 0.319010 (1.486 sec)
20.602... logprob:  0.525089, 0.236979 (1.431 sec)
20.603... logprob:  0.592100, 0.278646 (1.445 sec)
20.604... logprob:  0.712890, 0.299479 (1.469 sec)
20.605... logprob:  0.824865, 0.343750 (1.429 sec)
20.606... logprob:  0.607657, 0.274739 (1.439 sec)
20.607... logprob:  0.641896, 0.287760 (1.427 sec)
20.608... logprob:  0.674468, 0.281250 (1.426 sec)
20.609... logprob:  0.639847, 0.287760 (1.430 sec)
20.610... logprob:  0.713815, 0.320312 (1.470 sec)
20.611... logprob:  0.664301, 0.307292 (1.439 sec)
20.612... logprob:  0.717508, 0.305990 (1.450 sec)
20.613... logprob:  0.532651, 0.250000 (1.460 sec)
20.614... logprob:  0.776441, 0.309896 (1.444 sec)
20.615... logprob:  0.495489, 0.218750 (1.440 sec)
20.616... logprob:  0.567872, 0.253906 (1.424 sec)
20.617... logprob:  0.678644, 0.304687 (1.426 sec)
20.618... logprob:  0.770176, 0.315104 (1.433 sec)
20.619... logprob:  0.692174, 0.304688 (1.447 sec)
20.620... logprob:  0.867485, 0.354167 (1.460 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.433665, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.620674e-03 [1.810328e-07] 
Layer 'conv1' biases: 2.009192e-06 [2.597435e-10] 
Layer 'conv2' weights[0]: 3.613762e-03 [1.809305e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.003517e-09] 
Layer 'conv3' weights[0]: 3.612418e-03 [1.824327e-07] 
Layer 'conv3' biases: 3.312605e-05 [1.874021e-08] 
Layer 'conv4' weights[0]: 3.627570e-03 [1.844711e-07] 
Layer 'conv4' biases: 9.999572e-01 [4.204135e-07] 
Layer 'conv5' weights[0]: 3.749510e-03 [5.321148e-06] 
Layer 'conv5' biases: 9.990545e-01 [5.807458e-06] 
Layer 'fc6' weights[0]: 6.993388e-03 [9.422006e-08] 
Layer 'fc6' biases: 9.999921e-01 [1.042568e-07] 
Layer 'fc7' weights[0]: 7.343278e-03 [2.471504e-07] 
Layer 'fc7' biases: 9.997888e-01 [4.741135e-07] 
Layer 'fc8' weights[0]: 4.655891e-03 [2.658707e-05] 
Layer 'fc8' biases: 1.666905e-02 [7.303817e-05] 
Train error last 800 batches: 0.659137
-------------------------------------------------------
Not saving because 0.433665 > 0.299667 (9.300: -1.18%)
======================================================= (2.345 sec)
20.621... logprob:  0.514636, 0.252604 (1.455 sec)
20.622... logprob:  0.662407, 0.302083 (1.446 sec)
20.623... logprob:  0.690043, 0.308594 (1.463 sec)
20.624... logprob:  0.605317, 0.253906 (1.437 sec)
20.625... logprob:  0.617482, 0.272135 (1.421 sec)
20.626... logprob:  0.671183, 0.307292 (1.430 sec)
20.627... logprob:  0.643968, 0.278646 (1.435 sec)
20.628... logprob:  0.623321, 0.285156 (1.436 sec)
20.629... logprob:  0.575775, 0.242188 (1.472 sec)
20.630... logprob:  0.534246, 0.234375 (1.444 sec)
20.631... logprob:  0.785154, 0.342448 (1.430 sec)
20.632... logprob:  0.663723, 0.325521 (1.472 sec)
20.633... logprob:  0.617446, 0.260417 (1.433 sec)
20.634... logprob:  0.823807, 0.334635 (1.427 sec)
20.635... logprob:  0.612809, 0.266927 (1.429 sec)
20.636... logprob:  0.781173, 0.326823 (1.427 sec)
20.637... logprob:  0.610245, 0.261719 (1.433 sec)
20.638... logprob:  0.651094, 0.296875 (1.484 sec)
20.639... logprob:  0.545619, 0.218750 (1.441 sec)
20.640... logprob:  0.692915, 0.316406 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.480479, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.617055e-03 [1.809288e-07] 
Layer 'conv1' biases: 2.010143e-06 [1.552061e-10] 
Layer 'conv2' weights[0]: 3.610152e-03 [1.806114e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.430575e-09] 
Layer 'conv3' weights[0]: 3.608826e-03 [1.808740e-07] 
Layer 'conv3' biases: 3.316492e-05 [9.241057e-09] 
Layer 'conv4' weights[0]: 3.623925e-03 [1.818712e-07] 
Layer 'conv4' biases: 9.999564e-01 [1.654518e-07] 
Layer 'conv5' weights[0]: 3.745497e-03 [2.227004e-06] 
Layer 'conv5' biases: 9.990772e-01 [2.364092e-06] 
Layer 'fc6' weights[0]: 6.992671e-03 [5.912892e-08] 
Layer 'fc6' biases: 9.999923e-01 [5.320591e-08] 
Layer 'fc7' weights[0]: 7.342557e-03 [1.329388e-07] 
Layer 'fc7' biases: 9.997870e-01 [1.477504e-07] 
Layer 'fc8' weights[0]: 4.607717e-03 [1.185937e-05] 
Layer 'fc8' biases: 1.630258e-02 [3.265232e-06] 
Train error last 800 batches: 0.658652
-------------------------------------------------------
Not saving because 0.480479 > 0.299667 (9.300: -1.18%)
======================================================= (2.412 sec)
20.641... logprob:  0.635207, 0.291667 (1.481 sec)
20.642... logprob:  0.675715, 0.322917 (1.431 sec)
20.643... logprob:  0.843382, 0.355469 (1.429 sec)
20.644... logprob:  0.589160, 0.265625 (1.433 sec)
20.645... logprob:  0.647364, 0.272135 (1.431 sec)
20.646... logprob:  0.595233, 0.269531 (1.433 sec)
20.647... logprob:  0.665223, 0.316406 (1.480 sec)
20.648... logprob:  0.668908, 0.308594 (1.429 sec)
20.649... logprob:  0.599321, 0.247396 (1.449 sec)
20.650... logprob:  0.628679, 0.300781 (1.476 sec)
20.651... logprob:  0.546068, 0.239583 (1.433 sec)
20.652... logprob:  0.780998, 0.325521 (1.430 sec)
20.653... logprob:  0.738672, 0.319010 (1.436 sec)
20.654... logprob:  0.680405, 0.259115 (1.417 sec)
20.655... logprob:  0.617280, 0.270833 (1.429 sec)
20.656... logprob:  0.574474, 0.235677 (1.477 sec)
20.657... logprob:  0.601089, 0.268229 (1.441 sec)
20.658... logprob:  0.534720, 0.247396 (1.448 sec)
20.659... logprob:  0.628040, 0.282552 (1.472 sec)
20.660... logprob:  0.724384, 0.324219 (1.435 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.395364, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.613450e-03 [1.808647e-07] 
Layer 'conv1' biases: 2.011097e-06 [1.288350e-10] 
Layer 'conv2' weights[0]: 3.606538e-03 [1.804976e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.341130e-09] 
Layer 'conv3' weights[0]: 3.605192e-03 [1.808994e-07] 
Layer 'conv3' biases: 3.319367e-05 [1.003405e-08] 
Layer 'conv4' weights[0]: 3.620312e-03 [1.823466e-07] 
Layer 'conv4' biases: 9.999549e-01 [2.365668e-07] 
Layer 'conv5' weights[0]: 3.741358e-03 [2.643637e-06] 
Layer 'conv5' biases: 9.990694e-01 [2.829184e-06] 
Layer 'fc6' weights[0]: 6.991917e-03 [6.392259e-08] 
Layer 'fc6' biases: 9.999922e-01 [5.981244e-08] 
Layer 'fc7' weights[0]: 7.341826e-03 [1.483507e-07] 
Layer 'fc7' biases: 9.997875e-01 [2.113015e-07] 
Layer 'fc8' weights[0]: 4.647404e-03 [1.563044e-05] 
Layer 'fc8' biases: 1.654177e-02 [3.617378e-05] 
Train error last 800 batches: 0.658511
-------------------------------------------------------
Not saving because 0.395364 > 0.299667 (9.300: -1.18%)
======================================================= (2.365 sec)
20.661... logprob:  0.604422, 0.273437 (1.443 sec)
20.662... logprob:  0.734202, 0.328125 (1.431 sec)
20.663... logprob:  0.566497, 0.248698 (1.419 sec)
20.664... logprob:  0.544947, 0.257812 (1.434 sec)
20.665... logprob:  0.643305, 0.252604 (1.458 sec)
20.666... logprob:  0.652446, 0.295573 (1.450 sec)
20.667... logprob:  0.788256, 0.347656 (1.456 sec)
20.668... logprob:  0.661314, 0.289062 (1.452 sec)
20.669... logprob:  0.738314, 0.326823 (1.457 sec)
20.670... logprob:  0.608145, 0.265625 (1.437 sec)
20.671... logprob:  0.588218, 0.255208 (1.418 sec)
20.672... logprob:  0.737174, 0.334635 (1.423 sec)
20.673... logprob:  0.728363, 0.302083 (1.433 sec)
20.674... logprob:  0.737933, 0.329427 (1.432 sec)
20.675... logprob:  0.577701, 0.274740 (1.465 sec)
20.676... logprob:  0.713349, 0.316406 (1.445 sec)
20.677... logprob:  0.687326, 0.273438 (1.433 sec)
20.678... logprob:  0.580897, 0.247396 (1.476 sec)
20.679... logprob:  0.644067, 0.273437 (1.432 sec)
20.680... logprob:  0.507413, 0.234375 (1.422 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.506690, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.609831e-03 [1.806742e-07] 
Layer 'conv1' biases: 2.011935e-06 [1.173753e-10] 
Layer 'conv2' weights[0]: 3.602926e-03 [1.802920e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.360381e-09] 
Layer 'conv3' weights[0]: 3.601565e-03 [1.805491e-07] 
Layer 'conv3' biases: 3.322685e-05 [8.965381e-09] 
Layer 'conv4' weights[0]: 3.616694e-03 [1.816703e-07] 
Layer 'conv4' biases: 9.999551e-01 [1.848172e-07] 
Layer 'conv5' weights[0]: 3.738019e-03 [2.159771e-06] 
Layer 'conv5' biases: 9.990679e-01 [2.355270e-06] 
Layer 'fc6' weights[0]: 6.991209e-03 [5.811695e-08] 
Layer 'fc6' biases: 9.999921e-01 [5.202744e-08] 
Layer 'fc7' weights[0]: 7.341096e-03 [1.314434e-07] 
Layer 'fc7' biases: 9.997875e-01 [1.505529e-07] 
Layer 'fc8' weights[0]: 4.647871e-03 [1.197739e-05] 
Layer 'fc8' biases: 1.663951e-02 [1.052348e-05] 
Train error last 800 batches: 0.658383
-------------------------------------------------------
Not saving because 0.506690 > 0.299667 (9.300: -1.18%)
======================================================= (2.370 sec)
20.681... logprob:  0.611591, 0.270833 (1.433 sec)
20.682... logprob:  0.568057, 0.261719 (1.440 sec)
20.683... logprob:  0.632822, 0.279948 (1.427 sec)
20.684... logprob:  0.583356, 0.268229 (1.476 sec)
20.685... logprob:  0.600105, 0.264323 (1.441 sec)
20.686... logprob:  0.537222, 0.252604 (1.430 sec)
20.687... logprob:  0.584195, 0.283854 (1.480 sec)
20.688... logprob:  0.552813, 0.229167 (1.434 sec)
20.689... logprob:  0.712385, 0.322917 (1.424 sec)
20.690... logprob:  0.733210, 0.300781 (1.429 sec)
20.691... logprob:  0.752317, 0.350260 (1.435 sec)
20.692... logprob:  0.603882, 0.243490 (1.427 sec)
20.693... logprob:  0.645228, 0.283854 (1.476 sec)
20.694... logprob:  0.606277, 0.300781 (1.429 sec)
20.695... logprob:  0.607326, 0.259114 (1.438 sec)
20.696... logprob:  0.687749, 0.313802 (1.468 sec)
20.697... logprob:  0.653503, 0.300781 (1.431 sec)
20.698... logprob:  0.662382, 0.290365 (1.433 sec)
20.699... logprob:  0.613019, 0.277344 (1.428 sec)
20.700... logprob:  0.708748, 0.315104 (1.424 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.352151, 0.062500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.606225e-03 [1.805135e-07] 
Layer 'conv1' biases: 2.011806e-06 [1.503709e-10] 
Layer 'conv2' weights[0]: 3.599333e-03 [1.801549e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.229628e-09] 
Layer 'conv3' weights[0]: 3.597942e-03 [1.803817e-07] 
Layer 'conv3' biases: 3.326788e-05 [9.254830e-09] 
Layer 'conv4' weights[0]: 3.613072e-03 [1.813921e-07] 
Layer 'conv4' biases: 9.999535e-01 [2.085701e-07] 
Layer 'conv5' weights[0]: 3.733790e-03 [2.587421e-06] 
Layer 'conv5' biases: 9.990591e-01 [2.795830e-06] 
Layer 'fc6' weights[0]: 6.990536e-03 [6.239903e-08] 
Layer 'fc6' biases: 9.999920e-01 [5.830256e-08] 
Layer 'fc7' weights[0]: 7.340395e-03 [1.413808e-07] 
Layer 'fc7' biases: 9.997876e-01 [1.867790e-07] 
Layer 'fc8' weights[0]: 4.674673e-03 [1.404395e-05] 
Layer 'fc8' biases: 1.687185e-02 [2.352063e-05] 
Train error last 800 batches: 0.658551
-------------------------------------------------------
Not saving because 0.352151 > 0.299667 (9.300: -1.18%)
======================================================= (2.410 sec)
20.701... logprob:  0.592965, 0.250000 (1.431 sec)
20.702... logprob:  0.707731, 0.305990 (1.490 sec)
20.703... logprob:  0.663480, 0.289062 (1.436 sec)
20.704... logprob:  0.651722, 0.286458 (1.439 sec)
20.705... logprob:  0.573967, 0.226563 (1.471 sec)
20.706... logprob:  0.729186, 0.321615 (1.429 sec)
20.707... logprob:  0.744366, 0.311198 (1.430 sec)
20.708... logprob:  0.582373, 0.286458 (1.432 sec)
20.709... logprob:  0.642151, 0.289062 (1.418 sec)
20.710... logprob:  0.778721, 0.354167 (1.433 sec)
20.711... logprob:  0.739291, 0.325521 (1.459 sec)
20.712... logprob:  0.568647, 0.260417 (1.446 sec)
20.713... logprob:  0.709513, 0.304688 (1.452 sec)
20.714... logprob:  0.773810, 0.303385 (1.450 sec)
20.715... logprob:  0.629704, 0.276042 (1.448 sec)
20.716... logprob:  0.548970, 0.246094 (1.433 sec)
20.717... logprob:  0.634897, 0.277344 (1.417 sec)
20.718... logprob:  0.685509, 0.277344 (1.423 sec)
20.719... logprob:  0.593891, 0.274740 (1.434 sec)
20.720... logprob:  0.642430, 0.278646 (1.439 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.431933, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.602605e-03 [1.806284e-07] 
Layer 'conv1' biases: 2.012072e-06 [1.480118e-10] 
Layer 'conv2' weights[0]: 3.595726e-03 [1.800857e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.498920e-09] 
Layer 'conv3' weights[0]: 3.594353e-03 [1.804038e-07] 
Layer 'conv3' biases: 3.330732e-05 [1.052331e-08] 
Layer 'conv4' weights[0]: 3.609470e-03 [1.817756e-07] 
Layer 'conv4' biases: 9.999536e-01 [2.368605e-07] 
Layer 'conv5' weights[0]: 3.730603e-03 [2.513101e-06] 
Layer 'conv5' biases: 9.990690e-01 [2.740117e-06] 
Layer 'fc6' weights[0]: 6.989802e-03 [6.033946e-08] 
Layer 'fc6' biases: 9.999920e-01 [5.495327e-08] 
Layer 'fc7' weights[0]: 7.339585e-03 [1.342992e-07] 
Layer 'fc7' biases: 9.997865e-01 [1.529012e-07] 
Layer 'fc8' weights[0]: 4.628882e-03 [1.269548e-05] 
Layer 'fc8' biases: 1.650496e-02 [1.243604e-05] 
Train error last 800 batches: 0.657626
-------------------------------------------------------
Not saving because 0.431933 > 0.299667 (9.300: -1.18%)
======================================================= (2.363 sec)
20.721... logprob:  0.642352, 0.261719 (1.465 sec)
20.722... logprob:  0.786499, 0.337240 (1.452 sec)
20.723... logprob:  0.700852, 0.299479 (1.445 sec)
20.724... logprob:  0.645529, 0.289062 (1.466 sec)
20.725... logprob:  0.718177, 0.312500 (1.429 sec)
20.726... logprob:  0.570433, 0.236979 (1.420 sec)
20.727... logprob:  0.569977, 0.250000 (1.426 sec)
20.728... logprob:  0.683342, 0.305990 (1.432 sec)
20.729... logprob:  0.540047, 0.257812 (1.464 sec)
20.730... logprob:  0.748332, 0.305990 (1.475 sec)
20.731... logprob:  0.662061, 0.274739 (1.441 sec)
20.732... logprob:  0.507701, 0.223958 (1.431 sec)
20.733... logprob:  0.734256, 0.320312 (1.482 sec)
20.734... logprob:  0.559026, 0.257812 (1.427 sec)
20.735... logprob:  0.754255, 0.300781 (1.421 sec)
20.736... logprob:  0.824118, 0.352865 (1.432 sec)
20.737... logprob:  0.739328, 0.317708 (1.423 sec)
20.738... logprob:  0.639688, 0.292969 (1.429 sec)
20.739... logprob:  0.638383, 0.272135 (1.475 sec)
20.740... logprob:  0.544254, 0.233073 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.460481, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.599018e-03 [1.802690e-07] 
Layer 'conv1' biases: 2.012830e-06 [1.724934e-10] 
Layer 'conv2' weights[0]: 3.592128e-03 [1.797870e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.732260e-09] 
Layer 'conv3' weights[0]: 3.590762e-03 [1.803071e-07] 
Layer 'conv3' biases: 3.332348e-05 [1.183243e-08] 
Layer 'conv4' weights[0]: 3.605862e-03 [1.814562e-07] 
Layer 'conv4' biases: 9.999542e-01 [2.148993e-07] 
Layer 'conv5' weights[0]: 3.727390e-03 [2.459360e-06] 
Layer 'conv5' biases: 9.990656e-01 [2.537701e-06] 
Layer 'fc6' weights[0]: 6.989073e-03 [6.041045e-08] 
Layer 'fc6' biases: 9.999921e-01 [5.570911e-08] 
Layer 'fc7' weights[0]: 7.338883e-03 [1.356317e-07] 
Layer 'fc7' biases: 9.997863e-01 [1.581476e-07] 
Layer 'fc8' weights[0]: 4.631129e-03 [1.247211e-05] 
Layer 'fc8' biases: 1.647084e-02 [1.305523e-05] 
Train error last 800 batches: 0.657461
-------------------------------------------------------
Not saving because 0.460481 > 0.299667 (9.300: -1.18%)
======================================================= (2.376 sec)
20.741... logprob:  0.630699, 0.279948 (1.445 sec)
20.742... logprob:  0.696632, 0.312500 (1.481 sec)
20.743... logprob:  0.630077, 0.303385 (1.429 sec)
20.744... logprob:  0.731716, 0.308594 (1.426 sec)
20.745... logprob:  0.711606, 0.319010 (1.431 sec)
20.746... logprob:  0.603493, 0.256510 (1.425 sec)
20.747... logprob:  0.651874, 0.290365 (1.425 sec)
20.748... logprob:  0.665209, 0.305990 (1.480 sec)
20.749... logprob:  0.572172, 0.270833 (1.425 sec)
20.750... logprob:  0.693906, 0.320313 (1.442 sec)
20.751... logprob:  0.516884, 0.227865 (1.469 sec)
20.752... logprob:  0.711044, 0.296875 (1.435 sec)
20.753... logprob:  0.666105, 0.316406 (1.432 sec)
20.754... logprob:  0.632771, 0.259115 (1.426 sec)
20.755... logprob:  0.811003, 0.361979 (1.418 sec)
20.756... logprob:  0.546304, 0.248698 (1.427 sec)
20.757... logprob:  0.778948, 0.322917 (1.468 sec)
20.758... logprob:  0.631671, 0.292969 (1.439 sec)
20.759... logprob:  0.706991, 0.291667 (1.444 sec)
20.760... logprob:  0.728036, 0.319010 (1.457 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.470635, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.595421e-03 [1.798230e-07] 
Layer 'conv1' biases: 2.013073e-06 [1.486901e-10] 
Layer 'conv2' weights[0]: 3.588535e-03 [1.795698e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.602751e-09] 
Layer 'conv3' weights[0]: 3.587176e-03 [1.798726e-07] 
Layer 'conv3' biases: 3.332821e-05 [1.017400e-08] 
Layer 'conv4' weights[0]: 3.602248e-03 [1.809444e-07] 
Layer 'conv4' biases: 9.999557e-01 [2.350937e-07] 
Layer 'conv5' weights[0]: 3.724661e-03 [2.775733e-06] 
Layer 'conv5' biases: 9.990649e-01 [2.958743e-06] 
Layer 'fc6' weights[0]: 6.988376e-03 [6.705600e-08] 
Layer 'fc6' biases: 9.999920e-01 [6.432965e-08] 
Layer 'fc7' weights[0]: 7.338179e-03 [1.543877e-07] 
Layer 'fc7' biases: 9.997862e-01 [2.138380e-07] 
Layer 'fc8' weights[0]: 4.645688e-03 [1.544723e-05] 
Layer 'fc8' biases: 1.657828e-02 [2.741981e-05] 
Train error last 800 batches: 0.657656
-------------------------------------------------------
Not saving because 0.470635 > 0.299667 (9.300: -1.18%)
======================================================= (2.346 sec)
20.761... logprob:  0.672244, 0.317708 (1.443 sec)
20.762... logprob:  0.812760, 0.345052 (1.436 sec)
20.763... logprob:  0.678931, 0.291667 (1.428 sec)
20.764... logprob:  0.789061, 0.356771 (1.423 sec)
20.765... logprob:  0.596395, 0.279948 (1.439 sec)
20.766... logprob:  0.660783, 0.286458 (1.455 sec)
20.767... logprob:  0.586921, 0.273438 (1.510 sec)
20.768... logprob:  0.714192, 0.325521 (1.463 sec)
20.769... logprob:  0.722823, 0.312500 (1.461 sec)
20.770... logprob:  0.579630, 0.234375 (1.474 sec)
20.771... logprob:  0.681606, 0.294271 (1.454 sec)
20.772... logprob:  0.607881, 0.263021 (1.444 sec)
20.773... logprob:  0.733019, 0.311198 (1.443 sec)
20.774... logprob:  0.587169, 0.266927 (1.458 sec)
20.775... logprob:  0.650814, 0.263021 (1.454 sec)
20.776... logprob:  0.625590, 0.265625 (1.475 sec)
20.777... logprob:  0.606048, 0.259115 (1.463 sec)
20.778... logprob:  0.653612, 0.304687 (1.460 sec)
20.779... logprob:  0.729795, 0.313802 (1.482 sec)
20.780... logprob:  0.613439, 0.255208 (1.445 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.515878, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.591816e-03 [1.797825e-07] 
Layer 'conv1' biases: 2.014755e-06 [2.563206e-10] 
Layer 'conv2' weights[0]: 3.584964e-03 [1.794621e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.484788e-09] 
Layer 'conv3' weights[0]: 3.583566e-03 [1.807781e-07] 
Layer 'conv3' biases: 3.336098e-05 [1.675430e-08] 
Layer 'conv4' weights[0]: 3.598646e-03 [1.824286e-07] 
Layer 'conv4' biases: 9.999528e-01 [3.522644e-07] 
Layer 'conv5' weights[0]: 3.719511e-03 [2.741450e-06] 
Layer 'conv5' biases: 9.990837e-01 [2.876063e-06] 
Layer 'fc6' weights[0]: 6.987660e-03 [6.211277e-08] 
Layer 'fc6' biases: 9.999917e-01 [5.713263e-08] 
Layer 'fc7' weights[0]: 7.337407e-03 [1.441436e-07] 
Layer 'fc7' biases: 9.997848e-01 [1.840286e-07] 
Layer 'fc8' weights[0]: 4.629304e-03 [1.465213e-05] 
Layer 'fc8' biases: 1.642636e-02 [2.951024e-05] 
Train error last 800 batches: 0.657303
-------------------------------------------------------
Not saving because 0.515878 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
20.781... logprob:  0.506487, 0.226562 (1.450 sec)
20.782... logprob:  0.696389, 0.291667 (1.450 sec)
20.783... logprob:  0.671620, 0.276042 (1.453 sec)
20.784... logprob:  0.668723, 0.305990 (1.458 sec)
20.785... logprob:  0.676689, 0.320313 (1.486 sec)
20.786... logprob:  0.687422, 0.289062 (1.465 sec)
20.787... logprob:  0.773062, 0.329427 (1.449 sec)
20.788... logprob:  0.787343, 0.350260 (1.493 sec)
20.789... logprob:  0.563777, 0.270833 (1.451 sec)
20.790... logprob:  0.515810, 0.213542 (1.454 sec)
20.791... logprob:  0.681480, 0.279948 (1.446 sec)
20.792... logprob:  0.648544, 0.304687 (1.456 sec)
20.793... logprob:  0.548635, 0.250000 (1.445 sec)
20.794... logprob:  0.623994, 0.263021 (1.481 sec)
20.795... logprob:  0.570721, 0.260417 (1.461 sec)
20.796... logprob:  0.705470, 0.302083 (1.452 sec)
20.797... logprob:  0.589829, 0.274740 (1.494 sec)
20.798... logprob:  0.599638, 0.287760 (1.445 sec)
20.799... logprob:  0.587861, 0.260417 (1.440 sec)
20.800... logprob:  0.658237, 0.313802 (1.397 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.464533, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.588242e-03 [1.799017e-07] 
Layer 'conv1' biases: 2.017040e-06 [2.697080e-10] 
Layer 'conv2' weights[0]: 3.581369e-03 [1.794571e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.508232e-09] 
Layer 'conv3' weights[0]: 3.579994e-03 [1.806503e-07] 
Layer 'conv3' biases: 3.337562e-05 [1.640226e-08] 
Layer 'conv4' weights[0]: 3.595052e-03 [1.822410e-07] 
Layer 'conv4' biases: 9.999479e-01 [3.054462e-07] 
Layer 'conv5' weights[0]: 3.713281e-03 [3.560353e-06] 
Layer 'conv5' biases: 9.990747e-01 [3.733396e-06] 
Layer 'fc6' weights[0]: 6.986953e-03 [7.892720e-08] 
Layer 'fc6' biases: 9.999917e-01 [7.974357e-08] 
Layer 'fc7' weights[0]: 7.336671e-03 [1.967121e-07] 
Layer 'fc7' biases: 9.997863e-01 [3.524320e-07] 
Layer 'fc8' weights[0]: 4.691746e-03 [2.386583e-05] 
Layer 'fc8' biases: 1.687076e-02 [6.791204e-05] 
Train error last 800 batches: 0.656954
-------------------------------------------------------
Not saving because 0.464533 > 0.299667 (9.300: -1.18%)
======================================================= (2.337 sec)
21.1... logprob:  0.623819, 0.269531 (1.408 sec)
21.2... logprob:  0.634125, 0.287760 (1.456 sec)
21.3... logprob:  0.648564, 0.279948 (1.413 sec)
21.4... logprob:  0.678937, 0.311198 (1.400 sec)
21.5... logprob:  0.648949, 0.308594 (1.435 sec)
21.6... logprob:  0.720316, 0.283854 (1.390 sec)
21.7... logprob:  0.589618, 0.246094 (1.417 sec)
21.8... logprob:  0.686657, 0.325521 (1.393 sec)
21.9... logprob:  0.519036, 0.238281 (1.404 sec)
21.10... logprob:  0.558986, 0.248698 (1.408 sec)
21.11... logprob:  0.488990, 0.230469 (1.442 sec)
21.12... logprob:  0.642746, 0.276042 (1.394 sec)
21.13... logprob:  0.636284, 0.274740 (1.417 sec)
21.14... logprob:  0.663871, 0.283854 (1.398 sec)
21.15... logprob:  0.650329, 0.289062 (1.404 sec)
21.16... logprob:  0.614257, 0.291667 (1.402 sec)
21.17... logprob:  0.773463, 0.300781 (1.394 sec)
21.18... logprob:  0.544960, 0.250000 (1.397 sec)
21.19... logprob:  0.470622, 0.210937 (1.392 sec)
21.20... logprob:  0.661811, 0.289062 (1.400 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.509791, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.584650e-03 [1.794394e-07] 
Layer 'conv1' biases: 2.017976e-06 [1.546057e-10] 
Layer 'conv2' weights[0]: 3.577820e-03 [1.790658e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.429960e-09] 
Layer 'conv3' weights[0]: 3.576408e-03 [1.794527e-07] 
Layer 'conv3' biases: 3.339023e-05 [1.033452e-08] 
Layer 'conv4' weights[0]: 3.591451e-03 [1.805596e-07] 
Layer 'conv4' biases: 9.999444e-01 [2.233434e-07] 
Layer 'conv5' weights[0]: 3.707848e-03 [2.188284e-06] 
Layer 'conv5' biases: 9.990606e-01 [2.331111e-06] 
Layer 'fc6' weights[0]: 6.986227e-03 [5.773294e-08] 
Layer 'fc6' biases: 9.999917e-01 [5.162513e-08] 
Layer 'fc7' weights[0]: 7.335947e-03 [1.296776e-07] 
Layer 'fc7' biases: 9.997883e-01 [1.507898e-07] 
Layer 'fc8' weights[0]: 4.748169e-03 [1.202928e-05] 
Layer 'fc8' biases: 1.728876e-02 [1.615390e-05] 
Train error last 800 batches: 0.657110
-------------------------------------------------------
Not saving because 0.509791 > 0.299667 (9.300: -1.18%)
======================================================= (2.426 sec)
21.21... logprob:  0.647850, 0.281250 (1.411 sec)
21.22... logprob:  0.799200, 0.299479 (1.413 sec)
21.23... logprob:  0.677594, 0.283854 (1.414 sec)
21.24... logprob:  0.544340, 0.226562 (1.407 sec)
21.25... logprob:  0.637241, 0.270833 (1.396 sec)
21.26... logprob:  0.630918, 0.265625 (1.442 sec)
21.27... logprob:  0.706097, 0.300781 (1.388 sec)
21.28... logprob:  0.634049, 0.295573 (1.407 sec)
21.29... logprob:  0.548601, 0.257812 (1.427 sec)
21.30... logprob:  0.613399, 0.300781 (1.414 sec)
21.31... logprob:  0.657164, 0.285156 (1.395 sec)
21.32... logprob:  0.668555, 0.291667 (1.383 sec)
21.33... logprob:  0.626812, 0.294271 (1.439 sec)
21.34... logprob:  0.628751, 0.279948 (1.385 sec)
21.35... logprob:  0.578512, 0.261719 (1.394 sec)
21.36... logprob:  0.658383, 0.281250 (1.394 sec)
21.37... logprob:  0.717816, 0.303385 (1.403 sec)
21.38... logprob:  0.567644, 0.257812 (1.390 sec)
21.39... logprob:  0.751544, 0.319010 (1.428 sec)
21.40... logprob:  0.609797, 0.277344 (1.405 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.390071, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.581084e-03 [1.791314e-07] 
Layer 'conv1' biases: 2.018416e-06 [1.879727e-10] 
Layer 'conv2' weights[0]: 3.574201e-03 [1.788112e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.606917e-09] 
Layer 'conv3' weights[0]: 3.572821e-03 [1.794325e-07] 
Layer 'conv3' biases: 3.341249e-05 [1.213430e-08] 
Layer 'conv4' weights[0]: 3.587876e-03 [1.808117e-07] 
Layer 'conv4' biases: 9.999422e-01 [2.714143e-07] 
Layer 'conv5' weights[0]: 3.702963e-03 [2.694436e-06] 
Layer 'conv5' biases: 9.990868e-01 [2.882224e-06] 
Layer 'fc6' weights[0]: 6.985511e-03 [6.751358e-08] 
Layer 'fc6' biases: 9.999918e-01 [6.469844e-08] 
Layer 'fc7' weights[0]: 7.335215e-03 [1.601500e-07] 
Layer 'fc7' biases: 9.997864e-01 [2.452493e-07] 
Layer 'fc8' weights[0]: 4.699948e-03 [1.949181e-05] 
Layer 'fc8' biases: 1.689306e-02 [4.925324e-05] 
Train error last 800 batches: 0.656367
-------------------------------------------------------
Not saving because 0.390071 > 0.299667 (9.300: -1.18%)
======================================================= (2.350 sec)
21.41... logprob:  0.609181, 0.279948 (1.425 sec)
21.42... logprob:  0.617452, 0.292969 (1.416 sec)
21.43... logprob:  0.619649, 0.255208 (1.407 sec)
21.44... logprob:  0.671177, 0.276042 (1.443 sec)
21.45... logprob:  0.599130, 0.246094 (1.386 sec)
21.46... logprob:  0.689216, 0.298177 (1.396 sec)
21.47... logprob:  0.678143, 0.320312 (1.390 sec)
21.48... logprob:  0.668377, 0.309896 (1.424 sec)
21.49... logprob:  0.712494, 0.312500 (1.407 sec)
21.50... logprob:  0.582165, 0.282552 (1.421 sec)
21.51... logprob:  0.730222, 0.329427 (1.418 sec)
21.52... logprob:  0.722693, 0.311198 (1.393 sec)
21.53... logprob:  0.591500, 0.247396 (1.433 sec)
21.54... logprob:  0.573671, 0.234375 (1.385 sec)
21.55... logprob:  0.545501, 0.233073 (1.391 sec)
21.56... logprob:  0.661724, 0.298177 (1.397 sec)
21.57... logprob:  0.733103, 0.337240 (1.430 sec)
21.58... logprob:  0.688447, 0.312500 (1.403 sec)
21.59... logprob:  0.583604, 0.253906 (1.455 sec)
21.60... logprob:  0.910253, 0.384115 (1.416 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.503962, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.577500e-03 [1.789384e-07] 
Layer 'conv1' biases: 2.019681e-06 [1.904581e-10] 
Layer 'conv2' weights[0]: 3.570664e-03 [1.786492e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.938451e-09] 
Layer 'conv3' weights[0]: 3.569289e-03 [1.793931e-07] 
Layer 'conv3' biases: 3.340574e-05 [1.254418e-08] 
Layer 'conv4' weights[0]: 3.584297e-03 [1.808786e-07] 
Layer 'conv4' biases: 9.999411e-01 [2.964838e-07] 
Layer 'conv5' weights[0]: 3.699226e-03 [2.664367e-06] 
Layer 'conv5' biases: 9.990914e-01 [2.780696e-06] 
Layer 'fc6' weights[0]: 6.984793e-03 [6.560934e-08] 
Layer 'fc6' biases: 9.999918e-01 [6.208511e-08] 
Layer 'fc7' weights[0]: 7.334481e-03 [1.509506e-07] 
Layer 'fc7' biases: 9.997860e-01 [2.036087e-07] 
Layer 'fc8' weights[0]: 4.671862e-03 [1.504970e-05] 
Layer 'fc8' biases: 1.668707e-02 [2.249041e-05] 
Train error last 800 batches: 0.656048
-------------------------------------------------------
Not saving because 0.503962 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
21.61... logprob:  0.601967, 0.253906 (1.437 sec)
21.62... logprob:  0.745697, 0.330729 (1.453 sec)
21.63... logprob:  0.638632, 0.291667 (1.433 sec)
21.64... logprob:  0.647200, 0.299479 (1.406 sec)
21.65... logprob:  0.508969, 0.222656 (1.401 sec)
21.66... logprob:  0.554843, 0.259115 (1.456 sec)
21.67... logprob:  0.519966, 0.238281 (1.387 sec)
21.68... logprob:  0.628787, 0.270833 (1.392 sec)
21.69... logprob:  0.750744, 0.343750 (1.420 sec)
21.70... logprob:  0.491500, 0.209635 (1.421 sec)
21.71... logprob:  0.601364, 0.281250 (1.455 sec)
21.72... logprob:  0.763066, 0.304687 (1.399 sec)
21.73... logprob:  0.657816, 0.305990 (1.416 sec)
21.74... logprob:  0.674422, 0.290365 (1.409 sec)
21.75... logprob:  0.580347, 0.251302 (1.408 sec)
21.76... logprob:  0.670824, 0.308594 (1.431 sec)
21.77... logprob:  0.686225, 0.286458 (1.420 sec)
21.78... logprob:  0.674205, 0.295573 (1.449 sec)
21.79... logprob:  0.668535, 0.303385 (1.394 sec)
21.80... logprob:  0.733597, 0.312500 (1.416 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.458540, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.573918e-03 [1.788889e-07] 
Layer 'conv1' biases: 2.020397e-06 [1.777905e-10] 
Layer 'conv2' weights[0]: 3.567086e-03 [1.785609e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.816783e-09] 
Layer 'conv3' weights[0]: 3.565701e-03 [1.791269e-07] 
Layer 'conv3' biases: 3.341802e-05 [1.211169e-08] 
Layer 'conv4' weights[0]: 3.580711e-03 [1.798906e-07] 
Layer 'conv4' biases: 9.999403e-01 [2.320274e-07] 
Layer 'conv5' weights[0]: 3.695447e-03 [2.479872e-06] 
Layer 'conv5' biases: 9.990816e-01 [2.649293e-06] 
Layer 'fc6' weights[0]: 6.984097e-03 [6.273844e-08] 
Layer 'fc6' biases: 9.999917e-01 [5.852919e-08] 
Layer 'fc7' weights[0]: 7.333717e-03 [1.439987e-07] 
Layer 'fc7' biases: 9.997858e-01 [1.804463e-07] 
Layer 'fc8' weights[0]: 4.695499e-03 [1.334697e-05] 
Layer 'fc8' biases: 1.684184e-02 [1.741027e-05] 
Train error last 800 batches: 0.656348
-------------------------------------------------------
Not saving because 0.458540 > 0.299667 (9.300: -1.18%)
======================================================= (2.401 sec)
21.81... logprob:  0.635913, 0.276042 (1.417 sec)
21.82... logprob:  0.586566, 0.291667 (1.422 sec)
21.83... logprob:  0.753434, 0.343750 (1.403 sec)
21.84... logprob:  0.639036, 0.298177 (1.462 sec)
21.85... logprob:  0.649108, 0.273437 (1.416 sec)
21.86... logprob:  0.708164, 0.312500 (1.414 sec)
21.87... logprob:  0.890442, 0.371094 (1.416 sec)
21.88... logprob:  0.752153, 0.295573 (1.408 sec)
21.89... logprob:  0.649962, 0.295573 (1.428 sec)
21.90... logprob:  0.713815, 0.304687 (1.388 sec)
21.91... logprob:  0.617364, 0.270833 (1.392 sec)
21.92... logprob:  0.732148, 0.328125 (1.392 sec)
21.93... logprob:  0.717392, 0.316406 (1.393 sec)
21.94... logprob:  0.698014, 0.304687 (1.391 sec)
21.95... logprob:  0.722564, 0.325521 (1.400 sec)
21.96... logprob:  0.770051, 0.341146 (1.397 sec)
21.97... logprob:  0.712997, 0.303385 (1.385 sec)
21.98... logprob:  0.611301, 0.277344 (1.432 sec)
21.99... logprob:  0.760467, 0.325521 (1.396 sec)
21.100... logprob:  0.577847, 0.264323 (1.401 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.559010, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.570348e-03 [1.786585e-07] 
Layer 'conv1' biases: 2.021154e-06 [1.711156e-10] 
Layer 'conv2' weights[0]: 3.563512e-03 [1.783335e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.990730e-09] 
Layer 'conv3' weights[0]: 3.562149e-03 [1.790619e-07] 
Layer 'conv3' biases: 3.345062e-05 [1.409282e-08] 
Layer 'conv4' weights[0]: 3.577142e-03 [1.801783e-07] 
Layer 'conv4' biases: 9.999393e-01 [3.009321e-07] 
Layer 'conv5' weights[0]: 3.691627e-03 [2.807833e-06] 
Layer 'conv5' biases: 9.991159e-01 [2.983273e-06] 
Layer 'fc6' weights[0]: 6.983326e-03 [6.430300e-08] 
Layer 'fc6' biases: 9.999919e-01 [6.016447e-08] 
Layer 'fc7' weights[0]: 7.332967e-03 [1.469717e-07] 
Layer 'fc7' biases: 9.997832e-01 [1.938058e-07] 
Layer 'fc8' weights[0]: 4.602479e-03 [1.384518e-05] 
Layer 'fc8' biases: 1.613561e-02 [2.132333e-05] 
Train error last 800 batches: 0.657419
-------------------------------------------------------
Not saving because 0.559010 > 0.299667 (9.300: -1.18%)
======================================================= (2.368 sec)
21.101... logprob:  0.617262, 0.285156 (1.452 sec)
21.102... logprob:  0.766194, 0.350260 (1.388 sec)
21.103... logprob:  0.735053, 0.317708 (1.401 sec)
21.104... logprob:  0.632103, 0.289062 (1.394 sec)
21.105... logprob:  0.752345, 0.325521 (1.386 sec)
21.106... logprob:  0.569299, 0.263021 (1.388 sec)
21.107... logprob:  0.620889, 0.274740 (1.439 sec)
21.108... logprob:  0.660036, 0.294271 (1.392 sec)
21.109... logprob:  0.570782, 0.257812 (1.402 sec)
21.110... logprob:  0.713612, 0.303385 (1.395 sec)
21.111... logprob:  0.677851, 0.287760 (1.389 sec)
21.112... logprob:  0.594998, 0.263021 (1.394 sec)
21.113... logprob:  0.579940, 0.269531 (1.398 sec)
21.114... logprob:  0.703374, 0.312500 (1.429 sec)
21.115... logprob:  0.717795, 0.309896 (1.411 sec)
21.116... logprob:  0.625699, 0.291667 (1.401 sec)
21.117... logprob:  0.665156, 0.311198 (1.465 sec)
21.118... logprob:  0.634847, 0.286458 (1.396 sec)
21.119... logprob:  0.585268, 0.255208 (1.404 sec)
21.120... logprob:  0.765468, 0.346354 (1.405 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.422408, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.566779e-03 [1.785012e-07] 
Layer 'conv1' biases: 2.021140e-06 [1.377433e-10] 
Layer 'conv2' weights[0]: 3.559956e-03 [1.781369e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.623544e-09] 
Layer 'conv3' weights[0]: 3.558572e-03 [1.786341e-07] 
Layer 'conv3' biases: 3.341958e-05 [1.085546e-08] 
Layer 'conv4' weights[0]: 3.573531e-03 [1.798525e-07] 
Layer 'conv4' biases: 9.999406e-01 [2.461528e-07] 
Layer 'conv5' weights[0]: 3.688928e-03 [2.518796e-06] 
Layer 'conv5' biases: 9.990908e-01 [2.786824e-06] 
Layer 'fc6' weights[0]: 6.982622e-03 [6.221836e-08] 
Layer 'fc6' biases: 9.999919e-01 [5.710564e-08] 
Layer 'fc7' weights[0]: 7.332260e-03 [1.416080e-07] 
Layer 'fc7' biases: 9.997846e-01 [1.842349e-07] 
Layer 'fc8' weights[0]: 4.665943e-03 [1.407205e-05] 
Layer 'fc8' biases: 1.668992e-02 [2.696481e-05] 
Train error last 800 batches: 0.656875
-------------------------------------------------------
Not saving because 0.422408 > 0.299667 (9.300: -1.18%)
======================================================= (2.367 sec)
21.121... logprob:  0.562464, 0.209635 (1.410 sec)
21.122... logprob:  0.780713, 0.312500 (1.447 sec)
21.123... logprob:  0.667113, 0.272135 (1.384 sec)
21.124... logprob:  0.701321, 0.287760 (1.410 sec)
21.125... logprob:  0.799928, 0.317708 (1.401 sec)
21.126... logprob:  0.734501, 0.341146 (1.387 sec)
21.127... logprob:  0.709559, 0.300781 (1.404 sec)
21.128... logprob:  0.653517, 0.302083 (1.420 sec)
21.129... logprob:  0.750315, 0.304688 (1.423 sec)
21.130... logprob:  0.610426, 0.289062 (1.414 sec)
21.131... logprob:  0.681552, 0.263021 (1.402 sec)
21.132... logprob:  0.697629, 0.269531 (1.440 sec)
21.133... logprob:  0.642830, 0.273438 (1.398 sec)
21.134... logprob:  0.588085, 0.264323 (1.394 sec)
21.135... logprob:  0.584918, 0.236979 (1.399 sec)
21.136... logprob:  0.701203, 0.291667 (1.410 sec)
21.137... logprob:  0.647103, 0.279948 (1.395 sec)
21.138... logprob:  0.595505, 0.289062 (1.458 sec)
21.139... logprob:  0.661562, 0.278646 (1.406 sec)
21.140... logprob:  0.746348, 0.319010 (1.419 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.397560, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.563217e-03 [1.784105e-07] 
Layer 'conv1' biases: 2.021691e-06 [1.670965e-10] 
Layer 'conv2' weights[0]: 3.556396e-03 [1.779465e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.436380e-09] 
Layer 'conv3' weights[0]: 3.555031e-03 [1.783727e-07] 
Layer 'conv3' biases: 3.342138e-05 [9.673828e-09] 
Layer 'conv4' weights[0]: 3.569974e-03 [1.795143e-07] 
Layer 'conv4' biases: 9.999422e-01 [2.117381e-07] 
Layer 'conv5' weights[0]: 3.686660e-03 [2.438095e-06] 
Layer 'conv5' biases: 9.991192e-01 [2.731050e-06] 
Layer 'fc6' weights[0]: 6.981923e-03 [6.262796e-08] 
Layer 'fc6' biases: 9.999918e-01 [5.738335e-08] 
Layer 'fc7' weights[0]: 7.331527e-03 [1.406776e-07] 
Layer 'fc7' biases: 9.997825e-01 [1.639470e-07] 
Layer 'fc8' weights[0]: 4.599124e-03 [1.344327e-05] 
Layer 'fc8' biases: 1.618270e-02 [1.778111e-05] 
Train error last 800 batches: 0.656541
-------------------------------------------------------
Not saving because 0.397560 > 0.299667 (9.300: -1.18%)
======================================================= (2.390 sec)
21.141... logprob:  0.665606, 0.298177 (1.457 sec)
21.142... logprob:  0.636370, 0.252604 (1.413 sec)
21.143... logprob:  0.604903, 0.289062 (1.435 sec)
21.144... logprob:  0.722266, 0.305990 (1.425 sec)
21.145... logprob:  0.566206, 0.255208 (1.427 sec)
21.146... logprob:  0.730350, 0.298177 (1.412 sec)
21.147... logprob:  0.514605, 0.242187 (1.437 sec)
21.148... logprob:  0.669068, 0.290365 (1.390 sec)
21.149... logprob:  0.705100, 0.319010 (1.410 sec)
21.150... logprob:  0.594036, 0.272135 (1.406 sec)
21.151... logprob:  0.569616, 0.279948 (1.393 sec)
21.152... logprob:  0.868818, 0.364583 (1.399 sec)
21.153... logprob:  0.632821, 0.292969 (1.443 sec)
21.154... logprob:  0.714969, 0.326823 (1.394 sec)
21.155... logprob:  0.624006, 0.266927 (1.414 sec)
21.156... logprob:  0.515553, 0.209635 (1.437 sec)
21.157... logprob:  0.518892, 0.233073 (1.393 sec)
21.158... logprob:  0.650900, 0.290365 (1.405 sec)
21.159... logprob:  0.623187, 0.273437 (1.398 sec)
21.160... logprob:  0.617617, 0.276042 (1.388 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.466947, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.559652e-03 [1.783358e-07] 
Layer 'conv1' biases: 2.023428e-06 [2.055602e-10] 
Layer 'conv2' weights[0]: 3.552858e-03 [1.778819e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.202531e-09] 
Layer 'conv3' weights[0]: 3.551458e-03 [1.786724e-07] 
Layer 'conv3' biases: 3.341983e-05 [1.393630e-08] 
Layer 'conv4' weights[0]: 3.566415e-03 [1.803985e-07] 
Layer 'conv4' biases: 9.999391e-01 [3.079586e-07] 
Layer 'conv5' weights[0]: 3.681735e-03 [3.513961e-06] 
Layer 'conv5' biases: 9.990911e-01 [3.719958e-06] 
Layer 'fc6' weights[0]: 6.981210e-03 [7.180662e-08] 
Layer 'fc6' biases: 9.999919e-01 [6.966427e-08] 
Layer 'fc7' weights[0]: 7.330761e-03 [1.696116e-07] 
Layer 'fc7' biases: 9.997849e-01 [2.772884e-07] 
Layer 'fc8' weights[0]: 4.672922e-03 [1.921604e-05] 
Layer 'fc8' biases: 1.673974e-02 [4.715559e-05] 
Train error last 800 batches: 0.656331
-------------------------------------------------------
Not saving because 0.466947 > 0.299667 (9.300: -1.18%)
======================================================= (2.343 sec)
21.161... logprob:  0.571367, 0.286458 (1.407 sec)
21.162... logprob:  0.834393, 0.342448 (1.405 sec)
21.163... logprob:  0.652585, 0.277344 (1.418 sec)
21.164... logprob:  0.658542, 0.278646 (1.419 sec)
21.165... logprob:  0.688264, 0.313802 (1.412 sec)
21.166... logprob:  0.684802, 0.304687 (1.443 sec)
21.167... logprob:  0.613587, 0.300781 (1.424 sec)
21.168... logprob:  0.593780, 0.261719 (1.415 sec)
21.169... logprob:  0.644809, 0.282552 (1.456 sec)
21.170... logprob:  0.683985, 0.298177 (1.401 sec)
21.171... logprob:  0.709509, 0.305990 (1.417 sec)
21.172... logprob:  0.645543, 0.276042 (1.413 sec)
21.173... logprob:  0.632812, 0.266927 (1.418 sec)
21.174... logprob:  0.823560, 0.308594 (1.390 sec)
21.175... logprob:  0.686459, 0.285156 (1.465 sec)
21.176... logprob:  0.700243, 0.295573 (1.409 sec)
21.177... logprob:  0.538823, 0.248698 (1.419 sec)
21.178... logprob:  0.654120, 0.305990 (1.452 sec)
21.179... logprob:  0.541476, 0.233073 (1.402 sec)
21.180... logprob:  0.604170, 0.257812 (1.422 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.492664, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.556092e-03 [1.780087e-07] 
Layer 'conv1' biases: 2.023704e-06 [1.219067e-10] 
Layer 'conv2' weights[0]: 3.549292e-03 [1.776498e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.414168e-09] 
Layer 'conv3' weights[0]: 3.547916e-03 [1.781086e-07] 
Layer 'conv3' biases: 3.341625e-05 [1.111375e-08] 
Layer 'conv4' weights[0]: 3.562836e-03 [1.795691e-07] 
Layer 'conv4' biases: 9.999385e-01 [2.529703e-07] 
Layer 'conv5' weights[0]: 3.678044e-03 [2.813673e-06] 
Layer 'conv5' biases: 9.990896e-01 [3.004901e-06] 
Layer 'fc6' weights[0]: 6.980492e-03 [6.184889e-08] 
Layer 'fc6' biases: 9.999919e-01 [5.701182e-08] 
Layer 'fc7' weights[0]: 7.330025e-03 [1.428493e-07] 
Layer 'fc7' biases: 9.997848e-01 [1.907833e-07] 
Layer 'fc8' weights[0]: 4.668211e-03 [1.509638e-05] 
Layer 'fc8' biases: 1.675478e-02 [3.482446e-05] 
Train error last 800 batches: 0.656254
-------------------------------------------------------
Not saving because 0.492664 > 0.299667 (9.300: -1.18%)
======================================================= (2.376 sec)
21.181... logprob:  0.783499, 0.332031 (1.424 sec)
21.182... logprob:  0.572410, 0.268229 (1.417 sec)
21.183... logprob:  0.652076, 0.286458 (1.411 sec)
21.184... logprob:  0.706687, 0.283854 (1.413 sec)
21.185... logprob:  0.547409, 0.235677 (1.391 sec)
21.186... logprob:  0.627801, 0.283854 (1.389 sec)
21.187... logprob:  0.716245, 0.325521 (1.399 sec)
21.188... logprob:  0.695839, 0.320312 (1.394 sec)
21.189... logprob:  0.620626, 0.255208 (1.380 sec)
21.190... logprob:  0.624763, 0.259114 (1.432 sec)
21.191... logprob:  0.718646, 0.305990 (1.402 sec)
21.192... logprob:  0.643137, 0.277344 (1.416 sec)
21.193... logprob:  0.557436, 0.251302 (1.415 sec)
21.194... logprob:  0.627075, 0.286458 (1.416 sec)
21.195... logprob:  0.484390, 0.234375 (1.400 sec)
21.196... logprob:  0.650737, 0.302083 (1.384 sec)
21.197... logprob:  0.708735, 0.309896 (1.400 sec)
21.198... logprob:  0.626313, 0.294271 (1.396 sec)
21.199... logprob:  0.621439, 0.283854 (1.381 sec)
21.200... logprob:  0.646747, 0.289062 (1.435 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.551624, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.552552e-03 [1.780759e-07] 
Layer 'conv1' biases: 2.024247e-06 [1.390641e-10] 
Layer 'conv2' weights[0]: 3.545738e-03 [1.776308e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.418997e-09] 
Layer 'conv3' weights[0]: 3.544389e-03 [1.777830e-07] 
Layer 'conv3' biases: 3.339849e-05 [9.826751e-09] 
Layer 'conv4' weights[0]: 3.559287e-03 [1.790124e-07] 
Layer 'conv4' biases: 9.999406e-01 [2.105019e-07] 
Layer 'conv5' weights[0]: 3.675940e-03 [2.696846e-06] 
Layer 'conv5' biases: 9.990802e-01 [2.908198e-06] 
Layer 'fc6' weights[0]: 6.979776e-03 [6.532563e-08] 
Layer 'fc6' biases: 9.999919e-01 [6.147694e-08] 
Layer 'fc7' weights[0]: 7.329298e-03 [1.543312e-07] 
Layer 'fc7' biases: 9.997853e-01 [2.353165e-07] 
Layer 'fc8' weights[0]: 4.691297e-03 [1.604687e-05] 
Layer 'fc8' biases: 1.690335e-02 [3.493038e-05] 
Train error last 800 batches: 0.655804
-------------------------------------------------------
Not saving because 0.551624 > 0.299667 (9.300: -1.18%)
======================================================= (2.411 sec)
21.201... logprob:  0.627480, 0.278646 (1.408 sec)
21.202... logprob:  0.722509, 0.308594 (1.404 sec)
21.203... logprob:  0.673083, 0.313802 (1.440 sec)
21.204... logprob:  0.745662, 0.302083 (1.400 sec)
21.205... logprob:  0.621785, 0.283854 (1.399 sec)
21.206... logprob:  0.582387, 0.261719 (1.396 sec)
21.207... logprob:  0.604097, 0.278646 (1.388 sec)
21.208... logprob:  0.690580, 0.325521 (1.394 sec)
21.209... logprob:  0.550503, 0.248698 (1.414 sec)
21.210... logprob:  0.711575, 0.321615 (1.411 sec)
21.211... logprob:  0.694622, 0.299479 (1.415 sec)
21.212... logprob:  0.724270, 0.311198 (1.410 sec)
21.213... logprob:  0.612125, 0.253906 (1.452 sec)
21.214... logprob:  0.653597, 0.285156 (1.418 sec)
21.215... logprob:  0.516312, 0.251302 (1.410 sec)
21.216... logprob:  0.687147, 0.299479 (1.462 sec)
21.217... logprob:  0.507354, 0.221354 (1.392 sec)
21.218... logprob:  0.633660, 0.263021 (1.416 sec)
21.219... logprob:  0.794678, 0.354167 (1.411 sec)
21.220... logprob:  0.532675, 0.236979 (1.417 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.430823, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.548987e-03 [1.774572e-07] 
Layer 'conv1' biases: 2.024590e-06 [1.263979e-10] 
Layer 'conv2' weights[0]: 3.542188e-03 [1.771575e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.343966e-09] 
Layer 'conv3' weights[0]: 3.540825e-03 [1.774966e-07] 
Layer 'conv3' biases: 3.338517e-05 [9.221557e-09] 
Layer 'conv4' weights[0]: 3.555731e-03 [1.784743e-07] 
Layer 'conv4' biases: 9.999394e-01 [1.951635e-07] 
Layer 'conv5' weights[0]: 3.671698e-03 [2.429959e-06] 
Layer 'conv5' biases: 9.990875e-01 [2.575762e-06] 
Layer 'fc6' weights[0]: 6.979055e-03 [6.033240e-08] 
Layer 'fc6' biases: 9.999918e-01 [5.498861e-08] 
Layer 'fc7' weights[0]: 7.328581e-03 [1.375476e-07] 
Layer 'fc7' biases: 9.997843e-01 [1.747388e-07] 
Layer 'fc8' weights[0]: 4.686871e-03 [1.324551e-05] 
Layer 'fc8' biases: 1.682055e-02 [2.125164e-05] 
Train error last 800 batches: 0.655378
-------------------------------------------------------
Not saving because 0.430823 > 0.299667 (9.300: -1.18%)
======================================================= (2.376 sec)
21.221... logprob:  0.517783, 0.218750 (1.411 sec)
21.222... logprob:  0.739975, 0.321615 (1.458 sec)
21.223... logprob:  0.782548, 0.295573 (1.434 sec)
21.224... logprob:  0.581245, 0.244792 (1.423 sec)
21.225... logprob:  0.580975, 0.253906 (1.442 sec)
21.226... logprob:  0.626749, 0.265625 (1.418 sec)
21.227... logprob:  0.691989, 0.328125 (1.424 sec)
21.228... logprob:  0.688480, 0.292969 (1.417 sec)
21.229... logprob:  0.656048, 0.292969 (1.408 sec)
21.230... logprob:  0.764078, 0.316406 (1.426 sec)
21.231... logprob:  0.710424, 0.287760 (1.408 sec)
21.232... logprob:  0.672466, 0.294271 (1.458 sec)
21.233... logprob:  0.665537, 0.290365 (1.419 sec)
21.234... logprob:  0.751297, 0.342448 (1.416 sec)
21.235... logprob:  0.689151, 0.292969 (1.462 sec)
21.236... logprob:  0.656682, 0.295573 (1.395 sec)
21.237... logprob:  0.540887, 0.265625 (1.417 sec)
21.238... logprob:  0.593324, 0.235677 (1.415 sec)
21.239... logprob:  0.650048, 0.300781 (1.412 sec)
21.240... logprob:  0.706195, 0.304688 (1.394 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.523731, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.545450e-03 [1.774799e-07] 
Layer 'conv1' biases: 2.024800e-06 [1.392289e-10] 
Layer 'conv2' weights[0]: 3.538678e-03 [1.771059e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.378981e-09] 
Layer 'conv3' weights[0]: 3.537301e-03 [1.773847e-07] 
Layer 'conv3' biases: 3.341157e-05 [1.006439e-08] 
Layer 'conv4' weights[0]: 3.552162e-03 [1.784159e-07] 
Layer 'conv4' biases: 9.999394e-01 [2.017500e-07] 
Layer 'conv5' weights[0]: 3.668217e-03 [2.271879e-06] 
Layer 'conv5' biases: 9.991124e-01 [2.443315e-06] 
Layer 'fc6' weights[0]: 6.978321e-03 [6.103258e-08] 
Layer 'fc6' biases: 9.999919e-01 [5.544505e-08] 
Layer 'fc7' weights[0]: 7.327880e-03 [1.385764e-07] 
Layer 'fc7' biases: 9.997827e-01 [1.633954e-07] 
Layer 'fc8' weights[0]: 4.625293e-03 [1.266848e-05] 
Layer 'fc8' biases: 1.634236e-02 [1.027803e-05] 
Train error last 800 batches: 0.655028
-------------------------------------------------------
Not saving because 0.523731 > 0.299667 (9.300: -1.18%)
======================================================= (2.378 sec)
21.241... logprob:  0.692324, 0.278646 (1.459 sec)
21.242... logprob:  0.551589, 0.250000 (1.429 sec)
21.243... logprob:  0.609615, 0.252604 (1.430 sec)
21.244... logprob:  0.588219, 0.240885 (1.439 sec)
21.245... logprob:  0.708894, 0.303385 (1.417 sec)
21.246... logprob:  0.684761, 0.295573 (1.410 sec)
21.247... logprob:  0.587822, 0.253906 (1.411 sec)
21.248... logprob:  0.544105, 0.244792 (1.420 sec)
21.249... logprob:  0.690031, 0.313802 (1.419 sec)
21.250... logprob:  0.825873, 0.339844 (1.408 sec)
21.251... logprob:  0.555498, 0.255208 (1.451 sec)
21.252... logprob:  0.633401, 0.289062 (1.419 sec)
21.253... logprob:  0.636622, 0.270833 (1.410 sec)
21.254... logprob:  0.671726, 0.292969 (1.461 sec)
21.255... logprob:  0.571969, 0.253906 (1.403 sec)
21.256... logprob:  0.616885, 0.246094 (1.415 sec)
21.257... logprob:  0.549631, 0.260417 (1.410 sec)
21.258... logprob:  0.624316, 0.260417 (1.416 sec)
21.259... logprob:  0.678998, 0.291667 (1.394 sec)
21.260... logprob:  0.511932, 0.231771 (1.453 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.485068, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.541906e-03 [1.773086e-07] 
Layer 'conv1' biases: 2.025121e-06 [1.726285e-10] 
Layer 'conv2' weights[0]: 3.535121e-03 [1.770462e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.689916e-09] 
Layer 'conv3' weights[0]: 3.533737e-03 [1.775200e-07] 
Layer 'conv3' biases: 3.343929e-05 [1.239852e-08] 
Layer 'conv4' weights[0]: 3.548619e-03 [1.790788e-07] 
Layer 'conv4' biases: 9.999396e-01 [2.789790e-07] 
Layer 'conv5' weights[0]: 3.664842e-03 [2.858850e-06] 
Layer 'conv5' biases: 9.990835e-01 [3.097736e-06] 
Layer 'fc6' weights[0]: 6.977624e-03 [6.622059e-08] 
Layer 'fc6' biases: 9.999918e-01 [6.277205e-08] 
Layer 'fc7' weights[0]: 7.327162e-03 [1.523376e-07] 
Layer 'fc7' biases: 9.997844e-01 [2.253996e-07] 
Layer 'fc8' weights[0]: 4.681138e-03 [1.630371e-05] 
Layer 'fc8' biases: 1.681029e-02 [3.850650e-05] 
Train error last 800 batches: 0.655104
-------------------------------------------------------
Not saving because 0.485068 > 0.299667 (9.300: -1.18%)
======================================================= (2.404 sec)
21.261... logprob:  0.599069, 0.272135 (1.433 sec)
21.262... logprob:  0.707727, 0.307292 (1.427 sec)
21.263... logprob:  0.618572, 0.279948 (1.445 sec)
21.264... logprob:  0.554910, 0.233073 (1.418 sec)
21.265... logprob:  0.636724, 0.278646 (1.408 sec)
21.266... logprob:  0.773857, 0.342448 (1.409 sec)
21.267... logprob:  0.648346, 0.276042 (1.407 sec)
21.268... logprob:  0.782041, 0.312500 (1.417 sec)
21.269... logprob:  0.820603, 0.325521 (1.400 sec)
21.270... logprob:  0.742828, 0.296875 (1.451 sec)
21.271... logprob:  0.669485, 0.307292 (1.416 sec)
21.272... logprob:  0.568090, 0.259115 (1.413 sec)
21.273... logprob:  0.681276, 0.282552 (1.460 sec)
21.274... logprob:  0.829813, 0.342448 (1.395 sec)
21.275... logprob:  0.684000, 0.320312 (1.418 sec)
21.276... logprob:  0.526631, 0.230469 (1.409 sec)
21.277... logprob:  0.679139, 0.304687 (1.422 sec)
21.278... logprob:  0.625112, 0.253906 (1.441 sec)
21.279... logprob:  0.457174, 0.199219 (1.453 sec)
21.280... logprob:  0.551064, 0.263021 (1.400 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.521292, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.538368e-03 [1.773918e-07] 
Layer 'conv1' biases: 2.024618e-06 [1.994110e-10] 
Layer 'conv2' weights[0]: 3.531604e-03 [1.769296e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.127593e-09] 
Layer 'conv3' weights[0]: 3.530210e-03 [1.774496e-07] 
Layer 'conv3' biases: 3.347436e-05 [1.256585e-08] 
Layer 'conv4' weights[0]: 3.545047e-03 [1.790271e-07] 
Layer 'conv4' biases: 9.999409e-01 [2.819639e-07] 
Layer 'conv5' weights[0]: 3.662967e-03 [2.688706e-06] 
Layer 'conv5' biases: 9.990956e-01 [2.915880e-06] 
Layer 'fc6' weights[0]: 6.976899e-03 [6.537898e-08] 
Layer 'fc6' biases: 9.999920e-01 [6.150271e-08] 
Layer 'fc7' weights[0]: 7.326430e-03 [1.521642e-07] 
Layer 'fc7' biases: 9.997834e-01 [2.314529e-07] 
Layer 'fc8' weights[0]: 4.654732e-03 [1.583718e-05] 
Layer 'fc8' biases: 1.657881e-02 [3.656117e-05] 
Train error last 800 batches: 0.655680
-------------------------------------------------------
Not saving because 0.521292 > 0.299667 (9.300: -1.18%)
======================================================= (2.354 sec)
21.281... logprob:  0.674762, 0.273437 (1.425 sec)
21.282... logprob:  0.618121, 0.263021 (1.416 sec)
21.283... logprob:  0.643403, 0.296875 (1.413 sec)
21.284... logprob:  0.665008, 0.273437 (1.409 sec)
21.285... logprob:  0.679127, 0.311198 (1.440 sec)
21.286... logprob:  0.770248, 0.311198 (1.430 sec)
21.287... logprob:  0.625795, 0.285156 (1.424 sec)
21.288... logprob:  0.567252, 0.260417 (1.431 sec)
21.289... logprob:  0.659524, 0.282552 (1.433 sec)
21.290... logprob:  0.616168, 0.279948 (1.412 sec)
21.291... logprob:  0.704250, 0.324219 (1.420 sec)
21.292... logprob:  0.692507, 0.289062 (1.417 sec)
21.293... logprob:  0.682265, 0.308594 (1.414 sec)
21.294... logprob:  0.559375, 0.236979 (1.398 sec)
21.295... logprob:  0.686252, 0.305990 (1.458 sec)
21.296... logprob:  0.607631, 0.278646 (1.416 sec)
21.297... logprob:  0.756979, 0.329427 (1.420 sec)
21.298... logprob:  0.636196, 0.287760 (1.455 sec)
21.299... logprob:  0.559939, 0.272135 (1.395 sec)
21.300... logprob:  0.649938, 0.276042 (1.418 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.505050, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.534821e-03 [1.769199e-07] 
Layer 'conv1' biases: 2.024583e-06 [1.720004e-10] 
Layer 'conv2' weights[0]: 3.528066e-03 [1.766102e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.493492e-09] 
Layer 'conv3' weights[0]: 3.526703e-03 [1.769394e-07] 
Layer 'conv3' biases: 3.347246e-05 [9.974138e-09] 
Layer 'conv4' weights[0]: 3.541536e-03 [1.780653e-07] 
Layer 'conv4' biases: 9.999414e-01 [1.882567e-07] 
Layer 'conv5' weights[0]: 3.660122e-03 [2.460203e-06] 
Layer 'conv5' biases: 9.990836e-01 [2.623909e-06] 
Layer 'fc6' weights[0]: 6.976184e-03 [6.003718e-08] 
Layer 'fc6' biases: 9.999920e-01 [5.462701e-08] 
Layer 'fc7' weights[0]: 7.325711e-03 [1.393782e-07] 
Layer 'fc7' biases: 9.997837e-01 [1.836250e-07] 
Layer 'fc8' weights[0]: 4.686479e-03 [1.370971e-05] 
Layer 'fc8' biases: 1.680194e-02 [1.682100e-05] 
Train error last 800 batches: 0.656198
-------------------------------------------------------
Not saving because 0.505050 > 0.299667 (9.300: -1.18%)
======================================================= (2.384 sec)
21.301... logprob:  0.649524, 0.315104 (1.420 sec)
21.302... logprob:  0.716571, 0.332031 (1.421 sec)
21.303... logprob:  0.730310, 0.311198 (1.404 sec)
21.304... logprob:  0.739306, 0.308594 (1.433 sec)
21.305... logprob:  0.629421, 0.269531 (1.431 sec)
21.306... logprob:  0.591239, 0.242187 (1.428 sec)
21.307... logprob:  0.671975, 0.311198 (1.439 sec)
21.308... logprob:  0.627134, 0.305990 (1.452 sec)
21.309... logprob:  0.724200, 0.300781 (1.410 sec)
21.310... logprob:  0.634215, 0.263021 (1.414 sec)
21.311... logprob:  0.672019, 0.302083 (1.428 sec)
21.312... logprob:  0.698772, 0.304687 (1.426 sec)
21.313... logprob:  0.673362, 0.292969 (1.413 sec)
21.314... logprob:  0.611008, 0.292969 (1.456 sec)
21.315... logprob:  0.485646, 0.222656 (1.430 sec)
21.316... logprob:  0.653575, 0.295573 (1.419 sec)
21.317... logprob:  0.588886, 0.248698 (1.484 sec)
21.318... logprob:  0.613385, 0.291667 (1.408 sec)
21.319... logprob:  0.654803, 0.277344 (1.416 sec)
21.320... logprob:  0.545979, 0.257812 (1.418 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.489926, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.531294e-03 [1.768408e-07] 
Layer 'conv1' biases: 2.025691e-06 [1.763811e-10] 
Layer 'conv2' weights[0]: 3.524509e-03 [1.764773e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.667393e-09] 
Layer 'conv3' weights[0]: 3.523162e-03 [1.769156e-07] 
Layer 'conv3' biases: 3.351145e-05 [1.134643e-08] 
Layer 'conv4' weights[0]: 3.538003e-03 [1.783877e-07] 
Layer 'conv4' biases: 9.999397e-01 [2.459686e-07] 
Layer 'conv5' weights[0]: 3.655816e-03 [2.677005e-06] 
Layer 'conv5' biases: 9.990812e-01 [2.868086e-06] 
Layer 'fc6' weights[0]: 6.975443e-03 [6.508716e-08] 
Layer 'fc6' biases: 9.999921e-01 [6.155713e-08] 
Layer 'fc7' weights[0]: 7.324969e-03 [1.528668e-07] 
Layer 'fc7' biases: 9.997837e-01 [2.321391e-07] 
Layer 'fc8' weights[0]: 4.690041e-03 [1.626922e-05] 
Layer 'fc8' biases: 1.686108e-02 [3.787707e-05] 
Train error last 800 batches: 0.655765
-------------------------------------------------------
Not saving because 0.489926 > 0.299667 (9.300: -1.18%)
======================================================= (2.350 sec)
21.321... logprob:  0.560971, 0.259115 (1.425 sec)
21.322... logprob:  0.650306, 0.282552 (1.410 sec)
21.323... logprob:  0.587593, 0.266927 (1.476 sec)
21.324... logprob:  0.702151, 0.311198 (1.417 sec)
21.325... logprob:  0.597234, 0.268229 (1.430 sec)
21.326... logprob:  0.717490, 0.324219 (1.453 sec)
21.327... logprob:  0.742767, 0.325521 (1.421 sec)
21.328... logprob:  0.758596, 0.332031 (1.423 sec)
21.329... logprob:  0.672249, 0.294271 (1.417 sec)
21.330... logprob:  0.641713, 0.296875 (1.412 sec)
21.331... logprob:  0.554898, 0.247396 (1.415 sec)
21.332... logprob:  0.625928, 0.255208 (1.443 sec)
21.333... logprob:  0.541300, 0.240885 (1.436 sec)
21.334... logprob:  0.729307, 0.304687 (1.435 sec)
21.335... logprob:  0.553587, 0.227865 (1.434 sec)
21.336... logprob:  0.665603, 0.300781 (1.449 sec)
21.337... logprob:  0.689746, 0.273437 (1.409 sec)
21.338... logprob:  0.660555, 0.282552 (1.414 sec)
21.339... logprob:  0.637135, 0.299479 (1.415 sec)
21.340... logprob:  0.698506, 0.321615 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.403068, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.527761e-03 [1.765538e-07] 
Layer 'conv1' biases: 2.026230e-06 [1.547340e-10] 
Layer 'conv2' weights[0]: 3.520991e-03 [1.761663e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.304996e-09] 
Layer 'conv3' weights[0]: 3.519642e-03 [1.765399e-07] 
Layer 'conv3' biases: 3.354386e-05 [9.933331e-09] 
Layer 'conv4' weights[0]: 3.534438e-03 [1.775247e-07] 
Layer 'conv4' biases: 9.999398e-01 [1.937932e-07] 
Layer 'conv5' weights[0]: 3.652246e-03 [2.385461e-06] 
Layer 'conv5' biases: 9.990833e-01 [2.483146e-06] 
Layer 'fc6' weights[0]: 6.974713e-03 [6.182190e-08] 
Layer 'fc6' biases: 9.999918e-01 [5.700135e-08] 
Layer 'fc7' weights[0]: 7.324251e-03 [1.424575e-07] 
Layer 'fc7' biases: 9.997839e-01 [1.850206e-07] 
Layer 'fc8' weights[0]: 4.705114e-03 [1.353331e-05] 
Layer 'fc8' biases: 1.702192e-02 [1.871551e-05] 
Train error last 800 batches: 0.655284
-------------------------------------------------------
Not saving because 0.403068 > 0.299667 (9.300: -1.18%)
======================================================= (2.370 sec)
21.341... logprob:  0.725179, 0.322917 (1.422 sec)
21.342... logprob:  0.687577, 0.295573 (1.466 sec)
21.343... logprob:  0.646254, 0.311198 (1.441 sec)
21.344... logprob:  0.577938, 0.269531 (1.475 sec)
21.345... logprob:  0.674880, 0.285156 (1.439 sec)
21.346... logprob:  0.664630, 0.283854 (1.430 sec)
21.347... logprob:  0.509474, 0.221354 (1.476 sec)
21.348... logprob:  0.593665, 0.268229 (1.426 sec)
21.349... logprob:  0.763370, 0.345052 (1.429 sec)
21.350... logprob:  0.651815, 0.304687 (1.436 sec)
21.351... logprob:  0.797572, 0.352865 (1.422 sec)
21.352... logprob:  0.556543, 0.252604 (1.422 sec)
21.353... logprob:  0.677155, 0.282552 (1.487 sec)
21.354... logprob:  0.766767, 0.348958 (1.424 sec)
21.355... logprob:  0.601983, 0.257812 (1.479 sec)
21.356... logprob:  0.632433, 0.273438 (1.473 sec)
21.357... logprob:  0.542774, 0.227865 (1.430 sec)
21.358... logprob:  0.528844, 0.231771 (1.437 sec)
21.359... logprob:  0.746429, 0.341146 (1.430 sec)
21.360... logprob:  0.668642, 0.295573 (1.419 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.432674, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.524241e-03 [1.763755e-07] 
Layer 'conv1' biases: 2.027111e-06 [1.482145e-10] 
Layer 'conv2' weights[0]: 3.517493e-03 [1.760428e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.455017e-09] 
Layer 'conv3' weights[0]: 3.516136e-03 [1.764099e-07] 
Layer 'conv3' biases: 3.355097e-05 [9.670626e-09] 
Layer 'conv4' weights[0]: 3.530938e-03 [1.775535e-07] 
Layer 'conv4' biases: 9.999400e-01 [2.050127e-07] 
Layer 'conv5' weights[0]: 3.649192e-03 [2.445988e-06] 
Layer 'conv5' biases: 9.990956e-01 [2.611383e-06] 
Layer 'fc6' weights[0]: 6.973975e-03 [6.262272e-08] 
Layer 'fc6' biases: 9.999919e-01 [5.804571e-08] 
Layer 'fc7' weights[0]: 7.323537e-03 [1.438311e-07] 
Layer 'fc7' biases: 9.997833e-01 [1.903492e-07] 
Layer 'fc8' weights[0]: 4.688098e-03 [1.582463e-05] 
Layer 'fc8' biases: 1.692345e-02 [3.251443e-05] 
Train error last 800 batches: 0.655103
-------------------------------------------------------
Not saving because 0.432674 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
21.361... logprob:  0.658879, 0.313802 (1.436 sec)
21.362... logprob:  0.683040, 0.313802 (1.479 sec)
21.363... logprob:  0.704106, 0.296875 (1.438 sec)
21.364... logprob:  0.692387, 0.320313 (1.446 sec)
21.365... logprob:  0.693671, 0.302083 (1.461 sec)
21.366... logprob:  0.657486, 0.272135 (1.437 sec)
21.367... logprob:  0.564552, 0.248698 (1.433 sec)
21.368... logprob:  0.713601, 0.290365 (1.421 sec)
21.369... logprob:  0.655613, 0.296875 (1.421 sec)
21.370... logprob:  0.672325, 0.316406 (1.431 sec)
21.371... logprob:  0.640668, 0.282552 (1.450 sec)
21.372... logprob:  0.715890, 0.346354 (1.449 sec)
21.373... logprob:  0.755078, 0.303385 (1.449 sec)
21.374... logprob:  0.760522, 0.369792 (1.442 sec)
21.375... logprob:  0.673969, 0.322917 (1.456 sec)
21.376... logprob:  0.642542, 0.299479 (1.434 sec)
21.377... logprob:  0.578882, 0.253906 (1.418 sec)
21.378... logprob:  0.635447, 0.253906 (1.423 sec)
21.379... logprob:  0.481831, 0.235677 (1.432 sec)
21.380... logprob:  0.730841, 0.321615 (1.434 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.406992, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.520720e-03 [1.763048e-07] 
Layer 'conv1' biases: 2.027776e-06 [1.663847e-10] 
Layer 'conv2' weights[0]: 3.513974e-03 [1.759248e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.648417e-09] 
Layer 'conv3' weights[0]: 3.512630e-03 [1.763330e-07] 
Layer 'conv3' biases: 3.355816e-05 [9.596518e-09] 
Layer 'conv4' weights[0]: 3.527389e-03 [1.773931e-07] 
Layer 'conv4' biases: 9.999388e-01 [2.023541e-07] 
Layer 'conv5' weights[0]: 3.645153e-03 [2.300879e-06] 
Layer 'conv5' biases: 9.991006e-01 [2.384602e-06] 
Layer 'fc6' weights[0]: 6.973265e-03 [5.812033e-08] 
Layer 'fc6' biases: 9.999920e-01 [5.156527e-08] 
Layer 'fc7' weights[0]: 7.322764e-03 [1.317601e-07] 
Layer 'fc7' biases: 9.997823e-01 [1.542723e-07] 
Layer 'fc8' weights[0]: 4.673650e-03 [1.205363e-05] 
Layer 'fc8' biases: 1.683829e-02 [1.136416e-05] 
Train error last 800 batches: 0.655404
-------------------------------------------------------
Not saving because 0.406992 > 0.299667 (9.300: -1.18%)
======================================================= (2.427 sec)
21.381... logprob:  0.644362, 0.308594 (1.478 sec)
21.382... logprob:  0.781612, 0.332031 (1.453 sec)
21.383... logprob:  0.572766, 0.236979 (1.440 sec)
21.384... logprob:  0.678124, 0.298177 (1.480 sec)
21.385... logprob:  0.646233, 0.265625 (1.428 sec)
21.386... logprob:  0.834262, 0.333333 (1.429 sec)
21.387... logprob:  0.628389, 0.269531 (1.426 sec)
21.388... logprob:  0.665721, 0.292969 (1.428 sec)
21.389... logprob:  0.570013, 0.265625 (1.430 sec)
21.390... logprob:  0.639762, 0.285156 (1.476 sec)
21.391... logprob:  0.589363, 0.269531 (1.434 sec)
21.392... logprob:  0.615746, 0.290364 (1.433 sec)
21.393... logprob:  0.529836, 0.234375 (1.507 sec)
21.394... logprob:  0.594514, 0.256510 (1.432 sec)
21.395... logprob:  0.572237, 0.264323 (1.423 sec)
21.396... logprob:  0.520284, 0.233073 (1.430 sec)
21.397... logprob:  0.676054, 0.276042 (1.433 sec)
21.398... logprob:  0.576352, 0.277344 (1.424 sec)
21.399... logprob:  0.640982, 0.296875 (1.480 sec)
21.400... logprob:  0.799254, 0.333333 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.495891, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.517194e-03 [1.760955e-07] 
Layer 'conv1' biases: 2.029153e-06 [1.523712e-10] 
Layer 'conv2' weights[0]: 3.510446e-03 [1.757584e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.429340e-09] 
Layer 'conv3' weights[0]: 3.509131e-03 [1.760448e-07] 
Layer 'conv3' biases: 3.356390e-05 [9.372417e-09] 
Layer 'conv4' weights[0]: 3.523867e-03 [1.771845e-07] 
Layer 'conv4' biases: 9.999349e-01 [1.975152e-07] 
Layer 'conv5' weights[0]: 3.639614e-03 [2.514726e-06] 
Layer 'conv5' biases: 9.990916e-01 [2.789084e-06] 
Layer 'fc6' weights[0]: 6.972559e-03 [6.324478e-08] 
Layer 'fc6' biases: 9.999920e-01 [5.865323e-08] 
Layer 'fc7' weights[0]: 7.322053e-03 [1.450745e-07] 
Layer 'fc7' biases: 9.997827e-01 [1.926668e-07] 
Layer 'fc8' weights[0]: 4.699443e-03 [1.416838e-05] 
Layer 'fc8' biases: 1.702536e-02 [2.638106e-05] 
Train error last 800 batches: 0.654953
-------------------------------------------------------
Not saving because 0.495891 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
21.401... logprob:  0.649001, 0.270833 (1.440 sec)
21.402... logprob:  0.755134, 0.350260 (1.475 sec)
21.403... logprob:  0.660725, 0.313802 (1.432 sec)
21.404... logprob:  0.664533, 0.281250 (1.428 sec)
21.405... logprob:  0.667051, 0.292969 (1.429 sec)
21.406... logprob:  0.578037, 0.272135 (1.422 sec)
21.407... logprob:  0.741085, 0.326823 (1.428 sec)
21.408... logprob:  0.518938, 0.234375 (1.483 sec)
21.409... logprob:  0.621887, 0.276042 (1.430 sec)
21.410... logprob:  0.798221, 0.299479 (1.446 sec)
21.411... logprob:  0.679727, 0.294271 (1.472 sec)
21.412... logprob:  0.751810, 0.319010 (1.431 sec)
21.413... logprob:  0.692931, 0.312500 (1.432 sec)
21.414... logprob:  0.800686, 0.334635 (1.424 sec)
21.415... logprob:  0.693327, 0.320312 (1.419 sec)
21.416... logprob:  0.681896, 0.309896 (1.430 sec)
21.417... logprob:  0.634014, 0.286458 (1.455 sec)
21.418... logprob:  0.583734, 0.252604 (1.450 sec)
21.419... logprob:  0.724379, 0.300781 (1.451 sec)
21.420... logprob:  0.528017, 0.248698 (1.451 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.473326, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.513683e-03 [1.758644e-07] 
Layer 'conv1' biases: 2.029721e-06 [1.398104e-10] 
Layer 'conv2' weights[0]: 3.506945e-03 [1.755459e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.544604e-09] 
Layer 'conv3' weights[0]: 3.505578e-03 [1.759934e-07] 
Layer 'conv3' biases: 3.356139e-05 [9.883228e-09] 
Layer 'conv4' weights[0]: 3.520357e-03 [1.772958e-07] 
Layer 'conv4' biases: 9.999331e-01 [2.276273e-07] 
Layer 'conv5' weights[0]: 3.635240e-03 [2.416634e-06] 
Layer 'conv5' biases: 9.991077e-01 [2.559988e-06] 
Layer 'fc6' weights[0]: 6.971854e-03 [6.424821e-08] 
Layer 'fc6' biases: 9.999921e-01 [6.034217e-08] 
Layer 'fc7' weights[0]: 7.321316e-03 [1.508507e-07] 
Layer 'fc7' biases: 9.997817e-01 [2.172025e-07] 
Layer 'fc8' weights[0]: 4.662079e-03 [1.773228e-05] 
Layer 'fc8' biases: 1.678820e-02 [4.658868e-05] 
Train error last 800 batches: 0.655176
-------------------------------------------------------
Not saving because 0.473326 > 0.299667 (9.300: -1.18%)
======================================================= (2.380 sec)
21.421... logprob:  0.674917, 0.303385 (1.450 sec)
21.422... logprob:  0.707379, 0.299479 (1.438 sec)
21.423... logprob:  0.644982, 0.265625 (1.425 sec)
21.424... logprob:  0.613803, 0.282552 (1.425 sec)
21.425... logprob:  0.536963, 0.230469 (1.437 sec)
21.426... logprob:  0.704649, 0.302083 (1.439 sec)
21.427... logprob:  0.739326, 0.315104 (1.460 sec)
21.428... logprob:  0.833774, 0.354167 (1.447 sec)
21.429... logprob:  0.611624, 0.260417 (1.444 sec)
21.430... logprob:  0.580123, 0.282552 (1.476 sec)
21.431... logprob:  0.736835, 0.298177 (1.463 sec)
21.432... logprob:  0.708877, 0.330729 (1.425 sec)
21.433... logprob:  0.541257, 0.252604 (1.427 sec)
21.434... logprob:  0.766468, 0.333333 (1.429 sec)
21.435... logprob:  0.699581, 0.316406 (1.430 sec)
21.436... logprob:  0.669540, 0.298177 (1.468 sec)
21.437... logprob:  0.680477, 0.281250 (1.440 sec)
21.438... logprob:  0.613538, 0.264323 (1.425 sec)
21.439... logprob:  0.647457, 0.302083 (1.479 sec)
21.440... logprob:  0.684292, 0.298177 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.555861, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.510181e-03 [1.758298e-07] 
Layer 'conv1' biases: 2.030564e-06 [1.604889e-10] 
Layer 'conv2' weights[0]: 3.503430e-03 [1.753284e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.436203e-09] 
Layer 'conv3' weights[0]: 3.502092e-03 [1.757279e-07] 
Layer 'conv3' biases: 3.355389e-05 [1.039704e-08] 
Layer 'conv4' weights[0]: 3.516825e-03 [1.767305e-07] 
Layer 'conv4' biases: 9.999329e-01 [2.191286e-07] 
Layer 'conv5' weights[0]: 3.631742e-03 [2.435274e-06] 
Layer 'conv5' biases: 9.991218e-01 [2.665012e-06] 
Layer 'fc6' weights[0]: 6.971149e-03 [6.233134e-08] 
Layer 'fc6' biases: 9.999918e-01 [5.724873e-08] 
Layer 'fc7' weights[0]: 7.320603e-03 [1.404719e-07] 
Layer 'fc7' biases: 9.997803e-01 [1.747549e-07] 
Layer 'fc8' weights[0]: 4.628306e-03 [1.365326e-05] 
Layer 'fc8' biases: 1.653065e-02 [2.521230e-05] 
Train error last 800 batches: 0.655564
-------------------------------------------------------
Not saving because 0.555861 > 0.299667 (9.300: -1.18%)
======================================================= (2.404 sec)
21.441... logprob:  0.672067, 0.289062 (1.429 sec)
21.442... logprob:  0.634765, 0.283854 (1.435 sec)
21.443... logprob:  0.643907, 0.303385 (1.425 sec)
21.444... logprob:  0.626637, 0.265625 (1.425 sec)
21.445... logprob:  0.625257, 0.257812 (1.482 sec)
21.446... logprob:  0.640498, 0.289062 (1.435 sec)
21.447... logprob:  0.822417, 0.347656 (1.436 sec)
21.448... logprob:  0.593364, 0.273437 (1.480 sec)
21.449... logprob:  0.549873, 0.246094 (1.430 sec)
21.450... logprob:  0.502703, 0.220052 (1.428 sec)
21.451... logprob:  0.694345, 0.305989 (1.432 sec)
21.452... logprob:  0.605232, 0.264323 (1.423 sec)
21.453... logprob:  0.621384, 0.290365 (1.429 sec)
21.454... logprob:  0.698068, 0.307292 (1.484 sec)
21.455... logprob:  0.721956, 0.283854 (1.431 sec)
21.456... logprob:  0.602735, 0.251302 (1.442 sec)
21.457... logprob:  0.564704, 0.257812 (1.477 sec)
21.458... logprob:  0.571797, 0.269531 (1.432 sec)
21.459... logprob:  0.648461, 0.283854 (1.432 sec)
21.460... logprob:  0.493232, 0.251302 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.410525, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.506673e-03 [1.757098e-07] 
Layer 'conv1' biases: 2.031117e-06 [1.532841e-10] 
Layer 'conv2' weights[0]: 3.499956e-03 [1.752575e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.847904e-09] 
Layer 'conv3' weights[0]: 3.498602e-03 [1.758314e-07] 
Layer 'conv3' biases: 3.355604e-05 [1.194967e-08] 
Layer 'conv4' weights[0]: 3.513291e-03 [1.774665e-07] 
Layer 'conv4' biases: 9.999332e-01 [2.585323e-07] 
Layer 'conv5' weights[0]: 3.628973e-03 [3.504512e-06] 
Layer 'conv5' biases: 9.990926e-01 [3.701842e-06] 
Layer 'fc6' weights[0]: 6.970454e-03 [7.485896e-08] 
Layer 'fc6' biases: 9.999920e-01 [7.375448e-08] 
Layer 'fc7' weights[0]: 7.319902e-03 [1.834541e-07] 
Layer 'fc7' biases: 9.997823e-01 [3.267691e-07] 
Layer 'fc8' weights[0]: 4.708383e-03 [2.100963e-05] 
Layer 'fc8' biases: 1.709203e-02 [5.544995e-05] 
Train error last 800 batches: 0.654729
-------------------------------------------------------
Not saving because 0.410525 > 0.299667 (9.300: -1.18%)
======================================================= (2.349 sec)
21.461... logprob:  0.792278, 0.312500 (1.428 sec)
21.462... logprob:  0.608345, 0.292969 (1.430 sec)
21.463... logprob:  0.560952, 0.261719 (1.470 sec)
21.464... logprob:  0.609347, 0.273437 (1.442 sec)
21.465... logprob:  0.689530, 0.305990 (1.444 sec)
21.466... logprob:  0.555750, 0.264323 (1.453 sec)
21.467... logprob:  0.641834, 0.308594 (1.447 sec)
21.468... logprob:  0.516966, 0.226562 (1.439 sec)
21.469... logprob:  0.614229, 0.255208 (1.455 sec)
21.470... logprob:  0.650054, 0.296875 (1.422 sec)
21.471... logprob:  0.810438, 0.315104 (1.432 sec)
21.472... logprob:  0.710770, 0.315104 (1.451 sec)
21.473... logprob:  0.707396, 0.294271 (1.454 sec)
21.474... logprob:  0.749556, 0.309896 (1.448 sec)
21.475... logprob:  0.699549, 0.321615 (1.436 sec)
21.476... logprob:  0.719904, 0.290365 (1.583 sec)
21.477... logprob:  0.665812, 0.319010 (1.438 sec)
21.478... logprob:  0.677743, 0.292969 (1.421 sec)
21.479... logprob:  0.558122, 0.255208 (1.431 sec)
21.480... logprob:  0.587850, 0.266927 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.362882, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.503163e-03 [1.752591e-07] 
Layer 'conv1' biases: 2.031831e-06 [1.222438e-10] 
Layer 'conv2' weights[0]: 3.496449e-03 [1.749603e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.556066e-09] 
Layer 'conv3' weights[0]: 3.495079e-03 [1.755244e-07] 
Layer 'conv3' biases: 3.356436e-05 [1.111157e-08] 
Layer 'conv4' weights[0]: 3.509794e-03 [1.766556e-07] 
Layer 'conv4' biases: 9.999313e-01 [2.457555e-07] 
Layer 'conv5' weights[0]: 3.624492e-03 [2.871657e-06] 
Layer 'conv5' biases: 9.990969e-01 [3.083137e-06] 
Layer 'fc6' weights[0]: 6.969709e-03 [6.795692e-08] 
Layer 'fc6' biases: 9.999918e-01 [6.570686e-08] 
Layer 'fc7' weights[0]: 7.319148e-03 [1.577932e-07] 
Layer 'fc7' biases: 9.997817e-01 [2.325220e-07] 
Layer 'fc8' weights[0]: 4.700227e-03 [1.535393e-05] 
Layer 'fc8' biases: 1.703778e-02 [3.512871e-05] 
Train error last 800 batches: 0.654857
-------------------------------------------------------
Not saving because 0.362882 > 0.299667 (9.300: -1.18%)
======================================================= (2.359 sec)
21.481... logprob:  0.786384, 0.324219 (1.439 sec)
21.482... logprob:  0.662702, 0.308594 (1.475 sec)
21.483... logprob:  0.728457, 0.299479 (1.446 sec)
21.484... logprob:  0.690521, 0.283854 (1.427 sec)
21.485... logprob:  0.577603, 0.253906 (1.479 sec)
21.486... logprob:  0.689106, 0.315104 (1.428 sec)
21.487... logprob:  0.760627, 0.325521 (1.420 sec)
21.488... logprob:  0.646748, 0.292969 (1.429 sec)
21.489... logprob:  0.654026, 0.281250 (1.430 sec)
21.490... logprob:  0.692914, 0.313802 (1.424 sec)
21.491... logprob:  0.567962, 0.260417 (1.474 sec)
21.492... logprob:  0.623332, 0.257812 (1.432 sec)
21.493... logprob:  0.737608, 0.304688 (1.433 sec)
21.494... logprob:  0.626122, 0.272135 (1.478 sec)
21.495... logprob:  0.545306, 0.234375 (1.433 sec)
21.496... logprob:  0.750206, 0.292969 (1.425 sec)
21.497... logprob:  0.576483, 0.265625 (1.430 sec)
21.498... logprob:  0.775705, 0.358073 (1.422 sec)
21.499... logprob:  0.682858, 0.307292 (1.425 sec)
21.500... logprob:  0.681730, 0.326823 (1.482 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.514878, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.499666e-03 [1.750746e-07] 
Layer 'conv1' biases: 2.031683e-06 [1.751181e-10] 
Layer 'conv2' weights[0]: 3.492952e-03 [1.747726e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.944804e-09] 
Layer 'conv3' weights[0]: 3.491569e-03 [1.752933e-07] 
Layer 'conv3' biases: 3.360195e-05 [1.143003e-08] 
Layer 'conv4' weights[0]: 3.506276e-03 [1.764830e-07] 
Layer 'conv4' biases: 9.999333e-01 [2.439030e-07] 
Layer 'conv5' weights[0]: 3.622589e-03 [2.592535e-06] 
Layer 'conv5' biases: 9.991334e-01 [2.743743e-06] 
Layer 'fc6' weights[0]: 6.968973e-03 [6.169146e-08] 
Layer 'fc6' biases: 9.999917e-01 [5.606419e-08] 
Layer 'fc7' weights[0]: 7.318409e-03 [1.430959e-07] 
Layer 'fc7' biases: 9.997793e-01 [1.888582e-07] 
Layer 'fc8' weights[0]: 4.615042e-03 [1.541560e-05] 
Layer 'fc8' biases: 1.644165e-02 [3.137891e-05] 
Train error last 800 batches: 0.654485
-------------------------------------------------------
Not saving because 0.514878 > 0.299667 (9.300: -1.18%)
======================================================= (2.348 sec)
21.501... logprob:  0.564164, 0.227865 (1.438 sec)
21.502... logprob:  0.687136, 0.274740 (1.444 sec)
21.503... logprob:  0.609739, 0.255208 (1.487 sec)
21.504... logprob:  0.726615, 0.322917 (1.418 sec)
21.505... logprob:  0.698860, 0.299479 (1.440 sec)
21.506... logprob:  0.702477, 0.335937 (1.432 sec)
21.507... logprob:  0.549894, 0.233073 (1.456 sec)
21.508... logprob:  0.610151, 0.263021 (1.434 sec)
21.509... logprob:  0.505335, 0.238281 (1.477 sec)
21.510... logprob:  0.595584, 0.282552 (1.434 sec)
21.511... logprob:  0.637875, 0.322917 (1.448 sec)
21.512... logprob:  0.696499, 0.312500 (1.454 sec)
21.513... logprob:  0.665371, 0.279948 (1.441 sec)
21.514... logprob:  0.610096, 0.250000 (1.430 sec)
21.515... logprob:  0.590053, 0.257812 (1.425 sec)
21.516... logprob:  0.629834, 0.277344 (1.421 sec)
21.517... logprob:  0.818212, 0.328125 (1.436 sec)
21.518... logprob:  0.692243, 0.302083 (1.453 sec)
21.519... logprob:  0.709075, 0.283854 (1.449 sec)
21.520... logprob:  0.618290, 0.292969 (1.447 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.470589, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.496161e-03 [1.751533e-07] 
Layer 'conv1' biases: 2.032225e-06 [1.336211e-10] 
Layer 'conv2' weights[0]: 3.489449e-03 [1.746784e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.433521e-09] 
Layer 'conv3' weights[0]: 3.488099e-03 [1.750122e-07] 
Layer 'conv3' biases: 3.363693e-05 [9.516191e-09] 
Layer 'conv4' weights[0]: 3.502793e-03 [1.762935e-07] 
Layer 'conv4' biases: 9.999331e-01 [2.319450e-07] 
Layer 'conv5' weights[0]: 3.619463e-03 [2.466019e-06] 
Layer 'conv5' biases: 9.991028e-01 [2.590258e-06] 
Layer 'fc6' weights[0]: 6.968215e-03 [6.115228e-08] 
Layer 'fc6' biases: 9.999917e-01 [5.575061e-08] 
Layer 'fc7' weights[0]: 7.317733e-03 [1.396257e-07] 
Layer 'fc7' biases: 9.997812e-01 [1.643541e-07] 
Layer 'fc8' weights[0]: 4.694001e-03 [1.299188e-05] 
Layer 'fc8' biases: 1.709167e-02 [1.212276e-05] 
Train error last 800 batches: 0.654332
-------------------------------------------------------
Not saving because 0.470589 > 0.299667 (9.300: -1.18%)
======================================================= (2.358 sec)
21.521... logprob:  0.662440, 0.287760 (1.455 sec)
21.522... logprob:  0.803789, 0.319010 (1.464 sec)
21.523... logprob:  0.555545, 0.265625 (1.436 sec)
21.524... logprob:  0.617201, 0.272135 (1.418 sec)
21.525... logprob:  0.612777, 0.263021 (1.428 sec)
21.526... logprob:  0.550360, 0.221354 (1.437 sec)
21.527... logprob:  0.705246, 0.321615 (1.435 sec)
21.528... logprob:  0.575326, 0.264323 (1.461 sec)
21.529... logprob:  0.632810, 0.266927 (1.442 sec)
21.530... logprob:  0.704600, 0.290365 (1.434 sec)
21.531... logprob:  0.656844, 0.300781 (1.474 sec)
21.532... logprob:  0.675656, 0.283854 (1.428 sec)
21.533... logprob:  0.786274, 0.319010 (1.417 sec)
21.534... logprob:  0.522798, 0.272135 (1.432 sec)
21.535... logprob:  0.777992, 0.330729 (1.435 sec)
21.536... logprob:  0.737697, 0.329427 (1.436 sec)
21.537... logprob:  0.717598, 0.273437 (1.473 sec)
21.538... logprob:  0.704358, 0.316406 (1.445 sec)
21.539... logprob:  0.584694, 0.270833 (1.434 sec)
21.540... logprob:  0.733921, 0.316406 (1.477 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.425751, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.492662e-03 [1.748503e-07] 
Layer 'conv1' biases: 2.032603e-06 [1.451696e-10] 
Layer 'conv2' weights[0]: 3.485955e-03 [1.744355e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.383991e-09] 
Layer 'conv3' weights[0]: 3.484624e-03 [1.747236e-07] 
Layer 'conv3' biases: 3.363981e-05 [9.388648e-09] 
Layer 'conv4' weights[0]: 3.499292e-03 [1.759787e-07] 
Layer 'conv4' biases: 9.999323e-01 [2.094900e-07] 
Layer 'conv5' weights[0]: 3.616005e-03 [2.875377e-06] 
Layer 'conv5' biases: 9.991165e-01 [3.119452e-06] 
Layer 'fc6' weights[0]: 6.967495e-03 [7.045010e-08] 
Layer 'fc6' biases: 9.999920e-01 [6.836952e-08] 
Layer 'fc7' weights[0]: 7.316975e-03 [1.667534e-07] 
Layer 'fc7' biases: 9.997803e-01 [2.566874e-07] 
Layer 'fc8' weights[0]: 4.654492e-03 [1.707649e-05] 
Layer 'fc8' biases: 1.680323e-02 [3.762340e-05] 
Train error last 800 batches: 0.654258
-------------------------------------------------------
Not saving because 0.425751 > 0.299667 (9.300: -1.18%)
======================================================= (2.359 sec)
21.541... logprob:  0.591833, 0.274740 (1.438 sec)
21.542... logprob:  0.679367, 0.305990 (1.429 sec)
21.543... logprob:  0.550226, 0.264323 (1.432 sec)
21.544... logprob:  0.619908, 0.279948 (1.424 sec)
21.545... logprob:  0.549424, 0.236979 (1.452 sec)
21.546... logprob:  0.574097, 0.265625 (1.477 sec)
21.547... logprob:  0.632972, 0.268229 (1.428 sec)
21.548... logprob:  0.682402, 0.299479 (1.437 sec)
21.549... logprob:  0.639510, 0.291667 (1.471 sec)
21.550... logprob:  0.598205, 0.285156 (1.425 sec)
21.551... logprob:  0.746171, 0.311198 (1.428 sec)
21.552... logprob:  0.548176, 0.240885 (1.429 sec)
21.553... logprob:  0.558995, 0.268229 (1.421 sec)
21.554... logprob:  0.667197, 0.266927 (1.428 sec)
21.555... logprob:  0.715745, 0.335937 (1.475 sec)
21.556... logprob:  0.564486, 0.250000 (1.433 sec)
21.557... logprob:  0.640584, 0.312500 (1.452 sec)
21.558... logprob:  0.633351, 0.286458 (1.472 sec)
21.559... logprob:  0.613775, 0.268229 (1.429 sec)
21.560... logprob:  0.547724, 0.235677 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.432009, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.489178e-03 [1.748224e-07] 
Layer 'conv1' biases: 2.033037e-06 [1.125063e-10] 
Layer 'conv2' weights[0]: 3.482488e-03 [1.743759e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.391268e-09] 
Layer 'conv3' weights[0]: 3.481104e-03 [1.746833e-07] 
Layer 'conv3' biases: 3.361706e-05 [9.630809e-09] 
Layer 'conv4' weights[0]: 3.495788e-03 [1.760160e-07] 
Layer 'conv4' biases: 9.999321e-01 [2.061409e-07] 
Layer 'conv5' weights[0]: 3.612355e-03 [2.578794e-06] 
Layer 'conv5' biases: 9.991022e-01 [2.751690e-06] 
Layer 'fc6' weights[0]: 6.966802e-03 [6.162837e-08] 
Layer 'fc6' biases: 9.999919e-01 [5.657660e-08] 
Layer 'fc7' weights[0]: 7.316234e-03 [1.421785e-07] 
Layer 'fc7' biases: 9.997820e-01 [1.982450e-07] 
Layer 'fc8' weights[0]: 4.700173e-03 [1.463832e-05] 
Layer 'fc8' biases: 1.717567e-02 [3.078408e-05] 
Train error last 800 batches: 0.653532
-------------------------------------------------------
Not saving because 0.432009 > 0.299667 (9.300: -1.18%)
======================================================= (2.396 sec)
21.561... logprob:  0.619520, 0.269531 (1.431 sec)
21.562... logprob:  0.741414, 0.333333 (1.419 sec)
21.563... logprob:  0.580289, 0.265625 (1.440 sec)
21.564... logprob:  0.623816, 0.277344 (1.454 sec)
21.565... logprob:  0.709791, 0.281250 (1.445 sec)
21.566... logprob:  0.591160, 0.268229 (1.452 sec)
21.567... logprob:  0.656575, 0.276042 (1.462 sec)
21.568... logprob:  0.615300, 0.261719 (1.448 sec)
21.569... logprob:  0.764263, 0.304687 (1.432 sec)
21.570... logprob:  0.710741, 0.322917 (1.423 sec)
21.571... logprob:  0.669369, 0.283854 (1.423 sec)
21.572... logprob:  0.734789, 0.315104 (1.430 sec)
21.573... logprob:  0.704431, 0.289062 (1.439 sec)
21.574... logprob:  0.683435, 0.300781 (1.457 sec)
21.575... logprob:  0.519760, 0.229167 (1.443 sec)
21.576... logprob:  0.620423, 0.264323 (1.442 sec)
21.577... logprob:  0.616782, 0.272135 (1.475 sec)
21.578... logprob:  0.579962, 0.253906 (1.427 sec)
21.579... logprob:  0.665656, 0.290365 (1.421 sec)
21.580... logprob:  0.699084, 0.321615 (1.424 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.382380, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.485691e-03 [1.744519e-07] 
Layer 'conv1' biases: 2.033869e-06 [1.249454e-10] 
Layer 'conv2' weights[0]: 3.479001e-03 [1.741403e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.607679e-09] 
Layer 'conv3' weights[0]: 3.477641e-03 [1.746631e-07] 
Layer 'conv3' biases: 3.360566e-05 [1.097844e-08] 
Layer 'conv4' weights[0]: 3.492284e-03 [1.758265e-07] 
Layer 'conv4' biases: 9.999324e-01 [2.421120e-07] 
Layer 'conv5' weights[0]: 3.609592e-03 [2.499681e-06] 
Layer 'conv5' biases: 9.991120e-01 [2.674497e-06] 
Layer 'fc6' weights[0]: 6.966112e-03 [6.278683e-08] 
Layer 'fc6' biases: 9.999921e-01 [5.823945e-08] 
Layer 'fc7' weights[0]: 7.315511e-03 [1.420385e-07] 
Layer 'fc7' biases: 9.997806e-01 [1.861630e-07] 
Layer 'fc8' weights[0]: 4.674006e-03 [1.391747e-05] 
Layer 'fc8' biases: 1.700272e-02 [2.723103e-05] 
Train error last 800 batches: 0.652736
-------------------------------------------------------
Not saving because 0.382380 > 0.299667 (9.300: -1.18%)
======================================================= (2.379 sec)
21.581... logprob:  0.723827, 0.325521 (1.439 sec)
21.582... logprob:  0.634264, 0.248698 (1.435 sec)
21.583... logprob:  0.743337, 0.334635 (1.507 sec)
21.584... logprob:  0.643766, 0.304687 (1.438 sec)
21.585... logprob:  0.604027, 0.263021 (1.429 sec)
21.586... logprob:  0.652923, 0.303385 (1.478 sec)
21.587... logprob:  0.719427, 0.294271 (1.429 sec)
21.588... logprob:  0.656533, 0.321615 (1.429 sec)
21.589... logprob:  0.557156, 0.259114 (1.432 sec)
21.590... logprob:  0.709702, 0.307292 (1.423 sec)
21.591... logprob:  0.577837, 0.263021 (1.428 sec)
21.592... logprob:  0.740577, 0.313802 (1.474 sec)
21.593... logprob:  0.705831, 0.313802 (1.432 sec)
21.594... logprob:  0.603236, 0.264323 (1.433 sec)
21.595... logprob:  0.598872, 0.268229 (1.485 sec)
21.596... logprob:  0.624224, 0.266927 (1.432 sec)
21.597... logprob:  0.670765, 0.269531 (1.427 sec)
21.598... logprob:  0.668681, 0.294271 (1.429 sec)
21.599... logprob:  0.522032, 0.239583 (1.421 sec)
21.600... logprob:  0.627209, 0.278646 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.555412, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.482206e-03 [1.744079e-07] 
Layer 'conv1' biases: 2.034606e-06 [1.646334e-10] 
Layer 'conv2' weights[0]: 3.475520e-03 [1.740451e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.962707e-09] 
Layer 'conv3' weights[0]: 3.474201e-03 [1.746622e-07] 
Layer 'conv3' biases: 3.361279e-05 [1.260518e-08] 
Layer 'conv4' weights[0]: 3.488792e-03 [1.760673e-07] 
Layer 'conv4' biases: 9.999312e-01 [2.792594e-07] 
Layer 'conv5' weights[0]: 3.605541e-03 [3.294532e-06] 
Layer 'conv5' biases: 9.991060e-01 [3.612613e-06] 
Layer 'fc6' weights[0]: 6.965402e-03 [7.250112e-08] 
Layer 'fc6' biases: 9.999919e-01 [7.067190e-08] 
Layer 'fc7' weights[0]: 7.314789e-03 [1.669844e-07] 
Layer 'fc7' biases: 9.997807e-01 [2.678709e-07] 
Layer 'fc8' weights[0]: 4.690765e-03 [1.780039e-05] 
Layer 'fc8' biases: 1.715919e-02 [4.427113e-05] 
Train error last 800 batches: 0.652480
-------------------------------------------------------
Not saving because 0.555412 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
21.601... logprob:  0.650501, 0.292969 (1.489 sec)
21.602... logprob:  0.537674, 0.222656 (1.425 sec)
21.603... logprob:  0.516418, 0.246094 (1.441 sec)
21.604... logprob:  0.675967, 0.290365 (1.468 sec)
21.605... logprob:  0.625409, 0.285156 (1.431 sec)
21.606... logprob:  0.551321, 0.243490 (1.446 sec)
21.607... logprob:  0.669904, 0.289062 (1.427 sec)
21.608... logprob:  0.635755, 0.281250 (1.425 sec)
21.609... logprob:  0.579182, 0.277344 (1.429 sec)
21.610... logprob:  0.715815, 0.272135 (1.463 sec)
21.611... logprob:  0.618920, 0.236979 (1.441 sec)
21.612... logprob:  0.602432, 0.274740 (1.450 sec)
21.613... logprob:  0.510263, 0.238281 (1.458 sec)
21.614... logprob:  0.667814, 0.281250 (1.447 sec)
21.615... logprob:  0.638455, 0.247396 (1.437 sec)
21.616... logprob:  0.665190, 0.299479 (1.424 sec)
21.617... logprob:  0.616480, 0.289062 (1.426 sec)
21.618... logprob:  0.751174, 0.350260 (1.433 sec)
21.619... logprob:  0.701844, 0.308594 (1.443 sec)
21.620... logprob:  0.778794, 0.283854 (1.455 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.440036, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.478722e-03 [1.739410e-07] 
Layer 'conv1' biases: 2.035349e-06 [2.157643e-10] 
Layer 'conv2' weights[0]: 3.472036e-03 [1.737091e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.519607e-09] 
Layer 'conv3' weights[0]: 3.470730e-03 [1.752403e-07] 
Layer 'conv3' biases: 3.363346e-05 [1.785215e-08] 
Layer 'conv4' weights[0]: 3.485321e-03 [1.767628e-07] 
Layer 'conv4' biases: 9.999297e-01 [3.970863e-07] 
Layer 'conv5' weights[0]: 3.601518e-03 [4.290973e-06] 
Layer 'conv5' biases: 9.990932e-01 [4.772304e-06] 
Layer 'fc6' weights[0]: 6.964680e-03 [8.103648e-08] 
Layer 'fc6' biases: 9.999920e-01 [8.355289e-08] 
Layer 'fc7' weights[0]: 7.314046e-03 [1.982219e-07] 
Layer 'fc7' biases: 9.997822e-01 [3.579571e-07] 
Layer 'fc8' weights[0]: 4.733845e-03 [2.131073e-05] 
Layer 'fc8' biases: 1.755703e-02 [5.993817e-05] 
Train error last 800 batches: 0.651619
-------------------------------------------------------
Not saving because 0.440036 > 0.299667 (9.300: -1.18%)
======================================================= (2.378 sec)
21.621... logprob:  0.615209, 0.234375 (1.474 sec)
21.622... logprob:  0.583904, 0.247396 (1.446 sec)
21.623... logprob:  0.588902, 0.285156 (1.467 sec)
21.624... logprob:  0.570973, 0.257812 (1.432 sec)
21.625... logprob:  0.714604, 0.296875 (1.416 sec)
21.626... logprob:  0.623390, 0.278646 (1.427 sec)
21.627... logprob:  0.620472, 0.270833 (1.429 sec)
21.628... logprob:  0.625148, 0.264323 (1.430 sec)
21.629... logprob:  0.598346, 0.279948 (1.465 sec)
21.630... logprob:  0.643217, 0.313802 (1.441 sec)
21.631... logprob:  0.860910, 0.347656 (1.516 sec)
21.632... logprob:  0.659537, 0.298177 (1.478 sec)
21.633... logprob:  0.695815, 0.300781 (1.433 sec)
21.634... logprob:  0.927186, 0.363281 (1.422 sec)
21.635... logprob:  0.599385, 0.290365 (1.426 sec)
21.636... logprob:  0.679655, 0.302083 (1.432 sec)
21.637... logprob:  0.588054, 0.260417 (1.431 sec)
21.638... logprob:  0.707180, 0.302083 (1.478 sec)
21.639... logprob:  0.668643, 0.300781 (1.437 sec)
21.640... logprob:  0.674041, 0.292969 (1.434 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.406436, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.475257e-03 [1.737892e-07] 
Layer 'conv1' biases: 2.036019e-06 [1.852483e-10] 
Layer 'conv2' weights[0]: 3.468579e-03 [1.735479e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.834671e-09] 
Layer 'conv3' weights[0]: 3.467246e-03 [1.743834e-07] 
Layer 'conv3' biases: 3.367813e-05 [1.403670e-08] 
Layer 'conv4' weights[0]: 3.481821e-03 [1.755504e-07] 
Layer 'conv4' biases: 9.999295e-01 [2.910723e-07] 
Layer 'conv5' weights[0]: 3.598038e-03 [2.727262e-06] 
Layer 'conv5' biases: 9.991378e-01 [3.086134e-06] 
Layer 'fc6' weights[0]: 6.963995e-03 [6.712227e-08] 
Layer 'fc6' biases: 9.999920e-01 [6.330841e-08] 
Layer 'fc7' weights[0]: 7.313305e-03 [1.574060e-07] 
Layer 'fc7' biases: 9.997782e-01 [2.288836e-07] 
Layer 'fc8' weights[0]: 4.619905e-03 [1.791333e-05] 
Layer 'fc8' biases: 1.667766e-02 [4.561239e-05] 
Train error last 800 batches: 0.652022
-------------------------------------------------------
Not saving because 0.406436 > 0.299667 (9.300: -1.18%)
======================================================= (2.357 sec)
21.641... logprob:  0.592236, 0.263021 (1.485 sec)
21.642... logprob:  0.730043, 0.316406 (1.435 sec)
21.643... logprob:  0.719515, 0.303385 (1.433 sec)
21.644... logprob:  0.552655, 0.225260 (1.429 sec)
21.645... logprob:  0.707956, 0.305990 (1.423 sec)
21.646... logprob:  0.678122, 0.287760 (1.427 sec)
21.647... logprob:  0.630134, 0.274739 (1.480 sec)
21.648... logprob:  0.694914, 0.296875 (1.427 sec)
21.649... logprob:  0.606736, 0.266927 (1.437 sec)
21.650... logprob:  0.612086, 0.282552 (1.472 sec)
21.651... logprob:  0.732943, 0.325521 (1.424 sec)
21.652... logprob:  0.633545, 0.259115 (1.432 sec)
21.653... logprob:  0.771338, 0.325521 (1.425 sec)
21.654... logprob:  0.757549, 0.326823 (1.420 sec)
21.655... logprob:  0.700545, 0.311198 (1.431 sec)
21.656... logprob:  0.657810, 0.270833 (1.477 sec)
21.657... logprob:  0.730585, 0.312500 (1.435 sec)
21.658... logprob:  0.582545, 0.277344 (1.443 sec)
21.659... logprob:  0.627944, 0.259114 (1.459 sec)
21.660... logprob:  0.758672, 0.351563 (1.438 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.457968, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.471774e-03 [1.736627e-07] 
Layer 'conv1' biases: 2.036528e-06 [1.510938e-10] 
Layer 'conv2' weights[0]: 3.465114e-03 [1.733639e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.426408e-09] 
Layer 'conv3' weights[0]: 3.463771e-03 [1.736945e-07] 
Layer 'conv3' biases: 3.368276e-05 [9.323315e-09] 
Layer 'conv4' weights[0]: 3.478312e-03 [1.747686e-07] 
Layer 'conv4' biases: 9.999296e-01 [1.935787e-07] 
Layer 'conv5' weights[0]: 3.595120e-03 [2.358513e-06] 
Layer 'conv5' biases: 9.991494e-01 [2.575827e-06] 
Layer 'fc6' weights[0]: 6.963274e-03 [6.198188e-08] 
Layer 'fc6' biases: 9.999918e-01 [5.614272e-08] 
Layer 'fc7' weights[0]: 7.312591e-03 [1.429676e-07] 
Layer 'fc7' biases: 9.997775e-01 [1.759712e-07] 
Layer 'fc8' weights[0]: 4.602696e-03 [1.424843e-05] 
Layer 'fc8' biases: 1.649255e-02 [2.774593e-05] 
Train error last 800 batches: 0.652651
-------------------------------------------------------
Not saving because 0.457968 > 0.299667 (9.300: -1.18%)
======================================================= (2.400 sec)
21.661... logprob:  0.635792, 0.287760 (1.441 sec)
21.662... logprob:  0.746983, 0.335937 (1.434 sec)
21.663... logprob:  0.549829, 0.248698 (1.424 sec)
21.664... logprob:  0.574424, 0.264323 (1.439 sec)
21.665... logprob:  0.603660, 0.274740 (1.453 sec)
21.666... logprob:  0.605006, 0.282552 (1.447 sec)
21.667... logprob:  0.689053, 0.285156 (1.446 sec)
21.668... logprob:  0.616087, 0.279948 (1.447 sec)
21.669... logprob:  0.599806, 0.278646 (1.455 sec)
21.670... logprob:  0.618290, 0.276042 (1.430 sec)
21.671... logprob:  0.606118, 0.287760 (1.421 sec)
21.672... logprob:  0.619438, 0.268229 (1.425 sec)
21.673... logprob:  0.766751, 0.356771 (1.439 sec)
21.674... logprob:  0.618812, 0.296875 (1.435 sec)
21.675... logprob:  0.601430, 0.283854 (1.463 sec)
21.676... logprob:  0.751577, 0.332031 (1.449 sec)
21.677... logprob:  0.627800, 0.292969 (1.432 sec)
21.678... logprob:  0.622883, 0.242187 (1.476 sec)
21.679... logprob:  0.666506, 0.292969 (1.431 sec)
21.680... logprob:  0.582404, 0.238281 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.468049, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.468316e-03 [1.736184e-07] 
Layer 'conv1' biases: 2.037681e-06 [1.489284e-10] 
Layer 'conv2' weights[0]: 3.461662e-03 [1.731907e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.258942e-09] 
Layer 'conv3' weights[0]: 3.460306e-03 [1.734831e-07] 
Layer 'conv3' biases: 3.369203e-05 [9.208550e-09] 
Layer 'conv4' weights[0]: 3.474843e-03 [1.745501e-07] 
Layer 'conv4' biases: 9.999291e-01 [1.807718e-07] 
Layer 'conv5' weights[0]: 3.591629e-03 [2.128501e-06] 
Layer 'conv5' biases: 9.991149e-01 [2.251189e-06] 
Layer 'fc6' weights[0]: 6.962571e-03 [5.961638e-08] 
Layer 'fc6' biases: 9.999919e-01 [5.353823e-08] 
Layer 'fc7' weights[0]: 7.311841e-03 [1.352361e-07] 
Layer 'fc7' biases: 9.997798e-01 [1.611884e-07] 
Layer 'fc8' weights[0]: 4.691392e-03 [1.249592e-05] 
Layer 'fc8' biases: 1.721991e-02 [1.162152e-05] 
Train error last 800 batches: 0.652224
-------------------------------------------------------
Not saving because 0.468049 > 0.299667 (9.300: -1.18%)
======================================================= (2.357 sec)
21.681... logprob:  0.685020, 0.328125 (1.441 sec)
21.682... logprob:  0.507396, 0.238281 (1.437 sec)
21.683... logprob:  0.600287, 0.278646 (1.434 sec)
21.684... logprob:  0.613295, 0.250000 (1.469 sec)
21.685... logprob:  0.503092, 0.251302 (1.438 sec)
21.686... logprob:  0.536313, 0.221354 (1.429 sec)
21.687... logprob:  0.525968, 0.255208 (1.477 sec)
21.688... logprob:  0.590479, 0.263021 (1.427 sec)
21.689... logprob:  0.616193, 0.261719 (1.424 sec)
21.690... logprob:  0.716658, 0.324219 (1.432 sec)
21.691... logprob:  0.764345, 0.356771 (1.434 sec)
21.692... logprob:  0.685007, 0.304687 (1.432 sec)
21.693... logprob:  0.716227, 0.300781 (1.482 sec)
21.694... logprob:  0.566281, 0.236979 (1.436 sec)
21.695... logprob:  0.597507, 0.307291 (1.440 sec)
21.696... logprob:  0.743644, 0.295573 (1.473 sec)
21.697... logprob:  0.658507, 0.283854 (1.429 sec)
21.698... logprob:  0.746863, 0.311198 (1.434 sec)
21.699... logprob:  0.694013, 0.299479 (1.445 sec)
21.700... logprob:  0.588176, 0.257812 (1.422 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.495474, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.464831e-03 [1.734298e-07] 
Layer 'conv1' biases: 2.038629e-06 [1.869225e-10] 
Layer 'conv2' weights[0]: 3.458209e-03 [1.730448e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.102051e-09] 
Layer 'conv3' weights[0]: 3.456819e-03 [1.739082e-07] 
Layer 'conv3' biases: 3.372733e-05 [1.418917e-08] 
Layer 'conv4' weights[0]: 3.471362e-03 [1.753496e-07] 
Layer 'conv4' biases: 9.999290e-01 [3.189377e-07] 
Layer 'conv5' weights[0]: 3.588524e-03 [3.295736e-06] 
Layer 'conv5' biases: 9.991104e-01 [3.619050e-06] 
Layer 'fc6' weights[0]: 6.961837e-03 [7.472028e-08] 
Layer 'fc6' biases: 9.999919e-01 [7.378154e-08] 
Layer 'fc7' weights[0]: 7.311127e-03 [1.800574e-07] 
Layer 'fc7' biases: 9.997798e-01 [3.026562e-07] 
Layer 'fc8' weights[0]: 4.706200e-03 [1.906929e-05] 
Layer 'fc8' biases: 1.741126e-02 [4.674970e-05] 
Train error last 800 batches: 0.652223
-------------------------------------------------------
Not saving because 0.495474 > 0.299667 (9.300: -1.18%)
======================================================= (2.336 sec)
21.701... logprob:  0.634087, 0.302083 (1.433 sec)
21.702... logprob:  0.626452, 0.273437 (1.485 sec)
21.703... logprob:  0.605122, 0.268229 (1.439 sec)
21.704... logprob:  0.649068, 0.304688 (1.445 sec)
21.705... logprob:  0.626805, 0.276042 (1.468 sec)
21.706... logprob:  0.603241, 0.261719 (1.431 sec)
21.707... logprob:  0.757044, 0.308594 (1.434 sec)
21.708... logprob:  0.728447, 0.329427 (1.428 sec)
21.709... logprob:  0.634313, 0.266927 (1.420 sec)
21.710... logprob:  0.706158, 0.277344 (1.431 sec)
21.711... logprob:  0.621427, 0.261719 (1.462 sec)
21.712... logprob:  0.468188, 0.191406 (1.440 sec)
21.713... logprob:  0.845264, 0.343750 (1.448 sec)
21.714... logprob:  0.693223, 0.281250 (1.450 sec)
21.715... logprob:  0.625525, 0.273437 (1.446 sec)
21.716... logprob:  0.563438, 0.266927 (1.434 sec)
21.717... logprob:  0.622025, 0.276042 (1.428 sec)
21.718... logprob:  0.609612, 0.259115 (1.432 sec)
21.719... logprob:  0.609786, 0.260417 (1.438 sec)
21.720... logprob:  0.637708, 0.268229 (1.438 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.520570, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.461375e-03 [1.733132e-07] 
Layer 'conv1' biases: 2.038687e-06 [1.359140e-10] 
Layer 'conv2' weights[0]: 3.454740e-03 [1.728844e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.248455e-09] 
Layer 'conv3' weights[0]: 3.453356e-03 [1.732662e-07] 
Layer 'conv3' biases: 3.373032e-05 [9.253947e-09] 
Layer 'conv4' weights[0]: 3.467916e-03 [1.744142e-07] 
Layer 'conv4' biases: 9.999288e-01 [2.029475e-07] 
Layer 'conv5' weights[0]: 3.585330e-03 [2.707859e-06] 
Layer 'conv5' biases: 9.991325e-01 [2.890473e-06] 
Layer 'fc6' weights[0]: 6.961144e-03 [7.545047e-08] 
Layer 'fc6' biases: 9.999918e-01 [7.402991e-08] 
Layer 'fc7' weights[0]: 7.310423e-03 [1.869045e-07] 
Layer 'fc7' biases: 9.997776e-01 [3.125838e-07] 
Layer 'fc8' weights[0]: 4.653090e-03 [2.667102e-05] 
Layer 'fc8' biases: 1.699541e-02 [8.050657e-05] 
Train error last 800 batches: 0.651815
-------------------------------------------------------
Not saving because 0.520570 > 0.299667 (9.300: -1.18%)
======================================================= (2.345 sec)
21.721... logprob:  0.693619, 0.289062 (1.462 sec)
21.722... logprob:  0.758536, 0.358073 (1.457 sec)
21.723... logprob:  0.620575, 0.303385 (1.444 sec)
21.724... logprob:  0.599280, 0.286458 (1.464 sec)
21.725... logprob:  0.720339, 0.315104 (1.430 sec)
21.726... logprob:  0.654321, 0.320313 (1.420 sec)
21.727... logprob:  0.637549, 0.277344 (1.428 sec)
21.728... logprob:  0.653647, 0.296875 (1.439 sec)
21.729... logprob:  0.644085, 0.304687 (1.427 sec)
21.730... logprob:  0.710331, 0.312500 (1.470 sec)
21.731... logprob:  0.690836, 0.311198 (1.438 sec)
21.732... logprob:  0.528666, 0.253906 (1.427 sec)
21.733... logprob:  0.765456, 0.324219 (1.498 sec)
21.734... logprob:  0.560551, 0.239583 (1.425 sec)
21.735... logprob:  0.710976, 0.289062 (1.424 sec)
21.736... logprob:  0.744936, 0.326823 (1.432 sec)
21.737... logprob:  0.717653, 0.317708 (1.446 sec)
21.738... logprob:  0.622988, 0.268229 (1.435 sec)
21.739... logprob:  0.732515, 0.322917 (1.481 sec)
21.740... logprob:  0.497681, 0.204427 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.516119, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.457923e-03 [1.730381e-07] 
Layer 'conv1' biases: 2.038871e-06 [1.422571e-10] 
Layer 'conv2' weights[0]: 3.451279e-03 [1.726945e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.655781e-09] 
Layer 'conv3' weights[0]: 3.449926e-03 [1.731647e-07] 
Layer 'conv3' biases: 3.372396e-05 [1.082908e-08] 
Layer 'conv4' weights[0]: 3.464445e-03 [1.743016e-07] 
Layer 'conv4' biases: 9.999292e-01 [2.330761e-07] 
Layer 'conv5' weights[0]: 3.582571e-03 [2.939855e-06] 
Layer 'conv5' biases: 9.991364e-01 [3.123690e-06] 
Layer 'fc6' weights[0]: 6.960430e-03 [6.416684e-08] 
Layer 'fc6' biases: 9.999916e-01 [5.948217e-08] 
Layer 'fc7' weights[0]: 7.309731e-03 [1.452510e-07] 
Layer 'fc7' biases: 9.997770e-01 [1.904192e-07] 
Layer 'fc8' weights[0]: 4.644874e-03 [1.352697e-05] 
Layer 'fc8' biases: 1.690033e-02 [1.862987e-05] 
Train error last 800 batches: 0.651885
-------------------------------------------------------
Not saving because 0.516119 > 0.299667 (9.300: -1.18%)
======================================================= (2.409 sec)
21.741... logprob:  0.598767, 0.285156 (1.436 sec)
21.742... logprob:  0.538702, 0.233073 (1.476 sec)
21.743... logprob:  0.649739, 0.291667 (1.424 sec)
21.744... logprob:  0.752512, 0.325521 (1.426 sec)
21.745... logprob:  0.634539, 0.268229 (1.432 sec)
21.746... logprob:  0.706588, 0.321615 (1.421 sec)
21.747... logprob:  0.712978, 0.299479 (1.427 sec)
21.748... logprob:  0.604744, 0.265625 (1.485 sec)
21.749... logprob:  0.717971, 0.299479 (1.428 sec)
21.750... logprob:  0.708713, 0.313802 (1.441 sec)
21.751... logprob:  0.545732, 0.235677 (1.474 sec)
21.752... logprob:  0.648185, 0.295573 (1.433 sec)
21.753... logprob:  0.713498, 0.317708 (1.436 sec)
21.754... logprob:  0.665238, 0.290365 (1.424 sec)
21.755... logprob:  0.667283, 0.268229 (1.422 sec)
21.756... logprob:  0.590576, 0.234375 (1.426 sec)
21.757... logprob:  0.794129, 0.304688 (1.463 sec)
21.758... logprob:  0.678330, 0.307292 (1.440 sec)
21.759... logprob:  0.679496, 0.299479 (1.450 sec)
21.760... logprob:  0.613316, 0.257812 (1.461 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.459855, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.454463e-03 [1.727925e-07] 
Layer 'conv1' biases: 2.039386e-06 [1.649768e-10] 
Layer 'conv2' weights[0]: 3.447836e-03 [1.724937e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.522387e-09] 
Layer 'conv3' weights[0]: 3.446480e-03 [1.730918e-07] 
Layer 'conv3' biases: 3.376609e-05 [1.023650e-08] 
Layer 'conv4' weights[0]: 3.460997e-03 [1.741656e-07] 
Layer 'conv4' biases: 9.999294e-01 [2.380476e-07] 
Layer 'conv5' weights[0]: 3.579482e-03 [2.655866e-06] 
Layer 'conv5' biases: 9.991500e-01 [2.846409e-06] 
Layer 'fc6' weights[0]: 6.959691e-03 [6.614412e-08] 
Layer 'fc6' biases: 9.999918e-01 [6.142537e-08] 
Layer 'fc7' weights[0]: 7.308983e-03 [1.502595e-07] 
Layer 'fc7' biases: 9.997756e-01 [1.937279e-07] 
Layer 'fc8' weights[0]: 4.613714e-03 [1.418627e-05] 
Layer 'fc8' biases: 1.669949e-02 [1.964795e-05] 
Train error last 800 batches: 0.651765
-------------------------------------------------------
Not saving because 0.459855 > 0.299667 (9.300: -1.18%)
======================================================= (2.363 sec)
21.761... logprob:  0.621304, 0.282552 (1.445 sec)
21.762... logprob:  0.702623, 0.324219 (1.433 sec)
21.763... logprob:  0.721125, 0.298177 (1.424 sec)
21.764... logprob:  0.645710, 0.309896 (1.420 sec)
21.765... logprob:  0.504901, 0.231771 (1.437 sec)
21.766... logprob:  0.668719, 0.295573 (1.447 sec)
21.767... logprob:  0.705228, 0.315104 (1.451 sec)
21.768... logprob:  0.634261, 0.266927 (1.457 sec)
21.769... logprob:  0.701013, 0.292969 (1.461 sec)
21.770... logprob:  0.578140, 0.240885 (1.475 sec)
21.771... logprob:  0.742636, 0.345052 (1.452 sec)
21.772... logprob:  0.631961, 0.283854 (1.435 sec)
21.773... logprob:  0.765218, 0.308594 (1.439 sec)
21.774... logprob:  0.622945, 0.266927 (1.457 sec)
21.775... logprob:  0.663041, 0.270833 (1.481 sec)
21.776... logprob:  0.674411, 0.277344 (1.472 sec)
21.777... logprob:  0.624689, 0.260417 (1.475 sec)
21.778... logprob:  0.663293, 0.283854 (1.464 sec)
21.779... logprob:  0.682572, 0.319010 (1.481 sec)
21.780... logprob:  0.670679, 0.286458 (1.451 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.435017, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.451010e-03 [1.727984e-07] 
Layer 'conv1' biases: 2.040428e-06 [1.555231e-10] 
Layer 'conv2' weights[0]: 3.444390e-03 [1.724553e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.675907e-09] 
Layer 'conv3' weights[0]: 3.443022e-03 [1.730046e-07] 
Layer 'conv3' biases: 3.376719e-05 [1.173654e-08] 
Layer 'conv4' weights[0]: 3.457533e-03 [1.743249e-07] 
Layer 'conv4' biases: 9.999266e-01 [2.593870e-07] 
Layer 'conv5' weights[0]: 3.574666e-03 [2.446411e-06] 
Layer 'conv5' biases: 9.991437e-01 [2.626193e-06] 
Layer 'fc6' weights[0]: 6.958972e-03 [6.129676e-08] 
Layer 'fc6' biases: 9.999915e-01 [5.516625e-08] 
Layer 'fc7' weights[0]: 7.308238e-03 [1.394595e-07] 
Layer 'fc7' biases: 9.997758e-01 [1.615350e-07] 
Layer 'fc8' weights[0]: 4.633200e-03 [1.314331e-05] 
Layer 'fc8' biases: 1.685709e-02 [1.744515e-05] 
Train error last 800 batches: 0.651667
-------------------------------------------------------
Not saving because 0.435017 > 0.299667 (9.300: -1.18%)
======================================================= (2.392 sec)
21.781... logprob:  0.626253, 0.259115 (1.445 sec)
21.782... logprob:  0.587916, 0.279948 (1.450 sec)
21.783... logprob:  0.675791, 0.291667 (1.453 sec)
21.784... logprob:  0.596360, 0.247396 (1.450 sec)
21.785... logprob:  0.636401, 0.283854 (1.484 sec)
21.786... logprob:  0.571618, 0.244792 (1.468 sec)
21.787... logprob:  0.713287, 0.309896 (1.461 sec)
21.788... logprob:  0.801172, 0.335938 (1.485 sec)
21.789... logprob:  0.558694, 0.268229 (1.450 sec)
21.790... logprob:  0.600257, 0.247396 (1.453 sec)
21.791... logprob:  0.611102, 0.264323 (1.446 sec)
21.792... logprob:  0.608043, 0.263021 (1.462 sec)
21.793... logprob:  0.650138, 0.309896 (1.452 sec)
21.794... logprob:  0.571931, 0.248698 (1.483 sec)
21.795... logprob:  0.696936, 0.296875 (1.460 sec)
21.796... logprob:  0.611639, 0.266927 (1.461 sec)
21.797... logprob:  0.567217, 0.238281 (1.488 sec)
21.798... logprob:  0.610650, 0.287760 (1.449 sec)
21.799... logprob:  0.533863, 0.221354 (1.448 sec)
21.800... logprob:  0.573338, 0.253906 (1.404 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.549621, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.447549e-03 [1.727426e-07] 
Layer 'conv1' biases: 2.041904e-06 [1.382799e-10] 
Layer 'conv2' weights[0]: 3.440951e-03 [1.723197e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.475209e-09] 
Layer 'conv3' weights[0]: 3.439581e-03 [1.726778e-07] 
Layer 'conv3' biases: 3.376110e-05 [1.065026e-08] 
Layer 'conv4' weights[0]: 3.454067e-03 [1.740981e-07] 
Layer 'conv4' biases: 9.999247e-01 [2.504846e-07] 
Layer 'conv5' weights[0]: 3.570462e-03 [3.080292e-06] 
Layer 'conv5' biases: 9.991225e-01 [3.461838e-06] 
Layer 'fc6' weights[0]: 6.958274e-03 [7.361234e-08] 
Layer 'fc6' biases: 9.999914e-01 [7.139347e-08] 
Layer 'fc7' weights[0]: 7.307500e-03 [1.753846e-07] 
Layer 'fc7' biases: 9.997771e-01 [2.968170e-07] 
Layer 'fc8' weights[0]: 4.686137e-03 [1.918613e-05] 
Layer 'fc8' biases: 1.730406e-02 [4.964938e-05] 
Train error last 800 batches: 0.651218
-------------------------------------------------------
Not saving because 0.549621 > 0.299667 (9.300: -1.18%)
======================================================= (2.367 sec)
22.1... logprob:  0.639451, 0.286458 (1.408 sec)
22.2... logprob:  0.693234, 0.311198 (1.450 sec)
22.3... logprob:  0.592422, 0.253906 (1.415 sec)
22.4... logprob:  0.650726, 0.256510 (1.405 sec)
22.5... logprob:  0.548156, 0.259115 (1.431 sec)
22.6... logprob:  0.603938, 0.257812 (1.386 sec)
22.7... logprob:  0.574982, 0.250000 (1.420 sec)
22.8... logprob:  0.560949, 0.239583 (1.391 sec)
22.9... logprob:  0.661513, 0.287760 (1.404 sec)
22.10... logprob:  0.601319, 0.264323 (1.404 sec)
22.11... logprob:  0.629253, 0.303385 (1.435 sec)
22.12... logprob:  0.624253, 0.268229 (1.406 sec)
22.13... logprob:  0.618356, 0.256510 (1.431 sec)
22.14... logprob:  0.753889, 0.316406 (1.399 sec)
22.15... logprob:  0.647350, 0.291667 (1.404 sec)
22.16... logprob:  0.706803, 0.316406 (1.402 sec)
22.17... logprob:  0.785729, 0.337240 (1.394 sec)
22.18... logprob:  0.488146, 0.239583 (1.396 sec)
22.19... logprob:  0.553548, 0.269531 (1.395 sec)
22.20... logprob:  0.666327, 0.303385 (1.397 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.375758, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.444120e-03 [1.722537e-07] 
Layer 'conv1' biases: 2.043568e-06 [1.453955e-10] 
Layer 'conv2' weights[0]: 3.437501e-03 [1.719911e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.410029e-09] 
Layer 'conv3' weights[0]: 3.436155e-03 [1.724141e-07] 
Layer 'conv3' biases: 3.376229e-05 [9.926118e-09] 
Layer 'conv4' weights[0]: 3.450614e-03 [1.733798e-07] 
Layer 'conv4' biases: 9.999237e-01 [2.092282e-07] 
Layer 'conv5' weights[0]: 3.566663e-03 [2.415656e-06] 
Layer 'conv5' biases: 9.991122e-01 [2.579444e-06] 
Layer 'fc6' weights[0]: 6.957536e-03 [6.003358e-08] 
Layer 'fc6' biases: 9.999915e-01 [5.433955e-08] 
Layer 'fc7' weights[0]: 7.306746e-03 [1.368053e-07] 
Layer 'fc7' biases: 9.997776e-01 [1.813856e-07] 
Layer 'fc8' weights[0]: 4.714235e-03 [1.447872e-05] 
Layer 'fc8' biases: 1.756535e-02 [3.283610e-05] 
Train error last 800 batches: 0.651398
-------------------------------------------------------
Not saving because 0.375758 > 0.299667 (9.300: -1.18%)
======================================================= (2.391 sec)
22.21... logprob:  0.657177, 0.269531 (1.399 sec)
22.22... logprob:  0.793790, 0.322917 (1.415 sec)
22.23... logprob:  0.781318, 0.321615 (1.405 sec)
22.24... logprob:  0.593210, 0.287760 (1.415 sec)
22.25... logprob:  0.553692, 0.248698 (1.398 sec)
22.26... logprob:  0.660099, 0.308594 (1.444 sec)
22.27... logprob:  0.704464, 0.330729 (1.386 sec)
22.28... logprob:  0.662495, 0.287760 (1.409 sec)
22.29... logprob:  0.593716, 0.251302 (1.420 sec)
22.30... logprob:  0.681170, 0.298177 (1.412 sec)
22.31... logprob:  0.735720, 0.304687 (1.404 sec)
22.32... logprob:  0.643755, 0.277344 (1.379 sec)
22.33... logprob:  0.661934, 0.285156 (1.443 sec)
22.34... logprob:  0.665231, 0.281250 (1.392 sec)
22.35... logprob:  0.591100, 0.283854 (1.393 sec)
22.36... logprob:  0.704591, 0.326823 (1.394 sec)
22.37... logprob:  0.661421, 0.290365 (1.409 sec)
22.38... logprob:  0.674222, 0.295573 (1.392 sec)
22.39... logprob:  0.710678, 0.324219 (1.430 sec)
22.40... logprob:  0.647710, 0.264323 (1.404 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.536564, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.440672e-03 [1.721537e-07] 
Layer 'conv1' biases: 2.044297e-06 [1.264737e-10] 
Layer 'conv2' weights[0]: 3.434068e-03 [1.718364e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.579328e-09] 
Layer 'conv3' weights[0]: 3.432728e-03 [1.722744e-07] 
Layer 'conv3' biases: 3.379290e-05 [1.054812e-08] 
Layer 'conv4' weights[0]: 3.447153e-03 [1.730533e-07] 
Layer 'conv4' biases: 9.999243e-01 [2.092119e-07] 
Layer 'conv5' weights[0]: 3.564152e-03 [2.697562e-06] 
Layer 'conv5' biases: 9.991411e-01 [2.877708e-06] 
Layer 'fc6' weights[0]: 6.956853e-03 [6.815253e-08] 
Layer 'fc6' biases: 9.999916e-01 [6.419585e-08] 
Layer 'fc7' weights[0]: 7.306058e-03 [1.589408e-07] 
Layer 'fc7' biases: 9.997754e-01 [2.300158e-07] 
Layer 'fc8' weights[0]: 4.641683e-03 [1.582958e-05] 
Layer 'fc8' biases: 1.699888e-02 [3.815644e-05] 
Train error last 800 batches: 0.651989
-------------------------------------------------------
Not saving because 0.536564 > 0.299667 (9.300: -1.18%)
======================================================= (2.355 sec)
22.41... logprob:  0.533447, 0.240885 (1.424 sec)
22.42... logprob:  0.661690, 0.285156 (1.413 sec)
22.43... logprob:  0.629668, 0.290365 (1.403 sec)
22.44... logprob:  0.715710, 0.289062 (1.430 sec)
22.45... logprob:  0.621467, 0.253906 (1.383 sec)
22.46... logprob:  0.720843, 0.333333 (1.396 sec)
22.47... logprob:  0.575352, 0.269531 (1.392 sec)
22.48... logprob:  0.634902, 0.268229 (1.423 sec)
22.49... logprob:  0.732973, 0.317708 (1.404 sec)
22.50... logprob:  0.609321, 0.246094 (1.423 sec)
22.51... logprob:  0.645014, 0.265625 (1.412 sec)
22.52... logprob:  0.696323, 0.316406 (1.415 sec)
22.53... logprob:  0.551194, 0.220052 (1.443 sec)
22.54... logprob:  0.596873, 0.261719 (1.385 sec)
22.55... logprob:  0.585222, 0.244792 (1.388 sec)
22.56... logprob:  0.657294, 0.311198 (1.396 sec)
22.57... logprob:  0.763184, 0.309896 (1.423 sec)
22.58... logprob:  0.591170, 0.282552 (1.397 sec)
22.59... logprob:  0.641904, 0.286458 (1.579 sec)
22.60... logprob:  0.863912, 0.369792 (1.414 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.377837, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.437223e-03 [1.718594e-07] 
Layer 'conv1' biases: 2.045181e-06 [1.163000e-10] 
Layer 'conv2' weights[0]: 3.430629e-03 [1.716095e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.253603e-09] 
Layer 'conv3' weights[0]: 3.429291e-03 [1.718921e-07] 
Layer 'conv3' biases: 3.380951e-05 [8.525787e-09] 
Layer 'conv4' weights[0]: 3.443703e-03 [1.728014e-07] 
Layer 'conv4' biases: 9.999239e-01 [1.846211e-07] 
Layer 'conv5' weights[0]: 3.560706e-03 [2.567612e-06] 
Layer 'conv5' biases: 9.991229e-01 [2.758723e-06] 
Layer 'fc6' weights[0]: 6.956115e-03 [6.178580e-08] 
Layer 'fc6' biases: 9.999918e-01 [5.610315e-08] 
Layer 'fc7' weights[0]: 7.305341e-03 [1.437031e-07] 
Layer 'fc7' biases: 9.997765e-01 [1.774267e-07] 
Layer 'fc8' weights[0]: 4.681363e-03 [1.369964e-05] 
Layer 'fc8' biases: 1.731776e-02 [2.044646e-05] 
Train error last 800 batches: 0.651789
-------------------------------------------------------
Not saving because 0.377837 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
22.61... logprob:  0.601832, 0.231771 (1.433 sec)
22.62... logprob:  0.738435, 0.330729 (1.460 sec)
22.63... logprob:  0.639861, 0.277344 (1.438 sec)
22.64... logprob:  0.734751, 0.341146 (1.403 sec)
22.65... logprob:  0.619477, 0.269531 (1.396 sec)
22.66... logprob:  0.578633, 0.233073 (1.438 sec)
22.67... logprob:  0.633842, 0.270833 (1.384 sec)
22.68... logprob:  0.677021, 0.313802 (1.396 sec)
22.69... logprob:  0.755270, 0.320312 (1.417 sec)
22.70... logprob:  0.597937, 0.281250 (1.418 sec)
22.71... logprob:  0.621284, 0.285156 (1.456 sec)
22.72... logprob:  0.657240, 0.278646 (1.397 sec)
22.73... logprob:  0.608042, 0.266927 (1.427 sec)
22.74... logprob:  0.659659, 0.322917 (1.416 sec)
22.75... logprob:  0.621788, 0.269531 (1.408 sec)
22.76... logprob:  0.710715, 0.320312 (1.428 sec)
22.77... logprob:  0.628941, 0.292969 (1.422 sec)
22.78... logprob:  0.692626, 0.304688 (1.449 sec)
22.79... logprob:  0.716189, 0.287760 (1.407 sec)
22.80... logprob:  0.731050, 0.332031 (1.418 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.408656, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.433804e-03 [1.719381e-07] 
Layer 'conv1' biases: 2.045643e-06 [1.355711e-10] 
Layer 'conv2' weights[0]: 3.427192e-03 [1.715258e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.413498e-09] 
Layer 'conv3' weights[0]: 3.425846e-03 [1.718344e-07] 
Layer 'conv3' biases: 3.384191e-05 [9.359545e-09] 
Layer 'conv4' weights[0]: 3.440282e-03 [1.729491e-07] 
Layer 'conv4' biases: 9.999218e-01 [2.217468e-07] 
Layer 'conv5' weights[0]: 3.556092e-03 [2.800142e-06] 
Layer 'conv5' biases: 9.991314e-01 [3.033697e-06] 
Layer 'fc6' weights[0]: 6.955379e-03 [6.803102e-08] 
Layer 'fc6' biases: 9.999917e-01 [6.468201e-08] 
Layer 'fc7' weights[0]: 7.304620e-03 [1.592397e-07] 
Layer 'fc7' biases: 9.997759e-01 [2.311808e-07] 
Layer 'fc8' weights[0]: 4.651976e-03 [1.661292e-05] 
Layer 'fc8' biases: 1.717541e-02 [4.344080e-05] 
Train error last 800 batches: 0.652322
-------------------------------------------------------
Not saving because 0.408656 > 0.299667 (9.300: -1.18%)
======================================================= (2.346 sec)
22.81... logprob:  0.679733, 0.287760 (1.426 sec)
22.82... logprob:  0.519284, 0.225260 (1.421 sec)
22.83... logprob:  0.665181, 0.296875 (1.405 sec)
22.84... logprob:  0.739974, 0.303385 (1.463 sec)
22.85... logprob:  0.659033, 0.299479 (1.422 sec)
22.86... logprob:  0.700158, 0.287760 (1.410 sec)
22.87... logprob:  0.770253, 0.332031 (1.408 sec)
22.88... logprob:  0.747476, 0.300781 (1.401 sec)
22.89... logprob:  0.702464, 0.291667 (1.429 sec)
22.90... logprob:  0.764705, 0.351562 (1.381 sec)
22.91... logprob:  0.614383, 0.248698 (1.400 sec)
22.92... logprob:  0.596598, 0.269531 (1.401 sec)
22.93... logprob:  0.761317, 0.312500 (1.394 sec)
22.94... logprob:  0.692519, 0.296875 (1.390 sec)
22.95... logprob:  0.673984, 0.287760 (1.401 sec)
22.96... logprob:  0.739299, 0.302083 (1.397 sec)
22.97... logprob:  0.640705, 0.298177 (1.391 sec)
22.98... logprob:  0.631804, 0.285156 (1.433 sec)
22.99... logprob:  0.668317, 0.287760 (1.407 sec)
22.100... logprob:  0.573987, 0.272135 (1.401 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.464026, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.430367e-03 [1.717233e-07] 
Layer 'conv1' biases: 2.045485e-06 [1.480636e-10] 
Layer 'conv2' weights[0]: 3.423779e-03 [1.713059e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.469081e-09] 
Layer 'conv3' weights[0]: 3.422456e-03 [1.717074e-07] 
Layer 'conv3' biases: 3.385074e-05 [1.092666e-08] 
Layer 'conv4' weights[0]: 3.436829e-03 [1.727544e-07] 
Layer 'conv4' biases: 9.999249e-01 [2.342704e-07] 
Layer 'conv5' weights[0]: 3.555028e-03 [2.117517e-06] 
Layer 'conv5' biases: 9.991570e-01 [2.364352e-06] 
Layer 'fc6' weights[0]: 6.954654e-03 [6.162416e-08] 
Layer 'fc6' biases: 9.999917e-01 [5.529193e-08] 
Layer 'fc7' weights[0]: 7.303877e-03 [1.392806e-07] 
Layer 'fc7' biases: 9.997736e-01 [1.708258e-07] 
Layer 'fc8' weights[0]: 4.580214e-03 [1.286617e-05] 
Layer 'fc8' biases: 1.665411e-02 [1.881303e-05] 
Train error last 800 batches: 0.651875
-------------------------------------------------------
Not saving because 0.464026 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
22.101... logprob:  0.551157, 0.220052 (1.447 sec)
22.102... logprob:  0.711667, 0.303385 (1.391 sec)
22.103... logprob:  0.754540, 0.328125 (1.400 sec)
22.104... logprob:  0.625017, 0.289062 (1.394 sec)
22.105... logprob:  0.752567, 0.342448 (1.388 sec)
22.106... logprob:  0.615119, 0.264323 (1.387 sec)
22.107... logprob:  0.571824, 0.240885 (1.440 sec)
22.108... logprob:  0.806829, 0.342448 (1.398 sec)
22.109... logprob:  0.581678, 0.240885 (1.400 sec)
22.110... logprob:  0.712419, 0.332031 (1.389 sec)
22.111... logprob:  0.654256, 0.278646 (1.392 sec)
22.112... logprob:  0.603149, 0.274740 (1.393 sec)
22.113... logprob:  0.539407, 0.251302 (1.392 sec)
22.114... logprob:  0.728100, 0.289062 (1.422 sec)
22.115... logprob:  0.767987, 0.343750 (1.406 sec)
22.116... logprob:  0.683230, 0.330729 (1.393 sec)
22.117... logprob:  0.637194, 0.277344 (1.439 sec)
22.118... logprob:  0.650791, 0.292969 (1.386 sec)
22.119... logprob:  0.672586, 0.313802 (1.395 sec)
22.120... logprob:  0.703292, 0.295573 (1.399 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.518903, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.426944e-03 [1.715070e-07] 
Layer 'conv1' biases: 2.046644e-06 [1.563760e-10] 
Layer 'conv2' weights[0]: 3.420355e-03 [1.711426e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.456223e-09] 
Layer 'conv3' weights[0]: 3.418983e-03 [1.714811e-07] 
Layer 'conv3' biases: 3.386882e-05 [9.962548e-09] 
Layer 'conv4' weights[0]: 3.433414e-03 [1.724983e-07] 
Layer 'conv4' biases: 9.999263e-01 [2.356854e-07] 
Layer 'conv5' weights[0]: 3.552580e-03 [2.453111e-06] 
Layer 'conv5' biases: 9.991365e-01 [2.592031e-06] 
Layer 'fc6' weights[0]: 6.953886e-03 [6.049597e-08] 
Layer 'fc6' biases: 9.999915e-01 [5.393832e-08] 
Layer 'fc7' weights[0]: 7.303089e-03 [1.375236e-07] 
Layer 'fc7' biases: 9.997749e-01 [1.613489e-07] 
Layer 'fc8' weights[0]: 4.634128e-03 [1.228245e-05] 
Layer 'fc8' biases: 1.713031e-02 [9.330909e-06] 
Train error last 800 batches: 0.652043
-------------------------------------------------------
Not saving because 0.518903 > 0.299667 (9.300: -1.18%)
======================================================= (2.392 sec)
22.121... logprob:  0.668829, 0.274740 (1.398 sec)
22.122... logprob:  0.717281, 0.325521 (1.439 sec)
22.123... logprob:  0.698391, 0.260417 (1.383 sec)
22.124... logprob:  0.618586, 0.263021 (1.395 sec)
22.125... logprob:  0.780391, 0.325521 (1.394 sec)
22.126... logprob:  0.804334, 0.319010 (1.387 sec)
22.127... logprob:  0.739727, 0.298177 (1.390 sec)
22.128... logprob:  0.654636, 0.283854 (1.411 sec)
22.129... logprob:  0.753507, 0.330729 (1.412 sec)
22.130... logprob:  0.623886, 0.263021 (1.415 sec)
22.131... logprob:  0.725643, 0.315104 (1.403 sec)
22.132... logprob:  0.636084, 0.281250 (1.428 sec)
22.133... logprob:  0.705313, 0.294271 (1.384 sec)
22.134... logprob:  0.653998, 0.270833 (1.387 sec)
22.135... logprob:  0.717761, 0.312500 (1.397 sec)
22.136... logprob:  0.743480, 0.326823 (1.390 sec)
22.137... logprob:  0.714981, 0.294271 (1.391 sec)
22.138... logprob:  0.560787, 0.234375 (1.438 sec)
22.139... logprob:  0.658140, 0.283854 (1.389 sec)
22.140... logprob:  0.777395, 0.365885 (1.407 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.438946, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.423523e-03 [1.713481e-07] 
Layer 'conv1' biases: 2.047273e-06 [1.127001e-10] 
Layer 'conv2' weights[0]: 3.416938e-03 [1.709851e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.090947e-09] 
Layer 'conv3' weights[0]: 3.415608e-03 [1.711102e-07] 
Layer 'conv3' biases: 3.388427e-05 [7.360811e-09] 
Layer 'conv4' weights[0]: 3.429976e-03 [1.721891e-07] 
Layer 'conv4' biases: 9.999283e-01 [1.838053e-07] 
Layer 'conv5' weights[0]: 3.550314e-03 [2.229785e-06] 
Layer 'conv5' biases: 9.991659e-01 [2.396916e-06] 
Layer 'fc6' weights[0]: 6.953190e-03 [6.208838e-08] 
Layer 'fc6' biases: 9.999915e-01 [5.583702e-08] 
Layer 'fc7' weights[0]: 7.302414e-03 [1.411316e-07] 
Layer 'fc7' biases: 9.997723e-01 [1.647890e-07] 
Layer 'fc8' weights[0]: 4.565611e-03 [1.268981e-05] 
Layer 'fc8' biases: 1.657009e-02 [7.416696e-06] 
Train error last 800 batches: 0.652589
-------------------------------------------------------
Not saving because 0.438946 > 0.299667 (9.300: -1.18%)
======================================================= (2.377 sec)
22.141... logprob:  0.735510, 0.302083 (1.443 sec)
22.142... logprob:  0.673527, 0.311198 (1.393 sec)
22.143... logprob:  0.571892, 0.268229 (1.422 sec)
22.144... logprob:  0.650494, 0.315104 (1.410 sec)
22.145... logprob:  0.564965, 0.233073 (1.411 sec)
22.146... logprob:  0.644565, 0.305990 (1.409 sec)
22.147... logprob:  0.599546, 0.269531 (1.428 sec)
22.148... logprob:  0.634190, 0.270833 (1.389 sec)
22.149... logprob:  0.682793, 0.317708 (1.387 sec)
22.150... logprob:  0.716628, 0.311198 (1.397 sec)
22.151... logprob:  0.596965, 0.277344 (1.391 sec)
22.152... logprob:  0.809378, 0.342448 (1.383 sec)
22.153... logprob:  0.576469, 0.287760 (1.436 sec)
22.154... logprob:  0.710578, 0.302083 (1.394 sec)
22.155... logprob:  0.710460, 0.334635 (1.402 sec)
22.156... logprob:  0.542005, 0.261719 (1.435 sec)
22.157... logprob:  0.529442, 0.243490 (1.389 sec)
22.158... logprob:  0.602925, 0.272135 (1.399 sec)
22.159... logprob:  0.778375, 0.305990 (1.392 sec)
22.160... logprob:  0.680926, 0.296875 (1.390 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.500035, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.420088e-03 [1.710875e-07] 
Layer 'conv1' biases: 2.048010e-06 [1.176532e-10] 
Layer 'conv2' weights[0]: 3.413519e-03 [1.707661e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.335291e-09] 
Layer 'conv3' weights[0]: 3.412190e-03 [1.711621e-07] 
Layer 'conv3' biases: 3.391627e-05 [9.046045e-09] 
Layer 'conv4' weights[0]: 3.426537e-03 [1.725186e-07] 
Layer 'conv4' biases: 9.999263e-01 [2.427092e-07] 
Layer 'conv5' weights[0]: 3.546059e-03 [2.727651e-06] 
Layer 'conv5' biases: 9.991248e-01 [2.992916e-06] 
Layer 'fc6' weights[0]: 6.952446e-03 [6.571081e-08] 
Layer 'fc6' biases: 9.999914e-01 [6.087780e-08] 
Layer 'fc7' weights[0]: 7.301621e-03 [1.541675e-07] 
Layer 'fc7' biases: 9.997756e-01 [2.141981e-07] 
Layer 'fc8' weights[0]: 4.669889e-03 [1.616612e-05] 
Layer 'fc8' biases: 1.735001e-02 [3.658355e-05] 
Train error last 800 batches: 0.652922
-------------------------------------------------------
Not saving because 0.500035 > 0.299667 (9.300: -1.18%)
======================================================= (2.383 sec)
22.161... logprob:  0.615593, 0.290364 (1.405 sec)
22.162... logprob:  0.772728, 0.321615 (1.408 sec)
22.163... logprob:  0.607212, 0.270833 (1.425 sec)
22.164... logprob:  0.671093, 0.264323 (1.418 sec)
22.165... logprob:  0.665574, 0.278646 (1.413 sec)
22.166... logprob:  0.711681, 0.317708 (1.444 sec)
22.167... logprob:  0.572819, 0.274740 (1.421 sec)
22.168... logprob:  0.611228, 0.294271 (1.419 sec)
22.169... logprob:  0.639388, 0.274740 (1.467 sec)
22.170... logprob:  0.649384, 0.266927 (1.397 sec)
22.171... logprob:  0.726794, 0.324219 (1.419 sec)
22.172... logprob:  0.681790, 0.277344 (1.411 sec)
22.173... logprob:  0.619606, 0.287760 (1.414 sec)
22.174... logprob:  0.708121, 0.308594 (1.393 sec)
22.175... logprob:  0.647034, 0.289062 (1.461 sec)
22.176... logprob:  0.624289, 0.270833 (1.411 sec)
22.177... logprob:  0.509985, 0.220052 (1.416 sec)
22.178... logprob:  0.661385, 0.294271 (1.456 sec)
22.179... logprob:  0.700342, 0.287760 (1.400 sec)
22.180... logprob:  0.658522, 0.289062 (1.412 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.568456, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.416682e-03 [1.709684e-07] 
Layer 'conv1' biases: 2.048943e-06 [1.070616e-10] 
Layer 'conv2' weights[0]: 3.410111e-03 [1.706187e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.213113e-09] 
Layer 'conv3' weights[0]: 3.408770e-03 [1.708988e-07] 
Layer 'conv3' biases: 3.394234e-05 [9.133947e-09] 
Layer 'conv4' weights[0]: 3.423121e-03 [1.719235e-07] 
Layer 'conv4' biases: 9.999258e-01 [2.044066e-07] 
Layer 'conv5' weights[0]: 3.542508e-03 [2.225031e-06] 
Layer 'conv5' biases: 9.991254e-01 [2.365068e-06] 
Layer 'fc6' weights[0]: 6.951733e-03 [6.238528e-08] 
Layer 'fc6' biases: 9.999915e-01 [5.686325e-08] 
Layer 'fc7' weights[0]: 7.300889e-03 [1.443640e-07] 
Layer 'fc7' biases: 9.997755e-01 [1.904707e-07] 
Layer 'fc8' weights[0]: 4.666446e-03 [1.446021e-05] 
Layer 'fc8' biases: 1.735376e-02 [2.797162e-05] 
Train error last 800 batches: 0.652787
-------------------------------------------------------
Not saving because 0.568456 > 0.299667 (9.300: -1.18%)
======================================================= (2.393 sec)
22.181... logprob:  0.735172, 0.324219 (1.420 sec)
22.182... logprob:  0.582276, 0.252604 (1.416 sec)
22.183... logprob:  0.601370, 0.265625 (1.411 sec)
22.184... logprob:  0.742604, 0.330729 (1.419 sec)
22.185... logprob:  0.631556, 0.261719 (1.391 sec)
22.186... logprob:  0.574712, 0.273437 (1.393 sec)
22.187... logprob:  0.745830, 0.313802 (1.393 sec)
22.188... logprob:  0.602659, 0.278646 (1.397 sec)
22.189... logprob:  0.636934, 0.312500 (1.381 sec)
22.190... logprob:  0.530853, 0.242187 (1.431 sec)
22.191... logprob:  0.652972, 0.309896 (1.404 sec)
22.192... logprob:  0.665437, 0.292969 (1.416 sec)
22.193... logprob:  0.630007, 0.276042 (1.419 sec)
22.194... logprob:  0.624353, 0.273437 (1.408 sec)
22.195... logprob:  0.508638, 0.221354 (1.392 sec)
22.196... logprob:  0.558327, 0.259115 (1.385 sec)
22.197... logprob:  0.704827, 0.328125 (1.394 sec)
22.198... logprob:  0.623258, 0.261719 (1.404 sec)
22.199... logprob:  0.640401, 0.307292 (1.383 sec)
22.200... logprob:  0.685709, 0.311198 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.427329, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.413266e-03 [1.710303e-07] 
Layer 'conv1' biases: 2.049634e-06 [1.435738e-10] 
Layer 'conv2' weights[0]: 3.406706e-03 [1.705823e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.222904e-09] 
Layer 'conv3' weights[0]: 3.405383e-03 [1.708102e-07] 
Layer 'conv3' biases: 3.394742e-05 [8.793692e-09] 
Layer 'conv4' weights[0]: 3.419682e-03 [1.719805e-07] 
Layer 'conv4' biases: 9.999264e-01 [2.216408e-07] 
Layer 'conv5' weights[0]: 3.539632e-03 [2.669098e-06] 
Layer 'conv5' biases: 9.991010e-01 [2.857828e-06] 
Layer 'fc6' weights[0]: 6.951032e-03 [6.381019e-08] 
Layer 'fc6' biases: 9.999915e-01 [5.906440e-08] 
Layer 'fc7' weights[0]: 7.300150e-03 [1.484703e-07] 
Layer 'fc7' biases: 9.997764e-01 [2.129554e-07] 
Layer 'fc8' weights[0]: 4.724119e-03 [1.543930e-05] 
Layer 'fc8' biases: 1.781342e-02 [3.027347e-05] 
Train error last 800 batches: 0.652594
-------------------------------------------------------
Not saving because 0.427329 > 0.299667 (9.300: -1.18%)
======================================================= (2.379 sec)
22.201... logprob:  0.699153, 0.308594 (1.406 sec)
22.202... logprob:  0.805596, 0.341146 (1.404 sec)
22.203... logprob:  0.649867, 0.274739 (1.439 sec)
22.204... logprob:  0.676164, 0.309896 (1.385 sec)
22.205... logprob:  0.588428, 0.292969 (1.397 sec)
22.206... logprob:  0.648127, 0.291667 (1.394 sec)
22.207... logprob:  0.596279, 0.244792 (1.386 sec)
22.208... logprob:  0.703938, 0.276042 (1.406 sec)
22.209... logprob:  0.513450, 0.235677 (1.412 sec)
22.210... logprob:  0.788476, 0.356771 (1.409 sec)
22.211... logprob:  0.700217, 0.295573 (1.413 sec)
22.212... logprob:  0.726669, 0.313802 (1.410 sec)
22.213... logprob:  0.665307, 0.283854 (1.462 sec)
22.214... logprob:  0.692617, 0.283854 (1.424 sec)
22.215... logprob:  0.658569, 0.287760 (1.413 sec)
22.216... logprob:  0.658396, 0.268229 (1.466 sec)
22.217... logprob:  0.560408, 0.265625 (1.406 sec)
22.218... logprob:  0.698208, 0.273437 (1.420 sec)
22.219... logprob:  0.769373, 0.322917 (1.409 sec)
22.220... logprob:  0.616618, 0.247396 (1.413 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.325470, 0.039062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.409846e-03 [1.706454e-07] 
Layer 'conv1' biases: 2.050451e-06 [1.921494e-10] 
Layer 'conv2' weights[0]: 3.403304e-03 [1.703146e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.077295e-09] 
Layer 'conv3' weights[0]: 3.401956e-03 [1.711317e-07] 
Layer 'conv3' biases: 3.398080e-05 [1.401449e-08] 
Layer 'conv4' weights[0]: 3.416272e-03 [1.721337e-07] 
Layer 'conv4' biases: 9.999261e-01 [2.843660e-07] 
Layer 'conv5' weights[0]: 3.536334e-03 [3.389454e-06] 
Layer 'conv5' biases: 9.991268e-01 [3.789321e-06] 
Layer 'fc6' weights[0]: 6.950319e-03 [7.460596e-08] 
Layer 'fc6' biases: 9.999917e-01 [7.297604e-08] 
Layer 'fc7' weights[0]: 7.299436e-03 [1.783648e-07] 
Layer 'fc7' biases: 9.997747e-01 [2.846948e-07] 
Layer 'fc8' weights[0]: 4.665416e-03 [1.796945e-05] 
Layer 'fc8' biases: 1.730797e-02 [4.876162e-05] 
Train error last 800 batches: 0.653257
-------------------------------------------------------
Not saving because 0.325470 > 0.299667 (9.300: -1.18%)
======================================================= (2.354 sec)
22.221... logprob:  0.611784, 0.264323 (1.407 sec)
22.222... logprob:  0.773234, 0.339844 (1.449 sec)
22.223... logprob:  0.768819, 0.317708 (1.420 sec)
22.224... logprob:  0.574151, 0.260417 (1.433 sec)
22.225... logprob:  0.663550, 0.278646 (1.440 sec)
22.226... logprob:  0.641162, 0.277344 (1.419 sec)
22.227... logprob:  0.737412, 0.313802 (1.408 sec)
22.228... logprob:  0.581739, 0.264323 (1.408 sec)
22.229... logprob:  0.664163, 0.298177 (1.410 sec)
22.230... logprob:  0.623315, 0.248698 (1.422 sec)
22.231... logprob:  0.682436, 0.299479 (1.401 sec)
22.232... logprob:  0.690411, 0.309896 (1.455 sec)
22.233... logprob:  0.639632, 0.290365 (1.424 sec)
22.234... logprob:  0.715222, 0.329427 (1.409 sec)
22.235... logprob:  0.666497, 0.316406 (1.461 sec)
22.236... logprob:  0.632527, 0.264323 (1.397 sec)
22.237... logprob:  0.664985, 0.286458 (1.422 sec)
22.238... logprob:  0.647372, 0.270833 (1.417 sec)
22.239... logprob:  0.584983, 0.263021 (1.414 sec)
22.240... logprob:  0.774470, 0.294271 (1.401 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.474737, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.406441e-03 [1.704583e-07] 
Layer 'conv1' biases: 2.051569e-06 [1.297753e-10] 
Layer 'conv2' weights[0]: 3.399905e-03 [1.701113e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.147770e-09] 
Layer 'conv3' weights[0]: 3.398575e-03 [1.703120e-07] 
Layer 'conv3' biases: 3.401327e-05 [8.251740e-09] 
Layer 'conv4' weights[0]: 3.412858e-03 [1.712628e-07] 
Layer 'conv4' biases: 9.999273e-01 [1.793621e-07] 
Layer 'conv5' weights[0]: 3.533991e-03 [2.190806e-06] 
Layer 'conv5' biases: 9.991403e-01 [2.457999e-06] 
Layer 'fc6' weights[0]: 6.949620e-03 [6.291596e-08] 
Layer 'fc6' biases: 9.999915e-01 [5.733791e-08] 
Layer 'fc7' weights[0]: 7.298764e-03 [1.458699e-07] 
Layer 'fc7' biases: 9.997732e-01 [1.774214e-07] 
Layer 'fc8' weights[0]: 4.629534e-03 [1.391156e-05] 
Layer 'fc8' biases: 1.702759e-02 [1.939375e-05] 
Train error last 800 batches: 0.653346
-------------------------------------------------------
Not saving because 0.474737 > 0.299667 (9.300: -1.18%)
======================================================= (2.353 sec)
22.241... logprob:  0.786264, 0.332031 (1.457 sec)
22.242... logprob:  0.508018, 0.222656 (1.429 sec)
22.243... logprob:  0.606398, 0.268229 (1.430 sec)
22.244... logprob:  0.627028, 0.278646 (1.450 sec)
22.245... logprob:  0.670854, 0.265625 (1.416 sec)
22.246... logprob:  0.588058, 0.252604 (1.433 sec)
22.247... logprob:  0.568653, 0.278646 (1.420 sec)
22.248... logprob:  0.555219, 0.225260 (1.415 sec)
22.249... logprob:  0.747164, 0.325521 (1.424 sec)
22.250... logprob:  0.780354, 0.346354 (1.407 sec)
22.251... logprob:  0.626089, 0.268229 (1.452 sec)
22.252... logprob:  0.526298, 0.230469 (1.419 sec)
22.253... logprob:  0.586193, 0.253906 (1.410 sec)
22.254... logprob:  0.607170, 0.268229 (1.461 sec)
22.255... logprob:  0.578969, 0.276042 (1.394 sec)
22.256... logprob:  0.654528, 0.311198 (1.419 sec)
22.257... logprob:  0.570009, 0.266927 (1.413 sec)
22.258... logprob:  0.614374, 0.268229 (1.423 sec)
22.259... logprob:  0.710333, 0.315104 (1.395 sec)
22.260... logprob:  0.588186, 0.270833 (1.450 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.493710, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.403031e-03 [1.702628e-07] 
Layer 'conv1' biases: 2.052119e-06 [1.722883e-10] 
Layer 'conv2' weights[0]: 3.396506e-03 [1.700197e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.466676e-09] 
Layer 'conv3' weights[0]: 3.395196e-03 [1.704461e-07] 
Layer 'conv3' biases: 3.398362e-05 [1.036949e-08] 
Layer 'conv4' weights[0]: 3.409453e-03 [1.718233e-07] 
Layer 'conv4' biases: 9.999297e-01 [2.555421e-07] 
Layer 'conv5' weights[0]: 3.532544e-03 [2.926459e-06] 
Layer 'conv5' biases: 9.990976e-01 [3.156939e-06] 
Layer 'fc6' weights[0]: 6.948874e-03 [6.746685e-08] 
Layer 'fc6' biases: 9.999915e-01 [6.387902e-08] 
Layer 'fc7' weights[0]: 7.298068e-03 [1.567144e-07] 
Layer 'fc7' biases: 9.997758e-01 [2.434491e-07] 
Layer 'fc8' weights[0]: 4.723978e-03 [1.690561e-05] 
Layer 'fc8' biases: 1.785976e-02 [4.648101e-05] 
Train error last 800 batches: 0.653304
-------------------------------------------------------
Not saving because 0.493710 > 0.299667 (9.300: -1.18%)
======================================================= (2.348 sec)
22.261... logprob:  0.568450, 0.252604 (1.438 sec)
22.262... logprob:  0.788939, 0.326823 (1.426 sec)
22.263... logprob:  0.617800, 0.283854 (1.449 sec)
22.264... logprob:  0.584483, 0.259115 (1.413 sec)
22.265... logprob:  0.645224, 0.300781 (1.415 sec)
22.266... logprob:  0.648102, 0.296875 (1.417 sec)
22.267... logprob:  0.651102, 0.278646 (1.416 sec)
22.268... logprob:  0.632007, 0.261719 (1.432 sec)
22.269... logprob:  0.739810, 0.334635 (1.407 sec)
22.270... logprob:  0.696040, 0.296875 (1.453 sec)
22.271... logprob:  0.676443, 0.277344 (1.428 sec)
22.272... logprob:  0.544850, 0.250000 (1.417 sec)
22.273... logprob:  0.648052, 0.287760 (1.460 sec)
22.274... logprob:  0.670477, 0.312500 (1.393 sec)
22.275... logprob:  0.692147, 0.286458 (1.418 sec)
22.276... logprob:  0.564898, 0.253906 (1.407 sec)
22.277... logprob:  0.671611, 0.281250 (1.426 sec)
22.278... logprob:  0.556732, 0.248698 (1.416 sec)
22.279... logprob:  0.527852, 0.244792 (1.457 sec)
22.280... logprob:  0.467915, 0.218750 (1.394 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.433707, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.399637e-03 [1.701238e-07] 
Layer 'conv1' biases: 2.053474e-06 [1.240707e-10] 
Layer 'conv2' weights[0]: 3.393114e-03 [1.697811e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.130660e-09] 
Layer 'conv3' weights[0]: 3.391777e-03 [1.700651e-07] 
Layer 'conv3' biases: 3.397030e-05 [8.935539e-09] 
Layer 'conv4' weights[0]: 3.406026e-03 [1.712000e-07] 
Layer 'conv4' biases: 9.999298e-01 [2.041217e-07] 
Layer 'conv5' weights[0]: 3.529763e-03 [2.342986e-06] 
Layer 'conv5' biases: 9.991146e-01 [2.585321e-06] 
Layer 'fc6' weights[0]: 6.948187e-03 [6.255068e-08] 
Layer 'fc6' biases: 9.999914e-01 [5.730063e-08] 
Layer 'fc7' weights[0]: 7.297319e-03 [1.407416e-07] 
Layer 'fc7' biases: 9.997745e-01 [2.014156e-07] 
Layer 'fc8' weights[0]: 4.687259e-03 [1.400262e-05] 
Layer 'fc8' biases: 1.755947e-02 [3.109413e-05] 
Train error last 800 batches: 0.652600
-------------------------------------------------------
Not saving because 0.433707 > 0.299667 (9.300: -1.18%)
======================================================= (2.363 sec)
22.281... logprob:  0.664147, 0.302083 (1.434 sec)
22.282... logprob:  0.586141, 0.265625 (1.415 sec)
22.283... logprob:  0.651603, 0.259115 (1.408 sec)
22.284... logprob:  0.630112, 0.265625 (1.404 sec)
22.285... logprob:  0.718252, 0.286458 (1.454 sec)
22.286... logprob:  0.730702, 0.300781 (1.445 sec)
22.287... logprob:  0.628528, 0.317708 (1.423 sec)
22.288... logprob:  0.603409, 0.256510 (1.431 sec)
22.289... logprob:  0.631145, 0.298177 (1.444 sec)
22.290... logprob:  0.735341, 0.312500 (1.408 sec)
22.291... logprob:  0.618217, 0.277344 (1.413 sec)
22.292... logprob:  0.849567, 0.334635 (1.416 sec)
22.293... logprob:  0.662096, 0.305990 (1.416 sec)
22.294... logprob:  0.643805, 0.299479 (1.398 sec)
22.295... logprob:  0.605309, 0.269531 (1.463 sec)
22.296... logprob:  0.661129, 0.282552 (1.412 sec)
22.297... logprob:  0.606789, 0.265625 (1.419 sec)
22.298... logprob:  0.645999, 0.294271 (1.466 sec)
22.299... logprob:  0.565534, 0.242187 (1.397 sec)
22.300... logprob:  0.542225, 0.242187 (1.416 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.447982, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.396245e-03 [1.699874e-07] 
Layer 'conv1' biases: 2.054481e-06 [1.031061e-10] 
Layer 'conv2' weights[0]: 3.389726e-03 [1.696768e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.084906e-09] 
Layer 'conv3' weights[0]: 3.388389e-03 [1.698417e-07] 
Layer 'conv3' biases: 3.399421e-05 [7.757002e-09] 
Layer 'conv4' weights[0]: 3.402641e-03 [1.709859e-07] 
Layer 'conv4' biases: 9.999293e-01 [1.912571e-07] 
Layer 'conv5' weights[0]: 3.526221e-03 [2.026628e-06] 
Layer 'conv5' biases: 9.991252e-01 [2.155191e-06] 
Layer 'fc6' weights[0]: 6.947507e-03 [5.872059e-08] 
Layer 'fc6' biases: 9.999914e-01 [5.180216e-08] 
Layer 'fc7' weights[0]: 7.296610e-03 [1.329734e-07] 
Layer 'fc7' biases: 9.997730e-01 [1.626118e-07] 
Layer 'fc8' weights[0]: 4.653755e-03 [1.255001e-05] 
Layer 'fc8' biases: 1.735966e-02 [1.854014e-05] 
Train error last 800 batches: 0.652506
-------------------------------------------------------
Not saving because 0.447982 > 0.299667 (9.300: -1.18%)
======================================================= (2.388 sec)
22.301... logprob:  0.636231, 0.269531 (1.418 sec)
22.302... logprob:  0.710768, 0.320312 (1.419 sec)
22.303... logprob:  0.763406, 0.319010 (1.407 sec)
22.304... logprob:  0.691108, 0.343750 (1.436 sec)
22.305... logprob:  0.684519, 0.311198 (1.429 sec)
22.306... logprob:  0.638316, 0.291667 (1.427 sec)
22.307... logprob:  0.674011, 0.308594 (1.438 sec)
22.308... logprob:  0.657808, 0.294271 (1.443 sec)
22.309... logprob:  0.795263, 0.338542 (1.410 sec)
22.310... logprob:  0.739199, 0.365885 (1.425 sec)
22.311... logprob:  0.644493, 0.247396 (1.426 sec)
22.312... logprob:  0.663406, 0.311198 (1.419 sec)
22.313... logprob:  0.705280, 0.269531 (1.414 sec)
22.314... logprob:  0.727845, 0.290365 (1.462 sec)
22.315... logprob:  0.666538, 0.308594 (1.429 sec)
22.316... logprob:  0.663399, 0.291667 (1.420 sec)
22.317... logprob:  0.611602, 0.281250 (1.479 sec)
22.318... logprob:  0.649181, 0.283854 (1.411 sec)
22.319... logprob:  0.656708, 0.303385 (1.418 sec)
22.320... logprob:  0.614261, 0.253906 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.512138, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.392854e-03 [1.700000e-07] 
Layer 'conv1' biases: 2.054823e-06 [1.400179e-10] 
Layer 'conv2' weights[0]: 3.386316e-03 [1.695718e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.171454e-09] 
Layer 'conv3' weights[0]: 3.384994e-03 [1.697645e-07] 
Layer 'conv3' biases: 3.398885e-05 [8.844891e-09] 
Layer 'conv4' weights[0]: 3.399218e-03 [1.708232e-07] 
Layer 'conv4' biases: 9.999291e-01 [1.719035e-07] 
Layer 'conv5' weights[0]: 3.522879e-03 [2.313047e-06] 
Layer 'conv5' biases: 9.991308e-01 [2.414257e-06] 
Layer 'fc6' weights[0]: 6.946789e-03 [6.282006e-08] 
Layer 'fc6' biases: 9.999913e-01 [5.722891e-08] 
Layer 'fc7' weights[0]: 7.295901e-03 [1.394550e-07] 
Layer 'fc7' biases: 9.997724e-01 [1.696977e-07] 
Layer 'fc8' weights[0]: 4.629664e-03 [1.269028e-05] 
Layer 'fc8' biases: 1.725683e-02 [1.994490e-05] 
Train error last 800 batches: 0.653359
-------------------------------------------------------
Not saving because 0.512138 > 0.299667 (9.300: -1.18%)
======================================================= (2.379 sec)
22.321... logprob:  0.575516, 0.281250 (1.430 sec)
22.322... logprob:  0.601225, 0.273438 (1.421 sec)
22.323... logprob:  0.660886, 0.320312 (1.491 sec)
22.324... logprob:  0.666549, 0.298177 (1.436 sec)
22.325... logprob:  0.596148, 0.252604 (1.429 sec)
22.326... logprob:  0.753316, 0.298177 (1.458 sec)
22.327... logprob:  0.770325, 0.319010 (1.505 sec)
22.328... logprob:  0.742930, 0.317708 (1.419 sec)
22.329... logprob:  0.657590, 0.261719 (1.421 sec)
22.330... logprob:  0.694192, 0.291667 (1.418 sec)
22.331... logprob:  0.601138, 0.251302 (1.412 sec)
22.332... logprob:  0.658678, 0.309896 (1.441 sec)
22.333... logprob:  0.657935, 0.287760 (1.440 sec)
22.334... logprob:  0.786103, 0.354167 (1.442 sec)
22.335... logprob:  0.523220, 0.244792 (1.434 sec)
22.336... logprob:  0.686668, 0.305990 (1.452 sec)
22.337... logprob:  0.776146, 0.358073 (1.413 sec)
22.338... logprob:  0.628074, 0.257812 (1.422 sec)
22.339... logprob:  0.737780, 0.304688 (1.414 sec)
22.340... logprob:  0.720895, 0.332031 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.490407, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.389444e-03 [1.697564e-07] 
Layer 'conv1' biases: 2.054646e-06 [1.475498e-10] 
Layer 'conv2' weights[0]: 3.382936e-03 [1.692644e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.420161e-09] 
Layer 'conv3' weights[0]: 3.381607e-03 [1.696698e-07] 
Layer 'conv3' biases: 3.402992e-05 [9.996011e-09] 
Layer 'conv4' weights[0]: 3.395836e-03 [1.706403e-07] 
Layer 'conv4' biases: 9.999291e-01 [1.944617e-07] 
Layer 'conv5' weights[0]: 3.519457e-03 [2.334929e-06] 
Layer 'conv5' biases: 9.991348e-01 [2.494063e-06] 
Layer 'fc6' weights[0]: 6.946060e-03 [6.277859e-08] 
Layer 'fc6' biases: 9.999911e-01 [5.726249e-08] 
Layer 'fc7' weights[0]: 7.295147e-03 [1.447689e-07] 
Layer 'fc7' biases: 9.997720e-01 [1.787904e-07] 
Layer 'fc8' weights[0]: 4.619100e-03 [1.349196e-05] 
Layer 'fc8' biases: 1.715054e-02 [1.763499e-05] 
Train error last 800 batches: 0.653993
-------------------------------------------------------
Not saving because 0.490407 > 0.299667 (9.300: -1.18%)
======================================================= (2.362 sec)
22.341... logprob:  0.672531, 0.296875 (1.426 sec)
22.342... logprob:  0.710798, 0.294271 (1.466 sec)
22.343... logprob:  0.733377, 0.294271 (1.438 sec)
22.344... logprob:  0.746968, 0.320312 (1.478 sec)
22.345... logprob:  0.739597, 0.329427 (1.439 sec)
22.346... logprob:  0.656478, 0.270833 (1.430 sec)
22.347... logprob:  0.541722, 0.217448 (1.477 sec)
22.348... logprob:  0.653445, 0.290365 (1.428 sec)
22.349... logprob:  0.684832, 0.317708 (1.430 sec)
22.350... logprob:  0.620911, 0.276042 (1.434 sec)
22.351... logprob:  0.635711, 0.289062 (1.428 sec)
22.352... logprob:  0.670303, 0.283854 (1.426 sec)
22.353... logprob:  0.751207, 0.328125 (1.492 sec)
22.354... logprob:  0.791277, 0.341146 (1.424 sec)
22.355... logprob:  0.567671, 0.248698 (1.439 sec)
22.356... logprob:  0.603553, 0.257813 (1.471 sec)
22.357... logprob:  0.650754, 0.273437 (1.424 sec)
22.358... logprob:  0.531038, 0.229167 (1.431 sec)
22.359... logprob:  0.782018, 0.345052 (1.430 sec)
22.360... logprob:  0.713819, 0.326823 (1.423 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.466593, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.386068e-03 [1.693813e-07] 
Layer 'conv1' biases: 2.055364e-06 [1.296466e-10] 
Layer 'conv2' weights[0]: 3.379555e-03 [1.690619e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.149621e-09] 
Layer 'conv3' weights[0]: 3.378225e-03 [1.693085e-07] 
Layer 'conv3' biases: 3.405464e-05 [7.873962e-09] 
Layer 'conv4' weights[0]: 3.392441e-03 [1.704483e-07] 
Layer 'conv4' biases: 9.999305e-01 [1.851932e-07] 
Layer 'conv5' weights[0]: 3.517348e-03 [2.404474e-06] 
Layer 'conv5' biases: 9.991285e-01 [2.683589e-06] 
Layer 'fc6' weights[0]: 6.945352e-03 [6.478917e-08] 
Layer 'fc6' biases: 9.999912e-01 [5.980898e-08] 
Layer 'fc7' weights[0]: 7.294422e-03 [1.503890e-07] 
Layer 'fc7' biases: 9.997714e-01 [1.986287e-07] 
Layer 'fc8' weights[0]: 4.626223e-03 [1.482060e-05] 
Layer 'fc8' biases: 1.732097e-02 [2.933742e-05] 
Train error last 800 batches: 0.654548
-------------------------------------------------------
Not saving because 0.466593 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
22.361... logprob:  0.636252, 0.266927 (1.436 sec)
22.362... logprob:  0.611697, 0.265625 (1.480 sec)
22.363... logprob:  0.669512, 0.290365 (1.432 sec)
22.364... logprob:  0.676342, 0.285156 (1.449 sec)
22.365... logprob:  0.650540, 0.257812 (1.456 sec)
22.366... logprob:  0.559520, 0.238281 (1.437 sec)
22.367... logprob:  0.559208, 0.236979 (1.436 sec)
22.368... logprob:  0.815185, 0.328125 (1.428 sec)
22.369... logprob:  0.600252, 0.259115 (1.420 sec)
22.370... logprob:  0.576983, 0.225260 (1.429 sec)
22.371... logprob:  0.625848, 0.308594 (1.452 sec)
22.372... logprob:  0.824266, 0.356771 (1.447 sec)
22.373... logprob:  0.621984, 0.270833 (1.448 sec)
22.374... logprob:  0.704969, 0.300781 (1.441 sec)
22.375... logprob:  0.575524, 0.260417 (1.462 sec)
22.376... logprob:  0.535145, 0.212240 (1.438 sec)
22.377... logprob:  0.531799, 0.220052 (1.428 sec)
22.378... logprob:  0.676909, 0.281250 (1.430 sec)
22.379... logprob:  0.655983, 0.279948 (1.439 sec)
22.380... logprob:  0.728445, 0.313802 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.498770, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.382688e-03 [1.691674e-07] 
Layer 'conv1' biases: 2.056009e-06 [1.341714e-10] 
Layer 'conv2' weights[0]: 3.376170e-03 [1.688586e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.230849e-09] 
Layer 'conv3' weights[0]: 3.374854e-03 [1.691708e-07] 
Layer 'conv3' biases: 3.404775e-05 [8.899673e-09] 
Layer 'conv4' weights[0]: 3.389058e-03 [1.700793e-07] 
Layer 'conv4' biases: 9.999336e-01 [1.872976e-07] 
Layer 'conv5' weights[0]: 3.516020e-03 [2.334312e-06] 
Layer 'conv5' biases: 9.991153e-01 [2.436679e-06] 
Layer 'fc6' weights[0]: 6.944658e-03 [6.289029e-08] 
Layer 'fc6' biases: 9.999913e-01 [5.738661e-08] 
Layer 'fc7' weights[0]: 7.293674e-03 [1.449992e-07] 
Layer 'fc7' biases: 9.997722e-01 [1.875307e-07] 
Layer 'fc8' weights[0]: 4.652330e-03 [1.376943e-05] 
Layer 'fc8' biases: 1.749754e-02 [2.239902e-05] 
Train error last 800 batches: 0.653955
-------------------------------------------------------
Not saving because 0.498770 > 0.299667 (9.300: -1.18%)
======================================================= (2.363 sec)
22.381... logprob:  0.644686, 0.278646 (1.468 sec)
22.382... logprob:  0.652735, 0.298177 (1.450 sec)
22.383... logprob:  0.617497, 0.250000 (1.430 sec)
22.384... logprob:  0.774558, 0.335937 (1.479 sec)
22.385... logprob:  0.716011, 0.333333 (1.435 sec)
22.386... logprob:  0.784092, 0.322917 (1.426 sec)
22.387... logprob:  0.611908, 0.282552 (1.427 sec)
22.388... logprob:  0.671725, 0.296875 (1.430 sec)
22.389... logprob:  0.618174, 0.304687 (1.427 sec)
22.390... logprob:  0.643406, 0.286458 (1.481 sec)
22.391... logprob:  0.579981, 0.257812 (1.435 sec)
22.392... logprob:  0.716613, 0.272135 (1.427 sec)
22.393... logprob:  0.594128, 0.260417 (1.479 sec)
22.394... logprob:  0.668986, 0.304687 (1.425 sec)
22.395... logprob:  0.541995, 0.221354 (1.429 sec)
22.396... logprob:  0.514664, 0.234375 (1.436 sec)
22.397... logprob:  0.785722, 0.355469 (1.435 sec)
22.398... logprob:  0.754858, 0.304688 (1.429 sec)
22.399... logprob:  0.726087, 0.304688 (1.478 sec)
22.400... logprob:  0.635278, 0.264323 (1.432 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.415938, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.379306e-03 [1.692215e-07] 
Layer 'conv1' biases: 2.057396e-06 [1.317488e-10] 
Layer 'conv2' weights[0]: 3.372801e-03 [1.688359e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.494881e-09] 
Layer 'conv3' weights[0]: 3.371490e-03 [1.692872e-07] 
Layer 'conv3' biases: 3.404292e-05 [1.084580e-08] 
Layer 'conv4' weights[0]: 3.385672e-03 [1.704854e-07] 
Layer 'conv4' biases: 9.999332e-01 [2.219631e-07] 
Layer 'conv5' weights[0]: 3.512512e-03 [2.270834e-06] 
Layer 'conv5' biases: 9.991214e-01 [2.346683e-06] 
Layer 'fc6' weights[0]: 6.943950e-03 [6.322209e-08] 
Layer 'fc6' biases: 9.999912e-01 [5.775152e-08] 
Layer 'fc7' weights[0]: 7.292985e-03 [1.437917e-07] 
Layer 'fc7' biases: 9.997710e-01 [1.737764e-07] 
Layer 'fc8' weights[0]: 4.628733e-03 [1.343116e-05] 
Layer 'fc8' biases: 1.728083e-02 [1.659850e-05] 
Train error last 800 batches: 0.654551
-------------------------------------------------------
Not saving because 0.415938 > 0.299667 (9.300: -1.18%)
======================================================= (2.425 sec)
22.401... logprob:  0.703793, 0.307292 (1.440 sec)
22.402... logprob:  0.738551, 0.326823 (1.477 sec)
22.403... logprob:  0.649246, 0.303385 (1.434 sec)
22.404... logprob:  0.726259, 0.328125 (1.425 sec)
22.405... logprob:  0.789527, 0.332031 (1.432 sec)
22.406... logprob:  0.600101, 0.257813 (1.418 sec)
22.407... logprob:  0.695090, 0.302083 (1.430 sec)
22.408... logprob:  0.569072, 0.269531 (1.481 sec)
22.409... logprob:  0.647600, 0.305990 (1.433 sec)
22.410... logprob:  0.772812, 0.326823 (1.439 sec)
22.411... logprob:  0.556289, 0.244792 (1.470 sec)
22.412... logprob:  0.715619, 0.313802 (1.437 sec)
22.413... logprob:  0.738391, 0.321615 (1.428 sec)
22.414... logprob:  0.685916, 0.308594 (1.431 sec)
22.415... logprob:  0.575996, 0.277344 (1.421 sec)
22.416... logprob:  0.618146, 0.281250 (1.431 sec)
22.417... logprob:  0.600588, 0.274740 (1.459 sec)
22.418... logprob:  0.538323, 0.234375 (1.445 sec)
22.419... logprob:  0.691396, 0.320312 (1.445 sec)
22.420... logprob:  0.612313, 0.272135 (1.448 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.482526, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.375918e-03 [1.689627e-07] 
Layer 'conv1' biases: 2.058102e-06 [1.664789e-10] 
Layer 'conv2' weights[0]: 3.369434e-03 [1.686508e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.459031e-09] 
Layer 'conv3' weights[0]: 3.368137e-03 [1.691244e-07] 
Layer 'conv3' biases: 3.403724e-05 [1.147237e-08] 
Layer 'conv4' weights[0]: 3.382275e-03 [1.706029e-07] 
Layer 'conv4' biases: 9.999347e-01 [2.614663e-07] 
Layer 'conv5' weights[0]: 3.510478e-03 [3.440649e-06] 
Layer 'conv5' biases: 9.991133e-01 [3.775199e-06] 
Layer 'fc6' weights[0]: 6.943265e-03 [8.012702e-08] 
Layer 'fc6' biases: 9.999911e-01 [8.007511e-08] 
Layer 'fc7' weights[0]: 7.292233e-03 [1.990066e-07] 
Layer 'fc7' biases: 9.997719e-01 [3.580031e-07] 
Layer 'fc8' weights[0]: 4.641239e-03 [2.251757e-05] 
Layer 'fc8' biases: 1.750577e-02 [6.501528e-05] 
Train error last 800 batches: 0.654301
-------------------------------------------------------
Not saving because 0.482526 > 0.299667 (9.300: -1.18%)
======================================================= (2.354 sec)
22.421... logprob:  0.627751, 0.272135 (1.457 sec)
22.422... logprob:  0.762317, 0.326823 (1.440 sec)
22.423... logprob:  0.616318, 0.248698 (1.428 sec)
22.424... logprob:  0.587259, 0.256510 (1.430 sec)
22.425... logprob:  0.540360, 0.261719 (1.433 sec)
22.426... logprob:  0.756152, 0.337240 (1.447 sec)
22.427... logprob:  0.756727, 0.326823 (1.456 sec)
22.428... logprob:  0.653224, 0.289062 (1.455 sec)
22.429... logprob:  0.674606, 0.278646 (1.445 sec)
22.430... logprob:  0.546949, 0.217448 (1.467 sec)
22.431... logprob:  0.806027, 0.337240 (1.428 sec)
22.432... logprob:  0.600963, 0.287760 (1.420 sec)
22.433... logprob:  0.621042, 0.294271 (1.426 sec)
22.434... logprob:  0.717222, 0.279948 (1.431 sec)
22.435... logprob:  0.761705, 0.309896 (1.425 sec)
22.436... logprob:  0.584212, 0.260417 (1.469 sec)
22.437... logprob:  0.764701, 0.308594 (1.442 sec)
22.438... logprob:  0.758065, 0.320312 (1.432 sec)
22.439... logprob:  0.692182, 0.287760 (1.505 sec)
22.440... logprob:  0.672019, 0.302083 (1.425 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.464995, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.372561e-03 [1.686487e-07] 
Layer 'conv1' biases: 2.059465e-06 [1.779800e-10] 
Layer 'conv2' weights[0]: 3.366081e-03 [1.683466e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.974808e-09] 
Layer 'conv3' weights[0]: 3.364732e-03 [1.692734e-07] 
Layer 'conv3' biases: 3.406486e-05 [1.461524e-08] 
Layer 'conv4' weights[0]: 3.378894e-03 [1.705572e-07] 
Layer 'conv4' biases: 9.999335e-01 [3.495199e-07] 
Layer 'conv5' weights[0]: 3.506626e-03 [3.513821e-06] 
Layer 'conv5' biases: 9.991194e-01 [3.895932e-06] 
Layer 'fc6' weights[0]: 6.942543e-03 [7.858904e-08] 
Layer 'fc6' biases: 9.999911e-01 [7.842912e-08] 
Layer 'fc7' weights[0]: 7.291517e-03 [1.869935e-07] 
Layer 'fc7' biases: 9.997714e-01 [3.136976e-07] 
Layer 'fc8' weights[0]: 4.631265e-03 [1.982980e-05] 
Layer 'fc8' biases: 1.743939e-02 [5.525085e-05] 
Train error last 800 batches: 0.654431
-------------------------------------------------------
Not saving because 0.464995 > 0.299667 (9.300: -1.18%)
======================================================= (2.343 sec)
22.441... logprob:  0.670942, 0.292969 (1.433 sec)
22.442... logprob:  0.628111, 0.273437 (1.438 sec)
22.443... logprob:  0.705172, 0.321615 (1.431 sec)
22.444... logprob:  0.657228, 0.302083 (1.422 sec)
22.445... logprob:  0.566722, 0.229167 (1.489 sec)
22.446... logprob:  0.681521, 0.290365 (1.431 sec)
22.447... logprob:  0.705718, 0.300781 (1.432 sec)
22.448... logprob:  0.638334, 0.263021 (1.475 sec)
22.449... logprob:  0.661857, 0.289063 (1.426 sec)
22.450... logprob:  0.504316, 0.204427 (1.428 sec)
22.451... logprob:  0.682965, 0.315104 (1.426 sec)
22.452... logprob:  0.631300, 0.283854 (1.428 sec)
22.453... logprob:  0.681380, 0.300781 (1.435 sec)
22.454... logprob:  0.657645, 0.296875 (1.479 sec)
22.455... logprob:  0.677659, 0.334635 (1.434 sec)
22.456... logprob:  0.638075, 0.286458 (1.450 sec)
22.457... logprob:  0.630926, 0.265625 (1.472 sec)
22.458... logprob:  0.603613, 0.261719 (1.429 sec)
22.459... logprob:  0.723281, 0.308594 (1.439 sec)
22.460... logprob:  0.520718, 0.217448 (1.422 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.476020, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.369198e-03 [1.687312e-07] 
Layer 'conv1' biases: 2.060427e-06 [1.203728e-10] 
Layer 'conv2' weights[0]: 3.362709e-03 [1.683140e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.282731e-09] 
Layer 'conv3' weights[0]: 3.361383e-03 [1.687296e-07] 
Layer 'conv3' biases: 3.408675e-05 [1.023971e-08] 
Layer 'conv4' weights[0]: 3.375519e-03 [1.698865e-07] 
Layer 'conv4' biases: 9.999344e-01 [2.280762e-07] 
Layer 'conv5' weights[0]: 3.504046e-03 [2.636948e-06] 
Layer 'conv5' biases: 9.991142e-01 [2.965704e-06] 
Layer 'fc6' weights[0]: 6.941821e-03 [6.675720e-08] 
Layer 'fc6' biases: 9.999912e-01 [6.218595e-08] 
Layer 'fc7' weights[0]: 7.290770e-03 [1.552806e-07] 
Layer 'fc7' biases: 9.997714e-01 [2.215386e-07] 
Layer 'fc8' weights[0]: 4.632575e-03 [1.554754e-05] 
Layer 'fc8' biases: 1.743975e-02 [3.853457e-05] 
Train error last 800 batches: 0.654849
-------------------------------------------------------
Not saving because 0.476020 > 0.299667 (9.300: -1.18%)
======================================================= (2.416 sec)
22.461... logprob:  0.682619, 0.287760 (1.427 sec)
22.462... logprob:  0.679215, 0.302083 (1.436 sec)
22.463... logprob:  0.588258, 0.243490 (1.469 sec)
22.464... logprob:  0.747808, 0.315104 (1.444 sec)
22.465... logprob:  0.634672, 0.279948 (1.457 sec)
22.466... logprob:  0.569125, 0.255208 (1.460 sec)
22.467... logprob:  0.632889, 0.259115 (1.444 sec)
22.468... logprob:  0.613788, 0.242187 (1.438 sec)
22.469... logprob:  0.497618, 0.223958 (1.422 sec)
22.470... logprob:  0.682801, 0.299479 (1.424 sec)
22.471... logprob:  0.752998, 0.320312 (1.439 sec)
22.472... logprob:  0.577858, 0.259115 (1.455 sec)
22.473... logprob:  0.578441, 0.248698 (1.456 sec)
22.474... logprob:  0.721340, 0.295573 (1.449 sec)
22.475... logprob:  0.717074, 0.307292 (1.447 sec)
22.476... logprob:  0.753886, 0.320312 (1.474 sec)
22.477... logprob:  0.594496, 0.272135 (1.450 sec)
22.478... logprob:  0.690278, 0.313802 (1.419 sec)
22.479... logprob:  0.545556, 0.250000 (1.428 sec)
22.480... logprob:  0.610286, 0.272135 (1.432 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.487171, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.365828e-03 [1.684624e-07] 
Layer 'conv1' biases: 2.060927e-06 [1.350123e-10] 
Layer 'conv2' weights[0]: 3.359343e-03 [1.681031e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.344920e-09] 
Layer 'conv3' weights[0]: 3.358017e-03 [1.685344e-07] 
Layer 'conv3' biases: 3.409282e-05 [9.789129e-09] 
Layer 'conv4' weights[0]: 3.372153e-03 [1.697446e-07] 
Layer 'conv4' biases: 9.999356e-01 [2.308769e-07] 
Layer 'conv5' weights[0]: 3.501335e-03 [2.520820e-06] 
Layer 'conv5' biases: 9.991034e-01 [2.761584e-06] 
Layer 'fc6' weights[0]: 6.941114e-03 [6.289824e-08] 
Layer 'fc6' biases: 9.999912e-01 [5.773062e-08] 
Layer 'fc7' weights[0]: 7.290032e-03 [1.456177e-07] 
Layer 'fc7' biases: 9.997718e-01 [1.979659e-07] 
Layer 'fc8' weights[0]: 4.648023e-03 [1.623312e-05] 
Layer 'fc8' biases: 1.763595e-02 [3.538966e-05] 
Train error last 800 batches: 0.654529
-------------------------------------------------------
Not saving because 0.487171 > 0.299667 (9.300: -1.18%)
======================================================= (2.360 sec)
22.481... logprob:  0.798969, 0.337240 (1.438 sec)
22.482... logprob:  0.606223, 0.272135 (1.473 sec)
22.483... logprob:  0.673585, 0.305990 (1.445 sec)
22.484... logprob:  0.735286, 0.347656 (1.434 sec)
22.485... logprob:  0.631545, 0.279948 (1.475 sec)
22.486... logprob:  0.691387, 0.296875 (1.430 sec)
22.487... logprob:  0.690459, 0.278646 (1.423 sec)
22.488... logprob:  0.656895, 0.290365 (1.436 sec)
22.489... logprob:  0.604327, 0.268229 (1.426 sec)
22.490... logprob:  0.653826, 0.302083 (1.430 sec)
22.491... logprob:  0.579080, 0.270833 (1.480 sec)
22.492... logprob:  0.732236, 0.308594 (1.433 sec)
22.493... logprob:  0.733134, 0.303385 (1.432 sec)
22.494... logprob:  0.674852, 0.311198 (1.490 sec)
22.495... logprob:  0.518562, 0.242187 (1.427 sec)
22.496... logprob:  0.771203, 0.341146 (1.431 sec)
22.497... logprob:  0.628646, 0.307292 (1.435 sec)
22.498... logprob:  0.594666, 0.244792 (1.427 sec)
22.499... logprob:  0.650518, 0.289062 (1.432 sec)
22.500... logprob:  0.626495, 0.266927 (1.486 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.572844, 0.171875 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.362443e-03 [1.683753e-07] 
Layer 'conv1' biases: 2.061553e-06 [1.567441e-10] 
Layer 'conv2' weights[0]: 3.355982e-03 [1.680621e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.560939e-09] 
Layer 'conv3' weights[0]: 3.354654e-03 [1.686550e-07] 
Layer 'conv3' biases: 3.412095e-05 [1.212079e-08] 
Layer 'conv4' weights[0]: 3.368764e-03 [1.702225e-07] 
Layer 'conv4' biases: 9.999333e-01 [2.768861e-07] 
Layer 'conv5' weights[0]: 3.497128e-03 [2.837947e-06] 
Layer 'conv5' biases: 9.990995e-01 [3.053246e-06] 
Layer 'fc6' weights[0]: 6.940409e-03 [6.306950e-08] 
Layer 'fc6' biases: 9.999912e-01 [5.821417e-08] 
Layer 'fc7' weights[0]: 7.289308e-03 [1.453553e-07] 
Layer 'fc7' biases: 9.997711e-01 [2.005693e-07] 
Layer 'fc8' weights[0]: 4.662842e-03 [1.373247e-05] 
Layer 'fc8' biases: 1.774339e-02 [3.082230e-05] 
Train error last 800 batches: 0.654274
-------------------------------------------------------
Not saving because 0.572844 > 0.299667 (9.300: -1.18%)
======================================================= (2.358 sec)
22.501... logprob:  0.564012, 0.253906 (1.436 sec)
22.502... logprob:  0.674323, 0.287760 (1.447 sec)
22.503... logprob:  0.590093, 0.261719 (1.486 sec)
22.504... logprob:  0.696717, 0.278646 (1.428 sec)
22.505... logprob:  0.793878, 0.328125 (1.440 sec)
22.506... logprob:  0.620112, 0.257812 (1.431 sec)
22.507... logprob:  0.514309, 0.238281 (1.422 sec)
22.508... logprob:  0.671043, 0.302083 (1.432 sec)
22.509... logprob:  0.505423, 0.240885 (1.469 sec)
22.510... logprob:  0.626262, 0.283854 (1.439 sec)
22.511... logprob:  0.540472, 0.257812 (1.446 sec)
22.512... logprob:  0.718250, 0.316406 (1.465 sec)
22.513... logprob:  0.606269, 0.276042 (1.438 sec)
22.514... logprob:  0.624738, 0.260417 (1.433 sec)
22.515... logprob:  0.624804, 0.292969 (1.456 sec)
22.516... logprob:  0.669103, 0.298177 (1.418 sec)
22.517... logprob:  0.758571, 0.339844 (1.429 sec)
22.518... logprob:  0.663919, 0.285156 (1.456 sec)
22.519... logprob:  0.717524, 0.315104 (1.456 sec)
22.520... logprob:  0.699183, 0.315104 (1.455 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.463997, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.359094e-03 [1.679423e-07] 
Layer 'conv1' biases: 2.062526e-06 [1.235243e-10] 
Layer 'conv2' weights[0]: 3.352625e-03 [1.677037e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.318772e-09] 
Layer 'conv3' weights[0]: 3.351286e-03 [1.680636e-07] 
Layer 'conv3' biases: 3.412424e-05 [9.756224e-09] 
Layer 'conv4' weights[0]: 3.365384e-03 [1.689413e-07] 
Layer 'conv4' biases: 9.999321e-01 [2.297551e-07] 
Layer 'conv5' weights[0]: 3.493153e-03 [2.524852e-06] 
Layer 'conv5' biases: 9.990795e-01 [2.792292e-06] 
Layer 'fc6' weights[0]: 6.939662e-03 [6.336045e-08] 
Layer 'fc6' biases: 9.999912e-01 [5.938025e-08] 
Layer 'fc7' weights[0]: 7.288566e-03 [1.451437e-07] 
Layer 'fc7' biases: 9.997724e-01 [1.852749e-07] 
Layer 'fc8' weights[0]: 4.716990e-03 [1.324274e-05] 
Layer 'fc8' biases: 1.817982e-02 [2.221982e-05] 
Train error last 800 batches: 0.654226
-------------------------------------------------------
Not saving because 0.463997 > 0.299667 (9.300: -1.18%)
======================================================= (2.352 sec)
22.521... logprob:  0.651414, 0.298177 (1.450 sec)
22.522... logprob:  0.681803, 0.276042 (1.461 sec)
22.523... logprob:  0.575828, 0.270833 (1.434 sec)
22.524... logprob:  0.692750, 0.302083 (1.425 sec)
22.525... logprob:  0.634365, 0.277344 (1.424 sec)
22.526... logprob:  0.611523, 0.299479 (1.431 sec)
22.527... logprob:  0.748369, 0.300781 (1.432 sec)
22.528... logprob:  0.665811, 0.290364 (1.462 sec)
22.529... logprob:  0.584555, 0.229167 (1.447 sec)
22.530... logprob:  0.661546, 0.294271 (1.437 sec)
22.531... logprob:  0.742342, 0.329427 (1.474 sec)
22.532... logprob:  0.692945, 0.302083 (1.430 sec)
22.533... logprob:  0.727886, 0.315104 (1.427 sec)
22.534... logprob:  0.583246, 0.274739 (1.425 sec)
22.535... logprob:  0.721790, 0.300781 (1.432 sec)
22.536... logprob:  0.774867, 0.356771 (1.430 sec)
22.537... logprob:  0.740723, 0.296875 (1.478 sec)
22.538... logprob:  0.732216, 0.307292 (1.441 sec)
22.539... logprob:  0.502461, 0.209635 (1.432 sec)
22.540... logprob:  0.765755, 0.316406 (1.487 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.497038, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.355738e-03 [1.678106e-07] 
Layer 'conv1' biases: 2.063551e-06 [1.292169e-10] 
Layer 'conv2' weights[0]: 3.349252e-03 [1.676022e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.405004e-09] 
Layer 'conv3' weights[0]: 3.347942e-03 [1.679041e-07] 
Layer 'conv3' biases: 3.415109e-05 [9.667395e-09] 
Layer 'conv4' weights[0]: 3.362063e-03 [1.688654e-07] 
Layer 'conv4' biases: 9.999313e-01 [2.133515e-07] 
Layer 'conv5' weights[0]: 3.489333e-03 [3.035702e-06] 
Layer 'conv5' biases: 9.991166e-01 [3.351031e-06] 
Layer 'fc6' weights[0]: 6.938993e-03 [6.949423e-08] 
Layer 'fc6' biases: 9.999912e-01 [6.672477e-08] 
Layer 'fc7' weights[0]: 7.287852e-03 [1.657012e-07] 
Layer 'fc7' biases: 9.997700e-01 [2.477228e-07] 
Layer 'fc8' weights[0]: 4.624967e-03 [1.699410e-05] 
Layer 'fc8' biases: 1.745808e-02 [3.723440e-05] 
Train error last 800 batches: 0.654443
-------------------------------------------------------
Not saving because 0.497038 > 0.299667 (9.300: -1.18%)
======================================================= (2.358 sec)
22.541... logprob:  0.601200, 0.263021 (1.433 sec)
22.542... logprob:  0.579257, 0.235677 (1.425 sec)
22.543... logprob:  0.523178, 0.256510 (1.435 sec)
22.544... logprob:  0.648153, 0.282552 (1.426 sec)
22.545... logprob:  0.512550, 0.231771 (1.427 sec)
22.546... logprob:  0.544474, 0.236979 (1.479 sec)
22.547... logprob:  0.737164, 0.283854 (1.427 sec)
22.548... logprob:  0.637034, 0.285156 (1.435 sec)
22.549... logprob:  0.722652, 0.329427 (1.472 sec)
22.550... logprob:  0.555480, 0.244792 (1.430 sec)
22.551... logprob:  0.567926, 0.259115 (1.431 sec)
22.552... logprob:  0.711230, 0.309896 (1.434 sec)
22.553... logprob:  0.562085, 0.239583 (1.452 sec)
22.554... logprob:  0.674260, 0.302083 (1.434 sec)
22.555... logprob:  0.598585, 0.260417 (1.477 sec)
22.556... logprob:  0.557929, 0.242187 (1.430 sec)
22.557... logprob:  0.582758, 0.236979 (1.443 sec)
22.558... logprob:  0.635379, 0.281250 (1.466 sec)
22.559... logprob:  0.787230, 0.348958 (1.427 sec)
22.560... logprob:  0.496631, 0.229167 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.480366, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.352380e-03 [1.676916e-07] 
Layer 'conv1' biases: 2.064604e-06 [1.356493e-10] 
Layer 'conv2' weights[0]: 3.345920e-03 [1.674196e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.337900e-09] 
Layer 'conv3' weights[0]: 3.344590e-03 [1.677413e-07] 
Layer 'conv3' biases: 3.414313e-05 [9.699792e-09] 
Layer 'conv4' weights[0]: 3.358687e-03 [1.689669e-07] 
Layer 'conv4' biases: 9.999313e-01 [2.235805e-07] 
Layer 'conv5' weights[0]: 3.486334e-03 [2.979941e-06] 
Layer 'conv5' biases: 9.990835e-01 [3.259584e-06] 
Layer 'fc6' weights[0]: 6.938256e-03 [6.680474e-08] 
Layer 'fc6' biases: 9.999909e-01 [6.307351e-08] 
Layer 'fc7' weights[0]: 7.287156e-03 [1.576245e-07] 
Layer 'fc7' biases: 9.997721e-01 [2.385039e-07] 
Layer 'fc8' weights[0]: 4.710903e-03 [1.710060e-05] 
Layer 'fc8' biases: 1.808566e-02 [4.053817e-05] 
Train error last 800 batches: 0.654295
-------------------------------------------------------
Not saving because 0.480366 > 0.299667 (9.300: -1.18%)
======================================================= (2.350 sec)
22.561... logprob:  0.553803, 0.242187 (1.434 sec)
22.562... logprob:  0.710009, 0.299479 (1.422 sec)
22.563... logprob:  0.542908, 0.243490 (1.433 sec)
22.564... logprob:  0.678394, 0.312500 (1.465 sec)
22.565... logprob:  0.788925, 0.286458 (1.450 sec)
22.566... logprob:  0.594469, 0.270833 (1.453 sec)
22.567... logprob:  0.644059, 0.277344 (1.450 sec)
22.568... logprob:  0.768432, 0.299479 (1.456 sec)
22.569... logprob:  0.609794, 0.276042 (1.430 sec)
22.570... logprob:  0.798628, 0.348958 (1.423 sec)
22.571... logprob:  0.658125, 0.276042 (1.432 sec)
22.572... logprob:  0.769295, 0.312500 (1.437 sec)
22.573... logprob:  0.715960, 0.321615 (1.439 sec)
22.574... logprob:  0.650033, 0.283854 (1.457 sec)
22.575... logprob:  0.536781, 0.250000 (1.446 sec)
22.576... logprob:  0.588433, 0.270833 (1.444 sec)
22.577... logprob:  0.705184, 0.277344 (1.468 sec)
22.578... logprob:  0.559246, 0.250000 (1.428 sec)
22.579... logprob:  0.647619, 0.292969 (1.419 sec)
22.580... logprob:  0.712932, 0.312500 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.514140, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.349032e-03 [1.675280e-07] 
Layer 'conv1' biases: 2.064924e-06 [1.195533e-10] 
Layer 'conv2' weights[0]: 3.342590e-03 [1.672087e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.696724e-09] 
Layer 'conv3' weights[0]: 3.341272e-03 [1.678437e-07] 
Layer 'conv3' biases: 3.417549e-05 [1.251912e-08] 
Layer 'conv4' weights[0]: 3.355327e-03 [1.692361e-07] 
Layer 'conv4' biases: 9.999325e-01 [2.881727e-07] 
Layer 'conv5' weights[0]: 3.483913e-03 [2.854015e-06] 
Layer 'conv5' biases: 9.991117e-01 [3.039174e-06] 
Layer 'fc6' weights[0]: 6.937529e-03 [6.586402e-08] 
Layer 'fc6' biases: 9.999911e-01 [6.205077e-08] 
Layer 'fc7' weights[0]: 7.286422e-03 [1.539635e-07] 
Layer 'fc7' biases: 9.997696e-01 [2.215665e-07] 
Layer 'fc8' weights[0]: 4.657469e-03 [1.728096e-05] 
Layer 'fc8' biases: 1.761792e-02 [4.597848e-05] 
Train error last 800 batches: 0.654453
-------------------------------------------------------
Not saving because 0.514140 > 0.299667 (9.300: -1.18%)
======================================================= (2.394 sec)
22.581... logprob:  0.764131, 0.332031 (1.440 sec)
22.582... logprob:  0.756693, 0.348958 (1.437 sec)
22.583... logprob:  0.762854, 0.307292 (1.476 sec)
22.584... logprob:  0.703996, 0.276042 (1.438 sec)
22.585... logprob:  0.674247, 0.285156 (1.427 sec)
22.586... logprob:  0.620119, 0.274740 (1.479 sec)
22.587... logprob:  0.642549, 0.294271 (1.428 sec)
22.588... logprob:  0.643685, 0.300781 (1.428 sec)
22.589... logprob:  0.632603, 0.286458 (1.429 sec)
22.590... logprob:  0.731762, 0.296875 (1.425 sec)
22.591... logprob:  0.666507, 0.277344 (1.434 sec)
22.592... logprob:  0.708834, 0.290365 (1.488 sec)
22.593... logprob:  0.677663, 0.309896 (1.430 sec)
22.594... logprob:  0.533871, 0.234375 (1.433 sec)
22.595... logprob:  0.616518, 0.273437 (1.476 sec)
22.596... logprob:  0.656078, 0.311198 (1.433 sec)
22.597... logprob:  0.622209, 0.282552 (1.434 sec)
22.598... logprob:  0.663917, 0.285156 (1.430 sec)
22.599... logprob:  0.532707, 0.250000 (1.422 sec)
22.600... logprob:  0.542555, 0.246094 (1.425 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.500299, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.345698e-03 [1.675710e-07] 
Layer 'conv1' biases: 2.064470e-06 [1.187124e-10] 
Layer 'conv2' weights[0]: 3.339253e-03 [1.671580e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.489614e-09] 
Layer 'conv3' weights[0]: 3.337932e-03 [1.675502e-07] 
Layer 'conv3' biases: 3.417812e-05 [1.049249e-08] 
Layer 'conv4' weights[0]: 3.351959e-03 [1.691772e-07] 
Layer 'conv4' biases: 9.999336e-01 [2.874882e-07] 
Layer 'conv5' weights[0]: 3.481750e-03 [3.817896e-06] 
Layer 'conv5' biases: 9.991167e-01 [4.165723e-06] 
Layer 'fc6' weights[0]: 6.936825e-03 [8.029889e-08] 
Layer 'fc6' biases: 9.999906e-01 [8.073206e-08] 
Layer 'fc7' weights[0]: 7.285679e-03 [1.971833e-07] 
Layer 'fc7' biases: 9.997696e-01 [3.597916e-07] 
Layer 'fc8' weights[0]: 4.653463e-03 [2.184381e-05] 
Layer 'fc8' biases: 1.761749e-02 [6.567208e-05] 
Train error last 800 batches: 0.654664
-------------------------------------------------------
Not saving because 0.500299 > 0.299667 (9.300: -1.18%)
======================================================= (2.347 sec)
22.601... logprob:  0.617232, 0.239583 (1.483 sec)
22.602... logprob:  0.510277, 0.205729 (1.431 sec)
22.603... logprob:  0.516250, 0.235677 (1.454 sec)
22.604... logprob:  0.659718, 0.283854 (1.466 sec)
22.605... logprob:  0.626251, 0.268229 (1.432 sec)
22.606... logprob:  0.528282, 0.248698 (1.437 sec)
22.607... logprob:  0.775553, 0.332031 (1.429 sec)
22.608... logprob:  0.579938, 0.253906 (1.425 sec)
22.609... logprob:  0.601078, 0.264323 (1.428 sec)
22.610... logprob:  0.641946, 0.278646 (1.462 sec)
22.611... logprob:  0.748452, 0.322917 (1.439 sec)
22.612... logprob:  0.642386, 0.303385 (1.453 sec)
22.613... logprob:  0.536962, 0.234375 (1.461 sec)
22.614... logprob:  0.743427, 0.320312 (1.446 sec)
22.615... logprob:  0.568955, 0.265625 (1.433 sec)
22.616... logprob:  0.680127, 0.309896 (1.421 sec)
22.617... logprob:  0.634055, 0.282552 (1.418 sec)
22.618... logprob:  0.707439, 0.308594 (1.437 sec)
22.619... logprob:  0.750084, 0.326823 (1.451 sec)
22.620... logprob:  0.650697, 0.264323 (1.451 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.397556, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.342346e-03 [1.671980e-07] 
Layer 'conv1' biases: 2.064504e-06 [1.410399e-10] 
Layer 'conv2' weights[0]: 3.335905e-03 [1.668829e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.787369e-09] 
Layer 'conv3' weights[0]: 3.334585e-03 [1.676214e-07] 
Layer 'conv3' biases: 3.416692e-05 [1.274632e-08] 
Layer 'conv4' weights[0]: 3.348632e-03 [1.686971e-07] 
Layer 'conv4' biases: 9.999354e-01 [3.032450e-07] 
Layer 'conv5' weights[0]: 3.479561e-03 [3.089542e-06] 
Layer 'conv5' biases: 9.990928e-01 [3.336301e-06] 
Layer 'fc6' weights[0]: 6.936090e-03 [7.273231e-08] 
Layer 'fc6' biases: 9.999907e-01 [7.110530e-08] 
Layer 'fc7' weights[0]: 7.284894e-03 [1.704767e-07] 
Layer 'fc7' biases: 9.997711e-01 [2.738404e-07] 
Layer 'fc8' weights[0]: 4.718897e-03 [1.739678e-05] 
Layer 'fc8' biases: 1.822855e-02 [3.771580e-05] 
Train error last 800 batches: 0.654677
-------------------------------------------------------
Not saving because 0.397556 > 0.299667 (9.300: -1.18%)
======================================================= (2.355 sec)
22.621... logprob:  0.613973, 0.287760 (1.449 sec)
22.622... logprob:  0.575476, 0.272135 (1.443 sec)
22.623... logprob:  0.625651, 0.278646 (1.465 sec)
22.624... logprob:  0.582422, 0.274740 (1.436 sec)
22.625... logprob:  0.598403, 0.279948 (1.420 sec)
22.626... logprob:  0.730527, 0.313802 (1.434 sec)
22.627... logprob:  0.648521, 0.270833 (1.438 sec)
22.628... logprob:  0.625353, 0.300781 (1.440 sec)
22.629... logprob:  0.606950, 0.259115 (1.470 sec)
22.630... logprob:  0.599504, 0.266927 (1.452 sec)
22.631... logprob:  0.761069, 0.311198 (1.438 sec)
22.632... logprob:  0.590054, 0.268229 (1.472 sec)
22.633... logprob:  0.639199, 0.276042 (1.429 sec)
22.634... logprob:  0.746055, 0.316406 (1.423 sec)
22.635... logprob:  0.661907, 0.274740 (1.429 sec)
22.636... logprob:  0.678133, 0.312500 (1.428 sec)
22.637... logprob:  0.549484, 0.264323 (1.436 sec)
22.638... logprob:  0.757532, 0.322917 (1.479 sec)
22.639... logprob:  0.675998, 0.285156 (1.432 sec)
22.640... logprob:  0.734749, 0.291667 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.444404, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.339024e-03 [1.669714e-07] 
Layer 'conv1' biases: 2.064311e-06 [1.469879e-10] 
Layer 'conv2' weights[0]: 3.332581e-03 [1.666984e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.359270e-09] 
Layer 'conv3' weights[0]: 3.331240e-03 [1.671611e-07] 
Layer 'conv3' biases: 3.415671e-05 [9.385015e-09] 
Layer 'conv4' weights[0]: 3.345297e-03 [1.681147e-07] 
Layer 'conv4' biases: 9.999332e-01 [2.404393e-07] 
Layer 'conv5' weights[0]: 3.475566e-03 [3.060014e-06] 
Layer 'conv5' biases: 9.991184e-01 [3.395019e-06] 
Layer 'fc6' weights[0]: 6.935368e-03 [7.227304e-08] 
Layer 'fc6' biases: 9.999907e-01 [6.979242e-08] 
Layer 'fc7' weights[0]: 7.284149e-03 [1.676723e-07] 
Layer 'fc7' biases: 9.997693e-01 [2.608216e-07] 
Layer 'fc8' weights[0]: 4.659411e-03 [1.735505e-05] 
Layer 'fc8' biases: 1.780024e-02 [4.068153e-05] 
Train error last 800 batches: 0.654372
-------------------------------------------------------
Not saving because 0.444404 > 0.299667 (9.300: -1.18%)
======================================================= (2.411 sec)
22.641... logprob:  0.660637, 0.295573 (1.487 sec)
22.642... logprob:  0.685897, 0.303385 (1.435 sec)
22.643... logprob:  0.758341, 0.321615 (1.432 sec)
22.644... logprob:  0.531371, 0.252604 (1.427 sec)
22.645... logprob:  0.648422, 0.291667 (1.427 sec)
22.646... logprob:  0.633138, 0.290364 (1.432 sec)
22.647... logprob:  0.643452, 0.279948 (1.490 sec)
22.648... logprob:  0.736554, 0.329427 (1.432 sec)
22.649... logprob:  0.605920, 0.300781 (1.437 sec)
22.650... logprob:  0.587057, 0.260417 (1.472 sec)
22.651... logprob:  0.609479, 0.281250 (1.420 sec)
22.652... logprob:  0.725515, 0.289062 (1.436 sec)
22.653... logprob:  0.725043, 0.311198 (1.427 sec)
22.654... logprob:  0.757043, 0.321615 (1.423 sec)
22.655... logprob:  0.702923, 0.325521 (1.435 sec)
22.656... logprob:  0.634305, 0.282552 (1.481 sec)
22.657... logprob:  0.599767, 0.270833 (1.439 sec)
22.658... logprob:  0.680859, 0.308594 (1.447 sec)
22.659... logprob:  0.672456, 0.304687 (1.456 sec)
22.660... logprob:  0.671857, 0.312500 (1.439 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.464912, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.335674e-03 [1.668584e-07] 
Layer 'conv1' biases: 2.065324e-06 [1.447446e-10] 
Layer 'conv2' weights[0]: 3.329224e-03 [1.665994e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.355696e-09] 
Layer 'conv3' weights[0]: 3.327908e-03 [1.669984e-07] 
Layer 'conv3' biases: 3.415858e-05 [1.017307e-08] 
Layer 'conv4' weights[0]: 3.341926e-03 [1.680842e-07] 
Layer 'conv4' biases: 9.999327e-01 [2.025593e-07] 
Layer 'conv5' weights[0]: 3.471953e-03 [2.238885e-06] 
Layer 'conv5' biases: 9.991258e-01 [2.381311e-06] 
Layer 'fc6' weights[0]: 6.934626e-03 [6.075515e-08] 
Layer 'fc6' biases: 9.999908e-01 [5.449415e-08] 
Layer 'fc7' weights[0]: 7.283402e-03 [1.370531e-07] 
Layer 'fc7' biases: 9.997687e-01 [1.643988e-07] 
Layer 'fc8' weights[0]: 4.635752e-03 [1.296521e-05] 
Layer 'fc8' biases: 1.760119e-02 [1.920674e-05] 
Train error last 800 batches: 0.654112
-------------------------------------------------------
Not saving because 0.464912 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
22.661... logprob:  0.669832, 0.291667 (1.443 sec)
22.662... logprob:  0.673460, 0.276042 (1.433 sec)
22.663... logprob:  0.598929, 0.276042 (1.420 sec)
22.664... logprob:  0.521972, 0.220052 (1.435 sec)
22.665... logprob:  0.579042, 0.246094 (1.455 sec)
22.666... logprob:  0.684251, 0.302083 (1.445 sec)
22.667... logprob:  0.753239, 0.361979 (1.447 sec)
22.668... logprob:  0.639812, 0.287760 (1.460 sec)
22.669... logprob:  0.609279, 0.272135 (1.457 sec)
22.670... logprob:  0.582548, 0.265625 (1.428 sec)
22.671... logprob:  0.622186, 0.273438 (1.425 sec)
22.672... logprob:  0.644821, 0.302083 (1.429 sec)
22.673... logprob:  0.628171, 0.296875 (1.434 sec)
22.674... logprob:  0.722955, 0.298177 (1.439 sec)
22.675... logprob:  0.568043, 0.266927 (1.466 sec)
22.676... logprob:  0.616118, 0.277344 (1.449 sec)
22.677... logprob:  0.642596, 0.265625 (1.435 sec)
22.678... logprob:  0.700105, 0.309896 (1.474 sec)
22.679... logprob:  0.630513, 0.294271 (1.433 sec)
22.680... logprob:  0.562052, 0.242188 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.562093, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.332350e-03 [1.667879e-07] 
Layer 'conv1' biases: 2.066611e-06 [1.616333e-10] 
Layer 'conv2' weights[0]: 3.325902e-03 [1.664854e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.575639e-09] 
Layer 'conv3' weights[0]: 3.324569e-03 [1.670464e-07] 
Layer 'conv3' biases: 3.413800e-05 [1.111313e-08] 
Layer 'conv4' weights[0]: 3.338568e-03 [1.683175e-07] 
Layer 'conv4' biases: 9.999305e-01 [2.405976e-07] 
Layer 'conv5' weights[0]: 3.467545e-03 [2.727596e-06] 
Layer 'conv5' biases: 9.990978e-01 [2.968495e-06] 
Layer 'fc6' weights[0]: 6.933951e-03 [6.356282e-08] 
Layer 'fc6' biases: 9.999907e-01 [5.868301e-08] 
Layer 'fc7' weights[0]: 7.282667e-03 [1.477819e-07] 
Layer 'fc7' biases: 9.997701e-01 [2.096609e-07] 
Layer 'fc8' weights[0]: 4.709907e-03 [1.493964e-05] 
Layer 'fc8' biases: 1.821921e-02 [3.166203e-05] 
Train error last 800 batches: 0.654046
-------------------------------------------------------
Not saving because 0.562093 > 0.299667 (9.300: -1.18%)
======================================================= (2.350 sec)
22.681... logprob:  0.639751, 0.304688 (1.435 sec)
22.682... logprob:  0.630724, 0.276042 (1.439 sec)
22.683... logprob:  0.685751, 0.317708 (1.432 sec)
22.684... logprob:  0.647482, 0.305990 (1.474 sec)
22.685... logprob:  0.451949, 0.197917 (1.445 sec)
22.686... logprob:  0.591523, 0.270833 (1.433 sec)
22.687... logprob:  0.479390, 0.212240 (1.478 sec)
22.688... logprob:  0.577854, 0.261719 (1.429 sec)
22.689... logprob:  0.749859, 0.304687 (1.422 sec)
22.690... logprob:  0.784440, 0.352865 (1.431 sec)
22.691... logprob:  0.726240, 0.285156 (1.424 sec)
22.692... logprob:  0.572363, 0.266927 (1.430 sec)
22.693... logprob:  0.636446, 0.266927 (1.485 sec)
22.694... logprob:  0.531327, 0.246094 (1.429 sec)
22.695... logprob:  0.637186, 0.291667 (1.435 sec)
22.696... logprob:  0.736671, 0.277344 (1.471 sec)
22.697... logprob:  0.747287, 0.345052 (1.427 sec)
22.698... logprob:  0.696241, 0.302083 (1.429 sec)
22.699... logprob:  0.698871, 0.316406 (1.428 sec)
22.700... logprob:  0.715945, 0.300781 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.509597, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.329012e-03 [1.665977e-07] 
Layer 'conv1' biases: 2.066728e-06 [1.765970e-10] 
Layer 'conv2' weights[0]: 3.322587e-03 [1.662972e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.197631e-09] 
Layer 'conv3' weights[0]: 3.321251e-03 [1.674497e-07] 
Layer 'conv3' biases: 3.415407e-05 [1.592951e-08] 
Layer 'conv4' weights[0]: 3.335251e-03 [1.690458e-07] 
Layer 'conv4' biases: 9.999305e-01 [3.723078e-07] 
Layer 'conv5' weights[0]: 3.464349e-03 [4.338233e-06] 
Layer 'conv5' biases: 9.991012e-01 [4.835541e-06] 
Layer 'fc6' weights[0]: 6.933207e-03 [8.476187e-08] 
Layer 'fc6' biases: 9.999908e-01 [8.891561e-08] 
Layer 'fc7' weights[0]: 7.281944e-03 [2.111549e-07] 
Layer 'fc7' biases: 9.997706e-01 [3.871576e-07] 
Layer 'fc8' weights[0]: 4.716362e-03 [2.201022e-05] 
Layer 'fc8' biases: 1.829143e-02 [6.506761e-05] 
Train error last 800 batches: 0.654399
-------------------------------------------------------
Not saving because 0.509597 > 0.299667 (9.300: -1.18%)
======================================================= (2.336 sec)
22.701... logprob:  0.642983, 0.265625 (1.440 sec)
22.702... logprob:  0.721426, 0.312500 (1.480 sec)
22.703... logprob:  0.630440, 0.261719 (1.435 sec)
22.704... logprob:  0.658081, 0.292969 (1.444 sec)
22.705... logprob:  0.668136, 0.283854 (1.469 sec)
22.706... logprob:  0.646002, 0.274739 (1.437 sec)
22.707... logprob:  0.665909, 0.259115 (1.439 sec)
22.708... logprob:  0.685225, 0.321615 (1.424 sec)
22.709... logprob:  0.690736, 0.311198 (1.420 sec)
22.710... logprob:  0.719127, 0.341146 (1.440 sec)
22.711... logprob:  0.725953, 0.335937 (1.460 sec)
22.712... logprob:  0.528456, 0.217448 (1.449 sec)
22.713... logprob:  0.758114, 0.326823 (1.447 sec)
22.714... logprob:  0.659135, 0.298177 (1.451 sec)
22.715... logprob:  0.553313, 0.244792 (1.447 sec)
22.716... logprob:  0.615967, 0.282552 (1.433 sec)
22.717... logprob:  0.599389, 0.279948 (1.428 sec)
22.718... logprob:  0.652318, 0.302083 (1.421 sec)
22.719... logprob:  0.634810, 0.261719 (1.434 sec)
22.720... logprob:  0.683538, 0.270833 (1.447 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.466471, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.325681e-03 [1.666471e-07] 
Layer 'conv1' biases: 2.067000e-06 [1.233876e-10] 
Layer 'conv2' weights[0]: 3.319269e-03 [1.661967e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.405753e-09] 
Layer 'conv3' weights[0]: 3.317960e-03 [1.664654e-07] 
Layer 'conv3' biases: 3.419789e-05 [9.624819e-09] 
Layer 'conv4' weights[0]: 3.331904e-03 [1.677032e-07] 
Layer 'conv4' biases: 9.999293e-01 [2.396092e-07] 
Layer 'conv5' weights[0]: 3.460987e-03 [2.654761e-06] 
Layer 'conv5' biases: 9.991345e-01 [2.812381e-06] 
Layer 'fc6' weights[0]: 6.932496e-03 [6.212427e-08] 
Layer 'fc6' biases: 9.999909e-01 [5.615943e-08] 
Layer 'fc7' weights[0]: 7.281247e-03 [1.400649e-07] 
Layer 'fc7' biases: 9.997680e-01 [1.696282e-07] 
Layer 'fc8' weights[0]: 4.632132e-03 [1.334807e-05] 
Layer 'fc8' biases: 1.768054e-02 [1.369543e-05] 
Train error last 800 batches: 0.654739
-------------------------------------------------------
Not saving because 0.466471 > 0.299667 (9.300: -1.18%)
======================================================= (2.370 sec)
22.721... logprob:  0.695972, 0.309896 (1.462 sec)
22.722... logprob:  0.762323, 0.313802 (1.456 sec)
22.723... logprob:  0.743427, 0.343750 (1.451 sec)
22.724... logprob:  0.682254, 0.308594 (1.469 sec)
22.725... logprob:  0.665600, 0.287760 (1.428 sec)
22.726... logprob:  0.618535, 0.289062 (1.420 sec)
22.727... logprob:  0.670789, 0.309896 (1.428 sec)
22.728... logprob:  0.647561, 0.290365 (1.437 sec)
22.729... logprob:  0.567937, 0.264323 (1.428 sec)
22.730... logprob:  0.763701, 0.325521 (1.476 sec)
22.731... logprob:  0.716022, 0.309896 (1.437 sec)
22.732... logprob:  0.595365, 0.251302 (1.431 sec)
22.733... logprob:  0.814255, 0.334635 (1.477 sec)
22.734... logprob:  0.538323, 0.229167 (1.429 sec)
22.735... logprob:  0.784222, 0.334635 (1.425 sec)
22.736... logprob:  0.903657, 0.367188 (1.436 sec)
22.737... logprob:  0.699752, 0.313802 (1.430 sec)
22.738... logprob:  0.637381, 0.261719 (1.430 sec)
22.739... logprob:  0.765534, 0.328125 (1.474 sec)
22.740... logprob:  0.576450, 0.263021 (1.432 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.458560, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.322369e-03 [1.660993e-07] 
Layer 'conv1' biases: 2.067855e-06 [1.272370e-10] 
Layer 'conv2' weights[0]: 3.315955e-03 [1.658310e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.298100e-09] 
Layer 'conv3' weights[0]: 3.314626e-03 [1.661965e-07] 
Layer 'conv3' biases: 3.421609e-05 [9.098819e-09] 
Layer 'conv4' weights[0]: 3.328567e-03 [1.671180e-07] 
Layer 'conv4' biases: 9.999293e-01 [2.181732e-07] 
Layer 'conv5' weights[0]: 3.457689e-03 [2.737854e-06] 
Layer 'conv5' biases: 9.991342e-01 [2.941173e-06] 
Layer 'fc6' weights[0]: 6.931764e-03 [6.721681e-08] 
Layer 'fc6' biases: 9.999909e-01 [6.314035e-08] 
Layer 'fc7' weights[0]: 7.280491e-03 [1.567131e-07] 
Layer 'fc7' biases: 9.997678e-01 [2.149385e-07] 
Layer 'fc8' weights[0]: 4.625975e-03 [1.510101e-05] 
Layer 'fc8' biases: 1.762324e-02 [3.229016e-05] 
Train error last 800 batches: 0.655470
-------------------------------------------------------
Not saving because 0.458560 > 0.299667 (9.300: -1.18%)
======================================================= (2.351 sec)
22.741... logprob:  0.680112, 0.272135 (1.439 sec)
22.742... logprob:  0.721999, 0.338542 (1.484 sec)
22.743... logprob:  0.596913, 0.283854 (1.432 sec)
22.744... logprob:  0.672593, 0.296875 (1.436 sec)
22.745... logprob:  0.781437, 0.343750 (1.428 sec)
22.746... logprob:  0.641832, 0.300781 (1.425 sec)
22.747... logprob:  0.646104, 0.278646 (1.424 sec)
22.748... logprob:  0.621917, 0.282552 (1.483 sec)
22.749... logprob:  0.658391, 0.264323 (1.431 sec)
22.750... logprob:  0.775383, 0.342448 (1.444 sec)
22.751... logprob:  0.545455, 0.246094 (1.475 sec)
22.752... logprob:  0.711131, 0.308594 (1.425 sec)
22.753... logprob:  0.611517, 0.283854 (1.437 sec)
22.754... logprob:  0.624988, 0.287760 (1.431 sec)
22.755... logprob:  0.644039, 0.300781 (1.417 sec)
22.756... logprob:  0.607192, 0.260417 (1.429 sec)
22.757... logprob:  0.795133, 0.325521 (1.476 sec)
22.758... logprob:  0.635004, 0.268229 (1.437 sec)
22.759... logprob:  0.698760, 0.266927 (1.448 sec)
22.760... logprob:  0.626378, 0.278646 (1.454 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.477194, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.319033e-03 [1.660982e-07] 
Layer 'conv1' biases: 2.068388e-06 [1.225776e-10] 
Layer 'conv2' weights[0]: 3.312636e-03 [1.657460e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.287755e-09] 
Layer 'conv3' weights[0]: 3.311290e-03 [1.660670e-07] 
Layer 'conv3' biases: 3.423268e-05 [9.140670e-09] 
Layer 'conv4' weights[0]: 3.325248e-03 [1.670645e-07] 
Layer 'conv4' biases: 9.999278e-01 [2.047890e-07] 
Layer 'conv5' weights[0]: 3.453587e-03 [2.395807e-06] 
Layer 'conv5' biases: 9.991304e-01 [2.490762e-06] 
Layer 'fc6' weights[0]: 6.931077e-03 [6.180527e-08] 
Layer 'fc6' biases: 9.999908e-01 [5.576489e-08] 
Layer 'fc7' weights[0]: 7.279723e-03 [1.406753e-07] 
Layer 'fc7' biases: 9.997680e-01 [1.633904e-07] 
Layer 'fc8' weights[0]: 4.643631e-03 [1.261459e-05] 
Layer 'fc8' biases: 1.779276e-02 [1.407896e-05] 
Train error last 800 batches: 0.655564
-------------------------------------------------------
Not saving because 0.477194 > 0.299667 (9.300: -1.18%)
======================================================= (2.404 sec)
22.761... logprob:  0.620165, 0.269531 (1.443 sec)
22.762... logprob:  0.705302, 0.294271 (1.432 sec)
22.763... logprob:  0.721545, 0.294271 (1.423 sec)
22.764... logprob:  0.752359, 0.329427 (1.418 sec)
22.765... logprob:  0.559965, 0.261719 (1.433 sec)
22.766... logprob:  0.653684, 0.279948 (1.448 sec)
22.767... logprob:  0.621378, 0.282552 (1.448 sec)
22.768... logprob:  0.651736, 0.286458 (1.462 sec)
22.769... logprob:  0.706374, 0.278646 (1.466 sec)
22.770... logprob:  0.598994, 0.257812 (1.473 sec)
22.771... logprob:  0.774631, 0.319010 (1.452 sec)
22.772... logprob:  0.688587, 0.317708 (1.438 sec)
22.773... logprob:  0.698293, 0.281250 (1.438 sec)
22.774... logprob:  0.618471, 0.272135 (1.455 sec)
22.775... logprob:  0.670329, 0.313802 (1.459 sec)
22.776... logprob:  0.645940, 0.269531 (1.474 sec)
22.777... logprob:  0.579770, 0.246094 (1.476 sec)
22.778... logprob:  0.672494, 0.307292 (1.471 sec)
22.779... logprob:  0.662560, 0.283854 (1.478 sec)
22.780... logprob:  0.649125, 0.295573 (1.447 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.402806, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.315725e-03 [1.660335e-07] 
Layer 'conv1' biases: 2.068286e-06 [1.069625e-10] 
Layer 'conv2' weights[0]: 3.309326e-03 [1.656577e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.363206e-09] 
Layer 'conv3' weights[0]: 3.308006e-03 [1.660952e-07] 
Layer 'conv3' biases: 3.423141e-05 [9.789623e-09] 
Layer 'conv4' weights[0]: 3.321938e-03 [1.672110e-07] 
Layer 'conv4' biases: 9.999263e-01 [2.304521e-07] 
Layer 'conv5' weights[0]: 3.449591e-03 [2.292472e-06] 
Layer 'conv5' biases: 9.991308e-01 [2.557053e-06] 
Layer 'fc6' weights[0]: 6.930407e-03 [6.107443e-08] 
Layer 'fc6' biases: 9.999908e-01 [5.489133e-08] 
Layer 'fc7' weights[0]: 7.279027e-03 [1.404007e-07] 
Layer 'fc7' biases: 9.997685e-01 [1.732117e-07] 
Layer 'fc8' weights[0]: 4.649027e-03 [1.294965e-05] 
Layer 'fc8' biases: 1.790293e-02 [1.969605e-05] 
Train error last 800 batches: 0.655598
-------------------------------------------------------
Not saving because 0.402806 > 0.299667 (9.300: -1.18%)
======================================================= (2.367 sec)
22.781... logprob:  0.607517, 0.277344 (1.445 sec)
22.782... logprob:  0.538071, 0.227865 (1.456 sec)
22.783... logprob:  0.709651, 0.303385 (1.452 sec)
22.784... logprob:  0.655916, 0.296875 (1.450 sec)
22.785... logprob:  0.617185, 0.283854 (1.480 sec)
22.786... logprob:  0.720033, 0.299479 (1.466 sec)
22.787... logprob:  0.739785, 0.332031 (1.462 sec)
22.788... logprob:  0.667359, 0.264323 (1.494 sec)
22.789... logprob:  0.547581, 0.264323 (1.453 sec)
22.790... logprob:  0.691408, 0.278646 (1.441 sec)
22.791... logprob:  0.644812, 0.272135 (1.442 sec)
22.792... logprob:  0.675687, 0.321615 (1.451 sec)
22.793... logprob:  0.560912, 0.261719 (1.450 sec)
22.794... logprob:  0.636139, 0.296875 (1.479 sec)
22.795... logprob:  0.643707, 0.270833 (1.463 sec)
22.796... logprob:  0.651780, 0.253906 (1.462 sec)
22.797... logprob:  0.623790, 0.299479 (1.493 sec)
22.798... logprob:  0.646205, 0.305989 (1.450 sec)
22.799... logprob:  0.534746, 0.243490 (1.449 sec)
22.800... logprob:  0.551319, 0.231771 (1.401 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.503921, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.312407e-03 [1.657115e-07] 
Layer 'conv1' biases: 2.068823e-06 [1.655777e-10] 
Layer 'conv2' weights[0]: 3.306030e-03 [1.654563e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.387531e-09] 
Layer 'conv3' weights[0]: 3.304679e-03 [1.659802e-07] 
Layer 'conv3' biases: 3.424471e-05 [1.101397e-08] 
Layer 'conv4' weights[0]: 3.318607e-03 [1.674273e-07] 
Layer 'conv4' biases: 9.999241e-01 [2.589063e-07] 
Layer 'conv5' weights[0]: 3.445269e-03 [2.956336e-06] 
Layer 'conv5' biases: 9.991192e-01 [3.251294e-06] 
Layer 'fc6' weights[0]: 6.929686e-03 [6.733766e-08] 
Layer 'fc6' biases: 9.999908e-01 [6.315724e-08] 
Layer 'fc7' weights[0]: 7.278310e-03 [1.562780e-07] 
Layer 'fc7' biases: 9.997696e-01 [2.393930e-07] 
Layer 'fc8' weights[0]: 4.686291e-03 [1.510383e-05] 
Layer 'fc8' biases: 1.818254e-02 [3.874981e-05] 
Train error last 800 batches: 0.655924
-------------------------------------------------------
Not saving because 0.503921 > 0.299667 (9.300: -1.18%)
======================================================= (2.356 sec)
23.1... logprob:  0.648748, 0.260417 (1.404 sec)
23.2... logprob:  0.540780, 0.235677 (1.450 sec)
23.3... logprob:  0.611238, 0.278646 (1.410 sec)
23.4... logprob:  0.679987, 0.260417 (1.400 sec)
23.5... logprob:  0.663720, 0.287760 (1.430 sec)
23.6... logprob:  0.632354, 0.269531 (1.391 sec)
23.7... logprob:  0.534509, 0.214844 (1.414 sec)
23.8... logprob:  0.697607, 0.307292 (1.391 sec)
23.9... logprob:  0.561802, 0.242187 (1.399 sec)
23.10... logprob:  0.665874, 0.289062 (1.403 sec)
23.11... logprob:  0.626422, 0.312500 (1.446 sec)
23.12... logprob:  0.702299, 0.283854 (1.393 sec)
23.13... logprob:  0.701418, 0.298177 (1.418 sec)
23.14... logprob:  0.596321, 0.256510 (1.394 sec)
23.15... logprob:  0.540762, 0.256510 (1.406 sec)
23.16... logprob:  0.653354, 0.291667 (1.403 sec)
23.17... logprob:  0.622355, 0.286458 (1.394 sec)
23.18... logprob:  0.515768, 0.242188 (1.393 sec)
23.19... logprob:  0.558025, 0.257812 (1.397 sec)
23.20... logprob:  0.697665, 0.292969 (1.395 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.339923, 0.062500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.309101e-03 [1.655580e-07] 
Layer 'conv1' biases: 2.070047e-06 [1.076294e-10] 
Layer 'conv2' weights[0]: 3.302711e-03 [1.652355e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.988589e-10] 
Layer 'conv3' weights[0]: 3.301375e-03 [1.653940e-07] 
Layer 'conv3' biases: 3.425738e-05 [6.986899e-09] 
Layer 'conv4' weights[0]: 3.315297e-03 [1.661977e-07] 
Layer 'conv4' biases: 9.999233e-01 [1.374771e-07] 
Layer 'conv5' weights[0]: 3.441399e-03 [1.922541e-06] 
Layer 'conv5' biases: 9.991040e-01 [2.011326e-06] 
Layer 'fc6' weights[0]: 6.928964e-03 [5.809875e-08] 
Layer 'fc6' biases: 9.999908e-01 [5.132864e-08] 
Layer 'fc7' weights[0]: 7.277589e-03 [1.308895e-07] 
Layer 'fc7' biases: 9.997705e-01 [1.533074e-07] 
Layer 'fc8' weights[0]: 4.732181e-03 [1.127251e-05] 
Layer 'fc8' biases: 1.854025e-02 [1.516914e-05] 
Train error last 800 batches: 0.655737
-------------------------------------------------------
Not saving because 0.339923 > 0.299667 (9.300: -1.18%)
======================================================= (2.420 sec)
23.21... logprob:  0.681361, 0.289062 (1.401 sec)
23.22... logprob:  0.659102, 0.292969 (1.410 sec)
23.23... logprob:  0.692310, 0.296875 (1.410 sec)
23.24... logprob:  0.509948, 0.247396 (1.412 sec)
23.25... logprob:  0.555981, 0.236979 (1.399 sec)
23.26... logprob:  0.634105, 0.282552 (1.443 sec)
23.27... logprob:  0.616613, 0.266927 (1.515 sec)
23.28... logprob:  0.676268, 0.256510 (1.410 sec)
23.29... logprob:  0.509026, 0.218750 (1.416 sec)
23.30... logprob:  0.656047, 0.303385 (1.410 sec)
23.31... logprob:  0.672332, 0.292969 (1.399 sec)
23.32... logprob:  0.643496, 0.279948 (1.386 sec)
23.33... logprob:  0.730733, 0.290365 (1.441 sec)
23.34... logprob:  0.715522, 0.291667 (1.384 sec)
23.35... logprob:  0.555238, 0.250000 (1.394 sec)
23.36... logprob:  0.657004, 0.279948 (1.395 sec)
23.37... logprob:  0.646100, 0.303385 (1.407 sec)
23.38... logprob:  0.657187, 0.270833 (1.394 sec)
23.39... logprob:  0.900103, 0.358073 (1.427 sec)
23.40... logprob:  0.683735, 0.292969 (1.402 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.418056, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.305793e-03 [1.653031e-07] 
Layer 'conv1' biases: 2.071087e-06 [1.574382e-10] 
Layer 'conv2' weights[0]: 3.299412e-03 [1.650533e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.116566e-09] 
Layer 'conv3' weights[0]: 3.298093e-03 [1.660869e-07] 
Layer 'conv3' biases: 3.427148e-05 [1.477480e-08] 
Layer 'conv4' weights[0]: 3.311980e-03 [1.673445e-07] 
Layer 'conv4' biases: 9.999242e-01 [3.602334e-07] 
Layer 'conv5' weights[0]: 3.438757e-03 [4.300887e-06] 
Layer 'conv5' biases: 9.991130e-01 [4.820648e-06] 
Layer 'fc6' weights[0]: 6.928275e-03 [8.571845e-08] 
Layer 'fc6' biases: 9.999908e-01 [8.958922e-08] 
Layer 'fc7' weights[0]: 7.276851e-03 [2.144856e-07] 
Layer 'fc7' biases: 9.997690e-01 [3.863597e-07] 
Layer 'fc8' weights[0]: 4.691170e-03 [2.232349e-05] 
Layer 'fc8' biases: 1.825118e-02 [6.698081e-05] 
Train error last 800 batches: 0.655331
-------------------------------------------------------
Not saving because 0.418056 > 0.299667 (9.300: -1.18%)
======================================================= (2.337 sec)
23.41... logprob:  0.643691, 0.274740 (1.428 sec)
23.42... logprob:  0.587241, 0.263021 (1.419 sec)
23.43... logprob:  0.729961, 0.299479 (1.404 sec)
23.44... logprob:  0.720338, 0.316406 (1.435 sec)
23.45... logprob:  0.638550, 0.292969 (1.387 sec)
23.46... logprob:  0.695447, 0.286458 (1.392 sec)
23.47... logprob:  0.529582, 0.225260 (1.386 sec)
23.48... logprob:  0.748308, 0.329427 (1.419 sec)
23.49... logprob:  0.723557, 0.315104 (1.405 sec)
23.50... logprob:  0.680268, 0.279948 (1.418 sec)
23.51... logprob:  0.586593, 0.263021 (1.409 sec)
23.52... logprob:  0.629336, 0.269531 (1.395 sec)
23.53... logprob:  0.559534, 0.259114 (1.438 sec)
23.54... logprob:  0.627164, 0.276042 (1.384 sec)
23.55... logprob:  0.547117, 0.239583 (1.398 sec)
23.56... logprob:  0.674307, 0.277344 (1.398 sec)
23.57... logprob:  0.636969, 0.278646 (1.429 sec)
23.58... logprob:  0.681799, 0.316406 (1.401 sec)
23.59... logprob:  0.615924, 0.248698 (1.459 sec)
23.60... logprob:  0.837862, 0.325521 (1.417 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.464019, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.302492e-03 [1.651933e-07] 
Layer 'conv1' biases: 2.072307e-06 [1.168282e-10] 
Layer 'conv2' weights[0]: 3.296135e-03 [1.648769e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.063702e-09] 
Layer 'conv3' weights[0]: 3.294783e-03 [1.651205e-07] 
Layer 'conv3' biases: 3.431905e-05 [7.884670e-09] 
Layer 'conv4' weights[0]: 3.308682e-03 [1.660448e-07] 
Layer 'conv4' biases: 9.999222e-01 [1.704530e-07] 
Layer 'conv5' weights[0]: 3.434605e-03 [2.343611e-06] 
Layer 'conv5' biases: 9.991285e-01 [2.427837e-06] 
Layer 'fc6' weights[0]: 6.927549e-03 [6.344439e-08] 
Layer 'fc6' biases: 9.999909e-01 [5.812163e-08] 
Layer 'fc7' weights[0]: 7.276143e-03 [1.428426e-07] 
Layer 'fc7' biases: 9.997675e-01 [1.698777e-07] 
Layer 'fc8' weights[0]: 4.646306e-03 [1.294644e-05] 
Layer 'fc8' biases: 1.787033e-02 [1.564016e-05] 
Train error last 800 batches: 0.655413
-------------------------------------------------------
Not saving because 0.464019 > 0.299667 (9.300: -1.18%)
======================================================= (2.384 sec)
23.61... logprob:  0.659781, 0.305990 (1.430 sec)
23.62... logprob:  0.729355, 0.308594 (1.453 sec)
23.63... logprob:  0.628224, 0.282552 (1.432 sec)
23.64... logprob:  0.651149, 0.294271 (1.407 sec)
23.65... logprob:  0.588126, 0.252604 (1.399 sec)
23.66... logprob:  0.542687, 0.268229 (1.436 sec)
23.67... logprob:  0.537743, 0.231771 (1.382 sec)
23.68... logprob:  0.629956, 0.268229 (1.392 sec)
23.69... logprob:  0.698844, 0.317708 (1.421 sec)
23.70... logprob:  0.594340, 0.277344 (1.431 sec)
23.71... logprob:  0.719136, 0.303385 (1.455 sec)
23.72... logprob:  0.760798, 0.354167 (1.395 sec)
23.73... logprob:  0.695414, 0.319010 (1.428 sec)
23.74... logprob:  0.629567, 0.278646 (1.415 sec)
23.75... logprob:  0.630539, 0.291667 (1.409 sec)
23.76... logprob:  0.654166, 0.287760 (1.431 sec)
23.77... logprob:  0.610532, 0.303385 (1.428 sec)
23.78... logprob:  0.599147, 0.268229 (1.448 sec)
23.79... logprob:  0.681395, 0.287760 (1.397 sec)
23.80... logprob:  0.608388, 0.253906 (1.415 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.467690, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.299193e-03 [1.650617e-07] 
Layer 'conv1' biases: 2.073336e-06 [1.138013e-10] 
Layer 'conv2' weights[0]: 3.292835e-03 [1.647660e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.389191e-09] 
Layer 'conv3' weights[0]: 3.291548e-03 [1.651755e-07] 
Layer 'conv3' biases: 3.432062e-05 [1.025145e-08] 
Layer 'conv4' weights[0]: 3.305365e-03 [1.663098e-07] 
Layer 'conv4' biases: 9.999228e-01 [2.348830e-07] 
Layer 'conv5' weights[0]: 3.431977e-03 [2.623261e-06] 
Layer 'conv5' biases: 9.991049e-01 [2.887730e-06] 
Layer 'fc6' weights[0]: 6.926853e-03 [6.886202e-08] 
Layer 'fc6' biases: 9.999910e-01 [6.562917e-08] 
Layer 'fc7' weights[0]: 7.275387e-03 [1.661729e-07] 
Layer 'fc7' biases: 9.997688e-01 [2.644497e-07] 
Layer 'fc8' weights[0]: 4.696332e-03 [1.954768e-05] 
Layer 'fc8' biases: 1.834407e-02 [4.701278e-05] 
Train error last 800 batches: 0.654944
-------------------------------------------------------
Not saving because 0.467690 > 0.299667 (9.300: -1.18%)
======================================================= (2.350 sec)
23.81... logprob:  0.657839, 0.263021 (1.421 sec)
23.82... logprob:  0.497699, 0.227865 (1.424 sec)
23.83... logprob:  0.699419, 0.308594 (1.392 sec)
23.84... logprob:  0.619172, 0.273437 (1.462 sec)
23.85... logprob:  0.672632, 0.305990 (1.419 sec)
23.86... logprob:  0.614099, 0.259115 (1.412 sec)
23.87... logprob:  0.862885, 0.322917 (1.407 sec)
23.88... logprob:  0.810177, 0.324219 (1.401 sec)
23.89... logprob:  0.535595, 0.238281 (1.430 sec)
23.90... logprob:  0.681564, 0.287760 (1.380 sec)
23.91... logprob:  0.567229, 0.278646 (1.391 sec)
23.92... logprob:  0.683024, 0.287760 (1.394 sec)
23.93... logprob:  0.647511, 0.270833 (1.394 sec)
23.94... logprob:  0.676675, 0.304688 (1.382 sec)
23.95... logprob:  0.768534, 0.355469 (1.400 sec)
23.96... logprob:  0.807942, 0.337240 (1.396 sec)
23.97... logprob:  0.735324, 0.320312 (1.392 sec)
23.98... logprob:  0.600834, 0.260417 (1.431 sec)
23.99... logprob:  0.697051, 0.289062 (1.414 sec)
23.100... logprob:  0.658183, 0.313802 (1.396 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.514762, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.295901e-03 [1.649366e-07] 
Layer 'conv1' biases: 2.074107e-06 [1.722078e-10] 
Layer 'conv2' weights[0]: 3.289535e-03 [1.645612e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.617574e-09] 
Layer 'conv3' weights[0]: 3.288224e-03 [1.652886e-07] 
Layer 'conv3' biases: 3.434245e-05 [1.205834e-08] 
Layer 'conv4' weights[0]: 3.302068e-03 [1.662293e-07] 
Layer 'conv4' biases: 9.999220e-01 [2.722123e-07] 
Layer 'conv5' weights[0]: 3.428468e-03 [2.957248e-06] 
Layer 'conv5' biases: 9.991202e-01 [3.292473e-06] 
Layer 'fc6' weights[0]: 6.926154e-03 [6.595294e-08] 
Layer 'fc6' biases: 9.999911e-01 [6.181510e-08] 
Layer 'fc7' weights[0]: 7.274608e-03 [1.557778e-07] 
Layer 'fc7' biases: 9.997674e-01 [2.267157e-07] 
Layer 'fc8' weights[0]: 4.656956e-03 [1.507057e-05] 
Layer 'fc8' biases: 1.804213e-02 [3.112830e-05] 
Train error last 800 batches: 0.654885
-------------------------------------------------------
Not saving because 0.514762 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
23.101... logprob:  0.572923, 0.261719 (1.441 sec)
23.102... logprob:  0.777613, 0.351562 (1.387 sec)
23.103... logprob:  0.784603, 0.350260 (1.401 sec)
23.104... logprob:  0.627394, 0.268229 (1.400 sec)
23.105... logprob:  0.804908, 0.342448 (1.389 sec)
23.106... logprob:  0.601309, 0.278646 (1.389 sec)
23.107... logprob:  0.529082, 0.250000 (1.438 sec)
23.108... logprob:  0.762050, 0.320312 (1.397 sec)
23.109... logprob:  0.586442, 0.268229 (1.404 sec)
23.110... logprob:  0.755630, 0.309896 (1.395 sec)
23.111... logprob:  0.575074, 0.247396 (1.392 sec)
23.112... logprob:  0.626929, 0.299479 (1.398 sec)
23.113... logprob:  0.615828, 0.259115 (1.394 sec)
23.114... logprob:  0.646966, 0.282552 (1.423 sec)
23.115... logprob:  0.769129, 0.326823 (1.407 sec)
23.116... logprob:  0.636226, 0.282552 (1.395 sec)
23.117... logprob:  0.695737, 0.319010 (1.439 sec)
23.118... logprob:  0.637708, 0.276042 (1.396 sec)
23.119... logprob:  0.697118, 0.308594 (1.395 sec)
23.120... logprob:  0.735701, 0.305990 (1.394 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.472120, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.292595e-03 [1.648132e-07] 
Layer 'conv1' biases: 2.074521e-06 [9.923106e-11] 
Layer 'conv2' weights[0]: 3.286247e-03 [1.644161e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.764745e-10] 
Layer 'conv3' weights[0]: 3.284940e-03 [1.646142e-07] 
Layer 'conv3' biases: 3.435697e-05 [7.359739e-09] 
Layer 'conv4' weights[0]: 3.298769e-03 [1.654653e-07] 
Layer 'conv4' biases: 9.999220e-01 [1.631016e-07] 
Layer 'conv5' weights[0]: 3.425452e-03 [2.230817e-06] 
Layer 'conv5' biases: 9.991217e-01 [2.389022e-06] 
Layer 'fc6' weights[0]: 6.925436e-03 [6.121952e-08] 
Layer 'fc6' biases: 9.999909e-01 [5.508730e-08] 
Layer 'fc7' weights[0]: 7.273897e-03 [1.394536e-07] 
Layer 'fc7' biases: 9.997671e-01 [1.621751e-07] 
Layer 'fc8' weights[0]: 4.663281e-03 [1.233429e-05] 
Layer 'fc8' biases: 1.804993e-02 [5.599818e-06] 
Train error last 800 batches: 0.655029
-------------------------------------------------------
Not saving because 0.472120 > 0.299667 (9.300: -1.18%)
======================================================= (2.379 sec)
23.121... logprob:  0.718902, 0.325521 (1.400 sec)
23.122... logprob:  0.682857, 0.303385 (1.443 sec)
23.123... logprob:  0.696174, 0.287760 (1.390 sec)
23.124... logprob:  0.614647, 0.276042 (1.397 sec)
23.125... logprob:  0.710934, 0.295573 (1.388 sec)
23.126... logprob:  0.745182, 0.291667 (1.392 sec)
23.127... logprob:  0.728527, 0.307292 (1.397 sec)
23.128... logprob:  0.646444, 0.279948 (1.418 sec)
23.129... logprob:  0.886872, 0.339844 (1.423 sec)
23.130... logprob:  0.684093, 0.303385 (1.413 sec)
23.131... logprob:  0.733658, 0.303385 (1.401 sec)
23.132... logprob:  0.660479, 0.305990 (1.428 sec)
23.133... logprob:  0.620570, 0.259115 (1.382 sec)
23.134... logprob:  0.569422, 0.259114 (1.386 sec)
23.135... logprob:  0.683269, 0.317708 (1.396 sec)
23.136... logprob:  0.751733, 0.341146 (1.391 sec)
23.137... logprob:  0.698284, 0.291667 (1.390 sec)
23.138... logprob:  0.571712, 0.227865 (1.465 sec)
23.139... logprob:  0.614752, 0.253906 (1.390 sec)
23.140... logprob:  0.740790, 0.328125 (1.405 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.533731, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.289314e-03 [1.645226e-07] 
Layer 'conv1' biases: 2.074725e-06 [1.070717e-10] 
Layer 'conv2' weights[0]: 3.282954e-03 [1.642271e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.064257e-09] 
Layer 'conv3' weights[0]: 3.281657e-03 [1.644339e-07] 
Layer 'conv3' biases: 3.440465e-05 [7.608142e-09] 
Layer 'conv4' weights[0]: 3.295474e-03 [1.654664e-07] 
Layer 'conv4' biases: 9.999232e-01 [1.800193e-07] 
Layer 'conv5' weights[0]: 3.423189e-03 [2.256827e-06] 
Layer 'conv5' biases: 9.991506e-01 [2.420020e-06] 
Layer 'fc6' weights[0]: 6.924735e-03 [6.320216e-08] 
Layer 'fc6' biases: 9.999911e-01 [5.759604e-08] 
Layer 'fc7' weights[0]: 7.273205e-03 [1.436205e-07] 
Layer 'fc7' biases: 9.997647e-01 [1.774156e-07] 
Layer 'fc8' weights[0]: 4.597787e-03 [1.343742e-05] 
Layer 'fc8' biases: 1.755069e-02 [1.830833e-05] 
Train error last 800 batches: 0.654787
-------------------------------------------------------
Not saving because 0.533731 > 0.299667 (9.300: -1.18%)
======================================================= (2.420 sec)
23.141... logprob:  0.655508, 0.274740 (1.434 sec)
23.142... logprob:  0.646400, 0.283854 (1.395 sec)
23.143... logprob:  0.595331, 0.268229 (1.420 sec)
23.144... logprob:  0.642712, 0.290365 (1.411 sec)
23.145... logprob:  0.613547, 0.282552 (1.417 sec)
23.146... logprob:  0.669606, 0.277344 (1.399 sec)
23.147... logprob:  0.591821, 0.277344 (1.432 sec)
23.148... logprob:  0.617679, 0.252604 (1.391 sec)
23.149... logprob:  0.712836, 0.319010 (1.402 sec)
23.150... logprob:  0.534422, 0.252604 (1.396 sec)
23.151... logprob:  0.604228, 0.259115 (1.393 sec)
23.152... logprob:  0.989052, 0.386719 (1.394 sec)
23.153... logprob:  0.643784, 0.279948 (1.444 sec)
23.154... logprob:  0.758274, 0.319010 (1.399 sec)
23.155... logprob:  0.731451, 0.319010 (1.401 sec)
23.156... logprob:  0.550997, 0.235677 (1.430 sec)
23.157... logprob:  0.507922, 0.243490 (1.394 sec)
23.158... logprob:  0.676110, 0.291667 (1.396 sec)
23.159... logprob:  0.621827, 0.269531 (1.391 sec)
23.160... logprob:  0.581242, 0.256510 (1.388 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.401822, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.286030e-03 [1.644246e-07] 
Layer 'conv1' biases: 2.075924e-06 [1.460661e-10] 
Layer 'conv2' weights[0]: 3.279673e-03 [1.640745e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.103056e-09] 
Layer 'conv3' weights[0]: 3.278360e-03 [1.644030e-07] 
Layer 'conv3' biases: 3.442073e-05 [8.158396e-09] 
Layer 'conv4' weights[0]: 3.292176e-03 [1.653739e-07] 
Layer 'conv4' biases: 9.999206e-01 [1.890164e-07] 
Layer 'conv5' weights[0]: 3.418802e-03 [2.465266e-06] 
Layer 'conv5' biases: 9.991314e-01 [2.627410e-06] 
Layer 'fc6' weights[0]: 6.923985e-03 [6.278430e-08] 
Layer 'fc6' biases: 9.999910e-01 [5.706599e-08] 
Layer 'fc7' weights[0]: 7.272479e-03 [1.482729e-07] 
Layer 'fc7' biases: 9.997662e-01 [2.025989e-07] 
Layer 'fc8' weights[0]: 4.663949e-03 [1.471401e-05] 
Layer 'fc8' biases: 1.804876e-02 [3.527878e-05] 
Train error last 800 batches: 0.654703
-------------------------------------------------------
Not saving because 0.401822 > 0.299667 (9.300: -1.18%)
======================================================= (2.365 sec)
23.161... logprob:  0.542409, 0.260417 (1.403 sec)
23.162... logprob:  0.740776, 0.324219 (1.408 sec)
23.163... logprob:  0.746419, 0.329427 (1.425 sec)
23.164... logprob:  0.698196, 0.295573 (1.421 sec)
23.165... logprob:  0.762969, 0.309896 (1.419 sec)
23.166... logprob:  0.663125, 0.299479 (1.441 sec)
23.167... logprob:  0.605406, 0.304688 (1.428 sec)
23.168... logprob:  0.622415, 0.261719 (1.426 sec)
23.169... logprob:  0.600848, 0.251302 (1.458 sec)
23.170... logprob:  0.652583, 0.287760 (1.397 sec)
23.171... logprob:  0.733250, 0.313802 (1.420 sec)
23.172... logprob:  0.637917, 0.256510 (1.411 sec)
23.173... logprob:  0.556636, 0.233073 (1.416 sec)
23.174... logprob:  0.830004, 0.341146 (1.401 sec)
23.175... logprob:  0.660941, 0.269531 (1.463 sec)
23.176... logprob:  0.611683, 0.276042 (1.408 sec)
23.177... logprob:  0.549058, 0.259114 (1.447 sec)
23.178... logprob:  0.642485, 0.263021 (1.458 sec)
23.179... logprob:  0.573293, 0.277344 (1.403 sec)
23.180... logprob:  0.745195, 0.290365 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.505836, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.282748e-03 [1.642220e-07] 
Layer 'conv1' biases: 2.076740e-06 [1.216950e-10] 
Layer 'conv2' weights[0]: 3.276407e-03 [1.639196e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.328450e-09] 
Layer 'conv3' weights[0]: 3.275075e-03 [1.643491e-07] 
Layer 'conv3' biases: 3.440213e-05 [1.019622e-08] 
Layer 'conv4' weights[0]: 3.288871e-03 [1.658617e-07] 
Layer 'conv4' biases: 9.999219e-01 [2.780700e-07] 
Layer 'conv5' weights[0]: 3.416527e-03 [2.672759e-06] 
Layer 'conv5' biases: 9.991367e-01 [2.956324e-06] 
Layer 'fc6' weights[0]: 6.923292e-03 [6.841151e-08] 
Layer 'fc6' biases: 9.999910e-01 [6.473615e-08] 
Layer 'fc7' weights[0]: 7.271749e-03 [1.642794e-07] 
Layer 'fc7' biases: 9.997656e-01 [2.477956e-07] 
Layer 'fc8' weights[0]: 4.657060e-03 [1.949614e-05] 
Layer 'fc8' biases: 1.805027e-02 [4.775482e-05] 
Train error last 800 batches: 0.654854
-------------------------------------------------------
Not saving because 0.505836 > 0.299667 (9.300: -1.18%)
======================================================= (2.359 sec)
23.181... logprob:  0.689465, 0.279948 (1.419 sec)
23.182... logprob:  0.638993, 0.278646 (1.419 sec)
23.183... logprob:  0.671700, 0.304687 (1.423 sec)
23.184... logprob:  0.744573, 0.315104 (1.414 sec)
23.185... logprob:  0.556456, 0.246094 (1.388 sec)
23.186... logprob:  0.627175, 0.281250 (1.393 sec)
23.187... logprob:  0.781322, 0.321615 (1.396 sec)
23.188... logprob:  0.619656, 0.266927 (1.392 sec)
23.189... logprob:  0.654009, 0.281250 (1.386 sec)
23.190... logprob:  0.697008, 0.308594 (1.426 sec)
23.191... logprob:  0.626549, 0.270833 (1.403 sec)
23.192... logprob:  0.745068, 0.328125 (1.407 sec)
23.193... logprob:  0.587669, 0.291667 (1.415 sec)
23.194... logprob:  0.626562, 0.292969 (1.491 sec)
23.195... logprob:  0.573200, 0.265625 (1.400 sec)
23.196... logprob:  0.622873, 0.260417 (1.387 sec)
23.197... logprob:  0.634312, 0.268229 (1.398 sec)
23.198... logprob:  0.590123, 0.260417 (1.399 sec)
23.199... logprob:  0.623456, 0.261719 (1.386 sec)
23.200... logprob:  0.654565, 0.304687 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.468660, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.279459e-03 [1.641791e-07] 
Layer 'conv1' biases: 2.077293e-06 [1.472256e-10] 
Layer 'conv2' weights[0]: 3.273150e-03 [1.638355e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.309093e-09] 
Layer 'conv3' weights[0]: 3.271830e-03 [1.642028e-07] 
Layer 'conv3' biases: 3.440699e-05 [1.006900e-08] 
Layer 'conv4' weights[0]: 3.285599e-03 [1.653233e-07] 
Layer 'conv4' biases: 9.999225e-01 [2.291677e-07] 
Layer 'conv5' weights[0]: 3.414058e-03 [2.769198e-06] 
Layer 'conv5' biases: 9.991341e-01 [3.014718e-06] 
Layer 'fc6' weights[0]: 6.922556e-03 [6.726652e-08] 
Layer 'fc6' biases: 9.999909e-01 [6.303226e-08] 
Layer 'fc7' weights[0]: 7.270979e-03 [1.579690e-07] 
Layer 'fc7' biases: 9.997660e-01 [2.366905e-07] 
Layer 'fc8' weights[0]: 4.672058e-03 [1.759474e-05] 
Layer 'fc8' biases: 1.821646e-02 [4.995035e-05] 
Train error last 800 batches: 0.655213
-------------------------------------------------------
Not saving because 0.468660 > 0.299667 (9.300: -1.18%)
======================================================= (2.393 sec)
23.201... logprob:  0.766786, 0.338542 (1.409 sec)
23.202... logprob:  0.760005, 0.339844 (1.401 sec)
23.203... logprob:  0.728017, 0.302083 (1.435 sec)
23.204... logprob:  0.634883, 0.287760 (1.381 sec)
23.205... logprob:  0.614979, 0.259114 (1.396 sec)
23.206... logprob:  0.572606, 0.273438 (1.396 sec)
23.207... logprob:  0.513734, 0.210937 (1.386 sec)
23.208... logprob:  0.682152, 0.286458 (1.399 sec)
23.209... logprob:  0.542070, 0.238281 (1.422 sec)
23.210... logprob:  0.717842, 0.290365 (1.407 sec)
23.211... logprob:  0.629764, 0.263021 (1.412 sec)
23.212... logprob:  0.735923, 0.304687 (1.409 sec)
23.213... logprob:  0.714277, 0.299479 (1.454 sec)
23.214... logprob:  0.690063, 0.312500 (1.421 sec)
23.215... logprob:  0.599191, 0.269531 (1.415 sec)
23.216... logprob:  0.739798, 0.295573 (1.479 sec)
23.217... logprob:  0.580825, 0.272135 (1.404 sec)
23.218... logprob:  0.662607, 0.285156 (1.413 sec)
23.219... logprob:  0.733736, 0.332031 (1.411 sec)
23.220... logprob:  0.689651, 0.302083 (1.418 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.547713, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.276178e-03 [1.640040e-07] 
Layer 'conv1' biases: 2.078136e-06 [1.612601e-10] 
Layer 'conv2' weights[0]: 3.269854e-03 [1.636424e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.596099e-09] 
Layer 'conv3' weights[0]: 3.268540e-03 [1.641298e-07] 
Layer 'conv3' biases: 3.444230e-05 [1.100584e-08] 
Layer 'conv4' weights[0]: 3.282306e-03 [1.651772e-07] 
Layer 'conv4' biases: 9.999224e-01 [2.447088e-07] 
Layer 'conv5' weights[0]: 3.410943e-03 [3.006756e-06] 
Layer 'conv5' biases: 9.991503e-01 [3.221524e-06] 
Layer 'fc6' weights[0]: 6.921844e-03 [6.778594e-08] 
Layer 'fc6' biases: 9.999909e-01 [6.338936e-08] 
Layer 'fc7' weights[0]: 7.270233e-03 [1.550594e-07] 
Layer 'fc7' biases: 9.997652e-01 [2.196273e-07] 
Layer 'fc8' weights[0]: 4.650744e-03 [1.471823e-05] 
Layer 'fc8' biases: 1.798756e-02 [2.600690e-05] 
Train error last 800 batches: 0.655079
-------------------------------------------------------
Not saving because 0.547713 > 0.299667 (9.300: -1.18%)
======================================================= (2.359 sec)
23.221... logprob:  0.647264, 0.263021 (1.414 sec)
23.222... logprob:  0.732453, 0.313802 (1.457 sec)
23.223... logprob:  0.767657, 0.321615 (1.430 sec)
23.224... logprob:  0.601867, 0.251302 (1.424 sec)
23.225... logprob:  0.575092, 0.256510 (1.435 sec)
23.226... logprob:  0.650397, 0.285156 (1.422 sec)
23.227... logprob:  0.680696, 0.312500 (1.423 sec)
23.228... logprob:  0.663103, 0.290365 (1.408 sec)
23.229... logprob:  0.693090, 0.268229 (1.410 sec)
23.230... logprob:  0.603191, 0.268229 (1.416 sec)
23.231... logprob:  0.672823, 0.273437 (1.402 sec)
23.232... logprob:  0.647436, 0.252604 (1.457 sec)
23.233... logprob:  0.613611, 0.243490 (1.418 sec)
23.234... logprob:  0.688667, 0.294271 (1.413 sec)
23.235... logprob:  0.649193, 0.291667 (1.468 sec)
23.236... logprob:  0.617436, 0.269531 (1.394 sec)
23.237... logprob:  0.615605, 0.273437 (1.416 sec)
23.238... logprob:  0.628340, 0.282552 (1.417 sec)
23.239... logprob:  0.691417, 0.311198 (1.422 sec)
23.240... logprob:  0.637041, 0.265625 (1.393 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.434682, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.272907e-03 [1.638111e-07] 
Layer 'conv1' biases: 2.078340e-06 [8.638510e-11] 
Layer 'conv2' weights[0]: 3.266582e-03 [1.634791e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.083707e-09] 
Layer 'conv3' weights[0]: 3.265289e-03 [1.638972e-07] 
Layer 'conv3' biases: 3.445175e-05 [1.024508e-08] 
Layer 'conv4' weights[0]: 3.279025e-03 [1.648837e-07] 
Layer 'conv4' biases: 9.999233e-01 [2.040601e-07] 
Layer 'conv5' weights[0]: 3.408526e-03 [2.762927e-06] 
Layer 'conv5' biases: 9.991548e-01 [2.908760e-06] 
Layer 'fc6' weights[0]: 6.921089e-03 [6.513900e-08] 
Layer 'fc6' biases: 9.999909e-01 [5.970877e-08] 
Layer 'fc7' weights[0]: 7.269503e-03 [1.508228e-07] 
Layer 'fc7' biases: 9.997647e-01 [2.085005e-07] 
Layer 'fc8' weights[0]: 4.647563e-03 [1.475538e-05] 
Layer 'fc8' biases: 1.802674e-02 [2.778864e-05] 
Train error last 800 batches: 0.654752
-------------------------------------------------------
Not saving because 0.434682 > 0.299667 (9.300: -1.18%)
======================================================= (2.359 sec)
23.241... logprob:  0.772792, 0.303385 (1.462 sec)
23.242... logprob:  0.566208, 0.257812 (1.430 sec)
23.243... logprob:  0.532558, 0.226562 (1.426 sec)
23.244... logprob:  0.497097, 0.216146 (1.443 sec)
23.245... logprob:  0.681648, 0.300781 (1.423 sec)
23.246... logprob:  0.687553, 0.305990 (1.408 sec)
23.247... logprob:  0.590128, 0.251302 (1.410 sec)
23.248... logprob:  0.561607, 0.266927 (1.416 sec)
23.249... logprob:  0.650298, 0.272135 (1.414 sec)
23.250... logprob:  0.841451, 0.359375 (1.405 sec)
23.251... logprob:  0.561644, 0.257812 (1.459 sec)
23.252... logprob:  0.560804, 0.269531 (1.422 sec)
23.253... logprob:  0.665294, 0.299479 (1.414 sec)
23.254... logprob:  0.649128, 0.282552 (1.461 sec)
23.255... logprob:  0.615226, 0.308594 (1.402 sec)
23.256... logprob:  0.607606, 0.264323 (1.420 sec)
23.257... logprob:  0.599451, 0.255208 (1.413 sec)
23.258... logprob:  0.647587, 0.287760 (1.412 sec)
23.259... logprob:  0.575028, 0.263021 (1.401 sec)
23.260... logprob:  0.552876, 0.268229 (1.456 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.365298, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.269631e-03 [1.635903e-07] 
Layer 'conv1' biases: 2.078789e-06 [1.605821e-10] 
Layer 'conv2' weights[0]: 3.263321e-03 [1.633225e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.467553e-09] 
Layer 'conv3' weights[0]: 3.262010e-03 [1.638435e-07] 
Layer 'conv3' biases: 3.445355e-05 [1.034270e-08] 
Layer 'conv4' weights[0]: 3.275751e-03 [1.652643e-07] 
Layer 'conv4' biases: 9.999220e-01 [2.500181e-07] 
Layer 'conv5' weights[0]: 3.405139e-03 [2.924947e-06] 
Layer 'conv5' biases: 9.991246e-01 [3.135748e-06] 
Layer 'fc6' weights[0]: 6.920347e-03 [6.738728e-08] 
Layer 'fc6' biases: 9.999909e-01 [6.313191e-08] 
Layer 'fc7' weights[0]: 7.268777e-03 [1.579866e-07] 
Layer 'fc7' biases: 9.997672e-01 [2.525474e-07] 
Layer 'fc8' weights[0]: 4.733957e-03 [1.610556e-05] 
Layer 'fc8' biases: 1.875921e-02 [4.737177e-05] 
Train error last 800 batches: 0.654647
-------------------------------------------------------
Not saving because 0.365298 > 0.299667 (9.300: -1.18%)
======================================================= (2.353 sec)
23.261... logprob:  0.646638, 0.286458 (1.425 sec)
23.262... logprob:  0.683163, 0.279948 (1.424 sec)
23.263... logprob:  0.568563, 0.248698 (1.441 sec)
23.264... logprob:  0.654266, 0.272135 (1.415 sec)
23.265... logprob:  0.686001, 0.283854 (1.410 sec)
23.266... logprob:  0.646173, 0.279948 (1.407 sec)
23.267... logprob:  0.752430, 0.334635 (1.412 sec)
23.268... logprob:  0.595349, 0.263021 (1.428 sec)
23.269... logprob:  0.761252, 0.312500 (1.401 sec)
23.270... logprob:  0.820834, 0.333333 (1.454 sec)
23.271... logprob:  0.711768, 0.320312 (1.421 sec)
23.272... logprob:  0.588733, 0.248698 (1.417 sec)
23.273... logprob:  0.712882, 0.307292 (1.457 sec)
23.274... logprob:  0.784698, 0.315104 (1.396 sec)
23.275... logprob:  0.894082, 0.350260 (1.418 sec)
23.276... logprob:  0.589363, 0.268229 (1.411 sec)
23.277... logprob:  0.630503, 0.265625 (1.422 sec)
23.278... logprob:  0.544476, 0.256510 (1.415 sec)
23.279... logprob:  0.620330, 0.255208 (1.455 sec)
23.280... logprob:  0.501384, 0.252604 (1.397 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.477906, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.266373e-03 [1.634530e-07] 
Layer 'conv1' biases: 2.079364e-06 [1.142572e-10] 
Layer 'conv2' weights[0]: 3.260040e-03 [1.631534e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.259657e-09] 
Layer 'conv3' weights[0]: 3.258721e-03 [1.635690e-07] 
Layer 'conv3' biases: 3.447515e-05 [1.002747e-08] 
Layer 'conv4' weights[0]: 3.272470e-03 [1.647060e-07] 
Layer 'conv4' biases: 9.999218e-01 [2.353593e-07] 
Layer 'conv5' weights[0]: 3.401693e-03 [2.447038e-06] 
Layer 'conv5' biases: 9.991599e-01 [2.611695e-06] 
Layer 'fc6' weights[0]: 6.919656e-03 [6.155560e-08] 
Layer 'fc6' biases: 9.999909e-01 [5.529117e-08] 
Layer 'fc7' weights[0]: 7.268074e-03 [1.415944e-07] 
Layer 'fc7' biases: 9.997642e-01 [1.893207e-07] 
Layer 'fc8' weights[0]: 4.659237e-03 [1.422860e-05] 
Layer 'fc8' biases: 1.819141e-02 [3.465612e-05] 
Train error last 800 batches: 0.655647
-------------------------------------------------------
Not saving because 0.477906 > 0.299667 (9.300: -1.18%)
======================================================= (2.357 sec)
23.281... logprob:  0.614935, 0.291667 (1.429 sec)
23.282... logprob:  0.702565, 0.325521 (1.422 sec)
23.283... logprob:  0.573999, 0.234375 (1.415 sec)
23.284... logprob:  0.581411, 0.253906 (1.412 sec)
23.285... logprob:  0.710549, 0.313802 (1.431 sec)
23.286... logprob:  0.730732, 0.307292 (1.433 sec)
23.287... logprob:  0.630421, 0.309896 (1.422 sec)
23.288... logprob:  0.550478, 0.242187 (1.432 sec)
23.289... logprob:  0.651581, 0.300781 (1.455 sec)
23.290... logprob:  0.694769, 0.315104 (1.409 sec)
23.291... logprob:  0.683307, 0.330729 (1.415 sec)
23.292... logprob:  0.710469, 0.296875 (1.412 sec)
23.293... logprob:  0.631822, 0.273438 (1.439 sec)
23.294... logprob:  0.626492, 0.276042 (1.398 sec)
23.295... logprob:  0.567244, 0.274740 (1.464 sec)
23.296... logprob:  0.555013, 0.253906 (1.413 sec)
23.297... logprob:  0.638230, 0.273438 (1.423 sec)
23.298... logprob:  0.683124, 0.315104 (1.461 sec)
23.299... logprob:  0.570012, 0.261719 (1.399 sec)
23.300... logprob:  0.620395, 0.294271 (1.414 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.489657, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.263103e-03 [1.634105e-07] 
Layer 'conv1' biases: 2.080095e-06 [1.211662e-10] 
Layer 'conv2' weights[0]: 3.256789e-03 [1.631196e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.659642e-09] 
Layer 'conv3' weights[0]: 3.255470e-03 [1.636143e-07] 
Layer 'conv3' biases: 3.446179e-05 [1.165753e-08] 
Layer 'conv4' weights[0]: 3.269202e-03 [1.650042e-07] 
Layer 'conv4' biases: 9.999201e-01 [2.731640e-07] 
Layer 'conv5' weights[0]: 3.397951e-03 [2.907329e-06] 
Layer 'conv5' biases: 9.991347e-01 [3.234341e-06] 
Layer 'fc6' weights[0]: 6.918992e-03 [6.651376e-08] 
Layer 'fc6' biases: 9.999909e-01 [6.187307e-08] 
Layer 'fc7' weights[0]: 7.267341e-03 [1.526498e-07] 
Layer 'fc7' biases: 9.997658e-01 [2.358953e-07] 
Layer 'fc8' weights[0]: 4.717223e-03 [1.505608e-05] 
Layer 'fc8' biases: 1.865266e-02 [4.005777e-05] 
Train error last 800 batches: 0.655331
-------------------------------------------------------
Not saving because 0.489657 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
23.301... logprob:  0.662021, 0.278646 (1.418 sec)
23.302... logprob:  0.782394, 0.324219 (1.418 sec)
23.303... logprob:  0.677988, 0.274740 (1.401 sec)
23.304... logprob:  0.733160, 0.326823 (1.431 sec)
23.305... logprob:  0.607718, 0.259115 (1.433 sec)
23.306... logprob:  0.702147, 0.309896 (1.429 sec)
23.307... logprob:  0.619205, 0.303385 (1.442 sec)
23.308... logprob:  0.679583, 0.320312 (1.455 sec)
23.309... logprob:  0.688643, 0.313802 (1.406 sec)
23.310... logprob:  0.632083, 0.294271 (1.419 sec)
23.311... logprob:  0.726298, 0.319010 (1.423 sec)
23.312... logprob:  0.688590, 0.295573 (1.428 sec)
23.313... logprob:  0.687210, 0.285156 (1.416 sec)
23.314... logprob:  0.687282, 0.289062 (1.464 sec)
23.315... logprob:  0.597417, 0.279948 (1.428 sec)
23.316... logprob:  0.643434, 0.287760 (1.425 sec)
23.317... logprob:  0.617739, 0.286458 (1.487 sec)
23.318... logprob:  0.649981, 0.272135 (1.416 sec)
23.319... logprob:  0.586927, 0.255208 (1.444 sec)
23.320... logprob:  0.663717, 0.299479 (1.424 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.561009, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.259846e-03 [1.630622e-07] 
Layer 'conv1' biases: 2.080380e-06 [9.901402e-11] 
Layer 'conv2' weights[0]: 3.253545e-03 [1.628096e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.177035e-09] 
Layer 'conv3' weights[0]: 3.252243e-03 [1.631390e-07] 
Layer 'conv3' biases: 3.448544e-05 [9.255204e-09] 
Layer 'conv4' weights[0]: 3.265908e-03 [1.640547e-07] 
Layer 'conv4' biases: 9.999185e-01 [1.897418e-07] 
Layer 'conv5' weights[0]: 3.393804e-03 [2.224767e-06] 
Layer 'conv5' biases: 9.991539e-01 [2.315248e-06] 
Layer 'fc6' weights[0]: 6.918276e-03 [5.898012e-08] 
Layer 'fc6' biases: 9.999912e-01 [5.195682e-08] 
Layer 'fc7' weights[0]: 7.266632e-03 [1.332657e-07] 
Layer 'fc7' biases: 9.997644e-01 [1.572941e-07] 
Layer 'fc8' weights[0]: 4.674009e-03 [1.247519e-05] 
Layer 'fc8' biases: 1.839117e-02 [2.108743e-05] 
Train error last 800 batches: 0.655007
-------------------------------------------------------
Not saving because 0.561009 > 0.299667 (9.300: -1.18%)
======================================================= (2.408 sec)
23.321... logprob:  0.660665, 0.316406 (1.425 sec)
23.322... logprob:  0.647864, 0.317708 (1.424 sec)
23.323... logprob:  0.630716, 0.290365 (1.472 sec)
23.324... logprob:  0.709534, 0.304688 (1.422 sec)
23.325... logprob:  0.631071, 0.260417 (1.428 sec)
23.326... logprob:  0.776341, 0.329427 (1.455 sec)
23.327... logprob:  0.653121, 0.305990 (1.417 sec)
23.328... logprob:  0.738689, 0.329427 (1.434 sec)
23.329... logprob:  0.587876, 0.256510 (1.420 sec)
23.330... logprob:  0.517102, 0.226562 (1.418 sec)
23.331... logprob:  0.577613, 0.270833 (1.424 sec)
23.332... logprob:  0.667253, 0.273437 (1.454 sec)
23.333... logprob:  0.619509, 0.292969 (1.443 sec)
23.334... logprob:  0.751998, 0.329427 (1.435 sec)
23.335... logprob:  0.558672, 0.239583 (1.440 sec)
23.336... logprob:  0.690052, 0.282552 (1.455 sec)
23.337... logprob:  0.757489, 0.325521 (1.416 sec)
23.338... logprob:  0.528048, 0.244792 (1.416 sec)
23.339... logprob:  0.691126, 0.292969 (1.418 sec)
23.340... logprob:  0.656388, 0.270833 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.437737, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.256586e-03 [1.629270e-07] 
Layer 'conv1' biases: 2.080791e-06 [8.783615e-11] 
Layer 'conv2' weights[0]: 3.250292e-03 [1.626408e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.074153e-09] 
Layer 'conv3' weights[0]: 3.249003e-03 [1.628229e-07] 
Layer 'conv3' biases: 3.449717e-05 [8.001143e-09] 
Layer 'conv4' weights[0]: 3.262664e-03 [1.636872e-07] 
Layer 'conv4' biases: 9.999182e-01 [1.766224e-07] 
Layer 'conv5' weights[0]: 3.390440e-03 [2.220981e-06] 
Layer 'conv5' biases: 9.991456e-01 [2.417159e-06] 
Layer 'fc6' weights[0]: 6.917551e-03 [6.029172e-08] 
Layer 'fc6' biases: 9.999911e-01 [5.362821e-08] 
Layer 'fc7' weights[0]: 7.265918e-03 [1.362481e-07] 
Layer 'fc7' biases: 9.997647e-01 [1.573443e-07] 
Layer 'fc8' weights[0]: 4.692784e-03 [1.182276e-05] 
Layer 'fc8' biases: 1.859805e-02 [1.356843e-06] 
Train error last 800 batches: 0.654451
-------------------------------------------------------
Not saving because 0.437737 > 0.299667 (9.300: -1.18%)
======================================================= (2.377 sec)
23.341... logprob:  0.690444, 0.319010 (1.421 sec)
23.342... logprob:  0.579541, 0.268229 (1.464 sec)
23.343... logprob:  0.618367, 0.246094 (1.440 sec)
23.344... logprob:  0.620809, 0.294271 (1.475 sec)
23.345... logprob:  0.735724, 0.303385 (1.434 sec)
23.346... logprob:  0.591124, 0.242187 (1.430 sec)
23.347... logprob:  0.586626, 0.243490 (1.476 sec)
23.348... logprob:  0.663767, 0.305990 (1.434 sec)
23.349... logprob:  0.771504, 0.333333 (1.424 sec)
23.350... logprob:  0.600060, 0.260417 (1.431 sec)
23.351... logprob:  0.760618, 0.328125 (1.422 sec)
23.352... logprob:  0.535211, 0.255208 (1.431 sec)
23.353... logprob:  0.732951, 0.317708 (1.487 sec)
23.354... logprob:  0.834113, 0.348958 (1.435 sec)
23.355... logprob:  0.591027, 0.274740 (1.445 sec)
23.356... logprob:  0.666502, 0.312500 (1.477 sec)
23.357... logprob:  0.617360, 0.279948 (1.433 sec)
23.358... logprob:  0.558142, 0.250000 (1.431 sec)
23.359... logprob:  0.747182, 0.324219 (1.424 sec)
23.360... logprob:  0.721708, 0.339844 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.517847, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.253323e-03 [1.626722e-07] 
Layer 'conv1' biases: 2.081131e-06 [8.696151e-11] 
Layer 'conv2' weights[0]: 3.247025e-03 [1.623812e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.048022e-09] 
Layer 'conv3' weights[0]: 3.245752e-03 [1.626667e-07] 
Layer 'conv3' biases: 3.450737e-05 [8.733927e-09] 
Layer 'conv4' weights[0]: 3.259430e-03 [1.636784e-07] 
Layer 'conv4' biases: 9.999189e-01 [1.979438e-07] 
Layer 'conv5' weights[0]: 3.387863e-03 [2.192103e-06] 
Layer 'conv5' biases: 9.991518e-01 [2.295603e-06] 
Layer 'fc6' weights[0]: 6.916850e-03 [6.052309e-08] 
Layer 'fc6' biases: 9.999911e-01 [5.397553e-08] 
Layer 'fc7' weights[0]: 7.265174e-03 [1.366980e-07] 
Layer 'fc7' biases: 9.997640e-01 [1.671141e-07] 
Layer 'fc8' weights[0]: 4.670536e-03 [1.256842e-05] 
Layer 'fc8' biases: 1.847607e-02 [2.018012e-05] 
Train error last 800 batches: 0.654157
-------------------------------------------------------
Not saving because 0.517847 > 0.299667 (9.300: -1.18%)
======================================================= (2.371 sec)
23.361... logprob:  0.684911, 0.287760 (1.435 sec)
23.362... logprob:  0.636064, 0.264323 (1.478 sec)
23.363... logprob:  0.733202, 0.334635 (1.435 sec)
23.364... logprob:  0.656482, 0.274740 (1.444 sec)
23.365... logprob:  0.679233, 0.276042 (1.457 sec)
23.366... logprob:  0.629996, 0.291667 (1.442 sec)
23.367... logprob:  0.503444, 0.203125 (1.525 sec)
23.368... logprob:  0.743423, 0.322917 (1.430 sec)
23.369... logprob:  0.557031, 0.259115 (1.425 sec)
23.370... logprob:  0.620319, 0.274740 (1.443 sec)
23.371... logprob:  0.683867, 0.315104 (1.459 sec)
23.372... logprob:  0.630912, 0.261719 (1.457 sec)
23.373... logprob:  0.723528, 0.332031 (1.455 sec)
23.374... logprob:  0.645372, 0.276042 (1.451 sec)
23.375... logprob:  0.631009, 0.308594 (1.455 sec)
23.376... logprob:  0.593831, 0.255208 (1.435 sec)
23.377... logprob:  0.544421, 0.213542 (1.424 sec)
23.378... logprob:  0.678304, 0.276042 (1.422 sec)
23.379... logprob:  0.676377, 0.302083 (1.434 sec)
23.380... logprob:  0.812168, 0.351562 (1.432 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.487033, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.250084e-03 [1.626610e-07] 
Layer 'conv1' biases: 2.081142e-06 [1.102036e-10] 
Layer 'conv2' weights[0]: 3.243804e-03 [1.623133e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.246264e-09] 
Layer 'conv3' weights[0]: 3.242485e-03 [1.627284e-07] 
Layer 'conv3' biases: 3.450884e-05 [8.955697e-09] 
Layer 'conv4' weights[0]: 3.256150e-03 [1.637267e-07] 
Layer 'conv4' biases: 9.999208e-01 [2.188161e-07] 
Layer 'conv5' weights[0]: 3.385920e-03 [2.497578e-06] 
Layer 'conv5' biases: 9.991469e-01 [2.658509e-06] 
Layer 'fc6' weights[0]: 6.916137e-03 [6.414687e-08] 
Layer 'fc6' biases: 9.999910e-01 [5.855423e-08] 
Layer 'fc7' weights[0]: 7.264455e-03 [1.459603e-07] 
Layer 'fc7' biases: 9.997640e-01 [1.842314e-07] 
Layer 'fc8' weights[0]: 4.679291e-03 [1.437907e-05] 
Layer 'fc8' biases: 1.854655e-02 [2.924486e-05] 
Train error last 800 batches: 0.654442
-------------------------------------------------------
Not saving because 0.487033 > 0.299667 (9.300: -1.18%)
======================================================= (2.403 sec)
23.381... logprob:  0.702696, 0.328125 (1.471 sec)
23.382... logprob:  0.721467, 0.324219 (1.449 sec)
23.383... logprob:  0.659364, 0.324219 (1.434 sec)
23.384... logprob:  0.786343, 0.333333 (1.472 sec)
23.385... logprob:  0.765591, 0.317708 (1.427 sec)
23.386... logprob:  0.690290, 0.296875 (1.422 sec)
23.387... logprob:  0.622448, 0.298177 (1.436 sec)
23.388... logprob:  0.712880, 0.304687 (1.429 sec)
23.389... logprob:  0.580170, 0.251302 (1.426 sec)
23.390... logprob:  0.710744, 0.321615 (1.473 sec)
23.391... logprob:  0.584176, 0.279948 (1.442 sec)
23.392... logprob:  0.680955, 0.304687 (1.426 sec)
23.393... logprob:  0.607203, 0.285156 (1.481 sec)
23.394... logprob:  0.590919, 0.253906 (1.426 sec)
23.395... logprob:  0.567879, 0.252604 (1.425 sec)
23.396... logprob:  0.515403, 0.234375 (1.429 sec)
23.397... logprob:  0.612154, 0.278646 (1.422 sec)
23.398... logprob:  0.657826, 0.296875 (1.428 sec)
23.399... logprob:  0.690291, 0.316406 (1.478 sec)
23.400... logprob:  0.694732, 0.296875 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.515773, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.246831e-03 [1.625845e-07] 
Layer 'conv1' biases: 2.081465e-06 [1.350132e-10] 
Layer 'conv2' weights[0]: 3.240549e-03 [1.621991e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.288497e-09] 
Layer 'conv3' weights[0]: 3.239240e-03 [1.625293e-07] 
Layer 'conv3' biases: 3.448678e-05 [9.040277e-09] 
Layer 'conv4' weights[0]: 3.252882e-03 [1.636078e-07] 
Layer 'conv4' biases: 9.999204e-01 [2.125344e-07] 
Layer 'conv5' weights[0]: 3.383005e-03 [2.293356e-06] 
Layer 'conv5' biases: 9.991510e-01 [2.418232e-06] 
Layer 'fc6' weights[0]: 6.915437e-03 [6.273455e-08] 
Layer 'fc6' biases: 9.999909e-01 [5.659270e-08] 
Layer 'fc7' weights[0]: 7.263771e-03 [1.417976e-07] 
Layer 'fc7' biases: 9.997634e-01 [1.888077e-07] 
Layer 'fc8' weights[0]: 4.666690e-03 [1.318066e-05] 
Layer 'fc8' biases: 1.843512e-02 [2.878472e-05] 
Train error last 800 batches: 0.654317
-------------------------------------------------------
Not saving because 0.515773 > 0.299667 (9.300: -1.18%)
======================================================= (2.368 sec)
23.401... logprob:  0.722453, 0.289062 (1.446 sec)
23.402... logprob:  0.701144, 0.302083 (1.478 sec)
23.403... logprob:  0.696680, 0.286458 (1.427 sec)
23.404... logprob:  0.667205, 0.289062 (1.429 sec)
23.405... logprob:  0.768245, 0.324219 (1.429 sec)
23.406... logprob:  0.631235, 0.309896 (1.428 sec)
23.407... logprob:  0.766602, 0.320312 (1.425 sec)
23.408... logprob:  0.551807, 0.260417 (1.482 sec)
23.409... logprob:  0.682497, 0.283854 (1.435 sec)
23.410... logprob:  0.718500, 0.282552 (1.453 sec)
23.411... logprob:  0.616928, 0.272135 (1.471 sec)
23.412... logprob:  0.750057, 0.305990 (1.432 sec)
23.413... logprob:  0.673242, 0.302083 (1.436 sec)
23.414... logprob:  0.697112, 0.320312 (1.426 sec)
23.415... logprob:  0.616753, 0.283854 (1.428 sec)
23.416... logprob:  0.673376, 0.289062 (1.436 sec)
23.417... logprob:  0.647929, 0.274740 (1.457 sec)
23.418... logprob:  0.644879, 0.285156 (1.447 sec)
23.419... logprob:  0.674195, 0.291667 (1.445 sec)
23.420... logprob:  0.528037, 0.233073 (1.450 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.512322, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.243581e-03 [1.623167e-07] 
Layer 'conv1' biases: 2.082176e-06 [1.204404e-10] 
Layer 'conv2' weights[0]: 3.237311e-03 [1.619749e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.412160e-10] 
Layer 'conv3' weights[0]: 3.236008e-03 [1.621331e-07] 
Layer 'conv3' biases: 3.449391e-05 [6.750636e-09] 
Layer 'conv4' weights[0]: 3.249643e-03 [1.632479e-07] 
Layer 'conv4' biases: 9.999222e-01 [1.864154e-07] 
Layer 'conv5' weights[0]: 3.380915e-03 [2.800759e-06] 
Layer 'conv5' biases: 9.991628e-01 [3.008166e-06] 
Layer 'fc6' weights[0]: 6.914725e-03 [6.686386e-08] 
Layer 'fc6' biases: 9.999909e-01 [6.177232e-08] 
Layer 'fc7' weights[0]: 7.263051e-03 [1.553158e-07] 
Layer 'fc7' biases: 9.997622e-01 [2.309039e-07] 
Layer 'fc8' weights[0]: 4.641618e-03 [1.628663e-05] 
Layer 'fc8' biases: 1.831538e-02 [3.770602e-05] 
Train error last 800 batches: 0.654572
-------------------------------------------------------
Not saving because 0.512322 > 0.299667 (9.300: -1.18%)
======================================================= (2.360 sec)
23.421... logprob:  0.693332, 0.303385 (1.457 sec)
23.422... logprob:  0.677305, 0.309896 (1.439 sec)
23.423... logprob:  0.598767, 0.263021 (1.426 sec)
23.424... logprob:  0.593570, 0.283854 (1.426 sec)
23.425... logprob:  0.665499, 0.299479 (1.430 sec)
23.426... logprob:  0.665464, 0.260417 (1.439 sec)
23.427... logprob:  0.758181, 0.326823 (1.458 sec)
23.428... logprob:  0.754112, 0.345052 (1.454 sec)
23.429... logprob:  0.717367, 0.337239 (1.442 sec)
23.430... logprob:  0.614236, 0.250000 (1.470 sec)
23.431... logprob:  0.692315, 0.287760 (1.427 sec)
23.432... logprob:  0.583183, 0.264323 (1.421 sec)
23.433... logprob:  0.623717, 0.270833 (1.425 sec)
23.434... logprob:  0.745988, 0.311198 (1.434 sec)
23.435... logprob:  0.627831, 0.253906 (1.424 sec)
23.436... logprob:  0.665604, 0.292969 (1.471 sec)
23.437... logprob:  0.753995, 0.326823 (1.438 sec)
23.438... logprob:  0.659799, 0.278646 (1.426 sec)
23.439... logprob:  0.585483, 0.255208 (1.482 sec)
23.440... logprob:  0.768418, 0.304688 (1.423 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.495918, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.240339e-03 [1.622809e-07] 
Layer 'conv1' biases: 2.082793e-06 [1.382772e-10] 
Layer 'conv2' weights[0]: 3.234077e-03 [1.618414e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.396197e-09] 
Layer 'conv3' weights[0]: 3.232773e-03 [1.623003e-07] 
Layer 'conv3' biases: 3.451780e-05 [1.154539e-08] 
Layer 'conv4' weights[0]: 3.246388e-03 [1.634577e-07] 
Layer 'conv4' biases: 9.999214e-01 [2.535242e-07] 
Layer 'conv5' weights[0]: 3.377559e-03 [2.465859e-06] 
Layer 'conv5' biases: 9.991484e-01 [2.674023e-06] 
Layer 'fc6' weights[0]: 6.913997e-03 [6.727507e-08] 
Layer 'fc6' biases: 9.999909e-01 [6.259140e-08] 
Layer 'fc7' weights[0]: 7.262284e-03 [1.555096e-07] 
Layer 'fc7' biases: 9.997630e-01 [2.135285e-07] 
Layer 'fc8' weights[0]: 4.664825e-03 [1.596264e-05] 
Layer 'fc8' biases: 1.852941e-02 [4.011688e-05] 
Train error last 800 batches: 0.654503
-------------------------------------------------------
Not saving because 0.495918 > 0.299667 (9.300: -1.18%)
======================================================= (2.347 sec)
23.441... logprob:  0.786367, 0.312500 (1.430 sec)
23.442... logprob:  0.596559, 0.273437 (1.439 sec)
23.443... logprob:  0.676302, 0.265625 (1.430 sec)
23.444... logprob:  0.615048, 0.270833 (1.425 sec)
23.445... logprob:  0.661665, 0.283854 (1.479 sec)
23.446... logprob:  0.571340, 0.286458 (1.439 sec)
23.447... logprob:  0.689572, 0.283854 (1.436 sec)
23.448... logprob:  0.587365, 0.261719 (1.477 sec)
23.449... logprob:  0.679592, 0.295573 (1.428 sec)
23.450... logprob:  0.510807, 0.235677 (1.433 sec)
23.451... logprob:  0.692746, 0.279948 (1.431 sec)
23.452... logprob:  0.697531, 0.303385 (1.420 sec)
23.453... logprob:  0.617786, 0.264323 (1.430 sec)
23.454... logprob:  0.713150, 0.315104 (1.473 sec)
23.455... logprob:  0.768560, 0.322917 (1.432 sec)
23.456... logprob:  0.690489, 0.307292 (1.439 sec)
23.457... logprob:  0.611784, 0.305990 (1.469 sec)
23.458... logprob:  0.609173, 0.294271 (1.428 sec)
23.459... logprob:  0.757853, 0.321615 (1.428 sec)
23.460... logprob:  0.588880, 0.292969 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.407434, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.237107e-03 [1.621207e-07] 
Layer 'conv1' biases: 2.083382e-06 [1.347047e-10] 
Layer 'conv2' weights[0]: 3.230824e-03 [1.617548e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.472841e-09] 
Layer 'conv3' weights[0]: 3.229532e-03 [1.622104e-07] 
Layer 'conv3' biases: 3.452809e-05 [1.073499e-08] 
Layer 'conv4' weights[0]: 3.243137e-03 [1.635178e-07] 
Layer 'conv4' biases: 9.999229e-01 [2.806334e-07] 
Layer 'conv5' weights[0]: 3.375702e-03 [2.743225e-06] 
Layer 'conv5' biases: 9.991363e-01 [2.975715e-06] 
Layer 'fc6' weights[0]: 6.913246e-03 [6.555582e-08] 
Layer 'fc6' biases: 9.999908e-01 [6.048511e-08] 
Layer 'fc7' weights[0]: 7.261534e-03 [1.501477e-07] 
Layer 'fc7' biases: 9.997634e-01 [2.193288e-07] 
Layer 'fc8' weights[0]: 4.682663e-03 [1.565304e-05] 
Layer 'fc8' biases: 1.868993e-02 [4.192245e-05] 
Train error last 800 batches: 0.654822
-------------------------------------------------------
Not saving because 0.407434 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
23.461... logprob:  0.714334, 0.311198 (1.427 sec)
23.462... logprob:  0.676651, 0.268229 (1.437 sec)
23.463... logprob:  0.660868, 0.279948 (1.471 sec)
23.464... logprob:  0.717392, 0.322917 (1.439 sec)
23.465... logprob:  0.645989, 0.264323 (1.448 sec)
23.466... logprob:  0.631109, 0.300781 (1.454 sec)
23.467... logprob:  0.597577, 0.274740 (1.443 sec)
23.468... logprob:  0.632512, 0.286458 (1.435 sec)
23.469... logprob:  0.615912, 0.285156 (1.427 sec)
23.470... logprob:  0.562028, 0.236979 (1.422 sec)
23.471... logprob:  0.700994, 0.285156 (1.439 sec)
23.472... logprob:  0.628457, 0.290365 (1.452 sec)
23.473... logprob:  0.595805, 0.287760 (1.451 sec)
23.474... logprob:  0.650629, 0.289062 (1.450 sec)
23.475... logprob:  0.777277, 0.324219 (1.440 sec)
23.476... logprob:  0.671340, 0.269531 (1.463 sec)
23.477... logprob:  0.623089, 0.294271 (1.439 sec)
23.478... logprob:  0.727270, 0.299479 (1.417 sec)
23.479... logprob:  0.539492, 0.247396 (1.426 sec)
23.480... logprob:  0.654815, 0.290365 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.432130, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.233859e-03 [1.619242e-07] 
Layer 'conv1' biases: 2.083212e-06 [9.048843e-11] 
Layer 'conv2' weights[0]: 3.227609e-03 [1.615252e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.259863e-10] 
Layer 'conv3' weights[0]: 3.226301e-03 [1.616277e-07] 
Layer 'conv3' biases: 3.453730e-05 [6.776247e-09] 
Layer 'conv4' weights[0]: 3.239904e-03 [1.625043e-07] 
Layer 'conv4' biases: 9.999255e-01 [1.617043e-07] 
Layer 'conv5' weights[0]: 3.374196e-03 [1.920657e-06] 
Layer 'conv5' biases: 9.991265e-01 [2.029330e-06] 
Layer 'fc6' weights[0]: 6.912537e-03 [6.027566e-08] 
Layer 'fc6' biases: 9.999910e-01 [5.377809e-08] 
Layer 'fc7' weights[0]: 7.260824e-03 [1.371351e-07] 
Layer 'fc7' biases: 9.997637e-01 [1.676956e-07] 
Layer 'fc8' weights[0]: 4.695536e-03 [1.267423e-05] 
Layer 'fc8' biases: 1.883146e-02 [1.729514e-05] 
Train error last 800 batches: 0.655012
-------------------------------------------------------
Not saving because 0.432130 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
23.481... logprob:  0.731277, 0.285156 (1.444 sec)
23.482... logprob:  0.699472, 0.311198 (1.481 sec)
23.483... logprob:  0.782062, 0.339844 (1.445 sec)
23.484... logprob:  0.711483, 0.309896 (1.447 sec)
23.485... logprob:  0.552526, 0.252604 (1.480 sec)
23.486... logprob:  0.566242, 0.227865 (1.424 sec)
23.487... logprob:  0.692458, 0.287760 (1.424 sec)
23.488... logprob:  0.656909, 0.302083 (1.441 sec)
23.489... logprob:  0.617709, 0.243490 (1.429 sec)
23.490... logprob:  0.587273, 0.257812 (1.426 sec)
23.491... logprob:  0.603581, 0.281250 (1.473 sec)
23.492... logprob:  0.669011, 0.294271 (1.436 sec)
23.493... logprob:  0.716007, 0.298177 (1.430 sec)
23.494... logprob:  0.711693, 0.307292 (1.481 sec)
23.495... logprob:  0.655325, 0.270833 (1.431 sec)
23.496... logprob:  0.736355, 0.324219 (1.431 sec)
23.497... logprob:  0.612463, 0.248698 (1.429 sec)
23.498... logprob:  0.634965, 0.286458 (1.423 sec)
23.499... logprob:  0.707575, 0.283854 (1.429 sec)
23.500... logprob:  0.624732, 0.272135 (1.487 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.418309, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.230636e-03 [1.616382e-07] 
Layer 'conv1' biases: 2.083901e-06 [1.359140e-10] 
Layer 'conv2' weights[0]: 3.224385e-03 [1.613338e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.264151e-09] 
Layer 'conv3' weights[0]: 3.223087e-03 [1.616384e-07] 
Layer 'conv3' biases: 3.457456e-05 [9.514217e-09] 
Layer 'conv4' weights[0]: 3.236663e-03 [1.626316e-07] 
Layer 'conv4' biases: 9.999243e-01 [2.304690e-07] 
Layer 'conv5' weights[0]: 3.370919e-03 [2.467801e-06] 
Layer 'conv5' biases: 9.991472e-01 [2.608443e-06] 
Layer 'fc6' weights[0]: 6.911804e-03 [6.230299e-08] 
Layer 'fc6' biases: 9.999913e-01 [5.636744e-08] 
Layer 'fc7' weights[0]: 7.260100e-03 [1.417529e-07] 
Layer 'fc7' biases: 9.997620e-01 [1.683525e-07] 
Layer 'fc8' weights[0]: 4.644569e-03 [1.265063e-05] 
Layer 'fc8' biases: 1.843309e-02 [1.296703e-05] 
Train error last 800 batches: 0.655034
-------------------------------------------------------
Not saving because 0.418309 > 0.299667 (9.300: -1.18%)
======================================================= (2.414 sec)
23.501... logprob:  0.643531, 0.286458 (1.437 sec)
23.502... logprob:  0.724714, 0.333333 (1.446 sec)
23.503... logprob:  0.669481, 0.287760 (1.473 sec)
23.504... logprob:  0.739762, 0.342448 (1.428 sec)
23.505... logprob:  0.821607, 0.304687 (1.433 sec)
23.506... logprob:  0.687357, 0.317708 (1.429 sec)
23.507... logprob:  0.626148, 0.291667 (1.421 sec)
23.508... logprob:  0.571779, 0.239583 (1.425 sec)
23.509... logprob:  0.562714, 0.235677 (1.473 sec)
23.510... logprob:  0.644532, 0.273438 (1.434 sec)
23.511... logprob:  0.676432, 0.295573 (1.445 sec)
23.512... logprob:  0.758532, 0.339844 (1.456 sec)
23.513... logprob:  0.582624, 0.276042 (1.438 sec)
23.514... logprob:  0.621173, 0.261719 (1.433 sec)
23.515... logprob:  0.753712, 0.309896 (1.425 sec)
23.516... logprob:  0.754978, 0.321615 (1.418 sec)
23.517... logprob:  0.745649, 0.316406 (1.438 sec)
23.518... logprob:  0.773246, 0.321615 (1.453 sec)
23.519... logprob:  0.570870, 0.252604 (1.447 sec)
23.520... logprob:  0.618590, 0.290364 (1.448 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.512135, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.227408e-03 [1.613542e-07] 
Layer 'conv1' biases: 2.084578e-06 [1.374509e-10] 
Layer 'conv2' weights[0]: 3.221165e-03 [1.611435e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.206422e-09] 
Layer 'conv3' weights[0]: 3.219851e-03 [1.614730e-07] 
Layer 'conv3' biases: 3.460865e-05 [9.445229e-09] 
Layer 'conv4' weights[0]: 3.233448e-03 [1.623927e-07] 
Layer 'conv4' biases: 9.999243e-01 [1.975519e-07] 
Layer 'conv5' weights[0]: 3.367917e-03 [2.384055e-06] 
Layer 'conv5' biases: 9.991586e-01 [2.587827e-06] 
Layer 'fc6' weights[0]: 6.911067e-03 [6.428835e-08] 
Layer 'fc6' biases: 9.999911e-01 [5.842551e-08] 
Layer 'fc7' weights[0]: 7.259325e-03 [1.494153e-07] 
Layer 'fc7' biases: 9.997617e-01 [2.006716e-07] 
Layer 'fc8' weights[0]: 4.623747e-03 [1.500500e-05] 
Layer 'fc8' biases: 1.828899e-02 [3.110980e-05] 
Train error last 800 batches: 0.655869
-------------------------------------------------------
Not saving because 0.512135 > 0.299667 (9.300: -1.18%)
======================================================= (2.355 sec)
23.521... logprob:  0.622019, 0.266927 (1.451 sec)
23.522... logprob:  0.706456, 0.307292 (1.489 sec)
23.523... logprob:  0.514598, 0.225260 (1.438 sec)
23.524... logprob:  0.631536, 0.277344 (1.417 sec)
23.525... logprob:  0.570923, 0.243490 (1.423 sec)
23.526... logprob:  0.518262, 0.225260 (1.435 sec)
23.527... logprob:  0.772468, 0.325521 (1.439 sec)
23.528... logprob:  0.698063, 0.320312 (1.461 sec)
23.529... logprob:  0.632601, 0.291667 (1.447 sec)
23.530... logprob:  0.674264, 0.266927 (1.437 sec)
23.531... logprob:  0.582990, 0.235677 (1.476 sec)
23.532... logprob:  0.630023, 0.272135 (1.423 sec)
23.533... logprob:  0.721885, 0.316406 (1.424 sec)
23.534... logprob:  0.577349, 0.248698 (1.424 sec)
23.535... logprob:  0.805553, 0.339844 (1.428 sec)
23.536... logprob:  0.692465, 0.307292 (1.432 sec)
23.537... logprob:  0.725558, 0.309896 (1.476 sec)
23.538... logprob:  0.726729, 0.325521 (1.439 sec)
23.539... logprob:  0.578709, 0.289062 (1.427 sec)
23.540... logprob:  0.625822, 0.282552 (1.478 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.475753, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.224180e-03 [1.614303e-07] 
Layer 'conv1' biases: 2.085169e-06 [1.395975e-10] 
Layer 'conv2' weights[0]: 3.217943e-03 [1.610498e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.892271e-09] 
Layer 'conv3' weights[0]: 3.216646e-03 [1.618115e-07] 
Layer 'conv3' biases: 3.459487e-05 [1.297759e-08] 
Layer 'conv4' weights[0]: 3.230195e-03 [1.628444e-07] 
Layer 'conv4' biases: 9.999268e-01 [2.812195e-07] 
Layer 'conv5' weights[0]: 3.366155e-03 [2.324957e-06] 
Layer 'conv5' biases: 9.991488e-01 [2.527217e-06] 
Layer 'fc6' weights[0]: 6.910333e-03 [6.182045e-08] 
Layer 'fc6' biases: 9.999908e-01 [5.551012e-08] 
Layer 'fc7' weights[0]: 7.258639e-03 [1.398890e-07] 
Layer 'fc7' biases: 9.997622e-01 [1.775083e-07] 
Layer 'fc8' weights[0]: 4.648678e-03 [1.330523e-05] 
Layer 'fc8' biases: 1.849132e-02 [2.318983e-05] 
Train error last 800 batches: 0.655264
-------------------------------------------------------
Not saving because 0.475753 > 0.299667 (9.300: -1.18%)
======================================================= (2.380 sec)
23.541... logprob:  0.613832, 0.286458 (1.433 sec)
23.542... logprob:  0.672308, 0.299479 (1.429 sec)
23.543... logprob:  0.485815, 0.203125 (1.428 sec)
23.544... logprob:  0.519656, 0.204427 (1.425 sec)
23.545... logprob:  0.620392, 0.265625 (1.425 sec)
23.546... logprob:  0.614023, 0.278646 (1.481 sec)
23.547... logprob:  0.623085, 0.287760 (1.428 sec)
23.548... logprob:  0.686784, 0.300781 (1.435 sec)
23.549... logprob:  0.676517, 0.286458 (1.472 sec)
23.550... logprob:  0.613968, 0.277344 (1.424 sec)
23.551... logprob:  0.604021, 0.251302 (1.433 sec)
23.552... logprob:  0.550782, 0.233073 (1.434 sec)
23.553... logprob:  0.608246, 0.272135 (1.424 sec)
23.554... logprob:  0.687822, 0.263021 (1.432 sec)
23.555... logprob:  0.570322, 0.259114 (1.480 sec)
23.556... logprob:  0.654797, 0.302083 (1.440 sec)
23.557... logprob:  0.616141, 0.272135 (1.446 sec)
23.558... logprob:  0.705632, 0.315104 (1.467 sec)
23.559... logprob:  0.642692, 0.272135 (1.438 sec)
23.560... logprob:  0.608077, 0.298177 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.544451, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.220957e-03 [1.612439e-07] 
Layer 'conv1' biases: 2.085394e-06 [8.557869e-11] 
Layer 'conv2' weights[0]: 3.214732e-03 [1.608720e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.966098e-10] 
Layer 'conv3' weights[0]: 3.213449e-03 [1.610580e-07] 
Layer 'conv3' biases: 3.459242e-05 [7.041035e-09] 
Layer 'conv4' weights[0]: 3.226986e-03 [1.620737e-07] 
Layer 'conv4' biases: 9.999272e-01 [1.709648e-07] 
Layer 'conv5' weights[0]: 3.363253e-03 [2.427870e-06] 
Layer 'conv5' biases: 9.991233e-01 [2.684858e-06] 
Layer 'fc6' weights[0]: 6.909613e-03 [5.950132e-08] 
Layer 'fc6' biases: 9.999909e-01 [5.261623e-08] 
Layer 'fc7' weights[0]: 7.257905e-03 [1.369017e-07] 
Layer 'fc7' biases: 9.997638e-01 [1.717565e-07] 
Layer 'fc8' weights[0]: 4.707917e-03 [1.386580e-05] 
Layer 'fc8' biases: 1.898987e-02 [2.383277e-05] 
Train error last 800 batches: 0.655439
-------------------------------------------------------
Not saving because 0.544451 > 0.299667 (9.300: -1.18%)
======================================================= (2.393 sec)
23.561... logprob:  0.683205, 0.298177 (1.434 sec)
23.562... logprob:  0.737291, 0.339844 (1.424 sec)
23.563... logprob:  0.568042, 0.229167 (1.439 sec)
23.564... logprob:  0.727507, 0.337240 (1.456 sec)
23.565... logprob:  0.814033, 0.329427 (1.449 sec)
23.566... logprob:  0.580536, 0.235677 (1.452 sec)
23.567... logprob:  0.601354, 0.268229 (1.460 sec)
23.568... logprob:  0.766965, 0.342448 (1.456 sec)
23.569... logprob:  0.667737, 0.309896 (1.438 sec)
23.570... logprob:  0.680205, 0.295573 (1.420 sec)
23.571... logprob:  0.540918, 0.246094 (1.424 sec)
23.572... logprob:  0.731576, 0.313802 (1.439 sec)
23.573... logprob:  0.783028, 0.317708 (1.439 sec)
23.574... logprob:  0.711239, 0.309896 (1.457 sec)
23.575... logprob:  0.606373, 0.283854 (1.446 sec)
23.576... logprob:  0.582342, 0.265625 (1.437 sec)
23.577... logprob:  0.709562, 0.287760 (1.469 sec)
23.578... logprob:  0.511154, 0.233073 (1.435 sec)
23.579... logprob:  0.579200, 0.250000 (1.421 sec)
23.580... logprob:  0.697114, 0.334635 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.429941, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.217745e-03 [1.609444e-07] 
Layer 'conv1' biases: 2.086201e-06 [1.322074e-10] 
Layer 'conv2' weights[0]: 3.211514e-03 [1.606557e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.212597e-09] 
Layer 'conv3' weights[0]: 3.210205e-03 [1.610045e-07] 
Layer 'conv3' biases: 3.462492e-05 [8.689821e-09] 
Layer 'conv4' weights[0]: 3.223748e-03 [1.621193e-07] 
Layer 'conv4' biases: 9.999228e-01 [2.018682e-07] 
Layer 'conv5' weights[0]: 3.357543e-03 [2.411116e-06] 
Layer 'conv5' biases: 9.991459e-01 [2.548452e-06] 
Layer 'fc6' weights[0]: 6.908901e-03 [6.177138e-08] 
Layer 'fc6' biases: 9.999908e-01 [5.533909e-08] 
Layer 'fc7' weights[0]: 7.257154e-03 [1.410829e-07] 
Layer 'fc7' biases: 9.997625e-01 [1.842174e-07] 
Layer 'fc8' weights[0]: 4.653811e-03 [1.345346e-05] 
Layer 'fc8' biases: 1.861261e-02 [2.416314e-05] 
Train error last 800 batches: 0.655497
-------------------------------------------------------
Not saving because 0.429941 > 0.299667 (9.300: -1.18%)
======================================================= (2.369 sec)
23.581... logprob:  0.706317, 0.313802 (1.443 sec)
23.582... logprob:  0.602503, 0.263021 (1.433 sec)
23.583... logprob:  0.784364, 0.317708 (1.475 sec)
23.584... logprob:  0.700591, 0.326823 (1.440 sec)
23.585... logprob:  0.591891, 0.247396 (1.425 sec)
23.586... logprob:  0.536873, 0.222656 (1.484 sec)
23.587... logprob:  0.642129, 0.259115 (1.424 sec)
23.588... logprob:  0.575230, 0.251302 (1.424 sec)
23.589... logprob:  0.645697, 0.303385 (1.427 sec)
23.590... logprob:  0.729543, 0.303385 (1.428 sec)
23.591... logprob:  0.671428, 0.302083 (1.427 sec)
23.592... logprob:  0.648885, 0.312500 (1.477 sec)
23.593... logprob:  0.699164, 0.317708 (1.430 sec)
23.594... logprob:  0.623565, 0.273437 (1.433 sec)
23.595... logprob:  0.646247, 0.264323 (1.483 sec)
23.596... logprob:  0.679778, 0.305990 (1.428 sec)
23.597... logprob:  0.655544, 0.279948 (1.435 sec)
23.598... logprob:  0.593386, 0.236979 (1.436 sec)
23.599... logprob:  0.591079, 0.250000 (1.421 sec)
23.600... logprob:  0.589018, 0.278646 (1.438 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.370115, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.214533e-03 [1.608058e-07] 
Layer 'conv1' biases: 2.087506e-06 [8.487694e-11] 
Layer 'conv2' weights[0]: 3.208303e-03 [1.605068e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.799459e-10] 
Layer 'conv3' weights[0]: 3.206968e-03 [1.606556e-07] 
Layer 'conv3' biases: 3.463997e-05 [6.046590e-09] 
Layer 'conv4' weights[0]: 3.220522e-03 [1.616660e-07] 
Layer 'conv4' biases: 9.999213e-01 [1.587486e-07] 
Layer 'conv5' weights[0]: 3.353432e-03 [2.262748e-06] 
Layer 'conv5' biases: 9.991317e-01 [2.367548e-06] 
Layer 'fc6' weights[0]: 6.908182e-03 [6.303906e-08] 
Layer 'fc6' biases: 9.999909e-01 [5.727664e-08] 
Layer 'fc7' weights[0]: 7.256392e-03 [1.453179e-07] 
Layer 'fc7' biases: 9.997632e-01 [1.988388e-07] 
Layer 'fc8' weights[0]: 4.696451e-03 [1.421061e-05] 
Layer 'fc8' biases: 1.899220e-02 [3.375800e-05] 
Train error last 800 batches: 0.655197
-------------------------------------------------------
Not saving because 0.370115 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
23.601... logprob:  0.660537, 0.268229 (1.484 sec)
23.602... logprob:  0.498570, 0.243489 (1.435 sec)
23.603... logprob:  0.483969, 0.204427 (1.443 sec)
23.604... logprob:  0.723437, 0.285156 (1.470 sec)
23.605... logprob:  0.720053, 0.305990 (1.428 sec)
23.606... logprob:  0.441184, 0.200521 (1.433 sec)
23.607... logprob:  0.701473, 0.305990 (1.424 sec)
23.608... logprob:  0.547295, 0.230469 (1.422 sec)
23.609... logprob:  0.575089, 0.289062 (1.437 sec)
23.610... logprob:  0.718208, 0.313802 (1.470 sec)
23.611... logprob:  0.742620, 0.325521 (1.448 sec)
23.612... logprob:  0.645595, 0.292969 (1.448 sec)
23.613... logprob:  0.543560, 0.260417 (1.451 sec)
23.614... logprob:  0.741856, 0.337240 (1.445 sec)
23.615... logprob:  0.626458, 0.276042 (1.432 sec)
23.616... logprob:  0.706514, 0.324219 (1.420 sec)
23.617... logprob:  0.641205, 0.292969 (1.419 sec)
23.618... logprob:  0.802020, 0.326823 (1.430 sec)
23.619... logprob:  0.652143, 0.277344 (1.450 sec)
23.620... logprob:  0.772863, 0.339844 (1.450 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.497250, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.211307e-03 [1.606031e-07] 
Layer 'conv1' biases: 2.087543e-06 [1.929945e-10] 
Layer 'conv2' weights[0]: 3.205092e-03 [1.603103e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.141149e-09] 
Layer 'conv3' weights[0]: 3.203796e-03 [1.615016e-07] 
Layer 'conv3' biases: 3.462208e-05 [1.548214e-08] 
Layer 'conv4' weights[0]: 3.217299e-03 [1.627794e-07] 
Layer 'conv4' biases: 9.999243e-01 [3.501487e-07] 
Layer 'conv5' weights[0]: 3.352686e-03 [4.078369e-06] 
Layer 'conv5' biases: 9.991280e-01 [4.424518e-06] 
Layer 'fc6' weights[0]: 6.907475e-03 [7.836927e-08] 
Layer 'fc6' biases: 9.999909e-01 [7.730396e-08] 
Layer 'fc7' weights[0]: 7.255676e-03 [1.886330e-07] 
Layer 'fc7' biases: 9.997633e-01 [3.233907e-07] 
Layer 'fc8' weights[0]: 4.705343e-03 [1.925119e-05] 
Layer 'fc8' biases: 1.911232e-02 [5.509198e-05] 
Train error last 800 batches: 0.655479
-------------------------------------------------------
Not saving because 0.497250 > 0.299667 (9.300: -1.18%)
======================================================= (2.335 sec)
23.621... logprob:  0.645132, 0.287760 (1.454 sec)
23.622... logprob:  0.580123, 0.242188 (1.439 sec)
23.623... logprob:  0.670054, 0.332031 (1.461 sec)
23.624... logprob:  0.569799, 0.239583 (1.432 sec)
23.625... logprob:  0.640372, 0.308594 (1.417 sec)
23.626... logprob:  0.649550, 0.311198 (1.428 sec)
23.627... logprob:  0.636674, 0.255208 (1.438 sec)
23.628... logprob:  0.705561, 0.285156 (1.427 sec)
23.629... logprob:  0.697294, 0.283854 (1.470 sec)
23.630... logprob:  0.667972, 0.290365 (1.442 sec)
23.631... logprob:  0.799688, 0.371094 (1.427 sec)
23.632... logprob:  0.618773, 0.266927 (1.476 sec)
23.633... logprob:  0.657283, 0.276042 (1.427 sec)
23.634... logprob:  0.893712, 0.361979 (1.426 sec)
23.635... logprob:  0.546226, 0.238281 (1.435 sec)
23.636... logprob:  0.746488, 0.338542 (1.427 sec)
23.637... logprob:  0.515936, 0.218750 (1.426 sec)
23.638... logprob:  0.831204, 0.367187 (1.481 sec)
23.639... logprob:  0.595567, 0.253906 (1.434 sec)
23.640... logprob:  0.806073, 0.342448 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.488123, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.208111e-03 [1.604458e-07] 
Layer 'conv1' biases: 2.088485e-06 [1.544739e-10] 
Layer 'conv2' weights[0]: 3.201884e-03 [1.601396e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.547762e-09] 
Layer 'conv3' weights[0]: 3.200587e-03 [1.606362e-07] 
Layer 'conv3' biases: 3.465378e-05 [1.089102e-08] 
Layer 'conv4' weights[0]: 3.214105e-03 [1.618239e-07] 
Layer 'conv4' biases: 9.999267e-01 [2.617690e-07] 
Layer 'conv5' weights[0]: 3.350998e-03 [3.149632e-06] 
Layer 'conv5' biases: 9.991635e-01 [3.404125e-06] 
Layer 'fc6' weights[0]: 6.906753e-03 [7.121634e-08] 
Layer 'fc6' biases: 9.999911e-01 [6.718889e-08] 
Layer 'fc7' weights[0]: 7.254957e-03 [1.683309e-07] 
Layer 'fc7' biases: 9.997599e-01 [2.533248e-07] 
Layer 'fc8' weights[0]: 4.618936e-03 [1.637777e-05] 
Layer 'fc8' biases: 1.845645e-02 [3.619715e-05] 
Train error last 800 batches: 0.656069
-------------------------------------------------------
Not saving because 0.488123 > 0.299667 (9.300: -1.18%)
======================================================= (2.352 sec)
23.641... logprob:  0.690983, 0.308594 (1.485 sec)
23.642... logprob:  0.686671, 0.307292 (1.433 sec)
23.643... logprob:  0.782289, 0.350260 (1.425 sec)
23.644... logprob:  0.598369, 0.272135 (1.426 sec)
23.645... logprob:  0.803001, 0.348958 (1.429 sec)
23.646... logprob:  0.596623, 0.265625 (1.431 sec)
23.647... logprob:  0.647727, 0.279948 (1.481 sec)
23.648... logprob:  0.678134, 0.289062 (1.427 sec)
23.649... logprob:  0.672693, 0.326823 (1.437 sec)
23.650... logprob:  0.623361, 0.289062 (1.468 sec)
23.651... logprob:  0.619369, 0.265625 (1.429 sec)
23.652... logprob:  0.735977, 0.326823 (1.431 sec)
23.653... logprob:  0.734495, 0.333333 (1.431 sec)
23.654... logprob:  0.712789, 0.295573 (1.422 sec)
23.655... logprob:  0.666491, 0.311198 (1.428 sec)
23.656... logprob:  0.618418, 0.257812 (1.472 sec)
23.657... logprob:  0.649968, 0.269531 (1.436 sec)
23.658... logprob:  0.610611, 0.294271 (1.451 sec)
23.659... logprob:  0.675416, 0.307292 (1.460 sec)
23.660... logprob:  0.732792, 0.334635 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.435180, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.204913e-03 [1.602779e-07] 
Layer 'conv1' biases: 2.089153e-06 [9.544081e-11] 
Layer 'conv2' weights[0]: 3.198704e-03 [1.599919e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.075322e-09] 
Layer 'conv3' weights[0]: 3.197383e-03 [1.604467e-07] 
Layer 'conv3' biases: 3.467345e-05 [9.575061e-09] 
Layer 'conv4' weights[0]: 3.210888e-03 [1.615445e-07] 
Layer 'conv4' biases: 9.999270e-01 [2.237943e-07] 
Layer 'conv5' weights[0]: 3.348313e-03 [2.809326e-06] 
Layer 'conv5' biases: 9.991574e-01 [3.036050e-06] 
Layer 'fc6' weights[0]: 6.906028e-03 [6.620876e-08] 
Layer 'fc6' biases: 9.999911e-01 [6.068456e-08] 
Layer 'fc7' weights[0]: 7.254242e-03 [1.522816e-07] 
Layer 'fc7' biases: 9.997600e-01 [2.140364e-07] 
Layer 'fc8' weights[0]: 4.645019e-03 [1.480085e-05] 
Layer 'fc8' biases: 1.865249e-02 [2.930950e-05] 
Train error last 800 batches: 0.656402
-------------------------------------------------------
Not saving because 0.435180 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
23.661... logprob:  0.617192, 0.242187 (1.440 sec)
23.662... logprob:  0.685122, 0.303385 (1.424 sec)
23.663... logprob:  0.579098, 0.270833 (1.421 sec)
23.664... logprob:  0.580571, 0.269531 (1.430 sec)
23.665... logprob:  0.639511, 0.277344 (1.457 sec)
23.666... logprob:  0.673887, 0.308594 (1.452 sec)
23.667... logprob:  0.793948, 0.313802 (1.453 sec)
23.668... logprob:  0.742180, 0.320312 (1.444 sec)
23.669... logprob:  0.601842, 0.246094 (1.456 sec)
23.670... logprob:  0.639459, 0.264323 (1.430 sec)
23.671... logprob:  0.642692, 0.302083 (1.421 sec)
23.672... logprob:  0.658622, 0.279948 (1.423 sec)
23.673... logprob:  0.626200, 0.277344 (1.431 sec)
23.674... logprob:  0.684054, 0.292969 (1.433 sec)
23.675... logprob:  0.570766, 0.255208 (1.465 sec)
23.676... logprob:  0.612636, 0.286458 (1.485 sec)
23.677... logprob:  0.675299, 0.286458 (1.442 sec)
23.678... logprob:  0.723605, 0.334635 (1.480 sec)
23.679... logprob:  0.579324, 0.261719 (1.428 sec)
23.680... logprob:  0.559603, 0.256510 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.435157, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.201705e-03 [1.602462e-07] 
Layer 'conv1' biases: 2.089819e-06 [1.070323e-10] 
Layer 'conv2' weights[0]: 3.195504e-03 [1.599439e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.246768e-09] 
Layer 'conv3' weights[0]: 3.194204e-03 [1.604463e-07] 
Layer 'conv3' biases: 3.467604e-05 [9.952068e-09] 
Layer 'conv4' weights[0]: 3.207688e-03 [1.616470e-07] 
Layer 'conv4' biases: 9.999243e-01 [2.432058e-07] 
Layer 'conv5' weights[0]: 3.343922e-03 [2.641671e-06] 
Layer 'conv5' biases: 9.991402e-01 [2.912197e-06] 
Layer 'fc6' weights[0]: 6.905301e-03 [6.391435e-08] 
Layer 'fc6' biases: 9.999910e-01 [5.809607e-08] 
Layer 'fc7' weights[0]: 7.253549e-03 [1.454477e-07] 
Layer 'fc7' biases: 9.997615e-01 [2.060835e-07] 
Layer 'fc8' weights[0]: 4.697833e-03 [1.456310e-05] 
Layer 'fc8' biases: 1.908260e-02 [3.257387e-05] 
Train error last 800 batches: 0.656697
-------------------------------------------------------
Not saving because 0.435157 > 0.299667 (9.300: -1.18%)
======================================================= (2.383 sec)
23.681... logprob:  0.629053, 0.278646 (1.436 sec)
23.682... logprob:  0.593209, 0.269531 (1.435 sec)
23.683... logprob:  0.612628, 0.282552 (1.429 sec)
23.684... logprob:  0.607660, 0.274739 (1.468 sec)
23.685... logprob:  0.526823, 0.268229 (1.441 sec)
23.686... logprob:  0.529868, 0.246094 (1.433 sec)
23.687... logprob:  0.551337, 0.252604 (1.480 sec)
23.688... logprob:  0.582873, 0.273437 (1.426 sec)
23.689... logprob:  0.765676, 0.307292 (1.425 sec)
23.690... logprob:  0.684774, 0.317708 (1.428 sec)
23.691... logprob:  0.740777, 0.295573 (1.425 sec)
23.692... logprob:  0.683371, 0.290365 (1.424 sec)
23.693... logprob:  0.623051, 0.286458 (1.482 sec)
23.694... logprob:  0.564592, 0.273437 (1.428 sec)
23.695... logprob:  0.621034, 0.276042 (1.436 sec)
23.696... logprob:  0.751061, 0.319010 (1.473 sec)
23.697... logprob:  0.684687, 0.347656 (1.432 sec)
23.698... logprob:  0.669717, 0.282552 (1.432 sec)
23.699... logprob:  0.586672, 0.260417 (1.436 sec)
23.700... logprob:  0.631586, 0.243490 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.362979, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.198505e-03 [1.599895e-07] 
Layer 'conv1' biases: 2.089834e-06 [1.141108e-10] 
Layer 'conv2' weights[0]: 3.192308e-03 [1.596750e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.236941e-09] 
Layer 'conv3' weights[0]: 3.190999e-03 [1.600707e-07] 
Layer 'conv3' biases: 3.465175e-05 [9.261074e-09] 
Layer 'conv4' weights[0]: 3.204452e-03 [1.611079e-07] 
Layer 'conv4' biases: 9.999238e-01 [2.308592e-07] 
Layer 'conv5' weights[0]: 3.340715e-03 [2.743845e-06] 
Layer 'conv5' biases: 9.991300e-01 [2.925285e-06] 
Layer 'fc6' weights[0]: 6.904598e-03 [6.508307e-08] 
Layer 'fc6' biases: 9.999909e-01 [5.994386e-08] 
Layer 'fc7' weights[0]: 7.252849e-03 [1.480051e-07] 
Layer 'fc7' biases: 9.997630e-01 [2.028266e-07] 
Layer 'fc8' weights[0]: 4.734067e-03 [1.406927e-05] 
Layer 'fc8' biases: 1.936696e-02 [2.937251e-05] 
Train error last 800 batches: 0.656325
-------------------------------------------------------
Not saving because 0.362979 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
23.701... logprob:  0.678619, 0.294271 (1.430 sec)
23.702... logprob:  0.674254, 0.279948 (1.476 sec)
23.703... logprob:  0.620775, 0.268229 (1.431 sec)
23.704... logprob:  0.660353, 0.316406 (1.441 sec)
23.705... logprob:  0.615291, 0.281250 (1.466 sec)
23.706... logprob:  0.687172, 0.290365 (1.430 sec)
23.707... logprob:  0.739841, 0.346354 (1.433 sec)
23.708... logprob:  0.655285, 0.300781 (1.431 sec)
23.709... logprob:  0.618659, 0.261719 (1.421 sec)
23.710... logprob:  0.808413, 0.324219 (1.439 sec)
23.711... logprob:  0.679613, 0.274739 (1.469 sec)
23.712... logprob:  0.550128, 0.248698 (1.448 sec)
23.713... logprob:  0.730091, 0.332031 (1.448 sec)
23.714... logprob:  0.601753, 0.277344 (1.490 sec)
23.715... logprob:  0.601642, 0.295573 (1.450 sec)
23.716... logprob:  0.614857, 0.292969 (1.437 sec)
23.717... logprob:  0.641963, 0.276042 (1.430 sec)
23.718... logprob:  0.672237, 0.294271 (1.425 sec)
23.719... logprob:  0.663032, 0.294271 (1.438 sec)
23.720... logprob:  0.680970, 0.294271 (1.446 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.557049, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.195305e-03 [1.597871e-07] 
Layer 'conv1' biases: 2.090243e-06 [1.059840e-10] 
Layer 'conv2' weights[0]: 3.189113e-03 [1.595333e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.264046e-09] 
Layer 'conv3' weights[0]: 3.187807e-03 [1.599572e-07] 
Layer 'conv3' biases: 3.465618e-05 [9.145683e-09] 
Layer 'conv4' weights[0]: 3.201257e-03 [1.609916e-07] 
Layer 'conv4' biases: 9.999239e-01 [2.308763e-07] 
Layer 'conv5' weights[0]: 3.337649e-03 [2.187176e-06] 
Layer 'conv5' biases: 9.991620e-01 [2.370797e-06] 
Layer 'fc6' weights[0]: 6.903877e-03 [6.129202e-08] 
Layer 'fc6' biases: 9.999911e-01 [5.441107e-08] 
Layer 'fc7' weights[0]: 7.252126e-03 [1.385073e-07] 
Layer 'fc7' biases: 9.997602e-01 [1.722085e-07] 
Layer 'fc8' weights[0]: 4.661807e-03 [1.328235e-05] 
Layer 'fc8' biases: 1.885166e-02 [2.606699e-05] 
Train error last 800 batches: 0.656395
-------------------------------------------------------
Not saving because 0.557049 > 0.299667 (9.300: -1.18%)
======================================================= (2.362 sec)
23.721... logprob:  0.646752, 0.279948 (1.461 sec)
23.722... logprob:  0.829870, 0.351562 (1.454 sec)
23.723... logprob:  0.612669, 0.276042 (1.432 sec)
23.724... logprob:  0.637079, 0.250000 (1.471 sec)
23.725... logprob:  0.710737, 0.317708 (1.429 sec)
23.726... logprob:  0.536907, 0.240885 (1.421 sec)
23.727... logprob:  0.615830, 0.274740 (1.426 sec)
23.728... logprob:  0.700509, 0.300781 (1.439 sec)
23.729... logprob:  0.618460, 0.272135 (1.425 sec)
23.730... logprob:  0.700928, 0.282552 (1.473 sec)
23.731... logprob:  0.676132, 0.317708 (1.444 sec)
23.732... logprob:  0.591752, 0.268229 (1.431 sec)
23.733... logprob:  0.786401, 0.326823 (1.483 sec)
23.734... logprob:  0.535007, 0.250000 (1.426 sec)
23.735... logprob:  0.704979, 0.274740 (1.427 sec)
23.736... logprob:  0.850002, 0.367188 (1.434 sec)
23.737... logprob:  0.740906, 0.326823 (1.424 sec)
23.738... logprob:  0.701671, 0.307292 (1.429 sec)
23.739... logprob:  0.631225, 0.299479 (1.474 sec)
23.740... logprob:  0.527654, 0.244792 (1.434 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.462883, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.192113e-03 [1.597002e-07] 
Layer 'conv1' biases: 2.090999e-06 [9.345892e-11] 
Layer 'conv2' weights[0]: 3.185936e-03 [1.594225e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.806332e-10] 
Layer 'conv3' weights[0]: 3.184638e-03 [1.597107e-07] 
Layer 'conv3' biases: 3.465455e-05 [7.911652e-09] 
Layer 'conv4' weights[0]: 3.198073e-03 [1.606801e-07] 
Layer 'conv4' biases: 9.999233e-01 [1.820463e-07] 
Layer 'conv5' weights[0]: 3.334182e-03 [2.209541e-06] 
Layer 'conv5' biases: 9.991686e-01 [2.416872e-06] 
Layer 'fc6' weights[0]: 6.903178e-03 [6.256746e-08] 
Layer 'fc6' biases: 9.999912e-01 [5.595250e-08] 
Layer 'fc7' weights[0]: 7.251431e-03 [1.414190e-07] 
Layer 'fc7' biases: 9.997594e-01 [1.823897e-07] 
Layer 'fc8' weights[0]: 4.646091e-03 [1.390957e-05] 
Layer 'fc8' biases: 1.871044e-02 [2.795110e-05] 
Train error last 800 batches: 0.655778
-------------------------------------------------------
Not saving because 0.462883 > 0.299667 (9.300: -1.18%)
======================================================= (2.393 sec)
23.741... logprob:  0.522707, 0.242188 (1.441 sec)
23.742... logprob:  0.635107, 0.304688 (1.483 sec)
23.743... logprob:  0.641565, 0.291667 (1.431 sec)
23.744... logprob:  0.730149, 0.330729 (1.426 sec)
23.745... logprob:  0.706403, 0.308594 (1.433 sec)
23.746... logprob:  0.720571, 0.324219 (1.427 sec)
23.747... logprob:  0.628508, 0.256510 (1.427 sec)
23.748... logprob:  0.658616, 0.305990 (1.480 sec)
23.749... logprob:  0.678674, 0.317708 (1.429 sec)
23.750... logprob:  0.706746, 0.303385 (1.446 sec)
23.751... logprob:  0.540547, 0.261719 (1.480 sec)
23.752... logprob:  0.689636, 0.296875 (1.466 sec)
23.753... logprob:  0.603588, 0.250000 (1.434 sec)
23.754... logprob:  0.684293, 0.324219 (1.424 sec)
23.755... logprob:  0.683735, 0.263021 (1.419 sec)
23.756... logprob:  0.770407, 0.326823 (1.431 sec)
23.757... logprob:  0.724331, 0.313802 (1.473 sec)
23.758... logprob:  0.674832, 0.302083 (1.438 sec)
23.759... logprob:  0.696549, 0.322917 (1.447 sec)
23.760... logprob:  0.607669, 0.246094 (1.455 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.399321, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.188914e-03 [1.594918e-07] 
Layer 'conv1' biases: 2.091285e-06 [9.004908e-11] 
Layer 'conv2' weights[0]: 3.182742e-03 [1.592142e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.995952e-10] 
Layer 'conv3' weights[0]: 3.181466e-03 [1.594423e-07] 
Layer 'conv3' biases: 3.465318e-05 [8.005057e-09] 
Layer 'conv4' weights[0]: 3.194850e-03 [1.603561e-07] 
Layer 'conv4' biases: 9.999241e-01 [1.936742e-07] 
Layer 'conv5' weights[0]: 3.331805e-03 [2.432438e-06] 
Layer 'conv5' biases: 9.991530e-01 [2.587865e-06] 
Layer 'fc6' weights[0]: 6.902485e-03 [6.389526e-08] 
Layer 'fc6' biases: 9.999913e-01 [5.779568e-08] 
Layer 'fc7' weights[0]: 7.250664e-03 [1.434654e-07] 
Layer 'fc7' biases: 9.997603e-01 [1.805385e-07] 
Layer 'fc8' weights[0]: 4.665291e-03 [1.305242e-05] 
Layer 'fc8' biases: 1.889342e-02 [1.644449e-05] 
Train error last 800 batches: 0.655789
-------------------------------------------------------
Not saving because 0.399321 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
23.761... logprob:  0.738665, 0.334635 (1.452 sec)
23.762... logprob:  0.774100, 0.325521 (1.444 sec)
23.763... logprob:  0.723987, 0.302083 (1.427 sec)
23.764... logprob:  0.649481, 0.277344 (1.419 sec)
23.765... logprob:  0.550430, 0.230469 (1.428 sec)
23.766... logprob:  0.706692, 0.311198 (1.449 sec)
23.767... logprob:  0.654578, 0.277344 (1.450 sec)
23.768... logprob:  0.695392, 0.305990 (1.457 sec)
23.769... logprob:  0.677314, 0.308594 (1.459 sec)
23.770... logprob:  0.580267, 0.274739 (1.480 sec)
23.771... logprob:  0.734324, 0.308594 (1.455 sec)
23.772... logprob:  0.664916, 0.305990 (1.441 sec)
23.773... logprob:  0.849859, 0.363281 (1.445 sec)
23.774... logprob:  0.595845, 0.264323 (1.456 sec)
23.775... logprob:  0.671786, 0.291667 (1.454 sec)
23.776... logprob:  0.765421, 0.313802 (1.472 sec)
23.777... logprob:  0.648714, 0.282552 (1.466 sec)
23.778... logprob:  0.623981, 0.279948 (1.465 sec)
23.779... logprob:  0.689712, 0.276042 (1.484 sec)
23.780... logprob:  0.628604, 0.272135 (1.447 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.455880, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.185731e-03 [1.592904e-07] 
Layer 'conv1' biases: 2.091983e-06 [1.593545e-10] 
Layer 'conv2' weights[0]: 3.179563e-03 [1.590405e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.261664e-09] 
Layer 'conv3' weights[0]: 3.178270e-03 [1.594794e-07] 
Layer 'conv3' biases: 3.464760e-05 [8.471128e-09] 
Layer 'conv4' weights[0]: 3.191682e-03 [1.604854e-07] 
Layer 'conv4' biases: 9.999252e-01 [2.140223e-07] 
Layer 'conv5' weights[0]: 3.329473e-03 [2.287614e-06] 
Layer 'conv5' biases: 9.991644e-01 [2.436412e-06] 
Layer 'fc6' weights[0]: 6.901756e-03 [6.214216e-08] 
Layer 'fc6' biases: 9.999911e-01 [5.529828e-08] 
Layer 'fc7' weights[0]: 7.249982e-03 [1.412514e-07] 
Layer 'fc7' biases: 9.997590e-01 [1.702231e-07] 
Layer 'fc8' weights[0]: 4.625969e-03 [1.279346e-05] 
Layer 'fc8' biases: 1.856642e-02 [1.853010e-05] 
Train error last 800 batches: 0.656254
-------------------------------------------------------
Not saving because 0.455880 > 0.299667 (9.300: -1.18%)
======================================================= (2.377 sec)
23.781... logprob:  0.596444, 0.250000 (1.449 sec)
23.782... logprob:  0.587337, 0.268229 (1.449 sec)
23.783... logprob:  0.791882, 0.330729 (1.452 sec)
23.784... logprob:  0.615312, 0.247396 (1.448 sec)
23.785... logprob:  0.748837, 0.325521 (1.479 sec)
23.786... logprob:  0.585560, 0.264323 (1.464 sec)
23.787... logprob:  0.784679, 0.343750 (1.453 sec)
23.788... logprob:  0.734132, 0.320312 (1.489 sec)
23.789... logprob:  0.582201, 0.270833 (1.449 sec)
23.790... logprob:  0.726589, 0.322917 (1.457 sec)
23.791... logprob:  0.638973, 0.261719 (1.451 sec)
23.792... logprob:  0.662189, 0.322917 (1.458 sec)
23.793... logprob:  0.612377, 0.273437 (1.446 sec)
23.794... logprob:  0.676078, 0.311198 (1.490 sec)
23.795... logprob:  0.666005, 0.296875 (1.463 sec)
23.796... logprob:  0.643537, 0.265625 (1.459 sec)
23.797... logprob:  0.693598, 0.320312 (1.499 sec)
23.798... logprob:  0.668675, 0.298177 (1.446 sec)
23.799... logprob:  0.552531, 0.259115 (1.441 sec)
23.800... logprob:  0.555570, 0.236979 (1.403 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.477764, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.182550e-03 [1.591805e-07] 
Layer 'conv1' biases: 2.093052e-06 [1.482707e-10] 
Layer 'conv2' weights[0]: 3.176380e-03 [1.589267e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.519350e-09] 
Layer 'conv3' weights[0]: 3.175077e-03 [1.595787e-07] 
Layer 'conv3' biases: 3.464680e-05 [1.103126e-08] 
Layer 'conv4' weights[0]: 3.188472e-03 [1.608654e-07] 
Layer 'conv4' biases: 9.999231e-01 [2.733654e-07] 
Layer 'conv5' weights[0]: 3.325236e-03 [2.928116e-06] 
Layer 'conv5' biases: 9.991443e-01 [3.161521e-06] 
Layer 'fc6' weights[0]: 6.901049e-03 [6.400459e-08] 
Layer 'fc6' biases: 9.999912e-01 [5.769547e-08] 
Layer 'fc7' weights[0]: 7.249219e-03 [1.479644e-07] 
Layer 'fc7' biases: 9.997596e-01 [2.082136e-07] 
Layer 'fc8' weights[0]: 4.653614e-03 [1.392298e-05] 
Layer 'fc8' biases: 1.882656e-02 [3.416048e-05] 
Train error last 800 batches: 0.656828
-------------------------------------------------------
Not saving because 0.477764 > 0.299667 (9.300: -1.18%)
======================================================= (2.347 sec)
24.1... logprob:  0.660218, 0.315104 (1.400 sec)
24.2... logprob:  0.632561, 0.289063 (1.444 sec)
24.3... logprob:  0.617023, 0.283854 (1.411 sec)
24.4... logprob:  0.672407, 0.253906 (1.405 sec)
24.5... logprob:  0.669698, 0.299479 (1.434 sec)
24.6... logprob:  0.750463, 0.291667 (1.390 sec)
24.7... logprob:  0.548540, 0.246094 (1.420 sec)
24.8... logprob:  0.639616, 0.279948 (1.395 sec)
24.9... logprob:  0.614391, 0.287760 (1.407 sec)
24.10... logprob:  0.640305, 0.268229 (1.404 sec)
24.11... logprob:  0.489178, 0.236979 (1.447 sec)
24.12... logprob:  0.656515, 0.268229 (1.391 sec)
24.13... logprob:  0.551918, 0.257812 (1.420 sec)
24.14... logprob:  0.662202, 0.295573 (1.395 sec)
24.15... logprob:  0.561474, 0.246094 (1.405 sec)
24.16... logprob:  0.653422, 0.270833 (1.403 sec)
24.17... logprob:  0.675070, 0.333333 (1.395 sec)
24.18... logprob:  0.518576, 0.234375 (1.389 sec)
24.19... logprob:  0.509088, 0.230469 (1.399 sec)
24.20... logprob:  0.681618, 0.339844 (1.399 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.494436, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.179371e-03 [1.591821e-07] 
Layer 'conv1' biases: 2.093805e-06 [1.091148e-10] 
Layer 'conv2' weights[0]: 3.173193e-03 [1.588292e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.105197e-09] 
Layer 'conv3' weights[0]: 3.171937e-03 [1.590359e-07] 
Layer 'conv3' biases: 3.466016e-05 [8.081278e-09] 
Layer 'conv4' weights[0]: 3.185293e-03 [1.602717e-07] 
Layer 'conv4' biases: 9.999222e-01 [2.235224e-07] 
Layer 'conv5' weights[0]: 3.321501e-03 [3.306472e-06] 
Layer 'conv5' biases: 9.991158e-01 [3.671040e-06] 
Layer 'fc6' weights[0]: 6.900364e-03 [6.677477e-08] 
Layer 'fc6' biases: 9.999911e-01 [6.193030e-08] 
Layer 'fc7' weights[0]: 7.248512e-03 [1.561160e-07] 
Layer 'fc7' biases: 9.997615e-01 [2.563834e-07] 
Layer 'fc8' weights[0]: 4.725985e-03 [1.655558e-05] 
Layer 'fc8' biases: 1.938534e-02 [4.859714e-05] 
Train error last 800 batches: 0.656769
-------------------------------------------------------
Not saving because 0.494436 > 0.299667 (9.300: -1.18%)
======================================================= (2.353 sec)
24.21... logprob:  0.657834, 0.311198 (1.406 sec)
24.22... logprob:  0.610938, 0.253906 (1.411 sec)
24.23... logprob:  0.750110, 0.302083 (1.408 sec)
24.24... logprob:  0.638684, 0.299479 (1.412 sec)
24.25... logprob:  0.641120, 0.296875 (1.401 sec)
24.26... logprob:  0.664479, 0.294271 (1.439 sec)
24.27... logprob:  0.600310, 0.264323 (1.386 sec)
24.28... logprob:  0.722378, 0.319010 (1.430 sec)
24.29... logprob:  0.656165, 0.290365 (1.424 sec)
24.30... logprob:  0.611083, 0.272135 (1.416 sec)
24.31... logprob:  0.729412, 0.298177 (1.400 sec)
24.32... logprob:  0.698991, 0.302083 (1.383 sec)
24.33... logprob:  0.580550, 0.246094 (1.445 sec)
24.34... logprob:  0.739727, 0.289062 (1.391 sec)
24.35... logprob:  0.614283, 0.302083 (1.395 sec)
24.36... logprob:  0.683725, 0.307292 (1.391 sec)
24.37... logprob:  0.644848, 0.291667 (1.409 sec)
24.38... logprob:  0.750560, 0.303385 (1.392 sec)
24.39... logprob:  0.759157, 0.322917 (1.430 sec)
24.40... logprob:  0.731409, 0.328125 (1.403 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.520492, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.176197e-03 [1.588929e-07] 
Layer 'conv1' biases: 2.093658e-06 [1.867567e-10] 
Layer 'conv2' weights[0]: 3.170044e-03 [1.586171e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.038152e-09] 
Layer 'conv3' weights[0]: 3.168759e-03 [1.597425e-07] 
Layer 'conv3' biases: 3.468033e-05 [1.473209e-08] 
Layer 'conv4' weights[0]: 3.182125e-03 [1.611978e-07] 
Layer 'conv4' biases: 9.999226e-01 [3.401805e-07] 
Layer 'conv5' weights[0]: 3.318646e-03 [4.172677e-06] 
Layer 'conv5' biases: 9.991331e-01 [4.590285e-06] 
Layer 'fc6' weights[0]: 6.899648e-03 [8.452096e-08] 
Layer 'fc6' biases: 9.999911e-01 [8.697859e-08] 
Layer 'fc7' weights[0]: 7.247787e-03 [2.058860e-07] 
Layer 'fc7' biases: 9.997598e-01 [3.685285e-07] 
Layer 'fc8' weights[0]: 4.671852e-03 [2.124041e-05] 
Layer 'fc8' biases: 1.902212e-02 [6.108001e-05] 
Train error last 800 batches: 0.657311
-------------------------------------------------------
Not saving because 0.520492 > 0.299667 (9.300: -1.18%)
======================================================= (2.345 sec)
24.41... logprob:  0.591428, 0.277344 (1.430 sec)
24.42... logprob:  0.658922, 0.292969 (1.416 sec)
24.43... logprob:  0.650968, 0.265625 (1.408 sec)
24.44... logprob:  0.674632, 0.282552 (1.437 sec)
24.45... logprob:  0.586742, 0.279948 (1.392 sec)
24.46... logprob:  0.715874, 0.319010 (1.396 sec)
24.47... logprob:  0.642193, 0.281250 (1.388 sec)
24.48... logprob:  0.673252, 0.299479 (1.417 sec)
24.49... logprob:  0.756459, 0.337240 (1.409 sec)
24.50... logprob:  0.703773, 0.285156 (1.417 sec)
24.51... logprob:  0.663322, 0.287760 (1.411 sec)
24.52... logprob:  0.780823, 0.298177 (1.392 sec)
24.53... logprob:  0.575386, 0.250000 (1.437 sec)
24.54... logprob:  0.578776, 0.270833 (1.385 sec)
24.55... logprob:  0.571314, 0.259115 (1.396 sec)
24.56... logprob:  0.677066, 0.316406 (1.399 sec)
24.57... logprob:  0.689959, 0.281250 (1.430 sec)
24.58... logprob:  0.594932, 0.253906 (1.402 sec)
24.59... logprob:  0.567745, 0.252604 (1.457 sec)
24.60... logprob:  0.732518, 0.308594 (1.412 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.521894, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.173029e-03 [1.588084e-07] 
Layer 'conv1' biases: 2.093819e-06 [1.264531e-10] 
Layer 'conv2' weights[0]: 3.166857e-03 [1.584673e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.138323e-09] 
Layer 'conv3' weights[0]: 3.165546e-03 [1.588763e-07] 
Layer 'conv3' biases: 3.468188e-05 [8.891058e-09] 
Layer 'conv4' weights[0]: 3.178898e-03 [1.599732e-07] 
Layer 'conv4' biases: 9.999219e-01 [2.332627e-07] 
Layer 'conv5' weights[0]: 3.315534e-03 [2.386738e-06] 
Layer 'conv5' biases: 9.991449e-01 [2.570733e-06] 
Layer 'fc6' weights[0]: 6.898908e-03 [6.351679e-08] 
Layer 'fc6' biases: 9.999910e-01 [5.742084e-08] 
Layer 'fc7' weights[0]: 7.247045e-03 [1.462065e-07] 
Layer 'fc7' biases: 9.997590e-01 [1.904340e-07] 
Layer 'fc8' weights[0]: 4.655412e-03 [1.343616e-05] 
Layer 'fc8' biases: 1.881442e-02 [2.129634e-05] 
Train error last 800 batches: 0.657302
-------------------------------------------------------
Not saving because 0.521894 > 0.299667 (9.300: -1.18%)
======================================================= (2.395 sec)
24.61... logprob:  0.604515, 0.279948 (1.426 sec)
24.62... logprob:  0.676585, 0.296875 (1.456 sec)
24.63... logprob:  0.678691, 0.324219 (1.440 sec)
24.64... logprob:  0.683160, 0.273437 (1.411 sec)
24.65... logprob:  0.647248, 0.289062 (1.392 sec)
24.66... logprob:  0.610689, 0.259115 (1.438 sec)
24.67... logprob:  0.561647, 0.240885 (1.399 sec)
24.68... logprob:  0.644305, 0.266927 (1.390 sec)
24.69... logprob:  0.673159, 0.328125 (1.421 sec)
24.70... logprob:  0.580863, 0.248698 (1.425 sec)
24.71... logprob:  0.721272, 0.328125 (1.452 sec)
24.72... logprob:  0.794204, 0.343750 (1.401 sec)
24.73... logprob:  0.714060, 0.308594 (1.423 sec)
24.74... logprob:  0.675949, 0.281250 (1.411 sec)
24.75... logprob:  0.552376, 0.201823 (1.408 sec)
24.76... logprob:  0.586814, 0.276042 (1.428 sec)
24.77... logprob:  0.654633, 0.298177 (1.424 sec)
24.78... logprob:  0.683764, 0.277344 (1.447 sec)
24.79... logprob:  0.692110, 0.277344 (1.397 sec)
24.80... logprob:  0.630981, 0.270833 (1.408 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.447421, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.169854e-03 [1.584445e-07] 
Layer 'conv1' biases: 2.093658e-06 [1.107734e-10] 
Layer 'conv2' weights[0]: 3.163704e-03 [1.582476e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.298124e-09] 
Layer 'conv3' weights[0]: 3.162404e-03 [1.585383e-07] 
Layer 'conv3' biases: 3.465615e-05 [8.787142e-09] 
Layer 'conv4' weights[0]: 3.175720e-03 [1.596207e-07] 
Layer 'conv4' biases: 9.999228e-01 [2.232478e-07] 
Layer 'conv5' weights[0]: 3.313362e-03 [2.546192e-06] 
Layer 'conv5' biases: 9.991280e-01 [2.775888e-06] 
Layer 'fc6' weights[0]: 6.898227e-03 [6.483465e-08] 
Layer 'fc6' biases: 9.999907e-01 [5.989273e-08] 
Layer 'fc7' weights[0]: 7.246299e-03 [1.492442e-07] 
Layer 'fc7' biases: 9.997596e-01 [1.968518e-07] 
Layer 'fc8' weights[0]: 4.689311e-03 [1.431173e-05] 
Layer 'fc8' biases: 1.909541e-02 [3.249721e-05] 
Train error last 800 batches: 0.657574
-------------------------------------------------------
Not saving because 0.447421 > 0.299667 (9.300: -1.18%)
======================================================= (2.367 sec)
24.81... logprob:  0.596458, 0.278646 (1.422 sec)
24.82... logprob:  0.525690, 0.238281 (1.424 sec)
24.83... logprob:  0.658946, 0.283854 (1.395 sec)
24.84... logprob:  0.660948, 0.285156 (1.458 sec)
24.85... logprob:  0.670507, 0.302083 (1.418 sec)
24.86... logprob:  0.573584, 0.233073 (1.411 sec)
24.87... logprob:  0.825005, 0.339844 (1.414 sec)
24.88... logprob:  0.759246, 0.345052 (1.406 sec)
24.89... logprob:  0.576169, 0.239583 (1.426 sec)
24.90... logprob:  0.807551, 0.381510 (1.386 sec)
24.91... logprob:  0.535993, 0.242188 (1.387 sec)
24.92... logprob:  0.692770, 0.309896 (1.397 sec)
24.93... logprob:  0.644591, 0.269531 (1.389 sec)
24.94... logprob:  0.654374, 0.274740 (1.393 sec)
24.95... logprob:  0.683537, 0.295573 (1.400 sec)
24.96... logprob:  0.802591, 0.326823 (1.405 sec)
24.97... logprob:  0.668513, 0.300781 (1.383 sec)
24.98... logprob:  0.636973, 0.289062 (1.432 sec)
24.99... logprob:  0.727995, 0.294271 (1.404 sec)
24.100... logprob:  0.588728, 0.281250 (1.397 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.440935, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.166684e-03 [1.583440e-07] 
Layer 'conv1' biases: 2.094367e-06 [1.053002e-10] 
Layer 'conv2' weights[0]: 3.160530e-03 [1.580478e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.038797e-09] 
Layer 'conv3' weights[0]: 3.159249e-03 [1.582674e-07] 
Layer 'conv3' biases: 3.464179e-05 [7.112991e-09] 
Layer 'conv4' weights[0]: 3.172571e-03 [1.590815e-07] 
Layer 'conv4' biases: 9.999245e-01 [1.633696e-07] 
Layer 'conv5' weights[0]: 3.311210e-03 [2.181890e-06] 
Layer 'conv5' biases: 9.991465e-01 [2.313745e-06] 
Layer 'fc6' weights[0]: 6.897490e-03 [6.150081e-08] 
Layer 'fc6' biases: 9.999908e-01 [5.501427e-08] 
Layer 'fc7' weights[0]: 7.245622e-03 [1.431928e-07] 
Layer 'fc7' biases: 9.997584e-01 [1.850080e-07] 
Layer 'fc8' weights[0]: 4.645189e-03 [1.357483e-05] 
Layer 'fc8' biases: 1.875718e-02 [2.695406e-05] 
Train error last 800 batches: 0.657320
-------------------------------------------------------
Not saving because 0.440935 > 0.299667 (9.300: -1.18%)
======================================================= (2.389 sec)
24.101... logprob:  0.508290, 0.216146 (1.449 sec)
24.102... logprob:  0.741152, 0.305990 (1.392 sec)
24.103... logprob:  0.753026, 0.354167 (1.400 sec)
24.104... logprob:  0.574171, 0.240885 (1.397 sec)
24.105... logprob:  0.802346, 0.364583 (1.393 sec)
24.106... logprob:  0.622361, 0.294271 (1.404 sec)
24.107... logprob:  0.529804, 0.238281 (1.438 sec)
24.108... logprob:  0.727166, 0.313802 (1.390 sec)
24.109... logprob:  0.546905, 0.214844 (1.393 sec)
24.110... logprob:  0.669715, 0.337239 (1.390 sec)
24.111... logprob:  0.669528, 0.283854 (1.391 sec)
24.112... logprob:  0.555157, 0.260417 (1.398 sec)
24.113... logprob:  0.601045, 0.274740 (1.395 sec)
24.114... logprob:  0.629187, 0.259115 (1.428 sec)
24.115... logprob:  0.716870, 0.300781 (1.408 sec)
24.116... logprob:  0.627361, 0.270833 (1.396 sec)
24.117... logprob:  0.720521, 0.305990 (1.442 sec)
24.118... logprob:  0.601789, 0.257812 (1.382 sec)
24.119... logprob:  0.631579, 0.273438 (1.393 sec)
24.120... logprob:  0.792513, 0.333333 (1.391 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.552553, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.163509e-03 [1.583052e-07] 
Layer 'conv1' biases: 2.094736e-06 [7.346964e-11] 
Layer 'conv2' weights[0]: 3.157375e-03 [1.580009e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.195813e-09] 
Layer 'conv3' weights[0]: 3.156076e-03 [1.583369e-07] 
Layer 'conv3' biases: 3.465660e-05 [8.410256e-09] 
Layer 'conv4' weights[0]: 3.169382e-03 [1.592852e-07] 
Layer 'conv4' biases: 9.999235e-01 [2.258393e-07] 
Layer 'conv5' weights[0]: 3.308021e-03 [2.487836e-06] 
Layer 'conv5' biases: 9.991302e-01 [2.621366e-06] 
Layer 'fc6' weights[0]: 6.896801e-03 [6.265558e-08] 
Layer 'fc6' biases: 9.999906e-01 [5.682794e-08] 
Layer 'fc7' weights[0]: 7.244918e-03 [1.397784e-07] 
Layer 'fc7' biases: 9.997591e-01 [1.616664e-07] 
Layer 'fc8' weights[0]: 4.684629e-03 [1.220947e-05] 
Layer 'fc8' biases: 1.909708e-02 [7.321212e-06] 
Train error last 800 batches: 0.656798
-------------------------------------------------------
Not saving because 0.552553 > 0.299667 (9.300: -1.18%)
======================================================= (2.393 sec)
24.121... logprob:  0.669289, 0.296875 (1.398 sec)
24.122... logprob:  0.750482, 0.316406 (1.440 sec)
24.123... logprob:  0.733912, 0.299479 (1.389 sec)
24.124... logprob:  0.664136, 0.291667 (1.403 sec)
24.125... logprob:  0.604548, 0.274739 (1.397 sec)
24.126... logprob:  0.701628, 0.296875 (1.392 sec)
24.127... logprob:  0.657292, 0.302083 (1.393 sec)
24.128... logprob:  0.628745, 0.274740 (1.416 sec)
24.129... logprob:  0.795123, 0.355469 (1.414 sec)
24.130... logprob:  0.656256, 0.308594 (1.417 sec)
24.131... logprob:  0.631428, 0.292969 (1.406 sec)
24.132... logprob:  0.723835, 0.298177 (1.429 sec)
24.133... logprob:  0.642308, 0.276042 (1.382 sec)
24.134... logprob:  0.609869, 0.253906 (1.391 sec)
24.135... logprob:  0.610276, 0.281250 (1.394 sec)
24.136... logprob:  0.697136, 0.308594 (1.392 sec)
24.137... logprob:  0.627931, 0.248698 (1.386 sec)
24.138... logprob:  0.589131, 0.265625 (1.442 sec)
24.139... logprob:  0.683280, 0.294271 (1.402 sec)
24.140... logprob:  0.705933, 0.307292 (1.408 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.404947, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.160363e-03 [1.581325e-07] 
Layer 'conv1' biases: 2.094800e-06 [1.103059e-10] 
Layer 'conv2' weights[0]: 3.154232e-03 [1.578468e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.162182e-09] 
Layer 'conv3' weights[0]: 3.152936e-03 [1.581230e-07] 
Layer 'conv3' biases: 3.469158e-05 [8.217950e-09] 
Layer 'conv4' weights[0]: 3.166224e-03 [1.592040e-07] 
Layer 'conv4' biases: 9.999227e-01 [2.137309e-07] 
Layer 'conv5' weights[0]: 3.304284e-03 [2.369360e-06] 
Layer 'conv5' biases: 9.991415e-01 [2.465344e-06] 
Layer 'fc6' weights[0]: 6.896076e-03 [6.104791e-08] 
Layer 'fc6' biases: 9.999908e-01 [5.439255e-08] 
Layer 'fc7' weights[0]: 7.244190e-03 [1.395504e-07] 
Layer 'fc7' biases: 9.997582e-01 [1.713629e-07] 
Layer 'fc8' weights[0]: 4.649665e-03 [1.298688e-05] 
Layer 'fc8' biases: 1.884436e-02 [2.380783e-05] 
Train error last 800 batches: 0.656327
-------------------------------------------------------
Not saving because 0.404947 > 0.299667 (9.300: -1.18%)
======================================================= (2.385 sec)
24.141... logprob:  0.630823, 0.283854 (1.437 sec)
24.142... logprob:  0.635957, 0.274740 (1.395 sec)
24.143... logprob:  0.560026, 0.239583 (1.419 sec)
24.144... logprob:  0.742005, 0.320312 (1.412 sec)
24.145... logprob:  0.597301, 0.251302 (1.423 sec)
24.146... logprob:  0.668677, 0.282552 (1.407 sec)
24.147... logprob:  0.547826, 0.266927 (1.424 sec)
24.148... logprob:  0.709659, 0.305990 (1.381 sec)
24.149... logprob:  0.564098, 0.244792 (1.392 sec)
24.150... logprob:  0.583421, 0.257813 (1.396 sec)
24.151... logprob:  0.568243, 0.252604 (1.398 sec)
24.152... logprob:  0.828724, 0.360677 (1.380 sec)
24.153... logprob:  0.607396, 0.268229 (1.439 sec)
24.154... logprob:  0.747894, 0.321615 (1.393 sec)
24.155... logprob:  0.628459, 0.268229 (1.404 sec)
24.156... logprob:  0.536769, 0.259115 (1.425 sec)
24.157... logprob:  0.503322, 0.234375 (1.388 sec)
24.158... logprob:  0.640443, 0.291667 (1.396 sec)
24.159... logprob:  0.645107, 0.291667 (1.391 sec)
24.160... logprob:  0.724486, 0.319010 (1.388 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.526417, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.157199e-03 [1.579857e-07] 
Layer 'conv1' biases: 2.096026e-06 [1.001858e-10] 
Layer 'conv2' weights[0]: 3.151052e-03 [1.576602e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.557658e-10] 
Layer 'conv3' weights[0]: 3.149811e-03 [1.578577e-07] 
Layer 'conv3' biases: 3.469537e-05 [6.551786e-09] 
Layer 'conv4' weights[0]: 3.163062e-03 [1.587691e-07] 
Layer 'conv4' biases: 9.999202e-01 [1.753420e-07] 
Layer 'conv5' weights[0]: 3.299571e-03 [2.378496e-06] 
Layer 'conv5' biases: 9.991128e-01 [2.638292e-06] 
Layer 'fc6' weights[0]: 6.895338e-03 [6.025534e-08] 
Layer 'fc6' biases: 9.999905e-01 [5.372859e-08] 
Layer 'fc7' weights[0]: 7.243447e-03 [1.381745e-07] 
Layer 'fc7' biases: 9.997598e-01 [1.744417e-07] 
Layer 'fc8' weights[0]: 4.720157e-03 [1.280984e-05] 
Layer 'fc8' biases: 1.935034e-02 [2.252564e-05] 
Train error last 800 batches: 0.655984
-------------------------------------------------------
Not saving because 0.526417 > 0.299667 (9.300: -1.18%)
======================================================= (2.372 sec)
24.161... logprob:  0.686648, 0.302083 (1.406 sec)
24.162... logprob:  0.793940, 0.358073 (1.404 sec)
24.163... logprob:  0.714956, 0.315104 (1.419 sec)
24.164... logprob:  0.697764, 0.298177 (1.419 sec)
24.165... logprob:  0.815197, 0.305990 (1.413 sec)
24.166... logprob:  0.681323, 0.304687 (1.444 sec)
24.167... logprob:  0.631682, 0.287760 (1.422 sec)
24.168... logprob:  0.564705, 0.243490 (1.418 sec)
24.169... logprob:  0.654878, 0.266927 (1.453 sec)
24.170... logprob:  0.604807, 0.268229 (1.395 sec)
24.171... logprob:  0.762898, 0.345052 (1.412 sec)
24.172... logprob:  0.680362, 0.259114 (1.411 sec)
24.173... logprob:  0.694264, 0.294271 (1.416 sec)
24.174... logprob:  0.756389, 0.278646 (1.403 sec)
24.175... logprob:  0.709792, 0.294271 (1.467 sec)
24.176... logprob:  0.699707, 0.329427 (1.411 sec)
24.177... logprob:  0.589742, 0.253906 (1.425 sec)
24.178... logprob:  0.568748, 0.272135 (1.456 sec)
24.179... logprob:  0.597601, 0.270833 (1.408 sec)
24.180... logprob:  0.740858, 0.313802 (1.419 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.400459, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.154037e-03 [1.578945e-07] 
Layer 'conv1' biases: 2.096027e-06 [1.091946e-10] 
Layer 'conv2' weights[0]: 3.147928e-03 [1.575391e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.302990e-09] 
Layer 'conv3' weights[0]: 3.146619e-03 [1.579454e-07] 
Layer 'conv3' biases: 3.469418e-05 [9.821086e-09] 
Layer 'conv4' weights[0]: 3.159900e-03 [1.590179e-07] 
Layer 'conv4' biases: 9.999218e-01 [2.397807e-07] 
Layer 'conv5' weights[0]: 3.297732e-03 [2.164832e-06] 
Layer 'conv5' biases: 9.991416e-01 [2.324668e-06] 
Layer 'fc6' weights[0]: 6.894588e-03 [6.304285e-08] 
Layer 'fc6' biases: 9.999907e-01 [5.715798e-08] 
Layer 'fc7' weights[0]: 7.242776e-03 [1.480809e-07] 
Layer 'fc7' biases: 9.997567e-01 [2.035521e-07] 
Layer 'fc8' weights[0]: 4.634917e-03 [1.510277e-05] 
Layer 'fc8' biases: 1.872414e-02 [3.240489e-05] 
Train error last 800 batches: 0.656573
-------------------------------------------------------
Not saving because 0.400459 > 0.299667 (9.300: -1.18%)
======================================================= (2.365 sec)
24.181... logprob:  0.751763, 0.332031 (1.424 sec)
24.182... logprob:  0.624297, 0.292969 (1.417 sec)
24.183... logprob:  0.611401, 0.247396 (1.414 sec)
24.184... logprob:  0.718247, 0.312500 (1.438 sec)
24.185... logprob:  0.637795, 0.287760 (1.390 sec)
24.186... logprob:  0.628419, 0.263021 (1.393 sec)
24.187... logprob:  0.700435, 0.325521 (1.395 sec)
24.188... logprob:  0.658737, 0.274740 (1.398 sec)
24.189... logprob:  0.655742, 0.296875 (1.385 sec)
24.190... logprob:  0.645523, 0.265625 (1.434 sec)
24.191... logprob:  0.707959, 0.303385 (1.406 sec)
24.192... logprob:  0.765776, 0.355469 (1.409 sec)
24.193... logprob:  0.549872, 0.253906 (1.414 sec)
24.194... logprob:  0.723330, 0.322917 (1.410 sec)
24.195... logprob:  0.497721, 0.238281 (1.398 sec)
24.196... logprob:  0.754469, 0.322917 (1.388 sec)
24.197... logprob:  0.768805, 0.313802 (1.398 sec)
24.198... logprob:  0.602264, 0.268229 (1.404 sec)
24.199... logprob:  0.616918, 0.294271 (1.384 sec)
24.200... logprob:  0.689876, 0.291667 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.415503, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.150895e-03 [1.577313e-07] 
Layer 'conv1' biases: 2.095997e-06 [8.641128e-11] 
Layer 'conv2' weights[0]: 3.144771e-03 [1.573642e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.300087e-10] 
Layer 'conv3' weights[0]: 3.143488e-03 [1.575704e-07] 
Layer 'conv3' biases: 3.469209e-05 [7.290033e-09] 
Layer 'conv4' weights[0]: 3.156726e-03 [1.587480e-07] 
Layer 'conv4' biases: 9.999228e-01 [2.071670e-07] 
Layer 'conv5' weights[0]: 3.295322e-03 [2.668431e-06] 
Layer 'conv5' biases: 9.991172e-01 [2.862593e-06] 
Layer 'fc6' weights[0]: 6.893887e-03 [6.530947e-08] 
Layer 'fc6' biases: 9.999907e-01 [6.059944e-08] 
Layer 'fc7' weights[0]: 7.242044e-03 [1.519487e-07] 
Layer 'fc7' biases: 9.997578e-01 [2.105942e-07] 
Layer 'fc8' weights[0]: 4.676259e-03 [1.644644e-05] 
Layer 'fc8' biases: 1.906538e-02 [4.308606e-05] 
Train error last 800 batches: 0.657003
-------------------------------------------------------
Not saving because 0.415503 > 0.299667 (9.300: -1.18%)
======================================================= (2.350 sec)
24.201... logprob:  0.575936, 0.273437 (1.413 sec)
24.202... logprob:  0.808250, 0.337240 (1.405 sec)
24.203... logprob:  0.586650, 0.231771 (1.441 sec)
24.204... logprob:  0.722134, 0.308594 (1.382 sec)
24.205... logprob:  0.556312, 0.247396 (1.396 sec)
24.206... logprob:  0.660426, 0.283854 (1.401 sec)
24.207... logprob:  0.680360, 0.292969 (1.401 sec)
24.208... logprob:  0.705250, 0.319010 (1.394 sec)
24.209... logprob:  0.616357, 0.270833 (1.417 sec)
24.210... logprob:  0.753139, 0.320312 (1.411 sec)
24.211... logprob:  0.818637, 0.325521 (1.408 sec)
24.212... logprob:  0.758731, 0.326823 (1.413 sec)
24.213... logprob:  0.769008, 0.302083 (1.451 sec)
24.214... logprob:  0.670863, 0.292969 (1.419 sec)
24.215... logprob:  0.588143, 0.272135 (1.410 sec)
24.216... logprob:  0.735901, 0.315104 (1.462 sec)
24.217... logprob:  0.640632, 0.259114 (1.401 sec)
24.218... logprob:  0.673925, 0.299479 (1.414 sec)
24.219... logprob:  0.700263, 0.304687 (1.411 sec)
24.220... logprob:  0.686511, 0.319010 (1.411 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.457458, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.147741e-03 [1.573616e-07] 
Layer 'conv1' biases: 2.096907e-06 [1.234939e-10] 
Layer 'conv2' weights[0]: 3.141620e-03 [1.571862e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.599203e-09] 
Layer 'conv3' weights[0]: 3.140342e-03 [1.578489e-07] 
Layer 'conv3' biases: 3.472447e-05 [1.225756e-08] 
Layer 'conv4' weights[0]: 3.153582e-03 [1.590310e-07] 
Layer 'conv4' biases: 9.999208e-01 [3.049081e-07] 
Layer 'conv5' weights[0]: 3.291176e-03 [2.849694e-06] 
Layer 'conv5' biases: 9.991313e-01 [3.050234e-06] 
Layer 'fc6' weights[0]: 6.893155e-03 [6.391105e-08] 
Layer 'fc6' biases: 9.999906e-01 [5.857607e-08] 
Layer 'fc7' weights[0]: 7.241287e-03 [1.486674e-07] 
Layer 'fc7' biases: 9.997569e-01 [2.001448e-07] 
Layer 'fc8' weights[0]: 4.644073e-03 [1.418512e-05] 
Layer 'fc8' biases: 1.883500e-02 [2.981581e-05] 
Train error last 800 batches: 0.657501
-------------------------------------------------------
Not saving because 0.457458 > 0.299667 (9.300: -1.18%)
======================================================= (2.372 sec)
24.221... logprob:  0.650037, 0.277344 (1.409 sec)
24.222... logprob:  0.751457, 0.291667 (1.459 sec)
24.223... logprob:  0.711646, 0.315104 (1.443 sec)
24.224... logprob:  0.699528, 0.298177 (1.425 sec)
24.225... logprob:  0.587204, 0.252604 (1.441 sec)
24.226... logprob:  0.624607, 0.261719 (1.419 sec)
24.227... logprob:  0.697397, 0.295573 (1.414 sec)
24.228... logprob:  0.698214, 0.300781 (1.406 sec)
24.229... logprob:  0.793508, 0.352865 (1.411 sec)
24.230... logprob:  0.683658, 0.302083 (1.427 sec)
24.231... logprob:  0.686113, 0.294271 (1.411 sec)
24.232... logprob:  0.685841, 0.304688 (1.457 sec)
24.233... logprob:  0.685779, 0.312500 (1.421 sec)
24.234... logprob:  0.724748, 0.330729 (1.416 sec)
24.235... logprob:  0.681646, 0.292969 (1.542 sec)
24.236... logprob:  0.633942, 0.266927 (1.399 sec)
24.237... logprob:  0.641113, 0.283854 (1.423 sec)
24.238... logprob:  0.638121, 0.287760 (1.418 sec)
24.239... logprob:  0.668948, 0.315104 (1.418 sec)
24.240... logprob:  0.718964, 0.286458 (1.398 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.527002, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.144601e-03 [1.574425e-07] 
Layer 'conv1' biases: 2.097989e-06 [1.309339e-10] 
Layer 'conv2' weights[0]: 3.138490e-03 [1.571286e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.218840e-09] 
Layer 'conv3' weights[0]: 3.137205e-03 [1.574527e-07] 
Layer 'conv3' biases: 3.473344e-05 [9.672981e-09] 
Layer 'conv4' weights[0]: 3.150433e-03 [1.583319e-07] 
Layer 'conv4' biases: 9.999207e-01 [2.080915e-07] 
Layer 'conv5' weights[0]: 3.288473e-03 [2.544811e-06] 
Layer 'conv5' biases: 9.991314e-01 [2.767016e-06] 
Layer 'fc6' weights[0]: 6.892486e-03 [6.316157e-08] 
Layer 'fc6' biases: 9.999908e-01 [5.730961e-08] 
Layer 'fc7' weights[0]: 7.240475e-03 [1.454724e-07] 
Layer 'fc7' biases: 9.997566e-01 [1.841712e-07] 
Layer 'fc8' weights[0]: 4.641213e-03 [1.308084e-05] 
Layer 'fc8' biases: 1.883104e-02 [2.472192e-05] 
Train error last 800 batches: 0.658234
-------------------------------------------------------
Not saving because 0.527002 > 0.299667 (9.300: -1.18%)
======================================================= (2.389 sec)
24.241... logprob:  0.725253, 0.273437 (1.463 sec)
24.242... logprob:  0.640950, 0.281250 (1.435 sec)
24.243... logprob:  0.624434, 0.283854 (1.431 sec)
24.244... logprob:  0.671213, 0.298177 (1.439 sec)
24.245... logprob:  0.697338, 0.304687 (1.417 sec)
24.246... logprob:  0.653862, 0.282552 (1.410 sec)
24.247... logprob:  0.565955, 0.243490 (1.411 sec)
24.248... logprob:  0.636585, 0.291667 (1.412 sec)
24.249... logprob:  0.764412, 0.322917 (1.417 sec)
24.250... logprob:  0.659088, 0.291667 (1.401 sec)
24.251... logprob:  0.659356, 0.290365 (1.453 sec)
24.252... logprob:  0.683496, 0.319010 (1.425 sec)
24.253... logprob:  0.634495, 0.278646 (1.411 sec)
24.254... logprob:  0.620586, 0.272135 (1.462 sec)
24.255... logprob:  0.580152, 0.255208 (1.403 sec)
24.256... logprob:  0.687335, 0.319010 (1.417 sec)
24.257... logprob:  0.607157, 0.272135 (1.417 sec)
24.258... logprob:  0.664057, 0.305990 (1.420 sec)
24.259... logprob:  0.612885, 0.244792 (1.393 sec)
24.260... logprob:  0.597547, 0.289062 (1.450 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.402953, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.141457e-03 [1.571494e-07] 
Layer 'conv1' biases: 2.098751e-06 [1.671320e-10] 
Layer 'conv2' weights[0]: 3.135345e-03 [1.569390e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.504829e-09] 
Layer 'conv3' weights[0]: 3.134061e-03 [1.574979e-07] 
Layer 'conv3' biases: 3.470842e-05 [1.157858e-08] 
Layer 'conv4' weights[0]: 3.147274e-03 [1.587355e-07] 
Layer 'conv4' biases: 9.999220e-01 [2.684247e-07] 
Layer 'conv5' weights[0]: 3.286598e-03 [2.913643e-06] 
Layer 'conv5' biases: 9.991043e-01 [3.158967e-06] 
Layer 'fc6' weights[0]: 6.891802e-03 [6.811531e-08] 
Layer 'fc6' biases: 9.999905e-01 [6.399901e-08] 
Layer 'fc7' weights[0]: 7.239775e-03 [1.635139e-07] 
Layer 'fc7' biases: 9.997588e-01 [2.651996e-07] 
Layer 'fc8' weights[0]: 4.710564e-03 [1.772048e-05] 
Layer 'fc8' biases: 1.945076e-02 [4.968315e-05] 
Train error last 800 batches: 0.658947
-------------------------------------------------------
Not saving because 0.402953 > 0.299667 (9.300: -1.18%)
======================================================= (2.378 sec)
24.261... logprob:  0.643593, 0.276042 (1.455 sec)
24.262... logprob:  0.694055, 0.309896 (1.430 sec)
24.263... logprob:  0.723491, 0.295573 (1.446 sec)
24.264... logprob:  0.662272, 0.286458 (1.426 sec)
24.265... logprob:  0.632797, 0.250000 (1.404 sec)
24.266... logprob:  0.697513, 0.316406 (1.412 sec)
24.267... logprob:  0.647778, 0.292969 (1.407 sec)
24.268... logprob:  0.671392, 0.330729 (1.414 sec)
24.269... logprob:  0.744668, 0.304688 (1.402 sec)
24.270... logprob:  0.759346, 0.309896 (1.456 sec)
24.271... logprob:  0.701372, 0.316406 (1.427 sec)
24.272... logprob:  0.653998, 0.298177 (1.418 sec)
24.273... logprob:  0.704640, 0.321615 (1.467 sec)
24.274... logprob:  0.837255, 0.360677 (1.391 sec)
24.275... logprob:  0.769568, 0.317708 (1.417 sec)
24.276... logprob:  0.649631, 0.270833 (1.409 sec)
24.277... logprob:  0.607216, 0.257812 (1.424 sec)
24.278... logprob:  0.595063, 0.294271 (1.419 sec)
24.279... logprob:  0.570973, 0.251302 (1.459 sec)
24.280... logprob:  0.566870, 0.266927 (1.408 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.512415, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.138322e-03 [1.568725e-07] 
Layer 'conv1' biases: 2.099274e-06 [1.018729e-10] 
Layer 'conv2' weights[0]: 3.132214e-03 [1.566508e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.003923e-09] 
Layer 'conv3' weights[0]: 3.130937e-03 [1.569250e-07] 
Layer 'conv3' biases: 3.469870e-05 [7.852259e-09] 
Layer 'conv4' weights[0]: 3.144135e-03 [1.578282e-07] 
Layer 'conv4' biases: 9.999214e-01 [1.829151e-07] 
Layer 'conv5' weights[0]: 3.283598e-03 [2.327750e-06] 
Layer 'conv5' biases: 9.991306e-01 [2.487639e-06] 
Layer 'fc6' weights[0]: 6.891075e-03 [5.965681e-08] 
Layer 'fc6' biases: 9.999906e-01 [5.278365e-08] 
Layer 'fc7' weights[0]: 7.239045e-03 [1.370444e-07] 
Layer 'fc7' biases: 9.997568e-01 [1.758370e-07] 
Layer 'fc8' weights[0]: 4.645490e-03 [1.379040e-05] 
Layer 'fc8' biases: 1.894080e-02 [2.199099e-05] 
Train error last 800 batches: 0.659123
-------------------------------------------------------
Not saving because 0.512415 > 0.299667 (9.300: -1.18%)
======================================================= (2.385 sec)
24.281... logprob:  0.596875, 0.274740 (1.424 sec)
24.282... logprob:  0.561511, 0.259114 (1.419 sec)
24.283... logprob:  0.665067, 0.307292 (1.413 sec)
24.284... logprob:  0.656565, 0.309896 (1.410 sec)
24.285... logprob:  0.702150, 0.317708 (1.440 sec)
24.286... logprob:  0.684009, 0.300781 (1.431 sec)
24.287... logprob:  0.615209, 0.286458 (1.426 sec)
24.288... logprob:  0.557673, 0.250000 (1.433 sec)
24.289... logprob:  0.749127, 0.321615 (1.437 sec)
24.290... logprob:  0.694053, 0.316406 (1.397 sec)
24.291... logprob:  0.600041, 0.243489 (1.412 sec)
24.292... logprob:  0.817023, 0.348958 (1.414 sec)
24.293... logprob:  0.656090, 0.319010 (1.419 sec)
24.294... logprob:  0.577051, 0.260417 (1.400 sec)
24.295... logprob:  0.533194, 0.213542 (1.457 sec)
24.296... logprob:  0.663884, 0.294271 (1.420 sec)
24.297... logprob:  0.577753, 0.270833 (1.415 sec)
24.298... logprob:  0.638191, 0.278646 (1.455 sec)
24.299... logprob:  0.512556, 0.231771 (1.398 sec)
24.300... logprob:  0.651150, 0.265625 (1.414 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.565270, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.135177e-03 [1.569267e-07] 
Layer 'conv1' biases: 2.099672e-06 [9.140582e-11] 
Layer 'conv2' weights[0]: 3.129074e-03 [1.566294e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.018586e-09] 
Layer 'conv3' weights[0]: 3.127793e-03 [1.568129e-07] 
Layer 'conv3' biases: 3.468670e-05 [7.562051e-09] 
Layer 'conv4' weights[0]: 3.141004e-03 [1.579227e-07] 
Layer 'conv4' biases: 9.999224e-01 [2.066749e-07] 
Layer 'conv5' weights[0]: 3.281409e-03 [2.844493e-06] 
Layer 'conv5' biases: 9.990960e-01 [3.028608e-06] 
Layer 'fc6' weights[0]: 6.890357e-03 [6.576503e-08] 
Layer 'fc6' biases: 9.999905e-01 [6.121724e-08] 
Layer 'fc7' weights[0]: 7.238303e-03 [1.546591e-07] 
Layer 'fc7' biases: 9.997587e-01 [2.337854e-07] 
Layer 'fc8' weights[0]: 4.736424e-03 [1.612782e-05] 
Layer 'fc8' biases: 1.964942e-02 [3.898470e-05] 
Train error last 800 batches: 0.659100
-------------------------------------------------------
Not saving because 0.565270 > 0.299667 (9.300: -1.18%)
======================================================= (2.388 sec)
24.301... logprob:  0.698502, 0.316406 (1.417 sec)
24.302... logprob:  0.900222, 0.371094 (1.416 sec)
24.303... logprob:  0.695726, 0.299479 (1.403 sec)
24.304... logprob:  0.643020, 0.283854 (1.434 sec)
24.305... logprob:  0.641517, 0.265625 (1.430 sec)
24.306... logprob:  0.726223, 0.312500 (1.428 sec)
24.307... logprob:  0.577319, 0.253906 (1.437 sec)
24.308... logprob:  0.612471, 0.292969 (1.455 sec)
24.309... logprob:  0.684727, 0.300781 (1.417 sec)
24.310... logprob:  0.641085, 0.257812 (1.427 sec)
24.311... logprob:  0.670525, 0.260417 (1.421 sec)
24.312... logprob:  0.728552, 0.290365 (1.427 sec)
24.313... logprob:  0.664782, 0.298177 (1.413 sec)
24.314... logprob:  0.723337, 0.325521 (1.458 sec)
24.315... logprob:  0.656754, 0.290364 (1.430 sec)
24.316... logprob:  0.632810, 0.270833 (1.422 sec)
24.317... logprob:  0.620003, 0.289062 (1.470 sec)
24.318... logprob:  0.663270, 0.272135 (1.407 sec)
24.319... logprob:  0.678184, 0.304687 (1.424 sec)
24.320... logprob:  0.686224, 0.303385 (1.416 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.445122, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.132048e-03 [1.567084e-07] 
Layer 'conv1' biases: 2.100404e-06 [8.756565e-11] 
Layer 'conv2' weights[0]: 3.125948e-03 [1.563499e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.074018e-09] 
Layer 'conv3' weights[0]: 3.124657e-03 [1.566192e-07] 
Layer 'conv3' biases: 3.470216e-05 [7.858252e-09] 
Layer 'conv4' weights[0]: 3.137853e-03 [1.574584e-07] 
Layer 'conv4' biases: 9.999231e-01 [1.896360e-07] 
Layer 'conv5' weights[0]: 3.279286e-03 [2.310708e-06] 
Layer 'conv5' biases: 9.991170e-01 [2.522812e-06] 
Layer 'fc6' weights[0]: 6.889632e-03 [6.237853e-08] 
Layer 'fc6' biases: 9.999906e-01 [5.678077e-08] 
Layer 'fc7' weights[0]: 7.237588e-03 [1.438747e-07] 
Layer 'fc7' biases: 9.997569e-01 [1.819138e-07] 
Layer 'fc8' weights[0]: 4.688505e-03 [1.329422e-05] 
Layer 'fc8' biases: 1.928018e-02 [1.919862e-05] 
Train error last 800 batches: 0.659364
-------------------------------------------------------
Not saving because 0.445122 > 0.299667 (9.300: -1.18%)
======================================================= (2.386 sec)
24.321... logprob:  0.647193, 0.299479 (1.426 sec)
24.322... logprob:  0.555060, 0.227865 (1.415 sec)
24.323... logprob:  0.669894, 0.287760 (1.474 sec)
24.324... logprob:  0.648140, 0.270833 (1.417 sec)
24.325... logprob:  0.555312, 0.244792 (1.431 sec)
24.326... logprob:  0.669079, 0.285156 (1.454 sec)
24.327... logprob:  0.718542, 0.325521 (1.419 sec)
24.328... logprob:  0.757572, 0.329427 (1.426 sec)
24.329... logprob:  0.643495, 0.312500 (1.423 sec)
24.330... logprob:  0.631533, 0.325521 (1.416 sec)
24.331... logprob:  0.564090, 0.240885 (1.418 sec)
24.332... logprob:  0.754261, 0.334635 (1.443 sec)
24.333... logprob:  0.573417, 0.229167 (1.440 sec)
24.334... logprob:  0.738820, 0.308594 (1.441 sec)
24.335... logprob:  0.639913, 0.295573 (1.434 sec)
24.336... logprob:  0.609615, 0.238281 (1.451 sec)
24.337... logprob:  0.791448, 0.315104 (1.412 sec)
24.338... logprob:  0.567316, 0.263021 (1.421 sec)
24.339... logprob:  0.721681, 0.292969 (1.429 sec)
24.340... logprob:  0.590847, 0.269531 (1.452 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.324933, 0.039062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.128922e-03 [1.565428e-07] 
Layer 'conv1' biases: 2.101149e-06 [8.703273e-11] 
Layer 'conv2' weights[0]: 3.122832e-03 [1.562448e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.828578e-10] 
Layer 'conv3' weights[0]: 3.121544e-03 [1.564050e-07] 
Layer 'conv3' biases: 3.469139e-05 [6.973032e-09] 
Layer 'conv4' weights[0]: 3.134708e-03 [1.573666e-07] 
Layer 'conv4' biases: 9.999227e-01 [1.635956e-07] 
Layer 'conv5' weights[0]: 3.276116e-03 [2.243873e-06] 
Layer 'conv5' biases: 9.991176e-01 [2.364416e-06] 
Layer 'fc6' weights[0]: 6.888874e-03 [6.188064e-08] 
Layer 'fc6' biases: 9.999906e-01 [5.618577e-08] 
Layer 'fc7' weights[0]: 7.236876e-03 [1.430246e-07] 
Layer 'fc7' biases: 9.997563e-01 [1.772869e-07] 
Layer 'fc8' weights[0]: 4.685462e-03 [1.302081e-05] 
Layer 'fc8' biases: 1.924130e-02 [1.876462e-05] 
Train error last 800 batches: 0.659359
-------------------------------------------------------
Not saving because 0.324933 > 0.299667 (9.300: -1.18%)
======================================================= (2.377 sec)
24.341... logprob:  0.738290, 0.330729 (1.422 sec)
24.342... logprob:  0.591266, 0.273438 (1.465 sec)
24.343... logprob:  0.695547, 0.295573 (1.439 sec)
24.344... logprob:  0.703225, 0.307292 (1.476 sec)
24.345... logprob:  0.734277, 0.302083 (1.432 sec)
24.346... logprob:  0.682691, 0.315104 (1.430 sec)
24.347... logprob:  0.632143, 0.277344 (1.478 sec)
24.348... logprob:  0.627418, 0.283854 (1.426 sec)
24.349... logprob:  0.708151, 0.302083 (1.427 sec)
24.350... logprob:  0.615268, 0.274740 (1.426 sec)
24.351... logprob:  0.689127, 0.272135 (1.425 sec)
24.352... logprob:  0.555995, 0.244792 (1.428 sec)
24.353... logprob:  0.708920, 0.324219 (1.479 sec)
24.354... logprob:  0.855648, 0.325521 (1.430 sec)
24.355... logprob:  0.503045, 0.212240 (1.443 sec)
24.356... logprob:  0.657474, 0.273437 (1.470 sec)
24.357... logprob:  0.558877, 0.246094 (1.426 sec)
24.358... logprob:  0.622117, 0.268229 (1.441 sec)
24.359... logprob:  0.770461, 0.316406 (1.430 sec)
24.360... logprob:  0.612573, 0.260417 (1.422 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.471207, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.125788e-03 [1.562223e-07] 
Layer 'conv1' biases: 2.102019e-06 [1.018144e-10] 
Layer 'conv2' weights[0]: 3.119721e-03 [1.560357e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.027690e-09] 
Layer 'conv3' weights[0]: 3.118424e-03 [1.563008e-07] 
Layer 'conv3' biases: 3.467706e-05 [7.834479e-09] 
Layer 'conv4' weights[0]: 3.131574e-03 [1.572261e-07] 
Layer 'conv4' biases: 9.999231e-01 [1.713045e-07] 
Layer 'conv5' weights[0]: 3.273966e-03 [2.386037e-06] 
Layer 'conv5' biases: 9.991347e-01 [2.495245e-06] 
Layer 'fc6' weights[0]: 6.888191e-03 [6.350644e-08] 
Layer 'fc6' biases: 9.999908e-01 [5.767624e-08] 
Layer 'fc7' weights[0]: 7.236176e-03 [1.460006e-07] 
Layer 'fc7' biases: 9.997555e-01 [1.821125e-07] 
Layer 'fc8' weights[0]: 4.664373e-03 [1.351149e-05] 
Layer 'fc8' biases: 1.909273e-02 [2.456916e-05] 
Train error last 800 batches: 0.659409
-------------------------------------------------------
Not saving because 0.471207 > 0.299667 (9.300: -1.18%)
======================================================= (2.351 sec)
24.361... logprob:  0.632037, 0.296875 (1.444 sec)
24.362... logprob:  0.608110, 0.276042 (1.475 sec)
24.363... logprob:  0.682587, 0.278646 (1.440 sec)
24.364... logprob:  0.667476, 0.302083 (1.447 sec)
24.365... logprob:  0.633715, 0.257812 (1.454 sec)
24.366... logprob:  0.583679, 0.274740 (1.440 sec)
24.367... logprob:  0.552990, 0.233073 (1.432 sec)
24.368... logprob:  0.814649, 0.316406 (1.423 sec)
24.369... logprob:  0.613388, 0.281250 (1.420 sec)
24.370... logprob:  0.661233, 0.285156 (1.433 sec)
24.371... logprob:  0.562283, 0.240885 (1.458 sec)
24.372... logprob:  0.732241, 0.329427 (1.448 sec)
24.373... logprob:  0.682108, 0.313802 (1.449 sec)
24.374... logprob:  0.744908, 0.342448 (1.445 sec)
24.375... logprob:  0.681520, 0.290365 (1.455 sec)
24.376... logprob:  0.577318, 0.248698 (1.435 sec)
24.377... logprob:  0.553218, 0.260417 (1.425 sec)
24.378... logprob:  0.615528, 0.282552 (1.464 sec)
24.379... logprob:  0.637613, 0.287760 (1.429 sec)
24.380... logprob:  0.757128, 0.299479 (1.435 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.503980, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.122669e-03 [1.562083e-07] 
Layer 'conv1' biases: 2.102407e-06 [9.485011e-11] 
Layer 'conv2' weights[0]: 3.116601e-03 [1.558790e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.024560e-09] 
Layer 'conv3' weights[0]: 3.115302e-03 [1.561620e-07] 
Layer 'conv3' biases: 3.465499e-05 [7.149245e-09] 
Layer 'conv4' weights[0]: 3.128436e-03 [1.569832e-07] 
Layer 'conv4' biases: 9.999246e-01 [1.735605e-07] 
Layer 'conv5' weights[0]: 3.271742e-03 [2.176143e-06] 
Layer 'conv5' biases: 9.991238e-01 [2.359311e-06] 
Layer 'fc6' weights[0]: 6.887454e-03 [5.994200e-08] 
Layer 'fc6' biases: 9.999906e-01 [5.307877e-08] 
Layer 'fc7' weights[0]: 7.235464e-03 [1.390710e-07] 
Layer 'fc7' biases: 9.997562e-01 [1.657858e-07] 
Layer 'fc8' weights[0]: 4.703235e-03 [1.239870e-05] 
Layer 'fc8' biases: 1.944895e-02 [1.085791e-05] 
Train error last 800 batches: 0.659321
-------------------------------------------------------
Not saving because 0.503980 > 0.299667 (9.300: -1.18%)
======================================================= (2.363 sec)
24.381... logprob:  0.734984, 0.298177 (1.468 sec)
24.382... logprob:  0.685782, 0.291667 (1.452 sec)
24.383... logprob:  0.631924, 0.304687 (1.574 sec)
24.384... logprob:  0.724035, 0.286458 (1.472 sec)
24.385... logprob:  0.742527, 0.312500 (1.430 sec)
24.386... logprob:  0.760935, 0.324219 (1.427 sec)
24.387... logprob:  0.724088, 0.334635 (1.426 sec)
24.388... logprob:  0.740469, 0.322917 (1.434 sec)
24.389... logprob:  0.685879, 0.320312 (1.431 sec)
24.390... logprob:  0.585272, 0.248698 (1.470 sec)
24.391... logprob:  0.607634, 0.289062 (1.439 sec)
24.392... logprob:  0.598040, 0.277344 (1.427 sec)
24.393... logprob:  0.585669, 0.251302 (1.480 sec)
24.394... logprob:  0.555332, 0.235677 (1.424 sec)
24.395... logprob:  0.566327, 0.266927 (1.425 sec)
24.396... logprob:  0.538443, 0.225260 (1.430 sec)
24.397... logprob:  0.672472, 0.302083 (1.424 sec)
24.398... logprob:  0.646945, 0.276042 (1.425 sec)
24.399... logprob:  0.725792, 0.316406 (1.480 sec)
24.400... logprob:  0.791748, 0.372396 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.442607, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.119539e-03 [1.560501e-07] 
Layer 'conv1' biases: 2.102636e-06 [9.652646e-11] 
Layer 'conv2' weights[0]: 3.113466e-03 [1.558112e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.041952e-09] 
Layer 'conv3' weights[0]: 3.112192e-03 [1.562024e-07] 
Layer 'conv3' biases: 3.466037e-05 [8.661583e-09] 
Layer 'conv4' weights[0]: 3.125323e-03 [1.572897e-07] 
Layer 'conv4' biases: 9.999218e-01 [2.212014e-07] 
Layer 'conv5' weights[0]: 3.267623e-03 [2.475928e-06] 
Layer 'conv5' biases: 9.991223e-01 [2.674527e-06] 
Layer 'fc6' weights[0]: 6.886798e-03 [6.195171e-08] 
Layer 'fc6' biases: 9.999906e-01 [5.557558e-08] 
Layer 'fc7' weights[0]: 7.234716e-03 [1.417463e-07] 
Layer 'fc7' biases: 9.997564e-01 [1.818811e-07] 
Layer 'fc8' weights[0]: 4.700340e-03 [1.308671e-05] 
Layer 'fc8' biases: 1.941411e-02 [2.057891e-05] 
Train error last 800 batches: 0.659510
-------------------------------------------------------
Not saving because 0.442607 > 0.299667 (9.300: -1.18%)
======================================================= (2.359 sec)
24.401... logprob:  0.663897, 0.302083 (1.448 sec)
24.402... logprob:  0.656609, 0.300781 (1.478 sec)
24.403... logprob:  0.767956, 0.350260 (1.426 sec)
24.404... logprob:  0.654610, 0.295573 (1.429 sec)
24.405... logprob:  0.668799, 0.294271 (1.431 sec)
24.406... logprob:  0.610373, 0.279948 (1.417 sec)
24.407... logprob:  0.669975, 0.289062 (1.433 sec)
24.408... logprob:  0.449046, 0.192708 (1.479 sec)
24.409... logprob:  0.610417, 0.270833 (1.429 sec)
24.410... logprob:  0.752440, 0.329427 (1.444 sec)
24.411... logprob:  0.629314, 0.305990 (1.478 sec)
24.412... logprob:  0.798414, 0.326823 (1.435 sec)
24.413... logprob:  0.738470, 0.316406 (1.432 sec)
24.414... logprob:  0.602083, 0.261719 (1.424 sec)
24.415... logprob:  0.605411, 0.265625 (1.419 sec)
24.416... logprob:  0.701367, 0.296875 (1.457 sec)
24.417... logprob:  0.589354, 0.272135 (1.466 sec)
24.418... logprob:  0.601918, 0.266927 (1.444 sec)
24.419... logprob:  0.680221, 0.300781 (1.445 sec)
24.420... logprob:  0.614178, 0.268229 (1.449 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.445492, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.116424e-03 [1.560737e-07] 
Layer 'conv1' biases: 2.103212e-06 [1.166674e-10] 
Layer 'conv2' weights[0]: 3.110370e-03 [1.556757e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.095990e-09] 
Layer 'conv3' weights[0]: 3.109110e-03 [1.559314e-07] 
Layer 'conv3' biases: 3.466386e-05 [8.058829e-09] 
Layer 'conv4' weights[0]: 3.122185e-03 [1.569479e-07] 
Layer 'conv4' biases: 9.999208e-01 [1.849257e-07] 
Layer 'conv5' weights[0]: 3.263935e-03 [2.243174e-06] 
Layer 'conv5' biases: 9.991136e-01 [2.451616e-06] 
Layer 'fc6' weights[0]: 6.886086e-03 [6.114048e-08] 
Layer 'fc6' biases: 9.999906e-01 [5.492048e-08] 
Layer 'fc7' weights[0]: 7.233968e-03 [1.422569e-07] 
Layer 'fc7' biases: 9.997562e-01 [1.935714e-07] 
Layer 'fc8' weights[0]: 4.715564e-03 [1.437678e-05] 
Layer 'fc8' biases: 1.959190e-02 [2.834199e-05] 
Train error last 800 batches: 0.659055
-------------------------------------------------------
Not saving because 0.445492 > 0.299667 (9.300: -1.18%)
======================================================= (2.391 sec)
24.421... logprob:  0.589801, 0.266927 (1.460 sec)
24.422... logprob:  0.763657, 0.333333 (1.440 sec)
24.423... logprob:  0.696335, 0.298177 (1.426 sec)
24.424... logprob:  0.563760, 0.277344 (1.422 sec)
24.425... logprob:  0.597645, 0.281250 (1.429 sec)
24.426... logprob:  0.631559, 0.279948 (1.443 sec)
24.427... logprob:  0.805064, 0.319010 (1.453 sec)
24.428... logprob:  0.756181, 0.315104 (1.447 sec)
24.429... logprob:  0.750484, 0.317708 (1.437 sec)
24.430... logprob:  0.620979, 0.281250 (1.472 sec)
24.431... logprob:  0.762344, 0.304687 (1.434 sec)
24.432... logprob:  0.562012, 0.256510 (1.422 sec)
24.433... logprob:  0.544142, 0.250000 (1.435 sec)
24.434... logprob:  0.853772, 0.332031 (1.436 sec)
24.435... logprob:  0.781877, 0.322917 (1.430 sec)
24.436... logprob:  0.635219, 0.260417 (1.475 sec)
24.437... logprob:  0.674276, 0.289062 (1.444 sec)
24.438... logprob:  0.672733, 0.285156 (1.428 sec)
24.439... logprob:  0.678075, 0.309896 (1.482 sec)
24.440... logprob:  0.728690, 0.338542 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.514406, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.113322e-03 [1.558203e-07] 
Layer 'conv1' biases: 2.103527e-06 [1.178258e-10] 
Layer 'conv2' weights[0]: 3.107259e-03 [1.554087e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.282602e-09] 
Layer 'conv3' weights[0]: 3.106000e-03 [1.558868e-07] 
Layer 'conv3' biases: 3.465663e-05 [9.547174e-09] 
Layer 'conv4' weights[0]: 3.119060e-03 [1.568507e-07] 
Layer 'conv4' biases: 9.999201e-01 [2.607685e-07] 
Layer 'conv5' weights[0]: 3.260460e-03 [3.266776e-06] 
Layer 'conv5' biases: 9.991372e-01 [3.591105e-06] 
Layer 'fc6' weights[0]: 6.885371e-03 [7.096978e-08] 
Layer 'fc6' biases: 9.999905e-01 [6.723594e-08] 
Layer 'fc7' weights[0]: 7.233308e-03 [1.701935e-07] 
Layer 'fc7' biases: 9.997548e-01 [2.705398e-07] 
Layer 'fc8' weights[0]: 4.660448e-03 [1.708879e-05] 
Layer 'fc8' biases: 1.920132e-02 [4.482320e-05] 
Train error last 800 batches: 0.659335
-------------------------------------------------------
Not saving because 0.514406 > 0.299667 (9.300: -1.18%)
======================================================= (2.368 sec)
24.441... logprob:  0.690421, 0.311198 (1.428 sec)
24.442... logprob:  0.622312, 0.282552 (1.430 sec)
24.443... logprob:  0.748211, 0.326823 (1.430 sec)
24.444... logprob:  0.651029, 0.300781 (1.434 sec)
24.445... logprob:  0.638659, 0.303385 (1.486 sec)
24.446... logprob:  0.699969, 0.307292 (1.434 sec)
24.447... logprob:  0.719845, 0.300781 (1.438 sec)
24.448... logprob:  0.687916, 0.294271 (1.479 sec)
24.449... logprob:  0.651841, 0.281250 (1.434 sec)
24.450... logprob:  0.495250, 0.208333 (1.426 sec)
24.451... logprob:  0.660905, 0.319010 (1.433 sec)
24.452... logprob:  0.601816, 0.236979 (1.426 sec)
24.453... logprob:  0.737815, 0.303385 (1.432 sec)
24.454... logprob:  0.757637, 0.330729 (1.509 sec)
24.455... logprob:  0.718316, 0.342448 (1.425 sec)
24.456... logprob:  0.655759, 0.264323 (1.443 sec)
24.457... logprob:  0.633279, 0.289062 (1.479 sec)
24.458... logprob:  0.594343, 0.278646 (1.437 sec)
24.459... logprob:  0.774248, 0.332031 (1.436 sec)
24.460... logprob:  0.520377, 0.257812 (1.425 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.484787, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.110211e-03 [1.556195e-07] 
Layer 'conv1' biases: 2.103479e-06 [7.334047e-11] 
Layer 'conv2' weights[0]: 3.104153e-03 [1.553416e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.615597e-10] 
Layer 'conv3' weights[0]: 3.102868e-03 [1.555759e-07] 
Layer 'conv3' biases: 3.467308e-05 [7.857816e-09] 
Layer 'conv4' weights[0]: 3.115968e-03 [1.566615e-07] 
Layer 'conv4' biases: 9.999207e-01 [2.050841e-07] 
Layer 'conv5' weights[0]: 3.258201e-03 [2.646740e-06] 
Layer 'conv5' biases: 9.991364e-01 [2.815878e-06] 
Layer 'fc6' weights[0]: 6.884672e-03 [6.425843e-08] 
Layer 'fc6' biases: 9.999906e-01 [5.837724e-08] 
Layer 'fc7' weights[0]: 7.232553e-03 [1.468522e-07] 
Layer 'fc7' biases: 9.997548e-01 [2.069460e-07] 
Layer 'fc8' weights[0]: 4.661748e-03 [1.378064e-05] 
Layer 'fc8' biases: 1.918247e-02 [3.136200e-05] 
Train error last 800 batches: 0.659507
-------------------------------------------------------
Not saving because 0.484787 > 0.299667 (9.300: -1.18%)
======================================================= (2.356 sec)
24.461... logprob:  0.641604, 0.287760 (1.432 sec)
24.462... logprob:  0.604693, 0.266927 (1.441 sec)
24.463... logprob:  0.572180, 0.242187 (1.465 sec)
24.464... logprob:  0.640549, 0.287760 (1.443 sec)
24.465... logprob:  0.599998, 0.264323 (1.448 sec)
24.466... logprob:  0.596408, 0.250000 (1.454 sec)
24.467... logprob:  0.633528, 0.260417 (1.445 sec)
24.468... logprob:  0.606912, 0.253906 (1.438 sec)
24.469... logprob:  0.619961, 0.268229 (1.432 sec)
24.470... logprob:  0.617111, 0.256510 (1.427 sec)
24.471... logprob:  0.703546, 0.276042 (1.437 sec)
24.472... logprob:  0.694533, 0.299479 (1.447 sec)
24.473... logprob:  0.677787, 0.283854 (1.447 sec)
24.474... logprob:  0.651091, 0.276042 (1.450 sec)
24.475... logprob:  0.785357, 0.343750 (1.440 sec)
24.476... logprob:  0.711642, 0.317708 (1.466 sec)
24.477... logprob:  0.576918, 0.261719 (1.437 sec)
24.478... logprob:  0.634895, 0.311198 (1.427 sec)
24.479... logprob:  0.576002, 0.252604 (1.430 sec)
24.480... logprob:  0.635786, 0.260417 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.452789, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.107089e-03 [1.554236e-07] 
Layer 'conv1' biases: 2.103834e-06 [8.423843e-11] 
Layer 'conv2' weights[0]: 3.101036e-03 [1.551329e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.863469e-10] 
Layer 'conv3' weights[0]: 3.099775e-03 [1.552972e-07] 
Layer 'conv3' biases: 3.469103e-05 [6.145405e-09] 
Layer 'conv4' weights[0]: 3.112843e-03 [1.561126e-07] 
Layer 'conv4' biases: 9.999206e-01 [1.573718e-07] 
Layer 'conv5' weights[0]: 3.255586e-03 [2.200517e-06] 
Layer 'conv5' biases: 9.991153e-01 [2.381744e-06] 
Layer 'fc6' weights[0]: 6.883996e-03 [6.001596e-08] 
Layer 'fc6' biases: 9.999906e-01 [5.325380e-08] 
Layer 'fc7' weights[0]: 7.231820e-03 [1.373417e-07] 
Layer 'fc7' biases: 9.997562e-01 [1.679853e-07] 
Layer 'fc8' weights[0]: 4.714030e-03 [1.236545e-05] 
Layer 'fc8' biases: 1.970244e-02 [1.675363e-05] 
Train error last 800 batches: 0.659203
-------------------------------------------------------
Not saving because 0.452789 > 0.299667 (9.300: -1.18%)
======================================================= (2.370 sec)
24.481... logprob:  0.764665, 0.312500 (1.437 sec)
24.482... logprob:  0.675694, 0.298177 (1.477 sec)
24.483... logprob:  0.669496, 0.307292 (1.445 sec)
24.484... logprob:  0.767785, 0.321614 (1.432 sec)
24.485... logprob:  0.639567, 0.308594 (1.475 sec)
24.486... logprob:  0.629289, 0.278646 (1.429 sec)
24.487... logprob:  0.706700, 0.328125 (1.429 sec)
24.488... logprob:  0.627892, 0.298177 (1.427 sec)
24.489... logprob:  0.637560, 0.304688 (1.430 sec)
24.490... logprob:  0.645055, 0.291667 (1.429 sec)
24.491... logprob:  0.518624, 0.209635 (1.481 sec)
24.492... logprob:  0.703929, 0.308594 (1.473 sec)
24.493... logprob:  0.770779, 0.341146 (1.429 sec)
24.494... logprob:  0.671144, 0.308594 (1.479 sec)
24.495... logprob:  0.713755, 0.305990 (1.433 sec)
24.496... logprob:  0.697112, 0.281250 (1.430 sec)
24.497... logprob:  0.618868, 0.287760 (1.432 sec)
24.498... logprob:  0.631361, 0.265625 (1.424 sec)
24.499... logprob:  0.608379, 0.253906 (1.424 sec)
24.500... logprob:  0.614479, 0.261719 (1.482 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.505277, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.103984e-03 [1.552750e-07] 
Layer 'conv1' biases: 2.104559e-06 [7.835907e-11] 
Layer 'conv2' weights[0]: 3.097953e-03 [1.549708e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.723232e-10] 
Layer 'conv3' weights[0]: 3.096683e-03 [1.552117e-07] 
Layer 'conv3' biases: 3.469502e-05 [7.376541e-09] 
Layer 'conv4' weights[0]: 3.109716e-03 [1.559809e-07] 
Layer 'conv4' biases: 9.999190e-01 [1.678296e-07] 
Layer 'conv5' weights[0]: 3.251569e-03 [2.125008e-06] 
Layer 'conv5' biases: 9.991326e-01 [2.294368e-06] 
Layer 'fc6' weights[0]: 6.883312e-03 [6.071362e-08] 
Layer 'fc6' biases: 9.999909e-01 [5.413396e-08] 
Layer 'fc7' weights[0]: 7.231097e-03 [1.395382e-07] 
Layer 'fc7' biases: 9.997554e-01 [1.731502e-07] 
Layer 'fc8' weights[0]: 4.677143e-03 [1.375960e-05] 
Layer 'fc8' biases: 1.947910e-02 [2.704004e-05] 
Train error last 800 batches: 0.659257
-------------------------------------------------------
Not saving because 0.505277 > 0.299667 (9.300: -1.18%)
======================================================= (2.363 sec)
24.501... logprob:  0.590807, 0.264323 (1.430 sec)
24.502... logprob:  0.690399, 0.308594 (1.441 sec)
24.503... logprob:  0.672721, 0.283854 (1.475 sec)
24.504... logprob:  0.565905, 0.257812 (1.424 sec)
24.505... logprob:  0.798898, 0.330729 (1.433 sec)
24.506... logprob:  0.664483, 0.305990 (1.428 sec)
24.507... logprob:  0.646740, 0.269531 (1.419 sec)
24.508... logprob:  0.574564, 0.231771 (1.425 sec)
24.509... logprob:  0.576175, 0.238281 (1.469 sec)
24.510... logprob:  0.573107, 0.263021 (1.440 sec)
24.511... logprob:  0.597149, 0.248698 (1.454 sec)
24.512... logprob:  0.740699, 0.312500 (1.463 sec)
24.513... logprob:  0.586512, 0.266927 (1.439 sec)
24.514... logprob:  0.632716, 0.269531 (1.431 sec)
24.515... logprob:  0.684919, 0.276042 (1.427 sec)
24.516... logprob:  0.558436, 0.251302 (1.417 sec)
24.517... logprob:  0.794582, 0.361979 (1.434 sec)
24.518... logprob:  0.626001, 0.256510 (1.456 sec)
24.519... logprob:  0.691282, 0.308594 (1.447 sec)
24.520... logprob:  0.634756, 0.291667 (1.449 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.405379, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.100888e-03 [1.551967e-07] 
Layer 'conv1' biases: 2.104717e-06 [1.009725e-10] 
Layer 'conv2' weights[0]: 3.094852e-03 [1.548465e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.353319e-09] 
Layer 'conv3' weights[0]: 3.093584e-03 [1.553016e-07] 
Layer 'conv3' biases: 3.469236e-05 [9.953433e-09] 
Layer 'conv4' weights[0]: 3.106614e-03 [1.560769e-07] 
Layer 'conv4' biases: 9.999199e-01 [2.443265e-07] 
Layer 'conv5' weights[0]: 3.249292e-03 [2.258029e-06] 
Layer 'conv5' biases: 9.991140e-01 [2.395676e-06] 
Layer 'fc6' weights[0]: 6.882612e-03 [6.091350e-08] 
Layer 'fc6' biases: 9.999905e-01 [5.461448e-08] 
Layer 'fc7' weights[0]: 7.230409e-03 [1.361742e-07] 
Layer 'fc7' biases: 9.997562e-01 [1.628805e-07] 
Layer 'fc8' weights[0]: 4.711918e-03 [1.210406e-05] 
Layer 'fc8' biases: 1.980610e-02 [1.196041e-05] 
Train error last 800 batches: 0.658449
-------------------------------------------------------
Not saving because 0.405379 > 0.299667 (9.300: -1.18%)
======================================================= (2.396 sec)
24.521... logprob:  0.665914, 0.278646 (1.457 sec)
24.522... logprob:  0.768569, 0.343750 (1.458 sec)
24.523... logprob:  0.567143, 0.285156 (1.435 sec)
24.524... logprob:  0.574566, 0.260417 (1.422 sec)
24.525... logprob:  0.666747, 0.279948 (1.428 sec)
24.526... logprob:  0.591880, 0.246094 (1.434 sec)
24.527... logprob:  0.621186, 0.296875 (1.433 sec)
24.528... logprob:  0.670056, 0.298177 (1.463 sec)
24.529... logprob:  0.600728, 0.285156 (1.441 sec)
24.530... logprob:  0.702193, 0.294271 (1.464 sec)
24.531... logprob:  0.725698, 0.333333 (1.478 sec)
24.532... logprob:  0.598107, 0.244792 (1.428 sec)
24.533... logprob:  0.780096, 0.347656 (1.421 sec)
24.534... logprob:  0.589863, 0.274739 (1.436 sec)
24.535... logprob:  0.675633, 0.283854 (1.427 sec)
24.536... logprob:  0.641814, 0.279948 (1.430 sec)
24.537... logprob:  0.622769, 0.270833 (1.476 sec)
24.538... logprob:  0.724535, 0.294271 (1.437 sec)
24.539... logprob:  0.529348, 0.248698 (1.426 sec)
24.540... logprob:  0.604763, 0.277344 (1.488 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.474472, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.097786e-03 [1.548800e-07] 
Layer 'conv1' biases: 2.105468e-06 [8.485731e-11] 
Layer 'conv2' weights[0]: 3.091758e-03 [1.546421e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.327835e-10] 
Layer 'conv3' weights[0]: 3.090499e-03 [1.547883e-07] 
Layer 'conv3' biases: 3.470816e-05 [6.014434e-09] 
Layer 'conv4' weights[0]: 3.103500e-03 [1.555197e-07] 
Layer 'conv4' biases: 9.999205e-01 [1.436664e-07] 
Layer 'conv5' weights[0]: 3.246651e-03 [2.150517e-06] 
Layer 'conv5' biases: 9.991142e-01 [2.307808e-06] 
Layer 'fc6' weights[0]: 6.881924e-03 [5.932876e-08] 
Layer 'fc6' biases: 9.999905e-01 [5.260937e-08] 
Layer 'fc7' weights[0]: 7.229661e-03 [1.323495e-07] 
Layer 'fc7' biases: 9.997560e-01 [1.555248e-07] 
Layer 'fc8' weights[0]: 4.713380e-03 [1.137940e-05] 
Layer 'fc8' biases: 1.983128e-02 [8.806119e-06] 
Train error last 800 batches: 0.658340
-------------------------------------------------------
Not saving because 0.474472 > 0.299667 (9.300: -1.18%)
======================================================= (2.384 sec)
24.541... logprob:  0.599326, 0.253906 (1.433 sec)
24.542... logprob:  0.684087, 0.287760 (1.427 sec)
24.543... logprob:  0.550476, 0.246094 (1.435 sec)
24.544... logprob:  0.540081, 0.253906 (1.427 sec)
24.545... logprob:  0.675036, 0.313802 (1.433 sec)
24.546... logprob:  0.621955, 0.268229 (1.478 sec)
24.547... logprob:  0.550865, 0.229167 (1.429 sec)
24.548... logprob:  0.721211, 0.286458 (1.433 sec)
24.549... logprob:  0.703503, 0.292969 (1.473 sec)
24.550... logprob:  0.655345, 0.333333 (1.429 sec)
24.551... logprob:  0.639883, 0.278646 (1.435 sec)
24.552... logprob:  0.723845, 0.311198 (1.434 sec)
24.553... logprob:  0.503973, 0.216146 (1.424 sec)
24.554... logprob:  0.613161, 0.268229 (1.435 sec)
24.555... logprob:  0.709583, 0.307292 (1.480 sec)
24.556... logprob:  0.639254, 0.291667 (1.436 sec)
24.557... logprob:  0.701924, 0.313802 (1.448 sec)
24.558... logprob:  0.571364, 0.273437 (1.466 sec)
24.559... logprob:  0.715615, 0.312500 (1.431 sec)
24.560... logprob:  0.586840, 0.274740 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.450587, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.094697e-03 [1.547892e-07] 
Layer 'conv1' biases: 2.106058e-06 [7.577330e-11] 
Layer 'conv2' weights[0]: 3.088673e-03 [1.545012e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.377856e-10] 
Layer 'conv3' weights[0]: 3.087394e-03 [1.546269e-07] 
Layer 'conv3' biases: 3.471245e-05 [5.619667e-09] 
Layer 'conv4' weights[0]: 3.100413e-03 [1.554339e-07] 
Layer 'conv4' biases: 9.999208e-01 [1.537817e-07] 
Layer 'conv5' weights[0]: 3.243994e-03 [1.870830e-06] 
Layer 'conv5' biases: 9.991074e-01 [1.974290e-06] 
Layer 'fc6' weights[0]: 6.881217e-03 [5.951202e-08] 
Layer 'fc6' biases: 9.999908e-01 [5.264196e-08] 
Layer 'fc7' weights[0]: 7.228965e-03 [1.339750e-07] 
Layer 'fc7' biases: 9.997570e-01 [1.649308e-07] 
Layer 'fc8' weights[0]: 4.744391e-03 [1.233263e-05] 
Layer 'fc8' biases: 2.000785e-02 [2.328743e-05] 
Train error last 800 batches: 0.658756
-------------------------------------------------------
Not saving because 0.450587 > 0.299667 (9.300: -1.18%)
======================================================= (2.371 sec)
24.561... logprob:  0.705885, 0.278646 (1.433 sec)
24.562... logprob:  0.748921, 0.308594 (1.427 sec)
24.563... logprob:  0.607169, 0.269531 (1.438 sec)
24.564... logprob:  0.719501, 0.317708 (1.457 sec)
24.565... logprob:  0.804143, 0.358073 (1.445 sec)
24.566... logprob:  0.567169, 0.264323 (1.448 sec)
24.567... logprob:  0.623853, 0.264323 (1.457 sec)
24.568... logprob:  0.741545, 0.332031 (1.474 sec)
24.569... logprob:  0.716351, 0.309896 (1.430 sec)
24.570... logprob:  0.756545, 0.303385 (1.422 sec)
24.571... logprob:  0.644710, 0.289062 (1.431 sec)
24.572... logprob:  0.788279, 0.332031 (1.431 sec)
24.573... logprob:  0.747398, 0.317708 (1.440 sec)
24.574... logprob:  0.661996, 0.295573 (1.454 sec)
24.575... logprob:  0.599449, 0.274740 (1.449 sec)
24.576... logprob:  0.616558, 0.264323 (1.434 sec)
24.577... logprob:  0.598613, 0.278646 (1.473 sec)
24.578... logprob:  0.593639, 0.273437 (1.436 sec)
24.579... logprob:  0.653209, 0.286458 (1.428 sec)
24.580... logprob:  0.788271, 0.325521 (1.432 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.484431, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.091594e-03 [1.546053e-07] 
Layer 'conv1' biases: 2.106527e-06 [1.226579e-10] 
Layer 'conv2' weights[0]: 3.085569e-03 [1.543527e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.189742e-09] 
Layer 'conv3' weights[0]: 3.084318e-03 [1.547965e-07] 
Layer 'conv3' biases: 3.472879e-05 [9.045096e-09] 
Layer 'conv4' weights[0]: 3.097301e-03 [1.558019e-07] 
Layer 'conv4' biases: 9.999187e-01 [2.353917e-07] 
Layer 'conv5' weights[0]: 3.239884e-03 [2.442995e-06] 
Layer 'conv5' biases: 9.991539e-01 [2.598124e-06] 
Layer 'fc6' weights[0]: 6.880499e-03 [6.492755e-08] 
Layer 'fc6' biases: 9.999907e-01 [5.897885e-08] 
Layer 'fc7' weights[0]: 7.228242e-03 [1.481178e-07] 
Layer 'fc7' biases: 9.997537e-01 [1.993738e-07] 
Layer 'fc8' weights[0]: 4.648203e-03 [1.442846e-05] 
Layer 'fc8' biases: 1.930615e-02 [3.283357e-05] 
Train error last 800 batches: 0.659261
-------------------------------------------------------
Not saving because 0.484431 > 0.299667 (9.300: -1.18%)
======================================================= (2.410 sec)
24.581... logprob:  0.754051, 0.332031 (1.447 sec)
24.582... logprob:  0.708751, 0.317708 (1.429 sec)
24.583... logprob:  0.714193, 0.322917 (1.473 sec)
24.584... logprob:  0.620173, 0.250000 (1.439 sec)
24.585... logprob:  0.583190, 0.263021 (1.429 sec)
24.586... logprob:  0.510984, 0.227865 (1.486 sec)
24.587... logprob:  0.611043, 0.273437 (1.428 sec)
24.588... logprob:  0.581726, 0.286458 (1.426 sec)
24.589... logprob:  0.581297, 0.270833 (1.441 sec)
24.590... logprob:  0.733073, 0.341146 (1.432 sec)
24.591... logprob:  0.661659, 0.278646 (1.449 sec)
24.592... logprob:  0.693435, 0.311198 (1.482 sec)
24.593... logprob:  0.742554, 0.298177 (1.443 sec)
24.594... logprob:  0.513629, 0.230469 (1.445 sec)
24.595... logprob:  0.625575, 0.256510 (1.491 sec)
24.596... logprob:  0.667570, 0.285156 (1.434 sec)
24.597... logprob:  0.635262, 0.283854 (1.432 sec)
24.598... logprob:  0.587158, 0.269531 (1.433 sec)
24.599... logprob:  0.519323, 0.239583 (1.429 sec)
24.600... logprob:  0.621640, 0.279948 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.481190, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.088497e-03 [1.545960e-07] 
Layer 'conv1' biases: 2.106988e-06 [1.436960e-10] 
Layer 'conv2' weights[0]: 3.082486e-03 [1.542889e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.517009e-09] 
Layer 'conv3' weights[0]: 3.081194e-03 [1.549990e-07] 
Layer 'conv3' biases: 3.473871e-05 [1.158846e-08] 
Layer 'conv4' weights[0]: 3.094216e-03 [1.561523e-07] 
Layer 'conv4' biases: 9.999163e-01 [2.617100e-07] 
Layer 'conv5' weights[0]: 3.235102e-03 [3.298336e-06] 
Layer 'conv5' biases: 9.991360e-01 [3.449141e-06] 
Layer 'fc6' weights[0]: 6.879735e-03 [7.206305e-08] 
Layer 'fc6' biases: 9.999905e-01 [6.811359e-08] 
Layer 'fc7' weights[0]: 7.227552e-03 [1.717955e-07] 
Layer 'fc7' biases: 9.997553e-01 [2.903523e-07] 
Layer 'fc8' weights[0]: 4.711148e-03 [1.728260e-05] 
Layer 'fc8' biases: 1.983115e-02 [5.308930e-05] 
Train error last 800 batches: 0.658952
-------------------------------------------------------
Not saving because 0.481190 > 0.299667 (9.300: -1.18%)
======================================================= (2.345 sec)
24.601... logprob:  0.629447, 0.287760 (1.486 sec)
24.602... logprob:  0.538197, 0.238281 (1.449 sec)
24.603... logprob:  0.525021, 0.247396 (1.451 sec)
24.604... logprob:  0.541974, 0.255208 (1.479 sec)
24.605... logprob:  0.750936, 0.309896 (1.435 sec)
24.606... logprob:  0.527993, 0.251302 (1.478 sec)
24.607... logprob:  0.646410, 0.307292 (1.430 sec)
24.608... logprob:  0.581216, 0.250000 (1.432 sec)
24.609... logprob:  0.543587, 0.277344 (1.447 sec)
24.610... logprob:  0.654762, 0.281250 (1.479 sec)
24.611... logprob:  0.785202, 0.320312 (1.455 sec)
24.612... logprob:  0.645450, 0.264323 (1.463 sec)
24.613... logprob:  0.508614, 0.236979 (1.471 sec)
24.614... logprob:  0.555916, 0.276042 (1.457 sec)
24.615... logprob:  0.534001, 0.252604 (1.447 sec)
24.616... logprob:  0.745518, 0.343750 (1.440 sec)
24.617... logprob:  0.668049, 0.304688 (1.433 sec)
24.618... logprob:  0.686278, 0.292969 (1.447 sec)
24.619... logprob:  0.616573, 0.266927 (1.463 sec)
24.620... logprob:  0.700270, 0.298177 (1.459 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.573364, 0.171875 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.085421e-03 [1.542906e-07] 
Layer 'conv1' biases: 2.107538e-06 [1.042775e-10] 
Layer 'conv2' weights[0]: 3.079409e-03 [1.540202e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.129029e-09] 
Layer 'conv3' weights[0]: 3.078103e-03 [1.543815e-07] 
Layer 'conv3' biases: 3.473392e-05 [8.441615e-09] 
Layer 'conv4' weights[0]: 3.091120e-03 [1.550958e-07] 
Layer 'conv4' biases: 9.999159e-01 [1.849238e-07] 
Layer 'conv5' weights[0]: 3.231881e-03 [2.678369e-06] 
Layer 'conv5' biases: 9.991055e-01 [2.938139e-06] 
Layer 'fc6' weights[0]: 6.879052e-03 [6.505449e-08] 
Layer 'fc6' biases: 9.999905e-01 [6.036823e-08] 
Layer 'fc7' weights[0]: 7.226791e-03 [1.492981e-07] 
Layer 'fc7' biases: 9.997575e-01 [2.175146e-07] 
Layer 'fc8' weights[0]: 4.796354e-03 [1.382166e-05] 
Layer 'fc8' biases: 2.053920e-02 [3.034251e-05] 
Train error last 800 batches: 0.658253
-------------------------------------------------------
Not saving because 0.573364 > 0.299667 (9.300: -1.18%)
======================================================= (2.383 sec)
24.621... logprob:  0.595662, 0.265625 (1.458 sec)
24.622... logprob:  0.608168, 0.315104 (1.459 sec)
24.623... logprob:  0.647822, 0.279948 (1.473 sec)
24.624... logprob:  0.688365, 0.315104 (1.442 sec)
24.625... logprob:  0.609312, 0.269531 (1.424 sec)
24.626... logprob:  0.623256, 0.265625 (1.432 sec)
24.627... logprob:  0.747967, 0.333333 (1.443 sec)
24.628... logprob:  0.674032, 0.303385 (1.447 sec)
24.629... logprob:  0.570078, 0.259115 (1.474 sec)
24.630... logprob:  0.636564, 0.309896 (1.455 sec)
24.631... logprob:  0.762216, 0.287760 (1.440 sec)
24.632... logprob:  0.624623, 0.276042 (1.485 sec)
24.633... logprob:  0.548874, 0.256510 (1.434 sec)
24.634... logprob:  0.851444, 0.354167 (1.420 sec)
24.635... logprob:  0.633007, 0.260417 (1.430 sec)
24.636... logprob:  0.653799, 0.304688 (1.435 sec)
24.637... logprob:  0.577411, 0.236979 (1.425 sec)
24.638... logprob:  0.706154, 0.294271 (1.474 sec)
24.639... logprob:  0.639178, 0.257812 (1.435 sec)
24.640... logprob:  0.727511, 0.300781 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.472306, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.082332e-03 [1.540750e-07] 
Layer 'conv1' biases: 2.108240e-06 [1.118259e-10] 
Layer 'conv2' weights[0]: 3.076337e-03 [1.538455e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.392967e-09] 
Layer 'conv3' weights[0]: 3.075052e-03 [1.545155e-07] 
Layer 'conv3' biases: 3.477519e-05 [1.190455e-08] 
Layer 'conv4' weights[0]: 3.088027e-03 [1.555188e-07] 
Layer 'conv4' biases: 9.999139e-01 [2.951836e-07] 
Layer 'conv5' weights[0]: 3.228100e-03 [3.944984e-06] 
Layer 'conv5' biases: 9.991416e-01 [4.331553e-06] 
Layer 'fc6' weights[0]: 6.878347e-03 [7.624880e-08] 
Layer 'fc6' biases: 9.999903e-01 [7.415584e-08] 
Layer 'fc7' weights[0]: 7.226102e-03 [1.780281e-07] 
Layer 'fc7' biases: 9.997551e-01 [2.877809e-07] 
Layer 'fc8' weights[0]: 4.708827e-03 [1.809568e-05] 
Layer 'fc8' biases: 1.988074e-02 [4.899050e-05] 
Train error last 800 batches: 0.657818
-------------------------------------------------------
Not saving because 0.472306 > 0.299667 (9.300: -1.18%)
======================================================= (2.403 sec)
24.641... logprob:  0.681222, 0.299479 (1.490 sec)
24.642... logprob:  0.733964, 0.356771 (1.431 sec)
24.643... logprob:  0.722906, 0.312500 (1.435 sec)
24.644... logprob:  0.552484, 0.264323 (1.459 sec)
24.645... logprob:  0.657855, 0.291667 (1.423 sec)
24.646... logprob:  0.605296, 0.277344 (1.428 sec)
24.647... logprob:  0.614396, 0.259115 (1.491 sec)
24.648... logprob:  0.662319, 0.292969 (1.433 sec)
24.649... logprob:  0.565221, 0.235677 (1.442 sec)
24.650... logprob:  0.622568, 0.277344 (1.474 sec)
24.651... logprob:  0.704173, 0.311198 (1.426 sec)
24.652... logprob:  0.690124, 0.261719 (1.431 sec)
24.653... logprob:  0.816561, 0.363281 (1.433 sec)
24.654... logprob:  0.716906, 0.312500 (1.422 sec)
24.655... logprob:  0.730818, 0.292969 (1.425 sec)
24.656... logprob:  0.664649, 0.311198 (1.472 sec)
24.657... logprob:  0.716749, 0.320312 (1.433 sec)
24.658... logprob:  0.614769, 0.274740 (1.448 sec)
24.659... logprob:  0.707351, 0.315104 (1.457 sec)
24.660... logprob:  0.650804, 0.285156 (1.439 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.497573, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.079254e-03 [1.540973e-07] 
Layer 'conv1' biases: 2.109127e-06 [1.014035e-10] 
Layer 'conv2' weights[0]: 3.073260e-03 [1.537497e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.047618e-09] 
Layer 'conv3' weights[0]: 3.071983e-03 [1.541574e-07] 
Layer 'conv3' biases: 3.481770e-05 [9.162636e-09] 
Layer 'conv4' weights[0]: 3.084940e-03 [1.549474e-07] 
Layer 'conv4' biases: 9.999137e-01 [2.163063e-07] 
Layer 'conv5' weights[0]: 3.225473e-03 [2.271059e-06] 
Layer 'conv5' biases: 9.991600e-01 [2.348320e-06] 
Layer 'fc6' weights[0]: 6.877662e-03 [6.243343e-08] 
Layer 'fc6' biases: 9.999906e-01 [5.588871e-08] 
Layer 'fc7' weights[0]: 7.225359e-03 [1.399753e-07] 
Layer 'fc7' biases: 9.997529e-01 [1.725208e-07] 
Layer 'fc8' weights[0]: 4.647940e-03 [1.264096e-05] 
Layer 'fc8' biases: 1.938533e-02 [1.386791e-05] 
Train error last 800 batches: 0.657687
-------------------------------------------------------
Not saving because 0.497573 > 0.299667 (9.300: -1.18%)
======================================================= (2.377 sec)
24.661... logprob:  0.611345, 0.283854 (1.442 sec)
24.662... logprob:  0.665768, 0.290365 (1.433 sec)
24.663... logprob:  0.642468, 0.317708 (1.422 sec)
24.664... logprob:  0.545747, 0.264323 (1.434 sec)
24.665... logprob:  0.629638, 0.298177 (1.466 sec)
24.666... logprob:  0.728466, 0.315104 (1.450 sec)
24.667... logprob:  0.808322, 0.332031 (1.447 sec)
24.668... logprob:  0.738832, 0.334635 (1.452 sec)
24.669... logprob:  0.727636, 0.322917 (1.455 sec)
24.670... logprob:  0.615471, 0.277344 (1.430 sec)
24.671... logprob:  0.594317, 0.272135 (1.417 sec)
24.672... logprob:  0.719106, 0.294271 (1.426 sec)
24.673... logprob:  0.648658, 0.290365 (1.431 sec)
24.674... logprob:  0.644357, 0.296875 (1.437 sec)
24.675... logprob:  0.596170, 0.256510 (1.464 sec)
24.676... logprob:  0.699175, 0.302083 (1.448 sec)
24.677... logprob:  0.711831, 0.305990 (1.439 sec)
24.678... logprob:  0.708913, 0.315104 (1.478 sec)
24.679... logprob:  0.690531, 0.317708 (1.432 sec)
24.680... logprob:  0.648068, 0.289062 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.493282, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.076183e-03 [1.537955e-07] 
Layer 'conv1' biases: 2.109905e-06 [6.993088e-11] 
Layer 'conv2' weights[0]: 3.070180e-03 [1.535503e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.789235e-10] 
Layer 'conv3' weights[0]: 3.068893e-03 [1.537530e-07] 
Layer 'conv3' biases: 3.482666e-05 [6.848037e-09] 
Layer 'conv4' weights[0]: 3.081860e-03 [1.545536e-07] 
Layer 'conv4' biases: 9.999118e-01 [1.844929e-07] 
Layer 'conv5' weights[0]: 3.221684e-03 [2.322583e-06] 
Layer 'conv5' biases: 9.991420e-01 [2.502552e-06] 
Layer 'fc6' weights[0]: 6.876970e-03 [6.191842e-08] 
Layer 'fc6' biases: 9.999906e-01 [5.555870e-08] 
Layer 'fc7' weights[0]: 7.224641e-03 [1.420049e-07] 
Layer 'fc7' biases: 9.997538e-01 [1.803192e-07] 
Layer 'fc8' weights[0]: 4.682052e-03 [1.345568e-05] 
Layer 'fc8' biases: 1.960655e-02 [2.429245e-05] 
Train error last 800 batches: 0.658298
-------------------------------------------------------
Not saving because 0.493282 > 0.299667 (9.300: -1.18%)
======================================================= (2.357 sec)
24.681... logprob:  0.558968, 0.264323 (1.441 sec)
24.682... logprob:  0.563958, 0.246094 (1.463 sec)
24.683... logprob:  0.637298, 0.285156 (1.433 sec)
24.684... logprob:  0.595731, 0.273438 (1.477 sec)
24.685... logprob:  0.557831, 0.231771 (1.437 sec)
24.686... logprob:  0.595980, 0.261719 (1.429 sec)
24.687... logprob:  0.628945, 0.316406 (1.483 sec)
24.688... logprob:  0.627513, 0.266927 (1.429 sec)
24.689... logprob:  0.635179, 0.290364 (1.422 sec)
24.690... logprob:  0.729711, 0.307292 (1.434 sec)
24.691... logprob:  0.667185, 0.290365 (1.428 sec)
24.692... logprob:  0.609234, 0.238281 (1.426 sec)
24.693... logprob:  0.646127, 0.302083 (1.479 sec)
24.694... logprob:  0.583383, 0.256510 (1.428 sec)
24.695... logprob:  0.542334, 0.250000 (1.433 sec)
24.696... logprob:  0.702789, 0.289062 (1.476 sec)
24.697... logprob:  0.706837, 0.324219 (1.426 sec)
24.698... logprob:  0.655514, 0.282552 (1.425 sec)
24.699... logprob:  0.687369, 0.303385 (1.431 sec)
24.700... logprob:  0.684710, 0.311198 (1.424 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.499863, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.073095e-03 [1.536819e-07] 
Layer 'conv1' biases: 2.110484e-06 [1.034393e-10] 
Layer 'conv2' weights[0]: 3.067115e-03 [1.534292e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.398350e-09] 
Layer 'conv3' weights[0]: 3.065842e-03 [1.539800e-07] 
Layer 'conv3' biases: 3.484506e-05 [1.060622e-08] 
Layer 'conv4' weights[0]: 3.078790e-03 [1.550157e-07] 
Layer 'conv4' biases: 9.999104e-01 [2.785756e-07] 
Layer 'conv5' weights[0]: 3.218068e-03 [2.552043e-06] 
Layer 'conv5' biases: 9.991148e-01 [2.763747e-06] 
Layer 'fc6' weights[0]: 6.876253e-03 [6.482011e-08] 
Layer 'fc6' biases: 9.999906e-01 [5.969806e-08] 
Layer 'fc7' weights[0]: 7.223922e-03 [1.473167e-07] 
Layer 'fc7' biases: 9.997551e-01 [1.992472e-07] 
Layer 'fc8' weights[0]: 4.738656e-03 [1.354546e-05] 
Layer 'fc8' biases: 2.011541e-02 [2.540924e-05] 
Train error last 800 batches: 0.658268
-------------------------------------------------------
Not saving because 0.499863 > 0.299667 (9.300: -1.18%)
======================================================= (2.417 sec)
24.701... logprob:  0.686869, 0.299479 (1.437 sec)
24.702... logprob:  0.786288, 0.308594 (1.481 sec)
24.703... logprob:  0.685136, 0.296875 (1.435 sec)
24.704... logprob:  0.673325, 0.315104 (1.448 sec)
24.705... logprob:  0.638747, 0.294271 (1.465 sec)
24.706... logprob:  0.747051, 0.316406 (1.430 sec)
24.707... logprob:  0.686278, 0.291667 (1.433 sec)
24.708... logprob:  0.653699, 0.302083 (1.432 sec)
24.709... logprob:  0.589960, 0.272135 (1.413 sec)
24.710... logprob:  0.745774, 0.319010 (1.431 sec)
24.711... logprob:  0.677890, 0.299479 (1.463 sec)
24.712... logprob:  0.579194, 0.248698 (1.439 sec)
24.713... logprob:  0.762466, 0.345052 (1.447 sec)
24.714... logprob:  0.707002, 0.315104 (1.452 sec)
24.715... logprob:  0.605821, 0.256510 (1.446 sec)
24.716... logprob:  0.575065, 0.261719 (1.435 sec)
24.717... logprob:  0.618966, 0.247396 (1.426 sec)
24.718... logprob:  0.749451, 0.325521 (1.420 sec)
24.719... logprob:  0.654631, 0.299479 (1.437 sec)
24.720... logprob:  0.625485, 0.289063 (1.444 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.507157, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.070032e-03 [1.536396e-07] 
Layer 'conv1' biases: 2.110862e-06 [1.292476e-10] 
Layer 'conv2' weights[0]: 3.064048e-03 [1.533499e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.300250e-09] 
Layer 'conv3' weights[0]: 3.062757e-03 [1.538849e-07] 
Layer 'conv3' biases: 3.486317e-05 [1.105060e-08] 
Layer 'conv4' weights[0]: 3.075685e-03 [1.549754e-07] 
Layer 'conv4' biases: 9.999115e-01 [2.467093e-07] 
Layer 'conv5' weights[0]: 3.215867e-03 [2.637562e-06] 
Layer 'conv5' biases: 9.991402e-01 [2.855133e-06] 
Layer 'fc6' weights[0]: 6.875545e-03 [6.362867e-08] 
Layer 'fc6' biases: 9.999906e-01 [5.778505e-08] 
Layer 'fc7' weights[0]: 7.223177e-03 [1.459442e-07] 
Layer 'fc7' biases: 9.997523e-01 [2.031437e-07] 
Layer 'fc8' weights[0]: 4.662806e-03 [1.520911e-05] 
Layer 'fc8' biases: 1.959977e-02 [4.082490e-05] 
Train error last 800 batches: 0.658586
-------------------------------------------------------
Not saving because 0.507157 > 0.299667 (9.300: -1.18%)
======================================================= (2.367 sec)
24.721... logprob:  0.632415, 0.260417 (1.459 sec)
24.722... logprob:  0.674795, 0.296875 (1.460 sec)
24.723... logprob:  0.676393, 0.290365 (1.441 sec)
24.724... logprob:  0.633489, 0.277344 (1.463 sec)
24.725... logprob:  0.727546, 0.307292 (1.430 sec)
24.726... logprob:  0.642843, 0.304687 (1.424 sec)
24.727... logprob:  0.560452, 0.252604 (1.427 sec)
24.728... logprob:  0.722848, 0.315104 (1.436 sec)
24.729... logprob:  0.670297, 0.289063 (1.431 sec)
24.730... logprob:  0.755355, 0.312500 (1.474 sec)
24.731... logprob:  0.615544, 0.278646 (1.446 sec)
24.732... logprob:  0.538012, 0.234375 (1.435 sec)
24.733... logprob:  0.772688, 0.356771 (1.480 sec)
24.734... logprob:  0.576549, 0.276042 (1.424 sec)
24.735... logprob:  0.679172, 0.282552 (1.423 sec)
24.736... logprob:  0.781604, 0.333333 (1.431 sec)
24.737... logprob:  0.713897, 0.311198 (1.422 sec)
24.738... logprob:  0.701673, 0.309896 (1.428 sec)
24.739... logprob:  0.737022, 0.308594 (1.474 sec)
24.740... logprob:  0.589602, 0.276042 (1.436 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.420503, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.066961e-03 [1.534562e-07] 
Layer 'conv1' biases: 2.111397e-06 [8.430746e-11] 
Layer 'conv2' weights[0]: 3.060987e-03 [1.531599e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.064137e-09] 
Layer 'conv3' weights[0]: 3.059716e-03 [1.534077e-07] 
Layer 'conv3' biases: 3.486924e-05 [8.394097e-09] 
Layer 'conv4' weights[0]: 3.072634e-03 [1.541979e-07] 
Layer 'conv4' biases: 9.999113e-01 [1.995269e-07] 
Layer 'conv5' weights[0]: 3.213008e-03 [2.136664e-06] 
Layer 'conv5' biases: 9.991351e-01 [2.265333e-06] 
Layer 'fc6' weights[0]: 6.874822e-03 [6.165786e-08] 
Layer 'fc6' biases: 9.999905e-01 [5.539820e-08] 
Layer 'fc7' weights[0]: 7.222417e-03 [1.427260e-07] 
Layer 'fc7' biases: 9.997524e-01 [1.836473e-07] 
Layer 'fc8' weights[0]: 4.667830e-03 [1.390250e-05] 
Layer 'fc8' biases: 1.964256e-02 [2.259283e-05] 
Train error last 800 batches: 0.658644
-------------------------------------------------------
Not saving because 0.420503 > 0.299667 (9.300: -1.18%)
======================================================= (2.359 sec)
24.741... logprob:  0.646086, 0.270833 (1.439 sec)
24.742... logprob:  0.709508, 0.307292 (1.482 sec)
24.743... logprob:  0.559673, 0.243490 (1.427 sec)
24.744... logprob:  0.664244, 0.278646 (1.429 sec)
24.745... logprob:  0.685487, 0.290365 (1.436 sec)
24.746... logprob:  0.682649, 0.304688 (1.422 sec)
24.747... logprob:  0.676542, 0.278646 (1.428 sec)
24.748... logprob:  0.521279, 0.229167 (1.487 sec)
24.749... logprob:  0.673561, 0.308594 (1.428 sec)
24.750... logprob:  0.718381, 0.292969 (1.438 sec)
24.751... logprob:  0.474340, 0.209635 (1.472 sec)
24.752... logprob:  0.669219, 0.281250 (1.433 sec)
24.753... logprob:  0.603707, 0.238281 (1.429 sec)
24.754... logprob:  0.666114, 0.290364 (1.429 sec)
24.755... logprob:  0.711032, 0.312500 (1.418 sec)
24.756... logprob:  0.646212, 0.289062 (1.426 sec)
24.757... logprob:  0.734430, 0.348958 (1.469 sec)
24.758... logprob:  0.595845, 0.276042 (1.439 sec)
24.759... logprob:  0.548797, 0.256510 (1.445 sec)
24.760... logprob:  0.709617, 0.309896 (1.472 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.443918, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.063903e-03 [1.533578e-07] 
Layer 'conv1' biases: 2.111725e-06 [7.775423e-11] 
Layer 'conv2' weights[0]: 3.057926e-03 [1.530179e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.040540e-09] 
Layer 'conv3' weights[0]: 3.056680e-03 [1.531676e-07] 
Layer 'conv3' biases: 3.487367e-05 [7.205619e-09] 
Layer 'conv4' weights[0]: 3.069572e-03 [1.540013e-07] 
Layer 'conv4' biases: 9.999127e-01 [1.786766e-07] 
Layer 'conv5' weights[0]: 3.210896e-03 [2.300715e-06] 
Layer 'conv5' biases: 9.991224e-01 [2.479950e-06] 
Layer 'fc6' weights[0]: 6.874083e-03 [5.820119e-08] 
Layer 'fc6' biases: 9.999904e-01 [5.070617e-08] 
Layer 'fc7' weights[0]: 7.221668e-03 [1.335670e-07] 
Layer 'fc7' biases: 9.997528e-01 [1.567669e-07] 
Layer 'fc8' weights[0]: 4.683850e-03 [1.162007e-05] 
Layer 'fc8' biases: 1.980451e-02 [1.427493e-05] 
Train error last 800 batches: 0.658135
-------------------------------------------------------
Not saving because 0.443918 > 0.299667 (9.300: -1.18%)
======================================================= (2.414 sec)
24.761... logprob:  0.718894, 0.326823 (1.448 sec)
24.762... logprob:  0.716559, 0.294271 (1.441 sec)
24.763... logprob:  0.784068, 0.339844 (1.428 sec)
24.764... logprob:  0.634610, 0.272135 (1.423 sec)
24.765... logprob:  0.516973, 0.247396 (1.510 sec)
24.766... logprob:  0.654847, 0.296875 (1.454 sec)
24.767... logprob:  0.579990, 0.253906 (1.449 sec)
24.768... logprob:  0.667835, 0.319010 (1.460 sec)
24.769... logprob:  0.657009, 0.290365 (1.467 sec)
24.770... logprob:  0.601888, 0.277344 (1.475 sec)
24.771... logprob:  0.690116, 0.290365 (1.447 sec)
24.772... logprob:  0.627204, 0.285156 (1.441 sec)
24.773... logprob:  0.807530, 0.364583 (1.441 sec)
24.774... logprob:  0.616772, 0.265625 (1.453 sec)
24.775... logprob:  0.647237, 0.299479 (1.456 sec)
24.776... logprob:  0.660569, 0.295573 (1.472 sec)
24.777... logprob:  0.577900, 0.256510 (1.467 sec)
24.778... logprob:  0.675372, 0.309896 (1.464 sec)
24.779... logprob:  0.774414, 0.354167 (1.483 sec)
24.780... logprob:  0.637123, 0.269531 (1.457 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.456931, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.060843e-03 [1.531130e-07] 
Layer 'conv1' biases: 2.112171e-06 [6.567180e-11] 
Layer 'conv2' weights[0]: 3.054873e-03 [1.528016e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.530612e-10] 
Layer 'conv3' weights[0]: 3.053579e-03 [1.529923e-07] 
Layer 'conv3' biases: 3.487401e-05 [6.287206e-09] 
Layer 'conv4' weights[0]: 3.066495e-03 [1.538150e-07] 
Layer 'conv4' biases: 9.999132e-01 [1.585484e-07] 
Layer 'conv5' weights[0]: 3.208607e-03 [2.096779e-06] 
Layer 'conv5' biases: 9.991248e-01 [2.194086e-06] 
Layer 'fc6' weights[0]: 6.873378e-03 [5.888490e-08] 
Layer 'fc6' biases: 9.999904e-01 [5.168691e-08] 
Layer 'fc7' weights[0]: 7.220970e-03 [1.338024e-07] 
Layer 'fc7' biases: 9.997522e-01 [1.566806e-07] 
Layer 'fc8' weights[0]: 4.688915e-03 [1.171911e-05] 
Layer 'fc8' biases: 1.983152e-02 [1.109186e-05] 
Train error last 800 batches: 0.657663
-------------------------------------------------------
Not saving because 0.456931 > 0.299667 (9.300: -1.18%)
======================================================= (2.379 sec)
24.781... logprob:  0.499636, 0.234375 (1.445 sec)
24.782... logprob:  0.566847, 0.272135 (1.451 sec)
24.783... logprob:  0.795938, 0.290365 (1.456 sec)
24.784... logprob:  0.669682, 0.283854 (1.450 sec)
24.785... logprob:  0.796487, 0.324219 (1.491 sec)
24.786... logprob:  0.681943, 0.287760 (1.467 sec)
24.787... logprob:  0.700098, 0.313802 (1.456 sec)
24.788... logprob:  0.771771, 0.311198 (1.493 sec)
24.789... logprob:  0.576714, 0.272135 (1.450 sec)
24.790... logprob:  0.618711, 0.283854 (1.444 sec)
24.791... logprob:  0.639139, 0.283854 (1.441 sec)
24.792... logprob:  0.565666, 0.257812 (1.457 sec)
24.793... logprob:  0.625233, 0.259115 (1.442 sec)
24.794... logprob:  0.669983, 0.286458 (1.488 sec)
24.795... logprob:  0.646098, 0.283854 (1.467 sec)
24.796... logprob:  0.699443, 0.292969 (1.468 sec)
24.797... logprob:  0.644487, 0.287760 (1.522 sec)
24.798... logprob:  0.683186, 0.298177 (1.444 sec)
24.799... logprob:  0.608875, 0.253906 (1.444 sec)
24.800... logprob:  0.544238, 0.246094 (1.401 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.568141, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.057769e-03 [1.531097e-07] 
Layer 'conv1' biases: 2.112542e-06 [8.197097e-11] 
Layer 'conv2' weights[0]: 3.051804e-03 [1.527630e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.612650e-10] 
Layer 'conv3' weights[0]: 3.050536e-03 [1.529591e-07] 
Layer 'conv3' biases: 3.488245e-05 [7.150976e-09] 
Layer 'conv4' weights[0]: 3.063422e-03 [1.540135e-07] 
Layer 'conv4' biases: 9.999139e-01 [1.984520e-07] 
Layer 'conv5' weights[0]: 3.206236e-03 [2.831223e-06] 
Layer 'conv5' biases: 9.991248e-01 [3.088856e-06] 
Layer 'fc6' weights[0]: 6.872644e-03 [6.663075e-08] 
Layer 'fc6' biases: 9.999906e-01 [6.155481e-08] 
Layer 'fc7' weights[0]: 7.220233e-03 [1.561633e-07] 
Layer 'fc7' biases: 9.997513e-01 [2.356556e-07] 
Layer 'fc8' weights[0]: 4.674947e-03 [1.506017e-05] 
Layer 'fc8' biases: 1.976135e-02 [3.540439e-05] 
Train error last 800 batches: 0.657515
-------------------------------------------------------
Not saving because 0.568141 > 0.299667 (9.300: -1.18%)
======================================================= (2.351 sec)
25.1... logprob:  0.629801, 0.285156 (1.405 sec)
25.2... logprob:  0.657099, 0.286458 (1.449 sec)
25.3... logprob:  0.599956, 0.260417 (1.420 sec)
25.4... logprob:  0.644577, 0.285156 (1.399 sec)
25.5... logprob:  0.672431, 0.276042 (1.425 sec)
25.6... logprob:  0.595792, 0.274740 (1.391 sec)
25.7... logprob:  0.658637, 0.294271 (1.420 sec)
25.8... logprob:  0.552914, 0.243490 (1.390 sec)
25.9... logprob:  0.572159, 0.260417 (1.407 sec)
25.10... logprob:  0.586291, 0.277344 (1.404 sec)
25.11... logprob:  0.589496, 0.263021 (1.445 sec)
25.12... logprob:  0.642930, 0.295573 (1.394 sec)
25.13... logprob:  0.728868, 0.298177 (1.417 sec)
25.14... logprob:  0.688291, 0.320312 (1.398 sec)
25.15... logprob:  0.689115, 0.329427 (1.402 sec)
25.16... logprob:  0.693862, 0.287760 (1.403 sec)
25.17... logprob:  0.731831, 0.337240 (1.388 sec)
25.18... logprob:  0.567478, 0.260417 (1.394 sec)
25.19... logprob:  0.546057, 0.251302 (1.395 sec)
25.20... logprob:  0.741138, 0.326823 (1.395 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.509868, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.054718e-03 [1.528645e-07] 
Layer 'conv1' biases: 2.113208e-06 [1.143641e-10] 
Layer 'conv2' weights[0]: 3.048764e-03 [1.526025e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.433686e-09] 
Layer 'conv3' weights[0]: 3.047498e-03 [1.531983e-07] 
Layer 'conv3' biases: 3.488989e-05 [1.122117e-08] 
Layer 'conv4' weights[0]: 3.060365e-03 [1.542038e-07] 
Layer 'conv4' biases: 9.999112e-01 [2.710257e-07] 
Layer 'conv5' weights[0]: 3.201929e-03 [2.085208e-06] 
Layer 'conv5' biases: 9.990968e-01 [2.322235e-06] 
Layer 'fc6' weights[0]: 6.871926e-03 [5.750078e-08] 
Layer 'fc6' biases: 9.999903e-01 [5.028432e-08] 
Layer 'fc7' weights[0]: 7.219492e-03 [1.317589e-07] 
Layer 'fc7' biases: 9.997540e-01 [1.568453e-07] 
Layer 'fc8' weights[0]: 4.751932e-03 [1.137253e-05] 
Layer 'fc8' biases: 2.036250e-02 [9.430295e-06] 
Train error last 800 batches: 0.657996
-------------------------------------------------------
Not saving because 0.509868 > 0.299667 (9.300: -1.18%)
======================================================= (2.380 sec)
25.21... logprob:  0.743017, 0.319010 (1.400 sec)
25.22... logprob:  0.724942, 0.313802 (1.415 sec)
25.23... logprob:  0.730723, 0.273437 (1.413 sec)
25.24... logprob:  0.525134, 0.226562 (1.410 sec)
25.25... logprob:  0.600729, 0.282552 (1.397 sec)
25.26... logprob:  0.662967, 0.270833 (1.437 sec)
25.27... logprob:  0.643323, 0.286458 (1.387 sec)
25.28... logprob:  0.631758, 0.281250 (1.409 sec)
25.29... logprob:  0.674125, 0.269531 (1.419 sec)
25.30... logprob:  0.567806, 0.259115 (1.418 sec)
25.31... logprob:  0.688080, 0.268229 (1.404 sec)
25.32... logprob:  0.662945, 0.290365 (1.387 sec)
25.33... logprob:  0.681125, 0.294271 (1.441 sec)
25.34... logprob:  0.722570, 0.309896 (1.386 sec)
25.35... logprob:  0.608201, 0.255208 (1.395 sec)
25.36... logprob:  0.737441, 0.342448 (1.413 sec)
25.37... logprob:  0.718674, 0.305989 (1.400 sec)
25.38... logprob:  0.645173, 0.309896 (1.389 sec)
25.39... logprob:  0.787616, 0.311198 (1.427 sec)
25.40... logprob:  0.670242, 0.298177 (1.405 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.462144, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.051662e-03 [1.526139e-07] 
Layer 'conv1' biases: 2.113929e-06 [1.444734e-10] 
Layer 'conv2' weights[0]: 3.045717e-03 [1.523456e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.540406e-09] 
Layer 'conv3' weights[0]: 3.044435e-03 [1.529519e-07] 
Layer 'conv3' biases: 3.490642e-05 [1.162831e-08] 
Layer 'conv4' weights[0]: 3.057309e-03 [1.539808e-07] 
Layer 'conv4' biases: 9.999104e-01 [2.952435e-07] 
Layer 'conv5' weights[0]: 3.198507e-03 [3.421722e-06] 
Layer 'conv5' biases: 9.991341e-01 [3.757405e-06] 
Layer 'fc6' weights[0]: 6.871185e-03 [7.710956e-08] 
Layer 'fc6' biases: 9.999905e-01 [7.544837e-08] 
Layer 'fc7' weights[0]: 7.218759e-03 [1.850589e-07] 
Layer 'fc7' biases: 9.997507e-01 [3.105174e-07] 
Layer 'fc8' weights[0]: 4.658441e-03 [1.840355e-05] 
Layer 'fc8' biases: 1.965281e-02 [5.180943e-05] 
Train error last 800 batches: 0.657922
-------------------------------------------------------
Not saving because 0.462144 > 0.299667 (9.300: -1.18%)
======================================================= (2.345 sec)
25.41... logprob:  0.592333, 0.268229 (1.429 sec)
25.42... logprob:  0.589395, 0.268229 (1.414 sec)
25.43... logprob:  0.647329, 0.283854 (1.399 sec)
25.44... logprob:  0.706283, 0.300781 (1.431 sec)
25.45... logprob:  0.565718, 0.238281 (1.382 sec)
25.46... logprob:  0.671519, 0.298177 (1.403 sec)
25.47... logprob:  0.519266, 0.222656 (1.395 sec)
25.48... logprob:  0.662976, 0.269531 (1.422 sec)
25.49... logprob:  0.648009, 0.270833 (1.411 sec)
25.50... logprob:  0.673853, 0.270833 (1.422 sec)
25.51... logprob:  0.665703, 0.291667 (1.410 sec)
25.52... logprob:  0.768480, 0.326823 (1.393 sec)
25.53... logprob:  0.530016, 0.225260 (1.438 sec)
25.54... logprob:  0.670104, 0.294271 (1.380 sec)
25.55... logprob:  0.530607, 0.257812 (1.394 sec)
25.56... logprob:  0.608854, 0.222656 (1.394 sec)
25.57... logprob:  0.746713, 0.312500 (1.426 sec)
25.58... logprob:  0.588836, 0.282552 (1.400 sec)
25.59... logprob:  0.583756, 0.281250 (1.456 sec)
25.60... logprob:  0.820942, 0.324219 (1.414 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.445844, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.048627e-03 [1.525284e-07] 
Layer 'conv1' biases: 2.114224e-06 [9.110520e-11] 
Layer 'conv2' weights[0]: 3.042682e-03 [1.522557e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.219352e-10] 
Layer 'conv3' weights[0]: 3.041408e-03 [1.524746e-07] 
Layer 'conv3' biases: 3.490546e-05 [7.397386e-09] 
Layer 'conv4' weights[0]: 3.054251e-03 [1.534239e-07] 
Layer 'conv4' biases: 9.999108e-01 [1.684625e-07] 
Layer 'conv5' weights[0]: 3.196226e-03 [2.299337e-06] 
Layer 'conv5' biases: 9.991258e-01 [2.510668e-06] 
Layer 'fc6' weights[0]: 6.870508e-03 [6.075573e-08] 
Layer 'fc6' biases: 9.999906e-01 [5.408465e-08] 
Layer 'fc7' weights[0]: 7.218017e-03 [1.395298e-07] 
Layer 'fc7' biases: 9.997510e-01 [1.638271e-07] 
Layer 'fc8' weights[0]: 4.682206e-03 [1.222466e-05] 
Layer 'fc8' biases: 1.984326e-02 [1.443626e-05] 
Train error last 800 batches: 0.657553
-------------------------------------------------------
Not saving because 0.445844 > 0.299667 (9.300: -1.18%)
======================================================= (2.378 sec)
25.61... logprob:  0.604511, 0.266927 (1.431 sec)
25.62... logprob:  0.694760, 0.281250 (1.459 sec)
25.63... logprob:  0.600965, 0.243489 (1.441 sec)
25.64... logprob:  0.607631, 0.272135 (1.408 sec)
25.65... logprob:  0.702253, 0.308594 (1.393 sec)
25.66... logprob:  0.569482, 0.260417 (1.440 sec)
25.67... logprob:  0.607982, 0.291667 (1.390 sec)
25.68... logprob:  0.594854, 0.257812 (1.393 sec)
25.69... logprob:  0.612053, 0.282552 (1.424 sec)
25.70... logprob:  0.571031, 0.268229 (1.416 sec)
25.71... logprob:  0.539466, 0.259115 (1.456 sec)
25.72... logprob:  0.666825, 0.296875 (1.396 sec)
25.73... logprob:  0.612717, 0.259115 (1.430 sec)
25.74... logprob:  0.703055, 0.292969 (1.418 sec)
25.75... logprob:  0.605658, 0.285156 (1.434 sec)
25.76... logprob:  0.749688, 0.317708 (1.433 sec)
25.77... logprob:  0.636505, 0.290365 (1.428 sec)
25.78... logprob:  0.680162, 0.305990 (1.459 sec)
25.79... logprob:  0.718264, 0.295573 (1.399 sec)
25.80... logprob:  0.677544, 0.279948 (1.418 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.462693, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.045580e-03 [1.522852e-07] 
Layer 'conv1' biases: 2.114519e-06 [8.379241e-11] 
Layer 'conv2' weights[0]: 3.039631e-03 [1.520616e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.368756e-10] 
Layer 'conv3' weights[0]: 3.038359e-03 [1.523194e-07] 
Layer 'conv3' biases: 3.492566e-05 [6.942613e-09] 
Layer 'conv4' weights[0]: 3.051174e-03 [1.532715e-07] 
Layer 'conv4' biases: 9.999089e-01 [1.921888e-07] 
Layer 'conv5' weights[0]: 3.192025e-03 [2.768052e-06] 
Layer 'conv5' biases: 9.991037e-01 [2.933829e-06] 
Layer 'fc6' weights[0]: 6.869778e-03 [6.544539e-08] 
Layer 'fc6' biases: 9.999906e-01 [6.097197e-08] 
Layer 'fc7' weights[0]: 7.217300e-03 [1.511385e-07] 
Layer 'fc7' biases: 9.997526e-01 [2.062594e-07] 
Layer 'fc8' weights[0]: 4.732187e-03 [1.370062e-05] 
Layer 'fc8' biases: 2.025597e-02 [2.363698e-05] 
Train error last 800 batches: 0.657163
-------------------------------------------------------
Not saving because 0.462693 > 0.299667 (9.300: -1.18%)
======================================================= (2.402 sec)
25.81... logprob:  0.540707, 0.239583 (1.422 sec)
25.82... logprob:  0.598637, 0.294271 (1.420 sec)
25.83... logprob:  0.699716, 0.313802 (1.403 sec)
25.84... logprob:  0.700559, 0.305990 (1.458 sec)
25.85... logprob:  0.645175, 0.278646 (1.416 sec)
25.86... logprob:  0.656406, 0.308594 (1.415 sec)
25.87... logprob:  0.871986, 0.346354 (1.414 sec)
25.88... logprob:  0.718752, 0.298177 (1.403 sec)
25.89... logprob:  0.730543, 0.321614 (1.425 sec)
25.90... logprob:  0.798707, 0.338542 (1.385 sec)
25.91... logprob:  0.578099, 0.240885 (1.395 sec)
25.92... logprob:  0.705853, 0.322917 (1.396 sec)
25.93... logprob:  0.742212, 0.330729 (1.395 sec)
25.94... logprob:  0.722908, 0.309896 (1.385 sec)
25.95... logprob:  0.665842, 0.277344 (1.395 sec)
25.96... logprob:  0.831177, 0.359375 (1.397 sec)
25.97... logprob:  0.588860, 0.250000 (1.391 sec)
25.98... logprob:  0.609504, 0.263021 (1.430 sec)
25.99... logprob:  0.669262, 0.308594 (1.403 sec)
25.100... logprob:  0.553337, 0.252604 (1.394 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.419429, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.042529e-03 [1.521562e-07] 
Layer 'conv1' biases: 2.115332e-06 [7.900627e-11] 
Layer 'conv2' weights[0]: 3.036581e-03 [1.518665e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.439555e-10] 
Layer 'conv3' weights[0]: 3.035333e-03 [1.520474e-07] 
Layer 'conv3' biases: 3.495669e-05 [6.955679e-09] 
Layer 'conv4' weights[0]: 3.048123e-03 [1.528571e-07] 
Layer 'conv4' biases: 9.999080e-01 [1.849538e-07] 
Layer 'conv5' weights[0]: 3.188773e-03 [2.147201e-06] 
Layer 'conv5' biases: 9.991474e-01 [2.411273e-06] 
Layer 'fc6' weights[0]: 6.869101e-03 [6.014315e-08] 
Layer 'fc6' biases: 9.999906e-01 [5.321186e-08] 
Layer 'fc7' weights[0]: 7.216620e-03 [1.355424e-07] 
Layer 'fc7' biases: 9.997488e-01 [1.671733e-07] 
Layer 'fc8' weights[0]: 4.619020e-03 [1.167585e-05] 
Layer 'fc8' biases: 1.940982e-02 [1.026412e-05] 
Train error last 800 batches: 0.657586
-------------------------------------------------------
Not saving because 0.419429 > 0.299667 (9.300: -1.18%)
======================================================= (2.378 sec)
25.101... logprob:  0.572306, 0.253906 (1.450 sec)
25.102... logprob:  0.653632, 0.279948 (1.389 sec)
25.103... logprob:  0.764880, 0.325521 (1.391 sec)
25.104... logprob:  0.583778, 0.278646 (1.397 sec)
25.105... logprob:  0.817431, 0.328125 (1.385 sec)
25.106... logprob:  0.648227, 0.307292 (1.390 sec)
25.107... logprob:  0.606879, 0.257812 (1.439 sec)
25.108... logprob:  0.693714, 0.302083 (1.395 sec)
25.109... logprob:  0.618495, 0.285156 (1.396 sec)
25.110... logprob:  0.696961, 0.294271 (1.388 sec)
25.111... logprob:  0.508067, 0.209635 (1.389 sec)
25.112... logprob:  0.644026, 0.286458 (1.392 sec)
25.113... logprob:  0.620990, 0.273437 (1.397 sec)
25.114... logprob:  0.747240, 0.334635 (1.456 sec)
25.115... logprob:  0.680975, 0.319010 (1.404 sec)
25.116... logprob:  0.647185, 0.312500 (1.394 sec)
25.117... logprob:  0.633840, 0.266927 (1.437 sec)
25.118... logprob:  0.639850, 0.268229 (1.393 sec)
25.119... logprob:  0.605065, 0.248698 (1.387 sec)
25.120... logprob:  0.767899, 0.321615 (1.398 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.511285, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.039481e-03 [1.520814e-07] 
Layer 'conv1' biases: 2.115644e-06 [8.070783e-11] 
Layer 'conv2' weights[0]: 3.033568e-03 [1.517864e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.047743e-09] 
Layer 'conv3' weights[0]: 3.032287e-03 [1.520449e-07] 
Layer 'conv3' biases: 3.499309e-05 [7.653828e-09] 
Layer 'conv4' weights[0]: 3.045107e-03 [1.528384e-07] 
Layer 'conv4' biases: 9.999067e-01 [1.881839e-07] 
Layer 'conv5' weights[0]: 3.185050e-03 [2.081900e-06] 
Layer 'conv5' biases: 9.991349e-01 [2.217771e-06] 
Layer 'fc6' weights[0]: 6.868358e-03 [6.272188e-08] 
Layer 'fc6' biases: 9.999908e-01 [5.655705e-08] 
Layer 'fc7' weights[0]: 7.215911e-03 [1.427499e-07] 
Layer 'fc7' biases: 9.997502e-01 [1.743209e-07] 
Layer 'fc8' weights[0]: 4.673537e-03 [1.253461e-05] 
Layer 'fc8' biases: 1.986297e-02 [1.834271e-05] 
Train error last 800 batches: 0.657749
-------------------------------------------------------
Not saving because 0.511285 > 0.299667 (9.300: -1.18%)
======================================================= (2.363 sec)
25.121... logprob:  0.666915, 0.286458 (1.401 sec)
25.122... logprob:  0.601013, 0.259115 (1.445 sec)
25.123... logprob:  0.661894, 0.266927 (1.378 sec)
25.124... logprob:  0.645051, 0.308594 (1.405 sec)
25.125... logprob:  0.705821, 0.328125 (1.396 sec)
25.126... logprob:  0.715556, 0.298177 (1.387 sec)
25.127... logprob:  0.659313, 0.291667 (1.390 sec)
25.128... logprob:  0.722768, 0.311198 (1.413 sec)
25.129... logprob:  0.728733, 0.300781 (1.409 sec)
25.130... logprob:  0.574115, 0.251302 (1.406 sec)
25.131... logprob:  0.698508, 0.317708 (1.406 sec)
25.132... logprob:  0.727913, 0.337240 (1.430 sec)
25.133... logprob:  0.757960, 0.320312 (1.388 sec)
25.134... logprob:  0.626267, 0.272135 (1.392 sec)
25.135... logprob:  0.689215, 0.278646 (1.400 sec)
25.136... logprob:  0.776351, 0.329427 (1.393 sec)
25.137... logprob:  0.687500, 0.296875 (1.397 sec)
25.138... logprob:  0.531164, 0.234375 (1.436 sec)
25.139... logprob:  0.694565, 0.285156 (1.398 sec)
25.140... logprob:  0.767233, 0.352865 (1.408 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.372584, 0.062500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.036456e-03 [1.518872e-07] 
Layer 'conv1' biases: 2.115375e-06 [9.701704e-11] 
Layer 'conv2' weights[0]: 3.030529e-03 [1.515983e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.364079e-09] 
Layer 'conv3' weights[0]: 3.029261e-03 [1.520542e-07] 
Layer 'conv3' biases: 3.500542e-05 [9.642373e-09] 
Layer 'conv4' weights[0]: 3.042061e-03 [1.530600e-07] 
Layer 'conv4' biases: 9.999088e-01 [2.651817e-07] 
Layer 'conv5' weights[0]: 3.183691e-03 [2.781980e-06] 
Layer 'conv5' biases: 9.991453e-01 [3.041935e-06] 
Layer 'fc6' weights[0]: 6.867656e-03 [6.665209e-08] 
Layer 'fc6' biases: 9.999907e-01 [6.140928e-08] 
Layer 'fc7' weights[0]: 7.215184e-03 [1.545110e-07] 
Layer 'fc7' biases: 9.997492e-01 [2.112611e-07] 
Layer 'fc8' weights[0]: 4.648019e-03 [1.438229e-05] 
Layer 'fc8' biases: 1.970289e-02 [2.739671e-05] 
Train error last 800 batches: 0.658068
-------------------------------------------------------
Not saving because 0.372584 > 0.299667 (9.300: -1.18%)
======================================================= (2.417 sec)
25.141... logprob:  0.670632, 0.282552 (1.439 sec)
25.142... logprob:  0.654222, 0.285156 (1.397 sec)
25.143... logprob:  0.522272, 0.257812 (1.417 sec)
25.144... logprob:  0.655192, 0.276042 (1.413 sec)
25.145... logprob:  0.553589, 0.257812 (1.409 sec)
25.146... logprob:  0.677906, 0.302083 (1.404 sec)
25.147... logprob:  0.497730, 0.225260 (1.422 sec)
25.148... logprob:  0.627983, 0.278646 (1.385 sec)
25.149... logprob:  0.543008, 0.246094 (1.387 sec)
25.150... logprob:  0.540855, 0.243490 (1.395 sec)
25.151... logprob:  0.557252, 0.233073 (1.394 sec)
25.152... logprob:  0.929147, 0.364583 (1.380 sec)
25.153... logprob:  0.654996, 0.281250 (1.463 sec)
25.154... logprob:  0.745428, 0.296875 (1.392 sec)
25.155... logprob:  0.578128, 0.263021 (1.402 sec)
25.156... logprob:  0.543262, 0.264323 (1.429 sec)
25.157... logprob:  0.448120, 0.190104 (1.387 sec)
25.158... logprob:  0.698430, 0.305990 (1.396 sec)
25.159... logprob:  0.723912, 0.290365 (1.393 sec)
25.160... logprob:  0.671207, 0.285156 (1.386 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.419473, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.033409e-03 [1.516796e-07] 
Layer 'conv1' biases: 2.115757e-06 [9.681931e-11] 
Layer 'conv2' weights[0]: 3.027493e-03 [1.514359e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.027987e-10] 
Layer 'conv3' weights[0]: 3.026222e-03 [1.516300e-07] 
Layer 'conv3' biases: 3.499449e-05 [6.743730e-09] 
Layer 'conv4' weights[0]: 3.039012e-03 [1.524945e-07] 
Layer 'conv4' biases: 9.999093e-01 [1.520016e-07] 
Layer 'conv5' weights[0]: 3.181424e-03 [2.303424e-06] 
Layer 'conv5' biases: 9.991172e-01 [2.510461e-06] 
Layer 'fc6' weights[0]: 6.866953e-03 [6.036534e-08] 
Layer 'fc6' biases: 9.999906e-01 [5.379716e-08] 
Layer 'fc7' weights[0]: 7.214462e-03 [1.368117e-07] 
Layer 'fc7' biases: 9.997513e-01 [1.582729e-07] 
Layer 'fc8' weights[0]: 4.706899e-03 [1.182489e-05] 
Layer 'fc8' biases: 2.020701e-02 [8.183237e-06] 
Train error last 800 batches: 0.657847
-------------------------------------------------------
Not saving because 0.419473 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
25.161... logprob:  0.611469, 0.266927 (1.405 sec)
25.162... logprob:  0.790478, 0.345052 (1.398 sec)
25.163... logprob:  0.650949, 0.282552 (1.430 sec)
25.164... logprob:  0.638852, 0.269531 (1.416 sec)
25.165... logprob:  0.741186, 0.298177 (1.413 sec)
25.166... logprob:  0.687632, 0.287760 (1.443 sec)
25.167... logprob:  0.643475, 0.295573 (1.424 sec)
25.168... logprob:  0.574756, 0.263021 (1.415 sec)
25.169... logprob:  0.644946, 0.296875 (1.457 sec)
25.170... logprob:  0.674674, 0.287760 (1.398 sec)
25.171... logprob:  0.715849, 0.309896 (1.418 sec)
25.172... logprob:  0.559656, 0.233073 (1.407 sec)
25.173... logprob:  0.678614, 0.302083 (1.414 sec)
25.174... logprob:  0.766253, 0.346354 (1.395 sec)
25.175... logprob:  0.636854, 0.281250 (1.461 sec)
25.176... logprob:  0.535501, 0.236979 (1.418 sec)
25.177... logprob:  0.530586, 0.247396 (1.421 sec)
25.178... logprob:  0.712869, 0.325521 (1.451 sec)
25.179... logprob:  0.669911, 0.302083 (1.401 sec)
25.180... logprob:  0.746609, 0.307292 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.458593, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.030385e-03 [1.515435e-07] 
Layer 'conv1' biases: 2.115836e-06 [8.349454e-11] 
Layer 'conv2' weights[0]: 3.024477e-03 [1.512942e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.155524e-09] 
Layer 'conv3' weights[0]: 3.023181e-03 [1.516945e-07] 
Layer 'conv3' biases: 3.498386e-05 [9.347717e-09] 
Layer 'conv4' weights[0]: 3.035940e-03 [1.524921e-07] 
Layer 'conv4' biases: 9.999111e-01 [2.025471e-07] 
Layer 'conv5' weights[0]: 3.180015e-03 [2.590262e-06] 
Layer 'conv5' biases: 9.991206e-01 [2.800871e-06] 
Layer 'fc6' weights[0]: 6.866234e-03 [6.267571e-08] 
Layer 'fc6' biases: 9.999906e-01 [5.695436e-08] 
Layer 'fc7' weights[0]: 7.213762e-03 [1.433151e-07] 
Layer 'fc7' biases: 9.997503e-01 [1.837867e-07] 
Layer 'fc8' weights[0]: 4.676819e-03 [1.441876e-05] 
Layer 'fc8' biases: 2.002950e-02 [3.077762e-05] 
Train error last 800 batches: 0.657303
-------------------------------------------------------
Not saving because 0.458593 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
25.181... logprob:  0.673935, 0.294271 (1.424 sec)
25.182... logprob:  0.667023, 0.295573 (1.418 sec)
25.183... logprob:  0.573283, 0.247396 (1.413 sec)
25.184... logprob:  0.675579, 0.325521 (1.413 sec)
25.185... logprob:  0.524017, 0.253906 (1.389 sec)
25.186... logprob:  0.616900, 0.292969 (1.396 sec)
25.187... logprob:  0.674542, 0.290365 (1.394 sec)
25.188... logprob:  0.665874, 0.294271 (1.398 sec)
25.189... logprob:  0.653640, 0.277344 (1.379 sec)
25.190... logprob:  0.650090, 0.263021 (1.431 sec)
25.191... logprob:  0.745863, 0.303385 (1.400 sec)
25.192... logprob:  0.738312, 0.328125 (1.435 sec)
25.193... logprob:  0.562181, 0.244792 (1.409 sec)
25.194... logprob:  0.633632, 0.282552 (1.412 sec)
25.195... logprob:  0.550686, 0.253906 (1.392 sec)
25.196... logprob:  0.536711, 0.266927 (1.385 sec)
25.197... logprob:  0.626315, 0.281250 (1.398 sec)
25.198... logprob:  0.646810, 0.298177 (1.400 sec)
25.199... logprob:  0.605742, 0.255208 (1.381 sec)
25.200... logprob:  0.618983, 0.272135 (1.432 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.465000, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.027359e-03 [1.515209e-07] 
Layer 'conv1' biases: 2.116361e-06 [8.422799e-11] 
Layer 'conv2' weights[0]: 3.021460e-03 [1.512073e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.098769e-09] 
Layer 'conv3' weights[0]: 3.020176e-03 [1.516913e-07] 
Layer 'conv3' biases: 3.499113e-05 [9.357348e-09] 
Layer 'conv4' weights[0]: 3.032920e-03 [1.529952e-07] 
Layer 'conv4' biases: 9.999092e-01 [2.645472e-07] 
Layer 'conv5' weights[0]: 3.175825e-03 [2.417623e-06] 
Layer 'conv5' biases: 9.991025e-01 [2.566991e-06] 
Layer 'fc6' weights[0]: 6.865532e-03 [6.257870e-08] 
Layer 'fc6' biases: 9.999903e-01 [5.682481e-08] 
Layer 'fc7' weights[0]: 7.213012e-03 [1.441797e-07] 
Layer 'fc7' biases: 9.997522e-01 [2.027566e-07] 
Layer 'fc8' weights[0]: 4.717135e-03 [1.396343e-05] 
Layer 'fc8' biases: 2.034786e-02 [3.554084e-05] 
Train error last 800 batches: 0.656466
-------------------------------------------------------
Not saving because 0.465000 > 0.299667 (9.300: -1.18%)
======================================================= (2.353 sec)
25.201... logprob:  0.626829, 0.277344 (1.412 sec)
25.202... logprob:  0.730803, 0.296875 (1.399 sec)
25.203... logprob:  0.713609, 0.304687 (1.440 sec)
25.204... logprob:  0.662058, 0.282552 (1.378 sec)
25.205... logprob:  0.621546, 0.259114 (1.402 sec)
25.206... logprob:  0.611742, 0.279948 (1.399 sec)
25.207... logprob:  0.536964, 0.230469 (1.387 sec)
25.208... logprob:  0.678478, 0.307292 (1.394 sec)
25.209... logprob:  0.605595, 0.277344 (1.419 sec)
25.210... logprob:  0.801295, 0.333333 (1.414 sec)
25.211... logprob:  0.641326, 0.263021 (1.410 sec)
25.212... logprob:  0.625591, 0.259115 (1.409 sec)
25.213... logprob:  0.675642, 0.294271 (1.452 sec)
25.214... logprob:  0.660138, 0.285156 (1.420 sec)
25.215... logprob:  0.516887, 0.240885 (1.409 sec)
25.216... logprob:  0.693586, 0.313802 (1.462 sec)
25.217... logprob:  0.541280, 0.234375 (1.402 sec)
25.218... logprob:  0.744231, 0.320312 (1.417 sec)
25.219... logprob:  0.697260, 0.309896 (1.405 sec)
25.220... logprob:  0.692470, 0.287760 (1.419 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.508014, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.024317e-03 [1.514075e-07] 
Layer 'conv1' biases: 2.116888e-06 [7.751589e-11] 
Layer 'conv2' weights[0]: 3.018411e-03 [1.510386e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.087311e-09] 
Layer 'conv3' weights[0]: 3.017150e-03 [1.512948e-07] 
Layer 'conv3' biases: 3.500264e-05 [7.672107e-09] 
Layer 'conv4' weights[0]: 3.029885e-03 [1.522399e-07] 
Layer 'conv4' biases: 9.999085e-01 [1.939413e-07] 
Layer 'conv5' weights[0]: 3.172710e-03 [2.456986e-06] 
Layer 'conv5' biases: 9.991093e-01 [2.528113e-06] 
Layer 'fc6' weights[0]: 6.864803e-03 [6.216116e-08] 
Layer 'fc6' biases: 9.999903e-01 [5.634855e-08] 
Layer 'fc7' weights[0]: 7.212305e-03 [1.428872e-07] 
Layer 'fc7' biases: 9.997508e-01 [1.836156e-07] 
Layer 'fc8' weights[0]: 4.697072e-03 [1.252714e-05] 
Layer 'fc8' biases: 2.016714e-02 [1.946212e-05] 
Train error last 800 batches: 0.655679
-------------------------------------------------------
Not saving because 0.508014 > 0.299667 (9.300: -1.18%)
======================================================= (2.365 sec)
25.221... logprob:  0.595087, 0.276042 (1.413 sec)
25.222... logprob:  0.703665, 0.316406 (1.454 sec)
25.223... logprob:  0.775976, 0.322917 (1.428 sec)
25.224... logprob:  0.625618, 0.266927 (1.436 sec)
25.225... logprob:  0.690095, 0.312500 (1.449 sec)
25.226... logprob:  0.647165, 0.264323 (1.425 sec)
25.227... logprob:  0.592476, 0.272135 (1.411 sec)
25.228... logprob:  0.655159, 0.298177 (1.411 sec)
25.229... logprob:  0.658240, 0.285156 (1.407 sec)
25.230... logprob:  0.720983, 0.330729 (1.433 sec)
25.231... logprob:  0.763066, 0.348958 (1.407 sec)
25.232... logprob:  0.739140, 0.305990 (1.456 sec)
25.233... logprob:  0.691640, 0.304687 (1.423 sec)
25.234... logprob:  0.714840, 0.316406 (1.420 sec)
25.235... logprob:  0.747496, 0.316406 (1.460 sec)
25.236... logprob:  0.583093, 0.255208 (1.396 sec)
25.237... logprob:  0.583321, 0.261719 (1.417 sec)
25.238... logprob:  0.611483, 0.287760 (1.416 sec)
25.239... logprob:  0.710422, 0.319010 (1.414 sec)
25.240... logprob:  0.692407, 0.279948 (1.401 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.479691, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.021293e-03 [1.512442e-07] 
Layer 'conv1' biases: 2.116805e-06 [8.383447e-11] 
Layer 'conv2' weights[0]: 3.015414e-03 [1.509006e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.027765e-09] 
Layer 'conv3' weights[0]: 3.014168e-03 [1.512054e-07] 
Layer 'conv3' biases: 3.500686e-05 [9.090961e-09] 
Layer 'conv4' weights[0]: 3.026851e-03 [1.523105e-07] 
Layer 'conv4' biases: 9.999108e-01 [2.484589e-07] 
Layer 'conv5' weights[0]: 3.171608e-03 [2.999966e-06] 
Layer 'conv5' biases: 9.991294e-01 [3.285493e-06] 
Layer 'fc6' weights[0]: 6.864066e-03 [6.506679e-08] 
Layer 'fc6' biases: 9.999906e-01 [6.003805e-08] 
Layer 'fc7' weights[0]: 7.211586e-03 [1.478362e-07] 
Layer 'fc7' biases: 9.997486e-01 [1.941971e-07] 
Layer 'fc8' weights[0]: 4.648855e-03 [1.356438e-05] 
Layer 'fc8' biases: 1.979271e-02 [2.625833e-05] 
Train error last 800 batches: 0.655477
-------------------------------------------------------
Not saving because 0.479691 > 0.299667 (9.300: -1.18%)
======================================================= (2.355 sec)
25.241... logprob:  0.793076, 0.315104 (1.466 sec)
25.242... logprob:  0.577147, 0.261719 (1.435 sec)
25.243... logprob:  0.595269, 0.273438 (1.437 sec)
25.244... logprob:  0.630941, 0.279948 (1.438 sec)
25.245... logprob:  0.647243, 0.287760 (1.420 sec)
25.246... logprob:  0.607347, 0.300781 (1.409 sec)
25.247... logprob:  0.585108, 0.265625 (1.408 sec)
25.248... logprob:  0.610895, 0.269531 (1.419 sec)
25.249... logprob:  0.761178, 0.347656 (1.414 sec)
25.250... logprob:  0.719356, 0.305990 (1.401 sec)
25.251... logprob:  0.567041, 0.256510 (1.450 sec)
25.252... logprob:  0.579830, 0.246094 (1.420 sec)
25.253... logprob:  0.588455, 0.273437 (1.410 sec)
25.254... logprob:  0.685613, 0.294271 (1.458 sec)
25.255... logprob:  0.618785, 0.311198 (1.397 sec)
25.256... logprob:  0.566185, 0.264323 (1.418 sec)
25.257... logprob:  0.577565, 0.274740 (1.417 sec)
25.258... logprob:  0.613202, 0.269531 (1.416 sec)
25.259... logprob:  0.642418, 0.269531 (1.396 sec)
25.260... logprob:  0.587504, 0.261719 (1.454 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.512303, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.018281e-03 [1.510662e-07] 
Layer 'conv1' biases: 2.117019e-06 [1.251027e-10] 
Layer 'conv2' weights[0]: 3.012402e-03 [1.507670e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.559835e-09] 
Layer 'conv3' weights[0]: 3.011128e-03 [1.513902e-07] 
Layer 'conv3' biases: 3.499175e-05 [1.127634e-08] 
Layer 'conv4' weights[0]: 3.023837e-03 [1.526073e-07] 
Layer 'conv4' biases: 9.999113e-01 [3.005655e-07] 
Layer 'conv5' weights[0]: 3.168998e-03 [3.428140e-06] 
Layer 'conv5' biases: 9.990918e-01 [3.862496e-06] 
Layer 'fc6' weights[0]: 6.863342e-03 [7.633417e-08] 
Layer 'fc6' biases: 9.999906e-01 [7.419550e-08] 
Layer 'fc7' weights[0]: 7.210820e-03 [1.831339e-07] 
Layer 'fc7' biases: 9.997514e-01 [3.228959e-07] 
Layer 'fc8' weights[0]: 4.736235e-03 [1.900402e-05] 
Layer 'fc8' biases: 2.048778e-02 [5.865569e-05] 
Train error last 800 batches: 0.654937
-------------------------------------------------------
Not saving because 0.512303 > 0.299667 (9.300: -1.18%)
======================================================= (2.403 sec)
25.261... logprob:  0.645902, 0.279948 (1.428 sec)
25.262... logprob:  0.706943, 0.303385 (1.430 sec)
25.263... logprob:  0.671671, 0.268229 (1.444 sec)
25.264... logprob:  0.677319, 0.283854 (1.421 sec)
25.265... logprob:  0.682477, 0.304688 (1.415 sec)
25.266... logprob:  0.745681, 0.350260 (1.407 sec)
25.267... logprob:  0.643067, 0.299479 (1.408 sec)
25.268... logprob:  0.705307, 0.305990 (1.422 sec)
25.269... logprob:  0.700182, 0.302083 (1.422 sec)
25.270... logprob:  0.840235, 0.368490 (1.449 sec)
25.271... logprob:  0.686065, 0.277344 (1.424 sec)
25.272... logprob:  0.614431, 0.282552 (1.415 sec)
25.273... logprob:  0.629962, 0.287760 (1.459 sec)
25.274... logprob:  0.729869, 0.332031 (1.398 sec)
25.275... logprob:  0.708716, 0.302083 (1.419 sec)
25.276... logprob:  0.623144, 0.292969 (1.417 sec)
25.277... logprob:  0.661738, 0.278646 (1.429 sec)
25.278... logprob:  0.615164, 0.303385 (1.425 sec)
25.279... logprob:  0.547125, 0.238281 (1.462 sec)
25.280... logprob:  0.462402, 0.230469 (1.396 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.395200, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.015259e-03 [1.509197e-07] 
Layer 'conv1' biases: 2.117589e-06 [7.551737e-11] 
Layer 'conv2' weights[0]: 3.009378e-03 [1.505668e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.711857e-10] 
Layer 'conv3' weights[0]: 3.008120e-03 [1.507943e-07] 
Layer 'conv3' biases: 3.499390e-05 [6.175529e-09] 
Layer 'conv4' weights[0]: 3.020812e-03 [1.517270e-07] 
Layer 'conv4' biases: 9.999109e-01 [1.625451e-07] 
Layer 'conv5' weights[0]: 3.166182e-03 [2.029265e-06] 
Layer 'conv5' biases: 9.991151e-01 [2.107911e-06] 
Layer 'fc6' weights[0]: 6.862661e-03 [5.743354e-08] 
Layer 'fc6' biases: 9.999908e-01 [4.979333e-08] 
Layer 'fc7' weights[0]: 7.210074e-03 [1.290973e-07] 
Layer 'fc7' biases: 9.997498e-01 [1.632564e-07] 
Layer 'fc8' weights[0]: 4.689272e-03 [1.112284e-05] 
Layer 'fc8' biases: 2.013924e-02 [2.123436e-05] 
Train error last 800 batches: 0.654642
-------------------------------------------------------
Not saving because 0.395200 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
25.281... logprob:  0.608557, 0.272135 (1.426 sec)
25.282... logprob:  0.617105, 0.282552 (1.413 sec)
25.283... logprob:  0.589355, 0.243490 (1.417 sec)
25.284... logprob:  0.650469, 0.281250 (1.413 sec)
25.285... logprob:  0.531597, 0.239583 (1.441 sec)
25.286... logprob:  0.607094, 0.263021 (1.431 sec)
25.287... logprob:  0.577232, 0.239583 (1.430 sec)
25.288... logprob:  0.522592, 0.214844 (1.429 sec)
25.289... logprob:  0.679595, 0.291667 (1.439 sec)
25.290... logprob:  0.696806, 0.269531 (1.399 sec)
25.291... logprob:  0.671419, 0.279948 (1.415 sec)
25.292... logprob:  0.736575, 0.358073 (1.413 sec)
25.293... logprob:  0.687548, 0.295573 (1.421 sec)
25.294... logprob:  0.591035, 0.277344 (1.408 sec)
25.295... logprob:  0.531289, 0.253906 (1.460 sec)
25.296... logprob:  0.611005, 0.287760 (1.413 sec)
25.297... logprob:  0.605177, 0.250000 (1.422 sec)
25.298... logprob:  0.615003, 0.276042 (1.458 sec)
25.299... logprob:  0.611875, 0.263021 (1.396 sec)
25.300... logprob:  0.580288, 0.233073 (1.423 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.495514, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.012245e-03 [1.507705e-07] 
Layer 'conv1' biases: 2.118310e-06 [9.113531e-11] 
Layer 'conv2' weights[0]: 3.006357e-03 [1.504142e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.897974e-10] 
Layer 'conv3' weights[0]: 3.005124e-03 [1.506909e-07] 
Layer 'conv3' biases: 3.500566e-05 [7.919193e-09] 
Layer 'conv4' weights[0]: 3.017791e-03 [1.514805e-07] 
Layer 'conv4' biases: 9.999101e-01 [1.690248e-07] 
Layer 'conv5' weights[0]: 3.163054e-03 [1.907687e-06] 
Layer 'conv5' biases: 9.990965e-01 [1.962860e-06] 
Layer 'fc6' weights[0]: 6.861965e-03 [5.950912e-08] 
Layer 'fc6' biases: 9.999906e-01 [5.289196e-08] 
Layer 'fc7' weights[0]: 7.209352e-03 [1.356965e-07] 
Layer 'fc7' biases: 9.997510e-01 [1.689910e-07] 
Layer 'fc8' weights[0]: 4.735761e-03 [1.196717e-05] 
Layer 'fc8' biases: 2.048192e-02 [2.148896e-05] 
Train error last 800 batches: 0.654158
-------------------------------------------------------
Not saving because 0.495514 > 0.299667 (9.300: -1.18%)
======================================================= (2.384 sec)
25.301... logprob:  0.536653, 0.218750 (1.420 sec)
25.302... logprob:  0.837265, 0.360677 (1.422 sec)
25.303... logprob:  0.614449, 0.285156 (1.405 sec)
25.304... logprob:  0.784189, 0.328125 (1.430 sec)
25.305... logprob:  0.673270, 0.299479 (1.432 sec)
25.306... logprob:  0.666983, 0.309896 (1.428 sec)
25.307... logprob:  0.720129, 0.335937 (1.438 sec)
25.308... logprob:  0.605255, 0.279948 (1.456 sec)
25.309... logprob:  0.655642, 0.303385 (1.404 sec)
25.310... logprob:  0.673059, 0.276042 (1.418 sec)
25.311... logprob:  0.733705, 0.300781 (1.417 sec)
25.312... logprob:  0.690251, 0.286458 (1.422 sec)
25.313... logprob:  0.638792, 0.309896 (1.416 sec)
25.314... logprob:  0.645383, 0.282552 (1.462 sec)
25.315... logprob:  0.584344, 0.255208 (1.433 sec)
25.316... logprob:  0.677067, 0.281250 (1.420 sec)
25.317... logprob:  0.739884, 0.350260 (1.476 sec)
25.318... logprob:  0.745815, 0.326823 (1.410 sec)
25.319... logprob:  0.611922, 0.264323 (1.422 sec)
25.320... logprob:  0.610010, 0.300781 (1.419 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.469117, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.009240e-03 [1.505216e-07] 
Layer 'conv1' biases: 2.119259e-06 [1.165342e-10] 
Layer 'conv2' weights[0]: 3.003371e-03 [1.502754e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.119193e-09] 
Layer 'conv3' weights[0]: 3.002123e-03 [1.506824e-07] 
Layer 'conv3' biases: 3.502946e-05 [8.853528e-09] 
Layer 'conv4' weights[0]: 3.014787e-03 [1.516641e-07] 
Layer 'conv4' biases: 9.999093e-01 [2.334513e-07] 
Layer 'conv5' weights[0]: 3.159768e-03 [2.084123e-06] 
Layer 'conv5' biases: 9.991210e-01 [2.218125e-06] 
Layer 'fc6' weights[0]: 6.861239e-03 [5.913931e-08] 
Layer 'fc6' biases: 9.999908e-01 [5.223316e-08] 
Layer 'fc7' weights[0]: 7.208605e-03 [1.330504e-07] 
Layer 'fc7' biases: 9.997489e-01 [1.536172e-07] 
Layer 'fc8' weights[0]: 4.684751e-03 [1.178706e-05] 
Layer 'fc8' biases: 2.014414e-02 [1.715155e-05] 
Train error last 800 batches: 0.654031
-------------------------------------------------------
Not saving because 0.469117 > 0.299667 (9.300: -1.18%)
======================================================= (2.407 sec)
25.321... logprob:  0.591745, 0.276042 (1.438 sec)
25.322... logprob:  0.616290, 0.286458 (1.409 sec)
25.323... logprob:  0.697106, 0.292969 (1.471 sec)
25.324... logprob:  0.664666, 0.264323 (1.416 sec)
25.325... logprob:  0.648757, 0.299479 (1.432 sec)
25.326... logprob:  0.785193, 0.326823 (1.460 sec)
25.327... logprob:  0.732707, 0.317708 (1.420 sec)
25.328... logprob:  0.834705, 0.365885 (1.425 sec)
25.329... logprob:  0.576837, 0.253906 (1.416 sec)
25.330... logprob:  0.599613, 0.247396 (1.418 sec)
25.331... logprob:  0.618342, 0.270833 (1.424 sec)
25.332... logprob:  0.697989, 0.298177 (1.443 sec)
25.333... logprob:  0.626076, 0.308594 (1.441 sec)
25.334... logprob:  0.757805, 0.308594 (1.440 sec)
25.335... logprob:  0.545562, 0.247396 (1.432 sec)
25.336... logprob:  0.776194, 0.305990 (1.449 sec)
25.337... logprob:  0.803339, 0.322917 (1.408 sec)
25.338... logprob:  0.693385, 0.298177 (1.415 sec)
25.339... logprob:  0.698788, 0.308594 (1.416 sec)
25.340... logprob:  0.691124, 0.279948 (1.425 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.551358, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.006235e-03 [1.503728e-07] 
Layer 'conv1' biases: 2.120013e-06 [9.511622e-11] 
Layer 'conv2' weights[0]: 3.000362e-03 [1.500936e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.068736e-09] 
Layer 'conv3' weights[0]: 2.999075e-03 [1.503706e-07] 
Layer 'conv3' biases: 3.505311e-05 [7.632127e-09] 
Layer 'conv4' weights[0]: 3.011760e-03 [1.513644e-07] 
Layer 'conv4' biases: 9.999065e-01 [2.498735e-07] 
Layer 'conv5' weights[0]: 3.154755e-03 [3.465820e-06] 
Layer 'conv5' biases: 9.991345e-01 [3.895615e-06] 
Layer 'fc6' weights[0]: 6.860524e-03 [7.622007e-08] 
Layer 'fc6' biases: 9.999906e-01 [7.393879e-08] 
Layer 'fc7' weights[0]: 7.207884e-03 [1.806799e-07] 
Layer 'fc7' biases: 9.997480e-01 [2.890285e-07] 
Layer 'fc8' weights[0]: 4.659155e-03 [1.808367e-05] 
Layer 'fc8' biases: 1.990786e-02 [4.689463e-05] 
Train error last 800 batches: 0.654792
-------------------------------------------------------
Not saving because 0.551358 > 0.299667 (9.300: -1.18%)
======================================================= (2.346 sec)
25.341... logprob:  0.763893, 0.325521 (1.426 sec)
25.342... logprob:  0.675660, 0.281250 (1.461 sec)
25.343... logprob:  0.717013, 0.303385 (1.435 sec)
25.344... logprob:  0.631265, 0.274740 (1.473 sec)
25.345... logprob:  0.803340, 0.352865 (1.434 sec)
25.346... logprob:  0.687105, 0.317708 (1.456 sec)
25.347... logprob:  0.543895, 0.233073 (1.476 sec)
25.348... logprob:  0.582330, 0.259115 (1.427 sec)
25.349... logprob:  0.687328, 0.307292 (1.424 sec)
25.350... logprob:  0.592121, 0.274739 (1.431 sec)
25.351... logprob:  0.748998, 0.325521 (1.429 sec)
25.352... logprob:  0.565671, 0.253906 (1.430 sec)
25.353... logprob:  0.733921, 0.326823 (1.565 sec)
25.354... logprob:  0.847337, 0.368490 (1.434 sec)
25.355... logprob:  0.534802, 0.240885 (1.445 sec)
25.356... logprob:  0.646619, 0.298177 (1.471 sec)
25.357... logprob:  0.565014, 0.269531 (1.432 sec)
25.358... logprob:  0.519188, 0.231771 (1.433 sec)
25.359... logprob:  0.772149, 0.326823 (1.425 sec)
25.360... logprob:  0.537791, 0.243490 (1.419 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.433469, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.003235e-03 [1.503125e-07] 
Layer 'conv1' biases: 2.120456e-06 [1.092104e-10] 
Layer 'conv2' weights[0]: 2.997377e-03 [1.500124e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.275638e-09] 
Layer 'conv3' weights[0]: 2.996089e-03 [1.505571e-07] 
Layer 'conv3' biases: 3.504679e-05 [1.022469e-08] 
Layer 'conv4' weights[0]: 3.008744e-03 [1.518706e-07] 
Layer 'conv4' biases: 9.999053e-01 [2.582750e-07] 
Layer 'conv5' weights[0]: 3.151231e-03 [3.382989e-06] 
Layer 'conv5' biases: 9.991302e-01 [3.658741e-06] 
Layer 'fc6' weights[0]: 6.859815e-03 [7.462148e-08] 
Layer 'fc6' biases: 9.999906e-01 [7.130252e-08] 
Layer 'fc7' weights[0]: 7.207173e-03 [1.818713e-07] 
Layer 'fc7' biases: 9.997484e-01 [3.159319e-07] 
Layer 'fc8' weights[0]: 4.677728e-03 [1.981263e-05] 
Layer 'fc8' biases: 2.008941e-02 [6.093527e-05] 
Train error last 800 batches: 0.654659
-------------------------------------------------------
Not saving because 0.433469 > 0.299667 (9.300: -1.18%)
======================================================= (2.342 sec)
25.361... logprob:  0.655249, 0.281250 (1.435 sec)
25.362... logprob:  0.653811, 0.268229 (1.475 sec)
25.363... logprob:  0.657235, 0.268229 (1.438 sec)
25.364... logprob:  0.764077, 0.326823 (1.447 sec)
25.365... logprob:  0.632590, 0.277344 (1.458 sec)
25.366... logprob:  0.632945, 0.279948 (1.440 sec)
25.367... logprob:  0.536647, 0.238281 (1.429 sec)
25.368... logprob:  0.742316, 0.342448 (1.424 sec)
25.369... logprob:  0.631442, 0.273437 (1.423 sec)
25.370... logprob:  0.580476, 0.292969 (1.445 sec)
25.371... logprob:  0.574225, 0.273438 (1.457 sec)
25.372... logprob:  0.634238, 0.276042 (1.455 sec)
25.373... logprob:  0.631403, 0.290365 (1.448 sec)
25.374... logprob:  0.740227, 0.279948 (1.441 sec)
25.375... logprob:  0.642813, 0.276042 (1.461 sec)
25.376... logprob:  0.566160, 0.252604 (1.438 sec)
25.377... logprob:  0.528341, 0.226562 (1.420 sec)
25.378... logprob:  0.691826, 0.265625 (1.431 sec)
25.379... logprob:  0.671305, 0.303385 (1.431 sec)
25.380... logprob:  0.810280, 0.339844 (1.434 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.365723, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 3.000232e-03 [1.500791e-07] 
Layer 'conv1' biases: 2.121044e-06 [1.157299e-10] 
Layer 'conv2' weights[0]: 2.994365e-03 [1.498001e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.294792e-09] 
Layer 'conv3' weights[0]: 2.993091e-03 [1.502031e-07] 
Layer 'conv3' biases: 3.504413e-05 [9.512344e-09] 
Layer 'conv4' weights[0]: 3.005741e-03 [1.510855e-07] 
Layer 'conv4' biases: 9.999043e-01 [2.152949e-07] 
Layer 'conv5' weights[0]: 3.147737e-03 [2.635415e-06] 
Layer 'conv5' biases: 9.991127e-01 [2.798943e-06] 
Layer 'fc6' weights[0]: 6.859059e-03 [6.928368e-08] 
Layer 'fc6' biases: 9.999903e-01 [6.545307e-08] 
Layer 'fc7' weights[0]: 7.206445e-03 [1.601704e-07] 
Layer 'fc7' biases: 9.997498e-01 [2.292349e-07] 
Layer 'fc8' weights[0]: 4.749111e-03 [1.529574e-05] 
Layer 'fc8' biases: 2.060988e-02 [2.835426e-05] 
Train error last 800 batches: 0.654638
-------------------------------------------------------
Not saving because 0.365723 > 0.299667 (9.300: -1.18%)
======================================================= (2.350 sec)
25.381... logprob:  0.678501, 0.287760 (1.467 sec)
25.382... logprob:  0.701337, 0.317708 (1.448 sec)
25.383... logprob:  0.631577, 0.299479 (1.433 sec)
25.384... logprob:  0.679855, 0.285156 (1.495 sec)
25.385... logprob:  0.647755, 0.291667 (1.429 sec)
25.386... logprob:  0.830176, 0.342448 (1.423 sec)
25.387... logprob:  0.577164, 0.259115 (1.427 sec)
25.388... logprob:  0.712278, 0.303385 (1.429 sec)
25.389... logprob:  0.729980, 0.341146 (1.428 sec)
25.390... logprob:  0.615841, 0.248698 (1.470 sec)
25.391... logprob:  0.570556, 0.236979 (1.439 sec)
25.392... logprob:  0.684629, 0.287760 (1.426 sec)
25.393... logprob:  0.580840, 0.270833 (1.479 sec)
25.394... logprob:  0.678369, 0.303385 (1.430 sec)
25.395... logprob:  0.646997, 0.270833 (1.432 sec)
25.396... logprob:  0.517179, 0.229167 (1.436 sec)
25.397... logprob:  0.712537, 0.291667 (1.431 sec)
25.398... logprob:  0.700579, 0.282552 (1.426 sec)
25.399... logprob:  0.670638, 0.296875 (1.481 sec)
25.400... logprob:  0.762590, 0.329427 (1.424 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.477783, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.997239e-03 [1.499421e-07] 
Layer 'conv1' biases: 2.121527e-06 [6.562801e-11] 
Layer 'conv2' weights[0]: 2.991365e-03 [1.496576e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.784307e-10] 
Layer 'conv3' weights[0]: 2.990126e-03 [1.498248e-07] 
Layer 'conv3' biases: 3.505326e-05 [6.262683e-09] 
Layer 'conv4' weights[0]: 3.002730e-03 [1.506946e-07] 
Layer 'conv4' biases: 9.999043e-01 [1.851837e-07] 
Layer 'conv5' weights[0]: 3.145300e-03 [2.354430e-06] 
Layer 'conv5' biases: 9.991401e-01 [2.564705e-06] 
Layer 'fc6' weights[0]: 6.858336e-03 [6.491359e-08] 
Layer 'fc6' biases: 9.999906e-01 [5.899267e-08] 
Layer 'fc7' weights[0]: 7.205719e-03 [1.489104e-07] 
Layer 'fc7' biases: 9.997480e-01 [1.897454e-07] 
Layer 'fc8' weights[0]: 4.676521e-03 [1.335363e-05] 
Layer 'fc8' biases: 1.999382e-02 [1.886737e-05] 
Train error last 800 batches: 0.654670
-------------------------------------------------------
Not saving because 0.477783 > 0.299667 (9.300: -1.18%)
======================================================= (2.362 sec)
25.401... logprob:  0.785188, 0.333333 (1.448 sec)
25.402... logprob:  0.675682, 0.290365 (1.474 sec)
25.403... logprob:  0.735764, 0.305990 (1.430 sec)
25.404... logprob:  0.692134, 0.290365 (1.437 sec)
25.405... logprob:  0.763434, 0.332031 (1.434 sec)
25.406... logprob:  0.591933, 0.273437 (1.422 sec)
25.407... logprob:  0.703061, 0.292969 (1.425 sec)
25.408... logprob:  0.547036, 0.238281 (1.477 sec)
25.409... logprob:  0.596948, 0.272135 (1.431 sec)
25.410... logprob:  0.821713, 0.364583 (1.446 sec)
25.411... logprob:  0.578145, 0.248698 (1.479 sec)
25.412... logprob:  0.771938, 0.326823 (1.430 sec)
25.413... logprob:  0.733142, 0.332031 (1.436 sec)
25.414... logprob:  0.613735, 0.259114 (1.430 sec)
25.415... logprob:  0.713734, 0.328125 (1.420 sec)
25.416... logprob:  0.646390, 0.287760 (1.430 sec)
25.417... logprob:  0.642353, 0.278646 (1.467 sec)
25.418... logprob:  0.610067, 0.274740 (1.443 sec)
25.419... logprob:  0.618255, 0.257812 (1.445 sec)
25.420... logprob:  0.622098, 0.285156 (1.449 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.499171, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.994228e-03 [1.498581e-07] 
Layer 'conv1' biases: 2.121965e-06 [8.960863e-11] 
Layer 'conv2' weights[0]: 2.988376e-03 [1.495464e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.125612e-09] 
Layer 'conv3' weights[0]: 2.987106e-03 [1.498999e-07] 
Layer 'conv3' biases: 3.503915e-05 [8.933846e-09] 
Layer 'conv4' weights[0]: 2.999732e-03 [1.507628e-07] 
Layer 'conv4' biases: 9.999059e-01 [2.093226e-07] 
Layer 'conv5' weights[0]: 3.143569e-03 [2.955073e-06] 
Layer 'conv5' biases: 9.991454e-01 [3.249449e-06] 
Layer 'fc6' weights[0]: 6.857627e-03 [7.484818e-08] 
Layer 'fc6' biases: 9.999906e-01 [7.111867e-08] 
Layer 'fc7' weights[0]: 7.204944e-03 [1.789042e-07] 
Layer 'fc7' biases: 9.997470e-01 [3.008448e-07] 
Layer 'fc8' weights[0]: 4.672002e-03 [2.116156e-05] 
Layer 'fc8' biases: 1.998067e-02 [6.913867e-05] 
Train error last 800 batches: 0.655167
-------------------------------------------------------
Not saving because 0.499171 > 0.299667 (9.300: -1.18%)
======================================================= (2.343 sec)
25.421... logprob:  0.458687, 0.184896 (1.459 sec)
25.422... logprob:  0.723206, 0.312500 (1.466 sec)
25.423... logprob:  0.674905, 0.260417 (1.425 sec)
25.424... logprob:  0.582228, 0.251302 (1.425 sec)
25.425... logprob:  0.573217, 0.260417 (1.439 sec)
25.426... logprob:  0.666693, 0.283854 (1.438 sec)
25.427... logprob:  0.702250, 0.320312 (1.457 sec)
25.428... logprob:  0.751898, 0.312500 (1.448 sec)
25.429... logprob:  0.594114, 0.261719 (1.434 sec)
25.430... logprob:  0.563906, 0.263021 (1.467 sec)
25.431... logprob:  0.632913, 0.273437 (1.433 sec)
25.432... logprob:  0.552597, 0.226562 (1.426 sec)
25.433... logprob:  0.661484, 0.304687 (1.424 sec)
25.434... logprob:  0.772430, 0.294271 (1.436 sec)
25.435... logprob:  0.702476, 0.316406 (1.426 sec)
25.436... logprob:  0.602854, 0.256510 (1.478 sec)
25.437... logprob:  0.680768, 0.289062 (1.445 sec)
25.438... logprob:  0.726438, 0.268229 (1.425 sec)
25.439... logprob:  0.642989, 0.300781 (1.483 sec)
25.440... logprob:  0.605789, 0.244792 (1.424 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.557348, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.991242e-03 [1.495453e-07] 
Layer 'conv1' biases: 2.122784e-06 [9.987638e-11] 
Layer 'conv2' weights[0]: 2.985381e-03 [1.493203e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.223976e-09] 
Layer 'conv3' weights[0]: 2.984125e-03 [1.497946e-07] 
Layer 'conv3' biases: 3.502593e-05 [1.001125e-08] 
Layer 'conv4' weights[0]: 2.996739e-03 [1.507185e-07] 
Layer 'conv4' biases: 9.999054e-01 [2.701250e-07] 
Layer 'conv5' weights[0]: 3.140371e-03 [2.643125e-06] 
Layer 'conv5' biases: 9.991352e-01 [2.826279e-06] 
Layer 'fc6' weights[0]: 6.856916e-03 [6.611221e-08] 
Layer 'fc6' biases: 9.999905e-01 [6.085663e-08] 
Layer 'fc7' weights[0]: 7.204239e-03 [1.525509e-07] 
Layer 'fc7' biases: 9.997478e-01 [2.081940e-07] 
Layer 'fc8' weights[0]: 4.698086e-03 [1.397513e-05] 
Layer 'fc8' biases: 2.021299e-02 [2.830202e-05] 
Train error last 800 batches: 0.654171
-------------------------------------------------------
Not saving because 0.557348 > 0.299667 (9.300: -1.18%)
======================================================= (2.406 sec)
25.441... logprob:  0.626238, 0.277344 (1.430 sec)
25.442... logprob:  0.572083, 0.264323 (1.433 sec)
25.443... logprob:  0.758388, 0.342448 (1.435 sec)
25.444... logprob:  0.662100, 0.298177 (1.435 sec)
25.445... logprob:  0.636686, 0.285156 (1.473 sec)
25.446... logprob:  0.574715, 0.259114 (1.431 sec)
25.447... logprob:  0.760539, 0.299479 (1.435 sec)
25.448... logprob:  0.594591, 0.286458 (1.485 sec)
25.449... logprob:  0.632448, 0.268229 (1.432 sec)
25.450... logprob:  0.556937, 0.273437 (1.427 sec)
25.451... logprob:  0.656822, 0.295573 (1.428 sec)
25.452... logprob:  0.697502, 0.298177 (1.425 sec)
25.453... logprob:  0.666623, 0.322917 (1.432 sec)
25.454... logprob:  0.715163, 0.292969 (1.481 sec)
25.455... logprob:  0.754246, 0.335938 (1.425 sec)
25.456... logprob:  0.745607, 0.307292 (1.443 sec)
25.457... logprob:  0.528860, 0.221354 (1.477 sec)
25.458... logprob:  0.613311, 0.277344 (1.428 sec)
25.459... logprob:  0.658449, 0.300781 (1.440 sec)
25.460... logprob:  0.547259, 0.244792 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.443216, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.988244e-03 [1.494550e-07] 
Layer 'conv1' biases: 2.123924e-06 [8.241189e-11] 
Layer 'conv2' weights[0]: 2.982411e-03 [1.491713e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.836361e-10] 
Layer 'conv3' weights[0]: 2.981148e-03 [1.493457e-07] 
Layer 'conv3' biases: 3.502299e-05 [6.647850e-09] 
Layer 'conv4' weights[0]: 2.993746e-03 [1.501613e-07] 
Layer 'conv4' biases: 9.999046e-01 [1.726310e-07] 
Layer 'conv5' weights[0]: 3.137167e-03 [2.381757e-06] 
Layer 'conv5' biases: 9.991385e-01 [2.565572e-06] 
Layer 'fc6' weights[0]: 6.856230e-03 [6.089180e-08] 
Layer 'fc6' biases: 9.999905e-01 [5.393894e-08] 
Layer 'fc7' weights[0]: 7.203529e-03 [1.362505e-07] 
Layer 'fc7' biases: 9.997470e-01 [1.673808e-07] 
Layer 'fc8' weights[0]: 4.686770e-03 [1.171809e-05] 
Layer 'fc8' biases: 2.015434e-02 [1.674552e-05] 
Train error last 800 batches: 0.653795
-------------------------------------------------------
Not saving because 0.443216 > 0.299667 (9.300: -1.18%)
======================================================= (2.375 sec)
25.461... logprob:  0.665576, 0.315104 (1.431 sec)
25.462... logprob:  0.664176, 0.289062 (1.440 sec)
25.463... logprob:  0.626608, 0.289062 (1.468 sec)
25.464... logprob:  0.708394, 0.298177 (1.441 sec)
25.465... logprob:  0.702952, 0.304687 (1.446 sec)
25.466... logprob:  0.533599, 0.251302 (1.454 sec)
25.467... logprob:  0.631415, 0.313802 (1.442 sec)
25.468... logprob:  0.625240, 0.281250 (1.432 sec)
25.469... logprob:  0.640835, 0.294271 (1.423 sec)
25.470... logprob:  0.579332, 0.240885 (1.421 sec)
25.471... logprob:  0.749052, 0.325521 (1.440 sec)
25.472... logprob:  0.662678, 0.298177 (1.450 sec)
25.473... logprob:  0.624365, 0.266927 (1.454 sec)
25.474... logprob:  0.570226, 0.246094 (1.449 sec)
25.475... logprob:  0.714762, 0.294271 (1.447 sec)
25.476... logprob:  0.759296, 0.307292 (1.463 sec)
25.477... logprob:  0.634828, 0.298177 (1.436 sec)
25.478... logprob:  0.672057, 0.316406 (1.421 sec)
25.479... logprob:  0.599426, 0.287760 (1.431 sec)
25.480... logprob:  0.698499, 0.315104 (1.434 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.512904, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.985256e-03 [1.493729e-07] 
Layer 'conv1' biases: 2.124349e-06 [5.187726e-11] 
Layer 'conv2' weights[0]: 2.979426e-03 [1.490703e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.130085e-10] 
Layer 'conv3' weights[0]: 2.978179e-03 [1.491968e-07] 
Layer 'conv3' biases: 3.502653e-05 [6.766715e-09] 
Layer 'conv4' weights[0]: 2.990757e-03 [1.500174e-07] 
Layer 'conv4' biases: 9.999038e-01 [1.719526e-07] 
Layer 'conv5' weights[0]: 3.133603e-03 [2.058838e-06] 
Layer 'conv5' biases: 9.991226e-01 [2.169450e-06] 
Layer 'fc6' weights[0]: 6.855522e-03 [6.050691e-08] 
Layer 'fc6' biases: 9.999905e-01 [5.374212e-08] 
Layer 'fc7' weights[0]: 7.202738e-03 [1.352996e-07] 
Layer 'fc7' biases: 9.997478e-01 [1.678798e-07] 
Layer 'fc8' weights[0]: 4.728025e-03 [1.239801e-05] 
Layer 'fc8' biases: 2.056162e-02 [1.930965e-05] 
Train error last 800 batches: 0.654148
-------------------------------------------------------
Not saving because 0.512904 > 0.299667 (9.300: -1.18%)
======================================================= (2.365 sec)
25.481... logprob:  0.722189, 0.305990 (1.438 sec)
25.482... logprob:  0.663549, 0.291667 (1.475 sec)
25.483... logprob:  0.695858, 0.312500 (1.448 sec)
25.484... logprob:  0.800746, 0.324219 (1.437 sec)
25.485... logprob:  0.631775, 0.263021 (1.480 sec)
25.486... logprob:  0.629797, 0.252604 (1.426 sec)
25.487... logprob:  0.794345, 0.335937 (1.422 sec)
25.488... logprob:  0.611509, 0.264323 (1.435 sec)
25.489... logprob:  0.637131, 0.305990 (1.429 sec)
25.490... logprob:  0.632589, 0.259115 (1.428 sec)
25.491... logprob:  0.565083, 0.260417 (1.473 sec)
25.492... logprob:  0.583487, 0.279948 (1.432 sec)
25.493... logprob:  0.796389, 0.328125 (1.433 sec)
25.494... logprob:  0.696631, 0.298177 (1.492 sec)
25.495... logprob:  0.544916, 0.235677 (1.425 sec)
25.496... logprob:  0.862603, 0.364583 (1.428 sec)
25.497... logprob:  0.717377, 0.289062 (1.438 sec)
25.498... logprob:  0.651083, 0.313802 (1.429 sec)
25.499... logprob:  0.651943, 0.295573 (1.430 sec)
25.500... logprob:  0.553287, 0.251302 (1.512 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.495301, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.982276e-03 [1.490864e-07] 
Layer 'conv1' biases: 2.124975e-06 [7.615595e-11] 
Layer 'conv2' weights[0]: 2.976456e-03 [1.488855e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.178640e-10] 
Layer 'conv3' weights[0]: 2.975229e-03 [1.489707e-07] 
Layer 'conv3' biases: 3.501992e-05 [5.803794e-09] 
Layer 'conv4' weights[0]: 2.987776e-03 [1.496296e-07] 
Layer 'conv4' biases: 9.999054e-01 [1.531218e-07] 
Layer 'conv5' weights[0]: 3.131865e-03 [2.224931e-06] 
Layer 'conv5' biases: 9.991362e-01 [2.392277e-06] 
Layer 'fc6' weights[0]: 6.854822e-03 [6.417299e-08] 
Layer 'fc6' biases: 9.999905e-01 [5.846650e-08] 
Layer 'fc7' weights[0]: 7.202042e-03 [1.484989e-07] 
Layer 'fc7' biases: 9.997461e-01 [2.073951e-07] 
Layer 'fc8' weights[0]: 4.674774e-03 [1.468858e-05] 
Layer 'fc8' biases: 2.016579e-02 [3.429706e-05] 
Train error last 800 batches: 0.654311
-------------------------------------------------------
Not saving because 0.495301 > 0.299667 (9.300: -1.18%)
======================================================= (2.403 sec)
25.501... logprob:  0.559341, 0.230469 (1.430 sec)
25.502... logprob:  0.717880, 0.313802 (1.447 sec)
25.503... logprob:  0.580969, 0.260417 (1.479 sec)
25.504... logprob:  0.735622, 0.325521 (1.425 sec)
25.505... logprob:  0.694708, 0.328125 (1.433 sec)
25.506... logprob:  0.632378, 0.274740 (1.432 sec)
25.507... logprob:  0.637042, 0.277344 (1.422 sec)
25.508... logprob:  0.626424, 0.311198 (1.433 sec)
25.509... logprob:  0.545686, 0.261719 (1.472 sec)
25.510... logprob:  0.637581, 0.304688 (1.436 sec)
25.511... logprob:  0.678655, 0.298177 (1.447 sec)
25.512... logprob:  0.689109, 0.278646 (1.455 sec)
25.513... logprob:  0.533603, 0.243490 (1.441 sec)
25.514... logprob:  0.609801, 0.273437 (1.440 sec)
25.515... logprob:  0.709304, 0.313802 (1.432 sec)
25.516... logprob:  0.727734, 0.329427 (1.421 sec)
25.517... logprob:  0.758803, 0.337240 (1.431 sec)
25.518... logprob:  0.624524, 0.281250 (1.455 sec)
25.519... logprob:  0.637138, 0.307292 (1.448 sec)
25.520... logprob:  0.577428, 0.256510 (1.447 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.514116, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.979299e-03 [1.490127e-07] 
Layer 'conv1' biases: 2.125553e-06 [9.833774e-11] 
Layer 'conv2' weights[0]: 2.973482e-03 [1.487674e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.001856e-09] 
Layer 'conv3' weights[0]: 2.972232e-03 [1.491636e-07] 
Layer 'conv3' biases: 3.502273e-05 [8.573042e-09] 
Layer 'conv4' weights[0]: 2.984752e-03 [1.500601e-07] 
Layer 'conv4' biases: 9.999033e-01 [2.048259e-07] 
Layer 'conv5' weights[0]: 3.127750e-03 [2.149554e-06] 
Layer 'conv5' biases: 9.991187e-01 [2.299403e-06] 
Layer 'fc6' weights[0]: 6.854108e-03 [6.036182e-08] 
Layer 'fc6' biases: 9.999903e-01 [5.370363e-08] 
Layer 'fc7' weights[0]: 7.201332e-03 [1.379310e-07] 
Layer 'fc7' biases: 9.997473e-01 [1.780999e-07] 
Layer 'fc8' weights[0]: 4.720492e-03 [1.298145e-05] 
Layer 'fc8' biases: 2.048482e-02 [2.215334e-05] 
Train error last 800 batches: 0.654327
-------------------------------------------------------
Not saving because 0.514116 > 0.299667 (9.300: -1.18%)
======================================================= (2.358 sec)
25.521... logprob:  0.591335, 0.282552 (1.463 sec)
25.522... logprob:  0.779848, 0.322917 (1.465 sec)
25.523... logprob:  0.502340, 0.212239 (1.438 sec)
25.524... logprob:  0.691279, 0.276042 (1.417 sec)
25.525... logprob:  0.632224, 0.269531 (1.426 sec)
25.526... logprob:  0.548933, 0.236979 (1.433 sec)
25.527... logprob:  0.716744, 0.292969 (1.438 sec)
25.528... logprob:  0.679998, 0.296875 (1.461 sec)
25.529... logprob:  0.612562, 0.281250 (1.444 sec)
25.530... logprob:  0.639500, 0.270833 (1.433 sec)
25.531... logprob:  0.611078, 0.239583 (1.473 sec)
25.532... logprob:  0.743787, 0.303385 (1.429 sec)
25.533... logprob:  0.694026, 0.289062 (1.421 sec)
25.534... logprob:  0.524683, 0.231771 (1.431 sec)
25.535... logprob:  0.826510, 0.337240 (1.432 sec)
25.536... logprob:  0.739959, 0.320312 (1.430 sec)
25.537... logprob:  0.706669, 0.295573 (1.487 sec)
25.538... logprob:  0.759476, 0.335938 (1.478 sec)
25.539... logprob:  0.552368, 0.255208 (1.422 sec)
25.540... logprob:  0.617060, 0.283854 (1.485 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.507767, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.976324e-03 [1.488771e-07] 
Layer 'conv1' biases: 2.126045e-06 [8.023365e-11] 
Layer 'conv2' weights[0]: 2.970516e-03 [1.485860e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.214158e-10] 
Layer 'conv3' weights[0]: 2.969257e-03 [1.488002e-07] 
Layer 'conv3' biases: 3.503464e-05 [7.055836e-09] 
Layer 'conv4' weights[0]: 2.981773e-03 [1.495933e-07] 
Layer 'conv4' biases: 9.999027e-01 [1.908789e-07] 
Layer 'conv5' weights[0]: 3.124330e-03 [2.342373e-06] 
Layer 'conv5' biases: 9.991227e-01 [2.486842e-06] 
Layer 'fc6' weights[0]: 6.853408e-03 [6.272291e-08] 
Layer 'fc6' biases: 9.999904e-01 [5.693455e-08] 
Layer 'fc7' weights[0]: 7.200569e-03 [1.474101e-07] 
Layer 'fc7' biases: 9.997469e-01 [2.018069e-07] 
Layer 'fc8' weights[0]: 4.704673e-03 [1.384081e-05] 
Layer 'fc8' biases: 2.038427e-02 [2.912947e-05] 
Train error last 800 batches: 0.654638
-------------------------------------------------------
Not saving because 0.507767 > 0.299667 (9.300: -1.18%)
======================================================= (2.365 sec)
25.541... logprob:  0.649621, 0.326823 (1.436 sec)
25.542... logprob:  0.668269, 0.302083 (1.432 sec)
25.543... logprob:  0.486519, 0.234375 (1.437 sec)
25.544... logprob:  0.565400, 0.253906 (1.423 sec)
25.545... logprob:  0.604477, 0.291667 (1.428 sec)
25.546... logprob:  0.569644, 0.255208 (1.488 sec)
25.547... logprob:  0.646306, 0.266927 (1.433 sec)
25.548... logprob:  0.661672, 0.302083 (1.447 sec)
25.549... logprob:  0.565414, 0.260417 (1.478 sec)
25.550... logprob:  0.620461, 0.281250 (1.428 sec)
25.551... logprob:  0.623128, 0.291667 (1.432 sec)
25.552... logprob:  0.630462, 0.274739 (1.428 sec)
25.553... logprob:  0.590204, 0.278646 (1.421 sec)
25.554... logprob:  0.727517, 0.322917 (1.431 sec)
25.555... logprob:  0.618354, 0.286458 (1.481 sec)
25.556... logprob:  0.570308, 0.251302 (1.433 sec)
25.557... logprob:  0.650392, 0.260417 (1.450 sec)
25.558... logprob:  0.686376, 0.304687 (1.463 sec)
25.559... logprob:  0.610746, 0.286458 (1.432 sec)
25.560... logprob:  0.583524, 0.248698 (1.434 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.481214, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.973347e-03 [1.489115e-07] 
Layer 'conv1' biases: 2.125864e-06 [1.011519e-10] 
Layer 'conv2' weights[0]: 2.967528e-03 [1.485613e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.171552e-09] 
Layer 'conv3' weights[0]: 2.966270e-03 [1.489055e-07] 
Layer 'conv3' biases: 3.503848e-05 [8.558093e-09] 
Layer 'conv4' weights[0]: 2.978780e-03 [1.500182e-07] 
Layer 'conv4' biases: 9.999008e-01 [2.459537e-07] 
Layer 'conv5' weights[0]: 3.120297e-03 [2.455425e-06] 
Layer 'conv5' biases: 9.990909e-01 [2.643549e-06] 
Layer 'fc6' weights[0]: 6.852731e-03 [6.025471e-08] 
Layer 'fc6' biases: 9.999905e-01 [5.412944e-08] 
Layer 'fc7' weights[0]: 7.199860e-03 [1.371533e-07] 
Layer 'fc7' biases: 9.997489e-01 [1.735935e-07] 
Layer 'fc8' weights[0]: 4.775463e-03 [1.222733e-05] 
Layer 'fc8' biases: 2.094274e-02 [2.353043e-05] 
Train error last 800 batches: 0.654165
-------------------------------------------------------
Not saving because 0.481214 > 0.299667 (9.300: -1.18%)
======================================================= (2.348 sec)
25.561... logprob:  0.608000, 0.272135 (1.433 sec)
25.562... logprob:  0.622668, 0.289062 (1.418 sec)
25.563... logprob:  0.680906, 0.298177 (1.441 sec)
25.564... logprob:  0.666185, 0.286458 (1.458 sec)
25.565... logprob:  0.748909, 0.300781 (1.443 sec)
25.566... logprob:  0.548206, 0.251302 (1.443 sec)
25.567... logprob:  0.697134, 0.313802 (1.454 sec)
25.568... logprob:  0.775181, 0.333333 (1.455 sec)
25.569... logprob:  0.730021, 0.276042 (1.434 sec)
25.570... logprob:  0.744535, 0.292969 (1.426 sec)
25.571... logprob:  0.754326, 0.346354 (1.425 sec)
25.572... logprob:  0.679164, 0.277344 (1.441 sec)
25.573... logprob:  0.703910, 0.294271 (1.444 sec)
25.574... logprob:  0.723940, 0.305990 (1.459 sec)
25.575... logprob:  0.593223, 0.246094 (1.453 sec)
25.576... logprob:  0.666561, 0.292969 (1.464 sec)
25.577... logprob:  0.591504, 0.256510 (1.474 sec)
25.578... logprob:  0.536477, 0.243490 (1.426 sec)
25.579... logprob:  0.656229, 0.298177 (1.421 sec)
25.580... logprob:  0.701822, 0.319010 (1.425 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.418858, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.970370e-03 [1.485864e-07] 
Layer 'conv1' biases: 2.126189e-06 [9.575749e-11] 
Layer 'conv2' weights[0]: 2.964567e-03 [1.482821e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.369387e-10] 
Layer 'conv3' weights[0]: 2.963309e-03 [1.484976e-07] 
Layer 'conv3' biases: 3.505113e-05 [7.166786e-09] 
Layer 'conv4' weights[0]: 2.975834e-03 [1.492988e-07] 
Layer 'conv4' biases: 9.999011e-01 [1.749258e-07] 
Layer 'conv5' weights[0]: 3.118111e-03 [2.486229e-06] 
Layer 'conv5' biases: 9.991334e-01 [2.650875e-06] 
Layer 'fc6' weights[0]: 6.851998e-03 [6.420717e-08] 
Layer 'fc6' biases: 9.999903e-01 [5.889590e-08] 
Layer 'fc7' weights[0]: 7.199171e-03 [1.489683e-07] 
Layer 'fc7' biases: 9.997460e-01 [2.100500e-07] 
Layer 'fc8' weights[0]: 4.678909e-03 [1.473126e-05] 
Layer 'fc8' biases: 2.019436e-02 [2.483761e-05] 
Train error last 800 batches: 0.653847
-------------------------------------------------------
Not saving because 0.418858 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
25.581... logprob:  0.714395, 0.321615 (1.439 sec)
25.582... logprob:  0.608789, 0.274740 (1.429 sec)
25.583... logprob:  0.766277, 0.332031 (1.477 sec)
25.584... logprob:  0.687997, 0.302083 (1.437 sec)
25.585... logprob:  0.609453, 0.268229 (1.428 sec)
25.586... logprob:  0.512577, 0.225260 (1.481 sec)
25.587... logprob:  0.642944, 0.276042 (1.424 sec)
25.588... logprob:  0.634517, 0.287760 (1.424 sec)
25.589... logprob:  0.634039, 0.269531 (1.427 sec)
25.590... logprob:  0.749322, 0.330729 (1.429 sec)
25.591... logprob:  0.589763, 0.270833 (1.433 sec)
25.592... logprob:  0.608078, 0.260417 (1.474 sec)
25.593... logprob:  0.688592, 0.292969 (1.432 sec)
25.594... logprob:  0.598868, 0.265625 (1.433 sec)
25.595... logprob:  0.630599, 0.281250 (1.476 sec)
25.596... logprob:  0.665367, 0.274740 (1.431 sec)
25.597... logprob:  0.635242, 0.273437 (1.425 sec)
25.598... logprob:  0.635239, 0.265625 (1.430 sec)
25.599... logprob:  0.624986, 0.279948 (1.421 sec)
25.600... logprob:  0.496819, 0.231771 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.434969, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.967399e-03 [1.486222e-07] 
Layer 'conv1' biases: 2.126477e-06 [9.036239e-11] 
Layer 'conv2' weights[0]: 2.961594e-03 [1.482835e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.185036e-09] 
Layer 'conv3' weights[0]: 2.960339e-03 [1.486460e-07] 
Layer 'conv3' biases: 3.507093e-05 [8.359975e-09] 
Layer 'conv4' weights[0]: 2.972845e-03 [1.498507e-07] 
Layer 'conv4' biases: 9.999007e-01 [2.496696e-07] 
Layer 'conv5' weights[0]: 3.115239e-03 [3.307685e-06] 
Layer 'conv5' biases: 9.991184e-01 [3.675152e-06] 
Layer 'fc6' weights[0]: 6.851252e-03 [7.484867e-08] 
Layer 'fc6' biases: 9.999905e-01 [7.209047e-08] 
Layer 'fc7' weights[0]: 7.198412e-03 [1.795925e-07] 
Layer 'fc7' biases: 9.997469e-01 [3.086985e-07] 
Layer 'fc8' weights[0]: 4.719418e-03 [1.870777e-05] 
Layer 'fc8' biases: 2.049617e-02 [5.759396e-05] 
Train error last 800 batches: 0.653931
-------------------------------------------------------
Not saving because 0.434969 > 0.299667 (9.300: -1.18%)
======================================================= (2.343 sec)
25.601... logprob:  0.621096, 0.281250 (1.482 sec)
25.602... logprob:  0.496186, 0.207031 (1.433 sec)
25.603... logprob:  0.566732, 0.285156 (1.448 sec)
25.604... logprob:  0.591649, 0.247396 (1.473 sec)
25.605... logprob:  0.764233, 0.305989 (1.432 sec)
25.606... logprob:  0.490108, 0.214844 (1.440 sec)
25.607... logprob:  0.752268, 0.305990 (1.433 sec)
25.608... logprob:  0.643937, 0.274739 (1.424 sec)
25.609... logprob:  0.573724, 0.246094 (1.431 sec)
25.610... logprob:  0.651859, 0.295573 (1.465 sec)
25.611... logprob:  0.834563, 0.309896 (1.438 sec)
25.612... logprob:  0.666525, 0.312500 (1.448 sec)
25.613... logprob:  0.619349, 0.274740 (1.456 sec)
25.614... logprob:  0.719107, 0.277344 (1.475 sec)
25.615... logprob:  0.586714, 0.278646 (1.438 sec)
25.616... logprob:  0.593604, 0.247396 (1.423 sec)
25.617... logprob:  0.679838, 0.285156 (1.431 sec)
25.618... logprob:  0.748308, 0.308594 (1.442 sec)
25.619... logprob:  0.784464, 0.321615 (1.449 sec)
25.620... logprob:  0.854834, 0.360677 (1.451 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.402576, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.964439e-03 [1.481506e-07] 
Layer 'conv1' biases: 2.126949e-06 [1.667425e-10] 
Layer 'conv2' weights[0]: 2.958640e-03 [1.480017e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.479336e-09] 
Layer 'conv3' weights[0]: 2.957401e-03 [1.497031e-07] 
Layer 'conv3' biases: 3.507750e-05 [1.821153e-08] 
Layer 'conv4' weights[0]: 2.969860e-03 [1.511721e-07] 
Layer 'conv4' biases: 9.999018e-01 [4.735795e-07] 
Layer 'conv5' weights[0]: 3.113403e-03 [5.679080e-06] 
Layer 'conv5' biases: 9.991230e-01 [6.332447e-06] 
Layer 'fc6' weights[0]: 6.850521e-03 [9.476539e-08] 
Layer 'fc6' biases: 9.999907e-01 [1.008712e-07] 
Layer 'fc7' weights[0]: 7.197703e-03 [2.472982e-07] 
Layer 'fc7' biases: 9.997467e-01 [4.736566e-07] 
Layer 'fc8' weights[0]: 4.733086e-03 [2.597402e-05] 
Layer 'fc8' biases: 2.069597e-02 [8.509425e-05] 
Train error last 800 batches: 0.654998
-------------------------------------------------------
Not saving because 0.402576 > 0.299667 (9.300: -1.18%)
======================================================= (2.383 sec)
25.621... logprob:  0.603155, 0.251302 (1.455 sec)
25.622... logprob:  0.573849, 0.247396 (1.443 sec)
25.623... logprob:  0.689915, 0.287760 (1.460 sec)
25.624... logprob:  0.718560, 0.313802 (1.429 sec)
25.625... logprob:  0.680065, 0.291667 (1.423 sec)
25.626... logprob:  0.568576, 0.256510 (1.432 sec)
25.627... logprob:  0.629621, 0.265625 (1.435 sec)
25.628... logprob:  0.611512, 0.256510 (1.436 sec)
25.629... logprob:  0.683399, 0.311198 (1.471 sec)
25.630... logprob:  0.607690, 0.238281 (1.442 sec)
25.631... logprob:  0.833538, 0.352865 (1.426 sec)
25.632... logprob:  0.621733, 0.277344 (1.479 sec)
25.633... logprob:  0.550327, 0.265625 (1.428 sec)
25.634... logprob:  0.785018, 0.324219 (1.419 sec)
25.635... logprob:  0.633528, 0.278646 (1.432 sec)
25.636... logprob:  0.630744, 0.278646 (1.435 sec)
25.637... logprob:  0.600845, 0.279948 (1.433 sec)
25.638... logprob:  0.741047, 0.286458 (1.476 sec)
25.639... logprob:  0.675305, 0.311198 (1.441 sec)
25.640... logprob:  0.677709, 0.294271 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.513225, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.961479e-03 [1.481212e-07] 
Layer 'conv1' biases: 2.127465e-06 [7.535311e-11] 
Layer 'conv2' weights[0]: 2.955675e-03 [1.478655e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.249280e-10] 
Layer 'conv3' weights[0]: 2.954422e-03 [1.480012e-07] 
Layer 'conv3' biases: 3.511113e-05 [6.748423e-09] 
Layer 'conv4' weights[0]: 2.966914e-03 [1.487069e-07] 
Layer 'conv4' biases: 9.999029e-01 [1.626650e-07] 
Layer 'conv5' weights[0]: 3.111508e-03 [2.380626e-06] 
Layer 'conv5' biases: 9.991628e-01 [2.565466e-06] 
Layer 'fc6' weights[0]: 6.849831e-03 [6.212905e-08] 
Layer 'fc6' biases: 9.999906e-01 [5.524857e-08] 
Layer 'fc7' weights[0]: 7.196978e-03 [1.418651e-07] 
Layer 'fc7' biases: 9.997436e-01 [1.789375e-07] 
Layer 'fc8' weights[0]: 4.644005e-03 [1.327125e-05] 
Layer 'fc8' biases: 2.007418e-02 [2.696517e-05] 
Train error last 800 batches: 0.654987
-------------------------------------------------------
Not saving because 0.513225 > 0.299667 (9.300: -1.18%)
======================================================= (2.367 sec)
25.641... logprob:  0.661319, 0.282552 (1.488 sec)
25.642... logprob:  0.771303, 0.305990 (1.433 sec)
25.643... logprob:  0.757972, 0.307292 (1.425 sec)
25.644... logprob:  0.559866, 0.255208 (1.431 sec)
25.645... logprob:  0.626752, 0.282552 (1.430 sec)
25.646... logprob:  0.603489, 0.266927 (1.425 sec)
25.647... logprob:  0.693700, 0.295573 (1.482 sec)
25.648... logprob:  0.744427, 0.320312 (1.436 sec)
25.649... logprob:  0.563930, 0.272135 (1.442 sec)
25.650... logprob:  0.668411, 0.291667 (1.475 sec)
25.651... logprob:  0.602722, 0.260417 (1.429 sec)
25.652... logprob:  0.687253, 0.303385 (1.468 sec)
25.653... logprob:  0.647922, 0.277344 (1.431 sec)
25.654... logprob:  0.682872, 0.277344 (1.424 sec)
25.655... logprob:  0.613308, 0.272135 (1.433 sec)
25.656... logprob:  0.654363, 0.264323 (1.471 sec)
25.657... logprob:  0.597977, 0.264323 (1.437 sec)
25.658... logprob:  0.642542, 0.283854 (1.451 sec)
25.659... logprob:  0.705436, 0.299479 (1.464 sec)
25.660... logprob:  0.717283, 0.307292 (1.441 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.477225, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.958518e-03 [1.479582e-07] 
Layer 'conv1' biases: 2.128277e-06 [1.037273e-10] 
Layer 'conv2' weights[0]: 2.952719e-03 [1.477361e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.050376e-09] 
Layer 'conv3' weights[0]: 2.951494e-03 [1.481376e-07] 
Layer 'conv3' biases: 3.512356e-05 [8.362372e-09] 
Layer 'conv4' weights[0]: 2.963943e-03 [1.490773e-07] 
Layer 'conv4' biases: 9.999003e-01 [2.186837e-07] 
Layer 'conv5' weights[0]: 3.107464e-03 [2.312263e-06] 
Layer 'conv5' biases: 9.991505e-01 [2.464649e-06] 
Layer 'fc6' weights[0]: 6.849111e-03 [6.281050e-08] 
Layer 'fc6' biases: 9.999906e-01 [5.596040e-08] 
Layer 'fc7' weights[0]: 7.196246e-03 [1.449099e-07] 
Layer 'fc7' biases: 9.997446e-01 [1.809559e-07] 
Layer 'fc8' weights[0]: 4.677110e-03 [1.351750e-05] 
Layer 'fc8' biases: 2.032982e-02 [1.935524e-05] 
Train error last 800 batches: 0.654701
-------------------------------------------------------
Not saving because 0.477225 > 0.299667 (9.300: -1.18%)
======================================================= (2.384 sec)
25.661... logprob:  0.627912, 0.281250 (1.438 sec)
25.662... logprob:  0.724665, 0.274740 (1.428 sec)
25.663... logprob:  0.537502, 0.247396 (1.425 sec)
25.664... logprob:  0.552924, 0.239583 (1.433 sec)
25.665... logprob:  0.614558, 0.303385 (1.458 sec)
25.666... logprob:  0.642865, 0.285156 (1.450 sec)
25.667... logprob:  0.746205, 0.316406 (1.453 sec)
25.668... logprob:  0.702010, 0.299479 (1.444 sec)
25.669... logprob:  0.664757, 0.305990 (1.454 sec)
25.670... logprob:  0.523592, 0.216146 (1.441 sec)
25.671... logprob:  0.559228, 0.253906 (1.420 sec)
25.672... logprob:  0.576144, 0.261719 (1.423 sec)
25.673... logprob:  0.634293, 0.272135 (1.433 sec)
25.674... logprob:  0.610542, 0.269531 (1.431 sec)
25.675... logprob:  0.600301, 0.278646 (1.463 sec)
25.676... logprob:  0.652299, 0.283854 (1.444 sec)
25.677... logprob:  0.629031, 0.278646 (1.431 sec)
25.678... logprob:  0.679741, 0.282552 (1.478 sec)
25.679... logprob:  0.705875, 0.294271 (1.434 sec)
25.680... logprob:  0.507628, 0.243489 (1.418 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.545850, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.955557e-03 [1.478588e-07] 
Layer 'conv1' biases: 2.129175e-06 [7.043478e-11] 
Layer 'conv2' weights[0]: 2.949791e-03 [1.475887e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.791749e-10] 
Layer 'conv3' weights[0]: 2.948561e-03 [1.477554e-07] 
Layer 'conv3' biases: 3.512549e-05 [6.711462e-09] 
Layer 'conv4' weights[0]: 2.960960e-03 [1.487171e-07] 
Layer 'conv4' biases: 9.998984e-01 [1.633150e-07] 
Layer 'conv5' weights[0]: 3.103454e-03 [2.455835e-06] 
Layer 'conv5' biases: 9.991300e-01 [2.638651e-06] 
Layer 'fc6' weights[0]: 6.848394e-03 [6.286551e-08] 
Layer 'fc6' biases: 9.999903e-01 [5.656667e-08] 
Layer 'fc7' weights[0]: 7.195572e-03 [1.438487e-07] 
Layer 'fc7' biases: 9.997468e-01 [1.992224e-07] 
Layer 'fc8' weights[0]: 4.742557e-03 [1.280280e-05] 
Layer 'fc8' biases: 2.080018e-02 [2.985447e-05] 
Train error last 800 batches: 0.653598
-------------------------------------------------------
Not saving because 0.545850 > 0.299667 (9.300: -1.18%)
======================================================= (2.397 sec)
25.681... logprob:  0.599992, 0.292969 (1.434 sec)
25.682... logprob:  0.582686, 0.266927 (1.440 sec)
25.683... logprob:  0.623332, 0.264323 (1.430 sec)
25.684... logprob:  0.587134, 0.261719 (1.472 sec)
25.685... logprob:  0.560173, 0.238281 (1.435 sec)
25.686... logprob:  0.534214, 0.239583 (1.425 sec)
25.687... logprob:  0.532210, 0.260417 (1.481 sec)
25.688... logprob:  0.649766, 0.311198 (1.426 sec)
25.689... logprob:  0.683199, 0.291667 (1.426 sec)
25.690... logprob:  0.767899, 0.341146 (1.462 sec)
25.691... logprob:  0.668446, 0.309896 (1.426 sec)
25.692... logprob:  0.644431, 0.308594 (1.431 sec)
25.693... logprob:  0.587023, 0.264323 (1.480 sec)
25.694... logprob:  0.618590, 0.244792 (1.430 sec)
25.695... logprob:  0.592701, 0.269531 (1.433 sec)
25.696... logprob:  0.644383, 0.276042 (1.474 sec)
25.697... logprob:  0.644761, 0.286458 (1.435 sec)
25.698... logprob:  0.816890, 0.339844 (1.434 sec)
25.699... logprob:  0.697320, 0.307292 (1.430 sec)
25.700... logprob:  0.681184, 0.300781 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.404950, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.952612e-03 [1.475572e-07] 
Layer 'conv1' biases: 2.130088e-06 [1.123544e-10] 
Layer 'conv2' weights[0]: 2.946838e-03 [1.473822e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.635192e-09] 
Layer 'conv3' weights[0]: 2.945602e-03 [1.481369e-07] 
Layer 'conv3' biases: 3.512230e-05 [1.276687e-08] 
Layer 'conv4' weights[0]: 2.958008e-03 [1.488913e-07] 
Layer 'conv4' biases: 9.998975e-01 [3.168483e-07] 
Layer 'conv5' weights[0]: 3.099766e-03 [3.945727e-06] 
Layer 'conv5' biases: 9.991217e-01 [4.457298e-06] 
Layer 'fc6' weights[0]: 6.847712e-03 [7.626035e-08] 
Layer 'fc6' biases: 9.999900e-01 [7.427729e-08] 
Layer 'fc7' weights[0]: 7.194845e-03 [1.832190e-07] 
Layer 'fc7' biases: 9.997476e-01 [3.170857e-07] 
Layer 'fc8' weights[0]: 4.785987e-03 [1.756035e-05] 
Layer 'fc8' biases: 2.113549e-02 [4.910193e-05] 
Train error last 800 batches: 0.653723
-------------------------------------------------------
Not saving because 0.404950 > 0.299667 (9.300: -1.18%)
======================================================= (2.352 sec)
25.701... logprob:  0.604195, 0.273437 (1.434 sec)
25.702... logprob:  0.743125, 0.300781 (1.481 sec)
25.703... logprob:  0.746380, 0.311198 (1.431 sec)
25.704... logprob:  0.583057, 0.217448 (1.440 sec)
25.705... logprob:  0.639265, 0.266927 (1.473 sec)
25.706... logprob:  0.694592, 0.290365 (1.434 sec)
25.707... logprob:  0.619859, 0.259115 (1.430 sec)
25.708... logprob:  0.619277, 0.253906 (1.428 sec)
25.709... logprob:  0.648072, 0.295573 (1.418 sec)
25.710... logprob:  0.784732, 0.324219 (1.440 sec)
25.711... logprob:  0.753853, 0.339844 (1.468 sec)
25.712... logprob:  0.627712, 0.274740 (1.446 sec)
25.713... logprob:  0.774097, 0.351562 (1.450 sec)
25.714... logprob:  0.655430, 0.304687 (1.451 sec)
25.715... logprob:  0.672235, 0.295573 (1.448 sec)
25.716... logprob:  0.648885, 0.289062 (1.432 sec)
25.717... logprob:  0.684937, 0.298177 (1.425 sec)
25.718... logprob:  0.663434, 0.277344 (1.426 sec)
25.719... logprob:  0.637496, 0.287760 (1.438 sec)
25.720... logprob:  0.568847, 0.253906 (1.438 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.400239, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.949658e-03 [1.475671e-07] 
Layer 'conv1' biases: 2.130278e-06 [6.930744e-11] 
Layer 'conv2' weights[0]: 2.943885e-03 [1.472794e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.597055e-10] 
Layer 'conv3' weights[0]: 2.942663e-03 [1.474572e-07] 
Layer 'conv3' biases: 3.514809e-05 [6.112741e-09] 
Layer 'conv4' weights[0]: 2.955059e-03 [1.482299e-07] 
Layer 'conv4' biases: 9.998984e-01 [1.421799e-07] 
Layer 'conv5' weights[0]: 3.097864e-03 [2.040107e-06] 
Layer 'conv5' biases: 9.991833e-01 [2.175208e-06] 
Layer 'fc6' weights[0]: 6.847004e-03 [5.896064e-08] 
Layer 'fc6' biases: 9.999903e-01 [5.064560e-08] 
Layer 'fc7' weights[0]: 7.194164e-03 [1.321325e-07] 
Layer 'fc7' biases: 9.997430e-01 [1.501565e-07] 
Layer 'fc8' weights[0]: 4.653924e-03 [1.126374e-05] 
Layer 'fc8' biases: 2.015692e-02 [8.240385e-06] 
Train error last 800 batches: 0.653623
-------------------------------------------------------
Not saving because 0.400239 > 0.299667 (9.300: -1.18%)
======================================================= (2.378 sec)
25.721... logprob:  0.657940, 0.278646 (1.466 sec)
25.722... logprob:  0.686154, 0.302083 (1.451 sec)
25.723... logprob:  0.694417, 0.312500 (1.441 sec)
25.724... logprob:  0.647251, 0.282552 (1.466 sec)
25.725... logprob:  0.649981, 0.286458 (1.430 sec)
25.726... logprob:  0.548716, 0.240885 (1.424 sec)
25.727... logprob:  0.674724, 0.299479 (1.428 sec)
25.728... logprob:  0.719380, 0.308594 (1.475 sec)
25.729... logprob:  0.677087, 0.292969 (1.435 sec)
25.730... logprob:  0.704220, 0.303385 (1.476 sec)
25.731... logprob:  0.660479, 0.295573 (1.442 sec)
25.732... logprob:  0.585650, 0.268229 (1.439 sec)
25.733... logprob:  0.761064, 0.308594 (1.478 sec)
25.734... logprob:  0.627827, 0.270833 (1.429 sec)
25.735... logprob:  0.742575, 0.317708 (1.539 sec)
25.736... logprob:  0.933148, 0.360677 (1.430 sec)
25.737... logprob:  0.707267, 0.313802 (1.432 sec)
25.738... logprob:  0.685468, 0.281250 (1.428 sec)
25.739... logprob:  0.759011, 0.333333 (1.477 sec)
25.740... logprob:  0.609495, 0.264323 (1.438 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.514541, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.946711e-03 [1.473849e-07] 
Layer 'conv1' biases: 2.130660e-06 [9.593072e-11] 
Layer 'conv2' weights[0]: 2.940940e-03 [1.471161e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.229198e-09] 
Layer 'conv3' weights[0]: 2.939726e-03 [1.475243e-07] 
Layer 'conv3' biases: 3.516798e-05 [9.567469e-09] 
Layer 'conv4' weights[0]: 2.952117e-03 [1.484528e-07] 
Layer 'conv4' biases: 9.998984e-01 [2.615246e-07] 
Layer 'conv5' weights[0]: 3.095109e-03 [2.917049e-06] 
Layer 'conv5' biases: 9.991757e-01 [3.185912e-06] 
Layer 'fc6' weights[0]: 6.846309e-03 [7.077941e-08] 
Layer 'fc6' biases: 9.999901e-01 [6.586669e-08] 
Layer 'fc7' weights[0]: 7.193421e-03 [1.655630e-07] 
Layer 'fc7' biases: 9.997428e-01 [2.389789e-07] 
Layer 'fc8' weights[0]: 4.668192e-03 [1.564937e-05] 
Layer 'fc8' biases: 2.029344e-02 [3.800633e-05] 
Train error last 800 batches: 0.654035
-------------------------------------------------------
Not saving because 0.514541 > 0.299667 (9.300: -1.18%)
======================================================= (2.351 sec)
25.741... logprob:  0.614645, 0.270833 (1.439 sec)
25.742... logprob:  0.688977, 0.317708 (1.484 sec)
25.743... logprob:  0.615895, 0.265625 (1.424 sec)
25.744... logprob:  0.671879, 0.309896 (1.426 sec)
25.745... logprob:  0.747574, 0.317708 (1.432 sec)
25.746... logprob:  0.706792, 0.333333 (1.422 sec)
25.747... logprob:  0.658152, 0.274740 (1.426 sec)
25.748... logprob:  0.661199, 0.307292 (1.479 sec)
25.749... logprob:  0.607650, 0.250000 (1.429 sec)
25.750... logprob:  0.646971, 0.260417 (1.444 sec)
25.751... logprob:  0.528386, 0.246094 (1.474 sec)
25.752... logprob:  0.727476, 0.295573 (1.432 sec)
25.753... logprob:  0.639337, 0.285156 (1.432 sec)
25.754... logprob:  0.715096, 0.330729 (1.424 sec)
25.755... logprob:  0.737211, 0.308594 (1.418 sec)
25.756... logprob:  0.660854, 0.299479 (1.432 sec)
25.757... logprob:  0.723964, 0.339844 (1.473 sec)
25.758... logprob:  0.612583, 0.281250 (1.439 sec)
25.759... logprob:  0.582024, 0.272135 (1.447 sec)
25.760... logprob:  0.621731, 0.264323 (1.459 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.478451, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.943757e-03 [1.473590e-07] 
Layer 'conv1' biases: 2.130757e-06 [6.525880e-11] 
Layer 'conv2' weights[0]: 2.938016e-03 [1.470405e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.115187e-10] 
Layer 'conv3' weights[0]: 2.936763e-03 [1.472350e-07] 
Layer 'conv3' biases: 3.517706e-05 [7.565848e-09] 
Layer 'conv4' weights[0]: 2.949150e-03 [1.482112e-07] 
Layer 'conv4' biases: 9.998991e-01 [1.887582e-07] 
Layer 'conv5' weights[0]: 3.093226e-03 [2.657822e-06] 
Layer 'conv5' biases: 9.991608e-01 [2.855237e-06] 
Layer 'fc6' weights[0]: 6.845621e-03 [6.401930e-08] 
Layer 'fc6' biases: 9.999902e-01 [5.722730e-08] 
Layer 'fc7' weights[0]: 7.192689e-03 [1.492777e-07] 
Layer 'fc7' biases: 9.997442e-01 [2.140133e-07] 
Layer 'fc8' weights[0]: 4.700433e-03 [1.385753e-05] 
Layer 'fc8' biases: 2.059251e-02 [3.035234e-05] 
Train error last 800 batches: 0.654375
-------------------------------------------------------
Not saving because 0.478451 > 0.299667 (9.300: -1.18%)
======================================================= (2.343 sec)
25.761... logprob:  0.619505, 0.278646 (1.451 sec)
25.762... logprob:  0.695444, 0.294271 (1.433 sec)
25.763... logprob:  0.740779, 0.312500 (1.425 sec)
25.764... logprob:  0.737333, 0.324219 (1.424 sec)
25.765... logprob:  0.550203, 0.248698 (1.430 sec)
25.766... logprob:  0.705416, 0.299479 (1.483 sec)
25.767... logprob:  0.531874, 0.220052 (1.454 sec)
25.768... logprob:  0.571282, 0.263021 (1.461 sec)
25.769... logprob:  0.679782, 0.309896 (1.463 sec)
25.770... logprob:  0.516738, 0.233073 (1.481 sec)
25.771... logprob:  0.768333, 0.342448 (1.452 sec)
25.772... logprob:  0.625378, 0.281250 (1.436 sec)
25.773... logprob:  0.611452, 0.272135 (1.445 sec)
25.774... logprob:  0.681627, 0.317708 (1.454 sec)
25.775... logprob:  0.630334, 0.298177 (1.459 sec)
25.776... logprob:  0.723605, 0.316406 (1.475 sec)
25.777... logprob:  0.640730, 0.315104 (1.470 sec)
25.778... logprob:  0.693129, 0.312500 (1.469 sec)
25.779... logprob:  0.754643, 0.309896 (1.487 sec)
25.780... logprob:  0.647215, 0.313802 (1.446 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.419786, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.940815e-03 [1.471087e-07] 
Layer 'conv1' biases: 2.130913e-06 [6.525750e-11] 
Layer 'conv2' weights[0]: 2.935061e-03 [1.468256e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.173110e-10] 
Layer 'conv3' weights[0]: 2.933789e-03 [1.470038e-07] 
Layer 'conv3' biases: 3.517887e-05 [6.425408e-09] 
Layer 'conv4' weights[0]: 2.946221e-03 [1.478607e-07] 
Layer 'conv4' biases: 9.998988e-01 [1.702021e-07] 
Layer 'conv5' weights[0]: 3.090688e-03 [2.326598e-06] 
Layer 'conv5' biases: 9.991513e-01 [2.482207e-06] 
Layer 'fc6' weights[0]: 6.844918e-03 [6.349424e-08] 
Layer 'fc6' biases: 9.999903e-01 [5.697650e-08] 
Layer 'fc7' weights[0]: 7.192003e-03 [1.491108e-07] 
Layer 'fc7' biases: 9.997450e-01 [2.086645e-07] 
Layer 'fc8' weights[0]: 4.744712e-03 [1.689852e-05] 
Layer 'fc8' biases: 2.091247e-02 [5.030687e-05] 
Train error last 800 batches: 0.654222
-------------------------------------------------------
Not saving because 0.419786 > 0.299667 (9.300: -1.18%)
======================================================= (2.360 sec)
25.781... logprob:  0.617374, 0.264323 (1.450 sec)
25.782... logprob:  0.600712, 0.255208 (1.451 sec)
25.783... logprob:  0.644629, 0.290365 (1.456 sec)
25.784... logprob:  0.639422, 0.291667 (1.455 sec)
25.785... logprob:  0.745847, 0.363281 (1.479 sec)
25.786... logprob:  0.719412, 0.324219 (1.472 sec)
25.787... logprob:  0.717632, 0.299479 (1.463 sec)
25.788... logprob:  0.715037, 0.312500 (1.493 sec)
25.789... logprob:  0.534699, 0.251302 (1.448 sec)
25.790... logprob:  0.686061, 0.303385 (1.448 sec)
25.791... logprob:  0.711066, 0.304687 (1.442 sec)
25.792... logprob:  0.616390, 0.269531 (1.460 sec)
25.793... logprob:  0.555816, 0.255208 (1.452 sec)
25.794... logprob:  0.639288, 0.285156 (1.488 sec)
25.795... logprob:  0.667077, 0.277344 (1.465 sec)
25.796... logprob:  0.660440, 0.312500 (1.451 sec)
25.797... logprob:  0.575741, 0.236979 (1.492 sec)
25.798... logprob:  0.613410, 0.264323 (1.446 sec)
25.799... logprob:  0.540457, 0.243490 (1.442 sec)
25.800... logprob:  0.546299, 0.230469 (1.403 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.436363, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.937882e-03 [1.470718e-07] 
Layer 'conv1' biases: 2.131143e-06 [7.084157e-11] 
Layer 'conv2' weights[0]: 2.932135e-03 [1.467405e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.113649e-09] 
Layer 'conv3' weights[0]: 2.930894e-03 [1.471689e-07] 
Layer 'conv3' biases: 3.516762e-05 [9.518728e-09] 
Layer 'conv4' weights[0]: 2.943250e-03 [1.483822e-07] 
Layer 'conv4' biases: 9.999011e-01 [2.612661e-07] 
Layer 'conv5' weights[0]: 3.089233e-03 [3.210550e-06] 
Layer 'conv5' biases: 9.991500e-01 [3.528428e-06] 
Layer 'fc6' weights[0]: 6.844198e-03 [7.169994e-08] 
Layer 'fc6' biases: 9.999904e-01 [6.744749e-08] 
Layer 'fc7' weights[0]: 7.191273e-03 [1.686780e-07] 
Layer 'fc7' biases: 9.997450e-01 [2.796055e-07] 
Layer 'fc8' weights[0]: 4.756944e-03 [1.656079e-05] 
Layer 'fc8' biases: 2.101622e-02 [4.464064e-05] 
Train error last 800 batches: 0.653900
-------------------------------------------------------
Not saving because 0.436363 > 0.299667 (9.300: -1.18%)
======================================================= (2.380 sec)
26.1... logprob:  0.653282, 0.278646 (1.403 sec)
26.2... logprob:  0.651966, 0.322917 (1.449 sec)
26.3... logprob:  0.648714, 0.302083 (1.410 sec)
26.4... logprob:  0.672325, 0.290365 (1.429 sec)
26.5... logprob:  0.548313, 0.264323 (1.433 sec)
26.6... logprob:  0.615547, 0.294271 (1.392 sec)
26.7... logprob:  0.561232, 0.242187 (1.416 sec)
26.8... logprob:  0.619999, 0.251302 (1.391 sec)
26.9... logprob:  0.555780, 0.269531 (1.402 sec)
26.10... logprob:  0.609355, 0.286458 (1.402 sec)
26.11... logprob:  0.539092, 0.264323 (1.442 sec)
26.12... logprob:  0.715834, 0.283854 (1.392 sec)
26.13... logprob:  0.669911, 0.300781 (1.418 sec)
26.14... logprob:  0.612567, 0.287760 (1.398 sec)
26.15... logprob:  0.705582, 0.285156 (1.404 sec)
26.16... logprob:  0.626806, 0.273437 (1.403 sec)
26.17... logprob:  0.675579, 0.309896 (1.391 sec)
26.18... logprob:  0.519480, 0.244792 (1.393 sec)
26.19... logprob:  0.572424, 0.276042 (1.395 sec)
26.20... logprob:  0.625473, 0.302083 (1.397 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.357613, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.934936e-03 [1.468019e-07] 
Layer 'conv1' biases: 2.131110e-06 [6.772673e-11] 
Layer 'conv2' weights[0]: 2.929193e-03 [1.465426e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.310445e-10] 
Layer 'conv3' weights[0]: 2.927962e-03 [1.466935e-07] 
Layer 'conv3' biases: 3.515125e-05 [6.215841e-09] 
Layer 'conv4' weights[0]: 2.940307e-03 [1.474594e-07] 
Layer 'conv4' biases: 9.999006e-01 [1.430540e-07] 
Layer 'conv5' weights[0]: 3.086602e-03 [2.293747e-06] 
Layer 'conv5' biases: 9.991297e-01 [2.525174e-06] 
Layer 'fc6' weights[0]: 6.843515e-03 [5.813084e-08] 
Layer 'fc6' biases: 9.999903e-01 [5.044152e-08] 
Layer 'fc7' weights[0]: 7.190541e-03 [1.309305e-07] 
Layer 'fc7' biases: 9.997471e-01 [1.651454e-07] 
Layer 'fc8' weights[0]: 4.821035e-03 [1.195587e-05] 
Layer 'fc8' biases: 2.145800e-02 [2.441728e-05] 
Train error last 800 batches: 0.653414
-------------------------------------------------------
Not saving because 0.357613 > 0.299667 (9.300: -1.18%)
======================================================= (2.379 sec)
26.21... logprob:  0.746508, 0.296875 (1.403 sec)
26.22... logprob:  0.719468, 0.315104 (1.412 sec)
26.23... logprob:  0.714540, 0.295573 (1.416 sec)
26.24... logprob:  0.490175, 0.217448 (1.410 sec)
26.25... logprob:  0.531217, 0.218750 (1.405 sec)
26.26... logprob:  0.647856, 0.283854 (1.442 sec)
26.27... logprob:  0.647037, 0.285156 (1.386 sec)
26.28... logprob:  0.724433, 0.315104 (1.412 sec)
26.29... logprob:  0.602160, 0.256510 (1.424 sec)
26.30... logprob:  0.673068, 0.313802 (1.419 sec)
26.31... logprob:  0.748281, 0.326823 (1.402 sec)
26.32... logprob:  0.647775, 0.281250 (1.391 sec)
26.33... logprob:  0.792555, 0.333333 (1.445 sec)
26.34... logprob:  0.713057, 0.295573 (1.386 sec)
26.35... logprob:  0.542028, 0.257812 (1.394 sec)
26.36... logprob:  0.686406, 0.277344 (1.395 sec)
26.37... logprob:  0.619966, 0.283854 (1.405 sec)
26.38... logprob:  0.613072, 0.303385 (1.397 sec)
26.39... logprob:  0.738878, 0.304688 (1.435 sec)
26.40... logprob:  0.652615, 0.266927 (1.402 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.554701, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.932011e-03 [1.466289e-07] 
Layer 'conv1' biases: 2.131401e-06 [1.337374e-10] 
Layer 'conv2' weights[0]: 2.926267e-03 [1.463485e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.582772e-09] 
Layer 'conv3' weights[0]: 2.925052e-03 [1.472004e-07] 
Layer 'conv3' biases: 3.516351e-05 [1.247881e-08] 
Layer 'conv4' weights[0]: 2.937376e-03 [1.480014e-07] 
Layer 'conv4' biases: 9.999019e-01 [3.306140e-07] 
Layer 'conv5' weights[0]: 3.084742e-03 [3.490143e-06] 
Layer 'conv5' biases: 9.991689e-01 [3.736463e-06] 
Layer 'fc6' weights[0]: 6.842825e-03 [7.244297e-08] 
Layer 'fc6' biases: 9.999902e-01 [6.803257e-08] 
Layer 'fc7' weights[0]: 7.189843e-03 [1.713542e-07] 
Layer 'fc7' biases: 9.997437e-01 [2.731373e-07] 
Layer 'fc8' weights[0]: 4.731379e-03 [1.681782e-05] 
Layer 'fc8' biases: 2.081452e-02 [4.662445e-05] 
Train error last 800 batches: 0.653194
-------------------------------------------------------
Not saving because 0.554701 > 0.299667 (9.300: -1.18%)
======================================================= (2.368 sec)
26.41... logprob:  0.598718, 0.265625 (1.427 sec)
26.42... logprob:  0.571652, 0.263021 (1.418 sec)
26.43... logprob:  0.591745, 0.274740 (1.433 sec)
26.44... logprob:  0.662738, 0.282552 (1.428 sec)
26.45... logprob:  0.573738, 0.265625 (1.387 sec)
26.46... logprob:  0.698784, 0.311198 (1.397 sec)
26.47... logprob:  0.612271, 0.277344 (1.391 sec)
26.48... logprob:  0.790062, 0.298177 (1.421 sec)
26.49... logprob:  0.723447, 0.290365 (1.411 sec)
26.50... logprob:  0.614747, 0.246094 (1.424 sec)
26.51... logprob:  0.773014, 0.320312 (1.419 sec)
26.52... logprob:  0.748091, 0.351562 (1.399 sec)
26.53... logprob:  0.574588, 0.243490 (1.437 sec)
26.54... logprob:  0.633846, 0.266927 (1.382 sec)
26.55... logprob:  0.657143, 0.291667 (1.393 sec)
26.56... logprob:  0.636899, 0.302083 (1.395 sec)
26.57... logprob:  0.765832, 0.316406 (1.429 sec)
26.58... logprob:  0.610730, 0.278646 (1.398 sec)
26.59... logprob:  0.586486, 0.246094 (1.464 sec)
26.60... logprob:  0.806773, 0.352864 (1.412 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.465384, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.929098e-03 [1.464825e-07] 
Layer 'conv1' biases: 2.131818e-06 [8.108079e-11] 
Layer 'conv2' weights[0]: 2.923345e-03 [1.462295e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.031337e-09] 
Layer 'conv3' weights[0]: 2.922115e-03 [1.464946e-07] 
Layer 'conv3' biases: 3.519626e-05 [8.156781e-09] 
Layer 'conv4' weights[0]: 2.934437e-03 [1.471826e-07] 
Layer 'conv4' biases: 9.999023e-01 [1.899183e-07] 
Layer 'conv5' weights[0]: 3.082434e-03 [2.521327e-06] 
Layer 'conv5' biases: 9.991899e-01 [2.785972e-06] 
Layer 'fc6' weights[0]: 6.842126e-03 [6.386982e-08] 
Layer 'fc6' biases: 9.999900e-01 [5.688150e-08] 
Layer 'fc7' weights[0]: 7.189118e-03 [1.449733e-07] 
Layer 'fc7' biases: 9.997424e-01 [1.829026e-07] 
Layer 'fc8' weights[0]: 4.690864e-03 [1.267435e-05] 
Layer 'fc8' biases: 2.046248e-02 [1.735745e-05] 
Train error last 800 batches: 0.653745
-------------------------------------------------------
Not saving because 0.465384 > 0.299667 (9.300: -1.18%)
======================================================= (2.404 sec)
26.61... logprob:  0.610797, 0.265625 (1.443 sec)
26.62... logprob:  0.661577, 0.315104 (1.459 sec)
26.63... logprob:  0.685304, 0.302083 (1.430 sec)
26.64... logprob:  0.717371, 0.341146 (1.410 sec)
26.65... logprob:  0.616807, 0.276042 (1.396 sec)
26.66... logprob:  0.602446, 0.246094 (1.437 sec)
26.67... logprob:  0.603926, 0.270833 (1.383 sec)
26.68... logprob:  0.625301, 0.299479 (1.390 sec)
26.69... logprob:  0.690696, 0.320312 (1.423 sec)
26.70... logprob:  0.603693, 0.270833 (1.431 sec)
26.71... logprob:  0.544645, 0.240885 (1.453 sec)
26.72... logprob:  0.707989, 0.307292 (1.399 sec)
26.73... logprob:  0.722774, 0.278646 (1.422 sec)
26.74... logprob:  0.742013, 0.317708 (1.412 sec)
26.75... logprob:  0.589695, 0.240885 (1.408 sec)
26.76... logprob:  0.680407, 0.283854 (1.428 sec)
26.77... logprob:  0.579887, 0.265625 (1.424 sec)
26.78... logprob:  0.695258, 0.277344 (1.446 sec)
26.79... logprob:  0.660706, 0.291667 (1.407 sec)
26.80... logprob:  0.685677, 0.315104 (1.416 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.393264, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.926157e-03 [1.463396e-07] 
Layer 'conv1' biases: 2.131731e-06 [5.482079e-11] 
Layer 'conv2' weights[0]: 2.920416e-03 [1.461045e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.650731e-10] 
Layer 'conv3' weights[0]: 2.919174e-03 [1.462449e-07] 
Layer 'conv3' biases: 3.520965e-05 [6.583326e-09] 
Layer 'conv4' weights[0]: 2.931493e-03 [1.470063e-07] 
Layer 'conv4' biases: 9.999029e-01 [1.670932e-07] 
Layer 'conv5' weights[0]: 3.080227e-03 [2.156373e-06] 
Layer 'conv5' biases: 9.991756e-01 [2.272294e-06] 
Layer 'fc6' weights[0]: 6.841423e-03 [6.240731e-08] 
Layer 'fc6' biases: 9.999901e-01 [5.492982e-08] 
Layer 'fc7' weights[0]: 7.188394e-03 [1.457184e-07] 
Layer 'fc7' biases: 9.997433e-01 [1.899781e-07] 
Layer 'fc8' weights[0]: 4.725358e-03 [1.406225e-05] 
Layer 'fc8' biases: 2.074750e-02 [2.903042e-05] 
Train error last 800 batches: 0.654084
-------------------------------------------------------
Not saving because 0.393264 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
26.81... logprob:  0.604547, 0.278646 (1.417 sec)
26.82... logprob:  0.495487, 0.229167 (1.419 sec)
26.83... logprob:  0.697635, 0.317708 (1.399 sec)
26.84... logprob:  0.656151, 0.259115 (1.464 sec)
26.85... logprob:  0.563022, 0.246094 (1.412 sec)
26.86... logprob:  0.654464, 0.294271 (1.414 sec)
26.87... logprob:  0.843950, 0.345052 (1.409 sec)
26.88... logprob:  0.699989, 0.283854 (1.403 sec)
26.89... logprob:  0.711698, 0.316406 (1.427 sec)
26.90... logprob:  0.763637, 0.339844 (1.386 sec)
26.91... logprob:  0.589637, 0.256510 (1.394 sec)
26.92... logprob:  0.700943, 0.312500 (1.393 sec)
26.93... logprob:  0.777699, 0.341146 (1.392 sec)
26.94... logprob:  0.645148, 0.281250 (1.394 sec)
26.95... logprob:  0.614140, 0.290365 (1.400 sec)
26.96... logprob:  0.774816, 0.328125 (1.396 sec)
26.97... logprob:  0.646350, 0.285156 (1.390 sec)
26.98... logprob:  0.613687, 0.270833 (1.433 sec)
26.99... logprob:  0.667428, 0.313802 (1.399 sec)
26.100... logprob:  0.535912, 0.235677 (1.397 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.453763, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.923230e-03 [1.462233e-07] 
Layer 'conv1' biases: 2.131958e-06 [5.925109e-11] 
Layer 'conv2' weights[0]: 2.917508e-03 [1.459464e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.116874e-10] 
Layer 'conv3' weights[0]: 2.916273e-03 [1.460985e-07] 
Layer 'conv3' biases: 3.521103e-05 [6.468065e-09] 
Layer 'conv4' weights[0]: 2.928596e-03 [1.468827e-07] 
Layer 'conv4' biases: 9.999022e-01 [1.614450e-07] 
Layer 'conv5' weights[0]: 3.076954e-03 [2.296073e-06] 
Layer 'conv5' biases: 9.991910e-01 [2.491853e-06] 
Layer 'fc6' weights[0]: 6.840730e-03 [5.882950e-08] 
Layer 'fc6' biases: 9.999902e-01 [5.009169e-08] 
Layer 'fc7' weights[0]: 7.187670e-03 [1.338482e-07] 
Layer 'fc7' biases: 9.997416e-01 [1.589584e-07] 
Layer 'fc8' weights[0]: 4.686077e-03 [1.171293e-05] 
Layer 'fc8' biases: 2.046188e-02 [1.572852e-05] 
Train error last 800 batches: 0.653620
-------------------------------------------------------
Not saving because 0.453763 > 0.299667 (9.300: -1.18%)
======================================================= (2.377 sec)
26.101... logprob:  0.603291, 0.266927 (1.452 sec)
26.102... logprob:  0.824927, 0.335938 (1.387 sec)
26.103... logprob:  0.723826, 0.325521 (1.395 sec)
26.104... logprob:  0.707382, 0.322917 (1.394 sec)
26.105... logprob:  0.820917, 0.338542 (1.386 sec)
26.106... logprob:  0.643156, 0.270833 (1.387 sec)
26.107... logprob:  0.631712, 0.303385 (1.431 sec)
26.108... logprob:  0.720052, 0.313802 (1.393 sec)
26.109... logprob:  0.600435, 0.266927 (1.403 sec)
26.110... logprob:  0.709101, 0.281250 (1.400 sec)
26.111... logprob:  0.619225, 0.257812 (1.392 sec)
26.112... logprob:  0.641385, 0.286458 (1.396 sec)
26.113... logprob:  0.625544, 0.273437 (1.393 sec)
26.114... logprob:  0.578659, 0.247396 (1.424 sec)
26.115... logprob:  0.708243, 0.273438 (1.408 sec)
26.116... logprob:  0.637126, 0.281250 (1.398 sec)
26.117... logprob:  0.671849, 0.285156 (1.443 sec)
26.118... logprob:  0.630895, 0.270833 (1.383 sec)
26.119... logprob:  0.614005, 0.285156 (1.391 sec)
26.120... logprob:  0.779323, 0.325521 (1.394 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.486444, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.920318e-03 [1.460679e-07] 
Layer 'conv1' biases: 2.131821e-06 [1.052024e-10] 
Layer 'conv2' weights[0]: 2.914580e-03 [1.458144e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.138779e-09] 
Layer 'conv3' weights[0]: 2.913349e-03 [1.461763e-07] 
Layer 'conv3' biases: 3.521457e-05 [9.462095e-09] 
Layer 'conv4' weights[0]: 2.925658e-03 [1.471345e-07] 
Layer 'conv4' biases: 9.999017e-01 [2.325504e-07] 
Layer 'conv5' weights[0]: 3.073695e-03 [2.402450e-06] 
Layer 'conv5' biases: 9.991920e-01 [2.616521e-06] 
Layer 'fc6' weights[0]: 6.840034e-03 [6.396409e-08] 
Layer 'fc6' biases: 9.999900e-01 [5.648180e-08] 
Layer 'fc7' weights[0]: 7.186937e-03 [1.474937e-07] 
Layer 'fc7' biases: 9.997417e-01 [1.867116e-07] 
Layer 'fc8' weights[0]: 4.695359e-03 [1.340716e-05] 
Layer 'fc8' biases: 2.052297e-02 [2.170485e-05] 
Train error last 800 batches: 0.654044
-------------------------------------------------------
Not saving because 0.486444 > 0.299667 (9.300: -1.18%)
======================================================= (2.359 sec)
26.121... logprob:  0.660186, 0.285156 (1.400 sec)
26.122... logprob:  0.754554, 0.328125 (1.445 sec)
26.123... logprob:  0.655767, 0.273437 (1.386 sec)
26.124... logprob:  0.524197, 0.227865 (1.398 sec)
26.125... logprob:  0.851011, 0.365885 (1.395 sec)
26.126... logprob:  0.690692, 0.322917 (1.384 sec)
26.127... logprob:  0.647108, 0.311198 (1.393 sec)
26.128... logprob:  0.761853, 0.304687 (1.414 sec)
26.129... logprob:  0.793253, 0.324219 (1.415 sec)
26.130... logprob:  0.594834, 0.252604 (1.409 sec)
26.131... logprob:  0.630792, 0.283854 (1.401 sec)
26.132... logprob:  0.729805, 0.299479 (1.429 sec)
26.133... logprob:  0.697586, 0.329427 (1.391 sec)
26.134... logprob:  0.658245, 0.283854 (1.394 sec)
26.135... logprob:  0.637545, 0.279948 (1.397 sec)
26.136... logprob:  0.784011, 0.324219 (1.391 sec)
26.137... logprob:  0.639499, 0.285156 (1.389 sec)
26.138... logprob:  0.603834, 0.269531 (1.438 sec)
26.139... logprob:  0.691782, 0.299479 (1.395 sec)
26.140... logprob:  0.690559, 0.298177 (1.411 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.513322, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.917392e-03 [1.458857e-07] 
Layer 'conv1' biases: 2.132329e-06 [8.640403e-11] 
Layer 'conv2' weights[0]: 2.911662e-03 [1.456463e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.006899e-09] 
Layer 'conv3' weights[0]: 2.910439e-03 [1.459285e-07] 
Layer 'conv3' biases: 3.520981e-05 [7.358854e-09] 
Layer 'conv4' weights[0]: 2.922724e-03 [1.467128e-07] 
Layer 'conv4' biases: 9.999003e-01 [1.750848e-07] 
Layer 'conv5' weights[0]: 3.069915e-03 [2.324806e-06] 
Layer 'conv5' biases: 9.991939e-01 [2.515945e-06] 
Layer 'fc6' weights[0]: 6.839330e-03 [6.098284e-08] 
Layer 'fc6' biases: 9.999902e-01 [5.279377e-08] 
Layer 'fc7' weights[0]: 7.186200e-03 [1.373875e-07] 
Layer 'fc7' biases: 9.997416e-01 [1.566258e-07] 
Layer 'fc8' weights[0]: 4.685701e-03 [1.169855e-05] 
Layer 'fc8' biases: 2.054042e-02 [9.617167e-06] 
Train error last 800 batches: 0.654118
-------------------------------------------------------
Not saving because 0.513322 > 0.299667 (9.300: -1.18%)
======================================================= (2.360 sec)
26.141... logprob:  0.719809, 0.335937 (1.440 sec)
26.142... logprob:  0.641080, 0.273437 (1.391 sec)
26.143... logprob:  0.570347, 0.256510 (1.419 sec)
26.144... logprob:  0.708963, 0.294271 (1.408 sec)
26.145... logprob:  0.541603, 0.261719 (1.415 sec)
26.146... logprob:  0.703012, 0.315104 (1.411 sec)
26.147... logprob:  0.480823, 0.207031 (1.423 sec)
26.148... logprob:  0.620287, 0.268229 (1.386 sec)
26.149... logprob:  0.641631, 0.269531 (1.394 sec)
26.150... logprob:  0.514502, 0.218750 (1.398 sec)
26.151... logprob:  0.614640, 0.289062 (1.397 sec)
26.152... logprob:  0.871354, 0.361979 (1.385 sec)
26.153... logprob:  0.550750, 0.240885 (1.445 sec)
26.154... logprob:  0.809618, 0.346354 (1.401 sec)
26.155... logprob:  0.680721, 0.294271 (1.415 sec)
26.156... logprob:  0.561438, 0.259115 (1.429 sec)
26.157... logprob:  0.580629, 0.234375 (1.390 sec)
26.158... logprob:  0.636130, 0.299479 (1.402 sec)
26.159... logprob:  0.678782, 0.276042 (1.400 sec)
26.160... logprob:  0.705009, 0.300781 (1.393 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.514748, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.914480e-03 [1.458564e-07] 
Layer 'conv1' biases: 2.132800e-06 [8.883430e-11] 
Layer 'conv2' weights[0]: 2.908753e-03 [1.455162e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.602395e-10] 
Layer 'conv3' weights[0]: 2.907515e-03 [1.457021e-07] 
Layer 'conv3' biases: 3.521197e-05 [5.672191e-09] 
Layer 'conv4' weights[0]: 2.919822e-03 [1.463962e-07] 
Layer 'conv4' biases: 9.998991e-01 [1.501201e-07] 
Layer 'conv5' weights[0]: 3.066370e-03 [1.973864e-06] 
Layer 'conv5' biases: 9.991642e-01 [2.143856e-06] 
Layer 'fc6' weights[0]: 6.838634e-03 [6.194356e-08] 
Layer 'fc6' biases: 9.999901e-01 [5.441671e-08] 
Layer 'fc7' weights[0]: 7.185441e-03 [1.407646e-07] 
Layer 'fc7' biases: 9.997436e-01 [1.682971e-07] 
Layer 'fc8' weights[0]: 4.756397e-03 [1.238684e-05] 
Layer 'fc8' biases: 2.105300e-02 [1.961558e-05] 
Train error last 800 batches: 0.654540
-------------------------------------------------------
Not saving because 0.514748 > 0.299667 (9.300: -1.18%)
======================================================= (2.385 sec)
26.161... logprob:  0.628295, 0.285156 (1.405 sec)
26.162... logprob:  0.855703, 0.389323 (1.406 sec)
26.163... logprob:  0.678777, 0.296875 (1.428 sec)
26.164... logprob:  0.643946, 0.260417 (1.417 sec)
26.165... logprob:  0.630886, 0.290365 (1.425 sec)
26.166... logprob:  0.688746, 0.329427 (1.449 sec)
26.167... logprob:  0.566028, 0.226562 (1.441 sec)
26.168... logprob:  0.608311, 0.287760 (1.425 sec)
26.169... logprob:  0.561017, 0.244792 (1.458 sec)
26.170... logprob:  0.697342, 0.326823 (1.397 sec)
26.171... logprob:  0.672497, 0.260417 (1.415 sec)
26.172... logprob:  0.622833, 0.278646 (1.412 sec)
26.173... logprob:  0.634472, 0.290365 (1.417 sec)
26.174... logprob:  0.744187, 0.305990 (1.399 sec)
26.175... logprob:  0.657769, 0.276042 (1.468 sec)
26.176... logprob:  0.655442, 0.259115 (1.408 sec)
26.177... logprob:  0.511015, 0.220052 (1.424 sec)
26.178... logprob:  0.563370, 0.260417 (1.457 sec)
26.179... logprob:  0.645836, 0.292969 (1.411 sec)
26.180... logprob:  0.609898, 0.256510 (1.415 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.516558, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.911559e-03 [1.457988e-07] 
Layer 'conv1' biases: 2.133335e-06 [8.519724e-11] 
Layer 'conv2' weights[0]: 2.905862e-03 [1.454358e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.842807e-10] 
Layer 'conv3' weights[0]: 2.904627e-03 [1.455363e-07] 
Layer 'conv3' biases: 3.520906e-05 [5.764999e-09] 
Layer 'conv4' weights[0]: 2.916893e-03 [1.464089e-07] 
Layer 'conv4' biases: 9.998993e-01 [1.420975e-07] 
Layer 'conv5' weights[0]: 3.063889e-03 [2.172357e-06] 
Layer 'conv5' biases: 9.991696e-01 [2.407990e-06] 
Layer 'fc6' weights[0]: 6.837939e-03 [6.316406e-08] 
Layer 'fc6' biases: 9.999900e-01 [5.603122e-08] 
Layer 'fc7' weights[0]: 7.184704e-03 [1.431346e-07] 
Layer 'fc7' biases: 9.997425e-01 [1.897433e-07] 
Layer 'fc8' weights[0]: 4.736460e-03 [1.365692e-05] 
Layer 'fc8' biases: 2.093495e-02 [2.924372e-05] 
Train error last 800 batches: 0.654122
-------------------------------------------------------
Not saving because 0.516558 > 0.299667 (9.300: -1.18%)
======================================================= (2.397 sec)
26.181... logprob:  0.787441, 0.315104 (1.421 sec)
26.182... logprob:  0.571162, 0.257812 (1.415 sec)
26.183... logprob:  0.668934, 0.304688 (1.418 sec)
26.184... logprob:  0.721632, 0.299479 (1.412 sec)
26.185... logprob:  0.483783, 0.216146 (1.392 sec)
26.186... logprob:  0.593283, 0.270833 (1.400 sec)
26.187... logprob:  0.773269, 0.321615 (1.401 sec)
26.188... logprob:  0.779623, 0.330729 (1.398 sec)
26.189... logprob:  0.738602, 0.350260 (1.389 sec)
26.190... logprob:  0.596610, 0.260417 (1.429 sec)
26.191... logprob:  0.664058, 0.286458 (1.405 sec)
26.192... logprob:  0.692615, 0.330729 (1.418 sec)
26.193... logprob:  0.567959, 0.248698 (1.416 sec)
26.194... logprob:  0.640772, 0.287760 (1.406 sec)
26.195... logprob:  0.659194, 0.305990 (1.396 sec)
26.196... logprob:  0.614223, 0.277344 (1.399 sec)
26.197... logprob:  0.666002, 0.313802 (1.395 sec)
26.198... logprob:  0.533694, 0.246094 (1.403 sec)
26.199... logprob:  0.621510, 0.259115 (1.382 sec)
26.200... logprob:  0.652415, 0.276042 (1.459 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.442048, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.908655e-03 [1.456741e-07] 
Layer 'conv1' biases: 2.133650e-06 [5.542262e-11] 
Layer 'conv2' weights[0]: 2.902942e-03 [1.453098e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.042808e-10] 
Layer 'conv3' weights[0]: 2.901717e-03 [1.454650e-07] 
Layer 'conv3' biases: 3.519985e-05 [7.277356e-09] 
Layer 'conv4' weights[0]: 2.913962e-03 [1.463329e-07] 
Layer 'conv4' biases: 9.998998e-01 [1.857077e-07] 
Layer 'conv5' weights[0]: 3.061572e-03 [2.365887e-06] 
Layer 'conv5' biases: 9.991606e-01 [2.609669e-06] 
Layer 'fc6' weights[0]: 6.837235e-03 [6.293301e-08] 
Layer 'fc6' biases: 9.999899e-01 [5.583534e-08] 
Layer 'fc7' weights[0]: 7.183964e-03 [1.437692e-07] 
Layer 'fc7' biases: 9.997431e-01 [1.906885e-07] 
Layer 'fc8' weights[0]: 4.751906e-03 [1.277796e-05] 
Layer 'fc8' biases: 2.103726e-02 [2.540279e-05] 
Train error last 800 batches: 0.654605
-------------------------------------------------------
Not saving because 0.442048 > 0.299667 (9.300: -1.18%)
======================================================= (2.371 sec)
26.201... logprob:  0.667819, 0.325521 (1.412 sec)
26.202... logprob:  0.700048, 0.281250 (1.396 sec)
26.203... logprob:  0.648724, 0.273437 (1.443 sec)
26.204... logprob:  0.674424, 0.279948 (1.384 sec)
26.205... logprob:  0.577363, 0.270833 (1.400 sec)
26.206... logprob:  0.557418, 0.218750 (1.394 sec)
26.207... logprob:  0.641365, 0.304688 (1.390 sec)
26.208... logprob:  0.625522, 0.270833 (1.398 sec)
26.209... logprob:  0.592613, 0.256510 (1.420 sec)
26.210... logprob:  0.741682, 0.294271 (1.409 sec)
26.211... logprob:  0.712868, 0.305990 (1.412 sec)
26.212... logprob:  0.736742, 0.329427 (1.405 sec)
26.213... logprob:  0.656629, 0.286458 (1.454 sec)
26.214... logprob:  0.635307, 0.270833 (1.431 sec)
26.215... logprob:  0.586565, 0.270833 (1.418 sec)
26.216... logprob:  0.663009, 0.296875 (1.466 sec)
26.217... logprob:  0.605873, 0.273438 (1.402 sec)
26.218... logprob:  0.665534, 0.294271 (1.414 sec)
26.219... logprob:  0.722934, 0.341146 (1.412 sec)
26.220... logprob:  0.634933, 0.274740 (1.413 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.429065, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.905735e-03 [1.453289e-07] 
Layer 'conv1' biases: 2.133573e-06 [4.831927e-11] 
Layer 'conv2' weights[0]: 2.900038e-03 [1.450868e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.181125e-10] 
Layer 'conv3' weights[0]: 2.898807e-03 [1.451670e-07] 
Layer 'conv3' biases: 3.517643e-05 [5.524653e-09] 
Layer 'conv4' weights[0]: 2.911050e-03 [1.458749e-07] 
Layer 'conv4' biases: 9.999006e-01 [1.335177e-07] 
Layer 'conv5' weights[0]: 3.059471e-03 [1.834722e-06] 
Layer 'conv5' biases: 9.991570e-01 [1.933013e-06] 
Layer 'fc6' weights[0]: 6.836524e-03 [5.850838e-08] 
Layer 'fc6' biases: 9.999900e-01 [5.012523e-08] 
Layer 'fc7' weights[0]: 7.183278e-03 [1.326554e-07] 
Layer 'fc7' biases: 9.997430e-01 [1.521278e-07] 
Layer 'fc8' weights[0]: 4.752915e-03 [1.124535e-05] 
Layer 'fc8' biases: 2.105466e-02 [4.224146e-06] 
Train error last 800 batches: 0.654568
-------------------------------------------------------
Not saving because 0.429065 > 0.299667 (9.300: -1.18%)
======================================================= (2.397 sec)
26.221... logprob:  0.609640, 0.260417 (1.408 sec)
26.222... logprob:  0.708783, 0.325521 (1.461 sec)
26.223... logprob:  0.700984, 0.296875 (1.430 sec)
26.224... logprob:  0.712473, 0.325521 (1.431 sec)
26.225... logprob:  0.603819, 0.273438 (1.443 sec)
26.226... logprob:  0.653979, 0.300781 (1.416 sec)
26.227... logprob:  0.721589, 0.325521 (1.414 sec)
26.228... logprob:  0.560572, 0.242187 (1.410 sec)
26.229... logprob:  0.690352, 0.282552 (1.415 sec)
26.230... logprob:  0.671828, 0.269531 (1.435 sec)
26.231... logprob:  0.721740, 0.304687 (1.403 sec)
26.232... logprob:  0.760392, 0.345052 (1.457 sec)
26.233... logprob:  0.684312, 0.308594 (1.422 sec)
26.234... logprob:  0.793874, 0.348958 (1.418 sec)
26.235... logprob:  0.698624, 0.316406 (1.463 sec)
26.236... logprob:  0.617671, 0.239583 (1.402 sec)
26.237... logprob:  0.460672, 0.201823 (1.423 sec)
26.238... logprob:  0.612442, 0.283854 (1.409 sec)
26.239... logprob:  0.731596, 0.316406 (1.439 sec)
26.240... logprob:  0.715520, 0.326823 (1.392 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.560244, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.902831e-03 [1.451607e-07] 
Layer 'conv1' biases: 2.133483e-06 [6.510321e-11] 
Layer 'conv2' weights[0]: 2.897146e-03 [1.449380e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.074442e-10] 
Layer 'conv3' weights[0]: 2.895925e-03 [1.451817e-07] 
Layer 'conv3' biases: 3.516128e-05 [7.739795e-09] 
Layer 'conv4' weights[0]: 2.908138e-03 [1.460131e-07] 
Layer 'conv4' biases: 9.999035e-01 [1.728861e-07] 
Layer 'conv5' weights[0]: 3.058422e-03 [2.218038e-06] 
Layer 'conv5' biases: 9.991728e-01 [2.415882e-06] 
Layer 'fc6' weights[0]: 6.835837e-03 [6.035307e-08] 
Layer 'fc6' biases: 9.999901e-01 [5.254039e-08] 
Layer 'fc7' weights[0]: 7.182575e-03 [1.378593e-07] 
Layer 'fc7' biases: 9.997420e-01 [1.639466e-07] 
Layer 'fc8' weights[0]: 4.706884e-03 [1.218759e-05] 
Layer 'fc8' biases: 2.071109e-02 [1.009098e-05] 
Train error last 800 batches: 0.654480
-------------------------------------------------------
Not saving because 0.560244 > 0.299667 (9.300: -1.18%)
======================================================= (2.389 sec)
26.241... logprob:  0.715317, 0.299479 (1.466 sec)
26.242... logprob:  0.566457, 0.257812 (1.426 sec)
26.243... logprob:  0.618010, 0.298177 (1.440 sec)
26.244... logprob:  0.615943, 0.277344 (1.443 sec)
26.245... logprob:  0.659131, 0.299479 (1.421 sec)
26.246... logprob:  0.632604, 0.251302 (1.410 sec)
26.247... logprob:  0.668883, 0.277344 (1.409 sec)
26.248... logprob:  0.540338, 0.246094 (1.408 sec)
26.249... logprob:  0.677936, 0.291667 (1.418 sec)
26.250... logprob:  0.782445, 0.338542 (1.398 sec)
26.251... logprob:  0.613884, 0.291667 (1.449 sec)
26.252... logprob:  0.596843, 0.252604 (1.420 sec)
26.253... logprob:  0.615196, 0.285156 (1.412 sec)
26.254... logprob:  0.801600, 0.347656 (1.461 sec)
26.255... logprob:  0.662549, 0.299479 (1.391 sec)
26.256... logprob:  0.580507, 0.246094 (1.420 sec)
26.257... logprob:  0.677431, 0.270833 (1.415 sec)
26.258... logprob:  0.688362, 0.274740 (1.417 sec)
26.259... logprob:  0.652401, 0.274739 (1.392 sec)
26.260... logprob:  0.578537, 0.285156 (1.454 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.390588, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.899929e-03 [1.451324e-07] 
Layer 'conv1' biases: 2.133469e-06 [1.128406e-10] 
Layer 'conv2' weights[0]: 2.894251e-03 [1.448456e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.207828e-09] 
Layer 'conv3' weights[0]: 2.893013e-03 [1.453150e-07] 
Layer 'conv3' biases: 3.514654e-05 [9.553387e-09] 
Layer 'conv4' weights[0]: 2.905220e-03 [1.463593e-07] 
Layer 'conv4' biases: 9.999033e-01 [2.404628e-07] 
Layer 'conv5' weights[0]: 3.055739e-03 [2.210876e-06] 
Layer 'conv5' biases: 9.991559e-01 [2.346122e-06] 
Layer 'fc6' weights[0]: 6.835124e-03 [6.288579e-08] 
Layer 'fc6' biases: 9.999899e-01 [5.573363e-08] 
Layer 'fc7' weights[0]: 7.181799e-03 [1.453500e-07] 
Layer 'fc7' biases: 9.997424e-01 [1.952887e-07] 
Layer 'fc8' weights[0]: 4.748510e-03 [1.361911e-05] 
Layer 'fc8' biases: 2.107706e-02 [3.060765e-05] 
Train error last 800 batches: 0.654967
-------------------------------------------------------
Not saving because 0.390588 > 0.299667 (9.300: -1.18%)
======================================================= (2.379 sec)
26.261... logprob:  0.616320, 0.257812 (1.436 sec)
26.262... logprob:  0.722259, 0.290365 (1.437 sec)
26.263... logprob:  0.635415, 0.296875 (1.447 sec)
26.264... logprob:  0.529883, 0.235677 (1.418 sec)
26.265... logprob:  0.664117, 0.272135 (1.405 sec)
26.266... logprob:  0.714525, 0.346354 (1.410 sec)
26.267... logprob:  0.702116, 0.313802 (1.411 sec)
26.268... logprob:  0.637820, 0.278646 (1.423 sec)
26.269... logprob:  0.726553, 0.324219 (1.400 sec)
26.270... logprob:  0.704472, 0.329427 (1.449 sec)
26.271... logprob:  0.699549, 0.316406 (1.423 sec)
26.272... logprob:  0.672465, 0.302083 (1.414 sec)
26.273... logprob:  0.723211, 0.315104 (1.462 sec)
26.274... logprob:  0.713376, 0.313802 (1.396 sec)
26.275... logprob:  0.705546, 0.329427 (1.412 sec)
26.276... logprob:  0.582799, 0.278646 (1.413 sec)
26.277... logprob:  0.631140, 0.298177 (1.439 sec)
26.278... logprob:  0.573090, 0.263021 (1.413 sec)
26.279... logprob:  0.619091, 0.264323 (1.458 sec)
26.280... logprob:  0.486090, 0.221354 (1.396 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.533093, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.897038e-03 [1.449610e-07] 
Layer 'conv1' biases: 2.133790e-06 [1.127014e-10] 
Layer 'conv2' weights[0]: 2.891358e-03 [1.446897e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.310722e-09] 
Layer 'conv3' weights[0]: 2.890154e-03 [1.453686e-07] 
Layer 'conv3' biases: 3.517066e-05 [1.042186e-08] 
Layer 'conv4' weights[0]: 2.902322e-03 [1.465138e-07] 
Layer 'conv4' biases: 9.999004e-01 [2.818876e-07] 
Layer 'conv5' weights[0]: 3.051045e-03 [2.967663e-06] 
Layer 'conv5' biases: 9.991584e-01 [3.120112e-06] 
Layer 'fc6' weights[0]: 6.834432e-03 [6.723513e-08] 
Layer 'fc6' biases: 9.999899e-01 [6.128078e-08] 
Layer 'fc7' weights[0]: 7.181081e-03 [1.550343e-07] 
Layer 'fc7' biases: 9.997422e-01 [2.464903e-07] 
Layer 'fc8' weights[0]: 4.747170e-03 [1.554476e-05] 
Layer 'fc8' biases: 2.110297e-02 [4.529308e-05] 
Train error last 800 batches: 0.654671
-------------------------------------------------------
Not saving because 0.533093 > 0.299667 (9.300: -1.18%)
======================================================= (2.363 sec)
26.281... logprob:  0.589768, 0.243489 (1.432 sec)
26.282... logprob:  0.644409, 0.285156 (1.417 sec)
26.283... logprob:  0.565433, 0.276042 (1.417 sec)
26.284... logprob:  0.609659, 0.296875 (1.401 sec)
26.285... logprob:  0.595003, 0.268229 (1.432 sec)
26.286... logprob:  0.749055, 0.286458 (1.433 sec)
26.287... logprob:  0.515406, 0.238281 (1.424 sec)
26.288... logprob:  0.647251, 0.270833 (1.431 sec)
26.289... logprob:  0.747259, 0.299479 (1.440 sec)
26.290... logprob:  0.731715, 0.335937 (1.403 sec)
26.291... logprob:  0.638105, 0.296875 (1.418 sec)
26.292... logprob:  0.637764, 0.277344 (1.411 sec)
26.293... logprob:  0.675065, 0.298177 (1.422 sec)
26.294... logprob:  0.559771, 0.257812 (1.407 sec)
26.295... logprob:  0.573910, 0.264323 (1.463 sec)
26.296... logprob:  0.565126, 0.287760 (1.414 sec)
26.297... logprob:  0.555449, 0.255208 (1.420 sec)
26.298... logprob:  0.704367, 0.278646 (1.463 sec)
26.299... logprob:  0.627427, 0.269531 (1.399 sec)
26.300... logprob:  0.614211, 0.287760 (1.424 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.361935, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.894141e-03 [1.447444e-07] 
Layer 'conv1' biases: 2.134053e-06 [7.333740e-11] 
Layer 'conv2' weights[0]: 2.888475e-03 [1.444738e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.931105e-10] 
Layer 'conv3' weights[0]: 2.887243e-03 [1.447364e-07] 
Layer 'conv3' biases: 3.518501e-05 [6.580134e-09] 
Layer 'conv4' weights[0]: 2.899431e-03 [1.454994e-07] 
Layer 'conv4' biases: 9.998990e-01 [1.711017e-07] 
Layer 'conv5' weights[0]: 3.047323e-03 [2.144406e-06] 
Layer 'conv5' biases: 9.991344e-01 [2.282307e-06] 
Layer 'fc6' weights[0]: 6.833710e-03 [5.934380e-08] 
Layer 'fc6' biases: 9.999899e-01 [5.175557e-08] 
Layer 'fc7' weights[0]: 7.180353e-03 [1.340986e-07] 
Layer 'fc7' biases: 9.997448e-01 [1.677546e-07] 
Layer 'fc8' weights[0]: 4.813000e-03 [1.181240e-05] 
Layer 'fc8' biases: 2.161743e-02 [2.234477e-05] 
Train error last 800 batches: 0.654951
-------------------------------------------------------
Not saving because 0.361935 > 0.299667 (9.300: -1.18%)
======================================================= (2.360 sec)
26.301... logprob:  0.722725, 0.319010 (1.420 sec)
26.302... logprob:  0.736720, 0.341146 (1.417 sec)
26.303... logprob:  0.663831, 0.307292 (1.403 sec)
26.304... logprob:  0.703202, 0.290365 (1.436 sec)
26.305... logprob:  0.690342, 0.289062 (1.433 sec)
26.306... logprob:  0.669222, 0.292969 (1.431 sec)
26.307... logprob:  0.694152, 0.313802 (1.433 sec)
26.308... logprob:  0.595858, 0.277344 (1.448 sec)
26.309... logprob:  0.702704, 0.308594 (1.410 sec)
26.310... logprob:  0.594490, 0.251302 (1.413 sec)
26.311... logprob:  0.688591, 0.290365 (1.418 sec)
26.312... logprob:  0.733156, 0.315104 (1.420 sec)
26.313... logprob:  0.665058, 0.298177 (1.412 sec)
26.314... logprob:  0.663625, 0.302083 (1.458 sec)
26.315... logprob:  0.582763, 0.236979 (1.428 sec)
26.316... logprob:  0.652171, 0.283854 (1.450 sec)
26.317... logprob:  0.500208, 0.222656 (1.469 sec)
26.318... logprob:  0.640569, 0.281250 (1.405 sec)
26.319... logprob:  0.638996, 0.273438 (1.420 sec)
26.320... logprob:  0.689169, 0.302083 (1.422 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.413972, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.891260e-03 [1.446410e-07] 
Layer 'conv1' biases: 2.134385e-06 [6.551178e-11] 
Layer 'conv2' weights[0]: 2.885576e-03 [1.443565e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.014012e-10] 
Layer 'conv3' weights[0]: 2.884354e-03 [1.445622e-07] 
Layer 'conv3' biases: 3.520648e-05 [6.986228e-09] 
Layer 'conv4' weights[0]: 2.896523e-03 [1.452784e-07] 
Layer 'conv4' biases: 9.998988e-01 [1.481753e-07] 
Layer 'conv5' weights[0]: 3.044438e-03 [2.079585e-06] 
Layer 'conv5' biases: 9.991707e-01 [2.328178e-06] 
Layer 'fc6' weights[0]: 6.832976e-03 [6.312981e-08] 
Layer 'fc6' biases: 9.999900e-01 [5.609045e-08] 
Layer 'fc7' weights[0]: 7.179678e-03 [1.438461e-07] 
Layer 'fc7' biases: 9.997419e-01 [1.897333e-07] 
Layer 'fc8' weights[0]: 4.733533e-03 [1.361664e-05] 
Layer 'fc8' biases: 2.100256e-02 [2.989250e-05] 
Train error last 800 batches: 0.654681
-------------------------------------------------------
Not saving because 0.413972 > 0.299667 (9.300: -1.18%)
======================================================= (2.354 sec)
26.321... logprob:  0.505385, 0.242187 (1.554 sec)
26.322... logprob:  0.611907, 0.282552 (1.421 sec)
26.323... logprob:  0.566610, 0.251302 (1.475 sec)
26.324... logprob:  0.639719, 0.270833 (1.418 sec)
26.325... logprob:  0.573104, 0.251302 (1.432 sec)
26.326... logprob:  0.757813, 0.317708 (1.461 sec)
26.327... logprob:  0.754231, 0.363281 (1.414 sec)
26.328... logprob:  0.799523, 0.308594 (1.431 sec)
26.329... logprob:  0.613928, 0.286458 (1.421 sec)
26.330... logprob:  0.660771, 0.308594 (1.416 sec)
26.331... logprob:  0.588659, 0.255208 (1.411 sec)
26.332... logprob:  0.661007, 0.299479 (1.443 sec)
26.333... logprob:  0.492879, 0.200521 (1.438 sec)
26.334... logprob:  0.869318, 0.368490 (1.432 sec)
26.335... logprob:  0.641116, 0.289062 (1.433 sec)
26.336... logprob:  0.599518, 0.252604 (1.449 sec)
26.337... logprob:  0.763224, 0.326823 (1.409 sec)
26.338... logprob:  0.689721, 0.296875 (1.417 sec)
26.339... logprob:  0.779933, 0.343750 (1.417 sec)
26.340... logprob:  0.665604, 0.299479 (1.417 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.442711, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.888350e-03 [1.444040e-07] 
Layer 'conv1' biases: 2.134537e-06 [9.328447e-11] 
Layer 'conv2' weights[0]: 2.882685e-03 [1.441722e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.313037e-09] 
Layer 'conv3' weights[0]: 2.881463e-03 [1.446866e-07] 
Layer 'conv3' biases: 3.520893e-05 [9.862250e-09] 
Layer 'conv4' weights[0]: 2.893618e-03 [1.454159e-07] 
Layer 'conv4' biases: 9.998989e-01 [2.496556e-07] 
Layer 'conv5' weights[0]: 3.041967e-03 [3.113134e-06] 
Layer 'conv5' biases: 9.991697e-01 [3.388578e-06] 
Layer 'fc6' weights[0]: 6.832277e-03 [7.344922e-08] 
Layer 'fc6' biases: 9.999899e-01 [6.874784e-08] 
Layer 'fc7' weights[0]: 7.178970e-03 [1.678403e-07] 
Layer 'fc7' biases: 9.997420e-01 [2.523027e-07] 
Layer 'fc8' weights[0]: 4.741435e-03 [1.531130e-05] 
Layer 'fc8' biases: 2.101263e-02 [3.724442e-05] 
Train error last 800 batches: 0.654153
-------------------------------------------------------
Not saving because 0.442711 > 0.299667 (9.300: -1.18%)
======================================================= (2.365 sec)
26.341... logprob:  0.740326, 0.311198 (1.426 sec)
26.342... logprob:  0.588952, 0.268229 (1.463 sec)
26.343... logprob:  0.688661, 0.298177 (1.443 sec)
26.344... logprob:  0.680129, 0.307292 (1.475 sec)
26.345... logprob:  0.730970, 0.312500 (1.439 sec)
26.346... logprob:  0.650613, 0.279948 (1.431 sec)
26.347... logprob:  0.623577, 0.295573 (1.485 sec)
26.348... logprob:  0.613528, 0.244792 (1.434 sec)
26.349... logprob:  0.750645, 0.345052 (1.427 sec)
26.350... logprob:  0.566704, 0.244792 (1.433 sec)
26.351... logprob:  0.703102, 0.295573 (1.424 sec)
26.352... logprob:  0.637502, 0.287760 (1.429 sec)
26.353... logprob:  0.736279, 0.315104 (1.488 sec)
26.354... logprob:  0.759783, 0.338542 (1.458 sec)
26.355... logprob:  0.581101, 0.276042 (1.437 sec)
26.356... logprob:  0.629244, 0.255208 (1.470 sec)
26.357... logprob:  0.597003, 0.257812 (1.427 sec)
26.358... logprob:  0.648716, 0.287760 (1.433 sec)
26.359... logprob:  0.741921, 0.328125 (1.426 sec)
26.360... logprob:  0.675440, 0.294271 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.521721, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.885460e-03 [1.443393e-07] 
Layer 'conv1' biases: 2.134765e-06 [8.063332e-11] 
Layer 'conv2' weights[0]: 2.879828e-03 [1.440650e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.176177e-09] 
Layer 'conv3' weights[0]: 2.878561e-03 [1.445029e-07] 
Layer 'conv3' biases: 3.523052e-05 [9.510236e-09] 
Layer 'conv4' weights[0]: 2.890749e-03 [1.454860e-07] 
Layer 'conv4' biases: 9.998997e-01 [2.666974e-07] 
Layer 'conv5' weights[0]: 3.039891e-03 [2.370712e-06] 
Layer 'conv5' biases: 9.991769e-01 [2.629363e-06] 
Layer 'fc6' weights[0]: 6.831581e-03 [6.308498e-08] 
Layer 'fc6' biases: 9.999897e-01 [5.576653e-08] 
Layer 'fc7' weights[0]: 7.178260e-03 [1.433847e-07] 
Layer 'fc7' biases: 9.997405e-01 [1.781995e-07] 
Layer 'fc8' weights[0]: 4.708429e-03 [1.272865e-05] 
Layer 'fc8' biases: 2.075880e-02 [1.739412e-05] 
Train error last 800 batches: 0.654389
-------------------------------------------------------
Not saving because 0.521721 > 0.299667 (9.300: -1.18%)
======================================================= (2.382 sec)
26.361... logprob:  0.630256, 0.256510 (1.436 sec)
26.362... logprob:  0.715289, 0.283854 (1.479 sec)
26.363... logprob:  0.633934, 0.278646 (1.443 sec)
26.364... logprob:  0.706299, 0.299479 (1.446 sec)
26.365... logprob:  0.637845, 0.274740 (1.456 sec)
26.366... logprob:  0.682128, 0.299479 (1.440 sec)
26.367... logprob:  0.505015, 0.188802 (1.440 sec)
26.368... logprob:  0.822604, 0.333333 (1.432 sec)
26.369... logprob:  0.606697, 0.273438 (1.427 sec)
26.370... logprob:  0.550354, 0.231771 (1.437 sec)
26.371... logprob:  0.564295, 0.252604 (1.451 sec)
26.372... logprob:  0.722829, 0.294271 (1.448 sec)
26.373... logprob:  0.643172, 0.325521 (1.444 sec)
26.374... logprob:  0.732481, 0.328125 (1.449 sec)
26.375... logprob:  0.695648, 0.292969 (1.455 sec)
26.376... logprob:  0.682406, 0.292969 (1.436 sec)
26.377... logprob:  0.571726, 0.289062 (1.423 sec)
26.378... logprob:  0.647949, 0.287760 (1.425 sec)
26.379... logprob:  0.704289, 0.309896 (1.436 sec)
26.380... logprob:  0.830998, 0.371094 (1.434 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.417396, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.882602e-03 [1.441807e-07] 
Layer 'conv1' biases: 2.134633e-06 [6.036035e-11] 
Layer 'conv2' weights[0]: 2.876944e-03 [1.439183e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.688651e-10] 
Layer 'conv3' weights[0]: 2.875694e-03 [1.441407e-07] 
Layer 'conv3' biases: 3.523633e-05 [7.539789e-09] 
Layer 'conv4' weights[0]: 2.887844e-03 [1.447969e-07] 
Layer 'conv4' biases: 9.998980e-01 [1.804614e-07] 
Layer 'conv5' weights[0]: 3.036238e-03 [2.501510e-06] 
Layer 'conv5' biases: 9.991689e-01 [2.770709e-06] 
Layer 'fc6' weights[0]: 6.830883e-03 [6.643791e-08] 
Layer 'fc6' biases: 9.999898e-01 [6.013313e-08] 
Layer 'fc7' weights[0]: 7.177538e-03 [1.526487e-07] 
Layer 'fc7' biases: 9.997410e-01 [2.115026e-07] 
Layer 'fc8' weights[0]: 4.721032e-03 [1.548101e-05] 
Layer 'fc8' biases: 2.091469e-02 [3.727570e-05] 
Train error last 800 batches: 0.654774
-------------------------------------------------------
Not saving because 0.417396 > 0.299667 (9.300: -1.18%)
======================================================= (2.379 sec)
26.381... logprob:  0.649302, 0.286458 (1.469 sec)
26.382... logprob:  0.766504, 0.332031 (1.453 sec)
26.383... logprob:  0.601455, 0.266927 (1.436 sec)
26.384... logprob:  0.725954, 0.304688 (1.477 sec)
26.385... logprob:  0.711501, 0.305990 (1.429 sec)
26.386... logprob:  0.698916, 0.295573 (1.425 sec)
26.387... logprob:  0.774887, 0.312500 (1.432 sec)
26.388... logprob:  0.723176, 0.283854 (1.436 sec)
26.389... logprob:  0.582284, 0.270833 (1.431 sec)
26.390... logprob:  0.648262, 0.264323 (1.474 sec)
26.391... logprob:  0.596961, 0.252604 (1.437 sec)
26.392... logprob:  0.611805, 0.295573 (1.460 sec)
26.393... logprob:  0.545882, 0.217448 (1.481 sec)
26.394... logprob:  0.630893, 0.270833 (1.430 sec)
26.395... logprob:  0.586600, 0.235677 (1.428 sec)
26.396... logprob:  0.554485, 0.218750 (1.424 sec)
26.397... logprob:  0.694344, 0.326823 (1.428 sec)
26.398... logprob:  0.689378, 0.281250 (1.427 sec)
26.399... logprob:  0.594286, 0.247396 (1.479 sec)
26.400... logprob:  0.747341, 0.351562 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.507843, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.879706e-03 [1.440866e-07] 
Layer 'conv1' biases: 2.134855e-06 [7.307959e-11] 
Layer 'conv2' weights[0]: 2.874074e-03 [1.437987e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.575960e-10] 
Layer 'conv3' weights[0]: 2.872823e-03 [1.441425e-07] 
Layer 'conv3' biases: 3.524396e-05 [7.991039e-09] 
Layer 'conv4' weights[0]: 2.884966e-03 [1.450687e-07] 
Layer 'conv4' biases: 9.998957e-01 [2.126908e-07] 
Layer 'conv5' weights[0]: 3.032133e-03 [2.588161e-06] 
Layer 'conv5' biases: 9.991655e-01 [2.761037e-06] 
Layer 'fc6' weights[0]: 6.830153e-03 [6.390890e-08] 
Layer 'fc6' biases: 9.999897e-01 [5.696152e-08] 
Layer 'fc7' weights[0]: 7.176866e-03 [1.466122e-07] 
Layer 'fc7' biases: 9.997410e-01 [1.901035e-07] 
Layer 'fc8' weights[0]: 4.732839e-03 [1.353329e-05] 
Layer 'fc8' biases: 2.093990e-02 [2.385222e-05] 
Train error last 800 batches: 0.654531
-------------------------------------------------------
Not saving because 0.507843 > 0.299667 (9.300: -1.18%)
======================================================= (2.377 sec)
26.401... logprob:  0.597598, 0.266927 (1.444 sec)
26.402... logprob:  0.665322, 0.274739 (1.479 sec)
26.403... logprob:  0.708081, 0.319010 (1.425 sec)
26.404... logprob:  0.714178, 0.324219 (1.431 sec)
26.405... logprob:  0.717453, 0.302083 (1.435 sec)
26.406... logprob:  0.595033, 0.266927 (1.420 sec)
26.407... logprob:  0.665559, 0.298177 (1.425 sec)
26.408... logprob:  0.638835, 0.309896 (1.478 sec)
26.409... logprob:  0.661610, 0.298177 (1.428 sec)
26.410... logprob:  0.723029, 0.322917 (1.448 sec)
26.411... logprob:  0.643820, 0.305990 (1.483 sec)
26.412... logprob:  0.776197, 0.307292 (1.443 sec)
26.413... logprob:  0.763818, 0.294271 (1.431 sec)
26.414... logprob:  0.750491, 0.333333 (1.429 sec)
26.415... logprob:  0.674428, 0.291667 (1.424 sec)
26.416... logprob:  0.644281, 0.294271 (1.437 sec)
26.417... logprob:  0.616683, 0.257812 (1.458 sec)
26.418... logprob:  0.704434, 0.300781 (1.443 sec)
26.419... logprob:  0.583910, 0.247396 (1.448 sec)
26.420... logprob:  0.625295, 0.274739 (1.448 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.571498, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.876835e-03 [1.438937e-07] 
Layer 'conv1' biases: 2.135029e-06 [6.271204e-11] 
Layer 'conv2' weights[0]: 2.871175e-03 [1.436387e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.945714e-10] 
Layer 'conv3' weights[0]: 2.869954e-03 [1.437268e-07] 
Layer 'conv3' biases: 3.526700e-05 [5.202206e-09] 
Layer 'conv4' weights[0]: 2.882085e-03 [1.444810e-07] 
Layer 'conv4' biases: 9.998953e-01 [1.552534e-07] 
Layer 'conv5' weights[0]: 3.029126e-03 [2.291037e-06] 
Layer 'conv5' biases: 9.991683e-01 [2.512180e-06] 
Layer 'fc6' weights[0]: 6.829431e-03 [6.467494e-08] 
Layer 'fc6' biases: 9.999899e-01 [5.807159e-08] 
Layer 'fc7' weights[0]: 7.176153e-03 [1.506713e-07] 
Layer 'fc7' biases: 9.997414e-01 [2.038990e-07] 
Layer 'fc8' weights[0]: 4.730019e-03 [1.510505e-05] 
Layer 'fc8' biases: 2.096546e-02 [3.432910e-05] 
Train error last 800 batches: 0.654540
-------------------------------------------------------
Not saving because 0.571498 > 0.299667 (9.300: -1.18%)
======================================================= (2.381 sec)
26.421... logprob:  0.591810, 0.256510 (1.459 sec)
26.422... logprob:  0.737419, 0.294271 (1.433 sec)
26.423... logprob:  0.612868, 0.292969 (1.424 sec)
26.424... logprob:  0.665148, 0.294271 (1.423 sec)
26.425... logprob:  0.562535, 0.252604 (1.434 sec)
26.426... logprob:  0.648669, 0.291667 (1.437 sec)
26.427... logprob:  0.683813, 0.309896 (1.458 sec)
26.428... logprob:  0.784823, 0.319010 (1.454 sec)
26.429... logprob:  0.647435, 0.266927 (1.436 sec)
26.430... logprob:  0.519094, 0.248698 (1.485 sec)
26.431... logprob:  0.828972, 0.350260 (1.427 sec)
26.432... logprob:  0.677745, 0.307292 (1.419 sec)
26.433... logprob:  0.624290, 0.308594 (1.425 sec)
26.434... logprob:  0.755593, 0.324219 (1.435 sec)
26.435... logprob:  0.713906, 0.319010 (1.422 sec)
26.436... logprob:  0.578588, 0.259115 (1.472 sec)
26.437... logprob:  0.792934, 0.359375 (1.440 sec)
26.438... logprob:  0.740661, 0.339844 (1.426 sec)
26.439... logprob:  0.587407, 0.269531 (1.482 sec)
26.440... logprob:  0.701081, 0.295573 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.450708, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.873949e-03 [1.437261e-07] 
Layer 'conv1' biases: 2.135052e-06 [6.330350e-11] 
Layer 'conv2' weights[0]: 2.868317e-03 [1.434848e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.263771e-10] 
Layer 'conv3' weights[0]: 2.867093e-03 [1.436113e-07] 
Layer 'conv3' biases: 3.527330e-05 [5.598300e-09] 
Layer 'conv4' weights[0]: 2.879179e-03 [1.443269e-07] 
Layer 'conv4' biases: 9.998959e-01 [1.479788e-07] 
Layer 'conv5' weights[0]: 3.026918e-03 [2.321434e-06] 
Layer 'conv5' biases: 9.991773e-01 [2.490467e-06] 
Layer 'fc6' weights[0]: 6.828773e-03 [6.365301e-08] 
Layer 'fc6' biases: 9.999898e-01 [5.640000e-08] 
Layer 'fc7' weights[0]: 7.175445e-03 [1.460909e-07] 
Layer 'fc7' biases: 9.997400e-01 [1.889877e-07] 
Layer 'fc8' weights[0]: 4.719599e-03 [1.320042e-05] 
Layer 'fc8' biases: 2.093382e-02 [2.262466e-05] 
Train error last 800 batches: 0.655268
-------------------------------------------------------
Not saving because 0.450708 > 0.299667 (9.300: -1.18%)
======================================================= (2.379 sec)
26.441... logprob:  0.669742, 0.303385 (1.425 sec)
26.442... logprob:  0.608358, 0.252604 (1.433 sec)
26.443... logprob:  0.673537, 0.308594 (1.431 sec)
26.444... logprob:  0.631170, 0.276042 (1.424 sec)
26.445... logprob:  0.628022, 0.296875 (1.481 sec)
26.446... logprob:  0.644608, 0.263021 (1.434 sec)
26.447... logprob:  0.782388, 0.316406 (1.437 sec)
26.448... logprob:  0.519542, 0.247396 (1.478 sec)
26.449... logprob:  0.613557, 0.248698 (1.430 sec)
26.450... logprob:  0.497333, 0.229167 (1.426 sec)
26.451... logprob:  0.700210, 0.286458 (1.430 sec)
26.452... logprob:  0.662995, 0.283854 (1.423 sec)
26.453... logprob:  0.650769, 0.305990 (1.425 sec)
26.454... logprob:  0.775341, 0.304688 (1.480 sec)
26.455... logprob:  0.726909, 0.320313 (1.435 sec)
26.456... logprob:  0.686713, 0.272135 (1.442 sec)
26.457... logprob:  0.630884, 0.266927 (1.478 sec)
26.458... logprob:  0.522337, 0.238281 (1.433 sec)
26.459... logprob:  0.721570, 0.305990 (1.434 sec)
26.460... logprob:  0.479077, 0.222656 (1.432 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.316344, 0.039062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.871081e-03 [1.435922e-07] 
Layer 'conv1' biases: 2.135491e-06 [6.988385e-11] 
Layer 'conv2' weights[0]: 2.865437e-03 [1.433413e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.524014e-10] 
Layer 'conv3' weights[0]: 2.864224e-03 [1.435329e-07] 
Layer 'conv3' biases: 3.528470e-05 [6.523212e-09] 
Layer 'conv4' weights[0]: 2.876312e-03 [1.443051e-07] 
Layer 'conv4' biases: 9.998947e-01 [1.710583e-07] 
Layer 'conv5' weights[0]: 3.022983e-03 [2.449495e-06] 
Layer 'conv5' biases: 9.991691e-01 [2.637836e-06] 
Layer 'fc6' weights[0]: 6.828066e-03 [6.373718e-08] 
Layer 'fc6' biases: 9.999898e-01 [5.659788e-08] 
Layer 'fc7' weights[0]: 7.174716e-03 [1.446441e-07] 
Layer 'fc7' biases: 9.997411e-01 [1.991495e-07] 
Layer 'fc8' weights[0]: 4.754338e-03 [1.359094e-05] 
Layer 'fc8' biases: 2.122523e-02 [3.245087e-05] 
Train error last 800 batches: 0.655101
-------------------------------------------------------
Not saving because 0.316344 > 0.299667 (9.300: -1.18%)
======================================================= (2.377 sec)
26.461... logprob:  0.694816, 0.308594 (1.425 sec)
26.462... logprob:  0.681923, 0.317708 (1.437 sec)
26.463... logprob:  0.626185, 0.273438 (1.473 sec)
26.464... logprob:  0.727442, 0.312500 (1.440 sec)
26.465... logprob:  0.599885, 0.246094 (1.448 sec)
26.466... logprob:  0.533325, 0.239583 (1.457 sec)
26.467... logprob:  0.675513, 0.316406 (1.444 sec)
26.468... logprob:  0.634286, 0.250000 (1.454 sec)
26.469... logprob:  0.680109, 0.281250 (1.422 sec)
26.470... logprob:  0.599330, 0.274740 (1.423 sec)
26.471... logprob:  0.725403, 0.308594 (1.439 sec)
26.472... logprob:  0.644880, 0.299479 (1.444 sec)
26.473... logprob:  0.711862, 0.324219 (1.454 sec)
26.474... logprob:  0.574310, 0.274740 (1.446 sec)
26.475... logprob:  0.719913, 0.304687 (1.445 sec)
26.476... logprob:  0.719183, 0.316406 (1.466 sec)
26.477... logprob:  0.599452, 0.298177 (1.432 sec)
26.478... logprob:  0.728961, 0.322917 (1.414 sec)
26.479... logprob:  0.571636, 0.264323 (1.428 sec)
26.480... logprob:  0.644816, 0.303385 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.458057, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.868215e-03 [1.433921e-07] 
Layer 'conv1' biases: 2.135932e-06 [7.626847e-11] 
Layer 'conv2' weights[0]: 2.862567e-03 [1.431836e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.702131e-10] 
Layer 'conv3' weights[0]: 2.861354e-03 [1.433765e-07] 
Layer 'conv3' biases: 3.529686e-05 [5.998938e-09] 
Layer 'conv4' weights[0]: 2.873444e-03 [1.441743e-07] 
Layer 'conv4' biases: 9.998933e-01 [1.544700e-07] 
Layer 'conv5' weights[0]: 3.019357e-03 [1.983295e-06] 
Layer 'conv5' biases: 9.991656e-01 [2.147183e-06] 
Layer 'fc6' weights[0]: 6.827423e-03 [5.944562e-08] 
Layer 'fc6' biases: 9.999896e-01 [5.117619e-08] 
Layer 'fc7' weights[0]: 7.174034e-03 [1.341725e-07] 
Layer 'fc7' biases: 9.997409e-01 [1.647383e-07] 
Layer 'fc8' weights[0]: 4.767258e-03 [1.196297e-05] 
Layer 'fc8' biases: 2.137657e-02 [1.824590e-05] 
Train error last 800 batches: 0.655139
-------------------------------------------------------
Not saving because 0.458057 > 0.299667 (9.300: -1.18%)
======================================================= (2.347 sec)
26.481... logprob:  0.723105, 0.298177 (1.432 sec)
26.482... logprob:  0.639231, 0.294271 (1.471 sec)
26.483... logprob:  0.628249, 0.282552 (1.448 sec)
26.484... logprob:  0.661819, 0.295573 (1.426 sec)
26.485... logprob:  0.667763, 0.266927 (1.478 sec)
26.486... logprob:  0.585558, 0.256510 (1.430 sec)
26.487... logprob:  0.695640, 0.313802 (1.423 sec)
26.488... logprob:  0.662456, 0.300781 (1.435 sec)
26.489... logprob:  0.627023, 0.257813 (1.424 sec)
26.490... logprob:  0.658416, 0.273438 (1.431 sec)
26.491... logprob:  0.585527, 0.259115 (1.482 sec)
26.492... logprob:  0.608240, 0.294271 (1.438 sec)
26.493... logprob:  0.718937, 0.335938 (1.430 sec)
26.494... logprob:  0.676124, 0.296875 (1.488 sec)
26.495... logprob:  0.582623, 0.248698 (1.425 sec)
26.496... logprob:  0.800281, 0.347656 (1.429 sec)
26.497... logprob:  0.571872, 0.256510 (1.433 sec)
26.498... logprob:  0.675188, 0.291667 (1.422 sec)
26.499... logprob:  0.688003, 0.304687 (1.428 sec)
26.500... logprob:  0.595429, 0.268229 (1.483 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.502493, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.865339e-03 [1.433529e-07] 
Layer 'conv1' biases: 2.136056e-06 [5.594277e-11] 
Layer 'conv2' weights[0]: 2.859713e-03 [1.430483e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.528288e-10] 
Layer 'conv3' weights[0]: 2.858509e-03 [1.431179e-07] 
Layer 'conv3' biases: 3.530143e-05 [5.342229e-09] 
Layer 'conv4' weights[0]: 2.870568e-03 [1.438308e-07] 
Layer 'conv4' biases: 9.998933e-01 [1.381115e-07] 
Layer 'conv5' weights[0]: 3.016760e-03 [2.225396e-06] 
Layer 'conv5' biases: 9.991642e-01 [2.478038e-06] 
Layer 'fc6' weights[0]: 6.826705e-03 [6.363565e-08] 
Layer 'fc6' biases: 9.999896e-01 [5.669387e-08] 
Layer 'fc7' weights[0]: 7.173312e-03 [1.475839e-07] 
Layer 'fc7' biases: 9.997411e-01 [1.966971e-07] 
Layer 'fc8' weights[0]: 4.760979e-03 [1.490898e-05] 
Layer 'fc8' biases: 2.128913e-02 [3.941813e-05] 
Train error last 800 batches: 0.654650
-------------------------------------------------------
Not saving because 0.502493 > 0.299667 (9.300: -1.18%)
======================================================= (2.358 sec)
26.501... logprob:  0.638637, 0.291667 (1.432 sec)
26.502... logprob:  0.750888, 0.308594 (1.439 sec)
26.503... logprob:  0.576897, 0.240885 (1.477 sec)
26.504... logprob:  0.664560, 0.321615 (1.426 sec)
26.505... logprob:  0.753847, 0.332031 (1.431 sec)
26.506... logprob:  0.687840, 0.303385 (1.445 sec)
26.507... logprob:  0.559599, 0.242187 (1.419 sec)
26.508... logprob:  0.629384, 0.277344 (1.428 sec)
26.509... logprob:  0.571704, 0.256510 (1.469 sec)
26.510... logprob:  0.623765, 0.291667 (1.437 sec)
26.511... logprob:  0.634120, 0.268229 (1.442 sec)
26.512... logprob:  0.659128, 0.302083 (1.459 sec)
26.513... logprob:  0.609405, 0.259115 (1.438 sec)
26.514... logprob:  0.686036, 0.286458 (1.432 sec)
26.515... logprob:  0.635193, 0.296875 (1.424 sec)
26.516... logprob:  0.587835, 0.260417 (1.420 sec)
26.517... logprob:  0.773522, 0.360677 (1.438 sec)
26.518... logprob:  0.743460, 0.321615 (1.452 sec)
26.519... logprob:  0.764247, 0.330729 (1.454 sec)
26.520... logprob:  0.684772, 0.312500 (1.451 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.437190, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.862481e-03 [1.431349e-07] 
Layer 'conv1' biases: 2.136366e-06 [8.331485e-11] 
Layer 'conv2' weights[0]: 2.856870e-03 [1.428453e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.257247e-10] 
Layer 'conv3' weights[0]: 2.855678e-03 [1.430411e-07] 
Layer 'conv3' biases: 3.527950e-05 [6.813528e-09] 
Layer 'conv4' weights[0]: 2.867673e-03 [1.438619e-07] 
Layer 'conv4' biases: 9.998942e-01 [2.017004e-07] 
Layer 'conv5' weights[0]: 3.014624e-03 [2.870490e-06] 
Layer 'conv5' biases: 9.991555e-01 [3.147953e-06] 
Layer 'fc6' weights[0]: 6.825999e-03 [6.478946e-08] 
Layer 'fc6' biases: 9.999897e-01 [5.862773e-08] 
Layer 'fc7' weights[0]: 7.172582e-03 [1.486691e-07] 
Layer 'fc7' biases: 9.997416e-01 [1.971290e-07] 
Layer 'fc8' weights[0]: 4.777558e-03 [1.294559e-05] 
Layer 'fc8' biases: 2.142392e-02 [2.023308e-05] 
Train error last 800 batches: 0.655052
-------------------------------------------------------
Not saving because 0.437190 > 0.299667 (9.300: -1.18%)
======================================================= (2.360 sec)
26.521... logprob:  0.565256, 0.250000 (1.451 sec)
26.522... logprob:  0.762782, 0.330729 (1.462 sec)
26.523... logprob:  0.564661, 0.252604 (1.440 sec)
26.524... logprob:  0.575816, 0.261719 (1.427 sec)
26.525... logprob:  0.608997, 0.261719 (1.424 sec)
26.526... logprob:  0.543538, 0.238281 (1.430 sec)
26.527... logprob:  0.782033, 0.330729 (1.432 sec)
26.528... logprob:  0.618591, 0.285156 (1.465 sec)
26.529... logprob:  0.611652, 0.266927 (1.451 sec)
26.530... logprob:  0.713312, 0.307292 (1.434 sec)
26.531... logprob:  0.628914, 0.263021 (1.472 sec)
26.532... logprob:  0.754768, 0.317708 (1.428 sec)
26.533... logprob:  0.711097, 0.290364 (1.428 sec)
26.534... logprob:  0.602325, 0.276042 (1.429 sec)
26.535... logprob:  0.748137, 0.303385 (1.427 sec)
26.536... logprob:  0.649078, 0.285156 (1.431 sec)
26.537... logprob:  0.654801, 0.285156 (1.474 sec)
26.538... logprob:  0.717475, 0.298177 (1.439 sec)
26.539... logprob:  0.502529, 0.236979 (1.426 sec)
26.540... logprob:  0.604557, 0.270833 (1.478 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.451109, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.859627e-03 [1.430229e-07] 
Layer 'conv1' biases: 2.136386e-06 [5.147647e-11] 
Layer 'conv2' weights[0]: 2.854006e-03 [1.427654e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.290227e-10] 
Layer 'conv3' weights[0]: 2.852782e-03 [1.428785e-07] 
Layer 'conv3' biases: 3.526475e-05 [6.162605e-09] 
Layer 'conv4' weights[0]: 2.864817e-03 [1.436458e-07] 
Layer 'conv4' biases: 9.998964e-01 [1.683659e-07] 
Layer 'conv5' weights[0]: 3.013660e-03 [2.014506e-06] 
Layer 'conv5' biases: 9.991779e-01 [2.113486e-06] 
Layer 'fc6' weights[0]: 6.825279e-03 [6.144732e-08] 
Layer 'fc6' biases: 9.999895e-01 [5.395501e-08] 
Layer 'fc7' weights[0]: 7.171876e-03 [1.405375e-07] 
Layer 'fc7' biases: 9.997394e-01 [1.794119e-07] 
Layer 'fc8' weights[0]: 4.727585e-03 [1.296666e-05] 
Layer 'fc8' biases: 2.111435e-02 [2.768060e-05] 
Train error last 800 batches: 0.654739
-------------------------------------------------------
Not saving because 0.451109 > 0.299667 (9.300: -1.18%)
======================================================= (2.383 sec)
26.541... logprob:  0.671540, 0.299479 (1.427 sec)
26.542... logprob:  0.646207, 0.274740 (1.427 sec)
26.543... logprob:  0.546659, 0.282552 (1.436 sec)
26.544... logprob:  0.573975, 0.213542 (1.426 sec)
26.545... logprob:  0.548408, 0.247396 (1.425 sec)
26.546... logprob:  0.531160, 0.246094 (1.480 sec)
26.547... logprob:  0.563549, 0.253906 (1.426 sec)
26.548... logprob:  0.725069, 0.319010 (1.435 sec)
26.549... logprob:  0.660522, 0.283854 (1.474 sec)
26.550... logprob:  0.627304, 0.290365 (1.427 sec)
26.551... logprob:  0.674351, 0.289062 (1.425 sec)
26.552... logprob:  0.710740, 0.305990 (1.433 sec)
26.553... logprob:  0.586019, 0.282552 (1.427 sec)
26.554... logprob:  0.734840, 0.350260 (1.424 sec)
26.555... logprob:  0.602514, 0.255208 (1.479 sec)
26.556... logprob:  0.533091, 0.243490 (1.429 sec)
26.557... logprob:  0.550396, 0.255208 (1.445 sec)
26.558... logprob:  0.584818, 0.279948 (1.472 sec)
26.559... logprob:  0.742895, 0.330729 (1.429 sec)
26.560... logprob:  0.609618, 0.291667 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.496931, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.856751e-03 [1.429838e-07] 
Layer 'conv1' biases: 2.136919e-06 [1.280083e-10] 
Layer 'conv2' weights[0]: 2.851156e-03 [1.427181e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.419899e-09] 
Layer 'conv3' weights[0]: 2.849929e-03 [1.434650e-07] 
Layer 'conv3' biases: 3.525946e-05 [1.178864e-08] 
Layer 'conv4' weights[0]: 2.861967e-03 [1.445720e-07] 
Layer 'conv4' biases: 9.998937e-01 [2.772749e-07] 
Layer 'conv5' weights[0]: 3.009463e-03 [3.069919e-06] 
Layer 'conv5' biases: 9.991440e-01 [3.333633e-06] 
Layer 'fc6' weights[0]: 6.824562e-03 [6.608043e-08] 
Layer 'fc6' biases: 9.999897e-01 [6.011125e-08] 
Layer 'fc7' weights[0]: 7.171162e-03 [1.544826e-07] 
Layer 'fc7' biases: 9.997415e-01 [2.362336e-07] 
Layer 'fc8' weights[0]: 4.809032e-03 [1.442956e-05] 
Layer 'fc8' biases: 2.169255e-02 [3.568790e-05] 
Train error last 800 batches: 0.654858
-------------------------------------------------------
Not saving because 0.496931 > 0.299667 (9.300: -1.18%)
======================================================= (2.377 sec)
26.561... logprob:  0.610397, 0.244792 (1.430 sec)
26.562... logprob:  0.707072, 0.298177 (1.418 sec)
26.563... logprob:  0.681165, 0.289062 (1.440 sec)
26.564... logprob:  0.728646, 0.355469 (1.456 sec)
26.565... logprob:  0.888777, 0.367188 (1.444 sec)
26.566... logprob:  0.608406, 0.276042 (1.450 sec)
26.567... logprob:  0.674439, 0.281250 (1.455 sec)
26.568... logprob:  0.723139, 0.309896 (1.453 sec)
26.569... logprob:  0.671985, 0.286458 (1.435 sec)
26.570... logprob:  0.751733, 0.315104 (1.419 sec)
26.571... logprob:  0.652510, 0.304688 (1.423 sec)
26.572... logprob:  0.751359, 0.321615 (1.434 sec)
26.573... logprob:  0.729454, 0.326823 (1.440 sec)
26.574... logprob:  0.733525, 0.322917 (1.453 sec)
26.575... logprob:  0.572189, 0.277344 (1.449 sec)
26.576... logprob:  0.633851, 0.265625 (1.435 sec)
26.577... logprob:  0.664165, 0.291667 (1.470 sec)
26.578... logprob:  0.568238, 0.272135 (1.427 sec)
26.579... logprob:  0.716593, 0.295573 (1.419 sec)
26.580... logprob:  0.829758, 0.377604 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.486918, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.853914e-03 [1.427155e-07] 
Layer 'conv1' biases: 2.137405e-06 [7.326439e-11] 
Layer 'conv2' weights[0]: 2.848306e-03 [1.424694e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.097546e-09] 
Layer 'conv3' weights[0]: 2.847079e-03 [1.428229e-07] 
Layer 'conv3' biases: 3.528783e-05 [9.665426e-09] 
Layer 'conv4' weights[0]: 2.859117e-03 [1.435878e-07] 
Layer 'conv4' biases: 9.998939e-01 [2.443815e-07] 
Layer 'conv5' weights[0]: 3.007191e-03 [2.898215e-06] 
Layer 'conv5' biases: 9.991813e-01 [3.146803e-06] 
Layer 'fc6' weights[0]: 6.823851e-03 [6.868736e-08] 
Layer 'fc6' biases: 9.999896e-01 [6.313423e-08] 
Layer 'fc7' weights[0]: 7.170435e-03 [1.602120e-07] 
Layer 'fc7' biases: 9.997388e-01 [2.362332e-07] 
Layer 'fc8' weights[0]: 4.721166e-03 [1.453144e-05] 
Layer 'fc8' biases: 2.101292e-02 [3.683520e-05] 
Train error last 800 batches: 0.655443
-------------------------------------------------------
Not saving because 0.486918 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
26.581... logprob:  0.700567, 0.315104 (1.444 sec)
26.582... logprob:  0.731646, 0.307292 (1.433 sec)
26.583... logprob:  0.711733, 0.321615 (1.471 sec)
26.584... logprob:  0.647849, 0.309896 (1.440 sec)
26.585... logprob:  0.580213, 0.268229 (1.433 sec)
26.586... logprob:  0.525080, 0.230469 (1.481 sec)
26.587... logprob:  0.652933, 0.303385 (1.434 sec)
26.588... logprob:  0.693757, 0.319010 (1.425 sec)
26.589... logprob:  0.663862, 0.292969 (1.437 sec)
26.590... logprob:  0.701356, 0.309896 (1.425 sec)
26.591... logprob:  0.714059, 0.317708 (1.425 sec)
26.592... logprob:  0.676561, 0.292969 (1.478 sec)
26.593... logprob:  0.690569, 0.299479 (1.436 sec)
26.594... logprob:  0.634885, 0.286458 (1.435 sec)
26.595... logprob:  0.645214, 0.274740 (1.494 sec)
26.596... logprob:  0.722024, 0.316406 (1.433 sec)
26.597... logprob:  0.628539, 0.286458 (1.431 sec)
26.598... logprob:  0.620441, 0.277344 (1.430 sec)
26.599... logprob:  0.606818, 0.290365 (1.425 sec)
26.600... logprob:  0.563903, 0.272135 (1.432 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.464799, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.851053e-03 [1.427732e-07] 
Layer 'conv1' biases: 2.137443e-06 [1.034316e-10] 
Layer 'conv2' weights[0]: 2.845474e-03 [1.424311e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.244028e-09] 
Layer 'conv3' weights[0]: 2.844257e-03 [1.430347e-07] 
Layer 'conv3' biases: 3.528940e-05 [1.035169e-08] 
Layer 'conv4' weights[0]: 2.856242e-03 [1.443478e-07] 
Layer 'conv4' biases: 9.998933e-01 [3.067601e-07] 
Layer 'conv5' weights[0]: 3.004672e-03 [3.805889e-06] 
Layer 'conv5' biases: 9.991677e-01 [4.235670e-06] 
Layer 'fc6' weights[0]: 6.823138e-03 [7.466789e-08] 
Layer 'fc6' biases: 9.999896e-01 [7.004655e-08] 
Layer 'fc7' weights[0]: 7.169721e-03 [1.774901e-07] 
Layer 'fc7' biases: 9.997391e-01 [3.053103e-07] 
Layer 'fc8' weights[0]: 4.738920e-03 [1.742870e-05] 
Layer 'fc8' biases: 2.115221e-02 [5.396129e-05] 
Train error last 800 batches: 0.655916
-------------------------------------------------------
Not saving because 0.464799 > 0.299667 (9.300: -1.18%)
======================================================= (2.345 sec)
26.601... logprob:  0.565515, 0.238281 (1.485 sec)
26.602... logprob:  0.588751, 0.290364 (1.435 sec)
26.603... logprob:  0.477674, 0.205729 (1.441 sec)
26.604... logprob:  0.604342, 0.273437 (1.476 sec)
26.605... logprob:  0.726426, 0.317708 (1.426 sec)
26.606... logprob:  0.572741, 0.253906 (1.433 sec)
26.607... logprob:  0.771881, 0.307292 (1.426 sec)
26.608... logprob:  0.561064, 0.276042 (1.427 sec)
26.609... logprob:  0.588733, 0.276042 (1.433 sec)
26.610... logprob:  0.669313, 0.276042 (1.467 sec)
26.611... logprob:  0.696666, 0.299479 (1.442 sec)
26.612... logprob:  0.671566, 0.308594 (1.446 sec)
26.613... logprob:  0.633452, 0.296875 (1.457 sec)
26.614... logprob:  0.651758, 0.313802 (1.440 sec)
26.615... logprob:  0.562894, 0.250000 (1.432 sec)
26.616... logprob:  0.682739, 0.312500 (1.421 sec)
26.617... logprob:  0.657471, 0.298177 (1.423 sec)
26.618... logprob:  0.738141, 0.320312 (1.436 sec)
26.619... logprob:  0.630340, 0.238281 (1.449 sec)
26.620... logprob:  0.692397, 0.321615 (1.452 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.490377, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.848200e-03 [1.425668e-07] 
Layer 'conv1' biases: 2.137343e-06 [7.867939e-11] 
Layer 'conv2' weights[0]: 2.842615e-03 [1.422172e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.096456e-09] 
Layer 'conv3' weights[0]: 2.841394e-03 [1.425842e-07] 
Layer 'conv3' biases: 3.530016e-05 [8.705128e-09] 
Layer 'conv4' weights[0]: 2.853383e-03 [1.433289e-07] 
Layer 'conv4' biases: 9.998924e-01 [2.102126e-07] 
Layer 'conv5' weights[0]: 3.001356e-03 [2.620864e-06] 
Layer 'conv5' biases: 9.991229e-01 [2.906774e-06] 
Layer 'fc6' weights[0]: 6.822398e-03 [6.434928e-08] 
Layer 'fc6' biases: 9.999895e-01 [5.864469e-08] 
Layer 'fc7' weights[0]: 7.169012e-03 [1.491795e-07] 
Layer 'fc7' biases: 9.997420e-01 [2.123214e-07] 
Layer 'fc8' weights[0]: 4.837580e-03 [1.434392e-05] 
Layer 'fc8' biases: 2.199671e-02 [3.468617e-05] 
Train error last 800 batches: 0.655297
-------------------------------------------------------
Not saving because 0.490377 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
26.621... logprob:  0.534926, 0.230469 (1.461 sec)
26.622... logprob:  0.652870, 0.302083 (1.447 sec)
26.623... logprob:  0.676512, 0.287760 (1.460 sec)
26.624... logprob:  0.546391, 0.236979 (1.432 sec)
26.625... logprob:  0.703053, 0.291667 (1.420 sec)
26.626... logprob:  0.688478, 0.279948 (1.429 sec)
26.627... logprob:  0.731401, 0.309896 (1.433 sec)
26.628... logprob:  0.672151, 0.304687 (1.432 sec)
26.629... logprob:  0.534580, 0.242188 (1.472 sec)
26.630... logprob:  0.597288, 0.255208 (1.443 sec)
26.631... logprob:  0.851505, 0.361979 (1.437 sec)
26.632... logprob:  0.575742, 0.268229 (1.477 sec)
26.633... logprob:  0.591938, 0.266927 (1.425 sec)
26.634... logprob:  0.779795, 0.333333 (1.423 sec)
26.635... logprob:  0.528556, 0.250000 (1.427 sec)
26.636... logprob:  0.661490, 0.261719 (1.430 sec)
26.637... logprob:  0.537805, 0.248698 (1.433 sec)
26.638... logprob:  0.722478, 0.282552 (1.474 sec)
26.639... logprob:  0.625316, 0.274740 (1.444 sec)
26.640... logprob:  0.734761, 0.295573 (1.434 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.407509, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.845353e-03 [1.423859e-07] 
Layer 'conv1' biases: 2.137637e-06 [9.346277e-11] 
Layer 'conv2' weights[0]: 2.839771e-03 [1.420532e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.128019e-09] 
Layer 'conv3' weights[0]: 2.838533e-03 [1.425155e-07] 
Layer 'conv3' biases: 3.533243e-05 [9.066701e-09] 
Layer 'conv4' weights[0]: 2.850542e-03 [1.432564e-07] 
Layer 'conv4' biases: 9.998927e-01 [2.350305e-07] 
Layer 'conv5' weights[0]: 2.999123e-03 [2.922958e-06] 
Layer 'conv5' biases: 9.991526e-01 [3.198876e-06] 
Layer 'fc6' weights[0]: 6.821681e-03 [7.055628e-08] 
Layer 'fc6' biases: 9.999894e-01 [6.594048e-08] 
Layer 'fc7' weights[0]: 7.168240e-03 [1.628861e-07] 
Layer 'fc7' biases: 9.997395e-01 [2.432227e-07] 
Layer 'fc8' weights[0]: 4.770079e-03 [1.449806e-05] 
Layer 'fc8' biases: 2.154863e-02 [3.316587e-05] 
Train error last 800 batches: 0.655086
-------------------------------------------------------
Not saving because 0.407509 > 0.299667 (9.300: -1.18%)
======================================================= (2.393 sec)
26.641... logprob:  0.692710, 0.303385 (1.484 sec)
26.642... logprob:  0.722117, 0.325521 (1.431 sec)
26.643... logprob:  0.848982, 0.347656 (1.432 sec)
26.644... logprob:  0.599588, 0.279948 (1.428 sec)
26.645... logprob:  0.708610, 0.296875 (1.424 sec)
26.646... logprob:  0.607425, 0.256510 (1.431 sec)
26.647... logprob:  0.697977, 0.287760 (1.483 sec)
26.648... logprob:  0.657486, 0.276042 (1.426 sec)
26.649... logprob:  0.584422, 0.240885 (1.439 sec)
26.650... logprob:  0.648996, 0.277344 (1.471 sec)
26.651... logprob:  0.681386, 0.294271 (1.421 sec)
26.652... logprob:  0.744831, 0.341146 (1.437 sec)
26.653... logprob:  0.778339, 0.337240 (1.432 sec)
26.654... logprob:  0.759019, 0.316406 (1.421 sec)
26.655... logprob:  0.573183, 0.233073 (1.427 sec)
26.656... logprob:  0.630612, 0.281250 (1.472 sec)
26.657... logprob:  0.653689, 0.305989 (1.437 sec)
26.658... logprob:  0.623481, 0.276042 (1.451 sec)
26.659... logprob:  0.688644, 0.315104 (1.464 sec)
26.660... logprob:  0.689898, 0.300781 (1.457 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.492001, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.842507e-03 [1.421774e-07] 
Layer 'conv1' biases: 2.137959e-06 [5.736152e-11] 
Layer 'conv2' weights[0]: 2.836923e-03 [1.419286e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.410625e-10] 
Layer 'conv3' weights[0]: 2.835706e-03 [1.421314e-07] 
Layer 'conv3' biases: 3.537126e-05 [6.708598e-09] 
Layer 'conv4' weights[0]: 2.847700e-03 [1.429251e-07] 
Layer 'conv4' biases: 9.998937e-01 [1.796357e-07] 
Layer 'conv5' weights[0]: 2.997321e-03 [2.325556e-06] 
Layer 'conv5' biases: 9.991784e-01 [2.483626e-06] 
Layer 'fc6' weights[0]: 6.820974e-03 [6.157554e-08] 
Layer 'fc6' biases: 9.999896e-01 [5.391469e-08] 
Layer 'fc7' weights[0]: 7.167554e-03 [1.380954e-07] 
Layer 'fc7' biases: 9.997372e-01 [1.648057e-07] 
Layer 'fc8' weights[0]: 4.703971e-03 [1.164115e-05] 
Layer 'fc8' biases: 2.099083e-02 [1.275242e-05] 
Train error last 800 batches: 0.655571
-------------------------------------------------------
Not saving because 0.492001 > 0.299667 (9.300: -1.18%)
======================================================= (2.379 sec)
26.661... logprob:  0.626687, 0.278646 (1.438 sec)
26.662... logprob:  0.707433, 0.315104 (1.432 sec)
26.663... logprob:  0.541582, 0.242187 (1.424 sec)
26.664... logprob:  0.502886, 0.225260 (1.434 sec)
26.665... logprob:  0.617248, 0.243490 (1.460 sec)
26.666... logprob:  0.620949, 0.263021 (1.446 sec)
26.667... logprob:  0.738647, 0.289062 (1.446 sec)
26.668... logprob:  0.740970, 0.326823 (1.444 sec)
26.669... logprob:  0.607631, 0.261719 (1.458 sec)
26.670... logprob:  0.633410, 0.261719 (1.436 sec)
26.671... logprob:  0.571708, 0.247396 (1.422 sec)
26.672... logprob:  0.608451, 0.264323 (1.431 sec)
26.673... logprob:  0.656778, 0.278646 (1.429 sec)
26.674... logprob:  0.677160, 0.276042 (1.438 sec)
26.675... logprob:  0.599555, 0.264323 (1.459 sec)
26.676... logprob:  0.787957, 0.319010 (1.446 sec)
26.677... logprob:  0.655280, 0.278646 (1.440 sec)
26.678... logprob:  0.685200, 0.305990 (1.478 sec)
26.679... logprob:  0.743713, 0.319010 (1.429 sec)
26.680... logprob:  0.531986, 0.247396 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.457739, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.839678e-03 [1.421217e-07] 
Layer 'conv1' biases: 2.138263e-06 [7.068770e-11] 
Layer 'conv2' weights[0]: 2.834082e-03 [1.418374e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.704252e-10] 
Layer 'conv3' weights[0]: 2.832855e-03 [1.420232e-07] 
Layer 'conv3' biases: 3.537012e-05 [6.612058e-09] 
Layer 'conv4' weights[0]: 2.844845e-03 [1.428857e-07] 
Layer 'conv4' biases: 9.998925e-01 [1.761647e-07] 
Layer 'conv5' weights[0]: 2.993952e-03 [2.782695e-06] 
Layer 'conv5' biases: 9.991413e-01 [2.966009e-06] 
Layer 'fc6' weights[0]: 6.820227e-03 [6.375829e-08] 
Layer 'fc6' biases: 9.999897e-01 [5.702210e-08] 
Layer 'fc7' weights[0]: 7.166763e-03 [1.437249e-07] 
Layer 'fc7' biases: 9.997395e-01 [1.804372e-07] 
Layer 'fc8' weights[0]: 4.773680e-03 [1.219200e-05] 
Layer 'fc8' biases: 2.155496e-02 [1.600486e-05] 
Train error last 800 batches: 0.656025
-------------------------------------------------------
Not saving because 0.457739 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
26.681... logprob:  0.601501, 0.270833 (1.435 sec)
26.682... logprob:  0.592857, 0.263021 (1.435 sec)
26.683... logprob:  0.615041, 0.273437 (1.424 sec)
26.684... logprob:  0.554681, 0.225260 (1.472 sec)
26.685... logprob:  0.545863, 0.266927 (1.437 sec)
26.686... logprob:  0.601268, 0.256510 (1.428 sec)
26.687... logprob:  0.537109, 0.255208 (1.480 sec)
26.688... logprob:  0.528989, 0.253906 (1.431 sec)
26.689... logprob:  0.671409, 0.316406 (1.430 sec)
26.690... logprob:  0.737424, 0.276042 (1.428 sec)
26.691... logprob:  0.655595, 0.235677 (1.427 sec)
26.692... logprob:  0.559100, 0.268229 (1.425 sec)
26.693... logprob:  0.697157, 0.329427 (1.475 sec)
26.694... logprob:  0.559288, 0.251302 (1.433 sec)
26.695... logprob:  0.589746, 0.279948 (1.434 sec)
26.696... logprob:  0.738421, 0.320312 (1.474 sec)
26.697... logprob:  0.692626, 0.289062 (1.433 sec)
26.698... logprob:  0.708674, 0.296875 (1.448 sec)
26.699... logprob:  0.697389, 0.313802 (1.434 sec)
26.700... logprob:  0.696771, 0.304687 (1.418 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.461957, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.836840e-03 [1.418602e-07] 
Layer 'conv1' biases: 2.138387e-06 [9.007191e-11] 
Layer 'conv2' weights[0]: 2.831259e-03 [1.416046e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.262853e-09] 
Layer 'conv3' weights[0]: 2.830040e-03 [1.422008e-07] 
Layer 'conv3' biases: 3.537490e-05 [1.056327e-08] 
Layer 'conv4' weights[0]: 2.842018e-03 [1.429403e-07] 
Layer 'conv4' biases: 9.998919e-01 [2.726226e-07] 
Layer 'conv5' weights[0]: 2.991262e-03 [2.901338e-06] 
Layer 'conv5' biases: 9.991159e-01 [3.260959e-06] 
Layer 'fc6' weights[0]: 6.819526e-03 [6.947046e-08] 
Layer 'fc6' biases: 9.999896e-01 [6.531280e-08] 
Layer 'fc7' weights[0]: 7.166045e-03 [1.644939e-07] 
Layer 'fc7' biases: 9.997408e-01 [2.574073e-07] 
Layer 'fc8' weights[0]: 4.814023e-03 [1.512800e-05] 
Layer 'fc8' biases: 2.193624e-02 [3.983261e-05] 
Train error last 800 batches: 0.655856
-------------------------------------------------------
Not saving because 0.461957 > 0.299667 (9.300: -1.18%)
======================================================= (2.403 sec)
26.701... logprob:  0.698783, 0.294271 (1.435 sec)
26.702... logprob:  0.693328, 0.281250 (1.481 sec)
26.703... logprob:  0.674062, 0.292969 (1.556 sec)
26.704... logprob:  0.670901, 0.317708 (1.442 sec)
26.705... logprob:  0.670032, 0.322917 (1.468 sec)
26.706... logprob:  0.672987, 0.289062 (1.427 sec)
26.707... logprob:  0.665863, 0.312500 (1.433 sec)
26.708... logprob:  0.647630, 0.305990 (1.426 sec)
26.709... logprob:  0.662812, 0.261719 (1.422 sec)
26.710... logprob:  0.769793, 0.341146 (1.436 sec)
26.711... logprob:  0.650990, 0.273437 (1.457 sec)
26.712... logprob:  0.508816, 0.216146 (1.443 sec)
26.713... logprob:  0.771249, 0.329427 (1.452 sec)
26.714... logprob:  0.720689, 0.325521 (1.453 sec)
26.715... logprob:  0.720988, 0.329427 (1.446 sec)
26.716... logprob:  0.604134, 0.286458 (1.435 sec)
26.717... logprob:  0.733710, 0.335938 (1.419 sec)
26.718... logprob:  0.706379, 0.302083 (1.422 sec)
26.719... logprob:  0.620418, 0.261719 (1.434 sec)
26.720... logprob:  0.703170, 0.304687 (1.448 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.497784, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.833995e-03 [1.417386e-07] 
Layer 'conv1' biases: 2.138345e-06 [5.113877e-11] 
Layer 'conv2' weights[0]: 2.828426e-03 [1.414913e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.577990e-10] 
Layer 'conv3' weights[0]: 2.827184e-03 [1.416062e-07] 
Layer 'conv3' biases: 3.540693e-05 [5.523139e-09] 
Layer 'conv4' weights[0]: 2.839172e-03 [1.422770e-07] 
Layer 'conv4' biases: 9.998949e-01 [1.616595e-07] 
Layer 'conv5' weights[0]: 2.990854e-03 [2.298232e-06] 
Layer 'conv5' biases: 9.991606e-01 [2.506468e-06] 
Layer 'fc6' weights[0]: 6.818817e-03 [6.327553e-08] 
Layer 'fc6' biases: 9.999896e-01 [5.669317e-08] 
Layer 'fc7' weights[0]: 7.165320e-03 [1.442199e-07] 
Layer 'fc7' biases: 9.997368e-01 [1.836283e-07] 
Layer 'fc8' weights[0]: 4.704286e-03 [1.248129e-05] 
Layer 'fc8' biases: 2.108970e-02 [1.572734e-05] 
Train error last 800 batches: 0.656103
-------------------------------------------------------
Not saving because 0.497784 > 0.299667 (9.300: -1.18%)
======================================================= (2.345 sec)
26.721... logprob:  0.668473, 0.296875 (1.468 sec)
26.722... logprob:  0.747615, 0.322917 (1.451 sec)
26.723... logprob:  0.641689, 0.302083 (1.439 sec)
26.724... logprob:  0.741383, 0.334635 (1.465 sec)
26.725... logprob:  0.669885, 0.282552 (1.431 sec)
26.726... logprob:  0.563250, 0.264323 (1.422 sec)
26.727... logprob:  0.626738, 0.259115 (1.433 sec)
26.728... logprob:  0.604782, 0.268229 (1.437 sec)
26.729... logprob:  0.644091, 0.259115 (1.430 sec)
26.730... logprob:  0.809501, 0.313802 (1.468 sec)
26.731... logprob:  0.717862, 0.291667 (1.442 sec)
26.732... logprob:  0.517096, 0.223958 (1.435 sec)
26.733... logprob:  0.705253, 0.309896 (1.483 sec)
26.734... logprob:  0.643937, 0.278646 (1.432 sec)
26.735... logprob:  0.705508, 0.295573 (1.427 sec)
26.736... logprob:  0.772582, 0.346354 (1.455 sec)
26.737... logprob:  0.682440, 0.300781 (1.434 sec)
26.738... logprob:  0.706304, 0.326823 (1.425 sec)
26.739... logprob:  0.651923, 0.286458 (1.479 sec)
26.740... logprob:  0.532476, 0.231771 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.577051, 0.171875 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.831153e-03 [1.416649e-07] 
Layer 'conv1' biases: 2.138741e-06 [8.281761e-11] 
Layer 'conv2' weights[0]: 2.825594e-03 [1.413758e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.055728e-09] 
Layer 'conv3' weights[0]: 2.824390e-03 [1.417648e-07] 
Layer 'conv3' biases: 3.539697e-05 [9.168580e-09] 
Layer 'conv4' weights[0]: 2.836338e-03 [1.426391e-07] 
Layer 'conv4' biases: 9.998963e-01 [2.268055e-07] 
Layer 'conv5' weights[0]: 2.989055e-03 [2.415585e-06] 
Layer 'conv5' biases: 9.991605e-01 [2.538265e-06] 
Layer 'fc6' weights[0]: 6.818133e-03 [6.227728e-08] 
Layer 'fc6' biases: 9.999897e-01 [5.499758e-08] 
Layer 'fc7' weights[0]: 7.164598e-03 [1.391305e-07] 
Layer 'fc7' biases: 9.997370e-01 [1.663009e-07] 
Layer 'fc8' weights[0]: 4.708646e-03 [1.175360e-05] 
Layer 'fc8' biases: 2.113761e-02 [1.315957e-05] 
Train error last 800 batches: 0.655629
-------------------------------------------------------
Not saving because 0.577051 > 0.299667 (9.300: -1.18%)
======================================================= (2.367 sec)
26.741... logprob:  0.663630, 0.298177 (1.436 sec)
26.742... logprob:  0.660504, 0.266927 (1.486 sec)
26.743... logprob:  0.616219, 0.272135 (1.432 sec)
26.744... logprob:  0.740809, 0.350260 (1.427 sec)
26.745... logprob:  0.756569, 0.326823 (1.432 sec)
26.746... logprob:  0.621469, 0.273437 (1.429 sec)
26.747... logprob:  0.619407, 0.286458 (1.426 sec)
26.748... logprob:  0.569142, 0.272135 (1.481 sec)
26.749... logprob:  0.700642, 0.296875 (1.427 sec)
26.750... logprob:  0.694316, 0.291667 (1.440 sec)
26.751... logprob:  0.573116, 0.253906 (1.485 sec)
26.752... logprob:  0.723028, 0.308594 (1.433 sec)
26.753... logprob:  0.700667, 0.312500 (1.431 sec)
26.754... logprob:  0.671361, 0.309896 (1.429 sec)
26.755... logprob:  0.673468, 0.300781 (1.429 sec)
26.756... logprob:  0.641140, 0.260417 (1.432 sec)
26.757... logprob:  0.711866, 0.282552 (1.469 sec)
26.758... logprob:  0.645339, 0.292969 (1.436 sec)
26.759... logprob:  0.745374, 0.321615 (1.451 sec)
26.760... logprob:  0.661166, 0.278646 (1.468 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.476960, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.828330e-03 [1.415036e-07] 
Layer 'conv1' biases: 2.138803e-06 [8.437733e-11] 
Layer 'conv2' weights[0]: 2.822783e-03 [1.411946e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.440768e-10] 
Layer 'conv3' weights[0]: 2.821560e-03 [1.415005e-07] 
Layer 'conv3' biases: 3.539916e-05 [7.892334e-09] 
Layer 'conv4' weights[0]: 2.833479e-03 [1.422227e-07] 
Layer 'conv4' biases: 9.998961e-01 [1.990560e-07] 
Layer 'conv5' weights[0]: 2.986526e-03 [2.765221e-06] 
Layer 'conv5' biases: 9.991517e-01 [2.953973e-06] 
Layer 'fc6' weights[0]: 6.817436e-03 [6.645656e-08] 
Layer 'fc6' biases: 9.999896e-01 [6.057267e-08] 
Layer 'fc7' weights[0]: 7.163851e-03 [1.538516e-07] 
Layer 'fc7' biases: 9.997373e-01 [2.124335e-07] 
Layer 'fc8' weights[0]: 4.728443e-03 [1.351438e-05] 
Layer 'fc8' biases: 2.134765e-02 [2.689999e-05] 
Train error last 800 batches: 0.655905
-------------------------------------------------------
Not saving because 0.476960 > 0.299667 (9.300: -1.18%)
======================================================= (2.348 sec)
26.761... logprob:  0.665190, 0.307292 (1.446 sec)
26.762... logprob:  0.755314, 0.322917 (1.439 sec)
26.763... logprob:  0.722581, 0.309896 (1.430 sec)
26.764... logprob:  0.739318, 0.312500 (1.418 sec)
26.765... logprob:  0.525139, 0.252604 (1.433 sec)
26.766... logprob:  0.664712, 0.296875 (1.446 sec)
26.767... logprob:  0.644243, 0.285156 (1.451 sec)
26.768... logprob:  0.743771, 0.337239 (1.458 sec)
26.769... logprob:  0.688365, 0.282552 (1.459 sec)
26.770... logprob:  0.610027, 0.257812 (1.481 sec)
26.771... logprob:  0.787941, 0.339844 (1.453 sec)
26.772... logprob:  0.558134, 0.263021 (1.440 sec)
26.773... logprob:  0.749741, 0.333333 (1.438 sec)
26.774... logprob:  0.540790, 0.253906 (1.477 sec)
26.775... logprob:  0.667210, 0.295573 (1.459 sec)
26.776... logprob:  0.677899, 0.303385 (1.472 sec)
26.777... logprob:  0.587917, 0.263021 (1.466 sec)
26.778... logprob:  0.613797, 0.287760 (1.459 sec)
26.779... logprob:  0.770554, 0.332031 (1.479 sec)
26.780... logprob:  0.630502, 0.281250 (1.443 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.493669, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.825497e-03 [1.413675e-07] 
Layer 'conv1' biases: 2.139134e-06 [4.771034e-11] 
Layer 'conv2' weights[0]: 2.819971e-03 [1.410795e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.431670e-10] 
Layer 'conv3' weights[0]: 2.818734e-03 [1.413270e-07] 
Layer 'conv3' biases: 3.537496e-05 [7.183773e-09] 
Layer 'conv4' weights[0]: 2.830665e-03 [1.421705e-07] 
Layer 'conv4' biases: 9.998955e-01 [2.012285e-07] 
Layer 'conv5' weights[0]: 2.983735e-03 [2.261262e-06] 
Layer 'conv5' biases: 9.991607e-01 [2.406954e-06] 
Layer 'fc6' weights[0]: 6.816741e-03 [6.446071e-08] 
Layer 'fc6' biases: 9.999897e-01 [5.761505e-08] 
Layer 'fc7' weights[0]: 7.163170e-03 [1.485143e-07] 
Layer 'fc7' biases: 9.997370e-01 [2.009931e-07] 
Layer 'fc8' weights[0]: 4.709701e-03 [1.393882e-05] 
Layer 'fc8' biases: 2.122262e-02 [3.113365e-05] 
Train error last 800 batches: 0.656178
-------------------------------------------------------
Not saving because 0.493669 > 0.299667 (9.300: -1.18%)
======================================================= (2.353 sec)
26.781... logprob:  0.647486, 0.255208 (1.452 sec)
26.782... logprob:  0.573756, 0.235677 (1.449 sec)
26.783... logprob:  0.707413, 0.299479 (1.451 sec)
26.784... logprob:  0.666673, 0.295573 (1.448 sec)
26.785... logprob:  0.743382, 0.329427 (1.480 sec)
26.786... logprob:  0.701789, 0.319010 (1.465 sec)
26.787... logprob:  0.816040, 0.324219 (1.456 sec)
26.788... logprob:  0.726091, 0.315104 (1.496 sec)
26.789... logprob:  0.556351, 0.257812 (1.449 sec)
26.790... logprob:  0.632686, 0.283854 (1.446 sec)
26.791... logprob:  0.605971, 0.289062 (1.446 sec)
26.792... logprob:  0.614954, 0.252604 (1.454 sec)
26.793... logprob:  0.650514, 0.274739 (1.447 sec)
26.794... logprob:  0.627871, 0.299479 (1.481 sec)
26.795... logprob:  0.660176, 0.292969 (1.462 sec)
26.796... logprob:  0.659597, 0.272135 (1.456 sec)
26.797... logprob:  0.694293, 0.316406 (1.493 sec)
26.798... logprob:  0.623883, 0.283854 (1.450 sec)
26.799... logprob:  0.553664, 0.252604 (1.450 sec)
26.800... logprob:  0.567008, 0.256510 (1.398 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.488163, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.822673e-03 [1.413147e-07] 
Layer 'conv1' biases: 2.138973e-06 [9.966456e-11] 
Layer 'conv2' weights[0]: 2.817135e-03 [1.410036e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.240537e-09] 
Layer 'conv3' weights[0]: 2.815915e-03 [1.416802e-07] 
Layer 'conv3' biases: 3.537149e-05 [1.134206e-08] 
Layer 'conv4' weights[0]: 2.827837e-03 [1.428691e-07] 
Layer 'conv4' biases: 9.998951e-01 [3.165193e-07] 
Layer 'conv5' weights[0]: 2.980709e-03 [3.123656e-06] 
Layer 'conv5' biases: 9.991481e-01 [3.442354e-06] 
Layer 'fc6' weights[0]: 6.816061e-03 [7.550510e-08] 
Layer 'fc6' biases: 9.999895e-01 [7.140081e-08] 
Layer 'fc7' weights[0]: 7.162467e-03 [1.821523e-07] 
Layer 'fc7' biases: 9.997376e-01 [3.164816e-07] 
Layer 'fc8' weights[0]: 4.738303e-03 [1.923993e-05] 
Layer 'fc8' biases: 2.153023e-02 [5.979837e-05] 
Train error last 800 batches: 0.656531
-------------------------------------------------------
Not saving because 0.488163 > 0.299667 (9.300: -1.18%)
======================================================= (2.344 sec)
27.1... logprob:  0.551682, 0.261719 (1.409 sec)
27.2... logprob:  0.681045, 0.279948 (1.447 sec)
27.3... logprob:  0.729725, 0.313802 (1.417 sec)
27.4... logprob:  0.637068, 0.278646 (1.397 sec)
27.5... logprob:  0.660768, 0.320312 (1.429 sec)
27.6... logprob:  0.757088, 0.316406 (1.388 sec)
27.7... logprob:  0.615127, 0.286458 (1.418 sec)
27.8... logprob:  0.700877, 0.320312 (1.392 sec)
27.9... logprob:  0.525515, 0.257813 (1.404 sec)
27.10... logprob:  0.528168, 0.235677 (1.405 sec)
27.11... logprob:  0.659445, 0.330729 (1.443 sec)
27.12... logprob:  0.670732, 0.290365 (1.396 sec)
27.13... logprob:  0.641287, 0.299479 (1.419 sec)
27.14... logprob:  0.689736, 0.320313 (1.395 sec)
27.15... logprob:  0.746678, 0.304687 (1.406 sec)
27.16... logprob:  0.580947, 0.268229 (1.398 sec)
27.17... logprob:  0.738541, 0.335937 (1.391 sec)
27.18... logprob:  0.467424, 0.197917 (1.392 sec)
27.19... logprob:  0.529040, 0.231771 (1.394 sec)
27.20... logprob:  0.631996, 0.255208 (1.396 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.497181, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.819859e-03 [1.410686e-07] 
Layer 'conv1' biases: 2.139022e-06 [4.543985e-11] 
Layer 'conv2' weights[0]: 2.814324e-03 [1.407710e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.468820e-10] 
Layer 'conv3' weights[0]: 2.813104e-03 [1.408358e-07] 
Layer 'conv3' biases: 3.538571e-05 [4.835648e-09] 
Layer 'conv4' weights[0]: 2.825001e-03 [1.415018e-07] 
Layer 'conv4' biases: 9.998939e-01 [1.235583e-07] 
Layer 'conv5' weights[0]: 2.977468e-03 [2.194141e-06] 
Layer 'conv5' biases: 9.991301e-01 [2.331385e-06] 
Layer 'fc6' weights[0]: 6.815357e-03 [6.011336e-08] 
Layer 'fc6' biases: 9.999894e-01 [5.280563e-08] 
Layer 'fc7' weights[0]: 7.161719e-03 [1.366483e-07] 
Layer 'fc7' biases: 9.997389e-01 [1.719117e-07] 
Layer 'fc8' weights[0]: 4.783772e-03 [1.164098e-05] 
Layer 'fc8' biases: 2.195259e-02 [2.262031e-05] 
Train error last 800 batches: 0.656961
-------------------------------------------------------
Not saving because 0.497181 > 0.299667 (9.300: -1.18%)
======================================================= (2.416 sec)
27.21... logprob:  0.634559, 0.298177 (1.407 sec)
27.22... logprob:  0.731811, 0.317708 (1.414 sec)
27.23... logprob:  0.698219, 0.315104 (1.412 sec)
27.24... logprob:  0.551092, 0.244792 (1.413 sec)
27.25... logprob:  0.626622, 0.298177 (1.404 sec)
27.26... logprob:  0.694887, 0.319010 (1.436 sec)
27.27... logprob:  0.614110, 0.274740 (1.383 sec)
27.28... logprob:  0.659284, 0.289062 (1.416 sec)
27.29... logprob:  0.575233, 0.243490 (1.424 sec)
27.30... logprob:  0.561851, 0.243490 (1.412 sec)
27.31... logprob:  0.707583, 0.319010 (1.397 sec)
27.32... logprob:  0.666732, 0.320313 (1.382 sec)
27.33... logprob:  0.728259, 0.334635 (1.441 sec)
27.34... logprob:  0.673905, 0.268229 (1.392 sec)
27.35... logprob:  0.524198, 0.239583 (1.395 sec)
27.36... logprob:  0.706145, 0.290365 (1.394 sec)
27.37... logprob:  0.585422, 0.261719 (1.402 sec)
27.38... logprob:  0.696145, 0.332031 (1.391 sec)
27.39... logprob:  0.756572, 0.347656 (1.437 sec)
27.40... logprob:  0.652925, 0.300781 (1.409 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.498813, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.817018e-03 [1.409724e-07] 
Layer 'conv1' biases: 2.139240e-06 [9.293106e-11] 
Layer 'conv2' weights[0]: 2.811508e-03 [1.406776e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.213840e-09] 
Layer 'conv3' weights[0]: 2.810300e-03 [1.412566e-07] 
Layer 'conv3' biases: 3.541679e-05 [1.060803e-08] 
Layer 'conv4' weights[0]: 2.822179e-03 [1.420307e-07] 
Layer 'conv4' biases: 9.998929e-01 [2.758441e-07] 
Layer 'conv5' weights[0]: 2.974239e-03 [3.070294e-06] 
Layer 'conv5' biases: 9.991440e-01 [3.332494e-06] 
Layer 'fc6' weights[0]: 6.814684e-03 [7.125407e-08] 
Layer 'fc6' biases: 9.999896e-01 [6.689883e-08] 
Layer 'fc7' weights[0]: 7.161034e-03 [1.717676e-07] 
Layer 'fc7' biases: 9.997375e-01 [2.841857e-07] 
Layer 'fc8' weights[0]: 4.757376e-03 [1.982926e-05] 
Layer 'fc8' biases: 2.181767e-02 [6.167271e-05] 
Train error last 800 batches: 0.656704
-------------------------------------------------------
Not saving because 0.498813 > 0.299667 (9.300: -1.18%)
======================================================= (2.362 sec)
27.41... logprob:  0.565398, 0.250000 (1.428 sec)
27.42... logprob:  0.528719, 0.235677 (1.414 sec)
27.43... logprob:  0.666668, 0.292969 (1.401 sec)
27.44... logprob:  0.734018, 0.317708 (1.430 sec)
27.45... logprob:  0.595550, 0.279948 (1.382 sec)
27.46... logprob:  0.745119, 0.342448 (1.402 sec)
27.47... logprob:  0.587071, 0.235677 (1.394 sec)
27.48... logprob:  0.691583, 0.268229 (1.416 sec)
27.49... logprob:  0.771491, 0.319010 (1.410 sec)
27.50... logprob:  0.658268, 0.299479 (1.425 sec)
27.51... logprob:  0.618815, 0.265625 (1.435 sec)
27.52... logprob:  0.742588, 0.328125 (1.394 sec)
27.53... logprob:  0.548012, 0.252604 (1.444 sec)
27.54... logprob:  0.542800, 0.227864 (1.381 sec)
27.55... logprob:  0.636701, 0.305990 (1.401 sec)
27.56... logprob:  0.552209, 0.216146 (1.393 sec)
27.57... logprob:  0.736004, 0.333333 (1.423 sec)
27.58... logprob:  0.645625, 0.279948 (1.396 sec)
27.59... logprob:  0.594340, 0.260417 (1.460 sec)
27.60... logprob:  0.875404, 0.347656 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.419885, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.814229e-03 [1.407980e-07] 
Layer 'conv1' biases: 2.139448e-06 [6.857409e-11] 
Layer 'conv2' weights[0]: 2.808694e-03 [1.405113e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.483730e-10] 
Layer 'conv3' weights[0]: 2.807470e-03 [1.408046e-07] 
Layer 'conv3' biases: 3.545255e-05 [7.957638e-09] 
Layer 'conv4' weights[0]: 2.819339e-03 [1.415009e-07] 
Layer 'conv4' biases: 9.998922e-01 [2.127704e-07] 
Layer 'conv5' weights[0]: 2.970951e-03 [2.591954e-06] 
Layer 'conv5' biases: 9.991511e-01 [2.763093e-06] 
Layer 'fc6' weights[0]: 6.813979e-03 [6.725287e-08] 
Layer 'fc6' biases: 9.999895e-01 [6.158256e-08] 
Layer 'fc7' weights[0]: 7.160319e-03 [1.552508e-07] 
Layer 'fc7' biases: 9.997369e-01 [2.137450e-07] 
Layer 'fc8' weights[0]: 4.742487e-03 [1.391484e-05] 
Layer 'fc8' biases: 2.167499e-02 [2.793865e-05] 
Train error last 800 batches: 0.656460
-------------------------------------------------------
Not saving because 0.419885 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
27.61... logprob:  0.602365, 0.265625 (1.430 sec)
27.62... logprob:  0.718837, 0.337240 (1.455 sec)
27.63... logprob:  0.666365, 0.296875 (1.433 sec)
27.64... logprob:  0.673814, 0.312500 (1.406 sec)
27.65... logprob:  0.588892, 0.234375 (1.397 sec)
27.66... logprob:  0.532102, 0.213542 (1.439 sec)
27.67... logprob:  0.541436, 0.250000 (1.379 sec)
27.68... logprob:  0.670909, 0.311198 (1.394 sec)
27.69... logprob:  0.710016, 0.303385 (1.418 sec)
27.70... logprob:  0.616702, 0.269531 (1.425 sec)
27.71... logprob:  0.644652, 0.278646 (1.452 sec)
27.72... logprob:  0.723655, 0.315104 (1.403 sec)
27.73... logprob:  0.659922, 0.279948 (1.418 sec)
27.74... logprob:  0.635650, 0.283854 (1.415 sec)
27.75... logprob:  0.677940, 0.291667 (1.414 sec)
27.76... logprob:  0.671162, 0.326823 (1.429 sec)
27.77... logprob:  0.624975, 0.308594 (1.424 sec)
27.78... logprob:  0.718467, 0.308594 (1.453 sec)
27.79... logprob:  0.745440, 0.347656 (1.397 sec)
27.80... logprob:  0.765294, 0.313802 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.442594, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.811403e-03 [1.405595e-07] 
Layer 'conv1' biases: 2.139530e-06 [7.362054e-11] 
Layer 'conv2' weights[0]: 2.805880e-03 [1.403291e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.305164e-10] 
Layer 'conv3' weights[0]: 2.804664e-03 [1.406327e-07] 
Layer 'conv3' biases: 3.547516e-05 [7.942450e-09] 
Layer 'conv4' weights[0]: 2.816526e-03 [1.413671e-07] 
Layer 'conv4' biases: 9.998913e-01 [2.120313e-07] 
Layer 'conv5' weights[0]: 2.967880e-03 [2.617044e-06] 
Layer 'conv5' biases: 9.991381e-01 [2.803457e-06] 
Layer 'fc6' weights[0]: 6.813268e-03 [6.461326e-08] 
Layer 'fc6' biases: 9.999896e-01 [5.871217e-08] 
Layer 'fc7' weights[0]: 7.159570e-03 [1.477239e-07] 
Layer 'fc7' biases: 9.997379e-01 [1.952831e-07] 
Layer 'fc8' weights[0]: 4.768749e-03 [1.315413e-05] 
Layer 'fc8' biases: 2.188204e-02 [2.005488e-05] 
Train error last 800 batches: 0.656662
-------------------------------------------------------
Not saving because 0.442594 > 0.299667 (9.300: -1.18%)
======================================================= (2.408 sec)
27.81... logprob:  0.610175, 0.279948 (1.419 sec)
27.82... logprob:  0.499495, 0.236979 (1.424 sec)
27.83... logprob:  0.764106, 0.346354 (1.400 sec)
27.84... logprob:  0.627057, 0.268229 (1.460 sec)
27.85... logprob:  0.690787, 0.302083 (1.418 sec)
27.86... logprob:  0.753473, 0.316406 (1.413 sec)
27.87... logprob:  0.822805, 0.351562 (1.407 sec)
27.88... logprob:  0.822512, 0.324219 (1.402 sec)
27.89... logprob:  0.668641, 0.282552 (1.427 sec)
27.90... logprob:  0.794432, 0.341146 (1.407 sec)
27.91... logprob:  0.525851, 0.243490 (1.392 sec)
27.92... logprob:  0.679435, 0.294271 (1.403 sec)
27.93... logprob:  0.678107, 0.311198 (1.397 sec)
27.94... logprob:  0.729853, 0.287760 (1.393 sec)
27.95... logprob:  0.691883, 0.295573 (1.402 sec)
27.96... logprob:  0.824143, 0.350260 (1.417 sec)
27.97... logprob:  0.649255, 0.287760 (1.390 sec)
27.98... logprob:  0.625892, 0.291667 (1.439 sec)
27.99... logprob:  0.610294, 0.250000 (1.405 sec)
27.100... logprob:  0.604820, 0.265625 (1.391 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.477443, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.808600e-03 [1.404410e-07] 
Layer 'conv1' biases: 2.139926e-06 [4.828912e-11] 
Layer 'conv2' weights[0]: 2.803074e-03 [1.402079e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.081951e-10] 
Layer 'conv3' weights[0]: 2.801862e-03 [1.403732e-07] 
Layer 'conv3' biases: 3.548458e-05 [6.324724e-09] 
Layer 'conv4' weights[0]: 2.813727e-03 [1.411167e-07] 
Layer 'conv4' biases: 9.998935e-01 [1.652560e-07] 
Layer 'conv5' weights[0]: 2.967603e-03 [2.177166e-06] 
Layer 'conv5' biases: 9.991753e-01 [2.271106e-06] 
Layer 'fc6' weights[0]: 6.812569e-03 [6.214510e-08] 
Layer 'fc6' biases: 9.999899e-01 [5.473460e-08] 
Layer 'fc7' weights[0]: 7.158883e-03 [1.433049e-07] 
Layer 'fc7' biases: 9.997349e-01 [1.798459e-07] 
Layer 'fc8' weights[0]: 4.678385e-03 [1.305445e-05] 
Layer 'fc8' biases: 2.118971e-02 [2.477211e-05] 
Train error last 800 batches: 0.657183
-------------------------------------------------------
Not saving because 0.477443 > 0.299667 (9.300: -1.18%)
======================================================= (2.363 sec)
27.101... logprob:  0.589705, 0.277344 (1.445 sec)
27.102... logprob:  0.729686, 0.333333 (1.398 sec)
27.103... logprob:  0.712669, 0.303385 (1.399 sec)
27.104... logprob:  0.638997, 0.298177 (1.394 sec)
27.105... logprob:  0.803994, 0.376302 (1.388 sec)
27.106... logprob:  0.595160, 0.260417 (1.392 sec)
27.107... logprob:  0.594324, 0.268229 (1.437 sec)
27.108... logprob:  0.734900, 0.326823 (1.399 sec)
27.109... logprob:  0.600678, 0.279948 (1.400 sec)
27.110... logprob:  0.823087, 0.347656 (1.392 sec)
27.111... logprob:  0.636230, 0.286458 (1.387 sec)
27.112... logprob:  0.594253, 0.278646 (1.396 sec)
27.113... logprob:  0.576767, 0.236979 (1.406 sec)
27.114... logprob:  0.669909, 0.303385 (1.423 sec)
27.115... logprob:  0.759563, 0.367188 (1.408 sec)
27.116... logprob:  0.613885, 0.270833 (1.390 sec)
27.117... logprob:  0.661316, 0.269531 (1.437 sec)
27.118... logprob:  0.685085, 0.329427 (1.384 sec)
27.119... logprob:  0.639115, 0.300781 (1.387 sec)
27.120... logprob:  0.676095, 0.296875 (1.396 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.567401, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.805786e-03 [1.404033e-07] 
Layer 'conv1' biases: 2.140417e-06 [1.023980e-10] 
Layer 'conv2' weights[0]: 2.800264e-03 [1.401659e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.255894e-09] 
Layer 'conv3' weights[0]: 2.799080e-03 [1.408467e-07] 
Layer 'conv3' biases: 3.546786e-05 [1.077044e-08] 
Layer 'conv4' weights[0]: 2.810909e-03 [1.420246e-07] 
Layer 'conv4' biases: 9.998915e-01 [2.813720e-07] 
Layer 'conv5' weights[0]: 2.963707e-03 [2.785750e-06] 
Layer 'conv5' biases: 9.991436e-01 [2.995508e-06] 
Layer 'fc6' weights[0]: 6.811916e-03 [6.603615e-08] 
Layer 'fc6' biases: 9.999898e-01 [5.976565e-08] 
Layer 'fc7' weights[0]: 7.158114e-03 [1.543657e-07] 
Layer 'fc7' biases: 9.997369e-01 [2.324372e-07] 
Layer 'fc8' weights[0]: 4.741777e-03 [1.485904e-05] 
Layer 'fc8' biases: 2.175695e-02 [3.631582e-05] 
Train error last 800 batches: 0.656988
-------------------------------------------------------
Not saving because 0.567401 > 0.299667 (9.300: -1.18%)
======================================================= (2.353 sec)
27.121... logprob:  0.653037, 0.298177 (1.396 sec)
27.122... logprob:  0.679913, 0.298177 (1.445 sec)
27.123... logprob:  0.754473, 0.317708 (1.383 sec)
27.124... logprob:  0.701751, 0.308594 (1.397 sec)
27.125... logprob:  0.765811, 0.356771 (1.393 sec)
27.126... logprob:  0.606225, 0.286458 (1.386 sec)
27.127... logprob:  0.697187, 0.316406 (1.396 sec)
27.128... logprob:  0.638005, 0.257812 (1.414 sec)
27.129... logprob:  0.819327, 0.321615 (1.441 sec)
27.130... logprob:  0.586838, 0.270833 (1.409 sec)
27.131... logprob:  0.717604, 0.308594 (1.404 sec)
27.132... logprob:  0.730113, 0.296875 (1.428 sec)
27.133... logprob:  0.649350, 0.291667 (1.391 sec)
27.134... logprob:  0.626379, 0.287760 (1.390 sec)
27.135... logprob:  0.740113, 0.312500 (1.402 sec)
27.136... logprob:  0.713687, 0.298177 (1.390 sec)
27.137... logprob:  0.713764, 0.319010 (1.389 sec)
27.138... logprob:  0.512075, 0.253906 (1.441 sec)
27.139... logprob:  0.591955, 0.261719 (1.391 sec)
27.140... logprob:  0.699360, 0.296875 (1.405 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.523771, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.802986e-03 [1.401680e-07] 
Layer 'conv1' biases: 2.140685e-06 [6.171009e-11] 
Layer 'conv2' weights[0]: 2.797473e-03 [1.399199e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.622757e-10] 
Layer 'conv3' weights[0]: 2.796270e-03 [1.401033e-07] 
Layer 'conv3' biases: 3.546845e-05 [6.415756e-09] 
Layer 'conv4' weights[0]: 2.808094e-03 [1.408735e-07] 
Layer 'conv4' biases: 9.998918e-01 [1.831875e-07] 
Layer 'conv5' weights[0]: 2.961414e-03 [2.242239e-06] 
Layer 'conv5' biases: 9.991590e-01 [2.414258e-06] 
Layer 'fc6' weights[0]: 6.811211e-03 [6.152681e-08] 
Layer 'fc6' biases: 9.999899e-01 [5.452880e-08] 
Layer 'fc7' weights[0]: 7.157323e-03 [1.445062e-07] 
Layer 'fc7' biases: 9.997354e-01 [1.932155e-07] 
Layer 'fc8' weights[0]: 4.706232e-03 [1.362666e-05] 
Layer 'fc8' biases: 2.152258e-02 [3.059394e-05] 
Train error last 800 batches: 0.656863
-------------------------------------------------------
Not saving because 0.523771 > 0.299667 (9.300: -1.18%)
======================================================= (2.353 sec)
27.141... logprob:  0.720575, 0.320312 (1.437 sec)
27.142... logprob:  0.710049, 0.342448 (1.397 sec)
27.143... logprob:  0.512988, 0.203125 (1.422 sec)
27.144... logprob:  0.631745, 0.264323 (1.413 sec)
27.145... logprob:  0.542071, 0.240885 (1.411 sec)
27.146... logprob:  0.727656, 0.341146 (1.411 sec)
27.147... logprob:  0.561985, 0.255208 (1.431 sec)
27.148... logprob:  0.689175, 0.295573 (1.384 sec)
27.149... logprob:  0.668064, 0.282552 (1.388 sec)
27.150... logprob:  0.636683, 0.286458 (1.395 sec)
27.151... logprob:  0.526559, 0.210938 (1.394 sec)
27.152... logprob:  0.938502, 0.402344 (1.390 sec)
27.153... logprob:  0.662197, 0.305990 (1.435 sec)
27.154... logprob:  0.640621, 0.268229 (1.397 sec)
27.155... logprob:  0.643515, 0.264323 (1.408 sec)
27.156... logprob:  0.534480, 0.238281 (1.435 sec)
27.157... logprob:  0.520153, 0.226562 (1.389 sec)
27.158... logprob:  0.730369, 0.316406 (1.391 sec)
27.159... logprob:  0.723739, 0.329427 (1.394 sec)
27.160... logprob:  0.694530, 0.307292 (1.387 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.457566, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.800177e-03 [1.401160e-07] 
Layer 'conv1' biases: 2.141210e-06 [6.753651e-11] 
Layer 'conv2' weights[0]: 2.794685e-03 [1.398417e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.069816e-10] 
Layer 'conv3' weights[0]: 2.793455e-03 [1.400439e-07] 
Layer 'conv3' biases: 3.547983e-05 [6.376711e-09] 
Layer 'conv4' weights[0]: 2.805287e-03 [1.407680e-07] 
Layer 'conv4' biases: 9.998904e-01 [1.691814e-07] 
Layer 'conv5' weights[0]: 2.957622e-03 [2.282721e-06] 
Layer 'conv5' biases: 9.991404e-01 [2.491801e-06] 
Layer 'fc6' weights[0]: 6.810511e-03 [6.506692e-08] 
Layer 'fc6' biases: 9.999898e-01 [5.893701e-08] 
Layer 'fc7' weights[0]: 7.156624e-03 [1.480899e-07] 
Layer 'fc7' biases: 9.997363e-01 [1.978618e-07] 
Layer 'fc8' weights[0]: 4.741618e-03 [1.433364e-05] 
Layer 'fc8' biases: 2.177338e-02 [3.660291e-05] 
Train error last 800 batches: 0.657094
-------------------------------------------------------
Not saving because 0.457566 > 0.299667 (9.300: -1.18%)
======================================================= (2.360 sec)
27.161... logprob:  0.581805, 0.273437 (1.403 sec)
27.162... logprob:  0.656627, 0.277344 (1.403 sec)
27.163... logprob:  0.652325, 0.289062 (1.422 sec)
27.164... logprob:  0.658983, 0.294271 (1.416 sec)
27.165... logprob:  0.729920, 0.300781 (1.412 sec)
27.166... logprob:  0.691109, 0.294271 (1.445 sec)
27.167... logprob:  0.594395, 0.273437 (1.423 sec)
27.168... logprob:  0.666402, 0.302083 (1.450 sec)
27.169... logprob:  0.662480, 0.285156 (1.460 sec)
27.170... logprob:  0.744976, 0.303385 (1.394 sec)
27.171... logprob:  0.708072, 0.308594 (1.415 sec)
27.172... logprob:  0.580497, 0.248698 (1.410 sec)
27.173... logprob:  0.704786, 0.296875 (1.423 sec)
27.174... logprob:  0.672164, 0.315104 (1.396 sec)
27.175... logprob:  0.738788, 0.322917 (1.461 sec)
27.176... logprob:  0.748782, 0.321615 (1.405 sec)
27.177... logprob:  0.573523, 0.238281 (1.425 sec)
27.178... logprob:  0.597417, 0.265625 (1.451 sec)
27.179... logprob:  0.608142, 0.272135 (1.402 sec)
27.180... logprob:  0.708218, 0.285156 (1.418 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.450123, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.797387e-03 [1.399932e-07] 
Layer 'conv1' biases: 2.141568e-06 [7.350789e-11] 
Layer 'conv2' weights[0]: 2.791891e-03 [1.396953e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.070220e-10] 
Layer 'conv3' weights[0]: 2.790660e-03 [1.399563e-07] 
Layer 'conv3' biases: 3.548258e-05 [8.187242e-09] 
Layer 'conv4' weights[0]: 2.802480e-03 [1.408775e-07] 
Layer 'conv4' biases: 9.998894e-01 [2.302499e-07] 
Layer 'conv5' weights[0]: 2.954456e-03 [2.646110e-06] 
Layer 'conv5' biases: 9.991449e-01 [2.865506e-06] 
Layer 'fc6' weights[0]: 6.809794e-03 [6.614517e-08] 
Layer 'fc6' biases: 9.999900e-01 [6.050350e-08] 
Layer 'fc7' weights[0]: 7.155934e-03 [1.573044e-07] 
Layer 'fc7' biases: 9.997357e-01 [2.284572e-07] 
Layer 'fc8' weights[0]: 4.729403e-03 [1.671447e-05] 
Layer 'fc8' biases: 2.168629e-02 [4.503020e-05] 
Train error last 800 batches: 0.657598
-------------------------------------------------------
Not saving because 0.450123 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
27.181... logprob:  0.729431, 0.295573 (1.419 sec)
27.182... logprob:  0.618038, 0.270833 (1.408 sec)
27.183... logprob:  0.625461, 0.240885 (1.412 sec)
27.184... logprob:  0.704648, 0.305990 (1.408 sec)
27.185... logprob:  0.518375, 0.252604 (1.391 sec)
27.186... logprob:  0.552451, 0.225260 (1.392 sec)
27.187... logprob:  0.670983, 0.292969 (1.394 sec)
27.188... logprob:  0.697553, 0.329427 (1.392 sec)
27.189... logprob:  0.629000, 0.294271 (1.380 sec)
27.190... logprob:  0.553318, 0.244792 (1.431 sec)
27.191... logprob:  0.719053, 0.332031 (1.402 sec)
27.192... logprob:  0.720267, 0.315104 (1.410 sec)
27.193... logprob:  0.617236, 0.252604 (1.418 sec)
27.194... logprob:  0.552900, 0.235677 (1.409 sec)
27.195... logprob:  0.563664, 0.273437 (1.399 sec)
27.196... logprob:  0.577931, 0.199219 (1.385 sec)
27.197... logprob:  0.676808, 0.259115 (1.400 sec)
27.198... logprob:  0.620098, 0.265625 (1.396 sec)
27.199... logprob:  0.589019, 0.273437 (1.382 sec)
27.200... logprob:  0.628874, 0.276042 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.465863, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.794588e-03 [1.398252e-07] 
Layer 'conv1' biases: 2.141604e-06 [5.099408e-11] 
Layer 'conv2' weights[0]: 2.789102e-03 [1.395606e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.222575e-10] 
Layer 'conv3' weights[0]: 2.787877e-03 [1.397128e-07] 
Layer 'conv3' biases: 3.547617e-05 [6.455150e-09] 
Layer 'conv4' weights[0]: 2.799682e-03 [1.404386e-07] 
Layer 'conv4' biases: 9.998914e-01 [1.556949e-07] 
Layer 'conv5' weights[0]: 2.953256e-03 [2.363185e-06] 
Layer 'conv5' biases: 9.991249e-01 [2.494544e-06] 
Layer 'fc6' weights[0]: 6.809094e-03 [6.218542e-08] 
Layer 'fc6' biases: 9.999899e-01 [5.558849e-08] 
Layer 'fc7' weights[0]: 7.155149e-03 [1.433727e-07] 
Layer 'fc7' biases: 9.997365e-01 [1.889993e-07] 
Layer 'fc8' weights[0]: 4.770300e-03 [1.228546e-05] 
Layer 'fc8' biases: 2.206072e-02 [2.676148e-05] 
Train error last 800 batches: 0.657021
-------------------------------------------------------
Not saving because 0.465863 > 0.299667 (9.300: -1.18%)
======================================================= (2.410 sec)
27.201... logprob:  0.679786, 0.289062 (1.410 sec)
27.202... logprob:  0.789110, 0.339844 (1.403 sec)
27.203... logprob:  0.702911, 0.296875 (1.436 sec)
27.204... logprob:  0.764509, 0.316406 (1.389 sec)
27.205... logprob:  0.625359, 0.270833 (1.394 sec)
27.206... logprob:  0.595782, 0.264323 (1.396 sec)
27.207... logprob:  0.616510, 0.268229 (1.427 sec)
27.208... logprob:  0.688591, 0.300781 (1.397 sec)
27.209... logprob:  0.591030, 0.264323 (1.421 sec)
27.210... logprob:  0.797051, 0.373698 (1.413 sec)
27.211... logprob:  0.643226, 0.277344 (1.412 sec)
27.212... logprob:  0.757950, 0.339844 (1.413 sec)
27.213... logprob:  0.758223, 0.319010 (1.462 sec)
27.214... logprob:  0.746258, 0.321615 (1.423 sec)
27.215... logprob:  0.653203, 0.307292 (1.412 sec)
27.216... logprob:  0.644030, 0.294271 (1.468 sec)
27.217... logprob:  0.573110, 0.227865 (1.396 sec)
27.218... logprob:  0.652274, 0.281250 (1.416 sec)
27.219... logprob:  0.714524, 0.307292 (1.408 sec)
27.220... logprob:  0.638390, 0.276042 (1.412 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.408430, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.791799e-03 [1.396283e-07] 
Layer 'conv1' biases: 2.141900e-06 [9.060787e-11] 
Layer 'conv2' weights[0]: 2.786305e-03 [1.393683e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.140391e-09] 
Layer 'conv3' weights[0]: 2.785096e-03 [1.397478e-07] 
Layer 'conv3' biases: 3.550160e-05 [8.982928e-09] 
Layer 'conv4' weights[0]: 2.796892e-03 [1.406961e-07] 
Layer 'conv4' biases: 9.998940e-01 [2.681761e-07] 
Layer 'conv5' weights[0]: 2.952803e-03 [2.866835e-06] 
Layer 'conv5' biases: 9.991516e-01 [3.066640e-06] 
Layer 'fc6' weights[0]: 6.808420e-03 [6.594592e-08] 
Layer 'fc6' biases: 9.999899e-01 [6.005701e-08] 
Layer 'fc7' weights[0]: 7.154532e-03 [1.524787e-07] 
Layer 'fc7' biases: 9.997342e-01 [2.158832e-07] 
Layer 'fc8' weights[0]: 4.704606e-03 [1.413881e-05] 
Layer 'fc8' biases: 2.160208e-02 [3.175863e-05] 
Train error last 800 batches: 0.657751
-------------------------------------------------------
Not saving because 0.408430 > 0.299667 (9.300: -1.18%)
======================================================= (2.370 sec)
27.221... logprob:  0.560677, 0.270833 (1.410 sec)
27.222... logprob:  0.780004, 0.359375 (1.458 sec)
27.223... logprob:  0.762918, 0.317708 (1.434 sec)
27.224... logprob:  0.600957, 0.266927 (1.425 sec)
27.225... logprob:  0.601044, 0.283854 (1.450 sec)
27.226... logprob:  0.692870, 0.311198 (1.416 sec)
27.227... logprob:  0.732892, 0.312500 (1.408 sec)
27.228... logprob:  0.687912, 0.309896 (1.411 sec)
27.229... logprob:  0.694923, 0.289062 (1.417 sec)
27.230... logprob:  0.768209, 0.325521 (1.413 sec)
27.231... logprob:  0.692959, 0.308594 (1.404 sec)
27.232... logprob:  0.716038, 0.317708 (1.458 sec)
27.233... logprob:  0.691952, 0.303385 (1.422 sec)
27.234... logprob:  0.767617, 0.315104 (1.424 sec)
27.235... logprob:  0.605409, 0.274740 (1.462 sec)
27.236... logprob:  0.679398, 0.294271 (1.397 sec)
27.237... logprob:  0.584682, 0.255208 (1.425 sec)
27.238... logprob:  0.534221, 0.234375 (1.413 sec)
27.239... logprob:  0.750744, 0.315104 (1.418 sec)
27.240... logprob:  0.743324, 0.308594 (1.399 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.518434, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.789017e-03 [1.395698e-07] 
Layer 'conv1' biases: 2.142214e-06 [7.681493e-11] 
Layer 'conv2' weights[0]: 2.783540e-03 [1.392927e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.387226e-10] 
Layer 'conv3' weights[0]: 2.782323e-03 [1.394587e-07] 
Layer 'conv3' biases: 3.549272e-05 [6.434178e-09] 
Layer 'conv4' weights[0]: 2.794086e-03 [1.401937e-07] 
Layer 'conv4' biases: 9.998935e-01 [1.596090e-07] 
Layer 'conv5' weights[0]: 2.949805e-03 [2.394121e-06] 
Layer 'conv5' biases: 9.991595e-01 [2.476027e-06] 
Layer 'fc6' weights[0]: 6.807690e-03 [6.215996e-08] 
Layer 'fc6' biases: 9.999899e-01 [5.490329e-08] 
Layer 'fc7' weights[0]: 7.153799e-03 [1.441688e-07] 
Layer 'fc7' biases: 9.997334e-01 [1.736359e-07] 
Layer 'fc8' weights[0]: 4.684777e-03 [1.297383e-05] 
Layer 'fc8' biases: 2.141948e-02 [1.881360e-05] 
Train error last 800 batches: 0.658024
-------------------------------------------------------
Not saving because 0.518434 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
27.241... logprob:  0.752931, 0.311198 (1.459 sec)
27.242... logprob:  0.644742, 0.309896 (1.423 sec)
27.243... logprob:  0.582452, 0.240885 (1.429 sec)
27.244... logprob:  0.626867, 0.286458 (1.438 sec)
27.245... logprob:  0.686266, 0.300781 (1.418 sec)
27.246... logprob:  0.557491, 0.235677 (1.419 sec)
27.247... logprob:  0.509284, 0.217448 (1.407 sec)
27.248... logprob:  0.595857, 0.278646 (1.418 sec)
27.249... logprob:  0.789274, 0.324219 (1.416 sec)
27.250... logprob:  0.747018, 0.342448 (1.406 sec)
27.251... logprob:  0.673974, 0.321615 (1.454 sec)
27.252... logprob:  0.517592, 0.214844 (1.415 sec)
27.253... logprob:  0.609469, 0.257812 (1.412 sec)
27.254... logprob:  0.650658, 0.277344 (1.460 sec)
27.255... logprob:  0.571419, 0.244792 (1.395 sec)
27.256... logprob:  0.570466, 0.255208 (1.418 sec)
27.257... logprob:  0.563128, 0.236979 (1.417 sec)
27.258... logprob:  0.664080, 0.300781 (1.422 sec)
27.259... logprob:  0.695514, 0.291667 (1.390 sec)
27.260... logprob:  0.603684, 0.291667 (1.455 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.348235, 0.062500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.786221e-03 [1.394671e-07] 
Layer 'conv1' biases: 2.142702e-06 [1.064079e-10] 
Layer 'conv2' weights[0]: 2.780730e-03 [1.391857e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.247668e-09] 
Layer 'conv3' weights[0]: 2.779541e-03 [1.398407e-07] 
Layer 'conv3' biases: 3.546948e-05 [1.093514e-08] 
Layer 'conv4' weights[0]: 2.791273e-03 [1.409970e-07] 
Layer 'conv4' biases: 9.998909e-01 [2.925922e-07] 
Layer 'conv5' weights[0]: 2.945648e-03 [3.204062e-06] 
Layer 'conv5' biases: 9.991159e-01 [3.424072e-06] 
Layer 'fc6' weights[0]: 6.806954e-03 [6.631819e-08] 
Layer 'fc6' biases: 9.999896e-01 [6.082987e-08] 
Layer 'fc7' weights[0]: 7.153045e-03 [1.530006e-07] 
Layer 'fc7' biases: 9.997374e-01 [2.261489e-07] 
Layer 'fc8' weights[0]: 4.779714e-03 [1.392799e-05] 
Layer 'fc8' biases: 2.219520e-02 [3.685546e-05] 
Train error last 800 batches: 0.657608
-------------------------------------------------------
Not saving because 0.348235 > 0.299667 (9.300: -1.18%)
======================================================= (2.414 sec)
27.261... logprob:  0.590312, 0.265625 (1.435 sec)
27.262... logprob:  0.641930, 0.264323 (1.427 sec)
27.263... logprob:  0.669728, 0.315104 (1.439 sec)
27.264... logprob:  0.613958, 0.278646 (1.427 sec)
27.265... logprob:  0.653579, 0.298177 (1.409 sec)
27.266... logprob:  0.701812, 0.286458 (1.409 sec)
27.267... logprob:  0.637118, 0.285156 (1.410 sec)
27.268... logprob:  0.700075, 0.299479 (1.433 sec)
27.269... logprob:  0.692326, 0.299479 (1.404 sec)
27.270... logprob:  0.714654, 0.287760 (1.455 sec)
27.271... logprob:  0.635688, 0.285156 (1.426 sec)
27.272... logprob:  0.631259, 0.281250 (1.406 sec)
27.273... logprob:  0.758560, 0.338542 (1.465 sec)
27.274... logprob:  0.886880, 0.337240 (1.394 sec)
27.275... logprob:  0.729483, 0.315104 (1.416 sec)
27.276... logprob:  0.703544, 0.290365 (1.408 sec)
27.277... logprob:  0.604348, 0.274740 (1.426 sec)
27.278... logprob:  0.537954, 0.244792 (1.421 sec)
27.279... logprob:  0.512263, 0.233073 (1.457 sec)
27.280... logprob:  0.514984, 0.231771 (1.394 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.432246, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.783433e-03 [1.392468e-07] 
Layer 'conv1' biases: 2.142898e-06 [7.720838e-11] 
Layer 'conv2' weights[0]: 2.777957e-03 [1.390068e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.292667e-10] 
Layer 'conv3' weights[0]: 2.776759e-03 [1.392376e-07] 
Layer 'conv3' biases: 3.548559e-05 [6.554843e-09] 
Layer 'conv4' weights[0]: 2.788498e-03 [1.401322e-07] 
Layer 'conv4' biases: 9.998891e-01 [1.939023e-07] 
Layer 'conv5' weights[0]: 2.942244e-03 [2.013251e-06] 
Layer 'conv5' biases: 9.991400e-01 [2.156159e-06] 
Layer 'fc6' weights[0]: 6.806234e-03 [5.831270e-08] 
Layer 'fc6' biases: 9.999897e-01 [5.039724e-08] 
Layer 'fc7' weights[0]: 7.152318e-03 [1.299265e-07] 
Layer 'fc7' biases: 9.997345e-01 [1.545301e-07] 
Layer 'fc8' weights[0]: 4.714071e-03 [1.104470e-05] 
Layer 'fc8' biases: 2.172691e-02 [1.171073e-05] 
Train error last 800 batches: 0.657697
-------------------------------------------------------
Not saving because 0.432246 > 0.299667 (9.300: -1.18%)
======================================================= (2.359 sec)
27.281... logprob:  0.707859, 0.317708 (1.430 sec)
27.282... logprob:  0.593993, 0.253906 (1.418 sec)
27.283... logprob:  0.598020, 0.242187 (1.417 sec)
27.284... logprob:  0.635012, 0.282552 (1.426 sec)
27.285... logprob:  0.697253, 0.287760 (1.435 sec)
27.286... logprob:  0.823680, 0.352865 (1.432 sec)
27.287... logprob:  0.598911, 0.270833 (1.424 sec)
27.288... logprob:  0.607307, 0.277344 (1.431 sec)
27.289... logprob:  0.618924, 0.260417 (1.442 sec)
27.290... logprob:  0.681435, 0.305990 (1.401 sec)
27.291... logprob:  0.604748, 0.252604 (1.428 sec)
27.292... logprob:  0.751052, 0.303385 (1.417 sec)
27.293... logprob:  0.712272, 0.312500 (1.416 sec)
27.294... logprob:  0.543284, 0.238281 (1.396 sec)
27.295... logprob:  0.593127, 0.286458 (1.458 sec)
27.296... logprob:  0.577900, 0.248698 (1.413 sec)
27.297... logprob:  0.599003, 0.242187 (1.422 sec)
27.298... logprob:  0.689642, 0.315104 (1.458 sec)
27.299... logprob:  0.628320, 0.274739 (1.402 sec)
27.300... logprob:  0.692051, 0.286458 (1.416 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.458995, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.780646e-03 [1.390711e-07] 
Layer 'conv1' biases: 2.142972e-06 [6.836057e-11] 
Layer 'conv2' weights[0]: 2.775193e-03 [1.388292e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.501118e-10] 
Layer 'conv3' weights[0]: 2.773966e-03 [1.390390e-07] 
Layer 'conv3' biases: 3.549447e-05 [6.770418e-09] 
Layer 'conv4' weights[0]: 2.785693e-03 [1.398343e-07] 
Layer 'conv4' biases: 9.998892e-01 [1.605791e-07] 
Layer 'conv5' weights[0]: 2.939626e-03 [2.261313e-06] 
Layer 'conv5' biases: 9.991306e-01 [2.437753e-06] 
Layer 'fc6' weights[0]: 6.805548e-03 [6.175208e-08] 
Layer 'fc6' biases: 9.999898e-01 [5.505850e-08] 
Layer 'fc7' weights[0]: 7.151594e-03 [1.416650e-07] 
Layer 'fc7' biases: 9.997352e-01 [1.759726e-07] 
Layer 'fc8' weights[0]: 4.733317e-03 [1.242149e-05] 
Layer 'fc8' biases: 2.191855e-02 [1.878721e-05] 
Train error last 800 batches: 0.658206
-------------------------------------------------------
Not saving because 0.458995 > 0.299667 (9.300: -1.18%)
======================================================= (2.374 sec)
27.301... logprob:  0.691117, 0.307292 (1.424 sec)
27.302... logprob:  0.824427, 0.356771 (1.416 sec)
27.303... logprob:  0.656072, 0.273438 (1.408 sec)
27.304... logprob:  0.667886, 0.309896 (1.434 sec)
27.305... logprob:  0.611683, 0.257812 (1.432 sec)
27.306... logprob:  0.589559, 0.244792 (1.435 sec)
27.307... logprob:  0.625119, 0.260417 (1.434 sec)
27.308... logprob:  0.638697, 0.281250 (1.446 sec)
27.309... logprob:  0.640250, 0.276042 (1.414 sec)
27.310... logprob:  0.698921, 0.335938 (1.427 sec)
27.311... logprob:  0.718146, 0.298177 (1.422 sec)
27.312... logprob:  0.706178, 0.298177 (1.431 sec)
27.313... logprob:  0.633351, 0.274740 (1.416 sec)
27.314... logprob:  0.701298, 0.302083 (1.464 sec)
27.315... logprob:  0.589435, 0.277344 (1.429 sec)
27.316... logprob:  0.718685, 0.308594 (1.423 sec)
27.317... logprob:  0.597377, 0.266927 (1.471 sec)
27.318... logprob:  0.597590, 0.270833 (1.404 sec)
27.319... logprob:  0.619489, 0.234375 (1.422 sec)
27.320... logprob:  0.614096, 0.261719 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.476890, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.777870e-03 [1.390043e-07] 
Layer 'conv1' biases: 2.142995e-06 [6.997995e-11] 
Layer 'conv2' weights[0]: 2.772413e-03 [1.387319e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.777002e-10] 
Layer 'conv3' weights[0]: 2.771202e-03 [1.389648e-07] 
Layer 'conv3' biases: 3.548170e-05 [7.258217e-09] 
Layer 'conv4' weights[0]: 2.782918e-03 [1.398340e-07] 
Layer 'conv4' biases: 9.998906e-01 [2.002593e-07] 
Layer 'conv5' weights[0]: 2.938575e-03 [2.733202e-06] 
Layer 'conv5' biases: 9.991338e-01 [2.914583e-06] 
Layer 'fc6' weights[0]: 6.804852e-03 [6.465122e-08] 
Layer 'fc6' biases: 9.999898e-01 [5.859541e-08] 
Layer 'fc7' weights[0]: 7.150887e-03 [1.487844e-07] 
Layer 'fc7' biases: 9.997350e-01 [2.062027e-07] 
Layer 'fc8' weights[0]: 4.730985e-03 [1.351803e-05] 
Layer 'fc8' biases: 2.187444e-02 [2.565871e-05] 
Train error last 800 batches: 0.658096
-------------------------------------------------------
Not saving because 0.476890 > 0.299667 (9.300: -1.18%)
======================================================= (2.349 sec)
27.321... logprob:  0.568316, 0.276042 (1.432 sec)
27.322... logprob:  0.561039, 0.279948 (1.408 sec)
27.323... logprob:  0.615608, 0.287760 (1.469 sec)
27.324... logprob:  0.754045, 0.319010 (1.418 sec)
27.325... logprob:  0.609818, 0.273438 (1.431 sec)
27.326... logprob:  0.616260, 0.269531 (1.458 sec)
27.327... logprob:  0.660262, 0.304688 (1.422 sec)
27.328... logprob:  0.771470, 0.305990 (1.419 sec)
27.329... logprob:  0.631023, 0.281250 (1.426 sec)
27.330... logprob:  0.645381, 0.277344 (1.412 sec)
27.331... logprob:  0.641514, 0.276042 (1.422 sec)
27.332... logprob:  0.767652, 0.319010 (1.443 sec)
27.333... logprob:  0.616577, 0.283854 (1.435 sec)
27.334... logprob:  0.788292, 0.343750 (1.436 sec)
27.335... logprob:  0.617819, 0.289062 (1.428 sec)
27.336... logprob:  0.661321, 0.299479 (1.453 sec)
27.337... logprob:  0.767215, 0.309896 (1.414 sec)
27.338... logprob:  0.613947, 0.281250 (1.460 sec)
27.339... logprob:  0.774235, 0.312500 (1.417 sec)
27.340... logprob:  0.555206, 0.234375 (1.419 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.508782, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.775098e-03 [1.388050e-07] 
Layer 'conv1' biases: 2.143140e-06 [1.124560e-10] 
Layer 'conv2' weights[0]: 2.769642e-03 [1.385411e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.385470e-09] 
Layer 'conv3' weights[0]: 2.768410e-03 [1.391975e-07] 
Layer 'conv3' biases: 3.549307e-05 [1.070868e-08] 
Layer 'conv4' weights[0]: 2.780139e-03 [1.399994e-07] 
Layer 'conv4' biases: 9.998906e-01 [2.784351e-07] 
Layer 'conv5' weights[0]: 2.936111e-03 [2.981948e-06] 
Layer 'conv5' biases: 9.991212e-01 [3.274324e-06] 
Layer 'fc6' weights[0]: 6.804172e-03 [7.066694e-08] 
Layer 'fc6' biases: 9.999898e-01 [6.673578e-08] 
Layer 'fc7' weights[0]: 7.150149e-03 [1.629463e-07] 
Layer 'fc7' biases: 9.997352e-01 [2.456085e-07] 
Layer 'fc8' weights[0]: 4.752919e-03 [1.618254e-05] 
Layer 'fc8' biases: 2.205874e-02 [4.571080e-05] 
Train error last 800 batches: 0.658100
-------------------------------------------------------
Not saving because 0.508782 > 0.299667 (9.300: -1.18%)
======================================================= (2.348 sec)
27.341... logprob:  0.737128, 0.317708 (1.424 sec)
27.342... logprob:  0.628716, 0.276042 (1.466 sec)
27.343... logprob:  0.623323, 0.270833 (1.442 sec)
27.344... logprob:  0.712615, 0.300781 (1.480 sec)
27.345... logprob:  0.682905, 0.269531 (1.432 sec)
27.346... logprob:  0.639513, 0.278646 (1.429 sec)
27.347... logprob:  0.543331, 0.223958 (1.480 sec)
27.348... logprob:  0.672871, 0.319010 (1.435 sec)
27.349... logprob:  0.729931, 0.339844 (1.431 sec)
27.350... logprob:  0.621732, 0.272135 (1.429 sec)
27.351... logprob:  0.664109, 0.252604 (1.425 sec)
27.352... logprob:  0.584021, 0.268229 (1.424 sec)
27.353... logprob:  0.630804, 0.278646 (1.482 sec)
27.354... logprob:  0.793861, 0.350260 (1.424 sec)
27.355... logprob:  0.583754, 0.240885 (1.443 sec)
27.356... logprob:  0.753125, 0.319010 (1.476 sec)
27.357... logprob:  0.560833, 0.251302 (1.426 sec)
27.358... logprob:  0.514518, 0.233073 (1.431 sec)
27.359... logprob:  0.722823, 0.286458 (1.420 sec)
27.360... logprob:  0.633522, 0.283854 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.471569, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.772323e-03 [1.387659e-07] 
Layer 'conv1' biases: 2.143341e-06 [5.866786e-11] 
Layer 'conv2' weights[0]: 2.766864e-03 [1.384437e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.884435e-10] 
Layer 'conv3' weights[0]: 2.765664e-03 [1.385202e-07] 
Layer 'conv3' biases: 3.552652e-05 [5.289764e-09] 
Layer 'conv4' weights[0]: 2.777355e-03 [1.393197e-07] 
Layer 'conv4' biases: 9.998901e-01 [1.482979e-07] 
Layer 'conv5' weights[0]: 2.933223e-03 [2.271598e-06] 
Layer 'conv5' biases: 9.991232e-01 [2.440454e-06] 
Layer 'fc6' weights[0]: 6.803457e-03 [6.073640e-08] 
Layer 'fc6' biases: 9.999896e-01 [5.374088e-08] 
Layer 'fc7' weights[0]: 7.149398e-03 [1.380157e-07] 
Layer 'fc7' biases: 9.997349e-01 [1.624125e-07] 
Layer 'fc8' weights[0]: 4.752075e-03 [1.188250e-05] 
Layer 'fc8' biases: 2.211370e-02 [1.405829e-05] 
Train error last 800 batches: 0.657711
-------------------------------------------------------
Not saving because 0.471569 > 0.299667 (9.300: -1.18%)
======================================================= (2.359 sec)
27.361... logprob:  0.642578, 0.277344 (1.461 sec)
27.362... logprob:  0.606438, 0.264323 (1.478 sec)
27.363... logprob:  0.737789, 0.326823 (1.442 sec)
27.364... logprob:  0.705129, 0.285156 (1.447 sec)
27.365... logprob:  0.636704, 0.263021 (1.455 sec)
27.366... logprob:  0.692416, 0.287760 (1.442 sec)
27.367... logprob:  0.631140, 0.256510 (1.435 sec)
27.368... logprob:  0.866918, 0.342448 (1.426 sec)
27.369... logprob:  0.689262, 0.308594 (1.421 sec)
27.370... logprob:  0.600374, 0.260417 (1.438 sec)
27.371... logprob:  0.731354, 0.347656 (1.452 sec)
27.372... logprob:  0.795271, 0.316406 (1.445 sec)
27.373... logprob:  0.735313, 0.324219 (1.450 sec)
27.374... logprob:  0.754925, 0.309896 (1.444 sec)
27.375... logprob:  0.676111, 0.326823 (1.457 sec)
27.376... logprob:  0.603635, 0.256510 (1.439 sec)
27.377... logprob:  0.622634, 0.291667 (1.427 sec)
27.378... logprob:  0.628362, 0.272135 (1.429 sec)
27.379... logprob:  0.691503, 0.305990 (1.435 sec)
27.380... logprob:  0.720843, 0.304687 (1.438 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.529633, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.769557e-03 [1.385783e-07] 
Layer 'conv1' biases: 2.143269e-06 [7.165890e-11] 
Layer 'conv2' weights[0]: 2.764105e-03 [1.382788e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.596844e-10] 
Layer 'conv3' weights[0]: 2.762900e-03 [1.385722e-07] 
Layer 'conv3' biases: 3.553114e-05 [7.488270e-09] 
Layer 'conv4' weights[0]: 2.774582e-03 [1.393560e-07] 
Layer 'conv4' biases: 9.998919e-01 [2.038473e-07] 
Layer 'conv5' weights[0]: 2.932001e-03 [2.903607e-06] 
Layer 'conv5' biases: 9.991539e-01 [3.084692e-06] 
Layer 'fc6' weights[0]: 6.802796e-03 [6.565366e-08] 
Layer 'fc6' biases: 9.999896e-01 [5.964544e-08] 
Layer 'fc7' weights[0]: 7.148708e-03 [1.544643e-07] 
Layer 'fc7' biases: 9.997323e-01 [2.153433e-07] 
Layer 'fc8' weights[0]: 4.682286e-03 [1.526780e-05] 
Layer 'fc8' biases: 2.158131e-02 [2.781652e-05] 
Train error last 800 batches: 0.658314
-------------------------------------------------------
Not saving because 0.529633 > 0.299667 (9.300: -1.18%)
======================================================= (2.411 sec)
27.381... logprob:  0.715263, 0.299479 (1.470 sec)
27.382... logprob:  0.707357, 0.320312 (1.450 sec)
27.383... logprob:  0.711368, 0.320312 (1.434 sec)
27.384... logprob:  0.693168, 0.309896 (1.472 sec)
27.385... logprob:  0.665803, 0.296875 (1.428 sec)
27.386... logprob:  0.805647, 0.343750 (1.416 sec)
27.387... logprob:  0.685546, 0.316406 (1.431 sec)
27.388... logprob:  0.717726, 0.322917 (1.428 sec)
27.389... logprob:  0.659240, 0.289062 (1.432 sec)
27.390... logprob:  0.572350, 0.261719 (1.476 sec)
27.391... logprob:  0.526990, 0.226563 (1.437 sec)
27.392... logprob:  0.700999, 0.300781 (1.426 sec)
27.393... logprob:  0.572611, 0.269531 (1.480 sec)
27.394... logprob:  0.592226, 0.265625 (1.429 sec)
27.395... logprob:  0.651895, 0.282552 (1.434 sec)
27.396... logprob:  0.495644, 0.229167 (1.435 sec)
27.397... logprob:  0.758493, 0.321615 (1.432 sec)
27.398... logprob:  0.692239, 0.290365 (1.425 sec)
27.399... logprob:  0.677505, 0.285156 (1.477 sec)
27.400... logprob:  0.703335, 0.320312 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.401397, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.766781e-03 [1.383744e-07] 
Layer 'conv1' biases: 2.143593e-06 [8.194113e-11] 
Layer 'conv2' weights[0]: 2.761343e-03 [1.381483e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.275831e-10] 
Layer 'conv3' weights[0]: 2.760125e-03 [1.384981e-07] 
Layer 'conv3' biases: 3.551492e-05 [7.836662e-09] 
Layer 'conv4' weights[0]: 2.771796e-03 [1.394169e-07] 
Layer 'conv4' biases: 9.998911e-01 [2.132141e-07] 
Layer 'conv5' weights[0]: 2.928766e-03 [2.429690e-06] 
Layer 'conv5' biases: 9.991376e-01 [2.577056e-06] 
Layer 'fc6' weights[0]: 6.802080e-03 [6.466185e-08] 
Layer 'fc6' biases: 9.999895e-01 [5.804108e-08] 
Layer 'fc7' weights[0]: 7.147972e-03 [1.536914e-07] 
Layer 'fc7' biases: 9.997337e-01 [2.168464e-07] 
Layer 'fc8' weights[0]: 4.717618e-03 [1.485085e-05] 
Layer 'fc8' biases: 2.185774e-02 [3.816746e-05] 
Train error last 800 batches: 0.658528
-------------------------------------------------------
Not saving because 0.401397 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
27.401... logprob:  0.683762, 0.276042 (1.442 sec)
27.402... logprob:  0.680786, 0.287760 (1.473 sec)
27.403... logprob:  0.657690, 0.279948 (1.431 sec)
27.404... logprob:  0.723147, 0.330729 (1.432 sec)
27.405... logprob:  0.842226, 0.342448 (1.426 sec)
27.406... logprob:  0.626708, 0.281250 (1.422 sec)
27.407... logprob:  0.703654, 0.307292 (1.427 sec)
27.408... logprob:  0.671386, 0.276042 (1.475 sec)
27.409... logprob:  0.613341, 0.272135 (1.433 sec)
27.410... logprob:  0.823346, 0.334635 (1.450 sec)
27.411... logprob:  0.636234, 0.291667 (1.476 sec)
27.412... logprob:  0.714428, 0.315104 (1.437 sec)
27.413... logprob:  0.690191, 0.304687 (1.428 sec)
27.414... logprob:  0.684560, 0.312500 (1.428 sec)
27.415... logprob:  0.605845, 0.266927 (1.426 sec)
27.416... logprob:  0.703239, 0.311198 (1.439 sec)
27.417... logprob:  0.617826, 0.257812 (1.466 sec)
27.418... logprob:  0.586943, 0.266927 (1.446 sec)
27.419... logprob:  0.680773, 0.292969 (1.452 sec)
27.420... logprob:  0.575352, 0.256510 (1.447 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.516198, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.764019e-03 [1.383045e-07] 
Layer 'conv1' biases: 2.144024e-06 [8.286902e-11] 
Layer 'conv2' weights[0]: 2.758579e-03 [1.380238e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.468525e-10] 
Layer 'conv3' weights[0]: 2.757375e-03 [1.383053e-07] 
Layer 'conv3' biases: 3.553380e-05 [7.256750e-09] 
Layer 'conv4' weights[0]: 2.769032e-03 [1.392521e-07] 
Layer 'conv4' biases: 9.998895e-01 [1.948692e-07] 
Layer 'conv5' weights[0]: 2.925170e-03 [3.107147e-06] 
Layer 'conv5' biases: 9.991493e-01 [3.337092e-06] 
Layer 'fc6' weights[0]: 6.801383e-03 [7.294746e-08] 
Layer 'fc6' biases: 9.999896e-01 [6.853475e-08] 
Layer 'fc7' weights[0]: 7.147253e-03 [1.827378e-07] 
Layer 'fc7' biases: 9.997323e-01 [3.052923e-07] 
Layer 'fc8' weights[0]: 4.686907e-03 [2.061708e-05] 
Layer 'fc8' biases: 2.168108e-02 [5.589857e-05] 
Train error last 800 batches: 0.658593
-------------------------------------------------------
Not saving because 0.516198 > 0.299667 (9.300: -1.18%)
======================================================= (2.360 sec)
27.421... logprob:  0.566461, 0.250000 (1.465 sec)
27.422... logprob:  0.720123, 0.287760 (1.433 sec)
27.423... logprob:  0.641773, 0.286458 (1.429 sec)
27.424... logprob:  0.603600, 0.270833 (1.429 sec)
27.425... logprob:  0.573856, 0.257812 (1.432 sec)
27.426... logprob:  0.700970, 0.317708 (1.439 sec)
27.427... logprob:  0.755322, 0.339844 (1.455 sec)
27.428... logprob:  0.693955, 0.313802 (1.446 sec)
27.429... logprob:  0.634911, 0.263021 (1.447 sec)
27.430... logprob:  0.526620, 0.234375 (1.470 sec)
27.431... logprob:  0.866185, 0.346354 (1.427 sec)
27.432... logprob:  0.625630, 0.264323 (1.421 sec)
27.433... logprob:  0.593755, 0.294271 (1.425 sec)
27.434... logprob:  0.710652, 0.317708 (1.432 sec)
27.435... logprob:  0.630955, 0.283854 (1.429 sec)
27.436... logprob:  0.642527, 0.292969 (1.476 sec)
27.437... logprob:  0.718981, 0.334635 (1.441 sec)
27.438... logprob:  0.714779, 0.299479 (1.429 sec)
27.439... logprob:  0.536576, 0.218750 (1.481 sec)
27.440... logprob:  0.726496, 0.312500 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.468265, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.761244e-03 [1.381661e-07] 
Layer 'conv1' biases: 2.144206e-06 [5.290932e-11] 
Layer 'conv2' weights[0]: 2.755827e-03 [1.378858e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.933929e-10] 
Layer 'conv3' weights[0]: 2.754633e-03 [1.379970e-07] 
Layer 'conv3' biases: 3.553449e-05 [6.094516e-09] 
Layer 'conv4' weights[0]: 2.766259e-03 [1.386809e-07] 
Layer 'conv4' biases: 9.998882e-01 [1.731332e-07] 
Layer 'conv5' weights[0]: 2.922007e-03 [2.272352e-06] 
Layer 'conv5' biases: 9.991223e-01 [2.508940e-06] 
Layer 'fc6' weights[0]: 6.800653e-03 [6.139949e-08] 
Layer 'fc6' biases: 9.999894e-01 [5.485415e-08] 
Layer 'fc7' weights[0]: 7.146581e-03 [1.399651e-07] 
Layer 'fc7' biases: 9.997340e-01 [1.715664e-07] 
Layer 'fc8' weights[0]: 4.746901e-03 [1.172624e-05] 
Layer 'fc8' biases: 2.220678e-02 [1.234453e-05] 
Train error last 800 batches: 0.658254
-------------------------------------------------------
Not saving because 0.468265 > 0.299667 (9.300: -1.18%)
======================================================= (2.397 sec)
27.441... logprob:  0.710737, 0.309896 (1.425 sec)
27.442... logprob:  0.531505, 0.231771 (1.429 sec)
27.443... logprob:  0.765170, 0.324219 (1.426 sec)
27.444... logprob:  0.621035, 0.261719 (1.428 sec)
27.445... logprob:  0.610861, 0.283854 (1.476 sec)
27.446... logprob:  0.616030, 0.276042 (1.432 sec)
27.447... logprob:  0.646819, 0.298177 (1.432 sec)
27.448... logprob:  0.592991, 0.276042 (1.481 sec)
27.449... logprob:  0.695270, 0.279948 (1.427 sec)
27.450... logprob:  0.517207, 0.250000 (1.429 sec)
27.451... logprob:  0.628323, 0.248698 (1.427 sec)
27.452... logprob:  0.686377, 0.291667 (1.424 sec)
27.453... logprob:  0.613219, 0.289062 (1.426 sec)
27.454... logprob:  0.747816, 0.291667 (1.478 sec)
27.455... logprob:  0.651228, 0.269531 (1.429 sec)
27.456... logprob:  0.649829, 0.278646 (1.440 sec)
27.457... logprob:  0.622475, 0.264323 (1.467 sec)
27.458... logprob:  0.545461, 0.256510 (1.431 sec)
27.459... logprob:  0.666788, 0.304687 (1.435 sec)
27.460... logprob:  0.587487, 0.263021 (1.438 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.541372, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.758499e-03 [1.379374e-07] 
Layer 'conv1' biases: 2.143899e-06 [6.364635e-11] 
Layer 'conv2' weights[0]: 2.753058e-03 [1.377136e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.820197e-10] 
Layer 'conv3' weights[0]: 2.751893e-03 [1.380227e-07] 
Layer 'conv3' biases: 3.553853e-05 [7.462199e-09] 
Layer 'conv4' weights[0]: 2.763513e-03 [1.389604e-07] 
Layer 'conv4' biases: 9.998881e-01 [2.110091e-07] 
Layer 'conv5' weights[0]: 2.919378e-03 [2.273987e-06] 
Layer 'conv5' biases: 9.991183e-01 [2.438486e-06] 
Layer 'fc6' weights[0]: 6.799957e-03 [6.066743e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.372099e-08] 
Layer 'fc7' weights[0]: 7.145885e-03 [1.392305e-07] 
Layer 'fc7' biases: 9.997346e-01 [1.826750e-07] 
Layer 'fc8' weights[0]: 4.760846e-03 [1.263061e-05] 
Layer 'fc8' biases: 2.225477e-02 [2.061487e-05] 
Train error last 800 batches: 0.658106
-------------------------------------------------------
Not saving because 0.541372 > 0.299667 (9.300: -1.18%)
======================================================= (2.367 sec)
27.461... logprob:  0.732486, 0.296875 (1.428 sec)
27.462... logprob:  0.606346, 0.282552 (1.436 sec)
27.463... logprob:  0.646142, 0.290365 (1.467 sec)
27.464... logprob:  0.671734, 0.309896 (1.447 sec)
27.465... logprob:  0.699981, 0.321615 (1.452 sec)
27.466... logprob:  0.564154, 0.238281 (1.455 sec)
27.467... logprob:  0.640038, 0.279948 (1.441 sec)
27.468... logprob:  0.629369, 0.255208 (1.432 sec)
27.469... logprob:  0.570404, 0.242187 (1.422 sec)
27.470... logprob:  0.598155, 0.289062 (1.419 sec)
27.471... logprob:  0.731558, 0.317708 (1.435 sec)
27.472... logprob:  0.654178, 0.279948 (1.452 sec)
27.473... logprob:  0.616171, 0.273437 (1.449 sec)
27.474... logprob:  0.700115, 0.307292 (1.451 sec)
27.475... logprob:  0.655088, 0.287760 (1.441 sec)
27.476... logprob:  0.678779, 0.302083 (1.470 sec)
27.477... logprob:  0.590831, 0.257812 (1.435 sec)
27.478... logprob:  0.642764, 0.290365 (1.422 sec)
27.479... logprob:  0.570259, 0.291667 (1.432 sec)
27.480... logprob:  0.690300, 0.291667 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.421320, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.755740e-03 [1.378405e-07] 
Layer 'conv1' biases: 2.143923e-06 [6.686380e-11] 
Layer 'conv2' weights[0]: 2.750329e-03 [1.375818e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.342321e-10] 
Layer 'conv3' weights[0]: 2.749112e-03 [1.377579e-07] 
Layer 'conv3' biases: 3.556352e-05 [6.074227e-09] 
Layer 'conv4' weights[0]: 2.760741e-03 [1.385122e-07] 
Layer 'conv4' biases: 9.998889e-01 [1.717171e-07] 
Layer 'conv5' weights[0]: 2.917257e-03 [2.117566e-06] 
Layer 'conv5' biases: 9.991103e-01 [2.238539e-06] 
Layer 'fc6' weights[0]: 6.799286e-03 [5.813353e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.060359e-08] 
Layer 'fc7' weights[0]: 7.145154e-03 [1.300458e-07] 
Layer 'fc7' biases: 9.997344e-01 [1.449946e-07] 
Layer 'fc8' weights[0]: 4.767900e-03 [1.064013e-05] 
Layer 'fc8' biases: 2.231107e-02 [3.185600e-06] 
Train error last 800 batches: 0.657851
-------------------------------------------------------
Not saving because 0.421320 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
27.481... logprob:  0.714018, 0.305989 (1.441 sec)
27.482... logprob:  0.608044, 0.251302 (1.473 sec)
27.483... logprob:  0.695874, 0.274740 (1.442 sec)
27.484... logprob:  0.696482, 0.276042 (1.430 sec)
27.485... logprob:  0.640496, 0.285156 (1.478 sec)
27.486... logprob:  0.657757, 0.300781 (1.426 sec)
27.487... logprob:  0.835573, 0.347656 (1.425 sec)
27.488... logprob:  0.637772, 0.264323 (1.435 sec)
27.489... logprob:  0.614626, 0.277344 (1.434 sec)
27.490... logprob:  0.756608, 0.317708 (1.425 sec)
27.491... logprob:  0.611410, 0.268229 (1.475 sec)
27.492... logprob:  0.672795, 0.300781 (1.439 sec)
27.493... logprob:  0.653853, 0.298177 (1.437 sec)
27.494... logprob:  0.733489, 0.307292 (1.484 sec)
27.495... logprob:  0.589083, 0.268229 (1.431 sec)
27.496... logprob:  0.682381, 0.303385 (1.428 sec)
27.497... logprob:  0.735747, 0.328125 (1.434 sec)
27.498... logprob:  0.662159, 0.272135 (1.425 sec)
27.499... logprob:  0.644156, 0.286458 (1.432 sec)
27.500... logprob:  0.519729, 0.234375 (1.480 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.397842, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.752979e-03 [1.376993e-07] 
Layer 'conv1' biases: 2.143774e-06 [6.157988e-11] 
Layer 'conv2' weights[0]: 2.747562e-03 [1.374486e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.784826e-10] 
Layer 'conv3' weights[0]: 2.746358e-03 [1.378317e-07] 
Layer 'conv3' biases: 3.555838e-05 [8.097505e-09] 
Layer 'conv4' weights[0]: 2.757976e-03 [1.387017e-07] 
Layer 'conv4' biases: 9.998903e-01 [2.154636e-07] 
Layer 'conv5' weights[0]: 2.915869e-03 [2.373832e-06] 
Layer 'conv5' biases: 9.991319e-01 [2.530897e-06] 
Layer 'fc6' weights[0]: 6.798591e-03 [6.110305e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.394586e-08] 
Layer 'fc7' weights[0]: 7.144418e-03 [1.388846e-07] 
Layer 'fc7' biases: 9.997320e-01 [1.776843e-07] 
Layer 'fc8' weights[0]: 4.697706e-03 [1.196707e-05] 
Layer 'fc8' biases: 2.182230e-02 [2.189134e-05] 
Train error last 800 batches: 0.658239
-------------------------------------------------------
Not saving because 0.397842 > 0.299667 (9.300: -1.18%)
======================================================= (2.367 sec)
27.501... logprob:  0.530715, 0.231771 (1.432 sec)
27.502... logprob:  0.644491, 0.295573 (1.444 sec)
27.503... logprob:  0.630927, 0.256510 (1.497 sec)
27.504... logprob:  0.664047, 0.282552 (1.435 sec)
27.505... logprob:  0.816267, 0.352865 (1.441 sec)
27.506... logprob:  0.661824, 0.291667 (1.439 sec)
27.507... logprob:  0.667693, 0.269531 (1.427 sec)
27.508... logprob:  0.600790, 0.265625 (1.438 sec)
27.509... logprob:  0.554668, 0.265625 (1.477 sec)
27.510... logprob:  0.660895, 0.283854 (1.441 sec)
27.511... logprob:  0.547760, 0.247396 (1.462 sec)
27.512... logprob:  0.731358, 0.286458 (1.469 sec)
27.513... logprob:  0.560213, 0.240885 (1.448 sec)
27.514... logprob:  0.628541, 0.290365 (1.439 sec)
27.515... logprob:  0.662794, 0.272135 (1.440 sec)
27.516... logprob:  0.615915, 0.276042 (1.425 sec)
27.517... logprob:  0.854833, 0.360677 (1.437 sec)
27.518... logprob:  0.707615, 0.274740 (1.458 sec)
27.519... logprob:  0.713999, 0.302083 (1.462 sec)
27.520... logprob:  0.639809, 0.279948 (1.452 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.471804, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.750239e-03 [1.376337e-07] 
Layer 'conv1' biases: 2.144016e-06 [8.029453e-11] 
Layer 'conv2' weights[0]: 2.744815e-03 [1.372947e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.015178e-09] 
Layer 'conv3' weights[0]: 2.743619e-03 [1.377504e-07] 
Layer 'conv3' biases: 3.554274e-05 [8.646175e-09] 
Layer 'conv4' weights[0]: 2.755222e-03 [1.385332e-07] 
Layer 'conv4' biases: 9.998899e-01 [2.268411e-07] 
Layer 'conv5' weights[0]: 2.913407e-03 [2.722478e-06] 
Layer 'conv5' biases: 9.991120e-01 [2.833113e-06] 
Layer 'fc6' weights[0]: 6.797893e-03 [6.628512e-08] 
Layer 'fc6' biases: 9.999892e-01 [6.120752e-08] 
Layer 'fc7' weights[0]: 7.143726e-03 [1.536104e-07] 
Layer 'fc7' biases: 9.997334e-01 [2.089779e-07] 
Layer 'fc8' weights[0]: 4.747891e-03 [1.381087e-05] 
Layer 'fc8' biases: 2.229655e-02 [2.237144e-05] 
Train error last 800 batches: 0.658064
-------------------------------------------------------
Not saving because 0.471804 > 0.299667 (9.300: -1.18%)
======================================================= (2.355 sec)
27.521... logprob:  0.633857, 0.273438 (1.469 sec)
27.522... logprob:  0.787396, 0.307292 (1.473 sec)
27.523... logprob:  0.512179, 0.209635 (1.447 sec)
27.524... logprob:  0.689712, 0.305989 (1.432 sec)
27.525... logprob:  0.616127, 0.290364 (1.443 sec)
27.526... logprob:  0.629351, 0.287760 (1.446 sec)
27.527... logprob:  0.761172, 0.348958 (1.451 sec)
27.528... logprob:  0.593493, 0.266927 (1.477 sec)
27.529... logprob:  0.568382, 0.264323 (1.460 sec)
27.530... logprob:  0.536308, 0.242187 (1.449 sec)
27.531... logprob:  0.666169, 0.269531 (1.480 sec)
27.532... logprob:  0.702132, 0.303385 (1.438 sec)
27.533... logprob:  0.750265, 0.298177 (1.435 sec)
27.534... logprob:  0.605295, 0.291667 (1.434 sec)
27.535... logprob:  0.732735, 0.322917 (1.448 sec)
27.536... logprob:  0.692422, 0.303385 (1.436 sec)
27.537... logprob:  0.695596, 0.311198 (1.481 sec)
27.538... logprob:  0.700940, 0.312500 (1.445 sec)
27.539... logprob:  0.567759, 0.265625 (1.435 sec)
27.540... logprob:  0.575771, 0.281250 (1.496 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.493196, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.747483e-03 [1.374481e-07] 
Layer 'conv1' biases: 2.144280e-06 [7.090527e-11] 
Layer 'conv2' weights[0]: 2.742070e-03 [1.372002e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.368130e-10] 
Layer 'conv3' weights[0]: 2.740899e-03 [1.375410e-07] 
Layer 'conv3' biases: 3.553865e-05 [7.755492e-09] 
Layer 'conv4' weights[0]: 2.752473e-03 [1.384342e-07] 
Layer 'conv4' biases: 9.998885e-01 [1.937871e-07] 
Layer 'conv5' weights[0]: 2.909714e-03 [2.537817e-06] 
Layer 'conv5' biases: 9.991145e-01 [2.665045e-06] 
Layer 'fc6' weights[0]: 6.797182e-03 [6.349634e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.721644e-08] 
Layer 'fc7' weights[0]: 7.142991e-03 [1.492117e-07] 
Layer 'fc7' biases: 9.997335e-01 [2.171220e-07] 
Layer 'fc8' weights[0]: 4.746518e-03 [1.475857e-05] 
Layer 'fc8' biases: 2.227788e-02 [3.714562e-05] 
Train error last 800 batches: 0.658185
-------------------------------------------------------
Not saving because 0.493196 > 0.299667 (9.300: -1.18%)
======================================================= (2.382 sec)
27.541... logprob:  0.664518, 0.291667 (1.444 sec)
27.542... logprob:  0.647437, 0.289062 (1.430 sec)
27.543... logprob:  0.533862, 0.269531 (1.447 sec)
27.544... logprob:  0.562469, 0.246094 (1.433 sec)
27.545... logprob:  0.620154, 0.292969 (1.434 sec)
27.546... logprob:  0.539932, 0.248698 (1.478 sec)
27.547... logprob:  0.685319, 0.299479 (1.429 sec)
27.548... logprob:  0.637307, 0.263021 (1.493 sec)
27.549... logprob:  0.617961, 0.279948 (1.477 sec)
27.550... logprob:  0.580562, 0.261719 (1.431 sec)
27.551... logprob:  0.706056, 0.286458 (1.428 sec)
27.552... logprob:  0.592481, 0.273437 (1.431 sec)
27.553... logprob:  0.645371, 0.281250 (1.420 sec)
27.554... logprob:  0.676089, 0.291667 (1.426 sec)
27.555... logprob:  0.605875, 0.282552 (1.476 sec)
27.556... logprob:  0.532571, 0.244792 (1.432 sec)
27.557... logprob:  0.655265, 0.291667 (1.452 sec)
27.558... logprob:  0.639199, 0.274740 (1.470 sec)
27.559... logprob:  0.735485, 0.320312 (1.432 sec)
27.560... logprob:  0.535658, 0.230469 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.550098, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.744734e-03 [1.373366e-07] 
Layer 'conv1' biases: 2.144498e-06 [5.601245e-11] 
Layer 'conv2' weights[0]: 2.739336e-03 [1.370528e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.317388e-10] 
Layer 'conv3' weights[0]: 2.738144e-03 [1.371681e-07] 
Layer 'conv3' biases: 3.551786e-05 [4.891474e-09] 
Layer 'conv4' weights[0]: 2.749718e-03 [1.378336e-07] 
Layer 'conv4' biases: 9.998882e-01 [1.182743e-07] 
Layer 'conv5' weights[0]: 2.907002e-03 [2.118573e-06] 
Layer 'conv5' biases: 9.990820e-01 [2.288607e-06] 
Layer 'fc6' weights[0]: 6.796479e-03 [5.902822e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.225038e-08] 
Layer 'fc7' weights[0]: 7.142227e-03 [1.342466e-07] 
Layer 'fc7' biases: 9.997355e-01 [1.623986e-07] 
Layer 'fc8' weights[0]: 4.832357e-03 [1.175996e-05] 
Layer 'fc8' biases: 2.287437e-02 [1.564814e-05] 
Train error last 800 batches: 0.658173
-------------------------------------------------------
Not saving because 0.550098 > 0.299667 (9.300: -1.18%)
======================================================= (2.423 sec)
27.561... logprob:  0.539331, 0.264323 (1.437 sec)
27.562... logprob:  0.689860, 0.300781 (1.429 sec)
27.563... logprob:  0.625831, 0.268229 (1.439 sec)
27.564... logprob:  0.736709, 0.319010 (1.464 sec)
27.565... logprob:  0.851371, 0.346354 (1.445 sec)
27.566... logprob:  0.646030, 0.291667 (1.456 sec)
27.567... logprob:  0.683497, 0.303385 (1.452 sec)
27.568... logprob:  0.599275, 0.270833 (1.449 sec)
27.569... logprob:  0.825338, 0.316406 (1.430 sec)
27.570... logprob:  0.747053, 0.335937 (1.425 sec)
27.571... logprob:  0.756719, 0.329427 (1.428 sec)
27.572... logprob:  0.692526, 0.292969 (1.432 sec)
27.573... logprob:  0.722055, 0.277344 (1.438 sec)
27.574... logprob:  0.645539, 0.289062 (1.456 sec)
27.575... logprob:  0.586366, 0.265625 (1.445 sec)
27.576... logprob:  0.677130, 0.286458 (1.439 sec)
27.577... logprob:  0.675475, 0.305990 (1.470 sec)
27.578... logprob:  0.559981, 0.242187 (1.426 sec)
27.579... logprob:  0.624949, 0.281250 (1.421 sec)
27.580... logprob:  0.699713, 0.290365 (1.425 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.449239, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.741978e-03 [1.371656e-07] 
Layer 'conv1' biases: 2.144814e-06 [6.838407e-11] 
Layer 'conv2' weights[0]: 2.736593e-03 [1.368748e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.102932e-10] 
Layer 'conv3' weights[0]: 2.735403e-03 [1.370714e-07] 
Layer 'conv3' biases: 3.555099e-05 [6.234908e-09] 
Layer 'conv4' weights[0]: 2.746953e-03 [1.377270e-07] 
Layer 'conv4' biases: 9.998863e-01 [1.721097e-07] 
Layer 'conv5' weights[0]: 2.904030e-03 [2.495912e-06] 
Layer 'conv5' biases: 9.991389e-01 [2.676063e-06] 
Layer 'fc6' weights[0]: 6.795771e-03 [6.563485e-08] 
Layer 'fc6' biases: 9.999895e-01 [6.030934e-08] 
Layer 'fc7' weights[0]: 7.141562e-03 [1.522163e-07] 
Layer 'fc7' biases: 9.997313e-01 [2.110531e-07] 
Layer 'fc8' weights[0]: 4.711077e-03 [1.331384e-05] 
Layer 'fc8' biases: 2.192908e-02 [2.918532e-05] 
Train error last 800 batches: 0.657782
-------------------------------------------------------
Not saving because 0.449239 > 0.299667 (9.300: -1.18%)
======================================================= (2.356 sec)
27.581... logprob:  0.740441, 0.302083 (1.445 sec)
27.582... logprob:  0.646652, 0.283854 (1.434 sec)
27.583... logprob:  0.725806, 0.312500 (1.478 sec)
27.584... logprob:  0.688827, 0.296875 (1.445 sec)
27.585... logprob:  0.644767, 0.281250 (1.429 sec)
27.586... logprob:  0.608369, 0.257812 (1.478 sec)
27.587... logprob:  0.632284, 0.296875 (1.429 sec)
27.588... logprob:  0.584057, 0.260417 (1.429 sec)
27.589... logprob:  0.602886, 0.274740 (1.431 sec)
27.590... logprob:  0.746480, 0.305990 (1.428 sec)
27.591... logprob:  0.711989, 0.337239 (1.430 sec)
27.592... logprob:  0.661223, 0.309896 (1.480 sec)
27.593... logprob:  0.581812, 0.252604 (1.437 sec)
27.594... logprob:  0.636902, 0.289062 (1.430 sec)
27.595... logprob:  0.696787, 0.315104 (1.486 sec)
27.596... logprob:  0.622802, 0.298177 (1.425 sec)
27.597... logprob:  0.568740, 0.239583 (1.426 sec)
27.598... logprob:  0.640332, 0.290365 (1.433 sec)
27.599... logprob:  0.593950, 0.250000 (1.427 sec)
27.600... logprob:  0.569875, 0.236979 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.516270, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.739253e-03 [1.371200e-07] 
Layer 'conv1' biases: 2.145164e-06 [1.250854e-10] 
Layer 'conv2' weights[0]: 2.733862e-03 [1.368628e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.360272e-09] 
Layer 'conv3' weights[0]: 2.732630e-03 [1.376555e-07] 
Layer 'conv3' biases: 3.555579e-05 [1.145480e-08] 
Layer 'conv4' weights[0]: 2.744205e-03 [1.388248e-07] 
Layer 'conv4' biases: 9.998843e-01 [3.307194e-07] 
Layer 'conv5' weights[0]: 2.900312e-03 [4.115935e-06] 
Layer 'conv5' biases: 9.991211e-01 [4.473836e-06] 
Layer 'fc6' weights[0]: 6.795070e-03 [8.113943e-08] 
Layer 'fc6' biases: 9.999894e-01 [7.994024e-08] 
Layer 'fc7' weights[0]: 7.140828e-03 [2.031912e-07] 
Layer 'fc7' biases: 9.997325e-01 [3.737388e-07] 
Layer 'fc8' weights[0]: 4.755941e-03 [2.114036e-05] 
Layer 'fc8' biases: 2.228023e-02 [7.256445e-05] 
Train error last 800 batches: 0.657523
-------------------------------------------------------
Not saving because 0.516270 > 0.299667 (9.300: -1.18%)
======================================================= (2.342 sec)
27.601... logprob:  0.650237, 0.246094 (1.481 sec)
27.602... logprob:  0.573427, 0.269531 (1.433 sec)
27.603... logprob:  0.576594, 0.261719 (1.445 sec)
27.604... logprob:  0.622260, 0.261719 (1.471 sec)
27.605... logprob:  0.765219, 0.339844 (1.434 sec)
27.606... logprob:  0.538209, 0.251302 (1.432 sec)
27.607... logprob:  0.690451, 0.311198 (1.425 sec)
27.608... logprob:  0.530000, 0.264323 (1.427 sec)
27.609... logprob:  0.682972, 0.289062 (1.438 sec)
27.610... logprob:  0.695435, 0.311198 (1.464 sec)
27.611... logprob:  0.723324, 0.285156 (1.440 sec)
27.612... logprob:  0.604299, 0.279948 (1.449 sec)
27.613... logprob:  0.581885, 0.286458 (1.460 sec)
27.614... logprob:  0.720164, 0.304687 (1.443 sec)
27.615... logprob:  0.586847, 0.263021 (1.431 sec)
27.616... logprob:  0.808274, 0.334635 (1.424 sec)
27.617... logprob:  0.591766, 0.273438 (1.426 sec)
27.618... logprob:  0.780479, 0.351562 (1.433 sec)
27.619... logprob:  0.689485, 0.296875 (1.454 sec)
27.620... logprob:  0.667425, 0.292969 (1.451 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.480399, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.736508e-03 [1.368948e-07] 
Layer 'conv1' biases: 2.145315e-06 [6.709988e-11] 
Layer 'conv2' weights[0]: 2.731129e-03 [1.366301e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.572050e-10] 
Layer 'conv3' weights[0]: 2.729924e-03 [1.368817e-07] 
Layer 'conv3' biases: 3.553935e-05 [7.375586e-09] 
Layer 'conv4' weights[0]: 2.741471e-03 [1.376395e-07] 
Layer 'conv4' biases: 9.998825e-01 [2.019751e-07] 
Layer 'conv5' weights[0]: 2.896560e-03 [2.990726e-06] 
Layer 'conv5' biases: 9.990918e-01 [3.228664e-06] 
Layer 'fc6' weights[0]: 6.794402e-03 [6.798539e-08] 
Layer 'fc6' biases: 9.999891e-01 [6.378705e-08] 
Layer 'fc7' weights[0]: 7.140098e-03 [1.602657e-07] 
Layer 'fc7' biases: 9.997342e-01 [2.429169e-07] 
Layer 'fc8' weights[0]: 4.823399e-03 [1.455046e-05] 
Layer 'fc8' biases: 2.293006e-02 [2.979333e-05] 
Train error last 800 batches: 0.657942
-------------------------------------------------------
Not saving because 0.480399 > 0.299667 (9.300: -1.18%)
======================================================= (2.411 sec)
27.621... logprob:  0.634366, 0.278646 (1.452 sec)
27.622... logprob:  0.507115, 0.222656 (1.455 sec)
27.623... logprob:  0.651462, 0.294271 (1.465 sec)
27.624... logprob:  0.599436, 0.277344 (1.430 sec)
27.625... logprob:  0.705641, 0.311198 (1.421 sec)
27.626... logprob:  0.682124, 0.298177 (1.431 sec)
27.627... logprob:  0.638592, 0.278646 (1.438 sec)
27.628... logprob:  0.714617, 0.295573 (1.428 sec)
27.629... logprob:  0.670823, 0.282552 (1.472 sec)
27.630... logprob:  0.617546, 0.276042 (1.445 sec)
27.631... logprob:  0.920024, 0.371094 (1.432 sec)
27.632... logprob:  0.661840, 0.272135 (1.475 sec)
27.633... logprob:  0.607926, 0.279948 (1.428 sec)
27.634... logprob:  0.839243, 0.365885 (1.421 sec)
27.635... logprob:  0.531583, 0.255208 (1.432 sec)
27.636... logprob:  0.687317, 0.300781 (1.432 sec)
27.637... logprob:  0.527699, 0.236979 (1.424 sec)
27.638... logprob:  0.717616, 0.303385 (1.478 sec)
27.639... logprob:  0.680598, 0.292969 (1.433 sec)
27.640... logprob:  0.699819, 0.283854 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.520626, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.733771e-03 [1.367699e-07] 
Layer 'conv1' biases: 2.145800e-06 [6.484717e-11] 
Layer 'conv2' weights[0]: 2.728384e-03 [1.364669e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.788609e-10] 
Layer 'conv3' weights[0]: 2.727200e-03 [1.366537e-07] 
Layer 'conv3' biases: 3.556777e-05 [6.505131e-09] 
Layer 'conv4' weights[0]: 2.738726e-03 [1.373587e-07] 
Layer 'conv4' biases: 9.998821e-01 [1.827834e-07] 
Layer 'conv5' weights[0]: 2.893596e-03 [2.883151e-06] 
Layer 'conv5' biases: 9.991268e-01 [3.022557e-06] 
Layer 'fc6' weights[0]: 6.793761e-03 [6.824002e-08] 
Layer 'fc6' biases: 9.999890e-01 [6.343978e-08] 
Layer 'fc7' weights[0]: 7.139393e-03 [1.578926e-07] 
Layer 'fc7' biases: 9.997317e-01 [2.346704e-07] 
Layer 'fc8' weights[0]: 4.746562e-03 [1.424081e-05] 
Layer 'fc8' biases: 2.234423e-02 [3.356272e-05] 
Train error last 800 batches: 0.658377
-------------------------------------------------------
Not saving because 0.520626 > 0.299667 (9.300: -1.18%)
======================================================= (2.355 sec)
27.641... logprob:  0.580489, 0.265625 (1.481 sec)
27.642... logprob:  0.673829, 0.273437 (1.429 sec)
27.643... logprob:  0.747355, 0.300781 (1.433 sec)
27.644... logprob:  0.602966, 0.273437 (1.436 sec)
27.645... logprob:  0.611686, 0.273438 (1.426 sec)
27.646... logprob:  0.631569, 0.279948 (1.433 sec)
27.647... logprob:  0.684074, 0.332031 (1.481 sec)
27.648... logprob:  0.748804, 0.352865 (1.434 sec)
27.649... logprob:  0.619950, 0.278646 (1.437 sec)
27.650... logprob:  0.686235, 0.315104 (1.471 sec)
27.651... logprob:  0.662076, 0.276042 (1.426 sec)
27.652... logprob:  0.628425, 0.268229 (1.431 sec)
27.653... logprob:  0.665963, 0.283854 (1.438 sec)
27.654... logprob:  0.684859, 0.295573 (1.426 sec)
27.655... logprob:  0.672860, 0.296875 (1.426 sec)
27.656... logprob:  0.682007, 0.292969 (1.473 sec)
27.657... logprob:  0.626297, 0.282552 (1.444 sec)
27.658... logprob:  0.655181, 0.283854 (1.449 sec)
27.659... logprob:  0.681067, 0.312500 (1.458 sec)
27.660... logprob:  0.648575, 0.294271 (1.438 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.513741, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.731043e-03 [1.366505e-07] 
Layer 'conv1' biases: 2.146178e-06 [6.406861e-11] 
Layer 'conv2' weights[0]: 2.725666e-03 [1.363653e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.540379e-10] 
Layer 'conv3' weights[0]: 2.724446e-03 [1.365350e-07] 
Layer 'conv3' biases: 3.557714e-05 [5.860408e-09] 
Layer 'conv4' weights[0]: 2.735983e-03 [1.372785e-07] 
Layer 'conv4' biases: 9.998814e-01 [1.614296e-07] 
Layer 'conv5' weights[0]: 2.890991e-03 [2.346444e-06] 
Layer 'conv5' biases: 9.991357e-01 [2.522073e-06] 
Layer 'fc6' weights[0]: 6.793033e-03 [6.521760e-08] 
Layer 'fc6' biases: 9.999889e-01 [5.943070e-08] 
Layer 'fc7' weights[0]: 7.138731e-03 [1.520364e-07] 
Layer 'fc7' biases: 9.997306e-01 [2.164450e-07] 
Layer 'fc8' weights[0]: 4.735533e-03 [1.527009e-05] 
Layer 'fc8' biases: 2.219985e-02 [4.475649e-05] 
Train error last 800 batches: 0.657881
-------------------------------------------------------
Not saving because 0.513741 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
27.661... logprob:  0.603876, 0.281250 (1.438 sec)
27.662... logprob:  0.685551, 0.303385 (1.431 sec)
27.663... logprob:  0.527555, 0.248698 (1.424 sec)
27.664... logprob:  0.534190, 0.261719 (1.434 sec)
27.665... logprob:  0.627252, 0.286458 (1.461 sec)
27.666... logprob:  0.580241, 0.286458 (1.447 sec)
27.667... logprob:  0.739248, 0.330729 (1.452 sec)
27.668... logprob:  0.698405, 0.283854 (1.443 sec)
27.669... logprob:  0.669393, 0.268229 (1.459 sec)
27.670... logprob:  0.567705, 0.259114 (1.432 sec)
27.671... logprob:  0.629980, 0.274740 (1.417 sec)
27.672... logprob:  0.594235, 0.265625 (1.425 sec)
27.673... logprob:  0.622022, 0.287760 (1.508 sec)
27.674... logprob:  0.665399, 0.290364 (1.434 sec)
27.675... logprob:  0.576846, 0.268229 (1.464 sec)
27.676... logprob:  0.696307, 0.292969 (1.454 sec)
27.677... logprob:  0.673851, 0.274740 (1.434 sec)
27.678... logprob:  0.667513, 0.279948 (1.477 sec)
27.679... logprob:  0.632279, 0.269531 (1.424 sec)
27.680... logprob:  0.512272, 0.225260 (1.422 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.486121, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.728305e-03 [1.364442e-07] 
Layer 'conv1' biases: 2.146479e-06 [6.514227e-11] 
Layer 'conv2' weights[0]: 2.722946e-03 [1.362067e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.209897e-10] 
Layer 'conv3' weights[0]: 2.721738e-03 [1.363770e-07] 
Layer 'conv3' biases: 3.559666e-05 [5.990512e-09] 
Layer 'conv4' weights[0]: 2.733251e-03 [1.371330e-07] 
Layer 'conv4' biases: 9.998798e-01 [1.612115e-07] 
Layer 'conv5' weights[0]: 2.887201e-03 [2.296909e-06] 
Layer 'conv5' biases: 9.991102e-01 [2.464258e-06] 
Layer 'fc6' weights[0]: 6.792334e-03 [6.207151e-08] 
Layer 'fc6' biases: 9.999889e-01 [5.589317e-08] 
Layer 'fc7' weights[0]: 7.137964e-03 [1.445668e-07] 
Layer 'fc7' biases: 9.997325e-01 [1.951214e-07] 
Layer 'fc8' weights[0]: 4.807907e-03 [1.362154e-05] 
Layer 'fc8' biases: 2.279592e-02 [2.617728e-05] 
Train error last 800 batches: 0.657442
-------------------------------------------------------
Not saving because 0.486121 > 0.299667 (9.300: -1.18%)
======================================================= (2.351 sec)
27.681... logprob:  0.664971, 0.290365 (1.439 sec)
27.682... logprob:  0.614251, 0.300781 (1.435 sec)
27.683... logprob:  0.679477, 0.295573 (1.436 sec)
27.684... logprob:  0.543599, 0.260417 (1.484 sec)
27.685... logprob:  0.620908, 0.283854 (1.440 sec)
27.686... logprob:  0.575910, 0.278646 (1.433 sec)
27.687... logprob:  0.526695, 0.222656 (1.480 sec)
27.688... logprob:  0.499929, 0.214844 (1.426 sec)
27.689... logprob:  0.710815, 0.319010 (1.424 sec)
27.690... logprob:  0.683667, 0.304688 (1.427 sec)
27.691... logprob:  0.710550, 0.324219 (1.429 sec)
27.692... logprob:  0.714116, 0.313802 (1.423 sec)
27.693... logprob:  0.720952, 0.313802 (1.484 sec)
27.694... logprob:  0.615046, 0.281250 (1.431 sec)
27.695... logprob:  0.627784, 0.299479 (1.438 sec)
27.696... logprob:  0.707889, 0.299479 (1.474 sec)
27.697... logprob:  0.801423, 0.339844 (1.434 sec)
27.698... logprob:  0.729478, 0.311198 (1.426 sec)
27.699... logprob:  0.782901, 0.317708 (1.432 sec)
27.700... logprob:  0.663081, 0.311198 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.399899, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.725582e-03 [1.362795e-07] 
Layer 'conv1' biases: 2.146634e-06 [1.043546e-10] 
Layer 'conv2' weights[0]: 2.720220e-03 [1.360671e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.362689e-09] 
Layer 'conv3' weights[0]: 2.719038e-03 [1.367645e-07] 
Layer 'conv3' biases: 3.558963e-05 [1.134901e-08] 
Layer 'conv4' weights[0]: 2.730540e-03 [1.377874e-07] 
Layer 'conv4' biases: 9.998806e-01 [3.319133e-07] 
Layer 'conv5' weights[0]: 2.885310e-03 [4.743122e-06] 
Layer 'conv5' biases: 9.991120e-01 [5.227753e-06] 
Layer 'fc6' weights[0]: 6.791626e-03 [8.708441e-08] 
Layer 'fc6' biases: 9.999889e-01 [8.944839e-08] 
Layer 'fc7' weights[0]: 7.137232e-03 [2.234740e-07] 
Layer 'fc7' biases: 9.997322e-01 [4.212699e-07] 
Layer 'fc8' weights[0]: 4.796734e-03 [2.269227e-05] 
Layer 'fc8' biases: 2.276922e-02 [7.590623e-05] 
Train error last 800 batches: 0.658207
-------------------------------------------------------
Not saving because 0.399899 > 0.299667 (9.300: -1.18%)
======================================================= (2.342 sec)
27.701... logprob:  0.727355, 0.332031 (1.439 sec)
27.702... logprob:  0.756581, 0.317708 (1.486 sec)
27.703... logprob:  0.672361, 0.325521 (1.435 sec)
27.704... logprob:  0.676106, 0.281250 (1.440 sec)
27.705... logprob:  0.676703, 0.290365 (1.468 sec)
27.706... logprob:  0.666996, 0.274740 (1.429 sec)
27.707... logprob:  0.761720, 0.335937 (1.432 sec)
27.708... logprob:  0.728501, 0.305990 (1.432 sec)
27.709... logprob:  0.672699, 0.259115 (1.421 sec)
27.710... logprob:  0.807125, 0.319010 (1.438 sec)
27.711... logprob:  0.725407, 0.302083 (1.459 sec)
27.712... logprob:  0.672672, 0.303385 (1.443 sec)
27.713... logprob:  0.696133, 0.313802 (1.448 sec)
27.714... logprob:  0.777522, 0.279948 (1.449 sec)
27.715... logprob:  0.654359, 0.285156 (1.448 sec)
27.716... logprob:  0.574654, 0.244792 (1.432 sec)
27.717... logprob:  0.624299, 0.298177 (1.419 sec)
27.718... logprob:  0.764391, 0.312500 (1.421 sec)
27.719... logprob:  0.590946, 0.255208 (1.431 sec)
27.720... logprob:  0.681288, 0.299479 (1.441 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.462680, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.722861e-03 [1.362092e-07] 
Layer 'conv1' biases: 2.146480e-06 [5.434395e-11] 
Layer 'conv2' weights[0]: 2.717508e-03 [1.359383e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.485982e-10] 
Layer 'conv3' weights[0]: 2.716316e-03 [1.361408e-07] 
Layer 'conv3' biases: 3.558812e-05 [6.545916e-09] 
Layer 'conv4' weights[0]: 2.727805e-03 [1.368996e-07] 
Layer 'conv4' biases: 9.998840e-01 [1.731870e-07] 
Layer 'conv5' weights[0]: 2.886259e-03 [2.273861e-06] 
Layer 'conv5' biases: 9.991703e-01 [2.407201e-06] 
Layer 'fc6' weights[0]: 6.790964e-03 [6.239316e-08] 
Layer 'fc6' biases: 9.999893e-01 [5.497407e-08] 
Layer 'fc7' weights[0]: 7.136551e-03 [1.422750e-07] 
Layer 'fc7' biases: 9.997280e-01 [1.722073e-07] 
Layer 'fc8' weights[0]: 4.657260e-03 [1.204915e-05] 
Layer 'fc8' biases: 2.167445e-02 [1.478519e-05] 
Train error last 800 batches: 0.658634
-------------------------------------------------------
Not saving because 0.462680 > 0.299667 (9.300: -1.18%)
======================================================= (2.358 sec)
27.721... logprob:  0.659959, 0.294271 (1.461 sec)
27.722... logprob:  0.697921, 0.312500 (1.455 sec)
27.723... logprob:  0.658702, 0.278646 (1.444 sec)
27.724... logprob:  0.706119, 0.299479 (1.465 sec)
27.725... logprob:  0.722123, 0.308594 (1.431 sec)
27.726... logprob:  0.589417, 0.255208 (1.417 sec)
27.727... logprob:  0.659322, 0.300781 (1.434 sec)
27.728... logprob:  0.614928, 0.243490 (1.435 sec)
27.729... logprob:  0.619664, 0.291667 (1.429 sec)
27.730... logprob:  0.731766, 0.291667 (1.474 sec)
27.731... logprob:  0.634548, 0.294271 (1.447 sec)
27.732... logprob:  0.540490, 0.223958 (1.427 sec)
27.733... logprob:  0.733580, 0.322917 (1.481 sec)
27.734... logprob:  0.604014, 0.257812 (1.426 sec)
27.735... logprob:  0.641867, 0.264323 (1.420 sec)
27.736... logprob:  0.882785, 0.342448 (1.431 sec)
27.737... logprob:  0.744581, 0.348958 (1.425 sec)
27.738... logprob:  0.614382, 0.279948 (1.428 sec)
27.739... logprob:  0.671182, 0.304687 (1.472 sec)
27.740... logprob:  0.494278, 0.227864 (1.513 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.413003, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.720134e-03 [1.361303e-07] 
Layer 'conv1' biases: 2.147133e-06 [8.939791e-11] 
Layer 'conv2' weights[0]: 2.714773e-03 [1.358441e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.060365e-09] 
Layer 'conv3' weights[0]: 2.713595e-03 [1.362692e-07] 
Layer 'conv3' biases: 3.559640e-05 [8.636717e-09] 
Layer 'conv4' weights[0]: 2.725072e-03 [1.371272e-07] 
Layer 'conv4' biases: 9.998814e-01 [2.318687e-07] 
Layer 'conv5' weights[0]: 2.881945e-03 [2.608466e-06] 
Layer 'conv5' biases: 9.991313e-01 [2.763863e-06] 
Layer 'fc6' weights[0]: 6.790261e-03 [6.487310e-08] 
Layer 'fc6' biases: 9.999891e-01 [5.847802e-08] 
Layer 'fc7' weights[0]: 7.135801e-03 [1.510381e-07] 
Layer 'fc7' biases: 9.997299e-01 [2.220834e-07] 
Layer 'fc8' weights[0]: 4.744465e-03 [1.379692e-05] 
Layer 'fc8' biases: 2.240903e-02 [3.807809e-05] 
Train error last 800 batches: 0.658470
-------------------------------------------------------
Not saving because 0.413003 > 0.299667 (9.300: -1.18%)
======================================================= (2.408 sec)
27.741... logprob:  0.625693, 0.253906 (1.439 sec)
27.742... logprob:  0.629174, 0.286458 (1.485 sec)
27.743... logprob:  0.636193, 0.286458 (1.434 sec)
27.744... logprob:  0.616240, 0.305990 (1.432 sec)
27.745... logprob:  0.704176, 0.273437 (1.429 sec)
27.746... logprob:  0.644056, 0.282552 (1.422 sec)
27.747... logprob:  0.643251, 0.250000 (1.427 sec)
27.748... logprob:  0.631454, 0.321615 (1.479 sec)
27.749... logprob:  0.694035, 0.303385 (1.427 sec)
27.750... logprob:  0.744756, 0.308594 (1.441 sec)
27.751... logprob:  0.541431, 0.247396 (1.469 sec)
27.752... logprob:  0.625970, 0.304688 (1.426 sec)
27.753... logprob:  0.687224, 0.307292 (1.435 sec)
27.754... logprob:  0.648394, 0.272135 (1.423 sec)
27.755... logprob:  0.769356, 0.338542 (1.421 sec)
27.756... logprob:  0.611464, 0.257812 (1.427 sec)
27.757... logprob:  0.738572, 0.295573 (1.466 sec)
27.758... logprob:  0.695063, 0.304687 (1.439 sec)
27.759... logprob:  0.747588, 0.322917 (1.447 sec)
27.760... logprob:  0.643259, 0.279948 (1.466 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.499766, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.717420e-03 [1.359486e-07] 
Layer 'conv1' biases: 2.147438e-06 [5.874910e-11] 
Layer 'conv2' weights[0]: 2.712058e-03 [1.356735e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.356410e-10] 
Layer 'conv3' weights[0]: 2.710872e-03 [1.359543e-07] 
Layer 'conv3' biases: 3.558123e-05 [7.124446e-09] 
Layer 'conv4' weights[0]: 2.722343e-03 [1.366759e-07] 
Layer 'conv4' biases: 9.998802e-01 [1.969830e-07] 
Layer 'conv5' weights[0]: 2.878741e-03 [2.878923e-06] 
Layer 'conv5' biases: 9.991080e-01 [3.125857e-06] 
Layer 'fc6' weights[0]: 6.789541e-03 [6.779856e-08] 
Layer 'fc6' biases: 9.999890e-01 [6.328009e-08] 
Layer 'fc7' weights[0]: 7.135097e-03 [1.602669e-07] 
Layer 'fc7' biases: 9.997306e-01 [2.369297e-07] 
Layer 'fc8' weights[0]: 4.775206e-03 [1.486936e-05] 
Layer 'fc8' biases: 2.267332e-02 [3.040498e-05] 
Train error last 800 batches: 0.658330
-------------------------------------------------------
Not saving because 0.499766 > 0.299667 (9.300: -1.18%)
======================================================= (2.358 sec)
27.761... logprob:  0.649646, 0.296875 (1.449 sec)
27.762... logprob:  0.757727, 0.311198 (1.436 sec)
27.763... logprob:  0.690884, 0.290365 (1.427 sec)
27.764... logprob:  0.706123, 0.322917 (1.420 sec)
27.765... logprob:  0.601025, 0.278646 (1.428 sec)
27.766... logprob:  0.759625, 0.333333 (1.452 sec)
27.767... logprob:  0.560766, 0.240885 (1.449 sec)
27.768... logprob:  0.711556, 0.339844 (1.454 sec)
27.769... logprob:  0.746176, 0.330729 (1.463 sec)
27.770... logprob:  0.600304, 0.252604 (1.475 sec)
27.771... logprob:  0.834537, 0.343750 (1.451 sec)
27.772... logprob:  0.680385, 0.299479 (1.438 sec)
27.773... logprob:  0.741321, 0.329427 (1.437 sec)
27.774... logprob:  0.570115, 0.235677 (1.539 sec)
27.775... logprob:  0.636157, 0.274739 (1.457 sec)
27.776... logprob:  0.633314, 0.278646 (1.471 sec)
27.777... logprob:  0.623931, 0.308594 (1.467 sec)
27.778... logprob:  0.690182, 0.320312 (1.459 sec)
27.779... logprob:  0.708310, 0.320312 (1.478 sec)
27.780... logprob:  0.625371, 0.274739 (1.447 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.481649, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.714699e-03 [1.358306e-07] 
Layer 'conv1' biases: 2.147927e-06 [5.389792e-11] 
Layer 'conv2' weights[0]: 2.709350e-03 [1.355744e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.726086e-10] 
Layer 'conv3' weights[0]: 2.708160e-03 [1.357206e-07] 
Layer 'conv3' biases: 3.557829e-05 [5.893908e-09] 
Layer 'conv4' weights[0]: 2.719641e-03 [1.364868e-07] 
Layer 'conv4' biases: 9.998802e-01 [1.436894e-07] 
Layer 'conv5' weights[0]: 2.876293e-03 [2.110953e-06] 
Layer 'conv5' biases: 9.991373e-01 [2.251313e-06] 
Layer 'fc6' weights[0]: 6.788822e-03 [5.891302e-08] 
Layer 'fc6' biases: 9.999891e-01 [5.123387e-08] 
Layer 'fc7' weights[0]: 7.134427e-03 [1.353377e-07] 
Layer 'fc7' biases: 9.997289e-01 [1.643320e-07] 
Layer 'fc8' weights[0]: 4.708913e-03 [1.125997e-05] 
Layer 'fc8' biases: 2.215891e-02 [1.501070e-05] 
Train error last 800 batches: 0.658560
-------------------------------------------------------
Not saving because 0.481649 > 0.299667 (9.300: -1.18%)
======================================================= (2.374 sec)
27.781... logprob:  0.612520, 0.281250 (1.447 sec)
27.782... logprob:  0.530649, 0.234375 (1.447 sec)
27.783... logprob:  0.768261, 0.324219 (1.453 sec)
27.784... logprob:  0.667827, 0.290365 (1.451 sec)
27.785... logprob:  0.799151, 0.356771 (1.487 sec)
27.786... logprob:  0.648168, 0.290364 (1.465 sec)
27.787... logprob:  0.764901, 0.333333 (1.448 sec)
27.788... logprob:  0.761104, 0.346354 (1.493 sec)
27.789... logprob:  0.542370, 0.225260 (1.455 sec)
27.790... logprob:  0.656138, 0.285156 (1.440 sec)
27.791... logprob:  0.613353, 0.279948 (1.439 sec)
27.792... logprob:  0.599863, 0.281250 (1.457 sec)
27.793... logprob:  0.600294, 0.250000 (1.444 sec)
27.794... logprob:  0.644285, 0.298177 (1.486 sec)
27.795... logprob:  0.707836, 0.294271 (1.466 sec)
27.796... logprob:  0.671576, 0.265625 (1.450 sec)
27.797... logprob:  0.597421, 0.263021 (1.490 sec)
27.798... logprob:  0.633220, 0.266927 (1.449 sec)
27.799... logprob:  0.654733, 0.289062 (1.439 sec)
27.800... logprob:  0.711141, 0.287760 (1.398 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.551111, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.711992e-03 [1.356658e-07] 
Layer 'conv1' biases: 2.147928e-06 [6.561156e-11] 
Layer 'conv2' weights[0]: 2.706628e-03 [1.354088e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.978376e-10] 
Layer 'conv3' weights[0]: 2.705463e-03 [1.356483e-07] 
Layer 'conv3' biases: 3.557180e-05 [7.076370e-09] 
Layer 'conv4' weights[0]: 2.716911e-03 [1.364588e-07] 
Layer 'conv4' biases: 9.998800e-01 [1.923510e-07] 
Layer 'conv5' weights[0]: 2.873389e-03 [2.096354e-06] 
Layer 'conv5' biases: 9.991275e-01 [2.280086e-06] 
Layer 'fc6' weights[0]: 6.788135e-03 [6.270952e-08] 
Layer 'fc6' biases: 9.999894e-01 [5.607080e-08] 
Layer 'fc7' weights[0]: 7.133726e-03 [1.456863e-07] 
Layer 'fc7' biases: 9.997290e-01 [1.830701e-07] 
Layer 'fc8' weights[0]: 4.737197e-03 [1.261639e-05] 
Layer 'fc8' biases: 2.237630e-02 [1.948818e-05] 
Train error last 800 batches: 0.658754
-------------------------------------------------------
Not saving because 0.551111 > 0.299667 (9.300: -1.18%)
======================================================= (2.404 sec)
28.1... logprob:  0.693022, 0.319010 (1.410 sec)
28.2... logprob:  0.732217, 0.292969 (1.449 sec)
28.3... logprob:  0.616702, 0.268229 (1.417 sec)
28.4... logprob:  0.589081, 0.242188 (1.399 sec)
28.5... logprob:  0.691318, 0.283854 (1.428 sec)
28.6... logprob:  0.721823, 0.295573 (1.393 sec)
28.7... logprob:  0.630214, 0.287760 (1.416 sec)
28.8... logprob:  0.565073, 0.257812 (1.392 sec)
28.9... logprob:  0.592779, 0.285156 (1.404 sec)
28.10... logprob:  0.559077, 0.259115 (1.409 sec)
28.11... logprob:  0.595823, 0.273437 (1.444 sec)
28.12... logprob:  0.727913, 0.309896 (1.392 sec)
28.13... logprob:  0.734368, 0.278646 (1.417 sec)
28.14... logprob:  0.636534, 0.259115 (1.396 sec)
28.15... logprob:  0.627832, 0.287760 (1.404 sec)
28.16... logprob:  0.640372, 0.291667 (1.400 sec)
28.17... logprob:  0.744605, 0.294271 (1.390 sec)
28.18... logprob:  0.475001, 0.210937 (1.393 sec)
28.19... logprob:  0.582591, 0.257812 (1.395 sec)
28.20... logprob:  0.705755, 0.333333 (1.398 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.423514, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.709275e-03 [1.356049e-07] 
Layer 'conv1' biases: 2.148319e-06 [5.556014e-11] 
Layer 'conv2' weights[0]: 2.703939e-03 [1.352839e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.010047e-10] 
Layer 'conv3' weights[0]: 2.702774e-03 [1.355215e-07] 
Layer 'conv3' biases: 3.558180e-05 [6.718078e-09] 
Layer 'conv4' weights[0]: 2.714176e-03 [1.362753e-07] 
Layer 'conv4' biases: 9.998782e-01 [1.936469e-07] 
Layer 'conv5' weights[0]: 2.869575e-03 [2.247149e-06] 
Layer 'conv5' biases: 9.991187e-01 [2.410424e-06] 
Layer 'fc6' weights[0]: 6.787429e-03 [6.207467e-08] 
Layer 'fc6' biases: 9.999896e-01 [5.546762e-08] 
Layer 'fc7' weights[0]: 7.133046e-03 [1.419145e-07] 
Layer 'fc7' biases: 9.997302e-01 [1.863252e-07] 
Layer 'fc8' weights[0]: 4.761974e-03 [1.372351e-05] 
Layer 'fc8' biases: 2.260839e-02 [3.439697e-05] 
Train error last 800 batches: 0.658903
-------------------------------------------------------
Not saving because 0.423514 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
28.21... logprob:  0.625437, 0.305989 (1.406 sec)
28.22... logprob:  0.737293, 0.324219 (1.412 sec)
28.23... logprob:  0.682343, 0.298177 (1.416 sec)
28.24... logprob:  0.609078, 0.281250 (1.412 sec)
28.25... logprob:  0.593402, 0.268229 (1.400 sec)
28.26... logprob:  0.646868, 0.282552 (1.441 sec)
28.27... logprob:  0.598499, 0.234375 (1.380 sec)
28.28... logprob:  0.629341, 0.285156 (1.408 sec)
28.29... logprob:  0.671814, 0.295573 (1.419 sec)
28.30... logprob:  0.588549, 0.253906 (1.414 sec)
28.31... logprob:  0.739149, 0.317708 (1.397 sec)
28.32... logprob:  0.681680, 0.317708 (1.390 sec)
28.33... logprob:  0.689083, 0.309896 (1.439 sec)
28.34... logprob:  0.727668, 0.307292 (1.386 sec)
28.35... logprob:  0.543918, 0.240885 (1.392 sec)
28.36... logprob:  0.661863, 0.285156 (1.398 sec)
28.37... logprob:  0.693399, 0.286458 (1.404 sec)
28.38... logprob:  0.640837, 0.278646 (1.385 sec)
28.39... logprob:  0.778281, 0.320312 (1.432 sec)
28.40... logprob:  0.606909, 0.252604 (1.402 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.378481, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.706571e-03 [1.353373e-07] 
Layer 'conv1' biases: 2.148335e-06 [7.303307e-11] 
Layer 'conv2' weights[0]: 2.701245e-03 [1.350979e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.202930e-10] 
Layer 'conv3' weights[0]: 2.700042e-03 [1.354218e-07] 
Layer 'conv3' biases: 3.558813e-05 [7.681084e-09] 
Layer 'conv4' weights[0]: 2.711463e-03 [1.360659e-07] 
Layer 'conv4' biases: 9.998790e-01 [1.906182e-07] 
Layer 'conv5' weights[0]: 2.867553e-03 [2.284123e-06] 
Layer 'conv5' biases: 9.991094e-01 [2.461657e-06] 
Layer 'fc6' weights[0]: 6.786745e-03 [6.647103e-08] 
Layer 'fc6' biases: 9.999893e-01 [6.133639e-08] 
Layer 'fc7' weights[0]: 7.132306e-03 [1.557675e-07] 
Layer 'fc7' biases: 9.997298e-01 [2.213983e-07] 
Layer 'fc8' weights[0]: 4.766014e-03 [1.479500e-05] 
Layer 'fc8' biases: 2.265839e-02 [3.770101e-05] 
Train error last 800 batches: 0.659028
-------------------------------------------------------
Not saving because 0.378481 > 0.299667 (9.300: -1.18%)
======================================================= (2.365 sec)
28.41... logprob:  0.628077, 0.294271 (1.431 sec)
28.42... logprob:  0.637039, 0.303385 (1.414 sec)
28.43... logprob:  0.596285, 0.261719 (1.401 sec)
28.44... logprob:  0.717471, 0.311198 (1.428 sec)
28.45... logprob:  0.606907, 0.261719 (1.386 sec)
28.46... logprob:  0.665586, 0.287760 (1.399 sec)
28.47... logprob:  0.620279, 0.264323 (1.388 sec)
28.48... logprob:  0.756262, 0.308594 (1.428 sec)
28.49... logprob:  0.782417, 0.367187 (1.415 sec)
28.50... logprob:  0.577113, 0.255208 (1.421 sec)
28.51... logprob:  0.714680, 0.308594 (1.414 sec)
28.52... logprob:  0.752519, 0.326823 (1.390 sec)
28.53... logprob:  0.561489, 0.286458 (1.440 sec)
28.54... logprob:  0.650013, 0.279948 (1.379 sec)
28.55... logprob:  0.515343, 0.222656 (1.393 sec)
28.56... logprob:  0.639508, 0.285156 (1.396 sec)
28.57... logprob:  0.660503, 0.265625 (1.432 sec)
28.58... logprob:  0.605208, 0.247396 (1.392 sec)
28.59... logprob:  0.609955, 0.278646 (1.458 sec)
28.60... logprob:  0.734358, 0.315104 (1.413 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.507186, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.703870e-03 [1.352172e-07] 
Layer 'conv1' biases: 2.148424e-06 [6.673982e-11] 
Layer 'conv2' weights[0]: 2.698530e-03 [1.349989e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.871871e-10] 
Layer 'conv3' weights[0]: 2.697322e-03 [1.352199e-07] 
Layer 'conv3' biases: 3.559292e-05 [6.678488e-09] 
Layer 'conv4' weights[0]: 2.708750e-03 [1.360643e-07] 
Layer 'conv4' biases: 9.998792e-01 [1.966592e-07] 
Layer 'conv5' weights[0]: 2.865388e-03 [2.422164e-06] 
Layer 'conv5' biases: 9.990995e-01 [2.573895e-06] 
Layer 'fc6' weights[0]: 6.786030e-03 [6.166894e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.544733e-08] 
Layer 'fc7' weights[0]: 7.131588e-03 [1.399136e-07] 
Layer 'fc7' biases: 9.997300e-01 [1.711619e-07] 
Layer 'fc8' weights[0]: 4.764236e-03 [1.192102e-05] 
Layer 'fc8' biases: 2.263161e-02 [2.046665e-05] 
Train error last 800 batches: 0.659022
-------------------------------------------------------
Not saving because 0.507186 > 0.299667 (9.300: -1.18%)
======================================================= (2.378 sec)
28.61... logprob:  0.582327, 0.251302 (1.429 sec)
28.62... logprob:  0.706562, 0.272135 (1.461 sec)
28.63... logprob:  0.672621, 0.302083 (1.445 sec)
28.64... logprob:  0.655836, 0.299479 (1.409 sec)
28.65... logprob:  0.511584, 0.231771 (1.398 sec)
28.66... logprob:  0.569283, 0.278646 (1.440 sec)
28.67... logprob:  0.541240, 0.272135 (1.384 sec)
28.68... logprob:  0.577954, 0.260417 (1.397 sec)
28.69... logprob:  0.719673, 0.309896 (1.426 sec)
28.70... logprob:  0.544951, 0.259115 (1.417 sec)
28.71... logprob:  0.560467, 0.256510 (1.456 sec)
28.72... logprob:  0.712929, 0.278646 (1.395 sec)
28.73... logprob:  0.605277, 0.264323 (1.419 sec)
28.74... logprob:  0.626758, 0.244792 (1.407 sec)
28.75... logprob:  0.645254, 0.290365 (1.412 sec)
28.76... logprob:  0.566044, 0.244792 (1.427 sec)
28.77... logprob:  0.570802, 0.264323 (1.425 sec)
28.78... logprob:  0.693187, 0.283854 (1.453 sec)
28.79... logprob:  0.649164, 0.278646 (1.393 sec)
28.80... logprob:  0.699537, 0.295573 (1.411 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.460217, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.701164e-03 [1.351217e-07] 
Layer 'conv1' biases: 2.148641e-06 [4.735213e-11] 
Layer 'conv2' weights[0]: 2.695831e-03 [1.348711e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.084334e-10] 
Layer 'conv3' weights[0]: 2.694664e-03 [1.349877e-07] 
Layer 'conv3' biases: 3.556236e-05 [5.232061e-09] 
Layer 'conv4' weights[0]: 2.706048e-03 [1.356193e-07] 
Layer 'conv4' biases: 9.998782e-01 [1.353494e-07] 
Layer 'conv5' weights[0]: 2.862883e-03 [2.243312e-06] 
Layer 'conv5' biases: 9.990554e-01 [2.414456e-06] 
Layer 'fc6' weights[0]: 6.785371e-03 [5.833583e-08] 
Layer 'fc6' biases: 9.999887e-01 [5.195454e-08] 
Layer 'fc7' weights[0]: 7.130851e-03 [1.350723e-07] 
Layer 'fc7' biases: 9.997332e-01 [1.586950e-07] 
Layer 'fc8' weights[0]: 4.856514e-03 [1.162783e-05] 
Layer 'fc8' biases: 2.337344e-02 [1.627552e-05] 
Train error last 800 batches: 0.658050
-------------------------------------------------------
Not saving because 0.460217 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
28.81... logprob:  0.558034, 0.251302 (1.418 sec)
28.82... logprob:  0.569236, 0.281250 (1.427 sec)
28.83... logprob:  0.704230, 0.260417 (1.397 sec)
28.84... logprob:  0.692488, 0.315104 (1.465 sec)
28.85... logprob:  0.624483, 0.291667 (1.425 sec)
28.86... logprob:  0.618954, 0.286458 (1.419 sec)
28.87... logprob:  0.858970, 0.319010 (1.414 sec)
28.88... logprob:  0.699031, 0.311198 (1.400 sec)
28.89... logprob:  0.750208, 0.311198 (1.431 sec)
28.90... logprob:  0.729637, 0.325521 (1.378 sec)
28.91... logprob:  0.537688, 0.221354 (1.396 sec)
28.92... logprob:  0.686770, 0.260417 (1.405 sec)
28.93... logprob:  0.729089, 0.343750 (1.394 sec)
28.94... logprob:  0.708187, 0.328125 (1.387 sec)
28.95... logprob:  0.639441, 0.292969 (1.400 sec)
28.96... logprob:  0.787750, 0.319010 (1.398 sec)
28.97... logprob:  0.601160, 0.270833 (1.390 sec)
28.98... logprob:  0.599331, 0.274740 (1.453 sec)
28.99... logprob:  0.647011, 0.282552 (1.399 sec)
28.100... logprob:  0.565198, 0.282552 (1.395 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.427594, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.698464e-03 [1.349805e-07] 
Layer 'conv1' biases: 2.148802e-06 [4.516348e-11] 
Layer 'conv2' weights[0]: 2.693141e-03 [1.347222e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.705319e-10] 
Layer 'conv3' weights[0]: 2.691966e-03 [1.348335e-07] 
Layer 'conv3' biases: 3.555598e-05 [5.172964e-09] 
Layer 'conv4' weights[0]: 2.703352e-03 [1.354539e-07] 
Layer 'conv4' biases: 9.998790e-01 [1.268664e-07] 
Layer 'conv5' weights[0]: 2.860684e-03 [2.015573e-06] 
Layer 'conv5' biases: 9.990960e-01 [2.212014e-06] 
Layer 'fc6' weights[0]: 6.784686e-03 [5.685410e-08] 
Layer 'fc6' biases: 9.999889e-01 [4.950780e-08] 
Layer 'fc7' weights[0]: 7.130165e-03 [1.306401e-07] 
Layer 'fc7' biases: 9.997299e-01 [1.598751e-07] 
Layer 'fc8' weights[0]: 4.757579e-03 [1.173872e-05] 
Layer 'fc8' biases: 2.260618e-02 [2.095907e-05] 
Train error last 800 batches: 0.657592
-------------------------------------------------------
Not saving because 0.427594 > 0.299667 (9.300: -1.18%)
======================================================= (2.376 sec)
28.101... logprob:  0.605880, 0.255208 (1.447 sec)
28.102... logprob:  0.834299, 0.330729 (1.386 sec)
28.103... logprob:  0.673996, 0.279948 (1.394 sec)
28.104... logprob:  0.660035, 0.308594 (1.396 sec)
28.105... logprob:  0.766330, 0.316406 (1.391 sec)
28.106... logprob:  0.580902, 0.257812 (1.393 sec)
28.107... logprob:  0.545159, 0.251302 (1.438 sec)
28.108... logprob:  0.738226, 0.299479 (1.396 sec)
28.109... logprob:  0.634197, 0.274740 (1.395 sec)
28.110... logprob:  0.723408, 0.329427 (1.389 sec)
28.111... logprob:  0.597576, 0.259115 (1.390 sec)
28.112... logprob:  0.589201, 0.277344 (1.391 sec)
28.113... logprob:  0.642380, 0.276042 (1.397 sec)
28.114... logprob:  0.607535, 0.250000 (1.427 sec)
28.115... logprob:  0.692524, 0.282552 (1.409 sec)
28.116... logprob:  0.684098, 0.265625 (1.391 sec)
28.117... logprob:  0.637771, 0.266927 (1.440 sec)
28.118... logprob:  0.648654, 0.287760 (1.383 sec)
28.119... logprob:  0.568467, 0.239583 (1.399 sec)
28.120... logprob:  0.709609, 0.296875 (1.391 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.446570, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.695766e-03 [1.348773e-07] 
Layer 'conv1' biases: 2.148973e-06 [5.789112e-11] 
Layer 'conv2' weights[0]: 2.690445e-03 [1.346175e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.274777e-10] 
Layer 'conv3' weights[0]: 2.689264e-03 [1.347249e-07] 
Layer 'conv3' biases: 3.557401e-05 [5.283163e-09] 
Layer 'conv4' weights[0]: 2.700632e-03 [1.354881e-07] 
Layer 'conv4' biases: 9.998796e-01 [1.500943e-07] 
Layer 'conv5' weights[0]: 2.858917e-03 [2.526409e-06] 
Layer 'conv5' biases: 9.991021e-01 [2.714034e-06] 
Layer 'fc6' weights[0]: 6.783999e-03 [6.468322e-08] 
Layer 'fc6' biases: 9.999890e-01 [5.924164e-08] 
Layer 'fc7' weights[0]: 7.129450e-03 [1.507129e-07] 
Layer 'fc7' biases: 9.997292e-01 [2.035106e-07] 
Layer 'fc8' weights[0]: 4.743988e-03 [1.432107e-05] 
Layer 'fc8' biases: 2.247772e-02 [3.515112e-05] 
Train error last 800 batches: 0.657348
-------------------------------------------------------
Not saving because 0.446570 > 0.299667 (9.300: -1.18%)
======================================================= (2.399 sec)
28.121... logprob:  0.688170, 0.312500 (1.403 sec)
28.122... logprob:  0.762834, 0.312500 (1.445 sec)
28.123... logprob:  0.739563, 0.308594 (1.384 sec)
28.124... logprob:  0.675808, 0.278646 (1.404 sec)
28.125... logprob:  0.677509, 0.307292 (1.393 sec)
28.126... logprob:  0.700302, 0.304687 (1.385 sec)
28.127... logprob:  0.673656, 0.295573 (1.391 sec)
28.128... logprob:  0.582659, 0.238281 (1.420 sec)
28.129... logprob:  0.759896, 0.303385 (1.419 sec)
28.130... logprob:  0.593829, 0.256510 (1.407 sec)
28.131... logprob:  0.705471, 0.311198 (1.402 sec)
28.132... logprob:  0.729369, 0.302083 (1.430 sec)
28.133... logprob:  0.632198, 0.285156 (1.380 sec)
28.134... logprob:  0.609316, 0.281250 (1.389 sec)
28.135... logprob:  0.702658, 0.322917 (1.394 sec)
28.136... logprob:  0.809969, 0.347656 (1.393 sec)
28.137... logprob:  0.679880, 0.304688 (1.390 sec)
28.138... logprob:  0.597373, 0.283854 (1.441 sec)
28.139... logprob:  0.598033, 0.263021 (1.396 sec)
28.140... logprob:  0.742964, 0.335937 (1.403 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.391436, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.693069e-03 [1.347412e-07] 
Layer 'conv1' biases: 2.149221e-06 [5.698495e-11] 
Layer 'conv2' weights[0]: 2.687766e-03 [1.344806e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.695084e-10] 
Layer 'conv3' weights[0]: 2.686557e-03 [1.345880e-07] 
Layer 'conv3' biases: 3.559428e-05 [5.470646e-09] 
Layer 'conv4' weights[0]: 2.697933e-03 [1.352931e-07] 
Layer 'conv4' biases: 9.998813e-01 [1.413188e-07] 
Layer 'conv5' weights[0]: 2.857567e-03 [1.967244e-06] 
Layer 'conv5' biases: 9.991145e-01 [2.139425e-06] 
Layer 'fc6' weights[0]: 6.783319e-03 [5.972861e-08] 
Layer 'fc6' biases: 9.999890e-01 [5.269342e-08] 
Layer 'fc7' weights[0]: 7.128725e-03 [1.367885e-07] 
Layer 'fc7' biases: 9.997277e-01 [1.650687e-07] 
Layer 'fc8' weights[0]: 4.716280e-03 [1.189018e-05] 
Layer 'fc8' biases: 2.231938e-02 [1.703395e-05] 
Train error last 800 batches: 0.657429
-------------------------------------------------------
Not saving because 0.391436 > 0.299667 (9.300: -1.18%)
======================================================= (2.387 sec)
28.141... logprob:  0.692289, 0.287760 (1.447 sec)
28.142... logprob:  0.763475, 0.358073 (1.397 sec)
28.143... logprob:  0.545775, 0.242187 (1.428 sec)
28.144... logprob:  0.675278, 0.299479 (1.407 sec)
28.145... logprob:  0.653411, 0.338542 (1.409 sec)
28.146... logprob:  0.760068, 0.319010 (1.404 sec)
28.147... logprob:  0.533173, 0.221354 (1.424 sec)
28.148... logprob:  0.706538, 0.287760 (1.385 sec)
28.149... logprob:  0.620200, 0.244792 (1.388 sec)
28.150... logprob:  0.592472, 0.268229 (1.396 sec)
28.151... logprob:  0.564558, 0.227865 (1.394 sec)
28.152... logprob:  0.870974, 0.376302 (1.388 sec)
28.153... logprob:  0.582133, 0.251302 (1.442 sec)
28.154... logprob:  0.820859, 0.358073 (1.398 sec)
28.155... logprob:  0.569029, 0.243490 (1.404 sec)
28.156... logprob:  0.531192, 0.253906 (1.432 sec)
28.157... logprob:  0.521581, 0.235677 (1.388 sec)
28.158... logprob:  0.579048, 0.266927 (1.399 sec)
28.159... logprob:  0.748590, 0.307292 (1.392 sec)
28.160... logprob:  0.739193, 0.338542 (1.393 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.555260, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.690385e-03 [1.346275e-07] 
Layer 'conv1' biases: 2.149616e-06 [5.105231e-11] 
Layer 'conv2' weights[0]: 2.685075e-03 [1.343356e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.075193e-10] 
Layer 'conv3' weights[0]: 2.683878e-03 [1.344933e-07] 
Layer 'conv3' biases: 3.559167e-05 [6.024908e-09] 
Layer 'conv4' weights[0]: 2.695252e-03 [1.352106e-07] 
Layer 'conv4' biases: 9.998808e-01 [1.631231e-07] 
Layer 'conv5' weights[0]: 2.855122e-03 [2.126079e-06] 
Layer 'conv5' biases: 9.990991e-01 [2.263600e-06] 
Layer 'fc6' weights[0]: 6.782649e-03 [6.054984e-08] 
Layer 'fc6' biases: 9.999891e-01 [5.391501e-08] 
Layer 'fc7' weights[0]: 7.128017e-03 [1.405808e-07] 
Layer 'fc7' biases: 9.997290e-01 [1.794649e-07] 
Layer 'fc8' weights[0]: 4.750916e-03 [1.290273e-05] 
Layer 'fc8' biases: 2.260365e-02 [2.767583e-05] 
Train error last 800 batches: 0.657497
-------------------------------------------------------
Not saving because 0.555260 > 0.299667 (9.300: -1.18%)
======================================================= (2.382 sec)
28.161... logprob:  0.601384, 0.266927 (1.405 sec)
28.162... logprob:  0.824776, 0.329427 (1.405 sec)
28.163... logprob:  0.634247, 0.305990 (1.426 sec)
28.164... logprob:  0.713609, 0.292969 (1.419 sec)
28.165... logprob:  0.842963, 0.351562 (1.409 sec)
28.166... logprob:  0.697582, 0.282552 (1.446 sec)
28.167... logprob:  0.620713, 0.286458 (1.423 sec)
28.168... logprob:  0.676378, 0.282552 (1.416 sec)
28.169... logprob:  0.668393, 0.272135 (1.456 sec)
28.170... logprob:  0.674431, 0.328125 (1.394 sec)
28.171... logprob:  0.731278, 0.319010 (1.414 sec)
28.172... logprob:  0.702235, 0.312500 (1.409 sec)
28.173... logprob:  0.686636, 0.317708 (1.415 sec)
28.174... logprob:  0.796095, 0.339844 (1.392 sec)
28.175... logprob:  0.737237, 0.319010 (1.465 sec)
28.176... logprob:  0.721037, 0.317708 (1.433 sec)
28.177... logprob:  0.473196, 0.207031 (1.418 sec)
28.178... logprob:  0.601862, 0.266927 (1.450 sec)
28.179... logprob:  0.637130, 0.257812 (1.403 sec)
28.180... logprob:  0.588842, 0.242187 (1.414 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.470658, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.687694e-03 [1.345130e-07] 
Layer 'conv1' biases: 2.149948e-06 [6.461408e-11] 
Layer 'conv2' weights[0]: 2.682383e-03 [1.342420e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.738648e-10] 
Layer 'conv3' weights[0]: 2.681203e-03 [1.344420e-07] 
Layer 'conv3' biases: 3.559808e-05 [6.616783e-09] 
Layer 'conv4' weights[0]: 2.692564e-03 [1.353360e-07] 
Layer 'conv4' biases: 9.998825e-01 [2.032702e-07] 
Layer 'conv5' weights[0]: 2.854054e-03 [2.983249e-06] 
Layer 'conv5' biases: 9.991177e-01 [3.279893e-06] 
Layer 'fc6' weights[0]: 6.781965e-03 [6.905481e-08] 
Layer 'fc6' biases: 9.999893e-01 [6.408614e-08] 
Layer 'fc7' weights[0]: 7.127236e-03 [1.625282e-07] 
Layer 'fc7' biases: 9.997275e-01 [2.597262e-07] 
Layer 'fc8' weights[0]: 4.718468e-03 [1.569248e-05] 
Layer 'fc8' biases: 2.235285e-02 [4.424800e-05] 
Train error last 800 batches: 0.657935
-------------------------------------------------------
Not saving because 0.470658 > 0.299667 (9.300: -1.18%)
======================================================= (2.473 sec)
28.181... logprob:  0.760356, 0.316406 (1.424 sec)
28.182... logprob:  0.657828, 0.286458 (1.418 sec)
28.183... logprob:  0.658984, 0.307292 (1.415 sec)
28.184... logprob:  0.702010, 0.286458 (1.413 sec)
28.185... logprob:  0.542133, 0.222656 (1.397 sec)
28.186... logprob:  0.666483, 0.298177 (1.398 sec)
28.187... logprob:  0.701183, 0.316406 (1.398 sec)
28.188... logprob:  0.655746, 0.292969 (1.388 sec)
28.189... logprob:  0.608953, 0.248698 (1.382 sec)
28.190... logprob:  0.568246, 0.216146 (1.431 sec)
28.191... logprob:  0.628830, 0.264323 (1.403 sec)
28.192... logprob:  0.749509, 0.313802 (1.420 sec)
28.193... logprob:  0.573257, 0.265625 (1.419 sec)
28.194... logprob:  0.586522, 0.240885 (1.417 sec)
28.195... logprob:  0.536353, 0.251302 (1.404 sec)
28.196... logprob:  0.653835, 0.312500 (1.384 sec)
28.197... logprob:  0.692566, 0.309896 (1.392 sec)
28.198... logprob:  0.612294, 0.259115 (1.401 sec)
28.199... logprob:  0.577718, 0.259114 (1.387 sec)
28.200... logprob:  0.655074, 0.276042 (1.436 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.387224, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.684998e-03 [1.343338e-07] 
Layer 'conv1' biases: 2.150326e-06 [6.421262e-11] 
Layer 'conv2' weights[0]: 2.679709e-03 [1.340944e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.592121e-10] 
Layer 'conv3' weights[0]: 2.678541e-03 [1.343967e-07] 
Layer 'conv3' biases: 3.559721e-05 [8.400887e-09] 
Layer 'conv4' weights[0]: 2.689862e-03 [1.352483e-07] 
Layer 'conv4' biases: 9.998807e-01 [2.181797e-07] 
Layer 'conv5' weights[0]: 2.850358e-03 [2.683107e-06] 
Layer 'conv5' biases: 9.990863e-01 [2.953136e-06] 
Layer 'fc6' weights[0]: 6.781316e-03 [6.352027e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.779271e-08] 
Layer 'fc7' weights[0]: 7.126551e-03 [1.470904e-07] 
Layer 'fc7' biases: 9.997296e-01 [2.031086e-07] 
Layer 'fc8' weights[0]: 4.794923e-03 [1.293518e-05] 
Layer 'fc8' biases: 2.293637e-02 [3.006008e-05] 
Train error last 800 batches: 0.658214
-------------------------------------------------------
Not saving because 0.387224 > 0.299667 (9.300: -1.18%)
======================================================= (2.362 sec)
28.201... logprob:  0.642084, 0.316406 (1.411 sec)
28.202... logprob:  0.735722, 0.303385 (1.396 sec)
28.203... logprob:  0.722503, 0.338542 (1.450 sec)
28.204... logprob:  0.688163, 0.299479 (1.380 sec)
28.205... logprob:  0.608201, 0.253906 (1.399 sec)
28.206... logprob:  0.548745, 0.229167 (1.401 sec)
28.207... logprob:  0.644002, 0.302083 (1.385 sec)
28.208... logprob:  0.649574, 0.289062 (1.392 sec)
28.209... logprob:  0.500800, 0.214844 (1.419 sec)
28.210... logprob:  0.739883, 0.317708 (1.411 sec)
28.211... logprob:  0.719756, 0.304688 (1.409 sec)
28.212... logprob:  0.655052, 0.285156 (1.412 sec)
28.213... logprob:  0.722836, 0.289062 (1.461 sec)
28.214... logprob:  0.721915, 0.300781 (1.422 sec)
28.215... logprob:  0.585036, 0.268229 (1.439 sec)
28.216... logprob:  0.800278, 0.326823 (1.464 sec)
28.217... logprob:  0.509899, 0.231771 (1.398 sec)
28.218... logprob:  0.681336, 0.309896 (1.419 sec)
28.219... logprob:  0.856440, 0.371094 (1.415 sec)
28.220... logprob:  0.582344, 0.257812 (1.412 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.444456, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.682320e-03 [1.341217e-07] 
Layer 'conv1' biases: 2.150455e-06 [5.359043e-11] 
Layer 'conv2' weights[0]: 2.677035e-03 [1.338928e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.191567e-10] 
Layer 'conv3' weights[0]: 2.675850e-03 [1.341796e-07] 
Layer 'conv3' biases: 3.559722e-05 [7.466870e-09] 
Layer 'conv4' weights[0]: 2.687173e-03 [1.348679e-07] 
Layer 'conv4' biases: 9.998809e-01 [1.955985e-07] 
Layer 'conv5' weights[0]: 2.848412e-03 [2.565489e-06] 
Layer 'conv5' biases: 9.990914e-01 [2.747503e-06] 
Layer 'fc6' weights[0]: 6.780584e-03 [6.603444e-08] 
Layer 'fc6' biases: 9.999893e-01 [6.139486e-08] 
Layer 'fc7' weights[0]: 7.125826e-03 [1.557040e-07] 
Layer 'fc7' biases: 9.997284e-01 [2.202983e-07] 
Layer 'fc8' weights[0]: 4.767293e-03 [1.357709e-05] 
Layer 'fc8' biases: 2.272672e-02 [3.153616e-05] 
Train error last 800 batches: 0.657817
-------------------------------------------------------
Not saving because 0.444456 > 0.299667 (9.300: -1.18%)
======================================================= (2.378 sec)
28.221... logprob:  0.673160, 0.282552 (1.404 sec)
28.222... logprob:  0.786244, 0.358073 (1.460 sec)
28.223... logprob:  0.767668, 0.324219 (1.426 sec)
28.224... logprob:  0.636018, 0.248698 (1.423 sec)
28.225... logprob:  0.622547, 0.265625 (1.443 sec)
28.226... logprob:  0.689387, 0.286458 (1.422 sec)
28.227... logprob:  0.679164, 0.290365 (1.411 sec)
28.228... logprob:  0.621822, 0.255208 (1.414 sec)
28.229... logprob:  0.689393, 0.325521 (1.412 sec)
28.230... logprob:  0.650891, 0.290365 (1.417 sec)
28.231... logprob:  0.622627, 0.252604 (1.406 sec)
28.232... logprob:  0.616817, 0.274740 (1.454 sec)
28.233... logprob:  0.628656, 0.266927 (1.425 sec)
28.234... logprob:  0.810703, 0.339844 (1.412 sec)
28.235... logprob:  0.621262, 0.259115 (1.460 sec)
28.236... logprob:  0.631347, 0.298177 (1.395 sec)
28.237... logprob:  0.666934, 0.304687 (1.423 sec)
28.238... logprob:  0.571305, 0.251302 (1.407 sec)
28.239... logprob:  0.719808, 0.305990 (1.416 sec)
28.240... logprob:  0.622877, 0.257813 (1.394 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.490013, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.679630e-03 [1.340933e-07] 
Layer 'conv1' biases: 2.150984e-06 [7.121375e-11] 
Layer 'conv2' weights[0]: 2.674354e-03 [1.338376e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.520722e-10] 
Layer 'conv3' weights[0]: 2.673171e-03 [1.340809e-07] 
Layer 'conv3' biases: 3.560110e-05 [7.484365e-09] 
Layer 'conv4' weights[0]: 2.684468e-03 [1.349242e-07] 
Layer 'conv4' biases: 9.998802e-01 [1.933742e-07] 
Layer 'conv5' weights[0]: 2.845151e-03 [2.432795e-06] 
Layer 'conv5' biases: 9.991089e-01 [2.552222e-06] 
Layer 'fc6' weights[0]: 6.779850e-03 [6.141336e-08] 
Layer 'fc6' biases: 9.999893e-01 [5.476812e-08] 
Layer 'fc7' weights[0]: 7.125083e-03 [1.415648e-07] 
Layer 'fc7' biases: 9.997268e-01 [1.734593e-07] 
Layer 'fc8' weights[0]: 4.735566e-03 [1.202819e-05] 
Layer 'fc8' biases: 2.245002e-02 [1.803041e-05] 
Train error last 800 batches: 0.657417
-------------------------------------------------------
Not saving because 0.490013 > 0.299667 (9.300: -1.18%)
======================================================= (2.359 sec)
28.241... logprob:  0.713063, 0.296875 (1.462 sec)
28.242... logprob:  0.549195, 0.261719 (1.424 sec)
28.243... logprob:  0.614342, 0.261719 (1.433 sec)
28.244... logprob:  0.567277, 0.243490 (1.438 sec)
28.245... logprob:  0.648707, 0.276042 (1.419 sec)
28.246... logprob:  0.716555, 0.299479 (1.414 sec)
28.247... logprob:  0.619445, 0.287760 (1.410 sec)
28.248... logprob:  0.598990, 0.251302 (1.417 sec)
28.249... logprob:  0.772812, 0.315104 (1.415 sec)
28.250... logprob:  0.784134, 0.343750 (1.396 sec)
28.251... logprob:  0.556394, 0.233073 (1.457 sec)
28.252... logprob:  0.520189, 0.247396 (1.420 sec)
28.253... logprob:  0.609496, 0.278646 (1.411 sec)
28.254... logprob:  0.661529, 0.309896 (1.466 sec)
28.255... logprob:  0.627070, 0.298177 (1.398 sec)
28.256... logprob:  0.651365, 0.292969 (1.422 sec)
28.257... logprob:  0.585835, 0.248698 (1.410 sec)
28.258... logprob:  0.688279, 0.299479 (1.419 sec)
28.259... logprob:  0.598568, 0.270833 (1.394 sec)
28.260... logprob:  0.593181, 0.266927 (1.524 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.495541, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.676958e-03 [1.339935e-07] 
Layer 'conv1' biases: 2.151147e-06 [6.864669e-11] 
Layer 'conv2' weights[0]: 2.671664e-03 [1.337158e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.373633e-10] 
Layer 'conv3' weights[0]: 2.670499e-03 [1.340034e-07] 
Layer 'conv3' biases: 3.558761e-05 [7.398375e-09] 
Layer 'conv4' weights[0]: 2.681785e-03 [1.350275e-07] 
Layer 'conv4' biases: 9.998780e-01 [2.311284e-07] 
Layer 'conv5' weights[0]: 2.841340e-03 [3.123652e-06] 
Layer 'conv5' biases: 9.990775e-01 [3.444253e-06] 
Layer 'fc6' weights[0]: 6.779128e-03 [6.802027e-08] 
Layer 'fc6' biases: 9.999892e-01 [6.359103e-08] 
Layer 'fc7' weights[0]: 7.124366e-03 [1.614628e-07] 
Layer 'fc7' biases: 9.997290e-01 [2.605445e-07] 
Layer 'fc8' weights[0]: 4.811288e-03 [1.625468e-05] 
Layer 'fc8' biases: 2.315257e-02 [4.555511e-05] 
Train error last 800 batches: 0.657497
-------------------------------------------------------
Not saving because 0.495541 > 0.299667 (9.300: -1.18%)
======================================================= (2.367 sec)
28.261... logprob:  0.727318, 0.316406 (1.442 sec)
28.262... logprob:  0.707049, 0.317708 (1.430 sec)
28.263... logprob:  0.632661, 0.247396 (1.442 sec)
28.264... logprob:  0.504189, 0.233073 (1.423 sec)
28.265... logprob:  0.625008, 0.295573 (1.409 sec)
28.266... logprob:  0.703072, 0.302083 (1.410 sec)
28.267... logprob:  0.668619, 0.294271 (1.417 sec)
28.268... logprob:  0.571295, 0.264323 (1.421 sec)
28.269... logprob:  0.790674, 0.322917 (1.402 sec)
28.270... logprob:  0.780674, 0.343750 (1.450 sec)
28.271... logprob:  0.597541, 0.268229 (1.432 sec)
28.272... logprob:  0.615032, 0.287760 (1.418 sec)
28.273... logprob:  0.731893, 0.319010 (1.470 sec)
28.274... logprob:  0.707189, 0.309896 (1.401 sec)
28.275... logprob:  0.721184, 0.311198 (1.416 sec)
28.276... logprob:  0.612797, 0.268229 (1.413 sec)
28.277... logprob:  0.665770, 0.281250 (1.424 sec)
28.278... logprob:  0.556156, 0.255208 (1.418 sec)
28.279... logprob:  0.557669, 0.251302 (1.453 sec)
28.280... logprob:  0.453229, 0.217448 (1.398 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.516078, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.674285e-03 [1.337895e-07] 
Layer 'conv1' biases: 2.151635e-06 [7.945298e-11] 
Layer 'conv2' weights[0]: 2.669005e-03 [1.335367e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.399649e-10] 
Layer 'conv3' weights[0]: 2.667829e-03 [1.339695e-07] 
Layer 'conv3' biases: 3.560565e-05 [8.205844e-09] 
Layer 'conv4' weights[0]: 2.679090e-03 [1.349671e-07] 
Layer 'conv4' biases: 9.998764e-01 [2.426521e-07] 
Layer 'conv5' weights[0]: 2.837864e-03 [2.577451e-06] 
Layer 'conv5' biases: 9.990829e-01 [2.819374e-06] 
Layer 'fc6' weights[0]: 6.778437e-03 [6.286315e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.716614e-08] 
Layer 'fc7' weights[0]: 7.123675e-03 [1.434680e-07] 
Layer 'fc7' biases: 9.997284e-01 [2.142792e-07] 
Layer 'fc8' weights[0]: 4.797547e-03 [1.313445e-05] 
Layer 'fc8' biases: 2.311200e-02 [3.485605e-05] 
Train error last 800 batches: 0.657245
-------------------------------------------------------
Not saving because 0.516078 > 0.299667 (9.300: -1.18%)
======================================================= (2.358 sec)
28.281... logprob:  0.664466, 0.307292 (1.428 sec)
28.282... logprob:  0.604738, 0.265625 (1.419 sec)
28.283... logprob:  0.631612, 0.256510 (1.415 sec)
28.284... logprob:  0.552952, 0.226562 (1.405 sec)
28.285... logprob:  0.711672, 0.319010 (1.432 sec)
28.286... logprob:  0.745498, 0.328125 (1.432 sec)
28.287... logprob:  0.605670, 0.277344 (1.423 sec)
28.288... logprob:  0.605460, 0.256510 (1.431 sec)
28.289... logprob:  0.670662, 0.286458 (1.438 sec)
28.290... logprob:  0.791826, 0.351563 (1.407 sec)
28.291... logprob:  0.755597, 0.304688 (1.412 sec)
28.292... logprob:  0.854037, 0.351563 (1.430 sec)
28.293... logprob:  0.625509, 0.278646 (1.422 sec)
28.294... logprob:  0.585887, 0.270833 (1.392 sec)
28.295... logprob:  0.637605, 0.269531 (1.463 sec)
28.296... logprob:  0.592450, 0.270833 (1.418 sec)
28.297... logprob:  0.628132, 0.263021 (1.424 sec)
28.298... logprob:  0.606324, 0.247396 (1.455 sec)
28.299... logprob:  0.592728, 0.272135 (1.398 sec)
28.300... logprob:  0.712867, 0.307292 (1.415 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.515845, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.671608e-03 [1.336870e-07] 
Layer 'conv1' biases: 2.151805e-06 [5.987234e-11] 
Layer 'conv2' weights[0]: 2.666329e-03 [1.333922e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.194160e-10] 
Layer 'conv3' weights[0]: 2.665160e-03 [1.337164e-07] 
Layer 'conv3' biases: 3.559322e-05 [7.324963e-09] 
Layer 'conv4' weights[0]: 2.676425e-03 [1.344841e-07] 
Layer 'conv4' biases: 9.998773e-01 [2.066336e-07] 
Layer 'conv5' weights[0]: 2.836153e-03 [2.348151e-06] 
Layer 'conv5' biases: 9.990781e-01 [2.512429e-06] 
Layer 'fc6' weights[0]: 6.777729e-03 [6.010060e-08] 
Layer 'fc6' biases: 9.999894e-01 [5.351433e-08] 
Layer 'fc7' weights[0]: 7.122951e-03 [1.382961e-07] 
Layer 'fc7' biases: 9.997281e-01 [1.718405e-07] 
Layer 'fc8' weights[0]: 4.797574e-03 [1.231008e-05] 
Layer 'fc8' biases: 2.308235e-02 [2.183947e-05] 
Train error last 800 batches: 0.657523
-------------------------------------------------------
Not saving because 0.515845 > 0.299667 (9.300: -1.18%)
======================================================= (2.403 sec)
28.301... logprob:  0.693427, 0.299479 (1.415 sec)
28.302... logprob:  0.800959, 0.341146 (1.412 sec)
28.303... logprob:  0.629579, 0.285156 (1.405 sec)
28.304... logprob:  0.716139, 0.341146 (1.436 sec)
28.305... logprob:  0.667906, 0.276042 (1.431 sec)
28.306... logprob:  0.710386, 0.287760 (1.429 sec)
28.307... logprob:  0.575656, 0.248698 (1.436 sec)
28.308... logprob:  0.598108, 0.266927 (1.446 sec)
28.309... logprob:  0.600224, 0.274740 (1.413 sec)
28.310... logprob:  0.675646, 0.308594 (1.419 sec)
28.311... logprob:  0.792978, 0.346354 (1.420 sec)
28.312... logprob:  0.717392, 0.278646 (1.428 sec)
28.313... logprob:  0.784891, 0.352865 (1.420 sec)
28.314... logprob:  0.705801, 0.300781 (1.458 sec)
28.315... logprob:  0.577966, 0.264323 (1.425 sec)
28.316... logprob:  0.613243, 0.263021 (1.419 sec)
28.317... logprob:  0.610462, 0.287760 (1.470 sec)
28.318... logprob:  0.670495, 0.295573 (1.405 sec)
28.319... logprob:  0.659432, 0.281250 (1.418 sec)
28.320... logprob:  0.601655, 0.272135 (1.419 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.459634, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.668936e-03 [1.334839e-07] 
Layer 'conv1' biases: 2.151902e-06 [6.831917e-11] 
Layer 'conv2' weights[0]: 2.663671e-03 [1.332570e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.778249e-10] 
Layer 'conv3' weights[0]: 2.662503e-03 [1.334585e-07] 
Layer 'conv3' biases: 3.560633e-05 [6.509845e-09] 
Layer 'conv4' weights[0]: 2.673744e-03 [1.342154e-07] 
Layer 'conv4' biases: 9.998787e-01 [1.934299e-07] 
Layer 'conv5' weights[0]: 2.834497e-03 [2.104975e-06] 
Layer 'conv5' biases: 9.990921e-01 [2.191671e-06] 
Layer 'fc6' weights[0]: 6.777042e-03 [5.916364e-08] 
Layer 'fc6' biases: 9.999893e-01 [5.208530e-08] 
Layer 'fc7' weights[0]: 7.122234e-03 [1.349131e-07] 
Layer 'fc7' biases: 9.997270e-01 [1.589766e-07] 
Layer 'fc8' weights[0]: 4.758132e-03 [1.112229e-05] 
Layer 'fc8' biases: 2.272594e-02 [6.709016e-06] 
Train error last 800 batches: 0.657851
-------------------------------------------------------
Not saving because 0.459634 > 0.299667 (9.300: -1.18%)
======================================================= (2.371 sec)
28.321... logprob:  0.631735, 0.283854 (1.435 sec)
28.322... logprob:  0.657639, 0.279948 (1.420 sec)
28.323... logprob:  0.677320, 0.287760 (1.476 sec)
28.324... logprob:  0.718592, 0.316406 (1.418 sec)
28.325... logprob:  0.621912, 0.285156 (1.428 sec)
28.326... logprob:  0.780497, 0.312500 (1.458 sec)
28.327... logprob:  0.786868, 0.345052 (1.413 sec)
28.328... logprob:  0.736752, 0.330729 (1.417 sec)
28.329... logprob:  0.589803, 0.265625 (1.418 sec)
28.330... logprob:  0.606273, 0.289062 (1.412 sec)
28.331... logprob:  0.617827, 0.282552 (1.421 sec)
28.332... logprob:  0.644566, 0.276042 (1.446 sec)
28.333... logprob:  0.668733, 0.304687 (1.433 sec)
28.334... logprob:  0.755640, 0.316406 (1.439 sec)
28.335... logprob:  0.612460, 0.242187 (1.431 sec)
28.336... logprob:  0.697063, 0.283854 (1.453 sec)
28.337... logprob:  0.756687, 0.345052 (1.408 sec)
28.338... logprob:  0.657724, 0.294271 (1.421 sec)
28.339... logprob:  0.663890, 0.276042 (1.415 sec)
28.340... logprob:  0.659685, 0.298177 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.443207, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.666269e-03 [1.334497e-07] 
Layer 'conv1' biases: 2.152310e-06 [4.096294e-11] 
Layer 'conv2' weights[0]: 2.660998e-03 [1.331549e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.026972e-10] 
Layer 'conv3' weights[0]: 2.659846e-03 [1.332935e-07] 
Layer 'conv3' biases: 3.564192e-05 [5.943579e-09] 
Layer 'conv4' weights[0]: 2.671074e-03 [1.339097e-07] 
Layer 'conv4' biases: 9.998751e-01 [1.413181e-07] 
Layer 'conv5' weights[0]: 2.829498e-03 [2.135300e-06] 
Layer 'conv5' biases: 9.990894e-01 [2.334070e-06] 
Layer 'fc6' weights[0]: 6.776323e-03 [6.393984e-08] 
Layer 'fc6' biases: 9.999893e-01 [5.838561e-08] 
Layer 'fc7' weights[0]: 7.121460e-03 [1.512199e-07] 
Layer 'fc7' biases: 9.997277e-01 [2.058750e-07] 
Layer 'fc8' weights[0]: 4.764869e-03 [1.433438e-05] 
Layer 'fc8' biases: 2.279172e-02 [3.602858e-05] 
Train error last 800 batches: 0.658232
-------------------------------------------------------
Not saving because 0.443207 > 0.299667 (9.300: -1.18%)
======================================================= (2.382 sec)
28.341... logprob:  0.780671, 0.337240 (1.422 sec)
28.342... logprob:  0.647404, 0.269531 (1.462 sec)
28.343... logprob:  0.691754, 0.286458 (1.434 sec)
28.344... logprob:  0.623091, 0.298177 (1.476 sec)
28.345... logprob:  0.701539, 0.309896 (1.432 sec)
28.346... logprob:  0.760949, 0.317708 (1.430 sec)
28.347... logprob:  0.574237, 0.253906 (1.490 sec)
28.348... logprob:  0.677689, 0.296875 (1.431 sec)
28.349... logprob:  0.719054, 0.307292 (1.426 sec)
28.350... logprob:  0.562610, 0.248698 (1.431 sec)
28.351... logprob:  0.718147, 0.313802 (1.423 sec)
28.352... logprob:  0.584644, 0.261719 (1.426 sec)
28.353... logprob:  0.715050, 0.287760 (1.481 sec)
28.354... logprob:  0.806864, 0.352865 (1.424 sec)
28.355... logprob:  0.597732, 0.272135 (1.440 sec)
28.356... logprob:  0.704028, 0.307292 (1.468 sec)
28.357... logprob:  0.638929, 0.278646 (1.425 sec)
28.358... logprob:  0.550079, 0.252604 (1.433 sec)
28.359... logprob:  0.721207, 0.307292 (1.427 sec)
28.360... logprob:  0.670339, 0.295573 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.559401, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.663597e-03 [1.332319e-07] 
Layer 'conv1' biases: 2.152295e-06 [5.169474e-11] 
Layer 'conv2' weights[0]: 2.658341e-03 [1.329988e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.706759e-10] 
Layer 'conv3' weights[0]: 2.657179e-03 [1.331979e-07] 
Layer 'conv3' biases: 3.564353e-05 [6.045597e-09] 
Layer 'conv4' weights[0]: 2.668400e-03 [1.338566e-07] 
Layer 'conv4' biases: 9.998748e-01 [1.547626e-07] 
Layer 'conv5' weights[0]: 2.826913e-03 [2.046399e-06] 
Layer 'conv5' biases: 9.990894e-01 [2.088154e-06] 
Layer 'fc6' weights[0]: 6.775627e-03 [6.110358e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.496261e-08] 
Layer 'fc7' weights[0]: 7.120734e-03 [1.402865e-07] 
Layer 'fc7' biases: 9.997274e-01 [1.694215e-07] 
Layer 'fc8' weights[0]: 4.765581e-03 [1.171355e-05] 
Layer 'fc8' biases: 2.288378e-02 [1.265546e-05] 
Train error last 800 batches: 0.658748
-------------------------------------------------------
Not saving because 0.559401 > 0.299667 (9.300: -1.18%)
======================================================= (2.380 sec)
28.361... logprob:  0.649197, 0.273437 (1.433 sec)
28.362... logprob:  0.663685, 0.298177 (1.479 sec)
28.363... logprob:  0.662831, 0.298177 (1.439 sec)
28.364... logprob:  0.712435, 0.286458 (1.445 sec)
28.365... logprob:  0.592526, 0.260417 (1.461 sec)
28.366... logprob:  0.670248, 0.276042 (1.434 sec)
28.367... logprob:  0.521031, 0.229167 (1.435 sec)
28.368... logprob:  0.822642, 0.345052 (1.433 sec)
28.369... logprob:  0.542856, 0.234375 (1.456 sec)
28.370... logprob:  0.585949, 0.259115 (1.434 sec)
28.371... logprob:  0.655999, 0.281250 (1.451 sec)
28.372... logprob:  0.633231, 0.283854 (1.448 sec)
28.373... logprob:  0.733062, 0.337240 (1.448 sec)
28.374... logprob:  0.660991, 0.276042 (1.454 sec)
28.375... logprob:  0.665236, 0.305990 (1.454 sec)
28.376... logprob:  0.587136, 0.253906 (1.434 sec)
28.377... logprob:  0.547249, 0.255208 (1.425 sec)
28.378... logprob:  0.691200, 0.294271 (1.426 sec)
28.379... logprob:  0.711331, 0.302083 (1.427 sec)
28.380... logprob:  0.784715, 0.341146 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.389719, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.660933e-03 [1.330709e-07] 
Layer 'conv1' biases: 2.152066e-06 [4.630693e-11] 
Layer 'conv2' weights[0]: 2.655696e-03 [1.328261e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.108540e-10] 
Layer 'conv3' weights[0]: 2.654512e-03 [1.329987e-07] 
Layer 'conv3' biases: 3.565832e-05 [5.782665e-09] 
Layer 'conv4' weights[0]: 2.665739e-03 [1.336685e-07] 
Layer 'conv4' biases: 9.998744e-01 [1.660282e-07] 
Layer 'conv5' weights[0]: 2.824246e-03 [2.232565e-06] 
Layer 'conv5' biases: 9.990831e-01 [2.353293e-06] 
Layer 'fc6' weights[0]: 6.774917e-03 [5.975069e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.302305e-08] 
Layer 'fc7' weights[0]: 7.120031e-03 [1.376700e-07] 
Layer 'fc7' biases: 9.997278e-01 [1.600304e-07] 
Layer 'fc8' weights[0]: 4.773456e-03 [1.139951e-05] 
Layer 'fc8' biases: 2.298898e-02 [6.048205e-06] 
Train error last 800 batches: 0.657904
-------------------------------------------------------
Not saving because 0.389719 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
28.381... logprob:  0.625706, 0.281250 (1.470 sec)
28.382... logprob:  0.763232, 0.316406 (1.450 sec)
28.383... logprob:  0.592684, 0.243490 (1.437 sec)
28.384... logprob:  0.744610, 0.303385 (1.477 sec)
28.385... logprob:  0.719125, 0.337240 (1.426 sec)
28.386... logprob:  0.777004, 0.326823 (1.423 sec)
28.387... logprob:  0.649426, 0.292969 (1.433 sec)
28.388... logprob:  0.723702, 0.338542 (1.427 sec)
28.389... logprob:  0.639746, 0.286458 (1.431 sec)
28.390... logprob:  0.649968, 0.294271 (1.477 sec)
28.391... logprob:  0.538065, 0.229167 (1.446 sec)
28.392... logprob:  0.617303, 0.279948 (1.428 sec)
28.393... logprob:  0.583305, 0.290365 (1.478 sec)
28.394... logprob:  0.648987, 0.289062 (1.427 sec)
28.395... logprob:  0.579111, 0.274739 (1.424 sec)
28.396... logprob:  0.579421, 0.256510 (1.428 sec)
28.397... logprob:  0.675628, 0.312500 (1.427 sec)
28.398... logprob:  0.670120, 0.292969 (1.431 sec)
28.399... logprob:  0.759627, 0.330729 (1.482 sec)
28.400... logprob:  0.763815, 0.312500 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.529519, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.658283e-03 [1.329421e-07] 
Layer 'conv1' biases: 2.152299e-06 [4.304827e-11] 
Layer 'conv2' weights[0]: 2.653029e-03 [1.326898e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.623674e-10] 
Layer 'conv3' weights[0]: 2.651845e-03 [1.327786e-07] 
Layer 'conv3' biases: 3.567383e-05 [4.817880e-09] 
Layer 'conv4' weights[0]: 2.663075e-03 [1.334604e-07] 
Layer 'conv4' biases: 9.998742e-01 [1.261510e-07] 
Layer 'conv5' weights[0]: 2.821519e-03 [2.039004e-06] 
Layer 'conv5' biases: 9.990867e-01 [2.171009e-06] 
Layer 'fc6' weights[0]: 6.774222e-03 [6.096779e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.450108e-08] 
Layer 'fc7' weights[0]: 7.119325e-03 [1.395475e-07] 
Layer 'fc7' biases: 9.997272e-01 [1.618927e-07] 
Layer 'fc8' weights[0]: 4.775557e-03 [1.152209e-05] 
Layer 'fc8' biases: 2.299656e-02 [6.619648e-06] 
Train error last 800 batches: 0.657898
-------------------------------------------------------
Not saving because 0.529519 > 0.299667 (9.300: -1.18%)
======================================================= (2.368 sec)
28.401... logprob:  0.732343, 0.321615 (1.443 sec)
28.402... logprob:  0.750840, 0.321615 (1.482 sec)
28.403... logprob:  0.681223, 0.308594 (1.431 sec)
28.404... logprob:  0.668464, 0.302083 (1.430 sec)
28.405... logprob:  0.756487, 0.312500 (1.427 sec)
28.406... logprob:  0.531614, 0.233073 (1.424 sec)
28.407... logprob:  0.640887, 0.283854 (1.459 sec)
28.408... logprob:  0.636615, 0.273437 (1.485 sec)
28.409... logprob:  0.614681, 0.286458 (1.437 sec)
28.410... logprob:  0.758411, 0.325521 (1.441 sec)
28.411... logprob:  0.576978, 0.257812 (1.468 sec)
28.412... logprob:  0.710095, 0.316406 (1.428 sec)
28.413... logprob:  0.668982, 0.286458 (1.435 sec)
28.414... logprob:  0.737714, 0.313802 (1.431 sec)
28.415... logprob:  0.659016, 0.283854 (1.420 sec)
28.416... logprob:  0.638251, 0.291667 (1.439 sec)
28.417... logprob:  0.683029, 0.321615 (1.462 sec)
28.418... logprob:  0.589770, 0.261719 (1.449 sec)
28.419... logprob:  0.672957, 0.294271 (1.453 sec)
28.420... logprob:  0.524219, 0.239583 (1.445 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.392856, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.655619e-03 [1.328957e-07] 
Layer 'conv1' biases: 2.152643e-06 [6.532929e-11] 
Layer 'conv2' weights[0]: 2.650364e-03 [1.326412e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.584587e-10] 
Layer 'conv3' weights[0]: 2.649212e-03 [1.329151e-07] 
Layer 'conv3' biases: 3.566543e-05 [6.948487e-09] 
Layer 'conv4' weights[0]: 2.660404e-03 [1.337729e-07] 
Layer 'conv4' biases: 9.998746e-01 [1.904037e-07] 
Layer 'conv5' weights[0]: 2.819115e-03 [2.689390e-06] 
Layer 'conv5' biases: 9.991018e-01 [2.984223e-06] 
Layer 'fc6' weights[0]: 6.773519e-03 [6.419745e-08] 
Layer 'fc6' biases: 9.999893e-01 [5.844235e-08] 
Layer 'fc7' weights[0]: 7.118620e-03 [1.514957e-07] 
Layer 'fc7' biases: 9.997256e-01 [2.254632e-07] 
Layer 'fc8' weights[0]: 4.741536e-03 [1.422198e-05] 
Layer 'fc8' biases: 2.277805e-02 [3.793603e-05] 
Train error last 800 batches: 0.657537
-------------------------------------------------------
Not saving because 0.392856 > 0.299667 (9.300: -1.18%)
======================================================= (2.362 sec)
28.421... logprob:  0.535214, 0.260417 (1.460 sec)
28.422... logprob:  0.753284, 0.339844 (1.441 sec)
28.423... logprob:  0.729449, 0.350260 (1.425 sec)
28.424... logprob:  0.582372, 0.269531 (1.424 sec)
28.425... logprob:  0.574555, 0.244792 (1.430 sec)
28.426... logprob:  0.633826, 0.291667 (1.440 sec)
28.427... logprob:  0.732748, 0.312500 (1.455 sec)
28.428... logprob:  0.788431, 0.316406 (1.448 sec)
28.429... logprob:  0.681826, 0.303385 (1.438 sec)
28.430... logprob:  0.549457, 0.256510 (1.469 sec)
28.431... logprob:  0.771250, 0.337240 (1.426 sec)
28.432... logprob:  0.636810, 0.281250 (1.421 sec)
28.433... logprob:  0.603303, 0.311198 (1.432 sec)
28.434... logprob:  0.699800, 0.325521 (1.434 sec)
28.435... logprob:  0.776879, 0.345052 (1.433 sec)
28.436... logprob:  0.586036, 0.251302 (1.469 sec)
28.437... logprob:  0.717117, 0.311198 (1.438 sec)
28.438... logprob:  0.751438, 0.321615 (1.424 sec)
28.439... logprob:  0.538126, 0.236979 (1.482 sec)
28.440... logprob:  0.623205, 0.291667 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.408976, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.652964e-03 [1.327059e-07] 
Layer 'conv1' biases: 2.152700e-06 [4.686392e-11] 
Layer 'conv2' weights[0]: 2.647732e-03 [1.324481e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.312855e-10] 
Layer 'conv3' weights[0]: 2.646546e-03 [1.325441e-07] 
Layer 'conv3' biases: 3.565265e-05 [4.734702e-09] 
Layer 'conv4' weights[0]: 2.657746e-03 [1.332914e-07] 
Layer 'conv4' biases: 9.998738e-01 [1.484369e-07] 
Layer 'conv5' weights[0]: 2.816277e-03 [1.987130e-06] 
Layer 'conv5' biases: 9.990872e-01 [2.046453e-06] 
Layer 'fc6' weights[0]: 6.772879e-03 [5.877298e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.185921e-08] 
Layer 'fc7' weights[0]: 7.117892e-03 [1.321255e-07] 
Layer 'fc7' biases: 9.997276e-01 [1.537959e-07] 
Layer 'fc8' weights[0]: 4.787894e-03 [1.059306e-05] 
Layer 'fc8' biases: 2.320310e-02 [6.128903e-06] 
Train error last 800 batches: 0.657638
-------------------------------------------------------
Not saving because 0.408976 > 0.299667 (9.300: -1.18%)
======================================================= (2.354 sec)
28.441... logprob:  0.643422, 0.268229 (1.431 sec)
28.442... logprob:  0.622014, 0.278646 (1.437 sec)
28.443... logprob:  0.632210, 0.257812 (1.428 sec)
28.444... logprob:  0.601847, 0.279948 (1.432 sec)
28.445... logprob:  0.610183, 0.289062 (1.507 sec)
28.446... logprob:  0.659939, 0.294271 (1.431 sec)
28.447... logprob:  0.804692, 0.367188 (1.431 sec)
28.448... logprob:  0.539080, 0.265625 (1.476 sec)
28.449... logprob:  0.567040, 0.240885 (1.428 sec)
28.450... logprob:  0.486998, 0.195312 (1.433 sec)
28.451... logprob:  0.715438, 0.312500 (1.431 sec)
28.452... logprob:  0.725980, 0.325521 (1.424 sec)
28.453... logprob:  0.643495, 0.269531 (1.432 sec)
28.454... logprob:  0.750176, 0.328125 (1.477 sec)
28.455... logprob:  0.694276, 0.299479 (1.427 sec)
28.456... logprob:  0.765386, 0.347656 (1.452 sec)
28.457... logprob:  0.630056, 0.264323 (1.479 sec)
28.458... logprob:  0.660690, 0.300781 (1.432 sec)
28.459... logprob:  0.695427, 0.315104 (1.434 sec)
28.460... logprob:  0.550938, 0.256510 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.439017, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.650317e-03 [1.325489e-07] 
Layer 'conv1' biases: 2.153030e-06 [4.069644e-11] 
Layer 'conv2' weights[0]: 2.645085e-03 [1.323188e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.072474e-10] 
Layer 'conv3' weights[0]: 2.643907e-03 [1.324560e-07] 
Layer 'conv3' biases: 3.566401e-05 [5.636313e-09] 
Layer 'conv4' weights[0]: 2.655088e-03 [1.330780e-07] 
Layer 'conv4' biases: 9.998727e-01 [1.518925e-07] 
Layer 'conv5' weights[0]: 2.813156e-03 [2.301343e-06] 
Layer 'conv5' biases: 9.990851e-01 [2.491818e-06] 
Layer 'fc6' weights[0]: 6.772170e-03 [6.062399e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.460458e-08] 
Layer 'fc7' weights[0]: 7.117206e-03 [1.389845e-07] 
Layer 'fc7' biases: 9.997280e-01 [1.799010e-07] 
Layer 'fc8' weights[0]: 4.800693e-03 [1.249975e-05] 
Layer 'fc8' biases: 2.330747e-02 [2.663435e-05] 
Train error last 800 batches: 0.658004
-------------------------------------------------------
Not saving because 0.439017 > 0.299667 (9.300: -1.18%)
======================================================= (2.382 sec)
28.461... logprob:  0.661409, 0.305990 (1.428 sec)
28.462... logprob:  0.640776, 0.276042 (1.436 sec)
28.463... logprob:  0.592645, 0.244792 (1.461 sec)
28.464... logprob:  0.694293, 0.304687 (1.439 sec)
28.465... logprob:  0.609798, 0.277344 (1.450 sec)
28.466... logprob:  0.599822, 0.273437 (1.455 sec)
28.467... logprob:  0.655307, 0.307292 (1.445 sec)
28.468... logprob:  0.639590, 0.272135 (1.437 sec)
28.469... logprob:  0.585154, 0.259114 (1.422 sec)
28.470... logprob:  0.674025, 0.287760 (1.419 sec)
28.471... logprob:  0.755844, 0.325521 (1.431 sec)
28.472... logprob:  0.676043, 0.287760 (1.448 sec)
28.473... logprob:  0.600550, 0.251302 (1.450 sec)
28.474... logprob:  0.642784, 0.283854 (1.448 sec)
28.475... logprob:  0.775567, 0.319010 (1.443 sec)
28.476... logprob:  0.779537, 0.326823 (1.468 sec)
28.477... logprob:  0.545727, 0.252604 (1.430 sec)
28.478... logprob:  0.630404, 0.285156 (1.416 sec)
28.479... logprob:  0.530395, 0.266927 (1.429 sec)
28.480... logprob:  0.529851, 0.244792 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.513640, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.647665e-03 [1.324319e-07] 
Layer 'conv1' biases: 2.153138e-06 [7.116544e-11] 
Layer 'conv2' weights[0]: 2.642437e-03 [1.322264e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.395126e-10] 
Layer 'conv3' weights[0]: 2.641303e-03 [1.325722e-07] 
Layer 'conv3' biases: 3.566264e-05 [7.702267e-09] 
Layer 'conv4' weights[0]: 2.652439e-03 [1.335020e-07] 
Layer 'conv4' biases: 9.998730e-01 [2.393779e-07] 
Layer 'conv5' weights[0]: 2.810662e-03 [2.325884e-06] 
Layer 'conv5' biases: 9.990801e-01 [2.400201e-06] 
Layer 'fc6' weights[0]: 6.771477e-03 [6.004152e-08] 
Layer 'fc6' biases: 9.999890e-01 [5.359485e-08] 
Layer 'fc7' weights[0]: 7.116464e-03 [1.393873e-07] 
Layer 'fc7' biases: 9.997281e-01 [1.919186e-07] 
Layer 'fc8' weights[0]: 4.805520e-03 [1.280647e-05] 
Layer 'fc8' biases: 2.335061e-02 [2.680627e-05] 
Train error last 800 batches: 0.657917
-------------------------------------------------------
Not saving because 0.513640 > 0.299667 (9.300: -1.18%)
======================================================= (2.393 sec)
28.481... logprob:  0.665664, 0.290365 (1.441 sec)
28.482... logprob:  0.598906, 0.272135 (1.476 sec)
28.483... logprob:  0.692511, 0.296875 (1.482 sec)
28.484... logprob:  0.592933, 0.251302 (1.429 sec)
28.485... logprob:  0.642842, 0.295573 (1.476 sec)
28.486... logprob:  0.617284, 0.259115 (1.428 sec)
28.487... logprob:  0.851629, 0.342448 (1.423 sec)
28.488... logprob:  0.661288, 0.309896 (1.436 sec)
28.489... logprob:  0.618901, 0.266927 (1.427 sec)
28.490... logprob:  0.622923, 0.261719 (1.427 sec)
28.491... logprob:  0.573767, 0.259115 (1.474 sec)
28.492... logprob:  0.662064, 0.302083 (1.434 sec)
28.493... logprob:  0.665939, 0.278646 (1.428 sec)
28.494... logprob:  0.690400, 0.299479 (1.478 sec)
28.495... logprob:  0.530927, 0.242187 (1.427 sec)
28.496... logprob:  0.719861, 0.329427 (1.426 sec)
28.497... logprob:  0.656680, 0.278646 (1.428 sec)
28.498... logprob:  0.618416, 0.268229 (1.423 sec)
28.499... logprob:  0.660450, 0.305990 (1.427 sec)
28.500... logprob:  0.632871, 0.272135 (1.482 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.407248, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.645022e-03 [1.323009e-07] 
Layer 'conv1' biases: 2.153340e-06 [5.686483e-11] 
Layer 'conv2' weights[0]: 2.639781e-03 [1.320675e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.432485e-10] 
Layer 'conv3' weights[0]: 2.638658e-03 [1.321402e-07] 
Layer 'conv3' biases: 3.566482e-05 [4.938870e-09] 
Layer 'conv4' weights[0]: 2.649778e-03 [1.328135e-07] 
Layer 'conv4' biases: 9.998720e-01 [1.380371e-07] 
Layer 'conv5' weights[0]: 2.807379e-03 [1.995799e-06] 
Layer 'conv5' biases: 9.990782e-01 [2.077111e-06] 
Layer 'fc6' weights[0]: 6.770745e-03 [5.931246e-08] 
Layer 'fc6' biases: 9.999893e-01 [5.280614e-08] 
Layer 'fc7' weights[0]: 7.115746e-03 [1.383385e-07] 
Layer 'fc7' biases: 9.997277e-01 [1.719612e-07] 
Layer 'fc8' weights[0]: 4.793242e-03 [1.210564e-05] 
Layer 'fc8' biases: 2.325997e-02 [2.139748e-05] 
Train error last 800 batches: 0.657435
-------------------------------------------------------
Not saving because 0.407248 > 0.299667 (9.300: -1.18%)
======================================================= (2.384 sec)
28.501... logprob:  0.608203, 0.278646 (1.435 sec)
28.502... logprob:  0.645764, 0.295573 (1.444 sec)
28.503... logprob:  0.619927, 0.255208 (1.481 sec)
28.504... logprob:  0.640062, 0.270833 (1.432 sec)
28.505... logprob:  0.696094, 0.326823 (1.436 sec)
28.506... logprob:  0.774223, 0.315104 (1.430 sec)
28.507... logprob:  0.601314, 0.248698 (1.424 sec)
28.508... logprob:  0.595596, 0.261719 (1.434 sec)
28.509... logprob:  0.601420, 0.279948 (1.468 sec)
28.510... logprob:  0.713284, 0.294271 (1.439 sec)
28.511... logprob:  0.649250, 0.264323 (1.446 sec)
28.512... logprob:  0.769135, 0.322917 (1.455 sec)
28.513... logprob:  0.641708, 0.274740 (1.439 sec)
28.514... logprob:  0.643472, 0.304687 (1.433 sec)
28.515... logprob:  0.604925, 0.278646 (1.423 sec)
28.516... logprob:  0.588961, 0.265625 (1.418 sec)
28.517... logprob:  0.734301, 0.292969 (1.434 sec)
28.518... logprob:  0.662548, 0.305990 (1.454 sec)
28.519... logprob:  0.690419, 0.296875 (1.451 sec)
28.520... logprob:  0.663351, 0.291667 (1.446 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.508241, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.642374e-03 [1.321201e-07] 
Layer 'conv1' biases: 2.153591e-06 [5.961240e-11] 
Layer 'conv2' weights[0]: 2.637151e-03 [1.318866e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.148603e-10] 
Layer 'conv3' weights[0]: 2.635996e-03 [1.320001e-07] 
Layer 'conv3' biases: 3.565699e-05 [4.949235e-09] 
Layer 'conv4' weights[0]: 2.647141e-03 [1.326747e-07] 
Layer 'conv4' biases: 9.998736e-01 [1.477385e-07] 
Layer 'conv5' weights[0]: 2.806199e-03 [2.506629e-06] 
Layer 'conv5' biases: 9.990925e-01 [2.654003e-06] 
Layer 'fc6' weights[0]: 6.770041e-03 [6.151071e-08] 
Layer 'fc6' biases: 9.999893e-01 [5.544561e-08] 
Layer 'fc7' weights[0]: 7.115006e-03 [1.397660e-07] 
Layer 'fc7' biases: 9.997262e-01 [1.680435e-07] 
Layer 'fc8' weights[0]: 4.753458e-03 [1.153750e-05] 
Layer 'fc8' biases: 2.294905e-02 [1.276943e-05] 
Train error last 800 batches: 0.657496
-------------------------------------------------------
Not saving because 0.508241 > 0.299667 (9.300: -1.18%)
======================================================= (2.391 sec)
28.521... logprob:  0.667169, 0.338542 (1.474 sec)
28.522... logprob:  0.720638, 0.321615 (1.463 sec)
28.523... logprob:  0.590871, 0.265625 (1.428 sec)
28.524... logprob:  0.638964, 0.294271 (1.421 sec)
28.525... logprob:  0.608905, 0.252604 (1.427 sec)
28.526... logprob:  0.538761, 0.247396 (1.440 sec)
28.527... logprob:  0.829333, 0.333333 (1.441 sec)
28.528... logprob:  0.696481, 0.299479 (1.466 sec)
28.529... logprob:  0.579831, 0.277344 (1.446 sec)
28.530... logprob:  0.660954, 0.300781 (1.433 sec)
28.531... logprob:  0.573869, 0.243490 (1.472 sec)
28.532... logprob:  0.667840, 0.268229 (1.429 sec)
28.533... logprob:  0.738162, 0.319010 (1.419 sec)
28.534... logprob:  0.551553, 0.242187 (1.427 sec)
28.535... logprob:  0.700427, 0.292969 (1.433 sec)
28.536... logprob:  0.748453, 0.319010 (1.424 sec)
28.537... logprob:  0.774623, 0.324219 (1.479 sec)
28.538... logprob:  0.712076, 0.316406 (1.437 sec)
28.539... logprob:  0.580349, 0.270833 (1.428 sec)
28.540... logprob:  0.654679, 0.312500 (1.478 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.570826, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.639746e-03 [1.320305e-07] 
Layer 'conv1' biases: 2.154252e-06 [6.005802e-11] 
Layer 'conv2' weights[0]: 2.634525e-03 [1.317934e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.246291e-10] 
Layer 'conv3' weights[0]: 2.633354e-03 [1.319351e-07] 
Layer 'conv3' biases: 3.567724e-05 [5.931319e-09] 
Layer 'conv4' weights[0]: 2.644494e-03 [1.325683e-07] 
Layer 'conv4' biases: 9.998717e-01 [1.627680e-07] 
Layer 'conv5' weights[0]: 2.802530e-03 [2.364449e-06] 
Layer 'conv5' biases: 9.990863e-01 [2.534026e-06] 
Layer 'fc6' weights[0]: 6.769362e-03 [6.228988e-08] 
Layer 'fc6' biases: 9.999893e-01 [5.647833e-08] 
Layer 'fc7' weights[0]: 7.114273e-03 [1.424965e-07] 
Layer 'fc7' biases: 9.997259e-01 [1.841038e-07] 
Layer 'fc8' weights[0]: 4.764470e-03 [1.244479e-05] 
Layer 'fc8' biases: 2.302037e-02 [2.366518e-05] 
Train error last 800 batches: 0.657767
-------------------------------------------------------
Not saving because 0.570826 > 0.299667 (9.300: -1.18%)
======================================================= (2.392 sec)
28.541... logprob:  0.647271, 0.260417 (1.439 sec)
28.542... logprob:  0.623243, 0.281250 (1.432 sec)
28.543... logprob:  0.476664, 0.222656 (1.440 sec)
28.544... logprob:  0.597693, 0.256510 (1.430 sec)
28.545... logprob:  0.564772, 0.248698 (1.431 sec)
28.546... logprob:  0.610488, 0.265625 (1.478 sec)
28.547... logprob:  0.714892, 0.313802 (1.430 sec)
28.548... logprob:  0.732643, 0.312500 (1.434 sec)
28.549... logprob:  0.678088, 0.305989 (1.475 sec)
28.550... logprob:  0.646508, 0.294271 (1.426 sec)
28.551... logprob:  0.639843, 0.277344 (1.426 sec)
28.552... logprob:  0.624588, 0.281250 (1.428 sec)
28.553... logprob:  0.510124, 0.225260 (1.423 sec)
28.554... logprob:  0.632459, 0.272135 (1.431 sec)
28.555... logprob:  0.627332, 0.282552 (1.481 sec)
28.556... logprob:  0.536976, 0.235677 (1.431 sec)
28.557... logprob:  0.636596, 0.287760 (1.443 sec)
28.558... logprob:  0.632953, 0.302083 (1.465 sec)
28.559... logprob:  0.651962, 0.279948 (1.429 sec)
28.560... logprob:  0.661686, 0.286458 (1.434 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.431997, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.637095e-03 [1.320117e-07] 
Layer 'conv1' biases: 2.154390e-06 [5.360939e-11] 
Layer 'conv2' weights[0]: 2.631882e-03 [1.316944e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.936834e-10] 
Layer 'conv3' weights[0]: 2.630735e-03 [1.317694e-07] 
Layer 'conv3' biases: 3.567078e-05 [5.132573e-09] 
Layer 'conv4' weights[0]: 2.641839e-03 [1.325631e-07] 
Layer 'conv4' biases: 9.998706e-01 [1.526048e-07] 
Layer 'conv5' weights[0]: 2.799377e-03 [2.467243e-06] 
Layer 'conv5' biases: 9.990526e-01 [2.685032e-06] 
Layer 'fc6' weights[0]: 6.768681e-03 [6.423247e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.957427e-08] 
Layer 'fc7' weights[0]: 7.113544e-03 [1.531551e-07] 
Layer 'fc7' biases: 9.997286e-01 [2.278033e-07] 
Layer 'fc8' weights[0]: 4.834750e-03 [1.499536e-05] 
Layer 'fc8' biases: 2.358570e-02 [4.128102e-05] 
Train error last 800 batches: 0.657809
-------------------------------------------------------
Not saving because 0.431997 > 0.299667 (9.300: -1.18%)
======================================================= (2.382 sec)
28.561... logprob:  0.645061, 0.281250 (1.436 sec)
28.562... logprob:  0.728785, 0.334635 (1.429 sec)
28.563... logprob:  0.670232, 0.307292 (1.436 sec)
28.564... logprob:  0.697231, 0.299479 (1.458 sec)
28.565... logprob:  0.765787, 0.346354 (1.445 sec)
28.566... logprob:  0.694803, 0.328125 (1.447 sec)
28.567... logprob:  0.624507, 0.239583 (1.459 sec)
28.568... logprob:  0.674553, 0.285156 (1.446 sec)
28.569... logprob:  0.681531, 0.312500 (1.434 sec)
28.570... logprob:  0.751958, 0.338542 (1.419 sec)
28.571... logprob:  0.768757, 0.300781 (1.427 sec)
28.572... logprob:  0.692470, 0.296875 (1.439 sec)
28.573... logprob:  0.703365, 0.287760 (1.447 sec)
28.574... logprob:  0.685394, 0.313802 (1.455 sec)
28.575... logprob:  0.638448, 0.282552 (1.445 sec)
28.576... logprob:  0.658075, 0.261719 (1.438 sec)
28.577... logprob:  0.599349, 0.252604 (1.469 sec)
28.578... logprob:  0.654528, 0.302083 (1.429 sec)
28.579... logprob:  0.680879, 0.286458 (1.426 sec)
28.580... logprob:  0.716441, 0.320312 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.333200, 0.039062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.634467e-03 [1.317206e-07] 
Layer 'conv1' biases: 2.154613e-06 [4.319107e-11] 
Layer 'conv2' weights[0]: 2.629266e-03 [1.314824e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.326661e-10] 
Layer 'conv3' weights[0]: 2.628089e-03 [1.316406e-07] 
Layer 'conv3' biases: 3.569500e-05 [5.723869e-09] 
Layer 'conv4' weights[0]: 2.639203e-03 [1.323261e-07] 
Layer 'conv4' biases: 9.998718e-01 [1.740786e-07] 
Layer 'conv5' weights[0]: 2.798340e-03 [2.482954e-06] 
Layer 'conv5' biases: 9.990870e-01 [2.642958e-06] 
Layer 'fc6' weights[0]: 6.767999e-03 [6.509706e-08] 
Layer 'fc6' biases: 9.999893e-01 [6.048890e-08] 
Layer 'fc7' weights[0]: 7.112895e-03 [1.514934e-07] 
Layer 'fc7' biases: 9.997261e-01 [2.094566e-07] 
Layer 'fc8' weights[0]: 4.770818e-03 [1.356609e-05] 
Layer 'fc8' biases: 2.300132e-02 [2.365472e-05] 
Train error last 800 batches: 0.657993
-------------------------------------------------------
Not saving because 0.333200 > 0.299667 (9.300: -1.18%)
======================================================= (2.370 sec)
28.581... logprob:  0.839899, 0.361979 (1.437 sec)
28.582... logprob:  0.733178, 0.311198 (1.435 sec)
28.583... logprob:  0.788337, 0.368490 (1.474 sec)
28.584... logprob:  0.662936, 0.270833 (1.439 sec)
28.585... logprob:  0.506624, 0.230469 (1.427 sec)
28.586... logprob:  0.567648, 0.263021 (1.482 sec)
28.587... logprob:  0.610340, 0.283854 (1.423 sec)
28.588... logprob:  0.670514, 0.274740 (1.426 sec)
28.589... logprob:  0.552644, 0.251302 (1.430 sec)
28.590... logprob:  0.771143, 0.328125 (1.427 sec)
28.591... logprob:  0.665224, 0.322917 (1.433 sec)
28.592... logprob:  0.605507, 0.277344 (1.473 sec)
28.593... logprob:  0.648676, 0.272135 (1.433 sec)
28.594... logprob:  0.579377, 0.251302 (1.430 sec)
28.595... logprob:  0.666177, 0.300781 (1.573 sec)
28.596... logprob:  0.675215, 0.304687 (1.431 sec)
28.597... logprob:  0.666300, 0.276042 (1.423 sec)
28.598... logprob:  0.616995, 0.261719 (1.434 sec)
28.599... logprob:  0.549519, 0.248698 (1.429 sec)
28.600... logprob:  0.589224, 0.252604 (1.425 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.464975, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.631835e-03 [1.317003e-07] 
Layer 'conv1' biases: 2.154849e-06 [9.305884e-11] 
Layer 'conv2' weights[0]: 2.626617e-03 [1.314717e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.424686e-09] 
Layer 'conv3' weights[0]: 2.625481e-03 [1.325389e-07] 
Layer 'conv3' biases: 3.568584e-05 [1.262742e-08] 
Layer 'conv4' weights[0]: 2.636566e-03 [1.336754e-07] 
Layer 'conv4' biases: 9.998718e-01 [3.578219e-07] 
Layer 'conv5' weights[0]: 2.796376e-03 [3.766856e-06] 
Layer 'conv5' biases: 9.990769e-01 [4.046896e-06] 
Layer 'fc6' weights[0]: 6.767310e-03 [8.028147e-08] 
Layer 'fc6' biases: 9.999893e-01 [8.000804e-08] 
Layer 'fc7' weights[0]: 7.112147e-03 [2.031991e-07] 
Layer 'fc7' biases: 9.997261e-01 [3.711149e-07] 
Layer 'fc8' weights[0]: 4.792315e-03 [2.207043e-05] 
Layer 'fc8' biases: 2.324788e-02 [7.395500e-05] 
Train error last 800 batches: 0.658069
-------------------------------------------------------
Not saving because 0.464975 > 0.299667 (9.300: -1.18%)
======================================================= (2.337 sec)
28.601... logprob:  0.591145, 0.257812 (1.486 sec)
28.602... logprob:  0.562312, 0.256510 (1.428 sec)
28.603... logprob:  0.545853, 0.260417 (1.442 sec)
28.604... logprob:  0.663843, 0.290365 (1.473 sec)
28.605... logprob:  0.755517, 0.308594 (1.430 sec)
28.606... logprob:  0.519617, 0.239583 (1.432 sec)
28.607... logprob:  0.691866, 0.296875 (1.426 sec)
28.608... logprob:  0.636058, 0.296875 (1.428 sec)
28.609... logprob:  0.568362, 0.247396 (1.435 sec)
28.610... logprob:  0.758071, 0.337240 (1.469 sec)
28.611... logprob:  0.753188, 0.312500 (1.443 sec)
28.612... logprob:  0.728417, 0.294271 (1.448 sec)
28.613... logprob:  0.522675, 0.260417 (1.456 sec)
28.614... logprob:  0.783791, 0.303385 (1.442 sec)
28.615... logprob:  0.564959, 0.264323 (1.433 sec)
28.616... logprob:  0.572354, 0.253906 (1.429 sec)
28.617... logprob:  0.656807, 0.287760 (1.425 sec)
28.618... logprob:  0.857871, 0.302083 (1.434 sec)
28.619... logprob:  0.731724, 0.308594 (1.444 sec)
28.620... logprob:  0.725296, 0.319010 (1.455 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.496800, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.629202e-03 [1.315123e-07] 
Layer 'conv1' biases: 2.154916e-06 [1.094415e-10] 
Layer 'conv2' weights[0]: 2.624002e-03 [1.312553e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.547156e-09] 
Layer 'conv3' weights[0]: 2.622854e-03 [1.324030e-07] 
Layer 'conv3' biases: 3.567028e-05 [1.372773e-08] 
Layer 'conv4' weights[0]: 2.633936e-03 [1.334439e-07] 
Layer 'conv4' biases: 9.998716e-01 [4.098247e-07] 
Layer 'conv5' weights[0]: 2.794043e-03 [4.756167e-06] 
Layer 'conv5' biases: 9.990658e-01 [5.286429e-06] 
Layer 'fc6' weights[0]: 6.766632e-03 [9.070277e-08] 
Layer 'fc6' biases: 9.999894e-01 [9.632198e-08] 
Layer 'fc7' weights[0]: 7.111426e-03 [2.339845e-07] 
Layer 'fc7' biases: 9.997260e-01 [4.455695e-07] 
Layer 'fc8' weights[0]: 4.824412e-03 [2.285637e-05] 
Layer 'fc8' biases: 2.363583e-02 [6.780599e-05] 
Train error last 800 batches: 0.658207
-------------------------------------------------------
Not saving because 0.496800 > 0.299667 (9.300: -1.18%)
======================================================= (2.341 sec)
28.621... logprob:  0.589948, 0.240885 (1.455 sec)
28.622... logprob:  0.522833, 0.244792 (1.443 sec)
28.623... logprob:  0.625297, 0.286458 (1.470 sec)
28.624... logprob:  0.544930, 0.268229 (1.436 sec)
28.625... logprob:  0.651556, 0.298177 (1.421 sec)
28.626... logprob:  0.639157, 0.295573 (1.432 sec)
28.627... logprob:  0.550709, 0.243490 (1.429 sec)
28.628... logprob:  0.613407, 0.289062 (1.428 sec)
28.629... logprob:  0.578139, 0.252604 (1.476 sec)
28.630... logprob:  0.708879, 0.316406 (1.444 sec)
28.631... logprob:  0.794554, 0.341146 (1.429 sec)
28.632... logprob:  0.609168, 0.283854 (1.476 sec)
28.633... logprob:  0.596890, 0.272135 (1.430 sec)
28.634... logprob:  0.821338, 0.329427 (1.426 sec)
28.635... logprob:  0.542239, 0.269531 (1.432 sec)
28.636... logprob:  0.640406, 0.290365 (1.434 sec)
28.637... logprob:  0.641858, 0.269531 (1.466 sec)
28.638... logprob:  0.829823, 0.356771 (1.476 sec)
28.639... logprob:  0.612862, 0.266927 (1.438 sec)
28.640... logprob:  0.757058, 0.339844 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.441769, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.626561e-03 [1.314198e-07] 
Layer 'conv1' biases: 2.155154e-06 [7.556387e-11] 
Layer 'conv2' weights[0]: 2.621384e-03 [1.311220e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.593630e-10] 
Layer 'conv3' weights[0]: 2.620223e-03 [1.315036e-07] 
Layer 'conv3' biases: 3.570100e-05 [8.558390e-09] 
Layer 'conv4' weights[0]: 2.631297e-03 [1.320938e-07] 
Layer 'conv4' biases: 9.998716e-01 [2.311141e-07] 
Layer 'conv5' weights[0]: 2.791844e-03 [2.785849e-06] 
Layer 'conv5' biases: 9.990800e-01 [2.948443e-06] 
Layer 'fc6' weights[0]: 6.765968e-03 [6.529385e-08] 
Layer 'fc6' biases: 9.999896e-01 [6.053061e-08] 
Layer 'fc7' weights[0]: 7.110711e-03 [1.536991e-07] 
Layer 'fc7' biases: 9.997250e-01 [2.225896e-07] 
Layer 'fc8' weights[0]: 4.788145e-03 [1.314732e-05] 
Layer 'fc8' biases: 2.338026e-02 [2.921576e-05] 
Train error last 800 batches: 0.657677
-------------------------------------------------------
Not saving because 0.441769 > 0.299667 (9.300: -1.18%)
======================================================= (2.359 sec)
28.641... logprob:  0.670782, 0.305990 (1.488 sec)
28.642... logprob:  0.650259, 0.282552 (1.443 sec)
28.643... logprob:  0.796740, 0.325521 (1.431 sec)
28.644... logprob:  0.568404, 0.259115 (1.426 sec)
28.645... logprob:  0.596853, 0.260417 (1.427 sec)
28.646... logprob:  0.627079, 0.289062 (1.427 sec)
28.647... logprob:  0.667381, 0.287760 (1.477 sec)
28.648... logprob:  0.641595, 0.268229 (1.424 sec)
28.649... logprob:  0.546604, 0.256510 (1.443 sec)
28.650... logprob:  0.693610, 0.321615 (1.473 sec)
28.651... logprob:  0.619433, 0.272135 (1.428 sec)
28.652... logprob:  0.777003, 0.351562 (1.437 sec)
28.653... logprob:  0.699573, 0.309896 (1.432 sec)
28.654... logprob:  0.664166, 0.285156 (1.422 sec)
28.655... logprob:  0.630622, 0.285156 (1.425 sec)
28.656... logprob:  0.588656, 0.248698 (1.476 sec)
28.657... logprob:  0.614003, 0.278646 (1.441 sec)
28.658... logprob:  0.634059, 0.276042 (1.444 sec)
28.659... logprob:  0.617455, 0.273437 (1.469 sec)
28.660... logprob:  0.625458, 0.269531 (1.436 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.443944, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.623946e-03 [1.312353e-07] 
Layer 'conv1' biases: 2.155292e-06 [4.320696e-11] 
Layer 'conv2' weights[0]: 2.618766e-03 [1.310016e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.785500e-10] 
Layer 'conv3' weights[0]: 2.617595e-03 [1.311017e-07] 
Layer 'conv3' biases: 3.572945e-05 [5.291072e-09] 
Layer 'conv4' weights[0]: 2.628650e-03 [1.318085e-07] 
Layer 'conv4' biases: 9.998715e-01 [1.802506e-07] 
Layer 'conv5' weights[0]: 2.789414e-03 [2.253872e-06] 
Layer 'conv5' biases: 9.990843e-01 [2.452497e-06] 
Layer 'fc6' weights[0]: 6.765268e-03 [6.401854e-08] 
Layer 'fc6' biases: 9.999896e-01 [5.882926e-08] 
Layer 'fc7' weights[0]: 7.109985e-03 [1.517224e-07] 
Layer 'fc7' biases: 9.997247e-01 [2.226548e-07] 
Layer 'fc8' weights[0]: 4.785746e-03 [1.481848e-05] 
Layer 'fc8' biases: 2.339085e-02 [4.129398e-05] 
Train error last 800 batches: 0.657346
-------------------------------------------------------
Not saving because 0.443944 > 0.299667 (9.300: -1.18%)
======================================================= (2.383 sec)
28.661... logprob:  0.602041, 0.281250 (1.441 sec)
28.662... logprob:  0.728986, 0.316406 (1.434 sec)
28.663... logprob:  0.571105, 0.261719 (1.422 sec)
28.664... logprob:  0.566431, 0.243490 (1.432 sec)
28.665... logprob:  0.593543, 0.264323 (1.454 sec)
28.666... logprob:  0.615789, 0.239583 (1.449 sec)
28.667... logprob:  0.682846, 0.292969 (1.447 sec)
28.668... logprob:  0.730252, 0.337239 (1.454 sec)
28.669... logprob:  0.604029, 0.250000 (1.451 sec)
28.670... logprob:  0.545812, 0.282552 (1.433 sec)
28.671... logprob:  0.589904, 0.272135 (1.420 sec)
28.672... logprob:  0.647463, 0.298177 (1.426 sec)
28.673... logprob:  0.665139, 0.317708 (1.432 sec)
28.674... logprob:  0.583110, 0.259115 (1.434 sec)
28.675... logprob:  0.520464, 0.238281 (1.493 sec)
28.676... logprob:  0.722760, 0.333333 (1.445 sec)
28.677... logprob:  0.603917, 0.269531 (1.429 sec)
28.678... logprob:  0.621408, 0.278646 (1.478 sec)
28.679... logprob:  0.651123, 0.302083 (1.420 sec)
28.680... logprob:  0.532893, 0.239583 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.495383, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.621323e-03 [1.310966e-07] 
Layer 'conv1' biases: 2.155649e-06 [5.007730e-11] 
Layer 'conv2' weights[0]: 2.616130e-03 [1.308740e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.650080e-10] 
Layer 'conv3' weights[0]: 2.614982e-03 [1.309767e-07] 
Layer 'conv3' biases: 3.572148e-05 [5.676931e-09] 
Layer 'conv4' weights[0]: 2.626014e-03 [1.317764e-07] 
Layer 'conv4' biases: 9.998720e-01 [1.932894e-07] 
Layer 'conv5' weights[0]: 2.787016e-03 [2.306535e-06] 
Layer 'conv5' biases: 9.990678e-01 [2.537661e-06] 
Layer 'fc6' weights[0]: 6.764585e-03 [5.943858e-08] 
Layer 'fc6' biases: 9.999893e-01 [5.295155e-08] 
Layer 'fc7' weights[0]: 7.109266e-03 [1.372318e-07] 
Layer 'fc7' biases: 9.997264e-01 [1.869431e-07] 
Layer 'fc8' weights[0]: 4.835184e-03 [1.213806e-05] 
Layer 'fc8' biases: 2.375501e-02 [2.488426e-05] 
Train error last 800 batches: 0.657190
-------------------------------------------------------
Not saving because 0.495383 > 0.299667 (9.300: -1.18%)
======================================================= (2.382 sec)
28.681... logprob:  0.604242, 0.257812 (1.436 sec)
28.682... logprob:  0.513169, 0.235677 (1.434 sec)
28.683... logprob:  0.661941, 0.287760 (1.431 sec)
28.684... logprob:  0.633025, 0.256510 (1.479 sec)
28.685... logprob:  0.611593, 0.292969 (1.444 sec)
28.686... logprob:  0.587521, 0.236979 (1.425 sec)
28.687... logprob:  0.503763, 0.229167 (1.479 sec)
28.688... logprob:  0.580987, 0.256510 (1.426 sec)
28.689... logprob:  0.661734, 0.303385 (1.423 sec)
28.690... logprob:  0.671808, 0.295573 (1.431 sec)
28.691... logprob:  0.752717, 0.298177 (1.425 sec)
28.692... logprob:  0.637708, 0.281250 (1.428 sec)
28.693... logprob:  0.727040, 0.313802 (1.480 sec)
28.694... logprob:  0.570725, 0.246094 (1.443 sec)
28.695... logprob:  0.665218, 0.298177 (9.763 sec)
28.696... logprob:  0.774200, 0.333333 (8.811 sec)
28.697... logprob:  0.616524, 0.270833 (2.578 sec)
28.698... logprob:  0.746470, 0.291667 (1.733 sec)
28.699... logprob:  0.554453, 0.255208 (2.677 sec)
28.700... logprob:  0.619247, 0.270833 (4.732 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.468418, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.618687e-03 [1.308963e-07] 
Layer 'conv1' biases: 2.155794e-06 [7.717034e-11] 
Layer 'conv2' weights[0]: 2.613539e-03 [1.307040e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.327925e-09] 
Layer 'conv3' weights[0]: 2.612346e-03 [1.314402e-07] 
Layer 'conv3' biases: 3.574459e-05 [1.179195e-08] 
Layer 'conv4' weights[0]: 2.623408e-03 [1.321520e-07] 
Layer 'conv4' biases: 9.998729e-01 [3.231070e-07] 
Layer 'conv5' weights[0]: 2.785550e-03 [3.783961e-06] 
Layer 'conv5' biases: 9.990827e-01 [4.085485e-06] 
Layer 'fc6' weights[0]: 6.763905e-03 [7.700917e-08] 
Layer 'fc6' biases: 9.999893e-01 [7.567654e-08] 
Layer 'fc7' weights[0]: 7.108586e-03 [1.851899e-07] 
Layer 'fc7' biases: 9.997252e-01 [3.175849e-07] 
Layer 'fc8' weights[0]: 4.808663e-03 [1.703001e-05] 
Layer 'fc8' biases: 2.359855e-02 [5.092417e-05] 
Train error last 800 batches: 0.656566
-------------------------------------------------------
Not saving because 0.468418 > 0.299667 (9.300: -1.18%)
======================================================= (8.211 sec)
28.701... logprob:  0.612670, 0.253906 (9.664 sec)
28.702... logprob:  0.696238, 0.268229 (11.024 sec)
28.703... logprob:  0.668571, 0.302083 (6.029 sec)
28.704... logprob:  0.568087, 0.256510 (6.697 sec)
28.705... logprob:  0.619429, 0.276042 (1.554 sec)
28.706... logprob:  0.625869, 0.292969 (10.703 sec)
28.707... logprob:  0.622465, 0.269531 (2.891 sec)
28.708... logprob:  0.671625, 0.296875 (10.484 sec)
28.709... logprob:  0.728285, 0.315104 (2.829 sec)
28.710... logprob:  0.815099, 0.333333 (2.116 sec)
28.711... logprob:  0.638928, 0.274740 (1.481 sec)
28.712... logprob:  0.520700, 0.244792 (1.485 sec)
28.713... logprob:  0.819465, 0.333333 (1.536 sec)
28.714... logprob:  0.785860, 0.335937 (1.735 sec)
28.715... logprob:  0.662830, 0.289062 (1.732 sec)
28.716... logprob:  0.620861, 0.273437 (1.662 sec)
28.717... logprob:  0.666838, 0.266927 (1.464 sec)
28.718... logprob:  0.697420, 0.322917 (1.463 sec)
28.719... logprob:  0.610174, 0.302083 (1.554 sec)
28.720... logprob:  0.661891, 0.269531 (1.829 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.468251, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.616084e-03 [1.307785e-07] 
Layer 'conv1' biases: 2.156261e-06 [6.056931e-11] 
Layer 'conv2' weights[0]: 2.610911e-03 [1.305741e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.899393e-10] 
Layer 'conv3' weights[0]: 2.609732e-03 [1.307208e-07] 
Layer 'conv3' biases: 3.576304e-05 [5.268979e-09] 
Layer 'conv4' weights[0]: 2.620801e-03 [1.313215e-07] 
Layer 'conv4' biases: 9.998740e-01 [1.512515e-07] 
Layer 'conv5' weights[0]: 2.784341e-03 [2.409456e-06] 
Layer 'conv5' biases: 9.991252e-01 [2.452908e-06] 
Layer 'fc6' weights[0]: 6.763202e-03 [6.366515e-08] 
Layer 'fc6' biases: 9.999895e-01 [5.764918e-08] 
Layer 'fc7' weights[0]: 7.107934e-03 [1.452792e-07] 
Layer 'fc7' biases: 9.997224e-01 [1.911556e-07] 
Layer 'fc8' weights[0]: 4.723798e-03 [1.233521e-05] 
Layer 'fc8' biases: 2.293353e-02 [2.135899e-05] 
Train error last 800 batches: 0.655823
-------------------------------------------------------
Not saving because 0.468251 > 0.299667 (9.300: -1.18%)
======================================================= (8.723 sec)
28.721... logprob:  0.619614, 0.273437 (1.470 sec)
28.722... logprob:  0.756318, 0.330729 (1.452 sec)
28.723... logprob:  0.688046, 0.313802 (1.451 sec)
28.724... logprob:  0.682887, 0.304687 (1.471 sec)
28.725... logprob:  0.636384, 0.251302 (1.439 sec)
28.726... logprob:  0.596968, 0.277344 (1.426 sec)
28.727... logprob:  0.688742, 0.273438 (1.430 sec)
28.728... logprob:  0.631824, 0.278646 (1.448 sec)
28.729... logprob:  0.631161, 0.257812 (1.442 sec)
28.730... logprob:  0.745724, 0.341146 (1.482 sec)
28.731... logprob:  0.660907, 0.257812 (1.454 sec)
28.732... logprob:  0.596933, 0.257812 (1.440 sec)
28.733... logprob:  0.728513, 0.291667 (1.496 sec)
28.734... logprob:  0.590423, 0.250000 (1.435 sec)
28.735... logprob:  0.741911, 0.325521 (1.422 sec)
28.736... logprob:  0.825967, 0.364583 (1.432 sec)
28.737... logprob:  0.702640, 0.292969 (1.433 sec)
28.738... logprob:  0.657642, 0.317708 (1.437 sec)
28.739... logprob:  0.664192, 0.300781 (1.485 sec)
28.740... logprob:  0.583149, 0.253906 (1.441 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.510661, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.613463e-03 [1.307335e-07] 
Layer 'conv1' biases: 2.156724e-06 [5.255849e-11] 
Layer 'conv2' weights[0]: 2.608286e-03 [1.305010e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.961219e-10] 
Layer 'conv3' weights[0]: 2.607151e-03 [1.306156e-07] 
Layer 'conv3' biases: 3.574977e-05 [6.323756e-09] 
Layer 'conv4' weights[0]: 2.618178e-03 [1.313321e-07] 
Layer 'conv4' biases: 9.998747e-01 [1.686388e-07] 
Layer 'conv5' weights[0]: 2.782461e-03 [2.321061e-06] 
Layer 'conv5' biases: 9.991254e-01 [2.502072e-06] 
Layer 'fc6' weights[0]: 6.762482e-03 [6.031864e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.309876e-08] 
Layer 'fc7' weights[0]: 7.107222e-03 [1.380535e-07] 
Layer 'fc7' biases: 9.997219e-01 [1.641859e-07] 
Layer 'fc8' weights[0]: 4.717278e-03 [1.144084e-05] 
Layer 'fc8' biases: 2.287464e-02 [1.380369e-05] 
Train error last 800 batches: 0.656083
-------------------------------------------------------
Not saving because 0.510661 > 0.299667 (9.300: -1.18%)
======================================================= (2.340 sec)
28.741... logprob:  0.628529, 0.285156 (1.444 sec)
28.742... logprob:  0.629377, 0.276042 (1.479 sec)
28.743... logprob:  0.624325, 0.248698 (1.427 sec)
28.744... logprob:  0.731376, 0.329427 (1.427 sec)
28.745... logprob:  0.630715, 0.276042 (1.429 sec)
28.746... logprob:  0.615060, 0.251302 (1.422 sec)
28.747... logprob:  0.622593, 0.269531 (1.426 sec)
28.748... logprob:  0.621653, 0.287760 (1.478 sec)
28.749... logprob:  0.628173, 0.264323 (1.419 sec)
28.750... logprob:  0.708617, 0.283854 (1.429 sec)
28.751... logprob:  0.583601, 0.263021 (1.463 sec)
28.752... logprob:  0.662261, 0.282552 (1.416 sec)
28.753... logprob:  0.775081, 0.337240 (1.419 sec)
28.754... logprob:  0.684248, 0.317708 (1.419 sec)
28.755... logprob:  0.725450, 0.319010 (1.404 sec)
28.756... logprob:  0.689053, 0.305989 (1.418 sec)
28.757... logprob:  0.712961, 0.286458 (1.459 sec)
28.758... logprob:  0.650221, 0.269531 (1.443 sec)
28.759... logprob:  0.687346, 0.309896 (1.441 sec)
28.760... logprob:  0.675820, 0.296875 (1.449 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.417109, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.610854e-03 [1.305940e-07] 
Layer 'conv1' biases: 2.156913e-06 [4.830993e-11] 
Layer 'conv2' weights[0]: 2.605692e-03 [1.303415e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.998105e-10] 
Layer 'conv3' weights[0]: 2.604550e-03 [1.305170e-07] 
Layer 'conv3' biases: 3.574196e-05 [6.114103e-09] 
Layer 'conv4' weights[0]: 2.615547e-03 [1.311670e-07] 
Layer 'conv4' biases: 9.998737e-01 [1.625681e-07] 
Layer 'conv5' weights[0]: 2.779657e-03 [2.682066e-06] 
Layer 'conv5' biases: 9.991123e-01 [2.834195e-06] 
Layer 'fc6' weights[0]: 6.761809e-03 [6.633854e-08] 
Layer 'fc6' biases: 9.999894e-01 [6.097940e-08] 
Layer 'fc7' weights[0]: 7.106497e-03 [1.544133e-07] 
Layer 'fc7' biases: 9.997228e-01 [2.130019e-07] 
Layer 'fc8' weights[0]: 4.740053e-03 [1.390232e-05] 
Layer 'fc8' biases: 2.308718e-02 [3.070693e-05] 
Train error last 800 batches: 0.656094
-------------------------------------------------------
Not saving because 0.417109 > 0.299667 (9.300: -1.18%)
======================================================= (2.396 sec)
28.761... logprob:  0.567687, 0.248698 (1.443 sec)
28.762... logprob:  0.729551, 0.304688 (1.428 sec)
28.763... logprob:  0.752875, 0.316406 (1.421 sec)
28.764... logprob:  0.730401, 0.291667 (1.415 sec)
28.765... logprob:  0.547946, 0.252604 (1.433 sec)
28.766... logprob:  0.698713, 0.303385 (1.447 sec)
28.767... logprob:  0.669988, 0.311198 (1.450 sec)
28.768... logprob:  0.659479, 0.289062 (1.459 sec)
28.769... logprob:  0.704500, 0.320312 (1.460 sec)
28.770... logprob:  0.609318, 0.286458 (1.473 sec)
28.771... logprob:  0.727639, 0.315104 (1.453 sec)
28.772... logprob:  0.635111, 0.286458 (1.437 sec)
28.773... logprob:  0.724036, 0.316406 (1.444 sec)
28.774... logprob:  0.644326, 0.296875 (1.453 sec)
28.775... logprob:  0.643996, 0.296875 (1.458 sec)
28.776... logprob:  0.637751, 0.292969 (1.473 sec)
28.777... logprob:  0.611492, 0.270833 (1.465 sec)
28.778... logprob:  0.681674, 0.299479 (1.457 sec)
28.779... logprob:  0.705900, 0.317708 (1.479 sec)
28.780... logprob:  0.571107, 0.247396 (1.452 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.485426, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.608255e-03 [1.304871e-07] 
Layer 'conv1' biases: 2.157115e-06 [4.558112e-11] 
Layer 'conv2' weights[0]: 2.603084e-03 [1.302294e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.415166e-10] 
Layer 'conv3' weights[0]: 2.601937e-03 [1.303052e-07] 
Layer 'conv3' biases: 3.575586e-05 [5.218632e-09] 
Layer 'conv4' weights[0]: 2.612941e-03 [1.310002e-07] 
Layer 'conv4' biases: 9.998736e-01 [1.617730e-07] 
Layer 'conv5' weights[0]: 2.777300e-03 [2.445214e-06] 
Layer 'conv5' biases: 9.991190e-01 [2.717875e-06] 
Layer 'fc6' weights[0]: 6.761130e-03 [6.312034e-08] 
Layer 'fc6' biases: 9.999894e-01 [5.659899e-08] 
Layer 'fc7' weights[0]: 7.105777e-03 [1.460278e-07] 
Layer 'fc7' biases: 9.997222e-01 [2.002642e-07] 
Layer 'fc8' weights[0]: 4.730586e-03 [1.375943e-05] 
Layer 'fc8' biases: 2.308359e-02 [2.766176e-05] 
Train error last 800 batches: 0.655752
-------------------------------------------------------
Not saving because 0.485426 > 0.299667 (9.300: -1.18%)
======================================================= (2.352 sec)
28.781... logprob:  0.579993, 0.234375 (1.442 sec)
28.782... logprob:  0.578182, 0.257812 (1.448 sec)
28.783... logprob:  0.738230, 0.316406 (1.458 sec)
28.784... logprob:  0.662108, 0.273437 (1.455 sec)
28.785... logprob:  0.790396, 0.351562 (1.516 sec)
28.786... logprob:  0.693225, 0.305990 (1.467 sec)
28.787... logprob:  0.696734, 0.259115 (1.453 sec)
28.788... logprob:  0.747288, 0.319010 (1.489 sec)
28.789... logprob:  0.629091, 0.309896 (1.448 sec)
28.790... logprob:  0.576582, 0.269531 (1.446 sec)
28.791... logprob:  0.636153, 0.251302 (1.440 sec)
28.792... logprob:  0.625702, 0.286458 (1.455 sec)
28.793... logprob:  0.625626, 0.265625 (1.450 sec)
28.794... logprob:  0.714991, 0.291667 (1.489 sec)
28.795... logprob:  0.719253, 0.322917 (1.470 sec)
28.796... logprob:  0.718773, 0.303385 (1.458 sec)
28.797... logprob:  0.563428, 0.273438 (1.493 sec)
28.798... logprob:  0.587336, 0.234375 (1.443 sec)
28.799... logprob:  0.601789, 0.276042 (1.439 sec)
28.800... logprob:  0.625973, 0.264323 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.460079, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.605640e-03 [1.303228e-07] 
Layer 'conv1' biases: 2.157498e-06 [8.022299e-11] 
Layer 'conv2' weights[0]: 2.600477e-03 [1.301078e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.265074e-10] 
Layer 'conv3' weights[0]: 2.599331e-03 [1.305280e-07] 
Layer 'conv3' biases: 3.576912e-05 [8.703272e-09] 
Layer 'conv4' weights[0]: 2.610341e-03 [1.314831e-07] 
Layer 'conv4' biases: 9.998718e-01 [2.505424e-07] 
Layer 'conv5' weights[0]: 2.773456e-03 [2.820732e-06] 
Layer 'conv5' biases: 9.991016e-01 [2.995163e-06] 
Layer 'fc6' weights[0]: 6.760427e-03 [6.580586e-08] 
Layer 'fc6' biases: 9.999893e-01 [6.032111e-08] 
Layer 'fc7' weights[0]: 7.105064e-03 [1.547284e-07] 
Layer 'fc7' biases: 9.997230e-01 [2.284356e-07] 
Layer 'fc8' weights[0]: 4.763287e-03 [1.427161e-05] 
Layer 'fc8' biases: 2.340486e-02 [3.853086e-05] 
Train error last 800 batches: 0.655659
-------------------------------------------------------
Not saving because 0.460079 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
29.1... logprob:  0.676697, 0.320312 (1.403 sec)
29.2... logprob:  0.594777, 0.243489 (1.439 sec)
29.3... logprob:  0.612835, 0.266927 (1.414 sec)
29.4... logprob:  0.637340, 0.265625 (1.397 sec)
29.5... logprob:  0.718338, 0.309896 (1.421 sec)
29.6... logprob:  0.706596, 0.286458 (1.385 sec)
29.7... logprob:  0.619300, 0.281250 (1.405 sec)
29.8... logprob:  0.559714, 0.250000 (1.381 sec)
29.9... logprob:  0.599898, 0.252604 (1.390 sec)
29.10... logprob:  0.597174, 0.259114 (1.391 sec)
29.11... logprob:  0.676489, 0.281250 (1.428 sec)
29.12... logprob:  0.687389, 0.315104 (1.380 sec)
29.13... logprob:  0.697904, 0.303385 (1.409 sec)
29.14... logprob:  0.621837, 0.270833 (1.394 sec)
29.15... logprob:  0.690042, 0.289062 (1.404 sec)
29.16... logprob:  0.616533, 0.274740 (1.393 sec)
29.17... logprob:  0.764597, 0.339844 (1.393 sec)
29.18... logprob:  0.503646, 0.236979 (1.398 sec)
29.19... logprob:  0.581476, 0.279948 (1.398 sec)
29.20... logprob:  0.622643, 0.268229 (1.396 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.466646, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.603029e-03 [1.302367e-07] 
Layer 'conv1' biases: 2.157617e-06 [3.902048e-11] 
Layer 'conv2' weights[0]: 2.597877e-03 [1.299560e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.378202e-10] 
Layer 'conv3' weights[0]: 2.596742e-03 [1.300217e-07] 
Layer 'conv3' biases: 3.575901e-05 [4.006430e-09] 
Layer 'conv4' weights[0]: 2.607705e-03 [1.306312e-07] 
Layer 'conv4' biases: 9.998710e-01 [1.143845e-07] 
Layer 'conv5' weights[0]: 2.770422e-03 [2.225918e-06] 
Layer 'conv5' biases: 9.990860e-01 [2.407717e-06] 
Layer 'fc6' weights[0]: 6.759743e-03 [6.003062e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.297687e-08] 
Layer 'fc7' weights[0]: 7.104313e-03 [1.383342e-07] 
Layer 'fc7' biases: 9.997236e-01 [1.806994e-07] 
Layer 'fc8' weights[0]: 4.795339e-03 [1.245261e-05] 
Layer 'fc8' biases: 2.370114e-02 [2.868040e-05] 
Train error last 800 batches: 0.655563
-------------------------------------------------------
Not saving because 0.466646 > 0.299667 (9.300: -1.18%)
======================================================= (2.420 sec)
29.21... logprob:  0.667391, 0.300781 (1.405 sec)
29.22... logprob:  0.637084, 0.282552 (1.410 sec)
29.23... logprob:  0.738734, 0.307292 (1.410 sec)
29.24... logprob:  0.532766, 0.243490 (1.406 sec)
29.25... logprob:  0.602747, 0.296875 (1.396 sec)
29.26... logprob:  0.665086, 0.300781 (1.442 sec)
29.27... logprob:  0.674646, 0.290365 (1.379 sec)
29.28... logprob:  0.657679, 0.300781 (1.411 sec)
29.29... logprob:  0.601520, 0.246094 (1.418 sec)
29.30... logprob:  0.696623, 0.311198 (1.411 sec)
29.31... logprob:  0.705624, 0.303385 (1.392 sec)
29.32... logprob:  0.617946, 0.265625 (1.385 sec)
29.33... logprob:  0.733945, 0.332031 (1.463 sec)
29.34... logprob:  0.664870, 0.294271 (1.386 sec)
29.35... logprob:  0.571326, 0.279948 (1.395 sec)
29.36... logprob:  0.669273, 0.282552 (1.394 sec)
29.37... logprob:  0.596617, 0.278646 (1.393 sec)
29.38... logprob:  0.630234, 0.281250 (1.389 sec)
29.39... logprob:  0.871322, 0.375000 (1.436 sec)
29.40... logprob:  0.730074, 0.311198 (1.404 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.483361, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.600437e-03 [1.300114e-07] 
Layer 'conv1' biases: 2.157562e-06 [5.677917e-11] 
Layer 'conv2' weights[0]: 2.595286e-03 [1.297929e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.180404e-10] 
Layer 'conv3' weights[0]: 2.594155e-03 [1.301093e-07] 
Layer 'conv3' biases: 3.575981e-05 [8.258162e-09] 
Layer 'conv4' weights[0]: 2.605099e-03 [1.308094e-07] 
Layer 'conv4' biases: 9.998724e-01 [2.458038e-07] 
Layer 'conv5' weights[0]: 2.769139e-03 [3.500534e-06] 
Layer 'conv5' biases: 9.990889e-01 [3.822309e-06] 
Layer 'fc6' weights[0]: 6.759027e-03 [7.689703e-08] 
Layer 'fc6' biases: 9.999893e-01 [7.485464e-08] 
Layer 'fc7' weights[0]: 7.103548e-03 [1.872611e-07] 
Layer 'fc7' biases: 9.997228e-01 [3.232333e-07] 
Layer 'fc8' weights[0]: 4.776500e-03 [1.853811e-05] 
Layer 'fc8' biases: 2.353503e-02 [5.767064e-05] 
Train error last 800 batches: 0.655713
-------------------------------------------------------
Not saving because 0.483361 > 0.299667 (9.300: -1.18%)
======================================================= (2.349 sec)
29.41... logprob:  0.564596, 0.250000 (1.429 sec)
29.42... logprob:  0.568535, 0.256510 (1.417 sec)
29.43... logprob:  0.635986, 0.268229 (1.393 sec)
29.44... logprob:  0.723055, 0.292969 (1.435 sec)
29.45... logprob:  0.610643, 0.278646 (1.381 sec)
29.46... logprob:  0.678402, 0.309896 (1.490 sec)
29.47... logprob:  0.620348, 0.290365 (1.393 sec)
29.48... logprob:  0.649794, 0.291667 (1.415 sec)
29.49... logprob:  0.700680, 0.278646 (1.410 sec)
29.50... logprob:  0.652830, 0.273437 (1.418 sec)
29.51... logprob:  0.717198, 0.326823 (1.407 sec)
29.52... logprob:  0.687197, 0.328125 (1.392 sec)
29.53... logprob:  0.586156, 0.279948 (1.439 sec)
29.54... logprob:  0.556084, 0.250000 (1.383 sec)
29.55... logprob:  0.626071, 0.302083 (1.396 sec)
29.56... logprob:  0.686078, 0.290365 (1.402 sec)
29.57... logprob:  0.668517, 0.313802 (1.422 sec)
29.58... logprob:  0.625090, 0.277344 (1.396 sec)
29.59... logprob:  0.584988, 0.261719 (1.457 sec)
29.60... logprob:  0.736693, 0.325521 (1.409 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.574899, 0.171875 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.597829e-03 [1.300175e-07] 
Layer 'conv1' biases: 2.157459e-06 [6.341172e-11] 
Layer 'conv2' weights[0]: 2.592693e-03 [1.297391e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.152490e-10] 
Layer 'conv3' weights[0]: 2.591556e-03 [1.300179e-07] 
Layer 'conv3' biases: 3.576269e-05 [7.410599e-09] 
Layer 'conv4' weights[0]: 2.602511e-03 [1.307809e-07] 
Layer 'conv4' biases: 9.998728e-01 [1.831985e-07] 
Layer 'conv5' weights[0]: 2.767141e-03 [2.712831e-06] 
Layer 'conv5' biases: 9.990872e-01 [3.003672e-06] 
Layer 'fc6' weights[0]: 6.758330e-03 [6.258392e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.649311e-08] 
Layer 'fc7' weights[0]: 7.102835e-03 [1.455707e-07] 
Layer 'fc7' biases: 9.997220e-01 [2.030375e-07] 
Layer 'fc8' weights[0]: 4.757845e-03 [1.409239e-05] 
Layer 'fc8' biases: 2.341603e-02 [3.360404e-05] 
Train error last 800 batches: 0.655523
-------------------------------------------------------
Not saving because 0.574899 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
29.61... logprob:  0.559732, 0.248698 (1.428 sec)
29.62... logprob:  0.695835, 0.290365 (1.449 sec)
29.63... logprob:  0.638818, 0.304687 (1.437 sec)
29.64... logprob:  0.678172, 0.298177 (1.425 sec)
29.65... logprob:  0.595585, 0.261719 (1.399 sec)
29.66... logprob:  0.545004, 0.226562 (1.431 sec)
29.67... logprob:  0.586092, 0.253906 (1.374 sec)
29.68... logprob:  0.659281, 0.311198 (1.384 sec)
29.69... logprob:  0.627071, 0.264323 (1.413 sec)
29.70... logprob:  0.610783, 0.286458 (1.417 sec)
29.71... logprob:  0.621607, 0.330729 (1.450 sec)
29.72... logprob:  0.691874, 0.299479 (1.396 sec)
29.73... logprob:  0.666291, 0.253906 (1.411 sec)
29.74... logprob:  0.575767, 0.261719 (1.409 sec)
29.75... logprob:  0.615236, 0.268229 (1.413 sec)
29.76... logprob:  0.590223, 0.236979 (1.426 sec)
29.77... logprob:  0.593563, 0.257812 (1.427 sec)
29.78... logprob:  0.714724, 0.290365 (1.444 sec)
29.79... logprob:  0.677741, 0.303385 (1.407 sec)
29.80... logprob:  0.696987, 0.285156 (1.413 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.463706, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.595234e-03 [1.297405e-07] 
Layer 'conv1' biases: 2.157659e-06 [6.157908e-11] 
Layer 'conv2' weights[0]: 2.590100e-03 [1.295340e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.122914e-10] 
Layer 'conv3' weights[0]: 2.588957e-03 [1.296947e-07] 
Layer 'conv3' biases: 3.575228e-05 [6.026379e-09] 
Layer 'conv4' weights[0]: 2.599902e-03 [1.304813e-07] 
Layer 'conv4' biases: 9.998713e-01 [1.882855e-07] 
Layer 'conv5' weights[0]: 2.763569e-03 [2.515805e-06] 
Layer 'conv5' biases: 9.990533e-01 [2.600440e-06] 
Layer 'fc6' weights[0]: 6.757643e-03 [6.484329e-08] 
Layer 'fc6' biases: 9.999892e-01 [6.044989e-08] 
Layer 'fc7' weights[0]: 7.102109e-03 [1.522802e-07] 
Layer 'fc7' biases: 9.997241e-01 [2.146535e-07] 
Layer 'fc8' weights[0]: 4.826847e-03 [1.492735e-05] 
Layer 'fc8' biases: 2.401919e-02 [3.956987e-05] 
Train error last 800 batches: 0.655810
-------------------------------------------------------
Not saving because 0.463706 > 0.299667 (9.300: -1.18%)
======================================================= (2.360 sec)
29.81... logprob:  0.717440, 0.272135 (1.421 sec)
29.82... logprob:  0.500173, 0.223958 (1.413 sec)
29.83... logprob:  0.664683, 0.290365 (1.397 sec)
29.84... logprob:  0.695655, 0.329427 (1.457 sec)
29.85... logprob:  0.694160, 0.289062 (1.412 sec)
29.86... logprob:  0.634916, 0.256510 (1.410 sec)
29.87... logprob:  0.808021, 0.345052 (1.411 sec)
29.88... logprob:  0.629524, 0.286458 (1.402 sec)
29.89... logprob:  0.644109, 0.292969 (1.429 sec)
29.90... logprob:  0.802339, 0.348958 (1.381 sec)
29.91... logprob:  0.538174, 0.231771 (1.388 sec)
29.92... logprob:  0.737199, 0.329427 (1.395 sec)
29.93... logprob:  0.697019, 0.313802 (1.391 sec)
29.94... logprob:  0.697191, 0.305990 (1.383 sec)
29.95... logprob:  0.672789, 0.290365 (1.394 sec)
29.96... logprob:  0.744914, 0.304688 (1.398 sec)
29.97... logprob:  0.631210, 0.266927 (1.386 sec)
29.98... logprob:  0.593189, 0.265625 (1.427 sec)
29.99... logprob:  0.672243, 0.270833 (1.404 sec)
29.100... logprob:  0.568737, 0.248698 (1.391 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.499059, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.592647e-03 [1.296546e-07] 
Layer 'conv1' biases: 2.157939e-06 [4.641667e-11] 
Layer 'conv2' weights[0]: 2.587498e-03 [1.294210e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.532416e-10] 
Layer 'conv3' weights[0]: 2.586341e-03 [1.295658e-07] 
Layer 'conv3' biases: 3.578068e-05 [5.937103e-09] 
Layer 'conv4' weights[0]: 2.597307e-03 [1.301485e-07] 
Layer 'conv4' biases: 9.998718e-01 [1.566658e-07] 
Layer 'conv5' weights[0]: 2.761899e-03 [2.286402e-06] 
Layer 'conv5' biases: 9.990962e-01 [2.400534e-06] 
Layer 'fc6' weights[0]: 6.756962e-03 [6.257539e-08] 
Layer 'fc6' biases: 9.999893e-01 [5.678386e-08] 
Layer 'fc7' weights[0]: 7.101420e-03 [1.426570e-07] 
Layer 'fc7' biases: 9.997206e-01 [1.796681e-07] 
Layer 'fc8' weights[0]: 4.727090e-03 [1.226033e-05] 
Layer 'fc8' biases: 2.323858e-02 [1.534844e-05] 
Train error last 800 batches: 0.655856
-------------------------------------------------------
Not saving because 0.499059 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
29.101... logprob:  0.593124, 0.278646 (1.454 sec)
29.102... logprob:  0.782471, 0.348958 (1.391 sec)
29.103... logprob:  0.738018, 0.332031 (1.391 sec)
29.104... logprob:  0.649507, 0.315104 (1.394 sec)
29.105... logprob:  0.763976, 0.337240 (1.388 sec)
29.106... logprob:  0.602192, 0.270833 (1.387 sec)
29.107... logprob:  0.568296, 0.257812 (1.430 sec)
29.108... logprob:  0.824551, 0.348958 (1.391 sec)
29.109... logprob:  0.537296, 0.255208 (1.404 sec)
29.110... logprob:  0.770453, 0.303385 (1.390 sec)
29.111... logprob:  0.612850, 0.276042 (1.390 sec)
29.112... logprob:  0.596994, 0.243490 (1.395 sec)
29.113... logprob:  0.606016, 0.276042 (1.390 sec)
29.114... logprob:  0.635166, 0.287760 (1.425 sec)
29.115... logprob:  0.741479, 0.333333 (1.408 sec)
29.116... logprob:  0.622635, 0.270833 (1.392 sec)
29.117... logprob:  0.585289, 0.251302 (1.438 sec)
29.118... logprob:  0.554430, 0.227864 (1.384 sec)
29.119... logprob:  0.628051, 0.243490 (1.389 sec)
29.120... logprob:  0.745025, 0.321615 (1.396 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.492464, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.590062e-03 [1.296090e-07] 
Layer 'conv1' biases: 2.158009e-06 [4.955666e-11] 
Layer 'conv2' weights[0]: 2.584931e-03 [1.293436e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.881535e-10] 
Layer 'conv3' weights[0]: 2.583763e-03 [1.295453e-07] 
Layer 'conv3' biases: 3.579365e-05 [6.575892e-09] 
Layer 'conv4' weights[0]: 2.594701e-03 [1.303185e-07] 
Layer 'conv4' biases: 9.998707e-01 [2.049775e-07] 
Layer 'conv5' weights[0]: 2.759277e-03 [2.597109e-06] 
Layer 'conv5' biases: 9.990733e-01 [2.861083e-06] 
Layer 'fc6' weights[0]: 6.756269e-03 [6.478935e-08] 
Layer 'fc6' biases: 9.999893e-01 [5.967659e-08] 
Layer 'fc7' weights[0]: 7.100701e-03 [1.528217e-07] 
Layer 'fc7' biases: 9.997218e-01 [2.130615e-07] 
Layer 'fc8' weights[0]: 4.764314e-03 [1.436816e-05] 
Layer 'fc8' biases: 2.351698e-02 [3.947193e-05] 
Train error last 800 batches: 0.655878
-------------------------------------------------------
Not saving because 0.492464 > 0.299667 (9.300: -1.18%)
======================================================= (2.367 sec)
29.121... logprob:  0.532965, 0.234375 (1.402 sec)
29.122... logprob:  0.698273, 0.319010 (1.437 sec)
29.123... logprob:  0.632386, 0.300781 (1.377 sec)
29.124... logprob:  0.764874, 0.319010 (1.388 sec)
29.125... logprob:  0.725029, 0.315104 (1.386 sec)
29.126... logprob:  0.666218, 0.311198 (1.376 sec)
29.127... logprob:  0.686025, 0.296875 (1.387 sec)
29.128... logprob:  0.658876, 0.298177 (1.401 sec)
29.129... logprob:  0.802002, 0.319010 (1.409 sec)
29.130... logprob:  0.639731, 0.296875 (1.405 sec)
29.131... logprob:  0.734944, 0.317708 (1.398 sec)
29.132... logprob:  0.649407, 0.281250 (1.425 sec)
29.133... logprob:  0.629178, 0.259115 (1.379 sec)
29.134... logprob:  0.601386, 0.253906 (1.388 sec)
29.135... logprob:  0.645037, 0.291667 (1.398 sec)
29.136... logprob:  0.920081, 0.404948 (1.390 sec)
29.137... logprob:  0.593651, 0.264323 (1.385 sec)
29.138... logprob:  0.572280, 0.244792 (1.437 sec)
29.139... logprob:  0.625833, 0.266927 (1.393 sec)
29.140... logprob:  0.650260, 0.315104 (1.402 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.510258, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.587457e-03 [1.293786e-07] 
Layer 'conv1' biases: 2.158121e-06 [5.103549e-11] 
Layer 'conv2' weights[0]: 2.582339e-03 [1.291681e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.295324e-10] 
Layer 'conv3' weights[0]: 2.581206e-03 [1.292797e-07] 
Layer 'conv3' biases: 3.582069e-05 [5.012338e-09] 
Layer 'conv4' weights[0]: 2.592119e-03 [1.299947e-07] 
Layer 'conv4' biases: 9.998698e-01 [1.549239e-07] 
Layer 'conv5' weights[0]: 2.756363e-03 [2.094539e-06] 
Layer 'conv5' biases: 9.990721e-01 [2.309777e-06] 
Layer 'fc6' weights[0]: 6.755606e-03 [5.968827e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.321128e-08] 
Layer 'fc7' weights[0]: 7.100004e-03 [1.349354e-07] 
Layer 'fc7' biases: 9.997215e-01 [1.647580e-07] 
Layer 'fc8' weights[0]: 4.752156e-03 [1.135190e-05] 
Layer 'fc8' biases: 2.354384e-02 [1.198008e-05] 
Train error last 800 batches: 0.655586
-------------------------------------------------------
Not saving because 0.510258 > 0.299667 (9.300: -1.18%)
======================================================= (2.407 sec)
29.141... logprob:  0.685273, 0.320312 (1.438 sec)
29.142... logprob:  0.748582, 0.334635 (1.391 sec)
29.143... logprob:  0.496956, 0.207031 (1.416 sec)
29.144... logprob:  0.742362, 0.294271 (1.418 sec)
29.145... logprob:  0.554956, 0.247396 (1.405 sec)
29.146... logprob:  0.712178, 0.317708 (1.407 sec)
29.147... logprob:  0.530401, 0.242188 (1.427 sec)
29.148... logprob:  0.701373, 0.287760 (1.384 sec)
29.149... logprob:  0.663683, 0.252604 (1.394 sec)
29.150... logprob:  0.543212, 0.248698 (1.395 sec)
29.151... logprob:  0.576940, 0.285156 (1.400 sec)
29.152... logprob:  0.800065, 0.346354 (1.392 sec)
29.153... logprob:  0.621342, 0.278646 (1.435 sec)
29.154... logprob:  0.726523, 0.307292 (1.399 sec)
29.155... logprob:  0.642198, 0.279948 (1.402 sec)
29.156... logprob:  0.505817, 0.221354 (1.427 sec)
29.157... logprob:  0.562159, 0.247396 (1.387 sec)
29.158... logprob:  0.688778, 0.290365 (1.399 sec)
29.159... logprob:  0.637255, 0.278646 (1.399 sec)
29.160... logprob:  0.705488, 0.304687 (1.391 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.496531, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.584876e-03 [1.292754e-07] 
Layer 'conv1' biases: 2.158281e-06 [5.713036e-11] 
Layer 'conv2' weights[0]: 2.579762e-03 [1.290276e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.326352e-10] 
Layer 'conv3' weights[0]: 2.578609e-03 [1.291936e-07] 
Layer 'conv3' biases: 3.581823e-05 [5.596997e-09] 
Layer 'conv4' weights[0]: 2.589515e-03 [1.298794e-07] 
Layer 'conv4' biases: 9.998702e-01 [1.521815e-07] 
Layer 'conv5' weights[0]: 2.754056e-03 [2.239582e-06] 
Layer 'conv5' biases: 9.990578e-01 [2.346872e-06] 
Layer 'fc6' weights[0]: 6.754898e-03 [6.103076e-08] 
Layer 'fc6' biases: 9.999891e-01 [5.518819e-08] 
Layer 'fc7' weights[0]: 7.099315e-03 [1.429140e-07] 
Layer 'fc7' biases: 9.997225e-01 [1.832979e-07] 
Layer 'fc8' weights[0]: 4.780508e-03 [1.251182e-05] 
Layer 'fc8' biases: 2.378140e-02 [2.715758e-05] 
Train error last 800 batches: 0.655306
-------------------------------------------------------
Not saving because 0.496531 > 0.299667 (9.300: -1.18%)
======================================================= (2.376 sec)
29.161... logprob:  0.625806, 0.278646 (1.416 sec)
29.162... logprob:  0.842702, 0.368489 (1.403 sec)
29.163... logprob:  0.536677, 0.231771 (1.419 sec)
29.164... logprob:  0.769377, 0.326823 (1.418 sec)
29.165... logprob:  0.693172, 0.286458 (1.412 sec)
29.166... logprob:  0.671966, 0.300781 (1.444 sec)
29.167... logprob:  0.620321, 0.304688 (1.421 sec)
29.168... logprob:  0.587062, 0.247396 (1.420 sec)
29.169... logprob:  0.612550, 0.273437 (1.451 sec)
29.170... logprob:  0.667401, 0.307292 (1.398 sec)
29.171... logprob:  0.733219, 0.315104 (1.416 sec)
29.172... logprob:  0.584558, 0.251302 (1.406 sec)
29.173... logprob:  0.600200, 0.266927 (1.413 sec)
29.174... logprob:  0.788646, 0.319010 (1.474 sec)
29.175... logprob:  0.784886, 0.315104 (1.458 sec)
29.176... logprob:  0.640289, 0.259115 (1.407 sec)
29.177... logprob:  0.549261, 0.248698 (1.417 sec)
29.178... logprob:  0.638971, 0.253906 (1.453 sec)
29.179... logprob:  0.589786, 0.273437 (1.401 sec)
29.180... logprob:  0.671133, 0.287760 (1.424 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.416916, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.582292e-03 [1.291669e-07] 
Layer 'conv1' biases: 2.158484e-06 [4.855456e-11] 
Layer 'conv2' weights[0]: 2.577176e-03 [1.289196e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.064966e-10] 
Layer 'conv3' weights[0]: 2.576045e-03 [1.290045e-07] 
Layer 'conv3' biases: 3.583245e-05 [5.163344e-09] 
Layer 'conv4' weights[0]: 2.586945e-03 [1.296252e-07] 
Layer 'conv4' biases: 9.998707e-01 [1.522001e-07] 
Layer 'conv5' weights[0]: 2.751817e-03 [2.430171e-06] 
Layer 'conv5' biases: 9.990771e-01 [2.555794e-06] 
Layer 'fc6' weights[0]: 6.754195e-03 [6.154561e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.581303e-08] 
Layer 'fc7' weights[0]: 7.098615e-03 [1.439842e-07] 
Layer 'fc7' biases: 9.997209e-01 [1.915261e-07] 
Layer 'fc8' weights[0]: 4.743790e-03 [1.351179e-05] 
Layer 'fc8' biases: 2.354954e-02 [3.035033e-05] 
Train error last 800 batches: 0.654778
-------------------------------------------------------
Not saving because 0.416916 > 0.299667 (9.300: -1.18%)
======================================================= (2.358 sec)
29.181... logprob:  0.767246, 0.347656 (1.421 sec)
29.182... logprob:  0.632454, 0.279948 (1.405 sec)
29.183... logprob:  0.613765, 0.282552 (1.422 sec)
29.184... logprob:  0.718073, 0.315104 (1.409 sec)
29.185... logprob:  0.534375, 0.242187 (1.385 sec)
29.186... logprob:  0.655729, 0.300781 (1.390 sec)
29.187... logprob:  0.689710, 0.287760 (1.385 sec)
29.188... logprob:  0.735922, 0.302083 (1.384 sec)
29.189... logprob:  0.618114, 0.281250 (1.374 sec)
29.190... logprob:  0.667437, 0.308594 (1.421 sec)
29.191... logprob:  0.791658, 0.317708 (1.393 sec)
29.192... logprob:  0.653553, 0.295573 (1.406 sec)
29.193... logprob:  0.510122, 0.214844 (1.414 sec)
29.194... logprob:  0.594492, 0.257812 (1.411 sec)
29.195... logprob:  0.504221, 0.248698 (1.389 sec)
29.196... logprob:  0.622418, 0.252604 (1.385 sec)
29.197... logprob:  0.722886, 0.281250 (1.395 sec)
29.198... logprob:  0.534362, 0.226562 (1.397 sec)
29.199... logprob:  0.652394, 0.313802 (1.385 sec)
29.200... logprob:  0.537826, 0.239583 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.438810, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.579711e-03 [1.291314e-07] 
Layer 'conv1' biases: 2.158743e-06 [6.792313e-11] 
Layer 'conv2' weights[0]: 2.574606e-03 [1.288648e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.206357e-10] 
Layer 'conv3' weights[0]: 2.573439e-03 [1.292086e-07] 
Layer 'conv3' biases: 3.583775e-05 [7.997662e-09] 
Layer 'conv4' weights[0]: 2.584342e-03 [1.302157e-07] 
Layer 'conv4' biases: 9.998690e-01 [2.327620e-07] 
Layer 'conv5' weights[0]: 2.748273e-03 [3.163347e-06] 
Layer 'conv5' biases: 9.990636e-01 [3.348949e-06] 
Layer 'fc6' weights[0]: 6.753519e-03 [6.747123e-08] 
Layer 'fc6' biases: 9.999891e-01 [6.355927e-08] 
Layer 'fc7' weights[0]: 7.097853e-03 [1.603999e-07] 
Layer 'fc7' biases: 9.997218e-01 [2.540532e-07] 
Layer 'fc8' weights[0]: 4.775747e-03 [1.586367e-05] 
Layer 'fc8' biases: 2.384480e-02 [4.595810e-05] 
Train error last 800 batches: 0.654739
-------------------------------------------------------
Not saving because 0.438810 > 0.299667 (9.300: -1.18%)
======================================================= (2.408 sec)
29.201... logprob:  0.675195, 0.285156 (1.416 sec)
29.202... logprob:  0.698380, 0.274739 (1.402 sec)
29.203... logprob:  0.634737, 0.285156 (1.431 sec)
29.204... logprob:  0.802610, 0.332031 (1.391 sec)
29.205... logprob:  0.582052, 0.263021 (1.398 sec)
29.206... logprob:  0.596417, 0.259114 (1.392 sec)
29.207... logprob:  0.601257, 0.273437 (1.389 sec)
29.208... logprob:  0.755506, 0.324219 (1.385 sec)
29.209... logprob:  0.586975, 0.283854 (1.415 sec)
29.210... logprob:  0.740952, 0.339844 (1.409 sec)
29.211... logprob:  0.696772, 0.319010 (1.409 sec)
29.212... logprob:  0.746662, 0.330729 (1.407 sec)
29.213... logprob:  0.749624, 0.335937 (1.452 sec)
29.214... logprob:  0.738231, 0.294271 (1.419 sec)
29.215... logprob:  0.625061, 0.273437 (1.410 sec)
29.216... logprob:  0.725457, 0.350260 (1.464 sec)
29.217... logprob:  0.548086, 0.261719 (1.393 sec)
29.218... logprob:  0.649851, 0.283854 (1.418 sec)
29.219... logprob:  0.746837, 0.320312 (1.405 sec)
29.220... logprob:  0.673442, 0.316406 (1.411 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.460113, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.577134e-03 [1.289129e-07] 
Layer 'conv1' biases: 2.159114e-06 [5.924280e-11] 
Layer 'conv2' weights[0]: 2.572021e-03 [1.286495e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.844208e-10] 
Layer 'conv3' weights[0]: 2.570878e-03 [1.288790e-07] 
Layer 'conv3' biases: 3.584639e-05 [6.690855e-09] 
Layer 'conv4' weights[0]: 2.581764e-03 [1.295762e-07] 
Layer 'conv4' biases: 9.998697e-01 [1.812178e-07] 
Layer 'conv5' weights[0]: 2.746568e-03 [2.581827e-06] 
Layer 'conv5' biases: 9.990766e-01 [2.666298e-06] 
Layer 'fc6' weights[0]: 6.752838e-03 [6.501916e-08] 
Layer 'fc6' biases: 9.999894e-01 [6.019739e-08] 
Layer 'fc7' weights[0]: 7.097177e-03 [1.521363e-07] 
Layer 'fc7' biases: 9.997213e-01 [2.171385e-07] 
Layer 'fc8' weights[0]: 4.746334e-03 [1.348811e-05] 
Layer 'fc8' biases: 2.362549e-02 [3.134640e-05] 
Train error last 800 batches: 0.655064
-------------------------------------------------------
Not saving because 0.460113 > 0.299667 (9.300: -1.18%)
======================================================= (2.350 sec)
29.221... logprob:  0.570888, 0.248698 (1.410 sec)
29.222... logprob:  0.748540, 0.346354 (1.460 sec)
29.223... logprob:  0.801087, 0.338542 (1.432 sec)
29.224... logprob:  0.664074, 0.291667 (1.425 sec)
29.225... logprob:  0.606459, 0.252604 (1.442 sec)
29.226... logprob:  0.692232, 0.308594 (1.414 sec)
29.227... logprob:  0.608989, 0.251302 (1.408 sec)
29.228... logprob:  0.639277, 0.269531 (1.405 sec)
29.229... logprob:  0.658170, 0.282552 (1.412 sec)
29.230... logprob:  0.645540, 0.256510 (1.415 sec)
29.231... logprob:  0.723958, 0.326823 (1.401 sec)
29.232... logprob:  0.773268, 0.329427 (1.453 sec)
29.233... logprob:  0.646065, 0.303385 (1.419 sec)
29.234... logprob:  0.832154, 0.371094 (1.410 sec)
29.235... logprob:  0.642642, 0.265625 (1.460 sec)
29.236... logprob:  0.650330, 0.291667 (1.405 sec)
29.237... logprob:  0.585951, 0.250000 (1.416 sec)
29.238... logprob:  0.646669, 0.285156 (1.410 sec)
29.239... logprob:  0.704355, 0.304688 (1.411 sec)
29.240... logprob:  0.765331, 0.338542 (1.397 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.574219, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.574563e-03 [1.287607e-07] 
Layer 'conv1' biases: 2.159486e-06 [4.671102e-11] 
Layer 'conv2' weights[0]: 2.569457e-03 [1.285214e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.643337e-10] 
Layer 'conv3' weights[0]: 2.568313e-03 [1.286856e-07] 
Layer 'conv3' biases: 3.585971e-05 [5.600146e-09] 
Layer 'conv4' weights[0]: 2.579189e-03 [1.293944e-07] 
Layer 'conv4' biases: 9.998697e-01 [1.839645e-07] 
Layer 'conv5' weights[0]: 2.744328e-03 [2.393170e-06] 
Layer 'conv5' biases: 9.990905e-01 [2.565087e-06] 
Layer 'fc6' weights[0]: 6.752114e-03 [6.167920e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.548758e-08] 
Layer 'fc7' weights[0]: 7.096434e-03 [1.422728e-07] 
Layer 'fc7' biases: 9.997193e-01 [1.787565e-07] 
Layer 'fc8' weights[0]: 4.704785e-03 [1.196186e-05] 
Layer 'fc8' biases: 2.335207e-02 [1.623925e-05] 
Train error last 800 batches: 0.655411
-------------------------------------------------------
Not saving because 0.574219 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
29.241... logprob:  0.687414, 0.305990 (1.463 sec)
29.242... logprob:  0.637818, 0.287760 (1.422 sec)
29.243... logprob:  0.591628, 0.266927 (1.416 sec)
29.244... logprob:  0.554255, 0.230469 (1.441 sec)
29.245... logprob:  0.722251, 0.300781 (1.434 sec)
29.246... logprob:  0.578984, 0.281250 (1.409 sec)
29.247... logprob:  0.596632, 0.279948 (1.409 sec)
29.248... logprob:  0.562863, 0.248698 (1.413 sec)
29.249... logprob:  0.802951, 0.345052 (1.424 sec)
29.250... logprob:  0.765006, 0.364583 (1.400 sec)
29.251... logprob:  0.664752, 0.287760 (1.454 sec)
29.252... logprob:  0.606772, 0.281250 (1.417 sec)
29.253... logprob:  0.595222, 0.274740 (1.403 sec)
29.254... logprob:  0.678421, 0.282552 (1.460 sec)
29.255... logprob:  0.642577, 0.294271 (1.391 sec)
29.256... logprob:  0.639369, 0.300781 (1.416 sec)
29.257... logprob:  0.490122, 0.208333 (1.413 sec)
29.258... logprob:  0.602367, 0.261719 (1.412 sec)
29.259... logprob:  0.617712, 0.273437 (1.396 sec)
29.260... logprob:  0.655180, 0.278646 (1.449 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.512164, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.571985e-03 [1.287413e-07] 
Layer 'conv1' biases: 2.159755e-06 [5.257773e-11] 
Layer 'conv2' weights[0]: 2.566901e-03 [1.284638e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.729315e-10] 
Layer 'conv3' weights[0]: 2.565734e-03 [1.286603e-07] 
Layer 'conv3' biases: 3.584587e-05 [6.788017e-09] 
Layer 'conv4' weights[0]: 2.576605e-03 [1.295237e-07] 
Layer 'conv4' biases: 9.998685e-01 [2.065111e-07] 
Layer 'conv5' weights[0]: 2.741114e-03 [3.259946e-06] 
Layer 'conv5' biases: 9.990478e-01 [3.615627e-06] 
Layer 'fc6' weights[0]: 6.751448e-03 [7.014699e-08] 
Layer 'fc6' biases: 9.999892e-01 [6.672273e-08] 
Layer 'fc7' weights[0]: 7.095723e-03 [1.672171e-07] 
Layer 'fc7' biases: 9.997222e-01 [2.741709e-07] 
Layer 'fc8' weights[0]: 4.792879e-03 [1.599861e-05] 
Layer 'fc8' biases: 2.409165e-02 [4.673184e-05] 
Train error last 800 batches: 0.655430
-------------------------------------------------------
Not saving because 0.512164 > 0.299667 (9.300: -1.18%)
======================================================= (2.337 sec)
29.261... logprob:  0.581381, 0.248698 (1.436 sec)
29.262... logprob:  0.694512, 0.309896 (1.424 sec)
29.263... logprob:  0.605714, 0.281250 (1.438 sec)
29.264... logprob:  0.641916, 0.276042 (1.418 sec)
29.265... logprob:  0.622946, 0.270833 (1.408 sec)
29.266... logprob:  0.586877, 0.256510 (1.410 sec)
29.267... logprob:  0.608151, 0.274740 (1.409 sec)
29.268... logprob:  0.672977, 0.320312 (1.424 sec)
29.269... logprob:  0.754565, 0.332031 (1.399 sec)
29.270... logprob:  0.781311, 0.367188 (1.458 sec)
29.271... logprob:  0.681127, 0.269531 (1.416 sec)
29.272... logprob:  0.584585, 0.276042 (1.409 sec)
29.273... logprob:  0.694996, 0.308594 (1.464 sec)
29.274... logprob:  0.805783, 0.337240 (1.396 sec)
29.275... logprob:  0.711693, 0.304688 (1.416 sec)
29.276... logprob:  0.635753, 0.294271 (1.408 sec)
29.277... logprob:  0.657008, 0.303385 (1.424 sec)
29.278... logprob:  0.541217, 0.270833 (1.414 sec)
29.279... logprob:  0.555554, 0.255208 (1.457 sec)
29.280... logprob:  0.472584, 0.208333 (1.400 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.449984, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.569407e-03 [1.285679e-07] 
Layer 'conv1' biases: 2.160308e-06 [5.059930e-11] 
Layer 'conv2' weights[0]: 2.564315e-03 [1.283055e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.677596e-10] 
Layer 'conv3' weights[0]: 2.563179e-03 [1.284220e-07] 
Layer 'conv3' biases: 3.584394e-05 [5.464251e-09] 
Layer 'conv4' weights[0]: 2.574023e-03 [1.291741e-07] 
Layer 'conv4' biases: 9.998673e-01 [1.630373e-07] 
Layer 'conv5' weights[0]: 2.738226e-03 [2.289646e-06] 
Layer 'conv5' biases: 9.990447e-01 [2.474450e-06] 
Layer 'fc6' weights[0]: 6.750772e-03 [5.842740e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.169923e-08] 
Layer 'fc7' weights[0]: 7.095043e-03 [1.342645e-07] 
Layer 'fc7' biases: 9.997221e-01 [1.842032e-07] 
Layer 'fc8' weights[0]: 4.787021e-03 [1.190308e-05] 
Layer 'fc8' biases: 2.404847e-02 [2.692776e-05] 
Train error last 800 batches: 0.655382
-------------------------------------------------------
Not saving because 0.449984 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
29.281... logprob:  0.603874, 0.273437 (1.430 sec)
29.282... logprob:  0.598942, 0.266927 (1.418 sec)
29.283... logprob:  0.635922, 0.292969 (1.417 sec)
29.284... logprob:  0.534879, 0.239583 (1.434 sec)
29.285... logprob:  0.539164, 0.226562 (1.437 sec)
29.286... logprob:  0.746939, 0.320312 (1.429 sec)
29.287... logprob:  0.539684, 0.240885 (1.422 sec)
29.288... logprob:  0.565364, 0.263021 (1.431 sec)
29.289... logprob:  0.732785, 0.330729 (1.434 sec)
29.290... logprob:  0.657891, 0.285156 (1.402 sec)
29.291... logprob:  0.622488, 0.274740 (1.412 sec)
29.292... logprob:  0.701778, 0.304687 (1.410 sec)
29.293... logprob:  0.636015, 0.304687 (1.416 sec)
29.294... logprob:  0.584598, 0.243490 (1.403 sec)
29.295... logprob:  0.542987, 0.239583 (1.460 sec)
29.296... logprob:  0.596341, 0.268229 (1.414 sec)
29.297... logprob:  0.600387, 0.268229 (1.414 sec)
29.298... logprob:  0.652674, 0.283854 (1.456 sec)
29.299... logprob:  0.584600, 0.268229 (1.397 sec)
29.300... logprob:  0.557746, 0.240885 (1.415 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.432204, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.566839e-03 [1.284680e-07] 
Layer 'conv1' biases: 2.160564e-06 [4.256535e-11] 
Layer 'conv2' weights[0]: 2.561760e-03 [1.281888e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.681589e-10] 
Layer 'conv3' weights[0]: 2.560636e-03 [1.283370e-07] 
Layer 'conv3' biases: 3.582130e-05 [5.563104e-09] 
Layer 'conv4' weights[0]: 2.571445e-03 [1.290722e-07] 
Layer 'conv4' biases: 9.998663e-01 [1.483591e-07] 
Layer 'conv5' weights[0]: 2.735277e-03 [2.271980e-06] 
Layer 'conv5' biases: 9.990298e-01 [2.456763e-06] 
Layer 'fc6' weights[0]: 6.750096e-03 [5.839168e-08] 
Layer 'fc6' biases: 9.999890e-01 [5.219892e-08] 
Layer 'fc7' weights[0]: 7.094334e-03 [1.375664e-07] 
Layer 'fc7' biases: 9.997227e-01 [1.840262e-07] 
Layer 'fc8' weights[0]: 4.823475e-03 [1.157814e-05] 
Layer 'fc8' biases: 2.435923e-02 [2.317383e-05] 
Train error last 800 batches: 0.654207
-------------------------------------------------------
Not saving because 0.432204 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
29.301... logprob:  0.570696, 0.236979 (1.419 sec)
29.302... logprob:  0.804384, 0.305990 (1.410 sec)
29.303... logprob:  0.627166, 0.291667 (1.401 sec)
29.304... logprob:  0.652418, 0.326823 (1.435 sec)
29.305... logprob:  0.737798, 0.332031 (1.429 sec)
29.306... logprob:  0.678934, 0.283854 (1.440 sec)
29.307... logprob:  0.580899, 0.257812 (1.431 sec)
29.308... logprob:  0.574213, 0.270833 (1.443 sec)
29.309... logprob:  0.709991, 0.317708 (1.407 sec)
29.310... logprob:  0.729309, 0.304687 (1.415 sec)
29.311... logprob:  0.731542, 0.298177 (1.420 sec)
29.312... logprob:  0.747284, 0.307292 (1.426 sec)
29.313... logprob:  0.642781, 0.270833 (1.414 sec)
29.314... logprob:  0.642609, 0.287760 (1.458 sec)
29.315... logprob:  0.604399, 0.276042 (1.430 sec)
29.316... logprob:  0.680418, 0.285156 (1.417 sec)
29.317... logprob:  0.643271, 0.291667 (1.472 sec)
29.318... logprob:  0.649258, 0.287760 (1.408 sec)
29.319... logprob:  0.719637, 0.302083 (1.416 sec)
29.320... logprob:  0.684896, 0.283854 (1.415 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.473606, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.564275e-03 [1.282204e-07] 
Layer 'conv1' biases: 2.160980e-06 [4.331997e-11] 
Layer 'conv2' weights[0]: 2.559193e-03 [1.279912e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.211824e-10] 
Layer 'conv3' weights[0]: 2.558065e-03 [1.281818e-07] 
Layer 'conv3' biases: 3.580194e-05 [6.759521e-09] 
Layer 'conv4' weights[0]: 2.568871e-03 [1.288715e-07] 
Layer 'conv4' biases: 9.998666e-01 [2.047838e-07] 
Layer 'conv5' weights[0]: 2.733255e-03 [3.111515e-06] 
Layer 'conv5' biases: 9.990595e-01 [3.363393e-06] 
Layer 'fc6' weights[0]: 6.749365e-03 [7.147529e-08] 
Layer 'fc6' biases: 9.999891e-01 [6.904632e-08] 
Layer 'fc7' weights[0]: 7.093609e-03 [1.704306e-07] 
Layer 'fc7' biases: 9.997205e-01 [2.727231e-07] 
Layer 'fc8' weights[0]: 4.757620e-03 [1.573845e-05] 
Layer 'fc8' biases: 2.385428e-02 [4.431986e-05] 
Train error last 800 batches: 0.654219
-------------------------------------------------------
Not saving because 0.473606 > 0.299667 (9.300: -1.18%)
======================================================= (2.405 sec)
29.321... logprob:  0.567088, 0.261719 (1.425 sec)
29.322... logprob:  0.594160, 0.251302 (1.406 sec)
29.323... logprob:  0.661723, 0.290364 (1.465 sec)
29.324... logprob:  0.689982, 0.308594 (1.423 sec)
29.325... logprob:  0.590964, 0.256510 (1.427 sec)
29.326... logprob:  0.783926, 0.329427 (1.457 sec)
29.327... logprob:  0.700366, 0.315104 (1.417 sec)
29.328... logprob:  0.663873, 0.294271 (1.419 sec)
29.329... logprob:  0.633811, 0.305990 (1.414 sec)
29.330... logprob:  0.504870, 0.226562 (1.410 sec)
29.331... logprob:  0.548056, 0.269531 (1.410 sec)
29.332... logprob:  0.712221, 0.302083 (1.444 sec)
29.333... logprob:  0.651679, 0.303385 (1.437 sec)
29.334... logprob:  0.803069, 0.348958 (1.437 sec)
29.335... logprob:  0.597447, 0.251302 (1.432 sec)
29.336... logprob:  0.758298, 0.330729 (1.452 sec)
29.337... logprob:  0.722650, 0.326823 (1.407 sec)
29.338... logprob:  0.679574, 0.260417 (1.418 sec)
29.339... logprob:  0.689258, 0.274740 (1.418 sec)
29.340... logprob:  0.663532, 0.304687 (1.418 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.404096, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.561703e-03 [1.281301e-07] 
Layer 'conv1' biases: 2.161206e-06 [4.228708e-11] 
Layer 'conv2' weights[0]: 2.556630e-03 [1.278739e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.214351e-10] 
Layer 'conv3' weights[0]: 2.555495e-03 [1.280029e-07] 
Layer 'conv3' biases: 3.578311e-05 [5.756089e-09] 
Layer 'conv4' weights[0]: 2.566320e-03 [1.286728e-07] 
Layer 'conv4' biases: 9.998669e-01 [1.708426e-07] 
Layer 'conv5' weights[0]: 2.731417e-03 [2.389511e-06] 
Layer 'conv5' biases: 9.990630e-01 [2.581045e-06] 
Layer 'fc6' weights[0]: 6.748669e-03 [6.276029e-08] 
Layer 'fc6' biases: 9.999894e-01 [5.756538e-08] 
Layer 'fc7' weights[0]: 7.092902e-03 [1.483774e-07] 
Layer 'fc7' biases: 9.997205e-01 [1.941416e-07] 
Layer 'fc8' weights[0]: 4.745683e-03 [1.230680e-05] 
Layer 'fc8' biases: 2.373405e-02 [2.342625e-05] 
Train error last 800 batches: 0.653812
-------------------------------------------------------
Not saving because 0.404096 > 0.299667 (9.300: -1.18%)
======================================================= (2.370 sec)
29.341... logprob:  0.720584, 0.302083 (1.421 sec)
29.342... logprob:  0.628376, 0.274740 (1.457 sec)
29.343... logprob:  0.669417, 0.272135 (1.432 sec)
29.344... logprob:  0.697056, 0.309896 (1.474 sec)
29.345... logprob:  0.717541, 0.339844 (1.432 sec)
29.346... logprob:  0.644280, 0.294271 (1.432 sec)
29.347... logprob:  0.604189, 0.276042 (1.478 sec)
29.348... logprob:  0.711867, 0.307292 (1.425 sec)
29.349... logprob:  0.597339, 0.286458 (1.427 sec)
29.350... logprob:  0.568477, 0.238281 (1.431 sec)
29.351... logprob:  0.791616, 0.317708 (1.419 sec)
29.352... logprob:  0.622237, 0.282552 (1.426 sec)
29.353... logprob:  0.637132, 0.265625 (1.485 sec)
29.354... logprob:  0.766672, 0.319010 (1.425 sec)
29.355... logprob:  0.616939, 0.263021 (1.437 sec)
29.356... logprob:  0.681941, 0.295573 (1.471 sec)
29.357... logprob:  0.586305, 0.246094 (1.430 sec)
29.358... logprob:  0.622264, 0.283854 (1.435 sec)
29.359... logprob:  0.803315, 0.341146 (1.426 sec)
29.360... logprob:  0.644699, 0.266927 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.516782, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.559152e-03 [1.279592e-07] 
Layer 'conv1' biases: 2.161430e-06 [3.775358e-11] 
Layer 'conv2' weights[0]: 2.554090e-03 [1.277647e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.622595e-10] 
Layer 'conv3' weights[0]: 2.552964e-03 [1.277912e-07] 
Layer 'conv3' biases: 3.578653e-05 [4.486031e-09] 
Layer 'conv4' weights[0]: 2.563739e-03 [1.284088e-07] 
Layer 'conv4' biases: 9.998679e-01 [1.406579e-07] 
Layer 'conv5' weights[0]: 2.730195e-03 [2.154033e-06] 
Layer 'conv5' biases: 9.990730e-01 [2.261190e-06] 
Layer 'fc6' weights[0]: 6.748005e-03 [6.118524e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.504664e-08] 
Layer 'fc7' weights[0]: 7.092208e-03 [1.422178e-07] 
Layer 'fc7' biases: 9.997195e-01 [1.735622e-07] 
Layer 'fc8' weights[0]: 4.717126e-03 [1.210437e-05] 
Layer 'fc8' biases: 2.359923e-02 [1.413014e-05] 
Train error last 800 batches: 0.653670
-------------------------------------------------------
Not saving because 0.516782 > 0.299667 (9.300: -1.18%)
======================================================= (2.368 sec)
29.361... logprob:  0.599771, 0.253906 (1.428 sec)
29.362... logprob:  0.640846, 0.285156 (1.472 sec)
29.363... logprob:  0.799726, 0.320312 (1.434 sec)
29.364... logprob:  0.677132, 0.291667 (1.445 sec)
29.365... logprob:  0.657920, 0.270833 (1.460 sec)
29.366... logprob:  0.709878, 0.315104 (1.439 sec)
29.367... logprob:  0.639122, 0.273437 (1.431 sec)
29.368... logprob:  0.709616, 0.298177 (1.425 sec)
29.369... logprob:  0.646710, 0.285156 (1.418 sec)
29.370... logprob:  0.598228, 0.248698 (1.432 sec)
29.371... logprob:  0.584402, 0.251302 (1.450 sec)
29.372... logprob:  0.666322, 0.292969 (1.448 sec)
29.373... logprob:  0.708336, 0.316406 (1.452 sec)
29.374... logprob:  0.643399, 0.290365 (1.441 sec)
29.375... logprob:  0.646789, 0.290365 (1.458 sec)
29.376... logprob:  0.612210, 0.294271 (1.435 sec)
29.377... logprob:  0.533020, 0.261719 (1.415 sec)
29.378... logprob:  0.638963, 0.294271 (1.425 sec)
29.379... logprob:  0.659054, 0.295573 (1.433 sec)
29.380... logprob:  0.709023, 0.286458 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.364609, 0.062500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.556604e-03 [1.279284e-07] 
Layer 'conv1' biases: 2.161438e-06 [5.248995e-11] 
Layer 'conv2' weights[0]: 2.551519e-03 [1.276709e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.019762e-10] 
Layer 'conv3' weights[0]: 2.550404e-03 [1.279510e-07] 
Layer 'conv3' biases: 3.578423e-05 [6.983832e-09] 
Layer 'conv4' weights[0]: 2.561178e-03 [1.287655e-07] 
Layer 'conv4' biases: 9.998698e-01 [2.134933e-07] 
Layer 'conv5' weights[0]: 2.728908e-03 [3.340839e-06] 
Layer 'conv5' biases: 9.990608e-01 [3.652644e-06] 
Layer 'fc6' weights[0]: 6.747291e-03 [6.959865e-08] 
Layer 'fc6' biases: 9.999892e-01 [6.589469e-08] 
Layer 'fc7' weights[0]: 7.091500e-03 [1.673409e-07] 
Layer 'fc7' biases: 9.997199e-01 [2.723270e-07] 
Layer 'fc8' weights[0]: 4.740755e-03 [1.610937e-05] 
Layer 'fc8' biases: 2.380537e-02 [4.302388e-05] 
Train error last 800 batches: 0.653654
-------------------------------------------------------
Not saving because 0.364609 > 0.299667 (9.300: -1.18%)
======================================================= (2.395 sec)
29.381... logprob:  0.638416, 0.266927 (1.474 sec)
29.382... logprob:  0.750818, 0.313802 (1.449 sec)
29.383... logprob:  0.576478, 0.233073 (1.432 sec)
29.384... logprob:  0.813699, 0.352865 (1.472 sec)
29.385... logprob:  0.682243, 0.309896 (1.438 sec)
29.386... logprob:  0.698463, 0.294271 (1.421 sec)
29.387... logprob:  0.645947, 0.290365 (1.425 sec)
29.388... logprob:  0.672477, 0.309896 (1.432 sec)
29.389... logprob:  0.637555, 0.290365 (1.425 sec)
29.390... logprob:  0.598498, 0.255208 (1.472 sec)
29.391... logprob:  0.536542, 0.256510 (1.433 sec)
29.392... logprob:  0.642750, 0.291667 (1.432 sec)
29.393... logprob:  0.588355, 0.255208 (1.478 sec)
29.394... logprob:  0.521861, 0.216146 (1.428 sec)
29.395... logprob:  0.500505, 0.194010 (1.426 sec)
29.396... logprob:  0.573961, 0.264323 (1.431 sec)
29.397... logprob:  0.646405, 0.278646 (1.420 sec)
29.398... logprob:  0.705360, 0.294271 (1.426 sec)
29.399... logprob:  0.711432, 0.316406 (1.484 sec)
29.400... logprob:  0.793117, 0.328125 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.420758, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.554033e-03 [1.276984e-07] 
Layer 'conv1' biases: 2.161630e-06 [3.876269e-11] 
Layer 'conv2' weights[0]: 2.548969e-03 [1.274809e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.253302e-10] 
Layer 'conv3' weights[0]: 2.547847e-03 [1.276498e-07] 
Layer 'conv3' biases: 3.578632e-05 [5.432286e-09] 
Layer 'conv4' weights[0]: 2.558614e-03 [1.283087e-07] 
Layer 'conv4' biases: 9.998701e-01 [1.526521e-07] 
Layer 'conv5' weights[0]: 2.726835e-03 [2.570561e-06] 
Layer 'conv5' biases: 9.990488e-01 [2.756193e-06] 
Layer 'fc6' weights[0]: 6.746616e-03 [6.284868e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.769138e-08] 
Layer 'fc7' weights[0]: 7.090787e-03 [1.488880e-07] 
Layer 'fc7' biases: 9.997204e-01 [2.005002e-07] 
Layer 'fc8' weights[0]: 4.772379e-03 [1.486611e-05] 
Layer 'fc8' biases: 2.404546e-02 [3.844455e-05] 
Train error last 800 batches: 0.653196
-------------------------------------------------------
Not saving because 0.420758 > 0.299667 (9.300: -1.18%)
======================================================= (2.362 sec)
29.401... logprob:  0.670019, 0.276042 (1.441 sec)
29.402... logprob:  0.690878, 0.290365 (1.474 sec)
29.403... logprob:  0.618511, 0.282552 (1.427 sec)
29.404... logprob:  0.728389, 0.296875 (1.450 sec)
29.405... logprob:  0.675925, 0.300781 (1.429 sec)
29.406... logprob:  0.588982, 0.266927 (1.422 sec)
29.407... logprob:  0.655083, 0.313802 (1.424 sec)
29.408... logprob:  0.616732, 0.272135 (1.476 sec)
29.409... logprob:  0.609988, 0.265625 (1.432 sec)
29.410... logprob:  0.757190, 0.319010 (1.445 sec)
29.411... logprob:  0.601503, 0.255208 (1.466 sec)
29.412... logprob:  0.743365, 0.333333 (1.426 sec)
29.413... logprob:  0.678874, 0.296875 (1.435 sec)
29.414... logprob:  0.649818, 0.307292 (1.423 sec)
29.415... logprob:  0.642256, 0.304687 (1.421 sec)
29.416... logprob:  0.677199, 0.296875 (1.427 sec)
29.417... logprob:  0.604413, 0.285156 (1.459 sec)
29.418... logprob:  0.563704, 0.253906 (1.446 sec)
29.419... logprob:  0.641081, 0.282552 (1.449 sec)
29.420... logprob:  0.684016, 0.299479 (1.445 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.456107, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.551491e-03 [1.275752e-07] 
Layer 'conv1' biases: 2.161819e-06 [4.867246e-11] 
Layer 'conv2' weights[0]: 2.546424e-03 [1.273638e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.611640e-10] 
Layer 'conv3' weights[0]: 2.545288e-03 [1.274734e-07] 
Layer 'conv3' biases: 3.578488e-05 [4.944805e-09] 
Layer 'conv4' weights[0]: 2.556064e-03 [1.280906e-07] 
Layer 'conv4' biases: 9.998695e-01 [1.198554e-07] 
Layer 'conv5' weights[0]: 2.724134e-03 [2.052004e-06] 
Layer 'conv5' biases: 9.990489e-01 [2.197351e-06] 
Layer 'fc6' weights[0]: 6.745896e-03 [5.943096e-08] 
Layer 'fc6' biases: 9.999891e-01 [5.312998e-08] 
Layer 'fc7' weights[0]: 7.090078e-03 [1.373288e-07] 
Layer 'fc7' biases: 9.997202e-01 [1.795726e-07] 
Layer 'fc8' weights[0]: 4.759479e-03 [1.220654e-05] 
Layer 'fc8' biases: 2.396595e-02 [1.763436e-05] 
Train error last 800 batches: 0.653028
-------------------------------------------------------
Not saving because 0.456107 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
29.421... logprob:  0.546669, 0.259115 (1.455 sec)
29.422... logprob:  0.692352, 0.305990 (1.437 sec)
29.423... logprob:  0.625473, 0.282552 (1.420 sec)
29.424... logprob:  0.592056, 0.261719 (1.421 sec)
29.425... logprob:  0.553079, 0.239583 (1.434 sec)
29.426... logprob:  0.588925, 0.264323 (1.437 sec)
29.427... logprob:  0.667671, 0.272135 (1.458 sec)
29.428... logprob:  0.735206, 0.311198 (1.443 sec)
29.429... logprob:  0.638735, 0.304688 (1.440 sec)
29.430... logprob:  0.512658, 0.223958 (1.471 sec)
29.431... logprob:  0.812125, 0.367187 (1.426 sec)
29.432... logprob:  0.609443, 0.266927 (1.424 sec)
29.433... logprob:  0.666307, 0.312500 (1.423 sec)
29.434... logprob:  0.665343, 0.296875 (1.434 sec)
29.435... logprob:  0.589500, 0.251302 (1.426 sec)
29.436... logprob:  0.561390, 0.234375 (1.471 sec)
29.437... logprob:  0.628228, 0.272135 (1.439 sec)
29.438... logprob:  0.801200, 0.360677 (1.421 sec)
29.439... logprob:  0.612391, 0.278646 (1.483 sec)
29.440... logprob:  0.591475, 0.282552 (1.423 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.467261, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.548940e-03 [1.274422e-07] 
Layer 'conv1' biases: 2.162174e-06 [4.666528e-11] 
Layer 'conv2' weights[0]: 2.543891e-03 [1.272177e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.731981e-10] 
Layer 'conv3' weights[0]: 2.542749e-03 [1.273042e-07] 
Layer 'conv3' biases: 3.578387e-05 [4.727198e-09] 
Layer 'conv4' weights[0]: 2.553513e-03 [1.279509e-07] 
Layer 'conv4' biases: 9.998686e-01 [1.497722e-07] 
Layer 'conv5' weights[0]: 2.720921e-03 [1.882233e-06] 
Layer 'conv5' biases: 9.990385e-01 [2.114098e-06] 
Layer 'fc6' weights[0]: 6.745216e-03 [5.692473e-08] 
Layer 'fc6' biases: 9.999889e-01 [5.003913e-08] 
Layer 'fc7' weights[0]: 7.089407e-03 [1.294379e-07] 
Layer 'fc7' biases: 9.997209e-01 [1.530313e-07] 
Layer 'fc8' weights[0]: 4.785318e-03 [1.065179e-05] 
Layer 'fc8' biases: 2.422351e-02 [6.529910e-06] 
Train error last 800 batches: 0.652310
-------------------------------------------------------
Not saving because 0.467261 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
29.441... logprob:  0.658400, 0.296875 (1.433 sec)
29.442... logprob:  0.547778, 0.255208 (1.435 sec)
29.443... logprob:  0.712598, 0.294271 (1.426 sec)
29.444... logprob:  0.642337, 0.286458 (1.425 sec)
29.445... logprob:  0.652910, 0.300781 (1.478 sec)
29.446... logprob:  0.764074, 0.361979 (1.431 sec)
29.447... logprob:  0.803704, 0.333333 (1.436 sec)
29.448... logprob:  0.615379, 0.290365 (1.474 sec)
29.449... logprob:  0.534602, 0.242187 (1.428 sec)
29.450... logprob:  0.476715, 0.221354 (1.427 sec)
29.451... logprob:  0.744853, 0.304687 (1.439 sec)
29.452... logprob:  0.730099, 0.342448 (1.423 sec)
29.453... logprob:  0.658577, 0.273437 (1.430 sec)
29.454... logprob:  0.674213, 0.298177 (1.474 sec)
29.455... logprob:  0.674828, 0.305990 (1.433 sec)
29.456... logprob:  0.719176, 0.321615 (1.439 sec)
29.457... logprob:  0.625096, 0.268229 (1.469 sec)
29.458... logprob:  0.651908, 0.302083 (1.426 sec)
29.459... logprob:  0.738149, 0.328125 (1.431 sec)
29.460... logprob:  0.508813, 0.222656 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.507913, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.546380e-03 [1.273407e-07] 
Layer 'conv1' biases: 2.162495e-06 [4.522376e-11] 
Layer 'conv2' weights[0]: 2.541335e-03 [1.271226e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.927124e-10] 
Layer 'conv3' weights[0]: 2.540210e-03 [1.273419e-07] 
Layer 'conv3' biases: 3.576502e-05 [6.333352e-09] 
Layer 'conv4' weights[0]: 2.550945e-03 [1.280022e-07] 
Layer 'conv4' biases: 9.998684e-01 [1.765288e-07] 
Layer 'conv5' weights[0]: 2.718756e-03 [2.255297e-06] 
Layer 'conv5' biases: 9.990433e-01 [2.406830e-06] 
Layer 'fc6' weights[0]: 6.744540e-03 [5.857768e-08] 
Layer 'fc6' biases: 9.999890e-01 [5.249710e-08] 
Layer 'fc7' weights[0]: 7.088689e-03 [1.347653e-07] 
Layer 'fc7' biases: 9.997200e-01 [1.616604e-07] 
Layer 'fc8' weights[0]: 4.768354e-03 [1.098477e-05] 
Layer 'fc8' biases: 2.410280e-02 [1.250247e-05] 
Train error last 800 batches: 0.652478
-------------------------------------------------------
Not saving because 0.507913 > 0.299667 (9.300: -1.18%)
======================================================= (2.369 sec)
29.461... logprob:  0.691066, 0.312500 (1.433 sec)
29.462... logprob:  0.690984, 0.311198 (1.437 sec)
29.463... logprob:  0.606910, 0.276042 (1.471 sec)
29.464... logprob:  0.743059, 0.335938 (1.449 sec)
29.465... logprob:  0.640892, 0.289062 (1.453 sec)
29.466... logprob:  0.630761, 0.283854 (1.451 sec)
29.467... logprob:  0.568788, 0.236979 (1.447 sec)
29.468... logprob:  0.638155, 0.276042 (1.436 sec)
29.469... logprob:  0.605297, 0.256510 (1.422 sec)
29.470... logprob:  0.607801, 0.257812 (1.423 sec)
29.471... logprob:  0.641502, 0.315104 (1.431 sec)
29.472... logprob:  0.602128, 0.285156 (1.445 sec)
29.473... logprob:  0.581398, 0.269531 (1.446 sec)
29.474... logprob:  0.643300, 0.291666 (1.444 sec)
29.475... logprob:  0.729149, 0.313802 (1.439 sec)
29.476... logprob:  0.755398, 0.303385 (1.464 sec)
29.477... logprob:  0.599748, 0.277344 (1.434 sec)
29.478... logprob:  0.661283, 0.304687 (1.415 sec)
29.479... logprob:  0.481861, 0.234375 (1.429 sec)
29.480... logprob:  0.655922, 0.304687 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.464592, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.543839e-03 [1.272499e-07] 
Layer 'conv1' biases: 2.162862e-06 [5.531910e-11] 
Layer 'conv2' weights[0]: 2.538795e-03 [1.270124e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.272076e-10] 
Layer 'conv3' weights[0]: 2.537678e-03 [1.273617e-07] 
Layer 'conv3' biases: 3.576516e-05 [7.548263e-09] 
Layer 'conv4' weights[0]: 2.548401e-03 [1.281393e-07] 
Layer 'conv4' biases: 9.998685e-01 [2.054001e-07] 
Layer 'conv5' weights[0]: 2.716363e-03 [2.607571e-06] 
Layer 'conv5' biases: 9.990363e-01 [2.769739e-06] 
Layer 'fc6' weights[0]: 6.743860e-03 [5.940120e-08] 
Layer 'fc6' biases: 9.999889e-01 [5.342648e-08] 
Layer 'fc7' weights[0]: 7.087979e-03 [1.365851e-07] 
Layer 'fc7' biases: 9.997204e-01 [1.823990e-07] 
Layer 'fc8' weights[0]: 4.776147e-03 [1.180686e-05] 
Layer 'fc8' biases: 2.416113e-02 [2.312428e-05] 
Train error last 800 batches: 0.652423
-------------------------------------------------------
Not saving because 0.464592 > 0.299667 (9.300: -1.18%)
======================================================= (2.363 sec)
29.481... logprob:  0.769186, 0.313802 (1.438 sec)
29.482... logprob:  0.649515, 0.296875 (1.472 sec)
29.483... logprob:  0.704137, 0.343750 (1.441 sec)
29.484... logprob:  0.711068, 0.304687 (1.431 sec)
29.485... logprob:  0.608309, 0.263021 (1.477 sec)
29.486... logprob:  0.552071, 0.257812 (1.424 sec)
29.487... logprob:  0.645986, 0.272135 (1.425 sec)
29.488... logprob:  0.613222, 0.273438 (1.429 sec)
29.489... logprob:  0.691276, 0.303385 (1.424 sec)
29.490... logprob:  0.645805, 0.255208 (1.426 sec)
29.491... logprob:  0.603618, 0.296875 (1.475 sec)
29.492... logprob:  0.673420, 0.272135 (1.437 sec)
29.493... logprob:  0.750986, 0.309896 (1.430 sec)
29.494... logprob:  0.657799, 0.263021 (1.486 sec)
29.495... logprob:  0.631217, 0.279948 (1.427 sec)
29.496... logprob:  0.859861, 0.386719 (1.435 sec)
29.497... logprob:  0.623706, 0.273437 (1.427 sec)
29.498... logprob:  0.665089, 0.295573 (1.422 sec)
29.499... logprob:  0.569652, 0.263021 (1.430 sec)
29.500... logprob:  0.547552, 0.239583 (1.482 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.520064, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.541313e-03 [1.271151e-07] 
Layer 'conv1' biases: 2.163189e-06 [6.335364e-11] 
Layer 'conv2' weights[0]: 2.536272e-03 [1.268514e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.005519e-10] 
Layer 'conv3' weights[0]: 2.535135e-03 [1.270196e-07] 
Layer 'conv3' biases: 3.578353e-05 [6.572776e-09] 
Layer 'conv4' weights[0]: 2.545837e-03 [1.277788e-07] 
Layer 'conv4' biases: 9.998681e-01 [2.148153e-07] 
Layer 'conv5' weights[0]: 2.714166e-03 [2.059304e-06] 
Layer 'conv5' biases: 9.990549e-01 [2.165806e-06] 
Layer 'fc6' weights[0]: 6.743161e-03 [5.855353e-08] 
Layer 'fc6' biases: 9.999891e-01 [5.215849e-08] 
Layer 'fc7' weights[0]: 7.087300e-03 [1.352887e-07] 
Layer 'fc7' biases: 9.997190e-01 [1.680393e-07] 
Layer 'fc8' weights[0]: 4.735523e-03 [1.191015e-05] 
Layer 'fc8' biases: 2.386914e-02 [1.955701e-05] 
Train error last 800 batches: 0.652670
-------------------------------------------------------
Not saving because 0.520064 > 0.299667 (9.300: -1.18%)
======================================================= (2.419 sec)
29.501... logprob:  0.594361, 0.257812 (1.437 sec)
29.502... logprob:  0.729858, 0.299479 (1.442 sec)
29.503... logprob:  0.580742, 0.239583 (1.469 sec)
29.504... logprob:  0.697646, 0.282552 (1.427 sec)
29.505... logprob:  0.765886, 0.311198 (1.431 sec)
29.506... logprob:  0.623989, 0.265625 (1.429 sec)
29.507... logprob:  0.562926, 0.235677 (1.420 sec)
29.508... logprob:  0.595415, 0.273437 (1.427 sec)
29.509... logprob:  0.552195, 0.236979 (1.473 sec)
29.510... logprob:  0.607705, 0.287760 (1.432 sec)
29.511... logprob:  0.560881, 0.247396 (1.446 sec)
29.512... logprob:  0.699036, 0.283854 (1.462 sec)
29.513... logprob:  0.616725, 0.242187 (1.437 sec)
29.514... logprob:  0.710605, 0.311198 (1.432 sec)
29.515... logprob:  0.637880, 0.259115 (1.450 sec)
29.516... logprob:  0.559991, 0.256510 (1.418 sec)
29.517... logprob:  0.771609, 0.328125 (1.434 sec)
29.518... logprob:  0.590920, 0.270833 (1.451 sec)
29.519... logprob:  0.735034, 0.320312 (1.447 sec)
29.520... logprob:  0.699078, 0.302083 (1.448 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.394523, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.538762e-03 [1.269748e-07] 
Layer 'conv1' biases: 2.163355e-06 [3.301014e-11] 
Layer 'conv2' weights[0]: 2.533729e-03 [1.267399e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.144581e-10] 
Layer 'conv3' weights[0]: 2.532592e-03 [1.268183e-07] 
Layer 'conv3' biases: 3.579659e-05 [4.769082e-09] 
Layer 'conv4' weights[0]: 2.543315e-03 [1.274795e-07] 
Layer 'conv4' biases: 9.998682e-01 [1.345325e-07] 
Layer 'conv5' weights[0]: 2.711783e-03 [2.029980e-06] 
Layer 'conv5' biases: 9.990494e-01 [2.205710e-06] 
Layer 'fc6' weights[0]: 6.742456e-03 [6.086202e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.532818e-08] 
Layer 'fc7' weights[0]: 7.086651e-03 [1.419686e-07] 
Layer 'fc7' biases: 9.997196e-01 [1.789684e-07] 
Layer 'fc8' weights[0]: 4.756944e-03 [1.298197e-05] 
Layer 'fc8' biases: 2.405620e-02 [2.262288e-05] 
Train error last 800 batches: 0.652355
-------------------------------------------------------
Not saving because 0.394523 > 0.299667 (9.300: -1.18%)
======================================================= (2.376 sec)
29.521... logprob:  0.688726, 0.308594 (1.458 sec)
29.522... logprob:  0.721478, 0.321615 (1.461 sec)
29.523... logprob:  0.649395, 0.308594 (1.432 sec)
29.524... logprob:  0.759098, 0.312500 (1.422 sec)
29.525... logprob:  0.660650, 0.243490 (1.430 sec)
29.526... logprob:  0.577313, 0.273437 (1.438 sec)
29.527... logprob:  0.732789, 0.302083 (1.435 sec)
29.528... logprob:  0.576130, 0.247396 (1.458 sec)
29.529... logprob:  0.606741, 0.276042 (1.445 sec)
29.530... logprob:  0.646609, 0.290365 (1.434 sec)
29.531... logprob:  0.660321, 0.328125 (1.474 sec)
29.532... logprob:  0.620264, 0.285156 (1.425 sec)
29.533... logprob:  0.871207, 0.341146 (1.422 sec)
29.534... logprob:  0.529592, 0.238281 (1.429 sec)
29.535... logprob:  0.797512, 0.312500 (1.429 sec)
29.536... logprob:  0.733594, 0.316406 (1.422 sec)
29.537... logprob:  0.655688, 0.286458 (1.476 sec)
29.538... logprob:  0.714596, 0.311198 (1.433 sec)
29.539... logprob:  0.519679, 0.239583 (1.430 sec)
29.540... logprob:  0.764372, 0.335937 (1.476 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.507532, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.536218e-03 [1.268233e-07] 
Layer 'conv1' biases: 2.163513e-06 [4.812038e-11] 
Layer 'conv2' weights[0]: 2.531206e-03 [1.266097e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.449407e-10] 
Layer 'conv3' weights[0]: 2.530056e-03 [1.268337e-07] 
Layer 'conv3' biases: 3.578820e-05 [6.288399e-09] 
Layer 'conv4' weights[0]: 2.540778e-03 [1.275608e-07] 
Layer 'conv4' biases: 9.998677e-01 [2.141776e-07] 
Layer 'conv5' weights[0]: 2.709015e-03 [2.425435e-06] 
Layer 'conv5' biases: 9.990659e-01 [2.591327e-06] 
Layer 'fc6' weights[0]: 6.741732e-03 [6.210502e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.679945e-08] 
Layer 'fc7' weights[0]: 7.085903e-03 [1.438400e-07] 
Layer 'fc7' biases: 9.997181e-01 [1.834187e-07] 
Layer 'fc8' weights[0]: 4.723329e-03 [1.208304e-05] 
Layer 'fc8' biases: 2.379513e-02 [2.103296e-05] 
Train error last 800 batches: 0.652670
-------------------------------------------------------
Not saving because 0.507532 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
29.541... logprob:  0.618267, 0.264323 (1.437 sec)
29.542... logprob:  0.618746, 0.273437 (1.432 sec)
29.543... logprob:  0.568190, 0.279948 (1.428 sec)
29.544... logprob:  0.551338, 0.260417 (1.448 sec)
29.545... logprob:  0.593783, 0.274740 (1.429 sec)
29.546... logprob:  0.648079, 0.298177 (1.478 sec)
29.547... logprob:  0.749905, 0.356771 (1.428 sec)
29.548... logprob:  0.572691, 0.273438 (1.437 sec)
29.549... logprob:  0.685930, 0.295573 (1.473 sec)
29.550... logprob:  0.554648, 0.246094 (1.429 sec)
29.551... logprob:  0.615352, 0.247396 (1.423 sec)
29.552... logprob:  0.660426, 0.292969 (1.433 sec)
29.553... logprob:  0.615575, 0.264323 (1.437 sec)
29.554... logprob:  0.718319, 0.298177 (1.429 sec)
29.555... logprob:  0.584325, 0.225260 (1.471 sec)
29.556... logprob:  0.658552, 0.300781 (1.437 sec)
29.557... logprob:  0.685344, 0.304687 (1.442 sec)
29.558... logprob:  0.653439, 0.283854 (1.465 sec)
29.559... logprob:  0.703327, 0.292969 (1.527 sec)
29.560... logprob:  0.497671, 0.231771 (1.435 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.461494, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.533686e-03 [1.266877e-07] 
Layer 'conv1' biases: 2.163782e-06 [5.263947e-11] 
Layer 'conv2' weights[0]: 2.528658e-03 [1.264677e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.704914e-10] 
Layer 'conv3' weights[0]: 2.527530e-03 [1.266366e-07] 
Layer 'conv3' biases: 3.580104e-05 [5.455387e-09] 
Layer 'conv4' weights[0]: 2.538213e-03 [1.272776e-07] 
Layer 'conv4' biases: 9.998658e-01 [1.508148e-07] 
Layer 'conv5' weights[0]: 2.705583e-03 [2.119099e-06] 
Layer 'conv5' biases: 9.990461e-01 [2.235217e-06] 
Layer 'fc6' weights[0]: 6.741058e-03 [5.957409e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.352936e-08] 
Layer 'fc7' weights[0]: 7.085126e-03 [1.341194e-07] 
Layer 'fc7' biases: 9.997194e-01 [1.626747e-07] 
Layer 'fc8' weights[0]: 4.772217e-03 [1.123878e-05] 
Layer 'fc8' biases: 2.416100e-02 [1.256428e-05] 
Train error last 800 batches: 0.652804
-------------------------------------------------------
Not saving because 0.461494 > 0.299667 (9.300: -1.18%)
======================================================= (2.406 sec)
29.561... logprob:  0.657758, 0.266927 (1.431 sec)
29.562... logprob:  0.753353, 0.333333 (1.418 sec)
29.563... logprob:  0.629985, 0.283854 (1.427 sec)
29.564... logprob:  0.680047, 0.312500 (1.464 sec)
29.565... logprob:  0.788390, 0.330729 (1.443 sec)
29.566... logprob:  0.570722, 0.252604 (1.445 sec)
29.567... logprob:  0.606885, 0.265625 (1.448 sec)
29.568... logprob:  0.734849, 0.329427 (1.452 sec)
29.569... logprob:  0.666306, 0.279948 (1.430 sec)
29.570... logprob:  0.672800, 0.283854 (1.423 sec)
29.571... logprob:  0.631335, 0.296875 (1.424 sec)
29.572... logprob:  0.792623, 0.339844 (1.432 sec)
29.573... logprob:  0.768023, 0.317708 (1.440 sec)
29.574... logprob:  0.620973, 0.264323 (1.456 sec)
29.575... logprob:  0.580401, 0.261719 (1.448 sec)
29.576... logprob:  0.679506, 0.287760 (1.433 sec)
29.577... logprob:  0.719273, 0.309896 (1.475 sec)
29.578... logprob:  0.617390, 0.292969 (1.430 sec)
29.579... logprob:  0.636463, 0.303385 (1.429 sec)
29.580... logprob:  0.729267, 0.296875 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.551446, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.531155e-03 [1.266320e-07] 
Layer 'conv1' biases: 2.163982e-06 [4.717715e-11] 
Layer 'conv2' weights[0]: 2.526129e-03 [1.263716e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.943661e-10] 
Layer 'conv3' weights[0]: 2.525019e-03 [1.266715e-07] 
Layer 'conv3' biases: 3.583436e-05 [7.558744e-09] 
Layer 'conv4' weights[0]: 2.535694e-03 [1.274514e-07] 
Layer 'conv4' biases: 9.998670e-01 [2.263884e-07] 
Layer 'conv5' weights[0]: 2.704053e-03 [2.135446e-06] 
Layer 'conv5' biases: 9.990693e-01 [2.254332e-06] 
Layer 'fc6' weights[0]: 6.740323e-03 [5.972268e-08] 
Layer 'fc6' biases: 9.999893e-01 [5.344210e-08] 
Layer 'fc7' weights[0]: 7.084451e-03 [1.367641e-07] 
Layer 'fc7' biases: 9.997174e-01 [1.680241e-07] 
Layer 'fc8' weights[0]: 4.713059e-03 [1.192542e-05] 
Layer 'fc8' biases: 2.372628e-02 [1.878391e-05] 
Train error last 800 batches: 0.652559
-------------------------------------------------------
Not saving because 0.551446 > 0.299667 (9.300: -1.18%)
======================================================= (2.349 sec)
29.581... logprob:  0.811972, 0.320312 (1.447 sec)
29.582... logprob:  0.685559, 0.298177 (1.433 sec)
29.583... logprob:  0.659651, 0.299479 (1.468 sec)
29.584... logprob:  0.731649, 0.300781 (1.443 sec)
29.585... logprob:  0.664168, 0.315104 (1.429 sec)
29.586... logprob:  0.638096, 0.291667 (1.484 sec)
29.587... logprob:  0.628883, 0.276042 (1.440 sec)
29.588... logprob:  0.637500, 0.261719 (1.424 sec)
29.589... logprob:  0.624216, 0.274740 (1.430 sec)
29.590... logprob:  0.695710, 0.308594 (1.424 sec)
29.591... logprob:  0.558354, 0.236979 (1.443 sec)
29.592... logprob:  0.712471, 0.320312 (1.475 sec)
29.593... logprob:  0.732484, 0.311198 (1.430 sec)
29.594... logprob:  0.646516, 0.307292 (1.435 sec)
29.595... logprob:  0.657470, 0.290364 (1.476 sec)
29.596... logprob:  0.708948, 0.332031 (1.426 sec)
29.597... logprob:  0.667449, 0.292969 (1.427 sec)
29.598... logprob:  0.654563, 0.298177 (1.427 sec)
29.599... logprob:  0.668438, 0.330729 (1.431 sec)
29.600... logprob:  0.601685, 0.277344 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.431561, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.528630e-03 [1.265996e-07] 
Layer 'conv1' biases: 2.164063e-06 [6.382537e-11] 
Layer 'conv2' weights[0]: 2.523604e-03 [1.263172e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.012011e-09] 
Layer 'conv3' weights[0]: 2.522502e-03 [1.267405e-07] 
Layer 'conv3' biases: 3.583207e-05 [8.795334e-09] 
Layer 'conv4' weights[0]: 2.533159e-03 [1.277157e-07] 
Layer 'conv4' biases: 9.998667e-01 [2.703392e-07] 
Layer 'conv5' weights[0]: 2.701656e-03 [3.773404e-06] 
Layer 'conv5' biases: 9.990624e-01 [4.131344e-06] 
Layer 'fc6' weights[0]: 6.739615e-03 [7.758900e-08] 
Layer 'fc6' biases: 9.999892e-01 [7.579065e-08] 
Layer 'fc7' weights[0]: 7.083735e-03 [1.915549e-07] 
Layer 'fc7' biases: 9.997184e-01 [3.509000e-07] 
Layer 'fc8' weights[0]: 4.739367e-03 [1.964708e-05] 
Layer 'fc8' biases: 2.395201e-02 [6.674354e-05] 
Train error last 800 batches: 0.653085
-------------------------------------------------------
Not saving because 0.431561 > 0.299667 (9.300: -1.18%)
======================================================= (2.354 sec)
29.601... logprob:  0.596237, 0.268229 (1.486 sec)
29.602... logprob:  0.642961, 0.291667 (1.428 sec)
29.603... logprob:  0.546867, 0.256510 (1.438 sec)
29.604... logprob:  0.733531, 0.330729 (1.466 sec)
29.605... logprob:  0.742841, 0.307292 (1.430 sec)
29.606... logprob:  0.567430, 0.276042 (1.433 sec)
29.607... logprob:  0.587859, 0.247396 (1.427 sec)
29.608... logprob:  0.522018, 0.244791 (1.416 sec)
29.609... logprob:  0.644450, 0.290365 (1.430 sec)
29.610... logprob:  0.703243, 0.311198 (1.466 sec)
29.611... logprob:  0.792963, 0.359375 (1.439 sec)
29.612... logprob:  0.631135, 0.278646 (1.445 sec)
29.613... logprob:  0.516858, 0.229167 (1.454 sec)
29.614... logprob:  0.702461, 0.289062 (1.445 sec)
29.615... logprob:  0.649971, 0.277344 (1.431 sec)
29.616... logprob:  0.670880, 0.292969 (1.425 sec)
29.617... logprob:  0.647999, 0.274740 (1.420 sec)
29.618... logprob:  0.750504, 0.346354 (1.431 sec)
29.619... logprob:  0.645217, 0.292969 (1.444 sec)
29.620... logprob:  0.798585, 0.320312 (1.444 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.363697, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.526095e-03 [1.263385e-07] 
Layer 'conv1' biases: 2.164017e-06 [6.542949e-11] 
Layer 'conv2' weights[0]: 2.521087e-03 [1.260995e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.058718e-09] 
Layer 'conv3' weights[0]: 2.519968e-03 [1.266070e-07] 
Layer 'conv3' biases: 3.583860e-05 [9.335296e-09] 
Layer 'conv4' weights[0]: 2.530633e-03 [1.272045e-07] 
Layer 'conv4' biases: 9.998658e-01 [2.588047e-07] 
Layer 'conv5' weights[0]: 2.699273e-03 [3.448645e-06] 
Layer 'conv5' biases: 9.990363e-01 [3.842988e-06] 
Layer 'fc6' weights[0]: 6.738912e-03 [7.187152e-08] 
Layer 'fc6' biases: 9.999891e-01 [6.991742e-08] 
Layer 'fc7' weights[0]: 7.083005e-03 [1.710383e-07] 
Layer 'fc7' biases: 9.997202e-01 [2.721188e-07] 
Layer 'fc8' weights[0]: 4.808860e-03 [1.508945e-05] 
Layer 'fc8' biases: 2.459538e-02 [3.750172e-05] 
Train error last 800 batches: 0.652965
-------------------------------------------------------
Not saving because 0.363697 > 0.299667 (9.300: -1.18%)
======================================================= (2.339 sec)
29.621... logprob:  0.604364, 0.291667 (1.456 sec)
29.622... logprob:  0.684891, 0.309896 (1.443 sec)
29.623... logprob:  0.624671, 0.269531 (1.456 sec)
29.624... logprob:  0.606067, 0.278646 (1.430 sec)
29.625... logprob:  0.735604, 0.351562 (1.421 sec)
29.626... logprob:  0.600226, 0.264323 (1.423 sec)
29.627... logprob:  0.689333, 0.320312 (1.433 sec)
29.628... logprob:  0.683114, 0.319010 (1.428 sec)
29.629... logprob:  0.584675, 0.248698 (1.494 sec)
29.630... logprob:  0.604243, 0.264323 (1.440 sec)
29.631... logprob:  0.856527, 0.361979 (1.432 sec)
29.632... logprob:  0.532175, 0.238281 (1.479 sec)
29.633... logprob:  0.659805, 0.272135 (1.423 sec)
29.634... logprob:  0.946983, 0.385417 (1.426 sec)
29.635... logprob:  0.586782, 0.260417 (1.424 sec)
29.636... logprob:  0.689424, 0.290365 (1.430 sec)
29.637... logprob:  0.618119, 0.251302 (1.431 sec)
29.638... logprob:  0.741844, 0.276042 (1.477 sec)
29.639... logprob:  0.737086, 0.321614 (1.435 sec)
29.640... logprob:  0.731648, 0.315104 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.478504, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.523574e-03 [1.262151e-07] 
Layer 'conv1' biases: 2.164194e-06 [7.411696e-11] 
Layer 'conv2' weights[0]: 2.518566e-03 [1.259681e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.878639e-10] 
Layer 'conv3' weights[0]: 2.517454e-03 [1.264319e-07] 
Layer 'conv3' biases: 3.587065e-05 [9.205664e-09] 
Layer 'conv4' weights[0]: 2.528093e-03 [1.271609e-07] 
Layer 'conv4' biases: 9.998651e-01 [2.560425e-07] 
Layer 'conv5' weights[0]: 2.696222e-03 [4.108831e-06] 
Layer 'conv5' biases: 9.990768e-01 [4.579227e-06] 
Layer 'fc6' weights[0]: 6.738244e-03 [8.058757e-08] 
Layer 'fc6' biases: 9.999894e-01 [8.071058e-08] 
Layer 'fc7' weights[0]: 7.082369e-03 [1.978795e-07] 
Layer 'fc7' biases: 9.997172e-01 [3.442505e-07] 
Layer 'fc8' weights[0]: 4.722361e-03 [1.898552e-05] 
Layer 'fc8' biases: 2.388735e-02 [6.123276e-05] 
Train error last 800 batches: 0.653773
-------------------------------------------------------
Not saving because 0.478504 > 0.299667 (9.300: -1.18%)
======================================================= (2.348 sec)
29.641... logprob:  0.613550, 0.263021 (1.486 sec)
29.642... logprob:  0.678237, 0.294271 (1.432 sec)
29.643... logprob:  0.842713, 0.345052 (1.422 sec)
29.644... logprob:  0.581819, 0.260417 (1.432 sec)
29.645... logprob:  0.663814, 0.286458 (1.422 sec)
29.646... logprob:  0.611243, 0.269531 (1.429 sec)
29.647... logprob:  0.743598, 0.328125 (1.480 sec)
29.648... logprob:  0.694131, 0.319010 (1.426 sec)
29.649... logprob:  0.632911, 0.292969 (1.438 sec)
29.650... logprob:  0.636803, 0.295573 (1.470 sec)
29.651... logprob:  0.749927, 0.325521 (1.426 sec)
29.652... logprob:  0.684116, 0.302083 (1.431 sec)
29.653... logprob:  0.737006, 0.328125 (1.427 sec)
29.654... logprob:  0.716068, 0.289062 (1.423 sec)
29.655... logprob:  0.659179, 0.286458 (1.421 sec)
29.656... logprob:  0.678661, 0.291667 (1.476 sec)
29.657... logprob:  0.682131, 0.307292 (1.433 sec)
29.658... logprob:  0.615422, 0.273437 (1.447 sec)
29.659... logprob:  0.654034, 0.281250 (1.456 sec)
29.660... logprob:  0.643566, 0.296875 (1.440 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.510710, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.521058e-03 [1.260921e-07] 
Layer 'conv1' biases: 2.164122e-06 [3.451689e-11] 
Layer 'conv2' weights[0]: 2.516047e-03 [1.258702e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.900352e-10] 
Layer 'conv3' weights[0]: 2.514916e-03 [1.260002e-07] 
Layer 'conv3' biases: 3.589705e-05 [5.555812e-09] 
Layer 'conv4' weights[0]: 2.525567e-03 [1.267033e-07] 
Layer 'conv4' biases: 9.998639e-01 [1.588472e-07] 
Layer 'conv5' weights[0]: 2.693146e-03 [2.314789e-06] 
Layer 'conv5' biases: 9.990939e-01 [2.461747e-06] 
Layer 'fc6' weights[0]: 6.737561e-03 [6.572211e-08] 
Layer 'fc6' biases: 9.999896e-01 [6.030497e-08] 
Layer 'fc7' weights[0]: 7.081605e-03 [1.582445e-07] 
Layer 'fc7' biases: 9.997158e-01 [2.359212e-07] 
Layer 'fc8' weights[0]: 4.697328e-03 [1.580909e-05] 
Layer 'fc8' biases: 2.358986e-02 [4.159409e-05] 
Train error last 800 batches: 0.654510
-------------------------------------------------------
Not saving because 0.510710 > 0.299667 (9.300: -1.18%)
======================================================= (2.353 sec)
29.661... logprob:  0.674426, 0.282552 (1.439 sec)
29.662... logprob:  0.748294, 0.305990 (1.429 sec)
29.663... logprob:  0.543398, 0.235677 (1.417 sec)
29.664... logprob:  0.573466, 0.285156 (1.433 sec)
29.665... logprob:  0.602082, 0.263021 (1.451 sec)
29.666... logprob:  0.648402, 0.304688 (1.450 sec)
29.667... logprob:  0.782260, 0.354167 (1.471 sec)
29.668... logprob:  0.713021, 0.308594 (1.454 sec)
29.669... logprob:  0.667374, 0.266927 (1.452 sec)
29.670... logprob:  0.587600, 0.248698 (1.434 sec)
29.671... logprob:  0.627093, 0.274740 (1.422 sec)
29.672... logprob:  0.689916, 0.285156 (1.421 sec)
29.673... logprob:  0.663800, 0.294271 (1.430 sec)
29.674... logprob:  0.648375, 0.282552 (1.448 sec)
29.675... logprob:  0.584136, 0.266927 (1.459 sec)
29.676... logprob:  0.571301, 0.253906 (1.448 sec)
29.677... logprob:  0.657926, 0.285156 (1.431 sec)
29.678... logprob:  0.693950, 0.337240 (1.474 sec)
29.679... logprob:  0.753694, 0.326823 (1.430 sec)
29.680... logprob:  0.655819, 0.264323 (1.417 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.555044, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.518540e-03 [1.258713e-07] 
Layer 'conv1' biases: 2.164645e-06 [6.148767e-11] 
Layer 'conv2' weights[0]: 2.513538e-03 [1.257074e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.801273e-10] 
Layer 'conv3' weights[0]: 2.512404e-03 [1.259193e-07] 
Layer 'conv3' biases: 3.589880e-05 [6.174099e-09] 
Layer 'conv4' weights[0]: 2.523048e-03 [1.265193e-07] 
Layer 'conv4' biases: 9.998624e-01 [1.730311e-07] 
Layer 'conv5' weights[0]: 2.690036e-03 [2.332202e-06] 
Layer 'conv5' biases: 9.990693e-01 [2.448329e-06] 
Layer 'fc6' weights[0]: 6.736878e-03 [6.178761e-08] 
Layer 'fc6' biases: 9.999895e-01 [5.616126e-08] 
Layer 'fc7' weights[0]: 7.080885e-03 [1.418124e-07] 
Layer 'fc7' biases: 9.997177e-01 [1.770451e-07] 
Layer 'fc8' weights[0]: 4.769726e-03 [1.213026e-05] 
Layer 'fc8' biases: 2.415883e-02 [2.011858e-05] 
Train error last 800 batches: 0.655394
-------------------------------------------------------
Not saving because 0.555044 > 0.299667 (9.300: -1.18%)
======================================================= (2.419 sec)
29.681... logprob:  0.623265, 0.257812 (1.437 sec)
29.682... logprob:  0.551443, 0.251302 (1.428 sec)
29.683... logprob:  0.768905, 0.330729 (1.428 sec)
29.684... logprob:  0.651880, 0.286458 (1.467 sec)
29.685... logprob:  0.526127, 0.248698 (1.439 sec)
29.686... logprob:  0.597334, 0.246094 (1.430 sec)
29.687... logprob:  0.537118, 0.251302 (1.478 sec)
29.688... logprob:  0.596995, 0.285156 (1.427 sec)
29.689... logprob:  0.625749, 0.276042 (1.423 sec)
29.690... logprob:  0.664420, 0.296875 (1.432 sec)
29.691... logprob:  0.787158, 0.358073 (1.426 sec)
29.692... logprob:  0.515902, 0.230469 (1.425 sec)
29.693... logprob:  0.654757, 0.291667 (1.481 sec)
29.694... logprob:  0.592788, 0.269531 (1.428 sec)
29.695... logprob:  0.610215, 0.298177 (1.433 sec)
29.696... logprob:  0.732140, 0.338542 (1.474 sec)
29.697... logprob:  0.642277, 0.281250 (1.426 sec)
29.698... logprob:  0.744531, 0.341146 (1.425 sec)
29.699... logprob:  0.682594, 0.324219 (1.432 sec)
29.700... logprob:  0.716045, 0.337240 (1.417 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.431071, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.516013e-03 [1.257983e-07] 
Layer 'conv1' biases: 2.164931e-06 [3.759034e-11] 
Layer 'conv2' weights[0]: 2.511023e-03 [1.256054e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.503550e-10] 
Layer 'conv3' weights[0]: 2.509886e-03 [1.257240e-07] 
Layer 'conv3' biases: 3.589800e-05 [5.537492e-09] 
Layer 'conv4' weights[0]: 2.520519e-03 [1.263632e-07] 
Layer 'conv4' biases: 9.998615e-01 [1.537839e-07] 
Layer 'conv5' weights[0]: 2.686785e-03 [2.413224e-06] 
Layer 'conv5' biases: 9.990667e-01 [2.574276e-06] 
Layer 'fc6' weights[0]: 6.736182e-03 [6.419086e-08] 
Layer 'fc6' biases: 9.999896e-01 [5.909050e-08] 
Layer 'fc7' weights[0]: 7.080198e-03 [1.525887e-07] 
Layer 'fc7' biases: 9.997185e-01 [2.224484e-07] 
Layer 'fc8' weights[0]: 4.792888e-03 [1.510722e-05] 
Layer 'fc8' biases: 2.431019e-02 [3.702635e-05] 
Train error last 800 batches: 0.655553
-------------------------------------------------------
Not saving because 0.431071 > 0.299667 (9.300: -1.18%)
======================================================= (2.362 sec)
29.701... logprob:  0.595699, 0.272135 (1.438 sec)
29.702... logprob:  0.659443, 0.312500 (1.479 sec)
29.703... logprob:  0.580685, 0.276042 (1.432 sec)
29.704... logprob:  0.588606, 0.283854 (1.442 sec)
29.705... logprob:  0.646865, 0.287760 (1.494 sec)
29.706... logprob:  0.653952, 0.272135 (1.432 sec)
29.707... logprob:  0.715827, 0.322917 (1.434 sec)
29.708... logprob:  0.600481, 0.257813 (1.423 sec)
29.709... logprob:  0.732525, 0.332031 (1.417 sec)
29.710... logprob:  0.784221, 0.354167 (1.432 sec)
29.711... logprob:  0.731228, 0.320313 (1.460 sec)
29.712... logprob:  0.585453, 0.257812 (1.445 sec)
29.713... logprob:  0.878547, 0.355469 (1.444 sec)
29.714... logprob:  0.670307, 0.308594 (1.455 sec)
29.715... logprob:  0.746844, 0.335937 (1.445 sec)
29.716... logprob:  0.634366, 0.292969 (1.432 sec)
29.717... logprob:  0.638352, 0.269531 (1.417 sec)
29.718... logprob:  0.751338, 0.300781 (1.426 sec)
29.719... logprob:  0.649262, 0.279948 (1.433 sec)
29.720... logprob:  0.650898, 0.299479 (1.441 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.520771, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.513492e-03 [1.256877e-07] 
Layer 'conv1' biases: 2.164998e-06 [6.286910e-11] 
Layer 'conv2' weights[0]: 2.508511e-03 [1.254604e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.406063e-10] 
Layer 'conv3' weights[0]: 2.507402e-03 [1.258077e-07] 
Layer 'conv3' biases: 3.592364e-05 [8.192609e-09] 
Layer 'conv4' weights[0]: 2.518001e-03 [1.265603e-07] 
Layer 'conv4' biases: 9.998630e-01 [2.582699e-07] 
Layer 'conv5' weights[0]: 2.685402e-03 [3.269602e-06] 
Layer 'conv5' biases: 9.990934e-01 [3.485912e-06] 
Layer 'fc6' weights[0]: 6.735448e-03 [7.589109e-08] 
Layer 'fc6' biases: 9.999897e-01 [7.356547e-08] 
Layer 'fc7' weights[0]: 7.079466e-03 [1.829641e-07] 
Layer 'fc7' biases: 9.997169e-01 [3.140634e-07] 
Layer 'fc8' weights[0]: 4.734641e-03 [1.806916e-05] 
Layer 'fc8' biases: 2.384135e-02 [5.452222e-05] 
Train error last 800 batches: 0.655780
-------------------------------------------------------
Not saving because 0.520771 > 0.299667 (9.300: -1.18%)
======================================================= (2.357 sec)
29.721... logprob:  0.683959, 0.317708 (1.462 sec)
29.722... logprob:  0.659081, 0.294271 (1.450 sec)
29.723... logprob:  0.656116, 0.292969 (1.435 sec)
29.724... logprob:  0.646603, 0.295573 (1.467 sec)
29.725... logprob:  0.615381, 0.270833 (1.424 sec)
29.726... logprob:  0.582687, 0.252604 (1.420 sec)
29.727... logprob:  0.597704, 0.243490 (1.425 sec)
29.728... logprob:  0.662633, 0.299479 (1.433 sec)
29.729... logprob:  0.650589, 0.287760 (1.427 sec)
29.730... logprob:  0.807988, 0.325521 (1.471 sec)
29.731... logprob:  0.724955, 0.303385 (1.436 sec)
29.732... logprob:  0.522216, 0.223958 (1.437 sec)
29.733... logprob:  0.754909, 0.307292 (1.480 sec)
29.734... logprob:  0.563740, 0.250000 (1.426 sec)
29.735... logprob:  0.756027, 0.321615 (1.422 sec)
29.736... logprob:  0.790174, 0.341146 (1.434 sec)
29.737... logprob:  0.719892, 0.316406 (1.424 sec)
29.738... logprob:  0.658779, 0.308594 (1.426 sec)
29.739... logprob:  0.706837, 0.274740 (1.475 sec)
29.740... logprob:  0.553156, 0.257812 (1.432 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.504879, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.510989e-03 [1.256224e-07] 
Layer 'conv1' biases: 2.165239e-06 [5.042453e-11] 
Layer 'conv2' weights[0]: 2.506003e-03 [1.253665e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.619207e-10] 
Layer 'conv3' weights[0]: 2.504868e-03 [1.256492e-07] 
Layer 'conv3' biases: 3.596220e-05 [7.685207e-09] 
Layer 'conv4' weights[0]: 2.515474e-03 [1.263029e-07] 
Layer 'conv4' biases: 9.998622e-01 [2.334263e-07] 
Layer 'conv5' weights[0]: 2.682647e-03 [2.515050e-06] 
Layer 'conv5' biases: 9.991079e-01 [2.646512e-06] 
Layer 'fc6' weights[0]: 6.734764e-03 [6.205447e-08] 
Layer 'fc6' biases: 9.999897e-01 [5.555633e-08] 
Layer 'fc7' weights[0]: 7.078814e-03 [1.433641e-07] 
Layer 'fc7' biases: 9.997166e-01 [1.796096e-07] 
Layer 'fc8' weights[0]: 4.716361e-03 [1.269972e-05] 
Layer 'fc8' biases: 2.371951e-02 [2.673340e-05] 
Train error last 800 batches: 0.655634
-------------------------------------------------------
Not saving because 0.504879 > 0.299667 (9.300: -1.18%)
======================================================= (2.397 sec)
29.741... logprob:  0.655362, 0.266927 (1.441 sec)
29.742... logprob:  0.655999, 0.264323 (1.483 sec)
29.743... logprob:  0.667012, 0.287760 (1.427 sec)
29.744... logprob:  0.751259, 0.307292 (1.432 sec)
29.745... logprob:  0.711158, 0.296875 (1.432 sec)
29.746... logprob:  0.730117, 0.322917 (1.419 sec)
29.747... logprob:  0.651886, 0.291667 (1.432 sec)
29.748... logprob:  0.651343, 0.273438 (1.475 sec)
29.749... logprob:  0.569185, 0.240885 (1.431 sec)
29.750... logprob:  0.658643, 0.282552 (1.436 sec)
29.751... logprob:  0.515419, 0.242187 (1.471 sec)
29.752... logprob:  0.639396, 0.269531 (1.426 sec)
29.753... logprob:  0.635428, 0.296875 (1.434 sec)
29.754... logprob:  0.746427, 0.330729 (1.425 sec)
29.755... logprob:  0.703861, 0.308594 (1.418 sec)
29.756... logprob:  0.649677, 0.268229 (1.437 sec)
29.757... logprob:  0.725105, 0.296875 (1.468 sec)
29.758... logprob:  0.569265, 0.264323 (1.440 sec)
29.759... logprob:  0.683707, 0.309896 (1.445 sec)
29.760... logprob:  0.741288, 0.316406 (1.455 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.518898, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.508476e-03 [1.255128e-07] 
Layer 'conv1' biases: 2.165365e-06 [5.209116e-11] 
Layer 'conv2' weights[0]: 2.503499e-03 [1.252527e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.342680e-10] 
Layer 'conv3' weights[0]: 2.502382e-03 [1.254054e-07] 
Layer 'conv3' biases: 3.598424e-05 [5.834582e-09] 
Layer 'conv4' weights[0]: 2.512972e-03 [1.260744e-07] 
Layer 'conv4' biases: 9.998618e-01 [1.626883e-07] 
Layer 'conv5' weights[0]: 2.680189e-03 [2.267190e-06] 
Layer 'conv5' biases: 9.990941e-01 [2.419472e-06] 
Layer 'fc6' weights[0]: 6.734077e-03 [6.299863e-08] 
Layer 'fc6' biases: 9.999897e-01 [5.664219e-08] 
Layer 'fc7' weights[0]: 7.078093e-03 [1.479536e-07] 
Layer 'fc7' biases: 9.997172e-01 [1.912968e-07] 
Layer 'fc8' weights[0]: 4.752910e-03 [1.342014e-05] 
Layer 'fc8' biases: 2.405630e-02 [2.870309e-05] 
Train error last 800 batches: 0.655666
-------------------------------------------------------
Not saving because 0.518898 > 0.299667 (9.300: -1.18%)
======================================================= (2.363 sec)
29.761... logprob:  0.718386, 0.315104 (1.447 sec)
29.762... logprob:  0.621445, 0.269531 (1.433 sec)
29.763... logprob:  0.768145, 0.342448 (1.427 sec)
29.764... logprob:  0.648220, 0.270833 (1.419 sec)
29.765... logprob:  0.575016, 0.272135 (1.441 sec)
29.766... logprob:  0.630551, 0.276042 (1.445 sec)
29.767... logprob:  0.567732, 0.281250 (1.453 sec)
29.768... logprob:  0.617100, 0.276042 (1.460 sec)
29.769... logprob:  0.688810, 0.322917 (1.465 sec)
29.770... logprob:  0.635755, 0.278646 (1.476 sec)
29.771... logprob:  0.665465, 0.273438 (1.452 sec)
29.772... logprob:  0.679227, 0.295573 (1.435 sec)
29.773... logprob:  0.686767, 0.300781 (1.442 sec)
29.774... logprob:  0.584267, 0.269531 (1.453 sec)
29.775... logprob:  0.566459, 0.264323 (1.456 sec)
29.776... logprob:  0.613371, 0.268229 (1.472 sec)
29.777... logprob:  0.571167, 0.260417 (1.466 sec)
29.778... logprob:  0.664710, 0.290365 (1.464 sec)
29.779... logprob:  0.729369, 0.299479 (1.481 sec)
29.780... logprob:  0.601771, 0.276042 (1.446 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.502785, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.505965e-03 [1.253808e-07] 
Layer 'conv1' biases: 2.165766e-06 [5.072032e-11] 
Layer 'conv2' weights[0]: 2.500984e-03 [1.251224e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.914313e-10] 
Layer 'conv3' weights[0]: 2.499870e-03 [1.252672e-07] 
Layer 'conv3' biases: 3.597044e-05 [5.425578e-09] 
Layer 'conv4' weights[0]: 2.510454e-03 [1.259842e-07] 
Layer 'conv4' biases: 9.998612e-01 [1.545939e-07] 
Layer 'conv5' weights[0]: 2.677600e-03 [2.180496e-06] 
Layer 'conv5' biases: 9.990782e-01 [2.312721e-06] 
Layer 'fc6' weights[0]: 6.733413e-03 [5.848263e-08] 
Layer 'fc6' biases: 9.999897e-01 [5.128734e-08] 
Layer 'fc7' weights[0]: 7.077390e-03 [1.346231e-07] 
Layer 'fc7' biases: 9.997180e-01 [1.591753e-07] 
Layer 'fc8' weights[0]: 4.790961e-03 [1.085497e-05] 
Layer 'fc8' biases: 2.432872e-02 [9.383031e-06] 
Train error last 800 batches: 0.655141
-------------------------------------------------------
Not saving because 0.502785 > 0.299667 (9.300: -1.18%)
======================================================= (2.372 sec)
29.781... logprob:  0.568711, 0.269531 (1.449 sec)
29.782... logprob:  0.598654, 0.256510 (1.458 sec)
29.783... logprob:  0.672402, 0.302083 (1.449 sec)
29.784... logprob:  0.715388, 0.305990 (1.451 sec)
29.785... logprob:  0.781196, 0.326823 (1.479 sec)
29.786... logprob:  0.767272, 0.338542 (1.465 sec)
29.787... logprob:  0.685410, 0.290365 (1.454 sec)
29.788... logprob:  0.769107, 0.329427 (1.485 sec)
29.789... logprob:  0.498680, 0.238281 (1.449 sec)
29.790... logprob:  0.514598, 0.212240 (1.439 sec)
29.791... logprob:  0.537076, 0.238281 (1.445 sec)
29.792... logprob:  0.592404, 0.257812 (1.452 sec)
29.793... logprob:  0.658141, 0.296875 (1.448 sec)
29.794... logprob:  0.610889, 0.248698 (1.483 sec)
29.795... logprob:  0.694999, 0.321615 (1.460 sec)
29.796... logprob:  0.678652, 0.285156 (1.454 sec)
29.797... logprob:  0.551673, 0.269531 (1.488 sec)
29.798... logprob:  0.549683, 0.242187 (1.445 sec)
29.799... logprob:  0.573393, 0.250000 (1.442 sec)
29.800... logprob:  0.587635, 0.263021 (1.392 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.490127, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.503467e-03 [1.252080e-07] 
Layer 'conv1' biases: 2.166377e-06 [7.728773e-11] 
Layer 'conv2' weights[0]: 2.498488e-03 [1.249844e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.025374e-10] 
Layer 'conv3' weights[0]: 2.497395e-03 [1.252808e-07] 
Layer 'conv3' biases: 3.598067e-05 [7.123286e-09] 
Layer 'conv4' weights[0]: 2.507940e-03 [1.259490e-07] 
Layer 'conv4' biases: 9.998602e-01 [1.910176e-07] 
Layer 'conv5' weights[0]: 2.674535e-03 [2.598520e-06] 
Layer 'conv5' biases: 9.990821e-01 [2.791103e-06] 
Layer 'fc6' weights[0]: 6.732711e-03 [6.122665e-08] 
Layer 'fc6' biases: 9.999897e-01 [5.456067e-08] 
Layer 'fc7' weights[0]: 7.076697e-03 [1.430010e-07] 
Layer 'fc7' biases: 9.997175e-01 [2.062735e-07] 
Layer 'fc8' weights[0]: 4.778616e-03 [1.301157e-05] 
Layer 'fc8' biases: 2.431383e-02 [3.251409e-05] 
Train error last 800 batches: 0.654510
-------------------------------------------------------
Not saving because 0.490127 > 0.299667 (9.300: -1.18%)
======================================================= (2.363 sec)
30.1... logprob:  0.689758, 0.320312 (1.403 sec)
30.2... logprob:  0.627318, 0.294271 (1.448 sec)
30.3... logprob:  0.624429, 0.263021 (1.410 sec)
30.4... logprob:  0.694645, 0.316406 (1.402 sec)
30.5... logprob:  0.663987, 0.298177 (1.427 sec)
30.6... logprob:  0.721892, 0.324219 (1.389 sec)
30.7... logprob:  0.515685, 0.247396 (1.411 sec)
30.8... logprob:  0.633907, 0.291667 (1.389 sec)
30.9... logprob:  0.544332, 0.248698 (1.402 sec)
30.10... logprob:  0.651646, 0.268229 (1.408 sec)
30.11... logprob:  0.649301, 0.298177 (1.440 sec)
30.12... logprob:  0.697789, 0.316406 (1.386 sec)
30.13... logprob:  0.673130, 0.291667 (1.417 sec)
30.14... logprob:  0.792248, 0.322917 (1.398 sec)
30.15... logprob:  0.721118, 0.303385 (1.403 sec)
30.16... logprob:  0.693937, 0.338542 (1.403 sec)
30.17... logprob:  0.684245, 0.295573 (1.390 sec)
30.18... logprob:  0.550433, 0.264323 (1.389 sec)
30.19... logprob:  0.589285, 0.247396 (1.398 sec)
30.20... logprob:  0.615546, 0.282552 (1.395 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.400556, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.500961e-03 [1.250490e-07] 
Layer 'conv1' biases: 2.166841e-06 [4.474625e-11] 
Layer 'conv2' weights[0]: 2.495996e-03 [1.248369e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.226975e-10] 
Layer 'conv3' weights[0]: 2.494885e-03 [1.249652e-07] 
Layer 'conv3' biases: 3.598847e-05 [4.948292e-09] 
Layer 'conv4' weights[0]: 2.505438e-03 [1.255298e-07] 
Layer 'conv4' biases: 9.998581e-01 [1.441654e-07] 
Layer 'conv5' weights[0]: 2.670882e-03 [2.230678e-06] 
Layer 'conv5' biases: 9.990744e-01 [2.413026e-06] 
Layer 'fc6' weights[0]: 6.732006e-03 [5.826006e-08] 
Layer 'fc6' biases: 9.999897e-01 [5.130072e-08] 
Layer 'fc7' weights[0]: 7.075967e-03 [1.336228e-07] 
Layer 'fc7' biases: 9.997184e-01 [1.599655e-07] 
Layer 'fc8' weights[0]: 4.809072e-03 [1.101493e-05] 
Layer 'fc8' biases: 2.454300e-02 [1.253705e-05] 
Train error last 800 batches: 0.654822
-------------------------------------------------------
Not saving because 0.400556 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
30.21... logprob:  0.633848, 0.303385 (1.408 sec)
30.22... logprob:  0.751236, 0.352865 (1.412 sec)
30.23... logprob:  0.737906, 0.320312 (1.414 sec)
30.24... logprob:  0.606584, 0.279948 (1.411 sec)
30.25... logprob:  0.637917, 0.266927 (1.400 sec)
30.26... logprob:  0.650699, 0.307292 (1.441 sec)
30.27... logprob:  0.639904, 0.289062 (1.384 sec)
30.28... logprob:  0.643246, 0.283854 (1.406 sec)
30.29... logprob:  0.712924, 0.308594 (1.414 sec)
30.30... logprob:  0.554721, 0.255208 (1.410 sec)
30.31... logprob:  0.684500, 0.313802 (1.395 sec)
30.32... logprob:  0.732469, 0.315104 (1.384 sec)
30.33... logprob:  0.715078, 0.304687 (1.438 sec)
30.34... logprob:  0.672130, 0.289062 (1.387 sec)
30.35... logprob:  0.573268, 0.269531 (1.388 sec)
30.36... logprob:  0.651035, 0.281250 (1.395 sec)
30.37... logprob:  0.587582, 0.272135 (1.399 sec)
30.38... logprob:  0.598857, 0.281250 (1.389 sec)
30.39... logprob:  0.834344, 0.341146 (1.426 sec)
30.40... logprob:  0.575446, 0.257812 (1.401 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.437324, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.498471e-03 [1.249270e-07] 
Layer 'conv1' biases: 2.167067e-06 [4.076000e-11] 
Layer 'conv2' weights[0]: 2.493496e-03 [1.247141e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.567917e-10] 
Layer 'conv3' weights[0]: 2.492392e-03 [1.248911e-07] 
Layer 'conv3' biases: 3.600810e-05 [6.017981e-09] 
Layer 'conv4' weights[0]: 2.502951e-03 [1.255534e-07] 
Layer 'conv4' biases: 9.998591e-01 [1.939515e-07] 
Layer 'conv5' weights[0]: 2.669248e-03 [2.057979e-06] 
Layer 'conv5' biases: 9.990905e-01 [2.143306e-06] 
Layer 'fc6' weights[0]: 6.731300e-03 [5.914300e-08] 
Layer 'fc6' biases: 9.999896e-01 [5.226463e-08] 
Layer 'fc7' weights[0]: 7.075261e-03 [1.376581e-07] 
Layer 'fc7' biases: 9.997172e-01 [1.695830e-07] 
Layer 'fc8' weights[0]: 4.780976e-03 [1.147016e-05] 
Layer 'fc8' biases: 2.433346e-02 [1.718202e-05] 
Train error last 800 batches: 0.654732
-------------------------------------------------------
Not saving because 0.437324 > 0.299667 (9.300: -1.18%)
======================================================= (2.370 sec)
30.41... logprob:  0.589531, 0.279948 (1.428 sec)
30.42... logprob:  0.639669, 0.269531 (1.409 sec)
30.43... logprob:  0.700333, 0.298177 (1.400 sec)
30.44... logprob:  0.753559, 0.315104 (1.436 sec)
30.45... logprob:  0.641836, 0.291667 (1.386 sec)
30.46... logprob:  0.747265, 0.324219 (1.397 sec)
30.47... logprob:  0.566706, 0.270833 (1.385 sec)
30.48... logprob:  0.679351, 0.285156 (1.422 sec)
30.49... logprob:  0.678792, 0.300781 (1.406 sec)
30.50... logprob:  0.600104, 0.270833 (1.421 sec)
30.51... logprob:  0.670806, 0.279948 (1.408 sec)
30.52... logprob:  0.738453, 0.324219 (1.395 sec)
30.53... logprob:  0.548130, 0.240885 (1.436 sec)
30.54... logprob:  0.705520, 0.291667 (1.380 sec)
30.55... logprob:  0.640613, 0.274740 (1.395 sec)
30.56... logprob:  0.671505, 0.278646 (1.394 sec)
30.57... logprob:  0.736211, 0.315104 (1.423 sec)
30.58... logprob:  0.658195, 0.286458 (1.394 sec)
30.59... logprob:  0.616584, 0.264323 (1.458 sec)
30.60... logprob:  0.721205, 0.311198 (1.414 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.419183, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.495957e-03 [1.248389e-07] 
Layer 'conv1' biases: 2.167156e-06 [4.920836e-11] 
Layer 'conv2' weights[0]: 2.491002e-03 [1.245953e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.208412e-10] 
Layer 'conv3' weights[0]: 2.489901e-03 [1.248656e-07] 
Layer 'conv3' biases: 3.602975e-05 [7.022207e-09] 
Layer 'conv4' weights[0]: 2.500428e-03 [1.254164e-07] 
Layer 'conv4' biases: 9.998604e-01 [1.966080e-07] 
Layer 'conv5' weights[0]: 2.667997e-03 [2.128362e-06] 
Layer 'conv5' biases: 9.991069e-01 [2.188453e-06] 
Layer 'fc6' weights[0]: 6.730655e-03 [6.223857e-08] 
Layer 'fc6' biases: 9.999894e-01 [5.586275e-08] 
Layer 'fc7' weights[0]: 7.074547e-03 [1.436290e-07] 
Layer 'fc7' biases: 9.997159e-01 [1.765235e-07] 
Layer 'fc8' weights[0]: 4.749290e-03 [1.186137e-05] 
Layer 'fc8' biases: 2.398569e-02 [1.684072e-05] 
Train error last 800 batches: 0.655264
-------------------------------------------------------
Not saving because 0.419183 > 0.299667 (9.300: -1.18%)
======================================================= (2.417 sec)
30.61... logprob:  0.584382, 0.269531 (1.438 sec)
30.62... logprob:  0.667249, 0.305990 (1.450 sec)
30.63... logprob:  0.628173, 0.290365 (1.435 sec)
30.64... logprob:  0.683837, 0.290364 (1.403 sec)
30.65... logprob:  0.640920, 0.298177 (1.391 sec)
30.66... logprob:  0.605550, 0.266927 (1.439 sec)
30.67... logprob:  0.564820, 0.251302 (1.384 sec)
30.68... logprob:  0.584432, 0.270833 (1.390 sec)
30.69... logprob:  0.754469, 0.308594 (1.418 sec)
30.70... logprob:  0.526011, 0.220052 (1.416 sec)
30.71... logprob:  0.605643, 0.268229 (1.457 sec)
30.72... logprob:  0.608274, 0.281250 (1.395 sec)
30.73... logprob:  0.673437, 0.290364 (1.420 sec)
30.74... logprob:  0.647909, 0.313802 (1.408 sec)
30.75... logprob:  0.613092, 0.265625 (1.412 sec)
30.76... logprob:  0.633986, 0.311198 (1.425 sec)
30.77... logprob:  0.566213, 0.246094 (1.424 sec)
30.78... logprob:  0.725491, 0.330729 (1.447 sec)
30.79... logprob:  0.772591, 0.333333 (1.396 sec)
30.80... logprob:  0.718089, 0.308594 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.498293, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.493473e-03 [1.246705e-07] 
Layer 'conv1' biases: 2.167323e-06 [4.105418e-11] 
Layer 'conv2' weights[0]: 2.488529e-03 [1.244695e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.691674e-10] 
Layer 'conv3' weights[0]: 2.487388e-03 [1.245342e-07] 
Layer 'conv3' biases: 3.602023e-05 [4.114366e-09] 
Layer 'conv4' weights[0]: 2.497937e-03 [1.251477e-07] 
Layer 'conv4' biases: 9.998609e-01 [1.295217e-07] 
Layer 'conv5' weights[0]: 2.666086e-03 [2.183450e-06] 
Layer 'conv5' biases: 9.990793e-01 [2.301987e-06] 
Layer 'fc6' weights[0]: 6.729985e-03 [6.221743e-08] 
Layer 'fc6' biases: 9.999893e-01 [5.599554e-08] 
Layer 'fc7' weights[0]: 7.073848e-03 [1.457227e-07] 
Layer 'fc7' biases: 9.997180e-01 [1.922158e-07] 
Layer 'fc8' weights[0]: 4.806992e-03 [1.427022e-05] 
Layer 'fc8' biases: 2.447196e-02 [3.337951e-05] 
Train error last 800 batches: 0.655469
-------------------------------------------------------
Not saving because 0.498293 > 0.299667 (9.300: -1.18%)
======================================================= (2.371 sec)
30.81... logprob:  0.613614, 0.296875 (1.418 sec)
30.82... logprob:  0.470358, 0.233073 (1.417 sec)
30.83... logprob:  0.693870, 0.292969 (1.400 sec)
30.84... logprob:  0.662144, 0.283854 (1.461 sec)
30.85... logprob:  0.703460, 0.328125 (1.417 sec)
30.86... logprob:  0.616679, 0.256510 (1.414 sec)
30.87... logprob:  0.745872, 0.311198 (1.407 sec)
30.88... logprob:  0.767491, 0.316406 (1.401 sec)
30.89... logprob:  0.680013, 0.296875 (1.429 sec)
30.90... logprob:  0.817710, 0.321615 (1.384 sec)
30.91... logprob:  0.607043, 0.287760 (1.385 sec)
30.92... logprob:  0.725284, 0.305990 (1.396 sec)
30.93... logprob:  0.664308, 0.290365 (1.391 sec)
30.94... logprob:  0.687758, 0.273438 (1.384 sec)
30.95... logprob:  0.724046, 0.321615 (1.398 sec)
30.96... logprob:  0.722808, 0.322917 (1.408 sec)
30.97... logprob:  0.718600, 0.298177 (1.383 sec)
30.98... logprob:  0.638944, 0.298177 (1.432 sec)
30.99... logprob:  0.674034, 0.291667 (1.414 sec)
30.100... logprob:  0.599630, 0.281250 (1.395 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.482508, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.490974e-03 [1.245268e-07] 
Layer 'conv1' biases: 2.167552e-06 [4.926331e-11] 
Layer 'conv2' weights[0]: 2.486037e-03 [1.243338e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.473324e-10] 
Layer 'conv3' weights[0]: 2.484913e-03 [1.245203e-07] 
Layer 'conv3' biases: 3.602576e-05 [6.227033e-09] 
Layer 'conv4' weights[0]: 2.495438e-03 [1.251622e-07] 
Layer 'conv4' biases: 9.998612e-01 [1.966894e-07] 
Layer 'conv5' weights[0]: 2.664282e-03 [2.789450e-06] 
Layer 'conv5' biases: 9.991110e-01 [3.007566e-06] 
Layer 'fc6' weights[0]: 6.729287e-03 [6.348684e-08] 
Layer 'fc6' biases: 9.999895e-01 [5.754014e-08] 
Layer 'fc7' weights[0]: 7.073177e-03 [1.491492e-07] 
Layer 'fc7' biases: 9.997162e-01 [2.076756e-07] 
Layer 'fc8' weights[0]: 4.740455e-03 [1.293015e-05] 
Layer 'fc8' biases: 2.402889e-02 [2.536585e-05] 
Train error last 800 batches: 0.655706
-------------------------------------------------------
Not saving because 0.482508 > 0.299667 (9.300: -1.18%)
======================================================= (2.369 sec)
30.101... logprob:  0.518001, 0.199219 (1.446 sec)
30.102... logprob:  0.769813, 0.312500 (1.390 sec)
30.103... logprob:  0.733096, 0.312500 (1.393 sec)
30.104... logprob:  0.617237, 0.273437 (1.392 sec)
30.105... logprob:  0.791267, 0.354167 (1.389 sec)
30.106... logprob:  0.634569, 0.295573 (1.389 sec)
30.107... logprob:  0.505929, 0.216146 (1.437 sec)
30.108... logprob:  0.832852, 0.334635 (1.390 sec)
30.109... logprob:  0.566585, 0.243490 (1.394 sec)
30.110... logprob:  0.672154, 0.283854 (1.394 sec)
30.111... logprob:  0.601173, 0.274740 (1.386 sec)
30.112... logprob:  0.587970, 0.290365 (1.394 sec)
30.113... logprob:  0.540312, 0.247396 (1.395 sec)
30.114... logprob:  0.758929, 0.325521 (1.424 sec)
30.115... logprob:  0.651185, 0.295573 (1.404 sec)
30.116... logprob:  0.584632, 0.261719 (1.393 sec)
30.117... logprob:  0.595793, 0.251302 (1.439 sec)
30.118... logprob:  0.563842, 0.242187 (1.381 sec)
30.119... logprob:  0.601068, 0.269531 (1.394 sec)
30.120... logprob:  0.656580, 0.276042 (1.392 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.548197, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.488492e-03 [1.245327e-07] 
Layer 'conv1' biases: 2.167738e-06 [5.976949e-11] 
Layer 'conv2' weights[0]: 2.483536e-03 [1.242868e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.874348e-10] 
Layer 'conv3' weights[0]: 2.482442e-03 [1.245597e-07] 
Layer 'conv3' biases: 3.604667e-05 [6.936417e-09] 
Layer 'conv4' weights[0]: 2.492946e-03 [1.254509e-07] 
Layer 'conv4' biases: 9.998597e-01 [2.141358e-07] 
Layer 'conv5' weights[0]: 2.661343e-03 [3.153749e-06] 
Layer 'conv5' biases: 9.990936e-01 [3.444726e-06] 
Layer 'fc6' weights[0]: 6.728600e-03 [7.148766e-08] 
Layer 'fc6' biases: 9.999896e-01 [6.733549e-08] 
Layer 'fc7' weights[0]: 7.072449e-03 [1.717580e-07] 
Layer 'fc7' biases: 9.997169e-01 [2.827809e-07] 
Layer 'fc8' weights[0]: 4.780409e-03 [1.646707e-05] 
Layer 'fc8' biases: 2.437310e-02 [4.616379e-05] 
Train error last 800 batches: 0.655238
-------------------------------------------------------
Not saving because 0.548197 > 0.299667 (9.300: -1.18%)
======================================================= (2.394 sec)
30.121... logprob:  0.680971, 0.285156 (1.402 sec)
30.122... logprob:  0.812871, 0.328125 (1.440 sec)
30.123... logprob:  0.734557, 0.343750 (1.386 sec)
30.124... logprob:  0.689907, 0.311198 (1.395 sec)
30.125... logprob:  0.757309, 0.334635 (1.395 sec)
30.126... logprob:  0.743521, 0.315104 (1.381 sec)
30.127... logprob:  0.685461, 0.274739 (1.396 sec)
30.128... logprob:  0.649783, 0.272135 (1.415 sec)
30.129... logprob:  0.785850, 0.347656 (1.412 sec)
30.130... logprob:  0.705009, 0.335937 (1.409 sec)
30.131... logprob:  0.738413, 0.339844 (1.403 sec)
30.132... logprob:  0.746196, 0.334635 (1.428 sec)
30.133... logprob:  0.666431, 0.300781 (1.383 sec)
30.134... logprob:  0.615451, 0.282552 (1.388 sec)
30.135... logprob:  0.675250, 0.299479 (1.395 sec)
30.136... logprob:  0.768682, 0.320312 (1.394 sec)
30.137... logprob:  0.665892, 0.304687 (1.382 sec)
30.138... logprob:  0.597746, 0.246094 (1.436 sec)
30.139... logprob:  0.603298, 0.279948 (1.400 sec)
30.140... logprob:  0.696583, 0.294271 (1.405 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.433746, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.486004e-03 [1.243622e-07] 
Layer 'conv1' biases: 2.167986e-06 [4.169001e-11] 
Layer 'conv2' weights[0]: 2.481067e-03 [1.241201e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.089061e-10] 
Layer 'conv3' weights[0]: 2.479959e-03 [1.242729e-07] 
Layer 'conv3' biases: 3.607150e-05 [5.369127e-09] 
Layer 'conv4' weights[0]: 2.490453e-03 [1.248976e-07] 
Layer 'conv4' biases: 9.998597e-01 [1.587441e-07] 
Layer 'conv5' weights[0]: 2.659132e-03 [2.287613e-06] 
Layer 'conv5' biases: 9.991208e-01 [2.380054e-06] 
Layer 'fc6' weights[0]: 6.727885e-03 [6.395136e-08] 
Layer 'fc6' biases: 9.999899e-01 [5.781355e-08] 
Layer 'fc7' weights[0]: 7.071725e-03 [1.484298e-07] 
Layer 'fc7' biases: 9.997145e-01 [2.009042e-07] 
Layer 'fc8' weights[0]: 4.721875e-03 [1.389751e-05] 
Layer 'fc8' biases: 2.398175e-02 [3.716484e-05] 
Train error last 800 batches: 0.655976
-------------------------------------------------------
Not saving because 0.433746 > 0.299667 (9.300: -1.18%)
======================================================= (2.357 sec)
30.141... logprob:  0.721574, 0.329427 (1.444 sec)
30.142... logprob:  0.645232, 0.270833 (1.398 sec)
30.143... logprob:  0.546701, 0.244792 (1.548 sec)
30.144... logprob:  0.607316, 0.276042 (1.406 sec)
30.145... logprob:  0.646382, 0.307292 (1.414 sec)
30.146... logprob:  0.686889, 0.278646 (1.403 sec)
30.147... logprob:  0.542044, 0.251302 (1.425 sec)
30.148... logprob:  0.683985, 0.302083 (1.383 sec)
30.149... logprob:  0.697043, 0.296875 (1.386 sec)
30.150... logprob:  0.583982, 0.265625 (1.394 sec)
30.151... logprob:  0.633857, 0.265625 (1.394 sec)
30.152... logprob:  0.820460, 0.371094 (1.390 sec)
30.153... logprob:  0.642818, 0.282552 (1.440 sec)
30.154... logprob:  0.693174, 0.292969 (1.392 sec)
30.155... logprob:  0.729226, 0.334635 (1.404 sec)
30.156... logprob:  0.504596, 0.223958 (1.426 sec)
30.157... logprob:  0.582941, 0.278646 (1.388 sec)
30.158... logprob:  0.671739, 0.270833 (1.394 sec)
30.159... logprob:  0.633974, 0.283854 (1.392 sec)
30.160... logprob:  0.683963, 0.266927 (1.384 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.375847, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.483516e-03 [1.242369e-07] 
Layer 'conv1' biases: 2.168279e-06 [5.246504e-11] 
Layer 'conv2' weights[0]: 2.478579e-03 [1.239793e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.310518e-10] 
Layer 'conv3' weights[0]: 2.477474e-03 [1.241934e-07] 
Layer 'conv3' biases: 3.606279e-05 [6.070232e-09] 
Layer 'conv4' weights[0]: 2.487968e-03 [1.248433e-07] 
Layer 'conv4' biases: 9.998570e-01 [1.537684e-07] 
Layer 'conv5' weights[0]: 2.654150e-03 [2.015543e-06] 
Layer 'conv5' biases: 9.990999e-01 [2.145279e-06] 
Layer 'fc6' weights[0]: 6.727210e-03 [6.171407e-08] 
Layer 'fc6' biases: 9.999896e-01 [5.509624e-08] 
Layer 'fc7' weights[0]: 7.071031e-03 [1.411300e-07] 
Layer 'fc7' biases: 9.997159e-01 [1.695392e-07] 
Layer 'fc8' weights[0]: 4.769680e-03 [1.148272e-05] 
Layer 'fc8' biases: 2.441736e-02 [1.420412e-05] 
Train error last 800 batches: 0.656117
-------------------------------------------------------
Not saving because 0.375847 > 0.299667 (9.300: -1.18%)
======================================================= (2.382 sec)
30.161... logprob:  0.497997, 0.233073 (1.400 sec)
30.162... logprob:  0.828590, 0.339844 (1.398 sec)
30.163... logprob:  0.686929, 0.276042 (1.419 sec)
30.164... logprob:  0.660284, 0.298177 (1.417 sec)
30.165... logprob:  0.780838, 0.304687 (1.414 sec)
30.166... logprob:  0.686449, 0.294271 (1.443 sec)
30.167... logprob:  0.605703, 0.295573 (1.421 sec)
30.168... logprob:  0.596626, 0.281250 (1.417 sec)
30.169... logprob:  0.586055, 0.263021 (1.451 sec)
30.170... logprob:  0.598914, 0.257812 (1.398 sec)
30.171... logprob:  0.754294, 0.334635 (1.416 sec)
30.172... logprob:  0.628547, 0.286458 (1.407 sec)
30.173... logprob:  0.656845, 0.287760 (1.416 sec)
30.174... logprob:  0.843830, 0.352865 (1.398 sec)
30.175... logprob:  0.697521, 0.294271 (1.458 sec)
30.176... logprob:  0.658141, 0.285156 (1.411 sec)
30.177... logprob:  0.536263, 0.240885 (1.436 sec)
30.178... logprob:  0.576363, 0.246094 (1.452 sec)
30.179... logprob:  0.718966, 0.319010 (1.401 sec)
30.180... logprob:  0.745649, 0.337240 (1.414 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.505955, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.481046e-03 [1.240813e-07] 
Layer 'conv1' biases: 2.168601e-06 [4.739995e-11] 
Layer 'conv2' weights[0]: 2.476085e-03 [1.238309e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.242842e-10] 
Layer 'conv3' weights[0]: 2.474996e-03 [1.239718e-07] 
Layer 'conv3' biases: 3.605708e-05 [5.254933e-09] 
Layer 'conv4' weights[0]: 2.485480e-03 [1.246061e-07] 
Layer 'conv4' biases: 9.998557e-01 [1.553841e-07] 
Layer 'conv5' weights[0]: 2.650986e-03 [2.340422e-06] 
Layer 'conv5' biases: 9.991165e-01 [2.435561e-06] 
Layer 'fc6' weights[0]: 6.726543e-03 [6.337872e-08] 
Layer 'fc6' biases: 9.999896e-01 [5.701141e-08] 
Layer 'fc7' weights[0]: 7.070284e-03 [1.523127e-07] 
Layer 'fc7' biases: 9.997151e-01 [2.118855e-07] 
Layer 'fc8' weights[0]: 4.746977e-03 [1.464139e-05] 
Layer 'fc8' biases: 2.422916e-02 [3.600329e-05] 
Train error last 800 batches: 0.656288
-------------------------------------------------------
Not saving because 0.505955 > 0.299667 (9.300: -1.18%)
======================================================= (2.356 sec)
30.181... logprob:  0.776739, 0.361979 (1.413 sec)
30.182... logprob:  0.604979, 0.277344 (1.413 sec)
30.183... logprob:  0.664239, 0.296875 (1.409 sec)
30.184... logprob:  0.722907, 0.298177 (1.410 sec)
30.185... logprob:  0.548547, 0.268229 (1.391 sec)
30.186... logprob:  0.633709, 0.281250 (1.391 sec)
30.187... logprob:  0.742412, 0.274740 (1.397 sec)
30.188... logprob:  0.704243, 0.322917 (1.387 sec)
30.189... logprob:  0.550172, 0.253906 (1.385 sec)
30.190... logprob:  0.620399, 0.286458 (1.430 sec)
30.191... logprob:  0.753707, 0.352865 (1.396 sec)
30.192... logprob:  0.739496, 0.330729 (1.416 sec)
30.193... logprob:  0.454829, 0.201823 (1.407 sec)
30.194... logprob:  0.633645, 0.276042 (1.409 sec)
30.195... logprob:  0.603871, 0.253906 (1.395 sec)
30.196... logprob:  0.640640, 0.272135 (1.384 sec)
30.197... logprob:  0.685844, 0.305990 (1.392 sec)
30.198... logprob:  0.542540, 0.244792 (1.394 sec)
30.199... logprob:  0.636423, 0.261719 (1.386 sec)
30.200... logprob:  0.654614, 0.292969 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.474341, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.478552e-03 [1.240166e-07] 
Layer 'conv1' biases: 2.168891e-06 [5.069726e-11] 
Layer 'conv2' weights[0]: 2.473626e-03 [1.237651e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.292364e-10] 
Layer 'conv3' weights[0]: 2.472521e-03 [1.239637e-07] 
Layer 'conv3' biases: 3.605775e-05 [6.039625e-09] 
Layer 'conv4' weights[0]: 2.482979e-03 [1.247304e-07] 
Layer 'conv4' biases: 9.998538e-01 [1.847022e-07] 
Layer 'conv5' weights[0]: 2.647133e-03 [2.377726e-06] 
Layer 'conv5' biases: 9.991155e-01 [2.546959e-06] 
Layer 'fc6' weights[0]: 6.725841e-03 [6.251216e-08] 
Layer 'fc6' biases: 9.999896e-01 [5.571232e-08] 
Layer 'fc7' weights[0]: 7.069615e-03 [1.433540e-07] 
Layer 'fc7' biases: 9.997154e-01 [1.946268e-07] 
Layer 'fc8' weights[0]: 4.760356e-03 [1.299616e-05] 
Layer 'fc8' biases: 2.432266e-02 [2.190469e-05] 
Train error last 800 batches: 0.656484
-------------------------------------------------------
Not saving because 0.474341 > 0.299667 (9.300: -1.18%)
======================================================= (2.369 sec)
30.201... logprob:  0.688261, 0.277344 (1.413 sec)
30.202... logprob:  0.673750, 0.283854 (1.404 sec)
30.203... logprob:  0.631901, 0.312500 (1.440 sec)
30.204... logprob:  0.666576, 0.286458 (1.381 sec)
30.205... logprob:  0.583952, 0.265625 (1.396 sec)
30.206... logprob:  0.642529, 0.272135 (1.396 sec)
30.207... logprob:  0.605214, 0.276042 (1.383 sec)
30.208... logprob:  0.695730, 0.290365 (1.388 sec)
30.209... logprob:  0.556859, 0.281250 (1.414 sec)
30.210... logprob:  0.795313, 0.325521 (1.408 sec)
30.211... logprob:  0.627414, 0.259115 (1.409 sec)
30.212... logprob:  0.805251, 0.330729 (1.403 sec)
30.213... logprob:  0.711002, 0.303385 (1.455 sec)
30.214... logprob:  0.679693, 0.295573 (1.418 sec)
30.215... logprob:  0.599577, 0.279948 (1.407 sec)
30.216... logprob:  0.753430, 0.333333 (1.481 sec)
30.217... logprob:  0.575910, 0.269531 (1.393 sec)
30.218... logprob:  0.698164, 0.269531 (1.417 sec)
30.219... logprob:  0.657283, 0.264323 (1.408 sec)
30.220... logprob:  0.663026, 0.274740 (1.414 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.427269, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.476080e-03 [1.238249e-07] 
Layer 'conv1' biases: 2.169042e-06 [3.749766e-11] 
Layer 'conv2' weights[0]: 2.471162e-03 [1.235981e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.187766e-10] 
Layer 'conv3' weights[0]: 2.470027e-03 [1.236994e-07] 
Layer 'conv3' biases: 3.605425e-05 [5.499985e-09] 
Layer 'conv4' weights[0]: 2.480509e-03 [1.243006e-07] 
Layer 'conv4' biases: 9.998533e-01 [1.694277e-07] 
Layer 'conv5' weights[0]: 2.644197e-03 [2.548765e-06] 
Layer 'conv5' biases: 9.991165e-01 [2.693260e-06] 
Layer 'fc6' weights[0]: 6.725122e-03 [6.693285e-08] 
Layer 'fc6' biases: 9.999898e-01 [6.156311e-08] 
Layer 'fc7' weights[0]: 7.068884e-03 [1.548076e-07] 
Layer 'fc7' biases: 9.997149e-01 [2.193572e-07] 
Layer 'fc8' weights[0]: 4.756462e-03 [1.396957e-05] 
Layer 'fc8' biases: 2.434685e-02 [3.003836e-05] 
Train error last 800 batches: 0.656155
-------------------------------------------------------
Not saving because 0.427269 > 0.299667 (9.300: -1.18%)
======================================================= (2.355 sec)
30.221... logprob:  0.711414, 0.303385 (1.403 sec)
30.222... logprob:  0.759968, 0.342448 (1.458 sec)
30.223... logprob:  0.742503, 0.329427 (1.425 sec)
30.224... logprob:  0.593377, 0.252604 (1.426 sec)
30.225... logprob:  0.634620, 0.264323 (1.435 sec)
30.226... logprob:  0.656357, 0.292969 (1.420 sec)
30.227... logprob:  0.682122, 0.315104 (1.408 sec)
30.228... logprob:  0.693769, 0.312500 (1.406 sec)
30.229... logprob:  0.663712, 0.289062 (1.413 sec)
30.230... logprob:  0.706518, 0.298177 (1.416 sec)
30.231... logprob:  0.655582, 0.286458 (1.395 sec)
30.232... logprob:  0.666501, 0.282552 (1.454 sec)
30.233... logprob:  0.723342, 0.322917 (1.418 sec)
30.234... logprob:  0.653138, 0.299479 (1.411 sec)
30.235... logprob:  0.719658, 0.302083 (1.462 sec)
30.236... logprob:  0.648419, 0.281250 (1.399 sec)
30.237... logprob:  0.599706, 0.278646 (1.421 sec)
30.238... logprob:  0.698538, 0.311198 (1.407 sec)
30.239... logprob:  0.738407, 0.313802 (1.415 sec)
30.240... logprob:  0.642860, 0.286458 (1.395 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.458622, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.473608e-03 [1.237399e-07] 
Layer 'conv1' biases: 2.169346e-06 [3.600584e-11] 
Layer 'conv2' weights[0]: 2.468686e-03 [1.235038e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.183427e-10] 
Layer 'conv3' weights[0]: 2.467560e-03 [1.236469e-07] 
Layer 'conv3' biases: 3.606931e-05 [5.238862e-09] 
Layer 'conv4' weights[0]: 2.478029e-03 [1.242739e-07] 
Layer 'conv4' biases: 9.998538e-01 [1.589852e-07] 
Layer 'conv5' weights[0]: 2.642476e-03 [2.337991e-06] 
Layer 'conv5' biases: 9.991394e-01 [2.487293e-06] 
Layer 'fc6' weights[0]: 6.724431e-03 [6.066397e-08] 
Layer 'fc6' biases: 9.999897e-01 [5.320357e-08] 
Layer 'fc7' weights[0]: 7.068181e-03 [1.417443e-07] 
Layer 'fc7' biases: 9.997131e-01 [1.772397e-07] 
Layer 'fc8' weights[0]: 4.709028e-03 [1.272722e-05] 
Layer 'fc8' biases: 2.395682e-02 [2.644237e-05] 
Train error last 800 batches: 0.656136
-------------------------------------------------------
Not saving because 0.458622 > 0.299667 (9.300: -1.18%)
======================================================= (2.397 sec)
30.241... logprob:  0.698549, 0.282552 (1.457 sec)
30.242... logprob:  0.636923, 0.265625 (1.429 sec)
30.243... logprob:  0.702018, 0.303385 (1.429 sec)
30.244... logprob:  0.519329, 0.231771 (1.441 sec)
30.245... logprob:  0.596726, 0.270833 (1.417 sec)
30.246... logprob:  0.645282, 0.277344 (1.407 sec)
30.247... logprob:  0.617367, 0.278646 (1.409 sec)
30.248... logprob:  0.604312, 0.290365 (1.413 sec)
30.249... logprob:  0.740509, 0.337240 (1.420 sec)
30.250... logprob:  0.795321, 0.325521 (1.401 sec)
30.251... logprob:  0.611750, 0.247396 (1.453 sec)
30.252... logprob:  0.614223, 0.273437 (1.420 sec)
30.253... logprob:  0.666948, 0.283854 (1.409 sec)
30.254... logprob:  0.625111, 0.283854 (1.462 sec)
30.255... logprob:  0.570504, 0.256510 (1.425 sec)
30.256... logprob:  0.596647, 0.259114 (1.416 sec)
30.257... logprob:  0.543823, 0.260417 (1.407 sec)
30.258... logprob:  0.631227, 0.282552 (1.415 sec)
30.259... logprob:  0.600180, 0.251302 (1.398 sec)
30.260... logprob:  0.576462, 0.266927 (1.447 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.369604, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.471126e-03 [1.236573e-07] 
Layer 'conv1' biases: 2.169703e-06 [7.155157e-11] 
Layer 'conv2' weights[0]: 2.466223e-03 [1.234170e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.777765e-10] 
Layer 'conv3' weights[0]: 2.465121e-03 [1.237701e-07] 
Layer 'conv3' biases: 3.605766e-05 [8.193496e-09] 
Layer 'conv4' weights[0]: 2.475552e-03 [1.246164e-07] 
Layer 'conv4' biases: 9.998511e-01 [2.302517e-07] 
Layer 'conv5' weights[0]: 2.638583e-03 [3.888982e-06] 
Layer 'conv5' biases: 9.990920e-01 [4.230470e-06] 
Layer 'fc6' weights[0]: 6.723727e-03 [7.296977e-08] 
Layer 'fc6' biases: 9.999893e-01 [6.903638e-08] 
Layer 'fc7' weights[0]: 7.067454e-03 [1.732093e-07] 
Layer 'fc7' biases: 9.997157e-01 [3.006511e-07] 
Layer 'fc8' weights[0]: 4.793825e-03 [1.627266e-05] 
Layer 'fc8' biases: 2.473375e-02 [5.475262e-05] 
Train error last 800 batches: 0.656012
-------------------------------------------------------
Not saving because 0.369604 > 0.299667 (9.300: -1.18%)
======================================================= (2.350 sec)
30.261... logprob:  0.679383, 0.281250 (1.443 sec)
30.262... logprob:  0.768610, 0.300781 (1.429 sec)
30.263... logprob:  0.521023, 0.251302 (1.436 sec)
30.264... logprob:  0.673880, 0.292969 (1.422 sec)
30.265... logprob:  0.666198, 0.299479 (1.406 sec)
30.266... logprob:  0.640419, 0.281250 (1.406 sec)
30.267... logprob:  0.568090, 0.259115 (1.412 sec)
30.268... logprob:  0.752471, 0.325521 (1.432 sec)
30.269... logprob:  0.895084, 0.398438 (1.399 sec)
30.270... logprob:  0.771704, 0.302083 (1.453 sec)
30.271... logprob:  0.627631, 0.269531 (1.423 sec)
30.272... logprob:  0.611746, 0.283854 (1.409 sec)
30.273... logprob:  0.747445, 0.335937 (1.458 sec)
30.274... logprob:  0.723026, 0.337240 (1.397 sec)
30.275... logprob:  0.751143, 0.307292 (1.413 sec)
30.276... logprob:  0.574789, 0.239583 (1.409 sec)
30.277... logprob:  0.720423, 0.304687 (1.433 sec)
30.278... logprob:  0.552876, 0.235677 (1.415 sec)
30.279... logprob:  0.557939, 0.257812 (1.457 sec)
30.280... logprob:  0.511543, 0.243490 (1.399 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.556663, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.468658e-03 [1.234631e-07] 
Layer 'conv1' biases: 2.169978e-06 [4.212858e-11] 
Layer 'conv2' weights[0]: 2.463752e-03 [1.232410e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.472686e-10] 
Layer 'conv3' weights[0]: 2.462631e-03 [1.233288e-07] 
Layer 'conv3' biases: 3.609125e-05 [4.875864e-09] 
Layer 'conv4' weights[0]: 2.473068e-03 [1.238937e-07] 
Layer 'conv4' biases: 9.998517e-01 [1.305898e-07] 
Layer 'conv5' weights[0]: 2.637087e-03 [2.305841e-06] 
Layer 'conv5' biases: 9.991047e-01 [2.499577e-06] 
Layer 'fc6' weights[0]: 6.723086e-03 [5.927569e-08] 
Layer 'fc6' biases: 9.999896e-01 [5.194691e-08] 
Layer 'fc7' weights[0]: 7.066765e-03 [1.347935e-07] 
Layer 'fc7' biases: 9.997150e-01 [1.794939e-07] 
Layer 'fc8' weights[0]: 4.762585e-03 [1.217201e-05] 
Layer 'fc8' biases: 2.451146e-02 [2.658215e-05] 
Train error last 800 batches: 0.656543
-------------------------------------------------------
Not saving because 0.556663 > 0.299667 (9.300: -1.18%)
======================================================= (2.378 sec)
30.281... logprob:  0.641976, 0.285156 (1.424 sec)
30.282... logprob:  0.606341, 0.282552 (1.421 sec)
30.283... logprob:  0.677456, 0.283854 (1.412 sec)
30.284... logprob:  0.634453, 0.274739 (1.407 sec)
30.285... logprob:  0.668423, 0.300781 (1.429 sec)
30.286... logprob:  0.697036, 0.299479 (1.433 sec)
30.287... logprob:  0.592952, 0.270833 (1.425 sec)
30.288... logprob:  0.588337, 0.255208 (1.429 sec)
30.289... logprob:  0.630003, 0.302083 (1.438 sec)
30.290... logprob:  0.700924, 0.321614 (1.400 sec)
30.291... logprob:  0.653746, 0.302083 (1.411 sec)
30.292... logprob:  0.720344, 0.282552 (1.410 sec)
30.293... logprob:  0.706472, 0.298177 (1.416 sec)
30.294... logprob:  0.600943, 0.272135 (1.402 sec)
30.295... logprob:  0.587166, 0.242187 (1.461 sec)
30.296... logprob:  0.508850, 0.223958 (1.412 sec)
30.297... logprob:  0.594110, 0.244791 (1.419 sec)
30.298... logprob:  0.622083, 0.276042 (1.460 sec)
30.299... logprob:  0.593296, 0.265625 (1.396 sec)
30.300... logprob:  0.697616, 0.307292 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.451706, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.466195e-03 [1.233892e-07] 
Layer 'conv1' biases: 2.170219e-06 [3.597936e-11] 
Layer 'conv2' weights[0]: 2.461285e-03 [1.231435e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.185939e-10] 
Layer 'conv3' weights[0]: 2.460193e-03 [1.232175e-07] 
Layer 'conv3' biases: 3.609857e-05 [4.569654e-09] 
Layer 'conv4' weights[0]: 2.470589e-03 [1.238131e-07] 
Layer 'conv4' biases: 9.998517e-01 [1.419909e-07] 
Layer 'conv5' weights[0]: 2.634963e-03 [2.274950e-06] 
Layer 'conv5' biases: 9.990873e-01 [2.413562e-06] 
Layer 'fc6' weights[0]: 6.722383e-03 [6.034352e-08] 
Layer 'fc6' biases: 9.999894e-01 [5.372661e-08] 
Layer 'fc7' weights[0]: 7.066061e-03 [1.363143e-07] 
Layer 'fc7' biases: 9.997159e-01 [1.675927e-07] 
Layer 'fc8' weights[0]: 4.797366e-03 [1.127000e-05] 
Layer 'fc8' biases: 2.483298e-02 [1.659857e-05] 
Train error last 800 batches: 0.657152
-------------------------------------------------------
Not saving because 0.451706 > 0.299667 (9.300: -1.18%)
======================================================= (2.388 sec)
30.301... logprob:  0.633437, 0.270833 (1.423 sec)
30.302... logprob:  0.757126, 0.335938 (1.410 sec)
30.303... logprob:  0.622646, 0.291667 (1.399 sec)
30.304... logprob:  0.718077, 0.307292 (1.439 sec)
30.305... logprob:  0.641003, 0.290365 (1.435 sec)
30.306... logprob:  0.615292, 0.265625 (1.428 sec)
30.307... logprob:  0.624411, 0.279948 (1.435 sec)
30.308... logprob:  0.595331, 0.276042 (1.449 sec)
30.309... logprob:  0.721064, 0.317708 (1.409 sec)
30.310... logprob:  0.710458, 0.312500 (1.415 sec)
30.311... logprob:  0.637567, 0.277344 (1.418 sec)
30.312... logprob:  0.708506, 0.298177 (1.425 sec)
30.313... logprob:  0.678201, 0.290365 (1.418 sec)
30.314... logprob:  0.669721, 0.300781 (1.465 sec)
30.315... logprob:  0.554485, 0.261719 (1.425 sec)
30.316... logprob:  0.583427, 0.244792 (1.419 sec)
30.317... logprob:  0.575043, 0.268229 (1.471 sec)
30.318... logprob:  0.600702, 0.282552 (1.400 sec)
30.319... logprob:  0.638704, 0.282552 (1.423 sec)
30.320... logprob:  0.663715, 0.291667 (1.418 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.391201, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.463725e-03 [1.232088e-07] 
Layer 'conv1' biases: 2.170409e-06 [4.291845e-11] 
Layer 'conv2' weights[0]: 2.458819e-03 [1.229885e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.986570e-10] 
Layer 'conv3' weights[0]: 2.457733e-03 [1.230793e-07] 
Layer 'conv3' biases: 3.612528e-05 [4.405163e-09] 
Layer 'conv4' weights[0]: 2.468135e-03 [1.236683e-07] 
Layer 'conv4' biases: 9.998519e-01 [1.456733e-07] 
Layer 'conv5' weights[0]: 2.633019e-03 [2.335830e-06] 
Layer 'conv5' biases: 9.990929e-01 [2.479151e-06] 
Layer 'fc6' weights[0]: 6.721691e-03 [5.982721e-08] 
Layer 'fc6' biases: 9.999896e-01 [5.273155e-08] 
Layer 'fc7' weights[0]: 7.065350e-03 [1.363926e-07] 
Layer 'fc7' biases: 9.997156e-01 [1.739669e-07] 
Layer 'fc8' weights[0]: 4.785507e-03 [1.293187e-05] 
Layer 'fc8' biases: 2.472758e-02 [3.434934e-05] 
Train error last 800 batches: 0.656574
-------------------------------------------------------
Not saving because 0.391201 > 0.299667 (9.300: -1.18%)
======================================================= (2.374 sec)
30.321... logprob:  0.617758, 0.273437 (1.431 sec)
30.322... logprob:  0.618591, 0.305990 (1.412 sec)
30.323... logprob:  0.639462, 0.274740 (1.476 sec)
30.324... logprob:  0.668593, 0.294271 (1.417 sec)
30.325... logprob:  0.621401, 0.279948 (1.432 sec)
30.326... logprob:  0.775056, 0.311198 (1.456 sec)
30.327... logprob:  0.708844, 0.317708 (1.414 sec)
30.328... logprob:  0.789111, 0.346354 (1.425 sec)
30.329... logprob:  0.650751, 0.279948 (1.421 sec)
30.330... logprob:  0.594876, 0.264323 (1.411 sec)
30.331... logprob:  0.595652, 0.256510 (1.413 sec)
30.332... logprob:  0.621963, 0.251302 (1.457 sec)
30.333... logprob:  0.608426, 0.278646 (1.436 sec)
30.334... logprob:  0.788404, 0.324219 (1.437 sec)
30.335... logprob:  0.648197, 0.276042 (1.435 sec)
30.336... logprob:  0.700328, 0.307292 (1.447 sec)
30.337... logprob:  0.736505, 0.304687 (1.407 sec)
30.338... logprob:  0.642104, 0.308594 (1.416 sec)
30.339... logprob:  0.685300, 0.304687 (1.421 sec)
30.340... logprob:  0.628986, 0.287760 (1.424 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.452080, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.461273e-03 [1.231529e-07] 
Layer 'conv1' biases: 2.170491e-06 [4.972965e-11] 
Layer 'conv2' weights[0]: 2.456355e-03 [1.228678e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.985025e-10] 
Layer 'conv3' weights[0]: 2.455258e-03 [1.231618e-07] 
Layer 'conv3' biases: 3.612973e-05 [7.569059e-09] 
Layer 'conv4' weights[0]: 2.465653e-03 [1.238512e-07] 
Layer 'conv4' biases: 9.998528e-01 [2.148544e-07] 
Layer 'conv5' weights[0]: 2.631487e-03 [2.142005e-06] 
Layer 'conv5' biases: 9.991114e-01 [2.355932e-06] 
Layer 'fc6' weights[0]: 6.721019e-03 [6.455390e-08] 
Layer 'fc6' biases: 9.999896e-01 [5.894104e-08] 
Layer 'fc7' weights[0]: 7.064688e-03 [1.519095e-07] 
Layer 'fc7' biases: 9.997134e-01 [2.156806e-07] 
Layer 'fc8' weights[0]: 4.743933e-03 [1.416712e-05] 
Layer 'fc8' biases: 2.439685e-02 [2.938082e-05] 
Train error last 800 batches: 0.656728
-------------------------------------------------------
Not saving because 0.452080 > 0.299667 (9.300: -1.18%)
======================================================= (2.363 sec)
30.341... logprob:  0.851032, 0.332031 (1.422 sec)
30.342... logprob:  0.585798, 0.273437 (1.463 sec)
30.343... logprob:  0.727305, 0.294271 (1.440 sec)
30.344... logprob:  0.583569, 0.257812 (1.484 sec)
30.345... logprob:  0.620892, 0.281250 (1.434 sec)
30.346... logprob:  0.626939, 0.272135 (1.428 sec)
30.347... logprob:  0.546058, 0.212240 (1.478 sec)
30.348... logprob:  0.634824, 0.281250 (1.426 sec)
30.349... logprob:  0.659729, 0.300781 (1.422 sec)
30.350... logprob:  0.587742, 0.247396 (1.431 sec)
30.351... logprob:  0.727615, 0.299479 (1.425 sec)
30.352... logprob:  0.576832, 0.291667 (1.427 sec)
30.353... logprob:  0.662200, 0.296875 (1.484 sec)
30.354... logprob:  0.814401, 0.328125 (1.421 sec)
30.355... logprob:  0.657591, 0.292969 (1.440 sec)
30.356... logprob:  0.665256, 0.287760 (1.469 sec)
30.357... logprob:  0.533708, 0.235677 (1.428 sec)
30.358... logprob:  0.592644, 0.256510 (1.430 sec)
30.359... logprob:  0.815195, 0.341146 (1.436 sec)
30.360... logprob:  0.680707, 0.270833 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.481599, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.458806e-03 [1.229862e-07] 
Layer 'conv1' biases: 2.170543e-06 [3.730772e-11] 
Layer 'conv2' weights[0]: 2.453901e-03 [1.227363e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.040018e-10] 
Layer 'conv3' weights[0]: 2.452799e-03 [1.228849e-07] 
Layer 'conv3' biases: 3.613590e-05 [5.269476e-09] 
Layer 'conv4' weights[0]: 2.463182e-03 [1.235150e-07] 
Layer 'conv4' biases: 9.998534e-01 [1.696955e-07] 
Layer 'conv5' weights[0]: 2.630060e-03 [2.609706e-06] 
Layer 'conv5' biases: 9.990985e-01 [2.888028e-06] 
Layer 'fc6' weights[0]: 6.720353e-03 [6.648890e-08] 
Layer 'fc6' biases: 9.999896e-01 [6.132866e-08] 
Layer 'fc7' weights[0]: 7.063955e-03 [1.510543e-07] 
Layer 'fc7' biases: 9.997138e-01 [1.979283e-07] 
Layer 'fc8' weights[0]: 4.752245e-03 [1.327679e-05] 
Layer 'fc8' biases: 2.442440e-02 [1.931955e-05] 
Train error last 800 batches: 0.656501
-------------------------------------------------------
Not saving because 0.481599 > 0.299667 (9.300: -1.18%)
======================================================= (2.350 sec)
30.361... logprob:  0.615770, 0.272135 (1.427 sec)
30.362... logprob:  0.645808, 0.283854 (1.474 sec)
30.363... logprob:  0.748574, 0.322917 (1.433 sec)
30.364... logprob:  0.680000, 0.283854 (1.444 sec)
30.365... logprob:  0.569523, 0.263021 (1.461 sec)
30.366... logprob:  0.618670, 0.277344 (1.438 sec)
30.367... logprob:  0.643135, 0.279948 (1.430 sec)
30.368... logprob:  0.810295, 0.369792 (1.426 sec)
30.369... logprob:  0.645323, 0.298177 (1.418 sec)
30.370... logprob:  0.677300, 0.320312 (1.450 sec)
30.371... logprob:  0.645163, 0.283854 (1.453 sec)
30.372... logprob:  0.795325, 0.355469 (1.446 sec)
30.373... logprob:  0.650580, 0.305990 (1.448 sec)
30.374... logprob:  0.790454, 0.316406 (1.441 sec)
30.375... logprob:  0.659069, 0.292969 (1.462 sec)
30.376... logprob:  0.594236, 0.286458 (1.429 sec)
30.377... logprob:  0.512767, 0.235677 (1.418 sec)
30.378... logprob:  0.631485, 0.282552 (1.427 sec)
30.379... logprob:  0.644698, 0.282552 (1.427 sec)
30.380... logprob:  0.740959, 0.299479 (1.439 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.505318, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.456352e-03 [1.228215e-07] 
Layer 'conv1' biases: 2.170864e-06 [7.260515e-11] 
Layer 'conv2' weights[0]: 2.451461e-03 [1.226219e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.624848e-10] 
Layer 'conv3' weights[0]: 2.450356e-03 [1.228190e-07] 
Layer 'conv3' biases: 3.612272e-05 [5.872042e-09] 
Layer 'conv4' weights[0]: 2.460732e-03 [1.235212e-07] 
Layer 'conv4' biases: 9.998535e-01 [1.730430e-07] 
Layer 'conv5' weights[0]: 2.627935e-03 [2.255834e-06] 
Layer 'conv5' biases: 9.990951e-01 [2.446961e-06] 
Layer 'fc6' weights[0]: 6.719687e-03 [6.056199e-08] 
Layer 'fc6' biases: 9.999894e-01 [5.381181e-08] 
Layer 'fc7' weights[0]: 7.063231e-03 [1.396428e-07] 
Layer 'fc7' biases: 9.997135e-01 [1.724535e-07] 
Layer 'fc8' weights[0]: 4.753493e-03 [1.182034e-05] 
Layer 'fc8' biases: 2.450080e-02 [1.791219e-05] 
Train error last 800 batches: 0.656799
-------------------------------------------------------
Not saving because 0.505318 > 0.299667 (9.300: -1.18%)
======================================================= (2.376 sec)
30.381... logprob:  0.724099, 0.328125 (1.470 sec)
30.382... logprob:  0.752862, 0.299479 (1.454 sec)
30.383... logprob:  0.556953, 0.261719 (1.439 sec)
30.384... logprob:  0.630075, 0.263021 (1.473 sec)
30.385... logprob:  0.691055, 0.290365 (1.426 sec)
30.386... logprob:  0.767097, 0.315104 (1.423 sec)
30.387... logprob:  0.713878, 0.300781 (1.425 sec)
30.388... logprob:  0.812466, 0.317708 (1.432 sec)
30.389... logprob:  0.661337, 0.283854 (1.424 sec)
30.390... logprob:  0.563875, 0.247396 (1.471 sec)
30.391... logprob:  0.470359, 0.183594 (1.438 sec)
30.392... logprob:  0.672761, 0.302083 (1.427 sec)
30.393... logprob:  0.581267, 0.264323 (1.483 sec)
30.394... logprob:  0.616993, 0.274740 (1.421 sec)
30.395... logprob:  0.551833, 0.243490 (1.429 sec)
30.396... logprob:  0.502968, 0.223958 (1.427 sec)
30.397... logprob:  0.612891, 0.269531 (1.426 sec)
30.398... logprob:  0.732826, 0.308594 (1.424 sec)
30.399... logprob:  0.639993, 0.294271 (1.481 sec)
30.400... logprob:  0.710845, 0.300781 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.518487, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.453891e-03 [1.227753e-07] 
Layer 'conv1' biases: 2.171161e-06 [5.170278e-11] 
Layer 'conv2' weights[0]: 2.449013e-03 [1.225243e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.375047e-10] 
Layer 'conv3' weights[0]: 2.447871e-03 [1.226539e-07] 
Layer 'conv3' biases: 3.611416e-05 [5.363703e-09] 
Layer 'conv4' weights[0]: 2.458266e-03 [1.233569e-07] 
Layer 'conv4' biases: 9.998533e-01 [1.626092e-07] 
Layer 'conv5' weights[0]: 2.625216e-03 [2.642435e-06] 
Layer 'conv5' biases: 9.990902e-01 [2.900717e-06] 
Layer 'fc6' weights[0]: 6.719002e-03 [6.291694e-08] 
Layer 'fc6' biases: 9.999894e-01 [5.699444e-08] 
Layer 'fc7' weights[0]: 7.062542e-03 [1.481084e-07] 
Layer 'fc7' biases: 9.997139e-01 [2.038766e-07] 
Layer 'fc8' weights[0]: 4.774351e-03 [1.337091e-05] 
Layer 'fc8' biases: 2.467765e-02 [2.927678e-05] 
Train error last 800 batches: 0.656838
-------------------------------------------------------
Not saving because 0.518487 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
30.401... logprob:  0.672285, 0.257812 (1.448 sec)
30.402... logprob:  0.718631, 0.304688 (1.479 sec)
30.403... logprob:  0.682473, 0.286458 (1.482 sec)
30.404... logprob:  0.665708, 0.307292 (1.431 sec)
30.405... logprob:  0.700706, 0.325521 (1.427 sec)
30.406... logprob:  0.570920, 0.276042 (1.421 sec)
30.407... logprob:  0.716895, 0.334635 (1.424 sec)
30.408... logprob:  0.590659, 0.251302 (1.493 sec)
30.409... logprob:  0.620172, 0.263021 (1.435 sec)
30.410... logprob:  0.759312, 0.330729 (1.441 sec)
30.411... logprob:  0.586854, 0.277344 (1.475 sec)
30.412... logprob:  0.769950, 0.312500 (1.431 sec)
30.413... logprob:  0.821946, 0.334635 (1.431 sec)
30.414... logprob:  0.698059, 0.316406 (1.434 sec)
30.415... logprob:  0.555860, 0.247396 (1.418 sec)
30.416... logprob:  0.609461, 0.286458 (1.429 sec)
30.417... logprob:  0.709776, 0.304687 (1.458 sec)
30.418... logprob:  0.615095, 0.277344 (1.444 sec)
30.419... logprob:  0.624768, 0.277344 (1.447 sec)
30.420... logprob:  0.599875, 0.276042 (1.451 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.518893, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.451441e-03 [1.225594e-07] 
Layer 'conv1' biases: 2.171411e-06 [5.253942e-11] 
Layer 'conv2' weights[0]: 2.446554e-03 [1.223687e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.260584e-10] 
Layer 'conv3' weights[0]: 2.445438e-03 [1.224821e-07] 
Layer 'conv3' biases: 3.611873e-05 [4.411512e-09] 
Layer 'conv4' weights[0]: 2.455818e-03 [1.231617e-07] 
Layer 'conv4' biases: 9.998537e-01 [1.257018e-07] 
Layer 'conv5' weights[0]: 2.623804e-03 [2.042935e-06] 
Layer 'conv5' biases: 9.991010e-01 [2.177655e-06] 
Layer 'fc6' weights[0]: 6.718301e-03 [5.925080e-08] 
Layer 'fc6' biases: 9.999894e-01 [5.207786e-08] 
Layer 'fc7' weights[0]: 7.061834e-03 [1.379013e-07] 
Layer 'fc7' biases: 9.997132e-01 [1.798124e-07] 
Layer 'fc8' weights[0]: 4.751078e-03 [1.217500e-05] 
Layer 'fc8' biases: 2.450298e-02 [2.782459e-05] 
Train error last 800 batches: 0.657078
-------------------------------------------------------
Not saving because 0.518893 > 0.299667 (9.300: -1.18%)
======================================================= (2.408 sec)
30.421... logprob:  0.649902, 0.303385 (1.455 sec)
30.422... logprob:  0.697147, 0.307292 (1.438 sec)
30.423... logprob:  0.600757, 0.273438 (1.415 sec)
30.424... logprob:  0.577784, 0.240885 (1.425 sec)
30.425... logprob:  0.621240, 0.303385 (1.432 sec)
30.426... logprob:  0.744218, 0.307292 (1.439 sec)
30.427... logprob:  0.740493, 0.317708 (1.457 sec)
30.428... logprob:  0.797426, 0.309896 (1.443 sec)
30.429... logprob:  0.645274, 0.313802 (1.438 sec)
30.430... logprob:  0.598983, 0.278646 (1.480 sec)
30.431... logprob:  0.793703, 0.321615 (1.426 sec)
30.432... logprob:  0.559102, 0.269531 (1.420 sec)
30.433... logprob:  0.631194, 0.282552 (1.426 sec)
30.434... logprob:  0.703455, 0.290365 (1.432 sec)
30.435... logprob:  0.794379, 0.326823 (1.427 sec)
30.436... logprob:  0.631417, 0.309896 (1.468 sec)
30.437... logprob:  0.628980, 0.253906 (1.442 sec)
30.438... logprob:  0.715706, 0.304688 (1.422 sec)
30.439... logprob:  0.619864, 0.287760 (1.481 sec)
30.440... logprob:  0.654576, 0.308594 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.454888, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.448986e-03 [1.225088e-07] 
Layer 'conv1' biases: 2.171878e-06 [4.323826e-11] 
Layer 'conv2' weights[0]: 2.444125e-03 [1.222664e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.174013e-10] 
Layer 'conv3' weights[0]: 2.442997e-03 [1.224226e-07] 
Layer 'conv3' biases: 3.612038e-05 [5.073694e-09] 
Layer 'conv4' weights[0]: 2.453352e-03 [1.230326e-07] 
Layer 'conv4' biases: 9.998519e-01 [1.498743e-07] 
Layer 'conv5' weights[0]: 2.620078e-03 [2.212002e-06] 
Layer 'conv5' biases: 9.991021e-01 [2.408236e-06] 
Layer 'fc6' weights[0]: 6.717628e-03 [6.475807e-08] 
Layer 'fc6' biases: 9.999894e-01 [5.933462e-08] 
Layer 'fc7' weights[0]: 7.061096e-03 [1.514774e-07] 
Layer 'fc7' biases: 9.997128e-01 [2.191061e-07] 
Layer 'fc8' weights[0]: 4.749394e-03 [1.581985e-05] 
Layer 'fc8' biases: 2.449088e-02 [4.386644e-05] 
Train error last 800 batches: 0.657972
-------------------------------------------------------
Not saving because 0.454888 > 0.299667 (9.300: -1.18%)
======================================================= (2.370 sec)
30.441... logprob:  0.682919, 0.294271 (1.435 sec)
30.442... logprob:  0.621420, 0.282552 (1.437 sec)
30.443... logprob:  0.768216, 0.325521 (1.429 sec)
30.444... logprob:  0.637036, 0.300781 (1.430 sec)
30.445... logprob:  0.662881, 0.292969 (1.476 sec)
30.446... logprob:  0.576075, 0.251302 (1.448 sec)
30.447... logprob:  0.694304, 0.305990 (1.434 sec)
30.448... logprob:  0.595054, 0.270833 (1.481 sec)
30.449... logprob:  0.644071, 0.253906 (1.424 sec)
30.450... logprob:  0.512995, 0.222656 (1.426 sec)
30.451... logprob:  0.630935, 0.255208 (1.431 sec)
30.452... logprob:  0.681512, 0.295573 (1.424 sec)
30.453... logprob:  0.614827, 0.289062 (1.427 sec)
30.454... logprob:  0.607840, 0.274740 (1.475 sec)
30.455... logprob:  0.741331, 0.290365 (1.433 sec)
30.456... logprob:  0.666417, 0.298177 (1.437 sec)
30.457... logprob:  0.587733, 0.277344 (1.469 sec)
30.458... logprob:  0.586443, 0.256510 (1.428 sec)
30.459... logprob:  0.728664, 0.304688 (1.431 sec)
30.460... logprob:  0.528476, 0.252604 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.430299, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.446539e-03 [1.224331e-07] 
Layer 'conv1' biases: 2.171815e-06 [5.887498e-11] 
Layer 'conv2' weights[0]: 2.441659e-03 [1.221949e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.415796e-10] 
Layer 'conv3' weights[0]: 2.440574e-03 [1.224265e-07] 
Layer 'conv3' biases: 3.611274e-05 [6.349338e-09] 
Layer 'conv4' weights[0]: 2.450900e-03 [1.231714e-07] 
Layer 'conv4' biases: 9.998522e-01 [1.734567e-07] 
Layer 'conv5' weights[0]: 2.617960e-03 [2.554219e-06] 
Layer 'conv5' biases: 9.990851e-01 [2.777904e-06] 
Layer 'fc6' weights[0]: 6.716937e-03 [6.680171e-08] 
Layer 'fc6' biases: 9.999893e-01 [6.186156e-08] 
Layer 'fc7' weights[0]: 7.060353e-03 [1.565075e-07] 
Layer 'fc7' biases: 9.997137e-01 [2.427110e-07] 
Layer 'fc8' weights[0]: 4.780330e-03 [1.501221e-05] 
Layer 'fc8' biases: 2.477254e-02 [3.588815e-05] 
Train error last 800 batches: 0.657516
-------------------------------------------------------
Not saving because 0.430299 > 0.299667 (9.300: -1.18%)
======================================================= (2.372 sec)
30.461... logprob:  0.658288, 0.287760 (1.426 sec)
30.462... logprob:  0.729019, 0.326823 (1.436 sec)
30.463... logprob:  0.653238, 0.281250 (1.467 sec)
30.464... logprob:  0.576213, 0.272135 (1.442 sec)
30.465... logprob:  0.645449, 0.256510 (1.449 sec)
30.466... logprob:  0.576807, 0.292969 (1.459 sec)
30.467... logprob:  0.680245, 0.305990 (1.446 sec)
30.468... logprob:  0.533217, 0.234375 (1.430 sec)
30.469... logprob:  0.575350, 0.274740 (1.423 sec)
30.470... logprob:  0.618137, 0.296875 (1.420 sec)
30.471... logprob:  0.699775, 0.300781 (1.432 sec)
30.472... logprob:  0.718736, 0.343750 (1.445 sec)
30.473... logprob:  0.602359, 0.274740 (1.455 sec)
30.474... logprob:  0.671341, 0.312500 (1.443 sec)
30.475... logprob:  0.728165, 0.286458 (1.440 sec)
30.476... logprob:  0.791357, 0.335937 (1.464 sec)
30.477... logprob:  0.574691, 0.246094 (1.431 sec)
30.478... logprob:  0.612291, 0.279948 (1.418 sec)
30.479... logprob:  0.520134, 0.222656 (1.425 sec)
30.480... logprob:  0.631603, 0.274740 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.550776, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.444093e-03 [1.222950e-07] 
Layer 'conv1' biases: 2.172099e-06 [3.126580e-11] 
Layer 'conv2' weights[0]: 2.439220e-03 [1.220233e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.115913e-10] 
Layer 'conv3' weights[0]: 2.438122e-03 [1.220732e-07] 
Layer 'conv3' biases: 3.609724e-05 [4.093466e-09] 
Layer 'conv4' weights[0]: 2.448450e-03 [1.227195e-07] 
Layer 'conv4' biases: 9.998513e-01 [1.311223e-07] 
Layer 'conv5' weights[0]: 2.615420e-03 [2.116566e-06] 
Layer 'conv5' biases: 9.990671e-01 [2.255240e-06] 
Layer 'fc6' weights[0]: 6.716241e-03 [5.924860e-08] 
Layer 'fc6' biases: 9.999896e-01 [5.298262e-08] 
Layer 'fc7' weights[0]: 7.059657e-03 [1.324896e-07] 
Layer 'fc7' biases: 9.997144e-01 [1.570283e-07] 
Layer 'fc8' weights[0]: 4.816830e-03 [1.077916e-05] 
Layer 'fc8' biases: 2.512611e-02 [1.293203e-05] 
Train error last 800 batches: 0.657542
-------------------------------------------------------
Not saving because 0.550776 > 0.299667 (9.300: -1.18%)
======================================================= (2.399 sec)
30.481... logprob:  0.778966, 0.334635 (1.442 sec)
30.482... logprob:  0.637287, 0.279948 (1.474 sec)
30.483... logprob:  0.658469, 0.299479 (1.438 sec)
30.484... logprob:  0.607480, 0.266927 (1.447 sec)
30.485... logprob:  0.710793, 0.322917 (1.478 sec)
30.486... logprob:  0.552403, 0.246094 (1.427 sec)
30.487... logprob:  0.719837, 0.302083 (1.421 sec)
30.488... logprob:  0.661111, 0.302083 (1.428 sec)
30.489... logprob:  0.675664, 0.268229 (1.427 sec)
30.490... logprob:  0.667105, 0.282552 (1.429 sec)
30.491... logprob:  0.584807, 0.273437 (1.473 sec)
30.492... logprob:  0.655094, 0.304688 (1.435 sec)
30.493... logprob:  0.660857, 0.291667 (1.431 sec)
30.494... logprob:  0.704669, 0.292969 (1.471 sec)
30.495... logprob:  0.621519, 0.253906 (1.431 sec)
30.496... logprob:  0.755569, 0.328125 (1.426 sec)
30.497... logprob:  0.807605, 0.347656 (1.429 sec)
30.498... logprob:  0.623343, 0.286458 (1.419 sec)
30.499... logprob:  0.590534, 0.252604 (1.432 sec)
30.500... logprob:  0.637320, 0.279948 (1.479 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.392295, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.441645e-03 [1.221226e-07] 
Layer 'conv1' biases: 2.172149e-06 [3.511940e-11] 
Layer 'conv2' weights[0]: 2.436788e-03 [1.218803e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.710436e-10] 
Layer 'conv3' weights[0]: 2.435695e-03 [1.220003e-07] 
Layer 'conv3' biases: 3.610509e-05 [4.975701e-09] 
Layer 'conv4' weights[0]: 2.446012e-03 [1.226075e-07] 
Layer 'conv4' biases: 9.998507e-01 [1.600301e-07] 
Layer 'conv5' weights[0]: 2.612931e-03 [2.533257e-06] 
Layer 'conv5' biases: 9.990929e-01 [2.758699e-06] 
Layer 'fc6' weights[0]: 6.715584e-03 [6.380398e-08] 
Layer 'fc6' biases: 9.999898e-01 [5.822956e-08] 
Layer 'fc7' weights[0]: 7.058968e-03 [1.510103e-07] 
Layer 'fc7' biases: 9.997128e-01 [2.177812e-07] 
Layer 'fc8' weights[0]: 4.761845e-03 [1.387727e-05] 
Layer 'fc8' biases: 2.467843e-02 [2.858882e-05] 
Train error last 800 batches: 0.657713
-------------------------------------------------------
Not saving because 0.392295 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
30.501... logprob:  0.536597, 0.235677 (1.432 sec)
30.502... logprob:  0.740616, 0.350260 (1.445 sec)
30.503... logprob:  0.613357, 0.264323 (1.476 sec)
30.504... logprob:  0.678650, 0.286458 (1.428 sec)
30.505... logprob:  0.740263, 0.300781 (1.431 sec)
30.506... logprob:  0.754072, 0.303385 (1.425 sec)
30.507... logprob:  0.566613, 0.233073 (1.421 sec)
30.508... logprob:  0.607064, 0.279948 (1.429 sec)
30.509... logprob:  0.569432, 0.227865 (1.467 sec)
30.510... logprob:  0.659703, 0.291667 (1.441 sec)
30.511... logprob:  0.637452, 0.277344 (1.448 sec)
30.512... logprob:  0.674229, 0.295573 (1.460 sec)
30.513... logprob:  0.627408, 0.298177 (1.435 sec)
30.514... logprob:  0.727261, 0.315104 (1.437 sec)
30.515... logprob:  0.760734, 0.316406 (1.419 sec)
30.516... logprob:  0.615360, 0.266927 (1.422 sec)
30.517... logprob:  0.842578, 0.364583 (1.434 sec)
30.518... logprob:  0.662580, 0.302083 (1.456 sec)
30.519... logprob:  0.772701, 0.355469 (1.449 sec)
30.520... logprob:  0.599491, 0.244792 (1.445 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.535152, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.439207e-03 [1.219942e-07] 
Layer 'conv1' biases: 2.172396e-06 [4.431956e-11] 
Layer 'conv2' weights[0]: 2.434342e-03 [1.217469e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.550128e-10] 
Layer 'conv3' weights[0]: 2.433246e-03 [1.219048e-07] 
Layer 'conv3' biases: 3.610556e-05 [5.502044e-09] 
Layer 'conv4' weights[0]: 2.443566e-03 [1.224888e-07] 
Layer 'conv4' biases: 9.998496e-01 [1.675464e-07] 
Layer 'conv5' weights[0]: 2.609767e-03 [2.597826e-06] 
Layer 'conv5' biases: 9.991030e-01 [2.680932e-06] 
Layer 'fc6' weights[0]: 6.714893e-03 [6.486836e-08] 
Layer 'fc6' biases: 9.999899e-01 [5.917450e-08] 
Layer 'fc7' weights[0]: 7.058268e-03 [1.515006e-07] 
Layer 'fc7' biases: 9.997120e-01 [2.103109e-07] 
Layer 'fc8' weights[0]: 4.741855e-03 [1.389380e-05] 
Layer 'fc8' biases: 2.456745e-02 [3.345249e-05] 
Train error last 800 batches: 0.658330
-------------------------------------------------------
Not saving because 0.535152 > 0.299667 (9.300: -1.18%)
======================================================= (2.359 sec)
30.521... logprob:  0.703436, 0.322917 (1.457 sec)
30.522... logprob:  0.794118, 0.334635 (1.455 sec)
30.523... logprob:  0.648294, 0.311198 (1.437 sec)
30.524... logprob:  0.624455, 0.283854 (1.418 sec)
30.525... logprob:  0.625345, 0.272135 (1.428 sec)
30.526... logprob:  0.574898, 0.252604 (1.430 sec)
30.527... logprob:  0.635090, 0.265625 (1.432 sec)
30.528... logprob:  0.650299, 0.278646 (1.464 sec)
30.529... logprob:  0.669730, 0.283854 (1.449 sec)
30.530... logprob:  0.689891, 0.302083 (1.437 sec)
30.531... logprob:  0.632589, 0.300781 (1.469 sec)
30.532... logprob:  0.656997, 0.263021 (1.430 sec)
30.533... logprob:  0.764896, 0.341146 (1.419 sec)
30.534... logprob:  0.601385, 0.255208 (1.429 sec)
30.535... logprob:  0.751999, 0.295573 (1.427 sec)
30.536... logprob:  0.803657, 0.345052 (1.430 sec)
30.537... logprob:  0.763308, 0.321614 (1.469 sec)
30.538... logprob:  0.694339, 0.312500 (1.439 sec)
30.539... logprob:  0.567684, 0.242187 (1.426 sec)
30.540... logprob:  0.760984, 0.346354 (1.484 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.397056, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.436778e-03 [1.218759e-07] 
Layer 'conv1' biases: 2.172752e-06 [3.955164e-11] 
Layer 'conv2' weights[0]: 2.431932e-03 [1.216438e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.795305e-10] 
Layer 'conv3' weights[0]: 2.430814e-03 [1.217958e-07] 
Layer 'conv3' biases: 3.610198e-05 [5.680544e-09] 
Layer 'conv4' weights[0]: 2.441128e-03 [1.223677e-07] 
Layer 'conv4' biases: 9.998496e-01 [1.630824e-07] 
Layer 'conv5' weights[0]: 2.607579e-03 [2.541290e-06] 
Layer 'conv5' biases: 9.991118e-01 [2.720417e-06] 
Layer 'fc6' weights[0]: 6.714190e-03 [6.683590e-08] 
Layer 'fc6' biases: 9.999897e-01 [6.146827e-08] 
Layer 'fc7' weights[0]: 7.057591e-03 [1.549889e-07] 
Layer 'fc7' biases: 9.997109e-01 [2.181415e-07] 
Layer 'fc8' weights[0]: 4.713051e-03 [1.320114e-05] 
Layer 'fc8' biases: 2.437442e-02 [2.926134e-05] 
Train error last 800 batches: 0.658490
-------------------------------------------------------
Not saving because 0.397056 > 0.299667 (9.300: -1.18%)
======================================================= (2.349 sec)
30.541... logprob:  0.632168, 0.281250 (1.437 sec)
30.542... logprob:  0.668660, 0.299479 (1.433 sec)
30.543... logprob:  0.516273, 0.231771 (1.435 sec)
30.544... logprob:  0.590445, 0.240885 (1.421 sec)
30.545... logprob:  0.593076, 0.252604 (1.429 sec)
30.546... logprob:  0.586382, 0.273437 (1.480 sec)
30.547... logprob:  0.653443, 0.282552 (1.426 sec)
30.548... logprob:  0.717845, 0.272135 (1.436 sec)
30.549... logprob:  0.716075, 0.309896 (1.472 sec)
30.550... logprob:  0.535195, 0.238281 (1.432 sec)
30.551... logprob:  0.736820, 0.309896 (1.423 sec)
30.552... logprob:  0.745300, 0.313802 (1.429 sec)
30.553... logprob:  0.592211, 0.276042 (1.425 sec)
30.554... logprob:  0.744044, 0.311198 (1.422 sec)
30.555... logprob:  0.606555, 0.246094 (1.475 sec)
30.556... logprob:  0.577789, 0.252604 (1.434 sec)
30.557... logprob:  0.546706, 0.235677 (1.442 sec)
30.558... logprob:  0.695649, 0.302083 (1.464 sec)
30.559... logprob:  0.526801, 0.229167 (1.431 sec)
30.560... logprob:  0.541699, 0.238281 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.409882, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.434340e-03 [1.218618e-07] 
Layer 'conv1' biases: 2.172853e-06 [6.379596e-11] 
Layer 'conv2' weights[0]: 2.429489e-03 [1.215879e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.552032e-10] 
Layer 'conv3' weights[0]: 2.428383e-03 [1.221103e-07] 
Layer 'conv3' biases: 3.609603e-05 [9.059907e-09] 
Layer 'conv4' weights[0]: 2.438680e-03 [1.230412e-07] 
Layer 'conv4' biases: 9.998475e-01 [2.733762e-07] 
Layer 'conv5' weights[0]: 2.604127e-03 [3.501995e-06] 
Layer 'conv5' biases: 9.990835e-01 [3.660991e-06] 
Layer 'fc6' weights[0]: 6.713514e-03 [6.907151e-08] 
Layer 'fc6' biases: 9.999899e-01 [6.432785e-08] 
Layer 'fc7' weights[0]: 7.056870e-03 [1.655325e-07] 
Layer 'fc7' biases: 9.997120e-01 [2.705756e-07] 
Layer 'fc8' weights[0]: 4.766797e-03 [1.524860e-05] 
Layer 'fc8' biases: 2.478779e-02 [4.654904e-05] 
Train error last 800 batches: 0.658451
-------------------------------------------------------
Not saving because 0.409882 > 0.299667 (9.300: -1.18%)
======================================================= (2.349 sec)
30.561... logprob:  0.657993, 0.303385 (1.437 sec)
30.562... logprob:  0.672885, 0.286458 (1.427 sec)
30.563... logprob:  0.612044, 0.272135 (1.439 sec)
30.564... logprob:  0.684402, 0.296875 (1.456 sec)
30.565... logprob:  0.773367, 0.316406 (1.445 sec)
30.566... logprob:  0.486550, 0.195313 (1.448 sec)
30.567... logprob:  0.707268, 0.313802 (1.448 sec)
30.568... logprob:  0.730752, 0.324219 (1.448 sec)
30.569... logprob:  0.776312, 0.347656 (1.432 sec)
30.570... logprob:  0.815628, 0.338542 (1.418 sec)
30.571... logprob:  0.712468, 0.289062 (1.426 sec)
30.572... logprob:  0.736121, 0.337240 (1.430 sec)
30.573... logprob:  0.665210, 0.298177 (1.438 sec)
30.574... logprob:  0.670932, 0.292969 (1.467 sec)
30.575... logprob:  0.563649, 0.251302 (1.448 sec)
30.576... logprob:  0.672679, 0.329427 (1.444 sec)
30.577... logprob:  0.640634, 0.272135 (1.468 sec)
30.578... logprob:  0.529146, 0.209635 (1.427 sec)
30.579... logprob:  0.679765, 0.303385 (1.421 sec)
30.580... logprob:  0.766307, 0.352865 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.448104, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.431891e-03 [1.216463e-07] 
Layer 'conv1' biases: 2.172960e-06 [3.906223e-11] 
Layer 'conv2' weights[0]: 2.427061e-03 [1.214034e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.201736e-10] 
Layer 'conv3' weights[0]: 2.425950e-03 [1.214609e-07] 
Layer 'conv3' biases: 3.611643e-05 [4.349993e-09] 
Layer 'conv4' weights[0]: 2.436241e-03 [1.219967e-07] 
Layer 'conv4' biases: 9.998480e-01 [1.215722e-07] 
Layer 'conv5' weights[0]: 2.602400e-03 [1.953273e-06] 
Layer 'conv5' biases: 9.990994e-01 [2.110720e-06] 
Layer 'fc6' weights[0]: 6.712862e-03 [5.871119e-08] 
Layer 'fc6' biases: 9.999899e-01 [5.164229e-08] 
Layer 'fc7' weights[0]: 7.056214e-03 [1.370855e-07] 
Layer 'fc7' biases: 9.997111e-01 [1.649334e-07] 
Layer 'fc8' weights[0]: 4.740736e-03 [1.123913e-05] 
Layer 'fc8' biases: 2.455279e-02 [1.146117e-05] 
Train error last 800 batches: 0.658473
-------------------------------------------------------
Not saving because 0.448104 > 0.299667 (9.300: -1.18%)
======================================================= (2.368 sec)
30.581... logprob:  0.755707, 0.312500 (1.442 sec)
30.582... logprob:  0.615780, 0.242187 (1.433 sec)
30.583... logprob:  0.662569, 0.273438 (1.472 sec)
30.584... logprob:  0.670203, 0.304687 (1.433 sec)
30.585... logprob:  0.546824, 0.235677 (1.429 sec)
30.586... logprob:  0.592772, 0.268229 (1.480 sec)
30.587... logprob:  0.656715, 0.285156 (1.429 sec)
30.588... logprob:  0.675541, 0.283854 (1.419 sec)
30.589... logprob:  0.570452, 0.259115 (1.432 sec)
30.590... logprob:  0.729142, 0.311198 (1.426 sec)
30.591... logprob:  0.662902, 0.295573 (1.426 sec)
30.592... logprob:  0.667557, 0.292969 (1.476 sec)
30.593... logprob:  0.623385, 0.292969 (1.434 sec)
30.594... logprob:  0.601215, 0.274740 (1.431 sec)
30.595... logprob:  0.619382, 0.277344 (1.475 sec)
30.596... logprob:  0.658127, 0.309896 (1.423 sec)
30.597... logprob:  0.600435, 0.253906 (1.429 sec)
30.598... logprob:  0.614013, 0.281250 (1.428 sec)
30.599... logprob:  0.482826, 0.210938 (1.421 sec)
30.600... logprob:  0.566108, 0.260417 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.514022, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.429463e-03 [1.216197e-07] 
Layer 'conv1' biases: 2.173349e-06 [7.482903e-11] 
Layer 'conv2' weights[0]: 2.424638e-03 [1.213723e-07] 
Layer 'conv2' biases: 9.999996e-01 [1.072184e-09] 
Layer 'conv3' weights[0]: 2.423529e-03 [1.220914e-07] 
Layer 'conv3' biases: 3.611248e-05 [1.099223e-08] 
Layer 'conv4' weights[0]: 2.433810e-03 [1.232463e-07] 
Layer 'conv4' biases: 9.998478e-01 [3.260419e-07] 
Layer 'conv5' weights[0]: 2.600316e-03 [5.096923e-06] 
Layer 'conv5' biases: 9.990740e-01 [5.765498e-06] 
Layer 'fc6' weights[0]: 6.712164e-03 [8.738278e-08] 
Layer 'fc6' biases: 9.999895e-01 [8.961628e-08] 
Layer 'fc7' weights[0]: 7.055486e-03 [2.254741e-07] 
Layer 'fc7' biases: 9.997126e-01 [4.370541e-07] 
Layer 'fc8' weights[0]: 4.793548e-03 [2.282058e-05] 
Layer 'fc8' biases: 2.497836e-02 [8.553594e-05] 
Train error last 800 batches: 0.657456
-------------------------------------------------------
Not saving because 0.514022 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
30.601... logprob:  0.573130, 0.264323 (1.487 sec)
30.602... logprob:  0.540793, 0.253906 (1.437 sec)
30.603... logprob:  0.556242, 0.260417 (1.442 sec)
30.604... logprob:  0.680024, 0.328125 (1.471 sec)
30.605... logprob:  0.713748, 0.289062 (1.426 sec)
30.606... logprob:  0.526842, 0.235677 (1.434 sec)
30.607... logprob:  0.755481, 0.315104 (1.426 sec)
30.608... logprob:  0.544639, 0.230469 (1.421 sec)
30.609... logprob:  0.596905, 0.248698 (1.425 sec)
30.610... logprob:  0.746260, 0.305990 (1.465 sec)
30.611... logprob:  0.718007, 0.326823 (1.439 sec)
30.612... logprob:  0.677063, 0.268229 (1.449 sec)
30.613... logprob:  0.587395, 0.276042 (1.464 sec)
30.614... logprob:  0.738977, 0.308594 (1.440 sec)
30.615... logprob:  0.547468, 0.247396 (1.433 sec)
30.616... logprob:  0.669587, 0.274740 (1.418 sec)
30.617... logprob:  0.590994, 0.279948 (1.421 sec)
30.618... logprob:  0.711244, 0.290365 (1.432 sec)
30.619... logprob:  0.743794, 0.334635 (1.447 sec)
30.620... logprob:  0.621181, 0.302083 (1.451 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.393577, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.427051e-03 [1.213572e-07] 
Layer 'conv1' biases: 2.173641e-06 [4.451483e-11] 
Layer 'conv2' weights[0]: 2.422209e-03 [1.211239e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.614558e-10] 
Layer 'conv3' weights[0]: 2.421109e-03 [1.213851e-07] 
Layer 'conv3' biases: 3.609906e-05 [6.471882e-09] 
Layer 'conv4' weights[0]: 2.431355e-03 [1.219832e-07] 
Layer 'conv4' biases: 9.998480e-01 [1.930316e-07] 
Layer 'conv5' weights[0]: 2.599087e-03 [3.219096e-06] 
Layer 'conv5' biases: 9.990478e-01 [3.475806e-06] 
Layer 'fc6' weights[0]: 6.711457e-03 [6.790708e-08] 
Layer 'fc6' biases: 9.999893e-01 [6.507686e-08] 
Layer 'fc7' weights[0]: 7.054729e-03 [1.625378e-07] 
Layer 'fc7' biases: 9.997142e-01 [2.569530e-07] 
Layer 'fc8' weights[0]: 4.852961e-03 [1.480712e-05] 
Layer 'fc8' biases: 2.556568e-02 [3.843993e-05] 
Train error last 800 batches: 0.657138
-------------------------------------------------------
Not saving because 0.393577 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
30.621... logprob:  0.632602, 0.285156 (1.456 sec)
30.622... logprob:  0.542893, 0.259115 (1.446 sec)
30.623... logprob:  0.692358, 0.304687 (1.465 sec)
30.624... logprob:  0.683145, 0.324219 (1.434 sec)
30.625... logprob:  0.632952, 0.257812 (1.420 sec)
30.626... logprob:  0.586270, 0.238281 (1.424 sec)
30.627... logprob:  0.652386, 0.304687 (1.434 sec)
30.628... logprob:  0.648004, 0.270833 (1.433 sec)
30.629... logprob:  0.672639, 0.283854 (1.471 sec)
30.630... logprob:  0.651639, 0.263021 (1.439 sec)
30.631... logprob:  0.780197, 0.303385 (1.434 sec)
30.632... logprob:  0.628589, 0.264323 (1.476 sec)
30.633... logprob:  0.605194, 0.266927 (1.424 sec)
30.634... logprob:  0.863844, 0.341146 (1.421 sec)
30.635... logprob:  0.665055, 0.304687 (1.433 sec)
30.636... logprob:  0.731944, 0.295573 (1.433 sec)
30.637... logprob:  0.574240, 0.278646 (1.426 sec)
30.638... logprob:  0.716150, 0.287760 (1.473 sec)
30.639... logprob:  0.608757, 0.290365 (1.443 sec)
30.640... logprob:  0.665747, 0.287760 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.507450, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.424615e-03 [1.213371e-07] 
Layer 'conv1' biases: 2.173979e-06 [6.270325e-11] 
Layer 'conv2' weights[0]: 2.419795e-03 [1.210550e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.450513e-10] 
Layer 'conv3' weights[0]: 2.418689e-03 [1.213921e-07] 
Layer 'conv3' biases: 3.612346e-05 [7.741806e-09] 
Layer 'conv4' weights[0]: 2.428944e-03 [1.220720e-07] 
Layer 'conv4' biases: 9.998484e-01 [2.327053e-07] 
Layer 'conv5' weights[0]: 2.597237e-03 [2.919884e-06] 
Layer 'conv5' biases: 9.990957e-01 [3.151848e-06] 
Layer 'fc6' weights[0]: 6.710766e-03 [6.831158e-08] 
Layer 'fc6' biases: 9.999896e-01 [6.464730e-08] 
Layer 'fc7' weights[0]: 7.054070e-03 [1.612983e-07] 
Layer 'fc7' biases: 9.997109e-01 [2.522782e-07] 
Layer 'fc8' weights[0]: 4.752915e-03 [1.456598e-05] 
Layer 'fc8' biases: 2.483220e-02 [3.491317e-05] 
Train error last 800 batches: 0.656784
-------------------------------------------------------
Not saving because 0.507450 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
30.641... logprob:  0.657859, 0.278646 (1.483 sec)
30.642... logprob:  0.695189, 0.305989 (1.432 sec)
30.643... logprob:  0.813368, 0.333333 (1.426 sec)
30.644... logprob:  0.531897, 0.229167 (1.431 sec)
30.645... logprob:  0.663119, 0.286458 (1.421 sec)
30.646... logprob:  0.493581, 0.217448 (1.429 sec)
30.647... logprob:  0.593380, 0.244792 (1.480 sec)
30.648... logprob:  0.657853, 0.277344 (1.424 sec)
30.649... logprob:  0.627702, 0.276042 (1.442 sec)
30.650... logprob:  0.677160, 0.286458 (1.469 sec)
30.651... logprob:  0.629930, 0.278646 (1.422 sec)
30.652... logprob:  0.685902, 0.304687 (1.432 sec)
30.653... logprob:  0.706682, 0.252604 (1.427 sec)
30.654... logprob:  0.616150, 0.250000 (1.424 sec)
30.655... logprob:  0.629619, 0.263021 (1.425 sec)
30.656... logprob:  0.591799, 0.274740 (1.473 sec)
30.657... logprob:  0.700171, 0.328125 (1.435 sec)
30.658... logprob:  0.636262, 0.273438 (1.447 sec)
30.659... logprob:  0.663186, 0.279948 (1.466 sec)
30.660... logprob:  0.609813, 0.268229 (1.435 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.571128, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.422184e-03 [1.211396e-07] 
Layer 'conv1' biases: 2.174143e-06 [3.782502e-11] 
Layer 'conv2' weights[0]: 2.417381e-03 [1.209211e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.690181e-10] 
Layer 'conv3' weights[0]: 2.416287e-03 [1.210519e-07] 
Layer 'conv3' biases: 3.612018e-05 [5.441360e-09] 
Layer 'conv4' weights[0]: 2.426508e-03 [1.216876e-07] 
Layer 'conv4' biases: 9.998480e-01 [1.786729e-07] 
Layer 'conv5' weights[0]: 2.595221e-03 [2.339098e-06] 
Layer 'conv5' biases: 9.991019e-01 [2.412464e-06] 
Layer 'fc6' weights[0]: 6.710105e-03 [6.329165e-08] 
Layer 'fc6' biases: 9.999898e-01 [5.736933e-08] 
Layer 'fc7' weights[0]: 7.053351e-03 [1.483851e-07] 
Layer 'fc7' biases: 9.997103e-01 [2.031628e-07] 
Layer 'fc8' weights[0]: 4.746849e-03 [1.415986e-05] 
Layer 'fc8' biases: 2.471914e-02 [3.945035e-05] 
Train error last 800 batches: 0.655986
-------------------------------------------------------
Not saving because 0.571128 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
30.661... logprob:  0.622210, 0.265625 (1.434 sec)
30.662... logprob:  0.720019, 0.338542 (1.426 sec)
30.663... logprob:  0.572948, 0.253906 (1.424 sec)
30.664... logprob:  0.504010, 0.222656 (1.431 sec)
30.665... logprob:  0.719748, 0.350260 (1.455 sec)
30.666... logprob:  0.602613, 0.276042 (1.446 sec)
30.667... logprob:  0.760709, 0.343750 (1.452 sec)
30.668... logprob:  0.717730, 0.302083 (1.452 sec)
30.669... logprob:  0.656091, 0.292969 (1.455 sec)
30.670... logprob:  0.588257, 0.264323 (1.431 sec)
30.671... logprob:  0.575467, 0.246094 (1.419 sec)
30.672... logprob:  0.753113, 0.341146 (1.421 sec)
30.673... logprob:  0.741813, 0.320312 (1.433 sec)
30.674... logprob:  0.622412, 0.252604 (1.436 sec)
30.675... logprob:  0.600695, 0.250000 (1.460 sec)
30.676... logprob:  0.656759, 0.289062 (1.446 sec)
30.677... logprob:  0.748062, 0.295573 (1.440 sec)
30.678... logprob:  0.684624, 0.264323 (1.473 sec)
30.679... logprob:  0.639270, 0.279948 (1.428 sec)
30.680... logprob:  0.671840, 0.300781 (1.419 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.438943, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.419760e-03 [1.210100e-07] 
Layer 'conv1' biases: 2.174209e-06 [3.235388e-11] 
Layer 'conv2' weights[0]: 2.414948e-03 [1.208038e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.208110e-10] 
Layer 'conv3' weights[0]: 2.413863e-03 [1.208776e-07] 
Layer 'conv3' biases: 3.612915e-05 [4.177654e-09] 
Layer 'conv4' weights[0]: 2.424078e-03 [1.213798e-07] 
Layer 'conv4' biases: 9.998469e-01 [1.256498e-07] 
Layer 'conv5' weights[0]: 2.591947e-03 [2.210213e-06] 
Layer 'conv5' biases: 9.990869e-01 [2.295699e-06] 
Layer 'fc6' weights[0]: 6.709398e-03 [6.262238e-08] 
Layer 'fc6' biases: 9.999894e-01 [5.691965e-08] 
Layer 'fc7' weights[0]: 7.052625e-03 [1.474259e-07] 
Layer 'fc7' biases: 9.997114e-01 [1.932524e-07] 
Layer 'fc8' weights[0]: 4.790379e-03 [1.317976e-05] 
Layer 'fc8' biases: 2.504155e-02 [3.120111e-05] 
Train error last 800 batches: 0.656076
-------------------------------------------------------
Not saving because 0.438943 > 0.299667 (9.300: -1.18%)
======================================================= (2.376 sec)
30.681... logprob:  0.645701, 0.287760 (1.437 sec)
30.682... logprob:  0.538896, 0.246094 (1.430 sec)
30.683... logprob:  0.686478, 0.317708 (1.426 sec)
30.684... logprob:  0.635231, 0.281250 (1.470 sec)
30.685... logprob:  0.492745, 0.220052 (1.436 sec)
30.686... logprob:  0.659237, 0.313802 (1.429 sec)
30.687... logprob:  0.572687, 0.239583 (1.481 sec)
30.688... logprob:  0.527838, 0.240885 (1.424 sec)
30.689... logprob:  0.681652, 0.313802 (1.423 sec)
30.690... logprob:  0.736656, 0.317708 (1.430 sec)
30.691... logprob:  0.741570, 0.296875 (1.425 sec)
30.692... logprob:  0.634963, 0.295573 (1.426 sec)
30.693... logprob:  0.644420, 0.282552 (1.479 sec)
30.694... logprob:  0.564935, 0.238281 (1.428 sec)
30.695... logprob:  0.615435, 0.279948 (1.438 sec)
30.696... logprob:  0.771616, 0.316406 (1.468 sec)
30.697... logprob:  0.680441, 0.290365 (1.431 sec)
30.698... logprob:  0.778847, 0.356771 (1.427 sec)
30.699... logprob:  0.746475, 0.351562 (1.428 sec)
30.700... logprob:  0.699706, 0.276042 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.310505, 0.039062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.417351e-03 [1.208571e-07] 
Layer 'conv1' biases: 2.174359e-06 [5.661085e-11] 
Layer 'conv2' weights[0]: 2.412531e-03 [1.206488e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.644768e-10] 
Layer 'conv3' weights[0]: 2.411434e-03 [1.208938e-07] 
Layer 'conv3' biases: 3.613811e-05 [6.468388e-09] 
Layer 'conv4' weights[0]: 2.421644e-03 [1.214093e-07] 
Layer 'conv4' biases: 9.998461e-01 [1.791720e-07] 
Layer 'conv5' weights[0]: 2.589153e-03 [3.206624e-06] 
Layer 'conv5' biases: 9.990822e-01 [3.379971e-06] 
Layer 'fc6' weights[0]: 6.708689e-03 [7.487234e-08] 
Layer 'fc6' biases: 9.999893e-01 [7.243246e-08] 
Layer 'fc7' weights[0]: 7.051881e-03 [1.782550e-07] 
Layer 'fc7' biases: 9.997117e-01 [2.953747e-07] 
Layer 'fc8' weights[0]: 4.803421e-03 [1.695830e-05] 
Layer 'fc8' biases: 2.518335e-02 [4.696774e-05] 
Train error last 800 batches: 0.656369
-------------------------------------------------------
Not saving because 0.310505 > 0.299667 (9.300: -1.18%)
======================================================= (2.338 sec)
30.701... logprob:  0.609980, 0.270833 (1.435 sec)
30.702... logprob:  0.714830, 0.287760 (1.485 sec)
30.703... logprob:  0.651963, 0.270833 (1.433 sec)
30.704... logprob:  0.661101, 0.291667 (1.444 sec)
30.705... logprob:  0.611613, 0.259115 (1.468 sec)
30.706... logprob:  0.624749, 0.277344 (1.428 sec)
30.707... logprob:  0.705228, 0.308594 (1.433 sec)
30.708... logprob:  0.636144, 0.287760 (1.426 sec)
30.709... logprob:  0.606548, 0.277344 (1.416 sec)
30.710... logprob:  0.858429, 0.382812 (1.433 sec)
30.711... logprob:  0.647546, 0.287760 (1.456 sec)
30.712... logprob:  0.540789, 0.247396 (1.444 sec)
30.713... logprob:  0.702275, 0.302083 (1.448 sec)
30.714... logprob:  0.668241, 0.302083 (1.448 sec)
30.715... logprob:  0.648731, 0.296875 (1.459 sec)
30.716... logprob:  0.562089, 0.251302 (1.432 sec)
30.717... logprob:  0.585554, 0.265625 (1.418 sec)
30.718... logprob:  0.656120, 0.309896 (1.426 sec)
30.719... logprob:  0.610163, 0.263021 (1.431 sec)
30.720... logprob:  0.603798, 0.243490 (1.441 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.464279, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.414933e-03 [1.208222e-07] 
Layer 'conv1' biases: 2.174755e-06 [4.194912e-11] 
Layer 'conv2' weights[0]: 2.410133e-03 [1.205793e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.968180e-10] 
Layer 'conv3' weights[0]: 2.409040e-03 [1.207297e-07] 
Layer 'conv3' biases: 3.614994e-05 [5.159720e-09] 
Layer 'conv4' weights[0]: 2.419236e-03 [1.213924e-07] 
Layer 'conv4' biases: 9.998447e-01 [1.483833e-07] 
Layer 'conv5' weights[0]: 2.585693e-03 [2.460274e-06] 
Layer 'conv5' biases: 9.990948e-01 [2.651031e-06] 
Layer 'fc6' weights[0]: 6.707999e-03 [6.210452e-08] 
Layer 'fc6' biases: 9.999893e-01 [5.599879e-08] 
Layer 'fc7' weights[0]: 7.051192e-03 [1.438961e-07] 
Layer 'fc7' biases: 9.997104e-01 [1.988700e-07] 
Layer 'fc8' weights[0]: 4.773623e-03 [1.301529e-05] 
Layer 'fc8' biases: 2.502759e-02 [3.125306e-05] 
Train error last 800 batches: 0.655633
-------------------------------------------------------
Not saving because 0.464279 > 0.299667 (9.300: -1.18%)
======================================================= (2.359 sec)
30.721... logprob:  0.714342, 0.328125 (1.466 sec)
30.722... logprob:  0.711220, 0.313802 (1.450 sec)
30.723... logprob:  0.681627, 0.282552 (1.440 sec)
30.724... logprob:  0.708925, 0.319010 (1.472 sec)
30.725... logprob:  0.700967, 0.294271 (1.433 sec)
30.726... logprob:  0.582460, 0.278646 (1.417 sec)
30.727... logprob:  0.570156, 0.243490 (1.430 sec)
30.728... logprob:  0.685838, 0.300781 (1.439 sec)
30.729... logprob:  0.580379, 0.256510 (1.427 sec)
30.730... logprob:  0.860860, 0.355469 (1.465 sec)
30.731... logprob:  0.717161, 0.319010 (1.442 sec)
30.732... logprob:  0.547617, 0.253906 (1.428 sec)
30.733... logprob:  0.784895, 0.303385 (1.477 sec)
30.734... logprob:  0.577528, 0.261719 (1.429 sec)
30.735... logprob:  0.705718, 0.286458 (1.419 sec)
30.736... logprob:  0.878940, 0.372396 (1.432 sec)
30.737... logprob:  0.664022, 0.282552 (1.426 sec)
30.738... logprob:  0.684353, 0.286458 (1.430 sec)
30.739... logprob:  0.708374, 0.311198 (1.472 sec)
30.740... logprob:  0.537507, 0.216146 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.508824, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.412524e-03 [1.206751e-07] 
Layer 'conv1' biases: 2.174981e-06 [4.671058e-11] 
Layer 'conv2' weights[0]: 2.407710e-03 [1.204330e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.530497e-10] 
Layer 'conv3' weights[0]: 2.406624e-03 [1.207137e-07] 
Layer 'conv3' biases: 3.615291e-05 [7.244817e-09] 
Layer 'conv4' weights[0]: 2.416823e-03 [1.213610e-07] 
Layer 'conv4' biases: 9.998465e-01 [2.119846e-07] 
Layer 'conv5' weights[0]: 2.585094e-03 [2.631352e-06] 
Layer 'conv5' biases: 9.990973e-01 [2.802873e-06] 
Layer 'fc6' weights[0]: 6.707322e-03 [6.587420e-08] 
Layer 'fc6' biases: 9.999899e-01 [6.097809e-08] 
Layer 'fc7' weights[0]: 7.050468e-03 [1.555213e-07] 
Layer 'fc7' biases: 9.997098e-01 [2.164107e-07] 
Layer 'fc8' weights[0]: 4.760711e-03 [1.406064e-05] 
Layer 'fc8' biases: 2.499372e-02 [3.521038e-05] 
Train error last 800 batches: 0.655994
-------------------------------------------------------
Not saving because 0.508824 > 0.299667 (9.300: -1.18%)
======================================================= (2.347 sec)
30.741... logprob:  0.645745, 0.281250 (1.438 sec)
30.742... logprob:  0.630551, 0.259115 (1.476 sec)
30.743... logprob:  0.657167, 0.292969 (1.426 sec)
30.744... logprob:  0.705820, 0.317708 (1.425 sec)
30.745... logprob:  0.634658, 0.296875 (1.429 sec)
30.746... logprob:  0.726325, 0.322917 (1.425 sec)
30.747... logprob:  0.702427, 0.326823 (1.425 sec)
30.748... logprob:  0.645308, 0.309896 (1.479 sec)
30.749... logprob:  0.642395, 0.296875 (1.430 sec)
30.750... logprob:  0.657881, 0.285156 (1.439 sec)
30.751... logprob:  0.504206, 0.212239 (1.477 sec)
30.752... logprob:  0.749801, 0.321615 (1.424 sec)
30.753... logprob:  0.682359, 0.289062 (1.468 sec)
30.754... logprob:  0.704400, 0.321615 (1.425 sec)
30.755... logprob:  0.625318, 0.282552 (1.421 sec)
30.756... logprob:  0.657297, 0.278646 (1.427 sec)
30.757... logprob:  0.750140, 0.325521 (1.469 sec)
30.758... logprob:  0.618993, 0.259115 (1.435 sec)
30.759... logprob:  0.547626, 0.231771 (1.450 sec)
30.760... logprob:  0.605312, 0.265625 (1.454 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.444060, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.410113e-03 [1.205638e-07] 
Layer 'conv1' biases: 2.175048e-06 [4.575613e-11] 
Layer 'conv2' weights[0]: 2.405313e-03 [1.203294e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.090918e-10] 
Layer 'conv3' weights[0]: 2.404208e-03 [1.204861e-07] 
Layer 'conv3' biases: 3.614197e-05 [5.661430e-09] 
Layer 'conv4' weights[0]: 2.414406e-03 [1.211376e-07] 
Layer 'conv4' biases: 9.998464e-01 [1.664729e-07] 
Layer 'conv5' weights[0]: 2.583604e-03 [2.149493e-06] 
Layer 'conv5' biases: 9.990839e-01 [2.340207e-06] 
Layer 'fc6' weights[0]: 6.706630e-03 [5.940433e-08] 
Layer 'fc6' biases: 9.999896e-01 [5.251476e-08] 
Layer 'fc7' weights[0]: 7.049753e-03 [1.373079e-07] 
Layer 'fc7' biases: 9.997100e-01 [1.665635e-07] 
Layer 'fc8' weights[0]: 4.777886e-03 [1.141658e-05] 
Layer 'fc8' biases: 2.518217e-02 [1.653866e-05] 
Train error last 800 batches: 0.655722
-------------------------------------------------------
Not saving because 0.444060 > 0.299667 (9.300: -1.18%)
======================================================= (2.371 sec)
30.761... logprob:  0.616453, 0.289062 (1.448 sec)
30.762... logprob:  0.720066, 0.278646 (1.440 sec)
30.763... logprob:  0.792766, 0.328125 (1.422 sec)
30.764... logprob:  0.703400, 0.309896 (1.420 sec)
30.765... logprob:  0.619282, 0.295573 (1.430 sec)
30.766... logprob:  0.698429, 0.317708 (1.450 sec)
30.767... logprob:  0.601778, 0.238281 (1.449 sec)
30.768... logprob:  0.715593, 0.278646 (1.453 sec)
30.769... logprob:  0.702419, 0.319010 (1.465 sec)
30.770... logprob:  0.638663, 0.295573 (1.474 sec)
30.771... logprob:  0.753171, 0.321614 (1.449 sec)
30.772... logprob:  0.691869, 0.305990 (1.441 sec)
30.773... logprob:  0.765027, 0.325521 (1.436 sec)
30.774... logprob:  0.568389, 0.278646 (1.456 sec)
30.775... logprob:  0.688487, 0.302083 (1.457 sec)
30.776... logprob:  0.623687, 0.264323 (1.469 sec)
30.777... logprob:  0.591409, 0.263021 (1.471 sec)
30.778... logprob:  0.613286, 0.265625 (1.451 sec)
30.779... logprob:  0.701116, 0.305989 (1.482 sec)
30.780... logprob:  0.603809, 0.268229 (1.451 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.453262, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.407695e-03 [1.205259e-07] 
Layer 'conv1' biases: 2.175117e-06 [3.594819e-11] 
Layer 'conv2' weights[0]: 2.402894e-03 [1.202238e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.662289e-10] 
Layer 'conv3' weights[0]: 2.401819e-03 [1.203390e-07] 
Layer 'conv3' biases: 3.614738e-05 [4.907540e-09] 
Layer 'conv4' weights[0]: 2.411990e-03 [1.210494e-07] 
Layer 'conv4' biases: 9.998462e-01 [1.513139e-07] 
Layer 'conv5' weights[0]: 2.581097e-03 [2.647458e-06] 
Layer 'conv5' biases: 9.990936e-01 [2.863430e-06] 
Layer 'fc6' weights[0]: 6.705922e-03 [6.082492e-08] 
Layer 'fc6' biases: 9.999896e-01 [5.422410e-08] 
Layer 'fc7' weights[0]: 7.049032e-03 [1.419625e-07] 
Layer 'fc7' biases: 9.997092e-01 [1.872780e-07] 
Layer 'fc8' weights[0]: 4.749336e-03 [1.248513e-05] 
Layer 'fc8' biases: 2.498887e-02 [2.701671e-05] 
Train error last 800 batches: 0.656441
-------------------------------------------------------
Not saving because 0.453262 > 0.299667 (9.300: -1.18%)
======================================================= (2.377 sec)
30.781... logprob:  0.606696, 0.259115 (1.452 sec)
30.782... logprob:  0.577907, 0.250000 (1.451 sec)
30.783... logprob:  0.806308, 0.286458 (1.454 sec)
30.784... logprob:  0.590747, 0.266927 (1.455 sec)
30.785... logprob:  0.739872, 0.322917 (1.477 sec)
30.786... logprob:  0.670449, 0.302083 (1.466 sec)
30.787... logprob:  0.689450, 0.304688 (1.457 sec)
30.788... logprob:  0.717109, 0.315104 (1.490 sec)
30.789... logprob:  0.562927, 0.269531 (1.449 sec)
30.790... logprob:  0.653717, 0.285156 (1.448 sec)
30.791... logprob:  0.646486, 0.274740 (1.449 sec)
30.792... logprob:  0.512751, 0.235677 (1.451 sec)
30.793... logprob:  0.582053, 0.273437 (1.449 sec)
30.794... logprob:  0.601939, 0.264323 (1.481 sec)
30.795... logprob:  0.624435, 0.263021 (1.463 sec)
30.796... logprob:  0.642192, 0.317708 (1.454 sec)
30.797... logprob:  0.636328, 0.264323 (1.501 sec)
30.798... logprob:  0.690718, 0.305990 (1.444 sec)
30.799... logprob:  0.618915, 0.277344 (1.446 sec)
30.800... logprob:  0.589630, 0.292969 (1.395 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.500745, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.405288e-03 [1.203859e-07] 
Layer 'conv1' biases: 2.175037e-06 [6.049731e-11] 
Layer 'conv2' weights[0]: 2.400496e-03 [1.201176e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.702488e-10] 
Layer 'conv3' weights[0]: 2.399425e-03 [1.204857e-07] 
Layer 'conv3' biases: 3.614382e-05 [7.885469e-09] 
Layer 'conv4' weights[0]: 2.409584e-03 [1.212623e-07] 
Layer 'conv4' biases: 9.998459e-01 [2.173277e-07] 
Layer 'conv5' weights[0]: 2.578908e-03 [3.371990e-06] 
Layer 'conv5' biases: 9.990571e-01 [3.680620e-06] 
Layer 'fc6' weights[0]: 6.705215e-03 [6.582813e-08] 
Layer 'fc6' biases: 9.999894e-01 [6.118020e-08] 
Layer 'fc7' weights[0]: 7.048306e-03 [1.575385e-07] 
Layer 'fc7' biases: 9.997106e-01 [2.463845e-07] 
Layer 'fc8' weights[0]: 4.798966e-03 [1.413601e-05] 
Layer 'fc8' biases: 2.544972e-02 [4.310219e-05] 
Train error last 800 batches: 0.656635
-------------------------------------------------------
Not saving because 0.500745 > 0.299667 (9.300: -1.18%)
======================================================= (2.383 sec)
31.1... logprob:  0.588232, 0.292969 (1.404 sec)
31.2... logprob:  0.671654, 0.296875 (1.455 sec)
31.3... logprob:  0.644619, 0.290365 (1.414 sec)
31.4... logprob:  0.718228, 0.307292 (1.398 sec)
31.5... logprob:  0.612533, 0.272135 (1.426 sec)
31.6... logprob:  0.726115, 0.311198 (1.391 sec)
31.7... logprob:  0.583112, 0.261719 (1.421 sec)
31.8... logprob:  0.642977, 0.286458 (1.391 sec)
31.9... logprob:  0.643811, 0.289062 (1.400 sec)
31.10... logprob:  0.540048, 0.233073 (1.402 sec)
31.11... logprob:  0.567995, 0.244792 (1.444 sec)
31.12... logprob:  0.712993, 0.332031 (1.392 sec)
31.13... logprob:  0.679389, 0.287760 (1.418 sec)
31.14... logprob:  0.632915, 0.279948 (1.398 sec)
31.15... logprob:  0.687559, 0.328125 (1.404 sec)
31.16... logprob:  0.480048, 0.221354 (1.400 sec)
31.17... logprob:  0.661180, 0.279948 (1.389 sec)
31.18... logprob:  0.500551, 0.244792 (1.393 sec)
31.19... logprob:  0.518363, 0.248698 (1.393 sec)
31.20... logprob:  0.581789, 0.242187 (1.397 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.462863, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.402889e-03 [1.202265e-07] 
Layer 'conv1' biases: 2.175183e-06 [4.135773e-11] 
Layer 'conv2' weights[0]: 2.398094e-03 [1.199857e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.341458e-10] 
Layer 'conv3' weights[0]: 2.397013e-03 [1.201720e-07] 
Layer 'conv3' biases: 3.615083e-05 [5.854956e-09] 
Layer 'conv4' weights[0]: 2.407164e-03 [1.209115e-07] 
Layer 'conv4' biases: 9.998439e-01 [1.896646e-07] 
Layer 'conv5' weights[0]: 2.575023e-03 [2.723957e-06] 
Layer 'conv5' biases: 9.990356e-01 [3.088399e-06] 
Layer 'fc6' weights[0]: 6.704509e-03 [6.263406e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.773617e-08] 
Layer 'fc7' weights[0]: 7.047572e-03 [1.450647e-07] 
Layer 'fc7' biases: 9.997115e-01 [2.187380e-07] 
Layer 'fc8' weights[0]: 4.842380e-03 [1.251950e-05] 
Layer 'fc8' biases: 2.581534e-02 [3.640305e-05] 
Train error last 800 batches: 0.655834
-------------------------------------------------------
Not saving because 0.462863 > 0.299667 (9.300: -1.18%)
======================================================= (2.358 sec)
31.21... logprob:  0.650654, 0.260417 (1.407 sec)
31.22... logprob:  0.821694, 0.329427 (1.415 sec)
31.23... logprob:  0.681135, 0.309896 (1.411 sec)
31.24... logprob:  0.521453, 0.194010 (1.413 sec)
31.25... logprob:  0.596737, 0.273437 (1.404 sec)
31.26... logprob:  0.686434, 0.305990 (1.436 sec)
31.27... logprob:  0.635698, 0.295573 (1.383 sec)
31.28... logprob:  0.670905, 0.273437 (1.407 sec)
31.29... logprob:  0.642680, 0.315104 (1.431 sec)
31.30... logprob:  0.619935, 0.281250 (1.410 sec)
31.31... logprob:  0.676270, 0.268229 (1.393 sec)
31.32... logprob:  0.660619, 0.281250 (1.381 sec)
31.33... logprob:  0.743078, 0.291667 (1.440 sec)
31.34... logprob:  0.664121, 0.289062 (1.387 sec)
31.35... logprob:  0.552886, 0.260417 (1.392 sec)
31.36... logprob:  0.709472, 0.287760 (1.392 sec)
31.37... logprob:  0.621936, 0.272135 (1.396 sec)
31.38... logprob:  0.698085, 0.294271 (1.388 sec)
31.39... logprob:  0.793437, 0.371094 (1.431 sec)
31.40... logprob:  0.712914, 0.307292 (1.402 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.457622, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.400489e-03 [1.199808e-07] 
Layer 'conv1' biases: 2.175410e-06 [4.845651e-11] 
Layer 'conv2' weights[0]: 2.395703e-03 [1.197876e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.421970e-10] 
Layer 'conv3' weights[0]: 2.394626e-03 [1.200386e-07] 
Layer 'conv3' biases: 3.617671e-05 [6.331608e-09] 
Layer 'conv4' weights[0]: 2.404768e-03 [1.206133e-07] 
Layer 'conv4' biases: 9.998419e-01 [1.966862e-07] 
Layer 'conv5' weights[0]: 2.571211e-03 [3.599636e-06] 
Layer 'conv5' biases: 9.990684e-01 [3.922131e-06] 
Layer 'fc6' weights[0]: 6.703846e-03 [7.887862e-08] 
Layer 'fc6' biases: 9.999896e-01 [7.843867e-08] 
Layer 'fc7' weights[0]: 7.046829e-03 [1.915460e-07] 
Layer 'fc7' biases: 9.997093e-01 [3.385606e-07] 
Layer 'fc8' weights[0]: 4.778422e-03 [1.883641e-05] 
Layer 'fc8' biases: 2.533504e-02 [5.510400e-05] 
Train error last 800 batches: 0.656042
-------------------------------------------------------
Not saving because 0.457622 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
31.41... logprob:  0.587224, 0.248698 (1.429 sec)
31.42... logprob:  0.621354, 0.278646 (1.419 sec)
31.43... logprob:  0.586459, 0.256510 (1.405 sec)
31.44... logprob:  0.749858, 0.328125 (1.431 sec)
31.45... logprob:  0.694706, 0.311198 (1.380 sec)
31.46... logprob:  0.670378, 0.289062 (1.395 sec)
31.47... logprob:  0.601173, 0.272135 (1.385 sec)
31.48... logprob:  0.737359, 0.333333 (1.420 sec)
31.49... logprob:  0.737164, 0.324219 (1.405 sec)
31.50... logprob:  0.605478, 0.259114 (1.428 sec)
31.51... logprob:  0.739427, 0.329427 (1.411 sec)
31.52... logprob:  0.811072, 0.345052 (1.389 sec)
31.53... logprob:  0.479196, 0.212240 (1.442 sec)
31.54... logprob:  0.591404, 0.260417 (1.381 sec)
31.55... logprob:  0.576757, 0.265625 (1.392 sec)
31.56... logprob:  0.642971, 0.274740 (1.396 sec)
31.57... logprob:  0.637337, 0.264323 (1.419 sec)
31.58... logprob:  0.665908, 0.292969 (1.398 sec)
31.59... logprob:  0.518446, 0.221354 (1.454 sec)
31.60... logprob:  0.778674, 0.298177 (1.423 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.506944, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.398078e-03 [1.199501e-07] 
Layer 'conv1' biases: 2.175734e-06 [4.868812e-11] 
Layer 'conv2' weights[0]: 2.393318e-03 [1.197322e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.718861e-10] 
Layer 'conv3' weights[0]: 2.392221e-03 [1.199931e-07] 
Layer 'conv3' biases: 3.617543e-05 [6.361481e-09] 
Layer 'conv4' weights[0]: 2.402349e-03 [1.207125e-07] 
Layer 'conv4' biases: 9.998415e-01 [2.122415e-07] 
Layer 'conv5' weights[0]: 2.568354e-03 [2.283775e-06] 
Layer 'conv5' biases: 9.990768e-01 [2.499881e-06] 
Layer 'fc6' weights[0]: 6.703123e-03 [6.058881e-08] 
Layer 'fc6' biases: 9.999897e-01 [5.435913e-08] 
Layer 'fc7' weights[0]: 7.046173e-03 [1.416406e-07] 
Layer 'fc7' biases: 9.997088e-01 [1.686215e-07] 
Layer 'fc8' weights[0]: 4.756688e-03 [1.148972e-05] 
Layer 'fc8' biases: 2.518034e-02 [1.304231e-05] 
Train error last 800 batches: 0.655702
-------------------------------------------------------
Not saving because 0.506944 > 0.299667 (9.300: -1.18%)
======================================================= (2.372 sec)
31.61... logprob:  0.609258, 0.279948 (1.430 sec)
31.62... logprob:  0.716940, 0.302083 (1.458 sec)
31.63... logprob:  0.628657, 0.265625 (1.429 sec)
31.64... logprob:  0.641130, 0.290365 (1.408 sec)
31.65... logprob:  0.664435, 0.295573 (1.388 sec)
31.66... logprob:  0.569513, 0.240885 (1.441 sec)
31.67... logprob:  0.524070, 0.235677 (1.383 sec)
31.68... logprob:  0.594722, 0.246094 (1.414 sec)
31.69... logprob:  0.687971, 0.302083 (1.421 sec)
31.70... logprob:  0.558496, 0.248698 (1.419 sec)
31.71... logprob:  0.617607, 0.277344 (1.458 sec)
31.72... logprob:  0.634455, 0.268229 (1.397 sec)
31.73... logprob:  0.738710, 0.312500 (1.414 sec)
31.74... logprob:  0.650258, 0.289062 (1.411 sec)
31.75... logprob:  0.610346, 0.257812 (1.408 sec)
31.76... logprob:  0.636282, 0.291667 (1.432 sec)
31.77... logprob:  0.628425, 0.290365 (1.427 sec)
31.78... logprob:  0.688839, 0.302083 (1.451 sec)
31.79... logprob:  0.670596, 0.322917 (1.393 sec)
31.80... logprob:  0.801515, 0.335937 (1.411 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.398042, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.395680e-03 [1.197808e-07] 
Layer 'conv1' biases: 2.175873e-06 [4.640422e-11] 
Layer 'conv2' weights[0]: 2.390913e-03 [1.195629e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.275765e-10] 
Layer 'conv3' weights[0]: 2.389821e-03 [1.197495e-07] 
Layer 'conv3' biases: 3.615787e-05 [5.475459e-09] 
Layer 'conv4' weights[0]: 2.399937e-03 [1.203614e-07] 
Layer 'conv4' biases: 9.998407e-01 [1.575395e-07] 
Layer 'conv5' weights[0]: 2.566135e-03 [2.473743e-06] 
Layer 'conv5' biases: 9.990481e-01 [2.722905e-06] 
Layer 'fc6' weights[0]: 6.702444e-03 [6.297416e-08] 
Layer 'fc6' biases: 9.999894e-01 [5.830846e-08] 
Layer 'fc7' weights[0]: 7.045382e-03 [1.500788e-07] 
Layer 'fc7' biases: 9.997103e-01 [2.063217e-07] 
Layer 'fc8' weights[0]: 4.827080e-03 [1.429695e-05] 
Layer 'fc8' biases: 2.573293e-02 [3.380897e-05] 
Train error last 800 batches: 0.655787
-------------------------------------------------------
Not saving because 0.398042 > 0.299667 (9.300: -1.18%)
======================================================= (2.409 sec)
31.81... logprob:  0.581672, 0.285156 (1.424 sec)
31.82... logprob:  0.578314, 0.269531 (1.424 sec)
31.83... logprob:  0.714433, 0.274740 (1.399 sec)
31.84... logprob:  0.623056, 0.246094 (1.460 sec)
31.85... logprob:  0.675554, 0.286458 (1.418 sec)
31.86... logprob:  0.695539, 0.303385 (1.411 sec)
31.87... logprob:  0.718196, 0.322917 (1.408 sec)
31.88... logprob:  0.704831, 0.309896 (1.404 sec)
31.89... logprob:  0.493007, 0.243490 (1.429 sec)
31.90... logprob:  0.758104, 0.329427 (1.387 sec)
31.91... logprob:  0.538765, 0.235677 (1.392 sec)
31.92... logprob:  0.756820, 0.351562 (1.394 sec)
31.93... logprob:  0.682767, 0.295573 (1.391 sec)
31.94... logprob:  0.648117, 0.261719 (1.393 sec)
31.95... logprob:  0.699939, 0.337240 (1.398 sec)
31.96... logprob:  0.772127, 0.341146 (1.399 sec)
31.97... logprob:  0.659735, 0.296875 (1.399 sec)
31.98... logprob:  0.524248, 0.218750 (1.429 sec)
31.99... logprob:  0.666961, 0.272135 (1.403 sec)
31.100... logprob:  0.618290, 0.270833 (1.391 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.481189, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.393291e-03 [1.196808e-07] 
Layer 'conv1' biases: 2.176027e-06 [4.595676e-11] 
Layer 'conv2' weights[0]: 2.388528e-03 [1.194561e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.529045e-10] 
Layer 'conv3' weights[0]: 2.387426e-03 [1.197058e-07] 
Layer 'conv3' biases: 3.617175e-05 [6.354990e-09] 
Layer 'conv4' weights[0]: 2.397551e-03 [1.202958e-07] 
Layer 'conv4' biases: 9.998422e-01 [2.005415e-07] 
Layer 'conv5' weights[0]: 2.565251e-03 [2.496403e-06] 
Layer 'conv5' biases: 9.990914e-01 [2.730090e-06] 
Layer 'fc6' weights[0]: 6.701741e-03 [6.235168e-08] 
Layer 'fc6' biases: 9.999897e-01 [5.680147e-08] 
Layer 'fc7' weights[0]: 7.044700e-03 [1.457974e-07] 
Layer 'fc7' biases: 9.997080e-01 [1.963124e-07] 
Layer 'fc8' weights[0]: 4.746394e-03 [1.281331e-05] 
Layer 'fc8' biases: 2.512989e-02 [2.446102e-05] 
Train error last 800 batches: 0.655258
-------------------------------------------------------
Not saving because 0.481189 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
31.101... logprob:  0.503602, 0.236979 (1.447 sec)
31.102... logprob:  0.673162, 0.291667 (1.388 sec)
31.103... logprob:  0.761797, 0.351562 (1.394 sec)
31.104... logprob:  0.641686, 0.282552 (1.391 sec)
31.105... logprob:  0.782157, 0.315104 (1.388 sec)
31.106... logprob:  0.611287, 0.279948 (1.387 sec)
31.107... logprob:  0.633981, 0.276042 (1.447 sec)
31.108... logprob:  0.744200, 0.326823 (1.391 sec)
31.109... logprob:  0.607488, 0.282552 (1.393 sec)
31.110... logprob:  0.735794, 0.320312 (1.393 sec)
31.111... logprob:  0.613522, 0.260417 (1.387 sec)
31.112... logprob:  0.587851, 0.269531 (1.394 sec)
31.113... logprob:  0.586083, 0.250000 (1.394 sec)
31.114... logprob:  0.597396, 0.255208 (1.433 sec)
31.115... logprob:  0.720874, 0.304687 (1.405 sec)
31.116... logprob:  0.589458, 0.276042 (1.393 sec)
31.117... logprob:  0.615186, 0.248698 (1.436 sec)
31.118... logprob:  0.568055, 0.264323 (1.383 sec)
31.119... logprob:  0.642288, 0.308594 (1.388 sec)
31.120... logprob:  0.729419, 0.307292 (1.393 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.462908, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.390904e-03 [1.196049e-07] 
Layer 'conv1' biases: 2.176106e-06 [3.408702e-11] 
Layer 'conv2' weights[0]: 2.386137e-03 [1.193817e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.840220e-10] 
Layer 'conv3' weights[0]: 2.385065e-03 [1.194533e-07] 
Layer 'conv3' biases: 3.617594e-05 [4.347260e-09] 
Layer 'conv4' weights[0]: 2.395155e-03 [1.201288e-07] 
Layer 'conv4' biases: 9.998428e-01 [1.436081e-07] 
Layer 'conv5' weights[0]: 2.563685e-03 [2.420847e-06] 
Layer 'conv5' biases: 9.990851e-01 [2.609953e-06] 
Layer 'fc6' weights[0]: 6.701023e-03 [6.132463e-08] 
Layer 'fc6' biases: 9.999898e-01 [5.505660e-08] 
Layer 'fc7' weights[0]: 7.044051e-03 [1.445095e-07] 
Layer 'fc7' biases: 9.997083e-01 [1.933332e-07] 
Layer 'fc8' weights[0]: 4.766063e-03 [1.232105e-05] 
Layer 'fc8' biases: 2.524309e-02 [2.466744e-05] 
Train error last 800 batches: 0.655460
-------------------------------------------------------
Not saving because 0.462908 > 0.299667 (9.300: -1.18%)
======================================================= (2.375 sec)
31.121... logprob:  0.583880, 0.252604 (1.398 sec)
31.122... logprob:  0.704054, 0.298177 (1.445 sec)
31.123... logprob:  0.720117, 0.307292 (1.388 sec)
31.124... logprob:  0.688758, 0.312500 (1.400 sec)
31.125... logprob:  0.635964, 0.277344 (1.390 sec)
31.126... logprob:  0.692333, 0.308594 (1.383 sec)
31.127... logprob:  0.745518, 0.302083 (1.398 sec)
31.128... logprob:  0.602801, 0.269531 (1.418 sec)
31.129... logprob:  0.727631, 0.299479 (1.407 sec)
31.130... logprob:  0.600154, 0.286458 (1.413 sec)
31.131... logprob:  0.700882, 0.352865 (1.399 sec)
31.132... logprob:  0.735674, 0.311198 (1.429 sec)
31.133... logprob:  0.746975, 0.315104 (1.379 sec)
31.134... logprob:  0.654068, 0.303385 (1.390 sec)
31.135... logprob:  0.676175, 0.292969 (1.396 sec)
31.136... logprob:  0.729505, 0.345052 (1.394 sec)
31.137... logprob:  0.653202, 0.285156 (1.376 sec)
31.138... logprob:  0.542464, 0.240885 (1.440 sec)
31.139... logprob:  0.701484, 0.307292 (1.395 sec)
31.140... logprob:  0.790208, 0.347656 (1.407 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.479779, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.388502e-03 [1.195323e-07] 
Layer 'conv1' biases: 2.176267e-06 [3.017686e-11] 
Layer 'conv2' weights[0]: 2.383737e-03 [1.192691e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.493629e-10] 
Layer 'conv3' weights[0]: 2.382652e-03 [1.193433e-07] 
Layer 'conv3' biases: 3.616979e-05 [4.292873e-09] 
Layer 'conv4' weights[0]: 2.392755e-03 [1.200190e-07] 
Layer 'conv4' biases: 9.998416e-01 [1.558200e-07] 
Layer 'conv5' weights[0]: 2.560485e-03 [2.235927e-06] 
Layer 'conv5' biases: 9.990900e-01 [2.398295e-06] 
Layer 'fc6' weights[0]: 6.700311e-03 [6.078003e-08] 
Layer 'fc6' biases: 9.999898e-01 [5.445845e-08] 
Layer 'fc7' weights[0]: 7.043319e-03 [1.387526e-07] 
Layer 'fc7' biases: 9.997081e-01 [1.672089e-07] 
Layer 'fc8' weights[0]: 4.748871e-03 [1.145592e-05] 
Layer 'fc8' biases: 2.520014e-02 [1.559547e-05] 
Train error last 800 batches: 0.654976
-------------------------------------------------------
Not saving because 0.479779 > 0.299667 (9.300: -1.18%)
======================================================= (2.405 sec)
31.141... logprob:  0.705726, 0.302083 (1.459 sec)
31.142... logprob:  0.703129, 0.295573 (1.394 sec)
31.143... logprob:  0.539345, 0.238281 (1.424 sec)
31.144... logprob:  0.703844, 0.311198 (1.421 sec)
31.145... logprob:  0.613916, 0.283854 (1.421 sec)
31.146... logprob:  0.669884, 0.285156 (1.426 sec)
31.147... logprob:  0.562879, 0.247396 (1.436 sec)
31.148... logprob:  0.671722, 0.292969 (1.383 sec)
31.149... logprob:  0.578691, 0.256510 (1.396 sec)
31.150... logprob:  0.620310, 0.276042 (1.402 sec)
31.151... logprob:  0.574730, 0.259115 (1.399 sec)
31.152... logprob:  0.826387, 0.334635 (1.397 sec)
31.153... logprob:  0.690476, 0.309896 (1.447 sec)
31.154... logprob:  0.766778, 0.332031 (1.406 sec)
31.155... logprob:  0.602886, 0.273438 (1.415 sec)
31.156... logprob:  0.559164, 0.259115 (1.433 sec)
31.157... logprob:  0.523395, 0.236979 (1.388 sec)
31.158... logprob:  0.642264, 0.292969 (1.406 sec)
31.159... logprob:  0.724715, 0.320312 (1.407 sec)
31.160... logprob:  0.752828, 0.343750 (1.390 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.482534, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.386121e-03 [1.194084e-07] 
Layer 'conv1' biases: 2.176317e-06 [3.822394e-11] 
Layer 'conv2' weights[0]: 2.381369e-03 [1.191481e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.219688e-10] 
Layer 'conv3' weights[0]: 2.380272e-03 [1.193476e-07] 
Layer 'conv3' biases: 3.616945e-05 [6.208502e-09] 
Layer 'conv4' weights[0]: 2.390363e-03 [1.200011e-07] 
Layer 'conv4' biases: 9.998396e-01 [1.869656e-07] 
Layer 'conv5' weights[0]: 2.556947e-03 [2.550650e-06] 
Layer 'conv5' biases: 9.990560e-01 [2.741577e-06] 
Layer 'fc6' weights[0]: 6.699625e-03 [6.095531e-08] 
Layer 'fc6' biases: 9.999893e-01 [5.496112e-08] 
Layer 'fc7' weights[0]: 7.042590e-03 [1.407413e-07] 
Layer 'fc7' biases: 9.997090e-01 [1.796010e-07] 
Layer 'fc8' weights[0]: 4.805931e-03 [1.206816e-05] 
Layer 'fc8' biases: 2.564796e-02 [2.453183e-05] 
Train error last 800 batches: 0.655070
-------------------------------------------------------
Not saving because 0.482534 > 0.299667 (9.300: -1.18%)
======================================================= (2.368 sec)
31.161... logprob:  0.614634, 0.286458 (1.410 sec)
31.162... logprob:  0.764477, 0.337240 (1.415 sec)
31.163... logprob:  0.731766, 0.326823 (1.436 sec)
31.164... logprob:  0.658237, 0.308594 (1.427 sec)
31.165... logprob:  0.698399, 0.294271 (1.431 sec)
31.166... logprob:  0.679151, 0.298177 (1.457 sec)
31.167... logprob:  0.558086, 0.264323 (1.440 sec)
31.168... logprob:  0.582917, 0.274740 (1.440 sec)
31.169... logprob:  0.617869, 0.268229 (1.469 sec)
31.170... logprob:  0.630512, 0.283854 (1.413 sec)
31.171... logprob:  0.768123, 0.308594 (1.423 sec)
31.172... logprob:  0.577191, 0.225260 (1.417 sec)
31.173... logprob:  0.673532, 0.278646 (1.428 sec)
31.174... logprob:  0.804317, 0.342448 (1.402 sec)
31.175... logprob:  0.739303, 0.324219 (1.472 sec)
31.176... logprob:  0.713173, 0.296875 (1.424 sec)
31.177... logprob:  0.552435, 0.231771 (1.426 sec)
31.178... logprob:  0.660936, 0.286458 (1.452 sec)
31.179... logprob:  0.682784, 0.286458 (1.400 sec)
31.180... logprob:  0.734109, 0.320313 (1.424 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.573147, 0.171875 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.383744e-03 [1.191874e-07] 
Layer 'conv1' biases: 2.176386e-06 [3.878868e-11] 
Layer 'conv2' weights[0]: 2.378989e-03 [1.189850e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.171814e-10] 
Layer 'conv3' weights[0]: 2.377895e-03 [1.190969e-07] 
Layer 'conv3' biases: 3.617977e-05 [4.874704e-09] 
Layer 'conv4' weights[0]: 2.387980e-03 [1.196901e-07] 
Layer 'conv4' biases: 9.998394e-01 [1.624470e-07] 
Layer 'conv5' weights[0]: 2.554755e-03 [3.388466e-06] 
Layer 'conv5' biases: 9.990728e-01 [3.749584e-06] 
Layer 'fc6' weights[0]: 6.698951e-03 [7.104707e-08] 
Layer 'fc6' biases: 9.999894e-01 [6.805354e-08] 
Layer 'fc7' weights[0]: 7.041926e-03 [1.705493e-07] 
Layer 'fc7' biases: 9.997085e-01 [2.667163e-07] 
Layer 'fc8' weights[0]: 4.766416e-03 [1.570036e-05] 
Layer 'fc8' biases: 2.531978e-02 [4.299773e-05] 
Train error last 800 batches: 0.655192
-------------------------------------------------------
Not saving because 0.573147 > 0.299667 (9.300: -1.18%)
======================================================= (2.355 sec)
31.181... logprob:  0.695692, 0.286458 (1.424 sec)
31.182... logprob:  0.654436, 0.278646 (1.418 sec)
31.183... logprob:  0.640231, 0.270833 (1.423 sec)
31.184... logprob:  0.688108, 0.304688 (1.411 sec)
31.185... logprob:  0.556171, 0.250000 (1.428 sec)
31.186... logprob:  0.632776, 0.282552 (1.390 sec)
31.187... logprob:  0.831943, 0.346354 (1.397 sec)
31.188... logprob:  0.604965, 0.259115 (1.384 sec)
31.189... logprob:  0.751546, 0.337240 (1.393 sec)
31.190... logprob:  0.650677, 0.292969 (1.432 sec)
31.191... logprob:  0.738139, 0.324219 (1.397 sec)
31.192... logprob:  0.715731, 0.328125 (1.412 sec)
31.193... logprob:  0.527111, 0.252604 (1.415 sec)
31.194... logprob:  0.661687, 0.295573 (1.413 sec)
31.195... logprob:  0.585188, 0.259115 (1.391 sec)
31.196... logprob:  0.688984, 0.296875 (1.386 sec)
31.197... logprob:  0.714426, 0.328125 (1.392 sec)
31.198... logprob:  0.598783, 0.285156 (1.399 sec)
31.199... logprob:  0.651990, 0.274740 (1.382 sec)
31.200... logprob:  0.625740, 0.269531 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.481150, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.381350e-03 [1.191294e-07] 
Layer 'conv1' biases: 2.176461e-06 [4.274062e-11] 
Layer 'conv2' weights[0]: 2.376593e-03 [1.189001e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.604303e-10] 
Layer 'conv3' weights[0]: 2.375530e-03 [1.190624e-07] 
Layer 'conv3' biases: 3.620177e-05 [5.394228e-09] 
Layer 'conv4' weights[0]: 2.385580e-03 [1.197478e-07] 
Layer 'conv4' biases: 9.998384e-01 [1.751148e-07] 
Layer 'conv5' weights[0]: 2.551923e-03 [2.543061e-06] 
Layer 'conv5' biases: 9.990877e-01 [2.790820e-06] 
Layer 'fc6' weights[0]: 6.698227e-03 [6.307252e-08] 
Layer 'fc6' biases: 9.999896e-01 [5.718602e-08] 
Layer 'fc7' weights[0]: 7.041238e-03 [1.504153e-07] 
Layer 'fc7' biases: 9.997075e-01 [2.094400e-07] 
Layer 'fc8' weights[0]: 4.750303e-03 [1.348915e-05] 
Layer 'fc8' biases: 2.515276e-02 [3.757781e-05] 
Train error last 800 batches: 0.655567
-------------------------------------------------------
Not saving because 0.481150 > 0.299667 (9.300: -1.18%)
======================================================= (2.363 sec)
31.201... logprob:  0.685607, 0.299479 (1.408 sec)
31.202... logprob:  0.719433, 0.309896 (1.403 sec)
31.203... logprob:  0.676881, 0.273437 (1.442 sec)
31.204... logprob:  0.726078, 0.320312 (1.380 sec)
31.205... logprob:  0.559626, 0.227865 (1.397 sec)
31.206... logprob:  0.559094, 0.265625 (1.394 sec)
31.207... logprob:  0.649642, 0.315104 (1.387 sec)
31.208... logprob:  0.659074, 0.303385 (1.399 sec)
31.209... logprob:  0.622411, 0.270833 (1.418 sec)
31.210... logprob:  0.888076, 0.345052 (1.413 sec)
31.211... logprob:  0.721837, 0.322917 (1.407 sec)
31.212... logprob:  0.691569, 0.307292 (1.410 sec)
31.213... logprob:  0.787834, 0.312500 (1.452 sec)
31.214... logprob:  0.675466, 0.303385 (1.421 sec)
31.215... logprob:  0.661158, 0.270833 (1.406 sec)
31.216... logprob:  0.630869, 0.264323 (1.461 sec)
31.217... logprob:  0.594067, 0.277344 (1.394 sec)
31.218... logprob:  0.643111, 0.253906 (1.419 sec)
31.219... logprob:  0.614092, 0.263021 (1.410 sec)
31.220... logprob:  0.635202, 0.270833 (1.412 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.491549, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.378971e-03 [1.190004e-07] 
Layer 'conv1' biases: 2.176647e-06 [3.216097e-11] 
Layer 'conv2' weights[0]: 2.374231e-03 [1.187629e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.421940e-10] 
Layer 'conv3' weights[0]: 2.373151e-03 [1.189074e-07] 
Layer 'conv3' biases: 3.619889e-05 [5.313722e-09] 
Layer 'conv4' weights[0]: 2.383218e-03 [1.195974e-07] 
Layer 'conv4' biases: 9.998376e-01 [1.705041e-07] 
Layer 'conv5' weights[0]: 2.549048e-03 [2.603852e-06] 
Layer 'conv5' biases: 9.990869e-01 [2.814587e-06] 
Layer 'fc6' weights[0]: 6.697532e-03 [6.274970e-08] 
Layer 'fc6' biases: 9.999897e-01 [5.680575e-08] 
Layer 'fc7' weights[0]: 7.040488e-03 [1.503524e-07] 
Layer 'fc7' biases: 9.997073e-01 [2.048672e-07] 
Layer 'fc8' weights[0]: 4.757954e-03 [1.417585e-05] 
Layer 'fc8' biases: 2.523879e-02 [3.308137e-05] 
Train error last 800 batches: 0.655680
-------------------------------------------------------
Not saving because 0.491549 > 0.299667 (9.300: -1.18%)
======================================================= (2.356 sec)
31.221... logprob:  0.626231, 0.302083 (1.415 sec)
31.222... logprob:  0.817493, 0.345052 (1.453 sec)
31.223... logprob:  0.769970, 0.328125 (1.421 sec)
31.224... logprob:  0.723496, 0.316406 (1.449 sec)
31.225... logprob:  0.627806, 0.285156 (1.450 sec)
31.226... logprob:  0.600781, 0.286458 (1.422 sec)
31.227... logprob:  0.671768, 0.289062 (1.407 sec)
31.228... logprob:  0.607542, 0.285156 (1.411 sec)
31.229... logprob:  0.667606, 0.302083 (1.419 sec)
31.230... logprob:  0.678196, 0.260417 (1.420 sec)
31.231... logprob:  0.711390, 0.322917 (1.403 sec)
31.232... logprob:  0.773496, 0.326823 (1.460 sec)
31.233... logprob:  0.715402, 0.322917 (1.434 sec)
31.234... logprob:  0.811556, 0.322917 (1.413 sec)
31.235... logprob:  0.645256, 0.264323 (1.467 sec)
31.236... logprob:  0.595157, 0.274740 (1.395 sec)
31.237... logprob:  0.582179, 0.259115 (1.418 sec)
31.238... logprob:  0.543549, 0.238281 (1.415 sec)
31.239... logprob:  0.672927, 0.296875 (1.414 sec)
31.240... logprob:  0.730029, 0.317708 (1.399 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.500639, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.376591e-03 [1.188898e-07] 
Layer 'conv1' biases: 2.176791e-06 [3.098682e-11] 
Layer 'conv2' weights[0]: 2.371858e-03 [1.186469e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.253277e-10] 
Layer 'conv3' weights[0]: 2.370786e-03 [1.187478e-07] 
Layer 'conv3' biases: 3.620034e-05 [4.266571e-09] 
Layer 'conv4' weights[0]: 2.380826e-03 [1.194175e-07] 
Layer 'conv4' biases: 9.998370e-01 [1.497902e-07] 
Layer 'conv5' weights[0]: 2.546318e-03 [2.075648e-06] 
Layer 'conv5' biases: 9.990969e-01 [2.252812e-06] 
Layer 'fc6' weights[0]: 6.696852e-03 [5.929640e-08] 
Layer 'fc6' biases: 9.999897e-01 [5.232416e-08] 
Layer 'fc7' weights[0]: 7.039783e-03 [1.361963e-07] 
Layer 'fc7' biases: 9.997069e-01 [1.547663e-07] 
Layer 'fc8' weights[0]: 4.729280e-03 [1.095471e-05] 
Layer 'fc8' biases: 2.502112e-02 [6.990558e-06] 
Train error last 800 batches: 0.655657
-------------------------------------------------------
Not saving because 0.500639 > 0.299667 (9.300: -1.18%)
======================================================= (2.368 sec)
31.241... logprob:  0.637796, 0.272135 (1.467 sec)
31.242... logprob:  0.514732, 0.214844 (1.436 sec)
31.243... logprob:  0.594638, 0.263021 (1.435 sec)
31.244... logprob:  0.624979, 0.285156 (1.443 sec)
31.245... logprob:  0.661770, 0.308594 (1.415 sec)
31.246... logprob:  0.601687, 0.273437 (1.409 sec)
31.247... logprob:  0.650366, 0.270833 (1.411 sec)
31.248... logprob:  0.642423, 0.295573 (1.415 sec)
31.249... logprob:  0.794938, 0.348958 (1.423 sec)
31.250... logprob:  0.738021, 0.296875 (1.400 sec)
31.251... logprob:  0.591308, 0.252604 (1.451 sec)
31.252... logprob:  0.589739, 0.252604 (1.418 sec)
31.253... logprob:  0.639685, 0.308594 (1.414 sec)
31.254... logprob:  0.708200, 0.304687 (1.460 sec)
31.255... logprob:  0.598526, 0.274740 (1.396 sec)
31.256... logprob:  0.599125, 0.244792 (1.416 sec)
31.257... logprob:  0.544995, 0.239583 (1.498 sec)
31.258... logprob:  0.585652, 0.257812 (1.415 sec)
31.259... logprob:  0.629354, 0.276042 (1.395 sec)
31.260... logprob:  0.541905, 0.251302 (1.450 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.499253, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.374211e-03 [1.188356e-07] 
Layer 'conv1' biases: 2.176843e-06 [4.757956e-11] 
Layer 'conv2' weights[0]: 2.369475e-03 [1.185646e-07] 
Layer 'conv2' biases: 9.999996e-01 [8.038304e-10] 
Layer 'conv3' weights[0]: 2.368405e-03 [1.189092e-07] 
Layer 'conv3' biases: 3.617487e-05 [7.825378e-09] 
Layer 'conv4' weights[0]: 2.378426e-03 [1.197782e-07] 
Layer 'conv4' biases: 9.998361e-01 [2.661952e-07] 
Layer 'conv5' weights[0]: 2.543885e-03 [3.765513e-06] 
Layer 'conv5' biases: 9.990489e-01 [4.248218e-06] 
Layer 'fc6' weights[0]: 6.696157e-03 [7.245370e-08] 
Layer 'fc6' biases: 9.999892e-01 [6.956405e-08] 
Layer 'fc7' weights[0]: 7.039021e-03 [1.756219e-07] 
Layer 'fc7' biases: 9.997097e-01 [2.997685e-07] 
Layer 'fc8' weights[0]: 4.829563e-03 [1.636407e-05] 
Layer 'fc8' biases: 2.582841e-02 [5.415833e-05] 
Train error last 800 batches: 0.655527
-------------------------------------------------------
Not saving because 0.499253 > 0.299667 (9.300: -1.18%)
======================================================= (2.393 sec)
31.261... logprob:  0.562532, 0.272135 (1.427 sec)
31.262... logprob:  0.808578, 0.356771 (1.446 sec)
31.263... logprob:  0.688774, 0.289062 (1.443 sec)
31.264... logprob:  0.582844, 0.266927 (1.418 sec)
31.265... logprob:  0.664468, 0.308594 (1.416 sec)
31.266... logprob:  0.619347, 0.282552 (1.409 sec)
31.267... logprob:  0.655389, 0.281250 (1.408 sec)
31.268... logprob:  0.648305, 0.283854 (1.416 sec)
31.269... logprob:  0.756206, 0.308594 (1.402 sec)
31.270... logprob:  0.709486, 0.326823 (1.459 sec)
31.271... logprob:  0.671114, 0.295573 (1.427 sec)
31.272... logprob:  0.586700, 0.292969 (1.408 sec)
31.273... logprob:  0.715320, 0.330729 (1.462 sec)
31.274... logprob:  0.700552, 0.317708 (1.395 sec)
31.275... logprob:  0.644623, 0.291667 (1.414 sec)
31.276... logprob:  0.608141, 0.282552 (1.412 sec)
31.277... logprob:  0.684980, 0.287760 (1.424 sec)
31.278... logprob:  0.449495, 0.196615 (1.413 sec)
31.279... logprob:  0.599636, 0.272135 (1.456 sec)
31.280... logprob:  0.558726, 0.257812 (1.401 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.496366, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.371840e-03 [1.186723e-07] 
Layer 'conv1' biases: 2.176940e-06 [3.293089e-11] 
Layer 'conv2' weights[0]: 2.367111e-03 [1.184318e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.946359e-10] 
Layer 'conv3' weights[0]: 2.366050e-03 [1.185155e-07] 
Layer 'conv3' biases: 3.617008e-05 [4.759029e-09] 
Layer 'conv4' weights[0]: 2.376056e-03 [1.191841e-07] 
Layer 'conv4' biases: 9.998368e-01 [1.593438e-07] 
Layer 'conv5' weights[0]: 2.542664e-03 [2.308618e-06] 
Layer 'conv5' biases: 9.990470e-01 [2.587556e-06] 
Layer 'fc6' weights[0]: 6.695457e-03 [5.834543e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.189700e-08] 
Layer 'fc7' weights[0]: 7.038312e-03 [1.382081e-07] 
Layer 'fc7' biases: 9.997094e-01 [1.918354e-07] 
Layer 'fc8' weights[0]: 4.823121e-03 [1.207965e-05] 
Layer 'fc8' biases: 2.583024e-02 [2.859921e-05] 
Train error last 800 batches: 0.655027
-------------------------------------------------------
Not saving because 0.496366 > 0.299667 (9.300: -1.18%)
======================================================= (2.379 sec)
31.281... logprob:  0.649045, 0.274739 (1.428 sec)
31.282... logprob:  0.735552, 0.320312 (1.411 sec)
31.283... logprob:  0.580102, 0.247396 (1.408 sec)
31.284... logprob:  0.683064, 0.281250 (1.408 sec)
31.285... logprob:  0.616323, 0.286458 (1.438 sec)
31.286... logprob:  0.646245, 0.266927 (1.433 sec)
31.287... logprob:  0.549237, 0.242187 (1.426 sec)
31.288... logprob:  0.601769, 0.282552 (1.434 sec)
31.289... logprob:  0.683144, 0.276042 (1.438 sec)
31.290... logprob:  0.605166, 0.263021 (1.405 sec)
31.291... logprob:  0.661587, 0.269531 (1.412 sec)
31.292... logprob:  0.802059, 0.356771 (1.412 sec)
31.293... logprob:  0.660991, 0.290365 (1.417 sec)
31.294... logprob:  0.575218, 0.273438 (1.402 sec)
31.295... logprob:  0.563311, 0.277344 (1.460 sec)
31.296... logprob:  0.576054, 0.264323 (1.419 sec)
31.297... logprob:  0.587135, 0.253906 (1.423 sec)
31.298... logprob:  0.594660, 0.269531 (1.455 sec)
31.299... logprob:  0.590297, 0.251302 (1.392 sec)
31.300... logprob:  0.656603, 0.304687 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.403779, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.369467e-03 [1.185738e-07] 
Layer 'conv1' biases: 2.177036e-06 [2.808140e-11] 
Layer 'conv2' weights[0]: 2.364750e-03 [1.183107e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.336613e-10] 
Layer 'conv3' weights[0]: 2.363685e-03 [1.183965e-07] 
Layer 'conv3' biases: 3.618254e-05 [4.443323e-09] 
Layer 'conv4' weights[0]: 2.373676e-03 [1.190333e-07] 
Layer 'conv4' biases: 9.998360e-01 [1.376924e-07] 
Layer 'conv5' weights[0]: 2.539932e-03 [2.636053e-06] 
Layer 'conv5' biases: 9.990414e-01 [2.851903e-06] 
Layer 'fc6' weights[0]: 6.694744e-03 [5.952761e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.353718e-08] 
Layer 'fc7' weights[0]: 7.037645e-03 [1.379570e-07] 
Layer 'fc7' biases: 9.997093e-01 [1.899531e-07] 
Layer 'fc8' weights[0]: 4.840219e-03 [1.272841e-05] 
Layer 'fc8' biases: 2.596047e-02 [2.920980e-05] 
Train error last 800 batches: 0.654896
-------------------------------------------------------
Not saving because 0.403779 > 0.299667 (9.300: -1.18%)
======================================================= (2.357 sec)
31.301... logprob:  0.552324, 0.233073 (1.457 sec)
31.302... logprob:  0.822043, 0.376302 (1.419 sec)
31.303... logprob:  0.677621, 0.305990 (1.409 sec)
31.304... logprob:  0.642792, 0.263021 (1.437 sec)
31.305... logprob:  0.586773, 0.252604 (1.433 sec)
31.306... logprob:  0.731116, 0.317708 (1.427 sec)
31.307... logprob:  0.594384, 0.256510 (1.436 sec)
31.308... logprob:  0.572186, 0.273437 (1.444 sec)
31.309... logprob:  0.666504, 0.281250 (1.413 sec)
31.310... logprob:  0.696244, 0.317708 (1.425 sec)
31.311... logprob:  0.704585, 0.317708 (1.424 sec)
31.312... logprob:  0.739095, 0.324219 (1.427 sec)
31.313... logprob:  0.685530, 0.265625 (1.419 sec)
31.314... logprob:  0.695884, 0.312500 (1.460 sec)
31.315... logprob:  0.624441, 0.264323 (1.430 sec)
31.316... logprob:  0.754153, 0.335937 (1.418 sec)
31.317... logprob:  0.580025, 0.269531 (1.469 sec)
31.318... logprob:  0.670701, 0.269531 (1.406 sec)
31.319... logprob:  0.614941, 0.248698 (1.417 sec)
31.320... logprob:  0.591710, 0.236979 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.447366, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.367102e-03 [1.184209e-07] 
Layer 'conv1' biases: 2.177025e-06 [5.083699e-11] 
Layer 'conv2' weights[0]: 2.362380e-03 [1.181817e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.434794e-10] 
Layer 'conv3' weights[0]: 2.361309e-03 [1.184507e-07] 
Layer 'conv3' biases: 3.620350e-05 [7.060617e-09] 
Layer 'conv4' weights[0]: 2.371304e-03 [1.189585e-07] 
Layer 'conv4' biases: 9.998362e-01 [2.080969e-07] 
Layer 'conv5' weights[0]: 2.537732e-03 [2.555223e-06] 
Layer 'conv5' biases: 9.990638e-01 [2.869280e-06] 
Layer 'fc6' weights[0]: 6.694049e-03 [6.382108e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.903614e-08] 
Layer 'fc7' weights[0]: 7.036922e-03 [1.479881e-07] 
Layer 'fc7' biases: 9.997076e-01 [1.997285e-07] 
Layer 'fc8' weights[0]: 4.794293e-03 [1.236427e-05] 
Layer 'fc8' biases: 2.555091e-02 [2.319022e-05] 
Train error last 800 batches: 0.655214
-------------------------------------------------------
Not saving because 0.447366 > 0.299667 (9.300: -1.18%)
======================================================= (2.409 sec)
31.321... logprob:  0.521613, 0.225260 (1.430 sec)
31.322... logprob:  0.642432, 0.299479 (1.419 sec)
31.323... logprob:  0.623985, 0.265625 (1.476 sec)
31.324... logprob:  0.769001, 0.345052 (1.418 sec)
31.325... logprob:  0.587216, 0.279948 (1.427 sec)
31.326... logprob:  0.737822, 0.261719 (1.457 sec)
31.327... logprob:  0.714776, 0.296875 (1.416 sec)
31.328... logprob:  0.687980, 0.316406 (1.420 sec)
31.329... logprob:  0.639012, 0.291667 (1.414 sec)
31.330... logprob:  0.657493, 0.246094 (1.416 sec)
31.331... logprob:  0.520781, 0.240885 (1.410 sec)
31.332... logprob:  0.591227, 0.269531 (1.446 sec)
31.333... logprob:  0.660045, 0.294271 (1.437 sec)
31.334... logprob:  0.741150, 0.319010 (1.434 sec)
31.335... logprob:  0.593348, 0.263021 (1.433 sec)
31.336... logprob:  0.664129, 0.328125 (1.448 sec)
31.337... logprob:  0.766713, 0.326823 (1.409 sec)
31.338... logprob:  0.563358, 0.266927 (1.416 sec)
31.339... logprob:  0.642542, 0.292969 (1.419 sec)
31.340... logprob:  0.659033, 0.296875 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.460640, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.364732e-03 [1.183529e-07] 
Layer 'conv1' biases: 2.176841e-06 [4.180384e-11] 
Layer 'conv2' weights[0]: 2.360028e-03 [1.180894e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.352771e-10] 
Layer 'conv3' weights[0]: 2.358973e-03 [1.183012e-07] 
Layer 'conv3' biases: 3.621130e-05 [6.120416e-09] 
Layer 'conv4' weights[0]: 2.368946e-03 [1.189825e-07] 
Layer 'conv4' biases: 9.998353e-01 [2.013340e-07] 
Layer 'conv5' weights[0]: 2.534861e-03 [2.195438e-06] 
Layer 'conv5' biases: 9.990609e-01 [2.352569e-06] 
Layer 'fc6' weights[0]: 6.693346e-03 [5.912960e-08] 
Layer 'fc6' biases: 9.999894e-01 [5.244753e-08] 
Layer 'fc7' weights[0]: 7.036231e-03 [1.339994e-07] 
Layer 'fc7' biases: 9.997077e-01 [1.596655e-07] 
Layer 'fc8' weights[0]: 4.788974e-03 [1.089796e-05] 
Layer 'fc8' biases: 2.552166e-02 [1.262925e-05] 
Train error last 800 batches: 0.654768
-------------------------------------------------------
Not saving because 0.460640 > 0.299667 (9.300: -1.18%)
======================================================= (2.400 sec)
31.341... logprob:  0.661527, 0.287760 (1.421 sec)
31.342... logprob:  0.668469, 0.311198 (1.460 sec)
31.343... logprob:  0.548428, 0.239583 (1.434 sec)
31.344... logprob:  0.698543, 0.272135 (1.477 sec)
31.345... logprob:  0.762712, 0.295573 (1.435 sec)
31.346... logprob:  0.698710, 0.298177 (1.428 sec)
31.347... logprob:  0.612412, 0.296875 (1.477 sec)
31.348... logprob:  0.586950, 0.260417 (1.426 sec)
31.349... logprob:  0.723871, 0.325521 (1.428 sec)
31.350... logprob:  0.598374, 0.260417 (1.428 sec)
31.351... logprob:  0.673767, 0.305989 (1.424 sec)
31.352... logprob:  0.593464, 0.273437 (1.423 sec)
31.353... logprob:  0.665749, 0.269531 (1.486 sec)
31.354... logprob:  0.705824, 0.311198 (1.426 sec)
31.355... logprob:  0.537489, 0.257812 (1.439 sec)
31.356... logprob:  0.654405, 0.287760 (1.466 sec)
31.357... logprob:  0.619880, 0.300781 (1.425 sec)
31.358... logprob:  0.599473, 0.268229 (1.435 sec)
31.359... logprob:  0.803046, 0.363281 (1.425 sec)
31.360... logprob:  0.750913, 0.333333 (1.417 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.566053, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.362371e-03 [1.181816e-07] 
Layer 'conv1' biases: 2.176745e-06 [3.830530e-11] 
Layer 'conv2' weights[0]: 2.357669e-03 [1.179458e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.472750e-10] 
Layer 'conv3' weights[0]: 2.356593e-03 [1.181346e-07] 
Layer 'conv3' biases: 3.622307e-05 [5.968447e-09] 
Layer 'conv4' weights[0]: 2.366580e-03 [1.186914e-07] 
Layer 'conv4' biases: 9.998354e-01 [1.797630e-07] 
Layer 'conv5' weights[0]: 2.532585e-03 [1.999920e-06] 
Layer 'conv5' biases: 9.990488e-01 [2.150040e-06] 
Layer 'fc6' weights[0]: 6.692661e-03 [5.909277e-08] 
Layer 'fc6' biases: 9.999894e-01 [5.307389e-08] 
Layer 'fc7' weights[0]: 7.035523e-03 [1.377921e-07] 
Layer 'fc7' biases: 9.997082e-01 [1.668897e-07] 
Layer 'fc8' weights[0]: 4.801836e-03 [1.146898e-05] 
Layer 'fc8' biases: 2.571205e-02 [1.715146e-05] 
Train error last 800 batches: 0.654785
-------------------------------------------------------
Not saving because 0.566053 > 0.299667 (9.300: -1.18%)
======================================================= (2.360 sec)
31.361... logprob:  0.549863, 0.266927 (1.432 sec)
31.362... logprob:  0.643414, 0.303385 (1.480 sec)
31.363... logprob:  0.578199, 0.243490 (1.441 sec)
31.364... logprob:  0.680473, 0.264323 (1.445 sec)
31.365... logprob:  0.733373, 0.276042 (1.459 sec)
31.366... logprob:  0.716561, 0.342448 (1.436 sec)
31.367... logprob:  0.620112, 0.307292 (1.433 sec)
31.368... logprob:  0.771868, 0.311198 (1.426 sec)
31.369... logprob:  0.638176, 0.270833 (1.426 sec)
31.370... logprob:  0.638161, 0.294271 (1.431 sec)
31.371... logprob:  0.621269, 0.265625 (1.450 sec)
31.372... logprob:  0.687504, 0.279948 (1.450 sec)
31.373... logprob:  0.666128, 0.307292 (1.443 sec)
31.374... logprob:  0.668387, 0.264323 (1.447 sec)
31.375... logprob:  0.648220, 0.282552 (1.458 sec)
31.376... logprob:  0.660343, 0.286458 (1.432 sec)
31.377... logprob:  0.522765, 0.214844 (1.418 sec)
31.378... logprob:  0.618431, 0.277344 (1.428 sec)
31.379... logprob:  0.614724, 0.299479 (1.470 sec)
31.380... logprob:  0.662198, 0.276042 (1.436 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.517196, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.360002e-03 [1.181307e-07] 
Layer 'conv1' biases: 2.176738e-06 [2.721072e-11] 
Layer 'conv2' weights[0]: 2.355307e-03 [1.178611e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.762616e-10] 
Layer 'conv3' weights[0]: 2.354233e-03 [1.179675e-07] 
Layer 'conv3' biases: 3.622822e-05 [4.992348e-09] 
Layer 'conv4' weights[0]: 2.364211e-03 [1.186393e-07] 
Layer 'conv4' biases: 9.998353e-01 [1.683266e-07] 
Layer 'conv5' weights[0]: 2.530594e-03 [2.261083e-06] 
Layer 'conv5' biases: 9.990454e-01 [2.426941e-06] 
Layer 'fc6' weights[0]: 6.691952e-03 [6.007066e-08] 
Layer 'fc6' biases: 9.999894e-01 [5.425776e-08] 
Layer 'fc7' weights[0]: 7.034840e-03 [1.381927e-07] 
Layer 'fc7' biases: 9.997084e-01 [1.715452e-07] 
Layer 'fc8' weights[0]: 4.800106e-03 [1.139467e-05] 
Layer 'fc8' biases: 2.580519e-02 [1.713359e-05] 
Train error last 800 batches: 0.654312
-------------------------------------------------------
Not saving because 0.517196 > 0.299667 (9.300: -1.18%)
======================================================= (2.358 sec)
31.381... logprob:  0.645944, 0.295573 (1.471 sec)
31.382... logprob:  0.768346, 0.339844 (1.452 sec)
31.383... logprob:  0.636052, 0.282552 (1.441 sec)
31.384... logprob:  0.734324, 0.329427 (1.478 sec)
31.385... logprob:  0.788974, 0.304688 (1.430 sec)
31.386... logprob:  0.734357, 0.299479 (1.420 sec)
31.387... logprob:  0.655349, 0.300781 (1.429 sec)
31.388... logprob:  0.746208, 0.312500 (1.425 sec)
31.389... logprob:  0.667509, 0.287760 (1.433 sec)
31.390... logprob:  0.610779, 0.272135 (1.474 sec)
31.391... logprob:  0.508583, 0.227865 (1.437 sec)
31.392... logprob:  0.651641, 0.296875 (1.432 sec)
31.393... logprob:  0.595673, 0.269531 (1.480 sec)
31.394... logprob:  0.564579, 0.259115 (1.423 sec)
31.395... logprob:  0.591019, 0.263021 (1.425 sec)
31.396... logprob:  0.517813, 0.246094 (1.426 sec)
31.397... logprob:  0.687149, 0.279948 (1.428 sec)
31.398... logprob:  0.656525, 0.296875 (1.427 sec)
31.399... logprob:  0.658446, 0.289062 (1.477 sec)
31.400... logprob:  0.694321, 0.303385 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.453478, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.357649e-03 [1.179392e-07] 
Layer 'conv1' biases: 2.176970e-06 [3.913523e-11] 
Layer 'conv2' weights[0]: 2.352941e-03 [1.177051e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.338746e-10] 
Layer 'conv3' weights[0]: 2.351873e-03 [1.178685e-07] 
Layer 'conv3' biases: 3.623002e-05 [5.463519e-09] 
Layer 'conv4' weights[0]: 2.361827e-03 [1.185330e-07] 
Layer 'conv4' biases: 9.998347e-01 [1.793552e-07] 
Layer 'conv5' weights[0]: 2.528106e-03 [2.825292e-06] 
Layer 'conv5' biases: 9.990477e-01 [2.993068e-06] 
Layer 'fc6' weights[0]: 6.691264e-03 [6.558810e-08] 
Layer 'fc6' biases: 9.999894e-01 [6.132296e-08] 
Layer 'fc7' weights[0]: 7.034136e-03 [1.608968e-07] 
Layer 'fc7' biases: 9.997082e-01 [2.458488e-07] 
Layer 'fc8' weights[0]: 4.802581e-03 [1.623101e-05] 
Layer 'fc8' biases: 2.577224e-02 [5.100687e-05] 
Train error last 800 batches: 0.654496
-------------------------------------------------------
Not saving because 0.453478 > 0.299667 (9.300: -1.18%)
======================================================= (2.372 sec)
31.401... logprob:  0.671057, 0.312500 (1.439 sec)
31.402... logprob:  0.737250, 0.325521 (1.486 sec)
31.403... logprob:  0.652627, 0.305989 (1.431 sec)
31.404... logprob:  0.703158, 0.320312 (1.429 sec)
31.405... logprob:  0.724878, 0.315104 (1.428 sec)
31.406... logprob:  0.621624, 0.268229 (1.420 sec)
31.407... logprob:  0.783553, 0.359375 (1.427 sec)
31.408... logprob:  0.531787, 0.264323 (1.473 sec)
31.409... logprob:  0.592569, 0.286458 (1.433 sec)
31.410... logprob:  0.797325, 0.334635 (1.444 sec)
31.411... logprob:  0.648902, 0.307292 (1.467 sec)
31.412... logprob:  0.774485, 0.342448 (1.430 sec)
31.413... logprob:  0.707894, 0.309896 (1.433 sec)
31.414... logprob:  0.757225, 0.339844 (1.432 sec)
31.415... logprob:  0.580767, 0.278646 (1.415 sec)
31.416... logprob:  0.671636, 0.282552 (1.434 sec)
31.417... logprob:  0.632098, 0.260417 (1.481 sec)
31.418... logprob:  0.686739, 0.278646 (1.446 sec)
31.419... logprob:  0.662996, 0.273437 (1.446 sec)
31.420... logprob:  0.627054, 0.259114 (1.449 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.450754, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.355292e-03 [1.178270e-07] 
Layer 'conv1' biases: 2.177169e-06 [3.991162e-11] 
Layer 'conv2' weights[0]: 2.350598e-03 [1.175733e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.645726e-10] 
Layer 'conv3' weights[0]: 2.349518e-03 [1.177569e-07] 
Layer 'conv3' biases: 3.623567e-05 [5.524714e-09] 
Layer 'conv4' weights[0]: 2.359479e-03 [1.183773e-07] 
Layer 'conv4' biases: 9.998343e-01 [1.760499e-07] 
Layer 'conv5' weights[0]: 2.525584e-03 [2.643564e-06] 
Layer 'conv5' biases: 9.990584e-01 [2.925048e-06] 
Layer 'fc6' weights[0]: 6.690588e-03 [6.576429e-08] 
Layer 'fc6' biases: 9.999894e-01 [6.193303e-08] 
Layer 'fc7' weights[0]: 7.033456e-03 [1.564078e-07] 
Layer 'fc7' biases: 9.997073e-01 [2.226694e-07] 
Layer 'fc8' weights[0]: 4.773519e-03 [1.423397e-05] 
Layer 'fc8' biases: 2.557738e-02 [3.024300e-05] 
Train error last 800 batches: 0.654841
-------------------------------------------------------
Not saving because 0.450754 > 0.299667 (9.300: -1.18%)
======================================================= (2.351 sec)
31.421... logprob:  0.584762, 0.250000 (1.453 sec)
31.422... logprob:  0.734602, 0.298177 (1.442 sec)
31.423... logprob:  0.652988, 0.299479 (1.421 sec)
31.424... logprob:  0.572082, 0.256510 (1.426 sec)
31.425... logprob:  0.597741, 0.269531 (1.429 sec)
31.426... logprob:  0.652709, 0.296875 (1.442 sec)
31.427... logprob:  0.839947, 0.355469 (1.455 sec)
31.428... logprob:  0.748014, 0.341146 (1.449 sec)
31.429... logprob:  0.674386, 0.289063 (1.449 sec)
31.430... logprob:  0.597602, 0.276042 (1.463 sec)
31.431... logprob:  0.731166, 0.325521 (1.427 sec)
31.432... logprob:  0.557437, 0.233073 (1.422 sec)
31.433... logprob:  0.574671, 0.256510 (1.427 sec)
31.434... logprob:  0.789364, 0.338542 (1.433 sec)
31.435... logprob:  0.772815, 0.333333 (1.426 sec)
31.436... logprob:  0.621650, 0.291667 (1.479 sec)
31.437... logprob:  0.681400, 0.299479 (1.444 sec)
31.438... logprob:  0.768842, 0.346354 (1.423 sec)
31.439... logprob:  0.585287, 0.233073 (1.481 sec)
31.440... logprob:  0.631425, 0.253906 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.477593, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.352939e-03 [1.176607e-07] 
Layer 'conv1' biases: 2.177390e-06 [4.504945e-11] 
Layer 'conv2' weights[0]: 2.348243e-03 [1.174499e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.539343e-10] 
Layer 'conv3' weights[0]: 2.347175e-03 [1.176287e-07] 
Layer 'conv3' biases: 3.621948e-05 [5.465565e-09] 
Layer 'conv4' weights[0]: 2.357113e-03 [1.181767e-07] 
Layer 'conv4' biases: 9.998330e-01 [1.679404e-07] 
Layer 'conv5' weights[0]: 2.522416e-03 [2.157425e-06] 
Layer 'conv5' biases: 9.990684e-01 [2.342545e-06] 
Layer 'fc6' weights[0]: 6.689895e-03 [6.018341e-08] 
Layer 'fc6' biases: 9.999895e-01 [5.415633e-08] 
Layer 'fc7' weights[0]: 7.032756e-03 [1.406935e-07] 
Layer 'fc7' biases: 9.997063e-01 [1.711406e-07] 
Layer 'fc8' weights[0]: 4.756558e-03 [1.157074e-05] 
Layer 'fc8' biases: 2.550936e-02 [1.341960e-05] 
Train error last 800 batches: 0.654795
-------------------------------------------------------
Not saving because 0.477593 > 0.299667 (9.300: -1.18%)
======================================================= (2.417 sec)
31.441... logprob:  0.653095, 0.299479 (1.429 sec)
31.442... logprob:  0.597509, 0.265625 (1.435 sec)
31.443... logprob:  0.774667, 0.356771 (1.434 sec)
31.444... logprob:  0.614222, 0.240885 (1.425 sec)
31.445... logprob:  0.600890, 0.278646 (1.479 sec)
31.446... logprob:  0.627644, 0.292969 (1.427 sec)
31.447... logprob:  0.740089, 0.330729 (1.433 sec)
31.448... logprob:  0.598899, 0.272135 (1.472 sec)
31.449... logprob:  0.630784, 0.279948 (1.431 sec)
31.450... logprob:  0.492018, 0.208333 (1.427 sec)
31.451... logprob:  0.653014, 0.282552 (1.427 sec)
31.452... logprob:  0.663918, 0.285156 (1.422 sec)
31.453... logprob:  0.657542, 0.287760 (1.427 sec)
31.454... logprob:  0.653142, 0.300781 (1.480 sec)
31.455... logprob:  0.803648, 0.328125 (1.452 sec)
31.456... logprob:  0.695593, 0.286458 (1.444 sec)
31.457... logprob:  0.636958, 0.279948 (1.473 sec)
31.458... logprob:  0.608122, 0.272135 (1.429 sec)
31.459... logprob:  0.677438, 0.287760 (1.432 sec)
31.460... logprob:  0.462483, 0.216146 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.398441, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.350578e-03 [1.175660e-07] 
Layer 'conv1' biases: 2.177423e-06 [3.544745e-11] 
Layer 'conv2' weights[0]: 2.345900e-03 [1.173548e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.456827e-10] 
Layer 'conv3' weights[0]: 2.344825e-03 [1.174263e-07] 
Layer 'conv3' biases: 3.621350e-05 [4.476527e-09] 
Layer 'conv4' weights[0]: 2.354773e-03 [1.180224e-07] 
Layer 'conv4' biases: 9.998329e-01 [1.376910e-07] 
Layer 'conv5' weights[0]: 2.520218e-03 [2.589843e-06] 
Layer 'conv5' biases: 9.990578e-01 [2.798334e-06] 
Layer 'fc6' weights[0]: 6.689172e-03 [6.063561e-08] 
Layer 'fc6' biases: 9.999894e-01 [5.486122e-08] 
Layer 'fc7' weights[0]: 7.032034e-03 [1.407513e-07] 
Layer 'fc7' biases: 9.997066e-01 [1.890863e-07] 
Layer 'fc8' weights[0]: 4.781846e-03 [1.219862e-05] 
Layer 'fc8' biases: 2.568894e-02 [2.615501e-05] 
Train error last 800 batches: 0.654886
-------------------------------------------------------
Not saving because 0.398441 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
31.461... logprob:  0.702472, 0.285156 (1.431 sec)
31.462... logprob:  0.806506, 0.358073 (1.439 sec)
31.463... logprob:  0.631116, 0.290365 (1.469 sec)
31.464... logprob:  0.680561, 0.298177 (1.444 sec)
31.465... logprob:  0.568111, 0.259115 (1.455 sec)
31.466... logprob:  0.657398, 0.304687 (1.453 sec)
31.467... logprob:  0.639808, 0.289062 (1.442 sec)
31.468... logprob:  0.664542, 0.311198 (1.442 sec)
31.469... logprob:  0.579487, 0.266927 (1.420 sec)
31.470... logprob:  0.565325, 0.226562 (1.417 sec)
31.471... logprob:  0.760618, 0.286458 (1.437 sec)
31.472... logprob:  0.621042, 0.287760 (1.444 sec)
31.473... logprob:  0.656640, 0.312500 (1.453 sec)
31.474... logprob:  0.681126, 0.276042 (1.446 sec)
31.475... logprob:  0.722379, 0.299479 (1.439 sec)
31.476... logprob:  0.697375, 0.292969 (1.465 sec)
31.477... logprob:  0.567386, 0.252604 (1.431 sec)
31.478... logprob:  0.632431, 0.264323 (1.421 sec)
31.479... logprob:  0.587616, 0.242188 (1.422 sec)
31.480... logprob:  0.692577, 0.308594 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.508389, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.348240e-03 [1.174322e-07] 
Layer 'conv1' biases: 2.177648e-06 [5.416320e-11] 
Layer 'conv2' weights[0]: 2.343564e-03 [1.172376e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.549125e-10] 
Layer 'conv3' weights[0]: 2.342495e-03 [1.175274e-07] 
Layer 'conv3' biases: 3.620374e-05 [6.646471e-09] 
Layer 'conv4' weights[0]: 2.352408e-03 [1.181781e-07] 
Layer 'conv4' biases: 9.998322e-01 [1.913124e-07] 
Layer 'conv5' weights[0]: 2.517747e-03 [2.248385e-06] 
Layer 'conv5' biases: 9.990433e-01 [2.442824e-06] 
Layer 'fc6' weights[0]: 6.688526e-03 [5.938657e-08] 
Layer 'fc6' biases: 9.999897e-01 [5.350272e-08] 
Layer 'fc7' weights[0]: 7.031323e-03 [1.385315e-07] 
Layer 'fc7' biases: 9.997072e-01 [1.661744e-07] 
Layer 'fc8' weights[0]: 4.808773e-03 [1.144534e-05] 
Layer 'fc8' biases: 2.593379e-02 [1.549612e-05] 
Train error last 800 batches: 0.655283
-------------------------------------------------------
Not saving because 0.508389 > 0.299667 (9.300: -1.18%)
======================================================= (2.371 sec)
31.481... logprob:  0.732297, 0.312500 (1.438 sec)
31.482... logprob:  0.783954, 0.345052 (1.475 sec)
31.483... logprob:  0.719453, 0.333333 (1.450 sec)
31.484... logprob:  0.689515, 0.294271 (1.434 sec)
31.485... logprob:  0.628593, 0.282552 (1.478 sec)
31.486... logprob:  0.624192, 0.282552 (1.428 sec)
31.487... logprob:  0.769392, 0.303385 (1.421 sec)
31.488... logprob:  0.594094, 0.291667 (1.432 sec)
31.489... logprob:  0.579236, 0.259114 (1.433 sec)
31.490... logprob:  0.674425, 0.289062 (1.427 sec)
31.491... logprob:  0.679906, 0.328125 (1.472 sec)
31.492... logprob:  0.631094, 0.272135 (1.439 sec)
31.493... logprob:  0.634439, 0.274740 (1.452 sec)
31.494... logprob:  0.625669, 0.264323 (1.486 sec)
31.495... logprob:  0.645833, 0.282552 (1.432 sec)
31.496... logprob:  0.755004, 0.322917 (1.429 sec)
31.497... logprob:  0.651595, 0.273438 (1.426 sec)
31.498... logprob:  0.734933, 0.320312 (1.428 sec)
31.499... logprob:  0.712435, 0.316406 (1.426 sec)
31.500... logprob:  0.575918, 0.257812 (1.488 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.366684, 0.062500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.345884e-03 [1.173613e-07] 
Layer 'conv1' biases: 2.177801e-06 [2.913611e-11] 
Layer 'conv2' weights[0]: 2.341211e-03 [1.171192e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.007234e-10] 
Layer 'conv3' weights[0]: 2.340148e-03 [1.171840e-07] 
Layer 'conv3' biases: 3.620465e-05 [3.975805e-09] 
Layer 'conv4' weights[0]: 2.350061e-03 [1.178107e-07] 
Layer 'conv4' biases: 9.998319e-01 [1.330245e-07] 
Layer 'conv5' weights[0]: 2.514932e-03 [2.041781e-06] 
Layer 'conv5' biases: 9.990570e-01 [2.178528e-06] 
Layer 'fc6' weights[0]: 6.687858e-03 [5.923648e-08] 
Layer 'fc6' biases: 9.999895e-01 [5.322142e-08] 
Layer 'fc7' weights[0]: 7.030616e-03 [1.364767e-07] 
Layer 'fc7' biases: 9.997067e-01 [1.619135e-07] 
Layer 'fc8' weights[0]: 4.787408e-03 [1.082775e-05] 
Layer 'fc8' biases: 2.573731e-02 [7.011392e-06] 
Train error last 800 batches: 0.655448
-------------------------------------------------------
Not saving because 0.366684 > 0.299667 (9.300: -1.18%)
======================================================= (2.414 sec)
31.501... logprob:  0.680436, 0.312500 (1.429 sec)
31.502... logprob:  0.664636, 0.312500 (1.440 sec)
31.503... logprob:  0.595401, 0.274740 (1.477 sec)
31.504... logprob:  0.748389, 0.332031 (1.423 sec)
31.505... logprob:  0.722200, 0.343750 (1.434 sec)
31.506... logprob:  0.588164, 0.260417 (1.426 sec)
31.507... logprob:  0.542704, 0.253906 (1.417 sec)
31.508... logprob:  0.673851, 0.283854 (1.430 sec)
31.509... logprob:  0.566257, 0.272135 (1.467 sec)
31.510... logprob:  0.644753, 0.255208 (1.433 sec)
31.511... logprob:  0.608063, 0.285156 (1.448 sec)
31.512... logprob:  0.780356, 0.325521 (1.458 sec)
31.513... logprob:  0.627879, 0.289062 (1.438 sec)
31.514... logprob:  0.703130, 0.285156 (1.431 sec)
31.515... logprob:  0.726637, 0.324219 (1.428 sec)
31.516... logprob:  0.682945, 0.291667 (1.416 sec)
31.517... logprob:  0.759708, 0.332031 (1.429 sec)
31.518... logprob:  0.652162, 0.312500 (1.456 sec)
31.519... logprob:  0.658252, 0.295573 (1.446 sec)
31.520... logprob:  0.649839, 0.304687 (1.450 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.425960, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.343542e-03 [1.171868e-07] 
Layer 'conv1' biases: 2.178018e-06 [5.660640e-11] 
Layer 'conv2' weights[0]: 2.338870e-03 [1.169763e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.844617e-10] 
Layer 'conv3' weights[0]: 2.337802e-03 [1.173168e-07] 
Layer 'conv3' biases: 3.620031e-05 [6.875665e-09] 
Layer 'conv4' weights[0]: 2.347714e-03 [1.180315e-07] 
Layer 'conv4' biases: 9.998299e-01 [2.584342e-07] 
Layer 'conv5' weights[0]: 2.511153e-03 [2.596297e-06] 
Layer 'conv5' biases: 9.990479e-01 [2.877628e-06] 
Layer 'fc6' weights[0]: 6.687163e-03 [6.159816e-08] 
Layer 'fc6' biases: 9.999894e-01 [5.660434e-08] 
Layer 'fc7' weights[0]: 7.029902e-03 [1.417205e-07] 
Layer 'fc7' biases: 9.997067e-01 [1.888600e-07] 
Layer 'fc8' weights[0]: 4.798966e-03 [1.201490e-05] 
Layer 'fc8' biases: 2.585649e-02 [2.493279e-05] 
Train error last 800 batches: 0.655310
-------------------------------------------------------
Not saving because 0.425960 > 0.299667 (9.300: -1.18%)
======================================================= (2.368 sec)
31.521... logprob:  0.681588, 0.292969 (1.449 sec)
31.522... logprob:  0.683157, 0.295573 (1.459 sec)
31.523... logprob:  0.568431, 0.277344 (1.437 sec)
31.524... logprob:  0.621615, 0.276042 (1.419 sec)
31.525... logprob:  0.572359, 0.276042 (1.424 sec)
31.526... logprob:  0.594491, 0.276042 (1.431 sec)
31.527... logprob:  0.705671, 0.287760 (1.438 sec)
31.528... logprob:  0.607480, 0.253906 (1.467 sec)
31.529... logprob:  0.628194, 0.294271 (1.445 sec)
31.530... logprob:  0.711664, 0.315104 (1.432 sec)
31.531... logprob:  0.684624, 0.283854 (1.493 sec)
31.532... logprob:  0.630513, 0.269531 (1.422 sec)
31.533... logprob:  0.737245, 0.311198 (1.421 sec)
31.534... logprob:  0.549617, 0.253906 (1.429 sec)
31.535... logprob:  0.706346, 0.313802 (1.429 sec)
31.536... logprob:  0.728803, 0.309896 (1.429 sec)
31.537... logprob:  0.712804, 0.325521 (1.469 sec)
31.538... logprob:  0.722614, 0.290365 (1.436 sec)
31.539... logprob:  0.580770, 0.278646 (1.431 sec)
31.540... logprob:  0.686917, 0.322917 (1.479 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.456124, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.341196e-03 [1.170579e-07] 
Layer 'conv1' biases: 2.178279e-06 [2.714456e-11] 
Layer 'conv2' weights[0]: 2.336530e-03 [1.168635e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.061581e-10] 
Layer 'conv3' weights[0]: 2.335470e-03 [1.169667e-07] 
Layer 'conv3' biases: 3.620104e-05 [4.553815e-09] 
Layer 'conv4' weights[0]: 2.345368e-03 [1.175680e-07] 
Layer 'conv4' biases: 9.998264e-01 [1.402775e-07] 
Layer 'conv5' weights[0]: 2.505993e-03 [2.347072e-06] 
Layer 'conv5' biases: 9.990479e-01 [2.444750e-06] 
Layer 'fc6' weights[0]: 6.686480e-03 [6.056618e-08] 
Layer 'fc6' biases: 9.999894e-01 [5.544620e-08] 
Layer 'fc7' weights[0]: 7.029220e-03 [1.388042e-07] 
Layer 'fc7' biases: 9.997068e-01 [1.736512e-07] 
Layer 'fc8' weights[0]: 4.799988e-03 [1.147513e-05] 
Layer 'fc8' biases: 2.594381e-02 [1.688037e-05] 
Train error last 800 batches: 0.654687
-------------------------------------------------------
Not saving because 0.456124 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
31.541... logprob:  0.622276, 0.299479 (1.433 sec)
31.542... logprob:  0.721884, 0.333333 (1.428 sec)
31.543... logprob:  0.508845, 0.233073 (1.430 sec)
31.544... logprob:  0.544045, 0.240885 (1.428 sec)
31.545... logprob:  0.601846, 0.285156 (1.430 sec)
31.546... logprob:  0.676293, 0.295573 (1.477 sec)
31.547... logprob:  0.674095, 0.303385 (1.429 sec)
31.548... logprob:  0.582134, 0.257812 (1.431 sec)
31.549... logprob:  0.710483, 0.330729 (1.476 sec)
31.550... logprob:  0.598204, 0.272135 (1.426 sec)
31.551... logprob:  0.633179, 0.256510 (1.430 sec)
31.552... logprob:  0.707142, 0.294271 (1.427 sec)
31.553... logprob:  0.612371, 0.279948 (1.432 sec)
31.554... logprob:  0.643212, 0.287761 (1.423 sec)
31.555... logprob:  0.654636, 0.283854 (1.476 sec)
31.556... logprob:  0.547663, 0.220052 (1.435 sec)
31.557... logprob:  0.740490, 0.335938 (1.443 sec)
31.558... logprob:  0.643836, 0.282552 (1.467 sec)
31.559... logprob:  0.680119, 0.307292 (1.426 sec)
31.560... logprob:  0.592927, 0.248698 (1.435 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.466876, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.338853e-03 [1.170116e-07] 
Layer 'conv1' biases: 2.178466e-06 [2.897480e-11] 
Layer 'conv2' weights[0]: 2.334199e-03 [1.167745e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.123699e-10] 
Layer 'conv3' weights[0]: 2.333139e-03 [1.168083e-07] 
Layer 'conv3' biases: 3.619507e-05 [4.181231e-09] 
Layer 'conv4' weights[0]: 2.343013e-03 [1.173859e-07] 
Layer 'conv4' biases: 9.998254e-01 [1.529527e-07] 
Layer 'conv5' weights[0]: 2.503156e-03 [2.053827e-06] 
Layer 'conv5' biases: 9.990354e-01 [2.182897e-06] 
Layer 'fc6' weights[0]: 6.685778e-03 [5.942582e-08] 
Layer 'fc6' biases: 9.999894e-01 [5.402743e-08] 
Layer 'fc7' weights[0]: 7.028480e-03 [1.362409e-07] 
Layer 'fc7' biases: 9.997073e-01 [1.672329e-07] 
Layer 'fc8' weights[0]: 4.822230e-03 [1.128369e-05] 
Layer 'fc8' biases: 2.610939e-02 [1.746938e-05] 
Train error last 800 batches: 0.654902
-------------------------------------------------------
Not saving because 0.466876 > 0.299667 (9.300: -1.18%)
======================================================= (2.356 sec)
31.561... logprob:  0.662828, 0.299479 (1.433 sec)
31.562... logprob:  0.775729, 0.335937 (1.418 sec)
31.563... logprob:  0.620415, 0.278646 (1.432 sec)
31.564... logprob:  0.668808, 0.291667 (1.457 sec)
31.565... logprob:  0.720834, 0.298177 (1.444 sec)
31.566... logprob:  0.673257, 0.281250 (1.445 sec)
31.567... logprob:  0.694350, 0.320312 (1.462 sec)
31.568... logprob:  0.655564, 0.282552 (1.448 sec)
31.569... logprob:  0.663471, 0.291667 (1.431 sec)
31.570... logprob:  0.825053, 0.352865 (1.421 sec)
31.571... logprob:  0.720271, 0.322917 (1.422 sec)
31.572... logprob:  0.703854, 0.303385 (1.430 sec)
31.573... logprob:  0.777590, 0.316406 (1.442 sec)
31.574... logprob:  0.681100, 0.279948 (1.455 sec)
31.575... logprob:  0.592011, 0.276042 (1.447 sec)
31.576... logprob:  0.696994, 0.302083 (1.435 sec)
31.577... logprob:  0.652221, 0.316406 (1.471 sec)
31.578... logprob:  0.545794, 0.250000 (1.426 sec)
31.579... logprob:  0.613160, 0.281250 (1.419 sec)
31.580... logprob:  0.748247, 0.315104 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.517138, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.336525e-03 [1.168656e-07] 
Layer 'conv1' biases: 2.178720e-06 [2.809041e-11] 
Layer 'conv2' weights[0]: 2.331857e-03 [1.166439e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.484219e-10] 
Layer 'conv3' weights[0]: 2.330800e-03 [1.166775e-07] 
Layer 'conv3' biases: 3.621044e-05 [4.269795e-09] 
Layer 'conv4' weights[0]: 2.340664e-03 [1.172773e-07] 
Layer 'conv4' biases: 9.998262e-01 [1.304224e-07] 
Layer 'conv5' weights[0]: 2.502280e-03 [2.287386e-06] 
Layer 'conv5' biases: 9.990738e-01 [2.543964e-06] 
Layer 'fc6' weights[0]: 6.685093e-03 [6.011225e-08] 
Layer 'fc6' biases: 9.999899e-01 [5.404069e-08] 
Layer 'fc7' weights[0]: 7.027760e-03 [1.390962e-07] 
Layer 'fc7' biases: 9.997050e-01 [1.744477e-07] 
Layer 'fc8' weights[0]: 4.745462e-03 [1.209378e-05] 
Layer 'fc8' biases: 2.548859e-02 [1.949783e-05] 
Train error last 800 batches: 0.655074
-------------------------------------------------------
Not saving because 0.517138 > 0.299667 (9.300: -1.18%)
======================================================= (2.367 sec)
31.581... logprob:  0.837564, 0.332031 (1.442 sec)
31.582... logprob:  0.667767, 0.299479 (1.435 sec)
31.583... logprob:  0.731895, 0.333333 (1.478 sec)
31.584... logprob:  0.710214, 0.321615 (1.448 sec)
31.585... logprob:  0.580496, 0.256510 (1.425 sec)
31.586... logprob:  0.496562, 0.227865 (1.479 sec)
31.587... logprob:  0.718437, 0.296875 (1.427 sec)
31.588... logprob:  0.613317, 0.244792 (1.422 sec)
31.589... logprob:  0.648626, 0.296875 (1.432 sec)
31.590... logprob:  0.681753, 0.287760 (1.424 sec)
31.591... logprob:  0.589545, 0.260417 (1.426 sec)
31.592... logprob:  0.689014, 0.274740 (1.477 sec)
31.593... logprob:  0.691386, 0.313802 (1.431 sec)
31.594... logprob:  0.543285, 0.247396 (1.435 sec)
31.595... logprob:  0.582146, 0.269531 (1.488 sec)
31.596... logprob:  0.691447, 0.295573 (1.430 sec)
31.597... logprob:  0.642392, 0.290365 (1.431 sec)
31.598... logprob:  0.613697, 0.295573 (1.431 sec)
31.599... logprob:  0.582230, 0.265625 (1.422 sec)
31.600... logprob:  0.546211, 0.236979 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.467846, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.334188e-03 [1.168216e-07] 
Layer 'conv1' biases: 2.178861e-06 [6.787396e-11] 
Layer 'conv2' weights[0]: 2.329542e-03 [1.165810e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.855566e-10] 
Layer 'conv3' weights[0]: 2.328447e-03 [1.172227e-07] 
Layer 'conv3' biases: 3.619142e-05 [1.012824e-08] 
Layer 'conv4' weights[0]: 2.338334e-03 [1.181942e-07] 
Layer 'conv4' biases: 9.998272e-01 [3.146139e-07] 
Layer 'conv5' weights[0]: 2.501244e-03 [4.814968e-06] 
Layer 'conv5' biases: 9.990459e-01 [5.384115e-06] 
Layer 'fc6' weights[0]: 6.684413e-03 [8.521332e-08] 
Layer 'fc6' biases: 9.999895e-01 [8.754163e-08] 
Layer 'fc7' weights[0]: 7.027061e-03 [2.209768e-07] 
Layer 'fc7' biases: 9.997058e-01 [4.261940e-07] 
Layer 'fc8' weights[0]: 4.798344e-03 [2.235858e-05] 
Layer 'fc8' biases: 2.590471e-02 [7.408051e-05] 
Train error last 800 batches: 0.655432
-------------------------------------------------------
Not saving because 0.467846 > 0.299667 (9.300: -1.18%)
======================================================= (2.334 sec)
31.601... logprob:  0.641026, 0.252604 (1.483 sec)
31.602... logprob:  0.461115, 0.188802 (1.430 sec)
31.603... logprob:  0.520543, 0.251302 (1.445 sec)
31.604... logprob:  0.625097, 0.277344 (1.469 sec)
31.605... logprob:  0.725417, 0.324219 (1.426 sec)
31.606... logprob:  0.605360, 0.300781 (1.435 sec)
31.607... logprob:  0.702599, 0.294271 (1.425 sec)
31.608... logprob:  0.600864, 0.296875 (1.426 sec)
31.609... logprob:  0.567748, 0.235677 (1.428 sec)
31.610... logprob:  0.766849, 0.322917 (1.469 sec)
31.611... logprob:  0.750910, 0.334635 (1.437 sec)
31.612... logprob:  0.715498, 0.292969 (1.447 sec)
31.613... logprob:  0.544002, 0.231771 (1.464 sec)
31.614... logprob:  0.651820, 0.264323 (1.440 sec)
31.615... logprob:  0.598055, 0.264323 (1.432 sec)
31.616... logprob:  0.701721, 0.315104 (1.427 sec)
31.617... logprob:  0.591618, 0.261719 (1.433 sec)
31.618... logprob:  0.678978, 0.322917 (1.432 sec)
31.619... logprob:  0.674199, 0.292969 (1.448 sec)
31.620... logprob:  0.722351, 0.281250 (1.454 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.510050, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.331854e-03 [1.165655e-07] 
Layer 'conv1' biases: 2.179092e-06 [4.694142e-11] 
Layer 'conv2' weights[0]: 2.327197e-03 [1.163769e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.021068e-10] 
Layer 'conv3' weights[0]: 2.326129e-03 [1.167329e-07] 
Layer 'conv3' biases: 3.617390e-05 [7.577761e-09] 
Layer 'conv4' weights[0]: 2.335979e-03 [1.172416e-07] 
Layer 'conv4' biases: 9.998256e-01 [2.335871e-07] 
Layer 'conv5' weights[0]: 2.498246e-03 [3.963167e-06] 
Layer 'conv5' biases: 9.990171e-01 [4.476096e-06] 
Layer 'fc6' weights[0]: 6.683687e-03 [8.010702e-08] 
Layer 'fc6' biases: 9.999893e-01 [8.225797e-08] 
Layer 'fc7' weights[0]: 7.026410e-03 [2.004189e-07] 
Layer 'fc7' biases: 9.997069e-01 [3.666427e-07] 
Layer 'fc8' weights[0]: 4.854233e-03 [2.049735e-05] 
Layer 'fc8' biases: 2.641320e-02 [6.896589e-05] 
Train error last 800 batches: 0.655439
-------------------------------------------------------
Not saving because 0.510050 > 0.299667 (9.300: -1.18%)
======================================================= (2.381 sec)
31.621... logprob:  0.585150, 0.276042 (1.457 sec)
31.622... logprob:  0.550813, 0.247396 (1.440 sec)
31.623... logprob:  0.718703, 0.298177 (1.460 sec)
31.624... logprob:  0.604406, 0.286458 (1.433 sec)
31.625... logprob:  0.637011, 0.272135 (1.419 sec)
31.626... logprob:  0.663324, 0.286458 (1.434 sec)
31.627... logprob:  0.700619, 0.300781 (1.437 sec)
31.628... logprob:  0.574910, 0.261719 (1.430 sec)
31.629... logprob:  0.628625, 0.281250 (1.479 sec)
31.630... logprob:  0.620969, 0.302083 (1.442 sec)
31.631... logprob:  0.856955, 0.321615 (1.432 sec)
31.632... logprob:  0.636289, 0.282552 (1.480 sec)
31.633... logprob:  0.534949, 0.253906 (1.426 sec)
31.634... logprob:  0.839620, 0.345052 (1.420 sec)
31.635... logprob:  0.555396, 0.231771 (1.429 sec)
31.636... logprob:  0.648210, 0.278646 (1.431 sec)
31.637... logprob:  0.631918, 0.273437 (1.428 sec)
31.638... logprob:  0.795776, 0.329427 (1.479 sec)
31.639... logprob:  0.571315, 0.251302 (1.443 sec)
31.640... logprob:  0.721721, 0.302083 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.401496, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.329520e-03 [1.164333e-07] 
Layer 'conv1' biases: 2.179623e-06 [4.235274e-11] 
Layer 'conv2' weights[0]: 2.324872e-03 [1.162589e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.600900e-10] 
Layer 'conv3' weights[0]: 2.323828e-03 [1.164504e-07] 
Layer 'conv3' biases: 3.620926e-05 [6.076329e-09] 
Layer 'conv4' weights[0]: 2.333670e-03 [1.170471e-07] 
Layer 'conv4' biases: 9.998234e-01 [1.980175e-07] 
Layer 'conv5' weights[0]: 2.494848e-03 [3.550691e-06] 
Layer 'conv5' biases: 9.990624e-01 [3.848154e-06] 
Layer 'fc6' weights[0]: 6.683010e-03 [7.452091e-08] 
Layer 'fc6' biases: 9.999897e-01 [7.319061e-08] 
Layer 'fc7' weights[0]: 7.025727e-03 [1.891163e-07] 
Layer 'fc7' biases: 9.997043e-01 [3.255005e-07] 
Layer 'fc8' weights[0]: 4.767289e-03 [2.165242e-05] 
Layer 'fc8' biases: 2.577354e-02 [7.394458e-05] 
Train error last 800 batches: 0.655242
-------------------------------------------------------
Not saving because 0.401496 > 0.299667 (9.300: -1.18%)
======================================================= (2.344 sec)
31.641... logprob:  0.594286, 0.255208 (1.484 sec)
31.642... logprob:  0.660233, 0.279948 (1.426 sec)
31.643... logprob:  0.763137, 0.338542 (1.422 sec)
31.644... logprob:  0.507691, 0.196614 (1.432 sec)
31.645... logprob:  0.655115, 0.292969 (1.421 sec)
31.646... logprob:  0.559382, 0.251302 (1.438 sec)
31.647... logprob:  0.685344, 0.279948 (1.481 sec)
31.648... logprob:  0.669651, 0.308594 (1.426 sec)
31.649... logprob:  0.585213, 0.239583 (1.437 sec)
31.650... logprob:  0.660936, 0.270833 (1.468 sec)
31.651... logprob:  0.626321, 0.292969 (1.432 sec)
31.652... logprob:  0.689712, 0.335938 (1.436 sec)
31.653... logprob:  0.714701, 0.304687 (1.430 sec)
31.654... logprob:  0.723854, 0.330729 (1.418 sec)
31.655... logprob:  0.675043, 0.291667 (1.427 sec)
31.656... logprob:  0.616961, 0.257812 (1.471 sec)
31.657... logprob:  0.610713, 0.285156 (1.436 sec)
31.658... logprob:  0.548765, 0.243490 (1.449 sec)
31.659... logprob:  0.706849, 0.311198 (1.472 sec)
31.660... logprob:  0.749710, 0.317708 (1.438 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.508033, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.327195e-03 [1.163397e-07] 
Layer 'conv1' biases: 2.180036e-06 [4.560558e-11] 
Layer 'conv2' weights[0]: 2.322537e-03 [1.161570e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.939558e-10] 
Layer 'conv3' weights[0]: 2.321473e-03 [1.162229e-07] 
Layer 'conv3' biases: 3.620784e-05 [4.345337e-09] 
Layer 'conv4' weights[0]: 2.331328e-03 [1.168227e-07] 
Layer 'conv4' biases: 9.998228e-01 [1.490993e-07] 
Layer 'conv5' weights[0]: 2.492235e-03 [2.285012e-06] 
Layer 'conv5' biases: 9.990660e-01 [2.461960e-06] 
Layer 'fc6' weights[0]: 6.682331e-03 [6.320300e-08] 
Layer 'fc6' biases: 9.999897e-01 [5.820194e-08] 
Layer 'fc7' weights[0]: 7.025009e-03 [1.536342e-07] 
Layer 'fc7' biases: 9.997042e-01 [2.204728e-07] 
Layer 'fc8' weights[0]: 4.758753e-03 [1.485237e-05] 
Layer 'fc8' biases: 2.570013e-02 [4.290121e-05] 
Train error last 800 batches: 0.655396
-------------------------------------------------------
Not saving because 0.508033 > 0.299667 (9.300: -1.18%)
======================================================= (2.370 sec)
31.661... logprob:  0.625827, 0.265625 (1.431 sec)
31.662... logprob:  0.672518, 0.296875 (1.430 sec)
31.663... logprob:  0.569526, 0.239583 (1.421 sec)
31.664... logprob:  0.553146, 0.263021 (1.436 sec)
31.665... logprob:  0.691270, 0.304688 (1.453 sec)
31.666... logprob:  0.615880, 0.294271 (1.448 sec)
31.667... logprob:  0.821487, 0.348958 (1.445 sec)
31.668... logprob:  0.705841, 0.295573 (1.444 sec)
31.669... logprob:  0.616828, 0.285156 (1.456 sec)
31.670... logprob:  0.507886, 0.183594 (1.433 sec)
31.671... logprob:  0.610616, 0.292969 (1.419 sec)
31.672... logprob:  0.676647, 0.287760 (1.424 sec)
31.673... logprob:  0.649062, 0.289062 (1.429 sec)
31.674... logprob:  0.703494, 0.296875 (1.439 sec)
31.675... logprob:  0.542272, 0.227865 (1.459 sec)
31.676... logprob:  0.736855, 0.307292 (1.442 sec)
31.677... logprob:  0.678887, 0.282552 (1.437 sec)
31.678... logprob:  0.690627, 0.311198 (1.472 sec)
31.679... logprob:  0.633633, 0.287760 (1.425 sec)
31.680... logprob:  0.625404, 0.303385 (1.422 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.463385, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.324876e-03 [1.162842e-07] 
Layer 'conv1' biases: 2.180327e-06 [2.307520e-11] 
Layer 'conv2' weights[0]: 2.320219e-03 [1.160618e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.118425e-10] 
Layer 'conv3' weights[0]: 2.319149e-03 [1.160776e-07] 
Layer 'conv3' biases: 3.620907e-05 [3.711318e-09] 
Layer 'conv4' weights[0]: 2.328996e-03 [1.165854e-07] 
Layer 'conv4' biases: 9.998229e-01 [1.071916e-07] 
Layer 'conv5' weights[0]: 2.490348e-03 [1.960965e-06] 
Layer 'conv5' biases: 9.990514e-01 [2.116597e-06] 
Layer 'fc6' weights[0]: 6.681664e-03 [5.805724e-08] 
Layer 'fc6' biases: 9.999896e-01 [5.179159e-08] 
Layer 'fc7' weights[0]: 7.024268e-03 [1.352547e-07] 
Layer 'fc7' biases: 9.997047e-01 [1.681470e-07] 
Layer 'fc8' weights[0]: 4.790765e-03 [1.157022e-05] 
Layer 'fc8' biases: 2.591288e-02 [2.221869e-05] 
Train error last 800 batches: 0.655107
-------------------------------------------------------
Not saving because 0.463385 > 0.299667 (9.300: -1.18%)
======================================================= (2.411 sec)
31.681... logprob:  0.581361, 0.256510 (1.436 sec)
31.682... logprob:  0.614750, 0.270833 (1.428 sec)
31.683... logprob:  0.672932, 0.296875 (1.427 sec)
31.684... logprob:  0.564550, 0.270833 (1.481 sec)
31.685... logprob:  0.527116, 0.240885 (1.438 sec)
31.686... logprob:  0.473837, 0.200521 (1.432 sec)
31.687... logprob:  0.544862, 0.239583 (1.477 sec)
31.688... logprob:  0.620743, 0.266927 (1.429 sec)
31.689... logprob:  0.670505, 0.281250 (1.422 sec)
31.690... logprob:  0.680674, 0.296875 (1.432 sec)
31.691... logprob:  0.670506, 0.286458 (1.424 sec)
31.692... logprob:  0.577436, 0.257812 (1.426 sec)
31.693... logprob:  0.625819, 0.274740 (1.485 sec)
31.694... logprob:  0.621804, 0.270833 (1.427 sec)
31.695... logprob:  0.613995, 0.285156 (1.449 sec)
31.696... logprob:  0.697324, 0.307292 (1.470 sec)
31.697... logprob:  0.741704, 0.291667 (1.427 sec)
31.698... logprob:  0.785628, 0.339844 (1.428 sec)
31.699... logprob:  0.652074, 0.303385 (1.428 sec)
31.700... logprob:  0.643391, 0.300781 (1.423 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.538412, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.322549e-03 [1.161550e-07] 
Layer 'conv1' biases: 2.180521e-06 [3.063427e-11] 
Layer 'conv2' weights[0]: 2.317912e-03 [1.159513e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.634850e-10] 
Layer 'conv3' weights[0]: 2.316850e-03 [1.160920e-07] 
Layer 'conv3' biases: 3.619475e-05 [5.587526e-09] 
Layer 'conv4' weights[0]: 2.326662e-03 [1.166021e-07] 
Layer 'conv4' biases: 9.998235e-01 [1.656427e-07] 
Layer 'conv5' weights[0]: 2.488464e-03 [2.631909e-06] 
Layer 'conv5' biases: 9.990278e-01 [2.891807e-06] 
Layer 'fc6' weights[0]: 6.680975e-03 [6.548305e-08] 
Layer 'fc6' biases: 9.999894e-01 [6.211299e-08] 
Layer 'fc7' weights[0]: 7.023534e-03 [1.584870e-07] 
Layer 'fc7' biases: 9.997061e-01 [2.399349e-07] 
Layer 'fc8' weights[0]: 4.835436e-03 [1.482078e-05] 
Layer 'fc8' biases: 2.623252e-02 [3.539132e-05] 
Train error last 800 batches: 0.654514
-------------------------------------------------------
Not saving because 0.538412 > 0.299667 (9.300: -1.18%)
======================================================= (2.349 sec)
31.701... logprob:  0.643625, 0.265625 (1.439 sec)
31.702... logprob:  0.781737, 0.373698 (1.480 sec)
31.703... logprob:  0.628075, 0.291667 (1.429 sec)
31.704... logprob:  0.561384, 0.240885 (1.444 sec)
31.705... logprob:  0.602748, 0.257812 (1.473 sec)
31.706... logprob:  0.797946, 0.348958 (1.432 sec)
31.707... logprob:  0.728939, 0.295573 (1.432 sec)
31.708... logprob:  0.616068, 0.269531 (1.426 sec)
31.709... logprob:  0.612168, 0.256510 (1.414 sec)
31.710... logprob:  0.808486, 0.342448 (1.434 sec)
31.711... logprob:  0.723085, 0.291667 (1.458 sec)
31.712... logprob:  0.625882, 0.256510 (1.442 sec)
31.713... logprob:  0.757963, 0.321615 (1.449 sec)
31.714... logprob:  0.686875, 0.296875 (1.450 sec)
31.715... logprob:  0.616394, 0.269531 (1.448 sec)
31.716... logprob:  0.525222, 0.250000 (1.435 sec)
31.717... logprob:  0.735934, 0.342448 (1.426 sec)
31.718... logprob:  0.717603, 0.324219 (1.420 sec)
31.719... logprob:  0.628079, 0.257812 (1.431 sec)
31.720... logprob:  0.667148, 0.299479 (1.445 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.439379, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.320228e-03 [1.160231e-07] 
Layer 'conv1' biases: 2.180652e-06 [4.260023e-11] 
Layer 'conv2' weights[0]: 2.315601e-03 [1.158165e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.582729e-10] 
Layer 'conv3' weights[0]: 2.314534e-03 [1.160121e-07] 
Layer 'conv3' biases: 3.621641e-05 [6.404308e-09] 
Layer 'conv4' weights[0]: 2.324345e-03 [1.164981e-07] 
Layer 'conv4' biases: 9.998217e-01 [2.082381e-07] 
Layer 'conv5' weights[0]: 2.485502e-03 [2.299469e-06] 
Layer 'conv5' biases: 9.990758e-01 [2.460361e-06] 
Layer 'fc6' weights[0]: 6.680255e-03 [6.114553e-08] 
Layer 'fc6' biases: 9.999897e-01 [5.560118e-08] 
Layer 'fc7' weights[0]: 7.022798e-03 [1.429184e-07] 
Layer 'fc7' biases: 9.997029e-01 [1.871608e-07] 
Layer 'fc8' weights[0]: 4.743154e-03 [1.299984e-05] 
Layer 'fc8' biases: 2.556136e-02 [3.170090e-05] 
Train error last 800 batches: 0.655214
-------------------------------------------------------
Not saving because 0.439379 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
31.721... logprob:  0.616867, 0.285156 (1.464 sec)
31.722... logprob:  0.690391, 0.296875 (1.480 sec)
31.723... logprob:  0.616587, 0.259114 (1.435 sec)
31.724... logprob:  0.640338, 0.269531 (1.468 sec)
31.725... logprob:  0.667284, 0.309896 (1.429 sec)
31.726... logprob:  0.574628, 0.247396 (1.421 sec)
31.727... logprob:  0.667772, 0.292969 (1.421 sec)
31.728... logprob:  0.626657, 0.273437 (1.436 sec)
31.729... logprob:  0.698499, 0.295573 (1.425 sec)
31.730... logprob:  0.708501, 0.315104 (1.474 sec)
31.731... logprob:  0.720036, 0.335937 (1.446 sec)
31.732... logprob:  0.542426, 0.231771 (1.433 sec)
31.733... logprob:  0.735137, 0.312500 (1.480 sec)
31.734... logprob:  0.670783, 0.287760 (1.426 sec)
31.735... logprob:  0.687601, 0.295573 (1.424 sec)
31.736... logprob:  0.779590, 0.325521 (1.431 sec)
31.737... logprob:  0.822820, 0.322917 (1.422 sec)
31.738... logprob:  0.657713, 0.261719 (1.429 sec)
31.739... logprob:  0.671107, 0.292969 (1.476 sec)
31.740... logprob:  0.577294, 0.278646 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.392741, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.317901e-03 [1.159322e-07] 
Layer 'conv1' biases: 2.180886e-06 [3.155192e-11] 
Layer 'conv2' weights[0]: 2.313280e-03 [1.157022e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.285749e-10] 
Layer 'conv3' weights[0]: 2.312232e-03 [1.158115e-07] 
Layer 'conv3' biases: 3.623010e-05 [4.859771e-09] 
Layer 'conv4' weights[0]: 2.322016e-03 [1.162944e-07] 
Layer 'conv4' biases: 9.998206e-01 [1.377464e-07] 
Layer 'conv5' weights[0]: 2.482673e-03 [2.172411e-06] 
Layer 'conv5' biases: 9.990721e-01 [2.282557e-06] 
Layer 'fc6' weights[0]: 6.679571e-03 [6.081939e-08] 
Layer 'fc6' biases: 9.999897e-01 [5.517716e-08] 
Layer 'fc7' weights[0]: 7.022114e-03 [1.417266e-07] 
Layer 'fc7' biases: 9.997033e-01 [1.719165e-07] 
Layer 'fc8' weights[0]: 4.763233e-03 [1.203731e-05] 
Layer 'fc8' biases: 2.573526e-02 [1.565426e-05] 
Train error last 800 batches: 0.654925
-------------------------------------------------------
Not saving because 0.392741 > 0.299667 (9.300: -1.18%)
======================================================= (2.348 sec)
31.741... logprob:  0.603449, 0.282552 (1.438 sec)
31.742... logprob:  0.678455, 0.273437 (1.476 sec)
31.743... logprob:  0.572388, 0.248698 (1.427 sec)
31.744... logprob:  0.731854, 0.273438 (1.423 sec)
31.745... logprob:  0.662550, 0.315104 (1.428 sec)
31.746... logprob:  0.765492, 0.338542 (1.429 sec)
31.747... logprob:  0.679013, 0.282552 (1.424 sec)
31.748... logprob:  0.641399, 0.295573 (1.479 sec)
31.749... logprob:  0.653100, 0.287760 (1.425 sec)
31.750... logprob:  0.664512, 0.279948 (1.441 sec)
31.751... logprob:  0.572790, 0.283854 (1.470 sec)
31.752... logprob:  0.744276, 0.312500 (1.429 sec)
31.753... logprob:  0.633996, 0.285156 (1.435 sec)
31.754... logprob:  0.616164, 0.286458 (1.425 sec)
31.755... logprob:  0.707542, 0.334635 (1.423 sec)
31.756... logprob:  0.636623, 0.290365 (1.488 sec)
31.757... logprob:  0.674158, 0.287760 (1.469 sec)
31.758... logprob:  0.569542, 0.252604 (1.443 sec)
31.759... logprob:  0.680255, 0.304688 (1.443 sec)
31.760... logprob:  0.651508, 0.276042 (1.455 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.468244, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.315589e-03 [1.158681e-07] 
Layer 'conv1' biases: 2.181103e-06 [3.574916e-11] 
Layer 'conv2' weights[0]: 2.310963e-03 [1.156247e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.286300e-10] 
Layer 'conv3' weights[0]: 2.309909e-03 [1.157175e-07] 
Layer 'conv3' biases: 3.624386e-05 [4.703388e-09] 
Layer 'conv4' weights[0]: 2.319710e-03 [1.163432e-07] 
Layer 'conv4' biases: 9.998185e-01 [1.477384e-07] 
Layer 'conv5' weights[0]: 2.479136e-03 [2.342888e-06] 
Layer 'conv5' biases: 9.990579e-01 [2.649378e-06] 
Layer 'fc6' weights[0]: 6.678861e-03 [6.288683e-08] 
Layer 'fc6' biases: 9.999894e-01 [5.782777e-08] 
Layer 'fc7' weights[0]: 7.021412e-03 [1.471001e-07] 
Layer 'fc7' biases: 9.997042e-01 [2.059964e-07] 
Layer 'fc8' weights[0]: 4.796648e-03 [1.337198e-05] 
Layer 'fc8' biases: 2.602386e-02 [3.733378e-05] 
Train error last 800 batches: 0.654982
-------------------------------------------------------
Not saving because 0.468244 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
31.761... logprob:  0.746583, 0.316406 (1.445 sec)
31.762... logprob:  0.673168, 0.286458 (1.435 sec)
31.763... logprob:  0.779797, 0.335937 (1.427 sec)
31.764... logprob:  0.702973, 0.309896 (1.422 sec)
31.765... logprob:  0.570630, 0.252604 (1.427 sec)
31.766... logprob:  0.643766, 0.304687 (1.452 sec)
31.767... logprob:  0.603851, 0.268229 (1.459 sec)
31.768... logprob:  0.620827, 0.282552 (1.455 sec)
31.769... logprob:  0.639517, 0.268229 (1.461 sec)
31.770... logprob:  0.595098, 0.261719 (1.475 sec)
31.771... logprob:  0.745312, 0.289062 (1.452 sec)
31.772... logprob:  0.646259, 0.311198 (1.436 sec)
31.773... logprob:  0.690603, 0.273437 (1.442 sec)
31.774... logprob:  0.707672, 0.325521 (1.451 sec)
31.775... logprob:  0.741618, 0.335937 (1.465 sec)
31.776... logprob:  0.622029, 0.286458 (1.474 sec)
31.777... logprob:  0.609041, 0.272135 (1.467 sec)
31.778... logprob:  0.593299, 0.277344 (1.453 sec)
31.779... logprob:  0.693080, 0.311198 (1.483 sec)
31.780... logprob:  0.566146, 0.223958 (1.448 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.494619, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.313264e-03 [1.157362e-07] 
Layer 'conv1' biases: 2.181264e-06 [3.629870e-11] 
Layer 'conv2' weights[0]: 2.308650e-03 [1.154942e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.746665e-10] 
Layer 'conv3' weights[0]: 2.307601e-03 [1.156391e-07] 
Layer 'conv3' biases: 3.623308e-05 [5.305813e-09] 
Layer 'conv4' weights[0]: 2.317382e-03 [1.163096e-07] 
Layer 'conv4' biases: 9.998198e-01 [1.657398e-07] 
Layer 'conv5' weights[0]: 2.477817e-03 [2.681556e-06] 
Layer 'conv5' biases: 9.990605e-01 [2.913620e-06] 
Layer 'fc6' weights[0]: 6.678177e-03 [5.850530e-08] 
Layer 'fc6' biases: 9.999896e-01 [5.226826e-08] 
Layer 'fc7' weights[0]: 7.020715e-03 [1.343357e-07] 
Layer 'fc7' biases: 9.997036e-01 [1.645032e-07] 
Layer 'fc8' weights[0]: 4.782970e-03 [1.095169e-05] 
Layer 'fc8' biases: 2.597902e-02 [1.475662e-05] 
Train error last 800 batches: 0.654709
-------------------------------------------------------
Not saving because 0.494619 > 0.299667 (9.300: -1.18%)
======================================================= (2.357 sec)
31.781... logprob:  0.602333, 0.279948 (1.443 sec)
31.782... logprob:  0.613926, 0.247396 (1.449 sec)
31.783... logprob:  0.728094, 0.325521 (1.451 sec)
31.784... logprob:  0.653089, 0.277344 (1.452 sec)
31.785... logprob:  0.756515, 0.347656 (1.474 sec)
31.786... logprob:  0.678257, 0.324219 (1.468 sec)
31.787... logprob:  0.761254, 0.360677 (1.452 sec)
31.788... logprob:  0.781264, 0.329427 (1.491 sec)
31.789... logprob:  0.476274, 0.212239 (1.444 sec)
31.790... logprob:  0.597099, 0.261719 (1.439 sec)
31.791... logprob:  0.623351, 0.268229 (1.447 sec)
31.792... logprob:  0.600916, 0.279948 (1.452 sec)
31.793... logprob:  0.599630, 0.260417 (1.444 sec)
31.794... logprob:  0.667667, 0.287760 (1.493 sec)
31.795... logprob:  0.661228, 0.317708 (1.459 sec)
31.796... logprob:  0.653595, 0.305990 (1.458 sec)
31.797... logprob:  0.566837, 0.248698 (1.491 sec)
31.798... logprob:  0.603910, 0.246094 (1.449 sec)
31.799... logprob:  0.554444, 0.251302 (1.467 sec)
31.800... logprob:  0.670199, 0.317708 (1.403 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.555424, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.310963e-03 [1.156558e-07] 
Layer 'conv1' biases: 2.181526e-06 [3.889760e-11] 
Layer 'conv2' weights[0]: 2.306353e-03 [1.153855e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.107117e-10] 
Layer 'conv3' weights[0]: 2.305304e-03 [1.155091e-07] 
Layer 'conv3' biases: 3.622373e-05 [4.719242e-09] 
Layer 'conv4' weights[0]: 2.315069e-03 [1.161300e-07] 
Layer 'conv4' biases: 9.998208e-01 [1.548919e-07] 
Layer 'conv5' weights[0]: 2.477378e-03 [2.778451e-06] 
Layer 'conv5' biases: 9.990444e-01 [3.055448e-06] 
Layer 'fc6' weights[0]: 6.677507e-03 [6.383889e-08] 
Layer 'fc6' biases: 9.999894e-01 [5.904608e-08] 
Layer 'fc7' weights[0]: 7.019991e-03 [1.518233e-07] 
Layer 'fc7' biases: 9.997045e-01 [2.347970e-07] 
Layer 'fc8' weights[0]: 4.811939e-03 [1.353286e-05] 
Layer 'fc8' biases: 2.619049e-02 [3.842414e-05] 
Train error last 800 batches: 0.654821
-------------------------------------------------------
Not saving because 0.555424 > 0.299667 (9.300: -1.18%)
======================================================= (2.401 sec)
32.1... logprob:  0.672819, 0.274740 (1.408 sec)
32.2... logprob:  0.733226, 0.315104 (1.457 sec)
32.3... logprob:  0.657392, 0.287760 (1.414 sec)
32.4... logprob:  0.700315, 0.308594 (1.397 sec)
32.5... logprob:  0.664415, 0.266927 (1.429 sec)
32.6... logprob:  0.768367, 0.348958 (1.389 sec)
32.7... logprob:  0.598458, 0.276042 (1.419 sec)
32.8... logprob:  0.563698, 0.278646 (1.390 sec)
32.9... logprob:  0.651890, 0.296875 (1.395 sec)
32.10... logprob:  0.618116, 0.302083 (1.401 sec)
32.11... logprob:  0.606030, 0.251302 (1.444 sec)
32.12... logprob:  0.684000, 0.304687 (1.395 sec)
32.13... logprob:  0.617344, 0.281250 (1.416 sec)
32.14... logprob:  0.691549, 0.296875 (1.397 sec)
32.15... logprob:  0.662484, 0.295573 (1.404 sec)
32.16... logprob:  0.720898, 0.303385 (1.405 sec)
32.17... logprob:  0.746696, 0.298177 (1.396 sec)
32.18... logprob:  0.559868, 0.264323 (1.392 sec)
32.19... logprob:  0.508251, 0.261719 (1.394 sec)
32.20... logprob:  0.614277, 0.257812 (1.405 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.433258, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.308644e-03 [1.155069e-07] 
Layer 'conv1' biases: 2.181577e-06 [2.375347e-11] 
Layer 'conv2' weights[0]: 2.304035e-03 [1.152620e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.169514e-10] 
Layer 'conv3' weights[0]: 2.302997e-03 [1.152681e-07] 
Layer 'conv3' biases: 3.621900e-05 [3.175285e-09] 
Layer 'conv4' weights[0]: 2.312746e-03 [1.157914e-07] 
Layer 'conv4' biases: 9.998214e-01 [1.165761e-07] 
Layer 'conv5' weights[0]: 2.475582e-03 [1.947235e-06] 
Layer 'conv5' biases: 9.990440e-01 [2.131479e-06] 
Layer 'fc6' weights[0]: 6.676789e-03 [5.750549e-08] 
Layer 'fc6' biases: 9.999894e-01 [5.105244e-08] 
Layer 'fc7' weights[0]: 7.019258e-03 [1.336215e-07] 
Layer 'fc7' biases: 9.997044e-01 [1.644483e-07] 
Layer 'fc8' weights[0]: 4.812401e-03 [1.113892e-05] 
Layer 'fc8' biases: 2.624974e-02 [1.609310e-05] 
Train error last 800 batches: 0.655628
-------------------------------------------------------
Not saving because 0.433258 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
32.21... logprob:  0.649658, 0.253906 (1.406 sec)
32.22... logprob:  0.761047, 0.298177 (1.421 sec)
32.23... logprob:  0.706131, 0.332031 (1.407 sec)
32.24... logprob:  0.685158, 0.316406 (1.415 sec)
32.25... logprob:  0.606921, 0.277344 (1.398 sec)
32.26... logprob:  0.654684, 0.277344 (1.439 sec)
32.27... logprob:  0.538309, 0.243489 (1.386 sec)
32.28... logprob:  0.712868, 0.273438 (1.413 sec)
32.29... logprob:  0.689876, 0.300781 (1.412 sec)
32.30... logprob:  0.570244, 0.278646 (1.413 sec)
32.31... logprob:  0.707564, 0.308594 (1.403 sec)
32.32... logprob:  0.659764, 0.278646 (1.385 sec)
32.33... logprob:  0.681245, 0.289062 (1.437 sec)
32.34... logprob:  0.693030, 0.289062 (1.387 sec)
32.35... logprob:  0.509450, 0.233073 (1.392 sec)
32.36... logprob:  0.750305, 0.303385 (1.392 sec)
32.37... logprob:  0.672668, 0.290365 (1.402 sec)
32.38... logprob:  0.682108, 0.326823 (1.419 sec)
32.39... logprob:  0.840552, 0.347656 (1.426 sec)
32.40... logprob:  0.652167, 0.295573 (1.406 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.519457, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.306339e-03 [1.153298e-07] 
Layer 'conv1' biases: 2.181702e-06 [4.300436e-11] 
Layer 'conv2' weights[0]: 2.301734e-03 [1.151134e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.607764e-10] 
Layer 'conv3' weights[0]: 2.300691e-03 [1.153546e-07] 
Layer 'conv3' biases: 3.624169e-05 [6.566591e-09] 
Layer 'conv4' weights[0]: 2.310436e-03 [1.159790e-07] 
Layer 'conv4' biases: 9.998213e-01 [2.064671e-07] 
Layer 'conv5' weights[0]: 2.473517e-03 [3.120056e-06] 
Layer 'conv5' biases: 9.990679e-01 [3.481970e-06] 
Layer 'fc6' weights[0]: 6.676091e-03 [7.026198e-08] 
Layer 'fc6' biases: 9.999896e-01 [6.734264e-08] 
Layer 'fc7' weights[0]: 7.018592e-03 [1.695079e-07] 
Layer 'fc7' biases: 9.997028e-01 [2.669949e-07] 
Layer 'fc8' weights[0]: 4.761319e-03 [1.544393e-05] 
Layer 'fc8' biases: 2.588696e-02 [3.975846e-05] 
Train error last 800 batches: 0.655708
-------------------------------------------------------
Not saving because 0.519457 > 0.299667 (9.300: -1.18%)
======================================================= (2.374 sec)
32.41... logprob:  0.632312, 0.308594 (1.432 sec)
32.42... logprob:  0.603497, 0.257812 (1.417 sec)
32.43... logprob:  0.693856, 0.281250 (1.406 sec)
32.44... logprob:  0.777529, 0.325521 (1.430 sec)
32.45... logprob:  0.646001, 0.298177 (1.382 sec)
32.46... logprob:  0.703001, 0.319010 (1.393 sec)
32.47... logprob:  0.565742, 0.286458 (1.386 sec)
32.48... logprob:  0.640117, 0.272135 (1.419 sec)
32.49... logprob:  0.724688, 0.326823 (1.405 sec)
32.50... logprob:  0.565297, 0.256510 (1.421 sec)
32.51... logprob:  0.750666, 0.294271 (1.406 sec)
32.52... logprob:  0.725936, 0.332031 (1.394 sec)
32.53... logprob:  0.559806, 0.252604 (1.438 sec)
32.54... logprob:  0.644777, 0.282552 (1.380 sec)
32.55... logprob:  0.523238, 0.243490 (1.391 sec)
32.56... logprob:  0.613157, 0.289062 (1.398 sec)
32.57... logprob:  0.764126, 0.326823 (1.422 sec)
32.58... logprob:  0.619117, 0.276042 (1.397 sec)
32.59... logprob:  0.556212, 0.244792 (1.457 sec)
32.60... logprob:  0.821686, 0.356771 (1.422 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.495690, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.304037e-03 [1.152894e-07] 
Layer 'conv1' biases: 2.181856e-06 [3.374928e-11] 
Layer 'conv2' weights[0]: 2.299436e-03 [1.150376e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.391268e-10] 
Layer 'conv3' weights[0]: 2.298382e-03 [1.150854e-07] 
Layer 'conv3' biases: 3.626045e-05 [4.058775e-09] 
Layer 'conv4' weights[0]: 2.308133e-03 [1.157408e-07] 
Layer 'conv4' biases: 9.998228e-01 [1.486287e-07] 
Layer 'conv5' weights[0]: 2.472504e-03 [2.754705e-06] 
Layer 'conv5' biases: 9.990626e-01 [3.020789e-06] 
Layer 'fc6' weights[0]: 6.675422e-03 [6.168652e-08] 
Layer 'fc6' biases: 9.999897e-01 [5.592627e-08] 
Layer 'fc7' weights[0]: 7.017903e-03 [1.462869e-07] 
Layer 'fc7' biases: 9.997028e-01 [1.987617e-07] 
Layer 'fc8' weights[0]: 4.758243e-03 [1.241863e-05] 
Layer 'fc8' biases: 2.584031e-02 [2.781738e-05] 
Train error last 800 batches: 0.655831
-------------------------------------------------------
Not saving because 0.495690 > 0.299667 (9.300: -1.18%)
======================================================= (2.396 sec)
32.61... logprob:  0.648022, 0.302083 (1.435 sec)
32.62... logprob:  0.631562, 0.268229 (1.456 sec)
32.63... logprob:  0.680207, 0.277344 (1.437 sec)
32.64... logprob:  0.752440, 0.341146 (1.407 sec)
32.65... logprob:  0.605650, 0.265625 (1.392 sec)
32.66... logprob:  0.624949, 0.260417 (1.441 sec)
32.67... logprob:  0.584718, 0.261719 (1.381 sec)
32.68... logprob:  0.599242, 0.278646 (1.393 sec)
32.69... logprob:  0.807264, 0.352865 (1.416 sec)
32.70... logprob:  0.541562, 0.255208 (1.428 sec)
32.71... logprob:  0.595612, 0.265625 (1.454 sec)
32.72... logprob:  0.720686, 0.307292 (1.395 sec)
32.73... logprob:  0.600801, 0.252604 (1.428 sec)
32.74... logprob:  0.748572, 0.290365 (1.409 sec)
32.75... logprob:  0.672284, 0.265625 (1.409 sec)
32.76... logprob:  0.640304, 0.265625 (1.428 sec)
32.77... logprob:  0.590641, 0.277344 (1.447 sec)
32.78... logprob:  0.713313, 0.315104 (1.448 sec)
32.79... logprob:  0.613353, 0.289062 (1.393 sec)
32.80... logprob:  0.578191, 0.255208 (1.414 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.515057, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.301731e-03 [1.151602e-07] 
Layer 'conv1' biases: 2.181986e-06 [3.391954e-11] 
Layer 'conv2' weights[0]: 2.297142e-03 [1.149253e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.220171e-10] 
Layer 'conv3' weights[0]: 2.296074e-03 [1.150620e-07] 
Layer 'conv3' biases: 3.624921e-05 [5.390533e-09] 
Layer 'conv4' weights[0]: 2.305820e-03 [1.157131e-07] 
Layer 'conv4' biases: 9.998219e-01 [1.758082e-07] 
Layer 'conv5' weights[0]: 2.470056e-03 [2.511530e-06] 
Layer 'conv5' biases: 9.990512e-01 [2.701215e-06] 
Layer 'fc6' weights[0]: 6.674738e-03 [5.897222e-08] 
Layer 'fc6' biases: 9.999897e-01 [5.294164e-08] 
Layer 'fc7' weights[0]: 7.017167e-03 [1.357189e-07] 
Layer 'fc7' biases: 9.997029e-01 [1.659492e-07] 
Layer 'fc8' weights[0]: 4.788560e-03 [1.091328e-05] 
Layer 'fc8' biases: 2.613277e-02 [1.462740e-05] 
Train error last 800 batches: 0.655927
-------------------------------------------------------
Not saving because 0.515057 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
32.81... logprob:  0.604996, 0.269531 (1.420 sec)
32.82... logprob:  0.493077, 0.210938 (1.426 sec)
32.83... logprob:  0.731602, 0.348958 (1.397 sec)
32.84... logprob:  0.618468, 0.298177 (1.462 sec)
32.85... logprob:  0.675561, 0.317708 (1.417 sec)
32.86... logprob:  0.663467, 0.303385 (1.414 sec)
32.87... logprob:  0.841410, 0.358073 (1.407 sec)
32.88... logprob:  0.688162, 0.277344 (1.402 sec)
32.89... logprob:  0.648112, 0.291667 (1.429 sec)
32.90... logprob:  0.755789, 0.315104 (1.381 sec)
32.91... logprob:  0.631968, 0.278646 (1.393 sec)
32.92... logprob:  0.722532, 0.307292 (1.395 sec)
32.93... logprob:  0.765320, 0.319010 (1.391 sec)
32.94... logprob:  0.612525, 0.283854 (1.389 sec)
32.95... logprob:  0.660494, 0.261719 (1.396 sec)
32.96... logprob:  0.762645, 0.330729 (1.405 sec)
32.97... logprob:  0.697379, 0.312500 (1.389 sec)
32.98... logprob:  0.588736, 0.260417 (1.430 sec)
32.99... logprob:  0.766825, 0.324219 (1.411 sec)
32.100... logprob:  0.528741, 0.229167 (1.391 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.513036, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.299439e-03 [1.150054e-07] 
Layer 'conv1' biases: 2.182080e-06 [4.200951e-11] 
Layer 'conv2' weights[0]: 2.294831e-03 [1.147860e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.803311e-10] 
Layer 'conv3' weights[0]: 2.293769e-03 [1.149705e-07] 
Layer 'conv3' biases: 3.625120e-05 [5.490630e-09] 
Layer 'conv4' weights[0]: 2.303515e-03 [1.155549e-07] 
Layer 'conv4' biases: 9.998217e-01 [1.903712e-07] 
Layer 'conv5' weights[0]: 2.467967e-03 [2.655947e-06] 
Layer 'conv5' biases: 9.990594e-01 [2.855630e-06] 
Layer 'fc6' weights[0]: 6.674036e-03 [6.280506e-08] 
Layer 'fc6' biases: 9.999898e-01 [5.809781e-08] 
Layer 'fc7' weights[0]: 7.016474e-03 [1.465733e-07] 
Layer 'fc7' biases: 9.997022e-01 [2.003569e-07] 
Layer 'fc8' weights[0]: 4.757570e-03 [1.223645e-05] 
Layer 'fc8' biases: 2.593853e-02 [2.551980e-05] 
Train error last 800 batches: 0.656362
-------------------------------------------------------
Not saving because 0.513036 > 0.299667 (9.300: -1.18%)
======================================================= (2.369 sec)
32.101... logprob:  0.502622, 0.209635 (1.448 sec)
32.102... logprob:  0.781447, 0.312500 (1.388 sec)
32.103... logprob:  0.775595, 0.321615 (1.393 sec)
32.104... logprob:  0.627286, 0.291667 (1.393 sec)
32.105... logprob:  0.817486, 0.347656 (1.386 sec)
32.106... logprob:  0.589572, 0.243490 (1.392 sec)
32.107... logprob:  0.508389, 0.212240 (1.443 sec)
32.108... logprob:  0.691088, 0.294271 (1.394 sec)
32.109... logprob:  0.638836, 0.283854 (1.399 sec)
32.110... logprob:  0.609156, 0.279948 (1.393 sec)
32.111... logprob:  0.647894, 0.264323 (1.389 sec)
32.112... logprob:  0.583461, 0.289062 (1.393 sec)
32.113... logprob:  0.571640, 0.231771 (1.396 sec)
32.114... logprob:  0.633287, 0.263021 (1.429 sec)
32.115... logprob:  0.684959, 0.289062 (1.404 sec)
32.116... logprob:  0.604796, 0.266927 (1.414 sec)
32.117... logprob:  0.628596, 0.303385 (1.445 sec)
32.118... logprob:  0.607831, 0.256510 (1.394 sec)
32.119... logprob:  0.589088, 0.279948 (1.396 sec)
32.120... logprob:  0.739336, 0.326823 (1.390 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.491171, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.297132e-03 [1.149071e-07] 
Layer 'conv1' biases: 2.182289e-06 [4.698061e-11] 
Layer 'conv2' weights[0]: 2.292539e-03 [1.147005e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.795978e-10] 
Layer 'conv3' weights[0]: 2.291492e-03 [1.149403e-07] 
Layer 'conv3' biases: 3.623954e-05 [6.383084e-09] 
Layer 'conv4' weights[0]: 2.301203e-03 [1.156273e-07] 
Layer 'conv4' biases: 9.998197e-01 [1.904462e-07] 
Layer 'conv5' weights[0]: 2.464137e-03 [3.213641e-06] 
Layer 'conv5' biases: 9.990427e-01 [3.568506e-06] 
Layer 'fc6' weights[0]: 6.673312e-03 [6.870329e-08] 
Layer 'fc6' biases: 9.999898e-01 [6.527623e-08] 
Layer 'fc7' weights[0]: 7.015784e-03 [1.648709e-07] 
Layer 'fc7' biases: 9.997030e-01 [2.641549e-07] 
Layer 'fc8' weights[0]: 4.785783e-03 [1.546084e-05] 
Layer 'fc8' biases: 2.616578e-02 [3.776916e-05] 
Train error last 800 batches: 0.656220
-------------------------------------------------------
Not saving because 0.491171 > 0.299667 (9.300: -1.18%)
======================================================= (2.354 sec)
32.121... logprob:  0.694833, 0.274740 (1.392 sec)
32.122... logprob:  0.700652, 0.292969 (1.440 sec)
32.123... logprob:  0.712317, 0.287760 (1.388 sec)
32.124... logprob:  0.699866, 0.329427 (1.401 sec)
32.125... logprob:  0.724419, 0.312500 (1.391 sec)
32.126... logprob:  0.835677, 0.355469 (1.386 sec)
32.127... logprob:  0.624645, 0.286458 (1.391 sec)
32.128... logprob:  0.572340, 0.260417 (1.410 sec)
32.129... logprob:  0.681976, 0.299479 (1.411 sec)
32.130... logprob:  0.574567, 0.248698 (1.411 sec)
32.131... logprob:  0.753279, 0.305990 (1.402 sec)
32.132... logprob:  0.810333, 0.321615 (1.430 sec)
32.133... logprob:  0.652074, 0.279948 (1.381 sec)
32.134... logprob:  0.644117, 0.286458 (1.392 sec)
32.135... logprob:  0.680716, 0.304687 (1.393 sec)
32.136... logprob:  0.753886, 0.332031 (1.389 sec)
32.137... logprob:  0.636213, 0.304687 (1.385 sec)
32.138... logprob:  0.628367, 0.308594 (1.436 sec)
32.139... logprob:  0.624205, 0.277344 (1.389 sec)
32.140... logprob:  0.713308, 0.299479 (1.407 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.417411, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.294835e-03 [1.147800e-07] 
Layer 'conv1' biases: 2.182479e-06 [4.418902e-11] 
Layer 'conv2' weights[0]: 2.290247e-03 [1.145395e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.040951e-10] 
Layer 'conv3' weights[0]: 2.289205e-03 [1.147591e-07] 
Layer 'conv3' biases: 3.624355e-05 [6.431307e-09] 
Layer 'conv4' weights[0]: 2.298906e-03 [1.153907e-07] 
Layer 'conv4' biases: 9.998198e-01 [2.264312e-07] 
Layer 'conv5' weights[0]: 2.462299e-03 [2.502327e-06] 
Layer 'conv5' biases: 9.990684e-01 [2.796206e-06] 
Layer 'fc6' weights[0]: 6.672651e-03 [6.080352e-08] 
Layer 'fc6' biases: 9.999899e-01 [5.513896e-08] 
Layer 'fc7' weights[0]: 7.015089e-03 [1.432368e-07] 
Layer 'fc7' biases: 9.997014e-01 [1.864834e-07] 
Layer 'fc8' weights[0]: 4.744218e-03 [1.166995e-05] 
Layer 'fc8' biases: 2.585231e-02 [1.915444e-05] 
Train error last 800 batches: 0.656328
-------------------------------------------------------
Not saving because 0.417411 > 0.299667 (9.300: -1.18%)
======================================================= (2.352 sec)
32.141... logprob:  0.683616, 0.304688 (1.438 sec)
32.142... logprob:  0.695831, 0.308594 (1.395 sec)
32.143... logprob:  0.531545, 0.244792 (1.420 sec)
32.144... logprob:  0.669835, 0.277344 (1.410 sec)
32.145... logprob:  0.575054, 0.243490 (1.411 sec)
32.146... logprob:  0.679488, 0.285156 (1.402 sec)
32.147... logprob:  0.547183, 0.240885 (1.423 sec)
32.148... logprob:  0.643251, 0.260417 (1.389 sec)
32.149... logprob:  0.719379, 0.274740 (1.403 sec)
32.150... logprob:  0.576583, 0.270833 (1.394 sec)
32.151... logprob:  0.582001, 0.255208 (1.390 sec)
32.152... logprob:  0.874550, 0.361979 (1.383 sec)
32.153... logprob:  0.588481, 0.253906 (1.442 sec)
32.154... logprob:  0.705228, 0.299479 (1.396 sec)
32.155... logprob:  0.577269, 0.250000 (1.437 sec)
32.156... logprob:  0.628965, 0.283854 (1.431 sec)
32.157... logprob:  0.542186, 0.250000 (1.392 sec)
32.158... logprob:  0.699473, 0.303385 (1.397 sec)
32.159... logprob:  0.718961, 0.328125 (1.388 sec)
32.160... logprob:  0.658431, 0.272135 (1.391 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.441486, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.292538e-03 [1.146837e-07] 
Layer 'conv1' biases: 2.182789e-06 [2.746111e-11] 
Layer 'conv2' weights[0]: 2.287952e-03 [1.144430e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.246366e-10] 
Layer 'conv3' weights[0]: 2.286928e-03 [1.144588e-07] 
Layer 'conv3' biases: 3.624780e-05 [3.251931e-09] 
Layer 'conv4' weights[0]: 2.296605e-03 [1.150413e-07] 
Layer 'conv4' biases: 9.998206e-01 [1.212951e-07] 
Layer 'conv5' weights[0]: 2.460574e-03 [2.171868e-06] 
Layer 'conv5' biases: 9.990644e-01 [2.319613e-06] 
Layer 'fc6' weights[0]: 6.671976e-03 [5.965879e-08] 
Layer 'fc6' biases: 9.999897e-01 [5.354674e-08] 
Layer 'fc7' weights[0]: 7.014358e-03 [1.388756e-07] 
Layer 'fc7' biases: 9.997022e-01 [1.667093e-07] 
Layer 'fc8' weights[0]: 4.761383e-03 [1.105637e-05] 
Layer 'fc8' biases: 2.599821e-02 [1.273059e-05] 
Train error last 800 batches: 0.656158
-------------------------------------------------------
Not saving because 0.441486 > 0.299667 (9.300: -1.18%)
======================================================= (2.362 sec)
32.161... logprob:  0.528090, 0.231771 (1.406 sec)
32.162... logprob:  0.867764, 0.381510 (1.398 sec)
32.163... logprob:  0.659933, 0.291667 (1.417 sec)
32.164... logprob:  0.702664, 0.308594 (1.421 sec)
32.165... logprob:  0.796630, 0.351562 (1.410 sec)
32.166... logprob:  0.621896, 0.294271 (1.445 sec)
32.167... logprob:  0.538560, 0.240885 (1.424 sec)
32.168... logprob:  0.599858, 0.270833 (1.417 sec)
32.169... logprob:  0.655757, 0.296875 (1.464 sec)
32.170... logprob:  0.719627, 0.287760 (1.392 sec)
32.171... logprob:  0.751047, 0.335937 (1.416 sec)
32.172... logprob:  0.639740, 0.265625 (1.408 sec)
32.173... logprob:  0.707710, 0.294271 (1.416 sec)
32.174... logprob:  0.635567, 0.264323 (1.395 sec)
32.175... logprob:  0.720275, 0.295573 (1.459 sec)
32.176... logprob:  0.783571, 0.345052 (1.413 sec)
32.177... logprob:  0.582181, 0.264323 (1.421 sec)
32.178... logprob:  0.623372, 0.294271 (1.451 sec)
32.179... logprob:  0.654809, 0.295573 (1.401 sec)
32.180... logprob:  0.761097, 0.354167 (1.414 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.414422, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.290241e-03 [1.145485e-07] 
Layer 'conv1' biases: 2.182942e-06 [3.580863e-11] 
Layer 'conv2' weights[0]: 2.285680e-03 [1.143347e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.012777e-10] 
Layer 'conv3' weights[0]: 2.284625e-03 [1.143950e-07] 
Layer 'conv3' biases: 3.624743e-05 [4.035855e-09] 
Layer 'conv4' weights[0]: 2.294311e-03 [1.150082e-07] 
Layer 'conv4' biases: 9.998215e-01 [1.469939e-07] 
Layer 'conv5' weights[0]: 2.459835e-03 [2.201096e-06] 
Layer 'conv5' biases: 9.990606e-01 [2.319360e-06] 
Layer 'fc6' weights[0]: 6.671312e-03 [6.185683e-08] 
Layer 'fc6' biases: 9.999897e-01 [5.648117e-08] 
Layer 'fc7' weights[0]: 7.013664e-03 [1.423499e-07] 
Layer 'fc7' biases: 9.997020e-01 [1.845878e-07] 
Layer 'fc8' weights[0]: 4.758590e-03 [1.242026e-05] 
Layer 'fc8' biases: 2.600468e-02 [2.695346e-05] 
Train error last 800 batches: 0.656293
-------------------------------------------------------
Not saving because 0.414422 > 0.299667 (9.300: -1.18%)
======================================================= (2.400 sec)
32.181... logprob:  0.794510, 0.341146 (1.419 sec)
32.182... logprob:  0.579458, 0.272135 (1.419 sec)
32.183... logprob:  0.558273, 0.244792 (1.413 sec)
32.184... logprob:  0.756222, 0.319010 (1.412 sec)
32.185... logprob:  0.590161, 0.279948 (1.393 sec)
32.186... logprob:  0.690161, 0.322917 (1.388 sec)
32.187... logprob:  0.712877, 0.299479 (1.399 sec)
32.188... logprob:  0.702861, 0.322917 (1.394 sec)
32.189... logprob:  0.642506, 0.252604 (1.383 sec)
32.190... logprob:  0.612901, 0.257812 (1.431 sec)
32.191... logprob:  0.663769, 0.282552 (1.399 sec)
32.192... logprob:  0.631417, 0.256510 (1.410 sec)
32.193... logprob:  0.569407, 0.236979 (1.414 sec)
32.194... logprob:  0.587428, 0.266927 (1.442 sec)
32.195... logprob:  0.602458, 0.259115 (1.390 sec)
32.196... logprob:  0.655178, 0.299479 (1.387 sec)
32.197... logprob:  0.733467, 0.319010 (1.396 sec)
32.198... logprob:  0.612870, 0.276042 (1.403 sec)
32.199... logprob:  0.633610, 0.299479 (1.390 sec)
32.200... logprob:  0.712444, 0.319010 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.504585, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.287959e-03 [1.144375e-07] 
Layer 'conv1' biases: 2.183085e-06 [4.413483e-11] 
Layer 'conv2' weights[0]: 2.283383e-03 [1.142357e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.485529e-10] 
Layer 'conv3' weights[0]: 2.282336e-03 [1.144963e-07] 
Layer 'conv3' biases: 3.622737e-05 [6.661205e-09] 
Layer 'conv4' weights[0]: 2.292028e-03 [1.152440e-07] 
Layer 'conv4' biases: 9.998210e-01 [2.024130e-07] 
Layer 'conv5' weights[0]: 2.457399e-03 [2.214161e-06] 
Layer 'conv5' biases: 9.990563e-01 [2.403875e-06] 
Layer 'fc6' weights[0]: 6.670589e-03 [6.043762e-08] 
Layer 'fc6' biases: 9.999898e-01 [5.459497e-08] 
Layer 'fc7' weights[0]: 7.012941e-03 [1.437829e-07] 
Layer 'fc7' biases: 9.997010e-01 [1.978345e-07] 
Layer 'fc8' weights[0]: 4.757618e-03 [1.346634e-05] 
Layer 'fc8' biases: 2.599773e-02 [2.744792e-05] 
Train error last 800 batches: 0.656078
-------------------------------------------------------
Not saving because 0.504585 > 0.299667 (9.300: -1.18%)
======================================================= (2.369 sec)
32.201... logprob:  0.675108, 0.308594 (1.410 sec)
32.202... logprob:  0.660719, 0.294271 (1.403 sec)
32.203... logprob:  0.604810, 0.274740 (1.441 sec)
32.204... logprob:  0.782181, 0.308594 (1.381 sec)
32.205... logprob:  0.526274, 0.242188 (1.398 sec)
32.206... logprob:  0.656182, 0.296875 (1.401 sec)
32.207... logprob:  0.551157, 0.253906 (1.383 sec)
32.208... logprob:  0.666330, 0.305990 (1.397 sec)
32.209... logprob:  0.608999, 0.287760 (1.419 sec)
32.210... logprob:  0.739442, 0.312500 (1.414 sec)
32.211... logprob:  0.652903, 0.294271 (1.407 sec)
32.212... logprob:  0.693326, 0.309896 (1.404 sec)
32.213... logprob:  0.727037, 0.303385 (1.450 sec)
32.214... logprob:  0.639585, 0.276042 (1.422 sec)
32.215... logprob:  0.679082, 0.303385 (1.412 sec)
32.216... logprob:  0.742973, 0.316406 (1.467 sec)
32.217... logprob:  0.626182, 0.272135 (1.396 sec)
32.218... logprob:  0.661388, 0.287760 (1.417 sec)
32.219... logprob:  0.627248, 0.278646 (1.405 sec)
32.220... logprob:  0.646556, 0.317708 (1.417 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.476457, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.285678e-03 [1.143233e-07] 
Layer 'conv1' biases: 2.183351e-06 [3.160139e-11] 
Layer 'conv2' weights[0]: 2.281104e-03 [1.141097e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.348933e-10] 
Layer 'conv3' weights[0]: 2.280063e-03 [1.141995e-07] 
Layer 'conv3' biases: 3.622139e-05 [4.480746e-09] 
Layer 'conv4' weights[0]: 2.289722e-03 [1.148199e-07] 
Layer 'conv4' biases: 9.998191e-01 [1.574824e-07] 
Layer 'conv5' weights[0]: 2.453495e-03 [1.823405e-06] 
Layer 'conv5' biases: 9.990531e-01 [1.926132e-06] 
Layer 'fc6' weights[0]: 6.669929e-03 [5.895696e-08] 
Layer 'fc6' biases: 9.999896e-01 [5.283978e-08] 
Layer 'fc7' weights[0]: 7.012234e-03 [1.406868e-07] 
Layer 'fc7' biases: 9.997010e-01 [1.867838e-07] 
Layer 'fc8' weights[0]: 4.759118e-03 [1.309206e-05] 
Layer 'fc8' biases: 2.607652e-02 [3.028079e-05] 
Train error last 800 batches: 0.655786
-------------------------------------------------------
Not saving because 0.476457 > 0.299667 (9.300: -1.18%)
======================================================= (2.378 sec)
32.221... logprob:  0.688960, 0.285156 (1.410 sec)
32.222... logprob:  0.864528, 0.345052 (1.456 sec)
32.223... logprob:  0.730121, 0.299479 (1.426 sec)
32.224... logprob:  0.607185, 0.285156 (1.428 sec)
32.225... logprob:  0.584355, 0.246094 (1.438 sec)
32.226... logprob:  0.663035, 0.276042 (1.418 sec)
32.227... logprob:  0.646710, 0.270833 (1.406 sec)
32.228... logprob:  0.630268, 0.282552 (1.411 sec)
32.229... logprob:  0.679062, 0.295573 (1.406 sec)
32.230... logprob:  0.689524, 0.304688 (1.425 sec)
32.231... logprob:  0.660534, 0.291667 (1.398 sec)
32.232... logprob:  0.727647, 0.315104 (1.454 sec)
32.233... logprob:  0.687814, 0.290365 (1.444 sec)
32.234... logprob:  0.706782, 0.317708 (1.409 sec)
32.235... logprob:  0.675676, 0.312500 (1.462 sec)
32.236... logprob:  0.712553, 0.283854 (1.395 sec)
32.237... logprob:  0.565136, 0.230469 (1.417 sec)
32.238... logprob:  0.591615, 0.279948 (1.407 sec)
32.239... logprob:  0.676093, 0.294271 (1.415 sec)
32.240... logprob:  0.736251, 0.299479 (1.392 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.557022, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.283393e-03 [1.141930e-07] 
Layer 'conv1' biases: 2.183534e-06 [4.173694e-11] 
Layer 'conv2' weights[0]: 2.278821e-03 [1.139849e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.020891e-10] 
Layer 'conv3' weights[0]: 2.277783e-03 [1.142385e-07] 
Layer 'conv3' biases: 3.621930e-05 [5.936370e-09] 
Layer 'conv4' weights[0]: 2.287431e-03 [1.148534e-07] 
Layer 'conv4' biases: 9.998181e-01 [1.974128e-07] 
Layer 'conv5' weights[0]: 2.450726e-03 [2.390124e-06] 
Layer 'conv5' biases: 9.990624e-01 [2.587358e-06] 
Layer 'fc6' weights[0]: 6.669223e-03 [6.040864e-08] 
Layer 'fc6' biases: 9.999899e-01 [5.454164e-08] 
Layer 'fc7' weights[0]: 7.011530e-03 [1.447866e-07] 
Layer 'fc7' biases: 9.996999e-01 [1.894425e-07] 
Layer 'fc8' weights[0]: 4.741894e-03 [1.237704e-05] 
Layer 'fc8' biases: 2.591636e-02 [2.368423e-05] 
Train error last 800 batches: 0.655726
-------------------------------------------------------
Not saving because 0.557022 > 0.299667 (9.300: -1.18%)
======================================================= (2.401 sec)
32.241... logprob:  0.587650, 0.268229 (1.461 sec)
32.242... logprob:  0.599068, 0.248698 (1.428 sec)
32.243... logprob:  0.528417, 0.234375 (1.431 sec)
32.244... logprob:  0.518492, 0.210937 (1.439 sec)
32.245... logprob:  0.827255, 0.333333 (1.416 sec)
32.246... logprob:  0.740531, 0.330729 (1.410 sec)
32.247... logprob:  0.639725, 0.270833 (1.407 sec)
32.248... logprob:  0.608929, 0.264323 (1.409 sec)
32.249... logprob:  0.749926, 0.325521 (1.418 sec)
32.250... logprob:  0.804618, 0.321615 (1.399 sec)
32.251... logprob:  0.626092, 0.260417 (1.454 sec)
32.252... logprob:  0.524491, 0.238281 (1.424 sec)
32.253... logprob:  0.612018, 0.269531 (1.412 sec)
32.254... logprob:  0.564933, 0.230469 (1.468 sec)
32.255... logprob:  0.577950, 0.257812 (1.392 sec)
32.256... logprob:  0.637216, 0.279948 (1.417 sec)
32.257... logprob:  0.653874, 0.287760 (1.412 sec)
32.258... logprob:  0.616824, 0.291667 (1.412 sec)
32.259... logprob:  0.618336, 0.282552 (1.395 sec)
32.260... logprob:  0.667520, 0.325521 (1.451 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.414073, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.281096e-03 [1.141111e-07] 
Layer 'conv1' biases: 2.183688e-06 [3.985026e-11] 
Layer 'conv2' weights[0]: 2.276544e-03 [1.138933e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.032242e-10] 
Layer 'conv3' weights[0]: 2.275518e-03 [1.140053e-07] 
Layer 'conv3' biases: 3.619330e-05 [5.278203e-09] 
Layer 'conv4' weights[0]: 2.285143e-03 [1.147083e-07] 
Layer 'conv4' biases: 9.998183e-01 [1.804473e-07] 
Layer 'conv5' weights[0]: 2.449242e-03 [3.281035e-06] 
Layer 'conv5' biases: 9.990208e-01 [3.626648e-06] 
Layer 'fc6' weights[0]: 6.668503e-03 [6.534014e-08] 
Layer 'fc6' biases: 9.999897e-01 [6.146946e-08] 
Layer 'fc7' weights[0]: 7.010810e-03 [1.586215e-07] 
Layer 'fc7' biases: 9.997021e-01 [2.521300e-07] 
Layer 'fc8' weights[0]: 4.818034e-03 [1.445359e-05] 
Layer 'fc8' biases: 2.652593e-02 [4.174304e-05] 
Train error last 800 batches: 0.655993
-------------------------------------------------------
Not saving because 0.414073 > 0.299667 (9.300: -1.18%)
======================================================= (2.356 sec)
32.261... logprob:  0.660302, 0.295573 (1.441 sec)
32.262... logprob:  0.666649, 0.307292 (1.429 sec)
32.263... logprob:  0.657380, 0.272135 (1.442 sec)
32.264... logprob:  0.652556, 0.316406 (1.413 sec)
32.265... logprob:  0.611882, 0.260417 (1.413 sec)
32.266... logprob:  0.752359, 0.287760 (1.406 sec)
32.267... logprob:  0.696977, 0.311198 (1.408 sec)
32.268... logprob:  0.704045, 0.313802 (1.428 sec)
32.269... logprob:  0.753870, 0.316406 (1.405 sec)
32.270... logprob:  0.671884, 0.281250 (1.451 sec)
32.271... logprob:  0.630608, 0.285156 (1.422 sec)
32.272... logprob:  0.634640, 0.276042 (1.410 sec)
32.273... logprob:  0.701075, 0.285156 (1.461 sec)
32.274... logprob:  0.897381, 0.356771 (1.393 sec)
32.275... logprob:  0.665331, 0.308594 (1.419 sec)
32.276... logprob:  0.597959, 0.278646 (1.407 sec)
32.277... logprob:  0.699781, 0.305990 (1.427 sec)
32.278... logprob:  0.579015, 0.272135 (1.422 sec)
32.279... logprob:  0.575513, 0.270833 (1.450 sec)
32.280... logprob:  0.499432, 0.244792 (1.402 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.386899, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.278823e-03 [1.139602e-07] 
Layer 'conv1' biases: 2.183909e-06 [3.873671e-11] 
Layer 'conv2' weights[0]: 2.274271e-03 [1.137638e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.556607e-10] 
Layer 'conv3' weights[0]: 2.273251e-03 [1.139041e-07] 
Layer 'conv3' biases: 3.620330e-05 [4.921474e-09] 
Layer 'conv4' weights[0]: 2.282853e-03 [1.143743e-07] 
Layer 'conv4' biases: 9.998176e-01 [1.353535e-07] 
Layer 'conv5' weights[0]: 2.446923e-03 [2.115227e-06] 
Layer 'conv5' biases: 9.990461e-01 [2.300504e-06] 
Layer 'fc6' weights[0]: 6.667844e-03 [5.706800e-08] 
Layer 'fc6' biases: 9.999895e-01 [5.058635e-08] 
Layer 'fc7' weights[0]: 7.010148e-03 [1.330821e-07] 
Layer 'fc7' biases: 9.996998e-01 [1.734705e-07] 
Layer 'fc8' weights[0]: 4.745863e-03 [1.161276e-05] 
Layer 'fc8' biases: 2.597617e-02 [2.579785e-05] 
Train error last 800 batches: 0.656485
-------------------------------------------------------
Not saving because 0.386899 > 0.299667 (9.300: -1.18%)
======================================================= (2.371 sec)
32.281... logprob:  0.565631, 0.251302 (1.447 sec)
32.282... logprob:  0.572737, 0.261719 (1.427 sec)
32.283... logprob:  0.659611, 0.286458 (1.417 sec)
32.284... logprob:  0.566089, 0.247396 (1.403 sec)
32.285... logprob:  0.652326, 0.264323 (1.434 sec)
32.286... logprob:  0.770817, 0.345052 (1.433 sec)
32.287... logprob:  0.606591, 0.276042 (1.422 sec)
32.288... logprob:  0.581063, 0.263021 (1.433 sec)
32.289... logprob:  0.622125, 0.266927 (1.441 sec)
32.290... logprob:  0.689943, 0.296875 (1.401 sec)
32.291... logprob:  0.680991, 0.302083 (1.414 sec)
32.292... logprob:  0.809727, 0.341146 (1.417 sec)
32.293... logprob:  0.712129, 0.295573 (1.422 sec)
32.294... logprob:  0.576047, 0.256510 (1.399 sec)
32.295... logprob:  0.571370, 0.248698 (1.466 sec)
32.296... logprob:  0.565057, 0.238281 (1.419 sec)
32.297... logprob:  0.677038, 0.295573 (1.424 sec)
32.298... logprob:  0.661359, 0.300781 (1.454 sec)
32.299... logprob:  0.586172, 0.272135 (1.398 sec)
32.300... logprob:  0.701987, 0.313802 (1.416 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.502012, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.276539e-03 [1.138434e-07] 
Layer 'conv1' biases: 2.184239e-06 [3.712132e-11] 
Layer 'conv2' weights[0]: 2.271995e-03 [1.136533e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.226169e-10] 
Layer 'conv3' weights[0]: 2.270968e-03 [1.138168e-07] 
Layer 'conv3' biases: 3.620009e-05 [5.700741e-09] 
Layer 'conv4' weights[0]: 2.280589e-03 [1.144349e-07] 
Layer 'conv4' biases: 9.998164e-01 [1.849325e-07] 
Layer 'conv5' weights[0]: 2.444191e-03 [2.238507e-06] 
Layer 'conv5' biases: 9.990214e-01 [2.421252e-06] 
Layer 'fc6' weights[0]: 6.667161e-03 [5.888632e-08] 
Layer 'fc6' biases: 9.999896e-01 [5.335293e-08] 
Layer 'fc7' weights[0]: 7.009436e-03 [1.375999e-07] 
Layer 'fc7' biases: 9.997014e-01 [1.756067e-07] 
Layer 'fc8' weights[0]: 4.796186e-03 [1.135338e-05] 
Layer 'fc8' biases: 2.638386e-02 [2.127551e-05] 
Train error last 800 batches: 0.656749
-------------------------------------------------------
Not saving because 0.502012 > 0.299667 (9.300: -1.18%)
======================================================= (2.349 sec)
32.301... logprob:  0.627139, 0.274740 (1.420 sec)
32.302... logprob:  0.828990, 0.339844 (1.417 sec)
32.303... logprob:  0.661078, 0.296875 (1.401 sec)
32.304... logprob:  0.646587, 0.266927 (1.434 sec)
32.305... logprob:  0.727059, 0.335937 (1.428 sec)
32.306... logprob:  0.669611, 0.308594 (1.434 sec)
32.307... logprob:  0.746380, 0.303385 (1.439 sec)
32.308... logprob:  0.612612, 0.238281 (1.450 sec)
32.309... logprob:  0.629299, 0.286458 (1.414 sec)
32.310... logprob:  0.660203, 0.278646 (1.450 sec)
32.311... logprob:  0.660866, 0.307292 (1.416 sec)
32.312... logprob:  0.655480, 0.285156 (1.419 sec)
32.313... logprob:  0.731560, 0.324219 (1.416 sec)
32.314... logprob:  0.584492, 0.253906 (1.455 sec)
32.315... logprob:  0.566616, 0.261719 (1.429 sec)
32.316... logprob:  0.735780, 0.320313 (1.417 sec)
32.317... logprob:  0.605954, 0.265625 (1.469 sec)
32.318... logprob:  0.692659, 0.321614 (1.407 sec)
32.319... logprob:  0.714163, 0.321614 (1.416 sec)
32.320... logprob:  0.685034, 0.303385 (1.419 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.478185, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.274269e-03 [1.137392e-07] 
Layer 'conv1' biases: 2.184659e-06 [3.781835e-11] 
Layer 'conv2' weights[0]: 2.269728e-03 [1.135358e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.450354e-10] 
Layer 'conv3' weights[0]: 2.268687e-03 [1.136072e-07] 
Layer 'conv3' biases: 3.620046e-05 [4.387031e-09] 
Layer 'conv4' weights[0]: 2.278292e-03 [1.142240e-07] 
Layer 'conv4' biases: 9.998156e-01 [1.490595e-07] 
Layer 'conv5' weights[0]: 2.441520e-03 [2.034489e-06] 
Layer 'conv5' biases: 9.990356e-01 [2.110429e-06] 
Layer 'fc6' weights[0]: 6.666446e-03 [5.987934e-08] 
Layer 'fc6' biases: 9.999895e-01 [5.450781e-08] 
Layer 'fc7' weights[0]: 7.008737e-03 [1.406064e-07] 
Layer 'fc7' biases: 9.997004e-01 [1.794889e-07] 
Layer 'fc8' weights[0]: 4.771348e-03 [1.334119e-05] 
Layer 'fc8' biases: 2.621457e-02 [3.454981e-05] 
Train error last 800 batches: 0.657047
-------------------------------------------------------
Not saving because 0.478185 > 0.299667 (9.300: -1.18%)
======================================================= (2.356 sec)
32.321... logprob:  0.572790, 0.282552 (1.429 sec)
32.322... logprob:  0.645278, 0.296875 (1.420 sec)
32.323... logprob:  0.683170, 0.305989 (1.472 sec)
32.324... logprob:  0.742778, 0.307292 (1.423 sec)
32.325... logprob:  0.550091, 0.239583 (1.429 sec)
32.326... logprob:  0.770921, 0.321615 (1.456 sec)
32.327... logprob:  0.747929, 0.313802 (1.414 sec)
32.328... logprob:  0.761251, 0.338542 (1.418 sec)
32.329... logprob:  0.598385, 0.264323 (1.416 sec)
32.330... logprob:  0.562033, 0.261719 (1.417 sec)
32.331... logprob:  0.628399, 0.283854 (1.410 sec)
32.332... logprob:  0.765928, 0.322917 (1.442 sec)
32.333... logprob:  0.640734, 0.289062 (1.436 sec)
32.334... logprob:  0.716483, 0.298177 (1.436 sec)
32.335... logprob:  0.608209, 0.279948 (1.435 sec)
32.336... logprob:  0.648350, 0.270833 (1.449 sec)
32.337... logprob:  0.693407, 0.296875 (1.415 sec)
32.338... logprob:  0.659288, 0.278646 (1.416 sec)
32.339... logprob:  0.736528, 0.319010 (1.416 sec)
32.340... logprob:  0.698065, 0.291667 (1.422 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.431056, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.271999e-03 [1.135990e-07] 
Layer 'conv1' biases: 2.184795e-06 [3.364152e-11] 
Layer 'conv2' weights[0]: 2.267461e-03 [1.134032e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.112084e-10] 
Layer 'conv3' weights[0]: 2.266400e-03 [1.135625e-07] 
Layer 'conv3' biases: 3.620243e-05 [5.595892e-09] 
Layer 'conv4' weights[0]: 2.276016e-03 [1.140770e-07] 
Layer 'conv4' biases: 9.998164e-01 [1.781418e-07] 
Layer 'conv5' weights[0]: 2.440018e-03 [2.995592e-06] 
Layer 'conv5' biases: 9.990346e-01 [3.281682e-06] 
Layer 'fc6' weights[0]: 6.665802e-03 [7.039759e-08] 
Layer 'fc6' biases: 9.999896e-01 [6.816380e-08] 
Layer 'fc7' weights[0]: 7.007977e-03 [1.721975e-07] 
Layer 'fc7' biases: 9.997001e-01 [2.691823e-07] 
Layer 'fc8' weights[0]: 4.767985e-03 [1.577723e-05] 
Layer 'fc8' biases: 2.619786e-02 [3.961478e-05] 
Train error last 800 batches: 0.657605
-------------------------------------------------------
Not saving because 0.431056 > 0.299667 (9.300: -1.18%)
======================================================= (2.347 sec)
32.341... logprob:  0.820305, 0.348958 (1.424 sec)
32.342... logprob:  0.650311, 0.296875 (1.466 sec)
32.343... logprob:  0.705647, 0.321615 (1.438 sec)
32.344... logprob:  0.678590, 0.286458 (1.476 sec)
32.345... logprob:  0.730944, 0.307292 (1.432 sec)
32.346... logprob:  0.730874, 0.322917 (1.431 sec)
32.347... logprob:  0.557075, 0.229167 (1.476 sec)
32.348... logprob:  0.663405, 0.289062 (1.443 sec)
32.349... logprob:  0.629306, 0.266927 (1.424 sec)
32.350... logprob:  0.608681, 0.285156 (1.430 sec)
32.351... logprob:  0.697780, 0.321615 (1.422 sec)
32.352... logprob:  0.577078, 0.238281 (1.431 sec)
32.353... logprob:  0.734705, 0.305990 (1.490 sec)
32.354... logprob:  0.751278, 0.316406 (1.433 sec)
32.355... logprob:  0.631918, 0.298177 (1.442 sec)
32.356... logprob:  0.661305, 0.289062 (1.473 sec)
32.357... logprob:  0.580256, 0.243490 (1.428 sec)
32.358... logprob:  0.596801, 0.269531 (1.430 sec)
32.359... logprob:  0.751550, 0.352865 (1.426 sec)
32.360... logprob:  0.642381, 0.290364 (1.424 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.450339, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.269727e-03 [1.135576e-07] 
Layer 'conv1' biases: 2.184927e-06 [4.145001e-11] 
Layer 'conv2' weights[0]: 2.265184e-03 [1.133371e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.205986e-10] 
Layer 'conv3' weights[0]: 2.264153e-03 [1.135695e-07] 
Layer 'conv3' biases: 3.620840e-05 [6.406352e-09] 
Layer 'conv4' weights[0]: 2.273749e-03 [1.142590e-07] 
Layer 'conv4' biases: 9.998155e-01 [1.927954e-07] 
Layer 'conv5' weights[0]: 2.436844e-03 [2.680550e-06] 
Layer 'conv5' biases: 9.990495e-01 [2.965963e-06] 
Layer 'fc6' weights[0]: 6.665111e-03 [6.193488e-08] 
Layer 'fc6' biases: 9.999896e-01 [5.672832e-08] 
Layer 'fc7' weights[0]: 7.007271e-03 [1.487674e-07] 
Layer 'fc7' biases: 9.996997e-01 [2.165590e-07] 
Layer 'fc8' weights[0]: 4.753234e-03 [1.325039e-05] 
Layer 'fc8' biases: 2.610488e-02 [3.837195e-05] 
Train error last 800 batches: 0.657901
-------------------------------------------------------
Not saving because 0.450339 > 0.299667 (9.300: -1.18%)
======================================================= (2.406 sec)
32.361... logprob:  0.587243, 0.268229 (1.435 sec)
32.362... logprob:  0.611823, 0.253906 (1.472 sec)
32.363... logprob:  0.646855, 0.322917 (1.432 sec)
32.364... logprob:  0.646097, 0.292969 (1.448 sec)
32.365... logprob:  0.635577, 0.273437 (1.458 sec)
32.366... logprob:  0.618581, 0.281250 (1.440 sec)
32.367... logprob:  0.610923, 0.285156 (1.429 sec)
32.368... logprob:  0.711981, 0.292969 (1.424 sec)
32.369... logprob:  0.619947, 0.263021 (1.419 sec)
32.370... logprob:  0.682283, 0.305990 (1.434 sec)
32.371... logprob:  0.640069, 0.289062 (1.458 sec)
32.372... logprob:  0.651448, 0.286458 (1.448 sec)
32.373... logprob:  0.634966, 0.266927 (1.446 sec)
32.374... logprob:  0.759303, 0.316406 (1.444 sec)
32.375... logprob:  0.616376, 0.273438 (1.458 sec)
32.376... logprob:  0.615602, 0.273437 (1.430 sec)
32.377... logprob:  0.576946, 0.268229 (1.420 sec)
32.378... logprob:  0.636538, 0.282552 (1.424 sec)
32.379... logprob:  0.687828, 0.307292 (1.430 sec)
32.380... logprob:  0.780698, 0.334635 (1.432 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.374854, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.267459e-03 [1.133703e-07] 
Layer 'conv1' biases: 2.185163e-06 [3.183497e-11] 
Layer 'conv2' weights[0]: 2.262929e-03 [1.131742e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.276776e-10] 
Layer 'conv3' weights[0]: 2.261895e-03 [1.132916e-07] 
Layer 'conv3' biases: 3.620471e-05 [5.027759e-09] 
Layer 'conv4' weights[0]: 2.271473e-03 [1.137945e-07] 
Layer 'conv4' biases: 9.998139e-01 [1.532852e-07] 
Layer 'conv5' weights[0]: 2.433939e-03 [2.290826e-06] 
Layer 'conv5' biases: 9.990185e-01 [2.539193e-06] 
Layer 'fc6' weights[0]: 6.664429e-03 [6.174660e-08] 
Layer 'fc6' biases: 9.999898e-01 [5.730136e-08] 
Layer 'fc7' weights[0]: 7.006521e-03 [1.444467e-07] 
Layer 'fc7' biases: 9.997017e-01 [1.853800e-07] 
Layer 'fc8' weights[0]: 4.812690e-03 [1.181488e-05] 
Layer 'fc8' biases: 2.662693e-02 [1.594432e-05] 
Train error last 800 batches: 0.657939
-------------------------------------------------------
Not saving because 0.374854 > 0.299667 (9.300: -1.18%)
======================================================= (2.356 sec)
32.381... logprob:  0.777687, 0.343750 (1.468 sec)
32.382... logprob:  0.662470, 0.289062 (1.446 sec)
32.383... logprob:  0.625793, 0.289063 (1.436 sec)
32.384... logprob:  0.750812, 0.304688 (1.564 sec)
32.385... logprob:  0.715508, 0.294271 (1.431 sec)
32.386... logprob:  0.787492, 0.356771 (1.447 sec)
32.387... logprob:  0.581411, 0.259115 (1.426 sec)
32.388... logprob:  0.739871, 0.315104 (1.427 sec)
32.389... logprob:  0.697147, 0.294271 (1.429 sec)
32.390... logprob:  0.673510, 0.299479 (1.476 sec)
32.391... logprob:  0.638511, 0.294271 (1.441 sec)
32.392... logprob:  0.593198, 0.265625 (1.427 sec)
32.393... logprob:  0.613484, 0.285156 (1.480 sec)
32.394... logprob:  0.568371, 0.256510 (1.425 sec)
32.395... logprob:  0.579005, 0.268229 (1.423 sec)
32.396... logprob:  0.585029, 0.253906 (1.434 sec)
32.397... logprob:  0.692987, 0.308594 (1.421 sec)
32.398... logprob:  0.631444, 0.261719 (1.428 sec)
32.399... logprob:  0.694199, 0.311198 (1.478 sec)
32.400... logprob:  0.741191, 0.316406 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.556618, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.265194e-03 [1.132820e-07] 
Layer 'conv1' biases: 2.185354e-06 [2.863954e-11] 
Layer 'conv2' weights[0]: 2.260660e-03 [1.130791e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.103986e-10] 
Layer 'conv3' weights[0]: 2.259625e-03 [1.131970e-07] 
Layer 'conv3' biases: 3.623086e-05 [4.788120e-09] 
Layer 'conv4' weights[0]: 2.269201e-03 [1.137929e-07] 
Layer 'conv4' biases: 9.998137e-01 [1.583871e-07] 
Layer 'conv5' weights[0]: 2.432068e-03 [2.286739e-06] 
Layer 'conv5' biases: 9.990328e-01 [2.489510e-06] 
Layer 'fc6' weights[0]: 6.663756e-03 [6.429232e-08] 
Layer 'fc6' biases: 9.999899e-01 [6.015156e-08] 
Layer 'fc7' weights[0]: 7.005837e-03 [1.547301e-07] 
Layer 'fc7' biases: 9.997009e-01 [2.209895e-07] 
Layer 'fc8' weights[0]: 4.787453e-03 [1.526243e-05] 
Layer 'fc8' biases: 2.642064e-02 [4.629953e-05] 
Train error last 800 batches: 0.658234
-------------------------------------------------------
Not saving because 0.556618 > 0.299667 (9.300: -1.18%)
======================================================= (2.372 sec)
32.401... logprob:  0.627243, 0.279948 (1.443 sec)
32.402... logprob:  0.705334, 0.312500 (1.477 sec)
32.403... logprob:  0.665010, 0.268229 (1.425 sec)
32.404... logprob:  0.669345, 0.305990 (1.432 sec)
32.405... logprob:  0.695757, 0.285156 (1.426 sec)
32.406... logprob:  0.632598, 0.274739 (1.422 sec)
32.407... logprob:  0.715783, 0.321615 (1.435 sec)
32.408... logprob:  0.572888, 0.259115 (1.475 sec)
32.409... logprob:  0.622354, 0.273438 (1.431 sec)
32.410... logprob:  0.797107, 0.341146 (1.444 sec)
32.411... logprob:  0.626253, 0.279948 (1.470 sec)
32.412... logprob:  0.648153, 0.278646 (1.434 sec)
32.413... logprob:  0.757715, 0.311198 (1.429 sec)
32.414... logprob:  0.619015, 0.264323 (1.428 sec)
32.415... logprob:  0.717751, 0.307292 (1.419 sec)
32.416... logprob:  0.576830, 0.268229 (1.431 sec)
32.417... logprob:  0.648747, 0.270833 (1.458 sec)
32.418... logprob:  0.639620, 0.282552 (1.448 sec)
32.419... logprob:  0.626635, 0.296875 (1.453 sec)
32.420... logprob:  0.598793, 0.274739 (1.449 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.456181, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.262925e-03 [1.132146e-07] 
Layer 'conv1' biases: 2.185450e-06 [3.995086e-11] 
Layer 'conv2' weights[0]: 2.258395e-03 [1.129894e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.157900e-10] 
Layer 'conv3' weights[0]: 2.257374e-03 [1.131516e-07] 
Layer 'conv3' biases: 3.622895e-05 [5.307381e-09] 
Layer 'conv4' weights[0]: 2.266926e-03 [1.137831e-07] 
Layer 'conv4' biases: 9.998137e-01 [1.665398e-07] 
Layer 'conv5' weights[0]: 2.430257e-03 [2.742751e-06] 
Layer 'conv5' biases: 9.990307e-01 [2.987465e-06] 
Layer 'fc6' weights[0]: 6.663097e-03 [6.333098e-08] 
Layer 'fc6' biases: 9.999899e-01 [5.910254e-08] 
Layer 'fc7' weights[0]: 7.005117e-03 [1.527936e-07] 
Layer 'fc7' biases: 9.997007e-01 [2.340489e-07] 
Layer 'fc8' weights[0]: 4.785123e-03 [1.452674e-05] 
Layer 'fc8' biases: 2.643138e-02 [4.041759e-05] 
Train error last 800 batches: 0.657730
-------------------------------------------------------
Not saving because 0.456181 > 0.299667 (9.300: -1.18%)
======================================================= (2.389 sec)
32.421... logprob:  0.748551, 0.315104 (1.454 sec)
32.422... logprob:  0.708326, 0.316406 (1.439 sec)
32.423... logprob:  0.598840, 0.283854 (1.418 sec)
32.424... logprob:  0.573901, 0.270833 (1.424 sec)
32.425... logprob:  0.537277, 0.240885 (1.433 sec)
32.426... logprob:  0.565134, 0.252604 (1.435 sec)
32.427... logprob:  0.817398, 0.329427 (1.461 sec)
32.428... logprob:  0.848396, 0.356771 (1.450 sec)
32.429... logprob:  0.741386, 0.316406 (1.446 sec)
32.430... logprob:  0.551111, 0.238281 (1.470 sec)
32.431... logprob:  0.724437, 0.313802 (1.429 sec)
32.432... logprob:  0.525418, 0.227865 (1.422 sec)
32.433... logprob:  0.578220, 0.276042 (1.431 sec)
32.434... logprob:  0.720258, 0.302083 (1.429 sec)
32.435... logprob:  0.782708, 0.352865 (1.433 sec)
32.436... logprob:  0.536691, 0.210938 (1.476 sec)
32.437... logprob:  0.673148, 0.296875 (1.438 sec)
32.438... logprob:  0.697375, 0.281250 (1.426 sec)
32.439... logprob:  0.610803, 0.259114 (1.480 sec)
32.440... logprob:  0.795124, 0.338542 (1.425 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.399455, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.260662e-03 [1.130611e-07] 
Layer 'conv1' biases: 2.185482e-06 [2.612871e-11] 
Layer 'conv2' weights[0]: 2.256150e-03 [1.128396e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.315271e-10] 
Layer 'conv3' weights[0]: 2.255103e-03 [1.129054e-07] 
Layer 'conv3' biases: 3.622700e-05 [3.628650e-09] 
Layer 'conv4' weights[0]: 2.264677e-03 [1.134990e-07] 
Layer 'conv4' biases: 9.998132e-01 [1.639468e-07] 
Layer 'conv5' weights[0]: 2.427828e-03 [2.785430e-06] 
Layer 'conv5' biases: 9.990358e-01 [3.119553e-06] 
Layer 'fc6' weights[0]: 6.662402e-03 [6.454519e-08] 
Layer 'fc6' biases: 9.999897e-01 [6.056646e-08] 
Layer 'fc7' weights[0]: 7.004428e-03 [1.519297e-07] 
Layer 'fc7' biases: 9.997001e-01 [2.113330e-07] 
Layer 'fc8' weights[0]: 4.775494e-03 [1.287429e-05] 
Layer 'fc8' biases: 2.638551e-02 [2.399618e-05] 
Train error last 800 batches: 0.657687
-------------------------------------------------------
Not saving because 0.399455 > 0.299667 (9.300: -1.18%)
======================================================= (2.370 sec)
32.441... logprob:  0.614891, 0.281250 (1.428 sec)
32.442... logprob:  0.605054, 0.263021 (1.431 sec)
32.443... logprob:  0.723279, 0.330729 (1.424 sec)
32.444... logprob:  0.725870, 0.322917 (1.430 sec)
32.445... logprob:  0.635326, 0.295573 (1.476 sec)
32.446... logprob:  0.676509, 0.291667 (1.429 sec)
32.447... logprob:  0.821884, 0.324219 (1.435 sec)
32.448... logprob:  0.540067, 0.221354 (1.481 sec)
32.449... logprob:  0.635887, 0.296875 (1.428 sec)
32.450... logprob:  0.570811, 0.269531 (1.426 sec)
32.451... logprob:  0.659269, 0.285156 (1.432 sec)
32.452... logprob:  0.623072, 0.285156 (1.429 sec)
32.453... logprob:  0.681206, 0.296875 (1.422 sec)
32.454... logprob:  0.717298, 0.322917 (1.484 sec)
32.455... logprob:  0.655430, 0.287760 (1.424 sec)
32.456... logprob:  0.602895, 0.274740 (1.442 sec)
32.457... logprob:  0.642531, 0.277344 (1.465 sec)
32.458... logprob:  0.543807, 0.261719 (1.431 sec)
32.459... logprob:  0.783042, 0.335937 (1.433 sec)
32.460... logprob:  0.541702, 0.246094 (1.423 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.445356, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.258405e-03 [1.129946e-07] 
Layer 'conv1' biases: 2.185510e-06 [2.181921e-11] 
Layer 'conv2' weights[0]: 2.253905e-03 [1.127685e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.263121e-10] 
Layer 'conv3' weights[0]: 2.252844e-03 [1.128302e-07] 
Layer 'conv3' biases: 3.623115e-05 [4.394847e-09] 
Layer 'conv4' weights[0]: 2.262400e-03 [1.134499e-07] 
Layer 'conv4' biases: 9.998135e-01 [1.623392e-07] 
Layer 'conv5' weights[0]: 2.425703e-03 [2.296946e-06] 
Layer 'conv5' biases: 9.990317e-01 [2.554931e-06] 
Layer 'fc6' weights[0]: 6.661745e-03 [5.989032e-08] 
Layer 'fc6' biases: 9.999897e-01 [5.426092e-08] 
Layer 'fc7' weights[0]: 7.003712e-03 [1.433187e-07] 
Layer 'fc7' biases: 9.997006e-01 [1.954624e-07] 
Layer 'fc8' weights[0]: 4.788782e-03 [1.236476e-05] 
Layer 'fc8' biases: 2.651421e-02 [2.912823e-05] 
Train error last 800 batches: 0.657885
-------------------------------------------------------
Not saving because 0.445356 > 0.299667 (9.300: -1.18%)
======================================================= (2.363 sec)
32.461... logprob:  0.677996, 0.305989 (1.425 sec)
32.462... logprob:  0.684345, 0.273437 (1.429 sec)
32.463... logprob:  0.658369, 0.296875 (1.467 sec)
32.464... logprob:  0.645194, 0.274739 (1.445 sec)
32.465... logprob:  0.743696, 0.289062 (1.444 sec)
32.466... logprob:  0.546120, 0.252604 (1.456 sec)
32.467... logprob:  0.659906, 0.305990 (1.451 sec)
32.468... logprob:  0.650121, 0.283854 (1.431 sec)
32.469... logprob:  0.558615, 0.273437 (1.433 sec)
32.470... logprob:  0.663029, 0.283854 (1.419 sec)
32.471... logprob:  0.694901, 0.273437 (1.431 sec)
32.472... logprob:  0.628649, 0.303385 (1.445 sec)
32.473... logprob:  0.638409, 0.286458 (1.453 sec)
32.474... logprob:  0.742324, 0.308594 (1.444 sec)
32.475... logprob:  0.644016, 0.269531 (1.439 sec)
32.476... logprob:  0.680343, 0.287760 (1.468 sec)
32.477... logprob:  0.614149, 0.265625 (1.436 sec)
32.478... logprob:  0.675861, 0.315104 (1.420 sec)
32.479... logprob:  0.520800, 0.231771 (1.422 sec)
32.480... logprob:  0.545185, 0.278646 (1.437 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.471378, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.256152e-03 [1.128741e-07] 
Layer 'conv1' biases: 2.185584e-06 [3.992226e-11] 
Layer 'conv2' weights[0]: 2.251633e-03 [1.126490e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.326641e-10] 
Layer 'conv3' weights[0]: 2.250603e-03 [1.128920e-07] 
Layer 'conv3' biases: 3.621626e-05 [6.424388e-09] 
Layer 'conv4' weights[0]: 2.260139e-03 [1.135546e-07] 
Layer 'conv4' biases: 9.998136e-01 [1.910731e-07] 
Layer 'conv5' weights[0]: 2.423792e-03 [3.200542e-06] 
Layer 'conv5' biases: 9.990134e-01 [3.482505e-06] 
Layer 'fc6' weights[0]: 6.661080e-03 [6.548189e-08] 
Layer 'fc6' biases: 9.999896e-01 [6.181794e-08] 
Layer 'fc7' weights[0]: 7.003020e-03 [1.594557e-07] 
Layer 'fc7' biases: 9.997017e-01 [2.609782e-07] 
Layer 'fc8' weights[0]: 4.823315e-03 [1.520519e-05] 
Layer 'fc8' biases: 2.688927e-02 [4.633779e-05] 
Train error last 800 batches: 0.657582
-------------------------------------------------------
Not saving because 0.471378 > 0.299667 (9.300: -1.18%)
======================================================= (2.346 sec)
32.481... logprob:  0.753011, 0.305990 (1.442 sec)
32.482... logprob:  0.686105, 0.278646 (1.475 sec)
32.483... logprob:  0.771235, 0.341146 (1.443 sec)
32.484... logprob:  0.682180, 0.316406 (1.432 sec)
32.485... logprob:  0.711401, 0.308594 (1.478 sec)
32.486... logprob:  0.586661, 0.268229 (1.427 sec)
32.487... logprob:  0.614053, 0.263021 (1.422 sec)
32.488... logprob:  0.611069, 0.298177 (1.430 sec)
32.489... logprob:  0.628469, 0.300781 (1.428 sec)
32.490... logprob:  0.660078, 0.304687 (1.425 sec)
32.491... logprob:  0.587406, 0.279948 (1.476 sec)
32.492... logprob:  0.636570, 0.255208 (1.433 sec)
32.493... logprob:  0.719129, 0.302083 (1.431 sec)
32.494... logprob:  0.673885, 0.313802 (1.484 sec)
32.495... logprob:  0.585787, 0.250000 (1.426 sec)
32.496... logprob:  0.697517, 0.322917 (1.427 sec)
32.497... logprob:  0.595740, 0.278646 (1.438 sec)
32.498... logprob:  0.681683, 0.316406 (1.430 sec)
32.499... logprob:  0.636269, 0.274740 (1.423 sec)
32.500... logprob:  0.604330, 0.272135 (1.485 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.499841, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.253895e-03 [1.127374e-07] 
Layer 'conv1' biases: 2.185732e-06 [2.097137e-11] 
Layer 'conv2' weights[0]: 2.249391e-03 [1.125084e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.769835e-10] 
Layer 'conv3' weights[0]: 2.248343e-03 [1.125491e-07] 
Layer 'conv3' biases: 3.623077e-05 [3.414906e-09] 
Layer 'conv4' weights[0]: 2.257884e-03 [1.130702e-07] 
Layer 'conv4' biases: 9.998133e-01 [1.020062e-07] 
Layer 'conv5' weights[0]: 2.421337e-03 [1.974502e-06] 
Layer 'conv5' biases: 9.990242e-01 [2.184287e-06] 
Layer 'fc6' weights[0]: 6.660348e-03 [5.670137e-08] 
Layer 'fc6' biases: 9.999901e-01 [5.036532e-08] 
Layer 'fc7' weights[0]: 7.002306e-03 [1.321843e-07] 
Layer 'fc7' biases: 9.997007e-01 [1.621759e-07] 
Layer 'fc8' weights[0]: 4.802452e-03 [1.134286e-05] 
Layer 'fc8' biases: 2.668936e-02 [2.083023e-05] 
Train error last 800 batches: 0.657183
-------------------------------------------------------
Not saving because 0.499841 > 0.299667 (9.300: -1.18%)
======================================================= (2.354 sec)
32.501... logprob:  0.521785, 0.247396 (1.431 sec)
32.502... logprob:  0.639429, 0.270833 (1.447 sec)
32.503... logprob:  0.611076, 0.268229 (1.485 sec)
32.504... logprob:  0.839075, 0.364583 (1.427 sec)
32.505... logprob:  0.639677, 0.283854 (1.431 sec)
32.506... logprob:  0.640214, 0.266927 (1.428 sec)
32.507... logprob:  0.572369, 0.229167 (1.421 sec)
32.508... logprob:  0.644908, 0.309896 (1.434 sec)
32.509... logprob:  0.580075, 0.287760 (1.470 sec)
32.510... logprob:  0.601951, 0.278646 (1.437 sec)
32.511... logprob:  0.643869, 0.286458 (1.444 sec)
32.512... logprob:  0.649419, 0.294271 (1.460 sec)
32.513... logprob:  0.523284, 0.227865 (1.435 sec)
32.514... logprob:  0.655569, 0.286458 (1.436 sec)
32.515... logprob:  0.687792, 0.321615 (1.430 sec)
32.516... logprob:  0.659112, 0.292969 (1.420 sec)
32.517... logprob:  0.725119, 0.307292 (1.431 sec)
32.518... logprob:  0.668475, 0.286458 (1.450 sec)
32.519... logprob:  0.706919, 0.289062 (1.448 sec)
32.520... logprob:  0.603873, 0.270833 (1.444 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.513824, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.251636e-03 [1.125840e-07] 
Layer 'conv1' biases: 2.185872e-06 [2.769440e-11] 
Layer 'conv2' weights[0]: 2.247129e-03 [1.123953e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.875161e-10] 
Layer 'conv3' weights[0]: 2.246087e-03 [1.124111e-07] 
Layer 'conv3' biases: 3.623079e-05 [2.987339e-09] 
Layer 'conv4' weights[0]: 2.255632e-03 [1.129590e-07] 
Layer 'conv4' biases: 9.998122e-01 [1.133119e-07] 
Layer 'conv5' weights[0]: 2.418517e-03 [2.002740e-06] 
Layer 'conv5' biases: 9.990067e-01 [2.094313e-06] 
Layer 'fc6' weights[0]: 6.659657e-03 [5.816138e-08] 
Layer 'fc6' biases: 9.999894e-01 [5.264330e-08] 
Layer 'fc7' weights[0]: 7.001585e-03 [1.347304e-07] 
Layer 'fc7' biases: 9.997018e-01 [1.593693e-07] 
Layer 'fc8' weights[0]: 4.828958e-03 [1.095580e-05] 
Layer 'fc8' biases: 2.692343e-02 [1.099743e-05] 
Train error last 800 batches: 0.656605
-------------------------------------------------------
Not saving because 0.513824 > 0.299667 (9.300: -1.18%)
======================================================= (2.377 sec)
32.521... logprob:  0.669941, 0.292969 (1.448 sec)
32.522... logprob:  0.695449, 0.330729 (1.463 sec)
32.523... logprob:  0.572466, 0.263021 (1.429 sec)
32.524... logprob:  0.711923, 0.321615 (1.419 sec)
32.525... logprob:  0.602927, 0.283854 (1.428 sec)
32.526... logprob:  0.607139, 0.273437 (1.433 sec)
32.527... logprob:  0.750716, 0.333333 (1.438 sec)
32.528... logprob:  0.680079, 0.294271 (1.463 sec)
32.529... logprob:  0.623718, 0.273437 (1.443 sec)
32.530... logprob:  0.774112, 0.322917 (1.434 sec)
32.531... logprob:  0.613797, 0.281250 (1.474 sec)
32.532... logprob:  0.645481, 0.312500 (1.426 sec)
32.533... logprob:  0.735951, 0.337240 (1.421 sec)
32.534... logprob:  0.566391, 0.252604 (1.430 sec)
32.535... logprob:  0.692569, 0.312500 (1.426 sec)
32.536... logprob:  0.721841, 0.281250 (1.426 sec)
32.537... logprob:  0.737258, 0.307292 (1.481 sec)
32.538... logprob:  0.772590, 0.322917 (1.434 sec)
32.539... logprob:  0.556199, 0.261719 (1.434 sec)
32.540... logprob:  0.675767, 0.282552 (1.499 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.517368, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.249378e-03 [1.124920e-07] 
Layer 'conv1' biases: 2.186091e-06 [2.873040e-11] 
Layer 'conv2' weights[0]: 2.244887e-03 [1.122816e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.905408e-10] 
Layer 'conv3' weights[0]: 2.243836e-03 [1.124222e-07] 
Layer 'conv3' biases: 3.624063e-05 [5.353687e-09] 
Layer 'conv4' weights[0]: 2.253362e-03 [1.128824e-07] 
Layer 'conv4' biases: 9.998112e-01 [1.522577e-07] 
Layer 'conv5' weights[0]: 2.415829e-03 [2.159275e-06] 
Layer 'conv5' biases: 9.990177e-01 [2.237969e-06] 
Layer 'fc6' weights[0]: 6.658945e-03 [6.327590e-08] 
Layer 'fc6' biases: 9.999899e-01 [5.949998e-08] 
Layer 'fc7' weights[0]: 7.000919e-03 [1.495021e-07] 
Layer 'fc7' biases: 9.997003e-01 [2.032177e-07] 
Layer 'fc8' weights[0]: 4.797568e-03 [1.222249e-05] 
Layer 'fc8' biases: 2.673623e-02 [2.582911e-05] 
Train error last 800 batches: 0.656970
-------------------------------------------------------
Not saving because 0.517368 > 0.299667 (9.300: -1.18%)
======================================================= (2.384 sec)
32.541... logprob:  0.640183, 0.286458 (1.439 sec)
32.542... logprob:  0.649626, 0.292969 (1.430 sec)
32.543... logprob:  0.553238, 0.266927 (1.428 sec)
32.544... logprob:  0.633986, 0.270833 (1.425 sec)
32.545... logprob:  0.643785, 0.277344 (1.427 sec)
32.546... logprob:  0.587748, 0.247396 (1.475 sec)
32.547... logprob:  0.682773, 0.320312 (1.432 sec)
32.548... logprob:  0.674070, 0.307292 (1.434 sec)
32.549... logprob:  0.653822, 0.264323 (1.472 sec)
32.550... logprob:  0.667718, 0.300781 (1.426 sec)
32.551... logprob:  0.608775, 0.269531 (1.433 sec)
32.552... logprob:  0.634917, 0.290365 (1.433 sec)
32.553... logprob:  0.642685, 0.277344 (1.421 sec)
32.554... logprob:  0.628714, 0.269531 (1.426 sec)
32.555... logprob:  0.584269, 0.269531 (1.479 sec)
32.556... logprob:  0.575262, 0.266927 (1.430 sec)
32.557... logprob:  0.724790, 0.298177 (1.442 sec)
32.558... logprob:  0.701210, 0.311198 (1.467 sec)
32.559... logprob:  0.697494, 0.302083 (1.429 sec)
32.560... logprob:  0.572525, 0.244792 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.448938, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.247146e-03 [1.123881e-07] 
Layer 'conv1' biases: 2.186192e-06 [3.238702e-11] 
Layer 'conv2' weights[0]: 2.242656e-03 [1.121802e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.186964e-10] 
Layer 'conv3' weights[0]: 2.241599e-03 [1.122372e-07] 
Layer 'conv3' biases: 3.624450e-05 [4.294920e-09] 
Layer 'conv4' weights[0]: 2.251103e-03 [1.128126e-07] 
Layer 'conv4' biases: 9.998114e-01 [1.597263e-07] 
Layer 'conv5' weights[0]: 2.413739e-03 [2.144017e-06] 
Layer 'conv5' biases: 9.990093e-01 [2.310042e-06] 
Layer 'fc6' weights[0]: 6.658245e-03 [5.854597e-08] 
Layer 'fc6' biases: 9.999896e-01 [5.325585e-08] 
Layer 'fc7' weights[0]: 7.000160e-03 [1.381920e-07] 
Layer 'fc7' biases: 9.997007e-01 [1.703450e-07] 
Layer 'fc8' weights[0]: 4.803518e-03 [1.184251e-05] 
Layer 'fc8' biases: 2.670462e-02 [1.952144e-05] 
Train error last 800 batches: 0.657047
-------------------------------------------------------
Not saving because 0.448938 > 0.299667 (9.300: -1.18%)
======================================================= (2.377 sec)
32.561... logprob:  0.618014, 0.242187 (1.432 sec)
32.562... logprob:  0.699749, 0.333333 (1.414 sec)
32.563... logprob:  0.669931, 0.311198 (1.435 sec)
32.564... logprob:  0.753919, 0.319010 (1.458 sec)
32.565... logprob:  0.771999, 0.342448 (1.447 sec)
32.566... logprob:  0.587134, 0.257812 (1.451 sec)
32.567... logprob:  0.626906, 0.270833 (1.450 sec)
32.568... logprob:  0.641718, 0.292969 (1.447 sec)
32.569... logprob:  0.785462, 0.346354 (1.434 sec)
32.570... logprob:  0.712590, 0.322917 (1.421 sec)
32.571... logprob:  0.631650, 0.298177 (1.424 sec)
32.572... logprob:  0.628006, 0.269531 (1.437 sec)
32.573... logprob:  0.741875, 0.334635 (1.442 sec)
32.574... logprob:  0.561288, 0.244792 (1.454 sec)
32.575... logprob:  0.628949, 0.281250 (1.447 sec)
32.576... logprob:  0.616836, 0.269531 (1.439 sec)
32.577... logprob:  0.679776, 0.294271 (1.466 sec)
32.578... logprob:  0.572053, 0.259115 (1.427 sec)
32.579... logprob:  0.671908, 0.294271 (1.420 sec)
32.580... logprob:  0.752055, 0.296875 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.437314, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.244891e-03 [1.123169e-07] 
Layer 'conv1' biases: 2.186369e-06 [2.497829e-11] 
Layer 'conv2' weights[0]: 2.240396e-03 [1.120774e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.272910e-10] 
Layer 'conv3' weights[0]: 2.239367e-03 [1.121022e-07] 
Layer 'conv3' biases: 3.624966e-05 [3.524269e-09] 
Layer 'conv4' weights[0]: 2.248870e-03 [1.126922e-07] 
Layer 'conv4' biases: 9.998121e-01 [1.296570e-07] 
Layer 'conv5' weights[0]: 2.412437e-03 [2.379726e-06] 
Layer 'conv5' biases: 9.990103e-01 [2.544201e-06] 
Layer 'fc6' weights[0]: 6.657578e-03 [6.061256e-08] 
Layer 'fc6' biases: 9.999897e-01 [5.602595e-08] 
Layer 'fc7' weights[0]: 6.999480e-03 [1.485044e-07] 
Layer 'fc7' biases: 9.997001e-01 [2.009352e-07] 
Layer 'fc8' weights[0]: 4.789232e-03 [1.377748e-05] 
Layer 'fc8' biases: 2.663393e-02 [2.936446e-05] 
Train error last 800 batches: 0.656622
-------------------------------------------------------
Not saving because 0.437314 > 0.299667 (9.300: -1.18%)
======================================================= (2.378 sec)
32.581... logprob:  0.740829, 0.298177 (1.438 sec)
32.582... logprob:  0.701118, 0.286458 (1.428 sec)
32.583... logprob:  0.723647, 0.268229 (1.472 sec)
32.584... logprob:  0.647235, 0.274740 (1.440 sec)
32.585... logprob:  0.599846, 0.277344 (1.430 sec)
32.586... logprob:  0.489385, 0.218750 (1.478 sec)
32.587... logprob:  0.589780, 0.278646 (1.424 sec)
32.588... logprob:  0.677612, 0.308594 (1.426 sec)
32.589... logprob:  0.643414, 0.273437 (1.426 sec)
32.590... logprob:  0.640136, 0.251302 (1.423 sec)
32.591... logprob:  0.610699, 0.265625 (1.433 sec)
32.592... logprob:  0.717498, 0.317708 (1.476 sec)
32.593... logprob:  0.675682, 0.250000 (1.429 sec)
32.594... logprob:  0.593574, 0.272135 (1.434 sec)
32.595... logprob:  0.778112, 0.335937 (1.484 sec)
32.596... logprob:  0.680244, 0.326823 (1.427 sec)
32.597... logprob:  0.566396, 0.265625 (1.425 sec)
32.598... logprob:  0.605282, 0.264323 (1.430 sec)
32.599... logprob:  0.587880, 0.255208 (1.422 sec)
32.600... logprob:  0.573566, 0.276042 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.554412, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.242645e-03 [1.122081e-07] 
Layer 'conv1' biases: 2.186434e-06 [3.889367e-11] 
Layer 'conv2' weights[0]: 2.238160e-03 [1.119725e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.713091e-10] 
Layer 'conv3' weights[0]: 2.237136e-03 [1.121581e-07] 
Layer 'conv3' biases: 3.624070e-05 [5.836405e-09] 
Layer 'conv4' weights[0]: 2.246605e-03 [1.128500e-07] 
Layer 'conv4' biases: 9.998131e-01 [1.895383e-07] 
Layer 'conv5' weights[0]: 2.411529e-03 [3.815521e-06] 
Layer 'conv5' biases: 9.989883e-01 [4.244044e-06] 
Layer 'fc6' weights[0]: 6.656906e-03 [7.404002e-08] 
Layer 'fc6' biases: 9.999896e-01 [7.370406e-08] 
Layer 'fc7' weights[0]: 6.998772e-03 [1.801024e-07] 
Layer 'fc7' biases: 9.997010e-01 [3.176729e-07] 
Layer 'fc8' weights[0]: 4.819717e-03 [1.695049e-05] 
Layer 'fc8' biases: 2.696694e-02 [5.582919e-05] 
Train error last 800 batches: 0.656602
-------------------------------------------------------
Not saving because 0.554412 > 0.299667 (9.300: -1.18%)
======================================================= (2.367 sec)
32.601... logprob:  0.676216, 0.316406 (1.486 sec)
32.602... logprob:  0.542234, 0.243489 (1.426 sec)
32.603... logprob:  0.541804, 0.260417 (1.440 sec)
32.604... logprob:  0.618222, 0.281250 (1.469 sec)
32.605... logprob:  0.719367, 0.339844 (1.429 sec)
32.606... logprob:  0.567317, 0.266927 (1.437 sec)
32.607... logprob:  0.742970, 0.295573 (1.426 sec)
32.608... logprob:  0.654200, 0.291667 (1.425 sec)
32.609... logprob:  0.534768, 0.256510 (1.434 sec)
32.610... logprob:  0.726333, 0.302083 (1.464 sec)
32.611... logprob:  0.705992, 0.304688 (1.441 sec)
32.612... logprob:  0.681373, 0.278646 (1.447 sec)
32.613... logprob:  0.580012, 0.265625 (1.454 sec)
32.614... logprob:  0.664786, 0.281250 (1.443 sec)
32.615... logprob:  0.626343, 0.291667 (1.430 sec)
32.616... logprob:  0.651852, 0.283854 (1.421 sec)
32.617... logprob:  0.635207, 0.292969 (1.422 sec)
32.618... logprob:  0.736219, 0.287760 (1.430 sec)
32.619... logprob:  0.756572, 0.341146 (1.452 sec)
32.620... logprob:  0.778628, 0.330729 (1.455 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.378882, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.240403e-03 [1.120229e-07] 
Layer 'conv1' biases: 2.186451e-06 [6.036284e-11] 
Layer 'conv2' weights[0]: 2.235927e-03 [1.118188e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.526039e-10] 
Layer 'conv3' weights[0]: 2.234883e-03 [1.124108e-07] 
Layer 'conv3' biases: 3.623663e-05 [9.765949e-09] 
Layer 'conv4' weights[0]: 2.244370e-03 [1.130776e-07] 
Layer 'conv4' biases: 9.998139e-01 [3.074306e-07] 
Layer 'conv5' weights[0]: 2.410767e-03 [5.617218e-06] 
Layer 'conv5' biases: 9.989764e-01 [6.289137e-06] 
Layer 'fc6' weights[0]: 6.656215e-03 [8.926252e-08] 
Layer 'fc6' biases: 9.999895e-01 [9.689035e-08] 
Layer 'fc7' weights[0]: 6.998092e-03 [2.404508e-07] 
Layer 'fc7' biases: 9.997015e-01 [4.663949e-07] 
Layer 'fc8' weights[0]: 4.836394e-03 [2.298697e-05] 
Layer 'fc8' biases: 2.719797e-02 [7.624610e-05] 
Train error last 800 batches: 0.656971
-------------------------------------------------------
Not saving because 0.378882 > 0.299667 (9.300: -1.18%)
======================================================= (2.337 sec)
32.621... logprob:  0.571217, 0.243490 (1.454 sec)
32.622... logprob:  0.608196, 0.265625 (1.439 sec)
32.623... logprob:  0.545454, 0.257812 (1.462 sec)
32.624... logprob:  0.624179, 0.252604 (1.433 sec)
32.625... logprob:  0.699164, 0.312500 (1.415 sec)
32.626... logprob:  0.626283, 0.266927 (1.426 sec)
32.627... logprob:  0.612566, 0.272135 (1.433 sec)
32.628... logprob:  0.697972, 0.312500 (1.437 sec)
32.629... logprob:  0.609724, 0.287760 (1.468 sec)
32.630... logprob:  0.671230, 0.296875 (1.446 sec)
32.631... logprob:  0.777672, 0.360677 (1.433 sec)
32.632... logprob:  0.699865, 0.298177 (1.475 sec)
32.633... logprob:  0.623995, 0.263021 (1.426 sec)
32.634... logprob:  0.822310, 0.343750 (1.422 sec)
32.635... logprob:  0.625151, 0.292969 (1.432 sec)
32.636... logprob:  0.653765, 0.300781 (1.427 sec)
32.637... logprob:  0.572539, 0.239583 (1.426 sec)
32.638... logprob:  0.659301, 0.292969 (1.472 sec)
32.639... logprob:  0.616517, 0.287760 (1.438 sec)
32.640... logprob:  0.686128, 0.286458 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.535803, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.238167e-03 [1.119658e-07] 
Layer 'conv1' biases: 2.186551e-06 [3.415545e-11] 
Layer 'conv2' weights[0]: 2.233680e-03 [1.117368e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.217837e-10] 
Layer 'conv3' weights[0]: 2.232661e-03 [1.118597e-07] 
Layer 'conv3' biases: 3.626438e-05 [4.698111e-09] 
Layer 'conv4' weights[0]: 2.242117e-03 [1.124118e-07] 
Layer 'conv4' biases: 9.998127e-01 [1.601241e-07] 
Layer 'conv5' weights[0]: 2.407672e-03 [2.009009e-06] 
Layer 'conv5' biases: 9.990172e-01 [2.153187e-06] 
Layer 'fc6' weights[0]: 6.655538e-03 [5.703436e-08] 
Layer 'fc6' biases: 9.999898e-01 [5.120045e-08] 
Layer 'fc7' weights[0]: 6.997466e-03 [1.353760e-07] 
Layer 'fc7' biases: 9.996988e-01 [1.640608e-07] 
Layer 'fc8' weights[0]: 4.758265e-03 [1.107441e-05] 
Layer 'fc8' biases: 2.661683e-02 [1.192825e-05] 
Train error last 800 batches: 0.656879
-------------------------------------------------------
Not saving because 0.535803 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
32.641... logprob:  0.651560, 0.260417 (1.482 sec)
32.642... logprob:  0.655317, 0.294271 (1.435 sec)
32.643... logprob:  0.825681, 0.326823 (1.433 sec)
32.644... logprob:  0.631317, 0.286458 (1.428 sec)
32.645... logprob:  0.616197, 0.268229 (1.424 sec)
32.646... logprob:  0.640393, 0.290365 (1.427 sec)
32.647... logprob:  0.628125, 0.289062 (1.481 sec)
32.648... logprob:  0.757728, 0.346354 (1.423 sec)
32.649... logprob:  0.597275, 0.298177 (1.443 sec)
32.650... logprob:  0.625983, 0.287760 (1.477 sec)
32.651... logprob:  0.591239, 0.261719 (1.424 sec)
32.652... logprob:  0.798692, 0.343750 (1.431 sec)
32.653... logprob:  0.751811, 0.322917 (1.430 sec)
32.654... logprob:  0.677846, 0.273437 (1.417 sec)
32.655... logprob:  0.715742, 0.302083 (1.438 sec)
32.656... logprob:  0.695798, 0.311198 (1.471 sec)
32.657... logprob:  0.636174, 0.289062 (1.435 sec)
32.658... logprob:  0.635710, 0.312500 (1.442 sec)
32.659... logprob:  0.685432, 0.282552 (1.467 sec)
32.660... logprob:  0.661123, 0.282552 (1.441 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.395026, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.235932e-03 [1.118362e-07] 
Layer 'conv1' biases: 2.186648e-06 [2.423120e-11] 
Layer 'conv2' weights[0]: 2.231456e-03 [1.116263e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.192204e-10] 
Layer 'conv3' weights[0]: 2.230447e-03 [1.116679e-07] 
Layer 'conv3' biases: 3.628358e-05 [3.417705e-09] 
Layer 'conv4' weights[0]: 2.239881e-03 [1.122595e-07] 
Layer 'conv4' biases: 9.998124e-01 [1.128881e-07] 
Layer 'conv5' weights[0]: 2.405836e-03 [2.046755e-06] 
Layer 'conv5' biases: 9.990184e-01 [2.224713e-06] 
Layer 'fc6' weights[0]: 6.654868e-03 [5.865955e-08] 
Layer 'fc6' biases: 9.999899e-01 [5.292546e-08] 
Layer 'fc7' weights[0]: 6.996777e-03 [1.391810e-07] 
Layer 'fc7' biases: 9.996979e-01 [1.697433e-07] 
Layer 'fc8' weights[0]: 4.749712e-03 [1.186504e-05] 
Layer 'fc8' biases: 2.653878e-02 [2.073587e-05] 
Train error last 800 batches: 0.657473
-------------------------------------------------------
Not saving because 0.395026 > 0.299667 (9.300: -1.18%)
======================================================= (2.352 sec)
32.661... logprob:  0.642652, 0.278646 (1.436 sec)
32.662... logprob:  0.722536, 0.316406 (1.425 sec)
32.663... logprob:  0.586711, 0.282552 (1.418 sec)
32.664... logprob:  0.497411, 0.221354 (1.434 sec)
32.665... logprob:  0.652276, 0.264323 (1.457 sec)
32.666... logprob:  0.650762, 0.309896 (1.460 sec)
32.667... logprob:  0.714607, 0.290365 (1.453 sec)
32.668... logprob:  0.711634, 0.319010 (1.442 sec)
32.669... logprob:  0.604206, 0.255208 (1.457 sec)
32.670... logprob:  0.618668, 0.278646 (1.433 sec)
32.671... logprob:  0.603023, 0.251302 (1.417 sec)
32.672... logprob:  0.695109, 0.283854 (1.428 sec)
32.673... logprob:  0.716487, 0.309896 (1.430 sec)
32.674... logprob:  0.714636, 0.295573 (1.435 sec)
32.675... logprob:  0.581620, 0.247396 (1.460 sec)
32.676... logprob:  0.734940, 0.298177 (1.450 sec)
32.677... logprob:  0.595239, 0.277344 (1.436 sec)
32.678... logprob:  0.701920, 0.303385 (1.475 sec)
32.679... logprob:  0.599679, 0.277344 (1.425 sec)
32.680... logprob:  0.569442, 0.272135 (1.423 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.411078, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.233694e-03 [1.117292e-07] 
Layer 'conv1' biases: 2.186756e-06 [2.773053e-11] 
Layer 'conv2' weights[0]: 2.229227e-03 [1.115099e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.725039e-10] 
Layer 'conv3' weights[0]: 2.228213e-03 [1.115691e-07] 
Layer 'conv3' biases: 3.627448e-05 [3.574811e-09] 
Layer 'conv4' weights[0]: 2.237634e-03 [1.121123e-07] 
Layer 'conv4' biases: 9.998131e-01 [1.252871e-07] 
Layer 'conv5' weights[0]: 2.404570e-03 [2.381098e-06] 
Layer 'conv5' biases: 9.989967e-01 [2.572309e-06] 
Layer 'fc6' weights[0]: 6.654186e-03 [6.024392e-08] 
Layer 'fc6' biases: 9.999897e-01 [5.549004e-08] 
Layer 'fc7' weights[0]: 6.996059e-03 [1.425712e-07] 
Layer 'fc7' biases: 9.996995e-01 [1.941145e-07] 
Layer 'fc8' weights[0]: 4.788811e-03 [1.235144e-05] 
Layer 'fc8' biases: 2.684778e-02 [2.503875e-05] 
Train error last 800 batches: 0.657456
-------------------------------------------------------
Not saving because 0.411078 > 0.299667 (9.300: -1.18%)
======================================================= (2.355 sec)
32.681... logprob:  0.596113, 0.244792 (1.437 sec)
32.682... logprob:  0.589645, 0.290365 (1.430 sec)
32.683... logprob:  0.572009, 0.244792 (1.424 sec)
32.684... logprob:  0.664512, 0.286458 (1.470 sec)
32.685... logprob:  0.547720, 0.256510 (1.438 sec)
32.686... logprob:  0.608040, 0.286458 (1.428 sec)
32.687... logprob:  0.477637, 0.207031 (1.476 sec)
32.688... logprob:  0.562809, 0.253906 (1.431 sec)
32.689... logprob:  0.622882, 0.265625 (1.421 sec)
32.690... logprob:  0.645832, 0.269531 (1.430 sec)
32.691... logprob:  0.725606, 0.319010 (1.426 sec)
32.692... logprob:  0.669705, 0.292969 (1.425 sec)
32.693... logprob:  0.644833, 0.277344 (1.510 sec)
32.694... logprob:  0.572517, 0.246094 (1.430 sec)
32.695... logprob:  0.633793, 0.278646 (1.437 sec)
32.696... logprob:  0.751640, 0.311198 (1.470 sec)
32.697... logprob:  0.648988, 0.256510 (1.427 sec)
32.698... logprob:  0.717520, 0.320312 (1.431 sec)
32.699... logprob:  0.666792, 0.304687 (1.425 sec)
32.700... logprob:  0.668410, 0.281250 (1.423 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.425020, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.231462e-03 [1.116020e-07] 
Layer 'conv1' biases: 2.186759e-06 [2.484762e-11] 
Layer 'conv2' weights[0]: 2.226991e-03 [1.113974e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.961561e-10] 
Layer 'conv3' weights[0]: 2.225964e-03 [1.114666e-07] 
Layer 'conv3' biases: 3.626725e-05 [4.035750e-09] 
Layer 'conv4' weights[0]: 2.235403e-03 [1.120169e-07] 
Layer 'conv4' biases: 9.998136e-01 [1.532702e-07] 
Layer 'conv5' weights[0]: 2.402941e-03 [2.711947e-06] 
Layer 'conv5' biases: 9.989557e-01 [2.969064e-06] 
Layer 'fc6' weights[0]: 6.653532e-03 [6.348796e-08] 
Layer 'fc6' biases: 9.999896e-01 [6.130649e-08] 
Layer 'fc7' weights[0]: 6.995356e-03 [1.519339e-07] 
Layer 'fc7' biases: 9.997018e-01 [2.153973e-07] 
Layer 'fc8' weights[0]: 4.861366e-03 [1.315021e-05] 
Layer 'fc8' biases: 2.746107e-02 [2.770490e-05] 
Train error last 800 batches: 0.657463
-------------------------------------------------------
Not saving because 0.425020 > 0.299667 (9.300: -1.18%)
======================================================= (2.349 sec)
32.701... logprob:  0.571861, 0.243490 (1.438 sec)
32.702... logprob:  0.786842, 0.322917 (1.483 sec)
32.703... logprob:  0.543549, 0.276042 (1.430 sec)
32.704... logprob:  0.597279, 0.290364 (1.443 sec)
32.705... logprob:  0.574169, 0.270833 (1.464 sec)
32.706... logprob:  0.711456, 0.299479 (1.430 sec)
32.707... logprob:  0.615102, 0.268229 (1.431 sec)
32.708... logprob:  0.590945, 0.243490 (1.427 sec)
32.709... logprob:  0.667900, 0.305990 (1.415 sec)
32.710... logprob:  0.728598, 0.337240 (1.433 sec)
32.711... logprob:  0.544468, 0.225260 (1.458 sec)
32.712... logprob:  0.643588, 0.309896 (1.446 sec)
32.713... logprob:  0.714227, 0.277344 (1.446 sec)
32.714... logprob:  0.697295, 0.286458 (1.451 sec)
32.715... logprob:  0.674568, 0.311198 (1.451 sec)
32.716... logprob:  0.554452, 0.235677 (1.434 sec)
32.717... logprob:  0.697377, 0.294271 (1.419 sec)
32.718... logprob:  0.674569, 0.270833 (1.426 sec)
32.719... logprob:  0.673832, 0.307292 (1.431 sec)
32.720... logprob:  0.686414, 0.269531 (1.439 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.515869, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.229229e-03 [1.114392e-07] 
Layer 'conv1' biases: 2.186771e-06 [3.516588e-11] 
Layer 'conv2' weights[0]: 2.224765e-03 [1.112502e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.125166e-10] 
Layer 'conv3' weights[0]: 2.223751e-03 [1.114648e-07] 
Layer 'conv3' biases: 3.628210e-05 [5.866871e-09] 
Layer 'conv4' weights[0]: 2.233175e-03 [1.120663e-07] 
Layer 'conv4' biases: 9.998116e-01 [2.173595e-07] 
Layer 'conv5' weights[0]: 2.399601e-03 [4.115516e-06] 
Layer 'conv5' biases: 9.989908e-01 [4.532058e-06] 
Layer 'fc6' weights[0]: 6.652851e-03 [8.365393e-08] 
Layer 'fc6' biases: 9.999897e-01 [8.833839e-08] 
Layer 'fc7' weights[0]: 6.994667e-03 [2.192782e-07] 
Layer 'fc7' biases: 9.996989e-01 [4.118126e-07] 
Layer 'fc8' weights[0]: 4.779438e-03 [2.232306e-05] 
Layer 'fc8' biases: 2.685328e-02 [7.561490e-05] 
Train error last 800 batches: 0.656817
-------------------------------------------------------
Not saving because 0.515869 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
32.721... logprob:  0.655000, 0.256510 (1.464 sec)
32.722... logprob:  0.681511, 0.326823 (1.455 sec)
32.723... logprob:  0.746726, 0.311198 (1.437 sec)
32.724... logprob:  0.641893, 0.292969 (1.465 sec)
32.725... logprob:  0.693127, 0.307292 (1.429 sec)
32.726... logprob:  0.600778, 0.276042 (1.419 sec)
32.727... logprob:  0.618374, 0.279948 (1.427 sec)
32.728... logprob:  0.662271, 0.300781 (1.431 sec)
32.729... logprob:  0.561572, 0.244792 (1.428 sec)
32.730... logprob:  0.730006, 0.317708 (1.469 sec)
32.731... logprob:  0.639254, 0.283854 (1.466 sec)
32.732... logprob:  0.578788, 0.266927 (1.423 sec)
32.733... logprob:  0.707565, 0.312500 (1.482 sec)
32.734... logprob:  0.533696, 0.223958 (1.424 sec)
32.735... logprob:  0.658107, 0.289062 (1.426 sec)
32.736... logprob:  0.864943, 0.381510 (1.430 sec)
32.737... logprob:  0.810955, 0.329427 (1.426 sec)
32.738... logprob:  0.655107, 0.277344 (1.433 sec)
32.739... logprob:  0.821600, 0.335938 (1.478 sec)
32.740... logprob:  0.554064, 0.243490 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.429501, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.227005e-03 [1.113630e-07] 
Layer 'conv1' biases: 2.186893e-06 [2.489555e-11] 
Layer 'conv2' weights[0]: 2.222539e-03 [1.111567e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.206059e-10] 
Layer 'conv3' weights[0]: 2.221521e-03 [1.112300e-07] 
Layer 'conv3' biases: 3.629504e-05 [4.154771e-09] 
Layer 'conv4' weights[0]: 2.230933e-03 [1.117606e-07] 
Layer 'conv4' biases: 9.998115e-01 [1.352738e-07] 
Layer 'conv5' weights[0]: 2.397731e-03 [2.344610e-06] 
Layer 'conv5' biases: 9.990166e-01 [2.540408e-06] 
Layer 'fc6' weights[0]: 6.652141e-03 [6.201269e-08] 
Layer 'fc6' biases: 9.999897e-01 [5.786412e-08] 
Layer 'fc7' weights[0]: 6.993967e-03 [1.485404e-07] 
Layer 'fc7' biases: 9.996965e-01 [1.958166e-07] 
Layer 'fc8' weights[0]: 4.727575e-03 [1.256590e-05] 
Layer 'fc8' biases: 2.641028e-02 [2.598940e-05] 
Train error last 800 batches: 0.656871
-------------------------------------------------------
Not saving because 0.429501 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
32.741... logprob:  0.583745, 0.253906 (1.441 sec)
32.742... logprob:  0.640362, 0.277344 (1.477 sec)
32.743... logprob:  0.579332, 0.246094 (1.431 sec)
32.744... logprob:  0.682903, 0.277344 (1.424 sec)
32.745... logprob:  0.623825, 0.277344 (1.431 sec)
32.746... logprob:  0.670605, 0.283854 (1.424 sec)
32.747... logprob:  0.682028, 0.319010 (1.428 sec)
32.748... logprob:  0.592228, 0.290365 (1.476 sec)
32.749... logprob:  0.624093, 0.255208 (1.432 sec)
32.750... logprob:  0.698498, 0.300781 (1.437 sec)
32.751... logprob:  0.622804, 0.298177 (1.482 sec)
32.752... logprob:  0.712092, 0.329427 (1.432 sec)
32.753... logprob:  0.616494, 0.255208 (1.431 sec)
32.754... logprob:  0.740111, 0.313802 (1.424 sec)
32.755... logprob:  0.724298, 0.291667 (1.423 sec)
32.756... logprob:  0.710257, 0.322917 (1.427 sec)
32.757... logprob:  0.733624, 0.294271 (1.467 sec)
32.758... logprob:  0.644071, 0.261719 (1.438 sec)
32.759... logprob:  0.683953, 0.290365 (1.447 sec)
32.760... logprob:  0.641783, 0.298177 (1.450 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.506829, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.224772e-03 [1.112502e-07] 
Layer 'conv1' biases: 2.186973e-06 [2.514038e-11] 
Layer 'conv2' weights[0]: 2.220316e-03 [1.110602e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.261949e-10] 
Layer 'conv3' weights[0]: 2.219308e-03 [1.111405e-07] 
Layer 'conv3' biases: 3.629815e-05 [4.396887e-09] 
Layer 'conv4' weights[0]: 2.228710e-03 [1.116443e-07] 
Layer 'conv4' biases: 9.998120e-01 [1.412718e-07] 
Layer 'conv5' weights[0]: 2.396285e-03 [2.342235e-06] 
Layer 'conv5' biases: 9.989941e-01 [2.601204e-06] 
Layer 'fc6' weights[0]: 6.651440e-03 [6.176617e-08] 
Layer 'fc6' biases: 9.999898e-01 [5.801712e-08] 
Layer 'fc7' weights[0]: 6.993271e-03 [1.488026e-07] 
Layer 'fc7' biases: 9.996982e-01 [1.979263e-07] 
Layer 'fc8' weights[0]: 4.769473e-03 [1.311286e-05] 
Layer 'fc8' biases: 2.677808e-02 [2.329146e-05] 
Train error last 800 batches: 0.656956
-------------------------------------------------------
Not saving because 0.506829 > 0.299667 (9.300: -1.18%)
======================================================= (2.382 sec)
32.761... logprob:  0.656085, 0.285156 (1.448 sec)
32.762... logprob:  0.777021, 0.341146 (1.439 sec)
32.763... logprob:  0.728064, 0.320312 (1.432 sec)
32.764... logprob:  0.606914, 0.255208 (1.426 sec)
32.765... logprob:  0.510924, 0.229167 (1.433 sec)
32.766... logprob:  0.673638, 0.295573 (1.454 sec)
32.767... logprob:  0.553257, 0.257812 (1.451 sec)
32.768... logprob:  0.643054, 0.300781 (1.463 sec)
32.769... logprob:  0.592948, 0.286458 (1.497 sec)
32.770... logprob:  0.668616, 0.300781 (1.472 sec)
32.771... logprob:  0.716379, 0.302083 (1.453 sec)
32.772... logprob:  0.658328, 0.266927 (1.437 sec)
32.773... logprob:  0.805288, 0.363281 (1.443 sec)
32.774... logprob:  0.664922, 0.312500 (1.459 sec)
32.775... logprob:  0.584855, 0.264323 (1.456 sec)
32.776... logprob:  0.618120, 0.286458 (1.476 sec)
32.777... logprob:  0.664576, 0.305989 (1.473 sec)
32.778... logprob:  0.611855, 0.283854 (1.457 sec)
32.779... logprob:  0.667206, 0.300781 (1.481 sec)
32.780... logprob:  0.654370, 0.268229 (1.451 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.567316, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.222541e-03 [1.111853e-07] 
Layer 'conv1' biases: 2.187142e-06 [2.598004e-11] 
Layer 'conv2' weights[0]: 2.218115e-03 [1.109608e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.136063e-10] 
Layer 'conv3' weights[0]: 2.217078e-03 [1.110565e-07] 
Layer 'conv3' biases: 3.630479e-05 [4.451071e-09] 
Layer 'conv4' weights[0]: 2.226481e-03 [1.116235e-07] 
Layer 'conv4' biases: 9.998120e-01 [1.499200e-07] 
Layer 'conv5' weights[0]: 2.394851e-03 [2.537682e-06] 
Layer 'conv5' biases: 9.989768e-01 [2.738664e-06] 
Layer 'fc6' weights[0]: 6.650739e-03 [5.965675e-08] 
Layer 'fc6' biases: 9.999898e-01 [5.507356e-08] 
Layer 'fc7' weights[0]: 6.992570e-03 [1.401080e-07] 
Layer 'fc7' biases: 9.996991e-01 [1.846154e-07] 
Layer 'fc8' weights[0]: 4.798289e-03 [1.197927e-05] 
Layer 'fc8' biases: 2.702103e-02 [2.346757e-05] 
Train error last 800 batches: 0.656788
-------------------------------------------------------
Not saving because 0.567316 > 0.299667 (9.300: -1.18%)
======================================================= (2.386 sec)
32.781... logprob:  0.584350, 0.272135 (1.443 sec)
32.782... logprob:  0.620008, 0.282552 (1.451 sec)
32.783... logprob:  0.683422, 0.259115 (1.453 sec)
32.784... logprob:  0.627342, 0.274740 (1.449 sec)
32.785... logprob:  0.814401, 0.345052 (1.480 sec)
32.786... logprob:  0.731018, 0.337240 (1.463 sec)
32.787... logprob:  0.807020, 0.329427 (1.454 sec)
32.788... logprob:  0.792386, 0.325521 (1.485 sec)
32.789... logprob:  0.559027, 0.248698 (1.446 sec)
32.790... logprob:  0.644216, 0.251302 (1.453 sec)
32.791... logprob:  0.687893, 0.304687 (1.440 sec)
32.792... logprob:  0.627007, 0.272135 (1.453 sec)
32.793... logprob:  0.582776, 0.268229 (1.448 sec)
32.794... logprob:  0.639834, 0.259115 (1.477 sec)
32.795... logprob:  0.758751, 0.307292 (1.466 sec)
32.796... logprob:  0.700063, 0.295573 (1.455 sec)
32.797... logprob:  0.573232, 0.255208 (1.493 sec)
32.798... logprob:  0.566853, 0.252604 (1.449 sec)
32.799... logprob:  0.603300, 0.229167 (1.438 sec)
32.800... logprob:  0.650949, 0.263021 (1.393 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.445727, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.220322e-03 [1.110101e-07] 
Layer 'conv1' biases: 2.187259e-06 [3.850176e-11] 
Layer 'conv2' weights[0]: 2.215880e-03 [1.108129e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.237163e-10] 
Layer 'conv3' weights[0]: 2.214857e-03 [1.109849e-07] 
Layer 'conv3' biases: 3.631693e-05 [5.286961e-09] 
Layer 'conv4' weights[0]: 2.224267e-03 [1.115596e-07] 
Layer 'conv4' biases: 9.998101e-01 [1.744188e-07] 
Layer 'conv5' weights[0]: 2.391738e-03 [2.536513e-06] 
Layer 'conv5' biases: 9.990015e-01 [2.682564e-06] 
Layer 'fc6' weights[0]: 6.650051e-03 [6.259848e-08] 
Layer 'fc6' biases: 9.999900e-01 [5.923826e-08] 
Layer 'fc7' weights[0]: 6.991853e-03 [1.531923e-07] 
Layer 'fc7' biases: 9.996973e-01 [2.131042e-07] 
Layer 'fc8' weights[0]: 4.760311e-03 [1.500525e-05] 
Layer 'fc8' biases: 2.674641e-02 [3.980140e-05] 
Train error last 800 batches: 0.657293
-------------------------------------------------------
Not saving because 0.445727 > 0.299667 (9.300: -1.18%)
======================================================= (2.375 sec)
33.1... logprob:  0.657872, 0.320312 (1.405 sec)
33.2... logprob:  0.666875, 0.299479 (1.451 sec)
33.3... logprob:  0.628647, 0.300781 (1.422 sec)
33.4... logprob:  0.647417, 0.287760 (1.407 sec)
33.5... logprob:  0.645641, 0.276042 (1.427 sec)
33.6... logprob:  0.736506, 0.325521 (1.394 sec)
33.7... logprob:  0.680237, 0.296875 (1.447 sec)
33.8... logprob:  0.656311, 0.294271 (1.390 sec)
33.9... logprob:  0.660109, 0.295573 (1.406 sec)
33.10... logprob:  0.581354, 0.246094 (1.405 sec)
33.11... logprob:  0.560137, 0.274740 (1.444 sec)
33.12... logprob:  0.717943, 0.347656 (1.398 sec)
33.13... logprob:  0.673726, 0.285156 (1.419 sec)
33.14... logprob:  0.725220, 0.307292 (1.402 sec)
33.15... logprob:  0.626023, 0.261719 (1.410 sec)
33.16... logprob:  0.664226, 0.264323 (1.399 sec)
33.17... logprob:  0.667645, 0.283854 (1.392 sec)
33.18... logprob:  0.519120, 0.256510 (1.392 sec)
33.19... logprob:  0.482124, 0.212240 (1.396 sec)
33.20... logprob:  0.611202, 0.287760 (1.394 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.310013, 0.039062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.218115e-03 [1.109995e-07] 
Layer 'conv1' biases: 2.187291e-06 [3.471371e-11] 
Layer 'conv2' weights[0]: 2.213666e-03 [1.107551e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.864230e-10] 
Layer 'conv3' weights[0]: 2.212641e-03 [1.108915e-07] 
Layer 'conv3' biases: 3.630855e-05 [5.285929e-09] 
Layer 'conv4' weights[0]: 2.222016e-03 [1.115647e-07] 
Layer 'conv4' biases: 9.998096e-01 [1.771154e-07] 
Layer 'conv5' weights[0]: 2.389334e-03 [3.054572e-06] 
Layer 'conv5' biases: 9.989885e-01 [3.374278e-06] 
Layer 'fc6' weights[0]: 6.649344e-03 [6.220850e-08] 
Layer 'fc6' biases: 9.999900e-01 [5.829310e-08] 
Layer 'fc7' weights[0]: 6.991147e-03 [1.477981e-07] 
Layer 'fc7' biases: 9.996985e-01 [2.245691e-07] 
Layer 'fc8' weights[0]: 4.792497e-03 [1.333103e-05] 
Layer 'fc8' biases: 2.704422e-02 [3.949814e-05] 
Train error last 800 batches: 0.657003
-------------------------------------------------------
Not saving because 0.310013 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
33.21... logprob:  0.689173, 0.313802 (1.407 sec)
33.22... logprob:  0.679314, 0.300781 (1.413 sec)
33.23... logprob:  0.622816, 0.279948 (1.413 sec)
33.24... logprob:  0.636026, 0.303385 (1.411 sec)
33.25... logprob:  0.576671, 0.257812 (1.401 sec)
33.26... logprob:  0.636771, 0.273438 (1.440 sec)
33.27... logprob:  0.614102, 0.266927 (1.383 sec)
33.28... logprob:  0.715245, 0.307292 (1.404 sec)
33.29... logprob:  0.625174, 0.270833 (1.418 sec)
33.30... logprob:  0.653636, 0.295573 (1.407 sec)
33.31... logprob:  0.658076, 0.292969 (1.396 sec)
33.32... logprob:  0.627270, 0.281250 (1.384 sec)
33.33... logprob:  0.660538, 0.270833 (1.438 sec)
33.34... logprob:  0.687156, 0.303385 (1.387 sec)
33.35... logprob:  0.530225, 0.255208 (1.391 sec)
33.36... logprob:  0.675676, 0.335937 (1.395 sec)
33.37... logprob:  0.640139, 0.315104 (1.403 sec)
33.38... logprob:  0.596439, 0.264323 (1.392 sec)
33.39... logprob:  0.751682, 0.305990 (1.429 sec)
33.40... logprob:  0.659091, 0.278646 (1.400 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.450652, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.215898e-03 [1.108443e-07] 
Layer 'conv1' biases: 2.187339e-06 [2.891691e-11] 
Layer 'conv2' weights[0]: 2.211439e-03 [1.106209e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.505484e-10] 
Layer 'conv3' weights[0]: 2.210431e-03 [1.108296e-07] 
Layer 'conv3' biases: 3.631998e-05 [5.736630e-09] 
Layer 'conv4' weights[0]: 2.219796e-03 [1.113444e-07] 
Layer 'conv4' biases: 9.998095e-01 [1.897406e-07] 
Layer 'conv5' weights[0]: 2.387149e-03 [2.650364e-06] 
Layer 'conv5' biases: 9.989614e-01 [2.843592e-06] 
Layer 'fc6' weights[0]: 6.648651e-03 [6.571224e-08] 
Layer 'fc6' biases: 9.999899e-01 [6.410724e-08] 
Layer 'fc7' weights[0]: 6.990439e-03 [1.655523e-07] 
Layer 'fc7' biases: 9.996999e-01 [2.642546e-07] 
Layer 'fc8' weights[0]: 4.835680e-03 [1.843363e-05] 
Layer 'fc8' biases: 2.739330e-02 [6.096522e-05] 
Train error last 800 batches: 0.656392
-------------------------------------------------------
Not saving because 0.450652 > 0.299667 (9.300: -1.18%)
======================================================= (2.349 sec)
33.41... logprob:  0.726435, 0.325521 (1.420 sec)
33.42... logprob:  0.646324, 0.265625 (1.409 sec)
33.43... logprob:  0.669260, 0.281250 (1.401 sec)
33.44... logprob:  0.651748, 0.255208 (1.430 sec)
33.45... logprob:  0.619408, 0.252604 (1.383 sec)
33.46... logprob:  0.688761, 0.328125 (1.417 sec)
33.47... logprob:  0.508604, 0.205729 (1.388 sec)
33.48... logprob:  0.654470, 0.282552 (1.416 sec)
33.49... logprob:  0.712999, 0.338542 (1.408 sec)
33.50... logprob:  0.536911, 0.252604 (1.416 sec)
33.51... logprob:  0.763666, 0.339844 (1.415 sec)
33.52... logprob:  0.716085, 0.281250 (1.532 sec)
33.53... logprob:  0.489671, 0.200521 (1.438 sec)
33.54... logprob:  0.656531, 0.260417 (1.381 sec)
33.55... logprob:  0.523643, 0.222656 (1.391 sec)
33.56... logprob:  0.639401, 0.282552 (1.396 sec)
33.57... logprob:  0.728229, 0.305989 (1.426 sec)
33.58... logprob:  0.575333, 0.246094 (1.400 sec)
33.59... logprob:  0.617928, 0.283854 (1.456 sec)
33.60... logprob:  0.844089, 0.354167 (1.414 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.501335, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.213675e-03 [1.107151e-07] 
Layer 'conv1' biases: 2.187455e-06 [3.126775e-11] 
Layer 'conv2' weights[0]: 2.209240e-03 [1.105035e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.659021e-10] 
Layer 'conv3' weights[0]: 2.208239e-03 [1.106808e-07] 
Layer 'conv3' biases: 3.635227e-05 [5.351136e-09] 
Layer 'conv4' weights[0]: 2.217584e-03 [1.111805e-07] 
Layer 'conv4' biases: 9.998072e-01 [1.763062e-07] 
Layer 'conv5' weights[0]: 2.383429e-03 [2.716009e-06] 
Layer 'conv5' biases: 9.989742e-01 [2.977260e-06] 
Layer 'fc6' weights[0]: 6.647953e-03 [6.234716e-08] 
Layer 'fc6' biases: 9.999900e-01 [5.935813e-08] 
Layer 'fc7' weights[0]: 6.989710e-03 [1.498847e-07] 
Layer 'fc7' biases: 9.996986e-01 [2.062969e-07] 
Layer 'fc8' weights[0]: 4.802506e-03 [1.244904e-05] 
Layer 'fc8' biases: 2.710379e-02 [2.571788e-05] 
Train error last 800 batches: 0.656191
-------------------------------------------------------
Not saving because 0.501335 > 0.299667 (9.300: -1.18%)
======================================================= (2.346 sec)
33.61... logprob:  0.689687, 0.287760 (1.431 sec)
33.62... logprob:  0.659308, 0.291667 (1.457 sec)
33.63... logprob:  0.690783, 0.292969 (1.437 sec)
33.64... logprob:  0.675712, 0.277344 (1.405 sec)
33.65... logprob:  0.564500, 0.260417 (1.392 sec)
33.66... logprob:  0.595086, 0.287760 (1.436 sec)
33.67... logprob:  0.542345, 0.250000 (1.387 sec)
33.68... logprob:  0.607821, 0.244792 (1.389 sec)
33.69... logprob:  0.726119, 0.302083 (1.420 sec)
33.70... logprob:  0.589915, 0.253906 (1.414 sec)
33.71... logprob:  0.621743, 0.287760 (1.457 sec)
33.72... logprob:  0.732389, 0.292969 (1.398 sec)
33.73... logprob:  0.671976, 0.286458 (1.416 sec)
33.74... logprob:  0.578140, 0.229167 (1.410 sec)
33.75... logprob:  0.652355, 0.283854 (1.407 sec)
33.76... logprob:  0.727704, 0.319010 (1.429 sec)
33.77... logprob:  0.606604, 0.285156 (1.423 sec)
33.78... logprob:  0.681195, 0.276042 (1.447 sec)
33.79... logprob:  0.642197, 0.248698 (1.396 sec)
33.80... logprob:  0.659461, 0.281250 (1.419 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.446398, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.211466e-03 [1.105769e-07] 
Layer 'conv1' biases: 2.187302e-06 [2.665676e-11] 
Layer 'conv2' weights[0]: 2.207037e-03 [1.103774e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.985533e-10] 
Layer 'conv3' weights[0]: 2.206014e-03 [1.104739e-07] 
Layer 'conv3' biases: 3.637558e-05 [4.309506e-09] 
Layer 'conv4' weights[0]: 2.215379e-03 [1.109947e-07] 
Layer 'conv4' biases: 9.998062e-01 [1.348114e-07] 
Layer 'conv5' weights[0]: 2.380725e-03 [2.506471e-06] 
Layer 'conv5' biases: 9.989889e-01 [2.618792e-06] 
Layer 'fc6' weights[0]: 6.647259e-03 [6.194400e-08] 
Layer 'fc6' biases: 9.999899e-01 [5.856895e-08] 
Layer 'fc7' weights[0]: 6.989023e-03 [1.489478e-07] 
Layer 'fc7' biases: 9.996968e-01 [1.974311e-07] 
Layer 'fc8' weights[0]: 4.772736e-03 [1.282815e-05] 
Layer 'fc8' biases: 2.683813e-02 [2.094920e-05] 
Train error last 800 batches: 0.656148
-------------------------------------------------------
Not saving because 0.446398 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
33.81... logprob:  0.602280, 0.242187 (1.417 sec)
33.82... logprob:  0.497819, 0.236979 (1.422 sec)
33.83... logprob:  0.639829, 0.273438 (1.395 sec)
33.84... logprob:  0.766098, 0.313802 (1.456 sec)
33.85... logprob:  0.644962, 0.272135 (1.418 sec)
33.86... logprob:  0.663898, 0.242187 (1.414 sec)
33.87... logprob:  0.822386, 0.343750 (1.408 sec)
33.88... logprob:  0.688896, 0.281250 (1.404 sec)
33.89... logprob:  0.548669, 0.239583 (1.424 sec)
33.90... logprob:  0.774653, 0.334635 (1.387 sec)
33.91... logprob:  0.646387, 0.295573 (1.388 sec)
33.92... logprob:  0.766652, 0.345052 (1.396 sec)
33.93... logprob:  0.777043, 0.321615 (1.393 sec)
33.94... logprob:  0.669081, 0.287760 (1.386 sec)
33.95... logprob:  0.633380, 0.277344 (1.397 sec)
33.96... logprob:  0.717259, 0.302083 (1.403 sec)
33.97... logprob:  0.666270, 0.294271 (1.392 sec)
33.98... logprob:  0.638242, 0.283854 (1.430 sec)
33.99... logprob:  0.687251, 0.320312 (1.400 sec)
33.100... logprob:  0.595374, 0.252604 (1.396 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.465149, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.209261e-03 [1.104635e-07] 
Layer 'conv1' biases: 2.187438e-06 [3.234560e-11] 
Layer 'conv2' weights[0]: 2.204827e-03 [1.102786e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.525305e-10] 
Layer 'conv3' weights[0]: 2.203831e-03 [1.103752e-07] 
Layer 'conv3' biases: 3.638150e-05 [4.276910e-09] 
Layer 'conv4' weights[0]: 2.213158e-03 [1.108906e-07] 
Layer 'conv4' biases: 9.998058e-01 [1.519429e-07] 
Layer 'conv5' weights[0]: 2.378452e-03 [1.973131e-06] 
Layer 'conv5' biases: 9.990169e-01 [2.077880e-06] 
Layer 'fc6' weights[0]: 6.646569e-03 [5.861519e-08] 
Layer 'fc6' biases: 9.999902e-01 [5.348159e-08] 
Layer 'fc7' weights[0]: 6.988319e-03 [1.392461e-07] 
Layer 'fc7' biases: 9.996946e-01 [1.708384e-07] 
Layer 'fc8' weights[0]: 4.708825e-03 [1.166920e-05] 
Layer 'fc8' biases: 2.634157e-02 [1.588241e-05] 
Train error last 800 batches: 0.656133
-------------------------------------------------------
Not saving because 0.465149 > 0.299667 (9.300: -1.18%)
======================================================= (2.378 sec)
33.101... logprob:  0.567290, 0.252604 (1.451 sec)
33.102... logprob:  0.757821, 0.308594 (1.390 sec)
33.103... logprob:  0.682636, 0.299479 (1.399 sec)
33.104... logprob:  0.640826, 0.295573 (1.399 sec)
33.105... logprob:  0.783150, 0.332031 (1.393 sec)
33.106... logprob:  0.610297, 0.291667 (1.386 sec)
33.107... logprob:  0.611732, 0.270833 (1.434 sec)
33.108... logprob:  0.802246, 0.355469 (1.397 sec)
33.109... logprob:  0.554881, 0.260417 (1.394 sec)
33.110... logprob:  0.653544, 0.282552 (1.386 sec)
33.111... logprob:  0.611113, 0.277344 (1.392 sec)
33.112... logprob:  0.622233, 0.290365 (1.395 sec)
33.113... logprob:  0.619624, 0.278646 (1.393 sec)
33.114... logprob:  0.633405, 0.296875 (1.425 sec)
33.115... logprob:  0.716684, 0.278646 (1.408 sec)
33.116... logprob:  0.512717, 0.234375 (1.397 sec)
33.117... logprob:  0.634321, 0.283854 (1.444 sec)
33.118... logprob:  0.668667, 0.298177 (1.382 sec)
33.119... logprob:  0.639331, 0.302083 (1.392 sec)
33.120... logprob:  0.747246, 0.312500 (1.394 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.506029, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.207048e-03 [1.103849e-07] 
Layer 'conv1' biases: 2.187623e-06 [2.942405e-11] 
Layer 'conv2' weights[0]: 2.202618e-03 [1.101800e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.463519e-10] 
Layer 'conv3' weights[0]: 2.201607e-03 [1.101984e-07] 
Layer 'conv3' biases: 3.637853e-05 [3.679755e-09] 
Layer 'conv4' weights[0]: 2.210945e-03 [1.107339e-07] 
Layer 'conv4' biases: 9.998052e-01 [1.181980e-07] 
Layer 'conv5' weights[0]: 2.376032e-03 [2.471955e-06] 
Layer 'conv5' biases: 9.989855e-01 [2.608026e-06] 
Layer 'fc6' weights[0]: 6.645874e-03 [6.201973e-08] 
Layer 'fc6' biases: 9.999900e-01 [5.822934e-08] 
Layer 'fc7' weights[0]: 6.987592e-03 [1.455733e-07] 
Layer 'fc7' biases: 9.996976e-01 [1.958519e-07] 
Layer 'fc8' weights[0]: 4.784123e-03 [1.210506e-05] 
Layer 'fc8' biases: 2.694777e-02 [2.672126e-05] 
Train error last 800 batches: 0.656430
-------------------------------------------------------
Not saving because 0.506029 > 0.299667 (9.300: -1.18%)
======================================================= (2.386 sec)
33.121... logprob:  0.618845, 0.281250 (1.396 sec)
33.122... logprob:  0.708955, 0.311198 (1.448 sec)
33.123... logprob:  0.557930, 0.233073 (1.387 sec)
33.124... logprob:  0.612310, 0.273437 (1.399 sec)
33.125... logprob:  0.753299, 0.334635 (1.393 sec)
33.126... logprob:  0.727080, 0.325521 (1.385 sec)
33.127... logprob:  0.639374, 0.279948 (1.391 sec)
33.128... logprob:  0.748326, 0.332031 (1.409 sec)
33.129... logprob:  0.774650, 0.312500 (1.415 sec)
33.130... logprob:  0.608969, 0.264323 (1.406 sec)
33.131... logprob:  0.685146, 0.315104 (1.403 sec)
33.132... logprob:  0.714009, 0.303385 (1.429 sec)
33.133... logprob:  0.687926, 0.321615 (1.382 sec)
33.134... logprob:  0.575595, 0.251302 (1.387 sec)
33.135... logprob:  0.720162, 0.317708 (1.394 sec)
33.136... logprob:  0.674264, 0.298177 (1.393 sec)
33.137... logprob:  0.632247, 0.285156 (1.390 sec)
33.138... logprob:  0.614000, 0.279948 (1.436 sec)
33.139... logprob:  0.641327, 0.291667 (1.392 sec)
33.140... logprob:  0.786786, 0.377604 (1.405 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.476262, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.204844e-03 [1.102938e-07] 
Layer 'conv1' biases: 2.187701e-06 [2.329581e-11] 
Layer 'conv2' weights[0]: 2.200412e-03 [1.100706e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.595721e-10] 
Layer 'conv3' weights[0]: 2.199394e-03 [1.101233e-07] 
Layer 'conv3' biases: 3.639561e-05 [3.688570e-09] 
Layer 'conv4' weights[0]: 2.208724e-03 [1.106118e-07] 
Layer 'conv4' biases: 9.998059e-01 [1.196544e-07] 
Layer 'conv5' weights[0]: 2.374709e-03 [1.965471e-06] 
Layer 'conv5' biases: 9.989856e-01 [2.065094e-06] 
Layer 'fc6' weights[0]: 6.645201e-03 [5.977516e-08] 
Layer 'fc6' biases: 9.999900e-01 [5.569025e-08] 
Layer 'fc7' weights[0]: 6.986931e-03 [1.393412e-07] 
Layer 'fc7' biases: 9.996970e-01 [1.849489e-07] 
Layer 'fc8' weights[0]: 4.789388e-03 [1.277057e-05] 
Layer 'fc8' biases: 2.705140e-02 [3.016084e-05] 
Train error last 800 batches: 0.656134
-------------------------------------------------------
Not saving because 0.476262 > 0.299667 (9.300: -1.18%)
======================================================= (2.363 sec)
33.141... logprob:  0.637104, 0.290364 (1.444 sec)
33.142... logprob:  0.613418, 0.268229 (1.395 sec)
33.143... logprob:  0.617554, 0.279948 (1.421 sec)
33.144... logprob:  0.648805, 0.289062 (1.411 sec)
33.145... logprob:  0.545392, 0.256510 (1.415 sec)
33.146... logprob:  0.686037, 0.304688 (1.403 sec)
33.147... logprob:  0.521656, 0.235677 (1.427 sec)
33.148... logprob:  0.743303, 0.315104 (1.393 sec)
33.149... logprob:  0.637929, 0.270833 (1.397 sec)
33.150... logprob:  0.504156, 0.214844 (1.392 sec)
33.151... logprob:  0.629547, 0.278646 (1.392 sec)
33.152... logprob:  0.908677, 0.356771 (1.384 sec)
33.153... logprob:  0.632275, 0.269531 (1.436 sec)
33.154... logprob:  0.711931, 0.319010 (1.395 sec)
33.155... logprob:  0.638681, 0.296875 (1.400 sec)
33.156... logprob:  0.555211, 0.261719 (1.432 sec)
33.157... logprob:  0.555822, 0.263021 (1.392 sec)
33.158... logprob:  0.723143, 0.303385 (1.398 sec)
33.159... logprob:  0.675767, 0.294271 (1.389 sec)
33.160... logprob:  0.704089, 0.339844 (1.389 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.454909, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.202637e-03 [1.101771e-07] 
Layer 'conv1' biases: 2.187781e-06 [2.253818e-11] 
Layer 'conv2' weights[0]: 2.198219e-03 [1.099553e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.485970e-10] 
Layer 'conv3' weights[0]: 2.197205e-03 [1.100221e-07] 
Layer 'conv3' biases: 3.640595e-05 [3.901266e-09] 
Layer 'conv4' weights[0]: 2.206519e-03 [1.105420e-07] 
Layer 'conv4' biases: 9.998060e-01 [1.172123e-07] 
Layer 'conv5' weights[0]: 2.372811e-03 [1.909591e-06] 
Layer 'conv5' biases: 9.989741e-01 [2.098415e-06] 
Layer 'fc6' weights[0]: 6.644521e-03 [5.648535e-08] 
Layer 'fc6' biases: 9.999902e-01 [5.110525e-08] 
Layer 'fc7' weights[0]: 6.986152e-03 [1.326889e-07] 
Layer 'fc7' biases: 9.996977e-01 [1.586121e-07] 
Layer 'fc8' weights[0]: 4.812489e-03 [1.052387e-05] 
Layer 'fc8' biases: 2.724174e-02 [9.946319e-06] 
Train error last 800 batches: 0.656126
-------------------------------------------------------
Not saving because 0.454909 > 0.299667 (9.300: -1.18%)
======================================================= (2.372 sec)
33.161... logprob:  0.618359, 0.294271 (1.417 sec)
33.162... logprob:  0.761612, 0.305990 (1.402 sec)
33.163... logprob:  0.711108, 0.291667 (1.420 sec)
33.164... logprob:  0.643688, 0.279948 (1.417 sec)
33.165... logprob:  0.768526, 0.329427 (1.414 sec)
33.166... logprob:  0.715699, 0.332031 (1.443 sec)
33.167... logprob:  0.554106, 0.240885 (1.430 sec)
33.168... logprob:  0.582990, 0.272135 (1.416 sec)
33.169... logprob:  0.661977, 0.277344 (1.454 sec)
33.170... logprob:  0.645399, 0.277344 (1.398 sec)
33.171... logprob:  0.639773, 0.281250 (1.411 sec)
33.172... logprob:  0.622786, 0.295573 (1.413 sec)
33.173... logprob:  0.617670, 0.279948 (1.421 sec)
33.174... logprob:  0.688470, 0.315104 (1.399 sec)
33.175... logprob:  0.749672, 0.312500 (1.464 sec)
33.176... logprob:  0.707213, 0.303385 (1.413 sec)
33.177... logprob:  0.545823, 0.261719 (1.426 sec)
33.178... logprob:  0.588994, 0.273437 (1.450 sec)
33.179... logprob:  0.611680, 0.277344 (1.407 sec)
33.180... logprob:  0.648845, 0.279948 (1.418 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.502797, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.200432e-03 [1.100658e-07] 
Layer 'conv1' biases: 2.187700e-06 [2.111419e-11] 
Layer 'conv2' weights[0]: 2.196027e-03 [1.098531e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.706472e-10] 
Layer 'conv3' weights[0]: 2.195013e-03 [1.099344e-07] 
Layer 'conv3' biases: 3.641103e-05 [4.081009e-09] 
Layer 'conv4' weights[0]: 2.204317e-03 [1.105025e-07] 
Layer 'conv4' biases: 9.998085e-01 [1.367490e-07] 
Layer 'conv5' weights[0]: 2.372975e-03 [2.445878e-06] 
Layer 'conv5' biases: 9.989861e-01 [2.663797e-06] 
Layer 'fc6' weights[0]: 6.643809e-03 [6.049324e-08] 
Layer 'fc6' biases: 9.999900e-01 [5.633620e-08] 
Layer 'fc7' weights[0]: 6.985520e-03 [1.449048e-07] 
Layer 'fc7' biases: 9.996970e-01 [2.014555e-07] 
Layer 'fc8' weights[0]: 4.782902e-03 [1.365650e-05] 
Layer 'fc8' biases: 2.706533e-02 [3.891830e-05] 
Train error last 800 batches: 0.655544
-------------------------------------------------------
Not saving because 0.502797 > 0.299667 (9.300: -1.18%)
======================================================= (2.355 sec)
33.181... logprob:  0.725023, 0.304687 (1.415 sec)
33.182... logprob:  0.591118, 0.273437 (1.413 sec)
33.183... logprob:  0.601531, 0.273437 (1.412 sec)
33.184... logprob:  0.757189, 0.325521 (1.422 sec)
33.185... logprob:  0.560846, 0.255208 (1.390 sec)
33.186... logprob:  0.599092, 0.255208 (1.395 sec)
33.187... logprob:  0.794959, 0.311198 (1.397 sec)
33.188... logprob:  0.655051, 0.294271 (1.390 sec)
33.189... logprob:  0.625508, 0.281250 (1.465 sec)
33.190... logprob:  0.662142, 0.305990 (1.431 sec)
33.191... logprob:  0.724279, 0.313802 (1.403 sec)
33.192... logprob:  0.682426, 0.265625 (1.410 sec)
33.193... logprob:  0.688445, 0.299479 (1.409 sec)
33.194... logprob:  0.667265, 0.303385 (1.413 sec)
33.195... logprob:  0.565859, 0.287760 (1.397 sec)
33.196... logprob:  0.608575, 0.270833 (1.385 sec)
33.197... logprob:  0.680947, 0.247396 (1.394 sec)
33.198... logprob:  0.605579, 0.261719 (1.394 sec)
33.199... logprob:  0.644991, 0.305990 (1.385 sec)
33.200... logprob:  0.681435, 0.286458 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.407443, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.198228e-03 [1.099620e-07] 
Layer 'conv1' biases: 2.187785e-06 [2.207974e-11] 
Layer 'conv2' weights[0]: 2.193834e-03 [1.097465e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.164119e-10] 
Layer 'conv3' weights[0]: 2.192811e-03 [1.097782e-07] 
Layer 'conv3' biases: 3.640019e-05 [3.662270e-09] 
Layer 'conv4' weights[0]: 2.202105e-03 [1.102933e-07] 
Layer 'conv4' biases: 9.998086e-01 [1.180661e-07] 
Layer 'conv5' weights[0]: 2.371181e-03 [2.251809e-06] 
Layer 'conv5' biases: 9.989809e-01 [2.391865e-06] 
Layer 'fc6' weights[0]: 6.643107e-03 [5.814205e-08] 
Layer 'fc6' biases: 9.999902e-01 [5.301016e-08] 
Layer 'fc7' weights[0]: 6.984835e-03 [1.343069e-07] 
Layer 'fc7' biases: 9.996968e-01 [1.553374e-07] 
Layer 'fc8' weights[0]: 4.789170e-03 [1.053314e-05] 
Layer 'fc8' biases: 2.714603e-02 [5.691992e-06] 
Train error last 800 batches: 0.655644
-------------------------------------------------------
Not saving because 0.407443 > 0.299667 (9.300: -1.18%)
======================================================= (2.420 sec)
33.201... logprob:  0.613726, 0.278646 (1.407 sec)
33.202... logprob:  0.788982, 0.317708 (1.400 sec)
33.203... logprob:  0.639625, 0.285156 (1.434 sec)
33.204... logprob:  0.677260, 0.276042 (1.381 sec)
33.205... logprob:  0.564133, 0.244792 (1.400 sec)
33.206... logprob:  0.627505, 0.287760 (1.401 sec)
33.207... logprob:  0.617453, 0.298177 (1.383 sec)
33.208... logprob:  0.840649, 0.386719 (1.402 sec)
33.209... logprob:  0.578856, 0.264323 (1.421 sec)
33.210... logprob:  0.701262, 0.299479 (1.407 sec)
33.211... logprob:  0.697530, 0.319010 (1.413 sec)
33.212... logprob:  0.698045, 0.320312 (1.407 sec)
33.213... logprob:  0.685516, 0.287760 (1.453 sec)
33.214... logprob:  0.595988, 0.286458 (1.417 sec)
33.215... logprob:  0.676696, 0.308594 (1.414 sec)
33.216... logprob:  0.770487, 0.321615 (1.459 sec)
33.217... logprob:  0.642049, 0.294271 (1.394 sec)
33.218... logprob:  0.665021, 0.295573 (1.414 sec)
33.219... logprob:  0.728827, 0.291667 (1.412 sec)
33.220... logprob:  0.696181, 0.307292 (1.412 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.481536, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.196040e-03 [1.098424e-07] 
Layer 'conv1' biases: 2.187889e-06 [2.088170e-11] 
Layer 'conv2' weights[0]: 2.191633e-03 [1.096245e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.483081e-10] 
Layer 'conv3' weights[0]: 2.190626e-03 [1.096691e-07] 
Layer 'conv3' biases: 3.641395e-05 [3.423295e-09] 
Layer 'conv4' weights[0]: 2.199918e-03 [1.101828e-07] 
Layer 'conv4' biases: 9.998080e-01 [1.293572e-07] 
Layer 'conv5' weights[0]: 2.368487e-03 [2.214393e-06] 
Layer 'conv5' biases: 9.989932e-01 [2.426655e-06] 
Layer 'fc6' weights[0]: 6.642429e-03 [6.208173e-08] 
Layer 'fc6' biases: 9.999902e-01 [5.849136e-08] 
Layer 'fc7' weights[0]: 6.984153e-03 [1.488192e-07] 
Layer 'fc7' biases: 9.996957e-01 [2.012871e-07] 
Layer 'fc8' weights[0]: 4.755324e-03 [1.228692e-05] 
Layer 'fc8' biases: 2.689614e-02 [2.241966e-05] 
Train error last 800 batches: 0.656067
-------------------------------------------------------
Not saving because 0.481536 > 0.299667 (9.300: -1.18%)
======================================================= (2.370 sec)
33.221... logprob:  0.609322, 0.281250 (1.404 sec)
33.222... logprob:  0.744653, 0.302083 (1.459 sec)
33.223... logprob:  0.770828, 0.347656 (1.426 sec)
33.224... logprob:  0.613710, 0.273438 (1.423 sec)
33.225... logprob:  0.655884, 0.307292 (1.441 sec)
33.226... logprob:  0.663422, 0.287760 (1.416 sec)
33.227... logprob:  0.653804, 0.264323 (1.408 sec)
33.228... logprob:  0.589262, 0.256510 (1.410 sec)
33.229... logprob:  0.651640, 0.307292 (1.409 sec)
33.230... logprob:  0.733932, 0.309896 (1.434 sec)
33.231... logprob:  0.731359, 0.325521 (1.397 sec)
33.232... logprob:  0.717669, 0.305990 (1.454 sec)
33.233... logprob:  0.644006, 0.274740 (1.419 sec)
33.234... logprob:  0.739747, 0.333333 (1.407 sec)
33.235... logprob:  0.648408, 0.307292 (1.461 sec)
33.236... logprob:  0.652721, 0.295573 (1.396 sec)
33.237... logprob:  0.602037, 0.269531 (1.413 sec)
33.238... logprob:  0.629162, 0.272135 (1.415 sec)
33.239... logprob:  0.691964, 0.299479 (1.421 sec)
33.240... logprob:  0.680123, 0.292969 (1.400 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.473649, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.193844e-03 [1.097433e-07] 
Layer 'conv1' biases: 2.187901e-06 [4.520426e-11] 
Layer 'conv2' weights[0]: 2.189440e-03 [1.095411e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.123975e-10] 
Layer 'conv3' weights[0]: 2.188424e-03 [1.099392e-07] 
Layer 'conv3' biases: 3.641232e-05 [7.433616e-09] 
Layer 'conv4' weights[0]: 2.197711e-03 [1.106497e-07] 
Layer 'conv4' biases: 9.998062e-01 [2.750021e-07] 
Layer 'conv5' weights[0]: 2.365048e-03 [2.447441e-06] 
Layer 'conv5' biases: 9.989966e-01 [2.581327e-06] 
Layer 'fc6' weights[0]: 6.641780e-03 [5.815400e-08] 
Layer 'fc6' biases: 9.999903e-01 [5.281406e-08] 
Layer 'fc7' weights[0]: 6.983431e-03 [1.387592e-07] 
Layer 'fc7' biases: 9.996951e-01 [1.728923e-07] 
Layer 'fc8' weights[0]: 4.732501e-03 [1.167746e-05] 
Layer 'fc8' biases: 2.672838e-02 [1.674246e-05] 
Train error last 800 batches: 0.655942
-------------------------------------------------------
Not saving because 0.473649 > 0.299667 (9.300: -1.18%)
======================================================= (2.362 sec)
33.241... logprob:  0.631038, 0.295573 (1.459 sec)
33.242... logprob:  0.534913, 0.220052 (1.427 sec)
33.243... logprob:  0.723970, 0.304687 (1.432 sec)
33.244... logprob:  0.688819, 0.321615 (1.439 sec)
33.245... logprob:  0.712165, 0.272135 (1.416 sec)
33.246... logprob:  0.638087, 0.269531 (1.409 sec)
33.247... logprob:  0.544641, 0.231771 (1.408 sec)
33.248... logprob:  0.561277, 0.252604 (1.411 sec)
33.249... logprob:  0.751334, 0.337240 (1.423 sec)
33.250... logprob:  0.839755, 0.329427 (1.398 sec)
33.251... logprob:  0.584001, 0.274740 (1.453 sec)
33.252... logprob:  0.589499, 0.243490 (1.420 sec)
33.253... logprob:  0.661181, 0.256510 (1.407 sec)
33.254... logprob:  0.673539, 0.294271 (1.472 sec)
33.255... logprob:  0.613660, 0.265625 (1.393 sec)
33.256... logprob:  0.590386, 0.251302 (1.415 sec)
33.257... logprob:  0.644831, 0.291667 (1.412 sec)
33.258... logprob:  0.713989, 0.335937 (1.421 sec)
33.259... logprob:  0.747245, 0.339844 (1.396 sec)
33.260... logprob:  0.621959, 0.281250 (1.457 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.469649, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.191638e-03 [1.096104e-07] 
Layer 'conv1' biases: 2.188080e-06 [4.035818e-11] 
Layer 'conv2' weights[0]: 2.187265e-03 [1.094145e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.739921e-10] 
Layer 'conv3' weights[0]: 2.186229e-03 [1.096007e-07] 
Layer 'conv3' biases: 3.637408e-05 [5.379820e-09] 
Layer 'conv4' weights[0]: 2.195515e-03 [1.101833e-07] 
Layer 'conv4' biases: 9.998047e-01 [1.841561e-07] 
Layer 'conv5' weights[0]: 2.361833e-03 [2.060821e-06] 
Layer 'conv5' biases: 9.989633e-01 [2.185232e-06] 
Layer 'fc6' weights[0]: 6.641101e-03 [5.876797e-08] 
Layer 'fc6' biases: 9.999900e-01 [5.462780e-08] 
Layer 'fc7' weights[0]: 6.982684e-03 [1.421206e-07] 
Layer 'fc7' biases: 9.996962e-01 [1.864536e-07] 
Layer 'fc8' weights[0]: 4.788023e-03 [1.259216e-05] 
Layer 'fc8' biases: 2.725345e-02 [2.808389e-05] 
Train error last 800 batches: 0.656395
-------------------------------------------------------
Not saving because 0.469649 > 0.299667 (9.300: -1.18%)
======================================================= (2.402 sec)
33.261... logprob:  0.580868, 0.260417 (1.430 sec)
33.262... logprob:  0.842614, 0.360677 (1.432 sec)
33.263... logprob:  0.708932, 0.312500 (1.444 sec)
33.264... logprob:  0.551907, 0.252604 (1.414 sec)
33.265... logprob:  0.652655, 0.304688 (1.416 sec)
33.266... logprob:  0.698584, 0.334635 (1.413 sec)
33.267... logprob:  0.682019, 0.294271 (1.411 sec)
33.268... logprob:  0.673084, 0.285156 (1.415 sec)
33.269... logprob:  0.749747, 0.337240 (1.409 sec)
33.270... logprob:  0.793245, 0.345052 (1.458 sec)
33.271... logprob:  0.782058, 0.334635 (1.418 sec)
33.272... logprob:  0.639527, 0.269531 (1.411 sec)
33.273... logprob:  0.695385, 0.291667 (1.466 sec)
33.274... logprob:  0.760769, 0.303385 (1.400 sec)
33.275... logprob:  0.722330, 0.346354 (1.414 sec)
33.276... logprob:  0.641513, 0.283854 (1.410 sec)
33.277... logprob:  0.712473, 0.320312 (1.424 sec)
33.278... logprob:  0.595843, 0.286458 (1.418 sec)
33.279... logprob:  0.566115, 0.285156 (1.454 sec)
33.280... logprob:  0.512827, 0.225260 (1.397 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.494715, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.189455e-03 [1.095267e-07] 
Layer 'conv1' biases: 2.188302e-06 [3.364244e-11] 
Layer 'conv2' weights[0]: 2.185060e-03 [1.093176e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.186725e-10] 
Layer 'conv3' weights[0]: 2.184047e-03 [1.094365e-07] 
Layer 'conv3' biases: 3.638951e-05 [4.775689e-09] 
Layer 'conv4' weights[0]: 2.193317e-03 [1.100446e-07] 
Layer 'conv4' biases: 9.998027e-01 [1.627206e-07] 
Layer 'conv5' weights[0]: 2.358258e-03 [2.817568e-06] 
Layer 'conv5' biases: 9.989923e-01 [3.164725e-06] 
Layer 'fc6' weights[0]: 6.640448e-03 [5.955076e-08] 
Layer 'fc6' biases: 9.999900e-01 [5.470007e-08] 
Layer 'fc7' weights[0]: 6.982017e-03 [1.388714e-07] 
Layer 'fc7' biases: 9.996943e-01 [1.940249e-07] 
Layer 'fc8' weights[0]: 4.726325e-03 [1.178108e-05] 
Layer 'fc8' biases: 2.679779e-02 [3.259941e-05] 
Train error last 800 batches: 0.656712
-------------------------------------------------------
Not saving because 0.494715 > 0.299667 (9.300: -1.18%)
======================================================= (2.355 sec)
33.281... logprob:  0.695480, 0.303385 (1.434 sec)
33.282... logprob:  0.698787, 0.287760 (1.413 sec)
33.283... logprob:  0.627861, 0.265625 (1.417 sec)
33.284... logprob:  0.590774, 0.255208 (1.413 sec)
33.285... logprob:  0.631967, 0.269531 (1.452 sec)
33.286... logprob:  0.679689, 0.260417 (1.433 sec)
33.287... logprob:  0.483468, 0.204427 (1.428 sec)
33.288... logprob:  0.539016, 0.242187 (1.430 sec)
33.289... logprob:  0.696640, 0.300781 (1.436 sec)
33.290... logprob:  0.688714, 0.286458 (1.402 sec)
33.291... logprob:  0.671830, 0.289062 (1.410 sec)
33.292... logprob:  0.686727, 0.311198 (1.411 sec)
33.293... logprob:  0.677730, 0.289062 (1.417 sec)
33.294... logprob:  0.603832, 0.277344 (1.393 sec)
33.295... logprob:  0.532442, 0.235677 (1.459 sec)
33.296... logprob:  0.601749, 0.308594 (1.414 sec)
33.297... logprob:  0.626742, 0.272135 (1.414 sec)
33.298... logprob:  0.710194, 0.315104 (1.460 sec)
33.299... logprob:  0.550639, 0.265625 (1.391 sec)
33.300... logprob:  0.622651, 0.269531 (1.418 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.571831, 0.171875 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.187264e-03 [1.094870e-07] 
Layer 'conv1' biases: 2.188278e-06 [3.777234e-11] 
Layer 'conv2' weights[0]: 2.182879e-03 [1.092375e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.832895e-10] 
Layer 'conv3' weights[0]: 2.181856e-03 [1.094340e-07] 
Layer 'conv3' biases: 3.637647e-05 [5.525789e-09] 
Layer 'conv4' weights[0]: 2.191127e-03 [1.100972e-07] 
Layer 'conv4' biases: 9.998024e-01 [1.924883e-07] 
Layer 'conv5' weights[0]: 2.355998e-03 [3.465002e-06] 
Layer 'conv5' biases: 9.989557e-01 [3.908808e-06] 
Layer 'fc6' weights[0]: 6.639754e-03 [6.711043e-08] 
Layer 'fc6' biases: 9.999899e-01 [6.545730e-08] 
Layer 'fc7' weights[0]: 6.981276e-03 [1.610444e-07] 
Layer 'fc7' biases: 9.996963e-01 [2.650131e-07] 
Layer 'fc8' weights[0]: 4.797596e-03 [1.487675e-05] 
Layer 'fc8' biases: 2.737299e-02 [4.494115e-05] 
Train error last 800 batches: 0.656447
-------------------------------------------------------
Not saving because 0.571831 > 0.299667 (9.300: -1.18%)
======================================================= (2.343 sec)
33.301... logprob:  0.662688, 0.307292 (1.419 sec)
33.302... logprob:  0.837164, 0.346354 (1.410 sec)
33.303... logprob:  0.693847, 0.281250 (1.399 sec)
33.304... logprob:  0.666851, 0.291667 (1.437 sec)
33.305... logprob:  0.644037, 0.291667 (1.432 sec)
33.306... logprob:  0.624011, 0.305990 (1.437 sec)
33.307... logprob:  0.632903, 0.260417 (1.430 sec)
33.308... logprob:  0.550997, 0.229167 (1.450 sec)
33.309... logprob:  0.732588, 0.308594 (1.409 sec)
33.310... logprob:  0.654127, 0.304688 (1.423 sec)
33.311... logprob:  0.678409, 0.300781 (1.417 sec)
33.312... logprob:  0.624615, 0.278646 (1.419 sec)
33.313... logprob:  0.634320, 0.266927 (1.415 sec)
33.314... logprob:  0.654619, 0.277344 (1.476 sec)
33.315... logprob:  0.585363, 0.266927 (1.433 sec)
33.316... logprob:  0.676048, 0.287760 (1.420 sec)
33.317... logprob:  0.611689, 0.266927 (1.478 sec)
33.318... logprob:  0.684258, 0.305990 (1.411 sec)
33.319... logprob:  0.674533, 0.304688 (1.446 sec)
33.320... logprob:  0.590104, 0.255208 (1.422 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.471682, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.185082e-03 [1.093330e-07] 
Layer 'conv1' biases: 2.188370e-06 [2.248689e-11] 
Layer 'conv2' weights[0]: 2.180696e-03 [1.090956e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.262776e-10] 
Layer 'conv3' weights[0]: 2.179683e-03 [1.091374e-07] 
Layer 'conv3' biases: 3.637804e-05 [3.223271e-09] 
Layer 'conv4' weights[0]: 2.188921e-03 [1.096210e-07] 
Layer 'conv4' biases: 9.998018e-01 [1.140740e-07] 
Layer 'conv5' weights[0]: 2.353649e-03 [2.186627e-06] 
Layer 'conv5' biases: 9.989569e-01 [2.335136e-06] 
Layer 'fc6' weights[0]: 6.639078e-03 [5.711204e-08] 
Layer 'fc6' biases: 9.999900e-01 [5.272977e-08] 
Layer 'fc7' weights[0]: 6.980600e-03 [1.346334e-07] 
Layer 'fc7' biases: 9.996961e-01 [1.643873e-07] 
Layer 'fc8' weights[0]: 4.790401e-03 [1.096840e-05] 
Layer 'fc8' biases: 2.734086e-02 [1.596485e-05] 
Train error last 800 batches: 0.656037
-------------------------------------------------------
Not saving because 0.471682 > 0.299667 (9.300: -1.18%)
======================================================= (2.369 sec)
33.321... logprob:  0.657259, 0.283854 (1.430 sec)
33.322... logprob:  0.605480, 0.285156 (1.408 sec)
33.323... logprob:  0.695775, 0.312500 (1.472 sec)
33.324... logprob:  0.627951, 0.261719 (1.416 sec)
33.325... logprob:  0.525102, 0.220052 (1.440 sec)
33.326... logprob:  0.686119, 0.269531 (1.454 sec)
33.327... logprob:  0.676692, 0.294271 (1.417 sec)
33.328... logprob:  0.781780, 0.343750 (1.427 sec)
33.329... logprob:  0.660870, 0.273437 (1.416 sec)
33.330... logprob:  0.679482, 0.322917 (1.417 sec)
33.331... logprob:  0.640691, 0.299479 (1.408 sec)
33.332... logprob:  0.794158, 0.329427 (1.448 sec)
33.333... logprob:  0.575272, 0.250000 (1.441 sec)
33.334... logprob:  0.711307, 0.334635 (1.438 sec)
33.335... logprob:  0.560807, 0.264323 (1.431 sec)
33.336... logprob:  0.598332, 0.272135 (1.449 sec)
33.337... logprob:  0.750360, 0.307292 (1.406 sec)
33.338... logprob:  0.624663, 0.265625 (1.419 sec)
33.339... logprob:  0.712984, 0.320312 (1.416 sec)
33.340... logprob:  0.667428, 0.295573 (1.417 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.491832, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.182900e-03 [1.091856e-07] 
Layer 'conv1' biases: 2.188483e-06 [2.670660e-11] 
Layer 'conv2' weights[0]: 2.178513e-03 [1.089733e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.519948e-10] 
Layer 'conv3' weights[0]: 2.177508e-03 [1.090261e-07] 
Layer 'conv3' biases: 3.639717e-05 [4.004426e-09] 
Layer 'conv4' weights[0]: 2.186739e-03 [1.095130e-07] 
Layer 'conv4' biases: 9.998005e-01 [1.290534e-07] 
Layer 'conv5' weights[0]: 2.350290e-03 [2.076497e-06] 
Layer 'conv5' biases: 9.989686e-01 [2.248372e-06] 
Layer 'fc6' weights[0]: 6.638402e-03 [5.689981e-08] 
Layer 'fc6' biases: 9.999904e-01 [5.206078e-08] 
Layer 'fc7' weights[0]: 6.979878e-03 [1.330226e-07] 
Layer 'fc7' biases: 9.996952e-01 [1.529145e-07] 
Layer 'fc8' weights[0]: 4.752303e-03 [1.069173e-05] 
Layer 'fc8' biases: 2.706879e-02 [7.339222e-06] 
Train error last 800 batches: 0.655790
-------------------------------------------------------
Not saving because 0.491832 > 0.299667 (9.300: -1.18%)
======================================================= (2.367 sec)
33.341... logprob:  0.758673, 0.309896 (1.423 sec)
33.342... logprob:  0.547443, 0.255208 (1.460 sec)
33.343... logprob:  0.628756, 0.269531 (1.440 sec)
33.344... logprob:  0.709797, 0.329427 (1.472 sec)
33.345... logprob:  0.759643, 0.328125 (1.436 sec)
33.346... logprob:  0.715823, 0.316406 (1.429 sec)
33.347... logprob:  0.682757, 0.312500 (1.476 sec)
33.348... logprob:  0.628888, 0.300781 (1.426 sec)
33.349... logprob:  0.644900, 0.260417 (1.424 sec)
33.350... logprob:  0.561386, 0.256510 (1.432 sec)
33.351... logprob:  0.669943, 0.311198 (1.423 sec)
33.352... logprob:  0.621762, 0.277344 (1.429 sec)
33.353... logprob:  0.649969, 0.304687 (1.480 sec)
33.354... logprob:  0.785691, 0.343750 (1.426 sec)
33.355... logprob:  0.585543, 0.266927 (1.435 sec)
33.356... logprob:  0.679542, 0.300781 (1.474 sec)
33.357... logprob:  0.562331, 0.270833 (1.448 sec)
33.358... logprob:  0.625917, 0.274740 (1.435 sec)
33.359... logprob:  0.739594, 0.311198 (1.422 sec)
33.360... logprob:  0.690925, 0.298177 (1.425 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.489198, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.180719e-03 [1.090686e-07] 
Layer 'conv1' biases: 2.188540e-06 [3.166436e-11] 
Layer 'conv2' weights[0]: 2.176351e-03 [1.088644e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.282971e-10] 
Layer 'conv3' weights[0]: 2.175329e-03 [1.090179e-07] 
Layer 'conv3' biases: 3.639819e-05 [4.845092e-09] 
Layer 'conv4' weights[0]: 2.184557e-03 [1.096137e-07] 
Layer 'conv4' biases: 9.997997e-01 [1.622937e-07] 
Layer 'conv5' weights[0]: 2.347908e-03 [2.344328e-06] 
Layer 'conv5' biases: 9.989552e-01 [2.495585e-06] 
Layer 'fc6' weights[0]: 6.637761e-03 [5.915144e-08] 
Layer 'fc6' biases: 9.999903e-01 [5.535250e-08] 
Layer 'fc7' weights[0]: 6.979189e-03 [1.413300e-07] 
Layer 'fc7' biases: 9.996959e-01 [1.841394e-07] 
Layer 'fc8' weights[0]: 4.771621e-03 [1.185357e-05] 
Layer 'fc8' biases: 2.730908e-02 [1.980084e-05] 
Train error last 800 batches: 0.655601
-------------------------------------------------------
Not saving because 0.489198 > 0.299667 (9.300: -1.18%)
======================================================= (2.354 sec)
33.361... logprob:  0.613319, 0.276042 (1.431 sec)
33.362... logprob:  0.669188, 0.285156 (1.482 sec)
33.363... logprob:  0.728493, 0.286458 (1.440 sec)
33.364... logprob:  0.675129, 0.285156 (1.444 sec)
33.365... logprob:  0.683475, 0.322917 (1.457 sec)
33.366... logprob:  0.618741, 0.268229 (1.534 sec)
33.367... logprob:  0.581696, 0.256510 (1.436 sec)
33.368... logprob:  0.843707, 0.345052 (1.424 sec)
33.369... logprob:  0.592723, 0.264323 (1.418 sec)
33.370... logprob:  0.621917, 0.295573 (1.429 sec)
33.371... logprob:  0.608015, 0.260417 (1.454 sec)
33.372... logprob:  0.751433, 0.335937 (1.450 sec)
33.373... logprob:  0.615033, 0.282552 (1.447 sec)
33.374... logprob:  0.741337, 0.334635 (1.441 sec)
33.375... logprob:  0.628444, 0.299479 (1.461 sec)
33.376... logprob:  0.622487, 0.253906 (1.437 sec)
33.377... logprob:  0.588127, 0.268229 (1.422 sec)
33.378... logprob:  0.660135, 0.274739 (1.426 sec)
33.379... logprob:  0.666448, 0.290364 (1.444 sec)
33.380... logprob:  0.709129, 0.300781 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.507451, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.178537e-03 [1.089588e-07] 
Layer 'conv1' biases: 2.188759e-06 [3.270185e-11] 
Layer 'conv2' weights[0]: 2.174162e-03 [1.087591e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.066589e-10] 
Layer 'conv3' weights[0]: 2.173153e-03 [1.088700e-07] 
Layer 'conv3' biases: 3.638460e-05 [4.804171e-09] 
Layer 'conv4' weights[0]: 2.182376e-03 [1.094392e-07] 
Layer 'conv4' biases: 9.997991e-01 [1.629752e-07] 
Layer 'conv5' weights[0]: 2.345189e-03 [2.379448e-06] 
Layer 'conv5' biases: 9.989557e-01 [2.594545e-06] 
Layer 'fc6' weights[0]: 6.637056e-03 [5.859402e-08] 
Layer 'fc6' biases: 9.999901e-01 [5.488864e-08] 
Layer 'fc7' weights[0]: 6.978498e-03 [1.382586e-07] 
Layer 'fc7' biases: 9.996955e-01 [1.713969e-07] 
Layer 'fc8' weights[0]: 4.772099e-03 [1.161541e-05] 
Layer 'fc8' biases: 2.739518e-02 [1.880480e-05] 
Train error last 800 batches: 0.655911
-------------------------------------------------------
Not saving because 0.507451 > 0.299667 (9.300: -1.18%)
======================================================= (2.406 sec)
33.381... logprob:  0.662226, 0.308594 (1.469 sec)
33.382... logprob:  0.671076, 0.283854 (1.451 sec)
33.383... logprob:  0.530925, 0.234375 (1.439 sec)
33.384... logprob:  0.683706, 0.274740 (1.474 sec)
33.385... logprob:  0.744938, 0.317708 (1.428 sec)
33.386... logprob:  0.771891, 0.342448 (1.416 sec)
33.387... logprob:  0.645347, 0.292969 (1.433 sec)
33.388... logprob:  0.625286, 0.270833 (1.436 sec)
33.389... logprob:  0.625401, 0.276042 (1.425 sec)
33.390... logprob:  0.665376, 0.279948 (1.473 sec)
33.391... logprob:  0.575361, 0.236979 (1.437 sec)
33.392... logprob:  0.692616, 0.299479 (1.424 sec)
33.393... logprob:  0.650934, 0.285156 (1.477 sec)
33.394... logprob:  0.539527, 0.239583 (1.433 sec)
33.395... logprob:  0.604076, 0.268229 (1.445 sec)
33.396... logprob:  0.569623, 0.274740 (1.434 sec)
33.397... logprob:  0.750951, 0.315104 (1.426 sec)
33.398... logprob:  0.780854, 0.329427 (1.430 sec)
33.399... logprob:  0.618704, 0.279948 (1.479 sec)
33.400... logprob:  0.757433, 0.315104 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.499811, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.176354e-03 [1.088479e-07] 
Layer 'conv1' biases: 2.188771e-06 [3.063800e-11] 
Layer 'conv2' weights[0]: 2.171996e-03 [1.086475e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.187815e-10] 
Layer 'conv3' weights[0]: 2.170970e-03 [1.088260e-07] 
Layer 'conv3' biases: 3.638756e-05 [5.860330e-09] 
Layer 'conv4' weights[0]: 2.180188e-03 [1.093999e-07] 
Layer 'conv4' biases: 9.997991e-01 [2.098815e-07] 
Layer 'conv5' weights[0]: 2.343651e-03 [2.299335e-06] 
Layer 'conv5' biases: 9.989535e-01 [2.382365e-06] 
Layer 'fc6' weights[0]: 6.636382e-03 [5.987432e-08] 
Layer 'fc6' biases: 9.999903e-01 [5.651632e-08] 
Layer 'fc7' weights[0]: 6.977819e-03 [1.431029e-07] 
Layer 'fc7' biases: 9.996949e-01 [1.789271e-07] 
Layer 'fc8' weights[0]: 4.771516e-03 [1.250436e-05] 
Layer 'fc8' biases: 2.744290e-02 [2.456416e-05] 
Train error last 800 batches: 0.655683
-------------------------------------------------------
Not saving because 0.499811 > 0.299667 (9.300: -1.18%)
======================================================= (2.377 sec)
33.401... logprob:  0.588882, 0.278646 (1.443 sec)
33.402... logprob:  0.720427, 0.294271 (1.483 sec)
33.403... logprob:  0.703836, 0.328125 (1.429 sec)
33.404... logprob:  0.585509, 0.240885 (1.429 sec)
33.405... logprob:  0.683802, 0.294271 (1.428 sec)
33.406... logprob:  0.636750, 0.279948 (1.422 sec)
33.407... logprob:  0.715642, 0.316406 (1.428 sec)
33.408... logprob:  0.537432, 0.266927 (1.479 sec)
33.409... logprob:  0.636681, 0.289062 (1.433 sec)
33.410... logprob:  0.761486, 0.322917 (1.446 sec)
33.411... logprob:  0.684605, 0.302083 (1.472 sec)
33.412... logprob:  0.777049, 0.328125 (1.431 sec)
33.413... logprob:  0.698296, 0.313802 (1.427 sec)
33.414... logprob:  0.662596, 0.294271 (1.428 sec)
33.415... logprob:  0.551568, 0.252604 (1.419 sec)
33.416... logprob:  0.624806, 0.299479 (1.431 sec)
33.417... logprob:  0.632247, 0.272135 (1.468 sec)
33.418... logprob:  0.645775, 0.268229 (1.449 sec)
33.419... logprob:  0.643403, 0.268229 (1.448 sec)
33.420... logprob:  0.533235, 0.246094 (1.457 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.410980, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.174176e-03 [1.087630e-07] 
Layer 'conv1' biases: 2.188803e-06 [2.770431e-11] 
Layer 'conv2' weights[0]: 2.169829e-03 [1.085514e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.108071e-10] 
Layer 'conv3' weights[0]: 2.168784e-03 [1.086139e-07] 
Layer 'conv3' biases: 3.639833e-05 [4.210109e-09] 
Layer 'conv4' weights[0]: 2.178003e-03 [1.092532e-07] 
Layer 'conv4' biases: 9.997998e-01 [1.658057e-07] 
Layer 'conv5' weights[0]: 2.342370e-03 [2.743878e-06] 
Layer 'conv5' biases: 9.989501e-01 [2.936075e-06] 
Layer 'fc6' weights[0]: 6.635671e-03 [6.549615e-08] 
Layer 'fc6' biases: 9.999901e-01 [6.408001e-08] 
Layer 'fc7' weights[0]: 6.977154e-03 [1.652354e-07] 
Layer 'fc7' biases: 9.996951e-01 [2.757271e-07] 
Layer 'fc8' weights[0]: 4.775792e-03 [1.763661e-05] 
Layer 'fc8' biases: 2.747421e-02 [5.491213e-05] 
Train error last 800 batches: 0.655509
-------------------------------------------------------
Not saving because 0.410980 > 0.299667 (9.300: -1.18%)
======================================================= (2.345 sec)
33.421... logprob:  0.598221, 0.282552 (1.457 sec)
33.422... logprob:  0.748317, 0.337240 (1.440 sec)
33.423... logprob:  0.652996, 0.285156 (1.425 sec)
33.424... logprob:  0.592421, 0.252604 (1.425 sec)
33.425... logprob:  0.550245, 0.269531 (1.429 sec)
33.426... logprob:  0.632287, 0.276042 (1.439 sec)
33.427... logprob:  0.767605, 0.294271 (1.457 sec)
33.428... logprob:  0.775945, 0.335938 (1.447 sec)
33.429... logprob:  0.634874, 0.286458 (1.445 sec)
33.430... logprob:  0.593069, 0.266927 (1.466 sec)
33.431... logprob:  0.652846, 0.292969 (1.430 sec)
33.432... logprob:  0.647534, 0.230469 (1.421 sec)
33.433... logprob:  0.543655, 0.221354 (1.452 sec)
33.434... logprob:  0.612423, 0.289062 (1.434 sec)
33.435... logprob:  0.770161, 0.321615 (1.427 sec)
33.436... logprob:  0.592381, 0.277344 (1.472 sec)
33.437... logprob:  0.757679, 0.303385 (1.438 sec)
33.438... logprob:  0.714324, 0.316406 (1.427 sec)
33.439... logprob:  0.654503, 0.304688 (1.480 sec)
33.440... logprob:  0.653045, 0.285156 (1.435 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.440505, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.171999e-03 [1.086130e-07] 
Layer 'conv1' biases: 2.188816e-06 [3.459092e-11] 
Layer 'conv2' weights[0]: 2.167651e-03 [1.084114e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.812561e-10] 
Layer 'conv3' weights[0]: 2.166632e-03 [1.086364e-07] 
Layer 'conv3' biases: 3.640999e-05 [6.331352e-09] 
Layer 'conv4' weights[0]: 2.175828e-03 [1.092114e-07] 
Layer 'conv4' biases: 9.997998e-01 [2.383716e-07] 
Layer 'conv5' weights[0]: 2.340371e-03 [3.559413e-06] 
Layer 'conv5' biases: 9.989554e-01 [3.988837e-06] 
Layer 'fc6' weights[0]: 6.634973e-03 [7.052601e-08] 
Layer 'fc6' biases: 9.999901e-01 [7.106421e-08] 
Layer 'fc7' weights[0]: 6.976443e-03 [1.730627e-07] 
Layer 'fc7' biases: 9.996943e-01 [2.883246e-07] 
Layer 'fc8' weights[0]: 4.759835e-03 [1.552140e-05] 
Layer 'fc8' biases: 2.739035e-02 [3.986420e-05] 
Train error last 800 batches: 0.655271
-------------------------------------------------------
Not saving because 0.440505 > 0.299667 (9.300: -1.18%)
======================================================= (2.397 sec)
33.441... logprob:  0.658642, 0.274740 (1.426 sec)
33.442... logprob:  0.598066, 0.261719 (1.431 sec)
33.443... logprob:  0.774449, 0.347656 (1.430 sec)
33.444... logprob:  0.612459, 0.250000 (1.428 sec)
33.445... logprob:  0.584486, 0.257812 (1.476 sec)
33.446... logprob:  0.600474, 0.278646 (1.433 sec)
33.447... logprob:  0.766334, 0.311198 (1.433 sec)
33.448... logprob:  0.646465, 0.282552 (1.481 sec)
33.449... logprob:  0.634179, 0.291667 (1.426 sec)
33.450... logprob:  0.548048, 0.268229 (1.427 sec)
33.451... logprob:  0.682826, 0.315104 (1.428 sec)
33.452... logprob:  0.591529, 0.261719 (1.424 sec)
33.453... logprob:  0.682996, 0.257812 (1.429 sec)
33.454... logprob:  0.640156, 0.278646 (1.483 sec)
33.455... logprob:  0.698774, 0.305989 (1.430 sec)
33.456... logprob:  0.636363, 0.292969 (1.439 sec)
33.457... logprob:  0.635282, 0.298177 (1.469 sec)
33.458... logprob:  0.608575, 0.268229 (1.423 sec)
33.459... logprob:  0.721901, 0.317708 (1.436 sec)
33.460... logprob:  0.556771, 0.257812 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.462894, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.169829e-03 [1.085419e-07] 
Layer 'conv1' biases: 2.188995e-06 [2.863198e-11] 
Layer 'conv2' weights[0]: 2.165490e-03 [1.083341e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.639578e-10] 
Layer 'conv3' weights[0]: 2.164480e-03 [1.084295e-07] 
Layer 'conv3' biases: 3.642523e-05 [4.667521e-09] 
Layer 'conv4' weights[0]: 2.173652e-03 [1.090171e-07] 
Layer 'conv4' biases: 9.997984e-01 [1.675168e-07] 
Layer 'conv5' weights[0]: 2.337376e-03 [2.419249e-06] 
Layer 'conv5' biases: 9.989679e-01 [2.697312e-06] 
Layer 'fc6' weights[0]: 6.634307e-03 [6.050103e-08] 
Layer 'fc6' biases: 9.999902e-01 [5.676235e-08] 
Layer 'fc7' weights[0]: 6.975736e-03 [1.442385e-07] 
Layer 'fc7' biases: 9.996938e-01 [2.056562e-07] 
Layer 'fc8' weights[0]: 4.733831e-03 [1.288308e-05] 
Layer 'fc8' biases: 2.719981e-02 [3.395076e-05] 
Train error last 800 batches: 0.655120
-------------------------------------------------------
Not saving because 0.462894 > 0.299667 (9.300: -1.18%)
======================================================= (2.351 sec)
33.461... logprob:  0.699730, 0.324219 (1.427 sec)
33.462... logprob:  0.724577, 0.311198 (1.436 sec)
33.463... logprob:  0.559571, 0.220052 (1.473 sec)
33.464... logprob:  0.642392, 0.277344 (1.437 sec)
33.465... logprob:  0.654344, 0.303385 (1.449 sec)
33.466... logprob:  0.597027, 0.253906 (1.452 sec)
33.467... logprob:  0.640709, 0.294271 (1.444 sec)
33.468... logprob:  0.584772, 0.270833 (1.438 sec)
33.469... logprob:  0.614790, 0.276042 (1.424 sec)
33.470... logprob:  0.624897, 0.282552 (1.419 sec)
33.471... logprob:  0.708846, 0.294271 (1.432 sec)
33.472... logprob:  0.645284, 0.263021 (1.446 sec)
33.473... logprob:  0.583676, 0.233073 (1.451 sec)
33.474... logprob:  0.656278, 0.295573 (1.448 sec)
33.475... logprob:  0.733648, 0.307292 (1.439 sec)
33.476... logprob:  0.746798, 0.299479 (1.464 sec)
33.477... logprob:  0.548569, 0.246094 (1.437 sec)
33.478... logprob:  0.661976, 0.285156 (1.417 sec)
33.479... logprob:  0.530178, 0.250000 (1.425 sec)
33.480... logprob:  0.607285, 0.281250 (1.519 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.563734, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.167660e-03 [1.084729e-07] 
Layer 'conv1' biases: 2.189057e-06 [2.723944e-11] 
Layer 'conv2' weights[0]: 2.163317e-03 [1.082380e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.841855e-10] 
Layer 'conv3' weights[0]: 2.162316e-03 [1.082915e-07] 
Layer 'conv3' biases: 3.641290e-05 [4.228218e-09] 
Layer 'conv4' weights[0]: 2.171466e-03 [1.088472e-07] 
Layer 'conv4' biases: 9.997989e-01 [1.410278e-07] 
Layer 'conv5' weights[0]: 2.335968e-03 [2.211766e-06] 
Layer 'conv5' biases: 9.989476e-01 [2.368495e-06] 
Layer 'fc6' weights[0]: 6.633653e-03 [6.440933e-08] 
Layer 'fc6' biases: 9.999902e-01 [6.287724e-08] 
Layer 'fc7' weights[0]: 6.975020e-03 [1.582786e-07] 
Layer 'fc7' biases: 9.996951e-01 [2.524772e-07] 
Layer 'fc8' weights[0]: 4.788229e-03 [1.609221e-05] 
Layer 'fc8' biases: 2.763480e-02 [4.260532e-05] 
Train error last 800 batches: 0.654987
-------------------------------------------------------
Not saving because 0.563734 > 0.299667 (9.300: -1.18%)
======================================================= (2.359 sec)
33.481... logprob:  0.785644, 0.365885 (1.434 sec)
33.482... logprob:  0.734991, 0.296875 (1.468 sec)
33.483... logprob:  0.726074, 0.319010 (1.439 sec)
33.484... logprob:  0.702245, 0.304688 (1.434 sec)
33.485... logprob:  0.604404, 0.273437 (1.481 sec)
33.486... logprob:  0.568138, 0.229167 (1.426 sec)
33.487... logprob:  0.716738, 0.321615 (1.423 sec)
33.488... logprob:  0.605253, 0.268229 (1.428 sec)
33.489... logprob:  0.670577, 0.263021 (1.427 sec)
33.490... logprob:  0.599161, 0.269531 (1.428 sec)
33.491... logprob:  0.524748, 0.269531 (1.475 sec)
33.492... logprob:  0.648420, 0.268229 (1.439 sec)
33.493... logprob:  0.695086, 0.304687 (1.430 sec)
33.494... logprob:  0.600445, 0.270833 (1.483 sec)
33.495... logprob:  0.541251, 0.235677 (1.431 sec)
33.496... logprob:  0.705245, 0.296875 (1.425 sec)
33.497... logprob:  0.613322, 0.263021 (1.429 sec)
33.498... logprob:  0.680857, 0.290365 (1.424 sec)
33.499... logprob:  0.640990, 0.292969 (1.433 sec)
33.500... logprob:  0.621772, 0.287760 (1.481 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.514969, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.165502e-03 [1.083196e-07] 
Layer 'conv1' biases: 2.189004e-06 [2.465574e-11] 
Layer 'conv2' weights[0]: 2.161152e-03 [1.080977e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.980447e-10] 
Layer 'conv3' weights[0]: 2.160154e-03 [1.081682e-07] 
Layer 'conv3' biases: 3.641645e-05 [3.622448e-09] 
Layer 'conv4' weights[0]: 2.169300e-03 [1.086613e-07] 
Layer 'conv4' biases: 9.997987e-01 [1.166654e-07] 
Layer 'conv5' weights[0]: 2.333979e-03 [2.093695e-06] 
Layer 'conv5' biases: 9.989593e-01 [2.206873e-06] 
Layer 'fc6' weights[0]: 6.632972e-03 [5.888974e-08] 
Layer 'fc6' biases: 9.999899e-01 [5.511651e-08] 
Layer 'fc7' weights[0]: 6.974312e-03 [1.386918e-07] 
Layer 'fc7' biases: 9.996947e-01 [1.857542e-07] 
Layer 'fc8' weights[0]: 4.785161e-03 [1.281000e-05] 
Layer 'fc8' biases: 2.763342e-02 [2.901821e-05] 
Train error last 800 batches: 0.654815
-------------------------------------------------------
Not saving because 0.514969 > 0.299667 (9.300: -1.18%)
======================================================= (2.344 sec)
33.501... logprob:  0.559028, 0.252604 (1.431 sec)
33.502... logprob:  0.749447, 0.335938 (1.442 sec)
33.503... logprob:  0.616445, 0.279948 (1.476 sec)
33.504... logprob:  0.718721, 0.316406 (1.426 sec)
33.505... logprob:  0.839454, 0.351562 (1.434 sec)
33.506... logprob:  0.755687, 0.339844 (1.429 sec)
33.507... logprob:  0.512418, 0.230469 (1.422 sec)
33.508... logprob:  0.624345, 0.287760 (1.429 sec)
33.509... logprob:  0.577372, 0.265625 (1.467 sec)
33.510... logprob:  0.576663, 0.257812 (1.441 sec)
33.511... logprob:  0.620391, 0.264323 (1.451 sec)
33.512... logprob:  0.731418, 0.348958 (1.460 sec)
33.513... logprob:  0.606923, 0.296875 (1.436 sec)
33.514... logprob:  0.694904, 0.278646 (1.432 sec)
33.515... logprob:  0.655233, 0.276042 (1.424 sec)
33.516... logprob:  0.633403, 0.274740 (1.418 sec)
33.517... logprob:  0.767293, 0.312500 (1.432 sec)
33.518... logprob:  0.649098, 0.282552 (1.455 sec)
33.519... logprob:  0.664879, 0.279948 (1.444 sec)
33.520... logprob:  0.733008, 0.330729 (1.448 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.456468, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.163328e-03 [1.081619e-07] 
Layer 'conv1' biases: 2.189175e-06 [3.186618e-11] 
Layer 'conv2' weights[0]: 2.158998e-03 [1.079648e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.038846e-10] 
Layer 'conv3' weights[0]: 2.157983e-03 [1.080756e-07] 
Layer 'conv3' biases: 3.643615e-05 [4.202678e-09] 
Layer 'conv4' weights[0]: 2.167145e-03 [1.085871e-07] 
Layer 'conv4' biases: 9.997984e-01 [1.538327e-07] 
Layer 'conv5' weights[0]: 2.331776e-03 [2.591526e-06] 
Layer 'conv5' biases: 9.989651e-01 [2.876179e-06] 
Layer 'fc6' weights[0]: 6.632282e-03 [6.361075e-08] 
Layer 'fc6' biases: 9.999900e-01 [6.141862e-08] 
Layer 'fc7' weights[0]: 6.973625e-03 [1.518545e-07] 
Layer 'fc7' biases: 9.996934e-01 [2.141116e-07] 
Layer 'fc8' weights[0]: 4.760955e-03 [1.363615e-05] 
Layer 'fc8' biases: 2.748415e-02 [3.388177e-05] 
Train error last 800 batches: 0.655405
-------------------------------------------------------
Not saving because 0.456468 > 0.299667 (9.300: -1.18%)
======================================================= (2.357 sec)
33.521... logprob:  0.547984, 0.250000 (1.449 sec)
33.522... logprob:  0.769836, 0.329427 (1.466 sec)
33.523... logprob:  0.578745, 0.257812 (1.433 sec)
33.524... logprob:  0.670399, 0.298177 (1.422 sec)
33.525... logprob:  0.590226, 0.235677 (1.425 sec)
33.526... logprob:  0.684050, 0.300781 (1.431 sec)
33.527... logprob:  0.763979, 0.322917 (1.432 sec)
33.528... logprob:  0.674928, 0.303385 (1.465 sec)
33.529... logprob:  0.627554, 0.281250 (1.449 sec)
33.530... logprob:  0.691417, 0.322917 (1.433 sec)
33.531... logprob:  0.638605, 0.289062 (1.473 sec)
33.532... logprob:  0.702616, 0.321615 (1.427 sec)
33.533... logprob:  0.720675, 0.309896 (1.417 sec)
33.534... logprob:  0.517853, 0.231771 (1.431 sec)
33.535... logprob:  0.722763, 0.308594 (1.431 sec)
33.536... logprob:  0.671487, 0.291667 (1.433 sec)
33.537... logprob:  0.652865, 0.278646 (1.469 sec)
33.538... logprob:  0.686275, 0.294271 (1.438 sec)
33.539... logprob:  0.560206, 0.278646 (1.430 sec)
33.540... logprob:  0.667344, 0.315104 (1.494 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.448760, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.161167e-03 [1.080927e-07] 
Layer 'conv1' biases: 2.189445e-06 [2.684355e-11] 
Layer 'conv2' weights[0]: 2.156848e-03 [1.078826e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.109902e-10] 
Layer 'conv3' weights[0]: 2.155842e-03 [1.079422e-07] 
Layer 'conv3' biases: 3.643781e-05 [3.688734e-09] 
Layer 'conv4' weights[0]: 2.164980e-03 [1.084919e-07] 
Layer 'conv4' biases: 9.997984e-01 [1.192517e-07] 
Layer 'conv5' weights[0]: 2.329602e-03 [2.234980e-06] 
Layer 'conv5' biases: 9.989788e-01 [2.450002e-06] 
Layer 'fc6' weights[0]: 6.631599e-03 [5.762397e-08] 
Layer 'fc6' biases: 9.999902e-01 [5.277789e-08] 
Layer 'fc7' weights[0]: 6.972919e-03 [1.356179e-07] 
Layer 'fc7' biases: 9.996927e-01 [1.761515e-07] 
Layer 'fc8' weights[0]: 4.742887e-03 [1.143294e-05] 
Layer 'fc8' biases: 2.732873e-02 [2.210605e-05] 
Train error last 800 batches: 0.655072
-------------------------------------------------------
Not saving because 0.448760 > 0.299667 (9.300: -1.18%)
======================================================= (2.359 sec)
33.541... logprob:  0.621560, 0.261719 (1.433 sec)
33.542... logprob:  0.758062, 0.356771 (1.424 sec)
33.543... logprob:  0.546902, 0.253906 (1.431 sec)
33.544... logprob:  0.495374, 0.216146 (1.422 sec)
33.545... logprob:  0.667100, 0.290365 (1.431 sec)
33.546... logprob:  0.528552, 0.238281 (1.484 sec)
33.547... logprob:  0.663105, 0.292969 (1.428 sec)
33.548... logprob:  0.685241, 0.296875 (1.437 sec)
33.549... logprob:  0.673579, 0.286458 (1.472 sec)
33.550... logprob:  0.532871, 0.234375 (1.424 sec)
33.551... logprob:  0.640601, 0.266927 (1.430 sec)
33.552... logprob:  0.660968, 0.278646 (1.428 sec)
33.553... logprob:  0.518489, 0.251302 (1.422 sec)
33.554... logprob:  0.737517, 0.303385 (1.429 sec)
33.555... logprob:  0.663447, 0.294271 (1.482 sec)
33.556... logprob:  0.491618, 0.209635 (1.429 sec)
33.557... logprob:  0.545047, 0.244792 (1.444 sec)
33.558... logprob:  0.602933, 0.269531 (1.465 sec)
33.559... logprob:  0.660035, 0.299479 (1.431 sec)
33.560... logprob:  0.611736, 0.282552 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.462283, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.159003e-03 [1.080407e-07] 
Layer 'conv1' biases: 2.189669e-06 [4.255623e-11] 
Layer 'conv2' weights[0]: 2.154688e-03 [1.078186e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.286597e-10] 
Layer 'conv3' weights[0]: 2.153686e-03 [1.080248e-07] 
Layer 'conv3' biases: 3.640939e-05 [5.606715e-09] 
Layer 'conv4' weights[0]: 2.162809e-03 [1.086799e-07] 
Layer 'conv4' biases: 9.997989e-01 [1.806419e-07] 
Layer 'conv5' weights[0]: 2.328306e-03 [2.882007e-06] 
Layer 'conv5' biases: 9.989408e-01 [3.203999e-06] 
Layer 'fc6' weights[0]: 6.630941e-03 [6.096979e-08] 
Layer 'fc6' biases: 9.999896e-01 [5.793611e-08] 
Layer 'fc7' weights[0]: 6.972178e-03 [1.447440e-07] 
Layer 'fc7' biases: 9.996952e-01 [2.105198e-07] 
Layer 'fc8' weights[0]: 4.826662e-03 [1.220683e-05] 
Layer 'fc8' biases: 2.797047e-02 [3.367651e-05] 
Train error last 800 batches: 0.654506
-------------------------------------------------------
Not saving because 0.462283 > 0.299667 (9.300: -1.18%)
======================================================= (2.404 sec)
33.561... logprob:  0.704473, 0.329427 (1.436 sec)
33.562... logprob:  0.764743, 0.334635 (1.424 sec)
33.563... logprob:  0.548369, 0.247396 (1.430 sec)
33.564... logprob:  0.676118, 0.300781 (1.460 sec)
33.565... logprob:  0.823162, 0.360677 (1.442 sec)
33.566... logprob:  0.649234, 0.305989 (1.447 sec)
33.567... logprob:  0.671053, 0.305990 (1.461 sec)
33.568... logprob:  0.740681, 0.333333 (1.448 sec)
33.569... logprob:  0.639972, 0.272135 (1.430 sec)
33.570... logprob:  0.720757, 0.295573 (1.419 sec)
33.571... logprob:  0.683506, 0.294271 (1.427 sec)
33.572... logprob:  0.698418, 0.283854 (1.446 sec)
33.573... logprob:  0.694422, 0.305990 (1.438 sec)
33.574... logprob:  0.589855, 0.273437 (1.459 sec)
33.575... logprob:  0.607531, 0.251302 (1.447 sec)
33.576... logprob:  0.681186, 0.291667 (1.436 sec)
33.577... logprob:  0.650781, 0.286458 (1.470 sec)
33.578... logprob:  0.544955, 0.253906 (1.425 sec)
33.579... logprob:  0.708051, 0.312500 (1.419 sec)
33.580... logprob:  0.666818, 0.268229 (1.425 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.405041, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.156872e-03 [1.078742e-07] 
Layer 'conv1' biases: 2.189794e-06 [2.184245e-11] 
Layer 'conv2' weights[0]: 2.152514e-03 [1.076691e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.171587e-10] 
Layer 'conv3' weights[0]: 2.151525e-03 [1.077128e-07] 
Layer 'conv3' biases: 3.643124e-05 [3.510831e-09] 
Layer 'conv4' weights[0]: 2.160650e-03 [1.081657e-07] 
Layer 'conv4' biases: 9.997979e-01 [1.116852e-07] 
Layer 'conv5' weights[0]: 2.326201e-03 [2.222876e-06] 
Layer 'conv5' biases: 9.989681e-01 [2.383223e-06] 
Layer 'fc6' weights[0]: 6.630302e-03 [6.126565e-08] 
Layer 'fc6' biases: 9.999899e-01 [5.849213e-08] 
Layer 'fc7' weights[0]: 6.971499e-03 [1.439932e-07] 
Layer 'fc7' biases: 9.996933e-01 [1.943635e-07] 
Layer 'fc8' weights[0]: 4.759293e-03 [1.220697e-05] 
Layer 'fc8' biases: 2.750956e-02 [2.433272e-05] 
Train error last 800 batches: 0.654647
-------------------------------------------------------
Not saving because 0.405041 > 0.299667 (9.300: -1.18%)
======================================================= (2.359 sec)
33.581... logprob:  0.773703, 0.317708 (1.446 sec)
33.582... logprob:  0.662169, 0.292969 (1.431 sec)
33.583... logprob:  0.682216, 0.326823 (1.466 sec)
33.584... logprob:  0.710632, 0.335938 (1.445 sec)
33.585... logprob:  0.607210, 0.266927 (1.431 sec)
33.586... logprob:  0.559399, 0.263021 (1.488 sec)
33.587... logprob:  0.599174, 0.257812 (1.428 sec)
33.588... logprob:  0.695470, 0.303385 (1.425 sec)
33.589... logprob:  0.529662, 0.210937 (1.428 sec)
33.590... logprob:  0.733778, 0.296875 (1.423 sec)
33.591... logprob:  0.561568, 0.269531 (1.432 sec)
33.592... logprob:  0.666595, 0.281250 (1.480 sec)
33.593... logprob:  0.669514, 0.285156 (1.434 sec)
33.594... logprob:  0.581578, 0.240885 (1.441 sec)
33.595... logprob:  0.558648, 0.253906 (1.489 sec)
33.596... logprob:  0.732312, 0.305990 (1.430 sec)
33.597... logprob:  0.584961, 0.244792 (1.432 sec)
33.598... logprob:  0.598718, 0.268229 (1.428 sec)
33.599... logprob:  0.575428, 0.233073 (1.421 sec)
33.600... logprob:  0.579370, 0.278646 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.511514, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.154706e-03 [1.078035e-07] 
Layer 'conv1' biases: 2.189898e-06 [4.442008e-11] 
Layer 'conv2' weights[0]: 2.150376e-03 [1.075908e-07] 
Layer 'conv2' biases: 9.999996e-01 [7.127663e-10] 
Layer 'conv3' weights[0]: 2.149372e-03 [1.080080e-07] 
Layer 'conv3' biases: 3.641750e-05 [8.160111e-09] 
Layer 'conv4' weights[0]: 2.158491e-03 [1.088497e-07] 
Layer 'conv4' biases: 9.997991e-01 [3.095420e-07] 
Layer 'conv5' weights[0]: 2.325621e-03 [4.354829e-06] 
Layer 'conv5' biases: 9.989454e-01 [4.793328e-06] 
Layer 'fc6' weights[0]: 6.629600e-03 [7.644886e-08] 
Layer 'fc6' biases: 9.999895e-01 [7.799386e-08] 
Layer 'fc7' weights[0]: 6.970788e-03 [1.929012e-07] 
Layer 'fc7' biases: 9.996944e-01 [3.582342e-07] 
Layer 'fc8' weights[0]: 4.798973e-03 [1.926076e-05] 
Layer 'fc8' biases: 2.780919e-02 [6.421453e-05] 
Train error last 800 batches: 0.654422
-------------------------------------------------------
Not saving because 0.511514 > 0.299667 (9.300: -1.18%)
======================================================= (2.343 sec)
33.601... logprob:  0.573605, 0.252604 (1.486 sec)
33.602... logprob:  0.521844, 0.239583 (1.429 sec)
33.603... logprob:  0.550184, 0.246094 (1.438 sec)
33.604... logprob:  0.545874, 0.236979 (1.470 sec)
33.605... logprob:  0.752605, 0.304687 (1.426 sec)
33.606... logprob:  0.528669, 0.230469 (1.433 sec)
33.607... logprob:  0.689440, 0.316406 (1.433 sec)
33.608... logprob:  0.607235, 0.276042 (1.421 sec)
33.609... logprob:  0.509901, 0.234375 (1.427 sec)
33.610... logprob:  0.733674, 0.300781 (1.467 sec)
33.611... logprob:  0.634030, 0.286458 (1.438 sec)
33.612... logprob:  0.698123, 0.296875 (1.450 sec)
33.613... logprob:  0.535959, 0.230469 (1.460 sec)
33.614... logprob:  0.801976, 0.325521 (1.441 sec)
33.615... logprob:  0.723029, 0.324219 (1.433 sec)
33.616... logprob:  0.626370, 0.304687 (1.420 sec)
33.617... logprob:  0.668234, 0.281250 (1.422 sec)
33.618... logprob:  0.742935, 0.302083 (1.431 sec)
33.619... logprob:  0.716913, 0.283854 (1.446 sec)
33.620... logprob:  0.797425, 0.309896 (1.451 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.341281, 0.062500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.152544e-03 [1.075953e-07] 
Layer 'conv1' biases: 2.190058e-06 [6.081910e-11] 
Layer 'conv2' weights[0]: 2.148217e-03 [1.074227e-07] 
Layer 'conv2' biases: 9.999996e-01 [9.425670e-10] 
Layer 'conv3' weights[0]: 2.147232e-03 [1.080908e-07] 
Layer 'conv3' biases: 3.639975e-05 [1.023024e-08] 
Layer 'conv4' weights[0]: 2.156331e-03 [1.088161e-07] 
Layer 'conv4' biases: 9.997985e-01 [3.834236e-07] 
Layer 'conv5' weights[0]: 2.323830e-03 [6.159482e-06] 
Layer 'conv5' biases: 9.989220e-01 [6.859485e-06] 
Layer 'fc6' weights[0]: 6.628931e-03 [9.751644e-08] 
Layer 'fc6' biases: 9.999894e-01 [1.111148e-07] 
Layer 'fc7' weights[0]: 6.970067e-03 [2.635626e-07] 
Layer 'fc7' biases: 9.996952e-01 [5.250479e-07] 
Layer 'fc8' weights[0]: 4.849554e-03 [2.515806e-05] 
Layer 'fc8' biases: 2.829866e-02 [8.611899e-05] 
Train error last 800 batches: 0.654194
-------------------------------------------------------
Not saving because 0.341281 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
33.621... logprob:  0.540524, 0.236979 (1.456 sec)
33.622... logprob:  0.638588, 0.253906 (1.458 sec)
33.623... logprob:  0.672259, 0.294271 (1.460 sec)
33.624... logprob:  0.608735, 0.244792 (1.454 sec)
33.625... logprob:  0.675578, 0.279948 (1.422 sec)
33.626... logprob:  0.575913, 0.250000 (1.430 sec)
33.627... logprob:  0.650893, 0.291667 (1.433 sec)
33.628... logprob:  0.745223, 0.295573 (1.428 sec)
33.629... logprob:  0.611794, 0.266927 (1.468 sec)
33.630... logprob:  0.651923, 0.286458 (1.440 sec)
33.631... logprob:  0.909860, 0.355469 (1.432 sec)
33.632... logprob:  0.698025, 0.295573 (1.478 sec)
33.633... logprob:  0.586981, 0.266927 (1.425 sec)
33.634... logprob:  0.885004, 0.368490 (1.422 sec)
33.635... logprob:  0.644264, 0.277344 (1.435 sec)
33.636... logprob:  0.707624, 0.278646 (1.429 sec)
33.637... logprob:  0.588980, 0.285156 (1.427 sec)
33.638... logprob:  0.638453, 0.286458 (1.474 sec)
33.639... logprob:  0.620086, 0.298177 (1.433 sec)
33.640... logprob:  0.768150, 0.333333 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.446032, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.150384e-03 [1.075860e-07] 
Layer 'conv1' biases: 2.190220e-06 [2.966398e-11] 
Layer 'conv2' weights[0]: 2.146076e-03 [1.073495e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.252463e-10] 
Layer 'conv3' weights[0]: 2.145076e-03 [1.075089e-07] 
Layer 'conv3' biases: 3.644290e-05 [5.149233e-09] 
Layer 'conv4' weights[0]: 2.154178e-03 [1.080845e-07] 
Layer 'conv4' biases: 9.997956e-01 [1.707083e-07] 
Layer 'conv5' weights[0]: 2.320356e-03 [2.717702e-06] 
Layer 'conv5' biases: 9.989952e-01 [2.916910e-06] 
Layer 'fc6' weights[0]: 6.628232e-03 [6.194807e-08] 
Layer 'fc6' biases: 9.999899e-01 [5.891881e-08] 
Layer 'fc7' weights[0]: 6.969427e-03 [1.480067e-07] 
Layer 'fc7' biases: 9.996894e-01 [2.035878e-07] 
Layer 'fc8' weights[0]: 4.698708e-03 [1.234830e-05] 
Layer 'fc8' biases: 2.715928e-02 [2.660825e-05] 
Train error last 800 batches: 0.654713
-------------------------------------------------------
Not saving because 0.446032 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
33.641... logprob:  0.585212, 0.270833 (1.489 sec)
33.642... logprob:  0.693049, 0.283854 (1.431 sec)
33.643... logprob:  0.787394, 0.299479 (1.432 sec)
33.644... logprob:  0.552902, 0.259115 (1.429 sec)
33.645... logprob:  0.689103, 0.316406 (1.430 sec)
33.646... logprob:  0.649425, 0.285156 (1.429 sec)
33.647... logprob:  0.706964, 0.296875 (1.488 sec)
33.648... logprob:  0.598311, 0.250000 (1.424 sec)
33.649... logprob:  0.670067, 0.320312 (1.440 sec)
33.650... logprob:  0.644726, 0.282552 (1.469 sec)
33.651... logprob:  0.641014, 0.278646 (1.425 sec)
33.652... logprob:  0.747070, 0.325521 (1.435 sec)
33.653... logprob:  0.693399, 0.303385 (1.433 sec)
33.654... logprob:  0.825525, 0.358073 (1.420 sec)
33.655... logprob:  0.673796, 0.281250 (1.428 sec)
33.656... logprob:  0.639791, 0.278646 (1.471 sec)
33.657... logprob:  0.637706, 0.283854 (1.435 sec)
33.658... logprob:  0.637569, 0.269531 (1.444 sec)
33.659... logprob:  0.613265, 0.296875 (1.461 sec)
33.660... logprob:  0.653697, 0.311198 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.467343, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.148249e-03 [1.074578e-07] 
Layer 'conv1' biases: 2.190360e-06 [2.843059e-11] 
Layer 'conv2' weights[0]: 2.143925e-03 [1.072579e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.284327e-10] 
Layer 'conv3' weights[0]: 2.142942e-03 [1.073973e-07] 
Layer 'conv3' biases: 3.643476e-05 [5.138570e-09] 
Layer 'conv4' weights[0]: 2.152022e-03 [1.081171e-07] 
Layer 'conv4' biases: 9.997961e-01 [2.109733e-07] 
Layer 'conv5' weights[0]: 2.319845e-03 [3.342654e-06] 
Layer 'conv5' biases: 9.989845e-01 [3.594267e-06] 
Layer 'fc6' weights[0]: 6.627541e-03 [7.131900e-08] 
Layer 'fc6' biases: 9.999900e-01 [7.063057e-08] 
Layer 'fc7' weights[0]: 6.968724e-03 [1.797348e-07] 
Layer 'fc7' biases: 9.996898e-01 [3.081176e-07] 
Layer 'fc8' weights[0]: 4.720475e-03 [1.967939e-05] 
Layer 'fc8' biases: 2.726316e-02 [7.028653e-05] 
Train error last 800 batches: 0.654539
-------------------------------------------------------
Not saving because 0.467343 > 0.299667 (9.300: -1.18%)
======================================================= (2.329 sec)
33.661... logprob:  0.680911, 0.320312 (1.442 sec)
33.662... logprob:  0.734079, 0.308594 (1.463 sec)
33.663... logprob:  0.606296, 0.261719 (1.416 sec)
33.664... logprob:  0.547209, 0.264323 (1.433 sec)
33.665... logprob:  0.672956, 0.324219 (1.451 sec)
33.666... logprob:  0.600908, 0.283854 (1.453 sec)
33.667... logprob:  0.668454, 0.289062 (1.453 sec)
33.668... logprob:  0.637363, 0.279948 (1.451 sec)
33.669... logprob:  0.624602, 0.304687 (1.453 sec)
33.670... logprob:  0.627090, 0.259115 (1.432 sec)
33.671... logprob:  0.653684, 0.305990 (1.420 sec)
33.672... logprob:  0.636564, 0.283854 (1.422 sec)
33.673... logprob:  0.596270, 0.269531 (1.434 sec)
33.674... logprob:  0.651394, 0.287760 (1.441 sec)
33.675... logprob:  0.612405, 0.257812 (1.459 sec)
33.676... logprob:  0.734275, 0.335938 (1.448 sec)
33.677... logprob:  0.677066, 0.300781 (1.434 sec)
33.678... logprob:  0.695280, 0.295573 (1.473 sec)
33.679... logprob:  0.678760, 0.313802 (1.426 sec)
33.680... logprob:  0.604503, 0.251302 (1.419 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.466570, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.146090e-03 [1.073236e-07] 
Layer 'conv1' biases: 2.190640e-06 [3.165155e-11] 
Layer 'conv2' weights[0]: 2.141794e-03 [1.071303e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.438103e-10] 
Layer 'conv3' weights[0]: 2.140781e-03 [1.072073e-07] 
Layer 'conv3' biases: 3.640567e-05 [4.114107e-09] 
Layer 'conv4' weights[0]: 2.149860e-03 [1.077256e-07] 
Layer 'conv4' biases: 9.997971e-01 [1.401616e-07] 
Layer 'conv5' weights[0]: 2.319346e-03 [2.296042e-06] 
Layer 'conv5' biases: 9.989363e-01 [2.532876e-06] 
Layer 'fc6' weights[0]: 6.626851e-03 [5.788383e-08] 
Layer 'fc6' biases: 9.999896e-01 [5.408415e-08] 
Layer 'fc7' weights[0]: 6.967991e-03 [1.367764e-07] 
Layer 'fc7' biases: 9.996929e-01 [1.685762e-07] 
Layer 'fc8' weights[0]: 4.805552e-03 [1.143836e-05] 
Layer 'fc8' biases: 2.789707e-02 [2.070643e-05] 
Train error last 800 batches: 0.654573
-------------------------------------------------------
Not saving because 0.466570 > 0.299667 (9.300: -1.18%)
======================================================= (2.362 sec)
33.681... logprob:  0.635795, 0.292969 (1.434 sec)
33.682... logprob:  0.553314, 0.257812 (1.430 sec)
33.683... logprob:  0.648597, 0.269531 (1.422 sec)
33.684... logprob:  0.514777, 0.236979 (1.476 sec)
33.685... logprob:  0.524331, 0.236979 (1.437 sec)
33.686... logprob:  0.510989, 0.226562 (1.425 sec)
33.687... logprob:  0.494324, 0.233073 (1.480 sec)
33.688... logprob:  0.575951, 0.260417 (1.427 sec)
33.689... logprob:  0.638465, 0.290365 (1.423 sec)
33.690... logprob:  0.693510, 0.311198 (1.434 sec)
33.691... logprob:  0.752283, 0.322917 (1.430 sec)
33.692... logprob:  0.723698, 0.319010 (1.427 sec)
33.693... logprob:  0.706502, 0.309896 (1.475 sec)
33.694... logprob:  0.609153, 0.266927 (1.433 sec)
33.695... logprob:  0.538375, 0.235677 (1.444 sec)
33.696... logprob:  0.748369, 0.332031 (1.477 sec)
33.697... logprob:  0.666041, 0.305990 (1.428 sec)
33.698... logprob:  0.718996, 0.312500 (1.427 sec)
33.699... logprob:  0.710223, 0.329427 (1.425 sec)
33.700... logprob:  0.668832, 0.281250 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.499923, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.143945e-03 [1.071986e-07] 
Layer 'conv1' biases: 2.190806e-06 [3.109460e-11] 
Layer 'conv2' weights[0]: 2.139650e-03 [1.070122e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.773399e-10] 
Layer 'conv3' weights[0]: 2.138653e-03 [1.071764e-07] 
Layer 'conv3' biases: 3.638638e-05 [5.440765e-09] 
Layer 'conv4' weights[0]: 2.147707e-03 [1.076494e-07] 
Layer 'conv4' biases: 9.997980e-01 [1.842972e-07] 
Layer 'conv5' weights[0]: 2.318552e-03 [3.159784e-06] 
Layer 'conv5' biases: 9.989105e-01 [3.491783e-06] 
Layer 'fc6' weights[0]: 6.626136e-03 [6.566758e-08] 
Layer 'fc6' biases: 9.999896e-01 [6.546313e-08] 
Layer 'fc7' weights[0]: 6.967281e-03 [1.595121e-07] 
Layer 'fc7' biases: 9.996945e-01 [2.474252e-07] 
Layer 'fc8' weights[0]: 4.850608e-03 [1.371619e-05] 
Layer 'fc8' biases: 2.829649e-02 [3.311568e-05] 
Train error last 800 batches: 0.654629
-------------------------------------------------------
Not saving because 0.499923 > 0.299667 (9.300: -1.18%)
======================================================= (2.352 sec)
33.701... logprob:  0.729132, 0.312500 (1.438 sec)
33.702... logprob:  0.693092, 0.307292 (1.486 sec)
33.703... logprob:  0.635540, 0.282552 (1.438 sec)
33.704... logprob:  0.691258, 0.308594 (1.443 sec)
33.705... logprob:  0.637595, 0.285156 (1.471 sec)
33.706... logprob:  0.717257, 0.307292 (1.433 sec)
33.707... logprob:  0.673735, 0.290365 (1.438 sec)
33.708... logprob:  0.691094, 0.308594 (1.431 sec)
33.709... logprob:  0.719397, 0.312500 (1.419 sec)
33.710... logprob:  0.757797, 0.316406 (1.431 sec)
33.711... logprob:  0.697869, 0.311198 (1.459 sec)
33.712... logprob:  0.557313, 0.231771 (1.443 sec)
33.713... logprob:  0.857683, 0.329427 (1.448 sec)
33.714... logprob:  0.719613, 0.311198 (1.449 sec)
33.715... logprob:  0.591005, 0.246094 (1.448 sec)
33.716... logprob:  0.649079, 0.289062 (1.431 sec)
33.717... logprob:  0.620261, 0.282552 (1.418 sec)
33.718... logprob:  0.627124, 0.251302 (1.423 sec)
33.719... logprob:  0.625679, 0.278646 (1.432 sec)
33.720... logprob:  0.702019, 0.296875 (1.442 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.481817, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.141804e-03 [1.070949e-07] 
Layer 'conv1' biases: 2.190948e-06 [2.476609e-11] 
Layer 'conv2' weights[0]: 2.137518e-03 [1.069090e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.766733e-10] 
Layer 'conv3' weights[0]: 2.136500e-03 [1.069702e-07] 
Layer 'conv3' biases: 3.642211e-05 [3.910584e-09] 
Layer 'conv4' weights[0]: 2.145566e-03 [1.074861e-07] 
Layer 'conv4' biases: 9.997954e-01 [1.402240e-07] 
Layer 'conv5' weights[0]: 2.314873e-03 [2.502701e-06] 
Layer 'conv5' biases: 9.989788e-01 [2.708642e-06] 
Layer 'fc6' weights[0]: 6.625497e-03 [6.166259e-08] 
Layer 'fc6' biases: 9.999899e-01 [5.864413e-08] 
Layer 'fc7' weights[0]: 6.966581e-03 [1.446374e-07] 
Layer 'fc7' biases: 9.996897e-01 [1.948973e-07] 
Layer 'fc8' weights[0]: 4.720291e-03 [1.216851e-05] 
Layer 'fc8' biases: 2.733061e-02 [2.317977e-05] 
Train error last 800 batches: 0.655436
-------------------------------------------------------
Not saving because 0.481817 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
33.721... logprob:  0.655852, 0.272135 (1.464 sec)
33.722... logprob:  0.713332, 0.324219 (1.455 sec)
33.723... logprob:  0.669495, 0.294271 (1.445 sec)
33.724... logprob:  0.681652, 0.273437 (1.466 sec)
33.725... logprob:  0.674085, 0.309896 (1.425 sec)
33.726... logprob:  0.507217, 0.208333 (1.422 sec)
33.727... logprob:  0.653547, 0.289062 (1.427 sec)
33.728... logprob:  0.666537, 0.277344 (1.433 sec)
33.729... logprob:  0.634243, 0.265625 (1.426 sec)
33.730... logprob:  0.706433, 0.304687 (1.470 sec)
33.731... logprob:  0.718432, 0.348958 (1.444 sec)
33.732... logprob:  0.535556, 0.240885 (1.436 sec)
33.733... logprob:  0.806178, 0.363281 (1.481 sec)
33.734... logprob:  0.601788, 0.243490 (1.425 sec)
33.735... logprob:  0.836369, 0.371094 (1.425 sec)
33.736... logprob:  0.702260, 0.299479 (1.435 sec)
33.737... logprob:  0.719785, 0.308594 (1.425 sec)
33.738... logprob:  0.643005, 0.285156 (1.427 sec)
33.739... logprob:  0.718098, 0.320312 (1.475 sec)
33.740... logprob:  0.569307, 0.238281 (1.441 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.525411, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.139667e-03 [1.069674e-07] 
Layer 'conv1' biases: 2.191255e-06 [4.124499e-11] 
Layer 'conv2' weights[0]: 2.135370e-03 [1.067986e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.873315e-10] 
Layer 'conv3' weights[0]: 2.134378e-03 [1.070089e-07] 
Layer 'conv3' biases: 3.642132e-05 [5.375801e-09] 
Layer 'conv4' weights[0]: 2.143427e-03 [1.075464e-07] 
Layer 'conv4' biases: 9.997942e-01 [1.771857e-07] 
Layer 'conv5' weights[0]: 2.312437e-03 [2.167869e-06] 
Layer 'conv5' biases: 9.989769e-01 [2.343686e-06] 
Layer 'fc6' weights[0]: 6.624794e-03 [5.774469e-08] 
Layer 'fc6' biases: 9.999897e-01 [5.308540e-08] 
Layer 'fc7' weights[0]: 6.965895e-03 [1.377671e-07] 
Layer 'fc7' biases: 9.996899e-01 [1.599798e-07] 
Layer 'fc8' weights[0]: 4.735835e-03 [1.083342e-05] 
Layer 'fc8' biases: 2.746572e-02 [6.964173e-06] 
Train error last 800 batches: 0.655433
-------------------------------------------------------
Not saving because 0.525411 > 0.299667 (9.300: -1.18%)
======================================================= (2.402 sec)
33.741... logprob:  0.620875, 0.255208 (1.439 sec)
33.742... logprob:  0.658219, 0.299479 (1.484 sec)
33.743... logprob:  0.647691, 0.281250 (1.424 sec)
33.744... logprob:  0.699942, 0.283854 (1.424 sec)
33.745... logprob:  0.671227, 0.311198 (1.432 sec)
33.746... logprob:  0.626410, 0.279948 (1.420 sec)
33.747... logprob:  0.683915, 0.283854 (1.429 sec)
33.748... logprob:  0.644655, 0.252604 (1.478 sec)
33.749... logprob:  0.574038, 0.251302 (1.429 sec)
33.750... logprob:  0.643151, 0.287760 (1.438 sec)
33.751... logprob:  0.544449, 0.247396 (1.472 sec)
33.752... logprob:  0.660635, 0.291667 (1.426 sec)
33.753... logprob:  0.626415, 0.277344 (1.428 sec)
33.754... logprob:  0.666518, 0.279948 (1.428 sec)
33.755... logprob:  0.726402, 0.278646 (1.421 sec)
33.756... logprob:  0.724965, 0.272135 (1.426 sec)
33.757... logprob:  0.783650, 0.315104 (1.470 sec)
33.758... logprob:  0.626687, 0.283854 (1.443 sec)
33.759... logprob:  0.759664, 0.347656 (1.446 sec)
33.760... logprob:  0.657385, 0.283854 (1.463 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.403215, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.137521e-03 [1.068865e-07] 
Layer 'conv1' biases: 2.191414e-06 [2.655322e-11] 
Layer 'conv2' weights[0]: 2.133234e-03 [1.066858e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.441685e-10] 
Layer 'conv3' weights[0]: 2.132231e-03 [1.067493e-07] 
Layer 'conv3' biases: 3.642624e-05 [3.893358e-09] 
Layer 'conv4' weights[0]: 2.141280e-03 [1.072355e-07] 
Layer 'conv4' biases: 9.997932e-01 [1.503610e-07] 
Layer 'conv5' weights[0]: 2.309680e-03 [2.694350e-06] 
Layer 'conv5' biases: 9.989734e-01 [2.961523e-06] 
Layer 'fc6' weights[0]: 6.624133e-03 [6.442576e-08] 
Layer 'fc6' biases: 9.999897e-01 [6.207750e-08] 
Layer 'fc7' weights[0]: 6.965186e-03 [1.561931e-07] 
Layer 'fc7' biases: 9.996904e-01 [2.207371e-07] 
Layer 'fc8' weights[0]: 4.746973e-03 [1.275500e-05] 
Layer 'fc8' biases: 2.758853e-02 [2.812760e-05] 
Train error last 800 batches: 0.655483
-------------------------------------------------------
Not saving because 0.403215 > 0.299667 (9.300: -1.18%)
======================================================= (2.358 sec)
33.761... logprob:  0.683080, 0.335938 (1.453 sec)
33.762... logprob:  0.818796, 0.334635 (1.442 sec)
33.763... logprob:  0.716600, 0.320312 (1.427 sec)
33.764... logprob:  0.735424, 0.308594 (1.422 sec)
33.765... logprob:  0.520250, 0.214844 (1.437 sec)
33.766... logprob:  0.724253, 0.334635 (1.451 sec)
33.767... logprob:  0.640257, 0.282552 (1.450 sec)
33.768... logprob:  0.689102, 0.281250 (1.464 sec)
33.769... logprob:  0.715392, 0.321615 (1.461 sec)
33.770... logprob:  0.657197, 0.304688 (1.475 sec)
33.771... logprob:  0.714325, 0.304687 (1.448 sec)
33.772... logprob:  0.580488, 0.253906 (1.445 sec)
33.773... logprob:  0.763251, 0.322917 (1.442 sec)
33.774... logprob:  0.627689, 0.282552 (1.452 sec)
33.775... logprob:  0.624425, 0.276042 (1.457 sec)
33.776... logprob:  0.699053, 0.295573 (1.474 sec)
33.777... logprob:  0.608816, 0.266927 (1.464 sec)
33.778... logprob:  0.712946, 0.320313 (1.468 sec)
33.779... logprob:  0.760579, 0.308594 (1.482 sec)
33.780... logprob:  0.711174, 0.317708 (1.456 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.514223, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.135380e-03 [1.068002e-07] 
Layer 'conv1' biases: 2.191652e-06 [2.020407e-11] 
Layer 'conv2' weights[0]: 2.131106e-03 [1.065894e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.661605e-10] 
Layer 'conv3' weights[0]: 2.130109e-03 [1.066166e-07] 
Layer 'conv3' biases: 3.642710e-05 [3.187937e-09] 
Layer 'conv4' weights[0]: 2.139136e-03 [1.071007e-07] 
Layer 'conv4' biases: 9.997918e-01 [1.122126e-07] 
Layer 'conv5' weights[0]: 2.306869e-03 [2.030024e-06] 
Layer 'conv5' biases: 9.989850e-01 [2.222721e-06] 
Layer 'fc6' weights[0]: 6.623454e-03 [5.963618e-08] 
Layer 'fc6' biases: 9.999899e-01 [5.534994e-08] 
Layer 'fc7' weights[0]: 6.964496e-03 [1.429055e-07] 
Layer 'fc7' biases: 9.996896e-01 [1.732767e-07] 
Layer 'fc8' weights[0]: 4.719692e-03 [1.193090e-05] 
Layer 'fc8' biases: 2.740271e-02 [1.622375e-05] 
Train error last 800 batches: 0.656291
-------------------------------------------------------
Not saving because 0.514223 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
33.781... logprob:  0.659797, 0.300781 (1.451 sec)
33.782... logprob:  0.550527, 0.247396 (1.450 sec)
33.783... logprob:  0.703176, 0.330729 (1.450 sec)
33.784... logprob:  0.625791, 0.257813 (1.454 sec)
33.785... logprob:  0.718645, 0.335938 (1.485 sec)
33.786... logprob:  0.660784, 0.300781 (1.463 sec)
33.787... logprob:  0.734452, 0.320312 (1.454 sec)
33.788... logprob:  0.716178, 0.287760 (1.486 sec)
33.789... logprob:  0.631229, 0.285156 (1.449 sec)
33.790... logprob:  0.657711, 0.295573 (1.447 sec)
33.791... logprob:  0.635619, 0.273438 (1.440 sec)
33.792... logprob:  0.605498, 0.269531 (1.454 sec)
33.793... logprob:  0.581192, 0.276042 (1.449 sec)
33.794... logprob:  0.633997, 0.274740 (1.488 sec)
33.795... logprob:  0.684765, 0.269531 (1.460 sec)
33.796... logprob:  0.614540, 0.276042 (1.457 sec)
33.797... logprob:  0.612030, 0.259115 (1.494 sec)
33.798... logprob:  0.643442, 0.278646 (1.445 sec)
33.799... logprob:  0.624887, 0.294271 (1.445 sec)
33.800... logprob:  0.673972, 0.277344 (1.399 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.465525, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.133257e-03 [1.066681e-07] 
Layer 'conv1' biases: 2.191843e-06 [3.637016e-11] 
Layer 'conv2' weights[0]: 2.128974e-03 [1.064820e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.166740e-10] 
Layer 'conv3' weights[0]: 2.127974e-03 [1.065808e-07] 
Layer 'conv3' biases: 3.640960e-05 [4.602210e-09] 
Layer 'conv4' weights[0]: 2.137000e-03 [1.071144e-07] 
Layer 'conv4' biases: 9.997919e-01 [1.553285e-07] 
Layer 'conv5' weights[0]: 2.304865e-03 [2.868708e-06] 
Layer 'conv5' biases: 9.989565e-01 [3.200654e-06] 
Layer 'fc6' weights[0]: 6.622777e-03 [6.454358e-08] 
Layer 'fc6' biases: 9.999898e-01 [6.218840e-08] 
Layer 'fc7' weights[0]: 6.963796e-03 [1.579763e-07] 
Layer 'fc7' biases: 9.996904e-01 [2.382278e-07] 
Layer 'fc8' weights[0]: 4.781018e-03 [1.472405e-05] 
Layer 'fc8' biases: 2.788865e-02 [4.534208e-05] 
Train error last 800 batches: 0.655934
-------------------------------------------------------
Not saving because 0.465525 > 0.299667 (9.300: -1.18%)
======================================================= (2.397 sec)
34.1... logprob:  0.612535, 0.279948 (1.406 sec)
34.2... logprob:  0.595121, 0.260417 (1.446 sec)
34.3... logprob:  0.658497, 0.285156 (1.410 sec)
34.4... logprob:  0.664315, 0.290365 (1.405 sec)
34.5... logprob:  0.647005, 0.276042 (1.425 sec)
34.6... logprob:  0.665376, 0.281250 (1.391 sec)
34.7... logprob:  0.607655, 0.259115 (1.416 sec)
34.8... logprob:  0.776308, 0.312500 (1.394 sec)
34.9... logprob:  0.654511, 0.273438 (1.399 sec)
34.10... logprob:  0.618422, 0.223958 (1.406 sec)
34.11... logprob:  0.632531, 0.252604 (1.439 sec)
34.12... logprob:  0.675617, 0.279948 (1.394 sec)
34.13... logprob:  0.705842, 0.312500 (1.420 sec)
34.14... logprob:  0.670289, 0.291667 (1.392 sec)
34.15... logprob:  0.651435, 0.286458 (1.407 sec)
34.16... logprob:  0.661045, 0.296875 (1.427 sec)
34.17... logprob:  0.788799, 0.341146 (1.395 sec)
34.18... logprob:  0.533119, 0.252604 (1.395 sec)
34.19... logprob:  0.664646, 0.316406 (1.401 sec)
34.20... logprob:  0.599883, 0.270833 (1.397 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.539249, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.131127e-03 [1.065934e-07] 
Layer 'conv1' biases: 2.192013e-06 [2.026606e-11] 
Layer 'conv2' weights[0]: 2.126846e-03 [1.063876e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.664598e-10] 
Layer 'conv3' weights[0]: 2.125846e-03 [1.063983e-07] 
Layer 'conv3' biases: 3.642267e-05 [2.999341e-09] 
Layer 'conv4' weights[0]: 2.134861e-03 [1.068644e-07] 
Layer 'conv4' biases: 9.997911e-01 [9.558442e-08] 
Layer 'conv5' weights[0]: 2.302331e-03 [1.976727e-06] 
Layer 'conv5' biases: 9.989584e-01 [2.136117e-06] 
Layer 'fc6' weights[0]: 6.622095e-03 [5.677127e-08] 
Layer 'fc6' biases: 9.999896e-01 [5.216814e-08] 
Layer 'fc7' weights[0]: 6.963112e-03 [1.329417e-07] 
Layer 'fc7' biases: 9.996904e-01 [1.607801e-07] 
Layer 'fc8' weights[0]: 4.764275e-03 [1.102557e-05] 
Layer 'fc8' biases: 2.783143e-02 [1.845857e-05] 
Train error last 800 batches: 0.656277
-------------------------------------------------------
Not saving because 0.539249 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
34.21... logprob:  0.587966, 0.259115 (1.405 sec)
34.22... logprob:  0.769405, 0.319010 (1.413 sec)
34.23... logprob:  0.659917, 0.294271 (1.406 sec)
34.24... logprob:  0.546067, 0.250000 (1.412 sec)
34.25... logprob:  0.514578, 0.251302 (1.401 sec)
34.26... logprob:  0.709937, 0.291667 (1.438 sec)
34.27... logprob:  0.662709, 0.296875 (1.385 sec)
34.28... logprob:  0.620119, 0.276042 (1.415 sec)
34.29... logprob:  0.609246, 0.278646 (1.421 sec)
34.30... logprob:  0.578490, 0.247396 (1.410 sec)
34.31... logprob:  0.677224, 0.302083 (1.401 sec)
34.32... logprob:  0.700834, 0.304687 (1.383 sec)
34.33... logprob:  0.620222, 0.278646 (1.439 sec)
34.34... logprob:  0.638504, 0.269531 (1.385 sec)
34.35... logprob:  0.573039, 0.253906 (1.394 sec)
34.36... logprob:  0.600319, 0.242187 (1.396 sec)
34.37... logprob:  0.611140, 0.255208 (1.405 sec)
34.38... logprob:  0.574726, 0.286458 (1.389 sec)
34.39... logprob:  0.925941, 0.359375 (1.437 sec)
34.40... logprob:  0.630471, 0.292969 (1.398 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.420313, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.128992e-03 [1.064828e-07] 
Layer 'conv1' biases: 2.192069e-06 [2.396171e-11] 
Layer 'conv2' weights[0]: 2.124707e-03 [1.062768e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.147244e-10] 
Layer 'conv3' weights[0]: 2.123740e-03 [1.064085e-07] 
Layer 'conv3' biases: 3.641881e-05 [4.899996e-09] 
Layer 'conv4' weights[0]: 2.132728e-03 [1.069201e-07] 
Layer 'conv4' biases: 9.997924e-01 [1.730403e-07] 
Layer 'conv5' weights[0]: 2.302043e-03 [2.468531e-06] 
Layer 'conv5' biases: 9.989412e-01 [2.660021e-06] 
Layer 'fc6' weights[0]: 6.621432e-03 [6.155913e-08] 
Layer 'fc6' biases: 9.999897e-01 [5.909456e-08] 
Layer 'fc7' weights[0]: 6.962439e-03 [1.450186e-07] 
Layer 'fc7' biases: 9.996909e-01 [1.900174e-07] 
Layer 'fc8' weights[0]: 4.789565e-03 [1.242649e-05] 
Layer 'fc8' biases: 2.804047e-02 [2.299513e-05] 
Train error last 800 batches: 0.656122
-------------------------------------------------------
Not saving because 0.420313 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
34.41... logprob:  0.615909, 0.282552 (1.429 sec)
34.42... logprob:  0.697930, 0.322917 (1.412 sec)
34.43... logprob:  0.663968, 0.282552 (1.407 sec)
34.44... logprob:  0.650691, 0.299479 (1.429 sec)
34.45... logprob:  0.587335, 0.277344 (1.382 sec)
34.46... logprob:  0.604925, 0.261719 (1.399 sec)
34.47... logprob:  0.517879, 0.252604 (1.391 sec)
34.48... logprob:  0.644091, 0.274740 (1.424 sec)
34.49... logprob:  0.595443, 0.270833 (1.415 sec)
34.50... logprob:  0.631715, 0.260417 (1.415 sec)
34.51... logprob:  0.665447, 0.296875 (1.412 sec)
34.52... logprob:  0.720101, 0.307292 (1.391 sec)
34.53... logprob:  0.563759, 0.281250 (1.440 sec)
34.54... logprob:  0.594608, 0.269531 (1.383 sec)
34.55... logprob:  0.556528, 0.269531 (1.414 sec)
34.56... logprob:  0.677110, 0.278646 (1.395 sec)
34.57... logprob:  0.804127, 0.324219 (1.425 sec)
34.58... logprob:  0.670308, 0.292969 (1.397 sec)
34.59... logprob:  0.565618, 0.247396 (1.461 sec)
34.60... logprob:  0.850581, 0.377604 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.370214, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.126859e-03 [1.063688e-07] 
Layer 'conv1' biases: 2.192296e-06 [3.240158e-11] 
Layer 'conv2' weights[0]: 2.122597e-03 [1.061656e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.182548e-10] 
Layer 'conv3' weights[0]: 2.121603e-03 [1.064034e-07] 
Layer 'conv3' biases: 3.642882e-05 [6.085292e-09] 
Layer 'conv4' weights[0]: 2.130589e-03 [1.069090e-07] 
Layer 'conv4' biases: 9.997918e-01 [2.021753e-07] 
Layer 'conv5' weights[0]: 2.299718e-03 [3.211324e-06] 
Layer 'conv5' biases: 9.989379e-01 [3.542996e-06] 
Layer 'fc6' weights[0]: 6.620759e-03 [6.716542e-08] 
Layer 'fc6' biases: 9.999896e-01 [6.672810e-08] 
Layer 'fc7' weights[0]: 6.961720e-03 [1.584949e-07] 
Layer 'fc7' biases: 9.996913e-01 [2.340873e-07] 
Layer 'fc8' weights[0]: 4.803822e-03 [1.343837e-05] 
Layer 'fc8' biases: 2.810749e-02 [3.450082e-05] 
Train error last 800 batches: 0.656008
-------------------------------------------------------
Not saving because 0.370214 > 0.299667 (9.300: -1.18%)
======================================================= (2.344 sec)
34.61... logprob:  0.625224, 0.290365 (1.431 sec)
34.62... logprob:  0.687919, 0.305989 (1.456 sec)
34.63... logprob:  0.685172, 0.299479 (1.436 sec)
34.64... logprob:  0.616899, 0.273437 (1.401 sec)
34.65... logprob:  0.636080, 0.283854 (1.393 sec)
34.66... logprob:  0.629253, 0.269531 (1.439 sec)
34.67... logprob:  0.578196, 0.270833 (1.383 sec)
34.68... logprob:  0.728099, 0.321615 (1.394 sec)
34.69... logprob:  0.751218, 0.346354 (1.421 sec)
34.70... logprob:  0.565976, 0.252604 (1.429 sec)
34.71... logprob:  0.598739, 0.264323 (1.455 sec)
34.72... logprob:  0.709094, 0.324219 (1.393 sec)
34.73... logprob:  0.616588, 0.273437 (1.418 sec)
34.74... logprob:  0.698633, 0.299479 (1.411 sec)
34.75... logprob:  0.678247, 0.307292 (1.409 sec)
34.76... logprob:  0.608561, 0.282552 (1.428 sec)
34.77... logprob:  0.660416, 0.296875 (1.425 sec)
34.78... logprob:  0.774009, 0.313802 (1.444 sec)
34.79... logprob:  0.688609, 0.316406 (1.405 sec)
34.80... logprob:  0.670169, 0.282552 (1.413 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.470574, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.124736e-03 [1.062771e-07] 
Layer 'conv1' biases: 2.192263e-06 [2.983367e-11] 
Layer 'conv2' weights[0]: 2.120474e-03 [1.060809e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.115710e-10] 
Layer 'conv3' weights[0]: 2.119471e-03 [1.062848e-07] 
Layer 'conv3' biases: 3.644599e-05 [6.234900e-09] 
Layer 'conv4' weights[0]: 2.128471e-03 [1.067858e-07] 
Layer 'conv4' biases: 9.997922e-01 [1.944211e-07] 
Layer 'conv5' weights[0]: 2.298114e-03 [2.327987e-06] 
Layer 'conv5' biases: 9.989517e-01 [2.462474e-06] 
Layer 'fc6' weights[0]: 6.620082e-03 [5.963315e-08] 
Layer 'fc6' biases: 9.999899e-01 [5.615025e-08] 
Layer 'fc7' weights[0]: 6.960985e-03 [1.431599e-07] 
Layer 'fc7' biases: 9.996901e-01 [1.881243e-07] 
Layer 'fc8' weights[0]: 4.775600e-03 [1.256189e-05] 
Layer 'fc8' biases: 2.794148e-02 [2.638251e-05] 
Train error last 800 batches: 0.656373
-------------------------------------------------------
Not saving because 0.470574 > 0.299667 (9.300: -1.18%)
======================================================= (2.360 sec)
34.81... logprob:  0.668812, 0.309896 (1.418 sec)
34.82... logprob:  0.442253, 0.204427 (1.425 sec)
34.83... logprob:  0.711186, 0.339844 (1.390 sec)
34.84... logprob:  0.660409, 0.285156 (1.462 sec)
34.85... logprob:  0.689706, 0.322917 (1.417 sec)
34.86... logprob:  0.622963, 0.260417 (1.415 sec)
34.87... logprob:  0.790678, 0.347656 (1.414 sec)
34.88... logprob:  0.698090, 0.304688 (1.401 sec)
34.89... logprob:  0.663101, 0.290364 (1.435 sec)
34.90... logprob:  0.731823, 0.316406 (1.387 sec)
34.91... logprob:  0.650703, 0.329427 (1.390 sec)
34.92... logprob:  0.660278, 0.285156 (1.398 sec)
34.93... logprob:  0.601764, 0.265625 (1.396 sec)
34.94... logprob:  0.620715, 0.256510 (1.392 sec)
34.95... logprob:  0.616191, 0.274740 (1.401 sec)
34.96... logprob:  0.829472, 0.338542 (1.397 sec)
34.97... logprob:  0.664348, 0.292969 (1.391 sec)
34.98... logprob:  0.581993, 0.253906 (1.430 sec)
34.99... logprob:  0.776560, 0.341146 (1.403 sec)
34.100... logprob:  0.460787, 0.201823 (1.408 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.499950, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.122607e-03 [1.061953e-07] 
Layer 'conv1' biases: 2.192275e-06 [2.233721e-11] 
Layer 'conv2' weights[0]: 2.118343e-03 [1.059749e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.944386e-10] 
Layer 'conv3' weights[0]: 2.117351e-03 [1.059861e-07] 
Layer 'conv3' biases: 3.644787e-05 [3.178258e-09] 
Layer 'conv4' weights[0]: 2.126344e-03 [1.064786e-07] 
Layer 'conv4' biases: 9.997928e-01 [1.199931e-07] 
Layer 'conv5' weights[0]: 2.297222e-03 [2.061906e-06] 
Layer 'conv5' biases: 9.989564e-01 [2.207689e-06] 
Layer 'fc6' weights[0]: 6.619395e-03 [5.787817e-08] 
Layer 'fc6' biases: 9.999899e-01 [5.345024e-08] 
Layer 'fc7' weights[0]: 6.960314e-03 [1.360665e-07] 
Layer 'fc7' biases: 9.996893e-01 [1.664708e-07] 
Layer 'fc8' weights[0]: 4.758034e-03 [1.132527e-05] 
Layer 'fc8' biases: 2.776437e-02 [1.939391e-05] 
Train error last 800 batches: 0.655992
-------------------------------------------------------
Not saving because 0.499950 > 0.299667 (9.300: -1.18%)
======================================================= (2.362 sec)
34.101... logprob:  0.571004, 0.272135 (1.443 sec)
34.102... logprob:  0.793110, 0.321615 (1.392 sec)
34.103... logprob:  0.728813, 0.319010 (1.400 sec)
34.104... logprob:  0.599338, 0.252604 (1.395 sec)
34.105... logprob:  0.792552, 0.350260 (1.388 sec)
34.106... logprob:  0.474334, 0.225260 (1.386 sec)
34.107... logprob:  0.594089, 0.217448 (1.435 sec)
34.108... logprob:  0.748016, 0.324219 (1.398 sec)
34.109... logprob:  0.567063, 0.238281 (1.398 sec)
34.110... logprob:  0.687924, 0.299479 (1.392 sec)
34.111... logprob:  0.647181, 0.255208 (1.392 sec)
34.112... logprob:  0.660830, 0.315104 (1.399 sec)
34.113... logprob:  0.588337, 0.266927 (1.392 sec)
34.114... logprob:  0.585259, 0.255208 (1.426 sec)
34.115... logprob:  0.697321, 0.299479 (1.406 sec)
34.116... logprob:  0.584324, 0.259114 (1.396 sec)
34.117... logprob:  0.678339, 0.305990 (1.441 sec)
34.118... logprob:  0.613633, 0.253906 (1.387 sec)
34.119... logprob:  0.589673, 0.264323 (1.391 sec)
34.120... logprob:  0.782552, 0.341146 (1.397 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.558602, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.120492e-03 [1.060504e-07] 
Layer 'conv1' biases: 2.192398e-06 [3.228484e-11] 
Layer 'conv2' weights[0]: 2.116238e-03 [1.058675e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.695340e-10] 
Layer 'conv3' weights[0]: 2.115240e-03 [1.059825e-07] 
Layer 'conv3' biases: 3.643620e-05 [4.814644e-09] 
Layer 'conv4' weights[0]: 2.124210e-03 [1.065757e-07] 
Layer 'conv4' biases: 9.997938e-01 [1.497077e-07] 
Layer 'conv5' weights[0]: 2.296459e-03 [2.439211e-06] 
Layer 'conv5' biases: 9.989474e-01 [2.677806e-06] 
Layer 'fc6' weights[0]: 6.618780e-03 [6.005845e-08] 
Layer 'fc6' biases: 9.999899e-01 [5.637599e-08] 
Layer 'fc7' weights[0]: 6.959562e-03 [1.435488e-07] 
Layer 'fc7' biases: 9.996900e-01 [1.895248e-07] 
Layer 'fc8' weights[0]: 4.783822e-03 [1.205817e-05] 
Layer 'fc8' biases: 2.792444e-02 [2.778932e-05] 
Train error last 800 batches: 0.655884
-------------------------------------------------------
Not saving because 0.558602 > 0.299667 (9.300: -1.18%)
======================================================= (2.416 sec)
34.121... logprob:  0.592188, 0.263021 (1.398 sec)
34.122... logprob:  0.789949, 0.329427 (1.447 sec)
34.123... logprob:  0.665920, 0.298177 (1.387 sec)
34.124... logprob:  0.642066, 0.270833 (1.400 sec)
34.125... logprob:  0.737297, 0.305990 (1.389 sec)
34.126... logprob:  0.690949, 0.281250 (1.387 sec)
34.127... logprob:  0.657190, 0.296875 (1.391 sec)
34.128... logprob:  0.616640, 0.268229 (1.413 sec)
34.129... logprob:  0.724109, 0.299479 (1.412 sec)
34.130... logprob:  0.602393, 0.274740 (1.412 sec)
34.131... logprob:  0.651186, 0.312500 (1.404 sec)
34.132... logprob:  0.698394, 0.287760 (1.431 sec)
34.133... logprob:  0.613610, 0.277344 (1.386 sec)
34.134... logprob:  0.528439, 0.239583 (1.393 sec)
34.135... logprob:  0.618829, 0.298177 (1.404 sec)
34.136... logprob:  0.685713, 0.317708 (1.395 sec)
34.137... logprob:  0.662950, 0.291667 (1.389 sec)
34.138... logprob:  0.512469, 0.233073 (1.439 sec)
34.139... logprob:  0.619254, 0.272135 (1.392 sec)
34.140... logprob:  0.659102, 0.291667 (1.405 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.438673, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.118369e-03 [1.059733e-07] 
Layer 'conv1' biases: 2.192531e-06 [2.743451e-11] 
Layer 'conv2' weights[0]: 2.114110e-03 [1.057688e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.722244e-10] 
Layer 'conv3' weights[0]: 2.113131e-03 [1.058627e-07] 
Layer 'conv3' biases: 3.643192e-05 [4.587953e-09] 
Layer 'conv4' weights[0]: 2.122098e-03 [1.064952e-07] 
Layer 'conv4' biases: 9.997938e-01 [1.514724e-07] 
Layer 'conv5' weights[0]: 2.294631e-03 [2.814058e-06] 
Layer 'conv5' biases: 9.989433e-01 [3.087446e-06] 
Layer 'fc6' weights[0]: 6.618086e-03 [6.151128e-08] 
Layer 'fc6' biases: 9.999897e-01 [5.862708e-08] 
Layer 'fc7' weights[0]: 6.958854e-03 [1.486403e-07] 
Layer 'fc7' biases: 9.996898e-01 [2.188314e-07] 
Layer 'fc8' weights[0]: 4.787446e-03 [1.377513e-05] 
Layer 'fc8' biases: 2.801403e-02 [3.127641e-05] 
Train error last 800 batches: 0.655244
-------------------------------------------------------
Not saving because 0.438673 > 0.299667 (9.300: -1.18%)
======================================================= (2.355 sec)
34.141... logprob:  0.690512, 0.296875 (1.441 sec)
34.142... logprob:  0.599189, 0.274740 (1.397 sec)
34.143... logprob:  0.497188, 0.234375 (1.416 sec)
34.144... logprob:  0.589204, 0.257812 (1.414 sec)
34.145... logprob:  0.574521, 0.268229 (1.410 sec)
34.146... logprob:  0.802811, 0.345052 (1.400 sec)
34.147... logprob:  0.499936, 0.223958 (1.425 sec)
34.148... logprob:  0.594162, 0.279948 (1.386 sec)
34.149... logprob:  0.648552, 0.291667 (1.386 sec)
34.150... logprob:  0.610239, 0.268229 (1.396 sec)
34.151... logprob:  0.653520, 0.296875 (1.395 sec)
34.152... logprob:  0.952731, 0.394531 (1.392 sec)
34.153... logprob:  0.614804, 0.257812 (1.445 sec)
34.154... logprob:  0.759295, 0.328125 (1.407 sec)
34.155... logprob:  0.652500, 0.283854 (1.402 sec)
34.156... logprob:  0.623351, 0.266927 (1.430 sec)
34.157... logprob:  0.520707, 0.248698 (1.386 sec)
34.158... logprob:  0.712991, 0.298177 (1.396 sec)
34.159... logprob:  0.580993, 0.239583 (1.392 sec)
34.160... logprob:  0.682667, 0.276042 (1.382 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.515683, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.116254e-03 [1.058331e-07] 
Layer 'conv1' biases: 2.192627e-06 [2.670699e-11] 
Layer 'conv2' weights[0]: 2.112003e-03 [1.056358e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.927851e-10] 
Layer 'conv3' weights[0]: 2.111014e-03 [1.057587e-07] 
Layer 'conv3' biases: 3.643428e-05 [4.463751e-09] 
Layer 'conv4' weights[0]: 2.119967e-03 [1.062602e-07] 
Layer 'conv4' biases: 9.997947e-01 [1.534173e-07] 
Layer 'conv5' weights[0]: 2.293415e-03 [2.763222e-06] 
Layer 'conv5' biases: 9.989341e-01 [3.103727e-06] 
Layer 'fc6' weights[0]: 6.617392e-03 [6.519015e-08] 
Layer 'fc6' biases: 9.999898e-01 [6.405934e-08] 
Layer 'fc7' weights[0]: 6.958141e-03 [1.576741e-07] 
Layer 'fc7' biases: 9.996905e-01 [2.363701e-07] 
Layer 'fc8' weights[0]: 4.798740e-03 [1.500350e-05] 
Layer 'fc8' biases: 2.808505e-02 [4.303847e-05] 
Train error last 800 batches: 0.655205
-------------------------------------------------------
Not saving because 0.515683 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
34.161... logprob:  0.627496, 0.283854 (1.400 sec)
34.162... logprob:  0.789862, 0.300781 (1.405 sec)
34.163... logprob:  0.658385, 0.290364 (1.420 sec)
34.164... logprob:  0.656704, 0.294271 (1.424 sec)
34.165... logprob:  0.730819, 0.299479 (1.418 sec)
34.166... logprob:  0.594381, 0.264323 (1.442 sec)
34.167... logprob:  0.636969, 0.321615 (1.422 sec)
34.168... logprob:  0.606969, 0.253906 (1.417 sec)
34.169... logprob:  0.633848, 0.276042 (1.456 sec)
34.170... logprob:  0.688182, 0.276042 (1.403 sec)
34.171... logprob:  0.785625, 0.329427 (1.416 sec)
34.172... logprob:  0.655279, 0.270833 (1.411 sec)
34.173... logprob:  0.622419, 0.287760 (1.417 sec)
34.174... logprob:  0.805274, 0.324219 (1.398 sec)
34.175... logprob:  0.627769, 0.292969 (1.468 sec)
34.176... logprob:  0.629327, 0.277344 (1.408 sec)
34.177... logprob:  0.573743, 0.248698 (1.424 sec)
34.178... logprob:  0.616015, 0.248698 (1.457 sec)
34.179... logprob:  0.629198, 0.300781 (1.399 sec)
34.180... logprob:  0.705853, 0.312500 (1.424 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.495071, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.114136e-03 [1.057495e-07] 
Layer 'conv1' biases: 2.192721e-06 [1.725057e-11] 
Layer 'conv2' weights[0]: 2.109887e-03 [1.055498e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.172761e-10] 
Layer 'conv3' weights[0]: 2.108893e-03 [1.055847e-07] 
Layer 'conv3' biases: 3.644030e-05 [3.781987e-09] 
Layer 'conv4' weights[0]: 2.117841e-03 [1.061733e-07] 
Layer 'conv4' biases: 9.997942e-01 [1.587587e-07] 
Layer 'conv5' weights[0]: 2.291677e-03 [2.511514e-06] 
Layer 'conv5' biases: 9.989493e-01 [2.749637e-06] 
Layer 'fc6' weights[0]: 6.616720e-03 [6.353426e-08] 
Layer 'fc6' biases: 9.999898e-01 [6.132969e-08] 
Layer 'fc7' weights[0]: 6.957480e-03 [1.575672e-07] 
Layer 'fc7' biases: 9.996888e-01 [2.364115e-07] 
Layer 'fc8' weights[0]: 4.762842e-03 [1.581501e-05] 
Layer 'fc8' biases: 2.787187e-02 [4.998625e-05] 
Train error last 800 batches: 0.655443
-------------------------------------------------------
Not saving because 0.495071 > 0.299667 (9.300: -1.18%)
======================================================= (2.385 sec)
34.181... logprob:  0.718209, 0.319010 (1.419 sec)
34.182... logprob:  0.604343, 0.268229 (1.416 sec)
34.183... logprob:  0.614376, 0.256510 (1.406 sec)
34.184... logprob:  0.658433, 0.289062 (1.413 sec)
34.185... logprob:  0.572906, 0.252604 (1.395 sec)
34.186... logprob:  0.642684, 0.298177 (1.386 sec)
34.187... logprob:  0.679310, 0.292969 (1.400 sec)
34.188... logprob:  0.724414, 0.320312 (1.385 sec)
34.189... logprob:  0.574069, 0.270833 (1.385 sec)
34.190... logprob:  0.673525, 0.299479 (1.428 sec)
34.191... logprob:  0.684498, 0.282552 (1.403 sec)
34.192... logprob:  0.803957, 0.337240 (1.417 sec)
34.193... logprob:  0.499914, 0.210937 (1.410 sec)
34.194... logprob:  0.602418, 0.246094 (1.409 sec)
34.195... logprob:  0.577284, 0.268229 (1.391 sec)
34.196... logprob:  0.622767, 0.286458 (1.386 sec)
34.197... logprob:  0.684146, 0.303385 (1.392 sec)
34.198... logprob:  0.576531, 0.247396 (1.401 sec)
34.199... logprob:  0.700101, 0.295573 (1.386 sec)
34.200... logprob:  0.676443, 0.303385 (1.432 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.514442, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.112017e-03 [1.056293e-07] 
Layer 'conv1' biases: 2.192898e-06 [3.445168e-11] 
Layer 'conv2' weights[0]: 2.107769e-03 [1.054329e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.270569e-10] 
Layer 'conv3' weights[0]: 2.106790e-03 [1.055636e-07] 
Layer 'conv3' biases: 3.642827e-05 [4.736122e-09] 
Layer 'conv4' weights[0]: 2.115734e-03 [1.061151e-07] 
Layer 'conv4' biases: 9.997944e-01 [1.556921e-07] 
Layer 'conv5' weights[0]: 2.289646e-03 [2.200626e-06] 
Layer 'conv5' biases: 9.989324e-01 [2.278034e-06] 
Layer 'fc6' weights[0]: 6.616040e-03 [5.816630e-08] 
Layer 'fc6' biases: 9.999895e-01 [5.430175e-08] 
Layer 'fc7' weights[0]: 6.956787e-03 [1.382161e-07] 
Layer 'fc7' biases: 9.996890e-01 [1.736334e-07] 
Layer 'fc8' weights[0]: 4.791451e-03 [1.132442e-05] 
Layer 'fc8' biases: 2.815101e-02 [2.069811e-05] 
Train error last 800 batches: 0.655153
-------------------------------------------------------
Not saving because 0.514442 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
34.201... logprob:  0.642883, 0.274740 (1.407 sec)
34.202... logprob:  0.606312, 0.282552 (1.403 sec)
34.203... logprob:  0.616856, 0.253906 (1.434 sec)
34.204... logprob:  0.700452, 0.313802 (1.388 sec)
34.205... logprob:  0.573055, 0.277344 (1.395 sec)
34.206... logprob:  0.617744, 0.278646 (1.396 sec)
34.207... logprob:  0.592716, 0.268229 (1.389 sec)
34.208... logprob:  0.629355, 0.270833 (1.396 sec)
34.209... logprob:  0.586745, 0.278646 (1.414 sec)
34.210... logprob:  0.863863, 0.365885 (1.407 sec)
34.211... logprob:  0.683174, 0.319010 (1.409 sec)
34.212... logprob:  0.752719, 0.319010 (1.413 sec)
34.213... logprob:  0.702153, 0.303385 (1.458 sec)
34.214... logprob:  0.682972, 0.309896 (1.420 sec)
34.215... logprob:  0.591250, 0.248698 (1.412 sec)
34.216... logprob:  0.671852, 0.266927 (1.466 sec)
34.217... logprob:  0.589004, 0.250000 (1.398 sec)
34.218... logprob:  0.666045, 0.265625 (1.414 sec)
34.219... logprob:  0.768248, 0.324219 (1.408 sec)
34.220... logprob:  0.705744, 0.313802 (1.416 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.508188, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.109914e-03 [1.055279e-07] 
Layer 'conv1' biases: 2.192925e-06 [3.157331e-11] 
Layer 'conv2' weights[0]: 2.105677e-03 [1.053273e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.442292e-10] 
Layer 'conv3' weights[0]: 2.104681e-03 [1.054891e-07] 
Layer 'conv3' biases: 3.643077e-05 [5.351432e-09] 
Layer 'conv4' weights[0]: 2.113604e-03 [1.060786e-07] 
Layer 'conv4' biases: 9.997929e-01 [2.093293e-07] 
Layer 'conv5' weights[0]: 2.286461e-03 [3.615342e-06] 
Layer 'conv5' biases: 9.989488e-01 [4.026682e-06] 
Layer 'fc6' weights[0]: 6.615377e-03 [7.080504e-08] 
Layer 'fc6' biases: 9.999899e-01 [7.109079e-08] 
Layer 'fc7' weights[0]: 6.956109e-03 [1.759691e-07] 
Layer 'fc7' biases: 9.996882e-01 [2.911634e-07] 
Layer 'fc8' weights[0]: 4.762675e-03 [1.568184e-05] 
Layer 'fc8' biases: 2.793764e-02 [4.179621e-05] 
Train error last 800 batches: 0.654824
-------------------------------------------------------
Not saving because 0.508188 > 0.299667 (9.300: -1.18%)
======================================================= (2.347 sec)
34.221... logprob:  0.600390, 0.252604 (1.415 sec)
34.222... logprob:  0.679480, 0.309896 (1.457 sec)
34.223... logprob:  0.688576, 0.282552 (1.430 sec)
34.224... logprob:  0.639700, 0.269531 (1.432 sec)
34.225... logprob:  0.704679, 0.299479 (1.440 sec)
34.226... logprob:  0.667085, 0.319010 (1.415 sec)
34.227... logprob:  0.626913, 0.273438 (1.408 sec)
34.228... logprob:  0.577841, 0.251302 (1.409 sec)
34.229... logprob:  0.683353, 0.278646 (1.409 sec)
34.230... logprob:  0.641942, 0.287760 (1.425 sec)
34.231... logprob:  0.621177, 0.273437 (1.401 sec)
34.232... logprob:  0.668756, 0.294271 (1.461 sec)
34.233... logprob:  0.641694, 0.281250 (1.424 sec)
34.234... logprob:  0.736871, 0.322917 (1.413 sec)
34.235... logprob:  0.716040, 0.319010 (1.467 sec)
34.236... logprob:  0.745940, 0.333333 (1.406 sec)
34.237... logprob:  0.512684, 0.229167 (1.421 sec)
34.238... logprob:  0.558019, 0.246094 (1.406 sec)
34.239... logprob:  0.676142, 0.311198 (1.412 sec)
34.240... logprob:  0.769772, 0.334635 (1.398 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.500217, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.107804e-03 [1.054398e-07] 
Layer 'conv1' biases: 2.192991e-06 [2.846248e-11] 
Layer 'conv2' weights[0]: 2.103571e-03 [1.052386e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.158651e-10] 
Layer 'conv3' weights[0]: 2.102571e-03 [1.053255e-07] 
Layer 'conv3' biases: 3.644102e-05 [4.070812e-09] 
Layer 'conv4' weights[0]: 2.111499e-03 [1.058458e-07] 
Layer 'conv4' biases: 9.997916e-01 [1.466141e-07] 
Layer 'conv5' weights[0]: 2.283722e-03 [2.215907e-06] 
Layer 'conv5' biases: 9.989653e-01 [2.339896e-06] 
Layer 'fc6' weights[0]: 6.614734e-03 [5.918421e-08] 
Layer 'fc6' biases: 9.999898e-01 [5.502382e-08] 
Layer 'fc7' weights[0]: 6.955400e-03 [1.419732e-07] 
Layer 'fc7' biases: 9.996873e-01 [1.840095e-07] 
Layer 'fc8' weights[0]: 4.734094e-03 [1.298273e-05] 
Layer 'fc8' biases: 2.776257e-02 [2.830771e-05] 
Train error last 800 batches: 0.654491
-------------------------------------------------------
Not saving because 0.500217 > 0.299667 (9.300: -1.18%)
======================================================= (2.357 sec)
34.241... logprob:  0.729545, 0.292969 (1.457 sec)
34.242... logprob:  0.581172, 0.273437 (1.433 sec)
34.243... logprob:  0.611052, 0.291667 (1.429 sec)
34.244... logprob:  0.594602, 0.279948 (1.442 sec)
34.245... logprob:  0.673743, 0.278646 (1.416 sec)
34.246... logprob:  0.686398, 0.308594 (1.410 sec)
34.247... logprob:  0.626120, 0.289063 (1.408 sec)
34.248... logprob:  0.563043, 0.240885 (1.410 sec)
34.249... logprob:  0.760724, 0.333333 (1.446 sec)
34.250... logprob:  0.818737, 0.329427 (1.400 sec)
34.251... logprob:  0.578857, 0.246094 (1.456 sec)
34.252... logprob:  0.644764, 0.290365 (1.422 sec)
34.253... logprob:  0.645493, 0.285156 (1.415 sec)
34.254... logprob:  0.608010, 0.282552 (1.469 sec)
34.255... logprob:  0.719726, 0.308594 (1.400 sec)
34.256... logprob:  0.689602, 0.316406 (1.418 sec)
34.257... logprob:  0.524150, 0.239583 (1.409 sec)
34.258... logprob:  0.637115, 0.264323 (1.413 sec)
34.259... logprob:  0.558072, 0.253906 (1.401 sec)
34.260... logprob:  0.533372, 0.251302 (1.453 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.407503, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.105700e-03 [1.053583e-07] 
Layer 'conv1' biases: 2.193174e-06 [4.169778e-11] 
Layer 'conv2' weights[0]: 2.101472e-03 [1.051462e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.360745e-10] 
Layer 'conv3' weights[0]: 2.100485e-03 [1.053646e-07] 
Layer 'conv3' biases: 3.644551e-05 [6.079889e-09] 
Layer 'conv4' weights[0]: 2.109390e-03 [1.060490e-07] 
Layer 'conv4' biases: 9.997905e-01 [2.215470e-07] 
Layer 'conv5' weights[0]: 2.280812e-03 [4.410569e-06] 
Layer 'conv5' biases: 9.989330e-01 [5.006489e-06] 
Layer 'fc6' weights[0]: 6.614035e-03 [7.456959e-08] 
Layer 'fc6' biases: 9.999896e-01 [7.577369e-08] 
Layer 'fc7' weights[0]: 6.954691e-03 [1.889175e-07] 
Layer 'fc7' biases: 9.996891e-01 [3.442396e-07] 
Layer 'fc8' weights[0]: 4.785062e-03 [1.735416e-05] 
Layer 'fc8' biases: 2.823193e-02 [6.252458e-05] 
Train error last 800 batches: 0.654139
-------------------------------------------------------
Not saving because 0.407503 > 0.299667 (9.300: -1.18%)
======================================================= (2.339 sec)
34.261... logprob:  0.629111, 0.276042 (1.439 sec)
34.262... logprob:  0.773966, 0.332031 (1.434 sec)
34.263... logprob:  0.644113, 0.281250 (1.445 sec)
34.264... logprob:  0.599126, 0.273437 (1.414 sec)
34.265... logprob:  0.598034, 0.252604 (1.413 sec)
34.266... logprob:  0.618715, 0.274740 (1.417 sec)
34.267... logprob:  0.628230, 0.298177 (1.408 sec)
34.268... logprob:  0.668358, 0.295573 (1.418 sec)
34.269... logprob:  0.753137, 0.317708 (1.406 sec)
34.270... logprob:  0.774525, 0.315104 (1.456 sec)
34.271... logprob:  0.630732, 0.283854 (1.425 sec)
34.272... logprob:  0.563553, 0.250000 (1.417 sec)
34.273... logprob:  0.733637, 0.334635 (1.459 sec)
34.274... logprob:  0.750404, 0.313802 (1.398 sec)
34.275... logprob:  0.762541, 0.319010 (1.414 sec)
34.276... logprob:  0.580165, 0.268229 (1.410 sec)
34.277... logprob:  0.588183, 0.251302 (1.424 sec)
34.278... logprob:  0.549379, 0.244792 (1.422 sec)
34.279... logprob:  0.529547, 0.251302 (1.454 sec)
34.280... logprob:  0.475462, 0.226562 (1.399 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.432362, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.103588e-03 [1.052392e-07] 
Layer 'conv1' biases: 2.193380e-06 [2.422333e-11] 
Layer 'conv2' weights[0]: 2.099359e-03 [1.050247e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.950064e-10] 
Layer 'conv3' weights[0]: 2.098392e-03 [1.051448e-07] 
Layer 'conv3' biases: 3.645176e-05 [5.044662e-09] 
Layer 'conv4' weights[0]: 2.107286e-03 [1.058158e-07] 
Layer 'conv4' biases: 9.997906e-01 [2.069342e-07] 
Layer 'conv5' weights[0]: 2.279467e-03 [2.573178e-06] 
Layer 'conv5' biases: 9.989224e-01 [2.807534e-06] 
Layer 'fc6' weights[0]: 6.613331e-03 [5.765005e-08] 
Layer 'fc6' biases: 9.999897e-01 [5.392636e-08] 
Layer 'fc7' weights[0]: 6.953971e-03 [1.353324e-07] 
Layer 'fc7' biases: 9.996894e-01 [1.866653e-07] 
Layer 'fc8' weights[0]: 4.792714e-03 [1.138798e-05] 
Layer 'fc8' biases: 2.831777e-02 [2.540533e-05] 
Train error last 800 batches: 0.653249
-------------------------------------------------------
Not saving because 0.432362 > 0.299667 (9.300: -1.18%)
======================================================= (2.367 sec)
34.281... logprob:  0.651360, 0.295573 (1.425 sec)
34.282... logprob:  0.652113, 0.294271 (1.412 sec)
34.283... logprob:  0.743233, 0.304687 (1.419 sec)
34.284... logprob:  0.575039, 0.265625 (1.413 sec)
34.285... logprob:  0.598510, 0.248698 (1.439 sec)
34.286... logprob:  0.809433, 0.367188 (1.429 sec)
34.287... logprob:  0.644850, 0.277344 (1.426 sec)
34.288... logprob:  0.607562, 0.302083 (1.439 sec)
34.289... logprob:  0.668368, 0.282552 (1.435 sec)
34.290... logprob:  0.787037, 0.334635 (1.408 sec)
34.291... logprob:  0.714881, 0.309896 (1.411 sec)
34.292... logprob:  0.697678, 0.294271 (1.410 sec)
34.293... logprob:  0.673995, 0.304688 (1.422 sec)
34.294... logprob:  0.667778, 0.278646 (1.400 sec)
34.295... logprob:  0.559272, 0.256510 (1.463 sec)
34.296... logprob:  0.593315, 0.269531 (1.420 sec)
34.297... logprob:  0.608451, 0.272135 (1.416 sec)
34.298... logprob:  0.683217, 0.295573 (1.457 sec)
34.299... logprob:  0.626805, 0.283854 (1.402 sec)
34.300... logprob:  0.558113, 0.240885 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.408866, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.101486e-03 [1.051455e-07] 
Layer 'conv1' biases: 2.193523e-06 [2.023935e-11] 
Layer 'conv2' weights[0]: 2.097259e-03 [1.049224e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.311546e-10] 
Layer 'conv3' weights[0]: 2.096284e-03 [1.049911e-07] 
Layer 'conv3' biases: 3.645310e-05 [3.796286e-09] 
Layer 'conv4' weights[0]: 2.105171e-03 [1.055152e-07] 
Layer 'conv4' biases: 9.997909e-01 [1.250836e-07] 
Layer 'conv5' weights[0]: 2.278329e-03 [2.260015e-06] 
Layer 'conv5' biases: 9.989222e-01 [2.435854e-06] 
Layer 'fc6' weights[0]: 6.612662e-03 [5.747096e-08] 
Layer 'fc6' biases: 9.999896e-01 [5.369255e-08] 
Layer 'fc7' weights[0]: 6.953280e-03 [1.367898e-07] 
Layer 'fc7' biases: 9.996887e-01 [1.754889e-07] 
Layer 'fc8' weights[0]: 4.778032e-03 [1.185103e-05] 
Layer 'fc8' biases: 2.826683e-02 [2.698678e-05] 
Train error last 800 batches: 0.653879
-------------------------------------------------------
Not saving because 0.408866 > 0.299667 (9.300: -1.18%)
======================================================= (2.401 sec)
34.301... logprob:  0.679281, 0.270833 (1.417 sec)
34.302... logprob:  0.857018, 0.355469 (1.419 sec)
34.303... logprob:  0.642299, 0.274739 (1.401 sec)
34.304... logprob:  0.599576, 0.266927 (1.432 sec)
34.305... logprob:  0.728627, 0.328125 (1.430 sec)
34.306... logprob:  0.609140, 0.283854 (1.428 sec)
34.307... logprob:  0.600060, 0.247396 (1.434 sec)
34.308... logprob:  0.696700, 0.296875 (1.448 sec)
34.309... logprob:  0.696978, 0.283854 (1.419 sec)
34.310... logprob:  0.655725, 0.296875 (1.415 sec)
34.311... logprob:  0.702329, 0.302083 (1.414 sec)
34.312... logprob:  0.637341, 0.303385 (1.422 sec)
34.313... logprob:  0.631451, 0.276042 (1.413 sec)
34.314... logprob:  0.639839, 0.272135 (1.460 sec)
34.315... logprob:  0.510756, 0.223958 (1.432 sec)
34.316... logprob:  0.639194, 0.260417 (1.417 sec)
34.317... logprob:  0.584268, 0.256510 (1.471 sec)
34.318... logprob:  0.592586, 0.243490 (1.407 sec)
34.319... logprob:  0.671264, 0.298177 (1.424 sec)
34.320... logprob:  0.664999, 0.282552 (1.417 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.500899, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.099383e-03 [1.050196e-07] 
Layer 'conv1' biases: 2.193580e-06 [2.019852e-11] 
Layer 'conv2' weights[0]: 2.095164e-03 [1.048133e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.500928e-10] 
Layer 'conv3' weights[0]: 2.094188e-03 [1.048941e-07] 
Layer 'conv3' biases: 3.645173e-05 [4.083672e-09] 
Layer 'conv4' weights[0]: 2.103080e-03 [1.054041e-07] 
Layer 'conv4' biases: 9.997909e-01 [1.249006e-07] 
Layer 'conv5' weights[0]: 2.276369e-03 [2.272046e-06] 
Layer 'conv5' biases: 9.989215e-01 [2.416291e-06] 
Layer 'fc6' weights[0]: 6.612013e-03 [5.737136e-08] 
Layer 'fc6' biases: 9.999896e-01 [5.336739e-08] 
Layer 'fc7' weights[0]: 6.952576e-03 [1.359888e-07] 
Layer 'fc7' biases: 9.996884e-01 [1.613993e-07] 
Layer 'fc8' weights[0]: 4.775867e-03 [1.069475e-05] 
Layer 'fc8' biases: 2.827137e-02 [1.536322e-05] 
Train error last 800 batches: 0.653787
-------------------------------------------------------
Not saving because 0.500899 > 0.299667 (9.300: -1.18%)
======================================================= (2.374 sec)
34.321... logprob:  0.572869, 0.244792 (1.428 sec)
34.322... logprob:  0.637417, 0.300781 (1.417 sec)
34.323... logprob:  0.658223, 0.282552 (1.465 sec)
34.324... logprob:  0.649954, 0.299479 (1.421 sec)
34.325... logprob:  0.597187, 0.250000 (1.428 sec)
34.326... logprob:  0.809103, 0.322917 (1.488 sec)
34.327... logprob:  0.641638, 0.294271 (1.414 sec)
34.328... logprob:  0.834246, 0.363281 (1.419 sec)
34.329... logprob:  0.596473, 0.269531 (1.417 sec)
34.330... logprob:  0.599320, 0.268229 (1.416 sec)
34.331... logprob:  0.542967, 0.266927 (1.410 sec)
34.332... logprob:  0.603072, 0.277344 (1.442 sec)
34.333... logprob:  0.646921, 0.320312 (1.437 sec)
34.334... logprob:  0.712931, 0.299479 (1.433 sec)
34.335... logprob:  0.660137, 0.299479 (1.431 sec)
34.336... logprob:  0.720562, 0.291667 (1.450 sec)
34.337... logprob:  0.741262, 0.309896 (1.411 sec)
34.338... logprob:  0.650933, 0.295573 (1.414 sec)
34.339... logprob:  0.691979, 0.263021 (1.419 sec)
34.340... logprob:  0.544427, 0.250000 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.473914, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.097288e-03 [1.048702e-07] 
Layer 'conv1' biases: 2.193613e-06 [2.527545e-11] 
Layer 'conv2' weights[0]: 2.093075e-03 [1.046789e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.737291e-10] 
Layer 'conv3' weights[0]: 2.092099e-03 [1.048017e-07] 
Layer 'conv3' biases: 3.645199e-05 [4.725067e-09] 
Layer 'conv4' weights[0]: 2.100961e-03 [1.053020e-07] 
Layer 'conv4' biases: 9.997896e-01 [1.626357e-07] 
Layer 'conv5' weights[0]: 2.273154e-03 [2.735713e-06] 
Layer 'conv5' biases: 9.989272e-01 [3.025682e-06] 
Layer 'fc6' weights[0]: 6.611331e-03 [6.404201e-08] 
Layer 'fc6' biases: 9.999891e-01 [6.273913e-08] 
Layer 'fc7' weights[0]: 6.951869e-03 [1.562486e-07] 
Layer 'fc7' biases: 9.996883e-01 [2.347310e-07] 
Layer 'fc8' weights[0]: 4.769992e-03 [1.534981e-05] 
Layer 'fc8' biases: 2.822786e-02 [4.288378e-05] 
Train error last 800 batches: 0.653636
-------------------------------------------------------
Not saving because 0.473914 > 0.299667 (9.300: -1.18%)
======================================================= (2.372 sec)
34.341... logprob:  0.726849, 0.292969 (1.423 sec)
34.342... logprob:  0.635105, 0.266927 (1.458 sec)
34.343... logprob:  0.558244, 0.250000 (1.441 sec)
34.344... logprob:  0.648148, 0.278646 (1.474 sec)
34.345... logprob:  0.705451, 0.313802 (1.432 sec)
34.346... logprob:  0.673339, 0.278646 (1.431 sec)
34.347... logprob:  0.619621, 0.279948 (1.476 sec)
34.348... logprob:  0.706907, 0.308594 (1.426 sec)
34.349... logprob:  0.730058, 0.330729 (1.434 sec)
34.350... logprob:  0.585537, 0.261719 (1.430 sec)
34.351... logprob:  0.771323, 0.321615 (1.424 sec)
34.352... logprob:  0.613169, 0.298177 (1.428 sec)
34.353... logprob:  0.696909, 0.326823 (1.490 sec)
34.354... logprob:  0.873274, 0.348958 (1.431 sec)
34.355... logprob:  0.639069, 0.283854 (1.435 sec)
34.356... logprob:  0.703710, 0.292969 (1.568 sec)
34.357... logprob:  0.587442, 0.265625 (1.433 sec)
34.358... logprob:  0.597024, 0.283854 (1.444 sec)
34.359... logprob:  0.760111, 0.352865 (1.430 sec)
34.360... logprob:  0.701758, 0.319010 (1.416 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.555318, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.095187e-03 [1.047833e-07] 
Layer 'conv1' biases: 2.193610e-06 [2.246347e-11] 
Layer 'conv2' weights[0]: 2.090973e-03 [1.045920e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.712745e-10] 
Layer 'conv3' weights[0]: 2.090019e-03 [1.046223e-07] 
Layer 'conv3' biases: 3.645739e-05 [3.379228e-09] 
Layer 'conv4' weights[0]: 2.098863e-03 [1.051169e-07] 
Layer 'conv4' biases: 9.997902e-01 [1.203213e-07] 
Layer 'conv5' weights[0]: 2.272411e-03 [2.200053e-06] 
Layer 'conv5' biases: 9.989427e-01 [2.431979e-06] 
Layer 'fc6' weights[0]: 6.610696e-03 [5.795249e-08] 
Layer 'fc6' biases: 9.999894e-01 [5.412824e-08] 
Layer 'fc7' weights[0]: 6.951151e-03 [1.400026e-07] 
Layer 'fc7' biases: 9.996868e-01 [1.779266e-07] 
Layer 'fc8' weights[0]: 4.731783e-03 [1.178154e-05] 
Layer 'fc8' biases: 2.790589e-02 [1.371372e-05] 
Train error last 800 batches: 0.653991
-------------------------------------------------------
Not saving because 0.555318 > 0.299667 (9.300: -1.18%)
======================================================= (2.401 sec)
34.361... logprob:  0.665345, 0.303385 (1.438 sec)
34.362... logprob:  0.658953, 0.282552 (1.479 sec)
34.363... logprob:  0.724973, 0.274739 (1.437 sec)
34.364... logprob:  0.741856, 0.311198 (1.469 sec)
34.365... logprob:  0.611789, 0.282552 (1.461 sec)
34.366... logprob:  0.626224, 0.277344 (1.433 sec)
34.367... logprob:  0.598707, 0.285156 (1.437 sec)
34.368... logprob:  0.749555, 0.358073 (1.432 sec)
34.369... logprob:  0.575744, 0.270833 (1.425 sec)
34.370... logprob:  0.595223, 0.235677 (1.432 sec)
34.371... logprob:  0.687150, 0.294271 (1.451 sec)
34.372... logprob:  0.761152, 0.324219 (1.446 sec)
34.373... logprob:  0.658499, 0.283854 (1.450 sec)
34.374... logprob:  0.765203, 0.332031 (1.445 sec)
34.375... logprob:  0.662870, 0.286458 (1.464 sec)
34.376... logprob:  0.626737, 0.251302 (1.441 sec)
34.377... logprob:  0.587156, 0.277344 (1.424 sec)
34.378... logprob:  0.685854, 0.309896 (1.433 sec)
34.379... logprob:  0.678626, 0.282552 (1.430 sec)
34.380... logprob:  0.861492, 0.339844 (1.434 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.428850, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.093103e-03 [1.046920e-07] 
Layer 'conv1' biases: 2.193572e-06 [2.494075e-11] 
Layer 'conv2' weights[0]: 2.088892e-03 [1.044895e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.191034e-10] 
Layer 'conv3' weights[0]: 2.087910e-03 [1.046455e-07] 
Layer 'conv3' biases: 3.645818e-05 [5.080413e-09] 
Layer 'conv4' weights[0]: 2.096768e-03 [1.051148e-07] 
Layer 'conv4' biases: 9.997905e-01 [1.844174e-07] 
Layer 'conv5' weights[0]: 2.270965e-03 [2.622844e-06] 
Layer 'conv5' biases: 9.989339e-01 [2.904352e-06] 
Layer 'fc6' weights[0]: 6.610040e-03 [6.304249e-08] 
Layer 'fc6' biases: 9.999892e-01 [6.097484e-08] 
Layer 'fc7' weights[0]: 6.950440e-03 [1.511555e-07] 
Layer 'fc7' biases: 9.996872e-01 [2.004345e-07] 
Layer 'fc8' weights[0]: 4.743430e-03 [1.307407e-05] 
Layer 'fc8' biases: 2.803954e-02 [2.637533e-05] 
Train error last 800 batches: 0.654371
-------------------------------------------------------
Not saving because 0.428850 > 0.299667 (9.300: -1.18%)
======================================================= (2.351 sec)
34.381... logprob:  0.656845, 0.276042 (1.469 sec)
34.382... logprob:  0.736264, 0.312500 (1.449 sec)
34.383... logprob:  0.570396, 0.223958 (1.436 sec)
34.384... logprob:  0.760998, 0.309896 (1.469 sec)
34.385... logprob:  0.760808, 0.329427 (1.431 sec)
34.386... logprob:  0.794822, 0.335937 (1.419 sec)
34.387... logprob:  0.661391, 0.292969 (1.428 sec)
34.388... logprob:  0.666725, 0.287760 (1.429 sec)
34.389... logprob:  0.615750, 0.278646 (1.426 sec)
34.390... logprob:  0.674042, 0.302083 (1.471 sec)
34.391... logprob:  0.592362, 0.250000 (1.438 sec)
34.392... logprob:  0.707339, 0.291667 (1.426 sec)
34.393... logprob:  0.626514, 0.268229 (1.480 sec)
34.394... logprob:  0.579599, 0.239583 (1.424 sec)
34.395... logprob:  0.524742, 0.233073 (1.427 sec)
34.396... logprob:  0.543822, 0.240885 (1.427 sec)
34.397... logprob:  0.731840, 0.334635 (1.427 sec)
34.398... logprob:  0.748526, 0.312500 (1.425 sec)
34.399... logprob:  0.660074, 0.304687 (1.480 sec)
34.400... logprob:  0.656792, 0.287760 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.390131, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.091005e-03 [1.046352e-07] 
Layer 'conv1' biases: 2.193632e-06 [2.508495e-11] 
Layer 'conv2' weights[0]: 2.086803e-03 [1.044003e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.253277e-10] 
Layer 'conv3' weights[0]: 2.085829e-03 [1.045080e-07] 
Layer 'conv3' biases: 3.645726e-05 [4.629086e-09] 
Layer 'conv4' weights[0]: 2.094665e-03 [1.051103e-07] 
Layer 'conv4' biases: 9.997905e-01 [1.848551e-07] 
Layer 'conv5' weights[0]: 2.269597e-03 [2.960972e-06] 
Layer 'conv5' biases: 9.989366e-01 [3.062449e-06] 
Layer 'fc6' weights[0]: 6.609351e-03 [6.368728e-08] 
Layer 'fc6' biases: 9.999892e-01 [6.161196e-08] 
Layer 'fc7' weights[0]: 6.949771e-03 [1.525431e-07] 
Layer 'fc7' biases: 9.996866e-01 [2.195355e-07] 
Layer 'fc8' weights[0]: 4.736840e-03 [1.373239e-05] 
Layer 'fc8' biases: 2.801528e-02 [3.498021e-05] 
Train error last 800 batches: 0.654500
-------------------------------------------------------
Not saving because 0.390131 > 0.299667 (9.300: -1.18%)
======================================================= (2.352 sec)
34.401... logprob:  0.617163, 0.273437 (1.444 sec)
34.402... logprob:  0.777209, 0.368490 (1.479 sec)
34.403... logprob:  0.673338, 0.307292 (1.429 sec)
34.404... logprob:  0.675279, 0.278646 (1.432 sec)
34.405... logprob:  0.701641, 0.299479 (1.431 sec)
34.406... logprob:  0.568395, 0.240885 (1.420 sec)
34.407... logprob:  0.713961, 0.308594 (1.425 sec)
34.408... logprob:  0.585066, 0.274740 (1.476 sec)
34.409... logprob:  0.648831, 0.285156 (1.443 sec)
34.410... logprob:  0.755639, 0.302083 (1.448 sec)
34.411... logprob:  0.606787, 0.274740 (1.466 sec)
34.412... logprob:  0.748635, 0.315104 (1.429 sec)
34.413... logprob:  0.764063, 0.316406 (1.434 sec)
34.414... logprob:  0.625814, 0.279948 (1.431 sec)
34.415... logprob:  0.662062, 0.304688 (1.421 sec)
34.416... logprob:  0.612235, 0.289062 (1.437 sec)
34.417... logprob:  0.587816, 0.256510 (1.456 sec)
34.418... logprob:  0.524838, 0.221354 (1.447 sec)
34.419... logprob:  0.657104, 0.273437 (1.453 sec)
34.420... logprob:  0.613995, 0.289062 (1.447 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.504278, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.088915e-03 [1.044803e-07] 
Layer 'conv1' biases: 2.193713e-06 [3.236164e-11] 
Layer 'conv2' weights[0]: 2.084722e-03 [1.042954e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.994715e-10] 
Layer 'conv3' weights[0]: 2.083728e-03 [1.045588e-07] 
Layer 'conv3' biases: 3.644155e-05 [6.440800e-09] 
Layer 'conv4' weights[0]: 2.092576e-03 [1.052166e-07] 
Layer 'conv4' biases: 9.997919e-01 [2.333579e-07] 
Layer 'conv5' weights[0]: 2.269107e-03 [3.242666e-06] 
Layer 'conv5' biases: 9.989176e-01 [3.566741e-06] 
Layer 'fc6' weights[0]: 6.608672e-03 [6.719728e-08] 
Layer 'fc6' biases: 9.999889e-01 [6.662252e-08] 
Layer 'fc7' weights[0]: 6.949055e-03 [1.679504e-07] 
Layer 'fc7' biases: 9.996881e-01 [2.842972e-07] 
Layer 'fc8' weights[0]: 4.783265e-03 [1.724334e-05] 
Layer 'fc8' biases: 2.843754e-02 [5.745106e-05] 
Train error last 800 batches: 0.654620
-------------------------------------------------------
Not saving because 0.504278 > 0.299667 (9.300: -1.18%)
======================================================= (2.334 sec)
34.421... logprob:  0.702041, 0.338542 (1.460 sec)
34.422... logprob:  0.735125, 0.291667 (1.437 sec)
34.423... logprob:  0.665861, 0.289062 (1.428 sec)
34.424... logprob:  0.607612, 0.290364 (1.421 sec)
34.425... logprob:  0.546222, 0.230469 (1.429 sec)
34.426... logprob:  0.603485, 0.277344 (1.438 sec)
34.427... logprob:  0.664142, 0.307292 (1.464 sec)
34.428... logprob:  0.755086, 0.360677 (1.456 sec)
34.429... logprob:  0.519435, 0.230469 (1.442 sec)
34.430... logprob:  0.571521, 0.260417 (1.466 sec)
34.431... logprob:  0.737343, 0.325521 (1.433 sec)
34.432... logprob:  0.571662, 0.260417 (1.424 sec)
34.433... logprob:  0.593281, 0.274740 (1.431 sec)
34.434... logprob:  0.712149, 0.304688 (1.436 sec)
34.435... logprob:  0.810113, 0.319010 (1.426 sec)
34.436... logprob:  0.521003, 0.222656 (1.469 sec)
34.437... logprob:  0.721082, 0.321615 (1.436 sec)
34.438... logprob:  0.810840, 0.309896 (1.428 sec)
34.439... logprob:  0.676139, 0.287760 (1.481 sec)
34.440... logprob:  0.662526, 0.286458 (1.424 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.468873, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.086832e-03 [1.043271e-07] 
Layer 'conv1' biases: 2.193953e-06 [4.402091e-11] 
Layer 'conv2' weights[0]: 2.082635e-03 [1.041443e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.774579e-10] 
Layer 'conv3' weights[0]: 2.081658e-03 [1.044596e-07] 
Layer 'conv3' biases: 3.643215e-05 [6.486887e-09] 
Layer 'conv4' weights[0]: 2.090478e-03 [1.051191e-07] 
Layer 'conv4' biases: 9.997915e-01 [2.655941e-07] 
Layer 'conv5' weights[0]: 2.267372e-03 [3.907863e-06] 
Layer 'conv5' biases: 9.989023e-01 [4.294754e-06] 
Layer 'fc6' weights[0]: 6.608007e-03 [6.974985e-08] 
Layer 'fc6' biases: 9.999890e-01 [7.117114e-08] 
Layer 'fc7' weights[0]: 6.948375e-03 [1.715886e-07] 
Layer 'fc7' biases: 9.996889e-01 [2.743710e-07] 
Layer 'fc8' weights[0]: 4.814573e-03 [1.515969e-05] 
Layer 'fc8' biases: 2.867688e-02 [4.180153e-05] 
Train error last 800 batches: 0.654673
-------------------------------------------------------
Not saving because 0.468873 > 0.299667 (9.300: -1.18%)
======================================================= (2.339 sec)
34.441... logprob:  0.713588, 0.328125 (1.431 sec)
34.442... logprob:  0.645848, 0.296875 (1.432 sec)
34.443... logprob:  0.639486, 0.283854 (1.429 sec)
34.444... logprob:  0.671114, 0.298177 (1.425 sec)
34.445... logprob:  0.591288, 0.269531 (1.476 sec)
34.446... logprob:  0.681615, 0.328125 (1.428 sec)
34.447... logprob:  0.713651, 0.304688 (1.437 sec)
34.448... logprob:  0.640976, 0.286458 (1.482 sec)
34.449... logprob:  0.624194, 0.250000 (1.427 sec)
34.450... logprob:  0.441913, 0.212240 (1.426 sec)
34.451... logprob:  0.719901, 0.322917 (1.429 sec)
34.452... logprob:  0.676450, 0.307291 (1.420 sec)
34.453... logprob:  0.608177, 0.285156 (1.429 sec)
34.454... logprob:  0.709641, 0.285156 (1.474 sec)
34.455... logprob:  0.780013, 0.346354 (1.429 sec)
34.456... logprob:  0.686785, 0.274740 (1.445 sec)
34.457... logprob:  0.632950, 0.300781 (1.473 sec)
34.458... logprob:  0.607388, 0.274740 (1.431 sec)
34.459... logprob:  0.728826, 0.315104 (1.437 sec)
34.460... logprob:  0.500751, 0.247396 (1.424 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.425632, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.084734e-03 [1.042747e-07] 
Layer 'conv1' biases: 2.194147e-06 [2.572462e-11] 
Layer 'conv2' weights[0]: 2.080544e-03 [1.040754e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.730876e-10] 
Layer 'conv3' weights[0]: 2.079578e-03 [1.041481e-07] 
Layer 'conv3' biases: 3.643965e-05 [3.975763e-09] 
Layer 'conv4' weights[0]: 2.088400e-03 [1.046494e-07] 
Layer 'conv4' biases: 9.997906e-01 [1.409258e-07] 
Layer 'conv5' weights[0]: 2.264334e-03 [2.287002e-06] 
Layer 'conv5' biases: 9.989150e-01 [2.511737e-06] 
Layer 'fc6' weights[0]: 6.607380e-03 [5.716452e-08] 
Layer 'fc6' biases: 9.999889e-01 [5.357065e-08] 
Layer 'fc7' weights[0]: 6.947695e-03 [1.326125e-07] 
Layer 'fc7' biases: 9.996875e-01 [1.665227e-07] 
Layer 'fc8' weights[0]: 4.773279e-03 [1.101744e-05] 
Layer 'fc8' biases: 2.841818e-02 [1.443717e-05] 
Train error last 800 batches: 0.654842
-------------------------------------------------------
Not saving because 0.425632 > 0.299667 (9.300: -1.18%)
======================================================= (2.363 sec)
34.461... logprob:  0.663623, 0.292969 (1.426 sec)
34.462... logprob:  0.722862, 0.294271 (1.437 sec)
34.463... logprob:  0.620441, 0.266927 (1.463 sec)
34.464... logprob:  0.705855, 0.320312 (1.439 sec)
34.465... logprob:  0.527592, 0.244792 (1.448 sec)
34.466... logprob:  0.579916, 0.253906 (1.452 sec)
34.467... logprob:  0.534493, 0.248698 (1.445 sec)
34.468... logprob:  0.636735, 0.277344 (1.430 sec)
34.469... logprob:  0.579808, 0.264323 (1.421 sec)
34.470... logprob:  0.532196, 0.229167 (1.422 sec)
34.471... logprob:  0.822886, 0.354167 (1.430 sec)
34.472... logprob:  0.681323, 0.321615 (1.446 sec)
34.473... logprob:  0.550998, 0.252604 (1.452 sec)
34.474... logprob:  0.668946, 0.303385 (1.449 sec)
34.475... logprob:  0.769092, 0.334635 (1.437 sec)
34.476... logprob:  0.671090, 0.283854 (1.467 sec)
34.477... logprob:  0.555998, 0.260417 (1.429 sec)
34.478... logprob:  0.689633, 0.320312 (1.421 sec)
34.479... logprob:  0.588697, 0.273437 (1.434 sec)
34.480... logprob:  0.686125, 0.296875 (1.451 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.431555, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.082662e-03 [1.041726e-07] 
Layer 'conv1' biases: 2.194374e-06 [1.391833e-11] 
Layer 'conv2' weights[0]: 2.078481e-03 [1.039766e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.998384e-10] 
Layer 'conv3' weights[0]: 2.077484e-03 [1.040107e-07] 
Layer 'conv3' biases: 3.643668e-05 [3.450538e-09] 
Layer 'conv4' weights[0]: 2.086310e-03 [1.045225e-07] 
Layer 'conv4' biases: 9.997900e-01 [1.218388e-07] 
Layer 'conv5' weights[0]: 2.262337e-03 [2.058887e-06] 
Layer 'conv5' biases: 9.988874e-01 [2.260044e-06] 
Layer 'fc6' weights[0]: 6.606692e-03 [5.621702e-08] 
Layer 'fc6' biases: 9.999888e-01 [5.255189e-08] 
Layer 'fc7' weights[0]: 6.946951e-03 [1.348252e-07] 
Layer 'fc7' biases: 9.996893e-01 [1.712556e-07] 
Layer 'fc8' weights[0]: 4.823233e-03 [1.092658e-05] 
Layer 'fc8' biases: 2.882379e-02 [1.660683e-05] 
Train error last 800 batches: 0.654871
-------------------------------------------------------
Not saving because 0.431555 > 0.299667 (9.300: -1.18%)
======================================================= (2.409 sec)
34.481... logprob:  0.702412, 0.322917 (1.443 sec)
34.482... logprob:  0.598104, 0.255208 (1.481 sec)
34.483... logprob:  0.608482, 0.252604 (1.441 sec)
34.484... logprob:  0.735290, 0.295573 (1.430 sec)
34.485... logprob:  0.610960, 0.264323 (1.476 sec)
34.486... logprob:  0.519218, 0.225260 (1.430 sec)
34.487... logprob:  0.806340, 0.355469 (1.425 sec)
34.488... logprob:  0.623724, 0.289062 (1.433 sec)
34.489... logprob:  0.639350, 0.277344 (1.423 sec)
34.490... logprob:  0.672834, 0.290365 (1.426 sec)
34.491... logprob:  0.597199, 0.276042 (1.476 sec)
34.492... logprob:  0.694363, 0.294271 (1.435 sec)
34.493... logprob:  0.736576, 0.313802 (1.427 sec)
34.494... logprob:  0.612350, 0.255208 (1.486 sec)
34.495... logprob:  0.537178, 0.227865 (1.430 sec)
34.496... logprob:  0.823062, 0.312500 (1.431 sec)
34.497... logprob:  0.758199, 0.325521 (1.432 sec)
34.498... logprob:  0.638775, 0.295573 (1.429 sec)
34.499... logprob:  0.717296, 0.307292 (1.428 sec)
34.500... logprob:  0.645712, 0.273437 (1.486 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.383493, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.080576e-03 [1.040110e-07] 
Layer 'conv1' biases: 2.194512e-06 [4.031860e-11] 
Layer 'conv2' weights[0]: 2.076383e-03 [1.038420e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.558119e-10] 
Layer 'conv3' weights[0]: 2.075409e-03 [1.041440e-07] 
Layer 'conv3' biases: 3.645778e-05 [7.104971e-09] 
Layer 'conv4' weights[0]: 2.084209e-03 [1.046762e-07] 
Layer 'conv4' biases: 9.997890e-01 [2.680801e-07] 
Layer 'conv5' weights[0]: 2.259254e-03 [4.215466e-06] 
Layer 'conv5' biases: 9.989160e-01 [4.707282e-06] 
Layer 'fc6' weights[0]: 6.605994e-03 [7.601707e-08] 
Layer 'fc6' biases: 9.999890e-01 [7.923040e-08] 
Layer 'fc7' weights[0]: 6.946282e-03 [1.879910e-07] 
Layer 'fc7' biases: 9.996873e-01 [3.304964e-07] 
Layer 'fc8' weights[0]: 4.767157e-03 [1.761473e-05] 
Layer 'fc8' biases: 2.837605e-02 [5.311360e-05] 
Train error last 800 batches: 0.655236
-------------------------------------------------------
Not saving because 0.383493 > 0.299667 (9.300: -1.18%)
======================================================= (2.350 sec)
34.501... logprob:  0.603498, 0.272135 (1.439 sec)
34.502... logprob:  0.712476, 0.291667 (1.443 sec)
34.503... logprob:  0.649977, 0.308594 (1.473 sec)
34.504... logprob:  0.740189, 0.341146 (1.426 sec)
34.505... logprob:  0.828750, 0.351563 (1.430 sec)
34.506... logprob:  0.696448, 0.312500 (1.429 sec)
34.507... logprob:  0.604825, 0.269531 (1.427 sec)
34.508... logprob:  0.621304, 0.290365 (1.428 sec)
34.509... logprob:  0.594506, 0.266927 (1.467 sec)
34.510... logprob:  0.639842, 0.290365 (1.438 sec)
34.511... logprob:  0.564368, 0.239583 (1.445 sec)
34.512... logprob:  0.663728, 0.289062 (1.457 sec)
34.513... logprob:  0.643980, 0.287760 (1.437 sec)
34.514... logprob:  0.606594, 0.272135 (1.434 sec)
34.515... logprob:  0.630340, 0.274740 (1.432 sec)
34.516... logprob:  0.565733, 0.244792 (1.424 sec)
34.517... logprob:  0.848711, 0.359375 (1.435 sec)
34.518... logprob:  0.639426, 0.299479 (1.456 sec)
34.519... logprob:  0.714074, 0.298177 (1.448 sec)
34.520... logprob:  0.576709, 0.273438 (1.445 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.560450, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.078491e-03 [1.039689e-07] 
Layer 'conv1' biases: 2.194668e-06 [2.887212e-11] 
Layer 'conv2' weights[0]: 2.074306e-03 [1.037737e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.774895e-10] 
Layer 'conv3' weights[0]: 2.073346e-03 [1.038635e-07] 
Layer 'conv3' biases: 3.648178e-05 [4.240800e-09] 
Layer 'conv4' weights[0]: 2.082129e-03 [1.044427e-07] 
Layer 'conv4' biases: 9.997873e-01 [1.545138e-07] 
Layer 'conv5' weights[0]: 2.256426e-03 [2.602003e-06] 
Layer 'conv5' biases: 9.989368e-01 [2.822975e-06] 
Layer 'fc6' weights[0]: 6.605314e-03 [6.204344e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.962085e-08] 
Layer 'fc7' weights[0]: 6.945594e-03 [1.507039e-07] 
Layer 'fc7' biases: 9.996856e-01 [2.212375e-07] 
Layer 'fc8' weights[0]: 4.742571e-03 [1.343477e-05] 
Layer 'fc8' biases: 2.814428e-02 [3.397736e-05] 
Train error last 800 batches: 0.655060
-------------------------------------------------------
Not saving because 0.560450 > 0.299667 (9.300: -1.18%)
======================================================= (2.381 sec)
34.521... logprob:  0.700632, 0.290365 (1.459 sec)
34.522... logprob:  0.653707, 0.292969 (1.475 sec)
34.523... logprob:  0.615733, 0.268229 (1.436 sec)
34.524... logprob:  0.690001, 0.304687 (1.421 sec)
34.525... logprob:  0.680483, 0.322917 (1.430 sec)
34.526... logprob:  0.569223, 0.230469 (1.435 sec)
34.527... logprob:  0.707675, 0.309896 (1.437 sec)
34.528... logprob:  0.689721, 0.295573 (1.466 sec)
34.529... logprob:  0.575065, 0.251302 (1.442 sec)
34.530... logprob:  0.631401, 0.282552 (1.431 sec)
34.531... logprob:  0.696424, 0.313802 (1.478 sec)
34.532... logprob:  0.660124, 0.302083 (1.425 sec)
34.533... logprob:  0.768209, 0.341146 (1.421 sec)
34.534... logprob:  0.565032, 0.246094 (1.429 sec)
34.535... logprob:  0.712459, 0.286458 (1.427 sec)
34.536... logprob:  0.773029, 0.309896 (1.426 sec)
34.537... logprob:  0.652690, 0.268229 (1.486 sec)
34.538... logprob:  0.795574, 0.303385 (1.443 sec)
34.539... logprob:  0.552026, 0.244792 (1.432 sec)
34.540... logprob:  0.627749, 0.304687 (1.477 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.460718, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.076419e-03 [1.038062e-07] 
Layer 'conv1' biases: 2.194821e-06 [3.003336e-11] 
Layer 'conv2' weights[0]: 2.072240e-03 [1.036295e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.983937e-10] 
Layer 'conv3' weights[0]: 2.071269e-03 [1.037710e-07] 
Layer 'conv3' biases: 3.648914e-05 [4.889057e-09] 
Layer 'conv4' weights[0]: 2.080051e-03 [1.042282e-07] 
Layer 'conv4' biases: 9.997858e-01 [1.796100e-07] 
Layer 'conv5' weights[0]: 2.253264e-03 [2.918782e-06] 
Layer 'conv5' biases: 9.989328e-01 [3.174343e-06] 
Layer 'fc6' weights[0]: 6.604638e-03 [6.492647e-08] 
Layer 'fc6' biases: 9.999893e-01 [6.382066e-08] 
Layer 'fc7' weights[0]: 6.944934e-03 [1.584355e-07] 
Layer 'fc7' biases: 9.996862e-01 [2.348325e-07] 
Layer 'fc8' weights[0]: 4.753528e-03 [1.367513e-05] 
Layer 'fc8' biases: 2.824665e-02 [3.170731e-05] 
Train error last 800 batches: 0.655282
-------------------------------------------------------
Not saving because 0.460718 > 0.299667 (9.300: -1.18%)
======================================================= (2.383 sec)
34.541... logprob:  0.622121, 0.257812 (1.438 sec)
34.542... logprob:  0.690475, 0.330729 (1.432 sec)
34.543... logprob:  0.527117, 0.236979 (1.431 sec)
34.544... logprob:  0.545813, 0.261719 (1.421 sec)
34.545... logprob:  0.529067, 0.248698 (1.430 sec)
34.546... logprob:  0.661522, 0.291667 (1.487 sec)
34.547... logprob:  0.636061, 0.260417 (1.435 sec)
34.548... logprob:  0.684159, 0.300781 (1.435 sec)
34.549... logprob:  0.723260, 0.325521 (1.473 sec)
34.550... logprob:  0.664450, 0.313802 (1.431 sec)
34.551... logprob:  0.630296, 0.281250 (1.431 sec)
34.552... logprob:  0.735854, 0.305990 (1.428 sec)
34.553... logprob:  0.553286, 0.244792 (1.422 sec)
34.554... logprob:  0.705514, 0.321615 (1.425 sec)
34.555... logprob:  0.610377, 0.269531 (1.478 sec)
34.556... logprob:  0.558319, 0.251302 (1.438 sec)
34.557... logprob:  0.639932, 0.240885 (1.443 sec)
34.558... logprob:  0.505277, 0.227865 (1.466 sec)
34.559... logprob:  0.677876, 0.278646 (1.431 sec)
34.560... logprob:  0.538673, 0.230469 (1.436 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.389400, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.074336e-03 [1.037885e-07] 
Layer 'conv1' biases: 2.194826e-06 [2.699036e-11] 
Layer 'conv2' weights[0]: 2.070172e-03 [1.035707e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.603306e-10] 
Layer 'conv3' weights[0]: 2.069181e-03 [1.037082e-07] 
Layer 'conv3' biases: 3.648555e-05 [4.650664e-09] 
Layer 'conv4' weights[0]: 2.077969e-03 [1.043250e-07] 
Layer 'conv4' biases: 9.997867e-01 [1.853418e-07] 
Layer 'conv5' weights[0]: 2.252468e-03 [3.405474e-06] 
Layer 'conv5' biases: 9.989005e-01 [3.832442e-06] 
Layer 'fc6' weights[0]: 6.603965e-03 [6.385213e-08] 
Layer 'fc6' biases: 9.999890e-01 [6.251847e-08] 
Layer 'fc7' weights[0]: 6.944248e-03 [1.540507e-07] 
Layer 'fc7' biases: 9.996879e-01 [2.368013e-07] 
Layer 'fc8' weights[0]: 4.814202e-03 [1.371100e-05] 
Layer 'fc8' biases: 2.874039e-02 [4.113318e-05] 
Train error last 800 batches: 0.655450
-------------------------------------------------------
Not saving because 0.389400 > 0.299667 (9.300: -1.18%)
======================================================= (2.360 sec)
34.561... logprob:  0.719945, 0.311198 (1.433 sec)
34.562... logprob:  0.844505, 0.350260 (1.427 sec)
34.563... logprob:  0.630377, 0.269531 (1.439 sec)
34.564... logprob:  0.676689, 0.319010 (1.460 sec)
34.565... logprob:  0.834396, 0.350260 (1.443 sec)
34.566... logprob:  0.643306, 0.291667 (1.453 sec)
34.567... logprob:  0.705888, 0.307292 (1.461 sec)
34.568... logprob:  0.660099, 0.247396 (1.455 sec)
34.569... logprob:  0.730643, 0.338542 (1.439 sec)
34.570... logprob:  0.773105, 0.355469 (1.420 sec)
34.571... logprob:  0.640397, 0.294271 (1.426 sec)
34.572... logprob:  0.691178, 0.276042 (1.433 sec)
34.573... logprob:  0.684150, 0.274739 (1.441 sec)
34.574... logprob:  0.683901, 0.295573 (1.454 sec)
34.575... logprob:  0.558494, 0.250000 (1.449 sec)
34.576... logprob:  0.549847, 0.257812 (1.437 sec)
34.577... logprob:  0.570551, 0.265625 (1.470 sec)
34.578... logprob:  0.641418, 0.276042 (1.436 sec)
34.579... logprob:  0.551336, 0.259115 (1.420 sec)
34.580... logprob:  0.825664, 0.371094 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.449182, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.072270e-03 [1.036308e-07] 
Layer 'conv1' biases: 2.195010e-06 [2.636743e-11] 
Layer 'conv2' weights[0]: 2.068093e-03 [1.034473e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.618453e-10] 
Layer 'conv3' weights[0]: 2.067115e-03 [1.035128e-07] 
Layer 'conv3' biases: 3.649854e-05 [3.760244e-09] 
Layer 'conv4' weights[0]: 2.075889e-03 [1.040482e-07] 
Layer 'conv4' biases: 9.997865e-01 [1.456150e-07] 
Layer 'conv5' weights[0]: 2.250533e-03 [2.130223e-06] 
Layer 'conv5' biases: 9.989233e-01 [2.299769e-06] 
Layer 'fc6' weights[0]: 6.603295e-03 [5.783044e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.411017e-08] 
Layer 'fc7' weights[0]: 6.943556e-03 [1.382978e-07] 
Layer 'fc7' biases: 9.996868e-01 [1.779348e-07] 
Layer 'fc8' weights[0]: 4.766033e-03 [1.190764e-05] 
Layer 'fc8' biases: 2.838032e-02 [2.218512e-05] 
Train error last 800 batches: 0.655640
-------------------------------------------------------
Not saving because 0.449182 > 0.299667 (9.300: -1.18%)
======================================================= (2.365 sec)
34.581... logprob:  0.705718, 0.320312 (1.444 sec)
34.582... logprob:  0.672371, 0.316406 (1.434 sec)
34.583... logprob:  0.703920, 0.272135 (1.467 sec)
34.584... logprob:  0.628492, 0.283854 (1.442 sec)
34.585... logprob:  0.565237, 0.247396 (1.425 sec)
34.586... logprob:  0.526064, 0.225260 (1.478 sec)
34.587... logprob:  0.547584, 0.235677 (1.429 sec)
34.588... logprob:  0.593387, 0.265625 (1.423 sec)
34.589... logprob:  0.589033, 0.257812 (1.431 sec)
34.590... logprob:  0.826625, 0.330729 (1.422 sec)
34.591... logprob:  0.626643, 0.259115 (1.431 sec)
34.592... logprob:  0.659454, 0.304687 (1.483 sec)
34.593... logprob:  0.662317, 0.265625 (1.432 sec)
34.594... logprob:  0.560917, 0.246094 (1.440 sec)
34.595... logprob:  0.745204, 0.330729 (1.483 sec)
34.596... logprob:  0.662264, 0.299479 (1.430 sec)
34.597... logprob:  0.655238, 0.283854 (1.426 sec)
34.598... logprob:  0.669048, 0.302083 (1.432 sec)
34.599... logprob:  0.591485, 0.276042 (1.421 sec)
34.600... logprob:  0.626571, 0.270833 (1.425 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.476074, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.070194e-03 [1.035466e-07] 
Layer 'conv1' biases: 2.195185e-06 [2.296901e-11] 
Layer 'conv2' weights[0]: 2.066023e-03 [1.033562e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.438694e-10] 
Layer 'conv3' weights[0]: 2.065062e-03 [1.034700e-07] 
Layer 'conv3' biases: 3.648178e-05 [4.578738e-09] 
Layer 'conv4' weights[0]: 2.073808e-03 [1.040505e-07] 
Layer 'conv4' biases: 9.997871e-01 [1.590893e-07] 
Layer 'conv5' weights[0]: 2.249317e-03 [2.561581e-06] 
Layer 'conv5' biases: 9.989012e-01 [2.710833e-06] 
Layer 'fc6' weights[0]: 6.602575e-03 [5.868149e-08] 
Layer 'fc6' biases: 9.999891e-01 [5.523047e-08] 
Layer 'fc7' weights[0]: 6.942855e-03 [1.380141e-07] 
Layer 'fc7' biases: 9.996880e-01 [1.717841e-07] 
Layer 'fc8' weights[0]: 4.809734e-03 [1.124501e-05] 
Layer 'fc8' biases: 2.869146e-02 [1.933641e-05] 
Train error last 800 batches: 0.655834
-------------------------------------------------------
Not saving because 0.476074 > 0.299667 (9.300: -1.18%)
======================================================= (2.358 sec)
34.601... logprob:  0.595117, 0.252604 (1.481 sec)
34.602... logprob:  0.611434, 0.256510 (1.429 sec)
34.603... logprob:  0.498952, 0.227865 (1.437 sec)
34.604... logprob:  0.575603, 0.253906 (1.469 sec)
34.605... logprob:  0.728554, 0.286458 (1.437 sec)
34.606... logprob:  0.530474, 0.259115 (1.433 sec)
34.607... logprob:  0.706055, 0.309896 (1.424 sec)
34.608... logprob:  0.598894, 0.260417 (1.418 sec)
34.609... logprob:  0.650438, 0.296875 (1.434 sec)
34.610... logprob:  0.791255, 0.341146 (1.469 sec)
34.611... logprob:  0.732439, 0.335937 (1.441 sec)
34.612... logprob:  0.622136, 0.272135 (1.448 sec)
34.613... logprob:  0.495306, 0.223958 (1.456 sec)
34.614... logprob:  0.777660, 0.321615 (1.447 sec)
34.615... logprob:  0.627531, 0.263021 (1.431 sec)
34.616... logprob:  0.764086, 0.320313 (1.422 sec)
34.617... logprob:  0.686189, 0.276042 (1.421 sec)
34.618... logprob:  0.762546, 0.333333 (1.435 sec)
34.619... logprob:  0.656861, 0.273437 (1.448 sec)
34.620... logprob:  0.668522, 0.289062 (1.452 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.503097, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.068127e-03 [1.034026e-07] 
Layer 'conv1' biases: 2.195214e-06 [4.172490e-11] 
Layer 'conv2' weights[0]: 2.063961e-03 [1.032182e-07] 
Layer 'conv2' biases: 9.999996e-01 [6.289052e-10] 
Layer 'conv3' weights[0]: 2.062991e-03 [1.036200e-07] 
Layer 'conv3' biases: 3.648858e-05 [7.850229e-09] 
Layer 'conv4' weights[0]: 2.071748e-03 [1.042367e-07] 
Layer 'conv4' biases: 9.997857e-01 [3.018937e-07] 
Layer 'conv5' weights[0]: 2.246403e-03 [4.562002e-06] 
Layer 'conv5' biases: 9.989079e-01 [5.169627e-06] 
Layer 'fc6' weights[0]: 6.601918e-03 [7.966741e-08] 
Layer 'fc6' biases: 9.999891e-01 [8.491213e-08] 
Layer 'fc7' weights[0]: 6.942161e-03 [2.061587e-07] 
Layer 'fc7' biases: 9.996871e-01 [3.754517e-07] 
Layer 'fc8' weights[0]: 4.804598e-03 [1.879825e-05] 
Layer 'fc8' biases: 2.873655e-02 [6.017390e-05] 
Train error last 800 batches: 0.655987
-------------------------------------------------------
Not saving because 0.503097 > 0.299667 (9.300: -1.18%)
======================================================= (2.312 sec)
34.621... logprob:  0.571794, 0.282552 (1.459 sec)
34.622... logprob:  0.591836, 0.273437 (1.454 sec)
34.623... logprob:  0.612196, 0.276042 (1.478 sec)
34.624... logprob:  0.635690, 0.294271 (1.437 sec)
34.625... logprob:  0.705732, 0.347656 (1.434 sec)
34.626... logprob:  0.647286, 0.256510 (1.434 sec)
34.627... logprob:  0.706178, 0.298177 (1.441 sec)
34.628... logprob:  0.678814, 0.290365 (1.436 sec)
34.629... logprob:  0.647420, 0.285156 (1.490 sec)
34.630... logprob:  0.649301, 0.285156 (1.460 sec)
34.631... logprob:  0.715940, 0.304688 (1.439 sec)
34.632... logprob:  0.644614, 0.294271 (1.486 sec)
34.633... logprob:  0.600832, 0.268229 (1.439 sec)
34.634... logprob:  0.753481, 0.335937 (1.435 sec)
34.635... logprob:  0.569162, 0.257812 (1.435 sec)
34.636... logprob:  0.761187, 0.330729 (1.432 sec)
34.637... logprob:  0.601331, 0.264323 (1.434 sec)
34.638... logprob:  0.766290, 0.321615 (1.483 sec)
34.639... logprob:  0.705168, 0.322917 (1.439 sec)
34.640... logprob:  0.701009, 0.316406 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.522886, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.066058e-03 [1.033177e-07] 
Layer 'conv1' biases: 2.195325e-06 [2.541845e-11] 
Layer 'conv2' weights[0]: 2.061894e-03 [1.031239e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.174435e-10] 
Layer 'conv3' weights[0]: 2.060926e-03 [1.031968e-07] 
Layer 'conv3' biases: 3.650074e-05 [3.974892e-09] 
Layer 'conv4' weights[0]: 2.069682e-03 [1.037013e-07] 
Layer 'conv4' biases: 9.997857e-01 [1.500093e-07] 
Layer 'conv5' weights[0]: 2.244461e-03 [2.409313e-06] 
Layer 'conv5' biases: 9.989243e-01 [2.657556e-06] 
Layer 'fc6' weights[0]: 6.601233e-03 [6.065677e-08] 
Layer 'fc6' biases: 9.999890e-01 [5.832271e-08] 
Layer 'fc7' weights[0]: 6.941500e-03 [1.475059e-07] 
Layer 'fc7' biases: 9.996862e-01 [2.035394e-07] 
Layer 'fc8' weights[0]: 4.782294e-03 [1.332459e-05] 
Layer 'fc8' biases: 2.855250e-02 [3.312271e-05] 
Train error last 800 batches: 0.655795
-------------------------------------------------------
Not saving because 0.522886 > 0.299667 (9.300: -1.18%)
======================================================= (2.390 sec)
34.641... logprob:  0.634205, 0.287760 (1.498 sec)
34.642... logprob:  0.675139, 0.305990 (1.443 sec)
34.643... logprob:  0.736127, 0.329427 (1.438 sec)
34.644... logprob:  0.618747, 0.302083 (1.446 sec)
34.645... logprob:  0.658486, 0.281250 (1.437 sec)
34.646... logprob:  0.640663, 0.292969 (1.442 sec)
34.647... logprob:  0.650296, 0.308594 (1.498 sec)
34.648... logprob:  0.700622, 0.295573 (1.442 sec)
34.649... logprob:  0.613848, 0.268229 (1.452 sec)
34.650... logprob:  0.688448, 0.309896 (1.478 sec)
34.651... logprob:  0.604289, 0.260417 (1.444 sec)
34.652... logprob:  0.759903, 0.321615 (1.448 sec)
34.653... logprob:  0.787210, 0.325521 (1.434 sec)
34.654... logprob:  0.659801, 0.303385 (1.437 sec)
34.655... logprob:  0.619884, 0.270833 (1.431 sec)
34.656... logprob:  0.683311, 0.326823 (1.471 sec)
34.657... logprob:  0.620649, 0.257813 (1.435 sec)
34.658... logprob:  0.597919, 0.287760 (1.446 sec)
34.659... logprob:  0.605076, 0.276042 (1.469 sec)
34.660... logprob:  0.679026, 0.309896 (1.436 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.517622, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.063991e-03 [1.032481e-07] 
Layer 'conv1' biases: 2.195542e-06 [1.226201e-11] 
Layer 'conv2' weights[0]: 2.059838e-03 [1.030535e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.693814e-10] 
Layer 'conv3' weights[0]: 2.058880e-03 [1.030677e-07] 
Layer 'conv3' biases: 3.650716e-05 [3.209520e-09] 
Layer 'conv4' weights[0]: 2.067595e-03 [1.035744e-07] 
Layer 'conv4' biases: 9.997846e-01 [1.138200e-07] 
Layer 'conv5' weights[0]: 2.241973e-03 [2.411311e-06] 
Layer 'conv5' biases: 9.989247e-01 [2.620397e-06] 
Layer 'fc6' weights[0]: 6.600519e-03 [5.859661e-08] 
Layer 'fc6' biases: 9.999890e-01 [5.515363e-08] 
Layer 'fc7' weights[0]: 6.940797e-03 [1.402264e-07] 
Layer 'fc7' biases: 9.996865e-01 [1.880472e-07] 
Layer 'fc8' weights[0]: 4.793566e-03 [1.190295e-05] 
Layer 'fc8' biases: 2.854646e-02 [2.685006e-05] 
Train error last 800 batches: 0.655662
-------------------------------------------------------
Not saving because 0.517622 > 0.299667 (9.300: -1.18%)
======================================================= (2.398 sec)
34.661... logprob:  0.612799, 0.266927 (1.446 sec)
34.662... logprob:  0.745952, 0.334635 (1.428 sec)
34.663... logprob:  0.574159, 0.257812 (1.427 sec)
34.664... logprob:  0.560941, 0.273437 (1.438 sec)
34.665... logprob:  0.638140, 0.252604 (1.518 sec)
34.666... logprob:  0.620446, 0.269531 (1.453 sec)
34.667... logprob:  0.728184, 0.312500 (1.451 sec)
34.668... logprob:  0.714224, 0.308594 (1.446 sec)
34.669... logprob:  0.635291, 0.272135 (1.456 sec)
34.670... logprob:  0.577971, 0.264323 (1.439 sec)
34.671... logprob:  0.637634, 0.278646 (1.417 sec)
34.672... logprob:  0.601366, 0.273437 (1.428 sec)
34.673... logprob:  0.649924, 0.282552 (1.432 sec)
34.674... logprob:  0.597346, 0.251302 (1.437 sec)
34.675... logprob:  0.576922, 0.261719 (1.464 sec)
34.676... logprob:  0.630476, 0.255208 (1.438 sec)
34.677... logprob:  0.670421, 0.270833 (1.438 sec)
34.678... logprob:  0.643622, 0.296875 (1.478 sec)
34.679... logprob:  0.654278, 0.270833 (1.438 sec)
34.680... logprob:  0.588293, 0.283854 (1.424 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.438698, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.061932e-03 [1.031500e-07] 
Layer 'conv1' biases: 2.195557e-06 [2.960295e-11] 
Layer 'conv2' weights[0]: 2.057780e-03 [1.029503e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.958718e-10] 
Layer 'conv3' weights[0]: 2.056823e-03 [1.031005e-07] 
Layer 'conv3' biases: 3.650508e-05 [5.483955e-09] 
Layer 'conv4' weights[0]: 2.065542e-03 [1.036747e-07] 
Layer 'conv4' biases: 9.997869e-01 [2.318808e-07] 
Layer 'conv5' weights[0]: 2.242358e-03 [2.344571e-06] 
Layer 'conv5' biases: 9.989028e-01 [2.589027e-06] 
Layer 'fc6' weights[0]: 6.599826e-03 [5.786199e-08] 
Layer 'fc6' biases: 9.999889e-01 [5.446315e-08] 
Layer 'fc7' weights[0]: 6.940122e-03 [1.359827e-07] 
Layer 'fc7' biases: 9.996873e-01 [1.667675e-07] 
Layer 'fc8' weights[0]: 4.836203e-03 [1.127067e-05] 
Layer 'fc8' biases: 2.888082e-02 [2.150161e-05] 
Train error last 800 batches: 0.655310
-------------------------------------------------------
Not saving because 0.438698 > 0.299667 (9.300: -1.18%)
======================================================= (2.376 sec)
34.681... logprob:  0.643376, 0.300781 (1.435 sec)
34.682... logprob:  0.588214, 0.278646 (1.433 sec)
34.683... logprob:  0.694184, 0.309896 (1.428 sec)
34.684... logprob:  0.562200, 0.251302 (1.473 sec)
34.685... logprob:  0.552342, 0.278646 (1.436 sec)
34.686... logprob:  0.545795, 0.230469 (1.427 sec)
34.687... logprob:  0.597359, 0.285156 (1.479 sec)
34.688... logprob:  0.595386, 0.274739 (1.428 sec)
34.689... logprob:  0.730603, 0.299479 (1.427 sec)
34.690... logprob:  0.686626, 0.313802 (1.435 sec)
34.691... logprob:  0.760898, 0.312500 (1.426 sec)
34.692... logprob:  0.609409, 0.278646 (1.427 sec)
34.693... logprob:  0.660582, 0.302083 (1.476 sec)
34.694... logprob:  0.567146, 0.274740 (1.430 sec)
34.695... logprob:  0.528753, 0.233073 (1.435 sec)
34.696... logprob:  0.750514, 0.291667 (1.472 sec)
34.697... logprob:  0.670635, 0.303385 (1.428 sec)
34.698... logprob:  0.733453, 0.319010 (1.428 sec)
34.699... logprob:  0.623829, 0.303385 (1.428 sec)
34.700... logprob:  0.623772, 0.276042 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.419235, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.059868e-03 [1.030137e-07] 
Layer 'conv1' biases: 2.195631e-06 [2.676188e-11] 
Layer 'conv2' weights[0]: 2.055723e-03 [1.028183e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.978566e-10] 
Layer 'conv3' weights[0]: 2.054766e-03 [1.029636e-07] 
Layer 'conv3' biases: 3.649843e-05 [4.944993e-09] 
Layer 'conv4' weights[0]: 2.063471e-03 [1.034209e-07] 
Layer 'conv4' biases: 9.997892e-01 [1.850151e-07] 
Layer 'conv5' weights[0]: 2.242936e-03 [2.927651e-06] 
Layer 'conv5' biases: 9.988925e-01 [3.180334e-06] 
Layer 'fc6' weights[0]: 6.599150e-03 [6.156790e-08] 
Layer 'fc6' biases: 9.999889e-01 [6.012051e-08] 
Layer 'fc7' weights[0]: 6.939419e-03 [1.485529e-07] 
Layer 'fc7' biases: 9.996874e-01 [2.138373e-07] 
Layer 'fc8' weights[0]: 4.848156e-03 [1.243819e-05] 
Layer 'fc8' biases: 2.896865e-02 [2.819376e-05] 
Train error last 800 batches: 0.655425
-------------------------------------------------------
Not saving because 0.419235 > 0.299667 (9.300: -1.18%)
======================================================= (2.369 sec)
34.701... logprob:  0.633378, 0.302083 (1.438 sec)
34.702... logprob:  0.742982, 0.343750 (1.482 sec)
34.703... logprob:  0.636378, 0.269531 (1.435 sec)
34.704... logprob:  0.707569, 0.313802 (1.446 sec)
34.705... logprob:  0.740627, 0.326823 (1.474 sec)
34.706... logprob:  0.702858, 0.330729 (1.429 sec)
34.707... logprob:  0.753514, 0.339844 (1.429 sec)
34.708... logprob:  0.648809, 0.282552 (1.427 sec)
34.709... logprob:  0.646330, 0.286458 (1.420 sec)
34.710... logprob:  0.773297, 0.337240 (1.434 sec)
34.711... logprob:  0.659129, 0.281250 (1.463 sec)
34.712... logprob:  0.587489, 0.255208 (1.444 sec)
34.713... logprob:  0.694009, 0.295573 (1.446 sec)
34.714... logprob:  0.729303, 0.325521 (1.450 sec)
34.715... logprob:  0.576035, 0.255208 (1.449 sec)
34.716... logprob:  0.597475, 0.285156 (1.430 sec)
34.717... logprob:  0.645650, 0.281250 (1.424 sec)
34.718... logprob:  0.701477, 0.285156 (1.430 sec)
34.719... logprob:  0.625749, 0.289062 (1.437 sec)
34.720... logprob:  0.649743, 0.265625 (1.443 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.559247, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.057811e-03 [1.029289e-07] 
Layer 'conv1' biases: 2.195567e-06 [2.178971e-11] 
Layer 'conv2' weights[0]: 2.053668e-03 [1.027364e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.297711e-10] 
Layer 'conv3' weights[0]: 2.052704e-03 [1.028258e-07] 
Layer 'conv3' biases: 3.652330e-05 [4.059276e-09] 
Layer 'conv4' weights[0]: 2.061419e-03 [1.033598e-07] 
Layer 'conv4' biases: 9.997891e-01 [1.592444e-07] 
Layer 'conv5' weights[0]: 2.241641e-03 [2.102145e-06] 
Layer 'conv5' biases: 9.989305e-01 [2.171093e-06] 
Layer 'fc6' weights[0]: 6.598473e-03 [5.813699e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.446181e-08] 
Layer 'fc7' weights[0]: 6.938708e-03 [1.354187e-07] 
Layer 'fc7' biases: 9.996846e-01 [1.621781e-07] 
Layer 'fc8' weights[0]: 4.773361e-03 [1.057738e-05] 
Layer 'fc8' biases: 2.838869e-02 [9.838703e-06] 
Train error last 800 batches: 0.655248
-------------------------------------------------------
Not saving because 0.559247 > 0.299667 (9.300: -1.18%)
======================================================= (2.396 sec)
34.721... logprob:  0.707078, 0.326823 (1.460 sec)
34.722... logprob:  0.703455, 0.304688 (1.456 sec)
34.723... logprob:  0.581596, 0.281250 (1.448 sec)
34.724... logprob:  0.691013, 0.322917 (1.472 sec)
34.725... logprob:  0.700332, 0.321615 (1.434 sec)
34.726... logprob:  0.676600, 0.309896 (1.421 sec)
34.727... logprob:  0.592348, 0.292969 (1.426 sec)
34.728... logprob:  0.639261, 0.255208 (1.441 sec)
34.729... logprob:  0.611074, 0.259114 (1.427 sec)
34.730... logprob:  0.762871, 0.337239 (1.469 sec)
34.731... logprob:  0.662980, 0.282552 (1.449 sec)
34.732... logprob:  0.505392, 0.225260 (1.432 sec)
34.733... logprob:  0.764573, 0.291667 (1.479 sec)
34.734... logprob:  0.542517, 0.233073 (1.428 sec)
34.735... logprob:  0.659403, 0.298177 (1.425 sec)
34.736... logprob:  0.755499, 0.332031 (1.430 sec)
34.737... logprob:  0.684893, 0.311198 (1.427 sec)
34.738... logprob:  0.650342, 0.286458 (1.421 sec)
34.739... logprob:  0.700061, 0.292969 (1.479 sec)
34.740... logprob:  0.524064, 0.235677 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.397749, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.055750e-03 [1.028184e-07] 
Layer 'conv1' biases: 2.195640e-06 [2.108175e-11] 
Layer 'conv2' weights[0]: 2.051612e-03 [1.026289e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.679625e-10] 
Layer 'conv3' weights[0]: 2.050654e-03 [1.026511e-07] 
Layer 'conv3' biases: 3.652214e-05 [3.385958e-09] 
Layer 'conv4' weights[0]: 2.059354e-03 [1.032072e-07] 
Layer 'conv4' biases: 9.997892e-01 [1.411258e-07] 
Layer 'conv5' weights[0]: 2.240354e-03 [2.218346e-06] 
Layer 'conv5' biases: 9.989239e-01 [2.417948e-06] 
Layer 'fc6' weights[0]: 6.597760e-03 [5.785117e-08] 
Layer 'fc6' biases: 9.999894e-01 [5.398104e-08] 
Layer 'fc7' weights[0]: 6.937972e-03 [1.394974e-07] 
Layer 'fc7' biases: 9.996849e-01 [1.789713e-07] 
Layer 'fc8' weights[0]: 4.781592e-03 [1.187491e-05] 
Layer 'fc8' biases: 2.851820e-02 [2.504485e-05] 
Train error last 800 batches: 0.654876
-------------------------------------------------------
Not saving because 0.397749 > 0.299667 (9.300: -1.18%)
======================================================= (2.367 sec)
34.741... logprob:  0.691099, 0.294271 (1.438 sec)
34.742... logprob:  0.631688, 0.270833 (1.480 sec)
34.743... logprob:  0.579669, 0.261719 (1.432 sec)
34.744... logprob:  0.772055, 0.312500 (1.432 sec)
34.745... logprob:  0.683625, 0.296875 (1.436 sec)
34.746... logprob:  0.623583, 0.252604 (1.422 sec)
34.747... logprob:  0.626334, 0.247396 (1.427 sec)
34.748... logprob:  0.693330, 0.274740 (1.479 sec)
34.749... logprob:  0.645880, 0.302083 (1.428 sec)
34.750... logprob:  0.641658, 0.281250 (1.447 sec)
34.751... logprob:  0.543665, 0.251302 (1.476 sec)
34.752... logprob:  0.692447, 0.326823 (1.429 sec)
34.753... logprob:  0.643153, 0.273437 (1.431 sec)
34.754... logprob:  0.605780, 0.269531 (1.427 sec)
34.755... logprob:  0.805111, 0.356771 (1.419 sec)
34.756... logprob:  0.595192, 0.273437 (1.430 sec)
34.757... logprob:  0.790124, 0.360677 (1.465 sec)
34.758... logprob:  0.628010, 0.294271 (1.437 sec)
34.759... logprob:  0.795832, 0.350260 (1.448 sec)
34.760... logprob:  0.650194, 0.300781 (1.463 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.531605, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.053696e-03 [1.027228e-07] 
Layer 'conv1' biases: 2.195766e-06 [2.191729e-11] 
Layer 'conv2' weights[0]: 2.049572e-03 [1.025313e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.784257e-10] 
Layer 'conv3' weights[0]: 2.048608e-03 [1.026427e-07] 
Layer 'conv3' biases: 3.650195e-05 [4.501739e-09] 
Layer 'conv4' weights[0]: 2.057292e-03 [1.032320e-07] 
Layer 'conv4' biases: 9.997904e-01 [1.695375e-07] 
Layer 'conv5' weights[0]: 2.239460e-03 [2.217340e-06] 
Layer 'conv5' biases: 9.989066e-01 [2.341565e-06] 
Layer 'fc6' weights[0]: 6.597080e-03 [5.888682e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.576608e-08] 
Layer 'fc7' weights[0]: 6.937262e-03 [1.424330e-07] 
Layer 'fc7' biases: 9.996859e-01 [1.920223e-07] 
Layer 'fc8' weights[0]: 4.813005e-03 [1.285713e-05] 
Layer 'fc8' biases: 2.880197e-02 [3.681053e-05] 
Train error last 800 batches: 0.654990
-------------------------------------------------------
Not saving because 0.531605 > 0.299667 (9.300: -1.18%)
======================================================= (2.368 sec)
34.761... logprob:  0.604188, 0.253906 (1.450 sec)
34.762... logprob:  0.768322, 0.346354 (1.438 sec)
34.763... logprob:  0.714987, 0.320312 (1.423 sec)
34.764... logprob:  0.697138, 0.309896 (1.427 sec)
34.765... logprob:  0.523864, 0.239583 (1.431 sec)
34.766... logprob:  0.667370, 0.279948 (1.448 sec)
34.767... logprob:  0.637575, 0.305990 (1.455 sec)
34.768... logprob:  0.577386, 0.242187 (1.460 sec)
34.769... logprob:  0.597517, 0.236979 (1.461 sec)
34.770... logprob:  0.565055, 0.281250 (1.474 sec)
34.771... logprob:  0.752308, 0.317708 (1.452 sec)
34.772... logprob:  0.609843, 0.278646 (1.437 sec)
34.773... logprob:  0.699690, 0.332031 (1.441 sec)
34.774... logprob:  0.493995, 0.230469 (1.452 sec)
34.775... logprob:  0.638277, 0.278646 (1.459 sec)
34.776... logprob:  0.649362, 0.276042 (1.471 sec)
34.777... logprob:  0.653597, 0.308594 (1.468 sec)
34.778... logprob:  0.679487, 0.300781 (1.465 sec)
34.779... logprob:  0.750293, 0.354167 (1.477 sec)
34.780... logprob:  0.645628, 0.290365 (1.451 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.372491, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.051642e-03 [1.026080e-07] 
Layer 'conv1' biases: 2.195850e-06 [1.510960e-11] 
Layer 'conv2' weights[0]: 2.047517e-03 [1.024153e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.515244e-10] 
Layer 'conv3' weights[0]: 2.046554e-03 [1.024272e-07] 
Layer 'conv3' biases: 3.648665e-05 [2.652277e-09] 
Layer 'conv4' weights[0]: 2.055232e-03 [1.029365e-07] 
Layer 'conv4' biases: 9.997911e-01 [1.040053e-07] 
Layer 'conv5' weights[0]: 2.238434e-03 [2.164754e-06] 
Layer 'conv5' biases: 9.989008e-01 [2.370419e-06] 
Layer 'fc6' weights[0]: 6.596412e-03 [5.699566e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.335156e-08] 
Layer 'fc7' weights[0]: 6.936564e-03 [1.342648e-07] 
Layer 'fc7' biases: 9.996858e-01 [1.657273e-07] 
Layer 'fc8' weights[0]: 4.829013e-03 [1.124558e-05] 
Layer 'fc8' biases: 2.894996e-02 [2.057505e-05] 
Train error last 800 batches: 0.654019
-------------------------------------------------------
Not saving because 0.372491 > 0.299667 (9.300: -1.18%)
======================================================= (2.357 sec)
34.781... logprob:  0.576827, 0.260416 (1.453 sec)
34.782... logprob:  0.506551, 0.214844 (1.448 sec)
34.783... logprob:  0.676508, 0.274740 (1.452 sec)
34.784... logprob:  0.556306, 0.259115 (1.451 sec)
34.785... logprob:  0.710863, 0.313802 (1.486 sec)
34.786... logprob:  0.598223, 0.270833 (1.463 sec)
34.787... logprob:  0.687221, 0.307292 (1.452 sec)
34.788... logprob:  0.768148, 0.338542 (1.489 sec)
34.789... logprob:  0.527064, 0.253906 (1.447 sec)
34.790... logprob:  0.660300, 0.283854 (1.447 sec)
34.791... logprob:  0.648721, 0.311198 (1.449 sec)
34.792... logprob:  0.596902, 0.269531 (1.452 sec)
34.793... logprob:  0.627374, 0.276042 (1.447 sec)
34.794... logprob:  0.578118, 0.238281 (1.484 sec)
34.795... logprob:  0.648692, 0.300781 (1.458 sec)
34.796... logprob:  0.654561, 0.289062 (1.460 sec)
34.797... logprob:  0.590926, 0.251302 (1.490 sec)
34.798... logprob:  0.664120, 0.292969 (1.451 sec)
34.799... logprob:  0.579563, 0.272135 (1.441 sec)
34.800... logprob:  0.542405, 0.223958 (1.399 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.394927, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.049590e-03 [1.025123e-07] 
Layer 'conv1' biases: 2.195869e-06 [2.120076e-11] 
Layer 'conv2' weights[0]: 2.045461e-03 [1.023129e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.948425e-10] 
Layer 'conv3' weights[0]: 2.044514e-03 [1.023292e-07] 
Layer 'conv3' biases: 3.648614e-05 [2.790059e-09] 
Layer 'conv4' weights[0]: 2.053169e-03 [1.028359e-07] 
Layer 'conv4' biases: 9.997911e-01 [1.115144e-07] 
Layer 'conv5' weights[0]: 2.236643e-03 [2.045411e-06] 
Layer 'conv5' biases: 9.988869e-01 [2.260540e-06] 
Layer 'fc6' weights[0]: 6.595727e-03 [5.869290e-08] 
Layer 'fc6' biases: 9.999890e-01 [5.587633e-08] 
Layer 'fc7' weights[0]: 6.935856e-03 [1.380266e-07] 
Layer 'fc7' biases: 9.996871e-01 [1.877661e-07] 
Layer 'fc8' weights[0]: 4.859558e-03 [1.227820e-05] 
Layer 'fc8' biases: 2.915613e-02 [2.960360e-05] 
Train error last 800 batches: 0.653308
-------------------------------------------------------
Not saving because 0.394927 > 0.299667 (9.300: -1.18%)
======================================================= (2.359 sec)
35.1... logprob:  0.617551, 0.264323 (1.402 sec)
35.2... logprob:  0.610502, 0.250000 (1.454 sec)
35.3... logprob:  0.608949, 0.270833 (1.419 sec)
35.4... logprob:  0.672289, 0.255208 (1.400 sec)
35.5... logprob:  0.689881, 0.279948 (1.424 sec)
35.6... logprob:  0.697553, 0.302083 (1.391 sec)
35.7... logprob:  0.612524, 0.261719 (1.418 sec)
35.8... logprob:  0.610523, 0.287760 (1.389 sec)
35.9... logprob:  0.559039, 0.260417 (1.398 sec)
35.10... logprob:  0.552357, 0.252604 (1.403 sec)
35.11... logprob:  0.500806, 0.243490 (1.437 sec)
35.12... logprob:  0.660285, 0.321615 (1.396 sec)
35.13... logprob:  0.703742, 0.316406 (1.420 sec)
35.14... logprob:  0.615842, 0.263021 (1.399 sec)
35.15... logprob:  0.601123, 0.265625 (1.408 sec)
35.16... logprob:  0.608566, 0.268229 (1.403 sec)
35.17... logprob:  0.724541, 0.311198 (1.387 sec)
35.18... logprob:  0.488055, 0.222656 (1.396 sec)
35.19... logprob:  0.520876, 0.233073 (1.399 sec)
35.20... logprob:  0.613632, 0.264323 (1.397 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.429435, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.047546e-03 [1.024235e-07] 
Layer 'conv1' biases: 2.195971e-06 [2.498120e-11] 
Layer 'conv2' weights[0]: 2.043406e-03 [1.022229e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.187786e-10] 
Layer 'conv3' weights[0]: 2.042462e-03 [1.023493e-07] 
Layer 'conv3' biases: 3.648949e-05 [4.917873e-09] 
Layer 'conv4' weights[0]: 2.051133e-03 [1.029286e-07] 
Layer 'conv4' biases: 9.997904e-01 [1.720169e-07] 
Layer 'conv5' weights[0]: 2.234311e-03 [3.032280e-06] 
Layer 'conv5' biases: 9.988844e-01 [3.349561e-06] 
Layer 'fc6' weights[0]: 6.595056e-03 [6.119909e-08] 
Layer 'fc6' biases: 9.999888e-01 [5.924236e-08] 
Layer 'fc7' weights[0]: 6.935178e-03 [1.476381e-07] 
Layer 'fc7' biases: 9.996866e-01 [2.255655e-07] 
Layer 'fc8' weights[0]: 4.868700e-03 [1.315791e-05] 
Layer 'fc8' biases: 2.924941e-02 [3.593401e-05] 
Train error last 800 batches: 0.652290
-------------------------------------------------------
Not saving because 0.429435 > 0.299667 (9.300: -1.18%)
======================================================= (2.370 sec)
35.21... logprob:  0.651880, 0.304688 (1.402 sec)
35.22... logprob:  0.755408, 0.300781 (1.417 sec)
35.23... logprob:  0.819189, 0.341146 (1.429 sec)
35.24... logprob:  0.535733, 0.244792 (1.411 sec)
35.25... logprob:  0.592582, 0.266927 (1.400 sec)
35.26... logprob:  0.723502, 0.305990 (1.447 sec)
35.27... logprob:  0.719617, 0.299479 (1.381 sec)
35.28... logprob:  0.667297, 0.298177 (1.411 sec)
35.29... logprob:  0.566421, 0.270833 (1.421 sec)
35.30... logprob:  0.524556, 0.234375 (1.408 sec)
35.31... logprob:  0.749581, 0.328125 (1.394 sec)
35.32... logprob:  0.637960, 0.285156 (1.382 sec)
35.33... logprob:  0.810757, 0.345052 (1.440 sec)
35.34... logprob:  0.768045, 0.333333 (1.389 sec)
35.35... logprob:  0.609066, 0.279948 (1.398 sec)
35.36... logprob:  0.601396, 0.250000 (1.394 sec)
35.37... logprob:  0.594551, 0.285156 (1.407 sec)
35.38... logprob:  0.629621, 0.277344 (1.389 sec)
35.39... logprob:  0.786947, 0.330729 (1.427 sec)
35.40... logprob:  0.628285, 0.277344 (1.401 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.517238, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.045505e-03 [1.023136e-07] 
Layer 'conv1' biases: 2.196159e-06 [1.797790e-11] 
Layer 'conv2' weights[0]: 2.041369e-03 [1.021103e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.875092e-10] 
Layer 'conv3' weights[0]: 2.040416e-03 [1.022345e-07] 
Layer 'conv3' biases: 3.651185e-05 [4.868120e-09] 
Layer 'conv4' weights[0]: 2.049079e-03 [1.027498e-07] 
Layer 'conv4' biases: 9.997881e-01 [1.885335e-07] 
Layer 'conv5' weights[0]: 2.230094e-03 [2.755632e-06] 
Layer 'conv5' biases: 9.989097e-01 [3.028167e-06] 
Layer 'fc6' weights[0]: 6.594348e-03 [6.178777e-08] 
Layer 'fc6' biases: 9.999889e-01 [5.988649e-08] 
Layer 'fc7' weights[0]: 6.934441e-03 [1.464500e-07] 
Layer 'fc7' biases: 9.996852e-01 [2.019706e-07] 
Layer 'fc8' weights[0]: 4.820240e-03 [1.175015e-05] 
Layer 'fc8' biases: 2.888738e-02 [2.560635e-05] 
Train error last 800 batches: 0.652992
-------------------------------------------------------
Not saving because 0.517238 > 0.299667 (9.300: -1.18%)
======================================================= (2.391 sec)
35.41... logprob:  0.669625, 0.276042 (1.425 sec)
35.42... logprob:  0.636499, 0.294271 (1.419 sec)
35.43... logprob:  0.662299, 0.309896 (1.405 sec)
35.44... logprob:  0.707636, 0.289062 (1.430 sec)
35.45... logprob:  0.573498, 0.278646 (1.383 sec)
35.46... logprob:  0.746363, 0.335938 (1.397 sec)
35.47... logprob:  0.611968, 0.256510 (1.389 sec)
35.48... logprob:  0.767794, 0.326823 (1.417 sec)
35.49... logprob:  0.636927, 0.282552 (1.406 sec)
35.50... logprob:  0.640139, 0.279948 (1.420 sec)
35.51... logprob:  0.772331, 0.321615 (1.410 sec)
35.52... logprob:  0.713419, 0.304688 (1.391 sec)
35.53... logprob:  0.578658, 0.255208 (1.436 sec)
35.54... logprob:  0.585026, 0.260417 (1.384 sec)
35.55... logprob:  0.526429, 0.230469 (1.390 sec)
35.56... logprob:  0.612015, 0.273438 (1.396 sec)
35.57... logprob:  0.808793, 0.347656 (1.422 sec)
35.58... logprob:  0.652309, 0.268229 (1.397 sec)
35.59... logprob:  0.516949, 0.244792 (1.457 sec)
35.60... logprob:  0.767817, 0.300781 (1.414 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.413773, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.043458e-03 [1.022038e-07] 
Layer 'conv1' biases: 2.196288e-06 [1.713298e-11] 
Layer 'conv2' weights[0]: 2.039319e-03 [1.020078e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.505670e-10] 
Layer 'conv3' weights[0]: 2.038371e-03 [1.020328e-07] 
Layer 'conv3' biases: 3.653126e-05 [2.862938e-09] 
Layer 'conv4' weights[0]: 2.047028e-03 [1.024854e-07] 
Layer 'conv4' biases: 9.997872e-01 [1.068905e-07] 
Layer 'conv5' weights[0]: 2.227033e-03 [2.434403e-06] 
Layer 'conv5' biases: 9.989190e-01 [2.658835e-06] 
Layer 'fc6' weights[0]: 6.593712e-03 [5.950348e-08] 
Layer 'fc6' biases: 9.999890e-01 [5.632043e-08] 
Layer 'fc7' weights[0]: 6.933751e-03 [1.424377e-07] 
Layer 'fc7' biases: 9.996849e-01 [1.784448e-07] 
Layer 'fc8' weights[0]: 4.793741e-03 [1.209861e-05] 
Layer 'fc8' biases: 2.863353e-02 [2.078861e-05] 
Train error last 800 batches: 0.653377
-------------------------------------------------------
Not saving because 0.413773 > 0.299667 (9.300: -1.18%)
======================================================= (2.374 sec)
35.61... logprob:  0.668753, 0.299479 (1.442 sec)
35.62... logprob:  0.718726, 0.317708 (1.484 sec)
35.63... logprob:  0.629811, 0.302083 (1.434 sec)
35.64... logprob:  0.642861, 0.272135 (1.410 sec)
35.65... logprob:  0.608758, 0.260417 (1.391 sec)
35.66... logprob:  0.597170, 0.260417 (1.438 sec)
35.67... logprob:  0.574870, 0.266927 (1.383 sec)
35.68... logprob:  0.651442, 0.282552 (1.393 sec)
35.69... logprob:  0.695818, 0.302083 (1.426 sec)
35.70... logprob:  0.552628, 0.260417 (1.416 sec)
35.71... logprob:  0.658637, 0.277344 (1.454 sec)
35.72... logprob:  0.737788, 0.308594 (1.395 sec)
35.73... logprob:  0.620539, 0.278646 (1.421 sec)
35.74... logprob:  0.607276, 0.261719 (1.423 sec)
35.75... logprob:  0.648679, 0.264323 (1.412 sec)
35.76... logprob:  0.693067, 0.292969 (1.428 sec)
35.77... logprob:  0.620005, 0.278646 (1.419 sec)
35.78... logprob:  0.669593, 0.291667 (1.452 sec)
35.79... logprob:  0.713973, 0.309896 (1.392 sec)
35.80... logprob:  0.704469, 0.299479 (1.417 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.502508, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.041409e-03 [1.020930e-07] 
Layer 'conv1' biases: 2.196338e-06 [1.954950e-11] 
Layer 'conv2' weights[0]: 2.037299e-03 [1.019020e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.107039e-10] 
Layer 'conv3' weights[0]: 2.036343e-03 [1.020080e-07] 
Layer 'conv3' biases: 3.652200e-05 [4.263893e-09] 
Layer 'conv4' weights[0]: 2.044971e-03 [1.024888e-07] 
Layer 'conv4' biases: 9.997870e-01 [1.703277e-07] 
Layer 'conv5' weights[0]: 2.225495e-03 [2.517566e-06] 
Layer 'conv5' biases: 9.989052e-01 [2.725967e-06] 
Layer 'fc6' weights[0]: 6.593047e-03 [6.140077e-08] 
Layer 'fc6' biases: 9.999889e-01 [5.941257e-08] 
Layer 'fc7' weights[0]: 6.933042e-03 [1.495079e-07] 
Layer 'fc7' biases: 9.996848e-01 [2.018973e-07] 
Layer 'fc8' weights[0]: 4.813394e-03 [1.255723e-05] 
Layer 'fc8' biases: 2.871835e-02 [2.458843e-05] 
Train error last 800 batches: 0.653137
-------------------------------------------------------
Not saving because 0.502508 > 0.299667 (9.300: -1.18%)
======================================================= (2.387 sec)
35.81... logprob:  0.643428, 0.303385 (1.423 sec)
35.82... logprob:  0.449123, 0.208333 (1.427 sec)
35.83... logprob:  0.733147, 0.328125 (1.403 sec)
35.84... logprob:  0.664651, 0.268229 (1.460 sec)
35.85... logprob:  0.649294, 0.290365 (1.420 sec)
35.86... logprob:  0.677983, 0.302083 (1.412 sec)
35.87... logprob:  0.835443, 0.363281 (1.405 sec)
35.88... logprob:  0.847819, 0.337240 (1.403 sec)
35.89... logprob:  0.664011, 0.307292 (1.430 sec)
35.90... logprob:  0.724125, 0.304688 (1.382 sec)
35.91... logprob:  0.541188, 0.233073 (1.389 sec)
35.92... logprob:  0.825639, 0.372396 (1.394 sec)
35.93... logprob:  0.752382, 0.324219 (1.392 sec)
35.94... logprob:  0.559859, 0.246094 (1.383 sec)
35.95... logprob:  0.712928, 0.283854 (1.400 sec)
35.96... logprob:  0.733736, 0.326823 (1.407 sec)
35.97... logprob:  0.728523, 0.300781 (1.393 sec)
35.98... logprob:  0.519273, 0.243490 (1.427 sec)
35.99... logprob:  0.723936, 0.329427 (1.401 sec)
35.100... logprob:  0.482014, 0.227865 (1.398 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.574923, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.039364e-03 [1.020263e-07] 
Layer 'conv1' biases: 2.196518e-06 [1.898159e-11] 
Layer 'conv2' weights[0]: 2.035260e-03 [1.018089e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.291332e-10] 
Layer 'conv3' weights[0]: 2.034293e-03 [1.018299e-07] 
Layer 'conv3' biases: 3.653664e-05 [2.708046e-09] 
Layer 'conv4' weights[0]: 2.042930e-03 [1.023259e-07] 
Layer 'conv4' biases: 9.997854e-01 [1.068965e-07] 
Layer 'conv5' weights[0]: 2.222375e-03 [2.017683e-06] 
Layer 'conv5' biases: 9.989354e-01 [2.197075e-06] 
Layer 'fc6' weights[0]: 6.592347e-03 [5.799105e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.411561e-08] 
Layer 'fc7' weights[0]: 6.932334e-03 [1.336852e-07] 
Layer 'fc7' biases: 9.996831e-01 [1.642764e-07] 
Layer 'fc8' weights[0]: 4.759622e-03 [1.088541e-05] 
Layer 'fc8' biases: 2.832014e-02 [1.724911e-05] 
Train error last 800 batches: 0.653545
-------------------------------------------------------
Not saving because 0.574923 > 0.299667 (9.300: -1.18%)
======================================================= (2.384 sec)
35.101... logprob:  0.586938, 0.263021 (1.459 sec)
35.102... logprob:  0.730689, 0.298177 (1.395 sec)
35.103... logprob:  0.773195, 0.326823 (1.396 sec)
35.104... logprob:  0.574198, 0.273437 (1.396 sec)
35.105... logprob:  0.763984, 0.334635 (1.388 sec)
35.106... logprob:  0.557337, 0.250000 (1.386 sec)
35.107... logprob:  0.577339, 0.246094 (1.450 sec)
35.108... logprob:  0.736329, 0.326823 (1.395 sec)
35.109... logprob:  0.628274, 0.287760 (1.398 sec)
35.110... logprob:  0.822264, 0.369792 (1.398 sec)
35.111... logprob:  0.653071, 0.278646 (1.386 sec)
35.112... logprob:  0.636546, 0.315104 (1.396 sec)
35.113... logprob:  0.595760, 0.251302 (1.392 sec)
35.114... logprob:  0.702719, 0.303385 (1.424 sec)
35.115... logprob:  0.678083, 0.309896 (1.407 sec)
35.116... logprob:  0.563879, 0.276042 (1.388 sec)
35.117... logprob:  0.638030, 0.302083 (1.441 sec)
35.118... logprob:  0.579731, 0.256510 (1.386 sec)
35.119... logprob:  0.588684, 0.260417 (1.392 sec)
35.120... logprob:  0.743539, 0.311198 (1.393 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.443041, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.037328e-03 [1.019137e-07] 
Layer 'conv1' biases: 2.196662e-06 [3.011157e-11] 
Layer 'conv2' weights[0]: 2.033222e-03 [1.017219e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.258337e-10] 
Layer 'conv3' weights[0]: 2.032262e-03 [1.017729e-07] 
Layer 'conv3' biases: 3.653085e-05 [3.791332e-09] 
Layer 'conv4' weights[0]: 2.040883e-03 [1.022977e-07] 
Layer 'conv4' biases: 9.997861e-01 [1.301690e-07] 
Layer 'conv5' weights[0]: 2.221450e-03 [2.598195e-06] 
Layer 'conv5' biases: 9.989141e-01 [2.814358e-06] 
Layer 'fc6' weights[0]: 6.591682e-03 [6.275356e-08] 
Layer 'fc6' biases: 9.999890e-01 [6.058971e-08] 
Layer 'fc7' weights[0]: 6.931619e-03 [1.553513e-07] 
Layer 'fc7' biases: 9.996841e-01 [2.326916e-07] 
Layer 'fc8' weights[0]: 4.797088e-03 [1.432891e-05] 
Layer 'fc8' biases: 2.869734e-02 [3.775678e-05] 
Train error last 800 batches: 0.653729
-------------------------------------------------------
Not saving because 0.443041 > 0.299667 (9.300: -1.18%)
======================================================= (2.382 sec)
35.121... logprob:  0.598728, 0.273438 (1.405 sec)
35.122... logprob:  0.755795, 0.345052 (1.455 sec)
35.123... logprob:  0.711936, 0.296875 (1.386 sec)
35.124... logprob:  0.617225, 0.252604 (1.396 sec)
35.125... logprob:  0.736928, 0.320312 (1.391 sec)
35.126... logprob:  0.694367, 0.315104 (1.387 sec)
35.127... logprob:  0.672454, 0.307292 (1.392 sec)
35.128... logprob:  0.589359, 0.269531 (1.407 sec)
35.129... logprob:  0.717173, 0.320312 (1.414 sec)
35.130... logprob:  0.643094, 0.263021 (1.410 sec)
35.131... logprob:  0.676192, 0.324219 (1.400 sec)
35.132... logprob:  0.660053, 0.307292 (1.430 sec)
35.133... logprob:  0.740234, 0.328125 (1.380 sec)
35.134... logprob:  0.635886, 0.312500 (1.391 sec)
35.135... logprob:  0.673926, 0.291667 (1.398 sec)
35.136... logprob:  0.763442, 0.347656 (1.397 sec)
35.137... logprob:  0.636908, 0.261719 (1.381 sec)
35.138... logprob:  0.619357, 0.298177 (1.440 sec)
35.139... logprob:  0.580146, 0.260417 (1.393 sec)
35.140... logprob:  0.732105, 0.312500 (1.403 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.321522, 0.039062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.035290e-03 [1.017771e-07] 
Layer 'conv1' biases: 2.196848e-06 [2.071046e-11] 
Layer 'conv2' weights[0]: 2.031195e-03 [1.015960e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.599605e-10] 
Layer 'conv3' weights[0]: 2.030236e-03 [1.015945e-07] 
Layer 'conv3' biases: 3.651913e-05 [2.888023e-09] 
Layer 'conv4' weights[0]: 2.038843e-03 [1.020120e-07] 
Layer 'conv4' biases: 9.997859e-01 [9.593474e-08] 
Layer 'conv5' weights[0]: 2.219900e-03 [2.117641e-06] 
Layer 'conv5' biases: 9.989123e-01 [2.331140e-06] 
Layer 'fc6' weights[0]: 6.591020e-03 [5.679125e-08] 
Layer 'fc6' biases: 9.999890e-01 [5.245646e-08] 
Layer 'fc7' weights[0]: 6.930912e-03 [1.337428e-07] 
Layer 'fc7' biases: 9.996836e-01 [1.594455e-07] 
Layer 'fc8' weights[0]: 4.794616e-03 [1.065127e-05] 
Layer 'fc8' biases: 2.873839e-02 [1.316841e-05] 
Train error last 800 batches: 0.654337
-------------------------------------------------------
Not saving because 0.321522 > 0.299667 (9.300: -1.18%)
======================================================= (2.390 sec)
35.141... logprob:  0.667451, 0.290365 (1.440 sec)
35.142... logprob:  0.609374, 0.283854 (1.394 sec)
35.143... logprob:  0.505647, 0.223958 (1.422 sec)
35.144... logprob:  0.637565, 0.278646 (1.418 sec)
35.145... logprob:  0.548087, 0.214844 (1.410 sec)
35.146... logprob:  0.638749, 0.257812 (1.403 sec)
35.147... logprob:  0.521733, 0.239583 (1.422 sec)
35.148... logprob:  0.665499, 0.285156 (1.386 sec)
35.149... logprob:  0.733542, 0.338542 (1.390 sec)
35.150... logprob:  0.615703, 0.286458 (1.394 sec)
35.151... logprob:  0.589650, 0.269531 (1.395 sec)
35.152... logprob:  0.859851, 0.355469 (1.391 sec)
35.153... logprob:  0.628365, 0.311198 (1.438 sec)
35.154... logprob:  0.701983, 0.324219 (1.399 sec)
35.155... logprob:  0.651937, 0.289062 (1.404 sec)
35.156... logprob:  0.517819, 0.236979 (1.426 sec)
35.157... logprob:  0.508757, 0.233073 (1.390 sec)
35.158... logprob:  0.676808, 0.299479 (1.394 sec)
35.159... logprob:  0.691520, 0.308594 (1.389 sec)
35.160... logprob:  0.612040, 0.278646 (1.387 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.455258, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.033265e-03 [1.017339e-07] 
Layer 'conv1' biases: 2.196978e-06 [2.246280e-11] 
Layer 'conv2' weights[0]: 2.029164e-03 [1.015220e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.274448e-10] 
Layer 'conv3' weights[0]: 2.028204e-03 [1.015811e-07] 
Layer 'conv3' biases: 3.650498e-05 [3.661685e-09] 
Layer 'conv4' weights[0]: 2.036814e-03 [1.020993e-07] 
Layer 'conv4' biases: 9.997876e-01 [1.400717e-07] 
Layer 'conv5' weights[0]: 2.219713e-03 [2.784799e-06] 
Layer 'conv5' biases: 9.988850e-01 [3.051507e-06] 
Layer 'fc6' weights[0]: 6.590346e-03 [5.922735e-08] 
Layer 'fc6' biases: 9.999889e-01 [5.645396e-08] 
Layer 'fc7' weights[0]: 6.930253e-03 [1.410961e-07] 
Layer 'fc7' biases: 9.996852e-01 [1.952747e-07] 
Layer 'fc8' weights[0]: 4.844675e-03 [1.185615e-05] 
Layer 'fc8' biases: 2.909383e-02 [2.552167e-05] 
Train error last 800 batches: 0.653990
-------------------------------------------------------
Not saving because 0.455258 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
35.161... logprob:  0.602161, 0.256510 (1.410 sec)
35.162... logprob:  0.722303, 0.316406 (1.405 sec)
35.163... logprob:  0.643822, 0.292969 (1.420 sec)
35.164... logprob:  0.736452, 0.315104 (1.417 sec)
35.165... logprob:  0.704142, 0.295573 (1.414 sec)
35.166... logprob:  0.636465, 0.291667 (1.440 sec)
35.167... logprob:  0.558985, 0.248698 (1.426 sec)
35.168... logprob:  0.632545, 0.291667 (1.415 sec)
35.169... logprob:  0.673356, 0.334635 (1.456 sec)
35.170... logprob:  0.654967, 0.287760 (1.400 sec)
35.171... logprob:  0.706224, 0.320312 (1.418 sec)
35.172... logprob:  0.681741, 0.278646 (1.406 sec)
35.173... logprob:  0.786984, 0.345052 (1.418 sec)
35.174... logprob:  0.834134, 0.347656 (1.394 sec)
35.175... logprob:  0.748804, 0.299479 (1.458 sec)
35.176... logprob:  0.603873, 0.252604 (1.413 sec)
35.177... logprob:  0.525538, 0.244792 (1.419 sec)
35.178... logprob:  0.640841, 0.253906 (1.447 sec)
35.179... logprob:  0.688899, 0.309896 (1.404 sec)
35.180... logprob:  0.636641, 0.261719 (1.441 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.505246, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.031236e-03 [1.016051e-07] 
Layer 'conv1' biases: 2.196973e-06 [3.519298e-11] 
Layer 'conv2' weights[0]: 2.027124e-03 [1.014077e-07] 
Layer 'conv2' biases: 9.999996e-01 [5.505820e-10] 
Layer 'conv3' weights[0]: 2.026181e-03 [1.017438e-07] 
Layer 'conv3' biases: 3.652616e-05 [6.875506e-09] 
Layer 'conv4' weights[0]: 2.034770e-03 [1.022595e-07] 
Layer 'conv4' biases: 9.997864e-01 [2.672760e-07] 
Layer 'conv5' weights[0]: 2.216798e-03 [2.921259e-06] 
Layer 'conv5' biases: 9.989053e-01 [3.242448e-06] 
Layer 'fc6' weights[0]: 6.589703e-03 [6.738623e-08] 
Layer 'fc6' biases: 9.999891e-01 [6.766878e-08] 
Layer 'fc7' weights[0]: 6.929514e-03 [1.641020e-07] 
Layer 'fc7' biases: 9.996834e-01 [2.561007e-07] 
Layer 'fc8' weights[0]: 4.798091e-03 [1.489217e-05] 
Layer 'fc8' biases: 2.875437e-02 [4.097324e-05] 
Train error last 800 batches: 0.654171
-------------------------------------------------------
Not saving because 0.505246 > 0.299667 (9.300: -1.18%)
======================================================= (2.339 sec)
35.181... logprob:  0.724275, 0.308594 (1.425 sec)
35.182... logprob:  0.588622, 0.282552 (1.414 sec)
35.183... logprob:  0.634823, 0.283854 (1.409 sec)
35.184... logprob:  0.588435, 0.244792 (1.414 sec)
35.185... logprob:  0.580432, 0.272135 (1.391 sec)
35.186... logprob:  0.684280, 0.316406 (1.390 sec)
35.187... logprob:  0.664187, 0.307292 (1.397 sec)
35.188... logprob:  0.736880, 0.320312 (1.396 sec)
35.189... logprob:  0.718320, 0.300781 (1.378 sec)
35.190... logprob:  0.556873, 0.243490 (1.435 sec)
35.191... logprob:  0.660418, 0.281250 (1.405 sec)
35.192... logprob:  0.709314, 0.304687 (1.412 sec)
35.193... logprob:  0.539397, 0.261719 (1.407 sec)
35.194... logprob:  0.640527, 0.281250 (1.411 sec)
35.195... logprob:  0.519559, 0.252604 (1.393 sec)
35.196... logprob:  0.654805, 0.285156 (1.384 sec)
35.197... logprob:  0.744048, 0.285156 (1.389 sec)
35.198... logprob:  0.541882, 0.238281 (1.401 sec)
35.199... logprob:  0.724145, 0.329427 (1.381 sec)
35.200... logprob:  0.638836, 0.270833 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.440095, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.029190e-03 [1.015446e-07] 
Layer 'conv1' biases: 2.197015e-06 [2.817294e-11] 
Layer 'conv2' weights[0]: 2.025110e-03 [1.013280e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.122223e-10] 
Layer 'conv3' weights[0]: 2.024159e-03 [1.014431e-07] 
Layer 'conv3' biases: 3.653050e-05 [4.784826e-09] 
Layer 'conv4' weights[0]: 2.032743e-03 [1.021246e-07] 
Layer 'conv4' biases: 9.997863e-01 [2.031243e-07] 
Layer 'conv5' weights[0]: 2.215218e-03 [2.731627e-06] 
Layer 'conv5' biases: 9.988886e-01 [3.001836e-06] 
Layer 'fc6' weights[0]: 6.589022e-03 [6.140885e-08] 
Layer 'fc6' biases: 9.999890e-01 [5.942271e-08] 
Layer 'fc7' weights[0]: 6.928837e-03 [1.489986e-07] 
Layer 'fc7' biases: 9.996842e-01 [2.119634e-07] 
Layer 'fc8' weights[0]: 4.825828e-03 [1.420074e-05] 
Layer 'fc8' biases: 2.899413e-02 [3.150191e-05] 
Train error last 800 batches: 0.654121
-------------------------------------------------------
Not saving because 0.440095 > 0.299667 (9.300: -1.18%)
======================================================= (2.368 sec)
35.201... logprob:  0.700707, 0.292969 (1.412 sec)
35.202... logprob:  0.796015, 0.354167 (1.401 sec)
35.203... logprob:  0.666001, 0.290365 (1.438 sec)
35.204... logprob:  0.699325, 0.341146 (1.382 sec)
35.205... logprob:  0.644471, 0.281250 (1.394 sec)
35.206... logprob:  0.587467, 0.266927 (1.397 sec)
35.207... logprob:  0.629835, 0.259114 (1.390 sec)
35.208... logprob:  0.671510, 0.290365 (1.391 sec)
35.209... logprob:  0.614244, 0.291667 (1.413 sec)
35.210... logprob:  0.777456, 0.329427 (1.408 sec)
35.211... logprob:  0.736391, 0.299479 (1.412 sec)
35.212... logprob:  0.641709, 0.281250 (1.412 sec)
35.213... logprob:  0.708215, 0.282552 (1.452 sec)
35.214... logprob:  0.663341, 0.298177 (1.417 sec)
35.215... logprob:  0.657454, 0.317708 (1.411 sec)
35.216... logprob:  0.753219, 0.302083 (1.460 sec)
35.217... logprob:  0.554925, 0.250000 (1.396 sec)
35.218... logprob:  0.583165, 0.260417 (1.413 sec)
35.219... logprob:  0.813237, 0.347656 (1.426 sec)
35.220... logprob:  0.577213, 0.240885 (1.414 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.455977, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.027169e-03 [1.013773e-07] 
Layer 'conv1' biases: 2.197213e-06 [2.588221e-11] 
Layer 'conv2' weights[0]: 2.023085e-03 [1.011917e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.710299e-10] 
Layer 'conv3' weights[0]: 2.022137e-03 [1.012833e-07] 
Layer 'conv3' biases: 3.656034e-05 [4.046877e-09] 
Layer 'conv4' weights[0]: 2.030714e-03 [1.017867e-07] 
Layer 'conv4' biases: 9.997842e-01 [1.557760e-07] 
Layer 'conv5' weights[0]: 2.211382e-03 [2.312487e-06] 
Layer 'conv5' biases: 9.989052e-01 [2.470462e-06] 
Layer 'fc6' weights[0]: 6.588361e-03 [5.787254e-08] 
Layer 'fc6' biases: 9.999890e-01 [5.462397e-08] 
Layer 'fc7' weights[0]: 6.928104e-03 [1.368150e-07] 
Layer 'fc7' biases: 9.996831e-01 [1.596054e-07] 
Layer 'fc8' weights[0]: 4.796961e-03 [1.055206e-05] 
Layer 'fc8' biases: 2.873080e-02 [2.920850e-06] 
Train error last 800 batches: 0.654412
-------------------------------------------------------
Not saving because 0.455977 > 0.299667 (9.300: -1.18%)
======================================================= (2.390 sec)
35.221... logprob:  0.571427, 0.276042 (1.409 sec)
35.222... logprob:  0.756014, 0.335938 (1.457 sec)
35.223... logprob:  0.807777, 0.333333 (1.427 sec)
35.224... logprob:  0.645903, 0.304687 (1.422 sec)
35.225... logprob:  0.547242, 0.248698 (1.440 sec)
35.226... logprob:  0.728521, 0.315104 (1.420 sec)
35.227... logprob:  0.731975, 0.330729 (1.413 sec)
35.228... logprob:  0.612924, 0.252604 (1.407 sec)
35.229... logprob:  0.796182, 0.355469 (1.414 sec)
35.230... logprob:  0.675208, 0.286458 (1.415 sec)
35.231... logprob:  0.664697, 0.308594 (1.397 sec)
35.232... logprob:  0.691703, 0.283854 (1.454 sec)
35.233... logprob:  0.717039, 0.295573 (1.419 sec)
35.234... logprob:  0.778072, 0.330729 (1.409 sec)
35.235... logprob:  0.761353, 0.334635 (1.462 sec)
35.236... logprob:  0.663061, 0.269531 (1.394 sec)
35.237... logprob:  0.566791, 0.261719 (1.417 sec)
35.238... logprob:  0.613770, 0.272135 (1.411 sec)
35.239... logprob:  0.659987, 0.278646 (1.416 sec)
35.240... logprob:  0.675222, 0.287760 (1.398 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.515289, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.025136e-03 [1.012654e-07] 
Layer 'conv1' biases: 2.197500e-06 [2.681743e-11] 
Layer 'conv2' weights[0]: 2.021062e-03 [1.010909e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.240463e-10] 
Layer 'conv3' weights[0]: 2.020104e-03 [1.011438e-07] 
Layer 'conv3' biases: 3.657744e-05 [3.573458e-09] 
Layer 'conv4' weights[0]: 2.028678e-03 [1.016340e-07] 
Layer 'conv4' biases: 9.997827e-01 [1.280805e-07] 
Layer 'conv5' weights[0]: 2.208277e-03 [2.182525e-06] 
Layer 'conv5' biases: 9.989205e-01 [2.391749e-06] 
Layer 'fc6' weights[0]: 6.587701e-03 [5.864439e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.534772e-08] 
Layer 'fc7' weights[0]: 6.927435e-03 [1.388112e-07] 
Layer 'fc7' biases: 9.996821e-01 [1.712298e-07] 
Layer 'fc8' weights[0]: 4.777138e-03 [1.118768e-05] 
Layer 'fc8' biases: 2.852725e-02 [9.587303e-06] 
Train error last 800 batches: 0.655046
-------------------------------------------------------
Not saving because 0.515289 > 0.299667 (9.300: -1.18%)
======================================================= (2.394 sec)
35.241... logprob:  0.685575, 0.264323 (1.461 sec)
35.242... logprob:  0.551966, 0.239583 (1.426 sec)
35.243... logprob:  0.637221, 0.278646 (1.429 sec)
35.244... logprob:  0.617914, 0.269531 (1.443 sec)
35.245... logprob:  0.676261, 0.291667 (1.414 sec)
35.246... logprob:  0.648519, 0.274739 (1.412 sec)
35.247... logprob:  0.533760, 0.223958 (1.410 sec)
35.248... logprob:  0.571069, 0.217448 (1.413 sec)
35.249... logprob:  0.839936, 0.352865 (1.418 sec)
35.250... logprob:  0.793409, 0.343750 (1.406 sec)
35.251... logprob:  0.618584, 0.287760 (1.453 sec)
35.252... logprob:  0.557324, 0.248698 (1.416 sec)
35.253... logprob:  0.631558, 0.283854 (1.412 sec)
35.254... logprob:  0.611837, 0.274740 (1.461 sec)
35.255... logprob:  0.616452, 0.276042 (1.402 sec)
35.256... logprob:  0.659438, 0.276042 (1.419 sec)
35.257... logprob:  0.573919, 0.265625 (1.407 sec)
35.258... logprob:  0.682030, 0.304687 (1.440 sec)
35.259... logprob:  0.707446, 0.324219 (1.394 sec)
35.260... logprob:  0.600795, 0.270833 (1.452 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.471203, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.023118e-03 [1.011748e-07] 
Layer 'conv1' biases: 2.197686e-06 [2.815649e-11] 
Layer 'conv2' weights[0]: 2.019038e-03 [1.009973e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.750407e-10] 
Layer 'conv3' weights[0]: 2.018088e-03 [1.010990e-07] 
Layer 'conv3' biases: 3.655569e-05 [4.510442e-09] 
Layer 'conv4' weights[0]: 2.026659e-03 [1.016649e-07] 
Layer 'conv4' biases: 9.997857e-01 [1.590907e-07] 
Layer 'conv5' weights[0]: 2.209374e-03 [2.894984e-06] 
Layer 'conv5' biases: 9.988896e-01 [3.201552e-06] 
Layer 'fc6' weights[0]: 6.587018e-03 [6.056705e-08] 
Layer 'fc6' biases: 9.999887e-01 [5.801775e-08] 
Layer 'fc7' weights[0]: 6.926697e-03 [1.450059e-07] 
Layer 'fc7' biases: 9.996845e-01 [2.017233e-07] 
Layer 'fc8' weights[0]: 4.826026e-03 [1.201835e-05] 
Layer 'fc8' biases: 2.903870e-02 [3.230378e-05] 
Train error last 800 batches: 0.655085
-------------------------------------------------------
Not saving because 0.471203 > 0.299667 (9.300: -1.18%)
======================================================= (2.358 sec)
35.261... logprob:  0.617572, 0.294271 (1.437 sec)
35.262... logprob:  0.594545, 0.269531 (1.431 sec)
35.263... logprob:  0.679641, 0.338542 (1.442 sec)
35.264... logprob:  0.684262, 0.285156 (1.413 sec)
35.265... logprob:  0.646775, 0.307292 (1.418 sec)
35.266... logprob:  0.683820, 0.321615 (1.407 sec)
35.267... logprob:  0.657760, 0.285156 (1.413 sec)
35.268... logprob:  0.703555, 0.311198 (1.411 sec)
35.269... logprob:  0.696703, 0.279948 (1.402 sec)
35.270... logprob:  0.734018, 0.332031 (1.452 sec)
35.271... logprob:  0.650441, 0.294271 (1.424 sec)
35.272... logprob:  0.669407, 0.269531 (1.416 sec)
35.273... logprob:  0.807453, 0.312500 (1.465 sec)
35.274... logprob:  0.779967, 0.338542 (1.399 sec)
35.275... logprob:  0.605609, 0.256510 (1.422 sec)
35.276... logprob:  0.585676, 0.250000 (1.411 sec)
35.277... logprob:  0.638767, 0.250000 (1.419 sec)
35.278... logprob:  0.551085, 0.277344 (1.420 sec)
35.279... logprob:  0.582911, 0.291667 (1.458 sec)
35.280... logprob:  0.471978, 0.226562 (1.400 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.460860, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.021088e-03 [1.011449e-07] 
Layer 'conv1' biases: 2.197811e-06 [2.077020e-11] 
Layer 'conv2' weights[0]: 2.017018e-03 [1.009202e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.084593e-10] 
Layer 'conv3' weights[0]: 2.016073e-03 [1.009558e-07] 
Layer 'conv3' biases: 3.657413e-05 [3.504957e-09] 
Layer 'conv4' weights[0]: 2.024634e-03 [1.015314e-07] 
Layer 'conv4' biases: 9.997854e-01 [1.565973e-07] 
Layer 'conv5' weights[0]: 2.207632e-03 [2.736820e-06] 
Layer 'conv5' biases: 9.989016e-01 [2.975956e-06] 
Layer 'fc6' weights[0]: 6.586353e-03 [6.148739e-08] 
Layer 'fc6' biases: 9.999887e-01 [5.961230e-08] 
Layer 'fc7' weights[0]: 6.926042e-03 [1.490442e-07] 
Layer 'fc7' biases: 9.996828e-01 [2.321315e-07] 
Layer 'fc8' weights[0]: 4.799144e-03 [1.353922e-05] 
Layer 'fc8' biases: 2.890376e-02 [3.495913e-05] 
Train error last 800 batches: 0.655324
-------------------------------------------------------
Not saving because 0.460860 > 0.299667 (9.300: -1.18%)
======================================================= (2.374 sec)
35.281... logprob:  0.678990, 0.320312 (1.432 sec)
35.282... logprob:  0.550495, 0.239583 (1.418 sec)
35.283... logprob:  0.656087, 0.230469 (1.419 sec)
35.284... logprob:  0.559326, 0.270833 (1.408 sec)
35.285... logprob:  0.713892, 0.296875 (1.432 sec)
35.286... logprob:  0.637387, 0.278646 (1.434 sec)
35.287... logprob:  0.615604, 0.285156 (1.424 sec)
35.288... logprob:  0.563370, 0.244792 (1.428 sec)
35.289... logprob:  0.675205, 0.291667 (1.436 sec)
35.290... logprob:  0.658073, 0.296875 (1.402 sec)
35.291... logprob:  0.674897, 0.296875 (1.411 sec)
35.292... logprob:  0.730228, 0.307292 (1.417 sec)
35.293... logprob:  0.627945, 0.259115 (1.415 sec)
35.294... logprob:  0.651462, 0.298177 (1.398 sec)
35.295... logprob:  0.630338, 0.287760 (1.458 sec)
35.296... logprob:  0.515157, 0.239583 (1.410 sec)
35.297... logprob:  0.706191, 0.309896 (1.423 sec)
35.298... logprob:  0.644686, 0.303385 (1.459 sec)
35.299... logprob:  0.583168, 0.257812 (1.393 sec)
35.300... logprob:  0.548452, 0.229167 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.497194, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.019074e-03 [1.010098e-07] 
Layer 'conv1' biases: 2.197998e-06 [2.278311e-11] 
Layer 'conv2' weights[0]: 2.015000e-03 [1.008076e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.834909e-10] 
Layer 'conv3' weights[0]: 2.014055e-03 [1.009224e-07] 
Layer 'conv3' biases: 3.656107e-05 [4.393176e-09] 
Layer 'conv4' weights[0]: 2.022601e-03 [1.014644e-07] 
Layer 'conv4' biases: 9.997853e-01 [1.589162e-07] 
Layer 'conv5' weights[0]: 2.206129e-03 [2.502114e-06] 
Layer 'conv5' biases: 9.988722e-01 [2.766903e-06] 
Layer 'fc6' weights[0]: 6.585670e-03 [5.924425e-08] 
Layer 'fc6' biases: 9.999887e-01 [5.672532e-08] 
Layer 'fc7' weights[0]: 6.925357e-03 [1.382497e-07] 
Layer 'fc7' biases: 9.996845e-01 [1.850303e-07] 
Layer 'fc8' weights[0]: 4.855688e-03 [1.128963e-05] 
Layer 'fc8' biases: 2.937099e-02 [2.319751e-05] 
Train error last 800 batches: 0.654698
-------------------------------------------------------
Not saving because 0.497194 > 0.299667 (9.300: -1.18%)
======================================================= (2.359 sec)
35.301... logprob:  0.596569, 0.268229 (1.419 sec)
35.302... logprob:  0.716344, 0.311198 (1.420 sec)
35.303... logprob:  0.699375, 0.313802 (1.412 sec)
35.304... logprob:  0.622417, 0.281250 (1.436 sec)
35.305... logprob:  0.727974, 0.311198 (1.430 sec)
35.306... logprob:  0.695885, 0.292969 (1.430 sec)
35.307... logprob:  0.619834, 0.253906 (1.433 sec)
35.308... logprob:  0.640732, 0.277344 (1.447 sec)
35.309... logprob:  0.623095, 0.268229 (1.409 sec)
35.310... logprob:  0.661127, 0.270833 (1.416 sec)
35.311... logprob:  0.723730, 0.298177 (1.415 sec)
35.312... logprob:  0.754882, 0.328125 (1.422 sec)
35.313... logprob:  0.659722, 0.272135 (1.414 sec)
35.314... logprob:  0.620979, 0.265625 (1.458 sec)
35.315... logprob:  0.453066, 0.190104 (1.423 sec)
35.316... logprob:  0.730265, 0.308594 (1.422 sec)
35.317... logprob:  0.554309, 0.229167 (1.470 sec)
35.318... logprob:  0.653642, 0.281250 (1.408 sec)
35.319... logprob:  0.635216, 0.283854 (1.482 sec)
35.320... logprob:  0.628657, 0.277344 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.410306, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.017056e-03 [1.008537e-07] 
Layer 'conv1' biases: 2.198101e-06 [2.661269e-11] 
Layer 'conv2' weights[0]: 2.012983e-03 [1.006690e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.560027e-10] 
Layer 'conv3' weights[0]: 2.012032e-03 [1.007537e-07] 
Layer 'conv3' biases: 3.656816e-05 [3.917615e-09] 
Layer 'conv4' weights[0]: 2.020566e-03 [1.012195e-07] 
Layer 'conv4' biases: 9.997853e-01 [1.377244e-07] 
Layer 'conv5' weights[0]: 2.204524e-03 [2.161869e-06] 
Layer 'conv5' biases: 9.988917e-01 [2.316894e-06] 
Layer 'fc6' weights[0]: 6.584981e-03 [5.761776e-08] 
Layer 'fc6' biases: 9.999887e-01 [5.438656e-08] 
Layer 'fc7' weights[0]: 6.924671e-03 [1.349567e-07] 
Layer 'fc7' biases: 9.996827e-01 [1.641023e-07] 
Layer 'fc8' weights[0]: 4.814988e-03 [1.075425e-05] 
Layer 'fc8' biases: 2.901108e-02 [1.086505e-05] 
Train error last 800 batches: 0.654671
-------------------------------------------------------
Not saving because 0.410306 > 0.299667 (9.300: -1.18%)
======================================================= (2.421 sec)
35.321... logprob:  0.596150, 0.273438 (1.423 sec)
35.322... logprob:  0.604294, 0.281250 (1.422 sec)
35.323... logprob:  0.676727, 0.289062 (1.476 sec)
35.324... logprob:  0.730772, 0.300781 (1.418 sec)
35.325... logprob:  0.632679, 0.291667 (1.427 sec)
35.326... logprob:  0.712314, 0.315104 (1.456 sec)
35.327... logprob:  0.793044, 0.333333 (1.417 sec)
35.328... logprob:  0.766483, 0.315104 (1.419 sec)
35.329... logprob:  0.671219, 0.296875 (1.417 sec)
35.330... logprob:  0.642137, 0.296875 (1.411 sec)
35.331... logprob:  0.598745, 0.268229 (1.414 sec)
35.332... logprob:  0.708553, 0.292969 (1.442 sec)
35.333... logprob:  0.602029, 0.268229 (1.438 sec)
35.334... logprob:  0.751864, 0.322917 (1.432 sec)
35.335... logprob:  0.492149, 0.207031 (1.444 sec)
35.336... logprob:  0.677528, 0.286458 (1.448 sec)
35.337... logprob:  0.667177, 0.290365 (1.406 sec)
35.338... logprob:  0.699159, 0.317708 (1.421 sec)
35.339... logprob:  0.753215, 0.309896 (1.422 sec)
35.340... logprob:  0.632333, 0.263021 (1.422 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.489518, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.015040e-03 [1.007722e-07] 
Layer 'conv1' biases: 2.198233e-06 [2.338527e-11] 
Layer 'conv2' weights[0]: 2.010984e-03 [1.005902e-07] 
Layer 'conv2' biases: 9.999996e-01 [4.160761e-10] 
Layer 'conv3' weights[0]: 2.010032e-03 [1.007000e-07] 
Layer 'conv3' biases: 3.658098e-05 [4.395829e-09] 
Layer 'conv4' weights[0]: 2.018550e-03 [1.012103e-07] 
Layer 'conv4' biases: 9.997842e-01 [1.593274e-07] 
Layer 'conv5' weights[0]: 2.201968e-03 [2.268610e-06] 
Layer 'conv5' biases: 9.989088e-01 [2.420678e-06] 
Layer 'fc6' weights[0]: 6.584304e-03 [6.208477e-08] 
Layer 'fc6' biases: 9.999889e-01 [6.008003e-08] 
Layer 'fc7' weights[0]: 6.923965e-03 [1.512907e-07] 
Layer 'fc7' biases: 9.996811e-01 [2.085123e-07] 
Layer 'fc8' weights[0]: 4.779523e-03 [1.369377e-05] 
Layer 'fc8' biases: 2.866593e-02 [3.291228e-05] 
Train error last 800 batches: 0.655043
-------------------------------------------------------
Not saving because 0.489518 > 0.299667 (9.300: -1.18%)
======================================================= (2.360 sec)
35.341... logprob:  0.689067, 0.324219 (1.417 sec)
35.342... logprob:  0.618219, 0.273438 (1.460 sec)
35.343... logprob:  0.661861, 0.294271 (1.436 sec)
35.344... logprob:  0.695983, 0.312500 (1.476 sec)
35.345... logprob:  0.681454, 0.273438 (1.434 sec)
35.346... logprob:  0.642198, 0.289062 (1.430 sec)
35.347... logprob:  0.629269, 0.269531 (1.476 sec)
35.348... logprob:  0.625860, 0.289062 (1.427 sec)
35.349... logprob:  0.669437, 0.295573 (1.429 sec)
35.350... logprob:  0.609584, 0.283854 (1.428 sec)
35.351... logprob:  0.716813, 0.300781 (1.421 sec)
35.352... logprob:  0.608474, 0.276042 (1.430 sec)
35.353... logprob:  0.714028, 0.299479 (1.481 sec)
35.354... logprob:  0.786846, 0.339844 (1.423 sec)
35.355... logprob:  0.684782, 0.278646 (1.433 sec)
35.356... logprob:  0.778659, 0.350260 (1.476 sec)
35.357... logprob:  0.634421, 0.295573 (1.422 sec)
35.358... logprob:  0.554577, 0.239583 (1.433 sec)
35.359... logprob:  0.693689, 0.268229 (1.427 sec)
35.360... logprob:  0.678542, 0.312500 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.465938, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.013026e-03 [1.006623e-07] 
Layer 'conv1' biases: 2.198381e-06 [3.063488e-11] 
Layer 'conv2' weights[0]: 2.008962e-03 [1.004856e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.153503e-10] 
Layer 'conv3' weights[0]: 2.008020e-03 [1.005181e-07] 
Layer 'conv3' biases: 3.657514e-05 [3.364058e-09] 
Layer 'conv4' weights[0]: 2.016536e-03 [1.010297e-07] 
Layer 'conv4' biases: 9.997834e-01 [1.293375e-07] 
Layer 'conv5' weights[0]: 2.199470e-03 [2.251527e-06] 
Layer 'conv5' biases: 9.988910e-01 [2.306903e-06] 
Layer 'fc6' weights[0]: 6.583666e-03 [6.011674e-08] 
Layer 'fc6' biases: 9.999888e-01 [5.772548e-08] 
Layer 'fc7' weights[0]: 6.923318e-03 [1.497945e-07] 
Layer 'fc7' biases: 9.996821e-01 [2.078435e-07] 
Layer 'fc8' weights[0]: 4.804312e-03 [1.447833e-05] 
Layer 'fc8' biases: 2.890532e-02 [4.169925e-05] 
Train error last 800 batches: 0.654844
-------------------------------------------------------
Not saving because 0.465938 > 0.299667 (9.300: -1.18%)
======================================================= (2.368 sec)
35.361... logprob:  0.658587, 0.299479 (1.437 sec)
35.362... logprob:  0.647725, 0.289062 (1.481 sec)
35.363... logprob:  0.700959, 0.281250 (1.441 sec)
35.364... logprob:  0.702094, 0.317708 (1.444 sec)
35.365... logprob:  0.657642, 0.290365 (1.462 sec)
35.366... logprob:  0.583444, 0.242187 (1.442 sec)
35.367... logprob:  0.571866, 0.246094 (1.434 sec)
35.368... logprob:  0.709322, 0.308594 (1.425 sec)
35.369... logprob:  0.602104, 0.276042 (1.422 sec)
35.370... logprob:  0.599173, 0.276042 (1.438 sec)
35.371... logprob:  0.596769, 0.263021 (1.460 sec)
35.372... logprob:  0.698183, 0.319010 (1.451 sec)
35.373... logprob:  0.651482, 0.283854 (1.480 sec)
35.374... logprob:  0.746946, 0.295573 (1.448 sec)
35.375... logprob:  0.642503, 0.289062 (1.454 sec)
35.376... logprob:  0.659494, 0.299479 (1.432 sec)
35.377... logprob:  0.608751, 0.256510 (1.419 sec)
35.378... logprob:  0.678648, 0.287760 (1.425 sec)
35.379... logprob:  0.736808, 0.312500 (1.515 sec)
35.380... logprob:  0.721832, 0.337240 (1.434 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.469178, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.011006e-03 [1.005771e-07] 
Layer 'conv1' biases: 2.198545e-06 [1.923274e-11] 
Layer 'conv2' weights[0]: 2.006957e-03 [1.003868e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.351138e-10] 
Layer 'conv3' weights[0]: 2.006019e-03 [1.004574e-07] 
Layer 'conv3' biases: 3.657106e-05 [3.942385e-09] 
Layer 'conv4' weights[0]: 2.014519e-03 [1.008871e-07] 
Layer 'conv4' biases: 9.997838e-01 [1.532751e-07] 
Layer 'conv5' weights[0]: 2.197971e-03 [2.351500e-06] 
Layer 'conv5' biases: 9.988766e-01 [2.621695e-06] 
Layer 'fc6' weights[0]: 6.582990e-03 [5.921726e-08] 
Layer 'fc6' biases: 9.999887e-01 [5.686316e-08] 
Layer 'fc7' weights[0]: 6.922634e-03 [1.433836e-07] 
Layer 'fc7' biases: 9.996827e-01 [1.842346e-07] 
Layer 'fc8' weights[0]: 4.827061e-03 [1.176614e-05] 
Layer 'fc8' biases: 2.912559e-02 [1.851560e-05] 
Train error last 800 batches: 0.654408
-------------------------------------------------------
Not saving because 0.469178 > 0.299667 (9.300: -1.18%)
======================================================= (2.412 sec)
35.381... logprob:  0.717445, 0.302083 (1.468 sec)
35.382... logprob:  0.668563, 0.250000 (1.452 sec)
35.383... logprob:  0.647855, 0.278646 (1.439 sec)
35.384... logprob:  0.819791, 0.333333 (1.475 sec)
35.385... logprob:  0.737224, 0.316406 (1.424 sec)
35.386... logprob:  0.795957, 0.316406 (1.420 sec)
35.387... logprob:  0.663236, 0.308594 (1.434 sec)
35.388... logprob:  0.673236, 0.298177 (1.436 sec)
35.389... logprob:  0.698077, 0.309896 (1.426 sec)
35.390... logprob:  0.735355, 0.322917 (1.474 sec)
35.391... logprob:  0.543425, 0.248698 (1.441 sec)
35.392... logprob:  0.658523, 0.266927 (1.427 sec)
35.393... logprob:  0.579635, 0.270833 (1.478 sec)
35.394... logprob:  0.620640, 0.240885 (1.426 sec)
35.395... logprob:  0.646988, 0.281250 (1.425 sec)
35.396... logprob:  0.510694, 0.230469 (1.430 sec)
35.397... logprob:  0.703241, 0.295573 (1.427 sec)
35.398... logprob:  0.644928, 0.278646 (1.426 sec)
35.399... logprob:  0.581810, 0.255208 (1.477 sec)
35.400... logprob:  0.736084, 0.343750 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.493535, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.009005e-03 [1.005191e-07] 
Layer 'conv1' biases: 2.198750e-06 [1.837662e-11] 
Layer 'conv2' weights[0]: 2.004945e-03 [1.003112e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.746214e-10] 
Layer 'conv3' weights[0]: 2.004004e-03 [1.003261e-07] 
Layer 'conv3' biases: 3.660461e-05 [3.315122e-09] 
Layer 'conv4' weights[0]: 2.012516e-03 [1.008640e-07] 
Layer 'conv4' biases: 9.997812e-01 [1.502737e-07] 
Layer 'conv5' weights[0]: 2.194133e-03 [2.945415e-06] 
Layer 'conv5' biases: 9.989084e-01 [3.244107e-06] 
Layer 'fc6' weights[0]: 6.582348e-03 [6.269360e-08] 
Layer 'fc6' biases: 9.999889e-01 [6.045448e-08] 
Layer 'fc7' weights[0]: 6.921941e-03 [1.513863e-07] 
Layer 'fc7' biases: 9.996807e-01 [2.223253e-07] 
Layer 'fc8' weights[0]: 4.774116e-03 [1.308052e-05] 
Layer 'fc8' biases: 2.867952e-02 [3.392772e-05] 
Train error last 800 batches: 0.654549
-------------------------------------------------------
Not saving because 0.493535 > 0.299667 (9.300: -1.18%)
======================================================= (2.356 sec)
35.401... logprob:  0.625221, 0.285156 (1.444 sec)
35.402... logprob:  0.724506, 0.291667 (1.489 sec)
35.403... logprob:  0.652689, 0.311198 (1.430 sec)
35.404... logprob:  0.658480, 0.261719 (1.428 sec)
35.405... logprob:  0.736876, 0.356771 (1.430 sec)
35.406... logprob:  0.592582, 0.272135 (1.424 sec)
35.407... logprob:  0.654666, 0.278646 (1.421 sec)
35.408... logprob:  0.571272, 0.265625 (1.480 sec)
35.409... logprob:  0.624488, 0.269531 (1.432 sec)
35.410... logprob:  0.806057, 0.343750 (1.443 sec)
35.411... logprob:  0.660581, 0.276042 (1.498 sec)
35.412... logprob:  0.732452, 0.326823 (1.434 sec)
35.413... logprob:  0.759299, 0.298177 (1.436 sec)
35.414... logprob:  0.756544, 0.322917 (1.434 sec)
35.415... logprob:  0.618054, 0.265625 (1.418 sec)
35.416... logprob:  0.730185, 0.321615 (1.433 sec)
35.417... logprob:  0.594091, 0.260417 (1.464 sec)
35.418... logprob:  0.586373, 0.261719 (1.445 sec)
35.419... logprob:  0.588537, 0.274740 (1.444 sec)
35.420... logprob:  0.701497, 0.282552 (1.447 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.574357, 0.171875 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.006994e-03 [1.003747e-07] 
Layer 'conv1' biases: 2.198856e-06 [1.814807e-11] 
Layer 'conv2' weights[0]: 2.002940e-03 [1.001880e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.856032e-10] 
Layer 'conv3' weights[0]: 2.001992e-03 [1.002128e-07] 
Layer 'conv3' biases: 3.659569e-05 [3.342073e-09] 
Layer 'conv4' weights[0]: 2.010494e-03 [1.006967e-07] 
Layer 'conv4' biases: 9.997813e-01 [1.148034e-07] 
Layer 'conv5' weights[0]: 2.192776e-03 [2.427643e-06] 
Layer 'conv5' biases: 9.988899e-01 [2.593769e-06] 
Layer 'fc6' weights[0]: 6.581656e-03 [6.175834e-08] 
Layer 'fc6' biases: 9.999889e-01 [6.003318e-08] 
Layer 'fc7' weights[0]: 6.921289e-03 [1.477714e-07] 
Layer 'fc7' biases: 9.996817e-01 [2.019042e-07] 
Layer 'fc8' weights[0]: 4.808549e-03 [1.329153e-05] 
Layer 'fc8' biases: 2.899646e-02 [2.831812e-05] 
Train error last 800 batches: 0.654867
-------------------------------------------------------
Not saving because 0.574357 > 0.299667 (9.300: -1.18%)
======================================================= (2.355 sec)
35.421... logprob:  0.630484, 0.302083 (1.459 sec)
35.422... logprob:  0.717668, 0.294271 (1.439 sec)
35.423... logprob:  0.790376, 0.347656 (1.429 sec)
35.424... logprob:  0.616326, 0.283854 (1.429 sec)
35.425... logprob:  0.568160, 0.247396 (1.434 sec)
35.426... logprob:  0.562734, 0.253906 (1.448 sec)
35.427... logprob:  0.711126, 0.330729 (1.463 sec)
35.428... logprob:  0.741182, 0.315104 (1.446 sec)
35.429... logprob:  0.636200, 0.257812 (1.436 sec)
35.430... logprob:  0.521073, 0.240885 (1.469 sec)
35.431... logprob:  0.798740, 0.343750 (1.428 sec)
35.432... logprob:  0.619284, 0.287760 (1.422 sec)
35.433... logprob:  0.632852, 0.278646 (1.432 sec)
35.434... logprob:  0.767279, 0.303385 (1.431 sec)
35.435... logprob:  0.781851, 0.338542 (1.428 sec)
35.436... logprob:  0.555368, 0.236979 (1.467 sec)
35.437... logprob:  0.725193, 0.317708 (1.440 sec)
35.438... logprob:  0.719114, 0.324219 (1.425 sec)
35.439... logprob:  0.636237, 0.296875 (1.483 sec)
35.440... logprob:  0.674320, 0.283854 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.477722, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.004979e-03 [1.002685e-07] 
Layer 'conv1' biases: 2.198923e-06 [2.065247e-11] 
Layer 'conv2' weights[0]: 2.000933e-03 [1.000878e-07] 
Layer 'conv2' biases: 9.999996e-01 [2.679315e-10] 
Layer 'conv3' weights[0]: 2.000003e-03 [1.001253e-07] 
Layer 'conv3' biases: 3.660044e-05 [3.477499e-09] 
Layer 'conv4' weights[0]: 2.008482e-03 [1.005944e-07] 
Layer 'conv4' biases: 9.997804e-01 [1.510208e-07] 
Layer 'conv5' weights[0]: 2.190208e-03 [2.390284e-06] 
Layer 'conv5' biases: 9.988934e-01 [2.650433e-06] 
Layer 'fc6' weights[0]: 6.580973e-03 [6.160654e-08] 
Layer 'fc6' biases: 9.999890e-01 [5.994748e-08] 
Layer 'fc7' weights[0]: 6.920605e-03 [1.478266e-07] 
Layer 'fc7' biases: 9.996817e-01 [2.013089e-07] 
Layer 'fc8' weights[0]: 4.806311e-03 [1.268017e-05] 
Layer 'fc8' biases: 2.900469e-02 [2.894966e-05] 
Train error last 800 batches: 0.655141
-------------------------------------------------------
Not saving because 0.477722 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
35.441... logprob:  0.616995, 0.270833 (1.427 sec)
35.442... logprob:  0.632358, 0.278646 (1.440 sec)
35.443... logprob:  0.655901, 0.269531 (1.432 sec)
35.444... logprob:  0.603053, 0.266927 (1.430 sec)
35.445... logprob:  0.573145, 0.263021 (1.479 sec)
35.446... logprob:  0.656737, 0.299479 (1.432 sec)
35.447... logprob:  0.808156, 0.350260 (1.434 sec)
35.448... logprob:  0.610203, 0.257812 (1.474 sec)
35.449... logprob:  0.620911, 0.259115 (1.442 sec)
35.450... logprob:  0.498087, 0.220052 (1.427 sec)
35.451... logprob:  0.619790, 0.266927 (1.432 sec)
35.452... logprob:  0.694127, 0.315104 (1.428 sec)
35.453... logprob:  0.641424, 0.282552 (1.426 sec)
35.454... logprob:  0.669691, 0.299479 (1.481 sec)
35.455... logprob:  0.650357, 0.253906 (1.428 sec)
35.456... logprob:  0.700380, 0.300781 (1.442 sec)
35.457... logprob:  0.676002, 0.292969 (1.465 sec)
35.458... logprob:  0.581541, 0.248698 (1.429 sec)
35.459... logprob:  0.690910, 0.279948 (1.429 sec)
35.460... logprob:  0.547625, 0.273437 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.485796, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.002980e-03 [1.002002e-07] 
Layer 'conv1' biases: 2.199096e-06 [2.059340e-11] 
Layer 'conv2' weights[0]: 1.998948e-03 [1.000093e-07] 
Layer 'conv2' biases: 9.999996e-01 [3.147727e-10] 
Layer 'conv3' weights[0]: 1.997988e-03 [1.000824e-07] 
Layer 'conv3' biases: 3.660373e-05 [4.047762e-09] 
Layer 'conv4' weights[0]: 2.006476e-03 [1.006082e-07] 
Layer 'conv4' biases: 9.997812e-01 [1.501445e-07] 
Layer 'conv5' weights[0]: 2.189299e-03 [2.296525e-06] 
Layer 'conv5' biases: 9.988846e-01 [2.562521e-06] 
Layer 'fc6' weights[0]: 6.580339e-03 [5.831276e-08] 
Layer 'fc6' biases: 9.999890e-01 [5.542563e-08] 
Layer 'fc7' weights[0]: 6.919894e-03 [1.374446e-07] 
Layer 'fc7' biases: 9.996828e-01 [1.734423e-07] 
Layer 'fc8' weights[0]: 4.831674e-03 [1.071859e-05] 
Layer 'fc8' biases: 2.917308e-02 [1.748707e-05] 
Train error last 800 batches: 0.654807
-------------------------------------------------------
Not saving because 0.485796 > 0.299667 (9.300: -1.18%)
======================================================= (2.356 sec)
35.461... logprob:  0.636068, 0.279948 (1.430 sec)
35.462... logprob:  0.644172, 0.273437 (1.437 sec)
35.463... logprob:  0.685877, 0.269531 (1.473 sec)
35.464... logprob:  0.692772, 0.300781 (1.439 sec)
35.465... logprob:  0.670824, 0.295573 (1.447 sec)
35.466... logprob:  0.493132, 0.225260 (1.451 sec)
35.467... logprob:  0.675223, 0.304687 (1.444 sec)
35.468... logprob:  0.588711, 0.268229 (1.434 sec)
35.469... logprob:  0.609559, 0.263021 (1.421 sec)
35.470... logprob:  0.662454, 0.311198 (1.419 sec)
35.471... logprob:  0.864779, 0.348958 (1.432 sec)
35.472... logprob:  0.720595, 0.307292 (1.447 sec)
35.473... logprob:  0.615655, 0.272135 (1.454 sec)
35.474... logprob:  0.754571, 0.300781 (1.446 sec)
35.475... logprob:  0.732499, 0.321615 (1.434 sec)
35.476... logprob:  0.699921, 0.312500 (1.461 sec)
35.477... logprob:  0.524633, 0.247396 (1.430 sec)
35.478... logprob:  0.706369, 0.298177 (1.418 sec)
35.479... logprob:  0.554421, 0.256510 (1.424 sec)
35.480... logprob:  0.685589, 0.277344 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.489125, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 2.000985e-03 [1.000595e-07] 
Layer 'conv1' biases: 2.199224e-06 [2.336095e-11] 
Layer 'conv2' weights[0]: 1.996942e-03 [9.987931e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.357652e-10] 
Layer 'conv3' weights[0]: 1.995998e-03 [1.000059e-07] 
Layer 'conv3' biases: 3.660218e-05 [4.009996e-09] 
Layer 'conv4' weights[0]: 2.004475e-03 [1.004968e-07] 
Layer 'conv4' biases: 9.997818e-01 [1.537580e-07] 
Layer 'conv5' weights[0]: 2.187876e-03 [1.997349e-06] 
Layer 'conv5' biases: 9.988864e-01 [2.171809e-06] 
Layer 'fc6' weights[0]: 6.579689e-03 [5.906120e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.659991e-08] 
Layer 'fc7' weights[0]: 6.919211e-03 [1.372933e-07] 
Layer 'fc7' biases: 9.996831e-01 [1.643476e-07] 
Layer 'fc8' weights[0]: 4.833040e-03 [1.064760e-05] 
Layer 'fc8' biases: 2.918261e-02 [8.631416e-06] 
Train error last 800 batches: 0.655344
-------------------------------------------------------
Not saving because 0.489125 > 0.299667 (9.300: -1.18%)
======================================================= (2.369 sec)
35.481... logprob:  0.783118, 0.346354 (1.439 sec)
35.482... logprob:  0.575098, 0.235677 (1.471 sec)
35.483... logprob:  0.728886, 0.334635 (1.439 sec)
35.484... logprob:  0.670090, 0.292969 (1.432 sec)
35.485... logprob:  0.619942, 0.277344 (1.480 sec)
35.486... logprob:  0.668452, 0.283854 (1.435 sec)
35.487... logprob:  0.736938, 0.303385 (1.440 sec)
35.488... logprob:  0.631416, 0.261719 (1.434 sec)
35.489... logprob:  0.690208, 0.322917 (1.428 sec)
35.490... logprob:  0.644339, 0.286458 (1.524 sec)
35.491... logprob:  0.600943, 0.290365 (1.478 sec)
35.492... logprob:  0.616509, 0.261719 (1.432 sec)
35.493... logprob:  0.602330, 0.240885 (1.432 sec)
35.494... logprob:  0.663575, 0.292969 (1.484 sec)
35.495... logprob:  0.616783, 0.260417 (1.427 sec)
35.496... logprob:  0.670726, 0.308594 (1.431 sec)
35.497... logprob:  0.685672, 0.316406 (1.435 sec)
35.498... logprob:  0.732698, 0.324219 (1.424 sec)
35.499... logprob:  0.623768, 0.263021 (1.431 sec)
35.500... logprob:  0.636830, 0.278646 (1.482 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.509362, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.998976e-03 [9.998173e-08] 
Layer 'conv1' biases: 2.199351e-06 [1.624008e-11] 
Layer 'conv2' weights[0]: 1.994951e-03 [9.979196e-08] 
Layer 'conv2' biases: 9.999996e-01 [1.875528e-10] 
Layer 'conv3' weights[0]: 1.994023e-03 [9.980605e-08] 
Layer 'conv3' biases: 3.659596e-05 [2.966112e-09] 
Layer 'conv4' weights[0]: 2.002465e-03 [1.002967e-07] 
Layer 'conv4' biases: 9.997799e-01 [1.255254e-07] 
Layer 'conv5' weights[0]: 2.184512e-03 [1.929930e-06] 
Layer 'conv5' biases: 9.988966e-01 [2.036171e-06] 
Layer 'fc6' weights[0]: 6.579029e-03 [5.736173e-08] 
Layer 'fc6' biases: 9.999889e-01 [5.377980e-08] 
Layer 'fc7' weights[0]: 6.918490e-03 [1.353295e-07] 
Layer 'fc7' biases: 9.996821e-01 [1.621132e-07] 
Layer 'fc8' weights[0]: 4.814932e-03 [1.084999e-05] 
Layer 'fc8' biases: 2.905535e-02 [1.341435e-05] 
Train error last 800 batches: 0.655245
-------------------------------------------------------
Not saving because 0.509362 > 0.299667 (9.300: -1.18%)
======================================================= (2.419 sec)
35.501... logprob:  0.561008, 0.244792 (1.434 sec)
35.502... logprob:  0.619336, 0.268229 (1.446 sec)
35.503... logprob:  0.537498, 0.240885 (1.477 sec)
35.504... logprob:  0.676675, 0.304687 (1.427 sec)
35.505... logprob:  0.802810, 0.350260 (1.434 sec)
35.506... logprob:  0.681235, 0.294271 (1.435 sec)
35.507... logprob:  0.625588, 0.281250 (1.423 sec)
35.508... logprob:  0.623673, 0.253906 (1.432 sec)
35.509... logprob:  0.544715, 0.243490 (1.477 sec)
35.510... logprob:  0.641377, 0.273437 (1.433 sec)
35.511... logprob:  0.612158, 0.243490 (1.448 sec)
35.512... logprob:  0.678677, 0.260417 (1.455 sec)
35.513... logprob:  0.575219, 0.264323 (1.438 sec)
35.514... logprob:  0.657439, 0.272135 (1.433 sec)
35.515... logprob:  0.683066, 0.299479 (1.422 sec)
35.516... logprob:  0.617826, 0.273437 (1.422 sec)
35.517... logprob:  0.747988, 0.307292 (1.428 sec)
35.518... logprob:  0.661941, 0.291667 (1.457 sec)
35.519... logprob:  0.665620, 0.307292 (1.443 sec)
35.520... logprob:  0.670680, 0.311198 (1.451 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.501199, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.996977e-03 [9.987945e-08] 
Layer 'conv1' biases: 2.199424e-06 [2.047738e-11] 
Layer 'conv2' weights[0]: 1.992953e-03 [9.968259e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.213805e-10] 
Layer 'conv3' weights[0]: 1.992017e-03 [9.970601e-08] 
Layer 'conv3' biases: 3.659707e-05 [2.744560e-09] 
Layer 'conv4' weights[0]: 2.000469e-03 [1.001656e-07] 
Layer 'conv4' biases: 9.997802e-01 [1.155175e-07] 
Layer 'conv5' weights[0]: 2.182933e-03 [2.159363e-06] 
Layer 'conv5' biases: 9.988930e-01 [2.345772e-06] 
Layer 'fc6' weights[0]: 6.578355e-03 [5.725458e-08] 
Layer 'fc6' biases: 9.999891e-01 [5.383609e-08] 
Layer 'fc7' weights[0]: 6.917784e-03 [1.383929e-07] 
Layer 'fc7' biases: 9.996820e-01 [1.757848e-07] 
Layer 'fc8' weights[0]: 4.822460e-03 [1.139517e-05] 
Layer 'fc8' biases: 2.913309e-02 [1.762614e-05] 
Train error last 800 batches: 0.654919
-------------------------------------------------------
Not saving because 0.501199 > 0.299667 (9.300: -1.18%)
======================================================= (2.376 sec)
35.521... logprob:  0.590196, 0.244792 (1.452 sec)
35.522... logprob:  0.786392, 0.322917 (1.460 sec)
35.523... logprob:  0.536319, 0.221354 (1.433 sec)
35.524... logprob:  0.687309, 0.303385 (1.418 sec)
35.525... logprob:  0.678088, 0.289062 (1.452 sec)
35.526... logprob:  0.582569, 0.272135 (1.438 sec)
35.527... logprob:  0.675112, 0.302083 (1.431 sec)
35.528... logprob:  0.593382, 0.273437 (1.465 sec)
35.529... logprob:  0.571268, 0.248698 (1.445 sec)
35.530... logprob:  0.731368, 0.321615 (1.431 sec)
35.531... logprob:  0.666655, 0.298177 (1.475 sec)
35.532... logprob:  0.762276, 0.311198 (1.426 sec)
35.533... logprob:  0.659919, 0.298177 (1.420 sec)
35.534... logprob:  0.580490, 0.246094 (1.429 sec)
35.535... logprob:  0.757523, 0.351562 (1.425 sec)
35.536... logprob:  0.679313, 0.291667 (1.428 sec)
35.537... logprob:  0.713352, 0.324219 (1.476 sec)
35.538... logprob:  0.709339, 0.299479 (1.442 sec)
35.539... logprob:  0.539507, 0.246094 (1.428 sec)
35.540... logprob:  0.677966, 0.272135 (1.490 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.418500, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.994990e-03 [9.977435e-08] 
Layer 'conv1' biases: 2.199654e-06 [2.119758e-11] 
Layer 'conv2' weights[0]: 1.990960e-03 [9.958495e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.168831e-10] 
Layer 'conv3' weights[0]: 1.990005e-03 [9.964202e-08] 
Layer 'conv3' biases: 3.660674e-05 [3.447903e-09] 
Layer 'conv4' weights[0]: 1.998462e-03 [1.001105e-07] 
Layer 'conv4' biases: 9.997790e-01 [1.437793e-07] 
Layer 'conv5' weights[0]: 2.179805e-03 [2.293750e-06] 
Layer 'conv5' biases: 9.989041e-01 [2.521202e-06] 
Layer 'fc6' weights[0]: 6.577661e-03 [5.868184e-08] 
Layer 'fc6' biases: 9.999891e-01 [5.566683e-08] 
Layer 'fc7' weights[0]: 6.917097e-03 [1.414748e-07] 
Layer 'fc7' biases: 9.996812e-01 [1.812919e-07] 
Layer 'fc8' weights[0]: 4.803682e-03 [1.153907e-05] 
Layer 'fc8' biases: 2.903726e-02 [1.606102e-05] 
Train error last 800 batches: 0.654745
-------------------------------------------------------
Not saving because 0.418500 > 0.299667 (9.300: -1.18%)
======================================================= (2.353 sec)
35.541... logprob:  0.625872, 0.261719 (1.433 sec)
35.542... logprob:  0.677527, 0.266927 (1.433 sec)
35.543... logprob:  0.508226, 0.226562 (1.433 sec)
35.544... logprob:  0.586741, 0.256510 (1.425 sec)
35.545... logprob:  0.633275, 0.316406 (1.428 sec)
35.546... logprob:  0.529705, 0.239583 (1.481 sec)
35.547... logprob:  0.647399, 0.265625 (1.432 sec)
35.548... logprob:  0.670397, 0.300781 (1.438 sec)
35.549... logprob:  0.709718, 0.326823 (1.475 sec)
35.550... logprob:  0.662062, 0.300781 (1.431 sec)
35.551... logprob:  0.647393, 0.272135 (1.431 sec)
35.552... logprob:  0.637702, 0.291667 (1.424 sec)
35.553... logprob:  0.582823, 0.255208 (1.426 sec)
35.554... logprob:  0.679115, 0.266927 (1.424 sec)
35.555... logprob:  0.652785, 0.287760 (1.474 sec)
35.556... logprob:  0.543209, 0.248698 (1.433 sec)
35.557... logprob:  0.603686, 0.264323 (1.442 sec)
35.558... logprob:  0.639873, 0.295573 (1.465 sec)
35.559... logprob:  0.627670, 0.281250 (1.430 sec)
35.560... logprob:  0.615908, 0.265625 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.432077, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.992994e-03 [9.972240e-08] 
Layer 'conv1' biases: 2.199841e-06 [2.881584e-11] 
Layer 'conv2' weights[0]: 1.988967e-03 [9.950979e-08] 
Layer 'conv2' biases: 9.999996e-01 [4.647759e-10] 
Layer 'conv3' weights[0]: 1.988021e-03 [9.966298e-08] 
Layer 'conv3' biases: 3.658201e-05 [5.515307e-09] 
Layer 'conv4' weights[0]: 1.996461e-03 [1.003030e-07] 
Layer 'conv4' biases: 9.997811e-01 [2.383826e-07] 
Layer 'conv5' weights[0]: 2.180432e-03 [3.010656e-06] 
Layer 'conv5' biases: 9.988658e-01 [3.401611e-06] 
Layer 'fc6' weights[0]: 6.576991e-03 [6.274684e-08] 
Layer 'fc6' biases: 9.999891e-01 [6.189153e-08] 
Layer 'fc7' weights[0]: 6.916415e-03 [1.546590e-07] 
Layer 'fc7' biases: 9.996842e-01 [2.376889e-07] 
Layer 'fc8' weights[0]: 4.874353e-03 [1.531547e-05] 
Layer 'fc8' biases: 2.962390e-02 [4.771834e-05] 
Train error last 800 batches: 0.654797
-------------------------------------------------------
Not saving because 0.432077 > 0.299667 (9.300: -1.18%)
======================================================= (2.407 sec)
35.561... logprob:  0.701889, 0.312500 (1.438 sec)
35.562... logprob:  0.663547, 0.290364 (1.425 sec)
35.563... logprob:  0.561185, 0.285156 (1.465 sec)
35.564... logprob:  0.641570, 0.304688 (1.457 sec)
35.565... logprob:  0.755897, 0.343750 (1.444 sec)
35.566... logprob:  0.627744, 0.299479 (1.448 sec)
35.567... logprob:  0.663874, 0.291666 (1.464 sec)
35.568... logprob:  0.744339, 0.296875 (1.450 sec)
35.569... logprob:  0.840100, 0.332031 (1.432 sec)
35.570... logprob:  0.798613, 0.345052 (1.420 sec)
35.571... logprob:  0.697234, 0.315104 (1.420 sec)
35.572... logprob:  0.610874, 0.265625 (1.434 sec)
35.573... logprob:  0.661251, 0.257812 (1.439 sec)
35.574... logprob:  0.683371, 0.316406 (1.456 sec)
35.575... logprob:  0.607753, 0.290364 (1.449 sec)
35.576... logprob:  0.721891, 0.339844 (1.451 sec)
35.577... logprob:  0.708132, 0.311198 (1.469 sec)
35.578... logprob:  0.584290, 0.264323 (1.428 sec)
35.579... logprob:  0.711777, 0.285156 (1.418 sec)
35.580... logprob:  0.748984, 0.315104 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.467282, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.990996e-03 [9.957610e-08] 
Layer 'conv1' biases: 2.199968e-06 [2.208930e-11] 
Layer 'conv2' weights[0]: 1.986982e-03 [9.937804e-08] 
Layer 'conv2' biases: 9.999996e-01 [4.205800e-10] 
Layer 'conv3' weights[0]: 1.986059e-03 [9.952066e-08] 
Layer 'conv3' biases: 3.660991e-05 [4.674421e-09] 
Layer 'conv4' weights[0]: 1.994467e-03 [1.000044e-07] 
Layer 'conv4' biases: 9.997799e-01 [1.842968e-07] 
Layer 'conv5' weights[0]: 2.178447e-03 [3.534664e-06] 
Layer 'conv5' biases: 9.989063e-01 [4.052040e-06] 
Layer 'fc6' weights[0]: 6.576336e-03 [6.691011e-08] 
Layer 'fc6' biases: 9.999891e-01 [6.704821e-08] 
Layer 'fc7' weights[0]: 6.915678e-03 [1.643194e-07] 
Layer 'fc7' biases: 9.996809e-01 [2.587576e-07] 
Layer 'fc8' weights[0]: 4.800264e-03 [1.392736e-05] 
Layer 'fc8' biases: 2.901251e-02 [3.732769e-05] 
Train error last 800 batches: 0.654945
-------------------------------------------------------
Not saving because 0.467282 > 0.299667 (9.300: -1.18%)
======================================================= (2.352 sec)
35.581... logprob:  0.701824, 0.302083 (1.442 sec)
35.582... logprob:  0.720577, 0.325521 (1.429 sec)
35.583... logprob:  0.699911, 0.285156 (1.473 sec)
35.584... logprob:  0.660668, 0.302083 (1.444 sec)
35.585... logprob:  0.608947, 0.255208 (1.431 sec)
35.586... logprob:  0.546615, 0.247396 (1.479 sec)
35.587... logprob:  0.628281, 0.286458 (1.427 sec)
35.588... logprob:  0.610480, 0.282552 (1.423 sec)
35.589... logprob:  0.622338, 0.279948 (1.432 sec)
35.590... logprob:  0.672035, 0.282552 (1.430 sec)
35.591... logprob:  0.621943, 0.285156 (1.431 sec)
35.592... logprob:  0.696045, 0.305990 (1.484 sec)
35.593... logprob:  0.708191, 0.298177 (1.428 sec)
35.594... logprob:  0.600667, 0.236979 (1.436 sec)
35.595... logprob:  0.603587, 0.274739 (1.490 sec)
35.596... logprob:  0.722427, 0.309896 (1.424 sec)
35.597... logprob:  0.638890, 0.270833 (1.428 sec)
35.598... logprob:  0.598165, 0.273437 (1.426 sec)
35.599... logprob:  0.521906, 0.212240 (1.422 sec)
35.600... logprob:  0.566923, 0.251302 (1.430 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.565147, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.989009e-03 [9.951214e-08] 
Layer 'conv1' biases: 2.199971e-06 [2.796079e-11] 
Layer 'conv2' weights[0]: 1.984977e-03 [9.931415e-08] 
Layer 'conv2' biases: 9.999996e-01 [4.153654e-10] 
Layer 'conv3' weights[0]: 1.984050e-03 [9.944359e-08] 
Layer 'conv3' biases: 3.659149e-05 [5.185336e-09] 
Layer 'conv4' weights[0]: 1.992473e-03 [1.000133e-07] 
Layer 'conv4' biases: 9.997807e-01 [1.933945e-07] 
Layer 'conv5' weights[0]: 2.177537e-03 [3.238144e-06] 
Layer 'conv5' biases: 9.988933e-01 [3.541604e-06] 
Layer 'fc6' weights[0]: 6.575702e-03 [7.083714e-08] 
Layer 'fc6' biases: 9.999890e-01 [7.179476e-08] 
Layer 'fc7' weights[0]: 6.914995e-03 [1.798651e-07] 
Layer 'fc7' biases: 9.996828e-01 [3.132673e-07] 
Layer 'fc8' weights[0]: 4.841372e-03 [1.760593e-05] 
Layer 'fc8' biases: 2.939129e-02 [5.823772e-05] 
Train error last 800 batches: 0.654862
-------------------------------------------------------
Not saving because 0.565147 > 0.299667 (9.300: -1.18%)
======================================================= (2.352 sec)
35.601... logprob:  0.553391, 0.229167 (1.503 sec)
35.602... logprob:  0.562645, 0.269531 (1.431 sec)
35.603... logprob:  0.513365, 0.252604 (1.447 sec)
35.604... logprob:  0.597925, 0.264323 (1.467 sec)
35.605... logprob:  0.682726, 0.295573 (1.430 sec)
35.606... logprob:  0.577689, 0.248698 (1.438 sec)
35.607... logprob:  0.677376, 0.308594 (1.426 sec)
35.608... logprob:  0.556670, 0.257812 (1.417 sec)
35.609... logprob:  0.577013, 0.250000 (1.430 sec)
35.610... logprob:  0.722792, 0.325521 (1.468 sec)
35.611... logprob:  0.735922, 0.337240 (1.438 sec)
35.612... logprob:  0.685700, 0.304687 (1.445 sec)
35.613... logprob:  0.556223, 0.269531 (1.451 sec)
35.614... logprob:  0.669118, 0.286458 (1.447 sec)
35.615... logprob:  0.630524, 0.289062 (1.434 sec)
35.616... logprob:  0.636678, 0.289062 (1.429 sec)
35.617... logprob:  0.683518, 0.272135 (1.418 sec)
35.618... logprob:  0.691238, 0.305990 (1.432 sec)
35.619... logprob:  0.646259, 0.300781 (1.443 sec)
35.620... logprob:  0.750086, 0.317708 (1.457 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.506377, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.987016e-03 [9.933608e-08] 
Layer 'conv1' biases: 2.199969e-06 [3.767394e-11] 
Layer 'conv2' weights[0]: 1.983011e-03 [9.916875e-08] 
Layer 'conv2' biases: 9.999996e-01 [6.205077e-10] 
Layer 'conv3' weights[0]: 1.982075e-03 [9.960885e-08] 
Layer 'conv3' biases: 3.658413e-05 [8.029681e-09] 
Layer 'conv4' weights[0]: 1.990486e-03 [1.002872e-07] 
Layer 'conv4' biases: 9.997810e-01 [3.234862e-07] 
Layer 'conv5' weights[0]: 2.176581e-03 [4.402886e-06] 
Layer 'conv5' biases: 9.988635e-01 [4.828334e-06] 
Layer 'fc6' weights[0]: 6.575044e-03 [7.492180e-08] 
Layer 'fc6' biases: 9.999888e-01 [7.871586e-08] 
Layer 'fc7' weights[0]: 6.914298e-03 [1.837936e-07] 
Layer 'fc7' biases: 9.996846e-01 [3.193626e-07] 
Layer 'fc8' weights[0]: 4.904386e-03 [1.594806e-05] 
Layer 'fc8' biases: 3.001463e-02 [4.493323e-05] 
Train error last 800 batches: 0.654395
-------------------------------------------------------
Not saving because 0.506377 > 0.299667 (9.300: -1.18%)
======================================================= (2.338 sec)
35.621... logprob:  0.605404, 0.252604 (1.450 sec)
35.622... logprob:  0.616301, 0.287760 (1.447 sec)
35.623... logprob:  0.654076, 0.279948 (1.462 sec)
35.624... logprob:  0.589999, 0.247396 (1.431 sec)
35.625... logprob:  0.657327, 0.274740 (1.420 sec)
35.626... logprob:  0.673472, 0.303385 (1.432 sec)
35.627... logprob:  0.675428, 0.298177 (1.428 sec)
35.628... logprob:  0.715907, 0.316406 (1.431 sec)
35.629... logprob:  0.669171, 0.283854 (1.468 sec)
35.630... logprob:  0.639082, 0.282552 (1.442 sec)
35.631... logprob:  0.812629, 0.332031 (1.430 sec)
35.632... logprob:  0.668318, 0.291667 (1.474 sec)
35.633... logprob:  0.546870, 0.223958 (1.430 sec)
35.634... logprob:  0.803288, 0.371094 (1.419 sec)
35.635... logprob:  0.612831, 0.292969 (1.432 sec)
35.636... logprob:  0.727773, 0.313802 (1.425 sec)
35.637... logprob:  0.662249, 0.299479 (1.425 sec)
35.638... logprob:  0.735640, 0.317708 (1.477 sec)
35.639... logprob:  0.601516, 0.251302 (1.434 sec)
35.640... logprob:  0.741812, 0.298177 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.464910, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.985037e-03 [9.924676e-08] 
Layer 'conv1' biases: 2.200026e-06 [2.426700e-11] 
Layer 'conv2' weights[0]: 1.981015e-03 [9.906985e-08] 
Layer 'conv2' biases: 9.999996e-01 [4.183042e-10] 
Layer 'conv3' weights[0]: 1.980089e-03 [9.919034e-08] 
Layer 'conv3' biases: 3.662286e-05 [4.272877e-09] 
Layer 'conv4' weights[0]: 1.988493e-03 [9.967622e-08] 
Layer 'conv4' biases: 9.997772e-01 [1.735768e-07] 
Layer 'conv5' weights[0]: 2.171855e-03 [3.527553e-06] 
Layer 'conv5' biases: 9.989263e-01 [3.826168e-06] 
Layer 'fc6' weights[0]: 6.574359e-03 [6.753426e-08] 
Layer 'fc6' biases: 9.999890e-01 [6.719512e-08] 
Layer 'fc7' weights[0]: 6.913608e-03 [1.686521e-07] 
Layer 'fc7' biases: 9.996799e-01 [2.698351e-07] 
Layer 'fc8' weights[0]: 4.791864e-03 [1.456335e-05] 
Layer 'fc8' biases: 2.919398e-02 [4.200104e-05] 
Train error last 800 batches: 0.654575
-------------------------------------------------------
Not saving because 0.464910 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
35.641... logprob:  0.667204, 0.272135 (1.481 sec)
35.642... logprob:  0.588273, 0.229167 (1.428 sec)
35.643... logprob:  0.766027, 0.351562 (1.435 sec)
35.644... logprob:  0.646152, 0.300781 (1.434 sec)
35.645... logprob:  0.643796, 0.279948 (1.424 sec)
35.646... logprob:  0.650388, 0.273437 (1.426 sec)
35.647... logprob:  0.644994, 0.263021 (1.481 sec)
35.648... logprob:  0.584023, 0.255208 (1.435 sec)
35.649... logprob:  0.486309, 0.216146 (1.438 sec)
35.650... logprob:  0.684226, 0.299479 (1.469 sec)
35.651... logprob:  0.657555, 0.270833 (1.428 sec)
35.652... logprob:  0.665037, 0.261719 (1.430 sec)
35.653... logprob:  0.766621, 0.355469 (1.426 sec)
35.654... logprob:  0.690317, 0.305990 (1.423 sec)
35.655... logprob:  0.679864, 0.298177 (1.426 sec)
35.656... logprob:  0.692016, 0.312500 (1.470 sec)
35.657... logprob:  0.661595, 0.308594 (1.438 sec)
35.658... logprob:  0.578401, 0.269531 (1.442 sec)
35.659... logprob:  0.653021, 0.302083 (1.460 sec)
35.660... logprob:  0.645362, 0.292969 (1.438 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.450046, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.983047e-03 [9.919668e-08] 
Layer 'conv1' biases: 2.200272e-06 [2.721248e-11] 
Layer 'conv2' weights[0]: 1.979038e-03 [9.900460e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.735129e-10] 
Layer 'conv3' weights[0]: 1.978112e-03 [9.912158e-08] 
Layer 'conv3' biases: 3.662876e-05 [4.827817e-09] 
Layer 'conv4' weights[0]: 1.986507e-03 [9.968135e-08] 
Layer 'conv4' biases: 9.997772e-01 [1.808844e-07] 
Layer 'conv5' weights[0]: 2.170342e-03 [2.798434e-06] 
Layer 'conv5' biases: 9.989200e-01 [3.110124e-06] 
Layer 'fc6' weights[0]: 6.573669e-03 [6.182863e-08] 
Layer 'fc6' biases: 9.999888e-01 [5.898002e-08] 
Layer 'fc7' weights[0]: 6.912882e-03 [1.486693e-07] 
Layer 'fc7' biases: 9.996803e-01 [2.142334e-07] 
Layer 'fc8' weights[0]: 4.804125e-03 [1.327258e-05] 
Layer 'fc8' biases: 2.926119e-02 [3.784864e-05] 
Train error last 800 batches: 0.654347
-------------------------------------------------------
Not saving because 0.450046 > 0.299667 (9.300: -1.18%)
======================================================= (2.357 sec)
35.661... logprob:  0.645868, 0.278646 (1.442 sec)
35.662... logprob:  0.676077, 0.283854 (1.432 sec)
35.663... logprob:  0.584275, 0.244792 (1.426 sec)
35.664... logprob:  0.547339, 0.244792 (1.431 sec)
35.665... logprob:  0.523623, 0.234375 (1.461 sec)
35.666... logprob:  0.633759, 0.300781 (1.445 sec)
35.667... logprob:  0.688950, 0.302083 (1.451 sec)
35.668... logprob:  0.662527, 0.317708 (1.442 sec)
35.669... logprob:  0.611852, 0.279948 (1.458 sec)
35.670... logprob:  0.626887, 0.307292 (1.430 sec)
35.671... logprob:  0.601402, 0.259115 (1.421 sec)
35.672... logprob:  0.618680, 0.272135 (1.435 sec)
35.673... logprob:  0.673369, 0.309896 (1.435 sec)
35.674... logprob:  0.689074, 0.317708 (1.438 sec)
35.675... logprob:  0.623653, 0.287760 (1.458 sec)
35.676... logprob:  0.729588, 0.315104 (1.446 sec)
35.677... logprob:  0.726212, 0.337240 (1.433 sec)
35.678... logprob:  0.668938, 0.307292 (1.475 sec)
35.679... logprob:  0.751641, 0.337240 (1.440 sec)
35.680... logprob:  0.596710, 0.260417 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.462884, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.981064e-03 [9.905175e-08] 
Layer 'conv1' biases: 2.200473e-06 [1.707527e-11] 
Layer 'conv2' weights[0]: 1.977060e-03 [9.888447e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.151010e-10] 
Layer 'conv3' weights[0]: 1.976140e-03 [9.893952e-08] 
Layer 'conv3' biases: 3.660210e-05 [3.603509e-09] 
Layer 'conv4' weights[0]: 1.984531e-03 [9.935376e-08] 
Layer 'conv4' biases: 9.997784e-01 [1.121246e-07] 
Layer 'conv5' weights[0]: 2.170465e-03 [2.273897e-06] 
Layer 'conv5' biases: 9.988794e-01 [2.450444e-06] 
Layer 'fc6' weights[0]: 6.573007e-03 [5.833552e-08] 
Layer 'fc6' biases: 9.999888e-01 [5.545648e-08] 
Layer 'fc7' weights[0]: 6.912163e-03 [1.380754e-07] 
Layer 'fc7' biases: 9.996830e-01 [1.726365e-07] 
Layer 'fc8' weights[0]: 4.878132e-03 [1.079123e-05] 
Layer 'fc8' biases: 2.979385e-02 [1.601774e-05] 
Train error last 800 batches: 0.654624
-------------------------------------------------------
Not saving because 0.462884 > 0.299667 (9.300: -1.18%)
======================================================= (2.413 sec)
35.681... logprob:  0.583928, 0.234375 (1.440 sec)
35.682... logprob:  0.580555, 0.265625 (1.438 sec)
35.683... logprob:  0.515574, 0.244792 (1.434 sec)
35.684... logprob:  0.549440, 0.227865 (1.470 sec)
35.685... logprob:  0.536239, 0.263021 (1.439 sec)
35.686... logprob:  0.581380, 0.264323 (1.432 sec)
35.687... logprob:  0.548962, 0.259115 (1.481 sec)
35.688... logprob:  0.572125, 0.277344 (1.427 sec)
35.689... logprob:  0.646826, 0.279948 (1.423 sec)
35.690... logprob:  0.835085, 0.356771 (1.429 sec)
35.691... logprob:  0.664916, 0.277344 (1.426 sec)
35.692... logprob:  0.700759, 0.312500 (1.423 sec)
35.693... logprob:  0.633178, 0.268229 (1.482 sec)
35.694... logprob:  0.533769, 0.261719 (1.424 sec)
35.695... logprob:  0.615035, 0.243490 (1.439 sec)
35.696... logprob:  0.710768, 0.317708 (1.472 sec)
35.697... logprob:  0.691441, 0.298177 (1.426 sec)
35.698... logprob:  0.761497, 0.348958 (1.432 sec)
35.699... logprob:  0.606504, 0.282552 (1.426 sec)
35.700... logprob:  0.650085, 0.305990 (1.425 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.381114, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.979083e-03 [9.899260e-08] 
Layer 'conv1' biases: 2.200520e-06 [3.302199e-11] 
Layer 'conv2' weights[0]: 1.975098e-03 [9.879413e-08] 
Layer 'conv2' biases: 9.999996e-01 [5.408201e-10] 
Layer 'conv3' weights[0]: 1.974166e-03 [9.910846e-08] 
Layer 'conv3' biases: 3.659591e-05 [6.236319e-09] 
Layer 'conv4' weights[0]: 1.982552e-03 [9.957071e-08] 
Layer 'conv4' biases: 9.997798e-01 [2.238494e-07] 
Layer 'conv5' weights[0]: 2.170244e-03 [2.837341e-06] 
Layer 'conv5' biases: 9.988714e-01 [3.060388e-06] 
Layer 'fc6' weights[0]: 6.572342e-03 [6.050728e-08] 
Layer 'fc6' biases: 9.999889e-01 [5.872104e-08] 
Layer 'fc7' weights[0]: 6.911488e-03 [1.456116e-07] 
Layer 'fc7' biases: 9.996829e-01 [2.141330e-07] 
Layer 'fc8' weights[0]: 4.883934e-03 [1.175247e-05] 
Layer 'fc8' biases: 2.988424e-02 [2.730750e-05] 
Train error last 800 batches: 0.654366
-------------------------------------------------------
Not saving because 0.381114 > 0.299667 (9.300: -1.18%)
======================================================= (2.359 sec)
35.701... logprob:  0.613118, 0.273437 (1.443 sec)
35.702... logprob:  0.664671, 0.294271 (1.486 sec)
35.703... logprob:  0.690927, 0.307292 (1.435 sec)
35.704... logprob:  0.597624, 0.229167 (1.443 sec)
35.705... logprob:  0.664660, 0.274740 (1.466 sec)
35.706... logprob:  0.717961, 0.291667 (1.431 sec)
35.707... logprob:  0.691624, 0.332031 (1.431 sec)
35.708... logprob:  0.638307, 0.268229 (1.426 sec)
35.709... logprob:  0.673252, 0.290365 (1.417 sec)
35.710... logprob:  0.720422, 0.308594 (1.441 sec)
35.711... logprob:  0.673023, 0.270833 (1.467 sec)
35.712... logprob:  0.613099, 0.252604 (1.441 sec)
35.713... logprob:  0.762593, 0.302083 (1.449 sec)
35.714... logprob:  0.674511, 0.281250 (1.450 sec)
35.715... logprob:  0.634275, 0.289062 (1.445 sec)
35.716... logprob:  0.612942, 0.296875 (1.435 sec)
35.717... logprob:  0.622520, 0.263021 (1.435 sec)
35.718... logprob:  0.728405, 0.317708 (1.421 sec)
35.719... logprob:  0.686202, 0.320313 (1.433 sec)
35.720... logprob:  0.668829, 0.290365 (1.442 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.517043, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.977110e-03 [9.885534e-08] 
Layer 'conv1' biases: 2.200577e-06 [2.526492e-11] 
Layer 'conv2' weights[0]: 1.973108e-03 [9.868003e-08] 
Layer 'conv2' biases: 9.999996e-01 [4.142898e-10] 
Layer 'conv3' weights[0]: 1.972192e-03 [9.886471e-08] 
Layer 'conv3' biases: 3.662656e-05 [5.192126e-09] 
Layer 'conv4' weights[0]: 1.980561e-03 [9.934178e-08] 
Layer 'conv4' biases: 9.997783e-01 [1.989316e-07] 
Layer 'conv5' weights[0]: 2.167490e-03 [2.925312e-06] 
Layer 'conv5' biases: 9.989269e-01 [3.158658e-06] 
Layer 'fc6' weights[0]: 6.571652e-03 [6.234924e-08] 
Layer 'fc6' biases: 9.999892e-01 [6.026174e-08] 
Layer 'fc7' weights[0]: 6.910845e-03 [1.501437e-07] 
Layer 'fc7' biases: 9.996791e-01 [2.144714e-07] 
Layer 'fc8' weights[0]: 4.775340e-03 [1.270060e-05] 
Layer 'fc8' biases: 2.902488e-02 [3.075308e-05] 
Train error last 800 batches: 0.654237
-------------------------------------------------------
Not saving because 0.517043 > 0.299667 (9.300: -1.18%)
======================================================= (2.362 sec)
35.721... logprob:  0.581860, 0.242188 (1.464 sec)
35.722... logprob:  0.791382, 0.326823 (1.451 sec)
35.723... logprob:  0.640058, 0.274740 (1.436 sec)
35.724... logprob:  0.676385, 0.285156 (1.469 sec)
35.725... logprob:  0.770711, 0.313802 (1.427 sec)
35.726... logprob:  0.574448, 0.260417 (1.422 sec)
35.727... logprob:  0.622393, 0.256510 (1.424 sec)
35.728... logprob:  0.661366, 0.302083 (1.435 sec)
35.729... logprob:  0.622349, 0.285156 (1.428 sec)
35.730... logprob:  0.776823, 0.319010 (1.467 sec)
35.731... logprob:  0.575937, 0.269531 (1.440 sec)
35.732... logprob:  0.532260, 0.248698 (1.430 sec)
35.733... logprob:  0.732067, 0.281250 (1.478 sec)
35.734... logprob:  0.599186, 0.282552 (1.425 sec)
35.735... logprob:  0.726368, 0.317708 (1.424 sec)
35.736... logprob:  0.668251, 0.287760 (1.431 sec)
35.737... logprob:  0.652267, 0.290364 (1.426 sec)
35.738... logprob:  0.623610, 0.291667 (1.434 sec)
35.739... logprob:  0.678987, 0.307292 (1.473 sec)
35.740... logprob:  0.548286, 0.240885 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.368694, 0.062500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.975127e-03 [9.881988e-08] 
Layer 'conv1' biases: 2.200776e-06 [2.666177e-11] 
Layer 'conv2' weights[0]: 1.971147e-03 [9.861697e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.913309e-10] 
Layer 'conv3' weights[0]: 1.970208e-03 [9.875316e-08] 
Layer 'conv3' biases: 3.662586e-05 [4.769639e-09] 
Layer 'conv4' weights[0]: 1.978578e-03 [9.931107e-08] 
Layer 'conv4' biases: 9.997782e-01 [1.794291e-07] 
Layer 'conv5' weights[0]: 2.166084e-03 [2.996293e-06] 
Layer 'conv5' biases: 9.989180e-01 [3.409076e-06] 
Layer 'fc6' weights[0]: 6.571023e-03 [6.355284e-08] 
Layer 'fc6' biases: 9.999890e-01 [6.127147e-08] 
Layer 'fc7' weights[0]: 6.910140e-03 [1.548836e-07] 
Layer 'fc7' biases: 9.996796e-01 [2.423934e-07] 
Layer 'fc8' weights[0]: 4.790654e-03 [1.379089e-05] 
Layer 'fc8' biases: 2.914021e-02 [3.999420e-05] 
Train error last 800 batches: 0.654162
-------------------------------------------------------
Not saving because 0.368694 > 0.299667 (9.300: -1.18%)
======================================================= (2.399 sec)
35.741... logprob:  0.637105, 0.303385 (1.439 sec)
35.742... logprob:  0.574063, 0.259115 (1.481 sec)
35.743... logprob:  0.610471, 0.246094 (1.426 sec)
35.744... logprob:  0.640143, 0.279948 (1.423 sec)
35.745... logprob:  0.682316, 0.302083 (1.436 sec)
35.746... logprob:  0.603882, 0.253906 (1.426 sec)
35.747... logprob:  0.667136, 0.304688 (1.429 sec)
35.748... logprob:  0.571341, 0.255208 (1.480 sec)
35.749... logprob:  0.708311, 0.285156 (1.423 sec)
35.750... logprob:  0.681952, 0.285156 (1.441 sec)
35.751... logprob:  0.459240, 0.190104 (1.476 sec)
35.752... logprob:  0.732954, 0.326823 (1.428 sec)
35.753... logprob:  0.722134, 0.316406 (1.434 sec)
35.754... logprob:  0.732084, 0.326823 (1.424 sec)
35.755... logprob:  0.790946, 0.337240 (1.447 sec)
35.756... logprob:  0.710320, 0.272135 (1.428 sec)
35.757... logprob:  0.749936, 0.333333 (1.467 sec)
35.758... logprob:  0.645991, 0.263021 (1.440 sec)
35.759... logprob:  0.620192, 0.276042 (1.453 sec)
35.760... logprob:  0.747036, 0.300781 (1.463 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.425423, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.973150e-03 [9.863619e-08] 
Layer 'conv1' biases: 2.200814e-06 [2.743871e-11] 
Layer 'conv2' weights[0]: 1.969166e-03 [9.846877e-08] 
Layer 'conv2' biases: 9.999996e-01 [4.615773e-10] 
Layer 'conv3' weights[0]: 1.968238e-03 [9.868859e-08] 
Layer 'conv3' biases: 3.661505e-05 [5.629592e-09] 
Layer 'conv4' weights[0]: 1.976608e-03 [9.919456e-08] 
Layer 'conv4' biases: 9.997791e-01 [2.235196e-07] 
Layer 'conv5' weights[0]: 2.165871e-03 [3.760876e-06] 
Layer 'conv5' biases: 9.989012e-01 [4.172886e-06] 
Layer 'fc6' weights[0]: 6.570330e-03 [7.120532e-08] 
Layer 'fc6' biases: 9.999890e-01 [7.236825e-08] 
Layer 'fc7' weights[0]: 6.909412e-03 [1.793135e-07] 
Layer 'fc7' biases: 9.996799e-01 [2.992722e-07] 
Layer 'fc8' weights[0]: 4.815901e-03 [1.610476e-05] 
Layer 'fc8' biases: 2.941890e-02 [4.457294e-05] 
Train error last 800 batches: 0.654098
-------------------------------------------------------
Not saving because 0.425423 > 0.299667 (9.300: -1.18%)
======================================================= (2.424 sec)
35.761... logprob:  0.673307, 0.294271 (1.449 sec)
35.762... logprob:  0.651488, 0.281250 (1.443 sec)
35.763... logprob:  0.761204, 0.341146 (1.419 sec)
35.764... logprob:  0.663238, 0.270833 (1.422 sec)
35.765... logprob:  0.579726, 0.274740 (1.427 sec)
35.766... logprob:  0.688801, 0.299479 (1.450 sec)
35.767... logprob:  0.611590, 0.281250 (1.452 sec)
35.768... logprob:  0.672209, 0.317708 (1.454 sec)
35.769... logprob:  0.697566, 0.308594 (1.462 sec)
35.770... logprob:  0.628634, 0.282552 (1.476 sec)
35.771... logprob:  0.760746, 0.322917 (1.452 sec)
35.772... logprob:  0.651294, 0.302083 (1.441 sec)
35.773... logprob:  0.715294, 0.347656 (1.444 sec)
35.774... logprob:  0.591121, 0.256510 (1.451 sec)
35.775... logprob:  0.630664, 0.273437 (1.458 sec)
35.776... logprob:  0.598248, 0.278646 (1.474 sec)
35.777... logprob:  0.652309, 0.295573 (1.463 sec)
35.778... logprob:  0.664990, 0.281250 (1.467 sec)
35.779... logprob:  0.704130, 0.291667 (1.483 sec)
35.780... logprob:  0.676203, 0.295573 (1.443 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.466418, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.971186e-03 [9.858502e-08] 
Layer 'conv1' biases: 2.200931e-06 [2.964024e-11] 
Layer 'conv2' weights[0]: 1.967193e-03 [9.840065e-08] 
Layer 'conv2' biases: 9.999996e-01 [4.808546e-10] 
Layer 'conv3' weights[0]: 1.966269e-03 [9.864266e-08] 
Layer 'conv3' biases: 3.661343e-05 [5.864634e-09] 
Layer 'conv4' weights[0]: 1.974614e-03 [9.927619e-08] 
Layer 'conv4' biases: 9.997787e-01 [2.456380e-07] 
Layer 'conv5' weights[0]: 2.163459e-03 [2.231818e-06] 
Layer 'conv5' biases: 9.989263e-01 [2.345744e-06] 
Layer 'fc6' weights[0]: 6.569658e-03 [5.756168e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.320675e-08] 
Layer 'fc7' weights[0]: 6.908689e-03 [1.369522e-07] 
Layer 'fc7' biases: 9.996781e-01 [1.685576e-07] 
Layer 'fc8' weights[0]: 4.768785e-03 [1.159024e-05] 
Layer 'fc8' biases: 2.912497e-02 [2.242189e-05] 
Train error last 800 batches: 0.654532
-------------------------------------------------------
Not saving because 0.466418 > 0.299667 (9.300: -1.18%)
======================================================= (2.370 sec)
35.781... logprob:  0.580753, 0.252604 (1.450 sec)
35.782... logprob:  0.666666, 0.317708 (1.452 sec)
35.783... logprob:  0.762007, 0.299479 (1.458 sec)
35.784... logprob:  0.612821, 0.252604 (1.451 sec)
35.785... logprob:  0.670772, 0.303385 (1.477 sec)
35.786... logprob:  0.666973, 0.279948 (1.467 sec)
35.787... logprob:  0.696835, 0.303385 (1.450 sec)
35.788... logprob:  0.711555, 0.292969 (1.491 sec)
35.789... logprob:  0.524488, 0.240885 (1.445 sec)
35.790... logprob:  0.640961, 0.286458 (1.441 sec)
35.791... logprob:  0.663774, 0.285156 (1.439 sec)
35.792... logprob:  0.628185, 0.250000 (1.456 sec)
35.793... logprob:  0.592723, 0.303385 (1.463 sec)
35.794... logprob:  0.630390, 0.285156 (1.488 sec)
35.795... logprob:  0.680217, 0.273437 (1.464 sec)
35.796... logprob:  0.633700, 0.270833 (1.458 sec)
35.797... logprob:  0.582899, 0.261719 (1.505 sec)
35.798... logprob:  0.582990, 0.223958 (1.445 sec)
35.799... logprob:  0.586666, 0.243490 (1.446 sec)
35.800... logprob:  0.626412, 0.289062 (1.401 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.471876, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.969210e-03 [9.855003e-08] 
Layer 'conv1' biases: 2.201016e-06 [2.679403e-11] 
Layer 'conv2' weights[0]: 1.965230e-03 [9.833342e-08] 
Layer 'conv2' biases: 9.999996e-01 [4.721368e-10] 
Layer 'conv3' weights[0]: 1.964299e-03 [9.851943e-08] 
Layer 'conv3' biases: 3.658895e-05 [5.984337e-09] 
Layer 'conv4' weights[0]: 1.972654e-03 [9.918824e-08] 
Layer 'conv4' biases: 9.997811e-01 [2.403844e-07] 
Layer 'conv5' weights[0]: 2.164494e-03 [3.383867e-06] 
Layer 'conv5' biases: 9.989021e-01 [3.716537e-06] 
Layer 'fc6' weights[0]: 6.568995e-03 [6.737174e-08] 
Layer 'fc6' biases: 9.999891e-01 [6.663712e-08] 
Layer 'fc7' weights[0]: 6.908007e-03 [1.630736e-07] 
Layer 'fc7' biases: 9.996791e-01 [2.654710e-07] 
Layer 'fc8' weights[0]: 4.804468e-03 [1.444138e-05] 
Layer 'fc8' biases: 2.941392e-02 [4.427033e-05] 
Train error last 800 batches: 0.654960
-------------------------------------------------------
Not saving because 0.471876 > 0.299667 (9.300: -1.18%)
======================================================= (2.354 sec)
36.1... logprob:  0.667689, 0.309896 (1.406 sec)
36.2... logprob:  0.659985, 0.274740 (1.448 sec)
36.3... logprob:  0.657005, 0.307292 (1.413 sec)
36.4... logprob:  0.624733, 0.276042 (1.404 sec)
36.5... logprob:  0.760590, 0.343750 (1.434 sec)
36.6... logprob:  0.589962, 0.272135 (1.391 sec)
36.7... logprob:  0.574717, 0.239583 (1.418 sec)
36.8... logprob:  0.590143, 0.251302 (1.389 sec)
36.9... logprob:  0.536284, 0.236979 (1.405 sec)
36.10... logprob:  0.641787, 0.287760 (1.410 sec)
36.11... logprob:  0.586128, 0.273437 (1.440 sec)
36.12... logprob:  0.704723, 0.273438 (1.396 sec)
36.13... logprob:  0.702156, 0.320312 (1.415 sec)
36.14... logprob:  0.706409, 0.298177 (1.398 sec)
36.15... logprob:  0.659584, 0.283854 (1.404 sec)
36.16... logprob:  0.580819, 0.273438 (1.401 sec)
36.17... logprob:  0.717210, 0.287760 (1.395 sec)
36.18... logprob:  0.504128, 0.244792 (1.393 sec)
36.19... logprob:  0.481762, 0.217448 (1.395 sec)
36.20... logprob:  0.609282, 0.298177 (1.397 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.507616, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.967239e-03 [9.843360e-08] 
Layer 'conv1' biases: 2.201086e-06 [2.065756e-11] 
Layer 'conv2' weights[0]: 1.963259e-03 [9.822590e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.682790e-10] 
Layer 'conv3' weights[0]: 1.962345e-03 [9.837144e-08] 
Layer 'conv3' biases: 3.657561e-05 [4.976312e-09] 
Layer 'conv4' weights[0]: 1.970664e-03 [9.899996e-08] 
Layer 'conv4' biases: 9.997826e-01 [2.240718e-07] 
Layer 'conv5' weights[0]: 2.164490e-03 [2.930896e-06] 
Layer 'conv5' biases: 9.988692e-01 [3.240050e-06] 
Layer 'fc6' weights[0]: 6.568335e-03 [6.216760e-08] 
Layer 'fc6' biases: 9.999889e-01 [6.031485e-08] 
Layer 'fc7' weights[0]: 6.907291e-03 [1.503591e-07] 
Layer 'fc7' biases: 9.996812e-01 [2.363635e-07] 
Layer 'fc8' weights[0]: 4.864512e-03 [1.335351e-05] 
Layer 'fc8' biases: 2.990489e-02 [3.336542e-05] 
Train error last 800 batches: 0.655318
-------------------------------------------------------
Not saving because 0.507616 > 0.299667 (9.300: -1.18%)
======================================================= (2.362 sec)
36.21... logprob:  0.582802, 0.268229 (1.408 sec)
36.22... logprob:  0.666523, 0.282552 (1.413 sec)
36.23... logprob:  0.714109, 0.292969 (1.408 sec)
36.24... logprob:  0.514189, 0.257812 (1.411 sec)
36.25... logprob:  0.569312, 0.247396 (1.403 sec)
36.26... logprob:  0.722252, 0.312500 (1.437 sec)
36.27... logprob:  0.631430, 0.302083 (1.383 sec)
36.28... logprob:  0.615368, 0.265625 (1.407 sec)
36.29... logprob:  0.599985, 0.281250 (1.417 sec)
36.30... logprob:  0.598110, 0.251302 (1.416 sec)
36.31... logprob:  0.693349, 0.294271 (1.406 sec)
36.32... logprob:  0.697901, 0.313802 (1.394 sec)
36.33... logprob:  0.715235, 0.313802 (1.441 sec)
36.34... logprob:  0.745775, 0.305989 (1.384 sec)
36.35... logprob:  0.635109, 0.300781 (1.395 sec)
36.36... logprob:  0.719134, 0.324219 (1.393 sec)
36.37... logprob:  0.637706, 0.283854 (1.403 sec)
36.38... logprob:  0.636302, 0.304687 (1.392 sec)
36.39... logprob:  0.847831, 0.346354 (1.429 sec)
36.40... logprob:  0.600142, 0.233073 (1.401 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.467074, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.965278e-03 [9.824775e-08] 
Layer 'conv1' biases: 2.201208e-06 [3.982836e-11] 
Layer 'conv2' weights[0]: 1.961305e-03 [9.808587e-08] 
Layer 'conv2' biases: 9.999996e-01 [6.396945e-10] 
Layer 'conv3' weights[0]: 1.960379e-03 [9.847448e-08] 
Layer 'conv3' biases: 3.659016e-05 [7.377640e-09] 
Layer 'conv4' weights[0]: 1.968708e-03 [9.898581e-08] 
Layer 'conv4' biases: 9.997829e-01 [2.720221e-07] 
Layer 'conv5' weights[0]: 2.163224e-03 [5.004036e-06] 
Layer 'conv5' biases: 9.988866e-01 [5.561156e-06] 
Layer 'fc6' weights[0]: 6.567664e-03 [8.186933e-08] 
Layer 'fc6' biases: 9.999891e-01 [8.787961e-08] 
Layer 'fc7' weights[0]: 6.906584e-03 [2.092587e-07] 
Layer 'fc7' biases: 9.996791e-01 [3.928745e-07] 
Layer 'fc8' weights[0]: 4.823919e-03 [1.904994e-05] 
Layer 'fc8' biases: 2.958799e-02 [6.243370e-05] 
Train error last 800 batches: 0.655030
-------------------------------------------------------
Not saving because 0.467074 > 0.299667 (9.300: -1.18%)
======================================================= (2.341 sec)
36.41... logprob:  0.585781, 0.257812 (1.434 sec)
36.42... logprob:  0.547603, 0.265625 (1.417 sec)
36.43... logprob:  0.637786, 0.283854 (1.403 sec)
36.44... logprob:  0.659808, 0.279948 (1.433 sec)
36.45... logprob:  0.569458, 0.238281 (1.380 sec)
36.46... logprob:  0.759263, 0.351562 (1.392 sec)
36.47... logprob:  0.645105, 0.302083 (1.392 sec)
36.48... logprob:  0.721874, 0.328125 (1.423 sec)
36.49... logprob:  0.693118, 0.294271 (1.406 sec)
36.50... logprob:  0.651718, 0.305990 (1.420 sec)
36.51... logprob:  0.740900, 0.319010 (1.410 sec)
36.52... logprob:  0.751272, 0.300781 (1.395 sec)
36.53... logprob:  0.502932, 0.251302 (1.435 sec)
36.54... logprob:  0.636761, 0.277344 (1.385 sec)
36.55... logprob:  0.613434, 0.272135 (1.390 sec)
36.56... logprob:  0.561208, 0.263021 (1.392 sec)
36.57... logprob:  0.721752, 0.289062 (1.423 sec)
36.58... logprob:  0.657643, 0.312500 (1.399 sec)
36.59... logprob:  0.551870, 0.261719 (1.453 sec)
36.60... logprob:  0.740231, 0.296875 (1.419 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.522348, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.963311e-03 [9.818659e-08] 
Layer 'conv1' biases: 2.201269e-06 [2.299545e-11] 
Layer 'conv2' weights[0]: 1.959348e-03 [9.801474e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.866453e-10] 
Layer 'conv3' weights[0]: 1.958406e-03 [9.816993e-08] 
Layer 'conv3' biases: 3.660586e-05 [4.843756e-09] 
Layer 'conv4' weights[0]: 1.966729e-03 [9.871391e-08] 
Layer 'conv4' biases: 9.997818e-01 [2.000752e-07] 
Layer 'conv5' weights[0]: 2.160843e-03 [2.096151e-06] 
Layer 'conv5' biases: 9.989093e-01 [2.265184e-06] 
Layer 'fc6' weights[0]: 6.567001e-03 [5.849053e-08] 
Layer 'fc6' biases: 9.999893e-01 [5.468421e-08] 
Layer 'fc7' weights[0]: 6.905867e-03 [1.387334e-07] 
Layer 'fc7' biases: 9.996775e-01 [1.691549e-07] 
Layer 'fc8' weights[0]: 4.783902e-03 [1.106170e-05] 
Layer 'fc8' biases: 2.929400e-02 [1.849896e-05] 
Train error last 800 batches: 0.654734
-------------------------------------------------------
Not saving because 0.522348 > 0.299667 (9.300: -1.18%)
======================================================= (2.410 sec)
36.61... logprob:  0.587609, 0.263021 (1.432 sec)
36.62... logprob:  0.611175, 0.266927 (1.454 sec)
36.63... logprob:  0.673351, 0.294271 (1.434 sec)
36.64... logprob:  0.705448, 0.305989 (1.399 sec)
36.65... logprob:  0.653896, 0.304687 (1.395 sec)
36.66... logprob:  0.643637, 0.270833 (1.440 sec)
36.67... logprob:  0.582095, 0.283854 (1.382 sec)
36.68... logprob:  0.698251, 0.316406 (1.387 sec)
36.69... logprob:  0.621615, 0.278646 (1.420 sec)
36.70... logprob:  0.536169, 0.234375 (1.428 sec)
36.71... logprob:  0.533253, 0.229167 (1.466 sec)
36.72... logprob:  0.680833, 0.268229 (1.400 sec)
36.73... logprob:  0.678211, 0.285156 (1.434 sec)
36.74... logprob:  0.691021, 0.317708 (1.411 sec)
36.75... logprob:  0.610331, 0.279948 (1.415 sec)
36.76... logprob:  0.669073, 0.300781 (1.431 sec)
36.77... logprob:  0.595457, 0.246094 (1.431 sec)
36.78... logprob:  0.642200, 0.260417 (1.444 sec)
36.79... logprob:  0.696864, 0.299479 (1.396 sec)
36.80... logprob:  0.654933, 0.276042 (1.412 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.389590, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.961353e-03 [9.809600e-08] 
Layer 'conv1' biases: 2.201330e-06 [1.565253e-11] 
Layer 'conv2' weights[0]: 1.957395e-03 [9.790912e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.426949e-10] 
Layer 'conv3' weights[0]: 1.956460e-03 [9.793910e-08] 
Layer 'conv3' biases: 3.659011e-05 [3.090901e-09] 
Layer 'conv4' weights[0]: 1.964763e-03 [9.843040e-08] 
Layer 'conv4' biases: 9.997814e-01 [1.190845e-07] 
Layer 'conv5' weights[0]: 2.159333e-03 [2.394072e-06] 
Layer 'conv5' biases: 9.988869e-01 [2.553119e-06] 
Layer 'fc6' weights[0]: 6.566339e-03 [5.852819e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.509530e-08] 
Layer 'fc7' weights[0]: 6.905187e-03 [1.372776e-07] 
Layer 'fc7' biases: 9.996790e-01 [1.656965e-07] 
Layer 'fc8' weights[0]: 4.834287e-03 [1.056311e-05] 
Layer 'fc8' biases: 2.967129e-02 [8.309915e-06] 
Train error last 800 batches: 0.654422
-------------------------------------------------------
Not saving because 0.389590 > 0.299667 (9.300: -1.18%)
======================================================= (2.374 sec)
36.81... logprob:  0.615302, 0.292969 (1.424 sec)
36.82... logprob:  0.495987, 0.230469 (1.422 sec)
36.83... logprob:  0.722475, 0.321615 (1.401 sec)
36.84... logprob:  0.636047, 0.264323 (1.460 sec)
36.85... logprob:  0.601448, 0.269531 (1.418 sec)
36.86... logprob:  0.635173, 0.298177 (1.414 sec)
36.87... logprob:  0.716066, 0.313802 (1.416 sec)
36.88... logprob:  0.751870, 0.312500 (1.401 sec)
36.89... logprob:  0.593636, 0.256510 (1.428 sec)
36.90... logprob:  0.781262, 0.326823 (1.390 sec)
36.91... logprob:  0.584697, 0.257812 (1.387 sec)
36.92... logprob:  0.781268, 0.358073 (1.400 sec)
36.93... logprob:  0.769316, 0.337240 (1.397 sec)
36.94... logprob:  0.638479, 0.247396 (1.390 sec)
36.95... logprob:  0.755433, 0.283854 (1.401 sec)
36.96... logprob:  0.874218, 0.354167 (1.396 sec)
36.97... logprob:  0.660585, 0.283854 (1.387 sec)
36.98... logprob:  0.617191, 0.279948 (1.437 sec)
36.99... logprob:  0.679727, 0.273438 (1.401 sec)
36.100... logprob:  0.547307, 0.240885 (1.392 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.511680, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.959393e-03 [9.796017e-08] 
Layer 'conv1' biases: 2.201344e-06 [2.370079e-11] 
Layer 'conv2' weights[0]: 1.955431e-03 [9.779615e-08] 
Layer 'conv2' biases: 9.999996e-01 [4.258897e-10] 
Layer 'conv3' weights[0]: 1.954505e-03 [9.794033e-08] 
Layer 'conv3' biases: 3.662198e-05 [5.016886e-09] 
Layer 'conv4' weights[0]: 1.962804e-03 [9.842009e-08] 
Layer 'conv4' biases: 9.997807e-01 [1.963392e-07] 
Layer 'conv5' weights[0]: 2.157044e-03 [3.248750e-06] 
Layer 'conv5' biases: 9.989220e-01 [3.609308e-06] 
Layer 'fc6' weights[0]: 6.565709e-03 [6.762407e-08] 
Layer 'fc6' biases: 9.999893e-01 [6.762367e-08] 
Layer 'fc7' weights[0]: 6.904523e-03 [1.622809e-07] 
Layer 'fc7' biases: 9.996763e-01 [2.465892e-07] 
Layer 'fc8' weights[0]: 4.760682e-03 [1.360444e-05] 
Layer 'fc8' biases: 2.909052e-02 [3.830869e-05] 
Train error last 800 batches: 0.654409
-------------------------------------------------------
Not saving because 0.511680 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
36.101... logprob:  0.511529, 0.213542 (1.447 sec)
36.102... logprob:  0.729361, 0.326823 (1.389 sec)
36.103... logprob:  0.727140, 0.313802 (1.393 sec)
36.104... logprob:  0.605121, 0.264323 (1.394 sec)
36.105... logprob:  0.731289, 0.294271 (1.388 sec)
36.106... logprob:  0.616261, 0.279948 (1.383 sec)
36.107... logprob:  0.562847, 0.257812 (1.433 sec)
36.108... logprob:  0.731284, 0.308594 (1.391 sec)
36.109... logprob:  0.577405, 0.278646 (1.396 sec)
36.110... logprob:  0.640756, 0.292969 (1.404 sec)
36.111... logprob:  0.624976, 0.300781 (1.391 sec)
36.112... logprob:  0.636267, 0.272135 (1.400 sec)
36.113... logprob:  0.601378, 0.291667 (1.390 sec)
36.114... logprob:  0.653677, 0.319010 (1.428 sec)
36.115... logprob:  0.613303, 0.243490 (1.404 sec)
36.116... logprob:  0.624030, 0.264323 (1.396 sec)
36.117... logprob:  0.661749, 0.291667 (1.441 sec)
36.118... logprob:  0.647005, 0.279948 (1.384 sec)
36.119... logprob:  0.593621, 0.287760 (1.392 sec)
36.120... logprob:  0.588249, 0.242187 (1.396 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.466595, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.957427e-03 [9.794949e-08] 
Layer 'conv1' biases: 2.201463e-06 [3.155080e-11] 
Layer 'conv2' weights[0]: 1.953480e-03 [9.773847e-08] 
Layer 'conv2' biases: 9.999996e-01 [4.112771e-10] 
Layer 'conv3' weights[0]: 1.952550e-03 [9.784868e-08] 
Layer 'conv3' biases: 3.662066e-05 [4.318216e-09] 
Layer 'conv4' weights[0]: 1.960850e-03 [9.833821e-08] 
Layer 'conv4' biases: 9.997811e-01 [1.430541e-07] 
Layer 'conv5' weights[0]: 2.156467e-03 [3.251986e-06] 
Layer 'conv5' biases: 9.988954e-01 [3.542697e-06] 
Layer 'fc6' weights[0]: 6.565042e-03 [6.688480e-08] 
Layer 'fc6' biases: 9.999892e-01 [6.576504e-08] 
Layer 'fc7' weights[0]: 6.903845e-03 [1.649768e-07] 
Layer 'fc7' biases: 9.996782e-01 [2.720640e-07] 
Layer 'fc8' weights[0]: 4.805673e-03 [1.506606e-05] 
Layer 'fc8' biases: 2.947405e-02 [4.339421e-05] 
Train error last 800 batches: 0.653842
-------------------------------------------------------
Not saving because 0.466595 > 0.299667 (9.300: -1.18%)
======================================================= (2.402 sec)
36.121... logprob:  0.676958, 0.294271 (1.407 sec)
36.122... logprob:  0.769127, 0.296875 (1.440 sec)
36.123... logprob:  0.678145, 0.285156 (1.385 sec)
36.124... logprob:  0.580813, 0.244792 (1.398 sec)
36.125... logprob:  0.755052, 0.308594 (1.391 sec)
36.126... logprob:  0.598386, 0.294271 (1.385 sec)
36.127... logprob:  0.747221, 0.299479 (1.392 sec)
36.128... logprob:  0.591333, 0.246094 (1.413 sec)
36.129... logprob:  0.815218, 0.332031 (1.418 sec)
36.130... logprob:  0.613027, 0.282552 (1.418 sec)
36.131... logprob:  0.665221, 0.298177 (1.409 sec)
36.132... logprob:  0.851576, 0.347656 (1.434 sec)
36.133... logprob:  0.624160, 0.255208 (1.384 sec)
36.134... logprob:  0.624337, 0.264323 (1.389 sec)
36.135... logprob:  0.659242, 0.302083 (1.395 sec)
36.136... logprob:  0.737874, 0.352865 (1.394 sec)
36.137... logprob:  0.774186, 0.329427 (1.396 sec)
36.138... logprob:  0.536835, 0.238281 (1.442 sec)
36.139... logprob:  0.577871, 0.234375 (1.396 sec)
36.140... logprob:  0.688981, 0.311198 (1.407 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.546626, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.955476e-03 [9.781590e-08] 
Layer 'conv1' biases: 2.201582e-06 [1.429597e-11] 
Layer 'conv2' weights[0]: 1.951512e-03 [9.762289e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.378632e-10] 
Layer 'conv3' weights[0]: 1.950582e-03 [9.771729e-08] 
Layer 'conv3' biases: 3.664208e-05 [4.080737e-09] 
Layer 'conv4' weights[0]: 1.958884e-03 [9.820272e-08] 
Layer 'conv4' biases: 9.997800e-01 [1.776884e-07] 
Layer 'conv5' weights[0]: 2.153214e-03 [2.452113e-06] 
Layer 'conv5' biases: 9.989267e-01 [2.658351e-06] 
Layer 'fc6' weights[0]: 6.564334e-03 [6.036872e-08] 
Layer 'fc6' biases: 9.999894e-01 [5.720212e-08] 
Layer 'fc7' weights[0]: 6.903187e-03 [1.410863e-07] 
Layer 'fc7' biases: 9.996759e-01 [1.824900e-07] 
Layer 'fc8' weights[0]: 4.748111e-03 [1.149557e-05] 
Layer 'fc8' biases: 2.906981e-02 [1.872894e-05] 
Train error last 800 batches: 0.653980
-------------------------------------------------------
Not saving because 0.546626 > 0.299667 (9.300: -1.18%)
======================================================= (2.358 sec)
36.141... logprob:  0.641052, 0.286458 (1.437 sec)
36.142... logprob:  0.725654, 0.299479 (1.395 sec)
36.143... logprob:  0.644034, 0.290365 (1.422 sec)
36.144... logprob:  0.631822, 0.286458 (1.410 sec)
36.145... logprob:  0.506533, 0.233073 (1.410 sec)
36.146... logprob:  0.706618, 0.294271 (1.404 sec)
36.147... logprob:  0.556718, 0.261719 (1.424 sec)
36.148... logprob:  0.701602, 0.308594 (1.384 sec)
36.149... logprob:  0.589769, 0.266927 (1.396 sec)
36.150... logprob:  0.585056, 0.265625 (1.394 sec)
36.151... logprob:  0.575572, 0.272135 (1.392 sec)
36.152... logprob:  0.915298, 0.403646 (1.383 sec)
36.153... logprob:  0.643312, 0.287760 (1.436 sec)
36.154... logprob:  0.788483, 0.354167 (1.395 sec)
36.155... logprob:  0.693851, 0.287760 (1.397 sec)
36.156... logprob:  0.645330, 0.302083 (1.433 sec)
36.157... logprob:  0.495693, 0.229167 (1.388 sec)
36.158... logprob:  0.679647, 0.266927 (1.398 sec)
36.159... logprob:  0.657655, 0.302083 (1.393 sec)
36.160... logprob:  0.583789, 0.272135 (1.392 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.424254, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.953517e-03 [9.779582e-08] 
Layer 'conv1' biases: 2.201707e-06 [2.554749e-11] 
Layer 'conv2' weights[0]: 1.949570e-03 [9.755622e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.494681e-10] 
Layer 'conv3' weights[0]: 1.948631e-03 [9.761973e-08] 
Layer 'conv3' biases: 3.663604e-05 [4.093960e-09] 
Layer 'conv4' weights[0]: 1.956923e-03 [9.820848e-08] 
Layer 'conv4' biases: 9.997805e-01 [1.987572e-07] 
Layer 'conv5' weights[0]: 2.152465e-03 [2.969213e-06] 
Layer 'conv5' biases: 9.988904e-01 [3.318713e-06] 
Layer 'fc6' weights[0]: 6.563701e-03 [6.172993e-08] 
Layer 'fc6' biases: 9.999893e-01 [5.915211e-08] 
Layer 'fc7' weights[0]: 6.902466e-03 [1.491389e-07] 
Layer 'fc7' biases: 9.996772e-01 [2.196637e-07] 
Layer 'fc8' weights[0]: 4.812606e-03 [1.334866e-05] 
Layer 'fc8' biases: 2.957651e-02 [3.393939e-05] 
Train error last 800 batches: 0.654461
-------------------------------------------------------
Not saving because 0.424254 > 0.299667 (9.300: -1.18%)
======================================================= (2.368 sec)
36.161... logprob:  0.586490, 0.253906 (1.420 sec)
36.162... logprob:  0.749137, 0.334635 (1.405 sec)
36.163... logprob:  0.770709, 0.315104 (1.424 sec)
36.164... logprob:  0.747796, 0.308594 (1.420 sec)
36.165... logprob:  0.673733, 0.289062 (1.413 sec)
36.166... logprob:  0.606037, 0.263021 (1.443 sec)
36.167... logprob:  0.670319, 0.300781 (1.425 sec)
36.168... logprob:  0.610679, 0.261719 (1.432 sec)
36.169... logprob:  0.722675, 0.309896 (1.454 sec)
36.170... logprob:  0.671673, 0.300781 (1.403 sec)
36.171... logprob:  0.711394, 0.312500 (1.427 sec)
36.172... logprob:  0.647932, 0.285156 (1.414 sec)
36.173... logprob:  0.685264, 0.313802 (1.423 sec)
36.174... logprob:  0.741136, 0.300781 (1.393 sec)
36.175... logprob:  0.680554, 0.308594 (1.462 sec)
36.176... logprob:  0.764334, 0.317708 (1.409 sec)
36.177... logprob:  0.559064, 0.265625 (1.420 sec)
36.178... logprob:  0.683943, 0.252604 (1.448 sec)
36.179... logprob:  0.552160, 0.246094 (1.404 sec)
36.180... logprob:  0.611209, 0.260417 (1.415 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.389385, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.951569e-03 [9.759759e-08] 
Layer 'conv1' biases: 2.201868e-06 [1.952179e-11] 
Layer 'conv2' weights[0]: 1.947626e-03 [9.741630e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.121864e-10] 
Layer 'conv3' weights[0]: 1.946701e-03 [9.746032e-08] 
Layer 'conv3' biases: 3.665705e-05 [3.656610e-09] 
Layer 'conv4' weights[0]: 1.954967e-03 [9.792346e-08] 
Layer 'conv4' biases: 9.997791e-01 [1.606748e-07] 
Layer 'conv5' weights[0]: 2.150036e-03 [2.224317e-06] 
Layer 'conv5' biases: 9.989068e-01 [2.360730e-06] 
Layer 'fc6' weights[0]: 6.563032e-03 [5.917511e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.584315e-08] 
Layer 'fc7' weights[0]: 6.901718e-03 [1.425052e-07] 
Layer 'fc7' biases: 9.996762e-01 [1.875219e-07] 
Layer 'fc8' weights[0]: 4.773885e-03 [1.254205e-05] 
Layer 'fc8' biases: 2.931469e-02 [3.264451e-05] 
Train error last 800 batches: 0.654496
-------------------------------------------------------
Not saving because 0.389385 > 0.299667 (9.300: -1.18%)
======================================================= (2.357 sec)
36.181... logprob:  0.736500, 0.325521 (1.424 sec)
36.182... logprob:  0.581390, 0.276042 (1.415 sec)
36.183... logprob:  0.607708, 0.259115 (1.420 sec)
36.184... logprob:  0.674677, 0.304687 (1.416 sec)
36.185... logprob:  0.557320, 0.250000 (1.395 sec)
36.186... logprob:  0.512603, 0.227865 (1.399 sec)
36.187... logprob:  0.718880, 0.307292 (1.391 sec)
36.188... logprob:  0.652985, 0.289062 (1.393 sec)
36.189... logprob:  0.626699, 0.256510 (1.390 sec)
36.190... logprob:  0.655221, 0.261719 (1.433 sec)
36.191... logprob:  0.691943, 0.305990 (1.402 sec)
36.192... logprob:  0.740816, 0.289062 (1.411 sec)
36.193... logprob:  0.560965, 0.243490 (1.413 sec)
36.194... logprob:  0.657025, 0.269531 (1.404 sec)
36.195... logprob:  0.544626, 0.250000 (1.394 sec)
36.196... logprob:  0.645244, 0.286458 (1.387 sec)
36.197... logprob:  0.680925, 0.299479 (1.400 sec)
36.198... logprob:  0.654641, 0.312500 (1.393 sec)
36.199... logprob:  0.689371, 0.285156 (1.383 sec)
36.200... logprob:  0.667731, 0.302083 (1.432 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.471173, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.949610e-03 [9.756452e-08] 
Layer 'conv1' biases: 2.201942e-06 [2.567625e-11] 
Layer 'conv2' weights[0]: 1.945669e-03 [9.734706e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.625002e-10] 
Layer 'conv3' weights[0]: 1.944758e-03 [9.742731e-08] 
Layer 'conv3' biases: 3.665760e-05 [4.195819e-09] 
Layer 'conv4' weights[0]: 1.953008e-03 [9.780541e-08] 
Layer 'conv4' biases: 9.997786e-01 [1.239480e-07] 
Layer 'conv5' weights[0]: 2.147887e-03 [2.235522e-06] 
Layer 'conv5' biases: 9.988830e-01 [2.346293e-06] 
Layer 'fc6' weights[0]: 6.562349e-03 [6.033889e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.775783e-08] 
Layer 'fc7' weights[0]: 6.901028e-03 [1.470544e-07] 
Layer 'fc7' biases: 9.996773e-01 [2.047739e-07] 
Layer 'fc8' weights[0]: 4.811321e-03 [1.388020e-05] 
Layer 'fc8' biases: 2.966455e-02 [3.213780e-05] 
Train error last 800 batches: 0.654505
-------------------------------------------------------
Not saving because 0.471173 > 0.299667 (9.300: -1.18%)
======================================================= (2.357 sec)
36.201... logprob:  0.739546, 0.319010 (1.412 sec)
36.202... logprob:  0.654572, 0.313802 (1.400 sec)
36.203... logprob:  0.616286, 0.261719 (1.440 sec)
36.204... logprob:  0.732859, 0.337240 (1.390 sec)
36.205... logprob:  0.575202, 0.260417 (1.402 sec)
36.206... logprob:  0.662448, 0.307292 (1.394 sec)
36.207... logprob:  0.583230, 0.273438 (1.385 sec)
36.208... logprob:  0.605734, 0.260417 (1.392 sec)
36.209... logprob:  0.549437, 0.248698 (1.411 sec)
36.210... logprob:  0.682112, 0.290365 (1.410 sec)
36.211... logprob:  0.728105, 0.273438 (1.408 sec)
36.212... logprob:  0.663641, 0.285156 (1.413 sec)
36.213... logprob:  0.699320, 0.294271 (1.461 sec)
36.214... logprob:  0.731974, 0.328125 (1.419 sec)
36.215... logprob:  0.650505, 0.294271 (1.406 sec)
36.216... logprob:  0.758495, 0.302083 (1.464 sec)
36.217... logprob:  0.571768, 0.272135 (1.402 sec)
36.218... logprob:  0.648997, 0.305990 (1.414 sec)
36.219... logprob:  0.613948, 0.263021 (1.412 sec)
36.220... logprob:  0.676504, 0.302083 (1.411 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.495071, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.947660e-03 [9.741385e-08] 
Layer 'conv1' biases: 2.201937e-06 [2.147574e-11] 
Layer 'conv2' weights[0]: 1.943727e-03 [9.723623e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.868809e-10] 
Layer 'conv3' weights[0]: 1.942803e-03 [9.736686e-08] 
Layer 'conv3' biases: 3.665234e-05 [4.802694e-09] 
Layer 'conv4' weights[0]: 1.951063e-03 [9.793355e-08] 
Layer 'conv4' biases: 9.997786e-01 [1.874236e-07] 
Layer 'conv5' weights[0]: 2.146712e-03 [2.149611e-06] 
Layer 'conv5' biases: 9.988666e-01 [2.256856e-06] 
Layer 'fc6' weights[0]: 6.561688e-03 [5.885954e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.637594e-08] 
Layer 'fc7' weights[0]: 6.900355e-03 [1.400352e-07] 
Layer 'fc7' biases: 9.996774e-01 [1.814422e-07] 
Layer 'fc8' weights[0]: 4.827952e-03 [1.228482e-05] 
Layer 'fc8' biases: 2.982846e-02 [2.777237e-05] 
Train error last 800 batches: 0.654091
-------------------------------------------------------
Not saving because 0.495071 > 0.299667 (9.300: -1.18%)
======================================================= (2.358 sec)
36.221... logprob:  0.641439, 0.274740 (1.422 sec)
36.222... logprob:  0.781352, 0.341146 (1.452 sec)
36.223... logprob:  0.800073, 0.346354 (1.419 sec)
36.224... logprob:  0.668333, 0.282552 (1.434 sec)
36.225... logprob:  0.668436, 0.290365 (1.445 sec)
36.226... logprob:  0.680178, 0.279948 (1.434 sec)
36.227... logprob:  0.726364, 0.311198 (1.408 sec)
36.228... logprob:  0.660767, 0.278646 (1.407 sec)
36.229... logprob:  0.649245, 0.289062 (1.414 sec)
36.230... logprob:  0.643403, 0.272135 (1.421 sec)
36.231... logprob:  0.725537, 0.341146 (1.401 sec)
36.232... logprob:  0.712049, 0.328125 (1.452 sec)
36.233... logprob:  0.675972, 0.295573 (1.420 sec)
36.234... logprob:  0.798552, 0.315104 (1.411 sec)
36.235... logprob:  0.729744, 0.302083 (1.468 sec)
36.236... logprob:  0.622089, 0.256510 (1.399 sec)
36.237... logprob:  0.596816, 0.263021 (1.420 sec)
36.238... logprob:  0.647291, 0.279948 (1.410 sec)
36.239... logprob:  0.684721, 0.309896 (1.410 sec)
36.240... logprob:  0.710456, 0.321615 (1.396 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.569283, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.945718e-03 [9.734380e-08] 
Layer 'conv1' biases: 2.201992e-06 [1.368326e-11] 
Layer 'conv2' weights[0]: 1.941789e-03 [9.714403e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.400043e-10] 
Layer 'conv3' weights[0]: 1.940860e-03 [9.715185e-08] 
Layer 'conv3' biases: 3.666181e-05 [2.773878e-09] 
Layer 'conv4' weights[0]: 1.949122e-03 [9.760307e-08] 
Layer 'conv4' biases: 9.997779e-01 [1.075187e-07] 
Layer 'conv5' weights[0]: 2.144174e-03 [2.136978e-06] 
Layer 'conv5' biases: 9.989014e-01 [2.319961e-06] 
Layer 'fc6' weights[0]: 6.561029e-03 [5.862061e-08] 
Layer 'fc6' biases: 9.999894e-01 [5.546438e-08] 
Layer 'fc7' weights[0]: 6.899619e-03 [1.395988e-07] 
Layer 'fc7' biases: 9.996748e-01 [1.745032e-07] 
Layer 'fc8' weights[0]: 4.743888e-03 [1.141166e-05] 
Layer 'fc8' biases: 2.916265e-02 [1.452316e-05] 
Train error last 800 batches: 0.654288
-------------------------------------------------------
Not saving because 0.569283 > 0.299667 (9.300: -1.18%)
======================================================= (2.425 sec)
36.241... logprob:  0.716006, 0.289062 (1.464 sec)
36.242... logprob:  0.629375, 0.308594 (1.438 sec)
36.243... logprob:  0.614181, 0.240885 (1.428 sec)
36.244... logprob:  0.600895, 0.283854 (1.442 sec)
36.245... logprob:  0.691527, 0.277344 (1.415 sec)
36.246... logprob:  0.664347, 0.278646 (1.410 sec)
36.247... logprob:  0.592930, 0.285156 (1.415 sec)
36.248... logprob:  0.545001, 0.256510 (1.411 sec)
36.249... logprob:  0.772469, 0.360677 (1.417 sec)
36.250... logprob:  0.727544, 0.294271 (1.406 sec)
36.251... logprob:  0.639410, 0.290364 (1.463 sec)
36.252... logprob:  0.574354, 0.269531 (1.420 sec)
36.253... logprob:  0.615505, 0.294271 (1.408 sec)
36.254... logprob:  0.688808, 0.296875 (1.461 sec)
36.255... logprob:  0.618150, 0.279948 (1.399 sec)
36.256... logprob:  0.661956, 0.317708 (1.420 sec)
36.257... logprob:  0.637183, 0.290364 (1.410 sec)
36.258... logprob:  0.661954, 0.294271 (1.414 sec)
36.259... logprob:  0.670090, 0.276042 (1.395 sec)
36.260... logprob:  0.547576, 0.227865 (1.451 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.433867, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.943766e-03 [9.723260e-08] 
Layer 'conv1' biases: 2.202017e-06 [2.256966e-11] 
Layer 'conv2' weights[0]: 1.939840e-03 [9.704405e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.333079e-10] 
Layer 'conv3' weights[0]: 1.938929e-03 [9.715298e-08] 
Layer 'conv3' biases: 3.663799e-05 [4.771469e-09] 
Layer 'conv4' weights[0]: 1.947168e-03 [9.770509e-08] 
Layer 'conv4' biases: 9.997794e-01 [1.884521e-07] 
Layer 'conv5' weights[0]: 2.144732e-03 [3.172212e-06] 
Layer 'conv5' biases: 9.988558e-01 [3.520853e-06] 
Layer 'fc6' weights[0]: 6.560408e-03 [6.448631e-08] 
Layer 'fc6' biases: 9.999890e-01 [6.369367e-08] 
Layer 'fc7' weights[0]: 6.898913e-03 [1.583631e-07] 
Layer 'fc7' biases: 9.996779e-01 [2.424171e-07] 
Layer 'fc8' weights[0]: 4.830448e-03 [1.328783e-05] 
Layer 'fc8' biases: 2.993493e-02 [3.810362e-05] 
Train error last 800 batches: 0.654356
-------------------------------------------------------
Not saving because 0.433867 > 0.299667 (9.300: -1.18%)
======================================================= (2.350 sec)
36.261... logprob:  0.596120, 0.266927 (1.430 sec)
36.262... logprob:  0.681216, 0.299479 (1.432 sec)
36.263... logprob:  0.611452, 0.269531 (1.441 sec)
36.264... logprob:  0.622223, 0.273437 (1.414 sec)
36.265... logprob:  0.639972, 0.298177 (1.433 sec)
36.266... logprob:  0.626022, 0.252604 (1.410 sec)
36.267... logprob:  0.694510, 0.296875 (1.409 sec)
36.268... logprob:  0.641228, 0.296875 (1.418 sec)
36.269... logprob:  0.859604, 0.358073 (1.405 sec)
36.270... logprob:  0.699777, 0.295573 (1.453 sec)
36.271... logprob:  0.674011, 0.295573 (1.420 sec)
36.272... logprob:  0.553674, 0.247396 (1.410 sec)
36.273... logprob:  0.682640, 0.330729 (1.462 sec)
36.274... logprob:  0.729402, 0.303385 (1.397 sec)
36.275... logprob:  0.749258, 0.341146 (1.422 sec)
36.276... logprob:  0.603235, 0.250000 (1.409 sec)
36.277... logprob:  0.586281, 0.266927 (1.425 sec)
36.278... logprob:  0.541974, 0.257813 (1.413 sec)
36.279... logprob:  0.542191, 0.260417 (1.459 sec)
36.280... logprob:  0.523461, 0.257812 (1.395 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.513712, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.941826e-03 [9.715873e-08] 
Layer 'conv1' biases: 2.202053e-06 [1.766922e-11] 
Layer 'conv2' weights[0]: 1.937892e-03 [9.695954e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.211681e-10] 
Layer 'conv3' weights[0]: 1.936984e-03 [9.701729e-08] 
Layer 'conv3' biases: 3.664888e-05 [3.793798e-09] 
Layer 'conv4' weights[0]: 1.945204e-03 [9.756028e-08] 
Layer 'conv4' biases: 9.997796e-01 [1.726779e-07] 
Layer 'conv5' weights[0]: 2.143903e-03 [2.828447e-06] 
Layer 'conv5' biases: 9.988586e-01 [3.179946e-06] 
Layer 'fc6' weights[0]: 6.559717e-03 [5.928144e-08] 
Layer 'fc6' biases: 9.999889e-01 [5.683382e-08] 
Layer 'fc7' weights[0]: 6.898198e-03 [1.445520e-07] 
Layer 'fc7' biases: 9.996769e-01 [2.249177e-07] 
Layer 'fc8' weights[0]: 4.828011e-03 [1.245609e-05] 
Layer 'fc8' biases: 2.991465e-02 [3.787864e-05] 
Train error last 800 batches: 0.654126
-------------------------------------------------------
Not saving because 0.513712 > 0.299667 (9.300: -1.18%)
======================================================= (2.372 sec)
36.281... logprob:  0.615895, 0.283854 (1.433 sec)
36.282... logprob:  0.613378, 0.279948 (1.418 sec)
36.283... logprob:  0.623377, 0.278646 (1.416 sec)
36.284... logprob:  0.530396, 0.229167 (1.403 sec)
36.285... logprob:  0.667051, 0.295573 (1.434 sec)
36.286... logprob:  0.631599, 0.263021 (1.433 sec)
36.287... logprob:  0.608465, 0.285156 (1.428 sec)
36.288... logprob:  0.597955, 0.259114 (1.439 sec)
36.289... logprob:  0.601711, 0.247396 (1.436 sec)
36.290... logprob:  0.759570, 0.307292 (1.399 sec)
36.291... logprob:  0.660109, 0.273437 (1.414 sec)
36.292... logprob:  0.763509, 0.342448 (1.411 sec)
36.293... logprob:  0.654524, 0.309896 (1.415 sec)
36.294... logprob:  0.569660, 0.265625 (1.405 sec)
36.295... logprob:  0.514089, 0.223958 (1.459 sec)
36.296... logprob:  0.614080, 0.276041 (1.408 sec)
36.297... logprob:  0.594616, 0.255208 (1.419 sec)
36.298... logprob:  0.608024, 0.263021 (1.455 sec)
36.299... logprob:  0.615229, 0.260417 (1.394 sec)
36.300... logprob:  0.565192, 0.253906 (1.419 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.480858, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.939883e-03 [9.705405e-08] 
Layer 'conv1' biases: 2.202172e-06 [2.435449e-11] 
Layer 'conv2' weights[0]: 1.935958e-03 [9.685590e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.743244e-10] 
Layer 'conv3' weights[0]: 1.935049e-03 [9.692803e-08] 
Layer 'conv3' biases: 3.663888e-05 [4.475695e-09] 
Layer 'conv4' weights[0]: 1.943267e-03 [9.746327e-08] 
Layer 'conv4' biases: 9.997822e-01 [1.686279e-07] 
Layer 'conv5' weights[0]: 2.145218e-03 [2.505551e-06] 
Layer 'conv5' biases: 9.988217e-01 [2.702163e-06] 
Layer 'fc6' weights[0]: 6.559028e-03 [5.675441e-08] 
Layer 'fc6' biases: 9.999889e-01 [5.390044e-08] 
Layer 'fc7' weights[0]: 6.897489e-03 [1.343827e-07] 
Layer 'fc7' biases: 9.996786e-01 [1.721250e-07] 
Layer 'fc8' weights[0]: 4.885375e-03 [1.069209e-05] 
Layer 'fc8' biases: 3.035185e-02 [1.864541e-05] 
Train error last 800 batches: 0.653861
-------------------------------------------------------
Not saving because 0.480858 > 0.299667 (9.300: -1.18%)
======================================================= (2.399 sec)
36.301... logprob:  0.622099, 0.239583 (1.420 sec)
36.302... logprob:  0.749536, 0.347656 (1.417 sec)
36.303... logprob:  0.726899, 0.326823 (1.401 sec)
36.304... logprob:  0.637050, 0.282552 (1.433 sec)
36.305... logprob:  0.628228, 0.265625 (1.432 sec)
36.306... logprob:  0.740155, 0.316406 (1.427 sec)
36.307... logprob:  0.600139, 0.283854 (1.436 sec)
36.308... logprob:  0.664587, 0.311198 (1.447 sec)
36.309... logprob:  0.613646, 0.270833 (1.407 sec)
36.310... logprob:  0.625461, 0.290365 (1.416 sec)
36.311... logprob:  0.611641, 0.231771 (1.417 sec)
36.312... logprob:  0.708060, 0.283854 (1.430 sec)
36.313... logprob:  0.764720, 0.329427 (1.413 sec)
36.314... logprob:  0.632047, 0.287760 (1.461 sec)
36.315... logprob:  0.511383, 0.218750 (1.436 sec)
36.316... logprob:  0.723747, 0.309896 (1.414 sec)
36.317... logprob:  0.585386, 0.279948 (1.472 sec)
36.318... logprob:  0.711055, 0.290365 (1.405 sec)
36.319... logprob:  0.660682, 0.304687 (1.418 sec)
36.320... logprob:  0.707763, 0.319010 (1.418 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.514678, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.937951e-03 [9.691074e-08] 
Layer 'conv1' biases: 2.202272e-06 [2.193086e-11] 
Layer 'conv2' weights[0]: 1.934024e-03 [9.673128e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.050243e-10] 
Layer 'conv3' weights[0]: 1.933128e-03 [9.684139e-08] 
Layer 'conv3' biases: 3.665599e-05 [4.381385e-09] 
Layer 'conv4' weights[0]: 1.941335e-03 [9.732603e-08] 
Layer 'conv4' biases: 9.997801e-01 [2.007191e-07] 
Layer 'conv5' weights[0]: 2.141677e-03 [2.742319e-06] 
Layer 'conv5' biases: 9.988478e-01 [3.085587e-06] 
Layer 'fc6' weights[0]: 6.558329e-03 [6.094253e-08] 
Layer 'fc6' biases: 9.999890e-01 [5.973334e-08] 
Layer 'fc7' weights[0]: 6.896759e-03 [1.471241e-07] 
Layer 'fc7' biases: 9.996766e-01 [2.073305e-07] 
Layer 'fc8' weights[0]: 4.832119e-03 [1.172943e-05] 
Layer 'fc8' biases: 2.991818e-02 [2.486439e-05] 
Train error last 800 batches: 0.654119
-------------------------------------------------------
Not saving because 0.514678 > 0.299667 (9.300: -1.18%)
======================================================= (2.359 sec)
36.321... logprob:  0.605973, 0.270833 (1.427 sec)
36.322... logprob:  0.598390, 0.256510 (1.417 sec)
36.323... logprob:  0.708951, 0.305990 (1.474 sec)
36.324... logprob:  0.720841, 0.329427 (1.416 sec)
36.325... logprob:  0.521034, 0.208333 (1.432 sec)
36.326... logprob:  0.650181, 0.286458 (1.454 sec)
36.327... logprob:  0.771944, 0.307292 (1.417 sec)
36.328... logprob:  0.722978, 0.290365 (1.417 sec)
36.329... logprob:  0.617303, 0.282552 (1.419 sec)
36.330... logprob:  0.577716, 0.268229 (1.414 sec)
36.331... logprob:  0.631357, 0.291667 (1.409 sec)
36.332... logprob:  0.669829, 0.273438 (1.446 sec)
36.333... logprob:  0.644863, 0.294271 (1.438 sec)
36.334... logprob:  0.637299, 0.270833 (1.431 sec)
36.335... logprob:  0.591273, 0.238281 (1.435 sec)
36.336... logprob:  0.712056, 0.286458 (1.450 sec)
36.337... logprob:  0.763541, 0.325521 (1.423 sec)
36.338... logprob:  0.647577, 0.282552 (1.416 sec)
36.339... logprob:  0.692078, 0.337240 (1.416 sec)
36.340... logprob:  0.730099, 0.308594 (1.422 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.515273, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.936010e-03 [9.687306e-08] 
Layer 'conv1' biases: 2.202309e-06 [1.795520e-11] 
Layer 'conv2' weights[0]: 1.932095e-03 [9.665660e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.850926e-10] 
Layer 'conv3' weights[0]: 1.931191e-03 [9.672186e-08] 
Layer 'conv3' biases: 3.667132e-05 [3.829295e-09] 
Layer 'conv4' weights[0]: 1.939386e-03 [9.714438e-08] 
Layer 'conv4' biases: 9.997794e-01 [1.201988e-07] 
Layer 'conv5' weights[0]: 2.139087e-03 [2.121911e-06] 
Layer 'conv5' biases: 9.988644e-01 [2.214081e-06] 
Layer 'fc6' weights[0]: 6.557700e-03 [6.158633e-08] 
Layer 'fc6' biases: 9.999890e-01 [6.043687e-08] 
Layer 'fc7' weights[0]: 6.896034e-03 [1.483720e-07] 
Layer 'fc7' biases: 9.996756e-01 [2.012421e-07] 
Layer 'fc8' weights[0]: 4.796893e-03 [1.280629e-05] 
Layer 'fc8' biases: 2.960572e-02 [2.473591e-05] 
Train error last 800 batches: 0.653877
-------------------------------------------------------
Not saving because 0.515273 > 0.299667 (9.300: -1.18%)
======================================================= (2.349 sec)
36.341... logprob:  0.665169, 0.294271 (1.424 sec)
36.342... logprob:  0.670173, 0.304687 (1.499 sec)
36.343... logprob:  0.657553, 0.325521 (1.442 sec)
36.344... logprob:  0.754935, 0.347656 (1.482 sec)
36.345... logprob:  0.707362, 0.330729 (1.431 sec)
36.346... logprob:  0.663105, 0.289062 (1.430 sec)
36.347... logprob:  0.640812, 0.276042 (1.477 sec)
36.348... logprob:  0.627623, 0.246094 (1.545 sec)
36.349... logprob:  0.678631, 0.309896 (1.423 sec)
36.350... logprob:  0.638101, 0.290365 (1.429 sec)
36.351... logprob:  0.700321, 0.313802 (1.425 sec)
36.352... logprob:  0.579035, 0.266927 (1.425 sec)
36.353... logprob:  0.697225, 0.319010 (1.482 sec)
36.354... logprob:  0.770226, 0.328125 (1.423 sec)
36.355... logprob:  0.571629, 0.278646 (1.442 sec)
36.356... logprob:  0.681298, 0.294271 (1.467 sec)
36.357... logprob:  0.666191, 0.295573 (1.427 sec)
36.358... logprob:  0.622076, 0.282552 (1.431 sec)
36.359... logprob:  0.761741, 0.324219 (1.423 sec)
36.360... logprob:  0.562121, 0.256510 (1.423 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.496377, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.934076e-03 [9.675280e-08] 
Layer 'conv1' biases: 2.202369e-06 [2.438467e-11] 
Layer 'conv2' weights[0]: 1.930164e-03 [9.655746e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.635716e-10] 
Layer 'conv3' weights[0]: 1.929249e-03 [9.667583e-08] 
Layer 'conv3' biases: 3.666451e-05 [4.377596e-09] 
Layer 'conv4' weights[0]: 1.937451e-03 [9.723183e-08] 
Layer 'conv4' biases: 9.997807e-01 [1.964382e-07] 
Layer 'conv5' weights[0]: 2.138654e-03 [2.763809e-06] 
Layer 'conv5' biases: 9.988539e-01 [2.998598e-06] 
Layer 'fc6' weights[0]: 6.557029e-03 [6.204074e-08] 
Layer 'fc6' biases: 9.999889e-01 [6.080877e-08] 
Layer 'fc7' weights[0]: 6.895348e-03 [1.526234e-07] 
Layer 'fc7' biases: 9.996760e-01 [2.281625e-07] 
Layer 'fc8' weights[0]: 4.818076e-03 [1.406706e-05] 
Layer 'fc8' biases: 2.982494e-02 [4.179563e-05] 
Train error last 800 batches: 0.653804
-------------------------------------------------------
Not saving because 0.496377 > 0.299667 (9.300: -1.18%)
======================================================= (2.356 sec)
36.361... logprob:  0.620177, 0.252604 (1.430 sec)
36.362... logprob:  0.676777, 0.311198 (1.472 sec)
36.363... logprob:  0.626411, 0.257812 (1.434 sec)
36.364... logprob:  0.623436, 0.283854 (1.446 sec)
36.365... logprob:  0.674328, 0.296875 (1.459 sec)
36.366... logprob:  0.629211, 0.287760 (1.438 sec)
36.367... logprob:  0.593858, 0.264323 (1.430 sec)
36.368... logprob:  0.696097, 0.322917 (1.426 sec)
36.369... logprob:  0.614492, 0.253906 (1.418 sec)
36.370... logprob:  0.577931, 0.270833 (1.430 sec)
36.371... logprob:  0.662088, 0.265625 (1.451 sec)
36.372... logprob:  0.645631, 0.264323 (1.447 sec)
36.373... logprob:  0.518761, 0.229167 (1.452 sec)
36.374... logprob:  0.799426, 0.328125 (1.449 sec)
36.375... logprob:  0.582708, 0.272135 (1.459 sec)
36.376... logprob:  0.625106, 0.283854 (1.430 sec)
36.377... logprob:  0.508227, 0.221354 (1.419 sec)
36.378... logprob:  0.669654, 0.299479 (1.419 sec)
36.379... logprob:  0.649863, 0.304688 (1.434 sec)
36.380... logprob:  0.904135, 0.352865 (1.435 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.401173, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.932143e-03 [9.664665e-08] 
Layer 'conv1' biases: 2.202507e-06 [1.958463e-11] 
Layer 'conv2' weights[0]: 1.928233e-03 [9.644900e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.930275e-10] 
Layer 'conv3' weights[0]: 1.927302e-03 [9.651967e-08] 
Layer 'conv3' biases: 3.663182e-05 [3.861281e-09] 
Layer 'conv4' weights[0]: 1.935525e-03 [9.703210e-08] 
Layer 'conv4' biases: 9.997830e-01 [1.764773e-07] 
Layer 'conv5' weights[0]: 2.139974e-03 [2.842059e-06] 
Layer 'conv5' biases: 9.988323e-01 [3.124663e-06] 
Layer 'fc6' weights[0]: 6.556331e-03 [6.230116e-08] 
Layer 'fc6' biases: 9.999890e-01 [6.204931e-08] 
Layer 'fc7' weights[0]: 6.894660e-03 [1.491890e-07] 
Layer 'fc7' biases: 9.996774e-01 [2.056344e-07] 
Layer 'fc8' weights[0]: 4.853679e-03 [1.219546e-05] 
Layer 'fc8' biases: 3.014247e-02 [2.199434e-05] 
Train error last 800 batches: 0.653459
-------------------------------------------------------
Not saving because 0.401173 > 0.299667 (9.300: -1.18%)
======================================================= (2.356 sec)
36.381... logprob:  0.729127, 0.281250 (1.474 sec)
36.382... logprob:  0.792897, 0.363281 (1.453 sec)
36.383... logprob:  0.564884, 0.264323 (1.430 sec)
36.384... logprob:  0.696036, 0.286458 (1.473 sec)
36.385... logprob:  0.717069, 0.320312 (1.432 sec)
36.386... logprob:  0.728771, 0.325521 (1.425 sec)
36.387... logprob:  0.664523, 0.298177 (1.431 sec)
36.388... logprob:  0.776424, 0.322917 (1.435 sec)
36.389... logprob:  0.684863, 0.266927 (1.429 sec)
36.390... logprob:  0.651522, 0.333333 (1.473 sec)
36.391... logprob:  0.642355, 0.281250 (1.441 sec)
36.392... logprob:  0.667495, 0.298177 (1.429 sec)
36.393... logprob:  0.569708, 0.260417 (1.477 sec)
36.394... logprob:  0.573627, 0.227865 (1.432 sec)
36.395... logprob:  0.480399, 0.208333 (1.432 sec)
36.396... logprob:  0.612997, 0.264323 (1.433 sec)
36.397... logprob:  0.695022, 0.283854 (1.428 sec)
36.398... logprob:  0.676975, 0.308594 (1.425 sec)
36.399... logprob:  0.699628, 0.298177 (1.477 sec)
36.400... logprob:  0.765939, 0.308594 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.440368, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.930210e-03 [9.654959e-08] 
Layer 'conv1' biases: 2.202596e-06 [1.596699e-11] 
Layer 'conv2' weights[0]: 1.926296e-03 [9.635325e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.585563e-10] 
Layer 'conv3' weights[0]: 1.925407e-03 [9.639702e-08] 
Layer 'conv3' biases: 3.664660e-05 [3.264436e-09] 
Layer 'conv4' weights[0]: 1.933565e-03 [9.686403e-08] 
Layer 'conv4' biases: 9.997813e-01 [1.394205e-07] 
Layer 'conv5' weights[0]: 2.137045e-03 [1.974275e-06] 
Layer 'conv5' biases: 9.988604e-01 [2.163310e-06] 
Layer 'fc6' weights[0]: 6.555673e-03 [5.943406e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.718503e-08] 
Layer 'fc7' weights[0]: 6.893999e-03 [1.402882e-07] 
Layer 'fc7' biases: 9.996760e-01 [1.713222e-07] 
Layer 'fc8' weights[0]: 4.806691e-03 [1.093610e-05] 
Layer 'fc8' biases: 2.979621e-02 [1.068746e-05] 
Train error last 800 batches: 0.653468
-------------------------------------------------------
Not saving because 0.440368 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
36.401... logprob:  0.591019, 0.250000 (1.446 sec)
36.402... logprob:  0.629651, 0.266927 (1.480 sec)
36.403... logprob:  0.703161, 0.295573 (1.436 sec)
36.404... logprob:  0.706327, 0.304688 (1.435 sec)
36.405... logprob:  0.772138, 0.329427 (1.428 sec)
36.406... logprob:  0.581959, 0.236979 (1.420 sec)
36.407... logprob:  0.769326, 0.330729 (1.428 sec)
36.408... logprob:  0.612100, 0.277344 (1.475 sec)
36.409... logprob:  0.590538, 0.261719 (1.432 sec)
36.410... logprob:  0.767271, 0.326823 (1.453 sec)
36.411... logprob:  0.584345, 0.269531 (1.479 sec)
36.412... logprob:  0.765978, 0.354167 (1.434 sec)
36.413... logprob:  0.669688, 0.307291 (1.440 sec)
36.414... logprob:  0.699793, 0.292969 (1.430 sec)
36.415... logprob:  0.663685, 0.291667 (1.419 sec)
36.416... logprob:  0.639351, 0.296875 (1.432 sec)
36.417... logprob:  0.663300, 0.313802 (1.456 sec)
36.418... logprob:  0.626405, 0.273438 (1.445 sec)
36.419... logprob:  0.667473, 0.265625 (1.446 sec)
36.420... logprob:  0.621046, 0.278646 (1.466 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.416338, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.928278e-03 [9.644315e-08] 
Layer 'conv1' biases: 2.202653e-06 [1.713335e-11] 
Layer 'conv2' weights[0]: 1.924372e-03 [9.626148e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.051158e-10] 
Layer 'conv3' weights[0]: 1.923486e-03 [9.625659e-08] 
Layer 'conv3' biases: 3.666126e-05 [2.828445e-09] 
Layer 'conv4' weights[0]: 1.931641e-03 [9.673770e-08] 
Layer 'conv4' biases: 9.997802e-01 [1.247253e-07] 
Layer 'conv5' weights[0]: 2.134212e-03 [2.237006e-06] 
Layer 'conv5' biases: 9.988708e-01 [2.504529e-06] 
Layer 'fc6' weights[0]: 6.554978e-03 [5.848837e-08] 
Layer 'fc6' biases: 9.999891e-01 [5.554218e-08] 
Layer 'fc7' weights[0]: 6.893371e-03 [1.403806e-07] 
Layer 'fc7' biases: 9.996757e-01 [1.842530e-07] 
Layer 'fc8' weights[0]: 4.797908e-03 [1.139330e-05] 
Layer 'fc8' biases: 2.978222e-02 [2.087769e-05] 
Train error last 800 batches: 0.653406
-------------------------------------------------------
Not saving because 0.416338 > 0.299667 (9.300: -1.18%)
======================================================= (2.395 sec)
36.421... logprob:  0.624485, 0.273437 (1.457 sec)
36.422... logprob:  0.603227, 0.260417 (1.441 sec)
36.423... logprob:  0.679332, 0.281250 (1.425 sec)
36.424... logprob:  0.577091, 0.229167 (1.427 sec)
36.425... logprob:  0.564933, 0.260417 (1.436 sec)
36.426... logprob:  0.709551, 0.329427 (1.441 sec)
36.427... logprob:  0.647154, 0.277344 (1.457 sec)
36.428... logprob:  0.748139, 0.308594 (1.448 sec)
36.429... logprob:  0.553259, 0.244792 (1.435 sec)
36.430... logprob:  0.563147, 0.260417 (1.467 sec)
36.431... logprob:  0.763295, 0.315104 (1.429 sec)
36.432... logprob:  0.616174, 0.281250 (1.422 sec)
36.433... logprob:  0.592838, 0.256510 (1.424 sec)
36.434... logprob:  0.754093, 0.289062 (1.431 sec)
36.435... logprob:  0.733186, 0.311198 (1.429 sec)
36.436... logprob:  0.648052, 0.264323 (1.469 sec)
36.437... logprob:  0.770553, 0.339844 (1.435 sec)
36.438... logprob:  0.713598, 0.298177 (1.431 sec)
36.439... logprob:  0.620719, 0.295573 (1.478 sec)
36.440... logprob:  0.736012, 0.322917 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.503891, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.926353e-03 [9.632704e-08] 
Layer 'conv1' biases: 2.202765e-06 [2.913728e-11] 
Layer 'conv2' weights[0]: 1.922461e-03 [9.614642e-08] 
Layer 'conv2' biases: 9.999996e-01 [4.155125e-10] 
Layer 'conv3' weights[0]: 1.921541e-03 [9.634933e-08] 
Layer 'conv3' biases: 3.666795e-05 [5.495130e-09] 
Layer 'conv4' weights[0]: 1.929701e-03 [9.685766e-08] 
Layer 'conv4' biases: 9.997804e-01 [2.444391e-07] 
Layer 'conv5' weights[0]: 2.132989e-03 [2.858358e-06] 
Layer 'conv5' biases: 9.988620e-01 [3.167645e-06] 
Layer 'fc6' weights[0]: 6.554295e-03 [6.677763e-08] 
Layer 'fc6' biases: 9.999891e-01 [6.731087e-08] 
Layer 'fc7' weights[0]: 6.892649e-03 [1.607864e-07] 
Layer 'fc7' biases: 9.996762e-01 [2.412673e-07] 
Layer 'fc8' weights[0]: 4.803899e-03 [1.345765e-05] 
Layer 'fc8' biases: 2.987071e-02 [3.445775e-05] 
Train error last 800 batches: 0.653173
-------------------------------------------------------
Not saving because 0.503891 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
36.441... logprob:  0.620356, 0.269531 (1.433 sec)
36.442... logprob:  0.564661, 0.244792 (1.436 sec)
36.443... logprob:  0.743479, 0.341146 (1.426 sec)
36.444... logprob:  0.601059, 0.277344 (1.422 sec)
36.445... logprob:  0.685101, 0.286458 (1.481 sec)
36.446... logprob:  0.593510, 0.261719 (1.426 sec)
36.447... logprob:  0.734764, 0.338542 (1.436 sec)
36.448... logprob:  0.560940, 0.244792 (1.472 sec)
36.449... logprob:  0.677056, 0.283854 (1.430 sec)
36.450... logprob:  0.522778, 0.247396 (1.433 sec)
36.451... logprob:  0.765043, 0.322917 (1.430 sec)
36.452... logprob:  0.683432, 0.319010 (1.424 sec)
36.453... logprob:  0.622945, 0.257812 (1.425 sec)
36.454... logprob:  0.690911, 0.303385 (1.476 sec)
36.455... logprob:  0.680642, 0.317708 (1.431 sec)
36.456... logprob:  0.697329, 0.299479 (1.441 sec)
36.457... logprob:  0.655743, 0.298177 (1.470 sec)
36.458... logprob:  0.617867, 0.277344 (1.433 sec)
36.459... logprob:  0.702206, 0.279948 (1.435 sec)
36.460... logprob:  0.477804, 0.203125 (1.423 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.474567, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.924425e-03 [9.628885e-08] 
Layer 'conv1' biases: 2.202866e-06 [2.196223e-11] 
Layer 'conv2' weights[0]: 1.920532e-03 [9.608574e-08] 
Layer 'conv2' biases: 9.999996e-01 [4.166407e-10] 
Layer 'conv3' weights[0]: 1.919616e-03 [9.626347e-08] 
Layer 'conv3' biases: 3.667571e-05 [5.599640e-09] 
Layer 'conv4' weights[0]: 1.927786e-03 [9.690088e-08] 
Layer 'conv4' biases: 9.997818e-01 [2.708538e-07] 
Layer 'conv5' weights[0]: 2.132353e-03 [2.780385e-06] 
Layer 'conv5' biases: 9.988560e-01 [3.139983e-06] 
Layer 'fc6' weights[0]: 6.553638e-03 [6.042820e-08] 
Layer 'fc6' biases: 9.999891e-01 [5.852329e-08] 
Layer 'fc7' weights[0]: 6.891949e-03 [1.491849e-07] 
Layer 'fc7' biases: 9.996758e-01 [2.174500e-07] 
Layer 'fc8' weights[0]: 4.809631e-03 [1.369532e-05] 
Layer 'fc8' biases: 2.991371e-02 [4.093901e-05] 
Train error last 800 batches: 0.653360
-------------------------------------------------------
Not saving because 0.474567 > 0.299667 (9.300: -1.18%)
======================================================= (2.379 sec)
36.461... logprob:  0.646918, 0.272135 (1.428 sec)
36.462... logprob:  0.673358, 0.287760 (1.436 sec)
36.463... logprob:  0.678937, 0.286458 (1.470 sec)
36.464... logprob:  0.739660, 0.305990 (1.439 sec)
36.465... logprob:  0.667794, 0.315104 (1.450 sec)
36.466... logprob:  0.580249, 0.257813 (1.459 sec)
36.467... logprob:  0.702217, 0.312500 (1.444 sec)
36.468... logprob:  0.580589, 0.259115 (1.429 sec)
36.469... logprob:  0.578812, 0.246094 (1.424 sec)
36.470... logprob:  0.628661, 0.265625 (1.420 sec)
36.471... logprob:  0.704968, 0.289062 (1.432 sec)
36.472... logprob:  0.676697, 0.313802 (1.446 sec)
36.473... logprob:  0.638220, 0.289062 (1.455 sec)
36.474... logprob:  0.729703, 0.298177 (1.452 sec)
36.475... logprob:  0.672228, 0.302083 (1.441 sec)
36.476... logprob:  0.796694, 0.346354 (1.464 sec)
36.477... logprob:  0.622746, 0.285156 (1.433 sec)
36.478... logprob:  0.729381, 0.304687 (1.423 sec)
36.479... logprob:  0.551241, 0.268229 (1.424 sec)
36.480... logprob:  0.624116, 0.289062 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.550065, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.922502e-03 [9.615004e-08] 
Layer 'conv1' biases: 2.202950e-06 [1.648517e-11] 
Layer 'conv2' weights[0]: 1.918610e-03 [9.597128e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.343486e-10] 
Layer 'conv3' weights[0]: 1.917701e-03 [9.605819e-08] 
Layer 'conv3' biases: 3.666249e-05 [4.175501e-09] 
Layer 'conv4' weights[0]: 1.925842e-03 [9.653257e-08] 
Layer 'conv4' biases: 9.997840e-01 [1.541460e-07] 
Layer 'conv5' weights[0]: 2.133227e-03 [2.253765e-06] 
Layer 'conv5' biases: 9.988561e-01 [2.459916e-06] 
Layer 'fc6' weights[0]: 6.553014e-03 [5.677979e-08] 
Layer 'fc6' biases: 9.999889e-01 [5.367657e-08] 
Layer 'fc7' weights[0]: 6.891256e-03 [1.339966e-07] 
Layer 'fc7' biases: 9.996759e-01 [1.658359e-07] 
Layer 'fc8' weights[0]: 4.805226e-03 [1.089695e-05] 
Layer 'fc8' biases: 2.991483e-02 [1.508472e-05] 
Train error last 800 batches: 0.653367
-------------------------------------------------------
Not saving because 0.550065 > 0.299667 (9.300: -1.18%)
======================================================= (2.401 sec)
36.481... logprob:  0.661450, 0.263021 (1.442 sec)
36.482... logprob:  0.615703, 0.264323 (1.469 sec)
36.483... logprob:  0.700663, 0.289062 (1.444 sec)
36.484... logprob:  0.679659, 0.295573 (1.437 sec)
36.485... logprob:  0.607651, 0.277344 (1.477 sec)
36.486... logprob:  0.674746, 0.308594 (1.421 sec)
36.487... logprob:  0.781306, 0.351562 (1.427 sec)
36.488... logprob:  0.751356, 0.324219 (1.427 sec)
36.489... logprob:  0.578399, 0.253906 (1.428 sec)
36.490... logprob:  0.694083, 0.303385 (1.424 sec)
36.491... logprob:  0.628220, 0.298177 (1.476 sec)
36.492... logprob:  0.641471, 0.290365 (1.432 sec)
36.493... logprob:  0.764954, 0.307292 (1.431 sec)
36.494... logprob:  0.668924, 0.311198 (1.478 sec)
36.495... logprob:  0.610000, 0.256510 (1.425 sec)
36.496... logprob:  0.724499, 0.316406 (1.462 sec)
36.497... logprob:  0.696101, 0.312500 (1.427 sec)
36.498... logprob:  0.759433, 0.322917 (1.427 sec)
36.499... logprob:  0.773575, 0.330729 (1.421 sec)
36.500... logprob:  0.660059, 0.286458 (1.485 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.434602, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.920582e-03 [9.603138e-08] 
Layer 'conv1' biases: 2.203024e-06 [2.174116e-11] 
Layer 'conv2' weights[0]: 1.916693e-03 [9.585887e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.022029e-10] 
Layer 'conv3' weights[0]: 1.915780e-03 [9.597829e-08] 
Layer 'conv3' biases: 3.668555e-05 [4.605571e-09] 
Layer 'conv4' weights[0]: 1.923937e-03 [9.643059e-08] 
Layer 'conv4' biases: 9.997835e-01 [1.894854e-07] 
Layer 'conv5' weights[0]: 2.131391e-03 [2.892873e-06] 
Layer 'conv5' biases: 9.988782e-01 [3.142921e-06] 
Layer 'fc6' weights[0]: 6.552323e-03 [6.577326e-08] 
Layer 'fc6' biases: 9.999889e-01 [6.553133e-08] 
Layer 'fc7' weights[0]: 6.890571e-03 [1.621966e-07] 
Layer 'fc7' biases: 9.996741e-01 [2.476720e-07] 
Layer 'fc8' weights[0]: 4.760441e-03 [1.374143e-05] 
Layer 'fc8' biases: 2.952456e-02 [3.442338e-05] 
Train error last 800 batches: 0.653960
-------------------------------------------------------
Not saving because 0.434602 > 0.299667 (9.300: -1.18%)
======================================================= (2.349 sec)
36.501... logprob:  0.557220, 0.257812 (1.437 sec)
36.502... logprob:  0.657565, 0.292969 (1.442 sec)
36.503... logprob:  0.620931, 0.289062 (1.481 sec)
36.504... logprob:  0.719107, 0.303385 (1.431 sec)
36.505... logprob:  0.719611, 0.303385 (1.436 sec)
36.506... logprob:  0.548822, 0.235677 (1.431 sec)
36.507... logprob:  0.603857, 0.281250 (1.423 sec)
36.508... logprob:  0.565068, 0.257812 (1.424 sec)
36.509... logprob:  0.594385, 0.268229 (1.472 sec)
36.510... logprob:  0.595415, 0.269531 (1.434 sec)
36.511... logprob:  0.677217, 0.322917 (1.445 sec)
36.512... logprob:  0.779164, 0.317708 (1.459 sec)
36.513... logprob:  0.617558, 0.277344 (1.437 sec)
36.514... logprob:  0.569440, 0.217448 (1.432 sec)
36.515... logprob:  0.701398, 0.303385 (1.421 sec)
36.516... logprob:  0.623584, 0.263021 (1.422 sec)
36.517... logprob:  0.773362, 0.313802 (1.431 sec)
36.518... logprob:  0.707218, 0.309896 (1.451 sec)
36.519... logprob:  0.745716, 0.299479 (1.446 sec)
36.520... logprob:  0.645041, 0.266927 (1.449 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.375757, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.918663e-03 [9.595273e-08] 
Layer 'conv1' biases: 2.203142e-06 [1.787124e-11] 
Layer 'conv2' weights[0]: 1.914781e-03 [9.576988e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.380629e-10] 
Layer 'conv3' weights[0]: 1.913874e-03 [9.588030e-08] 
Layer 'conv3' biases: 3.666983e-05 [4.419815e-09] 
Layer 'conv4' weights[0]: 1.922016e-03 [9.635345e-08] 
Layer 'conv4' biases: 9.997848e-01 [1.745286e-07] 
Layer 'conv5' weights[0]: 2.130755e-03 [2.163492e-06] 
Layer 'conv5' biases: 9.988475e-01 [2.400331e-06] 
Layer 'fc6' weights[0]: 6.551668e-03 [5.923908e-08] 
Layer 'fc6' biases: 9.999889e-01 [5.719709e-08] 
Layer 'fc7' weights[0]: 6.889881e-03 [1.480481e-07] 
Layer 'fc7' biases: 9.996753e-01 [1.911800e-07] 
Layer 'fc8' weights[0]: 4.806041e-03 [1.172386e-05] 
Layer 'fc8' biases: 2.995767e-02 [1.570296e-05] 
Train error last 800 batches: 0.654131
-------------------------------------------------------
Not saving because 0.375757 > 0.299667 (9.300: -1.18%)
======================================================= (2.376 sec)
36.521... logprob:  0.645629, 0.283854 (1.462 sec)
36.522... logprob:  0.721779, 0.348958 (1.465 sec)
36.523... logprob:  0.636913, 0.303385 (1.439 sec)
36.524... logprob:  0.668683, 0.300781 (1.416 sec)
36.525... logprob:  0.639060, 0.304687 (1.425 sec)
36.526... logprob:  0.441889, 0.197917 (1.430 sec)
36.527... logprob:  0.775265, 0.312500 (1.435 sec)
36.528... logprob:  0.620794, 0.263021 (1.461 sec)
36.529... logprob:  0.657504, 0.292969 (1.442 sec)
36.530... logprob:  0.575901, 0.251302 (1.435 sec)
36.531... logprob:  0.625955, 0.240885 (1.474 sec)
36.532... logprob:  0.653458, 0.278646 (1.427 sec)
36.533... logprob:  0.795457, 0.341146 (1.420 sec)
36.534... logprob:  0.478372, 0.212240 (1.463 sec)
36.535... logprob:  0.795629, 0.322917 (1.429 sec)
36.536... logprob:  0.707540, 0.324219 (1.431 sec)
36.537... logprob:  0.672205, 0.300781 (1.473 sec)
36.538... logprob:  0.691459, 0.316406 (1.437 sec)
36.539... logprob:  0.536986, 0.234375 (1.425 sec)
36.540... logprob:  0.640962, 0.265625 (1.482 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.502887, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.916736e-03 [9.587328e-08] 
Layer 'conv1' biases: 2.203171e-06 [1.842821e-11] 
Layer 'conv2' weights[0]: 1.912868e-03 [9.568138e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.349145e-10] 
Layer 'conv3' weights[0]: 1.911959e-03 [9.578211e-08] 
Layer 'conv3' biases: 3.668340e-05 [3.947734e-09] 
Layer 'conv4' weights[0]: 1.920084e-03 [9.625092e-08] 
Layer 'conv4' biases: 9.997839e-01 [1.617827e-07] 
Layer 'conv5' weights[0]: 2.128427e-03 [2.188153e-06] 
Layer 'conv5' biases: 9.988375e-01 [2.369185e-06] 
Layer 'fc6' weights[0]: 6.551003e-03 [5.722947e-08] 
Layer 'fc6' biases: 9.999891e-01 [5.464554e-08] 
Layer 'fc7' weights[0]: 6.889224e-03 [1.367709e-07] 
Layer 'fc7' biases: 9.996758e-01 [1.669259e-07] 
Layer 'fc8' weights[0]: 4.807496e-03 [1.063547e-05] 
Layer 'fc8' biases: 3.000603e-02 [9.915129e-06] 
Train error last 800 batches: 0.653885
-------------------------------------------------------
Not saving because 0.502887 > 0.299667 (9.300: -1.18%)
======================================================= (2.356 sec)
36.541... logprob:  0.618218, 0.260417 (1.431 sec)
36.542... logprob:  0.608832, 0.261719 (1.430 sec)
36.543... logprob:  0.486368, 0.218750 (1.439 sec)
36.544... logprob:  0.569756, 0.246094 (1.430 sec)
36.545... logprob:  0.666263, 0.298177 (1.428 sec)
36.546... logprob:  0.619737, 0.300781 (1.477 sec)
36.547... logprob:  0.668810, 0.308594 (1.431 sec)
36.548... logprob:  0.651983, 0.285156 (1.439 sec)
36.549... logprob:  0.670182, 0.296875 (1.476 sec)
36.550... logprob:  0.563104, 0.238281 (1.424 sec)
36.551... logprob:  0.637961, 0.268229 (1.430 sec)
36.552... logprob:  0.701507, 0.300781 (1.430 sec)
36.553... logprob:  0.537689, 0.239583 (1.420 sec)
36.554... logprob:  0.676144, 0.289062 (1.428 sec)
36.555... logprob:  0.650378, 0.256510 (1.476 sec)
36.556... logprob:  0.572382, 0.273438 (1.429 sec)
36.557... logprob:  0.610324, 0.286458 (1.439 sec)
36.558... logprob:  0.619972, 0.274740 (1.471 sec)
36.559... logprob:  0.652019, 0.270833 (1.429 sec)
36.560... logprob:  0.652351, 0.285156 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.467203, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.914830e-03 [9.577096e-08] 
Layer 'conv1' biases: 2.203277e-06 [1.657042e-11] 
Layer 'conv2' weights[0]: 1.910949e-03 [9.559008e-08] 
Layer 'conv2' biases: 9.999996e-01 [1.835227e-10] 
Layer 'conv3' weights[0]: 1.910049e-03 [9.557259e-08] 
Layer 'conv3' biases: 3.667761e-05 [2.504171e-09] 
Layer 'conv4' weights[0]: 1.918167e-03 [9.603851e-08] 
Layer 'conv4' biases: 9.997853e-01 [9.792192e-08] 
Layer 'conv5' weights[0]: 2.128445e-03 [2.171281e-06] 
Layer 'conv5' biases: 9.988168e-01 [2.379965e-06] 
Layer 'fc6' weights[0]: 6.550332e-03 [5.724041e-08] 
Layer 'fc6' biases: 9.999891e-01 [5.487154e-08] 
Layer 'fc7' weights[0]: 6.888498e-03 [1.368550e-07] 
Layer 'fc7' biases: 9.996764e-01 [1.769392e-07] 
Layer 'fc8' weights[0]: 4.848882e-03 [1.207511e-05] 
Layer 'fc8' biases: 3.031996e-02 [2.356356e-05] 
Train error last 800 batches: 0.653826
-------------------------------------------------------
Not saving because 0.467203 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
36.561... logprob:  0.652102, 0.298177 (1.429 sec)
36.562... logprob:  0.708097, 0.311198 (1.420 sec)
36.563... logprob:  0.581464, 0.261719 (1.439 sec)
36.564... logprob:  0.696581, 0.309896 (1.458 sec)
36.565... logprob:  0.719436, 0.332031 (1.446 sec)
36.566... logprob:  0.609962, 0.248698 (1.446 sec)
36.567... logprob:  0.645898, 0.286458 (1.447 sec)
36.568... logprob:  0.800697, 0.337240 (1.448 sec)
36.569... logprob:  0.792277, 0.305989 (1.436 sec)
36.570... logprob:  0.720699, 0.308594 (1.427 sec)
36.571... logprob:  0.617392, 0.260417 (1.422 sec)
36.572... logprob:  0.739480, 0.338542 (1.459 sec)
36.573... logprob:  0.811832, 0.330729 (1.444 sec)
36.574... logprob:  0.609650, 0.252604 (1.458 sec)
36.575... logprob:  0.552671, 0.256510 (1.445 sec)
36.576... logprob:  0.600352, 0.253906 (1.440 sec)
36.577... logprob:  0.728309, 0.304688 (1.467 sec)
36.578... logprob:  0.587518, 0.247396 (1.429 sec)
36.579... logprob:  0.621514, 0.260417 (1.419 sec)
36.580... logprob:  0.816666, 0.345052 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.439242, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.912907e-03 [9.566988e-08] 
Layer 'conv1' biases: 2.203388e-06 [1.572226e-11] 
Layer 'conv2' weights[0]: 1.909033e-03 [9.548718e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.384820e-10] 
Layer 'conv3' weights[0]: 1.908140e-03 [9.563538e-08] 
Layer 'conv3' biases: 3.671237e-05 [4.668874e-09] 
Layer 'conv4' weights[0]: 1.916262e-03 [9.615959e-08] 
Layer 'conv4' biases: 9.997814e-01 [2.007535e-07] 
Layer 'conv5' weights[0]: 2.123109e-03 [2.624446e-06] 
Layer 'conv5' biases: 9.988585e-01 [2.788551e-06] 
Layer 'fc6' weights[0]: 6.549622e-03 [6.337561e-08] 
Layer 'fc6' biases: 9.999893e-01 [6.323214e-08] 
Layer 'fc7' weights[0]: 6.887795e-03 [1.527963e-07] 
Layer 'fc7' biases: 9.996737e-01 [2.106135e-07] 
Layer 'fc8' weights[0]: 4.763509e-03 [1.270715e-05] 
Layer 'fc8' biases: 2.965350e-02 [2.529782e-05] 
Train error last 800 batches: 0.653674
-------------------------------------------------------
Not saving because 0.439242 > 0.299667 (9.300: -1.18%)
======================================================= (2.358 sec)
36.581... logprob:  0.805541, 0.369792 (1.442 sec)
36.582... logprob:  0.679964, 0.295573 (1.435 sec)
36.583... logprob:  0.819927, 0.348958 (1.474 sec)
36.584... logprob:  0.708196, 0.321615 (1.440 sec)
36.585... logprob:  0.593829, 0.268229 (1.429 sec)
36.586... logprob:  0.537500, 0.234375 (1.480 sec)
36.587... logprob:  0.628224, 0.265625 (1.424 sec)
36.588... logprob:  0.641485, 0.286458 (1.424 sec)
36.589... logprob:  0.628846, 0.295573 (1.430 sec)
36.590... logprob:  0.684968, 0.282552 (1.424 sec)
36.591... logprob:  0.685400, 0.321615 (1.427 sec)
36.592... logprob:  0.644143, 0.283854 (1.477 sec)
36.593... logprob:  0.660025, 0.283854 (1.432 sec)
36.594... logprob:  0.733445, 0.338542 (1.431 sec)
36.595... logprob:  0.636324, 0.282552 (1.484 sec)
36.596... logprob:  0.739923, 0.319010 (1.429 sec)
36.597... logprob:  0.649377, 0.292969 (1.432 sec)
36.598... logprob:  0.639623, 0.281250 (1.431 sec)
36.599... logprob:  0.577859, 0.244792 (1.416 sec)
36.600... logprob:  0.608507, 0.268229 (1.432 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.447458, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.910999e-03 [9.561630e-08] 
Layer 'conv1' biases: 2.203497e-06 [2.524032e-11] 
Layer 'conv2' weights[0]: 1.907122e-03 [9.541194e-08] 
Layer 'conv2' biases: 9.999996e-01 [4.206976e-10] 
Layer 'conv3' weights[0]: 1.906222e-03 [9.557350e-08] 
Layer 'conv3' biases: 3.671519e-05 [5.178826e-09] 
Layer 'conv4' weights[0]: 1.914338e-03 [9.618115e-08] 
Layer 'conv4' biases: 9.997822e-01 [2.338741e-07] 
Layer 'conv5' weights[0]: 2.122514e-03 [3.470724e-06] 
Layer 'conv5' biases: 9.988375e-01 [3.932494e-06] 
Layer 'fc6' weights[0]: 6.548956e-03 [6.792810e-08] 
Layer 'fc6' biases: 9.999892e-01 [6.881309e-08] 
Layer 'fc7' weights[0]: 6.887121e-03 [1.718906e-07] 
Layer 'fc7' biases: 9.996747e-01 [2.868661e-07] 
Layer 'fc8' weights[0]: 4.794175e-03 [1.550025e-05] 
Layer 'fc8' biases: 2.994468e-02 [4.956520e-05] 
Train error last 800 batches: 0.654365
-------------------------------------------------------
Not saving because 0.447458 > 0.299667 (9.300: -1.18%)
======================================================= (2.388 sec)
36.601... logprob:  0.639112, 0.283854 (1.482 sec)
36.602... logprob:  0.602494, 0.291667 (1.431 sec)
36.603... logprob:  0.553358, 0.244792 (1.448 sec)
36.604... logprob:  0.669632, 0.272135 (1.466 sec)
36.605... logprob:  0.719185, 0.305990 (1.431 sec)
36.606... logprob:  0.565968, 0.250000 (1.438 sec)
36.607... logprob:  0.658090, 0.302083 (1.427 sec)
36.608... logprob:  0.553603, 0.250000 (1.426 sec)
36.609... logprob:  0.621763, 0.299479 (1.429 sec)
36.610... logprob:  0.636089, 0.287760 (1.500 sec)
36.611... logprob:  0.658569, 0.279948 (1.437 sec)
36.612... logprob:  0.685727, 0.291667 (1.450 sec)
36.613... logprob:  0.484629, 0.221354 (1.458 sec)
36.614... logprob:  0.695806, 0.285156 (1.442 sec)
36.615... logprob:  0.589688, 0.243490 (1.434 sec)
36.616... logprob:  0.657456, 0.303385 (1.423 sec)
36.617... logprob:  0.616818, 0.281250 (1.420 sec)
36.618... logprob:  0.778978, 0.358073 (1.431 sec)
36.619... logprob:  0.635099, 0.285156 (1.453 sec)
36.620... logprob:  0.812310, 0.343750 (1.461 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.364092, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.909092e-03 [9.545180e-08] 
Layer 'conv1' biases: 2.203576e-06 [2.560113e-11] 
Layer 'conv2' weights[0]: 1.905221e-03 [9.528762e-08] 
Layer 'conv2' biases: 9.999996e-01 [4.728854e-10] 
Layer 'conv3' weights[0]: 1.904310e-03 [9.551059e-08] 
Layer 'conv3' biases: 3.669786e-05 [5.383596e-09] 
Layer 'conv4' weights[0]: 1.912417e-03 [9.606305e-08] 
Layer 'conv4' biases: 9.997847e-01 [2.468633e-07] 
Layer 'conv5' weights[0]: 2.123410e-03 [3.281423e-06] 
Layer 'conv5' biases: 9.987986e-01 [3.664488e-06] 
Layer 'fc6' weights[0]: 6.548334e-03 [6.389521e-08] 
Layer 'fc6' biases: 9.999891e-01 [6.520746e-08] 
Layer 'fc7' weights[0]: 6.886437e-03 [1.574938e-07] 
Layer 'fc7' biases: 9.996769e-01 [2.350552e-07] 
Layer 'fc8' weights[0]: 4.866159e-03 [1.309714e-05] 
Layer 'fc8' biases: 3.060148e-02 [3.227447e-05] 
Train error last 800 batches: 0.654524
-------------------------------------------------------
Not saving because 0.364092 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
36.621... logprob:  0.663275, 0.294271 (1.454 sec)
36.622... logprob:  0.587854, 0.277344 (1.445 sec)
36.623... logprob:  0.577495, 0.250000 (1.467 sec)
36.624... logprob:  0.641594, 0.295573 (1.430 sec)
36.625... logprob:  0.707725, 0.320312 (1.425 sec)
36.626... logprob:  0.571792, 0.244792 (1.426 sec)
36.627... logprob:  0.720913, 0.320312 (1.434 sec)
36.628... logprob:  0.736162, 0.329427 (1.438 sec)
36.629... logprob:  0.582945, 0.282552 (1.468 sec)
36.630... logprob:  0.668668, 0.296875 (1.445 sec)
36.631... logprob:  0.880732, 0.365885 (1.431 sec)
36.632... logprob:  0.508877, 0.213542 (1.478 sec)
36.633... logprob:  0.655910, 0.308594 (1.429 sec)
36.634... logprob:  0.860975, 0.359375 (1.419 sec)
36.635... logprob:  0.598827, 0.247396 (1.429 sec)
36.636... logprob:  0.713898, 0.273438 (1.430 sec)
36.637... logprob:  0.591019, 0.281250 (1.429 sec)
36.638... logprob:  0.730941, 0.342448 (1.479 sec)
36.639... logprob:  0.636967, 0.281250 (1.434 sec)
36.640... logprob:  0.736576, 0.311198 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.555657, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.907176e-03 [9.534335e-08] 
Layer 'conv1' biases: 2.203703e-06 [3.320338e-11] 
Layer 'conv2' weights[0]: 1.903315e-03 [9.518171e-08] 
Layer 'conv2' biases: 9.999996e-01 [4.866739e-10] 
Layer 'conv3' weights[0]: 1.902416e-03 [9.542628e-08] 
Layer 'conv3' biases: 3.672582e-05 [5.830585e-09] 
Layer 'conv4' weights[0]: 1.910511e-03 [9.597482e-08] 
Layer 'conv4' biases: 9.997818e-01 [2.792786e-07] 
Layer 'conv5' weights[0]: 2.118708e-03 [3.640142e-06] 
Layer 'conv5' biases: 9.988390e-01 [4.122026e-06] 
Layer 'fc6' weights[0]: 6.547683e-03 [6.921203e-08] 
Layer 'fc6' biases: 9.999891e-01 [7.166163e-08] 
Layer 'fc7' weights[0]: 6.885754e-03 [1.723694e-07] 
Layer 'fc7' biases: 9.996740e-01 [2.824549e-07] 
Layer 'fc8' weights[0]: 4.788185e-03 [1.513456e-05] 
Layer 'fc8' biases: 2.999536e-02 [4.557994e-05] 
Train error last 800 batches: 0.654479
-------------------------------------------------------
Not saving because 0.555657 > 0.299667 (9.300: -1.18%)
======================================================= (2.365 sec)
36.641... logprob:  0.635397, 0.282552 (1.480 sec)
36.642... logprob:  0.748569, 0.305990 (1.429 sec)
36.643... logprob:  0.808862, 0.369792 (1.433 sec)
36.644... logprob:  0.548450, 0.235677 (1.426 sec)
36.645... logprob:  0.565760, 0.242187 (1.428 sec)
36.646... logprob:  0.639046, 0.263021 (1.424 sec)
36.647... logprob:  0.722474, 0.299479 (1.481 sec)
36.648... logprob:  0.663212, 0.304688 (1.453 sec)
36.649... logprob:  0.560882, 0.261719 (1.437 sec)
36.650... logprob:  0.656914, 0.289062 (1.471 sec)
36.651... logprob:  0.644245, 0.265625 (1.424 sec)
36.652... logprob:  0.731864, 0.312500 (1.432 sec)
36.653... logprob:  0.758615, 0.325521 (1.428 sec)
36.654... logprob:  0.652744, 0.309896 (1.418 sec)
36.655... logprob:  0.658341, 0.282552 (1.429 sec)
36.656... logprob:  0.673976, 0.309896 (1.479 sec)
36.657... logprob:  0.699983, 0.300781 (1.438 sec)
36.658... logprob:  0.571254, 0.253906 (1.449 sec)
36.659... logprob:  0.625554, 0.286458 (1.457 sec)
36.660... logprob:  0.688386, 0.304687 (1.440 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.468807, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.905277e-03 [9.529854e-08] 
Layer 'conv1' biases: 2.203781e-06 [2.186905e-11] 
Layer 'conv2' weights[0]: 1.901411e-03 [9.512261e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.416029e-10] 
Layer 'conv3' weights[0]: 1.900517e-03 [9.520455e-08] 
Layer 'conv3' biases: 3.674314e-05 [3.917230e-09] 
Layer 'conv4' weights[0]: 1.908592e-03 [9.575348e-08] 
Layer 'conv4' biases: 9.997800e-01 [1.612390e-07] 
Layer 'conv5' weights[0]: 2.115873e-03 [2.812942e-06] 
Layer 'conv5' biases: 9.988633e-01 [3.028399e-06] 
Layer 'fc6' weights[0]: 6.547009e-03 [5.967933e-08] 
Layer 'fc6' biases: 9.999894e-01 [5.735137e-08] 
Layer 'fc7' weights[0]: 6.885108e-03 [1.473731e-07] 
Layer 'fc7' biases: 9.996728e-01 [2.060963e-07] 
Layer 'fc8' weights[0]: 4.751928e-03 [1.327929e-05] 
Layer 'fc8' biases: 2.967720e-02 [2.590904e-05] 
Train error last 800 batches: 0.654733
-------------------------------------------------------
Not saving because 0.468807 > 0.299667 (9.300: -1.18%)
======================================================= (2.394 sec)
36.661... logprob:  0.519718, 0.227865 (1.439 sec)
36.662... logprob:  0.710682, 0.298177 (1.427 sec)
36.663... logprob:  0.549333, 0.234375 (1.430 sec)
36.664... logprob:  0.539113, 0.236979 (1.432 sec)
36.665... logprob:  0.603392, 0.259115 (1.454 sec)
36.666... logprob:  0.603890, 0.270833 (1.451 sec)
36.667... logprob:  0.695119, 0.291667 (1.453 sec)
36.668... logprob:  0.664693, 0.265625 (1.453 sec)
36.669... logprob:  0.647500, 0.277344 (1.456 sec)
36.670... logprob:  0.580725, 0.248698 (1.431 sec)
36.671... logprob:  0.585495, 0.239583 (1.430 sec)
36.672... logprob:  0.657012, 0.303385 (1.432 sec)
36.673... logprob:  0.609213, 0.270833 (1.435 sec)
36.674... logprob:  0.724883, 0.308594 (1.437 sec)
36.675... logprob:  0.569921, 0.263021 (1.459 sec)
36.676... logprob:  0.691194, 0.296875 (1.448 sec)
36.677... logprob:  0.690862, 0.315104 (1.441 sec)
36.678... logprob:  0.739588, 0.326823 (1.476 sec)
36.679... logprob:  0.699234, 0.311198 (1.430 sec)
36.680... logprob:  0.617304, 0.238281 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.392560, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.903370e-03 [9.522041e-08] 
Layer 'conv1' biases: 2.204007e-06 [1.717774e-11] 
Layer 'conv2' weights[0]: 1.899506e-03 [9.502337e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.355096e-10] 
Layer 'conv3' weights[0]: 1.898627e-03 [9.503964e-08] 
Layer 'conv3' biases: 3.672730e-05 [2.993569e-09] 
Layer 'conv4' weights[0]: 1.906685e-03 [9.550700e-08] 
Layer 'conv4' biases: 9.997822e-01 [1.104018e-07] 
Layer 'conv5' weights[0]: 2.117088e-03 [2.275337e-06] 
Layer 'conv5' biases: 9.988238e-01 [2.469886e-06] 
Layer 'fc6' weights[0]: 6.546337e-03 [5.810983e-08] 
Layer 'fc6' biases: 9.999893e-01 [5.628987e-08] 
Layer 'fc7' weights[0]: 6.884436e-03 [1.389251e-07] 
Layer 'fc7' biases: 9.996755e-01 [1.674840e-07] 
Layer 'fc8' weights[0]: 4.828402e-03 [1.072320e-05] 
Layer 'fc8' biases: 3.031251e-02 [5.229671e-06] 
Train error last 800 batches: 0.654506
-------------------------------------------------------
Not saving because 0.392560 > 0.299667 (9.300: -1.18%)
======================================================= (2.378 sec)
36.681... logprob:  0.540911, 0.252604 (1.437 sec)
36.682... logprob:  0.618256, 0.259115 (1.439 sec)
36.683... logprob:  0.666191, 0.304687 (1.432 sec)
36.684... logprob:  0.576522, 0.282552 (1.467 sec)
36.685... logprob:  0.595692, 0.250000 (1.441 sec)
36.686... logprob:  0.583744, 0.272135 (1.450 sec)
36.687... logprob:  0.525690, 0.264323 (1.483 sec)
36.688... logprob:  0.679256, 0.309896 (1.431 sec)
36.689... logprob:  0.719467, 0.316406 (1.425 sec)
36.690... logprob:  0.730443, 0.295573 (1.431 sec)
36.691... logprob:  0.809730, 0.321615 (1.435 sec)
36.692... logprob:  0.546573, 0.251302 (1.432 sec)
36.693... logprob:  0.681521, 0.309896 (1.480 sec)
36.694... logprob:  0.565954, 0.238281 (1.426 sec)
36.695... logprob:  0.628548, 0.279948 (1.435 sec)
36.696... logprob:  0.739204, 0.286458 (1.476 sec)
36.697... logprob:  0.713476, 0.303385 (1.432 sec)
36.698... logprob:  0.749331, 0.335937 (1.430 sec)
36.699... logprob:  0.617329, 0.277344 (1.427 sec)
36.700... logprob:  0.665563, 0.313802 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.434826, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.901462e-03 [9.507386e-08] 
Layer 'conv1' biases: 2.204194e-06 [3.137467e-11] 
Layer 'conv2' weights[0]: 1.897617e-03 [9.490821e-08] 
Layer 'conv2' biases: 9.999996e-01 [5.131878e-10] 
Layer 'conv3' weights[0]: 1.896722e-03 [9.520121e-08] 
Layer 'conv3' biases: 3.671426e-05 [6.574790e-09] 
Layer 'conv4' weights[0]: 1.904779e-03 [9.583369e-08] 
Layer 'conv4' biases: 9.997822e-01 [2.990569e-07] 
Layer 'conv5' weights[0]: 2.115947e-03 [3.139243e-06] 
Layer 'conv5' biases: 9.988156e-01 [3.489943e-06] 
Layer 'fc6' weights[0]: 6.545664e-03 [6.223676e-08] 
Layer 'fc6' biases: 9.999893e-01 [6.259634e-08] 
Layer 'fc7' weights[0]: 6.883738e-03 [1.537301e-07] 
Layer 'fc7' biases: 9.996761e-01 [2.284909e-07] 
Layer 'fc8' weights[0]: 4.854922e-03 [1.262992e-05] 
Layer 'fc8' biases: 3.060221e-02 [3.012229e-05] 
Train error last 800 batches: 0.655051
-------------------------------------------------------
Not saving because 0.434826 > 0.299667 (9.300: -1.18%)
======================================================= (2.351 sec)
36.701... logprob:  0.701044, 0.313802 (1.431 sec)
36.702... logprob:  0.787378, 0.322917 (1.481 sec)
36.703... logprob:  0.606924, 0.255208 (1.431 sec)
36.704... logprob:  0.618518, 0.273437 (1.440 sec)
36.705... logprob:  0.625879, 0.279948 (1.468 sec)
36.706... logprob:  0.622866, 0.278646 (1.430 sec)
36.707... logprob:  0.621242, 0.266927 (1.441 sec)
36.708... logprob:  0.697934, 0.298177 (1.425 sec)
36.709... logprob:  0.624284, 0.287760 (1.416 sec)
36.710... logprob:  0.775931, 0.308594 (1.432 sec)
36.711... logprob:  0.707250, 0.308594 (1.460 sec)
36.712... logprob:  0.578930, 0.278646 (1.440 sec)
36.713... logprob:  0.782842, 0.350260 (1.451 sec)
36.714... logprob:  0.662171, 0.307292 (1.446 sec)
36.715... logprob:  0.671366, 0.286458 (1.452 sec)
36.716... logprob:  0.564213, 0.229167 (1.430 sec)
36.717... logprob:  0.701234, 0.290365 (1.419 sec)
36.718... logprob:  0.747999, 0.296875 (1.423 sec)
36.719... logprob:  0.563154, 0.253906 (1.431 sec)
36.720... logprob:  0.715411, 0.308594 (1.442 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.487120, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.899565e-03 [9.499338e-08] 
Layer 'conv1' biases: 2.204326e-06 [1.657494e-11] 
Layer 'conv2' weights[0]: 1.895715e-03 [9.481704e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.658630e-10] 
Layer 'conv3' weights[0]: 1.894825e-03 [9.483885e-08] 
Layer 'conv3' biases: 3.672100e-05 [3.100392e-09] 
Layer 'conv4' weights[0]: 1.902863e-03 [9.527886e-08] 
Layer 'conv4' biases: 9.997794e-01 [1.193281e-07] 
Layer 'conv5' weights[0]: 2.111418e-03 [2.742326e-06] 
Layer 'conv5' biases: 9.988686e-01 [3.034075e-06] 
Layer 'fc6' weights[0]: 6.545007e-03 [6.245019e-08] 
Layer 'fc6' biases: 9.999893e-01 [6.148267e-08] 
Layer 'fc7' weights[0]: 6.883042e-03 [1.500081e-07] 
Layer 'fc7' biases: 9.996724e-01 [2.117743e-07] 
Layer 'fc8' weights[0]: 4.764937e-03 [1.252020e-05] 
Layer 'fc8' biases: 2.992516e-02 [2.642577e-05] 
Train error last 800 batches: 0.655085
-------------------------------------------------------
Not saving because 0.487120 > 0.299667 (9.300: -1.18%)
======================================================= (2.350 sec)
36.721... logprob:  0.669657, 0.290365 (1.456 sec)
36.722... logprob:  0.741011, 0.307292 (1.456 sec)
36.723... logprob:  0.672493, 0.287760 (1.447 sec)
36.724... logprob:  0.678691, 0.312500 (1.480 sec)
36.725... logprob:  0.658461, 0.277344 (1.432 sec)
36.726... logprob:  0.595641, 0.264323 (1.419 sec)
36.727... logprob:  0.627253, 0.296875 (1.423 sec)
36.728... logprob:  0.584304, 0.279948 (1.432 sec)
36.729... logprob:  0.710238, 0.292969 (1.426 sec)
36.730... logprob:  0.690872, 0.303385 (1.599 sec)
36.731... logprob:  0.712604, 0.304687 (1.444 sec)
36.732... logprob:  0.586753, 0.282552 (1.436 sec)
36.733... logprob:  0.767140, 0.322917 (1.481 sec)
36.734... logprob:  0.600037, 0.264323 (1.424 sec)
36.735... logprob:  0.829895, 0.341146 (1.425 sec)
36.736... logprob:  0.828988, 0.355469 (1.430 sec)
36.737... logprob:  0.817062, 0.351562 (1.425 sec)
36.738... logprob:  0.639699, 0.287760 (1.425 sec)
36.739... logprob:  0.682958, 0.308594 (1.474 sec)
36.740... logprob:  0.548021, 0.253906 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.512655, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.897664e-03 [9.490019e-08] 
Layer 'conv1' biases: 2.204445e-06 [1.623610e-11] 
Layer 'conv2' weights[0]: 1.893821e-03 [9.472316e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.463666e-10] 
Layer 'conv3' weights[0]: 1.892940e-03 [9.477346e-08] 
Layer 'conv3' biases: 3.671736e-05 [3.074833e-09] 
Layer 'conv4' weights[0]: 1.900975e-03 [9.519821e-08] 
Layer 'conv4' biases: 9.997789e-01 [1.127901e-07] 
Layer 'conv5' weights[0]: 2.109592e-03 [2.380468e-06] 
Layer 'conv5' biases: 9.988763e-01 [2.487391e-06] 
Layer 'fc6' weights[0]: 6.544359e-03 [5.959268e-08] 
Layer 'fc6' biases: 9.999894e-01 [5.724597e-08] 
Layer 'fc7' weights[0]: 6.882350e-03 [1.452702e-07] 
Layer 'fc7' biases: 9.996717e-01 [1.964168e-07] 
Layer 'fc8' weights[0]: 4.750614e-03 [1.215987e-05] 
Layer 'fc8' biases: 2.980459e-02 [2.990811e-05] 
Train error last 800 batches: 0.655819
-------------------------------------------------------
Not saving because 0.512655 > 0.299667 (9.300: -1.18%)
======================================================= (2.349 sec)
36.741... logprob:  0.612747, 0.279948 (1.436 sec)
36.742... logprob:  0.635590, 0.285156 (1.486 sec)
36.743... logprob:  0.619206, 0.279948 (1.432 sec)
36.744... logprob:  0.784068, 0.322917 (1.430 sec)
36.745... logprob:  0.652473, 0.282552 (1.434 sec)
36.746... logprob:  0.679969, 0.309896 (1.425 sec)
36.747... logprob:  0.705903, 0.312500 (1.436 sec)
36.748... logprob:  0.655849, 0.307292 (1.487 sec)
36.749... logprob:  0.636419, 0.282552 (1.433 sec)
36.750... logprob:  0.706404, 0.315104 (1.441 sec)
36.751... logprob:  0.564936, 0.276042 (1.484 sec)
36.752... logprob:  0.680852, 0.303385 (1.431 sec)
36.753... logprob:  0.604837, 0.264323 (1.437 sec)
36.754... logprob:  0.672706, 0.302083 (1.431 sec)
36.755... logprob:  0.694394, 0.303385 (1.423 sec)
36.756... logprob:  0.598032, 0.264323 (1.434 sec)
36.757... logprob:  0.812952, 0.337239 (1.466 sec)
36.758... logprob:  0.698587, 0.291667 (1.440 sec)
36.759... logprob:  0.652298, 0.291667 (1.446 sec)
36.760... logprob:  0.595557, 0.264323 (1.451 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.521229, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.895774e-03 [9.485603e-08] 
Layer 'conv1' biases: 2.204526e-06 [1.867806e-11] 
Layer 'conv2' weights[0]: 1.891915e-03 [9.465342e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.738075e-10] 
Layer 'conv3' weights[0]: 1.891038e-03 [9.469209e-08] 
Layer 'conv3' biases: 3.670844e-05 [3.446340e-09] 
Layer 'conv4' weights[0]: 1.899064e-03 [9.516978e-08] 
Layer 'conv4' biases: 9.997810e-01 [1.409478e-07] 
Layer 'conv5' weights[0]: 2.110340e-03 [2.151644e-06] 
Layer 'conv5' biases: 9.988522e-01 [2.365235e-06] 
Layer 'fc6' weights[0]: 6.543698e-03 [5.716439e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.402742e-08] 
Layer 'fc7' weights[0]: 6.881640e-03 [1.385915e-07] 
Layer 'fc7' biases: 9.996727e-01 [1.728876e-07] 
Layer 'fc8' weights[0]: 4.801783e-03 [1.128333e-05] 
Layer 'fc8' biases: 3.025728e-02 [1.460799e-05] 
Train error last 800 batches: 0.655789
-------------------------------------------------------
Not saving because 0.521229 > 0.299667 (9.300: -1.18%)
======================================================= (2.372 sec)
36.761... logprob:  0.673828, 0.269531 (1.450 sec)
36.762... logprob:  0.790792, 0.348958 (1.458 sec)
36.763... logprob:  0.731751, 0.319010 (1.445 sec)
36.764... logprob:  0.681393, 0.308594 (1.431 sec)
36.765... logprob:  0.547351, 0.235677 (1.437 sec)
36.766... logprob:  0.849527, 0.328125 (1.455 sec)
36.767... logprob:  0.596587, 0.252604 (1.448 sec)
36.768... logprob:  0.646906, 0.285156 (1.457 sec)
36.769... logprob:  0.705956, 0.300781 (1.464 sec)
36.770... logprob:  0.674561, 0.295573 (1.474 sec)
36.771... logprob:  0.713701, 0.316406 (1.452 sec)
36.772... logprob:  0.567316, 0.243490 (1.436 sec)
36.773... logprob:  0.780861, 0.302083 (1.439 sec)
36.774... logprob:  0.605126, 0.265625 (1.456 sec)
36.775... logprob:  0.589082, 0.246094 (1.453 sec)
36.776... logprob:  0.636912, 0.286458 (1.477 sec)
36.777... logprob:  0.605021, 0.246094 (1.472 sec)
36.778... logprob:  0.694408, 0.311198 (1.456 sec)
36.779... logprob:  0.696118, 0.307292 (1.480 sec)
36.780... logprob:  0.731714, 0.316406 (1.450 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.521618, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.893870e-03 [9.472202e-08] 
Layer 'conv1' biases: 2.204643e-06 [1.828587e-11] 
Layer 'conv2' weights[0]: 1.890038e-03 [9.454534e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.592919e-10] 
Layer 'conv3' weights[0]: 1.889133e-03 [9.460876e-08] 
Layer 'conv3' biases: 3.670714e-05 [3.533623e-09] 
Layer 'conv4' weights[0]: 1.897175e-03 [9.509334e-08] 
Layer 'conv4' biases: 9.997787e-01 [1.441862e-07] 
Layer 'conv5' weights[0]: 2.106367e-03 [2.051719e-06] 
Layer 'conv5' biases: 9.988680e-01 [2.259626e-06] 
Layer 'fc6' weights[0]: 6.543031e-03 [5.802581e-08] 
Layer 'fc6' biases: 9.999893e-01 [5.483967e-08] 
Layer 'fc7' weights[0]: 6.880962e-03 [1.441542e-07] 
Layer 'fc7' biases: 9.996715e-01 [1.856592e-07] 
Layer 'fc8' weights[0]: 4.777402e-03 [1.259113e-05] 
Layer 'fc8' biases: 3.003510e-02 [2.936019e-05] 
Train error last 800 batches: 0.656097
-------------------------------------------------------
Not saving because 0.521618 > 0.299667 (9.300: -1.18%)
======================================================= (2.389 sec)
36.781... logprob:  0.607170, 0.261719 (1.445 sec)
36.782... logprob:  0.535765, 0.230469 (1.448 sec)
36.783... logprob:  0.847979, 0.330729 (1.456 sec)
36.784... logprob:  0.730768, 0.341146 (1.455 sec)
36.785... logprob:  0.800329, 0.358073 (1.480 sec)
36.786... logprob:  0.621102, 0.261719 (1.461 sec)
36.787... logprob:  0.796022, 0.339844 (1.454 sec)
36.788... logprob:  0.756545, 0.337240 (1.488 sec)
36.789... logprob:  0.609800, 0.285156 (1.445 sec)
36.790... logprob:  0.646917, 0.299479 (1.441 sec)
36.791... logprob:  0.555352, 0.238281 (1.445 sec)
36.792... logprob:  0.579864, 0.260417 (1.461 sec)
36.793... logprob:  0.608165, 0.247396 (1.445 sec)
36.794... logprob:  0.572405, 0.240885 (1.483 sec)
36.795... logprob:  0.623876, 0.276042 (1.462 sec)
36.796... logprob:  0.691258, 0.300781 (1.451 sec)
36.797... logprob:  0.575623, 0.236979 (1.490 sec)
36.798... logprob:  0.541174, 0.253906 (1.446 sec)
36.799... logprob:  0.553560, 0.269531 (1.443 sec)
36.800... logprob:  0.630282, 0.269531 (1.398 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.443174, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.891982e-03 [9.470453e-08] 
Layer 'conv1' biases: 2.204724e-06 [3.710468e-11] 
Layer 'conv2' weights[0]: 1.888143e-03 [9.448925e-08] 
Layer 'conv2' biases: 9.999996e-01 [7.309609e-10] 
Layer 'conv3' weights[0]: 1.887254e-03 [9.513008e-08] 
Layer 'conv3' biases: 3.667724e-05 [1.001356e-08] 
Layer 'conv4' weights[0]: 1.895278e-03 [9.610263e-08] 
Layer 'conv4' biases: 9.997811e-01 [4.069217e-07] 
Layer 'conv5' weights[0]: 2.107641e-03 [5.562463e-06] 
Layer 'conv5' biases: 9.988369e-01 [6.265566e-06] 
Layer 'fc6' weights[0]: 6.542360e-03 [8.190547e-08] 
Layer 'fc6' biases: 9.999891e-01 [8.819579e-08] 
Layer 'fc7' weights[0]: 6.880224e-03 [2.172030e-07] 
Layer 'fc7' biases: 9.996732e-01 [4.253755e-07] 
Layer 'fc8' weights[0]: 4.819425e-03 [2.114682e-05] 
Layer 'fc8' biases: 3.044567e-02 [8.061563e-05] 
Train error last 800 batches: 0.656274
-------------------------------------------------------
Not saving because 0.443174 > 0.299667 (9.300: -1.18%)
======================================================= (2.344 sec)
37.1... logprob:  0.628862, 0.286458 (1.407 sec)
37.2... logprob:  0.721897, 0.321615 (1.449 sec)
37.3... logprob:  0.617895, 0.265625 (1.422 sec)
37.4... logprob:  0.672965, 0.328125 (1.404 sec)
37.5... logprob:  0.757421, 0.315104 (1.431 sec)
37.6... logprob:  0.741690, 0.309896 (1.387 sec)
37.7... logprob:  0.622949, 0.286458 (1.418 sec)
37.8... logprob:  0.612670, 0.256510 (1.393 sec)
37.9... logprob:  0.592301, 0.276042 (1.403 sec)
37.10... logprob:  0.655674, 0.304688 (1.407 sec)
37.11... logprob:  0.500527, 0.222656 (1.443 sec)
37.12... logprob:  0.658768, 0.278646 (1.393 sec)
37.13... logprob:  0.659770, 0.276042 (1.420 sec)
37.14... logprob:  0.620314, 0.250000 (1.399 sec)
37.15... logprob:  0.595285, 0.260417 (1.408 sec)
37.16... logprob:  0.644039, 0.279948 (1.402 sec)
37.17... logprob:  0.720185, 0.302083 (1.387 sec)
37.18... logprob:  0.640453, 0.278646 (1.394 sec)
37.19... logprob:  0.581598, 0.277344 (1.395 sec)
37.20... logprob:  0.612298, 0.296875 (1.397 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.414070, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.890089e-03 [9.453578e-08] 
Layer 'conv1' biases: 2.204833e-06 [1.507187e-11] 
Layer 'conv2' weights[0]: 1.886262e-03 [9.435413e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.706223e-10] 
Layer 'conv3' weights[0]: 1.885374e-03 [9.442055e-08] 
Layer 'conv3' biases: 3.665514e-05 [3.797238e-09] 
Layer 'conv4' weights[0]: 1.893380e-03 [9.491998e-08] 
Layer 'conv4' biases: 9.997835e-01 [1.433536e-07] 
Layer 'conv5' weights[0]: 2.108895e-03 [2.111674e-06] 
Layer 'conv5' biases: 9.988065e-01 [2.253250e-06] 
Layer 'fc6' weights[0]: 6.541692e-03 [5.592000e-08] 
Layer 'fc6' biases: 9.999887e-01 [5.306951e-08] 
Layer 'fc7' weights[0]: 6.879536e-03 [1.344817e-07] 
Layer 'fc7' biases: 9.996744e-01 [1.744140e-07] 
Layer 'fc8' weights[0]: 4.870850e-03 [1.112294e-05] 
Layer 'fc8' biases: 3.088793e-02 [1.893715e-05] 
Train error last 800 batches: 0.656652
-------------------------------------------------------
Not saving because 0.414070 > 0.299667 (9.300: -1.18%)
======================================================= (2.391 sec)
37.21... logprob:  0.633500, 0.278646 (1.404 sec)
37.22... logprob:  0.701861, 0.311198 (1.416 sec)
37.23... logprob:  0.751464, 0.322917 (1.414 sec)
37.24... logprob:  0.583353, 0.236979 (1.411 sec)
37.25... logprob:  0.608523, 0.274740 (1.403 sec)
37.26... logprob:  0.693334, 0.328125 (1.436 sec)
37.27... logprob:  0.622597, 0.276042 (1.384 sec)
37.28... logprob:  0.739522, 0.325521 (1.406 sec)
37.29... logprob:  0.541196, 0.250000 (1.414 sec)
37.30... logprob:  0.529839, 0.247396 (1.410 sec)
37.31... logprob:  0.693637, 0.273438 (1.397 sec)
37.32... logprob:  0.643160, 0.263021 (1.379 sec)
37.33... logprob:  0.770728, 0.325521 (1.440 sec)
37.34... logprob:  0.714831, 0.291667 (1.384 sec)
37.35... logprob:  0.592028, 0.290365 (1.395 sec)
37.36... logprob:  0.758219, 0.351562 (1.394 sec)
37.37... logprob:  0.733571, 0.333333 (1.397 sec)
37.38... logprob:  0.662789, 0.303385 (1.389 sec)
37.39... logprob:  0.770756, 0.348958 (1.427 sec)
37.40... logprob:  0.810441, 0.328125 (1.408 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.553490, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.888195e-03 [9.440128e-08] 
Layer 'conv1' biases: 2.204885e-06 [3.778736e-11] 
Layer 'conv2' weights[0]: 1.884363e-03 [9.424364e-08] 
Layer 'conv2' biases: 9.999996e-01 [7.380793e-10] 
Layer 'conv3' weights[0]: 1.883494e-03 [9.488900e-08] 
Layer 'conv3' biases: 3.668410e-05 [9.598997e-09] 
Layer 'conv4' weights[0]: 1.891492e-03 [9.569527e-08] 
Layer 'conv4' biases: 9.997816e-01 [4.141506e-07] 
Layer 'conv5' weights[0]: 2.105114e-03 [4.696282e-06] 
Layer 'conv5' biases: 9.988375e-01 [5.364670e-06] 
Layer 'fc6' weights[0]: 6.541067e-03 [8.079677e-08] 
Layer 'fc6' biases: 9.999889e-01 [8.780057e-08] 
Layer 'fc7' weights[0]: 6.878879e-03 [2.105138e-07] 
Layer 'fc7' biases: 9.996724e-01 [3.906849e-07] 
Layer 'fc8' weights[0]: 4.815139e-03 [1.974942e-05] 
Layer 'fc8' biases: 3.044012e-02 [6.846934e-05] 
Train error last 800 batches: 0.657168
-------------------------------------------------------
Not saving because 0.553490 > 0.299667 (9.300: -1.18%)
======================================================= (2.371 sec)
37.41... logprob:  0.535131, 0.227865 (1.421 sec)
37.42... logprob:  0.563760, 0.251302 (1.410 sec)
37.43... logprob:  0.658275, 0.296875 (1.401 sec)
37.44... logprob:  0.721601, 0.326823 (1.431 sec)
37.45... logprob:  0.716497, 0.329427 (1.381 sec)
37.46... logprob:  0.654830, 0.298177 (1.400 sec)
37.47... logprob:  0.543852, 0.255208 (1.388 sec)
37.48... logprob:  0.641112, 0.283854 (1.417 sec)
37.49... logprob:  0.750196, 0.319010 (1.410 sec)
37.50... logprob:  0.571538, 0.272135 (1.420 sec)
37.51... logprob:  0.650119, 0.286458 (1.413 sec)
37.52... logprob:  0.723632, 0.315104 (1.394 sec)
37.53... logprob:  0.564577, 0.260417 (1.436 sec)
37.54... logprob:  0.678759, 0.309896 (1.381 sec)
37.55... logprob:  0.559717, 0.270833 (1.395 sec)
37.56... logprob:  0.727736, 0.286458 (1.400 sec)
37.57... logprob:  0.761767, 0.348958 (1.423 sec)
37.58... logprob:  0.688189, 0.292969 (1.396 sec)
37.59... logprob:  0.542377, 0.248698 (1.460 sec)
37.60... logprob:  0.741273, 0.324219 (1.419 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.395417, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.886314e-03 [9.435406e-08] 
Layer 'conv1' biases: 2.204982e-06 [1.416911e-11] 
Layer 'conv2' weights[0]: 1.882488e-03 [9.416925e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.287177e-10] 
Layer 'conv3' weights[0]: 1.881603e-03 [9.420965e-08] 
Layer 'conv3' biases: 3.669653e-05 [3.086596e-09] 
Layer 'conv4' weights[0]: 1.889585e-03 [9.466289e-08] 
Layer 'conv4' biases: 9.997806e-01 [1.171668e-07] 
Layer 'conv5' weights[0]: 2.102567e-03 [1.976576e-06] 
Layer 'conv5' biases: 9.988378e-01 [2.094969e-06] 
Layer 'fc6' weights[0]: 6.540395e-03 [5.632417e-08] 
Layer 'fc6' biases: 9.999887e-01 [5.338091e-08] 
Layer 'fc7' weights[0]: 6.878190e-03 [1.350039e-07] 
Layer 'fc7' biases: 9.996724e-01 [1.600860e-07] 
Layer 'fc8' weights[0]: 4.800111e-03 [1.096108e-05] 
Layer 'fc8' biases: 3.031860e-02 [1.631238e-05] 
Train error last 800 batches: 0.657225
-------------------------------------------------------
Not saving because 0.395417 > 0.299667 (9.300: -1.18%)
======================================================= (2.378 sec)
37.61... logprob:  0.608946, 0.279948 (1.425 sec)
37.62... logprob:  0.674663, 0.296875 (1.453 sec)
37.63... logprob:  0.584749, 0.256510 (1.435 sec)
37.64... logprob:  0.667460, 0.300781 (1.411 sec)
37.65... logprob:  0.590538, 0.259115 (1.392 sec)
37.66... logprob:  0.618284, 0.277344 (1.437 sec)
37.67... logprob:  0.538426, 0.247396 (1.384 sec)
37.68... logprob:  0.612323, 0.287760 (1.400 sec)
37.69... logprob:  0.718555, 0.307292 (1.415 sec)
37.70... logprob:  0.505796, 0.240885 (1.426 sec)
37.71... logprob:  0.653228, 0.296875 (1.455 sec)
37.72... logprob:  0.713364, 0.319010 (1.397 sec)
37.73... logprob:  0.566314, 0.273437 (1.425 sec)
37.74... logprob:  0.720892, 0.289062 (1.412 sec)
37.75... logprob:  0.606983, 0.269531 (1.408 sec)
37.76... logprob:  0.630661, 0.277344 (1.429 sec)
37.77... logprob:  0.554778, 0.269531 (1.419 sec)
37.78... logprob:  0.746572, 0.321615 (1.451 sec)
37.79... logprob:  0.548250, 0.247396 (1.394 sec)
37.80... logprob:  0.691233, 0.295573 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.526070, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.884423e-03 [9.427696e-08] 
Layer 'conv1' biases: 2.205032e-06 [1.596035e-11] 
Layer 'conv2' weights[0]: 1.880608e-03 [9.408857e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.415533e-10] 
Layer 'conv3' weights[0]: 1.879713e-03 [9.411461e-08] 
Layer 'conv3' biases: 3.667241e-05 [3.094620e-09] 
Layer 'conv4' weights[0]: 1.887701e-03 [9.462994e-08] 
Layer 'conv4' biases: 9.997838e-01 [1.468666e-07] 
Layer 'conv5' weights[0]: 2.104577e-03 [2.394002e-06] 
Layer 'conv5' biases: 9.987956e-01 [2.648454e-06] 
Layer 'fc6' weights[0]: 6.539730e-03 [5.575737e-08] 
Layer 'fc6' biases: 9.999886e-01 [5.310962e-08] 
Layer 'fc7' weights[0]: 6.877476e-03 [1.355094e-07] 
Layer 'fc7' biases: 9.996741e-01 [1.774539e-07] 
Layer 'fc8' weights[0]: 4.869107e-03 [1.128201e-05] 
Layer 'fc8' biases: 3.090817e-02 [2.174307e-05] 
Train error last 800 batches: 0.656958
-------------------------------------------------------
Not saving because 0.526070 > 0.299667 (9.300: -1.18%)
======================================================= (2.378 sec)
37.81... logprob:  0.699016, 0.333333 (1.417 sec)
37.82... logprob:  0.462338, 0.204427 (1.424 sec)
37.83... logprob:  0.759648, 0.326823 (1.404 sec)
37.84... logprob:  0.815153, 0.322917 (1.465 sec)
37.85... logprob:  0.632281, 0.266927 (1.421 sec)
37.86... logprob:  0.587423, 0.260417 (1.421 sec)
37.87... logprob:  0.787712, 0.319010 (1.415 sec)
37.88... logprob:  0.709889, 0.311198 (1.408 sec)
37.89... logprob:  0.552116, 0.257812 (1.426 sec)
37.90... logprob:  0.768832, 0.332031 (1.381 sec)
37.91... logprob:  0.552737, 0.204427 (1.392 sec)
37.92... logprob:  0.627515, 0.278646 (1.395 sec)
37.93... logprob:  0.644109, 0.298177 (1.394 sec)
37.94... logprob:  0.752461, 0.319010 (1.378 sec)
37.95... logprob:  0.728953, 0.291667 (1.396 sec)
37.96... logprob:  0.818177, 0.334635 (1.398 sec)
37.97... logprob:  0.702246, 0.291667 (1.388 sec)
37.98... logprob:  0.620052, 0.304687 (1.432 sec)
37.99... logprob:  0.600884, 0.278646 (1.401 sec)
37.100... logprob:  0.586959, 0.253906 (1.394 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.388157, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.882537e-03 [9.415272e-08] 
Layer 'conv1' biases: 2.205239e-06 [1.801523e-11] 
Layer 'conv2' weights[0]: 1.878724e-03 [9.397282e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.318755e-10] 
Layer 'conv3' weights[0]: 1.877836e-03 [9.404958e-08] 
Layer 'conv3' biases: 3.669668e-05 [4.107183e-09] 
Layer 'conv4' weights[0]: 1.885811e-03 [9.451186e-08] 
Layer 'conv4' biases: 9.997800e-01 [1.631370e-07] 
Layer 'conv5' weights[0]: 2.099505e-03 [2.298348e-06] 
Layer 'conv5' biases: 9.988366e-01 [2.456190e-06] 
Layer 'fc6' weights[0]: 6.539050e-03 [5.806560e-08] 
Layer 'fc6' biases: 9.999889e-01 [5.621983e-08] 
Layer 'fc7' weights[0]: 6.876824e-03 [1.394561e-07] 
Layer 'fc7' biases: 9.996721e-01 [1.843554e-07] 
Layer 'fc8' weights[0]: 4.803314e-03 [1.084764e-05] 
Layer 'fc8' biases: 3.040837e-02 [1.509114e-05] 
Train error last 800 batches: 0.656897
-------------------------------------------------------
Not saving because 0.388157 > 0.299667 (9.300: -1.18%)
======================================================= (2.365 sec)
37.101... logprob:  0.584823, 0.270833 (1.449 sec)
37.102... logprob:  0.734133, 0.315104 (1.390 sec)
37.103... logprob:  0.772398, 0.302083 (1.399 sec)
37.104... logprob:  0.599138, 0.255208 (1.398 sec)
37.105... logprob:  0.717465, 0.312500 (1.396 sec)
37.106... logprob:  0.543639, 0.222656 (1.391 sec)
37.107... logprob:  0.582800, 0.268229 (1.436 sec)
37.108... logprob:  0.782430, 0.332031 (1.394 sec)
37.109... logprob:  0.607357, 0.289062 (1.406 sec)
37.110... logprob:  0.786325, 0.358073 (1.388 sec)
37.111... logprob:  0.696202, 0.304687 (1.388 sec)
37.112... logprob:  0.686844, 0.345052 (1.398 sec)
37.113... logprob:  0.591160, 0.255208 (1.396 sec)
37.114... logprob:  0.726621, 0.309896 (1.425 sec)
37.115... logprob:  0.761367, 0.334635 (1.408 sec)
37.116... logprob:  0.612095, 0.290364 (1.394 sec)
37.117... logprob:  0.645800, 0.269531 (1.440 sec)
37.118... logprob:  0.588876, 0.246094 (1.384 sec)
37.119... logprob:  0.617452, 0.274740 (1.391 sec)
37.120... logprob:  0.703620, 0.317708 (1.394 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.417656, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.880663e-03 [9.406384e-08] 
Layer 'conv1' biases: 2.205366e-06 [1.801808e-11] 
Layer 'conv2' weights[0]: 1.876856e-03 [9.388754e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.867804e-10] 
Layer 'conv3' weights[0]: 1.875948e-03 [9.397414e-08] 
Layer 'conv3' biases: 3.670057e-05 [3.613871e-09] 
Layer 'conv4' weights[0]: 1.883933e-03 [9.442400e-08] 
Layer 'conv4' biases: 9.997785e-01 [1.447675e-07] 
Layer 'conv5' weights[0]: 2.096592e-03 [2.033596e-06] 
Layer 'conv5' biases: 9.988465e-01 [2.201685e-06] 
Layer 'fc6' weights[0]: 6.538373e-03 [5.720101e-08] 
Layer 'fc6' biases: 9.999889e-01 [5.416737e-08] 
Layer 'fc7' weights[0]: 6.876123e-03 [1.362169e-07] 
Layer 'fc7' biases: 9.996709e-01 [1.679277e-07] 
Layer 'fc8' weights[0]: 4.792048e-03 [1.092823e-05] 
Layer 'fc8' biases: 3.036015e-02 [1.494890e-05] 
Train error last 800 batches: 0.657726
-------------------------------------------------------
Not saving because 0.417656 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
37.121... logprob:  0.706941, 0.319010 (1.398 sec)
37.122... logprob:  0.684512, 0.311198 (1.446 sec)
37.123... logprob:  0.691549, 0.295573 (1.389 sec)
37.124... logprob:  0.651675, 0.320312 (1.398 sec)
37.125... logprob:  0.699284, 0.300781 (1.392 sec)
37.126... logprob:  0.629679, 0.272135 (1.386 sec)
37.127... logprob:  0.712664, 0.324219 (1.389 sec)
37.128... logprob:  0.654800, 0.283854 (1.439 sec)
37.129... logprob:  0.753216, 0.313802 (1.418 sec)
37.130... logprob:  0.658003, 0.263021 (1.407 sec)
37.131... logprob:  0.749744, 0.300781 (1.405 sec)
37.132... logprob:  0.737645, 0.286458 (1.430 sec)
37.133... logprob:  0.649782, 0.285156 (1.387 sec)
37.134... logprob:  0.594219, 0.283854 (1.393 sec)
37.135... logprob:  0.675273, 0.283854 (1.403 sec)
37.136... logprob:  0.781111, 0.364583 (1.390 sec)
37.137... logprob:  0.692080, 0.295573 (1.380 sec)
37.138... logprob:  0.535441, 0.246094 (1.438 sec)
37.139... logprob:  0.605830, 0.269531 (1.390 sec)
37.140... logprob:  0.710013, 0.326823 (1.406 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.452082, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.878783e-03 [9.398431e-08] 
Layer 'conv1' biases: 2.205385e-06 [1.309895e-11] 
Layer 'conv2' weights[0]: 1.874968e-03 [9.379793e-08] 
Layer 'conv2' biases: 9.999996e-01 [1.906156e-10] 
Layer 'conv3' weights[0]: 1.874077e-03 [9.380113e-08] 
Layer 'conv3' biases: 3.669851e-05 [2.610562e-09] 
Layer 'conv4' weights[0]: 1.882040e-03 [9.424223e-08] 
Layer 'conv4' biases: 9.997792e-01 [1.052360e-07] 
Layer 'conv5' weights[0]: 2.095805e-03 [2.132754e-06] 
Layer 'conv5' biases: 9.988687e-01 [2.354589e-06] 
Layer 'fc6' weights[0]: 6.537711e-03 [5.758557e-08] 
Layer 'fc6' biases: 9.999891e-01 [5.452616e-08] 
Layer 'fc7' weights[0]: 6.875432e-03 [1.363056e-07] 
Layer 'fc7' biases: 9.996703e-01 [1.698511e-07] 
Layer 'fc8' weights[0]: 4.758694e-03 [1.142990e-05] 
Layer 'fc8' biases: 3.012077e-02 [2.409811e-05] 
Train error last 800 batches: 0.657736
-------------------------------------------------------
Not saving because 0.452082 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
37.141... logprob:  0.653787, 0.274740 (1.444 sec)
37.142... logprob:  0.725610, 0.324219 (1.395 sec)
37.143... logprob:  0.521074, 0.240885 (1.418 sec)
37.144... logprob:  0.701245, 0.305990 (1.410 sec)
37.145... logprob:  0.586680, 0.290365 (1.412 sec)
37.146... logprob:  0.697597, 0.290365 (1.406 sec)
37.147... logprob:  0.539073, 0.222656 (1.430 sec)
37.148... logprob:  0.628589, 0.283854 (1.386 sec)
37.149... logprob:  0.662312, 0.285156 (1.402 sec)
37.150... logprob:  0.574081, 0.283854 (1.393 sec)
37.151... logprob:  0.530687, 0.251302 (1.394 sec)
37.152... logprob:  0.825690, 0.333333 (1.382 sec)
37.153... logprob:  0.612437, 0.304688 (1.441 sec)
37.154... logprob:  0.730380, 0.316406 (1.391 sec)
37.155... logprob:  0.659534, 0.292969 (1.404 sec)
37.156... logprob:  0.526804, 0.225260 (1.436 sec)
37.157... logprob:  0.554749, 0.240885 (1.387 sec)
37.158... logprob:  0.693972, 0.283854 (1.397 sec)
37.159... logprob:  0.681349, 0.294271 (1.387 sec)
37.160... logprob:  0.779186, 0.321615 (1.386 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.512856, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.876894e-03 [9.387251e-08] 
Layer 'conv1' biases: 2.205488e-06 [2.459445e-11] 
Layer 'conv2' weights[0]: 1.873099e-03 [9.369189e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.829438e-10] 
Layer 'conv3' weights[0]: 1.872221e-03 [9.383536e-08] 
Layer 'conv3' biases: 3.668185e-05 [4.723958e-09] 
Layer 'conv4' weights[0]: 1.880164e-03 [9.428513e-08] 
Layer 'conv4' biases: 9.997818e-01 [1.814974e-07] 
Layer 'conv5' weights[0]: 2.097157e-03 [2.395774e-06] 
Layer 'conv5' biases: 9.988188e-01 [2.627375e-06] 
Layer 'fc6' weights[0]: 6.537031e-03 [6.284747e-08] 
Layer 'fc6' biases: 9.999889e-01 [6.295588e-08] 
Layer 'fc7' weights[0]: 6.874709e-03 [1.571103e-07] 
Layer 'fc7' biases: 9.996728e-01 [2.315103e-07] 
Layer 'fc8' weights[0]: 4.843176e-03 [1.522490e-05] 
Layer 'fc8' biases: 3.080712e-02 [4.651253e-05] 
Train error last 800 batches: 0.657633
-------------------------------------------------------
Not saving because 0.512856 > 0.299667 (9.300: -1.18%)
======================================================= (2.385 sec)
37.161... logprob:  0.520712, 0.231771 (1.415 sec)
37.162... logprob:  0.841305, 0.368490 (1.408 sec)
37.163... logprob:  0.600410, 0.272135 (1.423 sec)
37.164... logprob:  0.670374, 0.299479 (1.421 sec)
37.165... logprob:  0.774019, 0.319010 (1.420 sec)
37.166... logprob:  0.648233, 0.257813 (1.451 sec)
37.167... logprob:  0.576167, 0.270833 (1.424 sec)
37.168... logprob:  0.603844, 0.247396 (1.424 sec)
37.169... logprob:  0.639210, 0.295573 (1.453 sec)
37.170... logprob:  0.619983, 0.277344 (1.399 sec)
37.171... logprob:  0.688057, 0.319010 (1.417 sec)
37.172... logprob:  0.666148, 0.264323 (1.411 sec)
37.173... logprob:  0.561316, 0.227865 (1.420 sec)
37.174... logprob:  0.760751, 0.342448 (1.398 sec)
37.175... logprob:  0.702725, 0.294271 (1.462 sec)
37.176... logprob:  0.706845, 0.354167 (1.407 sec)
37.177... logprob:  0.575293, 0.233073 (1.422 sec)
37.178... logprob:  0.664108, 0.298177 (1.449 sec)
37.179... logprob:  0.531347, 0.235677 (1.403 sec)
37.180... logprob:  0.708167, 0.309896 (1.411 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.413370, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.875021e-03 [9.380130e-08] 
Layer 'conv1' biases: 2.205696e-06 [2.082768e-11] 
Layer 'conv2' weights[0]: 1.871226e-03 [9.361186e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.917135e-10] 
Layer 'conv3' weights[0]: 1.870336e-03 [9.369182e-08] 
Layer 'conv3' biases: 3.669073e-05 [3.955782e-09] 
Layer 'conv4' weights[0]: 1.878280e-03 [9.420856e-08] 
Layer 'conv4' biases: 9.997799e-01 [1.615394e-07] 
Layer 'conv5' weights[0]: 2.093870e-03 [2.337461e-06] 
Layer 'conv5' biases: 9.988273e-01 [2.580532e-06] 
Layer 'fc6' weights[0]: 6.536380e-03 [5.815006e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.603752e-08] 
Layer 'fc7' weights[0]: 6.874031e-03 [1.436132e-07] 
Layer 'fc7' biases: 9.996720e-01 [2.007667e-07] 
Layer 'fc8' weights[0]: 4.816929e-03 [1.245892e-05] 
Layer 'fc8' biases: 3.060439e-02 [3.364573e-05] 
Train error last 800 batches: 0.657149
-------------------------------------------------------
Not saving because 0.413370 > 0.299667 (9.300: -1.18%)
======================================================= (2.378 sec)
37.181... logprob:  0.724363, 0.289063 (1.421 sec)
37.182... logprob:  0.537343, 0.239583 (1.418 sec)
37.183... logprob:  0.521743, 0.243490 (1.416 sec)
37.184... logprob:  0.627789, 0.279948 (1.412 sec)
37.185... logprob:  0.462932, 0.212240 (1.393 sec)
37.186... logprob:  0.659679, 0.291667 (1.394 sec)
37.187... logprob:  0.782493, 0.312500 (1.398 sec)
37.188... logprob:  0.695797, 0.290365 (1.397 sec)
37.189... logprob:  0.574121, 0.279948 (1.384 sec)
37.190... logprob:  0.573889, 0.253906 (1.429 sec)
37.191... logprob:  0.634359, 0.290365 (1.402 sec)
37.192... logprob:  0.689865, 0.338542 (1.407 sec)
37.193... logprob:  0.537570, 0.273437 (1.413 sec)
37.194... logprob:  0.685046, 0.303385 (1.407 sec)
37.195... logprob:  0.497395, 0.235677 (1.394 sec)
37.196... logprob:  0.672121, 0.307292 (1.384 sec)
37.197... logprob:  0.651280, 0.300781 (1.392 sec)
37.198... logprob:  0.623081, 0.272135 (1.397 sec)
37.199... logprob:  0.567622, 0.240885 (1.382 sec)
37.200... logprob:  0.779850, 0.334635 (1.432 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.495356, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.873148e-03 [9.370604e-08] 
Layer 'conv1' biases: 2.205795e-06 [1.746298e-11] 
Layer 'conv2' weights[0]: 1.869351e-03 [9.351788e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.379368e-10] 
Layer 'conv3' weights[0]: 1.868475e-03 [9.355413e-08] 
Layer 'conv3' biases: 3.666607e-05 [3.046095e-09] 
Layer 'conv4' weights[0]: 1.876399e-03 [9.399503e-08] 
Layer 'conv4' biases: 9.997824e-01 [1.118076e-07] 
Layer 'conv5' weights[0]: 2.095152e-03 [2.305057e-06] 
Layer 'conv5' biases: 9.987805e-01 [2.440264e-06] 
Layer 'fc6' weights[0]: 6.535732e-03 [5.869921e-08] 
Layer 'fc6' biases: 9.999890e-01 [5.791765e-08] 
Layer 'fc7' weights[0]: 6.873356e-03 [1.456240e-07] 
Layer 'fc7' biases: 9.996746e-01 [2.082825e-07] 
Layer 'fc8' weights[0]: 4.883897e-03 [1.407443e-05] 
Layer 'fc8' biases: 3.117075e-02 [3.700652e-05] 
Train error last 800 batches: 0.656700
-------------------------------------------------------
Not saving because 0.495356 > 0.299667 (9.300: -1.18%)
======================================================= (2.390 sec)
37.201... logprob:  0.644076, 0.265625 (1.413 sec)
37.202... logprob:  0.751680, 0.328125 (1.405 sec)
37.203... logprob:  0.615773, 0.259114 (1.441 sec)
37.204... logprob:  0.769537, 0.287760 (1.389 sec)
37.205... logprob:  0.536694, 0.251302 (1.400 sec)
37.206... logprob:  0.656298, 0.328125 (1.398 sec)
37.207... logprob:  0.596462, 0.248698 (1.387 sec)
37.208... logprob:  0.666043, 0.292969 (1.403 sec)
37.209... logprob:  0.652426, 0.322917 (1.412 sec)
37.210... logprob:  0.709906, 0.283854 (1.412 sec)
37.211... logprob:  0.691368, 0.274740 (1.412 sec)
37.212... logprob:  0.672471, 0.304688 (1.411 sec)
37.213... logprob:  0.709769, 0.315104 (1.453 sec)
37.214... logprob:  0.659499, 0.282552 (1.424 sec)
37.215... logprob:  0.693469, 0.290365 (1.411 sec)
37.216... logprob:  0.711046, 0.286458 (1.462 sec)
37.217... logprob:  0.605765, 0.276042 (1.396 sec)
37.218... logprob:  0.719132, 0.303385 (1.412 sec)
37.219... logprob:  0.693828, 0.283854 (1.410 sec)
37.220... logprob:  0.658941, 0.295573 (1.414 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.569347, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.871273e-03 [9.357771e-08] 
Layer 'conv1' biases: 2.205953e-06 [3.002622e-11] 
Layer 'conv2' weights[0]: 1.867483e-03 [9.340605e-08] 
Layer 'conv2' biases: 9.999996e-01 [5.374987e-10] 
Layer 'conv3' weights[0]: 1.866600e-03 [9.369897e-08] 
Layer 'conv3' biases: 3.669749e-05 [6.434475e-09] 
Layer 'conv4' weights[0]: 1.874524e-03 [9.428317e-08] 
Layer 'conv4' biases: 9.997773e-01 [3.019959e-07] 
Layer 'conv5' weights[0]: 2.088641e-03 [3.496482e-06] 
Layer 'conv5' biases: 9.988176e-01 [3.897042e-06] 
Layer 'fc6' weights[0]: 6.535064e-03 [7.150411e-08] 
Layer 'fc6' biases: 9.999893e-01 [7.536928e-08] 
Layer 'fc7' weights[0]: 6.872685e-03 [1.767435e-07] 
Layer 'fc7' biases: 9.996716e-01 [2.936054e-07] 
Layer 'fc8' weights[0]: 4.807422e-03 [1.602962e-05] 
Layer 'fc8' biases: 3.058088e-02 [4.738729e-05] 
Train error last 800 batches: 0.657037
-------------------------------------------------------
Not saving because 0.569347 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
37.221... logprob:  0.585952, 0.260417 (1.413 sec)
37.222... logprob:  0.728879, 0.313802 (1.456 sec)
37.223... logprob:  0.744756, 0.322917 (1.426 sec)
37.224... logprob:  0.608037, 0.252604 (1.424 sec)
37.225... logprob:  0.647470, 0.273437 (1.440 sec)
37.226... logprob:  0.632694, 0.283854 (1.419 sec)
37.227... logprob:  0.635184, 0.274740 (1.416 sec)
37.228... logprob:  0.607784, 0.257812 (1.417 sec)
37.229... logprob:  0.659823, 0.289062 (1.419 sec)
37.230... logprob:  0.658853, 0.307292 (1.420 sec)
37.231... logprob:  0.661468, 0.312500 (1.398 sec)
37.232... logprob:  0.703425, 0.307292 (1.454 sec)
37.233... logprob:  0.708269, 0.315104 (1.422 sec)
37.234... logprob:  0.828825, 0.341146 (1.423 sec)
37.235... logprob:  0.753623, 0.320312 (1.489 sec)
37.236... logprob:  0.667167, 0.291667 (1.401 sec)
37.237... logprob:  0.563351, 0.255208 (1.417 sec)
37.238... logprob:  0.671882, 0.282552 (1.415 sec)
37.239... logprob:  0.688619, 0.299479 (1.412 sec)
37.240... logprob:  0.648836, 0.276042 (1.402 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.453313, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.869411e-03 [9.348306e-08] 
Layer 'conv1' biases: 2.206189e-06 [2.343678e-11] 
Layer 'conv2' weights[0]: 1.865615e-03 [9.331611e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.126751e-10] 
Layer 'conv3' weights[0]: 1.864742e-03 [9.339593e-08] 
Layer 'conv3' biases: 3.670480e-05 [3.535498e-09] 
Layer 'conv4' weights[0]: 1.872659e-03 [9.386432e-08] 
Layer 'conv4' biases: 9.997748e-01 [1.586708e-07] 
Layer 'conv5' weights[0]: 2.084690e-03 [1.998272e-06] 
Layer 'conv5' biases: 9.988431e-01 [2.109323e-06] 
Layer 'fc6' weights[0]: 6.534395e-03 [5.883736e-08] 
Layer 'fc6' biases: 9.999893e-01 [5.709557e-08] 
Layer 'fc7' weights[0]: 6.871999e-03 [1.395905e-07] 
Layer 'fc7' biases: 9.996696e-01 [1.713440e-07] 
Layer 'fc8' weights[0]: 4.764447e-03 [1.124491e-05] 
Layer 'fc8' biases: 3.023028e-02 [1.420113e-05] 
Train error last 800 batches: 0.656515
-------------------------------------------------------
Not saving because 0.453313 > 0.299667 (9.300: -1.18%)
======================================================= (2.392 sec)
37.241... logprob:  0.710324, 0.315104 (1.459 sec)
37.242... logprob:  0.571340, 0.230469 (1.434 sec)
37.243... logprob:  0.616136, 0.250000 (1.440 sec)
37.244... logprob:  0.608546, 0.259115 (1.441 sec)
37.245... logprob:  0.772840, 0.328125 (1.415 sec)
37.246... logprob:  0.621212, 0.259115 (1.409 sec)
37.247... logprob:  0.602308, 0.285156 (1.407 sec)
37.248... logprob:  0.566634, 0.240885 (1.414 sec)
37.249... logprob:  0.730524, 0.328125 (1.429 sec)
37.250... logprob:  0.780712, 0.325521 (1.401 sec)
37.251... logprob:  0.583784, 0.251302 (1.451 sec)
37.252... logprob:  0.645979, 0.282552 (1.420 sec)
37.253... logprob:  0.589107, 0.223958 (1.408 sec)
37.254... logprob:  0.730460, 0.315104 (1.464 sec)
37.255... logprob:  0.553215, 0.243490 (1.394 sec)
37.256... logprob:  0.661064, 0.279948 (1.417 sec)
37.257... logprob:  0.526326, 0.231771 (1.416 sec)
37.258... logprob:  0.608193, 0.265625 (1.414 sec)
37.259... logprob:  0.608439, 0.269531 (1.402 sec)
37.260... logprob:  0.527330, 0.244792 (1.450 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.313234, 0.039062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.867533e-03 [9.345327e-08] 
Layer 'conv1' biases: 2.206198e-06 [3.419303e-11] 
Layer 'conv2' weights[0]: 1.863740e-03 [9.325344e-08] 
Layer 'conv2' biases: 9.999996e-01 [6.869050e-10] 
Layer 'conv3' weights[0]: 1.862894e-03 [9.373807e-08] 
Layer 'conv3' biases: 3.667273e-05 [8.262970e-09] 
Layer 'conv4' weights[0]: 1.870781e-03 [9.452945e-08] 
Layer 'conv4' biases: 9.997768e-01 [3.574041e-07] 
Layer 'conv5' weights[0]: 2.085627e-03 [4.340643e-06] 
Layer 'conv5' biases: 9.988164e-01 [5.017789e-06] 
Layer 'fc6' weights[0]: 6.533760e-03 [7.490748e-08] 
Layer 'fc6' biases: 9.999891e-01 [7.887127e-08] 
Layer 'fc7' weights[0]: 6.871317e-03 [1.932082e-07] 
Layer 'fc7' biases: 9.996718e-01 [3.593940e-07] 
Layer 'fc8' weights[0]: 4.818272e-03 [1.829159e-05] 
Layer 'fc8' biases: 3.076414e-02 [6.386255e-05] 
Train error last 800 batches: 0.656196
-------------------------------------------------------
Not saving because 0.313234 > 0.299667 (9.300: -1.18%)
======================================================= (2.342 sec)
37.261... logprob:  0.639740, 0.304687 (1.431 sec)
37.262... logprob:  0.685264, 0.282552 (1.434 sec)
37.263... logprob:  0.609047, 0.272135 (1.444 sec)
37.264... logprob:  0.597100, 0.266927 (1.418 sec)
37.265... logprob:  0.674824, 0.308594 (1.405 sec)
37.266... logprob:  0.604980, 0.268229 (1.412 sec)
37.267... logprob:  0.679483, 0.304687 (1.412 sec)
37.268... logprob:  0.681964, 0.320312 (1.419 sec)
37.269... logprob:  0.698207, 0.272135 (1.403 sec)
37.270... logprob:  0.691903, 0.298177 (1.451 sec)
37.271... logprob:  0.586929, 0.250000 (1.422 sec)
37.272... logprob:  0.557090, 0.253906 (1.417 sec)
37.273... logprob:  0.731720, 0.319010 (1.462 sec)
37.274... logprob:  0.796573, 0.335938 (1.396 sec)
37.275... logprob:  0.695836, 0.316406 (1.423 sec)
37.276... logprob:  0.600798, 0.292969 (1.406 sec)
37.277... logprob:  0.706688, 0.330729 (1.428 sec)
37.278... logprob:  0.593432, 0.265625 (1.420 sec)
37.279... logprob:  0.585750, 0.281250 (1.460 sec)
37.280... logprob:  0.549734, 0.283854 (1.395 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.454709, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.865673e-03 [9.334043e-08] 
Layer 'conv1' biases: 2.206257e-06 [2.086507e-11] 
Layer 'conv2' weights[0]: 1.861889e-03 [9.315018e-08] 
Layer 'conv2' biases: 9.999996e-01 [4.711930e-10] 
Layer 'conv3' weights[0]: 1.861026e-03 [9.333583e-08] 
Layer 'conv3' biases: 3.666424e-05 [5.833474e-09] 
Layer 'conv4' weights[0]: 1.868911e-03 [9.398151e-08] 
Layer 'conv4' biases: 9.997773e-01 [2.208288e-07] 
Layer 'conv5' weights[0]: 2.084679e-03 [2.802760e-06] 
Layer 'conv5' biases: 9.987975e-01 [3.086703e-06] 
Layer 'fc6' weights[0]: 6.533106e-03 [5.732156e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.578361e-08] 
Layer 'fc7' weights[0]: 6.870612e-03 [1.399585e-07] 
Layer 'fc7' biases: 9.996727e-01 [2.074810e-07] 
Layer 'fc8' weights[0]: 4.851199e-03 [1.204932e-05] 
Layer 'fc8' biases: 3.106083e-02 [3.323528e-05] 
Train error last 800 batches: 0.656332
-------------------------------------------------------
Not saving because 0.454709 > 0.299667 (9.300: -1.18%)
======================================================= (2.356 sec)
37.281... logprob:  0.668514, 0.260417 (1.430 sec)
37.282... logprob:  0.620130, 0.281250 (1.416 sec)
37.283... logprob:  0.566491, 0.250000 (1.413 sec)
37.284... logprob:  0.647730, 0.295573 (1.402 sec)
37.285... logprob:  0.653934, 0.300781 (1.435 sec)
37.286... logprob:  0.663552, 0.277344 (1.429 sec)
37.287... logprob:  0.558078, 0.244792 (1.425 sec)
37.288... logprob:  0.520709, 0.220052 (1.427 sec)
37.289... logprob:  0.656510, 0.305990 (1.437 sec)
37.290... logprob:  0.685532, 0.304688 (1.400 sec)
37.291... logprob:  0.656936, 0.269531 (1.414 sec)
37.292... logprob:  0.772199, 0.343750 (1.417 sec)
37.293... logprob:  0.628602, 0.285156 (1.416 sec)
37.294... logprob:  0.600395, 0.255208 (1.411 sec)
37.295... logprob:  0.566124, 0.250000 (1.458 sec)
37.296... logprob:  0.531927, 0.247396 (1.415 sec)
37.297... logprob:  0.554622, 0.233073 (1.419 sec)
37.298... logprob:  0.687524, 0.265625 (1.460 sec)
37.299... logprob:  0.478537, 0.217448 (1.392 sec)
37.300... logprob:  0.756183, 0.326823 (1.418 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.494414, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.863806e-03 [9.323913e-08] 
Layer 'conv1' biases: 2.206233e-06 [1.434684e-11] 
Layer 'conv2' weights[0]: 1.860028e-03 [9.304914e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.580939e-10] 
Layer 'conv3' weights[0]: 1.859127e-03 [9.308842e-08] 
Layer 'conv3' biases: 3.664132e-05 [3.283684e-09] 
Layer 'conv4' weights[0]: 1.867038e-03 [9.353072e-08] 
Layer 'conv4' biases: 9.997808e-01 [1.447085e-07] 
Layer 'conv5' weights[0]: 2.087223e-03 [2.366818e-06] 
Layer 'conv5' biases: 9.987612e-01 [2.580075e-06] 
Layer 'fc6' weights[0]: 6.532434e-03 [5.649592e-08] 
Layer 'fc6' biases: 9.999893e-01 [5.521021e-08] 
Layer 'fc7' weights[0]: 6.869923e-03 [1.345936e-07] 
Layer 'fc7' biases: 9.996739e-01 [1.700963e-07] 
Layer 'fc8' weights[0]: 4.897756e-03 [1.119405e-05] 
Layer 'fc8' biases: 3.143674e-02 [2.029463e-05] 
Train error last 800 batches: 0.656414
-------------------------------------------------------
Not saving because 0.494414 > 0.299667 (9.300: -1.18%)
======================================================= (2.346 sec)
37.301... logprob:  0.563473, 0.244792 (1.418 sec)
37.302... logprob:  0.747002, 0.320312 (1.418 sec)
37.303... logprob:  0.589076, 0.244792 (1.412 sec)
37.304... logprob:  0.686598, 0.298177 (1.437 sec)
37.305... logprob:  0.620980, 0.259115 (1.435 sec)
37.306... logprob:  0.589688, 0.238281 (1.432 sec)
37.307... logprob:  0.610138, 0.278646 (1.437 sec)
37.308... logprob:  0.626526, 0.251302 (1.445 sec)
37.309... logprob:  0.711859, 0.308594 (1.410 sec)
37.310... logprob:  0.658612, 0.239583 (1.424 sec)
37.311... logprob:  0.629600, 0.256510 (1.418 sec)
37.312... logprob:  0.662528, 0.317708 (1.454 sec)
37.313... logprob:  0.583744, 0.264323 (1.421 sec)
37.314... logprob:  0.695083, 0.286458 (1.457 sec)
37.315... logprob:  0.586109, 0.274739 (1.427 sec)
37.316... logprob:  0.704206, 0.298177 (1.511 sec)
37.317... logprob:  0.597574, 0.277344 (1.476 sec)
37.318... logprob:  0.713018, 0.313802 (1.540 sec)
37.319... logprob:  0.653919, 0.286458 (1.415 sec)
37.320... logprob:  0.589931, 0.263021 (1.423 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.438486, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.861937e-03 [9.311326e-08] 
Layer 'conv1' biases: 2.206414e-06 [1.850817e-11] 
Layer 'conv2' weights[0]: 1.858165e-03 [9.294005e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.699024e-10] 
Layer 'conv3' weights[0]: 1.857279e-03 [9.309633e-08] 
Layer 'conv3' biases: 3.666409e-05 [4.850073e-09] 
Layer 'conv4' weights[0]: 1.865186e-03 [9.359020e-08] 
Layer 'conv4' biases: 9.997786e-01 [2.079302e-07] 
Layer 'conv5' weights[0]: 2.083290e-03 [2.317786e-06] 
Layer 'conv5' biases: 9.987929e-01 [2.475211e-06] 
Layer 'fc6' weights[0]: 6.531738e-03 [5.830003e-08] 
Layer 'fc6' biases: 9.999893e-01 [5.761279e-08] 
Layer 'fc7' weights[0]: 6.869270e-03 [1.441007e-07] 
Layer 'fc7' biases: 9.996717e-01 [2.024805e-07] 
Layer 'fc8' weights[0]: 4.841215e-03 [1.249195e-05] 
Layer 'fc8' biases: 3.098151e-02 [2.690136e-05] 
Train error last 800 batches: 0.655909
-------------------------------------------------------
Not saving because 0.438486 > 0.299667 (9.300: -1.18%)
======================================================= (2.381 sec)
37.321... logprob:  0.591688, 0.279948 (1.426 sec)
37.322... logprob:  0.634301, 0.299479 (1.410 sec)
37.323... logprob:  0.629807, 0.272135 (1.478 sec)
37.324... logprob:  0.787472, 0.359375 (1.420 sec)
37.325... logprob:  0.609907, 0.242188 (1.433 sec)
37.326... logprob:  0.688065, 0.289062 (1.464 sec)
37.327... logprob:  0.750810, 0.320312 (1.421 sec)
37.328... logprob:  0.713298, 0.279948 (1.416 sec)
37.329... logprob:  0.581747, 0.260417 (1.429 sec)
37.330... logprob:  0.630804, 0.264323 (1.413 sec)
37.331... logprob:  0.655506, 0.291667 (1.418 sec)
37.332... logprob:  0.658939, 0.294271 (1.445 sec)
37.333... logprob:  0.600420, 0.289062 (1.437 sec)
37.334... logprob:  0.753284, 0.322917 (1.430 sec)
37.335... logprob:  0.583400, 0.264323 (1.433 sec)
37.336... logprob:  0.727798, 0.328125 (1.454 sec)
37.337... logprob:  0.807447, 0.359375 (1.414 sec)
37.338... logprob:  0.638148, 0.289062 (1.419 sec)
37.339... logprob:  0.643236, 0.287760 (1.422 sec)
37.340... logprob:  0.671662, 0.299479 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.456239, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.860081e-03 [9.302757e-08] 
Layer 'conv1' biases: 2.206608e-06 [2.411889e-11] 
Layer 'conv2' weights[0]: 1.856309e-03 [9.285722e-08] 
Layer 'conv2' biases: 9.999996e-01 [4.721452e-10] 
Layer 'conv3' weights[0]: 1.855429e-03 [9.312971e-08] 
Layer 'conv3' biases: 3.669299e-05 [5.798463e-09] 
Layer 'conv4' weights[0]: 1.863312e-03 [9.365359e-08] 
Layer 'conv4' biases: 9.997749e-01 [2.530921e-07] 
Layer 'conv5' weights[0]: 2.077126e-03 [2.241883e-06] 
Layer 'conv5' biases: 9.988164e-01 [2.427797e-06] 
Layer 'fc6' weights[0]: 6.531113e-03 [5.676043e-08] 
Layer 'fc6' biases: 9.999893e-01 [5.480864e-08] 
Layer 'fc7' weights[0]: 6.868568e-03 [1.368415e-07] 
Layer 'fc7' biases: 9.996697e-01 [1.748594e-07] 
Layer 'fc8' weights[0]: 4.800822e-03 [1.133749e-05] 
Layer 'fc8' biases: 3.062145e-02 [1.824145e-05] 
Train error last 800 batches: 0.656087
-------------------------------------------------------
Not saving because 0.456239 > 0.299667 (9.300: -1.18%)
======================================================= (2.383 sec)
37.341... logprob:  0.726598, 0.342448 (1.419 sec)
37.342... logprob:  0.595551, 0.285156 (1.460 sec)
37.343... logprob:  0.609281, 0.277344 (1.441 sec)
37.344... logprob:  0.667814, 0.278646 (1.473 sec)
37.345... logprob:  0.734761, 0.334635 (1.433 sec)
37.346... logprob:  0.641003, 0.307292 (1.430 sec)
37.347... logprob:  0.621998, 0.255208 (1.478 sec)
37.348... logprob:  0.608984, 0.281250 (1.428 sec)
37.349... logprob:  0.661744, 0.269531 (1.426 sec)
37.350... logprob:  0.606668, 0.279948 (1.429 sec)
37.351... logprob:  0.626884, 0.265625 (1.421 sec)
37.352... logprob:  0.569434, 0.264323 (1.432 sec)
37.353... logprob:  0.719596, 0.315104 (1.487 sec)
37.354... logprob:  0.853225, 0.373698 (1.425 sec)
37.355... logprob:  0.638972, 0.286458 (1.437 sec)
37.356... logprob:  0.627699, 0.240885 (1.472 sec)
37.357... logprob:  0.588047, 0.260417 (1.421 sec)
37.358... logprob:  0.599413, 0.273437 (1.435 sec)
37.359... logprob:  0.728514, 0.312500 (1.424 sec)
37.360... logprob:  0.650387, 0.309896 (1.424 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.504517, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.858222e-03 [9.293049e-08] 
Layer 'conv1' biases: 2.206750e-06 [2.108136e-11] 
Layer 'conv2' weights[0]: 1.854450e-03 [9.276166e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.089374e-10] 
Layer 'conv3' weights[0]: 1.853566e-03 [9.285184e-08] 
Layer 'conv3' biases: 3.667586e-05 [3.758101e-09] 
Layer 'conv4' weights[0]: 1.861453e-03 [9.335976e-08] 
Layer 'conv4' biases: 9.997740e-01 [1.462799e-07] 
Layer 'conv5' weights[0]: 2.074979e-03 [2.256191e-06] 
Layer 'conv5' biases: 9.987981e-01 [2.368621e-06] 
Layer 'fc6' weights[0]: 6.530448e-03 [5.732478e-08] 
Layer 'fc6' biases: 9.999893e-01 [5.584306e-08] 
Layer 'fc7' weights[0]: 6.867901e-03 [1.407382e-07] 
Layer 'fc7' biases: 9.996713e-01 [1.908959e-07] 
Layer 'fc8' weights[0]: 4.832499e-03 [1.224792e-05] 
Layer 'fc8' biases: 3.093179e-02 [2.722114e-05] 
Train error last 800 batches: 0.655788
-------------------------------------------------------
Not saving because 0.504517 > 0.299667 (9.300: -1.18%)
======================================================= (2.383 sec)
37.361... logprob:  0.606413, 0.261719 (1.437 sec)
37.362... logprob:  0.760701, 0.298177 (1.476 sec)
37.363... logprob:  0.658370, 0.291667 (1.435 sec)
37.364... logprob:  0.596437, 0.240885 (1.447 sec)
37.365... logprob:  0.663974, 0.285156 (1.454 sec)
37.366... logprob:  0.614813, 0.300781 (1.442 sec)
37.367... logprob:  0.517234, 0.236979 (1.432 sec)
37.368... logprob:  0.766690, 0.321615 (1.421 sec)
37.369... logprob:  0.583581, 0.253906 (1.422 sec)
37.370... logprob:  0.668612, 0.281250 (1.429 sec)
37.371... logprob:  0.653814, 0.295573 (1.462 sec)
37.372... logprob:  0.707627, 0.315104 (1.447 sec)
37.373... logprob:  0.621182, 0.269531 (1.447 sec)
37.374... logprob:  0.660765, 0.251302 (1.443 sec)
37.375... logprob:  0.569817, 0.238281 (1.459 sec)
37.376... logprob:  0.638296, 0.300781 (1.433 sec)
37.377... logprob:  0.544480, 0.252604 (1.424 sec)
37.378... logprob:  0.727177, 0.335937 (1.428 sec)
37.379... logprob:  0.569344, 0.250000 (1.427 sec)
37.380... logprob:  0.740066, 0.348958 (1.435 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.472087, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.856359e-03 [9.286611e-08] 
Layer 'conv1' biases: 2.206820e-06 [1.231286e-11] 
Layer 'conv2' weights[0]: 1.852604e-03 [9.267669e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.484949e-10] 
Layer 'conv3' weights[0]: 1.851693e-03 [9.270569e-08] 
Layer 'conv3' biases: 3.667027e-05 [2.718670e-09] 
Layer 'conv4' weights[0]: 1.859581e-03 [9.316927e-08] 
Layer 'conv4' biases: 9.997737e-01 [1.028691e-07] 
Layer 'conv5' weights[0]: 2.073172e-03 [2.191665e-06] 
Layer 'conv5' biases: 9.987937e-01 [2.380160e-06] 
Layer 'fc6' weights[0]: 6.529817e-03 [5.432328e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.141125e-08] 
Layer 'fc7' weights[0]: 6.867238e-03 [1.321415e-07] 
Layer 'fc7' biases: 9.996709e-01 [1.614733e-07] 
Layer 'fc8' weights[0]: 4.843419e-03 [1.045584e-05] 
Layer 'fc8' biases: 3.107569e-02 [1.377164e-05] 
Train error last 800 batches: 0.655752
-------------------------------------------------------
Not saving because 0.472087 > 0.299667 (9.300: -1.18%)
======================================================= (2.359 sec)
37.381... logprob:  0.690464, 0.298177 (1.473 sec)
37.382... logprob:  0.721180, 0.296875 (1.450 sec)
37.383... logprob:  0.696557, 0.339844 (1.432 sec)
37.384... logprob:  0.654653, 0.295573 (1.473 sec)
37.385... logprob:  0.683136, 0.296875 (1.428 sec)
37.386... logprob:  0.705392, 0.309896 (1.421 sec)
37.387... logprob:  0.635593, 0.286458 (1.428 sec)
37.388... logprob:  0.725453, 0.302083 (1.429 sec)
37.389... logprob:  0.607797, 0.307292 (1.424 sec)
37.390... logprob:  0.605487, 0.272135 (1.473 sec)
37.391... logprob:  0.570949, 0.253906 (1.437 sec)
37.392... logprob:  0.552270, 0.230469 (1.429 sec)
37.393... logprob:  0.566979, 0.240885 (1.478 sec)
37.394... logprob:  0.649974, 0.281250 (1.427 sec)
37.395... logprob:  0.595871, 0.248698 (1.425 sec)
37.396... logprob:  0.504028, 0.223958 (1.431 sec)
37.397... logprob:  0.574144, 0.259115 (1.433 sec)
37.398... logprob:  0.647378, 0.296875 (1.425 sec)
37.399... logprob:  0.608277, 0.243490 (1.475 sec)
37.400... logprob:  0.758738, 0.281250 (1.432 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.450949, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.854507e-03 [9.276461e-08] 
Layer 'conv1' biases: 2.206815e-06 [1.498619e-11] 
Layer 'conv2' weights[0]: 1.850756e-03 [9.258346e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.622804e-10] 
Layer 'conv3' weights[0]: 1.849864e-03 [9.262250e-08] 
Layer 'conv3' biases: 3.665386e-05 [2.907197e-09] 
Layer 'conv4' weights[0]: 1.857726e-03 [9.312190e-08] 
Layer 'conv4' biases: 9.997744e-01 [1.236046e-07] 
Layer 'conv5' weights[0]: 2.072685e-03 [2.390442e-06] 
Layer 'conv5' biases: 9.987760e-01 [2.575689e-06] 
Layer 'fc6' weights[0]: 6.529155e-03 [5.844990e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.779980e-08] 
Layer 'fc7' weights[0]: 6.866542e-03 [1.429415e-07] 
Layer 'fc7' biases: 9.996712e-01 [1.880924e-07] 
Layer 'fc8' weights[0]: 4.857190e-03 [1.249921e-05] 
Layer 'fc8' biases: 3.117572e-02 [2.186206e-05] 
Train error last 800 batches: 0.654957
-------------------------------------------------------
Not saving because 0.450949 > 0.299667 (9.300: -1.18%)
======================================================= (2.376 sec)
37.401... logprob:  0.660745, 0.292969 (1.443 sec)
37.402... logprob:  0.653980, 0.272135 (1.482 sec)
37.403... logprob:  0.691546, 0.296875 (1.432 sec)
37.404... logprob:  0.668313, 0.300781 (1.427 sec)
37.405... logprob:  0.782734, 0.335937 (1.431 sec)
37.406... logprob:  0.619632, 0.286458 (1.420 sec)
37.407... logprob:  0.684182, 0.303385 (1.426 sec)
37.408... logprob:  0.552383, 0.253906 (1.474 sec)
37.409... logprob:  0.621222, 0.269531 (1.433 sec)
37.410... logprob:  0.755068, 0.341146 (1.445 sec)
37.411... logprob:  0.720926, 0.313802 (1.464 sec)
37.412... logprob:  0.722454, 0.325521 (1.432 sec)
37.413... logprob:  0.708701, 0.300781 (1.431 sec)
37.414... logprob:  0.672503, 0.298177 (1.423 sec)
37.415... logprob:  0.610448, 0.256510 (1.423 sec)
37.416... logprob:  0.676287, 0.300781 (1.436 sec)
37.417... logprob:  0.623940, 0.279948 (1.457 sec)
37.418... logprob:  0.608430, 0.282552 (1.443 sec)
37.419... logprob:  0.531667, 0.242188 (1.450 sec)
37.420... logprob:  0.568636, 0.260417 (1.455 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.502802, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.852648e-03 [9.268451e-08] 
Layer 'conv1' biases: 2.206915e-06 [2.001261e-11] 
Layer 'conv2' weights[0]: 1.848886e-03 [9.250263e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.623570e-10] 
Layer 'conv3' weights[0]: 1.848017e-03 [9.263610e-08] 
Layer 'conv3' biases: 3.665907e-05 [4.759433e-09] 
Layer 'conv4' weights[0]: 1.855867e-03 [9.322365e-08] 
Layer 'conv4' biases: 9.997737e-01 [2.192090e-07] 
Layer 'conv5' weights[0]: 2.070543e-03 [2.740549e-06] 
Layer 'conv5' biases: 9.987987e-01 [3.091644e-06] 
Layer 'fc6' weights[0]: 6.528475e-03 [6.183567e-08] 
Layer 'fc6' biases: 9.999891e-01 [6.217326e-08] 
Layer 'fc7' weights[0]: 6.865862e-03 [1.586381e-07] 
Layer 'fc7' biases: 9.996699e-01 [2.647635e-07] 
Layer 'fc8' weights[0]: 4.820940e-03 [1.556221e-05] 
Layer 'fc8' biases: 3.084791e-02 [5.184493e-05] 
Train error last 800 batches: 0.654719
-------------------------------------------------------
Not saving because 0.502802 > 0.299667 (9.300: -1.18%)
======================================================= (2.349 sec)
37.421... logprob:  0.619225, 0.282552 (1.452 sec)
37.422... logprob:  0.754111, 0.308594 (1.432 sec)
37.423... logprob:  0.654784, 0.289062 (1.428 sec)
37.424... logprob:  0.588065, 0.265625 (1.426 sec)
37.425... logprob:  0.601484, 0.273437 (1.434 sec)
37.426... logprob:  0.723103, 0.321615 (1.439 sec)
37.427... logprob:  0.781115, 0.328125 (1.455 sec)
37.428... logprob:  0.742555, 0.315104 (1.450 sec)
37.429... logprob:  0.657398, 0.277344 (1.435 sec)
37.430... logprob:  0.594940, 0.273437 (1.469 sec)
37.431... logprob:  0.812319, 0.358073 (1.429 sec)
37.432... logprob:  0.610839, 0.299479 (1.421 sec)
37.433... logprob:  0.625640, 0.300781 (1.434 sec)
37.434... logprob:  0.679054, 0.292969 (1.430 sec)
37.435... logprob:  0.745742, 0.308594 (1.430 sec)
37.436... logprob:  0.616597, 0.289062 (1.468 sec)
37.437... logprob:  0.774928, 0.332031 (1.438 sec)
37.438... logprob:  0.674213, 0.320312 (1.434 sec)
37.439... logprob:  0.617776, 0.250000 (1.477 sec)
37.440... logprob:  0.708606, 0.289063 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.413886, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.850800e-03 [9.255334e-08] 
Layer 'conv1' biases: 2.207028e-06 [1.622186e-11] 
Layer 'conv2' weights[0]: 1.847040e-03 [9.238639e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.121137e-10] 
Layer 'conv3' weights[0]: 1.846168e-03 [9.240976e-08] 
Layer 'conv3' biases: 3.666562e-05 [2.736458e-09] 
Layer 'conv4' weights[0]: 1.854003e-03 [9.282700e-08] 
Layer 'conv4' biases: 9.997741e-01 [1.279600e-07] 
Layer 'conv5' weights[0]: 2.069107e-03 [2.356004e-06] 
Layer 'conv5' biases: 9.987975e-01 [2.525393e-06] 
Layer 'fc6' weights[0]: 6.527819e-03 [5.836361e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.754069e-08] 
Layer 'fc7' weights[0]: 6.865154e-03 [1.423069e-07] 
Layer 'fc7' biases: 9.996690e-01 [1.851124e-07] 
Layer 'fc8' weights[0]: 4.814185e-03 [1.135579e-05] 
Layer 'fc8' biases: 3.083804e-02 [1.593189e-05] 
Train error last 800 batches: 0.655173
-------------------------------------------------------
Not saving because 0.413886 > 0.299667 (9.300: -1.18%)
======================================================= (2.399 sec)
37.441... logprob:  0.611880, 0.251302 (1.431 sec)
37.442... logprob:  0.623721, 0.268229 (1.433 sec)
37.443... logprob:  0.755837, 0.330729 (1.428 sec)
37.444... logprob:  0.592825, 0.270833 (1.428 sec)
37.445... logprob:  0.572493, 0.266927 (1.476 sec)
37.446... logprob:  0.697150, 0.316406 (1.430 sec)
37.447... logprob:  0.721272, 0.296875 (1.435 sec)
37.448... logprob:  0.610757, 0.294271 (1.472 sec)
37.449... logprob:  0.704620, 0.312500 (1.431 sec)
37.450... logprob:  0.542387, 0.278646 (1.429 sec)
37.451... logprob:  0.695039, 0.320312 (1.430 sec)
37.452... logprob:  0.720295, 0.308594 (1.425 sec)
37.453... logprob:  0.673733, 0.303385 (1.428 sec)
37.454... logprob:  0.749756, 0.313802 (1.486 sec)
37.455... logprob:  0.735387, 0.322917 (1.426 sec)
37.456... logprob:  0.728899, 0.330729 (1.442 sec)
37.457... logprob:  0.621676, 0.278646 (1.467 sec)
37.458... logprob:  0.577082, 0.268229 (1.428 sec)
37.459... logprob:  0.703020, 0.291667 (1.430 sec)
37.460... logprob:  0.590972, 0.291667 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.480398, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.848954e-03 [9.248625e-08] 
Layer 'conv1' biases: 2.207077e-06 [1.571417e-11] 
Layer 'conv2' weights[0]: 1.845195e-03 [9.231097e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.984689e-10] 
Layer 'conv3' weights[0]: 1.844325e-03 [9.241572e-08] 
Layer 'conv3' biases: 3.666086e-05 [4.374679e-09] 
Layer 'conv4' weights[0]: 1.852162e-03 [9.294727e-08] 
Layer 'conv4' biases: 9.997753e-01 [1.698993e-07] 
Layer 'conv5' weights[0]: 2.068911e-03 [2.289320e-06] 
Layer 'conv5' biases: 9.987909e-01 [2.467535e-06] 
Layer 'fc6' weights[0]: 6.527116e-03 [5.880369e-08] 
Layer 'fc6' biases: 9.999890e-01 [5.821968e-08] 
Layer 'fc7' weights[0]: 6.864446e-03 [1.467783e-07] 
Layer 'fc7' biases: 9.996691e-01 [2.112323e-07] 
Layer 'fc8' weights[0]: 4.822074e-03 [1.366124e-05] 
Layer 'fc8' biases: 3.091368e-02 [4.051379e-05] 
Train error last 800 batches: 0.655587
-------------------------------------------------------
Not saving because 0.480398 > 0.299667 (9.300: -1.18%)
======================================================= (2.370 sec)
37.461... logprob:  0.734384, 0.302083 (1.429 sec)
37.462... logprob:  0.722580, 0.355469 (1.436 sec)
37.463... logprob:  0.568622, 0.270833 (1.473 sec)
37.464... logprob:  0.647876, 0.269531 (1.440 sec)
37.465... logprob:  0.682766, 0.291667 (1.445 sec)
37.466... logprob:  0.570800, 0.250000 (1.454 sec)
37.467... logprob:  0.625519, 0.274740 (1.444 sec)
37.468... logprob:  0.621216, 0.285156 (1.435 sec)
37.469... logprob:  0.565562, 0.255208 (1.427 sec)
37.470... logprob:  0.629183, 0.261719 (1.417 sec)
37.471... logprob:  0.671774, 0.278646 (1.435 sec)
37.472... logprob:  0.557042, 0.260417 (1.446 sec)
37.473... logprob:  0.504634, 0.227865 (1.451 sec)
37.474... logprob:  0.682436, 0.300781 (1.450 sec)
37.475... logprob:  0.648804, 0.289062 (1.444 sec)
37.476... logprob:  0.716110, 0.287760 (1.466 sec)
37.477... logprob:  0.606002, 0.260417 (1.429 sec)
37.478... logprob:  0.701198, 0.279948 (1.421 sec)
37.479... logprob:  0.536193, 0.240885 (1.423 sec)
37.480... logprob:  0.629408, 0.269531 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.450419, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.847104e-03 [9.237283e-08] 
Layer 'conv1' biases: 2.207020e-06 [1.324322e-11] 
Layer 'conv2' weights[0]: 1.843347e-03 [9.220169e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.554164e-10] 
Layer 'conv3' weights[0]: 1.842474e-03 [9.226469e-08] 
Layer 'conv3' biases: 3.663943e-05 [3.581802e-09] 
Layer 'conv4' weights[0]: 1.850306e-03 [9.275464e-08] 
Layer 'conv4' biases: 9.997780e-01 [1.507317e-07] 
Layer 'conv5' weights[0]: 2.070202e-03 [2.202759e-06] 
Layer 'conv5' biases: 9.987703e-01 [2.443169e-06] 
Layer 'fc6' weights[0]: 6.526431e-03 [5.665517e-08] 
Layer 'fc6' biases: 9.999889e-01 [5.541207e-08] 
Layer 'fc7' weights[0]: 6.863759e-03 [1.365584e-07] 
Layer 'fc7' biases: 9.996706e-01 [1.707915e-07] 
Layer 'fc8' weights[0]: 4.857599e-03 [1.076719e-05] 
Layer 'fc8' biases: 3.119602e-02 [1.673028e-05] 
Train error last 800 batches: 0.654836
-------------------------------------------------------
Not saving because 0.450419 > 0.299667 (9.300: -1.18%)
======================================================= (2.368 sec)
37.481... logprob:  0.663941, 0.263021 (1.433 sec)
37.482... logprob:  0.638168, 0.295573 (1.471 sec)
37.483... logprob:  0.797874, 0.330729 (1.449 sec)
37.484... logprob:  0.772514, 0.320312 (1.429 sec)
37.485... logprob:  0.557139, 0.264323 (1.479 sec)
37.486... logprob:  0.567812, 0.250000 (1.425 sec)
37.487... logprob:  0.771531, 0.313802 (1.423 sec)
37.488... logprob:  0.605625, 0.279948 (1.428 sec)
37.489... logprob:  0.660740, 0.326823 (1.429 sec)
37.490... logprob:  0.782495, 0.325521 (1.431 sec)
37.491... logprob:  0.547825, 0.265625 (1.475 sec)
37.492... logprob:  0.629707, 0.246094 (1.433 sec)
37.493... logprob:  0.749573, 0.287760 (1.432 sec)
37.494... logprob:  0.711540, 0.302083 (1.474 sec)
37.495... logprob:  0.601353, 0.264323 (1.431 sec)
37.496... logprob:  0.774315, 0.304687 (1.421 sec)
37.497... logprob:  0.652000, 0.302083 (1.432 sec)
37.498... logprob:  0.734013, 0.328125 (1.423 sec)
37.499... logprob:  0.616878, 0.273437 (1.425 sec)
37.500... logprob:  0.641276, 0.279948 (1.482 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.477560, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.845253e-03 [9.227150e-08] 
Layer 'conv1' biases: 2.207101e-06 [2.115488e-11] 
Layer 'conv2' weights[0]: 1.841514e-03 [9.210922e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.700417e-10] 
Layer 'conv3' weights[0]: 1.840634e-03 [9.226237e-08] 
Layer 'conv3' biases: 3.665249e-05 [4.725902e-09] 
Layer 'conv4' weights[0]: 1.848454e-03 [9.272847e-08] 
Layer 'conv4' biases: 9.997752e-01 [2.235361e-07] 
Layer 'conv5' weights[0]: 2.065386e-03 [3.277941e-06] 
Layer 'conv5' biases: 9.988074e-01 [3.682451e-06] 
Layer 'fc6' weights[0]: 6.525785e-03 [6.546355e-08] 
Layer 'fc6' biases: 9.999890e-01 [6.745216e-08] 
Layer 'fc7' weights[0]: 6.863102e-03 [1.634876e-07] 
Layer 'fc7' biases: 9.996682e-01 [2.558327e-07] 
Layer 'fc8' weights[0]: 4.790053e-03 [1.472812e-05] 
Layer 'fc8' biases: 3.073142e-02 [3.936890e-05] 
Train error last 800 batches: 0.654591
-------------------------------------------------------
Not saving because 0.477560 > 0.299667 (9.300: -1.18%)
======================================================= (2.390 sec)
37.501... logprob:  0.636821, 0.282552 (1.437 sec)
37.502... logprob:  0.651389, 0.277344 (1.440 sec)
37.503... logprob:  0.646538, 0.282552 (1.493 sec)
37.504... logprob:  0.716600, 0.325521 (1.425 sec)
37.505... logprob:  0.782998, 0.322917 (1.435 sec)
37.506... logprob:  0.692358, 0.279948 (1.434 sec)
37.507... logprob:  0.575357, 0.277344 (1.422 sec)
37.508... logprob:  0.628650, 0.259115 (1.425 sec)
37.509... logprob:  0.556761, 0.248698 (1.471 sec)
37.510... logprob:  0.651914, 0.319010 (1.437 sec)
37.511... logprob:  0.636984, 0.287760 (1.446 sec)
37.512... logprob:  0.638248, 0.282552 (1.466 sec)
37.513... logprob:  0.567330, 0.255208 (1.437 sec)
37.514... logprob:  0.669900, 0.282552 (1.437 sec)
37.515... logprob:  0.607026, 0.248698 (1.425 sec)
37.516... logprob:  0.664695, 0.294271 (1.420 sec)
37.517... logprob:  0.726823, 0.320312 (1.433 sec)
37.518... logprob:  0.618626, 0.260417 (1.458 sec)
37.519... logprob:  0.771010, 0.315104 (1.447 sec)
37.520... logprob:  0.666608, 0.289062 (1.449 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.487905, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.843408e-03 [9.217890e-08] 
Layer 'conv1' biases: 2.207165e-06 [1.778321e-11] 
Layer 'conv2' weights[0]: 1.839671e-03 [9.201434e-08] 
Layer 'conv2' biases: 9.999996e-01 [1.832879e-10] 
Layer 'conv3' weights[0]: 1.838798e-03 [9.203894e-08] 
Layer 'conv3' biases: 3.664726e-05 [2.448402e-09] 
Layer 'conv4' weights[0]: 1.846606e-03 [9.249652e-08] 
Layer 'conv4' biases: 9.997749e-01 [1.128690e-07] 
Layer 'conv5' weights[0]: 2.064006e-03 [2.102698e-06] 
Layer 'conv5' biases: 9.987990e-01 [2.216348e-06] 
Layer 'fc6' weights[0]: 6.525138e-03 [5.682353e-08] 
Layer 'fc6' biases: 9.999889e-01 [5.515353e-08] 
Layer 'fc7' weights[0]: 6.862372e-03 [1.362651e-07] 
Layer 'fc7' biases: 9.996685e-01 [1.577176e-07] 
Layer 'fc8' weights[0]: 4.805806e-03 [1.055878e-05] 
Layer 'fc8' biases: 3.091126e-02 [4.418967e-06] 
Train error last 800 batches: 0.654697
-------------------------------------------------------
Not saving because 0.487905 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
37.521... logprob:  0.657375, 0.295573 (1.459 sec)
37.522... logprob:  0.660362, 0.295573 (1.456 sec)
37.523... logprob:  0.604574, 0.283854 (1.444 sec)
37.524... logprob:  0.623843, 0.252604 (1.415 sec)
37.525... logprob:  0.630172, 0.278646 (1.426 sec)
37.526... logprob:  0.550350, 0.246094 (1.434 sec)
37.527... logprob:  0.632443, 0.255208 (1.436 sec)
37.528... logprob:  0.605170, 0.252604 (1.459 sec)
37.529... logprob:  0.550042, 0.244792 (1.446 sec)
37.530... logprob:  0.688080, 0.290365 (1.438 sec)
37.531... logprob:  0.657959, 0.279948 (1.475 sec)
37.532... logprob:  0.693004, 0.298177 (1.430 sec)
37.533... logprob:  0.734359, 0.305990 (1.428 sec)
37.534... logprob:  0.613793, 0.303385 (1.422 sec)
37.535... logprob:  0.651104, 0.287760 (1.433 sec)
37.536... logprob:  0.669143, 0.296875 (1.428 sec)
37.537... logprob:  0.750990, 0.333333 (1.468 sec)
37.538... logprob:  0.764405, 0.346354 (1.439 sec)
37.539... logprob:  0.591960, 0.282552 (1.425 sec)
37.540... logprob:  0.724712, 0.296875 (1.493 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.574776, 0.171875 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.841561e-03 [9.206890e-08] 
Layer 'conv1' biases: 2.207231e-06 [2.281776e-11] 
Layer 'conv2' weights[0]: 1.837836e-03 [9.191640e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.492877e-10] 
Layer 'conv3' weights[0]: 1.836967e-03 [9.202569e-08] 
Layer 'conv3' biases: 3.663908e-05 [4.123312e-09] 
Layer 'conv4' weights[0]: 1.844760e-03 [9.249242e-08] 
Layer 'conv4' biases: 9.997760e-01 [1.793856e-07] 
Layer 'conv5' weights[0]: 2.063668e-03 [2.533461e-06] 
Layer 'conv5' biases: 9.987897e-01 [2.697228e-06] 
Layer 'fc6' weights[0]: 6.524476e-03 [5.984682e-08] 
Layer 'fc6' biases: 9.999891e-01 [5.969675e-08] 
Layer 'fc7' weights[0]: 6.861702e-03 [1.476268e-07] 
Layer 'fc7' biases: 9.996689e-01 [2.078347e-07] 
Layer 'fc8' weights[0]: 4.812869e-03 [1.226009e-05] 
Layer 'fc8' biases: 3.094998e-02 [2.369950e-05] 
Train error last 800 batches: 0.654788
-------------------------------------------------------
Not saving because 0.574776 > 0.299667 (9.300: -1.18%)
======================================================= (2.353 sec)
37.541... logprob:  0.573243, 0.270833 (1.465 sec)
37.542... logprob:  0.742436, 0.337240 (1.433 sec)
37.543... logprob:  0.533270, 0.239583 (1.433 sec)
37.544... logprob:  0.631817, 0.316406 (1.427 sec)
37.545... logprob:  0.593770, 0.272135 (1.424 sec)
37.546... logprob:  0.638918, 0.282552 (1.485 sec)
37.547... logprob:  0.655092, 0.276042 (1.433 sec)
37.548... logprob:  0.706218, 0.290365 (1.434 sec)
37.549... logprob:  0.639411, 0.276042 (1.471 sec)
37.550... logprob:  0.582069, 0.255208 (1.428 sec)
37.551... logprob:  0.630107, 0.242187 (1.426 sec)
37.552... logprob:  0.731775, 0.282552 (1.429 sec)
37.553... logprob:  0.615142, 0.286458 (1.423 sec)
37.554... logprob:  0.697724, 0.325521 (1.427 sec)
37.555... logprob:  0.683658, 0.290365 (1.477 sec)
37.556... logprob:  0.625561, 0.255208 (1.430 sec)
37.557... logprob:  0.724876, 0.315104 (1.442 sec)
37.558... logprob:  0.617553, 0.256510 (1.466 sec)
37.559... logprob:  0.660097, 0.312500 (1.429 sec)
37.560... logprob:  0.533166, 0.233073 (1.436 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.473855, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.839724e-03 [9.203609e-08] 
Layer 'conv1' biases: 2.207296e-06 [1.506338e-11] 
Layer 'conv2' weights[0]: 1.835994e-03 [9.184813e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.415091e-10] 
Layer 'conv3' weights[0]: 1.835144e-03 [9.188516e-08] 
Layer 'conv3' biases: 3.665087e-05 [2.862639e-09] 
Layer 'conv4' weights[0]: 1.842906e-03 [9.232068e-08] 
Layer 'conv4' biases: 9.997753e-01 [1.185201e-07] 
Layer 'conv5' weights[0]: 2.061549e-03 [2.126826e-06] 
Layer 'conv5' biases: 9.987826e-01 [2.342679e-06] 
Layer 'fc6' weights[0]: 6.523838e-03 [5.567607e-08] 
Layer 'fc6' biases: 9.999890e-01 [5.359603e-08] 
Layer 'fc7' weights[0]: 6.861011e-03 [1.328341e-07] 
Layer 'fc7' biases: 9.996691e-01 [1.607576e-07] 
Layer 'fc8' weights[0]: 4.817934e-03 [1.020394e-05] 
Layer 'fc8' biases: 3.098189e-02 [1.180138e-05] 
Train error last 800 batches: 0.655265
-------------------------------------------------------
Not saving because 0.473855 > 0.299667 (9.300: -1.18%)
======================================================= (2.374 sec)
37.561... logprob:  0.658389, 0.300781 (1.432 sec)
37.562... logprob:  0.757782, 0.339844 (1.421 sec)
37.563... logprob:  0.555158, 0.253906 (1.436 sec)
37.564... logprob:  0.641589, 0.273438 (1.459 sec)
37.565... logprob:  0.803560, 0.339844 (1.445 sec)
37.566... logprob:  0.594100, 0.263021 (1.448 sec)
37.567... logprob:  0.635822, 0.263021 (1.456 sec)
37.568... logprob:  0.698888, 0.305989 (1.449 sec)
37.569... logprob:  0.705787, 0.295573 (1.430 sec)
37.570... logprob:  0.782861, 0.322917 (1.422 sec)
37.571... logprob:  0.674951, 0.298177 (1.430 sec)
37.572... logprob:  0.707429, 0.290365 (1.433 sec)
37.573... logprob:  0.819327, 0.351562 (1.445 sec)
37.574... logprob:  0.607299, 0.261719 (1.459 sec)
37.575... logprob:  0.633075, 0.283854 (1.504 sec)
37.576... logprob:  0.602060, 0.252604 (1.442 sec)
37.577... logprob:  0.613513, 0.290365 (1.467 sec)
37.578... logprob:  0.598045, 0.253906 (1.431 sec)
37.579... logprob:  0.661846, 0.277344 (1.417 sec)
37.580... logprob:  0.812849, 0.345052 (1.428 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.497458, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.837881e-03 [9.194063e-08] 
Layer 'conv1' biases: 2.207362e-06 [1.587545e-11] 
Layer 'conv2' weights[0]: 1.834151e-03 [9.175405e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.467972e-10] 
Layer 'conv3' weights[0]: 1.833304e-03 [9.180518e-08] 
Layer 'conv3' biases: 3.667615e-05 [3.431510e-09] 
Layer 'conv4' weights[0]: 1.841066e-03 [9.222094e-08] 
Layer 'conv4' biases: 9.997725e-01 [1.455325e-07] 
Layer 'conv5' weights[0]: 2.057339e-03 [2.493591e-06] 
Layer 'conv5' biases: 9.988034e-01 [2.698941e-06] 
Layer 'fc6' weights[0]: 6.523166e-03 [6.189744e-08] 
Layer 'fc6' biases: 9.999893e-01 [6.244187e-08] 
Layer 'fc7' weights[0]: 6.860284e-03 [1.520959e-07] 
Layer 'fc7' biases: 9.996669e-01 [2.139982e-07] 
Layer 'fc8' weights[0]: 4.772040e-03 [1.355670e-05] 
Layer 'fc8' biases: 3.049842e-02 [2.573705e-05] 
Train error last 800 batches: 0.655205
-------------------------------------------------------
Not saving because 0.497458 > 0.299667 (9.300: -1.18%)
======================================================= (2.362 sec)
37.581... logprob:  0.766099, 0.330729 (1.438 sec)
37.582... logprob:  0.643235, 0.282552 (1.437 sec)
37.583... logprob:  0.821223, 0.339844 (1.473 sec)
37.584... logprob:  0.660889, 0.294271 (1.447 sec)
37.585... logprob:  0.583808, 0.255208 (1.423 sec)
37.586... logprob:  0.624429, 0.269531 (1.484 sec)
37.587... logprob:  0.640126, 0.276042 (1.428 sec)
37.588... logprob:  0.640468, 0.292969 (1.433 sec)
37.589... logprob:  0.641675, 0.278646 (1.428 sec)
37.590... logprob:  0.714927, 0.320312 (1.425 sec)
37.591... logprob:  0.573194, 0.248698 (1.425 sec)
37.592... logprob:  0.674305, 0.274739 (1.480 sec)
37.593... logprob:  0.651086, 0.292969 (1.429 sec)
37.594... logprob:  0.556854, 0.251302 (1.432 sec)
37.595... logprob:  0.659301, 0.287760 (1.483 sec)
37.596... logprob:  0.679608, 0.296875 (1.428 sec)
37.597... logprob:  0.571011, 0.247396 (1.424 sec)
37.598... logprob:  0.627576, 0.266927 (1.434 sec)
37.599... logprob:  0.535104, 0.214844 (1.418 sec)
37.600... logprob:  0.625431, 0.298177 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.493347, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.836050e-03 [9.190932e-08] 
Layer 'conv1' biases: 2.207463e-06 [2.964295e-11] 
Layer 'conv2' weights[0]: 1.832327e-03 [9.169178e-08] 
Layer 'conv2' biases: 9.999996e-01 [5.641542e-10] 
Layer 'conv3' weights[0]: 1.831463e-03 [9.198025e-08] 
Layer 'conv3' biases: 3.667749e-05 [6.594526e-09] 
Layer 'conv4' weights[0]: 1.839237e-03 [9.263722e-08] 
Layer 'conv4' biases: 9.997729e-01 [3.052523e-07] 
Layer 'conv5' weights[0]: 2.056655e-03 [4.668670e-06] 
Layer 'conv5' biases: 9.987826e-01 [5.215621e-06] 
Layer 'fc6' weights[0]: 6.522540e-03 [7.912608e-08] 
Layer 'fc6' biases: 9.999892e-01 [8.606696e-08] 
Layer 'fc7' weights[0]: 6.859624e-03 [2.074139e-07] 
Layer 'fc7' biases: 9.996681e-01 [3.922165e-07] 
Layer 'fc8' weights[0]: 4.812367e-03 [1.971322e-05] 
Layer 'fc8' biases: 3.079862e-02 [7.197584e-05] 
Train error last 800 batches: 0.654689
-------------------------------------------------------
Not saving because 0.493347 > 0.299667 (9.300: -1.18%)
======================================================= (2.337 sec)
37.601... logprob:  0.567126, 0.261719 (1.486 sec)
37.602... logprob:  0.555689, 0.281250 (1.432 sec)
37.603... logprob:  0.565692, 0.252604 (1.441 sec)
37.604... logprob:  0.611453, 0.286458 (1.471 sec)
37.605... logprob:  0.805686, 0.294271 (1.430 sec)
37.606... logprob:  0.635976, 0.305990 (1.438 sec)
37.607... logprob:  0.708635, 0.316406 (1.424 sec)
37.608... logprob:  0.555352, 0.256510 (1.420 sec)
37.609... logprob:  0.534004, 0.253906 (1.431 sec)
37.610... logprob:  0.715648, 0.329427 (1.473 sec)
37.611... logprob:  0.632541, 0.304687 (1.438 sec)
37.612... logprob:  0.642120, 0.298177 (1.448 sec)
37.613... logprob:  0.530063, 0.246094 (1.458 sec)
37.614... logprob:  0.683614, 0.290365 (1.448 sec)
37.615... logprob:  0.569447, 0.242187 (1.436 sec)
37.616... logprob:  0.704966, 0.317708 (1.426 sec)
37.617... logprob:  0.664160, 0.287760 (1.414 sec)
37.618... logprob:  0.769924, 0.305990 (1.435 sec)
37.619... logprob:  0.744748, 0.303385 (1.445 sec)
37.620... logprob:  0.765613, 0.326823 (1.452 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.494507, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.834213e-03 [9.168890e-08] 
Layer 'conv1' biases: 2.207405e-06 [3.839542e-11] 
Layer 'conv2' weights[0]: 1.830500e-03 [9.154382e-08] 
Layer 'conv2' biases: 9.999996e-01 [7.145556e-10] 
Layer 'conv3' weights[0]: 1.829625e-03 [9.215858e-08] 
Layer 'conv3' biases: 3.665254e-05 [8.648200e-09] 
Layer 'conv4' weights[0]: 1.837383e-03 [9.287309e-08] 
Layer 'conv4' biases: 9.997761e-01 [4.464304e-07] 
Layer 'conv5' weights[0]: 2.059569e-03 [4.608160e-06] 
Layer 'conv5' biases: 9.987314e-01 [5.235872e-06] 
Layer 'fc6' weights[0]: 6.521899e-03 [7.764111e-08] 
Layer 'fc6' biases: 9.999890e-01 [8.654137e-08] 
Layer 'fc7' weights[0]: 6.858930e-03 [2.048213e-07] 
Layer 'fc7' biases: 9.996710e-01 [3.767051e-07] 
Layer 'fc8' weights[0]: 4.918876e-03 [1.925627e-05] 
Layer 'fc8' biases: 3.180111e-02 [5.890568e-05] 
Train error last 800 batches: 0.654849
-------------------------------------------------------
Not saving because 0.494507 > 0.299667 (9.300: -1.18%)
======================================================= (2.375 sec)
37.621... logprob:  0.595962, 0.294271 (1.458 sec)
37.622... logprob:  0.618285, 0.233073 (1.453 sec)
37.623... logprob:  0.762601, 0.333333 (1.468 sec)
37.624... logprob:  0.634731, 0.296875 (1.436 sec)
37.625... logprob:  0.700035, 0.305990 (1.422 sec)
37.626... logprob:  0.726097, 0.309896 (1.432 sec)
37.627... logprob:  0.590750, 0.289062 (1.429 sec)
37.628... logprob:  0.698517, 0.334635 (1.433 sec)
37.629... logprob:  0.607360, 0.268229 (1.473 sec)
37.630... logprob:  0.726619, 0.324219 (1.449 sec)
37.631... logprob:  0.843743, 0.380208 (1.429 sec)
37.632... logprob:  0.608471, 0.251302 (1.478 sec)
37.633... logprob:  0.603588, 0.281250 (1.425 sec)
37.634... logprob:  0.834628, 0.368490 (1.425 sec)
37.635... logprob:  0.544474, 0.236979 (1.436 sec)
37.636... logprob:  0.684765, 0.287760 (1.429 sec)
37.637... logprob:  0.547867, 0.236979 (1.423 sec)
37.638... logprob:  0.600179, 0.274740 (1.475 sec)
37.639... logprob:  0.644685, 0.294271 (1.432 sec)
37.640... logprob:  0.714048, 0.305990 (1.432 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.506869, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.832379e-03 [9.164739e-08] 
Layer 'conv1' biases: 2.207550e-06 [1.919954e-11] 
Layer 'conv2' weights[0]: 1.828665e-03 [9.146748e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.693493e-10] 
Layer 'conv3' weights[0]: 1.827785e-03 [9.152753e-08] 
Layer 'conv3' biases: 3.668200e-05 [3.288798e-09] 
Layer 'conv4' weights[0]: 1.835555e-03 [9.196486e-08] 
Layer 'conv4' biases: 9.997718e-01 [1.467928e-07] 
Layer 'conv5' weights[0]: 2.053422e-03 [2.352653e-06] 
Layer 'conv5' biases: 9.987918e-01 [2.541642e-06] 
Layer 'fc6' weights[0]: 6.521232e-03 [5.663818e-08] 
Layer 'fc6' biases: 9.999893e-01 [5.523966e-08] 
Layer 'fc7' weights[0]: 6.858255e-03 [1.358693e-07] 
Layer 'fc7' biases: 9.996678e-01 [1.715226e-07] 
Layer 'fc8' weights[0]: 4.818938e-03 [1.071957e-05] 
Layer 'fc8' biases: 3.103953e-02 [1.673187e-05] 
Train error last 800 batches: 0.654742
-------------------------------------------------------
Not saving because 0.506869 > 0.299667 (9.300: -1.18%)
======================================================= (2.371 sec)
37.641... logprob:  0.621752, 0.299479 (1.488 sec)
37.642... logprob:  0.737990, 0.334635 (1.427 sec)
37.643... logprob:  0.762842, 0.332031 (1.428 sec)
37.644... logprob:  0.567569, 0.282552 (1.433 sec)
37.645... logprob:  0.673969, 0.317708 (1.424 sec)
37.646... logprob:  0.564350, 0.230469 (1.429 sec)
37.647... logprob:  0.678466, 0.281250 (1.480 sec)
37.648... logprob:  0.727921, 0.320312 (1.425 sec)
37.649... logprob:  0.627744, 0.302083 (1.443 sec)
37.650... logprob:  0.687684, 0.316406 (1.472 sec)
37.651... logprob:  0.605194, 0.240885 (1.429 sec)
37.652... logprob:  0.798906, 0.341146 (1.432 sec)
37.653... logprob:  0.751980, 0.322917 (1.425 sec)
37.654... logprob:  0.673456, 0.305990 (1.421 sec)
37.655... logprob:  0.663946, 0.282552 (1.430 sec)
37.656... logprob:  0.663372, 0.292969 (1.479 sec)
37.657... logprob:  0.633560, 0.274740 (1.434 sec)
37.658... logprob:  0.548793, 0.227865 (1.448 sec)
37.659... logprob:  0.674049, 0.282552 (1.465 sec)
37.660... logprob:  0.690659, 0.309896 (1.438 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.422862, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.830547e-03 [9.155788e-08] 
Layer 'conv1' biases: 2.207691e-06 [1.383755e-11] 
Layer 'conv2' weights[0]: 1.826834e-03 [9.138632e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.327931e-10] 
Layer 'conv3' weights[0]: 1.825959e-03 [9.140333e-08] 
Layer 'conv3' biases: 3.668206e-05 [2.905039e-09] 
Layer 'conv4' weights[0]: 1.833718e-03 [9.187294e-08] 
Layer 'conv4' biases: 9.997708e-01 [1.257483e-07] 
Layer 'conv5' weights[0]: 2.051588e-03 [2.265304e-06] 
Layer 'conv5' biases: 9.987910e-01 [2.466571e-06] 
Layer 'fc6' weights[0]: 6.520556e-03 [5.824536e-08] 
Layer 'fc6' biases: 9.999891e-01 [5.736605e-08] 
Layer 'fc7' weights[0]: 6.857527e-03 [1.438376e-07] 
Layer 'fc7' biases: 9.996668e-01 [1.936850e-07] 
Layer 'fc8' weights[0]: 4.815081e-03 [1.287896e-05] 
Layer 'fc8' biases: 3.097140e-02 [3.473604e-05] 
Train error last 800 batches: 0.654866
-------------------------------------------------------
Not saving because 0.422862 > 0.299667 (9.300: -1.18%)
======================================================= (2.363 sec)
37.661... logprob:  0.566183, 0.242188 (1.438 sec)
37.662... logprob:  0.644352, 0.283854 (1.431 sec)
37.663... logprob:  0.643791, 0.304688 (1.413 sec)
37.664... logprob:  0.603354, 0.270833 (1.435 sec)
37.665... logprob:  0.635461, 0.265625 (1.454 sec)
37.666... logprob:  0.723404, 0.300781 (1.448 sec)
37.667... logprob:  0.687495, 0.313802 (1.456 sec)
37.668... logprob:  0.709615, 0.311198 (1.446 sec)
37.669... logprob:  0.635502, 0.313802 (1.450 sec)
37.670... logprob:  0.609811, 0.281250 (1.437 sec)
37.671... logprob:  0.688384, 0.324219 (1.425 sec)
37.672... logprob:  0.695428, 0.313802 (1.421 sec)
37.673... logprob:  0.651303, 0.292969 (1.433 sec)
37.674... logprob:  0.732311, 0.328125 (1.435 sec)
37.675... logprob:  0.502825, 0.213542 (1.463 sec)
37.676... logprob:  0.697564, 0.292969 (1.441 sec)
37.677... logprob:  0.695326, 0.295573 (1.446 sec)
37.678... logprob:  0.694905, 0.320312 (1.471 sec)
37.679... logprob:  0.754848, 0.322917 (1.428 sec)
37.680... logprob:  0.594351, 0.261719 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.438915, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.828720e-03 [9.146550e-08] 
Layer 'conv1' biases: 2.207749e-06 [1.270674e-11] 
Layer 'conv2' weights[0]: 1.825014e-03 [9.128848e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.479549e-10] 
Layer 'conv3' weights[0]: 1.824135e-03 [9.132060e-08] 
Layer 'conv3' biases: 3.665637e-05 [2.895502e-09] 
Layer 'conv4' weights[0]: 1.831887e-03 [9.174398e-08] 
Layer 'conv4' biases: 9.997730e-01 [1.209682e-07] 
Layer 'conv5' weights[0]: 2.052905e-03 [2.150884e-06] 
Layer 'conv5' biases: 9.987564e-01 [2.309145e-06] 
Layer 'fc6' weights[0]: 6.519931e-03 [5.564915e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.412117e-08] 
Layer 'fc7' weights[0]: 6.856850e-03 [1.361983e-07] 
Layer 'fc7' biases: 9.996687e-01 [1.648528e-07] 
Layer 'fc8' weights[0]: 4.857260e-03 [1.075432e-05] 
Layer 'fc8' biases: 3.136132e-02 [1.174270e-05] 
Train error last 800 batches: 0.655450
-------------------------------------------------------
Not saving because 0.438915 > 0.299667 (9.300: -1.18%)
======================================================= (2.413 sec)
37.681... logprob:  0.596142, 0.252604 (1.432 sec)
37.682... logprob:  0.655258, 0.317708 (1.440 sec)
37.683... logprob:  0.647075, 0.277344 (1.433 sec)
37.684... logprob:  0.637877, 0.283854 (1.468 sec)
37.685... logprob:  0.550515, 0.277344 (1.437 sec)
37.686... logprob:  0.584881, 0.260417 (1.429 sec)
37.687... logprob:  0.501064, 0.227865 (1.481 sec)
37.688... logprob:  0.568240, 0.277344 (1.432 sec)
37.689... logprob:  0.668063, 0.291667 (1.430 sec)
37.690... logprob:  0.758412, 0.334635 (1.432 sec)
37.691... logprob:  0.688749, 0.287760 (1.428 sec)
37.692... logprob:  0.589787, 0.229167 (1.433 sec)
37.693... logprob:  0.786429, 0.326823 (1.479 sec)
37.694... logprob:  0.563250, 0.255208 (1.428 sec)
37.695... logprob:  0.571640, 0.273437 (1.444 sec)
37.696... logprob:  0.778148, 0.326823 (1.475 sec)
37.697... logprob:  0.666655, 0.311198 (1.432 sec)
37.698... logprob:  0.631029, 0.260417 (1.429 sec)
37.699... logprob:  0.665087, 0.299479 (1.426 sec)
37.700... logprob:  0.595863, 0.266927 (1.423 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.446504, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.826889e-03 [9.138258e-08] 
Layer 'conv1' biases: 2.207775e-06 [1.906441e-11] 
Layer 'conv2' weights[0]: 1.823181e-03 [9.120273e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.277674e-10] 
Layer 'conv3' weights[0]: 1.822319e-03 [9.127590e-08] 
Layer 'conv3' biases: 3.663665e-05 [3.696999e-09] 
Layer 'conv4' weights[0]: 1.830065e-03 [9.172406e-08] 
Layer 'conv4' biases: 9.997763e-01 [1.613794e-07] 
Layer 'conv5' weights[0]: 2.054311e-03 [2.461169e-06] 
Layer 'conv5' biases: 9.987358e-01 [2.624003e-06] 
Layer 'fc6' weights[0]: 6.519281e-03 [5.742326e-08] 
Layer 'fc6' biases: 9.999890e-01 [5.770470e-08] 
Layer 'fc7' weights[0]: 6.856150e-03 [1.387076e-07] 
Layer 'fc7' biases: 9.996694e-01 [1.817009e-07] 
Layer 'fc8' weights[0]: 4.890304e-03 [1.079843e-05] 
Layer 'fc8' biases: 3.169245e-02 [1.765409e-05] 
Train error last 800 batches: 0.655139
-------------------------------------------------------
Not saving because 0.446504 > 0.299667 (9.300: -1.18%)
======================================================= (2.364 sec)
37.701... logprob:  0.633665, 0.273438 (1.432 sec)
37.702... logprob:  0.724543, 0.304687 (1.486 sec)
37.703... logprob:  0.586360, 0.255208 (1.436 sec)
37.704... logprob:  0.607118, 0.268229 (1.439 sec)
37.705... logprob:  0.579697, 0.259115 (1.469 sec)
37.706... logprob:  0.652596, 0.277344 (1.427 sec)
37.707... logprob:  0.721811, 0.302083 (1.430 sec)
37.708... logprob:  0.634278, 0.269531 (1.429 sec)
37.709... logprob:  0.563305, 0.246094 (1.412 sec)
37.710... logprob:  0.660494, 0.299479 (1.433 sec)
37.711... logprob:  0.739180, 0.330729 (1.462 sec)
37.712... logprob:  0.595576, 0.260417 (1.443 sec)
37.713... logprob:  0.897024, 0.352865 (1.450 sec)
37.714... logprob:  0.713290, 0.286458 (1.455 sec)
37.715... logprob:  0.693998, 0.289062 (1.447 sec)
37.716... logprob:  0.620325, 0.290364 (1.433 sec)
37.717... logprob:  0.706538, 0.294271 (1.420 sec)
37.718... logprob:  0.661656, 0.279948 (1.422 sec)
37.719... logprob:  0.701936, 0.298177 (1.428 sec)
37.720... logprob:  0.612653, 0.261719 (1.444 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.569820, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.825063e-03 [9.124354e-08] 
Layer 'conv1' biases: 2.207966e-06 [3.219446e-11] 
Layer 'conv2' weights[0]: 1.821357e-03 [9.109620e-08] 
Layer 'conv2' biases: 9.999996e-01 [6.750108e-10] 
Layer 'conv3' weights[0]: 1.820487e-03 [9.155913e-08] 
Layer 'conv3' biases: 3.666679e-05 [7.838175e-09] 
Layer 'conv4' weights[0]: 1.828227e-03 [9.225058e-08] 
Layer 'conv4' biases: 9.997699e-01 [3.605218e-07] 
Layer 'conv5' weights[0]: 2.046626e-03 [3.565377e-06] 
Layer 'conv5' biases: 9.987916e-01 [4.126381e-06] 
Layer 'fc6' weights[0]: 6.518585e-03 [7.051088e-08] 
Layer 'fc6' biases: 9.999893e-01 [7.482710e-08] 
Layer 'fc7' weights[0]: 6.855468e-03 [1.780949e-07] 
Layer 'fc7' biases: 9.996662e-01 [2.995990e-07] 
Layer 'fc8' weights[0]: 4.796038e-03 [1.669042e-05] 
Layer 'fc8' biases: 3.094340e-02 [5.100941e-05] 
Train error last 800 batches: 0.655051
-------------------------------------------------------
Not saving because 0.569820 > 0.299667 (9.300: -1.18%)
======================================================= (2.348 sec)
37.721... logprob:  0.600914, 0.255208 (1.459 sec)
37.722... logprob:  0.737510, 0.342448 (1.454 sec)
37.723... logprob:  0.689160, 0.309896 (1.440 sec)
37.724... logprob:  0.632877, 0.253906 (1.466 sec)
37.725... logprob:  0.763514, 0.315104 (1.430 sec)
37.726... logprob:  0.559511, 0.263021 (1.426 sec)
37.727... logprob:  0.635211, 0.287760 (1.424 sec)
37.728... logprob:  0.602684, 0.274740 (1.433 sec)
37.729... logprob:  0.642361, 0.265625 (1.427 sec)
37.730... logprob:  0.723999, 0.335938 (1.470 sec)
37.731... logprob:  0.680755, 0.292969 (1.441 sec)
37.732... logprob:  0.607920, 0.266927 (1.425 sec)
37.733... logprob:  0.773186, 0.312500 (1.515 sec)
37.734... logprob:  0.617312, 0.289062 (1.424 sec)
37.735... logprob:  0.719048, 0.333333 (1.424 sec)
37.736... logprob:  0.818032, 0.356771 (1.428 sec)
37.737... logprob:  0.653312, 0.296875 (1.425 sec)
37.738... logprob:  0.706553, 0.272135 (1.427 sec)
37.739... logprob:  0.742848, 0.294271 (1.474 sec)
37.740... logprob:  0.518526, 0.238281 (1.432 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.524713, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.823239e-03 [9.118825e-08] 
Layer 'conv1' biases: 2.208124e-06 [1.188270e-11] 
Layer 'conv2' weights[0]: 1.819533e-03 [9.100965e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.340938e-10] 
Layer 'conv3' weights[0]: 1.818675e-03 [9.104684e-08] 
Layer 'conv3' biases: 3.666876e-05 [2.936144e-09] 
Layer 'conv4' weights[0]: 1.826381e-03 [9.146025e-08] 
Layer 'conv4' biases: 9.997694e-01 [1.040799e-07] 
Layer 'conv5' weights[0]: 2.043606e-03 [2.286337e-06] 
Layer 'conv5' biases: 9.987947e-01 [2.472161e-06] 
Layer 'fc6' weights[0]: 6.517942e-03 [5.728451e-08] 
Layer 'fc6' biases: 9.999896e-01 [5.583227e-08] 
Layer 'fc7' weights[0]: 6.854759e-03 [1.387952e-07] 
Layer 'fc7' biases: 9.996654e-01 [1.681017e-07] 
Layer 'fc8' weights[0]: 4.773006e-03 [1.110796e-05] 
Layer 'fc8' biases: 3.073841e-02 [1.095572e-05] 
Train error last 800 batches: 0.654780
-------------------------------------------------------
Not saving because 0.524713 > 0.299667 (9.300: -1.18%)
======================================================= (2.348 sec)
37.741... logprob:  0.675375, 0.302083 (1.435 sec)
37.742... logprob:  0.648195, 0.291667 (1.480 sec)
37.743... logprob:  0.689912, 0.292969 (1.431 sec)
37.744... logprob:  0.704545, 0.285156 (1.425 sec)
37.745... logprob:  0.673849, 0.295573 (1.433 sec)
37.746... logprob:  0.576555, 0.221354 (1.424 sec)
37.747... logprob:  0.669402, 0.283854 (1.433 sec)
37.748... logprob:  0.612182, 0.272135 (1.474 sec)
37.749... logprob:  0.625563, 0.269531 (1.433 sec)
37.750... logprob:  0.722257, 0.302083 (1.446 sec)
37.751... logprob:  0.550357, 0.257812 (1.471 sec)
37.752... logprob:  0.680187, 0.282552 (1.427 sec)
37.753... logprob:  0.684136, 0.298177 (1.431 sec)
37.754... logprob:  0.730614, 0.334635 (1.427 sec)
37.755... logprob:  0.751835, 0.326823 (1.421 sec)
37.756... logprob:  0.639677, 0.295573 (1.432 sec)
37.757... logprob:  0.714480, 0.292969 (1.467 sec)
37.758... logprob:  0.660807, 0.291667 (1.439 sec)
37.759... logprob:  0.616258, 0.272135 (1.445 sec)
37.760... logprob:  0.751630, 0.330729 (1.463 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.462443, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.821416e-03 [9.112834e-08] 
Layer 'conv1' biases: 2.208133e-06 [1.516075e-11] 
Layer 'conv2' weights[0]: 1.817710e-03 [9.093865e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.775286e-10] 
Layer 'conv3' weights[0]: 1.816859e-03 [9.098870e-08] 
Layer 'conv3' biases: 3.665647e-05 [3.696807e-09] 
Layer 'conv4' weights[0]: 1.824559e-03 [9.149635e-08] 
Layer 'conv4' biases: 9.997698e-01 [1.632734e-07] 
Layer 'conv5' weights[0]: 2.043521e-03 [2.097381e-06] 
Layer 'conv5' biases: 9.987842e-01 [2.264845e-06] 
Layer 'fc6' weights[0]: 6.517266e-03 [5.695799e-08] 
Layer 'fc6' biases: 9.999894e-01 [5.567177e-08] 
Layer 'fc7' weights[0]: 6.854112e-03 [1.374127e-07] 
Layer 'fc7' biases: 9.996670e-01 [1.620717e-07] 
Layer 'fc8' weights[0]: 4.795454e-03 [1.081704e-05] 
Layer 'fc8' biases: 3.091076e-02 [8.603716e-06] 
Train error last 800 batches: 0.654923
-------------------------------------------------------
Not saving because 0.462443 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
37.761... logprob:  0.581500, 0.248698 (1.451 sec)
37.762... logprob:  0.786727, 0.335937 (1.442 sec)
37.763... logprob:  0.791067, 0.341146 (1.428 sec)
37.764... logprob:  0.672624, 0.295573 (1.418 sec)
37.765... logprob:  0.538272, 0.251302 (1.433 sec)
37.766... logprob:  0.720868, 0.307292 (1.447 sec)
37.767... logprob:  0.586693, 0.231771 (1.450 sec)
37.768... logprob:  0.646421, 0.266927 (1.462 sec)
37.769... logprob:  0.706807, 0.317708 (1.465 sec)
37.770... logprob:  0.716451, 0.316406 (1.476 sec)
37.771... logprob:  0.727833, 0.302083 (1.485 sec)
37.772... logprob:  0.641524, 0.290365 (1.437 sec)
37.773... logprob:  0.709556, 0.298177 (1.440 sec)
37.774... logprob:  0.628180, 0.294271 (1.456 sec)
37.775... logprob:  0.630446, 0.266927 (1.455 sec)
37.776... logprob:  0.632895, 0.277344 (1.475 sec)
37.777... logprob:  0.612209, 0.285156 (1.472 sec)
37.778... logprob:  0.668286, 0.277344 (1.456 sec)
37.779... logprob:  0.742696, 0.324219 (1.485 sec)
37.780... logprob:  0.689340, 0.305990 (1.445 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.454355, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.819594e-03 [9.102746e-08] 
Layer 'conv1' biases: 2.208137e-06 [1.385003e-11] 
Layer 'conv2' weights[0]: 1.815897e-03 [9.084064e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.359984e-10] 
Layer 'conv3' weights[0]: 1.815050e-03 [9.088373e-08] 
Layer 'conv3' biases: 3.664955e-05 [3.095076e-09] 
Layer 'conv4' weights[0]: 1.822743e-03 [9.133555e-08] 
Layer 'conv4' biases: 9.997697e-01 [1.383440e-07] 
Layer 'conv5' weights[0]: 2.041954e-03 [2.217123e-06] 
Layer 'conv5' biases: 9.987863e-01 [2.419082e-06] 
Layer 'fc6' weights[0]: 6.516615e-03 [5.616110e-08] 
Layer 'fc6' biases: 9.999893e-01 [5.416430e-08] 
Layer 'fc7' weights[0]: 6.853416e-03 [1.358891e-07] 
Layer 'fc7' biases: 9.996662e-01 [1.608171e-07] 
Layer 'fc8' weights[0]: 4.779767e-03 [1.055126e-05] 
Layer 'fc8' biases: 3.077811e-02 [9.867611e-06] 
Train error last 800 batches: 0.654812
-------------------------------------------------------
Not saving because 0.454355 > 0.299667 (9.300: -1.18%)
======================================================= (2.369 sec)
37.781... logprob:  0.577660, 0.256510 (1.450 sec)
37.782... logprob:  0.595547, 0.264323 (1.451 sec)
37.783... logprob:  0.738535, 0.319010 (1.459 sec)
37.784... logprob:  0.600886, 0.277344 (1.451 sec)
37.785... logprob:  0.748503, 0.312500 (1.492 sec)
37.786... logprob:  0.649923, 0.265625 (1.466 sec)
37.787... logprob:  0.729720, 0.319010 (1.454 sec)
37.788... logprob:  0.736395, 0.311198 (1.486 sec)
37.789... logprob:  0.535474, 0.223958 (1.448 sec)
37.790... logprob:  0.636804, 0.291667 (1.447 sec)
37.791... logprob:  0.596370, 0.268229 (1.444 sec)
37.792... logprob:  0.651893, 0.278646 (1.454 sec)
37.793... logprob:  0.679776, 0.313802 (1.445 sec)
37.794... logprob:  0.623236, 0.247396 (1.481 sec)
37.795... logprob:  0.694099, 0.312500 (1.462 sec)
37.796... logprob:  0.594182, 0.257812 (1.453 sec)
37.797... logprob:  0.614370, 0.274740 (1.497 sec)
37.798... logprob:  0.601797, 0.264323 (1.448 sec)
37.799... logprob:  0.523208, 0.229167 (1.440 sec)
37.800... logprob:  0.530267, 0.234375 (1.395 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.471606, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.817775e-03 [9.095926e-08] 
Layer 'conv1' biases: 2.208186e-06 [2.541594e-11] 
Layer 'conv2' weights[0]: 1.814097e-03 [9.076112e-08] 
Layer 'conv2' biases: 9.999996e-01 [4.328171e-10] 
Layer 'conv3' weights[0]: 1.813231e-03 [9.094186e-08] 
Layer 'conv3' biases: 3.663128e-05 [5.460904e-09] 
Layer 'conv4' weights[0]: 1.820921e-03 [9.163473e-08] 
Layer 'conv4' biases: 9.997729e-01 [2.660904e-07] 
Layer 'conv5' weights[0]: 2.043419e-03 [3.933591e-06] 
Layer 'conv5' biases: 9.987552e-01 [4.433553e-06] 
Layer 'fc6' weights[0]: 6.515906e-03 [7.330858e-08] 
Layer 'fc6' biases: 9.999891e-01 [7.897805e-08] 
Layer 'fc7' weights[0]: 6.852661e-03 [1.893913e-07] 
Layer 'fc7' biases: 9.996673e-01 [3.480404e-07] 
Layer 'fc8' weights[0]: 4.826189e-03 [1.861482e-05] 
Layer 'fc8' biases: 3.123170e-02 [6.284987e-05] 
Train error last 800 batches: 0.654530
-------------------------------------------------------
Not saving because 0.471606 > 0.299667 (9.300: -1.18%)
======================================================= (2.391 sec)
38.1... logprob:  0.629582, 0.261719 (1.406 sec)
38.2... logprob:  0.649171, 0.285156 (1.447 sec)
38.3... logprob:  0.638700, 0.291667 (1.417 sec)
38.4... logprob:  0.593528, 0.259115 (1.405 sec)
38.5... logprob:  0.656855, 0.282552 (1.428 sec)
38.6... logprob:  0.630744, 0.264323 (1.387 sec)
38.7... logprob:  0.592291, 0.266927 (1.421 sec)
38.8... logprob:  0.733520, 0.315104 (1.399 sec)
38.9... logprob:  0.644254, 0.274740 (1.427 sec)
38.10... logprob:  0.646299, 0.286458 (1.411 sec)
38.11... logprob:  0.664034, 0.341146 (1.439 sec)
38.12... logprob:  0.744258, 0.319010 (1.406 sec)
38.13... logprob:  0.608630, 0.235677 (1.416 sec)
38.14... logprob:  0.562313, 0.238281 (1.397 sec)
38.15... logprob:  0.661114, 0.274740 (1.403 sec)
38.16... logprob:  0.714774, 0.343750 (1.400 sec)
38.17... logprob:  0.705701, 0.292969 (1.392 sec)
38.18... logprob:  0.513550, 0.244792 (1.398 sec)
38.19... logprob:  0.531236, 0.248698 (1.394 sec)
38.20... logprob:  0.657890, 0.285156 (1.397 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.380284, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.815961e-03 [9.083841e-08] 
Layer 'conv1' biases: 2.208161e-06 [1.690939e-11] 
Layer 'conv2' weights[0]: 1.812276e-03 [9.065396e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.165953e-10] 
Layer 'conv3' weights[0]: 1.811407e-03 [9.067515e-08] 
Layer 'conv3' biases: 3.660807e-05 [2.815238e-09] 
Layer 'conv4' weights[0]: 1.819104e-03 [9.112592e-08] 
Layer 'conv4' biases: 9.997748e-01 [1.314537e-07] 
Layer 'conv5' weights[0]: 2.044902e-03 [2.091558e-06] 
Layer 'conv5' biases: 9.987226e-01 [2.269431e-06] 
Layer 'fc6' weights[0]: 6.515238e-03 [5.496373e-08] 
Layer 'fc6' biases: 9.999889e-01 [5.428915e-08] 
Layer 'fc7' weights[0]: 6.851994e-03 [1.326320e-07] 
Layer 'fc7' biases: 9.996689e-01 [1.669135e-07] 
Layer 'fc8' weights[0]: 4.886828e-03 [1.080773e-05] 
Layer 'fc8' biases: 3.176857e-02 [2.190734e-05] 
Train error last 800 batches: 0.654431
-------------------------------------------------------
Not saving because 0.380284 > 0.299667 (9.300: -1.18%)
======================================================= (2.370 sec)
38.21... logprob:  0.667253, 0.282552 (1.403 sec)
38.22... logprob:  0.675127, 0.304687 (1.414 sec)
38.23... logprob:  0.726288, 0.339844 (1.405 sec)
38.24... logprob:  0.626709, 0.305989 (1.412 sec)
38.25... logprob:  0.623936, 0.281250 (1.402 sec)
38.26... logprob:  0.653283, 0.272135 (1.439 sec)
38.27... logprob:  0.625427, 0.300781 (1.381 sec)
38.28... logprob:  0.639922, 0.274740 (1.409 sec)
38.29... logprob:  0.655019, 0.286458 (1.415 sec)
38.30... logprob:  0.647550, 0.283854 (1.420 sec)
38.31... logprob:  0.673740, 0.296875 (1.402 sec)
38.32... logprob:  0.678228, 0.304687 (1.382 sec)
38.33... logprob:  0.657152, 0.287760 (1.439 sec)
38.34... logprob:  0.711974, 0.347656 (1.386 sec)
38.35... logprob:  0.505750, 0.234375 (1.394 sec)
38.36... logprob:  0.659288, 0.273437 (1.403 sec)
38.37... logprob:  0.693629, 0.313802 (1.399 sec)
38.38... logprob:  0.619790, 0.277344 (1.392 sec)
38.39... logprob:  0.767088, 0.342448 (1.427 sec)
38.40... logprob:  0.641760, 0.299479 (1.404 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.502007, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.814134e-03 [9.071097e-08] 
Layer 'conv1' biases: 2.208315e-06 [2.051049e-11] 
Layer 'conv2' weights[0]: 1.810458e-03 [9.055271e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.857611e-10] 
Layer 'conv3' weights[0]: 1.809594e-03 [9.067935e-08] 
Layer 'conv3' biases: 3.662726e-05 [4.361593e-09] 
Layer 'conv4' weights[0]: 1.817272e-03 [9.113785e-08] 
Layer 'conv4' biases: 9.997737e-01 [1.988762e-07] 
Layer 'conv5' weights[0]: 2.041396e-03 [2.314179e-06] 
Layer 'conv5' biases: 9.987443e-01 [2.554466e-06] 
Layer 'fc6' weights[0]: 6.514585e-03 [5.808264e-08] 
Layer 'fc6' biases: 9.999888e-01 [5.830234e-08] 
Layer 'fc7' weights[0]: 6.851322e-03 [1.426232e-07] 
Layer 'fc7' biases: 9.996675e-01 [1.978655e-07] 
Layer 'fc8' weights[0]: 4.853002e-03 [1.213072e-05] 
Layer 'fc8' biases: 3.150959e-02 [2.442811e-05] 
Train error last 800 batches: 0.653923
-------------------------------------------------------
Not saving because 0.502007 > 0.299667 (9.300: -1.18%)
======================================================= (2.372 sec)
38.41... logprob:  0.601357, 0.292969 (1.426 sec)
38.42... logprob:  0.588387, 0.256510 (1.417 sec)
38.43... logprob:  0.681046, 0.289062 (1.407 sec)
38.44... logprob:  0.657294, 0.292969 (1.431 sec)
38.45... logprob:  0.576925, 0.278646 (1.392 sec)
38.46... logprob:  0.684020, 0.299479 (1.402 sec)
38.47... logprob:  0.473019, 0.195312 (1.391 sec)
38.48... logprob:  0.650684, 0.243490 (1.452 sec)
38.49... logprob:  0.657668, 0.317708 (1.408 sec)
38.50... logprob:  0.676610, 0.295573 (1.416 sec)
38.51... logprob:  0.626062, 0.302083 (1.410 sec)
38.52... logprob:  0.753564, 0.300781 (1.393 sec)
38.53... logprob:  0.633274, 0.299479 (1.439 sec)
38.54... logprob:  0.735830, 0.321614 (1.381 sec)
38.55... logprob:  0.551242, 0.261719 (1.396 sec)
38.56... logprob:  0.641312, 0.270833 (1.397 sec)
38.57... logprob:  0.788403, 0.312500 (1.427 sec)
38.58... logprob:  0.625430, 0.277344 (1.398 sec)
38.59... logprob:  0.608053, 0.263021 (1.462 sec)
38.60... logprob:  0.746169, 0.326823 (1.410 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.358869, 0.062500 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.812326e-03 [9.061264e-08] 
Layer 'conv1' biases: 2.208435e-06 [2.625581e-11] 
Layer 'conv2' weights[0]: 1.808646e-03 [9.045866e-08] 
Layer 'conv2' biases: 9.999996e-01 [6.306722e-10] 
Layer 'conv3' weights[0]: 1.807791e-03 [9.090250e-08] 
Layer 'conv3' biases: 3.664680e-05 [7.659358e-09] 
Layer 'conv4' weights[0]: 1.815450e-03 [9.151221e-08] 
Layer 'conv4' biases: 9.997723e-01 [3.481862e-07] 
Layer 'conv5' weights[0]: 2.038194e-03 [3.348294e-06] 
Layer 'conv5' biases: 9.987612e-01 [3.744105e-06] 
Layer 'fc6' weights[0]: 6.513898e-03 [6.632357e-08] 
Layer 'fc6' biases: 9.999889e-01 [6.966344e-08] 
Layer 'fc7' weights[0]: 6.850661e-03 [1.684677e-07] 
Layer 'fc7' biases: 9.996668e-01 [2.747346e-07] 
Layer 'fc8' weights[0]: 4.829509e-03 [1.563790e-05] 
Layer 'fc8' biases: 3.125457e-02 [4.759232e-05] 
Train error last 800 batches: 0.653875
-------------------------------------------------------
Not saving because 0.358869 > 0.299667 (9.300: -1.18%)
======================================================= (2.393 sec)
38.61... logprob:  0.558265, 0.259115 (1.428 sec)
38.62... logprob:  0.633651, 0.278646 (1.454 sec)
38.63... logprob:  0.628866, 0.281250 (1.439 sec)
38.64... logprob:  0.671684, 0.266927 (1.406 sec)
38.65... logprob:  0.652192, 0.299479 (1.399 sec)
38.66... logprob:  0.603513, 0.289062 (1.437 sec)
38.67... logprob:  0.521762, 0.250000 (1.385 sec)
38.68... logprob:  0.675264, 0.320312 (1.397 sec)
38.69... logprob:  0.604072, 0.292969 (1.420 sec)
38.70... logprob:  0.596250, 0.268229 (1.417 sec)
38.71... logprob:  0.596545, 0.251302 (1.453 sec)
38.72... logprob:  0.689610, 0.307292 (1.401 sec)
38.73... logprob:  0.626541, 0.281250 (1.427 sec)
38.74... logprob:  0.618186, 0.263021 (1.412 sec)
38.75... logprob:  0.598160, 0.276042 (1.412 sec)
38.76... logprob:  0.583956, 0.263021 (1.425 sec)
38.77... logprob:  0.694947, 0.299479 (1.425 sec)
38.78... logprob:  0.696311, 0.317708 (1.447 sec)
38.79... logprob:  0.715361, 0.295573 (1.394 sec)
38.80... logprob:  0.765264, 0.312500 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.416178, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.810508e-03 [9.055335e-08] 
Layer 'conv1' biases: 2.208535e-06 [1.447740e-11] 
Layer 'conv2' weights[0]: 1.806839e-03 [9.036914e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.063861e-10] 
Layer 'conv3' weights[0]: 1.805990e-03 [9.042481e-08] 
Layer 'conv3' biases: 3.663563e-05 [3.121760e-09] 
Layer 'conv4' weights[0]: 1.813645e-03 [9.088926e-08] 
Layer 'conv4' biases: 9.997737e-01 [1.424432e-07] 
Layer 'conv5' weights[0]: 2.038788e-03 [2.191394e-06] 
Layer 'conv5' biases: 9.987319e-01 [2.473850e-06] 
Layer 'fc6' weights[0]: 6.513288e-03 [5.950479e-08] 
Layer 'fc6' biases: 9.999887e-01 [6.069235e-08] 
Layer 'fc7' weights[0]: 6.849956e-03 [1.498329e-07] 
Layer 'fc7' biases: 9.996684e-01 [2.097524e-07] 
Layer 'fc8' weights[0]: 4.885668e-03 [1.281586e-05] 
Layer 'fc8' biases: 3.171342e-02 [3.248758e-05] 
Train error last 800 batches: 0.654098
-------------------------------------------------------
Not saving because 0.416178 > 0.299667 (9.300: -1.18%)
======================================================= (2.359 sec)
38.81... logprob:  0.595385, 0.239583 (1.421 sec)
38.82... logprob:  0.478524, 0.216146 (1.426 sec)
38.83... logprob:  0.738574, 0.321615 (1.400 sec)
38.84... logprob:  0.634224, 0.302083 (1.460 sec)
38.85... logprob:  0.637457, 0.307292 (1.416 sec)
38.86... logprob:  0.666439, 0.292969 (1.412 sec)
38.87... logprob:  0.956837, 0.368490 (1.410 sec)
38.88... logprob:  0.848753, 0.368490 (1.407 sec)
38.89... logprob:  0.646566, 0.283854 (1.431 sec)
38.90... logprob:  0.794936, 0.332031 (1.387 sec)
38.91... logprob:  0.562443, 0.244792 (1.392 sec)
38.92... logprob:  0.634305, 0.269531 (1.394 sec)
38.93... logprob:  0.682519, 0.321615 (1.390 sec)
38.94... logprob:  0.549362, 0.231771 (1.391 sec)
38.95... logprob:  0.708801, 0.333333 (1.401 sec)
38.96... logprob:  0.784592, 0.325521 (1.399 sec)
38.97... logprob:  0.655845, 0.281250 (1.391 sec)
38.98... logprob:  0.648963, 0.298177 (1.446 sec)
38.99... logprob:  0.684874, 0.294271 (1.410 sec)
38.100... logprob:  0.593843, 0.260417 (1.396 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.466996, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.808702e-03 [9.045221e-08] 
Layer 'conv1' biases: 2.208752e-06 [2.279346e-11] 
Layer 'conv2' weights[0]: 1.805029e-03 [9.028460e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.948862e-10] 
Layer 'conv3' weights[0]: 1.804179e-03 [9.050265e-08] 
Layer 'conv3' biases: 3.666742e-05 [5.109336e-09] 
Layer 'conv4' weights[0]: 1.811834e-03 [9.101584e-08] 
Layer 'conv4' biases: 9.997666e-01 [2.552111e-07] 
Layer 'conv5' weights[0]: 2.029828e-03 [2.211949e-06] 
Layer 'conv5' biases: 9.987885e-01 [2.473239e-06] 
Layer 'fc6' weights[0]: 6.512650e-03 [5.863817e-08] 
Layer 'fc6' biases: 9.999891e-01 [5.855860e-08] 
Layer 'fc7' weights[0]: 6.849306e-03 [1.424777e-07] 
Layer 'fc7' biases: 9.996652e-01 [1.916084e-07] 
Layer 'fc8' weights[0]: 4.802036e-03 [1.151061e-05] 
Layer 'fc8' biases: 3.103021e-02 [2.068781e-05] 
Train error last 800 batches: 0.654217
-------------------------------------------------------
Not saving because 0.466996 > 0.299667 (9.300: -1.18%)
======================================================= (2.365 sec)
38.101... logprob:  0.524138, 0.226562 (1.447 sec)
38.102... logprob:  0.725749, 0.305990 (1.389 sec)
38.103... logprob:  0.729176, 0.334635 (1.393 sec)
38.104... logprob:  0.589225, 0.243490 (1.396 sec)
38.105... logprob:  0.832394, 0.355469 (1.387 sec)
38.106... logprob:  0.656333, 0.282552 (1.386 sec)
38.107... logprob:  0.616920, 0.296875 (1.434 sec)
38.108... logprob:  0.674383, 0.300781 (1.398 sec)
38.109... logprob:  0.650972, 0.304687 (1.400 sec)
38.110... logprob:  0.773203, 0.320312 (1.392 sec)
38.111... logprob:  0.633728, 0.276042 (1.389 sec)
38.112... logprob:  0.594830, 0.269531 (1.392 sec)
38.113... logprob:  0.545725, 0.264323 (1.392 sec)
38.114... logprob:  0.643024, 0.283854 (1.427 sec)
38.115... logprob:  0.657096, 0.269531 (1.403 sec)
38.116... logprob:  0.720279, 0.294271 (1.396 sec)
38.117... logprob:  0.703488, 0.295573 (1.443 sec)
38.118... logprob:  0.679002, 0.298177 (1.383 sec)
38.119... logprob:  0.609521, 0.287760 (1.389 sec)
38.120... logprob:  0.773090, 0.299479 (1.399 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.479752, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.806897e-03 [9.036137e-08] 
Layer 'conv1' biases: 2.208767e-06 [2.221792e-11] 
Layer 'conv2' weights[0]: 1.803226e-03 [9.019920e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.616197e-10] 
Layer 'conv3' weights[0]: 1.802377e-03 [9.036772e-08] 
Layer 'conv3' biases: 3.666593e-05 [4.580375e-09] 
Layer 'conv4' weights[0]: 1.810028e-03 [9.078228e-08] 
Layer 'conv4' biases: 9.997648e-01 [1.997471e-07] 
Layer 'conv5' weights[0]: 2.027289e-03 [2.345255e-06] 
Layer 'conv5' biases: 9.987826e-01 [2.575160e-06] 
Layer 'fc6' weights[0]: 6.511976e-03 [5.920778e-08] 
Layer 'fc6' biases: 9.999890e-01 [5.897045e-08] 
Layer 'fc7' weights[0]: 6.848656e-03 [1.455524e-07] 
Layer 'fc7' biases: 9.996650e-01 [1.839066e-07] 
Layer 'fc8' weights[0]: 4.810657e-03 [1.178184e-05] 
Layer 'fc8' biases: 3.109322e-02 [1.907023e-05] 
Train error last 800 batches: 0.654206
-------------------------------------------------------
Not saving because 0.479752 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
38.121... logprob:  0.578000, 0.261719 (1.397 sec)
38.122... logprob:  0.731397, 0.316406 (1.442 sec)
38.123... logprob:  0.699586, 0.300781 (1.381 sec)
38.124... logprob:  0.720737, 0.290365 (1.396 sec)
38.125... logprob:  0.706740, 0.308594 (1.395 sec)
38.126... logprob:  0.660487, 0.278646 (1.391 sec)
38.127... logprob:  0.651072, 0.290365 (1.394 sec)
38.128... logprob:  0.701126, 0.328125 (1.414 sec)
38.129... logprob:  0.811638, 0.346354 (1.412 sec)
38.130... logprob:  0.615380, 0.282552 (1.409 sec)
38.131... logprob:  0.743608, 0.315104 (1.402 sec)
38.132... logprob:  0.697749, 0.286458 (1.432 sec)
38.133... logprob:  0.718404, 0.356771 (1.388 sec)
38.134... logprob:  0.705279, 0.328125 (1.390 sec)
38.135... logprob:  0.609266, 0.279948 (1.392 sec)
38.136... logprob:  0.719372, 0.300781 (1.396 sec)
38.137... logprob:  0.677633, 0.273437 (1.387 sec)
38.138... logprob:  0.586195, 0.276042 (1.439 sec)
38.139... logprob:  0.631863, 0.276042 (1.390 sec)
38.140... logprob:  0.805402, 0.364583 (1.404 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.520999, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.805093e-03 [9.031774e-08] 
Layer 'conv1' biases: 2.208770e-06 [1.142519e-11] 
Layer 'conv2' weights[0]: 1.801430e-03 [9.012375e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.459216e-10] 
Layer 'conv3' weights[0]: 1.800578e-03 [9.015321e-08] 
Layer 'conv3' biases: 3.668074e-05 [3.006728e-09] 
Layer 'conv4' weights[0]: 1.808207e-03 [9.059943e-08] 
Layer 'conv4' biases: 9.997617e-01 [1.398974e-07] 
Layer 'conv5' weights[0]: 2.021918e-03 [2.015769e-06] 
Layer 'conv5' biases: 9.987969e-01 [2.127541e-06] 
Layer 'fc6' weights[0]: 6.511294e-03 [5.596392e-08] 
Layer 'fc6' biases: 9.999891e-01 [5.412499e-08] 
Layer 'fc7' weights[0]: 6.847949e-03 [1.361770e-07] 
Layer 'fc7' biases: 9.996637e-01 [1.616480e-07] 
Layer 'fc8' weights[0]: 4.788414e-03 [1.069388e-05] 
Layer 'fc8' biases: 3.096160e-02 [1.078976e-05] 
Train error last 800 batches: 0.654453
-------------------------------------------------------
Not saving because 0.520999 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
38.141... logprob:  0.678534, 0.274740 (1.439 sec)
38.142... logprob:  0.645937, 0.307292 (1.397 sec)
38.143... logprob:  0.513950, 0.235677 (1.420 sec)
38.144... logprob:  0.742009, 0.334635 (1.407 sec)
38.145... logprob:  0.555878, 0.243490 (1.410 sec)
38.146... logprob:  0.702703, 0.320312 (1.402 sec)
38.147... logprob:  0.547547, 0.252604 (1.429 sec)
38.148... logprob:  0.677386, 0.307292 (1.382 sec)
38.149... logprob:  0.694168, 0.325521 (1.389 sec)
38.150... logprob:  0.643508, 0.309896 (1.394 sec)
38.151... logprob:  0.559506, 0.230469 (1.389 sec)
38.152... logprob:  0.808862, 0.329427 (1.388 sec)
38.153... logprob:  0.626219, 0.268229 (1.436 sec)
38.154... logprob:  0.741110, 0.285156 (1.392 sec)
38.155... logprob:  0.661597, 0.295573 (1.402 sec)
38.156... logprob:  0.533957, 0.256510 (1.432 sec)
38.157... logprob:  0.560945, 0.281250 (1.392 sec)
38.158... logprob:  0.691282, 0.287760 (1.397 sec)
38.159... logprob:  0.648875, 0.277344 (1.388 sec)
38.160... logprob:  0.637837, 0.292969 (1.393 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.466986, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.803282e-03 [9.019194e-08] 
Layer 'conv1' biases: 2.208763e-06 [1.296822e-11] 
Layer 'conv2' weights[0]: 1.799625e-03 [9.001564e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.436611e-10] 
Layer 'conv3' weights[0]: 1.798759e-03 [9.005918e-08] 
Layer 'conv3' biases: 3.666197e-05 [3.245771e-09] 
Layer 'conv4' weights[0]: 1.806405e-03 [9.050458e-08] 
Layer 'conv4' biases: 9.997641e-01 [1.490536e-07] 
Layer 'conv5' weights[0]: 2.023372e-03 [2.539301e-06] 
Layer 'conv5' biases: 9.987496e-01 [2.748023e-06] 
Layer 'fc6' weights[0]: 6.510624e-03 [5.771360e-08] 
Layer 'fc6' biases: 9.999889e-01 [5.765646e-08] 
Layer 'fc7' weights[0]: 6.847257e-03 [1.429739e-07] 
Layer 'fc7' biases: 9.996663e-01 [1.984886e-07] 
Layer 'fc8' weights[0]: 4.861209e-03 [1.249030e-05] 
Layer 'fc8' biases: 3.159416e-02 [3.222621e-05] 
Train error last 800 batches: 0.654437
-------------------------------------------------------
Not saving because 0.466986 > 0.299667 (9.300: -1.18%)
======================================================= (2.379 sec)
38.161... logprob:  0.555745, 0.242187 (1.404 sec)
38.162... logprob:  0.799578, 0.335937 (1.402 sec)
38.163... logprob:  0.580597, 0.274740 (1.429 sec)
38.164... logprob:  0.623396, 0.256510 (1.416 sec)
38.165... logprob:  0.617947, 0.274740 (1.421 sec)
38.166... logprob:  0.744368, 0.296875 (1.441 sec)
38.167... logprob:  0.602145, 0.276042 (1.424 sec)
38.168... logprob:  0.613061, 0.260417 (1.416 sec)
38.169... logprob:  0.553859, 0.231771 (1.453 sec)
38.170... logprob:  0.626001, 0.276042 (1.395 sec)
38.171... logprob:  0.782962, 0.319010 (1.416 sec)
38.172... logprob:  0.637702, 0.273438 (1.409 sec)
38.173... logprob:  0.664089, 0.277344 (1.414 sec)
38.174... logprob:  0.854412, 0.342448 (1.414 sec)
38.175... logprob:  0.646421, 0.294271 (1.460 sec)
38.176... logprob:  0.690114, 0.300781 (1.410 sec)
38.177... logprob:  0.573752, 0.270833 (1.418 sec)
38.178... logprob:  0.618372, 0.289062 (1.454 sec)
38.179... logprob:  0.546487, 0.240885 (1.398 sec)
38.180... logprob:  0.704584, 0.330729 (1.416 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.520180, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.801485e-03 [9.009490e-08] 
Layer 'conv1' biases: 2.208857e-06 [1.431553e-11] 
Layer 'conv2' weights[0]: 1.797835e-03 [8.992543e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.641774e-10] 
Layer 'conv3' weights[0]: 1.796966e-03 [8.999023e-08] 
Layer 'conv3' biases: 3.668229e-05 [3.231517e-09] 
Layer 'conv4' weights[0]: 1.804605e-03 [9.047805e-08] 
Layer 'conv4' biases: 9.997613e-01 [1.891256e-07] 
Layer 'conv5' weights[0]: 2.018940e-03 [2.093203e-06] 
Layer 'conv5' biases: 9.987664e-01 [2.237333e-06] 
Layer 'fc6' weights[0]: 6.510027e-03 [5.582889e-08] 
Layer 'fc6' biases: 9.999890e-01 [5.470568e-08] 
Layer 'fc7' weights[0]: 6.846572e-03 [1.374978e-07] 
Layer 'fc7' biases: 9.996652e-01 [1.830477e-07] 
Layer 'fc8' weights[0]: 4.830454e-03 [1.192434e-05] 
Layer 'fc8' biases: 3.141419e-02 [2.631056e-05] 
Train error last 800 batches: 0.654407
-------------------------------------------------------
Not saving because 0.520180 > 0.299667 (9.300: -1.18%)
======================================================= (2.406 sec)
38.181... logprob:  0.669959, 0.252604 (1.422 sec)
38.182... logprob:  0.634507, 0.300781 (1.418 sec)
38.183... logprob:  0.648483, 0.289062 (1.417 sec)
38.184... logprob:  0.785787, 0.335938 (1.418 sec)
38.185... logprob:  0.570535, 0.252604 (1.395 sec)
38.186... logprob:  0.658664, 0.316406 (1.399 sec)
38.187... logprob:  0.671570, 0.263021 (1.390 sec)
38.188... logprob:  0.663546, 0.285156 (1.390 sec)
38.189... logprob:  0.666975, 0.302083 (1.385 sec)
38.190... logprob:  0.564048, 0.264323 (1.429 sec)
38.191... logprob:  0.707505, 0.337240 (1.402 sec)
38.192... logprob:  0.779526, 0.328125 (1.409 sec)
38.193... logprob:  0.559142, 0.255208 (1.414 sec)
38.194... logprob:  0.718842, 0.298177 (1.406 sec)
38.195... logprob:  0.543352, 0.255208 (1.396 sec)
38.196... logprob:  0.633018, 0.286458 (1.388 sec)
38.197... logprob:  0.632504, 0.266927 (1.394 sec)
38.198... logprob:  0.552283, 0.235677 (1.398 sec)
38.199... logprob:  0.657559, 0.278646 (1.382 sec)
38.200... logprob:  0.721601, 0.311198 (1.432 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.394362, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.799685e-03 [9.003023e-08] 
Layer 'conv1' biases: 2.208959e-06 [1.522561e-11] 
Layer 'conv2' weights[0]: 1.796024e-03 [8.984998e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.220507e-10] 
Layer 'conv3' weights[0]: 1.795178e-03 [8.987772e-08] 
Layer 'conv3' biases: 3.668702e-05 [2.742242e-09] 
Layer 'conv4' weights[0]: 1.802795e-03 [9.032020e-08] 
Layer 'conv4' biases: 9.997602e-01 [1.129699e-07] 
Layer 'conv5' weights[0]: 2.016425e-03 [2.301789e-06] 
Layer 'conv5' biases: 9.987585e-01 [2.465607e-06] 
Layer 'fc6' weights[0]: 6.509349e-03 [5.868685e-08] 
Layer 'fc6' biases: 9.999890e-01 [5.910104e-08] 
Layer 'fc7' weights[0]: 6.845895e-03 [1.456593e-07] 
Layer 'fc7' biases: 9.996653e-01 [2.015737e-07] 
Layer 'fc8' weights[0]: 4.845398e-03 [1.282710e-05] 
Layer 'fc8' biases: 3.153943e-02 [3.506151e-05] 
Train error last 800 batches: 0.655084
-------------------------------------------------------
Not saving because 0.394362 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
38.201... logprob:  0.708781, 0.282552 (1.419 sec)
38.202... logprob:  0.761051, 0.315104 (1.403 sec)
38.203... logprob:  0.669845, 0.278646 (1.437 sec)
38.204... logprob:  0.667729, 0.294271 (1.386 sec)
38.205... logprob:  0.495530, 0.214844 (1.401 sec)
38.206... logprob:  0.625118, 0.279948 (1.394 sec)
38.207... logprob:  0.598285, 0.261719 (1.386 sec)
38.208... logprob:  0.727149, 0.322917 (1.389 sec)
38.209... logprob:  0.570255, 0.268229 (1.413 sec)
38.210... logprob:  0.774929, 0.309896 (1.413 sec)
38.211... logprob:  0.695981, 0.311198 (1.415 sec)
38.212... logprob:  0.666481, 0.300781 (1.412 sec)
38.213... logprob:  0.685446, 0.313802 (1.451 sec)
38.214... logprob:  0.737716, 0.313802 (1.421 sec)
38.215... logprob:  0.571945, 0.226562 (1.414 sec)
38.216... logprob:  0.744528, 0.320312 (1.464 sec)
38.217... logprob:  0.496700, 0.234375 (1.394 sec)
38.218... logprob:  0.688762, 0.289062 (1.414 sec)
38.219... logprob:  0.771850, 0.350260 (1.409 sec)
38.220... logprob:  0.629295, 0.268229 (1.413 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.505868, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.797883e-03 [8.993380e-08] 
Layer 'conv1' biases: 2.209033e-06 [1.879171e-11] 
Layer 'conv2' weights[0]: 1.794234e-03 [8.975753e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.355365e-10] 
Layer 'conv3' weights[0]: 1.793367e-03 [8.989883e-08] 
Layer 'conv3' biases: 3.669411e-05 [4.362404e-09] 
Layer 'conv4' weights[0]: 1.800990e-03 [9.047541e-08] 
Layer 'conv4' biases: 9.997596e-01 [2.077748e-07] 
Layer 'conv5' weights[0]: 2.013768e-03 [2.725797e-06] 
Layer 'conv5' biases: 9.987645e-01 [2.869555e-06] 
Layer 'fc6' weights[0]: 6.508661e-03 [6.312034e-08] 
Layer 'fc6' biases: 9.999887e-01 [6.528872e-08] 
Layer 'fc7' weights[0]: 6.845182e-03 [1.637533e-07] 
Layer 'fc7' biases: 9.996646e-01 [2.521907e-07] 
Layer 'fc8' weights[0]: 4.831309e-03 [1.684467e-05] 
Layer 'fc8' biases: 3.146163e-02 [5.546833e-05] 
Train error last 800 batches: 0.654925
-------------------------------------------------------
Not saving because 0.505868 > 0.299667 (9.300: -1.18%)
======================================================= (2.367 sec)
38.221... logprob:  0.639263, 0.276042 (1.407 sec)
38.222... logprob:  0.726629, 0.325521 (1.463 sec)
38.223... logprob:  0.783022, 0.315104 (1.423 sec)
38.224... logprob:  0.624560, 0.265625 (1.436 sec)
38.225... logprob:  0.642260, 0.304687 (1.446 sec)
38.226... logprob:  0.673713, 0.320312 (1.417 sec)
38.227... logprob:  0.642759, 0.294271 (1.426 sec)
38.228... logprob:  0.682123, 0.289062 (1.420 sec)
38.229... logprob:  0.741334, 0.300781 (1.414 sec)
38.230... logprob:  0.685113, 0.292969 (1.420 sec)
38.231... logprob:  0.690948, 0.308594 (1.401 sec)
38.232... logprob:  0.741978, 0.315104 (1.453 sec)
38.233... logprob:  0.747107, 0.316406 (1.419 sec)
38.234... logprob:  0.714433, 0.289062 (1.413 sec)
38.235... logprob:  0.695238, 0.308594 (1.465 sec)
38.236... logprob:  0.611822, 0.244792 (1.393 sec)
38.237... logprob:  0.581060, 0.247396 (1.420 sec)
38.238... logprob:  0.627362, 0.270833 (1.410 sec)
38.239... logprob:  0.703732, 0.309896 (1.411 sec)
38.240... logprob:  0.562730, 0.244792 (1.400 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.482031, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.796094e-03 [8.984759e-08] 
Layer 'conv1' biases: 2.209079e-06 [1.421020e-11] 
Layer 'conv2' weights[0]: 1.792428e-03 [8.966488e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.044796e-10] 
Layer 'conv3' weights[0]: 1.791584e-03 [8.975724e-08] 
Layer 'conv3' biases: 3.671122e-05 [4.031627e-09] 
Layer 'conv4' weights[0]: 1.799186e-03 [9.029200e-08] 
Layer 'conv4' biases: 9.997596e-01 [1.885932e-07] 
Layer 'conv5' weights[0]: 2.012585e-03 [2.222136e-06] 
Layer 'conv5' biases: 9.987956e-01 [2.385406e-06] 
Layer 'fc6' weights[0]: 6.507992e-03 [5.972090e-08] 
Layer 'fc6' biases: 9.999890e-01 [5.961274e-08] 
Layer 'fc7' weights[0]: 6.844503e-03 [1.485656e-07] 
Layer 'fc7' biases: 9.996623e-01 [2.095766e-07] 
Layer 'fc8' weights[0]: 4.772820e-03 [1.397879e-05] 
Layer 'fc8' biases: 3.098785e-02 [3.830428e-05] 
Train error last 800 batches: 0.655066
-------------------------------------------------------
Not saving because 0.482031 > 0.299667 (9.300: -1.18%)
======================================================= (2.408 sec)
38.241... logprob:  0.700932, 0.324219 (1.456 sec)
38.242... logprob:  0.574475, 0.243490 (1.438 sec)
38.243... logprob:  0.670955, 0.307292 (1.431 sec)
38.244... logprob:  0.582508, 0.265625 (1.447 sec)
38.245... logprob:  0.716024, 0.308594 (1.418 sec)
38.246... logprob:  0.685036, 0.307292 (1.407 sec)
38.247... logprob:  0.601424, 0.269531 (1.409 sec)
38.248... logprob:  0.553572, 0.247396 (1.410 sec)
38.249... logprob:  0.684765, 0.305990 (1.415 sec)
38.250... logprob:  0.781564, 0.326823 (1.400 sec)
38.251... logprob:  0.627662, 0.273437 (1.453 sec)
38.252... logprob:  0.555387, 0.225260 (1.417 sec)
38.253... logprob:  0.571094, 0.257813 (1.412 sec)
38.254... logprob:  0.567554, 0.256510 (1.460 sec)
38.255... logprob:  0.641094, 0.286458 (1.393 sec)
38.256... logprob:  0.638536, 0.286458 (1.418 sec)
38.257... logprob:  0.517273, 0.248698 (1.408 sec)
38.258... logprob:  0.680523, 0.303385 (1.416 sec)
38.259... logprob:  0.686893, 0.302083 (1.390 sec)
38.260... logprob:  0.610385, 0.269531 (1.453 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.533258, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.794288e-03 [8.978706e-08] 
Layer 'conv1' biases: 2.209056e-06 [1.930118e-11] 
Layer 'conv2' weights[0]: 1.790639e-03 [8.959343e-08] 
Layer 'conv2' biases: 9.999996e-01 [4.057866e-10] 
Layer 'conv3' weights[0]: 1.789786e-03 [8.978133e-08] 
Layer 'conv3' biases: 3.666532e-05 [5.400818e-09] 
Layer 'conv4' weights[0]: 1.797388e-03 [9.043557e-08] 
Layer 'conv4' biases: 9.997653e-01 [2.532092e-07] 
Layer 'conv5' weights[0]: 2.017612e-03 [3.615576e-06] 
Layer 'conv5' biases: 9.987353e-01 [3.984017e-06] 
Layer 'fc6' weights[0]: 6.507323e-03 [6.462035e-08] 
Layer 'fc6' biases: 9.999887e-01 [6.715271e-08] 
Layer 'fc7' weights[0]: 6.843855e-03 [1.638025e-07] 
Layer 'fc7' biases: 9.996655e-01 [2.670375e-07] 
Layer 'fc8' weights[0]: 4.874687e-03 [1.404149e-05] 
Layer 'fc8' biases: 3.187730e-02 [4.651023e-05] 
Train error last 800 batches: 0.655107
-------------------------------------------------------
Not saving because 0.533258 > 0.299667 (9.300: -1.18%)
======================================================= (2.351 sec)
38.261... logprob:  0.624489, 0.276042 (1.430 sec)
38.262... logprob:  0.626598, 0.296875 (1.440 sec)
38.263... logprob:  0.655552, 0.268229 (1.445 sec)
38.264... logprob:  0.543336, 0.225260 (1.415 sec)
38.265... logprob:  0.541031, 0.252604 (1.412 sec)
38.266... logprob:  0.649927, 0.279948 (1.409 sec)
38.267... logprob:  0.606011, 0.255208 (1.410 sec)
38.268... logprob:  0.728056, 0.308594 (1.424 sec)
38.269... logprob:  0.685617, 0.294271 (1.400 sec)
38.270... logprob:  0.815236, 0.355469 (1.450 sec)
38.271... logprob:  0.653906, 0.290365 (1.420 sec)
38.272... logprob:  0.587181, 0.259115 (1.411 sec)
38.273... logprob:  0.738663, 0.321614 (1.464 sec)
38.274... logprob:  0.815523, 0.352865 (1.398 sec)
38.275... logprob:  0.719539, 0.317708 (1.416 sec)
38.276... logprob:  0.630814, 0.281250 (1.413 sec)
38.277... logprob:  0.647266, 0.295573 (1.417 sec)
38.278... logprob:  0.553366, 0.255208 (1.420 sec)
38.279... logprob:  0.618694, 0.291667 (1.462 sec)
38.280... logprob:  0.509252, 0.242188 (1.397 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.419048, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.792496e-03 [8.967061e-08] 
Layer 'conv1' biases: 2.209145e-06 [1.267871e-11] 
Layer 'conv2' weights[0]: 1.788860e-03 [8.948947e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.421308e-10] 
Layer 'conv3' weights[0]: 1.787988e-03 [8.954732e-08] 
Layer 'conv3' biases: 3.668541e-05 [3.343327e-09] 
Layer 'conv4' weights[0]: 1.795591e-03 [8.999377e-08] 
Layer 'conv4' biases: 9.997625e-01 [1.277850e-07] 
Layer 'conv5' weights[0]: 2.014007e-03 [2.331209e-06] 
Layer 'conv5' biases: 9.987413e-01 [2.503919e-06] 
Layer 'fc6' weights[0]: 6.506664e-03 [5.346237e-08] 
Layer 'fc6' biases: 9.999886e-01 [5.153990e-08] 
Layer 'fc7' weights[0]: 6.843137e-03 [1.257224e-07] 
Layer 'fc7' biases: 9.996656e-01 [1.492707e-07] 
Layer 'fc8' weights[0]: 4.859548e-03 [9.460936e-06] 
Layer 'fc8' biases: 3.177650e-02 [6.368888e-06] 
Train error last 800 batches: 0.655086
-------------------------------------------------------
Not saving because 0.419048 > 0.299667 (9.300: -1.18%)
======================================================= (2.371 sec)
38.281... logprob:  0.663900, 0.261719 (1.454 sec)
38.282... logprob:  0.562685, 0.247396 (1.415 sec)
38.283... logprob:  0.572532, 0.255208 (1.416 sec)
38.284... logprob:  0.611142, 0.260417 (1.404 sec)
38.285... logprob:  0.721149, 0.326823 (1.441 sec)
38.286... logprob:  0.690554, 0.296875 (1.428 sec)
38.287... logprob:  0.638729, 0.274739 (1.460 sec)
38.288... logprob:  0.596668, 0.272135 (1.427 sec)
38.289... logprob:  0.728691, 0.324219 (1.438 sec)
38.290... logprob:  0.711972, 0.294271 (1.406 sec)
38.291... logprob:  0.648352, 0.294271 (1.412 sec)
38.292... logprob:  0.819126, 0.348958 (1.410 sec)
38.293... logprob:  0.681884, 0.302083 (1.419 sec)
38.294... logprob:  0.624893, 0.277344 (1.400 sec)
38.295... logprob:  0.554736, 0.238281 (1.458 sec)
38.296... logprob:  0.574050, 0.217448 (1.414 sec)
38.297... logprob:  0.616131, 0.279948 (1.414 sec)
38.298... logprob:  0.744026, 0.322917 (1.457 sec)
38.299... logprob:  0.551493, 0.257812 (1.394 sec)
38.300... logprob:  0.623173, 0.239583 (1.415 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.383210, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.790703e-03 [8.959155e-08] 
Layer 'conv1' biases: 2.209247e-06 [1.404813e-11] 
Layer 'conv2' weights[0]: 1.787070e-03 [8.939896e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.309712e-10] 
Layer 'conv3' weights[0]: 1.786203e-03 [8.943037e-08] 
Layer 'conv3' biases: 3.669852e-05 [3.044687e-09] 
Layer 'conv4' weights[0]: 1.793804e-03 [8.989909e-08] 
Layer 'conv4' biases: 9.997596e-01 [1.491644e-07] 
Layer 'conv5' weights[0]: 2.009728e-03 [2.197835e-06] 
Layer 'conv5' biases: 9.987515e-01 [2.393496e-06] 
Layer 'fc6' weights[0]: 6.505993e-03 [5.633278e-08] 
Layer 'fc6' biases: 9.999889e-01 [5.558852e-08] 
Layer 'fc7' weights[0]: 6.842447e-03 [1.381459e-07] 
Layer 'fc7' biases: 9.996642e-01 [1.762317e-07] 
Layer 'fc8' weights[0]: 4.838551e-03 [1.181862e-05] 
Layer 'fc8' biases: 3.156996e-02 [2.629173e-05] 
Train error last 800 batches: 0.655663
-------------------------------------------------------
Not saving because 0.383210 > 0.299667 (9.300: -1.18%)
======================================================= (2.358 sec)
38.301... logprob:  0.661180, 0.292969 (1.423 sec)
38.302... logprob:  0.719805, 0.325521 (1.417 sec)
38.303... logprob:  0.693005, 0.315104 (1.402 sec)
38.304... logprob:  0.685615, 0.309896 (1.437 sec)
38.305... logprob:  0.647526, 0.287760 (1.439 sec)
38.306... logprob:  0.714710, 0.291667 (1.440 sec)
38.307... logprob:  0.568363, 0.243490 (1.436 sec)
38.308... logprob:  0.646807, 0.264323 (1.470 sec)
38.309... logprob:  0.704817, 0.305990 (1.418 sec)
38.310... logprob:  0.739403, 0.322917 (1.425 sec)
38.311... logprob:  0.710709, 0.289062 (1.421 sec)
38.312... logprob:  0.664616, 0.295573 (1.442 sec)
38.313... logprob:  0.679513, 0.296875 (1.425 sec)
38.314... logprob:  0.702537, 0.332031 (1.469 sec)
38.315... logprob:  0.547060, 0.230469 (1.437 sec)
38.316... logprob:  0.644623, 0.270833 (1.425 sec)
38.317... logprob:  0.664468, 0.273437 (1.483 sec)
38.318... logprob:  0.680348, 0.315104 (1.412 sec)
38.319... logprob:  0.607401, 0.256510 (1.429 sec)
38.320... logprob:  0.609348, 0.268229 (1.424 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.473538, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.788911e-03 [8.949630e-08] 
Layer 'conv1' biases: 2.209324e-06 [1.127459e-11] 
Layer 'conv2' weights[0]: 1.785276e-03 [8.930608e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.247781e-10] 
Layer 'conv3' weights[0]: 1.784418e-03 [8.934846e-08] 
Layer 'conv3' biases: 3.669776e-05 [3.069737e-09] 
Layer 'conv4' weights[0]: 1.791994e-03 [8.983173e-08] 
Layer 'conv4' biases: 9.997602e-01 [1.509915e-07] 
Layer 'conv5' weights[0]: 2.008502e-03 [2.597194e-06] 
Layer 'conv5' biases: 9.987554e-01 [2.741195e-06] 
Layer 'fc6' weights[0]: 6.505348e-03 [6.123677e-08] 
Layer 'fc6' biases: 9.999888e-01 [6.251506e-08] 
Layer 'fc7' weights[0]: 6.841754e-03 [1.577650e-07] 
Layer 'fc7' biases: 9.996640e-01 [2.390296e-07] 
Layer 'fc8' weights[0]: 4.827801e-03 [1.519914e-05] 
Layer 'fc8' biases: 3.148195e-02 [5.116472e-05] 
Train error last 800 batches: 0.656253
-------------------------------------------------------
Not saving because 0.473538 > 0.299667 (9.300: -1.18%)
======================================================= (2.416 sec)
38.321... logprob:  0.572749, 0.250000 (1.432 sec)
38.322... logprob:  0.586104, 0.276042 (1.422 sec)
38.323... logprob:  0.655169, 0.307292 (1.484 sec)
38.324... logprob:  0.804784, 0.338542 (1.437 sec)
38.325... logprob:  0.583442, 0.273437 (1.433 sec)
38.326... logprob:  0.717661, 0.292969 (1.461 sec)
38.327... logprob:  0.830037, 0.319010 (1.433 sec)
38.328... logprob:  0.653428, 0.307292 (1.433 sec)
38.329... logprob:  0.667433, 0.292969 (1.434 sec)
38.330... logprob:  0.664059, 0.265625 (1.427 sec)
38.331... logprob:  0.548199, 0.235677 (1.431 sec)
38.332... logprob:  0.677834, 0.305990 (1.456 sec)
38.333... logprob:  0.624383, 0.276042 (1.456 sec)
38.334... logprob:  0.712375, 0.307292 (1.447 sec)
38.335... logprob:  0.598352, 0.253906 (1.451 sec)
38.336... logprob:  0.596931, 0.277344 (1.465 sec)
38.337... logprob:  0.767446, 0.315104 (1.422 sec)
38.338... logprob:  0.753865, 0.321614 (1.421 sec)
38.339... logprob:  0.720257, 0.313802 (1.439 sec)
38.340... logprob:  0.748178, 0.316406 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.506721, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.787127e-03 [8.938237e-08] 
Layer 'conv1' biases: 2.209378e-06 [2.260919e-11] 
Layer 'conv2' weights[0]: 1.783496e-03 [8.921280e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.957623e-10] 
Layer 'conv3' weights[0]: 1.782647e-03 [8.936566e-08] 
Layer 'conv3' biases: 3.670488e-05 [4.951314e-09] 
Layer 'conv4' weights[0]: 1.790209e-03 [8.985776e-08] 
Layer 'conv4' biases: 9.997590e-01 [2.403978e-07] 
Layer 'conv5' weights[0]: 2.006293e-03 [3.460623e-06] 
Layer 'conv5' biases: 9.987577e-01 [3.799205e-06] 
Layer 'fc6' weights[0]: 6.504701e-03 [6.524429e-08] 
Layer 'fc6' biases: 9.999890e-01 [6.828122e-08] 
Layer 'fc7' weights[0]: 6.841075e-03 [1.659417e-07] 
Layer 'fc7' biases: 9.996635e-01 [2.592577e-07] 
Layer 'fc8' weights[0]: 4.817535e-03 [1.411455e-05] 
Layer 'fc8' biases: 3.129071e-02 [3.782733e-05] 
Train error last 800 batches: 0.656409
-------------------------------------------------------
Not saving because 0.506721 > 0.299667 (9.300: -1.18%)
======================================================= (2.377 sec)
38.341... logprob:  0.753412, 0.304687 (1.426 sec)
38.342... logprob:  0.726835, 0.328125 (1.463 sec)
38.343... logprob:  0.719790, 0.296875 (1.441 sec)
38.344... logprob:  0.675897, 0.272135 (1.483 sec)
38.345... logprob:  0.631300, 0.307292 (1.446 sec)
38.346... logprob:  0.676832, 0.298177 (1.443 sec)
38.347... logprob:  0.552345, 0.222656 (1.492 sec)
38.348... logprob:  0.636961, 0.278646 (1.440 sec)
38.349... logprob:  0.696247, 0.282552 (1.428 sec)
38.350... logprob:  0.621973, 0.282552 (1.435 sec)
38.351... logprob:  0.836169, 0.330729 (1.425 sec)
38.352... logprob:  0.650128, 0.316406 (1.429 sec)
38.353... logprob:  0.613293, 0.269531 (1.481 sec)
38.354... logprob:  0.868399, 0.328125 (1.431 sec)
38.355... logprob:  0.568822, 0.242188 (1.441 sec)
38.356... logprob:  0.617983, 0.277344 (1.477 sec)
38.357... logprob:  0.593036, 0.272135 (1.427 sec)
38.358... logprob:  0.474818, 0.196615 (1.435 sec)
38.359... logprob:  0.725650, 0.315104 (1.451 sec)
38.360... logprob:  0.665808, 0.273438 (1.422 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.569696, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.785338e-03 [8.932682e-08] 
Layer 'conv1' biases: 2.209444e-06 [1.747456e-11] 
Layer 'conv2' weights[0]: 1.781718e-03 [8.913999e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.631423e-10] 
Layer 'conv3' weights[0]: 1.780869e-03 [8.927904e-08] 
Layer 'conv3' biases: 3.670407e-05 [5.105723e-09] 
Layer 'conv4' weights[0]: 1.788409e-03 [8.985253e-08] 
Layer 'conv4' biases: 9.997582e-01 [2.164499e-07] 
Layer 'conv5' weights[0]: 2.004235e-03 [3.192609e-06] 
Layer 'conv5' biases: 9.987753e-01 [3.583927e-06] 
Layer 'fc6' weights[0]: 6.504047e-03 [6.368665e-08] 
Layer 'fc6' biases: 9.999889e-01 [6.526493e-08] 
Layer 'fc7' weights[0]: 6.840411e-03 [1.587580e-07] 
Layer 'fc7' biases: 9.996618e-01 [2.376520e-07] 
Layer 'fc8' weights[0]: 4.783271e-03 [1.337645e-05] 
Layer 'fc8' biases: 3.108473e-02 [3.689263e-05] 
Train error last 800 batches: 0.656696
-------------------------------------------------------
Not saving because 0.569696 > 0.299667 (9.300: -1.18%)
======================================================= (2.410 sec)
38.361... logprob:  0.632040, 0.268229 (1.435 sec)
38.362... logprob:  0.700356, 0.303385 (1.480 sec)
38.363... logprob:  0.683262, 0.313802 (1.444 sec)
38.364... logprob:  0.649734, 0.282552 (1.450 sec)
38.365... logprob:  0.636763, 0.282552 (1.458 sec)
38.366... logprob:  0.693652, 0.279948 (1.439 sec)
38.367... logprob:  0.625901, 0.270833 (1.433 sec)
38.368... logprob:  0.747255, 0.289062 (1.422 sec)
38.369... logprob:  0.643836, 0.276042 (1.423 sec)
38.370... logprob:  0.647142, 0.290365 (1.437 sec)
38.371... logprob:  0.666300, 0.286458 (1.451 sec)
38.372... logprob:  0.658470, 0.309896 (1.448 sec)
38.373... logprob:  0.752594, 0.334635 (1.447 sec)
38.374... logprob:  0.675515, 0.259115 (1.448 sec)
38.375... logprob:  0.525057, 0.231771 (1.452 sec)
38.376... logprob:  0.587454, 0.244792 (1.438 sec)
38.377... logprob:  0.582657, 0.257812 (1.423 sec)
38.378... logprob:  0.696375, 0.295573 (1.424 sec)
38.379... logprob:  0.644264, 0.278646 (1.433 sec)
38.380... logprob:  0.810663, 0.346354 (1.433 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.441656, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.783552e-03 [8.920817e-08] 
Layer 'conv1' biases: 2.209384e-06 [1.706913e-11] 
Layer 'conv2' weights[0]: 1.779930e-03 [8.902793e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.702837e-10] 
Layer 'conv3' weights[0]: 1.779074e-03 [8.912563e-08] 
Layer 'conv3' biases: 3.668582e-05 [3.777116e-09] 
Layer 'conv4' weights[0]: 1.786621e-03 [8.958851e-08] 
Layer 'conv4' biases: 9.997613e-01 [1.807730e-07] 
Layer 'conv5' weights[0]: 2.005897e-03 [2.546797e-06] 
Layer 'conv5' biases: 9.987447e-01 [2.738599e-06] 
Layer 'fc6' weights[0]: 6.503392e-03 [5.944929e-08] 
Layer 'fc6' biases: 9.999886e-01 [5.975384e-08] 
Layer 'fc7' weights[0]: 6.839741e-03 [1.500388e-07] 
Layer 'fc7' biases: 9.996630e-01 [2.028307e-07] 
Layer 'fc8' weights[0]: 4.823016e-03 [1.274343e-05] 
Layer 'fc8' biases: 3.147924e-02 [3.033778e-05] 
Train error last 800 batches: 0.657183
-------------------------------------------------------
Not saving because 0.441656 > 0.299667 (9.300: -1.18%)
======================================================= (2.360 sec)
38.381... logprob:  0.709500, 0.305990 (1.471 sec)
38.382... logprob:  0.741714, 0.291667 (1.453 sec)
38.383... logprob:  0.577211, 0.273437 (1.436 sec)
38.384... logprob:  0.661413, 0.291667 (1.474 sec)
38.385... logprob:  0.753358, 0.347656 (1.426 sec)
38.386... logprob:  0.771866, 0.315104 (1.421 sec)
38.387... logprob:  0.562938, 0.242187 (1.430 sec)
38.388... logprob:  0.684607, 0.303385 (1.427 sec)
38.389... logprob:  0.647837, 0.259115 (1.429 sec)
38.390... logprob:  0.596428, 0.269531 (1.472 sec)
38.391... logprob:  0.543751, 0.243490 (1.437 sec)
38.392... logprob:  0.724413, 0.315104 (1.435 sec)
38.393... logprob:  0.611539, 0.276042 (1.477 sec)
38.394... logprob:  0.616770, 0.263021 (1.428 sec)
38.395... logprob:  0.542775, 0.238281 (1.424 sec)
38.396... logprob:  0.558767, 0.266927 (1.429 sec)
38.397... logprob:  0.690038, 0.309896 (1.457 sec)
38.398... logprob:  0.696087, 0.338541 (1.428 sec)
38.399... logprob:  0.627646, 0.274739 (1.477 sec)
38.400... logprob:  0.679319, 0.300781 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.517264, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.781760e-03 [8.915056e-08] 
Layer 'conv1' biases: 2.209372e-06 [2.372368e-11] 
Layer 'conv2' weights[0]: 1.778151e-03 [8.895863e-08] 
Layer 'conv2' biases: 9.999996e-01 [4.606588e-10] 
Layer 'conv3' weights[0]: 1.777291e-03 [8.921762e-08] 
Layer 'conv3' biases: 3.667770e-05 [5.878495e-09] 
Layer 'conv4' weights[0]: 1.784833e-03 [8.986161e-08] 
Layer 'conv4' biases: 9.997642e-01 [2.967033e-07] 
Layer 'conv5' weights[0]: 2.007711e-03 [3.498520e-06] 
Layer 'conv5' biases: 9.987310e-01 [3.929977e-06] 
Layer 'fc6' weights[0]: 6.502734e-03 [6.311133e-08] 
Layer 'fc6' biases: 9.999883e-01 [6.527746e-08] 
Layer 'fc7' weights[0]: 6.839048e-03 [1.574151e-07] 
Layer 'fc7' biases: 9.996635e-01 [2.472760e-07] 
Layer 'fc8' weights[0]: 4.834813e-03 [1.404801e-05] 
Layer 'fc8' biases: 3.154768e-02 [3.636169e-05] 
Train error last 800 batches: 0.657488
-------------------------------------------------------
Not saving because 0.517264 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
38.401... logprob:  0.615830, 0.257812 (1.446 sec)
38.402... logprob:  0.656609, 0.282552 (1.479 sec)
38.403... logprob:  0.619116, 0.247396 (1.429 sec)
38.404... logprob:  0.723416, 0.320312 (1.432 sec)
38.405... logprob:  0.658734, 0.274740 (1.424 sec)
38.406... logprob:  0.649946, 0.290365 (1.426 sec)
38.407... logprob:  0.718693, 0.316406 (1.425 sec)
38.408... logprob:  0.548883, 0.225260 (1.475 sec)
38.409... logprob:  0.669147, 0.289062 (1.434 sec)
38.410... logprob:  0.752789, 0.329427 (1.453 sec)
38.411... logprob:  0.672517, 0.290365 (1.472 sec)
38.412... logprob:  0.686991, 0.312500 (1.431 sec)
38.413... logprob:  0.708781, 0.292969 (1.431 sec)
38.414... logprob:  0.666832, 0.308594 (1.426 sec)
38.415... logprob:  0.643611, 0.282552 (1.419 sec)
38.416... logprob:  0.760938, 0.339844 (1.438 sec)
38.417... logprob:  0.582042, 0.261719 (1.455 sec)
38.418... logprob:  0.631204, 0.282552 (1.448 sec)
38.419... logprob:  0.651491, 0.316406 (1.445 sec)
38.420... logprob:  0.638395, 0.286458 (1.450 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.492802, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.779989e-03 [8.904074e-08] 
Layer 'conv1' biases: 2.209464e-06 [1.585826e-11] 
Layer 'conv2' weights[0]: 1.776370e-03 [8.885927e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.512291e-10] 
Layer 'conv3' weights[0]: 1.775517e-03 [8.898809e-08] 
Layer 'conv3' biases: 3.667013e-05 [4.434526e-09] 
Layer 'conv4' weights[0]: 1.783071e-03 [8.951246e-08] 
Layer 'conv4' biases: 9.997652e-01 [1.911372e-07] 
Layer 'conv5' weights[0]: 2.008117e-03 [2.398300e-06] 
Layer 'conv5' biases: 9.987223e-01 [2.617833e-06] 
Layer 'fc6' weights[0]: 6.502026e-03 [5.909481e-08] 
Layer 'fc6' biases: 9.999883e-01 [6.018679e-08] 
Layer 'fc7' weights[0]: 6.838373e-03 [1.517606e-07] 
Layer 'fc7' biases: 9.996642e-01 [2.299747e-07] 
Layer 'fc8' weights[0]: 4.850090e-03 [1.398386e-05] 
Layer 'fc8' biases: 3.170158e-02 [3.351508e-05] 
Train error last 800 batches: 0.657640
-------------------------------------------------------
Not saving because 0.492802 > 0.299667 (9.300: -1.18%)
======================================================= (2.406 sec)
38.421... logprob:  0.600522, 0.260417 (1.463 sec)
38.422... logprob:  0.761709, 0.312500 (1.441 sec)
38.423... logprob:  0.672135, 0.309896 (1.426 sec)
38.424... logprob:  0.610339, 0.252604 (1.431 sec)
38.425... logprob:  0.477553, 0.214844 (1.429 sec)
38.426... logprob:  0.635657, 0.250000 (1.440 sec)
38.427... logprob:  0.716956, 0.294271 (1.457 sec)
38.428... logprob:  0.765806, 0.316406 (1.446 sec)
38.429... logprob:  0.664156, 0.282552 (1.434 sec)
38.430... logprob:  0.560143, 0.240885 (1.470 sec)
38.431... logprob:  0.772042, 0.311198 (1.427 sec)
38.432... logprob:  0.605734, 0.295573 (1.424 sec)
38.433... logprob:  0.577940, 0.250000 (1.433 sec)
38.434... logprob:  0.770819, 0.339844 (1.433 sec)
38.435... logprob:  0.747986, 0.321615 (1.459 sec)
38.436... logprob:  0.612191, 0.242187 (1.469 sec)
38.437... logprob:  0.690134, 0.289062 (1.437 sec)
38.438... logprob:  0.799457, 0.339844 (1.426 sec)
38.439... logprob:  0.553059, 0.233073 (1.479 sec)
38.440... logprob:  0.737169, 0.324219 (1.432 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.519292, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.778212e-03 [8.890555e-08] 
Layer 'conv1' biases: 2.209565e-06 [2.247157e-11] 
Layer 'conv2' weights[0]: 1.774592e-03 [8.874992e-08] 
Layer 'conv2' biases: 9.999996e-01 [4.188526e-10] 
Layer 'conv3' weights[0]: 1.773745e-03 [8.898493e-08] 
Layer 'conv3' biases: 3.667623e-05 [5.649612e-09] 
Layer 'conv4' weights[0]: 1.781284e-03 [8.949949e-08] 
Layer 'conv4' biases: 9.997635e-01 [2.969895e-07] 
Layer 'conv5' weights[0]: 2.004124e-03 [3.130695e-06] 
Layer 'conv5' biases: 9.987377e-01 [3.571355e-06] 
Layer 'fc6' weights[0]: 6.501400e-03 [6.363481e-08] 
Layer 'fc6' biases: 9.999885e-01 [6.681487e-08] 
Layer 'fc7' weights[0]: 6.837694e-03 [1.614927e-07] 
Layer 'fc7' biases: 9.996632e-01 [2.467132e-07] 
Layer 'fc8' weights[0]: 4.830565e-03 [1.399495e-05] 
Layer 'fc8' biases: 3.159036e-02 [3.734987e-05] 
Train error last 800 batches: 0.657327
-------------------------------------------------------
Not saving because 0.519292 > 0.299667 (9.300: -1.18%)
======================================================= (2.361 sec)
38.441... logprob:  0.671572, 0.305990 (1.430 sec)
38.442... logprob:  0.660406, 0.291667 (1.440 sec)
38.443... logprob:  0.653986, 0.295573 (1.428 sec)
38.444... logprob:  0.613866, 0.279948 (1.431 sec)
38.445... logprob:  0.627965, 0.302083 (1.481 sec)
38.446... logprob:  0.713785, 0.292969 (1.433 sec)
38.447... logprob:  0.645668, 0.274740 (1.430 sec)
38.448... logprob:  0.654682, 0.319010 (1.479 sec)
38.449... logprob:  0.665371, 0.304688 (1.432 sec)
38.450... logprob:  0.519939, 0.257812 (1.425 sec)
38.451... logprob:  0.639877, 0.264323 (1.433 sec)
38.452... logprob:  0.683501, 0.266927 (1.422 sec)
38.453... logprob:  0.712168, 0.315104 (1.426 sec)
38.454... logprob:  0.701171, 0.292969 (1.476 sec)
38.455... logprob:  0.705349, 0.315104 (1.426 sec)
38.456... logprob:  0.715682, 0.311198 (1.445 sec)
38.457... logprob:  0.663407, 0.286458 (1.467 sec)
38.458... logprob:  0.635337, 0.300781 (1.427 sec)
38.459... logprob:  0.695853, 0.266927 (1.432 sec)
38.460... logprob:  0.517188, 0.239583 (1.426 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.510212, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.776430e-03 [8.886662e-08] 
Layer 'conv1' biases: 2.209600e-06 [1.195546e-11] 
Layer 'conv2' weights[0]: 1.772811e-03 [8.868629e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.414033e-10] 
Layer 'conv3' weights[0]: 1.771976e-03 [8.873499e-08] 
Layer 'conv3' biases: 3.668650e-05 [3.030583e-09] 
Layer 'conv4' weights[0]: 1.779499e-03 [8.915163e-08] 
Layer 'conv4' biases: 9.997615e-01 [1.331790e-07] 
Layer 'conv5' weights[0]: 2.001264e-03 [2.425645e-06] 
Layer 'conv5' biases: 9.987420e-01 [2.606330e-06] 
Layer 'fc6' weights[0]: 6.500736e-03 [5.638999e-08] 
Layer 'fc6' biases: 9.999886e-01 [5.566706e-08] 
Layer 'fc7' weights[0]: 6.836975e-03 [1.388673e-07] 
Layer 'fc7' biases: 9.996627e-01 [1.774922e-07] 
Layer 'fc8' weights[0]: 4.829533e-03 [1.131984e-05] 
Layer 'fc8' biases: 3.163090e-02 [2.012305e-05] 
Train error last 800 batches: 0.657162
-------------------------------------------------------
Not saving because 0.510212 > 0.299667 (9.300: -1.18%)
======================================================= (2.370 sec)
38.461... logprob:  0.633764, 0.285156 (1.426 sec)
38.462... logprob:  0.702152, 0.325521 (1.437 sec)
38.463... logprob:  0.661224, 0.313802 (1.470 sec)
38.464... logprob:  0.664055, 0.299479 (1.440 sec)
38.465... logprob:  0.637467, 0.269531 (1.448 sec)
38.466... logprob:  0.502453, 0.240885 (1.451 sec)
38.467... logprob:  0.593185, 0.260417 (1.448 sec)
38.468... logprob:  0.649659, 0.298177 (1.437 sec)
38.469... logprob:  0.537152, 0.234375 (1.423 sec)
38.470... logprob:  0.637606, 0.311198 (1.427 sec)
38.471... logprob:  0.733214, 0.315104 (1.434 sec)
38.472... logprob:  0.625125, 0.300781 (1.447 sec)
38.473... logprob:  0.637517, 0.277344 (1.484 sec)
38.474... logprob:  0.620788, 0.276042 (1.445 sec)
38.475... logprob:  0.735138, 0.302083 (1.442 sec)
38.476... logprob:  0.756964, 0.312500 (1.463 sec)
38.477... logprob:  0.629936, 0.292969 (1.436 sec)
38.478... logprob:  0.714739, 0.304687 (1.420 sec)
38.479... logprob:  0.558219, 0.260417 (1.424 sec)
38.480... logprob:  0.671501, 0.298177 (1.432 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.486860, 0.125000 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.774656e-03 [8.877463e-08] 
Layer 'conv1' biases: 2.209668e-06 [1.380279e-11] 
Layer 'conv2' weights[0]: 1.771050e-03 [8.859809e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.793754e-10] 
Layer 'conv3' weights[0]: 1.770200e-03 [8.864415e-08] 
Layer 'conv3' biases: 3.667556e-05 [3.180987e-09] 
Layer 'conv4' weights[0]: 1.777710e-03 [8.905915e-08] 
Layer 'conv4' biases: 9.997636e-01 [1.420553e-07] 
Layer 'conv5' weights[0]: 2.002203e-03 [2.231331e-06] 
Layer 'conv5' biases: 9.987115e-01 [2.350501e-06] 
Layer 'fc6' weights[0]: 6.500043e-03 [5.538634e-08] 
Layer 'fc6' biases: 9.999884e-01 [5.496373e-08] 
Layer 'fc7' weights[0]: 6.836301e-03 [1.340382e-07] 
Layer 'fc7' biases: 9.996647e-01 [1.631371e-07] 
Layer 'fc8' weights[0]: 4.877859e-03 [1.066283e-05] 
Layer 'fc8' biases: 3.202166e-02 [1.586518e-05] 
Train error last 800 batches: 0.657511
-------------------------------------------------------
Not saving because 0.486860 > 0.299667 (9.300: -1.18%)
======================================================= (2.363 sec)
38.481... logprob:  0.756756, 0.326823 (1.436 sec)
38.482... logprob:  0.681463, 0.292969 (1.472 sec)
38.483... logprob:  0.704462, 0.296875 (1.443 sec)
38.484... logprob:  0.626936, 0.304687 (1.432 sec)
38.485... logprob:  0.602051, 0.264323 (1.482 sec)
38.486... logprob:  0.613512, 0.291666 (1.427 sec)
38.487... logprob:  0.737576, 0.302083 (1.419 sec)
38.488... logprob:  0.649620, 0.282552 (1.431 sec)
38.489... logprob:  0.603907, 0.253906 (1.427 sec)
38.490... logprob:  0.588255, 0.260417 (1.430 sec)
38.491... logprob:  0.609670, 0.263021 (1.479 sec)
38.492... logprob:  0.611193, 0.264323 (1.434 sec)
38.493... logprob:  0.697224, 0.311198 (1.427 sec)
38.494... logprob:  0.579733, 0.260417 (1.487 sec)
38.495... logprob:  0.487881, 0.235677 (1.424 sec)
38.496... logprob:  0.745521, 0.309896 (1.429 sec)
38.497... logprob:  0.709958, 0.274740 (1.427 sec)
38.498... logprob:  0.741802, 0.332031 (1.425 sec)
38.499... logprob:  0.621722, 0.261719 (1.424 sec)
38.500... logprob:  0.637529, 0.283854 (1.482 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.408700, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.772875e-03 [8.869245e-08] 
Layer 'conv1' biases: 2.209750e-06 [1.330202e-11] 
Layer 'conv2' weights[0]: 1.769276e-03 [8.851352e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.113962e-10] 
Layer 'conv3' weights[0]: 1.768434e-03 [8.853848e-08] 
Layer 'conv3' biases: 3.669230e-05 [2.797497e-09] 
Layer 'conv4' weights[0]: 1.775949e-03 [8.897536e-08] 
Layer 'conv4' biases: 9.997621e-01 [1.502164e-07] 
Layer 'conv5' weights[0]: 1.999273e-03 [2.428208e-06] 
Layer 'conv5' biases: 9.987333e-01 [2.674739e-06] 
Layer 'fc6' weights[0]: 6.499352e-03 [5.766545e-08] 
Layer 'fc6' biases: 9.999884e-01 [5.784194e-08] 
Layer 'fc7' weights[0]: 6.835635e-03 [1.412716e-07] 
Layer 'fc7' biases: 9.996635e-01 [1.859182e-07] 
Layer 'fc8' weights[0]: 4.841532e-03 [1.153860e-05] 
Layer 'fc8' biases: 3.175583e-02 [1.640557e-05] 
Train error last 800 batches: 0.656924
-------------------------------------------------------
Not saving because 0.408700 > 0.299667 (9.300: -1.18%)
======================================================= (2.354 sec)
38.501... logprob:  0.577177, 0.233073 (1.432 sec)
38.502... logprob:  0.679629, 0.290365 (1.444 sec)
38.503... logprob:  0.555008, 0.230469 (1.477 sec)
38.504... logprob:  0.716196, 0.316406 (1.424 sec)
38.505... logprob:  0.781795, 0.339844 (1.435 sec)
38.506... logprob:  0.684556, 0.296875 (1.427 sec)
38.507... logprob:  0.601172, 0.251302 (1.420 sec)
38.508... logprob:  0.563766, 0.244792 (1.425 sec)
38.509... logprob:  0.576005, 0.257812 (1.470 sec)
38.510... logprob:  0.598230, 0.260417 (1.439 sec)
38.511... logprob:  0.592604, 0.272135 (1.477 sec)
38.512... logprob:  0.715413, 0.321615 (1.456 sec)
38.513... logprob:  0.591528, 0.276042 (1.433 sec)
38.514... logprob:  0.533156, 0.222656 (1.437 sec)
38.515... logprob:  0.670593, 0.283854 (1.420 sec)
38.516... logprob:  0.620996, 0.269531 (1.424 sec)
38.517... logprob:  0.832603, 0.335938 (1.435 sec)
38.518... logprob:  0.676986, 0.309896 (1.451 sec)
38.519... logprob:  0.759944, 0.335938 (1.451 sec)
38.520... logprob:  0.668043, 0.324219 (1.447 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.436408, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.771106e-03 [8.858278e-08] 
Layer 'conv1' biases: 2.209794e-06 [1.684763e-11] 
Layer 'conv2' weights[0]: 1.767516e-03 [8.841464e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.597329e-10] 
Layer 'conv3' weights[0]: 1.766667e-03 [8.852121e-08] 
Layer 'conv3' biases: 3.669670e-05 [4.222761e-09] 
Layer 'conv4' weights[0]: 1.774175e-03 [8.897624e-08] 
Layer 'conv4' biases: 9.997621e-01 [1.878771e-07] 
Layer 'conv5' weights[0]: 1.998005e-03 [2.671618e-06] 
Layer 'conv5' biases: 9.987333e-01 [2.900446e-06] 
Layer 'fc6' weights[0]: 6.498707e-03 [6.125625e-08] 
Layer 'fc6' biases: 9.999886e-01 [6.306421e-08] 
Layer 'fc7' weights[0]: 6.834946e-03 [1.543789e-07] 
Layer 'fc7' biases: 9.996635e-01 [2.253849e-07] 
Layer 'fc8' weights[0]: 4.846790e-03 [1.333672e-05] 
Layer 'fc8' biases: 3.179449e-02 [3.510778e-05] 
Train error last 800 batches: 0.656785
-------------------------------------------------------
Not saving because 0.436408 > 0.299667 (9.300: -1.18%)
======================================================= (2.368 sec)
38.521... logprob:  0.610908, 0.274739 (1.455 sec)
38.522... logprob:  0.759442, 0.328125 (1.466 sec)
38.523... logprob:  0.523605, 0.227865 (1.433 sec)
38.524... logprob:  0.719880, 0.285156 (1.419 sec)
38.525... logprob:  0.701322, 0.322917 (1.424 sec)
38.526... logprob:  0.560011, 0.238281 (1.433 sec)
38.527... logprob:  0.771567, 0.324219 (1.433 sec)
38.528... logprob:  0.661248, 0.302083 (1.467 sec)
38.529... logprob:  0.573141, 0.230469 (1.447 sec)
38.530... logprob:  0.657280, 0.312500 (1.432 sec)
38.531... logprob:  0.687537, 0.287760 (1.475 sec)
38.532... logprob:  0.662341, 0.286458 (1.430 sec)
38.533... logprob:  0.765310, 0.313802 (1.425 sec)
38.534... logprob:  0.619904, 0.277344 (1.427 sec)
38.535... logprob:  0.764275, 0.354167 (1.428 sec)
38.536... logprob:  0.670544, 0.274740 (1.430 sec)
38.537... logprob:  0.687483, 0.312500 (1.469 sec)
38.538... logprob:  0.725352, 0.343750 (1.436 sec)
38.539... logprob:  0.626245, 0.263021 (1.429 sec)
38.540... logprob:  0.591108, 0.272135 (1.476 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.422646, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.769340e-03 [8.847828e-08] 
Layer 'conv1' biases: 2.209893e-06 [1.086893e-11] 
Layer 'conv2' weights[0]: 1.765741e-03 [8.831492e-08] 
Layer 'conv2' biases: 9.999996e-01 [1.929396e-10] 
Layer 'conv3' weights[0]: 1.764891e-03 [8.833005e-08] 
Layer 'conv3' biases: 3.671627e-05 [2.563397e-09] 
Layer 'conv4' weights[0]: 1.772391e-03 [8.874661e-08] 
Layer 'conv4' biases: 9.997589e-01 [1.186417e-07] 
Layer 'conv5' weights[0]: 1.992619e-03 [2.269841e-06] 
Layer 'conv5' biases: 9.987664e-01 [2.495648e-06] 
Layer 'fc6' weights[0]: 6.498042e-03 [5.646871e-08] 
Layer 'fc6' biases: 9.999887e-01 [5.556495e-08] 
Layer 'fc7' weights[0]: 6.834289e-03 [1.399879e-07] 
Layer 'fc7' biases: 9.996620e-01 [1.813350e-07] 
Layer 'fc8' weights[0]: 4.798857e-03 [1.234680e-05] 
Layer 'fc8' biases: 3.145072e-02 [3.132910e-05] 
Train error last 800 batches: 0.657141
-------------------------------------------------------
Not saving because 0.422646 > 0.299667 (9.300: -1.18%)
======================================================= (2.410 sec)
38.541... logprob:  0.607622, 0.251302 (1.438 sec)
38.542... logprob:  0.641785, 0.292969 (1.432 sec)
38.543... logprob:  0.573949, 0.276042 (1.428 sec)
38.544... logprob:  0.559657, 0.251302 (1.426 sec)
38.545... logprob:  0.544110, 0.259115 (1.427 sec)
38.546... logprob:  0.637455, 0.272135 (1.479 sec)
38.547... logprob:  0.699098, 0.316406 (1.424 sec)
38.548... logprob:  0.645665, 0.307292 (1.436 sec)
38.549... logprob:  0.714774, 0.307292 (1.507 sec)
38.550... logprob:  0.636231, 0.264323 (1.429 sec)
38.551... logprob:  0.699730, 0.300781 (1.425 sec)
38.552... logprob:  0.710114, 0.300781 (1.429 sec)
38.553... logprob:  0.623952, 0.277344 (1.423 sec)
38.554... logprob:  0.722408, 0.311198 (1.427 sec)
38.555... logprob:  0.574468, 0.252604 (1.473 sec)
38.556... logprob:  0.637555, 0.283854 (1.434 sec)
38.557... logprob:  0.681463, 0.307292 (1.443 sec)
38.558... logprob:  0.679092, 0.319010 (1.464 sec)
38.559... logprob:  0.651480, 0.295573 (1.440 sec)
38.560... logprob:  0.622916, 0.303385 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.498487, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.767568e-03 [8.842558e-08] 
Layer 'conv1' biases: 2.209852e-06 [1.336643e-11] 
Layer 'conv2' weights[0]: 1.763968e-03 [8.824338e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.069198e-10] 
Layer 'conv3' weights[0]: 1.763128e-03 [8.826772e-08] 
Layer 'conv3' biases: 3.669973e-05 [2.832481e-09] 
Layer 'conv4' weights[0]: 1.770614e-03 [8.869157e-08] 
Layer 'conv4' biases: 9.997621e-01 [1.159679e-07] 
Layer 'conv5' weights[0]: 1.995551e-03 [2.451411e-06] 
Layer 'conv5' biases: 9.987280e-01 [2.604906e-06] 
Layer 'fc6' weights[0]: 6.497372e-03 [5.558434e-08] 
Layer 'fc6' biases: 9.999889e-01 [5.450771e-08] 
Layer 'fc7' weights[0]: 6.833601e-03 [1.376715e-07] 
Layer 'fc7' biases: 9.996638e-01 [1.800805e-07] 
Layer 'fc8' weights[0]: 4.866728e-03 [1.129612e-05] 
Layer 'fc8' biases: 3.203227e-02 [2.074020e-05] 
Train error last 800 batches: 0.657201
-------------------------------------------------------
Not saving because 0.498487 > 0.299667 (9.300: -1.18%)
======================================================= (2.373 sec)
38.561... logprob:  0.644681, 0.321614 (1.436 sec)
38.562... logprob:  0.674199, 0.283854 (1.423 sec)
38.563... logprob:  0.604561, 0.272135 (1.433 sec)
38.564... logprob:  0.715131, 0.304688 (1.459 sec)
38.565... logprob:  0.826619, 0.352865 (1.447 sec)
38.566... logprob:  0.599800, 0.274740 (1.457 sec)
38.567... logprob:  0.805966, 0.335937 (1.463 sec)
38.568... logprob:  0.728864, 0.325521 (1.449 sec)
38.569... logprob:  0.726543, 0.317708 (1.430 sec)
38.570... logprob:  0.807765, 0.333333 (1.421 sec)
38.571... logprob:  0.646316, 0.292969 (1.424 sec)
38.572... logprob:  0.743293, 0.317708 (1.430 sec)
38.573... logprob:  0.693486, 0.312500 (1.444 sec)
38.574... logprob:  0.625096, 0.281250 (1.454 sec)
38.575... logprob:  0.577946, 0.278646 (1.444 sec)
38.576... logprob:  0.599738, 0.264323 (1.436 sec)
38.577... logprob:  0.647349, 0.286458 (1.472 sec)
38.578... logprob:  0.612514, 0.283854 (1.428 sec)
38.579... logprob:  0.579785, 0.256510 (1.419 sec)
38.580... logprob:  0.812026, 0.352865 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.480566, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.765802e-03 [8.830005e-08] 
Layer 'conv1' biases: 2.209965e-06 [1.530563e-11] 
Layer 'conv2' weights[0]: 1.762211e-03 [8.814221e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.375723e-10] 
Layer 'conv3' weights[0]: 1.761371e-03 [8.817591e-08] 
Layer 'conv3' biases: 3.671349e-05 [3.069079e-09] 
Layer 'conv4' weights[0]: 1.768855e-03 [8.865455e-08] 
Layer 'conv4' biases: 9.997582e-01 [1.531256e-07] 
Layer 'conv5' weights[0]: 1.990240e-03 [2.170330e-06] 
Layer 'conv5' biases: 9.987586e-01 [2.288697e-06] 
Layer 'fc6' weights[0]: 6.496737e-03 [5.637156e-08] 
Layer 'fc6' biases: 9.999890e-01 [5.547780e-08] 
Layer 'fc7' weights[0]: 6.832915e-03 [1.373668e-07] 
Layer 'fc7' biases: 9.996621e-01 [1.707452e-07] 
Layer 'fc8' weights[0]: 4.817627e-03 [1.154404e-05] 
Layer 'fc8' biases: 3.152868e-02 [1.990364e-05] 
Train error last 800 batches: 0.657335
-------------------------------------------------------
Not saving because 0.480566 > 0.299667 (9.300: -1.18%)
======================================================= (2.380 sec)
38.581... logprob:  0.787360, 0.361979 (1.439 sec)
38.582... logprob:  0.666253, 0.294271 (1.432 sec)
38.583... logprob:  0.785998, 0.326823 (1.477 sec)
38.584... logprob:  0.742454, 0.341146 (1.442 sec)
38.585... logprob:  0.525855, 0.208333 (1.428 sec)
38.586... logprob:  0.515524, 0.229167 (1.482 sec)
38.587... logprob:  0.643101, 0.311198 (1.442 sec)
38.588... logprob:  0.663682, 0.305990 (1.428 sec)
38.589... logprob:  0.640986, 0.270833 (1.431 sec)
38.590... logprob:  0.726035, 0.305990 (1.427 sec)
38.591... logprob:  0.700619, 0.324219 (1.429 sec)
38.592... logprob:  0.643660, 0.248698 (1.476 sec)
38.593... logprob:  0.680043, 0.309896 (1.430 sec)
38.594... logprob:  0.603360, 0.253906 (1.430 sec)
38.595... logprob:  0.694821, 0.281250 (1.477 sec)
38.596... logprob:  0.738320, 0.294271 (1.426 sec)
38.597... logprob:  0.607784, 0.269531 (1.423 sec)
38.598... logprob:  0.664954, 0.312500 (1.435 sec)
38.599... logprob:  0.549379, 0.244792 (1.418 sec)
38.600... logprob:  0.535736, 0.256510 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.550047, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.764035e-03 [8.827150e-08] 
Layer 'conv1' biases: 2.210055e-06 [2.157419e-11] 
Layer 'conv2' weights[0]: 1.760444e-03 [8.807983e-08] 
Layer 'conv2' biases: 9.999996e-01 [4.998726e-10] 
Layer 'conv3' weights[0]: 1.759611e-03 [8.837083e-08] 
Layer 'conv3' biases: 3.670120e-05 [6.489413e-09] 
Layer 'conv4' weights[0]: 1.767078e-03 [8.914128e-08] 
Layer 'conv4' biases: 9.997606e-01 [3.052886e-07] 
Layer 'conv5' weights[0]: 1.991312e-03 [3.367470e-06] 
Layer 'conv5' biases: 9.987401e-01 [3.798718e-06] 
Layer 'fc6' weights[0]: 6.496075e-03 [6.856509e-08] 
Layer 'fc6' biases: 9.999890e-01 [7.269505e-08] 
Layer 'fc7' weights[0]: 6.832198e-03 [1.784188e-07] 
Layer 'fc7' biases: 9.996632e-01 [3.106357e-07] 
Layer 'fc8' weights[0]: 4.851154e-03 [1.686575e-05] 
Layer 'fc8' biases: 3.184675e-02 [5.544382e-05] 
Train error last 800 batches: 0.657617
-------------------------------------------------------
Not saving because 0.550047 > 0.299667 (9.300: -1.18%)
======================================================= (2.393 sec)
38.601... logprob:  0.626687, 0.283854 (1.486 sec)
38.602... logprob:  0.567135, 0.274740 (1.429 sec)
38.603... logprob:  0.510503, 0.243490 (1.437 sec)
38.604... logprob:  0.652734, 0.302083 (1.470 sec)
38.605... logprob:  0.761097, 0.308594 (1.430 sec)
38.606... logprob:  0.536761, 0.243489 (1.438 sec)
38.607... logprob:  0.669001, 0.320312 (1.426 sec)
38.608... logprob:  0.583337, 0.257812 (1.419 sec)
38.609... logprob:  0.541687, 0.229167 (1.431 sec)
38.610... logprob:  0.772921, 0.316406 (1.474 sec)
38.611... logprob:  0.709961, 0.307292 (1.503 sec)
38.612... logprob:  0.682856, 0.307292 (1.447 sec)
38.613... logprob:  0.499876, 0.243489 (1.464 sec)
38.614... logprob:  0.723759, 0.338542 (1.442 sec)
38.615... logprob:  0.613702, 0.257812 (1.432 sec)
38.616... logprob:  0.603829, 0.270833 (1.428 sec)
38.617... logprob:  0.616129, 0.272135 (1.418 sec)
38.618... logprob:  0.654078, 0.304687 (1.435 sec)
38.619... logprob:  0.778954, 0.341146 (1.446 sec)
38.620... logprob:  0.814243, 0.360677 (1.454 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.408526, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.762269e-03 [8.810867e-08] 
Layer 'conv1' biases: 2.210086e-06 [2.226121e-11] 
Layer 'conv2' weights[0]: 1.758698e-03 [8.795858e-08] 
Layer 'conv2' biases: 9.999996e-01 [4.481560e-10] 
Layer 'conv3' weights[0]: 1.757854e-03 [8.828419e-08] 
Layer 'conv3' biases: 3.667291e-05 [6.537607e-09] 
Layer 'conv4' weights[0]: 1.765314e-03 [8.891896e-08] 
Layer 'conv4' biases: 9.997646e-01 [3.224839e-07] 
Layer 'conv5' weights[0]: 1.995121e-03 [3.557744e-06] 
Layer 'conv5' biases: 9.987027e-01 [3.977645e-06] 
Layer 'fc6' weights[0]: 6.495416e-03 [6.606567e-08] 
Layer 'fc6' biases: 9.999884e-01 [7.079642e-08] 
Layer 'fc7' weights[0]: 6.831525e-03 [1.695727e-07] 
Layer 'fc7' biases: 9.996649e-01 [2.773644e-07] 
Layer 'fc8' weights[0]: 4.927876e-03 [1.413422e-05] 
Layer 'fc8' biases: 3.257091e-02 [4.112504e-05] 
Train error last 800 batches: 0.657563
-------------------------------------------------------
Not saving because 0.408526 > 0.299667 (9.300: -1.18%)
======================================================= (2.348 sec)
38.621... logprob:  0.714903, 0.324219 (1.455 sec)
38.622... logprob:  0.656327, 0.303385 (1.443 sec)
38.623... logprob:  0.679989, 0.305990 (1.465 sec)
38.624... logprob:  0.541458, 0.253906 (1.434 sec)
38.625... logprob:  0.609963, 0.276042 (1.421 sec)
38.626... logprob:  0.695574, 0.311198 (1.434 sec)
38.627... logprob:  0.721429, 0.298177 (1.438 sec)
38.628... logprob:  0.716239, 0.313802 (1.431 sec)
38.629... logprob:  0.668947, 0.305990 (1.465 sec)
38.630... logprob:  0.713620, 0.324219 (1.442 sec)
38.631... logprob:  0.893469, 0.365885 (1.427 sec)
38.632... logprob:  0.682890, 0.302083 (1.481 sec)
38.633... logprob:  0.603219, 0.270833 (1.423 sec)
38.634... logprob:  0.836457, 0.322917 (1.424 sec)
38.635... logprob:  0.561517, 0.244792 (1.429 sec)
38.636... logprob:  0.718503, 0.328125 (1.427 sec)
38.637... logprob:  0.555183, 0.231771 (1.425 sec)
38.638... logprob:  0.714593, 0.292969 (1.478 sec)
38.639... logprob:  0.673977, 0.308594 (1.430 sec)
38.640... logprob:  0.680239, 0.307292 (1.431 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.389867, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.760514e-03 [8.802992e-08] 
Layer 'conv1' biases: 2.210233e-06 [1.904907e-11] 
Layer 'conv2' weights[0]: 1.756926e-03 [8.787799e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.112710e-10] 
Layer 'conv3' weights[0]: 1.756104e-03 [8.800843e-08] 
Layer 'conv3' biases: 3.671251e-05 [4.382065e-09] 
Layer 'conv4' weights[0]: 1.763550e-03 [8.849154e-08] 
Layer 'conv4' biases: 9.997572e-01 [2.377613e-07] 
Layer 'conv5' weights[0]: 1.986135e-03 [3.167315e-06] 
Layer 'conv5' biases: 9.987700e-01 [3.449624e-06] 
Layer 'fc6' weights[0]: 6.494781e-03 [6.491393e-08] 
Layer 'fc6' biases: 9.999889e-01 [6.794427e-08] 
Layer 'fc7' weights[0]: 6.830862e-03 [1.665288e-07] 
Layer 'fc7' biases: 9.996607e-01 [2.633865e-07] 
Layer 'fc8' weights[0]: 4.811006e-03 [1.549931e-05] 
Layer 'fc8' biases: 3.160036e-02 [3.784849e-05] 
Train error last 800 batches: 0.658002
-------------------------------------------------------
Not saving because 0.389867 > 0.299667 (9.300: -1.18%)
======================================================= (2.366 sec)
38.641... logprob:  0.674468, 0.292969 (1.491 sec)
38.642... logprob:  0.735278, 0.315104 (1.433 sec)
38.643... logprob:  0.788355, 0.356771 (1.433 sec)
38.644... logprob:  0.507379, 0.216146 (1.426 sec)
38.645... logprob:  0.600009, 0.264323 (1.425 sec)
38.646... logprob:  0.610393, 0.272135 (1.428 sec)
38.647... logprob:  0.647939, 0.276042 (1.486 sec)
38.648... logprob:  0.661567, 0.290365 (1.426 sec)
38.649... logprob:  0.650129, 0.279948 (1.440 sec)
38.650... logprob:  0.662352, 0.305990 (1.470 sec)
38.651... logprob:  0.608848, 0.286458 (1.432 sec)
38.652... logprob:  0.688514, 0.335938 (1.433 sec)
38.653... logprob:  0.718523, 0.322917 (1.433 sec)
38.654... logprob:  0.676069, 0.321615 (1.420 sec)
38.655... logprob:  0.686674, 0.309896 (1.428 sec)
38.656... logprob:  0.646061, 0.252604 (1.474 sec)
38.657... logprob:  0.708437, 0.316406 (1.434 sec)
38.658... logprob:  0.649843, 0.311198 (1.442 sec)
38.659... logprob:  0.640251, 0.287760 (1.463 sec)
38.660... logprob:  0.604693, 0.247396 (1.444 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.509473, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.758752e-03 [8.797518e-08] 
Layer 'conv1' biases: 2.210331e-06 [1.562292e-11] 
Layer 'conv2' weights[0]: 1.755173e-03 [8.780406e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.308299e-10] 
Layer 'conv3' weights[0]: 1.754338e-03 [8.783900e-08] 
Layer 'conv3' biases: 3.671466e-05 [2.871065e-09] 
Layer 'conv4' weights[0]: 1.761783e-03 [8.827260e-08] 
Layer 'conv4' biases: 9.997570e-01 [1.232320e-07] 
Layer 'conv5' weights[0]: 1.984294e-03 [2.503845e-06] 
Layer 'conv5' biases: 9.987673e-01 [2.745126e-06] 
Layer 'fc6' weights[0]: 6.494101e-03 [5.735452e-08] 
Layer 'fc6' biases: 9.999887e-01 [5.646316e-08] 
Layer 'fc7' weights[0]: 6.830204e-03 [1.428661e-07] 
Layer 'fc7' biases: 9.996601e-01 [1.873895e-07] 
Layer 'fc8' weights[0]: 4.815382e-03 [1.214010e-05] 
Layer 'fc8' biases: 3.160158e-02 [2.952416e-05] 
Train error last 800 batches: 0.657766
-------------------------------------------------------
Not saving because 0.509473 > 0.299667 (9.300: -1.18%)
======================================================= (2.345 sec)
38.661... logprob:  0.597296, 0.272135 (1.438 sec)
38.662... logprob:  0.685883, 0.330729 (1.433 sec)
38.663... logprob:  0.579909, 0.256510 (1.422 sec)
38.664... logprob:  0.576016, 0.272135 (1.432 sec)
38.665... logprob:  0.623463, 0.264323 (1.455 sec)
38.666... logprob:  0.643134, 0.304687 (1.447 sec)
38.667... logprob:  0.803115, 0.338542 (1.448 sec)
38.668... logprob:  0.740395, 0.309896 (1.441 sec)
38.669... logprob:  0.712449, 0.300781 (1.533 sec)
38.670... logprob:  0.680727, 0.291667 (1.431 sec)
38.671... logprob:  0.613700, 0.239583 (1.418 sec)
38.672... logprob:  0.639439, 0.286458 (1.428 sec)
38.673... logprob:  0.683182, 0.298177 (1.432 sec)
38.674... logprob:  0.712243, 0.304688 (1.439 sec)
38.675... logprob:  0.577517, 0.257812 (1.463 sec)
38.676... logprob:  0.697743, 0.302083 (1.446 sec)
38.677... logprob:  0.638916, 0.283854 (1.429 sec)
38.678... logprob:  0.647800, 0.278646 (1.478 sec)
38.679... logprob:  0.737149, 0.299479 (1.423 sec)
38.680... logprob:  0.602238, 0.263021 (1.424 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.480528, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.756991e-03 [8.788105e-08] 
Layer 'conv1' biases: 2.210425e-06 [1.346810e-11] 
Layer 'conv2' weights[0]: 1.753419e-03 [8.771160e-08] 
Layer 'conv2' biases: 9.999996e-01 [1.919026e-10] 
Layer 'conv3' weights[0]: 1.752576e-03 [8.774017e-08] 
Layer 'conv3' biases: 3.670714e-05 [2.673387e-09] 
Layer 'conv4' weights[0]: 1.760022e-03 [8.816841e-08] 
Layer 'conv4' biases: 9.997585e-01 [1.220689e-07] 
Layer 'conv5' weights[0]: 1.984680e-03 [2.242318e-06] 
Layer 'conv5' biases: 9.987504e-01 [2.363297e-06] 
Layer 'fc6' weights[0]: 6.493429e-03 [5.580289e-08] 
Layer 'fc6' biases: 9.999889e-01 [5.434491e-08] 
Layer 'fc7' weights[0]: 6.829510e-03 [1.367834e-07] 
Layer 'fc7' biases: 9.996608e-01 [1.591107e-07] 
Layer 'fc8' weights[0]: 4.836489e-03 [1.062139e-05] 
Layer 'fc8' biases: 3.177096e-02 [4.662469e-06] 
Train error last 800 batches: 0.657799
-------------------------------------------------------
Not saving because 0.480528 > 0.299667 (9.300: -1.18%)
======================================================= (2.358 sec)
38.681... logprob:  0.585098, 0.261719 (1.438 sec)
38.682... logprob:  0.576177, 0.259115 (1.438 sec)
38.683... logprob:  0.637203, 0.256510 (1.433 sec)
38.684... logprob:  0.566664, 0.248698 (1.474 sec)
38.685... logprob:  0.454662, 0.195312 (1.441 sec)
38.686... logprob:  0.636646, 0.282552 (1.428 sec)
38.687... logprob:  0.518244, 0.222656 (1.487 sec)
38.688... logprob:  0.532161, 0.252604 (1.424 sec)
38.689... logprob:  0.703217, 0.302083 (1.426 sec)
38.690... logprob:  0.689241, 0.302083 (1.429 sec)
38.691... logprob:  0.687433, 0.285156 (1.431 sec)
38.692... logprob:  0.575674, 0.257812 (1.429 sec)
38.693... logprob:  0.644070, 0.325521 (1.475 sec)
38.694... logprob:  0.643232, 0.283854 (1.432 sec)
38.695... logprob:  0.616416, 0.259115 (1.433 sec)
38.696... logprob:  0.769398, 0.324219 (1.475 sec)
38.697... logprob:  0.699144, 0.305990 (1.425 sec)
38.698... logprob:  0.740180, 0.316406 (1.430 sec)
38.699... logprob:  0.672477, 0.285156 (1.427 sec)
38.700... logprob:  0.679670, 0.303385 (1.425 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.413388, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.755233e-03 [8.778487e-08] 
Layer 'conv1' biases: 2.210412e-06 [2.124176e-11] 
Layer 'conv2' weights[0]: 1.751668e-03 [8.761764e-08] 
Layer 'conv2' biases: 9.999996e-01 [4.823970e-10] 
Layer 'conv3' weights[0]: 1.750828e-03 [8.796847e-08] 
Layer 'conv3' biases: 3.667597e-05 [6.479492e-09] 
Layer 'conv4' weights[0]: 1.758263e-03 [8.854141e-08] 
Layer 'conv4' biases: 9.997625e-01 [3.128169e-07] 
Layer 'conv5' weights[0]: 1.987972e-03 [2.838879e-06] 
Layer 'conv5' biases: 9.987082e-01 [3.096172e-06] 
Layer 'fc6' weights[0]: 6.492752e-03 [6.340239e-08] 
Layer 'fc6' biases: 9.999887e-01 [6.688884e-08] 
Layer 'fc7' weights[0]: 6.828810e-03 [1.570366e-07] 
Layer 'fc7' biases: 9.996626e-01 [2.333539e-07] 
Layer 'fc8' weights[0]: 4.894936e-03 [1.273266e-05] 
Layer 'fc8' biases: 3.225679e-02 [3.039008e-05] 
Train error last 800 batches: 0.657702
-------------------------------------------------------
Not saving because 0.413388 > 0.299667 (9.300: -1.18%)
======================================================= (2.347 sec)
38.701... logprob:  0.629167, 0.285156 (1.429 sec)
38.702... logprob:  0.692478, 0.281250 (1.485 sec)
38.703... logprob:  0.693243, 0.322917 (1.435 sec)
38.704... logprob:  0.626995, 0.282552 (1.443 sec)
38.705... logprob:  0.655807, 0.313802 (1.468 sec)
38.706... logprob:  0.701166, 0.294271 (1.426 sec)
38.707... logprob:  0.752918, 0.309896 (1.437 sec)
38.708... logprob:  0.664095, 0.313802 (1.431 sec)
38.709... logprob:  0.657054, 0.286458 (1.418 sec)
38.710... logprob:  0.746049, 0.322917 (1.432 sec)
38.711... logprob:  0.691767, 0.298177 (1.459 sec)
38.712... logprob:  0.529597, 0.240885 (1.442 sec)
38.713... logprob:  0.763621, 0.320312 (1.450 sec)
38.714... logprob:  0.652786, 0.278646 (1.457 sec)
38.715... logprob:  0.610379, 0.276042 (1.447 sec)
38.716... logprob:  0.660019, 0.291667 (1.431 sec)
38.717... logprob:  0.738423, 0.335938 (1.420 sec)
38.718... logprob:  0.694480, 0.322917 (1.421 sec)
38.719... logprob:  0.681758, 0.316406 (1.431 sec)
38.720... logprob:  0.702780, 0.329427 (1.441 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.448848, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.753483e-03 [8.770217e-08] 
Layer 'conv1' biases: 2.210504e-06 [1.313687e-11] 
Layer 'conv2' weights[0]: 1.749917e-03 [8.753454e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.021192e-10] 
Layer 'conv3' weights[0]: 1.749067e-03 [8.755997e-08] 
Layer 'conv3' biases: 3.671214e-05 [2.901738e-09] 
Layer 'conv4' weights[0]: 1.756501e-03 [8.795692e-08] 
Layer 'conv4' biases: 9.997581e-01 [1.178166e-07] 
Layer 'conv5' weights[0]: 1.982045e-03 [2.061706e-06] 
Layer 'conv5' biases: 9.987462e-01 [2.164426e-06] 
Layer 'fc6' weights[0]: 6.492078e-03 [5.774598e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.768813e-08] 
Layer 'fc7' weights[0]: 6.828139e-03 [1.433988e-07] 
Layer 'fc7' biases: 9.996598e-01 [2.015123e-07] 
Layer 'fc8' weights[0]: 4.819844e-03 [1.350317e-05] 
Layer 'fc8' biases: 3.167846e-02 [3.211454e-05] 
Train error last 800 batches: 0.658001
-------------------------------------------------------
Not saving because 0.448848 > 0.299667 (9.300: -1.18%)
======================================================= (2.395 sec)
38.721... logprob:  0.622803, 0.273437 (1.466 sec)
38.722... logprob:  0.644098, 0.290365 (1.451 sec)
38.723... logprob:  0.583095, 0.264323 (1.442 sec)
38.724... logprob:  0.574576, 0.270833 (1.463 sec)
38.725... logprob:  0.652800, 0.263021 (1.431 sec)
38.726... logprob:  0.651180, 0.299479 (1.418 sec)
38.727... logprob:  0.666077, 0.305990 (1.423 sec)
38.728... logprob:  0.642313, 0.287760 (1.437 sec)
38.729... logprob:  0.609572, 0.269531 (1.426 sec)
38.730... logprob:  0.739552, 0.316406 (1.470 sec)
38.731... logprob:  0.675218, 0.304687 (1.435 sec)
38.732... logprob:  0.544206, 0.221354 (1.426 sec)
38.733... logprob:  0.804758, 0.332031 (1.486 sec)
38.734... logprob:  0.516512, 0.221354 (1.424 sec)
38.735... logprob:  0.760847, 0.319010 (1.423 sec)
38.736... logprob:  0.778797, 0.341146 (1.433 sec)
38.737... logprob:  0.675556, 0.295573 (1.430 sec)
38.738... logprob:  0.726412, 0.321615 (1.430 sec)
38.739... logprob:  0.714269, 0.290365 (1.470 sec)
38.740... logprob:  0.553311, 0.253906 (1.435 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.393470, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.751733e-03 [8.760463e-08] 
Layer 'conv1' biases: 2.210581e-06 [1.587282e-11] 
Layer 'conv2' weights[0]: 1.748170e-03 [8.744002e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.282239e-10] 
Layer 'conv3' weights[0]: 1.747319e-03 [8.750119e-08] 
Layer 'conv3' biases: 3.671124e-05 [3.229915e-09] 
Layer 'conv4' weights[0]: 1.754743e-03 [8.790593e-08] 
Layer 'conv4' biases: 9.997589e-01 [1.469923e-07] 
Layer 'conv5' weights[0]: 1.981175e-03 [2.177126e-06] 
Layer 'conv5' biases: 9.987395e-01 [2.314857e-06] 
Layer 'fc6' weights[0]: 6.491407e-03 [5.695337e-08] 
Layer 'fc6' biases: 9.999892e-01 [5.661436e-08] 
Layer 'fc7' weights[0]: 6.827432e-03 [1.413912e-07] 
Layer 'fc7' biases: 9.996598e-01 [1.821364e-07] 
Layer 'fc8' weights[0]: 4.817990e-03 [1.128510e-05] 
Layer 'fc8' biases: 3.169760e-02 [1.658982e-05] 
Train error last 800 batches: 0.657639
-------------------------------------------------------
Not saving because 0.393470 > 0.299667 (9.300: -1.18%)
======================================================= (2.393 sec)
38.741... logprob:  0.581649, 0.253906 (1.440 sec)
38.742... logprob:  0.734504, 0.315104 (1.484 sec)
38.743... logprob:  0.585370, 0.234375 (1.435 sec)
38.744... logprob:  0.710784, 0.291667 (1.425 sec)
38.745... logprob:  0.701140, 0.329427 (1.429 sec)
38.746... logprob:  0.655268, 0.270833 (1.425 sec)
38.747... logprob:  0.773044, 0.339844 (1.431 sec)
38.748... logprob:  0.658231, 0.285156 (1.477 sec)
38.749... logprob:  0.699362, 0.289062 (1.431 sec)
38.750... logprob:  0.750303, 0.335938 (1.438 sec)
38.751... logprob:  0.565083, 0.264323 (1.472 sec)
38.752... logprob:  0.669545, 0.289062 (1.442 sec)
38.753... logprob:  0.680693, 0.281250 (1.430 sec)
38.754... logprob:  0.758224, 0.332031 (1.429 sec)
38.755... logprob:  0.612874, 0.268229 (1.425 sec)
38.756... logprob:  0.708196, 0.339844 (1.427 sec)
38.757... logprob:  0.733065, 0.330729 (1.467 sec)
38.758... logprob:  0.599909, 0.291667 (1.442 sec)
38.759... logprob:  0.709395, 0.320312 (1.445 sec)
38.760... logprob:  0.666290, 0.315104 (1.460 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.559934, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.749975e-03 [8.753954e-08] 
Layer 'conv1' biases: 2.210620e-06 [1.253988e-11] 
Layer 'conv2' weights[0]: 1.746421e-03 [8.736336e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.597223e-10] 
Layer 'conv3' weights[0]: 1.745566e-03 [8.743272e-08] 
Layer 'conv3' biases: 3.670746e-05 [3.871501e-09] 
Layer 'conv4' weights[0]: 1.752993e-03 [8.790868e-08] 
Layer 'conv4' biases: 9.997594e-01 [2.007260e-07] 
Layer 'conv5' weights[0]: 1.980329e-03 [2.141257e-06] 
Layer 'conv5' biases: 9.987380e-01 [2.421620e-06] 
Layer 'fc6' weights[0]: 6.490720e-03 [5.633006e-08] 
Layer 'fc6' biases: 9.999889e-01 [5.546966e-08] 
Layer 'fc7' weights[0]: 6.826809e-03 [1.360024e-07] 
Layer 'fc7' biases: 9.996592e-01 [1.730848e-07] 
Layer 'fc8' weights[0]: 4.814823e-03 [1.089046e-05] 
Layer 'fc8' biases: 3.174679e-02 [1.942642e-05] 
Train error last 800 batches: 0.657858
-------------------------------------------------------
Not saving because 0.559934 > 0.299667 (9.300: -1.18%)
======================================================= (2.382 sec)
38.761... logprob:  0.610526, 0.279948 (1.447 sec)
38.762... logprob:  0.669945, 0.292969 (1.442 sec)
38.763... logprob:  0.799941, 0.328125 (1.434 sec)
38.764... logprob:  0.697714, 0.260417 (1.422 sec)
38.765... logprob:  0.456657, 0.212239 (1.430 sec)
38.766... logprob:  0.667254, 0.309896 (1.448 sec)
38.767... logprob:  0.654700, 0.302083 (1.453 sec)
38.768... logprob:  0.636817, 0.296875 (1.463 sec)
38.769... logprob:  0.687384, 0.283854 (1.469 sec)
38.770... logprob:  0.591351, 0.256510 (1.481 sec)
38.771... logprob:  0.733372, 0.303385 (1.452 sec)
38.772... logprob:  0.604025, 0.251302 (1.438 sec)
38.773... logprob:  0.807166, 0.358073 (1.442 sec)
38.774... logprob:  0.568242, 0.242187 (1.459 sec)
38.775... logprob:  0.620607, 0.269531 (1.454 sec)
38.776... logprob:  0.641058, 0.292969 (1.475 sec)
38.777... logprob:  0.573345, 0.279948 (1.464 sec)
38.778... logprob:  0.670532, 0.282552 (1.462 sec)
38.779... logprob:  0.680889, 0.282552 (1.503 sec)
38.780... logprob:  0.537277, 0.248698 (1.445 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.454800, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.748224e-03 [8.746721e-08] 
Layer 'conv1' biases: 2.210712e-06 [1.649923e-11] 
Layer 'conv2' weights[0]: 1.744665e-03 [8.727913e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.371921e-10] 
Layer 'conv3' weights[0]: 1.743841e-03 [8.746389e-08] 
Layer 'conv3' biases: 3.670110e-05 [5.319576e-09] 
Layer 'conv4' weights[0]: 1.751247e-03 [8.801645e-08] 
Layer 'conv4' biases: 9.997627e-01 [2.595010e-07] 
Layer 'conv5' weights[0]: 1.982788e-03 [2.530946e-06] 
Layer 'conv5' biases: 9.987224e-01 [2.783255e-06] 
Layer 'fc6' weights[0]: 6.490051e-03 [5.790135e-08] 
Layer 'fc6' biases: 9.999887e-01 [5.794280e-08] 
Layer 'fc7' weights[0]: 6.826100e-03 [1.410235e-07] 
Layer 'fc7' biases: 9.996604e-01 [1.904240e-07] 
Layer 'fc8' weights[0]: 4.851890e-03 [1.138821e-05] 
Layer 'fc8' biases: 3.203298e-02 [2.397293e-05] 
Train error last 800 batches: 0.657206
-------------------------------------------------------
Not saving because 0.454800 > 0.299667 (9.300: -1.18%)
======================================================= (2.389 sec)
38.781... logprob:  0.649878, 0.285156 (1.446 sec)
38.782... logprob:  0.556892, 0.259115 (1.440 sec)
38.783... logprob:  0.841365, 0.365885 (1.456 sec)
38.784... logprob:  0.622679, 0.282552 (1.450 sec)
38.785... logprob:  0.713796, 0.302083 (1.486 sec)
38.786... logprob:  0.669304, 0.307292 (1.466 sec)
38.787... logprob:  0.702900, 0.309896 (1.450 sec)
38.788... logprob:  0.718425, 0.299479 (1.491 sec)
38.789... logprob:  0.585725, 0.278646 (1.448 sec)
38.790... logprob:  0.678570, 0.289063 (1.438 sec)
38.791... logprob:  0.624158, 0.266927 (1.442 sec)
38.792... logprob:  0.636189, 0.303385 (1.456 sec)
38.793... logprob:  0.568970, 0.281250 (1.448 sec)
38.794... logprob:  0.596681, 0.252604 (1.488 sec)
38.795... logprob:  0.725052, 0.308594 (1.462 sec)
38.796... logprob:  0.692435, 0.289062 (1.458 sec)
38.797... logprob:  0.563147, 0.251302 (1.489 sec)
38.798... logprob:  0.598257, 0.268229 (1.445 sec)
38.799... logprob:  0.629796, 0.281250 (1.452 sec)
38.800... logprob:  0.592157, 0.273438 (1.394 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.387737, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.746482e-03 [8.737287e-08] 
Layer 'conv1' biases: 2.210813e-06 [1.341305e-11] 
Layer 'conv2' weights[0]: 1.742927e-03 [8.719500e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.494114e-10] 
Layer 'conv3' weights[0]: 1.742080e-03 [8.724485e-08] 
Layer 'conv3' biases: 3.669775e-05 [3.245840e-09] 
Layer 'conv4' weights[0]: 1.749494e-03 [8.773607e-08] 
Layer 'conv4' biases: 9.997631e-01 [1.581930e-07] 
Layer 'conv5' weights[0]: 1.981747e-03 [2.854102e-06] 
Layer 'conv5' biases: 9.987126e-01 [3.112957e-06] 
Layer 'fc6' weights[0]: 6.489409e-03 [6.001211e-08] 
Layer 'fc6' biases: 9.999885e-01 [6.145394e-08] 
Layer 'fc7' weights[0]: 6.825429e-03 [1.488090e-07] 
Layer 'fc7' biases: 9.996610e-01 [2.209718e-07] 
Layer 'fc8' weights[0]: 4.873858e-03 [1.251301e-05] 
Layer 'fc8' biases: 3.226828e-02 [3.671702e-05] 
Train error last 800 batches: 0.657591
-------------------------------------------------------
Not saving because 0.387737 > 0.299667 (9.300: -1.18%)
======================================================= (2.365 sec)
39.1... logprob:  0.649091, 0.281250 (1.407 sec)
39.2... logprob:  0.674955, 0.274740 (1.448 sec)
39.3... logprob:  0.655767, 0.287760 (1.414 sec)
39.4... logprob:  0.690023, 0.265625 (1.399 sec)
39.5... logprob:  0.664900, 0.276042 (1.427 sec)
39.6... logprob:  0.707527, 0.289062 (1.392 sec)
39.7... logprob:  0.615221, 0.285156 (1.415 sec)
39.8... logprob:  0.562111, 0.238281 (1.391 sec)
39.9... logprob:  0.669605, 0.292969 (1.397 sec)
39.10... logprob:  0.633776, 0.285156 (1.407 sec)
39.11... logprob:  0.585486, 0.253906 (1.446 sec)
39.12... logprob:  0.703026, 0.295573 (1.392 sec)
39.13... logprob:  0.738840, 0.338542 (1.418 sec)
39.14... logprob:  0.698746, 0.283854 (1.396 sec)
39.15... logprob:  0.542063, 0.252604 (1.406 sec)
39.16... logprob:  0.647345, 0.270833 (1.399 sec)
39.17... logprob:  0.720344, 0.292969 (1.389 sec)
39.18... logprob:  0.542504, 0.248698 (1.396 sec)
39.19... logprob:  0.572512, 0.260417 (1.389 sec)
39.20... logprob:  0.628250, 0.270833 (1.400 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.439632, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.744731e-03 [8.727035e-08] 
Layer 'conv1' biases: 2.210910e-06 [1.693868e-11] 
Layer 'conv2' weights[0]: 1.741178e-03 [8.710352e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.934654e-10] 
Layer 'conv3' weights[0]: 1.740352e-03 [8.717588e-08] 
Layer 'conv3' biases: 3.669215e-05 [3.709818e-09] 
Layer 'conv4' weights[0]: 1.747757e-03 [8.769233e-08] 
Layer 'conv4' biases: 9.997625e-01 [1.708640e-07] 
Layer 'conv5' weights[0]: 1.979073e-03 [2.132911e-06] 
Layer 'conv5' biases: 9.987251e-01 [2.364067e-06] 
Layer 'fc6' weights[0]: 6.488737e-03 [5.417053e-08] 
Layer 'fc6' biases: 9.999884e-01 [5.245108e-08] 
Layer 'fc7' weights[0]: 6.824745e-03 [1.334332e-07] 
Layer 'fc7' biases: 9.996607e-01 [1.613478e-07] 
Layer 'fc8' weights[0]: 4.857377e-03 [1.048048e-05] 
Layer 'fc8' biases: 3.221727e-02 [1.675992e-05] 
Train error last 800 batches: 0.657745
-------------------------------------------------------
Not saving because 0.439632 > 0.299667 (9.300: -1.18%)
======================================================= (2.374 sec)
39.21... logprob:  0.663766, 0.286458 (1.408 sec)
39.22... logprob:  0.625533, 0.287760 (1.421 sec)
39.23... logprob:  0.724127, 0.302083 (1.414 sec)
39.24... logprob:  0.532873, 0.236979 (1.411 sec)
39.25... logprob:  0.607416, 0.272135 (1.403 sec)
39.26... logprob:  0.652786, 0.290365 (1.440 sec)
39.27... logprob:  0.599376, 0.261719 (1.383 sec)
39.28... logprob:  0.597205, 0.255208 (1.402 sec)
39.29... logprob:  0.671276, 0.286458 (1.420 sec)
39.30... logprob:  0.642458, 0.272135 (1.416 sec)
39.31... logprob:  0.677053, 0.290365 (1.402 sec)
39.32... logprob:  0.686003, 0.299479 (1.383 sec)
39.33... logprob:  0.702731, 0.285156 (1.446 sec)
39.34... logprob:  0.658661, 0.255208 (1.386 sec)
39.35... logprob:  0.583374, 0.283854 (1.392 sec)
39.36... logprob:  0.714224, 0.316406 (1.397 sec)
39.37... logprob:  0.664493, 0.304687 (1.403 sec)
39.38... logprob:  0.535232, 0.252604 (1.387 sec)
39.39... logprob:  0.854943, 0.354167 (1.428 sec)
39.40... logprob:  0.672046, 0.265625 (1.404 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.476255, 0.117188 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.742988e-03 [8.714899e-08] 
Layer 'conv1' biases: 2.211062e-06 [1.965951e-11] 
Layer 'conv2' weights[0]: 1.739443e-03 [8.699829e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.862646e-10] 
Layer 'conv3' weights[0]: 1.738611e-03 [8.722415e-08] 
Layer 'conv3' biases: 3.669574e-05 [5.265394e-09] 
Layer 'conv4' weights[0]: 1.745988e-03 [8.776829e-08] 
Layer 'conv4' biases: 9.997595e-01 [2.938151e-07] 
Layer 'conv5' weights[0]: 1.974243e-03 [2.599333e-06] 
Layer 'conv5' biases: 9.987256e-01 [2.837493e-06] 
Layer 'fc6' weights[0]: 6.488082e-03 [6.258519e-08] 
Layer 'fc6' biases: 9.999884e-01 [6.495464e-08] 
Layer 'fc7' weights[0]: 6.824049e-03 [1.545518e-07] 
Layer 'fc7' biases: 9.996604e-01 [2.185606e-07] 
Layer 'fc8' weights[0]: 4.853994e-03 [1.308191e-05] 
Layer 'fc8' biases: 3.220046e-02 [3.151989e-05] 
Train error last 800 batches: 0.657641
-------------------------------------------------------
Not saving because 0.476255 > 0.299667 (9.300: -1.18%)
======================================================= (2.357 sec)
39.41... logprob:  0.639988, 0.274740 (1.423 sec)
39.42... logprob:  0.607123, 0.291667 (1.412 sec)
39.43... logprob:  0.732035, 0.329427 (1.404 sec)
39.44... logprob:  0.662813, 0.278646 (1.432 sec)
39.45... logprob:  0.699591, 0.339844 (1.381 sec)
39.46... logprob:  0.670499, 0.278646 (1.390 sec)
39.47... logprob:  0.547244, 0.255208 (1.389 sec)
39.48... logprob:  0.753263, 0.325521 (1.415 sec)
39.49... logprob:  0.697708, 0.302083 (1.408 sec)
39.50... logprob:  0.612485, 0.279948 (1.420 sec)
39.51... logprob:  0.692218, 0.315104 (1.412 sec)
39.52... logprob:  0.643053, 0.286458 (1.396 sec)
39.53... logprob:  0.594420, 0.259115 (1.441 sec)
39.54... logprob:  0.549298, 0.250000 (1.381 sec)
39.55... logprob:  0.628721, 0.281250 (1.394 sec)
39.56... logprob:  0.626807, 0.287760 (1.393 sec)
39.57... logprob:  0.754076, 0.325521 (1.424 sec)
39.58... logprob:  0.637798, 0.257812 (1.405 sec)
39.59... logprob:  0.589198, 0.295573 (1.462 sec)
39.60... logprob:  0.808184, 0.356771 (1.416 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.500813, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.741251e-03 [8.710751e-08] 
Layer 'conv1' biases: 2.211106e-06 [1.446683e-11] 
Layer 'conv2' weights[0]: 1.737707e-03 [8.693100e-08] 
Layer 'conv2' biases: 9.999996e-01 [1.916829e-10] 
Layer 'conv3' weights[0]: 1.736891e-03 [8.695259e-08] 
Layer 'conv3' biases: 3.669349e-05 [2.442655e-09] 
Layer 'conv4' weights[0]: 1.744244e-03 [8.736516e-08] 
Layer 'conv4' biases: 9.997596e-01 [1.010032e-07] 
Layer 'conv5' weights[0]: 1.972687e-03 [2.059895e-06] 
Layer 'conv5' biases: 9.987116e-01 [2.179575e-06] 
Layer 'fc6' weights[0]: 6.487421e-03 [5.567006e-08] 
Layer 'fc6' biases: 9.999884e-01 [5.520796e-08] 
Layer 'fc7' weights[0]: 6.823334e-03 [1.383448e-07] 
Layer 'fc7' biases: 9.996605e-01 [1.746586e-07] 
Layer 'fc8' weights[0]: 4.863250e-03 [1.102556e-05] 
Layer 'fc8' biases: 3.225601e-02 [1.771094e-05] 
Train error last 800 batches: 0.657879
-------------------------------------------------------
Not saving because 0.500813 > 0.299667 (9.300: -1.18%)
======================================================= (2.355 sec)
39.61... logprob:  0.642794, 0.290365 (1.438 sec)
39.62... logprob:  0.656036, 0.299479 (1.454 sec)
39.63... logprob:  0.567997, 0.242187 (1.430 sec)
39.64... logprob:  0.588475, 0.269531 (1.407 sec)
39.65... logprob:  0.586350, 0.261719 (1.398 sec)
39.66... logprob:  0.523020, 0.233073 (1.440 sec)
39.67... logprob:  0.514871, 0.236979 (1.387 sec)
39.68... logprob:  0.631323, 0.291667 (1.400 sec)
39.69... logprob:  0.679532, 0.295573 (1.420 sec)
39.70... logprob:  0.534018, 0.255208 (1.420 sec)
39.71... logprob:  0.623396, 0.266927 (1.455 sec)
39.72... logprob:  0.742795, 0.311198 (1.396 sec)
39.73... logprob:  0.694369, 0.322917 (1.415 sec)
39.74... logprob:  0.671563, 0.291667 (1.413 sec)
39.75... logprob:  0.587819, 0.250000 (1.416 sec)
39.76... logprob:  0.618930, 0.270833 (1.428 sec)
39.77... logprob:  0.567104, 0.257812 (1.421 sec)
39.78... logprob:  0.721464, 0.303385 (1.450 sec)
39.79... logprob:  0.615200, 0.268229 (1.402 sec)
39.80... logprob:  0.688629, 0.273437 (1.411 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.509512, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.739499e-03 [8.698097e-08] 
Layer 'conv1' biases: 2.211109e-06 [1.655463e-11] 
Layer 'conv2' weights[0]: 1.735966e-03 [8.682538e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.640448e-10] 
Layer 'conv3' weights[0]: 1.735151e-03 [8.693856e-08] 
Layer 'conv3' biases: 3.667579e-05 [3.985581e-09] 
Layer 'conv4' weights[0]: 1.742499e-03 [8.737693e-08] 
Layer 'conv4' biases: 9.997627e-01 [1.687505e-07] 
Layer 'conv5' weights[0]: 1.976087e-03 [2.367939e-06] 
Layer 'conv5' biases: 9.986730e-01 [2.630104e-06] 
Layer 'fc6' weights[0]: 6.486755e-03 [5.801275e-08] 
Layer 'fc6' biases: 9.999884e-01 [5.974778e-08] 
Layer 'fc7' weights[0]: 6.822641e-03 [1.441224e-07] 
Layer 'fc7' biases: 9.996625e-01 [1.915039e-07] 
Layer 'fc8' weights[0]: 4.928942e-03 [1.160092e-05] 
Layer 'fc8' biases: 3.279183e-02 [1.879836e-05] 
Train error last 800 batches: 0.657535
-------------------------------------------------------
Not saving because 0.509512 > 0.299667 (9.300: -1.18%)
======================================================= (2.375 sec)
39.81... logprob:  0.658023, 0.312500 (1.420 sec)
39.82... logprob:  0.500284, 0.246094 (1.416 sec)
39.83... logprob:  0.694044, 0.292969 (1.397 sec)
39.84... logprob:  0.639841, 0.289062 (1.465 sec)
39.85... logprob:  0.628923, 0.277344 (1.418 sec)
39.86... logprob:  0.593387, 0.292969 (1.414 sec)
39.87... logprob:  0.843962, 0.342448 (1.416 sec)
39.88... logprob:  0.736371, 0.295573 (1.400 sec)
39.89... logprob:  0.645482, 0.286458 (1.428 sec)
39.90... logprob:  0.805648, 0.322917 (1.382 sec)
39.91... logprob:  0.572717, 0.257812 (1.391 sec)
39.92... logprob:  0.760033, 0.319010 (1.395 sec)
39.93... logprob:  0.634198, 0.282552 (1.388 sec)
39.94... logprob:  0.640306, 0.261719 (1.383 sec)
39.95... logprob:  0.673778, 0.290365 (1.427 sec)
39.96... logprob:  0.739090, 0.305990 (1.398 sec)
39.97... logprob:  0.689506, 0.304688 (1.386 sec)
39.98... logprob:  0.589944, 0.259115 (1.438 sec)
39.99... logprob:  0.675625, 0.291666 (1.396 sec)
39.100... logprob:  0.585329, 0.264323 (1.398 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.517741, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.737761e-03 [8.690179e-08] 
Layer 'conv1' biases: 2.211298e-06 [1.963952e-11] 
Layer 'conv2' weights[0]: 1.734221e-03 [8.674321e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.507186e-10] 
Layer 'conv3' weights[0]: 1.733404e-03 [8.688778e-08] 
Layer 'conv3' biases: 3.670562e-05 [4.507437e-09] 
Layer 'conv4' weights[0]: 1.740769e-03 [8.735460e-08] 
Layer 'conv4' biases: 9.997564e-01 [2.201904e-07] 
Layer 'conv5' weights[0]: 1.966842e-03 [2.494537e-06] 
Layer 'conv5' biases: 9.987205e-01 [2.743013e-06] 
Layer 'fc6' weights[0]: 6.486102e-03 [6.087571e-08] 
Layer 'fc6' biases: 9.999886e-01 [6.344559e-08] 
Layer 'fc7' weights[0]: 6.821950e-03 [1.580168e-07] 
Layer 'fc7' biases: 9.996595e-01 [2.421080e-07] 
Layer 'fc8' weights[0]: 4.839323e-03 [1.470576e-05] 
Layer 'fc8' biases: 3.206085e-02 [4.184076e-05] 
Train error last 800 batches: 0.657289
-------------------------------------------------------
Not saving because 0.517741 > 0.299667 (9.300: -1.18%)
======================================================= (2.385 sec)
39.101... logprob:  0.632966, 0.259114 (1.441 sec)
39.102... logprob:  0.797782, 0.343750 (1.383 sec)
39.103... logprob:  0.790173, 0.339844 (1.393 sec)
39.104... logprob:  0.681635, 0.322917 (1.398 sec)
39.105... logprob:  0.767838, 0.311198 (1.394 sec)
39.106... logprob:  0.609816, 0.268229 (1.385 sec)
39.107... logprob:  0.545364, 0.235677 (1.445 sec)
39.108... logprob:  0.817640, 0.352865 (1.396 sec)
39.109... logprob:  0.580302, 0.236979 (1.392 sec)
39.110... logprob:  0.709592, 0.317708 (1.390 sec)
39.111... logprob:  0.615506, 0.270833 (1.391 sec)
39.112... logprob:  0.596383, 0.252604 (1.392 sec)
39.113... logprob:  0.550836, 0.238281 (1.396 sec)
39.114... logprob:  0.594143, 0.263021 (1.421 sec)
39.115... logprob:  0.754174, 0.305990 (1.408 sec)
39.116... logprob:  0.611005, 0.268229 (1.388 sec)
39.117... logprob:  0.642885, 0.285156 (1.440 sec)
39.118... logprob:  0.585366, 0.256510 (1.382 sec)
39.119... logprob:  0.597274, 0.247396 (1.389 sec)
39.120... logprob:  0.750035, 0.334635 (1.393 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.449480, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.736029e-03 [8.685271e-08] 
Layer 'conv1' biases: 2.211339e-06 [1.585712e-11] 
Layer 'conv2' weights[0]: 1.732491e-03 [8.667197e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.920800e-10] 
Layer 'conv3' weights[0]: 1.731662e-03 [8.674465e-08] 
Layer 'conv3' biases: 3.671809e-05 [3.835314e-09] 
Layer 'conv4' weights[0]: 1.739009e-03 [8.722318e-08] 
Layer 'conv4' biases: 9.997543e-01 [1.926400e-07] 
Layer 'conv5' weights[0]: 1.964235e-03 [2.892895e-06] 
Layer 'conv5' biases: 9.987276e-01 [3.115762e-06] 
Layer 'fc6' weights[0]: 6.485439e-03 [6.106476e-08] 
Layer 'fc6' biases: 9.999886e-01 [6.239302e-08] 
Layer 'fc7' weights[0]: 6.821310e-03 [1.537773e-07] 
Layer 'fc7' biases: 9.996591e-01 [2.265889e-07] 
Layer 'fc8' weights[0]: 4.827804e-03 [1.304087e-05] 
Layer 'fc8' biases: 3.210257e-02 [3.592181e-05] 
Train error last 800 batches: 0.657162
-------------------------------------------------------
Not saving because 0.449480 > 0.299667 (9.300: -1.18%)
======================================================= (2.383 sec)
39.121... logprob:  0.553300, 0.257812 (1.404 sec)
39.122... logprob:  0.724806, 0.339844 (1.448 sec)
39.123... logprob:  0.703368, 0.294271 (1.388 sec)
39.124... logprob:  0.691886, 0.300781 (1.397 sec)
39.125... logprob:  0.713554, 0.326823 (1.392 sec)
39.126... logprob:  0.738039, 0.348958 (1.385 sec)
39.127... logprob:  0.658150, 0.283854 (1.391 sec)
39.128... logprob:  0.624890, 0.274740 (1.414 sec)
39.129... logprob:  0.724142, 0.313802 (1.425 sec)
39.130... logprob:  0.637342, 0.264323 (1.409 sec)
39.131... logprob:  0.654772, 0.302083 (1.402 sec)
39.132... logprob:  0.679903, 0.315104 (1.431 sec)
39.133... logprob:  0.680451, 0.281250 (1.388 sec)
39.134... logprob:  0.652584, 0.287760 (1.411 sec)
39.135... logprob:  0.625970, 0.279948 (1.399 sec)
39.136... logprob:  0.821792, 0.328125 (1.390 sec)
39.137... logprob:  0.724883, 0.319010 (1.384 sec)
39.138... logprob:  0.588706, 0.257812 (1.446 sec)
39.139... logprob:  0.601264, 0.255208 (1.390 sec)
39.140... logprob:  0.772147, 0.329427 (1.406 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.440586, 0.093750 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.734291e-03 [8.671337e-08] 
Layer 'conv1' biases: 2.211413e-06 [1.698082e-11] 
Layer 'conv2' weights[0]: 1.730765e-03 [8.656115e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.231837e-10] 
Layer 'conv3' weights[0]: 1.729934e-03 [8.670936e-08] 
Layer 'conv3' biases: 3.673948e-05 [4.418235e-09] 
Layer 'conv4' weights[0]: 1.737279e-03 [8.717146e-08] 
Layer 'conv4' biases: 9.997512e-01 [2.335863e-07] 
Layer 'conv5' weights[0]: 1.959449e-03 [2.737556e-06] 
Layer 'conv5' biases: 9.987383e-01 [2.930923e-06] 
Layer 'fc6' weights[0]: 6.484777e-03 [6.191954e-08] 
Layer 'fc6' biases: 9.999884e-01 [6.390861e-08] 
Layer 'fc7' weights[0]: 6.820621e-03 [1.558467e-07] 
Layer 'fc7' biases: 9.996586e-01 [2.256806e-07] 
Layer 'fc8' weights[0]: 4.814948e-03 [1.343309e-05] 
Layer 'fc8' biases: 3.201279e-02 [3.436058e-05] 
Train error last 800 batches: 0.656914
-------------------------------------------------------
Not saving because 0.440586 > 0.299667 (9.300: -1.18%)
======================================================= (2.379 sec)
39.141... logprob:  0.675373, 0.302083 (1.439 sec)
39.142... logprob:  0.625986, 0.285156 (1.399 sec)
39.143... logprob:  0.579304, 0.251302 (1.432 sec)
39.144... logprob:  0.638241, 0.277344 (1.414 sec)
39.145... logprob:  0.625568, 0.313802 (1.416 sec)
39.146... logprob:  0.739329, 0.309896 (1.402 sec)
39.147... logprob:  0.533747, 0.251302 (1.426 sec)
39.148... logprob:  0.672527, 0.298177 (1.386 sec)
39.149... logprob:  0.711646, 0.305989 (1.389 sec)
39.150... logprob:  0.572834, 0.253906 (1.391 sec)
39.151... logprob:  0.563074, 0.252604 (1.394 sec)
39.152... logprob:  0.939991, 0.385417 (1.383 sec)
39.153... logprob:  0.598638, 0.261719 (1.436 sec)
39.154... logprob:  0.706669, 0.332031 (1.394 sec)
39.155... logprob:  0.571347, 0.250000 (1.412 sec)
39.156... logprob:  0.571751, 0.247396 (1.430 sec)
39.157... logprob:  0.500706, 0.236979 (1.394 sec)
39.158... logprob:  0.648876, 0.253906 (1.483 sec)
39.159... logprob:  0.704186, 0.295573 (1.395 sec)
39.160... logprob:  0.577460, 0.273437 (1.387 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.554661, 0.156250 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.732563e-03 [8.669752e-08] 
Layer 'conv1' biases: 2.211482e-06 [2.656668e-11] 
Layer 'conv2' weights[0]: 1.729031e-03 [8.650907e-08] 
Layer 'conv2' biases: 9.999996e-01 [5.396554e-10] 
Layer 'conv3' weights[0]: 1.728185e-03 [8.692763e-08] 
Layer 'conv3' biases: 3.671900e-05 [7.803329e-09] 
Layer 'conv4' weights[0]: 1.735550e-03 [8.778289e-08] 
Layer 'conv4' biases: 9.997555e-01 [4.430496e-07] 
Layer 'conv5' weights[0]: 1.963057e-03 [3.973913e-06] 
Layer 'conv5' biases: 9.987017e-01 [4.519962e-06] 
Layer 'fc6' weights[0]: 6.484147e-03 [6.643372e-08] 
Layer 'fc6' biases: 9.999881e-01 [7.053133e-08] 
Layer 'fc7' weights[0]: 6.819871e-03 [1.679886e-07] 
Layer 'fc7' biases: 9.996601e-01 [2.778483e-07] 
Layer 'fc8' weights[0]: 4.872121e-03 [1.463395e-05] 
Layer 'fc8' biases: 3.248143e-02 [4.561548e-05] 
Train error last 800 batches: 0.656770
-------------------------------------------------------
Not saving because 0.554661 > 0.299667 (9.300: -1.18%)
======================================================= (2.380 sec)
39.161... logprob:  0.545186, 0.234375 (1.409 sec)
39.162... logprob:  0.831734, 0.334635 (1.403 sec)
39.163... logprob:  0.637627, 0.273438 (1.423 sec)
39.164... logprob:  0.661794, 0.309896 (1.412 sec)
39.165... logprob:  0.780172, 0.334635 (1.413 sec)
39.166... logprob:  0.740243, 0.312500 (1.442 sec)
39.167... logprob:  0.608348, 0.276042 (1.424 sec)
39.168... logprob:  0.542048, 0.229167 (1.420 sec)
39.169... logprob:  0.592560, 0.291667 (1.452 sec)
39.170... logprob:  0.609232, 0.268229 (1.397 sec)
39.171... logprob:  0.724145, 0.346354 (1.415 sec)
39.172... logprob:  0.666092, 0.266927 (1.409 sec)
39.173... logprob:  0.752766, 0.341146 (1.446 sec)
39.174... logprob:  0.691777, 0.277344 (1.396 sec)
39.175... logprob:  0.682668, 0.282552 (1.461 sec)
39.176... logprob:  0.667124, 0.282552 (1.409 sec)
39.177... logprob:  0.536083, 0.246094 (1.418 sec)
39.178... logprob:  0.618242, 0.278646 (1.454 sec)
39.179... logprob:  0.614768, 0.286458 (1.400 sec)
39.180... logprob:  0.801630, 0.305990 (1.422 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.387891, 0.078125 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.730819e-03 [8.654619e-08] 
Layer 'conv1' biases: 2.211590e-06 [1.993845e-11] 
Layer 'conv2' weights[0]: 1.727310e-03 [8.639115e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.655963e-10] 
Layer 'conv3' weights[0]: 1.726474e-03 [8.657146e-08] 
Layer 'conv3' biases: 3.672979e-05 [4.997974e-09] 
Layer 'conv4' weights[0]: 1.733822e-03 [8.710641e-08] 
Layer 'conv4' biases: 9.997542e-01 [2.736317e-07] 
Layer 'conv5' weights[0]: 1.961060e-03 [3.006968e-06] 
Layer 'conv5' biases: 9.987056e-01 [3.317655e-06] 
Layer 'fc6' weights[0]: 6.483487e-03 [6.319405e-08] 
Layer 'fc6' biases: 9.999886e-01 [6.670643e-08] 
Layer 'fc7' weights[0]: 6.819190e-03 [1.652616e-07] 
Layer 'fc7' biases: 9.996597e-01 [2.581932e-07] 
Layer 'fc8' weights[0]: 4.860423e-03 [1.542500e-05] 
Layer 'fc8' biases: 3.242971e-02 [4.401906e-05] 
Train error last 800 batches: 0.657106
-------------------------------------------------------
Not saving because 0.387891 > 0.299667 (9.300: -1.18%)
======================================================= (2.357 sec)
39.181... logprob:  0.783769, 0.339844 (1.423 sec)
39.182... logprob:  0.599062, 0.294271 (1.415 sec)
39.183... logprob:  0.689145, 0.292969 (1.412 sec)
39.184... logprob:  0.647689, 0.292969 (1.410 sec)
39.185... logprob:  0.549770, 0.268229 (1.392 sec)
39.186... logprob:  0.598908, 0.289062 (1.392 sec)
39.187... logprob:  0.859111, 0.359375 (1.397 sec)
39.188... logprob:  0.665665, 0.273437 (1.395 sec)
39.189... logprob:  0.691399, 0.290364 (1.380 sec)
39.190... logprob:  0.570330, 0.247396 (1.434 sec)
39.191... logprob:  0.720403, 0.299479 (1.399 sec)
39.192... logprob:  0.719297, 0.319010 (1.409 sec)
39.193... logprob:  0.520873, 0.246094 (1.409 sec)
39.194... logprob:  0.642662, 0.294271 (1.410 sec)
39.195... logprob:  0.539531, 0.253906 (1.391 sec)
39.196... logprob:  0.724174, 0.307292 (1.386 sec)
39.197... logprob:  0.573373, 0.242188 (1.392 sec)
39.198... logprob:  0.583992, 0.264323 (1.405 sec)
39.199... logprob:  0.670727, 0.290365 (1.385 sec)
39.200... logprob:  0.686417, 0.311198 (1.432 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.533772, 0.148438 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.729098e-03 [8.651529e-08] 
Layer 'conv1' biases: 2.211536e-06 [9.880781e-12] 
Layer 'conv2' weights[0]: 1.725577e-03 [8.633081e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.168212e-10] 
Layer 'conv3' weights[0]: 1.724744e-03 [8.643202e-08] 
Layer 'conv3' biases: 3.674037e-05 [4.392414e-09] 
Layer 'conv4' weights[0]: 1.732085e-03 [8.692668e-08] 
Layer 'conv4' biases: 9.997526e-01 [1.950026e-07] 
Layer 'conv5' weights[0]: 1.957589e-03 [2.538889e-06] 
Layer 'conv5' biases: 9.987136e-01 [2.762586e-06] 
Layer 'fc6' weights[0]: 6.482827e-03 [5.812428e-08] 
Layer 'fc6' biases: 9.999885e-01 [5.849918e-08] 
Layer 'fc7' weights[0]: 6.818523e-03 [1.432193e-07] 
Layer 'fc7' biases: 9.996591e-01 [1.910395e-07] 
Layer 'fc8' weights[0]: 4.843221e-03 [1.173757e-05] 
Layer 'fc8' biases: 3.234866e-02 [2.599108e-05] 
Train error last 800 batches: 0.657102
-------------------------------------------------------
Not saving because 0.533772 > 0.299667 (9.300: -1.18%)
======================================================= (2.384 sec)
39.201... logprob:  0.642636, 0.260417 (1.409 sec)
39.202... logprob:  0.844409, 0.375000 (1.406 sec)
39.203... logprob:  0.626590, 0.246094 (1.438 sec)
39.204... logprob:  0.722272, 0.312500 (1.381 sec)
39.205... logprob:  0.545924, 0.247396 (1.396 sec)
39.206... logprob:  0.550126, 0.247396 (1.392 sec)
39.207... logprob:  0.557145, 0.261719 (1.388 sec)
39.208... logprob:  0.625966, 0.255208 (1.389 sec)
39.209... logprob:  0.472525, 0.210938 (1.415 sec)
39.210... logprob:  0.724597, 0.307292 (1.409 sec)
39.211... logprob:  0.648182, 0.283854 (1.408 sec)
39.212... logprob:  0.794586, 0.304687 (1.426 sec)
39.213... logprob:  0.716535, 0.328125 (1.456 sec)
39.214... logprob:  0.644643, 0.281250 (1.415 sec)
39.215... logprob:  0.670386, 0.316406 (1.414 sec)
39.216... logprob:  0.782935, 0.290365 (1.459 sec)
39.217... logprob:  0.565658, 0.261719 (1.397 sec)
39.218... logprob:  0.672212, 0.325521 (1.415 sec)
39.219... logprob:  0.719315, 0.303385 (1.407 sec)
39.220... logprob:  0.652455, 0.287760 (1.411 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.387949, 0.070312 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.727366e-03 [8.638203e-08] 
Layer 'conv1' biases: 2.211569e-06 [1.582871e-11] 
Layer 'conv2' weights[0]: 1.723847e-03 [8.621935e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.077271e-10] 
Layer 'conv3' weights[0]: 1.723019e-03 [8.635620e-08] 
Layer 'conv3' biases: 3.675077e-05 [4.398517e-09] 
Layer 'conv4' weights[0]: 1.730354e-03 [8.680080e-08] 
Layer 'conv4' biases: 9.997503e-01 [2.430127e-07] 
Layer 'conv5' weights[0]: 1.953504e-03 [2.309584e-06] 
Layer 'conv5' biases: 9.987215e-01 [2.551514e-06] 
Layer 'fc6' weights[0]: 6.482163e-03 [6.003344e-08] 
Layer 'fc6' biases: 9.999884e-01 [6.174092e-08] 
Layer 'fc7' weights[0]: 6.817859e-03 [1.485176e-07] 
Layer 'fc7' biases: 9.996584e-01 [2.114173e-07] 
Layer 'fc8' weights[0]: 4.828262e-03 [1.275648e-05] 
Layer 'fc8' biases: 3.224879e-02 [3.073052e-05] 
Train error last 800 batches: 0.656967
-------------------------------------------------------
Not saving because 0.387949 > 0.299667 (9.300: -1.18%)
======================================================= (2.348 sec)
39.221... logprob:  0.669809, 0.272135 (1.404 sec)
39.222... logprob:  0.786993, 0.328125 (1.457 sec)
39.223... logprob:  0.696851, 0.302083 (1.426 sec)
39.224... logprob:  0.621663, 0.279948 (1.422 sec)
39.225... logprob:  0.656771, 0.279948 (1.444 sec)
39.226... logprob:  0.572996, 0.248698 (1.413 sec)
39.227... logprob:  0.677376, 0.287760 (1.407 sec)
39.228... logprob:  0.728203, 0.328125 (1.414 sec)
39.229... logprob:  0.667547, 0.294271 (1.418 sec)
39.230... logprob:  0.688896, 0.287760 (1.424 sec)
39.231... logprob:  0.598055, 0.274740 (1.397 sec)
39.232... logprob:  0.716270, 0.276042 (1.456 sec)
39.233... logprob:  0.708253, 0.316406 (1.425 sec)
39.234... logprob:  0.765430, 0.338542 (1.408 sec)
39.235... logprob:  0.606108, 0.285156 (1.462 sec)
39.236... logprob:  0.621386, 0.256510 (1.395 sec)
39.237... logprob:  0.614636, 0.265625 (1.418 sec)
39.238... logprob:  0.598555, 0.263021 (1.415 sec)
39.239... logprob:  0.778572, 0.330729 (1.415 sec)
39.240... logprob:  0.708325, 0.299479 (1.395 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.424695, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.725633e-03 [8.631376e-08] 
Layer 'conv1' biases: 2.211629e-06 [1.039491e-11] 
Layer 'conv2' weights[0]: 1.722129e-03 [8.614603e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.406208e-10] 
Layer 'conv3' weights[0]: 1.721288e-03 [8.621739e-08] 
Layer 'conv3' biases: 3.675732e-05 [3.575929e-09] 
Layer 'conv4' weights[0]: 1.728610e-03 [8.662228e-08] 
Layer 'conv4' biases: 9.997489e-01 [1.493528e-07] 
Layer 'conv5' weights[0]: 1.950855e-03 [2.442804e-06] 
Layer 'conv5' biases: 9.987394e-01 [2.652468e-06] 
Layer 'fc6' weights[0]: 6.481528e-03 [6.005391e-08] 
Layer 'fc6' biases: 9.999886e-01 [6.102815e-08] 
Layer 'fc7' weights[0]: 6.817153e-03 [1.546422e-07] 
Layer 'fc7' biases: 9.996571e-01 [2.136318e-07] 
Layer 'fc8' weights[0]: 4.791536e-03 [1.421376e-05] 
Layer 'fc8' biases: 3.193854e-02 [4.201496e-05] 
Train error last 800 batches: 0.656924
-------------------------------------------------------
Not saving because 0.424695 > 0.299667 (9.300: -1.18%)
======================================================= (2.356 sec)
39.241... logprob:  0.686243, 0.294271 (1.464 sec)
39.242... logprob:  0.625426, 0.294271 (1.425 sec)
39.243... logprob:  0.610750, 0.272135 (1.427 sec)
39.244... logprob:  0.484471, 0.200521 (1.445 sec)
39.245... logprob:  0.753218, 0.322916 (1.417 sec)
39.246... logprob:  0.657877, 0.278646 (1.408 sec)
39.247... logprob:  0.556942, 0.256510 (1.413 sec)
39.248... logprob:  0.550381, 0.247396 (1.416 sec)
39.249... logprob:  0.713554, 0.312500 (1.412 sec)
39.250... logprob:  0.695603, 0.300781 (1.403 sec)
39.251... logprob:  0.586755, 0.282552 (1.464 sec)
39.252... logprob:  0.649220, 0.276042 (1.425 sec)
39.253... logprob:  0.642294, 0.248698 (1.415 sec)
39.254... logprob:  0.682514, 0.308594 (1.461 sec)
39.255... logprob:  0.643662, 0.265625 (1.398 sec)
39.256... logprob:  0.587241, 0.261719 (1.413 sec)
39.257... logprob:  0.596698, 0.279948 (1.419 sec)
39.258... logprob:  0.674256, 0.329427 (1.419 sec)
39.259... logprob:  0.673396, 0.295573 (1.395 sec)
39.260... logprob:  0.593882, 0.264323 (1.452 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.431672, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.723916e-03 [8.624988e-08] 
Layer 'conv1' biases: 2.211581e-06 [1.368467e-11] 
Layer 'conv2' weights[0]: 1.720405e-03 [8.606794e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.632130e-10] 
Layer 'conv3' weights[0]: 1.719565e-03 [8.614058e-08] 
Layer 'conv3' biases: 3.671588e-05 [3.491060e-09] 
Layer 'conv4' weights[0]: 1.726883e-03 [8.659471e-08] 
Layer 'conv4' biases: 9.997543e-01 [1.747453e-07] 
Layer 'conv5' weights[0]: 1.956412e-03 [2.653057e-06] 
Layer 'conv5' biases: 9.986902e-01 [3.014574e-06] 
Layer 'fc6' weights[0]: 6.480907e-03 [5.769834e-08] 
Layer 'fc6' biases: 9.999884e-01 [5.805069e-08] 
Layer 'fc7' weights[0]: 6.816444e-03 [1.446396e-07] 
Layer 'fc7' biases: 9.996601e-01 [2.038746e-07] 
Layer 'fc8' weights[0]: 4.886117e-03 [1.185511e-05] 
Layer 'fc8' biases: 3.275174e-02 [3.094907e-05] 
Train error last 800 batches: 0.656945
-------------------------------------------------------
Not saving because 0.431672 > 0.299667 (9.300: -1.18%)
======================================================= (2.368 sec)
39.261... logprob:  0.562426, 0.277344 (1.431 sec)
39.262... logprob:  0.724455, 0.294271 (1.429 sec)
39.263... logprob:  0.640961, 0.250000 (1.440 sec)
39.264... logprob:  0.632776, 0.308594 (1.414 sec)
39.265... logprob:  0.697258, 0.307292 (1.411 sec)
39.266... logprob:  0.671975, 0.299479 (1.407 sec)
39.267... logprob:  0.573192, 0.278646 (1.411 sec)
39.268... logprob:  0.587684, 0.270833 (1.422 sec)
39.269... logprob:  0.703820, 0.324219 (1.400 sec)
39.270... logprob:  0.758111, 0.335937 (1.461 sec)
39.271... logprob:  0.580238, 0.250000 (1.422 sec)
39.272... logprob:  0.639903, 0.319010 (1.417 sec)
39.273... logprob:  0.638171, 0.261719 (1.468 sec)
39.274... logprob:  0.737078, 0.282552 (1.392 sec)
39.275... logprob:  0.699258, 0.302083 (1.420 sec)
39.276... logprob:  0.568174, 0.239583 (1.412 sec)
39.277... logprob:  0.490768, 0.233073 (1.418 sec)
39.278... logprob:  0.486907, 0.222656 (1.417 sec)
39.279... logprob:  0.627976, 0.299479 (1.457 sec)
39.280... logprob:  0.502186, 0.250000 (1.398 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.511189, 0.140625 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.722196e-03 [8.618030e-08] 
Layer 'conv1' biases: 2.211670e-06 [2.262729e-11] 
Layer 'conv2' weights[0]: 1.718685e-03 [8.599197e-08] 
Layer 'conv2' biases: 9.999996e-01 [4.754684e-10] 
Layer 'conv3' weights[0]: 1.717858e-03 [8.633836e-08] 
Layer 'conv3' biases: 3.671178e-05 [6.737260e-09] 
Layer 'conv4' weights[0]: 1.725156e-03 [8.705779e-08] 
Layer 'conv4' biases: 9.997541e-01 [3.495490e-07] 
Layer 'conv5' weights[0]: 1.954679e-03 [3.256041e-06] 
Layer 'conv5' biases: 9.986851e-01 [3.705610e-06] 
Layer 'fc6' weights[0]: 6.480260e-03 [6.069075e-08] 
Layer 'fc6' biases: 9.999884e-01 [6.282791e-08] 
Layer 'fc7' weights[0]: 6.815752e-03 [1.545612e-07] 
Layer 'fc7' biases: 9.996599e-01 [2.599687e-07] 
Layer 'fc8' weights[0]: 4.895554e-03 [1.378654e-05] 
Layer 'fc8' biases: 3.283250e-02 [4.145434e-05] 
Train error last 800 batches: 0.656411
-------------------------------------------------------
Not saving because 0.511189 > 0.299667 (9.300: -1.18%)
======================================================= (2.388 sec)
39.281... logprob:  0.514438, 0.257812 (1.430 sec)
39.282... logprob:  0.717924, 0.300781 (1.421 sec)
39.283... logprob:  0.618880, 0.279948 (1.416 sec)
39.284... logprob:  0.593815, 0.295573 (1.405 sec)
39.285... logprob:  0.598100, 0.256510 (1.436 sec)
39.286... logprob:  0.631669, 0.291667 (1.436 sec)
39.287... logprob:  0.602678, 0.269531 (1.428 sec)
39.288... logprob:  0.582362, 0.270833 (1.429 sec)
39.289... logprob:  0.725463, 0.317708 (1.456 sec)
39.290... logprob:  0.610772, 0.291667 (1.399 sec)
39.291... logprob:  0.628982, 0.289062 (1.413 sec)
39.292... logprob:  0.708440, 0.305990 (1.408 sec)
39.293... logprob:  0.617668, 0.294271 (1.425 sec)
39.294... logprob:  0.640948, 0.268229 (1.406 sec)
39.295... logprob:  0.570996, 0.283854 (1.453 sec)
39.296... logprob:  0.556269, 0.239583 (1.417 sec)
39.297... logprob:  0.710672, 0.341146 (1.416 sec)
39.298... logprob:  0.665779, 0.279948 (1.462 sec)
39.299... logprob:  0.608302, 0.296875 (1.395 sec)
39.300... logprob:  0.626761, 0.286458 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.393434, 0.085938 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.720469e-03 [8.605419e-08] 
Layer 'conv1' biases: 2.211785e-06 [9.648926e-12] 
Layer 'conv2' weights[0]: 1.716972e-03 [8.588485e-08] 
Layer 'conv2' biases: 9.999996e-01 [1.235261e-10] 
Layer 'conv3' weights[0]: 1.716150e-03 [8.586871e-08] 
Layer 'conv3' biases: 3.669944e-05 [1.769548e-09] 
Layer 'conv4' weights[0]: 1.723434e-03 [8.624737e-08] 
Layer 'conv4' biases: 9.997555e-01 [7.408479e-08] 
Layer 'conv5' weights[0]: 1.955415e-03 [1.871767e-06] 
Layer 'conv5' biases: 9.986617e-01 [2.017949e-06] 
Layer 'fc6' weights[0]: 6.479599e-03 [5.205590e-08] 
Layer 'fc6' biases: 9.999881e-01 [5.048622e-08] 
Layer 'fc7' weights[0]: 6.815072e-03 [1.262649e-07] 
Layer 'fc7' biases: 9.996609e-01 [1.495964e-07] 
Layer 'fc8' weights[0]: 4.939446e-03 [9.513543e-06] 
Layer 'fc8' biases: 3.314310e-02 [7.659861e-06] 
Train error last 800 batches: 0.655905
-------------------------------------------------------
Not saving because 0.393434 > 0.299667 (9.300: -1.18%)
======================================================= (2.378 sec)
39.301... logprob:  0.637889, 0.273438 (1.418 sec)
39.302... logprob:  0.829348, 0.325521 (1.421 sec)
39.303... logprob:  0.605722, 0.261719 (1.403 sec)
39.304... logprob:  0.667713, 0.321615 (1.435 sec)
39.305... logprob:  0.724932, 0.333333 (1.430 sec)
39.306... logprob:  0.681265, 0.300781 (1.431 sec)
39.307... logprob:  0.651671, 0.287760 (1.434 sec)
39.308... logprob:  0.563110, 0.252604 (1.446 sec)
39.309... logprob:  0.648694, 0.279948 (1.412 sec)
39.310... logprob:  0.584024, 0.261719 (1.414 sec)
39.311... logprob:  0.756430, 0.296875 (1.418 sec)
39.312... logprob:  0.549044, 0.234375 (1.427 sec)
39.313... logprob:  0.636071, 0.302083 (1.422 sec)
39.314... logprob:  0.655791, 0.265625 (1.454 sec)
39.315... logprob:  0.549771, 0.276042 (1.428 sec)
39.316... logprob:  0.643249, 0.291667 (1.419 sec)
39.317... logprob:  0.574742, 0.256510 (1.478 sec)
39.318... logprob:  0.618055, 0.286458 (1.414 sec)
39.319... logprob:  0.668517, 0.273438 (1.416 sec)
39.320... logprob:  0.580685, 0.259114 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.501446, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.718751e-03 [8.596297e-08] 
Layer 'conv1' biases: 2.211953e-06 [1.242571e-11] 
Layer 'conv2' weights[0]: 1.715250e-03 [8.579778e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.392243e-10] 
Layer 'conv3' weights[0]: 1.714444e-03 [8.583659e-08] 
Layer 'conv3' biases: 3.673382e-05 [3.179161e-09] 
Layer 'conv4' weights[0]: 1.721712e-03 [8.627920e-08] 
Layer 'conv4' biases: 9.997508e-01 [1.717377e-07] 
Layer 'conv5' weights[0]: 1.948126e-03 [1.904564e-06] 
Layer 'conv5' biases: 9.987024e-01 [2.135793e-06] 
Layer 'fc6' weights[0]: 6.478923e-03 [5.363786e-08] 
Layer 'fc6' biases: 9.999883e-01 [5.213973e-08] 
Layer 'fc7' weights[0]: 6.814412e-03 [1.314734e-07] 
Layer 'fc7' biases: 9.996595e-01 [1.580307e-07] 
Layer 'fc8' weights[0]: 4.878394e-03 [1.014385e-05] 
Layer 'fc8' biases: 3.265213e-02 [1.032871e-05] 
Train error last 800 batches: 0.655324
-------------------------------------------------------
Not saving because 0.501446 > 0.299667 (9.300: -1.18%)
======================================================= (2.393 sec)
39.321... logprob:  0.646519, 0.294271 (1.428 sec)
39.322... logprob:  0.582186, 0.217448 (1.419 sec)
39.323... logprob:  0.727867, 0.326823 (1.468 sec)
39.324... logprob:  0.716565, 0.307292 (1.415 sec)
39.325... logprob:  0.574364, 0.266927 (1.430 sec)
39.326... logprob:  0.646631, 0.272135 (1.461 sec)
39.327... logprob:  0.753100, 0.299479 (1.418 sec)
39.328... logprob:  0.720195, 0.304687 (1.430 sec)
39.329... logprob:  0.645636, 0.276042 (1.424 sec)
39.330... logprob:  0.580492, 0.269531 (1.416 sec)
39.331... logprob:  0.624377, 0.268229 (1.408 sec)
39.332... logprob:  0.718406, 0.328125 (1.446 sec)
39.333... logprob:  0.615399, 0.281250 (1.437 sec)
39.334... logprob:  0.722798, 0.300781 (1.432 sec)
39.335... logprob:  0.606530, 0.281250 (1.438 sec)
39.336... logprob:  0.598268, 0.243490 (1.446 sec)
39.337... logprob:  0.715529, 0.298177 (1.409 sec)
39.338... logprob:  0.611789, 0.282552 (1.418 sec)
39.339... logprob:  0.679248, 0.298177 (1.422 sec)
39.340... logprob:  0.672267, 0.290365 (1.420 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.569960, 0.164062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.717026e-03 [8.588784e-08] 
Layer 'conv1' biases: 2.212054e-06 [1.142004e-11] 
Layer 'conv2' weights[0]: 1.713531e-03 [8.571922e-08] 
Layer 'conv2' biases: 9.999996e-01 [1.723377e-10] 
Layer 'conv3' weights[0]: 1.712725e-03 [8.571419e-08] 
Layer 'conv3' biases: 3.675317e-05 [2.292084e-09] 
Layer 'conv4' weights[0]: 1.719991e-03 [8.611412e-08] 
Layer 'conv4' biases: 9.997489e-01 [1.077814e-07] 
Layer 'conv5' weights[0]: 1.944592e-03 [2.370397e-06] 
Layer 'conv5' biases: 9.987153e-01 [2.641500e-06] 
Layer 'fc6' weights[0]: 6.478263e-03 [5.615333e-08] 
Layer 'fc6' biases: 9.999886e-01 [5.580079e-08] 
Layer 'fc7' weights[0]: 6.813717e-03 [1.377768e-07] 
Layer 'fc7' biases: 9.996585e-01 [1.710546e-07] 
Layer 'fc8' weights[0]: 4.853700e-03 [1.079673e-05] 
Layer 'fc8' biases: 3.243492e-02 [1.093931e-05] 
Train error last 800 batches: 0.654918
-------------------------------------------------------
Not saving because 0.569960 > 0.299667 (9.300: -1.18%)
======================================================= (2.371 sec)
39.341... logprob:  0.812989, 0.295573 (1.414 sec)
39.342... logprob:  0.669501, 0.316406 (1.466 sec)
39.343... logprob:  0.695965, 0.291667 (1.437 sec)
39.344... logprob:  0.639966, 0.272135 (1.474 sec)
39.345... logprob:  0.749086, 0.324219 (1.434 sec)
39.346... logprob:  0.702586, 0.285156 (1.429 sec)
39.347... logprob:  0.638402, 0.259115 (1.478 sec)
39.348... logprob:  0.559956, 0.248698 (1.424 sec)
39.349... logprob:  0.688335, 0.307292 (1.429 sec)
39.350... logprob:  0.552524, 0.251302 (1.430 sec)
39.351... logprob:  0.741703, 0.312500 (1.423 sec)
39.352... logprob:  0.605262, 0.300781 (1.427 sec)
39.353... logprob:  0.702681, 0.304688 (1.481 sec)
39.354... logprob:  0.706555, 0.312500 (1.425 sec)
39.355... logprob:  0.651625, 0.292969 (1.441 sec)
39.356... logprob:  0.718129, 0.334635 (1.469 sec)
39.357... logprob:  0.616225, 0.305990 (1.423 sec)
39.358... logprob:  0.591809, 0.260417 (1.435 sec)
39.359... logprob:  0.764726, 0.341146 (1.432 sec)
39.360... logprob:  0.581290, 0.259115 (1.421 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.447438, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.715308e-03 [8.583473e-08] 
Layer 'conv1' biases: 2.212081e-06 [2.114305e-11] 
Layer 'conv2' weights[0]: 1.711818e-03 [8.564729e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.975961e-10] 
Layer 'conv3' weights[0]: 1.711004e-03 [8.587126e-08] 
Layer 'conv3' biases: 3.676735e-05 [5.877771e-09] 
Layer 'conv4' weights[0]: 1.718263e-03 [8.649648e-08] 
Layer 'conv4' biases: 9.997486e-01 [2.890128e-07] 
Layer 'conv5' weights[0]: 1.943336e-03 [2.667266e-06] 
Layer 'conv5' biases: 9.987316e-01 [2.900827e-06] 
Layer 'fc6' weights[0]: 6.477616e-03 [6.171955e-08] 
Layer 'fc6' biases: 9.999887e-01 [6.310175e-08] 
Layer 'fc7' weights[0]: 6.813081e-03 [1.553702e-07] 
Layer 'fc7' biases: 9.996575e-01 [2.420853e-07] 
Layer 'fc8' weights[0]: 4.828253e-03 [1.433815e-05] 
Layer 'fc8' biases: 3.223426e-02 [3.685919e-05] 
Train error last 800 batches: 0.655023
-------------------------------------------------------
Not saving because 0.447438 > 0.299667 (9.300: -1.18%)
======================================================= (2.376 sec)
39.361... logprob:  0.641483, 0.279948 (1.435 sec)
39.362... logprob:  0.615509, 0.266927 (1.480 sec)
39.363... logprob:  0.666866, 0.313802 (1.431 sec)
39.364... logprob:  0.726625, 0.302083 (1.449 sec)
39.365... logprob:  0.651360, 0.287760 (1.468 sec)
39.366... logprob:  0.628060, 0.259115 (1.473 sec)
39.367... logprob:  0.600828, 0.270833 (1.440 sec)
39.368... logprob:  0.765381, 0.330729 (1.427 sec)
39.369... logprob:  0.663281, 0.274740 (1.421 sec)
39.370... logprob:  0.643346, 0.296875 (1.430 sec)
39.371... logprob:  0.644625, 0.300781 (1.454 sec)
39.372... logprob:  0.754816, 0.338542 (1.446 sec)
39.373... logprob:  0.625163, 0.270833 (1.446 sec)
39.374... logprob:  0.644286, 0.279948 (1.444 sec)
39.375... logprob:  0.676248, 0.307291 (1.458 sec)
39.376... logprob:  0.679872, 0.320312 (1.429 sec)
39.377... logprob:  0.506164, 0.217448 (1.418 sec)
39.378... logprob:  0.666121, 0.279948 (1.424 sec)
39.379... logprob:  0.771198, 0.325521 (1.429 sec)
39.380... logprob:  0.803208, 0.364583 (1.435 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.314394, 0.039062 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.713595e-03 [8.571007e-08] 
Layer 'conv1' biases: 2.212066e-06 [1.875562e-11] 
Layer 'conv2' weights[0]: 1.710116e-03 [8.554277e-08] 
Layer 'conv2' biases: 9.999996e-01 [3.226186e-10] 
Layer 'conv3' weights[0]: 1.709291e-03 [8.566060e-08] 
Layer 'conv3' biases: 3.676453e-05 [4.155445e-09] 
Layer 'conv4' weights[0]: 1.716543e-03 [8.613623e-08] 
Layer 'conv4' biases: 9.997500e-01 [2.108108e-07] 
Layer 'conv5' weights[0]: 1.944023e-03 [2.767390e-06] 
Layer 'conv5' biases: 9.987172e-01 [3.073284e-06] 
Layer 'fc6' weights[0]: 6.476945e-03 [6.027554e-08] 
Layer 'fc6' biases: 9.999887e-01 [6.152512e-08] 
Layer 'fc7' weights[0]: 6.812420e-03 [1.518764e-07] 
Layer 'fc7' biases: 9.996582e-01 [2.137491e-07] 
Layer 'fc8' weights[0]: 4.847532e-03 [1.253965e-05] 
Layer 'fc8' biases: 3.243628e-02 [3.209088e-05] 
Train error last 800 batches: 0.655167
-------------------------------------------------------
Not saving because 0.314394 > 0.299667 (9.300: -1.18%)
======================================================= (2.365 sec)
39.381... logprob:  0.665577, 0.274740 (1.469 sec)
39.382... logprob:  0.640913, 0.285156 (1.451 sec)
39.383... logprob:  0.600907, 0.277344 (1.429 sec)
39.384... logprob:  0.742577, 0.332031 (1.479 sec)
39.385... logprob:  0.721521, 0.296875 (1.431 sec)
39.386... logprob:  0.699573, 0.290365 (1.420 sec)
39.387... logprob:  0.642852, 0.261719 (1.432 sec)
39.388... logprob:  0.658783, 0.283854 (1.428 sec)
39.389... logprob:  0.609509, 0.270833 (1.429 sec)
39.390... logprob:  0.555784, 0.260417 (1.466 sec)
39.391... logprob:  0.612412, 0.278646 (1.437 sec)
39.392... logprob:  0.633196, 0.265625 (1.433 sec)
39.393... logprob:  0.687734, 0.320312 (1.482 sec)
39.394... logprob:  0.617339, 0.276042 (1.431 sec)
39.395... logprob:  0.669532, 0.311198 (1.429 sec)
39.396... logprob:  0.462165, 0.204427 (1.431 sec)
39.397... logprob:  0.737190, 0.321615 (1.424 sec)
39.398... logprob:  0.670608, 0.292969 (1.433 sec)
39.399... logprob:  0.611324, 0.253906 (1.476 sec)
39.400... logprob:  0.785481, 0.356771 (1.429 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.462974, 0.109375 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.711885e-03 [8.564336e-08] 
Layer 'conv1' biases: 2.212090e-06 [1.076834e-11] 
Layer 'conv2' weights[0]: 1.708408e-03 [8.546545e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.197350e-10] 
Layer 'conv3' weights[0]: 1.707581e-03 [8.551260e-08] 
Layer 'conv3' biases: 3.677249e-05 [3.343578e-09] 
Layer 'conv4' weights[0]: 1.714847e-03 [8.599165e-08] 
Layer 'conv4' biases: 9.997499e-01 [1.638294e-07] 
Layer 'conv5' weights[0]: 1.942825e-03 [2.350558e-06] 
Layer 'conv5' biases: 9.987155e-01 [2.549106e-06] 
Layer 'fc6' weights[0]: 6.476313e-03 [5.775362e-08] 
Layer 'fc6' biases: 9.999888e-01 [5.772296e-08] 
Layer 'fc7' weights[0]: 6.811725e-03 [1.451648e-07] 
Layer 'fc7' biases: 9.996578e-01 [1.954904e-07] 
Layer 'fc8' weights[0]: 4.839240e-03 [1.243054e-05] 
Layer 'fc8' biases: 3.240768e-02 [2.566524e-05] 
Train error last 800 batches: 0.655200
-------------------------------------------------------
Not saving because 0.462974 > 0.299667 (9.300: -1.18%)
======================================================= (2.358 sec)
39.401... logprob:  0.659538, 0.295573 (1.441 sec)
39.402... logprob:  0.647473, 0.298177 (1.481 sec)
39.403... logprob:  0.624687, 0.261719 (1.432 sec)
39.404... logprob:  0.762253, 0.317708 (1.452 sec)
39.405... logprob:  0.717837, 0.335938 (1.427 sec)
39.406... logprob:  0.558239, 0.225260 (1.424 sec)
39.407... logprob:  0.735705, 0.273438 (1.425 sec)
39.408... logprob:  0.524983, 0.186198 (1.475 sec)
39.409... logprob:  0.642087, 0.292969 (1.432 sec)
39.410... logprob:  0.669532, 0.282552 (1.443 sec)
39.411... logprob:  0.600805, 0.256510 (1.468 sec)
39.412... logprob:  0.712162, 0.307292 (1.429 sec)
39.413... logprob:  0.802036, 0.342448 (1.432 sec)
39.414... logprob:  0.703268, 0.295573 (1.427 sec)
39.415... logprob:  0.619594, 0.257812 (1.417 sec)
39.416... logprob:  0.663161, 0.298177 (1.429 sec)
39.417... logprob:  0.631380, 0.283854 (1.458 sec)
39.418... logprob:  0.592392, 0.236979 (1.446 sec)
39.419... logprob:  0.673672, 0.287760 (1.446 sec)
39.420... logprob:  0.535846, 0.244792 (1.447 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.505561, 0.132812 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.710175e-03 [8.556038e-08] 
Layer 'conv1' biases: 2.212137e-06 [2.213381e-11] 
Layer 'conv2' weights[0]: 1.706691e-03 [8.538325e-08] 
Layer 'conv2' biases: 9.999996e-01 [4.439225e-10] 
Layer 'conv3' weights[0]: 1.705896e-03 [8.564859e-08] 
Layer 'conv3' biases: 3.677487e-05 [6.047075e-09] 
Layer 'conv4' weights[0]: 1.713131e-03 [8.627393e-08] 
Layer 'conv4' biases: 9.997504e-01 [3.436388e-07] 
Layer 'conv5' weights[0]: 1.941909e-03 [2.883170e-06] 
Layer 'conv5' biases: 9.987085e-01 [3.312701e-06] 
Layer 'fc6' weights[0]: 6.475612e-03 [6.282766e-08] 
Layer 'fc6' biases: 9.999889e-01 [6.548230e-08] 
Layer 'fc7' weights[0]: 6.811070e-03 [1.603076e-07] 
Layer 'fc7' biases: 9.996578e-01 [2.506027e-07] 
Layer 'fc8' weights[0]: 4.831028e-03 [1.428277e-05] 
Layer 'fc8' biases: 3.240357e-02 [4.370206e-05] 
Train error last 800 batches: 0.654976
-------------------------------------------------------
Not saving because 0.505561 > 0.299667 (9.300: -1.18%)
======================================================= (2.347 sec)
39.421... logprob:  0.602860, 0.290365 (1.458 sec)
39.422... logprob:  0.718767, 0.291667 (1.440 sec)
39.423... logprob:  0.671821, 0.290365 (1.425 sec)
39.424... logprob:  0.558317, 0.257812 (1.426 sec)
39.425... logprob:  0.680629, 0.329427 (1.437 sec)
39.426... logprob:  0.635804, 0.294271 (1.437 sec)
39.427... logprob:  0.695536, 0.296875 (1.459 sec)
39.428... logprob:  0.731733, 0.311198 (1.444 sec)
39.429... logprob:  0.744755, 0.329427 (1.441 sec)
39.430... logprob:  0.544599, 0.231771 (1.465 sec)
39.431... logprob:  0.780153, 0.295573 (1.430 sec)
39.432... logprob:  0.617193, 0.253906 (1.422 sec)
39.433... logprob:  0.590083, 0.290365 (1.433 sec)
39.434... logprob:  0.741531, 0.329427 (1.436 sec)
39.435... logprob:  0.749760, 0.321615 (1.427 sec)
39.436... logprob:  0.596871, 0.261719 (1.471 sec)
39.437... logprob:  0.703189, 0.286458 (1.439 sec)
39.438... logprob:  0.761600, 0.316406 (1.426 sec)
39.439... logprob:  0.576548, 0.256510 (1.479 sec)
39.440... logprob:  0.639003, 0.279948 (1.427 sec)
=========================
Testing 10 batches

======================Test output======================
logprob:  0.443865, 0.101562 
------------------------------------------------------- 
Layer 'conv1' weights[0]: 1.708464e-03 [8.542865e-08] 
Layer 'conv1' biases: 2.212233e-06 [1.879076e-11] 
Layer 'conv2' weights[0]: 1.704983e-03 [8.527546e-08] 
Layer 'conv2' biases: 9.999996e-01 [2.661185e-10] 
Layer 'conv3' weights[0]: 1.704169e-03 [8.536652e-08] 
Layer 'conv3' biases: 3.676987e-05 [3.436681e-09] 
Layer 'conv4' weights[0]: 1.711406e-03 [8.577872e-08] 
Layer 'conv4' biases: 9.997511e-01 [1.533307e-07] 
Layer 'conv5' weights[0]: 1.941653e-03 [2.308348e-06] 
Layer 'conv5' biases: 9.986915e-01 [2.569097e-06] 
Layer 'fc6' weights[0]: 6.474970e-03 [5.791184e-08] 
Layer 'fc6' biases: 9.999887e-01 [5.899239e-08] 
Layer 'fc7' weights[0]: 6.810378e-03 [1.452669e-07] 
Layer 'fc7' biases: 9.996584e-01 [1.925832e-07] 
Layer 'fc8' weights[0]: 4.845459e-03 [1.173227e-05] 
Layer 'fc8' biases: 3.259097e-02 [1.737606e-05] 
Train error last 800 batches: 0.654988
-------------------------------------------------------
Not saving because 0.443865 > 0.299667 (9.300: -1.18%)
======================================================= (2.369 sec)
39.441... logprob:  0.684188, 0.305990 (1.433 sec)
39.442... logprob:  0.645235, 0.274740 (1.469 sec)
39.443... logprob:  0.697007, 0.311198 (1.426 sec)
39.444...