TO DO
=====


visual insection of data
- once downsized to 256x256!!


Transfer Learning:
- freeze backprop on conv layers
- try tight fc, even proportion training cases

  
F-measure:
- modify cost function to account for imbalanced classes


False negatives:
- if we take the entire dataset (no filtering out), are there far more
false negatives than false positives? if so, I could modify my cost
function to penalise false negatives less
- plot this on a graph for intuition
- to test it properly, need a well-labelled dataset, with
representative class proportions


Data Augmentation:
- normal
- full rotation
- blind spots (cf blind spots paper)


InitW:
- SGD tricks


Smart Preprocessing:
- blurring if only colour matters
- greyscale if only shape matter
- filter spotted



MUST READS
==========

Image Blind Spots - Intriguing ppties of neural networks, Szegedy et al.

SGD tricks 1

SGD tricks 2


