\relax 
\citation{control-point}
\citation{control-point}
\citation{control-point}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Explaining the Problem}{5}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Code Coverage for Request Server\relax }}{5}}
\citation{control-point}
\citation{MIML}
\citation{MIML}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Formalising the problem: Multi-Instance Multi-Label Supervised Learning}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Challenges specific to the Pipe Weld Classification Task}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.1}Data Overview}{6}}
\citation{office}
\citation{surf}
\citation{krizhevsky}
\citation{transfer-learning}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Count of Redbox images with given label\relax }}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.2}Multi-Tagging}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.3}Domain Change}{7}}
\citation{krizhevsky}
\citation{transfer-learning}
\citation{decaf}
\citation{f-measure}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.4}Small Dataset Size}{8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.5}Class Imbalance}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces soil contamination risk (left), water contamination risk (centre), no risk (right)\relax }}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces left: a Redbox photo - right: a Bluebox photo\relax }}{10}}
\citation{univ-approx}
\@writefile{toc}{\contentsline {section}{\numberline {2}Literature Review}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Supervised Learning}{11}}
\newlabel{learning: optimisation equation}{{1}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Approximation vs Generalisation}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Models of Neurons}{11}}
\@writefile{toc}{\contentsline {paragraph}{Multipolar Biological Neuron}{11}}
\citation{DL-book}
\citation{krizhevsky}
\citation{rectifier}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces a multipolar biological neuron\relax }}{12}}
\@writefile{toc}{\contentsline {paragraph}{Binary Threshold Neuron}{12}}
\@writefile{toc}{\contentsline {paragraph}{Logistic Sigmoid Neuron}{12}}
\newlabel{sigmoid neuron}{{3}{12}}
\@writefile{toc}{\contentsline {paragraph}{Rectified Linear Neuron}{12}}
\newlabel{relu}{{4}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces single-input logistic sigmoid neuron\relax }}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces single-input rectified linear neuron\relax }}{13}}
\@writefile{toc}{\contentsline {paragraph}{Softmax Neuron}{13}}
\citation{DL-book}
\citation{DL-book}
\citation{DL-book}
\citation{Russel&Norvig}
\citation{DL-book}
\citation{MLP-univ-approx}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Feed-forward Architecture}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces graphical representation of $y = x*sin(a*x+b)$ (source: Bengio 2009)\relax }}{14}}
\@writefile{toc}{\contentsline {paragraph}{Shallow Feed-Forward Neural Networks: the Perceptron}{14}}
\@writefile{toc}{\contentsline {paragraph}{Deep Feed-Forward Neural Networks: the Multilayer Perceptron}{14}}
\citation{goodfellow_street_view}
\citation{DL-book}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Multi Layer Perceptron with 2 hidden layers\relax }}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Justifying Depth}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces LeNet7 architecture: each square is a kernel\relax }}{15}}
\citation{DL-book}
\citation{Bengio_G+}
\citation{Bengio_G+}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Backpropagation}{17}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.1}Compute Error-Weight Partial Derivatives}{17}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.2}Update Weight Values with Gradient Descent}{17}}
\newlabel{eqn:learning_rule}{{8}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}Overfit}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces an error surface with poor local minima\relax }}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Overfit as polynomial order increases (source: Bishop 2010)\relax }}{18}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.7.1}Cross Validation}{18}}
\citation{ML-book}
\citation{data-aug}
\citation{dropout}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.7.2}Data Augmentation}{19}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.7.3}Dropout}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces source: (Hinton et al 2012)\relax }}{19}}
\citation{rectifier}
\citation{goodfellow_street_view}
\citation{decaf}
\citation{fergus_tutorial}
\citation{colah}
\citation{zeiler_fergus}
\citation{transfer-learning}
\citation{caffe-website}
\citation{fergus_tutorial}
\citation{SIFT}
\citation{colah}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8}Deep Convolutional Neural Networks}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces LeNet7 architecture: each square is a kernel\relax }}{21}}
\citation{SIFT}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Architecture of CNN from (Krizhevsky et al 2012)\relax }}{22}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.1}Pixel Feature}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Selecting a pixel window and applying a kernel to it (source: convmatrix Gimp documentation)\relax }}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Producing a kernel map (source: River Trail documentation)\relax }}{23}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Image, kernel and resulting kernel map (source: convmatrix Gip documentation\relax }}{23}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{materialflowChart}{{16}{23}}
\newlabel{eqn:conv_learning_rule}{{9}{23}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.2}Non-linear Activation}{23}}
\newlabel{fig:2a}{{17(a)}{23}}
\newlabel{sub@fig:2a}{{(a)}{23}}
\newlabel{fig:2b}{{17(b)}{23}}
\newlabel{sub@fig:2b}{{(b)}{23}}
\citation{zeiler_fergus}
\newlabel{fig:2b}{{18(a)}{24}}
\newlabel{sub@fig:2b}{{(a)}{24}}
\newlabel{fig:2a}{{18(b)}{24}}
\newlabel{sub@fig:2a}{{(b)}{24}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces source: (Zeiler and Fergus 2013)\relax }}{24}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.3}Pooling aka Spatial Feature}{24}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.4}Contrast Normalisation}{25}}
\citation{krizhevsky}
\citation{rectifier}
\newlabel{fig:2a}{{19(a)}{26}}
\newlabel{sub@fig:2a}{{(a)}{26}}
\newlabel{fig:2b}{{19(b)}{26}}
\newlabel{sub@fig:2b}{{(b)}{26}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Analysis 1: ReLU Activation}{26}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Motivations}{26}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces ReLU path selection (source: Glorot et al 2013)\relax }}{27}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Mathematical Analysis}{27}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}How the Gradient Propagates}{27}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}An Example}{27}}
\citation{DL-book}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces $\mathbb  {R}^3 \rightarrow \mathbb  {R}$ MLP with 1 hidden layer\relax }}{28}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}Vanishing Gradient}{28}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.4}Impact of the ReLU}{29}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Analysis 2: Early Stopping}{31}}
\@writefile{toc}{\contentsline {paragraph}{Gradient Descent}{31}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Task 1: Generic Clamp Detection}{31}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Motivations}{31}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Implementation: Cuda-Convnet}{31}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Cuda-Convnet: An Out-of-the-box API}{32}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}Hardware: NVidia GeForce GTX 780}{32}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Discovery}{32}}
\citation{krizhevsky}
\citation{transfer-learning}
\citation{decaf}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces The clamp wraps around under the pipe - the glint of a metal rod gives it away\relax }}{33}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces This clamp is not a weld clamp\relax }}{33}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces The clamp on the vertical rod is not a weld clamp\relax }}{33}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}Non-Converging Error Rates}{33}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Test Run Training Results\relax }}{34}}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces test and validation error rates for clamp detection after fixing a large test range\relax }}{35}}
\@writefile{toc}{\contentsline {paragraph}{Increase Test Error Precision}{35}}
\@writefile{toc}{\contentsline {paragraph}{Alter Momentum}{36}}
\@writefile{toc}{\contentsline {subparagraph}{Increase}{36}}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces test and validation error rates for clamp detection after raising momentum\relax }}{36}}
\@writefile{toc}{\contentsline {subparagraph}{Decrease}{36}}
\@writefile{toc}{\contentsline {paragraph}{Reduce Learning Rate}{36}}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces test and validation error rates for clamp detection after setting momentum to zero\relax }}{37}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2}Class Imbalance}{37}}
\@writefile{toc}{\contentsline {paragraph}{Stuck in Sampling-Induced, "fake" Corner Minimum}{37}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Class Proportions Across Batches that Score Different Training Errors\relax }}{38}}
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces test and validation error rates for clamp detection after setting momentum to zero\relax }}{38}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.3}Mislabelling}{38}}
\@writefile{lof}{\contentsline {figure}{\numberline {31}{\ignorespaces filters learned from a successfully optimised lowest convolutional layer\relax }}{39}}
\@writefile{lof}{\contentsline {figure}{\numberline {32}{\ignorespaces filters learned at lowest convolutional layer of this network\relax }}{39}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.4}Data Complexity}{39}}
\citation{caffe-website}
\@writefile{toc}{\contentsline {section}{\numberline {6}Task 2: Transfer Learning}{40}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Motivations}{40}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Implementation: Caffe}{40}}
\@writefile{toc}{\contentsline {paragraph}{leveldb}{40}}
\@writefile{toc}{\contentsline {paragraph}{Class Imbalance Solver}{40}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Experimentation}{41}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.1}Test Run}{41}}
\@writefile{lof}{\contentsline {figure}{\numberline {33}{\ignorespaces Without transfer learning\relax }}{41}}
\@writefile{lof}{\contentsline {figure}{\numberline {34}{\ignorespaces With transfer learning\relax }}{42}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.2}Initialising Free Layers}{42}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.3}Freezing Backprop on various layers}{42}}
\newlabel{fig:2a}{{35(a)}{43}}
\newlabel{sub@fig:2a}{{(a)}{43}}
\newlabel{fig:2b}{{35(b)}{43}}
\newlabel{sub@fig:2b}{{(b)}{43}}
\@writefile{lof}{\contentsline {figure}{\numberline {35}{\ignorespaces Another figure\relax }}{43}}
\newlabel{fig:2}{{35}{43}}
\newlabel{fig:2a}{{36(a)}{43}}
\newlabel{sub@fig:2a}{{(a)}{43}}
\newlabel{fig:2b}{{36(b)}{43}}
\newlabel{sub@fig:2b}{{(b)}{43}}
\@writefile{lof}{\contentsline {figure}{\numberline {36}{\ignorespaces Another figure\relax }}{43}}
\newlabel{fig:2}{{36}{43}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.4}Parametric vs Non-parametric}{44}}
\newlabel{fig:2a}{{37(a)}{45}}
\newlabel{sub@fig:2a}{{(a)}{45}}
\newlabel{fig:2b}{{37(b)}{45}}
\newlabel{sub@fig:2b}{{(b)}{45}}
\@writefile{lof}{\contentsline {figure}{\numberline {37}{\ignorespaces hinge loss\relax }}{45}}
\newlabel{fig:2}{{37}{45}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Task 3: Class Imbalance}{46}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Motivations}{46}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Implementation}{46}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Experimentation}{46}}
\newlabel{fig:2a}{{38(a)}{47}}
\newlabel{sub@fig:2a}{{(a)}{47}}
\newlabel{fig:2b}{{38(b)}{47}}
\newlabel{sub@fig:2b}{{(b)}{47}}
\@writefile{lof}{\contentsline {figure}{\numberline {38}{\ignorespaces no transfer learning\relax }}{47}}
\newlabel{fig:2}{{38}{47}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.1}Test Run}{47}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.2}Transfer Learning}{47}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.3}Batch Size}{47}}
\newlabel{fig:2a}{{39(a)}{48}}
\newlabel{sub@fig:2a}{{(a)}{48}}
\newlabel{fig:2b}{{39(b)}{48}}
\newlabel{sub@fig:2b}{{(b)}{48}}
\newlabel{fig:2b}{{39(c)}{48}}
\newlabel{sub@fig:2b}{{(c)}{48}}
\@writefile{lof}{\contentsline {figure}{\numberline {39}{\ignorespaces 98\% imbalance, varying levels of transfer learning\relax }}{48}}
\newlabel{fig:2}{{39}{48}}
\@writefile{lof}{\contentsline {figure}{\numberline {40}{\ignorespaces Clamp Detection, Full Backpropagation\relax }}{49}}
\newlabel{fig:2a}{{41(a)}{49}}
\newlabel{sub@fig:2a}{{(a)}{49}}
\newlabel{fig:2b}{{41(b)}{49}}
\newlabel{sub@fig:2b}{{(b)}{49}}
\@writefile{lof}{\contentsline {figure}{\numberline {41}{\ignorespaces 98\% imbalance, different mini-batch sizes\relax }}{49}}
\newlabel{fig:2}{{41}{49}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.4}Learning Rate}{49}}
\newlabel{fig:2a}{{42(a)}{50}}
\newlabel{sub@fig:2a}{{(a)}{50}}
\newlabel{fig:2b}{{42(b)}{50}}
\newlabel{sub@fig:2b}{{(b)}{50}}
\@writefile{lof}{\contentsline {figure}{\numberline {42}{\ignorespaces 98\% imbalance, different learning rates\relax }}{50}}
\newlabel{fig:2}{{42}{50}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.5}Bayesian Cross Entropy Cost Function}{50}}
\@writefile{toc}{\contentsline {paragraph}{Motivations}{50}}
\@writefile{toc}{\contentsline {paragraph}{Implementation}{50}}
\newlabel{fig:2a}{{43(a)}{51}}
\newlabel{sub@fig:2a}{{(a)}{51}}
\newlabel{fig:2b}{{43(b)}{51}}
\newlabel{sub@fig:2b}{{(b)}{51}}
\@writefile{lof}{\contentsline {figure}{\numberline {43}{\ignorespaces Ground Sheet detection, different backpropagation formulae\relax }}{51}}
\newlabel{fig:2}{{43}{51}}
\@writefile{toc}{\contentsline {paragraph}{Results}{51}}
\newlabel{fig:2a}{{44(a)}{52}}
\newlabel{sub@fig:2a}{{(a)}{52}}
\newlabel{fig:2b}{{44(b)}{52}}
\newlabel{sub@fig:2b}{{(b)}{52}}
\@writefile{lof}{\contentsline {figure}{\numberline {44}{\ignorespaces 98\% imbalance, different cost functions\relax }}{52}}
\newlabel{fig:2}{{44}{52}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.6}Under-Sampling}{52}}
\@writefile{toc}{\contentsline {paragraph}{Overfitting consequences of under-sampling}{52}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.7}Over-Sampling}{52}}
\@writefile{lof}{\contentsline {figure}{\numberline {45}{\ignorespaces Clamp Detection, Full Backpropagation\relax }}{53}}
\@writefile{lof}{\contentsline {figure}{\numberline {46}{\ignorespaces Clamp Detection, Full Backpropagation\relax }}{53}}
\@writefile{lof}{\contentsline {figure}{\numberline {47}{\ignorespaces Clamp Detection, Full Backpropagation\relax }}{54}}
\@writefile{lof}{\contentsline {figure}{\numberline {48}{\ignorespaces Clamp Detection, Full Backpropagation\relax }}{54}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.8}Test-time threshold}{54}}
\@writefile{lof}{\contentsline {figure}{\numberline {49}{\ignorespaces Clamp Detection, Full Backpropagation\relax }}{55}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Task 4: Conserving Spatial Information}{55}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Motivations}{55}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}Implementation}{56}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3}Experimentation}{56}}
\@writefile{toc}{\contentsline {paragraph}{Test Run}{56}}
\@writefile{toc}{\contentsline {paragraph}{Remove pooling and an fc layer}{56}}
\@writefile{toc}{\contentsline {paragraph}{Softmax Bayesian Cross Entropy}{56}}
\@writefile{toc}{\contentsline {section}{\numberline {9}Final Results}{56}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1}Merging Classes}{56}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2}Learning Rate}{56}}
\@writefile{toc}{\contentsline {paragraph}{Step}{56}}
\@writefile{toc}{\contentsline {paragraph}{Exp}{57}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.3}Soil Risk Contamination Task}{57}}
\@writefile{lof}{\contentsline {figure}{\numberline {50}{\ignorespaces Clamp Detection, Full Backpropagation\relax }}{57}}
\@writefile{toc}{\contentsline {paragraph}{Test Run}{57}}
\@writefile{toc}{\contentsline {subparagraph}{Training Results}{58}}
\@writefile{toc}{\contentsline {subparagraph}{Observations}{58}}
\@writefile{toc}{\contentsline {paragraph}{Get more evidence}{58}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4}Hatch Markings}{58}}
\@writefile{lof}{\contentsline {figure}{\numberline {51}{\ignorespaces Clamp Detection, Full Backpropagation\relax }}{59}}
\bibcite{krizhevsky}{1}
\bibcite{rectifier}{2}
\bibcite{SIFT}{3}
\bibcite{goodfellow_street_view}{4}
\bibcite{ReLU_RBM}{5}
\bibcite{dropout}{6}
\bibcite{data-aug}{7}
\@writefile{toc}{\contentsline {section}{\numberline {10}Conclusions and Future Work}{60}}
\bibcite{decaf}{8}
\bibcite{fergus_tutorial}{9}
\bibcite{colah}{10}
\bibcite{MIML}{11}
\bibcite{f-measure}{12}
\bibcite{control-point}{13}
\bibcite{univ-approx}{14}
\bibcite{DL-book}{15}
\bibcite{ML-book}{16}
\bibcite{zeiler_fergus}{17}
\bibcite{Russel & Norvig}{18}
\bibcite{MLP-univ-approx}{19}
\bibcite{office}{20}
\bibcite{Bengio_G+}{21}
\bibcite{surf}{22}
\bibcite{transfer-learning}{23}
\bibcite{cuda-convnet}{24}
\bibcite{caffe-website}{25}
\bibcite{nips-tut}{26}
