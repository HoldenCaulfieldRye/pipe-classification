\contentsline {section}{\numberline {1}Introduction}{5}
\contentsline {subsection}{\numberline {1.1}Explaining the Problem}{5}
\contentsline {subsection}{\numberline {1.2}Formalising the problem: Multi-Instance Multi-Label Supervised Learning}{6}
\contentsline {subsection}{\numberline {1.3}Challenges specific to the Pipe Weld Classification Task}{6}
\contentsline {subsubsection}{\numberline {1.3.1}Data Overview}{6}
\contentsline {subsubsection}{\numberline {1.3.2}Multi-Tagging}{7}
\contentsline {subsubsection}{\numberline {1.3.3}Domain Change}{7}
\contentsline {subsubsection}{\numberline {1.3.4}Small Dataset Size}{8}
\contentsline {subsubsection}{\numberline {1.3.5}Class Imbalance}{8}
\contentsline {section}{\numberline {2}Literature Review}{11}
\contentsline {subsection}{\numberline {2.1}Supervised Learning}{11}
\contentsline {subsection}{\numberline {2.2}Approximation vs Generalisation}{11}
\contentsline {subsection}{\numberline {2.3}Models of Neurons}{11}
\contentsline {paragraph}{Multipolar Biological Neuron}{11}
\contentsline {paragraph}{Binary Threshold Neuron}{12}
\contentsline {paragraph}{Logistic Sigmoid Neuron}{12}
\contentsline {paragraph}{Rectified Linear Neuron}{12}
\contentsline {paragraph}{Softmax Neuron}{13}
\contentsline {subsection}{\numberline {2.4}Feed-forward Architecture}{14}
\contentsline {paragraph}{Shallow Feed-Forward Neural Networks: the Perceptron}{14}
\contentsline {paragraph}{Deep Feed-Forward Neural Networks: the Multilayer Perceptron}{14}
\contentsline {subsection}{\numberline {2.5}Justifying Depth}{15}
\contentsline {subsection}{\numberline {2.6}Backpropagation}{17}
\contentsline {subsubsection}{\numberline {2.6.1}Compute Error-Weight Partial Derivatives}{17}
\contentsline {subsubsection}{\numberline {2.6.2}Update Weight Values with Gradient Descent}{17}
\contentsline {subsection}{\numberline {2.7}Overfit}{17}
\contentsline {subsubsection}{\numberline {2.7.1}Cross Validation}{18}
\contentsline {subsubsection}{\numberline {2.7.2}Data Augmentation}{19}
\contentsline {subsubsection}{\numberline {2.7.3}Dropout}{19}
\contentsline {subsection}{\numberline {2.8}Deep Convolutional Neural Networks}{21}
\contentsline {subsubsection}{\numberline {2.8.1}Pixel Feature}{22}
\contentsline {subsubsection}{\numberline {2.8.2}Non-linear Activation}{23}
\contentsline {subsubsection}{\numberline {2.8.3}Pooling aka Spatial Feature}{24}
\contentsline {subsubsection}{\numberline {2.8.4}Contrast Normalisation}{25}
\contentsline {section}{\numberline {3}Analysis 1: ReLU Activation}{26}
\contentsline {subsection}{\numberline {3.1}Motivations}{26}
\contentsline {subsection}{\numberline {3.2}Mathematical Analysis}{27}
\contentsline {subsubsection}{\numberline {3.2.1}How the Gradient Propagates}{27}
\contentsline {subsubsection}{\numberline {3.2.2}An Example}{27}
\contentsline {subsubsection}{\numberline {3.2.3}Vanishing Gradient}{28}
\contentsline {subsubsection}{\numberline {3.2.4}Impact of the ReLU}{29}
\contentsline {section}{\numberline {4}Analysis 2: Early Stopping}{31}
\contentsline {paragraph}{Gradient Descent}{31}
\contentsline {section}{\numberline {5}Task 1: Generic Clamp Detection}{31}
\contentsline {subsection}{\numberline {5.1}Motivations}{31}
\contentsline {subsection}{\numberline {5.2}Implementation: Cuda-Convnet}{31}
\contentsline {subsubsection}{\numberline {5.2.1}Cuda-Convnet: An Out-of-the-box API}{32}
\contentsline {subsubsection}{\numberline {5.2.2}Hardware: NVidia GeForce GTX 780}{32}
\contentsline {subsection}{\numberline {5.3}Discovery}{32}
\contentsline {subsubsection}{\numberline {5.3.1}Non-Converging Error Rates}{33}
\contentsline {paragraph}{Increase Test Error Precision}{35}
\contentsline {paragraph}{Alter Momentum}{36}
\contentsline {subparagraph}{Increase}{36}
\contentsline {subparagraph}{Decrease}{36}
\contentsline {paragraph}{Reduce Learning Rate}{36}
\contentsline {subsubsection}{\numberline {5.3.2}Class Imbalance}{37}
\contentsline {paragraph}{Stuck in Sampling-Induced, "fake" Corner Minimum}{37}
\contentsline {subsubsection}{\numberline {5.3.3}Mislabelling}{38}
\contentsline {subsubsection}{\numberline {5.3.4}Data Complexity}{39}
\contentsline {section}{\numberline {6}Task 2: Transfer Learning}{40}
\contentsline {subsection}{\numberline {6.1}Motivations}{40}
\contentsline {subsection}{\numberline {6.2}Implementation: Caffe}{40}
\contentsline {paragraph}{leveldb}{40}
\contentsline {paragraph}{Class Imbalance Solver}{40}
\contentsline {subsection}{\numberline {6.3}Experimentation}{41}
\contentsline {subsubsection}{\numberline {6.3.1}Test Run}{41}
\contentsline {subsubsection}{\numberline {6.3.2}Initialising Free Layers}{42}
\contentsline {subsubsection}{\numberline {6.3.3}Freezing Backprop on various layers}{42}
\contentsline {subsubsection}{\numberline {6.3.4}Parametric vs Non-parametric}{44}
\contentsline {section}{\numberline {7}Task 3: Class Imbalance}{46}
\contentsline {subsection}{\numberline {7.1}Motivations}{46}
\contentsline {subsection}{\numberline {7.2}Implementation}{46}
\contentsline {subsection}{\numberline {7.3}Experimentation}{46}
\contentsline {subsubsection}{\numberline {7.3.1}Test Run}{47}
\contentsline {subsubsection}{\numberline {7.3.2}Transfer Learning}{47}
\contentsline {subsubsection}{\numberline {7.3.3}Batch Size}{47}
\contentsline {subsubsection}{\numberline {7.3.4}Learning Rate}{49}
\contentsline {subsubsection}{\numberline {7.3.5}Bayesian Cross Entropy Cost Function}{50}
\contentsline {paragraph}{Motivations}{50}
\contentsline {paragraph}{Implementation}{50}
\contentsline {paragraph}{Results}{51}
\contentsline {subsubsection}{\numberline {7.3.6}Under-Sampling}{52}
\contentsline {paragraph}{Overfitting consequences of under-sampling}{52}
\contentsline {subsubsection}{\numberline {7.3.7}Over-Sampling}{52}
\contentsline {subsubsection}{\numberline {7.3.8}Test-time threshold}{54}
\contentsline {section}{\numberline {8}Task 4: Conserving Spatial Information}{55}
\contentsline {subsection}{\numberline {8.1}Motivations}{55}
\contentsline {subsection}{\numberline {8.2}Implementation}{56}
\contentsline {subsection}{\numberline {8.3}Experimentation}{56}
\contentsline {paragraph}{Test Run}{56}
\contentsline {paragraph}{Remove pooling and an fc layer}{56}
\contentsline {paragraph}{Softmax Bayesian Cross Entropy}{56}
\contentsline {section}{\numberline {9}Final Results}{56}
\contentsline {subsection}{\numberline {9.1}Merging Classes}{56}
\contentsline {subsection}{\numberline {9.2}Learning Rate}{56}
\contentsline {paragraph}{Step}{56}
\contentsline {paragraph}{Exp}{57}
\contentsline {subsection}{\numberline {9.3}Soil Risk Contamination Task}{57}
\contentsline {paragraph}{Test Run}{57}
\contentsline {subparagraph}{Training Results}{58}
\contentsline {subparagraph}{Observations}{58}
\contentsline {paragraph}{Get more evidence}{58}
\contentsline {subsection}{\numberline {9.4}Hatch Markings}{58}
\contentsline {section}{\numberline {10}Conclusions and Future Work}{60}
