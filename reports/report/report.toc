\contentsline {section}{\numberline {1}Introduction}{5}
\contentsline {section}{\numberline {2}Defining the Problem}{5}
\contentsline {subsection}{\numberline {2.1}Explaining the Problem}{5}
\contentsline {subsection}{\numberline {2.2}Formalising the problem: Multi-Instance Multi-Label Supervised Learning}{6}
\contentsline {subsection}{\numberline {2.3}Challenges specific to the Pipe Weld Classification Task}{6}
\contentsline {subsubsection}{\numberline {2.3.1}Data Overview}{7}
\contentsline {subsubsection}{\numberline {2.3.2}Multi-Tagging}{7}
\contentsline {subsubsection}{\numberline {2.3.3}Domain Change}{7}
\contentsline {subsubsection}{\numberline {2.3.4}Small Dataset Size}{8}
\contentsline {subsubsection}{\numberline {2.3.5}Class Imbalance}{8}
\contentsline {section}{\numberline {3}Deep Supervised Learning}{11}
\contentsline {subsection}{\numberline {3.1}Supervised Learning}{11}
\contentsline {subsubsection}{\numberline {3.1.1}Approximation vs Generalisation}{11}
\contentsline {subsection}{\numberline {3.2}Deep Learning: Neurons and Depth}{11}
\contentsline {subsubsection}{\numberline {3.2.1}Models of Neurons}{11}
\contentsline {paragraph}{Multipolar Biological Neuron}{11}
\contentsline {paragraph}{Binary Threshold Neuron}{12}
\contentsline {paragraph}{Logistic Sigmoid Neuron}{12}
\contentsline {paragraph}{Rectified Linear Neuron}{12}
\contentsline {paragraph}{Softmax Neuron}{13}
\contentsline {subsubsection}{\numberline {3.2.2}Why Depth}{14}
\contentsline {paragraph}{Shallow Feed-Forward Neural Networks: the Perceptron}{14}
\contentsline {paragraph}{Deep Feed-Forward Neural Networks: the Multilayer Perceptron}{14}
\contentsline {subsection}{\numberline {3.3}Backpropagation}{16}
\contentsline {subsubsection}{\numberline {3.3.1}Compute Error-Weight Partial Derivatives}{16}
\contentsline {subsubsection}{\numberline {3.3.2}Update Weight Values (with Gradient Descent)}{17}
\contentsline {subsection}{\numberline {3.4}Cross Validation}{17}
\contentsline {subsection}{\numberline {3.5}Deep Convolutional Neural Networks}{18}
\contentsline {subsubsection}{\numberline {3.5.1}Operations in a convolutional layer}{18}
\contentsline {paragraph}{Sliding Kernel a.k.a\ Sliding Filter a.k.a\ Pixel Feature}{18}
\contentsline {paragraph}{Non-linear Activation}{19}
\contentsline {paragraph}{Pooling aka Spatial Feature}{19}
\contentsline {paragraph}{Possible Normalisation}{19}
\contentsline {subsubsection}{\numberline {3.5.2}Dropout}{19}
\contentsline {subsubsection}{\numberline {3.5.3}Data augmentation}{19}
\contentsline {section}{\numberline {4}Analysis 1: ReLU Activation}{20}
\contentsline {subsection}{\numberline {4.1}Motivations}{20}
\contentsline {subsection}{\numberline {4.2}Mathematical Analysis}{21}
\contentsline {subsubsection}{\numberline {4.2.1}How the Gradient Propagates}{21}
\contentsline {subsubsection}{\numberline {4.2.2}An Example}{21}
\contentsline {subsubsection}{\numberline {4.2.3}Vanishing Gradient}{22}
\contentsline {section}{\numberline {5}Analysis 2: Early Stopping}{24}
\contentsline {paragraph}{Gradient Descent}{24}
\contentsline {section}{\numberline {6}Task 1: Generic Clamp Detection}{24}
\contentsline {subsection}{\numberline {6.1}Motivations}{24}
\contentsline {subsection}{\numberline {6.2}Implementation: Cuda-Convnet}{24}
\contentsline {subsubsection}{\numberline {6.2.1}Cuda-Convnet: An Out-of-the-box API}{25}
\contentsline {subsubsection}{\numberline {6.2.2}Hardware: NVidia GeForce GTX 780}{25}
\contentsline {subsection}{\numberline {6.3}Discovery}{25}
\contentsline {subsubsection}{\numberline {6.3.1}Non-Converging Error Rates}{26}
\contentsline {paragraph}{Increase Test Error Precision}{28}
\contentsline {paragraph}{Alter Momentum}{29}
\contentsline {subparagraph}{Increase}{29}
\contentsline {subparagraph}{Decrease}{29}
\contentsline {paragraph}{Reduce Learning Rate}{29}
\contentsline {subsubsection}{\numberline {6.3.2}Class Imbalance}{30}
\contentsline {paragraph}{Stuck in Sampling-Induced, "fake" Corner Minimum}{30}
\contentsline {subsubsection}{\numberline {6.3.3}Mislabelling}{31}
\contentsline {subsubsection}{\numberline {6.3.4}Data Complexity}{32}
\contentsline {section}{\numberline {7}Task 2: Transfer Learning}{33}
\contentsline {subsection}{\numberline {7.1}Motivations}{33}
\contentsline {subsection}{\numberline {7.2}Implementation: Caffe}{33}
\contentsline {paragraph}{leveldb}{33}
\contentsline {paragraph}{Class Imbalance Solver}{33}
\contentsline {subsection}{\numberline {7.3}Experimentation}{34}
\contentsline {subsubsection}{\numberline {7.3.1}Test Run}{34}
\contentsline {subsubsection}{\numberline {7.3.2}Initialising Free Layers}{35}
\contentsline {subsubsection}{\numberline {7.3.3}Freezing Backprop on various layers}{35}
\contentsline {subsubsection}{\numberline {7.3.4}Parametric vs Non-parametric}{37}
\contentsline {section}{\numberline {8}Task 3: Class Imbalance}{39}
\contentsline {subsection}{\numberline {8.1}Motivations}{39}
\contentsline {subsection}{\numberline {8.2}Implementation}{39}
\contentsline {subsection}{\numberline {8.3}Experimentation}{39}
\contentsline {subsubsection}{\numberline {8.3.1}Test Run}{40}
\contentsline {subsubsection}{\numberline {8.3.2}Transfer Learning}{40}
\contentsline {subsubsection}{\numberline {8.3.3}Batch Size}{40}
\contentsline {subsubsection}{\numberline {8.3.4}Learning Rate}{42}
\contentsline {subsubsection}{\numberline {8.3.5}Bayesian Cross Entropy Cost Function}{43}
\contentsline {paragraph}{Motivations}{43}
\contentsline {paragraph}{Implementation}{43}
\contentsline {paragraph}{Results}{44}
\contentsline {subsubsection}{\numberline {8.3.6}Under-Sampling}{45}
\contentsline {paragraph}{Overfitting consequences of under-sampling}{45}
\contentsline {subsubsection}{\numberline {8.3.7}Over-Sampling}{45}
\contentsline {subsubsection}{\numberline {8.3.8}Test-time threshold}{47}
\contentsline {section}{\numberline {9}Task 4: Conserving Spatial Information}{48}
\contentsline {subsection}{\numberline {9.1}Motivations}{48}
\contentsline {subsection}{\numberline {9.2}Implementation}{49}
\contentsline {subsection}{\numberline {9.3}Experimentation}{49}
\contentsline {paragraph}{Test Run}{49}
\contentsline {paragraph}{Remove pooling and an fc layer}{49}
\contentsline {paragraph}{Softmax Bayesian Cross Entropy}{49}
\contentsline {section}{\numberline {10}Final Results}{49}
\contentsline {subsection}{\numberline {10.1}Merging Classes}{49}
\contentsline {subsection}{\numberline {10.2}Learning Rate}{49}
\contentsline {paragraph}{Step}{49}
\contentsline {paragraph}{Exp}{50}
\contentsline {subsection}{\numberline {10.3}Soil Risk Contamination Task}{50}
\contentsline {paragraph}{Test Run}{50}
\contentsline {subparagraph}{Training Results}{51}
\contentsline {subparagraph}{Observations}{51}
\contentsline {paragraph}{Get more evidence}{51}
\contentsline {subsection}{\numberline {10.4}Hatch Markings}{51}
\contentsline {section}{\numberline {11}Conclusions and Future Work}{53}
