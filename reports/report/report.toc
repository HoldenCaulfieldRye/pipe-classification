\contentsline {section}{\numberline {1}Background}{3}
\contentsline {subsection}{\numberline {1.1}Defining the Problem}{3}
\contentsline {subsubsection}{\numberline {1.1.1}Explaining the Problem}{3}
\contentsline {subsubsection}{\numberline {1.1.2}Formalising the problem: Multi-Instance Multi-Label Supervised Learning}{4}
\contentsline {subsubsection}{\numberline {1.1.3}Supervised Learning}{4}
\contentsline {subsubsection}{\numberline {1.1.4}Approximation vs Generalisation}{5}
\contentsline {subsection}{\numberline {1.2}Architecture of a Deep Convolutional Neural Network with Rectified Linear Neurons}{5}
\contentsline {subsubsection}{\numberline {1.2.1}Models of Neurons}{5}
\contentsline {paragraph}{Multipolar Biological Neuron}{5}
\contentsline {paragraph}{Binary Threshold Neuron}{6}
\contentsline {paragraph}{Logistic Sigmoid Neuron}{6}
\contentsline {paragraph}{Rectified Linear Neuron}{6}
\contentsline {paragraph}{Softmax Neuron}{7}
\contentsline {subsubsection}{\numberline {1.2.2}Feed-Forward Architecture}{7}
\contentsline {paragraph}{Shallow Feed-Forward Neural Networks: the Perceptron}{7}
\contentsline {paragraph}{Deep Feed-Forward Neural Networks: the Multilayer Perceptron}{8}
\contentsline {paragraph}{Deep Convolutional Neural Networks: for translation invariance}{8}
\contentsline {subsection}{\numberline {1.3}Training: Backpropagation}{9}
\contentsline {subsubsection}{\numberline {1.3.1}Compute Error-Weight Partial Derivatives}{9}
\contentsline {subsubsection}{\numberline {1.3.2}Update Weight Values (with Gradient Descent)}{9}
\contentsline {paragraph}{Training, Validation and Test Sets}{9}
\contentsline {subsection}{\numberline {1.4}Challenges specific to the Pipe Weld Classification Task}{10}
\contentsline {subsubsection}{\numberline {1.4.1}Data Overview}{10}
\contentsline {subsubsection}{\numberline {1.4.2}Multi-Tagging}{10}
\contentsline {subsubsection}{\numberline {1.4.3}Domain Change}{10}
\contentsline {subsubsection}{\numberline {1.4.4}Small Dataset Size}{11}
\contentsline {subsubsection}{\numberline {1.4.5}Class Imbalance}{12}
\contentsline {section}{\numberline {2}Design}{13}
\contentsline {section}{\numberline {3}Implementation}{14}
\contentsline {subsection}{\numberline {3.1}Cuda-Convnet}{14}
\contentsline {subsubsection}{\numberline {3.1.1}Theano}{14}
\contentsline {section}{\numberline {4}Experimentation}{15}
\contentsline {subsection}{\numberline {4.1}Non-Converging Error Rates}{15}
\contentsline {paragraph}{Increase Test Error Precision}{16}
\contentsline {paragraph}{Volatility of Training Error}{17}
\contentsline {paragraph}{Alter Momentum}{17}
\contentsline {subparagraph}{Increase}{17}
\contentsline {subparagraph}{Decrease}{18}
\contentsline {paragraph}{Reduce Learning Rate}{18}
\contentsline {paragraph}{Stuck in Sampling-Induced, "fake" Corner Minimum}{18}
\contentsline {subsection}{\numberline {4.2}Class Imbalance}{19}
\contentsline {paragraph}{Subset of Training Set}{19}
\contentsline {paragraph}{Partial Data Augmentation}{19}
\contentsline {paragraph}{F Measure}{19}
\contentsline {subsection}{\numberline {4.3}Tight Bowl Zig-zagging}{19}
\contentsline {subsection}{\numberline {4.4}Transfer Learning}{19}
\contentsline {subsection}{\numberline {4.5}Image Preprocessing}{19}
\contentsline {section}{\numberline {5}Conclusions and Future Work}{20}
