\documentclass[a4paper,11pt]{article}
\usepackage[margin=2cm]{geometry}
\usepackage{graphicx}
\usepackage{color, colortbl}
\usepackage{cite}
\usepackage{url}
\usepackage{float}
\usepackage{arydshln}
\usepackage{pdfpages}
\usepackage{csvsimple}
\usepackage{listings}
\usepackage{algpseudocode}
\usepackage{longtable}
\usepackage{pdflscape}
\usepackage{indentfirst}

\definecolor{Green}{rgb}{0.6,1,0.6}
\definecolor{Amber}{rgb}{1,1,0.4}
\definecolor{Red}{rgb}{1,0.6,0.6}

\setlength\parindent{24pt}

\usepackage{fancyhdr}
\pagestyle{fancyplain}
\fancyhf{}
\lhead{\fancyplain{}{M.Sc.\ Individual Project Literature Survey}}
\rhead{\fancyplain{}{\today}}
\cfoot{\fancyplain{}{\thepage}}

\title{Classification of Pipe Weld Images with Deep Neural Networks\\\Large{--- Literature Survey ---}}
\author{Dalyac Alexandre\\
       ad6813@ic.ac.uk\\ \\
       \small{Supervisors: Prof Murray Shanahan and Mr Jack Kelly}\\
       \small{Course: CO541, Imperial College London}
}

\begin{document}

\maketitle

\abstract
{
\par Automatic image classification experienced a breakthrough in 2012 with the advent of GPU implementations of deep neural networks. Since then, state-of-the-art has centred around improving these deep neural networks. The following is a literature survey of papers relevant to the task of learning to automatically multi-tag images of pipe welds, from a restrictive number of training cases, and with high-level knowledge of some abstract features. It is therefore divided into 5 sections: foundations of machine learning with neural networks, deep convolutional neural networks (including deep belief networks), multi-tag learning, learning with few training examples, and incorporating knowledge of the structure of the data into the network architecture to optimise learning.\\

\par In terms of progress, a deep convolutional neural network, pretrained on 10 million images from ImageNet, has been trained on 150,000 pipe weld images for the simplest possible task of discriminating 'good' pipe weld from 'bad' pipe welds. A classification error rate of ??\% has been attained. Although this figure is encouraging, it corresponds to a much simpler formulation of the task: the objective of this project is to achieve multi-tagging for 23 characteristics, some of which require considerable human training.  Include a separate section on progress that describes: the activities and accomplishments of the project to date; any problems or obstacles that might have cropped up and how those problems or obstacles are being dealt with; and plans for the next phases of the project.
}

\clearpage
\tableofcontents

\clearpage
\section{Background}

This project aims to automate the classification of pipe weld images with deep neural networks. Classification is a  machine learning task and deep neural networks are a class of machine learning tools, so we will start with fundamental concepts in machine learning and go through major refinements in neural network architectures to finish with the state-of-the-art machine learning model for image classification: convolutional deep belief nets. The last two sections focus on two challenges specific to the pipe weld image classification task: multi-tagging and learning features from a restricted training set.

\subsection{Defining the problem: Single-Instance Multi-Label Supervised Learning}

Given an instance space X and a set of class labels Y, learn a function f : X -> P(Y) from a given dataset {(x1,y1),(x2,y2), ..., (xn,yn)}, where xi € X is an instance and yi € 

The problem of learning to classify pipe weld images from a labelled dataset is a single-instance, multi-label, supervised learning classification problem. Indeed, the final classification of whether a pipe weld is accepted or rejected depends on the presence or absence of a number of characteristics (note that the term 'characteristic' is to be distinguished from feature and class, and could be defined as a component of a multidimensional class called the pipe weld). Formally, let X denote the instance space and Y = Y1 x Y2 x ... x Yp = {0,1}\^p the set of p characteristics. Then the task is to learn a function f : X -> Y from a given data set {(x1, Y1), (x2, Y2), · · · , (xm, Ym)}, where xi € X is an instance and yi € Y the known characteristics of xi.

This differs from the traditional supervised learning classification task of learning a function f : X → Y where Y = {e1, ... , ep} i.e. the standard normal vectors of R\^p. In other words, a traditional supervised learning classification task has one tag per instance, whereas in this case there can be a number of present characteristics. 

This also differs from the Multi-Instance Multi-Label supervised learning task of learning a function f : X\^2 → Y\^2, i.e. where any number of class instances can appear in one case-to-classify. 



\subsubsection{Supervised Learning}

\subsubsection{Unsupervised Learning}

\subsubsection{Approximation vs Generalisation}

\subsection{Existing Approaches}

This section is divided into the most successful known approaches to tackling the problem, starting with the most successful, and finishing with an oft-times superior contender (which is inferior in this case): discriminative deep neural networks, hidden markov models, gaussian mixture models, and generative deep neural networks. 

Or maybe deep belief nets have never been applied to multi-instance multi-label learning before and this project is a chance to explore their performance.

\subsection{Deep Neural Networks}

\subsubsection{Architecture of Deep Neural Networks}

\paragraph{Feed-Forward Architecture}

\paragraph{Multilayer Peceptron}

\subsubsection{Training}
\paragraph{Gradient Descent}
\paragraph{Backpropagation}

\pagebreak
\subsection{Deep Convolutional Neural Networks}

\subsubsection{Translation Invariance}

\subsubsection{Recent Architecture Improvements}

\pagebreak
\subsection{Deep Belief Nets: a generative model}


\subsection{Multi-Instance Multi-Label Learning}

\subsection{Transfer Learning: learning with a restricted training set}



\clearpage
\section{Progress}

\subsection{Data: pipe weld images}
There are 227,730 640x480 'RedBox' images. There are 1280x960 'BlueBox' images. They all have xx tags.

\subsubsection{Visual Inspection}
\subsubsection{Analysis}
\paragraph{ANOVA}
\paragraph{t-SNE}

\subsection{Cuda-Convnet}
\subsubsection{Test Run}
\subsection{Transfer Learning}

\subsection{Further Work}

\subsubsection{Caffe}

\subsubsection{Theano}

\subsubsection{Hidden Markov Model}

It might be interesting to explore hidden markov models because the data has obvious hidden states which humans benefit from learning: pipe welds can be T welds and standard welds, and this alters where scratch marks need to be seen.

\clearpage
\end{document}
